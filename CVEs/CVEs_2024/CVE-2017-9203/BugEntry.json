{"buggy_code": ["// imagew-bmp.c\n// Part of ImageWorsener, Copyright (c) 2011 by Jason Summers.\n// For more information, see the readme.txt file.\n\n#include \"imagew-config.h\"\n\n#include <stdio.h> // for SEEK_SET\n#include <stdlib.h>\n#include <string.h>\n\n#define IW_INCLUDE_UTIL_FUNCTIONS\n#include \"imagew.h\"\n\n#define IWBMP_BI_RGB       0 // = uncompressed\n#define IWBMP_BI_RLE8      1\n#define IWBMP_BI_RLE4      2\n#define IWBMP_BI_BITFIELDS 3\n#define IWBMP_BI_JPEG      4\n#define IWBMP_BI_PNG       5\n\n#define IWBMPCS_CALIBRATED_RGB    0\n#define IWBMPCS_DEVICE_RGB        1 // (Unconfirmed)\n#define IWBMPCS_DEVICE_CMYK       2 // (Unconfirmed)\n#define IWBMPCS_SRGB              0x73524742\n#define IWBMPCS_WINDOWS           0x57696e20\n#define IWBMPCS_PROFILE_LINKED    0x4c494e4b\n#define IWBMPCS_PROFILE_EMBEDDED  0x4d424544\n\nstatic size_t iwbmp_calc_bpr(int bpp, size_t width)\n{\n\treturn ((bpp*width+31)/32)*4;\n}\n\nstruct iwbmprcontext {\n\tstruct iw_iodescr *iodescr;\n\tstruct iw_context *ctx;\n\tstruct iw_image *img;\n\tint bmpversion;\n\tint width, height;\n\tint topdown;\n\tint has_fileheader;\n\tunsigned int bitcount; // bits per pixel\n\tunsigned int compression; // IWBMP_BI_*\n\tint uses_bitfields; // 'compression' is BI_BITFIELDS\n\tint has_alpha_channel;\n\tint bitfields_set;\n\tint need_16bit;\n\tunsigned int palette_entries;\n\tsize_t fileheader_size;\n\tsize_t infoheader_size;\n\tsize_t bitfields_nbytes; // Bytes consumed by BITFIELDs, if not part of the header.\n\tsize_t palette_nbytes;\n\tsize_t bfOffBits;\n\tstruct iw_palette palette;\n\n\t// For 16- & 32-bit images:\n\tunsigned int bf_mask[4];\n\tint bf_high_bit[4];\n\tint bf_low_bit[4];\n\tint bf_bits_count[4]; // number of bits in each channel\n\n\tstruct iw_csdescr csdescr;\n};\n\nstatic int iwbmp_read(struct iwbmprcontext *rctx,\n\t\tiw_byte *buf, size_t buflen)\n{\n\tint ret;\n\tsize_t bytesread = 0;\n\n\tret = (*rctx->iodescr->read_fn)(rctx->ctx,rctx->iodescr,\n\t\tbuf,buflen,&bytesread);\n\tif(!ret || bytesread!=buflen) {\n\t\treturn 0;\n\t}\n\treturn 1;\n}\n\nstatic int iwbmp_skip_bytes(struct iwbmprcontext *rctx, size_t n)\n{\n\tiw_byte buf[1024];\n\tsize_t still_to_read;\n\tsize_t num_to_read;\n\n\tstill_to_read = n;\n\twhile(still_to_read>0) {\n\t\tnum_to_read = still_to_read;\n\t\tif(num_to_read>1024) num_to_read=1024;\n\t\tif(!iwbmp_read(rctx,buf,num_to_read)) {\n\t\t\treturn 0;\n\t\t}\n\t\tstill_to_read -= num_to_read;\n\t}\n\treturn 1;\n}\n\nstatic int iwbmp_read_file_header(struct iwbmprcontext *rctx)\n{\n\tiw_byte buf[14];\n\n\tif(!iwbmp_read(rctx,buf,14)) return 0;\n\trctx->fileheader_size = 14;\n\n\tif(buf[0]=='B' && buf[1]=='A') { // OS/2 Bitmap Array\n\t\t// TODO: This type of file can contain more than one BMP image.\n\t\t// We only support the first one.\n\t\tif(!iwbmp_read(rctx,buf,14)) return 0;\n\t\trctx->fileheader_size += 14;\n\t}\n\n\tif(buf[0]=='B' && buf[1]=='M') {\n\t\t;\n\t}\n\telse if((buf[0]=='C' && buf[1]=='I') || // OS/2 Color Icon\n\t   (buf[0]=='C' && buf[1]=='P') || // OS/2 Color Pointer\n\t   (buf[0]=='I' && buf[1]=='C') || // OS/2 Icon\n\t   (buf[0]=='P' && buf[1]=='T'))   // OS/2 Pointer\n\t{\n\t\tiw_set_error(rctx->ctx,\"This type of BMP file is not supported\");\n\t\treturn 0;\n\t}\n\telse {\n\t\tiw_set_error(rctx->ctx,\"Not a BMP file\");\n\t\treturn 0;\n\t}\n\n\trctx->bfOffBits = iw_get_ui32le(&buf[10]);\n\treturn 1;\n}\n\n// Read the 12-byte header of a Windows v2 BMP (also known as OS/2 v1 BMP).\nstatic int decode_v2_header(struct iwbmprcontext *rctx, const iw_byte *buf)\n{\n\tunsigned int nplanes;\n\n\trctx->width = iw_get_ui16le(&buf[4]);\n\trctx->height = iw_get_ui16le(&buf[6]);\n\tnplanes = iw_get_ui16le(&buf[8]);\n\tif(nplanes!=1) return 0;\n\trctx->bitcount = iw_get_ui16le(&buf[10]);\n\tif(rctx->bitcount!=1 && rctx->bitcount!=4 &&\n\t\trctx->bitcount!=8 && rctx->bitcount!=24)\n\t{\n\t\treturn 0;\n\t}\n\tif(rctx->bitcount<=8) {\n\t\tsize_t palette_start, palette_end;\n\n\t\trctx->palette_entries = 1<<rctx->bitcount;\n\t\trctx->palette_nbytes = 3*rctx->palette_entries;\n\n\t\t// Since v2 BMPs have no direct way to indicate that the palette is not\n\t\t// full-sized, assume the palette ends no later than the start of the\n\t\t// bitmap bits.\n\t\tpalette_start = rctx->fileheader_size + rctx->infoheader_size;\n\t\tpalette_end = palette_start + rctx->palette_nbytes;\n\t\tif(rctx->bfOffBits >= palette_start+3 && rctx->bfOffBits < palette_end) {\n\t\t\trctx->palette_entries = (unsigned int)((rctx->bfOffBits - palette_start)/3);\n\t\t\trctx->palette_nbytes = 3*rctx->palette_entries;\n\t\t}\n\t}\n\treturn 1;\n}\n\n// Read a Windows v3 or OS/2 v2 header.\nstatic int decode_v3_header_fields(struct iwbmprcontext *rctx, const iw_byte *buf)\n{\n\tunsigned int nplanes;\n\tint biXPelsPerMeter, biYPelsPerMeter;\n\tunsigned int biClrUsed = 0;\n\t//unsigned int biSizeImage;\n\n\trctx->width = iw_get_i32le(&buf[4]);\n\trctx->height = iw_get_i32le(&buf[8]);\n\tif(rctx->height<0) {\n\t\trctx->height = -rctx->height;\n\t\trctx->topdown = 1;\n\t}\n\n\tnplanes = iw_get_ui16le(&buf[12]);\n\tif(nplanes!=1) return 0;\n\n\trctx->bitcount = iw_get_ui16le(&buf[14]);\n\t// We allow bitcount=2 because it's legal in Windows CE BMPs.\n\tif(rctx->bitcount!=1 && rctx->bitcount!=2 && rctx->bitcount!=4 &&\n\t\trctx->bitcount!=8 && rctx->bitcount!=16 && rctx->bitcount!=24 &&\n\t\trctx->bitcount!=32)\n\t{\n\t\tiw_set_errorf(rctx->ctx,\"Bad or unsupported bit count (%d)\",(int)rctx->bitcount);\n\t\treturn 0;\n\t}\n\n\tif(rctx->infoheader_size<=16) {\n\t\tgoto infoheaderdone;\n\t}\n\n\trctx->compression = iw_get_ui32le(&buf[16]);\n\tif(rctx->compression==IWBMP_BI_BITFIELDS) {\n\t\tif(rctx->bitcount==1) {\n\t\t\tiw_set_error(rctx->ctx,\"Huffman 1D compression not supported\");\n\t\t\treturn 0;\n\t\t}\n\t\telse if(rctx->bitcount!=16 && rctx->bitcount!=32) {\n\t\t\tiw_set_error(rctx->ctx,\"Bad or unsupported image type\");\n\t\t\treturn 0;\n\t\t}\n\n\t\t// The compression field is overloaded: BITFIELDS is not a type of\n\t\t// compression. Un-overload it.\n\t\trctx->uses_bitfields = 1;\n\n\t\t// The v4/v5 documentation for the \"BitCount\" field says that the\n\t\t// BITFIELDS data comes after the header, the same as with v3.\n\t\t// The v4/v5 documentation for the \"Compression\" field says that the\n\t\t// BITFIELDS data is stored in the \"Mask\" fields of the header.\n\t\t// Am I supposed to conclude that it is redundantly stored in both\n\t\t// places?\n\t\t// Evidence and common sense suggests the \"BitCount\" documentation is\n\t\t// incorrect, and v4/v5 BMPs never have a separate \"bitfields\" segment.\n\t\tif(rctx->bmpversion==3) {\n\t\t\trctx->bitfields_nbytes = 12;\n\t\t}\n\n\t\trctx->compression=IWBMP_BI_RGB;\n\t}\n\n\t//biSizeImage = iw_get_ui32le(&buf[20]);\n\tbiXPelsPerMeter = iw_get_i32le(&buf[24]);\n\tbiYPelsPerMeter = iw_get_i32le(&buf[28]);\n\n\trctx->img->density_code = IW_DENSITY_UNITS_PER_METER;\n\trctx->img->density_x = (double)biXPelsPerMeter;\n\trctx->img->density_y = (double)biYPelsPerMeter;\n\tif(!iw_is_valid_density(rctx->img->density_x,rctx->img->density_y,rctx->img->density_code)) {\n\t\trctx->img->density_code=IW_DENSITY_UNKNOWN;\n\t}\n\n\tbiClrUsed = iw_get_ui32le(&buf[32]);\n\tif(biClrUsed>100000) return 0;\n\ninfoheaderdone:\n\t// The documentation of the biClrUsed field is not very clear.\n\t// I'm going to assume that if biClrUsed is 0 and bitcount<=8, then\n\t// the number of palette colors is the maximum that would be useful\n\t// for that bitcount. In all other cases, the number of palette colors\n\t// equals biClrUsed.\n\tif(biClrUsed==0 && rctx->bitcount<=8) {\n\t\trctx->palette_entries = 1<<rctx->bitcount;\n\t}\n\telse {\n\t\trctx->palette_entries = biClrUsed;\n\t}\n\trctx->palette_nbytes = 4*rctx->palette_entries;\n\treturn 1;\n}\n\nstatic int process_bf_mask(struct iwbmprcontext *rctx, int k);\n\n// Decode the fields that are in v4 and not in v3.\nstatic int decode_v4_header_fields(struct iwbmprcontext *rctx, const iw_byte *buf)\n{\n\tint k;\n\tunsigned int cstype;\n\n\tif(rctx->uses_bitfields) {\n\t\t// Set the bitfields masks here, instead of in iwbmp_read_bitfields().\n\t\tfor(k=0;k<4;k++) {\n\t\t\trctx->bf_mask[k] = 0;\n\t\t}\n\t\tfor(k=0;k<4;k++) {\n\t\t\tif(rctx->infoheader_size < (size_t)(40+k*4+4)) break;\n\t\t\trctx->bf_mask[k] = iw_get_ui32le(&buf[40+k*4]);\n\t\t\tif(!process_bf_mask(rctx,k)) return 0;\n\t\t}\n\t\trctx->bitfields_set=1; // Remember not to overwrite the bf_* fields.\n\n\t\tif(rctx->bf_mask[3]!=0) {\n\t\t\t// The documentation says this is the mask that \"specifies the\n\t\t\t// alpha component of each pixel.\"\n\t\t\t// It doesn't say whther it's associated, or unassociated alpha.\n\t\t\t// It doesn't say whether 0=transparent, or 0=opaque.\n\t\t\t// It doesn't say how to tell whether an image has an alpha\n\t\t\t// channel.\n\t\t\t// These are the answers I'm going with:\n\t\t\t// - Unassociated alpha\n\t\t\t// - 0=transparent\n\t\t\t// - 16- and 32-bit images have an alpha channel if 'compression'\n\t\t\t// is set to BI_BITFIELDS, and this alpha mask is nonzero.\n\t\t\trctx->has_alpha_channel = 1;\n\t\t}\n\t}\n\n\tif(rctx->infoheader_size < 108) return 1;\n\n\tcstype = iw_get_ui32le(&buf[56]);\n\tswitch(cstype) {\n\tcase IWBMPCS_CALIBRATED_RGB:\n\t\t//  \"indicates that endpoints and gamma values are given in the\n\t\t//    appropriate fields.\"  (TODO)\n\t\tbreak;\n\n\tcase IWBMPCS_DEVICE_RGB:\n\tcase IWBMPCS_SRGB:\n\tcase IWBMPCS_WINDOWS:\n\t\tbreak;\n\n\tcase IWBMPCS_PROFILE_LINKED:\n\tcase IWBMPCS_PROFILE_EMBEDDED:\n\t\tif(rctx->bmpversion<5) {\n\t\t\tiw_warning(rctx->ctx,\"Invalid colorspace type for BMPv4\");\n\t\t}\n\t\tbreak;\n\n\tdefault:\n\t\tiw_warningf(rctx->ctx,\"Unrecognized or unsupported colorspace type (0x%x)\",cstype);\n\t}\n\n\t// Read Gamma fields\n\tif(cstype==IWBMPCS_CALIBRATED_RGB) {\n\t\tunsigned int bmpgamma;\n\t\tdouble gamma[3];\n\t\tdouble avggamma;\n\n\t\tfor(k=0;k<3;k++) {\n\t\t\tbmpgamma = iw_get_ui32le(&buf[96+k*4]);\n\t\t\tgamma[k] = ((double)bmpgamma)/65536.0;\n\t\t}\n\t\tavggamma = (gamma[0] + gamma[1] + gamma[2])/3.0;\n\n\t\tif(avggamma>=0.1 && avggamma<=10.0) {\n\t\t\tiw_make_gamma_csdescr(&rctx->csdescr,1.0/avggamma);\n\t\t}\n\t}\n\n\treturn 1;\n}\n\n// Decode the fields that are in v5 and not in v4.\nstatic int decode_v5_header_fields(struct iwbmprcontext *rctx, const iw_byte *buf)\n{\n\tunsigned int intent_bmp_style;\n\tint intent_iw_style;\n\n\tintent_bmp_style = iw_get_ui32le(&buf[108]);\n\tintent_iw_style = IW_INTENT_UNKNOWN;\n\tswitch(intent_bmp_style) {\n\t\tcase 1: intent_iw_style = IW_INTENT_SATURATION; break; // LCS_GM_BUSINESS\n\t\tcase 2: intent_iw_style = IW_INTENT_RELATIVE; break; // LCS_GM_GRAPHICS\n\t\tcase 4: intent_iw_style = IW_INTENT_PERCEPTUAL; break; // LCS_GM_IMAGES\n\t\tcase 8: intent_iw_style = IW_INTENT_ABSOLUTE; break; // LCS_GM_ABS_COLORIMETRIC\n\t}\n\trctx->img->rendering_intent = intent_iw_style;\n\n\t// The profile may either be after the color table, or after the bitmap bits.\n\t// I'm assuming that we will never need to use the profile size in order to\n\t// find the bitmap bits; i.e. that if the bfOffBits field in the file header\n\t// is not available, the profile must be after the bits.\n\t//profile_offset = iw_get_ui32le(&buf[112]); // bV5ProfileData;\n\t//profile_size = iw_get_ui32le(&buf[116]); // bV5ProfileSize;\n\n\treturn 1;\n}\n\nstatic int iwbmp_read_info_header(struct iwbmprcontext *rctx)\n{\n\tiw_byte buf[124];\n\tint retval = 0;\n\tsize_t n;\n\n\t// First, read just the \"size\" field. It tells the size of the header\n\t// structure, and identifies the BMP version.\n\tif(!iwbmp_read(rctx,buf,4)) goto done;\n\trctx->infoheader_size = iw_get_ui32le(&buf[0]);\n\tif(rctx->infoheader_size<12) goto done;\n\n\t// Read the rest of the header.\n\tn = rctx->infoheader_size;\n\tif(n>sizeof(buf)) n=sizeof(buf);\n\tif(!iwbmp_read(rctx,&buf[4],n-4)) goto done;\n\n\tif(rctx->infoheader_size==12) {\n\t\t// This is a \"Windows BMP v2\" or \"OS/2 BMP v1\" bitmap.\n\t\trctx->bmpversion=2;\n\t\tif(!decode_v2_header(rctx,buf)) goto done;\n\t}\n\telse if(rctx->infoheader_size==16 || rctx->infoheader_size==40 || rctx->infoheader_size==64) {\n\t\t// A Windows v3 or OS/2 v2 BMP.\n\t\t// OS/2 v2 BMPs can technically have other header sizes between 16 and 64,\n\t\t// but it's not clear if such files actually exist.\n\t\trctx->bmpversion=3;\n\t\tif(!decode_v3_header_fields(rctx,buf)) goto done;\n\t}\n\telse if(rctx->infoheader_size==108 || rctx->infoheader_size==52 || rctx->infoheader_size==56) {\n\t\t// We assume a a 52- or 56-byte header is for BITMAPV2INFOHEADER/BITMAPV3INFOHEADER,\n\t\t// and not OS/2v2 format. But if it OS/2v2, it will probably either work (because\n\t\t// the formats are similar enough), or fail due to an unsupported combination of\n\t\t// compression and bits/pixel.\n\t\trctx->bmpversion=4;\n\t\tif(!decode_v3_header_fields(rctx,buf)) goto done;\n\t\tif(!decode_v4_header_fields(rctx,buf)) goto done;\n\t}\n\telse if(rctx->infoheader_size==124) {\n\t\trctx->bmpversion=5;\n\t\tif(!decode_v3_header_fields(rctx,buf)) goto done;\n\t\tif(!decode_v4_header_fields(rctx,buf)) goto done;\n\t\tif(!decode_v5_header_fields(rctx,buf)) goto done;\n\t}\n\telse {\n\t\tiw_set_error(rctx->ctx,\"Unsupported BMP version\");\n\t\tgoto done;\n\t}\n\n\tif(!iw_check_image_dimensions(rctx->ctx,rctx->width,rctx->height)) {\n\t\tgoto done;\n\t}\n\n\tretval = 1;\n\ndone:\n\treturn retval;\n}\n\n// Find the highest/lowest bit that is set.\nstatic int find_high_bit(unsigned int x)\n{\n\tint i;\n\tfor(i=31;i>=0;i--) {\n\t\tif(x&(1U<<(unsigned int)i)) return i;\n\t}\n\treturn 0;\n}\nstatic int find_low_bit(unsigned int x)\n{\n\tint i;\n\tfor(i=0;i<=31;i++) {\n\t\tif(x&(1U<<(unsigned int)i)) return i;\n\t}\n\treturn 0;\n}\n\n// Given .bf_mask[k], set high_bit[k], low_bit[k], etc.\nstatic int process_bf_mask(struct iwbmprcontext *rctx, int k)\n{\n\t// The bits representing the mask for each channel are required to be\n\t// contiguous, so all we need to do is find the highest and lowest bit.\n\trctx->bf_high_bit[k] = find_high_bit(rctx->bf_mask[k]);\n\trctx->bf_low_bit[k] = find_low_bit(rctx->bf_mask[k]);\n\trctx->bf_bits_count[k] = 1+rctx->bf_high_bit[k]-rctx->bf_low_bit[k];\n\n\t// Check if the mask specifies an invalid bit\n\tif(rctx->bf_high_bit[k] > (int)(rctx->bitcount-1)) return 0;\n\n\tif(rctx->bf_bits_count[k]>16) {\n\t\t// We only support up to 16 bits. Ignore any bits after the 16th.\n\t\trctx->bf_low_bit[k] = rctx->bf_high_bit[k]-15;\n\t\trctx->bf_bits_count[k] = 16;\n\t}\n\n\tif(rctx->bf_bits_count[k]>8) {\n\t\trctx->need_16bit = 1;\n\t}\n\n\treturn 1;\n}\n\nstatic int iwbmp_read_bitfields(struct iwbmprcontext *rctx)\n{\n\tiw_byte buf[12];\n\tint k;\n\n\tif(!iwbmp_read(rctx,buf,12)) return 0;\n\n\tfor(k=0;k<3;k++) {\n\t\trctx->bf_mask[k] = iw_get_ui32le(&buf[k*4]);\n\t\tif(rctx->bf_mask[k]==0) return 0;\n\n\t\t// Find the high bit, low bit, etc.\n\t\tif(!process_bf_mask(rctx,k)) return 0;\n\t}\n\n\treturn 1;\n}\n\nstatic void iwbmp_set_default_bitfields(struct iwbmprcontext *rctx)\n{\n\tint k;\n\n\tif(rctx->bitfields_set) return;\n\n\tif(rctx->bitcount==16) {\n\t\t// Default is 5 bits for each channel.\n\t\trctx->bf_mask[0]=0x7c00; // 01111100 00000000 (red)\n\t\trctx->bf_mask[1]=0x03e0; // 00000011 11100000 (green)\n\t\trctx->bf_mask[2]=0x001f; // 00000000 00011111 (blue)\n\t}\n\telse if(rctx->bitcount==32) {\n\t\trctx->bf_mask[0]=0x00ff0000;\n\t\trctx->bf_mask[1]=0x0000ff00;\n\t\trctx->bf_mask[2]=0x000000ff;\n\t}\n\telse {\n\t\treturn;\n\t}\n\n\tfor(k=0;k<3;k++) {\n\t\tprocess_bf_mask(rctx,k);\n\t}\n}\n\nstatic int iwbmp_read_palette(struct iwbmprcontext *rctx)\n{\n\tsize_t i;\n\tiw_byte buf[4*256];\n\tsize_t b;\n\tunsigned int valid_palette_entries;\n\tsize_t valid_palette_nbytes;\n\n\tb = (rctx->bmpversion==2) ? 3 : 4; // bytes per palette entry\n\n\tif(rctx->infoheader_size==64) {\n\t\t// According to what little documentation I can find, OS/2v2 BMP files\n\t\t// have 4 bytes per palette entry. But some of the files I've seen have\n\t\t// only 3. This is a little hack to support them.\n\t\tif(rctx->fileheader_size + rctx->infoheader_size + rctx->palette_entries*3 ==\n\t\t\trctx->bfOffBits)\n\t\t{\n\t\t\tiw_warning(rctx->ctx,\"BMP bitmap overlaps colormap; assuming colormap uses 3 bytes per entry instead of 4\");\n\t\t\tb = 3;\n\t\t\trctx->palette_nbytes = 3*rctx->palette_entries;\n\t\t}\n\t}\n\n\t// If the palette has >256 colors, only use the first 256.\n\tvalid_palette_entries = (rctx->palette_entries<=256) ? rctx->palette_entries : 256;\n\tvalid_palette_nbytes = valid_palette_entries * b;\n\n\n\tif(!iwbmp_read(rctx,buf,valid_palette_nbytes)) return 0;\n\trctx->palette.num_entries = valid_palette_entries;\n\tfor(i=0;i<valid_palette_entries;i++) {\n\t\trctx->palette.entry[i].b = buf[i*b+0];\n\t\trctx->palette.entry[i].g = buf[i*b+1];\n\t\trctx->palette.entry[i].r = buf[i*b+2];\n\t\trctx->palette.entry[i].a = 255;\n\t}\n\n\t// If the palette is oversized, skip over the unused part of it.\n\tif(rctx->palette_nbytes > valid_palette_nbytes) {\n\t\tiwbmp_skip_bytes(rctx, rctx->palette_nbytes - valid_palette_nbytes);\n\t}\n\treturn 1;\n}\n\nstatic void bmpr_convert_row_32_16(struct iwbmprcontext *rctx, const iw_byte *src, size_t row)\n{\n\tint i,k;\n\tunsigned int v,x;\n\tint numchannels;\n\n\tnumchannels = rctx->has_alpha_channel ? 4 : 3;\n\n\tfor(i=0;i<rctx->width;i++) {\n\t\tif(rctx->bitcount==32) {\n\t\t\tx = ((unsigned int)src[i*4+0]) | ((unsigned int)src[i*4+1])<<8 |\n\t\t\t\t((unsigned int)src[i*4+2])<<16 | ((unsigned int)src[i*4+3])<<24;\n\t\t}\n\t\telse { // 16\n\t\t\tx = ((unsigned int)src[i*2+0]) | ((unsigned int)src[i*2+1])<<8;\n\t\t}\n\t\tv = 0;\n\t\tfor(k=0;k<numchannels;k++) { // For red, green, blue [, alpha]:\n\t\t\tv = x & rctx->bf_mask[k];\n\t\t\tif(rctx->bf_low_bit[k]>0)\n\t\t\t\tv >>= rctx->bf_low_bit[k];\n\t\t\tif(rctx->img->bit_depth==16) {\n\t\t\t\trctx->img->pixels[row*rctx->img->bpr + i*numchannels*2 + k*2+0] = (iw_byte)(v>>8);\n\t\t\t\trctx->img->pixels[row*rctx->img->bpr + i*numchannels*2 + k*2+1] = (iw_byte)(v&0xff);\n\t\t\t}\n\t\t\telse {\n\t\t\t\trctx->img->pixels[row*rctx->img->bpr + i*numchannels + k] = (iw_byte)v;\n\t\t\t}\n\t\t}\n\t}\n}\n\nstatic void bmpr_convert_row_24(struct iwbmprcontext *rctx,const iw_byte *src, size_t row)\n{\n\tint i;\n\tfor(i=0;i<rctx->width;i++) {\n\t\trctx->img->pixels[row*rctx->img->bpr + i*3 + 0] = src[i*3+2];\n\t\trctx->img->pixels[row*rctx->img->bpr + i*3 + 1] = src[i*3+1];\n\t\trctx->img->pixels[row*rctx->img->bpr + i*3 + 2] = src[i*3+0];\n\t}\n}\n\nstatic void bmpr_convert_row_8(struct iwbmprcontext *rctx,const iw_byte *src, size_t row)\n{\n\tint i;\n\tfor(i=0;i<rctx->width;i++) {\n\t\trctx->img->pixels[row*rctx->img->bpr + i*3 + 0] = rctx->palette.entry[src[i]].r;\n\t\trctx->img->pixels[row*rctx->img->bpr + i*3 + 1] = rctx->palette.entry[src[i]].g;\n\t\trctx->img->pixels[row*rctx->img->bpr + i*3 + 2] = rctx->palette.entry[src[i]].b;\n\t}\n}\n\nstatic void bmpr_convert_row_4(struct iwbmprcontext *rctx,const iw_byte *src, size_t row)\n{\n\tint i;\n\tint pal_index;\n\n\tfor(i=0;i<rctx->width;i++) {\n\t\tpal_index = (i&0x1) ? src[i/2]&0x0f : src[i/2]>>4;\n\t\trctx->img->pixels[row*rctx->img->bpr + i*3 + 0] = rctx->palette.entry[pal_index].r;\n\t\trctx->img->pixels[row*rctx->img->bpr + i*3 + 1] = rctx->palette.entry[pal_index].g;\n\t\trctx->img->pixels[row*rctx->img->bpr + i*3 + 2] = rctx->palette.entry[pal_index].b;\n\t}\n}\n\nstatic void bmpr_convert_row_2(struct iwbmprcontext *rctx,const iw_byte *src, size_t row)\n{\n\tint i;\n\tint pal_index;\n\n\tfor(i=0;i<rctx->width;i++) {\n\t\tpal_index = (src[i/4]>>(2*(3-i%4)))&0x03;\n\t\trctx->img->pixels[row*rctx->img->bpr + i*3 + 0] = rctx->palette.entry[pal_index].r;\n\t\trctx->img->pixels[row*rctx->img->bpr + i*3 + 1] = rctx->palette.entry[pal_index].g;\n\t\trctx->img->pixels[row*rctx->img->bpr + i*3 + 2] = rctx->palette.entry[pal_index].b;\n\t}\n}\n\nstatic void bmpr_convert_row_1(struct iwbmprcontext *rctx,const iw_byte *src, size_t row)\n{\n\tint i;\n\tint pal_index;\n\n\tfor(i=0;i<rctx->width;i++) {\n\t\tpal_index = (src[i/8] & (1<<(7-i%8))) ? 1 : 0;\n\t\trctx->img->pixels[row*rctx->img->bpr + i*3 + 0] = rctx->palette.entry[pal_index].r;\n\t\trctx->img->pixels[row*rctx->img->bpr + i*3 + 1] = rctx->palette.entry[pal_index].g;\n\t\trctx->img->pixels[row*rctx->img->bpr + i*3 + 2] = rctx->palette.entry[pal_index].b;\n\t}\n}\n\nstatic int bmpr_read_uncompressed(struct iwbmprcontext *rctx)\n{\n\tiw_byte *rowbuf = NULL;\n\tsize_t bmp_bpr;\n\tint j;\n\tint retval = 0;\n\n\tif(rctx->has_alpha_channel) {\n\t\trctx->img->imgtype = IW_IMGTYPE_RGBA;\n\t\t\n\t\trctx->img->bit_depth = rctx->need_16bit ? 16 : 8;\n\t\trctx->img->bpr = iw_calc_bytesperrow(rctx->width,4*rctx->img->bit_depth);\n\t}\n\telse {\n\t\trctx->img->imgtype = IW_IMGTYPE_RGB;\n\t\trctx->img->bit_depth = rctx->need_16bit ? 16 : 8;\n\t\trctx->img->bpr = iw_calc_bytesperrow(rctx->width,3*rctx->img->bit_depth);\n\t}\n\n\tbmp_bpr = iwbmp_calc_bpr(rctx->bitcount,rctx->width);\n\n\trctx->img->pixels = (iw_byte*)iw_malloc_large(rctx->ctx,rctx->img->bpr,rctx->img->height);\n\tif(!rctx->img->pixels) goto done;\n\n\trowbuf = iw_malloc(rctx->ctx,bmp_bpr);\n\n\tfor(j=0;j<rctx->img->height;j++) {\n\t\t// Read a row of the BMP file.\n\t\tif(!iwbmp_read(rctx,rowbuf,bmp_bpr)) {\n\t\t\tgoto done;\n\t\t}\n\t\tswitch(rctx->bitcount) {\n\t\tcase 32:\n\t\tcase 16:\n\t\t\tbmpr_convert_row_32_16(rctx,rowbuf,j);\n\t\t\tbreak;\n\t\tcase 24:\n\t\t\tbmpr_convert_row_24(rctx,rowbuf,j);\n\t\t\tbreak;\n\t\tcase 8:\n\t\t\tbmpr_convert_row_8(rctx,rowbuf,j);\n\t\t\tbreak;\n\t\tcase 4:\n\t\t\tbmpr_convert_row_4(rctx,rowbuf,j);\n\t\t\tbreak;\n\t\tcase 2:\n\t\t\tbmpr_convert_row_2(rctx,rowbuf,j);\n\t\t\tbreak;\n\t\tcase 1:\n\t\t\tbmpr_convert_row_1(rctx,rowbuf,j);\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tretval = 1;\ndone:\n\tif(rowbuf) iw_free(rctx->ctx,rowbuf);\n\treturn retval;\n}\n\n// Read and decompress RLE8 or RLE4-compressed bits, and write pixels to\n// rctx->img->pixels.\nstatic int bmpr_read_rle_internal(struct iwbmprcontext *rctx)\n{\n\tint retval = 0;\n\tint pos_x, pos_y;\n\tiw_byte buf[255];\n\tsize_t n_pix;\n\tsize_t n_bytes;\n\tsize_t i;\n\tsize_t pal_index;\n\n\t// The position of the next pixel to set.\n\t// pos_y is in IW coordinates (top=0), not BMP coordinates (bottom=0).\n\tpos_x = 0;\n\tpos_y = 0;\n\n\t// Initially make all pixels transparent, so that any any pixels we\n\t// don't modify will be transparent.\n\tiw_zeromem(rctx->img->pixels,rctx->img->bpr*rctx->img->height);\n\n\twhile(1) {\n\t\t// If we've reached the end of the bitmap, stop.\n\t\tif(pos_y>rctx->img->height-1) break;\n\t\tif(pos_y==rctx->img->height-1 && pos_x>=rctx->img->width) break;\n\n\t\tif(!iwbmp_read(rctx,buf,2)) goto done;\n\t\tif(buf[0]==0) {\n\t\t\tif(buf[1]==0) {\n\t\t\t\t// End of Line\n\t\t\t\tpos_y++;\n\t\t\t\tpos_x=0;\n\t\t\t}\n\t\t\telse if(buf[1]==1) {\n\t\t\t\t// (Premature) End of Bitmap\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\telse if(buf[1]==2) {\n\t\t\t\t// DELTA: The next two bytes are unsigned values representing\n\t\t\t\t// the relative position of the next pixel from the \"current\n\t\t\t\t// position\".\n\t\t\t\t// I interpret \"current position\" to mean the position at which\n\t\t\t\t// the next pixel would normally have been.\n\t\t\t\tif(!iwbmp_read(rctx,buf,2)) goto done;\n\n\t\t\t\tif(pos_x<rctx->img->width) pos_x += buf[0];\n\t\t\t\tpos_y += buf[1];\n\t\t\t}\n\t\t\telse {\n\t\t\t\t// A uncompressed segment\n\t\t\t\tn_pix = (size_t)buf[1]; // Number of uncompressed pixels which follow\n\t\t\t\tif(rctx->compression==IWBMP_BI_RLE4) {\n\t\t\t\t\tn_bytes = ((n_pix+3)/4)*2;\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\tn_bytes = ((n_pix+1)/2)*2;\n\t\t\t\t}\n\t\t\t\tif(!iwbmp_read(rctx,buf,n_bytes)) goto done;\n\t\t\t\tfor(i=0;i<n_pix;i++) {\n\t\t\t\t\tif(pos_x<rctx->img->width) {\n\t\t\t\t\t\tif(rctx->compression==IWBMP_BI_RLE4) {\n\t\t\t\t\t\t\tpal_index = (i%2) ? buf[i/2]&0x0f : buf[i/2]>>4;\n\t\t\t\t\t\t}\n\t\t\t\t\t\telse {\n\t\t\t\t\t\t\tpal_index = buf[i];\n\t\t\t\t\t\t}\n\t\t\t\t\t\trctx->img->pixels[rctx->img->bpr*pos_y + pos_x*4 + 0] = rctx->palette.entry[pal_index].r;\n\t\t\t\t\t\trctx->img->pixels[rctx->img->bpr*pos_y + pos_x*4 + 1] = rctx->palette.entry[pal_index].g;\n\t\t\t\t\t\trctx->img->pixels[rctx->img->bpr*pos_y + pos_x*4 + 2] = rctx->palette.entry[pal_index].b;\n\t\t\t\t\t\trctx->img->pixels[rctx->img->bpr*pos_y + pos_x*4 + 3] = 255;\n\t\t\t\t\t\tpos_x++;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\telse {\n\t\t\t// An RLE-compressed segment\n\t\t\tn_pix = (size_t)buf[0];\n\t\t\tfor(i=0;i<n_pix;i++) {\n\t\t\t\tif(pos_x<rctx->img->width) {\n\t\t\t\t\tif(rctx->compression==IWBMP_BI_RLE4) {\n\t\t\t\t\t\tpal_index = (i%2) ? buf[1]&0x0f : buf[1]>>4;\n\t\t\t\t\t}\n\t\t\t\t\telse {\n\t\t\t\t\t\tpal_index = buf[1];\n\t\t\t\t\t}\n\t\t\t\t\trctx->img->pixels[rctx->img->bpr*pos_y + pos_x*4 + 0] = rctx->palette.entry[pal_index].r;\n\t\t\t\t\trctx->img->pixels[rctx->img->bpr*pos_y + pos_x*4 + 1] = rctx->palette.entry[pal_index].g;\n\t\t\t\t\trctx->img->pixels[rctx->img->bpr*pos_y + pos_x*4 + 2] = rctx->palette.entry[pal_index].b;\n\t\t\t\t\trctx->img->pixels[rctx->img->bpr*pos_y + pos_x*4 + 3] = 255;\n\t\t\t\t\tpos_x++;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tretval = 1;\ndone:\n\treturn retval;\n}\n\nstatic int bmpr_has_transparency(struct iw_image *img)\n{\n\tint i,j;\n\n\tif(img->imgtype!=IW_IMGTYPE_RGBA) return 0;\n\n\tfor(j=0;j<img->height;j++) {\n\t\tfor(i=0;i<img->width;i++) {\n\t\t\tif(img->pixels[j*img->bpr + i*4 + 3] != 255)\n\t\t\t\treturn 1;\n\t\t}\n\t}\n\treturn 0;\n}\n\n// Remove the alpha channel.\n// This doesn't free the extra memory used by the alpha channel, it just\n// moves the pixels around in-place.\nstatic void bmpr_strip_alpha(struct iw_image *img)\n{\n\tint i,j;\n\tsize_t oldbpr;\n\n\timg->imgtype = IW_IMGTYPE_RGB;\n\toldbpr = img->bpr;\n\timg->bpr = iw_calc_bytesperrow(img->width,24);\n\n\tfor(j=0;j<img->height;j++) {\n\t\tfor(i=0;i<img->width;i++) {\n\t\t\timg->pixels[j*img->bpr + i*3 + 0] = img->pixels[j*oldbpr + i*4 + 0];\n\t\t\timg->pixels[j*img->bpr + i*3 + 1] = img->pixels[j*oldbpr + i*4 + 1];\n\t\t\timg->pixels[j*img->bpr + i*3 + 2] = img->pixels[j*oldbpr + i*4 + 2];\n\t\t}\n\t}\n}\n\nstatic int bmpr_read_rle(struct iwbmprcontext *rctx)\n{\n\tint retval = 0;\n\n\tif(!(rctx->compression==IWBMP_BI_RLE8 && rctx->bitcount==8) &&\n\t\t!(rctx->compression==IWBMP_BI_RLE4 && rctx->bitcount==4))\n\t{\n\t\tiw_set_error(rctx->ctx,\"Compression type incompatible with image type\");\n\t}\n\n\tif(rctx->topdown) {\n\t\t// The documentation says that top-down images may not be compressed.\n\t\tiw_set_error(rctx->ctx,\"Compression not allowed with top-down images\");\n\t}\n\n\t// RLE-compressed BMP images don't have to assign a color to every pixel,\n\t// and it's reasonable to interpret undefined pixels as transparent.\n\t// I'm not going to worry about handling compressed BMP images as\n\t// efficiently as possible, so start with an RGBA image, and convert to\n\t// RGB format later if (as is almost always the case) there was no\n\t// transparency.\n\trctx->img->imgtype = IW_IMGTYPE_RGBA;\n\trctx->img->bit_depth = 8;\n\trctx->img->bpr = iw_calc_bytesperrow(rctx->width,32);\n\n\trctx->img->pixels = (iw_byte*)iw_malloc_large(rctx->ctx,rctx->img->bpr,rctx->img->height);\n\tif(!rctx->img->pixels) goto done;\n\n\tif(!bmpr_read_rle_internal(rctx)) goto done;\n\n\tif(!bmpr_has_transparency(rctx->img)) {\n\t\tbmpr_strip_alpha(rctx->img);\n\t}\n\n\tretval = 1;\ndone:\n\treturn retval;\n}\n\nstatic int iwbmp_read_bits(struct iwbmprcontext *rctx)\n{\n\tint retval = 0;\n\n\trctx->img->width = rctx->width;\n\trctx->img->height = rctx->height;\n\n\t// If applicable, use the fileheader's \"bits offset\" field to locate the\n\t// bitmap bits.\n\tif(rctx->fileheader_size>0) {\n\t\tsize_t expected_offbits;\n\n\t\texpected_offbits = rctx->fileheader_size + rctx->infoheader_size +\n\t\t\trctx->bitfields_nbytes + rctx->palette_nbytes;\n\n\t\tif(rctx->bfOffBits==expected_offbits) {\n\t\t\t;\n\t\t}\n\t\telse if(rctx->bfOffBits>expected_offbits && rctx->bfOffBits<1000000) {\n\t\t\t// Apparently, there's some extra space between the header data and\n\t\t\t// the bits. If it's not unreasonably large, skip over it.\n\t\t\tif(!iwbmp_skip_bytes(rctx, rctx->bfOffBits - expected_offbits)) goto done;\n\t\t}\n\t\telse {\n\t\t\tiw_set_error(rctx->ctx,\"Invalid BMP bits offset\");\n\t\t\tgoto done;\n\t\t}\n\t}\n\n\tif(rctx->compression==IWBMP_BI_RGB) {\n\t\tif(!bmpr_read_uncompressed(rctx)) goto done;\n\t}\n\telse if(rctx->compression==IWBMP_BI_RLE8 || rctx->compression==IWBMP_BI_RLE4) {\n\t\tif(!bmpr_read_rle(rctx)) goto done;\n\t}\n\telse {\n\t\tiw_set_errorf(rctx->ctx,\"Unsupported BMP compression or image type (%d)\",(int)rctx->compression);\n\t\tgoto done;\n\t}\n\n\tretval = 1;\ndone:\n\treturn retval;\n}\n\nstatic void iwbmpr_misc_config(struct iw_context *ctx, struct iwbmprcontext *rctx)\n{\n\t// Have IW flip the image, if necessary.\n\tif(!rctx->topdown) {\n\t\tiw_reorient_image(ctx,IW_REORIENT_FLIP_V);\n\t}\n\n\t// Tell IW the colorspace.\n\tiw_set_input_colorspace(ctx,&rctx->csdescr);\n\n\t// Tell IW the significant bits.\n\tif(rctx->bitcount==16 || rctx->bitcount==32) {\n\t\tif(rctx->bf_bits_count[0]!=8 || rctx->bf_bits_count[1]!=8 || rctx->bf_bits_count[2]!=8 ||\n\t\t\t(IW_IMGTYPE_HAS_ALPHA(rctx->img->imgtype) && rctx->bf_bits_count[3]!=8))\n\t\t{\n\t\t\tiw_set_input_max_color_code(ctx,0, (1 << rctx->bf_bits_count[0])-1 );\n\t\t\tiw_set_input_max_color_code(ctx,1, (1 << rctx->bf_bits_count[1])-1 );\n\t\t\tiw_set_input_max_color_code(ctx,2, (1 << rctx->bf_bits_count[2])-1 );\n\t\t\tif(IW_IMGTYPE_HAS_ALPHA(rctx->img->imgtype)) {\n\t\t\t\tiw_set_input_max_color_code(ctx,3, (1 << rctx->bf_bits_count[3])-1 );\n\t\t\t}\n\t\t}\n\t}\n}\n\nIW_IMPL(int) iw_read_bmp_file(struct iw_context *ctx, struct iw_iodescr *iodescr)\n{\n\tstruct iwbmprcontext rctx;\n\tstruct iw_image img;\n\tint retval = 0;\n\n\tiw_zeromem(&rctx,sizeof(struct iwbmprcontext));\n\tiw_zeromem(&img,sizeof(struct iw_image));\n\n\trctx.ctx = ctx;\n\trctx.img = &img;\n\trctx.iodescr = iodescr;\n\n\t// Start with a default sRGB colorspace. This may be overridden later.\n\tiw_make_srgb_csdescr_2(&rctx.csdescr);\n\n\trctx.has_fileheader = !iw_get_value(ctx,IW_VAL_BMP_NO_FILEHEADER);\n\tif(rctx.has_fileheader) {\n\t\tif(!iwbmp_read_file_header(&rctx)) goto done;\n\t}\n\tif(!iwbmp_read_info_header(&rctx)) goto done;\n\n\tiwbmp_set_default_bitfields(&rctx);\n\tif(rctx.bitfields_nbytes>0) {\n\t\tif(!iwbmp_read_bitfields(&rctx)) goto done;\n\t}\n\n\tif(rctx.palette_entries>0) {\n\t\tif(!iwbmp_read_palette(&rctx)) goto done;\n\t}\n\tif(!iwbmp_read_bits(&rctx)) goto done;\n\n\tiw_set_input_image(ctx, &img);\n\n\tiwbmpr_misc_config(ctx, &rctx);\n\n\tretval = 1;\ndone:\n\tif(!retval) {\n\t\tiw_set_error(ctx,\"BMP read failed\");\n\t\t// If we didn't call iw_set_input_image, 'img' still belongs to us,\n\t\t// so free its contents.\n\t\tiw_free(ctx, img.pixels);\n\t}\n\treturn retval;\n}\n\nstruct iwbmpwcontext {\n\tint bmpversion;\n\tint include_file_header;\n\tint bitcount;\n\tint palentries;\n\tint compressed;\n\tint uses_bitfields;\n\tsize_t header_size;\n\tsize_t bitfields_size;\n\tsize_t palsize;\n\tsize_t unc_dst_bpr;\n\tsize_t unc_bitssize;\n\tstruct iw_iodescr *iodescr;\n\tstruct iw_context *ctx;\n\tstruct iw_image *img;\n\tconst struct iw_palette *pal;\n\tsize_t total_written;\n\tint bf_amt_to_shift[4]; // For 16-bit images\n\tunsigned int bf_mask[4];\n\tunsigned int maxcolor[4]; // R, G, B -- For 16-bit images.\n\tstruct iw_csdescr csdescr;\n\tint no_cslabel;\n};\n\nstatic void iwbmp_write(struct iwbmpwcontext *wctx, const void *buf, size_t n)\n{\n\t(*wctx->iodescr->write_fn)(wctx->ctx,wctx->iodescr,buf,n);\n\twctx->total_written+=n;\n}\n\nstatic void bmpw_convert_row_1(const iw_byte *srcrow, iw_byte *dstrow, int width)\n{\n\tint i;\n\tint m;\n\n\tfor(i=0;i<width;i++) {\n\t\tm = i%8;\n\t\tif(m==0)\n\t\t\tdstrow[i/8] = srcrow[i]<<7;\n\t\telse\n\t\t\tdstrow[i/8] |= srcrow[i]<<(7-m);\n\t}\n}\n\nstatic void bmpw_convert_row_4(const iw_byte *srcrow, iw_byte *dstrow, int width)\n{\n\tint i;\n\n\tfor(i=0;i<width;i++) {\n\t\tif(i%2==0)\n\t\t\tdstrow[i/2] = srcrow[i]<<4;\n\t\telse\n\t\t\tdstrow[i/2] |= srcrow[i];\n\t}\n}\n\nstatic void bmpw_convert_row_8(const iw_byte *srcrow, iw_byte *dstrow, int width)\n{\n\tmemcpy(dstrow,srcrow,width);\n}\n\nstatic void bmpw_convert_row_16_32(struct iwbmpwcontext *wctx, const iw_byte *srcrow,\n\tiw_byte *dstrow, int width)\n{\n\tint i,k;\n\tunsigned int v;\n\tint num_src_samples;\n\tunsigned int src_sample[4];\n\n\tfor(k=0;k<4;k++) src_sample[k]=0;\n\n\tnum_src_samples = iw_imgtype_num_channels(wctx->img->imgtype);\n\n\tfor(i=0;i<width;i++) {\n\n\t\t// Read the source samples into a convenient format.\n\t\tfor(k=0;k<num_src_samples;k++) {\n\t\t\tif(wctx->img->bit_depth==16) {\n\t\t\t\tsrc_sample[k] = (srcrow[num_src_samples*2*i + k*2]<<8) | srcrow[num_src_samples*2*i + k*2 +1];\n\t\t\t}\n\t\t\telse {\n\t\t\t\tsrc_sample[k] = srcrow[num_src_samples*i + k];\n\t\t\t}\n\t\t}\n\n\t\t// Pack the pixels' bits into a single int.\n\t\tswitch(wctx->img->imgtype) {\n\t\tcase IW_IMGTYPE_GRAY:\n\t\t\tv = src_sample[0] << wctx->bf_amt_to_shift[0];\n\t\t\tv |= src_sample[0] << wctx->bf_amt_to_shift[1];\n\t\t\tv |= src_sample[0] << wctx->bf_amt_to_shift[2];\n\t\t\tbreak;\n\t\tcase IW_IMGTYPE_RGBA:\n\t\t\tv = src_sample[0] << wctx->bf_amt_to_shift[0];\n\t\t\tv |= src_sample[1] << wctx->bf_amt_to_shift[1];\n\t\t\tv |= src_sample[2] << wctx->bf_amt_to_shift[2];\n\t\t\tv |= src_sample[3] << wctx->bf_amt_to_shift[3];\n\t\t\tbreak;\n\t\tcase IW_IMGTYPE_GRAYA:\n\t\t\tv = src_sample[0] << wctx->bf_amt_to_shift[0];\n\t\t\tv |= src_sample[0] << wctx->bf_amt_to_shift[1];\n\t\t\tv |= src_sample[0] << wctx->bf_amt_to_shift[2];\n\t\t\tv |= src_sample[1] << wctx->bf_amt_to_shift[3];\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tv = src_sample[0] << wctx->bf_amt_to_shift[0];\n\t\t\tv |= src_sample[1] << wctx->bf_amt_to_shift[1];\n\t\t\tv |= src_sample[2] << wctx->bf_amt_to_shift[2];\n\t\t}\n\n\t\t// Split the int into bytes, and write it to the target image.\n\t\tif(wctx->bitcount==32) {\n\t\t\tdstrow[i*4+0] = (iw_byte)(v&0xff);\n\t\t\tdstrow[i*4+1] = (iw_byte)((v&0x0000ff00)>>8);\n\t\t\tdstrow[i*4+2] = (iw_byte)((v&0x00ff0000)>>16);\n\t\t\tdstrow[i*4+3] = (iw_byte)((v&0xff000000)>>24);\n\t\t}\n\t\telse {\n\t\t\tdstrow[i*2+0] = (iw_byte)(v&0xff);\n\t\t\tdstrow[i*2+1] = (iw_byte)(v>>8);\n\t\t}\n\t}\n}\n\nstatic void bmpw_convert_row_24(struct iwbmpwcontext *wctx, const iw_byte *srcrow,\n\tiw_byte *dstrow, int width)\n{\n\tint i;\n\n\tif(wctx->img->imgtype==IW_IMGTYPE_GRAY) {\n\t\tfor(i=0;i<width;i++) {\n\t\t\tdstrow[i*3+0] = srcrow[i];\n\t\t\tdstrow[i*3+1] = srcrow[i];\n\t\t\tdstrow[i*3+2] = srcrow[i];\n\t\t}\n\t}\n\telse { // RGB\n\t\tfor(i=0;i<width;i++) {\n\t\t\tdstrow[i*3+0] = srcrow[i*3+2];\n\t\t\tdstrow[i*3+1] = srcrow[i*3+1];\n\t\t\tdstrow[i*3+2] = srcrow[i*3+0];\n\t\t}\n\t}\n}\n\nstatic void iwbmp_write_file_header(struct iwbmpwcontext *wctx)\n{\n\tiw_byte fileheader[14];\n\n\tif(!wctx->include_file_header) return;\n\n\tiw_zeromem(fileheader,sizeof(fileheader));\n\tfileheader[0] = 66; // 'B'\n\tfileheader[1] = 77; // 'M'\n\n\t// This will be overwritten later, if the bitmap was compressed.\n\tiw_set_ui32le(&fileheader[ 2], (unsigned int)(14+wctx->header_size+\n\t\twctx->bitfields_size+wctx->palsize+wctx->unc_bitssize)); // bfSize\n\tiw_set_ui32le(&fileheader[10],(unsigned int)(14+wctx->header_size+\n\t\twctx->bitfields_size+wctx->palsize)); // bfOffBits\n\tiwbmp_write(wctx,fileheader,14);\n}\n\nstatic int iwbmp_write_bmp_v2header(struct iwbmpwcontext *wctx)\n{\n\tiw_byte header[12];\n\n\tif(wctx->img->width>65535 || wctx->img->height>65535) {\n\t\tiw_set_error(wctx->ctx,\"Output image is too large for this BMP version\");\n\t\treturn 0;\n\t}\n\n\tiw_zeromem(header,sizeof(header));\n\tiw_set_ui32le(&header[ 0],12);                // bcSize\n\tiw_set_ui16le(&header[ 4],wctx->img->width);  // bcWidth\n\tiw_set_ui16le(&header[ 6],wctx->img->height); // bcHeight\n\tiw_set_ui16le(&header[ 8],1);                 // bcPlanes\n\tiw_set_ui16le(&header[10],wctx->bitcount);    // bcBitCount\n\n\tiwbmp_write(wctx,header,12);\n\treturn 1;\n}\n\nstatic int iwbmp_write_bmp_v3header(struct iwbmpwcontext *wctx)\n{\n\tunsigned int dens_x, dens_y;\n\tunsigned int cmpr;\n\tiw_byte header[40];\n\n\tiw_zeromem(header,sizeof(header));\n\n\tiw_set_ui32le(&header[ 0],(unsigned int)wctx->header_size); // biSize\n\tiw_set_ui32le(&header[ 4],wctx->img->width);  // biWidth\n\tiw_set_ui32le(&header[ 8],wctx->img->height); // biHeight\n\tiw_set_ui16le(&header[12],1);    // biPlanes\n\tiw_set_ui16le(&header[14],wctx->bitcount);   // biBitCount\n\n\tcmpr = IWBMP_BI_RGB;\n\tif(wctx->compressed) {\n\t\tif(wctx->bitcount==8) cmpr = IWBMP_BI_RLE8;\n\t\telse if(wctx->bitcount==4) cmpr = IWBMP_BI_RLE4;\n\t}\n\telse if(wctx->uses_bitfields) {\n\t\tcmpr = IWBMP_BI_BITFIELDS;\n\t}\n\tiw_set_ui32le(&header[16],cmpr); // biCompression\n\n\tiw_set_ui32le(&header[20],(unsigned int)wctx->unc_bitssize); // biSizeImage\n\n\tif(wctx->img->density_code==IW_DENSITY_UNITS_PER_METER) {\n\t\tdens_x = (unsigned int)(0.5+wctx->img->density_x);\n\t\tdens_y = (unsigned int)(0.5+wctx->img->density_y);\n\t}\n\telse {\n\t\tdens_x = dens_y = 2835;\n\t}\n\tiw_set_ui32le(&header[24],dens_x); // biXPelsPerMeter\n\tiw_set_ui32le(&header[28],dens_y); // biYPelsPerMeter\n\n\tiw_set_ui32le(&header[32],wctx->palentries);    // biClrUsed\n\t//iw_set_ui32le(&header[36],0);    // biClrImportant\n\tiwbmp_write(wctx,header,40);\n\treturn 1;\n}\n\nstatic int iwbmp_write_bmp_v45header_fields(struct iwbmpwcontext *wctx)\n{\n\tiw_byte header[124];\n\tunsigned int intent_bmp_style;\n\n\tiw_zeromem(header,sizeof(header));\n\n\tif(wctx->uses_bitfields) {\n\t\tiw_set_ui32le(&header[40],wctx->bf_mask[0]);\n\t\tiw_set_ui32le(&header[44],wctx->bf_mask[1]);\n\t\tiw_set_ui32le(&header[48],wctx->bf_mask[2]);\n\t\tiw_set_ui32le(&header[52],wctx->bf_mask[3]);\n\t}\n\n\t// Colorspace Type\n\t// TODO: We could support CSTYPE_GAMMA by using LCS_CALIBRATED_RGB,\n\t// but documentation about how to do that is hard to find.\n\tif(wctx->csdescr.cstype==IW_CSTYPE_SRGB && !wctx->no_cslabel)\n\t\tiw_set_ui32le(&header[56],IWBMPCS_SRGB);\n\telse\n\t\tiw_set_ui32le(&header[56],IWBMPCS_DEVICE_RGB);\n\n\t// Intent\n\t//intent_bmp_style = 4; // Perceptual\n\t//if(wctx->csdescr.cstype==IW_CSTYPE_SRGB && !wctx->no_cslabel) {\n\tswitch(wctx->img->rendering_intent) {\n\tcase IW_INTENT_PERCEPTUAL: intent_bmp_style = 4; break;\n\tcase IW_INTENT_RELATIVE:   intent_bmp_style = 2; break;\n\tcase IW_INTENT_SATURATION: intent_bmp_style = 1; break;\n\tcase IW_INTENT_ABSOLUTE:   intent_bmp_style = 8; break;\n\tdefault: intent_bmp_style = 4;\n\t}\n\t//}\n\tiw_set_ui32le(&header[108],intent_bmp_style);\n\n\tiwbmp_write(wctx,&header[40],124-40);\n\treturn 1;\n}\n\nstatic int iwbmp_write_bmp_header(struct iwbmpwcontext *wctx)\n{\n\tif(wctx->bmpversion==2) {\n\t\treturn iwbmp_write_bmp_v2header(wctx);\n\t}\n\telse if(wctx->bmpversion==5) {\n\t\tif(!iwbmp_write_bmp_v3header(wctx)) return 0;\n\t\treturn iwbmp_write_bmp_v45header_fields(wctx);\n\t}\n\treturn iwbmp_write_bmp_v3header(wctx);\n}\n\n// Given wctx->maxcolor[*], sets -> bf_mask[*] and bf_amt_to_shift[*],\n// and sets wctx->bitcount (to 16 or 32).\nstatic int iwbmp_calc_bitfields_masks(struct iwbmpwcontext *wctx, int num_masks)\n{\n\tint k;\n\tint bits[4]; // R, G, B, A\n\tint tot_bits = 0;\n\n\tfor(k=0;k<num_masks;k++) {\n\t\tbits[k] = iw_max_color_to_bitdepth(wctx->maxcolor[k]);\n\t\ttot_bits += bits[k];\n\t}\n\n\tif(tot_bits > 32) {\n\t\tiw_set_error(wctx->ctx,\"Cannot write a BMP image in this color format\");\n\t\treturn 0;\n\t}\n\t\n\twctx->bitcount = (tot_bits>16) ? 32 : 16;\n\n\twctx->bf_amt_to_shift[0] = bits[1] + bits[2];\n\twctx->bf_amt_to_shift[1] = bits[2];\n\twctx->bf_amt_to_shift[2] = 0;\n\tif(num_masks>3) wctx->bf_amt_to_shift[3] =  bits[0] + bits[1] + bits[2];\n\n\tfor(k=0;k<num_masks;k++) {\n\t\twctx->bf_mask[k] = wctx->maxcolor[k] << wctx->bf_amt_to_shift[k];\n\t}\n\n\treturn 1;\n}\n\n// Write the BITFIELDS segment, and set the wctx->bf_amt_to_shift[] values.\nstatic int iwbmp_write_bitfields(struct iwbmpwcontext *wctx)\n{\n\tiw_byte buf[12];\n\tint k;\n\n\tif(wctx->bitcount!=16 && wctx->bitcount!=32) return 0;\n\n\tfor(k=0;k<3;k++) {\n\t\tiw_set_ui32le(&buf[4*k],wctx->bf_mask[k]);\n\t}\n\tiwbmp_write(wctx,buf,12);\n\treturn 1;\n}\n\nstatic void iwbmp_write_palette(struct iwbmpwcontext *wctx)\n{\n\tint i,k;\n\tiw_byte buf[4];\n\n\tif(wctx->palentries<1) return;\n\n\tbuf[3] = 0; // Reserved field; always 0.\n\n\tfor(i=0;i<wctx->palentries;i++) {\n\t\tif(i<wctx->pal->num_entries) {\n\t\t\tif(wctx->pal->entry[i].a == 0) {\n\t\t\t\t// A transparent color. Because of the way we handle writing\n\t\t\t\t// transparent BMP images, the first palette entry may be a\n\t\t\t\t// fully transparent color, whose index will not be used when\n\t\t\t\t// we write the image. But many apps will interpret our\n\t\t\t\t// \"transparent\" pixels as having color #0. So, set it to\n\t\t\t\t// the background label color if available, otherwise to an\n\t\t\t\t// arbitrary high-contrast color (magenta).\n\t\t\t\tif(wctx->img->has_bkgdlabel) {\n\t\t\t\t\tfor(k=0;k<3;k++) {\n\t\t\t\t\t\tbuf[k] = (iw_byte)iw_color_get_int_sample(&wctx->img->bkgdlabel,2-k,255);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\tbuf[0] = 255;\n\t\t\t\t\tbuf[1] = 0;\n\t\t\t\t\tbuf[2] = 255;\n\t\t\t\t}\n\t\t\t}\n\t\t\telse {\n\t\t\t\tbuf[0] = wctx->pal->entry[i].b;\n\t\t\t\tbuf[1] = wctx->pal->entry[i].g;\n\t\t\t\tbuf[2] = wctx->pal->entry[i].r;\n\t\t\t}\n\t\t}\n\t\telse {\n\t\t\tbuf[0] = buf[1] = buf[2] = 0;\n\t\t}\n\t\tif(wctx->bmpversion==2)\n\t\t\tiwbmp_write(wctx,buf,3); // v2 BMPs don't have the 'reserved' field.\n\t\telse\n\t\t\tiwbmp_write(wctx,buf,4);\n\t}\n}\n\nstruct rle_context {\n\tstruct iw_context *ctx;\n\tstruct iwbmpwcontext *wctx;\n\tconst iw_byte *srcrow;\n\n\tsize_t img_width;\n\tint cur_row; // current row; 0=top (last)\n\n\t// Position in srcrow of the first byte that hasn't been written to the\n\t// output file\n\tsize_t pending_data_start;\n\n\t// Current number of uncompressible bytes that haven't been written yet\n\t// (starting at pending_data_start)\n\tsize_t unc_len;\n\n\t// Current number of identical bytes that haven't been written yet\n\t// (starting at pending_data_start+unc_len)\n\tsize_t run_len;\n\n\t// The value of the bytes referred to by run_len.\n\t// Valid if run_len>0.\n\tiw_byte run_byte;\n\n\tsize_t total_bytes_written; // Bytes written, after compression\n};\n\n//============================ RLE8 encoder ============================\n\n// TODO: The RLE8 and RLE4 encoders are more different than they should be.\n// The RLE8 encoder could probably be made more similar to the (more\n// complicated) RLE4 encoder.\n\nstatic void rle8_write_unc(struct rle_context *rlectx)\n{\n\tsize_t i;\n\tiw_byte dstbuf[2];\n\n\tif(rlectx->unc_len<1) return;\n\tif(rlectx->unc_len>=3 && (rlectx->unc_len&1)) {\n\t\tiw_set_error(rlectx->ctx,\"Internal: RLE encode error 4\");\n\t\treturn;\n\t}\n\tif(rlectx->unc_len>254) {\n\t\tiw_set_error(rlectx->ctx,\"Internal: RLE encode error 5\");\n\t\treturn;\n\t}\n\n\tif(rlectx->unc_len<3) {\n\t\t// The minimum length for a noncompressed run is 3. For shorter runs\n\t\t// write them \"compressed\".\n\t\tfor(i=0;i<rlectx->unc_len;i++) {\n\t\t\tdstbuf[0] = 0x01;  // count\n\t\t\tdstbuf[1] = rlectx->srcrow[i+rlectx->pending_data_start]; // value\n\t\t\tiwbmp_write(rlectx->wctx,dstbuf,2);\n\t\t\trlectx->total_bytes_written+=2;\n\t\t}\n\t}\n\telse {\n\t\tdstbuf[0] = 0x00;\n\t\tdstbuf[1] = (iw_byte)rlectx->unc_len;\n\t\tiwbmp_write(rlectx->wctx,dstbuf,2);\n\t\trlectx->total_bytes_written+=2;\n\t\tiwbmp_write(rlectx->wctx,&rlectx->srcrow[rlectx->pending_data_start],rlectx->unc_len);\n\t\trlectx->total_bytes_written+=rlectx->unc_len;\n\t\tif(rlectx->unc_len&0x1) {\n\t\t\t// Need a padding byte if the length was odd. (This shouldn't\n\t\t\t// happen, because we never write odd-length UNC segments.)\n\t\t\tdstbuf[0] = 0x00;\n\t\t\tiwbmp_write(rlectx->wctx,dstbuf,1);\n\t\t\trlectx->total_bytes_written+=1;\n\t\t}\n\t}\n\n\trlectx->pending_data_start+=rlectx->unc_len;\n\trlectx->unc_len=0;\n}\n\nstatic void rle8_write_unc_and_run(struct rle_context *rlectx)\n{\n\tiw_byte dstbuf[2];\n\n\trle8_write_unc(rlectx);\n\n\tif(rlectx->run_len<1) {\n\t\treturn;\n\t}\n\tif(rlectx->run_len>255) {\n\t\tiw_set_error(rlectx->ctx,\"Internal: RLE encode error 6\");\n\t\treturn;\n\t}\n\n\tdstbuf[0] = (iw_byte)rlectx->run_len;\n\tdstbuf[1] = rlectx->run_byte;\n\tiwbmp_write(rlectx->wctx,dstbuf,2);\n\trlectx->total_bytes_written+=2;\n\n\trlectx->pending_data_start+=rlectx->run_len;\n\trlectx->run_len=0;\n}\n\nstatic void rle_write_trns(struct rle_context *rlectx, int num_trns)\n{\n\tiw_byte dstbuf[4];\n\tint num_remaining = num_trns;\n\tint num_to_write;\n\n\twhile(num_remaining>0) {\n\t\tnum_to_write = num_remaining;\n\t\tif(num_to_write>255) num_to_write=255;\n\t\tdstbuf[0]=0x00; // 00 02 = Delta\n\t\tdstbuf[1]=0x02;\n\t\tdstbuf[2]=(iw_byte)num_to_write; // X offset\n\t\tdstbuf[3]=0x00; // Y offset\n\t\tiwbmp_write(rlectx->wctx,dstbuf,4);\n\t\trlectx->total_bytes_written+=4;\n\t\tnum_remaining -= num_to_write;\n\t}\n\trlectx->pending_data_start += num_trns;\n}\n\n// The RLE format used by BMP files is pretty simple, but I've gone to some\n// effort to optimize it for file size, which makes for a complicated\n// algorithm.\n// The overall idea:\n// We defer writing data until certain conditions are met. In the meantime,\n// we split the unwritten data into two segments:\n//  \"UNC\": data classified as uncompressible\n//  \"RUN\": data classified as compressible. All bytes in this segment must be\n//    identical.\n// The RUN segment always follows the UNC segment.\n// For each byte in turn, we examine the current state, and do one of a number\n// of things, such as:\n//    - add it to RUN\n//    - add it to UNC (if there is no RUN)\n//    - move RUN into UNC, then add it to RUN (or to UNC)\n//    - move UNC and RUN to the file, then make it the new RUN\n// Then, we check to see if we've accumulated enough data that something needs\n// to be written out.\nstatic int rle8_compress_row(struct rle_context *rlectx)\n{\n\tsize_t i;\n\tiw_byte dstbuf[2];\n\tiw_byte next_byte;\n\tint next_pix_is_trns;\n\tint num_trns = 0; // number of consecutive transparent pixels seen\n\tint retval = 0;\n\n\trlectx->pending_data_start=0;\n\trlectx->unc_len=0;\n\trlectx->run_len=0;\n\n\tfor(i=0;i<rlectx->img_width;i++) {\n\n\t\t// Read the next byte.\n\t\tnext_byte = rlectx->srcrow[i];\n\n\t\tnext_pix_is_trns = (rlectx->wctx->pal->entry[next_byte].a==0);\n\n\t\tif(num_trns>0 && !next_pix_is_trns) {\n\t\t\trle_write_trns(rlectx,num_trns);\n\t\t\tnum_trns=0;\n\t\t}\n\t\telse if(next_pix_is_trns) {\n\t\t\tif (rlectx->unc_len>0 || rlectx->run_len>0) {\n\t\t\t\trle8_write_unc_and_run(rlectx);\n\t\t\t}\n\t\t\tnum_trns++;\n\t\t\tcontinue;\n\t\t}\n\n\t\t// --------------------------------------------------------------\n\t\t// Add the byte we just read to either the UNC or the RUN data.\n\n\t\tif(rlectx->run_len>0 && next_byte==rlectx->run_byte) {\n\t\t\t// Byte fits in the current run; add it.\n\t\t\trlectx->run_len++;\n\t\t}\n\t\telse if(rlectx->run_len==0) {\n\t\t\t// We don't have a RUN, so we can put this byte there.\n\t\t\trlectx->run_len = 1;\n\t\t\trlectx->run_byte = next_byte;\n\t\t}\n\t\telse if(rlectx->unc_len==0 && rlectx->run_len==1) {\n\t\t\t// We have one previous byte, and it's different from this one.\n\t\t\t// Move it to UNC, and make this one the RUN.\n\t\t\trlectx->unc_len++;\n\t\t\trlectx->run_byte = next_byte;\n\t\t}\n\t\telse if(rlectx->unc_len>0 && rlectx->run_len<(rlectx->unc_len==1 ? 3U : 4U)) {\n\t\t\t// We have a run, but it's not long enough to be beneficial.\n\t\t\t// Convert it to uncompressed bytes.\n\t\t\t// A good rule is that a run length of 4 or more (3 or more if\n\t\t\t// unc_len=1) should always be run-legth encoded.\n\t\t\trlectx->unc_len += rlectx->run_len;\n\t\t\trlectx->run_len = 0;\n\t\t\t// If UNC is now odd and >1, add the next byte to it to make it even.\n\t\t\t// Otherwise, add it to RUN.\n\t\t\tif(rlectx->unc_len>=3 && (rlectx->unc_len&0x1)) {\n\t\t\t\trlectx->unc_len++;\n\t\t\t}\n\t\t\telse {\n\t\t\t\trlectx->run_len = 1;\n\t\t\t\trlectx->run_byte = next_byte;\n\t\t\t}\n\t\t}\n\t\telse {\n\t\t\t// Nowhere to put the byte: write out everything, and start fresh.\n\t\t\trle8_write_unc_and_run(rlectx);\n\t\t\trlectx->run_len = 1;\n\t\t\trlectx->run_byte = next_byte;\n\t\t}\n\n\t\t// --------------------------------------------------------------\n\t\t// If we hit certain high water marks, write out the current data.\n\n\t\tif(rlectx->unc_len>=254) {\n\t\t\t// Our maximum size for an UNC segment.\n\t\t\trle8_write_unc(rlectx);\n\t\t}\n\t\telse if(rlectx->unc_len>0 && (rlectx->unc_len+rlectx->run_len)>254) {\n\t\t\t// It will not be possible to coalesce the RUN into the UNC (it\n\t\t\t// would be too big) so write out the UNC.\n\t\t\trle8_write_unc(rlectx);\n\t\t}\n\t\telse if(rlectx->run_len>=255) {\n\t\t\t// The maximum size for an RLE segment.\n\t\t\trle8_write_unc_and_run(rlectx);\n\t\t}\n\n\t\t// --------------------------------------------------------------\n\t\t// Sanity checks. These can be removed if we're sure the algorithm\n\t\t// is bug-free.\n\n\t\t// We don't allow unc_len to be odd (except temporarily), except\n\t\t// that it can be 1.\n\t\t// What's special about 1 is that if we add another byte to it, it\n\t\t// increases the cost. For 3,5,...,253, we can add another byte for\n\t\t// free, so we should never fail to do that.\n\t\tif((rlectx->unc_len&0x1) && rlectx->unc_len!=1) {\n\t\t\tiw_set_errorf(rlectx->ctx,\"Internal: BMP RLE encode error 1\");\n\t\t\tgoto done;\n\t\t}\n\n\t\t// unc_len can be at most 252 at this point.\n\t\t// If it were 254, it should have been written out already.\n\t\tif(rlectx->unc_len>252) {\n\t\t\tiw_set_error(rlectx->ctx,\"Internal: BMP RLE encode error 2\");\n\t\t\tgoto done;\n\t\t}\n\n\t\t// run_len can be at most 254 at this point.\n\t\t// If it were 255, it should have been written out already.\n\t\tif(rlectx->run_len>254) {\n\t\t\tiw_set_error(rlectx->ctx,\"Internal: BMP RLE encode error 3\");\n\t\t\tgoto done;\n\t\t}\n\t}\n\n\t// End of row. Write out anything left over.\n\trle8_write_unc_and_run(rlectx);\n\n\t// Write an end-of-line marker (0 0), or if this is the last row,\n\t// an end-of-bitmap marker (0 1).\n\tdstbuf[0]=0x00;\n\tdstbuf[1]= (rlectx->cur_row==0)? 0x01 : 0x00;\n\tiwbmp_write(rlectx->wctx,dstbuf,2);\n\trlectx->total_bytes_written+=2;\n\n\tretval = 1;\n\ndone:\n\treturn retval;\n}\n\n//============================ RLE4 encoder ============================\n\n// Calculate the most efficient way to split a run of uncompressible pixels.\n// This only finds the first place to split the run. If the run is still\n// over 255 pixels, call it again to find the next split.\nstatic size_t rle4_get_best_unc_split(size_t n)\n{\n\t// For <=255 pixels, we can never do better than storing it as one run.\n\tif(n<=255) return n;\n\n\t// With runs of 252, we can store 252/128 = 1.96875 pixels/byte.\n\t// With runs of 255, we can store 255/130 = 1.96153 pixels/byte.\n\t// Hence, using runs of 252 is the most efficient way to store a large\n\t// number of uncompressible pixels.\n\t// (Lengths other than 252 or 255 are no help.)\n\t// However, there are three exceptional cases where, if we split at 252,\n\t// the most efficient encoding will no longer be possible:\n\tif(n==257 || n==510 || n==765) return 255;\n\n\treturn 252;\n}\n\n// Returns the incremental cost of adding a pixel to the current UNC\n// (which is always either 0 or 2).\n// To derive this function, I calculated the optimal cost of every length,\n// and enumerated the exceptions to the (n%4)?0:2 rule.\n// The exceptions are mostly caused by the cases where\n// rle4_get_best_unc_split() returns 255 instead of 252.\nstatic int rle4_get_incr_unc_cost(struct rle_context *rlectx)\n{\n\tint n;\n\tint m;\n\n\tn = (int)rlectx->unc_len;\n\n\tif(n==2 || n==255 || n==257 || n==507 || n==510) return 2;\n\tif(n==256 || n==508) return 0;\n\n\tif(n>=759) {\n\t\tm = n%252;\n\t\tif(m==3 || m==6 || m==9) return 2;\n\t\tif(m==4 || m==8) return 0;\n\t}\n\n\treturn (n%4)?0:2;\n}\n\nstatic void rle4_write_unc(struct rle_context *rlectx)\n{\n\tiw_byte dstbuf[128];\n\tsize_t pixels_to_write;\n\tsize_t bytes_to_write;\n\n\tif(rlectx->unc_len<1) return;\n\n\t// Note that, unlike the RLE8 encoder, we allow this function to be called\n\t// with uncompressed runs of arbitrary length.\n\n\twhile(rlectx->unc_len>0) {\n\t\tpixels_to_write = rle4_get_best_unc_split(rlectx->unc_len);\n\n\t\tif(pixels_to_write<3) {\n\t\t\t// The minimum length for an uncompressed run is 3. For shorter runs\n\t\t\t// write them \"compressed\".\n\t\t\tdstbuf[0] = (iw_byte)pixels_to_write;\n\t\t\tdstbuf[1] = (rlectx->srcrow[rlectx->pending_data_start]<<4);\n\t\t\tif(pixels_to_write>1)\n\t\t\t\tdstbuf[1] |= (rlectx->srcrow[rlectx->pending_data_start+1]);\n\n\t\t\t// The actual writing will occur below. Just indicate how many bytes\n\t\t\t// of dstbuf[] to write.\n\t\t\tbytes_to_write = 2;\n\t\t}\n\t\telse {\n\t\t\tsize_t i;\n\n\t\t\t// Write the length of the uncompressed run.\n\t\t\tdstbuf[0] = 0x00;\n\t\t\tdstbuf[1] = (iw_byte)pixels_to_write;\n\t\t\tiwbmp_write(rlectx->wctx,dstbuf,2);\n\t\t\trlectx->total_bytes_written+=2;\n\n\t\t\t// Put the data to write in dstbuf[].\n\t\t\tbytes_to_write = 2*((pixels_to_write+3)/4);\n\t\t\tiw_zeromem(dstbuf,bytes_to_write);\n\n\t\t\tfor(i=0;i<pixels_to_write;i++) {\n\t\t\t\tif(i&0x1) dstbuf[i/2] |= rlectx->srcrow[rlectx->pending_data_start+i];\n\t\t\t\telse dstbuf[i/2] = rlectx->srcrow[rlectx->pending_data_start+i]<<4;\n\t\t\t}\n\t\t}\n\n\t\tiwbmp_write(rlectx->wctx,dstbuf,bytes_to_write);\n\t\trlectx->total_bytes_written += bytes_to_write;\n\t\trlectx->unc_len -= pixels_to_write;\n\t\trlectx->pending_data_start += pixels_to_write;\n\t}\n}\n\nstatic void rle4_write_unc_and_run(struct rle_context *rlectx)\n{\n\tiw_byte dstbuf[2];\n\n\trle4_write_unc(rlectx);\n\n\tif(rlectx->run_len<1) {\n\t\treturn;\n\t}\n\tif(rlectx->run_len>255) {\n\t\tiw_set_error(rlectx->ctx,\"Internal: RLE encode error 6\");\n\t\treturn;\n\t}\n\n\tdstbuf[0] = (iw_byte)rlectx->run_len;\n\tdstbuf[1] = rlectx->run_byte;\n\tiwbmp_write(rlectx->wctx,dstbuf,2);\n\trlectx->total_bytes_written+=2;\n\n\trlectx->pending_data_start+=rlectx->run_len;\n\trlectx->run_len=0;\n}\n\n// Should we move the pending compressible data to the \"uncompressed\"\n// segment (return 1), or should we write it to disk as a compressed run of\n// pixels (0)?\nstatic int ok_to_move_to_unc(struct rle_context *rlectx)\n{\n\t// This logic is probably not optimal in every case.\n\t// One possible improvement might be to adjust the thresholds when\n\t// unc_len+run_len is around 255 or higher.\n\t// Other improvements might require looking ahead at pixels we haven't\n\t// read yet.\n\n\tif(rlectx->unc_len==0) {\n\t\treturn (rlectx->run_len<4);\n\t}\n\telse if(rlectx->unc_len<=2) {\n\t\treturn (rlectx->run_len<6);\n\t}\n\telse {\n\t\treturn (rlectx->run_len<8);\n\t}\n\treturn 0;\n}\n\nstatic int rle4_compress_row(struct rle_context *rlectx)\n{\n\tsize_t i;\n\tiw_byte dstbuf[2];\n\tiw_byte next_pix;\n\tint next_pix_is_trns;\n\tint num_trns = 0; // number of consecutive transparent pixels seen\n\tint retval = 0;\n\tiw_byte tmpb;\n\n\trlectx->pending_data_start=0;\n\trlectx->unc_len=0;\n\trlectx->run_len=0;\n\n\tfor(i=0;i<rlectx->img_width;i++) {\n\n\t\t// Read the next pixel\n\t\tnext_pix = rlectx->srcrow[i];\n\n\t\tnext_pix_is_trns = (rlectx->wctx->pal->entry[next_pix].a==0);\n\t\tif(num_trns>0 && !next_pix_is_trns) {\n\t\t\trle_write_trns(rlectx,num_trns);\n\t\t\tnum_trns=0;\n\t\t}\n\t\telse if(next_pix_is_trns) {\n\t\t\tif (rlectx->unc_len>0 || rlectx->run_len>0) {\n\t\t\t\trle4_write_unc_and_run(rlectx);\n\t\t\t}\n\t\t\tnum_trns++;\n\t\t\tcontinue;\n\t\t}\n\n\t\t// --------------------------------------------------------------\n\t\t// Add the pixel we just read to either the UNC or the RUN data.\n\n\t\tif(rlectx->run_len==0) {\n\t\t\t// We don't have a RUN, so we can put this pixel there.\n\t\t\trlectx->run_len = 1;\n\t\t\trlectx->run_byte = next_pix<<4;\n\t\t}\n\t\telse if(rlectx->run_len==1) {\n\t\t\t// If the run is 1, we can always add a 2nd pixel\n\t\t\trlectx->run_byte |= next_pix;\n\t\t\trlectx->run_len++;\n\t\t}\n\t\telse if(rlectx->run_len>=2 && (rlectx->run_len&1)==0 && next_pix==(rlectx->run_byte>>4)) {\n\t\t\t// pixel fits in the current run; add it.\n\t\t\trlectx->run_len++;\n\t\t}\n\t\telse if(rlectx->run_len>=3 && (rlectx->run_len&1) && next_pix==(rlectx->run_byte&0x0f)) {\n\t\t\t// pixel fits in the current run; add it.\n\t\t\trlectx->run_len++;\n\t\t}\n\t\telse if(rlectx->unc_len==0 && rlectx->run_len==2) {\n\t\t\t// We have one previous byte, and it's different from this one.\n\t\t\t// Move it to UNC, and make this one the RUN.\n\t\t\trlectx->unc_len+=rlectx->run_len;\n\t\t\trlectx->run_byte = next_pix<<4;\n\t\t\trlectx->run_len = 1;\n\t\t}\n\t\telse if(ok_to_move_to_unc(rlectx)) {\n\t\t\t// We have a compressible run, but we think it's not long enough to be\n\t\t\t// beneficial. Convert it to uncompressed bytes -- except for the last\n\t\t\t// pixel, which can be left in the run.\n\t\t\trlectx->unc_len += rlectx->run_len-1;\n \n\t\t\tif((rlectx->run_len&1)==0)\n\t\t\t\trlectx->run_byte = (rlectx->run_byte&0x0f)<<4;\n\t\t\telse\n\t\t\t\trlectx->run_byte = (rlectx->run_byte&0xf0);\n\n\t\t\t// Put the next byte in RLE. (It might get moved to UNC, below.)\n\t\t\trlectx->run_len = 2;\n\t\t\trlectx->run_byte |= next_pix;\n\t\t}\n\t\telse {\n\t\t\t// Nowhere to put the byte: write out everything, and start fresh.\n\t\t\trle4_write_unc_and_run(rlectx);\n\t\t\trlectx->run_len = 1;\n\t\t\trlectx->run_byte = next_pix<<4;\n\t\t}\n\n\t\t// --------------------------------------------------------------\n\t\t// If any RUN bytes that can be added to UNC for free, do so.\n\t\twhile(rlectx->unc_len>0 && rlectx->run_len>0 && rle4_get_incr_unc_cost(rlectx)==0) {\n\t\t\trlectx->unc_len++;\n\t\t\trlectx->run_len--;\n\t\t\ttmpb = rlectx->run_byte;\n\t\t\t// Reverse the two pixels stored in run_byte.\n\t\t\trlectx->run_byte = (tmpb>>4) | ((tmpb&0x0f)<<4);\n\t\t\tif(rlectx->run_len==1) rlectx->run_byte &= 0xf0;\n\t\t}\n\n\t\t// --------------------------------------------------------------\n\t\t// If we hit certain high water marks, write out the current data.\n\n\t\tif(rlectx->run_len>=255) {\n\t\t\t// The maximum size for an RLE segment.\n\t\t\trle4_write_unc_and_run(rlectx);\n\t\t}\n\n\t\t// --------------------------------------------------------------\n\t\t// Sanity check(s). This can be removed if we're sure the algorithm\n\t\t// is bug-free.\n\n\t\t// run_len can be at most 254 at this point.\n\t\t// If it were 255, it should have been written out already.\n\t\tif(rlectx->run_len>255) {\n\t\t\tiw_set_error(rlectx->ctx,\"Internal: BMP RLE encode error 3\");\n\t\t\tgoto done;\n\t\t}\n\t}\n\n\t// End of row. Write out anything left over.\n\trle4_write_unc_and_run(rlectx);\n\n\t// Write an end-of-line marker (0 0), or if this is the last row,\n\t// an end-of-bitmap marker (0 1).\n\tdstbuf[0]=0x00;\n\tdstbuf[1]= (rlectx->cur_row==0)? 0x01 : 0x00;\n\tiwbmp_write(rlectx->wctx,dstbuf,2);\n\trlectx->total_bytes_written+=2;\n\n\tretval = 1;\n\ndone:\n\treturn retval;\n}\n\n//======================================================================\n\n// Seek back and write the \"file size\" and \"bits size\" fields.\nstatic int rle_patch_file_size(struct iwbmpwcontext *wctx,size_t rlesize)\n{\n\tiw_byte buf[4];\n\tsize_t fileheader_size;\n\tint ret;\n\n\tif(!wctx->iodescr->seek_fn) {\n\t\tiw_set_error(wctx->ctx,\"Writing compressed BMP requires a seek function\");\n\t\treturn 0;\n\t}\n\n\tif(wctx->include_file_header) {\n\t\t// Patch the file size in the file header\n\t\tret=(*wctx->iodescr->seek_fn)(wctx->ctx,wctx->iodescr,2,SEEK_SET);\n\t\tif(!ret) return 0;\n\t\tiw_set_ui32le(buf,(unsigned int)(14+wctx->header_size+wctx->bitfields_size+wctx->palsize+rlesize));\n\t\tiwbmp_write(wctx,buf,4);\n\t\tfileheader_size = 14;\n\t}\n\telse {\n\t\tfileheader_size = 0;\n\t}\n\n\t// Patch the \"bits\" size\n\tret=(*wctx->iodescr->seek_fn)(wctx->ctx,wctx->iodescr,fileheader_size+20,SEEK_SET);\n\tif(!ret) return 0;\n\tiw_set_ui32le(buf,(unsigned int)rlesize);\n\tiwbmp_write(wctx,buf,4);\n\n\t(*wctx->iodescr->seek_fn)(wctx->ctx,wctx->iodescr,0,SEEK_END);\n\treturn 1;\n}\n\nstatic int iwbmp_write_pixels_compressed(struct iwbmpwcontext *wctx,\n\tstruct iw_image *img)\n{\n\tstruct rle_context rlectx;\n\tint j;\n\tint retval = 0;\n\n\tiw_zeromem(&rlectx,sizeof(struct rle_context));\n\n\trlectx.ctx = wctx->ctx;\n\trlectx.wctx = wctx;\n\trlectx.total_bytes_written = 0;\n\trlectx.img_width = img->width;\n\n\tfor(j=img->height-1;j>=0;j--) {\n\t\t// Compress and write a row of pixels\n\t\trlectx.srcrow = &img->pixels[j*img->bpr];\n\t\trlectx.cur_row = j;\n\n\t\tif(wctx->bitcount==4) {\n\t\t\tif(!rle4_compress_row(&rlectx)) goto done;\n\t\t}\n\t\telse if(wctx->bitcount==8) {\n\t\t\tif(!rle8_compress_row(&rlectx)) goto done;\n\t\t}\n\t\telse {\n\t\t\tgoto done;\n\t\t}\n\t}\n\n\t// Back-patch the 'file size' and 'bits size' fields\n\tif(!rle_patch_file_size(wctx,rlectx.total_bytes_written)) goto done;\n\n\tretval = 1;\ndone:\n\treturn retval;\n}\n\nstatic void iwbmp_write_pixels_uncompressed(struct iwbmpwcontext *wctx,\n\tstruct iw_image *img)\n{\n\tint j;\n\tiw_byte *dstrow = NULL;\n\tconst iw_byte *srcrow;\n\n\tdstrow = iw_mallocz(wctx->ctx,wctx->unc_dst_bpr);\n\tif(!dstrow) goto done;\n\n\tfor(j=img->height-1;j>=0;j--) {\n\t\tsrcrow = &img->pixels[j*img->bpr];\n\t\tswitch(wctx->bitcount) {\n\t\tcase 32: bmpw_convert_row_16_32(wctx,srcrow,dstrow,img->width); break;\n\t\tcase 24: bmpw_convert_row_24(wctx,srcrow,dstrow,img->width); break;\n\t\tcase 16: bmpw_convert_row_16_32(wctx,srcrow,dstrow,img->width); break;\n\t\tcase 8: bmpw_convert_row_8(srcrow,dstrow,img->width); break;\n\t\tcase 4: bmpw_convert_row_4(srcrow,dstrow,img->width); break;\n\t\tcase 1: bmpw_convert_row_1(srcrow,dstrow,img->width); break;\n\t\t}\n\t\tiwbmp_write(wctx,dstrow,wctx->unc_dst_bpr);\n\t}\n\ndone:\n\tif(dstrow) iw_free(wctx->ctx,dstrow);\n\treturn;\n}\n\n// 0 = no transparency\n// 1 = binary transparency\n// 2 = partial transparency\nstatic int check_palette_transparency(const struct iw_palette *p)\n{\n\tint i;\n\tint retval = 0;\n\n\tfor(i=0;i<p->num_entries;i++) {\n\t\tif(p->entry[i].a!=255) retval=1;\n\t\tif(p->entry[i].a!=255 && p->entry[i].a!=0) return 2;\n\t}\n\treturn retval;\n}\n\n// Do some preparations needed to write a 16-bit or 32-bit BMP.\nstatic int setup_16_32bit(struct iwbmpwcontext *wctx,\n\tint mcc_r, int mcc_g, int mcc_b, int mcc_a)\n{\n\tint has_alpha;\n\n\thas_alpha = IW_IMGTYPE_HAS_ALPHA(wctx->img->imgtype);\n\n\tif(wctx->bmpversion<3) {\n\t\tiw_set_errorf(wctx->ctx,\"Bit depth incompatible with BMP version %d\",\n\t\t\twctx->bmpversion);\n\t\treturn 0;\n\t}\n\n\tif(has_alpha && wctx->bmpversion<5) {\n\t\tiw_set_error(wctx->ctx,\"Internal: Attempt to write v3 16- or 32-bit image with transparency\");\n\t\treturn 0;\n\t}\n\n\t// Make our own copy of the max color codes, so that we don't have to\n\t// do \"if(grayscale)\" so much.\n\twctx->maxcolor[0] = mcc_r;\n\twctx->maxcolor[1] = mcc_g;\n\twctx->maxcolor[2] = mcc_b;\n\tif(has_alpha) wctx->maxcolor[3] = mcc_a;\n\n\tif(!iwbmp_calc_bitfields_masks(wctx,has_alpha?4:3)) return 0;\n\n\tif(mcc_r==31 && mcc_g==31 && mcc_b==31 && !has_alpha) {\n\t\t// For the default 5-5-5, set the 'compression' to BI_RGB\n\t\t// instead of BITFIELDS, and don't write a BITFIELDS segment\n\t\t// (or for v5 BMP, don't set the Mask fields).\n\t\twctx->bitfields_size = 0;\n\t}\n\telse {\n\t\twctx->uses_bitfields = 1;\n\t\twctx->bitfields_size = (wctx->bmpversion==3) ? 12 : 0;\n\t}\n\treturn 1;\n}\n\nstatic int iwbmp_write_main(struct iwbmpwcontext *wctx)\n{\n\tstruct iw_image *img;\n\tint cmpr_req;\n\tint retval = 0;\n\tint x;\n\tconst char *optv;\n\n\timg = wctx->img;\n\n\twctx->bmpversion = 0;\n\toptv = iw_get_option(wctx->ctx, \"bmp:version\");\n\tif(optv) {\n\t\twctx->bmpversion = iw_parse_int(optv);\n\t}\n\n\tif(wctx->bmpversion==0) wctx->bmpversion=3;\n\tif(wctx->bmpversion==4) {\n\t\tiw_warning(wctx->ctx,\"Writing BMP v4 is not supported; using v3 instead\");\n\t\twctx->bmpversion=3;\n\t}\n\tif(wctx->bmpversion!=2 && wctx->bmpversion!=3 && wctx->bmpversion!=5) {\n\t\tiw_set_errorf(wctx->ctx,\"Unsupported BMP version: %d\",wctx->bmpversion);\n\t\tgoto done;\n\t}\n\n\tif(wctx->bmpversion>=3)\n\t\tcmpr_req = iw_get_value(wctx->ctx,IW_VAL_COMPRESSION);\n\telse\n\t\tcmpr_req = IW_COMPRESSION_NONE;\n\n\tif(wctx->bmpversion==2)\n\t\twctx->header_size = 12;\n\telse if(wctx->bmpversion==5)\n\t\twctx->header_size = 124;\n\telse\n\t\twctx->header_size = 40;\n\n\twctx->no_cslabel = iw_get_value(wctx->ctx,IW_VAL_NO_CSLABEL);\n\n\t// If any kind of compression was requested, use RLE if possible.\n\tif(cmpr_req==IW_COMPRESSION_AUTO || cmpr_req==IW_COMPRESSION_NONE)\n\t\tcmpr_req = IW_COMPRESSION_NONE;\n\telse\n\t\tcmpr_req = IW_COMPRESSION_RLE;\n\n\tif(img->imgtype==IW_IMGTYPE_RGB) {\n\t\tif(img->reduced_maxcolors) {\n\t\t\tif(!setup_16_32bit(wctx,img->maxcolorcode[IW_CHANNELTYPE_RED],\n\t\t\t\timg->maxcolorcode[IW_CHANNELTYPE_GREEN],\n\t\t\t\timg->maxcolorcode[IW_CHANNELTYPE_BLUE],0))\n\t\t\t{\n\t\t\t\tgoto done;\n\t\t\t}\n\t\t}\n\t\telse {\n\t\t\twctx->bitcount=24;\n\t\t}\n\t}\n\telse if(img->imgtype==IW_IMGTYPE_PALETTE) {\n\t\tif(!wctx->pal) goto done;\n\n\t\tx = check_palette_transparency(wctx->pal);\n\n\t\tif(x!=0 && wctx->bmpversion<3) {\n\t\t\tiw_set_error(wctx->ctx,\"Cannot save as a transparent BMP: Incompatible BMP version\");\n\t\t\tgoto done;\n\t\t}\n\t\telse if(x==2) {\n\t\t\tiw_set_error(wctx->ctx,\"Cannot save this image as a transparent BMP: Has partial transparency\");\n\t\t\tgoto done;\n\t\t}\n\t\telse if(x!=0 && cmpr_req!=IW_COMPRESSION_RLE) {\n\t\t\tiw_set_error(wctx->ctx,\"Cannot save as a transparent BMP: RLE compression required\");\n\t\t\tgoto done;\n\t\t}\n\n\t\tif(wctx->pal->num_entries<=2 && cmpr_req!=IW_COMPRESSION_RLE)\n\t\t\twctx->bitcount=1;\n\t\telse if(wctx->pal->num_entries<=16)\n\t\t\twctx->bitcount=4;\n\t\telse\n\t\t\twctx->bitcount=8;\n\t}\n\telse if(img->imgtype==IW_IMGTYPE_RGBA) {\n\t\tif(img->reduced_maxcolors) {\n\t\t\tif(!setup_16_32bit(wctx,img->maxcolorcode[IW_CHANNELTYPE_RED],\n\t\t\t\timg->maxcolorcode[IW_CHANNELTYPE_GREEN],\n\t\t\t\timg->maxcolorcode[IW_CHANNELTYPE_BLUE],\n\t\t\t\timg->maxcolorcode[IW_CHANNELTYPE_ALPHA]))\n\t\t\t{\n\t\t\t\tgoto done;\n\t\t\t}\n\t\t}\n\t\telse {\n\t\t\tif(!setup_16_32bit(wctx,255,255,255,255)) {\n\t\t\t\tgoto done;\n\t\t\t}\n\t\t}\n\t}\n\telse if(img->imgtype==IW_IMGTYPE_GRAYA) {\n\t\tif(img->reduced_maxcolors) {\n\t\t\tif(!setup_16_32bit(wctx,img->maxcolorcode[IW_CHANNELTYPE_GRAY],\n\t\t\t\timg->maxcolorcode[IW_CHANNELTYPE_GRAY],\n\t\t\t\timg->maxcolorcode[IW_CHANNELTYPE_GRAY],\n\t\t\t\timg->maxcolorcode[IW_CHANNELTYPE_ALPHA]))\n\t\t\t{\n\t\t\t\tgoto done;\n\t\t\t}\n\t\t}\n\t\telse {\n\t\t\tif(!setup_16_32bit(wctx,255,255,255,255)) {\n\t\t\t\tgoto done;\n\t\t\t}\n\t\t}\n\t}\n\telse if(img->imgtype==IW_IMGTYPE_GRAY) {\n\t\tif(img->reduced_maxcolors) {\n\t\t\tif(img->maxcolorcode[IW_CHANNELTYPE_GRAY]<=1023) {\n\t\t\t\tif(!setup_16_32bit(wctx,img->maxcolorcode[IW_CHANNELTYPE_GRAY],\n\t\t\t\t\timg->maxcolorcode[IW_CHANNELTYPE_GRAY],\n\t\t\t\t\timg->maxcolorcode[IW_CHANNELTYPE_GRAY],0))\n\t\t\t\t{\n\t\t\t\t\tgoto done;\n\t\t\t\t}\n\t\t\t}\n\t\t\telse {\n\t\t\t\tiw_set_error(wctx->ctx,\"Cannot write grayscale BMP at this bit depth\");\n\t\t\t\tgoto done;\n\t\t\t}\n\t\t}\n\t\telse {\n\t\t\t// We normally won't get here, because a grayscale image should have\n\t\t\t// been optimized and converted to a palette image.\n\t\t\t// But maybe that optimization was disabled.\n\t\t\twctx->bitcount=24;\n\t\t}\n\t}\n\telse {\n\t\tiw_set_error(wctx->ctx,\"Internal: Bad image type for BMP\");\n\t\tgoto done;\n\t}\n\n\tif(cmpr_req==IW_COMPRESSION_RLE && (wctx->bitcount==4 || wctx->bitcount==8)) {\n\t\twctx->compressed = 1;\n\t}\n\n\twctx->unc_dst_bpr = iwbmp_calc_bpr(wctx->bitcount,img->width);\n\twctx->unc_bitssize = wctx->unc_dst_bpr * img->height;\n\twctx->palentries = 0;\n\n\tif(wctx->pal) {\n\t\tif(wctx->bmpversion==2) {\n\t\t\twctx->palentries = 1<<wctx->bitcount;\n\t\t\twctx->palsize = wctx->palentries*3;\n\t\t}\n\t\telse {\n\t\t\tif(wctx->bitcount==1) {\n\t\t\t\t// The documentation says that if the bitdepth is 1, the palette\n\t\t\t\t// contains exactly two entries.\n\t\t\t\twctx->palentries=2;\n\t\t\t}\n\t\t\telse {\n\t\t\t\twctx->palentries = wctx->pal->num_entries;\n\t\t\t}\n\t\t\twctx->palsize = wctx->palentries*4;\n\t\t}\n\t}\n\n\t// File header\n\tiwbmp_write_file_header(wctx);\n\n\t// Bitmap header (\"BITMAPINFOHEADER\")\n\tif(!iwbmp_write_bmp_header(wctx)) {\n\t\tgoto done;\n\t}\n\n\tif(wctx->bitfields_size>0) {\n\t\tif(!iwbmp_write_bitfields(wctx)) goto done;\n\t}\n\n\t// Palette\n\tiwbmp_write_palette(wctx);\n\n\t// Pixels\n\tif(wctx->compressed) {\n\t\tif(!iwbmp_write_pixels_compressed(wctx,img)) goto done;\n\t}\n\telse {\n\t\tiwbmp_write_pixels_uncompressed(wctx,img);\n\t}\n\n\tretval = 1;\ndone:\n\treturn retval;\n}\n\nIW_IMPL(int) iw_write_bmp_file(struct iw_context *ctx, struct iw_iodescr *iodescr)\n{\n\tstruct iwbmpwcontext wctx;\n\tint retval=0;\n\tstruct iw_image img1;\n\n\tiw_zeromem(&img1,sizeof(struct iw_image));\n\n\tiw_zeromem(&wctx,sizeof(struct iwbmpwcontext));\n\n\twctx.ctx = ctx;\n\twctx.include_file_header = 1;\n\n\twctx.iodescr=iodescr;\n\n\tiw_get_output_image(ctx,&img1);\n\twctx.img = &img1;\n\n\tif(wctx.img->imgtype==IW_IMGTYPE_PALETTE) {\n\t\twctx.pal = iw_get_output_palette(ctx);\n\t\tif(!wctx.pal) goto done;\n\t}\n\n\tiw_get_output_colorspace(ctx,&wctx.csdescr);\n\n\tif(!iwbmp_write_main(&wctx)) {\n\t\tiw_set_error(ctx,\"BMP write failed\");\n\t\tgoto done;\n\t}\n\n\tretval=1;\n\ndone:\n\treturn retval;\n}\n", "// imagew-main.c\n// Part of ImageWorsener, Copyright (c) 2011 by Jason Summers.\n// For more information, see the readme.txt file.\n\n#include \"imagew-config.h\"\n\n#include <stdlib.h>\n#include <string.h>\n#include <math.h>\n\n#include \"imagew-internals.h\"\n\n\n// Given a color type having an alpha channel, returns the index of the\n// alpha channel.\n// Return value is not meaningful if type does not have an alpha channel.\nstatic int iw_imgtype_alpha_channel_index(int t)\n{\n\tswitch(t) {\n\tcase IW_IMGTYPE_RGBA:\n\t\treturn 3;\n\tcase IW_IMGTYPE_GRAYA:\n\t\treturn 1;\n\t}\n\treturn 0;\n}\n\nstatic IW_INLINE iw_tmpsample srgb_to_linear_sample(iw_tmpsample v_srgb)\n{\n\tif(v_srgb<=0.04045) {\n\t\treturn v_srgb/12.92;\n\t}\n\telse {\n\t\treturn pow( (v_srgb+0.055)/(1.055) , 2.4);\n\t}\n}\n\nstatic IW_INLINE iw_tmpsample rec709_to_linear_sample(iw_tmpsample v_rec709)\n{\n\tif(v_rec709 < 4.5*0.020) {\n\t\treturn v_rec709/4.5;\n\t}\n\telse {\n\t\treturn pow( (v_rec709+0.099)/1.099 , 1.0/0.45);\n\t}\n}\n\nstatic IW_INLINE iw_tmpsample gamma_to_linear_sample(iw_tmpsample v, double gamma)\n{\n\treturn pow(v,gamma);\n}\n\nstatic iw_tmpsample x_to_linear_sample(iw_tmpsample v, const struct iw_csdescr *csdescr)\n{\n\tswitch(csdescr->cstype) {\n\tcase IW_CSTYPE_SRGB:\n\t\treturn srgb_to_linear_sample(v);\n\tcase IW_CSTYPE_LINEAR:\n\t\treturn v;\n\tcase IW_CSTYPE_GAMMA:\n\t\treturn gamma_to_linear_sample(v,csdescr->gamma);\n\tcase IW_CSTYPE_REC709:\n\t\treturn rec709_to_linear_sample(v);\n\t}\n\treturn srgb_to_linear_sample(v);\n}\n\n// Public version of x_to_linear_sample().\nIW_IMPL(double) iw_convert_sample_to_linear(double v, const struct iw_csdescr *csdescr)\n{\n\treturn (double)x_to_linear_sample(v,csdescr);\n}\n\nstatic IW_INLINE iw_tmpsample linear_to_srgb_sample(iw_tmpsample v_linear)\n{\n\tif(v_linear <= 0.0031308) {\n\t\treturn 12.92*v_linear;\n\t}\n\treturn 1.055*pow(v_linear,1.0/2.4) - 0.055;\n}\n\nstatic IW_INLINE iw_tmpsample linear_to_rec709_sample(iw_tmpsample v_linear)\n{\n\t// The cutoff point is supposed to be 0.018, but that doesn't make sense,\n\t// because the curves don't intersect there. They intersect at almost exactly\n\t// 0.020.\n\tif(v_linear < 0.020) {\n\t\treturn 4.5*v_linear;\n\t}\n\treturn 1.099*pow(v_linear,0.45) - 0.099;\n}\n\nstatic IW_INLINE iw_tmpsample linear_to_gamma_sample(iw_tmpsample v_linear, double gamma)\n{\n\treturn pow(v_linear,1.0/gamma);\n}\n\nstatic iw_float32 iw_get_float32(const iw_byte *m)\n{\n\tint k;\n\t// !!! Portability warning: Using a union in this way may be nonportable.\n\tunion su_union {\n\t\tiw_byte c[4];\n\t\tiw_float32 f;\n\t} volatile su;\n\n\tfor(k=0;k<4;k++) {\n\t\tsu.c[k] = m[k];\n\t}\n\treturn su.f;\n}\n\nstatic void iw_put_float32(iw_byte *m, iw_float32 s)\n{\n\tint k;\n\t// !!! Portability warning: Using a union in this way may be nonportable.\n\tunion su_union {\n\t\tiw_byte c[4];\n\t\tiw_float32 f;\n\t} volatile su;\n\n\tsu.f = s;\n\n\tfor(k=0;k<4;k++) {\n\t\tm[k] = su.c[k];\n\t}\n}\n\nstatic iw_tmpsample get_raw_sample_flt32(struct iw_context *ctx,\n\t   int x, int y, int channel)\n{\n\tsize_t z;\n\tz = y*ctx->img1.bpr + (ctx->img1_numchannels_physical*x + channel)*4;\n\treturn (iw_tmpsample)iw_get_float32(&ctx->img1.pixels[z]);\n}\n\nstatic IW_INLINE unsigned int get_raw_sample_16(struct iw_context *ctx,\n\t   int x, int y, int channel)\n{\n\tsize_t z;\n\tunsigned short tmpui16;\n\tz = y*ctx->img1.bpr + (ctx->img1_numchannels_physical*x + channel)*2;\n\ttmpui16 = ( ((unsigned short)(ctx->img1.pixels[z+0])) <<8) | ctx->img1.pixels[z+1];\n\treturn tmpui16;\n}\n\nstatic IW_INLINE unsigned int get_raw_sample_8(struct iw_context *ctx,\n\t   int x, int y, int channel)\n{\n\tunsigned short tmpui8;\n\ttmpui8 = ctx->img1.pixels[y*ctx->img1.bpr + ctx->img1_numchannels_physical*x + channel];\n\treturn tmpui8;\n}\n\n// 4 bits/pixel\nstatic IW_INLINE unsigned int get_raw_sample_4(struct iw_context *ctx,\n\t   int x, int y)\n{\n\tunsigned short tmpui8;\n\ttmpui8 = ctx->img1.pixels[y*ctx->img1.bpr + x/2];\n\tif(x&0x1)\n\t\ttmpui8 = tmpui8&0x0f;\n\telse\n\t\ttmpui8 = tmpui8>>4;\n\treturn tmpui8;\n}\n\n// 2 bits/pixel\nstatic IW_INLINE unsigned int get_raw_sample_2(struct iw_context *ctx,\n\t   int x, int y)\n{\n\tunsigned short tmpui8;\n\ttmpui8 = ctx->img1.pixels[y*ctx->img1.bpr + x/4];\n\ttmpui8 = ( tmpui8 >> ((3-x%4)*2) ) & 0x03;\n\treturn tmpui8;\n}\n\n// 1 bit/pixel\nstatic IW_INLINE unsigned int get_raw_sample_1(struct iw_context *ctx,\n\t   int x, int y)\n{\n\tunsigned short tmpui8;\n\ttmpui8 = ctx->img1.pixels[y*ctx->img1.bpr + x/8];\n\tif(tmpui8 & (1<<(7-x%8))) return 1;\n\treturn 0;\n}\n\n// Translate a pixel position from logical to physical coordinates.\nstatic IW_INLINE void translate_coords(struct iw_context *ctx,\n\tint x, int y, int *prx, int *pry)\n{\n\tif(ctx->img1.orient_transform==0) {\n\t\t// The fast path\n\t\t*prx = ctx->input_start_x+x;\n\t\t*pry = ctx->input_start_y+y;\n\t\treturn;\n\t}\n\n\tswitch(ctx->img1.orient_transform) {\n\tcase 1: // mirror-x\n\t\t*prx = ctx->img1.width - 1 - (ctx->input_start_x+x);\n\t\t*pry = ctx->input_start_y+y;\n\t\tbreak;\n\tcase 2: // mirror-y\n\t\t*prx = ctx->input_start_x+x;\n\t\t*pry = ctx->img1.height - 1 - (ctx->input_start_y+y);\n\t\tbreak;\n\tcase 3: // mirror-x, mirror-y\n\t\t*prx = ctx->img1.width - 1 - (ctx->input_start_x+x);\n\t\t*pry = ctx->img1.height - 1 - (ctx->input_start_y+y);\n\t\tbreak;\n\tcase 4:\n\t\t// transpose\n\t\t*prx = ctx->input_start_y+y;\n\t\t*pry = ctx->input_start_x+x;\n\t\tbreak;\n\tcase 5:\n\t\t*prx = ctx->input_start_y+y;\n\t\t*pry = ctx->img1.width - 1 - (ctx->input_start_x+x);\n\t\tbreak;\n\tcase 6:\n\t\t*prx = ctx->img1.height - 1 - (ctx->input_start_y+y);\n\t\t*pry = ctx->input_start_x+x;\n\t\tbreak;\n\tcase 7:\n\t\t*prx = ctx->img1.height - 1 - (ctx->input_start_y+y);\n\t\t*pry = ctx->img1.width - 1 - (ctx->input_start_x+x);\n\t\tbreak;\n\tdefault:\n\t\t*prx = 0;\n\t\t*pry = 0;\n\t\tbreak;\n\t}\n}\n\n// Returns a value from 0 to 2^(ctx->img1.bit_depth)-1.\n// x and y are logical coordinates.\nstatic unsigned int get_raw_sample_int(struct iw_context *ctx,\n\t   int x, int y, int channel)\n{\n\tint rx,ry; // physical coordinates\n\n\ttranslate_coords(ctx,x,y,&rx,&ry);\n\n\tswitch(ctx->img1.bit_depth) {\n\tcase 8: return get_raw_sample_8(ctx,rx,ry,channel);\n\tcase 1: return get_raw_sample_1(ctx,rx,ry);\n\tcase 16: return get_raw_sample_16(ctx,rx,ry,channel);\n\tcase 4: return get_raw_sample_4(ctx,rx,ry);\n\tcase 2: return get_raw_sample_2(ctx,rx,ry);\n\t}\n\treturn 0;\n}\n\n// Channel is the input channel number.\n// x and y are logical coordinates.\nstatic iw_tmpsample get_raw_sample(struct iw_context *ctx,\n\t   int x, int y, int channel)\n{\n\tunsigned int v;\n\n\tif(channel>=ctx->img1_numchannels_physical) {\n\t\t// This is a virtual alpha channel. Return \"opaque\".\n\t\treturn 1.0;\n\t}\n\n\tif(ctx->img1.sampletype==IW_SAMPLETYPE_FLOATINGPOINT) {\n\t\tint rx, ry;\n\t\ttranslate_coords(ctx,x,y,&rx,&ry);\n\t\tif(ctx->img1.bit_depth!=32) return 0.0;\n\t\treturn get_raw_sample_flt32(ctx,rx,ry,channel);\n\t}\n\n\tv = get_raw_sample_int(ctx,x,y,channel);\n\treturn ((double)v) / ctx->img1_ci[channel].maxcolorcode_dbl;\n}\n\nstatic iw_tmpsample iw_color_to_grayscale(struct iw_context *ctx,\n\tiw_tmpsample r, iw_tmpsample g, iw_tmpsample b)\n{\n\tiw_tmpsample v0,v1,v2;\n\n\tswitch(ctx->grayscale_formula) {\n\tcase IW_GSF_WEIGHTED:\n\t\treturn ctx->grayscale_weight[0]*r +\n\t\t\tctx->grayscale_weight[1]*g +\n\t\t\tctx->grayscale_weight[2]*b;\n\tcase IW_GSF_ORDERBYVALUE:\n\t\t// Sort the R, G, and B values, then use the corresponding weights.\n\t\tif(g<=r) { v0=r; v1=g; }\n\t\telse { v0=g; v1=r; }\n\t\tif(b<=v1) {\n\t\t\tv2=b;\n\t\t}\n\t\telse {\n\t\t\tv2=v1;\n\t\t\tif(b<=v0) { v1=b; }\n\t\t\telse { v1=v0; v0=b; }\n\t\t}\n\t\treturn ctx->grayscale_weight[0]*v0 +\n\t\t\tctx->grayscale_weight[1]*v1 +\n\t\t\tctx->grayscale_weight[2]*v2;\n\t}\n\treturn 0.0;\n}\n\n// Based on color depth of the input image.\n// Assumes this channel's maxcolorcode == ctx->input_maxcolorcode\nstatic iw_tmpsample cvt_int_sample_to_linear(struct iw_context *ctx,\n\tunsigned int v, const struct iw_csdescr *csdescr)\n{\n\tiw_tmpsample s;\n\n\tif(csdescr->cstype==IW_CSTYPE_LINEAR) {\n\t\t// Sort of a hack: This is not just an optimization for linear colorspaces,\n\t\t// but is necessary to handle alpha channels correctly.\n\t\t// The lookup table is not correct for alpha channels.\n\t\treturn ((double)v) / ctx->input_maxcolorcode;\n\t}\n\telse if(ctx->input_color_corr_table) {\n\t\t// If the colorspace is not linear, assume we can use the lookup table.\n\t\treturn ctx->input_color_corr_table[v];\n\t}\n\n\ts = ((double)v) / ctx->input_maxcolorcode;\n\treturn x_to_linear_sample(s,csdescr);\n}\n\n// Based on color depth of the output image.\nstatic iw_tmpsample cvt_int_sample_to_linear_output(struct iw_context *ctx,\n\tunsigned int v, const struct iw_csdescr *csdescr, double overall_maxcolorcode)\n{\n\tiw_tmpsample s;\n\n\tif(csdescr->cstype==IW_CSTYPE_LINEAR) {\n\t\treturn ((double)v) / overall_maxcolorcode;\n\t}\n\telse if(ctx->output_rev_color_corr_table) {\n\t\treturn ctx->output_rev_color_corr_table[v];\n\t}\n\n\ts = ((double)v) / overall_maxcolorcode;\n\treturn x_to_linear_sample(s,csdescr);\n}\n\n// Return a sample, converted to a linear colorspace if it isn't already in one.\n// Channel is the output channel number.\nstatic iw_tmpsample get_sample_cvt_to_linear(struct iw_context *ctx,\n\t   int x, int y, int channel, const struct iw_csdescr *csdescr)\n{\n\tunsigned int v1,v2,v3;\n\tiw_tmpsample r,g,b;\n\tint ch;\n\n\tch = ctx->intermed_ci[channel].corresponding_input_channel;\n\n\tif(ctx->img1_ci[ch].disable_fast_get_sample) {\n\t\t// The slow way...\n\t\tif(ctx->intermed_ci[channel].cvt_to_grayscale) {\n\t\t\tr = x_to_linear_sample(get_raw_sample(ctx,x,y,ch+0),csdescr);\n\t\t\tg = x_to_linear_sample(get_raw_sample(ctx,x,y,ch+1),csdescr);\n\t\t\tb = x_to_linear_sample(get_raw_sample(ctx,x,y,ch+2),csdescr);\n\t\t\treturn iw_color_to_grayscale(ctx,r,g,b);\n\t\t}\n\t\treturn x_to_linear_sample(get_raw_sample(ctx,x,y,ch),csdescr);\n\t}\n\n\t// This method is faster, because it may use a gamma lookup table.\n\t// But all channels have to have the nominal input bitdepth, and it doesn't\n\t// support floating point samples, or a virtual alpha channel.\n\tif(ctx->intermed_ci[channel].cvt_to_grayscale) {\n\t\tv1 = get_raw_sample_int(ctx,x,y,ch+0);\n\t\tv2 = get_raw_sample_int(ctx,x,y,ch+1);\n\t\tv3 = get_raw_sample_int(ctx,x,y,ch+2);\n\t\tr = cvt_int_sample_to_linear(ctx,v1,csdescr);\n\t\tg = cvt_int_sample_to_linear(ctx,v2,csdescr);\n\t\tb = cvt_int_sample_to_linear(ctx,v3,csdescr);\n\t\treturn iw_color_to_grayscale(ctx,r,g,b);\n\t}\n\n\tv1 = get_raw_sample_int(ctx,x,y,ch);\n\treturn cvt_int_sample_to_linear(ctx,v1,csdescr);\n}\n\n// s is from 0.0 to 65535.0\nstatic IW_INLINE void put_raw_sample_16(struct iw_context *ctx, double s,\n\t   int x, int y, int channel)\n{\n\tsize_t z;\n\tunsigned short tmpui16;\n\n\ttmpui16 = (unsigned short)(0.5+s);\n\tz = y*ctx->img2.bpr + (ctx->img2_numchannels*x + channel)*2;\n\tctx->img2.pixels[z+0] = (iw_byte)(tmpui16>>8);\n\tctx->img2.pixels[z+1] = (iw_byte)(tmpui16&0xff);\n}\n\n// s is from 0.0 to 255.0\nstatic IW_INLINE void put_raw_sample_8(struct iw_context *ctx, double s,\n\t   int x, int y, int channel)\n{\n\tiw_byte tmpui8;\n\n\ttmpui8 = (iw_byte)(0.5+s);\n\tctx->img2.pixels[y*ctx->img2.bpr + ctx->img2_numchannels*x + channel] = tmpui8;\n}\n\n// Sample must already be scaled and in the target colorspace. E.g. 255.0 might be white.\nstatic void put_raw_sample(struct iw_context *ctx, double s,\n\t   int x, int y, int channel)\n{\n\tswitch(ctx->img2.bit_depth) {\n\tcase 8:  put_raw_sample_8(ctx,s,x,y,channel); break;\n\tcase 16: put_raw_sample_16(ctx,s,x,y,channel); break;\n\t}\n}\n\n// s is from 0.0 to 1.0\nstatic void put_raw_sample_flt32(struct iw_context *ctx, double s,\n\t   int x, int y, int channel)\n{\n\tsize_t pos;\n\tpos = y*ctx->img2.bpr + (ctx->img2_numchannels*x + channel)*4;\n\tiw_put_float32(&ctx->img2.pixels[pos], (iw_float32)s);\n}\n\nstatic iw_tmpsample linear_to_x_sample(iw_tmpsample samp_lin, const struct iw_csdescr *csdescr)\n{\n\tif(samp_lin > 0.999999999) {\n\t\t// This check is done mostly because glibc's pow() function may be\n\t\t// very slow for some arguments near 1.\n\t\treturn 1.0;\n\t}\n\n\tswitch(csdescr->cstype) {\n\tcase IW_CSTYPE_SRGB:\n\t\treturn linear_to_srgb_sample(samp_lin);\n\tcase IW_CSTYPE_LINEAR:\n\t\treturn samp_lin;\n\tcase IW_CSTYPE_GAMMA:\n\t\treturn linear_to_gamma_sample(samp_lin,csdescr->gamma);\n\tcase IW_CSTYPE_REC709:\n\t\treturn linear_to_rec709_sample(samp_lin);\n\t}\n\treturn linear_to_srgb_sample(samp_lin);\n}\n\n// Public version of linear_to_x_sample().\nIW_IMPL(double) iw_convert_sample_from_linear(double v, const struct iw_csdescr *csdescr)\n{\n\treturn (double)linear_to_x_sample(v,csdescr);\n}\n\n// Returns 0 if we should round down, 1 if we should round up.\n// TODO: It might be good to use a different-sized matrix for alpha channels\n// (e.g. 9x7), but I don't know how to make a good one.\nstatic int iw_ordered_dither(int dithersubtype, double fraction, int x, int y)\n{\n\tdouble threshold;\n\tstatic const float pattern[2][64] = {\n\t { // Dispersed ordered dither\n\t\t 0.5/64,48.5/64,12.5/64,60.5/64, 3.5/64,51.5/64,15.5/64,63.5/64,\n\t\t32.5/64,16.5/64,44.5/64,28.5/64,35.5/64,19.5/64,47.5/64,31.5/64,\n\t\t 8.5/64,56.5/64, 4.5/64,52.5/64,11.5/64,59.5/64, 7.5/64,55.5/64,\n\t\t40.5/64,24.5/64,36.5/64,20.5/64,43.5/64,27.5/64,39.5/64,23.5/64,\n\t\t 2.5/64,50.5/64,14.5/64,62.5/64, 1.5/64,49.5/64,13.5/64,61.5/64,\n\t\t34.5/64,18.5/64,46.5/64,30.5/64,33.5/64,17.5/64,45.5/64,29.5/64,\n\t\t10.5/64,58.5/64, 6.5/64,54.5/64, 9.5/64,57.5/64, 5.5/64,53.5/64,\n\t\t42.5/64,26.5/64,38.5/64,22.5/64,41.5/64,25.5/64,37.5/64,21.5/64\n\t },\n\t { // Halftone ordered dither\n\t\t 3.5/64, 9.5/64,17.5/64,27.5/64,25.5/64,15.5/64, 7.5/64, 1.5/64,\n\t\t11.5/64,29.5/64,37.5/64,45.5/64,43.5/64,35.5/64,23.5/64, 5.5/64,\n\t\t19.5/64,39.5/64,51.5/64,57.5/64,55.5/64,49.5/64,33.5/64,13.5/64,\n\t\t31.5/64,47.5/64,59.5/64,63.5/64,61.5/64,53.5/64,41.5/64,21.5/64,\n\t\t30.5/64,46.5/64,58.5/64,62.5/64,60.5/64,52.5/64,40.5/64,20.5/64,\n\t\t18.5/64,38.5/64,50.5/64,56.5/64,54.5/64,48.5/64,32.5/64,12.5/64,\n\t\t10.5/64,28.5/64,36.5/64,44.5/64,42.5/64,34.5/64,22.5/64, 4.5/64,\n\t\t 2.5/64, 8.5/64,16.5/64,26.5/64,24.5/64,14.5/64, 6.5/64, 0.5/64\n\t }};\n\n\tthreshold = pattern[dithersubtype][(x%8) + 8*(y%8)];\n\treturn (fraction >= threshold);\n}\n\n// Returns 0 if we should round down, 1 if we should round up.\nstatic int iw_random_dither(struct iw_context *ctx, double fraction, int x, int y,\n\tint dithersubtype, int channel)\n{\n\tdouble threshold;\n\n\tthreshold = ((double)iwpvt_prng_rand(ctx->prng)) / (double)0xffffffff;\n\tif(fraction>=threshold) return 1;\n\treturn 0;\n}\n\nstatic void iw_errdiff_dither(struct iw_context *ctx,int dithersubtype,\n\tdouble err,int x,int y)\n{\n\tint fwd;\n\tconst double *m;\n\n\t//        x  0  1\n\t//  2  3  4  5  6\n\t//  7  8  9 10 11\n\n\tstatic const double matrix_list[][12] = {\n\t{                          7.0/16, 0.0,     // 0 = Floyd-Steinberg\n\t   0.0   , 3.0/16, 5.0/16, 1.0/16, 0.0,\n\t   0.0   ,    0.0,    0.0, 0.0   , 0.0    },\n\t{                          7.0/48, 5.0/48,  // 1 = JJN\n\t   3.0/48, 5.0/48, 7.0/48, 5.0/48, 3.0/48,\n\t   1.0/48, 3.0/48, 5.0/48, 3.0/48, 1.0/48 },\n\t{                          8.0/42, 4.0/42,  // 2 = Stucki\n\t   2.0/42, 4.0/42, 8.0/42, 4.0/42, 2.0/42,\n\t   1.0/42, 2.0/42, 4.0/42, 2.0/42, 1.0/42 },\n\t{                          8.0/32, 4.0/32,  // 3 = Burkes\n\t   2.0/32, 4.0/32, 8.0/32, 4.0/32, 2.0/32,\n\t   0.0   , 0.0   , 0.0   , 0.0   , 0.0    },\n\t{                          5.0/32, 3.0/32,  // 4 = Sierra3\n\t   2.0/32, 4.0/32, 5.0/32, 4.0/32, 2.0/32,\n\t      0.0, 2.0/32, 3.0/32, 2.0/32, 0.0    },\n\t{                          4.0/16, 3.0/16,  // 5 = Sierra2\n\t   1.0/16, 2.0/16, 3.0/16, 2.0/16, 1.0/16,\n\t   0.0   , 0.0   , 0.0   , 0.0   , 0.0    },\n\t{                          2.0/4 , 0.0,     // 6 = Sierra42a\n\t   0.0   , 1.0/4 , 1.0/4 , 0.0   , 0.0,\n\t   0.0   , 0.0   , 0.0   , 0.0   , 0.0    },\n\t{                          1.0/8 , 1.0/8,   // 7 = Atkinson\n\t   0.0   , 1.0/8 , 1.0/8 , 1.0/8 , 0.0,\n\t   0.0   , 0.0   , 1.0/8 , 0.0   , 0.0    }\n\t};\n\n\tif(dithersubtype<=7)\n\t\tm = matrix_list[dithersubtype];\n\telse\n\t\tm = matrix_list[0];\n\n\tfwd = (y%2)?(-1):1;\n\n\tif((x-fwd)>=0 && (x-fwd)<ctx->img2.width) {\n\t\tif((x-2*fwd)>=0 && (x-2*fwd)<ctx->img2.width) {\n\t\t\tctx->dither_errors[1][x-2*fwd] += err*(m[2]);\n\t\t\tctx->dither_errors[2][x-2*fwd] += err*(m[7]);\n\t\t}\n\t\tctx->dither_errors[1][x-fwd] += err*(m[3]);\n\t\tctx->dither_errors[2][x-fwd] += err*(m[8]);\n\t}\n\n\tctx->dither_errors[1][x] += err*(m[4]);\n\tctx->dither_errors[2][x] += err*(m[9]);\n\n\tif((x+fwd)>=0 && (x+fwd)<ctx->img2.width) {\n\t\tctx->dither_errors[0][x+fwd] += err*(m[0]);\n\t\tctx->dither_errors[1][x+fwd] += err*(m[5]);\n\t\tctx->dither_errors[2][x+fwd] += err*(m[10]);\n\t\tif((x+2*fwd)>=0 && (x+2*fwd)<ctx->img2.width) {\n\t\t\tctx->dither_errors[0][x+2*fwd] += err*(m[1]);\n\t\t\tctx->dither_errors[1][x+2*fwd] += err*(m[6]);\n\t\t\tctx->dither_errors[2][x+2*fwd] += err*(m[11]);\n\t\t}\n\t}\n}\n\n// 'channel' is the output channel.\nstatic int get_nearest_valid_colors(struct iw_context *ctx, iw_tmpsample samp_lin,\n\t\tconst struct iw_csdescr *csdescr,\n\t\tdouble *s_lin_floor_1, double *s_lin_ceil_1,\n\t\tdouble *s_cvt_floor_full, double *s_cvt_ceil_full,\n\t\tdouble overall_maxcolorcode, int color_count)\n{\n\tiw_tmpsample samp_cvt;\n\tdouble samp_cvt_expanded;\n\tunsigned int floor_int, ceil_int;\n\n\t// A prelimary conversion to the target color space.\n\tsamp_cvt = linear_to_x_sample(samp_lin,csdescr);\n\n\tif(color_count==0) {\n\t\t// The normal case: we want to use this channel's full available depth.\n\t\tsamp_cvt_expanded = samp_cvt * overall_maxcolorcode;\n\t\tif(samp_cvt_expanded>overall_maxcolorcode) samp_cvt_expanded=overall_maxcolorcode;\n\t\tif(samp_cvt_expanded<0.0) samp_cvt_expanded=0.0;\n\n\t\t// Find the next-smallest and next-largest valid values that\n\t\t// can be stored in this image.\n\t\t// We will use one of them, but in order to figure out *which* one,\n\t\t// we have to compare their distances in the *linear* color space.\n\t\t*s_cvt_floor_full = floor(samp_cvt_expanded);\n\t\t*s_cvt_ceil_full  = ceil(samp_cvt_expanded);\n\t}\n\telse {\n\t\t// We're \"posterizing\": restricting to a certain number of color shades.\n\t\tdouble posterized_maxcolorcode;\n\t\t// Example: color_count = 4, bit_depth = 8;\n\t\t// Colors are from 0.0 to 3.0, mapped to 0.0 to 255.0.\n\t\t// Reduction factor is 255.0/3.0 = 85.0\n\n\t\tposterized_maxcolorcode = (double)(color_count-1);\n\n\t\tsamp_cvt_expanded = samp_cvt * posterized_maxcolorcode;\n\t\tif(samp_cvt_expanded>posterized_maxcolorcode) samp_cvt_expanded=posterized_maxcolorcode;\n\t\tif(samp_cvt_expanded<0.0) samp_cvt_expanded=0.0;\n\n\t\t// If the number of shades is not 2, 4, 6, 16, 18, 52, 86, or 256 (assuming 8-bit depth),\n\t\t// then the shades will not be exactly evenly spaced. For example, if there are 3 shades,\n\t\t// they will be 0, 128, and 255. It will often be the case that the shade we want is exactly\n\t\t// halfway between the nearest two available shades, and the \"0.5000000001\" fudge factor is my\n\t\t// attempt to make sure it rounds consistently in the same direction.\n\t\t*s_cvt_floor_full = floor(0.5000000001 + floor(samp_cvt_expanded) * (overall_maxcolorcode/posterized_maxcolorcode));\n\t\t*s_cvt_ceil_full  = floor(0.5000000001 + ceil (samp_cvt_expanded) * (overall_maxcolorcode/posterized_maxcolorcode));\n\t}\n\n\tfloor_int = (unsigned int)(*s_cvt_floor_full);\n\tceil_int  = (unsigned int)(*s_cvt_ceil_full);\n\tif(floor_int == ceil_int) {\n\t\treturn 1;\n\t}\n\n\t// Convert the candidates to our linear color space\n\t*s_lin_floor_1 = cvt_int_sample_to_linear_output(ctx,floor_int,csdescr,overall_maxcolorcode);\n\t*s_lin_ceil_1 =  cvt_int_sample_to_linear_output(ctx,ceil_int ,csdescr,overall_maxcolorcode);\n\n\treturn 0;\n}\n\n// channel is the output channel\nstatic void put_sample_convert_from_linear_flt(struct iw_context *ctx, iw_tmpsample samp_lin,\n\t   int x, int y, int channel, const struct iw_csdescr *csdescr)\n{\n\tput_raw_sample_flt32(ctx,(double)samp_lin,x,y,channel);\n}\n\nstatic double get_final_sample_using_nc_tbl(struct iw_context *ctx, iw_tmpsample samp_lin)\n{\n\tunsigned int x;\n\tunsigned int d;\n\n\t// For numbers 0 through 254, find the smallest one for which the\n\t// corresponding table value is larger than samp_lin.\n\n\t// Do a binary search.\n\n\tx = 127;\n\td = 64;\n\n\twhile(1) {\n\t\tif(x>254 || ctx->nearest_color_table[x] > samp_lin)\n\t\t\tx -= d;\n\t\telse\n\t\t\tx += d;\n\n\t\tif(d==1) {\n\t\t\tif(x>254 || ctx->nearest_color_table[x] > samp_lin)\n\t\t\t\treturn (double)(x);\n\t\t\telse\n\t\t\t\treturn (double)(x+1);\n\t\t}\n\n\t\td = d/2;\n\t}\n}\n\n// channel is the output channel\nstatic void put_sample_convert_from_linear(struct iw_context *ctx, iw_tmpsample samp_lin,\n\t   int x, int y, int channel, const struct iw_csdescr *csdescr)\n{\n\tdouble s_lin_floor_1, s_lin_ceil_1;\n\tdouble s_cvt_floor_full, s_cvt_ceil_full;\n\tdouble d_floor, d_ceil;\n\tint is_exact;\n\tdouble s_full;\n\tint ditherfamily;\n\tint dd; // Dither decision: 0 to use floor, 1 to use ceil.\n\n\t// Clamp to the [0.0,1.0] range.\n\t// The sample type is UINT, so out-of-range samples can't be represented.\n\t// TODO: I think that out-of-range samples could still have a meaningful\n\t// effect if we are dithering. More investigation is needed here.\n\tif(samp_lin<0.0) samp_lin=0.0;\n\tif(samp_lin>1.0) samp_lin=1.0;\n\n\t// TODO: This is getting messy. The conditions under which we use lookup\n\t// tables are too complicated, and we still don't use them as often as we\n\t// should. For example, if we are not dithering, we can use a table optimized\n\t// for telling us the single nearest color. But if we are dithering, then we\n\t// instead need to know both the next-highest and next-lowest colors, which\n\t// would require a different table. The same table could be used for both,\n\t// but not quite as efficiently. Currently, we don't use use a lookup table\n\t// when dithering, except that we may still use one to do some of the\n\t// intermediate computations. Etc.\n\tif(ctx->img2_ci[channel].use_nearest_color_table) {\n\t\ts_full = get_final_sample_using_nc_tbl(ctx,samp_lin);\n\t\tgoto okay;\n\t}\n\n\tditherfamily=ctx->img2_ci[channel].ditherfamily;\n\n\tif(ditherfamily==IW_DITHERFAMILY_ERRDIFF) {\n\t\tsamp_lin += ctx->dither_errors[0][x];\n\t\t// If the prior error makes the ideal brightness out of the available range,\n\t\t// just throw away any extra.\n\t\tif(samp_lin>1.0) samp_lin=1.0;\n\t\telse if(samp_lin<0.0) samp_lin=0.0;\n\t}\n\n\tis_exact = get_nearest_valid_colors(ctx,samp_lin,csdescr,\n\t\t&s_lin_floor_1, &s_lin_ceil_1,\n\t\t&s_cvt_floor_full, &s_cvt_ceil_full,\n\t\tctx->img2_ci[channel].maxcolorcode_dbl, ctx->img2_ci[channel].color_count);\n\n\tif(is_exact) {\n\t\ts_full = s_cvt_floor_full;\n\n\t\t// Hack to keep the PRNG in sync. We have to generate exactly one random\n\t\t// number per sample, regardless of whether we use it.\n\t\tif(ditherfamily==IW_DITHERFAMILY_RANDOM) {\n\t\t\t(void)iwpvt_prng_rand(ctx->prng);\n\t\t}\n\t\tgoto okay;\n\t}\n\n\t// samp_lin should be between s_lin_floor_1 and s_lin_ceil_1. Figure out\n\t// which is closer, and use the final pixel value we figured out earlier\n\t// (either s_cvt_floor_full or s_cvt_ceil_full).\n\td_floor = samp_lin-s_lin_floor_1;\n\td_ceil  = s_lin_ceil_1-samp_lin;\n\n\tif(ditherfamily==IW_DITHERFAMILY_NONE) {\n\t\t// Not dithering. Just choose closest value.\n\t\tif(d_ceil<=d_floor) s_full=s_cvt_ceil_full;\n\t\telse s_full=s_cvt_floor_full;\n\t}\n\telse if(ditherfamily==IW_DITHERFAMILY_ERRDIFF) {\n\t\tif(d_ceil<=d_floor) {\n\t\t\t// Ceiling is closer. This pixel will be lighter than ideal.\n\t\t\t// so the error is negative, to make other pixels darker.\n\t\t\tiw_errdiff_dither(ctx,ctx->img2_ci[channel].dithersubtype,-d_ceil,x,y);\n\t\t\ts_full=s_cvt_ceil_full;\n\t\t}\n\t\telse {\n\t\t\tiw_errdiff_dither(ctx,ctx->img2_ci[channel].dithersubtype,d_floor,x,y);\n\t\t\ts_full=s_cvt_floor_full;\n\t\t}\n\t}\n\telse if(ditherfamily==IW_DITHERFAMILY_ORDERED) {\n\t\tdd=iw_ordered_dither(ctx->img2_ci[channel].dithersubtype, d_floor/(d_floor+d_ceil),x,y);\n\t\ts_full = dd ? s_cvt_ceil_full : s_cvt_floor_full;\n\t}\n\telse if(ditherfamily==IW_DITHERFAMILY_RANDOM) {\n\t\tdd=iw_random_dither(ctx,d_floor/(d_floor+d_ceil),x,y,ctx->img2_ci[channel].dithersubtype,channel);\n\t\ts_full = dd ? s_cvt_ceil_full : s_cvt_floor_full;\n\t}\n\telse {\n\t\t// Unsupported dither method.\n\t\ts_full = 0.0;\n\t}\n\nokay:\n\tput_raw_sample(ctx,s_full,x,y,channel);\n}\n\n// A stripped-down version of put_sample_convert_from_linear(),\n// intended for use with background colors.\nstatic unsigned int calc_sample_convert_from_linear(struct iw_context *ctx, iw_tmpsample samp_lin,\n\t   const struct iw_csdescr *csdescr, double overall_maxcolorcode)\n{\n\tdouble s_lin_floor_1, s_lin_ceil_1;\n\tdouble s_cvt_floor_full, s_cvt_ceil_full;\n\tdouble d_floor, d_ceil;\n\tint is_exact;\n\tdouble s_full;\n\n\tif(samp_lin<0.0) samp_lin=0.0;\n\tif(samp_lin>1.0) samp_lin=1.0;\n\n\tis_exact = get_nearest_valid_colors(ctx,samp_lin,csdescr,\n\t\t&s_lin_floor_1, &s_lin_ceil_1,\n\t\t&s_cvt_floor_full, &s_cvt_ceil_full,\n\t\toverall_maxcolorcode, 0);\n\n\tif(is_exact) {\n\t\ts_full = s_cvt_floor_full;\n\t\tgoto okay;\n\t}\n\n\td_floor = samp_lin-s_lin_floor_1;\n\td_ceil  = s_lin_ceil_1-samp_lin;\n\n\tif(d_ceil<=d_floor) s_full=s_cvt_ceil_full;\n\telse s_full=s_cvt_floor_full;\n\nokay:\n\treturn (unsigned int)(0.5+s_full);\n}\n\nstatic void clamp_output_samples(struct iw_context *ctx, iw_tmpsample *out_pix, int num_out_pix)\n{\n\tint i;\n\n\tfor(i=0;i<num_out_pix;i++) {\n\t\tif(out_pix[i]<0.0) out_pix[i]=0.0;\n\t\telse if(out_pix[i]>1.0) out_pix[i]=1.0;\n\t}\n}\n\n// TODO: Maybe this should be a flag in ctx, instead of a function that is\n// called repeatedly.\nstatic int iw_bkgd_has_transparency(struct iw_context *ctx)\n{\n\tif(!ctx->apply_bkgd) return 0;\n\tif(!(ctx->output_profile&IW_PROFILE_TRANSPARENCY)) return 0;\n\tif(ctx->apply_bkgd_strategy==IW_BKGD_STRATEGY_EARLY) return 0;\n\tif(ctx->bkgd_color_source==IW_BKGD_COLOR_SOURCE_FILE) {\n\t\tif(ctx->img1_bkgd_label_inputcs.c[3]<1.0) return 1;\n\t}\n\telse if(ctx->bkgd_color_source==IW_BKGD_COLOR_SOURCE_REQ) {\n\t\tif(ctx->bkgd_checkerboard) {\n\t\t\tif(ctx->req.bkgd2.c[3]<1.0) return 1;\n\t\t}\n\t\tif(ctx->req.bkgd.c[3]<1.0) return 1;\n\t}\n\treturn 0;\n}\n\n// 'channel' is an intermediate channel number.\nstatic int iw_process_cols_to_intermediate(struct iw_context *ctx, int channel,\n\tconst struct iw_csdescr *in_csdescr)\n{\n\tint i,j;\n\tint retval=0;\n\tiw_tmpsample tmp_alpha;\n\tiw_tmpsample *inpix_tofree = NULL;\n\tiw_tmpsample *outpix_tofree = NULL;\n\tint is_alpha_channel;\n\tstruct iw_resize_settings *rs = NULL;\n\tstruct iw_channelinfo_intermed *int_ci;\n\n\tiw_tmpsample *in_pix;\n\tiw_tmpsample *out_pix;\n\tint num_in_pix;\n\tint num_out_pix;\n\n\tint_ci = &ctx->intermed_ci[channel];\n\tis_alpha_channel = (int_ci->channeltype==IW_CHANNELTYPE_ALPHA);\n\n\tnum_in_pix = ctx->input_h;\n\tinpix_tofree = (iw_tmpsample*)iw_malloc(ctx, num_in_pix * sizeof(iw_tmpsample));\n\tif(!inpix_tofree) goto done;\n\tin_pix = inpix_tofree;\n\n\tnum_out_pix = ctx->intermed_canvas_height;\n\toutpix_tofree = (iw_tmpsample*)iw_malloc(ctx, num_out_pix * sizeof(iw_tmpsample));\n\tif(!outpix_tofree) goto done;\n\tout_pix = outpix_tofree;\n\n\trs=&ctx->resize_settings[IW_DIMENSION_V];\n\n\t// If the resize context for this dimension already exists, we should be\n\t// able to reuse it. Otherwise, create a new one.\n\tif(!rs->rrctx) {\n\t\t// TODO: The use of the word \"rows\" here is misleading, because we are\n\t\t// actually resizing columns.\n\t\trs->rrctx = iwpvt_resize_rows_init(ctx,rs,int_ci->channeltype,\n\t\t\tnum_in_pix, num_out_pix);\n\t\tif(!rs->rrctx) goto done;\n\t}\n\n\tfor(i=0;i<ctx->input_w;i++) {\n\n\t\t// Read a column of pixels into ctx->in_pix\n\t\tfor(j=0;j<ctx->input_h;j++) {\n\n\t\t\tin_pix[j] = get_sample_cvt_to_linear(ctx,i,j,channel,in_csdescr);\n\n\t\t\tif(int_ci->need_unassoc_alpha_processing) { // We need opacity information also\n\t\t\t\ttmp_alpha = get_raw_sample(ctx,i,j,ctx->img1_alpha_channel_index);\n\n\t\t\t\t// Multiply color amount by opacity\n\t\t\t\tin_pix[j] *= tmp_alpha;\n\t\t\t}\n\t\t\telse if(ctx->apply_bkgd && ctx->apply_bkgd_strategy==IW_BKGD_STRATEGY_EARLY) {\n\t\t\t\t// We're doing \"Early\" background color application.\n\t\t\t\t// All intermediate channels will need the background color\n\t\t\t\t// applied to them.\n\t\t\t\ttmp_alpha = get_raw_sample(ctx,i,j,ctx->img1_alpha_channel_index);\n\t\t\t\tin_pix[j] = (tmp_alpha)*(in_pix[j]) +\n\t\t\t\t\t(1.0-tmp_alpha)*(int_ci->bkgd_color_lin);\n\t\t\t}\n\t\t}\n\n\t\t// Now we have a row in the right format.\n\t\t// Resize it and store it in the right place in the intermediate array.\n\n\t\tiwpvt_resize_row_main(rs->rrctx,in_pix,out_pix);\n\n\t\tif(ctx->intclamp)\n\t\t\tclamp_output_samples(ctx,out_pix,num_out_pix);\n\n\t\t// The intermediate pixels are in ctx->out_pix. Copy them to the intermediate array.\n\t\tfor(j=0;j<ctx->intermed_canvas_height;j++) {\n\t\t\tif(is_alpha_channel) {\n\t\t\t\tctx->intermediate_alpha32[((size_t)j)*ctx->intermed_canvas_width + i] = (iw_float32)out_pix[j];\n\t\t\t}\n\t\t\telse {\n\t\t\t\tctx->intermediate32[((size_t)j)*ctx->intermed_canvas_width + i] = (iw_float32)out_pix[j];\n\t\t\t}\n\t\t}\n\t}\n\n\tretval=1;\n\ndone:\n\tif(rs && rs->disable_rrctx_cache && rs->rrctx) {\n\t\t// In some cases, the channels may need different resize contexts.\n\t\t// Delete the current context, so that it doesn't get reused.\n\t\tiwpvt_resize_rows_done(rs->rrctx);\n\t\trs->rrctx = NULL;\n\t}\n\tif(inpix_tofree) iw_free(ctx,inpix_tofree);\n\tif(outpix_tofree) iw_free(ctx,outpix_tofree);\n\treturn retval;\n}\n\n// 'handle_alpha_flag' must be set if an alpha channel exists and this is not\n// the alpha channel.\nstatic int iw_process_rows_intermediate_to_final(struct iw_context *ctx, int intermed_channel,\n\tconst struct iw_csdescr *out_csdescr)\n{\n\tint i,j;\n\tint z;\n\tint k;\n\tint retval=0;\n\tiw_tmpsample tmpsamp;\n\tiw_tmpsample alphasamp = 0.0;\n\tiw_tmpsample *inpix_tofree = NULL; // Used if we need a separate temp buffer for input samples\n\tiw_tmpsample *outpix_tofree = NULL; // Used if we need a separate temp buffer for output samples\n\t// Do any of the output channels use error-diffusion dithering?\n\tint using_errdiffdither = 0;\n\tint output_channel;\n\tint is_alpha_channel;\n\tint bkgd_has_transparency;\n\tdouble tmpbkgdalpha=0.0;\n\tint alt_bkgd = 0; // Nonzero if we should use bkgd2 for this sample\n\tstruct iw_resize_settings *rs = NULL;\n\tint ditherfamily, dithersubtype;\n\tstruct iw_channelinfo_intermed *int_ci;\n\tstruct iw_channelinfo_out *out_ci;\n\n\tiw_tmpsample *in_pix = NULL;\n\tiw_tmpsample *out_pix = NULL;\n\tint num_in_pix;\n\tint num_out_pix;\n\n\tnum_in_pix = ctx->intermed_canvas_width;\n\tnum_out_pix = ctx->img2.width;\n\n\tint_ci = &ctx->intermed_ci[intermed_channel];\n\toutput_channel = int_ci->corresponding_output_channel;\n\tout_ci = &ctx->img2_ci[output_channel];\n\tis_alpha_channel = (int_ci->channeltype==IW_CHANNELTYPE_ALPHA);\n\tbkgd_has_transparency = iw_bkgd_has_transparency(ctx);\n\n\tinpix_tofree = (iw_tmpsample*)iw_malloc(ctx, num_in_pix * sizeof(iw_tmpsample));\n\tin_pix = inpix_tofree;\n\n\t// We need an output buffer.\n\toutpix_tofree = (iw_tmpsample*)iw_malloc(ctx, num_out_pix * sizeof(iw_tmpsample));\n\tif(!outpix_tofree) goto done;\n\tout_pix = outpix_tofree;\n\n\t// Decide if the 'nearest color table' optimization can be used\n\tif(ctx->nearest_color_table && !is_alpha_channel &&\n\t   out_ci->ditherfamily==IW_DITHERFAMILY_NONE &&\n\t   out_ci->color_count==0)\n\t{\n\t\tout_ci->use_nearest_color_table = 1;\n\t}\n\telse {\n\t\tout_ci->use_nearest_color_table = 0;\n\t}\n\n\t// Seed the PRNG, if necessary.\n\tditherfamily = out_ci->ditherfamily;\n\tdithersubtype = out_ci->dithersubtype;\n\tif(ditherfamily==IW_DITHERFAMILY_RANDOM) {\n\t\t// Decide what random seed to use. The alpha channel always has its own\n\t\t// seed. If using \"r\" (not \"r2\") dithering, every channel has its own seed.\n\t\tif(dithersubtype==IW_DITHERSUBTYPE_SAMEPATTERN && out_ci->channeltype!=IW_CHANNELTYPE_ALPHA)\n\t\t{\n\t\t\tiwpvt_prng_set_random_seed(ctx->prng,ctx->random_seed);\n\t\t}\n\t\telse {\n\t\t\tiwpvt_prng_set_random_seed(ctx->prng,ctx->random_seed+out_ci->channeltype);\n\t\t}\n\t}\n\n\t// Initialize Floyd-Steinberg dithering.\n\tif(output_channel>=0 && out_ci->ditherfamily==IW_DITHERFAMILY_ERRDIFF) {\n\t\tusing_errdiffdither = 1;\n\t\tfor(i=0;i<ctx->img2.width;i++) {\n\t\t\tfor(k=0;k<IW_DITHER_MAXROWS;k++) {\n\t\t\t\tctx->dither_errors[k][i] = 0.0;\n\t\t\t}\n\t\t}\n\t}\n\n\trs=&ctx->resize_settings[IW_DIMENSION_H];\n\n\t// If the resize context for this dimension already exists, we should be\n\t// able to reuse it. Otherwise, create a new one.\n\tif(!rs->rrctx) {\n\t\trs->rrctx = iwpvt_resize_rows_init(ctx,rs,int_ci->channeltype,\n\t\t\tnum_in_pix, num_out_pix);\n\t\tif(!rs->rrctx) goto done;\n\t}\n\n\tfor(j=0;j<ctx->intermed_canvas_height;j++) {\n\n\t\t// As needed, either copy the input pixels to a temp buffer (inpix, which\n\t\t// ctx->in_pix already points to), or point ctx->in_pix directly to the\n\t\t// intermediate data.\n\t\tif(is_alpha_channel) {\n\t\t\tfor(i=0;i<num_in_pix;i++) {\n\t\t\t\tinpix_tofree[i] = ctx->intermediate_alpha32[((size_t)j)*ctx->intermed_canvas_width+i];\n\t\t\t}\n\t\t}\n\t\telse {\n\t\t\tfor(i=0;i<num_in_pix;i++) {\n\t\t\t\tinpix_tofree[i] = ctx->intermediate32[((size_t)j)*ctx->intermed_canvas_width+i];\n\t\t\t}\n\t\t}\n\n\t\t// Resize ctx->in_pix to ctx->out_pix.\n\t\tiwpvt_resize_row_main(rs->rrctx,in_pix,out_pix);\n\n\t\tif(ctx->intclamp)\n\t\t\tclamp_output_samples(ctx,out_pix,num_out_pix);\n\n\t\t// If necessary, copy the resized samples to the final_alpha image\n\t\tif(is_alpha_channel && outpix_tofree && ctx->final_alpha32) {\n\t\t\tfor(i=0;i<num_out_pix;i++) {\n\t\t\t\tctx->final_alpha32[((size_t)j)*ctx->img2.width+i] = (iw_float32)outpix_tofree[i];\n\t\t\t}\n\t\t}\n\n\t\t// Now convert the out_pix and put them in the final image.\n\n\t\tif(output_channel == -1) {\n\t\t\t// No corresponding output channel.\n\t\t\t// (Presumably because this is an alpha channel that's being\n\t\t\t// removed because we're applying a background.)\n\t\t\tgoto here;\n\t\t}\n\n\t\tfor(z=0;z<ctx->img2.width;z++) {\n\t\t\t// For decent Floyd-Steinberg dithering, we need to process alternate\n\t\t\t// rows in reverse order.\n\t\t\tif(using_errdiffdither && (j%2))\n\t\t\t\ti=ctx->img2.width-1-z;\n\t\t\telse\n\t\t\t\ti=z;\n\n\t\t\ttmpsamp = out_pix[i];\n\n\t\t\tif(ctx->bkgd_checkerboard) {\n\t\t\t\talt_bkgd = (((ctx->bkgd_check_origin[IW_DIMENSION_H]+i)/ctx->bkgd_check_size)%2) !=\n\t\t\t\t\t(((ctx->bkgd_check_origin[IW_DIMENSION_V]+j)/ctx->bkgd_check_size)%2);\n\t\t\t}\n\n\t\t\tif(bkgd_has_transparency) {\n\t\t\t\ttmpbkgdalpha = alt_bkgd ? ctx->bkgd2alpha : ctx->bkgd1alpha;\n\t\t\t}\n\n\t\t\tif(int_ci->need_unassoc_alpha_processing) {\n\t\t\t\t// Convert color samples back to unassociated alpha.\n\t\t\t\talphasamp = ctx->final_alpha32[((size_t)j)*ctx->img2.width + i];\n\n\t\t\t\tif(alphasamp!=0.0) {\n\t\t\t\t\ttmpsamp /= alphasamp;\n\t\t\t\t}\n\n\t\t\t\tif(ctx->apply_bkgd && ctx->apply_bkgd_strategy==IW_BKGD_STRATEGY_LATE) {\n\t\t\t\t\t// Apply a background color (or checkerboard pattern).\n\t\t\t\t\tdouble bkcolor;\n\t\t\t\t\tbkcolor = alt_bkgd ? out_ci->bkgd2_color_lin : out_ci->bkgd1_color_lin;\n\n\t\t\t\t\tif(bkgd_has_transparency) {\n\t\t\t\t\t\ttmpsamp = tmpsamp*alphasamp + bkcolor*tmpbkgdalpha*(1.0-alphasamp);\n\t\t\t\t\t}\n\t\t\t\t\telse {\n\t\t\t\t\t\ttmpsamp = tmpsamp*alphasamp + bkcolor*(1.0-alphasamp);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\telse if(is_alpha_channel && bkgd_has_transparency) {\n\t\t\t\t// Composite the alpha of the foreground over the alpha of the background.\n\t\t\t\ttmpsamp = tmpsamp + tmpbkgdalpha*(1.0-tmpsamp);\n\t\t\t}\n\n\t\t\tif(ctx->img2.sampletype==IW_SAMPLETYPE_FLOATINGPOINT)\n\t\t\t\tput_sample_convert_from_linear_flt(ctx,tmpsamp,i,j,output_channel,out_csdescr);\n\t\t\telse\n\t\t\t\tput_sample_convert_from_linear(ctx,tmpsamp,i,j,output_channel,out_csdescr);\n\n\t\t}\n\n\t\tif(using_errdiffdither) {\n\t\t\t// Move \"next row\" error data to \"this row\", and clear the \"next row\".\n\t\t\t// TODO: Obviously, it would be more efficient to just swap pointers\n\t\t\t// to the rows.\n\t\t\tfor(i=0;i<ctx->img2.width;i++) {\n\t\t\t\t// Move data in all rows but the first row up one row.\n\t\t\t\tfor(k=0;k<IW_DITHER_MAXROWS-1;k++) {\n\t\t\t\t\tctx->dither_errors[k][i] = ctx->dither_errors[k+1][i];\n\t\t\t\t}\n\t\t\t\t// Clear the last row.\n\t\t\t\tctx->dither_errors[IW_DITHER_MAXROWS-1][i] = 0.0;\n\t\t\t}\n\t\t}\n\nhere:\n\t\t;\n\t}\n\n\tretval=1;\n\ndone:\n\tif(rs && rs->disable_rrctx_cache && rs->rrctx) {\n\t\t// In some cases, the channels may need different resize contexts.\n\t\t// Delete the current context, so that it doesn't get reused.\n\t\tiwpvt_resize_rows_done(rs->rrctx);\n\t\trs->rrctx = NULL;\n\t}\n\tif(inpix_tofree) iw_free(ctx,inpix_tofree);\n\tif(outpix_tofree) iw_free(ctx,outpix_tofree);\n\n\treturn retval;\n}\n\nstatic int iw_process_one_channel(struct iw_context *ctx, int intermed_channel,\n  const struct iw_csdescr *in_csdescr, const struct iw_csdescr *out_csdescr)\n{\n\tif(!iw_process_cols_to_intermediate(ctx,intermed_channel,in_csdescr)) {\n\t\treturn 0;\n\t}\n\n\tif(!iw_process_rows_intermediate_to_final(ctx,intermed_channel,out_csdescr)) {\n\t\treturn 0;\n\t}\n\n\treturn 1;\n}\n\n// Potentially make a lookup table for color correction.\nstatic void iw_make_x_to_linear_table(struct iw_context *ctx, double **ptable,\n\tconst struct iw_image *img, const struct iw_csdescr *csdescr)\n{\n\tint ncolors;\n\tint i;\n\tdouble *tbl;\n\n\tif(csdescr->cstype==IW_CSTYPE_LINEAR) return;\n\n\tncolors = (1 << img->bit_depth);\n\tif(ncolors>256) return;\n\n\t// Don't make a table if the image is really small.\n\tif( ((size_t)img->width)*img->height <= 512 ) return;\n\n\ttbl = iw_malloc(ctx,ncolors*sizeof(double));\n\tif(!tbl) return;\n\n\tfor(i=0;i<ncolors;i++) {\n\t\ttbl[i] = x_to_linear_sample(((double)i)/(ncolors-1), csdescr);\n\t}\n\n\t*ptable = tbl;\n}\n\nstatic void iw_make_nearest_color_table(struct iw_context *ctx, double **ptable,\n\tconst struct iw_image *img, const struct iw_csdescr *csdescr)\n{\n\tint ncolors;\n\tint nentries;\n\tint i;\n\tdouble *tbl;\n\tdouble prev;\n\tdouble curr;\n\n\tif(ctx->no_gamma) return;\n\tif(csdescr->cstype==IW_CSTYPE_LINEAR) return;\n\tif(img->sampletype==IW_SAMPLETYPE_FLOATINGPOINT) return;\n\tif(img->bit_depth != ctx->img2.bit_depth) return;\n\n\tncolors = (1 << img->bit_depth);\n\tif(ncolors>256) return;\n\tnentries = ncolors-1;\n\n\t// Don't make a table if the image is really small.\n\tif( ((size_t)img->width)*img->height <= 512 ) return;\n\n\ttbl = iw_malloc(ctx,nentries*sizeof(double));\n\tif(!tbl) return;\n\n\t// Table stores the maximum value for the given entry.\n\t// The final entry is omitted, since there is no maximum value.\n\tprev = 0.0;\n\tfor(i=0;i<nentries;i++) {\n\t\t// This conversion may appear to be going in the wrong direction\n\t\t// (we're coverting *from* linear), but it's correct because we will\n\t\t// search through its contents to find the corresponding index,\n\t\t// instead of vice versa.\n\t\tcurr = x_to_linear_sample( ((double)(i+1))/(ncolors-1), csdescr);\n\t\ttbl[i] = (prev + curr)/2.0;\n\t\tprev = curr;\n\t}\n\n\t*ptable = tbl;\n}\n\n// Label is returned in linear colorspace.\n// Returns 0 if no label available.\nstatic int get_output_bkgd_label_lin(struct iw_context *ctx, struct iw_color *clr)\n{\n\tclr->c[0] = 1.0; clr->c[1] = 0.0; clr->c[2] = 1.0; clr->c[3] = 1.0;\n\n\tif(ctx->req.suppress_output_bkgd_label) return 0;\n\n\tif(ctx->req.output_bkgd_label_valid) {\n\t\t*clr = ctx->req.output_bkgd_label;\n\t\treturn 1;\n\t}\n\n\t// If the user didn't specify a label, but the input file had one, copy the\n\t// input file's label.\n\tif(ctx->img1_bkgd_label_set) {\n\t\t*clr = ctx->img1_bkgd_label_lin;\n\t\treturn 1;\n\t}\n\n\treturn 0;\n}\n\nstatic unsigned int iw_scale_to_int(double s, unsigned int maxcolor)\n{\n\tif(s<=0.0) return 0;\n\tif(s>=1.0) return maxcolor;\n\treturn (unsigned int)(0.5+s*maxcolor);\n}\n\n// Quantize the background color label, and store in ctx->img2.bkgdlabel.\n// Also convert it to grayscale if needed.\nstatic void iw_process_bkgd_label(struct iw_context *ctx)\n{\n\tint ret;\n\tint k;\n\tstruct iw_color clr;\n\tdouble maxcolor;\n\tunsigned int tmpu;\n\n\tif(!(ctx->output_profile&IW_PROFILE_PNG_BKGD) &&\n\t\t!(ctx->output_profile&IW_PROFILE_RGB8_BKGD) &&\n\t\t!(ctx->output_profile&IW_PROFILE_RGB16_BKGD))\n\t{\n\t\treturn;\n\t}\n\n\tret = get_output_bkgd_label_lin(ctx,&clr);\n\tif(!ret) return;\n\n\tif(ctx->to_grayscale) {\n\t\tiw_tmpsample g;\n\t\tg = iw_color_to_grayscale(ctx, clr.c[0], clr.c[1], clr.c[2]);\n\t\tclr.c[0] = clr.c[1] = clr.c[2] = g;\n\t}\n\n\tif(ctx->output_profile&IW_PROFILE_RGB8_BKGD) {\n\t\tmaxcolor=255.0;\n\t}\n\telse if(ctx->output_profile&IW_PROFILE_RGB16_BKGD) {\n\t\tmaxcolor=65535.0;\n\t}\n\telse if(ctx->img2.bit_depth==8) {\n\t\tmaxcolor=255.0;\n\t}\n\telse if(ctx->img2.bit_depth==16) {\n\t\tmaxcolor=65535.0;\n\t}\n\telse {\n\t\treturn;\n\t}\n\n\t// Although the bkgd label is stored as floating point, we're responsible for\n\t// making sure that, when scaled and rounded to a format suitable for the output\n\t// format, it will be the correct color.\n\tfor(k=0;k<3;k++) {\n\t\ttmpu = calc_sample_convert_from_linear(ctx, clr.c[k], &ctx->img2cs, maxcolor);\n\t\tctx->img2.bkgdlabel.c[k] = ((double)tmpu)/maxcolor;\n\t}\n\t// Alpha sample\n\ttmpu = iw_scale_to_int(clr.c[3],(unsigned int)maxcolor);\n\tctx->img2.bkgdlabel.c[3] = ((double)tmpu)/maxcolor;\n\n\tctx->img2.has_bkgdlabel = 1;\n}\n\nstatic void negate_target_image(struct iw_context *ctx)\n{\n\tint channel;\n\tstruct iw_channelinfo_out *ci;\n\tint i,j;\n\tsize_t pos;\n\tiw_float32 s;\n\tunsigned int n;\n\n\tfor(channel=0; channel<ctx->img2_numchannels; channel++) {\n\t\tci = &ctx->img2_ci[channel];\n\t\tif(ci->channeltype == IW_CHANNELTYPE_ALPHA) continue; // Don't negate alpha channels\n\n\t\tif(ctx->img2.sampletype==IW_SAMPLETYPE_FLOATINGPOINT) {\n\t\t\tfor(j=0; j<ctx->img2.height; j++) {\n\t\t\t\tfor(i=0; i<ctx->img2.width; i++) {\n\t\t\t\t\tpos = j*ctx->img2.bpr + ctx->img2_numchannels*i*4 + channel*4;\n\t\t\t\t\ts = iw_get_float32(&ctx->img2.pixels[pos]);\n\t\t\t\t\tiw_put_float32(&ctx->img2.pixels[pos], ((iw_float32)1.0)-s);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\telse if(ctx->img2.bit_depth==8) {\n\t\t\tfor(j=0; j<ctx->img2.height; j++) {\n\t\t\t\tfor(i=0; i<ctx->img2.width; i++) {\n\t\t\t\t\tpos = j*ctx->img2.bpr + ctx->img2_numchannels*i + channel;\n\t\t\t\t\tctx->img2.pixels[pos] = ci->maxcolorcode_int-ctx->img2.pixels[pos];\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\telse if(ctx->img2.bit_depth==16) {\n\t\t\tfor(j=0; j<ctx->img2.height; j++) {\n\t\t\t\tfor(i=0; i<ctx->img2.width; i++) {\n\t\t\t\t\tpos = j*ctx->img2.bpr + ctx->img2_numchannels*i*2 + channel*2;\n\t\t\t\t\tn = ctx->img2.pixels[pos]*256 + ctx->img2.pixels[pos+1];\n\t\t\t\t\tn = ci->maxcolorcode_int - n;\n\t\t\t\t\tctx->img2.pixels[pos] = (n&0xff00)>>8;\n\t\t\t\t\tctx->img2.pixels[pos+1] = n&0x00ff;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n}\n\nstatic int iw_process_internal(struct iw_context *ctx)\n{\n\tint channel;\n\tint retval=0;\n\tint i,k;\n\tint ret;\n\t// A linear color-correction descriptor to use with alpha channels.\n\tstruct iw_csdescr csdescr_linear;\n\n\tctx->intermediate32=NULL;\n\tctx->intermediate_alpha32=NULL;\n\tctx->final_alpha32=NULL;\n\tctx->intermed_canvas_width = ctx->input_w;\n\tctx->intermed_canvas_height = ctx->img2.height;\n\n\tiw_make_linear_csdescr(&csdescr_linear);\n\n\tctx->img2.bpr = iw_calc_bytesperrow(ctx->img2.width,ctx->img2.bit_depth*ctx->img2_numchannels);\n\n\tctx->img2.pixels = iw_malloc_large(ctx, ctx->img2.bpr, ctx->img2.height);\n\tif(!ctx->img2.pixels) {\n\t\tgoto done;\n\t}\n\n\tctx->intermediate32 = (iw_float32*)iw_malloc_large(ctx, ctx->intermed_canvas_width * ctx->intermed_canvas_height, sizeof(iw_float32));\n\tif(!ctx->intermediate32) {\n\t\tgoto done;\n\t}\n\n\tif(ctx->uses_errdiffdither) {\n\t\tfor(k=0;k<IW_DITHER_MAXROWS;k++) {\n\t\t\tctx->dither_errors[k] = (double*)iw_malloc(ctx, ctx->img2.width * sizeof(double));\n\t\t\tif(!ctx->dither_errors[k]) goto done;\n\t\t}\n\t}\n\n\tif(!ctx->disable_output_lookup_tables) {\n\t\tiw_make_x_to_linear_table(ctx,&ctx->output_rev_color_corr_table,&ctx->img2,&ctx->img2cs);\n\n\t\tiw_make_nearest_color_table(ctx,&ctx->nearest_color_table,&ctx->img2,&ctx->img2cs);\n\t}\n\n\t// If an alpha channel is present, we have to process it first.\n\tif(IW_IMGTYPE_HAS_ALPHA(ctx->intermed_imgtype)) {\n\t\tctx->intermediate_alpha32 = (iw_float32*)iw_malloc_large(ctx, ctx->intermed_canvas_width * ctx->intermed_canvas_height, sizeof(iw_float32));\n\t\tif(!ctx->intermediate_alpha32) {\n\t\t\tgoto done;\n\t\t}\n\t\tctx->final_alpha32 = (iw_float32*)iw_malloc_large(ctx, ctx->img2.width * ctx->img2.height, sizeof(iw_float32));\n\t\tif(!ctx->final_alpha32) {\n\t\t\tgoto done;\n\t\t}\n\n\t\tif(!iw_process_one_channel(ctx,ctx->intermed_alpha_channel_index,&csdescr_linear,&csdescr_linear)) goto done;\n\t}\n\n\t// Process the non-alpha channels.\n\n\tfor(channel=0;channel<ctx->intermed_numchannels;channel++) {\n\t\tif(ctx->intermed_ci[channel].channeltype!=IW_CHANNELTYPE_ALPHA) {\n\t\t\tif(ctx->no_gamma)\n\t\t\t\tret=iw_process_one_channel(ctx,channel,&csdescr_linear,&csdescr_linear);\n\t\t\telse\n\t\t\t\tret=iw_process_one_channel(ctx,channel,&ctx->img1cs,&ctx->img2cs);\n\n\t\t\tif(!ret) goto done;\n\t\t}\n\t}\n\n\tiw_process_bkgd_label(ctx);\n\n\tif(ctx->req.negate_target) {\n\t\tnegate_target_image(ctx);\n\t}\n\n\tretval=1;\n\ndone:\n\tif(ctx->intermediate32) { iw_free(ctx,ctx->intermediate32); ctx->intermediate32=NULL; }\n\tif(ctx->intermediate_alpha32) { iw_free(ctx,ctx->intermediate_alpha32); ctx->intermediate_alpha32=NULL; }\n\tif(ctx->final_alpha32) { iw_free(ctx,ctx->final_alpha32); ctx->final_alpha32=NULL; }\n\tfor(k=0;k<IW_DITHER_MAXROWS;k++) {\n\t\tif(ctx->dither_errors[k]) { iw_free(ctx,ctx->dither_errors[k]); ctx->dither_errors[k]=NULL; }\n\t}\n\t// The 'resize contexts' are usually kept around so that they can be reused.\n\t// Now that we're done with everything, free them.\n\tfor(i=0;i<2;i++) { // horizontal, vertical\n\t\tif(ctx->resize_settings[i].rrctx) {\n\t\t\tiwpvt_resize_rows_done(ctx->resize_settings[i].rrctx);\n\t\t\tctx->resize_settings[i].rrctx = NULL;\n\t\t}\n\t}\n\treturn retval;\n}\n\nstatic int iw_get_channeltype(int imgtype, int channel)\n{\n\tswitch(imgtype) {\n\tcase IW_IMGTYPE_GRAY:\n\t\tif(channel==0) return IW_CHANNELTYPE_GRAY;\n\t\tbreak;\n\tcase IW_IMGTYPE_GRAYA:\n\t\tif(channel==0) return IW_CHANNELTYPE_GRAY;\n\t\tif(channel==1) return IW_CHANNELTYPE_ALPHA;\n\t\tbreak;\n\tcase IW_IMGTYPE_RGB:\n\t\tif(channel==0) return IW_CHANNELTYPE_RED;\n\t\tif(channel==1) return IW_CHANNELTYPE_GREEN;\n\t\tif(channel==2) return IW_CHANNELTYPE_BLUE;\n\t\tbreak;\n\tcase IW_IMGTYPE_RGBA:\n\t\tif(channel==0) return IW_CHANNELTYPE_RED;\n\t\tif(channel==1) return IW_CHANNELTYPE_GREEN;\n\t\tif(channel==2) return IW_CHANNELTYPE_BLUE;\n\t\tif(channel==3) return IW_CHANNELTYPE_ALPHA;\n\t\tbreak;\n\t}\n\treturn 0;\n}\n\nstatic void iw_set_input_channeltypes(struct iw_context *ctx)\n{\n\tint i;\n\tfor(i=0;i<ctx->img1_numchannels_logical;i++) {\n\t\tctx->img1_ci[i].channeltype = iw_get_channeltype(ctx->img1_imgtype_logical,i);\n\t}\n}\n\nstatic void iw_set_intermed_channeltypes(struct iw_context *ctx)\n{\n\tint i;\n\tfor(i=0;i<ctx->intermed_numchannels;i++) {\n\t\tctx->intermed_ci[i].channeltype = iw_get_channeltype(ctx->intermed_imgtype,i);\n\t}\n}\n\nstatic void iw_set_out_channeltypes(struct iw_context *ctx)\n{\n\tint i;\n\tfor(i=0;i<ctx->img2_numchannels;i++) {\n\t\tctx->img2_ci[i].channeltype = iw_get_channeltype(ctx->img2.imgtype,i);\n\t}\n}\n\n// Set img2.bit_depth based on output_depth_req, etc.\n// Set img2.sampletype.\nstatic void decide_output_bit_depth(struct iw_context *ctx)\n{\n\tif(ctx->output_profile&IW_PROFILE_HDRI) {\n\t\tctx->img2.sampletype=IW_SAMPLETYPE_FLOATINGPOINT;\n\t}\n\telse {\n\t\tctx->img2.sampletype=IW_SAMPLETYPE_UINT;\n\t}\n\n\tif(ctx->img2.sampletype==IW_SAMPLETYPE_FLOATINGPOINT) {\n\t\t// Floating point output.\n\t\tctx->img2.bit_depth=32;\n\t\treturn;\n\t}\n\n\t// Below this point, sample type is UINT.\n\n\tif(ctx->req.output_depth>8 && (ctx->output_profile&IW_PROFILE_16BPS)) {\n\t\tctx->img2.bit_depth=16;\n\t}\n\telse {\n\t\tif(ctx->req.output_depth>8) {\n\t\t\t// Caller requested a depth higher than this format can handle.\n\t\t\tiw_warning(ctx,\"Reducing depth to 8; required by the output format.\");\n\t\t}\n\t\tctx->img2.bit_depth=8;\n\t}\n}\n\n// Set the background color samples that will be used when processing the\n// image. (All the logic about how to apply a background color is in\n// decide_how_to_apply_bkgd(), not here.)\nstatic void prepare_apply_bkgd(struct iw_context *ctx)\n{\n\tstruct iw_color bkgd1; // Main background color in linear colorspace\n\tstruct iw_color bkgd2; // Secondary background color ...\n\tint i;\n\n\tif(!ctx->apply_bkgd) return;\n\n\t// Start with a default background color.\n\tbkgd1.c[0]=1.0; bkgd1.c[1]=0.0; bkgd1.c[2]=1.0; bkgd1.c[3]=1.0;\n\tbkgd2.c[0]=0.0; bkgd2.c[1]=0.0; bkgd2.c[2]=0.0; bkgd2.c[3]=1.0;\n\n\t// Possibly overwrite it with the background color from the appropriate\n\t// source.\n\tif(ctx->bkgd_color_source == IW_BKGD_COLOR_SOURCE_FILE) {\n\t\tbkgd1 = ctx->img1_bkgd_label_lin; // sructure copy\n\t\tctx->bkgd_checkerboard = 0;\n\t}\n\telse if(ctx->bkgd_color_source == IW_BKGD_COLOR_SOURCE_REQ) {\n\t\tbkgd1 = ctx->req.bkgd;\n\t\tif(ctx->req.bkgd_checkerboard) {\n\t\t\tbkgd2 = ctx->req.bkgd2;\n\t\t}\n\t}\n\n\t// Set up the channelinfo (and ctx->bkgd*alpha) as needed according to the\n\t// target image type, and whether we are applying the background before or\n\t// after resizing.\n\n\tif(ctx->apply_bkgd_strategy==IW_BKGD_STRATEGY_EARLY) {\n\t\tctx->bkgd1alpha = 1.0;\n\t}\n\telse {\n\t\tctx->bkgd1alpha = bkgd1.c[3];\n\t\tctx->bkgd2alpha = bkgd2.c[3];\n\t}\n\n\tif(ctx->apply_bkgd_strategy==IW_BKGD_STRATEGY_LATE && (ctx->img2.imgtype==IW_IMGTYPE_RGB ||\n\t\tctx->img2.imgtype==IW_IMGTYPE_RGBA))\n\t{\n\t\tfor(i=0;i<3;i++) {\n\t\t\tctx->img2_ci[i].bkgd1_color_lin = bkgd1.c[i];\n\t\t}\n\t\tif(ctx->bkgd_checkerboard) {\n\t\t\tfor(i=0;i<3;i++) {\n\t\t\t\tctx->img2_ci[i].bkgd2_color_lin = bkgd2.c[i];\n\t\t\t}\n\t\t}\n\t}\n\telse if(ctx->apply_bkgd_strategy==IW_BKGD_STRATEGY_LATE && (ctx->img2.imgtype==IW_IMGTYPE_GRAY ||\n\t\tctx->img2.imgtype==IW_IMGTYPE_GRAYA))\n\t{\n\t\tctx->img2_ci[0].bkgd1_color_lin = iw_color_to_grayscale(ctx,bkgd1.c[0],bkgd1.c[1],bkgd1.c[2]);\n\t\tif(ctx->bkgd_checkerboard) {\n\t\t\tctx->img2_ci[0].bkgd2_color_lin = iw_color_to_grayscale(ctx,bkgd2.c[0],bkgd2.c[1],bkgd2.c[2]);\n\t\t}\n\t}\n\telse if(ctx->apply_bkgd_strategy==IW_BKGD_STRATEGY_EARLY && ctx->img2.imgtype==IW_IMGTYPE_RGB) {\n\t\tfor(i=0;i<3;i++) {\n\t\t\tctx->intermed_ci[i].bkgd_color_lin = bkgd1.c[i];\n\t\t}\n\t}\n\telse if(ctx->apply_bkgd_strategy==IW_BKGD_STRATEGY_EARLY && ctx->img2.imgtype==IW_IMGTYPE_GRAY) {\n\t\tctx->intermed_ci[0].bkgd_color_lin = iw_color_to_grayscale(ctx,bkgd1.c[0],bkgd1.c[1],bkgd1.c[2]);\n\t}\n}\n\n#define IW_STRAT1_G_G       0x011 // -grayscale\n#define IW_STRAT1_G_RGB     0x013 // default\n#define IW_STRAT1_GA_G      0x021 // -grayscale, BKGD_STRATEGY_EARLY (never happens?)\n#define IW_STRAT1_GA_GA     0x022 // -grayscale\n#define IW_STRAT1_GA_RGB    0x023 // BKGD_STRATEGY_EARLY\n#define IW_STRAT1_GA_RGBA   0x024 // default\n#define IW_STRAT1_RGB_G     0x031 // -grayscale\n#define IW_STRAT1_RGB_RGB   0x033 // default\n#define IW_STRAT1_RGBA_G    0x041 // -grayscale, BKGD_STRATEGY_EARLY (never happens?)\n#define IW_STRAT1_RGBA_GA   0x042 // -grayscale\n#define IW_STRAT1_RGBA_RGB  0x043 // BKGD_STRATEGY_EARLY\n#define IW_STRAT1_RGBA_RGBA 0x044 // default\n\n#define IW_STRAT2_G_G       0x111 // -grayscale\n#define IW_STRAT2_GA_G      0x121 // -grayscale, BKGD_STRATEGY_LATE\n#define IW_STRAT2_GA_GA     0x122 // -grayscale\n#define IW_STRAT2_RGB_RGB   0x133 // default\n#define IW_STRAT2_RGBA_RGB  0x143 // BKGD_STRATEGY_LATE\n#define IW_STRAT2_RGBA_RGBA 0x144 // default\n\n\nstatic void iw_restrict_to_range(int r1, int r2, int *pvar)\n{\n\tif(*pvar < r1) *pvar = r1;\n\telse if(*pvar > r2) *pvar = r2;\n}\n\nstatic void decide_strategy(struct iw_context *ctx, int *ps1, int *ps2)\n{\n\tint s1, s2;\n\n\t// Start with a default strategy\n\tswitch(ctx->img1_imgtype_logical) {\n\tcase IW_IMGTYPE_RGBA:\n\t\tif(ctx->to_grayscale) {\n\t\t\ts1=IW_STRAT1_RGBA_GA;\n\t\t\ts2=IW_STRAT2_GA_GA;\n\t\t}\n\t\telse {\n\t\t\ts1=IW_STRAT1_RGBA_RGBA;\n\t\t\ts2=IW_STRAT2_RGBA_RGBA;\n\t\t}\n\t\tbreak;\n\tcase IW_IMGTYPE_RGB:\n\t\tif(ctx->to_grayscale) {\n\t\t\ts1=IW_STRAT1_RGB_G;\n\t\t\ts2=IW_STRAT2_G_G;\n\t\t}\n\t\telse {\n\t\t\ts1=IW_STRAT1_RGB_RGB;\n\t\t\ts2=IW_STRAT2_RGB_RGB;\n\t\t}\n\t\tbreak;\n\tcase IW_IMGTYPE_GRAYA:\n\t\tif(ctx->to_grayscale) {\n\t\t\ts1=IW_STRAT1_GA_GA;\n\t\t\ts2=IW_STRAT2_GA_GA;\n\t\t}\n\t\telse {\n\t\t\ts1=IW_STRAT1_GA_RGBA;\n\t\t\ts2=IW_STRAT2_RGBA_RGBA;\n\t\t}\n\t\tbreak;\n\tdefault:\n\t\tif(ctx->to_grayscale) {\n\t\t\ts1=IW_STRAT1_G_G;\n\t\t\ts2=IW_STRAT2_G_G;\n\t\t}\n\t\telse {\n\t\t\ts1=IW_STRAT1_G_RGB;\n\t\t\ts2=IW_STRAT2_RGB_RGB;\n\t\t}\n\t}\n\n\tif(ctx->apply_bkgd && ctx->apply_bkgd_strategy==IW_BKGD_STRATEGY_EARLY) {\n\t\t// Applying background before resizing\n\t\tif(s1==IW_STRAT1_RGBA_RGBA) {\n\t\t\ts1=IW_STRAT1_RGBA_RGB;\n\t\t\ts2=IW_STRAT2_RGB_RGB;\n\t\t}\n\t\telse if(s1==IW_STRAT1_GA_GA) {\n\t\t\ts1=IW_STRAT1_GA_G;\n\t\t\ts2=IW_STRAT2_G_G;\n\t\t}\n\t\telse if(s1==IW_STRAT1_GA_RGBA) {\n\t\t\ts1=IW_STRAT1_GA_RGB;\n\t\t\ts2=IW_STRAT2_RGB_RGB;\n\t\t}\n\t\telse if(s1==IW_STRAT1_RGBA_GA) {\n\t\t\ts1=IW_STRAT1_RGBA_G;\n\t\t\ts2=IW_STRAT2_G_G;\n\t\t}\n\t}\n\n\tif(ctx->apply_bkgd && !iw_bkgd_has_transparency(ctx)) {\n\t\tif(s2==IW_STRAT2_GA_GA) {\n\t\t\ts2=IW_STRAT2_GA_G;\n\t\t}\n\t\telse if(s2==IW_STRAT2_RGBA_RGBA) {\n\t\t\ts2=IW_STRAT2_RGBA_RGB;\n\t\t}\n\t}\n\n\t*ps1 = s1;\n\t*ps2 = s2;\n}\n\n// Choose our strategy for applying a background to the image.\n// Uses:\n//   - ctx->img1_imgtype_logical (set by init_channel_info())\n//   - ctx->req.bkgd_valid (was background set by caller?)\n//   - ctx->req.bkgd_checkerboard (set by caller)\n//   - ctx->bkgd_check_size (set by caller)\n//   - ctx->resize_settings[d].use_offset\n// Sets:\n//   - ctx->apply_bkgd (flag indicating whether we'll apply a background)\n//   - ctx->apply_bkgd_strategy (flag indicating *when* we'll apply a background)\n//   - ctx->bkgd_color_source (where to get the background color)\n//   - ctx->bkgd_checkerboard\n//   - ctx->bkgd_check_size (sanitized)\n// May emit a warning if the caller's settings can't be honored.\nstatic void decide_how_to_apply_bkgd(struct iw_context *ctx)\n{\n\tif(!IW_IMGTYPE_HAS_ALPHA(ctx->img1_imgtype_logical)) {\n\t\t// If we know the image does not have any transparency,\n\t\t// we don't have to do anything.\n\t\tctx->apply_bkgd=0;\n\t\treturn;\n\t}\n\n\t// Figure out where to get the background color from, on the assumption\n\t// that we'll use one.\n\tif(ctx->img1_bkgd_label_set &&\n\t\t(ctx->req.use_bkgd_label_from_file || !ctx->req.bkgd_valid))\n\t{\n\t\t// The input file has a background color label, and either we are\n\t\t// requested to prefer it to the caller's background color, or\n\t\t// the caller did not give us a background color.\n\t\t// Use the color from the input file.\n\t\tctx->bkgd_color_source = IW_BKGD_COLOR_SOURCE_FILE;\n\t}\n\telse if(ctx->req.bkgd_valid) {\n\t\t// Use the background color given by the caller.\n\t\tctx->bkgd_color_source = IW_BKGD_COLOR_SOURCE_REQ;\n\t\t// Tentatively use the caller's checkerboard setting.\n\t\t// This may be overridden if we can't support checkerboard backgrounds\n\t\t// for some reason.\n\t\tctx->bkgd_checkerboard = ctx->req.bkgd_checkerboard;\n\t}\n\telse {\n\t\t// No background color available. If we need one, we'll have to invent one.\n\t\tctx->bkgd_color_source = IW_BKGD_COLOR_SOURCE_NONE;\n\t}\n\n\tif(ctx->bkgd_checkerboard) {\n\t\tif(ctx->bkgd_check_size<1) ctx->bkgd_check_size=1;\n\t}\n\n\tif(ctx->req.bkgd_valid) {\n\t\t// Caller told us to apply a background.\n\t\tctx->apply_bkgd=1;\n\t}\n\n\tif(!(ctx->output_profile&IW_PROFILE_TRANSPARENCY)) {\n\t\tif(!ctx->req.bkgd_valid && !ctx->apply_bkgd) {\n\t\t\tiw_warning(ctx,\"This image may have transparency, which is incompatible with the output format. A background color will be applied.\");\n\t\t}\n\t\tctx->apply_bkgd=1;\n\t}\n\n\tif(ctx->resize_settings[IW_DIMENSION_H].use_offset ||\n\t\tctx->resize_settings[IW_DIMENSION_V].use_offset)\n\t{\n\t\t// If channel offset is enabled, and the image has transparency, we\n\t\t// must apply a solid color background (and we must apply it before\n\t\t// resizing), regardless of whether the user asked for it. It's the\n\t\t// only strategy we support.\n\t\tif(!ctx->req.bkgd_valid && !ctx->apply_bkgd) {\n\t\t\tiw_warning(ctx,\"This image may have transparency, which is incompatible with a channel offset. A background color will be applied.\");\n\t\t}\n\t\tctx->apply_bkgd=1;\n\n\t\tif(ctx->bkgd_checkerboard && ctx->req.bkgd_checkerboard) {\n\t\t\tiw_warning(ctx,\"Checkerboard backgrounds are not supported when using a channel offset.\");\n\t\t\tctx->bkgd_checkerboard=0;\n\t\t}\n\t\tctx->apply_bkgd_strategy=IW_BKGD_STRATEGY_EARLY;\n\t\treturn;\n\t}\n\n\tif(!ctx->apply_bkgd) {\n\t\t// No reason to apply a background color.\n\t\treturn;\n\t}\n\n\tif(ctx->bkgd_checkerboard) {\n\t\t// Non-solid-color backgrounds must be applied after resizing.\n\t\tctx->apply_bkgd_strategy=IW_BKGD_STRATEGY_LATE;\n\t\treturn;\n\t}\n\n\t// At this point, either Early or Late background application is possible,\n\t// and (I think) would, in an idealized situation, yield the same result.\n\t// Things that can cause it to be different include\n\t// * using a different resampling algorithm for the alpha channel (this is\n\t//   no longer supported)\n\t// * 'intermediate clamping'\n\t//\n\t// Setting this to Late is the safe, though it is slower than Early.\n\tctx->apply_bkgd_strategy=IW_BKGD_STRATEGY_LATE;\n}\n\nstatic void iw_set_auto_resizetype(struct iw_context *ctx, int size1, int size2,\n\tint dimension)\n{\n\t// If not changing the size, default to \"null\" resize if we can.\n\t// (We can't do that if using a translation or channel offset.)\n\tif(size2==size1 && !ctx->resize_settings[dimension].use_offset &&\n\t\t!ctx->req.out_true_valid &&\n\t\tctx->resize_settings[dimension].translate==0.0)\n\t{\n\t\tiw_set_resize_alg(ctx, dimension, IW_RESIZETYPE_NULL, 1.0, 0.0, 0.0);\n\t\treturn;\n\t}\n\n\t// Otherwise, default to Catmull-Rom\n\tiw_set_resize_alg(ctx, dimension, IW_RESIZETYPE_CUBIC, 1.0, 0.0, 0.5);\n}\n\nstatic void init_channel_info(struct iw_context *ctx)\n{\n\tint i;\n\n\tctx->img1_imgtype_logical = ctx->img1.imgtype;\n\n\tif(ctx->resize_settings[IW_DIMENSION_H].edge_policy==IW_EDGE_POLICY_TRANSPARENT ||\n\t\tctx->resize_settings[IW_DIMENSION_V].edge_policy==IW_EDGE_POLICY_TRANSPARENT)\n\t{\n\t\t// Add a virtual alpha channel\n\t\tif(ctx->img1.imgtype==IW_IMGTYPE_GRAY) {\n\t\t\tctx->img1_imgtype_logical = IW_IMGTYPE_GRAYA;\n\t\t}\n\t\telse if(ctx->img1.imgtype==IW_IMGTYPE_RGB)\n\t\t\tctx->img1_imgtype_logical = IW_IMGTYPE_RGBA;\n\t}\n\n\tctx->img1_numchannels_physical = iw_imgtype_num_channels(ctx->img1.imgtype);\n\tctx->img1_numchannels_logical = iw_imgtype_num_channels(ctx->img1_imgtype_logical);\n\tctx->img1_alpha_channel_index = iw_imgtype_alpha_channel_index(ctx->img1_imgtype_logical);\n\n\tiw_set_input_channeltypes(ctx);\n\n\tctx->img2.imgtype = ctx->img1_imgtype_logical; // default\n\tctx->img2_numchannels = ctx->img1_numchannels_logical; // default\n\tctx->intermed_numchannels = ctx->img1_numchannels_logical; // default\n\n\tfor(i=0;i<ctx->img1_numchannels_logical;i++) {\n\t\tctx->intermed_ci[i].channeltype = ctx->img1_ci[i].channeltype;\n\t\tctx->intermed_ci[i].corresponding_input_channel = i;\n\t\tctx->img2_ci[i].channeltype = ctx->img1_ci[i].channeltype;\n\t\tif(i>=ctx->img1_numchannels_physical) {\n\t\t\t// This is a virtual channel, which is handled by get_raw_sample().\n\t\t\t// But some optimizations cause that function to be bypassed, so we\n\t\t\t// have to disable those optimizations.\n\t\t\tctx->img1_ci[i].disable_fast_get_sample = 1;\n\t\t}\n\t}\n}\n\n// Set the weights for the grayscale algorithm, if needed.\nstatic void prepare_grayscale(struct iw_context *ctx)\n{\n\tswitch(ctx->grayscale_formula) {\n\tcase IW_GSF_STANDARD:\n\t\tctx->grayscale_formula = IW_GSF_WEIGHTED;\n\t\tiw_set_grayscale_weights(ctx,0.212655,0.715158,0.072187);\n\t\tbreak;\n\tcase IW_GSF_COMPATIBLE:\n\t\tctx->grayscale_formula = IW_GSF_WEIGHTED;\n\t\tiw_set_grayscale_weights(ctx,0.299,0.587,0.114);\n\t\tbreak;\n\t}\n}\n\n// Set up some things before we do the resize, and check to make\n// sure everything looks okay.\nstatic int iw_prepare_processing(struct iw_context *ctx, int w, int h)\n{\n\tint i,j;\n\tint output_maxcolorcode_int;\n\tint strategy1, strategy2;\n\tint flag;\n\n\tif(ctx->output_profile==0) {\n\t\tiw_set_error(ctx,\"Output profile not set\");\n\t\treturn 0;\n\t}\n\n\tif(!ctx->prng) {\n\t\t// TODO: It would be better to only create the random number generator\n\t\t// if we will need it.\n\t\tctx->prng = iwpvt_prng_create(ctx);\n\t}\n\n\tif(ctx->randomize) {\n\t\t// Acquire and record a random seed. This also seeds the PRNG, but\n\t\t// that's irrelevant. It will be re-seeded before it is used.\n\t\tctx->random_seed = iwpvt_util_randomize(ctx->prng);\n\t}\n\n\tif(ctx->req.out_true_valid) {\n\t\tctx->resize_settings[IW_DIMENSION_H].out_true_size = ctx->req.out_true_width;\n\t\tctx->resize_settings[IW_DIMENSION_V].out_true_size = ctx->req.out_true_height;\n\t}\n\telse {\n\t\tctx->resize_settings[IW_DIMENSION_H].out_true_size = (double)w;\n\t\tctx->resize_settings[IW_DIMENSION_V].out_true_size = (double)h;\n\t}\n\n\tif(!iw_check_image_dimensions(ctx,ctx->img1.width,ctx->img1.height)) {\n\t\treturn 0;\n\t}\n\tif(!iw_check_image_dimensions(ctx,w,h)) {\n\t\treturn 0;\n\t}\n\n\tif(ctx->to_grayscale) {\n\t\tprepare_grayscale(ctx);\n\t}\n\n\tinit_channel_info(ctx);\n\n\tctx->img2.width = w;\n\tctx->img2.height = h;\n\n\t// Figure out the region of the source image to read from.\n\tif(ctx->input_start_x<0) ctx->input_start_x=0;\n\tif(ctx->input_start_y<0) ctx->input_start_y=0;\n\tif(ctx->input_start_x>ctx->img1.width-1) ctx->input_start_x=ctx->img1.width-1;\n\tif(ctx->input_start_y>ctx->img1.height-1) ctx->input_start_x=ctx->img1.height-1;\n\tif(ctx->input_w<0) ctx->input_w = ctx->img1.width - ctx->input_start_x;\n\tif(ctx->input_h<0) ctx->input_h = ctx->img1.height - ctx->input_start_y;\n\tif(ctx->input_w<1) ctx->input_w = 1;\n\tif(ctx->input_h<1) ctx->input_h = 1;\n\tif(ctx->input_w>(ctx->img1.width-ctx->input_start_x)) ctx->input_w=ctx->img1.width-ctx->input_start_x;\n\tif(ctx->input_h>(ctx->img1.height-ctx->input_start_y)) ctx->input_h=ctx->img1.height-ctx->input_start_y;\n\n\t// Decide on the output colorspace.\n\tif(ctx->req.output_cs_valid) {\n\t\t// Try to use colorspace requested by caller.\n\t\tctx->img2cs = ctx->req.output_cs;\n\n\t\tif(ctx->output_profile&IW_PROFILE_ALWAYSLINEAR) {\n\t\t\tif(ctx->img2cs.cstype!=IW_CSTYPE_LINEAR) {\n\t\t\t\tiw_warning(ctx,\"Forcing output colorspace to linear; required by the output format.\");\n\t\t\t\tiw_make_linear_csdescr(&ctx->img2cs);\n\t\t\t}\n\t\t}\n\t}\n\telse {\n\t\t// By default, set the output colorspace to sRGB in most cases.\n\t\tif(ctx->output_profile&IW_PROFILE_ALWAYSLINEAR) {\n\t\t\tiw_make_linear_csdescr(&ctx->img2cs);\n\t\t}\n\t\telse {\n\t\t\tiw_make_srgb_csdescr_2(&ctx->img2cs);\n\t\t}\n\t}\n\n\t// Make sure maxcolorcodes are set.\n\tif(ctx->img1.sampletype!=IW_SAMPLETYPE_FLOATINGPOINT) {\n\t\tctx->input_maxcolorcode_int = (1 << ctx->img1.bit_depth)-1;\n\t\tctx->input_maxcolorcode = (double)ctx->input_maxcolorcode_int;\n\n\t\tfor(i=0;i<IW_CI_COUNT;i++) {\n\t\t\tif(ctx->img1_ci[i].maxcolorcode_int<=0) {\n\t\t\t\tctx->img1_ci[i].maxcolorcode_int = ctx->input_maxcolorcode_int;\n\t\t\t}\n\t\t\tctx->img1_ci[i].maxcolorcode_dbl = (double)ctx->img1_ci[i].maxcolorcode_int;\n\n\t\t\tif(ctx->img1_ci[i].maxcolorcode_int != ctx->input_maxcolorcode_int) {\n\t\t\t\t// This is overzealous: We could enable it per-channel.\n\t\t\t\t// But it's probably not worth the trouble.\n\t\t\t\tctx->support_reduced_input_bitdepths = 1;\n\t\t\t}\n\t\t}\n\t}\n\n\tif(ctx->support_reduced_input_bitdepths ||\n\t\tctx->img1.sampletype==IW_SAMPLETYPE_FLOATINGPOINT)\n\t{\n\t\tfor(i=0;i<ctx->img1_numchannels_physical;i++) {\n\t\t\tctx->img1_ci[i].disable_fast_get_sample=1;\n\t\t}\n\t}\n\n\t// Set the .use_offset flags, based on whether the caller set any\n\t// .channel_offset[]s.\n\tfor(i=0;i<2;i++) { // horizontal, vertical\n\t\tfor(j=0;j<3;j++) { // red, green, blue\n\t\t\tif(fabs(ctx->resize_settings[i].channel_offset[j])>0.00001) {\n\t\t\t\tctx->resize_settings[i].use_offset=1;\n\t\t\t}\n\t\t}\n\t}\n\n\tif(ctx->to_grayscale &&\n\t\t(ctx->resize_settings[IW_DIMENSION_H].use_offset ||\n\t\tctx->resize_settings[IW_DIMENSION_V].use_offset) )\n\t{\n\t\tiw_warning(ctx,\"Disabling channel offset, due to grayscale output.\");\n\t\tctx->resize_settings[IW_DIMENSION_H].use_offset=0;\n\t\tctx->resize_settings[IW_DIMENSION_V].use_offset=0;\n\t}\n\n\tdecide_how_to_apply_bkgd(ctx);\n\n\t// Decide if we can cache the resize settings.\n\tfor(i=0;i<2;i++) {\n\t\tif(ctx->resize_settings[i].use_offset ||\n\t\t  (ctx->apply_bkgd &&\n\t\t   ctx->apply_bkgd_strategy==IW_BKGD_STRATEGY_EARLY &&\n\t\t   ctx->resize_settings[i].edge_policy==IW_EDGE_POLICY_TRANSPARENT))\n\t\t{\n\t\t\t// If a channel offset is used, we have to disable caching, because the\n\t\t\t// offset is stored in the cache, and it won't be the same for all channels.\n\t\t\t// If transparent virtual pixels will be converted to the background color\n\t\t\t// during the resize, we have to disable caching, because the background\n\t\t\t// sample value is stored in the cache, and it may be different for each\n\t\t\t// channel.\n\t\t\tctx->resize_settings[i].disable_rrctx_cache=1;\n\t\t}\n\t}\n\n\tdecide_strategy(ctx,&strategy1,&strategy2);\n\n\tswitch(strategy1) { // input-to-intermediate\n\tcase IW_STRAT1_RGBA_RGBA:\n\t\tctx->intermed_imgtype = IW_IMGTYPE_RGBA;\n\t\tbreak;\n\tcase IW_STRAT1_GA_RGBA:\n\t\tctx->intermed_imgtype = IW_IMGTYPE_RGBA;\n\t\tctx->intermed_ci[0].corresponding_input_channel=0;\n\t\tctx->intermed_ci[1].corresponding_input_channel=0;\n\t\tctx->intermed_ci[2].corresponding_input_channel=0;\n\t\tctx->intermed_ci[3].corresponding_input_channel=1;\n\t\tbreak;\n\tcase IW_STRAT1_RGB_RGB:\n\tcase IW_STRAT1_RGBA_RGB:\n\t\tctx->intermed_imgtype = IW_IMGTYPE_RGB;\n\t\tbreak;\n\tcase IW_STRAT1_G_RGB:\n\tcase IW_STRAT1_GA_RGB:\n\t\tctx->intermed_imgtype = IW_IMGTYPE_RGB;\n\t\tctx->intermed_ci[0].corresponding_input_channel=0;\n\t\tctx->intermed_ci[1].corresponding_input_channel=0;\n\t\tctx->intermed_ci[2].corresponding_input_channel=0;\n\t\tbreak;\n\tcase IW_STRAT1_RGBA_GA:\n\t\tctx->intermed_imgtype = IW_IMGTYPE_GRAYA;\n\t\tctx->intermed_ci[0].cvt_to_grayscale=1;\n\t\tctx->intermed_ci[0].corresponding_input_channel=0;\n\t\tctx->intermed_ci[1].corresponding_input_channel=3;\n\t\tbreak;\n\tcase IW_STRAT1_GA_GA:\n\t\tctx->intermed_imgtype = IW_IMGTYPE_GRAYA;\n\t\tbreak;\n\tcase IW_STRAT1_RGB_G:\n\t\tctx->intermed_imgtype = IW_IMGTYPE_GRAY;\n\t\tctx->intermed_ci[0].cvt_to_grayscale=1;\n\t\tctx->intermed_ci[0].corresponding_input_channel=0;\n\t\tbreak;\n\tcase IW_STRAT1_G_G:\n\t\tctx->intermed_imgtype = IW_IMGTYPE_GRAY;\n\t\tctx->intermed_ci[0].corresponding_input_channel=0;\n\t\tbreak;\n\tdefault:\n\t\tiw_set_errorf(ctx,\"Internal error, unknown strategy %d\",strategy1);\n\t\treturn 0;\n\t}\n\n\tctx->intermed_numchannels = iw_imgtype_num_channels(ctx->intermed_imgtype);\n\tctx->intermed_alpha_channel_index = iw_imgtype_alpha_channel_index(ctx->intermed_imgtype);\n\n\t// Start with default mapping:\n\tfor(i=0;i<ctx->intermed_numchannels;i++) {\n\t\tctx->intermed_ci[i].corresponding_output_channel = i;\n\t}\n\n\tswitch(strategy2) { // intermediate-to-output\n\tcase IW_STRAT2_RGBA_RGBA:\n\t\tctx->img2.imgtype = IW_IMGTYPE_RGBA;\n\t\tbreak;\n\tcase IW_STRAT2_RGB_RGB:\n\t\tctx->img2.imgtype = IW_IMGTYPE_RGB;\n\t\tbreak;\n\tcase IW_STRAT2_RGBA_RGB:\n\t\tctx->img2.imgtype = IW_IMGTYPE_RGB;\n\t\tctx->intermed_ci[3].corresponding_output_channel= -1;\n\t\tbreak;\n\tcase IW_STRAT2_GA_GA:\n\t\tctx->img2.imgtype = IW_IMGTYPE_GRAYA;\n\t\tbreak;\n\tcase IW_STRAT2_G_G:\n\t\tctx->img2.imgtype = IW_IMGTYPE_GRAY;\n\t\tbreak;\n\tcase IW_STRAT2_GA_G:\n\t\tctx->img2.imgtype = IW_IMGTYPE_GRAY;\n\t\tctx->intermed_ci[1].corresponding_output_channel= -1;\n\t\tbreak;\n\tdefault:\n\t\tiw_set_error(ctx,\"Internal error\");\n\t\treturn 0;\n\t}\n\n\tctx->img2_numchannels = iw_imgtype_num_channels(ctx->img2.imgtype);\n\n\tiw_set_intermed_channeltypes(ctx);\n\tiw_set_out_channeltypes(ctx);\n\n\t// If an alpha channel is present, set a flag on the other channels to indicate\n\t// that we have to process them differently.\n\tif(IW_IMGTYPE_HAS_ALPHA(ctx->intermed_imgtype)) {\n\t\tfor(i=0;i<ctx->intermed_numchannels;i++) {\n\t\t\tif(ctx->intermed_ci[i].channeltype!=IW_CHANNELTYPE_ALPHA)\n\t\t\t\tctx->intermed_ci[i].need_unassoc_alpha_processing = 1;\n\t\t}\n\t}\n\n\n\tdecide_output_bit_depth(ctx);\n\n\tif(ctx->img2.sampletype==IW_SAMPLETYPE_FLOATINGPOINT) {\n\t\tflag=0;\n\t\tfor(i=0;i<IW_NUM_CHANNELTYPES;i++) {\n\t\t\tif(ctx->req.color_count[i]) flag=1;\n\t\t}\n\t\tif(flag) {\n\t\t\tiw_warning(ctx,\"Posterization is not supported with floating point output.\");\n\t\t}\n\t}\n\telse {\n\t\toutput_maxcolorcode_int = (1 << ctx->img2.bit_depth)-1;\n\n\t\t// Set the default maxcolorcodes\n\t\tfor(i=0;i<ctx->img2_numchannels;i++) {\n\t\t\tctx->img2_ci[i].maxcolorcode_int = output_maxcolorcode_int;\n\t\t}\n\n\t\t// Check for special \"reduced\" colorcodes.\n\t\tif((ctx->output_profile&IW_PROFILE_REDUCEDBITDEPTHS)) {\n\t\t\tfor(i=0;i<ctx->img2_numchannels;i++) {\n\t\t\t\tint mccr;\n\t\t\t\tmccr = ctx->req.output_maxcolorcode[ctx->img2_ci[i].channeltype];\n\t\t\t\tif(mccr>0) {\n\t\t\t\t\tif(mccr>output_maxcolorcode_int) mccr=output_maxcolorcode_int;\n\t\t\t\t\tctx->img2_ci[i].maxcolorcode_int = mccr;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t// Set some flags, and set the floating-point versions of the maxcolorcodes.\n\t\tfor(i=0;i<ctx->img2_numchannels;i++) {\n\t\t\tif(ctx->img2_ci[i].maxcolorcode_int != output_maxcolorcode_int) {\n\t\t\t\tctx->reduced_output_maxcolor_flag = 1;\n\t\t\t\tctx->disable_output_lookup_tables = 1;\n\t\t\t}\n\n\t\t\tctx->img2_ci[i].maxcolorcode_dbl = (double)ctx->img2_ci[i].maxcolorcode_int;\n\t\t}\n\t}\n\n\tfor(i=0;i<ctx->img2_numchannels;i++) {\n\t\tctx->img2_ci[i].color_count = ctx->req.color_count[ctx->img2_ci[i].channeltype];\n\t\tif(ctx->img2_ci[i].color_count) {\n\t\t\tiw_restrict_to_range(2,ctx->img2_ci[i].maxcolorcode_int,&ctx->img2_ci[i].color_count);\n\t\t}\n\t\tif(ctx->img2_ci[i].color_count==1+ctx->img2_ci[i].maxcolorcode_int) {\n\t\t\tctx->img2_ci[i].color_count = 0;\n\t\t}\n\n\t\tctx->img2_ci[i].ditherfamily = ctx->ditherfamily_by_channeltype[ctx->img2_ci[i].channeltype];\n\t\tctx->img2_ci[i].dithersubtype = ctx->dithersubtype_by_channeltype[ctx->img2_ci[i].channeltype];\n\t}\n\n\t// Scan the output channels to see whether certain types of dithering are used.\n\tfor(i=0;i<ctx->img2_numchannels;i++) {\n\t\tif(ctx->img2_ci[i].ditherfamily==IW_DITHERFAMILY_ERRDIFF) {\n\t\t\tctx->uses_errdiffdither=1;\n\t\t}\n\t}\n\n\tif(!ctx->support_reduced_input_bitdepths && ctx->img1.sampletype==IW_SAMPLETYPE_UINT) {\n\t\tiw_make_x_to_linear_table(ctx,&ctx->input_color_corr_table,&ctx->img1,&ctx->img1cs);\n\t}\n\n\tif(ctx->img1_bkgd_label_set) {\n\t\t// Convert the background color to a linear colorspace.\n\t\tfor(i=0;i<3;i++) {\n\t\t\tctx->img1_bkgd_label_lin.c[i] = x_to_linear_sample(ctx->img1_bkgd_label_inputcs.c[i],&ctx->img1cs);\n\t\t}\n\t\tctx->img1_bkgd_label_lin.c[3] = ctx->img1_bkgd_label_inputcs.c[3];\n\t}\n\n\tif(ctx->apply_bkgd) {\n\t\tprepare_apply_bkgd(ctx);\n\t}\n\n\tif(ctx->req.output_rendering_intent==IW_INTENT_UNKNOWN) {\n\t\t// User didn't request a specific intent; copy from input file.\n\t\tctx->img2.rendering_intent = ctx->img1.rendering_intent;\n\t}\n\telse {\n\t\tctx->img2.rendering_intent = ctx->req.output_rendering_intent;\n\t}\n\n\tif(ctx->resize_settings[IW_DIMENSION_H].family==IW_RESIZETYPE_AUTO) {\n\t\tiw_set_auto_resizetype(ctx,ctx->input_w,ctx->img2.width,IW_DIMENSION_H);\n\t}\n\tif(ctx->resize_settings[IW_DIMENSION_V].family==IW_RESIZETYPE_AUTO) {\n\t\tiw_set_auto_resizetype(ctx,ctx->input_h,ctx->img2.height,IW_DIMENSION_V);\n\t}\n\n\tif(IW_IMGTYPE_HAS_ALPHA(ctx->img2.imgtype)) {\n\t\tif(!ctx->opt_strip_alpha) {\n\t\t\t// If we're not allowed to strip the alpha channel, also disable\n\t\t\t// other optimizations that would implicitly remove the alpha\n\t\t\t// channel. (The optimization routines may do weird things if we\n\t\t\t// were to allow this.)\n\t\t\tctx->opt_palette = 0;\n\t\t\tctx->opt_binary_trns = 0;\n\t\t}\n\t}\n\n\treturn 1;\n}\n\nIW_IMPL(int) iw_process_image(struct iw_context *ctx)\n{\n\tint ret;\n\tint retval = 0;\n\n\tif(ctx->use_count>0) {\n\t\tiw_set_error(ctx,\"Internal: Incorrect attempt to reprocess image\");\n\t\tgoto done;\n\t}\n\tctx->use_count++;\n\n\tret = iw_prepare_processing(ctx,ctx->canvas_width,ctx->canvas_height);\n\tif(!ret) goto done;\n\n\tret = iw_process_internal(ctx);\n\tif(!ret) goto done;\n\n\tiwpvt_optimize_image(ctx);\n\n\tretval = 1;\ndone:\n\treturn retval;\n}\n"], "fixing_code": ["// imagew-bmp.c\n// Part of ImageWorsener, Copyright (c) 2011 by Jason Summers.\n// For more information, see the readme.txt file.\n\n#include \"imagew-config.h\"\n\n#include <stdio.h> // for SEEK_SET\n#include <stdlib.h>\n#include <string.h>\n\n#define IW_INCLUDE_UTIL_FUNCTIONS\n#include \"imagew.h\"\n\n#define IWBMP_BI_RGB       0 // = uncompressed\n#define IWBMP_BI_RLE8      1\n#define IWBMP_BI_RLE4      2\n#define IWBMP_BI_BITFIELDS 3\n#define IWBMP_BI_JPEG      4\n#define IWBMP_BI_PNG       5\n\n#define IWBMPCS_CALIBRATED_RGB    0\n#define IWBMPCS_DEVICE_RGB        1 // (Unconfirmed)\n#define IWBMPCS_DEVICE_CMYK       2 // (Unconfirmed)\n#define IWBMPCS_SRGB              0x73524742\n#define IWBMPCS_WINDOWS           0x57696e20\n#define IWBMPCS_PROFILE_LINKED    0x4c494e4b\n#define IWBMPCS_PROFILE_EMBEDDED  0x4d424544\n\nstatic size_t iwbmp_calc_bpr(int bpp, size_t width)\n{\n\treturn ((bpp*width+31)/32)*4;\n}\n\nstruct iwbmprcontext {\n\tstruct iw_iodescr *iodescr;\n\tstruct iw_context *ctx;\n\tstruct iw_image *img;\n\tint bmpversion;\n\tint width, height;\n\tint topdown;\n\tint has_fileheader;\n\tunsigned int bitcount; // bits per pixel\n\tunsigned int compression; // IWBMP_BI_*\n\tint uses_bitfields; // 'compression' is BI_BITFIELDS\n\tint has_alpha_channel;\n\tint bitfields_set;\n\tint need_16bit;\n\tunsigned int palette_entries;\n\tsize_t fileheader_size;\n\tsize_t infoheader_size;\n\tsize_t bitfields_nbytes; // Bytes consumed by BITFIELDs, if not part of the header.\n\tsize_t palette_nbytes;\n\tsize_t bfOffBits;\n\tstruct iw_palette palette;\n\n\t// For 16- & 32-bit images:\n\tunsigned int bf_mask[4];\n\tint bf_high_bit[4];\n\tint bf_low_bit[4];\n\tint bf_bits_count[4]; // number of bits in each channel\n\n\tstruct iw_csdescr csdescr;\n};\n\nstatic int iwbmp_read(struct iwbmprcontext *rctx,\n\t\tiw_byte *buf, size_t buflen)\n{\n\tint ret;\n\tsize_t bytesread = 0;\n\n\tret = (*rctx->iodescr->read_fn)(rctx->ctx,rctx->iodescr,\n\t\tbuf,buflen,&bytesread);\n\tif(!ret || bytesread!=buflen) {\n\t\treturn 0;\n\t}\n\treturn 1;\n}\n\nstatic int iwbmp_skip_bytes(struct iwbmprcontext *rctx, size_t n)\n{\n\tiw_byte buf[1024];\n\tsize_t still_to_read;\n\tsize_t num_to_read;\n\n\tstill_to_read = n;\n\twhile(still_to_read>0) {\n\t\tnum_to_read = still_to_read;\n\t\tif(num_to_read>1024) num_to_read=1024;\n\t\tif(!iwbmp_read(rctx,buf,num_to_read)) {\n\t\t\treturn 0;\n\t\t}\n\t\tstill_to_read -= num_to_read;\n\t}\n\treturn 1;\n}\n\nstatic int iwbmp_read_file_header(struct iwbmprcontext *rctx)\n{\n\tiw_byte buf[14];\n\n\tif(!iwbmp_read(rctx,buf,14)) return 0;\n\trctx->fileheader_size = 14;\n\n\tif(buf[0]=='B' && buf[1]=='A') { // OS/2 Bitmap Array\n\t\t// TODO: This type of file can contain more than one BMP image.\n\t\t// We only support the first one.\n\t\tif(!iwbmp_read(rctx,buf,14)) return 0;\n\t\trctx->fileheader_size += 14;\n\t}\n\n\tif(buf[0]=='B' && buf[1]=='M') {\n\t\t;\n\t}\n\telse if((buf[0]=='C' && buf[1]=='I') || // OS/2 Color Icon\n\t   (buf[0]=='C' && buf[1]=='P') || // OS/2 Color Pointer\n\t   (buf[0]=='I' && buf[1]=='C') || // OS/2 Icon\n\t   (buf[0]=='P' && buf[1]=='T'))   // OS/2 Pointer\n\t{\n\t\tiw_set_error(rctx->ctx,\"This type of BMP file is not supported\");\n\t\treturn 0;\n\t}\n\telse {\n\t\tiw_set_error(rctx->ctx,\"Not a BMP file\");\n\t\treturn 0;\n\t}\n\n\trctx->bfOffBits = iw_get_ui32le(&buf[10]);\n\treturn 1;\n}\n\n// Read the 12-byte header of a Windows v2 BMP (also known as OS/2 v1 BMP).\nstatic int decode_v2_header(struct iwbmprcontext *rctx, const iw_byte *buf)\n{\n\tunsigned int nplanes;\n\n\trctx->width = iw_get_ui16le(&buf[4]);\n\trctx->height = iw_get_ui16le(&buf[6]);\n\tnplanes = iw_get_ui16le(&buf[8]);\n\tif(nplanes!=1) return 0;\n\trctx->bitcount = iw_get_ui16le(&buf[10]);\n\tif(rctx->bitcount!=1 && rctx->bitcount!=4 &&\n\t\trctx->bitcount!=8 && rctx->bitcount!=24)\n\t{\n\t\treturn 0;\n\t}\n\tif(rctx->bitcount<=8) {\n\t\tsize_t palette_start, palette_end;\n\n\t\trctx->palette_entries = 1<<rctx->bitcount;\n\t\trctx->palette_nbytes = 3*rctx->palette_entries;\n\n\t\t// Since v2 BMPs have no direct way to indicate that the palette is not\n\t\t// full-sized, assume the palette ends no later than the start of the\n\t\t// bitmap bits.\n\t\tpalette_start = rctx->fileheader_size + rctx->infoheader_size;\n\t\tpalette_end = palette_start + rctx->palette_nbytes;\n\t\tif(rctx->bfOffBits >= palette_start+3 && rctx->bfOffBits < palette_end) {\n\t\t\trctx->palette_entries = (unsigned int)((rctx->bfOffBits - palette_start)/3);\n\t\t\trctx->palette_nbytes = 3*rctx->palette_entries;\n\t\t}\n\t}\n\treturn 1;\n}\n\n// Read a Windows v3 or OS/2 v2 header.\nstatic int decode_v3_header_fields(struct iwbmprcontext *rctx, const iw_byte *buf)\n{\n\tunsigned int nplanes;\n\tint biXPelsPerMeter, biYPelsPerMeter;\n\tunsigned int biClrUsed = 0;\n\t//unsigned int biSizeImage;\n\n\trctx->width = iw_get_i32le(&buf[4]);\n\trctx->height = iw_get_i32le(&buf[8]);\n\tif(rctx->height<0) {\n\t\trctx->height = -rctx->height;\n\t\trctx->topdown = 1;\n\t}\n\n\tnplanes = iw_get_ui16le(&buf[12]);\n\tif(nplanes!=1) return 0;\n\n\trctx->bitcount = iw_get_ui16le(&buf[14]);\n\t// We allow bitcount=2 because it's legal in Windows CE BMPs.\n\tif(rctx->bitcount!=1 && rctx->bitcount!=2 && rctx->bitcount!=4 &&\n\t\trctx->bitcount!=8 && rctx->bitcount!=16 && rctx->bitcount!=24 &&\n\t\trctx->bitcount!=32)\n\t{\n\t\tiw_set_errorf(rctx->ctx,\"Bad or unsupported bit count (%d)\",(int)rctx->bitcount);\n\t\treturn 0;\n\t}\n\n\tif(rctx->infoheader_size<=16) {\n\t\tgoto infoheaderdone;\n\t}\n\n\trctx->compression = iw_get_ui32le(&buf[16]);\n\tif(rctx->compression==IWBMP_BI_BITFIELDS) {\n\t\tif(rctx->bitcount==1) {\n\t\t\tiw_set_error(rctx->ctx,\"Huffman 1D compression not supported\");\n\t\t\treturn 0;\n\t\t}\n\t\telse if(rctx->bitcount!=16 && rctx->bitcount!=32) {\n\t\t\tiw_set_error(rctx->ctx,\"Bad or unsupported image type\");\n\t\t\treturn 0;\n\t\t}\n\n\t\t// The compression field is overloaded: BITFIELDS is not a type of\n\t\t// compression. Un-overload it.\n\t\trctx->uses_bitfields = 1;\n\n\t\t// The v4/v5 documentation for the \"BitCount\" field says that the\n\t\t// BITFIELDS data comes after the header, the same as with v3.\n\t\t// The v4/v5 documentation for the \"Compression\" field says that the\n\t\t// BITFIELDS data is stored in the \"Mask\" fields of the header.\n\t\t// Am I supposed to conclude that it is redundantly stored in both\n\t\t// places?\n\t\t// Evidence and common sense suggests the \"BitCount\" documentation is\n\t\t// incorrect, and v4/v5 BMPs never have a separate \"bitfields\" segment.\n\t\tif(rctx->bmpversion==3) {\n\t\t\trctx->bitfields_nbytes = 12;\n\t\t}\n\n\t\trctx->compression=IWBMP_BI_RGB;\n\t}\n\n\t//biSizeImage = iw_get_ui32le(&buf[20]);\n\tbiXPelsPerMeter = iw_get_i32le(&buf[24]);\n\tbiYPelsPerMeter = iw_get_i32le(&buf[28]);\n\n\trctx->img->density_code = IW_DENSITY_UNITS_PER_METER;\n\trctx->img->density_x = (double)biXPelsPerMeter;\n\trctx->img->density_y = (double)biYPelsPerMeter;\n\tif(!iw_is_valid_density(rctx->img->density_x,rctx->img->density_y,rctx->img->density_code)) {\n\t\trctx->img->density_code=IW_DENSITY_UNKNOWN;\n\t}\n\n\tbiClrUsed = iw_get_ui32le(&buf[32]);\n\tif(biClrUsed>100000) return 0;\n\ninfoheaderdone:\n\t// The documentation of the biClrUsed field is not very clear.\n\t// I'm going to assume that if biClrUsed is 0 and bitcount<=8, then\n\t// the number of palette colors is the maximum that would be useful\n\t// for that bitcount. In all other cases, the number of palette colors\n\t// equals biClrUsed.\n\tif(biClrUsed==0 && rctx->bitcount<=8) {\n\t\trctx->palette_entries = 1<<rctx->bitcount;\n\t}\n\telse {\n\t\trctx->palette_entries = biClrUsed;\n\t}\n\trctx->palette_nbytes = 4*rctx->palette_entries;\n\treturn 1;\n}\n\nstatic int process_bf_mask(struct iwbmprcontext *rctx, int k);\n\n// Decode the fields that are in v4 and not in v3.\nstatic int decode_v4_header_fields(struct iwbmprcontext *rctx, const iw_byte *buf)\n{\n\tint k;\n\tunsigned int cstype;\n\n\tif(rctx->uses_bitfields) {\n\t\t// Set the bitfields masks here, instead of in iwbmp_read_bitfields().\n\t\tfor(k=0;k<4;k++) {\n\t\t\trctx->bf_mask[k] = 0;\n\t\t}\n\t\tfor(k=0;k<4;k++) {\n\t\t\tif(rctx->infoheader_size < (size_t)(40+k*4+4)) break;\n\t\t\trctx->bf_mask[k] = iw_get_ui32le(&buf[40+k*4]);\n\t\t\tif(!process_bf_mask(rctx,k)) return 0;\n\t\t}\n\t\trctx->bitfields_set=1; // Remember not to overwrite the bf_* fields.\n\n\t\tif(rctx->bf_mask[3]!=0) {\n\t\t\t// The documentation says this is the mask that \"specifies the\n\t\t\t// alpha component of each pixel.\"\n\t\t\t// It doesn't say whther it's associated, or unassociated alpha.\n\t\t\t// It doesn't say whether 0=transparent, or 0=opaque.\n\t\t\t// It doesn't say how to tell whether an image has an alpha\n\t\t\t// channel.\n\t\t\t// These are the answers I'm going with:\n\t\t\t// - Unassociated alpha\n\t\t\t// - 0=transparent\n\t\t\t// - 16- and 32-bit images have an alpha channel if 'compression'\n\t\t\t// is set to BI_BITFIELDS, and this alpha mask is nonzero.\n\t\t\trctx->has_alpha_channel = 1;\n\t\t}\n\t}\n\n\tif(rctx->infoheader_size < 108) return 1;\n\n\tcstype = iw_get_ui32le(&buf[56]);\n\tswitch(cstype) {\n\tcase IWBMPCS_CALIBRATED_RGB:\n\t\t//  \"indicates that endpoints and gamma values are given in the\n\t\t//    appropriate fields.\"  (TODO)\n\t\tbreak;\n\n\tcase IWBMPCS_DEVICE_RGB:\n\tcase IWBMPCS_SRGB:\n\tcase IWBMPCS_WINDOWS:\n\t\tbreak;\n\n\tcase IWBMPCS_PROFILE_LINKED:\n\tcase IWBMPCS_PROFILE_EMBEDDED:\n\t\tif(rctx->bmpversion<5) {\n\t\t\tiw_warning(rctx->ctx,\"Invalid colorspace type for BMPv4\");\n\t\t}\n\t\tbreak;\n\n\tdefault:\n\t\tiw_warningf(rctx->ctx,\"Unrecognized or unsupported colorspace type (0x%x)\",cstype);\n\t}\n\n\t// Read Gamma fields\n\tif(cstype==IWBMPCS_CALIBRATED_RGB) {\n\t\tunsigned int bmpgamma;\n\t\tdouble gamma[3];\n\t\tdouble avggamma;\n\n\t\tfor(k=0;k<3;k++) {\n\t\t\tbmpgamma = iw_get_ui32le(&buf[96+k*4]);\n\t\t\tgamma[k] = ((double)bmpgamma)/65536.0;\n\t\t}\n\t\tavggamma = (gamma[0] + gamma[1] + gamma[2])/3.0;\n\n\t\tif(avggamma>=0.1 && avggamma<=10.0) {\n\t\t\tiw_make_gamma_csdescr(&rctx->csdescr,1.0/avggamma);\n\t\t}\n\t}\n\n\treturn 1;\n}\n\n// Decode the fields that are in v5 and not in v4.\nstatic int decode_v5_header_fields(struct iwbmprcontext *rctx, const iw_byte *buf)\n{\n\tunsigned int intent_bmp_style;\n\tint intent_iw_style;\n\n\tintent_bmp_style = iw_get_ui32le(&buf[108]);\n\tintent_iw_style = IW_INTENT_UNKNOWN;\n\tswitch(intent_bmp_style) {\n\t\tcase 1: intent_iw_style = IW_INTENT_SATURATION; break; // LCS_GM_BUSINESS\n\t\tcase 2: intent_iw_style = IW_INTENT_RELATIVE; break; // LCS_GM_GRAPHICS\n\t\tcase 4: intent_iw_style = IW_INTENT_PERCEPTUAL; break; // LCS_GM_IMAGES\n\t\tcase 8: intent_iw_style = IW_INTENT_ABSOLUTE; break; // LCS_GM_ABS_COLORIMETRIC\n\t}\n\trctx->img->rendering_intent = intent_iw_style;\n\n\t// The profile may either be after the color table, or after the bitmap bits.\n\t// I'm assuming that we will never need to use the profile size in order to\n\t// find the bitmap bits; i.e. that if the bfOffBits field in the file header\n\t// is not available, the profile must be after the bits.\n\t//profile_offset = iw_get_ui32le(&buf[112]); // bV5ProfileData;\n\t//profile_size = iw_get_ui32le(&buf[116]); // bV5ProfileSize;\n\n\treturn 1;\n}\n\nstatic int iwbmp_read_info_header(struct iwbmprcontext *rctx)\n{\n\tiw_byte buf[124];\n\tint retval = 0;\n\tsize_t n;\n\n\t// First, read just the \"size\" field. It tells the size of the header\n\t// structure, and identifies the BMP version.\n\tif(!iwbmp_read(rctx,buf,4)) goto done;\n\trctx->infoheader_size = iw_get_ui32le(&buf[0]);\n\tif(rctx->infoheader_size<12) goto done;\n\n\t// Read the rest of the header.\n\tn = rctx->infoheader_size;\n\tif(n>sizeof(buf)) n=sizeof(buf);\n\tif(!iwbmp_read(rctx,&buf[4],n-4)) goto done;\n\n\tif(rctx->infoheader_size==12) {\n\t\t// This is a \"Windows BMP v2\" or \"OS/2 BMP v1\" bitmap.\n\t\trctx->bmpversion=2;\n\t\tif(!decode_v2_header(rctx,buf)) goto done;\n\t}\n\telse if(rctx->infoheader_size==16 || rctx->infoheader_size==40 || rctx->infoheader_size==64) {\n\t\t// A Windows v3 or OS/2 v2 BMP.\n\t\t// OS/2 v2 BMPs can technically have other header sizes between 16 and 64,\n\t\t// but it's not clear if such files actually exist.\n\t\trctx->bmpversion=3;\n\t\tif(!decode_v3_header_fields(rctx,buf)) goto done;\n\t}\n\telse if(rctx->infoheader_size==108 || rctx->infoheader_size==52 || rctx->infoheader_size==56) {\n\t\t// We assume a a 52- or 56-byte header is for BITMAPV2INFOHEADER/BITMAPV3INFOHEADER,\n\t\t// and not OS/2v2 format. But if it OS/2v2, it will probably either work (because\n\t\t// the formats are similar enough), or fail due to an unsupported combination of\n\t\t// compression and bits/pixel.\n\t\trctx->bmpversion=4;\n\t\tif(!decode_v3_header_fields(rctx,buf)) goto done;\n\t\tif(!decode_v4_header_fields(rctx,buf)) goto done;\n\t}\n\telse if(rctx->infoheader_size==124) {\n\t\trctx->bmpversion=5;\n\t\tif(!decode_v3_header_fields(rctx,buf)) goto done;\n\t\tif(!decode_v4_header_fields(rctx,buf)) goto done;\n\t\tif(!decode_v5_header_fields(rctx,buf)) goto done;\n\t}\n\telse {\n\t\tiw_set_error(rctx->ctx,\"Unsupported BMP version\");\n\t\tgoto done;\n\t}\n\n\tif(!iw_check_image_dimensions(rctx->ctx,rctx->width,rctx->height)) {\n\t\tgoto done;\n\t}\n\n\tretval = 1;\n\ndone:\n\treturn retval;\n}\n\n// Find the highest/lowest bit that is set.\nstatic int find_high_bit(unsigned int x)\n{\n\tint i;\n\tfor(i=31;i>=0;i--) {\n\t\tif(x&(1U<<(unsigned int)i)) return i;\n\t}\n\treturn 0;\n}\nstatic int find_low_bit(unsigned int x)\n{\n\tint i;\n\tfor(i=0;i<=31;i++) {\n\t\tif(x&(1U<<(unsigned int)i)) return i;\n\t}\n\treturn 0;\n}\n\n// Given .bf_mask[k], set high_bit[k], low_bit[k], etc.\nstatic int process_bf_mask(struct iwbmprcontext *rctx, int k)\n{\n\t// The bits representing the mask for each channel are required to be\n\t// contiguous, so all we need to do is find the highest and lowest bit.\n\trctx->bf_high_bit[k] = find_high_bit(rctx->bf_mask[k]);\n\trctx->bf_low_bit[k] = find_low_bit(rctx->bf_mask[k]);\n\trctx->bf_bits_count[k] = 1+rctx->bf_high_bit[k]-rctx->bf_low_bit[k];\n\n\t// Check if the mask specifies an invalid bit\n\tif(rctx->bf_high_bit[k] > (int)(rctx->bitcount-1)) return 0;\n\n\tif(rctx->bf_bits_count[k]>16) {\n\t\t// We only support up to 16 bits. Ignore any bits after the 16th.\n\t\trctx->bf_low_bit[k] = rctx->bf_high_bit[k]-15;\n\t\trctx->bf_bits_count[k] = 16;\n\t}\n\n\tif(rctx->bf_bits_count[k]>8) {\n\t\trctx->need_16bit = 1;\n\t}\n\n\treturn 1;\n}\n\nstatic int iwbmp_read_bitfields(struct iwbmprcontext *rctx)\n{\n\tiw_byte buf[12];\n\tint k;\n\n\tif(!iwbmp_read(rctx,buf,12)) return 0;\n\n\tfor(k=0;k<3;k++) {\n\t\trctx->bf_mask[k] = iw_get_ui32le(&buf[k*4]);\n\t\tif(rctx->bf_mask[k]==0) return 0;\n\n\t\t// Find the high bit, low bit, etc.\n\t\tif(!process_bf_mask(rctx,k)) return 0;\n\t}\n\n\treturn 1;\n}\n\nstatic void iwbmp_set_default_bitfields(struct iwbmprcontext *rctx)\n{\n\tint k;\n\n\tif(rctx->bitfields_set) return;\n\n\tif(rctx->bitcount==16) {\n\t\t// Default is 5 bits for each channel.\n\t\trctx->bf_mask[0]=0x7c00; // 01111100 00000000 (red)\n\t\trctx->bf_mask[1]=0x03e0; // 00000011 11100000 (green)\n\t\trctx->bf_mask[2]=0x001f; // 00000000 00011111 (blue)\n\t}\n\telse if(rctx->bitcount==32) {\n\t\trctx->bf_mask[0]=0x00ff0000;\n\t\trctx->bf_mask[1]=0x0000ff00;\n\t\trctx->bf_mask[2]=0x000000ff;\n\t}\n\telse {\n\t\treturn;\n\t}\n\n\tfor(k=0;k<3;k++) {\n\t\tprocess_bf_mask(rctx,k);\n\t}\n}\n\nstatic int iwbmp_read_palette(struct iwbmprcontext *rctx)\n{\n\tsize_t i;\n\tiw_byte buf[4*256];\n\tsize_t b;\n\tunsigned int valid_palette_entries;\n\tsize_t valid_palette_nbytes;\n\n\tb = (rctx->bmpversion==2) ? 3 : 4; // bytes per palette entry\n\n\tif(rctx->infoheader_size==64) {\n\t\t// According to what little documentation I can find, OS/2v2 BMP files\n\t\t// have 4 bytes per palette entry. But some of the files I've seen have\n\t\t// only 3. This is a little hack to support them.\n\t\tif(rctx->fileheader_size + rctx->infoheader_size + rctx->palette_entries*3 ==\n\t\t\trctx->bfOffBits)\n\t\t{\n\t\t\tiw_warning(rctx->ctx,\"BMP bitmap overlaps colormap; assuming colormap uses 3 bytes per entry instead of 4\");\n\t\t\tb = 3;\n\t\t\trctx->palette_nbytes = 3*rctx->palette_entries;\n\t\t}\n\t}\n\n\t// If the palette has >256 colors, only use the first 256.\n\tvalid_palette_entries = (rctx->palette_entries<=256) ? rctx->palette_entries : 256;\n\tvalid_palette_nbytes = valid_palette_entries * b;\n\n\n\tif(!iwbmp_read(rctx,buf,valid_palette_nbytes)) return 0;\n\trctx->palette.num_entries = valid_palette_entries;\n\tfor(i=0;i<valid_palette_entries;i++) {\n\t\trctx->palette.entry[i].b = buf[i*b+0];\n\t\trctx->palette.entry[i].g = buf[i*b+1];\n\t\trctx->palette.entry[i].r = buf[i*b+2];\n\t\trctx->palette.entry[i].a = 255;\n\t}\n\n\t// If the palette is oversized, skip over the unused part of it.\n\tif(rctx->palette_nbytes > valid_palette_nbytes) {\n\t\tiwbmp_skip_bytes(rctx, rctx->palette_nbytes - valid_palette_nbytes);\n\t}\n\treturn 1;\n}\n\nstatic void bmpr_convert_row_32_16(struct iwbmprcontext *rctx, const iw_byte *src, size_t row)\n{\n\tint i,k;\n\tunsigned int v,x;\n\tint numchannels;\n\n\tnumchannels = rctx->has_alpha_channel ? 4 : 3;\n\n\tfor(i=0;i<rctx->width;i++) {\n\t\tif(rctx->bitcount==32) {\n\t\t\tx = ((unsigned int)src[i*4+0]) | ((unsigned int)src[i*4+1])<<8 |\n\t\t\t\t((unsigned int)src[i*4+2])<<16 | ((unsigned int)src[i*4+3])<<24;\n\t\t}\n\t\telse { // 16\n\t\t\tx = ((unsigned int)src[i*2+0]) | ((unsigned int)src[i*2+1])<<8;\n\t\t}\n\t\tv = 0;\n\t\tfor(k=0;k<numchannels;k++) { // For red, green, blue [, alpha]:\n\t\t\tv = x & rctx->bf_mask[k];\n\t\t\tif(rctx->bf_low_bit[k]>0)\n\t\t\t\tv >>= rctx->bf_low_bit[k];\n\t\t\tif(rctx->img->bit_depth==16) {\n\t\t\t\trctx->img->pixels[row*rctx->img->bpr + i*numchannels*2 + k*2+0] = (iw_byte)(v>>8);\n\t\t\t\trctx->img->pixels[row*rctx->img->bpr + i*numchannels*2 + k*2+1] = (iw_byte)(v&0xff);\n\t\t\t}\n\t\t\telse {\n\t\t\t\trctx->img->pixels[row*rctx->img->bpr + i*numchannels + k] = (iw_byte)v;\n\t\t\t}\n\t\t}\n\t}\n}\n\nstatic void bmpr_convert_row_24(struct iwbmprcontext *rctx,const iw_byte *src, size_t row)\n{\n\tint i;\n\tfor(i=0;i<rctx->width;i++) {\n\t\trctx->img->pixels[row*rctx->img->bpr + i*3 + 0] = src[i*3+2];\n\t\trctx->img->pixels[row*rctx->img->bpr + i*3 + 1] = src[i*3+1];\n\t\trctx->img->pixels[row*rctx->img->bpr + i*3 + 2] = src[i*3+0];\n\t}\n}\n\nstatic void bmpr_convert_row_8(struct iwbmprcontext *rctx,const iw_byte *src, size_t row)\n{\n\tint i;\n\tfor(i=0;i<rctx->width;i++) {\n\t\trctx->img->pixels[row*rctx->img->bpr + i*3 + 0] = rctx->palette.entry[src[i]].r;\n\t\trctx->img->pixels[row*rctx->img->bpr + i*3 + 1] = rctx->palette.entry[src[i]].g;\n\t\trctx->img->pixels[row*rctx->img->bpr + i*3 + 2] = rctx->palette.entry[src[i]].b;\n\t}\n}\n\nstatic void bmpr_convert_row_4(struct iwbmprcontext *rctx,const iw_byte *src, size_t row)\n{\n\tint i;\n\tint pal_index;\n\n\tfor(i=0;i<rctx->width;i++) {\n\t\tpal_index = (i&0x1) ? src[i/2]&0x0f : src[i/2]>>4;\n\t\trctx->img->pixels[row*rctx->img->bpr + i*3 + 0] = rctx->palette.entry[pal_index].r;\n\t\trctx->img->pixels[row*rctx->img->bpr + i*3 + 1] = rctx->palette.entry[pal_index].g;\n\t\trctx->img->pixels[row*rctx->img->bpr + i*3 + 2] = rctx->palette.entry[pal_index].b;\n\t}\n}\n\nstatic void bmpr_convert_row_2(struct iwbmprcontext *rctx,const iw_byte *src, size_t row)\n{\n\tint i;\n\tint pal_index;\n\n\tfor(i=0;i<rctx->width;i++) {\n\t\tpal_index = (src[i/4]>>(2*(3-i%4)))&0x03;\n\t\trctx->img->pixels[row*rctx->img->bpr + i*3 + 0] = rctx->palette.entry[pal_index].r;\n\t\trctx->img->pixels[row*rctx->img->bpr + i*3 + 1] = rctx->palette.entry[pal_index].g;\n\t\trctx->img->pixels[row*rctx->img->bpr + i*3 + 2] = rctx->palette.entry[pal_index].b;\n\t}\n}\n\nstatic void bmpr_convert_row_1(struct iwbmprcontext *rctx,const iw_byte *src, size_t row)\n{\n\tint i;\n\tint pal_index;\n\n\tfor(i=0;i<rctx->width;i++) {\n\t\tpal_index = (src[i/8] & (1<<(7-i%8))) ? 1 : 0;\n\t\trctx->img->pixels[row*rctx->img->bpr + i*3 + 0] = rctx->palette.entry[pal_index].r;\n\t\trctx->img->pixels[row*rctx->img->bpr + i*3 + 1] = rctx->palette.entry[pal_index].g;\n\t\trctx->img->pixels[row*rctx->img->bpr + i*3 + 2] = rctx->palette.entry[pal_index].b;\n\t}\n}\n\nstatic int bmpr_read_uncompressed(struct iwbmprcontext *rctx)\n{\n\tiw_byte *rowbuf = NULL;\n\tsize_t bmp_bpr;\n\tint j;\n\tint retval = 0;\n\n\tif(rctx->has_alpha_channel) {\n\t\trctx->img->imgtype = IW_IMGTYPE_RGBA;\n\t\t\n\t\trctx->img->bit_depth = rctx->need_16bit ? 16 : 8;\n\t\trctx->img->bpr = iw_calc_bytesperrow(rctx->width,4*rctx->img->bit_depth);\n\t}\n\telse {\n\t\trctx->img->imgtype = IW_IMGTYPE_RGB;\n\t\trctx->img->bit_depth = rctx->need_16bit ? 16 : 8;\n\t\trctx->img->bpr = iw_calc_bytesperrow(rctx->width,3*rctx->img->bit_depth);\n\t}\n\n\tbmp_bpr = iwbmp_calc_bpr(rctx->bitcount,rctx->width);\n\n\trctx->img->pixels = (iw_byte*)iw_malloc_large(rctx->ctx,rctx->img->bpr,rctx->img->height);\n\tif(!rctx->img->pixels) goto done;\n\n\trowbuf = iw_malloc(rctx->ctx,bmp_bpr);\n\n\tfor(j=0;j<rctx->img->height;j++) {\n\t\t// Read a row of the BMP file.\n\t\tif(!iwbmp_read(rctx,rowbuf,bmp_bpr)) {\n\t\t\tgoto done;\n\t\t}\n\t\tswitch(rctx->bitcount) {\n\t\tcase 32:\n\t\tcase 16:\n\t\t\tbmpr_convert_row_32_16(rctx,rowbuf,j);\n\t\t\tbreak;\n\t\tcase 24:\n\t\t\tbmpr_convert_row_24(rctx,rowbuf,j);\n\t\t\tbreak;\n\t\tcase 8:\n\t\t\tbmpr_convert_row_8(rctx,rowbuf,j);\n\t\t\tbreak;\n\t\tcase 4:\n\t\t\tbmpr_convert_row_4(rctx,rowbuf,j);\n\t\t\tbreak;\n\t\tcase 2:\n\t\t\tbmpr_convert_row_2(rctx,rowbuf,j);\n\t\t\tbreak;\n\t\tcase 1:\n\t\t\tbmpr_convert_row_1(rctx,rowbuf,j);\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tretval = 1;\ndone:\n\tif(rowbuf) iw_free(rctx->ctx,rowbuf);\n\treturn retval;\n}\n\n// Read and decompress RLE8 or RLE4-compressed bits, and write pixels to\n// rctx->img->pixels.\nstatic int bmpr_read_rle_internal(struct iwbmprcontext *rctx)\n{\n\tint retval = 0;\n\tint pos_x, pos_y;\n\tiw_byte buf[255];\n\tsize_t n_pix;\n\tsize_t n_bytes;\n\tsize_t i;\n\tsize_t pal_index;\n\n\t// The position of the next pixel to set.\n\t// pos_y is in IW coordinates (top=0), not BMP coordinates (bottom=0).\n\tpos_x = 0;\n\tpos_y = 0;\n\n\t// Initially make all pixels transparent, so that any any pixels we\n\t// don't modify will be transparent.\n\tiw_zeromem(rctx->img->pixels,rctx->img->bpr*rctx->img->height);\n\n\twhile(1) {\n\t\t// If we've reached the end of the bitmap, stop.\n\t\tif(pos_y>rctx->img->height-1) break;\n\t\tif(pos_y==rctx->img->height-1 && pos_x>=rctx->img->width) break;\n\n\t\tif(!iwbmp_read(rctx,buf,2)) goto done;\n\t\tif(buf[0]==0) {\n\t\t\tif(buf[1]==0) {\n\t\t\t\t// End of Line\n\t\t\t\tpos_y++;\n\t\t\t\tpos_x=0;\n\t\t\t}\n\t\t\telse if(buf[1]==1) {\n\t\t\t\t// (Premature) End of Bitmap\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\telse if(buf[1]==2) {\n\t\t\t\t// DELTA: The next two bytes are unsigned values representing\n\t\t\t\t// the relative position of the next pixel from the \"current\n\t\t\t\t// position\".\n\t\t\t\t// I interpret \"current position\" to mean the position at which\n\t\t\t\t// the next pixel would normally have been.\n\t\t\t\tif(!iwbmp_read(rctx,buf,2)) goto done;\n\n\t\t\t\tif(pos_x<rctx->img->width) pos_x += buf[0];\n\t\t\t\tpos_y += buf[1];\n\t\t\t}\n\t\t\telse {\n\t\t\t\t// A uncompressed segment\n\t\t\t\tn_pix = (size_t)buf[1]; // Number of uncompressed pixels which follow\n\t\t\t\tif(rctx->compression==IWBMP_BI_RLE4) {\n\t\t\t\t\tn_bytes = ((n_pix+3)/4)*2;\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\tn_bytes = ((n_pix+1)/2)*2;\n\t\t\t\t}\n\t\t\t\tif(!iwbmp_read(rctx,buf,n_bytes)) goto done;\n\t\t\t\tfor(i=0;i<n_pix;i++) {\n\t\t\t\t\tif(pos_x<rctx->img->width) {\n\t\t\t\t\t\tif(rctx->compression==IWBMP_BI_RLE4) {\n\t\t\t\t\t\t\tpal_index = (i%2) ? buf[i/2]&0x0f : buf[i/2]>>4;\n\t\t\t\t\t\t}\n\t\t\t\t\t\telse {\n\t\t\t\t\t\t\tpal_index = buf[i];\n\t\t\t\t\t\t}\n\t\t\t\t\t\trctx->img->pixels[rctx->img->bpr*pos_y + pos_x*4 + 0] = rctx->palette.entry[pal_index].r;\n\t\t\t\t\t\trctx->img->pixels[rctx->img->bpr*pos_y + pos_x*4 + 1] = rctx->palette.entry[pal_index].g;\n\t\t\t\t\t\trctx->img->pixels[rctx->img->bpr*pos_y + pos_x*4 + 2] = rctx->palette.entry[pal_index].b;\n\t\t\t\t\t\trctx->img->pixels[rctx->img->bpr*pos_y + pos_x*4 + 3] = 255;\n\t\t\t\t\t\tpos_x++;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\telse {\n\t\t\t// An RLE-compressed segment\n\t\t\tn_pix = (size_t)buf[0];\n\t\t\tfor(i=0;i<n_pix;i++) {\n\t\t\t\tif(pos_x<rctx->img->width) {\n\t\t\t\t\tif(rctx->compression==IWBMP_BI_RLE4) {\n\t\t\t\t\t\tpal_index = (i%2) ? buf[1]&0x0f : buf[1]>>4;\n\t\t\t\t\t}\n\t\t\t\t\telse {\n\t\t\t\t\t\tpal_index = buf[1];\n\t\t\t\t\t}\n\t\t\t\t\trctx->img->pixels[rctx->img->bpr*pos_y + pos_x*4 + 0] = rctx->palette.entry[pal_index].r;\n\t\t\t\t\trctx->img->pixels[rctx->img->bpr*pos_y + pos_x*4 + 1] = rctx->palette.entry[pal_index].g;\n\t\t\t\t\trctx->img->pixels[rctx->img->bpr*pos_y + pos_x*4 + 2] = rctx->palette.entry[pal_index].b;\n\t\t\t\t\trctx->img->pixels[rctx->img->bpr*pos_y + pos_x*4 + 3] = 255;\n\t\t\t\t\tpos_x++;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tretval = 1;\ndone:\n\treturn retval;\n}\n\nstatic int bmpr_has_transparency(struct iw_image *img)\n{\n\tint i,j;\n\n\tif(img->imgtype!=IW_IMGTYPE_RGBA) return 0;\n\n\tfor(j=0;j<img->height;j++) {\n\t\tfor(i=0;i<img->width;i++) {\n\t\t\tif(img->pixels[j*img->bpr + i*4 + 3] != 255)\n\t\t\t\treturn 1;\n\t\t}\n\t}\n\treturn 0;\n}\n\n// Remove the alpha channel.\n// This doesn't free the extra memory used by the alpha channel, it just\n// moves the pixels around in-place.\nstatic void bmpr_strip_alpha(struct iw_image *img)\n{\n\tint i,j;\n\tsize_t oldbpr;\n\n\timg->imgtype = IW_IMGTYPE_RGB;\n\toldbpr = img->bpr;\n\timg->bpr = iw_calc_bytesperrow(img->width,24);\n\n\tfor(j=0;j<img->height;j++) {\n\t\tfor(i=0;i<img->width;i++) {\n\t\t\timg->pixels[j*img->bpr + i*3 + 0] = img->pixels[j*oldbpr + i*4 + 0];\n\t\t\timg->pixels[j*img->bpr + i*3 + 1] = img->pixels[j*oldbpr + i*4 + 1];\n\t\t\timg->pixels[j*img->bpr + i*3 + 2] = img->pixels[j*oldbpr + i*4 + 2];\n\t\t}\n\t}\n}\n\nstatic int bmpr_read_rle(struct iwbmprcontext *rctx)\n{\n\tint retval = 0;\n\n\tif(!(rctx->compression==IWBMP_BI_RLE8 && rctx->bitcount==8) &&\n\t\t!(rctx->compression==IWBMP_BI_RLE4 && rctx->bitcount==4))\n\t{\n\t\tiw_set_error(rctx->ctx,\"Compression type incompatible with image type\");\n\t\tgoto done;\n\t}\n\n\tif(rctx->topdown) {\n\t\t// The documentation says that top-down images may not be compressed.\n\t\tiw_set_error(rctx->ctx,\"Compression not allowed with top-down images\");\n\t\tgoto done;\n\t}\n\n\t// RLE-compressed BMP images don't have to assign a color to every pixel,\n\t// and it's reasonable to interpret undefined pixels as transparent.\n\t// I'm not going to worry about handling compressed BMP images as\n\t// efficiently as possible, so start with an RGBA image, and convert to\n\t// RGB format later if (as is almost always the case) there was no\n\t// transparency.\n\trctx->img->imgtype = IW_IMGTYPE_RGBA;\n\trctx->img->bit_depth = 8;\n\trctx->img->bpr = iw_calc_bytesperrow(rctx->width,32);\n\n\trctx->img->pixels = (iw_byte*)iw_malloc_large(rctx->ctx,rctx->img->bpr,rctx->img->height);\n\tif(!rctx->img->pixels) goto done;\n\n\tif(!bmpr_read_rle_internal(rctx)) goto done;\n\n\tif(!bmpr_has_transparency(rctx->img)) {\n\t\tbmpr_strip_alpha(rctx->img);\n\t}\n\n\tretval = 1;\ndone:\n\treturn retval;\n}\n\nstatic int iwbmp_read_bits(struct iwbmprcontext *rctx)\n{\n\tint retval = 0;\n\n\trctx->img->width = rctx->width;\n\trctx->img->height = rctx->height;\n\n\t// If applicable, use the fileheader's \"bits offset\" field to locate the\n\t// bitmap bits.\n\tif(rctx->fileheader_size>0) {\n\t\tsize_t expected_offbits;\n\n\t\texpected_offbits = rctx->fileheader_size + rctx->infoheader_size +\n\t\t\trctx->bitfields_nbytes + rctx->palette_nbytes;\n\n\t\tif(rctx->bfOffBits==expected_offbits) {\n\t\t\t;\n\t\t}\n\t\telse if(rctx->bfOffBits>expected_offbits && rctx->bfOffBits<1000000) {\n\t\t\t// Apparently, there's some extra space between the header data and\n\t\t\t// the bits. If it's not unreasonably large, skip over it.\n\t\t\tif(!iwbmp_skip_bytes(rctx, rctx->bfOffBits - expected_offbits)) goto done;\n\t\t}\n\t\telse {\n\t\t\tiw_set_error(rctx->ctx,\"Invalid BMP bits offset\");\n\t\t\tgoto done;\n\t\t}\n\t}\n\n\tif(rctx->compression==IWBMP_BI_RGB) {\n\t\tif(!bmpr_read_uncompressed(rctx)) goto done;\n\t}\n\telse if(rctx->compression==IWBMP_BI_RLE8 || rctx->compression==IWBMP_BI_RLE4) {\n\t\tif(!bmpr_read_rle(rctx)) goto done;\n\t}\n\telse {\n\t\tiw_set_errorf(rctx->ctx,\"Unsupported BMP compression or image type (%d)\",(int)rctx->compression);\n\t\tgoto done;\n\t}\n\n\tretval = 1;\ndone:\n\treturn retval;\n}\n\nstatic void iwbmpr_misc_config(struct iw_context *ctx, struct iwbmprcontext *rctx)\n{\n\t// Have IW flip the image, if necessary.\n\tif(!rctx->topdown) {\n\t\tiw_reorient_image(ctx,IW_REORIENT_FLIP_V);\n\t}\n\n\t// Tell IW the colorspace.\n\tiw_set_input_colorspace(ctx,&rctx->csdescr);\n\n\t// Tell IW the significant bits.\n\tif(rctx->bitcount==16 || rctx->bitcount==32) {\n\t\tif(rctx->bf_bits_count[0]!=8 || rctx->bf_bits_count[1]!=8 || rctx->bf_bits_count[2]!=8 ||\n\t\t\t(IW_IMGTYPE_HAS_ALPHA(rctx->img->imgtype) && rctx->bf_bits_count[3]!=8))\n\t\t{\n\t\t\tiw_set_input_max_color_code(ctx,0, (1 << rctx->bf_bits_count[0])-1 );\n\t\t\tiw_set_input_max_color_code(ctx,1, (1 << rctx->bf_bits_count[1])-1 );\n\t\t\tiw_set_input_max_color_code(ctx,2, (1 << rctx->bf_bits_count[2])-1 );\n\t\t\tif(IW_IMGTYPE_HAS_ALPHA(rctx->img->imgtype)) {\n\t\t\t\tiw_set_input_max_color_code(ctx,3, (1 << rctx->bf_bits_count[3])-1 );\n\t\t\t}\n\t\t}\n\t}\n}\n\nIW_IMPL(int) iw_read_bmp_file(struct iw_context *ctx, struct iw_iodescr *iodescr)\n{\n\tstruct iwbmprcontext rctx;\n\tstruct iw_image img;\n\tint retval = 0;\n\n\tiw_zeromem(&rctx,sizeof(struct iwbmprcontext));\n\tiw_zeromem(&img,sizeof(struct iw_image));\n\n\trctx.ctx = ctx;\n\trctx.img = &img;\n\trctx.iodescr = iodescr;\n\n\t// Start with a default sRGB colorspace. This may be overridden later.\n\tiw_make_srgb_csdescr_2(&rctx.csdescr);\n\n\trctx.has_fileheader = !iw_get_value(ctx,IW_VAL_BMP_NO_FILEHEADER);\n\tif(rctx.has_fileheader) {\n\t\tif(!iwbmp_read_file_header(&rctx)) goto done;\n\t}\n\tif(!iwbmp_read_info_header(&rctx)) goto done;\n\n\tiwbmp_set_default_bitfields(&rctx);\n\tif(rctx.bitfields_nbytes>0) {\n\t\tif(!iwbmp_read_bitfields(&rctx)) goto done;\n\t}\n\n\tif(rctx.palette_entries>0) {\n\t\tif(!iwbmp_read_palette(&rctx)) goto done;\n\t}\n\tif(!iwbmp_read_bits(&rctx)) goto done;\n\n\tiw_set_input_image(ctx, &img);\n\n\tiwbmpr_misc_config(ctx, &rctx);\n\n\tretval = 1;\ndone:\n\tif(!retval) {\n\t\tiw_set_error(ctx,\"BMP read failed\");\n\t\t// If we didn't call iw_set_input_image, 'img' still belongs to us,\n\t\t// so free its contents.\n\t\tiw_free(ctx, img.pixels);\n\t}\n\treturn retval;\n}\n\nstruct iwbmpwcontext {\n\tint bmpversion;\n\tint include_file_header;\n\tint bitcount;\n\tint palentries;\n\tint compressed;\n\tint uses_bitfields;\n\tsize_t header_size;\n\tsize_t bitfields_size;\n\tsize_t palsize;\n\tsize_t unc_dst_bpr;\n\tsize_t unc_bitssize;\n\tstruct iw_iodescr *iodescr;\n\tstruct iw_context *ctx;\n\tstruct iw_image *img;\n\tconst struct iw_palette *pal;\n\tsize_t total_written;\n\tint bf_amt_to_shift[4]; // For 16-bit images\n\tunsigned int bf_mask[4];\n\tunsigned int maxcolor[4]; // R, G, B -- For 16-bit images.\n\tstruct iw_csdescr csdescr;\n\tint no_cslabel;\n};\n\nstatic void iwbmp_write(struct iwbmpwcontext *wctx, const void *buf, size_t n)\n{\n\t(*wctx->iodescr->write_fn)(wctx->ctx,wctx->iodescr,buf,n);\n\twctx->total_written+=n;\n}\n\nstatic void bmpw_convert_row_1(const iw_byte *srcrow, iw_byte *dstrow, int width)\n{\n\tint i;\n\tint m;\n\n\tfor(i=0;i<width;i++) {\n\t\tm = i%8;\n\t\tif(m==0)\n\t\t\tdstrow[i/8] = srcrow[i]<<7;\n\t\telse\n\t\t\tdstrow[i/8] |= srcrow[i]<<(7-m);\n\t}\n}\n\nstatic void bmpw_convert_row_4(const iw_byte *srcrow, iw_byte *dstrow, int width)\n{\n\tint i;\n\n\tfor(i=0;i<width;i++) {\n\t\tif(i%2==0)\n\t\t\tdstrow[i/2] = srcrow[i]<<4;\n\t\telse\n\t\t\tdstrow[i/2] |= srcrow[i];\n\t}\n}\n\nstatic void bmpw_convert_row_8(const iw_byte *srcrow, iw_byte *dstrow, int width)\n{\n\tmemcpy(dstrow,srcrow,width);\n}\n\nstatic void bmpw_convert_row_16_32(struct iwbmpwcontext *wctx, const iw_byte *srcrow,\n\tiw_byte *dstrow, int width)\n{\n\tint i,k;\n\tunsigned int v;\n\tint num_src_samples;\n\tunsigned int src_sample[4];\n\n\tfor(k=0;k<4;k++) src_sample[k]=0;\n\n\tnum_src_samples = iw_imgtype_num_channels(wctx->img->imgtype);\n\n\tfor(i=0;i<width;i++) {\n\n\t\t// Read the source samples into a convenient format.\n\t\tfor(k=0;k<num_src_samples;k++) {\n\t\t\tif(wctx->img->bit_depth==16) {\n\t\t\t\tsrc_sample[k] = (srcrow[num_src_samples*2*i + k*2]<<8) | srcrow[num_src_samples*2*i + k*2 +1];\n\t\t\t}\n\t\t\telse {\n\t\t\t\tsrc_sample[k] = srcrow[num_src_samples*i + k];\n\t\t\t}\n\t\t}\n\n\t\t// Pack the pixels' bits into a single int.\n\t\tswitch(wctx->img->imgtype) {\n\t\tcase IW_IMGTYPE_GRAY:\n\t\t\tv = src_sample[0] << wctx->bf_amt_to_shift[0];\n\t\t\tv |= src_sample[0] << wctx->bf_amt_to_shift[1];\n\t\t\tv |= src_sample[0] << wctx->bf_amt_to_shift[2];\n\t\t\tbreak;\n\t\tcase IW_IMGTYPE_RGBA:\n\t\t\tv = src_sample[0] << wctx->bf_amt_to_shift[0];\n\t\t\tv |= src_sample[1] << wctx->bf_amt_to_shift[1];\n\t\t\tv |= src_sample[2] << wctx->bf_amt_to_shift[2];\n\t\t\tv |= src_sample[3] << wctx->bf_amt_to_shift[3];\n\t\t\tbreak;\n\t\tcase IW_IMGTYPE_GRAYA:\n\t\t\tv = src_sample[0] << wctx->bf_amt_to_shift[0];\n\t\t\tv |= src_sample[0] << wctx->bf_amt_to_shift[1];\n\t\t\tv |= src_sample[0] << wctx->bf_amt_to_shift[2];\n\t\t\tv |= src_sample[1] << wctx->bf_amt_to_shift[3];\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tv = src_sample[0] << wctx->bf_amt_to_shift[0];\n\t\t\tv |= src_sample[1] << wctx->bf_amt_to_shift[1];\n\t\t\tv |= src_sample[2] << wctx->bf_amt_to_shift[2];\n\t\t}\n\n\t\t// Split the int into bytes, and write it to the target image.\n\t\tif(wctx->bitcount==32) {\n\t\t\tdstrow[i*4+0] = (iw_byte)(v&0xff);\n\t\t\tdstrow[i*4+1] = (iw_byte)((v&0x0000ff00)>>8);\n\t\t\tdstrow[i*4+2] = (iw_byte)((v&0x00ff0000)>>16);\n\t\t\tdstrow[i*4+3] = (iw_byte)((v&0xff000000)>>24);\n\t\t}\n\t\telse {\n\t\t\tdstrow[i*2+0] = (iw_byte)(v&0xff);\n\t\t\tdstrow[i*2+1] = (iw_byte)(v>>8);\n\t\t}\n\t}\n}\n\nstatic void bmpw_convert_row_24(struct iwbmpwcontext *wctx, const iw_byte *srcrow,\n\tiw_byte *dstrow, int width)\n{\n\tint i;\n\n\tif(wctx->img->imgtype==IW_IMGTYPE_GRAY) {\n\t\tfor(i=0;i<width;i++) {\n\t\t\tdstrow[i*3+0] = srcrow[i];\n\t\t\tdstrow[i*3+1] = srcrow[i];\n\t\t\tdstrow[i*3+2] = srcrow[i];\n\t\t}\n\t}\n\telse { // RGB\n\t\tfor(i=0;i<width;i++) {\n\t\t\tdstrow[i*3+0] = srcrow[i*3+2];\n\t\t\tdstrow[i*3+1] = srcrow[i*3+1];\n\t\t\tdstrow[i*3+2] = srcrow[i*3+0];\n\t\t}\n\t}\n}\n\nstatic void iwbmp_write_file_header(struct iwbmpwcontext *wctx)\n{\n\tiw_byte fileheader[14];\n\n\tif(!wctx->include_file_header) return;\n\n\tiw_zeromem(fileheader,sizeof(fileheader));\n\tfileheader[0] = 66; // 'B'\n\tfileheader[1] = 77; // 'M'\n\n\t// This will be overwritten later, if the bitmap was compressed.\n\tiw_set_ui32le(&fileheader[ 2], (unsigned int)(14+wctx->header_size+\n\t\twctx->bitfields_size+wctx->palsize+wctx->unc_bitssize)); // bfSize\n\tiw_set_ui32le(&fileheader[10],(unsigned int)(14+wctx->header_size+\n\t\twctx->bitfields_size+wctx->palsize)); // bfOffBits\n\tiwbmp_write(wctx,fileheader,14);\n}\n\nstatic int iwbmp_write_bmp_v2header(struct iwbmpwcontext *wctx)\n{\n\tiw_byte header[12];\n\n\tif(wctx->img->width>65535 || wctx->img->height>65535) {\n\t\tiw_set_error(wctx->ctx,\"Output image is too large for this BMP version\");\n\t\treturn 0;\n\t}\n\n\tiw_zeromem(header,sizeof(header));\n\tiw_set_ui32le(&header[ 0],12);                // bcSize\n\tiw_set_ui16le(&header[ 4],wctx->img->width);  // bcWidth\n\tiw_set_ui16le(&header[ 6],wctx->img->height); // bcHeight\n\tiw_set_ui16le(&header[ 8],1);                 // bcPlanes\n\tiw_set_ui16le(&header[10],wctx->bitcount);    // bcBitCount\n\n\tiwbmp_write(wctx,header,12);\n\treturn 1;\n}\n\nstatic int iwbmp_write_bmp_v3header(struct iwbmpwcontext *wctx)\n{\n\tunsigned int dens_x, dens_y;\n\tunsigned int cmpr;\n\tiw_byte header[40];\n\n\tiw_zeromem(header,sizeof(header));\n\n\tiw_set_ui32le(&header[ 0],(unsigned int)wctx->header_size); // biSize\n\tiw_set_ui32le(&header[ 4],wctx->img->width);  // biWidth\n\tiw_set_ui32le(&header[ 8],wctx->img->height); // biHeight\n\tiw_set_ui16le(&header[12],1);    // biPlanes\n\tiw_set_ui16le(&header[14],wctx->bitcount);   // biBitCount\n\n\tcmpr = IWBMP_BI_RGB;\n\tif(wctx->compressed) {\n\t\tif(wctx->bitcount==8) cmpr = IWBMP_BI_RLE8;\n\t\telse if(wctx->bitcount==4) cmpr = IWBMP_BI_RLE4;\n\t}\n\telse if(wctx->uses_bitfields) {\n\t\tcmpr = IWBMP_BI_BITFIELDS;\n\t}\n\tiw_set_ui32le(&header[16],cmpr); // biCompression\n\n\tiw_set_ui32le(&header[20],(unsigned int)wctx->unc_bitssize); // biSizeImage\n\n\tif(wctx->img->density_code==IW_DENSITY_UNITS_PER_METER) {\n\t\tdens_x = (unsigned int)(0.5+wctx->img->density_x);\n\t\tdens_y = (unsigned int)(0.5+wctx->img->density_y);\n\t}\n\telse {\n\t\tdens_x = dens_y = 2835;\n\t}\n\tiw_set_ui32le(&header[24],dens_x); // biXPelsPerMeter\n\tiw_set_ui32le(&header[28],dens_y); // biYPelsPerMeter\n\n\tiw_set_ui32le(&header[32],wctx->palentries);    // biClrUsed\n\t//iw_set_ui32le(&header[36],0);    // biClrImportant\n\tiwbmp_write(wctx,header,40);\n\treturn 1;\n}\n\nstatic int iwbmp_write_bmp_v45header_fields(struct iwbmpwcontext *wctx)\n{\n\tiw_byte header[124];\n\tunsigned int intent_bmp_style;\n\n\tiw_zeromem(header,sizeof(header));\n\n\tif(wctx->uses_bitfields) {\n\t\tiw_set_ui32le(&header[40],wctx->bf_mask[0]);\n\t\tiw_set_ui32le(&header[44],wctx->bf_mask[1]);\n\t\tiw_set_ui32le(&header[48],wctx->bf_mask[2]);\n\t\tiw_set_ui32le(&header[52],wctx->bf_mask[3]);\n\t}\n\n\t// Colorspace Type\n\t// TODO: We could support CSTYPE_GAMMA by using LCS_CALIBRATED_RGB,\n\t// but documentation about how to do that is hard to find.\n\tif(wctx->csdescr.cstype==IW_CSTYPE_SRGB && !wctx->no_cslabel)\n\t\tiw_set_ui32le(&header[56],IWBMPCS_SRGB);\n\telse\n\t\tiw_set_ui32le(&header[56],IWBMPCS_DEVICE_RGB);\n\n\t// Intent\n\t//intent_bmp_style = 4; // Perceptual\n\t//if(wctx->csdescr.cstype==IW_CSTYPE_SRGB && !wctx->no_cslabel) {\n\tswitch(wctx->img->rendering_intent) {\n\tcase IW_INTENT_PERCEPTUAL: intent_bmp_style = 4; break;\n\tcase IW_INTENT_RELATIVE:   intent_bmp_style = 2; break;\n\tcase IW_INTENT_SATURATION: intent_bmp_style = 1; break;\n\tcase IW_INTENT_ABSOLUTE:   intent_bmp_style = 8; break;\n\tdefault: intent_bmp_style = 4;\n\t}\n\t//}\n\tiw_set_ui32le(&header[108],intent_bmp_style);\n\n\tiwbmp_write(wctx,&header[40],124-40);\n\treturn 1;\n}\n\nstatic int iwbmp_write_bmp_header(struct iwbmpwcontext *wctx)\n{\n\tif(wctx->bmpversion==2) {\n\t\treturn iwbmp_write_bmp_v2header(wctx);\n\t}\n\telse if(wctx->bmpversion==5) {\n\t\tif(!iwbmp_write_bmp_v3header(wctx)) return 0;\n\t\treturn iwbmp_write_bmp_v45header_fields(wctx);\n\t}\n\treturn iwbmp_write_bmp_v3header(wctx);\n}\n\n// Given wctx->maxcolor[*], sets -> bf_mask[*] and bf_amt_to_shift[*],\n// and sets wctx->bitcount (to 16 or 32).\nstatic int iwbmp_calc_bitfields_masks(struct iwbmpwcontext *wctx, int num_masks)\n{\n\tint k;\n\tint bits[4]; // R, G, B, A\n\tint tot_bits = 0;\n\n\tfor(k=0;k<num_masks;k++) {\n\t\tbits[k] = iw_max_color_to_bitdepth(wctx->maxcolor[k]);\n\t\ttot_bits += bits[k];\n\t}\n\n\tif(tot_bits > 32) {\n\t\tiw_set_error(wctx->ctx,\"Cannot write a BMP image in this color format\");\n\t\treturn 0;\n\t}\n\t\n\twctx->bitcount = (tot_bits>16) ? 32 : 16;\n\n\twctx->bf_amt_to_shift[0] = bits[1] + bits[2];\n\twctx->bf_amt_to_shift[1] = bits[2];\n\twctx->bf_amt_to_shift[2] = 0;\n\tif(num_masks>3) wctx->bf_amt_to_shift[3] =  bits[0] + bits[1] + bits[2];\n\n\tfor(k=0;k<num_masks;k++) {\n\t\twctx->bf_mask[k] = wctx->maxcolor[k] << wctx->bf_amt_to_shift[k];\n\t}\n\n\treturn 1;\n}\n\n// Write the BITFIELDS segment, and set the wctx->bf_amt_to_shift[] values.\nstatic int iwbmp_write_bitfields(struct iwbmpwcontext *wctx)\n{\n\tiw_byte buf[12];\n\tint k;\n\n\tif(wctx->bitcount!=16 && wctx->bitcount!=32) return 0;\n\n\tfor(k=0;k<3;k++) {\n\t\tiw_set_ui32le(&buf[4*k],wctx->bf_mask[k]);\n\t}\n\tiwbmp_write(wctx,buf,12);\n\treturn 1;\n}\n\nstatic void iwbmp_write_palette(struct iwbmpwcontext *wctx)\n{\n\tint i,k;\n\tiw_byte buf[4];\n\n\tif(wctx->palentries<1) return;\n\n\tbuf[3] = 0; // Reserved field; always 0.\n\n\tfor(i=0;i<wctx->palentries;i++) {\n\t\tif(i<wctx->pal->num_entries) {\n\t\t\tif(wctx->pal->entry[i].a == 0) {\n\t\t\t\t// A transparent color. Because of the way we handle writing\n\t\t\t\t// transparent BMP images, the first palette entry may be a\n\t\t\t\t// fully transparent color, whose index will not be used when\n\t\t\t\t// we write the image. But many apps will interpret our\n\t\t\t\t// \"transparent\" pixels as having color #0. So, set it to\n\t\t\t\t// the background label color if available, otherwise to an\n\t\t\t\t// arbitrary high-contrast color (magenta).\n\t\t\t\tif(wctx->img->has_bkgdlabel) {\n\t\t\t\t\tfor(k=0;k<3;k++) {\n\t\t\t\t\t\tbuf[k] = (iw_byte)iw_color_get_int_sample(&wctx->img->bkgdlabel,2-k,255);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\tbuf[0] = 255;\n\t\t\t\t\tbuf[1] = 0;\n\t\t\t\t\tbuf[2] = 255;\n\t\t\t\t}\n\t\t\t}\n\t\t\telse {\n\t\t\t\tbuf[0] = wctx->pal->entry[i].b;\n\t\t\t\tbuf[1] = wctx->pal->entry[i].g;\n\t\t\t\tbuf[2] = wctx->pal->entry[i].r;\n\t\t\t}\n\t\t}\n\t\telse {\n\t\t\tbuf[0] = buf[1] = buf[2] = 0;\n\t\t}\n\t\tif(wctx->bmpversion==2)\n\t\t\tiwbmp_write(wctx,buf,3); // v2 BMPs don't have the 'reserved' field.\n\t\telse\n\t\t\tiwbmp_write(wctx,buf,4);\n\t}\n}\n\nstruct rle_context {\n\tstruct iw_context *ctx;\n\tstruct iwbmpwcontext *wctx;\n\tconst iw_byte *srcrow;\n\n\tsize_t img_width;\n\tint cur_row; // current row; 0=top (last)\n\n\t// Position in srcrow of the first byte that hasn't been written to the\n\t// output file\n\tsize_t pending_data_start;\n\n\t// Current number of uncompressible bytes that haven't been written yet\n\t// (starting at pending_data_start)\n\tsize_t unc_len;\n\n\t// Current number of identical bytes that haven't been written yet\n\t// (starting at pending_data_start+unc_len)\n\tsize_t run_len;\n\n\t// The value of the bytes referred to by run_len.\n\t// Valid if run_len>0.\n\tiw_byte run_byte;\n\n\tsize_t total_bytes_written; // Bytes written, after compression\n};\n\n//============================ RLE8 encoder ============================\n\n// TODO: The RLE8 and RLE4 encoders are more different than they should be.\n// The RLE8 encoder could probably be made more similar to the (more\n// complicated) RLE4 encoder.\n\nstatic void rle8_write_unc(struct rle_context *rlectx)\n{\n\tsize_t i;\n\tiw_byte dstbuf[2];\n\n\tif(rlectx->unc_len<1) return;\n\tif(rlectx->unc_len>=3 && (rlectx->unc_len&1)) {\n\t\tiw_set_error(rlectx->ctx,\"Internal: RLE encode error 4\");\n\t\treturn;\n\t}\n\tif(rlectx->unc_len>254) {\n\t\tiw_set_error(rlectx->ctx,\"Internal: RLE encode error 5\");\n\t\treturn;\n\t}\n\n\tif(rlectx->unc_len<3) {\n\t\t// The minimum length for a noncompressed run is 3. For shorter runs\n\t\t// write them \"compressed\".\n\t\tfor(i=0;i<rlectx->unc_len;i++) {\n\t\t\tdstbuf[0] = 0x01;  // count\n\t\t\tdstbuf[1] = rlectx->srcrow[i+rlectx->pending_data_start]; // value\n\t\t\tiwbmp_write(rlectx->wctx,dstbuf,2);\n\t\t\trlectx->total_bytes_written+=2;\n\t\t}\n\t}\n\telse {\n\t\tdstbuf[0] = 0x00;\n\t\tdstbuf[1] = (iw_byte)rlectx->unc_len;\n\t\tiwbmp_write(rlectx->wctx,dstbuf,2);\n\t\trlectx->total_bytes_written+=2;\n\t\tiwbmp_write(rlectx->wctx,&rlectx->srcrow[rlectx->pending_data_start],rlectx->unc_len);\n\t\trlectx->total_bytes_written+=rlectx->unc_len;\n\t\tif(rlectx->unc_len&0x1) {\n\t\t\t// Need a padding byte if the length was odd. (This shouldn't\n\t\t\t// happen, because we never write odd-length UNC segments.)\n\t\t\tdstbuf[0] = 0x00;\n\t\t\tiwbmp_write(rlectx->wctx,dstbuf,1);\n\t\t\trlectx->total_bytes_written+=1;\n\t\t}\n\t}\n\n\trlectx->pending_data_start+=rlectx->unc_len;\n\trlectx->unc_len=0;\n}\n\nstatic void rle8_write_unc_and_run(struct rle_context *rlectx)\n{\n\tiw_byte dstbuf[2];\n\n\trle8_write_unc(rlectx);\n\n\tif(rlectx->run_len<1) {\n\t\treturn;\n\t}\n\tif(rlectx->run_len>255) {\n\t\tiw_set_error(rlectx->ctx,\"Internal: RLE encode error 6\");\n\t\treturn;\n\t}\n\n\tdstbuf[0] = (iw_byte)rlectx->run_len;\n\tdstbuf[1] = rlectx->run_byte;\n\tiwbmp_write(rlectx->wctx,dstbuf,2);\n\trlectx->total_bytes_written+=2;\n\n\trlectx->pending_data_start+=rlectx->run_len;\n\trlectx->run_len=0;\n}\n\nstatic void rle_write_trns(struct rle_context *rlectx, int num_trns)\n{\n\tiw_byte dstbuf[4];\n\tint num_remaining = num_trns;\n\tint num_to_write;\n\n\twhile(num_remaining>0) {\n\t\tnum_to_write = num_remaining;\n\t\tif(num_to_write>255) num_to_write=255;\n\t\tdstbuf[0]=0x00; // 00 02 = Delta\n\t\tdstbuf[1]=0x02;\n\t\tdstbuf[2]=(iw_byte)num_to_write; // X offset\n\t\tdstbuf[3]=0x00; // Y offset\n\t\tiwbmp_write(rlectx->wctx,dstbuf,4);\n\t\trlectx->total_bytes_written+=4;\n\t\tnum_remaining -= num_to_write;\n\t}\n\trlectx->pending_data_start += num_trns;\n}\n\n// The RLE format used by BMP files is pretty simple, but I've gone to some\n// effort to optimize it for file size, which makes for a complicated\n// algorithm.\n// The overall idea:\n// We defer writing data until certain conditions are met. In the meantime,\n// we split the unwritten data into two segments:\n//  \"UNC\": data classified as uncompressible\n//  \"RUN\": data classified as compressible. All bytes in this segment must be\n//    identical.\n// The RUN segment always follows the UNC segment.\n// For each byte in turn, we examine the current state, and do one of a number\n// of things, such as:\n//    - add it to RUN\n//    - add it to UNC (if there is no RUN)\n//    - move RUN into UNC, then add it to RUN (or to UNC)\n//    - move UNC and RUN to the file, then make it the new RUN\n// Then, we check to see if we've accumulated enough data that something needs\n// to be written out.\nstatic int rle8_compress_row(struct rle_context *rlectx)\n{\n\tsize_t i;\n\tiw_byte dstbuf[2];\n\tiw_byte next_byte;\n\tint next_pix_is_trns;\n\tint num_trns = 0; // number of consecutive transparent pixels seen\n\tint retval = 0;\n\n\trlectx->pending_data_start=0;\n\trlectx->unc_len=0;\n\trlectx->run_len=0;\n\n\tfor(i=0;i<rlectx->img_width;i++) {\n\n\t\t// Read the next byte.\n\t\tnext_byte = rlectx->srcrow[i];\n\n\t\tnext_pix_is_trns = (rlectx->wctx->pal->entry[next_byte].a==0);\n\n\t\tif(num_trns>0 && !next_pix_is_trns) {\n\t\t\trle_write_trns(rlectx,num_trns);\n\t\t\tnum_trns=0;\n\t\t}\n\t\telse if(next_pix_is_trns) {\n\t\t\tif (rlectx->unc_len>0 || rlectx->run_len>0) {\n\t\t\t\trle8_write_unc_and_run(rlectx);\n\t\t\t}\n\t\t\tnum_trns++;\n\t\t\tcontinue;\n\t\t}\n\n\t\t// --------------------------------------------------------------\n\t\t// Add the byte we just read to either the UNC or the RUN data.\n\n\t\tif(rlectx->run_len>0 && next_byte==rlectx->run_byte) {\n\t\t\t// Byte fits in the current run; add it.\n\t\t\trlectx->run_len++;\n\t\t}\n\t\telse if(rlectx->run_len==0) {\n\t\t\t// We don't have a RUN, so we can put this byte there.\n\t\t\trlectx->run_len = 1;\n\t\t\trlectx->run_byte = next_byte;\n\t\t}\n\t\telse if(rlectx->unc_len==0 && rlectx->run_len==1) {\n\t\t\t// We have one previous byte, and it's different from this one.\n\t\t\t// Move it to UNC, and make this one the RUN.\n\t\t\trlectx->unc_len++;\n\t\t\trlectx->run_byte = next_byte;\n\t\t}\n\t\telse if(rlectx->unc_len>0 && rlectx->run_len<(rlectx->unc_len==1 ? 3U : 4U)) {\n\t\t\t// We have a run, but it's not long enough to be beneficial.\n\t\t\t// Convert it to uncompressed bytes.\n\t\t\t// A good rule is that a run length of 4 or more (3 or more if\n\t\t\t// unc_len=1) should always be run-legth encoded.\n\t\t\trlectx->unc_len += rlectx->run_len;\n\t\t\trlectx->run_len = 0;\n\t\t\t// If UNC is now odd and >1, add the next byte to it to make it even.\n\t\t\t// Otherwise, add it to RUN.\n\t\t\tif(rlectx->unc_len>=3 && (rlectx->unc_len&0x1)) {\n\t\t\t\trlectx->unc_len++;\n\t\t\t}\n\t\t\telse {\n\t\t\t\trlectx->run_len = 1;\n\t\t\t\trlectx->run_byte = next_byte;\n\t\t\t}\n\t\t}\n\t\telse {\n\t\t\t// Nowhere to put the byte: write out everything, and start fresh.\n\t\t\trle8_write_unc_and_run(rlectx);\n\t\t\trlectx->run_len = 1;\n\t\t\trlectx->run_byte = next_byte;\n\t\t}\n\n\t\t// --------------------------------------------------------------\n\t\t// If we hit certain high water marks, write out the current data.\n\n\t\tif(rlectx->unc_len>=254) {\n\t\t\t// Our maximum size for an UNC segment.\n\t\t\trle8_write_unc(rlectx);\n\t\t}\n\t\telse if(rlectx->unc_len>0 && (rlectx->unc_len+rlectx->run_len)>254) {\n\t\t\t// It will not be possible to coalesce the RUN into the UNC (it\n\t\t\t// would be too big) so write out the UNC.\n\t\t\trle8_write_unc(rlectx);\n\t\t}\n\t\telse if(rlectx->run_len>=255) {\n\t\t\t// The maximum size for an RLE segment.\n\t\t\trle8_write_unc_and_run(rlectx);\n\t\t}\n\n\t\t// --------------------------------------------------------------\n\t\t// Sanity checks. These can be removed if we're sure the algorithm\n\t\t// is bug-free.\n\n\t\t// We don't allow unc_len to be odd (except temporarily), except\n\t\t// that it can be 1.\n\t\t// What's special about 1 is that if we add another byte to it, it\n\t\t// increases the cost. For 3,5,...,253, we can add another byte for\n\t\t// free, so we should never fail to do that.\n\t\tif((rlectx->unc_len&0x1) && rlectx->unc_len!=1) {\n\t\t\tiw_set_errorf(rlectx->ctx,\"Internal: BMP RLE encode error 1\");\n\t\t\tgoto done;\n\t\t}\n\n\t\t// unc_len can be at most 252 at this point.\n\t\t// If it were 254, it should have been written out already.\n\t\tif(rlectx->unc_len>252) {\n\t\t\tiw_set_error(rlectx->ctx,\"Internal: BMP RLE encode error 2\");\n\t\t\tgoto done;\n\t\t}\n\n\t\t// run_len can be at most 254 at this point.\n\t\t// If it were 255, it should have been written out already.\n\t\tif(rlectx->run_len>254) {\n\t\t\tiw_set_error(rlectx->ctx,\"Internal: BMP RLE encode error 3\");\n\t\t\tgoto done;\n\t\t}\n\t}\n\n\t// End of row. Write out anything left over.\n\trle8_write_unc_and_run(rlectx);\n\n\t// Write an end-of-line marker (0 0), or if this is the last row,\n\t// an end-of-bitmap marker (0 1).\n\tdstbuf[0]=0x00;\n\tdstbuf[1]= (rlectx->cur_row==0)? 0x01 : 0x00;\n\tiwbmp_write(rlectx->wctx,dstbuf,2);\n\trlectx->total_bytes_written+=2;\n\n\tretval = 1;\n\ndone:\n\treturn retval;\n}\n\n//============================ RLE4 encoder ============================\n\n// Calculate the most efficient way to split a run of uncompressible pixels.\n// This only finds the first place to split the run. If the run is still\n// over 255 pixels, call it again to find the next split.\nstatic size_t rle4_get_best_unc_split(size_t n)\n{\n\t// For <=255 pixels, we can never do better than storing it as one run.\n\tif(n<=255) return n;\n\n\t// With runs of 252, we can store 252/128 = 1.96875 pixels/byte.\n\t// With runs of 255, we can store 255/130 = 1.96153 pixels/byte.\n\t// Hence, using runs of 252 is the most efficient way to store a large\n\t// number of uncompressible pixels.\n\t// (Lengths other than 252 or 255 are no help.)\n\t// However, there are three exceptional cases where, if we split at 252,\n\t// the most efficient encoding will no longer be possible:\n\tif(n==257 || n==510 || n==765) return 255;\n\n\treturn 252;\n}\n\n// Returns the incremental cost of adding a pixel to the current UNC\n// (which is always either 0 or 2).\n// To derive this function, I calculated the optimal cost of every length,\n// and enumerated the exceptions to the (n%4)?0:2 rule.\n// The exceptions are mostly caused by the cases where\n// rle4_get_best_unc_split() returns 255 instead of 252.\nstatic int rle4_get_incr_unc_cost(struct rle_context *rlectx)\n{\n\tint n;\n\tint m;\n\n\tn = (int)rlectx->unc_len;\n\n\tif(n==2 || n==255 || n==257 || n==507 || n==510) return 2;\n\tif(n==256 || n==508) return 0;\n\n\tif(n>=759) {\n\t\tm = n%252;\n\t\tif(m==3 || m==6 || m==9) return 2;\n\t\tif(m==4 || m==8) return 0;\n\t}\n\n\treturn (n%4)?0:2;\n}\n\nstatic void rle4_write_unc(struct rle_context *rlectx)\n{\n\tiw_byte dstbuf[128];\n\tsize_t pixels_to_write;\n\tsize_t bytes_to_write;\n\n\tif(rlectx->unc_len<1) return;\n\n\t// Note that, unlike the RLE8 encoder, we allow this function to be called\n\t// with uncompressed runs of arbitrary length.\n\n\twhile(rlectx->unc_len>0) {\n\t\tpixels_to_write = rle4_get_best_unc_split(rlectx->unc_len);\n\n\t\tif(pixels_to_write<3) {\n\t\t\t// The minimum length for an uncompressed run is 3. For shorter runs\n\t\t\t// write them \"compressed\".\n\t\t\tdstbuf[0] = (iw_byte)pixels_to_write;\n\t\t\tdstbuf[1] = (rlectx->srcrow[rlectx->pending_data_start]<<4);\n\t\t\tif(pixels_to_write>1)\n\t\t\t\tdstbuf[1] |= (rlectx->srcrow[rlectx->pending_data_start+1]);\n\n\t\t\t// The actual writing will occur below. Just indicate how many bytes\n\t\t\t// of dstbuf[] to write.\n\t\t\tbytes_to_write = 2;\n\t\t}\n\t\telse {\n\t\t\tsize_t i;\n\n\t\t\t// Write the length of the uncompressed run.\n\t\t\tdstbuf[0] = 0x00;\n\t\t\tdstbuf[1] = (iw_byte)pixels_to_write;\n\t\t\tiwbmp_write(rlectx->wctx,dstbuf,2);\n\t\t\trlectx->total_bytes_written+=2;\n\n\t\t\t// Put the data to write in dstbuf[].\n\t\t\tbytes_to_write = 2*((pixels_to_write+3)/4);\n\t\t\tiw_zeromem(dstbuf,bytes_to_write);\n\n\t\t\tfor(i=0;i<pixels_to_write;i++) {\n\t\t\t\tif(i&0x1) dstbuf[i/2] |= rlectx->srcrow[rlectx->pending_data_start+i];\n\t\t\t\telse dstbuf[i/2] = rlectx->srcrow[rlectx->pending_data_start+i]<<4;\n\t\t\t}\n\t\t}\n\n\t\tiwbmp_write(rlectx->wctx,dstbuf,bytes_to_write);\n\t\trlectx->total_bytes_written += bytes_to_write;\n\t\trlectx->unc_len -= pixels_to_write;\n\t\trlectx->pending_data_start += pixels_to_write;\n\t}\n}\n\nstatic void rle4_write_unc_and_run(struct rle_context *rlectx)\n{\n\tiw_byte dstbuf[2];\n\n\trle4_write_unc(rlectx);\n\n\tif(rlectx->run_len<1) {\n\t\treturn;\n\t}\n\tif(rlectx->run_len>255) {\n\t\tiw_set_error(rlectx->ctx,\"Internal: RLE encode error 6\");\n\t\treturn;\n\t}\n\n\tdstbuf[0] = (iw_byte)rlectx->run_len;\n\tdstbuf[1] = rlectx->run_byte;\n\tiwbmp_write(rlectx->wctx,dstbuf,2);\n\trlectx->total_bytes_written+=2;\n\n\trlectx->pending_data_start+=rlectx->run_len;\n\trlectx->run_len=0;\n}\n\n// Should we move the pending compressible data to the \"uncompressed\"\n// segment (return 1), or should we write it to disk as a compressed run of\n// pixels (0)?\nstatic int ok_to_move_to_unc(struct rle_context *rlectx)\n{\n\t// This logic is probably not optimal in every case.\n\t// One possible improvement might be to adjust the thresholds when\n\t// unc_len+run_len is around 255 or higher.\n\t// Other improvements might require looking ahead at pixels we haven't\n\t// read yet.\n\n\tif(rlectx->unc_len==0) {\n\t\treturn (rlectx->run_len<4);\n\t}\n\telse if(rlectx->unc_len<=2) {\n\t\treturn (rlectx->run_len<6);\n\t}\n\telse {\n\t\treturn (rlectx->run_len<8);\n\t}\n\treturn 0;\n}\n\nstatic int rle4_compress_row(struct rle_context *rlectx)\n{\n\tsize_t i;\n\tiw_byte dstbuf[2];\n\tiw_byte next_pix;\n\tint next_pix_is_trns;\n\tint num_trns = 0; // number of consecutive transparent pixels seen\n\tint retval = 0;\n\tiw_byte tmpb;\n\n\trlectx->pending_data_start=0;\n\trlectx->unc_len=0;\n\trlectx->run_len=0;\n\n\tfor(i=0;i<rlectx->img_width;i++) {\n\n\t\t// Read the next pixel\n\t\tnext_pix = rlectx->srcrow[i];\n\n\t\tnext_pix_is_trns = (rlectx->wctx->pal->entry[next_pix].a==0);\n\t\tif(num_trns>0 && !next_pix_is_trns) {\n\t\t\trle_write_trns(rlectx,num_trns);\n\t\t\tnum_trns=0;\n\t\t}\n\t\telse if(next_pix_is_trns) {\n\t\t\tif (rlectx->unc_len>0 || rlectx->run_len>0) {\n\t\t\t\trle4_write_unc_and_run(rlectx);\n\t\t\t}\n\t\t\tnum_trns++;\n\t\t\tcontinue;\n\t\t}\n\n\t\t// --------------------------------------------------------------\n\t\t// Add the pixel we just read to either the UNC or the RUN data.\n\n\t\tif(rlectx->run_len==0) {\n\t\t\t// We don't have a RUN, so we can put this pixel there.\n\t\t\trlectx->run_len = 1;\n\t\t\trlectx->run_byte = next_pix<<4;\n\t\t}\n\t\telse if(rlectx->run_len==1) {\n\t\t\t// If the run is 1, we can always add a 2nd pixel\n\t\t\trlectx->run_byte |= next_pix;\n\t\t\trlectx->run_len++;\n\t\t}\n\t\telse if(rlectx->run_len>=2 && (rlectx->run_len&1)==0 && next_pix==(rlectx->run_byte>>4)) {\n\t\t\t// pixel fits in the current run; add it.\n\t\t\trlectx->run_len++;\n\t\t}\n\t\telse if(rlectx->run_len>=3 && (rlectx->run_len&1) && next_pix==(rlectx->run_byte&0x0f)) {\n\t\t\t// pixel fits in the current run; add it.\n\t\t\trlectx->run_len++;\n\t\t}\n\t\telse if(rlectx->unc_len==0 && rlectx->run_len==2) {\n\t\t\t// We have one previous byte, and it's different from this one.\n\t\t\t// Move it to UNC, and make this one the RUN.\n\t\t\trlectx->unc_len+=rlectx->run_len;\n\t\t\trlectx->run_byte = next_pix<<4;\n\t\t\trlectx->run_len = 1;\n\t\t}\n\t\telse if(ok_to_move_to_unc(rlectx)) {\n\t\t\t// We have a compressible run, but we think it's not long enough to be\n\t\t\t// beneficial. Convert it to uncompressed bytes -- except for the last\n\t\t\t// pixel, which can be left in the run.\n\t\t\trlectx->unc_len += rlectx->run_len-1;\n \n\t\t\tif((rlectx->run_len&1)==0)\n\t\t\t\trlectx->run_byte = (rlectx->run_byte&0x0f)<<4;\n\t\t\telse\n\t\t\t\trlectx->run_byte = (rlectx->run_byte&0xf0);\n\n\t\t\t// Put the next byte in RLE. (It might get moved to UNC, below.)\n\t\t\trlectx->run_len = 2;\n\t\t\trlectx->run_byte |= next_pix;\n\t\t}\n\t\telse {\n\t\t\t// Nowhere to put the byte: write out everything, and start fresh.\n\t\t\trle4_write_unc_and_run(rlectx);\n\t\t\trlectx->run_len = 1;\n\t\t\trlectx->run_byte = next_pix<<4;\n\t\t}\n\n\t\t// --------------------------------------------------------------\n\t\t// If any RUN bytes that can be added to UNC for free, do so.\n\t\twhile(rlectx->unc_len>0 && rlectx->run_len>0 && rle4_get_incr_unc_cost(rlectx)==0) {\n\t\t\trlectx->unc_len++;\n\t\t\trlectx->run_len--;\n\t\t\ttmpb = rlectx->run_byte;\n\t\t\t// Reverse the two pixels stored in run_byte.\n\t\t\trlectx->run_byte = (tmpb>>4) | ((tmpb&0x0f)<<4);\n\t\t\tif(rlectx->run_len==1) rlectx->run_byte &= 0xf0;\n\t\t}\n\n\t\t// --------------------------------------------------------------\n\t\t// If we hit certain high water marks, write out the current data.\n\n\t\tif(rlectx->run_len>=255) {\n\t\t\t// The maximum size for an RLE segment.\n\t\t\trle4_write_unc_and_run(rlectx);\n\t\t}\n\n\t\t// --------------------------------------------------------------\n\t\t// Sanity check(s). This can be removed if we're sure the algorithm\n\t\t// is bug-free.\n\n\t\t// run_len can be at most 254 at this point.\n\t\t// If it were 255, it should have been written out already.\n\t\tif(rlectx->run_len>255) {\n\t\t\tiw_set_error(rlectx->ctx,\"Internal: BMP RLE encode error 3\");\n\t\t\tgoto done;\n\t\t}\n\t}\n\n\t// End of row. Write out anything left over.\n\trle4_write_unc_and_run(rlectx);\n\n\t// Write an end-of-line marker (0 0), or if this is the last row,\n\t// an end-of-bitmap marker (0 1).\n\tdstbuf[0]=0x00;\n\tdstbuf[1]= (rlectx->cur_row==0)? 0x01 : 0x00;\n\tiwbmp_write(rlectx->wctx,dstbuf,2);\n\trlectx->total_bytes_written+=2;\n\n\tretval = 1;\n\ndone:\n\treturn retval;\n}\n\n//======================================================================\n\n// Seek back and write the \"file size\" and \"bits size\" fields.\nstatic int rle_patch_file_size(struct iwbmpwcontext *wctx,size_t rlesize)\n{\n\tiw_byte buf[4];\n\tsize_t fileheader_size;\n\tint ret;\n\n\tif(!wctx->iodescr->seek_fn) {\n\t\tiw_set_error(wctx->ctx,\"Writing compressed BMP requires a seek function\");\n\t\treturn 0;\n\t}\n\n\tif(wctx->include_file_header) {\n\t\t// Patch the file size in the file header\n\t\tret=(*wctx->iodescr->seek_fn)(wctx->ctx,wctx->iodescr,2,SEEK_SET);\n\t\tif(!ret) return 0;\n\t\tiw_set_ui32le(buf,(unsigned int)(14+wctx->header_size+wctx->bitfields_size+wctx->palsize+rlesize));\n\t\tiwbmp_write(wctx,buf,4);\n\t\tfileheader_size = 14;\n\t}\n\telse {\n\t\tfileheader_size = 0;\n\t}\n\n\t// Patch the \"bits\" size\n\tret=(*wctx->iodescr->seek_fn)(wctx->ctx,wctx->iodescr,fileheader_size+20,SEEK_SET);\n\tif(!ret) return 0;\n\tiw_set_ui32le(buf,(unsigned int)rlesize);\n\tiwbmp_write(wctx,buf,4);\n\n\t(*wctx->iodescr->seek_fn)(wctx->ctx,wctx->iodescr,0,SEEK_END);\n\treturn 1;\n}\n\nstatic int iwbmp_write_pixels_compressed(struct iwbmpwcontext *wctx,\n\tstruct iw_image *img)\n{\n\tstruct rle_context rlectx;\n\tint j;\n\tint retval = 0;\n\n\tiw_zeromem(&rlectx,sizeof(struct rle_context));\n\n\trlectx.ctx = wctx->ctx;\n\trlectx.wctx = wctx;\n\trlectx.total_bytes_written = 0;\n\trlectx.img_width = img->width;\n\n\tfor(j=img->height-1;j>=0;j--) {\n\t\t// Compress and write a row of pixels\n\t\trlectx.srcrow = &img->pixels[j*img->bpr];\n\t\trlectx.cur_row = j;\n\n\t\tif(wctx->bitcount==4) {\n\t\t\tif(!rle4_compress_row(&rlectx)) goto done;\n\t\t}\n\t\telse if(wctx->bitcount==8) {\n\t\t\tif(!rle8_compress_row(&rlectx)) goto done;\n\t\t}\n\t\telse {\n\t\t\tgoto done;\n\t\t}\n\t}\n\n\t// Back-patch the 'file size' and 'bits size' fields\n\tif(!rle_patch_file_size(wctx,rlectx.total_bytes_written)) goto done;\n\n\tretval = 1;\ndone:\n\treturn retval;\n}\n\nstatic void iwbmp_write_pixels_uncompressed(struct iwbmpwcontext *wctx,\n\tstruct iw_image *img)\n{\n\tint j;\n\tiw_byte *dstrow = NULL;\n\tconst iw_byte *srcrow;\n\n\tdstrow = iw_mallocz(wctx->ctx,wctx->unc_dst_bpr);\n\tif(!dstrow) goto done;\n\n\tfor(j=img->height-1;j>=0;j--) {\n\t\tsrcrow = &img->pixels[j*img->bpr];\n\t\tswitch(wctx->bitcount) {\n\t\tcase 32: bmpw_convert_row_16_32(wctx,srcrow,dstrow,img->width); break;\n\t\tcase 24: bmpw_convert_row_24(wctx,srcrow,dstrow,img->width); break;\n\t\tcase 16: bmpw_convert_row_16_32(wctx,srcrow,dstrow,img->width); break;\n\t\tcase 8: bmpw_convert_row_8(srcrow,dstrow,img->width); break;\n\t\tcase 4: bmpw_convert_row_4(srcrow,dstrow,img->width); break;\n\t\tcase 1: bmpw_convert_row_1(srcrow,dstrow,img->width); break;\n\t\t}\n\t\tiwbmp_write(wctx,dstrow,wctx->unc_dst_bpr);\n\t}\n\ndone:\n\tif(dstrow) iw_free(wctx->ctx,dstrow);\n\treturn;\n}\n\n// 0 = no transparency\n// 1 = binary transparency\n// 2 = partial transparency\nstatic int check_palette_transparency(const struct iw_palette *p)\n{\n\tint i;\n\tint retval = 0;\n\n\tfor(i=0;i<p->num_entries;i++) {\n\t\tif(p->entry[i].a!=255) retval=1;\n\t\tif(p->entry[i].a!=255 && p->entry[i].a!=0) return 2;\n\t}\n\treturn retval;\n}\n\n// Do some preparations needed to write a 16-bit or 32-bit BMP.\nstatic int setup_16_32bit(struct iwbmpwcontext *wctx,\n\tint mcc_r, int mcc_g, int mcc_b, int mcc_a)\n{\n\tint has_alpha;\n\n\thas_alpha = IW_IMGTYPE_HAS_ALPHA(wctx->img->imgtype);\n\n\tif(wctx->bmpversion<3) {\n\t\tiw_set_errorf(wctx->ctx,\"Bit depth incompatible with BMP version %d\",\n\t\t\twctx->bmpversion);\n\t\treturn 0;\n\t}\n\n\tif(has_alpha && wctx->bmpversion<5) {\n\t\tiw_set_error(wctx->ctx,\"Internal: Attempt to write v3 16- or 32-bit image with transparency\");\n\t\treturn 0;\n\t}\n\n\t// Make our own copy of the max color codes, so that we don't have to\n\t// do \"if(grayscale)\" so much.\n\twctx->maxcolor[0] = mcc_r;\n\twctx->maxcolor[1] = mcc_g;\n\twctx->maxcolor[2] = mcc_b;\n\tif(has_alpha) wctx->maxcolor[3] = mcc_a;\n\n\tif(!iwbmp_calc_bitfields_masks(wctx,has_alpha?4:3)) return 0;\n\n\tif(mcc_r==31 && mcc_g==31 && mcc_b==31 && !has_alpha) {\n\t\t// For the default 5-5-5, set the 'compression' to BI_RGB\n\t\t// instead of BITFIELDS, and don't write a BITFIELDS segment\n\t\t// (or for v5 BMP, don't set the Mask fields).\n\t\twctx->bitfields_size = 0;\n\t}\n\telse {\n\t\twctx->uses_bitfields = 1;\n\t\twctx->bitfields_size = (wctx->bmpversion==3) ? 12 : 0;\n\t}\n\treturn 1;\n}\n\nstatic int iwbmp_write_main(struct iwbmpwcontext *wctx)\n{\n\tstruct iw_image *img;\n\tint cmpr_req;\n\tint retval = 0;\n\tint x;\n\tconst char *optv;\n\n\timg = wctx->img;\n\n\twctx->bmpversion = 0;\n\toptv = iw_get_option(wctx->ctx, \"bmp:version\");\n\tif(optv) {\n\t\twctx->bmpversion = iw_parse_int(optv);\n\t}\n\n\tif(wctx->bmpversion==0) wctx->bmpversion=3;\n\tif(wctx->bmpversion==4) {\n\t\tiw_warning(wctx->ctx,\"Writing BMP v4 is not supported; using v3 instead\");\n\t\twctx->bmpversion=3;\n\t}\n\tif(wctx->bmpversion!=2 && wctx->bmpversion!=3 && wctx->bmpversion!=5) {\n\t\tiw_set_errorf(wctx->ctx,\"Unsupported BMP version: %d\",wctx->bmpversion);\n\t\tgoto done;\n\t}\n\n\tif(wctx->bmpversion>=3)\n\t\tcmpr_req = iw_get_value(wctx->ctx,IW_VAL_COMPRESSION);\n\telse\n\t\tcmpr_req = IW_COMPRESSION_NONE;\n\n\tif(wctx->bmpversion==2)\n\t\twctx->header_size = 12;\n\telse if(wctx->bmpversion==5)\n\t\twctx->header_size = 124;\n\telse\n\t\twctx->header_size = 40;\n\n\twctx->no_cslabel = iw_get_value(wctx->ctx,IW_VAL_NO_CSLABEL);\n\n\t// If any kind of compression was requested, use RLE if possible.\n\tif(cmpr_req==IW_COMPRESSION_AUTO || cmpr_req==IW_COMPRESSION_NONE)\n\t\tcmpr_req = IW_COMPRESSION_NONE;\n\telse\n\t\tcmpr_req = IW_COMPRESSION_RLE;\n\n\tif(img->imgtype==IW_IMGTYPE_RGB) {\n\t\tif(img->reduced_maxcolors) {\n\t\t\tif(!setup_16_32bit(wctx,img->maxcolorcode[IW_CHANNELTYPE_RED],\n\t\t\t\timg->maxcolorcode[IW_CHANNELTYPE_GREEN],\n\t\t\t\timg->maxcolorcode[IW_CHANNELTYPE_BLUE],0))\n\t\t\t{\n\t\t\t\tgoto done;\n\t\t\t}\n\t\t}\n\t\telse {\n\t\t\twctx->bitcount=24;\n\t\t}\n\t}\n\telse if(img->imgtype==IW_IMGTYPE_PALETTE) {\n\t\tif(!wctx->pal) goto done;\n\n\t\tx = check_palette_transparency(wctx->pal);\n\n\t\tif(x!=0 && wctx->bmpversion<3) {\n\t\t\tiw_set_error(wctx->ctx,\"Cannot save as a transparent BMP: Incompatible BMP version\");\n\t\t\tgoto done;\n\t\t}\n\t\telse if(x==2) {\n\t\t\tiw_set_error(wctx->ctx,\"Cannot save this image as a transparent BMP: Has partial transparency\");\n\t\t\tgoto done;\n\t\t}\n\t\telse if(x!=0 && cmpr_req!=IW_COMPRESSION_RLE) {\n\t\t\tiw_set_error(wctx->ctx,\"Cannot save as a transparent BMP: RLE compression required\");\n\t\t\tgoto done;\n\t\t}\n\n\t\tif(wctx->pal->num_entries<=2 && cmpr_req!=IW_COMPRESSION_RLE)\n\t\t\twctx->bitcount=1;\n\t\telse if(wctx->pal->num_entries<=16)\n\t\t\twctx->bitcount=4;\n\t\telse\n\t\t\twctx->bitcount=8;\n\t}\n\telse if(img->imgtype==IW_IMGTYPE_RGBA) {\n\t\tif(img->reduced_maxcolors) {\n\t\t\tif(!setup_16_32bit(wctx,img->maxcolorcode[IW_CHANNELTYPE_RED],\n\t\t\t\timg->maxcolorcode[IW_CHANNELTYPE_GREEN],\n\t\t\t\timg->maxcolorcode[IW_CHANNELTYPE_BLUE],\n\t\t\t\timg->maxcolorcode[IW_CHANNELTYPE_ALPHA]))\n\t\t\t{\n\t\t\t\tgoto done;\n\t\t\t}\n\t\t}\n\t\telse {\n\t\t\tif(!setup_16_32bit(wctx,255,255,255,255)) {\n\t\t\t\tgoto done;\n\t\t\t}\n\t\t}\n\t}\n\telse if(img->imgtype==IW_IMGTYPE_GRAYA) {\n\t\tif(img->reduced_maxcolors) {\n\t\t\tif(!setup_16_32bit(wctx,img->maxcolorcode[IW_CHANNELTYPE_GRAY],\n\t\t\t\timg->maxcolorcode[IW_CHANNELTYPE_GRAY],\n\t\t\t\timg->maxcolorcode[IW_CHANNELTYPE_GRAY],\n\t\t\t\timg->maxcolorcode[IW_CHANNELTYPE_ALPHA]))\n\t\t\t{\n\t\t\t\tgoto done;\n\t\t\t}\n\t\t}\n\t\telse {\n\t\t\tif(!setup_16_32bit(wctx,255,255,255,255)) {\n\t\t\t\tgoto done;\n\t\t\t}\n\t\t}\n\t}\n\telse if(img->imgtype==IW_IMGTYPE_GRAY) {\n\t\tif(img->reduced_maxcolors) {\n\t\t\tif(img->maxcolorcode[IW_CHANNELTYPE_GRAY]<=1023) {\n\t\t\t\tif(!setup_16_32bit(wctx,img->maxcolorcode[IW_CHANNELTYPE_GRAY],\n\t\t\t\t\timg->maxcolorcode[IW_CHANNELTYPE_GRAY],\n\t\t\t\t\timg->maxcolorcode[IW_CHANNELTYPE_GRAY],0))\n\t\t\t\t{\n\t\t\t\t\tgoto done;\n\t\t\t\t}\n\t\t\t}\n\t\t\telse {\n\t\t\t\tiw_set_error(wctx->ctx,\"Cannot write grayscale BMP at this bit depth\");\n\t\t\t\tgoto done;\n\t\t\t}\n\t\t}\n\t\telse {\n\t\t\t// We normally won't get here, because a grayscale image should have\n\t\t\t// been optimized and converted to a palette image.\n\t\t\t// But maybe that optimization was disabled.\n\t\t\twctx->bitcount=24;\n\t\t}\n\t}\n\telse {\n\t\tiw_set_error(wctx->ctx,\"Internal: Bad image type for BMP\");\n\t\tgoto done;\n\t}\n\n\tif(cmpr_req==IW_COMPRESSION_RLE && (wctx->bitcount==4 || wctx->bitcount==8)) {\n\t\twctx->compressed = 1;\n\t}\n\n\twctx->unc_dst_bpr = iwbmp_calc_bpr(wctx->bitcount,img->width);\n\twctx->unc_bitssize = wctx->unc_dst_bpr * img->height;\n\twctx->palentries = 0;\n\n\tif(wctx->pal) {\n\t\tif(wctx->bmpversion==2) {\n\t\t\twctx->palentries = 1<<wctx->bitcount;\n\t\t\twctx->palsize = wctx->palentries*3;\n\t\t}\n\t\telse {\n\t\t\tif(wctx->bitcount==1) {\n\t\t\t\t// The documentation says that if the bitdepth is 1, the palette\n\t\t\t\t// contains exactly two entries.\n\t\t\t\twctx->palentries=2;\n\t\t\t}\n\t\t\telse {\n\t\t\t\twctx->palentries = wctx->pal->num_entries;\n\t\t\t}\n\t\t\twctx->palsize = wctx->palentries*4;\n\t\t}\n\t}\n\n\t// File header\n\tiwbmp_write_file_header(wctx);\n\n\t// Bitmap header (\"BITMAPINFOHEADER\")\n\tif(!iwbmp_write_bmp_header(wctx)) {\n\t\tgoto done;\n\t}\n\n\tif(wctx->bitfields_size>0) {\n\t\tif(!iwbmp_write_bitfields(wctx)) goto done;\n\t}\n\n\t// Palette\n\tiwbmp_write_palette(wctx);\n\n\t// Pixels\n\tif(wctx->compressed) {\n\t\tif(!iwbmp_write_pixels_compressed(wctx,img)) goto done;\n\t}\n\telse {\n\t\tiwbmp_write_pixels_uncompressed(wctx,img);\n\t}\n\n\tretval = 1;\ndone:\n\treturn retval;\n}\n\nIW_IMPL(int) iw_write_bmp_file(struct iw_context *ctx, struct iw_iodescr *iodescr)\n{\n\tstruct iwbmpwcontext wctx;\n\tint retval=0;\n\tstruct iw_image img1;\n\n\tiw_zeromem(&img1,sizeof(struct iw_image));\n\n\tiw_zeromem(&wctx,sizeof(struct iwbmpwcontext));\n\n\twctx.ctx = ctx;\n\twctx.include_file_header = 1;\n\n\twctx.iodescr=iodescr;\n\n\tiw_get_output_image(ctx,&img1);\n\twctx.img = &img1;\n\n\tif(wctx.img->imgtype==IW_IMGTYPE_PALETTE) {\n\t\twctx.pal = iw_get_output_palette(ctx);\n\t\tif(!wctx.pal) goto done;\n\t}\n\n\tiw_get_output_colorspace(ctx,&wctx.csdescr);\n\n\tif(!iwbmp_write_main(&wctx)) {\n\t\tiw_set_error(ctx,\"BMP write failed\");\n\t\tgoto done;\n\t}\n\n\tretval=1;\n\ndone:\n\treturn retval;\n}\n", "// imagew-main.c\n// Part of ImageWorsener, Copyright (c) 2011 by Jason Summers.\n// For more information, see the readme.txt file.\n\n#include \"imagew-config.h\"\n\n#include <stdlib.h>\n#include <string.h>\n#include <math.h>\n\n#include \"imagew-internals.h\"\n\n\n// Given a color type having an alpha channel, returns the index of the\n// alpha channel.\n// Return value is not meaningful if type does not have an alpha channel.\nstatic int iw_imgtype_alpha_channel_index(int t)\n{\n\tswitch(t) {\n\tcase IW_IMGTYPE_RGBA:\n\t\treturn 3;\n\tcase IW_IMGTYPE_GRAYA:\n\t\treturn 1;\n\t}\n\treturn 0;\n}\n\nstatic IW_INLINE iw_tmpsample srgb_to_linear_sample(iw_tmpsample v_srgb)\n{\n\tif(v_srgb<=0.04045) {\n\t\treturn v_srgb/12.92;\n\t}\n\telse {\n\t\treturn pow( (v_srgb+0.055)/(1.055) , 2.4);\n\t}\n}\n\nstatic IW_INLINE iw_tmpsample rec709_to_linear_sample(iw_tmpsample v_rec709)\n{\n\tif(v_rec709 < 4.5*0.020) {\n\t\treturn v_rec709/4.5;\n\t}\n\telse {\n\t\treturn pow( (v_rec709+0.099)/1.099 , 1.0/0.45);\n\t}\n}\n\nstatic IW_INLINE iw_tmpsample gamma_to_linear_sample(iw_tmpsample v, double gamma)\n{\n\treturn pow(v,gamma);\n}\n\nstatic iw_tmpsample x_to_linear_sample(iw_tmpsample v, const struct iw_csdescr *csdescr)\n{\n\tswitch(csdescr->cstype) {\n\tcase IW_CSTYPE_SRGB:\n\t\treturn srgb_to_linear_sample(v);\n\tcase IW_CSTYPE_LINEAR:\n\t\treturn v;\n\tcase IW_CSTYPE_GAMMA:\n\t\treturn gamma_to_linear_sample(v,csdescr->gamma);\n\tcase IW_CSTYPE_REC709:\n\t\treturn rec709_to_linear_sample(v);\n\t}\n\treturn srgb_to_linear_sample(v);\n}\n\n// Public version of x_to_linear_sample().\nIW_IMPL(double) iw_convert_sample_to_linear(double v, const struct iw_csdescr *csdescr)\n{\n\treturn (double)x_to_linear_sample(v,csdescr);\n}\n\nstatic IW_INLINE iw_tmpsample linear_to_srgb_sample(iw_tmpsample v_linear)\n{\n\tif(v_linear <= 0.0031308) {\n\t\treturn 12.92*v_linear;\n\t}\n\treturn 1.055*pow(v_linear,1.0/2.4) - 0.055;\n}\n\nstatic IW_INLINE iw_tmpsample linear_to_rec709_sample(iw_tmpsample v_linear)\n{\n\t// The cutoff point is supposed to be 0.018, but that doesn't make sense,\n\t// because the curves don't intersect there. They intersect at almost exactly\n\t// 0.020.\n\tif(v_linear < 0.020) {\n\t\treturn 4.5*v_linear;\n\t}\n\treturn 1.099*pow(v_linear,0.45) - 0.099;\n}\n\nstatic IW_INLINE iw_tmpsample linear_to_gamma_sample(iw_tmpsample v_linear, double gamma)\n{\n\treturn pow(v_linear,1.0/gamma);\n}\n\nstatic iw_float32 iw_get_float32(const iw_byte *m)\n{\n\tint k;\n\t// !!! Portability warning: Using a union in this way may be nonportable.\n\tunion su_union {\n\t\tiw_byte c[4];\n\t\tiw_float32 f;\n\t} volatile su;\n\n\tfor(k=0;k<4;k++) {\n\t\tsu.c[k] = m[k];\n\t}\n\treturn su.f;\n}\n\nstatic void iw_put_float32(iw_byte *m, iw_float32 s)\n{\n\tint k;\n\t// !!! Portability warning: Using a union in this way may be nonportable.\n\tunion su_union {\n\t\tiw_byte c[4];\n\t\tiw_float32 f;\n\t} volatile su;\n\n\tsu.f = s;\n\n\tfor(k=0;k<4;k++) {\n\t\tm[k] = su.c[k];\n\t}\n}\n\nstatic iw_tmpsample get_raw_sample_flt32(struct iw_context *ctx,\n\t   int x, int y, int channel)\n{\n\tsize_t z;\n\tz = y*ctx->img1.bpr + (ctx->img1_numchannels_physical*x + channel)*4;\n\treturn (iw_tmpsample)iw_get_float32(&ctx->img1.pixels[z]);\n}\n\nstatic IW_INLINE unsigned int get_raw_sample_16(struct iw_context *ctx,\n\t   int x, int y, int channel)\n{\n\tsize_t z;\n\tunsigned short tmpui16;\n\tz = y*ctx->img1.bpr + (ctx->img1_numchannels_physical*x + channel)*2;\n\ttmpui16 = ( ((unsigned short)(ctx->img1.pixels[z+0])) <<8) | ctx->img1.pixels[z+1];\n\treturn tmpui16;\n}\n\nstatic IW_INLINE unsigned int get_raw_sample_8(struct iw_context *ctx,\n\t   int x, int y, int channel)\n{\n\tunsigned short tmpui8;\n\ttmpui8 = ctx->img1.pixels[y*ctx->img1.bpr + ctx->img1_numchannels_physical*x + channel];\n\treturn tmpui8;\n}\n\n// 4 bits/pixel\nstatic IW_INLINE unsigned int get_raw_sample_4(struct iw_context *ctx,\n\t   int x, int y)\n{\n\tunsigned short tmpui8;\n\ttmpui8 = ctx->img1.pixels[y*ctx->img1.bpr + x/2];\n\tif(x&0x1)\n\t\ttmpui8 = tmpui8&0x0f;\n\telse\n\t\ttmpui8 = tmpui8>>4;\n\treturn tmpui8;\n}\n\n// 2 bits/pixel\nstatic IW_INLINE unsigned int get_raw_sample_2(struct iw_context *ctx,\n\t   int x, int y)\n{\n\tunsigned short tmpui8;\n\ttmpui8 = ctx->img1.pixels[y*ctx->img1.bpr + x/4];\n\ttmpui8 = ( tmpui8 >> ((3-x%4)*2) ) & 0x03;\n\treturn tmpui8;\n}\n\n// 1 bit/pixel\nstatic IW_INLINE unsigned int get_raw_sample_1(struct iw_context *ctx,\n\t   int x, int y)\n{\n\tunsigned short tmpui8;\n\ttmpui8 = ctx->img1.pixels[y*ctx->img1.bpr + x/8];\n\tif(tmpui8 & (1<<(7-x%8))) return 1;\n\treturn 0;\n}\n\n// Translate a pixel position from logical to physical coordinates.\nstatic IW_INLINE void translate_coords(struct iw_context *ctx,\n\tint x, int y, int *prx, int *pry)\n{\n\tif(ctx->img1.orient_transform==0) {\n\t\t// The fast path\n\t\t*prx = ctx->input_start_x+x;\n\t\t*pry = ctx->input_start_y+y;\n\t\treturn;\n\t}\n\n\tswitch(ctx->img1.orient_transform) {\n\tcase 1: // mirror-x\n\t\t*prx = ctx->img1.width - 1 - (ctx->input_start_x+x);\n\t\t*pry = ctx->input_start_y+y;\n\t\tbreak;\n\tcase 2: // mirror-y\n\t\t*prx = ctx->input_start_x+x;\n\t\t*pry = ctx->img1.height - 1 - (ctx->input_start_y+y);\n\t\tbreak;\n\tcase 3: // mirror-x, mirror-y\n\t\t*prx = ctx->img1.width - 1 - (ctx->input_start_x+x);\n\t\t*pry = ctx->img1.height - 1 - (ctx->input_start_y+y);\n\t\tbreak;\n\tcase 4:\n\t\t// transpose\n\t\t*prx = ctx->input_start_y+y;\n\t\t*pry = ctx->input_start_x+x;\n\t\tbreak;\n\tcase 5:\n\t\t*prx = ctx->input_start_y+y;\n\t\t*pry = ctx->img1.width - 1 - (ctx->input_start_x+x);\n\t\tbreak;\n\tcase 6:\n\t\t*prx = ctx->img1.height - 1 - (ctx->input_start_y+y);\n\t\t*pry = ctx->input_start_x+x;\n\t\tbreak;\n\tcase 7:\n\t\t*prx = ctx->img1.height - 1 - (ctx->input_start_y+y);\n\t\t*pry = ctx->img1.width - 1 - (ctx->input_start_x+x);\n\t\tbreak;\n\tdefault:\n\t\t*prx = 0;\n\t\t*pry = 0;\n\t\tbreak;\n\t}\n}\n\n// Returns a value from 0 to 2^(ctx->img1.bit_depth)-1.\n// x and y are logical coordinates.\nstatic unsigned int get_raw_sample_int(struct iw_context *ctx,\n\t   int x, int y, int channel)\n{\n\tint rx,ry; // physical coordinates\n\n\ttranslate_coords(ctx,x,y,&rx,&ry);\n\n\tswitch(ctx->img1.bit_depth) {\n\tcase 8: return get_raw_sample_8(ctx,rx,ry,channel);\n\tcase 1: return get_raw_sample_1(ctx,rx,ry);\n\tcase 16: return get_raw_sample_16(ctx,rx,ry,channel);\n\tcase 4: return get_raw_sample_4(ctx,rx,ry);\n\tcase 2: return get_raw_sample_2(ctx,rx,ry);\n\t}\n\treturn 0;\n}\n\n// Channel is the input channel number.\n// x and y are logical coordinates.\nstatic iw_tmpsample get_raw_sample(struct iw_context *ctx,\n\t   int x, int y, int channel)\n{\n\tunsigned int v;\n\n\tif(channel>=ctx->img1_numchannels_physical) {\n\t\t// This is a virtual alpha channel. Return \"opaque\".\n\t\treturn 1.0;\n\t}\n\n\tif(ctx->img1.sampletype==IW_SAMPLETYPE_FLOATINGPOINT) {\n\t\tint rx, ry;\n\t\ttranslate_coords(ctx,x,y,&rx,&ry);\n\t\tif(ctx->img1.bit_depth!=32) return 0.0;\n\t\treturn get_raw_sample_flt32(ctx,rx,ry,channel);\n\t}\n\n\tv = get_raw_sample_int(ctx,x,y,channel);\n\treturn ((double)v) / ctx->img1_ci[channel].maxcolorcode_dbl;\n}\n\nstatic iw_tmpsample iw_color_to_grayscale(struct iw_context *ctx,\n\tiw_tmpsample r, iw_tmpsample g, iw_tmpsample b)\n{\n\tiw_tmpsample v0,v1,v2;\n\n\tswitch(ctx->grayscale_formula) {\n\tcase IW_GSF_WEIGHTED:\n\t\treturn ctx->grayscale_weight[0]*r +\n\t\t\tctx->grayscale_weight[1]*g +\n\t\t\tctx->grayscale_weight[2]*b;\n\tcase IW_GSF_ORDERBYVALUE:\n\t\t// Sort the R, G, and B values, then use the corresponding weights.\n\t\tif(g<=r) { v0=r; v1=g; }\n\t\telse { v0=g; v1=r; }\n\t\tif(b<=v1) {\n\t\t\tv2=b;\n\t\t}\n\t\telse {\n\t\t\tv2=v1;\n\t\t\tif(b<=v0) { v1=b; }\n\t\t\telse { v1=v0; v0=b; }\n\t\t}\n\t\treturn ctx->grayscale_weight[0]*v0 +\n\t\t\tctx->grayscale_weight[1]*v1 +\n\t\t\tctx->grayscale_weight[2]*v2;\n\t}\n\treturn 0.0;\n}\n\n// Based on color depth of the input image.\n// Assumes this channel's maxcolorcode == ctx->input_maxcolorcode\nstatic iw_tmpsample cvt_int_sample_to_linear(struct iw_context *ctx,\n\tunsigned int v, const struct iw_csdescr *csdescr)\n{\n\tiw_tmpsample s;\n\n\tif(csdescr->cstype==IW_CSTYPE_LINEAR) {\n\t\t// Sort of a hack: This is not just an optimization for linear colorspaces,\n\t\t// but is necessary to handle alpha channels correctly.\n\t\t// The lookup table is not correct for alpha channels.\n\t\treturn ((double)v) / ctx->input_maxcolorcode;\n\t}\n\telse if(ctx->input_color_corr_table) {\n\t\t// If the colorspace is not linear, assume we can use the lookup table.\n\t\treturn ctx->input_color_corr_table[v];\n\t}\n\n\ts = ((double)v) / ctx->input_maxcolorcode;\n\treturn x_to_linear_sample(s,csdescr);\n}\n\n// Based on color depth of the output image.\nstatic iw_tmpsample cvt_int_sample_to_linear_output(struct iw_context *ctx,\n\tunsigned int v, const struct iw_csdescr *csdescr, double overall_maxcolorcode)\n{\n\tiw_tmpsample s;\n\n\tif(csdescr->cstype==IW_CSTYPE_LINEAR) {\n\t\treturn ((double)v) / overall_maxcolorcode;\n\t}\n\telse if(ctx->output_rev_color_corr_table) {\n\t\treturn ctx->output_rev_color_corr_table[v];\n\t}\n\n\ts = ((double)v) / overall_maxcolorcode;\n\treturn x_to_linear_sample(s,csdescr);\n}\n\n// Return a sample, converted to a linear colorspace if it isn't already in one.\n// Channel is the output channel number.\nstatic iw_tmpsample get_sample_cvt_to_linear(struct iw_context *ctx,\n\t   int x, int y, int channel, const struct iw_csdescr *csdescr)\n{\n\tunsigned int v1,v2,v3;\n\tiw_tmpsample r,g,b;\n\tint ch;\n\n\tch = ctx->intermed_ci[channel].corresponding_input_channel;\n\n\tif(ctx->img1_ci[ch].disable_fast_get_sample) {\n\t\t// The slow way...\n\t\tif(ctx->intermed_ci[channel].cvt_to_grayscale) {\n\t\t\tr = x_to_linear_sample(get_raw_sample(ctx,x,y,ch+0),csdescr);\n\t\t\tg = x_to_linear_sample(get_raw_sample(ctx,x,y,ch+1),csdescr);\n\t\t\tb = x_to_linear_sample(get_raw_sample(ctx,x,y,ch+2),csdescr);\n\t\t\treturn iw_color_to_grayscale(ctx,r,g,b);\n\t\t}\n\t\treturn x_to_linear_sample(get_raw_sample(ctx,x,y,ch),csdescr);\n\t}\n\n\t// This method is faster, because it may use a gamma lookup table.\n\t// But all channels have to have the nominal input bitdepth, and it doesn't\n\t// support floating point samples, or a virtual alpha channel.\n\tif(ctx->intermed_ci[channel].cvt_to_grayscale) {\n\t\tv1 = get_raw_sample_int(ctx,x,y,ch+0);\n\t\tv2 = get_raw_sample_int(ctx,x,y,ch+1);\n\t\tv3 = get_raw_sample_int(ctx,x,y,ch+2);\n\t\tr = cvt_int_sample_to_linear(ctx,v1,csdescr);\n\t\tg = cvt_int_sample_to_linear(ctx,v2,csdescr);\n\t\tb = cvt_int_sample_to_linear(ctx,v3,csdescr);\n\t\treturn iw_color_to_grayscale(ctx,r,g,b);\n\t}\n\n\tv1 = get_raw_sample_int(ctx,x,y,ch);\n\treturn cvt_int_sample_to_linear(ctx,v1,csdescr);\n}\n\n// s is from 0.0 to 65535.0\nstatic IW_INLINE void put_raw_sample_16(struct iw_context *ctx, double s,\n\t   int x, int y, int channel)\n{\n\tsize_t z;\n\tunsigned short tmpui16;\n\n\ttmpui16 = (unsigned short)(0.5+s);\n\tz = y*ctx->img2.bpr + (ctx->img2_numchannels*x + channel)*2;\n\tctx->img2.pixels[z+0] = (iw_byte)(tmpui16>>8);\n\tctx->img2.pixels[z+1] = (iw_byte)(tmpui16&0xff);\n}\n\n// s is from 0.0 to 255.0\nstatic IW_INLINE void put_raw_sample_8(struct iw_context *ctx, double s,\n\t   int x, int y, int channel)\n{\n\tiw_byte tmpui8;\n\n\ttmpui8 = (iw_byte)(0.5+s);\n\tctx->img2.pixels[y*ctx->img2.bpr + ctx->img2_numchannels*x + channel] = tmpui8;\n}\n\n// Sample must already be scaled and in the target colorspace. E.g. 255.0 might be white.\nstatic void put_raw_sample(struct iw_context *ctx, double s,\n\t   int x, int y, int channel)\n{\n\tswitch(ctx->img2.bit_depth) {\n\tcase 8:  put_raw_sample_8(ctx,s,x,y,channel); break;\n\tcase 16: put_raw_sample_16(ctx,s,x,y,channel); break;\n\t}\n}\n\n// s is from 0.0 to 1.0\nstatic void put_raw_sample_flt32(struct iw_context *ctx, double s,\n\t   int x, int y, int channel)\n{\n\tsize_t pos;\n\tpos = y*ctx->img2.bpr + (ctx->img2_numchannels*x + channel)*4;\n\tiw_put_float32(&ctx->img2.pixels[pos], (iw_float32)s);\n}\n\nstatic iw_tmpsample linear_to_x_sample(iw_tmpsample samp_lin, const struct iw_csdescr *csdescr)\n{\n\tif(samp_lin > 0.999999999) {\n\t\t// This check is done mostly because glibc's pow() function may be\n\t\t// very slow for some arguments near 1.\n\t\treturn 1.0;\n\t}\n\n\tswitch(csdescr->cstype) {\n\tcase IW_CSTYPE_SRGB:\n\t\treturn linear_to_srgb_sample(samp_lin);\n\tcase IW_CSTYPE_LINEAR:\n\t\treturn samp_lin;\n\tcase IW_CSTYPE_GAMMA:\n\t\treturn linear_to_gamma_sample(samp_lin,csdescr->gamma);\n\tcase IW_CSTYPE_REC709:\n\t\treturn linear_to_rec709_sample(samp_lin);\n\t}\n\treturn linear_to_srgb_sample(samp_lin);\n}\n\n// Public version of linear_to_x_sample().\nIW_IMPL(double) iw_convert_sample_from_linear(double v, const struct iw_csdescr *csdescr)\n{\n\treturn (double)linear_to_x_sample(v,csdescr);\n}\n\n// Returns 0 if we should round down, 1 if we should round up.\n// TODO: It might be good to use a different-sized matrix for alpha channels\n// (e.g. 9x7), but I don't know how to make a good one.\nstatic int iw_ordered_dither(int dithersubtype, double fraction, int x, int y)\n{\n\tdouble threshold;\n\tstatic const float pattern[2][64] = {\n\t { // Dispersed ordered dither\n\t\t 0.5/64,48.5/64,12.5/64,60.5/64, 3.5/64,51.5/64,15.5/64,63.5/64,\n\t\t32.5/64,16.5/64,44.5/64,28.5/64,35.5/64,19.5/64,47.5/64,31.5/64,\n\t\t 8.5/64,56.5/64, 4.5/64,52.5/64,11.5/64,59.5/64, 7.5/64,55.5/64,\n\t\t40.5/64,24.5/64,36.5/64,20.5/64,43.5/64,27.5/64,39.5/64,23.5/64,\n\t\t 2.5/64,50.5/64,14.5/64,62.5/64, 1.5/64,49.5/64,13.5/64,61.5/64,\n\t\t34.5/64,18.5/64,46.5/64,30.5/64,33.5/64,17.5/64,45.5/64,29.5/64,\n\t\t10.5/64,58.5/64, 6.5/64,54.5/64, 9.5/64,57.5/64, 5.5/64,53.5/64,\n\t\t42.5/64,26.5/64,38.5/64,22.5/64,41.5/64,25.5/64,37.5/64,21.5/64\n\t },\n\t { // Halftone ordered dither\n\t\t 3.5/64, 9.5/64,17.5/64,27.5/64,25.5/64,15.5/64, 7.5/64, 1.5/64,\n\t\t11.5/64,29.5/64,37.5/64,45.5/64,43.5/64,35.5/64,23.5/64, 5.5/64,\n\t\t19.5/64,39.5/64,51.5/64,57.5/64,55.5/64,49.5/64,33.5/64,13.5/64,\n\t\t31.5/64,47.5/64,59.5/64,63.5/64,61.5/64,53.5/64,41.5/64,21.5/64,\n\t\t30.5/64,46.5/64,58.5/64,62.5/64,60.5/64,52.5/64,40.5/64,20.5/64,\n\t\t18.5/64,38.5/64,50.5/64,56.5/64,54.5/64,48.5/64,32.5/64,12.5/64,\n\t\t10.5/64,28.5/64,36.5/64,44.5/64,42.5/64,34.5/64,22.5/64, 4.5/64,\n\t\t 2.5/64, 8.5/64,16.5/64,26.5/64,24.5/64,14.5/64, 6.5/64, 0.5/64\n\t }};\n\n\tthreshold = pattern[dithersubtype][(x%8) + 8*(y%8)];\n\treturn (fraction >= threshold);\n}\n\n// Returns 0 if we should round down, 1 if we should round up.\nstatic int iw_random_dither(struct iw_context *ctx, double fraction, int x, int y,\n\tint dithersubtype, int channel)\n{\n\tdouble threshold;\n\n\tthreshold = ((double)iwpvt_prng_rand(ctx->prng)) / (double)0xffffffff;\n\tif(fraction>=threshold) return 1;\n\treturn 0;\n}\n\nstatic void iw_errdiff_dither(struct iw_context *ctx,int dithersubtype,\n\tdouble err,int x,int y)\n{\n\tint fwd;\n\tconst double *m;\n\n\t//        x  0  1\n\t//  2  3  4  5  6\n\t//  7  8  9 10 11\n\n\tstatic const double matrix_list[][12] = {\n\t{                          7.0/16, 0.0,     // 0 = Floyd-Steinberg\n\t   0.0   , 3.0/16, 5.0/16, 1.0/16, 0.0,\n\t   0.0   ,    0.0,    0.0, 0.0   , 0.0    },\n\t{                          7.0/48, 5.0/48,  // 1 = JJN\n\t   3.0/48, 5.0/48, 7.0/48, 5.0/48, 3.0/48,\n\t   1.0/48, 3.0/48, 5.0/48, 3.0/48, 1.0/48 },\n\t{                          8.0/42, 4.0/42,  // 2 = Stucki\n\t   2.0/42, 4.0/42, 8.0/42, 4.0/42, 2.0/42,\n\t   1.0/42, 2.0/42, 4.0/42, 2.0/42, 1.0/42 },\n\t{                          8.0/32, 4.0/32,  // 3 = Burkes\n\t   2.0/32, 4.0/32, 8.0/32, 4.0/32, 2.0/32,\n\t   0.0   , 0.0   , 0.0   , 0.0   , 0.0    },\n\t{                          5.0/32, 3.0/32,  // 4 = Sierra3\n\t   2.0/32, 4.0/32, 5.0/32, 4.0/32, 2.0/32,\n\t      0.0, 2.0/32, 3.0/32, 2.0/32, 0.0    },\n\t{                          4.0/16, 3.0/16,  // 5 = Sierra2\n\t   1.0/16, 2.0/16, 3.0/16, 2.0/16, 1.0/16,\n\t   0.0   , 0.0   , 0.0   , 0.0   , 0.0    },\n\t{                          2.0/4 , 0.0,     // 6 = Sierra42a\n\t   0.0   , 1.0/4 , 1.0/4 , 0.0   , 0.0,\n\t   0.0   , 0.0   , 0.0   , 0.0   , 0.0    },\n\t{                          1.0/8 , 1.0/8,   // 7 = Atkinson\n\t   0.0   , 1.0/8 , 1.0/8 , 1.0/8 , 0.0,\n\t   0.0   , 0.0   , 1.0/8 , 0.0   , 0.0    }\n\t};\n\n\tif(dithersubtype<=7)\n\t\tm = matrix_list[dithersubtype];\n\telse\n\t\tm = matrix_list[0];\n\n\tfwd = (y%2)?(-1):1;\n\n\tif((x-fwd)>=0 && (x-fwd)<ctx->img2.width) {\n\t\tif((x-2*fwd)>=0 && (x-2*fwd)<ctx->img2.width) {\n\t\t\tctx->dither_errors[1][x-2*fwd] += err*(m[2]);\n\t\t\tctx->dither_errors[2][x-2*fwd] += err*(m[7]);\n\t\t}\n\t\tctx->dither_errors[1][x-fwd] += err*(m[3]);\n\t\tctx->dither_errors[2][x-fwd] += err*(m[8]);\n\t}\n\n\tctx->dither_errors[1][x] += err*(m[4]);\n\tctx->dither_errors[2][x] += err*(m[9]);\n\n\tif((x+fwd)>=0 && (x+fwd)<ctx->img2.width) {\n\t\tctx->dither_errors[0][x+fwd] += err*(m[0]);\n\t\tctx->dither_errors[1][x+fwd] += err*(m[5]);\n\t\tctx->dither_errors[2][x+fwd] += err*(m[10]);\n\t\tif((x+2*fwd)>=0 && (x+2*fwd)<ctx->img2.width) {\n\t\t\tctx->dither_errors[0][x+2*fwd] += err*(m[1]);\n\t\t\tctx->dither_errors[1][x+2*fwd] += err*(m[6]);\n\t\t\tctx->dither_errors[2][x+2*fwd] += err*(m[11]);\n\t\t}\n\t}\n}\n\n// 'channel' is the output channel.\nstatic int get_nearest_valid_colors(struct iw_context *ctx, iw_tmpsample samp_lin,\n\t\tconst struct iw_csdescr *csdescr,\n\t\tdouble *s_lin_floor_1, double *s_lin_ceil_1,\n\t\tdouble *s_cvt_floor_full, double *s_cvt_ceil_full,\n\t\tdouble overall_maxcolorcode, int color_count)\n{\n\tiw_tmpsample samp_cvt;\n\tdouble samp_cvt_expanded;\n\tunsigned int floor_int, ceil_int;\n\n\t// A prelimary conversion to the target color space.\n\tsamp_cvt = linear_to_x_sample(samp_lin,csdescr);\n\n\tif(color_count==0) {\n\t\t// The normal case: we want to use this channel's full available depth.\n\t\tsamp_cvt_expanded = samp_cvt * overall_maxcolorcode;\n\t\tif(samp_cvt_expanded>overall_maxcolorcode) samp_cvt_expanded=overall_maxcolorcode;\n\t\tif(samp_cvt_expanded<0.0) samp_cvt_expanded=0.0;\n\n\t\t// Find the next-smallest and next-largest valid values that\n\t\t// can be stored in this image.\n\t\t// We will use one of them, but in order to figure out *which* one,\n\t\t// we have to compare their distances in the *linear* color space.\n\t\t*s_cvt_floor_full = floor(samp_cvt_expanded);\n\t\t*s_cvt_ceil_full  = ceil(samp_cvt_expanded);\n\t}\n\telse {\n\t\t// We're \"posterizing\": restricting to a certain number of color shades.\n\t\tdouble posterized_maxcolorcode;\n\t\t// Example: color_count = 4, bit_depth = 8;\n\t\t// Colors are from 0.0 to 3.0, mapped to 0.0 to 255.0.\n\t\t// Reduction factor is 255.0/3.0 = 85.0\n\n\t\tposterized_maxcolorcode = (double)(color_count-1);\n\n\t\tsamp_cvt_expanded = samp_cvt * posterized_maxcolorcode;\n\t\tif(samp_cvt_expanded>posterized_maxcolorcode) samp_cvt_expanded=posterized_maxcolorcode;\n\t\tif(samp_cvt_expanded<0.0) samp_cvt_expanded=0.0;\n\n\t\t// If the number of shades is not 2, 4, 6, 16, 18, 52, 86, or 256 (assuming 8-bit depth),\n\t\t// then the shades will not be exactly evenly spaced. For example, if there are 3 shades,\n\t\t// they will be 0, 128, and 255. It will often be the case that the shade we want is exactly\n\t\t// halfway between the nearest two available shades, and the \"0.5000000001\" fudge factor is my\n\t\t// attempt to make sure it rounds consistently in the same direction.\n\t\t*s_cvt_floor_full = floor(0.5000000001 + floor(samp_cvt_expanded) * (overall_maxcolorcode/posterized_maxcolorcode));\n\t\t*s_cvt_ceil_full  = floor(0.5000000001 + ceil (samp_cvt_expanded) * (overall_maxcolorcode/posterized_maxcolorcode));\n\t}\n\n\tfloor_int = (unsigned int)(*s_cvt_floor_full);\n\tceil_int  = (unsigned int)(*s_cvt_ceil_full);\n\tif(floor_int == ceil_int) {\n\t\treturn 1;\n\t}\n\n\t// Convert the candidates to our linear color space\n\t*s_lin_floor_1 = cvt_int_sample_to_linear_output(ctx,floor_int,csdescr,overall_maxcolorcode);\n\t*s_lin_ceil_1 =  cvt_int_sample_to_linear_output(ctx,ceil_int ,csdescr,overall_maxcolorcode);\n\n\treturn 0;\n}\n\n// channel is the output channel\nstatic void put_sample_convert_from_linear_flt(struct iw_context *ctx, iw_tmpsample samp_lin,\n\t   int x, int y, int channel, const struct iw_csdescr *csdescr)\n{\n\tput_raw_sample_flt32(ctx,(double)samp_lin,x,y,channel);\n}\n\nstatic double get_final_sample_using_nc_tbl(struct iw_context *ctx, iw_tmpsample samp_lin)\n{\n\tunsigned int x;\n\tunsigned int d;\n\n\t// For numbers 0 through 254, find the smallest one for which the\n\t// corresponding table value is larger than samp_lin.\n\n\t// Do a binary search.\n\n\tx = 127;\n\td = 64;\n\n\twhile(1) {\n\t\tif(x>254 || ctx->nearest_color_table[x] > samp_lin)\n\t\t\tx -= d;\n\t\telse\n\t\t\tx += d;\n\n\t\tif(d==1) {\n\t\t\tif(x>254 || ctx->nearest_color_table[x] > samp_lin)\n\t\t\t\treturn (double)(x);\n\t\t\telse\n\t\t\t\treturn (double)(x+1);\n\t\t}\n\n\t\td = d/2;\n\t}\n}\n\n// channel is the output channel\nstatic void put_sample_convert_from_linear(struct iw_context *ctx, iw_tmpsample samp_lin,\n\t   int x, int y, int channel, const struct iw_csdescr *csdescr)\n{\n\tdouble s_lin_floor_1, s_lin_ceil_1;\n\tdouble s_cvt_floor_full, s_cvt_ceil_full;\n\tdouble d_floor, d_ceil;\n\tint is_exact;\n\tdouble s_full;\n\tint ditherfamily;\n\tint dd; // Dither decision: 0 to use floor, 1 to use ceil.\n\n\t// Clamp to the [0.0,1.0] range.\n\t// The sample type is UINT, so out-of-range samples can't be represented.\n\t// TODO: I think that out-of-range samples could still have a meaningful\n\t// effect if we are dithering. More investigation is needed here.\n\tif(samp_lin<0.0) samp_lin=0.0;\n\tif(samp_lin>1.0) samp_lin=1.0;\n\n\t// TODO: This is getting messy. The conditions under which we use lookup\n\t// tables are too complicated, and we still don't use them as often as we\n\t// should. For example, if we are not dithering, we can use a table optimized\n\t// for telling us the single nearest color. But if we are dithering, then we\n\t// instead need to know both the next-highest and next-lowest colors, which\n\t// would require a different table. The same table could be used for both,\n\t// but not quite as efficiently. Currently, we don't use use a lookup table\n\t// when dithering, except that we may still use one to do some of the\n\t// intermediate computations. Etc.\n\tif(ctx->img2_ci[channel].use_nearest_color_table) {\n\t\ts_full = get_final_sample_using_nc_tbl(ctx,samp_lin);\n\t\tgoto okay;\n\t}\n\n\tditherfamily=ctx->img2_ci[channel].ditherfamily;\n\n\tif(ditherfamily==IW_DITHERFAMILY_ERRDIFF) {\n\t\tsamp_lin += ctx->dither_errors[0][x];\n\t\t// If the prior error makes the ideal brightness out of the available range,\n\t\t// just throw away any extra.\n\t\tif(samp_lin>1.0) samp_lin=1.0;\n\t\telse if(samp_lin<0.0) samp_lin=0.0;\n\t}\n\n\tis_exact = get_nearest_valid_colors(ctx,samp_lin,csdescr,\n\t\t&s_lin_floor_1, &s_lin_ceil_1,\n\t\t&s_cvt_floor_full, &s_cvt_ceil_full,\n\t\tctx->img2_ci[channel].maxcolorcode_dbl, ctx->img2_ci[channel].color_count);\n\n\tif(is_exact) {\n\t\ts_full = s_cvt_floor_full;\n\n\t\t// Hack to keep the PRNG in sync. We have to generate exactly one random\n\t\t// number per sample, regardless of whether we use it.\n\t\tif(ditherfamily==IW_DITHERFAMILY_RANDOM) {\n\t\t\t(void)iwpvt_prng_rand(ctx->prng);\n\t\t}\n\t\tgoto okay;\n\t}\n\n\t// samp_lin should be between s_lin_floor_1 and s_lin_ceil_1. Figure out\n\t// which is closer, and use the final pixel value we figured out earlier\n\t// (either s_cvt_floor_full or s_cvt_ceil_full).\n\td_floor = samp_lin-s_lin_floor_1;\n\td_ceil  = s_lin_ceil_1-samp_lin;\n\n\tif(ditherfamily==IW_DITHERFAMILY_NONE) {\n\t\t// Not dithering. Just choose closest value.\n\t\tif(d_ceil<=d_floor) s_full=s_cvt_ceil_full;\n\t\telse s_full=s_cvt_floor_full;\n\t}\n\telse if(ditherfamily==IW_DITHERFAMILY_ERRDIFF) {\n\t\tif(d_ceil<=d_floor) {\n\t\t\t// Ceiling is closer. This pixel will be lighter than ideal.\n\t\t\t// so the error is negative, to make other pixels darker.\n\t\t\tiw_errdiff_dither(ctx,ctx->img2_ci[channel].dithersubtype,-d_ceil,x,y);\n\t\t\ts_full=s_cvt_ceil_full;\n\t\t}\n\t\telse {\n\t\t\tiw_errdiff_dither(ctx,ctx->img2_ci[channel].dithersubtype,d_floor,x,y);\n\t\t\ts_full=s_cvt_floor_full;\n\t\t}\n\t}\n\telse if(ditherfamily==IW_DITHERFAMILY_ORDERED) {\n\t\tdd=iw_ordered_dither(ctx->img2_ci[channel].dithersubtype, d_floor/(d_floor+d_ceil),x,y);\n\t\ts_full = dd ? s_cvt_ceil_full : s_cvt_floor_full;\n\t}\n\telse if(ditherfamily==IW_DITHERFAMILY_RANDOM) {\n\t\tdd=iw_random_dither(ctx,d_floor/(d_floor+d_ceil),x,y,ctx->img2_ci[channel].dithersubtype,channel);\n\t\ts_full = dd ? s_cvt_ceil_full : s_cvt_floor_full;\n\t}\n\telse {\n\t\t// Unsupported dither method.\n\t\ts_full = 0.0;\n\t}\n\nokay:\n\tput_raw_sample(ctx,s_full,x,y,channel);\n}\n\n// A stripped-down version of put_sample_convert_from_linear(),\n// intended for use with background colors.\nstatic unsigned int calc_sample_convert_from_linear(struct iw_context *ctx, iw_tmpsample samp_lin,\n\t   const struct iw_csdescr *csdescr, double overall_maxcolorcode)\n{\n\tdouble s_lin_floor_1, s_lin_ceil_1;\n\tdouble s_cvt_floor_full, s_cvt_ceil_full;\n\tdouble d_floor, d_ceil;\n\tint is_exact;\n\tdouble s_full;\n\n\tif(samp_lin<0.0) samp_lin=0.0;\n\tif(samp_lin>1.0) samp_lin=1.0;\n\n\tis_exact = get_nearest_valid_colors(ctx,samp_lin,csdescr,\n\t\t&s_lin_floor_1, &s_lin_ceil_1,\n\t\t&s_cvt_floor_full, &s_cvt_ceil_full,\n\t\toverall_maxcolorcode, 0);\n\n\tif(is_exact) {\n\t\ts_full = s_cvt_floor_full;\n\t\tgoto okay;\n\t}\n\n\td_floor = samp_lin-s_lin_floor_1;\n\td_ceil  = s_lin_ceil_1-samp_lin;\n\n\tif(d_ceil<=d_floor) s_full=s_cvt_ceil_full;\n\telse s_full=s_cvt_floor_full;\n\nokay:\n\treturn (unsigned int)(0.5+s_full);\n}\n\nstatic void clamp_output_samples(struct iw_context *ctx, iw_tmpsample *out_pix, int num_out_pix)\n{\n\tint i;\n\n\tfor(i=0;i<num_out_pix;i++) {\n\t\tif(out_pix[i]<0.0) out_pix[i]=0.0;\n\t\telse if(out_pix[i]>1.0) out_pix[i]=1.0;\n\t}\n}\n\n// TODO: Maybe this should be a flag in ctx, instead of a function that is\n// called repeatedly.\nstatic int iw_bkgd_has_transparency(struct iw_context *ctx)\n{\n\tif(!ctx->apply_bkgd) return 0;\n\tif(!(ctx->output_profile&IW_PROFILE_TRANSPARENCY)) return 0;\n\tif(ctx->apply_bkgd_strategy==IW_BKGD_STRATEGY_EARLY) return 0;\n\tif(ctx->bkgd_color_source==IW_BKGD_COLOR_SOURCE_FILE) {\n\t\tif(ctx->img1_bkgd_label_inputcs.c[3]<1.0) return 1;\n\t}\n\telse if(ctx->bkgd_color_source==IW_BKGD_COLOR_SOURCE_REQ) {\n\t\tif(ctx->bkgd_checkerboard) {\n\t\t\tif(ctx->req.bkgd2.c[3]<1.0) return 1;\n\t\t}\n\t\tif(ctx->req.bkgd.c[3]<1.0) return 1;\n\t}\n\treturn 0;\n}\n\n// 'channel' is an intermediate channel number.\nstatic int iw_process_cols_to_intermediate(struct iw_context *ctx, int channel,\n\tconst struct iw_csdescr *in_csdescr)\n{\n\tint i,j;\n\tint retval=0;\n\tiw_tmpsample tmp_alpha;\n\tiw_tmpsample *inpix_tofree = NULL;\n\tiw_tmpsample *outpix_tofree = NULL;\n\tint is_alpha_channel;\n\tstruct iw_resize_settings *rs = NULL;\n\tstruct iw_channelinfo_intermed *int_ci;\n\n\tiw_tmpsample *in_pix;\n\tiw_tmpsample *out_pix;\n\tint num_in_pix;\n\tint num_out_pix;\n\n\tint_ci = &ctx->intermed_ci[channel];\n\tis_alpha_channel = (int_ci->channeltype==IW_CHANNELTYPE_ALPHA);\n\n\tnum_in_pix = ctx->input_h;\n\tinpix_tofree = (iw_tmpsample*)iw_malloc(ctx, num_in_pix * sizeof(iw_tmpsample));\n\tif(!inpix_tofree) goto done;\n\tin_pix = inpix_tofree;\n\n\tnum_out_pix = ctx->intermed_canvas_height;\n\toutpix_tofree = (iw_tmpsample*)iw_malloc(ctx, num_out_pix * sizeof(iw_tmpsample));\n\tif(!outpix_tofree) goto done;\n\tout_pix = outpix_tofree;\n\n\trs=&ctx->resize_settings[IW_DIMENSION_V];\n\n\t// If the resize context for this dimension already exists, we should be\n\t// able to reuse it. Otherwise, create a new one.\n\tif(!rs->rrctx) {\n\t\t// TODO: The use of the word \"rows\" here is misleading, because we are\n\t\t// actually resizing columns.\n\t\trs->rrctx = iwpvt_resize_rows_init(ctx,rs,int_ci->channeltype,\n\t\t\tnum_in_pix, num_out_pix);\n\t\tif(!rs->rrctx) goto done;\n\t}\n\n\tfor(i=0;i<ctx->input_w;i++) {\n\n\t\t// Read a column of pixels into ctx->in_pix\n\t\tfor(j=0;j<ctx->input_h;j++) {\n\n\t\t\tin_pix[j] = get_sample_cvt_to_linear(ctx,i,j,channel,in_csdescr);\n\n\t\t\tif(int_ci->need_unassoc_alpha_processing) { // We need opacity information also\n\t\t\t\ttmp_alpha = get_raw_sample(ctx,i,j,ctx->img1_alpha_channel_index);\n\n\t\t\t\t// Multiply color amount by opacity\n\t\t\t\tin_pix[j] *= tmp_alpha;\n\t\t\t}\n\t\t\telse if(ctx->apply_bkgd && ctx->apply_bkgd_strategy==IW_BKGD_STRATEGY_EARLY) {\n\t\t\t\t// We're doing \"Early\" background color application.\n\t\t\t\t// All intermediate channels will need the background color\n\t\t\t\t// applied to them.\n\t\t\t\ttmp_alpha = get_raw_sample(ctx,i,j,ctx->img1_alpha_channel_index);\n\t\t\t\tin_pix[j] = (tmp_alpha)*(in_pix[j]) +\n\t\t\t\t\t(1.0-tmp_alpha)*(int_ci->bkgd_color_lin);\n\t\t\t}\n\t\t}\n\n\t\t// Now we have a row in the right format.\n\t\t// Resize it and store it in the right place in the intermediate array.\n\n\t\tiwpvt_resize_row_main(rs->rrctx,in_pix,out_pix);\n\n\t\tif(ctx->intclamp)\n\t\t\tclamp_output_samples(ctx,out_pix,num_out_pix);\n\n\t\t// The intermediate pixels are in ctx->out_pix. Copy them to the intermediate array.\n\t\tfor(j=0;j<ctx->intermed_canvas_height;j++) {\n\t\t\tif(is_alpha_channel) {\n\t\t\t\tctx->intermediate_alpha32[((size_t)j)*ctx->intermed_canvas_width + i] = (iw_float32)out_pix[j];\n\t\t\t}\n\t\t\telse {\n\t\t\t\tctx->intermediate32[((size_t)j)*ctx->intermed_canvas_width + i] = (iw_float32)out_pix[j];\n\t\t\t}\n\t\t}\n\t}\n\n\tretval=1;\n\ndone:\n\tif(rs && rs->disable_rrctx_cache && rs->rrctx) {\n\t\t// In some cases, the channels may need different resize contexts.\n\t\t// Delete the current context, so that it doesn't get reused.\n\t\tiwpvt_resize_rows_done(rs->rrctx);\n\t\trs->rrctx = NULL;\n\t}\n\tif(inpix_tofree) iw_free(ctx,inpix_tofree);\n\tif(outpix_tofree) iw_free(ctx,outpix_tofree);\n\treturn retval;\n}\n\nstatic int iw_process_rows_intermediate_to_final(struct iw_context *ctx, int intermed_channel,\n\tconst struct iw_csdescr *out_csdescr)\n{\n\tint i,j;\n\tint z;\n\tint k;\n\tint retval=0;\n\tiw_tmpsample tmpsamp;\n\tiw_tmpsample alphasamp = 0.0;\n\tiw_tmpsample *inpix_tofree = NULL; // Used if we need a separate temp buffer for input samples\n\tiw_tmpsample *outpix_tofree = NULL; // Used if we need a separate temp buffer for output samples\n\t// Do any of the output channels use error-diffusion dithering?\n\tint using_errdiffdither = 0;\n\tint output_channel;\n\tint is_alpha_channel;\n\tint bkgd_has_transparency;\n\tdouble tmpbkgdalpha=0.0;\n\tint alt_bkgd = 0; // Nonzero if we should use bkgd2 for this sample\n\tstruct iw_resize_settings *rs = NULL;\n\tint ditherfamily, dithersubtype;\n\tstruct iw_channelinfo_intermed *int_ci;\n\tstruct iw_channelinfo_out *out_ci;\n\n\tiw_tmpsample *in_pix = NULL;\n\tiw_tmpsample *out_pix = NULL;\n\tint num_in_pix;\n\tint num_out_pix;\n\tstruct iw_channelinfo_out default_ci_out;\n\n\tnum_in_pix = ctx->intermed_canvas_width;\n\tnum_out_pix = ctx->img2.width;\n\n\tint_ci = &ctx->intermed_ci[intermed_channel];\n\toutput_channel = int_ci->corresponding_output_channel;\n\tif(output_channel>=0) {\n\t\tout_ci = &ctx->img2_ci[output_channel];\n\t}\n\telse {\n\t\t// If there is no output channelinfo struct, create a temporary one to\n\t\t// use.\n\t\t// TODO: This is admittedly ugly, but we use these settings for a few\n\t\t// things even when there is no corresponding output channel, and I\n\t\t// don't remember exactly why.\n\t\tiw_zeromem(&default_ci_out, sizeof(struct iw_channelinfo_out));\n\t\tdefault_ci_out.channeltype = IW_CHANNELTYPE_NONALPHA;\n\t\tout_ci = &default_ci_out;\n\t}\n\n\tis_alpha_channel = (int_ci->channeltype==IW_CHANNELTYPE_ALPHA);\n\tbkgd_has_transparency = iw_bkgd_has_transparency(ctx);\n\n\tinpix_tofree = (iw_tmpsample*)iw_malloc(ctx, num_in_pix * sizeof(iw_tmpsample));\n\tin_pix = inpix_tofree;\n\n\t// We need an output buffer.\n\toutpix_tofree = (iw_tmpsample*)iw_malloc(ctx, num_out_pix * sizeof(iw_tmpsample));\n\tif(!outpix_tofree) goto done;\n\tout_pix = outpix_tofree;\n\n\t// Decide if the 'nearest color table' optimization can be used\n\tif(ctx->nearest_color_table && !is_alpha_channel &&\n\t   out_ci->ditherfamily==IW_DITHERFAMILY_NONE &&\n\t   out_ci->color_count==0)\n\t{\n\t\tout_ci->use_nearest_color_table = 1;\n\t}\n\telse {\n\t\tout_ci->use_nearest_color_table = 0;\n\t}\n\n\t// Seed the PRNG, if necessary.\n\tditherfamily = out_ci->ditherfamily;\n\tdithersubtype = out_ci->dithersubtype;\n\tif(ditherfamily==IW_DITHERFAMILY_RANDOM) {\n\t\t// Decide what random seed to use. The alpha channel always has its own\n\t\t// seed. If using \"r\" (not \"r2\") dithering, every channel has its own seed.\n\t\tif(dithersubtype==IW_DITHERSUBTYPE_SAMEPATTERN && out_ci->channeltype!=IW_CHANNELTYPE_ALPHA)\n\t\t{\n\t\t\tiwpvt_prng_set_random_seed(ctx->prng,ctx->random_seed);\n\t\t}\n\t\telse {\n\t\t\tiwpvt_prng_set_random_seed(ctx->prng,ctx->random_seed+out_ci->channeltype);\n\t\t}\n\t}\n\n\t// Initialize Floyd-Steinberg dithering.\n\tif(output_channel>=0 && out_ci->ditherfamily==IW_DITHERFAMILY_ERRDIFF) {\n\t\tusing_errdiffdither = 1;\n\t\tfor(i=0;i<ctx->img2.width;i++) {\n\t\t\tfor(k=0;k<IW_DITHER_MAXROWS;k++) {\n\t\t\t\tctx->dither_errors[k][i] = 0.0;\n\t\t\t}\n\t\t}\n\t}\n\n\trs=&ctx->resize_settings[IW_DIMENSION_H];\n\n\t// If the resize context for this dimension already exists, we should be\n\t// able to reuse it. Otherwise, create a new one.\n\tif(!rs->rrctx) {\n\t\trs->rrctx = iwpvt_resize_rows_init(ctx,rs,int_ci->channeltype,\n\t\t\tnum_in_pix, num_out_pix);\n\t\tif(!rs->rrctx) goto done;\n\t}\n\n\tfor(j=0;j<ctx->intermed_canvas_height;j++) {\n\n\t\t// As needed, either copy the input pixels to a temp buffer (inpix, which\n\t\t// ctx->in_pix already points to), or point ctx->in_pix directly to the\n\t\t// intermediate data.\n\t\tif(is_alpha_channel) {\n\t\t\tfor(i=0;i<num_in_pix;i++) {\n\t\t\t\tinpix_tofree[i] = ctx->intermediate_alpha32[((size_t)j)*ctx->intermed_canvas_width+i];\n\t\t\t}\n\t\t}\n\t\telse {\n\t\t\tfor(i=0;i<num_in_pix;i++) {\n\t\t\t\tinpix_tofree[i] = ctx->intermediate32[((size_t)j)*ctx->intermed_canvas_width+i];\n\t\t\t}\n\t\t}\n\n\t\t// Resize ctx->in_pix to ctx->out_pix.\n\t\tiwpvt_resize_row_main(rs->rrctx,in_pix,out_pix);\n\n\t\tif(ctx->intclamp)\n\t\t\tclamp_output_samples(ctx,out_pix,num_out_pix);\n\n\t\t// If necessary, copy the resized samples to the final_alpha image\n\t\tif(is_alpha_channel && outpix_tofree && ctx->final_alpha32) {\n\t\t\tfor(i=0;i<num_out_pix;i++) {\n\t\t\t\tctx->final_alpha32[((size_t)j)*ctx->img2.width+i] = (iw_float32)outpix_tofree[i];\n\t\t\t}\n\t\t}\n\n\t\t// Now convert the out_pix and put them in the final image.\n\n\t\tif(output_channel == -1) {\n\t\t\t// No corresponding output channel.\n\t\t\t// (Presumably because this is an alpha channel that's being\n\t\t\t// removed because we're applying a background.)\n\t\t\tgoto here;\n\t\t}\n\n\t\tfor(z=0;z<ctx->img2.width;z++) {\n\t\t\t// For decent Floyd-Steinberg dithering, we need to process alternate\n\t\t\t// rows in reverse order.\n\t\t\tif(using_errdiffdither && (j%2))\n\t\t\t\ti=ctx->img2.width-1-z;\n\t\t\telse\n\t\t\t\ti=z;\n\n\t\t\ttmpsamp = out_pix[i];\n\n\t\t\tif(ctx->bkgd_checkerboard) {\n\t\t\t\talt_bkgd = (((ctx->bkgd_check_origin[IW_DIMENSION_H]+i)/ctx->bkgd_check_size)%2) !=\n\t\t\t\t\t(((ctx->bkgd_check_origin[IW_DIMENSION_V]+j)/ctx->bkgd_check_size)%2);\n\t\t\t}\n\n\t\t\tif(bkgd_has_transparency) {\n\t\t\t\ttmpbkgdalpha = alt_bkgd ? ctx->bkgd2alpha : ctx->bkgd1alpha;\n\t\t\t}\n\n\t\t\tif(int_ci->need_unassoc_alpha_processing) {\n\t\t\t\t// Convert color samples back to unassociated alpha.\n\t\t\t\talphasamp = ctx->final_alpha32[((size_t)j)*ctx->img2.width + i];\n\n\t\t\t\tif(alphasamp!=0.0) {\n\t\t\t\t\ttmpsamp /= alphasamp;\n\t\t\t\t}\n\n\t\t\t\tif(ctx->apply_bkgd && ctx->apply_bkgd_strategy==IW_BKGD_STRATEGY_LATE) {\n\t\t\t\t\t// Apply a background color (or checkerboard pattern).\n\t\t\t\t\tdouble bkcolor;\n\t\t\t\t\tbkcolor = alt_bkgd ? out_ci->bkgd2_color_lin : out_ci->bkgd1_color_lin;\n\n\t\t\t\t\tif(bkgd_has_transparency) {\n\t\t\t\t\t\ttmpsamp = tmpsamp*alphasamp + bkcolor*tmpbkgdalpha*(1.0-alphasamp);\n\t\t\t\t\t}\n\t\t\t\t\telse {\n\t\t\t\t\t\ttmpsamp = tmpsamp*alphasamp + bkcolor*(1.0-alphasamp);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\telse if(is_alpha_channel && bkgd_has_transparency) {\n\t\t\t\t// Composite the alpha of the foreground over the alpha of the background.\n\t\t\t\ttmpsamp = tmpsamp + tmpbkgdalpha*(1.0-tmpsamp);\n\t\t\t}\n\n\t\t\tif(ctx->img2.sampletype==IW_SAMPLETYPE_FLOATINGPOINT)\n\t\t\t\tput_sample_convert_from_linear_flt(ctx,tmpsamp,i,j,output_channel,out_csdescr);\n\t\t\telse\n\t\t\t\tput_sample_convert_from_linear(ctx,tmpsamp,i,j,output_channel,out_csdescr);\n\n\t\t}\n\n\t\tif(using_errdiffdither) {\n\t\t\t// Move \"next row\" error data to \"this row\", and clear the \"next row\".\n\t\t\t// TODO: Obviously, it would be more efficient to just swap pointers\n\t\t\t// to the rows.\n\t\t\tfor(i=0;i<ctx->img2.width;i++) {\n\t\t\t\t// Move data in all rows but the first row up one row.\n\t\t\t\tfor(k=0;k<IW_DITHER_MAXROWS-1;k++) {\n\t\t\t\t\tctx->dither_errors[k][i] = ctx->dither_errors[k+1][i];\n\t\t\t\t}\n\t\t\t\t// Clear the last row.\n\t\t\t\tctx->dither_errors[IW_DITHER_MAXROWS-1][i] = 0.0;\n\t\t\t}\n\t\t}\n\nhere:\n\t\t;\n\t}\n\n\tretval=1;\n\ndone:\n\tif(rs && rs->disable_rrctx_cache && rs->rrctx) {\n\t\t// In some cases, the channels may need different resize contexts.\n\t\t// Delete the current context, so that it doesn't get reused.\n\t\tiwpvt_resize_rows_done(rs->rrctx);\n\t\trs->rrctx = NULL;\n\t}\n\tif(inpix_tofree) iw_free(ctx,inpix_tofree);\n\tif(outpix_tofree) iw_free(ctx,outpix_tofree);\n\n\treturn retval;\n}\n\nstatic int iw_process_one_channel(struct iw_context *ctx, int intermed_channel,\n  const struct iw_csdescr *in_csdescr, const struct iw_csdescr *out_csdescr)\n{\n\tif(!iw_process_cols_to_intermediate(ctx,intermed_channel,in_csdescr)) {\n\t\treturn 0;\n\t}\n\n\tif(!iw_process_rows_intermediate_to_final(ctx,intermed_channel,out_csdescr)) {\n\t\treturn 0;\n\t}\n\n\treturn 1;\n}\n\n// Potentially make a lookup table for color correction.\nstatic void iw_make_x_to_linear_table(struct iw_context *ctx, double **ptable,\n\tconst struct iw_image *img, const struct iw_csdescr *csdescr)\n{\n\tint ncolors;\n\tint i;\n\tdouble *tbl;\n\n\tif(csdescr->cstype==IW_CSTYPE_LINEAR) return;\n\n\tncolors = (1 << img->bit_depth);\n\tif(ncolors>256) return;\n\n\t// Don't make a table if the image is really small.\n\tif( ((size_t)img->width)*img->height <= 512 ) return;\n\n\ttbl = iw_malloc(ctx,ncolors*sizeof(double));\n\tif(!tbl) return;\n\n\tfor(i=0;i<ncolors;i++) {\n\t\ttbl[i] = x_to_linear_sample(((double)i)/(ncolors-1), csdescr);\n\t}\n\n\t*ptable = tbl;\n}\n\nstatic void iw_make_nearest_color_table(struct iw_context *ctx, double **ptable,\n\tconst struct iw_image *img, const struct iw_csdescr *csdescr)\n{\n\tint ncolors;\n\tint nentries;\n\tint i;\n\tdouble *tbl;\n\tdouble prev;\n\tdouble curr;\n\n\tif(ctx->no_gamma) return;\n\tif(csdescr->cstype==IW_CSTYPE_LINEAR) return;\n\tif(img->sampletype==IW_SAMPLETYPE_FLOATINGPOINT) return;\n\tif(img->bit_depth != ctx->img2.bit_depth) return;\n\n\tncolors = (1 << img->bit_depth);\n\tif(ncolors>256) return;\n\tnentries = ncolors-1;\n\n\t// Don't make a table if the image is really small.\n\tif( ((size_t)img->width)*img->height <= 512 ) return;\n\n\ttbl = iw_malloc(ctx,nentries*sizeof(double));\n\tif(!tbl) return;\n\n\t// Table stores the maximum value for the given entry.\n\t// The final entry is omitted, since there is no maximum value.\n\tprev = 0.0;\n\tfor(i=0;i<nentries;i++) {\n\t\t// This conversion may appear to be going in the wrong direction\n\t\t// (we're coverting *from* linear), but it's correct because we will\n\t\t// search through its contents to find the corresponding index,\n\t\t// instead of vice versa.\n\t\tcurr = x_to_linear_sample( ((double)(i+1))/(ncolors-1), csdescr);\n\t\ttbl[i] = (prev + curr)/2.0;\n\t\tprev = curr;\n\t}\n\n\t*ptable = tbl;\n}\n\n// Label is returned in linear colorspace.\n// Returns 0 if no label available.\nstatic int get_output_bkgd_label_lin(struct iw_context *ctx, struct iw_color *clr)\n{\n\tclr->c[0] = 1.0; clr->c[1] = 0.0; clr->c[2] = 1.0; clr->c[3] = 1.0;\n\n\tif(ctx->req.suppress_output_bkgd_label) return 0;\n\n\tif(ctx->req.output_bkgd_label_valid) {\n\t\t*clr = ctx->req.output_bkgd_label;\n\t\treturn 1;\n\t}\n\n\t// If the user didn't specify a label, but the input file had one, copy the\n\t// input file's label.\n\tif(ctx->img1_bkgd_label_set) {\n\t\t*clr = ctx->img1_bkgd_label_lin;\n\t\treturn 1;\n\t}\n\n\treturn 0;\n}\n\nstatic unsigned int iw_scale_to_int(double s, unsigned int maxcolor)\n{\n\tif(s<=0.0) return 0;\n\tif(s>=1.0) return maxcolor;\n\treturn (unsigned int)(0.5+s*maxcolor);\n}\n\n// Quantize the background color label, and store in ctx->img2.bkgdlabel.\n// Also convert it to grayscale if needed.\nstatic void iw_process_bkgd_label(struct iw_context *ctx)\n{\n\tint ret;\n\tint k;\n\tstruct iw_color clr;\n\tdouble maxcolor;\n\tunsigned int tmpu;\n\n\tif(!(ctx->output_profile&IW_PROFILE_PNG_BKGD) &&\n\t\t!(ctx->output_profile&IW_PROFILE_RGB8_BKGD) &&\n\t\t!(ctx->output_profile&IW_PROFILE_RGB16_BKGD))\n\t{\n\t\treturn;\n\t}\n\n\tret = get_output_bkgd_label_lin(ctx,&clr);\n\tif(!ret) return;\n\n\tif(ctx->to_grayscale) {\n\t\tiw_tmpsample g;\n\t\tg = iw_color_to_grayscale(ctx, clr.c[0], clr.c[1], clr.c[2]);\n\t\tclr.c[0] = clr.c[1] = clr.c[2] = g;\n\t}\n\n\tif(ctx->output_profile&IW_PROFILE_RGB8_BKGD) {\n\t\tmaxcolor=255.0;\n\t}\n\telse if(ctx->output_profile&IW_PROFILE_RGB16_BKGD) {\n\t\tmaxcolor=65535.0;\n\t}\n\telse if(ctx->img2.bit_depth==8) {\n\t\tmaxcolor=255.0;\n\t}\n\telse if(ctx->img2.bit_depth==16) {\n\t\tmaxcolor=65535.0;\n\t}\n\telse {\n\t\treturn;\n\t}\n\n\t// Although the bkgd label is stored as floating point, we're responsible for\n\t// making sure that, when scaled and rounded to a format suitable for the output\n\t// format, it will be the correct color.\n\tfor(k=0;k<3;k++) {\n\t\ttmpu = calc_sample_convert_from_linear(ctx, clr.c[k], &ctx->img2cs, maxcolor);\n\t\tctx->img2.bkgdlabel.c[k] = ((double)tmpu)/maxcolor;\n\t}\n\t// Alpha sample\n\ttmpu = iw_scale_to_int(clr.c[3],(unsigned int)maxcolor);\n\tctx->img2.bkgdlabel.c[3] = ((double)tmpu)/maxcolor;\n\n\tctx->img2.has_bkgdlabel = 1;\n}\n\nstatic void negate_target_image(struct iw_context *ctx)\n{\n\tint channel;\n\tstruct iw_channelinfo_out *ci;\n\tint i,j;\n\tsize_t pos;\n\tiw_float32 s;\n\tunsigned int n;\n\n\tfor(channel=0; channel<ctx->img2_numchannels; channel++) {\n\t\tci = &ctx->img2_ci[channel];\n\t\tif(ci->channeltype == IW_CHANNELTYPE_ALPHA) continue; // Don't negate alpha channels\n\n\t\tif(ctx->img2.sampletype==IW_SAMPLETYPE_FLOATINGPOINT) {\n\t\t\tfor(j=0; j<ctx->img2.height; j++) {\n\t\t\t\tfor(i=0; i<ctx->img2.width; i++) {\n\t\t\t\t\tpos = j*ctx->img2.bpr + ctx->img2_numchannels*i*4 + channel*4;\n\t\t\t\t\ts = iw_get_float32(&ctx->img2.pixels[pos]);\n\t\t\t\t\tiw_put_float32(&ctx->img2.pixels[pos], ((iw_float32)1.0)-s);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\telse if(ctx->img2.bit_depth==8) {\n\t\t\tfor(j=0; j<ctx->img2.height; j++) {\n\t\t\t\tfor(i=0; i<ctx->img2.width; i++) {\n\t\t\t\t\tpos = j*ctx->img2.bpr + ctx->img2_numchannels*i + channel;\n\t\t\t\t\tctx->img2.pixels[pos] = ci->maxcolorcode_int-ctx->img2.pixels[pos];\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\telse if(ctx->img2.bit_depth==16) {\n\t\t\tfor(j=0; j<ctx->img2.height; j++) {\n\t\t\t\tfor(i=0; i<ctx->img2.width; i++) {\n\t\t\t\t\tpos = j*ctx->img2.bpr + ctx->img2_numchannels*i*2 + channel*2;\n\t\t\t\t\tn = ctx->img2.pixels[pos]*256 + ctx->img2.pixels[pos+1];\n\t\t\t\t\tn = ci->maxcolorcode_int - n;\n\t\t\t\t\tctx->img2.pixels[pos] = (n&0xff00)>>8;\n\t\t\t\t\tctx->img2.pixels[pos+1] = n&0x00ff;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n}\n\nstatic int iw_process_internal(struct iw_context *ctx)\n{\n\tint channel;\n\tint retval=0;\n\tint i,k;\n\tint ret;\n\t// A linear color-correction descriptor to use with alpha channels.\n\tstruct iw_csdescr csdescr_linear;\n\n\tctx->intermediate32=NULL;\n\tctx->intermediate_alpha32=NULL;\n\tctx->final_alpha32=NULL;\n\tctx->intermed_canvas_width = ctx->input_w;\n\tctx->intermed_canvas_height = ctx->img2.height;\n\n\tiw_make_linear_csdescr(&csdescr_linear);\n\n\tctx->img2.bpr = iw_calc_bytesperrow(ctx->img2.width,ctx->img2.bit_depth*ctx->img2_numchannels);\n\n\tctx->img2.pixels = iw_malloc_large(ctx, ctx->img2.bpr, ctx->img2.height);\n\tif(!ctx->img2.pixels) {\n\t\tgoto done;\n\t}\n\n\tctx->intermediate32 = (iw_float32*)iw_malloc_large(ctx, ctx->intermed_canvas_width * ctx->intermed_canvas_height, sizeof(iw_float32));\n\tif(!ctx->intermediate32) {\n\t\tgoto done;\n\t}\n\n\tif(ctx->uses_errdiffdither) {\n\t\tfor(k=0;k<IW_DITHER_MAXROWS;k++) {\n\t\t\tctx->dither_errors[k] = (double*)iw_malloc(ctx, ctx->img2.width * sizeof(double));\n\t\t\tif(!ctx->dither_errors[k]) goto done;\n\t\t}\n\t}\n\n\tif(!ctx->disable_output_lookup_tables) {\n\t\tiw_make_x_to_linear_table(ctx,&ctx->output_rev_color_corr_table,&ctx->img2,&ctx->img2cs);\n\n\t\tiw_make_nearest_color_table(ctx,&ctx->nearest_color_table,&ctx->img2,&ctx->img2cs);\n\t}\n\n\t// If an alpha channel is present, we have to process it first.\n\tif(IW_IMGTYPE_HAS_ALPHA(ctx->intermed_imgtype)) {\n\t\tctx->intermediate_alpha32 = (iw_float32*)iw_malloc_large(ctx, ctx->intermed_canvas_width * ctx->intermed_canvas_height, sizeof(iw_float32));\n\t\tif(!ctx->intermediate_alpha32) {\n\t\t\tgoto done;\n\t\t}\n\t\tctx->final_alpha32 = (iw_float32*)iw_malloc_large(ctx, ctx->img2.width * ctx->img2.height, sizeof(iw_float32));\n\t\tif(!ctx->final_alpha32) {\n\t\t\tgoto done;\n\t\t}\n\n\t\tif(!iw_process_one_channel(ctx,ctx->intermed_alpha_channel_index,&csdescr_linear,&csdescr_linear)) goto done;\n\t}\n\n\t// Process the non-alpha channels.\n\n\tfor(channel=0;channel<ctx->intermed_numchannels;channel++) {\n\t\tif(ctx->intermed_ci[channel].channeltype!=IW_CHANNELTYPE_ALPHA) {\n\t\t\tif(ctx->no_gamma)\n\t\t\t\tret=iw_process_one_channel(ctx,channel,&csdescr_linear,&csdescr_linear);\n\t\t\telse\n\t\t\t\tret=iw_process_one_channel(ctx,channel,&ctx->img1cs,&ctx->img2cs);\n\n\t\t\tif(!ret) goto done;\n\t\t}\n\t}\n\n\tiw_process_bkgd_label(ctx);\n\n\tif(ctx->req.negate_target) {\n\t\tnegate_target_image(ctx);\n\t}\n\n\tretval=1;\n\ndone:\n\tif(ctx->intermediate32) { iw_free(ctx,ctx->intermediate32); ctx->intermediate32=NULL; }\n\tif(ctx->intermediate_alpha32) { iw_free(ctx,ctx->intermediate_alpha32); ctx->intermediate_alpha32=NULL; }\n\tif(ctx->final_alpha32) { iw_free(ctx,ctx->final_alpha32); ctx->final_alpha32=NULL; }\n\tfor(k=0;k<IW_DITHER_MAXROWS;k++) {\n\t\tif(ctx->dither_errors[k]) { iw_free(ctx,ctx->dither_errors[k]); ctx->dither_errors[k]=NULL; }\n\t}\n\t// The 'resize contexts' are usually kept around so that they can be reused.\n\t// Now that we're done with everything, free them.\n\tfor(i=0;i<2;i++) { // horizontal, vertical\n\t\tif(ctx->resize_settings[i].rrctx) {\n\t\t\tiwpvt_resize_rows_done(ctx->resize_settings[i].rrctx);\n\t\t\tctx->resize_settings[i].rrctx = NULL;\n\t\t}\n\t}\n\treturn retval;\n}\n\nstatic int iw_get_channeltype(int imgtype, int channel)\n{\n\tswitch(imgtype) {\n\tcase IW_IMGTYPE_GRAY:\n\t\tif(channel==0) return IW_CHANNELTYPE_GRAY;\n\t\tbreak;\n\tcase IW_IMGTYPE_GRAYA:\n\t\tif(channel==0) return IW_CHANNELTYPE_GRAY;\n\t\tif(channel==1) return IW_CHANNELTYPE_ALPHA;\n\t\tbreak;\n\tcase IW_IMGTYPE_RGB:\n\t\tif(channel==0) return IW_CHANNELTYPE_RED;\n\t\tif(channel==1) return IW_CHANNELTYPE_GREEN;\n\t\tif(channel==2) return IW_CHANNELTYPE_BLUE;\n\t\tbreak;\n\tcase IW_IMGTYPE_RGBA:\n\t\tif(channel==0) return IW_CHANNELTYPE_RED;\n\t\tif(channel==1) return IW_CHANNELTYPE_GREEN;\n\t\tif(channel==2) return IW_CHANNELTYPE_BLUE;\n\t\tif(channel==3) return IW_CHANNELTYPE_ALPHA;\n\t\tbreak;\n\t}\n\treturn 0;\n}\n\nstatic void iw_set_input_channeltypes(struct iw_context *ctx)\n{\n\tint i;\n\tfor(i=0;i<ctx->img1_numchannels_logical;i++) {\n\t\tctx->img1_ci[i].channeltype = iw_get_channeltype(ctx->img1_imgtype_logical,i);\n\t}\n}\n\nstatic void iw_set_intermed_channeltypes(struct iw_context *ctx)\n{\n\tint i;\n\tfor(i=0;i<ctx->intermed_numchannels;i++) {\n\t\tctx->intermed_ci[i].channeltype = iw_get_channeltype(ctx->intermed_imgtype,i);\n\t}\n}\n\nstatic void iw_set_out_channeltypes(struct iw_context *ctx)\n{\n\tint i;\n\tfor(i=0;i<ctx->img2_numchannels;i++) {\n\t\tctx->img2_ci[i].channeltype = iw_get_channeltype(ctx->img2.imgtype,i);\n\t}\n}\n\n// Set img2.bit_depth based on output_depth_req, etc.\n// Set img2.sampletype.\nstatic void decide_output_bit_depth(struct iw_context *ctx)\n{\n\tif(ctx->output_profile&IW_PROFILE_HDRI) {\n\t\tctx->img2.sampletype=IW_SAMPLETYPE_FLOATINGPOINT;\n\t}\n\telse {\n\t\tctx->img2.sampletype=IW_SAMPLETYPE_UINT;\n\t}\n\n\tif(ctx->img2.sampletype==IW_SAMPLETYPE_FLOATINGPOINT) {\n\t\t// Floating point output.\n\t\tctx->img2.bit_depth=32;\n\t\treturn;\n\t}\n\n\t// Below this point, sample type is UINT.\n\n\tif(ctx->req.output_depth>8 && (ctx->output_profile&IW_PROFILE_16BPS)) {\n\t\tctx->img2.bit_depth=16;\n\t}\n\telse {\n\t\tif(ctx->req.output_depth>8) {\n\t\t\t// Caller requested a depth higher than this format can handle.\n\t\t\tiw_warning(ctx,\"Reducing depth to 8; required by the output format.\");\n\t\t}\n\t\tctx->img2.bit_depth=8;\n\t}\n}\n\n// Set the background color samples that will be used when processing the\n// image. (All the logic about how to apply a background color is in\n// decide_how_to_apply_bkgd(), not here.)\nstatic void prepare_apply_bkgd(struct iw_context *ctx)\n{\n\tstruct iw_color bkgd1; // Main background color in linear colorspace\n\tstruct iw_color bkgd2; // Secondary background color ...\n\tint i;\n\n\tif(!ctx->apply_bkgd) return;\n\n\t// Start with a default background color.\n\tbkgd1.c[0]=1.0; bkgd1.c[1]=0.0; bkgd1.c[2]=1.0; bkgd1.c[3]=1.0;\n\tbkgd2.c[0]=0.0; bkgd2.c[1]=0.0; bkgd2.c[2]=0.0; bkgd2.c[3]=1.0;\n\n\t// Possibly overwrite it with the background color from the appropriate\n\t// source.\n\tif(ctx->bkgd_color_source == IW_BKGD_COLOR_SOURCE_FILE) {\n\t\tbkgd1 = ctx->img1_bkgd_label_lin; // sructure copy\n\t\tctx->bkgd_checkerboard = 0;\n\t}\n\telse if(ctx->bkgd_color_source == IW_BKGD_COLOR_SOURCE_REQ) {\n\t\tbkgd1 = ctx->req.bkgd;\n\t\tif(ctx->req.bkgd_checkerboard) {\n\t\t\tbkgd2 = ctx->req.bkgd2;\n\t\t}\n\t}\n\n\t// Set up the channelinfo (and ctx->bkgd*alpha) as needed according to the\n\t// target image type, and whether we are applying the background before or\n\t// after resizing.\n\n\tif(ctx->apply_bkgd_strategy==IW_BKGD_STRATEGY_EARLY) {\n\t\tctx->bkgd1alpha = 1.0;\n\t}\n\telse {\n\t\tctx->bkgd1alpha = bkgd1.c[3];\n\t\tctx->bkgd2alpha = bkgd2.c[3];\n\t}\n\n\tif(ctx->apply_bkgd_strategy==IW_BKGD_STRATEGY_LATE && (ctx->img2.imgtype==IW_IMGTYPE_RGB ||\n\t\tctx->img2.imgtype==IW_IMGTYPE_RGBA))\n\t{\n\t\tfor(i=0;i<3;i++) {\n\t\t\tctx->img2_ci[i].bkgd1_color_lin = bkgd1.c[i];\n\t\t}\n\t\tif(ctx->bkgd_checkerboard) {\n\t\t\tfor(i=0;i<3;i++) {\n\t\t\t\tctx->img2_ci[i].bkgd2_color_lin = bkgd2.c[i];\n\t\t\t}\n\t\t}\n\t}\n\telse if(ctx->apply_bkgd_strategy==IW_BKGD_STRATEGY_LATE && (ctx->img2.imgtype==IW_IMGTYPE_GRAY ||\n\t\tctx->img2.imgtype==IW_IMGTYPE_GRAYA))\n\t{\n\t\tctx->img2_ci[0].bkgd1_color_lin = iw_color_to_grayscale(ctx,bkgd1.c[0],bkgd1.c[1],bkgd1.c[2]);\n\t\tif(ctx->bkgd_checkerboard) {\n\t\t\tctx->img2_ci[0].bkgd2_color_lin = iw_color_to_grayscale(ctx,bkgd2.c[0],bkgd2.c[1],bkgd2.c[2]);\n\t\t}\n\t}\n\telse if(ctx->apply_bkgd_strategy==IW_BKGD_STRATEGY_EARLY && ctx->img2.imgtype==IW_IMGTYPE_RGB) {\n\t\tfor(i=0;i<3;i++) {\n\t\t\tctx->intermed_ci[i].bkgd_color_lin = bkgd1.c[i];\n\t\t}\n\t}\n\telse if(ctx->apply_bkgd_strategy==IW_BKGD_STRATEGY_EARLY && ctx->img2.imgtype==IW_IMGTYPE_GRAY) {\n\t\tctx->intermed_ci[0].bkgd_color_lin = iw_color_to_grayscale(ctx,bkgd1.c[0],bkgd1.c[1],bkgd1.c[2]);\n\t}\n}\n\n#define IW_STRAT1_G_G       0x011 // -grayscale\n#define IW_STRAT1_G_RGB     0x013 // default\n#define IW_STRAT1_GA_G      0x021 // -grayscale, BKGD_STRATEGY_EARLY (never happens?)\n#define IW_STRAT1_GA_GA     0x022 // -grayscale\n#define IW_STRAT1_GA_RGB    0x023 // BKGD_STRATEGY_EARLY\n#define IW_STRAT1_GA_RGBA   0x024 // default\n#define IW_STRAT1_RGB_G     0x031 // -grayscale\n#define IW_STRAT1_RGB_RGB   0x033 // default\n#define IW_STRAT1_RGBA_G    0x041 // -grayscale, BKGD_STRATEGY_EARLY (never happens?)\n#define IW_STRAT1_RGBA_GA   0x042 // -grayscale\n#define IW_STRAT1_RGBA_RGB  0x043 // BKGD_STRATEGY_EARLY\n#define IW_STRAT1_RGBA_RGBA 0x044 // default\n\n#define IW_STRAT2_G_G       0x111 // -grayscale\n#define IW_STRAT2_GA_G      0x121 // -grayscale, BKGD_STRATEGY_LATE\n#define IW_STRAT2_GA_GA     0x122 // -grayscale\n#define IW_STRAT2_RGB_RGB   0x133 // default\n#define IW_STRAT2_RGBA_RGB  0x143 // BKGD_STRATEGY_LATE\n#define IW_STRAT2_RGBA_RGBA 0x144 // default\n\n\nstatic void iw_restrict_to_range(int r1, int r2, int *pvar)\n{\n\tif(*pvar < r1) *pvar = r1;\n\telse if(*pvar > r2) *pvar = r2;\n}\n\nstatic void decide_strategy(struct iw_context *ctx, int *ps1, int *ps2)\n{\n\tint s1, s2;\n\n\t// Start with a default strategy\n\tswitch(ctx->img1_imgtype_logical) {\n\tcase IW_IMGTYPE_RGBA:\n\t\tif(ctx->to_grayscale) {\n\t\t\ts1=IW_STRAT1_RGBA_GA;\n\t\t\ts2=IW_STRAT2_GA_GA;\n\t\t}\n\t\telse {\n\t\t\ts1=IW_STRAT1_RGBA_RGBA;\n\t\t\ts2=IW_STRAT2_RGBA_RGBA;\n\t\t}\n\t\tbreak;\n\tcase IW_IMGTYPE_RGB:\n\t\tif(ctx->to_grayscale) {\n\t\t\ts1=IW_STRAT1_RGB_G;\n\t\t\ts2=IW_STRAT2_G_G;\n\t\t}\n\t\telse {\n\t\t\ts1=IW_STRAT1_RGB_RGB;\n\t\t\ts2=IW_STRAT2_RGB_RGB;\n\t\t}\n\t\tbreak;\n\tcase IW_IMGTYPE_GRAYA:\n\t\tif(ctx->to_grayscale) {\n\t\t\ts1=IW_STRAT1_GA_GA;\n\t\t\ts2=IW_STRAT2_GA_GA;\n\t\t}\n\t\telse {\n\t\t\ts1=IW_STRAT1_GA_RGBA;\n\t\t\ts2=IW_STRAT2_RGBA_RGBA;\n\t\t}\n\t\tbreak;\n\tdefault:\n\t\tif(ctx->to_grayscale) {\n\t\t\ts1=IW_STRAT1_G_G;\n\t\t\ts2=IW_STRAT2_G_G;\n\t\t}\n\t\telse {\n\t\t\ts1=IW_STRAT1_G_RGB;\n\t\t\ts2=IW_STRAT2_RGB_RGB;\n\t\t}\n\t}\n\n\tif(ctx->apply_bkgd && ctx->apply_bkgd_strategy==IW_BKGD_STRATEGY_EARLY) {\n\t\t// Applying background before resizing\n\t\tif(s1==IW_STRAT1_RGBA_RGBA) {\n\t\t\ts1=IW_STRAT1_RGBA_RGB;\n\t\t\ts2=IW_STRAT2_RGB_RGB;\n\t\t}\n\t\telse if(s1==IW_STRAT1_GA_GA) {\n\t\t\ts1=IW_STRAT1_GA_G;\n\t\t\ts2=IW_STRAT2_G_G;\n\t\t}\n\t\telse if(s1==IW_STRAT1_GA_RGBA) {\n\t\t\ts1=IW_STRAT1_GA_RGB;\n\t\t\ts2=IW_STRAT2_RGB_RGB;\n\t\t}\n\t\telse if(s1==IW_STRAT1_RGBA_GA) {\n\t\t\ts1=IW_STRAT1_RGBA_G;\n\t\t\ts2=IW_STRAT2_G_G;\n\t\t}\n\t}\n\n\tif(ctx->apply_bkgd && !iw_bkgd_has_transparency(ctx)) {\n\t\tif(s2==IW_STRAT2_GA_GA) {\n\t\t\ts2=IW_STRAT2_GA_G;\n\t\t}\n\t\telse if(s2==IW_STRAT2_RGBA_RGBA) {\n\t\t\ts2=IW_STRAT2_RGBA_RGB;\n\t\t}\n\t}\n\n\t*ps1 = s1;\n\t*ps2 = s2;\n}\n\n// Choose our strategy for applying a background to the image.\n// Uses:\n//   - ctx->img1_imgtype_logical (set by init_channel_info())\n//   - ctx->req.bkgd_valid (was background set by caller?)\n//   - ctx->req.bkgd_checkerboard (set by caller)\n//   - ctx->bkgd_check_size (set by caller)\n//   - ctx->resize_settings[d].use_offset\n// Sets:\n//   - ctx->apply_bkgd (flag indicating whether we'll apply a background)\n//   - ctx->apply_bkgd_strategy (flag indicating *when* we'll apply a background)\n//   - ctx->bkgd_color_source (where to get the background color)\n//   - ctx->bkgd_checkerboard\n//   - ctx->bkgd_check_size (sanitized)\n// May emit a warning if the caller's settings can't be honored.\nstatic void decide_how_to_apply_bkgd(struct iw_context *ctx)\n{\n\tif(!IW_IMGTYPE_HAS_ALPHA(ctx->img1_imgtype_logical)) {\n\t\t// If we know the image does not have any transparency,\n\t\t// we don't have to do anything.\n\t\tctx->apply_bkgd=0;\n\t\treturn;\n\t}\n\n\t// Figure out where to get the background color from, on the assumption\n\t// that we'll use one.\n\tif(ctx->img1_bkgd_label_set &&\n\t\t(ctx->req.use_bkgd_label_from_file || !ctx->req.bkgd_valid))\n\t{\n\t\t// The input file has a background color label, and either we are\n\t\t// requested to prefer it to the caller's background color, or\n\t\t// the caller did not give us a background color.\n\t\t// Use the color from the input file.\n\t\tctx->bkgd_color_source = IW_BKGD_COLOR_SOURCE_FILE;\n\t}\n\telse if(ctx->req.bkgd_valid) {\n\t\t// Use the background color given by the caller.\n\t\tctx->bkgd_color_source = IW_BKGD_COLOR_SOURCE_REQ;\n\t\t// Tentatively use the caller's checkerboard setting.\n\t\t// This may be overridden if we can't support checkerboard backgrounds\n\t\t// for some reason.\n\t\tctx->bkgd_checkerboard = ctx->req.bkgd_checkerboard;\n\t}\n\telse {\n\t\t// No background color available. If we need one, we'll have to invent one.\n\t\tctx->bkgd_color_source = IW_BKGD_COLOR_SOURCE_NONE;\n\t}\n\n\tif(ctx->bkgd_checkerboard) {\n\t\tif(ctx->bkgd_check_size<1) ctx->bkgd_check_size=1;\n\t}\n\n\tif(ctx->req.bkgd_valid) {\n\t\t// Caller told us to apply a background.\n\t\tctx->apply_bkgd=1;\n\t}\n\n\tif(!(ctx->output_profile&IW_PROFILE_TRANSPARENCY)) {\n\t\tif(!ctx->req.bkgd_valid && !ctx->apply_bkgd) {\n\t\t\tiw_warning(ctx,\"This image may have transparency, which is incompatible with the output format. A background color will be applied.\");\n\t\t}\n\t\tctx->apply_bkgd=1;\n\t}\n\n\tif(ctx->resize_settings[IW_DIMENSION_H].use_offset ||\n\t\tctx->resize_settings[IW_DIMENSION_V].use_offset)\n\t{\n\t\t// If channel offset is enabled, and the image has transparency, we\n\t\t// must apply a solid color background (and we must apply it before\n\t\t// resizing), regardless of whether the user asked for it. It's the\n\t\t// only strategy we support.\n\t\tif(!ctx->req.bkgd_valid && !ctx->apply_bkgd) {\n\t\t\tiw_warning(ctx,\"This image may have transparency, which is incompatible with a channel offset. A background color will be applied.\");\n\t\t}\n\t\tctx->apply_bkgd=1;\n\n\t\tif(ctx->bkgd_checkerboard && ctx->req.bkgd_checkerboard) {\n\t\t\tiw_warning(ctx,\"Checkerboard backgrounds are not supported when using a channel offset.\");\n\t\t\tctx->bkgd_checkerboard=0;\n\t\t}\n\t\tctx->apply_bkgd_strategy=IW_BKGD_STRATEGY_EARLY;\n\t\treturn;\n\t}\n\n\tif(!ctx->apply_bkgd) {\n\t\t// No reason to apply a background color.\n\t\treturn;\n\t}\n\n\tif(ctx->bkgd_checkerboard) {\n\t\t// Non-solid-color backgrounds must be applied after resizing.\n\t\tctx->apply_bkgd_strategy=IW_BKGD_STRATEGY_LATE;\n\t\treturn;\n\t}\n\n\t// At this point, either Early or Late background application is possible,\n\t// and (I think) would, in an idealized situation, yield the same result.\n\t// Things that can cause it to be different include\n\t// * using a different resampling algorithm for the alpha channel (this is\n\t//   no longer supported)\n\t// * 'intermediate clamping'\n\t//\n\t// Setting this to Late is the safe, though it is slower than Early.\n\tctx->apply_bkgd_strategy=IW_BKGD_STRATEGY_LATE;\n}\n\nstatic void iw_set_auto_resizetype(struct iw_context *ctx, int size1, int size2,\n\tint dimension)\n{\n\t// If not changing the size, default to \"null\" resize if we can.\n\t// (We can't do that if using a translation or channel offset.)\n\tif(size2==size1 && !ctx->resize_settings[dimension].use_offset &&\n\t\t!ctx->req.out_true_valid &&\n\t\tctx->resize_settings[dimension].translate==0.0)\n\t{\n\t\tiw_set_resize_alg(ctx, dimension, IW_RESIZETYPE_NULL, 1.0, 0.0, 0.0);\n\t\treturn;\n\t}\n\n\t// Otherwise, default to Catmull-Rom\n\tiw_set_resize_alg(ctx, dimension, IW_RESIZETYPE_CUBIC, 1.0, 0.0, 0.5);\n}\n\nstatic void init_channel_info(struct iw_context *ctx)\n{\n\tint i;\n\n\tctx->img1_imgtype_logical = ctx->img1.imgtype;\n\n\tif(ctx->resize_settings[IW_DIMENSION_H].edge_policy==IW_EDGE_POLICY_TRANSPARENT ||\n\t\tctx->resize_settings[IW_DIMENSION_V].edge_policy==IW_EDGE_POLICY_TRANSPARENT)\n\t{\n\t\t// Add a virtual alpha channel\n\t\tif(ctx->img1.imgtype==IW_IMGTYPE_GRAY) {\n\t\t\tctx->img1_imgtype_logical = IW_IMGTYPE_GRAYA;\n\t\t}\n\t\telse if(ctx->img1.imgtype==IW_IMGTYPE_RGB)\n\t\t\tctx->img1_imgtype_logical = IW_IMGTYPE_RGBA;\n\t}\n\n\tctx->img1_numchannels_physical = iw_imgtype_num_channels(ctx->img1.imgtype);\n\tctx->img1_numchannels_logical = iw_imgtype_num_channels(ctx->img1_imgtype_logical);\n\tctx->img1_alpha_channel_index = iw_imgtype_alpha_channel_index(ctx->img1_imgtype_logical);\n\n\tiw_set_input_channeltypes(ctx);\n\n\tctx->img2.imgtype = ctx->img1_imgtype_logical; // default\n\tctx->img2_numchannels = ctx->img1_numchannels_logical; // default\n\tctx->intermed_numchannels = ctx->img1_numchannels_logical; // default\n\n\tfor(i=0;i<ctx->img1_numchannels_logical;i++) {\n\t\tctx->intermed_ci[i].channeltype = ctx->img1_ci[i].channeltype;\n\t\tctx->intermed_ci[i].corresponding_input_channel = i;\n\t\tctx->img2_ci[i].channeltype = ctx->img1_ci[i].channeltype;\n\t\tif(i>=ctx->img1_numchannels_physical) {\n\t\t\t// This is a virtual channel, which is handled by get_raw_sample().\n\t\t\t// But some optimizations cause that function to be bypassed, so we\n\t\t\t// have to disable those optimizations.\n\t\t\tctx->img1_ci[i].disable_fast_get_sample = 1;\n\t\t}\n\t}\n}\n\n// Set the weights for the grayscale algorithm, if needed.\nstatic void prepare_grayscale(struct iw_context *ctx)\n{\n\tswitch(ctx->grayscale_formula) {\n\tcase IW_GSF_STANDARD:\n\t\tctx->grayscale_formula = IW_GSF_WEIGHTED;\n\t\tiw_set_grayscale_weights(ctx,0.212655,0.715158,0.072187);\n\t\tbreak;\n\tcase IW_GSF_COMPATIBLE:\n\t\tctx->grayscale_formula = IW_GSF_WEIGHTED;\n\t\tiw_set_grayscale_weights(ctx,0.299,0.587,0.114);\n\t\tbreak;\n\t}\n}\n\n// Set up some things before we do the resize, and check to make\n// sure everything looks okay.\nstatic int iw_prepare_processing(struct iw_context *ctx, int w, int h)\n{\n\tint i,j;\n\tint output_maxcolorcode_int;\n\tint strategy1, strategy2;\n\tint flag;\n\n\tif(ctx->output_profile==0) {\n\t\tiw_set_error(ctx,\"Output profile not set\");\n\t\treturn 0;\n\t}\n\n\tif(!ctx->prng) {\n\t\t// TODO: It would be better to only create the random number generator\n\t\t// if we will need it.\n\t\tctx->prng = iwpvt_prng_create(ctx);\n\t}\n\n\tif(ctx->randomize) {\n\t\t// Acquire and record a random seed. This also seeds the PRNG, but\n\t\t// that's irrelevant. It will be re-seeded before it is used.\n\t\tctx->random_seed = iwpvt_util_randomize(ctx->prng);\n\t}\n\n\tif(ctx->req.out_true_valid) {\n\t\tctx->resize_settings[IW_DIMENSION_H].out_true_size = ctx->req.out_true_width;\n\t\tctx->resize_settings[IW_DIMENSION_V].out_true_size = ctx->req.out_true_height;\n\t}\n\telse {\n\t\tctx->resize_settings[IW_DIMENSION_H].out_true_size = (double)w;\n\t\tctx->resize_settings[IW_DIMENSION_V].out_true_size = (double)h;\n\t}\n\n\tif(!iw_check_image_dimensions(ctx,ctx->img1.width,ctx->img1.height)) {\n\t\treturn 0;\n\t}\n\tif(!iw_check_image_dimensions(ctx,w,h)) {\n\t\treturn 0;\n\t}\n\n\tif(ctx->to_grayscale) {\n\t\tprepare_grayscale(ctx);\n\t}\n\n\tinit_channel_info(ctx);\n\n\tctx->img2.width = w;\n\tctx->img2.height = h;\n\n\t// Figure out the region of the source image to read from.\n\tif(ctx->input_start_x<0) ctx->input_start_x=0;\n\tif(ctx->input_start_y<0) ctx->input_start_y=0;\n\tif(ctx->input_start_x>ctx->img1.width-1) ctx->input_start_x=ctx->img1.width-1;\n\tif(ctx->input_start_y>ctx->img1.height-1) ctx->input_start_x=ctx->img1.height-1;\n\tif(ctx->input_w<0) ctx->input_w = ctx->img1.width - ctx->input_start_x;\n\tif(ctx->input_h<0) ctx->input_h = ctx->img1.height - ctx->input_start_y;\n\tif(ctx->input_w<1) ctx->input_w = 1;\n\tif(ctx->input_h<1) ctx->input_h = 1;\n\tif(ctx->input_w>(ctx->img1.width-ctx->input_start_x)) ctx->input_w=ctx->img1.width-ctx->input_start_x;\n\tif(ctx->input_h>(ctx->img1.height-ctx->input_start_y)) ctx->input_h=ctx->img1.height-ctx->input_start_y;\n\n\t// Decide on the output colorspace.\n\tif(ctx->req.output_cs_valid) {\n\t\t// Try to use colorspace requested by caller.\n\t\tctx->img2cs = ctx->req.output_cs;\n\n\t\tif(ctx->output_profile&IW_PROFILE_ALWAYSLINEAR) {\n\t\t\tif(ctx->img2cs.cstype!=IW_CSTYPE_LINEAR) {\n\t\t\t\tiw_warning(ctx,\"Forcing output colorspace to linear; required by the output format.\");\n\t\t\t\tiw_make_linear_csdescr(&ctx->img2cs);\n\t\t\t}\n\t\t}\n\t}\n\telse {\n\t\t// By default, set the output colorspace to sRGB in most cases.\n\t\tif(ctx->output_profile&IW_PROFILE_ALWAYSLINEAR) {\n\t\t\tiw_make_linear_csdescr(&ctx->img2cs);\n\t\t}\n\t\telse {\n\t\t\tiw_make_srgb_csdescr_2(&ctx->img2cs);\n\t\t}\n\t}\n\n\t// Make sure maxcolorcodes are set.\n\tif(ctx->img1.sampletype!=IW_SAMPLETYPE_FLOATINGPOINT) {\n\t\tctx->input_maxcolorcode_int = (1 << ctx->img1.bit_depth)-1;\n\t\tctx->input_maxcolorcode = (double)ctx->input_maxcolorcode_int;\n\n\t\tfor(i=0;i<IW_CI_COUNT;i++) {\n\t\t\tif(ctx->img1_ci[i].maxcolorcode_int<=0) {\n\t\t\t\tctx->img1_ci[i].maxcolorcode_int = ctx->input_maxcolorcode_int;\n\t\t\t}\n\t\t\tctx->img1_ci[i].maxcolorcode_dbl = (double)ctx->img1_ci[i].maxcolorcode_int;\n\n\t\t\tif(ctx->img1_ci[i].maxcolorcode_int != ctx->input_maxcolorcode_int) {\n\t\t\t\t// This is overzealous: We could enable it per-channel.\n\t\t\t\t// But it's probably not worth the trouble.\n\t\t\t\tctx->support_reduced_input_bitdepths = 1;\n\t\t\t}\n\t\t}\n\t}\n\n\tif(ctx->support_reduced_input_bitdepths ||\n\t\tctx->img1.sampletype==IW_SAMPLETYPE_FLOATINGPOINT)\n\t{\n\t\tfor(i=0;i<ctx->img1_numchannels_physical;i++) {\n\t\t\tctx->img1_ci[i].disable_fast_get_sample=1;\n\t\t}\n\t}\n\n\t// Set the .use_offset flags, based on whether the caller set any\n\t// .channel_offset[]s.\n\tfor(i=0;i<2;i++) { // horizontal, vertical\n\t\tfor(j=0;j<3;j++) { // red, green, blue\n\t\t\tif(fabs(ctx->resize_settings[i].channel_offset[j])>0.00001) {\n\t\t\t\tctx->resize_settings[i].use_offset=1;\n\t\t\t}\n\t\t}\n\t}\n\n\tif(ctx->to_grayscale &&\n\t\t(ctx->resize_settings[IW_DIMENSION_H].use_offset ||\n\t\tctx->resize_settings[IW_DIMENSION_V].use_offset) )\n\t{\n\t\tiw_warning(ctx,\"Disabling channel offset, due to grayscale output.\");\n\t\tctx->resize_settings[IW_DIMENSION_H].use_offset=0;\n\t\tctx->resize_settings[IW_DIMENSION_V].use_offset=0;\n\t}\n\n\tdecide_how_to_apply_bkgd(ctx);\n\n\t// Decide if we can cache the resize settings.\n\tfor(i=0;i<2;i++) {\n\t\tif(ctx->resize_settings[i].use_offset ||\n\t\t  (ctx->apply_bkgd &&\n\t\t   ctx->apply_bkgd_strategy==IW_BKGD_STRATEGY_EARLY &&\n\t\t   ctx->resize_settings[i].edge_policy==IW_EDGE_POLICY_TRANSPARENT))\n\t\t{\n\t\t\t// If a channel offset is used, we have to disable caching, because the\n\t\t\t// offset is stored in the cache, and it won't be the same for all channels.\n\t\t\t// If transparent virtual pixels will be converted to the background color\n\t\t\t// during the resize, we have to disable caching, because the background\n\t\t\t// sample value is stored in the cache, and it may be different for each\n\t\t\t// channel.\n\t\t\tctx->resize_settings[i].disable_rrctx_cache=1;\n\t\t}\n\t}\n\n\tdecide_strategy(ctx,&strategy1,&strategy2);\n\n\tswitch(strategy1) { // input-to-intermediate\n\tcase IW_STRAT1_RGBA_RGBA:\n\t\tctx->intermed_imgtype = IW_IMGTYPE_RGBA;\n\t\tbreak;\n\tcase IW_STRAT1_GA_RGBA:\n\t\tctx->intermed_imgtype = IW_IMGTYPE_RGBA;\n\t\tctx->intermed_ci[0].corresponding_input_channel=0;\n\t\tctx->intermed_ci[1].corresponding_input_channel=0;\n\t\tctx->intermed_ci[2].corresponding_input_channel=0;\n\t\tctx->intermed_ci[3].corresponding_input_channel=1;\n\t\tbreak;\n\tcase IW_STRAT1_RGB_RGB:\n\tcase IW_STRAT1_RGBA_RGB:\n\t\tctx->intermed_imgtype = IW_IMGTYPE_RGB;\n\t\tbreak;\n\tcase IW_STRAT1_G_RGB:\n\tcase IW_STRAT1_GA_RGB:\n\t\tctx->intermed_imgtype = IW_IMGTYPE_RGB;\n\t\tctx->intermed_ci[0].corresponding_input_channel=0;\n\t\tctx->intermed_ci[1].corresponding_input_channel=0;\n\t\tctx->intermed_ci[2].corresponding_input_channel=0;\n\t\tbreak;\n\tcase IW_STRAT1_RGBA_GA:\n\t\tctx->intermed_imgtype = IW_IMGTYPE_GRAYA;\n\t\tctx->intermed_ci[0].cvt_to_grayscale=1;\n\t\tctx->intermed_ci[0].corresponding_input_channel=0;\n\t\tctx->intermed_ci[1].corresponding_input_channel=3;\n\t\tbreak;\n\tcase IW_STRAT1_GA_GA:\n\t\tctx->intermed_imgtype = IW_IMGTYPE_GRAYA;\n\t\tbreak;\n\tcase IW_STRAT1_RGB_G:\n\t\tctx->intermed_imgtype = IW_IMGTYPE_GRAY;\n\t\tctx->intermed_ci[0].cvt_to_grayscale=1;\n\t\tctx->intermed_ci[0].corresponding_input_channel=0;\n\t\tbreak;\n\tcase IW_STRAT1_G_G:\n\t\tctx->intermed_imgtype = IW_IMGTYPE_GRAY;\n\t\tctx->intermed_ci[0].corresponding_input_channel=0;\n\t\tbreak;\n\tdefault:\n\t\tiw_set_errorf(ctx,\"Internal error, unknown strategy %d\",strategy1);\n\t\treturn 0;\n\t}\n\n\tctx->intermed_numchannels = iw_imgtype_num_channels(ctx->intermed_imgtype);\n\tctx->intermed_alpha_channel_index = iw_imgtype_alpha_channel_index(ctx->intermed_imgtype);\n\n\t// Start with default mapping:\n\tfor(i=0;i<ctx->intermed_numchannels;i++) {\n\t\tctx->intermed_ci[i].corresponding_output_channel = i;\n\t}\n\n\tswitch(strategy2) { // intermediate-to-output\n\tcase IW_STRAT2_RGBA_RGBA:\n\t\tctx->img2.imgtype = IW_IMGTYPE_RGBA;\n\t\tbreak;\n\tcase IW_STRAT2_RGB_RGB:\n\t\tctx->img2.imgtype = IW_IMGTYPE_RGB;\n\t\tbreak;\n\tcase IW_STRAT2_RGBA_RGB:\n\t\tctx->img2.imgtype = IW_IMGTYPE_RGB;\n\t\tctx->intermed_ci[3].corresponding_output_channel= -1;\n\t\tbreak;\n\tcase IW_STRAT2_GA_GA:\n\t\tctx->img2.imgtype = IW_IMGTYPE_GRAYA;\n\t\tbreak;\n\tcase IW_STRAT2_G_G:\n\t\tctx->img2.imgtype = IW_IMGTYPE_GRAY;\n\t\tbreak;\n\tcase IW_STRAT2_GA_G:\n\t\tctx->img2.imgtype = IW_IMGTYPE_GRAY;\n\t\tctx->intermed_ci[1].corresponding_output_channel= -1;\n\t\tbreak;\n\tdefault:\n\t\tiw_set_error(ctx,\"Internal error\");\n\t\treturn 0;\n\t}\n\n\tctx->img2_numchannels = iw_imgtype_num_channels(ctx->img2.imgtype);\n\n\tiw_set_intermed_channeltypes(ctx);\n\tiw_set_out_channeltypes(ctx);\n\n\t// If an alpha channel is present, set a flag on the other channels to indicate\n\t// that we have to process them differently.\n\tif(IW_IMGTYPE_HAS_ALPHA(ctx->intermed_imgtype)) {\n\t\tfor(i=0;i<ctx->intermed_numchannels;i++) {\n\t\t\tif(ctx->intermed_ci[i].channeltype!=IW_CHANNELTYPE_ALPHA)\n\t\t\t\tctx->intermed_ci[i].need_unassoc_alpha_processing = 1;\n\t\t}\n\t}\n\n\n\tdecide_output_bit_depth(ctx);\n\n\tif(ctx->img2.sampletype==IW_SAMPLETYPE_FLOATINGPOINT) {\n\t\tflag=0;\n\t\tfor(i=0;i<IW_NUM_CHANNELTYPES;i++) {\n\t\t\tif(ctx->req.color_count[i]) flag=1;\n\t\t}\n\t\tif(flag) {\n\t\t\tiw_warning(ctx,\"Posterization is not supported with floating point output.\");\n\t\t}\n\t}\n\telse {\n\t\toutput_maxcolorcode_int = (1 << ctx->img2.bit_depth)-1;\n\n\t\t// Set the default maxcolorcodes\n\t\tfor(i=0;i<ctx->img2_numchannels;i++) {\n\t\t\tctx->img2_ci[i].maxcolorcode_int = output_maxcolorcode_int;\n\t\t}\n\n\t\t// Check for special \"reduced\" colorcodes.\n\t\tif((ctx->output_profile&IW_PROFILE_REDUCEDBITDEPTHS)) {\n\t\t\tfor(i=0;i<ctx->img2_numchannels;i++) {\n\t\t\t\tint mccr;\n\t\t\t\tmccr = ctx->req.output_maxcolorcode[ctx->img2_ci[i].channeltype];\n\t\t\t\tif(mccr>0) {\n\t\t\t\t\tif(mccr>output_maxcolorcode_int) mccr=output_maxcolorcode_int;\n\t\t\t\t\tctx->img2_ci[i].maxcolorcode_int = mccr;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t// Set some flags, and set the floating-point versions of the maxcolorcodes.\n\t\tfor(i=0;i<ctx->img2_numchannels;i++) {\n\t\t\tif(ctx->img2_ci[i].maxcolorcode_int != output_maxcolorcode_int) {\n\t\t\t\tctx->reduced_output_maxcolor_flag = 1;\n\t\t\t\tctx->disable_output_lookup_tables = 1;\n\t\t\t}\n\n\t\t\tctx->img2_ci[i].maxcolorcode_dbl = (double)ctx->img2_ci[i].maxcolorcode_int;\n\t\t}\n\t}\n\n\tfor(i=0;i<ctx->img2_numchannels;i++) {\n\t\tctx->img2_ci[i].color_count = ctx->req.color_count[ctx->img2_ci[i].channeltype];\n\t\tif(ctx->img2_ci[i].color_count) {\n\t\t\tiw_restrict_to_range(2,ctx->img2_ci[i].maxcolorcode_int,&ctx->img2_ci[i].color_count);\n\t\t}\n\t\tif(ctx->img2_ci[i].color_count==1+ctx->img2_ci[i].maxcolorcode_int) {\n\t\t\tctx->img2_ci[i].color_count = 0;\n\t\t}\n\n\t\tctx->img2_ci[i].ditherfamily = ctx->ditherfamily_by_channeltype[ctx->img2_ci[i].channeltype];\n\t\tctx->img2_ci[i].dithersubtype = ctx->dithersubtype_by_channeltype[ctx->img2_ci[i].channeltype];\n\t}\n\n\t// Scan the output channels to see whether certain types of dithering are used.\n\tfor(i=0;i<ctx->img2_numchannels;i++) {\n\t\tif(ctx->img2_ci[i].ditherfamily==IW_DITHERFAMILY_ERRDIFF) {\n\t\t\tctx->uses_errdiffdither=1;\n\t\t}\n\t}\n\n\tif(!ctx->support_reduced_input_bitdepths && ctx->img1.sampletype==IW_SAMPLETYPE_UINT) {\n\t\tiw_make_x_to_linear_table(ctx,&ctx->input_color_corr_table,&ctx->img1,&ctx->img1cs);\n\t}\n\n\tif(ctx->img1_bkgd_label_set) {\n\t\t// Convert the background color to a linear colorspace.\n\t\tfor(i=0;i<3;i++) {\n\t\t\tctx->img1_bkgd_label_lin.c[i] = x_to_linear_sample(ctx->img1_bkgd_label_inputcs.c[i],&ctx->img1cs);\n\t\t}\n\t\tctx->img1_bkgd_label_lin.c[3] = ctx->img1_bkgd_label_inputcs.c[3];\n\t}\n\n\tif(ctx->apply_bkgd) {\n\t\tprepare_apply_bkgd(ctx);\n\t}\n\n\tif(ctx->req.output_rendering_intent==IW_INTENT_UNKNOWN) {\n\t\t// User didn't request a specific intent; copy from input file.\n\t\tctx->img2.rendering_intent = ctx->img1.rendering_intent;\n\t}\n\telse {\n\t\tctx->img2.rendering_intent = ctx->req.output_rendering_intent;\n\t}\n\n\tif(ctx->resize_settings[IW_DIMENSION_H].family==IW_RESIZETYPE_AUTO) {\n\t\tiw_set_auto_resizetype(ctx,ctx->input_w,ctx->img2.width,IW_DIMENSION_H);\n\t}\n\tif(ctx->resize_settings[IW_DIMENSION_V].family==IW_RESIZETYPE_AUTO) {\n\t\tiw_set_auto_resizetype(ctx,ctx->input_h,ctx->img2.height,IW_DIMENSION_V);\n\t}\n\n\tif(IW_IMGTYPE_HAS_ALPHA(ctx->img2.imgtype)) {\n\t\tif(!ctx->opt_strip_alpha) {\n\t\t\t// If we're not allowed to strip the alpha channel, also disable\n\t\t\t// other optimizations that would implicitly remove the alpha\n\t\t\t// channel. (The optimization routines may do weird things if we\n\t\t\t// were to allow this.)\n\t\t\tctx->opt_palette = 0;\n\t\t\tctx->opt_binary_trns = 0;\n\t\t}\n\t}\n\n\treturn 1;\n}\n\nIW_IMPL(int) iw_process_image(struct iw_context *ctx)\n{\n\tint ret;\n\tint retval = 0;\n\n\tif(ctx->use_count>0) {\n\t\tiw_set_error(ctx,\"Internal: Incorrect attempt to reprocess image\");\n\t\tgoto done;\n\t}\n\tctx->use_count++;\n\n\tret = iw_prepare_processing(ctx,ctx->canvas_width,ctx->canvas_height);\n\tif(!ret) goto done;\n\n\tret = iw_process_internal(ctx);\n\tif(!ret) goto done;\n\n\tiwpvt_optimize_image(ctx);\n\n\tretval = 1;\ndone:\n\treturn retval;\n}\n"], "filenames": ["src/imagew-bmp.c", "src/imagew-main.c"], "buggy_code_start_loc": [849, 925], "buggy_code_end_loc": [854, 961], "fixing_code_start_loc": [850, 924], "fixing_code_end_loc": [857, 973], "type": "CWE-787", "message": "imagew-main.c:960:12 in libimageworsener.a in ImageWorsener 1.3.1 allows remote attackers to cause a denial of service (buffer underflow) via a crafted image, related to imagew-bmp.c.", "other": {"cve": {"id": "CVE-2017-9203", "sourceIdentifier": "cve@mitre.org", "published": "2017-05-23T04:29:04.447", "lastModified": "2019-10-03T00:03:26.223", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "imagew-main.c:960:12 in libimageworsener.a in ImageWorsener 1.3.1 allows remote attackers to cause a denial of service (buffer underflow) via a crafted image, related to imagew-bmp.c."}, {"lang": "es", "value": "Imagew-main.c:960:12 en libimageworsener.a en ImageWorsener 1.3.1 permite a atacantes remotos causar una denegaci\u00f3n de servicio (desbordamiento inferior de b\u00fafer) a trav\u00e9s de una imagen especialmente dise\u00f1ada, relacionada con imagew-bmp.c."}], "metrics": {"cvssMetricV30": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.0", "vectorString": "CVSS:3.0/AV:N/AC:L/PR:N/UI:R/S:U/C:N/I:N/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "REQUIRED", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 6.5, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 2.8, "impactScore": 3.6}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:N/AC:M/Au:N/C:N/I:N/A:P", "accessVector": "NETWORK", "accessComplexity": "MEDIUM", "authentication": "NONE", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "PARTIAL", "baseScore": 4.3}, "baseSeverity": "MEDIUM", "exploitabilityScore": 8.6, "impactScore": 2.9, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": true}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-787"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:entropymine:imageworsener:1.3.1:*:*:*:*:*:*:*", "matchCriteriaId": "60307047-29E3-470F-9482-7FA546DE3196"}]}]}], "references": [{"url": "https://blogs.gentoo.org/ago/2017/05/20/imageworsener-multiple-vulnerabilities/", "source": "cve@mitre.org", "tags": ["Patch", "Third Party Advisory", "VDB Entry"]}, {"url": "https://github.com/jsummers/imageworsener/commit/a4f247707f08e322f0b41e82c3e06e224240a654", "source": "cve@mitre.org", "tags": ["Issue Tracking", "Patch", "Third Party Advisory"]}]}, "github_commit_url": "https://github.com/jsummers/imageworsener/commit/a4f247707f08e322f0b41e82c3e06e224240a654"}}
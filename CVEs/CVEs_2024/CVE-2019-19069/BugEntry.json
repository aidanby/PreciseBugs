{"buggy_code": ["// SPDX-License-Identifier: GPL-2.0\n// Copyright (c) 2011-2018, The Linux Foundation. All rights reserved.\n// Copyright (c) 2018, Linaro Limited\n\n#include <linux/completion.h>\n#include <linux/device.h>\n#include <linux/dma-buf.h>\n#include <linux/dma-mapping.h>\n#include <linux/idr.h>\n#include <linux/list.h>\n#include <linux/miscdevice.h>\n#include <linux/module.h>\n#include <linux/of_address.h>\n#include <linux/of.h>\n#include <linux/sort.h>\n#include <linux/of_platform.h>\n#include <linux/rpmsg.h>\n#include <linux/scatterlist.h>\n#include <linux/slab.h>\n#include <uapi/misc/fastrpc.h>\n\n#define ADSP_DOMAIN_ID (0)\n#define MDSP_DOMAIN_ID (1)\n#define SDSP_DOMAIN_ID (2)\n#define CDSP_DOMAIN_ID (3)\n#define FASTRPC_DEV_MAX\t\t4 /* adsp, mdsp, slpi, cdsp*/\n#define FASTRPC_MAX_SESSIONS\t9 /*8 compute, 1 cpz*/\n#define FASTRPC_ALIGN\t\t128\n#define FASTRPC_MAX_FDLIST\t16\n#define FASTRPC_MAX_CRCLIST\t64\n#define FASTRPC_PHYS(p)\t((p) & 0xffffffff)\n#define FASTRPC_CTX_MAX (256)\n#define FASTRPC_INIT_HANDLE\t1\n#define FASTRPC_CTXID_MASK (0xFF0)\n#define INIT_FILELEN_MAX (64 * 1024 * 1024)\n#define FASTRPC_DEVICE_NAME\t\"fastrpc\"\n\n/* Retrives number of input buffers from the scalars parameter */\n#define REMOTE_SCALARS_INBUFS(sc)\t(((sc) >> 16) & 0x0ff)\n\n/* Retrives number of output buffers from the scalars parameter */\n#define REMOTE_SCALARS_OUTBUFS(sc)\t(((sc) >> 8) & 0x0ff)\n\n/* Retrives number of input handles from the scalars parameter */\n#define REMOTE_SCALARS_INHANDLES(sc)\t(((sc) >> 4) & 0x0f)\n\n/* Retrives number of output handles from the scalars parameter */\n#define REMOTE_SCALARS_OUTHANDLES(sc)\t((sc) & 0x0f)\n\n#define REMOTE_SCALARS_LENGTH(sc)\t(REMOTE_SCALARS_INBUFS(sc) +   \\\n\t\t\t\t\t REMOTE_SCALARS_OUTBUFS(sc) +  \\\n\t\t\t\t\t REMOTE_SCALARS_INHANDLES(sc)+ \\\n\t\t\t\t\t REMOTE_SCALARS_OUTHANDLES(sc))\n#define FASTRPC_BUILD_SCALARS(attr, method, in, out, oin, oout)  \\\n\t\t\t\t(((attr & 0x07) << 29) |\t\t\\\n\t\t\t\t((method & 0x1f) << 24) |\t\\\n\t\t\t\t((in & 0xff) << 16) |\t\t\\\n\t\t\t\t((out & 0xff) <<  8) |\t\t\\\n\t\t\t\t((oin & 0x0f) <<  4) |\t\t\\\n\t\t\t\t(oout & 0x0f))\n\n#define FASTRPC_SCALARS(method, in, out) \\\n\t\tFASTRPC_BUILD_SCALARS(0, method, in, out, 0, 0)\n\n#define FASTRPC_CREATE_PROCESS_NARGS\t6\n/* Remote Method id table */\n#define FASTRPC_RMID_INIT_ATTACH\t0\n#define FASTRPC_RMID_INIT_RELEASE\t1\n#define FASTRPC_RMID_INIT_CREATE\t6\n#define FASTRPC_RMID_INIT_CREATE_ATTR\t7\n#define FASTRPC_RMID_INIT_CREATE_STATIC\t8\n\n#define miscdev_to_cctx(d) container_of(d, struct fastrpc_channel_ctx, miscdev)\n\nstatic const char *domains[FASTRPC_DEV_MAX] = { \"adsp\", \"mdsp\",\n\t\t\t\t\t\t\"sdsp\", \"cdsp\"};\nstruct fastrpc_phy_page {\n\tu64 addr;\t\t/* physical address */\n\tu64 size;\t\t/* size of contiguous region */\n};\n\nstruct fastrpc_invoke_buf {\n\tu32 num;\t\t/* number of contiguous regions */\n\tu32 pgidx;\t\t/* index to start of contiguous region */\n};\n\nstruct fastrpc_remote_arg {\n\tu64 pv;\n\tu64 len;\n};\n\nstruct fastrpc_msg {\n\tint pid;\t\t/* process group id */\n\tint tid;\t\t/* thread id */\n\tu64 ctx;\t\t/* invoke caller context */\n\tu32 handle;\t/* handle to invoke */\n\tu32 sc;\t\t/* scalars structure describing the data */\n\tu64 addr;\t\t/* physical address */\n\tu64 size;\t\t/* size of contiguous region */\n};\n\nstruct fastrpc_invoke_rsp {\n\tu64 ctx;\t\t/* invoke caller context */\n\tint retval;\t\t/* invoke return value */\n};\n\nstruct fastrpc_buf_overlap {\n\tu64 start;\n\tu64 end;\n\tint raix;\n\tu64 mstart;\n\tu64 mend;\n\tu64 offset;\n};\n\nstruct fastrpc_buf {\n\tstruct fastrpc_user *fl;\n\tstruct dma_buf *dmabuf;\n\tstruct device *dev;\n\tvoid *virt;\n\tu64 phys;\n\tu64 size;\n\t/* Lock for dma buf attachments */\n\tstruct mutex lock;\n\tstruct list_head attachments;\n};\n\nstruct fastrpc_dma_buf_attachment {\n\tstruct device *dev;\n\tstruct sg_table sgt;\n\tstruct list_head node;\n};\n\nstruct fastrpc_map {\n\tstruct list_head node;\n\tstruct fastrpc_user *fl;\n\tint fd;\n\tstruct dma_buf *buf;\n\tstruct sg_table *table;\n\tstruct dma_buf_attachment *attach;\n\tu64 phys;\n\tu64 size;\n\tvoid *va;\n\tu64 len;\n\tstruct kref refcount;\n};\n\nstruct fastrpc_invoke_ctx {\n\tint nscalars;\n\tint nbufs;\n\tint retval;\n\tint pid;\n\tint tgid;\n\tu32 sc;\n\tu32 *crc;\n\tu64 ctxid;\n\tu64 msg_sz;\n\tstruct kref refcount;\n\tstruct list_head node; /* list of ctxs */\n\tstruct completion work;\n\tstruct work_struct put_work;\n\tstruct fastrpc_msg msg;\n\tstruct fastrpc_user *fl;\n\tstruct fastrpc_remote_arg *rpra;\n\tstruct fastrpc_map **maps;\n\tstruct fastrpc_buf *buf;\n\tstruct fastrpc_invoke_args *args;\n\tstruct fastrpc_buf_overlap *olaps;\n\tstruct fastrpc_channel_ctx *cctx;\n};\n\nstruct fastrpc_session_ctx {\n\tstruct device *dev;\n\tint sid;\n\tbool used;\n\tbool valid;\n};\n\nstruct fastrpc_channel_ctx {\n\tint domain_id;\n\tint sesscount;\n\tstruct rpmsg_device *rpdev;\n\tstruct fastrpc_session_ctx session[FASTRPC_MAX_SESSIONS];\n\tspinlock_t lock;\n\tstruct idr ctx_idr;\n\tstruct list_head users;\n\tstruct miscdevice miscdev;\n\tstruct kref refcount;\n};\n\nstruct fastrpc_user {\n\tstruct list_head user;\n\tstruct list_head maps;\n\tstruct list_head pending;\n\n\tstruct fastrpc_channel_ctx *cctx;\n\tstruct fastrpc_session_ctx *sctx;\n\tstruct fastrpc_buf *init_mem;\n\n\tint tgid;\n\tint pd;\n\t/* Lock for lists */\n\tspinlock_t lock;\n\t/* lock for allocations */\n\tstruct mutex mutex;\n};\n\nstatic void fastrpc_free_map(struct kref *ref)\n{\n\tstruct fastrpc_map *map;\n\n\tmap = container_of(ref, struct fastrpc_map, refcount);\n\n\tif (map->table) {\n\t\tdma_buf_unmap_attachment(map->attach, map->table,\n\t\t\t\t\t DMA_BIDIRECTIONAL);\n\t\tdma_buf_detach(map->buf, map->attach);\n\t\tdma_buf_put(map->buf);\n\t}\n\n\tkfree(map);\n}\n\nstatic void fastrpc_map_put(struct fastrpc_map *map)\n{\n\tif (map)\n\t\tkref_put(&map->refcount, fastrpc_free_map);\n}\n\nstatic void fastrpc_map_get(struct fastrpc_map *map)\n{\n\tif (map)\n\t\tkref_get(&map->refcount);\n}\n\nstatic int fastrpc_map_find(struct fastrpc_user *fl, int fd,\n\t\t\t    struct fastrpc_map **ppmap)\n{\n\tstruct fastrpc_map *map = NULL;\n\n\tmutex_lock(&fl->mutex);\n\tlist_for_each_entry(map, &fl->maps, node) {\n\t\tif (map->fd == fd) {\n\t\t\tfastrpc_map_get(map);\n\t\t\t*ppmap = map;\n\t\t\tmutex_unlock(&fl->mutex);\n\t\t\treturn 0;\n\t\t}\n\t}\n\tmutex_unlock(&fl->mutex);\n\n\treturn -ENOENT;\n}\n\nstatic void fastrpc_buf_free(struct fastrpc_buf *buf)\n{\n\tdma_free_coherent(buf->dev, buf->size, buf->virt,\n\t\t\t  FASTRPC_PHYS(buf->phys));\n\tkfree(buf);\n}\n\nstatic int fastrpc_buf_alloc(struct fastrpc_user *fl, struct device *dev,\n\t\t\t     u64 size, struct fastrpc_buf **obuf)\n{\n\tstruct fastrpc_buf *buf;\n\n\tbuf = kzalloc(sizeof(*buf), GFP_KERNEL);\n\tif (!buf)\n\t\treturn -ENOMEM;\n\n\tINIT_LIST_HEAD(&buf->attachments);\n\tmutex_init(&buf->lock);\n\n\tbuf->fl = fl;\n\tbuf->virt = NULL;\n\tbuf->phys = 0;\n\tbuf->size = size;\n\tbuf->dev = dev;\n\n\tbuf->virt = dma_alloc_coherent(dev, buf->size, (dma_addr_t *)&buf->phys,\n\t\t\t\t       GFP_KERNEL);\n\tif (!buf->virt) {\n\t\tmutex_destroy(&buf->lock);\n\t\tkfree(buf);\n\t\treturn -ENOMEM;\n\t}\n\n\tif (fl->sctx && fl->sctx->sid)\n\t\tbuf->phys += ((u64)fl->sctx->sid << 32);\n\n\t*obuf = buf;\n\n\treturn 0;\n}\n\nstatic void fastrpc_channel_ctx_free(struct kref *ref)\n{\n\tstruct fastrpc_channel_ctx *cctx;\n\n\tcctx = container_of(ref, struct fastrpc_channel_ctx, refcount);\n\n\tkfree(cctx);\n}\n\nstatic void fastrpc_channel_ctx_get(struct fastrpc_channel_ctx *cctx)\n{\n\tkref_get(&cctx->refcount);\n}\n\nstatic void fastrpc_channel_ctx_put(struct fastrpc_channel_ctx *cctx)\n{\n\tkref_put(&cctx->refcount, fastrpc_channel_ctx_free);\n}\n\nstatic void fastrpc_context_free(struct kref *ref)\n{\n\tstruct fastrpc_invoke_ctx *ctx;\n\tstruct fastrpc_channel_ctx *cctx;\n\tunsigned long flags;\n\tint i;\n\n\tctx = container_of(ref, struct fastrpc_invoke_ctx, refcount);\n\tcctx = ctx->cctx;\n\n\tfor (i = 0; i < ctx->nscalars; i++)\n\t\tfastrpc_map_put(ctx->maps[i]);\n\n\tif (ctx->buf)\n\t\tfastrpc_buf_free(ctx->buf);\n\n\tspin_lock_irqsave(&cctx->lock, flags);\n\tidr_remove(&cctx->ctx_idr, ctx->ctxid >> 4);\n\tspin_unlock_irqrestore(&cctx->lock, flags);\n\n\tkfree(ctx->maps);\n\tkfree(ctx->olaps);\n\tkfree(ctx);\n\n\tfastrpc_channel_ctx_put(cctx);\n}\n\nstatic void fastrpc_context_get(struct fastrpc_invoke_ctx *ctx)\n{\n\tkref_get(&ctx->refcount);\n}\n\nstatic void fastrpc_context_put(struct fastrpc_invoke_ctx *ctx)\n{\n\tkref_put(&ctx->refcount, fastrpc_context_free);\n}\n\nstatic void fastrpc_context_put_wq(struct work_struct *work)\n{\n\tstruct fastrpc_invoke_ctx *ctx =\n\t\t\tcontainer_of(work, struct fastrpc_invoke_ctx, put_work);\n\n\tfastrpc_context_put(ctx);\n}\n\n#define CMP(aa, bb) ((aa) == (bb) ? 0 : (aa) < (bb) ? -1 : 1)\nstatic int olaps_cmp(const void *a, const void *b)\n{\n\tstruct fastrpc_buf_overlap *pa = (struct fastrpc_buf_overlap *)a;\n\tstruct fastrpc_buf_overlap *pb = (struct fastrpc_buf_overlap *)b;\n\t/* sort with lowest starting buffer first */\n\tint st = CMP(pa->start, pb->start);\n\t/* sort with highest ending buffer first */\n\tint ed = CMP(pb->end, pa->end);\n\n\treturn st == 0 ? ed : st;\n}\n\nstatic void fastrpc_get_buff_overlaps(struct fastrpc_invoke_ctx *ctx)\n{\n\tu64 max_end = 0;\n\tint i;\n\n\tfor (i = 0; i < ctx->nbufs; ++i) {\n\t\tctx->olaps[i].start = ctx->args[i].ptr;\n\t\tctx->olaps[i].end = ctx->olaps[i].start + ctx->args[i].length;\n\t\tctx->olaps[i].raix = i;\n\t}\n\n\tsort(ctx->olaps, ctx->nbufs, sizeof(*ctx->olaps), olaps_cmp, NULL);\n\n\tfor (i = 0; i < ctx->nbufs; ++i) {\n\t\t/* Falling inside previous range */\n\t\tif (ctx->olaps[i].start < max_end) {\n\t\t\tctx->olaps[i].mstart = max_end;\n\t\t\tctx->olaps[i].mend = ctx->olaps[i].end;\n\t\t\tctx->olaps[i].offset = max_end - ctx->olaps[i].start;\n\n\t\t\tif (ctx->olaps[i].end > max_end) {\n\t\t\t\tmax_end = ctx->olaps[i].end;\n\t\t\t} else {\n\t\t\t\tctx->olaps[i].mend = 0;\n\t\t\t\tctx->olaps[i].mstart = 0;\n\t\t\t}\n\n\t\t} else  {\n\t\t\tctx->olaps[i].mend = ctx->olaps[i].end;\n\t\t\tctx->olaps[i].mstart = ctx->olaps[i].start;\n\t\t\tctx->olaps[i].offset = 0;\n\t\t\tmax_end = ctx->olaps[i].end;\n\t\t}\n\t}\n}\n\nstatic struct fastrpc_invoke_ctx *fastrpc_context_alloc(\n\t\t\tstruct fastrpc_user *user, u32 kernel, u32 sc,\n\t\t\tstruct fastrpc_invoke_args *args)\n{\n\tstruct fastrpc_channel_ctx *cctx = user->cctx;\n\tstruct fastrpc_invoke_ctx *ctx = NULL;\n\tunsigned long flags;\n\tint ret;\n\n\tctx = kzalloc(sizeof(*ctx), GFP_KERNEL);\n\tif (!ctx)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tINIT_LIST_HEAD(&ctx->node);\n\tctx->fl = user;\n\tctx->nscalars = REMOTE_SCALARS_LENGTH(sc);\n\tctx->nbufs = REMOTE_SCALARS_INBUFS(sc) +\n\t\t     REMOTE_SCALARS_OUTBUFS(sc);\n\n\tif (ctx->nscalars) {\n\t\tctx->maps = kcalloc(ctx->nscalars,\n\t\t\t\t    sizeof(*ctx->maps), GFP_KERNEL);\n\t\tif (!ctx->maps) {\n\t\t\tkfree(ctx);\n\t\t\treturn ERR_PTR(-ENOMEM);\n\t\t}\n\t\tctx->olaps = kcalloc(ctx->nscalars,\n\t\t\t\t    sizeof(*ctx->olaps), GFP_KERNEL);\n\t\tif (!ctx->olaps) {\n\t\t\tkfree(ctx->maps);\n\t\t\tkfree(ctx);\n\t\t\treturn ERR_PTR(-ENOMEM);\n\t\t}\n\t\tctx->args = args;\n\t\tfastrpc_get_buff_overlaps(ctx);\n\t}\n\n\t/* Released in fastrpc_context_put() */\n\tfastrpc_channel_ctx_get(cctx);\n\n\tctx->sc = sc;\n\tctx->retval = -1;\n\tctx->pid = current->pid;\n\tctx->tgid = user->tgid;\n\tctx->cctx = cctx;\n\tinit_completion(&ctx->work);\n\tINIT_WORK(&ctx->put_work, fastrpc_context_put_wq);\n\n\tspin_lock(&user->lock);\n\tlist_add_tail(&ctx->node, &user->pending);\n\tspin_unlock(&user->lock);\n\n\tspin_lock_irqsave(&cctx->lock, flags);\n\tret = idr_alloc_cyclic(&cctx->ctx_idr, ctx, 1,\n\t\t\t       FASTRPC_CTX_MAX, GFP_ATOMIC);\n\tif (ret < 0) {\n\t\tspin_unlock_irqrestore(&cctx->lock, flags);\n\t\tgoto err_idr;\n\t}\n\tctx->ctxid = ret << 4;\n\tspin_unlock_irqrestore(&cctx->lock, flags);\n\n\tkref_init(&ctx->refcount);\n\n\treturn ctx;\nerr_idr:\n\tspin_lock(&user->lock);\n\tlist_del(&ctx->node);\n\tspin_unlock(&user->lock);\n\tfastrpc_channel_ctx_put(cctx);\n\tkfree(ctx->maps);\n\tkfree(ctx->olaps);\n\tkfree(ctx);\n\n\treturn ERR_PTR(ret);\n}\n\nstatic struct sg_table *\nfastrpc_map_dma_buf(struct dma_buf_attachment *attachment,\n\t\t    enum dma_data_direction dir)\n{\n\tstruct fastrpc_dma_buf_attachment *a = attachment->priv;\n\tstruct sg_table *table;\n\n\ttable = &a->sgt;\n\n\tif (!dma_map_sg(attachment->dev, table->sgl, table->nents, dir))\n\t\treturn ERR_PTR(-ENOMEM);\n\n\treturn table;\n}\n\nstatic void fastrpc_unmap_dma_buf(struct dma_buf_attachment *attach,\n\t\t\t\t  struct sg_table *table,\n\t\t\t\t  enum dma_data_direction dir)\n{\n\tdma_unmap_sg(attach->dev, table->sgl, table->nents, dir);\n}\n\nstatic void fastrpc_release(struct dma_buf *dmabuf)\n{\n\tstruct fastrpc_buf *buffer = dmabuf->priv;\n\n\tfastrpc_buf_free(buffer);\n}\n\nstatic int fastrpc_dma_buf_attach(struct dma_buf *dmabuf,\n\t\t\t\t  struct dma_buf_attachment *attachment)\n{\n\tstruct fastrpc_dma_buf_attachment *a;\n\tstruct fastrpc_buf *buffer = dmabuf->priv;\n\tint ret;\n\n\ta = kzalloc(sizeof(*a), GFP_KERNEL);\n\tif (!a)\n\t\treturn -ENOMEM;\n\n\tret = dma_get_sgtable(buffer->dev, &a->sgt, buffer->virt,\n\t\t\t      FASTRPC_PHYS(buffer->phys), buffer->size);\n\tif (ret < 0) {\n\t\tdev_err(buffer->dev, \"failed to get scatterlist from DMA API\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\ta->dev = attachment->dev;\n\tINIT_LIST_HEAD(&a->node);\n\tattachment->priv = a;\n\n\tmutex_lock(&buffer->lock);\n\tlist_add(&a->node, &buffer->attachments);\n\tmutex_unlock(&buffer->lock);\n\n\treturn 0;\n}\n\nstatic void fastrpc_dma_buf_detatch(struct dma_buf *dmabuf,\n\t\t\t\t    struct dma_buf_attachment *attachment)\n{\n\tstruct fastrpc_dma_buf_attachment *a = attachment->priv;\n\tstruct fastrpc_buf *buffer = dmabuf->priv;\n\n\tmutex_lock(&buffer->lock);\n\tlist_del(&a->node);\n\tmutex_unlock(&buffer->lock);\n\tsg_free_table(&a->sgt);\n\tkfree(a);\n}\n\nstatic void *fastrpc_kmap(struct dma_buf *dmabuf, unsigned long pgnum)\n{\n\tstruct fastrpc_buf *buf = dmabuf->priv;\n\n\treturn buf->virt ? buf->virt + pgnum * PAGE_SIZE : NULL;\n}\n\nstatic void *fastrpc_vmap(struct dma_buf *dmabuf)\n{\n\tstruct fastrpc_buf *buf = dmabuf->priv;\n\n\treturn buf->virt;\n}\n\nstatic int fastrpc_mmap(struct dma_buf *dmabuf,\n\t\t\tstruct vm_area_struct *vma)\n{\n\tstruct fastrpc_buf *buf = dmabuf->priv;\n\tsize_t size = vma->vm_end - vma->vm_start;\n\n\treturn dma_mmap_coherent(buf->dev, vma, buf->virt,\n\t\t\t\t FASTRPC_PHYS(buf->phys), size);\n}\n\nstatic const struct dma_buf_ops fastrpc_dma_buf_ops = {\n\t.attach = fastrpc_dma_buf_attach,\n\t.detach = fastrpc_dma_buf_detatch,\n\t.map_dma_buf = fastrpc_map_dma_buf,\n\t.unmap_dma_buf = fastrpc_unmap_dma_buf,\n\t.mmap = fastrpc_mmap,\n\t.map = fastrpc_kmap,\n\t.vmap = fastrpc_vmap,\n\t.release = fastrpc_release,\n};\n\nstatic int fastrpc_map_create(struct fastrpc_user *fl, int fd,\n\t\t\t      u64 len, struct fastrpc_map **ppmap)\n{\n\tstruct fastrpc_session_ctx *sess = fl->sctx;\n\tstruct fastrpc_map *map = NULL;\n\tint err = 0;\n\n\tif (!fastrpc_map_find(fl, fd, ppmap))\n\t\treturn 0;\n\n\tmap = kzalloc(sizeof(*map), GFP_KERNEL);\n\tif (!map)\n\t\treturn -ENOMEM;\n\n\tINIT_LIST_HEAD(&map->node);\n\tmap->fl = fl;\n\tmap->fd = fd;\n\tmap->buf = dma_buf_get(fd);\n\tif (IS_ERR(map->buf)) {\n\t\terr = PTR_ERR(map->buf);\n\t\tgoto get_err;\n\t}\n\n\tmap->attach = dma_buf_attach(map->buf, sess->dev);\n\tif (IS_ERR(map->attach)) {\n\t\tdev_err(sess->dev, \"Failed to attach dmabuf\\n\");\n\t\terr = PTR_ERR(map->attach);\n\t\tgoto attach_err;\n\t}\n\n\tmap->table = dma_buf_map_attachment(map->attach, DMA_BIDIRECTIONAL);\n\tif (IS_ERR(map->table)) {\n\t\terr = PTR_ERR(map->table);\n\t\tgoto map_err;\n\t}\n\n\tmap->phys = sg_dma_address(map->table->sgl);\n\tmap->phys += ((u64)fl->sctx->sid << 32);\n\tmap->size = len;\n\tmap->va = sg_virt(map->table->sgl);\n\tmap->len = len;\n\tkref_init(&map->refcount);\n\n\tspin_lock(&fl->lock);\n\tlist_add_tail(&map->node, &fl->maps);\n\tspin_unlock(&fl->lock);\n\t*ppmap = map;\n\n\treturn 0;\n\nmap_err:\n\tdma_buf_detach(map->buf, map->attach);\nattach_err:\n\tdma_buf_put(map->buf);\nget_err:\n\tkfree(map);\n\n\treturn err;\n}\n\n/*\n * Fastrpc payload buffer with metadata looks like:\n *\n * >>>>>>  START of METADATA <<<<<<<<<\n * +---------------------------------+\n * |           Arguments             |\n * | type:(struct fastrpc_remote_arg)|\n * |             (0 - N)             |\n * +---------------------------------+\n * |         Invoke Buffer list      |\n * | type:(struct fastrpc_invoke_buf)|\n * |           (0 - N)               |\n * +---------------------------------+\n * |         Page info list          |\n * | type:(struct fastrpc_phy_page)  |\n * |             (0 - N)             |\n * +---------------------------------+\n * |         Optional info           |\n * |(can be specific to SoC/Firmware)|\n * +---------------------------------+\n * >>>>>>>>  END of METADATA <<<<<<<<<\n * +---------------------------------+\n * |         Inline ARGS             |\n * |            (0-N)                |\n * +---------------------------------+\n */\n\nstatic int fastrpc_get_meta_size(struct fastrpc_invoke_ctx *ctx)\n{\n\tint size = 0;\n\n\tsize = (sizeof(struct fastrpc_remote_arg) +\n\t\tsizeof(struct fastrpc_invoke_buf) +\n\t\tsizeof(struct fastrpc_phy_page)) * ctx->nscalars +\n\t\tsizeof(u64) * FASTRPC_MAX_FDLIST +\n\t\tsizeof(u32) * FASTRPC_MAX_CRCLIST;\n\n\treturn size;\n}\n\nstatic u64 fastrpc_get_payload_size(struct fastrpc_invoke_ctx *ctx, int metalen)\n{\n\tu64 size = 0;\n\tint i;\n\n\tsize = ALIGN(metalen, FASTRPC_ALIGN);\n\tfor (i = 0; i < ctx->nscalars; i++) {\n\t\tif (ctx->args[i].fd == 0 || ctx->args[i].fd == -1) {\n\n\t\t\tif (ctx->olaps[i].offset == 0)\n\t\t\t\tsize = ALIGN(size, FASTRPC_ALIGN);\n\n\t\t\tsize += (ctx->olaps[i].mend - ctx->olaps[i].mstart);\n\t\t}\n\t}\n\n\treturn size;\n}\n\nstatic int fastrpc_create_maps(struct fastrpc_invoke_ctx *ctx)\n{\n\tstruct device *dev = ctx->fl->sctx->dev;\n\tint i, err;\n\n\tfor (i = 0; i < ctx->nscalars; ++i) {\n\t\t/* Make sure reserved field is set to 0 */\n\t\tif (ctx->args[i].reserved)\n\t\t\treturn -EINVAL;\n\n\t\tif (ctx->args[i].fd == 0 || ctx->args[i].fd == -1 ||\n\t\t    ctx->args[i].length == 0)\n\t\t\tcontinue;\n\n\t\terr = fastrpc_map_create(ctx->fl, ctx->args[i].fd,\n\t\t\t\t\t ctx->args[i].length, &ctx->maps[i]);\n\t\tif (err) {\n\t\t\tdev_err(dev, \"Error Creating map %d\\n\", err);\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t}\n\treturn 0;\n}\n\nstatic int fastrpc_get_args(u32 kernel, struct fastrpc_invoke_ctx *ctx)\n{\n\tstruct device *dev = ctx->fl->sctx->dev;\n\tstruct fastrpc_remote_arg *rpra;\n\tstruct fastrpc_invoke_buf *list;\n\tstruct fastrpc_phy_page *pages;\n\tint inbufs, i, oix, err = 0;\n\tu64 len, rlen, pkt_size;\n\tu64 pg_start, pg_end;\n\tuintptr_t args;\n\tint metalen;\n\n\tinbufs = REMOTE_SCALARS_INBUFS(ctx->sc);\n\tmetalen = fastrpc_get_meta_size(ctx);\n\tpkt_size = fastrpc_get_payload_size(ctx, metalen);\n\n\terr = fastrpc_create_maps(ctx);\n\tif (err)\n\t\treturn err;\n\n\tctx->msg_sz = pkt_size;\n\n\terr = fastrpc_buf_alloc(ctx->fl, dev, pkt_size, &ctx->buf);\n\tif (err)\n\t\treturn err;\n\n\trpra = ctx->buf->virt;\n\tlist = ctx->buf->virt + ctx->nscalars * sizeof(*rpra);\n\tpages = ctx->buf->virt + ctx->nscalars * (sizeof(*list) +\n\t\tsizeof(*rpra));\n\targs = (uintptr_t)ctx->buf->virt + metalen;\n\trlen = pkt_size - metalen;\n\tctx->rpra = rpra;\n\n\tfor (oix = 0; oix < ctx->nbufs; ++oix) {\n\t\tint mlen;\n\n\t\ti = ctx->olaps[oix].raix;\n\t\tlen = ctx->args[i].length;\n\n\t\trpra[i].pv = 0;\n\t\trpra[i].len = len;\n\t\tlist[i].num = len ? 1 : 0;\n\t\tlist[i].pgidx = i;\n\n\t\tif (!len)\n\t\t\tcontinue;\n\n\t\tif (ctx->maps[i]) {\n\t\t\tstruct vm_area_struct *vma = NULL;\n\n\t\t\trpra[i].pv = (u64) ctx->args[i].ptr;\n\t\t\tpages[i].addr = ctx->maps[i]->phys;\n\n\t\t\tvma = find_vma(current->mm, ctx->args[i].ptr);\n\t\t\tif (vma)\n\t\t\t\tpages[i].addr += ctx->args[i].ptr -\n\t\t\t\t\t\t vma->vm_start;\n\n\t\t\tpg_start = (ctx->args[i].ptr & PAGE_MASK) >> PAGE_SHIFT;\n\t\t\tpg_end = ((ctx->args[i].ptr + len - 1) & PAGE_MASK) >>\n\t\t\t\t  PAGE_SHIFT;\n\t\t\tpages[i].size = (pg_end - pg_start + 1) * PAGE_SIZE;\n\n\t\t} else {\n\n\t\t\tif (ctx->olaps[oix].offset == 0) {\n\t\t\t\trlen -= ALIGN(args, FASTRPC_ALIGN) - args;\n\t\t\t\targs = ALIGN(args, FASTRPC_ALIGN);\n\t\t\t}\n\n\t\t\tmlen = ctx->olaps[oix].mend - ctx->olaps[oix].mstart;\n\n\t\t\tif (rlen < mlen)\n\t\t\t\tgoto bail;\n\n\t\t\trpra[i].pv = args - ctx->olaps[oix].offset;\n\t\t\tpages[i].addr = ctx->buf->phys -\n\t\t\t\t\tctx->olaps[oix].offset +\n\t\t\t\t\t(pkt_size - rlen);\n\t\t\tpages[i].addr = pages[i].addr &\tPAGE_MASK;\n\n\t\t\tpg_start = (args & PAGE_MASK) >> PAGE_SHIFT;\n\t\t\tpg_end = ((args + len - 1) & PAGE_MASK) >> PAGE_SHIFT;\n\t\t\tpages[i].size = (pg_end - pg_start + 1) * PAGE_SIZE;\n\t\t\targs = args + mlen;\n\t\t\trlen -= mlen;\n\t\t}\n\n\t\tif (i < inbufs && !ctx->maps[i]) {\n\t\t\tvoid *dst = (void *)(uintptr_t)rpra[i].pv;\n\t\t\tvoid *src = (void *)(uintptr_t)ctx->args[i].ptr;\n\n\t\t\tif (!kernel) {\n\t\t\t\tif (copy_from_user(dst, (void __user *)src,\n\t\t\t\t\t\t   len)) {\n\t\t\t\t\terr = -EFAULT;\n\t\t\t\t\tgoto bail;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tmemcpy(dst, src, len);\n\t\t\t}\n\t\t}\n\t}\n\n\tfor (i = ctx->nbufs; i < ctx->nscalars; ++i) {\n\t\trpra[i].pv = (u64) ctx->args[i].ptr;\n\t\trpra[i].len = ctx->args[i].length;\n\t\tlist[i].num = ctx->args[i].length ? 1 : 0;\n\t\tlist[i].pgidx = i;\n\t\tpages[i].addr = ctx->maps[i]->phys;\n\t\tpages[i].size = ctx->maps[i]->size;\n\t}\n\nbail:\n\tif (err)\n\t\tdev_err(dev, \"Error: get invoke args failed:%d\\n\", err);\n\n\treturn err;\n}\n\nstatic int fastrpc_put_args(struct fastrpc_invoke_ctx *ctx,\n\t\t\t    u32 kernel)\n{\n\tstruct fastrpc_remote_arg *rpra = ctx->rpra;\n\tint i, inbufs;\n\n\tinbufs = REMOTE_SCALARS_INBUFS(ctx->sc);\n\n\tfor (i = inbufs; i < ctx->nbufs; ++i) {\n\t\tvoid *src = (void *)(uintptr_t)rpra[i].pv;\n\t\tvoid *dst = (void *)(uintptr_t)ctx->args[i].ptr;\n\t\tu64 len = rpra[i].len;\n\n\t\tif (!kernel) {\n\t\t\tif (copy_to_user((void __user *)dst, src, len))\n\t\t\t\treturn -EFAULT;\n\t\t} else {\n\t\t\tmemcpy(dst, src, len);\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic int fastrpc_invoke_send(struct fastrpc_session_ctx *sctx,\n\t\t\t       struct fastrpc_invoke_ctx *ctx,\n\t\t\t       u32 kernel, uint32_t handle)\n{\n\tstruct fastrpc_channel_ctx *cctx;\n\tstruct fastrpc_user *fl = ctx->fl;\n\tstruct fastrpc_msg *msg = &ctx->msg;\n\n\tcctx = fl->cctx;\n\tmsg->pid = fl->tgid;\n\tmsg->tid = current->pid;\n\n\tif (kernel)\n\t\tmsg->pid = 0;\n\n\tmsg->ctx = ctx->ctxid | fl->pd;\n\tmsg->handle = handle;\n\tmsg->sc = ctx->sc;\n\tmsg->addr = ctx->buf ? ctx->buf->phys : 0;\n\tmsg->size = roundup(ctx->msg_sz, PAGE_SIZE);\n\tfastrpc_context_get(ctx);\n\n\treturn rpmsg_send(cctx->rpdev->ept, (void *)msg, sizeof(*msg));\n}\n\nstatic int fastrpc_internal_invoke(struct fastrpc_user *fl,  u32 kernel,\n\t\t\t\t   u32 handle, u32 sc,\n\t\t\t\t   struct fastrpc_invoke_args *args)\n{\n\tstruct fastrpc_invoke_ctx *ctx = NULL;\n\tint err = 0;\n\n\tif (!fl->sctx)\n\t\treturn -EINVAL;\n\n\tif (!fl->cctx->rpdev)\n\t\treturn -EPIPE;\n\n\tctx = fastrpc_context_alloc(fl, kernel, sc, args);\n\tif (IS_ERR(ctx))\n\t\treturn PTR_ERR(ctx);\n\n\tif (ctx->nscalars) {\n\t\terr = fastrpc_get_args(kernel, ctx);\n\t\tif (err)\n\t\t\tgoto bail;\n\t}\n\n\t/* make sure that all CPU memory writes are seen by DSP */\n\tdma_wmb();\n\t/* Send invoke buffer to remote dsp */\n\terr = fastrpc_invoke_send(fl->sctx, ctx, kernel, handle);\n\tif (err)\n\t\tgoto bail;\n\n\t/* Wait for remote dsp to respond or time out */\n\terr = wait_for_completion_interruptible(&ctx->work);\n\tif (err)\n\t\tgoto bail;\n\n\t/* Check the response from remote dsp */\n\terr = ctx->retval;\n\tif (err)\n\t\tgoto bail;\n\n\tif (ctx->nscalars) {\n\t\t/* make sure that all memory writes by DSP are seen by CPU */\n\t\tdma_rmb();\n\t\t/* populate all the output buffers with results */\n\t\terr = fastrpc_put_args(ctx, kernel);\n\t\tif (err)\n\t\t\tgoto bail;\n\t}\n\nbail:\n\t/* We are done with this compute context, remove it from pending list */\n\tspin_lock(&fl->lock);\n\tlist_del(&ctx->node);\n\tspin_unlock(&fl->lock);\n\tfastrpc_context_put(ctx);\n\n\tif (err)\n\t\tdev_dbg(fl->sctx->dev, \"Error: Invoke Failed %d\\n\", err);\n\n\treturn err;\n}\n\nstatic int fastrpc_init_create_process(struct fastrpc_user *fl,\n\t\t\t\t\tchar __user *argp)\n{\n\tstruct fastrpc_init_create init;\n\tstruct fastrpc_invoke_args *args;\n\tstruct fastrpc_phy_page pages[1];\n\tstruct fastrpc_map *map = NULL;\n\tstruct fastrpc_buf *imem = NULL;\n\tint memlen;\n\tint err;\n\tstruct {\n\t\tint pgid;\n\t\tu32 namelen;\n\t\tu32 filelen;\n\t\tu32 pageslen;\n\t\tu32 attrs;\n\t\tu32 siglen;\n\t} inbuf;\n\tu32 sc;\n\n\targs = kcalloc(FASTRPC_CREATE_PROCESS_NARGS, sizeof(*args), GFP_KERNEL);\n\tif (!args)\n\t\treturn -ENOMEM;\n\n\tif (copy_from_user(&init, argp, sizeof(init))) {\n\t\terr = -EFAULT;\n\t\tgoto err;\n\t}\n\n\tif (init.filelen > INIT_FILELEN_MAX) {\n\t\terr = -EINVAL;\n\t\tgoto err;\n\t}\n\n\tinbuf.pgid = fl->tgid;\n\tinbuf.namelen = strlen(current->comm) + 1;\n\tinbuf.filelen = init.filelen;\n\tinbuf.pageslen = 1;\n\tinbuf.attrs = init.attrs;\n\tinbuf.siglen = init.siglen;\n\tfl->pd = 1;\n\n\tif (init.filelen && init.filefd) {\n\t\terr = fastrpc_map_create(fl, init.filefd, init.filelen, &map);\n\t\tif (err)\n\t\t\tgoto err;\n\t}\n\n\tmemlen = ALIGN(max(INIT_FILELEN_MAX, (int)init.filelen * 4),\n\t\t       1024 * 1024);\n\terr = fastrpc_buf_alloc(fl, fl->sctx->dev, memlen,\n\t\t\t\t&imem);\n\tif (err)\n\t\tgoto err_alloc;\n\n\tfl->init_mem = imem;\n\targs[0].ptr = (u64)(uintptr_t)&inbuf;\n\targs[0].length = sizeof(inbuf);\n\targs[0].fd = -1;\n\n\targs[1].ptr = (u64)(uintptr_t)current->comm;\n\targs[1].length = inbuf.namelen;\n\targs[1].fd = -1;\n\n\targs[2].ptr = (u64) init.file;\n\targs[2].length = inbuf.filelen;\n\targs[2].fd = init.filefd;\n\n\tpages[0].addr = imem->phys;\n\tpages[0].size = imem->size;\n\n\targs[3].ptr = (u64)(uintptr_t) pages;\n\targs[3].length = 1 * sizeof(*pages);\n\targs[3].fd = -1;\n\n\targs[4].ptr = (u64)(uintptr_t)&inbuf.attrs;\n\targs[4].length = sizeof(inbuf.attrs);\n\targs[4].fd = -1;\n\n\targs[5].ptr = (u64)(uintptr_t) &inbuf.siglen;\n\targs[5].length = sizeof(inbuf.siglen);\n\targs[5].fd = -1;\n\n\tsc = FASTRPC_SCALARS(FASTRPC_RMID_INIT_CREATE, 4, 0);\n\tif (init.attrs)\n\t\tsc = FASTRPC_SCALARS(FASTRPC_RMID_INIT_CREATE_ATTR, 6, 0);\n\n\terr = fastrpc_internal_invoke(fl, true, FASTRPC_INIT_HANDLE,\n\t\t\t\t      sc, args);\n\tif (err)\n\t\tgoto err_invoke;\n\n\tkfree(args);\n\n\treturn 0;\n\nerr_invoke:\n\tfl->init_mem = NULL;\n\tfastrpc_buf_free(imem);\nerr_alloc:\n\tif (map) {\n\t\tspin_lock(&fl->lock);\n\t\tlist_del(&map->node);\n\t\tspin_unlock(&fl->lock);\n\t\tfastrpc_map_put(map);\n\t}\nerr:\n\tkfree(args);\n\n\treturn err;\n}\n\nstatic struct fastrpc_session_ctx *fastrpc_session_alloc(\n\t\t\t\t\tstruct fastrpc_channel_ctx *cctx)\n{\n\tstruct fastrpc_session_ctx *session = NULL;\n\tunsigned long flags;\n\tint i;\n\n\tspin_lock_irqsave(&cctx->lock, flags);\n\tfor (i = 0; i < cctx->sesscount; i++) {\n\t\tif (!cctx->session[i].used && cctx->session[i].valid) {\n\t\t\tcctx->session[i].used = true;\n\t\t\tsession = &cctx->session[i];\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock_irqrestore(&cctx->lock, flags);\n\n\treturn session;\n}\n\nstatic void fastrpc_session_free(struct fastrpc_channel_ctx *cctx,\n\t\t\t\t struct fastrpc_session_ctx *session)\n{\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&cctx->lock, flags);\n\tsession->used = false;\n\tspin_unlock_irqrestore(&cctx->lock, flags);\n}\n\nstatic int fastrpc_release_current_dsp_process(struct fastrpc_user *fl)\n{\n\tstruct fastrpc_invoke_args args[1];\n\tint tgid = 0;\n\tu32 sc;\n\n\ttgid = fl->tgid;\n\targs[0].ptr = (u64)(uintptr_t) &tgid;\n\targs[0].length = sizeof(tgid);\n\targs[0].fd = -1;\n\targs[0].reserved = 0;\n\tsc = FASTRPC_SCALARS(FASTRPC_RMID_INIT_RELEASE, 1, 0);\n\n\treturn fastrpc_internal_invoke(fl, true, FASTRPC_INIT_HANDLE,\n\t\t\t\t       sc, &args[0]);\n}\n\nstatic int fastrpc_device_release(struct inode *inode, struct file *file)\n{\n\tstruct fastrpc_user *fl = (struct fastrpc_user *)file->private_data;\n\tstruct fastrpc_channel_ctx *cctx = fl->cctx;\n\tstruct fastrpc_invoke_ctx *ctx, *n;\n\tstruct fastrpc_map *map, *m;\n\tunsigned long flags;\n\n\tfastrpc_release_current_dsp_process(fl);\n\n\tspin_lock_irqsave(&cctx->lock, flags);\n\tlist_del(&fl->user);\n\tspin_unlock_irqrestore(&cctx->lock, flags);\n\n\tif (fl->init_mem)\n\t\tfastrpc_buf_free(fl->init_mem);\n\n\tlist_for_each_entry_safe(ctx, n, &fl->pending, node) {\n\t\tlist_del(&ctx->node);\n\t\tfastrpc_context_put(ctx);\n\t}\n\n\tlist_for_each_entry_safe(map, m, &fl->maps, node) {\n\t\tlist_del(&map->node);\n\t\tfastrpc_map_put(map);\n\t}\n\n\tfastrpc_session_free(cctx, fl->sctx);\n\tfastrpc_channel_ctx_put(cctx);\n\n\tmutex_destroy(&fl->mutex);\n\tkfree(fl);\n\tfile->private_data = NULL;\n\n\treturn 0;\n}\n\nstatic int fastrpc_device_open(struct inode *inode, struct file *filp)\n{\n\tstruct fastrpc_channel_ctx *cctx = miscdev_to_cctx(filp->private_data);\n\tstruct fastrpc_user *fl = NULL;\n\tunsigned long flags;\n\n\tfl = kzalloc(sizeof(*fl), GFP_KERNEL);\n\tif (!fl)\n\t\treturn -ENOMEM;\n\n\t/* Released in fastrpc_device_release() */\n\tfastrpc_channel_ctx_get(cctx);\n\n\tfilp->private_data = fl;\n\tspin_lock_init(&fl->lock);\n\tmutex_init(&fl->mutex);\n\tINIT_LIST_HEAD(&fl->pending);\n\tINIT_LIST_HEAD(&fl->maps);\n\tINIT_LIST_HEAD(&fl->user);\n\tfl->tgid = current->tgid;\n\tfl->cctx = cctx;\n\n\tfl->sctx = fastrpc_session_alloc(cctx);\n\tif (!fl->sctx) {\n\t\tdev_err(&cctx->rpdev->dev, \"No session available\\n\");\n\t\tmutex_destroy(&fl->mutex);\n\t\tkfree(fl);\n\n\t\treturn -EBUSY;\n\t}\n\n\tspin_lock_irqsave(&cctx->lock, flags);\n\tlist_add_tail(&fl->user, &cctx->users);\n\tspin_unlock_irqrestore(&cctx->lock, flags);\n\n\treturn 0;\n}\n\nstatic int fastrpc_dmabuf_alloc(struct fastrpc_user *fl, char __user *argp)\n{\n\tstruct fastrpc_alloc_dma_buf bp;\n\tDEFINE_DMA_BUF_EXPORT_INFO(exp_info);\n\tstruct fastrpc_buf *buf = NULL;\n\tint err;\n\n\tif (copy_from_user(&bp, argp, sizeof(bp)))\n\t\treturn -EFAULT;\n\n\terr = fastrpc_buf_alloc(fl, fl->sctx->dev, bp.size, &buf);\n\tif (err)\n\t\treturn err;\n\texp_info.ops = &fastrpc_dma_buf_ops;\n\texp_info.size = bp.size;\n\texp_info.flags = O_RDWR;\n\texp_info.priv = buf;\n\tbuf->dmabuf = dma_buf_export(&exp_info);\n\tif (IS_ERR(buf->dmabuf)) {\n\t\terr = PTR_ERR(buf->dmabuf);\n\t\tfastrpc_buf_free(buf);\n\t\treturn err;\n\t}\n\n\tbp.fd = dma_buf_fd(buf->dmabuf, O_ACCMODE);\n\tif (bp.fd < 0) {\n\t\tdma_buf_put(buf->dmabuf);\n\t\treturn -EINVAL;\n\t}\n\n\tif (copy_to_user(argp, &bp, sizeof(bp))) {\n\t\tdma_buf_put(buf->dmabuf);\n\t\treturn -EFAULT;\n\t}\n\n\treturn 0;\n}\n\nstatic int fastrpc_init_attach(struct fastrpc_user *fl)\n{\n\tstruct fastrpc_invoke_args args[1];\n\tint tgid = fl->tgid;\n\tu32 sc;\n\n\targs[0].ptr = (u64)(uintptr_t) &tgid;\n\targs[0].length = sizeof(tgid);\n\targs[0].fd = -1;\n\targs[0].reserved = 0;\n\tsc = FASTRPC_SCALARS(FASTRPC_RMID_INIT_ATTACH, 1, 0);\n\tfl->pd = 0;\n\n\treturn fastrpc_internal_invoke(fl, true, FASTRPC_INIT_HANDLE,\n\t\t\t\t       sc, &args[0]);\n}\n\nstatic int fastrpc_invoke(struct fastrpc_user *fl, char __user *argp)\n{\n\tstruct fastrpc_invoke_args *args = NULL;\n\tstruct fastrpc_invoke inv;\n\tu32 nscalars;\n\tint err;\n\n\tif (copy_from_user(&inv, argp, sizeof(inv)))\n\t\treturn -EFAULT;\n\n\t/* nscalars is truncated here to max supported value */\n\tnscalars = REMOTE_SCALARS_LENGTH(inv.sc);\n\tif (nscalars) {\n\t\targs = kcalloc(nscalars, sizeof(*args), GFP_KERNEL);\n\t\tif (!args)\n\t\t\treturn -ENOMEM;\n\n\t\tif (copy_from_user(args, (void __user *)(uintptr_t)inv.args,\n\t\t\t\t   nscalars * sizeof(*args))) {\n\t\t\tkfree(args);\n\t\t\treturn -EFAULT;\n\t\t}\n\t}\n\n\terr = fastrpc_internal_invoke(fl, false, inv.handle, inv.sc, args);\n\tkfree(args);\n\n\treturn err;\n}\n\nstatic long fastrpc_device_ioctl(struct file *file, unsigned int cmd,\n\t\t\t\t unsigned long arg)\n{\n\tstruct fastrpc_user *fl = (struct fastrpc_user *)file->private_data;\n\tchar __user *argp = (char __user *)arg;\n\tint err;\n\n\tswitch (cmd) {\n\tcase FASTRPC_IOCTL_INVOKE:\n\t\terr = fastrpc_invoke(fl, argp);\n\t\tbreak;\n\tcase FASTRPC_IOCTL_INIT_ATTACH:\n\t\terr = fastrpc_init_attach(fl);\n\t\tbreak;\n\tcase FASTRPC_IOCTL_INIT_CREATE:\n\t\terr = fastrpc_init_create_process(fl, argp);\n\t\tbreak;\n\tcase FASTRPC_IOCTL_ALLOC_DMA_BUFF:\n\t\terr = fastrpc_dmabuf_alloc(fl, argp);\n\t\tbreak;\n\tdefault:\n\t\terr = -ENOTTY;\n\t\tbreak;\n\t}\n\n\treturn err;\n}\n\nstatic const struct file_operations fastrpc_fops = {\n\t.open = fastrpc_device_open,\n\t.release = fastrpc_device_release,\n\t.unlocked_ioctl = fastrpc_device_ioctl,\n\t.compat_ioctl = fastrpc_device_ioctl,\n};\n\nstatic int fastrpc_cb_probe(struct platform_device *pdev)\n{\n\tstruct fastrpc_channel_ctx *cctx;\n\tstruct fastrpc_session_ctx *sess;\n\tstruct device *dev = &pdev->dev;\n\tint i, sessions = 0;\n\tunsigned long flags;\n\tint rc;\n\n\tcctx = dev_get_drvdata(dev->parent);\n\tif (!cctx)\n\t\treturn -EINVAL;\n\n\tof_property_read_u32(dev->of_node, \"qcom,nsessions\", &sessions);\n\n\tspin_lock_irqsave(&cctx->lock, flags);\n\tsess = &cctx->session[cctx->sesscount];\n\tsess->used = false;\n\tsess->valid = true;\n\tsess->dev = dev;\n\tdev_set_drvdata(dev, sess);\n\n\tif (of_property_read_u32(dev->of_node, \"reg\", &sess->sid))\n\t\tdev_info(dev, \"FastRPC Session ID not specified in DT\\n\");\n\n\tif (sessions > 0) {\n\t\tstruct fastrpc_session_ctx *dup_sess;\n\n\t\tfor (i = 1; i < sessions; i++) {\n\t\t\tif (cctx->sesscount++ >= FASTRPC_MAX_SESSIONS)\n\t\t\t\tbreak;\n\t\t\tdup_sess = &cctx->session[cctx->sesscount];\n\t\t\tmemcpy(dup_sess, sess, sizeof(*dup_sess));\n\t\t}\n\t}\n\tcctx->sesscount++;\n\tspin_unlock_irqrestore(&cctx->lock, flags);\n\trc = dma_set_mask(dev, DMA_BIT_MASK(32));\n\tif (rc) {\n\t\tdev_err(dev, \"32-bit DMA enable failed\\n\");\n\t\treturn rc;\n\t}\n\n\treturn 0;\n}\n\nstatic int fastrpc_cb_remove(struct platform_device *pdev)\n{\n\tstruct fastrpc_channel_ctx *cctx = dev_get_drvdata(pdev->dev.parent);\n\tstruct fastrpc_session_ctx *sess = dev_get_drvdata(&pdev->dev);\n\tunsigned long flags;\n\tint i;\n\n\tspin_lock_irqsave(&cctx->lock, flags);\n\tfor (i = 1; i < FASTRPC_MAX_SESSIONS; i++) {\n\t\tif (cctx->session[i].sid == sess->sid) {\n\t\t\tcctx->session[i].valid = false;\n\t\t\tcctx->sesscount--;\n\t\t}\n\t}\n\tspin_unlock_irqrestore(&cctx->lock, flags);\n\n\treturn 0;\n}\n\nstatic const struct of_device_id fastrpc_match_table[] = {\n\t{ .compatible = \"qcom,fastrpc-compute-cb\", },\n\t{}\n};\n\nstatic struct platform_driver fastrpc_cb_driver = {\n\t.probe = fastrpc_cb_probe,\n\t.remove = fastrpc_cb_remove,\n\t.driver = {\n\t\t.name = \"qcom,fastrpc-cb\",\n\t\t.of_match_table = fastrpc_match_table,\n\t\t.suppress_bind_attrs = true,\n\t},\n};\n\nstatic int fastrpc_rpmsg_probe(struct rpmsg_device *rpdev)\n{\n\tstruct device *rdev = &rpdev->dev;\n\tstruct fastrpc_channel_ctx *data;\n\tint i, err, domain_id = -1;\n\tconst char *domain;\n\n\terr = of_property_read_string(rdev->of_node, \"label\", &domain);\n\tif (err) {\n\t\tdev_info(rdev, \"FastRPC Domain not specified in DT\\n\");\n\t\treturn err;\n\t}\n\n\tfor (i = 0; i <= CDSP_DOMAIN_ID; i++) {\n\t\tif (!strcmp(domains[i], domain)) {\n\t\t\tdomain_id = i;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (domain_id < 0) {\n\t\tdev_info(rdev, \"FastRPC Invalid Domain ID %d\\n\", domain_id);\n\t\treturn -EINVAL;\n\t}\n\n\tdata = kzalloc(sizeof(*data), GFP_KERNEL);\n\tif (!data)\n\t\treturn -ENOMEM;\n\n\tdata->miscdev.minor = MISC_DYNAMIC_MINOR;\n\tdata->miscdev.name = kasprintf(GFP_KERNEL, \"fastrpc-%s\",\n\t\t\t\tdomains[domain_id]);\n\tdata->miscdev.fops = &fastrpc_fops;\n\terr = misc_register(&data->miscdev);\n\tif (err)\n\t\treturn err;\n\n\tkref_init(&data->refcount);\n\n\tdev_set_drvdata(&rpdev->dev, data);\n\tdma_set_mask_and_coherent(rdev, DMA_BIT_MASK(32));\n\tINIT_LIST_HEAD(&data->users);\n\tspin_lock_init(&data->lock);\n\tidr_init(&data->ctx_idr);\n\tdata->domain_id = domain_id;\n\tdata->rpdev = rpdev;\n\n\treturn of_platform_populate(rdev->of_node, NULL, NULL, rdev);\n}\n\nstatic void fastrpc_notify_users(struct fastrpc_user *user)\n{\n\tstruct fastrpc_invoke_ctx *ctx;\n\n\tspin_lock(&user->lock);\n\tlist_for_each_entry(ctx, &user->pending, node)\n\t\tcomplete(&ctx->work);\n\tspin_unlock(&user->lock);\n}\n\nstatic void fastrpc_rpmsg_remove(struct rpmsg_device *rpdev)\n{\n\tstruct fastrpc_channel_ctx *cctx = dev_get_drvdata(&rpdev->dev);\n\tstruct fastrpc_user *user;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&cctx->lock, flags);\n\tlist_for_each_entry(user, &cctx->users, user)\n\t\tfastrpc_notify_users(user);\n\tspin_unlock_irqrestore(&cctx->lock, flags);\n\n\tmisc_deregister(&cctx->miscdev);\n\tof_platform_depopulate(&rpdev->dev);\n\n\tcctx->rpdev = NULL;\n\tfastrpc_channel_ctx_put(cctx);\n}\n\nstatic int fastrpc_rpmsg_callback(struct rpmsg_device *rpdev, void *data,\n\t\t\t\t  int len, void *priv, u32 addr)\n{\n\tstruct fastrpc_channel_ctx *cctx = dev_get_drvdata(&rpdev->dev);\n\tstruct fastrpc_invoke_rsp *rsp = data;\n\tstruct fastrpc_invoke_ctx *ctx;\n\tunsigned long flags;\n\tunsigned long ctxid;\n\n\tif (len < sizeof(*rsp))\n\t\treturn -EINVAL;\n\n\tctxid = ((rsp->ctx & FASTRPC_CTXID_MASK) >> 4);\n\n\tspin_lock_irqsave(&cctx->lock, flags);\n\tctx = idr_find(&cctx->ctx_idr, ctxid);\n\tspin_unlock_irqrestore(&cctx->lock, flags);\n\n\tif (!ctx) {\n\t\tdev_err(&rpdev->dev, \"No context ID matches response\\n\");\n\t\treturn -ENOENT;\n\t}\n\n\tctx->retval = rsp->retval;\n\tcomplete(&ctx->work);\n\n\t/*\n\t * The DMA buffer associated with the context cannot be freed in\n\t * interrupt context so schedule it through a worker thread to\n\t * avoid a kernel BUG.\n\t */\n\tschedule_work(&ctx->put_work);\n\n\treturn 0;\n}\n\nstatic const struct of_device_id fastrpc_rpmsg_of_match[] = {\n\t{ .compatible = \"qcom,fastrpc\" },\n\t{ },\n};\nMODULE_DEVICE_TABLE(of, fastrpc_rpmsg_of_match);\n\nstatic struct rpmsg_driver fastrpc_driver = {\n\t.probe = fastrpc_rpmsg_probe,\n\t.remove = fastrpc_rpmsg_remove,\n\t.callback = fastrpc_rpmsg_callback,\n\t.drv = {\n\t\t.name = \"qcom,fastrpc\",\n\t\t.of_match_table = fastrpc_rpmsg_of_match,\n\t},\n};\n\nstatic int fastrpc_init(void)\n{\n\tint ret;\n\n\tret = platform_driver_register(&fastrpc_cb_driver);\n\tif (ret < 0) {\n\t\tpr_err(\"fastrpc: failed to register cb driver\\n\");\n\t\treturn ret;\n\t}\n\n\tret = register_rpmsg_driver(&fastrpc_driver);\n\tif (ret < 0) {\n\t\tpr_err(\"fastrpc: failed to register rpmsg driver\\n\");\n\t\tplatform_driver_unregister(&fastrpc_cb_driver);\n\t\treturn ret;\n\t}\n\n\treturn 0;\n}\nmodule_init(fastrpc_init);\n\nstatic void fastrpc_exit(void)\n{\n\tplatform_driver_unregister(&fastrpc_cb_driver);\n\tunregister_rpmsg_driver(&fastrpc_driver);\n}\nmodule_exit(fastrpc_exit);\n\nMODULE_LICENSE(\"GPL v2\");\n"], "fixing_code": ["// SPDX-License-Identifier: GPL-2.0\n// Copyright (c) 2011-2018, The Linux Foundation. All rights reserved.\n// Copyright (c) 2018, Linaro Limited\n\n#include <linux/completion.h>\n#include <linux/device.h>\n#include <linux/dma-buf.h>\n#include <linux/dma-mapping.h>\n#include <linux/idr.h>\n#include <linux/list.h>\n#include <linux/miscdevice.h>\n#include <linux/module.h>\n#include <linux/of_address.h>\n#include <linux/of.h>\n#include <linux/sort.h>\n#include <linux/of_platform.h>\n#include <linux/rpmsg.h>\n#include <linux/scatterlist.h>\n#include <linux/slab.h>\n#include <uapi/misc/fastrpc.h>\n\n#define ADSP_DOMAIN_ID (0)\n#define MDSP_DOMAIN_ID (1)\n#define SDSP_DOMAIN_ID (2)\n#define CDSP_DOMAIN_ID (3)\n#define FASTRPC_DEV_MAX\t\t4 /* adsp, mdsp, slpi, cdsp*/\n#define FASTRPC_MAX_SESSIONS\t9 /*8 compute, 1 cpz*/\n#define FASTRPC_ALIGN\t\t128\n#define FASTRPC_MAX_FDLIST\t16\n#define FASTRPC_MAX_CRCLIST\t64\n#define FASTRPC_PHYS(p)\t((p) & 0xffffffff)\n#define FASTRPC_CTX_MAX (256)\n#define FASTRPC_INIT_HANDLE\t1\n#define FASTRPC_CTXID_MASK (0xFF0)\n#define INIT_FILELEN_MAX (64 * 1024 * 1024)\n#define FASTRPC_DEVICE_NAME\t\"fastrpc\"\n\n/* Retrives number of input buffers from the scalars parameter */\n#define REMOTE_SCALARS_INBUFS(sc)\t(((sc) >> 16) & 0x0ff)\n\n/* Retrives number of output buffers from the scalars parameter */\n#define REMOTE_SCALARS_OUTBUFS(sc)\t(((sc) >> 8) & 0x0ff)\n\n/* Retrives number of input handles from the scalars parameter */\n#define REMOTE_SCALARS_INHANDLES(sc)\t(((sc) >> 4) & 0x0f)\n\n/* Retrives number of output handles from the scalars parameter */\n#define REMOTE_SCALARS_OUTHANDLES(sc)\t((sc) & 0x0f)\n\n#define REMOTE_SCALARS_LENGTH(sc)\t(REMOTE_SCALARS_INBUFS(sc) +   \\\n\t\t\t\t\t REMOTE_SCALARS_OUTBUFS(sc) +  \\\n\t\t\t\t\t REMOTE_SCALARS_INHANDLES(sc)+ \\\n\t\t\t\t\t REMOTE_SCALARS_OUTHANDLES(sc))\n#define FASTRPC_BUILD_SCALARS(attr, method, in, out, oin, oout)  \\\n\t\t\t\t(((attr & 0x07) << 29) |\t\t\\\n\t\t\t\t((method & 0x1f) << 24) |\t\\\n\t\t\t\t((in & 0xff) << 16) |\t\t\\\n\t\t\t\t((out & 0xff) <<  8) |\t\t\\\n\t\t\t\t((oin & 0x0f) <<  4) |\t\t\\\n\t\t\t\t(oout & 0x0f))\n\n#define FASTRPC_SCALARS(method, in, out) \\\n\t\tFASTRPC_BUILD_SCALARS(0, method, in, out, 0, 0)\n\n#define FASTRPC_CREATE_PROCESS_NARGS\t6\n/* Remote Method id table */\n#define FASTRPC_RMID_INIT_ATTACH\t0\n#define FASTRPC_RMID_INIT_RELEASE\t1\n#define FASTRPC_RMID_INIT_CREATE\t6\n#define FASTRPC_RMID_INIT_CREATE_ATTR\t7\n#define FASTRPC_RMID_INIT_CREATE_STATIC\t8\n\n#define miscdev_to_cctx(d) container_of(d, struct fastrpc_channel_ctx, miscdev)\n\nstatic const char *domains[FASTRPC_DEV_MAX] = { \"adsp\", \"mdsp\",\n\t\t\t\t\t\t\"sdsp\", \"cdsp\"};\nstruct fastrpc_phy_page {\n\tu64 addr;\t\t/* physical address */\n\tu64 size;\t\t/* size of contiguous region */\n};\n\nstruct fastrpc_invoke_buf {\n\tu32 num;\t\t/* number of contiguous regions */\n\tu32 pgidx;\t\t/* index to start of contiguous region */\n};\n\nstruct fastrpc_remote_arg {\n\tu64 pv;\n\tu64 len;\n};\n\nstruct fastrpc_msg {\n\tint pid;\t\t/* process group id */\n\tint tid;\t\t/* thread id */\n\tu64 ctx;\t\t/* invoke caller context */\n\tu32 handle;\t/* handle to invoke */\n\tu32 sc;\t\t/* scalars structure describing the data */\n\tu64 addr;\t\t/* physical address */\n\tu64 size;\t\t/* size of contiguous region */\n};\n\nstruct fastrpc_invoke_rsp {\n\tu64 ctx;\t\t/* invoke caller context */\n\tint retval;\t\t/* invoke return value */\n};\n\nstruct fastrpc_buf_overlap {\n\tu64 start;\n\tu64 end;\n\tint raix;\n\tu64 mstart;\n\tu64 mend;\n\tu64 offset;\n};\n\nstruct fastrpc_buf {\n\tstruct fastrpc_user *fl;\n\tstruct dma_buf *dmabuf;\n\tstruct device *dev;\n\tvoid *virt;\n\tu64 phys;\n\tu64 size;\n\t/* Lock for dma buf attachments */\n\tstruct mutex lock;\n\tstruct list_head attachments;\n};\n\nstruct fastrpc_dma_buf_attachment {\n\tstruct device *dev;\n\tstruct sg_table sgt;\n\tstruct list_head node;\n};\n\nstruct fastrpc_map {\n\tstruct list_head node;\n\tstruct fastrpc_user *fl;\n\tint fd;\n\tstruct dma_buf *buf;\n\tstruct sg_table *table;\n\tstruct dma_buf_attachment *attach;\n\tu64 phys;\n\tu64 size;\n\tvoid *va;\n\tu64 len;\n\tstruct kref refcount;\n};\n\nstruct fastrpc_invoke_ctx {\n\tint nscalars;\n\tint nbufs;\n\tint retval;\n\tint pid;\n\tint tgid;\n\tu32 sc;\n\tu32 *crc;\n\tu64 ctxid;\n\tu64 msg_sz;\n\tstruct kref refcount;\n\tstruct list_head node; /* list of ctxs */\n\tstruct completion work;\n\tstruct work_struct put_work;\n\tstruct fastrpc_msg msg;\n\tstruct fastrpc_user *fl;\n\tstruct fastrpc_remote_arg *rpra;\n\tstruct fastrpc_map **maps;\n\tstruct fastrpc_buf *buf;\n\tstruct fastrpc_invoke_args *args;\n\tstruct fastrpc_buf_overlap *olaps;\n\tstruct fastrpc_channel_ctx *cctx;\n};\n\nstruct fastrpc_session_ctx {\n\tstruct device *dev;\n\tint sid;\n\tbool used;\n\tbool valid;\n};\n\nstruct fastrpc_channel_ctx {\n\tint domain_id;\n\tint sesscount;\n\tstruct rpmsg_device *rpdev;\n\tstruct fastrpc_session_ctx session[FASTRPC_MAX_SESSIONS];\n\tspinlock_t lock;\n\tstruct idr ctx_idr;\n\tstruct list_head users;\n\tstruct miscdevice miscdev;\n\tstruct kref refcount;\n};\n\nstruct fastrpc_user {\n\tstruct list_head user;\n\tstruct list_head maps;\n\tstruct list_head pending;\n\n\tstruct fastrpc_channel_ctx *cctx;\n\tstruct fastrpc_session_ctx *sctx;\n\tstruct fastrpc_buf *init_mem;\n\n\tint tgid;\n\tint pd;\n\t/* Lock for lists */\n\tspinlock_t lock;\n\t/* lock for allocations */\n\tstruct mutex mutex;\n};\n\nstatic void fastrpc_free_map(struct kref *ref)\n{\n\tstruct fastrpc_map *map;\n\n\tmap = container_of(ref, struct fastrpc_map, refcount);\n\n\tif (map->table) {\n\t\tdma_buf_unmap_attachment(map->attach, map->table,\n\t\t\t\t\t DMA_BIDIRECTIONAL);\n\t\tdma_buf_detach(map->buf, map->attach);\n\t\tdma_buf_put(map->buf);\n\t}\n\n\tkfree(map);\n}\n\nstatic void fastrpc_map_put(struct fastrpc_map *map)\n{\n\tif (map)\n\t\tkref_put(&map->refcount, fastrpc_free_map);\n}\n\nstatic void fastrpc_map_get(struct fastrpc_map *map)\n{\n\tif (map)\n\t\tkref_get(&map->refcount);\n}\n\nstatic int fastrpc_map_find(struct fastrpc_user *fl, int fd,\n\t\t\t    struct fastrpc_map **ppmap)\n{\n\tstruct fastrpc_map *map = NULL;\n\n\tmutex_lock(&fl->mutex);\n\tlist_for_each_entry(map, &fl->maps, node) {\n\t\tif (map->fd == fd) {\n\t\t\tfastrpc_map_get(map);\n\t\t\t*ppmap = map;\n\t\t\tmutex_unlock(&fl->mutex);\n\t\t\treturn 0;\n\t\t}\n\t}\n\tmutex_unlock(&fl->mutex);\n\n\treturn -ENOENT;\n}\n\nstatic void fastrpc_buf_free(struct fastrpc_buf *buf)\n{\n\tdma_free_coherent(buf->dev, buf->size, buf->virt,\n\t\t\t  FASTRPC_PHYS(buf->phys));\n\tkfree(buf);\n}\n\nstatic int fastrpc_buf_alloc(struct fastrpc_user *fl, struct device *dev,\n\t\t\t     u64 size, struct fastrpc_buf **obuf)\n{\n\tstruct fastrpc_buf *buf;\n\n\tbuf = kzalloc(sizeof(*buf), GFP_KERNEL);\n\tif (!buf)\n\t\treturn -ENOMEM;\n\n\tINIT_LIST_HEAD(&buf->attachments);\n\tmutex_init(&buf->lock);\n\n\tbuf->fl = fl;\n\tbuf->virt = NULL;\n\tbuf->phys = 0;\n\tbuf->size = size;\n\tbuf->dev = dev;\n\n\tbuf->virt = dma_alloc_coherent(dev, buf->size, (dma_addr_t *)&buf->phys,\n\t\t\t\t       GFP_KERNEL);\n\tif (!buf->virt) {\n\t\tmutex_destroy(&buf->lock);\n\t\tkfree(buf);\n\t\treturn -ENOMEM;\n\t}\n\n\tif (fl->sctx && fl->sctx->sid)\n\t\tbuf->phys += ((u64)fl->sctx->sid << 32);\n\n\t*obuf = buf;\n\n\treturn 0;\n}\n\nstatic void fastrpc_channel_ctx_free(struct kref *ref)\n{\n\tstruct fastrpc_channel_ctx *cctx;\n\n\tcctx = container_of(ref, struct fastrpc_channel_ctx, refcount);\n\n\tkfree(cctx);\n}\n\nstatic void fastrpc_channel_ctx_get(struct fastrpc_channel_ctx *cctx)\n{\n\tkref_get(&cctx->refcount);\n}\n\nstatic void fastrpc_channel_ctx_put(struct fastrpc_channel_ctx *cctx)\n{\n\tkref_put(&cctx->refcount, fastrpc_channel_ctx_free);\n}\n\nstatic void fastrpc_context_free(struct kref *ref)\n{\n\tstruct fastrpc_invoke_ctx *ctx;\n\tstruct fastrpc_channel_ctx *cctx;\n\tunsigned long flags;\n\tint i;\n\n\tctx = container_of(ref, struct fastrpc_invoke_ctx, refcount);\n\tcctx = ctx->cctx;\n\n\tfor (i = 0; i < ctx->nscalars; i++)\n\t\tfastrpc_map_put(ctx->maps[i]);\n\n\tif (ctx->buf)\n\t\tfastrpc_buf_free(ctx->buf);\n\n\tspin_lock_irqsave(&cctx->lock, flags);\n\tidr_remove(&cctx->ctx_idr, ctx->ctxid >> 4);\n\tspin_unlock_irqrestore(&cctx->lock, flags);\n\n\tkfree(ctx->maps);\n\tkfree(ctx->olaps);\n\tkfree(ctx);\n\n\tfastrpc_channel_ctx_put(cctx);\n}\n\nstatic void fastrpc_context_get(struct fastrpc_invoke_ctx *ctx)\n{\n\tkref_get(&ctx->refcount);\n}\n\nstatic void fastrpc_context_put(struct fastrpc_invoke_ctx *ctx)\n{\n\tkref_put(&ctx->refcount, fastrpc_context_free);\n}\n\nstatic void fastrpc_context_put_wq(struct work_struct *work)\n{\n\tstruct fastrpc_invoke_ctx *ctx =\n\t\t\tcontainer_of(work, struct fastrpc_invoke_ctx, put_work);\n\n\tfastrpc_context_put(ctx);\n}\n\n#define CMP(aa, bb) ((aa) == (bb) ? 0 : (aa) < (bb) ? -1 : 1)\nstatic int olaps_cmp(const void *a, const void *b)\n{\n\tstruct fastrpc_buf_overlap *pa = (struct fastrpc_buf_overlap *)a;\n\tstruct fastrpc_buf_overlap *pb = (struct fastrpc_buf_overlap *)b;\n\t/* sort with lowest starting buffer first */\n\tint st = CMP(pa->start, pb->start);\n\t/* sort with highest ending buffer first */\n\tint ed = CMP(pb->end, pa->end);\n\n\treturn st == 0 ? ed : st;\n}\n\nstatic void fastrpc_get_buff_overlaps(struct fastrpc_invoke_ctx *ctx)\n{\n\tu64 max_end = 0;\n\tint i;\n\n\tfor (i = 0; i < ctx->nbufs; ++i) {\n\t\tctx->olaps[i].start = ctx->args[i].ptr;\n\t\tctx->olaps[i].end = ctx->olaps[i].start + ctx->args[i].length;\n\t\tctx->olaps[i].raix = i;\n\t}\n\n\tsort(ctx->olaps, ctx->nbufs, sizeof(*ctx->olaps), olaps_cmp, NULL);\n\n\tfor (i = 0; i < ctx->nbufs; ++i) {\n\t\t/* Falling inside previous range */\n\t\tif (ctx->olaps[i].start < max_end) {\n\t\t\tctx->olaps[i].mstart = max_end;\n\t\t\tctx->olaps[i].mend = ctx->olaps[i].end;\n\t\t\tctx->olaps[i].offset = max_end - ctx->olaps[i].start;\n\n\t\t\tif (ctx->olaps[i].end > max_end) {\n\t\t\t\tmax_end = ctx->olaps[i].end;\n\t\t\t} else {\n\t\t\t\tctx->olaps[i].mend = 0;\n\t\t\t\tctx->olaps[i].mstart = 0;\n\t\t\t}\n\n\t\t} else  {\n\t\t\tctx->olaps[i].mend = ctx->olaps[i].end;\n\t\t\tctx->olaps[i].mstart = ctx->olaps[i].start;\n\t\t\tctx->olaps[i].offset = 0;\n\t\t\tmax_end = ctx->olaps[i].end;\n\t\t}\n\t}\n}\n\nstatic struct fastrpc_invoke_ctx *fastrpc_context_alloc(\n\t\t\tstruct fastrpc_user *user, u32 kernel, u32 sc,\n\t\t\tstruct fastrpc_invoke_args *args)\n{\n\tstruct fastrpc_channel_ctx *cctx = user->cctx;\n\tstruct fastrpc_invoke_ctx *ctx = NULL;\n\tunsigned long flags;\n\tint ret;\n\n\tctx = kzalloc(sizeof(*ctx), GFP_KERNEL);\n\tif (!ctx)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tINIT_LIST_HEAD(&ctx->node);\n\tctx->fl = user;\n\tctx->nscalars = REMOTE_SCALARS_LENGTH(sc);\n\tctx->nbufs = REMOTE_SCALARS_INBUFS(sc) +\n\t\t     REMOTE_SCALARS_OUTBUFS(sc);\n\n\tif (ctx->nscalars) {\n\t\tctx->maps = kcalloc(ctx->nscalars,\n\t\t\t\t    sizeof(*ctx->maps), GFP_KERNEL);\n\t\tif (!ctx->maps) {\n\t\t\tkfree(ctx);\n\t\t\treturn ERR_PTR(-ENOMEM);\n\t\t}\n\t\tctx->olaps = kcalloc(ctx->nscalars,\n\t\t\t\t    sizeof(*ctx->olaps), GFP_KERNEL);\n\t\tif (!ctx->olaps) {\n\t\t\tkfree(ctx->maps);\n\t\t\tkfree(ctx);\n\t\t\treturn ERR_PTR(-ENOMEM);\n\t\t}\n\t\tctx->args = args;\n\t\tfastrpc_get_buff_overlaps(ctx);\n\t}\n\n\t/* Released in fastrpc_context_put() */\n\tfastrpc_channel_ctx_get(cctx);\n\n\tctx->sc = sc;\n\tctx->retval = -1;\n\tctx->pid = current->pid;\n\tctx->tgid = user->tgid;\n\tctx->cctx = cctx;\n\tinit_completion(&ctx->work);\n\tINIT_WORK(&ctx->put_work, fastrpc_context_put_wq);\n\n\tspin_lock(&user->lock);\n\tlist_add_tail(&ctx->node, &user->pending);\n\tspin_unlock(&user->lock);\n\n\tspin_lock_irqsave(&cctx->lock, flags);\n\tret = idr_alloc_cyclic(&cctx->ctx_idr, ctx, 1,\n\t\t\t       FASTRPC_CTX_MAX, GFP_ATOMIC);\n\tif (ret < 0) {\n\t\tspin_unlock_irqrestore(&cctx->lock, flags);\n\t\tgoto err_idr;\n\t}\n\tctx->ctxid = ret << 4;\n\tspin_unlock_irqrestore(&cctx->lock, flags);\n\n\tkref_init(&ctx->refcount);\n\n\treturn ctx;\nerr_idr:\n\tspin_lock(&user->lock);\n\tlist_del(&ctx->node);\n\tspin_unlock(&user->lock);\n\tfastrpc_channel_ctx_put(cctx);\n\tkfree(ctx->maps);\n\tkfree(ctx->olaps);\n\tkfree(ctx);\n\n\treturn ERR_PTR(ret);\n}\n\nstatic struct sg_table *\nfastrpc_map_dma_buf(struct dma_buf_attachment *attachment,\n\t\t    enum dma_data_direction dir)\n{\n\tstruct fastrpc_dma_buf_attachment *a = attachment->priv;\n\tstruct sg_table *table;\n\n\ttable = &a->sgt;\n\n\tif (!dma_map_sg(attachment->dev, table->sgl, table->nents, dir))\n\t\treturn ERR_PTR(-ENOMEM);\n\n\treturn table;\n}\n\nstatic void fastrpc_unmap_dma_buf(struct dma_buf_attachment *attach,\n\t\t\t\t  struct sg_table *table,\n\t\t\t\t  enum dma_data_direction dir)\n{\n\tdma_unmap_sg(attach->dev, table->sgl, table->nents, dir);\n}\n\nstatic void fastrpc_release(struct dma_buf *dmabuf)\n{\n\tstruct fastrpc_buf *buffer = dmabuf->priv;\n\n\tfastrpc_buf_free(buffer);\n}\n\nstatic int fastrpc_dma_buf_attach(struct dma_buf *dmabuf,\n\t\t\t\t  struct dma_buf_attachment *attachment)\n{\n\tstruct fastrpc_dma_buf_attachment *a;\n\tstruct fastrpc_buf *buffer = dmabuf->priv;\n\tint ret;\n\n\ta = kzalloc(sizeof(*a), GFP_KERNEL);\n\tif (!a)\n\t\treturn -ENOMEM;\n\n\tret = dma_get_sgtable(buffer->dev, &a->sgt, buffer->virt,\n\t\t\t      FASTRPC_PHYS(buffer->phys), buffer->size);\n\tif (ret < 0) {\n\t\tdev_err(buffer->dev, \"failed to get scatterlist from DMA API\\n\");\n\t\tkfree(a);\n\t\treturn -EINVAL;\n\t}\n\n\ta->dev = attachment->dev;\n\tINIT_LIST_HEAD(&a->node);\n\tattachment->priv = a;\n\n\tmutex_lock(&buffer->lock);\n\tlist_add(&a->node, &buffer->attachments);\n\tmutex_unlock(&buffer->lock);\n\n\treturn 0;\n}\n\nstatic void fastrpc_dma_buf_detatch(struct dma_buf *dmabuf,\n\t\t\t\t    struct dma_buf_attachment *attachment)\n{\n\tstruct fastrpc_dma_buf_attachment *a = attachment->priv;\n\tstruct fastrpc_buf *buffer = dmabuf->priv;\n\n\tmutex_lock(&buffer->lock);\n\tlist_del(&a->node);\n\tmutex_unlock(&buffer->lock);\n\tsg_free_table(&a->sgt);\n\tkfree(a);\n}\n\nstatic void *fastrpc_kmap(struct dma_buf *dmabuf, unsigned long pgnum)\n{\n\tstruct fastrpc_buf *buf = dmabuf->priv;\n\n\treturn buf->virt ? buf->virt + pgnum * PAGE_SIZE : NULL;\n}\n\nstatic void *fastrpc_vmap(struct dma_buf *dmabuf)\n{\n\tstruct fastrpc_buf *buf = dmabuf->priv;\n\n\treturn buf->virt;\n}\n\nstatic int fastrpc_mmap(struct dma_buf *dmabuf,\n\t\t\tstruct vm_area_struct *vma)\n{\n\tstruct fastrpc_buf *buf = dmabuf->priv;\n\tsize_t size = vma->vm_end - vma->vm_start;\n\n\treturn dma_mmap_coherent(buf->dev, vma, buf->virt,\n\t\t\t\t FASTRPC_PHYS(buf->phys), size);\n}\n\nstatic const struct dma_buf_ops fastrpc_dma_buf_ops = {\n\t.attach = fastrpc_dma_buf_attach,\n\t.detach = fastrpc_dma_buf_detatch,\n\t.map_dma_buf = fastrpc_map_dma_buf,\n\t.unmap_dma_buf = fastrpc_unmap_dma_buf,\n\t.mmap = fastrpc_mmap,\n\t.map = fastrpc_kmap,\n\t.vmap = fastrpc_vmap,\n\t.release = fastrpc_release,\n};\n\nstatic int fastrpc_map_create(struct fastrpc_user *fl, int fd,\n\t\t\t      u64 len, struct fastrpc_map **ppmap)\n{\n\tstruct fastrpc_session_ctx *sess = fl->sctx;\n\tstruct fastrpc_map *map = NULL;\n\tint err = 0;\n\n\tif (!fastrpc_map_find(fl, fd, ppmap))\n\t\treturn 0;\n\n\tmap = kzalloc(sizeof(*map), GFP_KERNEL);\n\tif (!map)\n\t\treturn -ENOMEM;\n\n\tINIT_LIST_HEAD(&map->node);\n\tmap->fl = fl;\n\tmap->fd = fd;\n\tmap->buf = dma_buf_get(fd);\n\tif (IS_ERR(map->buf)) {\n\t\terr = PTR_ERR(map->buf);\n\t\tgoto get_err;\n\t}\n\n\tmap->attach = dma_buf_attach(map->buf, sess->dev);\n\tif (IS_ERR(map->attach)) {\n\t\tdev_err(sess->dev, \"Failed to attach dmabuf\\n\");\n\t\terr = PTR_ERR(map->attach);\n\t\tgoto attach_err;\n\t}\n\n\tmap->table = dma_buf_map_attachment(map->attach, DMA_BIDIRECTIONAL);\n\tif (IS_ERR(map->table)) {\n\t\terr = PTR_ERR(map->table);\n\t\tgoto map_err;\n\t}\n\n\tmap->phys = sg_dma_address(map->table->sgl);\n\tmap->phys += ((u64)fl->sctx->sid << 32);\n\tmap->size = len;\n\tmap->va = sg_virt(map->table->sgl);\n\tmap->len = len;\n\tkref_init(&map->refcount);\n\n\tspin_lock(&fl->lock);\n\tlist_add_tail(&map->node, &fl->maps);\n\tspin_unlock(&fl->lock);\n\t*ppmap = map;\n\n\treturn 0;\n\nmap_err:\n\tdma_buf_detach(map->buf, map->attach);\nattach_err:\n\tdma_buf_put(map->buf);\nget_err:\n\tkfree(map);\n\n\treturn err;\n}\n\n/*\n * Fastrpc payload buffer with metadata looks like:\n *\n * >>>>>>  START of METADATA <<<<<<<<<\n * +---------------------------------+\n * |           Arguments             |\n * | type:(struct fastrpc_remote_arg)|\n * |             (0 - N)             |\n * +---------------------------------+\n * |         Invoke Buffer list      |\n * | type:(struct fastrpc_invoke_buf)|\n * |           (0 - N)               |\n * +---------------------------------+\n * |         Page info list          |\n * | type:(struct fastrpc_phy_page)  |\n * |             (0 - N)             |\n * +---------------------------------+\n * |         Optional info           |\n * |(can be specific to SoC/Firmware)|\n * +---------------------------------+\n * >>>>>>>>  END of METADATA <<<<<<<<<\n * +---------------------------------+\n * |         Inline ARGS             |\n * |            (0-N)                |\n * +---------------------------------+\n */\n\nstatic int fastrpc_get_meta_size(struct fastrpc_invoke_ctx *ctx)\n{\n\tint size = 0;\n\n\tsize = (sizeof(struct fastrpc_remote_arg) +\n\t\tsizeof(struct fastrpc_invoke_buf) +\n\t\tsizeof(struct fastrpc_phy_page)) * ctx->nscalars +\n\t\tsizeof(u64) * FASTRPC_MAX_FDLIST +\n\t\tsizeof(u32) * FASTRPC_MAX_CRCLIST;\n\n\treturn size;\n}\n\nstatic u64 fastrpc_get_payload_size(struct fastrpc_invoke_ctx *ctx, int metalen)\n{\n\tu64 size = 0;\n\tint i;\n\n\tsize = ALIGN(metalen, FASTRPC_ALIGN);\n\tfor (i = 0; i < ctx->nscalars; i++) {\n\t\tif (ctx->args[i].fd == 0 || ctx->args[i].fd == -1) {\n\n\t\t\tif (ctx->olaps[i].offset == 0)\n\t\t\t\tsize = ALIGN(size, FASTRPC_ALIGN);\n\n\t\t\tsize += (ctx->olaps[i].mend - ctx->olaps[i].mstart);\n\t\t}\n\t}\n\n\treturn size;\n}\n\nstatic int fastrpc_create_maps(struct fastrpc_invoke_ctx *ctx)\n{\n\tstruct device *dev = ctx->fl->sctx->dev;\n\tint i, err;\n\n\tfor (i = 0; i < ctx->nscalars; ++i) {\n\t\t/* Make sure reserved field is set to 0 */\n\t\tif (ctx->args[i].reserved)\n\t\t\treturn -EINVAL;\n\n\t\tif (ctx->args[i].fd == 0 || ctx->args[i].fd == -1 ||\n\t\t    ctx->args[i].length == 0)\n\t\t\tcontinue;\n\n\t\terr = fastrpc_map_create(ctx->fl, ctx->args[i].fd,\n\t\t\t\t\t ctx->args[i].length, &ctx->maps[i]);\n\t\tif (err) {\n\t\t\tdev_err(dev, \"Error Creating map %d\\n\", err);\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t}\n\treturn 0;\n}\n\nstatic int fastrpc_get_args(u32 kernel, struct fastrpc_invoke_ctx *ctx)\n{\n\tstruct device *dev = ctx->fl->sctx->dev;\n\tstruct fastrpc_remote_arg *rpra;\n\tstruct fastrpc_invoke_buf *list;\n\tstruct fastrpc_phy_page *pages;\n\tint inbufs, i, oix, err = 0;\n\tu64 len, rlen, pkt_size;\n\tu64 pg_start, pg_end;\n\tuintptr_t args;\n\tint metalen;\n\n\tinbufs = REMOTE_SCALARS_INBUFS(ctx->sc);\n\tmetalen = fastrpc_get_meta_size(ctx);\n\tpkt_size = fastrpc_get_payload_size(ctx, metalen);\n\n\terr = fastrpc_create_maps(ctx);\n\tif (err)\n\t\treturn err;\n\n\tctx->msg_sz = pkt_size;\n\n\terr = fastrpc_buf_alloc(ctx->fl, dev, pkt_size, &ctx->buf);\n\tif (err)\n\t\treturn err;\n\n\trpra = ctx->buf->virt;\n\tlist = ctx->buf->virt + ctx->nscalars * sizeof(*rpra);\n\tpages = ctx->buf->virt + ctx->nscalars * (sizeof(*list) +\n\t\tsizeof(*rpra));\n\targs = (uintptr_t)ctx->buf->virt + metalen;\n\trlen = pkt_size - metalen;\n\tctx->rpra = rpra;\n\n\tfor (oix = 0; oix < ctx->nbufs; ++oix) {\n\t\tint mlen;\n\n\t\ti = ctx->olaps[oix].raix;\n\t\tlen = ctx->args[i].length;\n\n\t\trpra[i].pv = 0;\n\t\trpra[i].len = len;\n\t\tlist[i].num = len ? 1 : 0;\n\t\tlist[i].pgidx = i;\n\n\t\tif (!len)\n\t\t\tcontinue;\n\n\t\tif (ctx->maps[i]) {\n\t\t\tstruct vm_area_struct *vma = NULL;\n\n\t\t\trpra[i].pv = (u64) ctx->args[i].ptr;\n\t\t\tpages[i].addr = ctx->maps[i]->phys;\n\n\t\t\tvma = find_vma(current->mm, ctx->args[i].ptr);\n\t\t\tif (vma)\n\t\t\t\tpages[i].addr += ctx->args[i].ptr -\n\t\t\t\t\t\t vma->vm_start;\n\n\t\t\tpg_start = (ctx->args[i].ptr & PAGE_MASK) >> PAGE_SHIFT;\n\t\t\tpg_end = ((ctx->args[i].ptr + len - 1) & PAGE_MASK) >>\n\t\t\t\t  PAGE_SHIFT;\n\t\t\tpages[i].size = (pg_end - pg_start + 1) * PAGE_SIZE;\n\n\t\t} else {\n\n\t\t\tif (ctx->olaps[oix].offset == 0) {\n\t\t\t\trlen -= ALIGN(args, FASTRPC_ALIGN) - args;\n\t\t\t\targs = ALIGN(args, FASTRPC_ALIGN);\n\t\t\t}\n\n\t\t\tmlen = ctx->olaps[oix].mend - ctx->olaps[oix].mstart;\n\n\t\t\tif (rlen < mlen)\n\t\t\t\tgoto bail;\n\n\t\t\trpra[i].pv = args - ctx->olaps[oix].offset;\n\t\t\tpages[i].addr = ctx->buf->phys -\n\t\t\t\t\tctx->olaps[oix].offset +\n\t\t\t\t\t(pkt_size - rlen);\n\t\t\tpages[i].addr = pages[i].addr &\tPAGE_MASK;\n\n\t\t\tpg_start = (args & PAGE_MASK) >> PAGE_SHIFT;\n\t\t\tpg_end = ((args + len - 1) & PAGE_MASK) >> PAGE_SHIFT;\n\t\t\tpages[i].size = (pg_end - pg_start + 1) * PAGE_SIZE;\n\t\t\targs = args + mlen;\n\t\t\trlen -= mlen;\n\t\t}\n\n\t\tif (i < inbufs && !ctx->maps[i]) {\n\t\t\tvoid *dst = (void *)(uintptr_t)rpra[i].pv;\n\t\t\tvoid *src = (void *)(uintptr_t)ctx->args[i].ptr;\n\n\t\t\tif (!kernel) {\n\t\t\t\tif (copy_from_user(dst, (void __user *)src,\n\t\t\t\t\t\t   len)) {\n\t\t\t\t\terr = -EFAULT;\n\t\t\t\t\tgoto bail;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tmemcpy(dst, src, len);\n\t\t\t}\n\t\t}\n\t}\n\n\tfor (i = ctx->nbufs; i < ctx->nscalars; ++i) {\n\t\trpra[i].pv = (u64) ctx->args[i].ptr;\n\t\trpra[i].len = ctx->args[i].length;\n\t\tlist[i].num = ctx->args[i].length ? 1 : 0;\n\t\tlist[i].pgidx = i;\n\t\tpages[i].addr = ctx->maps[i]->phys;\n\t\tpages[i].size = ctx->maps[i]->size;\n\t}\n\nbail:\n\tif (err)\n\t\tdev_err(dev, \"Error: get invoke args failed:%d\\n\", err);\n\n\treturn err;\n}\n\nstatic int fastrpc_put_args(struct fastrpc_invoke_ctx *ctx,\n\t\t\t    u32 kernel)\n{\n\tstruct fastrpc_remote_arg *rpra = ctx->rpra;\n\tint i, inbufs;\n\n\tinbufs = REMOTE_SCALARS_INBUFS(ctx->sc);\n\n\tfor (i = inbufs; i < ctx->nbufs; ++i) {\n\t\tvoid *src = (void *)(uintptr_t)rpra[i].pv;\n\t\tvoid *dst = (void *)(uintptr_t)ctx->args[i].ptr;\n\t\tu64 len = rpra[i].len;\n\n\t\tif (!kernel) {\n\t\t\tif (copy_to_user((void __user *)dst, src, len))\n\t\t\t\treturn -EFAULT;\n\t\t} else {\n\t\t\tmemcpy(dst, src, len);\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nstatic int fastrpc_invoke_send(struct fastrpc_session_ctx *sctx,\n\t\t\t       struct fastrpc_invoke_ctx *ctx,\n\t\t\t       u32 kernel, uint32_t handle)\n{\n\tstruct fastrpc_channel_ctx *cctx;\n\tstruct fastrpc_user *fl = ctx->fl;\n\tstruct fastrpc_msg *msg = &ctx->msg;\n\n\tcctx = fl->cctx;\n\tmsg->pid = fl->tgid;\n\tmsg->tid = current->pid;\n\n\tif (kernel)\n\t\tmsg->pid = 0;\n\n\tmsg->ctx = ctx->ctxid | fl->pd;\n\tmsg->handle = handle;\n\tmsg->sc = ctx->sc;\n\tmsg->addr = ctx->buf ? ctx->buf->phys : 0;\n\tmsg->size = roundup(ctx->msg_sz, PAGE_SIZE);\n\tfastrpc_context_get(ctx);\n\n\treturn rpmsg_send(cctx->rpdev->ept, (void *)msg, sizeof(*msg));\n}\n\nstatic int fastrpc_internal_invoke(struct fastrpc_user *fl,  u32 kernel,\n\t\t\t\t   u32 handle, u32 sc,\n\t\t\t\t   struct fastrpc_invoke_args *args)\n{\n\tstruct fastrpc_invoke_ctx *ctx = NULL;\n\tint err = 0;\n\n\tif (!fl->sctx)\n\t\treturn -EINVAL;\n\n\tif (!fl->cctx->rpdev)\n\t\treturn -EPIPE;\n\n\tctx = fastrpc_context_alloc(fl, kernel, sc, args);\n\tif (IS_ERR(ctx))\n\t\treturn PTR_ERR(ctx);\n\n\tif (ctx->nscalars) {\n\t\terr = fastrpc_get_args(kernel, ctx);\n\t\tif (err)\n\t\t\tgoto bail;\n\t}\n\n\t/* make sure that all CPU memory writes are seen by DSP */\n\tdma_wmb();\n\t/* Send invoke buffer to remote dsp */\n\terr = fastrpc_invoke_send(fl->sctx, ctx, kernel, handle);\n\tif (err)\n\t\tgoto bail;\n\n\t/* Wait for remote dsp to respond or time out */\n\terr = wait_for_completion_interruptible(&ctx->work);\n\tif (err)\n\t\tgoto bail;\n\n\t/* Check the response from remote dsp */\n\terr = ctx->retval;\n\tif (err)\n\t\tgoto bail;\n\n\tif (ctx->nscalars) {\n\t\t/* make sure that all memory writes by DSP are seen by CPU */\n\t\tdma_rmb();\n\t\t/* populate all the output buffers with results */\n\t\terr = fastrpc_put_args(ctx, kernel);\n\t\tif (err)\n\t\t\tgoto bail;\n\t}\n\nbail:\n\t/* We are done with this compute context, remove it from pending list */\n\tspin_lock(&fl->lock);\n\tlist_del(&ctx->node);\n\tspin_unlock(&fl->lock);\n\tfastrpc_context_put(ctx);\n\n\tif (err)\n\t\tdev_dbg(fl->sctx->dev, \"Error: Invoke Failed %d\\n\", err);\n\n\treturn err;\n}\n\nstatic int fastrpc_init_create_process(struct fastrpc_user *fl,\n\t\t\t\t\tchar __user *argp)\n{\n\tstruct fastrpc_init_create init;\n\tstruct fastrpc_invoke_args *args;\n\tstruct fastrpc_phy_page pages[1];\n\tstruct fastrpc_map *map = NULL;\n\tstruct fastrpc_buf *imem = NULL;\n\tint memlen;\n\tint err;\n\tstruct {\n\t\tint pgid;\n\t\tu32 namelen;\n\t\tu32 filelen;\n\t\tu32 pageslen;\n\t\tu32 attrs;\n\t\tu32 siglen;\n\t} inbuf;\n\tu32 sc;\n\n\targs = kcalloc(FASTRPC_CREATE_PROCESS_NARGS, sizeof(*args), GFP_KERNEL);\n\tif (!args)\n\t\treturn -ENOMEM;\n\n\tif (copy_from_user(&init, argp, sizeof(init))) {\n\t\terr = -EFAULT;\n\t\tgoto err;\n\t}\n\n\tif (init.filelen > INIT_FILELEN_MAX) {\n\t\terr = -EINVAL;\n\t\tgoto err;\n\t}\n\n\tinbuf.pgid = fl->tgid;\n\tinbuf.namelen = strlen(current->comm) + 1;\n\tinbuf.filelen = init.filelen;\n\tinbuf.pageslen = 1;\n\tinbuf.attrs = init.attrs;\n\tinbuf.siglen = init.siglen;\n\tfl->pd = 1;\n\n\tif (init.filelen && init.filefd) {\n\t\terr = fastrpc_map_create(fl, init.filefd, init.filelen, &map);\n\t\tif (err)\n\t\t\tgoto err;\n\t}\n\n\tmemlen = ALIGN(max(INIT_FILELEN_MAX, (int)init.filelen * 4),\n\t\t       1024 * 1024);\n\terr = fastrpc_buf_alloc(fl, fl->sctx->dev, memlen,\n\t\t\t\t&imem);\n\tif (err)\n\t\tgoto err_alloc;\n\n\tfl->init_mem = imem;\n\targs[0].ptr = (u64)(uintptr_t)&inbuf;\n\targs[0].length = sizeof(inbuf);\n\targs[0].fd = -1;\n\n\targs[1].ptr = (u64)(uintptr_t)current->comm;\n\targs[1].length = inbuf.namelen;\n\targs[1].fd = -1;\n\n\targs[2].ptr = (u64) init.file;\n\targs[2].length = inbuf.filelen;\n\targs[2].fd = init.filefd;\n\n\tpages[0].addr = imem->phys;\n\tpages[0].size = imem->size;\n\n\targs[3].ptr = (u64)(uintptr_t) pages;\n\targs[3].length = 1 * sizeof(*pages);\n\targs[3].fd = -1;\n\n\targs[4].ptr = (u64)(uintptr_t)&inbuf.attrs;\n\targs[4].length = sizeof(inbuf.attrs);\n\targs[4].fd = -1;\n\n\targs[5].ptr = (u64)(uintptr_t) &inbuf.siglen;\n\targs[5].length = sizeof(inbuf.siglen);\n\targs[5].fd = -1;\n\n\tsc = FASTRPC_SCALARS(FASTRPC_RMID_INIT_CREATE, 4, 0);\n\tif (init.attrs)\n\t\tsc = FASTRPC_SCALARS(FASTRPC_RMID_INIT_CREATE_ATTR, 6, 0);\n\n\terr = fastrpc_internal_invoke(fl, true, FASTRPC_INIT_HANDLE,\n\t\t\t\t      sc, args);\n\tif (err)\n\t\tgoto err_invoke;\n\n\tkfree(args);\n\n\treturn 0;\n\nerr_invoke:\n\tfl->init_mem = NULL;\n\tfastrpc_buf_free(imem);\nerr_alloc:\n\tif (map) {\n\t\tspin_lock(&fl->lock);\n\t\tlist_del(&map->node);\n\t\tspin_unlock(&fl->lock);\n\t\tfastrpc_map_put(map);\n\t}\nerr:\n\tkfree(args);\n\n\treturn err;\n}\n\nstatic struct fastrpc_session_ctx *fastrpc_session_alloc(\n\t\t\t\t\tstruct fastrpc_channel_ctx *cctx)\n{\n\tstruct fastrpc_session_ctx *session = NULL;\n\tunsigned long flags;\n\tint i;\n\n\tspin_lock_irqsave(&cctx->lock, flags);\n\tfor (i = 0; i < cctx->sesscount; i++) {\n\t\tif (!cctx->session[i].used && cctx->session[i].valid) {\n\t\t\tcctx->session[i].used = true;\n\t\t\tsession = &cctx->session[i];\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock_irqrestore(&cctx->lock, flags);\n\n\treturn session;\n}\n\nstatic void fastrpc_session_free(struct fastrpc_channel_ctx *cctx,\n\t\t\t\t struct fastrpc_session_ctx *session)\n{\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&cctx->lock, flags);\n\tsession->used = false;\n\tspin_unlock_irqrestore(&cctx->lock, flags);\n}\n\nstatic int fastrpc_release_current_dsp_process(struct fastrpc_user *fl)\n{\n\tstruct fastrpc_invoke_args args[1];\n\tint tgid = 0;\n\tu32 sc;\n\n\ttgid = fl->tgid;\n\targs[0].ptr = (u64)(uintptr_t) &tgid;\n\targs[0].length = sizeof(tgid);\n\targs[0].fd = -1;\n\targs[0].reserved = 0;\n\tsc = FASTRPC_SCALARS(FASTRPC_RMID_INIT_RELEASE, 1, 0);\n\n\treturn fastrpc_internal_invoke(fl, true, FASTRPC_INIT_HANDLE,\n\t\t\t\t       sc, &args[0]);\n}\n\nstatic int fastrpc_device_release(struct inode *inode, struct file *file)\n{\n\tstruct fastrpc_user *fl = (struct fastrpc_user *)file->private_data;\n\tstruct fastrpc_channel_ctx *cctx = fl->cctx;\n\tstruct fastrpc_invoke_ctx *ctx, *n;\n\tstruct fastrpc_map *map, *m;\n\tunsigned long flags;\n\n\tfastrpc_release_current_dsp_process(fl);\n\n\tspin_lock_irqsave(&cctx->lock, flags);\n\tlist_del(&fl->user);\n\tspin_unlock_irqrestore(&cctx->lock, flags);\n\n\tif (fl->init_mem)\n\t\tfastrpc_buf_free(fl->init_mem);\n\n\tlist_for_each_entry_safe(ctx, n, &fl->pending, node) {\n\t\tlist_del(&ctx->node);\n\t\tfastrpc_context_put(ctx);\n\t}\n\n\tlist_for_each_entry_safe(map, m, &fl->maps, node) {\n\t\tlist_del(&map->node);\n\t\tfastrpc_map_put(map);\n\t}\n\n\tfastrpc_session_free(cctx, fl->sctx);\n\tfastrpc_channel_ctx_put(cctx);\n\n\tmutex_destroy(&fl->mutex);\n\tkfree(fl);\n\tfile->private_data = NULL;\n\n\treturn 0;\n}\n\nstatic int fastrpc_device_open(struct inode *inode, struct file *filp)\n{\n\tstruct fastrpc_channel_ctx *cctx = miscdev_to_cctx(filp->private_data);\n\tstruct fastrpc_user *fl = NULL;\n\tunsigned long flags;\n\n\tfl = kzalloc(sizeof(*fl), GFP_KERNEL);\n\tif (!fl)\n\t\treturn -ENOMEM;\n\n\t/* Released in fastrpc_device_release() */\n\tfastrpc_channel_ctx_get(cctx);\n\n\tfilp->private_data = fl;\n\tspin_lock_init(&fl->lock);\n\tmutex_init(&fl->mutex);\n\tINIT_LIST_HEAD(&fl->pending);\n\tINIT_LIST_HEAD(&fl->maps);\n\tINIT_LIST_HEAD(&fl->user);\n\tfl->tgid = current->tgid;\n\tfl->cctx = cctx;\n\n\tfl->sctx = fastrpc_session_alloc(cctx);\n\tif (!fl->sctx) {\n\t\tdev_err(&cctx->rpdev->dev, \"No session available\\n\");\n\t\tmutex_destroy(&fl->mutex);\n\t\tkfree(fl);\n\n\t\treturn -EBUSY;\n\t}\n\n\tspin_lock_irqsave(&cctx->lock, flags);\n\tlist_add_tail(&fl->user, &cctx->users);\n\tspin_unlock_irqrestore(&cctx->lock, flags);\n\n\treturn 0;\n}\n\nstatic int fastrpc_dmabuf_alloc(struct fastrpc_user *fl, char __user *argp)\n{\n\tstruct fastrpc_alloc_dma_buf bp;\n\tDEFINE_DMA_BUF_EXPORT_INFO(exp_info);\n\tstruct fastrpc_buf *buf = NULL;\n\tint err;\n\n\tif (copy_from_user(&bp, argp, sizeof(bp)))\n\t\treturn -EFAULT;\n\n\terr = fastrpc_buf_alloc(fl, fl->sctx->dev, bp.size, &buf);\n\tif (err)\n\t\treturn err;\n\texp_info.ops = &fastrpc_dma_buf_ops;\n\texp_info.size = bp.size;\n\texp_info.flags = O_RDWR;\n\texp_info.priv = buf;\n\tbuf->dmabuf = dma_buf_export(&exp_info);\n\tif (IS_ERR(buf->dmabuf)) {\n\t\terr = PTR_ERR(buf->dmabuf);\n\t\tfastrpc_buf_free(buf);\n\t\treturn err;\n\t}\n\n\tbp.fd = dma_buf_fd(buf->dmabuf, O_ACCMODE);\n\tif (bp.fd < 0) {\n\t\tdma_buf_put(buf->dmabuf);\n\t\treturn -EINVAL;\n\t}\n\n\tif (copy_to_user(argp, &bp, sizeof(bp))) {\n\t\tdma_buf_put(buf->dmabuf);\n\t\treturn -EFAULT;\n\t}\n\n\treturn 0;\n}\n\nstatic int fastrpc_init_attach(struct fastrpc_user *fl)\n{\n\tstruct fastrpc_invoke_args args[1];\n\tint tgid = fl->tgid;\n\tu32 sc;\n\n\targs[0].ptr = (u64)(uintptr_t) &tgid;\n\targs[0].length = sizeof(tgid);\n\targs[0].fd = -1;\n\targs[0].reserved = 0;\n\tsc = FASTRPC_SCALARS(FASTRPC_RMID_INIT_ATTACH, 1, 0);\n\tfl->pd = 0;\n\n\treturn fastrpc_internal_invoke(fl, true, FASTRPC_INIT_HANDLE,\n\t\t\t\t       sc, &args[0]);\n}\n\nstatic int fastrpc_invoke(struct fastrpc_user *fl, char __user *argp)\n{\n\tstruct fastrpc_invoke_args *args = NULL;\n\tstruct fastrpc_invoke inv;\n\tu32 nscalars;\n\tint err;\n\n\tif (copy_from_user(&inv, argp, sizeof(inv)))\n\t\treturn -EFAULT;\n\n\t/* nscalars is truncated here to max supported value */\n\tnscalars = REMOTE_SCALARS_LENGTH(inv.sc);\n\tif (nscalars) {\n\t\targs = kcalloc(nscalars, sizeof(*args), GFP_KERNEL);\n\t\tif (!args)\n\t\t\treturn -ENOMEM;\n\n\t\tif (copy_from_user(args, (void __user *)(uintptr_t)inv.args,\n\t\t\t\t   nscalars * sizeof(*args))) {\n\t\t\tkfree(args);\n\t\t\treturn -EFAULT;\n\t\t}\n\t}\n\n\terr = fastrpc_internal_invoke(fl, false, inv.handle, inv.sc, args);\n\tkfree(args);\n\n\treturn err;\n}\n\nstatic long fastrpc_device_ioctl(struct file *file, unsigned int cmd,\n\t\t\t\t unsigned long arg)\n{\n\tstruct fastrpc_user *fl = (struct fastrpc_user *)file->private_data;\n\tchar __user *argp = (char __user *)arg;\n\tint err;\n\n\tswitch (cmd) {\n\tcase FASTRPC_IOCTL_INVOKE:\n\t\terr = fastrpc_invoke(fl, argp);\n\t\tbreak;\n\tcase FASTRPC_IOCTL_INIT_ATTACH:\n\t\terr = fastrpc_init_attach(fl);\n\t\tbreak;\n\tcase FASTRPC_IOCTL_INIT_CREATE:\n\t\terr = fastrpc_init_create_process(fl, argp);\n\t\tbreak;\n\tcase FASTRPC_IOCTL_ALLOC_DMA_BUFF:\n\t\terr = fastrpc_dmabuf_alloc(fl, argp);\n\t\tbreak;\n\tdefault:\n\t\terr = -ENOTTY;\n\t\tbreak;\n\t}\n\n\treturn err;\n}\n\nstatic const struct file_operations fastrpc_fops = {\n\t.open = fastrpc_device_open,\n\t.release = fastrpc_device_release,\n\t.unlocked_ioctl = fastrpc_device_ioctl,\n\t.compat_ioctl = fastrpc_device_ioctl,\n};\n\nstatic int fastrpc_cb_probe(struct platform_device *pdev)\n{\n\tstruct fastrpc_channel_ctx *cctx;\n\tstruct fastrpc_session_ctx *sess;\n\tstruct device *dev = &pdev->dev;\n\tint i, sessions = 0;\n\tunsigned long flags;\n\tint rc;\n\n\tcctx = dev_get_drvdata(dev->parent);\n\tif (!cctx)\n\t\treturn -EINVAL;\n\n\tof_property_read_u32(dev->of_node, \"qcom,nsessions\", &sessions);\n\n\tspin_lock_irqsave(&cctx->lock, flags);\n\tsess = &cctx->session[cctx->sesscount];\n\tsess->used = false;\n\tsess->valid = true;\n\tsess->dev = dev;\n\tdev_set_drvdata(dev, sess);\n\n\tif (of_property_read_u32(dev->of_node, \"reg\", &sess->sid))\n\t\tdev_info(dev, \"FastRPC Session ID not specified in DT\\n\");\n\n\tif (sessions > 0) {\n\t\tstruct fastrpc_session_ctx *dup_sess;\n\n\t\tfor (i = 1; i < sessions; i++) {\n\t\t\tif (cctx->sesscount++ >= FASTRPC_MAX_SESSIONS)\n\t\t\t\tbreak;\n\t\t\tdup_sess = &cctx->session[cctx->sesscount];\n\t\t\tmemcpy(dup_sess, sess, sizeof(*dup_sess));\n\t\t}\n\t}\n\tcctx->sesscount++;\n\tspin_unlock_irqrestore(&cctx->lock, flags);\n\trc = dma_set_mask(dev, DMA_BIT_MASK(32));\n\tif (rc) {\n\t\tdev_err(dev, \"32-bit DMA enable failed\\n\");\n\t\treturn rc;\n\t}\n\n\treturn 0;\n}\n\nstatic int fastrpc_cb_remove(struct platform_device *pdev)\n{\n\tstruct fastrpc_channel_ctx *cctx = dev_get_drvdata(pdev->dev.parent);\n\tstruct fastrpc_session_ctx *sess = dev_get_drvdata(&pdev->dev);\n\tunsigned long flags;\n\tint i;\n\n\tspin_lock_irqsave(&cctx->lock, flags);\n\tfor (i = 1; i < FASTRPC_MAX_SESSIONS; i++) {\n\t\tif (cctx->session[i].sid == sess->sid) {\n\t\t\tcctx->session[i].valid = false;\n\t\t\tcctx->sesscount--;\n\t\t}\n\t}\n\tspin_unlock_irqrestore(&cctx->lock, flags);\n\n\treturn 0;\n}\n\nstatic const struct of_device_id fastrpc_match_table[] = {\n\t{ .compatible = \"qcom,fastrpc-compute-cb\", },\n\t{}\n};\n\nstatic struct platform_driver fastrpc_cb_driver = {\n\t.probe = fastrpc_cb_probe,\n\t.remove = fastrpc_cb_remove,\n\t.driver = {\n\t\t.name = \"qcom,fastrpc-cb\",\n\t\t.of_match_table = fastrpc_match_table,\n\t\t.suppress_bind_attrs = true,\n\t},\n};\n\nstatic int fastrpc_rpmsg_probe(struct rpmsg_device *rpdev)\n{\n\tstruct device *rdev = &rpdev->dev;\n\tstruct fastrpc_channel_ctx *data;\n\tint i, err, domain_id = -1;\n\tconst char *domain;\n\n\terr = of_property_read_string(rdev->of_node, \"label\", &domain);\n\tif (err) {\n\t\tdev_info(rdev, \"FastRPC Domain not specified in DT\\n\");\n\t\treturn err;\n\t}\n\n\tfor (i = 0; i <= CDSP_DOMAIN_ID; i++) {\n\t\tif (!strcmp(domains[i], domain)) {\n\t\t\tdomain_id = i;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (domain_id < 0) {\n\t\tdev_info(rdev, \"FastRPC Invalid Domain ID %d\\n\", domain_id);\n\t\treturn -EINVAL;\n\t}\n\n\tdata = kzalloc(sizeof(*data), GFP_KERNEL);\n\tif (!data)\n\t\treturn -ENOMEM;\n\n\tdata->miscdev.minor = MISC_DYNAMIC_MINOR;\n\tdata->miscdev.name = kasprintf(GFP_KERNEL, \"fastrpc-%s\",\n\t\t\t\tdomains[domain_id]);\n\tdata->miscdev.fops = &fastrpc_fops;\n\terr = misc_register(&data->miscdev);\n\tif (err)\n\t\treturn err;\n\n\tkref_init(&data->refcount);\n\n\tdev_set_drvdata(&rpdev->dev, data);\n\tdma_set_mask_and_coherent(rdev, DMA_BIT_MASK(32));\n\tINIT_LIST_HEAD(&data->users);\n\tspin_lock_init(&data->lock);\n\tidr_init(&data->ctx_idr);\n\tdata->domain_id = domain_id;\n\tdata->rpdev = rpdev;\n\n\treturn of_platform_populate(rdev->of_node, NULL, NULL, rdev);\n}\n\nstatic void fastrpc_notify_users(struct fastrpc_user *user)\n{\n\tstruct fastrpc_invoke_ctx *ctx;\n\n\tspin_lock(&user->lock);\n\tlist_for_each_entry(ctx, &user->pending, node)\n\t\tcomplete(&ctx->work);\n\tspin_unlock(&user->lock);\n}\n\nstatic void fastrpc_rpmsg_remove(struct rpmsg_device *rpdev)\n{\n\tstruct fastrpc_channel_ctx *cctx = dev_get_drvdata(&rpdev->dev);\n\tstruct fastrpc_user *user;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&cctx->lock, flags);\n\tlist_for_each_entry(user, &cctx->users, user)\n\t\tfastrpc_notify_users(user);\n\tspin_unlock_irqrestore(&cctx->lock, flags);\n\n\tmisc_deregister(&cctx->miscdev);\n\tof_platform_depopulate(&rpdev->dev);\n\n\tcctx->rpdev = NULL;\n\tfastrpc_channel_ctx_put(cctx);\n}\n\nstatic int fastrpc_rpmsg_callback(struct rpmsg_device *rpdev, void *data,\n\t\t\t\t  int len, void *priv, u32 addr)\n{\n\tstruct fastrpc_channel_ctx *cctx = dev_get_drvdata(&rpdev->dev);\n\tstruct fastrpc_invoke_rsp *rsp = data;\n\tstruct fastrpc_invoke_ctx *ctx;\n\tunsigned long flags;\n\tunsigned long ctxid;\n\n\tif (len < sizeof(*rsp))\n\t\treturn -EINVAL;\n\n\tctxid = ((rsp->ctx & FASTRPC_CTXID_MASK) >> 4);\n\n\tspin_lock_irqsave(&cctx->lock, flags);\n\tctx = idr_find(&cctx->ctx_idr, ctxid);\n\tspin_unlock_irqrestore(&cctx->lock, flags);\n\n\tif (!ctx) {\n\t\tdev_err(&rpdev->dev, \"No context ID matches response\\n\");\n\t\treturn -ENOENT;\n\t}\n\n\tctx->retval = rsp->retval;\n\tcomplete(&ctx->work);\n\n\t/*\n\t * The DMA buffer associated with the context cannot be freed in\n\t * interrupt context so schedule it through a worker thread to\n\t * avoid a kernel BUG.\n\t */\n\tschedule_work(&ctx->put_work);\n\n\treturn 0;\n}\n\nstatic const struct of_device_id fastrpc_rpmsg_of_match[] = {\n\t{ .compatible = \"qcom,fastrpc\" },\n\t{ },\n};\nMODULE_DEVICE_TABLE(of, fastrpc_rpmsg_of_match);\n\nstatic struct rpmsg_driver fastrpc_driver = {\n\t.probe = fastrpc_rpmsg_probe,\n\t.remove = fastrpc_rpmsg_remove,\n\t.callback = fastrpc_rpmsg_callback,\n\t.drv = {\n\t\t.name = \"qcom,fastrpc\",\n\t\t.of_match_table = fastrpc_rpmsg_of_match,\n\t},\n};\n\nstatic int fastrpc_init(void)\n{\n\tint ret;\n\n\tret = platform_driver_register(&fastrpc_cb_driver);\n\tif (ret < 0) {\n\t\tpr_err(\"fastrpc: failed to register cb driver\\n\");\n\t\treturn ret;\n\t}\n\n\tret = register_rpmsg_driver(&fastrpc_driver);\n\tif (ret < 0) {\n\t\tpr_err(\"fastrpc: failed to register rpmsg driver\\n\");\n\t\tplatform_driver_unregister(&fastrpc_cb_driver);\n\t\treturn ret;\n\t}\n\n\treturn 0;\n}\nmodule_init(fastrpc_init);\n\nstatic void fastrpc_exit(void)\n{\n\tplatform_driver_unregister(&fastrpc_cb_driver);\n\tunregister_rpmsg_driver(&fastrpc_driver);\n}\nmodule_exit(fastrpc_exit);\n\nMODULE_LICENSE(\"GPL v2\");\n"], "filenames": ["drivers/misc/fastrpc.c"], "buggy_code_start_loc": [529], "buggy_code_end_loc": [529], "fixing_code_start_loc": [530], "fixing_code_end_loc": [531], "type": "CWE-401", "message": "A memory leak in the fastrpc_dma_buf_attach() function in drivers/misc/fastrpc.c in the Linux kernel before 5.3.9 allows attackers to cause a denial of service (memory consumption) by triggering dma_get_sgtable() failures, aka CID-fc739a058d99.", "other": {"cve": {"id": "CVE-2019-19069", "sourceIdentifier": "cve@mitre.org", "published": "2019-11-18T06:15:12.920", "lastModified": "2021-06-22T14:47:56.090", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "A memory leak in the fastrpc_dma_buf_attach() function in drivers/misc/fastrpc.c in the Linux kernel before 5.3.9 allows attackers to cause a denial of service (memory consumption) by triggering dma_get_sgtable() failures, aka CID-fc739a058d99."}, {"lang": "es", "value": "Una p\u00e9rdida de memoria en la funci\u00f3n fastrpc_dma_buf_attach() en el archivo drivers/misc/fastrpc.c en el kernel de Linux versiones anteriores a la versi\u00f3n  5.3.9, permite a atacantes causar una denegaci\u00f3n de servicio (consumo de memoria) al desencadenar fallos de la funci\u00f3n dma_get_sgtable(), tambi\u00e9n se conoce como CID-fc739a058d99."}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 7.5, "baseSeverity": "HIGH"}, "exploitabilityScore": 3.9, "impactScore": 3.6}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:N/AC:L/Au:N/C:N/I:N/A:C", "accessVector": "NETWORK", "accessComplexity": "LOW", "authentication": "NONE", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "COMPLETE", "baseScore": 7.8}, "baseSeverity": "HIGH", "exploitabilityScore": 10.0, "impactScore": 6.9, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-401"}]}], "configurations": [{"operator": "AND", "nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionStartIncluding": "5.1", "versionEndExcluding": "5.3.9", "matchCriteriaId": "316A2191-9BA1-4C58-A61C-29F91E2CF3B7"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:5.4:rc1:*:*:*:*:*:*", "matchCriteriaId": "AD561918-619D-4363-8330-53B4B903D2CE"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:5.4:rc2:*:*:*:*:*:*", "matchCriteriaId": "DCF307A4-6CF2-43FA-94E5-2EBB1033634B"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:5.4:rc3:*:*:*:*:*:*", "matchCriteriaId": "72D64137-DAA7-40C0-8BAD-9DBCB285BC00"}]}]}, {"operator": "AND", "nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:canonical:ubuntu_linux:18.04:*:*:*:lts:*:*:*", "matchCriteriaId": "23A7C53F-B80F-4E6A-AFA9-58EEA84BE11D"}, {"vulnerable": true, "criteria": "cpe:2.3:o:canonical:ubuntu_linux:19.10:*:*:*:*:*:*:*", "matchCriteriaId": "A31C8344-3E02-4EB8-8BD8-4C84B7959624"}]}]}, {"operator": "AND", "nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:netapp:active_iq_unified_manager:-:*:*:*:*:vmware_vsphere:*:*", "matchCriteriaId": "3A756737-1CC4-42C2-A4DF-E1C893B4E2D5"}, {"vulnerable": true, "criteria": "cpe:2.3:a:netapp:data_availability_services:-:*:*:*:*:*:*:*", "matchCriteriaId": "0EF46487-B64A-454E-AECC-D74B83170ACD"}, {"vulnerable": true, "criteria": "cpe:2.3:a:netapp:e-series_santricity_os_controller:*:*:*:*:*:*:*:*", "versionStartIncluding": "11.0.0", "versionEndIncluding": "11.60.3", "matchCriteriaId": "BD1E9594-C46F-40D1-8BC2-6B16635B55C4"}, {"vulnerable": true, "criteria": "cpe:2.3:a:netapp:hci_management_node:-:*:*:*:*:*:*:*", "matchCriteriaId": "A3C19813-E823-456A-B1CE-EC0684CE1953"}, {"vulnerable": true, "criteria": "cpe:2.3:a:netapp:solidfire:-:*:*:*:*:*:*:*", "matchCriteriaId": "A6E9EF0C-AFA8-4F7B-9FDC-1E0F7C26E737"}, {"vulnerable": true, "criteria": "cpe:2.3:a:netapp:steelstore_cloud_integrated_storage:-:*:*:*:*:*:*:*", "matchCriteriaId": "E94F7F59-1785-493F-91A7-5F5EA5E87E4D"}, {"vulnerable": true, "criteria": "cpe:2.3:h:netapp:hci_compute_node:-:*:*:*:*:*:*:*", "matchCriteriaId": "AD7447BC-F315-4298-A822-549942FC118B"}, {"vulnerable": true, "criteria": "cpe:2.3:h:netapp:hci_storage_node:-:*:*:*:*:*:*:*", "matchCriteriaId": "02DEB4FB-A21D-4CB1-B522-EEE5093E8521"}, {"vulnerable": true, "criteria": "cpe:2.3:o:broadcom:fabric_operating_system:-:*:*:*:*:*:*:*", "matchCriteriaId": "046FB51E-B768-44D3-AEB5-D857145CA840"}]}]}, {"operator": "AND", "nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:netapp:aff_a700s_firmware:-:*:*:*:*:*:*:*", "matchCriteriaId": "952F55C9-7E7C-4539-9D08-E736B3488569"}]}, {"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": false, "criteria": "cpe:2.3:h:netapp:aff_a700s:-:*:*:*:*:*:*:*", "matchCriteriaId": "9FED1B0D-F901-413A-85D9-05D4C427570D"}]}]}, {"operator": "AND", "nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:netapp:fas8300_firmware:-:*:*:*:*:*:*:*", "matchCriteriaId": "89706810-031B-49F0-B353-FD27FD7B2776"}]}, {"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": false, "criteria": "cpe:2.3:h:netapp:fas8300:-:*:*:*:*:*:*:*", "matchCriteriaId": "03BCC59D-C782-4149-B6DC-5DDAFAB48F2D"}]}]}, {"operator": "AND", "nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:netapp:fas8700_firmware:-:*:*:*:*:*:*:*", "matchCriteriaId": "FDD1E822-1EA6-4E62-A58B-2378149D20DC"}]}, {"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": false, "criteria": "cpe:2.3:h:netapp:fas8700:-:*:*:*:*:*:*:*", "matchCriteriaId": "E07EAE5F-B1B5-4FDA-9B50-8CB1D2AFC5A0"}]}]}, {"operator": "AND", "nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:netapp:aff_a400_firmware:-:*:*:*:*:*:*:*", "matchCriteriaId": "56FD9B9A-BBE5-4CA5-B9F9-B16E1FE738C8"}]}, {"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": false, "criteria": "cpe:2.3:h:netapp:aff_a400:-:*:*:*:*:*:*:*", "matchCriteriaId": "F3E70A56-DBA8-45C7-8C49-1A036501156F"}]}]}, {"operator": "AND", "nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:netapp:h610s_firmware:-:*:*:*:*:*:*:*", "matchCriteriaId": "FD7CFE0E-9D1E-4495-B302-89C3096FC0DF"}]}, {"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": false, "criteria": "cpe:2.3:h:netapp:h610s:-:*:*:*:*:*:*:*", "matchCriteriaId": "F63A3FA7-AAED-4A9D-9FDE-6195302DA0F6"}]}]}], "references": [{"url": "https://cdn.kernel.org/pub/linux/kernel/v5.x/ChangeLog-5.3.9", "source": "cve@mitre.org", "tags": ["Release Notes", "Vendor Advisory"]}, {"url": "https://github.com/torvalds/linux/commit/fc739a058d99c9297ef6bfd923b809d85855b9a9", "source": "cve@mitre.org", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://security.netapp.com/advisory/ntap-20191205-0001/", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}, {"url": "https://usn.ubuntu.com/4208-1/", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}]}, "github_commit_url": "https://github.com/torvalds/linux/commit/fc739a058d99c9297ef6bfd923b809d85855b9a9"}}
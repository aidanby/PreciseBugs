{"buggy_code": ["require 'sinatra'\nrequire 'sinatra/reloader' if development?\nrequire 'sinatra/cookies'\nrequire 'rexml/document'\nrequire 'webrick'\nrequire 'webrick/https'\nrequire 'openssl'\nrequire 'logger'\nrequire 'thread'\n\nrequire 'bootstrap.rb'\nrequire 'resource.rb'\nrequire 'remote.rb'\nrequire 'fenceagent.rb'\nrequire 'cluster.rb'\nrequire 'config.rb'\nrequire 'pcs.rb'\nrequire 'auth.rb'\nrequire 'wizard.rb'\nrequire 'cfgsync.rb'\nrequire 'permissions.rb'\n\nDir[\"wizards/*.rb\"].each {|file| require file}\n\nuse Rack::CommonLogger\n\nset :app_file, __FILE__\n\ndef generate_cookie_secret\n  return SecureRandom.hex(30)\nend\n\nbegin\n  secret = File.read(COOKIE_FILE)\n  secret_errors = verify_cookie_secret(secret)\n  if secret_errors and not secret_errors.empty?\n    secret_errors.each { |err| $logger.error err }\n    $logger.error \"Invalid cookie secret, using temporary one\"\n    secret = generate_cookie_secret()\n  end\nrescue Errno::ENOENT\n  secret = generate_cookie_secret()\n  File.open(COOKIE_FILE, 'w', 0700) {|f| f.write(secret)}\nend\n\nuse Rack::Session::Cookie,\n  :expire_after => 60 * 60,\n  :secret => secret,\n  :secure => true, # only send over HTTPS\n  :httponly => true # don't provide to javascript\n\n#use Rack::SSL\n\nif development?\n  Dir[\"wizards/*.rb\"].each {|file| also_reload file}\n  also_reload 'resource.rb'\n  also_reload 'remote.rb'\n  also_reload 'fenceagent.rb'\n  also_reload 'cluster.rb'\n  also_reload 'config.rb'\n  also_reload 'pcs.rb'\n  also_reload 'auth.rb'\n  also_reload 'wizard.rb'\n  also_reload 'cfgsync.rb'\nend\n\nbefore do\n  if request.path != '/login' and not request.path == \"/logout\" and not request.path == '/remote/auth'\n    protected! \n  end\n  $cluster_name = get_cluster_name()\n  @errorval = session[:errorval]\n  @error = session[:error]\n  session[:errorval] = nil\n  session[:error] = nil\nend\n\nconfigure do\n  DISABLE_GUI = (ENV['DISABLE_GUI'] and ENV['DISABLE_GUI'].downcase == 'true')\n  PCS = get_pcs_path(File.expand_path(File.dirname(__FILE__)))\n  logger = File.open(\"/var/log/pcsd/pcsd.log\", \"a+\", 0600)\n  STDOUT.reopen(logger)\n  STDERR.reopen(logger)\n  STDOUT.sync = true\n  STDERR.sync = true\n  $logger = configure_logger('/var/log/pcsd/pcsd.log')\n  $semaphore_cfgsync = Mutex.new\nend\n\nset :logging, true\nset :run, false\n\n$thread_cfgsync = Thread.new {\n  while true\n    $semaphore_cfgsync.synchronize {\n      $logger.debug('Config files sync thread started')\n      if Cfgsync::ConfigSyncControl.sync_thread_allowed?()\n        begin\n          # do not sync if this host is not in a cluster\n          cluster_name = get_cluster_name()\n          if cluster_name and !cluster_name.empty?()\n            $logger.debug('Config files sync thread fetching')\n            fetcher = Cfgsync::ConfigFetcher.new(\n              PCSAuth.getSuperuserSession(), Cfgsync::get_cfg_classes(),\n              get_corosync_nodes(), cluster_name\n            )\n            cfgs_to_save, _ = fetcher.fetch()\n            cfgs_to_save.each { |cfg_to_save|\n              cfg_to_save.save()\n            }\n          end\n        rescue => e\n          $logger.warn(\"Config files sync thread exception: #{e}\")\n        end\n      end\n      $logger.debug('Config files sync thread finished')\n    }\n    sleep(Cfgsync::ConfigSyncControl.sync_thread_interval())\n  end\n}\n\nhelpers do\n  def protected!\n    if not PCSAuth.loginByToken(session, cookies) and not PCSAuth.isLoggedIn(session)\n      # If we're on /managec/<cluster_name>/main we redirect\n      match_expr = \"/managec/(.*)/(.*)\"\n      mymatch = request.path.match(match_expr)\n      on_managec_main = false\n      if mymatch and mymatch.length >= 3 and mymatch[2] == \"main\"\n        on_managec_main = true\n      end\n\n      if request.path.start_with?('/remote') or\n        (request.path.match(match_expr) and not on_managec_main) or\n        '/run_pcs' == request.path or\n        '/clusters_overview' == request.path or\n        request.path.start_with?('/permissions_')\n      then\n        $logger.info \"ERROR: Request without authentication\"\n        halt [401, '{\"notauthorized\":\"true\"}']\n      else\n        session[:pre_login_path] = request.path\n        redirect '/login'\n      end\n    end\n  end\n\n  def getParamList(params)\n    param_line = []\n    meta_options = []\n    params.each { |param, val|\n      if param.start_with?(\"_res_paramne_\") or (param.start_with?(\"_res_paramempty_\") and val != \"\")\n        myparam = param.sub(/^_res_paramne_/,\"\").sub(/^_res_paramempty_/,\"\")\n        param_line << \"#{myparam}=#{val}\"\n      end\n      if param == \"disabled\"\n        meta_options << 'meta' << 'target-role=Stopped'\n      end\n    }\n    return param_line + meta_options\n  end\nend\n\nget '/remote/?:command?' do\n  return remote(params, request, session)\nend\n\npost '/remote/?:command?' do\n  return remote(params, request, session)\nend\n\npost '/run_pcs' do\n  command = params['command'] || '{}'\n  std_in = params['stdin'] || nil\n  begin\n    command_decoded = JSON.parse(command)\n  rescue JSON::ParserError\n    result = {\n      'status' => 'error',\n      'data' => {},\n    }\n    return JSON.pretty_generate(result)\n  end\n  # do not reveal potentialy sensitive information\n  command_decoded.delete('--debug')\n\n  allowed_commands = {\n    ['cluster', 'auth', '...'] => {\n      'only_superuser' => false,\n      'permissions' => nil,\n    },\n    # runs on the local node, check permissions\n    ['cluster', 'corosync'] => {\n      'only_superuser' => false,\n      'permissions' => Permissions::READ,\n    },\n    # runs on a remote node which checks permissions by itself\n    ['cluster', 'corosync', '...'] => {\n      'only_superuser' => false,\n      'permissions' => nil,\n    },\n    ['cluster', 'destroy', '...'] => {\n      'only_superuser' => false,\n      'permissions' => Permissions::FULL,\n    },\n    # runs on the local node, check permissions\n    ['cluster', 'disable'] => {\n      'only_superuser' => false,\n      'permissions' => Permissions::WRITE,\n    },\n    # runs on a remote node which checks permissions by itself\n    ['cluster', 'disable', '...'] => {\n      'only_superuser' => false,\n      'permissions' => nil,\n    },\n    # runs on the local node, check permissions\n    ['cluster', 'enable'] => {\n      'only_superuser' => false,\n      'permissions' => Permissions::WRITE,\n    },\n    # runs on a remote node which checks permissions by itself\n    ['cluster', 'enable', '...'] => {\n      'only_superuser' => false,\n      'permissions' => nil,\n    },\n    ['cluster', 'node', '...'] => {\n      'only_superuser' => false,\n      'permissions' => Permissions::FULL,\n    },\n    ['cluster', 'pcsd-status', '...'] => {\n      'only_superuser' => false,\n      'permissions' => nil,\n    },\n    ['cluster', 'setup', '...'] => {\n      'only_superuser' => true,\n      'permissions' => nil,\n    },\n    # runs on the local node, check permissions\n    ['cluster', 'start'] => {\n      'only_superuser' => false,\n      'permissions' => Permissions::WRITE,\n    },\n    # runs on a remote node which checks permissions by itself\n    ['cluster', 'start', '...'] => {\n      'only_superuser' => false,\n      'permissions' => nil,\n    },\n    # runs on the local node, check permissions\n    ['cluster', 'stop'] => {\n      'only_superuser' => false,\n      'permissions' => Permissions::WRITE,\n    },\n    # runs on a remote node which checks permissions by itself\n    ['cluster', 'stop', '...'] => {\n      'only_superuser' => false,\n      'permissions' => nil,\n    },\n    ['cluster', 'sync', '...'] => {\n      'only_superuser' => false,\n      'permissions' => Permissions::FULL,\n    },\n    ['config', 'restore', '...'] => {\n      'only_superuser' => false,\n      'permissions' => Permissions::FULL,\n    },\n    ['pcsd', 'sync-certificates', '...'] => {\n      'only_superuser' => false,\n      'permissions' => Permissions::FULL,\n    },\n    ['status', 'nodes', 'corosync-id', '...'] => {\n      'only_superuser' => false,\n      'permissions' => Permissions::READ,\n    },\n    ['status', 'nodes', 'pacemaker-id', '...'] => {\n      'only_superuser' => false,\n      'permissions' => Permissions::READ,\n    },\n    ['status', 'pcsd', '...'] => {\n      'only_superuser' => false,\n      'permissions' => nil,\n    },\n  }\n  allowed = false\n  command_settings = {}\n  allowed_commands.each { |cmd, cmd_settings|\n    if command_decoded == cmd \\\n      or \\\n      (cmd[-1] == '...' and cmd[0..-2] == command_decoded[0..(cmd.length - 2)])\n      then\n        allowed = true\n        command_settings = cmd_settings\n        break\n    end\n  }\n  if !allowed\n    result = {\n      'status' => 'bad_command',\n      'data' => {},\n    }\n    return JSON.pretty_generate(result)\n  end\n\n  if command_settings['only_superuser']\n    if not allowed_for_superuser(session)\n      return 403, 'Permission denied'\n    end\n  end\n  if command_settings['permissions']\n    if not allowed_for_local_cluster(session, command_settings['permissions'])\n      return 403, 'Permission denied'\n    end\n  end\n\n  options = {}\n  options['stdin'] = std_in if std_in\n  std_out, std_err, retval = run_cmd_options(\n    session, options, PCS, *command_decoded\n  )\n  result = {\n    'status' => 'ok',\n    'data' => {\n      'stdout' => std_out.join(\"\"),\n      'stderr' => std_err.join(\"\"),\n      'code' => retval,\n    },\n  }\n  return JSON.pretty_generate(result)\nend\n\nif not DISABLE_GUI\n  get('/login'){ erb :login, :layout => :main }\n\n  get '/logout' do \n    session.clear\n    erb :login, :layout => :main\n  end\n\n  post '/login' do\n    if PCSAuth.loginByPassword(session, params['username'], params['password'])\n      # Temporarily ignore pre_login_path until we come up with a list of valid\n      # paths to redirect to (to prevent status_all issues)\n      #    if session[\"pre_login_path\"]\n      #      plp = session[\"pre_login_path\"]\n      #      session.delete(\"pre_login_path\")\n      #      pp \"Pre Login Path: \" + plp\n      #      if plp == \"\" or plp == \"/\"\n      #        plp = '/manage'\n      #      end\n      #      redirect plp\n      #    else\n      redirect '/manage'\n      #    end\n    else\n      session[\"bad_login_name\"] = params['username']\n      redirect '/login?badlogin=1'\n    end\n  end\n\n  post '/manage/existingcluster' do\n    pcs_config = PCSConfig.new(Cfgsync::PcsdSettings.from_file('{}').text())\n    node = params['node-name']\n    code, result = send_request_with_token(\n      PCSAuth.getSuperuserSession(), node, 'status'\n    )\n    begin\n      status = JSON.parse(result)\n    rescue JSON::ParserError\n      return 400, \"Unable to communicate with remote pcsd on node '#{node}'.\"\n    end\n\n    warning_messages = []\n\n    if status.has_key?(\"corosync_offline\") and\n      status.has_key?(\"corosync_online\") then\n      nodes = status[\"corosync_offline\"] + status[\"corosync_online\"]\n\n      if status[\"cluster_name\"] == ''\n        return 400, \"The node, '#{noname}', does not currently have a cluster\n configured.  You must create a cluster using this node before adding it to pcsd.\"\n      end\n\n      if pcs_config.is_cluster_name_in_use(status[\"cluster_name\"])\n        return 400, \"The cluster name, '#{status['cluster_name']}' has\nalready been added to pcsd.  You may not add two clusters with the same name into pcsd.\"\n      end\n\n      # auth begin\n      retval, out = send_request_with_token(\n        PCSAuth.getSuperuserSession(), node, '/get_cluster_tokens'\n      )\n      if retval == 404 # backward compatibility layer\n        warning_messages << \"Unable to do correct authentication of cluster because it is running old version of pcs/pcsd.\"\n      else\n        if retval != 200\n          return 400, \"Unable to get authentication info from cluster '#{status['cluster_name']}'.\"\n        end\n        begin\n          new_tokens = JSON.parse(out)\n        rescue\n          return 400, \"Unable to get authentication info from cluster '#{status['cluster_name']}'.\"\n        end\n\n        sync_config = Cfgsync::PcsdTokens.from_file('')\n        pushed, _ = Cfgsync::save_sync_new_tokens(\n          sync_config, new_tokens, get_corosync_nodes(), $cluster_name\n        )\n        if not pushed\n          return 400, \"Configuration conflict detected.\\n\\nSome nodes had a newer configuration than the local node. Local node's configuration was updated.  Please repeat the last action if appropriate.\"\n        end\n      end\n      #auth end\n\n      pcs_config.clusters << Cluster.new(status[\"cluster_name\"], nodes)\n\n      sync_config = Cfgsync::PcsdSettings.from_text(pcs_config.text())\n      pushed, _ = Cfgsync::save_sync_new_version(\n        sync_config, get_corosync_nodes(), $cluster_name, true\n      )\n      if not pushed\n        return 400, \"Configuration conflict detected.\\n\\nSome nodes had a newer configuration than the local node. Local node's configuration was updated.  Please repeat the last action if appropriate.\"\n      end\n      return 200, warning_messages.join(\"\\n\\n\")\n    else\n      return 400, \"Unable to communicate with remote pcsd on node '#{node}'.\"\n    end\n  end\n\n  post '/manage/newcluster' do\n    if not allowed_for_superuser(session)\n      return 400, 'Permission denied.'\n    end\n\n    warning_messages = []\n\n    pcs_config = PCSConfig.new(Cfgsync::PcsdSettings.from_file('{}').text())\n    @manage = true\n    @cluster_name = params[:clustername]\n    @nodes = []\n    nodes_with_indexes = []\n    @nodes_rrp = []\n    options = {}\n    params.each {|k,v|\n      if k.start_with?(\"node-\") and v != \"\"\n        @nodes << v\n        nodes_with_indexes << [k[5..-1].to_i, v]\n        if params.has_key?(\"ring1-\" + k) and params[\"ring1-\" + k] != \"\"\n          @nodes_rrp << v + \",\" + params[\"ring1-\" + k]\n        else\n          @nodes_rrp << v\n        end\n      end\n      if k.start_with?(\"config-\") and v != \"\"\n        options[k.sub(\"config-\",\"\")] = v\n      end\n    }\n    if pcs_config.is_cluster_name_in_use(@cluster_name)\n      return 400, \"The cluster name, '#{@cluster_name}' has already been added to pcsd.  You may not add two clusters with the same name into pcsd.\"\n    end\n\n    @nodes.each {|n|\n      if pcs_config.is_node_in_use(n)\n        return 400, \"The node, '#{n}' is already configured in pcsd.  You may not add a node to two different clusters in pcsd.\"\n      end\n    }\n\n    # first we need to authenticate nodes to each other\n    tokens = add_prefix_to_keys(get_tokens_of_nodes(@nodes), \"node:\")\n    @nodes.each {|n|\n      retval, out = send_request_with_token(\n        session, n, \"/save_tokens\", true, tokens\n      )\n      if retval == 404 # backward compatibility layer\n        warning_messages << \"Unable to do correct authentication of cluster on node '#{n}', because it is running old version of pcs/pcsd.\"\n        break\n      elsif retval != 200\n        return 400, \"Unable to authenticate all nodes on node '#{n}'.\"\n      end\n    }\n\n    # the first node from the form is the source of config files\n    node_to_send_to = nodes_with_indexes.sort[0][1]\n    $logger.info(\n      \"Sending setup cluster request for: #{@cluster_name} to: #{node_to_send_to}\"\n    )\n    code,out = send_request_with_token(\n      session,\n      node_to_send_to,\n      'setup_cluster',\n      true,\n      {\n        :clustername => @cluster_name,\n        :nodes => @nodes_rrp.join(';'),\n        :options => options.to_json\n      },\n      true,\n      nil,\n      60\n    )\n\n    if code == 200\n      pushed = false\n      2.times {\n        # Add the new cluster to config and publish the config.\n        # If this host is a node of the cluster, some other node may send its\n        # own PcsdSettings.  To handle it we just need to reload the config, as\n        # we are waiting for the request to finish, so no locking is needed.\n        # If we are in a different cluster we just try twice to update the\n        # config, dealing with any updates in between.\n        pcs_config = PCSConfig.new(Cfgsync::PcsdSettings.from_file('{}').text())\n        pcs_config.clusters << Cluster.new(@cluster_name, @nodes)\n        sync_config = Cfgsync::PcsdSettings.from_text(pcs_config.text())\n        pushed, _ = Cfgsync::save_sync_new_version(\n          sync_config, get_corosync_nodes(), $cluster_name, true\n        )\n        break if pushed\n      }\n      if not pushed\n        return 400, \"Configuration conflict detected.\\n\\nSome nodes had a newer configuration than the local node. Local node's configuration was updated.  Please repeat the last action if appropriate.\"\n      end\n    else\n      return 400, \"Unable to create new cluster. If cluster already exists on one or more of the nodes run 'pcs cluster destroy' on all nodes to remove current cluster configuration.\\n\\n#{node_to_send_to}: #{out}\"\n    end\n\n    return warning_messages.join(\"\\n\\n\")\n  end\n\n  post '/manage/removecluster' do\n    pcs_config = PCSConfig.new(Cfgsync::PcsdSettings.from_file('{}').text())\n    params.each { |k,v|\n      if k.start_with?(\"clusterid-\")\n        pcs_config.remove_cluster(k.sub(\"clusterid-\",\"\"))\n      end\n    }\n    sync_config = Cfgsync::PcsdSettings.from_text(pcs_config.text())\n    pushed, _ = Cfgsync::save_sync_new_version(\n      sync_config, get_corosync_nodes(), $cluster_name, true\n    )\n    if not pushed\n      return 400, \"Configuration conflict detected.\\n\\nSome nodes had a newer configuration than the local node.  Local node's configuration was updated.  Please repeat the last action if appropriate.\"\n    end\n  end\n\n  get '/manage/check_pcsd_status' do\n    node_results = {}\n    if params[:nodes] != nil and params[:nodes] != ''\n      node_array = params[:nodes].split(',')\n      online, offline, notauthorized = check_gui_status_of_nodes(\n        session, node_array\n      )\n      online.each { |node|\n        node_results[node] = 'Online'\n      }\n      offline.each { |node|\n        node_results[node] = 'Offline'\n      }\n      notauthorized.each { |node|\n        node_results[node] = 'Unable to authenticate'\n      }\n    end\n    return JSON.generate(node_results)\n  end\n\n  get '/manage/get_nodes_sw_versions' do\n    if params[:nodes] != nil and params[:nodes] != ''\n      nodes = params[:nodes].split(',')\n      final_response = {}\n      threads = []\n      nodes.each {|node|\n        threads << Thread.new {\n          code, response = send_request_with_token(\n            session, node, 'get_sw_versions'\n          )\n          begin\n            node_response = JSON.parse(response)\n            if node_response and node_response['notoken'] == true\n              $logger.error(\"ERROR: bad token for #{node}\")\n            end\n            final_response[node] = node_response\n          rescue JSON::ParserError => e\n          end\n        }\n      }\n      threads.each { |t| t.join }\n      return JSON.generate(final_response)\n    end\n    return '{}'\n  end\n\n  post '/manage/auth_gui_against_nodes' do\n    node_auth_error = {}\n    new_tokens = {}\n    threads = []\n    params.each { |node|\n      threads << Thread.new {\n        if node[0].end_with?(\"-pass\") and node[0].length > 5\n          nodename = node[0][0..-6]\n          if params.has_key?(\"all\")\n            pass = params[\"pass-all\"]\n          else\n            pass = node[1]\n          end\n          data = {\n            'node-0' => nodename,\n            'username' => SUPERUSER,\n            'password' => pass,\n            'force' => 1,\n          }\n          node_auth_error[nodename] = 1\n          code, response = send_request(session, nodename, 'auth', true, data)\n          if 200 == code\n            token = response.strip\n            if not token.empty?\n              new_tokens[nodename] = token\n              node_auth_error[nodename] = 0\n            end\n          end\n        end\n      }\n    }\n    threads.each { |t| t.join }\n\n    if not new_tokens.empty?\n      cluster_nodes = get_corosync_nodes()\n      tokens_cfg = Cfgsync::PcsdTokens.from_file('')\n      sync_successful, sync_responses = Cfgsync::save_sync_new_tokens(\n        tokens_cfg, new_tokens, cluster_nodes, $cluster_name\n      )\n    end\n\n    return [200, JSON.generate({'node_auth_error' => node_auth_error})]\n  end\n\n  get '/manage/?' do\n    @manage = true\n    erb :manage, :layout => :main\n  end\n\n  get '/clusters_overview' do\n    clusters_overview(params, request, session)\n  end\n\n  get '/permissions/?' do\n    @manage = true\n    pcs_config = PCSConfig.new(Cfgsync::PcsdSettings.from_file('{}').text())\n    @clusters = pcs_config.clusters.sort { |a, b| a.name <=> b.name }\n    erb :permissions, :layout => :main\n  end\n\n  get '/permissions_cluster_form/:cluster/?' do\n    @cluster_name = params[:cluster]\n    @error = nil\n    @permission_types = []\n    @permissions_dependencies = {}\n    @user_types = []\n    @users_permissions = []\n\n    pcs_config = PCSConfig.new(Cfgsync::PcsdSettings.from_file('{}').text())\n\n    if not pcs_config.is_cluster_name_in_use(@cluster_name)\n      @error = 'Cluster not found'\n    else\n      code, data = send_cluster_request_with_token(\n        session, @cluster_name, 'get_permissions'\n      )\n      if 404 == code\n        @error = 'Cluster is running an old version of pcsd which does not support permissions'\n      elsif 403 == code\n        @error = 'Permission denied'\n      elsif 200 != code\n        @error = 'Unable to load permissions of the cluster'\n      else\n        begin\n          permissions = JSON.parse(data)\n          if permissions['notoken'] or permissions['noresponse']\n            @error = 'Unable to load permissions of the cluster'\n          else\n            @permission_types = permissions['permission_types'] || []\n            @permissions_dependencies = permissions['permissions_dependencies'] || {}\n            @user_types = permissions['user_types'] || []\n            @users_permissions = permissions['users_permissions'] || []\n          end\n        rescue JSON::ParserError\n          @error = 'Unable to read permissions of the cluster'\n        end\n      end\n    end\n    erb :_permissions_cluster\n  end\n\n  get '/managec/:cluster/main' do\n    @cluster_name = params[:cluster]\n    pcs_config = PCSConfig.new(Cfgsync::PcsdSettings.from_file('{}').text())\n    @clusters = pcs_config.clusters\n    @nodes = get_cluster_nodes(params[:cluster])\n    if @nodes == []\n      redirect '/manage/'\n    end\n    @resource_agents = get_resource_agents_avail(session)\n    @stonith_agents = get_stonith_agents_avail(session)\n    erb :nodes, :layout => :main\n  end\n\n  post '/managec/:cluster/permissions_save/?' do\n    new_params = {\n      'json_data' => JSON.generate(params)\n    }\n    return send_cluster_request_with_token(\n      session, params[:cluster], \"set_permissions\", true, new_params\n    )\n  end\n\n  get '/managec/:cluster/status_all' do\n    status_all(params, request, session, get_cluster_nodes(params[:cluster]))\n  end\n\n  get '/managec/:cluster/cluster_status' do\n    cluster_status_gui(session, params[:cluster])\n  end\n\n  get '/managec/:cluster/cluster_properties' do\n    cluster = params[:cluster]\n    unless cluster\n      return 200, {}\n    end\n    code, out = send_cluster_request_with_token(session, cluster, 'get_cib')\n    if code == 403\n      return [403, 'Permission denied']\n    elsif code != 200\n      return [400, 'getting CIB failed']\n    end\n    begin\n      properties = getAllSettings(nil, REXML::Document.new(out))\n      code, out = send_cluster_request_with_token(\n        session, cluster, 'get_cluster_properties_definition'\n      )\n\n      if code == 403\n        return [403, 'Permission denied']\n      elsif code == 404\n        definition = {\n          'batch-limit' => {\n            'name' => 'batch-limit',\n            'source' => 'pengine',\n            'default' => '0',\n            'type' => 'integer',\n            'shortdesc' => 'The number of jobs that pacemaker is allowed to execute in parallel.',\n            'longdesc' => 'The \"correct\" value will depend on the speed and load of your network and cluster nodes.',\n            'readable_name' => 'Batch Limit',\n            'advanced' => false\n          },\n          'no-quorum-policy' => {\n            'name' => 'no-quorum-policy',\n            'source' => 'pengine',\n            'default' => 'stop',\n            'type' => 'enum',\n            'enum' => ['stop', 'freeze', 'ignore', 'suicide'],\n            'shortdesc' => 'What to do when the cluster does not have quorum.',\n            'longdesc' => 'Allowed values:\n    * ignore - continue all resource management\n    * freeze - continue resource management, but don\\'t recover resources from nodes not in the affected partition\n    * stop - stop all resources in the affected cluster partition\n    * suicide - fence all nodes in the affected cluster partition',\n            'readable_name' => 'No Quorum Policy',\n            'advanced' => false\n          },\n          'symmetric-cluster' => {\n            'name' => 'symmetric-cluster',\n            'source' => 'pengine',\n            'default' => 'true',\n            'type' => 'boolean',\n            'shortdesc' => 'All resources can run anywhere by default.',\n            'longdesc' => 'All resources can run anywhere by default.',\n            'readable_name' => 'Symmetric',\n            'advanced' => false\n          },\n          'stonith-enabled' => {\n            'name' => 'stonith-enabled',\n            'source' => 'pengine',\n            'default' => 'true',\n            'type' => 'boolean',\n            'shortdesc' => 'Failed nodes are STONITH\\'d',\n            'longdesc' => 'Failed nodes are STONITH\\'d',\n            'readable_name' => 'Stonith Enabled',\n            'advanced' => false\n          },\n          'stonith-action' => {\n            'name' => 'stonith-action',\n            'source' => 'pengine',\n            'default' => 'reboot',\n            'type' => 'enum',\n            'enum' => ['reboot', 'poweroff', 'off'],\n            'shortdesc' => 'Action to send to STONITH device',\n            'longdesc' => 'Action to send to STONITH device Allowed values: reboot, poweroff, off',\n            'readable_name' => 'Stonith Action',\n            'advanced' => false\n          },\n          'cluster-delay' => {\n            'name' => 'cluster-delay',\n            'source' => 'pengine',\n            'default' => '60s',\n            'type' => 'time',\n            'shortdesc' => 'Round trip delay over the network (excluding action execution)',\n            'longdesc' => 'The \"correct\" value will depend on the speed and load of your network and cluster nodes.',\n            'readable_name' => 'Cluster Delay',\n            'advanced' => false\n          },\n          'stop-orphan-resources' => {\n            'name' => 'stop-orphan-resources',\n            'source' => 'pengine',\n            'default' => 'true',\n            'type' => 'boolean',\n            'shortdesc' => 'Should deleted resources be stopped',\n            'longdesc' => 'Should deleted resources be stopped',\n            'readable_name' => 'Stop Orphan Resources',\n            'advanced' => false\n          },\n          'stop-orphan-actions' => {\n            'name' => 'stop-orphan-actions',\n            'source' => 'pengine',\n            'default' => 'true',\n            'type' => 'boolean',\n            'shortdesc' => 'Should deleted actions be cancelled',\n            'longdesc' => 'Should deleted actions be cancelled',\n            'readable_name' => 'top Orphan Actions',\n            'advanced' => false\n          },\n          'start-failure-is-fatal' => {\n            'name' => 'start-failure-is-fatal',\n            'source' => 'pengine',\n            'default' => 'true',\n            'type' => 'boolean',\n            'shortdesc' => 'Always treat start failures as fatal',\n            'longdesc' => 'This was the old default. However when set to FALSE, the cluster will instead use the resource\\'s failcount and value for resource-failure-stickiness',\n            'readable_name' => 'Start Failure is Fatal',\n            'advanced' => false\n          },\n          'pe-error-series-max' => {\n            'name' => 'pe-error-series-max',\n            'source' => 'pengine',\n            'default' => '-1',\n            'type' => 'integer',\n            'shortdesc' => 'The number of PE inputs resulting in ERRORs to save',\n            'longdesc' => 'Zero to disable, -1 to store unlimited.',\n            'readable_name' => 'PE Error Storage',\n            'advanced' => false\n          },\n          'pe-warn-series-max' => {\n            'name' => 'pe-warn-series-max',\n            'source' => 'pengine',\n            'default' => '5000',\n            'type' => 'integer',\n            'shortdesc' => 'The number of PE inputs resulting in WARNINGs to save',\n            'longdesc' => 'Zero to disable, -1 to store unlimited.',\n            'readable_name' => 'PE Warning Storage',\n            'advanced' => false\n          },\n          'pe-input-series-max' => {\n            'name' => 'pe-input-series-max',\n            'source' => 'pengine',\n            'default' => '4000',\n            'type' => 'integer',\n            'shortdesc' => 'The number of other PE inputs to save',\n            'longdesc' => 'Zero to disable, -1 to store unlimited.',\n            'readable_name' => 'PE Input Storage',\n            'advanced' => false\n          },\n          'enable-acl' => {\n            'name' => 'enable-acl',\n            'source' => 'cib',\n            'default' => 'false',\n            'type' => 'boolean',\n            'shortdesc' => 'Enable CIB ACL',\n            'longdesc' => 'Should pacemaker use ACLs to determine access to cluster',\n            'readable_name' => 'Enable ACLs',\n            'advanced' => false\n          },\n        }\n      elsif code != 200\n        return [400, 'getting properties definition failed']\n      else\n        definition = JSON.parse(out)\n      end\n  \n      definition.each { |name, prop|\n        prop['value'] = properties[name]\n      }\n      return [200, JSON.generate(definition)]\n    rescue\n      return [400, 'unable to get cluster properties']\n    end\n  end\n\n  post '/managec/:cluster/fix_auth_of_cluster' do\n    clustername = params[:cluster]\n    unless clustername\n      return [400, \"cluster name not defined\"]\n    end\n\n    nodes = get_cluster_nodes(clustername)\n    tokens_data = add_prefix_to_keys(get_tokens_of_nodes(nodes), \"node:\")\n\n    retval, out = send_cluster_request_with_token(\n      PCSAuth.getSuperuserSession(), clustername, \"/save_tokens\", true,\n      tokens_data, true\n    )\n    if retval == 404\n      return [400, \"Old version of PCS/PCSD is running on cluster nodes. Fixing authentication is not supported. Use 'pcs cluster auth' command to authenticate the nodes.\"]\n    elsif retval != 200\n      return [400, \"Authentication failed.\"]\n    end\n    return [200, \"Auhentication of nodes in cluster should be fixed.\"]\n  end\n\n  post '/managec/:cluster/add_node_to_cluster' do\n    clustername = params[:cluster]\n    new_node = params[\"new_nodename\"]\n\n    if clustername == $cluster_name\n      if not allowed_for_local_cluster(session, Permissions::FULL)\n        return 403, 'Permission denied'\n      end\n    end\n\n    tokens = read_tokens\n\n    if not tokens.include? new_node\n      return [400, \"New node is not authenticated.\"]\n    end\n\n    # Save the new node token on all nodes in a cluster the new node is beeing\n    # added to. Send the token to one node and let the cluster nodes synchronize\n    # it by themselves.\n    token_data = {\"node:#{new_node}\" => tokens[new_node]}\n    retval, out = send_cluster_request_with_token(\n      # new node doesn't have config with permissions yet\n      PCSAuth.getSuperuserSession(), clustername, '/save_tokens', true, token_data\n    )\n    # If the cluster runs an old pcsd which doesn't support /save_tokens,\n    # ignore 404 in order to not prevent the node to be added.\n    if retval != 404 and retval != 200\n      return [400, 'Failed to save the token of the new node in target cluster.']\n    end\n\n    retval, out = send_cluster_request_with_token(\n      session, clustername, \"/add_node_all\", true, params\n    )\n    if 403 == retval\n      return [retval, out]\n    end\n    if retval != 200\n      return [400, \"Failed to add new node '#{new_node}' into cluster '#{clustername}': #{out}\"]\n    end\n\n    return [200, \"Node added successfully.\"]\n  end\n\n  post '/managec/:cluster/?*' do\n    raw_data = request.env[\"rack.input\"].read\n    if params[:cluster]\n      request = \"/\" + params[:splat].join(\"/\")\n      code, out = send_cluster_request_with_token(\n        session, params[:cluster], request, true, params, true, raw_data\n      )\n\n      # backward compatibility layer BEGIN\n      # This code correctly remove constraints on pcs/pcsd version 0.9.137 and older\n      redirection = {\n          \"/remove_constraint_remote\" => \"/resource_cmd/rm_constraint\",\n          \"/remove_constraint_rule_remote\" => \"/resource_cmd/rm_constraint_rule\"\n      }\n      if code == 404 and redirection.key?(request)\n        code, out = send_cluster_request_with_token(\n          session, params[:cluster], redirection[request], true, params, false,\n          raw_data\n        )\n      end\n      # bcl END\n      return code, out\n    end\n  end\n\n  get '/managec/:cluster/?*' do\n    raw_data = request.env[\"rack.input\"].read\n    if params[:cluster]\n      send_cluster_request_with_token(\n        session, params[:cluster], \"/\" + params[:splat].join(\"/\"), false, params,\n        true, raw_data\n      )\n    end\n  end\n\n  get '/' do\n    $logger.info \"Redirecting '/'...\\n\"\n    redirect '/manage'\n  end\n\n  get '/wizards/?:wizard?' do\n    return wizard(params, request, params[:wizard])\n  end\n\n  post '/wizards/?:wizard?' do\n    return wizard(params, request, params[:wizard])\n  end\n\n  get '*' do\n    $logger.debug \"Bad URL\"\n    $logger.debug params[:splat]\n    $logger.info \"Redirecting '*'...\\n\"\n    redirect '/manage'\n    redirect \"Bad URL\"\n    call(env.merge(\"PATH_INFO\" => '/nodes'))\n  end\nelse\n  get '*' do\n    $logger.debug \"ERROR: GUI Disabled, Bad URL\"\n    $logger.debug params[:splat]\n    $logger.info \"Redirecting '*'...\\n\"\n    return \"PCSD GUI is disabled\"\n  end\n\nend\n\nclass Node\n  attr_accessor :active, :id, :name, :hostname\n\n  def initialize(id=nil, name=nil, hostname=nil, active=nil)\n    @id, @name, @hostname, @active = id, name, hostname, active\n  end\nend\n\nhelpers do\n  def h(text)\n    Rack::Utils.escape_html(text)\n  end\n\n  def nl2br(text)\n    text.gsub(/\\n/, \"<br>\")\n  end\nend\n"], "fixing_code": ["require 'sinatra'\nrequire 'sinatra/reloader' if development?\nrequire 'sinatra/cookies'\nrequire 'rexml/document'\nrequire 'webrick'\nrequire 'webrick/https'\nrequire 'openssl'\nrequire 'logger'\nrequire 'thread'\n\nrequire 'bootstrap.rb'\nrequire 'resource.rb'\nrequire 'remote.rb'\nrequire 'fenceagent.rb'\nrequire 'cluster.rb'\nrequire 'config.rb'\nrequire 'pcs.rb'\nrequire 'auth.rb'\nrequire 'wizard.rb'\nrequire 'cfgsync.rb'\nrequire 'permissions.rb'\n\nDir[\"wizards/*.rb\"].each {|file| require file}\n\nuse Rack::CommonLogger\n\nset :app_file, __FILE__\n\ndef generate_cookie_secret\n  return SecureRandom.hex(30)\nend\n\nbegin\n  secret = File.read(COOKIE_FILE)\n  secret_errors = verify_cookie_secret(secret)\n  if secret_errors and not secret_errors.empty?\n    secret_errors.each { |err| $logger.error err }\n    $logger.error \"Invalid cookie secret, using temporary one\"\n    secret = generate_cookie_secret()\n  end\nrescue Errno::ENOENT\n  secret = generate_cookie_secret()\n  File.open(COOKIE_FILE, 'w', 0700) {|f| f.write(secret)}\nend\n\nuse Rack::Session::Cookie,\n  :expire_after => 60 * 60,\n  :secret => secret,\n  :secure => true, # only send over HTTPS\n  :httponly => true # don't provide to javascript\n\n#use Rack::SSL\n\nif development?\n  Dir[\"wizards/*.rb\"].each {|file| also_reload file}\n  also_reload 'resource.rb'\n  also_reload 'remote.rb'\n  also_reload 'fenceagent.rb'\n  also_reload 'cluster.rb'\n  also_reload 'config.rb'\n  also_reload 'pcs.rb'\n  also_reload 'auth.rb'\n  also_reload 'wizard.rb'\n  also_reload 'cfgsync.rb'\nend\n\nbefore do\n  if request.path != '/login' and not request.path == \"/logout\" and not request.path == '/remote/auth'\n    protected! \n  end\n  $cluster_name = get_cluster_name()\n  @errorval = session[:errorval]\n  @error = session[:error]\n  session[:errorval] = nil\n  session[:error] = nil\nend\n\nconfigure do\n  DISABLE_GUI = (ENV['DISABLE_GUI'] and ENV['DISABLE_GUI'].downcase == 'true')\n  PCS = get_pcs_path(File.expand_path(File.dirname(__FILE__)))\n  logger = File.open(\"/var/log/pcsd/pcsd.log\", \"a+\", 0600)\n  STDOUT.reopen(logger)\n  STDERR.reopen(logger)\n  STDOUT.sync = true\n  STDERR.sync = true\n  $logger = configure_logger('/var/log/pcsd/pcsd.log')\n  $semaphore_cfgsync = Mutex.new\nend\n\nset :logging, true\nset :run, false\n\n$thread_cfgsync = Thread.new {\n  while true\n    $semaphore_cfgsync.synchronize {\n      $logger.debug('Config files sync thread started')\n      if Cfgsync::ConfigSyncControl.sync_thread_allowed?()\n        begin\n          # do not sync if this host is not in a cluster\n          cluster_name = get_cluster_name()\n          if cluster_name and !cluster_name.empty?()\n            $logger.debug('Config files sync thread fetching')\n            fetcher = Cfgsync::ConfigFetcher.new(\n              PCSAuth.getSuperuserSession(), Cfgsync::get_cfg_classes(),\n              get_corosync_nodes(), cluster_name\n            )\n            cfgs_to_save, _ = fetcher.fetch()\n            cfgs_to_save.each { |cfg_to_save|\n              cfg_to_save.save()\n            }\n          end\n        rescue => e\n          $logger.warn(\"Config files sync thread exception: #{e}\")\n        end\n      end\n      $logger.debug('Config files sync thread finished')\n    }\n    sleep(Cfgsync::ConfigSyncControl.sync_thread_interval())\n  end\n}\n\nhelpers do\n  def protected!\n    gui_request = ( # these are URLs for web pages\n      request.path == '/' or\n      request.path == '/manage' or\n      request.path == '/permissions' or\n      request.path.match('/managec/.+/main')\n    )\n    if request.path.start_with?('/remote/') or request.path == '/run_pcs'\n      unless PCSAuth.loginByToken(session, cookies)\n        halt [401, '{\"notauthorized\":\"true\"}']\n      end\n    else #/managec/* /manage/* /permissions\n      if !gui_request and\n        request.env['HTTP_X_REQUESTED_WITH'] != 'XMLHttpRequest'\n      then\n        # Accept non GUI requests only with header\n        # \"X_REQUESTED_WITH: XMLHttpRequest\". (check if they are send via AJAX).\n        # This prevents CSRF attack.\n        halt [401, '{\"notauthorized\":\"true\"}']\n      elsif not PCSAuth.isLoggedIn(session)\n        if gui_request\n          session[:pre_login_path] = request.path\n          redirect '/login'\n        else\n          halt [401, '{\"notauthorized\":\"true\"}']\n        end\n      end\n    end\n  end\n\n  def getParamList(params)\n    param_line = []\n    meta_options = []\n    params.each { |param, val|\n      if param.start_with?(\"_res_paramne_\") or (param.start_with?(\"_res_paramempty_\") and val != \"\")\n        myparam = param.sub(/^_res_paramne_/,\"\").sub(/^_res_paramempty_/,\"\")\n        param_line << \"#{myparam}=#{val}\"\n      end\n      if param == \"disabled\"\n        meta_options << 'meta' << 'target-role=Stopped'\n      end\n    }\n    return param_line + meta_options\n  end\nend\n\nget '/remote/?:command?' do\n  return remote(params, request, session)\nend\n\npost '/remote/?:command?' do\n  return remote(params, request, session)\nend\n\npost '/run_pcs' do\n  command = params['command'] || '{}'\n  std_in = params['stdin'] || nil\n  begin\n    command_decoded = JSON.parse(command)\n  rescue JSON::ParserError\n    result = {\n      'status' => 'error',\n      'data' => {},\n    }\n    return JSON.pretty_generate(result)\n  end\n  # do not reveal potentialy sensitive information\n  command_decoded.delete('--debug')\n\n  allowed_commands = {\n    ['cluster', 'auth', '...'] => {\n      'only_superuser' => false,\n      'permissions' => nil,\n    },\n    # runs on the local node, check permissions\n    ['cluster', 'corosync'] => {\n      'only_superuser' => false,\n      'permissions' => Permissions::READ,\n    },\n    # runs on a remote node which checks permissions by itself\n    ['cluster', 'corosync', '...'] => {\n      'only_superuser' => false,\n      'permissions' => nil,\n    },\n    ['cluster', 'destroy', '...'] => {\n      'only_superuser' => false,\n      'permissions' => Permissions::FULL,\n    },\n    # runs on the local node, check permissions\n    ['cluster', 'disable'] => {\n      'only_superuser' => false,\n      'permissions' => Permissions::WRITE,\n    },\n    # runs on a remote node which checks permissions by itself\n    ['cluster', 'disable', '...'] => {\n      'only_superuser' => false,\n      'permissions' => nil,\n    },\n    # runs on the local node, check permissions\n    ['cluster', 'enable'] => {\n      'only_superuser' => false,\n      'permissions' => Permissions::WRITE,\n    },\n    # runs on a remote node which checks permissions by itself\n    ['cluster', 'enable', '...'] => {\n      'only_superuser' => false,\n      'permissions' => nil,\n    },\n    ['cluster', 'node', '...'] => {\n      'only_superuser' => false,\n      'permissions' => Permissions::FULL,\n    },\n    ['cluster', 'pcsd-status', '...'] => {\n      'only_superuser' => false,\n      'permissions' => nil,\n    },\n    ['cluster', 'setup', '...'] => {\n      'only_superuser' => true,\n      'permissions' => nil,\n    },\n    # runs on the local node, check permissions\n    ['cluster', 'start'] => {\n      'only_superuser' => false,\n      'permissions' => Permissions::WRITE,\n    },\n    # runs on a remote node which checks permissions by itself\n    ['cluster', 'start', '...'] => {\n      'only_superuser' => false,\n      'permissions' => nil,\n    },\n    # runs on the local node, check permissions\n    ['cluster', 'stop'] => {\n      'only_superuser' => false,\n      'permissions' => Permissions::WRITE,\n    },\n    # runs on a remote node which checks permissions by itself\n    ['cluster', 'stop', '...'] => {\n      'only_superuser' => false,\n      'permissions' => nil,\n    },\n    ['cluster', 'sync', '...'] => {\n      'only_superuser' => false,\n      'permissions' => Permissions::FULL,\n    },\n    ['config', 'restore', '...'] => {\n      'only_superuser' => false,\n      'permissions' => Permissions::FULL,\n    },\n    ['pcsd', 'sync-certificates', '...'] => {\n      'only_superuser' => false,\n      'permissions' => Permissions::FULL,\n    },\n    ['status', 'nodes', 'corosync-id', '...'] => {\n      'only_superuser' => false,\n      'permissions' => Permissions::READ,\n    },\n    ['status', 'nodes', 'pacemaker-id', '...'] => {\n      'only_superuser' => false,\n      'permissions' => Permissions::READ,\n    },\n    ['status', 'pcsd', '...'] => {\n      'only_superuser' => false,\n      'permissions' => nil,\n    },\n  }\n  allowed = false\n  command_settings = {}\n  allowed_commands.each { |cmd, cmd_settings|\n    if command_decoded == cmd \\\n      or \\\n      (cmd[-1] == '...' and cmd[0..-2] == command_decoded[0..(cmd.length - 2)])\n      then\n        allowed = true\n        command_settings = cmd_settings\n        break\n    end\n  }\n  if !allowed\n    result = {\n      'status' => 'bad_command',\n      'data' => {},\n    }\n    return JSON.pretty_generate(result)\n  end\n\n  if command_settings['only_superuser']\n    if not allowed_for_superuser(session)\n      return 403, 'Permission denied'\n    end\n  end\n  if command_settings['permissions']\n    if not allowed_for_local_cluster(session, command_settings['permissions'])\n      return 403, 'Permission denied'\n    end\n  end\n\n  options = {}\n  options['stdin'] = std_in if std_in\n  std_out, std_err, retval = run_cmd_options(\n    session, options, PCS, *command_decoded\n  )\n  result = {\n    'status' => 'ok',\n    'data' => {\n      'stdout' => std_out.join(\"\"),\n      'stderr' => std_err.join(\"\"),\n      'code' => retval,\n    },\n  }\n  return JSON.pretty_generate(result)\nend\n\nif not DISABLE_GUI\n  get('/login'){ erb :login, :layout => :main }\n\n  get '/logout' do \n    session.clear\n    erb :login, :layout => :main\n  end\n\n  post '/login' do\n    if PCSAuth.loginByPassword(session, params['username'], params['password'])\n      # Temporarily ignore pre_login_path until we come up with a list of valid\n      # paths to redirect to (to prevent status_all issues)\n      #    if session[\"pre_login_path\"]\n      #      plp = session[\"pre_login_path\"]\n      #      session.delete(\"pre_login_path\")\n      #      pp \"Pre Login Path: \" + plp\n      #      if plp == \"\" or plp == \"/\"\n      #        plp = '/manage'\n      #      end\n      #      redirect plp\n      #    else\n      redirect '/manage'\n      #    end\n    else\n      session[\"bad_login_name\"] = params['username']\n      redirect '/login?badlogin=1'\n    end\n  end\n\n  post '/manage/existingcluster' do\n    pcs_config = PCSConfig.new(Cfgsync::PcsdSettings.from_file('{}').text())\n    node = params['node-name']\n    code, result = send_request_with_token(\n      PCSAuth.getSuperuserSession(), node, 'status'\n    )\n    begin\n      status = JSON.parse(result)\n    rescue JSON::ParserError\n      return 400, \"Unable to communicate with remote pcsd on node '#{node}'.\"\n    end\n\n    warning_messages = []\n\n    if status.has_key?(\"corosync_offline\") and\n      status.has_key?(\"corosync_online\") then\n      nodes = status[\"corosync_offline\"] + status[\"corosync_online\"]\n\n      if status[\"cluster_name\"] == ''\n        return 400, \"The node, '#{noname}', does not currently have a cluster\n configured.  You must create a cluster using this node before adding it to pcsd.\"\n      end\n\n      if pcs_config.is_cluster_name_in_use(status[\"cluster_name\"])\n        return 400, \"The cluster name, '#{status['cluster_name']}' has\nalready been added to pcsd.  You may not add two clusters with the same name into pcsd.\"\n      end\n\n      # auth begin\n      retval, out = send_request_with_token(\n        PCSAuth.getSuperuserSession(), node, '/get_cluster_tokens'\n      )\n      if retval == 404 # backward compatibility layer\n        warning_messages << \"Unable to do correct authentication of cluster because it is running old version of pcs/pcsd.\"\n      else\n        if retval != 200\n          return 400, \"Unable to get authentication info from cluster '#{status['cluster_name']}'.\"\n        end\n        begin\n          new_tokens = JSON.parse(out)\n        rescue\n          return 400, \"Unable to get authentication info from cluster '#{status['cluster_name']}'.\"\n        end\n\n        sync_config = Cfgsync::PcsdTokens.from_file('')\n        pushed, _ = Cfgsync::save_sync_new_tokens(\n          sync_config, new_tokens, get_corosync_nodes(), $cluster_name\n        )\n        if not pushed\n          return 400, \"Configuration conflict detected.\\n\\nSome nodes had a newer configuration than the local node. Local node's configuration was updated.  Please repeat the last action if appropriate.\"\n        end\n      end\n      #auth end\n\n      pcs_config.clusters << Cluster.new(status[\"cluster_name\"], nodes)\n\n      sync_config = Cfgsync::PcsdSettings.from_text(pcs_config.text())\n      pushed, _ = Cfgsync::save_sync_new_version(\n        sync_config, get_corosync_nodes(), $cluster_name, true\n      )\n      if not pushed\n        return 400, \"Configuration conflict detected.\\n\\nSome nodes had a newer configuration than the local node. Local node's configuration was updated.  Please repeat the last action if appropriate.\"\n      end\n      return 200, warning_messages.join(\"\\n\\n\")\n    else\n      return 400, \"Unable to communicate with remote pcsd on node '#{node}'.\"\n    end\n  end\n\n  post '/manage/newcluster' do\n    if not allowed_for_superuser(session)\n      return 400, 'Permission denied.'\n    end\n\n    warning_messages = []\n\n    pcs_config = PCSConfig.new(Cfgsync::PcsdSettings.from_file('{}').text())\n    @manage = true\n    @cluster_name = params[:clustername]\n    @nodes = []\n    nodes_with_indexes = []\n    @nodes_rrp = []\n    options = {}\n    params.each {|k,v|\n      if k.start_with?(\"node-\") and v != \"\"\n        @nodes << v\n        nodes_with_indexes << [k[5..-1].to_i, v]\n        if params.has_key?(\"ring1-\" + k) and params[\"ring1-\" + k] != \"\"\n          @nodes_rrp << v + \",\" + params[\"ring1-\" + k]\n        else\n          @nodes_rrp << v\n        end\n      end\n      if k.start_with?(\"config-\") and v != \"\"\n        options[k.sub(\"config-\",\"\")] = v\n      end\n    }\n    if pcs_config.is_cluster_name_in_use(@cluster_name)\n      return 400, \"The cluster name, '#{@cluster_name}' has already been added to pcsd.  You may not add two clusters with the same name into pcsd.\"\n    end\n\n    @nodes.each {|n|\n      if pcs_config.is_node_in_use(n)\n        return 400, \"The node, '#{n}' is already configured in pcsd.  You may not add a node to two different clusters in pcsd.\"\n      end\n    }\n\n    # first we need to authenticate nodes to each other\n    tokens = add_prefix_to_keys(get_tokens_of_nodes(@nodes), \"node:\")\n    @nodes.each {|n|\n      retval, out = send_request_with_token(\n        session, n, \"/save_tokens\", true, tokens\n      )\n      if retval == 404 # backward compatibility layer\n        warning_messages << \"Unable to do correct authentication of cluster on node '#{n}', because it is running old version of pcs/pcsd.\"\n        break\n      elsif retval != 200\n        return 400, \"Unable to authenticate all nodes on node '#{n}'.\"\n      end\n    }\n\n    # the first node from the form is the source of config files\n    node_to_send_to = nodes_with_indexes.sort[0][1]\n    $logger.info(\n      \"Sending setup cluster request for: #{@cluster_name} to: #{node_to_send_to}\"\n    )\n    code,out = send_request_with_token(\n      session,\n      node_to_send_to,\n      'setup_cluster',\n      true,\n      {\n        :clustername => @cluster_name,\n        :nodes => @nodes_rrp.join(';'),\n        :options => options.to_json\n      },\n      true,\n      nil,\n      60\n    )\n\n    if code == 200\n      pushed = false\n      2.times {\n        # Add the new cluster to config and publish the config.\n        # If this host is a node of the cluster, some other node may send its\n        # own PcsdSettings.  To handle it we just need to reload the config, as\n        # we are waiting for the request to finish, so no locking is needed.\n        # If we are in a different cluster we just try twice to update the\n        # config, dealing with any updates in between.\n        pcs_config = PCSConfig.new(Cfgsync::PcsdSettings.from_file('{}').text())\n        pcs_config.clusters << Cluster.new(@cluster_name, @nodes)\n        sync_config = Cfgsync::PcsdSettings.from_text(pcs_config.text())\n        pushed, _ = Cfgsync::save_sync_new_version(\n          sync_config, get_corosync_nodes(), $cluster_name, true\n        )\n        break if pushed\n      }\n      if not pushed\n        return 400, \"Configuration conflict detected.\\n\\nSome nodes had a newer configuration than the local node. Local node's configuration was updated.  Please repeat the last action if appropriate.\"\n      end\n    else\n      return 400, \"Unable to create new cluster. If cluster already exists on one or more of the nodes run 'pcs cluster destroy' on all nodes to remove current cluster configuration.\\n\\n#{node_to_send_to}: #{out}\"\n    end\n\n    return warning_messages.join(\"\\n\\n\")\n  end\n\n  post '/manage/removecluster' do\n    pcs_config = PCSConfig.new(Cfgsync::PcsdSettings.from_file('{}').text())\n    params.each { |k,v|\n      if k.start_with?(\"clusterid-\")\n        pcs_config.remove_cluster(k.sub(\"clusterid-\",\"\"))\n      end\n    }\n    sync_config = Cfgsync::PcsdSettings.from_text(pcs_config.text())\n    pushed, _ = Cfgsync::save_sync_new_version(\n      sync_config, get_corosync_nodes(), $cluster_name, true\n    )\n    if not pushed\n      return 400, \"Configuration conflict detected.\\n\\nSome nodes had a newer configuration than the local node.  Local node's configuration was updated.  Please repeat the last action if appropriate.\"\n    end\n  end\n\n  get '/manage/check_pcsd_status' do\n    node_results = {}\n    if params[:nodes] != nil and params[:nodes] != ''\n      node_array = params[:nodes].split(',')\n      online, offline, notauthorized = check_gui_status_of_nodes(\n        session, node_array\n      )\n      online.each { |node|\n        node_results[node] = 'Online'\n      }\n      offline.each { |node|\n        node_results[node] = 'Offline'\n      }\n      notauthorized.each { |node|\n        node_results[node] = 'Unable to authenticate'\n      }\n    end\n    return JSON.generate(node_results)\n  end\n\n  get '/manage/get_nodes_sw_versions' do\n    if params[:nodes] != nil and params[:nodes] != ''\n      nodes = params[:nodes].split(',')\n      final_response = {}\n      threads = []\n      nodes.each {|node|\n        threads << Thread.new {\n          code, response = send_request_with_token(\n            session, node, 'get_sw_versions'\n          )\n          begin\n            node_response = JSON.parse(response)\n            if node_response and node_response['notoken'] == true\n              $logger.error(\"ERROR: bad token for #{node}\")\n            end\n            final_response[node] = node_response\n          rescue JSON::ParserError => e\n          end\n        }\n      }\n      threads.each { |t| t.join }\n      return JSON.generate(final_response)\n    end\n    return '{}'\n  end\n\n  post '/manage/auth_gui_against_nodes' do\n    node_auth_error = {}\n    new_tokens = {}\n    threads = []\n    params.each { |node|\n      threads << Thread.new {\n        if node[0].end_with?(\"-pass\") and node[0].length > 5\n          nodename = node[0][0..-6]\n          if params.has_key?(\"all\")\n            pass = params[\"pass-all\"]\n          else\n            pass = node[1]\n          end\n          data = {\n            'node-0' => nodename,\n            'username' => SUPERUSER,\n            'password' => pass,\n            'force' => 1,\n          }\n          node_auth_error[nodename] = 1\n          code, response = send_request(session, nodename, 'auth', true, data)\n          if 200 == code\n            token = response.strip\n            if not token.empty?\n              new_tokens[nodename] = token\n              node_auth_error[nodename] = 0\n            end\n          end\n        end\n      }\n    }\n    threads.each { |t| t.join }\n\n    if not new_tokens.empty?\n      cluster_nodes = get_corosync_nodes()\n      tokens_cfg = Cfgsync::PcsdTokens.from_file('')\n      sync_successful, sync_responses = Cfgsync::save_sync_new_tokens(\n        tokens_cfg, new_tokens, cluster_nodes, $cluster_name\n      )\n    end\n\n    return [200, JSON.generate({'node_auth_error' => node_auth_error})]\n  end\n\n  get '/manage/?' do\n    @manage = true\n    erb :manage, :layout => :main\n  end\n\n  get '/clusters_overview' do\n    clusters_overview(params, request, session)\n  end\n\n  get '/permissions/?' do\n    @manage = true\n    pcs_config = PCSConfig.new(Cfgsync::PcsdSettings.from_file('{}').text())\n    @clusters = pcs_config.clusters.sort { |a, b| a.name <=> b.name }\n    erb :permissions, :layout => :main\n  end\n\n  get '/permissions_cluster_form/:cluster/?' do\n    @cluster_name = params[:cluster]\n    @error = nil\n    @permission_types = []\n    @permissions_dependencies = {}\n    @user_types = []\n    @users_permissions = []\n\n    pcs_config = PCSConfig.new(Cfgsync::PcsdSettings.from_file('{}').text())\n\n    if not pcs_config.is_cluster_name_in_use(@cluster_name)\n      @error = 'Cluster not found'\n    else\n      code, data = send_cluster_request_with_token(\n        session, @cluster_name, 'get_permissions'\n      )\n      if 404 == code\n        @error = 'Cluster is running an old version of pcsd which does not support permissions'\n      elsif 403 == code\n        @error = 'Permission denied'\n      elsif 200 != code\n        @error = 'Unable to load permissions of the cluster'\n      else\n        begin\n          permissions = JSON.parse(data)\n          if permissions['notoken'] or permissions['noresponse']\n            @error = 'Unable to load permissions of the cluster'\n          else\n            @permission_types = permissions['permission_types'] || []\n            @permissions_dependencies = permissions['permissions_dependencies'] || {}\n            @user_types = permissions['user_types'] || []\n            @users_permissions = permissions['users_permissions'] || []\n          end\n        rescue JSON::ParserError\n          @error = 'Unable to read permissions of the cluster'\n        end\n      end\n    end\n    erb :_permissions_cluster\n  end\n\n  get '/managec/:cluster/main' do\n    @cluster_name = params[:cluster]\n    pcs_config = PCSConfig.new(Cfgsync::PcsdSettings.from_file('{}').text())\n    @clusters = pcs_config.clusters\n    @nodes = get_cluster_nodes(params[:cluster])\n    if @nodes == []\n      redirect '/manage/'\n    end\n    @resource_agents = get_resource_agents_avail(session)\n    @stonith_agents = get_stonith_agents_avail(session)\n    erb :nodes, :layout => :main\n  end\n\n  post '/managec/:cluster/permissions_save/?' do\n    new_params = {\n      'json_data' => JSON.generate(params)\n    }\n    return send_cluster_request_with_token(\n      session, params[:cluster], \"set_permissions\", true, new_params\n    )\n  end\n\n  get '/managec/:cluster/status_all' do\n    status_all(params, request, session, get_cluster_nodes(params[:cluster]))\n  end\n\n  get '/managec/:cluster/cluster_status' do\n    cluster_status_gui(session, params[:cluster])\n  end\n\n  get '/managec/:cluster/cluster_properties' do\n    cluster = params[:cluster]\n    unless cluster\n      return 200, {}\n    end\n    code, out = send_cluster_request_with_token(session, cluster, 'get_cib')\n    if code == 403\n      return [403, 'Permission denied']\n    elsif code != 200\n      return [400, 'getting CIB failed']\n    end\n    begin\n      properties = getAllSettings(nil, REXML::Document.new(out))\n      code, out = send_cluster_request_with_token(\n        session, cluster, 'get_cluster_properties_definition'\n      )\n\n      if code == 403\n        return [403, 'Permission denied']\n      elsif code == 404\n        definition = {\n          'batch-limit' => {\n            'name' => 'batch-limit',\n            'source' => 'pengine',\n            'default' => '0',\n            'type' => 'integer',\n            'shortdesc' => 'The number of jobs that pacemaker is allowed to execute in parallel.',\n            'longdesc' => 'The \"correct\" value will depend on the speed and load of your network and cluster nodes.',\n            'readable_name' => 'Batch Limit',\n            'advanced' => false\n          },\n          'no-quorum-policy' => {\n            'name' => 'no-quorum-policy',\n            'source' => 'pengine',\n            'default' => 'stop',\n            'type' => 'enum',\n            'enum' => ['stop', 'freeze', 'ignore', 'suicide'],\n            'shortdesc' => 'What to do when the cluster does not have quorum.',\n            'longdesc' => 'Allowed values:\n    * ignore - continue all resource management\n    * freeze - continue resource management, but don\\'t recover resources from nodes not in the affected partition\n    * stop - stop all resources in the affected cluster partition\n    * suicide - fence all nodes in the affected cluster partition',\n            'readable_name' => 'No Quorum Policy',\n            'advanced' => false\n          },\n          'symmetric-cluster' => {\n            'name' => 'symmetric-cluster',\n            'source' => 'pengine',\n            'default' => 'true',\n            'type' => 'boolean',\n            'shortdesc' => 'All resources can run anywhere by default.',\n            'longdesc' => 'All resources can run anywhere by default.',\n            'readable_name' => 'Symmetric',\n            'advanced' => false\n          },\n          'stonith-enabled' => {\n            'name' => 'stonith-enabled',\n            'source' => 'pengine',\n            'default' => 'true',\n            'type' => 'boolean',\n            'shortdesc' => 'Failed nodes are STONITH\\'d',\n            'longdesc' => 'Failed nodes are STONITH\\'d',\n            'readable_name' => 'Stonith Enabled',\n            'advanced' => false\n          },\n          'stonith-action' => {\n            'name' => 'stonith-action',\n            'source' => 'pengine',\n            'default' => 'reboot',\n            'type' => 'enum',\n            'enum' => ['reboot', 'poweroff', 'off'],\n            'shortdesc' => 'Action to send to STONITH device',\n            'longdesc' => 'Action to send to STONITH device Allowed values: reboot, poweroff, off',\n            'readable_name' => 'Stonith Action',\n            'advanced' => false\n          },\n          'cluster-delay' => {\n            'name' => 'cluster-delay',\n            'source' => 'pengine',\n            'default' => '60s',\n            'type' => 'time',\n            'shortdesc' => 'Round trip delay over the network (excluding action execution)',\n            'longdesc' => 'The \"correct\" value will depend on the speed and load of your network and cluster nodes.',\n            'readable_name' => 'Cluster Delay',\n            'advanced' => false\n          },\n          'stop-orphan-resources' => {\n            'name' => 'stop-orphan-resources',\n            'source' => 'pengine',\n            'default' => 'true',\n            'type' => 'boolean',\n            'shortdesc' => 'Should deleted resources be stopped',\n            'longdesc' => 'Should deleted resources be stopped',\n            'readable_name' => 'Stop Orphan Resources',\n            'advanced' => false\n          },\n          'stop-orphan-actions' => {\n            'name' => 'stop-orphan-actions',\n            'source' => 'pengine',\n            'default' => 'true',\n            'type' => 'boolean',\n            'shortdesc' => 'Should deleted actions be cancelled',\n            'longdesc' => 'Should deleted actions be cancelled',\n            'readable_name' => 'top Orphan Actions',\n            'advanced' => false\n          },\n          'start-failure-is-fatal' => {\n            'name' => 'start-failure-is-fatal',\n            'source' => 'pengine',\n            'default' => 'true',\n            'type' => 'boolean',\n            'shortdesc' => 'Always treat start failures as fatal',\n            'longdesc' => 'This was the old default. However when set to FALSE, the cluster will instead use the resource\\'s failcount and value for resource-failure-stickiness',\n            'readable_name' => 'Start Failure is Fatal',\n            'advanced' => false\n          },\n          'pe-error-series-max' => {\n            'name' => 'pe-error-series-max',\n            'source' => 'pengine',\n            'default' => '-1',\n            'type' => 'integer',\n            'shortdesc' => 'The number of PE inputs resulting in ERRORs to save',\n            'longdesc' => 'Zero to disable, -1 to store unlimited.',\n            'readable_name' => 'PE Error Storage',\n            'advanced' => false\n          },\n          'pe-warn-series-max' => {\n            'name' => 'pe-warn-series-max',\n            'source' => 'pengine',\n            'default' => '5000',\n            'type' => 'integer',\n            'shortdesc' => 'The number of PE inputs resulting in WARNINGs to save',\n            'longdesc' => 'Zero to disable, -1 to store unlimited.',\n            'readable_name' => 'PE Warning Storage',\n            'advanced' => false\n          },\n          'pe-input-series-max' => {\n            'name' => 'pe-input-series-max',\n            'source' => 'pengine',\n            'default' => '4000',\n            'type' => 'integer',\n            'shortdesc' => 'The number of other PE inputs to save',\n            'longdesc' => 'Zero to disable, -1 to store unlimited.',\n            'readable_name' => 'PE Input Storage',\n            'advanced' => false\n          },\n          'enable-acl' => {\n            'name' => 'enable-acl',\n            'source' => 'cib',\n            'default' => 'false',\n            'type' => 'boolean',\n            'shortdesc' => 'Enable CIB ACL',\n            'longdesc' => 'Should pacemaker use ACLs to determine access to cluster',\n            'readable_name' => 'Enable ACLs',\n            'advanced' => false\n          },\n        }\n      elsif code != 200\n        return [400, 'getting properties definition failed']\n      else\n        definition = JSON.parse(out)\n      end\n  \n      definition.each { |name, prop|\n        prop['value'] = properties[name]\n      }\n      return [200, JSON.generate(definition)]\n    rescue\n      return [400, 'unable to get cluster properties']\n    end\n  end\n\n  post '/managec/:cluster/fix_auth_of_cluster' do\n    clustername = params[:cluster]\n    unless clustername\n      return [400, \"cluster name not defined\"]\n    end\n\n    nodes = get_cluster_nodes(clustername)\n    tokens_data = add_prefix_to_keys(get_tokens_of_nodes(nodes), \"node:\")\n\n    retval, out = send_cluster_request_with_token(\n      PCSAuth.getSuperuserSession(), clustername, \"/save_tokens\", true,\n      tokens_data, true\n    )\n    if retval == 404\n      return [400, \"Old version of PCS/PCSD is running on cluster nodes. Fixing authentication is not supported. Use 'pcs cluster auth' command to authenticate the nodes.\"]\n    elsif retval != 200\n      return [400, \"Authentication failed.\"]\n    end\n    return [200, \"Auhentication of nodes in cluster should be fixed.\"]\n  end\n\n  post '/managec/:cluster/add_node_to_cluster' do\n    clustername = params[:cluster]\n    new_node = params[\"new_nodename\"]\n\n    if clustername == $cluster_name\n      if not allowed_for_local_cluster(session, Permissions::FULL)\n        return 403, 'Permission denied'\n      end\n    end\n\n    tokens = read_tokens\n\n    if not tokens.include? new_node\n      return [400, \"New node is not authenticated.\"]\n    end\n\n    # Save the new node token on all nodes in a cluster the new node is beeing\n    # added to. Send the token to one node and let the cluster nodes synchronize\n    # it by themselves.\n    token_data = {\"node:#{new_node}\" => tokens[new_node]}\n    retval, out = send_cluster_request_with_token(\n      # new node doesn't have config with permissions yet\n      PCSAuth.getSuperuserSession(), clustername, '/save_tokens', true, token_data\n    )\n    # If the cluster runs an old pcsd which doesn't support /save_tokens,\n    # ignore 404 in order to not prevent the node to be added.\n    if retval != 404 and retval != 200\n      return [400, 'Failed to save the token of the new node in target cluster.']\n    end\n\n    retval, out = send_cluster_request_with_token(\n      session, clustername, \"/add_node_all\", true, params\n    )\n    if 403 == retval\n      return [retval, out]\n    end\n    if retval != 200\n      return [400, \"Failed to add new node '#{new_node}' into cluster '#{clustername}': #{out}\"]\n    end\n\n    return [200, \"Node added successfully.\"]\n  end\n\n  post '/managec/:cluster/?*' do\n    raw_data = request.env[\"rack.input\"].read\n    if params[:cluster]\n      request = \"/\" + params[:splat].join(\"/\")\n      code, out = send_cluster_request_with_token(\n        session, params[:cluster], request, true, params, true, raw_data\n      )\n\n      # backward compatibility layer BEGIN\n      # This code correctly remove constraints on pcs/pcsd version 0.9.137 and older\n      redirection = {\n          \"/remove_constraint_remote\" => \"/resource_cmd/rm_constraint\",\n          \"/remove_constraint_rule_remote\" => \"/resource_cmd/rm_constraint_rule\"\n      }\n      if code == 404 and redirection.key?(request)\n        code, out = send_cluster_request_with_token(\n          session, params[:cluster], redirection[request], true, params, false,\n          raw_data\n        )\n      end\n      # bcl END\n      return code, out\n    end\n  end\n\n  get '/managec/:cluster/?*' do\n    raw_data = request.env[\"rack.input\"].read\n    if params[:cluster]\n      send_cluster_request_with_token(\n        session, params[:cluster], \"/\" + params[:splat].join(\"/\"), false, params,\n        true, raw_data\n      )\n    end\n  end\n\n  get '/' do\n    $logger.info \"Redirecting '/'...\\n\"\n    redirect '/manage'\n  end\n\n  get '/wizards/?:wizard?' do\n    return wizard(params, request, params[:wizard])\n  end\n\n  post '/wizards/?:wizard?' do\n    return wizard(params, request, params[:wizard])\n  end\n\n  get '*' do\n    $logger.debug \"Bad URL\"\n    $logger.debug params[:splat]\n    $logger.info \"Redirecting '*'...\\n\"\n    redirect '/manage'\n    redirect \"Bad URL\"\n    call(env.merge(\"PATH_INFO\" => '/nodes'))\n  end\nelse\n  get '*' do\n    $logger.debug \"ERROR: GUI Disabled, Bad URL\"\n    $logger.debug params[:splat]\n    $logger.info \"Redirecting '*'...\\n\"\n    return \"PCSD GUI is disabled\"\n  end\n\nend\n\nclass Node\n  attr_accessor :active, :id, :name, :hostname\n\n  def initialize(id=nil, name=nil, hostname=nil, active=nil)\n    @id, @name, @hostname, @active = id, name, hostname, active\n  end\nend\n\nhelpers do\n  def h(text)\n    Rack::Utils.escape_html(text)\n  end\n\n  def nl2br(text)\n    text.gsub(/\\n/, \"<br>\")\n  end\nend\n"], "filenames": ["pcsd/pcsd.rb"], "buggy_code_start_loc": [124], "buggy_code_end_loc": [144], "fixing_code_start_loc": [124], "fixing_code_end_loc": [149], "type": "CWE-352", "message": "Cross-site request forgery (CSRF) vulnerability in pcsd web UI in pcs before 0.9.149.", "other": {"cve": {"id": "CVE-2016-0720", "sourceIdentifier": "secalert@redhat.com", "published": "2017-04-21T15:59:00.160", "lastModified": "2023-02-12T23:15:50.460", "vulnStatus": "Modified", "descriptions": [{"lang": "en", "value": "Cross-site request forgery (CSRF) vulnerability in pcsd web UI in pcs before 0.9.149."}, {"lang": "es", "value": "Vulnerabilidad de CSRF en pcsd web UI en pcs en versiones anteriores a 0.9.149."}], "metrics": {"cvssMetricV30": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.0", "vectorString": "CVSS:3.0/AV:N/AC:L/PR:N/UI:R/S:U/C:H/I:H/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "REQUIRED", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "HIGH", "availabilityImpact": "HIGH", "baseScore": 8.8, "baseSeverity": "HIGH"}, "exploitabilityScore": 2.8, "impactScore": 5.9}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:N/AC:M/Au:N/C:P/I:P/A:P", "accessVector": "NETWORK", "accessComplexity": "MEDIUM", "authentication": "NONE", "confidentialityImpact": "PARTIAL", "integrityImpact": "PARTIAL", "availabilityImpact": "PARTIAL", "baseScore": 6.8}, "baseSeverity": "MEDIUM", "exploitabilityScore": 8.6, "impactScore": 6.4, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-352"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:clusterlabs:pcs:*:*:*:*:*:*:*:*", "versionEndIncluding": "0.9.148", "matchCriteriaId": "02E79037-88A8-4B67-A0D9-983CB3EC41A0"}]}]}, {"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:fedoraproject:fedora:22:*:*:*:*:*:*:*", "matchCriteriaId": "253C303A-E577-4488-93E6-68A8DD942C38"}, {"vulnerable": true, "criteria": "cpe:2.3:o:fedoraproject:fedora:23:*:*:*:*:*:*:*", "matchCriteriaId": "E79AB8DD-C907-4038-A931-1A5A4CFB6A5B"}, {"vulnerable": true, "criteria": "cpe:2.3:o:redhat:enterprise_linux:7.0:*:*:*:*:*:*:*", "matchCriteriaId": "142AD0DD-4CF3-4D74-9442-459CE3347E3A"}]}]}], "references": [{"url": "http://lists.fedoraproject.org/pipermail/package-announce/2016-March/178261.html", "source": "secalert@redhat.com", "tags": ["Third Party Advisory"]}, {"url": "http://lists.fedoraproject.org/pipermail/package-announce/2016-March/178384.html", "source": "secalert@redhat.com", "tags": ["Third Party Advisory"]}, {"url": "http://rhn.redhat.com/errata/RHSA-2016-2596.html", "source": "secalert@redhat.com", "tags": ["Third Party Advisory"]}, {"url": "http://www.securityfocus.com/bid/97984", "source": "secalert@redhat.com", "tags": ["Third Party Advisory", "VDB Entry"]}, {"url": "https://bugzilla.redhat.com/show_bug.cgi?id=1299614", "source": "secalert@redhat.com", "tags": ["Issue Tracking", "Third Party Advisory"]}, {"url": "https://github.com/ClusterLabs/pcs/commit/b9e7f061788c3b86a0c67d2d4158f067ec5eb625", "source": "secalert@redhat.com", "tags": ["Issue Tracking", "Patch"]}]}, "github_commit_url": "https://github.com/ClusterLabs/pcs/commit/b9e7f061788c3b86a0c67d2d4158f067ec5eb625"}}
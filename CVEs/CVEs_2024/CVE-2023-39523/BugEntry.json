{"buggy_code": ["# SPDX-License-Identifier: Apache-2.0\n#\n# http://nexb.com and https://github.com/nexB/scancode.io\n# The ScanCode.io software is licensed under the Apache License version 2.0.\n# Data generated with ScanCode.io is provided as-is without warranties.\n# ScanCode is a trademark of nexB Inc.\n#\n# You may not use this software except in compliance with the License.\n# You may obtain a copy of the License at: http://apache.org/licenses/LICENSE-2.0\n# Unless required by applicable law or agreed to in writing, software distributed\n# under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR\n# CONDITIONS OF ANY KIND, either express or implied. See the License for the\n# specific language governing permissions and limitations under the License.\n#\n# Data Generated with ScanCode.io is provided on an \"AS IS\" BASIS, WITHOUT WARRANTIES\n# OR CONDITIONS OF ANY KIND, either express or implied. No content created from\n# ScanCode.io should be considered or used as legal advice. Consult an Attorney\n# for any legal advice.\n#\n# ScanCode.io is a free software code scanning tool from nexB Inc. and others.\n# Visit https://github.com/nexB/scancode.io for support and download.\n\nimport difflib\nimport logging\nimport subprocess\nimport sys\nimport uuid\nfrom contextlib import suppress\nfrom datetime import datetime\nfrom pathlib import Path\nfrom time import sleep\nfrom timeit import default_timer as timer\n\nfrom django.db.models import Count\n\nfrom scanpipe import humanize_time\nfrom scanpipe.models import CodebaseRelation\nfrom scanpipe.models import CodebaseResource\nfrom scanpipe.models import DiscoveredDependency\nfrom scanpipe.models import DiscoveredPackage\nfrom scanpipe.pipes import scancode\n\nlogger = logging.getLogger(\"scanpipe.pipes\")\n\n\ndef make_codebase_resource(project, location, save=True, **extra_fields):\n    \"\"\"\n    Create a CodebaseResource instance in the database for the given ``project``.\n\n    The provided ``location`` is the absolute path of this resource.\n    It must be rooted in `project.codebase_path` as only the relative path within the\n    project codebase/ directory is stored in the database.\n\n    Extra fields can be provided as keywords arguments to this function call::\n\n        make_codebase_resource(\n            project=project,\n            location=resource.location,\n            rootfs_path=resource.path,\n            tag=layer_tag,\n        )\n\n    In this example, ``rootfs_path`` is an optional path relative to a rootfs root\n    within an Image/VM filesystem context. e.g.: \"/var/log/file.log\"\n\n    All paths use the POSIX separators.\n\n    If a CodebaseResource already exists in the ``project`` with the same path,\n    the error raised on save() is not stored in the database and the creation is\n    skipped.\n    \"\"\"\n    relative_path = Path(location).relative_to(project.codebase_path)\n    resource_data = scancode.get_resource_info(location=str(location))\n\n    if extra_fields:\n        resource_data.update(**extra_fields)\n\n    codebase_resource = CodebaseResource(\n        project=project,\n        path=relative_path,\n        **resource_data,\n    )\n\n    if save:\n        codebase_resource.save(save_error=False)\n    return codebase_resource\n\n\ndef update_or_create_resource(project, resource_data):\n    \"\"\"Get, update or create a CodebaseResource then return it.\"\"\"\n    for_packages = resource_data.pop(\"for_packages\", None) or []\n\n    resource = CodebaseResource.objects.get_or_none(\n        project=project,\n        path=resource_data.get(\"path\"),\n    )\n\n    if resource:\n        resource.update_from_data(resource_data)\n    else:\n        resource = CodebaseResource.create_from_data(project, resource_data)\n\n    for package_uid in for_packages:\n        package = project.discoveredpackages.get(package_uid=package_uid)\n        resource.add_package(package)\n\n    return resource\n\n\ndef _clean_package_data(package_data):\n    \"\"\"Clean provided `package_data` to make it compatible with the model.\"\"\"\n    package_data = package_data.copy()\n    if release_date := package_data.get(\"release_date\"):\n        if type(release_date) is str:\n            if release_date.endswith(\"Z\"):\n                release_date = release_date[:-1]\n            package_data[\"release_date\"] = datetime.fromisoformat(release_date).date()\n    return package_data\n\n\ndef update_or_create_package(project, package_data, codebase_resources=None):\n    \"\"\"\n    Get, update or create a DiscoveredPackage then return it.\n    Use the `project` and `package_data` mapping to lookup and creates the\n    DiscoveredPackage using its Package URL and package_uid as a unique key.\n    The package can be associated to `codebase_resources` providing a list or queryset\n    of resources.\n    \"\"\"\n    purl_data = DiscoveredPackage.extract_purl_data(package_data)\n    package_data = _clean_package_data(package_data)\n    # No values for package_uid requires to be empty string for proper queryset lookup\n    package_uid = package_data.get(\"package_uid\") or \"\"\n\n    package = DiscoveredPackage.objects.get_or_none(\n        project=project,\n        package_uid=package_uid,\n        **purl_data,\n    )\n\n    if package:\n        package.update_from_data(package_data)\n    else:\n        package = DiscoveredPackage.create_from_data(project, package_data)\n\n    if codebase_resources:\n        package.add_resources(codebase_resources)\n\n    return package\n\n\ndef update_or_create_dependency(\n    project, dependency_data, for_package=None, strip_datafile_path_root=False\n):\n    \"\"\"\n    Get, update or create a DiscoveredDependency then returns it.\n    Use the `project` and `dependency_data` mapping to lookup and creates the\n    DiscoveredDependency using its dependency_uid and for_package_uid as a unique key.\n\n    If `strip_datafile_path_root` is True, then\n    `DiscoveredDependency.create_from_data()` will strip the root path segment\n    from the `datafile_path` of `dependency_data` before looking up the\n    corresponding CodebaseResource for `datafile_path`. This is used in the case\n    where Dependency data is imported from a scancode-toolkit scan, where the\n    root path segments are not stripped for `datafile_path`.\n    \"\"\"\n    dependency = None\n    dependency_uid = dependency_data.get(\"dependency_uid\")\n\n    if not dependency_uid:\n        dependency_data[\"dependency_uid\"] = uuid.uuid4()\n    else:\n        dependency = project.discovereddependencies.get_or_none(\n            dependency_uid=dependency_uid,\n        )\n\n    if dependency:\n        dependency.update_from_data(dependency_data)\n    else:\n        dependency = DiscoveredDependency.create_from_data(\n            project,\n            dependency_data,\n            for_package=for_package,\n            strip_datafile_path_root=strip_datafile_path_root,\n        )\n\n    return dependency\n\n\ndef get_or_create_relation(project, relation_data):\n    \"\"\"\n    Get  or create a CodebaseRelation then return it.\n    The support for update is not useful as there is no fields on the model that\n    could be updated.\n    \"\"\"\n    from_resource_path = relation_data.get(\"from_resource\")\n    to_resource_path = relation_data.get(\"to_resource\")\n    resource_qs = project.codebaseresources\n\n    codebase_relation, _ = CodebaseRelation.objects.get_or_create(\n        project=project,\n        from_resource=resource_qs.get(path=from_resource_path),\n        to_resource=resource_qs.get(path=to_resource_path),\n        map_type=relation_data.get(\"map_type\"),\n    )\n\n    return codebase_relation\n\n\ndef make_relation(from_resource, to_resource, map_type, **extra_fields):\n    return CodebaseRelation.objects.create(\n        project=from_resource.project,\n        from_resource=from_resource,\n        to_resource=to_resource,\n        map_type=map_type,\n        **extra_fields,\n    )\n\n\ndef normalize_path(path):\n    \"\"\"Return a normalized path from a `path` string.\"\"\"\n    return \"/\" + path.strip(\"/\")\n\n\ndef strip_root(location):\n    \"\"\"Return the provided `location` without the root directory.\"\"\"\n    return \"/\".join(str(location).strip(\"/\").split(\"/\")[1:])\n\n\ndef filename_now(sep=\"-\"):\n    \"\"\"Return the current date and time in iso format suitable for filename.\"\"\"\n    now = datetime.now().isoformat(sep=sep, timespec=\"seconds\")\n    return now.replace(\":\", sep)\n\n\ndef count_group_by(queryset, field_name):\n    \"\"\"\n    Return a summary of all existing values for the provided `field_name` on the\n    `queryset`, including the count of each entry, as a dictionary.\n    \"\"\"\n    counts = (\n        queryset.values(field_name)\n        .annotate(count=Count(field_name))\n        .order_by(field_name)\n    )\n\n    return {entry.get(field_name): entry.get(\"count\") for entry in counts}\n\n\ndef get_bin_executable(filename):\n    \"\"\"Return the location of the `filename` executable binary.\"\"\"\n    return str(Path(sys.executable).parent / filename)\n\n\ndef _stream_process(process, stream_to=logger.info):\n    exitcode = process.poll()\n\n    for line in process.stdout:\n        stream_to(line.rstrip(\"\\n\"))\n\n    has_terminated = exitcode is not None\n    return has_terminated\n\n\ndef run_command(cmd, log_output=False):\n    \"\"\"\n    Return (exitcode, output) of executing the provided `cmd` in a shell.\n    `cmd` can be provided as a string or as a list of arguments.\n\n    If `log_output` is True, the stdout and stderr of the process will be captured\n    and streamed to the `logger`.\n    \"\"\"\n    if isinstance(cmd, list):\n        cmd = \" \".join(cmd)\n\n    if not log_output:\n        exitcode, output = subprocess.getstatusoutput(cmd)\n        return exitcode, output\n\n    process = subprocess.Popen(\n        cmd,\n        shell=True,\n        stdout=subprocess.PIPE,\n        stderr=subprocess.STDOUT,\n        universal_newlines=True,\n    )\n\n    while _stream_process(process):\n        sleep(1)\n\n    exitcode = process.poll()\n    return exitcode, \"\"\n\n\ndef remove_prefix(text, prefix):\n    \"\"\"\n    Remove the `prefix` from `text`.\n    Note that build-in `removeprefix` was added in Python3.9 but we need to keep\n    this one for Python3.8 support.\n    https://docs.python.org/3.9/library/stdtypes.html#str.removeprefix\n    \"\"\"\n    if text.startswith(prefix):\n        prefix_len = len(prefix)\n        return text[prefix_len:]\n    return text\n\n\ndef get_progress_percentage(current_index, total_count):\n    \"\"\"\n    Return the percentage of progress given the current index and total count of\n    objects.\n    \"\"\"\n    if current_index < 0 or current_index >= total_count:\n        raise ValueError(\"current_index must be between 0 and total_count - 1\")\n\n    progress = current_index / total_count * 100\n    return progress\n\n\ndef log_progress(\n    log_func,\n    current_index,\n    total_count,\n    last_percent,\n    increment_percent,\n    start_time=None,\n):\n    \"\"\"\n    Log progress updates every `increment_percent` percentage points, given the\n    current index and total count of objects.\n    Return the latest percent logged.\n    \"\"\"\n    progress_percentage = int(get_progress_percentage(current_index, total_count))\n    if progress_percentage >= last_percent + increment_percent:\n        last_percent = progress_percentage\n        msg = f\"Progress: {progress_percentage}% ({current_index:,d}/{total_count:,d})\"\n\n        if start_time:\n            run_time = timer() - start_time\n            eta = round(run_time / progress_percentage * (100 - progress_percentage))\n            if eta:\n                msg += f\" ETA: {humanize_time(eta)}\"\n\n        log_func(msg)\n\n    return last_percent\n\n\ndef get_text_str_diff_ratio(str_a, str_b):\n    \"\"\"\n    Return a similarity ratio as a float between 0 and 1 by comparing the\n    text content of the ``str_a`` and ``str_b``.\n\n    Return None if any of the two resources str is empty.\n    \"\"\"\n    if not (str_a and str_b):\n        return\n\n    if not isinstance(str_a, str) or not isinstance(str_b, str):\n        raise ValueError(\"Values must be str\")\n\n    matcher = difflib.SequenceMatcher(a=str_a.splitlines(), b=str_b.splitlines())\n    return matcher.quick_ratio()\n\n\ndef get_resource_diff_ratio(resource_a, resource_b):\n    \"\"\"\n    Return a similarity ratio as a float between 0 and 1 by comparing the\n    text content of the CodebaseResource ``resource_a`` and ``resource_b``.\n\n    Return None if any of the two resources are not readable as text.\n    \"\"\"\n    with suppress(IOError):\n        return get_text_str_diff_ratio(\n            str_a=resource_a.file_content,\n            str_b=resource_b.file_content,\n        )\n", "# SPDX-License-Identifier: Apache-2.0\n#\n# http://nexb.com and https://github.com/nexB/scancode.io\n# The ScanCode.io software is licensed under the Apache License version 2.0.\n# Data generated with ScanCode.io is provided as-is without warranties.\n# ScanCode is a trademark of nexB Inc.\n#\n# You may not use this software except in compliance with the License.\n# You may obtain a copy of the License at: http://apache.org/licenses/LICENSE-2.0\n# Unless required by applicable law or agreed to in writing, software distributed\n# under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR\n# CONDITIONS OF ANY KIND, either express or implied. See the License for the\n# specific language governing permissions and limitations under the License.\n#\n# Data Generated with ScanCode.io is provided on an \"AS IS\" BASIS, WITHOUT WARRANTIES\n# OR CONDITIONS OF ANY KIND, either express or implied. No content created from\n# ScanCode.io should be considered or used as legal advice. Consult an Attorney\n# for any legal advice.\n#\n# ScanCode.io is a free software code scanning tool from nexB Inc. and others.\n# Visit https://github.com/nexB/scancode.io for support and download.\n\nimport cgi\nimport json\nimport logging\nimport os\nimport tempfile\nfrom collections import namedtuple\nfrom pathlib import Path\nfrom urllib.parse import urlparse\n\nimport requests\nfrom commoncode import command\nfrom commoncode.hash import multi_checksums\nfrom commoncode.text import python_safe_name\nfrom plugincode.location_provider import get_location\n\nfrom scanpipe import pipes\n\nlogger = logging.getLogger(\"scanpipe.pipes\")\n\nDownload = namedtuple(\"Download\", \"uri directory filename path size sha1 md5\")\n\n\ndef fetch_http(uri, to=None):\n    \"\"\"\n    Download a given `uri` in a temporary directory and return the directory's\n    path.\n    \"\"\"\n    response = requests.get(uri)\n\n    if response.status_code != 200:\n        raise requests.RequestException\n\n    content_disposition = response.headers.get(\"content-disposition\", \"\")\n    _, params = cgi.parse_header(content_disposition)\n    filename = params.get(\"filename\")\n    if not filename:\n        # Using `response.url` in place of provided `Scan.uri` since the former\n        # will be more accurate in case of HTTP redirect.\n        filename = Path(urlparse(response.url).path).name\n\n    download_directory = to or tempfile.mkdtemp()\n    output_file = Path(download_directory, filename)\n\n    file_content = response.content\n    with open(output_file, \"wb\") as f:\n        f.write(file_content)\n\n    checksums = multi_checksums(output_file, (\"md5\", \"sha1\"))\n\n    return Download(\n        uri=uri,\n        directory=download_directory,\n        filename=filename,\n        path=output_file,\n        size=len(file_content),\n        sha1=checksums[\"sha1\"],\n        md5=checksums[\"md5\"],\n    )\n\n\nclass FetchDockerImageError(Exception):\n    pass\n\n\n# key of a plugin-provided location\nFETCHCODE_SKOPEO_BINDIR = \"fetchcode_container.skopeo.bindir\"\n\nFETCHCODE_SKOPEO_PATH_ENVVAR = \"FETCHCODE_SKOPEO_PATH\"\n\n\ndef _get_skopeo_location(_cache=[]):\n    \"\"\"\n    Return the path to the skopeo command line executable, trying:\n    - an environment variable ``FETCHCODE_SKOPEO_PATH``,\n    - a plugin-provided path,\n    - the system PATH.\n    Raise an Exception if the skopeo binary cannot be found.\n    \"\"\"\n    if _cache:\n        return _cache[0]\n\n    # try the environment first\n    cmd_loc = os.environ.get(FETCHCODE_SKOPEO_PATH_ENVVAR)\n    if cmd_loc:\n        cmd_loc = Path(cmd_loc)\n\n    # try a plugin-provided path second\n    if not cmd_loc:\n        bin_location = get_location(FETCHCODE_SKOPEO_BINDIR)\n        if bin_location:\n            cmd_loc = Path(bin_location) / \"skopeo\"\n\n    # try the PATH\n    if not cmd_loc:\n        cmd_loc = command.find_in_path(\"skopeo\")\n        if cmd_loc:\n            cmd_loc = Path(cmd_loc)\n\n    if not cmd_loc or not os.path.isfile(cmd_loc):\n        raise Exception(\n            \"CRITICAL: skopeo executable is not installed. \"\n            \"Unable to continue: you need to install a valid fetchcode-container \"\n            \"plugin with a valid executable available. \"\n            \"OR set the FETCHCODE_SKOPEO_PATH environment variable. \"\n            \"OR ensure that skopeo is installed and available in the PATH.\"\n        )\n    _cache.append(cmd_loc)\n    return cmd_loc\n\n\ndef get_docker_image_platform(docker_reference):\n    \"\"\"\n    Return a platform mapping of a docker reference.\n    If there are more than one, return the first one by default.\n    \"\"\"\n    skopeo_executable = _get_skopeo_location()\n    cmd = (\n        f\"{skopeo_executable} inspect --insecure-policy --raw --no-creds \"\n        f\"{docker_reference}\"\n    )\n\n    logger.info(f\"Fetching image os/arch data: {cmd}\")\n    exitcode, output = pipes.run_command(cmd)\n    logger.info(output)\n    if exitcode != 0:\n        raise FetchDockerImageError(output)\n\n    # Data has this shape:\n    #\n    # \"schemaVersion\": 2,\n    # \"mediaType\": \"application/vnd.docker.distribution.manifest.list.v2+json\",\n    # \"manifests\": [\n    #    {\n    #       \"mediaType\": \"application/vnd.docker.distribution.manifest.v2+json\",\n    #       \"size\": 886,\n    #       \"digest\": \"sha256:305bad5caac7716b0715bfc77c8d8e19b070aa6c\",\n    #       \"platform\": {\n    #          \"architecture\": \"amd64\",\n    #          \"os\": \"windows\",\n    #          \"os.version\": \"10.0.19041.985\"\n    #       },\n    #      {\n    #        \"digest\": \"sha256:973ab50414f9597fdbd2b496e089c26229196259d\",\n    #        \"mediaType\": \"application/vnd.docker.distribution.manifest.v2+json\",\n    #        \"platform\": {\n    #          \"architecture\": \"arm\",\n    #          \"os\": \"linux\",\n    #          \"variant\": \"v7\"\n    #        },\n    #        \"size\": 529\n\n    inspection = json.loads(output)\n    for manifest in inspection.get(\"manifests\") or []:\n        platform = manifest.get(\"platform\") or {}\n        if platform:\n            return (\n                platform.get(\"os\") or \"linux\",\n                platform.get(\"architecture\") or \"amd64\",\n                platform.get(\"variant\") or \"\",\n            )\n\n\ndef fetch_docker_image(docker_reference, to=None):\n    \"\"\"\n    Fetch a docker image from the provided Docker image `docker_reference`\n    docker:// reference URL. Return a `download` object.\n\n    Docker references are documented here:\n    https://github.com/containers/skopeo/blob/0faf16017/docs/skopeo.1.md#image-names\n    \"\"\"\n    name = python_safe_name(docker_reference.replace(\"docker://\", \"\"))\n    filename = f\"{name}.tar\"\n    download_directory = to or tempfile.mkdtemp()\n    output_file = Path(download_directory, filename)\n    target = f\"docker-archive:{output_file}\"\n\n    skopeo_executable = _get_skopeo_location()\n    platform_args = []\n    platform = get_docker_image_platform(docker_reference)\n    if platform:\n        os, arch, variant = platform\n        if os:\n            platform_args.append(f\"--override-os={os}\")\n        if arch:\n            platform_args.append(f\"--override-arch={arch}\")\n        if variant:\n            platform_args.append(f\"--override-variant={variant}\")\n    platform_args = \" \".join(platform_args)\n\n    cmd = (\n        f\"{skopeo_executable} copy --insecure-policy \"\n        f\"{platform_args} {docker_reference} {target}\"\n    )\n    logger.info(f\"Fetching image with: {cmd}\")\n    exitcode, output = pipes.run_command(cmd)\n    logger.info(output)\n    if exitcode != 0:\n        raise FetchDockerImageError(output)\n\n    checksums = multi_checksums(output_file, (\"md5\", \"sha1\"))\n\n    return Download(\n        uri=docker_reference,\n        directory=download_directory,\n        filename=filename,\n        path=output_file,\n        size=output_file.stat().st_size,\n        sha1=checksums[\"sha1\"],\n        md5=checksums[\"md5\"],\n    )\n\n\ndef _get_fetcher(url):\n    \"\"\"Return the fetcher function based on the provided `url`.\"\"\"\n    if url.startswith(\"docker://\"):\n        return fetch_docker_image\n    return fetch_http\n\n\ndef fetch_urls(urls):\n    \"\"\"\n    Fetch provided `urls` list.\n    The `urls` can also be provided as a string containing one URL per line.\n    Return the fetched URLs as `downloads` objects and a list of `errors`.\n    \"\"\"\n    downloads = []\n    errors = []\n\n    if isinstance(urls, str):\n        urls = [url.strip() for url in urls.split()]\n\n    for url in urls:\n        fetcher = _get_fetcher(url)\n        logger.info(f'Fetching \"{url}\" using {fetcher.__name__}')\n        try:\n            downloaded = fetcher(url)\n        except Exception:\n            errors.append(url)\n        else:\n            downloads.append(downloaded)\n\n    return downloads, errors\n"], "fixing_code": ["# SPDX-License-Identifier: Apache-2.0\n#\n# http://nexb.com and https://github.com/nexB/scancode.io\n# The ScanCode.io software is licensed under the Apache License version 2.0.\n# Data generated with ScanCode.io is provided as-is without warranties.\n# ScanCode is a trademark of nexB Inc.\n#\n# You may not use this software except in compliance with the License.\n# You may obtain a copy of the License at: http://apache.org/licenses/LICENSE-2.0\n# Unless required by applicable law or agreed to in writing, software distributed\n# under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR\n# CONDITIONS OF ANY KIND, either express or implied. See the License for the\n# specific language governing permissions and limitations under the License.\n#\n# Data Generated with ScanCode.io is provided on an \"AS IS\" BASIS, WITHOUT WARRANTIES\n# OR CONDITIONS OF ANY KIND, either express or implied. No content created from\n# ScanCode.io should be considered or used as legal advice. Consult an Attorney\n# for any legal advice.\n#\n# ScanCode.io is a free software code scanning tool from nexB Inc. and others.\n# Visit https://github.com/nexB/scancode.io for support and download.\n\nimport difflib\nimport logging\nimport subprocess\nimport sys\nimport uuid\nfrom contextlib import suppress\nfrom datetime import datetime\nfrom pathlib import Path\nfrom time import sleep\nfrom timeit import default_timer as timer\n\nfrom django.db.models import Count\n\nfrom scanpipe import humanize_time\nfrom scanpipe.models import CodebaseRelation\nfrom scanpipe.models import CodebaseResource\nfrom scanpipe.models import DiscoveredDependency\nfrom scanpipe.models import DiscoveredPackage\nfrom scanpipe.pipes import scancode\n\nlogger = logging.getLogger(\"scanpipe.pipes\")\n\n\ndef make_codebase_resource(project, location, save=True, **extra_fields):\n    \"\"\"\n    Create a CodebaseResource instance in the database for the given ``project``.\n\n    The provided ``location`` is the absolute path of this resource.\n    It must be rooted in `project.codebase_path` as only the relative path within the\n    project codebase/ directory is stored in the database.\n\n    Extra fields can be provided as keywords arguments to this function call::\n\n        make_codebase_resource(\n            project=project,\n            location=resource.location,\n            rootfs_path=resource.path,\n            tag=layer_tag,\n        )\n\n    In this example, ``rootfs_path`` is an optional path relative to a rootfs root\n    within an Image/VM filesystem context. e.g.: \"/var/log/file.log\"\n\n    All paths use the POSIX separators.\n\n    If a CodebaseResource already exists in the ``project`` with the same path,\n    the error raised on save() is not stored in the database and the creation is\n    skipped.\n    \"\"\"\n    relative_path = Path(location).relative_to(project.codebase_path)\n    resource_data = scancode.get_resource_info(location=str(location))\n\n    if extra_fields:\n        resource_data.update(**extra_fields)\n\n    codebase_resource = CodebaseResource(\n        project=project,\n        path=relative_path,\n        **resource_data,\n    )\n\n    if save:\n        codebase_resource.save(save_error=False)\n    return codebase_resource\n\n\ndef update_or_create_resource(project, resource_data):\n    \"\"\"Get, update or create a CodebaseResource then return it.\"\"\"\n    for_packages = resource_data.pop(\"for_packages\", None) or []\n\n    resource = CodebaseResource.objects.get_or_none(\n        project=project,\n        path=resource_data.get(\"path\"),\n    )\n\n    if resource:\n        resource.update_from_data(resource_data)\n    else:\n        resource = CodebaseResource.create_from_data(project, resource_data)\n\n    for package_uid in for_packages:\n        package = project.discoveredpackages.get(package_uid=package_uid)\n        resource.add_package(package)\n\n    return resource\n\n\ndef _clean_package_data(package_data):\n    \"\"\"Clean provided `package_data` to make it compatible with the model.\"\"\"\n    package_data = package_data.copy()\n    if release_date := package_data.get(\"release_date\"):\n        if type(release_date) is str:\n            if release_date.endswith(\"Z\"):\n                release_date = release_date[:-1]\n            package_data[\"release_date\"] = datetime.fromisoformat(release_date).date()\n    return package_data\n\n\ndef update_or_create_package(project, package_data, codebase_resources=None):\n    \"\"\"\n    Get, update or create a DiscoveredPackage then return it.\n    Use the `project` and `package_data` mapping to lookup and creates the\n    DiscoveredPackage using its Package URL and package_uid as a unique key.\n    The package can be associated to `codebase_resources` providing a list or queryset\n    of resources.\n    \"\"\"\n    purl_data = DiscoveredPackage.extract_purl_data(package_data)\n    package_data = _clean_package_data(package_data)\n    # No values for package_uid requires to be empty string for proper queryset lookup\n    package_uid = package_data.get(\"package_uid\") or \"\"\n\n    package = DiscoveredPackage.objects.get_or_none(\n        project=project,\n        package_uid=package_uid,\n        **purl_data,\n    )\n\n    if package:\n        package.update_from_data(package_data)\n    else:\n        package = DiscoveredPackage.create_from_data(project, package_data)\n\n    if codebase_resources:\n        package.add_resources(codebase_resources)\n\n    return package\n\n\ndef update_or_create_dependency(\n    project, dependency_data, for_package=None, strip_datafile_path_root=False\n):\n    \"\"\"\n    Get, update or create a DiscoveredDependency then returns it.\n    Use the `project` and `dependency_data` mapping to lookup and creates the\n    DiscoveredDependency using its dependency_uid and for_package_uid as a unique key.\n\n    If `strip_datafile_path_root` is True, then\n    `DiscoveredDependency.create_from_data()` will strip the root path segment\n    from the `datafile_path` of `dependency_data` before looking up the\n    corresponding CodebaseResource for `datafile_path`. This is used in the case\n    where Dependency data is imported from a scancode-toolkit scan, where the\n    root path segments are not stripped for `datafile_path`.\n    \"\"\"\n    dependency = None\n    dependency_uid = dependency_data.get(\"dependency_uid\")\n\n    if not dependency_uid:\n        dependency_data[\"dependency_uid\"] = uuid.uuid4()\n    else:\n        dependency = project.discovereddependencies.get_or_none(\n            dependency_uid=dependency_uid,\n        )\n\n    if dependency:\n        dependency.update_from_data(dependency_data)\n    else:\n        dependency = DiscoveredDependency.create_from_data(\n            project,\n            dependency_data,\n            for_package=for_package,\n            strip_datafile_path_root=strip_datafile_path_root,\n        )\n\n    return dependency\n\n\ndef get_or_create_relation(project, relation_data):\n    \"\"\"\n    Get  or create a CodebaseRelation then return it.\n    The support for update is not useful as there is no fields on the model that\n    could be updated.\n    \"\"\"\n    from_resource_path = relation_data.get(\"from_resource\")\n    to_resource_path = relation_data.get(\"to_resource\")\n    resource_qs = project.codebaseresources\n\n    codebase_relation, _ = CodebaseRelation.objects.get_or_create(\n        project=project,\n        from_resource=resource_qs.get(path=from_resource_path),\n        to_resource=resource_qs.get(path=to_resource_path),\n        map_type=relation_data.get(\"map_type\"),\n    )\n\n    return codebase_relation\n\n\ndef make_relation(from_resource, to_resource, map_type, **extra_fields):\n    return CodebaseRelation.objects.create(\n        project=from_resource.project,\n        from_resource=from_resource,\n        to_resource=to_resource,\n        map_type=map_type,\n        **extra_fields,\n    )\n\n\ndef normalize_path(path):\n    \"\"\"Return a normalized path from a `path` string.\"\"\"\n    return \"/\" + path.strip(\"/\")\n\n\ndef strip_root(location):\n    \"\"\"Return the provided `location` without the root directory.\"\"\"\n    return \"/\".join(str(location).strip(\"/\").split(\"/\")[1:])\n\n\ndef filename_now(sep=\"-\"):\n    \"\"\"Return the current date and time in iso format suitable for filename.\"\"\"\n    now = datetime.now().isoformat(sep=sep, timespec=\"seconds\")\n    return now.replace(\":\", sep)\n\n\ndef count_group_by(queryset, field_name):\n    \"\"\"\n    Return a summary of all existing values for the provided `field_name` on the\n    `queryset`, including the count of each entry, as a dictionary.\n    \"\"\"\n    counts = (\n        queryset.values(field_name)\n        .annotate(count=Count(field_name))\n        .order_by(field_name)\n    )\n\n    return {entry.get(field_name): entry.get(\"count\") for entry in counts}\n\n\ndef get_bin_executable(filename):\n    \"\"\"Return the location of the `filename` executable binary.\"\"\"\n    return str(Path(sys.executable).parent / filename)\n\n\ndef _stream_process(process, stream_to=logger.info):\n    exitcode = process.poll()\n\n    for line in process.stdout:\n        stream_to(line.rstrip(\"\\n\"))\n\n    has_terminated = exitcode is not None\n    return has_terminated\n\n\ndef run_command(cmd, log_output=False):\n    \"\"\"\n    Return (exitcode, output) of executing the provided `cmd` in a shell.\n    `cmd` can be provided as a string or as a list of arguments.\n\n    If `log_output` is True, the stdout and stderr of the process will be captured\n    and streamed to the `logger`.\n    \"\"\"\n    if isinstance(cmd, list):\n        cmd = \" \".join(cmd)\n\n    if not log_output:\n        exitcode, output = subprocess.getstatusoutput(cmd)\n        return exitcode, output\n\n    process = subprocess.Popen(\n        cmd,\n        shell=False,\n        stdout=subprocess.PIPE,\n        stderr=subprocess.STDOUT,\n        universal_newlines=True,\n    )\n\n    while _stream_process(process):\n        sleep(1)\n\n    exitcode = process.poll()\n    return exitcode, \"\"\n\n\ndef remove_prefix(text, prefix):\n    \"\"\"\n    Remove the `prefix` from `text`.\n    Note that build-in `removeprefix` was added in Python3.9 but we need to keep\n    this one for Python3.8 support.\n    https://docs.python.org/3.9/library/stdtypes.html#str.removeprefix\n    \"\"\"\n    if text.startswith(prefix):\n        prefix_len = len(prefix)\n        return text[prefix_len:]\n    return text\n\n\ndef get_progress_percentage(current_index, total_count):\n    \"\"\"\n    Return the percentage of progress given the current index and total count of\n    objects.\n    \"\"\"\n    if current_index < 0 or current_index >= total_count:\n        raise ValueError(\"current_index must be between 0 and total_count - 1\")\n\n    progress = current_index / total_count * 100\n    return progress\n\n\ndef log_progress(\n    log_func,\n    current_index,\n    total_count,\n    last_percent,\n    increment_percent,\n    start_time=None,\n):\n    \"\"\"\n    Log progress updates every `increment_percent` percentage points, given the\n    current index and total count of objects.\n    Return the latest percent logged.\n    \"\"\"\n    progress_percentage = int(get_progress_percentage(current_index, total_count))\n    if progress_percentage >= last_percent + increment_percent:\n        last_percent = progress_percentage\n        msg = f\"Progress: {progress_percentage}% ({current_index:,d}/{total_count:,d})\"\n\n        if start_time:\n            run_time = timer() - start_time\n            eta = round(run_time / progress_percentage * (100 - progress_percentage))\n            if eta:\n                msg += f\" ETA: {humanize_time(eta)}\"\n\n        log_func(msg)\n\n    return last_percent\n\n\ndef get_text_str_diff_ratio(str_a, str_b):\n    \"\"\"\n    Return a similarity ratio as a float between 0 and 1 by comparing the\n    text content of the ``str_a`` and ``str_b``.\n\n    Return None if any of the two resources str is empty.\n    \"\"\"\n    if not (str_a and str_b):\n        return\n\n    if not isinstance(str_a, str) or not isinstance(str_b, str):\n        raise ValueError(\"Values must be str\")\n\n    matcher = difflib.SequenceMatcher(a=str_a.splitlines(), b=str_b.splitlines())\n    return matcher.quick_ratio()\n\n\ndef get_resource_diff_ratio(resource_a, resource_b):\n    \"\"\"\n    Return a similarity ratio as a float between 0 and 1 by comparing the\n    text content of the CodebaseResource ``resource_a`` and ``resource_b``.\n\n    Return None if any of the two resources are not readable as text.\n    \"\"\"\n    with suppress(IOError):\n        return get_text_str_diff_ratio(\n            str_a=resource_a.file_content,\n            str_b=resource_b.file_content,\n        )\n", "# SPDX-License-Identifier: Apache-2.0\n#\n# http://nexb.com and https://github.com/nexB/scancode.io\n# The ScanCode.io software is licensed under the Apache License version 2.0.\n# Data generated with ScanCode.io is provided as-is without warranties.\n# ScanCode is a trademark of nexB Inc.\n#\n# You may not use this software except in compliance with the License.\n# You may obtain a copy of the License at: http://apache.org/licenses/LICENSE-2.0\n# Unless required by applicable law or agreed to in writing, software distributed\n# under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR\n# CONDITIONS OF ANY KIND, either express or implied. See the License for the\n# specific language governing permissions and limitations under the License.\n#\n# Data Generated with ScanCode.io is provided on an \"AS IS\" BASIS, WITHOUT WARRANTIES\n# OR CONDITIONS OF ANY KIND, either express or implied. No content created from\n# ScanCode.io should be considered or used as legal advice. Consult an Attorney\n# for any legal advice.\n#\n# ScanCode.io is a free software code scanning tool from nexB Inc. and others.\n# Visit https://github.com/nexB/scancode.io for support and download.\n\nimport cgi\nimport json\nimport logging\nimport os\nimport re\nimport tempfile\nfrom collections import namedtuple\nfrom pathlib import Path\nfrom urllib.parse import urlparse\n\nimport requests\nfrom commoncode import command\nfrom commoncode.hash import multi_checksums\nfrom commoncode.text import python_safe_name\nfrom plugincode.location_provider import get_location\n\nfrom scanpipe import pipes\n\nlogger = logging.getLogger(\"scanpipe.pipes\")\n\nDownload = namedtuple(\"Download\", \"uri directory filename path size sha1 md5\")\n\n\ndef fetch_http(uri, to=None):\n    \"\"\"\n    Download a given `uri` in a temporary directory and return the directory's\n    path.\n    \"\"\"\n    response = requests.get(uri)\n\n    if response.status_code != 200:\n        raise requests.RequestException\n\n    content_disposition = response.headers.get(\"content-disposition\", \"\")\n    _, params = cgi.parse_header(content_disposition)\n    filename = params.get(\"filename\")\n    if not filename:\n        # Using `response.url` in place of provided `Scan.uri` since the former\n        # will be more accurate in case of HTTP redirect.\n        filename = Path(urlparse(response.url).path).name\n\n    download_directory = to or tempfile.mkdtemp()\n    output_file = Path(download_directory, filename)\n\n    file_content = response.content\n    with open(output_file, \"wb\") as f:\n        f.write(file_content)\n\n    checksums = multi_checksums(output_file, (\"md5\", \"sha1\"))\n\n    return Download(\n        uri=uri,\n        directory=download_directory,\n        filename=filename,\n        path=output_file,\n        size=len(file_content),\n        sha1=checksums[\"sha1\"],\n        md5=checksums[\"md5\"],\n    )\n\n\nclass FetchDockerImageError(Exception):\n    pass\n\n\n# key of a plugin-provided location\nFETCHCODE_SKOPEO_BINDIR = \"fetchcode_container.skopeo.bindir\"\n\nFETCHCODE_SKOPEO_PATH_ENVVAR = \"FETCHCODE_SKOPEO_PATH\"\n\n\ndef _get_skopeo_location(_cache=[]):\n    \"\"\"\n    Return the path to the skopeo command line executable, trying:\n    - an environment variable ``FETCHCODE_SKOPEO_PATH``,\n    - a plugin-provided path,\n    - the system PATH.\n    Raise an Exception if the skopeo binary cannot be found.\n    \"\"\"\n    if _cache:\n        return _cache[0]\n\n    # try the environment first\n    cmd_loc = os.environ.get(FETCHCODE_SKOPEO_PATH_ENVVAR)\n    if cmd_loc:\n        cmd_loc = Path(cmd_loc)\n\n    # try a plugin-provided path second\n    if not cmd_loc:\n        bin_location = get_location(FETCHCODE_SKOPEO_BINDIR)\n        if bin_location:\n            cmd_loc = Path(bin_location) / \"skopeo\"\n\n    # try the PATH\n    if not cmd_loc:\n        cmd_loc = command.find_in_path(\"skopeo\")\n        if cmd_loc:\n            cmd_loc = Path(cmd_loc)\n\n    if not cmd_loc or not os.path.isfile(cmd_loc):\n        raise Exception(\n            \"CRITICAL: skopeo executable is not installed. \"\n            \"Unable to continue: you need to install a valid fetchcode-container \"\n            \"plugin with a valid executable available. \"\n            \"OR set the FETCHCODE_SKOPEO_PATH environment variable. \"\n            \"OR ensure that skopeo is installed and available in the PATH.\"\n        )\n    _cache.append(cmd_loc)\n    return cmd_loc\n\n\ndef get_docker_image_platform(docker_reference):\n    \"\"\"\n    Return a platform mapping of a docker reference.\n    If there are more than one, return the first one by default.\n    \"\"\"\n    skopeo_executable = _get_skopeo_location()\n    cmd = (\n        f\"{skopeo_executable} inspect --insecure-policy --raw --no-creds \"\n        f\"{docker_reference}\"\n    )\n\n    logger.info(f\"Fetching image os/arch data: {cmd}\")\n    exitcode, output = pipes.run_command(cmd)\n    logger.info(output)\n    if exitcode != 0:\n        raise FetchDockerImageError(output)\n\n    # Data has this shape:\n    #\n    # \"schemaVersion\": 2,\n    # \"mediaType\": \"application/vnd.docker.distribution.manifest.list.v2+json\",\n    # \"manifests\": [\n    #    {\n    #       \"mediaType\": \"application/vnd.docker.distribution.manifest.v2+json\",\n    #       \"size\": 886,\n    #       \"digest\": \"sha256:305bad5caac7716b0715bfc77c8d8e19b070aa6c\",\n    #       \"platform\": {\n    #          \"architecture\": \"amd64\",\n    #          \"os\": \"windows\",\n    #          \"os.version\": \"10.0.19041.985\"\n    #       },\n    #      {\n    #        \"digest\": \"sha256:973ab50414f9597fdbd2b496e089c26229196259d\",\n    #        \"mediaType\": \"application/vnd.docker.distribution.manifest.v2+json\",\n    #        \"platform\": {\n    #          \"architecture\": \"arm\",\n    #          \"os\": \"linux\",\n    #          \"variant\": \"v7\"\n    #        },\n    #        \"size\": 529\n\n    inspection = json.loads(output)\n    for manifest in inspection.get(\"manifests\") or []:\n        platform = manifest.get(\"platform\") or {}\n        if platform:\n            return (\n                platform.get(\"os\") or \"linux\",\n                platform.get(\"architecture\") or \"amd64\",\n                platform.get(\"variant\") or \"\",\n            )\n\n\ndef fetch_docker_image(docker_reference, to=None):\n    \"\"\"\n    Fetch a docker image from the provided Docker image `docker_reference`\n    docker:// reference URL. Return a `download` object.\n\n    Docker references are documented here:\n    https://github.com/containers/skopeo/blob/0faf16017/docs/skopeo.1.md#image-names\n    \"\"\"\n\n    whitelist = r\"^docker://[a-zA-Z0-9_.:/@-]+$\"\n    if not re.match(whitelist, docker_reference):\n        raise ValueError(\"Invalid Docker reference.\")\n\n    name = python_safe_name(docker_reference.replace(\"docker://\", \"\"))\n    filename = f\"{name}.tar\"\n    download_directory = to or tempfile.mkdtemp()\n    output_file = Path(download_directory, filename)\n    target = f\"docker-archive:{output_file}\"\n\n    skopeo_executable = _get_skopeo_location()\n    platform_args = []\n    platform = get_docker_image_platform(docker_reference)\n    if platform:\n        os, arch, variant = platform\n        if os:\n            platform_args.append(f\"--override-os={os}\")\n        if arch:\n            platform_args.append(f\"--override-arch={arch}\")\n        if variant:\n            platform_args.append(f\"--override-variant={variant}\")\n    platform_args = \" \".join(platform_args)\n\n    cmd = (\n        f\"{skopeo_executable} copy --insecure-policy \"\n        f\"{platform_args} {docker_reference} {target}\"\n    )\n    logger.info(f\"Fetching image with: {cmd}\")\n    exitcode, output = pipes.run_command(cmd)\n    logger.info(output)\n    if exitcode != 0:\n        raise FetchDockerImageError(output)\n\n    checksums = multi_checksums(output_file, (\"md5\", \"sha1\"))\n\n    return Download(\n        uri=docker_reference,\n        directory=download_directory,\n        filename=filename,\n        path=output_file,\n        size=output_file.stat().st_size,\n        sha1=checksums[\"sha1\"],\n        md5=checksums[\"md5\"],\n    )\n\n\ndef _get_fetcher(url):\n    \"\"\"Return the fetcher function based on the provided `url`.\"\"\"\n    if url.startswith(\"docker://\"):\n        return fetch_docker_image\n    return fetch_http\n\n\ndef fetch_urls(urls):\n    \"\"\"\n    Fetch provided `urls` list.\n    The `urls` can also be provided as a string containing one URL per line.\n    Return the fetched URLs as `downloads` objects and a list of `errors`.\n    \"\"\"\n    downloads = []\n    errors = []\n\n    if isinstance(urls, str):\n        urls = [url.strip() for url in urls.split()]\n\n    for url in urls:\n        fetcher = _get_fetcher(url)\n        logger.info(f'Fetching \"{url}\" using {fetcher.__name__}')\n        try:\n            downloaded = fetcher(url)\n        except Exception:\n            errors.append(url)\n        else:\n            downloads.append(downloaded)\n\n    return downloads, errors\n"], "filenames": ["scanpipe/pipes/__init__.py", "scanpipe/pipes/fetch.py"], "buggy_code_start_loc": [281, 26], "buggy_code_end_loc": [282, 192], "fixing_code_start_loc": [281, 27], "fixing_code_end_loc": [282, 199], "type": "CWE-77", "message": "ScanCode.io is a server to script and automate software composition analysis with ScanPipe pipelines. Prior to version 32.5.1, the software has a possible command injection vulnerability in the docker fetch process as it allows to append malicious commands in the `docker_reference` parameter.\n\nIn the function `scanpipe/pipes/fetch.py:fetch_docker_image` the parameter `docker_reference` is user controllable. The `docker_reference` variable is then passed to the vulnerable function `get_docker_image_platform`.  However, the `get_docker_image_plaform` function constructs a shell command with the passed `docker_reference`. The `pipes.run_command` then executes the shell command without any prior sanitization, making the function vulnerable to command injections. A malicious user who is able to create or add inputs to a project can inject commands. Although the command injections are blind and the user will not receive direct feedback without logs, it is still possible to cause damage to the server/container. The vulnerability appears for example if a malicious user adds a semicolon after the input of `docker://;`, it would allow appending malicious commands.\n\nVersion 32.5.1 contains a patch for this issue. The `docker_reference` input should be sanitized to avoid command injections and, as a workaround, one may avoid creating commands with user controlled input directly.", "other": {"cve": {"id": "CVE-2023-39523", "sourceIdentifier": "security-advisories@github.com", "published": "2023-08-07T21:15:09.553", "lastModified": "2023-08-11T18:12:57.827", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "ScanCode.io is a server to script and automate software composition analysis with ScanPipe pipelines. Prior to version 32.5.1, the software has a possible command injection vulnerability in the docker fetch process as it allows to append malicious commands in the `docker_reference` parameter.\n\nIn the function `scanpipe/pipes/fetch.py:fetch_docker_image` the parameter `docker_reference` is user controllable. The `docker_reference` variable is then passed to the vulnerable function `get_docker_image_platform`.  However, the `get_docker_image_plaform` function constructs a shell command with the passed `docker_reference`. The `pipes.run_command` then executes the shell command without any prior sanitization, making the function vulnerable to command injections. A malicious user who is able to create or add inputs to a project can inject commands. Although the command injections are blind and the user will not receive direct feedback without logs, it is still possible to cause damage to the server/container. The vulnerability appears for example if a malicious user adds a semicolon after the input of `docker://;`, it would allow appending malicious commands.\n\nVersion 32.5.1 contains a patch for this issue. The `docker_reference` input should be sanitized to avoid command injections and, as a workaround, one may avoid creating commands with user controlled input directly."}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:H/I:H/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "HIGH", "availabilityImpact": "HIGH", "baseScore": 8.8, "baseSeverity": "HIGH"}, "exploitabilityScore": 2.8, "impactScore": 5.9}, {"source": "security-advisories@github.com", "type": "Secondary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:A/AC:L/PR:L/UI:N/S:U/C:L/I:L/A:H", "attackVector": "ADJACENT_NETWORK", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "LOW", "integrityImpact": "LOW", "availabilityImpact": "HIGH", "baseScore": 6.8, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 2.1, "impactScore": 4.7}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-77"}]}, {"source": "security-advisories@github.com", "type": "Secondary", "description": [{"lang": "en", "value": "CWE-77"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:nexb:scancode.io:*:*:*:*:*:*:*:*", "versionEndExcluding": "32.5.1", "matchCriteriaId": "B70F8F83-E2F9-4863-B8FC-88FF14215AD1"}]}]}], "references": [{"url": "https://github.com/nexB/scancode.io/blob/main/scanpipe/pipes/fetch.py#L185", "source": "security-advisories@github.com", "tags": ["Product"]}, {"url": "https://github.com/nexB/scancode.io/commit/07ec0de1964b14bf085a1c9a27ece2b61ab6105c", "source": "security-advisories@github.com", "tags": ["Patch"]}, {"url": "https://github.com/nexB/scancode.io/releases/tag/v32.5.1", "source": "security-advisories@github.com", "tags": ["Release Notes"]}, {"url": "https://github.com/nexB/scancode.io/security/advisories/GHSA-2ggp-cmvm-f62f", "source": "security-advisories@github.com", "tags": ["Exploit", "Patch", "Vendor Advisory"]}]}, "github_commit_url": "https://github.com/nexB/scancode.io/commit/07ec0de1964b14bf085a1c9a27ece2b61ab6105c"}}
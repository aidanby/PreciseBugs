{"buggy_code": ["import argparse\nimport os\nimport sys\n\nimport requests\n\nfrom .utils import Paginator, dynamic_bars, get_key_value, split_comma_separated\nfrom .url import build_URL_from_type, smart_select_url\nfrom ..network import Net, base_url\nfrom ..main import get_followed_list_from_user_library, get_list_from_user, get_list_from_user_library, search, get_manga_from_user_library\nfrom ..utils import (\n    validate_url as __validate,\n    validate_legacy_url,\n    input_handle\n)\nfrom ..group import Group\nfrom ..manga import ContentRating, Manga\nfrom ..errors import InvalidURL, MangaDexException, PillowNotInstalled\n\ndef _validate(url):\n    try:\n        _url = __validate(url)\n    except InvalidURL:\n        pass\n    else:\n        return _url\n    # Legacy support\n    try:\n        _url = validate_legacy_url(url)\n    except InvalidURL as e:\n        raise argparse.ArgumentTypeError(str(e))\n    return _url\n\ndef validate_url(url):\n    if os.path.exists(url):\n        with open(url, 'r') as opener:\n            content = opener.read()\n    else:\n        content = url\n\n    urls = []\n    for _url in content.splitlines():\n        if not _url:\n            continue\n\n        urls.append((_validate(_url), _url))\n    \n    return urls\n\ndef _create_prompt_choices(\n    parser,\n    iterator,\n    text,\n    on_empty_err,\n    on_preview,\n    limit=10\n):\n    def print_err(text):\n        print(f\"\\n{text}\\n\")\n\n    # Begin searching\n    count = 1\n    choices = {}\n    paginator = Paginator()\n\n    # For next results\n    choices['next'] = \"next\"\n\n    # For previous results\n    choices['previous'] = \"previous\"\n\n    # To see more details about selected result\n    if on_preview:\n        choices['preview'] = \"preview\"\n\n    fetch = True\n    while True:\n        if fetch:\n            items = []\n            # 10 results displayed at the screen\n            for _ in range(limit):\n                try:\n                    items.append(next(iterator))\n                except StopIteration:\n                    break\n            \n            if items:\n                paginator.add_page(*items)\n\n                # Append choices for user input\n                for item in items:\n                    choices[str(count)] = item\n                    count += 1\n            else:\n                try:\n                    paginator.previous()\n                except IndexError:\n                    parser.error(on_empty_err)\n                else:\n                    print_err(\"[ERROR] There are no more results\")\n\n        def print_choices():\n            # Build dynamic bars\n            dynamic_bar = \"\"\n            for _ in range(len(text)):\n                dynamic_bar += \"=\"\n            \n            print(dynamic_bar)\n            print(text)\n            print(dynamic_bar)\n\n            paginator.print()\n            \n            print(\"\")\n\n            print(\"type \\\"next\\\" to show next results\")\n            print(\"type \\\"previous\\\" to show previous results\")\n\n            if on_preview:\n                print(\n                    \"type \\\"preview NUMBER\\\" to show more details about selected result. \" \\\n                    \"For example: \\\"preview 2\\\"\"\n                )\n\n        print_choices()\n\n        # User input\n        _next = False\n        previous = False\n        preview = False\n        while True:\n            choice = input_handle(\"=> \")\n\n            # Parsing on_view\n            if choice.startswith('preview'):\n                choice = choice.split('preview')[1].strip()\n                preview = True\n\n            try:\n                item = choices[choice]\n            except KeyError:\n                print_err('[ERROR] Invalid choice, try again')\n                print_choices()\n                continue\n            else:\n                if item == \"next\":\n                    _next = True\n                elif item == \"previous\":\n                    try:\n                        paginator.previous()\n                    except IndexError:\n                        print_err('[ERROR] Choices are out of range, try again')\n                        print_choices()\n                        continue\n\n                    previous = True\n                break\n        \n        if _next:\n            paginator.next()\n            fetch = True\n            continue\n        elif previous:\n            fetch = False\n            continue\n        elif preview:\n            fetch = False\n            on_preview(item)\n            continue\n        else:\n            break\n    \n    return item\n\ndef preview_list(args, mdlist):\n    text_init = f'List of mangas from MangaDex list \\\"{mdlist.name}\\\"'\n\n    print('\\n')\n    print(text_init)\n    print(dynamic_bars(text_init))\n    for manga in mdlist.iter_manga(args.unsafe):\n        print(manga.title)\n    print('\\n\\n')\n\ndef preview_cover_manga(manga):\n    try:\n        from PIL import Image\n    except ImportError:\n        raise PillowNotInstalled(\"Pillow is not installed\") from None\n\n    r = Net.mangadex.get(manga.cover_art, stream=True)\n    im = Image.open(r.raw)\n\n    print(\"\\nCLOSE THE IMAGE PREVIEW TO CONTINUE\\n\")\n\n    im.show(manga.title)\n    im.close()\n\ndef validate(parser, args):\n    urls = args.URL\n\n    if (\n        not args.search and \n        not args.fetch_library_manga and\n        not args.fetch_library_list and\n        not args.fetch_library_follows_list and\n        not args.random and\n        not args.fetch_group\n    ):\n        # Parsing file path\n        if args.file:\n            result = urls.split(':')\n            file = result[1:]\n            file_path = \"\"\n            err_file = False\n\n            try:\n                file_path += file.pop(0)\n            except IndexError:\n                err_file = True\n            \n            if not file_path:\n                err_file = True\n\n            if err_file:\n                parser.error(\"Syntax error: file path argument is empty\")\n\n            # Because \":\" was removed during .split()\n            # add it again\n            for f in file:\n                file_path += ':' + f\n\n            # web URL location support for \"file:{location}\" syntax\n            if file_path.startswith('http://') or file_path.startswith('https://'):\n                r = Net.requests.get(file_path)\n                try:\n                    r.raise_for_status()\n                except requests.HTTPError:\n                    raise MangaDexException(f\"Failed to connect '{file_path}', status code = {r.status_code}\")\n\n                file_path = r.text\n            \n            # Because this is specified syntax for batch downloading\n            # If file doesn't exist, raise error\n            elif not os.path.exists(file_path):\n                parser.error(f\"File \\\"{file_path}\\\" is not exist\")\n        else:\n            file_path = urls\n        try:\n            args.URL = validate_url(file_path)\n        except argparse.ArgumentTypeError as e:\n            parser.error(str(e))\n        return\n\n    kwargs = {\n        'parser': parser\n    }\n\n    limit_items = None\n    if args.random:\n        def iter_random_manga():\n            ids = []\n            while True:\n                _, raw_cr = get_key_value(urls, sep=\":\")\n                content_ratings = split_comma_separated(raw_cr, single_value_to_list=True)\n                if not content_ratings[0]:\n                    # Fallback to default values\n                    content_ratings = [i.value for i in ContentRating]\n                else:\n                    # Verify it\n                    try:\n                        content_ratings = [ContentRating(i).value for i in content_ratings]\n                    except ValueError as e:\n                        raise MangaDexException(e)\n\n                params = {\n                    'includes[]': ['author', 'artist', 'cover_art'],\n                    \"contentRating[]\": content_ratings\n                }\n                r = Net.mangadex.get(f'{base_url}/manga/random', params=params)\n                data = r.json()['data']\n                manga = Manga(data=data)\n\n                if manga.id not in ids:\n                    # Make sure it's not duplicated manga\n                    ids.append(manga.id)\n                    yield manga\n\n                continue\n\n        iterator = iter_random_manga()\n        text = f\"Found random manga\"\n        on_empty_err = f\"Unknown Error\" # This should never happened\n        on_preview = preview_cover_manga\n        limit_items = 5\n    elif args.fetch_group:\n        # Getting group id\n        _, group_id = get_key_value(urls, sep=':')\n        if not group_id:\n            parser.error(\"group id or url are required\")\n        \n        group_id = __validate(group_id)\n        group = Group(group_id)\n\n        iterator = search(None, args.unsafe, group=group.id)\n        text = f'List manga from group \"{group.name}\"'\n        on_empty_err = f'Group \"{group.name}\" has no uploaded mangas'\n        on_preview = preview_cover_manga\n    elif args.search:\n        filter_kwargs = {}\n        filters = args.search_filter or []\n        for f in filters:\n            key, value  = get_key_value(f)\n            try:\n                value_filter_kwargs = filter_kwargs[key]\n            except KeyError:\n                filter_kwargs[key] = split_comma_separated(value)\n            else:\n                # Found duplicate filter with different value\n                if isinstance(value_filter_kwargs, str):\n                    new_values = [value_filter_kwargs]\n                else:\n                    new_values = value_filter_kwargs\n\n                values = split_comma_separated(value, single_value_to_list=True)\n                new_values.extend(values)\n\n                filter_kwargs[key] = new_values\n\n        iterator = search(urls, args.unsafe, **filter_kwargs)\n        text = f\"Search results for \\\"{urls}\\\"\"\n        on_empty_err = f\"Search results \\\"{urls}\\\" are empty\"\n        on_preview = preview_cover_manga\n    elif args.fetch_library_manga:\n        result = urls.split(':')\n        \n        # Try to get filter status\n        try:\n            status = result[1]\n        except IndexError:\n            status = None\n\n        try:\n            iterator = get_manga_from_user_library(status, args.unsafe)\n        except MangaDexException as e:\n            parser.error(str(e))\n        \n        user = Net.mangadex.user\n        text = f\"Manga library from user \\\"{user.name}\\\"\"\n        on_empty_err = f\"User \\\"{user.name}\\\" has no saved mangas\"\n        on_preview = preview_cover_manga\n    elif args.fetch_library_list:\n        # Try to get user (if available)\n        _, user = get_key_value(urls, sep=':')\n\n        user_id = None\n        if user:\n            try:\n                user_id = __validate(user)\n            except InvalidURL as e:\n                parser.error(f\"\\\"{user}\\\" is not a valid user\")\n\n        try:\n            if user:\n                iterator = get_list_from_user(user_id)\n            else:\n                iterator = get_list_from_user_library()\n        except MangaDexException as e:\n            parser.error(str(e))\n\n        try:\n            user = iterator.user\n        except AttributeError:\n            # Logged in user\n            user = Net.mangadex.user\n\n        text = f\"MangaDex List library from user \\\"{user.name}\\\"\"\n        on_empty_err = f\"User \\\"{user.name}\\\" has no saved lists\"\n        on_preview = lambda x: preview_list(args, x)\n    elif args.fetch_library_follows_list:\n        try:\n            iterator = get_followed_list_from_user_library()\n        except MangaDexException as e:\n            parser.error(str(e))\n        \n        user = Net.mangadex.user\n        text = f\"MangaDex followed List from user \\\"{user.name}\\\"\"\n        on_empty_err = f\"User \\\"{user.name}\\\" has no followed lists\"\n        on_preview = lambda x: preview_list(args, x)\n\n    kwargs.update({\n        'iterator': iterator,\n        'text': text,\n        'on_empty_err': on_empty_err,\n        'on_preview': on_preview\n    })\n\n    if limit_items:\n        kwargs.update(limit=limit_items)\n\n    result = _create_prompt_choices(**kwargs)\n\n    args.URL = validate_url(result.id)\n\ndef build_url(parser, args):\n    validate(parser, args)\n\n    if args.type:\n        urls = []\n        for parsed_url, orig_url in args.URL:\n            url = build_URL_from_type(args.type, parsed_url)\n            urls.append(url)\n        args.URL = urls\n    else:\n        urls = []\n        for parsed_url, orig_url in args.URL:\n            url = smart_select_url(orig_url)\n            urls.append(url)\n        args.URL = urls\n\n    # Make sure to check if args.URL is empty\n    # if empty exit the program\n    if not args.URL:\n        parser.error(\"the following arguments are required: URL\")"], "fixing_code": ["import argparse\nimport os\nimport sys\n\nimport requests\n\nfrom .utils import Paginator, dynamic_bars, get_key_value, split_comma_separated\nfrom .url import build_URL_from_type, smart_select_url\nfrom ..network import Net, base_url\nfrom ..main import get_followed_list_from_user_library, get_list_from_user, get_list_from_user_library, search, get_manga_from_user_library\nfrom ..utils import (\n    validate_url as __validate,\n    validate_legacy_url,\n    input_handle\n)\nfrom ..group import Group\nfrom ..manga import ContentRating, Manga\nfrom ..errors import InvalidURL, MangaDexException, PillowNotInstalled\n\ndef _validate(url):\n    try:\n        _url = __validate(url)\n    except InvalidURL:\n        pass\n    else:\n        return _url\n    # Legacy support\n    try:\n        _url = validate_legacy_url(url)\n    except InvalidURL as e:\n        raise argparse.ArgumentTypeError(str(e))\n    return _url\n\ndef _try_read(path):\n    if not os.path.exists(path):\n        return None\n    \n    with open(path, 'r') as o:\n        return o.read()\n\ndef validate_url(url):\n    urls = []\n    for _url in url.splitlines():\n        if not _url:\n            continue\n\n        urls.append((_validate(_url), _url))\n    \n    return urls\n\ndef _create_prompt_choices(\n    parser,\n    iterator,\n    text,\n    on_empty_err,\n    on_preview,\n    limit=10\n):\n    def print_err(text):\n        print(f\"\\n{text}\\n\")\n\n    # Begin searching\n    count = 1\n    choices = {}\n    paginator = Paginator()\n\n    # For next results\n    choices['next'] = \"next\"\n\n    # For previous results\n    choices['previous'] = \"previous\"\n\n    # To see more details about selected result\n    if on_preview:\n        choices['preview'] = \"preview\"\n\n    fetch = True\n    while True:\n        if fetch:\n            items = []\n            # 10 results displayed at the screen\n            for _ in range(limit):\n                try:\n                    items.append(next(iterator))\n                except StopIteration:\n                    break\n            \n            if items:\n                paginator.add_page(*items)\n\n                # Append choices for user input\n                for item in items:\n                    choices[str(count)] = item\n                    count += 1\n            else:\n                try:\n                    paginator.previous()\n                except IndexError:\n                    parser.error(on_empty_err)\n                else:\n                    print_err(\"[ERROR] There are no more results\")\n\n        def print_choices():\n            # Build dynamic bars\n            dynamic_bar = \"\"\n            for _ in range(len(text)):\n                dynamic_bar += \"=\"\n            \n            print(dynamic_bar)\n            print(text)\n            print(dynamic_bar)\n\n            paginator.print()\n            \n            print(\"\")\n\n            print(\"type \\\"next\\\" to show next results\")\n            print(\"type \\\"previous\\\" to show previous results\")\n\n            if on_preview:\n                print(\n                    \"type \\\"preview NUMBER\\\" to show more details about selected result. \" \\\n                    \"For example: \\\"preview 2\\\"\"\n                )\n\n        print_choices()\n\n        # User input\n        _next = False\n        previous = False\n        preview = False\n        while True:\n            choice = input_handle(\"=> \")\n\n            # Parsing on_view\n            if choice.startswith('preview'):\n                choice = choice.split('preview')[1].strip()\n                preview = True\n\n            try:\n                item = choices[choice]\n            except KeyError:\n                print_err('[ERROR] Invalid choice, try again')\n                print_choices()\n                continue\n            else:\n                if item == \"next\":\n                    _next = True\n                elif item == \"previous\":\n                    try:\n                        paginator.previous()\n                    except IndexError:\n                        print_err('[ERROR] Choices are out of range, try again')\n                        print_choices()\n                        continue\n\n                    previous = True\n                break\n        \n        if _next:\n            paginator.next()\n            fetch = True\n            continue\n        elif previous:\n            fetch = False\n            continue\n        elif preview:\n            fetch = False\n            on_preview(item)\n            continue\n        else:\n            break\n    \n    return item\n\ndef preview_list(args, mdlist):\n    text_init = f'List of mangas from MangaDex list \\\"{mdlist.name}\\\"'\n\n    print('\\n')\n    print(text_init)\n    print(dynamic_bars(text_init))\n    for manga in mdlist.iter_manga(args.unsafe):\n        print(manga.title)\n    print('\\n\\n')\n\ndef preview_cover_manga(manga):\n    try:\n        from PIL import Image\n    except ImportError:\n        raise PillowNotInstalled(\"Pillow is not installed\") from None\n\n    r = Net.mangadex.get(manga.cover_art, stream=True)\n    im = Image.open(r.raw)\n\n    print(\"\\nCLOSE THE IMAGE PREVIEW TO CONTINUE\\n\")\n\n    im.show(manga.title)\n    im.close()\n\ndef validate(parser, args):\n    urls = args.URL\n\n    if (\n        not args.search and \n        not args.fetch_library_manga and\n        not args.fetch_library_list and\n        not args.fetch_library_follows_list and\n        not args.random and\n        not args.fetch_group\n    ):\n        # Parsing file path\n        if args.file:\n            result = urls.split(':')\n            file = result[1:]\n            file_path = \"\"\n            err_file = False\n\n            try:\n                file_path += file.pop(0)\n            except IndexError:\n                err_file = True\n            \n            if not file_path:\n                err_file = True\n\n            if err_file:\n                parser.error(\"Syntax error: file path argument is empty\")\n\n            # Because \":\" was removed during .split()\n            # add it again\n            for f in file:\n                file_path += ':' + f\n\n            # web URL location support for \"file:{location}\" syntax\n            if file_path.startswith('http://') or file_path.startswith('https://'):\n                r = Net.requests.get(file_path)\n                try:\n                    r.raise_for_status()\n                except requests.HTTPError:\n                    raise MangaDexException(f\"Failed to connect '{file_path}', status code = {r.status_code}\")\n\n                file_path = r.text\n            \n            # Because this is specified syntax for batch downloading\n            # If file doesn't exist, raise error\n            elif not os.path.exists(file_path):\n                parser.error(f\"File \\\"{file_path}\\\" is not exist\")\n        else:\n            file_content = _try_read(urls)\n            file_path = file_content if file_content is not None else urls\n        try:\n            args.URL = validate_url(file_path)\n        except argparse.ArgumentTypeError as e:\n            parser.error(str(e))\n        return\n\n    kwargs = {\n        'parser': parser\n    }\n\n    limit_items = None\n    if args.random:\n        def iter_random_manga():\n            ids = []\n            while True:\n                _, raw_cr = get_key_value(urls, sep=\":\")\n                content_ratings = split_comma_separated(raw_cr, single_value_to_list=True)\n                if not content_ratings[0]:\n                    # Fallback to default values\n                    content_ratings = [i.value for i in ContentRating]\n                else:\n                    # Verify it\n                    try:\n                        content_ratings = [ContentRating(i).value for i in content_ratings]\n                    except ValueError as e:\n                        raise MangaDexException(e)\n\n                params = {\n                    'includes[]': ['author', 'artist', 'cover_art'],\n                    \"contentRating[]\": content_ratings\n                }\n                r = Net.mangadex.get(f'{base_url}/manga/random', params=params)\n                data = r.json()['data']\n                manga = Manga(data=data)\n\n                if manga.id not in ids:\n                    # Make sure it's not duplicated manga\n                    ids.append(manga.id)\n                    yield manga\n\n                continue\n\n        iterator = iter_random_manga()\n        text = f\"Found random manga\"\n        on_empty_err = f\"Unknown Error\" # This should never happened\n        on_preview = preview_cover_manga\n        limit_items = 5\n    elif args.fetch_group:\n        # Getting group id\n        _, group_id = get_key_value(urls, sep=':')\n        if not group_id:\n            parser.error(\"group id or url are required\")\n        \n        group_id = __validate(group_id)\n        group = Group(group_id)\n\n        iterator = search(None, args.unsafe, group=group.id)\n        text = f'List manga from group \"{group.name}\"'\n        on_empty_err = f'Group \"{group.name}\" has no uploaded mangas'\n        on_preview = preview_cover_manga\n    elif args.search:\n        filter_kwargs = {}\n        filters = args.search_filter or []\n        for f in filters:\n            key, value  = get_key_value(f)\n            try:\n                value_filter_kwargs = filter_kwargs[key]\n            except KeyError:\n                filter_kwargs[key] = split_comma_separated(value)\n            else:\n                # Found duplicate filter with different value\n                if isinstance(value_filter_kwargs, str):\n                    new_values = [value_filter_kwargs]\n                else:\n                    new_values = value_filter_kwargs\n\n                values = split_comma_separated(value, single_value_to_list=True)\n                new_values.extend(values)\n\n                filter_kwargs[key] = new_values\n\n        iterator = search(urls, args.unsafe, **filter_kwargs)\n        text = f\"Search results for \\\"{urls}\\\"\"\n        on_empty_err = f\"Search results \\\"{urls}\\\" are empty\"\n        on_preview = preview_cover_manga\n    elif args.fetch_library_manga:\n        result = urls.split(':')\n        \n        # Try to get filter status\n        try:\n            status = result[1]\n        except IndexError:\n            status = None\n\n        try:\n            iterator = get_manga_from_user_library(status, args.unsafe)\n        except MangaDexException as e:\n            parser.error(str(e))\n        \n        user = Net.mangadex.user\n        text = f\"Manga library from user \\\"{user.name}\\\"\"\n        on_empty_err = f\"User \\\"{user.name}\\\" has no saved mangas\"\n        on_preview = preview_cover_manga\n    elif args.fetch_library_list:\n        # Try to get user (if available)\n        _, user = get_key_value(urls, sep=':')\n\n        user_id = None\n        if user:\n            try:\n                user_id = __validate(user)\n            except InvalidURL as e:\n                parser.error(f\"\\\"{user}\\\" is not a valid user\")\n\n        try:\n            if user:\n                iterator = get_list_from_user(user_id)\n            else:\n                iterator = get_list_from_user_library()\n        except MangaDexException as e:\n            parser.error(str(e))\n\n        try:\n            user = iterator.user\n        except AttributeError:\n            # Logged in user\n            user = Net.mangadex.user\n\n        text = f\"MangaDex List library from user \\\"{user.name}\\\"\"\n        on_empty_err = f\"User \\\"{user.name}\\\" has no saved lists\"\n        on_preview = lambda x: preview_list(args, x)\n    elif args.fetch_library_follows_list:\n        try:\n            iterator = get_followed_list_from_user_library()\n        except MangaDexException as e:\n            parser.error(str(e))\n        \n        user = Net.mangadex.user\n        text = f\"MangaDex followed List from user \\\"{user.name}\\\"\"\n        on_empty_err = f\"User \\\"{user.name}\\\" has no followed lists\"\n        on_preview = lambda x: preview_list(args, x)\n\n    kwargs.update({\n        'iterator': iterator,\n        'text': text,\n        'on_empty_err': on_empty_err,\n        'on_preview': on_preview\n    })\n\n    if limit_items:\n        kwargs.update(limit=limit_items)\n\n    result = _create_prompt_choices(**kwargs)\n\n    args.URL = validate_url(result.id)\n\ndef build_url(parser, args):\n    validate(parser, args)\n\n    if args.type:\n        urls = []\n        for parsed_url, orig_url in args.URL:\n            url = build_URL_from_type(args.type, parsed_url)\n            urls.append(url)\n        args.URL = urls\n    else:\n        urls = []\n        for parsed_url, orig_url in args.URL:\n            url = smart_select_url(orig_url)\n            urls.append(url)\n        args.URL = urls\n\n    # Make sure to check if args.URL is empty\n    # if empty exit the program\n    if not args.URL:\n        parser.error(\"the following arguments are required: URL\")"], "filenames": ["mangadex_downloader/cli/validator.py"], "buggy_code_start_loc": [33], "buggy_code_end_loc": [249], "fixing_code_start_loc": [34], "fixing_code_end_loc": [251], "type": "NVD-CWE-noinfo", "message": "mangadex-downloader is a command-line tool to download manga from MangaDex. When using `file:<location>` command and `<location>` is a web URL location (http, https), mangadex-downloader between versions 1.3.0 and 1.7.2 will try to open and read a file in local disk for each line of website contents. Version 1.7.2 contains a patch for this issue.", "other": {"cve": {"id": "CVE-2022-36082", "sourceIdentifier": "security-advisories@github.com", "published": "2022-09-07T22:15:08.583", "lastModified": "2022-09-12T18:23:19.847", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "mangadex-downloader is a command-line tool to download manga from MangaDex. When using `file:<location>` command and `<location>` is a web URL location (http, https), mangadex-downloader between versions 1.3.0 and 1.7.2 will try to open and read a file in local disk for each line of website contents. Version 1.7.2 contains a patch for this issue."}, {"lang": "es", "value": "mangadex-downloader es una herramienta de l\u00ednea de comandos para descargar manga de MangaDex. Cuando es usado el comando \"file:(location)\" y \"(location)\" es una ubicaci\u00f3n URL de la web (http, https), mangadex-downloader entre las versiones 1.3.0 y 1.7.2, intentar\u00e1 abrir y leer un archivo en el disco local para cada l\u00ednea de contenido de la web. La versi\u00f3n 1.7.2 contiene un parche para este problema"}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:L/I:N/A:N", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "LOW", "integrityImpact": "NONE", "availabilityImpact": "NONE", "baseScore": 5.3, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 3.9, "impactScore": 1.4}, {"source": "security-advisories@github.com", "type": "Secondary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:L/I:N/A:N", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "LOW", "integrityImpact": "NONE", "availabilityImpact": "NONE", "baseScore": 5.3, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 3.9, "impactScore": 1.4}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "NVD-CWE-noinfo"}]}, {"source": "security-advisories@github.com", "type": "Secondary", "description": [{"lang": "en", "value": "CWE-20"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:mangadex-downloader_project:mangadex-downloader:*:*:*:*:*:*:*:*", "versionStartIncluding": "1.3.0", "versionEndExcluding": "1.7.2", "matchCriteriaId": "10680E3E-EBF6-4CD8-B655-E10FD3DA17B9"}]}]}], "references": [{"url": "https://github.com/mansuf/mangadex-downloader/commit/439cc2825198ebc12b3310c95c39a8c7710c9b42", "source": "security-advisories@github.com", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/mansuf/mangadex-downloader/security/advisories/GHSA-r9x7-2xmr-v8fw", "source": "security-advisories@github.com", "tags": ["Third Party Advisory"]}]}, "github_commit_url": "https://github.com/mansuf/mangadex-downloader/commit/439cc2825198ebc12b3310c95c39a8c7710c9b42"}}
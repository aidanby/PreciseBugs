{"buggy_code": ["import logging\nimport os\nfrom os.path import join\nimport shutil\nimport sys\nimport time\n\nfrom mlflow.entities.model_registry import (\n    RegisteredModel,\n    ModelVersion,\n    RegisteredModelTag,\n    ModelVersionTag,\n)\nfrom mlflow.entities.model_registry.model_version_stages import (\n    get_canonical_stage,\n    ALL_STAGES,\n    DEFAULT_STAGES_FOR_GET_LATEST_VERSIONS,\n    STAGE_ARCHIVED,\n    STAGE_NONE,\n    STAGE_DELETED_INTERNAL,\n)\nfrom mlflow.exceptions import MlflowException\nfrom mlflow.protos.databricks_pb2 import (\n    INVALID_PARAMETER_VALUE,\n    RESOURCE_ALREADY_EXISTS,\n    RESOURCE_DOES_NOT_EXIST,\n)\nfrom mlflow.store.entities.paged_list import PagedList\nfrom mlflow.store.model_registry.abstract_store import AbstractStore\nfrom mlflow.store.model_registry import (\n    DEFAULT_LOCAL_FILE_AND_ARTIFACT_PATH,\n    SEARCH_REGISTERED_MODEL_MAX_RESULTS_THRESHOLD,\n    SEARCH_MODEL_VERSION_MAX_RESULTS_THRESHOLD,\n)\nfrom mlflow.utils.search_utils import SearchUtils, SearchModelUtils, SearchModelVersionUtils\nfrom mlflow.utils.string_utils import is_string_type\nfrom mlflow.utils.validation import (\n    _validate_registered_model_tag,\n    _validate_model_version_tag,\n    _validate_model_name,\n    _validate_model_version,\n    _validate_tag_name,\n)\nfrom mlflow.utils.env import get_env\nfrom mlflow.utils.file_utils import (\n    is_directory,\n    list_subdirs,\n    mkdir,\n    exists,\n    write_yaml,\n    overwrite_yaml,\n    read_yaml,\n    find,\n    read_file,\n    write_to,\n    make_containing_dirs,\n    list_all,\n    local_file_uri_to_path,\n)\nfrom mlflow.utils.time_utils import get_current_time_millis\n\n\n_REGISTRY_DIR_ENV_VAR = \"MLFLOW_REGISTRY_DIR\"\n\n\ndef _default_root_dir():\n    return get_env(_REGISTRY_DIR_ENV_VAR) or os.path.abspath(DEFAULT_LOCAL_FILE_AND_ARTIFACT_PATH)\n\n\nclass FileStore(AbstractStore):\n    MODELS_FOLDER_NAME = \"models\"\n    META_DATA_FILE_NAME = \"meta.yaml\"\n    TAGS_FOLDER_NAME = \"tags\"\n    MODEL_VERSION_TAGS_FOLDER_NAME = \"tags\"\n    CREATE_MODEL_VERSION_RETRIES = 3\n\n    def __init__(self, root_directory=None):\n        \"\"\"\n        Create a new FileStore with the given root directory.\n        \"\"\"\n\n        super().__init__()\n        self.root_directory = local_file_uri_to_path(root_directory or _default_root_dir())\n        # Create models directory if needed\n        if not exists(self.models_directory):\n            mkdir(self.models_directory)\n\n    @property\n    def models_directory(self):\n        return os.path.join(self.root_directory, FileStore.MODELS_FOLDER_NAME)\n\n    def _check_root_dir(self):\n        \"\"\"\n        Run checks before running directory operations.\n        \"\"\"\n        if not exists(self.root_directory):\n            raise Exception(\"'%s' does not exist.\" % self.root_directory)\n        if not is_directory(self.root_directory):\n            raise Exception(\"'%s' is not a directory.\" % self.root_directory)\n\n    def _validate_registered_model_does_not_exist(self, name):\n        model_path = self._get_registered_model_path(name)\n        if exists(model_path):\n            raise MlflowException(\n                f\"Registered Model (name={name}) already exists.\",\n                RESOURCE_ALREADY_EXISTS,\n            )\n\n    def _save_registered_model_as_meta_file(self, registered_model, meta_dir=None, overwrite=True):\n        registered_model_dict = dict(registered_model)\n        # tags are stored under TAGS_FOLDER_NAME so remove them in meta file.\n        del registered_model_dict[\"tags\"]\n        del registered_model_dict[\"latest_versions\"]\n        meta_dir = meta_dir or self._get_registered_model_path(registered_model.name)\n        if overwrite:\n            overwrite_yaml(\n                meta_dir,\n                FileStore.META_DATA_FILE_NAME,\n                registered_model_dict,\n            )\n        else:\n            write_yaml(\n                meta_dir,\n                FileStore.META_DATA_FILE_NAME,\n                registered_model_dict,\n            )\n\n    def _update_registered_model_last_updated_time(self, name, updated_time):\n        registered_model = self.get_registered_model(name)\n        registered_model.last_updated_timestamp = updated_time\n        self._save_registered_model_as_meta_file(registered_model)\n\n    def create_registered_model(self, name, tags=None, description=None):\n        \"\"\"\n        Create a new registered model in backend store.\n\n        :param name: Name of the new model. This is expected to be unique in the backend store.\n        :param tags: A list of :py:class:`mlflow.entities.model_registry.RegisteredModelTag`\n                     instances associated with this registered model.\n        :param description: Description of the model.\n        :return: A single object of :py:class:`mlflow.entities.model_registry.RegisteredModel`\n                 created in the backend.\n        \"\"\"\n\n        self._check_root_dir()\n        _validate_model_name(name)\n        self._validate_registered_model_does_not_exist(name)\n        for tag in tags or []:\n            _validate_registered_model_tag(tag.key, tag.value)\n        meta_dir = self._get_registered_model_path(name)\n        mkdir(meta_dir)\n        creation_time = get_current_time_millis()\n        latest_versions = []\n        registered_model = RegisteredModel(\n            name=name,\n            creation_timestamp=creation_time,\n            last_updated_timestamp=creation_time,\n            description=description,\n            latest_versions=latest_versions,\n            tags=tags,\n        )\n        self._save_registered_model_as_meta_file(\n            registered_model, meta_dir=meta_dir, overwrite=False\n        )\n        if tags is not None:\n            for tag in tags:\n                self.set_registered_model_tag(name, tag)\n        return registered_model\n\n    def _get_registered_model_path(self, name):\n        self._check_root_dir()\n        _validate_model_name(name)\n        return join(self.root_directory, FileStore.MODELS_FOLDER_NAME, name)\n\n    def _get_registered_model_from_path(self, model_path):\n        meta = FileStore._read_yaml(model_path, FileStore.META_DATA_FILE_NAME)\n        meta[\"tags\"] = self.get_all_registered_model_tags_from_path(model_path)\n        registered_model = RegisteredModel.from_dictionary(meta)\n        registered_model.latest_versions = self.get_latest_versions(os.path.basename(model_path))\n        return registered_model\n\n    def update_registered_model(self, name, description):\n        \"\"\"\n        Update description of the registered model.\n\n        :param name: Registered model name.\n        :param description: New description.\n        :return: A single updated :py:class:`mlflow.entities.model_registry.RegisteredModel` object.\n        \"\"\"\n        registered_model = self.get_registered_model(name)\n        updated_time = get_current_time_millis()\n        registered_model.description = description\n        registered_model.last_updated_timestamp = updated_time\n        self._save_registered_model_as_meta_file(registered_model)\n        return registered_model\n\n    def rename_registered_model(self, name, new_name):\n        \"\"\"\n        Rename the registered model.\n\n        :param name: Registered model name.\n        :param new_name: New proposed name.\n        :return: A single updated :py:class:`mlflow.entities.model_registry.RegisteredModel` object.\n        \"\"\"\n        model_path = self._get_registered_model_path(name)\n        if not exists(model_path):\n            raise MlflowException(\n                f\"Registered Model with name={name} not found\",\n                RESOURCE_DOES_NOT_EXIST,\n            )\n        registered_model = self._get_registered_model_from_path(model_path)\n\n        new_meta_dir = self._get_registered_model_path(new_name)\n        if not exists(new_meta_dir):\n            mkdir(new_meta_dir)\n            updated_time = get_current_time_millis()\n            registered_model.name = new_name\n            registered_model.last_updated_timestamp = updated_time\n            self._save_registered_model_as_meta_file(\n                registered_model, meta_dir=new_meta_dir, overwrite=False\n            )\n            model_versions = self._list_model_versions_under_path(model_path)\n            for mv in model_versions:\n                mv.name = new_name\n                mv.last_updated_timestamp = updated_time\n                new_model_version_dir = join(new_meta_dir, f\"version-{mv.version}\")\n                mkdir(new_model_version_dir)\n                self._save_model_version_as_meta_file(\n                    mv, meta_dir=new_model_version_dir, overwrite=False\n                )\n                if mv.tags is not None:\n                    for tag in mv.tags:\n                        self.set_model_version_tag(new_name, mv.version, tag)\n            shutil.rmtree(model_path)\n        else:\n            raise MlflowException(\n                f\"Registered Model (name={new_name}) already exists.\",\n                RESOURCE_ALREADY_EXISTS,\n            )\n\n        return registered_model\n\n    def delete_registered_model(self, name):\n        \"\"\"\n        Delete the registered model.\n        Backend raises exception if a registered model with given name does not exist.\n\n        :param name: Registered model name.\n        :return: None\n        \"\"\"\n        meta_dir = self._get_registered_model_path(name)\n        if not exists(meta_dir):\n            raise MlflowException(\n                f\"Registered Model with name={name} not found\",\n                RESOURCE_DOES_NOT_EXIST,\n            )\n        shutil.rmtree(meta_dir)\n\n    def list_registered_models(self, max_results, page_token):\n        \"\"\"\n        List of all registered models.\n\n        :param max_results: Maximum number of registered models desired.\n        :param page_token: Token specifying the next page of results. It should be obtained from\n                            a ``list_registered_models`` call.\n        :return: A PagedList of :py:class:`mlflow.entities.model_registry.RegisteredModel` objects\n                that satisfy the search expressions. The pagination token for the next page can be\n                obtained via the ``token`` attribute of the object.\n        \"\"\"\n        return self.search_registered_models(max_results=max_results, page_token=page_token)\n\n    def _list_all_registered_models(self):\n        registered_model_paths = self._get_all_registered_model_paths()\n        registered_models = []\n        for path in registered_model_paths:\n            registered_models.append(self._get_registered_model_from_path(path))\n        return registered_models\n\n    def search_registered_models(\n        self, filter_string=None, max_results=None, order_by=None, page_token=None\n    ):\n        \"\"\"\n        Search for registered models in backend that satisfy the filter criteria.\n\n        :param filter_string: Filter query string, defaults to searching all registered models.\n        :param max_results: Maximum number of registered models desired.\n        :param order_by: List of column names with ASC|DESC annotation, to be used for ordering\n                         matching search results.\n        :param page_token: Token specifying the next page of results. It should be obtained from\n                            a ``search_registered_models`` call.\n        :return: A PagedList of :py:class:`mlflow.entities.model_registry.RegisteredModel` objects\n                that satisfy the search expressions. The pagination token for the next page can be\n                obtained via the ``token`` attribute of the object.\n        \"\"\"\n        if not isinstance(max_results, int) or max_results < 1:\n            raise MlflowException(\n                \"Invalid value for max_results. It must be a positive integer,\"\n                f\" but got {max_results}\",\n                INVALID_PARAMETER_VALUE,\n            )\n\n        if max_results > SEARCH_REGISTERED_MODEL_MAX_RESULTS_THRESHOLD:\n            raise MlflowException(\n                \"Invalid value for request parameter max_results. It must be at most \"\n                f\"{SEARCH_REGISTERED_MODEL_MAX_RESULTS_THRESHOLD}, but got value {max_results}\",\n                INVALID_PARAMETER_VALUE,\n            )\n\n        registered_models = self._list_all_registered_models()\n        filtered_rms = SearchModelUtils.filter(registered_models, filter_string)\n        sorted_rms = SearchModelUtils.sort(filtered_rms, order_by)\n        start_offset = SearchUtils.parse_start_offset_from_page_token(page_token)\n        final_offset = start_offset + max_results\n\n        paginated_rms = sorted_rms[start_offset:final_offset]\n        next_page_token = None\n        if final_offset < len(sorted_rms):\n            next_page_token = SearchUtils.create_page_token(final_offset)\n        return PagedList(paginated_rms, next_page_token)\n\n    def get_registered_model(self, name):\n        \"\"\"\n        Get registered model instance by name.\n\n        :param name: Registered model name.\n        :return: A single :py:class:`mlflow.entities.model_registry.RegisteredModel` object.\n        \"\"\"\n        model_path = self._get_registered_model_path(name)\n        if not exists(model_path):\n            raise MlflowException(\n                f\"Registered Model with name={name} not found\",\n                RESOURCE_DOES_NOT_EXIST,\n            )\n        return self._get_registered_model_from_path(model_path)\n\n    def get_latest_versions(self, name, stages=None):\n        \"\"\"\n        Latest version models for each requested stage. If no ``stages`` argument is provided,\n        returns the latest version for each stage.\n\n        :param name: Registered model name.\n        :param stages: List of desired stages. If input list is None, return latest versions for\n                       each stage.\n        :return: List of :py:class:`mlflow.entities.model_registry.ModelVersion` objects.\n        \"\"\"\n        registered_model_path = self._get_registered_model_path(name)\n        if not exists(registered_model_path):\n            raise MlflowException(\n                f\"Registered Model with name={name} not found\",\n                RESOURCE_DOES_NOT_EXIST,\n            )\n        model_versions = self._list_model_versions_under_path(registered_model_path)\n        if stages is None or len(stages) == 0:\n            expected_stages = {get_canonical_stage(stage) for stage in ALL_STAGES}\n        else:\n            expected_stages = {get_canonical_stage(stage) for stage in stages}\n        latest_versions = {}\n        for mv in model_versions:\n            if mv.current_stage in expected_stages:\n                if (\n                    mv.current_stage not in latest_versions\n                    or latest_versions[mv.current_stage].version < mv.version\n                ):\n                    latest_versions[mv.current_stage] = mv\n\n        return [latest_versions[stage] for stage in expected_stages if stage in latest_versions]\n\n    def _get_registered_model_tag_path(self, name, tag_name):\n        _validate_model_name(name)\n        _validate_tag_name(tag_name)\n        registered_model_path = self._get_registered_model_path(name)\n        if not exists(registered_model_path):\n            raise MlflowException(\n                f\"Registered Model with name={name} not found\",\n                RESOURCE_DOES_NOT_EXIST,\n            )\n        return os.path.join(registered_model_path, FileStore.TAGS_FOLDER_NAME, tag_name)\n\n    def _get_registered_model_tag_from_file(self, parent_path, tag_name):\n        _validate_tag_name(tag_name)\n        tag_data = read_file(parent_path, tag_name)\n        return RegisteredModelTag(tag_name, tag_data)\n\n    def _get_resource_files(self, root_dir, subfolder_name):\n        source_dirs = find(root_dir, subfolder_name, full_path=True)\n        if len(source_dirs) == 0:\n            return root_dir, []\n        file_names = []\n        for root, _, files in os.walk(source_dirs[0]):\n            for name in files:\n                abspath = join(root, name)\n                file_names.append(os.path.relpath(abspath, source_dirs[0]))\n        if sys.platform == \"win32\":\n            # Turn registered models / model versions relative path into metric name.\n            # Registered models and model versions can have '/' in the name.\n            # On windows, '/' is interpreted as a separator.\n            # When the model / model version is read back the path will use '\\' for separator.\n            # We need to translate the path into posix path.\n            from mlflow.utils.file_utils import relative_path_to_artifact_path\n\n            file_names = [relative_path_to_artifact_path(x) for x in file_names]\n        return source_dirs[0], file_names\n\n    def get_all_registered_model_tags_from_path(self, model_path):\n        parent_path, tag_files = self._get_resource_files(model_path, FileStore.TAGS_FOLDER_NAME)\n        tags = []\n        for tag_file in tag_files:\n            tags.append(self._get_registered_model_tag_from_file(parent_path, tag_file))\n        return tags\n\n    def _writeable_value(self, tag_value):\n        if tag_value is None:\n            return \"\"\n        elif is_string_type(tag_value):\n            return tag_value\n        else:\n            return \"%s\" % tag_value\n\n    def set_registered_model_tag(self, name, tag):\n        \"\"\"\n        Set a tag for the registered model.\n\n        :param name: Registered model name.\n        :param tag: :py:class:`mlflow.entities.model_registry.RegisteredModelTag` instance to log.\n        :return: None\n        \"\"\"\n        _validate_registered_model_tag(tag.key, tag.value)\n        tag_path = self._get_registered_model_tag_path(name, tag.key)\n        make_containing_dirs(tag_path)\n        write_to(tag_path, self._writeable_value(tag.value))\n        updated_time = get_current_time_millis()\n        self._update_registered_model_last_updated_time(name, updated_time)\n\n    def delete_registered_model_tag(self, name, key):\n        \"\"\"\n        Delete a tag associated with the registered model.\n\n        :param name: Registered model name.\n        :param key: Registered model tag key.\n        :return: None\n        \"\"\"\n        tag_path = self._get_registered_model_tag_path(name, key)\n        if exists(tag_path):\n            os.remove(tag_path)\n            updated_time = get_current_time_millis()\n            self._update_registered_model_last_updated_time(name, updated_time)\n\n    # CRUD API for ModelVersion objects\n\n    def _get_registered_model_version_tag_from_file(self, parent_path, tag_name):\n        _validate_tag_name(tag_name)\n        tag_data = read_file(parent_path, tag_name)\n        return ModelVersionTag(tag_name, tag_data)\n\n    def _get_model_version_tags_from_dir(self, directory):\n        parent_path, tag_files = self._get_resource_files(directory, FileStore.TAGS_FOLDER_NAME)\n        tags = []\n        for tag_file in tag_files:\n            tags.append(self._get_registered_model_version_tag_from_file(parent_path, tag_file))\n        return tags\n\n    def _get_model_version_dir(self, name, version):\n        registered_model_path = self._get_registered_model_path(name)\n        if not exists(registered_model_path):\n            raise MlflowException(\n                f\"Registered Model with name={name} not found\",\n                RESOURCE_DOES_NOT_EXIST,\n            )\n        return join(registered_model_path, f\"version-{version}\")\n\n    def _get_model_version_from_dir(self, directory):\n        meta = FileStore._read_yaml(directory, FileStore.META_DATA_FILE_NAME)\n        meta[\"tags\"] = self._get_model_version_tags_from_dir(directory)\n        model_version = ModelVersion.from_dictionary(meta)\n        return model_version\n\n    def _save_model_version_as_meta_file(self, model_version, meta_dir=None, overwrite=True):\n        model_version_dict = dict(model_version)\n        del model_version_dict[\"tags\"]\n        meta_dir = meta_dir or self._get_model_version_dir(\n            model_version.name, model_version.version\n        )\n        if overwrite:\n            overwrite_yaml(\n                meta_dir,\n                FileStore.META_DATA_FILE_NAME,\n                model_version_dict,\n            )\n        else:\n            write_yaml(\n                meta_dir,\n                FileStore.META_DATA_FILE_NAME,\n                model_version_dict,\n            )\n\n    def create_model_version(\n        self, name, source, run_id=None, tags=None, run_link=None, description=None\n    ):\n        \"\"\"\n        Create a new model version from given source and run ID.\n\n        :param name: Registered model name.\n        :param source: Source path where the MLflow model is stored.\n        :param run_id: Run ID from MLflow tracking server that generated the model.\n        :param tags: A list of :py:class:`mlflow.entities.model_registry.ModelVersionTag`\n                     instances associated with this model version.\n        :param run_link: Link to the run from an MLflow tracking server that generated this model.\n        :param description: Description of the version.\n        :return: A single object of :py:class:`mlflow.entities.model_registry.ModelVersion`\n                 created in the backend.\n        \"\"\"\n\n        def next_version(registered_model_name):\n            path = self._get_registered_model_path(registered_model_name)\n            model_versions = self._list_model_versions_under_path(path)\n            if model_versions:\n                return max(mv.version for mv in model_versions) + 1\n            else:\n                return 1\n\n        _validate_model_name(name)\n        for tag in tags or []:\n            _validate_model_version_tag(tag.key, tag.value)\n        for attempt in range(self.CREATE_MODEL_VERSION_RETRIES):\n            try:\n                creation_time = get_current_time_millis()\n                registered_model = self.get_registered_model(name)\n                registered_model.last_updated_timestamp = creation_time\n                self._save_registered_model_as_meta_file(registered_model)\n                version = next_version(name)\n                model_version = ModelVersion(\n                    name=name,\n                    version=version,\n                    creation_timestamp=creation_time,\n                    last_updated_timestamp=creation_time,\n                    description=description,\n                    current_stage=STAGE_NONE,\n                    source=source,\n                    run_id=run_id,\n                    run_link=run_link,\n                    tags=tags,\n                )\n                model_version_dir = self._get_model_version_dir(name, version)\n                mkdir(model_version_dir)\n                self._save_model_version_as_meta_file(\n                    model_version, meta_dir=model_version_dir, overwrite=False\n                )\n                self._save_registered_model_as_meta_file(registered_model)\n                if tags is not None:\n                    for tag in tags:\n                        self.set_model_version_tag(name, version, tag)\n                return model_version\n            except Exception as e:\n                more_retries = self.CREATE_MODEL_VERSION_RETRIES - attempt - 1\n                logging.warning(\n                    \"Model Version creation error (name=%s) Retrying %s more time%s.\",\n                    name,\n                    str(more_retries),\n                    \"s\" if more_retries > 1 else \"\",\n                )\n                if more_retries == 0:\n                    raise MlflowException(\n                        \"Model Version creation error (name={}). Error: {}. Giving up after \"\n                        \"{} attempts.\".format(name, e, self.CREATE_MODEL_VERSION_RETRIES)\n                    )\n\n    def update_model_version(self, name, version, description):\n        \"\"\"\n        Update metadata associated with a model version in backend.\n\n        :param name: Registered model name.\n        :param version: Registered model version.\n        :param description: New model description.\n        :return: A single :py:class:`mlflow.entities.model_registry.ModelVersion` object.\n        \"\"\"\n        updated_time = get_current_time_millis()\n        model_version = self.get_model_version(name=name, version=version)\n        model_version.description = description\n        model_version.last_updated_timestamp = updated_time\n        self._save_model_version_as_meta_file(model_version)\n        return model_version\n\n    def transition_model_version_stage(self, name, version, stage, archive_existing_versions):\n        \"\"\"\n        Update model version stage.\n\n        :param name: Registered model name.\n        :param version: Registered model version.\n        :param stage: New desired stage for this model version.\n        :param archive_existing_versions: If this flag is set to ``True``, all existing model\n            versions in the stage will be automatically moved to the \"archived\" stage. Only valid\n            when ``stage`` is ``\"staging\"`` or ``\"production\"`` otherwise an error will be raised.\n\n        :return: A single :py:class:`mlflow.entities.model_registry.ModelVersion` object.\n        \"\"\"\n        is_active_stage = get_canonical_stage(stage) in DEFAULT_STAGES_FOR_GET_LATEST_VERSIONS\n        if archive_existing_versions and not is_active_stage:\n            msg_tpl = (\n                \"Model version transition cannot archive existing model versions \"\n                \"because '{}' is not an Active stage. Valid stages are {}\"\n            )\n            raise MlflowException(msg_tpl.format(stage, DEFAULT_STAGES_FOR_GET_LATEST_VERSIONS))\n\n        last_updated_time = get_current_time_millis()\n        model_versions = []\n        if archive_existing_versions:\n            registered_model_path = self._get_registered_model_path(name)\n            model_versions = self._list_model_versions_under_path(registered_model_path)\n            for mv in model_versions:\n                if mv.version != version and mv.current_stage == get_canonical_stage(stage):\n                    mv.current_stage = STAGE_ARCHIVED\n                    mv.last_updated_timestamp = last_updated_time\n                    self._save_model_version_as_meta_file(mv)\n\n        model_version = self.get_model_version(name, version)\n        model_version.current_stage = get_canonical_stage(stage)\n        model_version.last_updated_timestamp = last_updated_time\n        self._save_model_version_as_meta_file(model_version)\n        self._update_registered_model_last_updated_time(name, last_updated_time)\n        return model_version\n\n    def delete_model_version(self, name, version):\n        \"\"\"\n        Delete model version in backend.\n\n        :param name: Registered model name.\n        :param version: Registered model version.\n        :return: None\n        \"\"\"\n        model_version = self.get_model_version(name=name, version=version)\n        model_version.current_stage = STAGE_DELETED_INTERNAL\n        updated_time = get_current_time_millis()\n        model_version.last_updated_timestamp = updated_time\n        self._save_model_version_as_meta_file(model_version)\n        self._update_registered_model_last_updated_time(name, updated_time)\n\n    def get_model_version(self, name, version):\n        \"\"\"\n        Get the model version instance by name and version.\n\n        :param name: Registered model name.\n        :param version: Registered model version.\n        :return: A single :py:class:`mlflow.entities.model_registry.ModelVersion` object.\n        \"\"\"\n        _validate_model_name(name)\n        _validate_model_version(version)\n        registered_model_version_dir = self._get_model_version_dir(name, version)\n        if not exists(registered_model_version_dir):\n            raise MlflowException(\n                f\"Model Version (name={name}, version={version}) not found\",\n                RESOURCE_DOES_NOT_EXIST,\n            )\n        model_version = self._get_model_version_from_dir(registered_model_version_dir)\n        if model_version.current_stage == STAGE_DELETED_INTERNAL:\n            raise MlflowException(\n                f\"Model Version (name={name}, version={version}) not found\",\n                RESOURCE_DOES_NOT_EXIST,\n            )\n        return model_version\n\n    def get_model_version_download_uri(self, name, version):\n        \"\"\"\n        Get the download location in Model Registry for this model version.\n        NOTE: For first version of Model Registry, since the models are not copied over to another\n              location, download URI points to input source path.\n\n        :param name: Registered model name.\n        :param version: Registered model version.\n        :return: A single URI location that allows reads for downloading.\n        \"\"\"\n        model_version = self.get_model_version(name, version)\n        return model_version.source\n\n    def _get_all_registered_model_paths(self):\n        self._check_root_dir()\n        model_dirs = list_subdirs(\n            join(self.root_directory, FileStore.MODELS_FOLDER_NAME), full_path=True\n        )\n        return model_dirs\n\n    def _list_model_versions_under_path(self, path):\n        model_versions = []\n        model_version_dirs = list_all(\n            path,\n            filter_func=lambda x: os.path.isdir(x)\n            and os.path.basename(os.path.normpath(x)).startswith(\"version-\"),\n            full_path=True,\n        )\n        for directory in model_version_dirs:\n            model_versions.append(self._get_model_version_from_dir(directory))\n        return model_versions\n\n    def search_model_versions(\n        self, filter_string=None, max_results=None, order_by=None, page_token=None\n    ):\n        \"\"\"\n        Search for model versions in backend that satisfy the filter criteria.\n\n        :param filter_string: A filter string expression. Currently supports a single filter\n                              condition either name of model like ``name = 'model_name'`` or\n                              ``run_id = '...'``.\n        :param max_results: Maximum number of model versions desired.\n        :param order_by: List of column names with ASC|DESC annotation, to be used for ordering\n                         matching search results.\n        :param page_token: Token specifying the next page of results. It should be obtained from\n                            a ``search_model_versions`` call.\n        :return: A PagedList of :py:class:`mlflow.entities.model_registry.ModelVersion`\n                 objects that satisfy the search expressions. The pagination token for the next\n                 page can be obtained via the ``token`` attribute of the object.\n        \"\"\"\n        if not isinstance(max_results, int) or max_results < 1:\n            raise MlflowException(\n                \"Invalid value for max_results. It must be a positive integer,\"\n                f\" but got {max_results}\",\n                INVALID_PARAMETER_VALUE,\n            )\n\n        if max_results > SEARCH_MODEL_VERSION_MAX_RESULTS_THRESHOLD:\n            raise MlflowException(\n                \"Invalid value for request parameter max_results. It must be at most \"\n                f\"{SEARCH_MODEL_VERSION_MAX_RESULTS_THRESHOLD}, but got value {max_results}\",\n                INVALID_PARAMETER_VALUE,\n            )\n\n        registered_model_paths = self._get_all_registered_model_paths()\n        model_versions = []\n        for path in registered_model_paths:\n            model_versions.extend(self._list_model_versions_under_path(path))\n        filtered_mvs = SearchModelVersionUtils.filter(model_versions, filter_string)\n\n        sorted_mvs = SearchModelVersionUtils.sort(\n            filtered_mvs,\n            order_by or [\"last_updated_timestamp DESC\", \"name ASC\", \"version_number DESC\"],\n        )\n        start_offset = SearchUtils.parse_start_offset_from_page_token(page_token)\n        final_offset = start_offset + max_results\n\n        paginated_mvs = sorted_mvs[start_offset:final_offset]\n        next_page_token = None\n        if final_offset < len(sorted_mvs):\n            next_page_token = SearchUtils.create_page_token(final_offset)\n        return PagedList(paginated_mvs, next_page_token)\n\n    def _get_registered_model_version_tag_path(self, name, version, tag_name):\n        _validate_model_name(name)\n        _validate_model_version(version)\n        _validate_tag_name(tag_name)\n        registered_model_version_path = self._get_model_version_dir(name, version)\n        if not exists(registered_model_version_path):\n            raise MlflowException(\n                f\"Model Version (name={name}, version={version}) not found\",\n                RESOURCE_DOES_NOT_EXIST,\n            )\n        model_version = self._get_model_version_from_dir(registered_model_version_path)\n        if model_version.current_stage == STAGE_DELETED_INTERNAL:\n            raise MlflowException(\n                f\"Model Version (name={name}, version={version}) not found\",\n                RESOURCE_DOES_NOT_EXIST,\n            )\n        return os.path.join(registered_model_version_path, FileStore.TAGS_FOLDER_NAME, tag_name)\n\n    def set_model_version_tag(self, name, version, tag):\n        \"\"\"\n        Set a tag for the model version.\n\n        :param name: Registered model name.\n        :param version: Registered model version.\n        :param tag: :py:class:`mlflow.entities.model_registry.ModelVersionTag` instance to log.\n        :return: None\n        \"\"\"\n        _validate_model_version_tag(tag.key, tag.value)\n        tag_path = self._get_registered_model_version_tag_path(name, version, tag.key)\n        make_containing_dirs(tag_path)\n        write_to(tag_path, self._writeable_value(tag.value))\n        updated_time = get_current_time_millis()\n        self._update_registered_model_last_updated_time(name, updated_time)\n\n    def delete_model_version_tag(self, name, version, key):\n        \"\"\"\n        Delete a tag associated with the model version.\n\n        :param name: Registered model name.\n        :param version: Registered model version.\n        :param key: Tag key.\n        :return: None\n        \"\"\"\n        tag_path = self._get_registered_model_version_tag_path(name, version, key)\n        if exists(tag_path):\n            os.remove(tag_path)\n            updated_time = get_current_time_millis()\n            self._update_registered_model_last_updated_time(name, updated_time)\n\n    @staticmethod\n    def _read_yaml(root, file_name, retries=2):\n        \"\"\"\n        Read data from yaml file and return as dictionary, retrying up to\n        a specified number of times if the file contents are unexpectedly\n        empty due to a concurrent write.\n\n        :param root: Directory name.\n        :param file_name: File name. Expects to have '.yaml' extension.\n        :param retries: The number of times to retry for unexpected empty content.\n        :return: Data in yaml file as dictionary\n        \"\"\"\n\n        def _read_helper(root, file_name, attempts_remaining=2):\n            result = read_yaml(root, file_name)\n            if result is not None or attempts_remaining == 0:\n                return result\n            else:\n                time.sleep(0.1 * (3 - attempts_remaining))\n                return _read_helper(root, file_name, attempts_remaining - 1)\n\n        return _read_helper(root, file_name, attempts_remaining=retries)\n", "import codecs\nimport errno\nimport gzip\nimport os\nimport posixpath\nimport shutil\nimport sys\nimport tarfile\nimport tempfile\nimport stat\nimport pathlib\n\nimport urllib.parse\nimport urllib.request\nfrom urllib.parse import unquote\nfrom urllib.request import pathname2url\n\nimport atexit\n\nimport yaml\n\ntry:\n    from yaml import CSafeLoader as YamlSafeLoader, CSafeDumper as YamlSafeDumper\nexcept ImportError:\n    from yaml import SafeLoader as YamlSafeLoader, SafeDumper as YamlSafeDumper\n\nfrom mlflow.entities import FileInfo\nfrom mlflow.exceptions import MissingConfigException\nfrom mlflow.utils.rest_utils import cloud_storage_http_request, augmented_raise_for_status\nfrom mlflow.utils.process import cache_return_value_per_process\nfrom mlflow.utils import merge_dicts\nfrom mlflow.utils.databricks_utils import _get_dbutils\nfrom mlflow.utils.os import is_windows\n\nENCODING = \"utf-8\"\n\n\ndef is_directory(name):\n    return os.path.isdir(name)\n\n\ndef is_file(name):\n    return os.path.isfile(name)\n\n\ndef exists(name):\n    return os.path.exists(name)\n\n\ndef list_all(root, filter_func=lambda x: True, full_path=False):\n    \"\"\"\n    List all entities directly under 'dir_name' that satisfy 'filter_func'\n\n    :param root: Name of directory to start search\n    :param filter_func: function or lambda that takes path\n    :param full_path: If True will return results as full path including `root`\n\n    :return: list of all files or directories that satisfy the criteria.\n    \"\"\"\n    if not is_directory(root):\n        raise Exception(\"Invalid parent directory '%s'\" % root)\n    matches = [x for x in os.listdir(root) if filter_func(os.path.join(root, x))]\n    return [os.path.join(root, m) for m in matches] if full_path else matches\n\n\ndef list_subdirs(dir_name, full_path=False):\n    \"\"\"\n    Equivalent to UNIX command:\n      ``find $dir_name -depth 1 -type d``\n\n    :param dir_name: Name of directory to start search\n    :param full_path: If True will return results as full path including `root`\n\n    :return: list of all directories directly under 'dir_name'\n    \"\"\"\n    return list_all(dir_name, os.path.isdir, full_path)\n\n\ndef list_files(dir_name, full_path=False):\n    \"\"\"\n    Equivalent to UNIX command:\n      ``find $dir_name -depth 1 -type f``\n\n    :param dir_name: Name of directory to start search\n    :param full_path: If True will return results as full path including `root`\n\n    :return: list of all files directly under 'dir_name'\n    \"\"\"\n    return list_all(dir_name, os.path.isfile, full_path)\n\n\ndef find(root, name, full_path=False):\n    \"\"\"\n    Search for a file in a root directory. Equivalent to:\n      ``find $root -name \"$name\" -depth 1``\n\n    :param root: Name of root directory for find\n    :param name: Name of file or directory to find directly under root directory\n    :param full_path: If True will return results as full path including `root`\n\n    :return: list of matching files or directories\n    \"\"\"\n    path_name = os.path.join(root, name)\n    return list_all(root, lambda x: x == path_name, full_path)\n\n\ndef mkdir(root, name=None):\n    \"\"\"\n    Make directory with name \"root/name\", or just \"root\" if name is None.\n\n    :param root: Name of parent directory\n    :param name: Optional name of leaf directory\n\n    :return: Path to created directory\n    \"\"\"\n    target = os.path.join(root, name) if name is not None else root\n    try:\n        os.makedirs(target)\n    except OSError as e:\n        if e.errno != errno.EEXIST or not os.path.isdir(target):\n            raise e\n    return target\n\n\ndef make_containing_dirs(path):\n    \"\"\"\n    Create the base directory for a given file path if it does not exist; also creates parent\n    directories.\n    \"\"\"\n    dir_name = os.path.dirname(path)\n    if not os.path.exists(dir_name):\n        os.makedirs(dir_name)\n\n\ndef write_yaml(root, file_name, data, overwrite=False, sort_keys=True):\n    \"\"\"\n    Write dictionary data in yaml format.\n\n    :param root: Directory name.\n    :param file_name: Desired file name. Will automatically add .yaml extension if not given\n    :param data: data to be dumped as yaml format\n    :param overwrite: If True, will overwrite existing files\n    \"\"\"\n    if not exists(root):\n        raise MissingConfigException(\"Parent directory '%s' does not exist.\" % root)\n\n    file_path = os.path.join(root, file_name)\n    yaml_file_name = file_path if file_path.endswith(\".yaml\") else file_path + \".yaml\"\n\n    if exists(yaml_file_name) and not overwrite:\n        raise Exception(f\"Yaml file '{file_path}' exists as '{yaml_file_name}\")\n\n    try:\n        with codecs.open(yaml_file_name, mode=\"w\", encoding=ENCODING) as yaml_file:\n            yaml.dump(\n                data,\n                yaml_file,\n                default_flow_style=False,\n                allow_unicode=True,\n                sort_keys=sort_keys,\n                Dumper=YamlSafeDumper,\n            )\n    except Exception as e:\n        raise e\n\n\ndef overwrite_yaml(root, file_name, data):\n    \"\"\"\n    Safely overwrites a preexisting yaml file, ensuring that file contents are not deleted or\n    corrupted if the write fails. This is achieved by writing contents to a temporary file\n    and moving the temporary file to replace the preexisting file, rather than opening the\n    preexisting file for a direct write.\n\n    :param root: Directory name.\n    :param file_name: File name. Expects to have '.yaml' extension.\n    :param data: The data to write, represented as a dictionary.\n    \"\"\"\n    tmp_file_path = None\n    try:\n        tmp_file_fd, tmp_file_path = tempfile.mkstemp(suffix=\"file.yaml\")\n        os.close(tmp_file_fd)\n        write_yaml(\n            root=get_parent_dir(tmp_file_path),\n            file_name=os.path.basename(tmp_file_path),\n            data=data,\n            overwrite=True,\n            sort_keys=True,\n        )\n        shutil.move(\n            tmp_file_path,\n            os.path.join(root, file_name),\n        )\n    finally:\n        if tmp_file_path is not None and os.path.exists(tmp_file_path):\n            os.remove(tmp_file_path)\n\n\ndef read_yaml(root, file_name):\n    \"\"\"\n    Read data from yaml file and return as dictionary\n\n    :param root: Directory name\n    :param file_name: File name. Expects to have '.yaml' extension\n\n    :return: Data in yaml file as dictionary\n    \"\"\"\n    if not exists(root):\n        raise MissingConfigException(\n            f\"Cannot read '{file_name}'. Parent dir '{root}' does not exist.\"\n        )\n\n    file_path = os.path.join(root, file_name)\n    if not exists(file_path):\n        raise MissingConfigException(\"Yaml file '%s' does not exist.\" % file_path)\n    try:\n        with codecs.open(file_path, mode=\"r\", encoding=ENCODING) as yaml_file:\n            return yaml.load(yaml_file, Loader=YamlSafeLoader)\n    except Exception as e:\n        raise e\n\n\nclass UniqueKeyLoader(YamlSafeLoader):\n    def construct_mapping(self, node, deep=False):\n        mapping = set()\n        for key_node, _ in node.value:\n            key = self.construct_object(key_node, deep=deep)\n            if key in mapping:\n                raise ValueError(f\"Duplicate '{key}' key found in YAML.\")\n            mapping.add(key)\n        return super().construct_mapping(node, deep)\n\n\ndef render_and_merge_yaml(root, template_name, context_name):\n    \"\"\"\n    Renders a Jinja2-templated YAML file based on a YAML context file, merge them, and return\n    result as a dictionary.\n\n    :param root: Root directory of the YAML files\n    :param template_name: Name of the template file\n    :param context_name: Name of the context file\n    :return: Data in yaml file as dictionary\n    \"\"\"\n    import jinja2\n\n    template_path = os.path.join(root, template_name)\n    context_path = os.path.join(root, context_name)\n\n    for path in (template_path, context_path):\n        if not pathlib.Path(path).is_file():\n            raise MissingConfigException(\"Yaml file '%s' does not exist.\" % path)\n\n    j2_env = jinja2.Environment(\n        loader=jinja2.FileSystemLoader(root, encoding=ENCODING),\n        undefined=jinja2.StrictUndefined,\n        line_comment_prefix=\"#\",\n    )\n\n    def from_json(input_var):\n        import json\n\n        with open(input_var, encoding=\"utf-8\") as f:\n            return json.load(f)\n\n    j2_env.filters[\"from_json\"] = from_json\n    # Compute final source of context file (e.g. my-profile.yml), applying Jinja filters\n    # like from_json as needed to load context information from files, then load into a dict\n    context_source = j2_env.get_template(context_name).render({})\n    context_dict = yaml.load(context_source, Loader=UniqueKeyLoader) or {}\n\n    # Substitute parameters from context dict into template\n    source = j2_env.get_template(template_name).render(context_dict)\n    rendered_template_dict = yaml.load(source, Loader=UniqueKeyLoader)\n    return merge_dicts(rendered_template_dict, context_dict)\n\n\ndef read_parquet_as_pandas_df(data_parquet_path: str):\n    \"\"\"\n    Deserialize and load the specified parquet file as a Pandas DataFrame.\n\n    :param data_parquet_path: String, path object (implementing os.PathLike[str]),\n    or file-like object implementing a binary read() function. The string\n    could be a URL. Valid URL schemes include http, ftp, s3, gs, and file.\n    For file URLs, a host is expected. A local file could\n    be: file://localhost/path/to/table.parquet. A file URL can also be a path to a\n    directory that contains multiple partitioned parquet files. Pyarrow\n    support paths to directories as well as file URLs. A directory\n    path could be: file://localhost/path/to/tables or s3://bucket/partition_dir.\n    :return: pandas dataframe\n    \"\"\"\n    import pandas as pd\n\n    return pd.read_parquet(data_parquet_path, engine=\"pyarrow\")\n\n\ndef write_pandas_df_as_parquet(df, data_parquet_path: str):\n    \"\"\"\n    Write a DataFrame to the binary parquet format.\n\n    :param df: pandas data frame.\n    :param data_parquet_path: String, path object (implementing os.PathLike[str]),\n    or file-like object implementing a binary write() function.\n    \"\"\"\n    df.to_parquet(data_parquet_path, engine=\"pyarrow\")\n\n\nclass TempDir:\n    def __init__(self, chdr=False, remove_on_exit=True):\n        self._dir = None\n        self._path = None\n        self._chdr = chdr\n        self._remove = remove_on_exit\n\n    def __enter__(self):\n        self._path = os.path.abspath(tempfile.mkdtemp())\n        assert os.path.exists(self._path)\n        if self._chdr:\n            self._dir = os.path.abspath(os.getcwd())\n            os.chdir(self._path)\n        return self\n\n    def __exit__(self, tp, val, traceback):\n        if self._chdr and self._dir:\n            os.chdir(self._dir)\n            self._dir = None\n        if self._remove and os.path.exists(self._path):\n            shutil.rmtree(self._path)\n\n        assert not self._remove or not os.path.exists(self._path)\n        assert os.path.exists(os.getcwd())\n\n    def path(self, *path):\n        return os.path.join(\"./\", *path) if self._chdr else os.path.join(self._path, *path)\n\n\ndef read_file_lines(parent_path, file_name):\n    \"\"\"\n    Return the contents of the file as an array where each element is a separate line.\n\n    :param parent_path: Full path to the directory that contains the file.\n    :param file_name: Leaf file name.\n\n    :return: All lines in the file as an array.\n    \"\"\"\n    file_path = os.path.join(parent_path, file_name)\n    with codecs.open(file_path, mode=\"r\", encoding=ENCODING) as f:\n        return f.readlines()\n\n\ndef read_file(parent_path, file_name):\n    \"\"\"\n    Return the contents of the file.\n\n    :param parent_path: Full path to the directory that contains the file.\n    :param file_name: Leaf file name.\n\n    :return: The contents of the file.\n    \"\"\"\n    file_path = os.path.join(parent_path, file_name)\n    with codecs.open(file_path, mode=\"r\", encoding=ENCODING) as f:\n        return f.read()\n\n\ndef get_file_info(path, rel_path):\n    \"\"\"\n    Returns file meta data : location, size, ... etc\n\n    :param path: Path to artifact\n\n    :return: `FileInfo` object\n    \"\"\"\n    if is_directory(path):\n        return FileInfo(rel_path, True, None)\n    else:\n        return FileInfo(rel_path, False, os.path.getsize(path))\n\n\ndef get_relative_path(root_path, target_path):\n    \"\"\"\n    Remove root path common prefix and return part of `path` relative to `root_path`.\n\n    :param root_path: Root path\n    :param target_path: Desired path for common prefix removal\n\n    :return: Path relative to root_path\n    \"\"\"\n    if len(root_path) > len(target_path):\n        raise Exception(f\"Root path '{root_path}' longer than target path '{target_path}'\")\n    common_prefix = os.path.commonprefix([root_path, target_path])\n    return os.path.relpath(target_path, common_prefix)\n\n\ndef mv(target, new_parent):\n    shutil.move(target, new_parent)\n\n\ndef write_to(filename, data):\n    with codecs.open(filename, mode=\"w\", encoding=ENCODING) as handle:\n        handle.write(data)\n\n\ndef append_to(filename, data):\n    with open(filename, \"a\") as handle:\n        handle.write(data)\n\n\ndef make_tarfile(output_filename, source_dir, archive_name, custom_filter=None):\n    # Helper for filtering out modification timestamps\n    def _filter_timestamps(tar_info):\n        tar_info.mtime = 0\n        return tar_info if custom_filter is None else custom_filter(tar_info)\n\n    unzipped_file_handle, unzipped_filename = tempfile.mkstemp()\n    try:\n        with tarfile.open(unzipped_filename, \"w\") as tar:\n            tar.add(source_dir, arcname=archive_name, filter=_filter_timestamps)\n        # When gzipping the tar, don't include the tar's filename or modification time in the\n        # zipped archive (see https://docs.python.org/3/library/gzip.html#gzip.GzipFile)\n        with gzip.GzipFile(\n            filename=\"\", fileobj=open(output_filename, \"wb\"), mode=\"wb\", mtime=0\n        ) as gzipped_tar, open(unzipped_filename, \"rb\") as tar:\n            gzipped_tar.write(tar.read())\n    finally:\n        os.close(unzipped_file_handle)\n\n\ndef _copy_project(src_path, dst_path=\"\"):\n    \"\"\"\n    Internal function used to copy MLflow project during development.\n\n    Copies the content of the whole directory tree except patterns defined in .dockerignore.\n    The MLflow is assumed to be accessible as a local directory in this case.\n\n\n    :param dst_path: MLflow will be copied here\n    :return: name of the MLflow project directory\n    \"\"\"\n\n    def _docker_ignore(mlflow_root):\n        docker_ignore = os.path.join(mlflow_root, \".dockerignore\")\n        patterns = []\n        if os.path.exists(docker_ignore):\n            with open(docker_ignore) as f:\n                patterns = [x.strip() for x in f.readlines()]\n\n        def ignore(_, names):\n            import fnmatch\n\n            res = set()\n            for p in patterns:\n                res.update(set(fnmatch.filter(names, p)))\n            return list(res)\n\n        return ignore if patterns else None\n\n    mlflow_dir = \"mlflow-project\"\n    # check if we have project root\n    assert os.path.isfile(os.path.join(src_path, \"setup.py\")), \"file not found \" + str(\n        os.path.abspath(os.path.join(src_path, \"setup.py\"))\n    )\n    shutil.copytree(src_path, os.path.join(dst_path, mlflow_dir), ignore=_docker_ignore(src_path))\n    return mlflow_dir\n\n\ndef _copy_file_or_tree(src, dst, dst_dir=None):\n    \"\"\"\n    :return: The path to the copied artifacts, relative to `dst`\n    \"\"\"\n    dst_subpath = os.path.basename(os.path.abspath(src))\n    if dst_dir is not None:\n        dst_subpath = os.path.join(dst_dir, dst_subpath)\n    dst_path = os.path.join(dst, dst_subpath)\n    if os.path.isfile(src):\n        dst_dirpath = os.path.dirname(dst_path)\n        if not os.path.exists(dst_dirpath):\n            os.makedirs(dst_dirpath)\n        shutil.copy(src=src, dst=dst_path)\n    else:\n        shutil.copytree(src=src, dst=dst_path, ignore=shutil.ignore_patterns(\"__pycache__\"))\n    return dst_subpath\n\n\ndef _get_local_project_dir_size(project_path):\n    \"\"\"\n    Internal function for reporting the size of a local project directory before copying to\n    destination for cli logging reporting to stdout.\n    :param project_path: local path of the project directory\n    :return: directory file sizes in KB, rounded to single decimal point for legibility\n    \"\"\"\n\n    total_size = 0\n    for root, _, files in os.walk(project_path):\n        for f in files:\n            path = os.path.join(root, f)\n            total_size += os.path.getsize(path)\n    return round(total_size / 1024.0, 1)\n\n\ndef _get_local_file_size(file):\n    \"\"\"\n    Get the size of a local file in KB\n    \"\"\"\n    return round(os.path.getsize(file) / 1024.0, 1)\n\n\ndef get_parent_dir(path):\n    return os.path.abspath(os.path.join(path, os.pardir))\n\n\ndef relative_path_to_artifact_path(path):\n    if os.path == posixpath:\n        return path\n    if os.path.abspath(path) == path:\n        raise Exception(\"This method only works with relative paths.\")\n    return unquote(pathname2url(path))\n\n\ndef path_to_local_file_uri(path):\n    \"\"\"\n    Convert local filesystem path to local file uri.\n    \"\"\"\n    return pathlib.Path(os.path.abspath(path)).as_uri()\n\n\ndef path_to_local_sqlite_uri(path):\n    \"\"\"\n    Convert local filesystem path to sqlite uri.\n    \"\"\"\n    path = posixpath.abspath(pathname2url(os.path.abspath(path)))\n    prefix = \"sqlite://\" if sys.platform == \"win32\" else \"sqlite:///\"\n    return prefix + path\n\n\ndef local_file_uri_to_path(uri):\n    \"\"\"\n    Convert URI to local filesystem path.\n    No-op if the uri does not have the expected scheme.\n    \"\"\"\n    path = uri\n    if uri.startswith(\"file:\"):\n        parsed_path = urllib.parse.urlparse(uri)\n        path = parsed_path.path\n        # Fix for retaining server name in UNC path.\n        if is_windows() and parsed_path.netloc:\n            return urllib.request.url2pathname(rf\"\\\\{parsed_path.netloc}{path}\")\n    return urllib.request.url2pathname(path)\n\n\ndef get_local_path_or_none(path_or_uri):\n    \"\"\"Check if the argument is a local path (no scheme or file:///) and return local path if true,\n    None otherwise.\n    \"\"\"\n    parsed_uri = urllib.parse.urlparse(path_or_uri)\n    if len(parsed_uri.scheme) == 0 or parsed_uri.scheme == \"file\" and len(parsed_uri.netloc) == 0:\n        return local_file_uri_to_path(path_or_uri)\n    else:\n        return None\n\n\ndef yield_file_in_chunks(file, chunk_size=100000000):\n    \"\"\"\n    Generator to chunk-ify the inputted file based on the chunk-size.\n    \"\"\"\n    with open(file, \"rb\") as f:\n        while True:\n            chunk = f.read(chunk_size)\n            if chunk:\n                yield chunk\n            else:\n                break\n\n\ndef download_file_using_http_uri(http_uri, download_path, chunk_size=100000000, headers=None):\n    \"\"\"\n    Downloads a file specified using the `http_uri` to a local `download_path`. This function\n    uses a `chunk_size` to ensure an OOM error is not raised a large file is downloaded.\n\n    Note : This function is meant to download files using presigned urls from various cloud\n            providers.\n    \"\"\"\n    if headers is None:\n        headers = {}\n    with cloud_storage_http_request(\"get\", http_uri, stream=True, headers=headers) as response:\n        augmented_raise_for_status(response)\n        with open(download_path, \"wb\") as output_file:\n            for chunk in response.iter_content(chunk_size=chunk_size):\n                if not chunk:\n                    break\n                output_file.write(chunk)\n\n\ndef _handle_readonly_on_windows(func, path, exc_info):\n    \"\"\"\n    This function should not be called directly but should be passed to `onerror` of\n    `shutil.rmtree` in order to reattempt the removal of a read-only file after making\n    it writable on Windows.\n\n    References:\n    - https://bugs.python.org/issue19643\n    - https://bugs.python.org/issue43657\n    \"\"\"\n    exc_type, exc_value = exc_info[:2]\n    should_reattempt = (\n        os.name == \"nt\"\n        and func in (os.unlink, os.rmdir)\n        and issubclass(exc_type, PermissionError)\n        and exc_value.winerror == 5\n    )\n    if not should_reattempt:\n        raise exc_value\n    os.chmod(path, stat.S_IWRITE)\n    func(path)\n\n\n@cache_return_value_per_process\ndef get_or_create_tmp_dir():\n    \"\"\"\n    Get or create a temporary directory which will be removed once python process exit.\n    \"\"\"\n    from mlflow.utils.databricks_utils import is_in_databricks_runtime, get_repl_id\n\n    if is_in_databricks_runtime() and get_repl_id() is not None:\n        # Note: For python process attached to databricks notebook, atexit does not work.\n        # The directory returned by `dbutils.entry_point.getReplLocalTempDir()`\n        # will be removed once databricks notebook detaches.\n        # The temp directory is designed to be used by all kinds of applications,\n        # so create a child directory \"mlflow\" for storing mlflow temp data.\n        try:\n            repl_local_tmp_dir = _get_dbutils().entry_point.getReplLocalTempDir()\n        except Exception:\n            repl_local_tmp_dir = os.path.join(\"/tmp\", \"repl_tmp_data\", get_repl_id())\n\n        tmp_dir = os.path.join(repl_local_tmp_dir, \"mlflow\")\n        os.makedirs(tmp_dir, exist_ok=True)\n    else:\n        tmp_dir = tempfile.mkdtemp()\n        # mkdtemp creates a directory with permission 0o700\n        # change it to be 0o777 to ensure it can be seen in spark UDF\n        os.chmod(tmp_dir, 0o777)\n        atexit.register(shutil.rmtree, tmp_dir, ignore_errors=True)\n\n    return tmp_dir\n\n\n@cache_return_value_per_process\ndef get_or_create_nfs_tmp_dir():\n    \"\"\"\n    Get or create a temporary NFS directory which will be removed once python process exit.\n    \"\"\"\n    from mlflow.utils.databricks_utils import is_in_databricks_runtime, get_repl_id\n    from mlflow.utils.nfs_on_spark import get_nfs_cache_root_dir\n\n    nfs_root_dir = get_nfs_cache_root_dir()\n\n    if is_in_databricks_runtime() and get_repl_id() is not None:\n        # Note: In databricks, atexit hook does not work.\n        # The directory returned by `dbutils.entry_point.getReplNFSTempDir()`\n        # will be removed once databricks notebook detaches.\n        # The temp directory is designed to be used by all kinds of applications,\n        # so create a child directory \"mlflow\" for storing mlflow temp data.\n        try:\n            repl_nfs_tmp_dir = _get_dbutils().entry_point.getReplNFSTempDir()\n        except Exception:\n            repl_nfs_tmp_dir = os.path.join(nfs_root_dir, \"repl_tmp_data\", get_repl_id())\n\n        tmp_nfs_dir = os.path.join(repl_nfs_tmp_dir, \"mlflow\")\n        os.makedirs(tmp_nfs_dir, exist_ok=True)\n    else:\n        tmp_nfs_dir = tempfile.mkdtemp(dir=nfs_root_dir)\n        # mkdtemp creates a directory with permission 0o700\n        # change it to be 0o777 to ensure it can be seen in spark UDF\n        os.chmod(tmp_nfs_dir, 0o777)\n        atexit.register(shutil.rmtree, tmp_nfs_dir, ignore_errors=True)\n\n    return tmp_nfs_dir\n\n\ndef write_spark_dataframe_to_parquet_on_local_disk(spark_df, output_path):\n    \"\"\"\n    Write spark dataframe in parquet format to local disk.\n\n    :param spark_df: Spark dataframe\n    :param output_path: path to write the data to\n    \"\"\"\n    from mlflow.utils.databricks_utils import is_in_databricks_runtime\n    import uuid\n\n    if is_in_databricks_runtime():\n        dbfs_path = os.path.join(\".mlflow\", \"cache\", str(uuid.uuid4()))\n        spark_df.coalesce(1).write.format(\"parquet\").save(dbfs_path)\n        shutil.copytree(\"/dbfs/\" + dbfs_path, output_path)\n        shutil.rmtree(\"/dbfs/\" + dbfs_path)\n    else:\n        spark_df.coalesce(1).write.format(\"parquet\").save(output_path)\n\n\ndef shutil_copytree_without_file_permissions(src_dir, dst_dir):\n    \"\"\"\n    Copies the directory src_dir into dst_dir, without preserving filesystem permissions\n    \"\"\"\n    for dirpath, dirnames, filenames in os.walk(src_dir):\n        for dirname in dirnames:\n            relative_dir_path = os.path.relpath(os.path.join(dirpath, dirname), src_dir)\n            # For each directory <dirname> immediately under <dirpath>, create an equivalently-named\n            # directory under the destination directory\n            abs_dir_path = os.path.join(dst_dir, relative_dir_path)\n            os.mkdir(abs_dir_path)\n        for filename in filenames:\n            # For each file with name <filename> immediately under <dirpath>, copy that file to\n            # the appropriate location in the destination directory\n            file_path = os.path.join(dirpath, filename)\n            relative_file_path = os.path.relpath(file_path, src_dir)\n            abs_file_path = os.path.join(dst_dir, relative_file_path)\n            shutil.copyfile(file_path, abs_file_path)\n", "import time\nimport uuid\nfrom unittest import mock\nfrom typing import NamedTuple, List\n\nimport pytest\n\nfrom mlflow.entities.model_registry import ModelVersion, ModelVersionTag, RegisteredModelTag\nfrom mlflow.exceptions import MlflowException\nfrom mlflow.protos.databricks_pb2 import INVALID_PARAMETER_VALUE, RESOURCE_DOES_NOT_EXIST, ErrorCode\nfrom mlflow.store.model_registry.file_store import FileStore\nfrom mlflow.utils.file_utils import path_to_local_file_uri, write_yaml\nfrom mlflow.utils.time_utils import get_current_time_millis\nfrom tests.helper_functions import random_int, random_str\n\n\n@pytest.fixture\ndef store(tmp_path):\n    return FileStore(str(tmp_path))\n\n\n@pytest.fixture\ndef registered_model_names():\n    return [random_str() for _ in range(3)]\n\n\n@pytest.fixture\ndef rm_data(registered_model_names, tmp_path):\n    rm_data = {}\n    for name in registered_model_names:\n        # create registered model\n        rm_folder = tmp_path.joinpath(FileStore.MODELS_FOLDER_NAME, name)\n        rm_folder.mkdir(parents=True, exist_ok=True)\n        creation_time = get_current_time_millis()\n        d = {\n            \"name\": name,\n            \"creation_timestamp\": creation_time,\n            \"last_updated_timestamp\": creation_time,\n            \"description\": None,\n            \"latest_versions\": [],\n            \"tags\": {},\n        }\n        rm_data[name] = d\n        write_yaml(rm_folder, FileStore.META_DATA_FILE_NAME, d)\n        tags_dir = rm_folder.joinpath(FileStore.TAGS_FOLDER_NAME)\n        tags_dir.mkdir(parents=True, exist_ok=True)\n    return rm_data\n\n\ndef test_create_registered_model(store):\n    # Error cases\n    with pytest.raises(MlflowException, match=r\"Registered model name cannot be empty\\.\"):\n        store.create_registered_model(None)\n    with pytest.raises(MlflowException, match=r\"Registered model name cannot be empty\\.\"):\n        store.create_registered_model(\"\")\n\n    name = random_str()\n    model = store.create_registered_model(name)\n    assert model.name == name\n    assert model.latest_versions == []\n    assert model.creation_timestamp == model.last_updated_timestamp\n    assert model.tags == {}\n\n\ndef _verify_registered_model(fs, name, rm_data):\n    rm = fs.get_registered_model(name)\n    assert rm.name == name\n    assert rm.creation_timestamp == rm_data[name][\"creation_timestamp\"]\n    assert rm.last_updated_timestamp == rm_data[name][\"last_updated_timestamp\"]\n    assert rm.description == rm_data[name][\"description\"]\n    assert rm.latest_versions == rm_data[name][\"latest_versions\"]\n    assert rm.tags == rm_data[name][\"tags\"]\n\n\ndef test_get_registered_model(store, registered_model_names, rm_data):\n    for name in registered_model_names:\n        _verify_registered_model(store, name, rm_data)\n\n    # test that fake registered models dont exist.\n    name = random_str()\n    with pytest.raises(MlflowException, match=f\"Registered Model with name={name} not found\"):\n        store.get_registered_model(name)\n\n\ndef test_list_registered_model(store, registered_model_names, rm_data):\n    for rm in store.list_registered_models(max_results=10, page_token=None):\n        name = rm.name\n        assert name in registered_model_names\n        assert name == rm_data[name][\"name\"]\n\n\ndef test_rename_registered_model(store, registered_model_names, rm_data):\n    # Error cases\n    model_name = registered_model_names[0]\n    with pytest.raises(MlflowException, match=r\"Registered model name cannot be empty\\.\"):\n        store.rename_registered_model(model_name, None)\n\n    # test that names of existing registered models are checked before renaming\n    other_model_name = registered_model_names[1]\n    with pytest.raises(\n        MlflowException, match=rf\"Registered Model \\(name={other_model_name}\\) already exists\\.\"\n    ):\n        store.rename_registered_model(model_name, other_model_name)\n\n    new_name = model_name + \"!!!\"\n    store.rename_registered_model(model_name, new_name)\n    assert store.get_registered_model(new_name).name == new_name\n\n\ndef _extract_names(registered_models):\n    return [rm.name for rm in registered_models]\n\n\ndef test_delete_registered_model(store, registered_model_names, rm_data):\n    model_name = registered_model_names[random_int(0, len(registered_model_names) - 1)]\n\n    # Error cases\n    with pytest.raises(\n        MlflowException, match=f\"Registered Model with name={model_name}!!! not found\"\n    ):\n        store.delete_registered_model(model_name + \"!!!\")\n\n    store.delete_registered_model(model_name)\n    assert model_name not in _extract_names(\n        store.list_registered_models(max_results=10, page_token=None)\n    )\n    # Cannot delete a deleted model\n    with pytest.raises(MlflowException, match=f\"Registered Model with name={model_name} not found\"):\n        store.delete_registered_model(model_name)\n\n\ndef test_list_registered_model_paginated(store):\n    for _ in range(10):\n        store.create_registered_model(random_str())\n    rms1 = store.list_registered_models(max_results=4, page_token=None)\n    assert len(rms1) == 4\n    assert rms1.token is not None\n    rms2 = store.list_registered_models(max_results=4, page_token=None)\n    assert len(rms2) == 4\n    assert rms2.token is not None\n    assert rms1 == rms2\n    rms3 = store.list_registered_models(max_results=500, page_token=rms2.token)\n    assert len(rms3) == 6\n    assert rms3.token is None\n\n\ndef test_list_registered_model_paginated_returns_in_correct_order(store):\n    rms = [store.create_registered_model(f\"RM{i:03}\").name for i in range(50)]\n\n    # test that pagination will return all valid results in sorted order\n    # by name ascending\n    result = store.list_registered_models(max_results=5, page_token=None)\n    assert result.token is not None\n    assert _extract_names(result) == rms[0:5]\n\n    result = store.list_registered_models(page_token=result.token, max_results=10)\n    assert result.token is not None\n    assert _extract_names(result) == rms[5:15]\n\n    result = store.list_registered_models(page_token=result.token, max_results=20)\n    assert result.token is not None\n    assert _extract_names(result) == rms[15:35]\n\n    result = store.list_registered_models(page_token=result.token, max_results=100)\n    assert result.token is None\n    assert _extract_names(result) == rms[35:]\n\n\ndef test_list_registered_model_paginated_errors(store):\n    rms = [store.create_registered_model(f\"RM{i:03}\").name for i in range(50)]\n    # test that providing a completely invalid page token throws\n    with pytest.raises(\n        MlflowException, match=r\"Invalid page token, could not base64-decode\"\n    ) as exception_context:\n        store.list_registered_models(page_token=\"evilhax\", max_results=20)\n    assert exception_context.value.error_code == ErrorCode.Name(INVALID_PARAMETER_VALUE)\n\n    # test that providing too large of a max_results throws\n    with pytest.raises(\n        MlflowException, match=r\"Invalid value for max_results\"\n    ) as exception_context:\n        store.list_registered_models(page_token=\"evilhax\", max_results=1e15)\n    assert exception_context.value.error_code == ErrorCode.Name(INVALID_PARAMETER_VALUE)\n    # list should not return deleted models\n    store.delete_registered_model(name=\"RM000\")\n    assert set(\n        _extract_names(store.list_registered_models(max_results=100, page_token=None))\n    ) == set(rms[1:])\n\n\ndef _create_model_version(\n    fs,\n    name,\n    source=\"path/to/source\",\n    run_id=uuid.uuid4().hex,\n    tags=None,\n    run_link=None,\n    description=None,\n):\n    time.sleep(0.001)\n    return fs.create_model_version(\n        name, source, run_id, tags, run_link=run_link, description=description\n    )\n\n\ndef _stage_to_version_map(latest_versions):\n    return {mvd.current_stage: mvd.version for mvd in latest_versions}\n\n\ndef test_get_latest_versions(store):\n    name = \"test_for_latest_versions\"\n    rmd1 = store.create_registered_model(name)\n    assert rmd1.latest_versions == []\n\n    mv1 = _create_model_version(store, name)\n    assert mv1.version == 1\n    rmd2 = store.get_registered_model(name)\n    assert _stage_to_version_map(rmd2.latest_versions) == {\"None\": 1}\n\n    # add a bunch more\n    mv2 = _create_model_version(store, name)\n    assert mv2.version == 2\n    store.transition_model_version_stage(\n        name=mv2.name, version=mv2.version, stage=\"Production\", archive_existing_versions=False\n    )\n\n    mv3 = _create_model_version(store, name)\n    assert mv3.version == 3\n    store.transition_model_version_stage(\n        name=mv3.name, version=mv3.version, stage=\"Production\", archive_existing_versions=False\n    )\n    mv4 = _create_model_version(store, name)\n    assert mv4.version == 4\n    store.transition_model_version_stage(\n        name=mv4.name, version=mv4.version, stage=\"Staging\", archive_existing_versions=False\n    )\n\n    # test that correct latest versions are returned for each stage\n    rmd4 = store.get_registered_model(name)\n    assert _stage_to_version_map(rmd4.latest_versions) == {\n        \"None\": 1,\n        \"Production\": 3,\n        \"Staging\": 4,\n    }\n    assert _stage_to_version_map(store.get_latest_versions(name=name, stages=None)) == {\n        \"None\": 1,\n        \"Production\": 3,\n        \"Staging\": 4,\n    }\n    assert _stage_to_version_map(store.get_latest_versions(name=name, stages=[])) == {\n        \"None\": 1,\n        \"Production\": 3,\n        \"Staging\": 4,\n    }\n    assert _stage_to_version_map(store.get_latest_versions(name=name, stages=[\"Production\"])) == {\n        \"Production\": 3\n    }\n    assert _stage_to_version_map(store.get_latest_versions(name=name, stages=[\"production\"])) == {\n        \"Production\": 3\n    }  # The stages are case insensitive.\n    assert _stage_to_version_map(store.get_latest_versions(name=name, stages=[\"pROduction\"])) == {\n        \"Production\": 3\n    }  # The stages are case insensitive.\n    assert _stage_to_version_map(\n        store.get_latest_versions(name=name, stages=[\"None\", \"Production\"])\n    ) == {\"None\": 1, \"Production\": 3}\n\n    # delete latest Production, and should point to previous one\n    store.delete_model_version(name=mv3.name, version=mv3.version)\n    rmd5 = store.get_registered_model(name=name)\n    assert _stage_to_version_map(rmd5.latest_versions) == {\n        \"None\": 1,\n        \"Production\": 2,\n        \"Staging\": 4,\n    }\n    assert _stage_to_version_map(store.get_latest_versions(name=name, stages=None)) == {\n        \"None\": 1,\n        \"Production\": 2,\n        \"Staging\": 4,\n    }\n    assert _stage_to_version_map(store.get_latest_versions(name=name, stages=[\"Production\"])) == {\n        \"Production\": 2\n    }\n\n\ndef test_set_registered_model_tag(store):\n    name1 = \"SetRegisteredModelTag_TestMod\"\n    name2 = \"SetRegisteredModelTag_TestMod 2\"\n    initial_tags = [\n        RegisteredModelTag(\"key\", \"value\"),\n        RegisteredModelTag(\"anotherKey\", \"some other value\"),\n    ]\n    store.create_registered_model(name1, initial_tags)\n    store.create_registered_model(name2, initial_tags)\n    new_tag = RegisteredModelTag(\"randomTag\", \"not a random value\")\n    store.set_registered_model_tag(name1, new_tag)\n    rm1 = store.get_registered_model(name=name1)\n    all_tags = [*initial_tags, new_tag]\n    assert rm1.tags == {tag.key: tag.value for tag in all_tags}\n\n    # test overriding a tag with the same key\n    overriding_tag = RegisteredModelTag(\"key\", \"overriding\")\n    store.set_registered_model_tag(name1, overriding_tag)\n    all_tags = [tag for tag in all_tags if tag.key != \"key\"] + [overriding_tag]\n    rm1 = store.get_registered_model(name=name1)\n    assert rm1.tags == {tag.key: tag.value for tag in all_tags}\n    # does not affect other models with the same key\n    rm2 = store.get_registered_model(name=name2)\n    assert rm2.tags == {tag.key: tag.value for tag in initial_tags}\n\n    # can not set tag on deleted (non-existed) registered model\n    store.delete_registered_model(name1)\n    with pytest.raises(\n        MlflowException, match=f\"Registered Model with name={name1} not found\"\n    ) as exception_context:\n        store.set_registered_model_tag(name1, overriding_tag)\n    assert exception_context.value.error_code == ErrorCode.Name(RESOURCE_DOES_NOT_EXIST)\n    # test cannot set tags that are too long\n    long_tag = RegisteredModelTag(\"longTagKey\", \"a\" * 5001)\n    with pytest.raises(\n        MlflowException,\n        match=(r\"Registered model value '.+' had length \\d+, which exceeded length limit of 5000\"),\n    ) as exception_context:\n        store.set_registered_model_tag(name2, long_tag)\n    assert exception_context.value.error_code == ErrorCode.Name(INVALID_PARAMETER_VALUE)\n    # test can set tags that are somewhat long\n    long_tag = RegisteredModelTag(\"longTagKey\", \"a\" * 4999)\n    store.set_registered_model_tag(name2, long_tag)\n    # can not set invalid tag\n    with pytest.raises(MlflowException, match=r\"Tag name cannot be None\") as exception_context:\n        store.set_registered_model_tag(name2, RegisteredModelTag(key=None, value=\"\"))\n    assert exception_context.value.error_code == ErrorCode.Name(INVALID_PARAMETER_VALUE)\n    # can not use invalid model name\n    with pytest.raises(\n        MlflowException, match=r\"Registered model name cannot be empty\"\n    ) as exception_context:\n        store.set_registered_model_tag(None, RegisteredModelTag(key=\"key\", value=\"value\"))\n    assert exception_context.value.error_code == ErrorCode.Name(INVALID_PARAMETER_VALUE)\n\n\ndef test_delete_registered_model_tag(store):\n    name1 = \"DeleteRegisteredModelTag_TestMod\"\n    name2 = \"DeleteRegisteredModelTag_TestMod 2\"\n    initial_tags = [\n        RegisteredModelTag(\"key\", \"value\"),\n        RegisteredModelTag(\"anotherKey\", \"some other value\"),\n    ]\n    store.create_registered_model(name1, initial_tags)\n    store.create_registered_model(name2, initial_tags)\n    new_tag = RegisteredModelTag(\"randomTag\", \"not a random value\")\n    store.set_registered_model_tag(name1, new_tag)\n    store.delete_registered_model_tag(name1, \"randomTag\")\n    rm1 = store.get_registered_model(name=name1)\n    assert rm1.tags == {tag.key: tag.value for tag in initial_tags}\n\n    # testing deleting a key does not affect other models with the same key\n    store.delete_registered_model_tag(name1, \"key\")\n    rm1 = store.get_registered_model(name=name1)\n    rm2 = store.get_registered_model(name=name2)\n    assert rm1.tags == {\"anotherKey\": \"some other value\"}\n    assert rm2.tags == {tag.key: tag.value for tag in initial_tags}\n\n    # delete tag that is already deleted does nothing\n    store.delete_registered_model_tag(name1, \"key\")\n    rm1 = store.get_registered_model(name=name1)\n    assert rm1.tags == {\"anotherKey\": \"some other value\"}\n\n    # can not delete tag on deleted (non-existed) registered model\n    store.delete_registered_model(name1)\n    with pytest.raises(\n        MlflowException, match=f\"Registered Model with name={name1} not found\"\n    ) as exception_context:\n        store.delete_registered_model_tag(name1, \"anotherKey\")\n    assert exception_context.value.error_code == ErrorCode.Name(RESOURCE_DOES_NOT_EXIST)\n    # can not delete tag with invalid key\n    with pytest.raises(MlflowException, match=r\"Tag name cannot be None\") as exception_context:\n        store.delete_registered_model_tag(name2, None)\n    assert exception_context.value.error_code == ErrorCode.Name(INVALID_PARAMETER_VALUE)\n    # can not use invalid model name\n    with pytest.raises(\n        MlflowException, match=r\"Registered model name cannot be empty\"\n    ) as exception_context:\n        store.delete_registered_model_tag(None, \"key\")\n    assert exception_context.value.error_code == ErrorCode.Name(INVALID_PARAMETER_VALUE)\n\n\ndef test_create_model_version(store):\n    name = \"test_for_create_MV\"\n    store.create_registered_model(name)\n    run_id = uuid.uuid4().hex\n    with mock.patch(\"time.time\", return_value=456778):\n        mv1 = _create_model_version(store, name, \"a/b/CD\", run_id)\n        assert mv1.name == name\n        assert mv1.version == 1\n\n    mvd1 = store.get_model_version(mv1.name, mv1.version)\n    assert mvd1.name == name\n    assert mvd1.version == 1\n    assert mvd1.current_stage == \"None\"\n    assert mvd1.creation_timestamp == 456778000\n    assert mvd1.last_updated_timestamp == 456778000\n    assert mvd1.description is None\n    assert mvd1.source == \"a/b/CD\"\n    assert mvd1.run_id == run_id\n    assert mvd1.status == \"READY\"\n    assert mvd1.status_message is None\n    assert mvd1.tags == {}\n\n    # new model versions for same name autoincrement versions\n    mv2 = _create_model_version(store, name)\n    mvd2 = store.get_model_version(name=mv2.name, version=mv2.version)\n    assert mv2.version == 2\n    assert mvd2.version == 2\n\n    # create model version with tags return model version entity with tags\n    tags = [ModelVersionTag(\"key\", \"value\"), ModelVersionTag(\"anotherKey\", \"some other value\")]\n    mv3 = _create_model_version(store, name, tags=tags)\n    mvd3 = store.get_model_version(name=mv3.name, version=mv3.version)\n    assert mv3.version == 3\n    assert mv3.tags == {tag.key: tag.value for tag in tags}\n    assert mvd3.version == 3\n    assert mvd3.tags == {tag.key: tag.value for tag in tags}\n\n    # create model versions with runLink\n    run_link = \"http://localhost:3000/path/to/run/\"\n    mv4 = _create_model_version(store, name, run_link=run_link)\n    mvd4 = store.get_model_version(name, mv4.version)\n    assert mv4.version == 4\n    assert mv4.run_link == run_link\n    assert mvd4.version == 4\n    assert mvd4.run_link == run_link\n\n    # create model version with description\n    description = \"the best model ever\"\n    mv5 = _create_model_version(store, name, description=description)\n    mvd5 = store.get_model_version(name, mv5.version)\n    assert mv5.version == 5\n    assert mv5.description == description\n    assert mvd5.version == 5\n    assert mvd5.description == description\n\n    # create model version without runId\n    mv6 = _create_model_version(store, name, run_id=None)\n    mvd6 = store.get_model_version(name, mv6.version)\n    assert mv6.version == 6\n    assert mv6.run_id is None\n    assert mvd6.version == 6\n    assert mvd6.run_id is None\n\n\ndef test_update_model_version(store):\n    name = \"test_for_update_MV\"\n    store.create_registered_model(name)\n    mv1 = _create_model_version(store, name)\n    mvd1 = store.get_model_version(name=mv1.name, version=mv1.version)\n    assert mvd1.name == name\n    assert mvd1.version == 1\n    assert mvd1.current_stage == \"None\"\n\n    # update stage\n    store.transition_model_version_stage(\n        name=mv1.name, version=mv1.version, stage=\"Production\", archive_existing_versions=False\n    )\n    mvd2 = store.get_model_version(name=mv1.name, version=mv1.version)\n    assert mvd2.name == name\n    assert mvd2.version == 1\n    assert mvd2.current_stage == \"Production\"\n    assert mvd2.description is None\n\n    # update description\n    store.update_model_version(name=mv1.name, version=mv1.version, description=\"test model version\")\n    mvd3 = store.get_model_version(name=mv1.name, version=mv1.version)\n    assert mvd3.name == name\n    assert mvd3.version == 1\n    assert mvd3.current_stage == \"Production\"\n    assert mvd3.description == \"test model version\"\n\n    # only valid stages can be set\n    with pytest.raises(\n        MlflowException,\n        match=(\n            r\"Invalid Model Version stage: unknown\\. \"\n            r\"Value must be one of None, Staging, Production, Archived\\.\"\n        ),\n    ) as exception_context:\n        store.transition_model_version_stage(\n            mv1.name, mv1.version, stage=\"unknown\", archive_existing_versions=False\n        )\n    assert exception_context.value.error_code == ErrorCode.Name(INVALID_PARAMETER_VALUE)\n\n    # stages are case-insensitive and auto-corrected to system stage names\n    for stage_name in [\"STAGING\", \"staging\", \"StAgInG\"]:\n        store.transition_model_version_stage(\n            name=mv1.name,\n            version=mv1.version,\n            stage=stage_name,\n            archive_existing_versions=False,\n        )\n        mvd5 = store.get_model_version(name=mv1.name, version=mv1.version)\n        assert mvd5.current_stage == \"Staging\"\n\n\ndef test_transition_model_version_stage_when_archive_existing_versions_is_false(store):\n    name = \"model\"\n    store.create_registered_model(name)\n    mv1 = _create_model_version(store, name)\n    mv2 = _create_model_version(store, name)\n    mv3 = _create_model_version(store, name)\n\n    # test that when `archive_existing_versions` is False, transitioning a model version\n    # to the inactive stages (\"Archived\" and \"None\") does not throw.\n    for stage in [\"Archived\", \"None\"]:\n        store.transition_model_version_stage(name, mv1.version, stage, False)\n\n    store.transition_model_version_stage(name, mv1.version, \"Staging\", False)\n    store.transition_model_version_stage(name, mv2.version, \"Production\", False)\n    store.transition_model_version_stage(name, mv3.version, \"Staging\", False)\n\n    mvd1 = store.get_model_version(name=name, version=mv1.version)\n    mvd2 = store.get_model_version(name=name, version=mv2.version)\n    mvd3 = store.get_model_version(name=name, version=mv3.version)\n\n    assert mvd1.current_stage == \"Staging\"\n    assert mvd2.current_stage == \"Production\"\n    assert mvd3.current_stage == \"Staging\"\n\n    store.transition_model_version_stage(name, mv3.version, \"Production\", False)\n\n    mvd1 = store.get_model_version(name=name, version=mv1.version)\n    mvd2 = store.get_model_version(name=name, version=mv2.version)\n    mvd3 = store.get_model_version(name=name, version=mv3.version)\n\n    assert mvd1.current_stage == \"Staging\"\n    assert mvd2.current_stage == \"Production\"\n    assert mvd3.current_stage == \"Production\"\n\n\ndef test_transition_model_version_stage_when_archive_existing_versions_is_true(store):\n    name = \"model\"\n    store.create_registered_model(name)\n    mv1 = _create_model_version(store, name)\n    mv2 = _create_model_version(store, name)\n    mv3 = _create_model_version(store, name)\n\n    msg = (\n        r\"Model version transition cannot archive existing model versions \"\n        r\"because .+ is not an Active stage\"\n    )\n\n    # test that when `archive_existing_versions` is True, transitioning a model version\n    # to the inactive stages (\"Archived\" and \"None\") throws.\n    for stage in [\"Archived\", \"None\"]:\n        with pytest.raises(MlflowException, match=msg):\n            store.transition_model_version_stage(name, mv1.version, stage, True)\n\n    store.transition_model_version_stage(name, mv1.version, \"Staging\", False)\n    store.transition_model_version_stage(name, mv2.version, \"Production\", False)\n    store.transition_model_version_stage(name, mv3.version, \"Staging\", True)\n\n    mvd1 = store.get_model_version(name=name, version=mv1.version)\n    mvd2 = store.get_model_version(name=name, version=mv2.version)\n    mvd3 = store.get_model_version(name=name, version=mv3.version)\n\n    assert mvd1.current_stage == \"Archived\"\n    assert mvd2.current_stage == \"Production\"\n    assert mvd3.current_stage == \"Staging\"\n    assert mvd1.last_updated_timestamp == mvd3.last_updated_timestamp\n\n    store.transition_model_version_stage(name, mv3.version, \"Production\", True)\n\n    mvd1 = store.get_model_version(name=name, version=mv1.version)\n    mvd2 = store.get_model_version(name=name, version=mv2.version)\n    mvd3 = store.get_model_version(name=name, version=mv3.version)\n\n    assert mvd1.current_stage == \"Archived\"\n    assert mvd2.current_stage == \"Archived\"\n    assert mvd3.current_stage == \"Production\"\n    assert mvd2.last_updated_timestamp == mvd3.last_updated_timestamp\n\n    for uncanonical_stage_name in [\"STAGING\", \"staging\", \"StAgInG\"]:\n        store.transition_model_version_stage(mv1.name, mv1.version, \"Staging\", False)\n        store.transition_model_version_stage(mv2.name, mv2.version, \"None\", False)\n\n        # stage names are case-insensitive and auto-corrected to system stage names\n        store.transition_model_version_stage(mv2.name, mv2.version, uncanonical_stage_name, True)\n\n        mvd1 = store.get_model_version(name=mv1.name, version=mv1.version)\n        mvd2 = store.get_model_version(name=mv2.name, version=mv2.version)\n        assert mvd1.current_stage == \"Archived\"\n        assert mvd2.current_stage == \"Staging\"\n\n\ndef test_delete_model_version(store):\n    name = \"test_for_delete_MV\"\n    initial_tags = [\n        ModelVersionTag(\"key\", \"value\"),\n        ModelVersionTag(\"anotherKey\", \"some other value\"),\n    ]\n    store.create_registered_model(name)\n    mv = _create_model_version(store, name, tags=initial_tags)\n    mvd = store.get_model_version(name=mv.name, version=mv.version)\n    assert mvd.name == name\n\n    store.delete_model_version(name=mv.name, version=mv.version)\n\n    # cannot get a deleted model version\n    with pytest.raises(\n        MlflowException,\n        match=rf\"Model Version \\(name={mv.name}, version={mv.version}\\) not found\",\n    ) as exception_context:\n        store.get_model_version(name=mv.name, version=mv.version)\n    assert exception_context.value.error_code == ErrorCode.Name(RESOURCE_DOES_NOT_EXIST)\n\n    # cannot update a delete\n    with pytest.raises(\n        MlflowException,\n        match=rf\"Model Version \\(name={mv.name}, version={mv.version}\\) not found\",\n    ) as exception_context:\n        store.update_model_version(mv.name, mv.version, description=\"deleted!\")\n    assert exception_context.value.error_code == ErrorCode.Name(RESOURCE_DOES_NOT_EXIST)\n\n    # cannot delete it again\n    with pytest.raises(\n        MlflowException,\n        match=rf\"Model Version \\(name={mv.name}, version={mv.version}\\) not found\",\n    ) as exception_context:\n        store.delete_model_version(name=mv.name, version=mv.version)\n    assert exception_context.value.error_code == ErrorCode.Name(RESOURCE_DOES_NOT_EXIST)\n\n\ndef _search_model_versions(fs, filter_string=None, max_results=10, order_by=None, page_token=None):\n    return fs.search_model_versions(\n        filter_string=filter_string,\n        max_results=max_results,\n        order_by=order_by,\n        page_token=page_token,\n    )\n\n\ndef test_search_model_versions(store):\n    # create some model versions\n    name = \"test_for_search_MV\"\n    store.create_registered_model(name)\n    run_id_1 = uuid.uuid4().hex\n    run_id_2 = uuid.uuid4().hex\n    run_id_3 = uuid.uuid4().hex\n    mv1 = _create_model_version(store, name=name, source=\"A/B\", run_id=run_id_1)\n    assert mv1.version == 1\n    mv2 = _create_model_version(store, name=name, source=\"A/C\", run_id=run_id_2)\n    assert mv2.version == 2\n    mv3 = _create_model_version(store, name=name, source=\"A/D\", run_id=run_id_2)\n    assert mv3.version == 3\n    mv4 = _create_model_version(store, name=name, source=\"A/D\", run_id=run_id_3)\n    assert mv4.version == 4\n\n    def search_versions(filter_string):\n        return [mvd.version for mvd in _search_model_versions(store, filter_string)]\n\n    # search using name should return all 4 versions\n    assert set(search_versions(\"name='%s'\" % name)) == {1, 2, 3, 4}\n\n    # search using version\n    assert set(search_versions(\"version_number=2\")) == {2}\n    assert set(search_versions(\"version_number<=3\")) == {1, 2, 3}\n\n    # search using run_id_1 should return version 1\n    assert set(search_versions(f\"run_id='{run_id_1}'\")) == {1}\n\n    # search using run_id_2 should return versions 2 and 3\n    assert set(search_versions(f\"run_id='{run_id_2}'\")) == {2, 3}\n\n    # search using the IN operator should return all versions\n    assert set(search_versions(f\"run_id IN ('{run_id_1}','{run_id_2}')\")) == {1, 2, 3}\n\n    # search IN operator is case sensitive\n    assert set(search_versions(f\"run_id IN ('{run_id_1.upper()}','{run_id_2}')\")) == {2, 3}\n\n    # search IN operator with right-hand side value containing whitespaces\n    assert set(search_versions(f\"run_id IN ('{run_id_1}', '{run_id_2}')\")) == {1, 2, 3}\n\n    # search using the IN operator with bad lists should return exceptions\n    with pytest.raises(\n        MlflowException,\n        match=(\n            r\"While parsing a list in the query, \"\n            r\"expected string value, punctuation, or whitespace, \"\n            r\"but got different type in list\"\n        ),\n    ) as exception_context:\n        search_versions(\"run_id IN (1,2,3)\")\n    assert exception_context.value.error_code == ErrorCode.Name(INVALID_PARAMETER_VALUE)\n\n    assert set(search_versions(f\"run_id LIKE '{run_id_2[:30]}%'\")) == {2, 3}\n\n    assert set(search_versions(f\"run_id ILIKE '{run_id_2[:30].upper()}%'\")) == {2, 3}\n\n    # search using the IN operator with empty lists should return exceptions\n    with pytest.raises(\n        MlflowException,\n        match=(\n            r\"While parsing a list in the query, \"\n            r\"expected a non-empty list of string values, \"\n            r\"but got empty list\"\n        ),\n    ) as exception_context:\n        search_versions(\"run_id IN ()\")\n    assert exception_context.value.error_code == ErrorCode.Name(INVALID_PARAMETER_VALUE)\n\n    # search using an ill-formed IN operator correctly throws exception\n    with pytest.raises(\n        MlflowException, match=r\"Invalid clause\\(s\\) in filter string\"\n    ) as exception_context:\n        search_versions(\"run_id IN (\")\n    assert exception_context.value.error_code == ErrorCode.Name(INVALID_PARAMETER_VALUE)\n\n    with pytest.raises(\n        MlflowException, match=r\"Invalid clause\\(s\\) in filter string\"\n    ) as exception_context:\n        search_versions(\"run_id IN\")\n    assert exception_context.value.error_code == ErrorCode.Name(INVALID_PARAMETER_VALUE)\n\n    with pytest.raises(\n        MlflowException, match=r\"Invalid clause\\(s\\) in filter string\"\n    ) as exception_context:\n        search_versions(\"name LIKE\")\n    assert exception_context.value.error_code == ErrorCode.Name(INVALID_PARAMETER_VALUE)\n\n    with pytest.raises(\n        MlflowException,\n        match=(\n            r\"While parsing a list in the query, \"\n            r\"expected a non-empty list of string values, \"\n            r\"but got ill-formed list\"\n        ),\n    ) as exception_context:\n        search_versions(\"run_id IN (,)\")\n    assert exception_context.value.error_code == ErrorCode.Name(INVALID_PARAMETER_VALUE)\n\n    with pytest.raises(\n        MlflowException,\n        match=(\n            r\"While parsing a list in the query, \"\n            r\"expected a non-empty list of string values, \"\n            r\"but got ill-formed list\"\n        ),\n    ) as exception_context:\n        search_versions(\"run_id IN ('runid1',,'runid2')\")\n    assert exception_context.value.error_code == ErrorCode.Name(INVALID_PARAMETER_VALUE)\n\n    # search using source_path \"A/D\" should return version 3 and 4\n    assert set(search_versions(\"source_path = 'A/D'\")) == {3, 4}\n\n    # search using source_path \"A\" should not return anything\n    assert len(search_versions(\"source_path = 'A'\")) == 0\n    assert len(search_versions(\"source_path = 'A/'\")) == 0\n    assert len(search_versions(\"source_path = ''\")) == 0\n\n    # delete mv4. search should not return version 4\n    store.delete_model_version(name=mv4.name, version=mv4.version)\n    assert set(search_versions(\"\")) == {1, 2, 3}\n\n    assert set(search_versions(None)) == {1, 2, 3}\n\n    assert set(search_versions(f\"name='{name}'\")) == {1, 2, 3}\n\n    store.transition_model_version_stage(\n        name=mv1.name, version=mv1.version, stage=\"production\", archive_existing_versions=False\n    )\n\n    store.update_model_version(\n        name=mv1.name, version=mv1.version, description=\"Online prediction model!\"\n    )\n\n    mvds = store.search_model_versions(\"run_id = '%s'\" % run_id_1, max_results=10)\n    assert len(mvds) == 1\n    assert isinstance(mvds[0], ModelVersion)\n    assert mvds[0].current_stage == \"Production\"\n    assert mvds[0].run_id == run_id_1\n    assert mvds[0].source == \"A/B\"\n    assert mvds[0].description == \"Online prediction model!\"\n\n\ndef test_search_model_versions_order_by_simple(store):\n    # create some model versions\n    names = [\"RM1\", \"RM2\", \"RM3\", \"RM4\", \"RM1\", \"RM4\"]\n    sources = [\"A\"] * 3 + [\"B\"] * 3\n    run_ids = [uuid.uuid4().hex for _ in range(6)]\n    for name in set(names):\n        store.create_registered_model(name)\n    for i in range(6):\n        _create_model_version(store, name=names[i], source=sources[i], run_id=run_ids[i])\n        time.sleep(0.001)  # sleep for windows fs timestamp precision issues\n\n    # by default order by last_updated_timestamp DESC\n    mvs = _search_model_versions(store).to_list()\n    assert [mv.name for mv in mvs] == names[::-1]\n    assert [mv.version for mv in mvs] == [2, 2, 1, 1, 1, 1]\n\n    # order by name DESC\n    mvs = _search_model_versions(store, order_by=[\"name DESC\"])\n    assert [mv.name for mv in mvs] == sorted(names)[::-1]\n    assert [mv.version for mv in mvs] == [2, 1, 1, 1, 2, 1]\n\n    # order by version DESC\n    mvs = _search_model_versions(store, order_by=[\"version_number DESC\"])\n    assert [mv.name for mv in mvs] == [\"RM1\", \"RM4\", \"RM1\", \"RM2\", \"RM3\", \"RM4\"]\n    assert [mv.version for mv in mvs] == [2, 2, 1, 1, 1, 1]\n\n    # order by creation_timestamp DESC\n    mvs = _search_model_versions(store, order_by=[\"creation_timestamp DESC\"])\n    assert [mv.name for mv in mvs] == names[::-1]\n    assert [mv.version for mv in mvs] == [2, 2, 1, 1, 1, 1]\n\n    # order by last_updated_timestamp ASC\n    store.update_model_version(names[0], 1, \"latest updated\")\n    mvs = _search_model_versions(store, order_by=[\"last_updated_timestamp ASC\"])\n    assert mvs[-1].name == names[0]\n    assert mvs[-1].version == 1\n\n\ndef test_search_model_versions_pagination(store):\n    def search_versions(filter_string, page_token=None, max_results=10):\n        result = _search_model_versions(\n            store, filter_string=filter_string, page_token=page_token, max_results=max_results\n        )\n        return result.to_list(), result.token\n\n    name = \"test_for_search_MV_pagination\"\n    store.create_registered_model(name)\n    mvs = [_create_model_version(store, name) for _ in range(50)][::-1]\n\n    # test flow with fixed max_results\n    returned_mvs = []\n    query = \"name LIKE 'test_for_search_MV_pagination%'\"\n    result, token = search_versions(query, page_token=None, max_results=5)\n    returned_mvs.extend(result)\n    while token:\n        result, token = search_versions(query, page_token=token, max_results=5)\n        returned_mvs.extend(result)\n    assert mvs == returned_mvs\n\n    # test that pagination will return all valid results in sorted order\n    # by name ascending\n    result, token1 = search_versions(query, max_results=5)\n    assert token1 is not None\n    assert result == mvs[0:5]\n\n    result, token2 = search_versions(query, page_token=token1, max_results=10)\n    assert token2 is not None\n    assert result == mvs[5:15]\n\n    result, token3 = search_versions(query, page_token=token2, max_results=20)\n    assert token3 is not None\n    assert result == mvs[15:35]\n\n    result, token4 = search_versions(query, page_token=token3, max_results=100)\n    # assert that page token is None\n    assert token4 is None\n    assert result == mvs[35:]\n\n    # test that providing a completely invalid page token throws\n    with pytest.raises(\n        MlflowException, match=r\"Invalid page token, could not base64-decode\"\n    ) as exception_context:\n        search_versions(query, page_token=\"evilhax\", max_results=20)\n    assert exception_context.value.error_code == ErrorCode.Name(INVALID_PARAMETER_VALUE)\n\n    # test that providing too large of a max_results throws\n    with pytest.raises(\n        MlflowException, match=r\"Invalid value for max_results.\"\n    ) as exception_context:\n        search_versions(query, page_token=\"evilhax\", max_results=1e15)\n    assert exception_context.value.error_code == ErrorCode.Name(INVALID_PARAMETER_VALUE)\n\n\ndef test_search_model_versions_by_tag(store):\n    # create some model versions\n    name = \"test_for_search_MV_by_tag\"\n    store.create_registered_model(name)\n    run_id_1 = uuid.uuid4().hex\n    run_id_2 = uuid.uuid4().hex\n\n    mv1 = _create_model_version(\n        store,\n        name=name,\n        source=\"A/B\",\n        run_id=run_id_1,\n        tags=[ModelVersionTag(\"t1\", \"abc\"), ModelVersionTag(\"t2\", \"xyz\")],\n    )\n    assert mv1.version == 1\n    mv2 = _create_model_version(\n        store,\n        name=name,\n        source=\"A/C\",\n        run_id=run_id_2,\n        tags=[ModelVersionTag(\"t1\", \"abc\"), ModelVersionTag(\"t2\", \"x123\")],\n    )\n    assert mv2.version == 2\n\n    def search_versions(filter_string):\n        return [mvd.version for mvd in _search_model_versions(store, filter_string)]\n\n    assert search_versions(f\"name = '{name}' and tag.t2 = 'xyz'\") == [1]\n    assert search_versions(\"name = 'wrong_name' and tag.t2 = 'xyz'\") == []\n    assert search_versions(\"tag.`t2` = 'xyz'\") == [1]\n    assert search_versions(\"tag.t3 = 'xyz'\") == []\n    assert set(search_versions(\"tag.t2 != 'xy'\")) == {2, 1}\n    assert search_versions(\"tag.t2 LIKE 'xy%'\") == [1]\n    assert search_versions(\"tag.t2 LIKE 'xY%'\") == []\n    assert search_versions(\"tag.t2 ILIKE 'xY%'\") == [1]\n    assert set(search_versions(\"tag.t2 LIKE 'x%'\")) == {2, 1}\n    assert search_versions(\"tag.T2 = 'xyz'\") == []\n    assert search_versions(\"tag.t1 = 'abc' and tag.t2 = 'xyz'\") == [1]\n    assert set(search_versions(\"tag.t1 = 'abc' and tag.t2 LIKE 'x%'\")) == {2, 1}\n    assert search_versions(\"tag.t1 = 'abc' and tag.t2 LIKE 'y%'\") == []\n    # test filter with duplicated keys\n    assert search_versions(\"tag.t2 like 'x%' and tag.t2 != 'xyz'\") == [2]\n\n\nclass SearchRegisteredModelsResult(NamedTuple):\n    names: List[str]\n    token: str\n\n\ndef _search_registered_models(\n    store, filter_string=None, max_results=10, order_by=None, page_token=None\n):\n    result = store.search_registered_models(\n        filter_string=filter_string,\n        max_results=max_results,\n        order_by=order_by,\n        page_token=page_token,\n    )\n    return SearchRegisteredModelsResult(\n        names=[registered_model.name for registered_model in result],\n        token=result.token,\n    )\n\n\ndef test_search_registered_models(store):\n    # create some registered models\n    prefix = \"test_for_search_\"\n    names = [prefix + name for name in [\"RM1\", \"RM2\", \"RM3\", \"RM4\", \"RM4A\", \"RM4ab\"]]\n    for name in names:\n        store.create_registered_model(name)\n\n    # search with no filter should return all registered models\n    res = _search_registered_models(store, None)\n    assert res.names == names\n\n    # equality search using name should return exactly the 1 name\n    res = _search_registered_models(store, f\"name='{names[0]}'\")\n    assert res.names == [names[0]]\n\n    # equality search using name that is not valid should return nothing\n    res = _search_registered_models(store, f\"name='{names[0]}cats'\")\n    assert res.names == []\n\n    # case-sensitive prefix search using LIKE should return all the RMs\n    res = _search_registered_models(store, f\"name LIKE '{prefix}%'\")\n    assert res.names == names\n\n    # case-sensitive prefix search using LIKE with surrounding % should return all the RMs\n    res = _search_registered_models(store, \"name LIKE '%RM%'\")\n    assert res.names == names\n\n    # case-sensitive prefix search using LIKE with surrounding % should return all the RMs\n    # _e% matches test_for_search_ , so all RMs should match\n    res = _search_registered_models(store, \"name LIKE '_e%'\")\n    assert res.names == names\n\n    # case-sensitive prefix search using LIKE should return just rm4\n    res = _search_registered_models(store, f\"name LIKE '{prefix}RM4A%'\")\n    assert res.names == [names[4]]\n\n    # case-sensitive prefix search using LIKE should return no models if no match\n    res = _search_registered_models(store, f\"name LIKE '{prefix}cats%'\")\n    assert res.names == []\n\n    # confirm that LIKE is not case-sensitive\n    res = _search_registered_models(store, \"name lIkE '%blah%'\")\n    assert res.names == []\n\n    res = _search_registered_models(store, f\"name like '{prefix}RM4A%'\")\n    assert res.names == [names[4]]\n\n    # case-insensitive prefix search using ILIKE should return both rm5 and rm6\n    res = _search_registered_models(store, f\"name ILIKE '{prefix}RM4A%'\")\n    assert res.names == names[4:]\n\n    # case-insensitive postfix search with ILIKE\n    res = _search_registered_models(store, \"name ILIKE '%RM4a%'\")\n    assert res.names == names[4:]\n\n    # case-insensitive prefix search using ILIKE should return both rm5 and rm6\n    res = _search_registered_models(store, f\"name ILIKE '{prefix}cats%'\")\n    assert res.names == []\n\n    # confirm that ILIKE is not case-sensitive\n    res = _search_registered_models(store, \"name iLike '%blah%'\")\n    assert res.names == []\n\n    # confirm that ILIKE works for empty query\n    res = _search_registered_models(store, \"name iLike '%%'\")\n    assert res.names == names\n\n    res = _search_registered_models(store, \"name ilike '%RM4a%'\")\n    assert res.names == names[4:]\n\n    # cannot search by invalid comparator types\n    with pytest.raises(\n        MlflowException,\n        match=\"Parameter value is either not quoted or unidentified quote types used for \"\n        \"string value something\",\n    ) as exception_context:\n        _search_registered_models(store, \"name!=something\")\n    assert exception_context.value.error_code == ErrorCode.Name(INVALID_PARAMETER_VALUE)\n\n    # cannot search by run_id\n    with pytest.raises(\n        MlflowException,\n        match=r\"Invalid attribute key 'run_id' specified. Valid keys are '{'name'}'\",\n    ) as exception_context:\n        _search_registered_models(store, \"run_id='somerunID'\")\n    assert exception_context.value.error_code == ErrorCode.Name(INVALID_PARAMETER_VALUE)\n\n    # cannot search by source_path\n    with pytest.raises(\n        MlflowException,\n        match=r\"Invalid attribute key 'source_path' specified\\. Valid keys are '{'name'}'\",\n    ) as exception_context:\n        _search_registered_models(store, \"source_path = 'A/D'\")\n    assert exception_context.value.error_code == ErrorCode.Name(INVALID_PARAMETER_VALUE)\n\n    # cannot search by other params\n    with pytest.raises(\n        MlflowException, match=r\"Invalid clause\\(s\\) in filter string\"\n    ) as exception_context:\n        _search_registered_models(store, \"evilhax = true\")\n    assert exception_context.value.error_code == ErrorCode.Name(INVALID_PARAMETER_VALUE)\n\n    # delete last registered model. search should not return the first 5\n    store.delete_registered_model(name=names[-1])\n    res = _search_registered_models(store, None, max_results=1000)\n    assert res.names == names[:-1]\n    assert res.token is None\n\n    # equality search using name should return no names\n    assert _search_registered_models(store, f\"name='{names[-1]}'\") == ([], None)\n\n    # case-sensitive prefix search using LIKE should return all the RMs\n    res = _search_registered_models(store, f\"name LIKE '{prefix}%'\")\n    assert res.names == names[0:5]\n    assert res.token is None\n\n    # case-insensitive prefix search using ILIKE should return both rm5 and rm6\n    res = _search_registered_models(store, f\"name ILIKE '{prefix}RM4A%'\")\n    assert res.names == [names[4]]\n    assert res.token is None\n\n\ndef test_search_registered_models_by_tag(store):\n    name1 = \"test_for_search_RM_by_tag1\"\n    name2 = \"test_for_search_RM_by_tag2\"\n    tags1 = [\n        RegisteredModelTag(\"t1\", \"abc\"),\n        RegisteredModelTag(\"t2\", \"xyz\"),\n    ]\n    tags2 = [\n        RegisteredModelTag(\"t1\", \"abcd\"),\n        RegisteredModelTag(\"t2\", \"xyz123\"),\n        RegisteredModelTag(\"t3\", \"XYZ\"),\n    ]\n    store.create_registered_model(name1, tags1)\n    store.create_registered_model(name2, tags2)\n\n    res = _search_registered_models(store, \"tag.t3 = 'XYZ'\")\n    assert res.names == [name2]\n\n    res = _search_registered_models(store, f\"name = '{name1}' and tag.t1 = 'abc'\")\n    assert res.names == [name1]\n\n    res = _search_registered_models(store, \"tag.t1 LIKE 'ab%'\")\n    assert res.names == [name1, name2]\n\n    res = _search_registered_models(store, \"tag.t1 ILIKE 'aB%'\")\n    assert res.names == [name1, name2]\n\n    res = _search_registered_models(store, \"tag.t1 LIKE 'ab%' AND tag.t2 LIKE 'xy%'\")\n    assert res.names == [name1, name2]\n\n    res = _search_registered_models(store, \"tag.t3 = 'XYz'\")\n    assert res.names == []\n\n    res = _search_registered_models(store, \"tag.T3 = 'XYZ'\")\n    assert res.names == []\n\n    res = _search_registered_models(store, \"tag.t1 != 'abc'\")\n    assert res.names == [name2]\n\n    # test filter with duplicated keys\n    res = _search_registered_models(store, \"tag.t1 != 'abcd' and tag.t1 LIKE 'ab%'\")\n    assert res.names == [name1]\n\n\ndef test_search_registered_models_order_by_simple(store):\n    # create some registered models\n    names = [\"RM1\", \"RM2\", \"RM3\", \"RM4\", \"RM4A\", \"RM4ab\"]\n    for name in names:\n        store.create_registered_model(name)\n        time.sleep(0.001)  # sleep for windows store timestamp precision issues\n\n    # by default order by name ASC\n    res = _search_registered_models(store)\n    assert res.names == names\n\n    # order by name DESC\n    res = _search_registered_models(store, order_by=[\"name DESC\"])\n    assert res.names == names[::-1]\n\n    # order by last_updated_timestamp ASC\n    store.update_registered_model(names[0], \"latest updated\")\n    res = _search_registered_models(store, order_by=[\"last_updated_timestamp ASC\"])\n    assert res.names[-1] == names[0]\n\n\ndef test_search_registered_model_pagination(store):\n    rms = [store.create_registered_model(f\"RM{i:03}\").name for i in range(50)]\n\n    # test flow with fixed max_results\n    returned_rms = []\n    query = \"name LIKE 'RM%'\"\n    res = _search_registered_models(store, query, page_token=None, max_results=5)\n    returned_rms.extend(res.names)\n    while res.token:\n        res = _search_registered_models(store, query, page_token=res.token, max_results=5)\n        returned_rms.extend(res.names)\n    assert returned_rms == rms\n\n    # test that pagination will return all valid results in sorted order\n    # by name ascending\n    res = _search_registered_models(store, query, max_results=5)\n    assert res.token is not None\n    assert res.names == rms[0:5]\n\n    res = _search_registered_models(store, query, page_token=res.token, max_results=10)\n    assert res.token is not None\n    assert res.names == rms[5:15]\n\n    res = _search_registered_models(store, query, page_token=res.token, max_results=20)\n    assert res.token is not None\n    assert res.names == rms[15:35]\n\n    res = _search_registered_models(store, query, page_token=res.token, max_results=100)\n    # assert that page token is None\n    assert res.token is None\n    assert res.names == rms[35:]\n\n    # test that providing a completely invalid page token throws\n    with pytest.raises(\n        MlflowException, match=r\"Invalid page token, could not base64-decode\"\n    ) as exception_context:\n        _search_registered_models(store, query, page_token=\"evilhax\", max_results=20)\n    assert exception_context.value.error_code == ErrorCode.Name(INVALID_PARAMETER_VALUE)\n\n    # test that providing too large of a max_results throws\n    with pytest.raises(\n        MlflowException, match=r\"Invalid value for max_results.\"\n    ) as exception_context:\n        _search_registered_models(store, query, page_token=\"evilhax\", max_results=1e15)\n    assert exception_context.value.error_code == ErrorCode.Name(INVALID_PARAMETER_VALUE)\n\n\ndef test_search_registered_model_order_by(store):\n    rms = []\n    # explicitly mock the creation_timestamps because timestamps seem to be unstable in Windows\n    for i in range(50):\n        rms.append(store.create_registered_model(f\"RM{i:03}\").name)\n        time.sleep(0.01)\n\n    # test flow with fixed max_results and order_by (test stable order across pages)\n    returned_rms = []\n    query = \"name LIKE 'RM%'\"\n    result, token = _search_registered_models(\n        store, query, page_token=None, order_by=[\"name DESC\"], max_results=5\n    )\n    returned_rms.extend(result)\n    while token:\n        result, token = _search_registered_models(\n            store, query, page_token=token, order_by=[\"name DESC\"], max_results=5\n        )\n        returned_rms.extend(result)\n    # name descending should be the opposite order of the current order\n    assert returned_rms == rms[::-1]\n    # last_updated_timestamp descending should have the newest RMs first\n    res = _search_registered_models(\n        store, query, page_token=None, order_by=[\"last_updated_timestamp DESC\"], max_results=100\n    )\n    assert res.names == rms[::-1]\n    # last_updated_timestamp ascending should have the oldest RMs first\n    res = _search_registered_models(\n        store, query, page_token=None, order_by=[\"last_updated_timestamp ASC\"], max_results=100\n    )\n    assert res.names == rms\n    # name ascending should have the original order\n    res = _search_registered_models(\n        store, query, page_token=None, order_by=[\"name ASC\"], max_results=100\n    )\n    assert res.names == rms\n    # test that no ASC/DESC defaults to ASC\n    res = _search_registered_models(\n        store, query, page_token=None, order_by=[\"last_updated_timestamp\"], max_results=100\n    )\n    assert res.names == rms\n    with mock.patch(\n        \"mlflow.store.model_registry.file_store.get_current_time_millis\", return_value=1\n    ):\n        rm1 = store.create_registered_model(\"MR1\").name\n        rm2 = store.create_registered_model(\"MR2\").name\n    with mock.patch(\n        \"mlflow.store.model_registry.file_store.get_current_time_millis\", return_value=2\n    ):\n        rm3 = store.create_registered_model(\"MR3\").name\n        rm4 = store.create_registered_model(\"MR4\").name\n    query = \"name LIKE 'MR%'\"\n    # test with multiple clauses\n    res = _search_registered_models(\n        store,\n        query,\n        page_token=None,\n        order_by=[\"last_updated_timestamp ASC\", \"name DESC\"],\n        max_results=100,\n    )\n    assert res.names == [rm2, rm1, rm4, rm3]\n    # confirm that name ascending is the default, even if ties exist on other fields\n    res = _search_registered_models(store, query, page_token=None, order_by=[], max_results=100)\n    assert res.names == [rm1, rm2, rm3, rm4]\n    # test default tiebreak with descending timestamps\n    res = _search_registered_models(\n        store, query, page_token=None, order_by=[\"last_updated_timestamp DESC\"], max_results=100\n    )\n    assert res.names == [rm3, rm4, rm1, rm2]\n\n\ndef test_search_registered_model_order_by_errors(store):\n    store.create_registered_model(\"dummy\")\n    query = \"name LIKE 'RM%'\"\n    # test that invalid columns throw even if they come after valid columns\n    with pytest.raises(\n        MlflowException, match=\"Invalid attribute key 'description' specified.\"\n    ) as exception_context:\n        _search_registered_models(\n            store,\n            query,\n            page_token=None,\n            order_by=[\"name ASC\", \"description DESC\"],\n            max_results=5,\n        )\n    assert exception_context.value.error_code == ErrorCode.Name(INVALID_PARAMETER_VALUE)\n    # test that invalid columns with random text throw even if they come after valid columns\n    with pytest.raises(MlflowException, match=r\"Invalid order_by clause '.+'\") as exception_context:\n        _search_registered_models(\n            store,\n            query,\n            page_token=None,\n            order_by=[\"name ASC\", \"last_updated_timestamp DESC blah\"],\n            max_results=5,\n        )\n    assert exception_context.value.error_code == ErrorCode.Name(INVALID_PARAMETER_VALUE)\n\n\ndef test_set_model_version_tag(store):\n    name1 = \"SetModelVersionTag_TestMod\"\n    name2 = \"SetModelVersionTag_TestMod 2\"\n    initial_tags = [\n        ModelVersionTag(\"key\", \"value\"),\n        ModelVersionTag(\"anotherKey\", \"some other value\"),\n    ]\n    store.create_registered_model(name1)\n    store.create_registered_model(name2)\n    run_id_1 = uuid.uuid4().hex\n    run_id_2 = uuid.uuid4().hex\n    run_id_3 = uuid.uuid4().hex\n    store.create_model_version(name1, \"A/B\", run_id_1, initial_tags)\n    store.create_model_version(name1, \"A/C\", run_id_2, initial_tags)\n    store.create_model_version(name2, \"A/D\", run_id_3, initial_tags)\n    new_tag = ModelVersionTag(\"randomTag\", \"not a random value\")\n    store.set_model_version_tag(name1, 1, new_tag)\n    all_tags = [*initial_tags, new_tag]\n    rm1mv1 = store.get_model_version(name1, 1)\n    assert rm1mv1.tags == {tag.key: tag.value for tag in all_tags}\n\n    # test overriding a tag with the same key\n    overriding_tag = ModelVersionTag(\"key\", \"overriding\")\n    store.set_model_version_tag(name1, 1, overriding_tag)\n    all_tags = [tag for tag in all_tags if tag.key != \"key\"] + [overriding_tag]\n    rm1mv1 = store.get_model_version(name1, 1)\n    assert rm1mv1.tags == {tag.key: tag.value for tag in all_tags}\n    # does not affect other model versions with the same key\n    rm1mv2 = store.get_model_version(name1, 2)\n    rm2mv1 = store.get_model_version(name2, 1)\n    assert rm1mv2.tags == {tag.key: tag.value for tag in initial_tags}\n    assert rm2mv1.tags == {tag.key: tag.value for tag in initial_tags}\n\n    # can not set tag on deleted (non-existed) model version\n    store.delete_model_version(name1, 2)\n    with pytest.raises(\n        MlflowException, match=rf\"Model Version \\(name={name1}, version=2\\) not found\"\n    ) as exception_context:\n        store.set_model_version_tag(name1, 2, overriding_tag)\n    assert exception_context.value.error_code == ErrorCode.Name(RESOURCE_DOES_NOT_EXIST)\n    # test cannot set tags that are too long\n    long_tag = ModelVersionTag(\"longTagKey\", \"a\" * 5001)\n    with pytest.raises(\n        MlflowException,\n        match=r\"Model version value '.+' had length \\d+, which exceeded length limit of 5000\",\n    ) as exception_context:\n        store.set_model_version_tag(name1, 1, long_tag)\n    assert exception_context.value.error_code == ErrorCode.Name(INVALID_PARAMETER_VALUE)\n    # test can set tags that are somewhat long\n    long_tag = ModelVersionTag(\"longTagKey\", \"a\" * 4999)\n    store.set_model_version_tag(name1, 1, long_tag)\n    # can not set invalid tag\n    with pytest.raises(MlflowException, match=r\"Tag name cannot be None\") as exception_context:\n        store.set_model_version_tag(name2, 1, ModelVersionTag(key=None, value=\"\"))\n    assert exception_context.value.error_code == ErrorCode.Name(INVALID_PARAMETER_VALUE)\n    # can not use invalid model name or version\n    with pytest.raises(\n        MlflowException, match=r\"Registered model name cannot be empty\"\n    ) as exception_context:\n        store.set_model_version_tag(None, 1, ModelVersionTag(key=\"key\", value=\"value\"))\n    assert exception_context.value.error_code == ErrorCode.Name(INVALID_PARAMETER_VALUE)\n    with pytest.raises(\n        MlflowException, match=r\"Model version must be an integer\"\n    ) as exception_context:\n        store.set_model_version_tag(\n            name2, \"I am not a version\", ModelVersionTag(key=\"key\", value=\"value\")\n        )\n    assert exception_context.value.error_code == ErrorCode.Name(INVALID_PARAMETER_VALUE)\n\n\ndef test_delete_model_version_tag(store):\n    name1 = \"DeleteModelVersionTag_TestMod\"\n    name2 = \"DeleteModelVersionTag_TestMod 2\"\n    initial_tags = [\n        ModelVersionTag(\"key\", \"value\"),\n        ModelVersionTag(\"anotherKey\", \"some other value\"),\n    ]\n    store.create_registered_model(name1)\n    store.create_registered_model(name2)\n    run_id_1 = uuid.uuid4().hex\n    run_id_2 = uuid.uuid4().hex\n    run_id_3 = uuid.uuid4().hex\n    store.create_model_version(name1, \"A/B\", run_id_1, initial_tags)\n    store.create_model_version(name1, \"A/C\", run_id_2, initial_tags)\n    store.create_model_version(name2, \"A/D\", run_id_3, initial_tags)\n    new_tag = ModelVersionTag(\"randomTag\", \"not a random value\")\n    store.set_model_version_tag(name1, 1, new_tag)\n    store.delete_model_version_tag(name1, 1, \"randomTag\")\n    rm1mv1 = store.get_model_version(name1, 1)\n    assert rm1mv1.tags == {tag.key: tag.value for tag in initial_tags}\n\n    # testing deleting a key does not affect other model versions with the same key\n    store.delete_model_version_tag(name1, 1, \"key\")\n    rm1mv1 = store.get_model_version(name1, 1)\n    rm1mv2 = store.get_model_version(name1, 2)\n    rm2mv1 = store.get_model_version(name2, 1)\n    assert rm1mv1.tags == {\"anotherKey\": \"some other value\"}\n    assert rm1mv2.tags == {tag.key: tag.value for tag in initial_tags}\n    assert rm2mv1.tags == {tag.key: tag.value for tag in initial_tags}\n\n    # delete tag that is already deleted does nothing\n    store.delete_model_version_tag(name1, 1, \"key\")\n    rm1mv1 = store.get_model_version(name1, 1)\n    assert rm1mv1.tags == {\"anotherKey\": \"some other value\"}\n\n    # can not delete tag on deleted (non-existed) model version\n    store.delete_model_version(name2, 1)\n    with pytest.raises(\n        MlflowException, match=rf\"Model Version \\(name={name2}, version=1\\) not found\"\n    ) as exception_context:\n        store.delete_model_version_tag(name2, 1, \"key\")\n    assert exception_context.value.error_code == ErrorCode.Name(RESOURCE_DOES_NOT_EXIST)\n    # can not delete tag with invalid key\n    with pytest.raises(MlflowException, match=r\"Tag name cannot be None\") as exception_context:\n        store.delete_model_version_tag(name1, 2, None)\n    assert exception_context.value.error_code == ErrorCode.Name(INVALID_PARAMETER_VALUE)\n    # can not use invalid model name or version\n    with pytest.raises(\n        MlflowException, match=r\"Registered model name cannot be empty\"\n    ) as exception_context:\n        store.delete_model_version_tag(None, 2, \"key\")\n    assert exception_context.value.error_code == ErrorCode.Name(INVALID_PARAMETER_VALUE)\n    with pytest.raises(\n        MlflowException, match=r\"Model version must be an integer\"\n    ) as exception_context:\n        store.delete_model_version_tag(name1, \"I am not a version\", \"key\")\n    assert exception_context.value.error_code == ErrorCode.Name(INVALID_PARAMETER_VALUE)\n\n\ndef test_pyfunc_model_registry_with_file_store(store):\n    import mlflow\n    from mlflow.pyfunc import PythonModel\n\n    class MyModel(PythonModel):\n        def predict(self, context, model_input):\n            return 7\n\n    mlflow.set_registry_uri(path_to_local_file_uri(store.root_directory))\n    with mlflow.start_run():\n        mlflow.pyfunc.log_model(\n            python_model=MyModel(), artifact_path=\"foo\", registered_model_name=\"model1\"\n        )\n        mlflow.pyfunc.log_model(\n            python_model=MyModel(), artifact_path=\"foo\", registered_model_name=\"model2\"\n        )\n        mlflow.pyfunc.log_model(\n            python_model=MyModel(), artifact_path=\"foo\", registered_model_name=\"model1\"\n        )\n\n    with mlflow.start_run():\n        mlflow.log_param(\"A\", \"B\")\n\n        models = store.search_registered_models(max_results=10)\n        assert len(models) == 2\n        assert models[0].name == \"model1\"\n        assert models[1].name == \"model2\"\n        mv1 = store.search_model_versions(\"name = 'model1'\", max_results=10)\n        assert len(mv1) == 2\n        assert mv1[0].name == \"model1\"\n        mv2 = store.search_model_versions(\"name = 'model2'\", max_results=10)\n        assert len(mv2) == 1 and mv2[0].name == \"model2\"\n"], "fixing_code": ["import logging\nimport os\nfrom os.path import join\nimport shutil\nimport sys\nimport time\n\nfrom mlflow.entities.model_registry import (\n    RegisteredModel,\n    ModelVersion,\n    RegisteredModelTag,\n    ModelVersionTag,\n)\nfrom mlflow.entities.model_registry.model_version_stages import (\n    get_canonical_stage,\n    ALL_STAGES,\n    DEFAULT_STAGES_FOR_GET_LATEST_VERSIONS,\n    STAGE_ARCHIVED,\n    STAGE_NONE,\n    STAGE_DELETED_INTERNAL,\n)\nfrom mlflow.exceptions import MlflowException\nfrom mlflow.protos.databricks_pb2 import (\n    INVALID_PARAMETER_VALUE,\n    RESOURCE_ALREADY_EXISTS,\n    RESOURCE_DOES_NOT_EXIST,\n)\nfrom mlflow.store.entities.paged_list import PagedList\nfrom mlflow.store.model_registry.abstract_store import AbstractStore\nfrom mlflow.store.model_registry import (\n    DEFAULT_LOCAL_FILE_AND_ARTIFACT_PATH,\n    SEARCH_REGISTERED_MODEL_MAX_RESULTS_THRESHOLD,\n    SEARCH_MODEL_VERSION_MAX_RESULTS_THRESHOLD,\n)\nfrom mlflow.utils.search_utils import SearchUtils, SearchModelUtils, SearchModelVersionUtils\nfrom mlflow.utils.string_utils import is_string_type\nfrom mlflow.utils.validation import (\n    _validate_registered_model_tag,\n    _validate_model_version_tag,\n    _validate_model_name as _original_validate_model_name,\n    _validate_model_version,\n    _validate_tag_name,\n)\nfrom mlflow.utils.env import get_env\nfrom mlflow.utils.file_utils import (\n    is_directory,\n    list_subdirs,\n    mkdir,\n    exists,\n    write_yaml,\n    overwrite_yaml,\n    read_yaml,\n    find,\n    read_file,\n    write_to,\n    make_containing_dirs,\n    list_all,\n    local_file_uri_to_path,\n    contains_path_separator,\n)\nfrom mlflow.utils.time_utils import get_current_time_millis\n\n\n_REGISTRY_DIR_ENV_VAR = \"MLFLOW_REGISTRY_DIR\"\n\n\ndef _default_root_dir():\n    return get_env(_REGISTRY_DIR_ENV_VAR) or os.path.abspath(DEFAULT_LOCAL_FILE_AND_ARTIFACT_PATH)\n\n\ndef _validate_model_name(name):\n    _original_validate_model_name(name)\n    if contains_path_separator(name):\n        raise MlflowException(\n            f\"Invalid name: '{name}'. Registered model name cannot contain path separator\",\n            INVALID_PARAMETER_VALUE,\n        )\n\n\nclass FileStore(AbstractStore):\n    MODELS_FOLDER_NAME = \"models\"\n    META_DATA_FILE_NAME = \"meta.yaml\"\n    TAGS_FOLDER_NAME = \"tags\"\n    MODEL_VERSION_TAGS_FOLDER_NAME = \"tags\"\n    CREATE_MODEL_VERSION_RETRIES = 3\n\n    def __init__(self, root_directory=None):\n        \"\"\"\n        Create a new FileStore with the given root directory.\n        \"\"\"\n\n        super().__init__()\n        self.root_directory = local_file_uri_to_path(root_directory or _default_root_dir())\n        # Create models directory if needed\n        if not exists(self.models_directory):\n            mkdir(self.models_directory)\n\n    @property\n    def models_directory(self):\n        return os.path.join(self.root_directory, FileStore.MODELS_FOLDER_NAME)\n\n    def _check_root_dir(self):\n        \"\"\"\n        Run checks before running directory operations.\n        \"\"\"\n        if not exists(self.root_directory):\n            raise Exception(\"'%s' does not exist.\" % self.root_directory)\n        if not is_directory(self.root_directory):\n            raise Exception(\"'%s' is not a directory.\" % self.root_directory)\n\n    def _validate_registered_model_does_not_exist(self, name):\n        model_path = self._get_registered_model_path(name)\n        if exists(model_path):\n            raise MlflowException(\n                f\"Registered Model (name={name}) already exists.\",\n                RESOURCE_ALREADY_EXISTS,\n            )\n\n    def _save_registered_model_as_meta_file(self, registered_model, meta_dir=None, overwrite=True):\n        registered_model_dict = dict(registered_model)\n        # tags are stored under TAGS_FOLDER_NAME so remove them in meta file.\n        del registered_model_dict[\"tags\"]\n        del registered_model_dict[\"latest_versions\"]\n        meta_dir = meta_dir or self._get_registered_model_path(registered_model.name)\n        if overwrite:\n            overwrite_yaml(\n                meta_dir,\n                FileStore.META_DATA_FILE_NAME,\n                registered_model_dict,\n            )\n        else:\n            write_yaml(\n                meta_dir,\n                FileStore.META_DATA_FILE_NAME,\n                registered_model_dict,\n            )\n\n    def _update_registered_model_last_updated_time(self, name, updated_time):\n        registered_model = self.get_registered_model(name)\n        registered_model.last_updated_timestamp = updated_time\n        self._save_registered_model_as_meta_file(registered_model)\n\n    def create_registered_model(self, name, tags=None, description=None):\n        \"\"\"\n        Create a new registered model in backend store.\n\n        :param name: Name of the new model. This is expected to be unique in the backend store.\n        :param tags: A list of :py:class:`mlflow.entities.model_registry.RegisteredModelTag`\n                     instances associated with this registered model.\n        :param description: Description of the model.\n        :return: A single object of :py:class:`mlflow.entities.model_registry.RegisteredModel`\n                 created in the backend.\n        \"\"\"\n\n        self._check_root_dir()\n        _validate_model_name(name)\n        self._validate_registered_model_does_not_exist(name)\n        for tag in tags or []:\n            _validate_registered_model_tag(tag.key, tag.value)\n        meta_dir = self._get_registered_model_path(name)\n        mkdir(meta_dir)\n        creation_time = get_current_time_millis()\n        latest_versions = []\n        registered_model = RegisteredModel(\n            name=name,\n            creation_timestamp=creation_time,\n            last_updated_timestamp=creation_time,\n            description=description,\n            latest_versions=latest_versions,\n            tags=tags,\n        )\n        self._save_registered_model_as_meta_file(\n            registered_model, meta_dir=meta_dir, overwrite=False\n        )\n        if tags is not None:\n            for tag in tags:\n                self.set_registered_model_tag(name, tag)\n        return registered_model\n\n    def _get_registered_model_path(self, name):\n        self._check_root_dir()\n        _validate_model_name(name)\n        return join(self.root_directory, FileStore.MODELS_FOLDER_NAME, name)\n\n    def _get_registered_model_from_path(self, model_path):\n        meta = FileStore._read_yaml(model_path, FileStore.META_DATA_FILE_NAME)\n        meta[\"tags\"] = self.get_all_registered_model_tags_from_path(model_path)\n        registered_model = RegisteredModel.from_dictionary(meta)\n        registered_model.latest_versions = self.get_latest_versions(os.path.basename(model_path))\n        return registered_model\n\n    def update_registered_model(self, name, description):\n        \"\"\"\n        Update description of the registered model.\n\n        :param name: Registered model name.\n        :param description: New description.\n        :return: A single updated :py:class:`mlflow.entities.model_registry.RegisteredModel` object.\n        \"\"\"\n        registered_model = self.get_registered_model(name)\n        updated_time = get_current_time_millis()\n        registered_model.description = description\n        registered_model.last_updated_timestamp = updated_time\n        self._save_registered_model_as_meta_file(registered_model)\n        return registered_model\n\n    def rename_registered_model(self, name, new_name):\n        \"\"\"\n        Rename the registered model.\n\n        :param name: Registered model name.\n        :param new_name: New proposed name.\n        :return: A single updated :py:class:`mlflow.entities.model_registry.RegisteredModel` object.\n        \"\"\"\n        model_path = self._get_registered_model_path(name)\n        if not exists(model_path):\n            raise MlflowException(\n                f\"Registered Model with name={name} not found\",\n                RESOURCE_DOES_NOT_EXIST,\n            )\n        registered_model = self._get_registered_model_from_path(model_path)\n\n        new_meta_dir = self._get_registered_model_path(new_name)\n        if not exists(new_meta_dir):\n            mkdir(new_meta_dir)\n            updated_time = get_current_time_millis()\n            registered_model.name = new_name\n            registered_model.last_updated_timestamp = updated_time\n            self._save_registered_model_as_meta_file(\n                registered_model, meta_dir=new_meta_dir, overwrite=False\n            )\n            model_versions = self._list_model_versions_under_path(model_path)\n            for mv in model_versions:\n                mv.name = new_name\n                mv.last_updated_timestamp = updated_time\n                new_model_version_dir = join(new_meta_dir, f\"version-{mv.version}\")\n                mkdir(new_model_version_dir)\n                self._save_model_version_as_meta_file(\n                    mv, meta_dir=new_model_version_dir, overwrite=False\n                )\n                if mv.tags is not None:\n                    for tag in mv.tags:\n                        self.set_model_version_tag(new_name, mv.version, tag)\n            shutil.rmtree(model_path)\n        else:\n            raise MlflowException(\n                f\"Registered Model (name={new_name}) already exists.\",\n                RESOURCE_ALREADY_EXISTS,\n            )\n\n        return registered_model\n\n    def delete_registered_model(self, name):\n        \"\"\"\n        Delete the registered model.\n        Backend raises exception if a registered model with given name does not exist.\n\n        :param name: Registered model name.\n        :return: None\n        \"\"\"\n        meta_dir = self._get_registered_model_path(name)\n        if not exists(meta_dir):\n            raise MlflowException(\n                f\"Registered Model with name={name} not found\",\n                RESOURCE_DOES_NOT_EXIST,\n            )\n        shutil.rmtree(meta_dir)\n\n    def list_registered_models(self, max_results, page_token):\n        \"\"\"\n        List of all registered models.\n\n        :param max_results: Maximum number of registered models desired.\n        :param page_token: Token specifying the next page of results. It should be obtained from\n                            a ``list_registered_models`` call.\n        :return: A PagedList of :py:class:`mlflow.entities.model_registry.RegisteredModel` objects\n                that satisfy the search expressions. The pagination token for the next page can be\n                obtained via the ``token`` attribute of the object.\n        \"\"\"\n        return self.search_registered_models(max_results=max_results, page_token=page_token)\n\n    def _list_all_registered_models(self):\n        registered_model_paths = self._get_all_registered_model_paths()\n        registered_models = []\n        for path in registered_model_paths:\n            registered_models.append(self._get_registered_model_from_path(path))\n        return registered_models\n\n    def search_registered_models(\n        self, filter_string=None, max_results=None, order_by=None, page_token=None\n    ):\n        \"\"\"\n        Search for registered models in backend that satisfy the filter criteria.\n\n        :param filter_string: Filter query string, defaults to searching all registered models.\n        :param max_results: Maximum number of registered models desired.\n        :param order_by: List of column names with ASC|DESC annotation, to be used for ordering\n                         matching search results.\n        :param page_token: Token specifying the next page of results. It should be obtained from\n                            a ``search_registered_models`` call.\n        :return: A PagedList of :py:class:`mlflow.entities.model_registry.RegisteredModel` objects\n                that satisfy the search expressions. The pagination token for the next page can be\n                obtained via the ``token`` attribute of the object.\n        \"\"\"\n        if not isinstance(max_results, int) or max_results < 1:\n            raise MlflowException(\n                \"Invalid value for max_results. It must be a positive integer,\"\n                f\" but got {max_results}\",\n                INVALID_PARAMETER_VALUE,\n            )\n\n        if max_results > SEARCH_REGISTERED_MODEL_MAX_RESULTS_THRESHOLD:\n            raise MlflowException(\n                \"Invalid value for request parameter max_results. It must be at most \"\n                f\"{SEARCH_REGISTERED_MODEL_MAX_RESULTS_THRESHOLD}, but got value {max_results}\",\n                INVALID_PARAMETER_VALUE,\n            )\n\n        registered_models = self._list_all_registered_models()\n        filtered_rms = SearchModelUtils.filter(registered_models, filter_string)\n        sorted_rms = SearchModelUtils.sort(filtered_rms, order_by)\n        start_offset = SearchUtils.parse_start_offset_from_page_token(page_token)\n        final_offset = start_offset + max_results\n\n        paginated_rms = sorted_rms[start_offset:final_offset]\n        next_page_token = None\n        if final_offset < len(sorted_rms):\n            next_page_token = SearchUtils.create_page_token(final_offset)\n        return PagedList(paginated_rms, next_page_token)\n\n    def get_registered_model(self, name):\n        \"\"\"\n        Get registered model instance by name.\n\n        :param name: Registered model name.\n        :return: A single :py:class:`mlflow.entities.model_registry.RegisteredModel` object.\n        \"\"\"\n        model_path = self._get_registered_model_path(name)\n        if not exists(model_path):\n            raise MlflowException(\n                f\"Registered Model with name={name} not found\",\n                RESOURCE_DOES_NOT_EXIST,\n            )\n        return self._get_registered_model_from_path(model_path)\n\n    def get_latest_versions(self, name, stages=None):\n        \"\"\"\n        Latest version models for each requested stage. If no ``stages`` argument is provided,\n        returns the latest version for each stage.\n\n        :param name: Registered model name.\n        :param stages: List of desired stages. If input list is None, return latest versions for\n                       each stage.\n        :return: List of :py:class:`mlflow.entities.model_registry.ModelVersion` objects.\n        \"\"\"\n        registered_model_path = self._get_registered_model_path(name)\n        if not exists(registered_model_path):\n            raise MlflowException(\n                f\"Registered Model with name={name} not found\",\n                RESOURCE_DOES_NOT_EXIST,\n            )\n        model_versions = self._list_model_versions_under_path(registered_model_path)\n        if stages is None or len(stages) == 0:\n            expected_stages = {get_canonical_stage(stage) for stage in ALL_STAGES}\n        else:\n            expected_stages = {get_canonical_stage(stage) for stage in stages}\n        latest_versions = {}\n        for mv in model_versions:\n            if mv.current_stage in expected_stages:\n                if (\n                    mv.current_stage not in latest_versions\n                    or latest_versions[mv.current_stage].version < mv.version\n                ):\n                    latest_versions[mv.current_stage] = mv\n\n        return [latest_versions[stage] for stage in expected_stages if stage in latest_versions]\n\n    def _get_registered_model_tag_path(self, name, tag_name):\n        _validate_model_name(name)\n        _validate_tag_name(tag_name)\n        registered_model_path = self._get_registered_model_path(name)\n        if not exists(registered_model_path):\n            raise MlflowException(\n                f\"Registered Model with name={name} not found\",\n                RESOURCE_DOES_NOT_EXIST,\n            )\n        return os.path.join(registered_model_path, FileStore.TAGS_FOLDER_NAME, tag_name)\n\n    def _get_registered_model_tag_from_file(self, parent_path, tag_name):\n        _validate_tag_name(tag_name)\n        tag_data = read_file(parent_path, tag_name)\n        return RegisteredModelTag(tag_name, tag_data)\n\n    def _get_resource_files(self, root_dir, subfolder_name):\n        source_dirs = find(root_dir, subfolder_name, full_path=True)\n        if len(source_dirs) == 0:\n            return root_dir, []\n        file_names = []\n        for root, _, files in os.walk(source_dirs[0]):\n            for name in files:\n                abspath = join(root, name)\n                file_names.append(os.path.relpath(abspath, source_dirs[0]))\n        if sys.platform == \"win32\":\n            # Turn registered models / model versions relative path into metric name.\n            # Registered models and model versions can have '/' in the name.\n            # On windows, '/' is interpreted as a separator.\n            # When the model / model version is read back the path will use '\\' for separator.\n            # We need to translate the path into posix path.\n            from mlflow.utils.file_utils import relative_path_to_artifact_path\n\n            file_names = [relative_path_to_artifact_path(x) for x in file_names]\n        return source_dirs[0], file_names\n\n    def get_all_registered_model_tags_from_path(self, model_path):\n        parent_path, tag_files = self._get_resource_files(model_path, FileStore.TAGS_FOLDER_NAME)\n        tags = []\n        for tag_file in tag_files:\n            tags.append(self._get_registered_model_tag_from_file(parent_path, tag_file))\n        return tags\n\n    def _writeable_value(self, tag_value):\n        if tag_value is None:\n            return \"\"\n        elif is_string_type(tag_value):\n            return tag_value\n        else:\n            return \"%s\" % tag_value\n\n    def set_registered_model_tag(self, name, tag):\n        \"\"\"\n        Set a tag for the registered model.\n\n        :param name: Registered model name.\n        :param tag: :py:class:`mlflow.entities.model_registry.RegisteredModelTag` instance to log.\n        :return: None\n        \"\"\"\n        _validate_registered_model_tag(tag.key, tag.value)\n        tag_path = self._get_registered_model_tag_path(name, tag.key)\n        make_containing_dirs(tag_path)\n        write_to(tag_path, self._writeable_value(tag.value))\n        updated_time = get_current_time_millis()\n        self._update_registered_model_last_updated_time(name, updated_time)\n\n    def delete_registered_model_tag(self, name, key):\n        \"\"\"\n        Delete a tag associated with the registered model.\n\n        :param name: Registered model name.\n        :param key: Registered model tag key.\n        :return: None\n        \"\"\"\n        tag_path = self._get_registered_model_tag_path(name, key)\n        if exists(tag_path):\n            os.remove(tag_path)\n            updated_time = get_current_time_millis()\n            self._update_registered_model_last_updated_time(name, updated_time)\n\n    # CRUD API for ModelVersion objects\n\n    def _get_registered_model_version_tag_from_file(self, parent_path, tag_name):\n        _validate_tag_name(tag_name)\n        tag_data = read_file(parent_path, tag_name)\n        return ModelVersionTag(tag_name, tag_data)\n\n    def _get_model_version_tags_from_dir(self, directory):\n        parent_path, tag_files = self._get_resource_files(directory, FileStore.TAGS_FOLDER_NAME)\n        tags = []\n        for tag_file in tag_files:\n            tags.append(self._get_registered_model_version_tag_from_file(parent_path, tag_file))\n        return tags\n\n    def _get_model_version_dir(self, name, version):\n        registered_model_path = self._get_registered_model_path(name)\n        if not exists(registered_model_path):\n            raise MlflowException(\n                f\"Registered Model with name={name} not found\",\n                RESOURCE_DOES_NOT_EXIST,\n            )\n        return join(registered_model_path, f\"version-{version}\")\n\n    def _get_model_version_from_dir(self, directory):\n        meta = FileStore._read_yaml(directory, FileStore.META_DATA_FILE_NAME)\n        meta[\"tags\"] = self._get_model_version_tags_from_dir(directory)\n        model_version = ModelVersion.from_dictionary(meta)\n        return model_version\n\n    def _save_model_version_as_meta_file(self, model_version, meta_dir=None, overwrite=True):\n        model_version_dict = dict(model_version)\n        del model_version_dict[\"tags\"]\n        meta_dir = meta_dir or self._get_model_version_dir(\n            model_version.name, model_version.version\n        )\n        if overwrite:\n            overwrite_yaml(\n                meta_dir,\n                FileStore.META_DATA_FILE_NAME,\n                model_version_dict,\n            )\n        else:\n            write_yaml(\n                meta_dir,\n                FileStore.META_DATA_FILE_NAME,\n                model_version_dict,\n            )\n\n    def create_model_version(\n        self, name, source, run_id=None, tags=None, run_link=None, description=None\n    ):\n        \"\"\"\n        Create a new model version from given source and run ID.\n\n        :param name: Registered model name.\n        :param source: Source path where the MLflow model is stored.\n        :param run_id: Run ID from MLflow tracking server that generated the model.\n        :param tags: A list of :py:class:`mlflow.entities.model_registry.ModelVersionTag`\n                     instances associated with this model version.\n        :param run_link: Link to the run from an MLflow tracking server that generated this model.\n        :param description: Description of the version.\n        :return: A single object of :py:class:`mlflow.entities.model_registry.ModelVersion`\n                 created in the backend.\n        \"\"\"\n\n        def next_version(registered_model_name):\n            path = self._get_registered_model_path(registered_model_name)\n            model_versions = self._list_model_versions_under_path(path)\n            if model_versions:\n                return max(mv.version for mv in model_versions) + 1\n            else:\n                return 1\n\n        _validate_model_name(name)\n        for tag in tags or []:\n            _validate_model_version_tag(tag.key, tag.value)\n        for attempt in range(self.CREATE_MODEL_VERSION_RETRIES):\n            try:\n                creation_time = get_current_time_millis()\n                registered_model = self.get_registered_model(name)\n                registered_model.last_updated_timestamp = creation_time\n                self._save_registered_model_as_meta_file(registered_model)\n                version = next_version(name)\n                model_version = ModelVersion(\n                    name=name,\n                    version=version,\n                    creation_timestamp=creation_time,\n                    last_updated_timestamp=creation_time,\n                    description=description,\n                    current_stage=STAGE_NONE,\n                    source=source,\n                    run_id=run_id,\n                    run_link=run_link,\n                    tags=tags,\n                )\n                model_version_dir = self._get_model_version_dir(name, version)\n                mkdir(model_version_dir)\n                self._save_model_version_as_meta_file(\n                    model_version, meta_dir=model_version_dir, overwrite=False\n                )\n                self._save_registered_model_as_meta_file(registered_model)\n                if tags is not None:\n                    for tag in tags:\n                        self.set_model_version_tag(name, version, tag)\n                return model_version\n            except Exception as e:\n                more_retries = self.CREATE_MODEL_VERSION_RETRIES - attempt - 1\n                logging.warning(\n                    \"Model Version creation error (name=%s) Retrying %s more time%s.\",\n                    name,\n                    str(more_retries),\n                    \"s\" if more_retries > 1 else \"\",\n                )\n                if more_retries == 0:\n                    raise MlflowException(\n                        \"Model Version creation error (name={}). Error: {}. Giving up after \"\n                        \"{} attempts.\".format(name, e, self.CREATE_MODEL_VERSION_RETRIES)\n                    )\n\n    def update_model_version(self, name, version, description):\n        \"\"\"\n        Update metadata associated with a model version in backend.\n\n        :param name: Registered model name.\n        :param version: Registered model version.\n        :param description: New model description.\n        :return: A single :py:class:`mlflow.entities.model_registry.ModelVersion` object.\n        \"\"\"\n        updated_time = get_current_time_millis()\n        model_version = self.get_model_version(name=name, version=version)\n        model_version.description = description\n        model_version.last_updated_timestamp = updated_time\n        self._save_model_version_as_meta_file(model_version)\n        return model_version\n\n    def transition_model_version_stage(self, name, version, stage, archive_existing_versions):\n        \"\"\"\n        Update model version stage.\n\n        :param name: Registered model name.\n        :param version: Registered model version.\n        :param stage: New desired stage for this model version.\n        :param archive_existing_versions: If this flag is set to ``True``, all existing model\n            versions in the stage will be automatically moved to the \"archived\" stage. Only valid\n            when ``stage`` is ``\"staging\"`` or ``\"production\"`` otherwise an error will be raised.\n\n        :return: A single :py:class:`mlflow.entities.model_registry.ModelVersion` object.\n        \"\"\"\n        is_active_stage = get_canonical_stage(stage) in DEFAULT_STAGES_FOR_GET_LATEST_VERSIONS\n        if archive_existing_versions and not is_active_stage:\n            msg_tpl = (\n                \"Model version transition cannot archive existing model versions \"\n                \"because '{}' is not an Active stage. Valid stages are {}\"\n            )\n            raise MlflowException(msg_tpl.format(stage, DEFAULT_STAGES_FOR_GET_LATEST_VERSIONS))\n\n        last_updated_time = get_current_time_millis()\n        model_versions = []\n        if archive_existing_versions:\n            registered_model_path = self._get_registered_model_path(name)\n            model_versions = self._list_model_versions_under_path(registered_model_path)\n            for mv in model_versions:\n                if mv.version != version and mv.current_stage == get_canonical_stage(stage):\n                    mv.current_stage = STAGE_ARCHIVED\n                    mv.last_updated_timestamp = last_updated_time\n                    self._save_model_version_as_meta_file(mv)\n\n        model_version = self.get_model_version(name, version)\n        model_version.current_stage = get_canonical_stage(stage)\n        model_version.last_updated_timestamp = last_updated_time\n        self._save_model_version_as_meta_file(model_version)\n        self._update_registered_model_last_updated_time(name, last_updated_time)\n        return model_version\n\n    def delete_model_version(self, name, version):\n        \"\"\"\n        Delete model version in backend.\n\n        :param name: Registered model name.\n        :param version: Registered model version.\n        :return: None\n        \"\"\"\n        model_version = self.get_model_version(name=name, version=version)\n        model_version.current_stage = STAGE_DELETED_INTERNAL\n        updated_time = get_current_time_millis()\n        model_version.last_updated_timestamp = updated_time\n        self._save_model_version_as_meta_file(model_version)\n        self._update_registered_model_last_updated_time(name, updated_time)\n\n    def get_model_version(self, name, version):\n        \"\"\"\n        Get the model version instance by name and version.\n\n        :param name: Registered model name.\n        :param version: Registered model version.\n        :return: A single :py:class:`mlflow.entities.model_registry.ModelVersion` object.\n        \"\"\"\n        _validate_model_name(name)\n        _validate_model_version(version)\n        registered_model_version_dir = self._get_model_version_dir(name, version)\n        if not exists(registered_model_version_dir):\n            raise MlflowException(\n                f\"Model Version (name={name}, version={version}) not found\",\n                RESOURCE_DOES_NOT_EXIST,\n            )\n        model_version = self._get_model_version_from_dir(registered_model_version_dir)\n        if model_version.current_stage == STAGE_DELETED_INTERNAL:\n            raise MlflowException(\n                f\"Model Version (name={name}, version={version}) not found\",\n                RESOURCE_DOES_NOT_EXIST,\n            )\n        return model_version\n\n    def get_model_version_download_uri(self, name, version):\n        \"\"\"\n        Get the download location in Model Registry for this model version.\n        NOTE: For first version of Model Registry, since the models are not copied over to another\n              location, download URI points to input source path.\n\n        :param name: Registered model name.\n        :param version: Registered model version.\n        :return: A single URI location that allows reads for downloading.\n        \"\"\"\n        model_version = self.get_model_version(name, version)\n        return model_version.source\n\n    def _get_all_registered_model_paths(self):\n        self._check_root_dir()\n        model_dirs = list_subdirs(\n            join(self.root_directory, FileStore.MODELS_FOLDER_NAME), full_path=True\n        )\n        return model_dirs\n\n    def _list_model_versions_under_path(self, path):\n        model_versions = []\n        model_version_dirs = list_all(\n            path,\n            filter_func=lambda x: os.path.isdir(x)\n            and os.path.basename(os.path.normpath(x)).startswith(\"version-\"),\n            full_path=True,\n        )\n        for directory in model_version_dirs:\n            model_versions.append(self._get_model_version_from_dir(directory))\n        return model_versions\n\n    def search_model_versions(\n        self, filter_string=None, max_results=None, order_by=None, page_token=None\n    ):\n        \"\"\"\n        Search for model versions in backend that satisfy the filter criteria.\n\n        :param filter_string: A filter string expression. Currently supports a single filter\n                              condition either name of model like ``name = 'model_name'`` or\n                              ``run_id = '...'``.\n        :param max_results: Maximum number of model versions desired.\n        :param order_by: List of column names with ASC|DESC annotation, to be used for ordering\n                         matching search results.\n        :param page_token: Token specifying the next page of results. It should be obtained from\n                            a ``search_model_versions`` call.\n        :return: A PagedList of :py:class:`mlflow.entities.model_registry.ModelVersion`\n                 objects that satisfy the search expressions. The pagination token for the next\n                 page can be obtained via the ``token`` attribute of the object.\n        \"\"\"\n        if not isinstance(max_results, int) or max_results < 1:\n            raise MlflowException(\n                \"Invalid value for max_results. It must be a positive integer,\"\n                f\" but got {max_results}\",\n                INVALID_PARAMETER_VALUE,\n            )\n\n        if max_results > SEARCH_MODEL_VERSION_MAX_RESULTS_THRESHOLD:\n            raise MlflowException(\n                \"Invalid value for request parameter max_results. It must be at most \"\n                f\"{SEARCH_MODEL_VERSION_MAX_RESULTS_THRESHOLD}, but got value {max_results}\",\n                INVALID_PARAMETER_VALUE,\n            )\n\n        registered_model_paths = self._get_all_registered_model_paths()\n        model_versions = []\n        for path in registered_model_paths:\n            model_versions.extend(self._list_model_versions_under_path(path))\n        filtered_mvs = SearchModelVersionUtils.filter(model_versions, filter_string)\n\n        sorted_mvs = SearchModelVersionUtils.sort(\n            filtered_mvs,\n            order_by or [\"last_updated_timestamp DESC\", \"name ASC\", \"version_number DESC\"],\n        )\n        start_offset = SearchUtils.parse_start_offset_from_page_token(page_token)\n        final_offset = start_offset + max_results\n\n        paginated_mvs = sorted_mvs[start_offset:final_offset]\n        next_page_token = None\n        if final_offset < len(sorted_mvs):\n            next_page_token = SearchUtils.create_page_token(final_offset)\n        return PagedList(paginated_mvs, next_page_token)\n\n    def _get_registered_model_version_tag_path(self, name, version, tag_name):\n        _validate_model_name(name)\n        _validate_model_version(version)\n        _validate_tag_name(tag_name)\n        registered_model_version_path = self._get_model_version_dir(name, version)\n        if not exists(registered_model_version_path):\n            raise MlflowException(\n                f\"Model Version (name={name}, version={version}) not found\",\n                RESOURCE_DOES_NOT_EXIST,\n            )\n        model_version = self._get_model_version_from_dir(registered_model_version_path)\n        if model_version.current_stage == STAGE_DELETED_INTERNAL:\n            raise MlflowException(\n                f\"Model Version (name={name}, version={version}) not found\",\n                RESOURCE_DOES_NOT_EXIST,\n            )\n        return os.path.join(registered_model_version_path, FileStore.TAGS_FOLDER_NAME, tag_name)\n\n    def set_model_version_tag(self, name, version, tag):\n        \"\"\"\n        Set a tag for the model version.\n\n        :param name: Registered model name.\n        :param version: Registered model version.\n        :param tag: :py:class:`mlflow.entities.model_registry.ModelVersionTag` instance to log.\n        :return: None\n        \"\"\"\n        _validate_model_version_tag(tag.key, tag.value)\n        tag_path = self._get_registered_model_version_tag_path(name, version, tag.key)\n        make_containing_dirs(tag_path)\n        write_to(tag_path, self._writeable_value(tag.value))\n        updated_time = get_current_time_millis()\n        self._update_registered_model_last_updated_time(name, updated_time)\n\n    def delete_model_version_tag(self, name, version, key):\n        \"\"\"\n        Delete a tag associated with the model version.\n\n        :param name: Registered model name.\n        :param version: Registered model version.\n        :param key: Tag key.\n        :return: None\n        \"\"\"\n        tag_path = self._get_registered_model_version_tag_path(name, version, key)\n        if exists(tag_path):\n            os.remove(tag_path)\n            updated_time = get_current_time_millis()\n            self._update_registered_model_last_updated_time(name, updated_time)\n\n    @staticmethod\n    def _read_yaml(root, file_name, retries=2):\n        \"\"\"\n        Read data from yaml file and return as dictionary, retrying up to\n        a specified number of times if the file contents are unexpectedly\n        empty due to a concurrent write.\n\n        :param root: Directory name.\n        :param file_name: File name. Expects to have '.yaml' extension.\n        :param retries: The number of times to retry for unexpected empty content.\n        :return: Data in yaml file as dictionary\n        \"\"\"\n\n        def _read_helper(root, file_name, attempts_remaining=2):\n            result = read_yaml(root, file_name)\n            if result is not None or attempts_remaining == 0:\n                return result\n            else:\n                time.sleep(0.1 * (3 - attempts_remaining))\n                return _read_helper(root, file_name, attempts_remaining - 1)\n\n        return _read_helper(root, file_name, attempts_remaining=retries)\n", "import codecs\nimport errno\nimport gzip\nimport os\nimport posixpath\nimport shutil\nimport sys\nimport tarfile\nimport tempfile\nimport stat\nimport pathlib\n\nimport urllib.parse\nimport urllib.request\nfrom urllib.parse import unquote\nfrom urllib.request import pathname2url\n\nimport atexit\n\nimport yaml\n\ntry:\n    from yaml import CSafeLoader as YamlSafeLoader, CSafeDumper as YamlSafeDumper\nexcept ImportError:\n    from yaml import SafeLoader as YamlSafeLoader, SafeDumper as YamlSafeDumper\n\nfrom mlflow.entities import FileInfo\nfrom mlflow.exceptions import MissingConfigException\nfrom mlflow.utils.rest_utils import cloud_storage_http_request, augmented_raise_for_status\nfrom mlflow.utils.process import cache_return_value_per_process\nfrom mlflow.utils import merge_dicts\nfrom mlflow.utils.databricks_utils import _get_dbutils\nfrom mlflow.utils.os import is_windows\n\nENCODING = \"utf-8\"\n\n\ndef is_directory(name):\n    return os.path.isdir(name)\n\n\ndef is_file(name):\n    return os.path.isfile(name)\n\n\ndef exists(name):\n    return os.path.exists(name)\n\n\ndef list_all(root, filter_func=lambda x: True, full_path=False):\n    \"\"\"\n    List all entities directly under 'dir_name' that satisfy 'filter_func'\n\n    :param root: Name of directory to start search\n    :param filter_func: function or lambda that takes path\n    :param full_path: If True will return results as full path including `root`\n\n    :return: list of all files or directories that satisfy the criteria.\n    \"\"\"\n    if not is_directory(root):\n        raise Exception(\"Invalid parent directory '%s'\" % root)\n    matches = [x for x in os.listdir(root) if filter_func(os.path.join(root, x))]\n    return [os.path.join(root, m) for m in matches] if full_path else matches\n\n\ndef list_subdirs(dir_name, full_path=False):\n    \"\"\"\n    Equivalent to UNIX command:\n      ``find $dir_name -depth 1 -type d``\n\n    :param dir_name: Name of directory to start search\n    :param full_path: If True will return results as full path including `root`\n\n    :return: list of all directories directly under 'dir_name'\n    \"\"\"\n    return list_all(dir_name, os.path.isdir, full_path)\n\n\ndef list_files(dir_name, full_path=False):\n    \"\"\"\n    Equivalent to UNIX command:\n      ``find $dir_name -depth 1 -type f``\n\n    :param dir_name: Name of directory to start search\n    :param full_path: If True will return results as full path including `root`\n\n    :return: list of all files directly under 'dir_name'\n    \"\"\"\n    return list_all(dir_name, os.path.isfile, full_path)\n\n\ndef find(root, name, full_path=False):\n    \"\"\"\n    Search for a file in a root directory. Equivalent to:\n      ``find $root -name \"$name\" -depth 1``\n\n    :param root: Name of root directory for find\n    :param name: Name of file or directory to find directly under root directory\n    :param full_path: If True will return results as full path including `root`\n\n    :return: list of matching files or directories\n    \"\"\"\n    path_name = os.path.join(root, name)\n    return list_all(root, lambda x: x == path_name, full_path)\n\n\ndef mkdir(root, name=None):\n    \"\"\"\n    Make directory with name \"root/name\", or just \"root\" if name is None.\n\n    :param root: Name of parent directory\n    :param name: Optional name of leaf directory\n\n    :return: Path to created directory\n    \"\"\"\n    target = os.path.join(root, name) if name is not None else root\n    try:\n        os.makedirs(target)\n    except OSError as e:\n        if e.errno != errno.EEXIST or not os.path.isdir(target):\n            raise e\n    return target\n\n\ndef make_containing_dirs(path):\n    \"\"\"\n    Create the base directory for a given file path if it does not exist; also creates parent\n    directories.\n    \"\"\"\n    dir_name = os.path.dirname(path)\n    if not os.path.exists(dir_name):\n        os.makedirs(dir_name)\n\n\ndef write_yaml(root, file_name, data, overwrite=False, sort_keys=True):\n    \"\"\"\n    Write dictionary data in yaml format.\n\n    :param root: Directory name.\n    :param file_name: Desired file name. Will automatically add .yaml extension if not given\n    :param data: data to be dumped as yaml format\n    :param overwrite: If True, will overwrite existing files\n    \"\"\"\n    if not exists(root):\n        raise MissingConfigException(\"Parent directory '%s' does not exist.\" % root)\n\n    file_path = os.path.join(root, file_name)\n    yaml_file_name = file_path if file_path.endswith(\".yaml\") else file_path + \".yaml\"\n\n    if exists(yaml_file_name) and not overwrite:\n        raise Exception(f\"Yaml file '{file_path}' exists as '{yaml_file_name}\")\n\n    try:\n        with codecs.open(yaml_file_name, mode=\"w\", encoding=ENCODING) as yaml_file:\n            yaml.dump(\n                data,\n                yaml_file,\n                default_flow_style=False,\n                allow_unicode=True,\n                sort_keys=sort_keys,\n                Dumper=YamlSafeDumper,\n            )\n    except Exception as e:\n        raise e\n\n\ndef overwrite_yaml(root, file_name, data):\n    \"\"\"\n    Safely overwrites a preexisting yaml file, ensuring that file contents are not deleted or\n    corrupted if the write fails. This is achieved by writing contents to a temporary file\n    and moving the temporary file to replace the preexisting file, rather than opening the\n    preexisting file for a direct write.\n\n    :param root: Directory name.\n    :param file_name: File name. Expects to have '.yaml' extension.\n    :param data: The data to write, represented as a dictionary.\n    \"\"\"\n    tmp_file_path = None\n    try:\n        tmp_file_fd, tmp_file_path = tempfile.mkstemp(suffix=\"file.yaml\")\n        os.close(tmp_file_fd)\n        write_yaml(\n            root=get_parent_dir(tmp_file_path),\n            file_name=os.path.basename(tmp_file_path),\n            data=data,\n            overwrite=True,\n            sort_keys=True,\n        )\n        shutil.move(\n            tmp_file_path,\n            os.path.join(root, file_name),\n        )\n    finally:\n        if tmp_file_path is not None and os.path.exists(tmp_file_path):\n            os.remove(tmp_file_path)\n\n\ndef read_yaml(root, file_name):\n    \"\"\"\n    Read data from yaml file and return as dictionary\n\n    :param root: Directory name\n    :param file_name: File name. Expects to have '.yaml' extension\n\n    :return: Data in yaml file as dictionary\n    \"\"\"\n    if not exists(root):\n        raise MissingConfigException(\n            f\"Cannot read '{file_name}'. Parent dir '{root}' does not exist.\"\n        )\n\n    file_path = os.path.join(root, file_name)\n    if not exists(file_path):\n        raise MissingConfigException(\"Yaml file '%s' does not exist.\" % file_path)\n    try:\n        with codecs.open(file_path, mode=\"r\", encoding=ENCODING) as yaml_file:\n            return yaml.load(yaml_file, Loader=YamlSafeLoader)\n    except Exception as e:\n        raise e\n\n\nclass UniqueKeyLoader(YamlSafeLoader):\n    def construct_mapping(self, node, deep=False):\n        mapping = set()\n        for key_node, _ in node.value:\n            key = self.construct_object(key_node, deep=deep)\n            if key in mapping:\n                raise ValueError(f\"Duplicate '{key}' key found in YAML.\")\n            mapping.add(key)\n        return super().construct_mapping(node, deep)\n\n\ndef render_and_merge_yaml(root, template_name, context_name):\n    \"\"\"\n    Renders a Jinja2-templated YAML file based on a YAML context file, merge them, and return\n    result as a dictionary.\n\n    :param root: Root directory of the YAML files\n    :param template_name: Name of the template file\n    :param context_name: Name of the context file\n    :return: Data in yaml file as dictionary\n    \"\"\"\n    import jinja2\n\n    template_path = os.path.join(root, template_name)\n    context_path = os.path.join(root, context_name)\n\n    for path in (template_path, context_path):\n        if not pathlib.Path(path).is_file():\n            raise MissingConfigException(\"Yaml file '%s' does not exist.\" % path)\n\n    j2_env = jinja2.Environment(\n        loader=jinja2.FileSystemLoader(root, encoding=ENCODING),\n        undefined=jinja2.StrictUndefined,\n        line_comment_prefix=\"#\",\n    )\n\n    def from_json(input_var):\n        import json\n\n        with open(input_var, encoding=\"utf-8\") as f:\n            return json.load(f)\n\n    j2_env.filters[\"from_json\"] = from_json\n    # Compute final source of context file (e.g. my-profile.yml), applying Jinja filters\n    # like from_json as needed to load context information from files, then load into a dict\n    context_source = j2_env.get_template(context_name).render({})\n    context_dict = yaml.load(context_source, Loader=UniqueKeyLoader) or {}\n\n    # Substitute parameters from context dict into template\n    source = j2_env.get_template(template_name).render(context_dict)\n    rendered_template_dict = yaml.load(source, Loader=UniqueKeyLoader)\n    return merge_dicts(rendered_template_dict, context_dict)\n\n\ndef read_parquet_as_pandas_df(data_parquet_path: str):\n    \"\"\"\n    Deserialize and load the specified parquet file as a Pandas DataFrame.\n\n    :param data_parquet_path: String, path object (implementing os.PathLike[str]),\n    or file-like object implementing a binary read() function. The string\n    could be a URL. Valid URL schemes include http, ftp, s3, gs, and file.\n    For file URLs, a host is expected. A local file could\n    be: file://localhost/path/to/table.parquet. A file URL can also be a path to a\n    directory that contains multiple partitioned parquet files. Pyarrow\n    support paths to directories as well as file URLs. A directory\n    path could be: file://localhost/path/to/tables or s3://bucket/partition_dir.\n    :return: pandas dataframe\n    \"\"\"\n    import pandas as pd\n\n    return pd.read_parquet(data_parquet_path, engine=\"pyarrow\")\n\n\ndef write_pandas_df_as_parquet(df, data_parquet_path: str):\n    \"\"\"\n    Write a DataFrame to the binary parquet format.\n\n    :param df: pandas data frame.\n    :param data_parquet_path: String, path object (implementing os.PathLike[str]),\n    or file-like object implementing a binary write() function.\n    \"\"\"\n    df.to_parquet(data_parquet_path, engine=\"pyarrow\")\n\n\nclass TempDir:\n    def __init__(self, chdr=False, remove_on_exit=True):\n        self._dir = None\n        self._path = None\n        self._chdr = chdr\n        self._remove = remove_on_exit\n\n    def __enter__(self):\n        self._path = os.path.abspath(tempfile.mkdtemp())\n        assert os.path.exists(self._path)\n        if self._chdr:\n            self._dir = os.path.abspath(os.getcwd())\n            os.chdir(self._path)\n        return self\n\n    def __exit__(self, tp, val, traceback):\n        if self._chdr and self._dir:\n            os.chdir(self._dir)\n            self._dir = None\n        if self._remove and os.path.exists(self._path):\n            shutil.rmtree(self._path)\n\n        assert not self._remove or not os.path.exists(self._path)\n        assert os.path.exists(os.getcwd())\n\n    def path(self, *path):\n        return os.path.join(\"./\", *path) if self._chdr else os.path.join(self._path, *path)\n\n\ndef read_file_lines(parent_path, file_name):\n    \"\"\"\n    Return the contents of the file as an array where each element is a separate line.\n\n    :param parent_path: Full path to the directory that contains the file.\n    :param file_name: Leaf file name.\n\n    :return: All lines in the file as an array.\n    \"\"\"\n    file_path = os.path.join(parent_path, file_name)\n    with codecs.open(file_path, mode=\"r\", encoding=ENCODING) as f:\n        return f.readlines()\n\n\ndef read_file(parent_path, file_name):\n    \"\"\"\n    Return the contents of the file.\n\n    :param parent_path: Full path to the directory that contains the file.\n    :param file_name: Leaf file name.\n\n    :return: The contents of the file.\n    \"\"\"\n    file_path = os.path.join(parent_path, file_name)\n    with codecs.open(file_path, mode=\"r\", encoding=ENCODING) as f:\n        return f.read()\n\n\ndef get_file_info(path, rel_path):\n    \"\"\"\n    Returns file meta data : location, size, ... etc\n\n    :param path: Path to artifact\n\n    :return: `FileInfo` object\n    \"\"\"\n    if is_directory(path):\n        return FileInfo(rel_path, True, None)\n    else:\n        return FileInfo(rel_path, False, os.path.getsize(path))\n\n\ndef get_relative_path(root_path, target_path):\n    \"\"\"\n    Remove root path common prefix and return part of `path` relative to `root_path`.\n\n    :param root_path: Root path\n    :param target_path: Desired path for common prefix removal\n\n    :return: Path relative to root_path\n    \"\"\"\n    if len(root_path) > len(target_path):\n        raise Exception(f\"Root path '{root_path}' longer than target path '{target_path}'\")\n    common_prefix = os.path.commonprefix([root_path, target_path])\n    return os.path.relpath(target_path, common_prefix)\n\n\ndef mv(target, new_parent):\n    shutil.move(target, new_parent)\n\n\ndef write_to(filename, data):\n    with codecs.open(filename, mode=\"w\", encoding=ENCODING) as handle:\n        handle.write(data)\n\n\ndef append_to(filename, data):\n    with open(filename, \"a\") as handle:\n        handle.write(data)\n\n\ndef make_tarfile(output_filename, source_dir, archive_name, custom_filter=None):\n    # Helper for filtering out modification timestamps\n    def _filter_timestamps(tar_info):\n        tar_info.mtime = 0\n        return tar_info if custom_filter is None else custom_filter(tar_info)\n\n    unzipped_file_handle, unzipped_filename = tempfile.mkstemp()\n    try:\n        with tarfile.open(unzipped_filename, \"w\") as tar:\n            tar.add(source_dir, arcname=archive_name, filter=_filter_timestamps)\n        # When gzipping the tar, don't include the tar's filename or modification time in the\n        # zipped archive (see https://docs.python.org/3/library/gzip.html#gzip.GzipFile)\n        with gzip.GzipFile(\n            filename=\"\", fileobj=open(output_filename, \"wb\"), mode=\"wb\", mtime=0\n        ) as gzipped_tar, open(unzipped_filename, \"rb\") as tar:\n            gzipped_tar.write(tar.read())\n    finally:\n        os.close(unzipped_file_handle)\n\n\ndef _copy_project(src_path, dst_path=\"\"):\n    \"\"\"\n    Internal function used to copy MLflow project during development.\n\n    Copies the content of the whole directory tree except patterns defined in .dockerignore.\n    The MLflow is assumed to be accessible as a local directory in this case.\n\n\n    :param dst_path: MLflow will be copied here\n    :return: name of the MLflow project directory\n    \"\"\"\n\n    def _docker_ignore(mlflow_root):\n        docker_ignore = os.path.join(mlflow_root, \".dockerignore\")\n        patterns = []\n        if os.path.exists(docker_ignore):\n            with open(docker_ignore) as f:\n                patterns = [x.strip() for x in f.readlines()]\n\n        def ignore(_, names):\n            import fnmatch\n\n            res = set()\n            for p in patterns:\n                res.update(set(fnmatch.filter(names, p)))\n            return list(res)\n\n        return ignore if patterns else None\n\n    mlflow_dir = \"mlflow-project\"\n    # check if we have project root\n    assert os.path.isfile(os.path.join(src_path, \"setup.py\")), \"file not found \" + str(\n        os.path.abspath(os.path.join(src_path, \"setup.py\"))\n    )\n    shutil.copytree(src_path, os.path.join(dst_path, mlflow_dir), ignore=_docker_ignore(src_path))\n    return mlflow_dir\n\n\ndef _copy_file_or_tree(src, dst, dst_dir=None):\n    \"\"\"\n    :return: The path to the copied artifacts, relative to `dst`\n    \"\"\"\n    dst_subpath = os.path.basename(os.path.abspath(src))\n    if dst_dir is not None:\n        dst_subpath = os.path.join(dst_dir, dst_subpath)\n    dst_path = os.path.join(dst, dst_subpath)\n    if os.path.isfile(src):\n        dst_dirpath = os.path.dirname(dst_path)\n        if not os.path.exists(dst_dirpath):\n            os.makedirs(dst_dirpath)\n        shutil.copy(src=src, dst=dst_path)\n    else:\n        shutil.copytree(src=src, dst=dst_path, ignore=shutil.ignore_patterns(\"__pycache__\"))\n    return dst_subpath\n\n\ndef _get_local_project_dir_size(project_path):\n    \"\"\"\n    Internal function for reporting the size of a local project directory before copying to\n    destination for cli logging reporting to stdout.\n    :param project_path: local path of the project directory\n    :return: directory file sizes in KB, rounded to single decimal point for legibility\n    \"\"\"\n\n    total_size = 0\n    for root, _, files in os.walk(project_path):\n        for f in files:\n            path = os.path.join(root, f)\n            total_size += os.path.getsize(path)\n    return round(total_size / 1024.0, 1)\n\n\ndef _get_local_file_size(file):\n    \"\"\"\n    Get the size of a local file in KB\n    \"\"\"\n    return round(os.path.getsize(file) / 1024.0, 1)\n\n\ndef get_parent_dir(path):\n    return os.path.abspath(os.path.join(path, os.pardir))\n\n\ndef relative_path_to_artifact_path(path):\n    if os.path == posixpath:\n        return path\n    if os.path.abspath(path) == path:\n        raise Exception(\"This method only works with relative paths.\")\n    return unquote(pathname2url(path))\n\n\ndef path_to_local_file_uri(path):\n    \"\"\"\n    Convert local filesystem path to local file uri.\n    \"\"\"\n    return pathlib.Path(os.path.abspath(path)).as_uri()\n\n\ndef path_to_local_sqlite_uri(path):\n    \"\"\"\n    Convert local filesystem path to sqlite uri.\n    \"\"\"\n    path = posixpath.abspath(pathname2url(os.path.abspath(path)))\n    prefix = \"sqlite://\" if sys.platform == \"win32\" else \"sqlite:///\"\n    return prefix + path\n\n\ndef local_file_uri_to_path(uri):\n    \"\"\"\n    Convert URI to local filesystem path.\n    No-op if the uri does not have the expected scheme.\n    \"\"\"\n    path = uri\n    if uri.startswith(\"file:\"):\n        parsed_path = urllib.parse.urlparse(uri)\n        path = parsed_path.path\n        # Fix for retaining server name in UNC path.\n        if is_windows() and parsed_path.netloc:\n            return urllib.request.url2pathname(rf\"\\\\{parsed_path.netloc}{path}\")\n    return urllib.request.url2pathname(path)\n\n\ndef get_local_path_or_none(path_or_uri):\n    \"\"\"Check if the argument is a local path (no scheme or file:///) and return local path if true,\n    None otherwise.\n    \"\"\"\n    parsed_uri = urllib.parse.urlparse(path_or_uri)\n    if len(parsed_uri.scheme) == 0 or parsed_uri.scheme == \"file\" and len(parsed_uri.netloc) == 0:\n        return local_file_uri_to_path(path_or_uri)\n    else:\n        return None\n\n\ndef yield_file_in_chunks(file, chunk_size=100000000):\n    \"\"\"\n    Generator to chunk-ify the inputted file based on the chunk-size.\n    \"\"\"\n    with open(file, \"rb\") as f:\n        while True:\n            chunk = f.read(chunk_size)\n            if chunk:\n                yield chunk\n            else:\n                break\n\n\ndef download_file_using_http_uri(http_uri, download_path, chunk_size=100000000, headers=None):\n    \"\"\"\n    Downloads a file specified using the `http_uri` to a local `download_path`. This function\n    uses a `chunk_size` to ensure an OOM error is not raised a large file is downloaded.\n\n    Note : This function is meant to download files using presigned urls from various cloud\n            providers.\n    \"\"\"\n    if headers is None:\n        headers = {}\n    with cloud_storage_http_request(\"get\", http_uri, stream=True, headers=headers) as response:\n        augmented_raise_for_status(response)\n        with open(download_path, \"wb\") as output_file:\n            for chunk in response.iter_content(chunk_size=chunk_size):\n                if not chunk:\n                    break\n                output_file.write(chunk)\n\n\ndef _handle_readonly_on_windows(func, path, exc_info):\n    \"\"\"\n    This function should not be called directly but should be passed to `onerror` of\n    `shutil.rmtree` in order to reattempt the removal of a read-only file after making\n    it writable on Windows.\n\n    References:\n    - https://bugs.python.org/issue19643\n    - https://bugs.python.org/issue43657\n    \"\"\"\n    exc_type, exc_value = exc_info[:2]\n    should_reattempt = (\n        os.name == \"nt\"\n        and func in (os.unlink, os.rmdir)\n        and issubclass(exc_type, PermissionError)\n        and exc_value.winerror == 5\n    )\n    if not should_reattempt:\n        raise exc_value\n    os.chmod(path, stat.S_IWRITE)\n    func(path)\n\n\n@cache_return_value_per_process\ndef get_or_create_tmp_dir():\n    \"\"\"\n    Get or create a temporary directory which will be removed once python process exit.\n    \"\"\"\n    from mlflow.utils.databricks_utils import is_in_databricks_runtime, get_repl_id\n\n    if is_in_databricks_runtime() and get_repl_id() is not None:\n        # Note: For python process attached to databricks notebook, atexit does not work.\n        # The directory returned by `dbutils.entry_point.getReplLocalTempDir()`\n        # will be removed once databricks notebook detaches.\n        # The temp directory is designed to be used by all kinds of applications,\n        # so create a child directory \"mlflow\" for storing mlflow temp data.\n        try:\n            repl_local_tmp_dir = _get_dbutils().entry_point.getReplLocalTempDir()\n        except Exception:\n            repl_local_tmp_dir = os.path.join(\"/tmp\", \"repl_tmp_data\", get_repl_id())\n\n        tmp_dir = os.path.join(repl_local_tmp_dir, \"mlflow\")\n        os.makedirs(tmp_dir, exist_ok=True)\n    else:\n        tmp_dir = tempfile.mkdtemp()\n        # mkdtemp creates a directory with permission 0o700\n        # change it to be 0o777 to ensure it can be seen in spark UDF\n        os.chmod(tmp_dir, 0o777)\n        atexit.register(shutil.rmtree, tmp_dir, ignore_errors=True)\n\n    return tmp_dir\n\n\n@cache_return_value_per_process\ndef get_or_create_nfs_tmp_dir():\n    \"\"\"\n    Get or create a temporary NFS directory which will be removed once python process exit.\n    \"\"\"\n    from mlflow.utils.databricks_utils import is_in_databricks_runtime, get_repl_id\n    from mlflow.utils.nfs_on_spark import get_nfs_cache_root_dir\n\n    nfs_root_dir = get_nfs_cache_root_dir()\n\n    if is_in_databricks_runtime() and get_repl_id() is not None:\n        # Note: In databricks, atexit hook does not work.\n        # The directory returned by `dbutils.entry_point.getReplNFSTempDir()`\n        # will be removed once databricks notebook detaches.\n        # The temp directory is designed to be used by all kinds of applications,\n        # so create a child directory \"mlflow\" for storing mlflow temp data.\n        try:\n            repl_nfs_tmp_dir = _get_dbutils().entry_point.getReplNFSTempDir()\n        except Exception:\n            repl_nfs_tmp_dir = os.path.join(nfs_root_dir, \"repl_tmp_data\", get_repl_id())\n\n        tmp_nfs_dir = os.path.join(repl_nfs_tmp_dir, \"mlflow\")\n        os.makedirs(tmp_nfs_dir, exist_ok=True)\n    else:\n        tmp_nfs_dir = tempfile.mkdtemp(dir=nfs_root_dir)\n        # mkdtemp creates a directory with permission 0o700\n        # change it to be 0o777 to ensure it can be seen in spark UDF\n        os.chmod(tmp_nfs_dir, 0o777)\n        atexit.register(shutil.rmtree, tmp_nfs_dir, ignore_errors=True)\n\n    return tmp_nfs_dir\n\n\ndef write_spark_dataframe_to_parquet_on_local_disk(spark_df, output_path):\n    \"\"\"\n    Write spark dataframe in parquet format to local disk.\n\n    :param spark_df: Spark dataframe\n    :param output_path: path to write the data to\n    \"\"\"\n    from mlflow.utils.databricks_utils import is_in_databricks_runtime\n    import uuid\n\n    if is_in_databricks_runtime():\n        dbfs_path = os.path.join(\".mlflow\", \"cache\", str(uuid.uuid4()))\n        spark_df.coalesce(1).write.format(\"parquet\").save(dbfs_path)\n        shutil.copytree(\"/dbfs/\" + dbfs_path, output_path)\n        shutil.rmtree(\"/dbfs/\" + dbfs_path)\n    else:\n        spark_df.coalesce(1).write.format(\"parquet\").save(output_path)\n\n\ndef shutil_copytree_without_file_permissions(src_dir, dst_dir):\n    \"\"\"\n    Copies the directory src_dir into dst_dir, without preserving filesystem permissions\n    \"\"\"\n    for dirpath, dirnames, filenames in os.walk(src_dir):\n        for dirname in dirnames:\n            relative_dir_path = os.path.relpath(os.path.join(dirpath, dirname), src_dir)\n            # For each directory <dirname> immediately under <dirpath>, create an equivalently-named\n            # directory under the destination directory\n            abs_dir_path = os.path.join(dst_dir, relative_dir_path)\n            os.mkdir(abs_dir_path)\n        for filename in filenames:\n            # For each file with name <filename> immediately under <dirpath>, copy that file to\n            # the appropriate location in the destination directory\n            file_path = os.path.join(dirpath, filename)\n            relative_file_path = os.path.relpath(file_path, src_dir)\n            abs_file_path = os.path.join(dst_dir, relative_file_path)\n            shutil.copyfile(file_path, abs_file_path)\n\n\ndef contains_path_separator(path):\n    \"\"\"\n    Returns True if a path contains a path separator, False otherwise.\n    \"\"\"\n    return any((sep in path) for sep in (os.path.sep, os.path.altsep) if sep is not None)\n", "import time\nimport uuid\nfrom unittest import mock\nfrom typing import NamedTuple, List\n\nimport pytest\n\nfrom mlflow.entities.model_registry import ModelVersion, ModelVersionTag, RegisteredModelTag\nfrom mlflow.exceptions import MlflowException\nfrom mlflow.protos.databricks_pb2 import INVALID_PARAMETER_VALUE, RESOURCE_DOES_NOT_EXIST, ErrorCode\nfrom mlflow.store.model_registry.file_store import FileStore\nfrom mlflow.utils.file_utils import path_to_local_file_uri, write_yaml\nfrom mlflow.utils.time_utils import get_current_time_millis\nfrom tests.helper_functions import random_int, random_str\n\n\n@pytest.fixture\ndef store(tmp_path):\n    return FileStore(str(tmp_path))\n\n\n@pytest.fixture\ndef registered_model_names():\n    return [random_str() for _ in range(3)]\n\n\n@pytest.fixture\ndef rm_data(registered_model_names, tmp_path):\n    rm_data = {}\n    for name in registered_model_names:\n        # create registered model\n        rm_folder = tmp_path.joinpath(FileStore.MODELS_FOLDER_NAME, name)\n        rm_folder.mkdir(parents=True, exist_ok=True)\n        creation_time = get_current_time_millis()\n        d = {\n            \"name\": name,\n            \"creation_timestamp\": creation_time,\n            \"last_updated_timestamp\": creation_time,\n            \"description\": None,\n            \"latest_versions\": [],\n            \"tags\": {},\n        }\n        rm_data[name] = d\n        write_yaml(rm_folder, FileStore.META_DATA_FILE_NAME, d)\n        tags_dir = rm_folder.joinpath(FileStore.TAGS_FOLDER_NAME)\n        tags_dir.mkdir(parents=True, exist_ok=True)\n    return rm_data\n\n\ndef test_create_registered_model(store):\n    # Error cases\n    with pytest.raises(MlflowException, match=r\"Registered model name cannot be empty\\.\"):\n        store.create_registered_model(None)\n    with pytest.raises(MlflowException, match=r\"Registered model name cannot be empty\\.\"):\n        store.create_registered_model(\"\")\n\n    name = random_str()\n    model = store.create_registered_model(name)\n    assert model.name == name\n    assert model.latest_versions == []\n    assert model.creation_timestamp == model.last_updated_timestamp\n    assert model.tags == {}\n\n\ndef test_create_registered_model_with_name_that_looks_like_path(store, tmp_path):\n    name = str(tmp_path.joinpath(\"test\"))\n    with pytest.raises(\n        MlflowException, match=r\"Registered model name cannot contain path separator\"\n    ):\n        store.get_registered_model(name)\n\n\ndef _verify_registered_model(fs, name, rm_data):\n    rm = fs.get_registered_model(name)\n    assert rm.name == name\n    assert rm.creation_timestamp == rm_data[name][\"creation_timestamp\"]\n    assert rm.last_updated_timestamp == rm_data[name][\"last_updated_timestamp\"]\n    assert rm.description == rm_data[name][\"description\"]\n    assert rm.latest_versions == rm_data[name][\"latest_versions\"]\n    assert rm.tags == rm_data[name][\"tags\"]\n\n\ndef test_get_registered_model(store, registered_model_names, rm_data):\n    for name in registered_model_names:\n        _verify_registered_model(store, name, rm_data)\n\n    # test that fake registered models dont exist.\n    name = random_str()\n    with pytest.raises(MlflowException, match=f\"Registered Model with name={name} not found\"):\n        store.get_registered_model(name)\n\n\ndef test_list_registered_model(store, registered_model_names, rm_data):\n    for rm in store.list_registered_models(max_results=10, page_token=None):\n        name = rm.name\n        assert name in registered_model_names\n        assert name == rm_data[name][\"name\"]\n\n\ndef test_rename_registered_model(store, registered_model_names, rm_data):\n    # Error cases\n    model_name = registered_model_names[0]\n    with pytest.raises(MlflowException, match=r\"Registered model name cannot be empty\\.\"):\n        store.rename_registered_model(model_name, None)\n\n    # test that names of existing registered models are checked before renaming\n    other_model_name = registered_model_names[1]\n    with pytest.raises(\n        MlflowException, match=rf\"Registered Model \\(name={other_model_name}\\) already exists\\.\"\n    ):\n        store.rename_registered_model(model_name, other_model_name)\n\n    new_name = model_name + \"!!!\"\n    store.rename_registered_model(model_name, new_name)\n    assert store.get_registered_model(new_name).name == new_name\n\n\ndef _extract_names(registered_models):\n    return [rm.name for rm in registered_models]\n\n\ndef test_delete_registered_model(store, registered_model_names, rm_data):\n    model_name = registered_model_names[random_int(0, len(registered_model_names) - 1)]\n\n    # Error cases\n    with pytest.raises(\n        MlflowException, match=f\"Registered Model with name={model_name}!!! not found\"\n    ):\n        store.delete_registered_model(model_name + \"!!!\")\n\n    store.delete_registered_model(model_name)\n    assert model_name not in _extract_names(\n        store.list_registered_models(max_results=10, page_token=None)\n    )\n    # Cannot delete a deleted model\n    with pytest.raises(MlflowException, match=f\"Registered Model with name={model_name} not found\"):\n        store.delete_registered_model(model_name)\n\n\ndef test_list_registered_model_paginated(store):\n    for _ in range(10):\n        store.create_registered_model(random_str())\n    rms1 = store.list_registered_models(max_results=4, page_token=None)\n    assert len(rms1) == 4\n    assert rms1.token is not None\n    rms2 = store.list_registered_models(max_results=4, page_token=None)\n    assert len(rms2) == 4\n    assert rms2.token is not None\n    assert rms1 == rms2\n    rms3 = store.list_registered_models(max_results=500, page_token=rms2.token)\n    assert len(rms3) == 6\n    assert rms3.token is None\n\n\ndef test_list_registered_model_paginated_returns_in_correct_order(store):\n    rms = [store.create_registered_model(f\"RM{i:03}\").name for i in range(50)]\n\n    # test that pagination will return all valid results in sorted order\n    # by name ascending\n    result = store.list_registered_models(max_results=5, page_token=None)\n    assert result.token is not None\n    assert _extract_names(result) == rms[0:5]\n\n    result = store.list_registered_models(page_token=result.token, max_results=10)\n    assert result.token is not None\n    assert _extract_names(result) == rms[5:15]\n\n    result = store.list_registered_models(page_token=result.token, max_results=20)\n    assert result.token is not None\n    assert _extract_names(result) == rms[15:35]\n\n    result = store.list_registered_models(page_token=result.token, max_results=100)\n    assert result.token is None\n    assert _extract_names(result) == rms[35:]\n\n\ndef test_list_registered_model_paginated_errors(store):\n    rms = [store.create_registered_model(f\"RM{i:03}\").name for i in range(50)]\n    # test that providing a completely invalid page token throws\n    with pytest.raises(\n        MlflowException, match=r\"Invalid page token, could not base64-decode\"\n    ) as exception_context:\n        store.list_registered_models(page_token=\"evilhax\", max_results=20)\n    assert exception_context.value.error_code == ErrorCode.Name(INVALID_PARAMETER_VALUE)\n\n    # test that providing too large of a max_results throws\n    with pytest.raises(\n        MlflowException, match=r\"Invalid value for max_results\"\n    ) as exception_context:\n        store.list_registered_models(page_token=\"evilhax\", max_results=1e15)\n    assert exception_context.value.error_code == ErrorCode.Name(INVALID_PARAMETER_VALUE)\n    # list should not return deleted models\n    store.delete_registered_model(name=\"RM000\")\n    assert set(\n        _extract_names(store.list_registered_models(max_results=100, page_token=None))\n    ) == set(rms[1:])\n\n\ndef _create_model_version(\n    fs,\n    name,\n    source=\"path/to/source\",\n    run_id=uuid.uuid4().hex,\n    tags=None,\n    run_link=None,\n    description=None,\n):\n    time.sleep(0.001)\n    return fs.create_model_version(\n        name, source, run_id, tags, run_link=run_link, description=description\n    )\n\n\ndef _stage_to_version_map(latest_versions):\n    return {mvd.current_stage: mvd.version for mvd in latest_versions}\n\n\ndef test_get_latest_versions(store):\n    name = \"test_for_latest_versions\"\n    rmd1 = store.create_registered_model(name)\n    assert rmd1.latest_versions == []\n\n    mv1 = _create_model_version(store, name)\n    assert mv1.version == 1\n    rmd2 = store.get_registered_model(name)\n    assert _stage_to_version_map(rmd2.latest_versions) == {\"None\": 1}\n\n    # add a bunch more\n    mv2 = _create_model_version(store, name)\n    assert mv2.version == 2\n    store.transition_model_version_stage(\n        name=mv2.name, version=mv2.version, stage=\"Production\", archive_existing_versions=False\n    )\n\n    mv3 = _create_model_version(store, name)\n    assert mv3.version == 3\n    store.transition_model_version_stage(\n        name=mv3.name, version=mv3.version, stage=\"Production\", archive_existing_versions=False\n    )\n    mv4 = _create_model_version(store, name)\n    assert mv4.version == 4\n    store.transition_model_version_stage(\n        name=mv4.name, version=mv4.version, stage=\"Staging\", archive_existing_versions=False\n    )\n\n    # test that correct latest versions are returned for each stage\n    rmd4 = store.get_registered_model(name)\n    assert _stage_to_version_map(rmd4.latest_versions) == {\n        \"None\": 1,\n        \"Production\": 3,\n        \"Staging\": 4,\n    }\n    assert _stage_to_version_map(store.get_latest_versions(name=name, stages=None)) == {\n        \"None\": 1,\n        \"Production\": 3,\n        \"Staging\": 4,\n    }\n    assert _stage_to_version_map(store.get_latest_versions(name=name, stages=[])) == {\n        \"None\": 1,\n        \"Production\": 3,\n        \"Staging\": 4,\n    }\n    assert _stage_to_version_map(store.get_latest_versions(name=name, stages=[\"Production\"])) == {\n        \"Production\": 3\n    }\n    assert _stage_to_version_map(store.get_latest_versions(name=name, stages=[\"production\"])) == {\n        \"Production\": 3\n    }  # The stages are case insensitive.\n    assert _stage_to_version_map(store.get_latest_versions(name=name, stages=[\"pROduction\"])) == {\n        \"Production\": 3\n    }  # The stages are case insensitive.\n    assert _stage_to_version_map(\n        store.get_latest_versions(name=name, stages=[\"None\", \"Production\"])\n    ) == {\"None\": 1, \"Production\": 3}\n\n    # delete latest Production, and should point to previous one\n    store.delete_model_version(name=mv3.name, version=mv3.version)\n    rmd5 = store.get_registered_model(name=name)\n    assert _stage_to_version_map(rmd5.latest_versions) == {\n        \"None\": 1,\n        \"Production\": 2,\n        \"Staging\": 4,\n    }\n    assert _stage_to_version_map(store.get_latest_versions(name=name, stages=None)) == {\n        \"None\": 1,\n        \"Production\": 2,\n        \"Staging\": 4,\n    }\n    assert _stage_to_version_map(store.get_latest_versions(name=name, stages=[\"Production\"])) == {\n        \"Production\": 2\n    }\n\n\ndef test_set_registered_model_tag(store):\n    name1 = \"SetRegisteredModelTag_TestMod\"\n    name2 = \"SetRegisteredModelTag_TestMod 2\"\n    initial_tags = [\n        RegisteredModelTag(\"key\", \"value\"),\n        RegisteredModelTag(\"anotherKey\", \"some other value\"),\n    ]\n    store.create_registered_model(name1, initial_tags)\n    store.create_registered_model(name2, initial_tags)\n    new_tag = RegisteredModelTag(\"randomTag\", \"not a random value\")\n    store.set_registered_model_tag(name1, new_tag)\n    rm1 = store.get_registered_model(name=name1)\n    all_tags = [*initial_tags, new_tag]\n    assert rm1.tags == {tag.key: tag.value for tag in all_tags}\n\n    # test overriding a tag with the same key\n    overriding_tag = RegisteredModelTag(\"key\", \"overriding\")\n    store.set_registered_model_tag(name1, overriding_tag)\n    all_tags = [tag for tag in all_tags if tag.key != \"key\"] + [overriding_tag]\n    rm1 = store.get_registered_model(name=name1)\n    assert rm1.tags == {tag.key: tag.value for tag in all_tags}\n    # does not affect other models with the same key\n    rm2 = store.get_registered_model(name=name2)\n    assert rm2.tags == {tag.key: tag.value for tag in initial_tags}\n\n    # can not set tag on deleted (non-existed) registered model\n    store.delete_registered_model(name1)\n    with pytest.raises(\n        MlflowException, match=f\"Registered Model with name={name1} not found\"\n    ) as exception_context:\n        store.set_registered_model_tag(name1, overriding_tag)\n    assert exception_context.value.error_code == ErrorCode.Name(RESOURCE_DOES_NOT_EXIST)\n    # test cannot set tags that are too long\n    long_tag = RegisteredModelTag(\"longTagKey\", \"a\" * 5001)\n    with pytest.raises(\n        MlflowException,\n        match=(r\"Registered model value '.+' had length \\d+, which exceeded length limit of 5000\"),\n    ) as exception_context:\n        store.set_registered_model_tag(name2, long_tag)\n    assert exception_context.value.error_code == ErrorCode.Name(INVALID_PARAMETER_VALUE)\n    # test can set tags that are somewhat long\n    long_tag = RegisteredModelTag(\"longTagKey\", \"a\" * 4999)\n    store.set_registered_model_tag(name2, long_tag)\n    # can not set invalid tag\n    with pytest.raises(MlflowException, match=r\"Tag name cannot be None\") as exception_context:\n        store.set_registered_model_tag(name2, RegisteredModelTag(key=None, value=\"\"))\n    assert exception_context.value.error_code == ErrorCode.Name(INVALID_PARAMETER_VALUE)\n    # can not use invalid model name\n    with pytest.raises(\n        MlflowException, match=r\"Registered model name cannot be empty\"\n    ) as exception_context:\n        store.set_registered_model_tag(None, RegisteredModelTag(key=\"key\", value=\"value\"))\n    assert exception_context.value.error_code == ErrorCode.Name(INVALID_PARAMETER_VALUE)\n\n\ndef test_delete_registered_model_tag(store):\n    name1 = \"DeleteRegisteredModelTag_TestMod\"\n    name2 = \"DeleteRegisteredModelTag_TestMod 2\"\n    initial_tags = [\n        RegisteredModelTag(\"key\", \"value\"),\n        RegisteredModelTag(\"anotherKey\", \"some other value\"),\n    ]\n    store.create_registered_model(name1, initial_tags)\n    store.create_registered_model(name2, initial_tags)\n    new_tag = RegisteredModelTag(\"randomTag\", \"not a random value\")\n    store.set_registered_model_tag(name1, new_tag)\n    store.delete_registered_model_tag(name1, \"randomTag\")\n    rm1 = store.get_registered_model(name=name1)\n    assert rm1.tags == {tag.key: tag.value for tag in initial_tags}\n\n    # testing deleting a key does not affect other models with the same key\n    store.delete_registered_model_tag(name1, \"key\")\n    rm1 = store.get_registered_model(name=name1)\n    rm2 = store.get_registered_model(name=name2)\n    assert rm1.tags == {\"anotherKey\": \"some other value\"}\n    assert rm2.tags == {tag.key: tag.value for tag in initial_tags}\n\n    # delete tag that is already deleted does nothing\n    store.delete_registered_model_tag(name1, \"key\")\n    rm1 = store.get_registered_model(name=name1)\n    assert rm1.tags == {\"anotherKey\": \"some other value\"}\n\n    # can not delete tag on deleted (non-existed) registered model\n    store.delete_registered_model(name1)\n    with pytest.raises(\n        MlflowException, match=f\"Registered Model with name={name1} not found\"\n    ) as exception_context:\n        store.delete_registered_model_tag(name1, \"anotherKey\")\n    assert exception_context.value.error_code == ErrorCode.Name(RESOURCE_DOES_NOT_EXIST)\n    # can not delete tag with invalid key\n    with pytest.raises(MlflowException, match=r\"Tag name cannot be None\") as exception_context:\n        store.delete_registered_model_tag(name2, None)\n    assert exception_context.value.error_code == ErrorCode.Name(INVALID_PARAMETER_VALUE)\n    # can not use invalid model name\n    with pytest.raises(\n        MlflowException, match=r\"Registered model name cannot be empty\"\n    ) as exception_context:\n        store.delete_registered_model_tag(None, \"key\")\n    assert exception_context.value.error_code == ErrorCode.Name(INVALID_PARAMETER_VALUE)\n\n\ndef test_create_model_version(store):\n    name = \"test_for_create_MV\"\n    store.create_registered_model(name)\n    run_id = uuid.uuid4().hex\n    with mock.patch(\"time.time\", return_value=456778):\n        mv1 = _create_model_version(store, name, \"a/b/CD\", run_id)\n        assert mv1.name == name\n        assert mv1.version == 1\n\n    mvd1 = store.get_model_version(mv1.name, mv1.version)\n    assert mvd1.name == name\n    assert mvd1.version == 1\n    assert mvd1.current_stage == \"None\"\n    assert mvd1.creation_timestamp == 456778000\n    assert mvd1.last_updated_timestamp == 456778000\n    assert mvd1.description is None\n    assert mvd1.source == \"a/b/CD\"\n    assert mvd1.run_id == run_id\n    assert mvd1.status == \"READY\"\n    assert mvd1.status_message is None\n    assert mvd1.tags == {}\n\n    # new model versions for same name autoincrement versions\n    mv2 = _create_model_version(store, name)\n    mvd2 = store.get_model_version(name=mv2.name, version=mv2.version)\n    assert mv2.version == 2\n    assert mvd2.version == 2\n\n    # create model version with tags return model version entity with tags\n    tags = [ModelVersionTag(\"key\", \"value\"), ModelVersionTag(\"anotherKey\", \"some other value\")]\n    mv3 = _create_model_version(store, name, tags=tags)\n    mvd3 = store.get_model_version(name=mv3.name, version=mv3.version)\n    assert mv3.version == 3\n    assert mv3.tags == {tag.key: tag.value for tag in tags}\n    assert mvd3.version == 3\n    assert mvd3.tags == {tag.key: tag.value for tag in tags}\n\n    # create model versions with runLink\n    run_link = \"http://localhost:3000/path/to/run/\"\n    mv4 = _create_model_version(store, name, run_link=run_link)\n    mvd4 = store.get_model_version(name, mv4.version)\n    assert mv4.version == 4\n    assert mv4.run_link == run_link\n    assert mvd4.version == 4\n    assert mvd4.run_link == run_link\n\n    # create model version with description\n    description = \"the best model ever\"\n    mv5 = _create_model_version(store, name, description=description)\n    mvd5 = store.get_model_version(name, mv5.version)\n    assert mv5.version == 5\n    assert mv5.description == description\n    assert mvd5.version == 5\n    assert mvd5.description == description\n\n    # create model version without runId\n    mv6 = _create_model_version(store, name, run_id=None)\n    mvd6 = store.get_model_version(name, mv6.version)\n    assert mv6.version == 6\n    assert mv6.run_id is None\n    assert mvd6.version == 6\n    assert mvd6.run_id is None\n\n\ndef test_update_model_version(store):\n    name = \"test_for_update_MV\"\n    store.create_registered_model(name)\n    mv1 = _create_model_version(store, name)\n    mvd1 = store.get_model_version(name=mv1.name, version=mv1.version)\n    assert mvd1.name == name\n    assert mvd1.version == 1\n    assert mvd1.current_stage == \"None\"\n\n    # update stage\n    store.transition_model_version_stage(\n        name=mv1.name, version=mv1.version, stage=\"Production\", archive_existing_versions=False\n    )\n    mvd2 = store.get_model_version(name=mv1.name, version=mv1.version)\n    assert mvd2.name == name\n    assert mvd2.version == 1\n    assert mvd2.current_stage == \"Production\"\n    assert mvd2.description is None\n\n    # update description\n    store.update_model_version(name=mv1.name, version=mv1.version, description=\"test model version\")\n    mvd3 = store.get_model_version(name=mv1.name, version=mv1.version)\n    assert mvd3.name == name\n    assert mvd3.version == 1\n    assert mvd3.current_stage == \"Production\"\n    assert mvd3.description == \"test model version\"\n\n    # only valid stages can be set\n    with pytest.raises(\n        MlflowException,\n        match=(\n            r\"Invalid Model Version stage: unknown\\. \"\n            r\"Value must be one of None, Staging, Production, Archived\\.\"\n        ),\n    ) as exception_context:\n        store.transition_model_version_stage(\n            mv1.name, mv1.version, stage=\"unknown\", archive_existing_versions=False\n        )\n    assert exception_context.value.error_code == ErrorCode.Name(INVALID_PARAMETER_VALUE)\n\n    # stages are case-insensitive and auto-corrected to system stage names\n    for stage_name in [\"STAGING\", \"staging\", \"StAgInG\"]:\n        store.transition_model_version_stage(\n            name=mv1.name,\n            version=mv1.version,\n            stage=stage_name,\n            archive_existing_versions=False,\n        )\n        mvd5 = store.get_model_version(name=mv1.name, version=mv1.version)\n        assert mvd5.current_stage == \"Staging\"\n\n\ndef test_transition_model_version_stage_when_archive_existing_versions_is_false(store):\n    name = \"model\"\n    store.create_registered_model(name)\n    mv1 = _create_model_version(store, name)\n    mv2 = _create_model_version(store, name)\n    mv3 = _create_model_version(store, name)\n\n    # test that when `archive_existing_versions` is False, transitioning a model version\n    # to the inactive stages (\"Archived\" and \"None\") does not throw.\n    for stage in [\"Archived\", \"None\"]:\n        store.transition_model_version_stage(name, mv1.version, stage, False)\n\n    store.transition_model_version_stage(name, mv1.version, \"Staging\", False)\n    store.transition_model_version_stage(name, mv2.version, \"Production\", False)\n    store.transition_model_version_stage(name, mv3.version, \"Staging\", False)\n\n    mvd1 = store.get_model_version(name=name, version=mv1.version)\n    mvd2 = store.get_model_version(name=name, version=mv2.version)\n    mvd3 = store.get_model_version(name=name, version=mv3.version)\n\n    assert mvd1.current_stage == \"Staging\"\n    assert mvd2.current_stage == \"Production\"\n    assert mvd3.current_stage == \"Staging\"\n\n    store.transition_model_version_stage(name, mv3.version, \"Production\", False)\n\n    mvd1 = store.get_model_version(name=name, version=mv1.version)\n    mvd2 = store.get_model_version(name=name, version=mv2.version)\n    mvd3 = store.get_model_version(name=name, version=mv3.version)\n\n    assert mvd1.current_stage == \"Staging\"\n    assert mvd2.current_stage == \"Production\"\n    assert mvd3.current_stage == \"Production\"\n\n\ndef test_transition_model_version_stage_when_archive_existing_versions_is_true(store):\n    name = \"model\"\n    store.create_registered_model(name)\n    mv1 = _create_model_version(store, name)\n    mv2 = _create_model_version(store, name)\n    mv3 = _create_model_version(store, name)\n\n    msg = (\n        r\"Model version transition cannot archive existing model versions \"\n        r\"because .+ is not an Active stage\"\n    )\n\n    # test that when `archive_existing_versions` is True, transitioning a model version\n    # to the inactive stages (\"Archived\" and \"None\") throws.\n    for stage in [\"Archived\", \"None\"]:\n        with pytest.raises(MlflowException, match=msg):\n            store.transition_model_version_stage(name, mv1.version, stage, True)\n\n    store.transition_model_version_stage(name, mv1.version, \"Staging\", False)\n    store.transition_model_version_stage(name, mv2.version, \"Production\", False)\n    store.transition_model_version_stage(name, mv3.version, \"Staging\", True)\n\n    mvd1 = store.get_model_version(name=name, version=mv1.version)\n    mvd2 = store.get_model_version(name=name, version=mv2.version)\n    mvd3 = store.get_model_version(name=name, version=mv3.version)\n\n    assert mvd1.current_stage == \"Archived\"\n    assert mvd2.current_stage == \"Production\"\n    assert mvd3.current_stage == \"Staging\"\n    assert mvd1.last_updated_timestamp == mvd3.last_updated_timestamp\n\n    store.transition_model_version_stage(name, mv3.version, \"Production\", True)\n\n    mvd1 = store.get_model_version(name=name, version=mv1.version)\n    mvd2 = store.get_model_version(name=name, version=mv2.version)\n    mvd3 = store.get_model_version(name=name, version=mv3.version)\n\n    assert mvd1.current_stage == \"Archived\"\n    assert mvd2.current_stage == \"Archived\"\n    assert mvd3.current_stage == \"Production\"\n    assert mvd2.last_updated_timestamp == mvd3.last_updated_timestamp\n\n    for uncanonical_stage_name in [\"STAGING\", \"staging\", \"StAgInG\"]:\n        store.transition_model_version_stage(mv1.name, mv1.version, \"Staging\", False)\n        store.transition_model_version_stage(mv2.name, mv2.version, \"None\", False)\n\n        # stage names are case-insensitive and auto-corrected to system stage names\n        store.transition_model_version_stage(mv2.name, mv2.version, uncanonical_stage_name, True)\n\n        mvd1 = store.get_model_version(name=mv1.name, version=mv1.version)\n        mvd2 = store.get_model_version(name=mv2.name, version=mv2.version)\n        assert mvd1.current_stage == \"Archived\"\n        assert mvd2.current_stage == \"Staging\"\n\n\ndef test_delete_model_version(store):\n    name = \"test_for_delete_MV\"\n    initial_tags = [\n        ModelVersionTag(\"key\", \"value\"),\n        ModelVersionTag(\"anotherKey\", \"some other value\"),\n    ]\n    store.create_registered_model(name)\n    mv = _create_model_version(store, name, tags=initial_tags)\n    mvd = store.get_model_version(name=mv.name, version=mv.version)\n    assert mvd.name == name\n\n    store.delete_model_version(name=mv.name, version=mv.version)\n\n    # cannot get a deleted model version\n    with pytest.raises(\n        MlflowException,\n        match=rf\"Model Version \\(name={mv.name}, version={mv.version}\\) not found\",\n    ) as exception_context:\n        store.get_model_version(name=mv.name, version=mv.version)\n    assert exception_context.value.error_code == ErrorCode.Name(RESOURCE_DOES_NOT_EXIST)\n\n    # cannot update a delete\n    with pytest.raises(\n        MlflowException,\n        match=rf\"Model Version \\(name={mv.name}, version={mv.version}\\) not found\",\n    ) as exception_context:\n        store.update_model_version(mv.name, mv.version, description=\"deleted!\")\n    assert exception_context.value.error_code == ErrorCode.Name(RESOURCE_DOES_NOT_EXIST)\n\n    # cannot delete it again\n    with pytest.raises(\n        MlflowException,\n        match=rf\"Model Version \\(name={mv.name}, version={mv.version}\\) not found\",\n    ) as exception_context:\n        store.delete_model_version(name=mv.name, version=mv.version)\n    assert exception_context.value.error_code == ErrorCode.Name(RESOURCE_DOES_NOT_EXIST)\n\n\ndef _search_model_versions(fs, filter_string=None, max_results=10, order_by=None, page_token=None):\n    return fs.search_model_versions(\n        filter_string=filter_string,\n        max_results=max_results,\n        order_by=order_by,\n        page_token=page_token,\n    )\n\n\ndef test_search_model_versions(store):\n    # create some model versions\n    name = \"test_for_search_MV\"\n    store.create_registered_model(name)\n    run_id_1 = uuid.uuid4().hex\n    run_id_2 = uuid.uuid4().hex\n    run_id_3 = uuid.uuid4().hex\n    mv1 = _create_model_version(store, name=name, source=\"A/B\", run_id=run_id_1)\n    assert mv1.version == 1\n    mv2 = _create_model_version(store, name=name, source=\"A/C\", run_id=run_id_2)\n    assert mv2.version == 2\n    mv3 = _create_model_version(store, name=name, source=\"A/D\", run_id=run_id_2)\n    assert mv3.version == 3\n    mv4 = _create_model_version(store, name=name, source=\"A/D\", run_id=run_id_3)\n    assert mv4.version == 4\n\n    def search_versions(filter_string):\n        return [mvd.version for mvd in _search_model_versions(store, filter_string)]\n\n    # search using name should return all 4 versions\n    assert set(search_versions(\"name='%s'\" % name)) == {1, 2, 3, 4}\n\n    # search using version\n    assert set(search_versions(\"version_number=2\")) == {2}\n    assert set(search_versions(\"version_number<=3\")) == {1, 2, 3}\n\n    # search using run_id_1 should return version 1\n    assert set(search_versions(f\"run_id='{run_id_1}'\")) == {1}\n\n    # search using run_id_2 should return versions 2 and 3\n    assert set(search_versions(f\"run_id='{run_id_2}'\")) == {2, 3}\n\n    # search using the IN operator should return all versions\n    assert set(search_versions(f\"run_id IN ('{run_id_1}','{run_id_2}')\")) == {1, 2, 3}\n\n    # search IN operator is case sensitive\n    assert set(search_versions(f\"run_id IN ('{run_id_1.upper()}','{run_id_2}')\")) == {2, 3}\n\n    # search IN operator with right-hand side value containing whitespaces\n    assert set(search_versions(f\"run_id IN ('{run_id_1}', '{run_id_2}')\")) == {1, 2, 3}\n\n    # search using the IN operator with bad lists should return exceptions\n    with pytest.raises(\n        MlflowException,\n        match=(\n            r\"While parsing a list in the query, \"\n            r\"expected string value, punctuation, or whitespace, \"\n            r\"but got different type in list\"\n        ),\n    ) as exception_context:\n        search_versions(\"run_id IN (1,2,3)\")\n    assert exception_context.value.error_code == ErrorCode.Name(INVALID_PARAMETER_VALUE)\n\n    assert set(search_versions(f\"run_id LIKE '{run_id_2[:30]}%'\")) == {2, 3}\n\n    assert set(search_versions(f\"run_id ILIKE '{run_id_2[:30].upper()}%'\")) == {2, 3}\n\n    # search using the IN operator with empty lists should return exceptions\n    with pytest.raises(\n        MlflowException,\n        match=(\n            r\"While parsing a list in the query, \"\n            r\"expected a non-empty list of string values, \"\n            r\"but got empty list\"\n        ),\n    ) as exception_context:\n        search_versions(\"run_id IN ()\")\n    assert exception_context.value.error_code == ErrorCode.Name(INVALID_PARAMETER_VALUE)\n\n    # search using an ill-formed IN operator correctly throws exception\n    with pytest.raises(\n        MlflowException, match=r\"Invalid clause\\(s\\) in filter string\"\n    ) as exception_context:\n        search_versions(\"run_id IN (\")\n    assert exception_context.value.error_code == ErrorCode.Name(INVALID_PARAMETER_VALUE)\n\n    with pytest.raises(\n        MlflowException, match=r\"Invalid clause\\(s\\) in filter string\"\n    ) as exception_context:\n        search_versions(\"run_id IN\")\n    assert exception_context.value.error_code == ErrorCode.Name(INVALID_PARAMETER_VALUE)\n\n    with pytest.raises(\n        MlflowException, match=r\"Invalid clause\\(s\\) in filter string\"\n    ) as exception_context:\n        search_versions(\"name LIKE\")\n    assert exception_context.value.error_code == ErrorCode.Name(INVALID_PARAMETER_VALUE)\n\n    with pytest.raises(\n        MlflowException,\n        match=(\n            r\"While parsing a list in the query, \"\n            r\"expected a non-empty list of string values, \"\n            r\"but got ill-formed list\"\n        ),\n    ) as exception_context:\n        search_versions(\"run_id IN (,)\")\n    assert exception_context.value.error_code == ErrorCode.Name(INVALID_PARAMETER_VALUE)\n\n    with pytest.raises(\n        MlflowException,\n        match=(\n            r\"While parsing a list in the query, \"\n            r\"expected a non-empty list of string values, \"\n            r\"but got ill-formed list\"\n        ),\n    ) as exception_context:\n        search_versions(\"run_id IN ('runid1',,'runid2')\")\n    assert exception_context.value.error_code == ErrorCode.Name(INVALID_PARAMETER_VALUE)\n\n    # search using source_path \"A/D\" should return version 3 and 4\n    assert set(search_versions(\"source_path = 'A/D'\")) == {3, 4}\n\n    # search using source_path \"A\" should not return anything\n    assert len(search_versions(\"source_path = 'A'\")) == 0\n    assert len(search_versions(\"source_path = 'A/'\")) == 0\n    assert len(search_versions(\"source_path = ''\")) == 0\n\n    # delete mv4. search should not return version 4\n    store.delete_model_version(name=mv4.name, version=mv4.version)\n    assert set(search_versions(\"\")) == {1, 2, 3}\n\n    assert set(search_versions(None)) == {1, 2, 3}\n\n    assert set(search_versions(f\"name='{name}'\")) == {1, 2, 3}\n\n    store.transition_model_version_stage(\n        name=mv1.name, version=mv1.version, stage=\"production\", archive_existing_versions=False\n    )\n\n    store.update_model_version(\n        name=mv1.name, version=mv1.version, description=\"Online prediction model!\"\n    )\n\n    mvds = store.search_model_versions(\"run_id = '%s'\" % run_id_1, max_results=10)\n    assert len(mvds) == 1\n    assert isinstance(mvds[0], ModelVersion)\n    assert mvds[0].current_stage == \"Production\"\n    assert mvds[0].run_id == run_id_1\n    assert mvds[0].source == \"A/B\"\n    assert mvds[0].description == \"Online prediction model!\"\n\n\ndef test_search_model_versions_order_by_simple(store):\n    # create some model versions\n    names = [\"RM1\", \"RM2\", \"RM3\", \"RM4\", \"RM1\", \"RM4\"]\n    sources = [\"A\"] * 3 + [\"B\"] * 3\n    run_ids = [uuid.uuid4().hex for _ in range(6)]\n    for name in set(names):\n        store.create_registered_model(name)\n    for i in range(6):\n        _create_model_version(store, name=names[i], source=sources[i], run_id=run_ids[i])\n        time.sleep(0.001)  # sleep for windows fs timestamp precision issues\n\n    # by default order by last_updated_timestamp DESC\n    mvs = _search_model_versions(store).to_list()\n    assert [mv.name for mv in mvs] == names[::-1]\n    assert [mv.version for mv in mvs] == [2, 2, 1, 1, 1, 1]\n\n    # order by name DESC\n    mvs = _search_model_versions(store, order_by=[\"name DESC\"])\n    assert [mv.name for mv in mvs] == sorted(names)[::-1]\n    assert [mv.version for mv in mvs] == [2, 1, 1, 1, 2, 1]\n\n    # order by version DESC\n    mvs = _search_model_versions(store, order_by=[\"version_number DESC\"])\n    assert [mv.name for mv in mvs] == [\"RM1\", \"RM4\", \"RM1\", \"RM2\", \"RM3\", \"RM4\"]\n    assert [mv.version for mv in mvs] == [2, 2, 1, 1, 1, 1]\n\n    # order by creation_timestamp DESC\n    mvs = _search_model_versions(store, order_by=[\"creation_timestamp DESC\"])\n    assert [mv.name for mv in mvs] == names[::-1]\n    assert [mv.version for mv in mvs] == [2, 2, 1, 1, 1, 1]\n\n    # order by last_updated_timestamp ASC\n    store.update_model_version(names[0], 1, \"latest updated\")\n    mvs = _search_model_versions(store, order_by=[\"last_updated_timestamp ASC\"])\n    assert mvs[-1].name == names[0]\n    assert mvs[-1].version == 1\n\n\ndef test_search_model_versions_pagination(store):\n    def search_versions(filter_string, page_token=None, max_results=10):\n        result = _search_model_versions(\n            store, filter_string=filter_string, page_token=page_token, max_results=max_results\n        )\n        return result.to_list(), result.token\n\n    name = \"test_for_search_MV_pagination\"\n    store.create_registered_model(name)\n    mvs = [_create_model_version(store, name) for _ in range(50)][::-1]\n\n    # test flow with fixed max_results\n    returned_mvs = []\n    query = \"name LIKE 'test_for_search_MV_pagination%'\"\n    result, token = search_versions(query, page_token=None, max_results=5)\n    returned_mvs.extend(result)\n    while token:\n        result, token = search_versions(query, page_token=token, max_results=5)\n        returned_mvs.extend(result)\n    assert mvs == returned_mvs\n\n    # test that pagination will return all valid results in sorted order\n    # by name ascending\n    result, token1 = search_versions(query, max_results=5)\n    assert token1 is not None\n    assert result == mvs[0:5]\n\n    result, token2 = search_versions(query, page_token=token1, max_results=10)\n    assert token2 is not None\n    assert result == mvs[5:15]\n\n    result, token3 = search_versions(query, page_token=token2, max_results=20)\n    assert token3 is not None\n    assert result == mvs[15:35]\n\n    result, token4 = search_versions(query, page_token=token3, max_results=100)\n    # assert that page token is None\n    assert token4 is None\n    assert result == mvs[35:]\n\n    # test that providing a completely invalid page token throws\n    with pytest.raises(\n        MlflowException, match=r\"Invalid page token, could not base64-decode\"\n    ) as exception_context:\n        search_versions(query, page_token=\"evilhax\", max_results=20)\n    assert exception_context.value.error_code == ErrorCode.Name(INVALID_PARAMETER_VALUE)\n\n    # test that providing too large of a max_results throws\n    with pytest.raises(\n        MlflowException, match=r\"Invalid value for max_results.\"\n    ) as exception_context:\n        search_versions(query, page_token=\"evilhax\", max_results=1e15)\n    assert exception_context.value.error_code == ErrorCode.Name(INVALID_PARAMETER_VALUE)\n\n\ndef test_search_model_versions_by_tag(store):\n    # create some model versions\n    name = \"test_for_search_MV_by_tag\"\n    store.create_registered_model(name)\n    run_id_1 = uuid.uuid4().hex\n    run_id_2 = uuid.uuid4().hex\n\n    mv1 = _create_model_version(\n        store,\n        name=name,\n        source=\"A/B\",\n        run_id=run_id_1,\n        tags=[ModelVersionTag(\"t1\", \"abc\"), ModelVersionTag(\"t2\", \"xyz\")],\n    )\n    assert mv1.version == 1\n    mv2 = _create_model_version(\n        store,\n        name=name,\n        source=\"A/C\",\n        run_id=run_id_2,\n        tags=[ModelVersionTag(\"t1\", \"abc\"), ModelVersionTag(\"t2\", \"x123\")],\n    )\n    assert mv2.version == 2\n\n    def search_versions(filter_string):\n        return [mvd.version for mvd in _search_model_versions(store, filter_string)]\n\n    assert search_versions(f\"name = '{name}' and tag.t2 = 'xyz'\") == [1]\n    assert search_versions(\"name = 'wrong_name' and tag.t2 = 'xyz'\") == []\n    assert search_versions(\"tag.`t2` = 'xyz'\") == [1]\n    assert search_versions(\"tag.t3 = 'xyz'\") == []\n    assert set(search_versions(\"tag.t2 != 'xy'\")) == {2, 1}\n    assert search_versions(\"tag.t2 LIKE 'xy%'\") == [1]\n    assert search_versions(\"tag.t2 LIKE 'xY%'\") == []\n    assert search_versions(\"tag.t2 ILIKE 'xY%'\") == [1]\n    assert set(search_versions(\"tag.t2 LIKE 'x%'\")) == {2, 1}\n    assert search_versions(\"tag.T2 = 'xyz'\") == []\n    assert search_versions(\"tag.t1 = 'abc' and tag.t2 = 'xyz'\") == [1]\n    assert set(search_versions(\"tag.t1 = 'abc' and tag.t2 LIKE 'x%'\")) == {2, 1}\n    assert search_versions(\"tag.t1 = 'abc' and tag.t2 LIKE 'y%'\") == []\n    # test filter with duplicated keys\n    assert search_versions(\"tag.t2 like 'x%' and tag.t2 != 'xyz'\") == [2]\n\n\nclass SearchRegisteredModelsResult(NamedTuple):\n    names: List[str]\n    token: str\n\n\ndef _search_registered_models(\n    store, filter_string=None, max_results=10, order_by=None, page_token=None\n):\n    result = store.search_registered_models(\n        filter_string=filter_string,\n        max_results=max_results,\n        order_by=order_by,\n        page_token=page_token,\n    )\n    return SearchRegisteredModelsResult(\n        names=[registered_model.name for registered_model in result],\n        token=result.token,\n    )\n\n\ndef test_search_registered_models(store):\n    # create some registered models\n    prefix = \"test_for_search_\"\n    names = [prefix + name for name in [\"RM1\", \"RM2\", \"RM3\", \"RM4\", \"RM4A\", \"RM4ab\"]]\n    for name in names:\n        store.create_registered_model(name)\n\n    # search with no filter should return all registered models\n    res = _search_registered_models(store, None)\n    assert res.names == names\n\n    # equality search using name should return exactly the 1 name\n    res = _search_registered_models(store, f\"name='{names[0]}'\")\n    assert res.names == [names[0]]\n\n    # equality search using name that is not valid should return nothing\n    res = _search_registered_models(store, f\"name='{names[0]}cats'\")\n    assert res.names == []\n\n    # case-sensitive prefix search using LIKE should return all the RMs\n    res = _search_registered_models(store, f\"name LIKE '{prefix}%'\")\n    assert res.names == names\n\n    # case-sensitive prefix search using LIKE with surrounding % should return all the RMs\n    res = _search_registered_models(store, \"name LIKE '%RM%'\")\n    assert res.names == names\n\n    # case-sensitive prefix search using LIKE with surrounding % should return all the RMs\n    # _e% matches test_for_search_ , so all RMs should match\n    res = _search_registered_models(store, \"name LIKE '_e%'\")\n    assert res.names == names\n\n    # case-sensitive prefix search using LIKE should return just rm4\n    res = _search_registered_models(store, f\"name LIKE '{prefix}RM4A%'\")\n    assert res.names == [names[4]]\n\n    # case-sensitive prefix search using LIKE should return no models if no match\n    res = _search_registered_models(store, f\"name LIKE '{prefix}cats%'\")\n    assert res.names == []\n\n    # confirm that LIKE is not case-sensitive\n    res = _search_registered_models(store, \"name lIkE '%blah%'\")\n    assert res.names == []\n\n    res = _search_registered_models(store, f\"name like '{prefix}RM4A%'\")\n    assert res.names == [names[4]]\n\n    # case-insensitive prefix search using ILIKE should return both rm5 and rm6\n    res = _search_registered_models(store, f\"name ILIKE '{prefix}RM4A%'\")\n    assert res.names == names[4:]\n\n    # case-insensitive postfix search with ILIKE\n    res = _search_registered_models(store, \"name ILIKE '%RM4a%'\")\n    assert res.names == names[4:]\n\n    # case-insensitive prefix search using ILIKE should return both rm5 and rm6\n    res = _search_registered_models(store, f\"name ILIKE '{prefix}cats%'\")\n    assert res.names == []\n\n    # confirm that ILIKE is not case-sensitive\n    res = _search_registered_models(store, \"name iLike '%blah%'\")\n    assert res.names == []\n\n    # confirm that ILIKE works for empty query\n    res = _search_registered_models(store, \"name iLike '%%'\")\n    assert res.names == names\n\n    res = _search_registered_models(store, \"name ilike '%RM4a%'\")\n    assert res.names == names[4:]\n\n    # cannot search by invalid comparator types\n    with pytest.raises(\n        MlflowException,\n        match=\"Parameter value is either not quoted or unidentified quote types used for \"\n        \"string value something\",\n    ) as exception_context:\n        _search_registered_models(store, \"name!=something\")\n    assert exception_context.value.error_code == ErrorCode.Name(INVALID_PARAMETER_VALUE)\n\n    # cannot search by run_id\n    with pytest.raises(\n        MlflowException,\n        match=r\"Invalid attribute key 'run_id' specified. Valid keys are '{'name'}'\",\n    ) as exception_context:\n        _search_registered_models(store, \"run_id='somerunID'\")\n    assert exception_context.value.error_code == ErrorCode.Name(INVALID_PARAMETER_VALUE)\n\n    # cannot search by source_path\n    with pytest.raises(\n        MlflowException,\n        match=r\"Invalid attribute key 'source_path' specified\\. Valid keys are '{'name'}'\",\n    ) as exception_context:\n        _search_registered_models(store, \"source_path = 'A/D'\")\n    assert exception_context.value.error_code == ErrorCode.Name(INVALID_PARAMETER_VALUE)\n\n    # cannot search by other params\n    with pytest.raises(\n        MlflowException, match=r\"Invalid clause\\(s\\) in filter string\"\n    ) as exception_context:\n        _search_registered_models(store, \"evilhax = true\")\n    assert exception_context.value.error_code == ErrorCode.Name(INVALID_PARAMETER_VALUE)\n\n    # delete last registered model. search should not return the first 5\n    store.delete_registered_model(name=names[-1])\n    res = _search_registered_models(store, None, max_results=1000)\n    assert res.names == names[:-1]\n    assert res.token is None\n\n    # equality search using name should return no names\n    assert _search_registered_models(store, f\"name='{names[-1]}'\") == ([], None)\n\n    # case-sensitive prefix search using LIKE should return all the RMs\n    res = _search_registered_models(store, f\"name LIKE '{prefix}%'\")\n    assert res.names == names[0:5]\n    assert res.token is None\n\n    # case-insensitive prefix search using ILIKE should return both rm5 and rm6\n    res = _search_registered_models(store, f\"name ILIKE '{prefix}RM4A%'\")\n    assert res.names == [names[4]]\n    assert res.token is None\n\n\ndef test_search_registered_models_by_tag(store):\n    name1 = \"test_for_search_RM_by_tag1\"\n    name2 = \"test_for_search_RM_by_tag2\"\n    tags1 = [\n        RegisteredModelTag(\"t1\", \"abc\"),\n        RegisteredModelTag(\"t2\", \"xyz\"),\n    ]\n    tags2 = [\n        RegisteredModelTag(\"t1\", \"abcd\"),\n        RegisteredModelTag(\"t2\", \"xyz123\"),\n        RegisteredModelTag(\"t3\", \"XYZ\"),\n    ]\n    store.create_registered_model(name1, tags1)\n    store.create_registered_model(name2, tags2)\n\n    res = _search_registered_models(store, \"tag.t3 = 'XYZ'\")\n    assert res.names == [name2]\n\n    res = _search_registered_models(store, f\"name = '{name1}' and tag.t1 = 'abc'\")\n    assert res.names == [name1]\n\n    res = _search_registered_models(store, \"tag.t1 LIKE 'ab%'\")\n    assert res.names == [name1, name2]\n\n    res = _search_registered_models(store, \"tag.t1 ILIKE 'aB%'\")\n    assert res.names == [name1, name2]\n\n    res = _search_registered_models(store, \"tag.t1 LIKE 'ab%' AND tag.t2 LIKE 'xy%'\")\n    assert res.names == [name1, name2]\n\n    res = _search_registered_models(store, \"tag.t3 = 'XYz'\")\n    assert res.names == []\n\n    res = _search_registered_models(store, \"tag.T3 = 'XYZ'\")\n    assert res.names == []\n\n    res = _search_registered_models(store, \"tag.t1 != 'abc'\")\n    assert res.names == [name2]\n\n    # test filter with duplicated keys\n    res = _search_registered_models(store, \"tag.t1 != 'abcd' and tag.t1 LIKE 'ab%'\")\n    assert res.names == [name1]\n\n\ndef test_search_registered_models_order_by_simple(store):\n    # create some registered models\n    names = [\"RM1\", \"RM2\", \"RM3\", \"RM4\", \"RM4A\", \"RM4ab\"]\n    for name in names:\n        store.create_registered_model(name)\n        time.sleep(0.001)  # sleep for windows store timestamp precision issues\n\n    # by default order by name ASC\n    res = _search_registered_models(store)\n    assert res.names == names\n\n    # order by name DESC\n    res = _search_registered_models(store, order_by=[\"name DESC\"])\n    assert res.names == names[::-1]\n\n    # order by last_updated_timestamp ASC\n    store.update_registered_model(names[0], \"latest updated\")\n    res = _search_registered_models(store, order_by=[\"last_updated_timestamp ASC\"])\n    assert res.names[-1] == names[0]\n\n\ndef test_search_registered_model_pagination(store):\n    rms = [store.create_registered_model(f\"RM{i:03}\").name for i in range(50)]\n\n    # test flow with fixed max_results\n    returned_rms = []\n    query = \"name LIKE 'RM%'\"\n    res = _search_registered_models(store, query, page_token=None, max_results=5)\n    returned_rms.extend(res.names)\n    while res.token:\n        res = _search_registered_models(store, query, page_token=res.token, max_results=5)\n        returned_rms.extend(res.names)\n    assert returned_rms == rms\n\n    # test that pagination will return all valid results in sorted order\n    # by name ascending\n    res = _search_registered_models(store, query, max_results=5)\n    assert res.token is not None\n    assert res.names == rms[0:5]\n\n    res = _search_registered_models(store, query, page_token=res.token, max_results=10)\n    assert res.token is not None\n    assert res.names == rms[5:15]\n\n    res = _search_registered_models(store, query, page_token=res.token, max_results=20)\n    assert res.token is not None\n    assert res.names == rms[15:35]\n\n    res = _search_registered_models(store, query, page_token=res.token, max_results=100)\n    # assert that page token is None\n    assert res.token is None\n    assert res.names == rms[35:]\n\n    # test that providing a completely invalid page token throws\n    with pytest.raises(\n        MlflowException, match=r\"Invalid page token, could not base64-decode\"\n    ) as exception_context:\n        _search_registered_models(store, query, page_token=\"evilhax\", max_results=20)\n    assert exception_context.value.error_code == ErrorCode.Name(INVALID_PARAMETER_VALUE)\n\n    # test that providing too large of a max_results throws\n    with pytest.raises(\n        MlflowException, match=r\"Invalid value for max_results.\"\n    ) as exception_context:\n        _search_registered_models(store, query, page_token=\"evilhax\", max_results=1e15)\n    assert exception_context.value.error_code == ErrorCode.Name(INVALID_PARAMETER_VALUE)\n\n\ndef test_search_registered_model_order_by(store):\n    rms = []\n    # explicitly mock the creation_timestamps because timestamps seem to be unstable in Windows\n    for i in range(50):\n        rms.append(store.create_registered_model(f\"RM{i:03}\").name)\n        time.sleep(0.01)\n\n    # test flow with fixed max_results and order_by (test stable order across pages)\n    returned_rms = []\n    query = \"name LIKE 'RM%'\"\n    result, token = _search_registered_models(\n        store, query, page_token=None, order_by=[\"name DESC\"], max_results=5\n    )\n    returned_rms.extend(result)\n    while token:\n        result, token = _search_registered_models(\n            store, query, page_token=token, order_by=[\"name DESC\"], max_results=5\n        )\n        returned_rms.extend(result)\n    # name descending should be the opposite order of the current order\n    assert returned_rms == rms[::-1]\n    # last_updated_timestamp descending should have the newest RMs first\n    res = _search_registered_models(\n        store, query, page_token=None, order_by=[\"last_updated_timestamp DESC\"], max_results=100\n    )\n    assert res.names == rms[::-1]\n    # last_updated_timestamp ascending should have the oldest RMs first\n    res = _search_registered_models(\n        store, query, page_token=None, order_by=[\"last_updated_timestamp ASC\"], max_results=100\n    )\n    assert res.names == rms\n    # name ascending should have the original order\n    res = _search_registered_models(\n        store, query, page_token=None, order_by=[\"name ASC\"], max_results=100\n    )\n    assert res.names == rms\n    # test that no ASC/DESC defaults to ASC\n    res = _search_registered_models(\n        store, query, page_token=None, order_by=[\"last_updated_timestamp\"], max_results=100\n    )\n    assert res.names == rms\n    with mock.patch(\n        \"mlflow.store.model_registry.file_store.get_current_time_millis\", return_value=1\n    ):\n        rm1 = store.create_registered_model(\"MR1\").name\n        rm2 = store.create_registered_model(\"MR2\").name\n    with mock.patch(\n        \"mlflow.store.model_registry.file_store.get_current_time_millis\", return_value=2\n    ):\n        rm3 = store.create_registered_model(\"MR3\").name\n        rm4 = store.create_registered_model(\"MR4\").name\n    query = \"name LIKE 'MR%'\"\n    # test with multiple clauses\n    res = _search_registered_models(\n        store,\n        query,\n        page_token=None,\n        order_by=[\"last_updated_timestamp ASC\", \"name DESC\"],\n        max_results=100,\n    )\n    assert res.names == [rm2, rm1, rm4, rm3]\n    # confirm that name ascending is the default, even if ties exist on other fields\n    res = _search_registered_models(store, query, page_token=None, order_by=[], max_results=100)\n    assert res.names == [rm1, rm2, rm3, rm4]\n    # test default tiebreak with descending timestamps\n    res = _search_registered_models(\n        store, query, page_token=None, order_by=[\"last_updated_timestamp DESC\"], max_results=100\n    )\n    assert res.names == [rm3, rm4, rm1, rm2]\n\n\ndef test_search_registered_model_order_by_errors(store):\n    store.create_registered_model(\"dummy\")\n    query = \"name LIKE 'RM%'\"\n    # test that invalid columns throw even if they come after valid columns\n    with pytest.raises(\n        MlflowException, match=\"Invalid attribute key 'description' specified.\"\n    ) as exception_context:\n        _search_registered_models(\n            store,\n            query,\n            page_token=None,\n            order_by=[\"name ASC\", \"description DESC\"],\n            max_results=5,\n        )\n    assert exception_context.value.error_code == ErrorCode.Name(INVALID_PARAMETER_VALUE)\n    # test that invalid columns with random text throw even if they come after valid columns\n    with pytest.raises(MlflowException, match=r\"Invalid order_by clause '.+'\") as exception_context:\n        _search_registered_models(\n            store,\n            query,\n            page_token=None,\n            order_by=[\"name ASC\", \"last_updated_timestamp DESC blah\"],\n            max_results=5,\n        )\n    assert exception_context.value.error_code == ErrorCode.Name(INVALID_PARAMETER_VALUE)\n\n\ndef test_set_model_version_tag(store):\n    name1 = \"SetModelVersionTag_TestMod\"\n    name2 = \"SetModelVersionTag_TestMod 2\"\n    initial_tags = [\n        ModelVersionTag(\"key\", \"value\"),\n        ModelVersionTag(\"anotherKey\", \"some other value\"),\n    ]\n    store.create_registered_model(name1)\n    store.create_registered_model(name2)\n    run_id_1 = uuid.uuid4().hex\n    run_id_2 = uuid.uuid4().hex\n    run_id_3 = uuid.uuid4().hex\n    store.create_model_version(name1, \"A/B\", run_id_1, initial_tags)\n    store.create_model_version(name1, \"A/C\", run_id_2, initial_tags)\n    store.create_model_version(name2, \"A/D\", run_id_3, initial_tags)\n    new_tag = ModelVersionTag(\"randomTag\", \"not a random value\")\n    store.set_model_version_tag(name1, 1, new_tag)\n    all_tags = [*initial_tags, new_tag]\n    rm1mv1 = store.get_model_version(name1, 1)\n    assert rm1mv1.tags == {tag.key: tag.value for tag in all_tags}\n\n    # test overriding a tag with the same key\n    overriding_tag = ModelVersionTag(\"key\", \"overriding\")\n    store.set_model_version_tag(name1, 1, overriding_tag)\n    all_tags = [tag for tag in all_tags if tag.key != \"key\"] + [overriding_tag]\n    rm1mv1 = store.get_model_version(name1, 1)\n    assert rm1mv1.tags == {tag.key: tag.value for tag in all_tags}\n    # does not affect other model versions with the same key\n    rm1mv2 = store.get_model_version(name1, 2)\n    rm2mv1 = store.get_model_version(name2, 1)\n    assert rm1mv2.tags == {tag.key: tag.value for tag in initial_tags}\n    assert rm2mv1.tags == {tag.key: tag.value for tag in initial_tags}\n\n    # can not set tag on deleted (non-existed) model version\n    store.delete_model_version(name1, 2)\n    with pytest.raises(\n        MlflowException, match=rf\"Model Version \\(name={name1}, version=2\\) not found\"\n    ) as exception_context:\n        store.set_model_version_tag(name1, 2, overriding_tag)\n    assert exception_context.value.error_code == ErrorCode.Name(RESOURCE_DOES_NOT_EXIST)\n    # test cannot set tags that are too long\n    long_tag = ModelVersionTag(\"longTagKey\", \"a\" * 5001)\n    with pytest.raises(\n        MlflowException,\n        match=r\"Model version value '.+' had length \\d+, which exceeded length limit of 5000\",\n    ) as exception_context:\n        store.set_model_version_tag(name1, 1, long_tag)\n    assert exception_context.value.error_code == ErrorCode.Name(INVALID_PARAMETER_VALUE)\n    # test can set tags that are somewhat long\n    long_tag = ModelVersionTag(\"longTagKey\", \"a\" * 4999)\n    store.set_model_version_tag(name1, 1, long_tag)\n    # can not set invalid tag\n    with pytest.raises(MlflowException, match=r\"Tag name cannot be None\") as exception_context:\n        store.set_model_version_tag(name2, 1, ModelVersionTag(key=None, value=\"\"))\n    assert exception_context.value.error_code == ErrorCode.Name(INVALID_PARAMETER_VALUE)\n    # can not use invalid model name or version\n    with pytest.raises(\n        MlflowException, match=r\"Registered model name cannot be empty\"\n    ) as exception_context:\n        store.set_model_version_tag(None, 1, ModelVersionTag(key=\"key\", value=\"value\"))\n    assert exception_context.value.error_code == ErrorCode.Name(INVALID_PARAMETER_VALUE)\n    with pytest.raises(\n        MlflowException, match=r\"Model version must be an integer\"\n    ) as exception_context:\n        store.set_model_version_tag(\n            name2, \"I am not a version\", ModelVersionTag(key=\"key\", value=\"value\")\n        )\n    assert exception_context.value.error_code == ErrorCode.Name(INVALID_PARAMETER_VALUE)\n\n\ndef test_delete_model_version_tag(store):\n    name1 = \"DeleteModelVersionTag_TestMod\"\n    name2 = \"DeleteModelVersionTag_TestMod 2\"\n    initial_tags = [\n        ModelVersionTag(\"key\", \"value\"),\n        ModelVersionTag(\"anotherKey\", \"some other value\"),\n    ]\n    store.create_registered_model(name1)\n    store.create_registered_model(name2)\n    run_id_1 = uuid.uuid4().hex\n    run_id_2 = uuid.uuid4().hex\n    run_id_3 = uuid.uuid4().hex\n    store.create_model_version(name1, \"A/B\", run_id_1, initial_tags)\n    store.create_model_version(name1, \"A/C\", run_id_2, initial_tags)\n    store.create_model_version(name2, \"A/D\", run_id_3, initial_tags)\n    new_tag = ModelVersionTag(\"randomTag\", \"not a random value\")\n    store.set_model_version_tag(name1, 1, new_tag)\n    store.delete_model_version_tag(name1, 1, \"randomTag\")\n    rm1mv1 = store.get_model_version(name1, 1)\n    assert rm1mv1.tags == {tag.key: tag.value for tag in initial_tags}\n\n    # testing deleting a key does not affect other model versions with the same key\n    store.delete_model_version_tag(name1, 1, \"key\")\n    rm1mv1 = store.get_model_version(name1, 1)\n    rm1mv2 = store.get_model_version(name1, 2)\n    rm2mv1 = store.get_model_version(name2, 1)\n    assert rm1mv1.tags == {\"anotherKey\": \"some other value\"}\n    assert rm1mv2.tags == {tag.key: tag.value for tag in initial_tags}\n    assert rm2mv1.tags == {tag.key: tag.value for tag in initial_tags}\n\n    # delete tag that is already deleted does nothing\n    store.delete_model_version_tag(name1, 1, \"key\")\n    rm1mv1 = store.get_model_version(name1, 1)\n    assert rm1mv1.tags == {\"anotherKey\": \"some other value\"}\n\n    # can not delete tag on deleted (non-existed) model version\n    store.delete_model_version(name2, 1)\n    with pytest.raises(\n        MlflowException, match=rf\"Model Version \\(name={name2}, version=1\\) not found\"\n    ) as exception_context:\n        store.delete_model_version_tag(name2, 1, \"key\")\n    assert exception_context.value.error_code == ErrorCode.Name(RESOURCE_DOES_NOT_EXIST)\n    # can not delete tag with invalid key\n    with pytest.raises(MlflowException, match=r\"Tag name cannot be None\") as exception_context:\n        store.delete_model_version_tag(name1, 2, None)\n    assert exception_context.value.error_code == ErrorCode.Name(INVALID_PARAMETER_VALUE)\n    # can not use invalid model name or version\n    with pytest.raises(\n        MlflowException, match=r\"Registered model name cannot be empty\"\n    ) as exception_context:\n        store.delete_model_version_tag(None, 2, \"key\")\n    assert exception_context.value.error_code == ErrorCode.Name(INVALID_PARAMETER_VALUE)\n    with pytest.raises(\n        MlflowException, match=r\"Model version must be an integer\"\n    ) as exception_context:\n        store.delete_model_version_tag(name1, \"I am not a version\", \"key\")\n    assert exception_context.value.error_code == ErrorCode.Name(INVALID_PARAMETER_VALUE)\n\n\ndef test_pyfunc_model_registry_with_file_store(store):\n    import mlflow\n    from mlflow.pyfunc import PythonModel\n\n    class MyModel(PythonModel):\n        def predict(self, context, model_input):\n            return 7\n\n    mlflow.set_registry_uri(path_to_local_file_uri(store.root_directory))\n    with mlflow.start_run():\n        mlflow.pyfunc.log_model(\n            python_model=MyModel(), artifact_path=\"foo\", registered_model_name=\"model1\"\n        )\n        mlflow.pyfunc.log_model(\n            python_model=MyModel(), artifact_path=\"foo\", registered_model_name=\"model2\"\n        )\n        mlflow.pyfunc.log_model(\n            python_model=MyModel(), artifact_path=\"foo\", registered_model_name=\"model1\"\n        )\n\n    with mlflow.start_run():\n        mlflow.log_param(\"A\", \"B\")\n\n        models = store.search_registered_models(max_results=10)\n        assert len(models) == 2\n        assert models[0].name == \"model1\"\n        assert models[1].name == \"model2\"\n        mv1 = store.search_model_versions(\"name = 'model1'\", max_results=10)\n        assert len(mv1) == 2\n        assert mv1[0].name == \"model1\"\n        mv2 = store.search_model_versions(\"name = 'model2'\", max_results=10)\n        assert len(mv2) == 1 and mv2[0].name == \"model2\"\n"], "filenames": ["mlflow/store/model_registry/file_store.py", "mlflow/utils/file_utils.py", "tests/store/model_registry/test_file_store.py"], "buggy_code_start_loc": [40, 713, 62], "buggy_code_end_loc": [67, 713, 62], "fixing_code_start_loc": [40, 714, 63], "fixing_code_end_loc": [78, 721, 71], "type": "CWE-36", "message": "Absolute Path Traversal in GitHub repository mlflow/mlflow prior to 2.2.2.", "other": {"cve": {"id": "CVE-2023-1176", "sourceIdentifier": "security@huntr.dev", "published": "2023-03-24T15:15:10.110", "lastModified": "2023-03-28T14:44:39.890", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "Absolute Path Traversal in GitHub repository mlflow/mlflow prior to 2.2.2."}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:L/AC:L/PR:L/UI:N/S:U/C:L/I:N/A:N", "attackVector": "LOCAL", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "LOW", "integrityImpact": "NONE", "availabilityImpact": "NONE", "baseScore": 3.3, "baseSeverity": "LOW"}, "exploitabilityScore": 1.8, "impactScore": 1.4}], "cvssMetricV30": [{"source": "security@huntr.dev", "type": "Secondary", "cvssData": {"version": "3.0", "vectorString": "CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:L/I:N/A:N", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "LOW", "integrityImpact": "NONE", "availabilityImpact": "NONE", "baseScore": 5.3, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 3.9, "impactScore": 1.4}]}, "weaknesses": [{"source": "security@huntr.dev", "type": "Primary", "description": [{"lang": "en", "value": "CWE-36"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:lfprojects:mlflow:*:*:*:*:*:*:*:*", "versionEndExcluding": "2.2.2", "matchCriteriaId": "84D05E2A-38B6-4CE3-A817-5EFA0F802CF3"}]}]}], "references": [{"url": "https://github.com/mlflow/mlflow/commit/63ef72aa4334a6473ce7f889573c92fcae0b3c0d", "source": "security@huntr.dev", "tags": ["Patch"]}, {"url": "https://huntr.dev/bounties/ae92f814-6a08-435c-8445-eec0ef4f1085", "source": "security@huntr.dev", "tags": ["Exploit", "Patch"]}]}, "github_commit_url": "https://github.com/mlflow/mlflow/commit/63ef72aa4334a6473ce7f889573c92fcae0b3c0d"}}
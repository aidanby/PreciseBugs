{"buggy_code": ["#include \"source/common/upstream/health_checker_impl.h\"\n\n#include <memory>\n\n#include \"envoy/config/core/v3/health_check.pb.h\"\n#include \"envoy/data/core/v3/health_check_event.pb.h\"\n#include \"envoy/server/health_checker_config.h\"\n#include \"envoy/type/v3/http.pb.h\"\n#include \"envoy/type/v3/range.pb.h\"\n\n#include \"source/common/buffer/zero_copy_input_stream_impl.h\"\n#include \"source/common/common/empty_string.h\"\n#include \"source/common/common/enum_to_int.h\"\n#include \"source/common/common/macros.h\"\n#include \"source/common/config/utility.h\"\n#include \"source/common/config/well_known_names.h\"\n#include \"source/common/grpc/common.h\"\n#include \"source/common/http/header_map_impl.h\"\n#include \"source/common/http/header_utility.h\"\n#include \"source/common/network/address_impl.h\"\n#include \"source/common/network/socket_impl.h\"\n#include \"source/common/network/utility.h\"\n#include \"source/common/router/router.h\"\n#include \"source/common/runtime/runtime_features.h\"\n#include \"source/common/upstream/host_utility.h\"\n\n#include \"absl/strings/match.h\"\n#include \"absl/strings/str_cat.h\"\n\nnamespace Envoy {\nnamespace Upstream {\n\nnamespace {\n\n// Helper functions to get the correct hostname for an L7 health check.\nconst std::string& getHostname(const HostSharedPtr& host, const std::string& config_hostname,\n                               const ClusterInfoConstSharedPtr& cluster) {\n  if (!host->hostnameForHealthChecks().empty()) {\n    return host->hostnameForHealthChecks();\n  }\n\n  if (!config_hostname.empty()) {\n    return config_hostname;\n  }\n\n  return cluster->name();\n}\n\nconst std::string& getHostname(const HostSharedPtr& host,\n                               const absl::optional<std::string>& config_hostname,\n                               const ClusterInfoConstSharedPtr& cluster) {\n  if (config_hostname.has_value()) {\n    return getHostname(host, config_hostname.value(), cluster);\n  }\n  return getHostname(host, EMPTY_STRING, cluster);\n}\n\n} // namespace\n\nclass HealthCheckerFactoryContextImpl : public Server::Configuration::HealthCheckerFactoryContext {\npublic:\n  HealthCheckerFactoryContextImpl(Upstream::Cluster& cluster, Envoy::Runtime::Loader& runtime,\n                                  Event::Dispatcher& dispatcher,\n                                  HealthCheckEventLoggerPtr&& event_logger,\n                                  ProtobufMessage::ValidationVisitor& validation_visitor,\n                                  Api::Api& api)\n      : cluster_(cluster), runtime_(runtime), dispatcher_(dispatcher),\n        event_logger_(std::move(event_logger)), validation_visitor_(validation_visitor), api_(api) {\n  }\n  Upstream::Cluster& cluster() override { return cluster_; }\n  Envoy::Runtime::Loader& runtime() override { return runtime_; }\n  Event::Dispatcher& mainThreadDispatcher() override { return dispatcher_; }\n  HealthCheckEventLoggerPtr eventLogger() override { return std::move(event_logger_); }\n  ProtobufMessage::ValidationVisitor& messageValidationVisitor() override {\n    return validation_visitor_;\n  }\n  Api::Api& api() override { return api_; }\n\nprivate:\n  Upstream::Cluster& cluster_;\n  Envoy::Runtime::Loader& runtime_;\n  Event::Dispatcher& dispatcher_;\n  HealthCheckEventLoggerPtr event_logger_;\n  ProtobufMessage::ValidationVisitor& validation_visitor_;\n  Api::Api& api_;\n};\n\nHealthCheckerSharedPtr HealthCheckerFactory::create(\n    const envoy::config::core::v3::HealthCheck& health_check_config, Upstream::Cluster& cluster,\n    Runtime::Loader& runtime, Event::Dispatcher& dispatcher,\n    AccessLog::AccessLogManager& log_manager,\n    ProtobufMessage::ValidationVisitor& validation_visitor, Api::Api& api) {\n  HealthCheckEventLoggerPtr event_logger;\n  if (!health_check_config.event_log_path().empty()) {\n    event_logger = std::make_unique<HealthCheckEventLoggerImpl>(\n        log_manager, dispatcher.timeSource(), health_check_config.event_log_path());\n  }\n  switch (health_check_config.health_checker_case()) {\n  case envoy::config::core::v3::HealthCheck::HealthCheckerCase::HEALTH_CHECKER_NOT_SET:\n    throw EnvoyException(\"invalid cluster config\");\n  case envoy::config::core::v3::HealthCheck::HealthCheckerCase::kHttpHealthCheck:\n    return std::make_shared<ProdHttpHealthCheckerImpl>(cluster, health_check_config, dispatcher,\n                                                       runtime, api.randomGenerator(),\n                                                       std::move(event_logger));\n  case envoy::config::core::v3::HealthCheck::HealthCheckerCase::kTcpHealthCheck:\n    return std::make_shared<TcpHealthCheckerImpl>(cluster, health_check_config, dispatcher, runtime,\n                                                  api.randomGenerator(), std::move(event_logger));\n  case envoy::config::core::v3::HealthCheck::HealthCheckerCase::kGrpcHealthCheck:\n    if (!(cluster.info()->features() & Upstream::ClusterInfo::Features::HTTP2)) {\n      throw EnvoyException(fmt::format(\"{} cluster must support HTTP/2 for gRPC healthchecking\",\n                                       cluster.info()->name()));\n    }\n    return std::make_shared<ProdGrpcHealthCheckerImpl>(cluster, health_check_config, dispatcher,\n                                                       runtime, api.randomGenerator(),\n                                                       std::move(event_logger));\n  case envoy::config::core::v3::HealthCheck::HealthCheckerCase::kCustomHealthCheck: {\n    auto& factory =\n        Config::Utility::getAndCheckFactory<Server::Configuration::CustomHealthCheckerFactory>(\n            health_check_config.custom_health_check());\n    std::unique_ptr<Server::Configuration::HealthCheckerFactoryContext> context(\n        new HealthCheckerFactoryContextImpl(cluster, runtime, dispatcher, std::move(event_logger),\n                                            validation_visitor, api));\n    return factory.createCustomHealthChecker(health_check_config, *context);\n  }\n  }\n  PANIC_DUE_TO_CORRUPT_ENUM;\n}\n\nHttpHealthCheckerImpl::HttpHealthCheckerImpl(const Cluster& cluster,\n                                             const envoy::config::core::v3::HealthCheck& config,\n                                             Event::Dispatcher& dispatcher,\n                                             Runtime::Loader& runtime,\n                                             Random::RandomGenerator& random,\n                                             HealthCheckEventLoggerPtr&& event_logger)\n    : HealthCheckerImplBase(cluster, config, dispatcher, runtime, random, std::move(event_logger)),\n      path_(config.http_health_check().path()), host_value_(config.http_health_check().host()),\n      request_headers_parser_(\n          Router::HeaderParser::configure(config.http_health_check().request_headers_to_add(),\n                                          config.http_health_check().request_headers_to_remove())),\n      http_status_checker_(config.http_health_check().expected_statuses(),\n                           config.http_health_check().retriable_statuses(),\n                           static_cast<uint64_t>(Http::Code::OK)),\n      codec_client_type_(codecClientType(config.http_health_check().codec_client_type())),\n      random_generator_(random) {\n  if (config.http_health_check().has_service_name_matcher()) {\n    service_name_matcher_.emplace(config.http_health_check().service_name_matcher());\n  }\n}\n\nHttpHealthCheckerImpl::HttpStatusChecker::HttpStatusChecker(\n    const Protobuf::RepeatedPtrField<envoy::type::v3::Int64Range>& expected_statuses,\n    const Protobuf::RepeatedPtrField<envoy::type::v3::Int64Range>& retriable_statuses,\n    uint64_t default_expected_status) {\n  for (const auto& status_range : expected_statuses) {\n    const auto start = static_cast<uint64_t>(status_range.start());\n    const auto end = static_cast<uint64_t>(status_range.end());\n\n    validateRange(start, end, \"expected\");\n\n    expected_ranges_.emplace_back(std::make_pair(start, end));\n  }\n\n  if (expected_ranges_.empty()) {\n    expected_ranges_.emplace_back(\n        std::make_pair(default_expected_status, default_expected_status + 1));\n  }\n\n  for (const auto& status_range : retriable_statuses) {\n    const auto start = static_cast<uint64_t>(status_range.start());\n    const auto end = static_cast<uint64_t>(status_range.end());\n\n    validateRange(start, end, \"retriable\");\n\n    retriable_ranges_.emplace_back(std::make_pair(start, end));\n  }\n}\n\nvoid HttpHealthCheckerImpl::HttpStatusChecker::validateRange(uint64_t start, uint64_t end,\n                                                             absl::string_view range_type) {\n  if (start >= end) {\n    throw EnvoyException(fmt::format(\"Invalid http {} status range: expecting start < \"\n                                     \"end, but found start={} and end={}\",\n                                     range_type, start, end));\n  }\n\n  if (start < 100) {\n    throw EnvoyException(\n        fmt::format(\"Invalid http {} status range: expecting start >= 100, but found start={}\",\n                    range_type, start));\n  }\n\n  if (end > 600) {\n    throw EnvoyException(fmt::format(\n        \"Invalid http {} status range: expecting end <= 600, but found end={}\", range_type, end));\n  }\n}\n\nbool HttpHealthCheckerImpl::HttpStatusChecker::inRetriableRanges(uint64_t http_status) const {\n  return inRanges(http_status, retriable_ranges_);\n}\n\nbool HttpHealthCheckerImpl::HttpStatusChecker::inExpectedRanges(uint64_t http_status) const {\n  return inRanges(http_status, expected_ranges_);\n}\n\nbool HttpHealthCheckerImpl::HttpStatusChecker::inRanges(\n    uint64_t http_status, const std::vector<std::pair<uint64_t, uint64_t>>& ranges) {\n  for (const auto& range : ranges) {\n    if (http_status >= range.first && http_status < range.second) {\n      return true;\n    }\n  }\n\n  return false;\n}\n\nHttp::Protocol codecClientTypeToProtocol(Http::CodecType codec_client_type) {\n  switch (codec_client_type) {\n  case Http::CodecType::HTTP1:\n    return Http::Protocol::Http11;\n  case Http::CodecType::HTTP2:\n    return Http::Protocol::Http2;\n  case Http::CodecType::HTTP3:\n    return Http::Protocol::Http3;\n  }\n  PANIC_DUE_TO_CORRUPT_ENUM\n}\n\nHttpHealthCheckerImpl::HttpActiveHealthCheckSession::HttpActiveHealthCheckSession(\n    HttpHealthCheckerImpl& parent, const HostSharedPtr& host)\n    : ActiveHealthCheckSession(parent, host), parent_(parent),\n      hostname_(getHostname(host, parent_.host_value_, parent_.cluster_.info())),\n      protocol_(codecClientTypeToProtocol(parent_.codec_client_type_)),\n      local_connection_info_provider_(std::make_shared<Network::ConnectionInfoSetterImpl>(\n          Network::Utility::getCanonicalIpv4LoopbackAddress(),\n          Network::Utility::getCanonicalIpv4LoopbackAddress())) {}\n\nHttpHealthCheckerImpl::HttpActiveHealthCheckSession::~HttpActiveHealthCheckSession() {\n  ASSERT(client_ == nullptr);\n}\n\nvoid HttpHealthCheckerImpl::HttpActiveHealthCheckSession::onDeferredDelete() {\n  if (client_) {\n    // If there is an active request it will get reset, so make sure we ignore the reset.\n    expect_reset_ = true;\n    client_->close();\n  }\n}\n\nvoid HttpHealthCheckerImpl::HttpActiveHealthCheckSession::decodeHeaders(\n    Http::ResponseHeaderMapPtr&& headers, bool end_stream) {\n  ASSERT(!response_headers_);\n  response_headers_ = std::move(headers);\n  if (end_stream) {\n    onResponseComplete();\n  }\n}\n\nvoid HttpHealthCheckerImpl::HttpActiveHealthCheckSession::onEvent(Network::ConnectionEvent event) {\n  if (event == Network::ConnectionEvent::RemoteClose ||\n      event == Network::ConnectionEvent::LocalClose) {\n    // For the raw disconnect event, we are either between intervals in which case we already have\n    // a timer setup, or we did the close or got a reset, in which case we already setup a new\n    // timer. There is nothing to do here other than blow away the client.\n    response_headers_.reset();\n    parent_.dispatcher_.deferredDelete(std::move(client_));\n  }\n}\n\n// TODO(lilika) : Support connection pooling\nvoid HttpHealthCheckerImpl::HttpActiveHealthCheckSession::onInterval() {\n  if (!client_) {\n    Upstream::Host::CreateConnectionData conn =\n        host_->createHealthCheckConnection(parent_.dispatcher_, parent_.transportSocketOptions(),\n                                           parent_.transportSocketMatchMetadata().get());\n    client_.reset(parent_.createCodecClient(conn));\n    client_->addConnectionCallbacks(connection_callback_impl_);\n    client_->setCodecConnectionCallbacks(http_connection_callback_impl_);\n    expect_reset_ = false;\n    reuse_connection_ = parent_.reuse_connection_;\n  }\n\n  Http::RequestEncoder* request_encoder = &client_->newStream(*this);\n  request_encoder->getStream().addCallbacks(*this);\n  request_in_flight_ = true;\n\n  const auto request_headers = Http::createHeaderMap<Http::RequestHeaderMapImpl>(\n      {{Http::Headers::get().Method, \"GET\"},\n       {Http::Headers::get().Host, hostname_},\n       {Http::Headers::get().Path, parent_.path_},\n       {Http::Headers::get().UserAgent, Http::Headers::get().UserAgentValues.EnvoyHealthChecker}});\n  Router::FilterUtility::setUpstreamScheme(\n      *request_headers,\n      // Here there is no downstream connection so scheme will be based on\n      // upstream crypto\n      host_->transportSocketFactory().implementsSecureTransport());\n  StreamInfo::StreamInfoImpl stream_info(protocol_, parent_.dispatcher_.timeSource(),\n                                         local_connection_info_provider_);\n  stream_info.setUpstreamInfo(std::make_shared<StreamInfo::UpstreamInfoImpl>());\n  stream_info.upstreamInfo()->setUpstreamHost(host_);\n  parent_.request_headers_parser_->evaluateHeaders(*request_headers, stream_info);\n  auto status = request_encoder->encodeHeaders(*request_headers, true);\n  // Encoding will only fail if required request headers are missing.\n  ASSERT(status.ok());\n}\n\nvoid HttpHealthCheckerImpl::HttpActiveHealthCheckSession::onResetStream(Http::StreamResetReason,\n                                                                        absl::string_view) {\n  request_in_flight_ = false;\n  ENVOY_CONN_LOG(debug, \"connection/stream error health_flags={}\", *client_,\n                 HostUtility::healthFlagsToString(*host_));\n  if (expect_reset_) {\n    return;\n  }\n\n  if (client_ && !reuse_connection_) {\n    client_->close();\n  }\n\n  handleFailure(envoy::data::core::v3::NETWORK);\n}\n\nvoid HttpHealthCheckerImpl::HttpActiveHealthCheckSession::onGoAway(\n    Http::GoAwayErrorCode error_code) {\n  ENVOY_CONN_LOG(debug, \"connection going away goaway_code={}, health_flags={}\", *client_,\n                 static_cast<int>(error_code), HostUtility::healthFlagsToString(*host_));\n\n  if (request_in_flight_ && error_code == Http::GoAwayErrorCode::NoError) {\n    // The server is starting a graceful shutdown. Allow the in flight request\n    // to finish without treating this as a health check error, and then\n    // reconnect.\n    reuse_connection_ = false;\n    return;\n  }\n\n  if (request_in_flight_) {\n    // Record this as a failed health check.\n    handleFailure(envoy::data::core::v3::NETWORK);\n  }\n\n  if (client_) {\n    expect_reset_ = true;\n    client_->close();\n  }\n}\n\nHttpHealthCheckerImpl::HttpActiveHealthCheckSession::HealthCheckResult\nHttpHealthCheckerImpl::HttpActiveHealthCheckSession::healthCheckResult() {\n  const uint64_t response_code = Http::Utility::getResponseStatus(*response_headers_);\n  ENVOY_CONN_LOG(debug, \"hc response={} health_flags={}\", *client_, response_code,\n                 HostUtility::healthFlagsToString(*host_));\n\n  if (!parent_.http_status_checker_.inExpectedRanges(response_code)) {\n    // If the HTTP response code would indicate failure AND the immediate health check\n    // failure header is set, exclude the host from LB.\n    // TODO(mattklein123): We could consider doing this check for any HTTP response code, but this\n    // seems like the least surprising behavior and we could consider relaxing this in the future.\n    // TODO(mattklein123): This will not force a host set rebuild of the host was already failed.\n    // This is something we could do in the future but seems unnecessary right now.\n    if (response_headers_->EnvoyImmediateHealthCheckFail() != nullptr) {\n      host_->healthFlagSet(Host::HealthFlag::EXCLUDED_VIA_IMMEDIATE_HC_FAIL);\n    }\n\n    if (parent_.http_status_checker_.inRetriableRanges(response_code)) {\n      return HealthCheckResult::Retriable;\n    } else {\n      return HealthCheckResult::Failed;\n    }\n  }\n\n  const auto degraded = response_headers_->EnvoyDegraded() != nullptr;\n\n  if (parent_.service_name_matcher_.has_value() &&\n      parent_.runtime_.snapshot().featureEnabled(\"health_check.verify_cluster\", 100UL)) {\n    parent_.stats_.verify_cluster_.inc();\n    std::string service_cluster_healthchecked =\n        response_headers_->EnvoyUpstreamHealthCheckedCluster()\n            ? std::string(response_headers_->getEnvoyUpstreamHealthCheckedClusterValue())\n            : EMPTY_STRING;\n    if (parent_.service_name_matcher_->match(service_cluster_healthchecked)) {\n      return degraded ? HealthCheckResult::Degraded : HealthCheckResult::Succeeded;\n    } else {\n      return HealthCheckResult::Failed;\n    }\n  }\n\n  return degraded ? HealthCheckResult::Degraded : HealthCheckResult::Succeeded;\n}\n\nvoid HttpHealthCheckerImpl::HttpActiveHealthCheckSession::onResponseComplete() {\n  request_in_flight_ = false;\n\n  switch (healthCheckResult()) {\n  case HealthCheckResult::Succeeded:\n    handleSuccess(false);\n    break;\n  case HealthCheckResult::Degraded:\n    handleSuccess(true);\n    break;\n  case HealthCheckResult::Failed:\n    handleFailure(envoy::data::core::v3::ACTIVE, /*retriable=*/false);\n    break;\n  case HealthCheckResult::Retriable:\n    handleFailure(envoy::data::core::v3::ACTIVE, /*retriable=*/true);\n    break;\n  }\n\n  if (shouldClose()) {\n    client_->close();\n  }\n\n  response_headers_.reset();\n}\n\n// It is possible for this session to have been deferred destroyed inline in handleFailure()\n// above so make sure we still have a connection that we might need to close.\nbool HttpHealthCheckerImpl::HttpActiveHealthCheckSession::shouldClose() const {\n  if (client_ == nullptr) {\n    return false;\n  }\n\n  if (!reuse_connection_) {\n    return true;\n  }\n\n  return Http::HeaderUtility::shouldCloseConnection(client_->protocol(), *response_headers_);\n}\n\nvoid HttpHealthCheckerImpl::HttpActiveHealthCheckSession::onTimeout() {\n  request_in_flight_ = false;\n  if (client_) {\n    ENVOY_CONN_LOG(debug, \"connection/stream timeout health_flags={}\", *client_,\n                   HostUtility::healthFlagsToString(*host_));\n\n    // If there is an active request it will get reset, so make sure we ignore the reset.\n    expect_reset_ = true;\n\n    client_->close();\n  }\n}\n\nHttp::CodecType\nHttpHealthCheckerImpl::codecClientType(const envoy::type::v3::CodecClientType& type) {\n  switch (type) {\n    PANIC_ON_PROTO_ENUM_SENTINEL_VALUES;\n  case envoy::type::v3::HTTP3:\n    return Http::CodecType::HTTP3;\n  case envoy::type::v3::HTTP2:\n    return Http::CodecType::HTTP2;\n  case envoy::type::v3::HTTP1:\n    return Http::CodecType::HTTP1;\n  }\n  PANIC_DUE_TO_CORRUPT_ENUM\n}\n\nHttp::CodecClient*\nProdHttpHealthCheckerImpl::createCodecClient(Upstream::Host::CreateConnectionData& data) {\n  return new Http::CodecClientProd(codec_client_type_, std::move(data.connection_),\n                                   data.host_description_, dispatcher_, random_generator_);\n}\n\nTcpHealthCheckMatcher::MatchSegments TcpHealthCheckMatcher::loadProtoBytes(\n    const Protobuf::RepeatedPtrField<envoy::config::core::v3::HealthCheck::Payload>& byte_array) {\n  MatchSegments result;\n\n  for (const auto& entry : byte_array) {\n    const auto decoded = Hex::decode(entry.text());\n    if (decoded.empty()) {\n      throw EnvoyException(fmt::format(\"invalid hex string '{}'\", entry.text()));\n    }\n    result.push_back(decoded);\n  }\n\n  return result;\n}\n\nbool TcpHealthCheckMatcher::match(const MatchSegments& expected, const Buffer::Instance& buffer) {\n  uint64_t start_index = 0;\n  for (const std::vector<uint8_t>& segment : expected) {\n    ssize_t search_result = buffer.search(segment.data(), segment.size(), start_index);\n    if (search_result == -1) {\n      return false;\n    }\n\n    start_index = search_result + segment.size();\n  }\n\n  return true;\n}\n\nTcpHealthCheckerImpl::TcpHealthCheckerImpl(const Cluster& cluster,\n                                           const envoy::config::core::v3::HealthCheck& config,\n                                           Event::Dispatcher& dispatcher, Runtime::Loader& runtime,\n                                           Random::RandomGenerator& random,\n                                           HealthCheckEventLoggerPtr&& event_logger)\n    : HealthCheckerImplBase(cluster, config, dispatcher, runtime, random, std::move(event_logger)),\n      send_bytes_([&config] {\n        Protobuf::RepeatedPtrField<envoy::config::core::v3::HealthCheck::Payload> send_repeated;\n        if (!config.tcp_health_check().send().text().empty()) {\n          send_repeated.Add()->CopyFrom(config.tcp_health_check().send());\n        }\n        return TcpHealthCheckMatcher::loadProtoBytes(send_repeated);\n      }()),\n      receive_bytes_(TcpHealthCheckMatcher::loadProtoBytes(config.tcp_health_check().receive())) {}\n\nTcpHealthCheckerImpl::TcpActiveHealthCheckSession::~TcpActiveHealthCheckSession() {\n  ASSERT(client_ == nullptr);\n}\n\nvoid TcpHealthCheckerImpl::TcpActiveHealthCheckSession::onDeferredDelete() {\n  if (client_) {\n    expect_close_ = true;\n    client_->close(Network::ConnectionCloseType::NoFlush);\n  }\n}\n\nvoid TcpHealthCheckerImpl::TcpActiveHealthCheckSession::onData(Buffer::Instance& data) {\n  ENVOY_CONN_LOG(trace, \"total pending buffer={}\", *client_, data.length());\n  // TODO(lilika): The TCP health checker does generic pattern matching so we can't differentiate\n  // between wrong data and not enough data. We could likely do better here and figure out cases in\n  // which a match is not possible but that is not done now.\n  if (TcpHealthCheckMatcher::match(parent_.receive_bytes_, data)) {\n    ENVOY_CONN_LOG(trace, \"healthcheck passed\", *client_);\n    data.drain(data.length());\n    handleSuccess(false);\n    if (!parent_.reuse_connection_) {\n      expect_close_ = true;\n      client_->close(Network::ConnectionCloseType::NoFlush);\n    }\n  }\n}\n\nvoid TcpHealthCheckerImpl::TcpActiveHealthCheckSession::onEvent(Network::ConnectionEvent event) {\n  if (event == Network::ConnectionEvent::RemoteClose ||\n      event == Network::ConnectionEvent::LocalClose) {\n    if (!expect_close_) {\n      handleFailure(envoy::data::core::v3::NETWORK);\n    }\n    parent_.dispatcher_.deferredDelete(std::move(client_));\n  }\n\n  if (event == Network::ConnectionEvent::Connected && parent_.receive_bytes_.empty()) {\n    // In this case we are just testing that we can connect, so immediately succeed. Also, since\n    // we are just doing a connection test, close the connection.\n    // NOTE(mattklein123): I've seen cases where the kernel will report a successful connection, and\n    // then proceed to fail subsequent calls (so the connection did not actually succeed). I'm not\n    // sure what situations cause this. If this turns into a problem, we may need to introduce a\n    // timer and see if the connection stays alive for some period of time while waiting to read.\n    // (Though we may never get a FIN and won't know until if/when we try to write). In short, this\n    // may need to get more complicated but we can start here.\n    // TODO(mattklein123): If we had a way on the connection interface to do an immediate read (vs.\n    // evented), that would be a good check to run here to make sure it returns the equivalent of\n    // EAGAIN. Need to think through how that would look from an interface perspective.\n    // TODO(mattklein123): In the case that a user configured bytes to write, they will not be\n    // be written, since we currently have no way to know if the bytes actually get written via\n    // the connection interface. We might want to figure out how to handle this better later.\n    expect_close_ = true;\n    client_->close(Network::ConnectionCloseType::NoFlush);\n    handleSuccess(false);\n  }\n}\n\n// TODO(lilika) : Support connection pooling\nvoid TcpHealthCheckerImpl::TcpActiveHealthCheckSession::onInterval() {\n  if (!client_) {\n    client_ =\n        host_\n            ->createHealthCheckConnection(parent_.dispatcher_, parent_.transportSocketOptions(),\n                                          parent_.transportSocketMatchMetadata().get())\n            .connection_;\n    session_callbacks_ = std::make_shared<TcpSessionCallbacks>(*this);\n    client_->addConnectionCallbacks(*session_callbacks_);\n    client_->addReadFilter(session_callbacks_);\n\n    expect_close_ = false;\n    client_->connect();\n    client_->noDelay(true);\n  }\n\n  if (!parent_.send_bytes_.empty()) {\n    Buffer::OwnedImpl data;\n    for (const std::vector<uint8_t>& segment : parent_.send_bytes_) {\n      data.add(segment.data(), segment.size());\n    }\n\n    client_->write(data, false);\n  }\n}\n\nvoid TcpHealthCheckerImpl::TcpActiveHealthCheckSession::onTimeout() {\n  expect_close_ = true;\n  client_->close(Network::ConnectionCloseType::NoFlush);\n}\n\nGrpcHealthCheckerImpl::GrpcHealthCheckerImpl(const Cluster& cluster,\n                                             const envoy::config::core::v3::HealthCheck& config,\n                                             Event::Dispatcher& dispatcher,\n                                             Runtime::Loader& runtime,\n                                             Random::RandomGenerator& random,\n                                             HealthCheckEventLoggerPtr&& event_logger)\n    : HealthCheckerImplBase(cluster, config, dispatcher, runtime, random, std::move(event_logger)),\n      random_generator_(random),\n      service_method_(*Protobuf::DescriptorPool::generated_pool()->FindMethodByName(\n          \"grpc.health.v1.Health.Check\")),\n      request_headers_parser_(\n          Router::HeaderParser::configure(config.grpc_health_check().initial_metadata())) {\n  if (!config.grpc_health_check().service_name().empty()) {\n    service_name_ = config.grpc_health_check().service_name();\n  }\n\n  if (!config.grpc_health_check().authority().empty()) {\n    authority_value_ = config.grpc_health_check().authority();\n  }\n}\n\nGrpcHealthCheckerImpl::GrpcActiveHealthCheckSession::GrpcActiveHealthCheckSession(\n    GrpcHealthCheckerImpl& parent, const HostSharedPtr& host)\n    : ActiveHealthCheckSession(parent, host), parent_(parent),\n      local_connection_info_provider_(std::make_shared<Network::ConnectionInfoSetterImpl>(\n          Network::Utility::getCanonicalIpv4LoopbackAddress(),\n          Network::Utility::getCanonicalIpv4LoopbackAddress())) {}\n\nGrpcHealthCheckerImpl::GrpcActiveHealthCheckSession::~GrpcActiveHealthCheckSession() {\n  ASSERT(client_ == nullptr);\n}\n\nvoid GrpcHealthCheckerImpl::GrpcActiveHealthCheckSession::onDeferredDelete() {\n  if (client_) {\n    // If there is an active request it will get reset, so make sure we ignore the reset.\n    expect_reset_ = true;\n    client_->close();\n  }\n}\n\nvoid GrpcHealthCheckerImpl::GrpcActiveHealthCheckSession::decodeHeaders(\n    Http::ResponseHeaderMapPtr&& headers, bool end_stream) {\n  const auto http_response_status = Http::Utility::getResponseStatus(*headers);\n  if (http_response_status != enumToInt(Http::Code::OK)) {\n    // https://github.com/grpc/grpc/blob/master/doc/http-grpc-status-mapping.md requires that\n    // grpc-status be used if available.\n    if (end_stream) {\n      const auto grpc_status = Grpc::Common::getGrpcStatus(*headers);\n      if (grpc_status) {\n        onRpcComplete(grpc_status.value(), Grpc::Common::getGrpcMessage(*headers), true);\n        return;\n      }\n    }\n    onRpcComplete(Grpc::Utility::httpToGrpcStatus(http_response_status), \"non-200 HTTP response\",\n                  end_stream);\n    return;\n  }\n  if (!Grpc::Common::isGrpcResponseHeaders(*headers, end_stream)) {\n    onRpcComplete(Grpc::Status::WellKnownGrpcStatus::Internal, \"not a gRPC request\", false);\n    return;\n  }\n  if (end_stream) {\n    // This is how, for instance, grpc-go signals about missing service - HTTP/2 200 OK with\n    // 'unimplemented' gRPC status.\n    const auto grpc_status = Grpc::Common::getGrpcStatus(*headers);\n    if (grpc_status) {\n      onRpcComplete(grpc_status.value(), Grpc::Common::getGrpcMessage(*headers), true);\n      return;\n    }\n    onRpcComplete(Grpc::Status::WellKnownGrpcStatus::Internal,\n                  \"gRPC protocol violation: unexpected stream end\", true);\n  }\n}\n\nvoid GrpcHealthCheckerImpl::GrpcActiveHealthCheckSession::decodeData(Buffer::Instance& data,\n                                                                     bool end_stream) {\n  if (end_stream) {\n    onRpcComplete(Grpc::Status::WellKnownGrpcStatus::Internal,\n                  \"gRPC protocol violation: unexpected stream end\", true);\n    return;\n  }\n  // We should end up with only one frame here.\n  std::vector<Grpc::Frame> decoded_frames;\n  if (!decoder_.decode(data, decoded_frames)) {\n    onRpcComplete(Grpc::Status::WellKnownGrpcStatus::Internal, \"gRPC wire protocol decode error\",\n                  false);\n    return;\n  }\n  for (auto& frame : decoded_frames) {\n    if (frame.length_ > 0) {\n      if (health_check_response_) {\n        // grpc.health.v1.Health.Check is unary RPC, so only one message is allowed.\n        onRpcComplete(Grpc::Status::WellKnownGrpcStatus::Internal, \"unexpected streaming\", false);\n        return;\n      }\n      health_check_response_ = std::make_unique<grpc::health::v1::HealthCheckResponse>();\n      Buffer::ZeroCopyInputStreamImpl stream(std::move(frame.data_));\n\n      if (frame.flags_ != Grpc::GRPC_FH_DEFAULT ||\n          !health_check_response_->ParseFromZeroCopyStream(&stream)) {\n        onRpcComplete(Grpc::Status::WellKnownGrpcStatus::Internal,\n                      \"invalid grpc.health.v1 RPC payload\", false);\n        return;\n      }\n    }\n  }\n}\n\nvoid GrpcHealthCheckerImpl::GrpcActiveHealthCheckSession::decodeTrailers(\n    Http::ResponseTrailerMapPtr&& trailers) {\n  auto maybe_grpc_status = Grpc::Common::getGrpcStatus(*trailers);\n  auto grpc_status =\n      maybe_grpc_status\n          ? maybe_grpc_status.value()\n          : static_cast<Grpc::Status::GrpcStatus>(Grpc::Status::WellKnownGrpcStatus::Internal);\n  const std::string grpc_message =\n      maybe_grpc_status ? Grpc::Common::getGrpcMessage(*trailers) : \"invalid gRPC status\";\n  onRpcComplete(grpc_status, grpc_message, true);\n}\n\nvoid GrpcHealthCheckerImpl::GrpcActiveHealthCheckSession::onEvent(Network::ConnectionEvent event) {\n  if (event == Network::ConnectionEvent::RemoteClose ||\n      event == Network::ConnectionEvent::LocalClose) {\n    // For the raw disconnect event, we are either between intervals in which case we already have\n    // a timer setup, or we did the close or got a reset, in which case we already setup a new\n    // timer. There is nothing to do here other than blow away the client.\n    parent_.dispatcher_.deferredDelete(std::move(client_));\n  }\n}\n\nvoid GrpcHealthCheckerImpl::GrpcActiveHealthCheckSession::onInterval() {\n  if (!client_) {\n    Upstream::Host::CreateConnectionData conn =\n        host_->createHealthCheckConnection(parent_.dispatcher_, parent_.transportSocketOptions(),\n                                           parent_.transportSocketMatchMetadata().get());\n    client_ = parent_.createCodecClient(conn);\n    client_->addConnectionCallbacks(connection_callback_impl_);\n    client_->setCodecConnectionCallbacks(http_connection_callback_impl_);\n  }\n\n  request_encoder_ = &client_->newStream(*this);\n  request_encoder_->getStream().addCallbacks(*this);\n\n  const std::string& authority =\n      getHostname(host_, parent_.authority_value_, parent_.cluster_.info());\n  auto headers_message =\n      Grpc::Common::prepareHeaders(authority, parent_.service_method_.service()->full_name(),\n                                   parent_.service_method_.name(), absl::nullopt);\n  headers_message->headers().setReferenceUserAgent(\n      Http::Headers::get().UserAgentValues.EnvoyHealthChecker);\n\n  StreamInfo::StreamInfoImpl stream_info(Http::Protocol::Http2, parent_.dispatcher_.timeSource(),\n                                         local_connection_info_provider_);\n  stream_info.setUpstreamInfo(std::make_shared<StreamInfo::UpstreamInfoImpl>());\n  stream_info.upstreamInfo()->setUpstreamHost(host_);\n  parent_.request_headers_parser_->evaluateHeaders(headers_message->headers(), stream_info);\n\n  Grpc::Common::toGrpcTimeout(parent_.timeout_, headers_message->headers());\n\n  Router::FilterUtility::setUpstreamScheme(\n      headers_message->headers(),\n      // Here there is no downstream connection so scheme will be based on\n      // upstream crypto\n      host_->transportSocketFactory().implementsSecureTransport());\n\n  auto status = request_encoder_->encodeHeaders(headers_message->headers(), false);\n  // Encoding will only fail if required headers are missing.\n  ASSERT(status.ok());\n\n  grpc::health::v1::HealthCheckRequest request;\n  if (parent_.service_name_.has_value()) {\n    request.set_service(parent_.service_name_.value());\n  }\n\n  request_encoder_->encodeData(*Grpc::Common::serializeToGrpcFrame(request), true);\n}\n\nvoid GrpcHealthCheckerImpl::GrpcActiveHealthCheckSession::onResetStream(Http::StreamResetReason,\n                                                                        absl::string_view) {\n  const bool expected_reset = expect_reset_;\n  const bool goaway = received_no_error_goaway_;\n  resetState();\n\n  if (expected_reset) {\n    // Stream reset was initiated by us (bogus gRPC response, timeout or cluster host is going\n    // away). In these cases health check failure has already been reported and a GOAWAY (if any)\n    // has already been handled, so just return.\n    return;\n  }\n\n  ENVOY_CONN_LOG(debug, \"connection/stream error health_flags={}\", *client_,\n                 HostUtility::healthFlagsToString(*host_));\n\n  if (goaway || !parent_.reuse_connection_) {\n    // Stream reset was unexpected, so we haven't closed the connection\n    // yet in response to a GOAWAY or due to disabled connection reuse.\n    client_->close();\n  }\n\n  // TODO(baranov1ch): according to all HTTP standards, we should check if reason is one of\n  // Http::StreamResetReason::RemoteRefusedStreamReset (which may mean GOAWAY),\n  // Http::StreamResetReason::RemoteReset or Http::StreamResetReason::ConnectionTermination (both\n  // mean connection close), check if connection is not fresh (was used for at least 1 request)\n  // and silently retry request on the fresh connection. This is also true for HTTP/1.1 healthcheck.\n  handleFailure(envoy::data::core::v3::NETWORK);\n}\n\nvoid GrpcHealthCheckerImpl::GrpcActiveHealthCheckSession::onGoAway(\n    Http::GoAwayErrorCode error_code) {\n  ENVOY_CONN_LOG(debug, \"connection going away health_flags={}\", *client_,\n                 HostUtility::healthFlagsToString(*host_));\n  // If we have an active health check probe and receive a GOAWAY indicating\n  // graceful shutdown, allow the probe to complete before closing the connection.\n  // The connection will be closed when the active check completes or another\n  // terminal condition occurs, such as a timeout or stream reset.\n  if (request_encoder_ && error_code == Http::GoAwayErrorCode::NoError) {\n    received_no_error_goaway_ = true;\n    return;\n  }\n\n  // Even if we have active health check probe, fail it on GOAWAY and schedule new one.\n  if (request_encoder_) {\n    handleFailure(envoy::data::core::v3::NETWORK);\n    expect_reset_ = true;\n    request_encoder_->getStream().resetStream(Http::StreamResetReason::LocalReset);\n  }\n  client_->close();\n}\n\nbool GrpcHealthCheckerImpl::GrpcActiveHealthCheckSession::isHealthCheckSucceeded(\n    Grpc::Status::GrpcStatus grpc_status) const {\n  if (grpc_status != Grpc::Status::WellKnownGrpcStatus::Ok) {\n    return false;\n  }\n\n  if (!health_check_response_ ||\n      health_check_response_->status() != grpc::health::v1::HealthCheckResponse::SERVING) {\n    return false;\n  }\n\n  return true;\n}\n\nvoid GrpcHealthCheckerImpl::GrpcActiveHealthCheckSession::onRpcComplete(\n    Grpc::Status::GrpcStatus grpc_status, const std::string& grpc_message, bool end_stream) {\n  logHealthCheckStatus(grpc_status, grpc_message);\n  if (isHealthCheckSucceeded(grpc_status)) {\n    handleSuccess(false);\n  } else {\n    handleFailure(envoy::data::core::v3::ACTIVE);\n  }\n\n  // Read the value as we may call resetState() and clear it.\n  const bool goaway = received_no_error_goaway_;\n\n  // |end_stream| will be false if we decided to stop healthcheck before HTTP stream has ended -\n  // invalid gRPC payload, unexpected message stream or wrong content-type.\n  if (end_stream) {\n    resetState();\n  } else {\n    // resetState() will be called by onResetStream().\n    expect_reset_ = true;\n    request_encoder_->getStream().resetStream(Http::StreamResetReason::LocalReset);\n  }\n\n  if (!parent_.reuse_connection_ || goaway) {\n    client_->close();\n  }\n}\n\nvoid GrpcHealthCheckerImpl::GrpcActiveHealthCheckSession::resetState() {\n  expect_reset_ = false;\n  request_encoder_ = nullptr;\n  decoder_ = Grpc::Decoder();\n  health_check_response_.reset();\n  received_no_error_goaway_ = false;\n}\n\nvoid GrpcHealthCheckerImpl::GrpcActiveHealthCheckSession::onTimeout() {\n  ENVOY_CONN_LOG(debug, \"connection/stream timeout health_flags={}\", *client_,\n                 HostUtility::healthFlagsToString(*host_));\n  expect_reset_ = true;\n  if (received_no_error_goaway_ || !parent_.reuse_connection_) {\n    client_->close();\n  } else {\n    request_encoder_->getStream().resetStream(Http::StreamResetReason::LocalReset);\n  }\n}\n\nvoid GrpcHealthCheckerImpl::GrpcActiveHealthCheckSession::logHealthCheckStatus(\n    Grpc::Status::GrpcStatus grpc_status, const std::string& grpc_message) {\n  const char* service_status;\n  if (!health_check_response_) {\n    service_status = \"rpc_error\";\n  } else {\n    switch (health_check_response_->status()) {\n    case grpc::health::v1::HealthCheckResponse::SERVING:\n      service_status = \"serving\";\n      break;\n    case grpc::health::v1::HealthCheckResponse::NOT_SERVING:\n      service_status = \"not_serving\";\n      break;\n    case grpc::health::v1::HealthCheckResponse::UNKNOWN:\n      service_status = \"unknown\";\n      break;\n    case grpc::health::v1::HealthCheckResponse::SERVICE_UNKNOWN:\n      service_status = \"service_unknown\";\n      break;\n    default:\n      service_status = \"unknown_healthcheck_response\";\n      break;\n    }\n  }\n  std::string grpc_status_message;\n  if (grpc_status != Grpc::Status::WellKnownGrpcStatus::Ok && !grpc_message.empty()) {\n    grpc_status_message = fmt::format(\"{} ({})\", grpc_status, grpc_message);\n  } else {\n    grpc_status_message = absl::StrCat(\"\", grpc_status);\n  }\n\n  ENVOY_CONN_LOG(debug, \"hc grpc_status={} service_status={} health_flags={}\", *client_,\n                 grpc_status_message, service_status, HostUtility::healthFlagsToString(*host_));\n}\n\nHttp::CodecClientPtr\nProdGrpcHealthCheckerImpl::createCodecClient(Upstream::Host::CreateConnectionData& data) {\n  return std::make_unique<Http::CodecClientProd>(\n      Http::CodecType::HTTP2, std::move(data.connection_), data.host_description_, dispatcher_,\n      random_generator_);\n}\n\nstd::ostream& operator<<(std::ostream& out, HealthState state) {\n  switch (state) {\n  case HealthState::Unhealthy:\n    out << \"Unhealthy\";\n    break;\n  case HealthState::Healthy:\n    out << \"Healthy\";\n    break;\n  }\n  return out;\n}\n\nstd::ostream& operator<<(std::ostream& out, HealthTransition changed_state) {\n  switch (changed_state) {\n  case HealthTransition::Unchanged:\n    out << \"Unchanged\";\n    break;\n  case HealthTransition::Changed:\n    out << \"Changed\";\n    break;\n  case HealthTransition::ChangePending:\n    out << \"ChangePending\";\n    break;\n  }\n  return out;\n}\n\n} // namespace Upstream\n} // namespace Envoy\n", "#include <chrono>\n#include <memory>\n#include <ostream>\n#include <string>\n\n#include \"envoy/config/core/v3/base.pb.h\"\n#include \"envoy/config/core/v3/health_check.pb.h\"\n#include \"envoy/config/core/v3/health_check.pb.validate.h\"\n#include \"envoy/config/endpoint/v3/endpoint_components.pb.h\"\n#include \"envoy/data/core/v3/health_check_event.pb.h\"\n#include \"envoy/upstream/health_check_host_monitor.h\"\n\n#include \"source/common/buffer/buffer_impl.h\"\n#include \"source/common/buffer/zero_copy_input_stream_impl.h\"\n#include \"source/common/grpc/common.h\"\n#include \"source/common/http/headers.h\"\n#include \"source/common/json/json_loader.h\"\n#include \"source/common/network/utility.h\"\n#include \"source/common/protobuf/utility.h\"\n#include \"source/common/upstream/health_checker_impl.h\"\n#include \"source/common/upstream/upstream_impl.h\"\n\n#include \"test/common/http/common.h\"\n#include \"test/common/upstream/utility.h\"\n#include \"test/mocks/access_log/mocks.h\"\n#include \"test/mocks/api/mocks.h\"\n#include \"test/mocks/common.h\"\n#include \"test/mocks/http/mocks.h\"\n#include \"test/mocks/network/mocks.h\"\n#include \"test/mocks/protobuf/mocks.h\"\n#include \"test/mocks/runtime/mocks.h\"\n#include \"test/mocks/upstream/cluster_info.h\"\n#include \"test/mocks/upstream/cluster_priority_set.h\"\n#include \"test/mocks/upstream/health_check_event_logger.h\"\n#include \"test/mocks/upstream/host_set.h\"\n#include \"test/mocks/upstream/transport_socket_match.h\"\n#include \"test/test_common/printers.h\"\n#include \"test/test_common/simulated_time_system.h\"\n#include \"test/test_common/test_runtime.h\"\n#include \"test/test_common/utility.h\"\n\n#include \"gmock/gmock.h\"\n#include \"gtest/gtest.h\"\n\nusing testing::_;\nusing testing::DoAll;\nusing testing::InSequence;\nusing testing::Invoke;\nusing testing::InvokeWithoutArgs;\nusing testing::NiceMock;\nusing testing::Return;\nusing testing::ReturnRef;\nusing testing::SaveArg;\n\nnamespace Envoy {\nnamespace Upstream {\nnamespace {\n\nenvoy::config::core::v3::HealthCheck createGrpcHealthCheckConfig() {\n  envoy::config::core::v3::HealthCheck health_check;\n  health_check.mutable_timeout()->set_seconds(1);\n  health_check.mutable_interval()->set_seconds(1);\n  health_check.mutable_unhealthy_threshold()->set_value(2);\n  health_check.mutable_healthy_threshold()->set_value(2);\n  health_check.mutable_grpc_health_check();\n  return health_check;\n}\n\nTEST(HealthCheckerFactoryTest, GrpcHealthCheckHTTP2NotConfiguredException) {\n  NiceMock<Upstream::MockClusterMockPrioritySet> cluster;\n  EXPECT_CALL(*cluster.info_, features()).WillRepeatedly(Return(0));\n\n  Runtime::MockLoader runtime;\n  Event::MockDispatcher dispatcher;\n  AccessLog::MockAccessLogManager log_manager;\n  NiceMock<ProtobufMessage::MockValidationVisitor> validation_visitor;\n  Api::MockApi api;\n\n  EXPECT_THROW_WITH_MESSAGE(\n      HealthCheckerFactory::create(createGrpcHealthCheckConfig(), cluster, runtime, dispatcher,\n                                   log_manager, validation_visitor, api),\n      EnvoyException, \"fake_cluster cluster must support HTTP/2 for gRPC healthchecking\");\n}\n\nTEST(HealthCheckerFactoryTest, CreateGrpc) {\n\n  NiceMock<Upstream::MockClusterMockPrioritySet> cluster;\n  EXPECT_CALL(*cluster.info_, features())\n      .WillRepeatedly(Return(Upstream::ClusterInfo::Features::HTTP2));\n\n  Runtime::MockLoader runtime;\n  Event::MockDispatcher dispatcher;\n  AccessLog::MockAccessLogManager log_manager;\n  NiceMock<ProtobufMessage::MockValidationVisitor> validation_visitor;\n  NiceMock<Api::MockApi> api;\n\n  EXPECT_NE(nullptr,\n            dynamic_cast<GrpcHealthCheckerImpl*>(\n                HealthCheckerFactory::create(createGrpcHealthCheckConfig(), cluster, runtime,\n                                             dispatcher, log_manager, validation_visitor, api)\n                    .get()));\n}\n\nclass HealthCheckerTestBase {\npublic:\n  std::shared_ptr<MockClusterMockPrioritySet> cluster_{\n      std::make_shared<NiceMock<MockClusterMockPrioritySet>>()};\n  NiceMock<Event::MockDispatcher> dispatcher_;\n  std::unique_ptr<MockHealthCheckEventLogger> event_logger_storage_{\n      std::make_unique<MockHealthCheckEventLogger>()};\n  MockHealthCheckEventLogger& event_logger_{*event_logger_storage_};\n  NiceMock<Random::MockRandomGenerator> random_;\n  NiceMock<Runtime::MockLoader> runtime_;\n};\n\nclass TestHttpHealthCheckerImpl : public HttpHealthCheckerImpl {\npublic:\n  using HttpHealthCheckerImpl::HttpHealthCheckerImpl;\n\n  Http::CodecClient* createCodecClient(Upstream::Host::CreateConnectionData& conn_data) override {\n    return createCodecClient_(conn_data);\n  };\n\n  // HttpHealthCheckerImpl\n  MOCK_METHOD(Http::CodecClient*, createCodecClient_, (Upstream::Host::CreateConnectionData&));\n\n  Http::CodecType codecClientType() { return codec_client_type_; }\n};\n\nclass HttpHealthCheckerImplTest : public Event::TestUsingSimulatedTime,\n                                  public testing::Test,\n                                  public HealthCheckerTestBase {\npublic:\n  struct TestSession {\n    Event::MockTimer* interval_timer_{};\n    Event::MockTimer* timeout_timer_{};\n    Http::MockClientConnection* codec_{};\n    Stats::IsolatedStoreImpl stats_store_;\n    Network::MockClientConnection* client_connection_{};\n    NiceMock<Http::MockRequestEncoder> request_encoder_;\n    Http::ResponseDecoder* stream_response_callbacks_{};\n    CodecClientForTest* codec_client_{};\n  };\n\n  using TestSessionPtr = std::unique_ptr<TestSession>;\n  using HostWithHealthCheckMap =\n      absl::node_hash_map<std::string,\n                          const envoy::config::endpoint::v3::Endpoint::HealthCheckConfig>;\n\n  void allocHealthChecker(const std::string& yaml) {\n    health_checker_ = std::make_shared<TestHttpHealthCheckerImpl>(\n        *cluster_, parseHealthCheckFromV3Yaml(yaml), dispatcher_, runtime_, random_,\n        HealthCheckEventLoggerPtr(event_logger_storage_.release()));\n  }\n\n  void addCompletionCallback() {\n    health_checker_->addHostCheckCompleteCb(\n        [this](HostSharedPtr host, HealthTransition changed_state) -> void {\n          onHostStatus(host, changed_state);\n        });\n  }\n\n  void setupNoServiceValidationHCWithHttp2() {\n    const std::string yaml = R\"EOF(\n    timeout: 1s\n    interval: 1s\n    no_traffic_interval: 5s\n    interval_jitter: 1s\n    unhealthy_threshold: 2\n    healthy_threshold: 2\n    http_health_check:\n      service_name_matcher:\n        prefix: locations\n      path: /healthcheck\n      codec_client_type: Http2\n    )EOF\";\n\n    allocHealthChecker(yaml);\n    addCompletionCallback();\n  }\n\n  void setupHCHttp2() {\n    const std::string yaml = R\"EOF(\n    timeout: 1s\n    interval: 1s\n    no_traffic_interval: 5s\n    interval_jitter: 1s\n    unhealthy_threshold: 1\n    healthy_threshold: 1\n    http_health_check:\n      service_name_matcher:\n        prefix: locations\n      path: /healthcheck\n      codec_client_type: Http2\n    )EOF\";\n\n    allocHealthChecker(yaml);\n    addCompletionCallback();\n  }\n\n  void setupInitialJitter() {\n    const std::string yaml = R\"EOF(\n    timeout: 1s\n    interval: 1s\n    no_traffic_interval: 5s\n    initial_jitter: 5s\n    interval_jitter_percent: 40\n    unhealthy_threshold: 2\n    healthy_threshold: 2\n    http_health_check:\n      service_name_matcher:\n        prefix: locations\n      path: /healthcheck\n    )EOF\";\n\n    allocHealthChecker(yaml);\n    addCompletionCallback();\n  }\n\n  void setupIntervalJitterPercent() {\n    const std::string yaml = R\"EOF(\n    timeout: 1s\n    interval: 1s\n    no_traffic_interval: 5s\n    interval_jitter_percent: 40\n    unhealthy_threshold: 2\n    healthy_threshold: 2\n    http_health_check:\n      service_name_matcher:\n        prefix: locations\n      path: /healthcheck\n    )EOF\";\n\n    allocHealthChecker(yaml);\n    addCompletionCallback();\n  }\n\n  void setupNoServiceValidationHC() {\n    const std::string yaml = R\"EOF(\n    timeout: 1s\n    interval: 1s\n    no_traffic_interval: 5s\n    interval_jitter: 1s\n    unhealthy_threshold: 2\n    healthy_threshold: 2\n    http_health_check:\n      service_name_matcher:\n        prefix: locations\n      path: /healthcheck\n    )EOF\";\n\n    allocHealthChecker(yaml);\n    addCompletionCallback();\n  }\n\n  void setupNoTrafficHealthyValidationHC() {\n    const std::string yaml = R\"EOF(\n    timeout: 1s\n    interval: 1s\n    no_traffic_interval: 5s\n    no_traffic_healthy_interval: 10s\n    interval_jitter: 1s\n    unhealthy_threshold: 1\n    healthy_threshold: 1\n    http_health_check:\n      service_name_matcher:\n        prefix: locations\n      path: /healthcheck\n    )EOF\";\n\n    allocHealthChecker(yaml);\n    addCompletionCallback();\n  }\n\n  void setupNoServiceValidationHCOneUnhealthy() {\n    const std::string yaml = R\"EOF(\n    timeout: 1s\n    interval: 1s\n    no_traffic_interval: 5s\n    interval_jitter: 1s\n    unhealthy_threshold: 1\n    healthy_threshold: 2\n    http_health_check:\n      service_name_matcher:\n        prefix: locations\n      path: /healthcheck\n    )EOF\";\n\n    allocHealthChecker(yaml);\n    addCompletionCallback();\n  }\n\n  void setupNoServiceValidationHCAlwaysLogFailure() {\n    const std::string yaml = R\"EOF(\n    timeout: 1s\n    interval: 1s\n    no_traffic_interval: 5s\n    interval_jitter: 1s\n    unhealthy_threshold: 2\n    healthy_threshold: 2\n    http_health_check:\n      service_name_matcher:\n        prefix: locations\n      path: /healthcheck\n    always_log_health_check_failures: true\n    )EOF\";\n\n    allocHealthChecker(yaml);\n    addCompletionCallback();\n  }\n\n  void setupNoServiceValidationNoReuseConnectionHC() {\n    std::string yaml = R\"EOF(\n    timeout: 1s\n    interval: 1s\n    interval_jitter: 1s\n    unhealthy_threshold: 2\n    healthy_threshold: 2\n    reuse_connection: false\n    http_health_check:\n      path: /healthcheck\n    )EOF\";\n\n    allocHealthChecker(yaml);\n    addCompletionCallback();\n  }\n\n  void setupHealthCheckIntervalOverridesHC() {\n    const std::string yaml = R\"EOF(\n    timeout: 1s\n    interval: 1s\n    unhealthy_interval: 2s\n    unhealthy_edge_interval: 3s\n    healthy_edge_interval: 4s\n    no_traffic_interval: 5s\n    interval_jitter: 0s\n    unhealthy_threshold: 3\n    healthy_threshold: 3\n    http_health_check:\n      service_name_matcher:\n        prefix: locations\n      path: /healthcheck\n    )EOF\";\n\n    allocHealthChecker(yaml);\n    addCompletionCallback();\n  }\n\n  void setupServiceValidationHC() {\n    std::string yaml = R\"EOF(\n    timeout: 1s\n    interval: 1s\n    interval_jitter: 1s\n    unhealthy_threshold: 2\n    healthy_threshold: 2\n    http_health_check:\n      service_name_matcher:\n        prefix: locations\n      path: /healthcheck\n    )EOF\";\n\n    allocHealthChecker(yaml);\n    addCompletionCallback();\n  }\n\n  void setupServiceNameValidationHC(const std::string& prefix) {\n    std::string yaml = fmt::format(R\"EOF(\n    timeout: 1s\n    interval: 1s\n    interval_jitter: 1s\n    unhealthy_threshold: 2\n    healthy_threshold: 2\n    http_health_check:\n      service_name_matcher:\n        prefix: {0}\n      path: /healthcheck\n    )EOF\",\n                                   prefix);\n\n    allocHealthChecker(yaml);\n    addCompletionCallback();\n  }\n\n  void setupServicePrefixPatternValidationHC() {\n    std::string yaml = R\"EOF(\n    timeout: 1s\n    interval: 1s\n    interval_jitter: 1s\n    unhealthy_threshold: 2\n    healthy_threshold: 2\n    http_health_check:\n      service_name_matcher:\n        prefix: locations\n      path: /healthcheck\n    )EOF\";\n\n    allocHealthChecker(yaml);\n    addCompletionCallback();\n  }\n\n  void setupServiceExactPatternValidationHC() {\n    std::string yaml = R\"EOF(\n    timeout: 1s\n    interval: 1s\n    interval_jitter: 1s\n    unhealthy_threshold: 2\n    healthy_threshold: 2\n    http_health_check:\n      service_name_matcher:\n        exact: locations-production-iad\n      path: /healthcheck\n    )EOF\";\n\n    allocHealthChecker(yaml);\n    addCompletionCallback();\n  }\n\n  void setupServiceRegexPatternValidationHC() {\n    std::string yaml = R\"EOF(\n    timeout: 1s\n    interval: 1s\n    interval_jitter: 1s\n    unhealthy_threshold: 2\n    healthy_threshold: 2\n    http_health_check:\n      service_name_matcher:\n        safe_regex:\n          google_re2: {}\n          regex: 'locations-.*-.*$'\n      path: /healthcheck\n    )EOF\";\n\n    allocHealthChecker(yaml);\n    addCompletionCallback();\n  }\n\n  void setupServiceValidationWithCustomHostValueHC(const std::string& host) {\n    std::string yaml = fmt::format(R\"EOF(\n    timeout: 1s\n    interval: 1s\n    interval_jitter: 1s\n    unhealthy_threshold: 2\n    healthy_threshold: 2\n    http_health_check:\n      service_name_matcher:\n        prefix: locations\n      path: /healthcheck\n      host: {0}\n    )EOF\",\n                                   host);\n\n    allocHealthChecker(yaml);\n    addCompletionCallback();\n  }\n\n  const envoy::config::endpoint::v3::Endpoint::HealthCheckConfig\n  makeHealthCheckConfig(const uint32_t port_value) {\n    envoy::config::endpoint::v3::Endpoint::HealthCheckConfig config;\n    config.set_port_value(port_value);\n    return config;\n  }\n\n  void appendTestHosts(std::shared_ptr<MockClusterMockPrioritySet> cluster,\n                       const HostWithHealthCheckMap& hosts, const std::string& protocol = \"tcp://\",\n                       const uint32_t priority = 0) {\n    for (const auto& host : hosts) {\n      cluster->prioritySet().getMockHostSet(priority)->hosts_.emplace_back(makeTestHost(\n          cluster->info_, fmt::format(\"{}{}\", protocol, host.first), host.second, simTime()));\n    }\n  }\n\n  void setupServiceValidationWithAdditionalHeaders() {\n    std::string yaml = R\"EOF(\n    timeout: 1s\n    interval: 1s\n    interval_jitter: 1s\n    unhealthy_threshold: 2\n    healthy_threshold: 2\n    http_health_check:\n      service_name_matcher:\n        prefix: locations\n      path: /healthcheck\n      host: \"www.envoyproxy.io\"\n      request_headers_to_add:\n        - header:\n            key: x-envoy-ok\n            value: ok\n        - header:\n            key: x-envoy-cool\n            value: cool\n        - header:\n            key: x-envoy-awesome\n            value: awesome\n        # The following entry replaces the current user-agent.\n        - header:\n            key: user-agent\n            value: CoolEnvoy/HC\n          append: false\n        - header:\n            key: x-protocol\n            value: \"%PROTOCOL%\"\n        - header:\n            key: x-upstream-metadata\n            value: \"%UPSTREAM_METADATA([\\\"namespace\\\", \\\"key\\\"])%\"\n        - header:\n            key: x-downstream-remote-address\n            value: \"%DOWNSTREAM_REMOTE_ADDRESS%\"\n        - header:\n            key: x-downstream-remote-address-without-port\n            value: \"%DOWNSTREAM_REMOTE_ADDRESS_WITHOUT_PORT%\"\n        - header:\n            key: x-downstream-local-address\n            value: \"%DOWNSTREAM_LOCAL_ADDRESS%\"\n        - header:\n            key: x-downstream-local-address-without-port\n            value: \"%DOWNSTREAM_LOCAL_ADDRESS_WITHOUT_PORT%\"\n        - header:\n            key: x-start-time\n            value: \"%START_TIME(%s.%9f)%\"\n    )EOF\";\n\n    allocHealthChecker(yaml);\n    addCompletionCallback();\n  }\n\n  void setupServiceValidationWithoutUserAgent() {\n    std::string yaml = R\"EOF(\n    timeout: 1s\n    interval: 1s\n    interval_jitter: 1s\n    unhealthy_threshold: 2\n    healthy_threshold: 2\n    http_health_check:\n      service_name_matcher:\n        prefix: locations\n      path: /healthcheck\n      host: \"www.envoyproxy.io\"\n      # The following entry removes the default \"user-agent\" header.\n      request_headers_to_remove: [\"user-agent\"]\n    )EOF\";\n\n    allocHealthChecker(yaml);\n    addCompletionCallback();\n  }\n\n  void expectSessionCreate(const HostWithHealthCheckMap& health_check_map) {\n    // Expectations are in LIFO order.\n    TestSessionPtr new_test_session(new TestSession());\n    new_test_session->timeout_timer_ = new Event::MockTimer(&dispatcher_);\n    new_test_session->interval_timer_ = new Event::MockTimer(&dispatcher_);\n    test_sessions_.emplace_back(std::move(new_test_session));\n    expectClientCreate(test_sessions_.size() - 1, health_check_map);\n  }\n\n  void expectClientCreate(size_t index, const HostWithHealthCheckMap& health_check_map) {\n    TestSession& test_session = *test_sessions_[index];\n    test_session.codec_ = new NiceMock<Http::MockClientConnection>();\n    ON_CALL(*test_session.codec_, protocol()).WillByDefault(Return(Http::Protocol::Http11));\n    test_session.client_connection_ = new NiceMock<Network::MockClientConnection>();\n    connection_index_.push_back(index);\n    codec_index_.push_back(index);\n\n    EXPECT_CALL(dispatcher_, createClientConnection_(_, _, _, _))\n        .Times(testing::AnyNumber())\n        .WillRepeatedly(InvokeWithoutArgs([&]() -> Network::ClientConnection* {\n          const uint32_t index = connection_index_.front();\n          connection_index_.pop_front();\n          return test_sessions_[index]->client_connection_;\n        }));\n    EXPECT_CALL(*health_checker_, createCodecClient_(_))\n        .WillRepeatedly(\n            Invoke([&](Upstream::Host::CreateConnectionData& conn_data) -> Http::CodecClient* {\n              if (!health_check_map.empty()) {\n                const auto& health_check_config =\n                    health_check_map.at(conn_data.host_description_->address()->asString());\n                // To make sure health checker checks the correct port.\n                EXPECT_EQ(health_check_config.port_value(),\n                          conn_data.host_description_->healthCheckAddress()->ip()->port());\n              }\n              const uint32_t index = codec_index_.front();\n              codec_index_.pop_front();\n              TestSession& test_session = *test_sessions_[index];\n              std::shared_ptr<Upstream::MockClusterInfo> cluster{\n                  new NiceMock<Upstream::MockClusterInfo>()};\n              Event::MockDispatcher dispatcher_;\n              test_session.codec_client_ = new CodecClientForTest(\n                  Http::CodecType::HTTP1, std::move(conn_data.connection_), test_session.codec_,\n                  nullptr, Upstream::makeTestHost(cluster, \"tcp://127.0.0.1:9000\", simTime()),\n                  dispatcher_);\n              return test_session.codec_client_;\n            }));\n  }\n\n  void expectStreamCreate(size_t index) {\n    test_sessions_[index]->request_encoder_.stream_.callbacks_.clear();\n    EXPECT_CALL(*test_sessions_[index]->codec_, newStream(_))\n        .WillOnce(DoAll(SaveArgAddress(&test_sessions_[index]->stream_response_callbacks_),\n                        ReturnRef(test_sessions_[index]->request_encoder_)));\n  }\n\n  void respond(size_t index, const std::string& code, bool conn_close, bool proxy_close = false,\n               bool body = false, bool trailers = false,\n               const absl::optional<std::string>& service_cluster = absl::optional<std::string>(),\n               bool degraded = false, bool immediate_hc_fail = false) {\n    std::unique_ptr<Http::TestResponseHeaderMapImpl> response_headers(\n        new Http::TestResponseHeaderMapImpl{{\":status\", code}});\n\n    if (degraded) {\n      response_headers->setEnvoyDegraded(\"\");\n    }\n    if (service_cluster) {\n      response_headers->addCopy(Http::Headers::get().EnvoyUpstreamHealthCheckedCluster,\n                                service_cluster.value());\n    }\n    if (conn_close) {\n      response_headers->addCopy(\"connection\", \"close\");\n    }\n    if (proxy_close) {\n      response_headers->addCopy(\"proxy-connection\", \"close\");\n    }\n    if (immediate_hc_fail) {\n      response_headers->setEnvoyImmediateHealthCheckFail(\"true\");\n    }\n\n    test_sessions_[index]->stream_response_callbacks_->decodeHeaders(std::move(response_headers),\n                                                                     !body && !trailers);\n    if (body) {\n      Buffer::OwnedImpl response_data;\n      test_sessions_[index]->stream_response_callbacks_->decodeData(response_data, !trailers);\n    }\n\n    if (trailers) {\n      test_sessions_[index]->stream_response_callbacks_->decodeTrailers(\n          Http::ResponseTrailerMapPtr{new Http::TestResponseTrailerMapImpl{{\"some\", \"trailer\"}}});\n    }\n  }\n\n  void expectSessionCreate() { expectSessionCreate(health_checker_map_); }\n  void expectClientCreate(size_t index) { expectClientCreate(index, health_checker_map_); }\n\n  void expectSuccessStartFailedFailFirst(\n      const absl::optional<std::string>& health_checked_cluster = absl::optional<std::string>()) {\n    cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n        makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n    cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthFlagSet(\n        Host::HealthFlag::FAILED_ACTIVE_HC);\n    expectSessionCreate();\n    expectStreamCreate(0);\n    EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n    health_checker_->start();\n\n    // Test that failing first disables fast success.\n    EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n    EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(_, _));\n    EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n    EXPECT_CALL(event_logger_, logUnhealthy(_, _, _, true));\n    respond(0, \"503\", false, false, false, false, health_checked_cluster);\n    EXPECT_TRUE(cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthFlagGet(\n        Host::HealthFlag::FAILED_ACTIVE_HC));\n    EXPECT_EQ(Host::Health::Unhealthy,\n              cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n\n    EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n    expectStreamCreate(0);\n    test_sessions_[0]->interval_timer_->invokeCallback();\n\n    EXPECT_CALL(*this, onHostStatus(_, HealthTransition::ChangePending));\n    EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(_, _));\n    EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n    respond(0, \"200\", false, false, false, false, health_checked_cluster);\n    EXPECT_TRUE(cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthFlagGet(\n        Host::HealthFlag::FAILED_ACTIVE_HC));\n    EXPECT_EQ(Host::Health::Unhealthy,\n              cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n\n    EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n    expectStreamCreate(0);\n    test_sessions_[0]->interval_timer_->invokeCallback();\n\n    EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Changed));\n    EXPECT_CALL(event_logger_, logAddHealthy(_, _, false));\n    EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(_, _));\n    EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n    respond(0, \"200\", false, false, false, false, health_checked_cluster);\n    EXPECT_EQ(Host::Health::Healthy,\n              cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n  }\n\n  MOCK_METHOD(void, onHostStatus, (HostSharedPtr host, HealthTransition changed_state));\n\n  void expectUnhealthyTransition(size_t index, bool first_check) {\n    EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Changed));\n    EXPECT_CALL(*test_sessions_[index]->timeout_timer_, disableTimer());\n    EXPECT_CALL(*test_sessions_[index]->interval_timer_, enableTimer(_, _));\n    if (first_check) {\n      EXPECT_CALL(event_logger_, logUnhealthy(_, _, _, _));\n    }\n    EXPECT_CALL(event_logger_, logEjectUnhealthy(_, _, _));\n  }\n\n  void expectHealthyTransition(size_t index) {\n    EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Changed));\n    EXPECT_CALL(*test_sessions_[index]->timeout_timer_, disableTimer());\n    EXPECT_CALL(*test_sessions_[index]->interval_timer_, enableTimer(_, _));\n    EXPECT_CALL(event_logger_, logAddHealthy(_, _, _));\n  }\n\n  void expectUnchanged(size_t index) {\n    EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n    EXPECT_CALL(*test_sessions_[index]->timeout_timer_, disableTimer());\n    EXPECT_CALL(*test_sessions_[index]->interval_timer_, enableTimer(_, _));\n  }\n\n  void expectChangePending(size_t index) {\n    EXPECT_CALL(*this, onHostStatus(_, HealthTransition::ChangePending));\n    EXPECT_CALL(*test_sessions_[index]->timeout_timer_, disableTimer());\n    EXPECT_CALL(*test_sessions_[index]->interval_timer_, enableTimer(_, _));\n  }\n\n  std::vector<TestSessionPtr> test_sessions_;\n  std::shared_ptr<TestHttpHealthCheckerImpl> health_checker_;\n  std::list<uint32_t> connection_index_{};\n  std::list<uint32_t> codec_index_{};\n  const HostWithHealthCheckMap health_checker_map_{};\n};\n\nTEST_F(HttpHealthCheckerImplTest, Success) {\n  setupNoServiceValidationHC();\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  cluster_->info_->stats().upstream_cx_total_.inc();\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.max_interval\", _));\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.min_interval\", _))\n      .WillOnce(Return(45000));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_,\n              enableTimer(std::chrono::milliseconds(45000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  respond(0, \"200\", false, false, true);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n}\n\nTEST_F(HttpHealthCheckerImplTest, Degraded) {\n  setupNoServiceValidationHC();\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Changed)).Times(2);\n\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  cluster_->info_->stats().upstream_cx_total_.inc();\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.max_interval\", _));\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.min_interval\", _))\n      .WillRepeatedly(Return(45000));\n\n  // We start off as healthy, and should go degraded after receiving the degraded health response.\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(_, _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  EXPECT_CALL(event_logger_, logDegraded(_, _));\n  respond(0, \"200\", false, false, true, false, {}, true);\n  EXPECT_EQ(Host::Health::Degraded, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n\n  // Then, after receiving a regular health check response we should go back to healthy.\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  expectStreamCreate(0);\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.max_interval\", _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  test_sessions_[0]->interval_timer_->invokeCallback();\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(_, _));\n  EXPECT_CALL(event_logger_, logNoLongerDegraded(_, _));\n  respond(0, \"200\", false, false, true, false, {}, false);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n}\n\nTEST_F(HttpHealthCheckerImplTest, SuccessIntervalJitter) {\n  setupNoServiceValidationHC();\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged)).Times(testing::AnyNumber());\n\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(_, _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  respond(0, \"200\", false, false, true, true);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n\n  for (int i = 0; i < 50000; i += 239) {\n    EXPECT_CALL(random_, random()).WillOnce(Return(i));\n    EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n    expectStreamCreate(0);\n    test_sessions_[0]->interval_timer_->invokeCallback();\n    // the jitter is 1000ms here\n    EXPECT_CALL(*test_sessions_[0]->interval_timer_,\n                enableTimer(std::chrono::milliseconds(5000 + i % 1000), _));\n    EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n    respond(0, \"200\", false, false, true, true);\n  }\n}\n\nTEST_F(HttpHealthCheckerImplTest, InitialJitterNoTraffic) {\n  setupInitialJitter();\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged)).Times(testing::AnyNumber());\n\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(_, _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(_, _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  respond(0, \"200\", false, false, true, true);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n\n  for (int i = 0; i < 2; i += 1) {\n    EXPECT_CALL(random_, random()).WillOnce(Return(i));\n    EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n    expectStreamCreate(0);\n    test_sessions_[0]->interval_timer_->invokeCallback();\n    // the jitter is 40% of 5000, so should be 2000\n    EXPECT_CALL(*test_sessions_[0]->interval_timer_,\n                enableTimer(std::chrono::milliseconds(5000 + i % 2000), _));\n    EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n    respond(0, \"200\", false, false, true, true);\n  }\n}\n\nTEST_F(HttpHealthCheckerImplTest, SuccessIntervalJitterPercentNoTraffic) {\n  setupIntervalJitterPercent();\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged)).Times(testing::AnyNumber());\n\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(_, _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  respond(0, \"200\", false, false, true, true);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n\n  for (int i = 0; i < 50000; i += 239) {\n    EXPECT_CALL(random_, random()).WillOnce(Return(i));\n    EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n    expectStreamCreate(0);\n    test_sessions_[0]->interval_timer_->invokeCallback();\n    // the jitter is 40% of 5000, so should be 2000\n    EXPECT_CALL(*test_sessions_[0]->interval_timer_,\n                enableTimer(std::chrono::milliseconds(5000 + i % 2000), _));\n    EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n    respond(0, \"200\", false, false, true, true);\n  }\n}\n\nTEST_F(HttpHealthCheckerImplTest, SuccessIntervalJitterPercent) {\n  setupIntervalJitterPercent();\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged)).Times(testing::AnyNumber());\n\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  cluster_->info_->stats().upstream_cx_total_.inc();\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(_, _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  respond(0, \"200\", false, false, true, true);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n\n  for (int i = 0; i < 50000; i += 239) {\n    EXPECT_CALL(random_, random()).WillOnce(Return(i));\n    EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n    expectStreamCreate(0);\n    test_sessions_[0]->interval_timer_->invokeCallback();\n    // the jitter is 40% of 1000, so should be 400\n    EXPECT_CALL(*test_sessions_[0]->interval_timer_,\n                enableTimer(std::chrono::milliseconds(1000 + i % 400), _));\n    EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n    respond(0, \"200\", false, false, true, true);\n  }\n}\n\nTEST_F(HttpHealthCheckerImplTest, SuccessWithSpurious1xx) {\n  setupNoServiceValidationHC();\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  cluster_->info_->stats().upstream_cx_total_.inc();\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.max_interval\", _));\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.min_interval\", _))\n      .WillOnce(Return(45000));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_,\n              enableTimer(std::chrono::milliseconds(45000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n\n  std::unique_ptr<Http::TestResponseHeaderMapImpl> continue_headers(\n      new Http::TestResponseHeaderMapImpl{{\":status\", \"100\"}});\n  test_sessions_[0]->stream_response_callbacks_->decode1xxHeaders(std::move(continue_headers));\n\n  respond(0, \"200\", false, false, true);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n}\n\nTEST_F(HttpHealthCheckerImplTest, SuccessWithSpuriousMetadata) {\n  setupNoServiceValidationHC();\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  cluster_->info_->stats().upstream_cx_total_.inc();\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.max_interval\", _));\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.min_interval\", _))\n      .WillOnce(Return(45000));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_,\n              enableTimer(std::chrono::milliseconds(45000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n\n  std::unique_ptr<Http::MetadataMap> metadata_map(new Http::MetadataMap());\n  metadata_map->insert(std::make_pair<std::string, std::string>(\"key\", \"value\"));\n  test_sessions_[0]->stream_response_callbacks_->decodeMetadata(std::move(metadata_map));\n\n  respond(0, \"200\", false, false, true);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n}\n\n// Test host check success with multiple hosts.\nTEST_F(HttpHealthCheckerImplTest, SuccessWithMultipleHosts) {\n  setupNoServiceValidationHC();\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged)).Times(2);\n\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime()),\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:81\", simTime())};\n  cluster_->info_->stats().upstream_cx_total_.inc();\n  cluster_->info_->stats().upstream_cx_total_.inc();\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  expectSessionCreate();\n  expectStreamCreate(1);\n  EXPECT_CALL(*test_sessions_[1]->timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.max_interval\", _)).Times(2);\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.min_interval\", _))\n      .Times(2)\n      .WillRepeatedly(Return(45000));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_,\n              enableTimer(std::chrono::milliseconds(45000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  EXPECT_CALL(*test_sessions_[1]->interval_timer_,\n              enableTimer(std::chrono::milliseconds(45000), _));\n  EXPECT_CALL(*test_sessions_[1]->timeout_timer_, disableTimer());\n  respond(0, \"200\", false, false, true);\n  respond(1, \"200\", false, false, true);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[1]->health());\n}\n\n// Test host check success with multiple hosts across multiple priorities.\nTEST_F(HttpHealthCheckerImplTest, SuccessWithMultipleHostSets) {\n  setupNoServiceValidationHC();\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged)).Times(2);\n\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  cluster_->prioritySet().getMockHostSet(1)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:81\", simTime())};\n  cluster_->info_->stats().upstream_cx_total_.inc();\n  cluster_->info_->stats().upstream_cx_total_.inc();\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  expectSessionCreate();\n  expectStreamCreate(1);\n  EXPECT_CALL(*test_sessions_[1]->timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.max_interval\", _)).Times(2);\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.min_interval\", _))\n      .Times(2)\n      .WillRepeatedly(Return(45000));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_,\n              enableTimer(std::chrono::milliseconds(45000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  EXPECT_CALL(*test_sessions_[1]->interval_timer_,\n              enableTimer(std::chrono::milliseconds(45000), _));\n  EXPECT_CALL(*test_sessions_[1]->timeout_timer_, disableTimer());\n  respond(0, \"200\", false, false, true);\n  respond(1, \"200\", false, false, true);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(1)->hosts_[0]->health());\n}\n\n// Validate that runtime settings can't force a zero lengthy retry duration (and hence livelock).\nTEST_F(HttpHealthCheckerImplTest, ZeroRetryInterval) {\n  const std::string host = \"fake_cluster\";\n  const std::string path = \"/healthcheck\";\n  const std::string yaml = R\"EOF(\n    timeout: 1s\n    interval: 1s\n    no_traffic_interval: 1s\n    interval_jitter_percent: 40\n    unhealthy_threshold: 2\n    healthy_threshold: 2\n    http_health_check:\n      service_name_matcher:\n        prefix: locations\n      path: /healthcheck\n    )EOF\";\n\n  allocHealthChecker(yaml);\n  addCompletionCallback();\n\n  EXPECT_CALL(runtime_.snapshot_, featureEnabled(\"health_check.verify_cluster\", 100))\n      .WillOnce(Return(true));\n\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  cluster_->info_->stats().upstream_cx_total_.inc();\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  EXPECT_CALL(test_sessions_[0]->request_encoder_, encodeHeaders(_, true))\n      .WillOnce(Invoke([&](const Http::RequestHeaderMap& headers, bool) -> Http::Status {\n        EXPECT_EQ(headers.getHostValue(), host);\n        EXPECT_EQ(headers.getPathValue(), path);\n        EXPECT_EQ(headers.getSchemeValue(), Http::Headers::get().SchemeValues.Http);\n        return Http::okStatus();\n      }));\n  health_checker_->start();\n\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.max_interval\", _)).WillOnce(Return(0));\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.min_interval\", _)).WillOnce(Return(0));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(std::chrono::milliseconds(1), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  absl::optional<std::string> health_checked_cluster(\"locations-production-iad\");\n  respond(0, \"200\", false, false, true, false, health_checked_cluster);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n}\n\nMATCHER_P(ApplicationProtocolListEq, expected, \"\") {\n  const Network::TransportSocketOptionsConstSharedPtr& options = arg;\n  EXPECT_EQ(options->applicationProtocolListOverride(), std::vector<std::string>{expected});\n  return true;\n}\n\nTEST_F(HttpHealthCheckerImplTest, TlsOptions) {\n  const std::string host = \"fake_cluster\";\n  const std::string path = \"/healthcheck\";\n  const std::string yaml = R\"EOF(\n    timeout: 1s\n    interval: 1s\n    no_traffic_interval: 1s\n    interval_jitter_percent: 40\n    unhealthy_threshold: 2\n    healthy_threshold: 2\n    http_health_check:\n      service_name_matcher:\n        prefix: locations\n      path: /healthcheck\n    tls_options:\n      alpn_protocols:\n      - http1\n    )EOF\";\n\n  auto socket_factory = new Network::MockTransportSocketFactory();\n  EXPECT_CALL(*socket_factory, implementsSecureTransport()).WillRepeatedly(Return(true));\n  auto transport_socket_match = new NiceMock<Upstream::MockTransportSocketMatcher>(\n      Network::TransportSocketFactoryPtr(socket_factory));\n  cluster_->info_->transport_socket_matcher_.reset(transport_socket_match);\n\n  EXPECT_CALL(*socket_factory, createTransportSocket(ApplicationProtocolListEq(\"http1\")));\n\n  allocHealthChecker(yaml);\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  cluster_->info_->stats().upstream_cx_total_.inc();\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n}\n\nTEST_F(HttpHealthCheckerImplTest, SuccessServiceCheck) {\n  const std::string host = \"fake_cluster\";\n  const std::string path = \"/healthcheck\";\n  setupServiceValidationHC();\n  EXPECT_CALL(runtime_.snapshot_, featureEnabled(\"health_check.verify_cluster\", 100))\n      .WillOnce(Return(true));\n\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  cluster_->info_->stats().upstream_cx_total_.inc();\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  EXPECT_CALL(test_sessions_[0]->request_encoder_, encodeHeaders(_, true))\n      .WillOnce(Invoke([&](const Http::RequestHeaderMap& headers, bool) -> Http::Status {\n        EXPECT_EQ(headers.getHostValue(), host);\n        EXPECT_EQ(headers.getPathValue(), path);\n        EXPECT_EQ(headers.getSchemeValue(), Http::Headers::get().SchemeValues.Http);\n        return Http::okStatus();\n      }));\n  health_checker_->start();\n\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.max_interval\", _));\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.min_interval\", _))\n      .WillOnce(Return(45000));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_,\n              enableTimer(std::chrono::milliseconds(45000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  absl::optional<std::string> health_checked_cluster(\"locations-production-iad\");\n  respond(0, \"200\", false, false, true, false, health_checked_cluster);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n}\n\nTEST_F(HttpHealthCheckerImplTest, SuccessServicePrefixPatternCheck) {\n  const std::string host = \"fake_cluster\";\n  const std::string path = \"/healthcheck\";\n  setupServicePrefixPatternValidationHC();\n  EXPECT_CALL(runtime_.snapshot_, featureEnabled(\"health_check.verify_cluster\", 100))\n      .WillOnce(Return(true));\n\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  cluster_->info_->stats().upstream_cx_total_.inc();\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  EXPECT_CALL(test_sessions_[0]->request_encoder_, encodeHeaders(_, true))\n      .WillOnce(Invoke([&](const Http::RequestHeaderMap& headers, bool) -> Http::Status {\n        EXPECT_EQ(headers.getHostValue(), host);\n        EXPECT_EQ(headers.getPathValue(), path);\n        EXPECT_EQ(headers.getSchemeValue(), Http::Headers::get().SchemeValues.Http);\n        return Http::okStatus();\n      }));\n  health_checker_->start();\n\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.max_interval\", _));\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.min_interval\", _))\n      .WillOnce(Return(45000));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_,\n              enableTimer(std::chrono::milliseconds(45000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  absl::optional<std::string> health_checked_cluster(\"locations-production-iad\");\n  respond(0, \"200\", false, false, true, false, health_checked_cluster);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n}\n\nTEST_F(HttpHealthCheckerImplTest, SuccessServiceExactPatternCheck) {\n  const std::string host = \"fake_cluster\";\n  const std::string path = \"/healthcheck\";\n  setupServiceExactPatternValidationHC();\n  EXPECT_CALL(runtime_.snapshot_, featureEnabled(\"health_check.verify_cluster\", 100))\n      .WillOnce(Return(true));\n\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  cluster_->info_->stats().upstream_cx_total_.inc();\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  EXPECT_CALL(test_sessions_[0]->request_encoder_, encodeHeaders(_, true))\n      .WillOnce(Invoke([&](const Http::RequestHeaderMap& headers, bool) -> Http::Status {\n        EXPECT_EQ(headers.getHostValue(), host);\n        EXPECT_EQ(headers.getPathValue(), path);\n        EXPECT_EQ(headers.getSchemeValue(), Http::Headers::get().SchemeValues.Http);\n        return Http::okStatus();\n      }));\n  health_checker_->start();\n\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.max_interval\", _));\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.min_interval\", _))\n      .WillOnce(Return(45000));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_,\n              enableTimer(std::chrono::milliseconds(45000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  absl::optional<std::string> health_checked_cluster(\"locations-production-iad\");\n  respond(0, \"200\", false, false, true, false, health_checked_cluster);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n}\n\nTEST_F(HttpHealthCheckerImplTest, SuccessServiceRegexPatternCheck) {\n  const std::string host = \"fake_cluster\";\n  const std::string path = \"/healthcheck\";\n  setupServiceRegexPatternValidationHC();\n  EXPECT_CALL(runtime_.snapshot_, featureEnabled(\"health_check.verify_cluster\", 100))\n      .WillOnce(Return(true));\n\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  cluster_->info_->stats().upstream_cx_total_.inc();\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  EXPECT_CALL(test_sessions_[0]->request_encoder_, encodeHeaders(_, true))\n      .WillOnce(Invoke([&](const Http::RequestHeaderMap& headers, bool) -> Http::Status {\n        EXPECT_EQ(headers.getHostValue(), host);\n        EXPECT_EQ(headers.getPathValue(), path);\n        EXPECT_EQ(headers.getSchemeValue(), Http::Headers::get().SchemeValues.Http);\n        return Http::okStatus();\n      }));\n  health_checker_->start();\n\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.max_interval\", _));\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.min_interval\", _))\n      .WillOnce(Return(45000));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_,\n              enableTimer(std::chrono::milliseconds(45000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  absl::optional<std::string> health_checked_cluster(\"locations-production-iad\");\n  respond(0, \"200\", false, false, true, false, health_checked_cluster);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n}\n\n// This test verifies that when a hostname is set in the endpoint's HealthCheckConfig, it is used in\n// the health check request.\nTEST_F(HttpHealthCheckerImplTest, SuccessServiceCheckWithCustomHostValueOnTheHost) {\n  const std::string host = \"www.envoyproxy.io\";\n  envoy::config::endpoint::v3::Endpoint::HealthCheckConfig health_check_config;\n  health_check_config.set_hostname(host);\n  auto test_host = std::make_shared<HostImpl>(\n      cluster_->info_, \"\", Network::Utility::resolveUrl(\"tcp://127.0.0.1:80\"), nullptr, 1,\n      envoy::config::core::v3::Locality(), health_check_config, 0, envoy::config::core::v3::UNKNOWN,\n      simTime());\n  const std::string path = \"/healthcheck\";\n  setupServiceValidationHC();\n  // Requires non-empty `service_name` in config.\n  EXPECT_CALL(runtime_.snapshot_, featureEnabled(\"health_check.verify_cluster\", 100))\n      .WillOnce(Return(true));\n\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {test_host};\n  cluster_->info_->stats().upstream_cx_total_.inc();\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  EXPECT_CALL(test_sessions_[0]->request_encoder_, encodeHeaders(_, true))\n      .WillOnce(Invoke([&](const Http::RequestHeaderMap& headers, bool) -> Http::Status {\n        EXPECT_EQ(headers.getHostValue(), host);\n        EXPECT_EQ(headers.getPathValue(), path);\n        return Http::okStatus();\n      }));\n  health_checker_->start();\n\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.max_interval\", _));\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.min_interval\", _))\n      .WillOnce(Return(45000));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_,\n              enableTimer(std::chrono::milliseconds(45000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  absl::optional<std::string> health_checked_cluster(\"locations-production-iad\");\n  respond(0, \"200\", false, false, true, false, health_checked_cluster);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n}\n\n// This test verifies that when a hostname is set in the endpoint's HealthCheckConfig and in the\n// cluster level configuration, the one in the endpoint takes priority.\nTEST_F(HttpHealthCheckerImplTest,\n       SuccessServiceCheckWithCustomHostValueOnTheHostThatOverridesConfigValue) {\n  const std::string host = \"www.envoyproxy.io\";\n  envoy::config::endpoint::v3::Endpoint::HealthCheckConfig health_check_config;\n  health_check_config.set_hostname(host);\n  auto test_host = std::make_shared<HostImpl>(\n      cluster_->info_, \"\", Network::Utility::resolveUrl(\"tcp://127.0.0.1:80\"), nullptr, 1,\n      envoy::config::core::v3::Locality(), health_check_config, 0, envoy::config::core::v3::UNKNOWN,\n      simTime());\n  const std::string path = \"/healthcheck\";\n  // Setup health check config with a different host, to check that we still get the host configured\n  // on the endpoint.\n  setupServiceValidationWithCustomHostValueHC(\"foo.com\");\n  // Requires non-empty `service_name` in config.\n  EXPECT_CALL(runtime_.snapshot_, featureEnabled(\"health_check.verify_cluster\", 100))\n      .WillOnce(Return(true));\n\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {test_host};\n  cluster_->info_->stats().upstream_cx_total_.inc();\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  EXPECT_CALL(test_sessions_[0]->request_encoder_, encodeHeaders(_, true))\n      .WillOnce(Invoke([&](const Http::RequestHeaderMap& headers, bool) -> Http::Status {\n        EXPECT_EQ(headers.getHostValue(), host);\n        EXPECT_EQ(headers.getPathValue(), path);\n        return Http::okStatus();\n      }));\n  health_checker_->start();\n\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.max_interval\", _));\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.min_interval\", _))\n      .WillOnce(Return(45000));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_,\n              enableTimer(std::chrono::milliseconds(45000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  absl::optional<std::string> health_checked_cluster(\"locations-production-iad\");\n  respond(0, \"200\", false, false, true, false, health_checked_cluster);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n}\n\nTEST_F(HttpHealthCheckerImplTest, SuccessServiceCheckWithCustomHostValue) {\n  const std::string host = \"www.envoyproxy.io\";\n  const std::string path = \"/healthcheck\";\n  setupServiceValidationWithCustomHostValueHC(host);\n  // Requires non-empty `service_name` in config.\n  EXPECT_CALL(runtime_.snapshot_, featureEnabled(\"health_check.verify_cluster\", 100))\n      .WillOnce(Return(true));\n\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  cluster_->info_->stats().upstream_cx_total_.inc();\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  EXPECT_CALL(test_sessions_[0]->request_encoder_, encodeHeaders(_, true))\n      .WillOnce(Invoke([&](const Http::RequestHeaderMap& headers, bool) -> Http::Status {\n        EXPECT_EQ(headers.getHostValue(), host);\n        EXPECT_EQ(headers.getPathValue(), path);\n        return Http::okStatus();\n      }));\n  health_checker_->start();\n\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.max_interval\", _));\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.min_interval\", _))\n      .WillOnce(Return(45000));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_,\n              enableTimer(std::chrono::milliseconds(45000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  absl::optional<std::string> health_checked_cluster(\"locations-production-iad\");\n  respond(0, \"200\", false, false, true, false, health_checked_cluster);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n}\n\nTEST_F(HttpHealthCheckerImplTest, SuccessServiceCheckWithAdditionalHeaders) {\n  const Http::LowerCaseString header_ok(\"x-envoy-ok\");\n  const Http::LowerCaseString header_cool(\"x-envoy-cool\");\n  const Http::LowerCaseString header_awesome(\"x-envoy-awesome\");\n  const Http::LowerCaseString upstream_metadata(\"x-upstream-metadata\");\n  const Http::LowerCaseString protocol(\"x-protocol\");\n  const Http::LowerCaseString downstream_remote_address(\"x-downstream-remote-address\");\n  const Http::LowerCaseString downstream_remote_address_without_port(\n      \"x-downstream-remote-address-without-port\");\n  const Http::LowerCaseString downstream_local_address(\"x-downstream-local-address\");\n  const Http::LowerCaseString downstream_local_address_without_port(\n      \"x-downstream-local-address-without-port\");\n  const Http::LowerCaseString start_time(\"x-start-time\");\n\n  const std::string value_ok = \"ok\";\n  const std::string value_cool = \"cool\";\n  const std::string value_awesome = \"awesome\";\n\n  const std::string value_user_agent = \"CoolEnvoy/HC\";\n  const std::string value_upstream_metadata = \"value\";\n  const std::string value_protocol = \"HTTP/1.1\";\n  const std::string value_downstream_remote_address = \"127.0.0.1:0\";\n  const std::string value_downstream_remote_address_without_port = \"127.0.0.1\";\n  const std::string value_downstream_local_address = \"127.0.0.1:0\";\n  const std::string value_downstream_local_address_without_port = \"127.0.0.1\";\n\n  setupServiceValidationWithAdditionalHeaders();\n  // Requires non-empty `service_name` in config.\n  EXPECT_CALL(runtime_.snapshot_, featureEnabled(\"health_check.verify_cluster\", 100))\n      .WillOnce(Return(true));\n\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n  auto metadata = TestUtility::parseYaml<envoy::config::core::v3::Metadata>(\n      R\"EOF(\n        filter_metadata:\n          namespace:\n            key: value\n      )EOF\");\n\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", metadata, simTime())};\n  cluster_->info_->stats().upstream_cx_total_.inc();\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  EXPECT_CALL(test_sessions_[0]->request_encoder_, encodeHeaders(_, true))\n      .WillRepeatedly(Invoke([&](const Http::RequestHeaderMap& headers, bool) -> Http::Status {\n        EXPECT_EQ(headers.get(header_ok)[0]->value().getStringView(), value_ok);\n        EXPECT_EQ(headers.get(header_cool)[0]->value().getStringView(), value_cool);\n        EXPECT_EQ(headers.get(header_awesome)[0]->value().getStringView(), value_awesome);\n\n        EXPECT_EQ(headers.getUserAgentValue(), value_user_agent);\n        EXPECT_EQ(headers.get(upstream_metadata)[0]->value().getStringView(),\n                  value_upstream_metadata);\n\n        EXPECT_EQ(headers.get(protocol)[0]->value().getStringView(), value_protocol);\n        EXPECT_EQ(headers.get(downstream_remote_address)[0]->value().getStringView(),\n                  value_downstream_remote_address);\n        EXPECT_EQ(headers.get(downstream_remote_address_without_port)[0]->value().getStringView(),\n                  value_downstream_remote_address_without_port);\n        EXPECT_EQ(headers.get(downstream_local_address)[0]->value().getStringView(),\n                  value_downstream_local_address);\n        EXPECT_EQ(headers.get(downstream_local_address_without_port)[0]->value().getStringView(),\n                  value_downstream_local_address_without_port);\n\n        Envoy::DateFormatter date_formatter(\"%s.%9f\");\n        std::string current_start_time =\n            date_formatter.fromTime(dispatcher_.timeSource().systemTime());\n        EXPECT_EQ(headers.get(start_time)[0]->value().getStringView(), current_start_time);\n        return Http::okStatus();\n      }));\n  health_checker_->start();\n\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.max_interval\", _));\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.min_interval\", _))\n      .WillOnce(Return(45000));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_,\n              enableTimer(std::chrono::milliseconds(45000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  absl::optional<std::string> health_checked_cluster(\"locations-production-iad\");\n  respond(0, \"200\", false, false, true, false, health_checked_cluster);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  expectStreamCreate(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n}\n\nTEST_F(HttpHealthCheckerImplTest, SuccessServiceCheckWithoutUserAgent) {\n  setupServiceValidationWithoutUserAgent();\n  // Requires non-empty `service_name` in config.\n  EXPECT_CALL(runtime_.snapshot_, featureEnabled(\"health_check.verify_cluster\", 100))\n      .WillOnce(Return(true));\n\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n  auto metadata = TestUtility::parseYaml<envoy::config::core::v3::Metadata>(\n      R\"EOF(\n        filter_metadata:\n          namespace:\n            key: value\n      )EOF\");\n\n  std::string current_start_time;\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", metadata, simTime())};\n  cluster_->info_->stats().upstream_cx_total_.inc();\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  EXPECT_CALL(test_sessions_[0]->request_encoder_, encodeHeaders(_, true))\n      .WillRepeatedly(Invoke([&](const Http::RequestHeaderMap& headers, bool) -> Http::Status {\n        EXPECT_EQ(headers.UserAgent(), nullptr);\n        return Http::okStatus();\n      }));\n  health_checker_->start();\n\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.max_interval\", _));\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.min_interval\", _))\n      .WillOnce(Return(45000));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_,\n              enableTimer(std::chrono::milliseconds(45000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  absl::optional<std::string> health_checked_cluster(\"locations-production-iad\");\n  respond(0, \"200\", false, false, true, false, health_checked_cluster);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  expectStreamCreate(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n}\n\nTEST_F(HttpHealthCheckerImplTest, ServiceDoesNotMatchFail) {\n  setupServiceValidationHC();\n  EXPECT_CALL(event_logger_, logUnhealthy(_, _, _, true));\n  EXPECT_CALL(runtime_.snapshot_, featureEnabled(\"health_check.verify_cluster\", 100))\n      .WillOnce(Return(true));\n\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Changed));\n  EXPECT_CALL(event_logger_, logEjectUnhealthy(_, _, _));\n\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  cluster_->info_->stats().upstream_cx_total_.inc();\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.max_interval\", _));\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.min_interval\", _))\n      .WillOnce(Return(45000));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_,\n              enableTimer(std::chrono::milliseconds(45000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  absl::optional<std::string> health_checked_cluster(\"api-production-iad\");\n  respond(0, \"200\", false, false, true, false, health_checked_cluster);\n  EXPECT_TRUE(cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthFlagGet(\n      Host::HealthFlag::FAILED_ACTIVE_HC));\n  EXPECT_EQ(Host::Health::Unhealthy,\n            cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n}\n\nTEST_F(HttpHealthCheckerImplTest, ServicePatternDoesNotMatchFail) {\n  setupServiceRegexPatternValidationHC();\n  EXPECT_CALL(event_logger_, logUnhealthy(_, _, _, true));\n  EXPECT_CALL(runtime_.snapshot_, featureEnabled(\"health_check.verify_cluster\", 100))\n      .WillOnce(Return(true));\n\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Changed));\n  EXPECT_CALL(event_logger_, logEjectUnhealthy(_, _, _));\n\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  cluster_->info_->stats().upstream_cx_total_.inc();\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.max_interval\", _));\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.min_interval\", _))\n      .WillOnce(Return(45000));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_,\n              enableTimer(std::chrono::milliseconds(45000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  absl::optional<std::string> health_checked_cluster(\"api-production-iad\");\n  respond(0, \"200\", false, false, true, false, health_checked_cluster);\n  EXPECT_TRUE(cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthFlagGet(\n      Host::HealthFlag::FAILED_ACTIVE_HC));\n  EXPECT_EQ(Host::Health::Unhealthy,\n            cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n}\n\nTEST_F(HttpHealthCheckerImplTest, ServiceNotPresentInResponseFail) {\n  setupServiceValidationHC();\n  EXPECT_CALL(event_logger_, logUnhealthy(_, _, _, true));\n  EXPECT_CALL(runtime_.snapshot_, featureEnabled(\"health_check.verify_cluster\", 100))\n      .WillOnce(Return(true));\n\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Changed));\n  EXPECT_CALL(event_logger_, logEjectUnhealthy(_, _, _));\n\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  cluster_->info_->stats().upstream_cx_total_.inc();\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.max_interval\", _));\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.min_interval\", _))\n      .WillOnce(Return(45000));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_,\n              enableTimer(std::chrono::milliseconds(45000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  respond(0, \"200\", false, false, true, false);\n  EXPECT_TRUE(cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthFlagGet(\n      Host::HealthFlag::FAILED_ACTIVE_HC));\n  EXPECT_EQ(Host::Health::Unhealthy,\n            cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n}\n\nTEST_F(HttpHealthCheckerImplTest, ServiceCheckRuntimeOff) {\n  setupServiceValidationHC();\n  EXPECT_CALL(runtime_.snapshot_, featureEnabled(\"health_check.verify_cluster\", 100))\n      .WillOnce(Return(false));\n\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  cluster_->info_->stats().upstream_cx_total_.inc();\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.max_interval\", _));\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.min_interval\", _))\n      .WillOnce(Return(45000));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_,\n              enableTimer(std::chrono::milliseconds(45000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  absl::optional<std::string> health_checked_cluster(\"api-production-iad\");\n  respond(0, \"200\", false, false, true, false, health_checked_cluster);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n}\n\nTEST_F(HttpHealthCheckerImplTest, ServiceCheckRuntimeOffWithStringPattern) {\n  setupServicePrefixPatternValidationHC();\n  EXPECT_CALL(runtime_.snapshot_, featureEnabled(\"health_check.verify_cluster\", 100))\n      .WillOnce(Return(false));\n\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  cluster_->info_->stats().upstream_cx_total_.inc();\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.max_interval\", _));\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.min_interval\", _))\n      .WillOnce(Return(45000));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_,\n              enableTimer(std::chrono::milliseconds(45000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  absl::optional<std::string> health_checked_cluster(\"api-production-iad\");\n  respond(0, \"200\", false, false, true, false, health_checked_cluster);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n}\n\nTEST_F(HttpHealthCheckerImplTest, SuccessStartFailedFailFirstServiceCheck) {\n  setupNoServiceValidationHC();\n  EXPECT_CALL(runtime_.snapshot_, featureEnabled(\"health_check.verify_cluster\", 100))\n      .WillRepeatedly(Return(true));\n  absl::optional<std::string> health_checked_cluster(\"locations-production-iad\");\n  expectSuccessStartFailedFailFirst(health_checked_cluster);\n}\n\nTEST_F(HttpHealthCheckerImplTest, SuccessNoTraffic) {\n  setupNoServiceValidationHC();\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(std::chrono::milliseconds(5000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  respond(0, \"200\", false, false, true, true);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n}\n\n// First start with an unhealthy cluster that moves to\n// no_traffic_healthy_interval.\nTEST_F(HttpHealthCheckerImplTest, UnhealthyTransitionNoTrafficHealthy) {\n  setupNoTrafficHealthyValidationHC();\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthFlagSet(\n      Host::HealthFlag::FAILED_ACTIVE_HC);\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n\n  // Successful health check should now trigger the no_traffic_healthy_interval 10000ms.\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Changed));\n  EXPECT_CALL(event_logger_, logAddHealthy(_, _, _));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_,\n              enableTimer(std::chrono::milliseconds(10000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  respond(0, \"200\", false, false, false, false);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n}\n\nTEST_F(HttpHealthCheckerImplTest, SuccessStartFailedSuccessFirst) {\n  setupNoServiceValidationHC();\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthFlagSet(\n      Host::HealthFlag::FAILED_ACTIVE_HC);\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n\n  // Test fast success immediately moves us to healthy.\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Changed));\n  EXPECT_CALL(event_logger_, logAddHealthy(_, _, true));\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.max_interval\", _)).WillOnce(Return(500));\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.min_interval\", _));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(std::chrono::milliseconds(500), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  respond(0, \"200\", false);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n}\n\nTEST_F(HttpHealthCheckerImplTest, SuccessStartFailedFailFirst) {\n  setupNoServiceValidationHC();\n  expectSuccessStartFailedFailFirst();\n}\n\nTEST_F(HttpHealthCheckerImplTest, SuccessStartFailedFailFirstLogError) {\n  setupNoServiceValidationHCAlwaysLogFailure();\n  expectSuccessStartFailedFailFirst();\n}\n\n// Verify that removal during a failure callback works.\nTEST_F(HttpHealthCheckerImplTest, HttpFailRemoveHostInCallbackNoClose) {\n  setupNoServiceValidationHC();\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Changed))\n      .WillOnce(Invoke([&](HostSharedPtr host, HealthTransition) {\n        cluster_->prioritySet().getMockHostSet(0)->hosts_ = {};\n        cluster_->prioritySet().runUpdateCallbacks(0, {}, {host});\n      }));\n  EXPECT_CALL(event_logger_, logEjectUnhealthy(_, _, _));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(_, _)).Times(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer()).Times(0);\n  EXPECT_CALL(event_logger_, logUnhealthy(_, _, _, true));\n  respond(0, \"503\", false);\n}\n\n// Verify that removal during a failure callback works with connection close.\nTEST_F(HttpHealthCheckerImplTest, HttpFailRemoveHostInCallbackClose) {\n  setupNoServiceValidationHC();\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Changed))\n      .WillOnce(Invoke([&](HostSharedPtr host, HealthTransition) {\n        cluster_->prioritySet().getMockHostSet(0)->hosts_ = {};\n        cluster_->prioritySet().runUpdateCallbacks(0, {}, {host});\n      }));\n  EXPECT_CALL(event_logger_, logEjectUnhealthy(_, _, _));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(_, _)).Times(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer()).Times(0);\n  EXPECT_CALL(event_logger_, logUnhealthy(_, _, _, true));\n  respond(0, \"503\", true);\n}\n\nTEST_F(HttpHealthCheckerImplTest, HttpFail) {\n  setupNoServiceValidationHC();\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Changed));\n  EXPECT_CALL(event_logger_, logEjectUnhealthy(_, _, _));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(_, _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  EXPECT_CALL(event_logger_, logUnhealthy(_, _, _, true));\n  respond(0, \"503\", false);\n  EXPECT_TRUE(cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthFlagGet(\n      Host::HealthFlag::FAILED_ACTIVE_HC));\n  EXPECT_FALSE(cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthFlagGet(\n      Host::HealthFlag::EXCLUDED_VIA_IMMEDIATE_HC_FAIL));\n  EXPECT_EQ(Host::Health::Unhealthy,\n            cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  expectStreamCreate(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::ChangePending));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(_, _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  respond(0, \"200\", false);\n  EXPECT_TRUE(cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthFlagGet(\n      Host::HealthFlag::FAILED_ACTIVE_HC));\n  EXPECT_EQ(Host::Health::Unhealthy,\n            cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  expectStreamCreate(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Changed));\n  EXPECT_CALL(event_logger_, logAddHealthy(_, _, false));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(_, _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  respond(0, \"200\", false);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n}\n\nTEST_F(HttpHealthCheckerImplTest, ImmediateFailure) {\n  setupNoServiceValidationHC();\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Changed));\n  EXPECT_CALL(event_logger_, logEjectUnhealthy(_, _, _));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(_, _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  EXPECT_CALL(event_logger_, logUnhealthy(_, _, _, true));\n  respond(0, \"503\", false, false, true, false, absl::nullopt, false, true);\n  EXPECT_TRUE(cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthFlagGet(\n      Host::HealthFlag::FAILED_ACTIVE_HC));\n  EXPECT_TRUE(cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthFlagGet(\n      Host::HealthFlag::EXCLUDED_VIA_IMMEDIATE_HC_FAIL));\n  EXPECT_EQ(Host::Health::Unhealthy,\n            cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n}\n\nTEST_F(HttpHealthCheckerImplTest, HttpFailLogError) {\n  setupNoServiceValidationHCAlwaysLogFailure();\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Changed));\n  EXPECT_CALL(event_logger_, logEjectUnhealthy(_, _, _));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(_, _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  EXPECT_CALL(event_logger_, logUnhealthy(_, _, _, true));\n  respond(0, \"503\", false);\n  EXPECT_TRUE(cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthFlagGet(\n      Host::HealthFlag::FAILED_ACTIVE_HC));\n  EXPECT_EQ(Host::Health::Unhealthy,\n            cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  expectStreamCreate(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  // logUnhealthy is called with first_check == false\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(_, _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  EXPECT_CALL(event_logger_, logUnhealthy(_, _, _, false));\n  respond(0, \"503\", false);\n  EXPECT_TRUE(cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthFlagGet(\n      Host::HealthFlag::FAILED_ACTIVE_HC));\n  EXPECT_EQ(Host::Health::Unhealthy,\n            cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  expectStreamCreate(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::ChangePending));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(_, _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  respond(0, \"200\", false);\n  EXPECT_TRUE(cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthFlagGet(\n      Host::HealthFlag::FAILED_ACTIVE_HC));\n  EXPECT_EQ(Host::Health::Unhealthy,\n            cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  expectStreamCreate(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Changed));\n  EXPECT_CALL(event_logger_, logAddHealthy(_, _, false));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(_, _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  respond(0, \"200\", false);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n}\n\nTEST_F(HttpHealthCheckerImplTest, Disconnect) {\n  setupNoServiceValidationHC();\n  EXPECT_CALL(event_logger_, logUnhealthy(_, _, _, true));\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::ChangePending));\n\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(_, _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  test_sessions_[0]->client_connection_->raiseEvent(Network::ConnectionEvent::RemoteClose);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n\n  expectClientCreate(0);\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  EXPECT_CALL(*this, onHostStatus(cluster_->prioritySet().getMockHostSet(0)->hosts_[0],\n                                  HealthTransition::Changed));\n  EXPECT_CALL(event_logger_, logEjectUnhealthy(_, _, _));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(_, _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  test_sessions_[0]->client_connection_->raiseEvent(Network::ConnectionEvent::RemoteClose);\n  EXPECT_TRUE(cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthFlagGet(\n      Host::HealthFlag::FAILED_ACTIVE_HC));\n  EXPECT_EQ(Host::Health::Unhealthy,\n            cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n}\n\nTEST_F(HttpHealthCheckerImplTest, Timeout) {\n  setupNoServiceValidationHCOneUnhealthy();\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Changed));\n  EXPECT_CALL(*test_sessions_[0]->client_connection_, close(_));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(_, _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  EXPECT_CALL(event_logger_, logUnhealthy(_, _, _, true));\n  EXPECT_CALL(event_logger_, logEjectUnhealthy(_, _, _));\n  test_sessions_[0]->timeout_timer_->invokeCallback();\n  EXPECT_EQ(Host::Health::Unhealthy,\n            cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n  EXPECT_TRUE(cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthFlagGet(\n      Host::HealthFlag::ACTIVE_HC_TIMEOUT));\n}\n\n// Make sure that a timeout during a partial response works correctly.\nTEST_F(HttpHealthCheckerImplTest, TimeoutThenSuccess) {\n  setupNoServiceValidationHC();\n\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n\n  // Do a response that is not complete but includes headers.\n  std::unique_ptr<Http::TestResponseHeaderMapImpl> response_headers(\n      new Http::TestResponseHeaderMapImpl{{\":status\", \"200\"}});\n  test_sessions_[0]->stream_response_callbacks_->decodeHeaders(std::move(response_headers), false);\n\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::ChangePending));\n  EXPECT_CALL(event_logger_, logUnhealthy(_, _, _, true));\n  EXPECT_CALL(*test_sessions_[0]->client_connection_, close(_));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(_, _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  test_sessions_[0]->timeout_timer_->invokeCallback();\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n\n  expectClientCreate(0);\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(_, _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  respond(0, \"200\", false, false, true);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n}\n\nTEST_F(HttpHealthCheckerImplTest, TimeoutThenRemoteClose) {\n  setupNoServiceValidationHC();\n  EXPECT_CALL(event_logger_, logUnhealthy(_, _, _, true));\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::ChangePending));\n  EXPECT_CALL(*test_sessions_[0]->client_connection_, close(_));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(_, _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  test_sessions_[0]->timeout_timer_->invokeCallback();\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n\n  expectClientCreate(0);\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Changed));\n  EXPECT_CALL(event_logger_, logEjectUnhealthy(_, _, _));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(_, _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  test_sessions_[0]->client_connection_->raiseEvent(Network::ConnectionEvent::RemoteClose);\n  EXPECT_TRUE(cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthFlagGet(\n      Host::HealthFlag::FAILED_ACTIVE_HC));\n  EXPECT_EQ(Host::Health::Unhealthy,\n            cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n  EXPECT_FALSE(cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthFlagGet(\n      Host::HealthFlag::ACTIVE_HC_TIMEOUT));\n}\n\nTEST_F(HttpHealthCheckerImplTest, TimeoutAfterDisconnect) {\n  setupNoServiceValidationHC();\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(event_logger_, logUnhealthy(_, _, _, true));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _)).Times(2);\n  health_checker_->start();\n\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::ChangePending));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(_, _)).Times(2);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  for (auto& session : test_sessions_) {\n    session->client_connection_->close(Network::ConnectionCloseType::NoFlush);\n  }\n\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Changed));\n  EXPECT_CALL(event_logger_, logEjectUnhealthy(_, _, _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n\n  test_sessions_[0]->timeout_timer_->enableTimer(std::chrono::seconds(10), nullptr);\n  test_sessions_[0]->timeout_timer_->invokeCallback();\n  EXPECT_EQ(Host::Health::Unhealthy,\n            cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n}\n\nTEST_F(HttpHealthCheckerImplTest, DynamicAddAndRemove) {\n  setupNoServiceValidationHC();\n  health_checker_->start();\n\n  expectSessionCreate();\n  expectStreamCreate(0);\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  cluster_->prioritySet().getMockHostSet(0)->runCallbacks(\n      {cluster_->prioritySet().getMockHostSet(0)->hosts_.back()}, {});\n\n  HostVector removed{cluster_->prioritySet().getMockHostSet(0)->hosts_.back()};\n  cluster_->prioritySet().getMockHostSet(0)->hosts_.clear();\n  EXPECT_CALL(*test_sessions_[0]->client_connection_, close(_));\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n  cluster_->prioritySet().getMockHostSet(0)->runCallbacks({}, removed);\n}\n\nTEST_F(HttpHealthCheckerImplTest, ConnectionClose) {\n  setupNoServiceValidationHC();\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(_, _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  respond(0, \"200\", true);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n\n  expectClientCreate(0);\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  test_sessions_[0]->interval_timer_->invokeCallback();\n}\n\nTEST_F(HttpHealthCheckerImplTest, ProxyConnectionClose) {\n  setupNoServiceValidationHC();\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(_, _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  respond(0, \"200\", false, true);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n\n  expectClientCreate(0);\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  test_sessions_[0]->interval_timer_->invokeCallback();\n}\n\nTEST_F(HttpHealthCheckerImplTest, HealthCheckIntervals) {\n  setupHealthCheckIntervalOverridesHC();\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://128.0.0.1:80\", simTime())};\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n\n  // First check should respect no_traffic_interval setting.\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(std::chrono::milliseconds(5000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  respond(0, \"200\", false);\n  cluster_->info_->stats().upstream_cx_total_.inc();\n\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  // Needed after a response is sent.\n  expectStreamCreate(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  // Follow up successful checks should respect interval setting.\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(std::chrono::milliseconds(1000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  respond(0, \"200\", false);\n\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  // Needed after a response is sent.\n  expectStreamCreate(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  // Follow up successful checks should respect interval setting.\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(std::chrono::milliseconds(1000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  respond(0, \"200\", false);\n\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  // Needed after a response is sent.\n  expectStreamCreate(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  // A logical failure is not considered a network failure, therefore the unhealthy threshold is\n  // ignored and health state changes immediately. Since the threshold is ignored, next health\n  // check respects \"unhealthy_interval\".\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Changed));\n  EXPECT_CALL(event_logger_, logEjectUnhealthy(_, _, _));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(std::chrono::milliseconds(2000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  respond(0, \"503\", false);\n\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  // Needed after a response is sent.\n  expectStreamCreate(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  // Subsequent failing checks should respect unhealthy_interval.\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(std::chrono::milliseconds(2000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  respond(0, \"503\", false);\n\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  // Needed after a response is sent.\n  expectStreamCreate(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  // Subsequent failing checks should respect unhealthy_interval.\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(std::chrono::milliseconds(2000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  respond(0, \"503\", false);\n\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  // Needed after a response is sent.\n  expectStreamCreate(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  // When transitioning to a successful state, checks should respect healthy_edge_interval. Health\n  // state should be delayed pending healthy threshold.\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::ChangePending));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(std::chrono::milliseconds(4000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  respond(0, \"200\", false);\n\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  // Needed after a response is sent.\n  expectStreamCreate(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::ChangePending));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(std::chrono::milliseconds(4000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  respond(0, \"200\", false);\n\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  // Needed after a response is sent.\n  expectStreamCreate(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  // After the healthy threshold is reached, health state should change while checks should respect\n  // the default interval.\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Changed));\n  EXPECT_CALL(event_logger_, logAddHealthy(_, _, false));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(std::chrono::milliseconds(1000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  respond(0, \"200\", false);\n\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  // Needed after a response is sent.\n  expectStreamCreate(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  // Subsequent checks shouldn't change the state.\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(std::chrono::milliseconds(1000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  respond(0, \"200\", false);\n\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  // Needed after a response is sent.\n  expectStreamCreate(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  // First failed check after a run of successful ones should respect unhealthy_edge_interval. A\n  // timeout, being a network type failure, should respect unhealthy threshold before changing the\n  // health state.\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::ChangePending));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(std::chrono::milliseconds(3000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  test_sessions_[0]->timeout_timer_->invokeCallback();\n  EXPECT_FALSE(cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthFlagGet(\n      Host::HealthFlag::ACTIVE_HC_TIMEOUT));\n\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  // Needed after a network timeout.\n  expectClientCreate(0);\n  // Needed after a response is sent.\n  expectStreamCreate(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::ChangePending));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(std::chrono::milliseconds(3000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  test_sessions_[0]->timeout_timer_->invokeCallback();\n  EXPECT_FALSE(cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthFlagGet(\n      Host::HealthFlag::ACTIVE_HC_TIMEOUT));\n\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  // Needed after a network timeout.\n  expectClientCreate(0);\n  // Needed after a response is sent.\n  expectStreamCreate(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  // Subsequent failing checks should respect unhealthy_interval. As the unhealthy threshold is\n  // reached, health state should also change.\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Changed));\n  EXPECT_CALL(event_logger_, logEjectUnhealthy(_, _, _));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(std::chrono::milliseconds(2000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  test_sessions_[0]->timeout_timer_->invokeCallback();\n  EXPECT_TRUE(cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthFlagGet(\n      Host::HealthFlag::ACTIVE_HC_TIMEOUT));\n\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  // Needed after a network timeout.\n  expectClientCreate(0);\n  // Needed after a response is sent.\n  expectStreamCreate(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  // Remaining failing checks shouldn't change the state.\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(std::chrono::milliseconds(2000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  test_sessions_[0]->timeout_timer_->invokeCallback();\n\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  // Needed after a network timeout.\n  expectClientCreate(0);\n  // Needed after a response is sent.\n  expectStreamCreate(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  // When transitioning to a successful state, checks should respect healthy_edge_interval.\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::ChangePending));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(std::chrono::milliseconds(4000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  respond(0, \"200\", false);\n  EXPECT_TRUE(cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthFlagGet(\n      Host::HealthFlag::ACTIVE_HC_TIMEOUT));\n\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  // Needed after a response is sent.\n  expectStreamCreate(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::ChangePending));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(std::chrono::milliseconds(4000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  respond(0, \"200\", false);\n  EXPECT_TRUE(cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthFlagGet(\n      Host::HealthFlag::ACTIVE_HC_TIMEOUT));\n\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  // Needed after a response is sent.\n  expectStreamCreate(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  // After the healthy threshold is reached, health state should change while checks should respect\n  // the default interval.\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Changed));\n  EXPECT_CALL(event_logger_, logAddHealthy(_, _, false));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(std::chrono::milliseconds(1000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  respond(0, \"200\", false);\n  EXPECT_FALSE(cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthFlagGet(\n      Host::HealthFlag::ACTIVE_HC_TIMEOUT));\n\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  // Needed after a response is sent.\n  expectStreamCreate(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  // Subsequent checks shouldn't change the state.\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(std::chrono::milliseconds(1000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  respond(0, \"200\", false);\n}\n\nTEST_F(HttpHealthCheckerImplTest, RemoteCloseBetweenChecks) {\n  setupNoServiceValidationHC();\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged)).Times(2);\n\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(_, _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  respond(0, \"200\", false);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n\n  test_sessions_[0]->client_connection_->raiseEvent(Network::ConnectionEvent::RemoteClose);\n\n  expectClientCreate(0);\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(_, _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  respond(0, \"200\", false);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n}\n\n// Test that we close connections on a healthy check when reuse_connection is false.\nTEST_F(HttpHealthCheckerImplTest, DontReuseConnectionBetweenChecks) {\n  setupNoServiceValidationNoReuseConnectionHC();\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged)).Times(2);\n\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(_, _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  respond(0, \"200\", false);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n\n  // A new client is created because we close the connection ourselves.\n  // See HttpHealthCheckerImplTest.RemoteCloseBetweenChecks for how this works when the remote end\n  // closes the connection.\n  expectClientCreate(0);\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(_, _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  respond(0, \"200\", false);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n}\n\nTEST_F(HttpHealthCheckerImplTest, StreamReachesWatermarkDuringCheck) {\n  setupNoServiceValidationHC();\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(_, _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n\n  test_sessions_[0]->request_encoder_.stream_.runHighWatermarkCallbacks();\n  test_sessions_[0]->request_encoder_.stream_.runLowWatermarkCallbacks();\n\n  respond(0, \"200\", true);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n}\n\nTEST_F(HttpHealthCheckerImplTest, ConnectionReachesWatermarkDuringCheck) {\n  setupNoServiceValidationHC();\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(_, _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n\n  test_sessions_[0]->client_connection_->runHighWatermarkCallbacks();\n  test_sessions_[0]->client_connection_->runLowWatermarkCallbacks();\n\n  respond(0, \"200\", true);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n}\n\nTEST_F(HttpHealthCheckerImplTest, SuccessServiceCheckWithAltPort) {\n  const std::string host = \"fake_cluster\";\n  const std::string path = \"/healthcheck\";\n  setupServiceValidationHC();\n  EXPECT_CALL(runtime_.snapshot_, featureEnabled(\"health_check.verify_cluster\", 100))\n      .WillOnce(Return(true));\n\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n\n  // Prepares a host with its designated health check port.\n  const HostWithHealthCheckMap hosts{{\"127.0.0.1:80\", makeHealthCheckConfig(8000)}};\n  appendTestHosts(cluster_, hosts);\n  cluster_->info_->stats().upstream_cx_total_.inc();\n  expectSessionCreate(hosts);\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  EXPECT_CALL(test_sessions_[0]->request_encoder_, encodeHeaders(_, true))\n      .WillOnce(Invoke([&](const Http::RequestHeaderMap& headers, bool) -> Http::Status {\n        EXPECT_EQ(headers.getHostValue(), host);\n        EXPECT_EQ(headers.getPathValue(), path);\n        return Http::okStatus();\n      }));\n  health_checker_->start();\n\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.max_interval\", _));\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.min_interval\", _))\n      .WillOnce(Return(45000));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_,\n              enableTimer(std::chrono::milliseconds(45000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  absl::optional<std::string> health_checked_cluster(\"locations-production-iad\");\n  respond(0, \"200\", false, false, true, false, health_checked_cluster);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n}\n\n// Test host check success with multiple hosts by checking each host defined health check port.\nTEST_F(HttpHealthCheckerImplTest, SuccessWithMultipleHostsAndAltPort) {\n  setupNoServiceValidationHC();\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged)).Times(2);\n\n  // Prepares a set of hosts along with its designated health check ports.\n  const HostWithHealthCheckMap hosts = {{\"127.0.0.1:80\", makeHealthCheckConfig(8000)},\n                                        {\"127.0.0.1:81\", makeHealthCheckConfig(8001)}};\n  appendTestHosts(cluster_, hosts);\n  cluster_->info_->stats().upstream_cx_total_.inc();\n  cluster_->info_->stats().upstream_cx_total_.inc();\n  expectSessionCreate(hosts);\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  expectSessionCreate(hosts);\n  expectStreamCreate(1);\n  EXPECT_CALL(*test_sessions_[1]->timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.max_interval\", _)).Times(2);\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.min_interval\", _))\n      .Times(2)\n      .WillRepeatedly(Return(45000));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_,\n              enableTimer(std::chrono::milliseconds(45000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  EXPECT_CALL(*test_sessions_[1]->interval_timer_,\n              enableTimer(std::chrono::milliseconds(45000), _));\n  EXPECT_CALL(*test_sessions_[1]->timeout_timer_, disableTimer());\n  respond(0, \"200\", false, false, true);\n  respond(1, \"200\", false, false, true);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[1]->health());\n}\n\nTEST_F(HttpHealthCheckerImplTest, Http2ClusterUseHttp2CodecClient) {\n  setupNoServiceValidationHCWithHttp2();\n  EXPECT_EQ(Http::CodecType::HTTP2, health_checker_->codecClientType());\n}\n\nMATCHER_P(MetadataEq, expected, \"\") {\n  const envoy::config::core::v3::Metadata* metadata = arg;\n  if (!metadata) {\n    return false;\n  }\n  EXPECT_TRUE(Envoy::Protobuf::util::MessageDifferencer::Equals(*metadata, expected));\n  return true;\n}\n\nTEST_F(HttpHealthCheckerImplTest, TransportSocketMatchCriteria) {\n  const std::string host = \"fake_cluster\";\n  const std::string path = \"/healthcheck\";\n  const std::string yaml = R\"EOF(\n    timeout: 1s\n    interval: 1s\n    no_traffic_interval: 1s\n    interval_jitter_percent: 40\n    unhealthy_threshold: 2\n    healthy_threshold: 2\n    http_health_check:\n      service_name_matcher:\n        prefix: locations\n      path: /healthcheck\n    transport_socket_match_criteria:\n      key: value\n    )EOF\";\n\n  auto default_socket_factory = std::make_unique<Network::MockTransportSocketFactory>();\n  // We expect that this default_socket_factory will NOT be used to create a transport socket for\n  // the health check connection.\n  EXPECT_CALL(*default_socket_factory, createTransportSocket(_)).Times(0);\n  EXPECT_CALL(*default_socket_factory, implementsSecureTransport()).WillRepeatedly(Return(true));\n  auto transport_socket_match =\n      std::make_unique<Upstream::MockTransportSocketMatcher>(std::move(default_socket_factory));\n\n  auto metadata = TestUtility::parseYaml<envoy::config::core::v3::Metadata>(\n      R\"EOF(\n    filter_metadata:\n      envoy.transport_socket_match:\n        key: value\n  )EOF\");\n\n  Stats::IsolatedStoreImpl stats_store;\n  auto health_transport_socket_stats = TransportSocketMatchStats{\n      ALL_TRANSPORT_SOCKET_MATCH_STATS(POOL_COUNTER_PREFIX(stats_store, \"test\"))};\n  auto health_check_only_socket_factory = std::make_unique<Network::MockTransportSocketFactory>();\n\n  // We expect resolve() to be called twice, once for endpoint socket matching (with no metadata in\n  // this test) and once for health check socket matching. In the latter we expect metadata that\n  // matches the above object.\n  EXPECT_CALL(*transport_socket_match, resolve(nullptr));\n  EXPECT_CALL(*transport_socket_match, resolve(MetadataEq(metadata)))\n      .WillOnce(Return(TransportSocketMatcher::MatchData(\n          *health_check_only_socket_factory, health_transport_socket_stats, \"health_check_only\")));\n  // The health_check_only_socket_factory should be used to create a transport socket for the health\n  // check connection.\n  EXPECT_CALL(*health_check_only_socket_factory, createTransportSocket(_));\n\n  cluster_->info_->transport_socket_matcher_ = std::move(transport_socket_match);\n\n  allocHealthChecker(yaml);\n\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  cluster_->info_->stats().upstream_cx_total_.inc();\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n  EXPECT_EQ(health_transport_socket_stats.total_match_count_.value(), 1);\n}\n\nTEST_F(HttpHealthCheckerImplTest, NoTransportSocketMatchCriteria) {\n  const std::string host = \"fake_cluster\";\n  const std::string path = \"/healthcheck\";\n  const std::string yaml = R\"EOF(\n    timeout: 1s\n    interval: 1s\n    no_traffic_interval: 1s\n    interval_jitter_percent: 40\n    unhealthy_threshold: 2\n    healthy_threshold: 2\n    http_health_check:\n      service_name_matcher:\n        prefix: locations\n      path: /healthcheck\n    )EOF\";\n\n  auto default_socket_factory = std::make_unique<Network::MockTransportSocketFactory>();\n  // The default_socket_factory should be used to create a transport socket for the health check\n  // connection.\n  EXPECT_CALL(*default_socket_factory, createTransportSocket(_));\n  EXPECT_CALL(*default_socket_factory, implementsSecureTransport()).WillRepeatedly(Return(true));\n  auto transport_socket_match =\n      std::make_unique<Upstream::MockTransportSocketMatcher>(std::move(default_socket_factory));\n  // We expect resolve() to be called exactly once for endpoint socket matching. We should not\n  // attempt to match again for health checks since there is not match criteria in the config.\n  EXPECT_CALL(*transport_socket_match, resolve(nullptr));\n\n  cluster_->info_->transport_socket_matcher_ = std::move(transport_socket_match);\n\n  allocHealthChecker(yaml);\n\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  cluster_->info_->stats().upstream_cx_total_.inc();\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n}\n\n// Test receiving GOAWAY (error) is interpreted as connection close event.\nTEST_F(HttpHealthCheckerImplTest, GoAwayErrorProbeInProgress) {\n  // FailureType::Network will be issued, it will render host unhealthy only if unhealthy_threshold\n  // is reached.\n  setupNoServiceValidationHCWithHttp2();\n  EXPECT_CALL(runtime_.snapshot_, featureEnabled(\"health_check.verify_cluster\", 100))\n      .WillRepeatedly(Return(false));\n\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  cluster_->info_->stats().upstream_cx_total_.inc();\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n\n  // We start off as healthy, and should continue to be healthy.\n  expectUnchanged(0);\n  respond(0, \"200\", false, false, true, false, {}, false);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  expectStreamCreate(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  // GOAWAY with non-NO_ERROR code will result in a healthcheck failure and the\n  // connection closing. Status is unchanged because unhealthy_threshold is 2.\n  expectChangePending(0);\n\n  test_sessions_[0]->codec_client_->raiseGoAway(Http::GoAwayErrorCode::Other);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  expectClientCreate(0);\n  expectStreamCreate(0);\n\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  // GOAWAY with non-NO_ERROR code will result in a healthcheck failure and the\n  // connection closing. This time it goes unhealthy.\n  expectUnhealthyTransition(0, false);\n\n  test_sessions_[0]->codec_client_->raiseGoAway(Http::GoAwayErrorCode::Other);\n  EXPECT_EQ(Host::Health::Unhealthy,\n            cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n  EXPECT_TRUE(cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthFlagGet(\n      Host::HealthFlag::FAILED_ACTIVE_HC));\n}\n\n// Test receiving GOAWAY (no error) is handled gracefully while a check is in progress.\nTEST_F(HttpHealthCheckerImplTest, GoAwayProbeInProgress) {\n  setupHCHttp2();\n  EXPECT_CALL(runtime_.snapshot_, featureEnabled(\"health_check.verify_cluster\", 100))\n      .WillRepeatedly(Return(false));\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  cluster_->info_->stats().upstream_cx_total_.inc();\n\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n\n  // GOAWAY with NO_ERROR code during check should be handled gracefully.\n  test_sessions_[0]->codec_client_->raiseGoAway(Http::GoAwayErrorCode::NoError);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n\n  expectUnchanged(0);\n  respond(0, \"200\", false, false, true, false, {}, false);\n\n  // GOAWAY should cause a new connection to be created.\n  expectClientCreate(0);\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  // Test host state hasn't changed.\n  expectUnchanged(0);\n  respond(0, \"200\", false, false, true, false, {}, false);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n}\n\n// Test receiving GOAWAY (no error) closes connection after an in progress probe times outs.\nTEST_F(HttpHealthCheckerImplTest, GoAwayProbeInProgressTimeout) {\n  setupHCHttp2();\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  EXPECT_CALL(runtime_.snapshot_, featureEnabled(\"health_check.verify_cluster\", 100))\n      .WillRepeatedly(Return(false));\n\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n\n  test_sessions_[0]->codec_client_->raiseGoAway(Http::GoAwayErrorCode::NoError);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n\n  // Unhealthy threshold is 1 so first timeout causes unhealthy\n  expectUnhealthyTransition(0, true);\n  test_sessions_[0]->timeout_timer_->invokeCallback();\n  EXPECT_EQ(Host::Health::Unhealthy,\n            cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n\n  // GOAWAY should cause a new connection to be created.\n  expectClientCreate(0);\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  // Host should go back to healthy after a successful check.\n  expectHealthyTransition(0);\n  respond(0, \"200\", false, false, true, false, {}, false);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n}\n\n// Test receiving GOAWAY (no error) closes connection after a stream reset.\nTEST_F(HttpHealthCheckerImplTest, GoAwayProbeInProgressStreamReset) {\n  setupHCHttp2();\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  EXPECT_CALL(runtime_.snapshot_, featureEnabled(\"health_check.verify_cluster\", 100))\n      .WillRepeatedly(Return(false));\n\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n\n  test_sessions_[0]->codec_client_->raiseGoAway(Http::GoAwayErrorCode::NoError);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n\n  // Unhealthy threshold is 1 so first timeout causes unhealthy\n  expectUnhealthyTransition(0, true);\n  test_sessions_[0]->request_encoder_.stream_.resetStream(Http::StreamResetReason::RemoteReset);\n  EXPECT_EQ(Host::Health::Unhealthy,\n            cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n\n  // GOAWAY should cause a new connection to be created.\n  expectClientCreate(0);\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  // Host should go back to healthy after a successful check.\n  expectHealthyTransition(0);\n  respond(0, \"200\", false, false, true, false, {}, false);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n}\n\n// Test receiving GOAWAY (no error) and a connection close.\nTEST_F(HttpHealthCheckerImplTest, GoAwayProbeInProgressConnectionClose) {\n  setupHCHttp2();\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  EXPECT_CALL(runtime_.snapshot_, featureEnabled(\"health_check.verify_cluster\", 100))\n      .WillRepeatedly(Return(false));\n\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n\n  test_sessions_[0]->codec_client_->raiseGoAway(Http::GoAwayErrorCode::NoError);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n\n  // Unhealthy threshold is 1 so first timeout causes unhealthy\n  expectUnhealthyTransition(0, true);\n  test_sessions_[0]->client_connection_->raiseEvent(Network::ConnectionEvent::RemoteClose);\n  EXPECT_EQ(Host::Health::Unhealthy,\n            cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n\n  // GOAWAY should cause a new connection to be created.\n  expectClientCreate(0);\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  // Host should go back to healthy after a successful check.\n  expectHealthyTransition(0);\n  respond(0, \"200\", false, false, true, false, {}, false);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n}\n\n// Test receiving GOAWAY between checks affects nothing.\nTEST_F(HttpHealthCheckerImplTest, GoAwayBetweenChecks) {\n  setupHCHttp2();\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  EXPECT_CALL(runtime_.snapshot_, featureEnabled(\"health_check.verify_cluster\", 100))\n      .WillRepeatedly(Return(false));\n\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n\n  expectUnchanged(0);\n  respond(0, \"200\", false, false, true, false, {}, false);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n\n  // GOAWAY should cause a new connection to be created but should not affect health status.\n  test_sessions_[0]->codec_client_->raiseGoAway(Http::GoAwayErrorCode::Other);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n\n  expectClientCreate(0);\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  // Host should stay healthy.\n  expectUnchanged(0);\n  respond(0, \"200\", false, false, true, false, {}, false);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n}\n\nclass TestProdHttpHealthChecker : public ProdHttpHealthCheckerImpl {\npublic:\n  using ProdHttpHealthCheckerImpl::ProdHttpHealthCheckerImpl;\n\n  std::unique_ptr<Http::CodecClient>\n  createCodecClientForTest(std::unique_ptr<Network::ClientConnection>&& connection) {\n    Upstream::Host::CreateConnectionData data;\n    data.connection_ = std::move(connection);\n    data.host_description_ = std::make_shared<NiceMock<Upstream::MockHostDescription>>();\n    return std::unique_ptr<Http::CodecClient>(createCodecClient(data));\n  }\n};\n\nclass ProdHttpHealthCheckerTest : public testing::Test, public HealthCheckerTestBase {\npublic:\n  void allocHealthChecker(const std::string& yaml) {\n    health_checker_ = std::make_shared<TestProdHttpHealthChecker>(\n        *cluster_, parseHealthCheckFromV3Yaml(yaml), dispatcher_, runtime_, random_,\n        HealthCheckEventLoggerPtr(event_logger_storage_.release()));\n  }\n\n  void addCompletionCallback() {\n    health_checker_->addHostCheckCompleteCb(\n        [this](HostSharedPtr host, HealthTransition changed_state) -> void {\n          onHostStatus(host, changed_state);\n        });\n  }\n\n  void setupNoServiceValidationHCWithHttp2() {\n    const std::string yaml = R\"EOF(\n    timeout: 1s\n    interval: 1s\n    no_traffic_interval: 5s\n    interval_jitter: 1s\n    unhealthy_threshold: 2\n    healthy_threshold: 2\n    http_health_check:\n      service_name_matcher:\n        prefix: locations\n      path: /healthcheck\n      codec_client_type: Http2\n    )EOF\";\n\n    allocHealthChecker(yaml);\n    addCompletionCallback();\n  }\n\n  void setupNoServiceValidationHC() {\n    const std::string yaml = R\"EOF(\n    timeout: 1s\n    interval: 1s\n    no_traffic_interval: 5s\n    interval_jitter: 1s\n    unhealthy_threshold: 2\n    healthy_threshold: 2\n    http_health_check:\n      service_name_matcher:\n        prefix: locations\n      path: /healthcheck\n    )EOF\";\n\n    allocHealthChecker(yaml);\n    addCompletionCallback();\n  }\n\n  MOCK_METHOD(void, onHostStatus, (HostSharedPtr host, HealthTransition changed_state));\n  std::unique_ptr<Network::MockClientConnection> connection_ =\n      std::make_unique<NiceMock<Network::MockClientConnection>>();\n  std::shared_ptr<TestProdHttpHealthChecker> health_checker_;\n};\n\nTEST_F(ProdHttpHealthCheckerTest, ProdHttpHealthCheckerH1HealthChecking) {\n  setupNoServiceValidationHC();\n  EXPECT_EQ(Http::CodecType::HTTP1,\n            health_checker_->createCodecClientForTest(std::move(connection_))->type());\n}\n\nTEST_F(HttpHealthCheckerImplTest, Http1CodecClient) {\n  const std::string yaml = R\"EOF(\n    timeout: 1s\n    interval: 1s\n    no_traffic_interval: 5s\n    interval_jitter: 1s\n    unhealthy_threshold: 2\n    healthy_threshold: 2\n    http_health_check:\n      service_name_matcher:\n        prefix: locations\n      path: /healthcheck\n      codec_client_type: Http1\n    )EOF\";\n\n  allocHealthChecker(yaml);\n  addCompletionCallback();\n  EXPECT_EQ(Http::CodecType::HTTP1, health_checker_->codecClientType());\n}\n\nTEST_F(HttpHealthCheckerImplTest, Http2CodecClient) {\n  const std::string yaml = R\"EOF(\n    timeout: 1s\n    interval: 1s\n    no_traffic_interval: 5s\n    interval_jitter: 1s\n    unhealthy_threshold: 2\n    healthy_threshold: 2\n    http_health_check:\n      service_name_matcher:\n        prefix: locations\n      path: /healthcheck\n      codec_client_type: Http2\n    )EOF\";\n\n  allocHealthChecker(yaml);\n  addCompletionCallback();\n  EXPECT_EQ(Http::CodecType::HTTP2, health_checker_->codecClientType());\n}\n\nTEST_F(HttpHealthCheckerImplTest, ServiceNameMatch) {\n  const std::string host = \"fake_cluster\";\n  const std::string path = \"/healthcheck\";\n  setupServiceNameValidationHC(\"locations\");\n  EXPECT_CALL(runtime_.snapshot_, featureEnabled(\"health_check.verify_cluster\", 100))\n      .WillOnce(Return(true));\n\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  cluster_->info_->stats().upstream_cx_total_.inc();\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  EXPECT_CALL(test_sessions_[0]->request_encoder_, encodeHeaders(_, true))\n      .WillOnce(Invoke([&](const Http::RequestHeaderMap& headers, bool) -> Http::Status {\n        EXPECT_EQ(headers.getHostValue(), host);\n        EXPECT_EQ(headers.getPathValue(), path);\n        EXPECT_EQ(headers.getSchemeValue(), Http::Headers::get().SchemeValues.Http);\n        return Http::okStatus();\n      }));\n  health_checker_->start();\n\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.max_interval\", _));\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.min_interval\", _))\n      .WillOnce(Return(45000));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_,\n              enableTimer(std::chrono::milliseconds(45000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  absl::optional<std::string> health_checked_cluster(\"locations-production-iad\");\n  respond(0, \"200\", false, false, true, false, health_checked_cluster);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n}\n\nTEST_F(HttpHealthCheckerImplTest, ServiceNameMismatch) {\n  setupServiceNameValidationHC(\"locations\");\n  EXPECT_CALL(event_logger_, logUnhealthy(_, _, _, true));\n  EXPECT_CALL(runtime_.snapshot_, featureEnabled(\"health_check.verify_cluster\", 100))\n      .WillOnce(Return(true));\n\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Changed));\n  EXPECT_CALL(event_logger_, logEjectUnhealthy(_, _, _));\n\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  cluster_->info_->stats().upstream_cx_total_.inc();\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.max_interval\", _));\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.min_interval\", _))\n      .WillOnce(Return(45000));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_,\n              enableTimer(std::chrono::milliseconds(45000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  absl::optional<std::string> health_checked_cluster(\"api-production-iad\");\n  respond(0, \"200\", false, false, true, false, health_checked_cluster);\n  EXPECT_TRUE(cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthFlagGet(\n      Host::HealthFlag::FAILED_ACTIVE_HC));\n  EXPECT_EQ(Host::Health::Unhealthy,\n            cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n}\n\nTEST_F(ProdHttpHealthCheckerTest, ProdHttpHealthCheckerH2HealthChecking) {\n  setupNoServiceValidationHCWithHttp2();\n  EXPECT_EQ(Http::CodecType::HTTP2,\n            health_checker_->createCodecClientForTest(std::move(connection_))->type());\n}\n\nTEST(HttpStatusChecker, Default) {\n  const std::string yaml = R\"EOF(\n  timeout: 1s\n  interval: 1s\n  unhealthy_threshold: 2\n  healthy_threshold: 2\n  http_health_check:\n    service_name_matcher:\n        prefix: locations\n    path: /healthcheck\n  )EOF\";\n\n  auto conf = parseHealthCheckFromV3Yaml(yaml);\n  HttpHealthCheckerImpl::HttpStatusChecker http_status_checker(\n      conf.http_health_check().expected_statuses(), conf.http_health_check().retriable_statuses(),\n      200);\n\n  EXPECT_TRUE(http_status_checker.inExpectedRanges(200));\n  EXPECT_FALSE(http_status_checker.inExpectedRanges(204));\n  EXPECT_FALSE(http_status_checker.inRetriableRanges(200));\n}\n\nTEST(HttpStatusChecker, SingleExpected100) {\n  const std::string yaml = R\"EOF(\n  timeout: 1s\n  interval: 1s\n  unhealthy_threshold: 2\n  healthy_threshold: 2\n  http_health_check:\n    service_name_matcher:\n        prefix: locations\n    path: /healthcheck\n    expected_statuses:\n      - start: 100\n        end: 101\n  )EOF\";\n\n  auto conf = parseHealthCheckFromV3Yaml(yaml);\n  HttpHealthCheckerImpl::HttpStatusChecker http_status_checker(\n      conf.http_health_check().expected_statuses(), conf.http_health_check().retriable_statuses(),\n      200);\n\n  EXPECT_FALSE(http_status_checker.inExpectedRanges(200));\n\n  EXPECT_FALSE(http_status_checker.inExpectedRanges(99));\n  EXPECT_TRUE(http_status_checker.inExpectedRanges(100));\n  EXPECT_FALSE(http_status_checker.inExpectedRanges(101));\n}\n\nTEST(HttpStatusChecker, SingleRetriable100) {\n  const std::string yaml = R\"EOF(\n  timeout: 1s\n  interval: 1s\n  unhealthy_threshold: 2\n  healthy_threshold: 2\n  http_health_check:\n    service_name_matcher:\n        prefix: locations\n    path: /healthcheck\n    retriable_statuses:\n      - start: 100\n        end: 101\n  )EOF\";\n\n  auto conf = parseHealthCheckFromV3Yaml(yaml);\n  HttpHealthCheckerImpl::HttpStatusChecker http_status_checker(\n      conf.http_health_check().expected_statuses(), conf.http_health_check().retriable_statuses(),\n      200);\n\n  EXPECT_FALSE(http_status_checker.inRetriableRanges(99));\n  EXPECT_TRUE(http_status_checker.inRetriableRanges(100));\n  EXPECT_FALSE(http_status_checker.inRetriableRanges(101));\n}\n\nTEST(HttpStatusChecker, SingleExpected599) {\n  const std::string yaml = R\"EOF(\n  timeout: 1s\n  interval: 1s\n  unhealthy_threshold: 2\n  healthy_threshold: 2\n  http_health_check:\n    service_name_matcher:\n        prefix: locations\n    path: /healthcheck\n    expected_statuses:\n      - start: 599\n        end: 600\n  )EOF\";\n\n  auto conf = parseHealthCheckFromV3Yaml(yaml);\n  HttpHealthCheckerImpl::HttpStatusChecker http_status_checker(\n      conf.http_health_check().expected_statuses(), conf.http_health_check().retriable_statuses(),\n      200);\n\n  EXPECT_FALSE(http_status_checker.inExpectedRanges(200));\n\n  EXPECT_FALSE(http_status_checker.inExpectedRanges(598));\n  EXPECT_TRUE(http_status_checker.inExpectedRanges(599));\n  EXPECT_FALSE(http_status_checker.inExpectedRanges(600));\n}\n\nTEST(HttpStatusChecker, SingleRetriable599) {\n  const std::string yaml = R\"EOF(\n  timeout: 1s\n  interval: 1s\n  unhealthy_threshold: 2\n  healthy_threshold: 2\n  http_health_check:\n    service_name_matcher:\n        prefix: locations\n    path: /healthcheck\n    retriable_statuses:\n      - start: 599\n        end: 600\n  )EOF\";\n\n  auto conf = parseHealthCheckFromV3Yaml(yaml);\n  HttpHealthCheckerImpl::HttpStatusChecker http_status_checker(\n      conf.http_health_check().expected_statuses(), conf.http_health_check().retriable_statuses(),\n      200);\n\n  EXPECT_FALSE(http_status_checker.inRetriableRanges(598));\n  EXPECT_TRUE(http_status_checker.inRetriableRanges(599));\n  EXPECT_FALSE(http_status_checker.inRetriableRanges(600));\n}\n\nTEST(HttpStatusChecker, ExpectedRanges_204_304) {\n  const std::string yaml = R\"EOF(\n  timeout: 1s\n  interval: 1s\n  unhealthy_threshold: 2\n  healthy_threshold: 2\n  http_health_check:\n    service_name_matcher:\n        prefix: locations\n    path: /healthcheck\n    expected_statuses:\n      - start: 204\n        end: 205\n      - start: 304\n        end: 305\n  )EOF\";\n\n  auto conf = parseHealthCheckFromV3Yaml(yaml);\n  HttpHealthCheckerImpl::HttpStatusChecker http_status_checker(\n      conf.http_health_check().expected_statuses(), conf.http_health_check().retriable_statuses(),\n      200);\n\n  EXPECT_FALSE(http_status_checker.inExpectedRanges(200));\n\n  EXPECT_FALSE(http_status_checker.inExpectedRanges(203));\n  EXPECT_TRUE(http_status_checker.inExpectedRanges(204));\n  EXPECT_FALSE(http_status_checker.inExpectedRanges(205));\n  EXPECT_FALSE(http_status_checker.inExpectedRanges(303));\n  EXPECT_TRUE(http_status_checker.inExpectedRanges(304));\n  EXPECT_FALSE(http_status_checker.inExpectedRanges(305));\n}\n\nTEST(HttpStatusChecker, RetriableRanges_304_404) {\n  const std::string yaml = R\"EOF(\n  timeout: 1s\n  interval: 1s\n  unhealthy_threshold: 2\n  healthy_threshold: 2\n  http_health_check:\n    service_name_matcher:\n        prefix: locations\n    path: /healthcheck\n    retriable_statuses:\n      - start: 304\n        end: 305\n      - start: 404\n        end: 405\n  )EOF\";\n\n  auto conf = parseHealthCheckFromV3Yaml(yaml);\n  HttpHealthCheckerImpl::HttpStatusChecker http_status_checker(\n      conf.http_health_check().expected_statuses(), conf.http_health_check().retriable_statuses(),\n      200);\n\n  EXPECT_FALSE(http_status_checker.inRetriableRanges(303));\n  EXPECT_TRUE(http_status_checker.inRetriableRanges(304));\n  EXPECT_FALSE(http_status_checker.inRetriableRanges(305));\n  EXPECT_FALSE(http_status_checker.inRetriableRanges(403));\n  EXPECT_TRUE(http_status_checker.inRetriableRanges(404));\n  EXPECT_FALSE(http_status_checker.inRetriableRanges(405));\n}\n\nTEST(HttpStatusChecker, ExpectedBelow100) {\n  const std::string yaml = R\"EOF(\n  timeout: 1s\n  interval: 1s\n  unhealthy_threshold: 2\n  healthy_threshold: 2\n  http_health_check:\n    service_name_matcher:\n        prefix: locations\n    path: /healthcheck\n    expected_statuses:\n      - start: 99\n        end: 100\n  )EOF\";\n\n  auto conf = parseHealthCheckFromV3Yaml(yaml);\n  EXPECT_THROW_WITH_MESSAGE(\n      HttpHealthCheckerImpl::HttpStatusChecker http_status_checker(\n          conf.http_health_check().expected_statuses(),\n          conf.http_health_check().retriable_statuses(), 200),\n      EnvoyException,\n      \"Invalid http expected status range: expecting start >= 100, but found start=99\");\n}\n\nTEST(HttpStatusChecker, RetriableBelow100) {\n  const std::string yaml = R\"EOF(\n  timeout: 1s\n  interval: 1s\n  unhealthy_threshold: 2\n  healthy_threshold: 2\n  http_health_check:\n    service_name_matcher:\n        prefix: locations\n    path: /healthcheck\n    retriable_statuses:\n      - start: 99\n        end: 100\n  )EOF\";\n\n  auto conf = parseHealthCheckFromV3Yaml(yaml);\n  EXPECT_THROW_WITH_MESSAGE(\n      HttpHealthCheckerImpl::HttpStatusChecker http_status_checker(\n          conf.http_health_check().expected_statuses(),\n          conf.http_health_check().retriable_statuses(), 200),\n      EnvoyException,\n      \"Invalid http retriable status range: expecting start >= 100, but found start=99\");\n}\n\nTEST(HttpStatusChecker, ExpectedAbove599) {\n  const std::string yaml = R\"EOF(\n  timeout: 1s\n  interval: 1s\n  unhealthy_threshold: 2\n  healthy_threshold: 2\n  http_health_check:\n    service_name_matcher:\n        prefix: locations\n    path: /healthchecka\n    expected_statuses:\n      - start: 600\n        end: 601\n  )EOF\";\n\n  auto conf = parseHealthCheckFromV3Yaml(yaml);\n  EXPECT_THROW_WITH_MESSAGE(\n      HttpHealthCheckerImpl::HttpStatusChecker http_status_checker(\n          conf.http_health_check().expected_statuses(),\n          conf.http_health_check().retriable_statuses(), 200),\n      EnvoyException,\n      \"Invalid http expected status range: expecting end <= 600, but found end=601\");\n}\n\nTEST(HttpStatusChecker, RetriableAbove599) {\n  const std::string yaml = R\"EOF(\n  timeout: 1s\n  interval: 1s\n  unhealthy_threshold: 2\n  healthy_threshold: 2\n  http_health_check:\n    service_name_matcher:\n        prefix: locations\n    path: /healthchecka\n    retriable_statuses:\n      - start: 600\n        end: 601\n  )EOF\";\n\n  auto conf = parseHealthCheckFromV3Yaml(yaml);\n  EXPECT_THROW_WITH_MESSAGE(\n      HttpHealthCheckerImpl::HttpStatusChecker http_status_checker(\n          conf.http_health_check().expected_statuses(),\n          conf.http_health_check().retriable_statuses(), 200),\n      EnvoyException,\n      \"Invalid http retriable status range: expecting end <= 600, but found end=601\");\n}\n\nTEST(HttpStatusChecker, InvalidExpectedRange) {\n  const std::string yaml = R\"EOF(\n  timeout: 1s\n  interval: 1s\n  unhealthy_threshold: 2\n  healthy_threshold: 2\n  http_health_check:\n    service_name_matcher:\n        prefix: locations\n    path: /healthchecka\n    expected_statuses:\n      - start: 200\n        end: 200\n  )EOF\";\n\n  auto conf = parseHealthCheckFromV3Yaml(yaml);\n  EXPECT_THROW_WITH_MESSAGE(\n      HttpHealthCheckerImpl::HttpStatusChecker http_status_checker(\n          conf.http_health_check().expected_statuses(),\n          conf.http_health_check().retriable_statuses(), 200),\n      EnvoyException,\n      \"Invalid http expected status range: expecting start < end, but found start=200 and end=200\");\n}\n\nTEST(HttpStatusChecker, InvalidRetriableRange) {\n  const std::string yaml = R\"EOF(\n  timeout: 1s\n  interval: 1s\n  unhealthy_threshold: 2\n  healthy_threshold: 2\n  http_health_check:\n    service_name_matcher:\n        prefix: locations\n    path: /healthchecka\n    retriable_statuses:\n      - start: 200\n        end: 200\n  )EOF\";\n\n  auto conf = parseHealthCheckFromV3Yaml(yaml);\n  EXPECT_THROW_WITH_MESSAGE(HttpHealthCheckerImpl::HttpStatusChecker http_status_checker(\n                                conf.http_health_check().expected_statuses(),\n                                conf.http_health_check().retriable_statuses(), 200),\n                            EnvoyException,\n                            \"Invalid http retriable status range: expecting start < end, but found \"\n                            \"start=200 and end=200\");\n}\n\nTEST(TcpHealthCheckMatcher, loadJsonBytes) {\n  {\n    Protobuf::RepeatedPtrField<envoy::config::core::v3::HealthCheck::Payload> repeated_payload;\n    repeated_payload.Add()->set_text(\"39000000\");\n    repeated_payload.Add()->set_text(\"EEEEEEEE\");\n\n    TcpHealthCheckMatcher::MatchSegments segments =\n        TcpHealthCheckMatcher::loadProtoBytes(repeated_payload);\n    EXPECT_EQ(2U, segments.size());\n  }\n\n  {\n    Protobuf::RepeatedPtrField<envoy::config::core::v3::HealthCheck::Payload> repeated_payload;\n    repeated_payload.Add()->set_text(\"4\");\n\n    EXPECT_THROW(TcpHealthCheckMatcher::loadProtoBytes(repeated_payload), EnvoyException);\n  }\n\n  {\n    Protobuf::RepeatedPtrField<envoy::config::core::v3::HealthCheck::Payload> repeated_payload;\n    repeated_payload.Add()->set_text(\"gg\");\n\n    EXPECT_THROW(TcpHealthCheckMatcher::loadProtoBytes(repeated_payload), EnvoyException);\n  }\n}\n\nstatic void addUint8(Buffer::Instance& buffer, uint8_t addend) {\n  buffer.add(&addend, sizeof(addend));\n}\n\nTEST(TcpHealthCheckMatcher, match) {\n  Protobuf::RepeatedPtrField<envoy::config::core::v3::HealthCheck::Payload> repeated_payload;\n  repeated_payload.Add()->set_text(\"01\");\n  repeated_payload.Add()->set_text(\"02\");\n\n  TcpHealthCheckMatcher::MatchSegments segments =\n      TcpHealthCheckMatcher::loadProtoBytes(repeated_payload);\n\n  Buffer::OwnedImpl buffer;\n  EXPECT_FALSE(TcpHealthCheckMatcher::match(segments, buffer));\n  addUint8(buffer, 1);\n  EXPECT_FALSE(TcpHealthCheckMatcher::match(segments, buffer));\n  addUint8(buffer, 2);\n  EXPECT_TRUE(TcpHealthCheckMatcher::match(segments, buffer));\n\n  buffer.drain(2);\n  addUint8(buffer, 1);\n  addUint8(buffer, 3);\n  addUint8(buffer, 2);\n  EXPECT_TRUE(TcpHealthCheckMatcher::match(segments, buffer));\n\n  buffer.drain(3);\n  addUint8(buffer, 0);\n  addUint8(buffer, 3);\n  addUint8(buffer, 1);\n  addUint8(buffer, 2);\n  EXPECT_TRUE(TcpHealthCheckMatcher::match(segments, buffer));\n}\n\nclass TcpHealthCheckerImplTest : public testing::Test,\n                                 public HealthCheckerTestBase,\n                                 public Event::TestUsingSimulatedTime {\npublic:\n  void allocHealthChecker(const std::string& yaml) {\n    health_checker_ = std::make_shared<TcpHealthCheckerImpl>(\n        *cluster_, parseHealthCheckFromV3Yaml(yaml), dispatcher_, runtime_, random_,\n        HealthCheckEventLoggerPtr(event_logger_storage_.release()));\n  }\n\n  void setupData(unsigned int unhealthy_threshold = 2) {\n    std::ostringstream yaml;\n    yaml << R\"EOF(\n    timeout: 1s\n    interval: 1s\n    unhealthy_threshold: )EOF\"\n         << unhealthy_threshold << R\"EOF(\n    healthy_threshold: 2\n    tcp_health_check:\n      send:\n        text: \"01\"\n      receive:\n      - text: \"02\"\n    )EOF\";\n\n    allocHealthChecker(yaml.str());\n  }\n\n  void setupNoData() {\n    std::string yaml = R\"EOF(\n    timeout: 1s\n    interval: 1s\n    unhealthy_threshold: 2\n    healthy_threshold: 2\n    tcp_health_check: {}\n    )EOF\";\n\n    allocHealthChecker(yaml);\n  }\n\n  void setupDataDontReuseConnection() {\n    std::string yaml = R\"EOF(\n    timeout: 1s\n    interval: 1s\n    unhealthy_threshold: 2\n    healthy_threshold: 2\n    reuse_connection: false\n    tcp_health_check:\n      send:\n        text: \"01\"\n      receive:\n      - text: \"02\"\n    )EOF\";\n\n    allocHealthChecker(yaml);\n  }\n\n  void expectSessionCreate() {\n    interval_timer_ = new Event::MockTimer(&dispatcher_);\n    timeout_timer_ = new Event::MockTimer(&dispatcher_);\n  }\n\n  void expectClientCreate() {\n    connection_ = new NiceMock<Network::MockClientConnection>();\n    EXPECT_CALL(dispatcher_, createClientConnection_(_, _, _, _)).WillOnce(Return(connection_));\n    EXPECT_CALL(*connection_, addReadFilter(_)).WillOnce(SaveArg<0>(&read_filter_));\n  }\n\n  std::shared_ptr<TcpHealthCheckerImpl> health_checker_;\n  Network::MockClientConnection* connection_{};\n  Event::MockTimer* timeout_timer_{};\n  Event::MockTimer* interval_timer_{};\n  Network::ReadFilterSharedPtr read_filter_;\n};\n\nTEST_F(TcpHealthCheckerImplTest, Success) {\n  InSequence s;\n\n  setupData();\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  expectSessionCreate();\n  expectClientCreate();\n  EXPECT_CALL(*connection_, write(_, _));\n  EXPECT_CALL(*timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n\n  connection_->runHighWatermarkCallbacks();\n  connection_->runLowWatermarkCallbacks();\n  connection_->raiseEvent(Network::ConnectionEvent::Connected);\n\n  EXPECT_CALL(*timeout_timer_, disableTimer());\n  EXPECT_CALL(*interval_timer_, enableTimer(_, _));\n  Buffer::OwnedImpl response;\n  addUint8(response, 2);\n  read_filter_->onData(response, false);\n}\n\n// Tests that a successful healthcheck will disconnect the client when reuse_connection is false.\nTEST_F(TcpHealthCheckerImplTest, DataWithoutReusingConnection) {\n  InSequence s;\n\n  setupDataDontReuseConnection();\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  expectSessionCreate();\n  expectClientCreate();\n  EXPECT_CALL(*connection_, write(_, _));\n  EXPECT_CALL(*timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n\n  connection_->raiseEvent(Network::ConnectionEvent::Connected);\n\n  // Expected execution flow when a healthcheck is successful and reuse_connection is false.\n  EXPECT_CALL(*timeout_timer_, disableTimer());\n  EXPECT_CALL(*interval_timer_, enableTimer(_, _));\n  EXPECT_CALL(*connection_, close(Network::ConnectionCloseType::NoFlush));\n\n  Buffer::OwnedImpl response;\n  addUint8(response, 2);\n  read_filter_->onData(response, false);\n\n  // These are the expected metric results after testing.\n  EXPECT_EQ(1UL, cluster_->info_->stats_store_.counter(\"health_check.success\").value());\n  EXPECT_EQ(0UL, cluster_->info_->stats_store_.counter(\"health_check.failure\").value());\n}\n\n// Tests an unsuccessful healthcheck, where the endpoint sends wrong data\nTEST_F(TcpHealthCheckerImplTest, WrongData) {\n  InSequence s;\n\n  setupDataDontReuseConnection();\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  expectSessionCreate();\n  expectClientCreate();\n  EXPECT_CALL(*connection_, write(_, _));\n  EXPECT_CALL(*timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n\n  connection_->raiseEvent(Network::ConnectionEvent::Connected);\n\n  // Not the expected response\n  Buffer::OwnedImpl response;\n  addUint8(response, 3);\n  read_filter_->onData(response, false);\n\n  // These are the expected metric results after testing.\n  EXPECT_EQ(0UL, cluster_->info_->stats_store_.counter(\"health_check.success\").value());\n  // TODO(lilika): The TCP health checker does generic pattern matching so we can't differentiate\n  // between wrong data and not enough data. We could likely do better here and figure out cases in\n  // which a match is not possible but that is not done now.\n  EXPECT_EQ(0UL, cluster_->info_->stats_store_.counter(\"health_check.failure\").value());\n}\n\nTEST_F(TcpHealthCheckerImplTest, TimeoutThenRemoteClose) {\n  InSequence s;\n\n  setupData();\n  health_checker_->start();\n\n  expectSessionCreate();\n  expectClientCreate();\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  EXPECT_CALL(*connection_, write(_, _));\n  EXPECT_CALL(*timeout_timer_, enableTimer(_, _));\n\n  cluster_->prioritySet().getMockHostSet(0)->runCallbacks(\n      {cluster_->prioritySet().getMockHostSet(0)->hosts_.back()}, {});\n\n  connection_->raiseEvent(Network::ConnectionEvent::Connected);\n\n  Buffer::OwnedImpl response;\n  addUint8(response, 1);\n  read_filter_->onData(response, false);\n\n  EXPECT_CALL(*connection_, close(_));\n  EXPECT_CALL(event_logger_, logUnhealthy(_, _, _, true));\n  EXPECT_CALL(*timeout_timer_, disableTimer());\n  EXPECT_CALL(*interval_timer_, enableTimer(_, _));\n  timeout_timer_->invokeCallback();\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n\n  expectClientCreate();\n  EXPECT_CALL(*connection_, write(_, _));\n  EXPECT_CALL(*timeout_timer_, enableTimer(_, _));\n  interval_timer_->invokeCallback();\n\n  connection_->raiseEvent(Network::ConnectionEvent::Connected);\n\n  EXPECT_CALL(event_logger_, logEjectUnhealthy(_, _, _));\n  EXPECT_CALL(*timeout_timer_, disableTimer());\n  EXPECT_CALL(*interval_timer_, enableTimer(_, _));\n  connection_->raiseEvent(Network::ConnectionEvent::RemoteClose);\n  EXPECT_TRUE(cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthFlagGet(\n      Host::HealthFlag::FAILED_ACTIVE_HC));\n  EXPECT_EQ(Host::Health::Unhealthy,\n            cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n\n  expectClientCreate();\n  EXPECT_CALL(*connection_, write(_, _));\n  EXPECT_CALL(*timeout_timer_, enableTimer(_, _));\n  interval_timer_->invokeCallback();\n\n  connection_->raiseEvent(Network::ConnectionEvent::Connected);\n\n  HostVector removed{cluster_->prioritySet().getMockHostSet(0)->hosts_.back()};\n  cluster_->prioritySet().getMockHostSet(0)->hosts_.clear();\n  EXPECT_CALL(*connection_, close(_));\n  cluster_->prioritySet().getMockHostSet(0)->runCallbacks({}, removed);\n}\n\nTEST_F(TcpHealthCheckerImplTest, Timeout) {\n  InSequence s;\n\n  setupData(1);\n  health_checker_->start();\n\n  expectSessionCreate();\n  expectClientCreate();\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  EXPECT_CALL(*connection_, write(_, _));\n  EXPECT_CALL(*timeout_timer_, enableTimer(_, _));\n\n  cluster_->prioritySet().getMockHostSet(0)->runCallbacks(\n      {cluster_->prioritySet().getMockHostSet(0)->hosts_.back()}, {});\n\n  connection_->raiseEvent(Network::ConnectionEvent::Connected);\n\n  Buffer::OwnedImpl response;\n  addUint8(response, 1);\n  read_filter_->onData(response, false);\n\n  EXPECT_CALL(*connection_, close(_));\n  EXPECT_CALL(event_logger_, logEjectUnhealthy(_, _, _));\n  EXPECT_CALL(event_logger_, logUnhealthy(_, _, _, true));\n  EXPECT_CALL(*timeout_timer_, disableTimer());\n  EXPECT_CALL(*interval_timer_, enableTimer(_, _));\n  timeout_timer_->invokeCallback();\n  EXPECT_TRUE(cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthFlagGet(\n      Host::HealthFlag::ACTIVE_HC_TIMEOUT));\n  EXPECT_EQ(Host::Health::Unhealthy,\n            cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n}\n\nTEST_F(TcpHealthCheckerImplTest, DoubleTimeout) {\n  InSequence s;\n\n  setupData();\n  health_checker_->start();\n\n  expectSessionCreate();\n  expectClientCreate();\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  EXPECT_CALL(*connection_, write(_, _));\n  EXPECT_CALL(*timeout_timer_, enableTimer(_, _));\n\n  cluster_->prioritySet().getMockHostSet(0)->runCallbacks(\n      {cluster_->prioritySet().getMockHostSet(0)->hosts_.back()}, {});\n\n  connection_->raiseEvent(Network::ConnectionEvent::Connected);\n\n  Buffer::OwnedImpl response;\n  addUint8(response, 1);\n  read_filter_->onData(response, false);\n\n  EXPECT_CALL(*connection_, close(_));\n  EXPECT_CALL(event_logger_, logUnhealthy(_, _, _, true));\n  EXPECT_CALL(*timeout_timer_, disableTimer());\n  EXPECT_CALL(*interval_timer_, enableTimer(_, _));\n  timeout_timer_->invokeCallback();\n  EXPECT_FALSE(cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthFlagGet(\n      Host::HealthFlag::ACTIVE_HC_TIMEOUT));\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n\n  expectClientCreate();\n  EXPECT_CALL(*connection_, write(_, _));\n  EXPECT_CALL(*timeout_timer_, enableTimer(_, _));\n  interval_timer_->invokeCallback();\n\n  connection_->raiseEvent(Network::ConnectionEvent::Connected);\n\n  EXPECT_CALL(*connection_, close(_));\n  EXPECT_CALL(event_logger_, logEjectUnhealthy(_, _, _));\n  EXPECT_CALL(*timeout_timer_, disableTimer());\n  EXPECT_CALL(*interval_timer_, enableTimer(_, _));\n  timeout_timer_->invokeCallback();\n  EXPECT_TRUE(cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthFlagGet(\n      Host::HealthFlag::ACTIVE_HC_TIMEOUT));\n  EXPECT_EQ(Host::Health::Unhealthy,\n            cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n\n  expectClientCreate();\n  EXPECT_CALL(*connection_, write(_, _));\n  EXPECT_CALL(*timeout_timer_, enableTimer(_, _));\n  interval_timer_->invokeCallback();\n\n  connection_->raiseEvent(Network::ConnectionEvent::Connected);\n\n  HostVector removed{cluster_->prioritySet().getMockHostSet(0)->hosts_.back()};\n  cluster_->prioritySet().getMockHostSet(0)->hosts_.clear();\n  EXPECT_CALL(*connection_, close(_));\n  cluster_->prioritySet().getMockHostSet(0)->runCallbacks({}, removed);\n}\n\n// Tests that when reuse_connection is false timeouts execute normally.\nTEST_F(TcpHealthCheckerImplTest, TimeoutWithoutReusingConnection) {\n  InSequence s;\n\n  setupDataDontReuseConnection();\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  expectSessionCreate();\n  expectClientCreate();\n  EXPECT_CALL(*connection_, write(_, _));\n  EXPECT_CALL(*timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n\n  connection_->raiseEvent(Network::ConnectionEvent::Connected);\n\n  // Expected flow when a healthcheck is successful and reuse_connection is false.\n  EXPECT_CALL(*timeout_timer_, disableTimer());\n  EXPECT_CALL(*interval_timer_, enableTimer(_, _));\n  EXPECT_CALL(*connection_, close(Network::ConnectionCloseType::NoFlush));\n\n  Buffer::OwnedImpl response;\n  addUint8(response, 2);\n  read_filter_->onData(response, false);\n\n  EXPECT_EQ(1UL, cluster_->info_->stats_store_.counter(\"health_check.success\").value());\n  EXPECT_EQ(0UL, cluster_->info_->stats_store_.counter(\"health_check.failure\").value());\n\n  // The healthcheck will run again.\n  expectClientCreate();\n  EXPECT_CALL(*connection_, write(_, _));\n  EXPECT_CALL(*timeout_timer_, enableTimer(_, _));\n  interval_timer_->invokeCallback();\n\n  connection_->raiseEvent(Network::ConnectionEvent::Connected);\n\n  // Expected flow when a healthcheck times out.\n  EXPECT_CALL(*timeout_timer_, disableTimer());\n  EXPECT_CALL(*interval_timer_, enableTimer(_, _));\n  connection_->raiseEvent(Network::ConnectionEvent::RemoteClose);\n  // The healthcheck is not yet at the unhealthy threshold.\n  EXPECT_FALSE(cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthFlagGet(\n      Host::HealthFlag::FAILED_ACTIVE_HC));\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n\n  // The healthcheck metric results after first timeout block.\n  EXPECT_EQ(1UL, cluster_->info_->stats_store_.counter(\"health_check.success\").value());\n  EXPECT_EQ(1UL, cluster_->info_->stats_store_.counter(\"health_check.failure\").value());\n\n  // The healthcheck will run again, it should be failing after this attempt.\n  expectClientCreate();\n  EXPECT_CALL(*connection_, write(_, _));\n  EXPECT_CALL(*timeout_timer_, enableTimer(_, _));\n  interval_timer_->invokeCallback();\n\n  connection_->raiseEvent(Network::ConnectionEvent::Connected);\n\n  // Expected flow when a healthcheck times out.\n  EXPECT_CALL(event_logger_, logEjectUnhealthy(_, _, _));\n  EXPECT_CALL(*timeout_timer_, disableTimer());\n  EXPECT_CALL(*interval_timer_, enableTimer(_, _));\n  connection_->raiseEvent(Network::ConnectionEvent::RemoteClose);\n  EXPECT_TRUE(cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthFlagGet(\n      Host::HealthFlag::FAILED_ACTIVE_HC));\n  EXPECT_EQ(Host::Health::Unhealthy,\n            cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n\n  // The healthcheck metric results after the second timeout block.\n  EXPECT_EQ(1UL, cluster_->info_->stats_store_.counter(\"health_check.success\").value());\n  EXPECT_EQ(2UL, cluster_->info_->stats_store_.counter(\"health_check.failure\").value());\n}\n\nTEST_F(TcpHealthCheckerImplTest, NoData) {\n  InSequence s;\n\n  setupNoData();\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  expectSessionCreate();\n  expectClientCreate();\n  EXPECT_CALL(*connection_, write(_, _)).Times(0);\n  EXPECT_CALL(*timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n\n  EXPECT_CALL(*connection_, close(_));\n  EXPECT_CALL(*timeout_timer_, disableTimer());\n  EXPECT_CALL(*interval_timer_, enableTimer(_, _));\n  connection_->raiseEvent(Network::ConnectionEvent::Connected);\n\n  expectClientCreate();\n  EXPECT_CALL(*connection_, write(_, _)).Times(0);\n  EXPECT_CALL(*timeout_timer_, enableTimer(_, _));\n  interval_timer_->invokeCallback();\n}\n\nTEST_F(TcpHealthCheckerImplTest, PassiveFailure) {\n  InSequence s;\n\n  setupNoData();\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  expectSessionCreate();\n  expectClientCreate();\n  EXPECT_CALL(*connection_, write(_, _)).Times(0);\n  EXPECT_CALL(*timeout_timer_, enableTimer(_, _));\n  EXPECT_CALL(event_logger_, logEjectUnhealthy(_, _, _));\n  EXPECT_CALL(event_logger_, logUnhealthy(_, _, _, true));\n  health_checker_->start();\n\n  // Do multiple passive failures. This will not reset the active HC timers.\n  cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthChecker().setUnhealthy(\n      HealthCheckHostMonitor::UnhealthyType::ImmediateHealthCheckFail);\n  cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthChecker().setUnhealthy(\n      HealthCheckHostMonitor::UnhealthyType::ImmediateHealthCheckFail);\n  EXPECT_TRUE(cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthFlagGet(\n      Host::HealthFlag::FAILED_ACTIVE_HC));\n  EXPECT_TRUE(cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthFlagGet(\n      Host::HealthFlag::EXCLUDED_VIA_IMMEDIATE_HC_FAIL));\n  EXPECT_EQ(Host::Health::Unhealthy,\n            cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n\n  // A single success should not bring us back to healthy.\n  EXPECT_CALL(*connection_, close(_));\n  EXPECT_CALL(*timeout_timer_, disableTimer());\n  EXPECT_CALL(*interval_timer_, enableTimer(_, _));\n  connection_->raiseEvent(Network::ConnectionEvent::Connected);\n  EXPECT_TRUE(cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthFlagGet(\n      Host::HealthFlag::FAILED_ACTIVE_HC));\n  EXPECT_TRUE(cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthFlagGet(\n      Host::HealthFlag::EXCLUDED_VIA_IMMEDIATE_HC_FAIL));\n  EXPECT_EQ(Host::Health::Unhealthy,\n            cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n\n  // Bring back to healthy and check flag clearing.\n  expectClientCreate();\n  EXPECT_CALL(*timeout_timer_, enableTimer(_, _));\n  interval_timer_->invokeCallback();\n\n  EXPECT_CALL(*connection_, close(_));\n  EXPECT_CALL(event_logger_, logAddHealthy(_, _, false));\n  EXPECT_CALL(*timeout_timer_, disableTimer());\n  EXPECT_CALL(*interval_timer_, enableTimer(_, _));\n  connection_->raiseEvent(Network::ConnectionEvent::Connected);\n  EXPECT_FALSE(cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthFlagGet(\n      Host::HealthFlag::FAILED_ACTIVE_HC));\n  EXPECT_FALSE(cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthFlagGet(\n      Host::HealthFlag::EXCLUDED_VIA_IMMEDIATE_HC_FAIL));\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n\n  EXPECT_EQ(2UL, cluster_->info_->stats_store_.counter(\"health_check.attempt\").value());\n  EXPECT_EQ(2UL, cluster_->info_->stats_store_.counter(\"health_check.success\").value());\n  EXPECT_EQ(2UL, cluster_->info_->stats_store_.counter(\"health_check.failure\").value());\n  EXPECT_EQ(2UL, cluster_->info_->stats_store_.counter(\"health_check.passive_failure\").value());\n}\n\nTEST_F(TcpHealthCheckerImplTest, PassiveFailureCrossThreadRemoveHostRace) {\n  InSequence s;\n\n  setupNoData();\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  expectSessionCreate();\n  expectClientCreate();\n  EXPECT_CALL(*connection_, write(_, _)).Times(0);\n  EXPECT_CALL(*timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n\n  // Do a passive failure. This will not reset the active HC timers.\n  Event::PostCb post_cb;\n  EXPECT_CALL(dispatcher_, post(_)).WillOnce(SaveArg<0>(&post_cb));\n  cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthChecker().setUnhealthy(\n      HealthCheckHostMonitor::UnhealthyType::ImmediateHealthCheckFail);\n\n  // Remove before the cross thread event comes in.\n  EXPECT_CALL(*connection_, close(_));\n  HostVector old_hosts = std::move(cluster_->prioritySet().getMockHostSet(0)->hosts_);\n  cluster_->prioritySet().getMockHostSet(0)->runCallbacks({}, old_hosts);\n  post_cb();\n\n  EXPECT_EQ(1UL, cluster_->info_->stats_store_.counter(\"health_check.attempt\").value());\n  EXPECT_EQ(0UL, cluster_->info_->stats_store_.counter(\"health_check.success\").value());\n  EXPECT_EQ(0UL, cluster_->info_->stats_store_.counter(\"health_check.failure\").value());\n  EXPECT_EQ(0UL, cluster_->info_->stats_store_.counter(\"health_check.passive_failure\").value());\n}\n\nTEST_F(TcpHealthCheckerImplTest, PassiveFailureCrossThreadRemoveClusterRace) {\n  InSequence s;\n\n  setupNoData();\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  expectSessionCreate();\n  expectClientCreate();\n  EXPECT_CALL(*connection_, write(_, _)).Times(0);\n  EXPECT_CALL(*timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n\n  // Do a passive failure. This will not reset the active HC timers.\n  Event::PostCb post_cb;\n  EXPECT_CALL(dispatcher_, post(_)).WillOnce(SaveArg<0>(&post_cb));\n  cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthChecker().setUnhealthy(\n      HealthCheckHostMonitor::UnhealthyType::ImmediateHealthCheckFail);\n\n  // Remove before the cross thread event comes in.\n  EXPECT_CALL(*connection_, close(_));\n  health_checker_.reset();\n  post_cb();\n\n  EXPECT_EQ(1UL, cluster_->info_->stats_store_.counter(\"health_check.attempt\").value());\n  EXPECT_EQ(0UL, cluster_->info_->stats_store_.counter(\"health_check.success\").value());\n  EXPECT_EQ(0UL, cluster_->info_->stats_store_.counter(\"health_check.failure\").value());\n  EXPECT_EQ(0UL, cluster_->info_->stats_store_.counter(\"health_check.passive_failure\").value());\n}\n\nTEST_F(TcpHealthCheckerImplTest, ConnectionLocalFailure) {\n  InSequence s;\n\n  setupData();\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  expectSessionCreate();\n  expectClientCreate();\n  EXPECT_CALL(*connection_, write(_, _));\n  EXPECT_CALL(*timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n\n  // Expect the LocalClose to be handled as a health check failure\n  EXPECT_CALL(event_logger_, logUnhealthy(_, _, _, true));\n  EXPECT_CALL(*timeout_timer_, disableTimer());\n  EXPECT_CALL(*interval_timer_, enableTimer(_, _));\n\n  // Raise a LocalClose that is not triggered by the health monitor itself.\n  // e.g. a failure to setsockopt().\n  connection_->raiseEvent(Network::ConnectionEvent::LocalClose);\n\n  EXPECT_EQ(1UL, cluster_->info_->stats_store_.counter(\"health_check.attempt\").value());\n  EXPECT_EQ(0UL, cluster_->info_->stats_store_.counter(\"health_check.success\").value());\n  EXPECT_EQ(1UL, cluster_->info_->stats_store_.counter(\"health_check.failure\").value());\n  EXPECT_EQ(0UL, cluster_->info_->stats_store_.counter(\"health_check.passive_failure\").value());\n}\n\nclass TestGrpcHealthCheckerImpl : public GrpcHealthCheckerImpl {\npublic:\n  using GrpcHealthCheckerImpl::GrpcHealthCheckerImpl;\n\n  Http::CodecClientPtr createCodecClient(Upstream::Host::CreateConnectionData& conn_data) override {\n    auto codec_client = createCodecClient_(conn_data);\n    return Http::CodecClientPtr(codec_client);\n  };\n\n  // GrpcHealthCheckerImpl\n  MOCK_METHOD(Http::CodecClient*, createCodecClient_, (Upstream::Host::CreateConnectionData&));\n};\n\nclass GrpcHealthCheckerImplTestBase : public Event::TestUsingSimulatedTime,\n                                      public HealthCheckerTestBase {\npublic:\n  struct TestSession {\n    TestSession() = default;\n\n    Event::MockTimer* interval_timer_{};\n    Event::MockTimer* timeout_timer_{};\n    Http::MockClientConnection* codec_{};\n    Stats::IsolatedStoreImpl stats_store_;\n    Network::MockClientConnection* client_connection_{};\n    NiceMock<Http::MockRequestEncoder> request_encoder_;\n    Http::ResponseDecoder* stream_response_callbacks_{};\n    CodecClientForTest* codec_client_{};\n  };\n\n  using TestSessionPtr = std::unique_ptr<TestSession>;\n\n  struct ResponseSpec {\n    struct ChunkSpec {\n      bool valid;\n      std::vector<uint8_t> data;\n    };\n    static ChunkSpec invalidChunk() {\n      ChunkSpec spec;\n      spec.valid = false;\n      return spec;\n    }\n    static ChunkSpec invalidPayload(uint8_t flags, bool valid_message) {\n      ChunkSpec spec;\n      spec.valid = true;\n      spec.data = serializeResponse(grpc::health::v1::HealthCheckResponse::SERVING);\n      spec.data[0] = flags;\n      if (!valid_message) {\n        const size_t kGrpcHeaderSize = 5;\n        for (size_t i = kGrpcHeaderSize; i < spec.data.size(); i++) {\n          // Fill payload with some random data.\n          spec.data[i] = i % 256;\n        }\n      }\n      return spec;\n    }\n    // Null dereference from health check fuzzer\n    static ChunkSpec badData() {\n      std::string data(\"\\000\\000\\000\\000\\0000000\", 9);\n      std::vector<uint8_t> chunk(data.begin(), data.end());\n      ChunkSpec spec;\n      spec.valid = true;\n      spec.data = chunk;\n      return spec;\n    }\n    static ChunkSpec validFramesThenInvalidFrames() {\n      grpc::health::v1::HealthCheckResponse response;\n      response.set_status(grpc::health::v1::HealthCheckResponse::SERVING);\n      const auto data = Grpc::Common::serializeToGrpcFrame(response);\n      std::vector<uint8_t> buffer_vector = std::vector<uint8_t>(data->length(), 0);\n      data->copyOut(0, data->length(), &buffer_vector[0]);\n      // Invalid frame here\n      for (size_t i = 0; i < 6; i++) {\n        buffer_vector.push_back(48); // Represents ASCII Character of 0\n      }\n      ChunkSpec spec;\n      spec.valid = true;\n      spec.data = buffer_vector;\n      return spec;\n    }\n    static ChunkSpec validChunk(grpc::health::v1::HealthCheckResponse::ServingStatus status) {\n      ChunkSpec spec;\n      spec.valid = true;\n      spec.data = serializeResponse(status);\n      return spec;\n    }\n\n    static ChunkSpec servingResponse() {\n      return validChunk(grpc::health::v1::HealthCheckResponse::SERVING);\n    }\n\n    static ChunkSpec notServingResponse() {\n      return validChunk(grpc::health::v1::HealthCheckResponse::NOT_SERVING);\n    }\n\n    static std::vector<uint8_t>\n    serializeResponse(grpc::health::v1::HealthCheckResponse::ServingStatus status) {\n      grpc::health::v1::HealthCheckResponse response;\n      response.set_status(status);\n      const auto data = Grpc::Common::serializeToGrpcFrame(response);\n      auto ret = std::vector<uint8_t>(data->length(), 0);\n      data->copyOut(0, data->length(), &ret[0]);\n      return ret;\n    }\n\n    std::vector<std::pair<std::string, std::string>> response_headers;\n    std::vector<ChunkSpec> body_chunks;\n    std::vector<std::pair<std::string, std::string>> trailers;\n  };\n\n  GrpcHealthCheckerImplTestBase() {\n    EXPECT_CALL(*cluster_->info_, features())\n        .WillRepeatedly(Return(Upstream::ClusterInfo::Features::HTTP2));\n  }\n\n  void allocHealthChecker(const envoy::config::core::v3::HealthCheck& config) {\n    health_checker_ = std::make_shared<TestGrpcHealthCheckerImpl>(\n        *cluster_, config, dispatcher_, runtime_, random_,\n        HealthCheckEventLoggerPtr(event_logger_storage_.release()));\n  }\n\n  void addCompletionCallback() {\n    health_checker_->addHostCheckCompleteCb(\n        [this](HostSharedPtr host, HealthTransition changed_state) -> void {\n          onHostStatus(host, changed_state);\n        });\n  }\n\n  void setupHC() {\n    const auto config = createGrpcHealthCheckConfig();\n    allocHealthChecker(config);\n    addCompletionCallback();\n  }\n\n  void setupHCWithUnhealthyThreshold(int value) {\n    auto config = createGrpcHealthCheckConfig();\n    config.mutable_unhealthy_threshold()->set_value(value);\n    allocHealthChecker(config);\n    addCompletionCallback();\n  }\n\n  void setupServiceNameHC(const absl::optional<std::string>& authority) {\n    auto config = createGrpcHealthCheckConfig();\n    config.mutable_grpc_health_check()->set_service_name(\"service\");\n    if (authority.has_value()) {\n      config.mutable_grpc_health_check()->set_authority(authority.value());\n    }\n    allocHealthChecker(config);\n    addCompletionCallback();\n  }\n\n  void setupHCWithHeaders(const absl::flat_hash_map<std::string, std::string> headers_to_add) {\n    auto config = createGrpcHealthCheckConfig();\n    config.mutable_grpc_health_check()->set_service_name(\"service\");\n    for (const auto& pair : headers_to_add) {\n      auto header_value_option = config.mutable_grpc_health_check()->add_initial_metadata();\n      header_value_option->mutable_append()->set_value(false);\n      auto header = header_value_option->mutable_header();\n      header->set_key(pair.first);\n      header->set_value(pair.second);\n    }\n    allocHealthChecker(config);\n    addCompletionCallback();\n  }\n\n  void setupNoReuseConnectionHC() {\n    auto config = createGrpcHealthCheckConfig();\n    config.mutable_reuse_connection()->set_value(false);\n    allocHealthChecker(config);\n    addCompletionCallback();\n  }\n\n  void setupHealthCheckIntervalOverridesHC() {\n    auto config = createGrpcHealthCheckConfig();\n    config.mutable_interval()->set_seconds(1);\n    config.mutable_unhealthy_interval()->set_seconds(2);\n    config.mutable_unhealthy_edge_interval()->set_seconds(3);\n    config.mutable_healthy_edge_interval()->set_seconds(4);\n    config.mutable_no_traffic_interval()->set_seconds(5);\n    config.mutable_interval_jitter()->set_seconds(0);\n    config.mutable_unhealthy_threshold()->set_value(3);\n    config.mutable_healthy_threshold()->set_value(3);\n    allocHealthChecker(config);\n    addCompletionCallback();\n  }\n\n  void expectSessionCreate() {\n    // Expectations are in LIFO order.\n    TestSessionPtr new_test_session(new TestSession());\n    new_test_session->timeout_timer_ = new Event::MockTimer(&dispatcher_);\n    new_test_session->interval_timer_ = new Event::MockTimer(&dispatcher_);\n    test_sessions_.emplace_back(std::move(new_test_session));\n    expectClientCreate(test_sessions_.size() - 1);\n  }\n\n  void expectClientCreate(size_t index) {\n    TestSession& test_session = *test_sessions_[index];\n    test_session.codec_ = new NiceMock<Http::MockClientConnection>();\n    test_session.client_connection_ = new NiceMock<Network::MockClientConnection>();\n    connection_index_.push_back(index);\n    codec_index_.push_back(index);\n\n    EXPECT_CALL(dispatcher_, createClientConnection_(_, _, _, _))\n        .Times(testing::AnyNumber())\n        .WillRepeatedly(InvokeWithoutArgs([&]() -> Network::ClientConnection* {\n          const uint32_t index = connection_index_.front();\n          connection_index_.pop_front();\n          return test_sessions_[index]->client_connection_;\n        }));\n\n    EXPECT_CALL(*health_checker_, createCodecClient_(_))\n        .WillRepeatedly(\n            Invoke([&](Upstream::Host::CreateConnectionData& conn_data) -> Http::CodecClient* {\n              const uint32_t index = codec_index_.front();\n              codec_index_.pop_front();\n              TestSession& test_session = *test_sessions_[index];\n              std::shared_ptr<Upstream::MockClusterInfo> cluster{\n                  new NiceMock<Upstream::MockClusterInfo>()};\n              Event::MockDispatcher dispatcher_;\n\n              test_session.codec_client_ = new CodecClientForTest(\n                  Http::CodecType::HTTP1, std::move(conn_data.connection_), test_session.codec_,\n                  nullptr, Upstream::makeTestHost(cluster, \"tcp://127.0.0.1:9000\", simTime()),\n                  dispatcher_);\n              return test_session.codec_client_;\n            }));\n  }\n\n  void expectStreamCreate(size_t index) {\n    test_sessions_[index]->request_encoder_.stream_.callbacks_.clear();\n    EXPECT_CALL(*test_sessions_[index]->codec_, newStream(_))\n        .WillOnce(DoAll(SaveArgAddress(&test_sessions_[index]->stream_response_callbacks_),\n                        ReturnRef(test_sessions_[index]->request_encoder_)));\n  }\n\n  // Starts healthchecker and sets up timer expectations, leaving up future specification of\n  // healthcheck response for the caller. Useful when there is only one healthcheck attempt\n  // performed during test case (but possibly on many hosts).\n  void expectHealthchecks(HealthTransition host_changed_state, size_t num_healthchecks) {\n    for (size_t i = 0; i < num_healthchecks; i++) {\n      cluster_->info_->stats().upstream_cx_total_.inc();\n      expectSessionCreate();\n      expectHealthcheckStart(i);\n    }\n    health_checker_->start();\n\n    EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.max_interval\", _))\n        .Times(num_healthchecks);\n    EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.min_interval\", _))\n        .Times(num_healthchecks)\n        .WillRepeatedly(Return(45000));\n    for (size_t i = 0; i < num_healthchecks; i++) {\n      expectHealthcheckStop(i, 45000);\n    }\n    EXPECT_CALL(*this, onHostStatus(_, host_changed_state)).Times(num_healthchecks);\n  }\n\n  void expectSingleHealthcheck(HealthTransition host_changed_state) {\n    cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n        makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n    expectHealthchecks(host_changed_state, 1);\n  }\n\n  // Hides timer/stream-related boilerplate of healthcheck start.\n  void expectHealthcheckStart(size_t index) {\n    expectStreamCreate(index);\n    EXPECT_CALL(*test_sessions_[index]->timeout_timer_, enableTimer(_, _));\n  }\n\n  // Hides timer-related boilerplate of healthcheck stop.\n  void expectHealthcheckStop(size_t index, int interval_ms = 0) {\n    if (interval_ms > 0) {\n      EXPECT_CALL(*test_sessions_[index]->interval_timer_,\n                  enableTimer(std::chrono::milliseconds(interval_ms), _));\n    } else {\n      EXPECT_CALL(*test_sessions_[index]->interval_timer_, enableTimer(_, _));\n    }\n    EXPECT_CALL(*test_sessions_[index]->timeout_timer_, disableTimer());\n  }\n\n  // Hides host status checking boilerplate when only single host is used in test.\n  void expectHostHealthy(bool healthy) {\n    const auto host = cluster_->prioritySet().getMockHostSet(0)->hosts_[0];\n    if (!healthy) {\n      EXPECT_TRUE(host->healthFlagGet(Host::HealthFlag::FAILED_ACTIVE_HC));\n      EXPECT_EQ(Host::Health::Unhealthy, host->health());\n    } else {\n      EXPECT_EQ(Host::Health::Healthy, host->health());\n    }\n  }\n\n  void respondServiceStatus(size_t index,\n                            grpc::health::v1::HealthCheckResponse::ServingStatus status) {\n    respondResponseSpec(index,\n                        ResponseSpec{{{\":status\", \"200\"}, {\"content-type\", \"application/grpc\"}},\n                                     {ResponseSpec::validChunk(status)},\n                                     {{\"grpc-status\", \"0\"}}});\n  }\n\n  void respondResponseSpec(size_t index, ResponseSpec&& spec) {\n    const bool trailers_empty = spec.trailers.empty();\n    const bool end_stream_on_headers = spec.body_chunks.empty() && trailers_empty;\n    auto response_headers = std::make_unique<Http::TestResponseHeaderMapImpl>();\n    for (const auto& header : spec.response_headers) {\n      response_headers->addCopy(header.first, header.second);\n    }\n    test_sessions_[index]->stream_response_callbacks_->decodeHeaders(std::move(response_headers),\n                                                                     end_stream_on_headers);\n    for (size_t i = 0; i < spec.body_chunks.size(); i++) {\n      const bool end_stream = i == spec.body_chunks.size() - 1 && trailers_empty;\n      const auto& chunk = spec.body_chunks[i];\n      if (chunk.valid) {\n        const auto data = std::make_unique<Buffer::OwnedImpl>(chunk.data.data(), chunk.data.size());\n        test_sessions_[index]->stream_response_callbacks_->decodeData(*data, end_stream);\n      } else {\n        Buffer::OwnedImpl incorrect_data(\"incorrect\");\n        test_sessions_[index]->stream_response_callbacks_->decodeData(incorrect_data, end_stream);\n      }\n    }\n    if (!trailers_empty) {\n      auto trailers = std::make_unique<Http::TestResponseTrailerMapImpl>();\n      for (const auto& header : spec.trailers) {\n        trailers->addCopy(header.first, header.second);\n      }\n      test_sessions_[index]->stream_response_callbacks_->decodeTrailers(std::move(trailers));\n    }\n  }\n\n  void testSingleHostSuccess(const absl::optional<std::string>& authority) {\n    std::string expected_host = cluster_->info_->name();\n    if (authority.has_value()) {\n      expected_host = authority.value();\n    }\n\n    setupServiceNameHC(authority);\n\n    cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n        makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n    runHealthCheck(expected_host);\n  }\n\n  void runHealthCheck(std::string expected_host) {\n\n    cluster_->info_->stats().upstream_cx_total_.inc();\n\n    expectSessionCreate();\n    expectHealthcheckStart(0);\n\n    EXPECT_CALL(test_sessions_[0]->request_encoder_, encodeHeaders(_, false))\n        .WillOnce(Invoke([&](const Http::RequestHeaderMap& headers, bool) -> Http::Status {\n          EXPECT_EQ(Http::Headers::get().ContentTypeValues.Grpc, headers.getContentTypeValue());\n          EXPECT_EQ(std::string(\"/grpc.health.v1.Health/Check\"), headers.getPathValue());\n          EXPECT_EQ(Http::Headers::get().SchemeValues.Http, headers.getSchemeValue());\n          EXPECT_NE(nullptr, headers.Method());\n          EXPECT_EQ(expected_host, headers.getHostValue());\n          EXPECT_EQ(std::chrono::milliseconds(1000).count(),\n                    Envoy::Grpc::Common::getGrpcTimeout(headers).value().count());\n          return Http::okStatus();\n        }));\n    EXPECT_CALL(test_sessions_[0]->request_encoder_, encodeData(_, true))\n        .WillOnce(Invoke([&](Buffer::Instance& data, bool) {\n          std::vector<Grpc::Frame> decoded_frames;\n          Grpc::Decoder decoder;\n          ASSERT_TRUE(decoder.decode(data, decoded_frames));\n          ASSERT_EQ(1U, decoded_frames.size());\n          auto& frame = decoded_frames[0];\n          Buffer::ZeroCopyInputStreamImpl stream(std::move(frame.data_));\n          grpc::health::v1::HealthCheckRequest request;\n          ASSERT_TRUE(request.ParseFromZeroCopyStream(&stream));\n          EXPECT_EQ(\"service\", request.service());\n        }));\n    health_checker_->start();\n\n    EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.max_interval\", _));\n    EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.min_interval\", _))\n        .WillOnce(Return(45000));\n    expectHealthcheckStop(0, 45000);\n\n    // Host state should not be changed (remains healthy).\n    EXPECT_CALL(*this, onHostStatus(cluster_->prioritySet().getMockHostSet(0)->hosts_[0],\n                                    HealthTransition::Unchanged));\n    respondServiceStatus(0, grpc::health::v1::HealthCheckResponse::SERVING);\n    expectHostHealthy(true);\n  }\n\n  MOCK_METHOD(void, onHostStatus, (HostSharedPtr host, HealthTransition changed_state));\n\n  std::vector<TestSessionPtr> test_sessions_;\n  std::shared_ptr<TestGrpcHealthCheckerImpl> health_checker_;\n  std::list<uint32_t> connection_index_{};\n  std::list<uint32_t> codec_index_{};\n};\n\n// NOLINTNEXTLINE(readability-identifier-naming)\nvoid PrintTo(const GrpcHealthCheckerImplTestBase::ResponseSpec& spec, std::ostream* os) {\n  (*os) << \"(headers{\" << absl::StrJoin(spec.response_headers, \",\", absl::PairFormatter(\":\"))\n        << \"},\";\n  (*os) << \"body{\" << absl::StrJoin(spec.body_chunks, \",\", [](std::string* out, const auto& spec) {\n    absl::StrAppend(out, spec.valid ? \"valid\" : \"invalid\", \",{\",\n                    absl::StrJoin(spec.data, \"-\",\n                                  [](std::string* out, uint8_t byte) {\n                                    absl::StrAppend(out, absl::Hex(byte, absl::kZeroPad2));\n                                  }),\n                    \"}\");\n  }) << \"}\";\n  (*os) << \"trailers{\" << absl::StrJoin(spec.trailers, \",\", absl::PairFormatter(\":\")) << \"})\";\n}\n\nclass GrpcHealthCheckerImplTest : public testing::Test, public GrpcHealthCheckerImplTestBase {};\n\n// Test single host check success.\nTEST_F(GrpcHealthCheckerImplTest, Success) { testSingleHostSuccess(absl::nullopt); }\n\nTEST_F(GrpcHealthCheckerImplTest, SuccessWithHostname) {\n  std::string expected_host = \"www.envoyproxy.io\";\n\n  setupServiceNameHC(absl::nullopt);\n\n  envoy::config::endpoint::v3::Endpoint::HealthCheckConfig health_check_config;\n  health_check_config.set_hostname(expected_host);\n  auto test_host = std::make_shared<HostImpl>(\n      cluster_->info_, \"\", Network::Utility::resolveUrl(\"tcp://127.0.0.1:80\"), nullptr, 1,\n      envoy::config::core::v3::Locality(), health_check_config, 0, envoy::config::core::v3::UNKNOWN,\n      simTime());\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {test_host};\n  runHealthCheck(expected_host);\n}\n\nTEST_F(GrpcHealthCheckerImplTest, SuccessWithHostnameOverridesConfig) {\n  std::string expected_host = \"www.envoyproxy.io\";\n\n  setupServiceNameHC(\"foo.com\");\n\n  envoy::config::endpoint::v3::Endpoint::HealthCheckConfig health_check_config;\n  health_check_config.set_hostname(expected_host);\n  auto test_host = std::make_shared<HostImpl>(\n      cluster_->info_, \"\", Network::Utility::resolveUrl(\"tcp://127.0.0.1:80\"), nullptr, 1,\n      envoy::config::core::v3::Locality(), health_check_config, 0, envoy::config::core::v3::UNKNOWN,\n      simTime());\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {test_host};\n  runHealthCheck(expected_host);\n}\n\n// Test single host check success with custom authority.\nTEST_F(GrpcHealthCheckerImplTest, SuccessWithCustomAuthority) {\n  const std::string authority = \"www.envoyproxy.io\";\n  testSingleHostSuccess(authority);\n}\n\n// Test single host check success with additional headers.\nTEST_F(GrpcHealthCheckerImplTest, SuccessWithAdditionalHeaders) {\n  const std::string ENVOY_OK_KEY = \"x-envoy-ok\";\n  const std::string ENVOY_OK_VAL = \"ok\";\n  const std::string ENVOY_COOL_KEY = \"x-envoy-cool\";\n  const std::string ENVOY_COOL_VAL = \"cool\";\n  const std::string ENVOY_AWESOME_KEY = \"x-envoy-awesome\";\n  const std::string ENVOY_AWESOME_VAL = \"awesome\";\n  const std::string USER_AGENT_KEY = \"user-agent\";\n  const std::string USER_AGENT_VAL = \"CoolEnvoy/HC\";\n  const std::string PROTOCOL_KEY = \"x-protocol\";\n  const std::string PROTOCOL_VAL = \"%PROTOCOL%\";\n  const std::string DOWNSTREAM_LOCAL_ADDRESS_KEY = \"x-downstream-local-address\";\n  const std::string DOWNSTREAM_LOCAL_ADDRESS_WITHOUT_PORT_KEY =\n      \"x-downstream-local-address-without-port\";\n  const std::string DOWNSTREAM_REMOTE_ADDRESS_KEY = \"x-downstream-remote-address\";\n  const std::string DOWNSTREAM_REMOTE_ADDRESS_WITHOUT_PORT_KEY =\n      \"x-downstream-remote-address-without-port\";\n  const std::string START_TIME_KEY = \"x-start-time\";\n  const std::string UPSTREAM_METADATA_KEY = \"x-upstream-metadata\";\n\n  setupHCWithHeaders(\n      {{ENVOY_OK_KEY, ENVOY_OK_VAL},\n       {ENVOY_COOL_KEY, ENVOY_COOL_VAL},\n       {ENVOY_AWESOME_KEY, ENVOY_AWESOME_VAL},\n       {USER_AGENT_KEY, USER_AGENT_VAL},\n       {PROTOCOL_KEY, PROTOCOL_VAL},\n       {DOWNSTREAM_LOCAL_ADDRESS_KEY, \"%DOWNSTREAM_LOCAL_ADDRESS%\"},\n       {DOWNSTREAM_LOCAL_ADDRESS_WITHOUT_PORT_KEY, \"%DOWNSTREAM_LOCAL_ADDRESS_WITHOUT_PORT%\"},\n       {DOWNSTREAM_REMOTE_ADDRESS_KEY, \"%DOWNSTREAM_REMOTE_ADDRESS%\"},\n       {DOWNSTREAM_REMOTE_ADDRESS_WITHOUT_PORT_KEY, \"%DOWNSTREAM_REMOTE_ADDRESS_WITHOUT_PORT%\"},\n       {START_TIME_KEY, \"%START_TIME(%s.%9f)%\"},\n       {UPSTREAM_METADATA_KEY, \"%UPSTREAM_METADATA([\\\"namespace\\\", \\\"key\\\"])%\"}});\n\n  auto metadata = TestUtility::parseYaml<envoy::config::core::v3::Metadata>(\n      R\"EOF(\n        filter_metadata:\n          namespace:\n            key: value\n      )EOF\");\n\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", metadata, simTime())};\n\n  cluster_->info_->stats().upstream_cx_total_.inc();\n\n  expectSessionCreate();\n  expectHealthcheckStart(0);\n\n  EXPECT_CALL(test_sessions_[0]->request_encoder_, encodeHeaders(_, false))\n      .WillOnce(Invoke([&](const Http::RequestHeaderMap& headers, bool) -> Http::Status {\n        EXPECT_EQ(Http::Headers::get().ContentTypeValues.Grpc, headers.getContentTypeValue());\n        EXPECT_EQ(std::string(\"/grpc.health.v1.Health/Check\"), headers.getPathValue());\n        EXPECT_EQ(Http::Headers::get().SchemeValues.Http, headers.getSchemeValue());\n        EXPECT_NE(nullptr, headers.Method());\n        EXPECT_EQ(cluster_->info_->name(), headers.getHostValue());\n        EXPECT_EQ(ENVOY_OK_VAL,\n                  headers.get(Http::LowerCaseString(ENVOY_OK_KEY))[0]->value().getStringView());\n        EXPECT_EQ(ENVOY_COOL_VAL,\n                  headers.get(Http::LowerCaseString(ENVOY_COOL_KEY))[0]->value().getStringView());\n        EXPECT_EQ(\n            ENVOY_AWESOME_VAL,\n            headers.get(Http::LowerCaseString(ENVOY_AWESOME_KEY))[0]->value().getStringView());\n        EXPECT_EQ(USER_AGENT_VAL, headers.getUserAgentValue());\n        EXPECT_EQ(\"HTTP/2\",\n                  headers.get(Http::LowerCaseString(PROTOCOL_KEY))[0]->value().getStringView());\n        EXPECT_EQ(\"127.0.0.1:0\",\n                  headers.get(Http::LowerCaseString(DOWNSTREAM_LOCAL_ADDRESS_KEY))[0]\n                      ->value()\n                      .getStringView());\n        EXPECT_EQ(\"127.0.0.1\",\n                  headers.get(Http::LowerCaseString(DOWNSTREAM_LOCAL_ADDRESS_WITHOUT_PORT_KEY))[0]\n                      ->value()\n                      .getStringView());\n        EXPECT_EQ(\"127.0.0.1:0\",\n                  headers.get(Http::LowerCaseString(DOWNSTREAM_REMOTE_ADDRESS_KEY))[0]\n                      ->value()\n                      .getStringView());\n        EXPECT_EQ(\"127.0.0.1\",\n                  headers.get(Http::LowerCaseString(DOWNSTREAM_REMOTE_ADDRESS_WITHOUT_PORT_KEY))[0]\n                      ->value()\n                      .getStringView());\n        Envoy::DateFormatter date_formatter(\"%s.%9f\");\n        std::string current_start_time =\n            date_formatter.fromTime(dispatcher_.timeSource().systemTime());\n        EXPECT_EQ(current_start_time,\n                  headers.get(Http::LowerCaseString(START_TIME_KEY))[0]->value().getStringView());\n        EXPECT_EQ(\n            \"value\",\n            headers.get(Http::LowerCaseString(UPSTREAM_METADATA_KEY))[0]->value().getStringView());\n        EXPECT_EQ(std::chrono::milliseconds(1000).count(),\n                  Envoy::Grpc::Common::getGrpcTimeout(headers).value().count());\n        return Http::okStatus();\n      }));\n  EXPECT_CALL(test_sessions_[0]->request_encoder_, encodeData(_, true))\n      .WillOnce(Invoke([&](Buffer::Instance& data, bool) {\n        std::vector<Grpc::Frame> decoded_frames;\n        Grpc::Decoder decoder;\n        ASSERT_TRUE(decoder.decode(data, decoded_frames));\n        ASSERT_EQ(1U, decoded_frames.size());\n        auto& frame = decoded_frames[0];\n        Buffer::ZeroCopyInputStreamImpl stream(std::move(frame.data_));\n        grpc::health::v1::HealthCheckRequest request;\n        ASSERT_TRUE(request.ParseFromZeroCopyStream(&stream));\n        EXPECT_EQ(\"service\", request.service());\n      }));\n\n  health_checker_->start();\n\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.max_interval\", _));\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.min_interval\", _))\n      .WillOnce(Return(45000));\n  expectHealthcheckStop(0, 45000);\n\n  // Host state should not be changed (remains healthy).\n  EXPECT_CALL(*this, onHostStatus(cluster_->prioritySet().getMockHostSet(0)->hosts_[0],\n                                  HealthTransition::Unchanged));\n  respondServiceStatus(0, grpc::health::v1::HealthCheckResponse::SERVING);\n  expectHostHealthy(true);\n}\n\n// Test host check success when gRPC response payload is split between several incoming data chunks.\nTEST_F(GrpcHealthCheckerImplTest, SuccessResponseSplitBetweenChunks) {\n  setupServiceNameHC(absl::nullopt);\n  expectSingleHealthcheck(HealthTransition::Unchanged);\n\n  auto response_headers = std::make_unique<Http::TestResponseHeaderMapImpl>(\n      std::initializer_list<std::pair<std::string, std::string>>{\n          {\":status\", \"200\"},\n          {\"content-type\", \"application/grpc\"},\n      });\n  test_sessions_[0]->stream_response_callbacks_->decodeHeaders(std::move(response_headers), false);\n\n  grpc::health::v1::HealthCheckResponse response;\n  response.set_status(grpc::health::v1::HealthCheckResponse::SERVING);\n  auto data = Grpc::Common::serializeToGrpcFrame(response);\n\n  const char* raw_data = static_cast<char*>(data->linearize(data->length()));\n  const uint64_t chunk_size = data->length() / 5;\n  for (uint64_t offset = 0; offset < data->length(); offset += chunk_size) {\n    const uint64_t effective_size = std::min(chunk_size, data->length() - offset);\n    const auto chunk = std::make_unique<Buffer::OwnedImpl>(raw_data + offset, effective_size);\n    test_sessions_[0]->stream_response_callbacks_->decodeData(*chunk, false);\n  }\n\n  auto trailers = std::make_unique<Http::TestResponseTrailerMapImpl>(\n      std::initializer_list<std::pair<std::string, std::string>>{{\"grpc-status\", \"0\"}});\n  test_sessions_[0]->stream_response_callbacks_->decodeTrailers(std::move(trailers));\n\n  expectHostHealthy(true);\n}\n\n// Test host check success with multiple hosts.\nTEST_F(GrpcHealthCheckerImplTest, SuccessWithMultipleHosts) {\n  setupHC();\n\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime()),\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:81\", simTime())};\n\n  expectHealthchecks(HealthTransition::Unchanged, 2);\n\n  respondServiceStatus(0, grpc::health::v1::HealthCheckResponse::SERVING);\n  respondServiceStatus(1, grpc::health::v1::HealthCheckResponse::SERVING);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[1]->health());\n}\n\n// Test host check success with multiple hosts across multiple priorities.\nTEST_F(GrpcHealthCheckerImplTest, SuccessWithMultipleHostSets) {\n  setupHC();\n\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  cluster_->prioritySet().getMockHostSet(1)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:81\", simTime())};\n\n  expectHealthchecks(HealthTransition::Unchanged, 2);\n\n  respondServiceStatus(0, grpc::health::v1::HealthCheckResponse::SERVING);\n  respondServiceStatus(1, grpc::health::v1::HealthCheckResponse::SERVING);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(1)->hosts_[0]->health());\n}\n\n// Test stream-level watermarks does not interfere with health check.\nTEST_F(GrpcHealthCheckerImplTest, StreamReachesWatermarkDuringCheck) {\n  setupHC();\n  expectSingleHealthcheck(HealthTransition::Unchanged);\n\n  test_sessions_[0]->request_encoder_.stream_.runHighWatermarkCallbacks();\n  test_sessions_[0]->request_encoder_.stream_.runLowWatermarkCallbacks();\n\n  respondServiceStatus(0, grpc::health::v1::HealthCheckResponse::SERVING);\n  expectHostHealthy(true);\n}\n\n// Test connection-level watermarks does not interfere with health check.\nTEST_F(GrpcHealthCheckerImplTest, ConnectionReachesWatermarkDuringCheck) {\n  setupHC();\n  expectSingleHealthcheck(HealthTransition::Unchanged);\n\n  test_sessions_[0]->client_connection_->runHighWatermarkCallbacks();\n  test_sessions_[0]->client_connection_->runLowWatermarkCallbacks();\n\n  respondServiceStatus(0, grpc::health::v1::HealthCheckResponse::SERVING);\n  expectHostHealthy(true);\n}\n\n// Test health check on host without traffic sets larger unconfigurable interval for the next check.\nTEST_F(GrpcHealthCheckerImplTest, SuccessNoTraffic) {\n  setupHC();\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n\n  expectSessionCreate();\n  expectHealthcheckStart(0);\n  health_checker_->start();\n\n  // Default healthcheck interval for hosts without traffic is 60 seconds.\n  expectHealthcheckStop(0, 60000);\n  // Host state should not be changed (remains healthy).\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n  respondServiceStatus(0, grpc::health::v1::HealthCheckResponse::SERVING);\n  expectHostHealthy(true);\n}\n\n// Test first successful check immediately makes failed host available (without 2nd probe).\nTEST_F(GrpcHealthCheckerImplTest, SuccessStartFailedSuccessFirst) {\n  setupHC();\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthFlagSet(\n      Host::HealthFlag::FAILED_ACTIVE_HC);\n  cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthFlagSet(\n      Host::HealthFlag::PENDING_ACTIVE_HC);\n\n  expectSessionCreate();\n  expectHealthcheckStart(0);\n  health_checker_->start();\n\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.max_interval\", _)).WillOnce(Return(500));\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.min_interval\", _));\n  expectHealthcheckStop(0, 500);\n  // Fast success immediately moves us to healthy.\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Changed));\n  EXPECT_CALL(event_logger_, logAddHealthy(_, _, true));\n  respondServiceStatus(0, grpc::health::v1::HealthCheckResponse::SERVING);\n  expectHostHealthy(true);\n  EXPECT_FALSE(cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthFlagGet(\n      Host::HealthFlag::PENDING_ACTIVE_HC));\n}\n\n// Test host recovery after first failed check requires several successful checks.\nTEST_F(GrpcHealthCheckerImplTest, SuccessStartFailedFailFirst) {\n  setupHC();\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthFlagSet(\n      Host::HealthFlag::FAILED_ACTIVE_HC);\n  cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthFlagSet(\n      Host::HealthFlag::PENDING_ACTIVE_HC);\n\n  expectSessionCreate();\n  expectHealthcheckStart(0);\n  health_checker_->start();\n\n  // Failing first disables fast success.\n  expectHealthcheckStop(0);\n  // Host was unhealthy from the start, but we expect a state change due to the pending active hc\n  // flag changing.\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Changed));\n  EXPECT_CALL(event_logger_, logUnhealthy(_, _, _, true));\n  respondServiceStatus(0, grpc::health::v1::HealthCheckResponse::NOT_SERVING);\n  expectHostHealthy(false);\n  EXPECT_FALSE(cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthFlagGet(\n      Host::HealthFlag::PENDING_ACTIVE_HC));\n\n  // Next successful healthcheck does not move host int healthy state (because we configured\n  // healthchecker this way).\n  expectHealthcheckStart(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  expectHealthcheckStop(0);\n  // Host still unhealthy, need yet another healthcheck.\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::ChangePending));\n  respondServiceStatus(0, grpc::health::v1::HealthCheckResponse::SERVING);\n  expectHostHealthy(false);\n\n  // 2nd successful healthcheck renders host healthy.\n  expectHealthcheckStart(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  expectHealthcheckStop(0);\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Changed));\n  EXPECT_CALL(event_logger_, logAddHealthy(_, _, false));\n  respondServiceStatus(0, grpc::health::v1::HealthCheckResponse::SERVING);\n  expectHostHealthy(true);\n}\n\n// Test host recovery after explicit check failure requires several successful checks.\nTEST_F(GrpcHealthCheckerImplTest, GrpcHealthFail) {\n  setupHC();\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n\n  expectSessionCreate();\n  expectHealthcheckStart(0);\n  EXPECT_CALL(event_logger_, logUnhealthy(_, _, _, true));\n  health_checker_->start();\n\n  // Explicit healthcheck failure immediately renders host unhealthy.\n  expectHealthcheckStop(0);\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Changed));\n  EXPECT_CALL(event_logger_, logEjectUnhealthy(_, _, _));\n  respondServiceStatus(0, grpc::health::v1::HealthCheckResponse::NOT_SERVING);\n  expectHostHealthy(false);\n\n  // Next, we need 2 successful checks for host to become available again.\n  expectHealthcheckStart(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  expectHealthcheckStop(0);\n  // Host still considered unhealthy.\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::ChangePending));\n  respondServiceStatus(0, grpc::health::v1::HealthCheckResponse::SERVING);\n  expectHostHealthy(false);\n\n  expectHealthcheckStart(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  expectHealthcheckStop(0);\n  // Host should has become healthy.\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Changed));\n  EXPECT_CALL(event_logger_, logAddHealthy(_, _, false));\n  respondServiceStatus(0, grpc::health::v1::HealthCheckResponse::SERVING);\n  expectHostHealthy(true);\n}\n\n// Test disconnects produce network-type failures which does not lead to immediate unhealthy state.\nTEST_F(GrpcHealthCheckerImplTest, Disconnect) {\n  setupHC();\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n\n  expectSessionCreate();\n  expectHealthcheckStart(0);\n  EXPECT_CALL(event_logger_, logUnhealthy(_, _, _, true));\n  health_checker_->start();\n\n  expectHealthcheckStop(0);\n  // Network-type healthcheck failure should make host unhealthy only after 2nd event in a row.\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::ChangePending));\n  test_sessions_[0]->client_connection_->raiseEvent(Network::ConnectionEvent::RemoteClose);\n  expectHostHealthy(true);\n\n  expectClientCreate(0);\n  expectHealthcheckStart(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  expectHealthcheckStop(0);\n  // Now, host should be unhealthy.\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Changed));\n  EXPECT_CALL(event_logger_, logEjectUnhealthy(_, _, _));\n  test_sessions_[0]->client_connection_->raiseEvent(Network::ConnectionEvent::RemoteClose);\n  expectHostHealthy(false);\n}\n\nTEST_F(GrpcHealthCheckerImplTest, Timeout) {\n  setupHCWithUnhealthyThreshold(1);\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  expectSessionCreate();\n\n  expectHealthcheckStart(0);\n  EXPECT_CALL(event_logger_, logUnhealthy(_, _, _, true));\n  health_checker_->start();\n\n  expectHealthcheckStop(0);\n  // Unhealthy threshold is 1 so first timeout causes unhealthy\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Changed));\n  EXPECT_CALL(event_logger_, logEjectUnhealthy(_, _, _));\n  test_sessions_[0]->timeout_timer_->invokeCallback();\n  expectHostHealthy(false);\n}\n\n// Test timeouts produce network-type failures which does not lead to immediate unhealthy state.\nTEST_F(GrpcHealthCheckerImplTest, DoubleTimeout) {\n  setupHC();\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  expectSessionCreate();\n\n  expectHealthcheckStart(0);\n  EXPECT_CALL(event_logger_, logUnhealthy(_, _, _, true));\n  health_checker_->start();\n\n  expectHealthcheckStop(0);\n  // Timeouts are considered network failures and make host unhealthy also after 2nd event.\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::ChangePending));\n  test_sessions_[0]->timeout_timer_->invokeCallback();\n  expectHostHealthy(true);\n\n  expectHealthcheckStart(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  expectHealthcheckStop(0);\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Changed));\n  EXPECT_CALL(event_logger_, logEjectUnhealthy(_, _, _));\n  // Close connection. Timeouts and connection closes counts together.\n  test_sessions_[0]->client_connection_->raiseEvent(Network::ConnectionEvent::RemoteClose);\n  expectHostHealthy(false);\n}\n\n// Test adding and removal of hosts starts and closes healthcheck sessions.\nTEST_F(GrpcHealthCheckerImplTest, DynamicAddAndRemove) {\n  setupHC();\n  health_checker_->start();\n\n  expectSessionCreate();\n  expectStreamCreate(0);\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  cluster_->prioritySet().getMockHostSet(0)->runCallbacks(\n      {cluster_->prioritySet().getMockHostSet(0)->hosts_.back()}, {});\n\n  HostVector removed{cluster_->prioritySet().getMockHostSet(0)->hosts_.back()};\n  cluster_->prioritySet().getMockHostSet(0)->hosts_.clear();\n  EXPECT_CALL(*test_sessions_[0]->client_connection_, close(_));\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n  cluster_->prioritySet().getMockHostSet(0)->runCallbacks({}, removed);\n}\n\nTEST_F(GrpcHealthCheckerImplTest, HealthCheckIntervals) {\n  setupHealthCheckIntervalOverridesHC();\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://128.0.0.1:80\", simTime())};\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n\n  // First check should respect no_traffic_interval setting.\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(std::chrono::milliseconds(5000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  respondServiceStatus(0, grpc::health::v1::HealthCheckResponse::SERVING);\n  cluster_->info_->stats().upstream_cx_total_.inc();\n\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  // Needed after a response is sent.\n  expectStreamCreate(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  // Follow up successful checks should respect interval setting.\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(std::chrono::milliseconds(1000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  respondServiceStatus(0, grpc::health::v1::HealthCheckResponse::SERVING);\n\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  // Needed after a response is sent.\n  expectStreamCreate(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  // Follow up successful checks should respect interval setting.\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(std::chrono::milliseconds(1000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  respondServiceStatus(0, grpc::health::v1::HealthCheckResponse::SERVING);\n\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  // Needed after a response is sent.\n  expectStreamCreate(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  // A logical failure is not considered a network failure, therefore the unhealthy threshold is\n  // ignored and health state changes immediately. Since the threshold is ignored, next health\n  // check respects \"unhealthy_interval\".\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Changed));\n  EXPECT_CALL(event_logger_, logEjectUnhealthy(_, _, _));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(std::chrono::milliseconds(2000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  respondServiceStatus(0, grpc::health::v1::HealthCheckResponse::NOT_SERVING);\n\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  // Needed after a response is sent.\n  expectStreamCreate(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  // Subsequent failing checks should respect unhealthy_interval.\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(std::chrono::milliseconds(2000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  respondServiceStatus(0, grpc::health::v1::HealthCheckResponse::NOT_SERVING);\n\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  // Needed after a response is sent.\n  expectStreamCreate(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  // Subsequent failing checks should respect unhealthy_interval.\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(std::chrono::milliseconds(2000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  respondServiceStatus(0, grpc::health::v1::HealthCheckResponse::NOT_SERVING);\n\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  // Needed after a response is sent.\n  expectStreamCreate(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  // When transitioning to a successful state, checks should respect healthy_edge_interval. Health\n  // state should be delayed pending healthy threshold.\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::ChangePending));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(std::chrono::milliseconds(4000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  respondServiceStatus(0, grpc::health::v1::HealthCheckResponse::SERVING);\n\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  // Needed after a response is sent.\n  expectStreamCreate(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::ChangePending));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(std::chrono::milliseconds(4000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  respondServiceStatus(0, grpc::health::v1::HealthCheckResponse::SERVING);\n\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  // Needed after a response is sent.\n  expectStreamCreate(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  // After the healthy threshold is reached, health state should change while checks should respect\n  // the default interval.\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Changed));\n  EXPECT_CALL(event_logger_, logAddHealthy(_, _, false));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(std::chrono::milliseconds(1000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  respondServiceStatus(0, grpc::health::v1::HealthCheckResponse::SERVING);\n\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  // Needed after a response is sent.\n  expectStreamCreate(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  // Subsequent checks shouldn't change the state.\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(std::chrono::milliseconds(1000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  respondServiceStatus(0, grpc::health::v1::HealthCheckResponse::SERVING);\n\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  // Needed after a response is sent.\n  expectStreamCreate(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  // First failed check after a run o successful ones should respect unhealthy_edge_interval. A\n  // timeout, being a network type failure, should respect unhealthy threshold before changing the\n  // health state.\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::ChangePending));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(std::chrono::milliseconds(3000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  test_sessions_[0]->timeout_timer_->invokeCallback();\n\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  // Needed after a response is sent.\n  expectStreamCreate(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::ChangePending));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(std::chrono::milliseconds(3000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  test_sessions_[0]->timeout_timer_->invokeCallback();\n\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  // Needed after a response is sent.\n  expectStreamCreate(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  // Subsequent failing checks should respect unhealthy_interval. As the unhealthy threshold is\n  // reached, health state should also change.\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Changed));\n  EXPECT_CALL(event_logger_, logEjectUnhealthy(_, _, _));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(std::chrono::milliseconds(2000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  test_sessions_[0]->timeout_timer_->invokeCallback();\n\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  // Needed after a response is sent.\n  expectStreamCreate(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  // Remaining failing checks shouldn't change the state.\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(std::chrono::milliseconds(2000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  test_sessions_[0]->timeout_timer_->invokeCallback();\n\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  // Needed after a response is sent.\n  expectStreamCreate(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  // When transitioning to a successful state, checks should respect healthy_edge_interval.\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::ChangePending));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(std::chrono::milliseconds(4000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  respondServiceStatus(0, grpc::health::v1::HealthCheckResponse::SERVING);\n\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  // Needed after a response is sent.\n  expectStreamCreate(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::ChangePending));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(std::chrono::milliseconds(4000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  respondServiceStatus(0, grpc::health::v1::HealthCheckResponse::SERVING);\n\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  // Needed after a response is sent.\n  expectStreamCreate(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  // After the healthy threshold is reached, health state should change while checks should respect\n  // the default interval.\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Changed));\n  EXPECT_CALL(event_logger_, logAddHealthy(_, _, false));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(std::chrono::milliseconds(1000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  respondServiceStatus(0, grpc::health::v1::HealthCheckResponse::SERVING);\n\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  // Needed after a response is sent.\n  expectStreamCreate(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  // Subsequent checks shouldn't change the state.\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(std::chrono::milliseconds(1000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  respondServiceStatus(0, grpc::health::v1::HealthCheckResponse::SERVING);\n}\n\n// Test connection close between checks affects nothing.\nTEST_F(GrpcHealthCheckerImplTest, RemoteCloseBetweenChecks) {\n  setupHC();\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n\n  expectSessionCreate();\n  expectHealthcheckStart(0);\n  health_checker_->start();\n\n  expectHealthcheckStop(0);\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n  respondServiceStatus(0, grpc::health::v1::HealthCheckResponse::SERVING);\n  expectHostHealthy(true);\n\n  // Connection closed between checks - nothing happens, just re-create client.\n  test_sessions_[0]->client_connection_->raiseEvent(Network::ConnectionEvent::RemoteClose);\n\n  expectClientCreate(0);\n  expectHealthcheckStart(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  expectHealthcheckStop(0);\n  // Test host state haven't changed.\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n  respondServiceStatus(0, grpc::health::v1::HealthCheckResponse::SERVING);\n  expectHostHealthy(true);\n}\n\n// Test that we close connections on a healthy check when reuse_connection is false.\nTEST_F(GrpcHealthCheckerImplTest, DontReuseConnectionBetweenChecks) {\n  setupNoReuseConnectionHC();\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n\n  expectSessionCreate();\n  expectHealthcheckStart(0);\n  health_checker_->start();\n\n  expectHealthcheckStop(0);\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n  respondServiceStatus(0, grpc::health::v1::HealthCheckResponse::SERVING);\n  expectHostHealthy(true);\n\n  // A new client is created because we close the connection ourselves.\n  // See GrpcHealthCheckerImplTest.RemoteCloseBetweenChecks for how this works when the remote end\n  // closes the connection.\n  expectClientCreate(0);\n  expectHealthcheckStart(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  expectHealthcheckStop(0);\n  // Test host state haven't changed.\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n  respondServiceStatus(0, grpc::health::v1::HealthCheckResponse::SERVING);\n  expectHostHealthy(true);\n}\n\n// Test that we close connections when a timeout occurs and reuse_connection is false.\nTEST_F(GrpcHealthCheckerImplTest, DontReuseConnectionTimeout) {\n  setupNoReuseConnectionHC();\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n\n  expectSessionCreate();\n  expectHealthcheckStart(0);\n  EXPECT_CALL(event_logger_, logUnhealthy(_, _, _, true));\n  health_checker_->start();\n\n  expectHealthcheckStop(0);\n  // Timeouts are considered network failures and make host unhealthy also after 2nd event.\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::ChangePending));\n  test_sessions_[0]->timeout_timer_->invokeCallback();\n  expectHostHealthy(true);\n\n  // A new client is created because we close the connection\n  // when a timeout occurs and connection reuse is disabled.\n  expectClientCreate(0);\n  expectHealthcheckStart(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  expectHealthcheckStop(0);\n  // Test host state haven't changed.\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n  respondServiceStatus(0, grpc::health::v1::HealthCheckResponse::SERVING);\n  expectHostHealthy(true);\n}\n\n// Test that we close connections when a stream reset occurs and reuse_connection is false.\nTEST_F(GrpcHealthCheckerImplTest, DontReuseConnectionStreamReset) {\n  setupNoReuseConnectionHC();\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n\n  expectSessionCreate();\n  expectHealthcheckStart(0);\n  EXPECT_CALL(event_logger_, logUnhealthy(_, _, _, true));\n  health_checker_->start();\n\n  expectHealthcheckStop(0);\n  // Resets are considered network failures and make host unhealthy also after 2nd event.\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::ChangePending));\n  test_sessions_[0]->request_encoder_.stream_.resetStream(Http::StreamResetReason::RemoteReset);\n  expectHostHealthy(true);\n\n  // A new client is created because we close the connection\n  // when a stream reset occurs and connection reuse is disabled.\n  expectClientCreate(0);\n  expectHealthcheckStart(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  expectHealthcheckStop(0);\n  // Test host state haven't changed.\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n  respondServiceStatus(0, grpc::health::v1::HealthCheckResponse::SERVING);\n  expectHostHealthy(true);\n}\n\n// Test UNKNOWN health status is considered unhealthy.\nTEST_F(GrpcHealthCheckerImplTest, GrpcFailUnknown) {\n  setupHC();\n  expectSingleHealthcheck(HealthTransition::Changed);\n  EXPECT_CALL(event_logger_, logEjectUnhealthy(_, _, _));\n  EXPECT_CALL(event_logger_, logUnhealthy(_, _, _, true));\n\n  respondServiceStatus(0, grpc::health::v1::HealthCheckResponse::UNKNOWN);\n  EXPECT_TRUE(cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthFlagGet(\n      Host::HealthFlag::FAILED_ACTIVE_HC));\n  EXPECT_EQ(Host::Health::Unhealthy,\n            cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n}\n\n// This used to cause a null dereference\nTEST_F(GrpcHealthCheckerImplTest, GrpcFailNullBytes) {\n  setupHC();\n  expectSingleHealthcheck(HealthTransition::Changed);\n  EXPECT_CALL(event_logger_, logEjectUnhealthy(_, _, _));\n  EXPECT_CALL(event_logger_, logUnhealthy(_, _, _, true));\n  respondResponseSpec(0, ResponseSpec{{{\":status\", \"200\"}, {\"content-type\", \"application/grpc\"}},\n                                      {GrpcHealthCheckerImplTest::ResponseSpec::badData()},\n                                      {}});\n  EXPECT_TRUE(cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthFlagGet(\n      Host::HealthFlag::FAILED_ACTIVE_HC));\n  EXPECT_EQ(Host::Health::Unhealthy,\n            cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n}\n\n// This used to cause a null dereference\nTEST_F(GrpcHealthCheckerImplTest, GrpcValidFramesThenInvalidFrames) {\n  setupHC();\n  expectSingleHealthcheck(HealthTransition::Changed);\n  EXPECT_CALL(event_logger_, logEjectUnhealthy(_, _, _));\n  EXPECT_CALL(event_logger_, logUnhealthy(_, _, _, true));\n  respondResponseSpec(\n      0, ResponseSpec{{{\":status\", \"200\"}, {\"content-type\", \"application/grpc\"}},\n                      {GrpcHealthCheckerImplTest::ResponseSpec::validFramesThenInvalidFrames()},\n                      {}});\n  EXPECT_TRUE(cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthFlagGet(\n      Host::HealthFlag::FAILED_ACTIVE_HC));\n  EXPECT_EQ(Host::Health::Unhealthy,\n            cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n}\n\n// Test SERVICE_UNKNOWN health status is considered unhealthy.\nTEST_F(GrpcHealthCheckerImplTest, GrpcFailServiceUnknown) {\n  setupHC();\n  expectSingleHealthcheck(HealthTransition::Changed);\n  EXPECT_CALL(event_logger_, logEjectUnhealthy(_, _, _));\n  EXPECT_CALL(event_logger_, logUnhealthy(_, _, _, true));\n\n  respondServiceStatus(0, grpc::health::v1::HealthCheckResponse::SERVICE_UNKNOWN);\n  EXPECT_TRUE(cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthFlagGet(\n      Host::HealthFlag::FAILED_ACTIVE_HC));\n  EXPECT_EQ(Host::Health::Unhealthy,\n            cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n}\n\n// Test non existent health status enum is considered unhealthy.\nTEST_F(GrpcHealthCheckerImplTest, GrpcFailUnknownHealthStatus) {\n  setupHC();\n  expectSingleHealthcheck(HealthTransition::Changed);\n  EXPECT_CALL(event_logger_, logEjectUnhealthy(_, _, _));\n  EXPECT_CALL(event_logger_, logUnhealthy(_, _, _, true));\n\n  respondServiceStatus(0, static_cast<grpc::health::v1::HealthCheckResponse::ServingStatus>(999));\n  EXPECT_TRUE(cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthFlagGet(\n      Host::HealthFlag::FAILED_ACTIVE_HC));\n  EXPECT_EQ(Host::Health::Unhealthy,\n            cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n}\n\n// Test receiving GOAWAY (error) is interpreted as connection close event.\nTEST_F(GrpcHealthCheckerImplTest, GoAwayErrorProbeInProgress) {\n  // FailureType::Network will be issued, it will render host unhealthy only if unhealthy_threshold\n  // is reached.\n  setupHCWithUnhealthyThreshold(1);\n  expectSingleHealthcheck(HealthTransition::Changed);\n  EXPECT_CALL(event_logger_, logEjectUnhealthy(_, _, _));\n  EXPECT_CALL(event_logger_, logUnhealthy(_, _, _, true));\n\n  // GOAWAY with non-NO_ERROR code will result in a healthcheck failure\n  // and the connection closing.\n  test_sessions_[0]->codec_client_->raiseGoAway(Http::GoAwayErrorCode::Other);\n\n  EXPECT_TRUE(cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthFlagGet(\n      Host::HealthFlag::FAILED_ACTIVE_HC));\n  EXPECT_EQ(Host::Health::Unhealthy,\n            cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n}\n\n// Test receiving GOAWAY (no error) is handled gracefully while a check is in progress.\nTEST_F(GrpcHealthCheckerImplTest, GoAwayProbeInProgress) {\n  setupHCWithUnhealthyThreshold(/*threshold=*/1);\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n\n  expectSessionCreate();\n  expectHealthcheckStart(0);\n  health_checker_->start();\n\n  expectHealthcheckStop(0);\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n\n  // GOAWAY with NO_ERROR code during check should be handle gracefully.\n  test_sessions_[0]->codec_client_->raiseGoAway(Http::GoAwayErrorCode::NoError);\n  respondServiceStatus(0, grpc::health::v1::HealthCheckResponse::SERVING);\n  expectHostHealthy(true);\n\n  // GOAWAY should cause a new connection to be created.\n  expectClientCreate(0);\n  expectHealthcheckStart(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  expectHealthcheckStop(0);\n  // Test host state haven't changed.\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n  respondServiceStatus(0, grpc::health::v1::HealthCheckResponse::SERVING);\n  expectHostHealthy(true);\n}\n\n// Test receiving GOAWAY (no error) closes connection after an in progress probe times outs.\nTEST_F(GrpcHealthCheckerImplTest, GoAwayProbeInProgressTimeout) {\n  setupHCWithUnhealthyThreshold(/*threshold=*/1);\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n\n  expectSessionCreate();\n  expectHealthcheckStart(0);\n  EXPECT_CALL(event_logger_, logUnhealthy(_, _, _, true));\n  health_checker_->start();\n\n  expectHealthcheckStop(0);\n  // Unhealthy threshold is 1 so first timeout causes unhealthy\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Changed));\n  EXPECT_CALL(event_logger_, logEjectUnhealthy(_, _, _));\n\n  // GOAWAY during check should be handled gracefully.\n  test_sessions_[0]->codec_client_->raiseGoAway(Http::GoAwayErrorCode::NoError);\n  expectHostHealthy(true);\n\n  test_sessions_[0]->timeout_timer_->invokeCallback();\n  expectHostHealthy(false);\n\n  // GOAWAY should cause a new connection to be created.\n  expectClientCreate(0);\n  expectHealthcheckStart(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  expectHealthcheckStop(0);\n  // Healthy threshold is 2, so the we'ere pending a state change.\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::ChangePending));\n  respondServiceStatus(0, grpc::health::v1::HealthCheckResponse::SERVING);\n  expectHostHealthy(false);\n}\n\n// Test receiving GOAWAY (no error) closes connection after an unexpected stream reset.\nTEST_F(GrpcHealthCheckerImplTest, GoAwayProbeInProgressStreamReset) {\n  setupHCWithUnhealthyThreshold(/*threshold=*/1);\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n\n  expectSessionCreate();\n  expectHealthcheckStart(0);\n  EXPECT_CALL(event_logger_, logUnhealthy(_, _, _, true));\n  health_checker_->start();\n\n  expectHealthcheckStop(0);\n  // Unhealthy threshold is 1 so first stream reset causes unhealthy\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Changed));\n  EXPECT_CALL(event_logger_, logEjectUnhealthy(_, _, _));\n\n  // GOAWAY during check should be handled gracefully.\n  test_sessions_[0]->codec_client_->raiseGoAway(Http::GoAwayErrorCode::NoError);\n  expectHostHealthy(true);\n\n  test_sessions_[0]->request_encoder_.stream_.resetStream(Http::StreamResetReason::RemoteReset);\n  expectHostHealthy(false);\n\n  // GOAWAY should cause a new connection to be created.\n  expectClientCreate(0);\n  expectHealthcheckStart(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  expectHealthcheckStop(0);\n  // Healthy threshold is 2, so the we'ere pending a state change.\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::ChangePending));\n  respondServiceStatus(0, grpc::health::v1::HealthCheckResponse::SERVING);\n  expectHostHealthy(false);\n}\n\n// Test receiving GOAWAY (no error) closes connection after a bad response.\nTEST_F(GrpcHealthCheckerImplTest, GoAwayProbeInProgressBadResponse) {\n  setupHCWithUnhealthyThreshold(/*threshold=*/1);\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n\n  expectSessionCreate();\n  expectHealthcheckStart(0);\n  EXPECT_CALL(event_logger_, logUnhealthy(_, _, _, true));\n  health_checker_->start();\n\n  expectHealthcheckStop(0);\n  // Unhealthy threshold is 1 so first bad response causes unhealthy\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Changed));\n  EXPECT_CALL(event_logger_, logEjectUnhealthy(_, _, _));\n\n  // GOAWAY during check should be handled gracefully.\n  test_sessions_[0]->codec_client_->raiseGoAway(Http::GoAwayErrorCode::NoError);\n  expectHostHealthy(true);\n\n  respondResponseSpec(0, ResponseSpec{{{\":status\", \"200\"}, {\"content-type\", \"application/grpc\"}},\n                                      {ResponseSpec::invalidChunk()},\n                                      {}});\n  expectHostHealthy(false);\n\n  // GOAWAY should cause a new connection to be created.\n  expectClientCreate(0);\n  expectHealthcheckStart(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  expectHealthcheckStop(0);\n  // Healthy threshold is 2, so the we'ere pending a state change.\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::ChangePending));\n  respondServiceStatus(0, grpc::health::v1::HealthCheckResponse::SERVING);\n  expectHostHealthy(false);\n}\n\n// Test receiving GOAWAY (no error) and a connection close.\nTEST_F(GrpcHealthCheckerImplTest, GoAwayProbeInProgressConnectionClose) {\n  setupHCWithUnhealthyThreshold(/*threshold=*/1);\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n\n  expectSessionCreate();\n  expectHealthcheckStart(0);\n  EXPECT_CALL(event_logger_, logUnhealthy(_, _, _, true));\n  health_checker_->start();\n\n  expectHealthcheckStop(0);\n  // Unhealthy threshold is 1 so first bad response causes unhealthy\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Changed));\n  EXPECT_CALL(event_logger_, logEjectUnhealthy(_, _, _));\n\n  // GOAWAY during check should be handled gracefully.\n  test_sessions_[0]->codec_client_->raiseGoAway(Http::GoAwayErrorCode::NoError);\n  expectHostHealthy(true);\n\n  test_sessions_[0]->client_connection_->raiseEvent(Network::ConnectionEvent::RemoteClose);\n  expectHostHealthy(false);\n\n  // GOAWAY should cause a new connection to be created.\n  expectClientCreate(0);\n  expectHealthcheckStart(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  expectHealthcheckStop(0);\n  // Healthy threshold is 2, so the we'ere pending a state change.\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::ChangePending));\n  respondServiceStatus(0, grpc::health::v1::HealthCheckResponse::SERVING);\n  expectHostHealthy(false);\n}\n\n// Test receiving GOAWAY between checks affects nothing.\nTEST_F(GrpcHealthCheckerImplTest, GoAwayBetweenChecks) {\n  setupHC();\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n\n  expectSessionCreate();\n  expectHealthcheckStart(0);\n  health_checker_->start();\n\n  expectHealthcheckStop(0);\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n  respondServiceStatus(0, grpc::health::v1::HealthCheckResponse::SERVING);\n  expectHostHealthy(true);\n\n  // GOAWAY between checks should go unnoticed.\n  test_sessions_[0]->codec_client_->raiseGoAway(Http::GoAwayErrorCode::NoError);\n\n  expectClientCreate(0);\n  expectHealthcheckStart(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  expectHealthcheckStop(0);\n  // Test host state haven't changed.\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n  respondServiceStatus(0, grpc::health::v1::HealthCheckResponse::SERVING);\n  expectHostHealthy(true);\n}\n\nclass BadResponseGrpcHealthCheckerImplTest\n    : public testing::TestWithParam<GrpcHealthCheckerImplTest::ResponseSpec>,\n      public GrpcHealthCheckerImplTestBase {};\n\nINSTANTIATE_TEST_SUITE_P(\n    BadResponse, BadResponseGrpcHealthCheckerImplTest,\n    testing::ValuesIn(std::vector<GrpcHealthCheckerImplTest::ResponseSpec>{\n        // Non-200 response.\n        {\n            {{\":status\", \"500\"}},\n            {},\n            {},\n        },\n        // Non-200 response with gRPC status.\n        {\n            {{\":status\", \"500\"}, {\"grpc-status\", \"2\"}},\n            {},\n            {},\n        },\n        // Missing content-type.\n        {\n            {{\":status\", \"200\"}},\n            {},\n            {},\n        },\n        // End stream on response headers.\n        {\n            {{\":status\", \"200\"}, {\"content-type\", \"application/grpc\"}},\n            {},\n            {},\n        },\n        // Non-OK gRPC status in headers.\n        {\n            {{\":status\", \"200\"}, {\"content-type\", \"application/grpc\"}, {\"grpc-status\", \"2\"}},\n            {},\n            {},\n        },\n        // Non-OK gRPC status\n        {\n            {{\":status\", \"200\"}, {\"content-type\", \"application/grpc\"}},\n            {GrpcHealthCheckerImplTest::ResponseSpec::servingResponse()},\n            {{\"grpc-status\", \"2\"}},\n        },\n        // Missing body.\n        {\n            {{\":status\", \"200\"}, {\"content-type\", \"application/grpc\"}, {\"grpc-status\", \"0\"}},\n            {},\n            {},\n        },\n        // Compressed body.\n        {\n            {{\":status\", \"200\"}, {\"content-type\", \"application/grpc\"}},\n            {GrpcHealthCheckerImplTest::ResponseSpec::invalidPayload(Grpc::GRPC_FH_COMPRESSED,\n                                                                     true)},\n            {},\n        },\n        // Invalid proto message.\n        {\n            {{\":status\", \"200\"}, {\"content-type\", \"application/grpc\"}},\n            {GrpcHealthCheckerImplTest::ResponseSpec::invalidPayload(Grpc::GRPC_FH_DEFAULT, false)},\n            {},\n        },\n        // Duplicate response.\n        {\n            {{\":status\", \"200\"}, {\"content-type\", \"application/grpc\"}},\n            {GrpcHealthCheckerImplTest::ResponseSpec::servingResponse(),\n             GrpcHealthCheckerImplTest::ResponseSpec::servingResponse()},\n            {},\n        },\n        // Invalid response.\n        {\n            {{\":status\", \"200\"}, {\"content-type\", \"application/grpc\"}},\n            {GrpcHealthCheckerImplTest::ResponseSpec::invalidChunk()},\n            {},\n        },\n        // No trailers.\n        {\n            {{\":status\", \"200\"}, {\"content-type\", \"application/grpc\"}},\n            {GrpcHealthCheckerImplTest::ResponseSpec::servingResponse()},\n            {},\n        },\n        // No gRPC status in trailer.\n        {\n            {{\":status\", \"200\"}, {\"content-type\", \"application/grpc\"}},\n            {GrpcHealthCheckerImplTest::ResponseSpec::servingResponse()},\n            {{\"some-header\", \"1\"}},\n        },\n        // Invalid gRPC status.\n        {\n            {{\":status\", \"200\"}, {\"content-type\", \"application/grpc\"}},\n            {GrpcHealthCheckerImplTest::ResponseSpec::servingResponse()},\n            {{\"grpc-status\", \"invalid\"}},\n        },\n    }));\n\n// Test different cases of invalid gRPC response makes host unhealthy.\nTEST_P(BadResponseGrpcHealthCheckerImplTest, GrpcBadResponse) {\n  setupHC();\n  expectSingleHealthcheck(HealthTransition::Changed);\n  EXPECT_CALL(event_logger_, logUnhealthy(_, _, _, true));\n  EXPECT_CALL(event_logger_, logEjectUnhealthy(_, _, _));\n\n  ResponseSpec spec = GetParam();\n  respondResponseSpec(0, std::move(spec));\n  expectHostHealthy(false);\n}\n\nTEST(Printer, HealthStatePrinter) {\n  std::ostringstream healthy;\n  healthy << HealthState::Healthy;\n  EXPECT_EQ(\"Healthy\", healthy.str());\n\n  std::ostringstream unhealthy;\n  unhealthy << HealthState::Unhealthy;\n  EXPECT_EQ(\"Unhealthy\", unhealthy.str());\n}\n\nTEST(Printer, HealthTransitionPrinter) {\n  std::ostringstream changed;\n  changed << HealthTransition::Changed;\n  EXPECT_EQ(\"Changed\", changed.str());\n\n  std::ostringstream unchanged;\n  unchanged << HealthTransition::Unchanged;\n  EXPECT_EQ(\"Unchanged\", unchanged.str());\n}\n\nTEST(HealthCheckEventLoggerImplTest, All) {\n  AccessLog::MockAccessLogManager log_manager;\n  std::shared_ptr<AccessLog::MockAccessLogFile> file(new AccessLog::MockAccessLogFile());\n  EXPECT_CALL(log_manager, createAccessLog(Filesystem::FilePathAndType{\n                               Filesystem::DestinationType::File, \"foo\"}))\n      .WillOnce(Return(file));\n\n  std::shared_ptr<MockHostDescription> host(new NiceMock<MockHostDescription>());\n  NiceMock<MockClusterInfo> cluster;\n  ON_CALL(*host, cluster()).WillByDefault(ReturnRef(cluster));\n\n  Event::SimulatedTimeSystem time_system;\n  // This is rendered as \"2009-02-13T23:31:31.234Z\".a\n  time_system.setSystemTime(std::chrono::milliseconds(1234567891234));\n\n  HealthCheckEventLoggerImpl event_logger(log_manager, time_system, \"foo\");\n\n  EXPECT_CALL(*file, write(absl::string_view{\n                         \"{\\\"health_checker_type\\\":\\\"HTTP\\\",\\\"host\\\":{\\\"socket_address\\\":{\"\n                         \"\\\"protocol\\\":\\\"TCP\\\",\\\"address\\\":\\\"10.0.0.1\\\",\\\"resolver_name\\\":\\\"\\\",\"\n                         \"\\\"ipv4_compat\\\":false,\\\"port_value\\\":443}},\\\"cluster_name\\\":\\\"fake_\"\n                         \"cluster\\\",\\\"eject_unhealthy_event\\\":{\\\"failure_type\\\":\\\"ACTIVE\\\"},\"\n                         \"\\\"timestamp\\\":\\\"2009-02-13T23:31:31.234Z\\\"}\\n\"}));\n  event_logger.logEjectUnhealthy(envoy::data::core::v3::HTTP, host, envoy::data::core::v3::ACTIVE);\n\n  EXPECT_CALL(*file, write(absl::string_view{\n                         \"{\\\"health_checker_type\\\":\\\"HTTP\\\",\\\"host\\\":{\\\"socket_address\\\":{\"\n                         \"\\\"protocol\\\":\\\"TCP\\\",\\\"address\\\":\\\"10.0.0.1\\\",\\\"resolver_name\\\":\\\"\\\",\"\n                         \"\\\"ipv4_compat\\\":false,\\\"port_value\\\":443}},\\\"cluster_name\\\":\\\"fake_\"\n                         \"cluster\\\",\\\"add_healthy_event\\\":{\\\"first_check\\\":false},\\\"timestamp\\\":\"\n                         \"\\\"2009-02-13T23:31:31.234Z\\\"}\\n\"}));\n  event_logger.logAddHealthy(envoy::data::core::v3::HTTP, host, false);\n\n  EXPECT_CALL(*file, write(absl::string_view{\n                         \"{\\\"health_checker_type\\\":\\\"HTTP\\\",\\\"host\\\":{\\\"socket_address\\\":{\"\n                         \"\\\"protocol\\\":\\\"TCP\\\",\\\"address\\\":\\\"10.0.0.1\\\",\\\"resolver_name\\\":\\\"\\\",\"\n                         \"\\\"ipv4_compat\\\":false,\\\"port_value\\\":443}},\\\"cluster_name\\\":\\\"fake_\"\n                         \"cluster\\\",\\\"health_check_failure_event\\\":{\\\"failure_type\\\":\\\"ACTIVE\\\",\"\n                         \"\\\"first_check\\\":false},\"\n                         \"\\\"timestamp\\\":\\\"2009-02-13T23:31:31.234Z\\\"}\\n\"}));\n  event_logger.logUnhealthy(envoy::data::core::v3::HTTP, host, envoy::data::core::v3::ACTIVE,\n                            false);\n\n  EXPECT_CALL(*file, write(absl::string_view{\n                         \"{\\\"health_checker_type\\\":\\\"HTTP\\\",\\\"host\\\":{\\\"socket_address\\\":{\"\n                         \"\\\"protocol\\\":\\\"TCP\\\",\\\"address\\\":\\\"10.0.0.1\\\",\\\"resolver_name\\\":\\\"\\\",\"\n                         \"\\\"ipv4_compat\\\":false,\\\"port_value\\\":443}},\\\"cluster_name\\\":\\\"fake_\"\n                         \"cluster\\\",\\\"degraded_healthy_host\\\":{},\"\n                         \"\\\"timestamp\\\":\\\"2009-02-13T23:31:31.234Z\\\"}\\n\"}));\n  event_logger.logDegraded(envoy::data::core::v3::HTTP, host);\n\n  EXPECT_CALL(*file, write(absl::string_view{\n                         \"{\\\"health_checker_type\\\":\\\"HTTP\\\",\\\"host\\\":{\\\"socket_address\\\":{\"\n                         \"\\\"protocol\\\":\\\"TCP\\\",\\\"address\\\":\\\"10.0.0.1\\\",\\\"resolver_name\\\":\\\"\\\",\"\n                         \"\\\"ipv4_compat\\\":false,\\\"port_value\\\":443}},\\\"cluster_name\\\":\\\"fake_\"\n                         \"cluster\\\",\\\"no_longer_degraded_host\\\":{},\"\n                         \"\\\"timestamp\\\":\\\"2009-02-13T23:31:31.234Z\\\"}\\n\"}));\n  event_logger.logNoLongerDegraded(envoy::data::core::v3::HTTP, host);\n}\n\n// Validate that the proto constraints don't allow zero length edge durations.\nTEST(HealthCheckProto, Validation) {\n  {\n    const std::string yaml = R\"EOF(\n    timeout: 1s\n    interval: 1s\n    healthy_threshold: 1\n    unhealthy_threshold: 1\n    no_traffic_interval: 0s\n    http_health_check:\n      service_name_matcher:\n        prefix: locations\n      path: /healthcheck\n    )EOF\";\n    envoy::config::core::v3::HealthCheck health_check_proto;\n    EXPECT_THROW_WITH_REGEX(TestUtility::validate(parseHealthCheckFromV3Yaml(yaml)), EnvoyException,\n                            \"Proto constraint validation failed.*value must be greater than.*\");\n  }\n  {\n    const std::string yaml = R\"EOF(\n    timeout: 1s\n    interval: 1s\n    healthy_threshold: 1\n    unhealthy_threshold: 1\n    unhealthy_interval: 0s\n    http_health_check:\n      service_name_matcher:\n        prefix: locations\n      path: /healthcheck\n    )EOF\";\n    envoy::config::core::v3::HealthCheck health_check_proto;\n    EXPECT_THROW_WITH_REGEX(TestUtility::validate(parseHealthCheckFromV3Yaml(yaml)), EnvoyException,\n                            \"Proto constraint validation failed.*value must be greater than.*\");\n  }\n  {\n    const std::string yaml = R\"EOF(\n    timeout: 1s\n    interval: 1s\n    healthy_threshold: 1\n    unhealthy_threshold: 1\n    unhealthy_edge_interval: 0s\n    http_health_check:\n      service_name_matcher:\n        prefix: locations\n      path: /healthcheck\n    )EOF\";\n    envoy::config::core::v3::HealthCheck health_check_proto;\n    EXPECT_THROW_WITH_REGEX(TestUtility::validate(parseHealthCheckFromV3Yaml(yaml)), EnvoyException,\n                            \"Proto constraint validation failed.*value must be greater than.*\");\n  }\n  {\n    const std::string yaml = R\"EOF(\n    timeout: 1s\n    interval: 1s\n    healthy_threshold: 1\n    unhealthy_threshold: 1\n    healthy_edge_interval: 0s\n    http_health_check:\n      service_name_matcher:\n        prefix: locations\n      path: /healthcheck\n    )EOF\";\n    envoy::config::core::v3::HealthCheck health_check_proto;\n    EXPECT_THROW_WITH_REGEX(TestUtility::validate(parseHealthCheckFromV3Yaml(yaml)), EnvoyException,\n                            \"Proto constraint validation failed.*value must be greater than.*\");\n  }\n  {\n    const std::string yaml = R\"EOF(\n    timeout: 1s\n    interval: 1s\n    unhealthy_threshold: 1\n    http_health_check:\n      service_name_matcher:\n        prefix: locations\n      path: /healthcheck\n    )EOF\";\n    envoy::config::core::v3::HealthCheck health_check_proto;\n    EXPECT_THROW_WITH_REGEX(TestUtility::validate(parseHealthCheckFromV3Yaml(yaml)), EnvoyException,\n                            \"Proto constraint validation failed.*value is required.*\");\n  }\n  {\n    const std::string yaml = R\"EOF(\n    timeout: 1s\n    interval: 1s\n    healthy_threshold: 1\n    http_health_check:\n      service_name_matcher:\n        prefix: locations\n      path: /healthcheck\n    )EOF\";\n    envoy::config::core::v3::HealthCheck health_check_proto;\n    EXPECT_THROW_WITH_REGEX(TestUtility::validate(parseHealthCheckFromV3Yaml(yaml)), EnvoyException,\n                            \"Proto constraint validation failed.*value is required.*\");\n  }\n}\n\n} // namespace\n} // namespace Upstream\n} // namespace Envoy\n"], "fixing_code": ["#include \"source/common/upstream/health_checker_impl.h\"\n\n#include <memory>\n\n#include \"envoy/config/core/v3/health_check.pb.h\"\n#include \"envoy/data/core/v3/health_check_event.pb.h\"\n#include \"envoy/server/health_checker_config.h\"\n#include \"envoy/type/v3/http.pb.h\"\n#include \"envoy/type/v3/range.pb.h\"\n\n#include \"source/common/buffer/zero_copy_input_stream_impl.h\"\n#include \"source/common/common/empty_string.h\"\n#include \"source/common/common/enum_to_int.h\"\n#include \"source/common/common/macros.h\"\n#include \"source/common/config/utility.h\"\n#include \"source/common/config/well_known_names.h\"\n#include \"source/common/grpc/common.h\"\n#include \"source/common/http/header_map_impl.h\"\n#include \"source/common/http/header_utility.h\"\n#include \"source/common/network/address_impl.h\"\n#include \"source/common/network/socket_impl.h\"\n#include \"source/common/network/utility.h\"\n#include \"source/common/router/router.h\"\n#include \"source/common/runtime/runtime_features.h\"\n#include \"source/common/upstream/host_utility.h\"\n\n#include \"absl/strings/match.h\"\n#include \"absl/strings/str_cat.h\"\n\nnamespace Envoy {\nnamespace Upstream {\n\nnamespace {\n\n// Helper functions to get the correct hostname for an L7 health check.\nconst std::string& getHostname(const HostSharedPtr& host, const std::string& config_hostname,\n                               const ClusterInfoConstSharedPtr& cluster) {\n  if (!host->hostnameForHealthChecks().empty()) {\n    return host->hostnameForHealthChecks();\n  }\n\n  if (!config_hostname.empty()) {\n    return config_hostname;\n  }\n\n  return cluster->name();\n}\n\nconst std::string& getHostname(const HostSharedPtr& host,\n                               const absl::optional<std::string>& config_hostname,\n                               const ClusterInfoConstSharedPtr& cluster) {\n  if (config_hostname.has_value()) {\n    return getHostname(host, config_hostname.value(), cluster);\n  }\n  return getHostname(host, EMPTY_STRING, cluster);\n}\n\n} // namespace\n\nclass HealthCheckerFactoryContextImpl : public Server::Configuration::HealthCheckerFactoryContext {\npublic:\n  HealthCheckerFactoryContextImpl(Upstream::Cluster& cluster, Envoy::Runtime::Loader& runtime,\n                                  Event::Dispatcher& dispatcher,\n                                  HealthCheckEventLoggerPtr&& event_logger,\n                                  ProtobufMessage::ValidationVisitor& validation_visitor,\n                                  Api::Api& api)\n      : cluster_(cluster), runtime_(runtime), dispatcher_(dispatcher),\n        event_logger_(std::move(event_logger)), validation_visitor_(validation_visitor), api_(api) {\n  }\n  Upstream::Cluster& cluster() override { return cluster_; }\n  Envoy::Runtime::Loader& runtime() override { return runtime_; }\n  Event::Dispatcher& mainThreadDispatcher() override { return dispatcher_; }\n  HealthCheckEventLoggerPtr eventLogger() override { return std::move(event_logger_); }\n  ProtobufMessage::ValidationVisitor& messageValidationVisitor() override {\n    return validation_visitor_;\n  }\n  Api::Api& api() override { return api_; }\n\nprivate:\n  Upstream::Cluster& cluster_;\n  Envoy::Runtime::Loader& runtime_;\n  Event::Dispatcher& dispatcher_;\n  HealthCheckEventLoggerPtr event_logger_;\n  ProtobufMessage::ValidationVisitor& validation_visitor_;\n  Api::Api& api_;\n};\n\nHealthCheckerSharedPtr HealthCheckerFactory::create(\n    const envoy::config::core::v3::HealthCheck& health_check_config, Upstream::Cluster& cluster,\n    Runtime::Loader& runtime, Event::Dispatcher& dispatcher,\n    AccessLog::AccessLogManager& log_manager,\n    ProtobufMessage::ValidationVisitor& validation_visitor, Api::Api& api) {\n  HealthCheckEventLoggerPtr event_logger;\n  if (!health_check_config.event_log_path().empty()) {\n    event_logger = std::make_unique<HealthCheckEventLoggerImpl>(\n        log_manager, dispatcher.timeSource(), health_check_config.event_log_path());\n  }\n  switch (health_check_config.health_checker_case()) {\n  case envoy::config::core::v3::HealthCheck::HealthCheckerCase::HEALTH_CHECKER_NOT_SET:\n    throw EnvoyException(\"invalid cluster config\");\n  case envoy::config::core::v3::HealthCheck::HealthCheckerCase::kHttpHealthCheck:\n    return std::make_shared<ProdHttpHealthCheckerImpl>(cluster, health_check_config, dispatcher,\n                                                       runtime, api.randomGenerator(),\n                                                       std::move(event_logger));\n  case envoy::config::core::v3::HealthCheck::HealthCheckerCase::kTcpHealthCheck:\n    return std::make_shared<TcpHealthCheckerImpl>(cluster, health_check_config, dispatcher, runtime,\n                                                  api.randomGenerator(), std::move(event_logger));\n  case envoy::config::core::v3::HealthCheck::HealthCheckerCase::kGrpcHealthCheck:\n    if (!(cluster.info()->features() & Upstream::ClusterInfo::Features::HTTP2)) {\n      throw EnvoyException(fmt::format(\"{} cluster must support HTTP/2 for gRPC healthchecking\",\n                                       cluster.info()->name()));\n    }\n    return std::make_shared<ProdGrpcHealthCheckerImpl>(cluster, health_check_config, dispatcher,\n                                                       runtime, api.randomGenerator(),\n                                                       std::move(event_logger));\n  case envoy::config::core::v3::HealthCheck::HealthCheckerCase::kCustomHealthCheck: {\n    auto& factory =\n        Config::Utility::getAndCheckFactory<Server::Configuration::CustomHealthCheckerFactory>(\n            health_check_config.custom_health_check());\n    std::unique_ptr<Server::Configuration::HealthCheckerFactoryContext> context(\n        new HealthCheckerFactoryContextImpl(cluster, runtime, dispatcher, std::move(event_logger),\n                                            validation_visitor, api));\n    return factory.createCustomHealthChecker(health_check_config, *context);\n  }\n  }\n  PANIC_DUE_TO_CORRUPT_ENUM;\n}\n\nHttpHealthCheckerImpl::HttpHealthCheckerImpl(const Cluster& cluster,\n                                             const envoy::config::core::v3::HealthCheck& config,\n                                             Event::Dispatcher& dispatcher,\n                                             Runtime::Loader& runtime,\n                                             Random::RandomGenerator& random,\n                                             HealthCheckEventLoggerPtr&& event_logger)\n    : HealthCheckerImplBase(cluster, config, dispatcher, runtime, random, std::move(event_logger)),\n      path_(config.http_health_check().path()), host_value_(config.http_health_check().host()),\n      request_headers_parser_(\n          Router::HeaderParser::configure(config.http_health_check().request_headers_to_add(),\n                                          config.http_health_check().request_headers_to_remove())),\n      http_status_checker_(config.http_health_check().expected_statuses(),\n                           config.http_health_check().retriable_statuses(),\n                           static_cast<uint64_t>(Http::Code::OK)),\n      codec_client_type_(codecClientType(config.http_health_check().codec_client_type())),\n      random_generator_(random) {\n  if (config.http_health_check().has_service_name_matcher()) {\n    service_name_matcher_.emplace(config.http_health_check().service_name_matcher());\n  }\n}\n\nHttpHealthCheckerImpl::HttpStatusChecker::HttpStatusChecker(\n    const Protobuf::RepeatedPtrField<envoy::type::v3::Int64Range>& expected_statuses,\n    const Protobuf::RepeatedPtrField<envoy::type::v3::Int64Range>& retriable_statuses,\n    uint64_t default_expected_status) {\n  for (const auto& status_range : expected_statuses) {\n    const auto start = static_cast<uint64_t>(status_range.start());\n    const auto end = static_cast<uint64_t>(status_range.end());\n\n    validateRange(start, end, \"expected\");\n\n    expected_ranges_.emplace_back(std::make_pair(start, end));\n  }\n\n  if (expected_ranges_.empty()) {\n    expected_ranges_.emplace_back(\n        std::make_pair(default_expected_status, default_expected_status + 1));\n  }\n\n  for (const auto& status_range : retriable_statuses) {\n    const auto start = static_cast<uint64_t>(status_range.start());\n    const auto end = static_cast<uint64_t>(status_range.end());\n\n    validateRange(start, end, \"retriable\");\n\n    retriable_ranges_.emplace_back(std::make_pair(start, end));\n  }\n}\n\nvoid HttpHealthCheckerImpl::HttpStatusChecker::validateRange(uint64_t start, uint64_t end,\n                                                             absl::string_view range_type) {\n  if (start >= end) {\n    throw EnvoyException(fmt::format(\"Invalid http {} status range: expecting start < \"\n                                     \"end, but found start={} and end={}\",\n                                     range_type, start, end));\n  }\n\n  if (start < 100) {\n    throw EnvoyException(\n        fmt::format(\"Invalid http {} status range: expecting start >= 100, but found start={}\",\n                    range_type, start));\n  }\n\n  if (end > 600) {\n    throw EnvoyException(fmt::format(\n        \"Invalid http {} status range: expecting end <= 600, but found end={}\", range_type, end));\n  }\n}\n\nbool HttpHealthCheckerImpl::HttpStatusChecker::inRetriableRanges(uint64_t http_status) const {\n  return inRanges(http_status, retriable_ranges_);\n}\n\nbool HttpHealthCheckerImpl::HttpStatusChecker::inExpectedRanges(uint64_t http_status) const {\n  return inRanges(http_status, expected_ranges_);\n}\n\nbool HttpHealthCheckerImpl::HttpStatusChecker::inRanges(\n    uint64_t http_status, const std::vector<std::pair<uint64_t, uint64_t>>& ranges) {\n  for (const auto& range : ranges) {\n    if (http_status >= range.first && http_status < range.second) {\n      return true;\n    }\n  }\n\n  return false;\n}\n\nHttp::Protocol codecClientTypeToProtocol(Http::CodecType codec_client_type) {\n  switch (codec_client_type) {\n  case Http::CodecType::HTTP1:\n    return Http::Protocol::Http11;\n  case Http::CodecType::HTTP2:\n    return Http::Protocol::Http2;\n  case Http::CodecType::HTTP3:\n    return Http::Protocol::Http3;\n  }\n  PANIC_DUE_TO_CORRUPT_ENUM\n}\n\nHttpHealthCheckerImpl::HttpActiveHealthCheckSession::HttpActiveHealthCheckSession(\n    HttpHealthCheckerImpl& parent, const HostSharedPtr& host)\n    : ActiveHealthCheckSession(parent, host), parent_(parent),\n      hostname_(getHostname(host, parent_.host_value_, parent_.cluster_.info())),\n      protocol_(codecClientTypeToProtocol(parent_.codec_client_type_)),\n      local_connection_info_provider_(std::make_shared<Network::ConnectionInfoSetterImpl>(\n          Network::Utility::getCanonicalIpv4LoopbackAddress(),\n          Network::Utility::getCanonicalIpv4LoopbackAddress())) {}\n\nHttpHealthCheckerImpl::HttpActiveHealthCheckSession::~HttpActiveHealthCheckSession() {\n  ASSERT(client_ == nullptr);\n}\n\nvoid HttpHealthCheckerImpl::HttpActiveHealthCheckSession::onDeferredDelete() {\n  if (client_) {\n    // If there is an active request it will get reset, so make sure we ignore the reset.\n    expect_reset_ = true;\n    client_->close();\n  }\n}\n\nvoid HttpHealthCheckerImpl::HttpActiveHealthCheckSession::decodeHeaders(\n    Http::ResponseHeaderMapPtr&& headers, bool end_stream) {\n  ASSERT(!response_headers_);\n  response_headers_ = std::move(headers);\n  if (end_stream) {\n    onResponseComplete();\n  }\n}\n\nvoid HttpHealthCheckerImpl::HttpActiveHealthCheckSession::onEvent(Network::ConnectionEvent event) {\n  if (event == Network::ConnectionEvent::RemoteClose ||\n      event == Network::ConnectionEvent::LocalClose) {\n    // For the raw disconnect event, we are either between intervals in which case we already have\n    // a timer setup, or we did the close or got a reset, in which case we already setup a new\n    // timer. There is nothing to do here other than blow away the client.\n    response_headers_.reset();\n    parent_.dispatcher_.deferredDelete(std::move(client_));\n  }\n}\n\n// TODO(lilika) : Support connection pooling\nvoid HttpHealthCheckerImpl::HttpActiveHealthCheckSession::onInterval() {\n  if (!client_) {\n    Upstream::Host::CreateConnectionData conn =\n        host_->createHealthCheckConnection(parent_.dispatcher_, parent_.transportSocketOptions(),\n                                           parent_.transportSocketMatchMetadata().get());\n    client_.reset(parent_.createCodecClient(conn));\n    client_->addConnectionCallbacks(connection_callback_impl_);\n    client_->setCodecConnectionCallbacks(http_connection_callback_impl_);\n    expect_reset_ = false;\n    reuse_connection_ = parent_.reuse_connection_;\n  }\n\n  Http::RequestEncoder* request_encoder = &client_->newStream(*this);\n  request_encoder->getStream().addCallbacks(*this);\n  request_in_flight_ = true;\n\n  const auto request_headers = Http::createHeaderMap<Http::RequestHeaderMapImpl>(\n      {{Http::Headers::get().Method, \"GET\"},\n       {Http::Headers::get().Host, hostname_},\n       {Http::Headers::get().Path, parent_.path_},\n       {Http::Headers::get().UserAgent, Http::Headers::get().UserAgentValues.EnvoyHealthChecker}});\n  Router::FilterUtility::setUpstreamScheme(\n      *request_headers,\n      // Here there is no downstream connection so scheme will be based on\n      // upstream crypto\n      host_->transportSocketFactory().implementsSecureTransport());\n  StreamInfo::StreamInfoImpl stream_info(protocol_, parent_.dispatcher_.timeSource(),\n                                         local_connection_info_provider_);\n  stream_info.setUpstreamInfo(std::make_shared<StreamInfo::UpstreamInfoImpl>());\n  stream_info.upstreamInfo()->setUpstreamHost(host_);\n  parent_.request_headers_parser_->evaluateHeaders(*request_headers, stream_info);\n  auto status = request_encoder->encodeHeaders(*request_headers, true);\n  // Encoding will only fail if required request headers are missing.\n  ASSERT(status.ok());\n}\n\nvoid HttpHealthCheckerImpl::HttpActiveHealthCheckSession::onResetStream(Http::StreamResetReason,\n                                                                        absl::string_view) {\n  request_in_flight_ = false;\n  ENVOY_CONN_LOG(debug, \"connection/stream error health_flags={}\", *client_,\n                 HostUtility::healthFlagsToString(*host_));\n  if (expect_reset_) {\n    return;\n  }\n\n  if (client_ && !reuse_connection_) {\n    client_->close();\n  }\n\n  handleFailure(envoy::data::core::v3::NETWORK);\n}\n\nvoid HttpHealthCheckerImpl::HttpActiveHealthCheckSession::onGoAway(\n    Http::GoAwayErrorCode error_code) {\n  ENVOY_CONN_LOG(debug, \"connection going away goaway_code={}, health_flags={}\", *client_,\n                 static_cast<int>(error_code), HostUtility::healthFlagsToString(*host_));\n\n  if (request_in_flight_ && error_code == Http::GoAwayErrorCode::NoError) {\n    // The server is starting a graceful shutdown. Allow the in flight request\n    // to finish without treating this as a health check error, and then\n    // reconnect.\n    reuse_connection_ = false;\n    return;\n  }\n\n  if (request_in_flight_) {\n    // Record this as a failed health check.\n    handleFailure(envoy::data::core::v3::NETWORK);\n  }\n\n  if (client_) {\n    expect_reset_ = true;\n    client_->close();\n  }\n}\n\nHttpHealthCheckerImpl::HttpActiveHealthCheckSession::HealthCheckResult\nHttpHealthCheckerImpl::HttpActiveHealthCheckSession::healthCheckResult() {\n  const uint64_t response_code = Http::Utility::getResponseStatus(*response_headers_);\n  ENVOY_CONN_LOG(debug, \"hc response={} health_flags={}\", *client_, response_code,\n                 HostUtility::healthFlagsToString(*host_));\n\n  if (!parent_.http_status_checker_.inExpectedRanges(response_code)) {\n    // If the HTTP response code would indicate failure AND the immediate health check\n    // failure header is set, exclude the host from LB.\n    // TODO(mattklein123): We could consider doing this check for any HTTP response code, but this\n    // seems like the least surprising behavior and we could consider relaxing this in the future.\n    // TODO(mattklein123): This will not force a host set rebuild of the host was already failed.\n    // This is something we could do in the future but seems unnecessary right now.\n    if (response_headers_->EnvoyImmediateHealthCheckFail() != nullptr) {\n      host_->healthFlagSet(Host::HealthFlag::EXCLUDED_VIA_IMMEDIATE_HC_FAIL);\n    }\n\n    if (parent_.http_status_checker_.inRetriableRanges(response_code)) {\n      return HealthCheckResult::Retriable;\n    } else {\n      return HealthCheckResult::Failed;\n    }\n  }\n\n  const auto degraded = response_headers_->EnvoyDegraded() != nullptr;\n\n  if (parent_.service_name_matcher_.has_value() &&\n      parent_.runtime_.snapshot().featureEnabled(\"health_check.verify_cluster\", 100UL)) {\n    parent_.stats_.verify_cluster_.inc();\n    std::string service_cluster_healthchecked =\n        response_headers_->EnvoyUpstreamHealthCheckedCluster()\n            ? std::string(response_headers_->getEnvoyUpstreamHealthCheckedClusterValue())\n            : EMPTY_STRING;\n    if (parent_.service_name_matcher_->match(service_cluster_healthchecked)) {\n      return degraded ? HealthCheckResult::Degraded : HealthCheckResult::Succeeded;\n    } else {\n      return HealthCheckResult::Failed;\n    }\n  }\n\n  return degraded ? HealthCheckResult::Degraded : HealthCheckResult::Succeeded;\n}\n\nvoid HttpHealthCheckerImpl::HttpActiveHealthCheckSession::onResponseComplete() {\n  request_in_flight_ = false;\n\n  switch (healthCheckResult()) {\n  case HealthCheckResult::Succeeded:\n    handleSuccess(false);\n    break;\n  case HealthCheckResult::Degraded:\n    handleSuccess(true);\n    break;\n  case HealthCheckResult::Failed:\n    handleFailure(envoy::data::core::v3::ACTIVE, /*retriable=*/false);\n    break;\n  case HealthCheckResult::Retriable:\n    handleFailure(envoy::data::core::v3::ACTIVE, /*retriable=*/true);\n    break;\n  }\n\n  if (shouldClose()) {\n    client_->close();\n  }\n\n  response_headers_.reset();\n}\n\n// It is possible for this session to have been deferred destroyed inline in handleFailure()\n// above so make sure we still have a connection that we might need to close.\nbool HttpHealthCheckerImpl::HttpActiveHealthCheckSession::shouldClose() const {\n  if (client_ == nullptr) {\n    return false;\n  }\n\n  if (!reuse_connection_) {\n    return true;\n  }\n\n  return Http::HeaderUtility::shouldCloseConnection(client_->protocol(), *response_headers_);\n}\n\nvoid HttpHealthCheckerImpl::HttpActiveHealthCheckSession::onTimeout() {\n  request_in_flight_ = false;\n  if (client_) {\n    ENVOY_CONN_LOG(debug, \"connection/stream timeout health_flags={}\", *client_,\n                   HostUtility::healthFlagsToString(*host_));\n\n    // If there is an active request it will get reset, so make sure we ignore the reset.\n    expect_reset_ = true;\n\n    client_->close();\n  }\n}\n\nHttp::CodecType\nHttpHealthCheckerImpl::codecClientType(const envoy::type::v3::CodecClientType& type) {\n  switch (type) {\n    PANIC_ON_PROTO_ENUM_SENTINEL_VALUES;\n  case envoy::type::v3::HTTP3:\n    return Http::CodecType::HTTP3;\n  case envoy::type::v3::HTTP2:\n    return Http::CodecType::HTTP2;\n  case envoy::type::v3::HTTP1:\n    return Http::CodecType::HTTP1;\n  }\n  PANIC_DUE_TO_CORRUPT_ENUM\n}\n\nHttp::CodecClient*\nProdHttpHealthCheckerImpl::createCodecClient(Upstream::Host::CreateConnectionData& data) {\n  return new Http::CodecClientProd(codec_client_type_, std::move(data.connection_),\n                                   data.host_description_, dispatcher_, random_generator_);\n}\n\nTcpHealthCheckMatcher::MatchSegments TcpHealthCheckMatcher::loadProtoBytes(\n    const Protobuf::RepeatedPtrField<envoy::config::core::v3::HealthCheck::Payload>& byte_array) {\n  MatchSegments result;\n\n  for (const auto& entry : byte_array) {\n    const auto decoded = Hex::decode(entry.text());\n    if (decoded.empty()) {\n      throw EnvoyException(fmt::format(\"invalid hex string '{}'\", entry.text()));\n    }\n    result.push_back(decoded);\n  }\n\n  return result;\n}\n\nbool TcpHealthCheckMatcher::match(const MatchSegments& expected, const Buffer::Instance& buffer) {\n  uint64_t start_index = 0;\n  for (const std::vector<uint8_t>& segment : expected) {\n    ssize_t search_result = buffer.search(segment.data(), segment.size(), start_index);\n    if (search_result == -1) {\n      return false;\n    }\n\n    start_index = search_result + segment.size();\n  }\n\n  return true;\n}\n\nTcpHealthCheckerImpl::TcpHealthCheckerImpl(const Cluster& cluster,\n                                           const envoy::config::core::v3::HealthCheck& config,\n                                           Event::Dispatcher& dispatcher, Runtime::Loader& runtime,\n                                           Random::RandomGenerator& random,\n                                           HealthCheckEventLoggerPtr&& event_logger)\n    : HealthCheckerImplBase(cluster, config, dispatcher, runtime, random, std::move(event_logger)),\n      send_bytes_([&config] {\n        Protobuf::RepeatedPtrField<envoy::config::core::v3::HealthCheck::Payload> send_repeated;\n        if (!config.tcp_health_check().send().text().empty()) {\n          send_repeated.Add()->CopyFrom(config.tcp_health_check().send());\n        }\n        return TcpHealthCheckMatcher::loadProtoBytes(send_repeated);\n      }()),\n      receive_bytes_(TcpHealthCheckMatcher::loadProtoBytes(config.tcp_health_check().receive())) {}\n\nTcpHealthCheckerImpl::TcpActiveHealthCheckSession::~TcpActiveHealthCheckSession() {\n  ASSERT(client_ == nullptr);\n}\n\nvoid TcpHealthCheckerImpl::TcpActiveHealthCheckSession::onDeferredDelete() {\n  if (client_) {\n    expect_close_ = true;\n    client_->close(Network::ConnectionCloseType::NoFlush);\n  }\n}\n\nvoid TcpHealthCheckerImpl::TcpActiveHealthCheckSession::onData(Buffer::Instance& data) {\n  ENVOY_CONN_LOG(trace, \"total pending buffer={}\", *client_, data.length());\n  // TODO(lilika): The TCP health checker does generic pattern matching so we can't differentiate\n  // between wrong data and not enough data. We could likely do better here and figure out cases in\n  // which a match is not possible but that is not done now.\n  if (TcpHealthCheckMatcher::match(parent_.receive_bytes_, data)) {\n    ENVOY_CONN_LOG(trace, \"healthcheck passed\", *client_);\n    data.drain(data.length());\n    handleSuccess(false);\n    if (!parent_.reuse_connection_) {\n      expect_close_ = true;\n      client_->close(Network::ConnectionCloseType::NoFlush);\n    }\n  }\n}\n\nvoid TcpHealthCheckerImpl::TcpActiveHealthCheckSession::onEvent(Network::ConnectionEvent event) {\n  if (event == Network::ConnectionEvent::RemoteClose ||\n      event == Network::ConnectionEvent::LocalClose) {\n    if (!expect_close_) {\n      handleFailure(envoy::data::core::v3::NETWORK);\n    }\n    parent_.dispatcher_.deferredDelete(std::move(client_));\n  }\n\n  if (event == Network::ConnectionEvent::Connected && parent_.receive_bytes_.empty()) {\n    // In this case we are just testing that we can connect, so immediately succeed. Also, since\n    // we are just doing a connection test, close the connection.\n    // NOTE(mattklein123): I've seen cases where the kernel will report a successful connection, and\n    // then proceed to fail subsequent calls (so the connection did not actually succeed). I'm not\n    // sure what situations cause this. If this turns into a problem, we may need to introduce a\n    // timer and see if the connection stays alive for some period of time while waiting to read.\n    // (Though we may never get a FIN and won't know until if/when we try to write). In short, this\n    // may need to get more complicated but we can start here.\n    // TODO(mattklein123): If we had a way on the connection interface to do an immediate read (vs.\n    // evented), that would be a good check to run here to make sure it returns the equivalent of\n    // EAGAIN. Need to think through how that would look from an interface perspective.\n    // TODO(mattklein123): In the case that a user configured bytes to write, they will not be\n    // be written, since we currently have no way to know if the bytes actually get written via\n    // the connection interface. We might want to figure out how to handle this better later.\n    expect_close_ = true;\n    client_->close(Network::ConnectionCloseType::NoFlush);\n    handleSuccess(false);\n  }\n}\n\n// TODO(lilika) : Support connection pooling\nvoid TcpHealthCheckerImpl::TcpActiveHealthCheckSession::onInterval() {\n  if (!client_) {\n    client_ =\n        host_\n            ->createHealthCheckConnection(parent_.dispatcher_, parent_.transportSocketOptions(),\n                                          parent_.transportSocketMatchMetadata().get())\n            .connection_;\n    session_callbacks_ = std::make_shared<TcpSessionCallbacks>(*this);\n    client_->addConnectionCallbacks(*session_callbacks_);\n    client_->addReadFilter(session_callbacks_);\n\n    expect_close_ = false;\n    client_->connect();\n    client_->noDelay(true);\n  }\n\n  if (!parent_.send_bytes_.empty()) {\n    Buffer::OwnedImpl data;\n    for (const std::vector<uint8_t>& segment : parent_.send_bytes_) {\n      data.add(segment.data(), segment.size());\n    }\n\n    client_->write(data, false);\n  }\n}\n\nvoid TcpHealthCheckerImpl::TcpActiveHealthCheckSession::onTimeout() {\n  expect_close_ = true;\n  client_->close(Network::ConnectionCloseType::NoFlush);\n}\n\nGrpcHealthCheckerImpl::GrpcHealthCheckerImpl(const Cluster& cluster,\n                                             const envoy::config::core::v3::HealthCheck& config,\n                                             Event::Dispatcher& dispatcher,\n                                             Runtime::Loader& runtime,\n                                             Random::RandomGenerator& random,\n                                             HealthCheckEventLoggerPtr&& event_logger)\n    : HealthCheckerImplBase(cluster, config, dispatcher, runtime, random, std::move(event_logger)),\n      random_generator_(random),\n      service_method_(*Protobuf::DescriptorPool::generated_pool()->FindMethodByName(\n          \"grpc.health.v1.Health.Check\")),\n      request_headers_parser_(\n          Router::HeaderParser::configure(config.grpc_health_check().initial_metadata())) {\n  if (!config.grpc_health_check().service_name().empty()) {\n    service_name_ = config.grpc_health_check().service_name();\n  }\n\n  if (!config.grpc_health_check().authority().empty()) {\n    authority_value_ = config.grpc_health_check().authority();\n  }\n}\n\nGrpcHealthCheckerImpl::GrpcActiveHealthCheckSession::GrpcActiveHealthCheckSession(\n    GrpcHealthCheckerImpl& parent, const HostSharedPtr& host)\n    : ActiveHealthCheckSession(parent, host), parent_(parent),\n      local_connection_info_provider_(std::make_shared<Network::ConnectionInfoSetterImpl>(\n          Network::Utility::getCanonicalIpv4LoopbackAddress(),\n          Network::Utility::getCanonicalIpv4LoopbackAddress())) {}\n\nGrpcHealthCheckerImpl::GrpcActiveHealthCheckSession::~GrpcActiveHealthCheckSession() {\n  ASSERT(client_ == nullptr);\n}\n\nvoid GrpcHealthCheckerImpl::GrpcActiveHealthCheckSession::onDeferredDelete() {\n  if (client_) {\n    // If there is an active request it will get reset, so make sure we ignore the reset.\n    expect_reset_ = true;\n    client_->close();\n  }\n}\n\nvoid GrpcHealthCheckerImpl::GrpcActiveHealthCheckSession::decodeHeaders(\n    Http::ResponseHeaderMapPtr&& headers, bool end_stream) {\n  const auto http_response_status = Http::Utility::getResponseStatus(*headers);\n  if (http_response_status != enumToInt(Http::Code::OK)) {\n    // https://github.com/grpc/grpc/blob/master/doc/http-grpc-status-mapping.md requires that\n    // grpc-status be used if available.\n    if (end_stream) {\n      const auto grpc_status = Grpc::Common::getGrpcStatus(*headers);\n      if (grpc_status) {\n        onRpcComplete(grpc_status.value(), Grpc::Common::getGrpcMessage(*headers), true);\n        return;\n      }\n    }\n    onRpcComplete(Grpc::Utility::httpToGrpcStatus(http_response_status), \"non-200 HTTP response\",\n                  end_stream);\n    return;\n  }\n  if (!Grpc::Common::isGrpcResponseHeaders(*headers, end_stream)) {\n    onRpcComplete(Grpc::Status::WellKnownGrpcStatus::Internal, \"not a gRPC request\", false);\n    return;\n  }\n  if (end_stream) {\n    // This is how, for instance, grpc-go signals about missing service - HTTP/2 200 OK with\n    // 'unimplemented' gRPC status.\n    const auto grpc_status = Grpc::Common::getGrpcStatus(*headers);\n    if (grpc_status) {\n      onRpcComplete(grpc_status.value(), Grpc::Common::getGrpcMessage(*headers), true);\n      return;\n    }\n    onRpcComplete(Grpc::Status::WellKnownGrpcStatus::Internal,\n                  \"gRPC protocol violation: unexpected stream end\", true);\n  }\n}\n\nvoid GrpcHealthCheckerImpl::GrpcActiveHealthCheckSession::decodeData(Buffer::Instance& data,\n                                                                     bool end_stream) {\n  if (end_stream) {\n    onRpcComplete(Grpc::Status::WellKnownGrpcStatus::Internal,\n                  \"gRPC protocol violation: unexpected stream end\", true);\n    return;\n  }\n  // We should end up with only one frame here.\n  std::vector<Grpc::Frame> decoded_frames;\n  if (!decoder_.decode(data, decoded_frames)) {\n    onRpcComplete(Grpc::Status::WellKnownGrpcStatus::Internal, \"gRPC wire protocol decode error\",\n                  false);\n    return;\n  }\n  for (auto& frame : decoded_frames) {\n    if (frame.length_ > 0) {\n      if (health_check_response_) {\n        // grpc.health.v1.Health.Check is unary RPC, so only one message is allowed.\n        onRpcComplete(Grpc::Status::WellKnownGrpcStatus::Internal, \"unexpected streaming\", false);\n        return;\n      }\n      health_check_response_ = std::make_unique<grpc::health::v1::HealthCheckResponse>();\n      Buffer::ZeroCopyInputStreamImpl stream(std::move(frame.data_));\n\n      if (frame.flags_ != Grpc::GRPC_FH_DEFAULT ||\n          !health_check_response_->ParseFromZeroCopyStream(&stream)) {\n        onRpcComplete(Grpc::Status::WellKnownGrpcStatus::Internal,\n                      \"invalid grpc.health.v1 RPC payload\", false);\n        return;\n      }\n    }\n  }\n}\n\nvoid GrpcHealthCheckerImpl::GrpcActiveHealthCheckSession::decodeTrailers(\n    Http::ResponseTrailerMapPtr&& trailers) {\n  auto maybe_grpc_status = Grpc::Common::getGrpcStatus(*trailers);\n  auto grpc_status =\n      maybe_grpc_status\n          ? maybe_grpc_status.value()\n          : static_cast<Grpc::Status::GrpcStatus>(Grpc::Status::WellKnownGrpcStatus::Internal);\n  const std::string grpc_message =\n      maybe_grpc_status ? Grpc::Common::getGrpcMessage(*trailers) : \"invalid gRPC status\";\n  onRpcComplete(grpc_status, grpc_message, true);\n}\n\nvoid GrpcHealthCheckerImpl::GrpcActiveHealthCheckSession::onEvent(Network::ConnectionEvent event) {\n  if (event == Network::ConnectionEvent::RemoteClose ||\n      event == Network::ConnectionEvent::LocalClose) {\n    // For the raw disconnect event, we are either between intervals in which case we already have\n    // a timer setup, or we did the close or got a reset, in which case we already setup a new\n    // timer. There is nothing to do here other than blow away the client.\n    parent_.dispatcher_.deferredDelete(std::move(client_));\n  }\n}\n\nvoid GrpcHealthCheckerImpl::GrpcActiveHealthCheckSession::onInterval() {\n  if (!client_) {\n    Upstream::Host::CreateConnectionData conn =\n        host_->createHealthCheckConnection(parent_.dispatcher_, parent_.transportSocketOptions(),\n                                           parent_.transportSocketMatchMetadata().get());\n    client_ = parent_.createCodecClient(conn);\n    client_->addConnectionCallbacks(connection_callback_impl_);\n    client_->setCodecConnectionCallbacks(http_connection_callback_impl_);\n  }\n\n  request_encoder_ = &client_->newStream(*this);\n  request_encoder_->getStream().addCallbacks(*this);\n\n  const std::string& authority =\n      getHostname(host_, parent_.authority_value_, parent_.cluster_.info());\n  auto headers_message =\n      Grpc::Common::prepareHeaders(authority, parent_.service_method_.service()->full_name(),\n                                   parent_.service_method_.name(), absl::nullopt);\n  headers_message->headers().setReferenceUserAgent(\n      Http::Headers::get().UserAgentValues.EnvoyHealthChecker);\n\n  StreamInfo::StreamInfoImpl stream_info(Http::Protocol::Http2, parent_.dispatcher_.timeSource(),\n                                         local_connection_info_provider_);\n  stream_info.setUpstreamInfo(std::make_shared<StreamInfo::UpstreamInfoImpl>());\n  stream_info.upstreamInfo()->setUpstreamHost(host_);\n  parent_.request_headers_parser_->evaluateHeaders(headers_message->headers(), stream_info);\n\n  Grpc::Common::toGrpcTimeout(parent_.timeout_, headers_message->headers());\n\n  Router::FilterUtility::setUpstreamScheme(\n      headers_message->headers(),\n      // Here there is no downstream connection so scheme will be based on\n      // upstream crypto\n      host_->transportSocketFactory().implementsSecureTransport());\n\n  auto status = request_encoder_->encodeHeaders(headers_message->headers(), false);\n  // Encoding will only fail if required headers are missing.\n  ASSERT(status.ok());\n\n  grpc::health::v1::HealthCheckRequest request;\n  if (parent_.service_name_.has_value()) {\n    request.set_service(parent_.service_name_.value());\n  }\n\n  request_encoder_->encodeData(*Grpc::Common::serializeToGrpcFrame(request), true);\n}\n\nvoid GrpcHealthCheckerImpl::GrpcActiveHealthCheckSession::onResetStream(Http::StreamResetReason,\n                                                                        absl::string_view) {\n  const bool expected_reset = expect_reset_;\n  const bool goaway = received_no_error_goaway_;\n  resetState();\n\n  if (expected_reset) {\n    // Stream reset was initiated by us (bogus gRPC response, timeout or cluster host is going\n    // away). In these cases health check failure has already been reported and a GOAWAY (if any)\n    // has already been handled, so just return.\n    return;\n  }\n\n  ENVOY_CONN_LOG(debug, \"connection/stream error health_flags={}\", *client_,\n                 HostUtility::healthFlagsToString(*host_));\n\n  if (goaway || !parent_.reuse_connection_) {\n    // Stream reset was unexpected, so we haven't closed the connection\n    // yet in response to a GOAWAY or due to disabled connection reuse.\n    client_->close();\n  }\n\n  // TODO(baranov1ch): according to all HTTP standards, we should check if reason is one of\n  // Http::StreamResetReason::RemoteRefusedStreamReset (which may mean GOAWAY),\n  // Http::StreamResetReason::RemoteReset or Http::StreamResetReason::ConnectionTermination (both\n  // mean connection close), check if connection is not fresh (was used for at least 1 request)\n  // and silently retry request on the fresh connection. This is also true for HTTP/1.1 healthcheck.\n  handleFailure(envoy::data::core::v3::NETWORK);\n}\n\nvoid GrpcHealthCheckerImpl::GrpcActiveHealthCheckSession::onGoAway(\n    Http::GoAwayErrorCode error_code) {\n  ENVOY_CONN_LOG(debug, \"connection going away health_flags={}\", *client_,\n                 HostUtility::healthFlagsToString(*host_));\n  // If we have an active health check probe and receive a GOAWAY indicating\n  // graceful shutdown, allow the probe to complete before closing the connection.\n  // The connection will be closed when the active check completes or another\n  // terminal condition occurs, such as a timeout or stream reset.\n  if (request_encoder_ && error_code == Http::GoAwayErrorCode::NoError) {\n    received_no_error_goaway_ = true;\n    return;\n  }\n\n  // Even if we have active health check probe, fail it on GOAWAY and schedule new one.\n  if (request_encoder_) {\n    handleFailure(envoy::data::core::v3::NETWORK);\n    // request_encoder_ can already be destroyed if the host was removed during the failure callback\n    // above.\n    if (request_encoder_ != nullptr) {\n      expect_reset_ = true;\n      request_encoder_->getStream().resetStream(Http::StreamResetReason::LocalReset);\n    }\n  }\n  // client_ can already be destroyed if the host was removed during the failure callback above.\n  if (client_ != nullptr) {\n    client_->close();\n  }\n}\n\nbool GrpcHealthCheckerImpl::GrpcActiveHealthCheckSession::isHealthCheckSucceeded(\n    Grpc::Status::GrpcStatus grpc_status) const {\n  if (grpc_status != Grpc::Status::WellKnownGrpcStatus::Ok) {\n    return false;\n  }\n\n  if (!health_check_response_ ||\n      health_check_response_->status() != grpc::health::v1::HealthCheckResponse::SERVING) {\n    return false;\n  }\n\n  return true;\n}\n\nvoid GrpcHealthCheckerImpl::GrpcActiveHealthCheckSession::onRpcComplete(\n    Grpc::Status::GrpcStatus grpc_status, const std::string& grpc_message, bool end_stream) {\n  logHealthCheckStatus(grpc_status, grpc_message);\n  if (isHealthCheckSucceeded(grpc_status)) {\n    handleSuccess(false);\n  } else {\n    handleFailure(envoy::data::core::v3::ACTIVE);\n  }\n\n  // Read the value as we may call resetState() and clear it.\n  const bool goaway = received_no_error_goaway_;\n\n  // |end_stream| will be false if we decided to stop healthcheck before HTTP stream has ended -\n  // invalid gRPC payload, unexpected message stream or wrong content-type.\n  if (end_stream) {\n    resetState();\n  } else {\n    // request_encoder_ can already be destroyed if the host was removed during the failure callback\n    // above.\n    if (request_encoder_ != nullptr) {\n      // resetState() will be called by onResetStream().\n      expect_reset_ = true;\n      request_encoder_->getStream().resetStream(Http::StreamResetReason::LocalReset);\n    }\n  }\n\n  // client_ can already be destroyed if the host was removed during the failure callback above.\n  if (client_ != nullptr && (!parent_.reuse_connection_ || goaway)) {\n    client_->close();\n  }\n}\n\nvoid GrpcHealthCheckerImpl::GrpcActiveHealthCheckSession::resetState() {\n  expect_reset_ = false;\n  request_encoder_ = nullptr;\n  decoder_ = Grpc::Decoder();\n  health_check_response_.reset();\n  received_no_error_goaway_ = false;\n}\n\nvoid GrpcHealthCheckerImpl::GrpcActiveHealthCheckSession::onTimeout() {\n  ENVOY_CONN_LOG(debug, \"connection/stream timeout health_flags={}\", *client_,\n                 HostUtility::healthFlagsToString(*host_));\n  expect_reset_ = true;\n  if (received_no_error_goaway_ || !parent_.reuse_connection_) {\n    client_->close();\n  } else {\n    request_encoder_->getStream().resetStream(Http::StreamResetReason::LocalReset);\n  }\n}\n\nvoid GrpcHealthCheckerImpl::GrpcActiveHealthCheckSession::logHealthCheckStatus(\n    Grpc::Status::GrpcStatus grpc_status, const std::string& grpc_message) {\n  const char* service_status;\n  if (!health_check_response_) {\n    service_status = \"rpc_error\";\n  } else {\n    switch (health_check_response_->status()) {\n    case grpc::health::v1::HealthCheckResponse::SERVING:\n      service_status = \"serving\";\n      break;\n    case grpc::health::v1::HealthCheckResponse::NOT_SERVING:\n      service_status = \"not_serving\";\n      break;\n    case grpc::health::v1::HealthCheckResponse::UNKNOWN:\n      service_status = \"unknown\";\n      break;\n    case grpc::health::v1::HealthCheckResponse::SERVICE_UNKNOWN:\n      service_status = \"service_unknown\";\n      break;\n    default:\n      service_status = \"unknown_healthcheck_response\";\n      break;\n    }\n  }\n  std::string grpc_status_message;\n  if (grpc_status != Grpc::Status::WellKnownGrpcStatus::Ok && !grpc_message.empty()) {\n    grpc_status_message = fmt::format(\"{} ({})\", grpc_status, grpc_message);\n  } else {\n    grpc_status_message = absl::StrCat(\"\", grpc_status);\n  }\n\n  ENVOY_CONN_LOG(debug, \"hc grpc_status={} service_status={} health_flags={}\", *client_,\n                 grpc_status_message, service_status, HostUtility::healthFlagsToString(*host_));\n}\n\nHttp::CodecClientPtr\nProdGrpcHealthCheckerImpl::createCodecClient(Upstream::Host::CreateConnectionData& data) {\n  return std::make_unique<Http::CodecClientProd>(\n      Http::CodecType::HTTP2, std::move(data.connection_), data.host_description_, dispatcher_,\n      random_generator_);\n}\n\nstd::ostream& operator<<(std::ostream& out, HealthState state) {\n  switch (state) {\n  case HealthState::Unhealthy:\n    out << \"Unhealthy\";\n    break;\n  case HealthState::Healthy:\n    out << \"Healthy\";\n    break;\n  }\n  return out;\n}\n\nstd::ostream& operator<<(std::ostream& out, HealthTransition changed_state) {\n  switch (changed_state) {\n  case HealthTransition::Unchanged:\n    out << \"Unchanged\";\n    break;\n  case HealthTransition::Changed:\n    out << \"Changed\";\n    break;\n  case HealthTransition::ChangePending:\n    out << \"ChangePending\";\n    break;\n  }\n  return out;\n}\n\n} // namespace Upstream\n} // namespace Envoy\n", "#include <chrono>\n#include <memory>\n#include <ostream>\n#include <string>\n\n#include \"envoy/config/core/v3/base.pb.h\"\n#include \"envoy/config/core/v3/health_check.pb.h\"\n#include \"envoy/config/core/v3/health_check.pb.validate.h\"\n#include \"envoy/config/endpoint/v3/endpoint_components.pb.h\"\n#include \"envoy/data/core/v3/health_check_event.pb.h\"\n#include \"envoy/upstream/health_check_host_monitor.h\"\n\n#include \"source/common/buffer/buffer_impl.h\"\n#include \"source/common/buffer/zero_copy_input_stream_impl.h\"\n#include \"source/common/grpc/common.h\"\n#include \"source/common/http/headers.h\"\n#include \"source/common/json/json_loader.h\"\n#include \"source/common/network/utility.h\"\n#include \"source/common/protobuf/utility.h\"\n#include \"source/common/upstream/health_checker_impl.h\"\n#include \"source/common/upstream/upstream_impl.h\"\n\n#include \"test/common/http/common.h\"\n#include \"test/common/upstream/utility.h\"\n#include \"test/mocks/access_log/mocks.h\"\n#include \"test/mocks/api/mocks.h\"\n#include \"test/mocks/common.h\"\n#include \"test/mocks/http/mocks.h\"\n#include \"test/mocks/network/mocks.h\"\n#include \"test/mocks/protobuf/mocks.h\"\n#include \"test/mocks/runtime/mocks.h\"\n#include \"test/mocks/upstream/cluster_info.h\"\n#include \"test/mocks/upstream/cluster_priority_set.h\"\n#include \"test/mocks/upstream/health_check_event_logger.h\"\n#include \"test/mocks/upstream/host_set.h\"\n#include \"test/mocks/upstream/transport_socket_match.h\"\n#include \"test/test_common/printers.h\"\n#include \"test/test_common/simulated_time_system.h\"\n#include \"test/test_common/test_runtime.h\"\n#include \"test/test_common/utility.h\"\n\n#include \"gmock/gmock.h\"\n#include \"gtest/gtest.h\"\n\nusing testing::_;\nusing testing::DoAll;\nusing testing::InSequence;\nusing testing::Invoke;\nusing testing::InvokeWithoutArgs;\nusing testing::NiceMock;\nusing testing::Return;\nusing testing::ReturnRef;\nusing testing::SaveArg;\n\nnamespace Envoy {\nnamespace Upstream {\nnamespace {\n\nenvoy::config::core::v3::HealthCheck createGrpcHealthCheckConfig() {\n  envoy::config::core::v3::HealthCheck health_check;\n  health_check.mutable_timeout()->set_seconds(1);\n  health_check.mutable_interval()->set_seconds(1);\n  health_check.mutable_unhealthy_threshold()->set_value(2);\n  health_check.mutable_healthy_threshold()->set_value(2);\n  health_check.mutable_grpc_health_check();\n  return health_check;\n}\n\nTEST(HealthCheckerFactoryTest, GrpcHealthCheckHTTP2NotConfiguredException) {\n  NiceMock<Upstream::MockClusterMockPrioritySet> cluster;\n  EXPECT_CALL(*cluster.info_, features()).WillRepeatedly(Return(0));\n\n  Runtime::MockLoader runtime;\n  Event::MockDispatcher dispatcher;\n  AccessLog::MockAccessLogManager log_manager;\n  NiceMock<ProtobufMessage::MockValidationVisitor> validation_visitor;\n  Api::MockApi api;\n\n  EXPECT_THROW_WITH_MESSAGE(\n      HealthCheckerFactory::create(createGrpcHealthCheckConfig(), cluster, runtime, dispatcher,\n                                   log_manager, validation_visitor, api),\n      EnvoyException, \"fake_cluster cluster must support HTTP/2 for gRPC healthchecking\");\n}\n\nTEST(HealthCheckerFactoryTest, CreateGrpc) {\n\n  NiceMock<Upstream::MockClusterMockPrioritySet> cluster;\n  EXPECT_CALL(*cluster.info_, features())\n      .WillRepeatedly(Return(Upstream::ClusterInfo::Features::HTTP2));\n\n  Runtime::MockLoader runtime;\n  Event::MockDispatcher dispatcher;\n  AccessLog::MockAccessLogManager log_manager;\n  NiceMock<ProtobufMessage::MockValidationVisitor> validation_visitor;\n  NiceMock<Api::MockApi> api;\n\n  EXPECT_NE(nullptr,\n            dynamic_cast<GrpcHealthCheckerImpl*>(\n                HealthCheckerFactory::create(createGrpcHealthCheckConfig(), cluster, runtime,\n                                             dispatcher, log_manager, validation_visitor, api)\n                    .get()));\n}\n\nclass HealthCheckerTestBase {\npublic:\n  std::shared_ptr<MockClusterMockPrioritySet> cluster_{\n      std::make_shared<NiceMock<MockClusterMockPrioritySet>>()};\n  NiceMock<Event::MockDispatcher> dispatcher_;\n  std::unique_ptr<MockHealthCheckEventLogger> event_logger_storage_{\n      std::make_unique<MockHealthCheckEventLogger>()};\n  MockHealthCheckEventLogger& event_logger_{*event_logger_storage_};\n  NiceMock<Random::MockRandomGenerator> random_;\n  NiceMock<Runtime::MockLoader> runtime_;\n};\n\nclass TestHttpHealthCheckerImpl : public HttpHealthCheckerImpl {\npublic:\n  using HttpHealthCheckerImpl::HttpHealthCheckerImpl;\n\n  Http::CodecClient* createCodecClient(Upstream::Host::CreateConnectionData& conn_data) override {\n    return createCodecClient_(conn_data);\n  };\n\n  // HttpHealthCheckerImpl\n  MOCK_METHOD(Http::CodecClient*, createCodecClient_, (Upstream::Host::CreateConnectionData&));\n\n  Http::CodecType codecClientType() { return codec_client_type_; }\n};\n\nclass HttpHealthCheckerImplTest : public Event::TestUsingSimulatedTime,\n                                  public testing::Test,\n                                  public HealthCheckerTestBase {\npublic:\n  struct TestSession {\n    Event::MockTimer* interval_timer_{};\n    Event::MockTimer* timeout_timer_{};\n    Http::MockClientConnection* codec_{};\n    Stats::IsolatedStoreImpl stats_store_;\n    Network::MockClientConnection* client_connection_{};\n    NiceMock<Http::MockRequestEncoder> request_encoder_;\n    Http::ResponseDecoder* stream_response_callbacks_{};\n    CodecClientForTest* codec_client_{};\n  };\n\n  using TestSessionPtr = std::unique_ptr<TestSession>;\n  using HostWithHealthCheckMap =\n      absl::node_hash_map<std::string,\n                          const envoy::config::endpoint::v3::Endpoint::HealthCheckConfig>;\n\n  void allocHealthChecker(const std::string& yaml) {\n    health_checker_ = std::make_shared<TestHttpHealthCheckerImpl>(\n        *cluster_, parseHealthCheckFromV3Yaml(yaml), dispatcher_, runtime_, random_,\n        HealthCheckEventLoggerPtr(event_logger_storage_.release()));\n  }\n\n  void addCompletionCallback() {\n    health_checker_->addHostCheckCompleteCb(\n        [this](HostSharedPtr host, HealthTransition changed_state) -> void {\n          onHostStatus(host, changed_state);\n        });\n  }\n\n  void setupNoServiceValidationHCWithHttp2() {\n    const std::string yaml = R\"EOF(\n    timeout: 1s\n    interval: 1s\n    no_traffic_interval: 5s\n    interval_jitter: 1s\n    unhealthy_threshold: 2\n    healthy_threshold: 2\n    http_health_check:\n      service_name_matcher:\n        prefix: locations\n      path: /healthcheck\n      codec_client_type: Http2\n    )EOF\";\n\n    allocHealthChecker(yaml);\n    addCompletionCallback();\n  }\n\n  void setupHCHttp2() {\n    const std::string yaml = R\"EOF(\n    timeout: 1s\n    interval: 1s\n    no_traffic_interval: 5s\n    interval_jitter: 1s\n    unhealthy_threshold: 1\n    healthy_threshold: 1\n    http_health_check:\n      service_name_matcher:\n        prefix: locations\n      path: /healthcheck\n      codec_client_type: Http2\n    )EOF\";\n\n    allocHealthChecker(yaml);\n    addCompletionCallback();\n  }\n\n  void setupInitialJitter() {\n    const std::string yaml = R\"EOF(\n    timeout: 1s\n    interval: 1s\n    no_traffic_interval: 5s\n    initial_jitter: 5s\n    interval_jitter_percent: 40\n    unhealthy_threshold: 2\n    healthy_threshold: 2\n    http_health_check:\n      service_name_matcher:\n        prefix: locations\n      path: /healthcheck\n    )EOF\";\n\n    allocHealthChecker(yaml);\n    addCompletionCallback();\n  }\n\n  void setupIntervalJitterPercent() {\n    const std::string yaml = R\"EOF(\n    timeout: 1s\n    interval: 1s\n    no_traffic_interval: 5s\n    interval_jitter_percent: 40\n    unhealthy_threshold: 2\n    healthy_threshold: 2\n    http_health_check:\n      service_name_matcher:\n        prefix: locations\n      path: /healthcheck\n    )EOF\";\n\n    allocHealthChecker(yaml);\n    addCompletionCallback();\n  }\n\n  void setupNoServiceValidationHC() {\n    const std::string yaml = R\"EOF(\n    timeout: 1s\n    interval: 1s\n    no_traffic_interval: 5s\n    interval_jitter: 1s\n    unhealthy_threshold: 2\n    healthy_threshold: 2\n    http_health_check:\n      service_name_matcher:\n        prefix: locations\n      path: /healthcheck\n    )EOF\";\n\n    allocHealthChecker(yaml);\n    addCompletionCallback();\n  }\n\n  void setupNoTrafficHealthyValidationHC() {\n    const std::string yaml = R\"EOF(\n    timeout: 1s\n    interval: 1s\n    no_traffic_interval: 5s\n    no_traffic_healthy_interval: 10s\n    interval_jitter: 1s\n    unhealthy_threshold: 1\n    healthy_threshold: 1\n    http_health_check:\n      service_name_matcher:\n        prefix: locations\n      path: /healthcheck\n    )EOF\";\n\n    allocHealthChecker(yaml);\n    addCompletionCallback();\n  }\n\n  void setupNoServiceValidationHCOneUnhealthy() {\n    const std::string yaml = R\"EOF(\n    timeout: 1s\n    interval: 1s\n    no_traffic_interval: 5s\n    interval_jitter: 1s\n    unhealthy_threshold: 1\n    healthy_threshold: 2\n    http_health_check:\n      service_name_matcher:\n        prefix: locations\n      path: /healthcheck\n    )EOF\";\n\n    allocHealthChecker(yaml);\n    addCompletionCallback();\n  }\n\n  void setupNoServiceValidationHCAlwaysLogFailure() {\n    const std::string yaml = R\"EOF(\n    timeout: 1s\n    interval: 1s\n    no_traffic_interval: 5s\n    interval_jitter: 1s\n    unhealthy_threshold: 2\n    healthy_threshold: 2\n    http_health_check:\n      service_name_matcher:\n        prefix: locations\n      path: /healthcheck\n    always_log_health_check_failures: true\n    )EOF\";\n\n    allocHealthChecker(yaml);\n    addCompletionCallback();\n  }\n\n  void setupNoServiceValidationNoReuseConnectionHC() {\n    std::string yaml = R\"EOF(\n    timeout: 1s\n    interval: 1s\n    interval_jitter: 1s\n    unhealthy_threshold: 2\n    healthy_threshold: 2\n    reuse_connection: false\n    http_health_check:\n      path: /healthcheck\n    )EOF\";\n\n    allocHealthChecker(yaml);\n    addCompletionCallback();\n  }\n\n  void setupHealthCheckIntervalOverridesHC() {\n    const std::string yaml = R\"EOF(\n    timeout: 1s\n    interval: 1s\n    unhealthy_interval: 2s\n    unhealthy_edge_interval: 3s\n    healthy_edge_interval: 4s\n    no_traffic_interval: 5s\n    interval_jitter: 0s\n    unhealthy_threshold: 3\n    healthy_threshold: 3\n    http_health_check:\n      service_name_matcher:\n        prefix: locations\n      path: /healthcheck\n    )EOF\";\n\n    allocHealthChecker(yaml);\n    addCompletionCallback();\n  }\n\n  void setupServiceValidationHC() {\n    std::string yaml = R\"EOF(\n    timeout: 1s\n    interval: 1s\n    interval_jitter: 1s\n    unhealthy_threshold: 2\n    healthy_threshold: 2\n    http_health_check:\n      service_name_matcher:\n        prefix: locations\n      path: /healthcheck\n    )EOF\";\n\n    allocHealthChecker(yaml);\n    addCompletionCallback();\n  }\n\n  void setupServiceNameValidationHC(const std::string& prefix) {\n    std::string yaml = fmt::format(R\"EOF(\n    timeout: 1s\n    interval: 1s\n    interval_jitter: 1s\n    unhealthy_threshold: 2\n    healthy_threshold: 2\n    http_health_check:\n      service_name_matcher:\n        prefix: {0}\n      path: /healthcheck\n    )EOF\",\n                                   prefix);\n\n    allocHealthChecker(yaml);\n    addCompletionCallback();\n  }\n\n  void setupServicePrefixPatternValidationHC() {\n    std::string yaml = R\"EOF(\n    timeout: 1s\n    interval: 1s\n    interval_jitter: 1s\n    unhealthy_threshold: 2\n    healthy_threshold: 2\n    http_health_check:\n      service_name_matcher:\n        prefix: locations\n      path: /healthcheck\n    )EOF\";\n\n    allocHealthChecker(yaml);\n    addCompletionCallback();\n  }\n\n  void setupServiceExactPatternValidationHC() {\n    std::string yaml = R\"EOF(\n    timeout: 1s\n    interval: 1s\n    interval_jitter: 1s\n    unhealthy_threshold: 2\n    healthy_threshold: 2\n    http_health_check:\n      service_name_matcher:\n        exact: locations-production-iad\n      path: /healthcheck\n    )EOF\";\n\n    allocHealthChecker(yaml);\n    addCompletionCallback();\n  }\n\n  void setupServiceRegexPatternValidationHC() {\n    std::string yaml = R\"EOF(\n    timeout: 1s\n    interval: 1s\n    interval_jitter: 1s\n    unhealthy_threshold: 2\n    healthy_threshold: 2\n    http_health_check:\n      service_name_matcher:\n        safe_regex:\n          google_re2: {}\n          regex: 'locations-.*-.*$'\n      path: /healthcheck\n    )EOF\";\n\n    allocHealthChecker(yaml);\n    addCompletionCallback();\n  }\n\n  void setupServiceValidationWithCustomHostValueHC(const std::string& host) {\n    std::string yaml = fmt::format(R\"EOF(\n    timeout: 1s\n    interval: 1s\n    interval_jitter: 1s\n    unhealthy_threshold: 2\n    healthy_threshold: 2\n    http_health_check:\n      service_name_matcher:\n        prefix: locations\n      path: /healthcheck\n      host: {0}\n    )EOF\",\n                                   host);\n\n    allocHealthChecker(yaml);\n    addCompletionCallback();\n  }\n\n  const envoy::config::endpoint::v3::Endpoint::HealthCheckConfig\n  makeHealthCheckConfig(const uint32_t port_value) {\n    envoy::config::endpoint::v3::Endpoint::HealthCheckConfig config;\n    config.set_port_value(port_value);\n    return config;\n  }\n\n  void appendTestHosts(std::shared_ptr<MockClusterMockPrioritySet> cluster,\n                       const HostWithHealthCheckMap& hosts, const std::string& protocol = \"tcp://\",\n                       const uint32_t priority = 0) {\n    for (const auto& host : hosts) {\n      cluster->prioritySet().getMockHostSet(priority)->hosts_.emplace_back(makeTestHost(\n          cluster->info_, fmt::format(\"{}{}\", protocol, host.first), host.second, simTime()));\n    }\n  }\n\n  void setupServiceValidationWithAdditionalHeaders() {\n    std::string yaml = R\"EOF(\n    timeout: 1s\n    interval: 1s\n    interval_jitter: 1s\n    unhealthy_threshold: 2\n    healthy_threshold: 2\n    http_health_check:\n      service_name_matcher:\n        prefix: locations\n      path: /healthcheck\n      host: \"www.envoyproxy.io\"\n      request_headers_to_add:\n        - header:\n            key: x-envoy-ok\n            value: ok\n        - header:\n            key: x-envoy-cool\n            value: cool\n        - header:\n            key: x-envoy-awesome\n            value: awesome\n        # The following entry replaces the current user-agent.\n        - header:\n            key: user-agent\n            value: CoolEnvoy/HC\n          append: false\n        - header:\n            key: x-protocol\n            value: \"%PROTOCOL%\"\n        - header:\n            key: x-upstream-metadata\n            value: \"%UPSTREAM_METADATA([\\\"namespace\\\", \\\"key\\\"])%\"\n        - header:\n            key: x-downstream-remote-address\n            value: \"%DOWNSTREAM_REMOTE_ADDRESS%\"\n        - header:\n            key: x-downstream-remote-address-without-port\n            value: \"%DOWNSTREAM_REMOTE_ADDRESS_WITHOUT_PORT%\"\n        - header:\n            key: x-downstream-local-address\n            value: \"%DOWNSTREAM_LOCAL_ADDRESS%\"\n        - header:\n            key: x-downstream-local-address-without-port\n            value: \"%DOWNSTREAM_LOCAL_ADDRESS_WITHOUT_PORT%\"\n        - header:\n            key: x-start-time\n            value: \"%START_TIME(%s.%9f)%\"\n    )EOF\";\n\n    allocHealthChecker(yaml);\n    addCompletionCallback();\n  }\n\n  void setupServiceValidationWithoutUserAgent() {\n    std::string yaml = R\"EOF(\n    timeout: 1s\n    interval: 1s\n    interval_jitter: 1s\n    unhealthy_threshold: 2\n    healthy_threshold: 2\n    http_health_check:\n      service_name_matcher:\n        prefix: locations\n      path: /healthcheck\n      host: \"www.envoyproxy.io\"\n      # The following entry removes the default \"user-agent\" header.\n      request_headers_to_remove: [\"user-agent\"]\n    )EOF\";\n\n    allocHealthChecker(yaml);\n    addCompletionCallback();\n  }\n\n  void expectSessionCreate(const HostWithHealthCheckMap& health_check_map) {\n    // Expectations are in LIFO order.\n    TestSessionPtr new_test_session(new TestSession());\n    new_test_session->timeout_timer_ = new Event::MockTimer(&dispatcher_);\n    new_test_session->interval_timer_ = new Event::MockTimer(&dispatcher_);\n    test_sessions_.emplace_back(std::move(new_test_session));\n    expectClientCreate(test_sessions_.size() - 1, health_check_map);\n  }\n\n  void expectClientCreate(size_t index, const HostWithHealthCheckMap& health_check_map) {\n    TestSession& test_session = *test_sessions_[index];\n    test_session.codec_ = new NiceMock<Http::MockClientConnection>();\n    ON_CALL(*test_session.codec_, protocol()).WillByDefault(Return(Http::Protocol::Http11));\n    test_session.client_connection_ = new NiceMock<Network::MockClientConnection>();\n    connection_index_.push_back(index);\n    codec_index_.push_back(index);\n\n    EXPECT_CALL(dispatcher_, createClientConnection_(_, _, _, _))\n        .Times(testing::AnyNumber())\n        .WillRepeatedly(InvokeWithoutArgs([&]() -> Network::ClientConnection* {\n          const uint32_t index = connection_index_.front();\n          connection_index_.pop_front();\n          return test_sessions_[index]->client_connection_;\n        }));\n    EXPECT_CALL(*health_checker_, createCodecClient_(_))\n        .WillRepeatedly(\n            Invoke([&](Upstream::Host::CreateConnectionData& conn_data) -> Http::CodecClient* {\n              if (!health_check_map.empty()) {\n                const auto& health_check_config =\n                    health_check_map.at(conn_data.host_description_->address()->asString());\n                // To make sure health checker checks the correct port.\n                EXPECT_EQ(health_check_config.port_value(),\n                          conn_data.host_description_->healthCheckAddress()->ip()->port());\n              }\n              const uint32_t index = codec_index_.front();\n              codec_index_.pop_front();\n              TestSession& test_session = *test_sessions_[index];\n              std::shared_ptr<Upstream::MockClusterInfo> cluster{\n                  new NiceMock<Upstream::MockClusterInfo>()};\n              Event::MockDispatcher dispatcher_;\n              test_session.codec_client_ = new CodecClientForTest(\n                  Http::CodecType::HTTP1, std::move(conn_data.connection_), test_session.codec_,\n                  nullptr, Upstream::makeTestHost(cluster, \"tcp://127.0.0.1:9000\", simTime()),\n                  dispatcher_);\n              return test_session.codec_client_;\n            }));\n  }\n\n  void expectStreamCreate(size_t index) {\n    test_sessions_[index]->request_encoder_.stream_.callbacks_.clear();\n    EXPECT_CALL(*test_sessions_[index]->codec_, newStream(_))\n        .WillOnce(DoAll(SaveArgAddress(&test_sessions_[index]->stream_response_callbacks_),\n                        ReturnRef(test_sessions_[index]->request_encoder_)));\n  }\n\n  void respond(size_t index, const std::string& code, bool conn_close, bool proxy_close = false,\n               bool body = false, bool trailers = false,\n               const absl::optional<std::string>& service_cluster = absl::optional<std::string>(),\n               bool degraded = false, bool immediate_hc_fail = false) {\n    std::unique_ptr<Http::TestResponseHeaderMapImpl> response_headers(\n        new Http::TestResponseHeaderMapImpl{{\":status\", code}});\n\n    if (degraded) {\n      response_headers->setEnvoyDegraded(\"\");\n    }\n    if (service_cluster) {\n      response_headers->addCopy(Http::Headers::get().EnvoyUpstreamHealthCheckedCluster,\n                                service_cluster.value());\n    }\n    if (conn_close) {\n      response_headers->addCopy(\"connection\", \"close\");\n    }\n    if (proxy_close) {\n      response_headers->addCopy(\"proxy-connection\", \"close\");\n    }\n    if (immediate_hc_fail) {\n      response_headers->setEnvoyImmediateHealthCheckFail(\"true\");\n    }\n\n    test_sessions_[index]->stream_response_callbacks_->decodeHeaders(std::move(response_headers),\n                                                                     !body && !trailers);\n    if (body) {\n      Buffer::OwnedImpl response_data;\n      test_sessions_[index]->stream_response_callbacks_->decodeData(response_data, !trailers);\n    }\n\n    if (trailers) {\n      test_sessions_[index]->stream_response_callbacks_->decodeTrailers(\n          Http::ResponseTrailerMapPtr{new Http::TestResponseTrailerMapImpl{{\"some\", \"trailer\"}}});\n    }\n  }\n\n  void expectSessionCreate() { expectSessionCreate(health_checker_map_); }\n  void expectClientCreate(size_t index) { expectClientCreate(index, health_checker_map_); }\n\n  void expectSuccessStartFailedFailFirst(\n      const absl::optional<std::string>& health_checked_cluster = absl::optional<std::string>()) {\n    cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n        makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n    cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthFlagSet(\n        Host::HealthFlag::FAILED_ACTIVE_HC);\n    expectSessionCreate();\n    expectStreamCreate(0);\n    EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n    health_checker_->start();\n\n    // Test that failing first disables fast success.\n    EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n    EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(_, _));\n    EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n    EXPECT_CALL(event_logger_, logUnhealthy(_, _, _, true));\n    respond(0, \"503\", false, false, false, false, health_checked_cluster);\n    EXPECT_TRUE(cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthFlagGet(\n        Host::HealthFlag::FAILED_ACTIVE_HC));\n    EXPECT_EQ(Host::Health::Unhealthy,\n              cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n\n    EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n    expectStreamCreate(0);\n    test_sessions_[0]->interval_timer_->invokeCallback();\n\n    EXPECT_CALL(*this, onHostStatus(_, HealthTransition::ChangePending));\n    EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(_, _));\n    EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n    respond(0, \"200\", false, false, false, false, health_checked_cluster);\n    EXPECT_TRUE(cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthFlagGet(\n        Host::HealthFlag::FAILED_ACTIVE_HC));\n    EXPECT_EQ(Host::Health::Unhealthy,\n              cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n\n    EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n    expectStreamCreate(0);\n    test_sessions_[0]->interval_timer_->invokeCallback();\n\n    EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Changed));\n    EXPECT_CALL(event_logger_, logAddHealthy(_, _, false));\n    EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(_, _));\n    EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n    respond(0, \"200\", false, false, false, false, health_checked_cluster);\n    EXPECT_EQ(Host::Health::Healthy,\n              cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n  }\n\n  MOCK_METHOD(void, onHostStatus, (HostSharedPtr host, HealthTransition changed_state));\n\n  void expectUnhealthyTransition(size_t index, bool first_check) {\n    EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Changed));\n    EXPECT_CALL(*test_sessions_[index]->timeout_timer_, disableTimer());\n    EXPECT_CALL(*test_sessions_[index]->interval_timer_, enableTimer(_, _));\n    if (first_check) {\n      EXPECT_CALL(event_logger_, logUnhealthy(_, _, _, _));\n    }\n    EXPECT_CALL(event_logger_, logEjectUnhealthy(_, _, _));\n  }\n\n  void expectHealthyTransition(size_t index) {\n    EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Changed));\n    EXPECT_CALL(*test_sessions_[index]->timeout_timer_, disableTimer());\n    EXPECT_CALL(*test_sessions_[index]->interval_timer_, enableTimer(_, _));\n    EXPECT_CALL(event_logger_, logAddHealthy(_, _, _));\n  }\n\n  void expectUnchanged(size_t index) {\n    EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n    EXPECT_CALL(*test_sessions_[index]->timeout_timer_, disableTimer());\n    EXPECT_CALL(*test_sessions_[index]->interval_timer_, enableTimer(_, _));\n  }\n\n  void expectChangePending(size_t index) {\n    EXPECT_CALL(*this, onHostStatus(_, HealthTransition::ChangePending));\n    EXPECT_CALL(*test_sessions_[index]->timeout_timer_, disableTimer());\n    EXPECT_CALL(*test_sessions_[index]->interval_timer_, enableTimer(_, _));\n  }\n\n  std::vector<TestSessionPtr> test_sessions_;\n  std::shared_ptr<TestHttpHealthCheckerImpl> health_checker_;\n  std::list<uint32_t> connection_index_{};\n  std::list<uint32_t> codec_index_{};\n  const HostWithHealthCheckMap health_checker_map_{};\n};\n\nTEST_F(HttpHealthCheckerImplTest, Success) {\n  setupNoServiceValidationHC();\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  cluster_->info_->stats().upstream_cx_total_.inc();\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.max_interval\", _));\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.min_interval\", _))\n      .WillOnce(Return(45000));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_,\n              enableTimer(std::chrono::milliseconds(45000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  respond(0, \"200\", false, false, true);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n}\n\nTEST_F(HttpHealthCheckerImplTest, Degraded) {\n  setupNoServiceValidationHC();\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Changed)).Times(2);\n\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  cluster_->info_->stats().upstream_cx_total_.inc();\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.max_interval\", _));\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.min_interval\", _))\n      .WillRepeatedly(Return(45000));\n\n  // We start off as healthy, and should go degraded after receiving the degraded health response.\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(_, _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  EXPECT_CALL(event_logger_, logDegraded(_, _));\n  respond(0, \"200\", false, false, true, false, {}, true);\n  EXPECT_EQ(Host::Health::Degraded, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n\n  // Then, after receiving a regular health check response we should go back to healthy.\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  expectStreamCreate(0);\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.max_interval\", _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  test_sessions_[0]->interval_timer_->invokeCallback();\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(_, _));\n  EXPECT_CALL(event_logger_, logNoLongerDegraded(_, _));\n  respond(0, \"200\", false, false, true, false, {}, false);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n}\n\nTEST_F(HttpHealthCheckerImplTest, SuccessIntervalJitter) {\n  setupNoServiceValidationHC();\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged)).Times(testing::AnyNumber());\n\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(_, _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  respond(0, \"200\", false, false, true, true);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n\n  for (int i = 0; i < 50000; i += 239) {\n    EXPECT_CALL(random_, random()).WillOnce(Return(i));\n    EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n    expectStreamCreate(0);\n    test_sessions_[0]->interval_timer_->invokeCallback();\n    // the jitter is 1000ms here\n    EXPECT_CALL(*test_sessions_[0]->interval_timer_,\n                enableTimer(std::chrono::milliseconds(5000 + i % 1000), _));\n    EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n    respond(0, \"200\", false, false, true, true);\n  }\n}\n\nTEST_F(HttpHealthCheckerImplTest, InitialJitterNoTraffic) {\n  setupInitialJitter();\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged)).Times(testing::AnyNumber());\n\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(_, _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(_, _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  respond(0, \"200\", false, false, true, true);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n\n  for (int i = 0; i < 2; i += 1) {\n    EXPECT_CALL(random_, random()).WillOnce(Return(i));\n    EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n    expectStreamCreate(0);\n    test_sessions_[0]->interval_timer_->invokeCallback();\n    // the jitter is 40% of 5000, so should be 2000\n    EXPECT_CALL(*test_sessions_[0]->interval_timer_,\n                enableTimer(std::chrono::milliseconds(5000 + i % 2000), _));\n    EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n    respond(0, \"200\", false, false, true, true);\n  }\n}\n\nTEST_F(HttpHealthCheckerImplTest, SuccessIntervalJitterPercentNoTraffic) {\n  setupIntervalJitterPercent();\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged)).Times(testing::AnyNumber());\n\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(_, _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  respond(0, \"200\", false, false, true, true);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n\n  for (int i = 0; i < 50000; i += 239) {\n    EXPECT_CALL(random_, random()).WillOnce(Return(i));\n    EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n    expectStreamCreate(0);\n    test_sessions_[0]->interval_timer_->invokeCallback();\n    // the jitter is 40% of 5000, so should be 2000\n    EXPECT_CALL(*test_sessions_[0]->interval_timer_,\n                enableTimer(std::chrono::milliseconds(5000 + i % 2000), _));\n    EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n    respond(0, \"200\", false, false, true, true);\n  }\n}\n\nTEST_F(HttpHealthCheckerImplTest, SuccessIntervalJitterPercent) {\n  setupIntervalJitterPercent();\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged)).Times(testing::AnyNumber());\n\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  cluster_->info_->stats().upstream_cx_total_.inc();\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(_, _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  respond(0, \"200\", false, false, true, true);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n\n  for (int i = 0; i < 50000; i += 239) {\n    EXPECT_CALL(random_, random()).WillOnce(Return(i));\n    EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n    expectStreamCreate(0);\n    test_sessions_[0]->interval_timer_->invokeCallback();\n    // the jitter is 40% of 1000, so should be 400\n    EXPECT_CALL(*test_sessions_[0]->interval_timer_,\n                enableTimer(std::chrono::milliseconds(1000 + i % 400), _));\n    EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n    respond(0, \"200\", false, false, true, true);\n  }\n}\n\nTEST_F(HttpHealthCheckerImplTest, SuccessWithSpurious1xx) {\n  setupNoServiceValidationHC();\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  cluster_->info_->stats().upstream_cx_total_.inc();\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.max_interval\", _));\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.min_interval\", _))\n      .WillOnce(Return(45000));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_,\n              enableTimer(std::chrono::milliseconds(45000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n\n  std::unique_ptr<Http::TestResponseHeaderMapImpl> continue_headers(\n      new Http::TestResponseHeaderMapImpl{{\":status\", \"100\"}});\n  test_sessions_[0]->stream_response_callbacks_->decode1xxHeaders(std::move(continue_headers));\n\n  respond(0, \"200\", false, false, true);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n}\n\nTEST_F(HttpHealthCheckerImplTest, SuccessWithSpuriousMetadata) {\n  setupNoServiceValidationHC();\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  cluster_->info_->stats().upstream_cx_total_.inc();\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.max_interval\", _));\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.min_interval\", _))\n      .WillOnce(Return(45000));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_,\n              enableTimer(std::chrono::milliseconds(45000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n\n  std::unique_ptr<Http::MetadataMap> metadata_map(new Http::MetadataMap());\n  metadata_map->insert(std::make_pair<std::string, std::string>(\"key\", \"value\"));\n  test_sessions_[0]->stream_response_callbacks_->decodeMetadata(std::move(metadata_map));\n\n  respond(0, \"200\", false, false, true);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n}\n\n// Test host check success with multiple hosts.\nTEST_F(HttpHealthCheckerImplTest, SuccessWithMultipleHosts) {\n  setupNoServiceValidationHC();\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged)).Times(2);\n\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime()),\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:81\", simTime())};\n  cluster_->info_->stats().upstream_cx_total_.inc();\n  cluster_->info_->stats().upstream_cx_total_.inc();\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  expectSessionCreate();\n  expectStreamCreate(1);\n  EXPECT_CALL(*test_sessions_[1]->timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.max_interval\", _)).Times(2);\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.min_interval\", _))\n      .Times(2)\n      .WillRepeatedly(Return(45000));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_,\n              enableTimer(std::chrono::milliseconds(45000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  EXPECT_CALL(*test_sessions_[1]->interval_timer_,\n              enableTimer(std::chrono::milliseconds(45000), _));\n  EXPECT_CALL(*test_sessions_[1]->timeout_timer_, disableTimer());\n  respond(0, \"200\", false, false, true);\n  respond(1, \"200\", false, false, true);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[1]->health());\n}\n\n// Test host check success with multiple hosts across multiple priorities.\nTEST_F(HttpHealthCheckerImplTest, SuccessWithMultipleHostSets) {\n  setupNoServiceValidationHC();\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged)).Times(2);\n\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  cluster_->prioritySet().getMockHostSet(1)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:81\", simTime())};\n  cluster_->info_->stats().upstream_cx_total_.inc();\n  cluster_->info_->stats().upstream_cx_total_.inc();\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  expectSessionCreate();\n  expectStreamCreate(1);\n  EXPECT_CALL(*test_sessions_[1]->timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.max_interval\", _)).Times(2);\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.min_interval\", _))\n      .Times(2)\n      .WillRepeatedly(Return(45000));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_,\n              enableTimer(std::chrono::milliseconds(45000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  EXPECT_CALL(*test_sessions_[1]->interval_timer_,\n              enableTimer(std::chrono::milliseconds(45000), _));\n  EXPECT_CALL(*test_sessions_[1]->timeout_timer_, disableTimer());\n  respond(0, \"200\", false, false, true);\n  respond(1, \"200\", false, false, true);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(1)->hosts_[0]->health());\n}\n\n// Validate that runtime settings can't force a zero lengthy retry duration (and hence livelock).\nTEST_F(HttpHealthCheckerImplTest, ZeroRetryInterval) {\n  const std::string host = \"fake_cluster\";\n  const std::string path = \"/healthcheck\";\n  const std::string yaml = R\"EOF(\n    timeout: 1s\n    interval: 1s\n    no_traffic_interval: 1s\n    interval_jitter_percent: 40\n    unhealthy_threshold: 2\n    healthy_threshold: 2\n    http_health_check:\n      service_name_matcher:\n        prefix: locations\n      path: /healthcheck\n    )EOF\";\n\n  allocHealthChecker(yaml);\n  addCompletionCallback();\n\n  EXPECT_CALL(runtime_.snapshot_, featureEnabled(\"health_check.verify_cluster\", 100))\n      .WillOnce(Return(true));\n\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  cluster_->info_->stats().upstream_cx_total_.inc();\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  EXPECT_CALL(test_sessions_[0]->request_encoder_, encodeHeaders(_, true))\n      .WillOnce(Invoke([&](const Http::RequestHeaderMap& headers, bool) -> Http::Status {\n        EXPECT_EQ(headers.getHostValue(), host);\n        EXPECT_EQ(headers.getPathValue(), path);\n        EXPECT_EQ(headers.getSchemeValue(), Http::Headers::get().SchemeValues.Http);\n        return Http::okStatus();\n      }));\n  health_checker_->start();\n\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.max_interval\", _)).WillOnce(Return(0));\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.min_interval\", _)).WillOnce(Return(0));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(std::chrono::milliseconds(1), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  absl::optional<std::string> health_checked_cluster(\"locations-production-iad\");\n  respond(0, \"200\", false, false, true, false, health_checked_cluster);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n}\n\nMATCHER_P(ApplicationProtocolListEq, expected, \"\") {\n  const Network::TransportSocketOptionsConstSharedPtr& options = arg;\n  EXPECT_EQ(options->applicationProtocolListOverride(), std::vector<std::string>{expected});\n  return true;\n}\n\nTEST_F(HttpHealthCheckerImplTest, TlsOptions) {\n  const std::string host = \"fake_cluster\";\n  const std::string path = \"/healthcheck\";\n  const std::string yaml = R\"EOF(\n    timeout: 1s\n    interval: 1s\n    no_traffic_interval: 1s\n    interval_jitter_percent: 40\n    unhealthy_threshold: 2\n    healthy_threshold: 2\n    http_health_check:\n      service_name_matcher:\n        prefix: locations\n      path: /healthcheck\n    tls_options:\n      alpn_protocols:\n      - http1\n    )EOF\";\n\n  auto socket_factory = new Network::MockTransportSocketFactory();\n  EXPECT_CALL(*socket_factory, implementsSecureTransport()).WillRepeatedly(Return(true));\n  auto transport_socket_match = new NiceMock<Upstream::MockTransportSocketMatcher>(\n      Network::TransportSocketFactoryPtr(socket_factory));\n  cluster_->info_->transport_socket_matcher_.reset(transport_socket_match);\n\n  EXPECT_CALL(*socket_factory, createTransportSocket(ApplicationProtocolListEq(\"http1\")));\n\n  allocHealthChecker(yaml);\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  cluster_->info_->stats().upstream_cx_total_.inc();\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n}\n\nTEST_F(HttpHealthCheckerImplTest, SuccessServiceCheck) {\n  const std::string host = \"fake_cluster\";\n  const std::string path = \"/healthcheck\";\n  setupServiceValidationHC();\n  EXPECT_CALL(runtime_.snapshot_, featureEnabled(\"health_check.verify_cluster\", 100))\n      .WillOnce(Return(true));\n\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  cluster_->info_->stats().upstream_cx_total_.inc();\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  EXPECT_CALL(test_sessions_[0]->request_encoder_, encodeHeaders(_, true))\n      .WillOnce(Invoke([&](const Http::RequestHeaderMap& headers, bool) -> Http::Status {\n        EXPECT_EQ(headers.getHostValue(), host);\n        EXPECT_EQ(headers.getPathValue(), path);\n        EXPECT_EQ(headers.getSchemeValue(), Http::Headers::get().SchemeValues.Http);\n        return Http::okStatus();\n      }));\n  health_checker_->start();\n\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.max_interval\", _));\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.min_interval\", _))\n      .WillOnce(Return(45000));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_,\n              enableTimer(std::chrono::milliseconds(45000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  absl::optional<std::string> health_checked_cluster(\"locations-production-iad\");\n  respond(0, \"200\", false, false, true, false, health_checked_cluster);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n}\n\nTEST_F(HttpHealthCheckerImplTest, SuccessServicePrefixPatternCheck) {\n  const std::string host = \"fake_cluster\";\n  const std::string path = \"/healthcheck\";\n  setupServicePrefixPatternValidationHC();\n  EXPECT_CALL(runtime_.snapshot_, featureEnabled(\"health_check.verify_cluster\", 100))\n      .WillOnce(Return(true));\n\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  cluster_->info_->stats().upstream_cx_total_.inc();\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  EXPECT_CALL(test_sessions_[0]->request_encoder_, encodeHeaders(_, true))\n      .WillOnce(Invoke([&](const Http::RequestHeaderMap& headers, bool) -> Http::Status {\n        EXPECT_EQ(headers.getHostValue(), host);\n        EXPECT_EQ(headers.getPathValue(), path);\n        EXPECT_EQ(headers.getSchemeValue(), Http::Headers::get().SchemeValues.Http);\n        return Http::okStatus();\n      }));\n  health_checker_->start();\n\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.max_interval\", _));\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.min_interval\", _))\n      .WillOnce(Return(45000));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_,\n              enableTimer(std::chrono::milliseconds(45000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  absl::optional<std::string> health_checked_cluster(\"locations-production-iad\");\n  respond(0, \"200\", false, false, true, false, health_checked_cluster);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n}\n\nTEST_F(HttpHealthCheckerImplTest, SuccessServiceExactPatternCheck) {\n  const std::string host = \"fake_cluster\";\n  const std::string path = \"/healthcheck\";\n  setupServiceExactPatternValidationHC();\n  EXPECT_CALL(runtime_.snapshot_, featureEnabled(\"health_check.verify_cluster\", 100))\n      .WillOnce(Return(true));\n\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  cluster_->info_->stats().upstream_cx_total_.inc();\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  EXPECT_CALL(test_sessions_[0]->request_encoder_, encodeHeaders(_, true))\n      .WillOnce(Invoke([&](const Http::RequestHeaderMap& headers, bool) -> Http::Status {\n        EXPECT_EQ(headers.getHostValue(), host);\n        EXPECT_EQ(headers.getPathValue(), path);\n        EXPECT_EQ(headers.getSchemeValue(), Http::Headers::get().SchemeValues.Http);\n        return Http::okStatus();\n      }));\n  health_checker_->start();\n\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.max_interval\", _));\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.min_interval\", _))\n      .WillOnce(Return(45000));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_,\n              enableTimer(std::chrono::milliseconds(45000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  absl::optional<std::string> health_checked_cluster(\"locations-production-iad\");\n  respond(0, \"200\", false, false, true, false, health_checked_cluster);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n}\n\nTEST_F(HttpHealthCheckerImplTest, SuccessServiceRegexPatternCheck) {\n  const std::string host = \"fake_cluster\";\n  const std::string path = \"/healthcheck\";\n  setupServiceRegexPatternValidationHC();\n  EXPECT_CALL(runtime_.snapshot_, featureEnabled(\"health_check.verify_cluster\", 100))\n      .WillOnce(Return(true));\n\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  cluster_->info_->stats().upstream_cx_total_.inc();\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  EXPECT_CALL(test_sessions_[0]->request_encoder_, encodeHeaders(_, true))\n      .WillOnce(Invoke([&](const Http::RequestHeaderMap& headers, bool) -> Http::Status {\n        EXPECT_EQ(headers.getHostValue(), host);\n        EXPECT_EQ(headers.getPathValue(), path);\n        EXPECT_EQ(headers.getSchemeValue(), Http::Headers::get().SchemeValues.Http);\n        return Http::okStatus();\n      }));\n  health_checker_->start();\n\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.max_interval\", _));\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.min_interval\", _))\n      .WillOnce(Return(45000));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_,\n              enableTimer(std::chrono::milliseconds(45000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  absl::optional<std::string> health_checked_cluster(\"locations-production-iad\");\n  respond(0, \"200\", false, false, true, false, health_checked_cluster);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n}\n\n// This test verifies that when a hostname is set in the endpoint's HealthCheckConfig, it is used in\n// the health check request.\nTEST_F(HttpHealthCheckerImplTest, SuccessServiceCheckWithCustomHostValueOnTheHost) {\n  const std::string host = \"www.envoyproxy.io\";\n  envoy::config::endpoint::v3::Endpoint::HealthCheckConfig health_check_config;\n  health_check_config.set_hostname(host);\n  auto test_host = std::make_shared<HostImpl>(\n      cluster_->info_, \"\", Network::Utility::resolveUrl(\"tcp://127.0.0.1:80\"), nullptr, 1,\n      envoy::config::core::v3::Locality(), health_check_config, 0, envoy::config::core::v3::UNKNOWN,\n      simTime());\n  const std::string path = \"/healthcheck\";\n  setupServiceValidationHC();\n  // Requires non-empty `service_name` in config.\n  EXPECT_CALL(runtime_.snapshot_, featureEnabled(\"health_check.verify_cluster\", 100))\n      .WillOnce(Return(true));\n\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {test_host};\n  cluster_->info_->stats().upstream_cx_total_.inc();\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  EXPECT_CALL(test_sessions_[0]->request_encoder_, encodeHeaders(_, true))\n      .WillOnce(Invoke([&](const Http::RequestHeaderMap& headers, bool) -> Http::Status {\n        EXPECT_EQ(headers.getHostValue(), host);\n        EXPECT_EQ(headers.getPathValue(), path);\n        return Http::okStatus();\n      }));\n  health_checker_->start();\n\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.max_interval\", _));\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.min_interval\", _))\n      .WillOnce(Return(45000));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_,\n              enableTimer(std::chrono::milliseconds(45000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  absl::optional<std::string> health_checked_cluster(\"locations-production-iad\");\n  respond(0, \"200\", false, false, true, false, health_checked_cluster);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n}\n\n// This test verifies that when a hostname is set in the endpoint's HealthCheckConfig and in the\n// cluster level configuration, the one in the endpoint takes priority.\nTEST_F(HttpHealthCheckerImplTest,\n       SuccessServiceCheckWithCustomHostValueOnTheHostThatOverridesConfigValue) {\n  const std::string host = \"www.envoyproxy.io\";\n  envoy::config::endpoint::v3::Endpoint::HealthCheckConfig health_check_config;\n  health_check_config.set_hostname(host);\n  auto test_host = std::make_shared<HostImpl>(\n      cluster_->info_, \"\", Network::Utility::resolveUrl(\"tcp://127.0.0.1:80\"), nullptr, 1,\n      envoy::config::core::v3::Locality(), health_check_config, 0, envoy::config::core::v3::UNKNOWN,\n      simTime());\n  const std::string path = \"/healthcheck\";\n  // Setup health check config with a different host, to check that we still get the host configured\n  // on the endpoint.\n  setupServiceValidationWithCustomHostValueHC(\"foo.com\");\n  // Requires non-empty `service_name` in config.\n  EXPECT_CALL(runtime_.snapshot_, featureEnabled(\"health_check.verify_cluster\", 100))\n      .WillOnce(Return(true));\n\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {test_host};\n  cluster_->info_->stats().upstream_cx_total_.inc();\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  EXPECT_CALL(test_sessions_[0]->request_encoder_, encodeHeaders(_, true))\n      .WillOnce(Invoke([&](const Http::RequestHeaderMap& headers, bool) -> Http::Status {\n        EXPECT_EQ(headers.getHostValue(), host);\n        EXPECT_EQ(headers.getPathValue(), path);\n        return Http::okStatus();\n      }));\n  health_checker_->start();\n\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.max_interval\", _));\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.min_interval\", _))\n      .WillOnce(Return(45000));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_,\n              enableTimer(std::chrono::milliseconds(45000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  absl::optional<std::string> health_checked_cluster(\"locations-production-iad\");\n  respond(0, \"200\", false, false, true, false, health_checked_cluster);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n}\n\nTEST_F(HttpHealthCheckerImplTest, SuccessServiceCheckWithCustomHostValue) {\n  const std::string host = \"www.envoyproxy.io\";\n  const std::string path = \"/healthcheck\";\n  setupServiceValidationWithCustomHostValueHC(host);\n  // Requires non-empty `service_name` in config.\n  EXPECT_CALL(runtime_.snapshot_, featureEnabled(\"health_check.verify_cluster\", 100))\n      .WillOnce(Return(true));\n\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  cluster_->info_->stats().upstream_cx_total_.inc();\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  EXPECT_CALL(test_sessions_[0]->request_encoder_, encodeHeaders(_, true))\n      .WillOnce(Invoke([&](const Http::RequestHeaderMap& headers, bool) -> Http::Status {\n        EXPECT_EQ(headers.getHostValue(), host);\n        EXPECT_EQ(headers.getPathValue(), path);\n        return Http::okStatus();\n      }));\n  health_checker_->start();\n\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.max_interval\", _));\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.min_interval\", _))\n      .WillOnce(Return(45000));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_,\n              enableTimer(std::chrono::milliseconds(45000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  absl::optional<std::string> health_checked_cluster(\"locations-production-iad\");\n  respond(0, \"200\", false, false, true, false, health_checked_cluster);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n}\n\nTEST_F(HttpHealthCheckerImplTest, SuccessServiceCheckWithAdditionalHeaders) {\n  const Http::LowerCaseString header_ok(\"x-envoy-ok\");\n  const Http::LowerCaseString header_cool(\"x-envoy-cool\");\n  const Http::LowerCaseString header_awesome(\"x-envoy-awesome\");\n  const Http::LowerCaseString upstream_metadata(\"x-upstream-metadata\");\n  const Http::LowerCaseString protocol(\"x-protocol\");\n  const Http::LowerCaseString downstream_remote_address(\"x-downstream-remote-address\");\n  const Http::LowerCaseString downstream_remote_address_without_port(\n      \"x-downstream-remote-address-without-port\");\n  const Http::LowerCaseString downstream_local_address(\"x-downstream-local-address\");\n  const Http::LowerCaseString downstream_local_address_without_port(\n      \"x-downstream-local-address-without-port\");\n  const Http::LowerCaseString start_time(\"x-start-time\");\n\n  const std::string value_ok = \"ok\";\n  const std::string value_cool = \"cool\";\n  const std::string value_awesome = \"awesome\";\n\n  const std::string value_user_agent = \"CoolEnvoy/HC\";\n  const std::string value_upstream_metadata = \"value\";\n  const std::string value_protocol = \"HTTP/1.1\";\n  const std::string value_downstream_remote_address = \"127.0.0.1:0\";\n  const std::string value_downstream_remote_address_without_port = \"127.0.0.1\";\n  const std::string value_downstream_local_address = \"127.0.0.1:0\";\n  const std::string value_downstream_local_address_without_port = \"127.0.0.1\";\n\n  setupServiceValidationWithAdditionalHeaders();\n  // Requires non-empty `service_name` in config.\n  EXPECT_CALL(runtime_.snapshot_, featureEnabled(\"health_check.verify_cluster\", 100))\n      .WillOnce(Return(true));\n\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n  auto metadata = TestUtility::parseYaml<envoy::config::core::v3::Metadata>(\n      R\"EOF(\n        filter_metadata:\n          namespace:\n            key: value\n      )EOF\");\n\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", metadata, simTime())};\n  cluster_->info_->stats().upstream_cx_total_.inc();\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  EXPECT_CALL(test_sessions_[0]->request_encoder_, encodeHeaders(_, true))\n      .WillRepeatedly(Invoke([&](const Http::RequestHeaderMap& headers, bool) -> Http::Status {\n        EXPECT_EQ(headers.get(header_ok)[0]->value().getStringView(), value_ok);\n        EXPECT_EQ(headers.get(header_cool)[0]->value().getStringView(), value_cool);\n        EXPECT_EQ(headers.get(header_awesome)[0]->value().getStringView(), value_awesome);\n\n        EXPECT_EQ(headers.getUserAgentValue(), value_user_agent);\n        EXPECT_EQ(headers.get(upstream_metadata)[0]->value().getStringView(),\n                  value_upstream_metadata);\n\n        EXPECT_EQ(headers.get(protocol)[0]->value().getStringView(), value_protocol);\n        EXPECT_EQ(headers.get(downstream_remote_address)[0]->value().getStringView(),\n                  value_downstream_remote_address);\n        EXPECT_EQ(headers.get(downstream_remote_address_without_port)[0]->value().getStringView(),\n                  value_downstream_remote_address_without_port);\n        EXPECT_EQ(headers.get(downstream_local_address)[0]->value().getStringView(),\n                  value_downstream_local_address);\n        EXPECT_EQ(headers.get(downstream_local_address_without_port)[0]->value().getStringView(),\n                  value_downstream_local_address_without_port);\n\n        Envoy::DateFormatter date_formatter(\"%s.%9f\");\n        std::string current_start_time =\n            date_formatter.fromTime(dispatcher_.timeSource().systemTime());\n        EXPECT_EQ(headers.get(start_time)[0]->value().getStringView(), current_start_time);\n        return Http::okStatus();\n      }));\n  health_checker_->start();\n\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.max_interval\", _));\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.min_interval\", _))\n      .WillOnce(Return(45000));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_,\n              enableTimer(std::chrono::milliseconds(45000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  absl::optional<std::string> health_checked_cluster(\"locations-production-iad\");\n  respond(0, \"200\", false, false, true, false, health_checked_cluster);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  expectStreamCreate(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n}\n\nTEST_F(HttpHealthCheckerImplTest, SuccessServiceCheckWithoutUserAgent) {\n  setupServiceValidationWithoutUserAgent();\n  // Requires non-empty `service_name` in config.\n  EXPECT_CALL(runtime_.snapshot_, featureEnabled(\"health_check.verify_cluster\", 100))\n      .WillOnce(Return(true));\n\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n  auto metadata = TestUtility::parseYaml<envoy::config::core::v3::Metadata>(\n      R\"EOF(\n        filter_metadata:\n          namespace:\n            key: value\n      )EOF\");\n\n  std::string current_start_time;\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", metadata, simTime())};\n  cluster_->info_->stats().upstream_cx_total_.inc();\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  EXPECT_CALL(test_sessions_[0]->request_encoder_, encodeHeaders(_, true))\n      .WillRepeatedly(Invoke([&](const Http::RequestHeaderMap& headers, bool) -> Http::Status {\n        EXPECT_EQ(headers.UserAgent(), nullptr);\n        return Http::okStatus();\n      }));\n  health_checker_->start();\n\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.max_interval\", _));\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.min_interval\", _))\n      .WillOnce(Return(45000));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_,\n              enableTimer(std::chrono::milliseconds(45000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  absl::optional<std::string> health_checked_cluster(\"locations-production-iad\");\n  respond(0, \"200\", false, false, true, false, health_checked_cluster);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  expectStreamCreate(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n}\n\nTEST_F(HttpHealthCheckerImplTest, ServiceDoesNotMatchFail) {\n  setupServiceValidationHC();\n  EXPECT_CALL(event_logger_, logUnhealthy(_, _, _, true));\n  EXPECT_CALL(runtime_.snapshot_, featureEnabled(\"health_check.verify_cluster\", 100))\n      .WillOnce(Return(true));\n\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Changed));\n  EXPECT_CALL(event_logger_, logEjectUnhealthy(_, _, _));\n\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  cluster_->info_->stats().upstream_cx_total_.inc();\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.max_interval\", _));\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.min_interval\", _))\n      .WillOnce(Return(45000));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_,\n              enableTimer(std::chrono::milliseconds(45000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  absl::optional<std::string> health_checked_cluster(\"api-production-iad\");\n  respond(0, \"200\", false, false, true, false, health_checked_cluster);\n  EXPECT_TRUE(cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthFlagGet(\n      Host::HealthFlag::FAILED_ACTIVE_HC));\n  EXPECT_EQ(Host::Health::Unhealthy,\n            cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n}\n\nTEST_F(HttpHealthCheckerImplTest, ServicePatternDoesNotMatchFail) {\n  setupServiceRegexPatternValidationHC();\n  EXPECT_CALL(event_logger_, logUnhealthy(_, _, _, true));\n  EXPECT_CALL(runtime_.snapshot_, featureEnabled(\"health_check.verify_cluster\", 100))\n      .WillOnce(Return(true));\n\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Changed));\n  EXPECT_CALL(event_logger_, logEjectUnhealthy(_, _, _));\n\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  cluster_->info_->stats().upstream_cx_total_.inc();\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.max_interval\", _));\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.min_interval\", _))\n      .WillOnce(Return(45000));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_,\n              enableTimer(std::chrono::milliseconds(45000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  absl::optional<std::string> health_checked_cluster(\"api-production-iad\");\n  respond(0, \"200\", false, false, true, false, health_checked_cluster);\n  EXPECT_TRUE(cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthFlagGet(\n      Host::HealthFlag::FAILED_ACTIVE_HC));\n  EXPECT_EQ(Host::Health::Unhealthy,\n            cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n}\n\nTEST_F(HttpHealthCheckerImplTest, ServiceNotPresentInResponseFail) {\n  setupServiceValidationHC();\n  EXPECT_CALL(event_logger_, logUnhealthy(_, _, _, true));\n  EXPECT_CALL(runtime_.snapshot_, featureEnabled(\"health_check.verify_cluster\", 100))\n      .WillOnce(Return(true));\n\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Changed));\n  EXPECT_CALL(event_logger_, logEjectUnhealthy(_, _, _));\n\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  cluster_->info_->stats().upstream_cx_total_.inc();\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.max_interval\", _));\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.min_interval\", _))\n      .WillOnce(Return(45000));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_,\n              enableTimer(std::chrono::milliseconds(45000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  respond(0, \"200\", false, false, true, false);\n  EXPECT_TRUE(cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthFlagGet(\n      Host::HealthFlag::FAILED_ACTIVE_HC));\n  EXPECT_EQ(Host::Health::Unhealthy,\n            cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n}\n\nTEST_F(HttpHealthCheckerImplTest, ServiceCheckRuntimeOff) {\n  setupServiceValidationHC();\n  EXPECT_CALL(runtime_.snapshot_, featureEnabled(\"health_check.verify_cluster\", 100))\n      .WillOnce(Return(false));\n\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  cluster_->info_->stats().upstream_cx_total_.inc();\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.max_interval\", _));\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.min_interval\", _))\n      .WillOnce(Return(45000));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_,\n              enableTimer(std::chrono::milliseconds(45000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  absl::optional<std::string> health_checked_cluster(\"api-production-iad\");\n  respond(0, \"200\", false, false, true, false, health_checked_cluster);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n}\n\nTEST_F(HttpHealthCheckerImplTest, ServiceCheckRuntimeOffWithStringPattern) {\n  setupServicePrefixPatternValidationHC();\n  EXPECT_CALL(runtime_.snapshot_, featureEnabled(\"health_check.verify_cluster\", 100))\n      .WillOnce(Return(false));\n\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  cluster_->info_->stats().upstream_cx_total_.inc();\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.max_interval\", _));\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.min_interval\", _))\n      .WillOnce(Return(45000));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_,\n              enableTimer(std::chrono::milliseconds(45000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  absl::optional<std::string> health_checked_cluster(\"api-production-iad\");\n  respond(0, \"200\", false, false, true, false, health_checked_cluster);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n}\n\nTEST_F(HttpHealthCheckerImplTest, SuccessStartFailedFailFirstServiceCheck) {\n  setupNoServiceValidationHC();\n  EXPECT_CALL(runtime_.snapshot_, featureEnabled(\"health_check.verify_cluster\", 100))\n      .WillRepeatedly(Return(true));\n  absl::optional<std::string> health_checked_cluster(\"locations-production-iad\");\n  expectSuccessStartFailedFailFirst(health_checked_cluster);\n}\n\nTEST_F(HttpHealthCheckerImplTest, SuccessNoTraffic) {\n  setupNoServiceValidationHC();\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(std::chrono::milliseconds(5000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  respond(0, \"200\", false, false, true, true);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n}\n\n// First start with an unhealthy cluster that moves to\n// no_traffic_healthy_interval.\nTEST_F(HttpHealthCheckerImplTest, UnhealthyTransitionNoTrafficHealthy) {\n  setupNoTrafficHealthyValidationHC();\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthFlagSet(\n      Host::HealthFlag::FAILED_ACTIVE_HC);\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n\n  // Successful health check should now trigger the no_traffic_healthy_interval 10000ms.\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Changed));\n  EXPECT_CALL(event_logger_, logAddHealthy(_, _, _));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_,\n              enableTimer(std::chrono::milliseconds(10000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  respond(0, \"200\", false, false, false, false);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n}\n\nTEST_F(HttpHealthCheckerImplTest, SuccessStartFailedSuccessFirst) {\n  setupNoServiceValidationHC();\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthFlagSet(\n      Host::HealthFlag::FAILED_ACTIVE_HC);\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n\n  // Test fast success immediately moves us to healthy.\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Changed));\n  EXPECT_CALL(event_logger_, logAddHealthy(_, _, true));\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.max_interval\", _)).WillOnce(Return(500));\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.min_interval\", _));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(std::chrono::milliseconds(500), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  respond(0, \"200\", false);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n}\n\nTEST_F(HttpHealthCheckerImplTest, SuccessStartFailedFailFirst) {\n  setupNoServiceValidationHC();\n  expectSuccessStartFailedFailFirst();\n}\n\nTEST_F(HttpHealthCheckerImplTest, SuccessStartFailedFailFirstLogError) {\n  setupNoServiceValidationHCAlwaysLogFailure();\n  expectSuccessStartFailedFailFirst();\n}\n\n// Verify that removal during a failure callback works.\nTEST_F(HttpHealthCheckerImplTest, HttpFailRemoveHostInCallbackNoClose) {\n  setupNoServiceValidationHC();\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Changed))\n      .WillOnce(Invoke([&](HostSharedPtr host, HealthTransition) {\n        cluster_->prioritySet().getMockHostSet(0)->hosts_ = {};\n        cluster_->prioritySet().runUpdateCallbacks(0, {}, {host});\n      }));\n  EXPECT_CALL(event_logger_, logEjectUnhealthy(_, _, _));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(_, _)).Times(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer()).Times(0);\n  EXPECT_CALL(event_logger_, logUnhealthy(_, _, _, true));\n  respond(0, \"503\", false);\n}\n\n// Verify that removal during a failure callback works with connection close.\nTEST_F(HttpHealthCheckerImplTest, HttpFailRemoveHostInCallbackClose) {\n  setupNoServiceValidationHC();\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Changed))\n      .WillOnce(Invoke([&](HostSharedPtr host, HealthTransition) {\n        cluster_->prioritySet().getMockHostSet(0)->hosts_ = {};\n        cluster_->prioritySet().runUpdateCallbacks(0, {}, {host});\n      }));\n  EXPECT_CALL(event_logger_, logEjectUnhealthy(_, _, _));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(_, _)).Times(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer()).Times(0);\n  EXPECT_CALL(event_logger_, logUnhealthy(_, _, _, true));\n  respond(0, \"503\", true);\n}\n\nTEST_F(HttpHealthCheckerImplTest, HttpFail) {\n  setupNoServiceValidationHC();\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Changed));\n  EXPECT_CALL(event_logger_, logEjectUnhealthy(_, _, _));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(_, _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  EXPECT_CALL(event_logger_, logUnhealthy(_, _, _, true));\n  respond(0, \"503\", false);\n  EXPECT_TRUE(cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthFlagGet(\n      Host::HealthFlag::FAILED_ACTIVE_HC));\n  EXPECT_FALSE(cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthFlagGet(\n      Host::HealthFlag::EXCLUDED_VIA_IMMEDIATE_HC_FAIL));\n  EXPECT_EQ(Host::Health::Unhealthy,\n            cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  expectStreamCreate(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::ChangePending));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(_, _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  respond(0, \"200\", false);\n  EXPECT_TRUE(cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthFlagGet(\n      Host::HealthFlag::FAILED_ACTIVE_HC));\n  EXPECT_EQ(Host::Health::Unhealthy,\n            cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  expectStreamCreate(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Changed));\n  EXPECT_CALL(event_logger_, logAddHealthy(_, _, false));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(_, _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  respond(0, \"200\", false);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n}\n\nTEST_F(HttpHealthCheckerImplTest, ImmediateFailure) {\n  setupNoServiceValidationHC();\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Changed));\n  EXPECT_CALL(event_logger_, logEjectUnhealthy(_, _, _));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(_, _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  EXPECT_CALL(event_logger_, logUnhealthy(_, _, _, true));\n  respond(0, \"503\", false, false, true, false, absl::nullopt, false, true);\n  EXPECT_TRUE(cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthFlagGet(\n      Host::HealthFlag::FAILED_ACTIVE_HC));\n  EXPECT_TRUE(cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthFlagGet(\n      Host::HealthFlag::EXCLUDED_VIA_IMMEDIATE_HC_FAIL));\n  EXPECT_EQ(Host::Health::Unhealthy,\n            cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n}\n\nTEST_F(HttpHealthCheckerImplTest, HttpFailLogError) {\n  setupNoServiceValidationHCAlwaysLogFailure();\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Changed));\n  EXPECT_CALL(event_logger_, logEjectUnhealthy(_, _, _));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(_, _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  EXPECT_CALL(event_logger_, logUnhealthy(_, _, _, true));\n  respond(0, \"503\", false);\n  EXPECT_TRUE(cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthFlagGet(\n      Host::HealthFlag::FAILED_ACTIVE_HC));\n  EXPECT_EQ(Host::Health::Unhealthy,\n            cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  expectStreamCreate(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  // logUnhealthy is called with first_check == false\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(_, _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  EXPECT_CALL(event_logger_, logUnhealthy(_, _, _, false));\n  respond(0, \"503\", false);\n  EXPECT_TRUE(cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthFlagGet(\n      Host::HealthFlag::FAILED_ACTIVE_HC));\n  EXPECT_EQ(Host::Health::Unhealthy,\n            cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  expectStreamCreate(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::ChangePending));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(_, _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  respond(0, \"200\", false);\n  EXPECT_TRUE(cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthFlagGet(\n      Host::HealthFlag::FAILED_ACTIVE_HC));\n  EXPECT_EQ(Host::Health::Unhealthy,\n            cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  expectStreamCreate(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Changed));\n  EXPECT_CALL(event_logger_, logAddHealthy(_, _, false));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(_, _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  respond(0, \"200\", false);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n}\n\nTEST_F(HttpHealthCheckerImplTest, Disconnect) {\n  setupNoServiceValidationHC();\n  EXPECT_CALL(event_logger_, logUnhealthy(_, _, _, true));\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::ChangePending));\n\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(_, _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  test_sessions_[0]->client_connection_->raiseEvent(Network::ConnectionEvent::RemoteClose);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n\n  expectClientCreate(0);\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  EXPECT_CALL(*this, onHostStatus(cluster_->prioritySet().getMockHostSet(0)->hosts_[0],\n                                  HealthTransition::Changed));\n  EXPECT_CALL(event_logger_, logEjectUnhealthy(_, _, _));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(_, _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  test_sessions_[0]->client_connection_->raiseEvent(Network::ConnectionEvent::RemoteClose);\n  EXPECT_TRUE(cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthFlagGet(\n      Host::HealthFlag::FAILED_ACTIVE_HC));\n  EXPECT_EQ(Host::Health::Unhealthy,\n            cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n}\n\nTEST_F(HttpHealthCheckerImplTest, Timeout) {\n  setupNoServiceValidationHCOneUnhealthy();\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Changed));\n  EXPECT_CALL(*test_sessions_[0]->client_connection_, close(_));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(_, _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  EXPECT_CALL(event_logger_, logUnhealthy(_, _, _, true));\n  EXPECT_CALL(event_logger_, logEjectUnhealthy(_, _, _));\n  test_sessions_[0]->timeout_timer_->invokeCallback();\n  EXPECT_EQ(Host::Health::Unhealthy,\n            cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n  EXPECT_TRUE(cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthFlagGet(\n      Host::HealthFlag::ACTIVE_HC_TIMEOUT));\n}\n\n// Make sure that a timeout during a partial response works correctly.\nTEST_F(HttpHealthCheckerImplTest, TimeoutThenSuccess) {\n  setupNoServiceValidationHC();\n\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n\n  // Do a response that is not complete but includes headers.\n  std::unique_ptr<Http::TestResponseHeaderMapImpl> response_headers(\n      new Http::TestResponseHeaderMapImpl{{\":status\", \"200\"}});\n  test_sessions_[0]->stream_response_callbacks_->decodeHeaders(std::move(response_headers), false);\n\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::ChangePending));\n  EXPECT_CALL(event_logger_, logUnhealthy(_, _, _, true));\n  EXPECT_CALL(*test_sessions_[0]->client_connection_, close(_));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(_, _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  test_sessions_[0]->timeout_timer_->invokeCallback();\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n\n  expectClientCreate(0);\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(_, _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  respond(0, \"200\", false, false, true);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n}\n\nTEST_F(HttpHealthCheckerImplTest, TimeoutThenRemoteClose) {\n  setupNoServiceValidationHC();\n  EXPECT_CALL(event_logger_, logUnhealthy(_, _, _, true));\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::ChangePending));\n  EXPECT_CALL(*test_sessions_[0]->client_connection_, close(_));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(_, _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  test_sessions_[0]->timeout_timer_->invokeCallback();\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n\n  expectClientCreate(0);\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Changed));\n  EXPECT_CALL(event_logger_, logEjectUnhealthy(_, _, _));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(_, _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  test_sessions_[0]->client_connection_->raiseEvent(Network::ConnectionEvent::RemoteClose);\n  EXPECT_TRUE(cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthFlagGet(\n      Host::HealthFlag::FAILED_ACTIVE_HC));\n  EXPECT_EQ(Host::Health::Unhealthy,\n            cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n  EXPECT_FALSE(cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthFlagGet(\n      Host::HealthFlag::ACTIVE_HC_TIMEOUT));\n}\n\nTEST_F(HttpHealthCheckerImplTest, TimeoutAfterDisconnect) {\n  setupNoServiceValidationHC();\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(event_logger_, logUnhealthy(_, _, _, true));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _)).Times(2);\n  health_checker_->start();\n\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::ChangePending));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(_, _)).Times(2);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  for (auto& session : test_sessions_) {\n    session->client_connection_->close(Network::ConnectionCloseType::NoFlush);\n  }\n\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Changed));\n  EXPECT_CALL(event_logger_, logEjectUnhealthy(_, _, _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n\n  test_sessions_[0]->timeout_timer_->enableTimer(std::chrono::seconds(10), nullptr);\n  test_sessions_[0]->timeout_timer_->invokeCallback();\n  EXPECT_EQ(Host::Health::Unhealthy,\n            cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n}\n\nTEST_F(HttpHealthCheckerImplTest, DynamicAddAndRemove) {\n  setupNoServiceValidationHC();\n  health_checker_->start();\n\n  expectSessionCreate();\n  expectStreamCreate(0);\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  cluster_->prioritySet().getMockHostSet(0)->runCallbacks(\n      {cluster_->prioritySet().getMockHostSet(0)->hosts_.back()}, {});\n\n  HostVector removed{cluster_->prioritySet().getMockHostSet(0)->hosts_.back()};\n  cluster_->prioritySet().getMockHostSet(0)->hosts_.clear();\n  EXPECT_CALL(*test_sessions_[0]->client_connection_, close(_));\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n  cluster_->prioritySet().getMockHostSet(0)->runCallbacks({}, removed);\n}\n\nTEST_F(HttpHealthCheckerImplTest, ConnectionClose) {\n  setupNoServiceValidationHC();\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(_, _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  respond(0, \"200\", true);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n\n  expectClientCreate(0);\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  test_sessions_[0]->interval_timer_->invokeCallback();\n}\n\nTEST_F(HttpHealthCheckerImplTest, ProxyConnectionClose) {\n  setupNoServiceValidationHC();\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(_, _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  respond(0, \"200\", false, true);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n\n  expectClientCreate(0);\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  test_sessions_[0]->interval_timer_->invokeCallback();\n}\n\nTEST_F(HttpHealthCheckerImplTest, HealthCheckIntervals) {\n  setupHealthCheckIntervalOverridesHC();\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://128.0.0.1:80\", simTime())};\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n\n  // First check should respect no_traffic_interval setting.\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(std::chrono::milliseconds(5000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  respond(0, \"200\", false);\n  cluster_->info_->stats().upstream_cx_total_.inc();\n\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  // Needed after a response is sent.\n  expectStreamCreate(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  // Follow up successful checks should respect interval setting.\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(std::chrono::milliseconds(1000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  respond(0, \"200\", false);\n\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  // Needed after a response is sent.\n  expectStreamCreate(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  // Follow up successful checks should respect interval setting.\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(std::chrono::milliseconds(1000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  respond(0, \"200\", false);\n\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  // Needed after a response is sent.\n  expectStreamCreate(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  // A logical failure is not considered a network failure, therefore the unhealthy threshold is\n  // ignored and health state changes immediately. Since the threshold is ignored, next health\n  // check respects \"unhealthy_interval\".\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Changed));\n  EXPECT_CALL(event_logger_, logEjectUnhealthy(_, _, _));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(std::chrono::milliseconds(2000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  respond(0, \"503\", false);\n\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  // Needed after a response is sent.\n  expectStreamCreate(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  // Subsequent failing checks should respect unhealthy_interval.\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(std::chrono::milliseconds(2000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  respond(0, \"503\", false);\n\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  // Needed after a response is sent.\n  expectStreamCreate(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  // Subsequent failing checks should respect unhealthy_interval.\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(std::chrono::milliseconds(2000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  respond(0, \"503\", false);\n\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  // Needed after a response is sent.\n  expectStreamCreate(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  // When transitioning to a successful state, checks should respect healthy_edge_interval. Health\n  // state should be delayed pending healthy threshold.\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::ChangePending));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(std::chrono::milliseconds(4000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  respond(0, \"200\", false);\n\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  // Needed after a response is sent.\n  expectStreamCreate(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::ChangePending));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(std::chrono::milliseconds(4000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  respond(0, \"200\", false);\n\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  // Needed after a response is sent.\n  expectStreamCreate(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  // After the healthy threshold is reached, health state should change while checks should respect\n  // the default interval.\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Changed));\n  EXPECT_CALL(event_logger_, logAddHealthy(_, _, false));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(std::chrono::milliseconds(1000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  respond(0, \"200\", false);\n\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  // Needed after a response is sent.\n  expectStreamCreate(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  // Subsequent checks shouldn't change the state.\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(std::chrono::milliseconds(1000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  respond(0, \"200\", false);\n\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  // Needed after a response is sent.\n  expectStreamCreate(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  // First failed check after a run of successful ones should respect unhealthy_edge_interval. A\n  // timeout, being a network type failure, should respect unhealthy threshold before changing the\n  // health state.\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::ChangePending));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(std::chrono::milliseconds(3000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  test_sessions_[0]->timeout_timer_->invokeCallback();\n  EXPECT_FALSE(cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthFlagGet(\n      Host::HealthFlag::ACTIVE_HC_TIMEOUT));\n\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  // Needed after a network timeout.\n  expectClientCreate(0);\n  // Needed after a response is sent.\n  expectStreamCreate(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::ChangePending));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(std::chrono::milliseconds(3000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  test_sessions_[0]->timeout_timer_->invokeCallback();\n  EXPECT_FALSE(cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthFlagGet(\n      Host::HealthFlag::ACTIVE_HC_TIMEOUT));\n\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  // Needed after a network timeout.\n  expectClientCreate(0);\n  // Needed after a response is sent.\n  expectStreamCreate(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  // Subsequent failing checks should respect unhealthy_interval. As the unhealthy threshold is\n  // reached, health state should also change.\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Changed));\n  EXPECT_CALL(event_logger_, logEjectUnhealthy(_, _, _));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(std::chrono::milliseconds(2000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  test_sessions_[0]->timeout_timer_->invokeCallback();\n  EXPECT_TRUE(cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthFlagGet(\n      Host::HealthFlag::ACTIVE_HC_TIMEOUT));\n\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  // Needed after a network timeout.\n  expectClientCreate(0);\n  // Needed after a response is sent.\n  expectStreamCreate(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  // Remaining failing checks shouldn't change the state.\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(std::chrono::milliseconds(2000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  test_sessions_[0]->timeout_timer_->invokeCallback();\n\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  // Needed after a network timeout.\n  expectClientCreate(0);\n  // Needed after a response is sent.\n  expectStreamCreate(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  // When transitioning to a successful state, checks should respect healthy_edge_interval.\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::ChangePending));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(std::chrono::milliseconds(4000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  respond(0, \"200\", false);\n  EXPECT_TRUE(cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthFlagGet(\n      Host::HealthFlag::ACTIVE_HC_TIMEOUT));\n\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  // Needed after a response is sent.\n  expectStreamCreate(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::ChangePending));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(std::chrono::milliseconds(4000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  respond(0, \"200\", false);\n  EXPECT_TRUE(cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthFlagGet(\n      Host::HealthFlag::ACTIVE_HC_TIMEOUT));\n\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  // Needed after a response is sent.\n  expectStreamCreate(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  // After the healthy threshold is reached, health state should change while checks should respect\n  // the default interval.\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Changed));\n  EXPECT_CALL(event_logger_, logAddHealthy(_, _, false));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(std::chrono::milliseconds(1000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  respond(0, \"200\", false);\n  EXPECT_FALSE(cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthFlagGet(\n      Host::HealthFlag::ACTIVE_HC_TIMEOUT));\n\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  // Needed after a response is sent.\n  expectStreamCreate(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  // Subsequent checks shouldn't change the state.\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(std::chrono::milliseconds(1000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  respond(0, \"200\", false);\n}\n\nTEST_F(HttpHealthCheckerImplTest, RemoteCloseBetweenChecks) {\n  setupNoServiceValidationHC();\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged)).Times(2);\n\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(_, _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  respond(0, \"200\", false);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n\n  test_sessions_[0]->client_connection_->raiseEvent(Network::ConnectionEvent::RemoteClose);\n\n  expectClientCreate(0);\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(_, _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  respond(0, \"200\", false);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n}\n\n// Test that we close connections on a healthy check when reuse_connection is false.\nTEST_F(HttpHealthCheckerImplTest, DontReuseConnectionBetweenChecks) {\n  setupNoServiceValidationNoReuseConnectionHC();\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged)).Times(2);\n\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(_, _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  respond(0, \"200\", false);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n\n  // A new client is created because we close the connection ourselves.\n  // See HttpHealthCheckerImplTest.RemoteCloseBetweenChecks for how this works when the remote end\n  // closes the connection.\n  expectClientCreate(0);\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(_, _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  respond(0, \"200\", false);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n}\n\nTEST_F(HttpHealthCheckerImplTest, StreamReachesWatermarkDuringCheck) {\n  setupNoServiceValidationHC();\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(_, _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n\n  test_sessions_[0]->request_encoder_.stream_.runHighWatermarkCallbacks();\n  test_sessions_[0]->request_encoder_.stream_.runLowWatermarkCallbacks();\n\n  respond(0, \"200\", true);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n}\n\nTEST_F(HttpHealthCheckerImplTest, ConnectionReachesWatermarkDuringCheck) {\n  setupNoServiceValidationHC();\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(_, _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n\n  test_sessions_[0]->client_connection_->runHighWatermarkCallbacks();\n  test_sessions_[0]->client_connection_->runLowWatermarkCallbacks();\n\n  respond(0, \"200\", true);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n}\n\nTEST_F(HttpHealthCheckerImplTest, SuccessServiceCheckWithAltPort) {\n  const std::string host = \"fake_cluster\";\n  const std::string path = \"/healthcheck\";\n  setupServiceValidationHC();\n  EXPECT_CALL(runtime_.snapshot_, featureEnabled(\"health_check.verify_cluster\", 100))\n      .WillOnce(Return(true));\n\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n\n  // Prepares a host with its designated health check port.\n  const HostWithHealthCheckMap hosts{{\"127.0.0.1:80\", makeHealthCheckConfig(8000)}};\n  appendTestHosts(cluster_, hosts);\n  cluster_->info_->stats().upstream_cx_total_.inc();\n  expectSessionCreate(hosts);\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  EXPECT_CALL(test_sessions_[0]->request_encoder_, encodeHeaders(_, true))\n      .WillOnce(Invoke([&](const Http::RequestHeaderMap& headers, bool) -> Http::Status {\n        EXPECT_EQ(headers.getHostValue(), host);\n        EXPECT_EQ(headers.getPathValue(), path);\n        return Http::okStatus();\n      }));\n  health_checker_->start();\n\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.max_interval\", _));\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.min_interval\", _))\n      .WillOnce(Return(45000));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_,\n              enableTimer(std::chrono::milliseconds(45000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  absl::optional<std::string> health_checked_cluster(\"locations-production-iad\");\n  respond(0, \"200\", false, false, true, false, health_checked_cluster);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n}\n\n// Test host check success with multiple hosts by checking each host defined health check port.\nTEST_F(HttpHealthCheckerImplTest, SuccessWithMultipleHostsAndAltPort) {\n  setupNoServiceValidationHC();\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged)).Times(2);\n\n  // Prepares a set of hosts along with its designated health check ports.\n  const HostWithHealthCheckMap hosts = {{\"127.0.0.1:80\", makeHealthCheckConfig(8000)},\n                                        {\"127.0.0.1:81\", makeHealthCheckConfig(8001)}};\n  appendTestHosts(cluster_, hosts);\n  cluster_->info_->stats().upstream_cx_total_.inc();\n  cluster_->info_->stats().upstream_cx_total_.inc();\n  expectSessionCreate(hosts);\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  expectSessionCreate(hosts);\n  expectStreamCreate(1);\n  EXPECT_CALL(*test_sessions_[1]->timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.max_interval\", _)).Times(2);\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.min_interval\", _))\n      .Times(2)\n      .WillRepeatedly(Return(45000));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_,\n              enableTimer(std::chrono::milliseconds(45000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  EXPECT_CALL(*test_sessions_[1]->interval_timer_,\n              enableTimer(std::chrono::milliseconds(45000), _));\n  EXPECT_CALL(*test_sessions_[1]->timeout_timer_, disableTimer());\n  respond(0, \"200\", false, false, true);\n  respond(1, \"200\", false, false, true);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[1]->health());\n}\n\nTEST_F(HttpHealthCheckerImplTest, Http2ClusterUseHttp2CodecClient) {\n  setupNoServiceValidationHCWithHttp2();\n  EXPECT_EQ(Http::CodecType::HTTP2, health_checker_->codecClientType());\n}\n\nMATCHER_P(MetadataEq, expected, \"\") {\n  const envoy::config::core::v3::Metadata* metadata = arg;\n  if (!metadata) {\n    return false;\n  }\n  EXPECT_TRUE(Envoy::Protobuf::util::MessageDifferencer::Equals(*metadata, expected));\n  return true;\n}\n\nTEST_F(HttpHealthCheckerImplTest, TransportSocketMatchCriteria) {\n  const std::string host = \"fake_cluster\";\n  const std::string path = \"/healthcheck\";\n  const std::string yaml = R\"EOF(\n    timeout: 1s\n    interval: 1s\n    no_traffic_interval: 1s\n    interval_jitter_percent: 40\n    unhealthy_threshold: 2\n    healthy_threshold: 2\n    http_health_check:\n      service_name_matcher:\n        prefix: locations\n      path: /healthcheck\n    transport_socket_match_criteria:\n      key: value\n    )EOF\";\n\n  auto default_socket_factory = std::make_unique<Network::MockTransportSocketFactory>();\n  // We expect that this default_socket_factory will NOT be used to create a transport socket for\n  // the health check connection.\n  EXPECT_CALL(*default_socket_factory, createTransportSocket(_)).Times(0);\n  EXPECT_CALL(*default_socket_factory, implementsSecureTransport()).WillRepeatedly(Return(true));\n  auto transport_socket_match =\n      std::make_unique<Upstream::MockTransportSocketMatcher>(std::move(default_socket_factory));\n\n  auto metadata = TestUtility::parseYaml<envoy::config::core::v3::Metadata>(\n      R\"EOF(\n    filter_metadata:\n      envoy.transport_socket_match:\n        key: value\n  )EOF\");\n\n  Stats::IsolatedStoreImpl stats_store;\n  auto health_transport_socket_stats = TransportSocketMatchStats{\n      ALL_TRANSPORT_SOCKET_MATCH_STATS(POOL_COUNTER_PREFIX(stats_store, \"test\"))};\n  auto health_check_only_socket_factory = std::make_unique<Network::MockTransportSocketFactory>();\n\n  // We expect resolve() to be called twice, once for endpoint socket matching (with no metadata in\n  // this test) and once for health check socket matching. In the latter we expect metadata that\n  // matches the above object.\n  EXPECT_CALL(*transport_socket_match, resolve(nullptr));\n  EXPECT_CALL(*transport_socket_match, resolve(MetadataEq(metadata)))\n      .WillOnce(Return(TransportSocketMatcher::MatchData(\n          *health_check_only_socket_factory, health_transport_socket_stats, \"health_check_only\")));\n  // The health_check_only_socket_factory should be used to create a transport socket for the health\n  // check connection.\n  EXPECT_CALL(*health_check_only_socket_factory, createTransportSocket(_));\n\n  cluster_->info_->transport_socket_matcher_ = std::move(transport_socket_match);\n\n  allocHealthChecker(yaml);\n\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  cluster_->info_->stats().upstream_cx_total_.inc();\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n  EXPECT_EQ(health_transport_socket_stats.total_match_count_.value(), 1);\n}\n\nTEST_F(HttpHealthCheckerImplTest, NoTransportSocketMatchCriteria) {\n  const std::string host = \"fake_cluster\";\n  const std::string path = \"/healthcheck\";\n  const std::string yaml = R\"EOF(\n    timeout: 1s\n    interval: 1s\n    no_traffic_interval: 1s\n    interval_jitter_percent: 40\n    unhealthy_threshold: 2\n    healthy_threshold: 2\n    http_health_check:\n      service_name_matcher:\n        prefix: locations\n      path: /healthcheck\n    )EOF\";\n\n  auto default_socket_factory = std::make_unique<Network::MockTransportSocketFactory>();\n  // The default_socket_factory should be used to create a transport socket for the health check\n  // connection.\n  EXPECT_CALL(*default_socket_factory, createTransportSocket(_));\n  EXPECT_CALL(*default_socket_factory, implementsSecureTransport()).WillRepeatedly(Return(true));\n  auto transport_socket_match =\n      std::make_unique<Upstream::MockTransportSocketMatcher>(std::move(default_socket_factory));\n  // We expect resolve() to be called exactly once for endpoint socket matching. We should not\n  // attempt to match again for health checks since there is not match criteria in the config.\n  EXPECT_CALL(*transport_socket_match, resolve(nullptr));\n\n  cluster_->info_->transport_socket_matcher_ = std::move(transport_socket_match);\n\n  allocHealthChecker(yaml);\n\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  cluster_->info_->stats().upstream_cx_total_.inc();\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n}\n\n// Test receiving GOAWAY (error) is interpreted as connection close event.\nTEST_F(HttpHealthCheckerImplTest, GoAwayErrorProbeInProgress) {\n  // FailureType::Network will be issued, it will render host unhealthy only if unhealthy_threshold\n  // is reached.\n  setupNoServiceValidationHCWithHttp2();\n  EXPECT_CALL(runtime_.snapshot_, featureEnabled(\"health_check.verify_cluster\", 100))\n      .WillRepeatedly(Return(false));\n\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  cluster_->info_->stats().upstream_cx_total_.inc();\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n\n  // We start off as healthy, and should continue to be healthy.\n  expectUnchanged(0);\n  respond(0, \"200\", false, false, true, false, {}, false);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  expectStreamCreate(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  // GOAWAY with non-NO_ERROR code will result in a healthcheck failure and the\n  // connection closing. Status is unchanged because unhealthy_threshold is 2.\n  expectChangePending(0);\n\n  test_sessions_[0]->codec_client_->raiseGoAway(Http::GoAwayErrorCode::Other);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  expectClientCreate(0);\n  expectStreamCreate(0);\n\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  // GOAWAY with non-NO_ERROR code will result in a healthcheck failure and the\n  // connection closing. This time it goes unhealthy.\n  expectUnhealthyTransition(0, false);\n\n  test_sessions_[0]->codec_client_->raiseGoAway(Http::GoAwayErrorCode::Other);\n  EXPECT_EQ(Host::Health::Unhealthy,\n            cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n  EXPECT_TRUE(cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthFlagGet(\n      Host::HealthFlag::FAILED_ACTIVE_HC));\n}\n\n// Test receiving GOAWAY (no error) is handled gracefully while a check is in progress.\nTEST_F(HttpHealthCheckerImplTest, GoAwayProbeInProgress) {\n  setupHCHttp2();\n  EXPECT_CALL(runtime_.snapshot_, featureEnabled(\"health_check.verify_cluster\", 100))\n      .WillRepeatedly(Return(false));\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  cluster_->info_->stats().upstream_cx_total_.inc();\n\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n\n  // GOAWAY with NO_ERROR code during check should be handled gracefully.\n  test_sessions_[0]->codec_client_->raiseGoAway(Http::GoAwayErrorCode::NoError);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n\n  expectUnchanged(0);\n  respond(0, \"200\", false, false, true, false, {}, false);\n\n  // GOAWAY should cause a new connection to be created.\n  expectClientCreate(0);\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  // Test host state hasn't changed.\n  expectUnchanged(0);\n  respond(0, \"200\", false, false, true, false, {}, false);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n}\n\n// Test receiving GOAWAY (no error) closes connection after an in progress probe times outs.\nTEST_F(HttpHealthCheckerImplTest, GoAwayProbeInProgressTimeout) {\n  setupHCHttp2();\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  EXPECT_CALL(runtime_.snapshot_, featureEnabled(\"health_check.verify_cluster\", 100))\n      .WillRepeatedly(Return(false));\n\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n\n  test_sessions_[0]->codec_client_->raiseGoAway(Http::GoAwayErrorCode::NoError);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n\n  // Unhealthy threshold is 1 so first timeout causes unhealthy\n  expectUnhealthyTransition(0, true);\n  test_sessions_[0]->timeout_timer_->invokeCallback();\n  EXPECT_EQ(Host::Health::Unhealthy,\n            cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n\n  // GOAWAY should cause a new connection to be created.\n  expectClientCreate(0);\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  // Host should go back to healthy after a successful check.\n  expectHealthyTransition(0);\n  respond(0, \"200\", false, false, true, false, {}, false);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n}\n\n// Test receiving GOAWAY (no error) closes connection after a stream reset.\nTEST_F(HttpHealthCheckerImplTest, GoAwayProbeInProgressStreamReset) {\n  setupHCHttp2();\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  EXPECT_CALL(runtime_.snapshot_, featureEnabled(\"health_check.verify_cluster\", 100))\n      .WillRepeatedly(Return(false));\n\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n\n  test_sessions_[0]->codec_client_->raiseGoAway(Http::GoAwayErrorCode::NoError);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n\n  // Unhealthy threshold is 1 so first timeout causes unhealthy\n  expectUnhealthyTransition(0, true);\n  test_sessions_[0]->request_encoder_.stream_.resetStream(Http::StreamResetReason::RemoteReset);\n  EXPECT_EQ(Host::Health::Unhealthy,\n            cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n\n  // GOAWAY should cause a new connection to be created.\n  expectClientCreate(0);\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  // Host should go back to healthy after a successful check.\n  expectHealthyTransition(0);\n  respond(0, \"200\", false, false, true, false, {}, false);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n}\n\n// Test receiving GOAWAY (no error) and a connection close.\nTEST_F(HttpHealthCheckerImplTest, GoAwayProbeInProgressConnectionClose) {\n  setupHCHttp2();\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  EXPECT_CALL(runtime_.snapshot_, featureEnabled(\"health_check.verify_cluster\", 100))\n      .WillRepeatedly(Return(false));\n\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n\n  test_sessions_[0]->codec_client_->raiseGoAway(Http::GoAwayErrorCode::NoError);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n\n  // Unhealthy threshold is 1 so first timeout causes unhealthy\n  expectUnhealthyTransition(0, true);\n  test_sessions_[0]->client_connection_->raiseEvent(Network::ConnectionEvent::RemoteClose);\n  EXPECT_EQ(Host::Health::Unhealthy,\n            cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n\n  // GOAWAY should cause a new connection to be created.\n  expectClientCreate(0);\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  // Host should go back to healthy after a successful check.\n  expectHealthyTransition(0);\n  respond(0, \"200\", false, false, true, false, {}, false);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n}\n\n// Test receiving GOAWAY between checks affects nothing.\nTEST_F(HttpHealthCheckerImplTest, GoAwayBetweenChecks) {\n  setupHCHttp2();\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  EXPECT_CALL(runtime_.snapshot_, featureEnabled(\"health_check.verify_cluster\", 100))\n      .WillRepeatedly(Return(false));\n\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n\n  expectUnchanged(0);\n  respond(0, \"200\", false, false, true, false, {}, false);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n\n  // GOAWAY should cause a new connection to be created but should not affect health status.\n  test_sessions_[0]->codec_client_->raiseGoAway(Http::GoAwayErrorCode::Other);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n\n  expectClientCreate(0);\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  // Host should stay healthy.\n  expectUnchanged(0);\n  respond(0, \"200\", false, false, true, false, {}, false);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n}\n\nclass TestProdHttpHealthChecker : public ProdHttpHealthCheckerImpl {\npublic:\n  using ProdHttpHealthCheckerImpl::ProdHttpHealthCheckerImpl;\n\n  std::unique_ptr<Http::CodecClient>\n  createCodecClientForTest(std::unique_ptr<Network::ClientConnection>&& connection) {\n    Upstream::Host::CreateConnectionData data;\n    data.connection_ = std::move(connection);\n    data.host_description_ = std::make_shared<NiceMock<Upstream::MockHostDescription>>();\n    return std::unique_ptr<Http::CodecClient>(createCodecClient(data));\n  }\n};\n\nclass ProdHttpHealthCheckerTest : public testing::Test, public HealthCheckerTestBase {\npublic:\n  void allocHealthChecker(const std::string& yaml) {\n    health_checker_ = std::make_shared<TestProdHttpHealthChecker>(\n        *cluster_, parseHealthCheckFromV3Yaml(yaml), dispatcher_, runtime_, random_,\n        HealthCheckEventLoggerPtr(event_logger_storage_.release()));\n  }\n\n  void addCompletionCallback() {\n    health_checker_->addHostCheckCompleteCb(\n        [this](HostSharedPtr host, HealthTransition changed_state) -> void {\n          onHostStatus(host, changed_state);\n        });\n  }\n\n  void setupNoServiceValidationHCWithHttp2() {\n    const std::string yaml = R\"EOF(\n    timeout: 1s\n    interval: 1s\n    no_traffic_interval: 5s\n    interval_jitter: 1s\n    unhealthy_threshold: 2\n    healthy_threshold: 2\n    http_health_check:\n      service_name_matcher:\n        prefix: locations\n      path: /healthcheck\n      codec_client_type: Http2\n    )EOF\";\n\n    allocHealthChecker(yaml);\n    addCompletionCallback();\n  }\n\n  void setupNoServiceValidationHC() {\n    const std::string yaml = R\"EOF(\n    timeout: 1s\n    interval: 1s\n    no_traffic_interval: 5s\n    interval_jitter: 1s\n    unhealthy_threshold: 2\n    healthy_threshold: 2\n    http_health_check:\n      service_name_matcher:\n        prefix: locations\n      path: /healthcheck\n    )EOF\";\n\n    allocHealthChecker(yaml);\n    addCompletionCallback();\n  }\n\n  MOCK_METHOD(void, onHostStatus, (HostSharedPtr host, HealthTransition changed_state));\n  std::unique_ptr<Network::MockClientConnection> connection_ =\n      std::make_unique<NiceMock<Network::MockClientConnection>>();\n  std::shared_ptr<TestProdHttpHealthChecker> health_checker_;\n};\n\nTEST_F(ProdHttpHealthCheckerTest, ProdHttpHealthCheckerH1HealthChecking) {\n  setupNoServiceValidationHC();\n  EXPECT_EQ(Http::CodecType::HTTP1,\n            health_checker_->createCodecClientForTest(std::move(connection_))->type());\n}\n\nTEST_F(HttpHealthCheckerImplTest, Http1CodecClient) {\n  const std::string yaml = R\"EOF(\n    timeout: 1s\n    interval: 1s\n    no_traffic_interval: 5s\n    interval_jitter: 1s\n    unhealthy_threshold: 2\n    healthy_threshold: 2\n    http_health_check:\n      service_name_matcher:\n        prefix: locations\n      path: /healthcheck\n      codec_client_type: Http1\n    )EOF\";\n\n  allocHealthChecker(yaml);\n  addCompletionCallback();\n  EXPECT_EQ(Http::CodecType::HTTP1, health_checker_->codecClientType());\n}\n\nTEST_F(HttpHealthCheckerImplTest, Http2CodecClient) {\n  const std::string yaml = R\"EOF(\n    timeout: 1s\n    interval: 1s\n    no_traffic_interval: 5s\n    interval_jitter: 1s\n    unhealthy_threshold: 2\n    healthy_threshold: 2\n    http_health_check:\n      service_name_matcher:\n        prefix: locations\n      path: /healthcheck\n      codec_client_type: Http2\n    )EOF\";\n\n  allocHealthChecker(yaml);\n  addCompletionCallback();\n  EXPECT_EQ(Http::CodecType::HTTP2, health_checker_->codecClientType());\n}\n\nTEST_F(HttpHealthCheckerImplTest, ServiceNameMatch) {\n  const std::string host = \"fake_cluster\";\n  const std::string path = \"/healthcheck\";\n  setupServiceNameValidationHC(\"locations\");\n  EXPECT_CALL(runtime_.snapshot_, featureEnabled(\"health_check.verify_cluster\", 100))\n      .WillOnce(Return(true));\n\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  cluster_->info_->stats().upstream_cx_total_.inc();\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  EXPECT_CALL(test_sessions_[0]->request_encoder_, encodeHeaders(_, true))\n      .WillOnce(Invoke([&](const Http::RequestHeaderMap& headers, bool) -> Http::Status {\n        EXPECT_EQ(headers.getHostValue(), host);\n        EXPECT_EQ(headers.getPathValue(), path);\n        EXPECT_EQ(headers.getSchemeValue(), Http::Headers::get().SchemeValues.Http);\n        return Http::okStatus();\n      }));\n  health_checker_->start();\n\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.max_interval\", _));\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.min_interval\", _))\n      .WillOnce(Return(45000));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_,\n              enableTimer(std::chrono::milliseconds(45000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  absl::optional<std::string> health_checked_cluster(\"locations-production-iad\");\n  respond(0, \"200\", false, false, true, false, health_checked_cluster);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n}\n\nTEST_F(HttpHealthCheckerImplTest, ServiceNameMismatch) {\n  setupServiceNameValidationHC(\"locations\");\n  EXPECT_CALL(event_logger_, logUnhealthy(_, _, _, true));\n  EXPECT_CALL(runtime_.snapshot_, featureEnabled(\"health_check.verify_cluster\", 100))\n      .WillOnce(Return(true));\n\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Changed));\n  EXPECT_CALL(event_logger_, logEjectUnhealthy(_, _, _));\n\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  cluster_->info_->stats().upstream_cx_total_.inc();\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.max_interval\", _));\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.min_interval\", _))\n      .WillOnce(Return(45000));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_,\n              enableTimer(std::chrono::milliseconds(45000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  absl::optional<std::string> health_checked_cluster(\"api-production-iad\");\n  respond(0, \"200\", false, false, true, false, health_checked_cluster);\n  EXPECT_TRUE(cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthFlagGet(\n      Host::HealthFlag::FAILED_ACTIVE_HC));\n  EXPECT_EQ(Host::Health::Unhealthy,\n            cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n}\n\nTEST_F(ProdHttpHealthCheckerTest, ProdHttpHealthCheckerH2HealthChecking) {\n  setupNoServiceValidationHCWithHttp2();\n  EXPECT_EQ(Http::CodecType::HTTP2,\n            health_checker_->createCodecClientForTest(std::move(connection_))->type());\n}\n\nTEST(HttpStatusChecker, Default) {\n  const std::string yaml = R\"EOF(\n  timeout: 1s\n  interval: 1s\n  unhealthy_threshold: 2\n  healthy_threshold: 2\n  http_health_check:\n    service_name_matcher:\n        prefix: locations\n    path: /healthcheck\n  )EOF\";\n\n  auto conf = parseHealthCheckFromV3Yaml(yaml);\n  HttpHealthCheckerImpl::HttpStatusChecker http_status_checker(\n      conf.http_health_check().expected_statuses(), conf.http_health_check().retriable_statuses(),\n      200);\n\n  EXPECT_TRUE(http_status_checker.inExpectedRanges(200));\n  EXPECT_FALSE(http_status_checker.inExpectedRanges(204));\n  EXPECT_FALSE(http_status_checker.inRetriableRanges(200));\n}\n\nTEST(HttpStatusChecker, SingleExpected100) {\n  const std::string yaml = R\"EOF(\n  timeout: 1s\n  interval: 1s\n  unhealthy_threshold: 2\n  healthy_threshold: 2\n  http_health_check:\n    service_name_matcher:\n        prefix: locations\n    path: /healthcheck\n    expected_statuses:\n      - start: 100\n        end: 101\n  )EOF\";\n\n  auto conf = parseHealthCheckFromV3Yaml(yaml);\n  HttpHealthCheckerImpl::HttpStatusChecker http_status_checker(\n      conf.http_health_check().expected_statuses(), conf.http_health_check().retriable_statuses(),\n      200);\n\n  EXPECT_FALSE(http_status_checker.inExpectedRanges(200));\n\n  EXPECT_FALSE(http_status_checker.inExpectedRanges(99));\n  EXPECT_TRUE(http_status_checker.inExpectedRanges(100));\n  EXPECT_FALSE(http_status_checker.inExpectedRanges(101));\n}\n\nTEST(HttpStatusChecker, SingleRetriable100) {\n  const std::string yaml = R\"EOF(\n  timeout: 1s\n  interval: 1s\n  unhealthy_threshold: 2\n  healthy_threshold: 2\n  http_health_check:\n    service_name_matcher:\n        prefix: locations\n    path: /healthcheck\n    retriable_statuses:\n      - start: 100\n        end: 101\n  )EOF\";\n\n  auto conf = parseHealthCheckFromV3Yaml(yaml);\n  HttpHealthCheckerImpl::HttpStatusChecker http_status_checker(\n      conf.http_health_check().expected_statuses(), conf.http_health_check().retriable_statuses(),\n      200);\n\n  EXPECT_FALSE(http_status_checker.inRetriableRanges(99));\n  EXPECT_TRUE(http_status_checker.inRetriableRanges(100));\n  EXPECT_FALSE(http_status_checker.inRetriableRanges(101));\n}\n\nTEST(HttpStatusChecker, SingleExpected599) {\n  const std::string yaml = R\"EOF(\n  timeout: 1s\n  interval: 1s\n  unhealthy_threshold: 2\n  healthy_threshold: 2\n  http_health_check:\n    service_name_matcher:\n        prefix: locations\n    path: /healthcheck\n    expected_statuses:\n      - start: 599\n        end: 600\n  )EOF\";\n\n  auto conf = parseHealthCheckFromV3Yaml(yaml);\n  HttpHealthCheckerImpl::HttpStatusChecker http_status_checker(\n      conf.http_health_check().expected_statuses(), conf.http_health_check().retriable_statuses(),\n      200);\n\n  EXPECT_FALSE(http_status_checker.inExpectedRanges(200));\n\n  EXPECT_FALSE(http_status_checker.inExpectedRanges(598));\n  EXPECT_TRUE(http_status_checker.inExpectedRanges(599));\n  EXPECT_FALSE(http_status_checker.inExpectedRanges(600));\n}\n\nTEST(HttpStatusChecker, SingleRetriable599) {\n  const std::string yaml = R\"EOF(\n  timeout: 1s\n  interval: 1s\n  unhealthy_threshold: 2\n  healthy_threshold: 2\n  http_health_check:\n    service_name_matcher:\n        prefix: locations\n    path: /healthcheck\n    retriable_statuses:\n      - start: 599\n        end: 600\n  )EOF\";\n\n  auto conf = parseHealthCheckFromV3Yaml(yaml);\n  HttpHealthCheckerImpl::HttpStatusChecker http_status_checker(\n      conf.http_health_check().expected_statuses(), conf.http_health_check().retriable_statuses(),\n      200);\n\n  EXPECT_FALSE(http_status_checker.inRetriableRanges(598));\n  EXPECT_TRUE(http_status_checker.inRetriableRanges(599));\n  EXPECT_FALSE(http_status_checker.inRetriableRanges(600));\n}\n\nTEST(HttpStatusChecker, ExpectedRanges_204_304) {\n  const std::string yaml = R\"EOF(\n  timeout: 1s\n  interval: 1s\n  unhealthy_threshold: 2\n  healthy_threshold: 2\n  http_health_check:\n    service_name_matcher:\n        prefix: locations\n    path: /healthcheck\n    expected_statuses:\n      - start: 204\n        end: 205\n      - start: 304\n        end: 305\n  )EOF\";\n\n  auto conf = parseHealthCheckFromV3Yaml(yaml);\n  HttpHealthCheckerImpl::HttpStatusChecker http_status_checker(\n      conf.http_health_check().expected_statuses(), conf.http_health_check().retriable_statuses(),\n      200);\n\n  EXPECT_FALSE(http_status_checker.inExpectedRanges(200));\n\n  EXPECT_FALSE(http_status_checker.inExpectedRanges(203));\n  EXPECT_TRUE(http_status_checker.inExpectedRanges(204));\n  EXPECT_FALSE(http_status_checker.inExpectedRanges(205));\n  EXPECT_FALSE(http_status_checker.inExpectedRanges(303));\n  EXPECT_TRUE(http_status_checker.inExpectedRanges(304));\n  EXPECT_FALSE(http_status_checker.inExpectedRanges(305));\n}\n\nTEST(HttpStatusChecker, RetriableRanges_304_404) {\n  const std::string yaml = R\"EOF(\n  timeout: 1s\n  interval: 1s\n  unhealthy_threshold: 2\n  healthy_threshold: 2\n  http_health_check:\n    service_name_matcher:\n        prefix: locations\n    path: /healthcheck\n    retriable_statuses:\n      - start: 304\n        end: 305\n      - start: 404\n        end: 405\n  )EOF\";\n\n  auto conf = parseHealthCheckFromV3Yaml(yaml);\n  HttpHealthCheckerImpl::HttpStatusChecker http_status_checker(\n      conf.http_health_check().expected_statuses(), conf.http_health_check().retriable_statuses(),\n      200);\n\n  EXPECT_FALSE(http_status_checker.inRetriableRanges(303));\n  EXPECT_TRUE(http_status_checker.inRetriableRanges(304));\n  EXPECT_FALSE(http_status_checker.inRetriableRanges(305));\n  EXPECT_FALSE(http_status_checker.inRetriableRanges(403));\n  EXPECT_TRUE(http_status_checker.inRetriableRanges(404));\n  EXPECT_FALSE(http_status_checker.inRetriableRanges(405));\n}\n\nTEST(HttpStatusChecker, ExpectedBelow100) {\n  const std::string yaml = R\"EOF(\n  timeout: 1s\n  interval: 1s\n  unhealthy_threshold: 2\n  healthy_threshold: 2\n  http_health_check:\n    service_name_matcher:\n        prefix: locations\n    path: /healthcheck\n    expected_statuses:\n      - start: 99\n        end: 100\n  )EOF\";\n\n  auto conf = parseHealthCheckFromV3Yaml(yaml);\n  EXPECT_THROW_WITH_MESSAGE(\n      HttpHealthCheckerImpl::HttpStatusChecker http_status_checker(\n          conf.http_health_check().expected_statuses(),\n          conf.http_health_check().retriable_statuses(), 200),\n      EnvoyException,\n      \"Invalid http expected status range: expecting start >= 100, but found start=99\");\n}\n\nTEST(HttpStatusChecker, RetriableBelow100) {\n  const std::string yaml = R\"EOF(\n  timeout: 1s\n  interval: 1s\n  unhealthy_threshold: 2\n  healthy_threshold: 2\n  http_health_check:\n    service_name_matcher:\n        prefix: locations\n    path: /healthcheck\n    retriable_statuses:\n      - start: 99\n        end: 100\n  )EOF\";\n\n  auto conf = parseHealthCheckFromV3Yaml(yaml);\n  EXPECT_THROW_WITH_MESSAGE(\n      HttpHealthCheckerImpl::HttpStatusChecker http_status_checker(\n          conf.http_health_check().expected_statuses(),\n          conf.http_health_check().retriable_statuses(), 200),\n      EnvoyException,\n      \"Invalid http retriable status range: expecting start >= 100, but found start=99\");\n}\n\nTEST(HttpStatusChecker, ExpectedAbove599) {\n  const std::string yaml = R\"EOF(\n  timeout: 1s\n  interval: 1s\n  unhealthy_threshold: 2\n  healthy_threshold: 2\n  http_health_check:\n    service_name_matcher:\n        prefix: locations\n    path: /healthchecka\n    expected_statuses:\n      - start: 600\n        end: 601\n  )EOF\";\n\n  auto conf = parseHealthCheckFromV3Yaml(yaml);\n  EXPECT_THROW_WITH_MESSAGE(\n      HttpHealthCheckerImpl::HttpStatusChecker http_status_checker(\n          conf.http_health_check().expected_statuses(),\n          conf.http_health_check().retriable_statuses(), 200),\n      EnvoyException,\n      \"Invalid http expected status range: expecting end <= 600, but found end=601\");\n}\n\nTEST(HttpStatusChecker, RetriableAbove599) {\n  const std::string yaml = R\"EOF(\n  timeout: 1s\n  interval: 1s\n  unhealthy_threshold: 2\n  healthy_threshold: 2\n  http_health_check:\n    service_name_matcher:\n        prefix: locations\n    path: /healthchecka\n    retriable_statuses:\n      - start: 600\n        end: 601\n  )EOF\";\n\n  auto conf = parseHealthCheckFromV3Yaml(yaml);\n  EXPECT_THROW_WITH_MESSAGE(\n      HttpHealthCheckerImpl::HttpStatusChecker http_status_checker(\n          conf.http_health_check().expected_statuses(),\n          conf.http_health_check().retriable_statuses(), 200),\n      EnvoyException,\n      \"Invalid http retriable status range: expecting end <= 600, but found end=601\");\n}\n\nTEST(HttpStatusChecker, InvalidExpectedRange) {\n  const std::string yaml = R\"EOF(\n  timeout: 1s\n  interval: 1s\n  unhealthy_threshold: 2\n  healthy_threshold: 2\n  http_health_check:\n    service_name_matcher:\n        prefix: locations\n    path: /healthchecka\n    expected_statuses:\n      - start: 200\n        end: 200\n  )EOF\";\n\n  auto conf = parseHealthCheckFromV3Yaml(yaml);\n  EXPECT_THROW_WITH_MESSAGE(\n      HttpHealthCheckerImpl::HttpStatusChecker http_status_checker(\n          conf.http_health_check().expected_statuses(),\n          conf.http_health_check().retriable_statuses(), 200),\n      EnvoyException,\n      \"Invalid http expected status range: expecting start < end, but found start=200 and end=200\");\n}\n\nTEST(HttpStatusChecker, InvalidRetriableRange) {\n  const std::string yaml = R\"EOF(\n  timeout: 1s\n  interval: 1s\n  unhealthy_threshold: 2\n  healthy_threshold: 2\n  http_health_check:\n    service_name_matcher:\n        prefix: locations\n    path: /healthchecka\n    retriable_statuses:\n      - start: 200\n        end: 200\n  )EOF\";\n\n  auto conf = parseHealthCheckFromV3Yaml(yaml);\n  EXPECT_THROW_WITH_MESSAGE(HttpHealthCheckerImpl::HttpStatusChecker http_status_checker(\n                                conf.http_health_check().expected_statuses(),\n                                conf.http_health_check().retriable_statuses(), 200),\n                            EnvoyException,\n                            \"Invalid http retriable status range: expecting start < end, but found \"\n                            \"start=200 and end=200\");\n}\n\nTEST(TcpHealthCheckMatcher, loadJsonBytes) {\n  {\n    Protobuf::RepeatedPtrField<envoy::config::core::v3::HealthCheck::Payload> repeated_payload;\n    repeated_payload.Add()->set_text(\"39000000\");\n    repeated_payload.Add()->set_text(\"EEEEEEEE\");\n\n    TcpHealthCheckMatcher::MatchSegments segments =\n        TcpHealthCheckMatcher::loadProtoBytes(repeated_payload);\n    EXPECT_EQ(2U, segments.size());\n  }\n\n  {\n    Protobuf::RepeatedPtrField<envoy::config::core::v3::HealthCheck::Payload> repeated_payload;\n    repeated_payload.Add()->set_text(\"4\");\n\n    EXPECT_THROW(TcpHealthCheckMatcher::loadProtoBytes(repeated_payload), EnvoyException);\n  }\n\n  {\n    Protobuf::RepeatedPtrField<envoy::config::core::v3::HealthCheck::Payload> repeated_payload;\n    repeated_payload.Add()->set_text(\"gg\");\n\n    EXPECT_THROW(TcpHealthCheckMatcher::loadProtoBytes(repeated_payload), EnvoyException);\n  }\n}\n\nstatic void addUint8(Buffer::Instance& buffer, uint8_t addend) {\n  buffer.add(&addend, sizeof(addend));\n}\n\nTEST(TcpHealthCheckMatcher, match) {\n  Protobuf::RepeatedPtrField<envoy::config::core::v3::HealthCheck::Payload> repeated_payload;\n  repeated_payload.Add()->set_text(\"01\");\n  repeated_payload.Add()->set_text(\"02\");\n\n  TcpHealthCheckMatcher::MatchSegments segments =\n      TcpHealthCheckMatcher::loadProtoBytes(repeated_payload);\n\n  Buffer::OwnedImpl buffer;\n  EXPECT_FALSE(TcpHealthCheckMatcher::match(segments, buffer));\n  addUint8(buffer, 1);\n  EXPECT_FALSE(TcpHealthCheckMatcher::match(segments, buffer));\n  addUint8(buffer, 2);\n  EXPECT_TRUE(TcpHealthCheckMatcher::match(segments, buffer));\n\n  buffer.drain(2);\n  addUint8(buffer, 1);\n  addUint8(buffer, 3);\n  addUint8(buffer, 2);\n  EXPECT_TRUE(TcpHealthCheckMatcher::match(segments, buffer));\n\n  buffer.drain(3);\n  addUint8(buffer, 0);\n  addUint8(buffer, 3);\n  addUint8(buffer, 1);\n  addUint8(buffer, 2);\n  EXPECT_TRUE(TcpHealthCheckMatcher::match(segments, buffer));\n}\n\nclass TcpHealthCheckerImplTest : public testing::Test,\n                                 public HealthCheckerTestBase,\n                                 public Event::TestUsingSimulatedTime {\npublic:\n  void allocHealthChecker(const std::string& yaml) {\n    health_checker_ = std::make_shared<TcpHealthCheckerImpl>(\n        *cluster_, parseHealthCheckFromV3Yaml(yaml), dispatcher_, runtime_, random_,\n        HealthCheckEventLoggerPtr(event_logger_storage_.release()));\n  }\n\n  void setupData(unsigned int unhealthy_threshold = 2) {\n    std::ostringstream yaml;\n    yaml << R\"EOF(\n    timeout: 1s\n    interval: 1s\n    unhealthy_threshold: )EOF\"\n         << unhealthy_threshold << R\"EOF(\n    healthy_threshold: 2\n    tcp_health_check:\n      send:\n        text: \"01\"\n      receive:\n      - text: \"02\"\n    )EOF\";\n\n    allocHealthChecker(yaml.str());\n  }\n\n  void setupNoData() {\n    std::string yaml = R\"EOF(\n    timeout: 1s\n    interval: 1s\n    unhealthy_threshold: 2\n    healthy_threshold: 2\n    tcp_health_check: {}\n    )EOF\";\n\n    allocHealthChecker(yaml);\n  }\n\n  void setupDataDontReuseConnection() {\n    std::string yaml = R\"EOF(\n    timeout: 1s\n    interval: 1s\n    unhealthy_threshold: 2\n    healthy_threshold: 2\n    reuse_connection: false\n    tcp_health_check:\n      send:\n        text: \"01\"\n      receive:\n      - text: \"02\"\n    )EOF\";\n\n    allocHealthChecker(yaml);\n  }\n\n  void expectSessionCreate() {\n    interval_timer_ = new Event::MockTimer(&dispatcher_);\n    timeout_timer_ = new Event::MockTimer(&dispatcher_);\n  }\n\n  void expectClientCreate() {\n    connection_ = new NiceMock<Network::MockClientConnection>();\n    EXPECT_CALL(dispatcher_, createClientConnection_(_, _, _, _)).WillOnce(Return(connection_));\n    EXPECT_CALL(*connection_, addReadFilter(_)).WillOnce(SaveArg<0>(&read_filter_));\n  }\n\n  std::shared_ptr<TcpHealthCheckerImpl> health_checker_;\n  Network::MockClientConnection* connection_{};\n  Event::MockTimer* timeout_timer_{};\n  Event::MockTimer* interval_timer_{};\n  Network::ReadFilterSharedPtr read_filter_;\n};\n\nTEST_F(TcpHealthCheckerImplTest, Success) {\n  InSequence s;\n\n  setupData();\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  expectSessionCreate();\n  expectClientCreate();\n  EXPECT_CALL(*connection_, write(_, _));\n  EXPECT_CALL(*timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n\n  connection_->runHighWatermarkCallbacks();\n  connection_->runLowWatermarkCallbacks();\n  connection_->raiseEvent(Network::ConnectionEvent::Connected);\n\n  EXPECT_CALL(*timeout_timer_, disableTimer());\n  EXPECT_CALL(*interval_timer_, enableTimer(_, _));\n  Buffer::OwnedImpl response;\n  addUint8(response, 2);\n  read_filter_->onData(response, false);\n}\n\n// Tests that a successful healthcheck will disconnect the client when reuse_connection is false.\nTEST_F(TcpHealthCheckerImplTest, DataWithoutReusingConnection) {\n  InSequence s;\n\n  setupDataDontReuseConnection();\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  expectSessionCreate();\n  expectClientCreate();\n  EXPECT_CALL(*connection_, write(_, _));\n  EXPECT_CALL(*timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n\n  connection_->raiseEvent(Network::ConnectionEvent::Connected);\n\n  // Expected execution flow when a healthcheck is successful and reuse_connection is false.\n  EXPECT_CALL(*timeout_timer_, disableTimer());\n  EXPECT_CALL(*interval_timer_, enableTimer(_, _));\n  EXPECT_CALL(*connection_, close(Network::ConnectionCloseType::NoFlush));\n\n  Buffer::OwnedImpl response;\n  addUint8(response, 2);\n  read_filter_->onData(response, false);\n\n  // These are the expected metric results after testing.\n  EXPECT_EQ(1UL, cluster_->info_->stats_store_.counter(\"health_check.success\").value());\n  EXPECT_EQ(0UL, cluster_->info_->stats_store_.counter(\"health_check.failure\").value());\n}\n\n// Tests an unsuccessful healthcheck, where the endpoint sends wrong data\nTEST_F(TcpHealthCheckerImplTest, WrongData) {\n  InSequence s;\n\n  setupDataDontReuseConnection();\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  expectSessionCreate();\n  expectClientCreate();\n  EXPECT_CALL(*connection_, write(_, _));\n  EXPECT_CALL(*timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n\n  connection_->raiseEvent(Network::ConnectionEvent::Connected);\n\n  // Not the expected response\n  Buffer::OwnedImpl response;\n  addUint8(response, 3);\n  read_filter_->onData(response, false);\n\n  // These are the expected metric results after testing.\n  EXPECT_EQ(0UL, cluster_->info_->stats_store_.counter(\"health_check.success\").value());\n  // TODO(lilika): The TCP health checker does generic pattern matching so we can't differentiate\n  // between wrong data and not enough data. We could likely do better here and figure out cases in\n  // which a match is not possible but that is not done now.\n  EXPECT_EQ(0UL, cluster_->info_->stats_store_.counter(\"health_check.failure\").value());\n}\n\nTEST_F(TcpHealthCheckerImplTest, TimeoutThenRemoteClose) {\n  InSequence s;\n\n  setupData();\n  health_checker_->start();\n\n  expectSessionCreate();\n  expectClientCreate();\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  EXPECT_CALL(*connection_, write(_, _));\n  EXPECT_CALL(*timeout_timer_, enableTimer(_, _));\n\n  cluster_->prioritySet().getMockHostSet(0)->runCallbacks(\n      {cluster_->prioritySet().getMockHostSet(0)->hosts_.back()}, {});\n\n  connection_->raiseEvent(Network::ConnectionEvent::Connected);\n\n  Buffer::OwnedImpl response;\n  addUint8(response, 1);\n  read_filter_->onData(response, false);\n\n  EXPECT_CALL(*connection_, close(_));\n  EXPECT_CALL(event_logger_, logUnhealthy(_, _, _, true));\n  EXPECT_CALL(*timeout_timer_, disableTimer());\n  EXPECT_CALL(*interval_timer_, enableTimer(_, _));\n  timeout_timer_->invokeCallback();\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n\n  expectClientCreate();\n  EXPECT_CALL(*connection_, write(_, _));\n  EXPECT_CALL(*timeout_timer_, enableTimer(_, _));\n  interval_timer_->invokeCallback();\n\n  connection_->raiseEvent(Network::ConnectionEvent::Connected);\n\n  EXPECT_CALL(event_logger_, logEjectUnhealthy(_, _, _));\n  EXPECT_CALL(*timeout_timer_, disableTimer());\n  EXPECT_CALL(*interval_timer_, enableTimer(_, _));\n  connection_->raiseEvent(Network::ConnectionEvent::RemoteClose);\n  EXPECT_TRUE(cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthFlagGet(\n      Host::HealthFlag::FAILED_ACTIVE_HC));\n  EXPECT_EQ(Host::Health::Unhealthy,\n            cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n\n  expectClientCreate();\n  EXPECT_CALL(*connection_, write(_, _));\n  EXPECT_CALL(*timeout_timer_, enableTimer(_, _));\n  interval_timer_->invokeCallback();\n\n  connection_->raiseEvent(Network::ConnectionEvent::Connected);\n\n  HostVector removed{cluster_->prioritySet().getMockHostSet(0)->hosts_.back()};\n  cluster_->prioritySet().getMockHostSet(0)->hosts_.clear();\n  EXPECT_CALL(*connection_, close(_));\n  cluster_->prioritySet().getMockHostSet(0)->runCallbacks({}, removed);\n}\n\nTEST_F(TcpHealthCheckerImplTest, Timeout) {\n  InSequence s;\n\n  setupData(1);\n  health_checker_->start();\n\n  expectSessionCreate();\n  expectClientCreate();\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  EXPECT_CALL(*connection_, write(_, _));\n  EXPECT_CALL(*timeout_timer_, enableTimer(_, _));\n\n  cluster_->prioritySet().getMockHostSet(0)->runCallbacks(\n      {cluster_->prioritySet().getMockHostSet(0)->hosts_.back()}, {});\n\n  connection_->raiseEvent(Network::ConnectionEvent::Connected);\n\n  Buffer::OwnedImpl response;\n  addUint8(response, 1);\n  read_filter_->onData(response, false);\n\n  EXPECT_CALL(*connection_, close(_));\n  EXPECT_CALL(event_logger_, logEjectUnhealthy(_, _, _));\n  EXPECT_CALL(event_logger_, logUnhealthy(_, _, _, true));\n  EXPECT_CALL(*timeout_timer_, disableTimer());\n  EXPECT_CALL(*interval_timer_, enableTimer(_, _));\n  timeout_timer_->invokeCallback();\n  EXPECT_TRUE(cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthFlagGet(\n      Host::HealthFlag::ACTIVE_HC_TIMEOUT));\n  EXPECT_EQ(Host::Health::Unhealthy,\n            cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n}\n\nTEST_F(TcpHealthCheckerImplTest, DoubleTimeout) {\n  InSequence s;\n\n  setupData();\n  health_checker_->start();\n\n  expectSessionCreate();\n  expectClientCreate();\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  EXPECT_CALL(*connection_, write(_, _));\n  EXPECT_CALL(*timeout_timer_, enableTimer(_, _));\n\n  cluster_->prioritySet().getMockHostSet(0)->runCallbacks(\n      {cluster_->prioritySet().getMockHostSet(0)->hosts_.back()}, {});\n\n  connection_->raiseEvent(Network::ConnectionEvent::Connected);\n\n  Buffer::OwnedImpl response;\n  addUint8(response, 1);\n  read_filter_->onData(response, false);\n\n  EXPECT_CALL(*connection_, close(_));\n  EXPECT_CALL(event_logger_, logUnhealthy(_, _, _, true));\n  EXPECT_CALL(*timeout_timer_, disableTimer());\n  EXPECT_CALL(*interval_timer_, enableTimer(_, _));\n  timeout_timer_->invokeCallback();\n  EXPECT_FALSE(cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthFlagGet(\n      Host::HealthFlag::ACTIVE_HC_TIMEOUT));\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n\n  expectClientCreate();\n  EXPECT_CALL(*connection_, write(_, _));\n  EXPECT_CALL(*timeout_timer_, enableTimer(_, _));\n  interval_timer_->invokeCallback();\n\n  connection_->raiseEvent(Network::ConnectionEvent::Connected);\n\n  EXPECT_CALL(*connection_, close(_));\n  EXPECT_CALL(event_logger_, logEjectUnhealthy(_, _, _));\n  EXPECT_CALL(*timeout_timer_, disableTimer());\n  EXPECT_CALL(*interval_timer_, enableTimer(_, _));\n  timeout_timer_->invokeCallback();\n  EXPECT_TRUE(cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthFlagGet(\n      Host::HealthFlag::ACTIVE_HC_TIMEOUT));\n  EXPECT_EQ(Host::Health::Unhealthy,\n            cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n\n  expectClientCreate();\n  EXPECT_CALL(*connection_, write(_, _));\n  EXPECT_CALL(*timeout_timer_, enableTimer(_, _));\n  interval_timer_->invokeCallback();\n\n  connection_->raiseEvent(Network::ConnectionEvent::Connected);\n\n  HostVector removed{cluster_->prioritySet().getMockHostSet(0)->hosts_.back()};\n  cluster_->prioritySet().getMockHostSet(0)->hosts_.clear();\n  EXPECT_CALL(*connection_, close(_));\n  cluster_->prioritySet().getMockHostSet(0)->runCallbacks({}, removed);\n}\n\n// Tests that when reuse_connection is false timeouts execute normally.\nTEST_F(TcpHealthCheckerImplTest, TimeoutWithoutReusingConnection) {\n  InSequence s;\n\n  setupDataDontReuseConnection();\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  expectSessionCreate();\n  expectClientCreate();\n  EXPECT_CALL(*connection_, write(_, _));\n  EXPECT_CALL(*timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n\n  connection_->raiseEvent(Network::ConnectionEvent::Connected);\n\n  // Expected flow when a healthcheck is successful and reuse_connection is false.\n  EXPECT_CALL(*timeout_timer_, disableTimer());\n  EXPECT_CALL(*interval_timer_, enableTimer(_, _));\n  EXPECT_CALL(*connection_, close(Network::ConnectionCloseType::NoFlush));\n\n  Buffer::OwnedImpl response;\n  addUint8(response, 2);\n  read_filter_->onData(response, false);\n\n  EXPECT_EQ(1UL, cluster_->info_->stats_store_.counter(\"health_check.success\").value());\n  EXPECT_EQ(0UL, cluster_->info_->stats_store_.counter(\"health_check.failure\").value());\n\n  // The healthcheck will run again.\n  expectClientCreate();\n  EXPECT_CALL(*connection_, write(_, _));\n  EXPECT_CALL(*timeout_timer_, enableTimer(_, _));\n  interval_timer_->invokeCallback();\n\n  connection_->raiseEvent(Network::ConnectionEvent::Connected);\n\n  // Expected flow when a healthcheck times out.\n  EXPECT_CALL(*timeout_timer_, disableTimer());\n  EXPECT_CALL(*interval_timer_, enableTimer(_, _));\n  connection_->raiseEvent(Network::ConnectionEvent::RemoteClose);\n  // The healthcheck is not yet at the unhealthy threshold.\n  EXPECT_FALSE(cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthFlagGet(\n      Host::HealthFlag::FAILED_ACTIVE_HC));\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n\n  // The healthcheck metric results after first timeout block.\n  EXPECT_EQ(1UL, cluster_->info_->stats_store_.counter(\"health_check.success\").value());\n  EXPECT_EQ(1UL, cluster_->info_->stats_store_.counter(\"health_check.failure\").value());\n\n  // The healthcheck will run again, it should be failing after this attempt.\n  expectClientCreate();\n  EXPECT_CALL(*connection_, write(_, _));\n  EXPECT_CALL(*timeout_timer_, enableTimer(_, _));\n  interval_timer_->invokeCallback();\n\n  connection_->raiseEvent(Network::ConnectionEvent::Connected);\n\n  // Expected flow when a healthcheck times out.\n  EXPECT_CALL(event_logger_, logEjectUnhealthy(_, _, _));\n  EXPECT_CALL(*timeout_timer_, disableTimer());\n  EXPECT_CALL(*interval_timer_, enableTimer(_, _));\n  connection_->raiseEvent(Network::ConnectionEvent::RemoteClose);\n  EXPECT_TRUE(cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthFlagGet(\n      Host::HealthFlag::FAILED_ACTIVE_HC));\n  EXPECT_EQ(Host::Health::Unhealthy,\n            cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n\n  // The healthcheck metric results after the second timeout block.\n  EXPECT_EQ(1UL, cluster_->info_->stats_store_.counter(\"health_check.success\").value());\n  EXPECT_EQ(2UL, cluster_->info_->stats_store_.counter(\"health_check.failure\").value());\n}\n\nTEST_F(TcpHealthCheckerImplTest, NoData) {\n  InSequence s;\n\n  setupNoData();\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  expectSessionCreate();\n  expectClientCreate();\n  EXPECT_CALL(*connection_, write(_, _)).Times(0);\n  EXPECT_CALL(*timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n\n  EXPECT_CALL(*connection_, close(_));\n  EXPECT_CALL(*timeout_timer_, disableTimer());\n  EXPECT_CALL(*interval_timer_, enableTimer(_, _));\n  connection_->raiseEvent(Network::ConnectionEvent::Connected);\n\n  expectClientCreate();\n  EXPECT_CALL(*connection_, write(_, _)).Times(0);\n  EXPECT_CALL(*timeout_timer_, enableTimer(_, _));\n  interval_timer_->invokeCallback();\n}\n\nTEST_F(TcpHealthCheckerImplTest, PassiveFailure) {\n  InSequence s;\n\n  setupNoData();\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  expectSessionCreate();\n  expectClientCreate();\n  EXPECT_CALL(*connection_, write(_, _)).Times(0);\n  EXPECT_CALL(*timeout_timer_, enableTimer(_, _));\n  EXPECT_CALL(event_logger_, logEjectUnhealthy(_, _, _));\n  EXPECT_CALL(event_logger_, logUnhealthy(_, _, _, true));\n  health_checker_->start();\n\n  // Do multiple passive failures. This will not reset the active HC timers.\n  cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthChecker().setUnhealthy(\n      HealthCheckHostMonitor::UnhealthyType::ImmediateHealthCheckFail);\n  cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthChecker().setUnhealthy(\n      HealthCheckHostMonitor::UnhealthyType::ImmediateHealthCheckFail);\n  EXPECT_TRUE(cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthFlagGet(\n      Host::HealthFlag::FAILED_ACTIVE_HC));\n  EXPECT_TRUE(cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthFlagGet(\n      Host::HealthFlag::EXCLUDED_VIA_IMMEDIATE_HC_FAIL));\n  EXPECT_EQ(Host::Health::Unhealthy,\n            cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n\n  // A single success should not bring us back to healthy.\n  EXPECT_CALL(*connection_, close(_));\n  EXPECT_CALL(*timeout_timer_, disableTimer());\n  EXPECT_CALL(*interval_timer_, enableTimer(_, _));\n  connection_->raiseEvent(Network::ConnectionEvent::Connected);\n  EXPECT_TRUE(cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthFlagGet(\n      Host::HealthFlag::FAILED_ACTIVE_HC));\n  EXPECT_TRUE(cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthFlagGet(\n      Host::HealthFlag::EXCLUDED_VIA_IMMEDIATE_HC_FAIL));\n  EXPECT_EQ(Host::Health::Unhealthy,\n            cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n\n  // Bring back to healthy and check flag clearing.\n  expectClientCreate();\n  EXPECT_CALL(*timeout_timer_, enableTimer(_, _));\n  interval_timer_->invokeCallback();\n\n  EXPECT_CALL(*connection_, close(_));\n  EXPECT_CALL(event_logger_, logAddHealthy(_, _, false));\n  EXPECT_CALL(*timeout_timer_, disableTimer());\n  EXPECT_CALL(*interval_timer_, enableTimer(_, _));\n  connection_->raiseEvent(Network::ConnectionEvent::Connected);\n  EXPECT_FALSE(cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthFlagGet(\n      Host::HealthFlag::FAILED_ACTIVE_HC));\n  EXPECT_FALSE(cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthFlagGet(\n      Host::HealthFlag::EXCLUDED_VIA_IMMEDIATE_HC_FAIL));\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n\n  EXPECT_EQ(2UL, cluster_->info_->stats_store_.counter(\"health_check.attempt\").value());\n  EXPECT_EQ(2UL, cluster_->info_->stats_store_.counter(\"health_check.success\").value());\n  EXPECT_EQ(2UL, cluster_->info_->stats_store_.counter(\"health_check.failure\").value());\n  EXPECT_EQ(2UL, cluster_->info_->stats_store_.counter(\"health_check.passive_failure\").value());\n}\n\nTEST_F(TcpHealthCheckerImplTest, PassiveFailureCrossThreadRemoveHostRace) {\n  InSequence s;\n\n  setupNoData();\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  expectSessionCreate();\n  expectClientCreate();\n  EXPECT_CALL(*connection_, write(_, _)).Times(0);\n  EXPECT_CALL(*timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n\n  // Do a passive failure. This will not reset the active HC timers.\n  Event::PostCb post_cb;\n  EXPECT_CALL(dispatcher_, post(_)).WillOnce(SaveArg<0>(&post_cb));\n  cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthChecker().setUnhealthy(\n      HealthCheckHostMonitor::UnhealthyType::ImmediateHealthCheckFail);\n\n  // Remove before the cross thread event comes in.\n  EXPECT_CALL(*connection_, close(_));\n  HostVector old_hosts = std::move(cluster_->prioritySet().getMockHostSet(0)->hosts_);\n  cluster_->prioritySet().getMockHostSet(0)->runCallbacks({}, old_hosts);\n  post_cb();\n\n  EXPECT_EQ(1UL, cluster_->info_->stats_store_.counter(\"health_check.attempt\").value());\n  EXPECT_EQ(0UL, cluster_->info_->stats_store_.counter(\"health_check.success\").value());\n  EXPECT_EQ(0UL, cluster_->info_->stats_store_.counter(\"health_check.failure\").value());\n  EXPECT_EQ(0UL, cluster_->info_->stats_store_.counter(\"health_check.passive_failure\").value());\n}\n\nTEST_F(TcpHealthCheckerImplTest, PassiveFailureCrossThreadRemoveClusterRace) {\n  InSequence s;\n\n  setupNoData();\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  expectSessionCreate();\n  expectClientCreate();\n  EXPECT_CALL(*connection_, write(_, _)).Times(0);\n  EXPECT_CALL(*timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n\n  // Do a passive failure. This will not reset the active HC timers.\n  Event::PostCb post_cb;\n  EXPECT_CALL(dispatcher_, post(_)).WillOnce(SaveArg<0>(&post_cb));\n  cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthChecker().setUnhealthy(\n      HealthCheckHostMonitor::UnhealthyType::ImmediateHealthCheckFail);\n\n  // Remove before the cross thread event comes in.\n  EXPECT_CALL(*connection_, close(_));\n  health_checker_.reset();\n  post_cb();\n\n  EXPECT_EQ(1UL, cluster_->info_->stats_store_.counter(\"health_check.attempt\").value());\n  EXPECT_EQ(0UL, cluster_->info_->stats_store_.counter(\"health_check.success\").value());\n  EXPECT_EQ(0UL, cluster_->info_->stats_store_.counter(\"health_check.failure\").value());\n  EXPECT_EQ(0UL, cluster_->info_->stats_store_.counter(\"health_check.passive_failure\").value());\n}\n\nTEST_F(TcpHealthCheckerImplTest, ConnectionLocalFailure) {\n  InSequence s;\n\n  setupData();\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  expectSessionCreate();\n  expectClientCreate();\n  EXPECT_CALL(*connection_, write(_, _));\n  EXPECT_CALL(*timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n\n  // Expect the LocalClose to be handled as a health check failure\n  EXPECT_CALL(event_logger_, logUnhealthy(_, _, _, true));\n  EXPECT_CALL(*timeout_timer_, disableTimer());\n  EXPECT_CALL(*interval_timer_, enableTimer(_, _));\n\n  // Raise a LocalClose that is not triggered by the health monitor itself.\n  // e.g. a failure to setsockopt().\n  connection_->raiseEvent(Network::ConnectionEvent::LocalClose);\n\n  EXPECT_EQ(1UL, cluster_->info_->stats_store_.counter(\"health_check.attempt\").value());\n  EXPECT_EQ(0UL, cluster_->info_->stats_store_.counter(\"health_check.success\").value());\n  EXPECT_EQ(1UL, cluster_->info_->stats_store_.counter(\"health_check.failure\").value());\n  EXPECT_EQ(0UL, cluster_->info_->stats_store_.counter(\"health_check.passive_failure\").value());\n}\n\nclass TestGrpcHealthCheckerImpl : public GrpcHealthCheckerImpl {\npublic:\n  using GrpcHealthCheckerImpl::GrpcHealthCheckerImpl;\n\n  Http::CodecClientPtr createCodecClient(Upstream::Host::CreateConnectionData& conn_data) override {\n    auto codec_client = createCodecClient_(conn_data);\n    return Http::CodecClientPtr(codec_client);\n  };\n\n  // GrpcHealthCheckerImpl\n  MOCK_METHOD(Http::CodecClient*, createCodecClient_, (Upstream::Host::CreateConnectionData&));\n};\n\nclass GrpcHealthCheckerImplTestBase : public Event::TestUsingSimulatedTime,\n                                      public HealthCheckerTestBase {\npublic:\n  struct TestSession {\n    TestSession() = default;\n\n    Event::MockTimer* interval_timer_{};\n    Event::MockTimer* timeout_timer_{};\n    Http::MockClientConnection* codec_{};\n    Stats::IsolatedStoreImpl stats_store_;\n    Network::MockClientConnection* client_connection_{};\n    NiceMock<Http::MockRequestEncoder> request_encoder_;\n    Http::ResponseDecoder* stream_response_callbacks_{};\n    CodecClientForTest* codec_client_{};\n  };\n\n  using TestSessionPtr = std::unique_ptr<TestSession>;\n\n  struct ResponseSpec {\n    struct ChunkSpec {\n      bool valid;\n      std::vector<uint8_t> data;\n    };\n    static ChunkSpec invalidChunk() {\n      ChunkSpec spec;\n      spec.valid = false;\n      return spec;\n    }\n    static ChunkSpec invalidPayload(uint8_t flags, bool valid_message) {\n      ChunkSpec spec;\n      spec.valid = true;\n      spec.data = serializeResponse(grpc::health::v1::HealthCheckResponse::SERVING);\n      spec.data[0] = flags;\n      if (!valid_message) {\n        const size_t kGrpcHeaderSize = 5;\n        for (size_t i = kGrpcHeaderSize; i < spec.data.size(); i++) {\n          // Fill payload with some random data.\n          spec.data[i] = i % 256;\n        }\n      }\n      return spec;\n    }\n    // Null dereference from health check fuzzer\n    static ChunkSpec badData() {\n      std::string data(\"\\000\\000\\000\\000\\0000000\", 9);\n      std::vector<uint8_t> chunk(data.begin(), data.end());\n      ChunkSpec spec;\n      spec.valid = true;\n      spec.data = chunk;\n      return spec;\n    }\n    static ChunkSpec validFramesThenInvalidFrames() {\n      grpc::health::v1::HealthCheckResponse response;\n      response.set_status(grpc::health::v1::HealthCheckResponse::SERVING);\n      const auto data = Grpc::Common::serializeToGrpcFrame(response);\n      std::vector<uint8_t> buffer_vector = std::vector<uint8_t>(data->length(), 0);\n      data->copyOut(0, data->length(), &buffer_vector[0]);\n      // Invalid frame here\n      for (size_t i = 0; i < 6; i++) {\n        buffer_vector.push_back(48); // Represents ASCII Character of 0\n      }\n      ChunkSpec spec;\n      spec.valid = true;\n      spec.data = buffer_vector;\n      return spec;\n    }\n    static ChunkSpec validChunk(grpc::health::v1::HealthCheckResponse::ServingStatus status) {\n      ChunkSpec spec;\n      spec.valid = true;\n      spec.data = serializeResponse(status);\n      return spec;\n    }\n\n    static ChunkSpec servingResponse() {\n      return validChunk(grpc::health::v1::HealthCheckResponse::SERVING);\n    }\n\n    static ChunkSpec notServingResponse() {\n      return validChunk(grpc::health::v1::HealthCheckResponse::NOT_SERVING);\n    }\n\n    static std::vector<uint8_t>\n    serializeResponse(grpc::health::v1::HealthCheckResponse::ServingStatus status) {\n      grpc::health::v1::HealthCheckResponse response;\n      response.set_status(status);\n      const auto data = Grpc::Common::serializeToGrpcFrame(response);\n      auto ret = std::vector<uint8_t>(data->length(), 0);\n      data->copyOut(0, data->length(), &ret[0]);\n      return ret;\n    }\n\n    std::vector<std::pair<std::string, std::string>> response_headers;\n    std::vector<ChunkSpec> body_chunks;\n    std::vector<std::pair<std::string, std::string>> trailers;\n  };\n\n  GrpcHealthCheckerImplTestBase() {\n    EXPECT_CALL(*cluster_->info_, features())\n        .WillRepeatedly(Return(Upstream::ClusterInfo::Features::HTTP2));\n  }\n\n  void allocHealthChecker(const envoy::config::core::v3::HealthCheck& config) {\n    health_checker_ = std::make_shared<TestGrpcHealthCheckerImpl>(\n        *cluster_, config, dispatcher_, runtime_, random_,\n        HealthCheckEventLoggerPtr(event_logger_storage_.release()));\n  }\n\n  void addCompletionCallback() {\n    health_checker_->addHostCheckCompleteCb(\n        [this](HostSharedPtr host, HealthTransition changed_state) -> void {\n          onHostStatus(host, changed_state);\n        });\n  }\n\n  void setupHC() {\n    const auto config = createGrpcHealthCheckConfig();\n    allocHealthChecker(config);\n    addCompletionCallback();\n  }\n\n  void setupHCWithUnhealthyThreshold(int value) {\n    auto config = createGrpcHealthCheckConfig();\n    config.mutable_unhealthy_threshold()->set_value(value);\n    allocHealthChecker(config);\n    addCompletionCallback();\n  }\n\n  void setupServiceNameHC(const absl::optional<std::string>& authority) {\n    auto config = createGrpcHealthCheckConfig();\n    config.mutable_grpc_health_check()->set_service_name(\"service\");\n    if (authority.has_value()) {\n      config.mutable_grpc_health_check()->set_authority(authority.value());\n    }\n    allocHealthChecker(config);\n    addCompletionCallback();\n  }\n\n  void setupHCWithHeaders(const absl::flat_hash_map<std::string, std::string> headers_to_add) {\n    auto config = createGrpcHealthCheckConfig();\n    config.mutable_grpc_health_check()->set_service_name(\"service\");\n    for (const auto& pair : headers_to_add) {\n      auto header_value_option = config.mutable_grpc_health_check()->add_initial_metadata();\n      header_value_option->mutable_append()->set_value(false);\n      auto header = header_value_option->mutable_header();\n      header->set_key(pair.first);\n      header->set_value(pair.second);\n    }\n    allocHealthChecker(config);\n    addCompletionCallback();\n  }\n\n  void setupNoReuseConnectionHC() {\n    auto config = createGrpcHealthCheckConfig();\n    config.mutable_reuse_connection()->set_value(false);\n    allocHealthChecker(config);\n    addCompletionCallback();\n  }\n\n  void setupHealthCheckIntervalOverridesHC() {\n    auto config = createGrpcHealthCheckConfig();\n    config.mutable_interval()->set_seconds(1);\n    config.mutable_unhealthy_interval()->set_seconds(2);\n    config.mutable_unhealthy_edge_interval()->set_seconds(3);\n    config.mutable_healthy_edge_interval()->set_seconds(4);\n    config.mutable_no_traffic_interval()->set_seconds(5);\n    config.mutable_interval_jitter()->set_seconds(0);\n    config.mutable_unhealthy_threshold()->set_value(3);\n    config.mutable_healthy_threshold()->set_value(3);\n    allocHealthChecker(config);\n    addCompletionCallback();\n  }\n\n  void expectSessionCreate() {\n    // Expectations are in LIFO order.\n    TestSessionPtr new_test_session(new TestSession());\n    new_test_session->timeout_timer_ = new Event::MockTimer(&dispatcher_);\n    new_test_session->interval_timer_ = new Event::MockTimer(&dispatcher_);\n    test_sessions_.emplace_back(std::move(new_test_session));\n    expectClientCreate(test_sessions_.size() - 1);\n  }\n\n  void expectClientCreate(size_t index) {\n    TestSession& test_session = *test_sessions_[index];\n    test_session.codec_ = new NiceMock<Http::MockClientConnection>();\n    test_session.client_connection_ = new NiceMock<Network::MockClientConnection>();\n    connection_index_.push_back(index);\n    codec_index_.push_back(index);\n\n    EXPECT_CALL(dispatcher_, createClientConnection_(_, _, _, _))\n        .Times(testing::AnyNumber())\n        .WillRepeatedly(InvokeWithoutArgs([&]() -> Network::ClientConnection* {\n          const uint32_t index = connection_index_.front();\n          connection_index_.pop_front();\n          return test_sessions_[index]->client_connection_;\n        }));\n\n    EXPECT_CALL(*health_checker_, createCodecClient_(_))\n        .WillRepeatedly(\n            Invoke([&](Upstream::Host::CreateConnectionData& conn_data) -> Http::CodecClient* {\n              const uint32_t index = codec_index_.front();\n              codec_index_.pop_front();\n              TestSession& test_session = *test_sessions_[index];\n              std::shared_ptr<Upstream::MockClusterInfo> cluster{\n                  new NiceMock<Upstream::MockClusterInfo>()};\n              Event::MockDispatcher dispatcher_;\n\n              test_session.codec_client_ = new CodecClientForTest(\n                  Http::CodecType::HTTP1, std::move(conn_data.connection_), test_session.codec_,\n                  nullptr, Upstream::makeTestHost(cluster, \"tcp://127.0.0.1:9000\", simTime()),\n                  dispatcher_);\n              return test_session.codec_client_;\n            }));\n  }\n\n  void expectStreamCreate(size_t index) {\n    test_sessions_[index]->request_encoder_.stream_.callbacks_.clear();\n    EXPECT_CALL(*test_sessions_[index]->codec_, newStream(_))\n        .WillOnce(DoAll(SaveArgAddress(&test_sessions_[index]->stream_response_callbacks_),\n                        ReturnRef(test_sessions_[index]->request_encoder_)));\n  }\n\n  // Starts healthchecker and sets up timer expectations, leaving up future specification of\n  // healthcheck response for the caller. Useful when there is only one healthcheck attempt\n  // performed during test case (but possibly on many hosts).\n  void expectHealthchecks(HealthTransition host_changed_state, size_t num_healthchecks) {\n    for (size_t i = 0; i < num_healthchecks; i++) {\n      cluster_->info_->stats().upstream_cx_total_.inc();\n      expectSessionCreate();\n      expectHealthcheckStart(i);\n    }\n    health_checker_->start();\n\n    EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.max_interval\", _))\n        .Times(num_healthchecks);\n    EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.min_interval\", _))\n        .Times(num_healthchecks)\n        .WillRepeatedly(Return(45000));\n    for (size_t i = 0; i < num_healthchecks; i++) {\n      expectHealthcheckStop(i, 45000);\n    }\n    EXPECT_CALL(*this, onHostStatus(_, host_changed_state)).Times(num_healthchecks);\n  }\n\n  void expectSingleHealthcheck(HealthTransition host_changed_state) {\n    cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n        makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n    expectHealthchecks(host_changed_state, 1);\n  }\n\n  // Hides timer/stream-related boilerplate of healthcheck start.\n  void expectHealthcheckStart(size_t index) {\n    expectStreamCreate(index);\n    EXPECT_CALL(*test_sessions_[index]->timeout_timer_, enableTimer(_, _));\n  }\n\n  // Hides timer-related boilerplate of healthcheck stop.\n  void expectHealthcheckStop(size_t index, int interval_ms = 0) {\n    if (interval_ms > 0) {\n      EXPECT_CALL(*test_sessions_[index]->interval_timer_,\n                  enableTimer(std::chrono::milliseconds(interval_ms), _));\n    } else {\n      EXPECT_CALL(*test_sessions_[index]->interval_timer_, enableTimer(_, _));\n    }\n    EXPECT_CALL(*test_sessions_[index]->timeout_timer_, disableTimer());\n  }\n\n  // Hides host status checking boilerplate when only single host is used in test.\n  void expectHostHealthy(bool healthy) {\n    const auto host = cluster_->prioritySet().getMockHostSet(0)->hosts_[0];\n    if (!healthy) {\n      EXPECT_TRUE(host->healthFlagGet(Host::HealthFlag::FAILED_ACTIVE_HC));\n      EXPECT_EQ(Host::Health::Unhealthy, host->health());\n    } else {\n      EXPECT_EQ(Host::Health::Healthy, host->health());\n    }\n  }\n\n  void respondServiceStatus(size_t index,\n                            grpc::health::v1::HealthCheckResponse::ServingStatus status) {\n    respondResponseSpec(index,\n                        ResponseSpec{{{\":status\", \"200\"}, {\"content-type\", \"application/grpc\"}},\n                                     {ResponseSpec::validChunk(status)},\n                                     {{\"grpc-status\", \"0\"}}});\n  }\n\n  void respondResponseSpec(size_t index, ResponseSpec&& spec) {\n    const bool trailers_empty = spec.trailers.empty();\n    const bool end_stream_on_headers = spec.body_chunks.empty() && trailers_empty;\n    auto response_headers = std::make_unique<Http::TestResponseHeaderMapImpl>();\n    for (const auto& header : spec.response_headers) {\n      response_headers->addCopy(header.first, header.second);\n    }\n    test_sessions_[index]->stream_response_callbacks_->decodeHeaders(std::move(response_headers),\n                                                                     end_stream_on_headers);\n    for (size_t i = 0; i < spec.body_chunks.size(); i++) {\n      const bool end_stream = i == spec.body_chunks.size() - 1 && trailers_empty;\n      const auto& chunk = spec.body_chunks[i];\n      if (chunk.valid) {\n        const auto data = std::make_unique<Buffer::OwnedImpl>(chunk.data.data(), chunk.data.size());\n        test_sessions_[index]->stream_response_callbacks_->decodeData(*data, end_stream);\n      } else {\n        Buffer::OwnedImpl incorrect_data(\"incorrect\");\n        test_sessions_[index]->stream_response_callbacks_->decodeData(incorrect_data, end_stream);\n      }\n    }\n    if (!trailers_empty) {\n      auto trailers = std::make_unique<Http::TestResponseTrailerMapImpl>();\n      for (const auto& header : spec.trailers) {\n        trailers->addCopy(header.first, header.second);\n      }\n      test_sessions_[index]->stream_response_callbacks_->decodeTrailers(std::move(trailers));\n    }\n  }\n\n  void testSingleHostSuccess(const absl::optional<std::string>& authority) {\n    std::string expected_host = cluster_->info_->name();\n    if (authority.has_value()) {\n      expected_host = authority.value();\n    }\n\n    setupServiceNameHC(authority);\n\n    cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n        makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n    runHealthCheck(expected_host);\n  }\n\n  void runHealthCheck(std::string expected_host) {\n\n    cluster_->info_->stats().upstream_cx_total_.inc();\n\n    expectSessionCreate();\n    expectHealthcheckStart(0);\n\n    EXPECT_CALL(test_sessions_[0]->request_encoder_, encodeHeaders(_, false))\n        .WillOnce(Invoke([&](const Http::RequestHeaderMap& headers, bool) -> Http::Status {\n          EXPECT_EQ(Http::Headers::get().ContentTypeValues.Grpc, headers.getContentTypeValue());\n          EXPECT_EQ(std::string(\"/grpc.health.v1.Health/Check\"), headers.getPathValue());\n          EXPECT_EQ(Http::Headers::get().SchemeValues.Http, headers.getSchemeValue());\n          EXPECT_NE(nullptr, headers.Method());\n          EXPECT_EQ(expected_host, headers.getHostValue());\n          EXPECT_EQ(std::chrono::milliseconds(1000).count(),\n                    Envoy::Grpc::Common::getGrpcTimeout(headers).value().count());\n          return Http::okStatus();\n        }));\n    EXPECT_CALL(test_sessions_[0]->request_encoder_, encodeData(_, true))\n        .WillOnce(Invoke([&](Buffer::Instance& data, bool) {\n          std::vector<Grpc::Frame> decoded_frames;\n          Grpc::Decoder decoder;\n          ASSERT_TRUE(decoder.decode(data, decoded_frames));\n          ASSERT_EQ(1U, decoded_frames.size());\n          auto& frame = decoded_frames[0];\n          Buffer::ZeroCopyInputStreamImpl stream(std::move(frame.data_));\n          grpc::health::v1::HealthCheckRequest request;\n          ASSERT_TRUE(request.ParseFromZeroCopyStream(&stream));\n          EXPECT_EQ(\"service\", request.service());\n        }));\n    health_checker_->start();\n\n    EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.max_interval\", _));\n    EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.min_interval\", _))\n        .WillOnce(Return(45000));\n    expectHealthcheckStop(0, 45000);\n\n    // Host state should not be changed (remains healthy).\n    EXPECT_CALL(*this, onHostStatus(cluster_->prioritySet().getMockHostSet(0)->hosts_[0],\n                                    HealthTransition::Unchanged));\n    respondServiceStatus(0, grpc::health::v1::HealthCheckResponse::SERVING);\n    expectHostHealthy(true);\n  }\n\n  MOCK_METHOD(void, onHostStatus, (HostSharedPtr host, HealthTransition changed_state));\n\n  std::vector<TestSessionPtr> test_sessions_;\n  std::shared_ptr<TestGrpcHealthCheckerImpl> health_checker_;\n  std::list<uint32_t> connection_index_{};\n  std::list<uint32_t> codec_index_{};\n};\n\n// NOLINTNEXTLINE(readability-identifier-naming)\nvoid PrintTo(const GrpcHealthCheckerImplTestBase::ResponseSpec& spec, std::ostream* os) {\n  (*os) << \"(headers{\" << absl::StrJoin(spec.response_headers, \",\", absl::PairFormatter(\":\"))\n        << \"},\";\n  (*os) << \"body{\" << absl::StrJoin(spec.body_chunks, \",\", [](std::string* out, const auto& spec) {\n    absl::StrAppend(out, spec.valid ? \"valid\" : \"invalid\", \",{\",\n                    absl::StrJoin(spec.data, \"-\",\n                                  [](std::string* out, uint8_t byte) {\n                                    absl::StrAppend(out, absl::Hex(byte, absl::kZeroPad2));\n                                  }),\n                    \"}\");\n  }) << \"}\";\n  (*os) << \"trailers{\" << absl::StrJoin(spec.trailers, \",\", absl::PairFormatter(\":\")) << \"})\";\n}\n\nclass GrpcHealthCheckerImplTest : public testing::Test, public GrpcHealthCheckerImplTestBase {};\n\n// Test single host check success.\nTEST_F(GrpcHealthCheckerImplTest, Success) { testSingleHostSuccess(absl::nullopt); }\n\nTEST_F(GrpcHealthCheckerImplTest, SuccessWithHostname) {\n  std::string expected_host = \"www.envoyproxy.io\";\n\n  setupServiceNameHC(absl::nullopt);\n\n  envoy::config::endpoint::v3::Endpoint::HealthCheckConfig health_check_config;\n  health_check_config.set_hostname(expected_host);\n  auto test_host = std::make_shared<HostImpl>(\n      cluster_->info_, \"\", Network::Utility::resolveUrl(\"tcp://127.0.0.1:80\"), nullptr, 1,\n      envoy::config::core::v3::Locality(), health_check_config, 0, envoy::config::core::v3::UNKNOWN,\n      simTime());\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {test_host};\n  runHealthCheck(expected_host);\n}\n\nTEST_F(GrpcHealthCheckerImplTest, SuccessWithHostnameOverridesConfig) {\n  std::string expected_host = \"www.envoyproxy.io\";\n\n  setupServiceNameHC(\"foo.com\");\n\n  envoy::config::endpoint::v3::Endpoint::HealthCheckConfig health_check_config;\n  health_check_config.set_hostname(expected_host);\n  auto test_host = std::make_shared<HostImpl>(\n      cluster_->info_, \"\", Network::Utility::resolveUrl(\"tcp://127.0.0.1:80\"), nullptr, 1,\n      envoy::config::core::v3::Locality(), health_check_config, 0, envoy::config::core::v3::UNKNOWN,\n      simTime());\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {test_host};\n  runHealthCheck(expected_host);\n}\n\n// Test single host check success with custom authority.\nTEST_F(GrpcHealthCheckerImplTest, SuccessWithCustomAuthority) {\n  const std::string authority = \"www.envoyproxy.io\";\n  testSingleHostSuccess(authority);\n}\n\n// Test single host check success with additional headers.\nTEST_F(GrpcHealthCheckerImplTest, SuccessWithAdditionalHeaders) {\n  const std::string ENVOY_OK_KEY = \"x-envoy-ok\";\n  const std::string ENVOY_OK_VAL = \"ok\";\n  const std::string ENVOY_COOL_KEY = \"x-envoy-cool\";\n  const std::string ENVOY_COOL_VAL = \"cool\";\n  const std::string ENVOY_AWESOME_KEY = \"x-envoy-awesome\";\n  const std::string ENVOY_AWESOME_VAL = \"awesome\";\n  const std::string USER_AGENT_KEY = \"user-agent\";\n  const std::string USER_AGENT_VAL = \"CoolEnvoy/HC\";\n  const std::string PROTOCOL_KEY = \"x-protocol\";\n  const std::string PROTOCOL_VAL = \"%PROTOCOL%\";\n  const std::string DOWNSTREAM_LOCAL_ADDRESS_KEY = \"x-downstream-local-address\";\n  const std::string DOWNSTREAM_LOCAL_ADDRESS_WITHOUT_PORT_KEY =\n      \"x-downstream-local-address-without-port\";\n  const std::string DOWNSTREAM_REMOTE_ADDRESS_KEY = \"x-downstream-remote-address\";\n  const std::string DOWNSTREAM_REMOTE_ADDRESS_WITHOUT_PORT_KEY =\n      \"x-downstream-remote-address-without-port\";\n  const std::string START_TIME_KEY = \"x-start-time\";\n  const std::string UPSTREAM_METADATA_KEY = \"x-upstream-metadata\";\n\n  setupHCWithHeaders(\n      {{ENVOY_OK_KEY, ENVOY_OK_VAL},\n       {ENVOY_COOL_KEY, ENVOY_COOL_VAL},\n       {ENVOY_AWESOME_KEY, ENVOY_AWESOME_VAL},\n       {USER_AGENT_KEY, USER_AGENT_VAL},\n       {PROTOCOL_KEY, PROTOCOL_VAL},\n       {DOWNSTREAM_LOCAL_ADDRESS_KEY, \"%DOWNSTREAM_LOCAL_ADDRESS%\"},\n       {DOWNSTREAM_LOCAL_ADDRESS_WITHOUT_PORT_KEY, \"%DOWNSTREAM_LOCAL_ADDRESS_WITHOUT_PORT%\"},\n       {DOWNSTREAM_REMOTE_ADDRESS_KEY, \"%DOWNSTREAM_REMOTE_ADDRESS%\"},\n       {DOWNSTREAM_REMOTE_ADDRESS_WITHOUT_PORT_KEY, \"%DOWNSTREAM_REMOTE_ADDRESS_WITHOUT_PORT%\"},\n       {START_TIME_KEY, \"%START_TIME(%s.%9f)%\"},\n       {UPSTREAM_METADATA_KEY, \"%UPSTREAM_METADATA([\\\"namespace\\\", \\\"key\\\"])%\"}});\n\n  auto metadata = TestUtility::parseYaml<envoy::config::core::v3::Metadata>(\n      R\"EOF(\n        filter_metadata:\n          namespace:\n            key: value\n      )EOF\");\n\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", metadata, simTime())};\n\n  cluster_->info_->stats().upstream_cx_total_.inc();\n\n  expectSessionCreate();\n  expectHealthcheckStart(0);\n\n  EXPECT_CALL(test_sessions_[0]->request_encoder_, encodeHeaders(_, false))\n      .WillOnce(Invoke([&](const Http::RequestHeaderMap& headers, bool) -> Http::Status {\n        EXPECT_EQ(Http::Headers::get().ContentTypeValues.Grpc, headers.getContentTypeValue());\n        EXPECT_EQ(std::string(\"/grpc.health.v1.Health/Check\"), headers.getPathValue());\n        EXPECT_EQ(Http::Headers::get().SchemeValues.Http, headers.getSchemeValue());\n        EXPECT_NE(nullptr, headers.Method());\n        EXPECT_EQ(cluster_->info_->name(), headers.getHostValue());\n        EXPECT_EQ(ENVOY_OK_VAL,\n                  headers.get(Http::LowerCaseString(ENVOY_OK_KEY))[0]->value().getStringView());\n        EXPECT_EQ(ENVOY_COOL_VAL,\n                  headers.get(Http::LowerCaseString(ENVOY_COOL_KEY))[0]->value().getStringView());\n        EXPECT_EQ(\n            ENVOY_AWESOME_VAL,\n            headers.get(Http::LowerCaseString(ENVOY_AWESOME_KEY))[0]->value().getStringView());\n        EXPECT_EQ(USER_AGENT_VAL, headers.getUserAgentValue());\n        EXPECT_EQ(\"HTTP/2\",\n                  headers.get(Http::LowerCaseString(PROTOCOL_KEY))[0]->value().getStringView());\n        EXPECT_EQ(\"127.0.0.1:0\",\n                  headers.get(Http::LowerCaseString(DOWNSTREAM_LOCAL_ADDRESS_KEY))[0]\n                      ->value()\n                      .getStringView());\n        EXPECT_EQ(\"127.0.0.1\",\n                  headers.get(Http::LowerCaseString(DOWNSTREAM_LOCAL_ADDRESS_WITHOUT_PORT_KEY))[0]\n                      ->value()\n                      .getStringView());\n        EXPECT_EQ(\"127.0.0.1:0\",\n                  headers.get(Http::LowerCaseString(DOWNSTREAM_REMOTE_ADDRESS_KEY))[0]\n                      ->value()\n                      .getStringView());\n        EXPECT_EQ(\"127.0.0.1\",\n                  headers.get(Http::LowerCaseString(DOWNSTREAM_REMOTE_ADDRESS_WITHOUT_PORT_KEY))[0]\n                      ->value()\n                      .getStringView());\n        Envoy::DateFormatter date_formatter(\"%s.%9f\");\n        std::string current_start_time =\n            date_formatter.fromTime(dispatcher_.timeSource().systemTime());\n        EXPECT_EQ(current_start_time,\n                  headers.get(Http::LowerCaseString(START_TIME_KEY))[0]->value().getStringView());\n        EXPECT_EQ(\n            \"value\",\n            headers.get(Http::LowerCaseString(UPSTREAM_METADATA_KEY))[0]->value().getStringView());\n        EXPECT_EQ(std::chrono::milliseconds(1000).count(),\n                  Envoy::Grpc::Common::getGrpcTimeout(headers).value().count());\n        return Http::okStatus();\n      }));\n  EXPECT_CALL(test_sessions_[0]->request_encoder_, encodeData(_, true))\n      .WillOnce(Invoke([&](Buffer::Instance& data, bool) {\n        std::vector<Grpc::Frame> decoded_frames;\n        Grpc::Decoder decoder;\n        ASSERT_TRUE(decoder.decode(data, decoded_frames));\n        ASSERT_EQ(1U, decoded_frames.size());\n        auto& frame = decoded_frames[0];\n        Buffer::ZeroCopyInputStreamImpl stream(std::move(frame.data_));\n        grpc::health::v1::HealthCheckRequest request;\n        ASSERT_TRUE(request.ParseFromZeroCopyStream(&stream));\n        EXPECT_EQ(\"service\", request.service());\n      }));\n\n  health_checker_->start();\n\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.max_interval\", _));\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.min_interval\", _))\n      .WillOnce(Return(45000));\n  expectHealthcheckStop(0, 45000);\n\n  // Host state should not be changed (remains healthy).\n  EXPECT_CALL(*this, onHostStatus(cluster_->prioritySet().getMockHostSet(0)->hosts_[0],\n                                  HealthTransition::Unchanged));\n  respondServiceStatus(0, grpc::health::v1::HealthCheckResponse::SERVING);\n  expectHostHealthy(true);\n}\n\n// Test host check success when gRPC response payload is split between several incoming data chunks.\nTEST_F(GrpcHealthCheckerImplTest, SuccessResponseSplitBetweenChunks) {\n  setupServiceNameHC(absl::nullopt);\n  expectSingleHealthcheck(HealthTransition::Unchanged);\n\n  auto response_headers = std::make_unique<Http::TestResponseHeaderMapImpl>(\n      std::initializer_list<std::pair<std::string, std::string>>{\n          {\":status\", \"200\"},\n          {\"content-type\", \"application/grpc\"},\n      });\n  test_sessions_[0]->stream_response_callbacks_->decodeHeaders(std::move(response_headers), false);\n\n  grpc::health::v1::HealthCheckResponse response;\n  response.set_status(grpc::health::v1::HealthCheckResponse::SERVING);\n  auto data = Grpc::Common::serializeToGrpcFrame(response);\n\n  const char* raw_data = static_cast<char*>(data->linearize(data->length()));\n  const uint64_t chunk_size = data->length() / 5;\n  for (uint64_t offset = 0; offset < data->length(); offset += chunk_size) {\n    const uint64_t effective_size = std::min(chunk_size, data->length() - offset);\n    const auto chunk = std::make_unique<Buffer::OwnedImpl>(raw_data + offset, effective_size);\n    test_sessions_[0]->stream_response_callbacks_->decodeData(*chunk, false);\n  }\n\n  auto trailers = std::make_unique<Http::TestResponseTrailerMapImpl>(\n      std::initializer_list<std::pair<std::string, std::string>>{{\"grpc-status\", \"0\"}});\n  test_sessions_[0]->stream_response_callbacks_->decodeTrailers(std::move(trailers));\n\n  expectHostHealthy(true);\n}\n\n// Test host check success with multiple hosts.\nTEST_F(GrpcHealthCheckerImplTest, SuccessWithMultipleHosts) {\n  setupHC();\n\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime()),\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:81\", simTime())};\n\n  expectHealthchecks(HealthTransition::Unchanged, 2);\n\n  respondServiceStatus(0, grpc::health::v1::HealthCheckResponse::SERVING);\n  respondServiceStatus(1, grpc::health::v1::HealthCheckResponse::SERVING);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[1]->health());\n}\n\n// Test host check success with multiple hosts across multiple priorities.\nTEST_F(GrpcHealthCheckerImplTest, SuccessWithMultipleHostSets) {\n  setupHC();\n\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  cluster_->prioritySet().getMockHostSet(1)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:81\", simTime())};\n\n  expectHealthchecks(HealthTransition::Unchanged, 2);\n\n  respondServiceStatus(0, grpc::health::v1::HealthCheckResponse::SERVING);\n  respondServiceStatus(1, grpc::health::v1::HealthCheckResponse::SERVING);\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n  EXPECT_EQ(Host::Health::Healthy, cluster_->prioritySet().getMockHostSet(1)->hosts_[0]->health());\n}\n\n// Test stream-level watermarks does not interfere with health check.\nTEST_F(GrpcHealthCheckerImplTest, StreamReachesWatermarkDuringCheck) {\n  setupHC();\n  expectSingleHealthcheck(HealthTransition::Unchanged);\n\n  test_sessions_[0]->request_encoder_.stream_.runHighWatermarkCallbacks();\n  test_sessions_[0]->request_encoder_.stream_.runLowWatermarkCallbacks();\n\n  respondServiceStatus(0, grpc::health::v1::HealthCheckResponse::SERVING);\n  expectHostHealthy(true);\n}\n\n// Test connection-level watermarks does not interfere with health check.\nTEST_F(GrpcHealthCheckerImplTest, ConnectionReachesWatermarkDuringCheck) {\n  setupHC();\n  expectSingleHealthcheck(HealthTransition::Unchanged);\n\n  test_sessions_[0]->client_connection_->runHighWatermarkCallbacks();\n  test_sessions_[0]->client_connection_->runLowWatermarkCallbacks();\n\n  respondServiceStatus(0, grpc::health::v1::HealthCheckResponse::SERVING);\n  expectHostHealthy(true);\n}\n\n// Test health check on host without traffic sets larger unconfigurable interval for the next check.\nTEST_F(GrpcHealthCheckerImplTest, SuccessNoTraffic) {\n  setupHC();\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n\n  expectSessionCreate();\n  expectHealthcheckStart(0);\n  health_checker_->start();\n\n  // Default healthcheck interval for hosts without traffic is 60 seconds.\n  expectHealthcheckStop(0, 60000);\n  // Host state should not be changed (remains healthy).\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n  respondServiceStatus(0, grpc::health::v1::HealthCheckResponse::SERVING);\n  expectHostHealthy(true);\n}\n\n// Test first successful check immediately makes failed host available (without 2nd probe).\nTEST_F(GrpcHealthCheckerImplTest, SuccessStartFailedSuccessFirst) {\n  setupHC();\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthFlagSet(\n      Host::HealthFlag::FAILED_ACTIVE_HC);\n  cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthFlagSet(\n      Host::HealthFlag::PENDING_ACTIVE_HC);\n\n  expectSessionCreate();\n  expectHealthcheckStart(0);\n  health_checker_->start();\n\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.max_interval\", _)).WillOnce(Return(500));\n  EXPECT_CALL(runtime_.snapshot_, getInteger(\"health_check.min_interval\", _));\n  expectHealthcheckStop(0, 500);\n  // Fast success immediately moves us to healthy.\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Changed));\n  EXPECT_CALL(event_logger_, logAddHealthy(_, _, true));\n  respondServiceStatus(0, grpc::health::v1::HealthCheckResponse::SERVING);\n  expectHostHealthy(true);\n  EXPECT_FALSE(cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthFlagGet(\n      Host::HealthFlag::PENDING_ACTIVE_HC));\n}\n\n// Test host recovery after first failed check requires several successful checks.\nTEST_F(GrpcHealthCheckerImplTest, SuccessStartFailedFailFirst) {\n  setupHC();\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthFlagSet(\n      Host::HealthFlag::FAILED_ACTIVE_HC);\n  cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthFlagSet(\n      Host::HealthFlag::PENDING_ACTIVE_HC);\n\n  expectSessionCreate();\n  expectHealthcheckStart(0);\n  health_checker_->start();\n\n  // Failing first disables fast success.\n  expectHealthcheckStop(0);\n  // Host was unhealthy from the start, but we expect a state change due to the pending active hc\n  // flag changing.\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Changed));\n  EXPECT_CALL(event_logger_, logUnhealthy(_, _, _, true));\n  respondServiceStatus(0, grpc::health::v1::HealthCheckResponse::NOT_SERVING);\n  expectHostHealthy(false);\n  EXPECT_FALSE(cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthFlagGet(\n      Host::HealthFlag::PENDING_ACTIVE_HC));\n\n  // Next successful healthcheck does not move host int healthy state (because we configured\n  // healthchecker this way).\n  expectHealthcheckStart(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  expectHealthcheckStop(0);\n  // Host still unhealthy, need yet another healthcheck.\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::ChangePending));\n  respondServiceStatus(0, grpc::health::v1::HealthCheckResponse::SERVING);\n  expectHostHealthy(false);\n\n  // 2nd successful healthcheck renders host healthy.\n  expectHealthcheckStart(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  expectHealthcheckStop(0);\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Changed));\n  EXPECT_CALL(event_logger_, logAddHealthy(_, _, false));\n  respondServiceStatus(0, grpc::health::v1::HealthCheckResponse::SERVING);\n  expectHostHealthy(true);\n}\n\n// Verify functionality when a host is removed inline with a failure via RPC that was proceeded\n// by a GOAWAY.\nTEST_F(GrpcHealthCheckerImplTest, GrpcHealthFailViaRpcRemoveHostInCallback) {\n  setupHC();\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n\n  expectSessionCreate();\n  expectHealthcheckStart(0);\n  EXPECT_CALL(event_logger_, logUnhealthy(_, _, _, true));\n  health_checker_->start();\n\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Changed))\n      .WillOnce(Invoke([&](HostSharedPtr host, HealthTransition) {\n        cluster_->prioritySet().getMockHostSet(0)->hosts_ = {};\n        cluster_->prioritySet().runUpdateCallbacks(0, {}, {host});\n      }));\n  EXPECT_CALL(event_logger_, logEjectUnhealthy(_, _, _));\n  test_sessions_[0]->codec_client_->raiseGoAway(Http::GoAwayErrorCode::NoError);\n  respondServiceStatus(0, grpc::health::v1::HealthCheckResponse::NOT_SERVING);\n}\n\n// Verify functionality when a host is removed inline with a failure via an error GOAWAY.\nTEST_F(GrpcHealthCheckerImplTest, GrpcHealthFailViaGoawayRemoveHostInCallback) {\n  setupHCWithUnhealthyThreshold(/*threshold=*/1);\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n\n  expectSessionCreate();\n  expectHealthcheckStart(0);\n  EXPECT_CALL(event_logger_, logUnhealthy(_, _, _, true));\n  health_checker_->start();\n\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Changed))\n      .WillOnce(Invoke([&](HostSharedPtr host, HealthTransition) {\n        cluster_->prioritySet().getMockHostSet(0)->hosts_ = {};\n        cluster_->prioritySet().runUpdateCallbacks(0, {}, {host});\n      }));\n  EXPECT_CALL(event_logger_, logEjectUnhealthy(_, _, _));\n  test_sessions_[0]->codec_client_->raiseGoAway(Http::GoAwayErrorCode::Other);\n}\n\n// Verify functionality when a host is removed inline with by a bad RPC response.\nTEST_F(GrpcHealthCheckerImplTest, GrpcHealthFailViaBadResponseRemoveHostInCallback) {\n  setupHCWithUnhealthyThreshold(/*threshold=*/1);\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n\n  expectSessionCreate();\n  expectHealthcheckStart(0);\n  EXPECT_CALL(event_logger_, logUnhealthy(_, _, _, true));\n  health_checker_->start();\n\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Changed))\n      .WillOnce(Invoke([&](HostSharedPtr host, HealthTransition) {\n        cluster_->prioritySet().getMockHostSet(0)->hosts_ = {};\n        cluster_->prioritySet().runUpdateCallbacks(0, {}, {host});\n      }));\n  EXPECT_CALL(event_logger_, logEjectUnhealthy(_, _, _));\n  std::unique_ptr<Http::TestResponseHeaderMapImpl> response_headers(\n      new Http::TestResponseHeaderMapImpl{{\":status\", \"500\"}});\n  test_sessions_[0]->stream_response_callbacks_->decodeHeaders(std::move(response_headers), false);\n}\n\n// Test host recovery after explicit check failure requires several successful checks.\nTEST_F(GrpcHealthCheckerImplTest, GrpcHealthFail) {\n  setupHC();\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n\n  expectSessionCreate();\n  expectHealthcheckStart(0);\n  EXPECT_CALL(event_logger_, logUnhealthy(_, _, _, true));\n  health_checker_->start();\n\n  // Explicit healthcheck failure immediately renders host unhealthy.\n  expectHealthcheckStop(0);\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Changed));\n  EXPECT_CALL(event_logger_, logEjectUnhealthy(_, _, _));\n  respondServiceStatus(0, grpc::health::v1::HealthCheckResponse::NOT_SERVING);\n  expectHostHealthy(false);\n\n  // Next, we need 2 successful checks for host to become available again.\n  expectHealthcheckStart(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  expectHealthcheckStop(0);\n  // Host still considered unhealthy.\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::ChangePending));\n  respondServiceStatus(0, grpc::health::v1::HealthCheckResponse::SERVING);\n  expectHostHealthy(false);\n\n  expectHealthcheckStart(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  expectHealthcheckStop(0);\n  // Host should has become healthy.\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Changed));\n  EXPECT_CALL(event_logger_, logAddHealthy(_, _, false));\n  respondServiceStatus(0, grpc::health::v1::HealthCheckResponse::SERVING);\n  expectHostHealthy(true);\n}\n\n// Test disconnects produce network-type failures which does not lead to immediate unhealthy state.\nTEST_F(GrpcHealthCheckerImplTest, Disconnect) {\n  setupHC();\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n\n  expectSessionCreate();\n  expectHealthcheckStart(0);\n  EXPECT_CALL(event_logger_, logUnhealthy(_, _, _, true));\n  health_checker_->start();\n\n  expectHealthcheckStop(0);\n  // Network-type healthcheck failure should make host unhealthy only after 2nd event in a row.\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::ChangePending));\n  test_sessions_[0]->client_connection_->raiseEvent(Network::ConnectionEvent::RemoteClose);\n  expectHostHealthy(true);\n\n  expectClientCreate(0);\n  expectHealthcheckStart(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  expectHealthcheckStop(0);\n  // Now, host should be unhealthy.\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Changed));\n  EXPECT_CALL(event_logger_, logEjectUnhealthy(_, _, _));\n  test_sessions_[0]->client_connection_->raiseEvent(Network::ConnectionEvent::RemoteClose);\n  expectHostHealthy(false);\n}\n\nTEST_F(GrpcHealthCheckerImplTest, Timeout) {\n  setupHCWithUnhealthyThreshold(1);\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  expectSessionCreate();\n\n  expectHealthcheckStart(0);\n  EXPECT_CALL(event_logger_, logUnhealthy(_, _, _, true));\n  health_checker_->start();\n\n  expectHealthcheckStop(0);\n  // Unhealthy threshold is 1 so first timeout causes unhealthy\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Changed));\n  EXPECT_CALL(event_logger_, logEjectUnhealthy(_, _, _));\n  test_sessions_[0]->timeout_timer_->invokeCallback();\n  expectHostHealthy(false);\n}\n\n// Test timeouts produce network-type failures which does not lead to immediate unhealthy state.\nTEST_F(GrpcHealthCheckerImplTest, DoubleTimeout) {\n  setupHC();\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  expectSessionCreate();\n\n  expectHealthcheckStart(0);\n  EXPECT_CALL(event_logger_, logUnhealthy(_, _, _, true));\n  health_checker_->start();\n\n  expectHealthcheckStop(0);\n  // Timeouts are considered network failures and make host unhealthy also after 2nd event.\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::ChangePending));\n  test_sessions_[0]->timeout_timer_->invokeCallback();\n  expectHostHealthy(true);\n\n  expectHealthcheckStart(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  expectHealthcheckStop(0);\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Changed));\n  EXPECT_CALL(event_logger_, logEjectUnhealthy(_, _, _));\n  // Close connection. Timeouts and connection closes counts together.\n  test_sessions_[0]->client_connection_->raiseEvent(Network::ConnectionEvent::RemoteClose);\n  expectHostHealthy(false);\n}\n\n// Test adding and removal of hosts starts and closes healthcheck sessions.\nTEST_F(GrpcHealthCheckerImplTest, DynamicAddAndRemove) {\n  setupHC();\n  health_checker_->start();\n\n  expectSessionCreate();\n  expectStreamCreate(0);\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  cluster_->prioritySet().getMockHostSet(0)->runCallbacks(\n      {cluster_->prioritySet().getMockHostSet(0)->hosts_.back()}, {});\n\n  HostVector removed{cluster_->prioritySet().getMockHostSet(0)->hosts_.back()};\n  cluster_->prioritySet().getMockHostSet(0)->hosts_.clear();\n  EXPECT_CALL(*test_sessions_[0]->client_connection_, close(_));\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n  cluster_->prioritySet().getMockHostSet(0)->runCallbacks({}, removed);\n}\n\nTEST_F(GrpcHealthCheckerImplTest, HealthCheckIntervals) {\n  setupHealthCheckIntervalOverridesHC();\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://128.0.0.1:80\", simTime())};\n  expectSessionCreate();\n  expectStreamCreate(0);\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  health_checker_->start();\n\n  // First check should respect no_traffic_interval setting.\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(std::chrono::milliseconds(5000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  respondServiceStatus(0, grpc::health::v1::HealthCheckResponse::SERVING);\n  cluster_->info_->stats().upstream_cx_total_.inc();\n\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  // Needed after a response is sent.\n  expectStreamCreate(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  // Follow up successful checks should respect interval setting.\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(std::chrono::milliseconds(1000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  respondServiceStatus(0, grpc::health::v1::HealthCheckResponse::SERVING);\n\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  // Needed after a response is sent.\n  expectStreamCreate(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  // Follow up successful checks should respect interval setting.\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(std::chrono::milliseconds(1000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  respondServiceStatus(0, grpc::health::v1::HealthCheckResponse::SERVING);\n\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  // Needed after a response is sent.\n  expectStreamCreate(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  // A logical failure is not considered a network failure, therefore the unhealthy threshold is\n  // ignored and health state changes immediately. Since the threshold is ignored, next health\n  // check respects \"unhealthy_interval\".\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Changed));\n  EXPECT_CALL(event_logger_, logEjectUnhealthy(_, _, _));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(std::chrono::milliseconds(2000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  respondServiceStatus(0, grpc::health::v1::HealthCheckResponse::NOT_SERVING);\n\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  // Needed after a response is sent.\n  expectStreamCreate(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  // Subsequent failing checks should respect unhealthy_interval.\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(std::chrono::milliseconds(2000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  respondServiceStatus(0, grpc::health::v1::HealthCheckResponse::NOT_SERVING);\n\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  // Needed after a response is sent.\n  expectStreamCreate(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  // Subsequent failing checks should respect unhealthy_interval.\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(std::chrono::milliseconds(2000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  respondServiceStatus(0, grpc::health::v1::HealthCheckResponse::NOT_SERVING);\n\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  // Needed after a response is sent.\n  expectStreamCreate(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  // When transitioning to a successful state, checks should respect healthy_edge_interval. Health\n  // state should be delayed pending healthy threshold.\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::ChangePending));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(std::chrono::milliseconds(4000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  respondServiceStatus(0, grpc::health::v1::HealthCheckResponse::SERVING);\n\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  // Needed after a response is sent.\n  expectStreamCreate(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::ChangePending));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(std::chrono::milliseconds(4000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  respondServiceStatus(0, grpc::health::v1::HealthCheckResponse::SERVING);\n\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  // Needed after a response is sent.\n  expectStreamCreate(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  // After the healthy threshold is reached, health state should change while checks should respect\n  // the default interval.\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Changed));\n  EXPECT_CALL(event_logger_, logAddHealthy(_, _, false));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(std::chrono::milliseconds(1000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  respondServiceStatus(0, grpc::health::v1::HealthCheckResponse::SERVING);\n\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  // Needed after a response is sent.\n  expectStreamCreate(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  // Subsequent checks shouldn't change the state.\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(std::chrono::milliseconds(1000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  respondServiceStatus(0, grpc::health::v1::HealthCheckResponse::SERVING);\n\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  // Needed after a response is sent.\n  expectStreamCreate(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  // First failed check after a run o successful ones should respect unhealthy_edge_interval. A\n  // timeout, being a network type failure, should respect unhealthy threshold before changing the\n  // health state.\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::ChangePending));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(std::chrono::milliseconds(3000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  test_sessions_[0]->timeout_timer_->invokeCallback();\n\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  // Needed after a response is sent.\n  expectStreamCreate(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::ChangePending));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(std::chrono::milliseconds(3000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  test_sessions_[0]->timeout_timer_->invokeCallback();\n\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  // Needed after a response is sent.\n  expectStreamCreate(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  // Subsequent failing checks should respect unhealthy_interval. As the unhealthy threshold is\n  // reached, health state should also change.\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Changed));\n  EXPECT_CALL(event_logger_, logEjectUnhealthy(_, _, _));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(std::chrono::milliseconds(2000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  test_sessions_[0]->timeout_timer_->invokeCallback();\n\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  // Needed after a response is sent.\n  expectStreamCreate(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  // Remaining failing checks shouldn't change the state.\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(std::chrono::milliseconds(2000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  test_sessions_[0]->timeout_timer_->invokeCallback();\n\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  // Needed after a response is sent.\n  expectStreamCreate(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  // When transitioning to a successful state, checks should respect healthy_edge_interval.\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::ChangePending));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(std::chrono::milliseconds(4000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  respondServiceStatus(0, grpc::health::v1::HealthCheckResponse::SERVING);\n\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  // Needed after a response is sent.\n  expectStreamCreate(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::ChangePending));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(std::chrono::milliseconds(4000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  respondServiceStatus(0, grpc::health::v1::HealthCheckResponse::SERVING);\n\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  // Needed after a response is sent.\n  expectStreamCreate(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  // After the healthy threshold is reached, health state should change while checks should respect\n  // the default interval.\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Changed));\n  EXPECT_CALL(event_logger_, logAddHealthy(_, _, false));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(std::chrono::milliseconds(1000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  respondServiceStatus(0, grpc::health::v1::HealthCheckResponse::SERVING);\n\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, enableTimer(_, _));\n  // Needed after a response is sent.\n  expectStreamCreate(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  // Subsequent checks shouldn't change the state.\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n  EXPECT_CALL(*test_sessions_[0]->interval_timer_, enableTimer(std::chrono::milliseconds(1000), _));\n  EXPECT_CALL(*test_sessions_[0]->timeout_timer_, disableTimer());\n  respondServiceStatus(0, grpc::health::v1::HealthCheckResponse::SERVING);\n}\n\n// Test connection close between checks affects nothing.\nTEST_F(GrpcHealthCheckerImplTest, RemoteCloseBetweenChecks) {\n  setupHC();\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n\n  expectSessionCreate();\n  expectHealthcheckStart(0);\n  health_checker_->start();\n\n  expectHealthcheckStop(0);\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n  respondServiceStatus(0, grpc::health::v1::HealthCheckResponse::SERVING);\n  expectHostHealthy(true);\n\n  // Connection closed between checks - nothing happens, just re-create client.\n  test_sessions_[0]->client_connection_->raiseEvent(Network::ConnectionEvent::RemoteClose);\n\n  expectClientCreate(0);\n  expectHealthcheckStart(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  expectHealthcheckStop(0);\n  // Test host state haven't changed.\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n  respondServiceStatus(0, grpc::health::v1::HealthCheckResponse::SERVING);\n  expectHostHealthy(true);\n}\n\n// Test that we close connections on a healthy check when reuse_connection is false.\nTEST_F(GrpcHealthCheckerImplTest, DontReuseConnectionBetweenChecks) {\n  setupNoReuseConnectionHC();\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n\n  expectSessionCreate();\n  expectHealthcheckStart(0);\n  health_checker_->start();\n\n  expectHealthcheckStop(0);\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n  respondServiceStatus(0, grpc::health::v1::HealthCheckResponse::SERVING);\n  expectHostHealthy(true);\n\n  // A new client is created because we close the connection ourselves.\n  // See GrpcHealthCheckerImplTest.RemoteCloseBetweenChecks for how this works when the remote end\n  // closes the connection.\n  expectClientCreate(0);\n  expectHealthcheckStart(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  expectHealthcheckStop(0);\n  // Test host state haven't changed.\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n  respondServiceStatus(0, grpc::health::v1::HealthCheckResponse::SERVING);\n  expectHostHealthy(true);\n}\n\n// Test that we close connections when a timeout occurs and reuse_connection is false.\nTEST_F(GrpcHealthCheckerImplTest, DontReuseConnectionTimeout) {\n  setupNoReuseConnectionHC();\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n\n  expectSessionCreate();\n  expectHealthcheckStart(0);\n  EXPECT_CALL(event_logger_, logUnhealthy(_, _, _, true));\n  health_checker_->start();\n\n  expectHealthcheckStop(0);\n  // Timeouts are considered network failures and make host unhealthy also after 2nd event.\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::ChangePending));\n  test_sessions_[0]->timeout_timer_->invokeCallback();\n  expectHostHealthy(true);\n\n  // A new client is created because we close the connection\n  // when a timeout occurs and connection reuse is disabled.\n  expectClientCreate(0);\n  expectHealthcheckStart(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  expectHealthcheckStop(0);\n  // Test host state haven't changed.\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n  respondServiceStatus(0, grpc::health::v1::HealthCheckResponse::SERVING);\n  expectHostHealthy(true);\n}\n\n// Test that we close connections when a stream reset occurs and reuse_connection is false.\nTEST_F(GrpcHealthCheckerImplTest, DontReuseConnectionStreamReset) {\n  setupNoReuseConnectionHC();\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n\n  expectSessionCreate();\n  expectHealthcheckStart(0);\n  EXPECT_CALL(event_logger_, logUnhealthy(_, _, _, true));\n  health_checker_->start();\n\n  expectHealthcheckStop(0);\n  // Resets are considered network failures and make host unhealthy also after 2nd event.\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::ChangePending));\n  test_sessions_[0]->request_encoder_.stream_.resetStream(Http::StreamResetReason::RemoteReset);\n  expectHostHealthy(true);\n\n  // A new client is created because we close the connection\n  // when a stream reset occurs and connection reuse is disabled.\n  expectClientCreate(0);\n  expectHealthcheckStart(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  expectHealthcheckStop(0);\n  // Test host state haven't changed.\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n  respondServiceStatus(0, grpc::health::v1::HealthCheckResponse::SERVING);\n  expectHostHealthy(true);\n}\n\n// Test UNKNOWN health status is considered unhealthy.\nTEST_F(GrpcHealthCheckerImplTest, GrpcFailUnknown) {\n  setupHC();\n  expectSingleHealthcheck(HealthTransition::Changed);\n  EXPECT_CALL(event_logger_, logEjectUnhealthy(_, _, _));\n  EXPECT_CALL(event_logger_, logUnhealthy(_, _, _, true));\n\n  respondServiceStatus(0, grpc::health::v1::HealthCheckResponse::UNKNOWN);\n  EXPECT_TRUE(cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthFlagGet(\n      Host::HealthFlag::FAILED_ACTIVE_HC));\n  EXPECT_EQ(Host::Health::Unhealthy,\n            cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n}\n\n// This used to cause a null dereference\nTEST_F(GrpcHealthCheckerImplTest, GrpcFailNullBytes) {\n  setupHC();\n  expectSingleHealthcheck(HealthTransition::Changed);\n  EXPECT_CALL(event_logger_, logEjectUnhealthy(_, _, _));\n  EXPECT_CALL(event_logger_, logUnhealthy(_, _, _, true));\n  respondResponseSpec(0, ResponseSpec{{{\":status\", \"200\"}, {\"content-type\", \"application/grpc\"}},\n                                      {GrpcHealthCheckerImplTest::ResponseSpec::badData()},\n                                      {}});\n  EXPECT_TRUE(cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthFlagGet(\n      Host::HealthFlag::FAILED_ACTIVE_HC));\n  EXPECT_EQ(Host::Health::Unhealthy,\n            cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n}\n\n// This used to cause a null dereference\nTEST_F(GrpcHealthCheckerImplTest, GrpcValidFramesThenInvalidFrames) {\n  setupHC();\n  expectSingleHealthcheck(HealthTransition::Changed);\n  EXPECT_CALL(event_logger_, logEjectUnhealthy(_, _, _));\n  EXPECT_CALL(event_logger_, logUnhealthy(_, _, _, true));\n  respondResponseSpec(\n      0, ResponseSpec{{{\":status\", \"200\"}, {\"content-type\", \"application/grpc\"}},\n                      {GrpcHealthCheckerImplTest::ResponseSpec::validFramesThenInvalidFrames()},\n                      {}});\n  EXPECT_TRUE(cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthFlagGet(\n      Host::HealthFlag::FAILED_ACTIVE_HC));\n  EXPECT_EQ(Host::Health::Unhealthy,\n            cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n}\n\n// Test SERVICE_UNKNOWN health status is considered unhealthy.\nTEST_F(GrpcHealthCheckerImplTest, GrpcFailServiceUnknown) {\n  setupHC();\n  expectSingleHealthcheck(HealthTransition::Changed);\n  EXPECT_CALL(event_logger_, logEjectUnhealthy(_, _, _));\n  EXPECT_CALL(event_logger_, logUnhealthy(_, _, _, true));\n\n  respondServiceStatus(0, grpc::health::v1::HealthCheckResponse::SERVICE_UNKNOWN);\n  EXPECT_TRUE(cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthFlagGet(\n      Host::HealthFlag::FAILED_ACTIVE_HC));\n  EXPECT_EQ(Host::Health::Unhealthy,\n            cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n}\n\n// Test non existent health status enum is considered unhealthy.\nTEST_F(GrpcHealthCheckerImplTest, GrpcFailUnknownHealthStatus) {\n  setupHC();\n  expectSingleHealthcheck(HealthTransition::Changed);\n  EXPECT_CALL(event_logger_, logEjectUnhealthy(_, _, _));\n  EXPECT_CALL(event_logger_, logUnhealthy(_, _, _, true));\n\n  respondServiceStatus(0, static_cast<grpc::health::v1::HealthCheckResponse::ServingStatus>(999));\n  EXPECT_TRUE(cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthFlagGet(\n      Host::HealthFlag::FAILED_ACTIVE_HC));\n  EXPECT_EQ(Host::Health::Unhealthy,\n            cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n}\n\n// Test receiving GOAWAY (error) is interpreted as connection close event.\nTEST_F(GrpcHealthCheckerImplTest, GoAwayErrorProbeInProgress) {\n  // FailureType::Network will be issued, it will render host unhealthy only if unhealthy_threshold\n  // is reached.\n  setupHCWithUnhealthyThreshold(1);\n  expectSingleHealthcheck(HealthTransition::Changed);\n  EXPECT_CALL(event_logger_, logEjectUnhealthy(_, _, _));\n  EXPECT_CALL(event_logger_, logUnhealthy(_, _, _, true));\n\n  // GOAWAY with non-NO_ERROR code will result in a healthcheck failure\n  // and the connection closing.\n  test_sessions_[0]->codec_client_->raiseGoAway(Http::GoAwayErrorCode::Other);\n\n  EXPECT_TRUE(cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->healthFlagGet(\n      Host::HealthFlag::FAILED_ACTIVE_HC));\n  EXPECT_EQ(Host::Health::Unhealthy,\n            cluster_->prioritySet().getMockHostSet(0)->hosts_[0]->health());\n}\n\n// Test receiving GOAWAY (no error) is handled gracefully while a check is in progress.\nTEST_F(GrpcHealthCheckerImplTest, GoAwayProbeInProgress) {\n  setupHCWithUnhealthyThreshold(/*threshold=*/1);\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n\n  expectSessionCreate();\n  expectHealthcheckStart(0);\n  health_checker_->start();\n\n  expectHealthcheckStop(0);\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n\n  // GOAWAY with NO_ERROR code during check should be handle gracefully.\n  test_sessions_[0]->codec_client_->raiseGoAway(Http::GoAwayErrorCode::NoError);\n  respondServiceStatus(0, grpc::health::v1::HealthCheckResponse::SERVING);\n  expectHostHealthy(true);\n\n  // GOAWAY should cause a new connection to be created.\n  expectClientCreate(0);\n  expectHealthcheckStart(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  expectHealthcheckStop(0);\n  // Test host state haven't changed.\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n  respondServiceStatus(0, grpc::health::v1::HealthCheckResponse::SERVING);\n  expectHostHealthy(true);\n}\n\n// Test receiving GOAWAY (no error) closes connection after an in progress probe times outs.\nTEST_F(GrpcHealthCheckerImplTest, GoAwayProbeInProgressTimeout) {\n  setupHCWithUnhealthyThreshold(/*threshold=*/1);\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n\n  expectSessionCreate();\n  expectHealthcheckStart(0);\n  EXPECT_CALL(event_logger_, logUnhealthy(_, _, _, true));\n  health_checker_->start();\n\n  expectHealthcheckStop(0);\n  // Unhealthy threshold is 1 so first timeout causes unhealthy\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Changed));\n  EXPECT_CALL(event_logger_, logEjectUnhealthy(_, _, _));\n\n  // GOAWAY during check should be handled gracefully.\n  test_sessions_[0]->codec_client_->raiseGoAway(Http::GoAwayErrorCode::NoError);\n  expectHostHealthy(true);\n\n  test_sessions_[0]->timeout_timer_->invokeCallback();\n  expectHostHealthy(false);\n\n  // GOAWAY should cause a new connection to be created.\n  expectClientCreate(0);\n  expectHealthcheckStart(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  expectHealthcheckStop(0);\n  // Healthy threshold is 2, so the we'ere pending a state change.\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::ChangePending));\n  respondServiceStatus(0, grpc::health::v1::HealthCheckResponse::SERVING);\n  expectHostHealthy(false);\n}\n\n// Test receiving GOAWAY (no error) closes connection after an unexpected stream reset.\nTEST_F(GrpcHealthCheckerImplTest, GoAwayProbeInProgressStreamReset) {\n  setupHCWithUnhealthyThreshold(/*threshold=*/1);\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n\n  expectSessionCreate();\n  expectHealthcheckStart(0);\n  EXPECT_CALL(event_logger_, logUnhealthy(_, _, _, true));\n  health_checker_->start();\n\n  expectHealthcheckStop(0);\n  // Unhealthy threshold is 1 so first stream reset causes unhealthy\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Changed));\n  EXPECT_CALL(event_logger_, logEjectUnhealthy(_, _, _));\n\n  // GOAWAY during check should be handled gracefully.\n  test_sessions_[0]->codec_client_->raiseGoAway(Http::GoAwayErrorCode::NoError);\n  expectHostHealthy(true);\n\n  test_sessions_[0]->request_encoder_.stream_.resetStream(Http::StreamResetReason::RemoteReset);\n  expectHostHealthy(false);\n\n  // GOAWAY should cause a new connection to be created.\n  expectClientCreate(0);\n  expectHealthcheckStart(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  expectHealthcheckStop(0);\n  // Healthy threshold is 2, so the we'ere pending a state change.\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::ChangePending));\n  respondServiceStatus(0, grpc::health::v1::HealthCheckResponse::SERVING);\n  expectHostHealthy(false);\n}\n\n// Test receiving GOAWAY (no error) closes connection after a bad response.\nTEST_F(GrpcHealthCheckerImplTest, GoAwayProbeInProgressBadResponse) {\n  setupHCWithUnhealthyThreshold(/*threshold=*/1);\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n\n  expectSessionCreate();\n  expectHealthcheckStart(0);\n  EXPECT_CALL(event_logger_, logUnhealthy(_, _, _, true));\n  health_checker_->start();\n\n  expectHealthcheckStop(0);\n  // Unhealthy threshold is 1 so first bad response causes unhealthy\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Changed));\n  EXPECT_CALL(event_logger_, logEjectUnhealthy(_, _, _));\n\n  // GOAWAY during check should be handled gracefully.\n  test_sessions_[0]->codec_client_->raiseGoAway(Http::GoAwayErrorCode::NoError);\n  expectHostHealthy(true);\n\n  respondResponseSpec(0, ResponseSpec{{{\":status\", \"200\"}, {\"content-type\", \"application/grpc\"}},\n                                      {ResponseSpec::invalidChunk()},\n                                      {}});\n  expectHostHealthy(false);\n\n  // GOAWAY should cause a new connection to be created.\n  expectClientCreate(0);\n  expectHealthcheckStart(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  expectHealthcheckStop(0);\n  // Healthy threshold is 2, so the we'ere pending a state change.\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::ChangePending));\n  respondServiceStatus(0, grpc::health::v1::HealthCheckResponse::SERVING);\n  expectHostHealthy(false);\n}\n\n// Test receiving GOAWAY (no error) and a connection close.\nTEST_F(GrpcHealthCheckerImplTest, GoAwayProbeInProgressConnectionClose) {\n  setupHCWithUnhealthyThreshold(/*threshold=*/1);\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n\n  expectSessionCreate();\n  expectHealthcheckStart(0);\n  EXPECT_CALL(event_logger_, logUnhealthy(_, _, _, true));\n  health_checker_->start();\n\n  expectHealthcheckStop(0);\n  // Unhealthy threshold is 1 so first bad response causes unhealthy\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Changed));\n  EXPECT_CALL(event_logger_, logEjectUnhealthy(_, _, _));\n\n  // GOAWAY during check should be handled gracefully.\n  test_sessions_[0]->codec_client_->raiseGoAway(Http::GoAwayErrorCode::NoError);\n  expectHostHealthy(true);\n\n  test_sessions_[0]->client_connection_->raiseEvent(Network::ConnectionEvent::RemoteClose);\n  expectHostHealthy(false);\n\n  // GOAWAY should cause a new connection to be created.\n  expectClientCreate(0);\n  expectHealthcheckStart(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  expectHealthcheckStop(0);\n  // Healthy threshold is 2, so the we'ere pending a state change.\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::ChangePending));\n  respondServiceStatus(0, grpc::health::v1::HealthCheckResponse::SERVING);\n  expectHostHealthy(false);\n}\n\n// Test receiving GOAWAY between checks affects nothing.\nTEST_F(GrpcHealthCheckerImplTest, GoAwayBetweenChecks) {\n  setupHC();\n  cluster_->prioritySet().getMockHostSet(0)->hosts_ = {\n      makeTestHost(cluster_->info_, \"tcp://127.0.0.1:80\", simTime())};\n\n  expectSessionCreate();\n  expectHealthcheckStart(0);\n  health_checker_->start();\n\n  expectHealthcheckStop(0);\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n  respondServiceStatus(0, grpc::health::v1::HealthCheckResponse::SERVING);\n  expectHostHealthy(true);\n\n  // GOAWAY between checks should go unnoticed.\n  test_sessions_[0]->codec_client_->raiseGoAway(Http::GoAwayErrorCode::NoError);\n\n  expectClientCreate(0);\n  expectHealthcheckStart(0);\n  test_sessions_[0]->interval_timer_->invokeCallback();\n\n  expectHealthcheckStop(0);\n  // Test host state haven't changed.\n  EXPECT_CALL(*this, onHostStatus(_, HealthTransition::Unchanged));\n  respondServiceStatus(0, grpc::health::v1::HealthCheckResponse::SERVING);\n  expectHostHealthy(true);\n}\n\nclass BadResponseGrpcHealthCheckerImplTest\n    : public testing::TestWithParam<GrpcHealthCheckerImplTest::ResponseSpec>,\n      public GrpcHealthCheckerImplTestBase {};\n\nINSTANTIATE_TEST_SUITE_P(\n    BadResponse, BadResponseGrpcHealthCheckerImplTest,\n    testing::ValuesIn(std::vector<GrpcHealthCheckerImplTest::ResponseSpec>{\n        // Non-200 response.\n        {\n            {{\":status\", \"500\"}},\n            {},\n            {},\n        },\n        // Non-200 response with gRPC status.\n        {\n            {{\":status\", \"500\"}, {\"grpc-status\", \"2\"}},\n            {},\n            {},\n        },\n        // Missing content-type.\n        {\n            {{\":status\", \"200\"}},\n            {},\n            {},\n        },\n        // End stream on response headers.\n        {\n            {{\":status\", \"200\"}, {\"content-type\", \"application/grpc\"}},\n            {},\n            {},\n        },\n        // Non-OK gRPC status in headers.\n        {\n            {{\":status\", \"200\"}, {\"content-type\", \"application/grpc\"}, {\"grpc-status\", \"2\"}},\n            {},\n            {},\n        },\n        // Non-OK gRPC status\n        {\n            {{\":status\", \"200\"}, {\"content-type\", \"application/grpc\"}},\n            {GrpcHealthCheckerImplTest::ResponseSpec::servingResponse()},\n            {{\"grpc-status\", \"2\"}},\n        },\n        // Missing body.\n        {\n            {{\":status\", \"200\"}, {\"content-type\", \"application/grpc\"}, {\"grpc-status\", \"0\"}},\n            {},\n            {},\n        },\n        // Compressed body.\n        {\n            {{\":status\", \"200\"}, {\"content-type\", \"application/grpc\"}},\n            {GrpcHealthCheckerImplTest::ResponseSpec::invalidPayload(Grpc::GRPC_FH_COMPRESSED,\n                                                                     true)},\n            {},\n        },\n        // Invalid proto message.\n        {\n            {{\":status\", \"200\"}, {\"content-type\", \"application/grpc\"}},\n            {GrpcHealthCheckerImplTest::ResponseSpec::invalidPayload(Grpc::GRPC_FH_DEFAULT, false)},\n            {},\n        },\n        // Duplicate response.\n        {\n            {{\":status\", \"200\"}, {\"content-type\", \"application/grpc\"}},\n            {GrpcHealthCheckerImplTest::ResponseSpec::servingResponse(),\n             GrpcHealthCheckerImplTest::ResponseSpec::servingResponse()},\n            {},\n        },\n        // Invalid response.\n        {\n            {{\":status\", \"200\"}, {\"content-type\", \"application/grpc\"}},\n            {GrpcHealthCheckerImplTest::ResponseSpec::invalidChunk()},\n            {},\n        },\n        // No trailers.\n        {\n            {{\":status\", \"200\"}, {\"content-type\", \"application/grpc\"}},\n            {GrpcHealthCheckerImplTest::ResponseSpec::servingResponse()},\n            {},\n        },\n        // No gRPC status in trailer.\n        {\n            {{\":status\", \"200\"}, {\"content-type\", \"application/grpc\"}},\n            {GrpcHealthCheckerImplTest::ResponseSpec::servingResponse()},\n            {{\"some-header\", \"1\"}},\n        },\n        // Invalid gRPC status.\n        {\n            {{\":status\", \"200\"}, {\"content-type\", \"application/grpc\"}},\n            {GrpcHealthCheckerImplTest::ResponseSpec::servingResponse()},\n            {{\"grpc-status\", \"invalid\"}},\n        },\n    }));\n\n// Test different cases of invalid gRPC response makes host unhealthy.\nTEST_P(BadResponseGrpcHealthCheckerImplTest, GrpcBadResponse) {\n  setupHC();\n  expectSingleHealthcheck(HealthTransition::Changed);\n  EXPECT_CALL(event_logger_, logUnhealthy(_, _, _, true));\n  EXPECT_CALL(event_logger_, logEjectUnhealthy(_, _, _));\n\n  ResponseSpec spec = GetParam();\n  respondResponseSpec(0, std::move(spec));\n  expectHostHealthy(false);\n}\n\nTEST(Printer, HealthStatePrinter) {\n  std::ostringstream healthy;\n  healthy << HealthState::Healthy;\n  EXPECT_EQ(\"Healthy\", healthy.str());\n\n  std::ostringstream unhealthy;\n  unhealthy << HealthState::Unhealthy;\n  EXPECT_EQ(\"Unhealthy\", unhealthy.str());\n}\n\nTEST(Printer, HealthTransitionPrinter) {\n  std::ostringstream changed;\n  changed << HealthTransition::Changed;\n  EXPECT_EQ(\"Changed\", changed.str());\n\n  std::ostringstream unchanged;\n  unchanged << HealthTransition::Unchanged;\n  EXPECT_EQ(\"Unchanged\", unchanged.str());\n}\n\nTEST(HealthCheckEventLoggerImplTest, All) {\n  AccessLog::MockAccessLogManager log_manager;\n  std::shared_ptr<AccessLog::MockAccessLogFile> file(new AccessLog::MockAccessLogFile());\n  EXPECT_CALL(log_manager, createAccessLog(Filesystem::FilePathAndType{\n                               Filesystem::DestinationType::File, \"foo\"}))\n      .WillOnce(Return(file));\n\n  std::shared_ptr<MockHostDescription> host(new NiceMock<MockHostDescription>());\n  NiceMock<MockClusterInfo> cluster;\n  ON_CALL(*host, cluster()).WillByDefault(ReturnRef(cluster));\n\n  Event::SimulatedTimeSystem time_system;\n  // This is rendered as \"2009-02-13T23:31:31.234Z\".a\n  time_system.setSystemTime(std::chrono::milliseconds(1234567891234));\n\n  HealthCheckEventLoggerImpl event_logger(log_manager, time_system, \"foo\");\n\n  EXPECT_CALL(*file, write(absl::string_view{\n                         \"{\\\"health_checker_type\\\":\\\"HTTP\\\",\\\"host\\\":{\\\"socket_address\\\":{\"\n                         \"\\\"protocol\\\":\\\"TCP\\\",\\\"address\\\":\\\"10.0.0.1\\\",\\\"resolver_name\\\":\\\"\\\",\"\n                         \"\\\"ipv4_compat\\\":false,\\\"port_value\\\":443}},\\\"cluster_name\\\":\\\"fake_\"\n                         \"cluster\\\",\\\"eject_unhealthy_event\\\":{\\\"failure_type\\\":\\\"ACTIVE\\\"},\"\n                         \"\\\"timestamp\\\":\\\"2009-02-13T23:31:31.234Z\\\"}\\n\"}));\n  event_logger.logEjectUnhealthy(envoy::data::core::v3::HTTP, host, envoy::data::core::v3::ACTIVE);\n\n  EXPECT_CALL(*file, write(absl::string_view{\n                         \"{\\\"health_checker_type\\\":\\\"HTTP\\\",\\\"host\\\":{\\\"socket_address\\\":{\"\n                         \"\\\"protocol\\\":\\\"TCP\\\",\\\"address\\\":\\\"10.0.0.1\\\",\\\"resolver_name\\\":\\\"\\\",\"\n                         \"\\\"ipv4_compat\\\":false,\\\"port_value\\\":443}},\\\"cluster_name\\\":\\\"fake_\"\n                         \"cluster\\\",\\\"add_healthy_event\\\":{\\\"first_check\\\":false},\\\"timestamp\\\":\"\n                         \"\\\"2009-02-13T23:31:31.234Z\\\"}\\n\"}));\n  event_logger.logAddHealthy(envoy::data::core::v3::HTTP, host, false);\n\n  EXPECT_CALL(*file, write(absl::string_view{\n                         \"{\\\"health_checker_type\\\":\\\"HTTP\\\",\\\"host\\\":{\\\"socket_address\\\":{\"\n                         \"\\\"protocol\\\":\\\"TCP\\\",\\\"address\\\":\\\"10.0.0.1\\\",\\\"resolver_name\\\":\\\"\\\",\"\n                         \"\\\"ipv4_compat\\\":false,\\\"port_value\\\":443}},\\\"cluster_name\\\":\\\"fake_\"\n                         \"cluster\\\",\\\"health_check_failure_event\\\":{\\\"failure_type\\\":\\\"ACTIVE\\\",\"\n                         \"\\\"first_check\\\":false},\"\n                         \"\\\"timestamp\\\":\\\"2009-02-13T23:31:31.234Z\\\"}\\n\"}));\n  event_logger.logUnhealthy(envoy::data::core::v3::HTTP, host, envoy::data::core::v3::ACTIVE,\n                            false);\n\n  EXPECT_CALL(*file, write(absl::string_view{\n                         \"{\\\"health_checker_type\\\":\\\"HTTP\\\",\\\"host\\\":{\\\"socket_address\\\":{\"\n                         \"\\\"protocol\\\":\\\"TCP\\\",\\\"address\\\":\\\"10.0.0.1\\\",\\\"resolver_name\\\":\\\"\\\",\"\n                         \"\\\"ipv4_compat\\\":false,\\\"port_value\\\":443}},\\\"cluster_name\\\":\\\"fake_\"\n                         \"cluster\\\",\\\"degraded_healthy_host\\\":{},\"\n                         \"\\\"timestamp\\\":\\\"2009-02-13T23:31:31.234Z\\\"}\\n\"}));\n  event_logger.logDegraded(envoy::data::core::v3::HTTP, host);\n\n  EXPECT_CALL(*file, write(absl::string_view{\n                         \"{\\\"health_checker_type\\\":\\\"HTTP\\\",\\\"host\\\":{\\\"socket_address\\\":{\"\n                         \"\\\"protocol\\\":\\\"TCP\\\",\\\"address\\\":\\\"10.0.0.1\\\",\\\"resolver_name\\\":\\\"\\\",\"\n                         \"\\\"ipv4_compat\\\":false,\\\"port_value\\\":443}},\\\"cluster_name\\\":\\\"fake_\"\n                         \"cluster\\\",\\\"no_longer_degraded_host\\\":{},\"\n                         \"\\\"timestamp\\\":\\\"2009-02-13T23:31:31.234Z\\\"}\\n\"}));\n  event_logger.logNoLongerDegraded(envoy::data::core::v3::HTTP, host);\n}\n\n// Validate that the proto constraints don't allow zero length edge durations.\nTEST(HealthCheckProto, Validation) {\n  {\n    const std::string yaml = R\"EOF(\n    timeout: 1s\n    interval: 1s\n    healthy_threshold: 1\n    unhealthy_threshold: 1\n    no_traffic_interval: 0s\n    http_health_check:\n      service_name_matcher:\n        prefix: locations\n      path: /healthcheck\n    )EOF\";\n    envoy::config::core::v3::HealthCheck health_check_proto;\n    EXPECT_THROW_WITH_REGEX(TestUtility::validate(parseHealthCheckFromV3Yaml(yaml)), EnvoyException,\n                            \"Proto constraint validation failed.*value must be greater than.*\");\n  }\n  {\n    const std::string yaml = R\"EOF(\n    timeout: 1s\n    interval: 1s\n    healthy_threshold: 1\n    unhealthy_threshold: 1\n    unhealthy_interval: 0s\n    http_health_check:\n      service_name_matcher:\n        prefix: locations\n      path: /healthcheck\n    )EOF\";\n    envoy::config::core::v3::HealthCheck health_check_proto;\n    EXPECT_THROW_WITH_REGEX(TestUtility::validate(parseHealthCheckFromV3Yaml(yaml)), EnvoyException,\n                            \"Proto constraint validation failed.*value must be greater than.*\");\n  }\n  {\n    const std::string yaml = R\"EOF(\n    timeout: 1s\n    interval: 1s\n    healthy_threshold: 1\n    unhealthy_threshold: 1\n    unhealthy_edge_interval: 0s\n    http_health_check:\n      service_name_matcher:\n        prefix: locations\n      path: /healthcheck\n    )EOF\";\n    envoy::config::core::v3::HealthCheck health_check_proto;\n    EXPECT_THROW_WITH_REGEX(TestUtility::validate(parseHealthCheckFromV3Yaml(yaml)), EnvoyException,\n                            \"Proto constraint validation failed.*value must be greater than.*\");\n  }\n  {\n    const std::string yaml = R\"EOF(\n    timeout: 1s\n    interval: 1s\n    healthy_threshold: 1\n    unhealthy_threshold: 1\n    healthy_edge_interval: 0s\n    http_health_check:\n      service_name_matcher:\n        prefix: locations\n      path: /healthcheck\n    )EOF\";\n    envoy::config::core::v3::HealthCheck health_check_proto;\n    EXPECT_THROW_WITH_REGEX(TestUtility::validate(parseHealthCheckFromV3Yaml(yaml)), EnvoyException,\n                            \"Proto constraint validation failed.*value must be greater than.*\");\n  }\n  {\n    const std::string yaml = R\"EOF(\n    timeout: 1s\n    interval: 1s\n    unhealthy_threshold: 1\n    http_health_check:\n      service_name_matcher:\n        prefix: locations\n      path: /healthcheck\n    )EOF\";\n    envoy::config::core::v3::HealthCheck health_check_proto;\n    EXPECT_THROW_WITH_REGEX(TestUtility::validate(parseHealthCheckFromV3Yaml(yaml)), EnvoyException,\n                            \"Proto constraint validation failed.*value is required.*\");\n  }\n  {\n    const std::string yaml = R\"EOF(\n    timeout: 1s\n    interval: 1s\n    healthy_threshold: 1\n    http_health_check:\n      service_name_matcher:\n        prefix: locations\n      path: /healthcheck\n    )EOF\";\n    envoy::config::core::v3::HealthCheck health_check_proto;\n    EXPECT_THROW_WITH_REGEX(TestUtility::validate(parseHealthCheckFromV3Yaml(yaml)), EnvoyException,\n                            \"Proto constraint validation failed.*value is required.*\");\n  }\n}\n\n} // namespace\n} // namespace Upstream\n} // namespace Envoy\n"], "filenames": ["source/common/upstream/health_checker_impl.cc", "test/common/upstream/health_checker_impl_test.cc"], "buggy_code_start_loc": [818, 4737], "buggy_code_end_loc": [861, 4737], "fixing_code_start_loc": [818, 4738], "fixing_code_end_loc": [873, 4802], "type": "CWE-476", "message": "Envoy is a cloud-native high-performance proxy. Versions of envoy prior to 1.22.1 are subject to a segmentation fault in the GrpcHealthCheckerImpl. Envoy can perform various types of upstream health checking. One of them uses gRPC. Envoy also has a feature which can \u00e2\u20ac\u0153hold\u00e2\u20ac? (prevent removal) upstream hosts obtained via service discovery until configured active health checking fails. If an attacker controls an upstream host and also controls service discovery of that host (via DNS, the EDS API, etc.), an attacker can crash Envoy by forcing removal of the host from service discovery, and then failing the gRPC health check request. This will crash Envoy via a null pointer dereference. Users are advised to upgrade to resolve this vulnerability. Users unable to upgrade may disable gRPC health checking and/or replace it with a different health checking type as a mitigation.", "other": {"cve": {"id": "CVE-2022-29224", "sourceIdentifier": "security-advisories@github.com", "published": "2022-06-09T19:15:10.450", "lastModified": "2023-02-23T17:53:27.450", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "Envoy is a cloud-native high-performance proxy. Versions of envoy prior to 1.22.1 are subject to a segmentation fault in the GrpcHealthCheckerImpl. Envoy can perform various types of upstream health checking. One of them uses gRPC. Envoy also has a feature which can \u00e2\u20ac\u0153hold\u00e2\u20ac? (prevent removal) upstream hosts obtained via service discovery until configured active health checking fails. If an attacker controls an upstream host and also controls service discovery of that host (via DNS, the EDS API, etc.), an attacker can crash Envoy by forcing removal of the host from service discovery, and then failing the gRPC health check request. This will crash Envoy via a null pointer dereference. Users are advised to upgrade to resolve this vulnerability. Users unable to upgrade may disable gRPC health checking and/or replace it with a different health checking type as a mitigation."}, {"lang": "es", "value": "Envoy es un proxy de alto rendimiento nativo de la nube. Las versiones de Envoy anteriores a 1.22.1 est\u00e1n sujetas a un fallo de segmentaci\u00f3n en el GrpcHealthCheckerImpl. Envoy puede llevar a cabo varios tipos de comprobaci\u00f3n de la salud de los usuarios. Uno de ellos usa gRPC. Envoy tambi\u00e9n presenta una funci\u00f3n que puede \"retener\" (impedir la eliminaci\u00f3n) los hosts upstream obtenidos por medio de la detecci\u00f3n de servicios hasta que falle la comprobaci\u00f3n de salud activa configurada. Si un atacante controla un host upstream y tambi\u00e9n controla la detecci\u00f3n de servicios de ese host (a trav\u00e9s de DNS, la API EDS, etc.), un atacante puede bloquear Envoy al forzar la eliminaci\u00f3n del host de la detecci\u00f3n de servicios, y luego fallando la petici\u00f3n de comprobaci\u00f3n de salud gRPC. Esto bloquear\u00e1 Envoy por medio de una desreferencia de puntero null. Es recomendado a usuarios actualizar para resolver esta vulnerabilidad. Los usuarios que no puedan actualizar pueden deshabilitar la comprobaci\u00f3n de estado de gRPC y/o sustituirla por un tipo de comprobaci\u00f3n de estado diferente como medida de mitigaci\u00f3n"}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:H/PR:N/UI:N/S:U/C:N/I:N/A:H", "attackVector": "NETWORK", "attackComplexity": "HIGH", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 5.9, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 2.2, "impactScore": 3.6}, {"source": "security-advisories@github.com", "type": "Secondary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:H/PR:N/UI:N/S:U/C:N/I:N/A:H", "attackVector": "NETWORK", "attackComplexity": "HIGH", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 5.9, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 2.2, "impactScore": 3.6}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:N/AC:M/Au:N/C:N/I:N/A:P", "accessVector": "NETWORK", "accessComplexity": "MEDIUM", "authentication": "NONE", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "PARTIAL", "baseScore": 4.3}, "baseSeverity": "MEDIUM", "exploitabilityScore": 8.6, "impactScore": 2.9, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "security-advisories@github.com", "type": "Primary", "description": [{"lang": "en", "value": "CWE-476"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:envoyproxy:envoy:*:*:*:*:*:*:*:*", "versionEndExcluding": "1.22.1", "matchCriteriaId": "343FE7CD-C2BF-42EE-8384-AAD008BE690D"}]}]}], "references": [{"url": "https://github.com/envoyproxy/envoy/commit/9b1c3962172a972bc0359398af6daa3790bb59db", "source": "security-advisories@github.com", "tags": ["Patch"]}, {"url": "https://github.com/envoyproxy/envoy/security/advisories/GHSA-m4j9-86g3-8f49", "source": "security-advisories@github.com", "tags": ["Third Party Advisory"]}]}, "github_commit_url": "https://github.com/envoyproxy/envoy/commit/9b1c3962172a972bc0359398af6daa3790bb59db"}}
{"buggy_code": ["// SPDX-License-Identifier: GPL-2.0-only\n#include <linux/bitmap.h>\n#include <linux/bug.h>\n#include <linux/export.h>\n#include <linux/idr.h>\n#include <linux/slab.h>\n#include <linux/spinlock.h>\n#include <linux/xarray.h>\n\n/**\n * idr_alloc_u32() - Allocate an ID.\n * @idr: IDR handle.\n * @ptr: Pointer to be associated with the new ID.\n * @nextid: Pointer to an ID.\n * @max: The maximum ID to allocate (inclusive).\n * @gfp: Memory allocation flags.\n *\n * Allocates an unused ID in the range specified by @nextid and @max.\n * Note that @max is inclusive whereas the @end parameter to idr_alloc()\n * is exclusive.  The new ID is assigned to @nextid before the pointer\n * is inserted into the IDR, so if @nextid points into the object pointed\n * to by @ptr, a concurrent lookup will not find an uninitialised ID.\n *\n * The caller should provide their own locking to ensure that two\n * concurrent modifications to the IDR are not possible.  Read-only\n * accesses to the IDR may be done under the RCU read lock or may\n * exclude simultaneous writers.\n *\n * Return: 0 if an ID was allocated, -ENOMEM if memory allocation failed,\n * or -ENOSPC if no free IDs could be found.  If an error occurred,\n * @nextid is unchanged.\n */\nint idr_alloc_u32(struct idr *idr, void *ptr, u32 *nextid,\n\t\t\tunsigned long max, gfp_t gfp)\n{\n\tstruct radix_tree_iter iter;\n\tvoid __rcu **slot;\n\tunsigned int base = idr->idr_base;\n\tunsigned int id = *nextid;\n\n\tif (WARN_ON_ONCE(!(idr->idr_rt.xa_flags & ROOT_IS_IDR)))\n\t\tidr->idr_rt.xa_flags |= IDR_RT_MARKER;\n\n\tid = (id < base) ? 0 : id - base;\n\tradix_tree_iter_init(&iter, id);\n\tslot = idr_get_free(&idr->idr_rt, &iter, gfp, max - base);\n\tif (IS_ERR(slot))\n\t\treturn PTR_ERR(slot);\n\n\t*nextid = iter.index + base;\n\t/* there is a memory barrier inside radix_tree_iter_replace() */\n\tradix_tree_iter_replace(&idr->idr_rt, &iter, slot, ptr);\n\tradix_tree_iter_tag_clear(&idr->idr_rt, &iter, IDR_FREE);\n\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(idr_alloc_u32);\n\n/**\n * idr_alloc() - Allocate an ID.\n * @idr: IDR handle.\n * @ptr: Pointer to be associated with the new ID.\n * @start: The minimum ID (inclusive).\n * @end: The maximum ID (exclusive).\n * @gfp: Memory allocation flags.\n *\n * Allocates an unused ID in the range specified by @start and @end.  If\n * @end is <= 0, it is treated as one larger than %INT_MAX.  This allows\n * callers to use @start + N as @end as long as N is within integer range.\n *\n * The caller should provide their own locking to ensure that two\n * concurrent modifications to the IDR are not possible.  Read-only\n * accesses to the IDR may be done under the RCU read lock or may\n * exclude simultaneous writers.\n *\n * Return: The newly allocated ID, -ENOMEM if memory allocation failed,\n * or -ENOSPC if no free IDs could be found.\n */\nint idr_alloc(struct idr *idr, void *ptr, int start, int end, gfp_t gfp)\n{\n\tu32 id = start;\n\tint ret;\n\n\tif (WARN_ON_ONCE(start < 0))\n\t\treturn -EINVAL;\n\n\tret = idr_alloc_u32(idr, ptr, &id, end > 0 ? end - 1 : INT_MAX, gfp);\n\tif (ret)\n\t\treturn ret;\n\n\treturn id;\n}\nEXPORT_SYMBOL_GPL(idr_alloc);\n\n/**\n * idr_alloc_cyclic() - Allocate an ID cyclically.\n * @idr: IDR handle.\n * @ptr: Pointer to be associated with the new ID.\n * @start: The minimum ID (inclusive).\n * @end: The maximum ID (exclusive).\n * @gfp: Memory allocation flags.\n *\n * Allocates an unused ID in the range specified by @start and @end.  If\n * @end is <= 0, it is treated as one larger than %INT_MAX.  This allows\n * callers to use @start + N as @end as long as N is within integer range.\n * The search for an unused ID will start at the last ID allocated and will\n * wrap around to @start if no free IDs are found before reaching @end.\n *\n * The caller should provide their own locking to ensure that two\n * concurrent modifications to the IDR are not possible.  Read-only\n * accesses to the IDR may be done under the RCU read lock or may\n * exclude simultaneous writers.\n *\n * Return: The newly allocated ID, -ENOMEM if memory allocation failed,\n * or -ENOSPC if no free IDs could be found.\n */\nint idr_alloc_cyclic(struct idr *idr, void *ptr, int start, int end, gfp_t gfp)\n{\n\tu32 id = idr->idr_next;\n\tint err, max = end > 0 ? end - 1 : INT_MAX;\n\n\tif ((int)id < start)\n\t\tid = start;\n\n\terr = idr_alloc_u32(idr, ptr, &id, max, gfp);\n\tif ((err == -ENOSPC) && (id > start)) {\n\t\tid = start;\n\t\terr = idr_alloc_u32(idr, ptr, &id, max, gfp);\n\t}\n\tif (err)\n\t\treturn err;\n\n\tidr->idr_next = id + 1;\n\treturn id;\n}\nEXPORT_SYMBOL(idr_alloc_cyclic);\n\n/**\n * idr_remove() - Remove an ID from the IDR.\n * @idr: IDR handle.\n * @id: Pointer ID.\n *\n * Removes this ID from the IDR.  If the ID was not previously in the IDR,\n * this function returns %NULL.\n *\n * Since this function modifies the IDR, the caller should provide their\n * own locking to ensure that concurrent modification of the same IDR is\n * not possible.\n *\n * Return: The pointer formerly associated with this ID.\n */\nvoid *idr_remove(struct idr *idr, unsigned long id)\n{\n\treturn radix_tree_delete_item(&idr->idr_rt, id - idr->idr_base, NULL);\n}\nEXPORT_SYMBOL_GPL(idr_remove);\n\n/**\n * idr_find() - Return pointer for given ID.\n * @idr: IDR handle.\n * @id: Pointer ID.\n *\n * Looks up the pointer associated with this ID.  A %NULL pointer may\n * indicate that @id is not allocated or that the %NULL pointer was\n * associated with this ID.\n *\n * This function can be called under rcu_read_lock(), given that the leaf\n * pointers lifetimes are correctly managed.\n *\n * Return: The pointer associated with this ID.\n */\nvoid *idr_find(const struct idr *idr, unsigned long id)\n{\n\treturn radix_tree_lookup(&idr->idr_rt, id - idr->idr_base);\n}\nEXPORT_SYMBOL_GPL(idr_find);\n\n/**\n * idr_for_each() - Iterate through all stored pointers.\n * @idr: IDR handle.\n * @fn: Function to be called for each pointer.\n * @data: Data passed to callback function.\n *\n * The callback function will be called for each entry in @idr, passing\n * the ID, the entry and @data.\n *\n * If @fn returns anything other than %0, the iteration stops and that\n * value is returned from this function.\n *\n * idr_for_each() can be called concurrently with idr_alloc() and\n * idr_remove() if protected by RCU.  Newly added entries may not be\n * seen and deleted entries may be seen, but adding and removing entries\n * will not cause other entries to be skipped, nor spurious ones to be seen.\n */\nint idr_for_each(const struct idr *idr,\n\t\tint (*fn)(int id, void *p, void *data), void *data)\n{\n\tstruct radix_tree_iter iter;\n\tvoid __rcu **slot;\n\tint base = idr->idr_base;\n\n\tradix_tree_for_each_slot(slot, &idr->idr_rt, &iter, 0) {\n\t\tint ret;\n\t\tunsigned long id = iter.index + base;\n\n\t\tif (WARN_ON_ONCE(id > INT_MAX))\n\t\t\tbreak;\n\t\tret = fn(id, rcu_dereference_raw(*slot), data);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\treturn 0;\n}\nEXPORT_SYMBOL(idr_for_each);\n\n/**\n * idr_get_next_ul() - Find next populated entry.\n * @idr: IDR handle.\n * @nextid: Pointer to an ID.\n *\n * Returns the next populated entry in the tree with an ID greater than\n * or equal to the value pointed to by @nextid.  On exit, @nextid is updated\n * to the ID of the found value.  To use in a loop, the value pointed to by\n * nextid must be incremented by the user.\n */\nvoid *idr_get_next_ul(struct idr *idr, unsigned long *nextid)\n{\n\tstruct radix_tree_iter iter;\n\tvoid __rcu **slot;\n\tvoid *entry = NULL;\n\tunsigned long base = idr->idr_base;\n\tunsigned long id = *nextid;\n\n\tid = (id < base) ? 0 : id - base;\n\tradix_tree_for_each_slot(slot, &idr->idr_rt, &iter, id) {\n\t\tentry = rcu_dereference_raw(*slot);\n\t\tif (!entry)\n\t\t\tcontinue;\n\t\tif (!xa_is_internal(entry))\n\t\t\tbreak;\n\t\tif (slot != &idr->idr_rt.xa_head && !xa_is_retry(entry))\n\t\t\tbreak;\n\t\tslot = radix_tree_iter_retry(&iter);\n\t}\n\tif (!slot)\n\t\treturn NULL;\n\n\t*nextid = iter.index + base;\n\treturn entry;\n}\nEXPORT_SYMBOL(idr_get_next_ul);\n\n/**\n * idr_get_next() - Find next populated entry.\n * @idr: IDR handle.\n * @nextid: Pointer to an ID.\n *\n * Returns the next populated entry in the tree with an ID greater than\n * or equal to the value pointed to by @nextid.  On exit, @nextid is updated\n * to the ID of the found value.  To use in a loop, the value pointed to by\n * nextid must be incremented by the user.\n */\nvoid *idr_get_next(struct idr *idr, int *nextid)\n{\n\tunsigned long id = *nextid;\n\tvoid *entry = idr_get_next_ul(idr, &id);\n\n\tif (WARN_ON_ONCE(id > INT_MAX))\n\t\treturn NULL;\n\t*nextid = id;\n\treturn entry;\n}\nEXPORT_SYMBOL(idr_get_next);\n\n/**\n * idr_replace() - replace pointer for given ID.\n * @idr: IDR handle.\n * @ptr: New pointer to associate with the ID.\n * @id: ID to change.\n *\n * Replace the pointer registered with an ID and return the old value.\n * This function can be called under the RCU read lock concurrently with\n * idr_alloc() and idr_remove() (as long as the ID being removed is not\n * the one being replaced!).\n *\n * Returns: the old value on success.  %-ENOENT indicates that @id was not\n * found.  %-EINVAL indicates that @ptr was not valid.\n */\nvoid *idr_replace(struct idr *idr, void *ptr, unsigned long id)\n{\n\tstruct radix_tree_node *node;\n\tvoid __rcu **slot = NULL;\n\tvoid *entry;\n\n\tid -= idr->idr_base;\n\n\tentry = __radix_tree_lookup(&idr->idr_rt, id, &node, &slot);\n\tif (!slot || radix_tree_tag_get(&idr->idr_rt, id, IDR_FREE))\n\t\treturn ERR_PTR(-ENOENT);\n\n\t__radix_tree_replace(&idr->idr_rt, node, slot, ptr);\n\n\treturn entry;\n}\nEXPORT_SYMBOL(idr_replace);\n\n/**\n * DOC: IDA description\n *\n * The IDA is an ID allocator which does not provide the ability to\n * associate an ID with a pointer.  As such, it only needs to store one\n * bit per ID, and so is more space efficient than an IDR.  To use an IDA,\n * define it using DEFINE_IDA() (or embed a &struct ida in a data structure,\n * then initialise it using ida_init()).  To allocate a new ID, call\n * ida_alloc(), ida_alloc_min(), ida_alloc_max() or ida_alloc_range().\n * To free an ID, call ida_free().\n *\n * ida_destroy() can be used to dispose of an IDA without needing to\n * free the individual IDs in it.  You can use ida_is_empty() to find\n * out whether the IDA has any IDs currently allocated.\n *\n * The IDA handles its own locking.  It is safe to call any of the IDA\n * functions without synchronisation in your code.\n *\n * IDs are currently limited to the range [0-INT_MAX].  If this is an awkward\n * limitation, it should be quite straightforward to raise the maximum.\n */\n\n/*\n * Developer's notes:\n *\n * The IDA uses the functionality provided by the XArray to store bitmaps in\n * each entry.  The XA_FREE_MARK is only cleared when all bits in the bitmap\n * have been set.\n *\n * I considered telling the XArray that each slot is an order-10 node\n * and indexing by bit number, but the XArray can't allow a single multi-index\n * entry in the head, which would significantly increase memory consumption\n * for the IDA.  So instead we divide the index by the number of bits in the\n * leaf bitmap before doing a radix tree lookup.\n *\n * As an optimisation, if there are only a few low bits set in any given\n * leaf, instead of allocating a 128-byte bitmap, we store the bits\n * as a value entry.  Value entries never have the XA_FREE_MARK cleared\n * because we can always convert them into a bitmap entry.\n *\n * It would be possible to optimise further; once we've run out of a\n * single 128-byte bitmap, we currently switch to a 576-byte node, put\n * the 128-byte bitmap in the first entry and then start allocating extra\n * 128-byte entries.  We could instead use the 512 bytes of the node's\n * data as a bitmap before moving to that scheme.  I do not believe this\n * is a worthwhile optimisation; Rasmus Villemoes surveyed the current\n * users of the IDA and almost none of them use more than 1024 entries.\n * Those that do use more than the 8192 IDs that the 512 bytes would\n * provide.\n *\n * The IDA always uses a lock to alloc/free.  If we add a 'test_bit'\n * equivalent, it will still need locking.  Going to RCU lookup would require\n * using RCU to free bitmaps, and that's not trivial without embedding an\n * RCU head in the bitmap, which adds a 2-pointer overhead to each 128-byte\n * bitmap, which is excessive.\n */\n\n/**\n * ida_alloc_range() - Allocate an unused ID.\n * @ida: IDA handle.\n * @min: Lowest ID to allocate.\n * @max: Highest ID to allocate.\n * @gfp: Memory allocation flags.\n *\n * Allocate an ID between @min and @max, inclusive.  The allocated ID will\n * not exceed %INT_MAX, even if @max is larger.\n *\n * Context: Any context. It is safe to call this function without\n * locking in your code.\n * Return: The allocated ID, or %-ENOMEM if memory could not be allocated,\n * or %-ENOSPC if there are no free IDs.\n */\nint ida_alloc_range(struct ida *ida, unsigned int min, unsigned int max,\n\t\t\tgfp_t gfp)\n{\n\tXA_STATE(xas, &ida->xa, min / IDA_BITMAP_BITS);\n\tunsigned bit = min % IDA_BITMAP_BITS;\n\tunsigned long flags;\n\tstruct ida_bitmap *bitmap, *alloc = NULL;\n\n\tif ((int)min < 0)\n\t\treturn -ENOSPC;\n\n\tif ((int)max < 0)\n\t\tmax = INT_MAX;\n\nretry:\n\txas_lock_irqsave(&xas, flags);\nnext:\n\tbitmap = xas_find_marked(&xas, max / IDA_BITMAP_BITS, XA_FREE_MARK);\n\tif (xas.xa_index > min / IDA_BITMAP_BITS)\n\t\tbit = 0;\n\tif (xas.xa_index * IDA_BITMAP_BITS + bit > max)\n\t\tgoto nospc;\n\n\tif (xa_is_value(bitmap)) {\n\t\tunsigned long tmp = xa_to_value(bitmap);\n\n\t\tif (bit < BITS_PER_XA_VALUE) {\n\t\t\tbit = find_next_zero_bit(&tmp, BITS_PER_XA_VALUE, bit);\n\t\t\tif (xas.xa_index * IDA_BITMAP_BITS + bit > max)\n\t\t\t\tgoto nospc;\n\t\t\tif (bit < BITS_PER_XA_VALUE) {\n\t\t\t\ttmp |= 1UL << bit;\n\t\t\t\txas_store(&xas, xa_mk_value(tmp));\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t}\n\t\tbitmap = alloc;\n\t\tif (!bitmap)\n\t\t\tbitmap = kzalloc(sizeof(*bitmap), GFP_NOWAIT);\n\t\tif (!bitmap)\n\t\t\tgoto alloc;\n\t\tbitmap->bitmap[0] = tmp;\n\t\txas_store(&xas, bitmap);\n\t\tif (xas_error(&xas)) {\n\t\t\tbitmap->bitmap[0] = 0;\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\tif (bitmap) {\n\t\tbit = find_next_zero_bit(bitmap->bitmap, IDA_BITMAP_BITS, bit);\n\t\tif (xas.xa_index * IDA_BITMAP_BITS + bit > max)\n\t\t\tgoto nospc;\n\t\tif (bit == IDA_BITMAP_BITS)\n\t\t\tgoto next;\n\n\t\t__set_bit(bit, bitmap->bitmap);\n\t\tif (bitmap_full(bitmap->bitmap, IDA_BITMAP_BITS))\n\t\t\txas_clear_mark(&xas, XA_FREE_MARK);\n\t} else {\n\t\tif (bit < BITS_PER_XA_VALUE) {\n\t\t\tbitmap = xa_mk_value(1UL << bit);\n\t\t} else {\n\t\t\tbitmap = alloc;\n\t\t\tif (!bitmap)\n\t\t\t\tbitmap = kzalloc(sizeof(*bitmap), GFP_NOWAIT);\n\t\t\tif (!bitmap)\n\t\t\t\tgoto alloc;\n\t\t\t__set_bit(bit, bitmap->bitmap);\n\t\t}\n\t\txas_store(&xas, bitmap);\n\t}\nout:\n\txas_unlock_irqrestore(&xas, flags);\n\tif (xas_nomem(&xas, gfp)) {\n\t\txas.xa_index = min / IDA_BITMAP_BITS;\n\t\tbit = min % IDA_BITMAP_BITS;\n\t\tgoto retry;\n\t}\n\tif (bitmap != alloc)\n\t\tkfree(alloc);\n\tif (xas_error(&xas))\n\t\treturn xas_error(&xas);\n\treturn xas.xa_index * IDA_BITMAP_BITS + bit;\nalloc:\n\txas_unlock_irqrestore(&xas, flags);\n\talloc = kzalloc(sizeof(*bitmap), gfp);\n\tif (!alloc)\n\t\treturn -ENOMEM;\n\txas_set(&xas, min / IDA_BITMAP_BITS);\n\tbit = min % IDA_BITMAP_BITS;\n\tgoto retry;\nnospc:\n\txas_unlock_irqrestore(&xas, flags);\n\tkfree(alloc);\n\treturn -ENOSPC;\n}\nEXPORT_SYMBOL(ida_alloc_range);\n\n/**\n * ida_free() - Release an allocated ID.\n * @ida: IDA handle.\n * @id: Previously allocated ID.\n *\n * Context: Any context. It is safe to call this function without\n * locking in your code.\n */\nvoid ida_free(struct ida *ida, unsigned int id)\n{\n\tXA_STATE(xas, &ida->xa, id / IDA_BITMAP_BITS);\n\tunsigned bit = id % IDA_BITMAP_BITS;\n\tstruct ida_bitmap *bitmap;\n\tunsigned long flags;\n\n\tif ((int)id < 0)\n\t\treturn;\n\n\txas_lock_irqsave(&xas, flags);\n\tbitmap = xas_load(&xas);\n\n\tif (xa_is_value(bitmap)) {\n\t\tunsigned long v = xa_to_value(bitmap);\n\t\tif (bit >= BITS_PER_XA_VALUE)\n\t\t\tgoto err;\n\t\tif (!(v & (1UL << bit)))\n\t\t\tgoto err;\n\t\tv &= ~(1UL << bit);\n\t\tif (!v)\n\t\t\tgoto delete;\n\t\txas_store(&xas, xa_mk_value(v));\n\t} else {\n\t\tif (!test_bit(bit, bitmap->bitmap))\n\t\t\tgoto err;\n\t\t__clear_bit(bit, bitmap->bitmap);\n\t\txas_set_mark(&xas, XA_FREE_MARK);\n\t\tif (bitmap_empty(bitmap->bitmap, IDA_BITMAP_BITS)) {\n\t\t\tkfree(bitmap);\ndelete:\n\t\t\txas_store(&xas, NULL);\n\t\t}\n\t}\n\txas_unlock_irqrestore(&xas, flags);\n\treturn;\n err:\n\txas_unlock_irqrestore(&xas, flags);\n\tWARN(1, \"ida_free called for id=%d which is not allocated.\\n\", id);\n}\nEXPORT_SYMBOL(ida_free);\n\n/**\n * ida_destroy() - Free all IDs.\n * @ida: IDA handle.\n *\n * Calling this function frees all IDs and releases all resources used\n * by an IDA.  When this call returns, the IDA is empty and can be reused\n * or freed.  If the IDA is already empty, there is no need to call this\n * function.\n *\n * Context: Any context. It is safe to call this function without\n * locking in your code.\n */\nvoid ida_destroy(struct ida *ida)\n{\n\tXA_STATE(xas, &ida->xa, 0);\n\tstruct ida_bitmap *bitmap;\n\tunsigned long flags;\n\n\txas_lock_irqsave(&xas, flags);\n\txas_for_each(&xas, bitmap, ULONG_MAX) {\n\t\tif (!xa_is_value(bitmap))\n\t\t\tkfree(bitmap);\n\t\txas_store(&xas, NULL);\n\t}\n\txas_unlock_irqrestore(&xas, flags);\n}\nEXPORT_SYMBOL(ida_destroy);\n\n#ifndef __KERNEL__\nextern void xa_dump_index(unsigned long index, unsigned int shift);\n#define IDA_CHUNK_SHIFT\t\tilog2(IDA_BITMAP_BITS)\n\nstatic void ida_dump_entry(void *entry, unsigned long index)\n{\n\tunsigned long i;\n\n\tif (!entry)\n\t\treturn;\n\n\tif (xa_is_node(entry)) {\n\t\tstruct xa_node *node = xa_to_node(entry);\n\t\tunsigned int shift = node->shift + IDA_CHUNK_SHIFT +\n\t\t\tXA_CHUNK_SHIFT;\n\n\t\txa_dump_index(index * IDA_BITMAP_BITS, shift);\n\t\txa_dump_node(node);\n\t\tfor (i = 0; i < XA_CHUNK_SIZE; i++)\n\t\t\tida_dump_entry(node->slots[i],\n\t\t\t\t\tindex | (i << node->shift));\n\t} else if (xa_is_value(entry)) {\n\t\txa_dump_index(index * IDA_BITMAP_BITS, ilog2(BITS_PER_LONG));\n\t\tpr_cont(\"value: data %lx [%px]\\n\", xa_to_value(entry), entry);\n\t} else {\n\t\tstruct ida_bitmap *bitmap = entry;\n\n\t\txa_dump_index(index * IDA_BITMAP_BITS, IDA_CHUNK_SHIFT);\n\t\tpr_cont(\"bitmap: %p data\", bitmap);\n\t\tfor (i = 0; i < IDA_BITMAP_LONGS; i++)\n\t\t\tpr_cont(\" %lx\", bitmap->bitmap[i]);\n\t\tpr_cont(\"\\n\");\n\t}\n}\n\nstatic void ida_dump(struct ida *ida)\n{\n\tstruct xarray *xa = &ida->xa;\n\tpr_debug(\"ida: %p node %p free %d\\n\", ida, xa->xa_head,\n\t\t\t\txa->xa_flags >> ROOT_TAG_SHIFT);\n\tida_dump_entry(xa->xa_head, 0);\n}\n#endif\n", "// SPDX-License-Identifier: GPL-2.0+\n/*\n * test_ida.c: Test the IDA API\n * Copyright (c) 2016-2018 Microsoft Corporation\n * Copyright (c) 2018 Oracle Corporation\n * Author: Matthew Wilcox <willy@infradead.org>\n */\n\n#include <linux/idr.h>\n#include <linux/module.h>\n\nstatic unsigned int tests_run;\nstatic unsigned int tests_passed;\n\n#ifdef __KERNEL__\nvoid ida_dump(struct ida *ida) { }\n#endif\n#define IDA_BUG_ON(ida, x) do {\t\t\t\t\t\t\\\n\ttests_run++;\t\t\t\t\t\t\t\\\n\tif (x) {\t\t\t\t\t\t\t\\\n\t\tida_dump(ida);\t\t\t\t\t\t\\\n\t\tdump_stack();\t\t\t\t\t\t\\\n\t} else {\t\t\t\t\t\t\t\\\n\t\ttests_passed++;\t\t\t\t\t\t\\\n\t}\t\t\t\t\t\t\t\t\\\n} while (0)\n\n/*\n * Straightforward checks that allocating and freeing IDs work.\n */\nstatic void ida_check_alloc(struct ida *ida)\n{\n\tint i, id;\n\n\tfor (i = 0; i < 10000; i++)\n\t\tIDA_BUG_ON(ida, ida_alloc(ida, GFP_KERNEL) != i);\n\n\tida_free(ida, 20);\n\tida_free(ida, 21);\n\tfor (i = 0; i < 3; i++) {\n\t\tid = ida_alloc(ida, GFP_KERNEL);\n\t\tIDA_BUG_ON(ida, id < 0);\n\t\tif (i == 2)\n\t\t\tIDA_BUG_ON(ida, id != 10000);\n\t}\n\n\tfor (i = 0; i < 5000; i++)\n\t\tida_free(ida, i);\n\n\tIDA_BUG_ON(ida, ida_alloc_min(ida, 5000, GFP_KERNEL) != 10001);\n\tida_destroy(ida);\n\n\tIDA_BUG_ON(ida, !ida_is_empty(ida));\n}\n\n/* Destroy an IDA with a single entry at @base */\nstatic void ida_check_destroy_1(struct ida *ida, unsigned int base)\n{\n\tIDA_BUG_ON(ida, ida_alloc_min(ida, base, GFP_KERNEL) != base);\n\tIDA_BUG_ON(ida, ida_is_empty(ida));\n\tida_destroy(ida);\n\tIDA_BUG_ON(ida, !ida_is_empty(ida));\n}\n\n/* Check that ida_destroy and ida_is_empty work */\nstatic void ida_check_destroy(struct ida *ida)\n{\n\t/* Destroy an already-empty IDA */\n\tIDA_BUG_ON(ida, !ida_is_empty(ida));\n\tida_destroy(ida);\n\tIDA_BUG_ON(ida, !ida_is_empty(ida));\n\n\tida_check_destroy_1(ida, 0);\n\tida_check_destroy_1(ida, 1);\n\tida_check_destroy_1(ida, 1023);\n\tida_check_destroy_1(ida, 1024);\n\tida_check_destroy_1(ida, 12345678);\n}\n\n/*\n * Check what happens when we fill a leaf and then delete it.  This may\n * discover mishandling of IDR_FREE.\n */\nstatic void ida_check_leaf(struct ida *ida, unsigned int base)\n{\n\tunsigned long i;\n\n\tfor (i = 0; i < IDA_BITMAP_BITS; i++) {\n\t\tIDA_BUG_ON(ida, ida_alloc_min(ida, base, GFP_KERNEL) !=\n\t\t\t\tbase + i);\n\t}\n\n\tida_destroy(ida);\n\tIDA_BUG_ON(ida, !ida_is_empty(ida));\n\n\tIDA_BUG_ON(ida, ida_alloc(ida, GFP_KERNEL) != 0);\n\tIDA_BUG_ON(ida, ida_is_empty(ida));\n\tida_free(ida, 0);\n\tIDA_BUG_ON(ida, !ida_is_empty(ida));\n}\n\n/*\n * Check allocations up to and slightly above the maximum allowed (2^31-1) ID.\n * Allocating up to 2^31-1 should succeed, and then allocating the next one\n * should fail.\n */\nstatic void ida_check_max(struct ida *ida)\n{\n\tunsigned long i, j;\n\n\tfor (j = 1; j < 65537; j *= 2) {\n\t\tunsigned long base = (1UL << 31) - j;\n\t\tfor (i = 0; i < j; i++) {\n\t\t\tIDA_BUG_ON(ida, ida_alloc_min(ida, base, GFP_KERNEL) !=\n\t\t\t\t\tbase + i);\n\t\t}\n\t\tIDA_BUG_ON(ida, ida_alloc_min(ida, base, GFP_KERNEL) !=\n\t\t\t\t-ENOSPC);\n\t\tida_destroy(ida);\n\t\tIDA_BUG_ON(ida, !ida_is_empty(ida));\n\t}\n}\n\n/*\n * Check handling of conversions between exceptional entries and full bitmaps.\n */\nstatic void ida_check_conv(struct ida *ida)\n{\n\tunsigned long i;\n\n\tfor (i = 0; i < IDA_BITMAP_BITS * 2; i += IDA_BITMAP_BITS) {\n\t\tIDA_BUG_ON(ida, ida_alloc_min(ida, i + 1, GFP_KERNEL) != i + 1);\n\t\tIDA_BUG_ON(ida, ida_alloc_min(ida, i + BITS_PER_LONG,\n\t\t\t\t\tGFP_KERNEL) != i + BITS_PER_LONG);\n\t\tida_free(ida, i + 1);\n\t\tida_free(ida, i + BITS_PER_LONG);\n\t\tIDA_BUG_ON(ida, !ida_is_empty(ida));\n\t}\n\n\tfor (i = 0; i < IDA_BITMAP_BITS * 2; i++)\n\t\tIDA_BUG_ON(ida, ida_alloc(ida, GFP_KERNEL) != i);\n\tfor (i = IDA_BITMAP_BITS * 2; i > 0; i--)\n\t\tida_free(ida, i - 1);\n\tIDA_BUG_ON(ida, !ida_is_empty(ida));\n\n\tfor (i = 0; i < IDA_BITMAP_BITS + BITS_PER_LONG - 4; i++)\n\t\tIDA_BUG_ON(ida, ida_alloc(ida, GFP_KERNEL) != i);\n\tfor (i = IDA_BITMAP_BITS + BITS_PER_LONG - 4; i > 0; i--)\n\t\tida_free(ida, i - 1);\n\tIDA_BUG_ON(ida, !ida_is_empty(ida));\n}\n\nstatic DEFINE_IDA(ida);\n\nstatic int ida_checks(void)\n{\n\tIDA_BUG_ON(&ida, !ida_is_empty(&ida));\n\tida_check_alloc(&ida);\n\tida_check_destroy(&ida);\n\tida_check_leaf(&ida, 0);\n\tida_check_leaf(&ida, 1024);\n\tida_check_leaf(&ida, 1024 * 64);\n\tida_check_max(&ida);\n\tida_check_conv(&ida);\n\n\tprintk(\"IDA: %u of %u tests passed\\n\", tests_passed, tests_run);\n\treturn (tests_run != tests_passed) ? 0 : -EINVAL;\n}\n\nstatic void ida_exit(void)\n{\n}\n\nmodule_init(ida_checks);\nmodule_exit(ida_exit);\nMODULE_AUTHOR(\"Matthew Wilcox <willy@infradead.org>\");\nMODULE_LICENSE(\"GPL\");\n"], "fixing_code": ["// SPDX-License-Identifier: GPL-2.0-only\n#include <linux/bitmap.h>\n#include <linux/bug.h>\n#include <linux/export.h>\n#include <linux/idr.h>\n#include <linux/slab.h>\n#include <linux/spinlock.h>\n#include <linux/xarray.h>\n\n/**\n * idr_alloc_u32() - Allocate an ID.\n * @idr: IDR handle.\n * @ptr: Pointer to be associated with the new ID.\n * @nextid: Pointer to an ID.\n * @max: The maximum ID to allocate (inclusive).\n * @gfp: Memory allocation flags.\n *\n * Allocates an unused ID in the range specified by @nextid and @max.\n * Note that @max is inclusive whereas the @end parameter to idr_alloc()\n * is exclusive.  The new ID is assigned to @nextid before the pointer\n * is inserted into the IDR, so if @nextid points into the object pointed\n * to by @ptr, a concurrent lookup will not find an uninitialised ID.\n *\n * The caller should provide their own locking to ensure that two\n * concurrent modifications to the IDR are not possible.  Read-only\n * accesses to the IDR may be done under the RCU read lock or may\n * exclude simultaneous writers.\n *\n * Return: 0 if an ID was allocated, -ENOMEM if memory allocation failed,\n * or -ENOSPC if no free IDs could be found.  If an error occurred,\n * @nextid is unchanged.\n */\nint idr_alloc_u32(struct idr *idr, void *ptr, u32 *nextid,\n\t\t\tunsigned long max, gfp_t gfp)\n{\n\tstruct radix_tree_iter iter;\n\tvoid __rcu **slot;\n\tunsigned int base = idr->idr_base;\n\tunsigned int id = *nextid;\n\n\tif (WARN_ON_ONCE(!(idr->idr_rt.xa_flags & ROOT_IS_IDR)))\n\t\tidr->idr_rt.xa_flags |= IDR_RT_MARKER;\n\n\tid = (id < base) ? 0 : id - base;\n\tradix_tree_iter_init(&iter, id);\n\tslot = idr_get_free(&idr->idr_rt, &iter, gfp, max - base);\n\tif (IS_ERR(slot))\n\t\treturn PTR_ERR(slot);\n\n\t*nextid = iter.index + base;\n\t/* there is a memory barrier inside radix_tree_iter_replace() */\n\tradix_tree_iter_replace(&idr->idr_rt, &iter, slot, ptr);\n\tradix_tree_iter_tag_clear(&idr->idr_rt, &iter, IDR_FREE);\n\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(idr_alloc_u32);\n\n/**\n * idr_alloc() - Allocate an ID.\n * @idr: IDR handle.\n * @ptr: Pointer to be associated with the new ID.\n * @start: The minimum ID (inclusive).\n * @end: The maximum ID (exclusive).\n * @gfp: Memory allocation flags.\n *\n * Allocates an unused ID in the range specified by @start and @end.  If\n * @end is <= 0, it is treated as one larger than %INT_MAX.  This allows\n * callers to use @start + N as @end as long as N is within integer range.\n *\n * The caller should provide their own locking to ensure that two\n * concurrent modifications to the IDR are not possible.  Read-only\n * accesses to the IDR may be done under the RCU read lock or may\n * exclude simultaneous writers.\n *\n * Return: The newly allocated ID, -ENOMEM if memory allocation failed,\n * or -ENOSPC if no free IDs could be found.\n */\nint idr_alloc(struct idr *idr, void *ptr, int start, int end, gfp_t gfp)\n{\n\tu32 id = start;\n\tint ret;\n\n\tif (WARN_ON_ONCE(start < 0))\n\t\treturn -EINVAL;\n\n\tret = idr_alloc_u32(idr, ptr, &id, end > 0 ? end - 1 : INT_MAX, gfp);\n\tif (ret)\n\t\treturn ret;\n\n\treturn id;\n}\nEXPORT_SYMBOL_GPL(idr_alloc);\n\n/**\n * idr_alloc_cyclic() - Allocate an ID cyclically.\n * @idr: IDR handle.\n * @ptr: Pointer to be associated with the new ID.\n * @start: The minimum ID (inclusive).\n * @end: The maximum ID (exclusive).\n * @gfp: Memory allocation flags.\n *\n * Allocates an unused ID in the range specified by @start and @end.  If\n * @end is <= 0, it is treated as one larger than %INT_MAX.  This allows\n * callers to use @start + N as @end as long as N is within integer range.\n * The search for an unused ID will start at the last ID allocated and will\n * wrap around to @start if no free IDs are found before reaching @end.\n *\n * The caller should provide their own locking to ensure that two\n * concurrent modifications to the IDR are not possible.  Read-only\n * accesses to the IDR may be done under the RCU read lock or may\n * exclude simultaneous writers.\n *\n * Return: The newly allocated ID, -ENOMEM if memory allocation failed,\n * or -ENOSPC if no free IDs could be found.\n */\nint idr_alloc_cyclic(struct idr *idr, void *ptr, int start, int end, gfp_t gfp)\n{\n\tu32 id = idr->idr_next;\n\tint err, max = end > 0 ? end - 1 : INT_MAX;\n\n\tif ((int)id < start)\n\t\tid = start;\n\n\terr = idr_alloc_u32(idr, ptr, &id, max, gfp);\n\tif ((err == -ENOSPC) && (id > start)) {\n\t\tid = start;\n\t\terr = idr_alloc_u32(idr, ptr, &id, max, gfp);\n\t}\n\tif (err)\n\t\treturn err;\n\n\tidr->idr_next = id + 1;\n\treturn id;\n}\nEXPORT_SYMBOL(idr_alloc_cyclic);\n\n/**\n * idr_remove() - Remove an ID from the IDR.\n * @idr: IDR handle.\n * @id: Pointer ID.\n *\n * Removes this ID from the IDR.  If the ID was not previously in the IDR,\n * this function returns %NULL.\n *\n * Since this function modifies the IDR, the caller should provide their\n * own locking to ensure that concurrent modification of the same IDR is\n * not possible.\n *\n * Return: The pointer formerly associated with this ID.\n */\nvoid *idr_remove(struct idr *idr, unsigned long id)\n{\n\treturn radix_tree_delete_item(&idr->idr_rt, id - idr->idr_base, NULL);\n}\nEXPORT_SYMBOL_GPL(idr_remove);\n\n/**\n * idr_find() - Return pointer for given ID.\n * @idr: IDR handle.\n * @id: Pointer ID.\n *\n * Looks up the pointer associated with this ID.  A %NULL pointer may\n * indicate that @id is not allocated or that the %NULL pointer was\n * associated with this ID.\n *\n * This function can be called under rcu_read_lock(), given that the leaf\n * pointers lifetimes are correctly managed.\n *\n * Return: The pointer associated with this ID.\n */\nvoid *idr_find(const struct idr *idr, unsigned long id)\n{\n\treturn radix_tree_lookup(&idr->idr_rt, id - idr->idr_base);\n}\nEXPORT_SYMBOL_GPL(idr_find);\n\n/**\n * idr_for_each() - Iterate through all stored pointers.\n * @idr: IDR handle.\n * @fn: Function to be called for each pointer.\n * @data: Data passed to callback function.\n *\n * The callback function will be called for each entry in @idr, passing\n * the ID, the entry and @data.\n *\n * If @fn returns anything other than %0, the iteration stops and that\n * value is returned from this function.\n *\n * idr_for_each() can be called concurrently with idr_alloc() and\n * idr_remove() if protected by RCU.  Newly added entries may not be\n * seen and deleted entries may be seen, but adding and removing entries\n * will not cause other entries to be skipped, nor spurious ones to be seen.\n */\nint idr_for_each(const struct idr *idr,\n\t\tint (*fn)(int id, void *p, void *data), void *data)\n{\n\tstruct radix_tree_iter iter;\n\tvoid __rcu **slot;\n\tint base = idr->idr_base;\n\n\tradix_tree_for_each_slot(slot, &idr->idr_rt, &iter, 0) {\n\t\tint ret;\n\t\tunsigned long id = iter.index + base;\n\n\t\tif (WARN_ON_ONCE(id > INT_MAX))\n\t\t\tbreak;\n\t\tret = fn(id, rcu_dereference_raw(*slot), data);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\treturn 0;\n}\nEXPORT_SYMBOL(idr_for_each);\n\n/**\n * idr_get_next_ul() - Find next populated entry.\n * @idr: IDR handle.\n * @nextid: Pointer to an ID.\n *\n * Returns the next populated entry in the tree with an ID greater than\n * or equal to the value pointed to by @nextid.  On exit, @nextid is updated\n * to the ID of the found value.  To use in a loop, the value pointed to by\n * nextid must be incremented by the user.\n */\nvoid *idr_get_next_ul(struct idr *idr, unsigned long *nextid)\n{\n\tstruct radix_tree_iter iter;\n\tvoid __rcu **slot;\n\tvoid *entry = NULL;\n\tunsigned long base = idr->idr_base;\n\tunsigned long id = *nextid;\n\n\tid = (id < base) ? 0 : id - base;\n\tradix_tree_for_each_slot(slot, &idr->idr_rt, &iter, id) {\n\t\tentry = rcu_dereference_raw(*slot);\n\t\tif (!entry)\n\t\t\tcontinue;\n\t\tif (!xa_is_internal(entry))\n\t\t\tbreak;\n\t\tif (slot != &idr->idr_rt.xa_head && !xa_is_retry(entry))\n\t\t\tbreak;\n\t\tslot = radix_tree_iter_retry(&iter);\n\t}\n\tif (!slot)\n\t\treturn NULL;\n\n\t*nextid = iter.index + base;\n\treturn entry;\n}\nEXPORT_SYMBOL(idr_get_next_ul);\n\n/**\n * idr_get_next() - Find next populated entry.\n * @idr: IDR handle.\n * @nextid: Pointer to an ID.\n *\n * Returns the next populated entry in the tree with an ID greater than\n * or equal to the value pointed to by @nextid.  On exit, @nextid is updated\n * to the ID of the found value.  To use in a loop, the value pointed to by\n * nextid must be incremented by the user.\n */\nvoid *idr_get_next(struct idr *idr, int *nextid)\n{\n\tunsigned long id = *nextid;\n\tvoid *entry = idr_get_next_ul(idr, &id);\n\n\tif (WARN_ON_ONCE(id > INT_MAX))\n\t\treturn NULL;\n\t*nextid = id;\n\treturn entry;\n}\nEXPORT_SYMBOL(idr_get_next);\n\n/**\n * idr_replace() - replace pointer for given ID.\n * @idr: IDR handle.\n * @ptr: New pointer to associate with the ID.\n * @id: ID to change.\n *\n * Replace the pointer registered with an ID and return the old value.\n * This function can be called under the RCU read lock concurrently with\n * idr_alloc() and idr_remove() (as long as the ID being removed is not\n * the one being replaced!).\n *\n * Returns: the old value on success.  %-ENOENT indicates that @id was not\n * found.  %-EINVAL indicates that @ptr was not valid.\n */\nvoid *idr_replace(struct idr *idr, void *ptr, unsigned long id)\n{\n\tstruct radix_tree_node *node;\n\tvoid __rcu **slot = NULL;\n\tvoid *entry;\n\n\tid -= idr->idr_base;\n\n\tentry = __radix_tree_lookup(&idr->idr_rt, id, &node, &slot);\n\tif (!slot || radix_tree_tag_get(&idr->idr_rt, id, IDR_FREE))\n\t\treturn ERR_PTR(-ENOENT);\n\n\t__radix_tree_replace(&idr->idr_rt, node, slot, ptr);\n\n\treturn entry;\n}\nEXPORT_SYMBOL(idr_replace);\n\n/**\n * DOC: IDA description\n *\n * The IDA is an ID allocator which does not provide the ability to\n * associate an ID with a pointer.  As such, it only needs to store one\n * bit per ID, and so is more space efficient than an IDR.  To use an IDA,\n * define it using DEFINE_IDA() (or embed a &struct ida in a data structure,\n * then initialise it using ida_init()).  To allocate a new ID, call\n * ida_alloc(), ida_alloc_min(), ida_alloc_max() or ida_alloc_range().\n * To free an ID, call ida_free().\n *\n * ida_destroy() can be used to dispose of an IDA without needing to\n * free the individual IDs in it.  You can use ida_is_empty() to find\n * out whether the IDA has any IDs currently allocated.\n *\n * The IDA handles its own locking.  It is safe to call any of the IDA\n * functions without synchronisation in your code.\n *\n * IDs are currently limited to the range [0-INT_MAX].  If this is an awkward\n * limitation, it should be quite straightforward to raise the maximum.\n */\n\n/*\n * Developer's notes:\n *\n * The IDA uses the functionality provided by the XArray to store bitmaps in\n * each entry.  The XA_FREE_MARK is only cleared when all bits in the bitmap\n * have been set.\n *\n * I considered telling the XArray that each slot is an order-10 node\n * and indexing by bit number, but the XArray can't allow a single multi-index\n * entry in the head, which would significantly increase memory consumption\n * for the IDA.  So instead we divide the index by the number of bits in the\n * leaf bitmap before doing a radix tree lookup.\n *\n * As an optimisation, if there are only a few low bits set in any given\n * leaf, instead of allocating a 128-byte bitmap, we store the bits\n * as a value entry.  Value entries never have the XA_FREE_MARK cleared\n * because we can always convert them into a bitmap entry.\n *\n * It would be possible to optimise further; once we've run out of a\n * single 128-byte bitmap, we currently switch to a 576-byte node, put\n * the 128-byte bitmap in the first entry and then start allocating extra\n * 128-byte entries.  We could instead use the 512 bytes of the node's\n * data as a bitmap before moving to that scheme.  I do not believe this\n * is a worthwhile optimisation; Rasmus Villemoes surveyed the current\n * users of the IDA and almost none of them use more than 1024 entries.\n * Those that do use more than the 8192 IDs that the 512 bytes would\n * provide.\n *\n * The IDA always uses a lock to alloc/free.  If we add a 'test_bit'\n * equivalent, it will still need locking.  Going to RCU lookup would require\n * using RCU to free bitmaps, and that's not trivial without embedding an\n * RCU head in the bitmap, which adds a 2-pointer overhead to each 128-byte\n * bitmap, which is excessive.\n */\n\n/**\n * ida_alloc_range() - Allocate an unused ID.\n * @ida: IDA handle.\n * @min: Lowest ID to allocate.\n * @max: Highest ID to allocate.\n * @gfp: Memory allocation flags.\n *\n * Allocate an ID between @min and @max, inclusive.  The allocated ID will\n * not exceed %INT_MAX, even if @max is larger.\n *\n * Context: Any context. It is safe to call this function without\n * locking in your code.\n * Return: The allocated ID, or %-ENOMEM if memory could not be allocated,\n * or %-ENOSPC if there are no free IDs.\n */\nint ida_alloc_range(struct ida *ida, unsigned int min, unsigned int max,\n\t\t\tgfp_t gfp)\n{\n\tXA_STATE(xas, &ida->xa, min / IDA_BITMAP_BITS);\n\tunsigned bit = min % IDA_BITMAP_BITS;\n\tunsigned long flags;\n\tstruct ida_bitmap *bitmap, *alloc = NULL;\n\n\tif ((int)min < 0)\n\t\treturn -ENOSPC;\n\n\tif ((int)max < 0)\n\t\tmax = INT_MAX;\n\nretry:\n\txas_lock_irqsave(&xas, flags);\nnext:\n\tbitmap = xas_find_marked(&xas, max / IDA_BITMAP_BITS, XA_FREE_MARK);\n\tif (xas.xa_index > min / IDA_BITMAP_BITS)\n\t\tbit = 0;\n\tif (xas.xa_index * IDA_BITMAP_BITS + bit > max)\n\t\tgoto nospc;\n\n\tif (xa_is_value(bitmap)) {\n\t\tunsigned long tmp = xa_to_value(bitmap);\n\n\t\tif (bit < BITS_PER_XA_VALUE) {\n\t\t\tbit = find_next_zero_bit(&tmp, BITS_PER_XA_VALUE, bit);\n\t\t\tif (xas.xa_index * IDA_BITMAP_BITS + bit > max)\n\t\t\t\tgoto nospc;\n\t\t\tif (bit < BITS_PER_XA_VALUE) {\n\t\t\t\ttmp |= 1UL << bit;\n\t\t\t\txas_store(&xas, xa_mk_value(tmp));\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t}\n\t\tbitmap = alloc;\n\t\tif (!bitmap)\n\t\t\tbitmap = kzalloc(sizeof(*bitmap), GFP_NOWAIT);\n\t\tif (!bitmap)\n\t\t\tgoto alloc;\n\t\tbitmap->bitmap[0] = tmp;\n\t\txas_store(&xas, bitmap);\n\t\tif (xas_error(&xas)) {\n\t\t\tbitmap->bitmap[0] = 0;\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\tif (bitmap) {\n\t\tbit = find_next_zero_bit(bitmap->bitmap, IDA_BITMAP_BITS, bit);\n\t\tif (xas.xa_index * IDA_BITMAP_BITS + bit > max)\n\t\t\tgoto nospc;\n\t\tif (bit == IDA_BITMAP_BITS)\n\t\t\tgoto next;\n\n\t\t__set_bit(bit, bitmap->bitmap);\n\t\tif (bitmap_full(bitmap->bitmap, IDA_BITMAP_BITS))\n\t\t\txas_clear_mark(&xas, XA_FREE_MARK);\n\t} else {\n\t\tif (bit < BITS_PER_XA_VALUE) {\n\t\t\tbitmap = xa_mk_value(1UL << bit);\n\t\t} else {\n\t\t\tbitmap = alloc;\n\t\t\tif (!bitmap)\n\t\t\t\tbitmap = kzalloc(sizeof(*bitmap), GFP_NOWAIT);\n\t\t\tif (!bitmap)\n\t\t\t\tgoto alloc;\n\t\t\t__set_bit(bit, bitmap->bitmap);\n\t\t}\n\t\txas_store(&xas, bitmap);\n\t}\nout:\n\txas_unlock_irqrestore(&xas, flags);\n\tif (xas_nomem(&xas, gfp)) {\n\t\txas.xa_index = min / IDA_BITMAP_BITS;\n\t\tbit = min % IDA_BITMAP_BITS;\n\t\tgoto retry;\n\t}\n\tif (bitmap != alloc)\n\t\tkfree(alloc);\n\tif (xas_error(&xas))\n\t\treturn xas_error(&xas);\n\treturn xas.xa_index * IDA_BITMAP_BITS + bit;\nalloc:\n\txas_unlock_irqrestore(&xas, flags);\n\talloc = kzalloc(sizeof(*bitmap), gfp);\n\tif (!alloc)\n\t\treturn -ENOMEM;\n\txas_set(&xas, min / IDA_BITMAP_BITS);\n\tbit = min % IDA_BITMAP_BITS;\n\tgoto retry;\nnospc:\n\txas_unlock_irqrestore(&xas, flags);\n\tkfree(alloc);\n\treturn -ENOSPC;\n}\nEXPORT_SYMBOL(ida_alloc_range);\n\n/**\n * ida_free() - Release an allocated ID.\n * @ida: IDA handle.\n * @id: Previously allocated ID.\n *\n * Context: Any context. It is safe to call this function without\n * locking in your code.\n */\nvoid ida_free(struct ida *ida, unsigned int id)\n{\n\tXA_STATE(xas, &ida->xa, id / IDA_BITMAP_BITS);\n\tunsigned bit = id % IDA_BITMAP_BITS;\n\tstruct ida_bitmap *bitmap;\n\tunsigned long flags;\n\n\tif ((int)id < 0)\n\t\treturn;\n\n\txas_lock_irqsave(&xas, flags);\n\tbitmap = xas_load(&xas);\n\n\tif (xa_is_value(bitmap)) {\n\t\tunsigned long v = xa_to_value(bitmap);\n\t\tif (bit >= BITS_PER_XA_VALUE)\n\t\t\tgoto err;\n\t\tif (!(v & (1UL << bit)))\n\t\t\tgoto err;\n\t\tv &= ~(1UL << bit);\n\t\tif (!v)\n\t\t\tgoto delete;\n\t\txas_store(&xas, xa_mk_value(v));\n\t} else {\n\t\tif (!bitmap || !test_bit(bit, bitmap->bitmap))\n\t\t\tgoto err;\n\t\t__clear_bit(bit, bitmap->bitmap);\n\t\txas_set_mark(&xas, XA_FREE_MARK);\n\t\tif (bitmap_empty(bitmap->bitmap, IDA_BITMAP_BITS)) {\n\t\t\tkfree(bitmap);\ndelete:\n\t\t\txas_store(&xas, NULL);\n\t\t}\n\t}\n\txas_unlock_irqrestore(&xas, flags);\n\treturn;\n err:\n\txas_unlock_irqrestore(&xas, flags);\n\tWARN(1, \"ida_free called for id=%d which is not allocated.\\n\", id);\n}\nEXPORT_SYMBOL(ida_free);\n\n/**\n * ida_destroy() - Free all IDs.\n * @ida: IDA handle.\n *\n * Calling this function frees all IDs and releases all resources used\n * by an IDA.  When this call returns, the IDA is empty and can be reused\n * or freed.  If the IDA is already empty, there is no need to call this\n * function.\n *\n * Context: Any context. It is safe to call this function without\n * locking in your code.\n */\nvoid ida_destroy(struct ida *ida)\n{\n\tXA_STATE(xas, &ida->xa, 0);\n\tstruct ida_bitmap *bitmap;\n\tunsigned long flags;\n\n\txas_lock_irqsave(&xas, flags);\n\txas_for_each(&xas, bitmap, ULONG_MAX) {\n\t\tif (!xa_is_value(bitmap))\n\t\t\tkfree(bitmap);\n\t\txas_store(&xas, NULL);\n\t}\n\txas_unlock_irqrestore(&xas, flags);\n}\nEXPORT_SYMBOL(ida_destroy);\n\n#ifndef __KERNEL__\nextern void xa_dump_index(unsigned long index, unsigned int shift);\n#define IDA_CHUNK_SHIFT\t\tilog2(IDA_BITMAP_BITS)\n\nstatic void ida_dump_entry(void *entry, unsigned long index)\n{\n\tunsigned long i;\n\n\tif (!entry)\n\t\treturn;\n\n\tif (xa_is_node(entry)) {\n\t\tstruct xa_node *node = xa_to_node(entry);\n\t\tunsigned int shift = node->shift + IDA_CHUNK_SHIFT +\n\t\t\tXA_CHUNK_SHIFT;\n\n\t\txa_dump_index(index * IDA_BITMAP_BITS, shift);\n\t\txa_dump_node(node);\n\t\tfor (i = 0; i < XA_CHUNK_SIZE; i++)\n\t\t\tida_dump_entry(node->slots[i],\n\t\t\t\t\tindex | (i << node->shift));\n\t} else if (xa_is_value(entry)) {\n\t\txa_dump_index(index * IDA_BITMAP_BITS, ilog2(BITS_PER_LONG));\n\t\tpr_cont(\"value: data %lx [%px]\\n\", xa_to_value(entry), entry);\n\t} else {\n\t\tstruct ida_bitmap *bitmap = entry;\n\n\t\txa_dump_index(index * IDA_BITMAP_BITS, IDA_CHUNK_SHIFT);\n\t\tpr_cont(\"bitmap: %p data\", bitmap);\n\t\tfor (i = 0; i < IDA_BITMAP_LONGS; i++)\n\t\t\tpr_cont(\" %lx\", bitmap->bitmap[i]);\n\t\tpr_cont(\"\\n\");\n\t}\n}\n\nstatic void ida_dump(struct ida *ida)\n{\n\tstruct xarray *xa = &ida->xa;\n\tpr_debug(\"ida: %p node %p free %d\\n\", ida, xa->xa_head,\n\t\t\t\txa->xa_flags >> ROOT_TAG_SHIFT);\n\tida_dump_entry(xa->xa_head, 0);\n}\n#endif\n", "// SPDX-License-Identifier: GPL-2.0+\n/*\n * test_ida.c: Test the IDA API\n * Copyright (c) 2016-2018 Microsoft Corporation\n * Copyright (c) 2018 Oracle Corporation\n * Author: Matthew Wilcox <willy@infradead.org>\n */\n\n#include <linux/idr.h>\n#include <linux/module.h>\n\nstatic unsigned int tests_run;\nstatic unsigned int tests_passed;\n\n#ifdef __KERNEL__\nvoid ida_dump(struct ida *ida) { }\n#endif\n#define IDA_BUG_ON(ida, x) do {\t\t\t\t\t\t\\\n\ttests_run++;\t\t\t\t\t\t\t\\\n\tif (x) {\t\t\t\t\t\t\t\\\n\t\tida_dump(ida);\t\t\t\t\t\t\\\n\t\tdump_stack();\t\t\t\t\t\t\\\n\t} else {\t\t\t\t\t\t\t\\\n\t\ttests_passed++;\t\t\t\t\t\t\\\n\t}\t\t\t\t\t\t\t\t\\\n} while (0)\n\n/*\n * Straightforward checks that allocating and freeing IDs work.\n */\nstatic void ida_check_alloc(struct ida *ida)\n{\n\tint i, id;\n\n\tfor (i = 0; i < 10000; i++)\n\t\tIDA_BUG_ON(ida, ida_alloc(ida, GFP_KERNEL) != i);\n\n\tida_free(ida, 20);\n\tida_free(ida, 21);\n\tfor (i = 0; i < 3; i++) {\n\t\tid = ida_alloc(ida, GFP_KERNEL);\n\t\tIDA_BUG_ON(ida, id < 0);\n\t\tif (i == 2)\n\t\t\tIDA_BUG_ON(ida, id != 10000);\n\t}\n\n\tfor (i = 0; i < 5000; i++)\n\t\tida_free(ida, i);\n\n\tIDA_BUG_ON(ida, ida_alloc_min(ida, 5000, GFP_KERNEL) != 10001);\n\tida_destroy(ida);\n\n\tIDA_BUG_ON(ida, !ida_is_empty(ida));\n}\n\n/* Destroy an IDA with a single entry at @base */\nstatic void ida_check_destroy_1(struct ida *ida, unsigned int base)\n{\n\tIDA_BUG_ON(ida, ida_alloc_min(ida, base, GFP_KERNEL) != base);\n\tIDA_BUG_ON(ida, ida_is_empty(ida));\n\tida_destroy(ida);\n\tIDA_BUG_ON(ida, !ida_is_empty(ida));\n}\n\n/* Check that ida_destroy and ida_is_empty work */\nstatic void ida_check_destroy(struct ida *ida)\n{\n\t/* Destroy an already-empty IDA */\n\tIDA_BUG_ON(ida, !ida_is_empty(ida));\n\tida_destroy(ida);\n\tIDA_BUG_ON(ida, !ida_is_empty(ida));\n\n\tida_check_destroy_1(ida, 0);\n\tida_check_destroy_1(ida, 1);\n\tida_check_destroy_1(ida, 1023);\n\tida_check_destroy_1(ida, 1024);\n\tida_check_destroy_1(ida, 12345678);\n}\n\n/*\n * Check what happens when we fill a leaf and then delete it.  This may\n * discover mishandling of IDR_FREE.\n */\nstatic void ida_check_leaf(struct ida *ida, unsigned int base)\n{\n\tunsigned long i;\n\n\tfor (i = 0; i < IDA_BITMAP_BITS; i++) {\n\t\tIDA_BUG_ON(ida, ida_alloc_min(ida, base, GFP_KERNEL) !=\n\t\t\t\tbase + i);\n\t}\n\n\tida_destroy(ida);\n\tIDA_BUG_ON(ida, !ida_is_empty(ida));\n\n\tIDA_BUG_ON(ida, ida_alloc(ida, GFP_KERNEL) != 0);\n\tIDA_BUG_ON(ida, ida_is_empty(ida));\n\tida_free(ida, 0);\n\tIDA_BUG_ON(ida, !ida_is_empty(ida));\n}\n\n/*\n * Check allocations up to and slightly above the maximum allowed (2^31-1) ID.\n * Allocating up to 2^31-1 should succeed, and then allocating the next one\n * should fail.\n */\nstatic void ida_check_max(struct ida *ida)\n{\n\tunsigned long i, j;\n\n\tfor (j = 1; j < 65537; j *= 2) {\n\t\tunsigned long base = (1UL << 31) - j;\n\t\tfor (i = 0; i < j; i++) {\n\t\t\tIDA_BUG_ON(ida, ida_alloc_min(ida, base, GFP_KERNEL) !=\n\t\t\t\t\tbase + i);\n\t\t}\n\t\tIDA_BUG_ON(ida, ida_alloc_min(ida, base, GFP_KERNEL) !=\n\t\t\t\t-ENOSPC);\n\t\tida_destroy(ida);\n\t\tIDA_BUG_ON(ida, !ida_is_empty(ida));\n\t}\n}\n\n/*\n * Check handling of conversions between exceptional entries and full bitmaps.\n */\nstatic void ida_check_conv(struct ida *ida)\n{\n\tunsigned long i;\n\n\tfor (i = 0; i < IDA_BITMAP_BITS * 2; i += IDA_BITMAP_BITS) {\n\t\tIDA_BUG_ON(ida, ida_alloc_min(ida, i + 1, GFP_KERNEL) != i + 1);\n\t\tIDA_BUG_ON(ida, ida_alloc_min(ida, i + BITS_PER_LONG,\n\t\t\t\t\tGFP_KERNEL) != i + BITS_PER_LONG);\n\t\tida_free(ida, i + 1);\n\t\tida_free(ida, i + BITS_PER_LONG);\n\t\tIDA_BUG_ON(ida, !ida_is_empty(ida));\n\t}\n\n\tfor (i = 0; i < IDA_BITMAP_BITS * 2; i++)\n\t\tIDA_BUG_ON(ida, ida_alloc(ida, GFP_KERNEL) != i);\n\tfor (i = IDA_BITMAP_BITS * 2; i > 0; i--)\n\t\tida_free(ida, i - 1);\n\tIDA_BUG_ON(ida, !ida_is_empty(ida));\n\n\tfor (i = 0; i < IDA_BITMAP_BITS + BITS_PER_LONG - 4; i++)\n\t\tIDA_BUG_ON(ida, ida_alloc(ida, GFP_KERNEL) != i);\n\tfor (i = IDA_BITMAP_BITS + BITS_PER_LONG - 4; i > 0; i--)\n\t\tida_free(ida, i - 1);\n\tIDA_BUG_ON(ida, !ida_is_empty(ida));\n}\n\n/*\n * Check various situations where we attempt to free an ID we don't own.\n */\nstatic void ida_check_bad_free(struct ida *ida)\n{\n\tunsigned long i;\n\n\tprintk(\"vvv Ignore \\\"not allocated\\\" warnings\\n\");\n\t/* IDA is empty; all of these will fail */\n\tida_free(ida, 0);\n\tfor (i = 0; i < 31; i++)\n\t\tida_free(ida, 1 << i);\n\n\t/* IDA contains a single value entry */\n\tIDA_BUG_ON(ida, ida_alloc_min(ida, 3, GFP_KERNEL) != 3);\n\tida_free(ida, 0);\n\tfor (i = 0; i < 31; i++)\n\t\tida_free(ida, 1 << i);\n\n\t/* IDA contains a single bitmap */\n\tIDA_BUG_ON(ida, ida_alloc_min(ida, 1023, GFP_KERNEL) != 1023);\n\tida_free(ida, 0);\n\tfor (i = 0; i < 31; i++)\n\t\tida_free(ida, 1 << i);\n\n\t/* IDA contains a tree */\n\tIDA_BUG_ON(ida, ida_alloc_min(ida, (1 << 20) - 1, GFP_KERNEL) != (1 << 20) - 1);\n\tida_free(ida, 0);\n\tfor (i = 0; i < 31; i++)\n\t\tida_free(ida, 1 << i);\n\tprintk(\"^^^ \\\"not allocated\\\" warnings over\\n\");\n\n\tida_free(ida, 3);\n\tida_free(ida, 1023);\n\tida_free(ida, (1 << 20) - 1);\n\n\tIDA_BUG_ON(ida, !ida_is_empty(ida));\n}\n\nstatic DEFINE_IDA(ida);\n\nstatic int ida_checks(void)\n{\n\tIDA_BUG_ON(&ida, !ida_is_empty(&ida));\n\tida_check_alloc(&ida);\n\tida_check_destroy(&ida);\n\tida_check_leaf(&ida, 0);\n\tida_check_leaf(&ida, 1024);\n\tida_check_leaf(&ida, 1024 * 64);\n\tida_check_max(&ida);\n\tida_check_conv(&ida);\n\tida_check_bad_free(&ida);\n\n\tprintk(\"IDA: %u of %u tests passed\\n\", tests_passed, tests_run);\n\treturn (tests_run != tests_passed) ? 0 : -EINVAL;\n}\n\nstatic void ida_exit(void)\n{\n}\n\nmodule_init(ida_checks);\nmodule_exit(ida_exit);\nMODULE_AUTHOR(\"Matthew Wilcox <willy@infradead.org>\");\nMODULE_LICENSE(\"GPL\");\n"], "filenames": ["lib/idr.c", "lib/test_ida.c"], "buggy_code_start_loc": [511, 152], "buggy_code_end_loc": [512, 164], "fixing_code_start_loc": [511, 153], "fixing_code_end_loc": [512, 205], "type": "CWE-476", "message": "A Null pointer dereference problem was found in ida_free in lib/idr.c in the Linux Kernel. This issue may allow an attacker using this library to cause a denial of service problem due to a missing check at a function return.", "other": {"cve": {"id": "CVE-2023-6915", "sourceIdentifier": "secalert@redhat.com", "published": "2024-01-15T10:15:26.627", "lastModified": "2024-02-06T19:58:45.947", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "A Null pointer dereference problem was found in ida_free in lib/idr.c in the Linux Kernel. This issue may allow an attacker using this library to cause a denial of service problem due to a missing check at a function return."}, {"lang": "es", "value": "Se encontr\u00f3 un problema de desreferencia de puntero null en ida_free en lib/idr.c en el kernel de Linux. Este problema puede permitir que un atacante que utilice esta librer\u00eda cause un problema de denegaci\u00f3n de servicio debido a una verificaci\u00f3n faltante en el retorno de una funci\u00f3n."}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:L/AC:L/PR:L/UI:N/S:U/C:N/I:N/A:H", "attackVector": "LOCAL", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 5.5, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 1.8, "impactScore": 3.6}, {"source": "secalert@redhat.com", "type": "Secondary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:L/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H", "attackVector": "LOCAL", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 6.2, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 2.5, "impactScore": 3.6}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-476"}]}, {"source": "secalert@redhat.com", "type": "Secondary", "description": [{"lang": "en", "value": "CWE-476"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionEndExcluding": "6.7", "matchCriteriaId": "668F5607-E136-4E8E-86F2-316E9DC41ADC"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:6.7:rc7:*:*:*:*:*:*", "matchCriteriaId": "81A7ABCB-0807-4AA2-8F4E-75E38D2E3FD4"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:6.7:rc8:*:*:*:*:*:*", "matchCriteriaId": "B01471D6-2DB4-4AF2-8BE0-B5082B4B9253"}]}]}, {"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:redhat:enterprise_linux:8.0:*:*:*:*:*:*:*", "matchCriteriaId": "F4CFF558-3C47-480D-A2F0-BABF26042943"}, {"vulnerable": true, "criteria": "cpe:2.3:o:redhat:enterprise_linux:9.0:*:*:*:*:*:*:*", "matchCriteriaId": "7F6FB57C-2BC7-487C-96DD-132683AEB35D"}]}]}], "references": [{"url": "https://access.redhat.com/security/cve/CVE-2023-6915", "source": "secalert@redhat.com", "tags": ["Third Party Advisory"]}, {"url": "https://bugzilla.redhat.com/show_bug.cgi?id=2254982", "source": "secalert@redhat.com", "tags": ["Issue Tracking"]}, {"url": "https://github.com/torvalds/linux/commit/af73483f4e8b6f5c68c9aa63257bdd929a9c194a", "source": "secalert@redhat.com", "tags": ["Patch"]}]}, "github_commit_url": "https://github.com/torvalds/linux/commit/af73483f4e8b6f5c68c9aa63257bdd929a9c194a"}}
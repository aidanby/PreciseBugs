{"buggy_code": ["import os\nimport re\nimport json\nimport random\nimport requests\nimport tldextract\nimport logging\nimport shutil\n\nfrom threading import Thread\n\nfrom urllib.parse import urlparse\n\nfrom bs4 import BeautifulSoup\nfrom lxml import html\n\nfrom discord_webhook import DiscordWebhook\nfrom django.db.models import Q\nfrom functools import reduce\nfrom scanEngine.models import *\nfrom startScan.models import *\nfrom targetApp.models import *\nfrom reNgine.definitions import *\nfrom rest_framework import serializers\n\n\n# Serializers for NS\nclass NSRecordSerializer(serializers.ModelSerializer):\n    class Meta:\n        model = NSRecord\n        fields = '__all__'\n\n\nclass NameServerHistorySerializer(serializers.ModelSerializer):\n    class Meta:\n        model = NameServerHistory\n        fields = '__all__'\n\n\nclass AssociatedDomainSerializer(serializers.ModelSerializer):\n    class Meta:\n        model = AssociatedDomain\n        fields = '__all__'\n\n\ndef get_lookup_keywords():\n    default_lookup_keywords = [\n        key.strip() for key in InterestingLookupModel.objects.get(\n            id=1).keywords.split(',')]\n    custom_lookup_keywords = []\n    if InterestingLookupModel.objects.filter(custom_type=True):\n        custom_lookup_keywords = [\n            key.strip() for key in InterestingLookupModel.objects.filter(\n                custom_type=True).order_by('-id')[0].keywords.split(',')]\n    lookup_keywords = default_lookup_keywords + custom_lookup_keywords\n    # remove empty strings from list, if any\n    lookup_keywords = list(filter(None, lookup_keywords))\n\n    return lookup_keywords\n\n\ndef get_interesting_subdomains(scan_history=None, target=None):\n    lookup_keywords = get_lookup_keywords()\n\n    subdomain_lookup_query = Q()\n    page_title_lookup_query = Q()\n\n    for key in lookup_keywords:\n        if InterestingLookupModel.objects.filter(custom_type=True).exists():\n            if InterestingLookupModel.objects.filter(\n                    custom_type=True).order_by('-id')[0].url_lookup:\n                subdomain_lookup_query |= Q(name__icontains=key)\n            if InterestingLookupModel.objects.filter(\n                    custom_type=True).order_by('-id')[0].title_lookup:\n                page_title_lookup_query |= Q(\n                    page_title__iregex=\"\\\\y{}\\\\y\".format(key))\n        else:\n            subdomain_lookup_query |= Q(name__icontains=key)\n            page_title_lookup_query |= Q(\n                page_title__iregex=\"\\\\y{}\\\\y\".format(key))\n\n    if InterestingLookupModel.objects.filter(\n            custom_type=True) and InterestingLookupModel.objects.filter(\n            custom_type=True).order_by('-id')[0].condition_200_http_lookup:\n        subdomain_lookup_query &= Q(http_status__exact=200)\n        page_title_lookup_query &= Q(http_status__exact=200)\n\n    subdomain_lookup = Subdomain.objects.none()\n    title_lookup = Subdomain.objects.none()\n\n    if target:\n        subdomains = Subdomain.objects.filter(target_domain__id=target).distinct('name')\n        if subdomain_lookup_query:\n            subdomain_lookup = subdomains.filter(subdomain_lookup_query)\n        if page_title_lookup_query:\n            title_lookup = subdomains.filter(page_title_lookup_query)\n    elif scan_history:\n        subdomains = Subdomain.objects.filter(scan_history__id=scan_history)\n        if subdomain_lookup_query:\n            subdomain_lookup = subdomains.filter(subdomain_lookup_query)\n        if page_title_lookup_query:\n            title_lookup = subdomains.filter(page_title_lookup_query)\n    else:\n        if subdomain_lookup_query:\n            subdomain_lookup = Subdomain.objects.filter(subdomain_lookup_query)\n        if page_title_lookup_query:\n            title_lookup = Subdomain.objects.filter(page_title_lookup_query)\n    lookup = subdomain_lookup | title_lookup\n    return lookup\n\n\ndef get_interesting_endpoint(scan_history=None, target=None):\n    lookup_keywords = get_lookup_keywords()\n\n    url_lookup_query = Q()\n    page_title_lookup_query = Q()\n\n    for key in lookup_keywords:\n        if InterestingLookupModel.objects.filter(custom_type=True).exists():\n            if InterestingLookupModel.objects.filter(custom_type=True).order_by('-id')[0].url_lookup:\n                url_lookup_query |= Q(http_url__icontains=key)\n            if InterestingLookupModel.objects.filter(custom_type=True).order_by('-id')[0].title_lookup:\n                page_title_lookup_query |= Q(page_title__iregex=\"\\\\y{}\\\\y\".format(key))\n\n        else:\n            url_lookup_query |= Q(http_url__icontains=key)\n            page_title_lookup_query |= Q(page_title__iregex=\"\\\\y{}\\\\y\".format(key))\n\n    if InterestingLookupModel.objects.filter(custom_type=True) and InterestingLookupModel.objects.filter(custom_type=True).order_by('-id')[0].condition_200_http_lookup:\n        url_lookup_query &= Q(http_status__exact=200)\n        page_title_lookup_query &= Q(http_status__exact=200)\n\n    url_lookup = EndPoint.objects.none()\n    title_lookup = EndPoint.objects.none()\n\n    if target:\n        urls = EndPoint.objects.filter(target_domain__id=target).distinct('http_url')\n        if url_lookup_query:\n            url_lookup = urls.filter(url_lookup_query)\n        if page_title_lookup_query:\n            title_lookup = urls.filter(page_title_lookup_query)\n    elif scan_history:\n        urls = EndPoint.objects.filter(scan_history__id=scan_history)\n        if url_lookup_query:\n            url_lookup = urls.filter(url_lookup_query)\n        if page_title_lookup_query:\n            title_lookup = urls.filter(page_title_lookup_query)\n\n    else:\n        if url_lookup_query:\n            url_lookup = EndPoint.objects.filter(url_lookup_query)\n        if page_title_lookup_query:\n            title_lookup = EndPoint.objects.filter(page_title_lookup_query)\n\n    return url_lookup | title_lookup\n\ndef check_keyword_exists(keyword_list, subdomain):\n    return any(sub in subdomain for sub in keyword_list)\n\ndef get_subdomain_from_url(url):\n    extract_url = tldextract.extract(url)\n    subdomain = '.'.join(extract_url[:4])\n    if subdomain[0] == '.':\n        subdomain = subdomain[1:]\n    return subdomain\n\ndef get_domain_from_subdomain(subdomain):\n    ext = tldextract.extract(subdomain)\n    return '.'.join(ext[1:3])\n\ndef send_telegram_message(message):\n    notification = Notification.objects.all()\n    if notification and notification[0].send_to_telegram \\\n    and notification[0].telegram_bot_token \\\n    and notification[0].telegram_bot_chat_id:\n        telegram_bot_token = notification[0].telegram_bot_token\n        telegram_bot_chat_id = notification[0].telegram_bot_chat_id\n        send_text = 'https://api.telegram.org/bot' + telegram_bot_token \\\n            + '/sendMessage?chat_id=' + telegram_bot_chat_id \\\n            + '&parse_mode=Markdown&text=' + message\n        thread = Thread(target=requests.get, args = (send_text, ))\n        thread.start()\n\ndef send_slack_message(message):\n    headers = {'content-type': 'application/json'}\n    message = {'text': message}\n    notification = Notification.objects.all()\n    if notification and notification[0].send_to_slack \\\n    and notification[0].slack_hook_url:\n        hook_url = notification[0].slack_hook_url\n        thread = Thread(\n            target=requests.post,\n            kwargs = {\n                'url': hook_url,\n                'data': json.dumps(message),\n                'headers': headers,\n            })\n        thread.start()\n\ndef send_discord_message(message):\n    notification = Notification.objects.all()\n    if notification and notification[0].send_to_discord \\\n    and notification[0].discord_hook_url:\n        webhook = DiscordWebhook(\n            url=notification[0].discord_hook_url,\n            content=message,\n            rate_limit_retry=True\n            )\n        thread = Thread(target=webhook.execute)\n        thread.start()\n\ndef send_files_to_discord(file_path):\n    notification = Notification.objects.all()\n    if notification and notification[0].send_to_discord \\\n    and notification[0].discord_hook_url:\n        webhook = DiscordWebhook(\n            url=notification[0].discord_hook_url,\n            rate_limit_retry=True,\n            username=\"Scan Results - File\"\n        )\n        with open(file_path, \"rb\") as f:\n            head, tail = os.path.split(file_path)\n            webhook.add_file(file=f.read(), filename=tail)\n        thread = Thread(target=webhook.execute)\n        thread.start()\n\ndef send_notification(message):\n    send_slack_message(message)\n    send_discord_message(message)\n    send_telegram_message(message)\n\ndef get_random_proxy():\n    if Proxy.objects.all().exists():\n        proxy = Proxy.objects.all()[0]\n        if proxy.use_proxy:\n            proxy_name = random.choice(proxy.proxies.splitlines())\n            print('Using proxy: ' + proxy_name)\n            return proxy_name\n    return False\n\ndef send_hackerone_report(vulnerability_id):\n    headers = {\n        'Content-Type': 'application/json',\n        'Accept': 'application/json'\n    }\n    # get hackerone creds\n    vulnerability = Vulnerability.objects.get(id=vulnerability_id)\n    # can only send vulnerability report if team_handle exists\n    if len(vulnerability.target_domain.h1_team_handle) !=0:\n        if Hackerone.objects.all().exists():\n            hackerone = Hackerone.objects.all()[0]\n            if vulnerability.severity == 0:\n                severity_value = 'none'\n            elif vulnerability.severity == 1:\n                severity_value = 'low'\n            elif vulnerability.severity == 2:\n                severity_value = 'medium'\n            elif vulnerability.severity == 3:\n                severity_value = 'high'\n            elif vulnerability.severity == 4:\n                severity_value = 'critical'\n            report_template = hackerone.report_template\n            # Replace syntax of report template with actual content\n            if '{vulnerability_name}' in report_template:\n                report_template = report_template.replace('{vulnerability_name}', vulnerability.name)\n            if '{vulnerable_url}' in report_template:\n                report_template = report_template.replace('{vulnerable_url}', vulnerability.http_url)\n            if '{vulnerability_severity}' in report_template:\n                report_template = report_template.replace('{vulnerability_severity}', severity_value)\n            if '{vulnerability_description}' in report_template:\n                report_template = report_template.replace('{vulnerability_description}', vulnerability.description if vulnerability.description else '')\n            if '{vulnerability_extracted_results}' in report_template:\n                report_template = report_template.replace('{vulnerability_extracted_results}', vulnerability.extracted_results if vulnerability.extracted_results else '')\n            if '{vulnerability_reference}' in report_template:\n                report_template = report_template.replace('{vulnerability_reference}', vulnerability.reference if vulnerability.reference else '')\n\n            data = {\n              \"data\": {\n                \"type\": \"report\",\n                \"attributes\": {\n                  \"team_handle\": vulnerability.target_domain.h1_team_handle,\n                  \"title\": '{} found in {}'.format(vulnerability.name, vulnerability.http_url),\n                  \"vulnerability_information\": report_template,\n                  \"severity_rating\": severity_value,\n                  \"impact\": \"More information about the impact and vulnerability can be found here: \\n\" + vulnerability.reference if vulnerability.reference else \"NA\",\n                }\n              }\n            }\n\n            r = requests.post(\n              'https://api.hackerone.com/v1/hackers/reports',\n              auth=(hackerone.username, hackerone.api_key),\n              json = data,\n              headers = headers\n            )\n\n            response = r.json()\n\n            # print(response)\n\n            status_code = r.status_code\n            print(status_code)\n\n            if status_code == 201:\n                vulnerability.hackerone_report_id = response['data'][\"id\"]\n                vulnerability.open_status = False\n                vulnerability.save()\n\n            return status_code\n\n    else:\n        print('No target ')\n        status_code = 111\n\n        return status_code\n\ndef get_whois(ip_domain, save_db=False, fetch_from_db=True):\n    # this function will fetch whois details for domains\n    # if save_db = True, then the whois will be saved in db\n    # if fetch_from_db = True then whois will be fetched from db, no lookup on\n    #     bigdomain data will be done\n    if ip_domain and not fetch_from_db:\n        response = requests.get('https://domainbigdata.com/{}'.format(ip_domain))\n        tree = html.fromstring(response.content)\n        try:\n            #RegistrantInfo Model\n            name = tree.xpath('//*[@id=\"trRegistrantName\"]/td[2]/a/text()')\n            organization = tree.xpath('//*[@id=\"MainMaster_trRegistrantOrganization\"]/td[2]/a/text()')\n            email = tree.xpath('//*[@id=\"trRegistrantEmail\"]/td[2]/a/text()')\n            address = tree.xpath('//*[@id=\"trRegistrantAddress\"]/td[2]/text()')\n            city = tree.xpath('//*[@id=\"trRegistrantCity\"]/td[2]/text()')\n            state = tree.xpath('//*[@id=\"trRegistrantState\"]/td[2]/text()')\n            country = tree.xpath('//*[@id=\"trRegistrantCountry\"]/td[2]/text()')\n            country_iso = tree.xpath('//*[@id=\"imgFlagRegistrant\"]/@alt')\n            tel = tree.xpath('//*[@id=\"trRegistrantTel\"]/td[2]/text()')\n            fax = tree.xpath('//*[@id=\"trRegistrantFax\"]/td[2]/text()')\n\n            #finding domain association using organization\n            organization_association_href = tree.xpath('//*[@id=\"MainMaster_trRegistrantOrganization\"]/td[2]/a/@href')\n            #finding domain association using email\n            email_association_href = tree.xpath('//*[@id=\"trRegistrantEmail\"]/td[2]/a/@href')\n\n            # related tlds\n            related_tlds = tree.xpath('//*[@id=\"divListOtherTLD\"]/descendant::*/text()')\n\n            # whois model\n            whois = tree.xpath('//*[@id=\"whois\"]/div/div[3]/text()')\n            whois = \"\\n\".join(whois).strip()\n\n            # DomainInfo Model\n            date_created = tree.xpath('//*[@id=\"trDateCreation\"]/td[2]/text()')\n            domain_age = tree.xpath('//*[@id=\"trWebAge\"]/td[2]/text()')\n            ip_address = tree.xpath('//*[@id=\"trIP\"]/td[2]/a/text()')\n            geolocation = tree.xpath('//*[@id=\"imgFlag\"]/following-sibling::text()')\n            geolocation_iso = tree.xpath('//*[@id=\"imgFlag\"]/@alt')\n\n            is_private_path = tree.xpath(\"//*[contains(@class, 'websiteglobalstats')]/tr[10]/td[2]/span/text()\")\n            is_private = False\n            if len(is_private_path) > 0:\n                is_private = True\n\n\n            date_created = date_created[0].strip() if date_created else None\n            domain_age = domain_age[0].strip() if domain_age else None\n            ip_address = ip_address[0].strip() if ip_address else None\n            geolocation = geolocation[0].strip() if geolocation else None\n            geolocation_iso = geolocation_iso[0].strip() if geolocation_iso else None\n            name = name[0].strip() if name else None\n            organization = organization[0].strip() if organization else None\n            email = email[0].strip() if email else None\n            address = address[0].strip() if address else None\n            city = city[0].strip() if city else None\n            state = state[0].strip() if state else None\n            country = country[0].strip() if country else None\n            country_iso = country_iso[0].strip() if country_iso else None\n            tel = tel[0].strip() if tel else None\n            fax = fax[0].strip() if fax else None\n\n            # association\n            organization_association_href = organization_association_href[0].strip() if organization_association_href else None\n            email_association_href = email_association_href[0].strip() if email_association_href else None\n\n            # other tlds\n            related_tlds = [ tld for tld in related_tlds if \"\\r\\n\" not in tld ]\n\n            dns_history_xpath = tree.xpath(\"//*[@id='MainMaster_divNSHistory']/table/tbody/tr\")\n            dns_history = []\n            for table_row in dns_history_xpath:\n                row = table_row.xpath('td/text()')\n                dns_history.append(\n                    {\n                        'date': row[0],\n                        'action': row[1],\n                        'nameserver': row[2],\n                    }\n                )\n\n            associated_domains = []\n            if organization_association_href and organization not in IGNORE_WHOIS_RELATED_KEYWORD:\n                # get all associated domains using organization\n                response_org = requests.get('https://domainbigdata.com{}'.format(organization_association_href))\n                tree_org = html.fromstring(response_org.content)\n                associated_domains_tree = tree_org.xpath('//*[@id=\"aDomain\"]/text()')\n                for domain in associated_domains_tree:\n                    associated_domains.append(domain)\n\n            if email_association_href and email not in IGNORE_WHOIS_RELATED_KEYWORD:\n                print(email_association_href)\n                response_email = requests.get('https://domainbigdata.com{}'.format(email_association_href))\n                tree_email = html.fromstring(response_email.content)\n                associated_domains_tree = tree_email.xpath('//*[@id=\"aDomain\"]/text()')\n                for domain in associated_domains_tree:\n                    associated_domains.append(domain)\n\n            # unique associated_domains\n            unique_associated_domains = []\n            [unique_associated_domains.append(domain) for domain in associated_domains if domain not in unique_associated_domains]\n\n            # save in db\n            if save_db and Domain.objects.filter(name=ip_domain).exists():\n                # look for domain and save in db\n                domain = Domain.objects.get(name=ip_domain)\n\n\n                # check if registrant exists\n                if RegistrantInfo.objects.filter(email=email).filter(name=name).exists():\n                    registrant = RegistrantInfo.objects.get(email=email, name=name)\n                else:\n                    registrant = RegistrantInfo()\n                    registrant.name = name\n                    registrant.organization = organization\n                    registrant.email = email\n                    registrant.address = address\n                    registrant.city = city\n                    registrant.state = state\n                    registrant.country = country\n                    registrant.country_iso = country_iso\n                    registrant.phone_number = tel\n                    registrant.fax = fax\n                    registrant.organization_association_href = organization_association_href\n                    registrant.email_association_href = email_association_href\n                    registrant.save()\n\n                if WhoisDetail.objects.filter(details=whois).exists():\n                    whois_model = WhoisDetail.objects.get(details=whois)\n                else:\n                    whois_model = WhoisDetail()\n                    whois_model.details = whois if whois else None\n                    whois_model.registrant = registrant\n                    whois_model.save()\n\n                domain_info = DomainInfo()\n                domain_info.date_created = date_created\n                domain_info.domain_age = domain_age\n                domain_info.ip_address = ip_address\n                domain_info.geolocation = geolocation\n                domain_info.geolocation_iso = geolocation_iso\n                domain_info.whois = whois_model\n                domain_info.save()\n\n                for table_row in dns_history_xpath:\n                    row = table_row.xpath('td/text()')\n                    ns_history = NameServerHistory()\n                    ns_history.date = row[0]\n                    ns_history.action = row[1]\n                    ns_history.server = row[2]\n                    ns_history.save()\n\n                    domain_info.nameserver_history.add(ns_history);\n\n                domain.domain_info = domain_info\n                domain.save()\n\n\n                # save associated domains\n                for domain in unique_associated_domains:\n                    if AssociatedDomain.objects.filter(name=domain).exists():\n                        ass_domain = AssociatedDomain.objects.get(name=domain)\n                    else:\n                        ass_domain = AssociatedDomain()\n                        ass_domain.name = domain\n                        ass_domain.save()\n                    domain_info.associated_domains.add(ass_domain)\n\n                # save related TLDs\n                for tld in related_tlds:\n                    if RelatedTLD.objects.filter(name=tld).exists():\n                        rel_tld = RelatedTLD.objects.get(name=tld)\n                    else:\n                        rel_tld = RelatedTLD()\n                        rel_tld.name = tld\n                        rel_tld.save()\n                    domain_info.related_tlds.add(rel_tld)\n\n            ns_records = []\n            for i in range(4):\n                ns_records_xpath = tree.xpath(\"//*[@id='divDNSRecords']/table[{}]/tbody/tr\".format(i))\n                for table_row in ns_records_xpath:\n                    row = table_row.xpath('td/text()')\n                    if row[0] == 'A':\n                        # for getting address, use child lookup\n                        address = table_row.xpath('td/a/text()')\n                        address = address[0] if address else None\n\n                        ns_records.append(\n                            {\n                                'type': row[0],\n                                'hostname': row[1],\n                                'address': address,\n                                'ttl': row[2],\n                                'class': row[3],\n                            }\n                        )\n\n                        if save_db and Domain.objects.filter(name=ip_domain).exists():\n                            ns = NSRecord()\n                            ns.type = row[0]\n                            ns.hostname = row[1]\n                            ns.address = address\n                            ns.ttl = row[2]\n                            ns.ns_class = row[3]\n                            ns.save()\n                            domain_info.nameserver_record.add(ns)\n\n                    elif row[0] == 'AAAA':\n                        # for getting address, use child lookup\n                        ns_records.append(\n                            {\n                                'type': row[0],\n                                'hostname': row[1],\n                                'address': row[2],\n                                'ttl': row[3],\n                                'class': row[4],\n                            }\n                        )\n\n                        if save_db and Domain.objects.filter(name=ip_domain).exists():\n                            ns = NSRecord()\n                            ns.type = row[0]\n                            ns.hostname = row[1]\n                            ns.address = row[2]\n                            ns.ttl = row[3]\n                            ns.ns_class = row[4]\n                            ns.save()\n                            domain_info.nameserver_record.add(ns)\n\n                    elif row[0] == 'MX':\n                        ns_records.append(\n                            {\n                                'type': row[0],\n                                'hostname': row[1],\n                                'address': row[2],\n                                'preference': row[3],\n                                'ttl': row[4],\n                                'class': row[5],\n                            }\n                        )\n\n                        if save_db and Domain.objects.filter(name=ip_domain).exists():\n                            ns = NSRecord()\n                            ns.type = row[0]\n                            ns.hostname = row[1]\n                            ns.address = address\n                            ns.preference = row[3]\n                            ns.ttl = row[4]\n                            ns.ns_class = row[5]\n                            ns.save()\n                            domain_info.nameserver_record.add(ns)\n\n\n            final_organization_association_url = 'https://domainbigdata.com' + organization_association_href if organization_association_href else None\n            final_email_association_url = 'https://domainbigdata.com' + email_association_href if email_association_href else None\n\n\n            return {\n                'status': True,\n                'ip_domain': ip_domain,\n                'domain': {\n                    'date_created': date_created,\n                    'domain_age': domain_age,\n                    'ip_address': ip_address,\n                    'geolocation': geolocation,\n                    'geolocation_iso': geolocation_iso,\n                },\n                'nameserver': {\n                    'history': dns_history,\n                    'records': ns_records\n                },\n                'registrant': {\n                    'name': name,\n                    'organization': organization,\n                    'email': email,\n                    'address': address,\n                    'city': city,\n                    'state': state,\n                    'country': country,\n                    'country_iso': country_iso,\n                    'tel': tel,\n                    'fax': fax,\n                    'organization_association_url': final_organization_association_url,\n                    'email_association_url': final_email_association_url,\n                },\n                'related_domains': unique_associated_domains,\n                'related_tlds': related_tlds,\n                'whois': whois if whois else None\n            }\n        except Exception as e:\n            logging.exception(e)\n            return {\n                'status': False,\n                'ip_domain': ip_domain,\n                'result': 'Domain not found'\n            }\n    elif ip_domain and fetch_from_db:\n        if Domain.objects.filter(name=ip_domain).exists():\n            domain = Domain.objects.get(name=ip_domain)\n            unique_associated_domains = []\n\n            if domain.domain_info and domain.domain_info.associated_domains:\n                unique_associated_domains = [d.name for d in domain.domain_info.associated_domains.all()]\n\n\n            unique_related_tlds = []\n            if domain.domain_info and domain.domain_info.related_tlds:\n                unique_related_tlds = [d.name for d in domain.domain_info.related_tlds.all()]\n\n            if domain.domain_info:\n                return {\n                    'status': True,\n                    'ip_domain': ip_domain,\n                    'domain': {\n                        'date_created': domain.domain_info.date_created,\n                        'domain_age': domain.domain_info.domain_age,\n                        'ip_address': domain.domain_info.ip_address,\n                        'geolocation': domain.domain_info.geolocation,\n                        'geolocation_iso': domain.domain_info.geolocation_iso,\n                    },\n                    'nameserver': {\n                        'history': NameServerHistorySerializer(domain.domain_info.nameserver_history.all(), many=True).data,\n                        'records': NSRecordSerializer(domain.domain_info.nameserver_record.all(), many=True).data\n                    },\n                    'registrant': {\n                        'name': domain.domain_info.whois.registrant.name,\n                        'organization': domain.domain_info.whois.registrant.organization,\n                        'email': domain.domain_info.whois.registrant.email,\n                        'address': domain.domain_info.whois.registrant.address,\n                        'city': domain.domain_info.whois.registrant.city,\n                        'state': domain.domain_info.whois.registrant.state,\n                        'country': domain.domain_info.whois.registrant.country,\n                        'country_iso': domain.domain_info.whois.registrant.country_iso,\n                        'tel': domain.domain_info.whois.registrant.phone_number,\n                        'fax': domain.domain_info.whois.registrant.fax,\n                    },\n                    'related_domains': unique_associated_domains,\n                    'related_tlds': unique_related_tlds,\n                    'whois': domain.domain_info.whois.details\n                }\n            return {\n                'status': False,\n                'message': 'WHOIS does not exist.'\n            }\n        return {\n            'status': False,\n            'message': 'Domain ' + ip_domain + ' does not exist as target and could not fetch WHOIS from database.'\n        }\n\n\ndef get_cms_details(url):\n    # this function will fetch cms details using cms_detector\n    response = {}\n    cms_detector_command = 'python3 /usr/src/github/CMSeeK/cmseek.py -u {} --random-agent --batch --follow-redirect'.format(url)\n    os.system(cms_detector_command)\n\n    response['status'] = False\n    response['message'] = 'Could not detect CMS!'\n\n    parsed_url = urlparse(url)\n\n    domain_name = parsed_url.hostname\n    port = parsed_url.port\n\n    find_dir = domain_name\n\n    if port:\n        find_dir += '_{}'.format(port)\n\n\n    print(url)\n    print(find_dir)\n\n    # subdomain may also have port number, and is stored in dir as _port\n\n    cms_dir_path =  '/usr/src/github/CMSeeK/Result/{}'.format(find_dir)\n    cms_json_path =  cms_dir_path + '/cms.json'\n\n    if os.path.isfile(cms_json_path):\n        cms_file_content = json.loads(open(cms_json_path, 'r').read())\n        if not cms_file_content.get('cms_id'):\n            return response\n        response = {}\n        response = cms_file_content\n        response['status'] = True\n        # remove cms dir path\n        try:\n            shutil.rmtree(cms_dir_path)\n        except Exception as e:\n            print(e)\n\n    return response\n"], "fixing_code": ["import os\nimport re\nimport json\nimport random\nimport requests\nimport tldextract\nimport logging\nimport shutil\nimport subprocess\n\nfrom threading import Thread\n\nfrom urllib.parse import urlparse\n\nfrom bs4 import BeautifulSoup\nfrom lxml import html\n\nfrom discord_webhook import DiscordWebhook\nfrom django.db.models import Q\nfrom functools import reduce\nfrom scanEngine.models import *\nfrom startScan.models import *\nfrom targetApp.models import *\nfrom reNgine.definitions import *\nfrom rest_framework import serializers\n\n\n# Serializers for NS\nclass NSRecordSerializer(serializers.ModelSerializer):\n    class Meta:\n        model = NSRecord\n        fields = '__all__'\n\n\nclass NameServerHistorySerializer(serializers.ModelSerializer):\n    class Meta:\n        model = NameServerHistory\n        fields = '__all__'\n\n\nclass AssociatedDomainSerializer(serializers.ModelSerializer):\n    class Meta:\n        model = AssociatedDomain\n        fields = '__all__'\n\n\ndef get_lookup_keywords():\n    default_lookup_keywords = [\n        key.strip() for key in InterestingLookupModel.objects.get(\n            id=1).keywords.split(',')]\n    custom_lookup_keywords = []\n    if InterestingLookupModel.objects.filter(custom_type=True):\n        custom_lookup_keywords = [\n            key.strip() for key in InterestingLookupModel.objects.filter(\n                custom_type=True).order_by('-id')[0].keywords.split(',')]\n    lookup_keywords = default_lookup_keywords + custom_lookup_keywords\n    # remove empty strings from list, if any\n    lookup_keywords = list(filter(None, lookup_keywords))\n\n    return lookup_keywords\n\n\ndef get_interesting_subdomains(scan_history=None, target=None):\n    lookup_keywords = get_lookup_keywords()\n\n    subdomain_lookup_query = Q()\n    page_title_lookup_query = Q()\n\n    for key in lookup_keywords:\n        if InterestingLookupModel.objects.filter(custom_type=True).exists():\n            if InterestingLookupModel.objects.filter(\n                    custom_type=True).order_by('-id')[0].url_lookup:\n                subdomain_lookup_query |= Q(name__icontains=key)\n            if InterestingLookupModel.objects.filter(\n                    custom_type=True).order_by('-id')[0].title_lookup:\n                page_title_lookup_query |= Q(\n                    page_title__iregex=\"\\\\y{}\\\\y\".format(key))\n        else:\n            subdomain_lookup_query |= Q(name__icontains=key)\n            page_title_lookup_query |= Q(\n                page_title__iregex=\"\\\\y{}\\\\y\".format(key))\n\n    if InterestingLookupModel.objects.filter(\n            custom_type=True) and InterestingLookupModel.objects.filter(\n            custom_type=True).order_by('-id')[0].condition_200_http_lookup:\n        subdomain_lookup_query &= Q(http_status__exact=200)\n        page_title_lookup_query &= Q(http_status__exact=200)\n\n    subdomain_lookup = Subdomain.objects.none()\n    title_lookup = Subdomain.objects.none()\n\n    if target:\n        subdomains = Subdomain.objects.filter(target_domain__id=target).distinct('name')\n        if subdomain_lookup_query:\n            subdomain_lookup = subdomains.filter(subdomain_lookup_query)\n        if page_title_lookup_query:\n            title_lookup = subdomains.filter(page_title_lookup_query)\n    elif scan_history:\n        subdomains = Subdomain.objects.filter(scan_history__id=scan_history)\n        if subdomain_lookup_query:\n            subdomain_lookup = subdomains.filter(subdomain_lookup_query)\n        if page_title_lookup_query:\n            title_lookup = subdomains.filter(page_title_lookup_query)\n    else:\n        if subdomain_lookup_query:\n            subdomain_lookup = Subdomain.objects.filter(subdomain_lookup_query)\n        if page_title_lookup_query:\n            title_lookup = Subdomain.objects.filter(page_title_lookup_query)\n    lookup = subdomain_lookup | title_lookup\n    return lookup\n\n\ndef get_interesting_endpoint(scan_history=None, target=None):\n    lookup_keywords = get_lookup_keywords()\n\n    url_lookup_query = Q()\n    page_title_lookup_query = Q()\n\n    for key in lookup_keywords:\n        if InterestingLookupModel.objects.filter(custom_type=True).exists():\n            if InterestingLookupModel.objects.filter(custom_type=True).order_by('-id')[0].url_lookup:\n                url_lookup_query |= Q(http_url__icontains=key)\n            if InterestingLookupModel.objects.filter(custom_type=True).order_by('-id')[0].title_lookup:\n                page_title_lookup_query |= Q(page_title__iregex=\"\\\\y{}\\\\y\".format(key))\n\n        else:\n            url_lookup_query |= Q(http_url__icontains=key)\n            page_title_lookup_query |= Q(page_title__iregex=\"\\\\y{}\\\\y\".format(key))\n\n    if InterestingLookupModel.objects.filter(custom_type=True) and InterestingLookupModel.objects.filter(custom_type=True).order_by('-id')[0].condition_200_http_lookup:\n        url_lookup_query &= Q(http_status__exact=200)\n        page_title_lookup_query &= Q(http_status__exact=200)\n\n    url_lookup = EndPoint.objects.none()\n    title_lookup = EndPoint.objects.none()\n\n    if target:\n        urls = EndPoint.objects.filter(target_domain__id=target).distinct('http_url')\n        if url_lookup_query:\n            url_lookup = urls.filter(url_lookup_query)\n        if page_title_lookup_query:\n            title_lookup = urls.filter(page_title_lookup_query)\n    elif scan_history:\n        urls = EndPoint.objects.filter(scan_history__id=scan_history)\n        if url_lookup_query:\n            url_lookup = urls.filter(url_lookup_query)\n        if page_title_lookup_query:\n            title_lookup = urls.filter(page_title_lookup_query)\n\n    else:\n        if url_lookup_query:\n            url_lookup = EndPoint.objects.filter(url_lookup_query)\n        if page_title_lookup_query:\n            title_lookup = EndPoint.objects.filter(page_title_lookup_query)\n\n    return url_lookup | title_lookup\n\ndef check_keyword_exists(keyword_list, subdomain):\n    return any(sub in subdomain for sub in keyword_list)\n\ndef get_subdomain_from_url(url):\n    extract_url = tldextract.extract(url)\n    subdomain = '.'.join(extract_url[:4])\n    if subdomain[0] == '.':\n        subdomain = subdomain[1:]\n    return subdomain\n\ndef get_domain_from_subdomain(subdomain):\n    ext = tldextract.extract(subdomain)\n    return '.'.join(ext[1:3])\n\ndef send_telegram_message(message):\n    notification = Notification.objects.all()\n    if notification and notification[0].send_to_telegram \\\n    and notification[0].telegram_bot_token \\\n    and notification[0].telegram_bot_chat_id:\n        telegram_bot_token = notification[0].telegram_bot_token\n        telegram_bot_chat_id = notification[0].telegram_bot_chat_id\n        send_text = 'https://api.telegram.org/bot' + telegram_bot_token \\\n            + '/sendMessage?chat_id=' + telegram_bot_chat_id \\\n            + '&parse_mode=Markdown&text=' + message\n        thread = Thread(target=requests.get, args = (send_text, ))\n        thread.start()\n\ndef send_slack_message(message):\n    headers = {'content-type': 'application/json'}\n    message = {'text': message}\n    notification = Notification.objects.all()\n    if notification and notification[0].send_to_slack \\\n    and notification[0].slack_hook_url:\n        hook_url = notification[0].slack_hook_url\n        thread = Thread(\n            target=requests.post,\n            kwargs = {\n                'url': hook_url,\n                'data': json.dumps(message),\n                'headers': headers,\n            })\n        thread.start()\n\ndef send_discord_message(message):\n    notification = Notification.objects.all()\n    if notification and notification[0].send_to_discord \\\n    and notification[0].discord_hook_url:\n        webhook = DiscordWebhook(\n            url=notification[0].discord_hook_url,\n            content=message,\n            rate_limit_retry=True\n            )\n        thread = Thread(target=webhook.execute)\n        thread.start()\n\ndef send_files_to_discord(file_path):\n    notification = Notification.objects.all()\n    if notification and notification[0].send_to_discord \\\n    and notification[0].discord_hook_url:\n        webhook = DiscordWebhook(\n            url=notification[0].discord_hook_url,\n            rate_limit_retry=True,\n            username=\"Scan Results - File\"\n        )\n        with open(file_path, \"rb\") as f:\n            head, tail = os.path.split(file_path)\n            webhook.add_file(file=f.read(), filename=tail)\n        thread = Thread(target=webhook.execute)\n        thread.start()\n\ndef send_notification(message):\n    send_slack_message(message)\n    send_discord_message(message)\n    send_telegram_message(message)\n\ndef get_random_proxy():\n    if Proxy.objects.all().exists():\n        proxy = Proxy.objects.all()[0]\n        if proxy.use_proxy:\n            proxy_name = random.choice(proxy.proxies.splitlines())\n            print('Using proxy: ' + proxy_name)\n            return proxy_name\n    return False\n\ndef send_hackerone_report(vulnerability_id):\n    headers = {\n        'Content-Type': 'application/json',\n        'Accept': 'application/json'\n    }\n    # get hackerone creds\n    vulnerability = Vulnerability.objects.get(id=vulnerability_id)\n    # can only send vulnerability report if team_handle exists\n    if len(vulnerability.target_domain.h1_team_handle) !=0:\n        if Hackerone.objects.all().exists():\n            hackerone = Hackerone.objects.all()[0]\n            if vulnerability.severity == 0:\n                severity_value = 'none'\n            elif vulnerability.severity == 1:\n                severity_value = 'low'\n            elif vulnerability.severity == 2:\n                severity_value = 'medium'\n            elif vulnerability.severity == 3:\n                severity_value = 'high'\n            elif vulnerability.severity == 4:\n                severity_value = 'critical'\n            report_template = hackerone.report_template\n            # Replace syntax of report template with actual content\n            if '{vulnerability_name}' in report_template:\n                report_template = report_template.replace('{vulnerability_name}', vulnerability.name)\n            if '{vulnerable_url}' in report_template:\n                report_template = report_template.replace('{vulnerable_url}', vulnerability.http_url)\n            if '{vulnerability_severity}' in report_template:\n                report_template = report_template.replace('{vulnerability_severity}', severity_value)\n            if '{vulnerability_description}' in report_template:\n                report_template = report_template.replace('{vulnerability_description}', vulnerability.description if vulnerability.description else '')\n            if '{vulnerability_extracted_results}' in report_template:\n                report_template = report_template.replace('{vulnerability_extracted_results}', vulnerability.extracted_results if vulnerability.extracted_results else '')\n            if '{vulnerability_reference}' in report_template:\n                report_template = report_template.replace('{vulnerability_reference}', vulnerability.reference if vulnerability.reference else '')\n\n            data = {\n              \"data\": {\n                \"type\": \"report\",\n                \"attributes\": {\n                  \"team_handle\": vulnerability.target_domain.h1_team_handle,\n                  \"title\": '{} found in {}'.format(vulnerability.name, vulnerability.http_url),\n                  \"vulnerability_information\": report_template,\n                  \"severity_rating\": severity_value,\n                  \"impact\": \"More information about the impact and vulnerability can be found here: \\n\" + vulnerability.reference if vulnerability.reference else \"NA\",\n                }\n              }\n            }\n\n            r = requests.post(\n              'https://api.hackerone.com/v1/hackers/reports',\n              auth=(hackerone.username, hackerone.api_key),\n              json = data,\n              headers = headers\n            )\n\n            response = r.json()\n\n            # print(response)\n\n            status_code = r.status_code\n            print(status_code)\n\n            if status_code == 201:\n                vulnerability.hackerone_report_id = response['data'][\"id\"]\n                vulnerability.open_status = False\n                vulnerability.save()\n\n            return status_code\n\n    else:\n        print('No target ')\n        status_code = 111\n\n        return status_code\n\ndef get_whois(ip_domain, save_db=False, fetch_from_db=True):\n    # this function will fetch whois details for domains\n    # if save_db = True, then the whois will be saved in db\n    # if fetch_from_db = True then whois will be fetched from db, no lookup on\n    #     bigdomain data will be done\n    if ip_domain and not fetch_from_db:\n        response = requests.get('https://domainbigdata.com/{}'.format(ip_domain))\n        tree = html.fromstring(response.content)\n        try:\n            #RegistrantInfo Model\n            name = tree.xpath('//*[@id=\"trRegistrantName\"]/td[2]/a/text()')\n            organization = tree.xpath('//*[@id=\"MainMaster_trRegistrantOrganization\"]/td[2]/a/text()')\n            email = tree.xpath('//*[@id=\"trRegistrantEmail\"]/td[2]/a/text()')\n            address = tree.xpath('//*[@id=\"trRegistrantAddress\"]/td[2]/text()')\n            city = tree.xpath('//*[@id=\"trRegistrantCity\"]/td[2]/text()')\n            state = tree.xpath('//*[@id=\"trRegistrantState\"]/td[2]/text()')\n            country = tree.xpath('//*[@id=\"trRegistrantCountry\"]/td[2]/text()')\n            country_iso = tree.xpath('//*[@id=\"imgFlagRegistrant\"]/@alt')\n            tel = tree.xpath('//*[@id=\"trRegistrantTel\"]/td[2]/text()')\n            fax = tree.xpath('//*[@id=\"trRegistrantFax\"]/td[2]/text()')\n\n            #finding domain association using organization\n            organization_association_href = tree.xpath('//*[@id=\"MainMaster_trRegistrantOrganization\"]/td[2]/a/@href')\n            #finding domain association using email\n            email_association_href = tree.xpath('//*[@id=\"trRegistrantEmail\"]/td[2]/a/@href')\n\n            # related tlds\n            related_tlds = tree.xpath('//*[@id=\"divListOtherTLD\"]/descendant::*/text()')\n\n            # whois model\n            whois = tree.xpath('//*[@id=\"whois\"]/div/div[3]/text()')\n            whois = \"\\n\".join(whois).strip()\n\n            # DomainInfo Model\n            date_created = tree.xpath('//*[@id=\"trDateCreation\"]/td[2]/text()')\n            domain_age = tree.xpath('//*[@id=\"trWebAge\"]/td[2]/text()')\n            ip_address = tree.xpath('//*[@id=\"trIP\"]/td[2]/a/text()')\n            geolocation = tree.xpath('//*[@id=\"imgFlag\"]/following-sibling::text()')\n            geolocation_iso = tree.xpath('//*[@id=\"imgFlag\"]/@alt')\n\n            is_private_path = tree.xpath(\"//*[contains(@class, 'websiteglobalstats')]/tr[10]/td[2]/span/text()\")\n            is_private = False\n            if len(is_private_path) > 0:\n                is_private = True\n\n\n            date_created = date_created[0].strip() if date_created else None\n            domain_age = domain_age[0].strip() if domain_age else None\n            ip_address = ip_address[0].strip() if ip_address else None\n            geolocation = geolocation[0].strip() if geolocation else None\n            geolocation_iso = geolocation_iso[0].strip() if geolocation_iso else None\n            name = name[0].strip() if name else None\n            organization = organization[0].strip() if organization else None\n            email = email[0].strip() if email else None\n            address = address[0].strip() if address else None\n            city = city[0].strip() if city else None\n            state = state[0].strip() if state else None\n            country = country[0].strip() if country else None\n            country_iso = country_iso[0].strip() if country_iso else None\n            tel = tel[0].strip() if tel else None\n            fax = fax[0].strip() if fax else None\n\n            # association\n            organization_association_href = organization_association_href[0].strip() if organization_association_href else None\n            email_association_href = email_association_href[0].strip() if email_association_href else None\n\n            # other tlds\n            related_tlds = [ tld for tld in related_tlds if \"\\r\\n\" not in tld ]\n\n            dns_history_xpath = tree.xpath(\"//*[@id='MainMaster_divNSHistory']/table/tbody/tr\")\n            dns_history = []\n            for table_row in dns_history_xpath:\n                row = table_row.xpath('td/text()')\n                dns_history.append(\n                    {\n                        'date': row[0],\n                        'action': row[1],\n                        'nameserver': row[2],\n                    }\n                )\n\n            associated_domains = []\n            if organization_association_href and organization not in IGNORE_WHOIS_RELATED_KEYWORD:\n                # get all associated domains using organization\n                response_org = requests.get('https://domainbigdata.com{}'.format(organization_association_href))\n                tree_org = html.fromstring(response_org.content)\n                associated_domains_tree = tree_org.xpath('//*[@id=\"aDomain\"]/text()')\n                for domain in associated_domains_tree:\n                    associated_domains.append(domain)\n\n            if email_association_href and email not in IGNORE_WHOIS_RELATED_KEYWORD:\n                print(email_association_href)\n                response_email = requests.get('https://domainbigdata.com{}'.format(email_association_href))\n                tree_email = html.fromstring(response_email.content)\n                associated_domains_tree = tree_email.xpath('//*[@id=\"aDomain\"]/text()')\n                for domain in associated_domains_tree:\n                    associated_domains.append(domain)\n\n            # unique associated_domains\n            unique_associated_domains = []\n            [unique_associated_domains.append(domain) for domain in associated_domains if domain not in unique_associated_domains]\n\n            # save in db\n            if save_db and Domain.objects.filter(name=ip_domain).exists():\n                # look for domain and save in db\n                domain = Domain.objects.get(name=ip_domain)\n\n\n                # check if registrant exists\n                if RegistrantInfo.objects.filter(email=email).filter(name=name).exists():\n                    registrant = RegistrantInfo.objects.get(email=email, name=name)\n                else:\n                    registrant = RegistrantInfo()\n                    registrant.name = name\n                    registrant.organization = organization\n                    registrant.email = email\n                    registrant.address = address\n                    registrant.city = city\n                    registrant.state = state\n                    registrant.country = country\n                    registrant.country_iso = country_iso\n                    registrant.phone_number = tel\n                    registrant.fax = fax\n                    registrant.organization_association_href = organization_association_href\n                    registrant.email_association_href = email_association_href\n                    registrant.save()\n\n                if WhoisDetail.objects.filter(details=whois).exists():\n                    whois_model = WhoisDetail.objects.get(details=whois)\n                else:\n                    whois_model = WhoisDetail()\n                    whois_model.details = whois if whois else None\n                    whois_model.registrant = registrant\n                    whois_model.save()\n\n                domain_info = DomainInfo()\n                domain_info.date_created = date_created\n                domain_info.domain_age = domain_age\n                domain_info.ip_address = ip_address\n                domain_info.geolocation = geolocation\n                domain_info.geolocation_iso = geolocation_iso\n                domain_info.whois = whois_model\n                domain_info.save()\n\n                for table_row in dns_history_xpath:\n                    row = table_row.xpath('td/text()')\n                    ns_history = NameServerHistory()\n                    ns_history.date = row[0]\n                    ns_history.action = row[1]\n                    ns_history.server = row[2]\n                    ns_history.save()\n\n                    domain_info.nameserver_history.add(ns_history);\n\n                domain.domain_info = domain_info\n                domain.save()\n\n\n                # save associated domains\n                for domain in unique_associated_domains:\n                    if AssociatedDomain.objects.filter(name=domain).exists():\n                        ass_domain = AssociatedDomain.objects.get(name=domain)\n                    else:\n                        ass_domain = AssociatedDomain()\n                        ass_domain.name = domain\n                        ass_domain.save()\n                    domain_info.associated_domains.add(ass_domain)\n\n                # save related TLDs\n                for tld in related_tlds:\n                    if RelatedTLD.objects.filter(name=tld).exists():\n                        rel_tld = RelatedTLD.objects.get(name=tld)\n                    else:\n                        rel_tld = RelatedTLD()\n                        rel_tld.name = tld\n                        rel_tld.save()\n                    domain_info.related_tlds.add(rel_tld)\n\n            ns_records = []\n            for i in range(4):\n                ns_records_xpath = tree.xpath(\"//*[@id='divDNSRecords']/table[{}]/tbody/tr\".format(i))\n                for table_row in ns_records_xpath:\n                    row = table_row.xpath('td/text()')\n                    if row[0] == 'A':\n                        # for getting address, use child lookup\n                        address = table_row.xpath('td/a/text()')\n                        address = address[0] if address else None\n\n                        ns_records.append(\n                            {\n                                'type': row[0],\n                                'hostname': row[1],\n                                'address': address,\n                                'ttl': row[2],\n                                'class': row[3],\n                            }\n                        )\n\n                        if save_db and Domain.objects.filter(name=ip_domain).exists():\n                            ns = NSRecord()\n                            ns.type = row[0]\n                            ns.hostname = row[1]\n                            ns.address = address\n                            ns.ttl = row[2]\n                            ns.ns_class = row[3]\n                            ns.save()\n                            domain_info.nameserver_record.add(ns)\n\n                    elif row[0] == 'AAAA':\n                        # for getting address, use child lookup\n                        ns_records.append(\n                            {\n                                'type': row[0],\n                                'hostname': row[1],\n                                'address': row[2],\n                                'ttl': row[3],\n                                'class': row[4],\n                            }\n                        )\n\n                        if save_db and Domain.objects.filter(name=ip_domain).exists():\n                            ns = NSRecord()\n                            ns.type = row[0]\n                            ns.hostname = row[1]\n                            ns.address = row[2]\n                            ns.ttl = row[3]\n                            ns.ns_class = row[4]\n                            ns.save()\n                            domain_info.nameserver_record.add(ns)\n\n                    elif row[0] == 'MX':\n                        ns_records.append(\n                            {\n                                'type': row[0],\n                                'hostname': row[1],\n                                'address': row[2],\n                                'preference': row[3],\n                                'ttl': row[4],\n                                'class': row[5],\n                            }\n                        )\n\n                        if save_db and Domain.objects.filter(name=ip_domain).exists():\n                            ns = NSRecord()\n                            ns.type = row[0]\n                            ns.hostname = row[1]\n                            ns.address = address\n                            ns.preference = row[3]\n                            ns.ttl = row[4]\n                            ns.ns_class = row[5]\n                            ns.save()\n                            domain_info.nameserver_record.add(ns)\n\n\n            final_organization_association_url = 'https://domainbigdata.com' + organization_association_href if organization_association_href else None\n            final_email_association_url = 'https://domainbigdata.com' + email_association_href if email_association_href else None\n\n\n            return {\n                'status': True,\n                'ip_domain': ip_domain,\n                'domain': {\n                    'date_created': date_created,\n                    'domain_age': domain_age,\n                    'ip_address': ip_address,\n                    'geolocation': geolocation,\n                    'geolocation_iso': geolocation_iso,\n                },\n                'nameserver': {\n                    'history': dns_history,\n                    'records': ns_records\n                },\n                'registrant': {\n                    'name': name,\n                    'organization': organization,\n                    'email': email,\n                    'address': address,\n                    'city': city,\n                    'state': state,\n                    'country': country,\n                    'country_iso': country_iso,\n                    'tel': tel,\n                    'fax': fax,\n                    'organization_association_url': final_organization_association_url,\n                    'email_association_url': final_email_association_url,\n                },\n                'related_domains': unique_associated_domains,\n                'related_tlds': related_tlds,\n                'whois': whois if whois else None\n            }\n        except Exception as e:\n            logging.exception(e)\n            return {\n                'status': False,\n                'ip_domain': ip_domain,\n                'result': 'Domain not found'\n            }\n    elif ip_domain and fetch_from_db:\n        if Domain.objects.filter(name=ip_domain).exists():\n            domain = Domain.objects.get(name=ip_domain)\n            unique_associated_domains = []\n\n            if domain.domain_info and domain.domain_info.associated_domains:\n                unique_associated_domains = [d.name for d in domain.domain_info.associated_domains.all()]\n\n\n            unique_related_tlds = []\n            if domain.domain_info and domain.domain_info.related_tlds:\n                unique_related_tlds = [d.name for d in domain.domain_info.related_tlds.all()]\n\n            if domain.domain_info:\n                return {\n                    'status': True,\n                    'ip_domain': ip_domain,\n                    'domain': {\n                        'date_created': domain.domain_info.date_created,\n                        'domain_age': domain.domain_info.domain_age,\n                        'ip_address': domain.domain_info.ip_address,\n                        'geolocation': domain.domain_info.geolocation,\n                        'geolocation_iso': domain.domain_info.geolocation_iso,\n                    },\n                    'nameserver': {\n                        'history': NameServerHistorySerializer(domain.domain_info.nameserver_history.all(), many=True).data,\n                        'records': NSRecordSerializer(domain.domain_info.nameserver_record.all(), many=True).data\n                    },\n                    'registrant': {\n                        'name': domain.domain_info.whois.registrant.name,\n                        'organization': domain.domain_info.whois.registrant.organization,\n                        'email': domain.domain_info.whois.registrant.email,\n                        'address': domain.domain_info.whois.registrant.address,\n                        'city': domain.domain_info.whois.registrant.city,\n                        'state': domain.domain_info.whois.registrant.state,\n                        'country': domain.domain_info.whois.registrant.country,\n                        'country_iso': domain.domain_info.whois.registrant.country_iso,\n                        'tel': domain.domain_info.whois.registrant.phone_number,\n                        'fax': domain.domain_info.whois.registrant.fax,\n                    },\n                    'related_domains': unique_associated_domains,\n                    'related_tlds': unique_related_tlds,\n                    'whois': domain.domain_info.whois.details\n                }\n            return {\n                'status': False,\n                'message': 'WHOIS does not exist.'\n            }\n        return {\n            'status': False,\n            'message': 'Domain ' + ip_domain + ' does not exist as target and could not fetch WHOIS from database.'\n        }\n\n\ndef get_cms_details(url):\n    # this function will fetch cms details using cms_detector\n    response = {}\n    cms_detector_command = 'python3 /usr/src/github/CMSeeK/cmseek.py --random-agent --batch --follow-redirect'\n    subprocess_splitted_command = cms_detector_command.split()\n    subprocess_splitted_command.append('-u')\n    subprocess_splitted_command.append(url)\n    process = subprocess.Popen(subprocess_splitted_command)\n    process.wait()\n\n    response['status'] = False\n    response['message'] = 'Could not detect CMS!'\n\n    parsed_url = urlparse(url)\n\n    domain_name = parsed_url.hostname\n    port = parsed_url.port\n\n    find_dir = domain_name\n\n    if port:\n        find_dir += '_{}'.format(port)\n\n\n    print(url)\n    print(find_dir)\n\n    # subdomain may also have port number, and is stored in dir as _port\n\n    cms_dir_path =  '/usr/src/github/CMSeeK/Result/{}'.format(find_dir)\n    cms_json_path =  cms_dir_path + '/cms.json'\n\n    if os.path.isfile(cms_json_path):\n        cms_file_content = json.loads(open(cms_json_path, 'r').read())\n        if not cms_file_content.get('cms_id'):\n            return response\n        response = {}\n        response = cms_file_content\n        response['status'] = True\n        # remove cms dir path\n        try:\n            shutil.rmtree(cms_dir_path)\n        except Exception as e:\n            print(e)\n\n    return response\n"], "filenames": ["web/reNgine/common_func.py"], "buggy_code_start_loc": [8], "buggy_code_end_loc": [673], "fixing_code_start_loc": [9], "fixing_code_end_loc": [678], "type": "CWE-78", "message": "OS Command Injection in GitHub repository yogeshojha/rengine prior to 1.2.0.", "other": {"cve": {"id": "CVE-2022-1813", "sourceIdentifier": "security@huntr.dev", "published": "2022-05-22T16:15:08.173", "lastModified": "2022-05-30T00:26:10.517", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "OS Command Injection in GitHub repository yogeshojha/rengine prior to 1.2.0."}, {"lang": "es", "value": "Inyecci\u00f3n de comandos del sistema operativo en el repositorio GitHub yogeshojha/rengine versiones anteriores a 1.2.0"}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "HIGH", "availabilityImpact": "HIGH", "baseScore": 9.8, "baseSeverity": "CRITICAL"}, "exploitabilityScore": 3.9, "impactScore": 5.9}], "cvssMetricV30": [{"source": "security@huntr.dev", "type": "Secondary", "cvssData": {"version": "3.0", "vectorString": "CVSS:3.0/AV:N/AC:L/PR:L/UI:N/S:U/C:H/I:L/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "LOW", "availabilityImpact": "HIGH", "baseScore": 8.3, "baseSeverity": "HIGH"}, "exploitabilityScore": 2.8, "impactScore": 5.5}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:N/AC:L/Au:N/C:P/I:P/A:P", "accessVector": "NETWORK", "accessComplexity": "LOW", "authentication": "NONE", "confidentialityImpact": "PARTIAL", "integrityImpact": "PARTIAL", "availabilityImpact": "PARTIAL", "baseScore": 7.5}, "baseSeverity": "HIGH", "exploitabilityScore": 10.0, "impactScore": 6.4, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-78"}]}, {"source": "security@huntr.dev", "type": "Secondary", "description": [{"lang": "en", "value": "CWE-78"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:rengine_project:rengine:*:*:*:*:*:*:*:*", "versionEndExcluding": "1.2.0", "matchCriteriaId": "2209F323-EEEA-46C5-B1E6-BC1E42A8B3AF"}]}]}], "references": [{"url": "https://github.com/yogeshojha/rengine/commit/8277cec0f008a0451371a92e7e0bf082ab3f0c34", "source": "security@huntr.dev", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://huntr.dev/bounties/b255cf59-9ecd-4255-b9a2-b40b5ec6c572", "source": "security@huntr.dev", "tags": ["Exploit", "Patch", "Third Party Advisory"]}]}, "github_commit_url": "https://github.com/yogeshojha/rengine/commit/8277cec0f008a0451371a92e7e0bf082ab3f0c34"}}
{"buggy_code": ["# Exposure Notification: Risks and Mitigations FAQ\n\nThis document explains the key design decisions that affect the privacy and\nsecurity of the Google/Apple Exposure Notifications system (ENS), the risks that\nwere evaluated, and the mitigations that are in place for these risks. Details\nof the ENS design can be found\n[here](https://www.google.com/covid19/exposurenotifications/).\n\n# Key design decisions and constraints relevant to security and privacy\n\n## Decentralized architecture\n\nThe design of an effective exposure notification system requires trade-offs\nbetween efficacy, privacy, and security. A common way of categorizing contact\ntracing and Exposure Notification designs is between:\n\n1.  **Centralized.** A central service makes decisions about whether to\n    notify someone if they have been exposed or not. Centralized designs\n    require devices to share a list of observed Bluetooth identifiers with a\n    central notification service.\n2.  **Decentralized.** The user's device decides locally whether to notify\n    someone if they have been exposed or not. Decentralized designs require\n    devices to receive a list of all COVID-positive users' broadcast Bluetooth\n    identifiers.\n\nThe Google/Apple design uses a decentralized architecture because:\n\n1.  Devices of COVID-negative users do not share any information about\n    social interactions, location, or infection status. Decentralized designs\n    provide better privacy protection for COVID-negative participants compared\n    to centralized designs, since they do not require sharing any information\n    with a central service unless a user declares themselves COVID-positive.\n    This is especially important since we assume that the vast majority of\n    participants will be COVID-negative.\n    In contrast, centralized designs have the property that any party with\n    access to the central service has access to observed Bluetooth Low Energy\n    (BLE) identifiers\u2014and therefore information about social interactions\u2014for\n    all participants, including those who have not declared themselves as\n    COVID-positive.\n2.  For COVID-positive users, the information shared with the server in a\n    decentralized model is their COVID-positive status rather than any\n    information about social interactions: decentralized designs require\n    sharing broadcast Rolling Proximity Identifiers (RPIs) of COVID-positive\n    users with all participating devices (usually via a central service).\n    Centralized designs expose users' social interactions to a central service\n    in order to receive notifications. Even if care is taken not to store\n    information on relationships, the centralized designs inherently risk that\n    this information may be obtained by an adversary.\n    COVID-positive status data presents less incremental risk to the user and\n    is less permanent than a person's social interactions: see\n    [here](#covid-positive) for more details.\n3.  Centralized designs also expose COVID-positive status. While centralized\n    designs can minimize information revealed to the public at large, and make\n    such attacks more difficult, they cannot prevent attacks that identify\n    COVID-positive users entirely.\n    In a centralized model an adversary can emit Bluetooth IDs in the vicinity\n    of a device whose owner has been identified via other means, for example,\n    by using vehicle number plate recognition. Once this device reports its\n    owner as COVID-positive, the adversary's device will receive an exposure\n    notification, which can be tied to the identified user. If they want to do\n    this multiple times, however, they would need to have a single Healthcare\n    Authority account, that is notification channel, per identified user.\n    Healthcare Authority diagnosis servers could implement defenses against\n    Sybil attacks using multiple accounts, but this could put legitimate users\n    at higher risk of being falsely excluded from receiving exposure notifications.\n\n## Location\n\nLocation data from the device is not used by the Google/Apple EN API in any\nway.\n\nHealthcare Authority applications using the Exposure Notification API are also\nsubject to the condition that applications do not make use of location APIs, and\ndo not record or store location information from the device.\n\nEN respects the Android requirement for all Bluetooth scanning services to\nenable the device location setting. This requirement has been present in the\nAndroid platform since 2015, and is designed to protect the user's privacy by\npreventing apps from using nearby Bluetooth beacons to locate the user when the\nuser has explicitly turned off all location for the device.\n\nEnabling this setting by itself does _not_ mean that an application is using the\ndevice's location: the location runtime permission is _also_ required for any\napplication to access the device's location. Android users can still decide\nwhether any app they've installed has permission to access the location of their\ndevice, even if the device location setting is on.\n\n## Bandwidth usage\n\nThe decentralized model requires a larger amount of data to be downloaded by\neach device. In the EN, devices download a highly compressed version of 14 days\nworth of Rolling Proximity Identifiers of every COVID-positive user. Using daily\nexposure keys achieves approximately 100x compression by allowing the 15 minute\nRPIs to be regenerated from daily seeds. We estimate that 14 days' worth of\ndaily keys for 100,000 COVID-positive people is 22.4 MB. We recommend that EN\napps download keys when the device is connected to wifi and power if possible.\n\n## Use of connectionless protocol\n\nThe ENS uses a connectionless protocol. In our experience, protocols that\nrequire BLE connections or other forms of two-way interactions between\nparticipants' phones result in error-prone implementations, and can have\nsignificant negative effects on battery life. This led to a decision to use\nconnectionless BLE advertisements as part of the protocol. One consequence of\nthis is that the size of proximity identifiers is constrained to 20 bytes.\n\n# Risks and Mitigations\n\nThe following is an analysis of security and privacy risks to the system and its\nusers that were considered and mitigated to the extent possible within the above\ndesign constraints.\n\n## Disruption\n\n**Concern**\n\nAdversaries may attempt to disrupt the EN to create fraudulent exposure\nnotifications. Such fraudulent exposure notifications may result in\nindividuals or targeted groups unnecessarily self-quarantining. Disruptions\ncould also decrease the effectiveness of the system and increase its cost\nof operation to both users and networks by, for example, increasing\nbandwidth costs for users.\n\n### RPI Spoofing using reported diagnosis keys\n\n**Concern**\n\nAn adversary may try to use diagnosis keys downloaded from the server to\ngenerate and broadcast proximity identifiers in an attempt to create false\nENs to users receiving them.\n\n**Mitigations**\n\nThe EN implementations in both Android and iOS manage temporary exposure\nkeys on behalf of client apps. When a user tests positive, the user can\ninstruct their client app to upload their keys.\n\nBoth Android and iOS only return keys that are no longer in use. This means\nthat only expired keys are uploaded and revealed publicly. The matching\nalgorithm prevents a proximity identifier generated by expired keys from\nleading to Exposure Notifications, mitigating this replay attack scenario.\n\n### Relaying RPIs\n\n**Concern**\n\nAn adversary could record proximity identifiers being broadcast by\nlegitimate users and rebroadcast them elsewhere. This could be done for\nusers likely to be diagnosed soon thereafter\u2014for example, near a hospital\nor testing center\u2014and then rebroadcast to target a large number of users.\nAlternatively, a large number of collected RPIs could be rebroadcast over a\nlarge group, increasing the notification rate for that group in line with\nthe increased broadcast rate, effectively simulating being in a crowd.\n\nA second variant, where the adversary is able to compromise the test\nverification process, is to broadcast RPIs from Temporary Exposure Keys\n(TEKs) that are subsequently uploaded to a diagnosis key server.\n\n**Mitigations and considerations**\n\nWe acknowledge that a sophisticated adversary could mount relay attacks\nagainst our system but we note that:\n\n*   Any potential attack would require relayed broadcasts to persist for\n    as long as the Healthcare Authority app threshold for an exposure, for\n    example, 5-10 minute duration of close proximity to the target devices.\n    This would require high powered antennas for most targets, which both\n    increases the complexity of an attack and makes it more detectable.\n*   Potential device-based malware that rebroadcasts BLE RPIs\n    would have to be deployed at large scale to be successful. Any such malware\n    detected during Google Play's rigorous review process would be removed.\n*   Deploying fixed BLE listeners and broadcasters requires non-trivial\n    physical setup and a source of power, which puts adversaries and their\n    equipment at risk of discovery.\n*   A hypothetical attack of this type could readily be detected by\n    monitoring the rate of exposure notifications for anomalous changes that\n    are inconsistent with an epidemiologically realistic model and/or data\n    from other sources, such as manual contract tracing.\n\n    For example, if mutually independent sources\u2014e.g. test results and\n    manual contact tracing data\u2014show the infection rate is stable at 0.1% in\n    a specific area, but exposure notifications increase tenfold, this would\n    be a clear abuse signal.\n*   A mechanism to verify that keys uploaded are tied to a positive test\n    result is strongly recommended to all Health Authorities to limit the\n    ability to upload fake diagnosis keys.\n    Google has published a reference verification service design\n    [here](https://developers.google.com/android/exposure-notifications/verification-system)\n    and open source code\n    [here](https://github.com/google/exposure-notifications-verification-server).\n    This design is built with two foundational privacy goals in mind:\n\n    *   The diagnosis key server should not learn the identity of a\n        COVID-positive individual\n    *   The verification server and the Healthcare Authority should not\n        learn the TEKs of the COVID-positive individual\n\n#### Additional considerations\n\nRelay attacks are well understood and have been studied for many years:\nall mitigations require either location information, which creates a new\nprivacy risk for ENS, or precise timing information. Timing-based solutions\nare not feasible in this system since BLE packets can be relayed almost\ninstantaneously over the internet. Matching in ENS must be tolerant to\nlegitimate variations in timing such as processor speed. Distance-bounding\nprotocols that also rely on precise timing were discounted because they\nrequire a 2-way protocol (see [connectionless\nprotocols](#use-of-connectionless-protocol)) and the high degree of precision\nrequired is not supported by most BLE device firmware. That said, we\ncontinue to evaluate potential mitigations within the parameters of our\ndesign goals.\n\n**Concern**\n\nAssociated Encrypted Metadata (AEM) TX (transmit) power could be altered as\npart of a relay attack. We do not believe that TX power authentication\nwould be a useful defense against relay attacks for the following reasons:\n\n*   TX power authentication doesn't protect against the use of a\n    high-power antenna positioned to cover a large area with a signal strength\n    indicative of proximity. This is because the system is designed to be\n    highly tolerant of differences between TX-power and received signal\n    strength indicator (RSSI) caused, for example, by both devices being\n    in-pocket. The Android ecosystem also has a diverse range of hardware: some\n    Android devices transmit signals as much as 30dB weaker than others. The\n    required system tolerance to differences in transmit power means that\n    relaying a packet from such a weak device on a higher transmit power device\n    would already allow the higher power device to appear nearby without\n    altering the TX field.\n*   TX power authentication would not prevent the deployment of malware on\n    phones to perform relay packets; app-store and OS policy are more effective\n    to prevent collection of EN packets by third party apps.\n*   In this context, encrypting the AEM prevents an adversary from joining\n    between RPIs coming from the same device (using device-specific TX power\n    as a source of entropy).\n\n\n### Server data pollution\n\n**Concern**\n\nAn adversary broadcasts RPIs based on adversary-chosen diagnosis keys to\nmany targets, then fraudulently uploads the keys as if they belonged to a\nlegitimately diagnosed individual. Even without broadcasting RPIs based on\nthese keys, this could be used to disrupt the service since an excessive\nnumber of keys would result in unacceptable bandwidth and CPU usage to\ndownload and match keys on devices.\n\n**Mitigations**\n\n*   We strongly recommend that all Health Authorities implement a\n    mechanism to verify that keys uploaded are tied to a positive test result.\n    This will limit the ability to upload fake diagnosis keys. See [Relaying\n    RPIs](#relaying-rpis) for more details\n*   Servers are also strongly encouraged to implement standard denial of\n    service/abuse prevention mechanisms.\n\n## Learning COVID-positive status\n\n### Re-identification\n\n**Concern**\n\nDuring the 14 day exposure window, an adversary could collect a target's\nRolling Proximity Identifiers and then correlate them with published\ndiagnosis keys. The adversary (who could be a legitimate participant in EN)\ncould then identify the source of the exposure based on information\nexternal to the system, for example, using knowledge of who was present at\nthe same time and place.\n\nTo succeed, the adversary must simultaneously identify the specific target\n(visually, for example via number plate recognition, at a border control\npoint, physical access controls to buildings)\u00a0and record the RPI\ntransmitted by an EN app on the target's mobile device. If both can be done\nat the same time, the adversary can discover that the target was\nCOVID-positive after they upload their Temporary Exposure Keys (TEKs).\nIf multiple users of the EN app are within range, the adversary will have\nto distinguish between several users' RPIs, though signal strength could be\nused to narrow identification. Conclusive identification of the target's\ndiagnosis status might require several periods of RPI capture during the\nsame day. TEKs are randomly and independently generated using a\ncryptographic random number generator (see\n[EN Cryptography Specification](https://blog.google/documents/69/Exposure_Notification_-_Cryptography_Specification_v1.2.1.pdf)).\nTherefore, an adversary would have to carry out re-identification attacks\nseparately for each day.\n\n**Mitigations**\n\nThe core purpose of an EN system is to learn whether any COVID-positive\npeople have been close enough for long enough to put the device owner at\nrisk of infection. Without this ability, the system doesn't do what it was\ndesigned to. The alternative is not to operate an EN system at all. While\nENS apps do not have access to scanned RPIs via the ENS APIs, it's not\npossible to prevent a sophisticated adversary from capturing BLE RPIs using\na dedicated eavesdropping device.\n\n<a id=\"covid-positive\">With</a> this in mind, an important motivation in deciding between centralized\nand decentralized has been that COVID-positive status data presents less\nincremental risk to a person, and is less permanent than a person's social\ninteractions, which are exposed by a centralized approach. For example:\n\n*   COVID-positive status may only be accurate for a few days after\n    someone reports their diagnosis keys\n*   Many celebrities have publicly shared their COVID-positive status on\n    social media\n*   Governments keep records of COVID-positive individuals\u2014separate from\n    diagnosis key servers\u2014whether or not an ENS is in operation\n*   COVID-positive status is easily observed by other means; for example,\n    neighbors or the press can often observe if someone has been hospitalized\n*   Some already operational government contact tracing discloses a person's\n    COVID-positive status to their contacts\n\n#### Additional considerations\n\n**Split key** approaches are one proposed mitigation: multiple pieces\n(cryptographic secret shares) of an RPI, broadcast at different times, must\nbe observed before a match with a reported diagnosis key is possible. To\nsucceed, a re-identifying adversary would have to be near the target for\nlong enough to successfully match. We have not implemented such a scheme\nfor several reasons:\n\n*   The requirements for an adversary seem no different from the\n    Healthcare Authority-defined criteria for an exposure\n*   The risk of missing relevant contacts increases as the split key window\n    increases. Our design avoids situations where valid contacts are otherwise lost.\n*   The encounter duration threshold for a valid contact can be set by an EN\n    app's Healthcare Authority at matching time. A split key solution requires\n    this threshold to be decided at broadcast time, which reduces the\n    flexibility to modify duration thresholds, for example, in roaming scenarios.\n\nWe note that centralized solutions are also vulnerable to a targeted\nre-identification attack. In the centralized case, the adversary broadcasts\nRPIs in proximity to their target, shares the RPIS with the central\nservice, and then observes whether or not they receive an Exposure\nNotification.\n\n### Network traffic analysis\n\n**Concern**\n\nAn adversary could learn about infection status by observing network\ntraffic between devices and servers, including diagnosis servers.\n\n**Mitigations**\n\n*   Use Transport Layer Security (TLS) to protect the integrity and\n    confidentiality of network data.\n*   We recommend that Healthcare Authority apps make randomized requests to\n    servers to prevent an adversary from concluding a user was diagnosed based\n    on observing network traffic to the diagnosis server that only happens upon\n    diagnosis. This is implemented in the Google open-source sample app\n[here](https://github.com/google/exposure-notifications-android/blob/master/app/src/main/java/com/google/android/apps/exposurenotification/network/DiagnosisKeyUploader.java#L115).  \n\n### Diagnosis server compromise\n\n**Concern**\n\nAn adversary with access to the data on the diagnosis server could use this\ninformation to potentially identify users.\n\n**Mitigations**\n\nDiagnosis keys do not identify users. They are randomly generated and not\ninherently linked to individuals' identities. Each person's diagnosis keys\nare generated independently each day and are unrelated.\nGoogle's API Terms of Service forbid associating diagnosis keys with\npersonally identifiable information, or with other diagnosis keys from the\nsame device, except temporarily for verification purposes to support\ncertain already deployed verification flows. We also recommend that\ndiagnosis server operators limit retention of potentially identifiable\ninformation including, but not limited to, server logs that contain IP\naddresses.\n\n### Compromised mobile device\n\n**Concern**\n\nEN apps store information on-device that would allow an adversary to\ndetermine the device user's diagnosis status. For example, whether or not\nthe user is participating in EN and hasn't yet uploaded diagnosis keys.\n\n**Mitigations**\n\nAndroid includes multiple strong layers of defense against device\ncompromise, including [Google Play\nProtect](https://www.android.com/play-protect/). If an adversary is able to\ncompromise the device, much more sensitive information is available,\nincluding the user's contacts, messaging history, emails, and photos.\n\n### Forensics and physical access to devices\n\n**Concern**\n\nAn adversary with physical access to the device could extract historical\ninformation such as observed RPIs or the TEKs used to generate broadcast\nRPIs\n\n**Mitigations**\n\n*   Whenever a device supports full-disk encryption (FDE) or file-based\n\tencryption (FBE), all data stored on disk is encrypted using this\n\tstandard mechanism by default. For devices that do not support either of\n\tthese, encryption-at-rest of data has no benefit because the key would\n\tneed to be stored in plaintext alongside the data. Such encryption is\n\tmandatory on all devices running Android 10 and above and on all devices\n\trunning Android 6.0 or later, excluding low-RAM devices and devices on\n\twhich AES bulk encryption performance is below 50MB/s. \n\n*   Encryption of data sent to the server and stored by the HA app is\n\tthe responsibility of these apps. Google\u2019s sample app uses HTTPS and the\n\tdefault FBE implementation available. Disabling HTTPS requires the HA to\n\tset an explicit network security configuration setting in the APK\n\tmanifest.\n\n*   TEKs generated by the device are stored for 14 days before being\n\tdeleted by a daily maintenance process. The same is true for RPIs\n\tscanned by the device and matches detected. Note that Healthcare\n\tAuthorities are also responsible for handling TEKs when reporting a\n\tpositive diagnosis. In this case, storage and deletion are under the\n\tcontrol of the HA app.\n\n*   Even when an attacker has physical access to local storage, platform\n\tencryption protects the data. If an attacker were to try and compromise\n\tsystem integrity (rooting) this would require unlocking the bootloader,\n\twhich on all modern Android devices automatically wipes user data as a\n\tsecurity precaution.\n\n*   Android devices do not have swap partitions. Where the related\n\tfeature ``zram writeback`` is used, compressed RAM is written to the\n\t``/data/per_boot`` directory, which is encrypted with a newly generated key\n\ton each boot and stored only in RAM.\n\n*   Devices using a physical secure element (SE) and implementing\n\tFile-Based Encryption (FBE, introduced in Android 7.0 and mandatory on\n\tnew devices since Android 10) store the Key Derivation Function (KDF)\n\tsecret in the SE and destroy it upon Factory Data Reset (FDR), thus\n\trendering data irrecoverable;\n\n*   Devices using the SE in general provide non-recoverability guarantees\n\tthat are at least as strong as the physical and logical integrity of the\n\tSE.\n\n*   Even if they do not have a secure element (SE), devices running\n\teither FBE or full-disk encryption (FDE) generally require at least the\n\tphysical compromise of the flash memory to recover any data after FDR.\n\n## Learning social interactions\n\n**Concern**\n\nAn adversary could potentially identify a participant of EN as the origin\nof an Exposure Notification. This would also reveal social interactions\nsince it implies the two were in proximity.\n\nAn adversary with access to a device's EN APIs could feed a custom match\nquery to the provideDiagnosisKeys API with a known, identified diagnosis\nkey. If the API returns a match, the adversary knows that the individual\nwith the diagnosis key exposed the device owner, that they met, and for how\nlong.\n\nAn adversary could also feed a group of diagnosis keys to the API to learn\nif a user associated with the group of keys exposed the device owner. TEK\nmetadata could be used to increase the effectiveness of this potential\nattack by observing matching results for a subset of diagnosis keys, tagged\nusing TEK metadata. This could involve chaining between multiple\nobservations if metadata state changes are possible.\n\nLocation variant: If the RPIs associated with that group of diagnosis keys\nwere broadcast from a fixed location known to the adversary, the same\nattack could be used to learn about a target's location.\n\n**Mitigations**\n\nThis type of potential attack would require connecting a user's identity\nwith any diagnosis keys used in the attack. Mitigations against this attack\ninclude:\n\n1. Logging hashes of queries and making them exportable in the UI with the\nuser's consent. These keys can be pooled for analysis to detect targeted\nattacks.\n\n2. The diagnosis server must sign all key bundles used in matching. Invalid\nsignatures will result in an error upon matching. This prevents an attack\nvia a compromised app that submits malicious queries. This mechanism also\nlets servers control the queries made and rate-limit them.\n\n3. Starting with Exposure Notification API v1.5, Healthcare Authority apps\ncan only make six queries for `ExposureWindow` per day, reducing the\nrisk of brute force attacks of this type.\n\n4. Metadata state changes are limited to only one per key. Such state\nchanges are used, for example, to allow self-reported keys to transition to\na confirmed diagnosis.\n\n5. The API can only be called from a limited set of known, approved apps.\nThis means that an adversary must either have root-exploited the device or\nhas compromised an Exposure Notification app's code signing keys.\n\n6. Connecting diagnosis keys with a user's identity for any purpose other\nthan test verification is against\n[Google's additional terms of service for ENS apps](https://blog.google/documents/72/Exposure_Notifications_Service_Additional_Terms.pdf).\n\n#### Additional considerations\n\nRequiring a minimum query size would not help mitigate this attack\nbecause the API has no way to differentiate between a valid and invalid\ndiagnosis key. An adversary could fill the rest of the query with fake or\nCOVID-negative keys.\n\n## Tracking\n\n### Tracking COVID-positive users for the rolling window period using the Temporary Exposure Key\n\n**Concern**\n\nAn adversary with access to the downloaded TEKs could link a\nCOVID-positive user's RPIs for the duration of a rolling window period.\nUsing BLE sniffers in multiple places, an adversary could link together\ndifferent observations of the user over the rolling window period but not\nlonger.\n\nSee also [Learning Social Interactions: location\nvariant](#learning-social-interactions) above.\n\n**Mitigations and considerations**\n\nLinking Rolling Proximity Identifiers with a Temporary Exposure Key for the\nduration of the Rolling Window is a network compression mechanism that\nreduces bandwidth costs for all users by approximately 100X. (See\n[Bandwidth Usage](#bandwidth-usage) above). The impact of this\neffect is greater in high-population countries where bandwidth is\nrelatively costly. Our design must balance cost and network load with\nlimiting trackability. We note that:\n\n1.  This attack would allow trackability **only** **for declared\n    COVID-positive users** and only over the rolling period window, which is 24\n    hours in EN version 1.5. Users are clearly informed and can opt-out when\n    uploading TEKs following a positive diagnosis.\n2.  For users who have not consented to upload their diagnosis keys\n    following a positive COVID test result, an adversary cannot learn any more\n    about the user than they already can by sniffing BLE packets.\n\n    Rolling Proximity Identifiers are designed to be no more linkable than\n    standard Bluetooth broadcast packets, which include a frequently rotating\n    MAC address. Bluetooth Low-Energy (BLE) MAC addresses rotate at least every\n    15 minutes, at the same time as the EN RPI. Therefore, a COVID-negative\n    person's device can at most be recognized for 15 minutes by another device\n    within physical BLE range. RPI intervals are synchronized with these\n    rotating Bluetooth MAC addresses to prevent linking alternately based on\n    MAC address and RPI.\n\n    By restarting the BLE interface on RPI reset, EN creates a random rotation\n    interval for all devices that is synchronized with BLE MAC rotation. This\n    prevents the BLE MAC being used to bridge the RPI rotation.\n3.  This attack would require a large network of BLE sniffers.\n4.  Unless the adversary has an independent means (for example, a camera\n    network) of identifying users whose devices are transmitting BLE packets,\n    the adversary will not learn the identity of COVID-positive users. If an\n    adversary has a mechanism for identifying users in proximity, then they\n    could already use this to track the user's movements. Using EN does not\n    significantly increase tracking risks.\n5.  To reduce the impact on the user's network bandwidth, the rolling period\n    window is set at 24 hours but can be reduced in lower infection rate\n    scenarios to lessen risks.\n6.  The movements and interactions of COVID-positive users are revealed to a\n    much greater extent by some manual contact tracing methods.\n7.  Any app capturing BLE RPIs that is detected in Google Play's rigorous\n    review process would be removed from the Play Store.\n\n#### Additional considerations\n\n**Cuckoo filter approach as a mitigation**\n\nOne mitigation that has been proposed\n[[see DP3T White Paper](https://github.com/DP-3T/documents/blob/master/DP3T%20White%20Paper.pdf)]\nis to distribute RPIs using a cuckoo filter rather than using temporary\nexposure keys and a pseudo-random function as in the current EN design.\n\nA cuckoo filter approach trades a reduction in bandwidth usage for a\nhigher number of false-positives and reduced trackability. We decided\nagainst this approach because achieving an acceptable number of\nfalse-positives would require excessive bandwidth and device storage\nconsumption.\n\nAn in-depth analysis of the tolerable false-positive rate as part of our\ninitial design led us to use 128-bit RPIs. Reaching a similarly low\nfalse-positive rate would make the use of cuckoo filters unfeasible from a\nbandwidth and storage perspective, given that the cuckoo filter is used for\nmatching with RPIs, 144x more of them than Temporary Exposure Keys. For\nexample, even allowing for a significantly higher false-positive rate for\nlarge deployments, for a daily infection rate of 60,000 with 50 million\nusers, the download sizes required by each user would be over 1 GB per day.\n\nUnlike our current design, another concern with the use of cuckoo filters\nis that a match can be caused without the knowledge of the TEK that\ngenerated that RPI value. This means that clients performing RPI matching\ncannot verify that a corresponding TEK from which they were derived was\nreleased, or when they were supposed to be broadcast. This makes the time\nwindow for messages to be replayed longer.\n\nUsing a cuckoo filter as a first stage match with a full check following\nwould leak information about the user's social interactions to the server,\nwhich goes against a core privacy property of the system.\n\n### Bluetooth-based tracking\n\n**Concern**\n\nSwitching on Bluetooth for users who had it switched off enables any\ntracking risk present with the standard Bluetooth stack.\n\n**Mitigations and considerations**\n\nThe incremental risk of turning Bluetooth on to enable EN should be\nconsidered small because:\n\n*   All BLE packet MAC addresses rotate at least every 15 minutes in sync\n    with the EN RPI. At most, a person's device can be recognized for 15\n    minutes by another device within physical BLE range.\n*   7-15 minute rotating BLE advertising IDs are used by Android devices\n    starting with Android Marshmallow, that is approximately 80% of devices in\n    use. A large percentage of pre-Marshmallow devices do not have BLE, and\n    would therefore not be able to run EN. Bluetooth Classic uses a fixed MAC\n    address but this is only advertised if the device is in discoverable mode,\n    that is when Bluetooth settings are open or when an app has triggered this\n    mode, with a short timeout. Some manufacturers' Android devices enable\n    Bluetooth Classic in discoverable mode whenever Bluetooth is turned on. We\n    have notified, and are working with, affected manufacturers to fix this\n    vulnerability. In the meantime, on Android, we turn off discoverability the\n    first time EN is run, and every 24 hours thereafter.\n*   Unless the adversary has an independent means of identifying users whose\n    devices are transmitting BLE packets ( for example, a network of cameras)\n    an adversary could not learn the identity of users or anything about who\n    associates with whom. If an adversary has a mechanism for identifying users\n    in proximity, then they can already use this to track the users' movements,\n    and BLE does not introduce additional risk.\n\n**Bridging rotations at MAC/RPI boundaries**\n\nMAC and RPI rotations are designed to protect against adversaries\nobserving the device\u2019s BLE emissions across different locations and\ntimes, rather than continuously. For example, this mitigation protects\nagainst an adversary putting BLE sniffers in multiple train stations\nacross a city, or against a store owner who links a user\u2019s prior\npurchases to their path around the store.\n\nConversely, protecting against an adversary who can continuously collect\nevery BLE frame emitted by a device is not a design goal for either MAC\nor RPI rotation.\n\n*   This attack requires continuous proximity; an adversary would need\n    to have an independent means of tracking the user\u2019s location, or a\n    spatially continuous network of sensors. For example, in order to track\n    a device leaving from home at 0900, going to a coffee shop at 0930, and\n    then to the library at 1100, the attacker must observe all 0915, 0930,\n    0945, 1000, \u2026 1100 rotation events. If they could only observe the 0900\n    and 1100 rotations they would not be able to deduce that those were the\n    same device. \n\n*   While this means that such attacks aren\u2019t useful for an adversary,\n    it\u2019s worth noting that the ability to bridge between temporally adjacent\n    broadcast IDs is inherent in the use of any RF protocol since: \n\n    *   Adjacent timestamps can be used to link sources across frames\n\n    *   Signal strength can be assumed to be invariant between adjacent frames\n        and can therefore also be used to link sources across frames.\n\n### Linking diagnosis keys through export file analysis\n\n**Concern**\n\nAn adversary could attempt to link Diagnosis Keys from different days\u2014which\nare independently randomly generated and _a priori_ not linkable\u2014based on\nanalysis of Diagnosis Key batches served by the Diagnosis server.\n\n**Mitigations**\n\n*   This may be feasible specifically in situations where very few\n    individuals are diagnosed positive in a given timeframe. If a diagnosis key\n    batch only contains one diagnosis key for each day, the keys in the batch\n    must correspond to the same individual. To mitigate this potential for\n    correlation, we recommend that diagnosis key servers pad out diagnosis key\n    batches with random keys, with some jitter so exports don't leak the fact\n    that they were padded. This is implemented in our reference server\n    ([code](https://github.com/google/exposure-notifications-server/blob/821531b167d794ec4a57075cd2009adbcd137505/internal/export/worker.go#L358)).\n*   The natural order in which diagnosis keys are stored in the diagnosis\n    server's database may confer some information about their association at\n    time of upload. To ensure this information is not leaked in diagnosis key\n    export batches, we recommend that batches are re-ordered before\n    publication, as we've done in our\n    [reference implementation](https://github.com/google/exposure-notifications-server/blob/1aef0fbe22aef93ec86f5432dd9d0317418eba15/internal/export/exportfile.go#L139).\n\n### Feedback\n\nIf you have questions or feedback about this document, please let us know by\nemailing [ens-privsec@google.com](mailto:ens-privsec@google.com).\n"], "fixing_code": ["# Exposure Notification: Risks and Mitigations FAQ\n\nThis document explains the key design decisions that affect the privacy and\nsecurity of the Google/Apple Exposure Notifications system (ENS), the risks that\nwere evaluated, and the mitigations that are in place for these risks. Details\nof the ENS design can be found\n[here](https://www.google.com/covid19/exposurenotifications/).\n\n# Key design decisions and constraints relevant to security and privacy\n\n## Decentralized architecture\n\nThe design of an effective exposure notification system requires trade-offs\nbetween efficacy, privacy, and security. A common way of categorizing contact\ntracing and Exposure Notification designs is between:\n\n1.  **Centralized.** A central service makes decisions about whether to\n    notify someone if they have been exposed or not. Centralized designs\n    require devices to share a list of observed Bluetooth identifiers with a\n    central notification service.\n2.  **Decentralized.** The user's device decides locally whether to notify\n    someone if they have been exposed or not. Decentralized designs require\n    devices to receive a list of all COVID-positive users' broadcast Bluetooth\n    identifiers.\n\nThe Google/Apple design uses a decentralized architecture because:\n\n1.  Devices of COVID-negative users do not share any information about\n    social interactions, location, or infection status. Decentralized designs\n    provide better privacy protection for COVID-negative participants compared\n    to centralized designs, since they do not require sharing any information\n    with a central service unless a user declares themselves COVID-positive.\n    This is especially important since we assume that the vast majority of\n    participants will be COVID-negative.\n    In contrast, centralized designs have the property that any party with\n    access to the central service has access to observed Bluetooth Low Energy\n    (BLE) identifiers\u2014and therefore information about social interactions\u2014for\n    all participants, including those who have not declared themselves as\n    COVID-positive.\n2.  For COVID-positive users, the information shared with the server in a\n    decentralized model is their COVID-positive status rather than any\n    information about social interactions: decentralized designs require\n    sharing broadcast Rolling Proximity Identifiers (RPIs) of COVID-positive\n    users with all participating devices (usually via a central service).\n    Centralized designs expose users' social interactions to a central service\n    in order to receive notifications. Even if care is taken not to store\n    information on relationships, the centralized designs inherently risk that\n    this information may be obtained by an adversary.\n    COVID-positive status data presents less incremental risk to the user and\n    is less permanent than a person's social interactions: see\n    [here](#covid-positive) for more details.\n3.  Centralized designs also expose COVID-positive status. While centralized\n    designs can minimize information revealed to the public at large, and make\n    such attacks more difficult, they cannot prevent attacks that identify\n    COVID-positive users entirely.\n    In a centralized model an adversary can emit Bluetooth IDs in the vicinity\n    of a device whose owner has been identified via other means, for example,\n    by using vehicle number plate recognition. Once this device reports its\n    owner as COVID-positive, the adversary's device will receive an exposure\n    notification, which can be tied to the identified user. If they want to do\n    this multiple times, however, they would need to have a single Healthcare\n    Authority account, that is notification channel, per identified user.\n    Healthcare Authority diagnosis servers could implement defenses against\n    Sybil attacks using multiple accounts, but this could put legitimate users\n    at higher risk of being falsely excluded from receiving exposure notifications.\n\n## Location\n\nLocation data from the device is not used by the Google/Apple EN API in any\nway.\n\nHealthcare Authority applications using the Exposure Notification API are also\nsubject to the condition that applications do not make use of location APIs, and\ndo not record or store location information from the device.\n\nEN respects the Android requirement for all Bluetooth scanning services to\nenable the device location setting. This requirement has been present in the\nAndroid platform since 2015, and is designed to protect the user's privacy by\npreventing apps from using nearby Bluetooth beacons to locate the user when the\nuser has explicitly turned off all location for the device.\n\nEnabling this setting by itself does _not_ mean that an application is using the\ndevice's location: the location runtime permission is _also_ required for any\napplication to access the device's location. Android users can still decide\nwhether any app they've installed has permission to access the location of their\ndevice, even if the device location setting is on.\n\n## Bandwidth usage\n\nThe decentralized model requires a larger amount of data to be downloaded by\neach device. In the EN, devices download a highly compressed version of 14 days\nworth of Rolling Proximity Identifiers of every COVID-positive user. Using daily\nexposure keys achieves approximately 100x compression by allowing the 15 minute\nRPIs to be regenerated from daily seeds. We estimate that 14 days' worth of\ndaily keys for 100,000 COVID-positive people is 22.4 MB. We recommend that EN\napps download keys when the device is connected to wifi and power if possible.\n\n## Use of connectionless protocol\n\nThe ENS uses a connectionless protocol. In our experience, protocols that\nrequire BLE connections or other forms of two-way interactions between\nparticipants' phones result in error-prone implementations, and can have\nsignificant negative effects on battery life. This led to a decision to use\nconnectionless BLE advertisements as part of the protocol. One consequence of\nthis is that the size of proximity identifiers is constrained to 20 bytes.\n\n# Risks and Mitigations\n\nThe following is an analysis of security and privacy risks to the system and its\nusers that were considered and mitigated to the extent possible within the above\ndesign constraints.\n\n## Disruption\n\n**Concern**\n\nAdversaries may attempt to disrupt the EN to create fraudulent exposure\nnotifications. Such fraudulent exposure notifications may result in\nindividuals or targeted groups unnecessarily self-quarantining. Disruptions\ncould also decrease the effectiveness of the system and increase its cost\nof operation to both users and networks by, for example, increasing\nbandwidth costs for users.\n\n### RPI Spoofing using reported diagnosis keys\n\n**Concern**\n\nAn adversary may try to use diagnosis keys downloaded from the server to\ngenerate and broadcast proximity identifiers in an attempt to create false\nENs to users receiving them.\n\n**Mitigations**\n\nThe EN implementations in both Android and iOS manage temporary exposure\nkeys on behalf of client apps. When a user tests positive, the user can\ninstruct their client app to upload their keys.\n\nBoth Android and iOS only return keys that are no longer in use. This means\nthat only expired keys are uploaded and revealed publicly. The matching\nalgorithm prevents a proximity identifier generated by expired keys from\nleading to Exposure Notifications, mitigating this replay attack scenario.\n\n### Relaying RPIs\n\n**Concern**\n\nAn adversary could record proximity identifiers being broadcast by\nlegitimate users and rebroadcast them elsewhere. This could be done for\nusers likely to be diagnosed soon thereafter\u2014for example, near a hospital\nor testing center\u2014and then rebroadcast to target a large number of users.\nAlternatively, a large number of collected RPIs could be rebroadcast over a\nlarge group, increasing the notification rate for that group in line with\nthe increased broadcast rate, effectively simulating being in a crowd.\n\nA second variant, where the adversary is able to compromise the test\nverification process, is to broadcast RPIs from Temporary Exposure Keys\n(TEKs) that are subsequently uploaded to a diagnosis key server.\n\n**Mitigations and considerations**\n\nWe acknowledge that a sophisticated adversary could mount relay attacks\nagainst our system but we note that:\n\n*   Any potential attack would require relayed broadcasts to persist for\n    as long as the Healthcare Authority app threshold for an exposure, for\n    example, 5-10 minute duration of close proximity to the target devices.\n    This would require high powered antennas for most targets, which both\n    increases the complexity of an attack and makes it more detectable.\n*   Potential device-based malware that rebroadcasts BLE RPIs\n    would have to be deployed at large scale to be successful. Any such malware\n    detected during Google Play's rigorous review process would be removed.\n*   Deploying fixed BLE listeners and broadcasters requires non-trivial\n    physical setup and a source of power, which puts adversaries and their\n    equipment at risk of discovery.\n*   A hypothetical attack of this type could readily be detected by\n    monitoring the rate of exposure notifications for anomalous changes that\n    are inconsistent with an epidemiologically realistic model and/or data\n    from other sources, such as manual contract tracing.\n\n    For example, if mutually independent sources\u2014e.g. test results and\n    manual contact tracing data\u2014show the infection rate is stable at 0.1% in\n    a specific area, but exposure notifications increase tenfold, this would\n    be a clear abuse signal.\n*   A mechanism to verify that keys uploaded are tied to a positive test\n    result is strongly recommended to all Health Authorities to limit the\n    ability to upload fake diagnosis keys.\n    Google has published a reference verification service design\n    [here](https://developers.google.com/android/exposure-notifications/verification-system)\n    and open source code\n    [here](https://github.com/google/exposure-notifications-verification-server).\n    This design is built with two foundational privacy goals in mind:\n\n    *   The diagnosis key server should not learn the identity of a\n        COVID-positive individual\n    *   The verification server and the Healthcare Authority should not\n        learn the TEKs of the COVID-positive individual\n\n#### Additional considerations\n\nRelay attacks are well understood and have been studied for many years:\nall mitigations require either location information, which creates a new\nprivacy risk for ENS, or precise timing information. Timing-based solutions\nare not feasible in this system since BLE packets can be relayed almost\ninstantaneously over the internet. Matching in ENS must be tolerant to\nlegitimate variations in timing such as processor speed. Distance-bounding\nprotocols that also rely on precise timing were discounted because they\nrequire a 2-way protocol (see [connectionless\nprotocols](#use-of-connectionless-protocol)) and the high degree of precision\nrequired is not supported by most BLE device firmware. That said, we\ncontinue to evaluate potential mitigations within the parameters of our\ndesign goals.\n\n**Concern**\n\nAssociated Encrypted Metadata (AEM) TX (transmit) power could be altered as\npart of a relay attack. We do not believe that TX power authentication\nwould be a useful defense against relay attacks for the following reasons:\n\n*   TX power authentication doesn't protect against the use of a\n    high-power antenna positioned to cover a large area with a signal strength\n    indicative of proximity. This is because the system is designed to be\n    highly tolerant of differences between TX-power and received signal\n    strength indicator (RSSI) caused, for example, by both devices being\n    in-pocket. The Android ecosystem also has a diverse range of hardware: some\n    Android devices transmit signals as much as 30dB weaker than others. The\n    required system tolerance to differences in transmit power means that\n    relaying a packet from such a weak device on a higher transmit power device\n    would already allow the higher power device to appear nearby without\n    altering the TX field.\n*   TX power authentication would not prevent the deployment of malware on\n    phones to perform relay packets; app-store and OS policy are more effective\n    to prevent collection of EN packets by third party apps.\n*   In this context, encrypting the AEM prevents an adversary from joining\n    between RPIs coming from the same device (using device-specific TX power\n    as a source of entropy).\n\n\n### Server data pollution\n\n**Concern**\n\nAn adversary broadcasts RPIs based on adversary-chosen diagnosis keys to\nmany targets, then fraudulently uploads the keys as if they belonged to a\nlegitimately diagnosed individual. Even without broadcasting RPIs based on\nthese keys, this could be used to disrupt the service since an excessive\nnumber of keys would result in unacceptable bandwidth and CPU usage to\ndownload and match keys on devices.\n\n**Mitigations**\n\n*   We strongly recommend that all Health Authorities implement a\n    mechanism to verify that keys uploaded are tied to a positive test result.\n    This will limit the ability to upload fake diagnosis keys. See [Relaying\n    RPIs](#relaying-rpis) for more details\n*   Servers are also strongly encouraged to implement standard denial of\n    service/abuse prevention mechanisms.\n\n## Learning COVID-positive status\n\n### Re-identification\n\n**Concern**\n\nDuring the 14 day exposure window, an adversary could collect a target's\nRolling Proximity Identifiers and then correlate them with published\ndiagnosis keys. The adversary (who could be a legitimate participant in EN)\ncould then identify the source of the exposure based on information\nexternal to the system, for example, using knowledge of who was present at\nthe same time and place.\n\nTo succeed, the adversary must simultaneously identify the specific target\n(visually, for example via number plate recognition, at a border control\npoint, physical access controls to buildings)\u00a0and record the RPI\ntransmitted by an EN app on the target's mobile device. If both can be done\nat the same time, the adversary can discover that the target was\nCOVID-positive after they upload their Temporary Exposure Keys (TEKs).\nIf multiple users of the EN app are within range, the adversary will have\nto distinguish between several users' RPIs, though signal strength could be\nused to narrow identification. Conclusive identification of the target's\ndiagnosis status might require several periods of RPI capture during the\nsame day. TEKs are randomly and independently generated using a\ncryptographic random number generator (see\n[EN Cryptography Specification](https://blog.google/documents/69/Exposure_Notification_-_Cryptography_Specification_v1.2.1.pdf)).\nTherefore, an adversary would have to carry out re-identification attacks\nseparately for each day.\n\n**Mitigations**\n\nThe core purpose of an EN system is to learn whether any COVID-positive\npeople have been close enough for long enough to put the device owner at\nrisk of infection. Without this ability, the system doesn't do what it was\ndesigned to. The alternative is not to operate an EN system at all. While\nENS apps do not have access to scanned RPIs via the ENS APIs, it's not\npossible to prevent a sophisticated adversary from capturing BLE RPIs using\na dedicated eavesdropping device.\n\n<a id=\"covid-positive\">With</a> this in mind, an important motivation in deciding between centralized\nand decentralized has been that COVID-positive status data presents less\nincremental risk to a person, and is less permanent than a person's social\ninteractions, which are exposed by a centralized approach. For example:\n\n*   COVID-positive status may only be accurate for a few days after\n    someone reports their diagnosis keys\n*   Many celebrities have publicly shared their COVID-positive status on\n    social media\n*   Governments keep records of COVID-positive individuals\u2014separate from\n    diagnosis key servers\u2014whether or not an ENS is in operation\n*   COVID-positive status is easily observed by other means; for example,\n    neighbors or the press can often observe if someone has been hospitalized\n*   Some already operational government contact tracing discloses a person's\n    COVID-positive status to their contacts\n\n#### Additional considerations\n\n**Split key** approaches are one proposed mitigation: multiple pieces\n(cryptographic secret shares) of an RPI, broadcast at different times, must\nbe observed before a match with a reported diagnosis key is possible. To\nsucceed, a re-identifying adversary would have to be near the target for\nlong enough to successfully match. We have not implemented such a scheme\nfor several reasons:\n\n*   The requirements for an adversary seem no different from the\n    Healthcare Authority-defined criteria for an exposure\n*   The risk of missing relevant contacts increases as the split key window\n    increases. Our design avoids situations where valid contacts are otherwise lost.\n*   The encounter duration threshold for a valid contact can be set by an EN\n    app's Healthcare Authority at matching time. A split key solution requires\n    this threshold to be decided at broadcast time, which reduces the\n    flexibility to modify duration thresholds, for example, in roaming scenarios.\n\nWe note that centralized solutions are also vulnerable to a targeted\nre-identification attack. In the centralized case, the adversary broadcasts\nRPIs in proximity to their target, shares the RPIS with the central\nservice, and then observes whether or not they receive an Exposure\nNotification.\n\n### Network traffic analysis\n\n**Concern**\n\nAn adversary could learn about infection status by observing network\ntraffic between devices and servers, including diagnosis servers.\n\n**Mitigations**\n\n*   Use Transport Layer Security (TLS) to protect the integrity and\n    confidentiality of network data.\n*   We recommend that Healthcare Authority apps make randomized requests to\n    servers to prevent an adversary from concluding a user was diagnosed based\n    on observing network traffic to the diagnosis server that only happens upon\n    diagnosis. This is implemented in the Google open-source sample app\n[here](https://github.com/google/exposure-notifications-android/blob/master/app/src/main/java/com/google/android/apps/exposurenotification/network/DiagnosisKeyUploader.java#L115).  \n\n### Diagnosis server compromise\n\n**Concern**\n\nAn adversary with access to the data on the diagnosis server could use this\ninformation to potentially identify users.\n\n**Mitigations**\n\nDiagnosis keys do not identify users. They are randomly generated and not\ninherently linked to individuals' identities. Each person's diagnosis keys\nare generated independently each day and are unrelated.\nGoogle's API Terms of Service forbid associating diagnosis keys with\npersonally identifiable information, or with other diagnosis keys from the\nsame device, except temporarily for verification purposes to support\ncertain already deployed verification flows. We also recommend that\ndiagnosis server operators limit retention of potentially identifiable\ninformation including, but not limited to, server logs that contain IP\naddresses.\n\n### Compromised mobile device\n\n**Concern**\n\nEN apps store information on-device that would allow an adversary to\ndetermine the device user's diagnosis status. For example, whether or not\nthe user is participating in EN and hasn't yet uploaded diagnosis keys.\n\n**Mitigations**\n\nAndroid includes multiple strong layers of defense against device\ncompromise, including [Google Play\nProtect](https://www.android.com/play-protect/). If an adversary is able to\ncompromise the device, much more sensitive information is available,\nincluding the user's contacts, messaging history, emails, and photos.\n\n### Forensics and physical access to devices\n\n**Concern**\n\nAn adversary with physical access to the device could extract historical\ninformation such as observed RPIs or the TEKs used to generate broadcast\nRPIs\n\n**Mitigations**\n\n*   Whenever a device supports full-disk encryption (FDE) or file-based\n\tencryption (FBE), all data stored on disk is encrypted using this\n\tstandard mechanism by default. For devices that do not support either of\n\tthese, encryption-at-rest of data has no benefit because the key would\n\tneed to be stored in plaintext alongside the data. Such encryption is\n\tmandatory on all devices running Android 10 and above and on all devices\n\trunning Android 6.0 or later, excluding low-RAM devices and devices on\n\twhich AES bulk encryption performance is below 50MB/s. \n\n*   Encryption of data sent to the server and stored by the HA app is\n\tthe responsibility of these apps. Google\u2019s sample app uses HTTPS and the\n\tdefault FBE implementation available. Disabling HTTPS requires the HA to\n\tset an explicit network security configuration setting in the APK\n\tmanifest.\n\n*   TEKs generated by the device are stored for 14 days before being\n\tdeleted by a daily maintenance process. The same is true for RPIs\n\tscanned by the device and matches detected. Note that Healthcare\n\tAuthorities are also responsible for handling TEKs when reporting a\n\tpositive diagnosis. In this case, storage and deletion are under the\n\tcontrol of the HA app.\n\n*   Even when an attacker has physical access to local storage, platform\n\tencryption protects the data. If an attacker were to try and compromise\n\tsystem integrity (rooting) this would require unlocking the bootloader,\n\twhich on all modern Android devices automatically wipes user data as a\n\tsecurity precaution.\n\n*   Android devices do not have swap partitions. Where the related\n\tfeature ``zram writeback`` is used, compressed RAM is written to the\n\t``/data/per_boot`` directory, which is encrypted with a newly generated key\n\ton each boot and stored only in RAM.\n\n*   Devices using a physical secure element (SE) and implementing\n\tFile-Based Encryption (FBE, introduced in Android 7.0 and mandatory on\n\tnew devices since Android 10) store the Key Derivation Function (KDF)\n\tsecret in the SE and destroy it upon Factory Data Reset (FDR), thus\n\trendering data irrecoverable;\n\n*   Devices using the SE in general provide non-recoverability guarantees\n\tthat are at least as strong as the physical and logical integrity of the\n\tSE.\n\n*   Even if they do not have a secure element (SE), devices running\n\teither FBE or full-disk encryption (FDE) generally require at least the\n\tphysical compromise of the flash memory to recover any data after FDR.\n\n## Learning social interactions\n\n**Concern**\n\nAn adversary could potentially identify a participant of EN as the origin\nof an Exposure Notification. This would also reveal social interactions\nsince it implies the two were in proximity.\n\nAn adversary with access to a device's EN APIs could feed a custom match\nquery to the provideDiagnosisKeys API with a known, identified diagnosis\nkey. If the API returns a match, the adversary knows that the individual\nwith the diagnosis key exposed the device owner, that they met, and for how\nlong.\n\nAn adversary could also feed a group of diagnosis keys to the API to learn\nif a user associated with the group of keys exposed the device owner. TEK\nmetadata could be used to increase the effectiveness of this potential\nattack by observing matching results for a subset of diagnosis keys, tagged\nusing TEK metadata. This could involve chaining between multiple\nobservations if metadata state changes are possible.\n\nLocation variant: If the RPIs associated with that group of diagnosis keys\nwere broadcast from a fixed location known to the adversary, the same\nattack could be used to learn about a target's location.\n\n**Mitigations**\n\nThis type of potential attack would require connecting a user's identity\nwith any diagnosis keys used in the attack. Mitigations against this attack\ninclude:\n\n1. Logging hashes of queries and making them exportable in the UI with the\nuser's consent. These keys can be pooled for analysis to detect targeted\nattacks.\n\n2. The diagnosis server must sign all key bundles used in matching. Invalid\nsignatures will result in an error upon matching. This prevents an attack\nvia a compromised app that submits malicious queries. This mechanism also\nlets servers control the queries made and rate-limit them.\n\n3. Starting with Exposure Notification API v1.5, Healthcare Authority apps\ncan only make six queries for `ExposureWindow` per day, reducing the\nrisk of brute force attacks of this type.\n\n4. Metadata state changes are limited to only one per key. Such state\nchanges are used, for example, to allow self-reported keys to transition to\na confirmed diagnosis.\n\n5. The API can only be called from a limited set of known, approved apps.\nThis means that an adversary must either have root-exploited the device or\nhas compromised an Exposure Notification app's code signing keys.\n\n6. Connecting diagnosis keys with a user's identity for any purpose other\nthan test verification is against\n[Google's additional terms of service for ENS apps](https://blog.google/documents/72/Exposure_Notifications_Service_Additional_Terms.pdf).\n\n#### Additional considerations\n\nRequiring a minimum query size would not help mitigate this attack\nbecause the API has no way to differentiate between a valid and invalid\ndiagnosis key. An adversary could fill the rest of the query with fake or\nCOVID-negative keys.\n\n## Tracking\n\n### Tracking COVID-positive users for the rolling window period using the Temporary Exposure Key\n\n**Concern**\n\nAn adversary with access to the downloaded TEKs could link a\nCOVID-positive user's RPIs for the duration of a rolling window period.\nUsing BLE sniffers in multiple places, an adversary could link together\ndifferent observations of the user over the rolling window period but not\nlonger.\n\nSee also [Learning Social Interactions: location\nvariant](#learning-social-interactions) above.\n\n**Mitigations and considerations**\n\nLinking Rolling Proximity Identifiers with a Temporary Exposure Key for the\nduration of the Rolling Window is a network compression mechanism that\nreduces bandwidth costs for all users by approximately 100X. (See\n[Bandwidth Usage](#bandwidth-usage) above). The impact of this\neffect is greater in high-population countries where bandwidth is\nrelatively costly. Our design must balance cost and network load with\nlimiting trackability. We note that:\n\n1.  This attack would allow trackability **only** **for declared\n    COVID-positive users** and only over the rolling period window, which is 24\n    hours in EN version 1.5. Users are clearly informed and can opt-out when\n    uploading TEKs following a positive diagnosis.\n2.  For users who have not consented to upload their diagnosis keys\n    following a positive COVID test result, an adversary cannot learn any more\n    about the user than they already can by sniffing BLE packets.\n\n    Rolling Proximity Identifiers are designed to be no more linkable than\n    standard Bluetooth broadcast packets, which include a frequently rotating\n    MAC address. Bluetooth Low-Energy (BLE) MAC addresses rotate at least every\n    15 minutes, at the same time as the EN RPI. Therefore, a COVID-negative\n    person's device can at most be recognized for 15 minutes by another device\n    within physical BLE range. RPI intervals are synchronized with these\n    rotating Bluetooth MAC addresses to prevent linking alternately based on\n    MAC address and RPI.\n\n    By restarting the BLE interface on RPI reset, EN creates a random rotation\n    interval for all devices that is synchronized with BLE MAC rotation. This\n    prevents the BLE MAC being used to bridge the RPI rotation.\n3.  This attack would require a large network of BLE sniffers.\n4.  Unless the adversary has an independent means (for example, a camera\n    network) of identifying users whose devices are transmitting BLE packets,\n    the adversary will not learn the identity of COVID-positive users. If an\n    adversary has a mechanism for identifying users in proximity, then they\n    could already use this to track the user's movements. Using EN does not\n    significantly increase tracking risks.\n5.  To reduce the impact on the user's network bandwidth, the rolling period\n    window is set at 24 hours but can be reduced in lower infection rate\n    scenarios to lessen risks.\n6.  The movements and interactions of COVID-positive users are revealed to a\n    much greater extent by some manual contact tracing methods.\n7.  Google Play\u2019s policies forbid the malicious use of BLE scanning, and\n    Play\u2019s rigorous review processes are designed to detect it. Any app\n    found to be explicitly capturing BLE RPIs will be removed.\n\t\n#### Additional considerations\n\n**Cuckoo filter approach as a mitigation**\n\nOne mitigation that has been proposed\n[[see DP3T White Paper](https://github.com/DP-3T/documents/blob/master/DP3T%20White%20Paper.pdf)]\nis to distribute RPIs using a cuckoo filter rather than using temporary\nexposure keys and a pseudo-random function as in the current EN design.\n\nA cuckoo filter approach trades a reduction in bandwidth usage for a\nhigher number of false-positives and reduced trackability. We decided\nagainst this approach because achieving an acceptable number of\nfalse-positives would require excessive bandwidth and device storage\nconsumption.\n\nAn in-depth analysis of the tolerable false-positive rate as part of our\ninitial design led us to use 128-bit RPIs. Reaching a similarly low\nfalse-positive rate would make the use of cuckoo filters unfeasible from a\nbandwidth and storage perspective, given that the cuckoo filter is used for\nmatching with RPIs, 144x more of them than Temporary Exposure Keys. For\nexample, even allowing for a significantly higher false-positive rate for\nlarge deployments, for a daily infection rate of 60,000 with 50 million\nusers, the download sizes required by each user would be over 1 GB per day.\n\nUnlike our current design, another concern with the use of cuckoo filters\nis that a match can be caused without the knowledge of the TEK that\ngenerated that RPI value. This means that clients performing RPI matching\ncannot verify that a corresponding TEK from which they were derived was\nreleased, or when they were supposed to be broadcast. This makes the time\nwindow for messages to be replayed longer.\n\nUsing a cuckoo filter as a first stage match with a full check following\nwould leak information about the user's social interactions to the server,\nwhich goes against a core privacy property of the system.\n\n### Bluetooth-based tracking\n\n**Concern**\n\nSwitching on Bluetooth for users who had it switched off enables any\ntracking risk present with the standard Bluetooth stack.\n\n**Mitigations and considerations**\n\nThe incremental risk of turning Bluetooth on to enable EN should be\nconsidered small because:\n\n*   All BLE packet MAC addresses rotate at least every 15 minutes in sync\n    with the EN RPI. At most, a person's device can be recognized for 15\n    minutes by another device within physical BLE range.\n*   7-15 minute rotating BLE advertising IDs are used by Android devices\n    starting with Android Marshmallow, that is approximately 80% of devices in\n    use. A large percentage of pre-Marshmallow devices do not have BLE, and\n    would therefore not be able to run EN. Bluetooth Classic uses a fixed MAC\n    address but this is only advertised if the device is in discoverable mode,\n    that is when Bluetooth settings are open or when an app has triggered this\n    mode, with a short timeout. Some manufacturers' Android devices enable\n    Bluetooth Classic in discoverable mode whenever Bluetooth is turned on. We\n    have notified, and are working with, affected manufacturers to fix this\n    vulnerability. In the meantime, on Android, we turn off discoverability the\n    first time EN is run, and every 24 hours thereafter.\n*   Unless the adversary has an independent means of identifying users whose\n    devices are transmitting BLE packets ( for example, a network of cameras)\n    an adversary could not learn the identity of users or anything about who\n    associates with whom. If an adversary has a mechanism for identifying users\n    in proximity, then they can already use this to track the users' movements,\n    and BLE does not introduce additional risk.\n\n**Bridging rotations at MAC/RPI boundaries**\n\nMAC and RPI rotations are designed to protect against adversaries\nobserving the device\u2019s BLE emissions across different locations and\ntimes, rather than continuously. For example, this mitigation protects\nagainst an adversary putting BLE sniffers in multiple train stations\nacross a city, or against a store owner who links a user\u2019s prior\npurchases to their path around the store.\n\nConversely, protecting against an adversary who can continuously collect\nevery BLE frame emitted by a device is not a design goal for either MAC\nor RPI rotation.\n\n*   This attack requires continuous proximity; an adversary would need\n    to have an independent means of tracking the user\u2019s location, or a\n    spatially continuous network of sensors. For example, in order to track\n    a device leaving from home at 0900, going to a coffee shop at 0930, and\n    then to the library at 1100, the attacker must observe all 0915, 0930,\n    0945, 1000, \u2026 1100 rotation events. If they could only observe the 0900\n    and 1100 rotations they would not be able to deduce that those were the\n    same device. \n\n*   While this means that such attacks aren\u2019t useful for an adversary,\n    it\u2019s worth noting that the ability to bridge between temporally adjacent\n    broadcast IDs is inherent in the use of any RF protocol since: \n\n    *   Adjacent timestamps can be used to link sources across frames\n\n    *   Signal strength can be assumed to be invariant between adjacent frames\n        and can therefore also be used to link sources across frames.\n\nFor the sake of transparency, we note that this issue was confirmed on a\nsubset of Android devices globally.  These issues likely resulted from\nhow certain OEMs have implemented Bluetooth since, for the reasons noted\nabove, the [Android Compatibility Definition Document](https://source.android.com/compatibility/10/android-10-cdd#7_4_3_bluetooth) (CDD) does not\nrequire rotation in sync.  After extensive testing, a change to EN has\nnevertheless been rolled out that removes this opportunity for\ndevice-specific misbehavior with respect to EN for all devices. The RPI\nis now set to a globally fixed value for a small number of BLE frames\nsurrounding the RPI rollover.\n\nAs noted above, Google Play\u2019s policies forbid the malicious use of BLE\nscanning, and Play\u2019s rigorous review processes are designed to detect\nit. Any app found to be explicitly capturing BLE RPIs will be removed.\n\n### Linking diagnosis keys through export file analysis\n\n**Concern**\n\nAn adversary could attempt to link Diagnosis Keys from different days\u2014which\nare independently randomly generated and _a priori_ not linkable\u2014based on\nanalysis of Diagnosis Key batches served by the Diagnosis server.\n\n**Mitigations**\n\n*   This may be feasible specifically in situations where very few\n    individuals are diagnosed positive in a given timeframe. If a diagnosis key\n    batch only contains one diagnosis key for each day, the keys in the batch\n    must correspond to the same individual. To mitigate this potential for\n    correlation, we recommend that diagnosis key servers pad out diagnosis key\n    batches with random keys, with some jitter so exports don't leak the fact\n    that they were padded. This is implemented in our reference server\n    ([code](https://github.com/google/exposure-notifications-server/blob/821531b167d794ec4a57075cd2009adbcd137505/internal/export/worker.go#L358)).\n*   The natural order in which diagnosis keys are stored in the diagnosis\n    server's database may confer some information about their association at\n    time of upload. To ensure this information is not leaked in diagnosis key\n    export batches, we recommend that batches are re-ordered before\n    publication, as we've done in our\n    [reference implementation](https://github.com/google/exposure-notifications-server/blob/1aef0fbe22aef93ec86f5432dd9d0317418eba15/internal/export/exportfile.go#L139).\n\n### Feedback\n\nIf you have questions or feedback about this document, please let us know by\nemailing [ens-privsec@google.com](mailto:ens-privsec@google.com).\n"], "filenames": ["en-risks-and-mitigations-faq.md"], "buggy_code_start_loc": [567], "buggy_code_end_loc": [668], "fixing_code_start_loc": [567], "fixing_code_end_loc": [684], "type": "CWE-200", "message": "The Rolling Proximity Identifier used in the Apple/Google Exposure Notification API beta through 2020-05-29 enables attackers to circumvent Bluetooth Smart Privacy because there is a secondary temporary UID. An attacker with access to Beacon or IoT networks can seamlessly track individual device movement via a Bluetooth LE discovery mechanism.", "other": {"cve": {"id": "CVE-2020-13702", "sourceIdentifier": "cve@mitre.org", "published": "2020-06-11T19:15:10.073", "lastModified": "2021-03-12T12:58:55.347", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "The Rolling Proximity Identifier used in the Apple/Google Exposure Notification API beta through 2020-05-29 enables attackers to circumvent Bluetooth Smart Privacy because there is a secondary temporary UID. An attacker with access to Beacon or IoT networks can seamlessly track individual device movement via a Bluetooth LE discovery mechanism."}, {"lang": "es", "value": "El Rolling Proximity Identifier usado en la API Exposure Notification de Apple/Google versi\u00f3n beta hasta 29-05-2020, permite a atacantes omitir Bluetooth Smart Privacy porque existe un UID temporal secundario. Un atacante con acceso a redes Beacon o IoT puede rastrear sin problemas el movimiento de dispositivos individuales por medio de un mecanismo de detecci\u00f3n Bluetooth LE"}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:C/C:H/I:H/A:N", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "CHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "HIGH", "availabilityImpact": "NONE", "baseScore": 10.0, "baseSeverity": "CRITICAL"}, "exploitabilityScore": 3.9, "impactScore": 5.8}, {"source": "cve@mitre.org", "type": "Secondary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:A/AC:L/PR:N/UI:N/S:U/C:L/I:N/A:N", "attackVector": "ADJACENT_NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "LOW", "integrityImpact": "NONE", "availabilityImpact": "NONE", "baseScore": 4.3, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 2.8, "impactScore": 1.4}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:N/AC:L/Au:N/C:P/I:P/A:N", "accessVector": "NETWORK", "accessComplexity": "LOW", "authentication": "NONE", "confidentialityImpact": "PARTIAL", "integrityImpact": "PARTIAL", "availabilityImpact": "NONE", "baseScore": 6.4}, "baseSeverity": "MEDIUM", "exploitabilityScore": 10.0, "impactScore": 4.9, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-200"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:the_rolling_proximity_identifier_project:the_rolling_proximity_identifier:*:*:*:*:*:*:*:*", "versionEndIncluding": "2020-05-29", "matchCriteriaId": "476BD5D6-9B40-40C9-B914-A2DB84E073CE"}]}]}], "references": [{"url": "https://blog.google/documents/70/Exposure_Notification_-_Bluetooth_Specification_v1.2.2.pdf", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}, {"url": "https://github.com/google/exposure-notifications-internals/commit/8f751a666697", "source": "cve@mitre.org", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/google/exposure-notifications-internals/commit/8f751a666697c3cae0a56ae3464c2c6cbe31b69e", "source": "cve@mitre.org", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/normanluhrmann/infosec/raw/master/exposure-notification-vulnerability-20200611.pdf", "source": "cve@mitre.org", "tags": ["Exploit", "Technical Description", "Third Party Advisory"]}, {"url": "https://github.com/normanluhrmann/infosec/raw/master/exposure-notification-vulnerability-20200616-2.pdf", "source": "cve@mitre.org", "tags": ["Exploit", "Technical Description", "Third Party Advisory"]}, {"url": "https://github.com/normanluhrmann/infosec/raw/master/exposure-notification-vulnerability-20200616.pdf", "source": "cve@mitre.org", "tags": ["Exploit", "Technical Description", "Third Party Advisory"]}]}, "github_commit_url": "https://github.com/google/exposure-notifications-internals/commit/8f751a666697c3cae0a56ae3464c2c6cbe31b69e"}}
{"buggy_code": ["#!/usr/bin/env python    \n# -*- coding: utf-8 -*- \n\n#\n#  Copyright 2019 The FATE Authors. All Rights Reserved.\n#\n#  Licensed under the Apache License, Version 2.0 (the \"License\");\n#  you may not use this file except in compliance with the License.\n#  You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n#  Unless required by applicable law or agreed to in writing, software\n#  distributed under the License is distributed on an \"AS IS\" BASIS,\n#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n#  See the License for the specific language governing permissions and\n#  limitations under the License.\n#\n################################################################################\n#\n#\n################################################################################\n\n# =============================================================================\n# HeteroDecisionTreeGuest\n# =============================================================================\n\nimport copy\nimport functools\n\nfrom arch.api import session\nfrom arch.api.utils import log_utils\nfrom federatedml.feature.fate_element_type import NoneType\nfrom federatedml.protobuf.generated.boosting_tree_model_meta_pb2 import CriterionMeta\nfrom federatedml.protobuf.generated.boosting_tree_model_meta_pb2 import DecisionTreeModelMeta\nfrom federatedml.protobuf.generated.boosting_tree_model_param_pb2 import DecisionTreeModelParam\nfrom federatedml.transfer_variable.transfer_class.hetero_decision_tree_transfer_variable import \\\n    HeteroDecisionTreeTransferVariable\nfrom federatedml.tree import DecisionTree\nfrom federatedml.tree import FeatureHistogram\nfrom federatedml.tree import Node\nfrom federatedml.tree import Splitter\nfrom federatedml.util import consts\nfrom federatedml.util.io_check import assert_io_num_rows_equal\n\nLOGGER = log_utils.getLogger()\n\n\nclass HeteroDecisionTreeGuest(DecisionTree):\n    def __init__(self, tree_param):\n        LOGGER.info(\"hetero decision tree guest init!\")\n        super(HeteroDecisionTreeGuest, self).__init__(tree_param)\n        self.splitter = Splitter(self.criterion_method, self.criterion_params, self.min_impurity_split,\n                                 self.min_sample_split, self.min_leaf_node)\n\n        self.data_bin = None\n        self.grad_and_hess = None\n        self.bin_split_points = None\n        self.bin_sparse_points = None\n        self.data_bin_with_node_dispatch = None\n        self.node_dispatch = None\n        self.infos = None\n        self.valid_features = None\n        self.encrypter = None\n        self.encrypted_mode_calculator = None\n        self.best_splitinfo_guest = None\n        self.tree_node_queue = None\n        self.cur_split_nodes = None\n        self.tree_ = []\n        self.tree_node_num = 0\n        self.split_maskdict = {}\n        self.missing_dir_maskdict = {}\n        self.transfer_inst = HeteroDecisionTreeTransferVariable()\n        self.predict_weights = None\n        self.host_party_idlist = []\n        self.runtime_idx = 0\n        self.sitename = consts.GUEST\n        self.feature_importances_ = {}\n\n    def set_flowid(self, flowid=0):\n        LOGGER.info(\"set flowid, flowid is {}\".format(flowid))\n        self.transfer_inst.set_flowid(flowid)\n\n    def set_host_party_idlist(self, host_party_idlist):\n        self.host_party_idlist = host_party_idlist\n\n    def set_inputinfo(self, data_bin=None, grad_and_hess=None, bin_split_points=None, bin_sparse_points=None):\n        LOGGER.info(\"set input info\")\n        self.data_bin = data_bin\n        self.grad_and_hess = grad_and_hess\n        self.bin_split_points = bin_split_points\n        self.bin_sparse_points = bin_sparse_points\n\n    def set_encrypter(self, encrypter):\n        LOGGER.info(\"set encrypter\")\n        self.encrypter = encrypter\n\n    def set_encrypted_mode_calculator(self, encrypted_mode_calculator):\n        self.encrypted_mode_calculator = encrypted_mode_calculator\n\n    def encrypt(self, val):\n        return self.encrypter.encrypt(val)\n\n    def decrypt(self, val):\n        return self.encrypter.decrypt(val)\n\n    def encode(self, etype=\"feature_idx\", val=None, nid=None):\n        if etype == \"feature_idx\":\n            return val\n\n        if etype == \"feature_val\":\n            self.split_maskdict[nid] = val\n            return None\n\n        if etype == \"missing_dir\":\n            self.missing_dir_maskdict[nid] = val\n            return None\n\n        raise TypeError(\"encode type %s is not support!\" % (str(etype)))\n\n    @staticmethod\n    def decode(dtype=\"feature_idx\", val=None, nid=None, split_maskdict=None, missing_dir_maskdict=None):\n        if dtype == \"feature_idx\":\n            return val\n\n        if dtype == \"feature_val\":\n            if nid in split_maskdict:\n                return split_maskdict[nid]\n            else:\n                raise ValueError(\"decode val %s cause error, can't reconize it!\" % (str(val)))\n\n        if dtype == \"missing_dir\":\n            if nid in missing_dir_maskdict:\n                return missing_dir_maskdict[nid]\n            else:\n                raise ValueError(\"decode val %s cause error, can't reconize it!\" % (str(val)))\n\n        return TypeError(\"decode type %s is not support!\" % (str(dtype)))\n\n    def set_valid_features(self, valid_features=None):\n        LOGGER.info(\"set valid features\")\n        self.valid_features = valid_features\n\n    def sync_encrypted_grad_and_hess(self):\n        LOGGER.info(\"send encrypted grad and hess to host\")\n        encrypted_grad_and_hess = self.encrypt_grad_and_hess()\n        # LOGGER.debug(\"encrypted_grad_and_hess is {}\".format(list(encrypted_grad_and_hess.collect())))\n\n        self.transfer_inst.encrypted_grad_and_hess.remote(encrypted_grad_and_hess,\n                                                          role=consts.HOST,\n                                                          idx=-1)\n        \"\"\"\n        federation.remote(obj=encrypted_grad_and_hess,\n                          name=self.transfer_inst.encrypted_grad_and_hess.name,\n                          tag=self.transfer_inst.generate_transferid(self.transfer_inst.encrypted_grad_and_hess),\n                          role=consts.HOST,\n                          idx=-1)\n        \"\"\"\n\n    def encrypt_grad_and_hess(self):\n        LOGGER.info(\"start to encrypt grad and hess\")\n        encrypted_grad_and_hess = self.encrypted_mode_calculator.encrypt(self.grad_and_hess)\n        return encrypted_grad_and_hess\n\n    def get_grad_hess_sum(self, grad_and_hess_table):\n        LOGGER.info(\"calculate the sum of grad and hess\")\n        grad, hess = grad_and_hess_table.reduce(\n            lambda value1, value2: (value1[0] + value2[0], value1[1] + value2[1]))\n        return grad, hess\n\n    def dispatch_all_node_to_root(self, root_id=0):\n        LOGGER.info(\"dispatch all node to root\")\n        self.node_dispatch = self.data_bin.mapValues(lambda data_inst: (1, root_id))\n\n    def get_histograms(self, node_map={}):\n        LOGGER.info(\"start to get node histograms\")\n        acc_histograms = FeatureHistogram.calculate_histogram(\n            self.data_bin_with_node_dispatch, self.grad_and_hess,\n            self.bin_split_points, self.bin_sparse_points,\n            self.valid_features, node_map,\n            self.use_missing, self.zero_as_missing)\n\n        return acc_histograms\n\n    def sync_tree_node_queue(self, tree_node_queue, dep=-1):\n        LOGGER.info(\"send tree node queue of depth {}\".format(dep))\n        mask_tree_node_queue = copy.deepcopy(tree_node_queue)\n        for i in range(len(mask_tree_node_queue)):\n            mask_tree_node_queue[i] = Node(id=mask_tree_node_queue[i].id)\n\n        self.transfer_inst.tree_node_queue.remote(mask_tree_node_queue,\n                                                  role=consts.HOST,\n                                                  idx=-1,\n                                                  suffix=(dep,))\n        \"\"\"\n        federation.remote(obj=mask_tree_node_queue,\n                          name=self.transfer_inst.tree_node_queue.name,\n                          tag=self.transfer_inst.generate_transferid(self.transfer_inst.tree_node_queue, dep),\n                          role=consts.HOST,\n                          idx=-1)\n        \"\"\"\n\n    def sync_node_positions(self, dep):\n        LOGGER.info(\"send node positions of depth {}\".format(dep))\n        self.transfer_inst.node_positions.remote(self.node_dispatch,\n                                                 role=consts.HOST,\n                                                 idx=-1,\n                                                 suffix=(dep,))\n        \"\"\"\n        federation.remote(obj=self.node_dispatch,\n                          name=self.transfer_inst.node_positions.name,\n                          tag=self.transfer_inst.generate_transferid(self.transfer_inst.node_positions, dep),\n                          role=consts.HOST,\n                          idx=-1)\n        \"\"\"\n\n    def sync_encrypted_splitinfo_host(self, dep=-1, batch=-1):\n        LOGGER.info(\"get encrypted splitinfo of depth {}, batch {}\".format(dep, batch))\n        encrypted_splitinfo_host = self.transfer_inst.encrypted_splitinfo_host.get(idx=-1,\n                                                                                   suffix=(dep, batch,))\n\n        ret = []\n        for obj in encrypted_splitinfo_host:\n            ret.append(obj.get_data())\n        \"\"\"\n        encrypted_splitinfo_host = federation.get(name=self.transfer_inst.encrypted_splitinfo_host.name,\n                                                  tag=self.transfer_inst.generate_transferid(\n                                                      self.transfer_inst.encrypted_splitinfo_host, dep, batch),\n                                                  idx=-1)\n        \"\"\"\n        return ret\n\n    def sync_federated_best_splitinfo_host(self, federated_best_splitinfo_host, dep=-1, batch=-1, idx=-1):\n        LOGGER.info(\"send federated best splitinfo of depth {}, batch {}\".format(dep, batch))\n        self.transfer_inst.federated_best_splitinfo_host.remote(federated_best_splitinfo_host,\n                                                                role=consts.HOST,\n                                                                idx=idx,\n                                                                suffix=(dep, batch,))\n        \"\"\"\n        federation.remote(obj=federated_best_splitinfo_host,\n                          name=self.transfer_inst.federated_best_splitinfo_host.name,\n                          tag=self.transfer_inst.generate_transferid(self.transfer_inst.federated_best_splitinfo_host,\n                                                                     dep,\n                                                                     batch),\n                          role=consts.HOST,\n                          idx=idx)\n        \"\"\"\n\n    def find_host_split(self, value):\n        cur_split_node, encrypted_splitinfo_host = value\n        sum_grad = cur_split_node.sum_grad\n        sum_hess = cur_split_node.sum_hess\n        best_gain = self.min_impurity_split - consts.FLOAT_ZERO\n        best_idx = -1\n\n        for i in range(len(encrypted_splitinfo_host)):\n            sum_grad_l, sum_hess_l = encrypted_splitinfo_host[i]\n            sum_grad_l = self.decrypt(sum_grad_l)\n            sum_hess_l = self.decrypt(sum_hess_l)\n            sum_grad_r = sum_grad - sum_grad_l\n            sum_hess_r = sum_hess - sum_hess_l\n            gain = self.splitter.split_gain(sum_grad, sum_hess, sum_grad_l,\n                                            sum_hess_l, sum_grad_r, sum_hess_r)\n\n            if gain > self.min_impurity_split and gain > best_gain:\n                best_gain = gain\n                best_idx = i\n\n        encrypted_best_gain = self.encrypt(best_gain)\n        return best_idx, encrypted_best_gain, best_gain\n\n    def federated_find_split(self, dep=-1, batch=-1):\n        LOGGER.info(\"federated find split of depth {}, batch {}\".format(dep, batch))\n        encrypted_splitinfo_host = self.sync_encrypted_splitinfo_host(dep, batch)\n\n        for i in range(len(encrypted_splitinfo_host)):\n            init_gain = self.min_impurity_split - consts.FLOAT_ZERO\n            encrypted_init_gain = self.encrypter.encrypt(init_gain)\n            best_splitinfo_host = [[-1, encrypted_init_gain] for j in range(len(self.cur_split_nodes))]\n            best_gains = [init_gain for j in range(len(self.cur_split_nodes))]\n            max_nodes = max(len(encrypted_splitinfo_host[i][j]) for j in range(len(self.cur_split_nodes)))\n            for k in range(0, max_nodes, consts.MAX_FEDERATED_NODES):\n                batch_splitinfo_host = [encrypted_splitinfo[k: k + consts.MAX_FEDERATED_NODES] for encrypted_splitinfo\n                                        in encrypted_splitinfo_host[i]]\n                encrypted_splitinfo_host_table = session.parallelize(zip(self.cur_split_nodes, batch_splitinfo_host),\n                                                                     include_key=False,\n                                                                     partition=self.data_bin._partitions)\n                splitinfos = encrypted_splitinfo_host_table.mapValues(self.find_host_split).collect()\n                for _, splitinfo in splitinfos:\n                    if best_splitinfo_host[_][0] == -1:\n                        best_splitinfo_host[_] = list(splitinfo[:2])\n                        best_gains[_] = splitinfo[2]\n                    elif splitinfo[0] != -1 and splitinfo[2] > best_gains[_]:\n                        best_splitinfo_host[_][0] = k + splitinfo[0]\n                        best_splitinfo_host[_][1] = splitinfo[1]\n                        best_gains[_] = splitinfo[2]\n\n            self.sync_federated_best_splitinfo_host(best_splitinfo_host, dep, batch, i)\n\n    def sync_final_split_host(self, dep=-1, batch=-1):\n        LOGGER.info(\"get host final splitinfo of depth {}, batch {}\".format(dep, batch))\n        final_splitinfo_host = self.transfer_inst.final_splitinfo_host.get(idx=-1,\n                                                                           suffix=(dep, batch,))\n        \"\"\"\n        final_splitinfo_host = federation.get(name=self.transfer_inst.final_splitinfo_host.name,\n                                              tag=self.transfer_inst.generate_transferid(\n                                                  self.transfer_inst.final_splitinfo_host, dep, batch),\n                                              idx=-1)\n        \"\"\"\n        return final_splitinfo_host\n\n    def find_best_split_guest_and_host(self, splitinfo_guest_host):\n        best_gain_host = self.decrypt(splitinfo_guest_host[1].gain)\n        best_gain_host_idx = 1\n        for i in range(1, len(splitinfo_guest_host)):\n            gain_host_i = self.decrypt(splitinfo_guest_host[i].gain)\n            if best_gain_host < gain_host_i:\n                best_gain_host = gain_host_i\n                best_gain_host_idx = i\n\n        if splitinfo_guest_host[0].gain >= best_gain_host - consts.FLOAT_ZERO:\n            best_splitinfo = splitinfo_guest_host[0]\n        else:\n            best_splitinfo = splitinfo_guest_host[best_gain_host_idx]\n            best_splitinfo.sum_grad = self.decrypt(best_splitinfo.sum_grad)\n            best_splitinfo.sum_hess = self.decrypt(best_splitinfo.sum_hess)\n            best_splitinfo.gain = best_gain_host\n\n        return best_splitinfo\n\n    def merge_splitinfo(self, splitinfo_guest, splitinfo_host):\n        LOGGER.info(\"merge splitinfo\")\n        merge_infos = []\n        for i in range(len(splitinfo_guest)):\n            splitinfo = [splitinfo_guest[i]]\n            for j in range(len(splitinfo_host)):\n                splitinfo.append(splitinfo_host[j][i])\n\n            merge_infos.append(splitinfo)\n\n        splitinfo_guest_host_table = session.parallelize(merge_infos,\n                                                         include_key=False,\n                                                         partition=self.data_bin._partitions)\n        best_splitinfo_table = splitinfo_guest_host_table.mapValues(self.find_best_split_guest_and_host)\n\n        best_splitinfos = [None for i in range(len(merge_infos))]\n        for _, best_splitinfo in best_splitinfo_table.collect():\n            best_splitinfos[_] = best_splitinfo\n        # best_splitinfos = [best_splitinfo[1] for best_splitinfo in best_splitinfo_table.collect()]\n\n        return best_splitinfos\n\n    def update_feature_importance(self, splitinfo):\n        if self.feature_importance_type == \"split\":\n            inc = 1\n        elif self.feature_importance_type == \"gain\":\n            inc = splitinfo.gain\n        else:\n            raise ValueError(\"feature importance type {} not support yet\".format(self.feature_importance_type))\n\n        sitename = splitinfo.sitename\n        fid = splitinfo.best_fid\n\n        if (sitename, fid) not in self.feature_importances_:\n            self.feature_importances_[(sitename, fid)] = 0\n\n        self.feature_importances_[(sitename, fid)] += inc\n\n    def update_tree_node_queue(self, splitinfos, max_depth_reach):\n        LOGGER.info(\"update tree node, splitlist length is {}, tree node queue size is {}\".format(\n            len(splitinfos), len(self.tree_node_queue)))\n        new_tree_node_queue = []\n        for i in range(len(self.tree_node_queue)):\n            sum_grad = self.tree_node_queue[i].sum_grad\n            sum_hess = self.tree_node_queue[i].sum_hess\n            if max_depth_reach or splitinfos[i].gain <= \\\n                    self.min_impurity_split + consts.FLOAT_ZERO:\n                self.tree_node_queue[i].is_leaf = True\n            else:\n                self.tree_node_queue[i].left_nodeid = self.tree_node_num + 1\n                self.tree_node_queue[i].right_nodeid = self.tree_node_num + 2\n                self.tree_node_num += 2\n\n                left_node = Node(id=self.tree_node_queue[i].left_nodeid,\n                                 sitename=self.sitename,\n                                 sum_grad=splitinfos[i].sum_grad,\n                                 sum_hess=splitinfos[i].sum_hess,\n                                 weight=self.splitter.node_weight(splitinfos[i].sum_grad, splitinfos[i].sum_hess))\n                right_node = Node(id=self.tree_node_queue[i].right_nodeid,\n                                  sitename=self.sitename,\n                                  sum_grad=sum_grad - splitinfos[i].sum_grad,\n                                  sum_hess=sum_hess - splitinfos[i].sum_hess,\n                                  weight=self.splitter.node_weight( \\\n                                      sum_grad - splitinfos[i].sum_grad,\n                                      sum_hess - splitinfos[i].sum_hess))\n\n                new_tree_node_queue.append(left_node)\n                new_tree_node_queue.append(right_node)\n\n                self.tree_node_queue[i].sitename = splitinfos[i].sitename\n                if self.tree_node_queue[i].sitename == self.sitename:\n                    self.tree_node_queue[i].fid = self.encode(\"feature_idx\", splitinfos[i].best_fid)\n                    self.tree_node_queue[i].bid = self.encode(\"feature_val\", splitinfos[i].best_bid,\n                                                              self.tree_node_queue[i].id)\n                    self.tree_node_queue[i].missing_dir = self.encode(\"missing_dir\",\n                                                                      splitinfos[i].missing_dir,\n                                                                      self.tree_node_queue[i].id)\n                else:\n                    self.tree_node_queue[i].fid = splitinfos[i].best_fid\n                    self.tree_node_queue[i].bid = splitinfos[i].best_bid\n\n                self.update_feature_importance(splitinfos[i])\n            self.tree_.append(self.tree_node_queue[i])\n\n        self.tree_node_queue = new_tree_node_queue\n\n    @staticmethod\n    def dispatch_node(value, tree_=None, decoder=None, sitename=consts.GUEST,\n                      split_maskdict=None, bin_sparse_points=None,\n                      use_missing=False, zero_as_missing=False,\n                      missing_dir_maskdict=None):\n        unleaf_state, nodeid = value[1]\n\n        if tree_[nodeid].is_leaf is True:\n            return tree_[nodeid].weight\n        else:\n            if tree_[nodeid].sitename == sitename:\n                fid = decoder(\"feature_idx\", tree_[nodeid].fid, split_maskdict=split_maskdict)\n                bid = decoder(\"feature_val\", tree_[nodeid].bid, nodeid, split_maskdict=split_maskdict)\n                if not use_missing:\n                    if value[0].features.get_data(fid, bin_sparse_points[fid]) <= bid:\n                        return 1, tree_[nodeid].left_nodeid\n                    else:\n                        return 1, tree_[nodeid].right_nodeid\n                else:\n                    missing_dir = decoder(\"missing_dir\", tree_[nodeid].missing_dir, nodeid,\n                                          missing_dir_maskdict=missing_dir_maskdict)\n\n                    missing_val = False\n                    if zero_as_missing:\n                        if value[0].features.get_data(fid, None) is None or \\\n                                value[0].features.get_data(fid) == NoneType():\n                            missing_val = True\n                    elif use_missing and value[0].features.get_data(fid) == NoneType():\n                        missing_val = True\n\n                    if missing_val:\n                        if missing_dir == 1:\n                            return 1, tree_[nodeid].right_nodeid\n                        else:\n                            return 1, tree_[nodeid].left_nodeid\n                    else:\n                        LOGGER.debug(\"fid is {}, bid is {}, sitename is {}\".format(fid, bid, sitename))\n                        if value[0].features.get_data(fid, bin_sparse_points[fid]) <= bid:\n                            return 1, tree_[nodeid].left_nodeid\n                        else:\n                            return 1, tree_[nodeid].right_nodeid\n            else:\n                return (1, tree_[nodeid].fid, tree_[nodeid].bid, tree_[nodeid].sitename,\n                        nodeid, tree_[nodeid].left_nodeid, tree_[nodeid].right_nodeid)\n\n    def sync_dispatch_node_host(self, dispatch_guest_data, dep=-1):\n        LOGGER.info(\"send node to host to dispath, depth is {}\".format(dep))\n        self.transfer_inst.dispatch_node_host.remote(dispatch_guest_data,\n                                                     role=consts.HOST,\n                                                     idx=-1,\n                                                     suffix=(dep,))\n        \"\"\"\n        federation.remote(obj=dispatch_guest_data,\n                          name=self.transfer_inst.dispatch_node_host.name,\n                          tag=self.transfer_inst.generate_transferid(self.transfer_inst.dispatch_node_host, dep),\n                          role=consts.HOST,\n                          idx=-1)\n        \"\"\"\n\n    def sync_dispatch_node_host_result(self, dep=-1):\n        LOGGER.info(\"get host dispatch result, depth is {}\".format(dep))\n        dispatch_node_host_result = self.transfer_inst.dispatch_node_host_result.get(idx=-1,\n                                                                                     suffix=(dep,))\n        \"\"\"\n        dispatch_node_host_result = federation.get(name=self.transfer_inst.dispatch_node_host_result.name,\n                                                   tag=self.transfer_inst.generate_transferid(\n                                                       self.transfer_inst.dispatch_node_host_result, dep),\n                                                   idx=-1)\n        \"\"\"\n        return dispatch_node_host_result\n\n    def redispatch_node(self, dep=-1, max_depth_reach=False):\n        LOGGER.info(\"redispatch node of depth {}\".format(dep))\n        dispatch_node_method = functools.partial(self.dispatch_node,\n                                                 tree_=self.tree_,\n                                                 decoder=self.decode,\n                                                 sitename=self.sitename,\n                                                 split_maskdict=self.split_maskdict,\n                                                 bin_sparse_points=self.bin_sparse_points,\n                                                 use_missing=self.use_missing,\n                                                 zero_as_missing=self.zero_as_missing,\n                                                 missing_dir_maskdict=self.missing_dir_maskdict)\n        dispatch_guest_result = self.data_bin_with_node_dispatch.mapValues(dispatch_node_method)\n        tree_node_num = self.tree_node_num\n        LOGGER.info(\"remask dispatch node result of depth {}\".format(dep))\n\n        dispatch_to_host_result = dispatch_guest_result.filter(\n            lambda key, value: isinstance(value, tuple) and len(value) > 2)\n\n        dispatch_guest_result = dispatch_guest_result.subtractByKey(dispatch_to_host_result)\n        leaf = dispatch_guest_result.filter(lambda key, value: isinstance(value, tuple) is False)\n        if self.predict_weights is None:\n            self.predict_weights = leaf\n        else:\n            self.predict_weights = self.predict_weights.union(leaf)\n\n        if max_depth_reach:\n            return\n\n        dispatch_guest_result = dispatch_guest_result.subtractByKey(leaf)\n\n        self.sync_dispatch_node_host(dispatch_to_host_result, dep)\n        dispatch_node_host_result = self.sync_dispatch_node_host_result(dep)\n\n        self.node_dispatch = None\n        for idx in range(len(dispatch_node_host_result)):\n            if self.node_dispatch is None:\n                self.node_dispatch = dispatch_node_host_result[idx]\n            else:\n                self.node_dispatch = self.node_dispatch.join(dispatch_node_host_result[idx], \\\n                                                             lambda unleaf_state_nodeid1, unleaf_state_nodeid2: \\\n                                                                 unleaf_state_nodeid1 if len(\n                                                                     unleaf_state_nodeid1) == 2 else unleaf_state_nodeid2)\n        self.node_dispatch = self.node_dispatch.union(dispatch_guest_result)\n\n    def sync_tree(self):\n        LOGGER.info(\"sync tree to host\")\n\n        self.transfer_inst.tree.remote(self.tree_,\n                                       role=consts.HOST,\n                                       idx=-1)\n        \"\"\"\n        federation.remote(obj=self.tree_,\n                          name=self.transfer_inst.tree.name,\n                          tag=self.transfer_inst.generate_transferid(self.transfer_inst.tree),\n                          role=consts.HOST,\n                          idx=-1)\n        \"\"\"\n\n    def convert_bin_to_real(self):\n        LOGGER.info(\"convert tree node bins to real value\")\n        for i in range(len(self.tree_)):\n            if self.tree_[i].is_leaf is True:\n                continue\n            if self.tree_[i].sitename == self.sitename:\n                fid = self.decode(\"feature_idx\", self.tree_[i].fid, split_maskdict=self.split_maskdict)\n                bid = self.decode(\"feature_val\", self.tree_[i].bid, self.tree_[i].id, self.split_maskdict)\n                real_splitval = self.encode(\"feature_val\", self.bin_split_points[fid][bid], self.tree_[i].id)\n                self.tree_[i].bid = real_splitval\n\n    def fit(self):\n        LOGGER.info(\"begin to fit guest decision tree\")\n        self.sync_encrypted_grad_and_hess()\n\n        # LOGGER.debug(\"self.grad and hess is {}\".format(list(self.grad_and_hess.collect())))\n        root_sum_grad, root_sum_hess = self.get_grad_hess_sum(self.grad_and_hess)\n        root_node = Node(id=0, sitename=self.sitename, sum_grad=root_sum_grad, sum_hess=root_sum_hess,\n                         weight=self.splitter.node_weight(root_sum_grad, root_sum_hess))\n        self.tree_node_queue = [root_node]\n\n        self.dispatch_all_node_to_root()\n\n        for dep in range(self.max_depth):\n            LOGGER.info(\"start to fit depth {}, tree node queue size is {}\".format(dep, len(self.tree_node_queue)))\n\n            self.sync_tree_node_queue(self.tree_node_queue, dep)\n            if len(self.tree_node_queue) == 0:\n                break\n\n            self.sync_node_positions(dep)\n\n            self.data_bin_with_node_dispatch = self.data_bin.join(self.node_dispatch,\n                                                                  lambda data_inst, dispatch_info: (\n                                                                      data_inst, dispatch_info))\n\n            batch = 0\n            splitinfos = []\n            for i in range(0, len(self.tree_node_queue), self.max_split_nodes):\n                self.cur_split_nodes = self.tree_node_queue[i: i + self.max_split_nodes]\n\n                node_map = {}\n                node_num = 0\n                for tree_node in self.cur_split_nodes:\n                    node_map[tree_node.id] = node_num\n                    node_num += 1\n\n                acc_histograms = self.get_histograms(node_map=node_map)\n\n                self.best_splitinfo_guest = self.splitter.find_split(acc_histograms, self.valid_features,\n                                                                     self.data_bin._partitions,\n                                                                     self.sitename,\n                                                                     self.use_missing, self.zero_as_missing)\n                self.federated_find_split(dep, batch)\n                final_splitinfo_host = self.sync_final_split_host(dep, batch)\n\n                cur_splitinfos = self.merge_splitinfo(self.best_splitinfo_guest, final_splitinfo_host)\n                splitinfos.extend(cur_splitinfos)\n\n                batch += 1\n\n            self.update_tree_node_queue(splitinfos, False)\n\n            self.redispatch_node(dep)\n\n        if self.tree_node_queue:\n            self.update_tree_node_queue([], True)\n            self.data_bin_with_node_dispatch = self.data_bin.join(self.node_dispatch,\n                                                                  lambda data_inst, dispatch_info: (\n                                                                      data_inst, dispatch_info))\n\n            self.redispatch_node(self.max_depth, max_depth_reach=True)\n\n        self.sync_tree()\n        self.convert_bin_to_real()\n        tree_ = self.tree_\n        LOGGER.info(\"tree node num is %d\" % len(tree_))\n        LOGGER.info(\"end to fit guest decision tree\")\n\n    @staticmethod\n    def traverse_tree(predict_state, data_inst, tree_=None,\n                      decoder=None, sitename=consts.GUEST, split_maskdict=None,\n                      use_missing=None, zero_as_missing=None, missing_dir_maskdict=None):\n        nid, tag = predict_state\n\n        while tree_[nid].sitename == sitename:\n            if tree_[nid].is_leaf is True:\n                return tree_[nid].weight\n\n            fid = decoder(\"feature_idx\", tree_[nid].fid, split_maskdict=split_maskdict)\n            bid = decoder(\"feature_val\", tree_[nid].bid, nid, split_maskdict=split_maskdict)\n            if use_missing:\n                missing_dir = decoder(\"missing_dir\", 1, nid, missing_dir_maskdict=missing_dir_maskdict)\n            else:\n                missing_dir = 1\n\n            if use_missing and zero_as_missing:\n                missing_dir = decoder(\"missing_dir\", 1, nid, missing_dir_maskdict=missing_dir_maskdict)\n                if data_inst.features.get_data(fid) == NoneType() or data_inst.features.get_data(fid, None) is None:\n                    if missing_dir == 1:\n                        nid = tree_[nid].right_nodeid\n                    else:\n                        nid = tree_[nid].left_nodeid\n                elif data_inst.features.get_data(fid) <= bid:\n                    nid = tree_[nid].left_nodeid\n                else:\n                    nid = tree_[nid].right_nodeid\n            elif data_inst.features.get_data(fid) == NoneType():\n                if missing_dir == 1:\n                    nid = tree_[nid].right_nodeid\n                else:\n                    nid = tree_[nid].left_nodeid\n            elif data_inst.features.get_data(fid, 0) <= bid:\n                nid = tree_[nid].left_nodeid\n            else:\n                nid = tree_[nid].right_nodeid\n\n        return nid, 1\n\n    def sync_predict_finish_tag(self, finish_tag, send_times):\n        LOGGER.info(\"send the {}-th predict finish tag {} to host\".format(finish_tag, send_times))\n\n        self.transfer_inst.predict_finish_tag.remote(finish_tag,\n                                                     role=consts.HOST,\n                                                     idx=-1,\n                                                     suffix=(send_times,))\n        \"\"\"\n        federation.remote(obj=finish_tag,\n                          name=self.transfer_inst.predict_finish_tag.name,\n                          tag=self.transfer_inst.generate_transferid(self.transfer_inst.predict_finish_tag, send_times),\n                          role=consts.HOST,\n                          idx=-1)\n        \"\"\"\n\n    def sync_predict_data(self, predict_data, send_times):\n        LOGGER.info(\"send predict data to host, sending times is {}\".format(send_times))\n        self.transfer_inst.predict_data.remote(predict_data,\n                                               role=consts.HOST,\n                                               idx=-1,\n                                               suffix=(send_times,))\n\n        \"\"\"\n        federation.remote(obj=predict_data,\n                          name=self.transfer_inst.predict_data.name,\n                          tag=self.transfer_inst.generate_transferid(self.transfer_inst.predict_data, send_times),\n                          role=consts.HOST,\n                          idx=-1)\n        \"\"\"\n\n    def sync_data_predicted_by_host(self, send_times):\n        LOGGER.info(\"get predicted data by host, recv times is {}\".format(send_times))\n        predict_data = self.transfer_inst.predict_data_by_host.get(idx=-1,\n                                                                   suffix=(send_times,))\n        \"\"\"\n        predict_data = federation.get(name=self.transfer_inst.predict_data_by_host.name,\n                                      tag=self.transfer_inst.generate_transferid(\n                                          self.transfer_inst.predict_data_by_host, send_times),\n                                      idx=-1)\n        \"\"\"\n        return predict_data\n\n    @assert_io_num_rows_equal\n    def predict(self, data_inst):\n        LOGGER.info(\"start to predict!\")\n        predict_data = data_inst.mapValues(lambda data_inst: (0, 1))\n        site_host_send_times = 0\n        predict_result = None\n\n        while True:\n            traverse_tree = functools.partial(self.traverse_tree,\n                                              tree_=self.tree_,\n                                              decoder=self.decode,\n                                              sitename=self.sitename,\n                                              split_maskdict=self.split_maskdict,\n                                              use_missing=self.use_missing,\n                                              zero_as_missing=self.zero_as_missing,\n                                              missing_dir_maskdict=self.missing_dir_maskdict)\n            predict_data = predict_data.join(data_inst, traverse_tree)\n            predict_leaf = predict_data.filter(lambda key, value: isinstance(value, tuple) is False)\n            if predict_result is None:\n                predict_result = predict_leaf\n            else:\n                predict_result = predict_result.union(predict_leaf)\n\n            predict_data = predict_data.subtractByKey(predict_leaf)\n\n            unleaf_node_count = predict_data.count()\n\n            if unleaf_node_count == 0:\n                self.sync_predict_finish_tag(True, site_host_send_times)\n                break\n\n            self.sync_predict_finish_tag(False, site_host_send_times)\n            self.sync_predict_data(predict_data, site_host_send_times)\n\n            predict_data_host = self.sync_data_predicted_by_host(site_host_send_times)\n            for i in range(len(predict_data_host)):\n                predict_data = predict_data.join(predict_data_host[i],\n                                                 lambda state1_nodeid1, state2_nodeid2:\n                                                 state1_nodeid1 if state1_nodeid1[\n                                                                       1] == 0 else state2_nodeid2)\n\n            site_host_send_times += 1\n\n        LOGGER.info(\"predict finish!\")\n        return predict_result\n\n    def get_model_meta(self):\n        model_meta = DecisionTreeModelMeta()\n        model_meta.criterion_meta.CopyFrom(CriterionMeta(criterion_method=self.criterion_method,\n                                                         criterion_param=self.criterion_params))\n\n        model_meta.max_depth = self.max_depth\n        model_meta.min_sample_split = self.min_sample_split\n        model_meta.min_impurity_split = self.min_impurity_split\n        model_meta.min_leaf_node = self.min_leaf_node\n        model_meta.use_missing = self.use_missing\n        model_meta.zero_as_missing = self.zero_as_missing\n\n        return model_meta\n\n    def set_model_meta(self, model_meta):\n        self.max_depth = model_meta.max_depth\n        self.min_sample_split = model_meta.min_sample_split\n        self.min_impurity_split = model_meta.min_impurity_split\n        self.min_leaf_node = model_meta.min_leaf_node\n        self.criterion_method = model_meta.criterion_meta.criterion_method\n        self.criterion_params = list(model_meta.criterion_meta.criterion_param)\n        self.use_missing = model_meta.use_missing\n        self.zero_as_missing = model_meta.zero_as_missing\n\n    def get_model_param(self):\n        model_param = DecisionTreeModelParam()\n        for node in self.tree_:\n            model_param.tree_.add(id=node.id,\n                                  sitename=node.sitename,\n                                  fid=node.fid,\n                                  bid=node.bid,\n                                  weight=node.weight,\n                                  is_leaf=node.is_leaf,\n                                  left_nodeid=node.left_nodeid,\n                                  right_nodeid=node.right_nodeid,\n                                  missing_dir=node.missing_dir)\n            LOGGER.debug(\"missing_dir is {}, sitename is {}, is_leaf is {}\".format(node.missing_dir, node.sitename,\n                                                                                   node.is_leaf))\n\n        model_param.split_maskdict.update(self.split_maskdict)\n        model_param.missing_dir_maskdict.update(self.missing_dir_maskdict)\n\n        return model_param\n\n    def set_model_param(self, model_param):\n        self.tree_ = []\n        for node_param in model_param.tree_:\n            _node = Node(id=node_param.id,\n                         sitename=node_param.sitename,\n                         fid=node_param.fid,\n                         bid=node_param.bid,\n                         weight=node_param.weight,\n                         is_leaf=node_param.is_leaf,\n                         left_nodeid=node_param.left_nodeid,\n                         right_nodeid=node_param.right_nodeid,\n                         missing_dir=node_param.missing_dir)\n\n            self.tree_.append(_node)\n\n        self.split_maskdict = dict(model_param.split_maskdict)\n        self.missing_dir_maskdict = dict(model_param.missing_dir_maskdict)\n\n    def get_model(self):\n        model_meta = self.get_model_meta()\n        model_param = self.get_model_param()\n\n        return model_meta, model_param\n\n    def load_model(self, model_meta=None, model_param=None):\n        LOGGER.info(\"load tree model\")\n        self.set_model_meta(model_meta)\n        self.set_model_param(model_param)\n\n    def get_feature_importance(self):\n        return self.feature_importances_\n"], "fixing_code": ["#!/usr/bin/env python    \n# -*- coding: utf-8 -*- \n\n#\n#  Copyright 2019 The FATE Authors. All Rights Reserved.\n#\n#  Licensed under the Apache License, Version 2.0 (the \"License\");\n#  you may not use this file except in compliance with the License.\n#  You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n#  Unless required by applicable law or agreed to in writing, software\n#  distributed under the License is distributed on an \"AS IS\" BASIS,\n#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n#  See the License for the specific language governing permissions and\n#  limitations under the License.\n#\n################################################################################\n#\n#\n################################################################################\n\n# =============================================================================\n# HeteroDecisionTreeGuest\n# =============================================================================\n\nimport copy\nimport functools\n\nfrom arch.api import session\nfrom arch.api.utils import log_utils\nfrom federatedml.feature.fate_element_type import NoneType\nfrom federatedml.protobuf.generated.boosting_tree_model_meta_pb2 import CriterionMeta\nfrom federatedml.protobuf.generated.boosting_tree_model_meta_pb2 import DecisionTreeModelMeta\nfrom federatedml.protobuf.generated.boosting_tree_model_param_pb2 import DecisionTreeModelParam\nfrom federatedml.transfer_variable.transfer_class.hetero_decision_tree_transfer_variable import \\\n    HeteroDecisionTreeTransferVariable\nfrom federatedml.tree import DecisionTree\nfrom federatedml.tree import FeatureHistogram\nfrom federatedml.tree import Node\nfrom federatedml.tree import Splitter\nfrom federatedml.util import consts\nfrom federatedml.util.io_check import assert_io_num_rows_equal\n\nLOGGER = log_utils.getLogger()\n\n\nclass HeteroDecisionTreeGuest(DecisionTree):\n    def __init__(self, tree_param):\n        LOGGER.info(\"hetero decision tree guest init!\")\n        super(HeteroDecisionTreeGuest, self).__init__(tree_param)\n        self.splitter = Splitter(self.criterion_method, self.criterion_params, self.min_impurity_split,\n                                 self.min_sample_split, self.min_leaf_node)\n\n        self.data_bin = None\n        self.grad_and_hess = None\n        self.bin_split_points = None\n        self.bin_sparse_points = None\n        self.data_bin_with_node_dispatch = None\n        self.node_dispatch = None\n        self.infos = None\n        self.valid_features = None\n        self.encrypter = None\n        self.encrypted_mode_calculator = None\n        self.best_splitinfo_guest = None\n        self.tree_node_queue = None\n        self.cur_split_nodes = None\n        self.tree_ = []\n        self.tree_node_num = 0\n        self.split_maskdict = {}\n        self.missing_dir_maskdict = {}\n        self.transfer_inst = HeteroDecisionTreeTransferVariable()\n        self.predict_weights = None\n        self.host_party_idlist = []\n        self.runtime_idx = 0\n        self.sitename = consts.GUEST\n        self.feature_importances_ = {}\n\n    def set_flowid(self, flowid=0):\n        LOGGER.info(\"set flowid, flowid is {}\".format(flowid))\n        self.transfer_inst.set_flowid(flowid)\n\n    def set_host_party_idlist(self, host_party_idlist):\n        self.host_party_idlist = host_party_idlist\n\n    def set_inputinfo(self, data_bin=None, grad_and_hess=None, bin_split_points=None, bin_sparse_points=None):\n        LOGGER.info(\"set input info\")\n        self.data_bin = data_bin\n        self.grad_and_hess = grad_and_hess\n        self.bin_split_points = bin_split_points\n        self.bin_sparse_points = bin_sparse_points\n\n    def set_encrypter(self, encrypter):\n        LOGGER.info(\"set encrypter\")\n        self.encrypter = encrypter\n\n    def set_encrypted_mode_calculator(self, encrypted_mode_calculator):\n        self.encrypted_mode_calculator = encrypted_mode_calculator\n\n    def encrypt(self, val):\n        return self.encrypter.encrypt(val)\n\n    def decrypt(self, val):\n        return self.encrypter.decrypt(val)\n\n    def encode(self, etype=\"feature_idx\", val=None, nid=None):\n        if etype == \"feature_idx\":\n            return val\n\n        if etype == \"feature_val\":\n            self.split_maskdict[nid] = val\n            return None\n\n        if etype == \"missing_dir\":\n            self.missing_dir_maskdict[nid] = val\n            return None\n\n        raise TypeError(\"encode type %s is not support!\" % (str(etype)))\n\n    @staticmethod\n    def decode(dtype=\"feature_idx\", val=None, nid=None, split_maskdict=None, missing_dir_maskdict=None):\n        if dtype == \"feature_idx\":\n            return val\n\n        if dtype == \"feature_val\":\n            if nid in split_maskdict:\n                return split_maskdict[nid]\n            else:\n                raise ValueError(\"decode val %s cause error, can't reconize it!\" % (str(val)))\n\n        if dtype == \"missing_dir\":\n            if nid in missing_dir_maskdict:\n                return missing_dir_maskdict[nid]\n            else:\n                raise ValueError(\"decode val %s cause error, can't reconize it!\" % (str(val)))\n\n        return TypeError(\"decode type %s is not support!\" % (str(dtype)))\n\n    def set_valid_features(self, valid_features=None):\n        LOGGER.info(\"set valid features\")\n        self.valid_features = valid_features\n\n    def sync_encrypted_grad_and_hess(self):\n        LOGGER.info(\"send encrypted grad and hess to host\")\n        encrypted_grad_and_hess = self.encrypt_grad_and_hess()\n        # LOGGER.debug(\"encrypted_grad_and_hess is {}\".format(list(encrypted_grad_and_hess.collect())))\n\n        self.transfer_inst.encrypted_grad_and_hess.remote(encrypted_grad_and_hess,\n                                                          role=consts.HOST,\n                                                          idx=-1)\n        \"\"\"\n        federation.remote(obj=encrypted_grad_and_hess,\n                          name=self.transfer_inst.encrypted_grad_and_hess.name,\n                          tag=self.transfer_inst.generate_transferid(self.transfer_inst.encrypted_grad_and_hess),\n                          role=consts.HOST,\n                          idx=-1)\n        \"\"\"\n\n    def encrypt_grad_and_hess(self):\n        LOGGER.info(\"start to encrypt grad and hess\")\n        encrypted_grad_and_hess = self.encrypted_mode_calculator.encrypt(self.grad_and_hess)\n        return encrypted_grad_and_hess\n\n    def get_grad_hess_sum(self, grad_and_hess_table):\n        LOGGER.info(\"calculate the sum of grad and hess\")\n        grad, hess = grad_and_hess_table.reduce(\n            lambda value1, value2: (value1[0] + value2[0], value1[1] + value2[1]))\n        return grad, hess\n\n    def dispatch_all_node_to_root(self, root_id=0):\n        LOGGER.info(\"dispatch all node to root\")\n        self.node_dispatch = self.data_bin.mapValues(lambda data_inst: (1, root_id))\n\n    def get_histograms(self, node_map={}):\n        LOGGER.info(\"start to get node histograms\")\n        acc_histograms = FeatureHistogram.calculate_histogram(\n            self.data_bin_with_node_dispatch, self.grad_and_hess,\n            self.bin_split_points, self.bin_sparse_points,\n            self.valid_features, node_map,\n            self.use_missing, self.zero_as_missing)\n\n        return acc_histograms\n\n    def sync_tree_node_queue(self, tree_node_queue, dep=-1):\n        LOGGER.info(\"send tree node queue of depth {}\".format(dep))\n        mask_tree_node_queue = copy.deepcopy(tree_node_queue)\n        for i in range(len(mask_tree_node_queue)):\n            mask_tree_node_queue[i] = Node(id=mask_tree_node_queue[i].id)\n\n        self.transfer_inst.tree_node_queue.remote(mask_tree_node_queue,\n                                                  role=consts.HOST,\n                                                  idx=-1,\n                                                  suffix=(dep,))\n        \"\"\"\n        federation.remote(obj=mask_tree_node_queue,\n                          name=self.transfer_inst.tree_node_queue.name,\n                          tag=self.transfer_inst.generate_transferid(self.transfer_inst.tree_node_queue, dep),\n                          role=consts.HOST,\n                          idx=-1)\n        \"\"\"\n\n    def sync_node_positions(self, dep):\n        LOGGER.info(\"send node positions of depth {}\".format(dep))\n        self.transfer_inst.node_positions.remote(self.node_dispatch,\n                                                 role=consts.HOST,\n                                                 idx=-1,\n                                                 suffix=(dep,))\n        \"\"\"\n        federation.remote(obj=self.node_dispatch,\n                          name=self.transfer_inst.node_positions.name,\n                          tag=self.transfer_inst.generate_transferid(self.transfer_inst.node_positions, dep),\n                          role=consts.HOST,\n                          idx=-1)\n        \"\"\"\n\n    def sync_encrypted_splitinfo_host(self, dep=-1, batch=-1):\n        LOGGER.info(\"get encrypted splitinfo of depth {}, batch {}\".format(dep, batch))\n        encrypted_splitinfo_host = self.transfer_inst.encrypted_splitinfo_host.get(idx=-1,\n                                                                                   suffix=(dep, batch,))\n\n        ret = []\n        for obj in encrypted_splitinfo_host:\n            ret.append(obj.get_data())\n        \"\"\"\n        encrypted_splitinfo_host = federation.get(name=self.transfer_inst.encrypted_splitinfo_host.name,\n                                                  tag=self.transfer_inst.generate_transferid(\n                                                      self.transfer_inst.encrypted_splitinfo_host, dep, batch),\n                                                  idx=-1)\n        \"\"\"\n        return ret\n\n    def sync_federated_best_splitinfo_host(self, federated_best_splitinfo_host, dep=-1, batch=-1, idx=-1):\n        LOGGER.info(\"send federated best splitinfo of depth {}, batch {}\".format(dep, batch))\n        self.transfer_inst.federated_best_splitinfo_host.remote(federated_best_splitinfo_host,\n                                                                role=consts.HOST,\n                                                                idx=idx,\n                                                                suffix=(dep, batch,))\n        \"\"\"\n        federation.remote(obj=federated_best_splitinfo_host,\n                          name=self.transfer_inst.federated_best_splitinfo_host.name,\n                          tag=self.transfer_inst.generate_transferid(self.transfer_inst.federated_best_splitinfo_host,\n                                                                     dep,\n                                                                     batch),\n                          role=consts.HOST,\n                          idx=idx)\n        \"\"\"\n\n    def find_host_split(self, value):\n        cur_split_node, encrypted_splitinfo_host = value\n        sum_grad = cur_split_node.sum_grad\n        sum_hess = cur_split_node.sum_hess\n        best_gain = self.min_impurity_split - consts.FLOAT_ZERO\n        best_idx = -1\n\n        for i in range(len(encrypted_splitinfo_host)):\n            sum_grad_l, sum_hess_l = encrypted_splitinfo_host[i]\n            sum_grad_l = self.decrypt(sum_grad_l)\n            sum_hess_l = self.decrypt(sum_hess_l)\n            sum_grad_r = sum_grad - sum_grad_l\n            sum_hess_r = sum_hess - sum_hess_l\n            gain = self.splitter.split_gain(sum_grad, sum_hess, sum_grad_l,\n                                            sum_hess_l, sum_grad_r, sum_hess_r)\n\n            if gain > self.min_impurity_split and gain > best_gain:\n                best_gain = gain\n                best_idx = i\n\n        encrypted_best_gain = self.encrypt(best_gain)\n        return best_idx, encrypted_best_gain, best_gain\n\n    def federated_find_split(self, dep=-1, batch=-1):\n        LOGGER.info(\"federated find split of depth {}, batch {}\".format(dep, batch))\n        encrypted_splitinfo_host = self.sync_encrypted_splitinfo_host(dep, batch)\n\n        for i in range(len(encrypted_splitinfo_host)):\n            init_gain = self.min_impurity_split - consts.FLOAT_ZERO\n            encrypted_init_gain = self.encrypter.encrypt(init_gain)\n            best_splitinfo_host = [[-1, encrypted_init_gain] for j in range(len(self.cur_split_nodes))]\n            best_gains = [init_gain for j in range(len(self.cur_split_nodes))]\n            max_nodes = max(len(encrypted_splitinfo_host[i][j]) for j in range(len(self.cur_split_nodes)))\n            for k in range(0, max_nodes, consts.MAX_FEDERATED_NODES):\n                batch_splitinfo_host = [encrypted_splitinfo[k: k + consts.MAX_FEDERATED_NODES] for encrypted_splitinfo\n                                        in encrypted_splitinfo_host[i]]\n                encrypted_splitinfo_host_table = session.parallelize(zip(self.cur_split_nodes, batch_splitinfo_host),\n                                                                     include_key=False,\n                                                                     partition=self.data_bin._partitions)\n                splitinfos = encrypted_splitinfo_host_table.mapValues(self.find_host_split).collect()\n                for _, splitinfo in splitinfos:\n                    if best_splitinfo_host[_][0] == -1:\n                        best_splitinfo_host[_] = list(splitinfo[:2])\n                        best_gains[_] = splitinfo[2]\n                    elif splitinfo[0] != -1 and splitinfo[2] > best_gains[_]:\n                        best_splitinfo_host[_][0] = k + splitinfo[0]\n                        best_splitinfo_host[_][1] = splitinfo[1]\n                        best_gains[_] = splitinfo[2]\n\n            self.sync_federated_best_splitinfo_host(best_splitinfo_host, dep, batch, i)\n\n    def sync_final_split_host(self, dep=-1, batch=-1):\n        LOGGER.info(\"get host final splitinfo of depth {}, batch {}\".format(dep, batch))\n        final_splitinfo_host = self.transfer_inst.final_splitinfo_host.get(idx=-1,\n                                                                           suffix=(dep, batch,))\n        \"\"\"\n        final_splitinfo_host = federation.get(name=self.transfer_inst.final_splitinfo_host.name,\n                                              tag=self.transfer_inst.generate_transferid(\n                                                  self.transfer_inst.final_splitinfo_host, dep, batch),\n                                              idx=-1)\n        \"\"\"\n        return final_splitinfo_host\n\n    def find_best_split_guest_and_host(self, splitinfo_guest_host):\n        best_gain_host = self.decrypt(splitinfo_guest_host[1].gain)\n        best_gain_host_idx = 1\n        for i in range(1, len(splitinfo_guest_host)):\n            gain_host_i = self.decrypt(splitinfo_guest_host[i].gain)\n            if best_gain_host < gain_host_i:\n                best_gain_host = gain_host_i\n                best_gain_host_idx = i\n\n        if splitinfo_guest_host[0].gain >= best_gain_host - consts.FLOAT_ZERO:\n            best_splitinfo = splitinfo_guest_host[0]\n        else:\n            best_splitinfo = splitinfo_guest_host[best_gain_host_idx]\n            best_splitinfo.sum_grad = self.decrypt(best_splitinfo.sum_grad)\n            best_splitinfo.sum_hess = self.decrypt(best_splitinfo.sum_hess)\n            best_splitinfo.gain = best_gain_host\n\n        return best_splitinfo\n\n    def merge_splitinfo(self, splitinfo_guest, splitinfo_host):\n        LOGGER.info(\"merge splitinfo\")\n        merge_infos = []\n        for i in range(len(splitinfo_guest)):\n            splitinfo = [splitinfo_guest[i]]\n            for j in range(len(splitinfo_host)):\n                splitinfo.append(splitinfo_host[j][i])\n\n            merge_infos.append(splitinfo)\n\n        splitinfo_guest_host_table = session.parallelize(merge_infos,\n                                                         include_key=False,\n                                                         partition=self.data_bin._partitions)\n        best_splitinfo_table = splitinfo_guest_host_table.mapValues(self.find_best_split_guest_and_host)\n\n        best_splitinfos = [None for i in range(len(merge_infos))]\n        for _, best_splitinfo in best_splitinfo_table.collect():\n            best_splitinfos[_] = best_splitinfo\n        # best_splitinfos = [best_splitinfo[1] for best_splitinfo in best_splitinfo_table.collect()]\n\n        return best_splitinfos\n\n    def update_feature_importance(self, splitinfo):\n        if self.feature_importance_type == \"split\":\n            inc = 1\n        elif self.feature_importance_type == \"gain\":\n            inc = splitinfo.gain\n        else:\n            raise ValueError(\"feature importance type {} not support yet\".format(self.feature_importance_type))\n\n        sitename = splitinfo.sitename\n        fid = splitinfo.best_fid\n\n        if (sitename, fid) not in self.feature_importances_:\n            self.feature_importances_[(sitename, fid)] = 0\n\n        self.feature_importances_[(sitename, fid)] += inc\n\n    def update_tree_node_queue(self, splitinfos, max_depth_reach):\n        LOGGER.info(\"update tree node, splitlist length is {}, tree node queue size is {}\".format(\n            len(splitinfos), len(self.tree_node_queue)))\n        new_tree_node_queue = []\n        for i in range(len(self.tree_node_queue)):\n            sum_grad = self.tree_node_queue[i].sum_grad\n            sum_hess = self.tree_node_queue[i].sum_hess\n            if max_depth_reach or splitinfos[i].gain <= \\\n                    self.min_impurity_split + consts.FLOAT_ZERO:\n                self.tree_node_queue[i].is_leaf = True\n            else:\n                self.tree_node_queue[i].left_nodeid = self.tree_node_num + 1\n                self.tree_node_queue[i].right_nodeid = self.tree_node_num + 2\n                self.tree_node_num += 2\n\n                left_node = Node(id=self.tree_node_queue[i].left_nodeid,\n                                 sitename=self.sitename,\n                                 sum_grad=splitinfos[i].sum_grad,\n                                 sum_hess=splitinfos[i].sum_hess,\n                                 weight=self.splitter.node_weight(splitinfos[i].sum_grad, splitinfos[i].sum_hess))\n                right_node = Node(id=self.tree_node_queue[i].right_nodeid,\n                                  sitename=self.sitename,\n                                  sum_grad=sum_grad - splitinfos[i].sum_grad,\n                                  sum_hess=sum_hess - splitinfos[i].sum_hess,\n                                  weight=self.splitter.node_weight( \\\n                                      sum_grad - splitinfos[i].sum_grad,\n                                      sum_hess - splitinfos[i].sum_hess))\n\n                new_tree_node_queue.append(left_node)\n                new_tree_node_queue.append(right_node)\n\n                self.tree_node_queue[i].sitename = splitinfos[i].sitename\n                if self.tree_node_queue[i].sitename == self.sitename:\n                    self.tree_node_queue[i].fid = self.encode(\"feature_idx\", splitinfos[i].best_fid)\n                    self.tree_node_queue[i].bid = self.encode(\"feature_val\", splitinfos[i].best_bid,\n                                                              self.tree_node_queue[i].id)\n                    self.tree_node_queue[i].missing_dir = self.encode(\"missing_dir\",\n                                                                      splitinfos[i].missing_dir,\n                                                                      self.tree_node_queue[i].id)\n                else:\n                    self.tree_node_queue[i].fid = splitinfos[i].best_fid\n                    self.tree_node_queue[i].bid = splitinfos[i].best_bid\n\n                self.update_feature_importance(splitinfos[i])\n            self.tree_.append(self.tree_node_queue[i])\n\n        self.tree_node_queue = new_tree_node_queue\n\n    @staticmethod\n    def dispatch_node(value, tree_=None, decoder=None, sitename=consts.GUEST,\n                      split_maskdict=None, bin_sparse_points=None,\n                      use_missing=False, zero_as_missing=False,\n                      missing_dir_maskdict=None):\n        unleaf_state, nodeid = value[1]\n\n        if tree_[nodeid].is_leaf is True:\n            return tree_[nodeid].weight\n        else:\n            if tree_[nodeid].sitename == sitename:\n                fid = decoder(\"feature_idx\", tree_[nodeid].fid, split_maskdict=split_maskdict)\n                bid = decoder(\"feature_val\", tree_[nodeid].bid, nodeid, split_maskdict=split_maskdict)\n                if not use_missing:\n                    if value[0].features.get_data(fid, bin_sparse_points[fid]) <= bid:\n                        return 1, tree_[nodeid].left_nodeid\n                    else:\n                        return 1, tree_[nodeid].right_nodeid\n                else:\n                    missing_dir = decoder(\"missing_dir\", tree_[nodeid].missing_dir, nodeid,\n                                          missing_dir_maskdict=missing_dir_maskdict)\n\n                    missing_val = False\n                    if zero_as_missing:\n                        if value[0].features.get_data(fid, None) is None or \\\n                                value[0].features.get_data(fid) == NoneType():\n                            missing_val = True\n                    elif use_missing and value[0].features.get_data(fid) == NoneType():\n                        missing_val = True\n\n                    if missing_val:\n                        if missing_dir == 1:\n                            return 1, tree_[nodeid].right_nodeid\n                        else:\n                            return 1, tree_[nodeid].left_nodeid\n                    else:\n                        LOGGER.debug(\"fid is {}, bid is {}, sitename is {}\".format(fid, bid, sitename))\n                        if value[0].features.get_data(fid, bin_sparse_points[fid]) <= bid:\n                            return 1, tree_[nodeid].left_nodeid\n                        else:\n                            return 1, tree_[nodeid].right_nodeid\n            else:\n                return (1, tree_[nodeid].fid, tree_[nodeid].bid, tree_[nodeid].sitename,\n                        nodeid, tree_[nodeid].left_nodeid, tree_[nodeid].right_nodeid)\n\n    def sync_dispatch_node_host(self, dispatch_guest_data, dep=-1):\n        LOGGER.info(\"send node to host to dispath, depth is {}\".format(dep))\n        self.transfer_inst.dispatch_node_host.remote(dispatch_guest_data,\n                                                     role=consts.HOST,\n                                                     idx=-1,\n                                                     suffix=(dep,))\n        \"\"\"\n        federation.remote(obj=dispatch_guest_data,\n                          name=self.transfer_inst.dispatch_node_host.name,\n                          tag=self.transfer_inst.generate_transferid(self.transfer_inst.dispatch_node_host, dep),\n                          role=consts.HOST,\n                          idx=-1)\n        \"\"\"\n\n    def sync_dispatch_node_host_result(self, dep=-1):\n        LOGGER.info(\"get host dispatch result, depth is {}\".format(dep))\n        dispatch_node_host_result = self.transfer_inst.dispatch_node_host_result.get(idx=-1,\n                                                                                     suffix=(dep,))\n        \"\"\"\n        dispatch_node_host_result = federation.get(name=self.transfer_inst.dispatch_node_host_result.name,\n                                                   tag=self.transfer_inst.generate_transferid(\n                                                       self.transfer_inst.dispatch_node_host_result, dep),\n                                                   idx=-1)\n        \"\"\"\n        return dispatch_node_host_result\n\n    def redispatch_node(self, dep=-1, max_depth_reach=False):\n        LOGGER.info(\"redispatch node of depth {}\".format(dep))\n        dispatch_node_method = functools.partial(self.dispatch_node,\n                                                 tree_=self.tree_,\n                                                 decoder=self.decode,\n                                                 sitename=self.sitename,\n                                                 split_maskdict=self.split_maskdict,\n                                                 bin_sparse_points=self.bin_sparse_points,\n                                                 use_missing=self.use_missing,\n                                                 zero_as_missing=self.zero_as_missing,\n                                                 missing_dir_maskdict=self.missing_dir_maskdict)\n        dispatch_guest_result = self.data_bin_with_node_dispatch.mapValues(dispatch_node_method)\n        tree_node_num = self.tree_node_num\n        LOGGER.info(\"remask dispatch node result of depth {}\".format(dep))\n\n        dispatch_to_host_result = dispatch_guest_result.filter(\n            lambda key, value: isinstance(value, tuple) and len(value) > 2)\n\n        dispatch_guest_result = dispatch_guest_result.subtractByKey(dispatch_to_host_result)\n        leaf = dispatch_guest_result.filter(lambda key, value: isinstance(value, tuple) is False)\n        if self.predict_weights is None:\n            self.predict_weights = leaf\n        else:\n            self.predict_weights = self.predict_weights.union(leaf)\n\n        if max_depth_reach:\n            return\n\n        dispatch_guest_result = dispatch_guest_result.subtractByKey(leaf)\n\n        self.sync_dispatch_node_host(dispatch_to_host_result, dep)\n        dispatch_node_host_result = self.sync_dispatch_node_host_result(dep)\n\n        self.node_dispatch = None\n        for idx in range(len(dispatch_node_host_result)):\n            if self.node_dispatch is None:\n                self.node_dispatch = dispatch_node_host_result[idx]\n            else:\n                self.node_dispatch = self.node_dispatch.join(dispatch_node_host_result[idx], \\\n                                                             lambda unleaf_state_nodeid1, unleaf_state_nodeid2: \\\n                                                                 unleaf_state_nodeid1 if len(\n                                                                     unleaf_state_nodeid1) == 2 else unleaf_state_nodeid2)\n        self.node_dispatch = self.node_dispatch.union(dispatch_guest_result)\n\n    def remove_sensitive_info(self):\n        \"\"\"\n        host is not allowed to get weights/g/h\n        \"\"\"\n        new_tree_ = copy.deepcopy(self.tree_)\n        for node in new_tree_:\n            node.weight = None\n            node.sum_grad = None\n            node.sum_hess = None\n\n        return new_tree_\n\n    def sync_tree(self):\n        LOGGER.info(\"sync tree to host\")\n\n        tree_nodes = self.remove_sensitive_info()\n        self.transfer_inst.tree.remote(tree_nodes,\n                                       role=consts.HOST,\n                                       idx=-1)\n        \"\"\"\n        federation.remote(obj=self.tree_,\n                          name=self.transfer_inst.tree.name,\n                          tag=self.transfer_inst.generate_transferid(self.transfer_inst.tree),\n                          role=consts.HOST,\n                          idx=-1)\n        \"\"\"\n\n    def convert_bin_to_real(self):\n        LOGGER.info(\"convert tree node bins to real value\")\n        for i in range(len(self.tree_)):\n            if self.tree_[i].is_leaf is True:\n                continue\n            if self.tree_[i].sitename == self.sitename:\n                fid = self.decode(\"feature_idx\", self.tree_[i].fid, split_maskdict=self.split_maskdict)\n                bid = self.decode(\"feature_val\", self.tree_[i].bid, self.tree_[i].id, self.split_maskdict)\n                real_splitval = self.encode(\"feature_val\", self.bin_split_points[fid][bid], self.tree_[i].id)\n                self.tree_[i].bid = real_splitval\n\n    def fit(self):\n        LOGGER.info(\"begin to fit guest decision tree\")\n        self.sync_encrypted_grad_and_hess()\n\n        # LOGGER.debug(\"self.grad and hess is {}\".format(list(self.grad_and_hess.collect())))\n        root_sum_grad, root_sum_hess = self.get_grad_hess_sum(self.grad_and_hess)\n        root_node = Node(id=0, sitename=self.sitename, sum_grad=root_sum_grad, sum_hess=root_sum_hess,\n                         weight=self.splitter.node_weight(root_sum_grad, root_sum_hess))\n        self.tree_node_queue = [root_node]\n\n        self.dispatch_all_node_to_root()\n\n        for dep in range(self.max_depth):\n            LOGGER.info(\"start to fit depth {}, tree node queue size is {}\".format(dep, len(self.tree_node_queue)))\n\n            self.sync_tree_node_queue(self.tree_node_queue, dep)\n            if len(self.tree_node_queue) == 0:\n                break\n\n            self.sync_node_positions(dep)\n\n            self.data_bin_with_node_dispatch = self.data_bin.join(self.node_dispatch,\n                                                                  lambda data_inst, dispatch_info: (\n                                                                      data_inst, dispatch_info))\n\n            batch = 0\n            splitinfos = []\n            for i in range(0, len(self.tree_node_queue), self.max_split_nodes):\n                self.cur_split_nodes = self.tree_node_queue[i: i + self.max_split_nodes]\n\n                node_map = {}\n                node_num = 0\n                for tree_node in self.cur_split_nodes:\n                    node_map[tree_node.id] = node_num\n                    node_num += 1\n\n                acc_histograms = self.get_histograms(node_map=node_map)\n\n                self.best_splitinfo_guest = self.splitter.find_split(acc_histograms, self.valid_features,\n                                                                     self.data_bin._partitions,\n                                                                     self.sitename,\n                                                                     self.use_missing, self.zero_as_missing)\n                self.federated_find_split(dep, batch)\n                final_splitinfo_host = self.sync_final_split_host(dep, batch)\n\n                cur_splitinfos = self.merge_splitinfo(self.best_splitinfo_guest, final_splitinfo_host)\n                splitinfos.extend(cur_splitinfos)\n\n                batch += 1\n\n            self.update_tree_node_queue(splitinfos, False)\n\n            self.redispatch_node(dep)\n\n        if self.tree_node_queue:\n            self.update_tree_node_queue([], True)\n            self.data_bin_with_node_dispatch = self.data_bin.join(self.node_dispatch,\n                                                                  lambda data_inst, dispatch_info: (\n                                                                      data_inst, dispatch_info))\n\n            self.redispatch_node(self.max_depth, max_depth_reach=True)\n\n        self.sync_tree()\n        self.convert_bin_to_real()\n        tree_ = self.tree_\n        LOGGER.info(\"tree node num is %d\" % len(tree_))\n        LOGGER.info(\"end to fit guest decision tree\")\n\n    @staticmethod\n    def traverse_tree(predict_state, data_inst, tree_=None,\n                      decoder=None, sitename=consts.GUEST, split_maskdict=None,\n                      use_missing=None, zero_as_missing=None, missing_dir_maskdict=None):\n        nid, tag = predict_state\n\n        while tree_[nid].sitename == sitename:\n            if tree_[nid].is_leaf is True:\n                return tree_[nid].weight\n\n            fid = decoder(\"feature_idx\", tree_[nid].fid, split_maskdict=split_maskdict)\n            bid = decoder(\"feature_val\", tree_[nid].bid, nid, split_maskdict=split_maskdict)\n            if use_missing:\n                missing_dir = decoder(\"missing_dir\", 1, nid, missing_dir_maskdict=missing_dir_maskdict)\n            else:\n                missing_dir = 1\n\n            if use_missing and zero_as_missing:\n                missing_dir = decoder(\"missing_dir\", 1, nid, missing_dir_maskdict=missing_dir_maskdict)\n                if data_inst.features.get_data(fid) == NoneType() or data_inst.features.get_data(fid, None) is None:\n                    if missing_dir == 1:\n                        nid = tree_[nid].right_nodeid\n                    else:\n                        nid = tree_[nid].left_nodeid\n                elif data_inst.features.get_data(fid) <= bid:\n                    nid = tree_[nid].left_nodeid\n                else:\n                    nid = tree_[nid].right_nodeid\n            elif data_inst.features.get_data(fid) == NoneType():\n                if missing_dir == 1:\n                    nid = tree_[nid].right_nodeid\n                else:\n                    nid = tree_[nid].left_nodeid\n            elif data_inst.features.get_data(fid, 0) <= bid:\n                nid = tree_[nid].left_nodeid\n            else:\n                nid = tree_[nid].right_nodeid\n\n        return nid, 1\n\n    def sync_predict_finish_tag(self, finish_tag, send_times):\n        LOGGER.info(\"send the {}-th predict finish tag {} to host\".format(finish_tag, send_times))\n\n        self.transfer_inst.predict_finish_tag.remote(finish_tag,\n                                                     role=consts.HOST,\n                                                     idx=-1,\n                                                     suffix=(send_times,))\n        \"\"\"\n        federation.remote(obj=finish_tag,\n                          name=self.transfer_inst.predict_finish_tag.name,\n                          tag=self.transfer_inst.generate_transferid(self.transfer_inst.predict_finish_tag, send_times),\n                          role=consts.HOST,\n                          idx=-1)\n        \"\"\"\n\n    def sync_predict_data(self, predict_data, send_times):\n        LOGGER.info(\"send predict data to host, sending times is {}\".format(send_times))\n        self.transfer_inst.predict_data.remote(predict_data,\n                                               role=consts.HOST,\n                                               idx=-1,\n                                               suffix=(send_times,))\n\n        \"\"\"\n        federation.remote(obj=predict_data,\n                          name=self.transfer_inst.predict_data.name,\n                          tag=self.transfer_inst.generate_transferid(self.transfer_inst.predict_data, send_times),\n                          role=consts.HOST,\n                          idx=-1)\n        \"\"\"\n\n    def sync_data_predicted_by_host(self, send_times):\n        LOGGER.info(\"get predicted data by host, recv times is {}\".format(send_times))\n        predict_data = self.transfer_inst.predict_data_by_host.get(idx=-1,\n                                                                   suffix=(send_times,))\n        \"\"\"\n        predict_data = federation.get(name=self.transfer_inst.predict_data_by_host.name,\n                                      tag=self.transfer_inst.generate_transferid(\n                                          self.transfer_inst.predict_data_by_host, send_times),\n                                      idx=-1)\n        \"\"\"\n        return predict_data\n\n    @assert_io_num_rows_equal\n    def predict(self, data_inst):\n        LOGGER.info(\"start to predict!\")\n        predict_data = data_inst.mapValues(lambda data_inst: (0, 1))\n        site_host_send_times = 0\n        predict_result = None\n\n        while True:\n            traverse_tree = functools.partial(self.traverse_tree,\n                                              tree_=self.tree_,\n                                              decoder=self.decode,\n                                              sitename=self.sitename,\n                                              split_maskdict=self.split_maskdict,\n                                              use_missing=self.use_missing,\n                                              zero_as_missing=self.zero_as_missing,\n                                              missing_dir_maskdict=self.missing_dir_maskdict)\n            predict_data = predict_data.join(data_inst, traverse_tree)\n            predict_leaf = predict_data.filter(lambda key, value: isinstance(value, tuple) is False)\n            if predict_result is None:\n                predict_result = predict_leaf\n            else:\n                predict_result = predict_result.union(predict_leaf)\n\n            predict_data = predict_data.subtractByKey(predict_leaf)\n\n            unleaf_node_count = predict_data.count()\n\n            if unleaf_node_count == 0:\n                self.sync_predict_finish_tag(True, site_host_send_times)\n                break\n\n            self.sync_predict_finish_tag(False, site_host_send_times)\n            self.sync_predict_data(predict_data, site_host_send_times)\n\n            predict_data_host = self.sync_data_predicted_by_host(site_host_send_times)\n            for i in range(len(predict_data_host)):\n                predict_data = predict_data.join(predict_data_host[i],\n                                                 lambda state1_nodeid1, state2_nodeid2:\n                                                 state1_nodeid1 if state1_nodeid1[\n                                                                       1] == 0 else state2_nodeid2)\n\n            site_host_send_times += 1\n\n        LOGGER.info(\"predict finish!\")\n        return predict_result\n\n    def get_model_meta(self):\n        model_meta = DecisionTreeModelMeta()\n        model_meta.criterion_meta.CopyFrom(CriterionMeta(criterion_method=self.criterion_method,\n                                                         criterion_param=self.criterion_params))\n\n        model_meta.max_depth = self.max_depth\n        model_meta.min_sample_split = self.min_sample_split\n        model_meta.min_impurity_split = self.min_impurity_split\n        model_meta.min_leaf_node = self.min_leaf_node\n        model_meta.use_missing = self.use_missing\n        model_meta.zero_as_missing = self.zero_as_missing\n\n        return model_meta\n\n    def set_model_meta(self, model_meta):\n        self.max_depth = model_meta.max_depth\n        self.min_sample_split = model_meta.min_sample_split\n        self.min_impurity_split = model_meta.min_impurity_split\n        self.min_leaf_node = model_meta.min_leaf_node\n        self.criterion_method = model_meta.criterion_meta.criterion_method\n        self.criterion_params = list(model_meta.criterion_meta.criterion_param)\n        self.use_missing = model_meta.use_missing\n        self.zero_as_missing = model_meta.zero_as_missing\n\n    def get_model_param(self):\n        model_param = DecisionTreeModelParam()\n        for node in self.tree_:\n            model_param.tree_.add(id=node.id,\n                                  sitename=node.sitename,\n                                  fid=node.fid,\n                                  bid=node.bid,\n                                  weight=node.weight,\n                                  is_leaf=node.is_leaf,\n                                  left_nodeid=node.left_nodeid,\n                                  right_nodeid=node.right_nodeid,\n                                  missing_dir=node.missing_dir)\n            LOGGER.debug(\"missing_dir is {}, sitename is {}, is_leaf is {}\".format(node.missing_dir, node.sitename,\n                                                                                   node.is_leaf))\n\n        model_param.split_maskdict.update(self.split_maskdict)\n        model_param.missing_dir_maskdict.update(self.missing_dir_maskdict)\n\n        return model_param\n\n    def set_model_param(self, model_param):\n        self.tree_ = []\n        for node_param in model_param.tree_:\n            _node = Node(id=node_param.id,\n                         sitename=node_param.sitename,\n                         fid=node_param.fid,\n                         bid=node_param.bid,\n                         weight=node_param.weight,\n                         is_leaf=node_param.is_leaf,\n                         left_nodeid=node_param.left_nodeid,\n                         right_nodeid=node_param.right_nodeid,\n                         missing_dir=node_param.missing_dir)\n\n            self.tree_.append(_node)\n\n        self.split_maskdict = dict(model_param.split_maskdict)\n        self.missing_dir_maskdict = dict(model_param.missing_dir_maskdict)\n\n    def get_model(self):\n        model_meta = self.get_model_meta()\n        model_param = self.get_model_param()\n\n        return model_meta, model_param\n\n    def load_model(self, model_meta=None, model_param=None):\n        LOGGER.info(\"load tree model\")\n        self.set_model_meta(model_meta)\n        self.set_model_param(model_param)\n\n    def get_feature_importance(self):\n        return self.feature_importances_\n"], "filenames": ["federatedml/tree/hetero/hetero_decision_tree_guest.py"], "buggy_code_start_loc": [531], "buggy_code_end_loc": [536], "fixing_code_start_loc": [532], "fixing_code_end_loc": [549], "type": "CWE-668", "message": "An issue was discovered in function sync_tree in hetero_decision_tree_guest.py in WeBank FATE (Federated AI Technology Enabler) 0.1 through 1.4.2 allows attackers to read sensitive information during the training process of machine learning joint modeling.", "other": {"cve": {"id": "CVE-2020-25459", "sourceIdentifier": "cve@mitre.org", "published": "2022-06-16T21:15:07.713", "lastModified": "2022-06-28T17:06:16.787", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "An issue was discovered in function sync_tree in hetero_decision_tree_guest.py in WeBank FATE (Federated AI Technology Enabler) 0.1 through 1.4.2 allows attackers to read sensitive information during the training process of machine learning joint modeling."}, {"lang": "es", "value": "Se ha detectado un problema en la funci\u00f3n sync_tree en el archivo hetero_decision_tree_guest.py en WeBank FATE (Federated AI Technology Enabler) versiones 0.1 hasta 1.4.2, permite a atacantes leer informaci\u00f3n confidencial durante el proceso de entrenamiento del modelado conjunto de aprendizaje autom\u00e1tico"}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "NONE", "availabilityImpact": "NONE", "baseScore": 7.5, "baseSeverity": "HIGH"}, "exploitabilityScore": 3.9, "impactScore": 3.6}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:N/AC:L/Au:N/C:P/I:N/A:N", "accessVector": "NETWORK", "accessComplexity": "LOW", "authentication": "NONE", "confidentialityImpact": "PARTIAL", "integrityImpact": "NONE", "availabilityImpact": "NONE", "baseScore": 5.0}, "baseSeverity": "MEDIUM", "exploitabilityScore": 10.0, "impactScore": 2.9, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-668"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:webank:federated_ai_technology_enabler:*:*:*:*:*:*:*:*", "versionStartIncluding": "0.1", "versionEndIncluding": "1.4.2", "matchCriteriaId": "54363CB1-9BC4-4040-AE2C-6756D12DAB91"}]}]}], "references": [{"url": "https://github.com/FederatedAI/FATE/commit/6feccf6d752184a6f9365d56a76fe627983e7139", "source": "cve@mitre.org", "tags": ["Patch", "Third Party Advisory"]}]}, "github_commit_url": "https://github.com/FederatedAI/FATE/commit/6feccf6d752184a6f9365d56a76fe627983e7139"}}
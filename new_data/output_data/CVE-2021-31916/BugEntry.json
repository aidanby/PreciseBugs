{"buggy_code": ["/*\n * Copyright (C) 2001, 2002 Sistina Software (UK) Limited.\n * Copyright (C) 2004 - 2006 Red Hat, Inc. All rights reserved.\n *\n * This file is released under the GPL.\n */\n\n#include \"dm-core.h\"\n\n#include <linux/module.h>\n#include <linux/vmalloc.h>\n#include <linux/miscdevice.h>\n#include <linux/sched/mm.h>\n#include <linux/init.h>\n#include <linux/wait.h>\n#include <linux/slab.h>\n#include <linux/dm-ioctl.h>\n#include <linux/hdreg.h>\n#include <linux/compat.h>\n\n#include <linux/uaccess.h>\n\n#define DM_MSG_PREFIX \"ioctl\"\n#define DM_DRIVER_EMAIL \"dm-devel@redhat.com\"\n\nstruct dm_file {\n\t/*\n\t * poll will wait until the global event number is greater than\n\t * this value.\n\t */\n\tvolatile unsigned global_event_nr;\n};\n\n/*-----------------------------------------------------------------\n * The ioctl interface needs to be able to look up devices by\n * name or uuid.\n *---------------------------------------------------------------*/\nstruct hash_cell {\n\tstruct list_head name_list;\n\tstruct list_head uuid_list;\n\n\tchar *name;\n\tchar *uuid;\n\tstruct mapped_device *md;\n\tstruct dm_table *new_map;\n};\n\nstruct vers_iter {\n    size_t param_size;\n    struct dm_target_versions *vers, *old_vers;\n    char *end;\n    uint32_t flags;\n};\n\n\n#define NUM_BUCKETS 64\n#define MASK_BUCKETS (NUM_BUCKETS - 1)\nstatic struct list_head _name_buckets[NUM_BUCKETS];\nstatic struct list_head _uuid_buckets[NUM_BUCKETS];\n\nstatic void dm_hash_remove_all(bool keep_open_devices, bool mark_deferred, bool only_deferred);\n\n/*\n * Guards access to both hash tables.\n */\nstatic DECLARE_RWSEM(_hash_lock);\n\n/*\n * Protects use of mdptr to obtain hash cell name and uuid from mapped device.\n */\nstatic DEFINE_MUTEX(dm_hash_cells_mutex);\n\nstatic void init_buckets(struct list_head *buckets)\n{\n\tunsigned int i;\n\n\tfor (i = 0; i < NUM_BUCKETS; i++)\n\t\tINIT_LIST_HEAD(buckets + i);\n}\n\nstatic int dm_hash_init(void)\n{\n\tinit_buckets(_name_buckets);\n\tinit_buckets(_uuid_buckets);\n\treturn 0;\n}\n\nstatic void dm_hash_exit(void)\n{\n\tdm_hash_remove_all(false, false, false);\n}\n\n/*-----------------------------------------------------------------\n * Hash function:\n * We're not really concerned with the str hash function being\n * fast since it's only used by the ioctl interface.\n *---------------------------------------------------------------*/\nstatic unsigned int hash_str(const char *str)\n{\n\tconst unsigned int hash_mult = 2654435387U;\n\tunsigned int h = 0;\n\n\twhile (*str)\n\t\th = (h + (unsigned int) *str++) * hash_mult;\n\n\treturn h & MASK_BUCKETS;\n}\n\n/*-----------------------------------------------------------------\n * Code for looking up a device by name\n *---------------------------------------------------------------*/\nstatic struct hash_cell *__get_name_cell(const char *str)\n{\n\tstruct hash_cell *hc;\n\tunsigned int h = hash_str(str);\n\n\tlist_for_each_entry (hc, _name_buckets + h, name_list)\n\t\tif (!strcmp(hc->name, str)) {\n\t\t\tdm_get(hc->md);\n\t\t\treturn hc;\n\t\t}\n\n\treturn NULL;\n}\n\nstatic struct hash_cell *__get_uuid_cell(const char *str)\n{\n\tstruct hash_cell *hc;\n\tunsigned int h = hash_str(str);\n\n\tlist_for_each_entry (hc, _uuid_buckets + h, uuid_list)\n\t\tif (!strcmp(hc->uuid, str)) {\n\t\t\tdm_get(hc->md);\n\t\t\treturn hc;\n\t\t}\n\n\treturn NULL;\n}\n\nstatic struct hash_cell *__get_dev_cell(uint64_t dev)\n{\n\tstruct mapped_device *md;\n\tstruct hash_cell *hc;\n\n\tmd = dm_get_md(huge_decode_dev(dev));\n\tif (!md)\n\t\treturn NULL;\n\n\thc = dm_get_mdptr(md);\n\tif (!hc) {\n\t\tdm_put(md);\n\t\treturn NULL;\n\t}\n\n\treturn hc;\n}\n\n/*-----------------------------------------------------------------\n * Inserting, removing and renaming a device.\n *---------------------------------------------------------------*/\nstatic struct hash_cell *alloc_cell(const char *name, const char *uuid,\n\t\t\t\t    struct mapped_device *md)\n{\n\tstruct hash_cell *hc;\n\n\thc = kmalloc(sizeof(*hc), GFP_KERNEL);\n\tif (!hc)\n\t\treturn NULL;\n\n\thc->name = kstrdup(name, GFP_KERNEL);\n\tif (!hc->name) {\n\t\tkfree(hc);\n\t\treturn NULL;\n\t}\n\n\tif (!uuid)\n\t\thc->uuid = NULL;\n\n\telse {\n\t\thc->uuid = kstrdup(uuid, GFP_KERNEL);\n\t\tif (!hc->uuid) {\n\t\t\tkfree(hc->name);\n\t\t\tkfree(hc);\n\t\t\treturn NULL;\n\t\t}\n\t}\n\n\tINIT_LIST_HEAD(&hc->name_list);\n\tINIT_LIST_HEAD(&hc->uuid_list);\n\thc->md = md;\n\thc->new_map = NULL;\n\treturn hc;\n}\n\nstatic void free_cell(struct hash_cell *hc)\n{\n\tif (hc) {\n\t\tkfree(hc->name);\n\t\tkfree(hc->uuid);\n\t\tkfree(hc);\n\t}\n}\n\n/*\n * The kdev_t and uuid of a device can never change once it is\n * initially inserted.\n */\nstatic int dm_hash_insert(const char *name, const char *uuid, struct mapped_device *md)\n{\n\tstruct hash_cell *cell, *hc;\n\n\t/*\n\t * Allocate the new cells.\n\t */\n\tcell = alloc_cell(name, uuid, md);\n\tif (!cell)\n\t\treturn -ENOMEM;\n\n\t/*\n\t * Insert the cell into both hash tables.\n\t */\n\tdown_write(&_hash_lock);\n\thc = __get_name_cell(name);\n\tif (hc) {\n\t\tdm_put(hc->md);\n\t\tgoto bad;\n\t}\n\n\tlist_add(&cell->name_list, _name_buckets + hash_str(name));\n\n\tif (uuid) {\n\t\thc = __get_uuid_cell(uuid);\n\t\tif (hc) {\n\t\t\tlist_del(&cell->name_list);\n\t\t\tdm_put(hc->md);\n\t\t\tgoto bad;\n\t\t}\n\t\tlist_add(&cell->uuid_list, _uuid_buckets + hash_str(uuid));\n\t}\n\tdm_get(md);\n\tmutex_lock(&dm_hash_cells_mutex);\n\tdm_set_mdptr(md, cell);\n\tmutex_unlock(&dm_hash_cells_mutex);\n\tup_write(&_hash_lock);\n\n\treturn 0;\n\n bad:\n\tup_write(&_hash_lock);\n\tfree_cell(cell);\n\treturn -EBUSY;\n}\n\nstatic struct dm_table *__hash_remove(struct hash_cell *hc)\n{\n\tstruct dm_table *table;\n\tint srcu_idx;\n\n\t/* remove from the dev hash */\n\tlist_del(&hc->uuid_list);\n\tlist_del(&hc->name_list);\n\tmutex_lock(&dm_hash_cells_mutex);\n\tdm_set_mdptr(hc->md, NULL);\n\tmutex_unlock(&dm_hash_cells_mutex);\n\n\ttable = dm_get_live_table(hc->md, &srcu_idx);\n\tif (table)\n\t\tdm_table_event(table);\n\tdm_put_live_table(hc->md, srcu_idx);\n\n\ttable = NULL;\n\tif (hc->new_map)\n\t\ttable = hc->new_map;\n\tdm_put(hc->md);\n\tfree_cell(hc);\n\n\treturn table;\n}\n\nstatic void dm_hash_remove_all(bool keep_open_devices, bool mark_deferred, bool only_deferred)\n{\n\tint i, dev_skipped;\n\tstruct hash_cell *hc;\n\tstruct mapped_device *md;\n\tstruct dm_table *t;\n\nretry:\n\tdev_skipped = 0;\n\n\tdown_write(&_hash_lock);\n\n\tfor (i = 0; i < NUM_BUCKETS; i++) {\n\t\tlist_for_each_entry(hc, _name_buckets + i, name_list) {\n\t\t\tmd = hc->md;\n\t\t\tdm_get(md);\n\n\t\t\tif (keep_open_devices &&\n\t\t\t    dm_lock_for_deletion(md, mark_deferred, only_deferred)) {\n\t\t\t\tdm_put(md);\n\t\t\t\tdev_skipped++;\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tt = __hash_remove(hc);\n\n\t\t\tup_write(&_hash_lock);\n\n\t\t\tif (t) {\n\t\t\t\tdm_sync_table(md);\n\t\t\t\tdm_table_destroy(t);\n\t\t\t}\n\t\t\tdm_put(md);\n\t\t\tif (likely(keep_open_devices))\n\t\t\t\tdm_destroy(md);\n\t\t\telse\n\t\t\t\tdm_destroy_immediate(md);\n\n\t\t\t/*\n\t\t\t * Some mapped devices may be using other mapped\n\t\t\t * devices, so repeat until we make no further\n\t\t\t * progress.  If a new mapped device is created\n\t\t\t * here it will also get removed.\n\t\t\t */\n\t\t\tgoto retry;\n\t\t}\n\t}\n\n\tup_write(&_hash_lock);\n\n\tif (dev_skipped)\n\t\tDMWARN(\"remove_all left %d open device(s)\", dev_skipped);\n}\n\n/*\n * Set the uuid of a hash_cell that isn't already set.\n */\nstatic void __set_cell_uuid(struct hash_cell *hc, char *new_uuid)\n{\n\tmutex_lock(&dm_hash_cells_mutex);\n\thc->uuid = new_uuid;\n\tmutex_unlock(&dm_hash_cells_mutex);\n\n\tlist_add(&hc->uuid_list, _uuid_buckets + hash_str(new_uuid));\n}\n\n/*\n * Changes the name of a hash_cell and returns the old name for\n * the caller to free.\n */\nstatic char *__change_cell_name(struct hash_cell *hc, char *new_name)\n{\n\tchar *old_name;\n\n\t/*\n\t * Rename and move the name cell.\n\t */\n\tlist_del(&hc->name_list);\n\told_name = hc->name;\n\n\tmutex_lock(&dm_hash_cells_mutex);\n\thc->name = new_name;\n\tmutex_unlock(&dm_hash_cells_mutex);\n\n\tlist_add(&hc->name_list, _name_buckets + hash_str(new_name));\n\n\treturn old_name;\n}\n\nstatic struct mapped_device *dm_hash_rename(struct dm_ioctl *param,\n\t\t\t\t\t    const char *new)\n{\n\tchar *new_data, *old_name = NULL;\n\tstruct hash_cell *hc;\n\tstruct dm_table *table;\n\tstruct mapped_device *md;\n\tunsigned change_uuid = (param->flags & DM_UUID_FLAG) ? 1 : 0;\n\tint srcu_idx;\n\n\t/*\n\t * duplicate new.\n\t */\n\tnew_data = kstrdup(new, GFP_KERNEL);\n\tif (!new_data)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tdown_write(&_hash_lock);\n\n\t/*\n\t * Is new free ?\n\t */\n\tif (change_uuid)\n\t\thc = __get_uuid_cell(new);\n\telse\n\t\thc = __get_name_cell(new);\n\n\tif (hc) {\n\t\tDMWARN(\"Unable to change %s on mapped device %s to one that \"\n\t\t       \"already exists: %s\",\n\t\t       change_uuid ? \"uuid\" : \"name\",\n\t\t       param->name, new);\n\t\tdm_put(hc->md);\n\t\tup_write(&_hash_lock);\n\t\tkfree(new_data);\n\t\treturn ERR_PTR(-EBUSY);\n\t}\n\n\t/*\n\t * Is there such a device as 'old' ?\n\t */\n\thc = __get_name_cell(param->name);\n\tif (!hc) {\n\t\tDMWARN(\"Unable to rename non-existent device, %s to %s%s\",\n\t\t       param->name, change_uuid ? \"uuid \" : \"\", new);\n\t\tup_write(&_hash_lock);\n\t\tkfree(new_data);\n\t\treturn ERR_PTR(-ENXIO);\n\t}\n\n\t/*\n\t * Does this device already have a uuid?\n\t */\n\tif (change_uuid && hc->uuid) {\n\t\tDMWARN(\"Unable to change uuid of mapped device %s to %s \"\n\t\t       \"because uuid is already set to %s\",\n\t\t       param->name, new, hc->uuid);\n\t\tdm_put(hc->md);\n\t\tup_write(&_hash_lock);\n\t\tkfree(new_data);\n\t\treturn ERR_PTR(-EINVAL);\n\t}\n\n\tif (change_uuid)\n\t\t__set_cell_uuid(hc, new_data);\n\telse\n\t\told_name = __change_cell_name(hc, new_data);\n\n\t/*\n\t * Wake up any dm event waiters.\n\t */\n\ttable = dm_get_live_table(hc->md, &srcu_idx);\n\tif (table)\n\t\tdm_table_event(table);\n\tdm_put_live_table(hc->md, srcu_idx);\n\n\tif (!dm_kobject_uevent(hc->md, KOBJ_CHANGE, param->event_nr))\n\t\tparam->flags |= DM_UEVENT_GENERATED_FLAG;\n\n\tmd = hc->md;\n\tup_write(&_hash_lock);\n\tkfree(old_name);\n\n\treturn md;\n}\n\nvoid dm_deferred_remove(void)\n{\n\tdm_hash_remove_all(true, false, true);\n}\n\n/*-----------------------------------------------------------------\n * Implementation of the ioctl commands\n *---------------------------------------------------------------*/\n/*\n * All the ioctl commands get dispatched to functions with this\n * prototype.\n */\ntypedef int (*ioctl_fn)(struct file *filp, struct dm_ioctl *param, size_t param_size);\n\nstatic int remove_all(struct file *filp, struct dm_ioctl *param, size_t param_size)\n{\n\tdm_hash_remove_all(true, !!(param->flags & DM_DEFERRED_REMOVE), false);\n\tparam->data_size = 0;\n\treturn 0;\n}\n\n/*\n * Round up the ptr to an 8-byte boundary.\n */\n#define ALIGN_MASK 7\nstatic inline size_t align_val(size_t val)\n{\n\treturn (val + ALIGN_MASK) & ~ALIGN_MASK;\n}\nstatic inline void *align_ptr(void *ptr)\n{\n\treturn (void *)align_val((size_t)ptr);\n}\n\n/*\n * Retrieves the data payload buffer from an already allocated\n * struct dm_ioctl.\n */\nstatic void *get_result_buffer(struct dm_ioctl *param, size_t param_size,\n\t\t\t       size_t *len)\n{\n\tparam->data_start = align_ptr(param + 1) - (void *) param;\n\n\tif (param->data_start < param_size)\n\t\t*len = param_size - param->data_start;\n\telse\n\t\t*len = 0;\n\n\treturn ((void *) param) + param->data_start;\n}\n\nstatic int list_devices(struct file *filp, struct dm_ioctl *param, size_t param_size)\n{\n\tunsigned int i;\n\tstruct hash_cell *hc;\n\tsize_t len, needed = 0;\n\tstruct gendisk *disk;\n\tstruct dm_name_list *orig_nl, *nl, *old_nl = NULL;\n\tuint32_t *event_nr;\n\n\tdown_write(&_hash_lock);\n\n\t/*\n\t * Loop through all the devices working out how much\n\t * space we need.\n\t */\n\tfor (i = 0; i < NUM_BUCKETS; i++) {\n\t\tlist_for_each_entry (hc, _name_buckets + i, name_list) {\n\t\t\tneeded += align_val(offsetof(struct dm_name_list, name) + strlen(hc->name) + 1);\n\t\t\tneeded += align_val(sizeof(uint32_t));\n\t\t}\n\t}\n\n\t/*\n\t * Grab our output buffer.\n\t */\n\tnl = orig_nl = get_result_buffer(param, param_size, &len);\n\tif (len < needed) {\n\t\tparam->flags |= DM_BUFFER_FULL_FLAG;\n\t\tgoto out;\n\t}\n\tparam->data_size = param->data_start + needed;\n\n\tnl->dev = 0;\t/* Flags no data */\n\n\t/*\n\t * Now loop through filling out the names.\n\t */\n\tfor (i = 0; i < NUM_BUCKETS; i++) {\n\t\tlist_for_each_entry (hc, _name_buckets + i, name_list) {\n\t\t\tif (old_nl)\n\t\t\t\told_nl->next = (uint32_t) ((void *) nl -\n\t\t\t\t\t\t\t   (void *) old_nl);\n\t\t\tdisk = dm_disk(hc->md);\n\t\t\tnl->dev = huge_encode_dev(disk_devt(disk));\n\t\t\tnl->next = 0;\n\t\t\tstrcpy(nl->name, hc->name);\n\n\t\t\told_nl = nl;\n\t\t\tevent_nr = align_ptr(nl->name + strlen(hc->name) + 1);\n\t\t\t*event_nr = dm_get_event_nr(hc->md);\n\t\t\tnl = align_ptr(event_nr + 1);\n\t\t}\n\t}\n\t/*\n\t * If mismatch happens, security may be compromised due to buffer\n\t * overflow, so it's better to crash.\n\t */\n\tBUG_ON((char *)nl - (char *)orig_nl != needed);\n\n out:\n\tup_write(&_hash_lock);\n\treturn 0;\n}\n\nstatic void list_version_get_needed(struct target_type *tt, void *needed_param)\n{\n    size_t *needed = needed_param;\n\n    *needed += sizeof(struct dm_target_versions);\n    *needed += strlen(tt->name);\n    *needed += ALIGN_MASK;\n}\n\nstatic void list_version_get_info(struct target_type *tt, void *param)\n{\n    struct vers_iter *info = param;\n\n    /* Check space - it might have changed since the first iteration */\n    if ((char *)info->vers + sizeof(tt->version) + strlen(tt->name) + 1 >\n\tinfo->end) {\n\n\tinfo->flags = DM_BUFFER_FULL_FLAG;\n\treturn;\n    }\n\n    if (info->old_vers)\n\tinfo->old_vers->next = (uint32_t) ((void *)info->vers -\n\t\t\t\t\t   (void *)info->old_vers);\n    info->vers->version[0] = tt->version[0];\n    info->vers->version[1] = tt->version[1];\n    info->vers->version[2] = tt->version[2];\n    info->vers->next = 0;\n    strcpy(info->vers->name, tt->name);\n\n    info->old_vers = info->vers;\n    info->vers = align_ptr(((void *) ++info->vers) + strlen(tt->name) + 1);\n}\n\nstatic int __list_versions(struct dm_ioctl *param, size_t param_size, const char *name)\n{\n\tsize_t len, needed = 0;\n\tstruct dm_target_versions *vers;\n\tstruct vers_iter iter_info;\n\tstruct target_type *tt = NULL;\n\n\tif (name) {\n\t\ttt = dm_get_target_type(name);\n\t\tif (!tt)\n\t\t\treturn -EINVAL;\n\t}\n\n\t/*\n\t * Loop through all the devices working out how much\n\t * space we need.\n\t */\n\tif (!tt)\n\t\tdm_target_iterate(list_version_get_needed, &needed);\n\telse\n\t\tlist_version_get_needed(tt, &needed);\n\n\t/*\n\t * Grab our output buffer.\n\t */\n\tvers = get_result_buffer(param, param_size, &len);\n\tif (len < needed) {\n\t\tparam->flags |= DM_BUFFER_FULL_FLAG;\n\t\tgoto out;\n\t}\n\tparam->data_size = param->data_start + needed;\n\n\titer_info.param_size = param_size;\n\titer_info.old_vers = NULL;\n\titer_info.vers = vers;\n\titer_info.flags = 0;\n\titer_info.end = (char *)vers+len;\n\n\t/*\n\t * Now loop through filling out the names & versions.\n\t */\n\tif (!tt)\n\t\tdm_target_iterate(list_version_get_info, &iter_info);\n\telse\n\t\tlist_version_get_info(tt, &iter_info);\n\tparam->flags |= iter_info.flags;\n\n out:\n\tif (tt)\n\t\tdm_put_target_type(tt);\n\treturn 0;\n}\n\nstatic int list_versions(struct file *filp, struct dm_ioctl *param, size_t param_size)\n{\n\treturn __list_versions(param, param_size, NULL);\n}\n\nstatic int get_target_version(struct file *filp, struct dm_ioctl *param, size_t param_size)\n{\n\treturn __list_versions(param, param_size, param->name);\n}\n\nstatic int check_name(const char *name)\n{\n\tif (strchr(name, '/')) {\n\t\tDMWARN(\"invalid device name\");\n\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\n/*\n * On successful return, the caller must not attempt to acquire\n * _hash_lock without first calling dm_put_live_table, because dm_table_destroy\n * waits for this dm_put_live_table and could be called under this lock.\n */\nstatic struct dm_table *dm_get_inactive_table(struct mapped_device *md, int *srcu_idx)\n{\n\tstruct hash_cell *hc;\n\tstruct dm_table *table = NULL;\n\n\t/* increment rcu count, we don't care about the table pointer */\n\tdm_get_live_table(md, srcu_idx);\n\n\tdown_read(&_hash_lock);\n\thc = dm_get_mdptr(md);\n\tif (!hc || hc->md != md) {\n\t\tDMWARN(\"device has been removed from the dev hash table.\");\n\t\tgoto out;\n\t}\n\n\ttable = hc->new_map;\n\nout:\n\tup_read(&_hash_lock);\n\n\treturn table;\n}\n\nstatic struct dm_table *dm_get_live_or_inactive_table(struct mapped_device *md,\n\t\t\t\t\t\t      struct dm_ioctl *param,\n\t\t\t\t\t\t      int *srcu_idx)\n{\n\treturn (param->flags & DM_QUERY_INACTIVE_TABLE_FLAG) ?\n\t\tdm_get_inactive_table(md, srcu_idx) : dm_get_live_table(md, srcu_idx);\n}\n\n/*\n * Fills in a dm_ioctl structure, ready for sending back to\n * userland.\n */\nstatic void __dev_status(struct mapped_device *md, struct dm_ioctl *param)\n{\n\tstruct gendisk *disk = dm_disk(md);\n\tstruct dm_table *table;\n\tint srcu_idx;\n\n\tparam->flags &= ~(DM_SUSPEND_FLAG | DM_READONLY_FLAG |\n\t\t\t  DM_ACTIVE_PRESENT_FLAG | DM_INTERNAL_SUSPEND_FLAG);\n\n\tif (dm_suspended_md(md))\n\t\tparam->flags |= DM_SUSPEND_FLAG;\n\n\tif (dm_suspended_internally_md(md))\n\t\tparam->flags |= DM_INTERNAL_SUSPEND_FLAG;\n\n\tif (dm_test_deferred_remove_flag(md))\n\t\tparam->flags |= DM_DEFERRED_REMOVE;\n\n\tparam->dev = huge_encode_dev(disk_devt(disk));\n\n\t/*\n\t * Yes, this will be out of date by the time it gets back\n\t * to userland, but it is still very useful for\n\t * debugging.\n\t */\n\tparam->open_count = dm_open_count(md);\n\n\tparam->event_nr = dm_get_event_nr(md);\n\tparam->target_count = 0;\n\n\ttable = dm_get_live_table(md, &srcu_idx);\n\tif (table) {\n\t\tif (!(param->flags & DM_QUERY_INACTIVE_TABLE_FLAG)) {\n\t\t\tif (get_disk_ro(disk))\n\t\t\t\tparam->flags |= DM_READONLY_FLAG;\n\t\t\tparam->target_count = dm_table_get_num_targets(table);\n\t\t}\n\n\t\tparam->flags |= DM_ACTIVE_PRESENT_FLAG;\n\t}\n\tdm_put_live_table(md, srcu_idx);\n\n\tif (param->flags & DM_QUERY_INACTIVE_TABLE_FLAG) {\n\t\tint srcu_idx;\n\t\ttable = dm_get_inactive_table(md, &srcu_idx);\n\t\tif (table) {\n\t\t\tif (!(dm_table_get_mode(table) & FMODE_WRITE))\n\t\t\t\tparam->flags |= DM_READONLY_FLAG;\n\t\t\tparam->target_count = dm_table_get_num_targets(table);\n\t\t}\n\t\tdm_put_live_table(md, srcu_idx);\n\t}\n}\n\nstatic int dev_create(struct file *filp, struct dm_ioctl *param, size_t param_size)\n{\n\tint r, m = DM_ANY_MINOR;\n\tstruct mapped_device *md;\n\n\tr = check_name(param->name);\n\tif (r)\n\t\treturn r;\n\n\tif (param->flags & DM_PERSISTENT_DEV_FLAG)\n\t\tm = MINOR(huge_decode_dev(param->dev));\n\n\tr = dm_create(m, &md);\n\tif (r)\n\t\treturn r;\n\n\tr = dm_hash_insert(param->name, *param->uuid ? param->uuid : NULL, md);\n\tif (r) {\n\t\tdm_put(md);\n\t\tdm_destroy(md);\n\t\treturn r;\n\t}\n\n\tparam->flags &= ~DM_INACTIVE_PRESENT_FLAG;\n\n\t__dev_status(md, param);\n\n\tdm_put(md);\n\n\treturn 0;\n}\n\n/*\n * Always use UUID for lookups if it's present, otherwise use name or dev.\n */\nstatic struct hash_cell *__find_device_hash_cell(struct dm_ioctl *param)\n{\n\tstruct hash_cell *hc = NULL;\n\n\tif (*param->uuid) {\n\t\tif (*param->name || param->dev)\n\t\t\treturn NULL;\n\n\t\thc = __get_uuid_cell(param->uuid);\n\t\tif (!hc)\n\t\t\treturn NULL;\n\t} else if (*param->name) {\n\t\tif (param->dev)\n\t\t\treturn NULL;\n\n\t\thc = __get_name_cell(param->name);\n\t\tif (!hc)\n\t\t\treturn NULL;\n\t} else if (param->dev) {\n\t\thc = __get_dev_cell(param->dev);\n\t\tif (!hc)\n\t\t\treturn NULL;\n\t} else\n\t\treturn NULL;\n\n\t/*\n\t * Sneakily write in both the name and the uuid\n\t * while we have the cell.\n\t */\n\tstrlcpy(param->name, hc->name, sizeof(param->name));\n\tif (hc->uuid)\n\t\tstrlcpy(param->uuid, hc->uuid, sizeof(param->uuid));\n\telse\n\t\tparam->uuid[0] = '\\0';\n\n\tif (hc->new_map)\n\t\tparam->flags |= DM_INACTIVE_PRESENT_FLAG;\n\telse\n\t\tparam->flags &= ~DM_INACTIVE_PRESENT_FLAG;\n\n\treturn hc;\n}\n\nstatic struct mapped_device *find_device(struct dm_ioctl *param)\n{\n\tstruct hash_cell *hc;\n\tstruct mapped_device *md = NULL;\n\n\tdown_read(&_hash_lock);\n\thc = __find_device_hash_cell(param);\n\tif (hc)\n\t\tmd = hc->md;\n\tup_read(&_hash_lock);\n\n\treturn md;\n}\n\nstatic int dev_remove(struct file *filp, struct dm_ioctl *param, size_t param_size)\n{\n\tstruct hash_cell *hc;\n\tstruct mapped_device *md;\n\tint r;\n\tstruct dm_table *t;\n\n\tdown_write(&_hash_lock);\n\thc = __find_device_hash_cell(param);\n\n\tif (!hc) {\n\t\tDMDEBUG_LIMIT(\"device doesn't appear to be in the dev hash table.\");\n\t\tup_write(&_hash_lock);\n\t\treturn -ENXIO;\n\t}\n\n\tmd = hc->md;\n\n\t/*\n\t * Ensure the device is not open and nothing further can open it.\n\t */\n\tr = dm_lock_for_deletion(md, !!(param->flags & DM_DEFERRED_REMOVE), false);\n\tif (r) {\n\t\tif (r == -EBUSY && param->flags & DM_DEFERRED_REMOVE) {\n\t\t\tup_write(&_hash_lock);\n\t\t\tdm_put(md);\n\t\t\treturn 0;\n\t\t}\n\t\tDMDEBUG_LIMIT(\"unable to remove open device %s\", hc->name);\n\t\tup_write(&_hash_lock);\n\t\tdm_put(md);\n\t\treturn r;\n\t}\n\n\tt = __hash_remove(hc);\n\tup_write(&_hash_lock);\n\n\tif (t) {\n\t\tdm_sync_table(md);\n\t\tdm_table_destroy(t);\n\t}\n\n\tparam->flags &= ~DM_DEFERRED_REMOVE;\n\n\tif (!dm_kobject_uevent(md, KOBJ_REMOVE, param->event_nr))\n\t\tparam->flags |= DM_UEVENT_GENERATED_FLAG;\n\n\tdm_put(md);\n\tdm_destroy(md);\n\treturn 0;\n}\n\n/*\n * Check a string doesn't overrun the chunk of\n * memory we copied from userland.\n */\nstatic int invalid_str(char *str, void *end)\n{\n\twhile ((void *) str < end)\n\t\tif (!*str++)\n\t\t\treturn 0;\n\n\treturn -EINVAL;\n}\n\nstatic int dev_rename(struct file *filp, struct dm_ioctl *param, size_t param_size)\n{\n\tint r;\n\tchar *new_data = (char *) param + param->data_start;\n\tstruct mapped_device *md;\n\tunsigned change_uuid = (param->flags & DM_UUID_FLAG) ? 1 : 0;\n\n\tif (new_data < param->data ||\n\t    invalid_str(new_data, (void *) param + param_size) || !*new_data ||\n\t    strlen(new_data) > (change_uuid ? DM_UUID_LEN - 1 : DM_NAME_LEN - 1)) {\n\t\tDMWARN(\"Invalid new mapped device name or uuid string supplied.\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (!change_uuid) {\n\t\tr = check_name(new_data);\n\t\tif (r)\n\t\t\treturn r;\n\t}\n\n\tmd = dm_hash_rename(param, new_data);\n\tif (IS_ERR(md))\n\t\treturn PTR_ERR(md);\n\n\t__dev_status(md, param);\n\tdm_put(md);\n\n\treturn 0;\n}\n\nstatic int dev_set_geometry(struct file *filp, struct dm_ioctl *param, size_t param_size)\n{\n\tint r = -EINVAL, x;\n\tstruct mapped_device *md;\n\tstruct hd_geometry geometry;\n\tunsigned long indata[4];\n\tchar *geostr = (char *) param + param->data_start;\n\tchar dummy;\n\n\tmd = find_device(param);\n\tif (!md)\n\t\treturn -ENXIO;\n\n\tif (geostr < param->data ||\n\t    invalid_str(geostr, (void *) param + param_size)) {\n\t\tDMWARN(\"Invalid geometry supplied.\");\n\t\tgoto out;\n\t}\n\n\tx = sscanf(geostr, \"%lu %lu %lu %lu%c\", indata,\n\t\t   indata + 1, indata + 2, indata + 3, &dummy);\n\n\tif (x != 4) {\n\t\tDMWARN(\"Unable to interpret geometry settings.\");\n\t\tgoto out;\n\t}\n\n\tif (indata[0] > 65535 || indata[1] > 255 ||\n\t    indata[2] > 255 || indata[3] > ULONG_MAX) {\n\t\tDMWARN(\"Geometry exceeds range limits.\");\n\t\tgoto out;\n\t}\n\n\tgeometry.cylinders = indata[0];\n\tgeometry.heads = indata[1];\n\tgeometry.sectors = indata[2];\n\tgeometry.start = indata[3];\n\n\tr = dm_set_geometry(md, &geometry);\n\n\tparam->data_size = 0;\n\nout:\n\tdm_put(md);\n\treturn r;\n}\n\nstatic int do_suspend(struct dm_ioctl *param)\n{\n\tint r = 0;\n\tunsigned suspend_flags = DM_SUSPEND_LOCKFS_FLAG;\n\tstruct mapped_device *md;\n\n\tmd = find_device(param);\n\tif (!md)\n\t\treturn -ENXIO;\n\n\tif (param->flags & DM_SKIP_LOCKFS_FLAG)\n\t\tsuspend_flags &= ~DM_SUSPEND_LOCKFS_FLAG;\n\tif (param->flags & DM_NOFLUSH_FLAG)\n\t\tsuspend_flags |= DM_SUSPEND_NOFLUSH_FLAG;\n\n\tif (!dm_suspended_md(md)) {\n\t\tr = dm_suspend(md, suspend_flags);\n\t\tif (r)\n\t\t\tgoto out;\n\t}\n\n\t__dev_status(md, param);\n\nout:\n\tdm_put(md);\n\n\treturn r;\n}\n\nstatic int do_resume(struct dm_ioctl *param)\n{\n\tint r = 0;\n\tunsigned suspend_flags = DM_SUSPEND_LOCKFS_FLAG;\n\tstruct hash_cell *hc;\n\tstruct mapped_device *md;\n\tstruct dm_table *new_map, *old_map = NULL;\n\n\tdown_write(&_hash_lock);\n\n\thc = __find_device_hash_cell(param);\n\tif (!hc) {\n\t\tDMDEBUG_LIMIT(\"device doesn't appear to be in the dev hash table.\");\n\t\tup_write(&_hash_lock);\n\t\treturn -ENXIO;\n\t}\n\n\tmd = hc->md;\n\n\tnew_map = hc->new_map;\n\thc->new_map = NULL;\n\tparam->flags &= ~DM_INACTIVE_PRESENT_FLAG;\n\n\tup_write(&_hash_lock);\n\n\t/* Do we need to load a new map ? */\n\tif (new_map) {\n\t\t/* Suspend if it isn't already suspended */\n\t\tif (param->flags & DM_SKIP_LOCKFS_FLAG)\n\t\t\tsuspend_flags &= ~DM_SUSPEND_LOCKFS_FLAG;\n\t\tif (param->flags & DM_NOFLUSH_FLAG)\n\t\t\tsuspend_flags |= DM_SUSPEND_NOFLUSH_FLAG;\n\t\tif (!dm_suspended_md(md))\n\t\t\tdm_suspend(md, suspend_flags);\n\n\t\told_map = dm_swap_table(md, new_map);\n\t\tif (IS_ERR(old_map)) {\n\t\t\tdm_sync_table(md);\n\t\t\tdm_table_destroy(new_map);\n\t\t\tdm_put(md);\n\t\t\treturn PTR_ERR(old_map);\n\t\t}\n\n\t\tif (dm_table_get_mode(new_map) & FMODE_WRITE)\n\t\t\tset_disk_ro(dm_disk(md), 0);\n\t\telse\n\t\t\tset_disk_ro(dm_disk(md), 1);\n\t}\n\n\tif (dm_suspended_md(md)) {\n\t\tr = dm_resume(md);\n\t\tif (!r && !dm_kobject_uevent(md, KOBJ_CHANGE, param->event_nr))\n\t\t\tparam->flags |= DM_UEVENT_GENERATED_FLAG;\n\t}\n\n\t/*\n\t * Since dm_swap_table synchronizes RCU, nobody should be in\n\t * read-side critical section already.\n\t */\n\tif (old_map)\n\t\tdm_table_destroy(old_map);\n\n\tif (!r)\n\t\t__dev_status(md, param);\n\n\tdm_put(md);\n\treturn r;\n}\n\n/*\n * Set or unset the suspension state of a device.\n * If the device already is in the requested state we just return its status.\n */\nstatic int dev_suspend(struct file *filp, struct dm_ioctl *param, size_t param_size)\n{\n\tif (param->flags & DM_SUSPEND_FLAG)\n\t\treturn do_suspend(param);\n\n\treturn do_resume(param);\n}\n\n/*\n * Copies device info back to user space, used by\n * the create and info ioctls.\n */\nstatic int dev_status(struct file *filp, struct dm_ioctl *param, size_t param_size)\n{\n\tstruct mapped_device *md;\n\n\tmd = find_device(param);\n\tif (!md)\n\t\treturn -ENXIO;\n\n\t__dev_status(md, param);\n\tdm_put(md);\n\n\treturn 0;\n}\n\n/*\n * Build up the status struct for each target\n */\nstatic void retrieve_status(struct dm_table *table,\n\t\t\t    struct dm_ioctl *param, size_t param_size)\n{\n\tunsigned int i, num_targets;\n\tstruct dm_target_spec *spec;\n\tchar *outbuf, *outptr;\n\tstatus_type_t type;\n\tsize_t remaining, len, used = 0;\n\tunsigned status_flags = 0;\n\n\toutptr = outbuf = get_result_buffer(param, param_size, &len);\n\n\tif (param->flags & DM_STATUS_TABLE_FLAG)\n\t\ttype = STATUSTYPE_TABLE;\n\telse\n\t\ttype = STATUSTYPE_INFO;\n\n\t/* Get all the target info */\n\tnum_targets = dm_table_get_num_targets(table);\n\tfor (i = 0; i < num_targets; i++) {\n\t\tstruct dm_target *ti = dm_table_get_target(table, i);\n\t\tsize_t l;\n\n\t\tremaining = len - (outptr - outbuf);\n\t\tif (remaining <= sizeof(struct dm_target_spec)) {\n\t\t\tparam->flags |= DM_BUFFER_FULL_FLAG;\n\t\t\tbreak;\n\t\t}\n\n\t\tspec = (struct dm_target_spec *) outptr;\n\n\t\tspec->status = 0;\n\t\tspec->sector_start = ti->begin;\n\t\tspec->length = ti->len;\n\t\tstrncpy(spec->target_type, ti->type->name,\n\t\t\tsizeof(spec->target_type) - 1);\n\n\t\toutptr += sizeof(struct dm_target_spec);\n\t\tremaining = len - (outptr - outbuf);\n\t\tif (remaining <= 0) {\n\t\t\tparam->flags |= DM_BUFFER_FULL_FLAG;\n\t\t\tbreak;\n\t\t}\n\n\t\t/* Get the status/table string from the target driver */\n\t\tif (ti->type->status) {\n\t\t\tif (param->flags & DM_NOFLUSH_FLAG)\n\t\t\t\tstatus_flags |= DM_STATUS_NOFLUSH_FLAG;\n\t\t\tti->type->status(ti, type, status_flags, outptr, remaining);\n\t\t} else\n\t\t\toutptr[0] = '\\0';\n\n\t\tl = strlen(outptr) + 1;\n\t\tif (l == remaining) {\n\t\t\tparam->flags |= DM_BUFFER_FULL_FLAG;\n\t\t\tbreak;\n\t\t}\n\n\t\toutptr += l;\n\t\tused = param->data_start + (outptr - outbuf);\n\n\t\toutptr = align_ptr(outptr);\n\t\tspec->next = outptr - outbuf;\n\t}\n\n\tif (used)\n\t\tparam->data_size = used;\n\n\tparam->target_count = num_targets;\n}\n\n/*\n * Wait for a device to report an event\n */\nstatic int dev_wait(struct file *filp, struct dm_ioctl *param, size_t param_size)\n{\n\tint r = 0;\n\tstruct mapped_device *md;\n\tstruct dm_table *table;\n\tint srcu_idx;\n\n\tmd = find_device(param);\n\tif (!md)\n\t\treturn -ENXIO;\n\n\t/*\n\t * Wait for a notification event\n\t */\n\tif (dm_wait_event(md, param->event_nr)) {\n\t\tr = -ERESTARTSYS;\n\t\tgoto out;\n\t}\n\n\t/*\n\t * The userland program is going to want to know what\n\t * changed to trigger the event, so we may as well tell\n\t * him and save an ioctl.\n\t */\n\t__dev_status(md, param);\n\n\ttable = dm_get_live_or_inactive_table(md, param, &srcu_idx);\n\tif (table)\n\t\tretrieve_status(table, param, param_size);\n\tdm_put_live_table(md, srcu_idx);\n\nout:\n\tdm_put(md);\n\n\treturn r;\n}\n\n/*\n * Remember the global event number and make it possible to poll\n * for further events.\n */\nstatic int dev_arm_poll(struct file *filp, struct dm_ioctl *param, size_t param_size)\n{\n\tstruct dm_file *priv = filp->private_data;\n\n\tpriv->global_event_nr = atomic_read(&dm_global_event_nr);\n\n\treturn 0;\n}\n\nstatic inline fmode_t get_mode(struct dm_ioctl *param)\n{\n\tfmode_t mode = FMODE_READ | FMODE_WRITE;\n\n\tif (param->flags & DM_READONLY_FLAG)\n\t\tmode = FMODE_READ;\n\n\treturn mode;\n}\n\nstatic int next_target(struct dm_target_spec *last, uint32_t next, void *end,\n\t\t       struct dm_target_spec **spec, char **target_params)\n{\n\t*spec = (struct dm_target_spec *) ((unsigned char *) last + next);\n\t*target_params = (char *) (*spec + 1);\n\n\tif (*spec < (last + 1))\n\t\treturn -EINVAL;\n\n\treturn invalid_str(*target_params, end);\n}\n\nstatic int populate_table(struct dm_table *table,\n\t\t\t  struct dm_ioctl *param, size_t param_size)\n{\n\tint r;\n\tunsigned int i = 0;\n\tstruct dm_target_spec *spec = (struct dm_target_spec *) param;\n\tuint32_t next = param->data_start;\n\tvoid *end = (void *) param + param_size;\n\tchar *target_params;\n\n\tif (!param->target_count) {\n\t\tDMWARN(\"populate_table: no targets specified\");\n\t\treturn -EINVAL;\n\t}\n\n\tfor (i = 0; i < param->target_count; i++) {\n\n\t\tr = next_target(spec, next, end, &spec, &target_params);\n\t\tif (r) {\n\t\t\tDMWARN(\"unable to find target\");\n\t\t\treturn r;\n\t\t}\n\n\t\tr = dm_table_add_target(table, spec->target_type,\n\t\t\t\t\t(sector_t) spec->sector_start,\n\t\t\t\t\t(sector_t) spec->length,\n\t\t\t\t\ttarget_params);\n\t\tif (r) {\n\t\t\tDMWARN(\"error adding target to table\");\n\t\t\treturn r;\n\t\t}\n\n\t\tnext = spec->next;\n\t}\n\n\treturn dm_table_complete(table);\n}\n\nstatic bool is_valid_type(enum dm_queue_mode cur, enum dm_queue_mode new)\n{\n\tif (cur == new ||\n\t    (cur == DM_TYPE_BIO_BASED && new == DM_TYPE_DAX_BIO_BASED))\n\t\treturn true;\n\n\treturn false;\n}\n\nstatic int table_load(struct file *filp, struct dm_ioctl *param, size_t param_size)\n{\n\tint r;\n\tstruct hash_cell *hc;\n\tstruct dm_table *t, *old_map = NULL;\n\tstruct mapped_device *md;\n\tstruct target_type *immutable_target_type;\n\n\tmd = find_device(param);\n\tif (!md)\n\t\treturn -ENXIO;\n\n\tr = dm_table_create(&t, get_mode(param), param->target_count, md);\n\tif (r)\n\t\tgoto err;\n\n\t/* Protect md->type and md->queue against concurrent table loads. */\n\tdm_lock_md_type(md);\n\tr = populate_table(t, param, param_size);\n\tif (r)\n\t\tgoto err_unlock_md_type;\n\n\timmutable_target_type = dm_get_immutable_target_type(md);\n\tif (immutable_target_type &&\n\t    (immutable_target_type != dm_table_get_immutable_target_type(t)) &&\n\t    !dm_table_get_wildcard_target(t)) {\n\t\tDMWARN(\"can't replace immutable target type %s\",\n\t\t       immutable_target_type->name);\n\t\tr = -EINVAL;\n\t\tgoto err_unlock_md_type;\n\t}\n\n\tif (dm_get_md_type(md) == DM_TYPE_NONE) {\n\t\t/* Initial table load: acquire type of table. */\n\t\tdm_set_md_type(md, dm_table_get_type(t));\n\n\t\t/* setup md->queue to reflect md's type (may block) */\n\t\tr = dm_setup_md_queue(md, t);\n\t\tif (r) {\n\t\t\tDMWARN(\"unable to set up device queue for new table.\");\n\t\t\tgoto err_unlock_md_type;\n\t\t}\n\t} else if (!is_valid_type(dm_get_md_type(md), dm_table_get_type(t))) {\n\t\tDMWARN(\"can't change device type (old=%u vs new=%u) after initial table load.\",\n\t\t       dm_get_md_type(md), dm_table_get_type(t));\n\t\tr = -EINVAL;\n\t\tgoto err_unlock_md_type;\n\t}\n\n\tdm_unlock_md_type(md);\n\n\t/* stage inactive table */\n\tdown_write(&_hash_lock);\n\thc = dm_get_mdptr(md);\n\tif (!hc || hc->md != md) {\n\t\tDMWARN(\"device has been removed from the dev hash table.\");\n\t\tup_write(&_hash_lock);\n\t\tr = -ENXIO;\n\t\tgoto err_destroy_table;\n\t}\n\n\tif (hc->new_map)\n\t\told_map = hc->new_map;\n\thc->new_map = t;\n\tup_write(&_hash_lock);\n\n\tparam->flags |= DM_INACTIVE_PRESENT_FLAG;\n\t__dev_status(md, param);\n\n\tif (old_map) {\n\t\tdm_sync_table(md);\n\t\tdm_table_destroy(old_map);\n\t}\n\n\tdm_put(md);\n\n\treturn 0;\n\nerr_unlock_md_type:\n\tdm_unlock_md_type(md);\nerr_destroy_table:\n\tdm_table_destroy(t);\nerr:\n\tdm_put(md);\n\n\treturn r;\n}\n\nstatic int table_clear(struct file *filp, struct dm_ioctl *param, size_t param_size)\n{\n\tstruct hash_cell *hc;\n\tstruct mapped_device *md;\n\tstruct dm_table *old_map = NULL;\n\n\tdown_write(&_hash_lock);\n\n\thc = __find_device_hash_cell(param);\n\tif (!hc) {\n\t\tDMDEBUG_LIMIT(\"device doesn't appear to be in the dev hash table.\");\n\t\tup_write(&_hash_lock);\n\t\treturn -ENXIO;\n\t}\n\n\tif (hc->new_map) {\n\t\told_map = hc->new_map;\n\t\thc->new_map = NULL;\n\t}\n\n\tparam->flags &= ~DM_INACTIVE_PRESENT_FLAG;\n\n\t__dev_status(hc->md, param);\n\tmd = hc->md;\n\tup_write(&_hash_lock);\n\tif (old_map) {\n\t\tdm_sync_table(md);\n\t\tdm_table_destroy(old_map);\n\t}\n\tdm_put(md);\n\n\treturn 0;\n}\n\n/*\n * Retrieves a list of devices used by a particular dm device.\n */\nstatic void retrieve_deps(struct dm_table *table,\n\t\t\t  struct dm_ioctl *param, size_t param_size)\n{\n\tunsigned int count = 0;\n\tstruct list_head *tmp;\n\tsize_t len, needed;\n\tstruct dm_dev_internal *dd;\n\tstruct dm_target_deps *deps;\n\n\tdeps = get_result_buffer(param, param_size, &len);\n\n\t/*\n\t * Count the devices.\n\t */\n\tlist_for_each (tmp, dm_table_get_devices(table))\n\t\tcount++;\n\n\t/*\n\t * Check we have enough space.\n\t */\n\tneeded = struct_size(deps, dev, count);\n\tif (len < needed) {\n\t\tparam->flags |= DM_BUFFER_FULL_FLAG;\n\t\treturn;\n\t}\n\n\t/*\n\t * Fill in the devices.\n\t */\n\tdeps->count = count;\n\tcount = 0;\n\tlist_for_each_entry (dd, dm_table_get_devices(table), list)\n\t\tdeps->dev[count++] = huge_encode_dev(dd->dm_dev->bdev->bd_dev);\n\n\tparam->data_size = param->data_start + needed;\n}\n\nstatic int table_deps(struct file *filp, struct dm_ioctl *param, size_t param_size)\n{\n\tstruct mapped_device *md;\n\tstruct dm_table *table;\n\tint srcu_idx;\n\n\tmd = find_device(param);\n\tif (!md)\n\t\treturn -ENXIO;\n\n\t__dev_status(md, param);\n\n\ttable = dm_get_live_or_inactive_table(md, param, &srcu_idx);\n\tif (table)\n\t\tretrieve_deps(table, param, param_size);\n\tdm_put_live_table(md, srcu_idx);\n\n\tdm_put(md);\n\n\treturn 0;\n}\n\n/*\n * Return the status of a device as a text string for each\n * target.\n */\nstatic int table_status(struct file *filp, struct dm_ioctl *param, size_t param_size)\n{\n\tstruct mapped_device *md;\n\tstruct dm_table *table;\n\tint srcu_idx;\n\n\tmd = find_device(param);\n\tif (!md)\n\t\treturn -ENXIO;\n\n\t__dev_status(md, param);\n\n\ttable = dm_get_live_or_inactive_table(md, param, &srcu_idx);\n\tif (table)\n\t\tretrieve_status(table, param, param_size);\n\tdm_put_live_table(md, srcu_idx);\n\n\tdm_put(md);\n\n\treturn 0;\n}\n\n/*\n * Process device-mapper dependent messages.  Messages prefixed with '@'\n * are processed by the DM core.  All others are delivered to the target.\n * Returns a number <= 1 if message was processed by device mapper.\n * Returns 2 if message should be delivered to the target.\n */\nstatic int message_for_md(struct mapped_device *md, unsigned argc, char **argv,\n\t\t\t  char *result, unsigned maxlen)\n{\n\tint r;\n\n\tif (**argv != '@')\n\t\treturn 2; /* no '@' prefix, deliver to target */\n\n\tif (!strcasecmp(argv[0], \"@cancel_deferred_remove\")) {\n\t\tif (argc != 1) {\n\t\t\tDMERR(\"Invalid arguments for @cancel_deferred_remove\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t\treturn dm_cancel_deferred_remove(md);\n\t}\n\n\tr = dm_stats_message(md, argc, argv, result, maxlen);\n\tif (r < 2)\n\t\treturn r;\n\n\tDMERR(\"Unsupported message sent to DM core: %s\", argv[0]);\n\treturn -EINVAL;\n}\n\n/*\n * Pass a message to the target that's at the supplied device offset.\n */\nstatic int target_message(struct file *filp, struct dm_ioctl *param, size_t param_size)\n{\n\tint r, argc;\n\tchar **argv;\n\tstruct mapped_device *md;\n\tstruct dm_table *table;\n\tstruct dm_target *ti;\n\tstruct dm_target_msg *tmsg = (void *) param + param->data_start;\n\tsize_t maxlen;\n\tchar *result = get_result_buffer(param, param_size, &maxlen);\n\tint srcu_idx;\n\n\tmd = find_device(param);\n\tif (!md)\n\t\treturn -ENXIO;\n\n\tif (tmsg < (struct dm_target_msg *) param->data ||\n\t    invalid_str(tmsg->message, (void *) param + param_size)) {\n\t\tDMWARN(\"Invalid target message parameters.\");\n\t\tr = -EINVAL;\n\t\tgoto out;\n\t}\n\n\tr = dm_split_args(&argc, &argv, tmsg->message);\n\tif (r) {\n\t\tDMWARN(\"Failed to split target message parameters\");\n\t\tgoto out;\n\t}\n\n\tif (!argc) {\n\t\tDMWARN(\"Empty message received.\");\n\t\tr = -EINVAL;\n\t\tgoto out_argv;\n\t}\n\n\tr = message_for_md(md, argc, argv, result, maxlen);\n\tif (r <= 1)\n\t\tgoto out_argv;\n\n\ttable = dm_get_live_table(md, &srcu_idx);\n\tif (!table)\n\t\tgoto out_table;\n\n\tif (dm_deleting_md(md)) {\n\t\tr = -ENXIO;\n\t\tgoto out_table;\n\t}\n\n\tti = dm_table_find_target(table, tmsg->sector);\n\tif (!ti) {\n\t\tDMWARN(\"Target message sector outside device.\");\n\t\tr = -EINVAL;\n\t} else if (ti->type->message)\n\t\tr = ti->type->message(ti, argc, argv, result, maxlen);\n\telse {\n\t\tDMWARN(\"Target type does not support messages\");\n\t\tr = -EINVAL;\n\t}\n\n out_table:\n\tdm_put_live_table(md, srcu_idx);\n out_argv:\n\tkfree(argv);\n out:\n\tif (r >= 0)\n\t\t__dev_status(md, param);\n\n\tif (r == 1) {\n\t\tparam->flags |= DM_DATA_OUT_FLAG;\n\t\tif (dm_message_test_buffer_overflow(result, maxlen))\n\t\t\tparam->flags |= DM_BUFFER_FULL_FLAG;\n\t\telse\n\t\t\tparam->data_size = param->data_start + strlen(result) + 1;\n\t\tr = 0;\n\t}\n\n\tdm_put(md);\n\treturn r;\n}\n\n/*\n * The ioctl parameter block consists of two parts, a dm_ioctl struct\n * followed by a data buffer.  This flag is set if the second part,\n * which has a variable size, is not used by the function processing\n * the ioctl.\n */\n#define IOCTL_FLAGS_NO_PARAMS\t\t1\n#define IOCTL_FLAGS_ISSUE_GLOBAL_EVENT\t2\n\n/*-----------------------------------------------------------------\n * Implementation of open/close/ioctl on the special char\n * device.\n *---------------------------------------------------------------*/\nstatic ioctl_fn lookup_ioctl(unsigned int cmd, int *ioctl_flags)\n{\n\tstatic const struct {\n\t\tint cmd;\n\t\tint flags;\n\t\tioctl_fn fn;\n\t} _ioctls[] = {\n\t\t{DM_VERSION_CMD, 0, NULL}, /* version is dealt with elsewhere */\n\t\t{DM_REMOVE_ALL_CMD, IOCTL_FLAGS_NO_PARAMS | IOCTL_FLAGS_ISSUE_GLOBAL_EVENT, remove_all},\n\t\t{DM_LIST_DEVICES_CMD, 0, list_devices},\n\n\t\t{DM_DEV_CREATE_CMD, IOCTL_FLAGS_NO_PARAMS | IOCTL_FLAGS_ISSUE_GLOBAL_EVENT, dev_create},\n\t\t{DM_DEV_REMOVE_CMD, IOCTL_FLAGS_NO_PARAMS | IOCTL_FLAGS_ISSUE_GLOBAL_EVENT, dev_remove},\n\t\t{DM_DEV_RENAME_CMD, IOCTL_FLAGS_ISSUE_GLOBAL_EVENT, dev_rename},\n\t\t{DM_DEV_SUSPEND_CMD, IOCTL_FLAGS_NO_PARAMS, dev_suspend},\n\t\t{DM_DEV_STATUS_CMD, IOCTL_FLAGS_NO_PARAMS, dev_status},\n\t\t{DM_DEV_WAIT_CMD, 0, dev_wait},\n\n\t\t{DM_TABLE_LOAD_CMD, 0, table_load},\n\t\t{DM_TABLE_CLEAR_CMD, IOCTL_FLAGS_NO_PARAMS, table_clear},\n\t\t{DM_TABLE_DEPS_CMD, 0, table_deps},\n\t\t{DM_TABLE_STATUS_CMD, 0, table_status},\n\n\t\t{DM_LIST_VERSIONS_CMD, 0, list_versions},\n\n\t\t{DM_TARGET_MSG_CMD, 0, target_message},\n\t\t{DM_DEV_SET_GEOMETRY_CMD, 0, dev_set_geometry},\n\t\t{DM_DEV_ARM_POLL, IOCTL_FLAGS_NO_PARAMS, dev_arm_poll},\n\t\t{DM_GET_TARGET_VERSION, 0, get_target_version},\n\t};\n\n\tif (unlikely(cmd >= ARRAY_SIZE(_ioctls)))\n\t\treturn NULL;\n\n\t*ioctl_flags = _ioctls[cmd].flags;\n\treturn _ioctls[cmd].fn;\n}\n\n/*\n * As well as checking the version compatibility this always\n * copies the kernel interface version out.\n */\nstatic int check_version(unsigned int cmd, struct dm_ioctl __user *user)\n{\n\tuint32_t version[3];\n\tint r = 0;\n\n\tif (copy_from_user(version, user->version, sizeof(version)))\n\t\treturn -EFAULT;\n\n\tif ((DM_VERSION_MAJOR != version[0]) ||\n\t    (DM_VERSION_MINOR < version[1])) {\n\t\tDMWARN(\"ioctl interface mismatch: \"\n\t\t       \"kernel(%u.%u.%u), user(%u.%u.%u), cmd(%d)\",\n\t\t       DM_VERSION_MAJOR, DM_VERSION_MINOR,\n\t\t       DM_VERSION_PATCHLEVEL,\n\t\t       version[0], version[1], version[2], cmd);\n\t\tr = -EINVAL;\n\t}\n\n\t/*\n\t * Fill in the kernel version.\n\t */\n\tversion[0] = DM_VERSION_MAJOR;\n\tversion[1] = DM_VERSION_MINOR;\n\tversion[2] = DM_VERSION_PATCHLEVEL;\n\tif (copy_to_user(user->version, version, sizeof(version)))\n\t\treturn -EFAULT;\n\n\treturn r;\n}\n\n#define DM_PARAMS_MALLOC\t0x0001\t/* Params allocated with kvmalloc() */\n#define DM_WIPE_BUFFER\t\t0x0010\t/* Wipe input buffer before returning from ioctl */\n\nstatic void free_params(struct dm_ioctl *param, size_t param_size, int param_flags)\n{\n\tif (param_flags & DM_WIPE_BUFFER)\n\t\tmemset(param, 0, param_size);\n\n\tif (param_flags & DM_PARAMS_MALLOC)\n\t\tkvfree(param);\n}\n\nstatic int copy_params(struct dm_ioctl __user *user, struct dm_ioctl *param_kernel,\n\t\t       int ioctl_flags, struct dm_ioctl **param, int *param_flags)\n{\n\tstruct dm_ioctl *dmi;\n\tint secure_data;\n\tconst size_t minimum_data_size = offsetof(struct dm_ioctl, data);\n\tunsigned noio_flag;\n\n\tif (copy_from_user(param_kernel, user, minimum_data_size))\n\t\treturn -EFAULT;\n\n\tif (param_kernel->data_size < minimum_data_size)\n\t\treturn -EINVAL;\n\n\tsecure_data = param_kernel->flags & DM_SECURE_DATA_FLAG;\n\n\t*param_flags = secure_data ? DM_WIPE_BUFFER : 0;\n\n\tif (ioctl_flags & IOCTL_FLAGS_NO_PARAMS) {\n\t\tdmi = param_kernel;\n\t\tdmi->data_size = minimum_data_size;\n\t\tgoto data_copied;\n\t}\n\n\t/*\n\t * Use __GFP_HIGH to avoid low memory issues when a device is\n\t * suspended and the ioctl is needed to resume it.\n\t * Use kmalloc() rather than vmalloc() when we can.\n\t */\n\tdmi = NULL;\n\tnoio_flag = memalloc_noio_save();\n\tdmi = kvmalloc(param_kernel->data_size, GFP_KERNEL | __GFP_HIGH);\n\tmemalloc_noio_restore(noio_flag);\n\n\tif (!dmi) {\n\t\tif (secure_data && clear_user(user, param_kernel->data_size))\n\t\t\treturn -EFAULT;\n\t\treturn -ENOMEM;\n\t}\n\n\t*param_flags |= DM_PARAMS_MALLOC;\n\n\t/* Copy from param_kernel (which was already copied from user) */\n\tmemcpy(dmi, param_kernel, minimum_data_size);\n\n\tif (copy_from_user(&dmi->data, (char __user *)user + minimum_data_size,\n\t\t\t   param_kernel->data_size - minimum_data_size))\n\t\tgoto bad;\ndata_copied:\n\t/* Wipe the user buffer so we do not return it to userspace */\n\tif (secure_data && clear_user(user, param_kernel->data_size))\n\t\tgoto bad;\n\n\t*param = dmi;\n\treturn 0;\n\nbad:\n\tfree_params(dmi, param_kernel->data_size, *param_flags);\n\n\treturn -EFAULT;\n}\n\nstatic int validate_params(uint cmd, struct dm_ioctl *param)\n{\n\t/* Always clear this flag */\n\tparam->flags &= ~DM_BUFFER_FULL_FLAG;\n\tparam->flags &= ~DM_UEVENT_GENERATED_FLAG;\n\tparam->flags &= ~DM_SECURE_DATA_FLAG;\n\tparam->flags &= ~DM_DATA_OUT_FLAG;\n\n\t/* Ignores parameters */\n\tif (cmd == DM_REMOVE_ALL_CMD ||\n\t    cmd == DM_LIST_DEVICES_CMD ||\n\t    cmd == DM_LIST_VERSIONS_CMD)\n\t\treturn 0;\n\n\tif (cmd == DM_DEV_CREATE_CMD) {\n\t\tif (!*param->name) {\n\t\t\tDMWARN(\"name not supplied when creating device\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t} else if (*param->uuid && *param->name) {\n\t\tDMWARN(\"only supply one of name or uuid, cmd(%u)\", cmd);\n\t\treturn -EINVAL;\n\t}\n\n\t/* Ensure strings are terminated */\n\tparam->name[DM_NAME_LEN - 1] = '\\0';\n\tparam->uuid[DM_UUID_LEN - 1] = '\\0';\n\n\treturn 0;\n}\n\nstatic int ctl_ioctl(struct file *file, uint command, struct dm_ioctl __user *user)\n{\n\tint r = 0;\n\tint ioctl_flags;\n\tint param_flags;\n\tunsigned int cmd;\n\tstruct dm_ioctl *param;\n\tioctl_fn fn = NULL;\n\tsize_t input_param_size;\n\tstruct dm_ioctl param_kernel;\n\n\t/* only root can play with this */\n\tif (!capable(CAP_SYS_ADMIN))\n\t\treturn -EACCES;\n\n\tif (_IOC_TYPE(command) != DM_IOCTL)\n\t\treturn -ENOTTY;\n\n\tcmd = _IOC_NR(command);\n\n\t/*\n\t * Check the interface version passed in.  This also\n\t * writes out the kernel's interface version.\n\t */\n\tr = check_version(cmd, user);\n\tif (r)\n\t\treturn r;\n\n\t/*\n\t * Nothing more to do for the version command.\n\t */\n\tif (cmd == DM_VERSION_CMD)\n\t\treturn 0;\n\n\tfn = lookup_ioctl(cmd, &ioctl_flags);\n\tif (!fn) {\n\t\tDMWARN(\"dm_ctl_ioctl: unknown command 0x%x\", command);\n\t\treturn -ENOTTY;\n\t}\n\n\t/*\n\t * Copy the parameters into kernel space.\n\t */\n\tr = copy_params(user, &param_kernel, ioctl_flags, &param, &param_flags);\n\n\tif (r)\n\t\treturn r;\n\n\tinput_param_size = param->data_size;\n\tr = validate_params(cmd, param);\n\tif (r)\n\t\tgoto out;\n\n\tparam->data_size = offsetof(struct dm_ioctl, data);\n\tr = fn(file, param, input_param_size);\n\n\tif (unlikely(param->flags & DM_BUFFER_FULL_FLAG) &&\n\t    unlikely(ioctl_flags & IOCTL_FLAGS_NO_PARAMS))\n\t\tDMERR(\"ioctl %d tried to output some data but has IOCTL_FLAGS_NO_PARAMS set\", cmd);\n\n\tif (!r && ioctl_flags & IOCTL_FLAGS_ISSUE_GLOBAL_EVENT)\n\t\tdm_issue_global_event();\n\n\t/*\n\t * Copy the results back to userland.\n\t */\n\tif (!r && copy_to_user(user, param, param->data_size))\n\t\tr = -EFAULT;\n\nout:\n\tfree_params(param, input_param_size, param_flags);\n\treturn r;\n}\n\nstatic long dm_ctl_ioctl(struct file *file, uint command, ulong u)\n{\n\treturn (long)ctl_ioctl(file, command, (struct dm_ioctl __user *)u);\n}\n\n#ifdef CONFIG_COMPAT\nstatic long dm_compat_ctl_ioctl(struct file *file, uint command, ulong u)\n{\n\treturn (long)dm_ctl_ioctl(file, command, (ulong) compat_ptr(u));\n}\n#else\n#define dm_compat_ctl_ioctl NULL\n#endif\n\nstatic int dm_open(struct inode *inode, struct file *filp)\n{\n\tint r;\n\tstruct dm_file *priv;\n\n\tr = nonseekable_open(inode, filp);\n\tif (unlikely(r))\n\t\treturn r;\n\n\tpriv = filp->private_data = kmalloc(sizeof(struct dm_file), GFP_KERNEL);\n\tif (!priv)\n\t\treturn -ENOMEM;\n\n\tpriv->global_event_nr = atomic_read(&dm_global_event_nr);\n\n\treturn 0;\n}\n\nstatic int dm_release(struct inode *inode, struct file *filp)\n{\n\tkfree(filp->private_data);\n\treturn 0;\n}\n\nstatic __poll_t dm_poll(struct file *filp, poll_table *wait)\n{\n\tstruct dm_file *priv = filp->private_data;\n\t__poll_t mask = 0;\n\n\tpoll_wait(filp, &dm_global_eventq, wait);\n\n\tif ((int)(atomic_read(&dm_global_event_nr) - priv->global_event_nr) > 0)\n\t\tmask |= EPOLLIN;\n\n\treturn mask;\n}\n\nstatic const struct file_operations _ctl_fops = {\n\t.open    = dm_open,\n\t.release = dm_release,\n\t.poll    = dm_poll,\n\t.unlocked_ioctl\t = dm_ctl_ioctl,\n\t.compat_ioctl = dm_compat_ctl_ioctl,\n\t.owner\t = THIS_MODULE,\n\t.llseek  = noop_llseek,\n};\n\nstatic struct miscdevice _dm_misc = {\n\t.minor\t\t= MAPPER_CTRL_MINOR,\n\t.name  \t\t= DM_NAME,\n\t.nodename\t= DM_DIR \"/\" DM_CONTROL_NODE,\n\t.fops  \t\t= &_ctl_fops\n};\n\nMODULE_ALIAS_MISCDEV(MAPPER_CTRL_MINOR);\nMODULE_ALIAS(\"devname:\" DM_DIR \"/\" DM_CONTROL_NODE);\n\n/*\n * Create misc character device and link to DM_DIR/control.\n */\nint __init dm_interface_init(void)\n{\n\tint r;\n\n\tr = dm_hash_init();\n\tif (r)\n\t\treturn r;\n\n\tr = misc_register(&_dm_misc);\n\tif (r) {\n\t\tDMERR(\"misc_register failed for control device\");\n\t\tdm_hash_exit();\n\t\treturn r;\n\t}\n\n\tDMINFO(\"%d.%d.%d%s initialised: %s\", DM_VERSION_MAJOR,\n\t       DM_VERSION_MINOR, DM_VERSION_PATCHLEVEL, DM_VERSION_EXTRA,\n\t       DM_DRIVER_EMAIL);\n\treturn 0;\n}\n\nvoid dm_interface_exit(void)\n{\n\tmisc_deregister(&_dm_misc);\n\tdm_hash_exit();\n}\n\n/**\n * dm_copy_name_and_uuid - Copy mapped device name & uuid into supplied buffers\n * @md: Pointer to mapped_device\n * @name: Buffer (size DM_NAME_LEN) for name\n * @uuid: Buffer (size DM_UUID_LEN) for uuid or empty string if uuid not defined\n */\nint dm_copy_name_and_uuid(struct mapped_device *md, char *name, char *uuid)\n{\n\tint r = 0;\n\tstruct hash_cell *hc;\n\n\tif (!md)\n\t\treturn -ENXIO;\n\n\tmutex_lock(&dm_hash_cells_mutex);\n\thc = dm_get_mdptr(md);\n\tif (!hc || hc->md != md) {\n\t\tr = -ENXIO;\n\t\tgoto out;\n\t}\n\n\tif (name)\n\t\tstrcpy(name, hc->name);\n\tif (uuid)\n\t\tstrcpy(uuid, hc->uuid ? : \"\");\n\nout:\n\tmutex_unlock(&dm_hash_cells_mutex);\n\n\treturn r;\n}\nEXPORT_SYMBOL_GPL(dm_copy_name_and_uuid);\n\n/**\n * dm_early_create - create a mapped device in early boot.\n *\n * @dmi: Contains main information of the device mapping to be created.\n * @spec_array: array of pointers to struct dm_target_spec. Describes the\n * mapping table of the device.\n * @target_params_array: array of strings with the parameters to a specific\n * target.\n *\n * Instead of having the struct dm_target_spec and the parameters for every\n * target embedded at the end of struct dm_ioctl (as performed in a normal\n * ioctl), pass them as arguments, so the caller doesn't need to serialize them.\n * The size of the spec_array and target_params_array is given by\n * @dmi->target_count.\n * This function is supposed to be called in early boot, so locking mechanisms\n * to protect against concurrent loads are not required.\n */\nint __init dm_early_create(struct dm_ioctl *dmi,\n\t\t\t   struct dm_target_spec **spec_array,\n\t\t\t   char **target_params_array)\n{\n\tint r, m = DM_ANY_MINOR;\n\tstruct dm_table *t, *old_map;\n\tstruct mapped_device *md;\n\tunsigned int i;\n\n\tif (!dmi->target_count)\n\t\treturn -EINVAL;\n\n\tr = check_name(dmi->name);\n\tif (r)\n\t\treturn r;\n\n\tif (dmi->flags & DM_PERSISTENT_DEV_FLAG)\n\t\tm = MINOR(huge_decode_dev(dmi->dev));\n\n\t/* alloc dm device */\n\tr = dm_create(m, &md);\n\tif (r)\n\t\treturn r;\n\n\t/* hash insert */\n\tr = dm_hash_insert(dmi->name, *dmi->uuid ? dmi->uuid : NULL, md);\n\tif (r)\n\t\tgoto err_destroy_dm;\n\n\t/* alloc table */\n\tr = dm_table_create(&t, get_mode(dmi), dmi->target_count, md);\n\tif (r)\n\t\tgoto err_hash_remove;\n\n\t/* add targets */\n\tfor (i = 0; i < dmi->target_count; i++) {\n\t\tr = dm_table_add_target(t, spec_array[i]->target_type,\n\t\t\t\t\t(sector_t) spec_array[i]->sector_start,\n\t\t\t\t\t(sector_t) spec_array[i]->length,\n\t\t\t\t\ttarget_params_array[i]);\n\t\tif (r) {\n\t\t\tDMWARN(\"error adding target to table\");\n\t\t\tgoto err_destroy_table;\n\t\t}\n\t}\n\n\t/* finish table */\n\tr = dm_table_complete(t);\n\tif (r)\n\t\tgoto err_destroy_table;\n\n\tmd->type = dm_table_get_type(t);\n\t/* setup md->queue to reflect md's type (may block) */\n\tr = dm_setup_md_queue(md, t);\n\tif (r) {\n\t\tDMWARN(\"unable to set up device queue for new table.\");\n\t\tgoto err_destroy_table;\n\t}\n\n\t/* Set new map */\n\tdm_suspend(md, 0);\n\told_map = dm_swap_table(md, t);\n\tif (IS_ERR(old_map)) {\n\t\tr = PTR_ERR(old_map);\n\t\tgoto err_destroy_table;\n\t}\n\tset_disk_ro(dm_disk(md), !!(dmi->flags & DM_READONLY_FLAG));\n\n\t/* resume device */\n\tr = dm_resume(md);\n\tif (r)\n\t\tgoto err_destroy_table;\n\n\tDMINFO(\"%s (%s) is ready\", md->disk->disk_name, dmi->name);\n\tdm_put(md);\n\treturn 0;\n\nerr_destroy_table:\n\tdm_table_destroy(t);\nerr_hash_remove:\n\t(void) __hash_remove(__get_name_cell(dmi->name));\n\t/* release reference from __get_name_cell */\n\tdm_put(md);\nerr_destroy_dm:\n\tdm_put(md);\n\tdm_destroy(md);\n\treturn r;\n}\n"], "fixing_code": ["/*\n * Copyright (C) 2001, 2002 Sistina Software (UK) Limited.\n * Copyright (C) 2004 - 2006 Red Hat, Inc. All rights reserved.\n *\n * This file is released under the GPL.\n */\n\n#include \"dm-core.h\"\n\n#include <linux/module.h>\n#include <linux/vmalloc.h>\n#include <linux/miscdevice.h>\n#include <linux/sched/mm.h>\n#include <linux/init.h>\n#include <linux/wait.h>\n#include <linux/slab.h>\n#include <linux/dm-ioctl.h>\n#include <linux/hdreg.h>\n#include <linux/compat.h>\n\n#include <linux/uaccess.h>\n\n#define DM_MSG_PREFIX \"ioctl\"\n#define DM_DRIVER_EMAIL \"dm-devel@redhat.com\"\n\nstruct dm_file {\n\t/*\n\t * poll will wait until the global event number is greater than\n\t * this value.\n\t */\n\tvolatile unsigned global_event_nr;\n};\n\n/*-----------------------------------------------------------------\n * The ioctl interface needs to be able to look up devices by\n * name or uuid.\n *---------------------------------------------------------------*/\nstruct hash_cell {\n\tstruct list_head name_list;\n\tstruct list_head uuid_list;\n\n\tchar *name;\n\tchar *uuid;\n\tstruct mapped_device *md;\n\tstruct dm_table *new_map;\n};\n\nstruct vers_iter {\n    size_t param_size;\n    struct dm_target_versions *vers, *old_vers;\n    char *end;\n    uint32_t flags;\n};\n\n\n#define NUM_BUCKETS 64\n#define MASK_BUCKETS (NUM_BUCKETS - 1)\nstatic struct list_head _name_buckets[NUM_BUCKETS];\nstatic struct list_head _uuid_buckets[NUM_BUCKETS];\n\nstatic void dm_hash_remove_all(bool keep_open_devices, bool mark_deferred, bool only_deferred);\n\n/*\n * Guards access to both hash tables.\n */\nstatic DECLARE_RWSEM(_hash_lock);\n\n/*\n * Protects use of mdptr to obtain hash cell name and uuid from mapped device.\n */\nstatic DEFINE_MUTEX(dm_hash_cells_mutex);\n\nstatic void init_buckets(struct list_head *buckets)\n{\n\tunsigned int i;\n\n\tfor (i = 0; i < NUM_BUCKETS; i++)\n\t\tINIT_LIST_HEAD(buckets + i);\n}\n\nstatic int dm_hash_init(void)\n{\n\tinit_buckets(_name_buckets);\n\tinit_buckets(_uuid_buckets);\n\treturn 0;\n}\n\nstatic void dm_hash_exit(void)\n{\n\tdm_hash_remove_all(false, false, false);\n}\n\n/*-----------------------------------------------------------------\n * Hash function:\n * We're not really concerned with the str hash function being\n * fast since it's only used by the ioctl interface.\n *---------------------------------------------------------------*/\nstatic unsigned int hash_str(const char *str)\n{\n\tconst unsigned int hash_mult = 2654435387U;\n\tunsigned int h = 0;\n\n\twhile (*str)\n\t\th = (h + (unsigned int) *str++) * hash_mult;\n\n\treturn h & MASK_BUCKETS;\n}\n\n/*-----------------------------------------------------------------\n * Code for looking up a device by name\n *---------------------------------------------------------------*/\nstatic struct hash_cell *__get_name_cell(const char *str)\n{\n\tstruct hash_cell *hc;\n\tunsigned int h = hash_str(str);\n\n\tlist_for_each_entry (hc, _name_buckets + h, name_list)\n\t\tif (!strcmp(hc->name, str)) {\n\t\t\tdm_get(hc->md);\n\t\t\treturn hc;\n\t\t}\n\n\treturn NULL;\n}\n\nstatic struct hash_cell *__get_uuid_cell(const char *str)\n{\n\tstruct hash_cell *hc;\n\tunsigned int h = hash_str(str);\n\n\tlist_for_each_entry (hc, _uuid_buckets + h, uuid_list)\n\t\tif (!strcmp(hc->uuid, str)) {\n\t\t\tdm_get(hc->md);\n\t\t\treturn hc;\n\t\t}\n\n\treturn NULL;\n}\n\nstatic struct hash_cell *__get_dev_cell(uint64_t dev)\n{\n\tstruct mapped_device *md;\n\tstruct hash_cell *hc;\n\n\tmd = dm_get_md(huge_decode_dev(dev));\n\tif (!md)\n\t\treturn NULL;\n\n\thc = dm_get_mdptr(md);\n\tif (!hc) {\n\t\tdm_put(md);\n\t\treturn NULL;\n\t}\n\n\treturn hc;\n}\n\n/*-----------------------------------------------------------------\n * Inserting, removing and renaming a device.\n *---------------------------------------------------------------*/\nstatic struct hash_cell *alloc_cell(const char *name, const char *uuid,\n\t\t\t\t    struct mapped_device *md)\n{\n\tstruct hash_cell *hc;\n\n\thc = kmalloc(sizeof(*hc), GFP_KERNEL);\n\tif (!hc)\n\t\treturn NULL;\n\n\thc->name = kstrdup(name, GFP_KERNEL);\n\tif (!hc->name) {\n\t\tkfree(hc);\n\t\treturn NULL;\n\t}\n\n\tif (!uuid)\n\t\thc->uuid = NULL;\n\n\telse {\n\t\thc->uuid = kstrdup(uuid, GFP_KERNEL);\n\t\tif (!hc->uuid) {\n\t\t\tkfree(hc->name);\n\t\t\tkfree(hc);\n\t\t\treturn NULL;\n\t\t}\n\t}\n\n\tINIT_LIST_HEAD(&hc->name_list);\n\tINIT_LIST_HEAD(&hc->uuid_list);\n\thc->md = md;\n\thc->new_map = NULL;\n\treturn hc;\n}\n\nstatic void free_cell(struct hash_cell *hc)\n{\n\tif (hc) {\n\t\tkfree(hc->name);\n\t\tkfree(hc->uuid);\n\t\tkfree(hc);\n\t}\n}\n\n/*\n * The kdev_t and uuid of a device can never change once it is\n * initially inserted.\n */\nstatic int dm_hash_insert(const char *name, const char *uuid, struct mapped_device *md)\n{\n\tstruct hash_cell *cell, *hc;\n\n\t/*\n\t * Allocate the new cells.\n\t */\n\tcell = alloc_cell(name, uuid, md);\n\tif (!cell)\n\t\treturn -ENOMEM;\n\n\t/*\n\t * Insert the cell into both hash tables.\n\t */\n\tdown_write(&_hash_lock);\n\thc = __get_name_cell(name);\n\tif (hc) {\n\t\tdm_put(hc->md);\n\t\tgoto bad;\n\t}\n\n\tlist_add(&cell->name_list, _name_buckets + hash_str(name));\n\n\tif (uuid) {\n\t\thc = __get_uuid_cell(uuid);\n\t\tif (hc) {\n\t\t\tlist_del(&cell->name_list);\n\t\t\tdm_put(hc->md);\n\t\t\tgoto bad;\n\t\t}\n\t\tlist_add(&cell->uuid_list, _uuid_buckets + hash_str(uuid));\n\t}\n\tdm_get(md);\n\tmutex_lock(&dm_hash_cells_mutex);\n\tdm_set_mdptr(md, cell);\n\tmutex_unlock(&dm_hash_cells_mutex);\n\tup_write(&_hash_lock);\n\n\treturn 0;\n\n bad:\n\tup_write(&_hash_lock);\n\tfree_cell(cell);\n\treturn -EBUSY;\n}\n\nstatic struct dm_table *__hash_remove(struct hash_cell *hc)\n{\n\tstruct dm_table *table;\n\tint srcu_idx;\n\n\t/* remove from the dev hash */\n\tlist_del(&hc->uuid_list);\n\tlist_del(&hc->name_list);\n\tmutex_lock(&dm_hash_cells_mutex);\n\tdm_set_mdptr(hc->md, NULL);\n\tmutex_unlock(&dm_hash_cells_mutex);\n\n\ttable = dm_get_live_table(hc->md, &srcu_idx);\n\tif (table)\n\t\tdm_table_event(table);\n\tdm_put_live_table(hc->md, srcu_idx);\n\n\ttable = NULL;\n\tif (hc->new_map)\n\t\ttable = hc->new_map;\n\tdm_put(hc->md);\n\tfree_cell(hc);\n\n\treturn table;\n}\n\nstatic void dm_hash_remove_all(bool keep_open_devices, bool mark_deferred, bool only_deferred)\n{\n\tint i, dev_skipped;\n\tstruct hash_cell *hc;\n\tstruct mapped_device *md;\n\tstruct dm_table *t;\n\nretry:\n\tdev_skipped = 0;\n\n\tdown_write(&_hash_lock);\n\n\tfor (i = 0; i < NUM_BUCKETS; i++) {\n\t\tlist_for_each_entry(hc, _name_buckets + i, name_list) {\n\t\t\tmd = hc->md;\n\t\t\tdm_get(md);\n\n\t\t\tif (keep_open_devices &&\n\t\t\t    dm_lock_for_deletion(md, mark_deferred, only_deferred)) {\n\t\t\t\tdm_put(md);\n\t\t\t\tdev_skipped++;\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tt = __hash_remove(hc);\n\n\t\t\tup_write(&_hash_lock);\n\n\t\t\tif (t) {\n\t\t\t\tdm_sync_table(md);\n\t\t\t\tdm_table_destroy(t);\n\t\t\t}\n\t\t\tdm_put(md);\n\t\t\tif (likely(keep_open_devices))\n\t\t\t\tdm_destroy(md);\n\t\t\telse\n\t\t\t\tdm_destroy_immediate(md);\n\n\t\t\t/*\n\t\t\t * Some mapped devices may be using other mapped\n\t\t\t * devices, so repeat until we make no further\n\t\t\t * progress.  If a new mapped device is created\n\t\t\t * here it will also get removed.\n\t\t\t */\n\t\t\tgoto retry;\n\t\t}\n\t}\n\n\tup_write(&_hash_lock);\n\n\tif (dev_skipped)\n\t\tDMWARN(\"remove_all left %d open device(s)\", dev_skipped);\n}\n\n/*\n * Set the uuid of a hash_cell that isn't already set.\n */\nstatic void __set_cell_uuid(struct hash_cell *hc, char *new_uuid)\n{\n\tmutex_lock(&dm_hash_cells_mutex);\n\thc->uuid = new_uuid;\n\tmutex_unlock(&dm_hash_cells_mutex);\n\n\tlist_add(&hc->uuid_list, _uuid_buckets + hash_str(new_uuid));\n}\n\n/*\n * Changes the name of a hash_cell and returns the old name for\n * the caller to free.\n */\nstatic char *__change_cell_name(struct hash_cell *hc, char *new_name)\n{\n\tchar *old_name;\n\n\t/*\n\t * Rename and move the name cell.\n\t */\n\tlist_del(&hc->name_list);\n\told_name = hc->name;\n\n\tmutex_lock(&dm_hash_cells_mutex);\n\thc->name = new_name;\n\tmutex_unlock(&dm_hash_cells_mutex);\n\n\tlist_add(&hc->name_list, _name_buckets + hash_str(new_name));\n\n\treturn old_name;\n}\n\nstatic struct mapped_device *dm_hash_rename(struct dm_ioctl *param,\n\t\t\t\t\t    const char *new)\n{\n\tchar *new_data, *old_name = NULL;\n\tstruct hash_cell *hc;\n\tstruct dm_table *table;\n\tstruct mapped_device *md;\n\tunsigned change_uuid = (param->flags & DM_UUID_FLAG) ? 1 : 0;\n\tint srcu_idx;\n\n\t/*\n\t * duplicate new.\n\t */\n\tnew_data = kstrdup(new, GFP_KERNEL);\n\tif (!new_data)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tdown_write(&_hash_lock);\n\n\t/*\n\t * Is new free ?\n\t */\n\tif (change_uuid)\n\t\thc = __get_uuid_cell(new);\n\telse\n\t\thc = __get_name_cell(new);\n\n\tif (hc) {\n\t\tDMWARN(\"Unable to change %s on mapped device %s to one that \"\n\t\t       \"already exists: %s\",\n\t\t       change_uuid ? \"uuid\" : \"name\",\n\t\t       param->name, new);\n\t\tdm_put(hc->md);\n\t\tup_write(&_hash_lock);\n\t\tkfree(new_data);\n\t\treturn ERR_PTR(-EBUSY);\n\t}\n\n\t/*\n\t * Is there such a device as 'old' ?\n\t */\n\thc = __get_name_cell(param->name);\n\tif (!hc) {\n\t\tDMWARN(\"Unable to rename non-existent device, %s to %s%s\",\n\t\t       param->name, change_uuid ? \"uuid \" : \"\", new);\n\t\tup_write(&_hash_lock);\n\t\tkfree(new_data);\n\t\treturn ERR_PTR(-ENXIO);\n\t}\n\n\t/*\n\t * Does this device already have a uuid?\n\t */\n\tif (change_uuid && hc->uuid) {\n\t\tDMWARN(\"Unable to change uuid of mapped device %s to %s \"\n\t\t       \"because uuid is already set to %s\",\n\t\t       param->name, new, hc->uuid);\n\t\tdm_put(hc->md);\n\t\tup_write(&_hash_lock);\n\t\tkfree(new_data);\n\t\treturn ERR_PTR(-EINVAL);\n\t}\n\n\tif (change_uuid)\n\t\t__set_cell_uuid(hc, new_data);\n\telse\n\t\told_name = __change_cell_name(hc, new_data);\n\n\t/*\n\t * Wake up any dm event waiters.\n\t */\n\ttable = dm_get_live_table(hc->md, &srcu_idx);\n\tif (table)\n\t\tdm_table_event(table);\n\tdm_put_live_table(hc->md, srcu_idx);\n\n\tif (!dm_kobject_uevent(hc->md, KOBJ_CHANGE, param->event_nr))\n\t\tparam->flags |= DM_UEVENT_GENERATED_FLAG;\n\n\tmd = hc->md;\n\tup_write(&_hash_lock);\n\tkfree(old_name);\n\n\treturn md;\n}\n\nvoid dm_deferred_remove(void)\n{\n\tdm_hash_remove_all(true, false, true);\n}\n\n/*-----------------------------------------------------------------\n * Implementation of the ioctl commands\n *---------------------------------------------------------------*/\n/*\n * All the ioctl commands get dispatched to functions with this\n * prototype.\n */\ntypedef int (*ioctl_fn)(struct file *filp, struct dm_ioctl *param, size_t param_size);\n\nstatic int remove_all(struct file *filp, struct dm_ioctl *param, size_t param_size)\n{\n\tdm_hash_remove_all(true, !!(param->flags & DM_DEFERRED_REMOVE), false);\n\tparam->data_size = 0;\n\treturn 0;\n}\n\n/*\n * Round up the ptr to an 8-byte boundary.\n */\n#define ALIGN_MASK 7\nstatic inline size_t align_val(size_t val)\n{\n\treturn (val + ALIGN_MASK) & ~ALIGN_MASK;\n}\nstatic inline void *align_ptr(void *ptr)\n{\n\treturn (void *)align_val((size_t)ptr);\n}\n\n/*\n * Retrieves the data payload buffer from an already allocated\n * struct dm_ioctl.\n */\nstatic void *get_result_buffer(struct dm_ioctl *param, size_t param_size,\n\t\t\t       size_t *len)\n{\n\tparam->data_start = align_ptr(param + 1) - (void *) param;\n\n\tif (param->data_start < param_size)\n\t\t*len = param_size - param->data_start;\n\telse\n\t\t*len = 0;\n\n\treturn ((void *) param) + param->data_start;\n}\n\nstatic int list_devices(struct file *filp, struct dm_ioctl *param, size_t param_size)\n{\n\tunsigned int i;\n\tstruct hash_cell *hc;\n\tsize_t len, needed = 0;\n\tstruct gendisk *disk;\n\tstruct dm_name_list *orig_nl, *nl, *old_nl = NULL;\n\tuint32_t *event_nr;\n\n\tdown_write(&_hash_lock);\n\n\t/*\n\t * Loop through all the devices working out how much\n\t * space we need.\n\t */\n\tfor (i = 0; i < NUM_BUCKETS; i++) {\n\t\tlist_for_each_entry (hc, _name_buckets + i, name_list) {\n\t\t\tneeded += align_val(offsetof(struct dm_name_list, name) + strlen(hc->name) + 1);\n\t\t\tneeded += align_val(sizeof(uint32_t));\n\t\t}\n\t}\n\n\t/*\n\t * Grab our output buffer.\n\t */\n\tnl = orig_nl = get_result_buffer(param, param_size, &len);\n\tif (len < needed || len < sizeof(nl->dev)) {\n\t\tparam->flags |= DM_BUFFER_FULL_FLAG;\n\t\tgoto out;\n\t}\n\tparam->data_size = param->data_start + needed;\n\n\tnl->dev = 0;\t/* Flags no data */\n\n\t/*\n\t * Now loop through filling out the names.\n\t */\n\tfor (i = 0; i < NUM_BUCKETS; i++) {\n\t\tlist_for_each_entry (hc, _name_buckets + i, name_list) {\n\t\t\tif (old_nl)\n\t\t\t\told_nl->next = (uint32_t) ((void *) nl -\n\t\t\t\t\t\t\t   (void *) old_nl);\n\t\t\tdisk = dm_disk(hc->md);\n\t\t\tnl->dev = huge_encode_dev(disk_devt(disk));\n\t\t\tnl->next = 0;\n\t\t\tstrcpy(nl->name, hc->name);\n\n\t\t\told_nl = nl;\n\t\t\tevent_nr = align_ptr(nl->name + strlen(hc->name) + 1);\n\t\t\t*event_nr = dm_get_event_nr(hc->md);\n\t\t\tnl = align_ptr(event_nr + 1);\n\t\t}\n\t}\n\t/*\n\t * If mismatch happens, security may be compromised due to buffer\n\t * overflow, so it's better to crash.\n\t */\n\tBUG_ON((char *)nl - (char *)orig_nl != needed);\n\n out:\n\tup_write(&_hash_lock);\n\treturn 0;\n}\n\nstatic void list_version_get_needed(struct target_type *tt, void *needed_param)\n{\n    size_t *needed = needed_param;\n\n    *needed += sizeof(struct dm_target_versions);\n    *needed += strlen(tt->name);\n    *needed += ALIGN_MASK;\n}\n\nstatic void list_version_get_info(struct target_type *tt, void *param)\n{\n    struct vers_iter *info = param;\n\n    /* Check space - it might have changed since the first iteration */\n    if ((char *)info->vers + sizeof(tt->version) + strlen(tt->name) + 1 >\n\tinfo->end) {\n\n\tinfo->flags = DM_BUFFER_FULL_FLAG;\n\treturn;\n    }\n\n    if (info->old_vers)\n\tinfo->old_vers->next = (uint32_t) ((void *)info->vers -\n\t\t\t\t\t   (void *)info->old_vers);\n    info->vers->version[0] = tt->version[0];\n    info->vers->version[1] = tt->version[1];\n    info->vers->version[2] = tt->version[2];\n    info->vers->next = 0;\n    strcpy(info->vers->name, tt->name);\n\n    info->old_vers = info->vers;\n    info->vers = align_ptr(((void *) ++info->vers) + strlen(tt->name) + 1);\n}\n\nstatic int __list_versions(struct dm_ioctl *param, size_t param_size, const char *name)\n{\n\tsize_t len, needed = 0;\n\tstruct dm_target_versions *vers;\n\tstruct vers_iter iter_info;\n\tstruct target_type *tt = NULL;\n\n\tif (name) {\n\t\ttt = dm_get_target_type(name);\n\t\tif (!tt)\n\t\t\treturn -EINVAL;\n\t}\n\n\t/*\n\t * Loop through all the devices working out how much\n\t * space we need.\n\t */\n\tif (!tt)\n\t\tdm_target_iterate(list_version_get_needed, &needed);\n\telse\n\t\tlist_version_get_needed(tt, &needed);\n\n\t/*\n\t * Grab our output buffer.\n\t */\n\tvers = get_result_buffer(param, param_size, &len);\n\tif (len < needed) {\n\t\tparam->flags |= DM_BUFFER_FULL_FLAG;\n\t\tgoto out;\n\t}\n\tparam->data_size = param->data_start + needed;\n\n\titer_info.param_size = param_size;\n\titer_info.old_vers = NULL;\n\titer_info.vers = vers;\n\titer_info.flags = 0;\n\titer_info.end = (char *)vers+len;\n\n\t/*\n\t * Now loop through filling out the names & versions.\n\t */\n\tif (!tt)\n\t\tdm_target_iterate(list_version_get_info, &iter_info);\n\telse\n\t\tlist_version_get_info(tt, &iter_info);\n\tparam->flags |= iter_info.flags;\n\n out:\n\tif (tt)\n\t\tdm_put_target_type(tt);\n\treturn 0;\n}\n\nstatic int list_versions(struct file *filp, struct dm_ioctl *param, size_t param_size)\n{\n\treturn __list_versions(param, param_size, NULL);\n}\n\nstatic int get_target_version(struct file *filp, struct dm_ioctl *param, size_t param_size)\n{\n\treturn __list_versions(param, param_size, param->name);\n}\n\nstatic int check_name(const char *name)\n{\n\tif (strchr(name, '/')) {\n\t\tDMWARN(\"invalid device name\");\n\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}\n\n/*\n * On successful return, the caller must not attempt to acquire\n * _hash_lock without first calling dm_put_live_table, because dm_table_destroy\n * waits for this dm_put_live_table and could be called under this lock.\n */\nstatic struct dm_table *dm_get_inactive_table(struct mapped_device *md, int *srcu_idx)\n{\n\tstruct hash_cell *hc;\n\tstruct dm_table *table = NULL;\n\n\t/* increment rcu count, we don't care about the table pointer */\n\tdm_get_live_table(md, srcu_idx);\n\n\tdown_read(&_hash_lock);\n\thc = dm_get_mdptr(md);\n\tif (!hc || hc->md != md) {\n\t\tDMWARN(\"device has been removed from the dev hash table.\");\n\t\tgoto out;\n\t}\n\n\ttable = hc->new_map;\n\nout:\n\tup_read(&_hash_lock);\n\n\treturn table;\n}\n\nstatic struct dm_table *dm_get_live_or_inactive_table(struct mapped_device *md,\n\t\t\t\t\t\t      struct dm_ioctl *param,\n\t\t\t\t\t\t      int *srcu_idx)\n{\n\treturn (param->flags & DM_QUERY_INACTIVE_TABLE_FLAG) ?\n\t\tdm_get_inactive_table(md, srcu_idx) : dm_get_live_table(md, srcu_idx);\n}\n\n/*\n * Fills in a dm_ioctl structure, ready for sending back to\n * userland.\n */\nstatic void __dev_status(struct mapped_device *md, struct dm_ioctl *param)\n{\n\tstruct gendisk *disk = dm_disk(md);\n\tstruct dm_table *table;\n\tint srcu_idx;\n\n\tparam->flags &= ~(DM_SUSPEND_FLAG | DM_READONLY_FLAG |\n\t\t\t  DM_ACTIVE_PRESENT_FLAG | DM_INTERNAL_SUSPEND_FLAG);\n\n\tif (dm_suspended_md(md))\n\t\tparam->flags |= DM_SUSPEND_FLAG;\n\n\tif (dm_suspended_internally_md(md))\n\t\tparam->flags |= DM_INTERNAL_SUSPEND_FLAG;\n\n\tif (dm_test_deferred_remove_flag(md))\n\t\tparam->flags |= DM_DEFERRED_REMOVE;\n\n\tparam->dev = huge_encode_dev(disk_devt(disk));\n\n\t/*\n\t * Yes, this will be out of date by the time it gets back\n\t * to userland, but it is still very useful for\n\t * debugging.\n\t */\n\tparam->open_count = dm_open_count(md);\n\n\tparam->event_nr = dm_get_event_nr(md);\n\tparam->target_count = 0;\n\n\ttable = dm_get_live_table(md, &srcu_idx);\n\tif (table) {\n\t\tif (!(param->flags & DM_QUERY_INACTIVE_TABLE_FLAG)) {\n\t\t\tif (get_disk_ro(disk))\n\t\t\t\tparam->flags |= DM_READONLY_FLAG;\n\t\t\tparam->target_count = dm_table_get_num_targets(table);\n\t\t}\n\n\t\tparam->flags |= DM_ACTIVE_PRESENT_FLAG;\n\t}\n\tdm_put_live_table(md, srcu_idx);\n\n\tif (param->flags & DM_QUERY_INACTIVE_TABLE_FLAG) {\n\t\tint srcu_idx;\n\t\ttable = dm_get_inactive_table(md, &srcu_idx);\n\t\tif (table) {\n\t\t\tif (!(dm_table_get_mode(table) & FMODE_WRITE))\n\t\t\t\tparam->flags |= DM_READONLY_FLAG;\n\t\t\tparam->target_count = dm_table_get_num_targets(table);\n\t\t}\n\t\tdm_put_live_table(md, srcu_idx);\n\t}\n}\n\nstatic int dev_create(struct file *filp, struct dm_ioctl *param, size_t param_size)\n{\n\tint r, m = DM_ANY_MINOR;\n\tstruct mapped_device *md;\n\n\tr = check_name(param->name);\n\tif (r)\n\t\treturn r;\n\n\tif (param->flags & DM_PERSISTENT_DEV_FLAG)\n\t\tm = MINOR(huge_decode_dev(param->dev));\n\n\tr = dm_create(m, &md);\n\tif (r)\n\t\treturn r;\n\n\tr = dm_hash_insert(param->name, *param->uuid ? param->uuid : NULL, md);\n\tif (r) {\n\t\tdm_put(md);\n\t\tdm_destroy(md);\n\t\treturn r;\n\t}\n\n\tparam->flags &= ~DM_INACTIVE_PRESENT_FLAG;\n\n\t__dev_status(md, param);\n\n\tdm_put(md);\n\n\treturn 0;\n}\n\n/*\n * Always use UUID for lookups if it's present, otherwise use name or dev.\n */\nstatic struct hash_cell *__find_device_hash_cell(struct dm_ioctl *param)\n{\n\tstruct hash_cell *hc = NULL;\n\n\tif (*param->uuid) {\n\t\tif (*param->name || param->dev)\n\t\t\treturn NULL;\n\n\t\thc = __get_uuid_cell(param->uuid);\n\t\tif (!hc)\n\t\t\treturn NULL;\n\t} else if (*param->name) {\n\t\tif (param->dev)\n\t\t\treturn NULL;\n\n\t\thc = __get_name_cell(param->name);\n\t\tif (!hc)\n\t\t\treturn NULL;\n\t} else if (param->dev) {\n\t\thc = __get_dev_cell(param->dev);\n\t\tif (!hc)\n\t\t\treturn NULL;\n\t} else\n\t\treturn NULL;\n\n\t/*\n\t * Sneakily write in both the name and the uuid\n\t * while we have the cell.\n\t */\n\tstrlcpy(param->name, hc->name, sizeof(param->name));\n\tif (hc->uuid)\n\t\tstrlcpy(param->uuid, hc->uuid, sizeof(param->uuid));\n\telse\n\t\tparam->uuid[0] = '\\0';\n\n\tif (hc->new_map)\n\t\tparam->flags |= DM_INACTIVE_PRESENT_FLAG;\n\telse\n\t\tparam->flags &= ~DM_INACTIVE_PRESENT_FLAG;\n\n\treturn hc;\n}\n\nstatic struct mapped_device *find_device(struct dm_ioctl *param)\n{\n\tstruct hash_cell *hc;\n\tstruct mapped_device *md = NULL;\n\n\tdown_read(&_hash_lock);\n\thc = __find_device_hash_cell(param);\n\tif (hc)\n\t\tmd = hc->md;\n\tup_read(&_hash_lock);\n\n\treturn md;\n}\n\nstatic int dev_remove(struct file *filp, struct dm_ioctl *param, size_t param_size)\n{\n\tstruct hash_cell *hc;\n\tstruct mapped_device *md;\n\tint r;\n\tstruct dm_table *t;\n\n\tdown_write(&_hash_lock);\n\thc = __find_device_hash_cell(param);\n\n\tif (!hc) {\n\t\tDMDEBUG_LIMIT(\"device doesn't appear to be in the dev hash table.\");\n\t\tup_write(&_hash_lock);\n\t\treturn -ENXIO;\n\t}\n\n\tmd = hc->md;\n\n\t/*\n\t * Ensure the device is not open and nothing further can open it.\n\t */\n\tr = dm_lock_for_deletion(md, !!(param->flags & DM_DEFERRED_REMOVE), false);\n\tif (r) {\n\t\tif (r == -EBUSY && param->flags & DM_DEFERRED_REMOVE) {\n\t\t\tup_write(&_hash_lock);\n\t\t\tdm_put(md);\n\t\t\treturn 0;\n\t\t}\n\t\tDMDEBUG_LIMIT(\"unable to remove open device %s\", hc->name);\n\t\tup_write(&_hash_lock);\n\t\tdm_put(md);\n\t\treturn r;\n\t}\n\n\tt = __hash_remove(hc);\n\tup_write(&_hash_lock);\n\n\tif (t) {\n\t\tdm_sync_table(md);\n\t\tdm_table_destroy(t);\n\t}\n\n\tparam->flags &= ~DM_DEFERRED_REMOVE;\n\n\tif (!dm_kobject_uevent(md, KOBJ_REMOVE, param->event_nr))\n\t\tparam->flags |= DM_UEVENT_GENERATED_FLAG;\n\n\tdm_put(md);\n\tdm_destroy(md);\n\treturn 0;\n}\n\n/*\n * Check a string doesn't overrun the chunk of\n * memory we copied from userland.\n */\nstatic int invalid_str(char *str, void *end)\n{\n\twhile ((void *) str < end)\n\t\tif (!*str++)\n\t\t\treturn 0;\n\n\treturn -EINVAL;\n}\n\nstatic int dev_rename(struct file *filp, struct dm_ioctl *param, size_t param_size)\n{\n\tint r;\n\tchar *new_data = (char *) param + param->data_start;\n\tstruct mapped_device *md;\n\tunsigned change_uuid = (param->flags & DM_UUID_FLAG) ? 1 : 0;\n\n\tif (new_data < param->data ||\n\t    invalid_str(new_data, (void *) param + param_size) || !*new_data ||\n\t    strlen(new_data) > (change_uuid ? DM_UUID_LEN - 1 : DM_NAME_LEN - 1)) {\n\t\tDMWARN(\"Invalid new mapped device name or uuid string supplied.\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (!change_uuid) {\n\t\tr = check_name(new_data);\n\t\tif (r)\n\t\t\treturn r;\n\t}\n\n\tmd = dm_hash_rename(param, new_data);\n\tif (IS_ERR(md))\n\t\treturn PTR_ERR(md);\n\n\t__dev_status(md, param);\n\tdm_put(md);\n\n\treturn 0;\n}\n\nstatic int dev_set_geometry(struct file *filp, struct dm_ioctl *param, size_t param_size)\n{\n\tint r = -EINVAL, x;\n\tstruct mapped_device *md;\n\tstruct hd_geometry geometry;\n\tunsigned long indata[4];\n\tchar *geostr = (char *) param + param->data_start;\n\tchar dummy;\n\n\tmd = find_device(param);\n\tif (!md)\n\t\treturn -ENXIO;\n\n\tif (geostr < param->data ||\n\t    invalid_str(geostr, (void *) param + param_size)) {\n\t\tDMWARN(\"Invalid geometry supplied.\");\n\t\tgoto out;\n\t}\n\n\tx = sscanf(geostr, \"%lu %lu %lu %lu%c\", indata,\n\t\t   indata + 1, indata + 2, indata + 3, &dummy);\n\n\tif (x != 4) {\n\t\tDMWARN(\"Unable to interpret geometry settings.\");\n\t\tgoto out;\n\t}\n\n\tif (indata[0] > 65535 || indata[1] > 255 ||\n\t    indata[2] > 255 || indata[3] > ULONG_MAX) {\n\t\tDMWARN(\"Geometry exceeds range limits.\");\n\t\tgoto out;\n\t}\n\n\tgeometry.cylinders = indata[0];\n\tgeometry.heads = indata[1];\n\tgeometry.sectors = indata[2];\n\tgeometry.start = indata[3];\n\n\tr = dm_set_geometry(md, &geometry);\n\n\tparam->data_size = 0;\n\nout:\n\tdm_put(md);\n\treturn r;\n}\n\nstatic int do_suspend(struct dm_ioctl *param)\n{\n\tint r = 0;\n\tunsigned suspend_flags = DM_SUSPEND_LOCKFS_FLAG;\n\tstruct mapped_device *md;\n\n\tmd = find_device(param);\n\tif (!md)\n\t\treturn -ENXIO;\n\n\tif (param->flags & DM_SKIP_LOCKFS_FLAG)\n\t\tsuspend_flags &= ~DM_SUSPEND_LOCKFS_FLAG;\n\tif (param->flags & DM_NOFLUSH_FLAG)\n\t\tsuspend_flags |= DM_SUSPEND_NOFLUSH_FLAG;\n\n\tif (!dm_suspended_md(md)) {\n\t\tr = dm_suspend(md, suspend_flags);\n\t\tif (r)\n\t\t\tgoto out;\n\t}\n\n\t__dev_status(md, param);\n\nout:\n\tdm_put(md);\n\n\treturn r;\n}\n\nstatic int do_resume(struct dm_ioctl *param)\n{\n\tint r = 0;\n\tunsigned suspend_flags = DM_SUSPEND_LOCKFS_FLAG;\n\tstruct hash_cell *hc;\n\tstruct mapped_device *md;\n\tstruct dm_table *new_map, *old_map = NULL;\n\n\tdown_write(&_hash_lock);\n\n\thc = __find_device_hash_cell(param);\n\tif (!hc) {\n\t\tDMDEBUG_LIMIT(\"device doesn't appear to be in the dev hash table.\");\n\t\tup_write(&_hash_lock);\n\t\treturn -ENXIO;\n\t}\n\n\tmd = hc->md;\n\n\tnew_map = hc->new_map;\n\thc->new_map = NULL;\n\tparam->flags &= ~DM_INACTIVE_PRESENT_FLAG;\n\n\tup_write(&_hash_lock);\n\n\t/* Do we need to load a new map ? */\n\tif (new_map) {\n\t\t/* Suspend if it isn't already suspended */\n\t\tif (param->flags & DM_SKIP_LOCKFS_FLAG)\n\t\t\tsuspend_flags &= ~DM_SUSPEND_LOCKFS_FLAG;\n\t\tif (param->flags & DM_NOFLUSH_FLAG)\n\t\t\tsuspend_flags |= DM_SUSPEND_NOFLUSH_FLAG;\n\t\tif (!dm_suspended_md(md))\n\t\t\tdm_suspend(md, suspend_flags);\n\n\t\told_map = dm_swap_table(md, new_map);\n\t\tif (IS_ERR(old_map)) {\n\t\t\tdm_sync_table(md);\n\t\t\tdm_table_destroy(new_map);\n\t\t\tdm_put(md);\n\t\t\treturn PTR_ERR(old_map);\n\t\t}\n\n\t\tif (dm_table_get_mode(new_map) & FMODE_WRITE)\n\t\t\tset_disk_ro(dm_disk(md), 0);\n\t\telse\n\t\t\tset_disk_ro(dm_disk(md), 1);\n\t}\n\n\tif (dm_suspended_md(md)) {\n\t\tr = dm_resume(md);\n\t\tif (!r && !dm_kobject_uevent(md, KOBJ_CHANGE, param->event_nr))\n\t\t\tparam->flags |= DM_UEVENT_GENERATED_FLAG;\n\t}\n\n\t/*\n\t * Since dm_swap_table synchronizes RCU, nobody should be in\n\t * read-side critical section already.\n\t */\n\tif (old_map)\n\t\tdm_table_destroy(old_map);\n\n\tif (!r)\n\t\t__dev_status(md, param);\n\n\tdm_put(md);\n\treturn r;\n}\n\n/*\n * Set or unset the suspension state of a device.\n * If the device already is in the requested state we just return its status.\n */\nstatic int dev_suspend(struct file *filp, struct dm_ioctl *param, size_t param_size)\n{\n\tif (param->flags & DM_SUSPEND_FLAG)\n\t\treturn do_suspend(param);\n\n\treturn do_resume(param);\n}\n\n/*\n * Copies device info back to user space, used by\n * the create and info ioctls.\n */\nstatic int dev_status(struct file *filp, struct dm_ioctl *param, size_t param_size)\n{\n\tstruct mapped_device *md;\n\n\tmd = find_device(param);\n\tif (!md)\n\t\treturn -ENXIO;\n\n\t__dev_status(md, param);\n\tdm_put(md);\n\n\treturn 0;\n}\n\n/*\n * Build up the status struct for each target\n */\nstatic void retrieve_status(struct dm_table *table,\n\t\t\t    struct dm_ioctl *param, size_t param_size)\n{\n\tunsigned int i, num_targets;\n\tstruct dm_target_spec *spec;\n\tchar *outbuf, *outptr;\n\tstatus_type_t type;\n\tsize_t remaining, len, used = 0;\n\tunsigned status_flags = 0;\n\n\toutptr = outbuf = get_result_buffer(param, param_size, &len);\n\n\tif (param->flags & DM_STATUS_TABLE_FLAG)\n\t\ttype = STATUSTYPE_TABLE;\n\telse\n\t\ttype = STATUSTYPE_INFO;\n\n\t/* Get all the target info */\n\tnum_targets = dm_table_get_num_targets(table);\n\tfor (i = 0; i < num_targets; i++) {\n\t\tstruct dm_target *ti = dm_table_get_target(table, i);\n\t\tsize_t l;\n\n\t\tremaining = len - (outptr - outbuf);\n\t\tif (remaining <= sizeof(struct dm_target_spec)) {\n\t\t\tparam->flags |= DM_BUFFER_FULL_FLAG;\n\t\t\tbreak;\n\t\t}\n\n\t\tspec = (struct dm_target_spec *) outptr;\n\n\t\tspec->status = 0;\n\t\tspec->sector_start = ti->begin;\n\t\tspec->length = ti->len;\n\t\tstrncpy(spec->target_type, ti->type->name,\n\t\t\tsizeof(spec->target_type) - 1);\n\n\t\toutptr += sizeof(struct dm_target_spec);\n\t\tremaining = len - (outptr - outbuf);\n\t\tif (remaining <= 0) {\n\t\t\tparam->flags |= DM_BUFFER_FULL_FLAG;\n\t\t\tbreak;\n\t\t}\n\n\t\t/* Get the status/table string from the target driver */\n\t\tif (ti->type->status) {\n\t\t\tif (param->flags & DM_NOFLUSH_FLAG)\n\t\t\t\tstatus_flags |= DM_STATUS_NOFLUSH_FLAG;\n\t\t\tti->type->status(ti, type, status_flags, outptr, remaining);\n\t\t} else\n\t\t\toutptr[0] = '\\0';\n\n\t\tl = strlen(outptr) + 1;\n\t\tif (l == remaining) {\n\t\t\tparam->flags |= DM_BUFFER_FULL_FLAG;\n\t\t\tbreak;\n\t\t}\n\n\t\toutptr += l;\n\t\tused = param->data_start + (outptr - outbuf);\n\n\t\toutptr = align_ptr(outptr);\n\t\tspec->next = outptr - outbuf;\n\t}\n\n\tif (used)\n\t\tparam->data_size = used;\n\n\tparam->target_count = num_targets;\n}\n\n/*\n * Wait for a device to report an event\n */\nstatic int dev_wait(struct file *filp, struct dm_ioctl *param, size_t param_size)\n{\n\tint r = 0;\n\tstruct mapped_device *md;\n\tstruct dm_table *table;\n\tint srcu_idx;\n\n\tmd = find_device(param);\n\tif (!md)\n\t\treturn -ENXIO;\n\n\t/*\n\t * Wait for a notification event\n\t */\n\tif (dm_wait_event(md, param->event_nr)) {\n\t\tr = -ERESTARTSYS;\n\t\tgoto out;\n\t}\n\n\t/*\n\t * The userland program is going to want to know what\n\t * changed to trigger the event, so we may as well tell\n\t * him and save an ioctl.\n\t */\n\t__dev_status(md, param);\n\n\ttable = dm_get_live_or_inactive_table(md, param, &srcu_idx);\n\tif (table)\n\t\tretrieve_status(table, param, param_size);\n\tdm_put_live_table(md, srcu_idx);\n\nout:\n\tdm_put(md);\n\n\treturn r;\n}\n\n/*\n * Remember the global event number and make it possible to poll\n * for further events.\n */\nstatic int dev_arm_poll(struct file *filp, struct dm_ioctl *param, size_t param_size)\n{\n\tstruct dm_file *priv = filp->private_data;\n\n\tpriv->global_event_nr = atomic_read(&dm_global_event_nr);\n\n\treturn 0;\n}\n\nstatic inline fmode_t get_mode(struct dm_ioctl *param)\n{\n\tfmode_t mode = FMODE_READ | FMODE_WRITE;\n\n\tif (param->flags & DM_READONLY_FLAG)\n\t\tmode = FMODE_READ;\n\n\treturn mode;\n}\n\nstatic int next_target(struct dm_target_spec *last, uint32_t next, void *end,\n\t\t       struct dm_target_spec **spec, char **target_params)\n{\n\t*spec = (struct dm_target_spec *) ((unsigned char *) last + next);\n\t*target_params = (char *) (*spec + 1);\n\n\tif (*spec < (last + 1))\n\t\treturn -EINVAL;\n\n\treturn invalid_str(*target_params, end);\n}\n\nstatic int populate_table(struct dm_table *table,\n\t\t\t  struct dm_ioctl *param, size_t param_size)\n{\n\tint r;\n\tunsigned int i = 0;\n\tstruct dm_target_spec *spec = (struct dm_target_spec *) param;\n\tuint32_t next = param->data_start;\n\tvoid *end = (void *) param + param_size;\n\tchar *target_params;\n\n\tif (!param->target_count) {\n\t\tDMWARN(\"populate_table: no targets specified\");\n\t\treturn -EINVAL;\n\t}\n\n\tfor (i = 0; i < param->target_count; i++) {\n\n\t\tr = next_target(spec, next, end, &spec, &target_params);\n\t\tif (r) {\n\t\t\tDMWARN(\"unable to find target\");\n\t\t\treturn r;\n\t\t}\n\n\t\tr = dm_table_add_target(table, spec->target_type,\n\t\t\t\t\t(sector_t) spec->sector_start,\n\t\t\t\t\t(sector_t) spec->length,\n\t\t\t\t\ttarget_params);\n\t\tif (r) {\n\t\t\tDMWARN(\"error adding target to table\");\n\t\t\treturn r;\n\t\t}\n\n\t\tnext = spec->next;\n\t}\n\n\treturn dm_table_complete(table);\n}\n\nstatic bool is_valid_type(enum dm_queue_mode cur, enum dm_queue_mode new)\n{\n\tif (cur == new ||\n\t    (cur == DM_TYPE_BIO_BASED && new == DM_TYPE_DAX_BIO_BASED))\n\t\treturn true;\n\n\treturn false;\n}\n\nstatic int table_load(struct file *filp, struct dm_ioctl *param, size_t param_size)\n{\n\tint r;\n\tstruct hash_cell *hc;\n\tstruct dm_table *t, *old_map = NULL;\n\tstruct mapped_device *md;\n\tstruct target_type *immutable_target_type;\n\n\tmd = find_device(param);\n\tif (!md)\n\t\treturn -ENXIO;\n\n\tr = dm_table_create(&t, get_mode(param), param->target_count, md);\n\tif (r)\n\t\tgoto err;\n\n\t/* Protect md->type and md->queue against concurrent table loads. */\n\tdm_lock_md_type(md);\n\tr = populate_table(t, param, param_size);\n\tif (r)\n\t\tgoto err_unlock_md_type;\n\n\timmutable_target_type = dm_get_immutable_target_type(md);\n\tif (immutable_target_type &&\n\t    (immutable_target_type != dm_table_get_immutable_target_type(t)) &&\n\t    !dm_table_get_wildcard_target(t)) {\n\t\tDMWARN(\"can't replace immutable target type %s\",\n\t\t       immutable_target_type->name);\n\t\tr = -EINVAL;\n\t\tgoto err_unlock_md_type;\n\t}\n\n\tif (dm_get_md_type(md) == DM_TYPE_NONE) {\n\t\t/* Initial table load: acquire type of table. */\n\t\tdm_set_md_type(md, dm_table_get_type(t));\n\n\t\t/* setup md->queue to reflect md's type (may block) */\n\t\tr = dm_setup_md_queue(md, t);\n\t\tif (r) {\n\t\t\tDMWARN(\"unable to set up device queue for new table.\");\n\t\t\tgoto err_unlock_md_type;\n\t\t}\n\t} else if (!is_valid_type(dm_get_md_type(md), dm_table_get_type(t))) {\n\t\tDMWARN(\"can't change device type (old=%u vs new=%u) after initial table load.\",\n\t\t       dm_get_md_type(md), dm_table_get_type(t));\n\t\tr = -EINVAL;\n\t\tgoto err_unlock_md_type;\n\t}\n\n\tdm_unlock_md_type(md);\n\n\t/* stage inactive table */\n\tdown_write(&_hash_lock);\n\thc = dm_get_mdptr(md);\n\tif (!hc || hc->md != md) {\n\t\tDMWARN(\"device has been removed from the dev hash table.\");\n\t\tup_write(&_hash_lock);\n\t\tr = -ENXIO;\n\t\tgoto err_destroy_table;\n\t}\n\n\tif (hc->new_map)\n\t\told_map = hc->new_map;\n\thc->new_map = t;\n\tup_write(&_hash_lock);\n\n\tparam->flags |= DM_INACTIVE_PRESENT_FLAG;\n\t__dev_status(md, param);\n\n\tif (old_map) {\n\t\tdm_sync_table(md);\n\t\tdm_table_destroy(old_map);\n\t}\n\n\tdm_put(md);\n\n\treturn 0;\n\nerr_unlock_md_type:\n\tdm_unlock_md_type(md);\nerr_destroy_table:\n\tdm_table_destroy(t);\nerr:\n\tdm_put(md);\n\n\treturn r;\n}\n\nstatic int table_clear(struct file *filp, struct dm_ioctl *param, size_t param_size)\n{\n\tstruct hash_cell *hc;\n\tstruct mapped_device *md;\n\tstruct dm_table *old_map = NULL;\n\n\tdown_write(&_hash_lock);\n\n\thc = __find_device_hash_cell(param);\n\tif (!hc) {\n\t\tDMDEBUG_LIMIT(\"device doesn't appear to be in the dev hash table.\");\n\t\tup_write(&_hash_lock);\n\t\treturn -ENXIO;\n\t}\n\n\tif (hc->new_map) {\n\t\told_map = hc->new_map;\n\t\thc->new_map = NULL;\n\t}\n\n\tparam->flags &= ~DM_INACTIVE_PRESENT_FLAG;\n\n\t__dev_status(hc->md, param);\n\tmd = hc->md;\n\tup_write(&_hash_lock);\n\tif (old_map) {\n\t\tdm_sync_table(md);\n\t\tdm_table_destroy(old_map);\n\t}\n\tdm_put(md);\n\n\treturn 0;\n}\n\n/*\n * Retrieves a list of devices used by a particular dm device.\n */\nstatic void retrieve_deps(struct dm_table *table,\n\t\t\t  struct dm_ioctl *param, size_t param_size)\n{\n\tunsigned int count = 0;\n\tstruct list_head *tmp;\n\tsize_t len, needed;\n\tstruct dm_dev_internal *dd;\n\tstruct dm_target_deps *deps;\n\n\tdeps = get_result_buffer(param, param_size, &len);\n\n\t/*\n\t * Count the devices.\n\t */\n\tlist_for_each (tmp, dm_table_get_devices(table))\n\t\tcount++;\n\n\t/*\n\t * Check we have enough space.\n\t */\n\tneeded = struct_size(deps, dev, count);\n\tif (len < needed) {\n\t\tparam->flags |= DM_BUFFER_FULL_FLAG;\n\t\treturn;\n\t}\n\n\t/*\n\t * Fill in the devices.\n\t */\n\tdeps->count = count;\n\tcount = 0;\n\tlist_for_each_entry (dd, dm_table_get_devices(table), list)\n\t\tdeps->dev[count++] = huge_encode_dev(dd->dm_dev->bdev->bd_dev);\n\n\tparam->data_size = param->data_start + needed;\n}\n\nstatic int table_deps(struct file *filp, struct dm_ioctl *param, size_t param_size)\n{\n\tstruct mapped_device *md;\n\tstruct dm_table *table;\n\tint srcu_idx;\n\n\tmd = find_device(param);\n\tif (!md)\n\t\treturn -ENXIO;\n\n\t__dev_status(md, param);\n\n\ttable = dm_get_live_or_inactive_table(md, param, &srcu_idx);\n\tif (table)\n\t\tretrieve_deps(table, param, param_size);\n\tdm_put_live_table(md, srcu_idx);\n\n\tdm_put(md);\n\n\treturn 0;\n}\n\n/*\n * Return the status of a device as a text string for each\n * target.\n */\nstatic int table_status(struct file *filp, struct dm_ioctl *param, size_t param_size)\n{\n\tstruct mapped_device *md;\n\tstruct dm_table *table;\n\tint srcu_idx;\n\n\tmd = find_device(param);\n\tif (!md)\n\t\treturn -ENXIO;\n\n\t__dev_status(md, param);\n\n\ttable = dm_get_live_or_inactive_table(md, param, &srcu_idx);\n\tif (table)\n\t\tretrieve_status(table, param, param_size);\n\tdm_put_live_table(md, srcu_idx);\n\n\tdm_put(md);\n\n\treturn 0;\n}\n\n/*\n * Process device-mapper dependent messages.  Messages prefixed with '@'\n * are processed by the DM core.  All others are delivered to the target.\n * Returns a number <= 1 if message was processed by device mapper.\n * Returns 2 if message should be delivered to the target.\n */\nstatic int message_for_md(struct mapped_device *md, unsigned argc, char **argv,\n\t\t\t  char *result, unsigned maxlen)\n{\n\tint r;\n\n\tif (**argv != '@')\n\t\treturn 2; /* no '@' prefix, deliver to target */\n\n\tif (!strcasecmp(argv[0], \"@cancel_deferred_remove\")) {\n\t\tif (argc != 1) {\n\t\t\tDMERR(\"Invalid arguments for @cancel_deferred_remove\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t\treturn dm_cancel_deferred_remove(md);\n\t}\n\n\tr = dm_stats_message(md, argc, argv, result, maxlen);\n\tif (r < 2)\n\t\treturn r;\n\n\tDMERR(\"Unsupported message sent to DM core: %s\", argv[0]);\n\treturn -EINVAL;\n}\n\n/*\n * Pass a message to the target that's at the supplied device offset.\n */\nstatic int target_message(struct file *filp, struct dm_ioctl *param, size_t param_size)\n{\n\tint r, argc;\n\tchar **argv;\n\tstruct mapped_device *md;\n\tstruct dm_table *table;\n\tstruct dm_target *ti;\n\tstruct dm_target_msg *tmsg = (void *) param + param->data_start;\n\tsize_t maxlen;\n\tchar *result = get_result_buffer(param, param_size, &maxlen);\n\tint srcu_idx;\n\n\tmd = find_device(param);\n\tif (!md)\n\t\treturn -ENXIO;\n\n\tif (tmsg < (struct dm_target_msg *) param->data ||\n\t    invalid_str(tmsg->message, (void *) param + param_size)) {\n\t\tDMWARN(\"Invalid target message parameters.\");\n\t\tr = -EINVAL;\n\t\tgoto out;\n\t}\n\n\tr = dm_split_args(&argc, &argv, tmsg->message);\n\tif (r) {\n\t\tDMWARN(\"Failed to split target message parameters\");\n\t\tgoto out;\n\t}\n\n\tif (!argc) {\n\t\tDMWARN(\"Empty message received.\");\n\t\tr = -EINVAL;\n\t\tgoto out_argv;\n\t}\n\n\tr = message_for_md(md, argc, argv, result, maxlen);\n\tif (r <= 1)\n\t\tgoto out_argv;\n\n\ttable = dm_get_live_table(md, &srcu_idx);\n\tif (!table)\n\t\tgoto out_table;\n\n\tif (dm_deleting_md(md)) {\n\t\tr = -ENXIO;\n\t\tgoto out_table;\n\t}\n\n\tti = dm_table_find_target(table, tmsg->sector);\n\tif (!ti) {\n\t\tDMWARN(\"Target message sector outside device.\");\n\t\tr = -EINVAL;\n\t} else if (ti->type->message)\n\t\tr = ti->type->message(ti, argc, argv, result, maxlen);\n\telse {\n\t\tDMWARN(\"Target type does not support messages\");\n\t\tr = -EINVAL;\n\t}\n\n out_table:\n\tdm_put_live_table(md, srcu_idx);\n out_argv:\n\tkfree(argv);\n out:\n\tif (r >= 0)\n\t\t__dev_status(md, param);\n\n\tif (r == 1) {\n\t\tparam->flags |= DM_DATA_OUT_FLAG;\n\t\tif (dm_message_test_buffer_overflow(result, maxlen))\n\t\t\tparam->flags |= DM_BUFFER_FULL_FLAG;\n\t\telse\n\t\t\tparam->data_size = param->data_start + strlen(result) + 1;\n\t\tr = 0;\n\t}\n\n\tdm_put(md);\n\treturn r;\n}\n\n/*\n * The ioctl parameter block consists of two parts, a dm_ioctl struct\n * followed by a data buffer.  This flag is set if the second part,\n * which has a variable size, is not used by the function processing\n * the ioctl.\n */\n#define IOCTL_FLAGS_NO_PARAMS\t\t1\n#define IOCTL_FLAGS_ISSUE_GLOBAL_EVENT\t2\n\n/*-----------------------------------------------------------------\n * Implementation of open/close/ioctl on the special char\n * device.\n *---------------------------------------------------------------*/\nstatic ioctl_fn lookup_ioctl(unsigned int cmd, int *ioctl_flags)\n{\n\tstatic const struct {\n\t\tint cmd;\n\t\tint flags;\n\t\tioctl_fn fn;\n\t} _ioctls[] = {\n\t\t{DM_VERSION_CMD, 0, NULL}, /* version is dealt with elsewhere */\n\t\t{DM_REMOVE_ALL_CMD, IOCTL_FLAGS_NO_PARAMS | IOCTL_FLAGS_ISSUE_GLOBAL_EVENT, remove_all},\n\t\t{DM_LIST_DEVICES_CMD, 0, list_devices},\n\n\t\t{DM_DEV_CREATE_CMD, IOCTL_FLAGS_NO_PARAMS | IOCTL_FLAGS_ISSUE_GLOBAL_EVENT, dev_create},\n\t\t{DM_DEV_REMOVE_CMD, IOCTL_FLAGS_NO_PARAMS | IOCTL_FLAGS_ISSUE_GLOBAL_EVENT, dev_remove},\n\t\t{DM_DEV_RENAME_CMD, IOCTL_FLAGS_ISSUE_GLOBAL_EVENT, dev_rename},\n\t\t{DM_DEV_SUSPEND_CMD, IOCTL_FLAGS_NO_PARAMS, dev_suspend},\n\t\t{DM_DEV_STATUS_CMD, IOCTL_FLAGS_NO_PARAMS, dev_status},\n\t\t{DM_DEV_WAIT_CMD, 0, dev_wait},\n\n\t\t{DM_TABLE_LOAD_CMD, 0, table_load},\n\t\t{DM_TABLE_CLEAR_CMD, IOCTL_FLAGS_NO_PARAMS, table_clear},\n\t\t{DM_TABLE_DEPS_CMD, 0, table_deps},\n\t\t{DM_TABLE_STATUS_CMD, 0, table_status},\n\n\t\t{DM_LIST_VERSIONS_CMD, 0, list_versions},\n\n\t\t{DM_TARGET_MSG_CMD, 0, target_message},\n\t\t{DM_DEV_SET_GEOMETRY_CMD, 0, dev_set_geometry},\n\t\t{DM_DEV_ARM_POLL, IOCTL_FLAGS_NO_PARAMS, dev_arm_poll},\n\t\t{DM_GET_TARGET_VERSION, 0, get_target_version},\n\t};\n\n\tif (unlikely(cmd >= ARRAY_SIZE(_ioctls)))\n\t\treturn NULL;\n\n\t*ioctl_flags = _ioctls[cmd].flags;\n\treturn _ioctls[cmd].fn;\n}\n\n/*\n * As well as checking the version compatibility this always\n * copies the kernel interface version out.\n */\nstatic int check_version(unsigned int cmd, struct dm_ioctl __user *user)\n{\n\tuint32_t version[3];\n\tint r = 0;\n\n\tif (copy_from_user(version, user->version, sizeof(version)))\n\t\treturn -EFAULT;\n\n\tif ((DM_VERSION_MAJOR != version[0]) ||\n\t    (DM_VERSION_MINOR < version[1])) {\n\t\tDMWARN(\"ioctl interface mismatch: \"\n\t\t       \"kernel(%u.%u.%u), user(%u.%u.%u), cmd(%d)\",\n\t\t       DM_VERSION_MAJOR, DM_VERSION_MINOR,\n\t\t       DM_VERSION_PATCHLEVEL,\n\t\t       version[0], version[1], version[2], cmd);\n\t\tr = -EINVAL;\n\t}\n\n\t/*\n\t * Fill in the kernel version.\n\t */\n\tversion[0] = DM_VERSION_MAJOR;\n\tversion[1] = DM_VERSION_MINOR;\n\tversion[2] = DM_VERSION_PATCHLEVEL;\n\tif (copy_to_user(user->version, version, sizeof(version)))\n\t\treturn -EFAULT;\n\n\treturn r;\n}\n\n#define DM_PARAMS_MALLOC\t0x0001\t/* Params allocated with kvmalloc() */\n#define DM_WIPE_BUFFER\t\t0x0010\t/* Wipe input buffer before returning from ioctl */\n\nstatic void free_params(struct dm_ioctl *param, size_t param_size, int param_flags)\n{\n\tif (param_flags & DM_WIPE_BUFFER)\n\t\tmemset(param, 0, param_size);\n\n\tif (param_flags & DM_PARAMS_MALLOC)\n\t\tkvfree(param);\n}\n\nstatic int copy_params(struct dm_ioctl __user *user, struct dm_ioctl *param_kernel,\n\t\t       int ioctl_flags, struct dm_ioctl **param, int *param_flags)\n{\n\tstruct dm_ioctl *dmi;\n\tint secure_data;\n\tconst size_t minimum_data_size = offsetof(struct dm_ioctl, data);\n\tunsigned noio_flag;\n\n\tif (copy_from_user(param_kernel, user, minimum_data_size))\n\t\treturn -EFAULT;\n\n\tif (param_kernel->data_size < minimum_data_size)\n\t\treturn -EINVAL;\n\n\tsecure_data = param_kernel->flags & DM_SECURE_DATA_FLAG;\n\n\t*param_flags = secure_data ? DM_WIPE_BUFFER : 0;\n\n\tif (ioctl_flags & IOCTL_FLAGS_NO_PARAMS) {\n\t\tdmi = param_kernel;\n\t\tdmi->data_size = minimum_data_size;\n\t\tgoto data_copied;\n\t}\n\n\t/*\n\t * Use __GFP_HIGH to avoid low memory issues when a device is\n\t * suspended and the ioctl is needed to resume it.\n\t * Use kmalloc() rather than vmalloc() when we can.\n\t */\n\tdmi = NULL;\n\tnoio_flag = memalloc_noio_save();\n\tdmi = kvmalloc(param_kernel->data_size, GFP_KERNEL | __GFP_HIGH);\n\tmemalloc_noio_restore(noio_flag);\n\n\tif (!dmi) {\n\t\tif (secure_data && clear_user(user, param_kernel->data_size))\n\t\t\treturn -EFAULT;\n\t\treturn -ENOMEM;\n\t}\n\n\t*param_flags |= DM_PARAMS_MALLOC;\n\n\t/* Copy from param_kernel (which was already copied from user) */\n\tmemcpy(dmi, param_kernel, minimum_data_size);\n\n\tif (copy_from_user(&dmi->data, (char __user *)user + minimum_data_size,\n\t\t\t   param_kernel->data_size - minimum_data_size))\n\t\tgoto bad;\ndata_copied:\n\t/* Wipe the user buffer so we do not return it to userspace */\n\tif (secure_data && clear_user(user, param_kernel->data_size))\n\t\tgoto bad;\n\n\t*param = dmi;\n\treturn 0;\n\nbad:\n\tfree_params(dmi, param_kernel->data_size, *param_flags);\n\n\treturn -EFAULT;\n}\n\nstatic int validate_params(uint cmd, struct dm_ioctl *param)\n{\n\t/* Always clear this flag */\n\tparam->flags &= ~DM_BUFFER_FULL_FLAG;\n\tparam->flags &= ~DM_UEVENT_GENERATED_FLAG;\n\tparam->flags &= ~DM_SECURE_DATA_FLAG;\n\tparam->flags &= ~DM_DATA_OUT_FLAG;\n\n\t/* Ignores parameters */\n\tif (cmd == DM_REMOVE_ALL_CMD ||\n\t    cmd == DM_LIST_DEVICES_CMD ||\n\t    cmd == DM_LIST_VERSIONS_CMD)\n\t\treturn 0;\n\n\tif (cmd == DM_DEV_CREATE_CMD) {\n\t\tif (!*param->name) {\n\t\t\tDMWARN(\"name not supplied when creating device\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t} else if (*param->uuid && *param->name) {\n\t\tDMWARN(\"only supply one of name or uuid, cmd(%u)\", cmd);\n\t\treturn -EINVAL;\n\t}\n\n\t/* Ensure strings are terminated */\n\tparam->name[DM_NAME_LEN - 1] = '\\0';\n\tparam->uuid[DM_UUID_LEN - 1] = '\\0';\n\n\treturn 0;\n}\n\nstatic int ctl_ioctl(struct file *file, uint command, struct dm_ioctl __user *user)\n{\n\tint r = 0;\n\tint ioctl_flags;\n\tint param_flags;\n\tunsigned int cmd;\n\tstruct dm_ioctl *param;\n\tioctl_fn fn = NULL;\n\tsize_t input_param_size;\n\tstruct dm_ioctl param_kernel;\n\n\t/* only root can play with this */\n\tif (!capable(CAP_SYS_ADMIN))\n\t\treturn -EACCES;\n\n\tif (_IOC_TYPE(command) != DM_IOCTL)\n\t\treturn -ENOTTY;\n\n\tcmd = _IOC_NR(command);\n\n\t/*\n\t * Check the interface version passed in.  This also\n\t * writes out the kernel's interface version.\n\t */\n\tr = check_version(cmd, user);\n\tif (r)\n\t\treturn r;\n\n\t/*\n\t * Nothing more to do for the version command.\n\t */\n\tif (cmd == DM_VERSION_CMD)\n\t\treturn 0;\n\n\tfn = lookup_ioctl(cmd, &ioctl_flags);\n\tif (!fn) {\n\t\tDMWARN(\"dm_ctl_ioctl: unknown command 0x%x\", command);\n\t\treturn -ENOTTY;\n\t}\n\n\t/*\n\t * Copy the parameters into kernel space.\n\t */\n\tr = copy_params(user, &param_kernel, ioctl_flags, &param, &param_flags);\n\n\tif (r)\n\t\treturn r;\n\n\tinput_param_size = param->data_size;\n\tr = validate_params(cmd, param);\n\tif (r)\n\t\tgoto out;\n\n\tparam->data_size = offsetof(struct dm_ioctl, data);\n\tr = fn(file, param, input_param_size);\n\n\tif (unlikely(param->flags & DM_BUFFER_FULL_FLAG) &&\n\t    unlikely(ioctl_flags & IOCTL_FLAGS_NO_PARAMS))\n\t\tDMERR(\"ioctl %d tried to output some data but has IOCTL_FLAGS_NO_PARAMS set\", cmd);\n\n\tif (!r && ioctl_flags & IOCTL_FLAGS_ISSUE_GLOBAL_EVENT)\n\t\tdm_issue_global_event();\n\n\t/*\n\t * Copy the results back to userland.\n\t */\n\tif (!r && copy_to_user(user, param, param->data_size))\n\t\tr = -EFAULT;\n\nout:\n\tfree_params(param, input_param_size, param_flags);\n\treturn r;\n}\n\nstatic long dm_ctl_ioctl(struct file *file, uint command, ulong u)\n{\n\treturn (long)ctl_ioctl(file, command, (struct dm_ioctl __user *)u);\n}\n\n#ifdef CONFIG_COMPAT\nstatic long dm_compat_ctl_ioctl(struct file *file, uint command, ulong u)\n{\n\treturn (long)dm_ctl_ioctl(file, command, (ulong) compat_ptr(u));\n}\n#else\n#define dm_compat_ctl_ioctl NULL\n#endif\n\nstatic int dm_open(struct inode *inode, struct file *filp)\n{\n\tint r;\n\tstruct dm_file *priv;\n\n\tr = nonseekable_open(inode, filp);\n\tif (unlikely(r))\n\t\treturn r;\n\n\tpriv = filp->private_data = kmalloc(sizeof(struct dm_file), GFP_KERNEL);\n\tif (!priv)\n\t\treturn -ENOMEM;\n\n\tpriv->global_event_nr = atomic_read(&dm_global_event_nr);\n\n\treturn 0;\n}\n\nstatic int dm_release(struct inode *inode, struct file *filp)\n{\n\tkfree(filp->private_data);\n\treturn 0;\n}\n\nstatic __poll_t dm_poll(struct file *filp, poll_table *wait)\n{\n\tstruct dm_file *priv = filp->private_data;\n\t__poll_t mask = 0;\n\n\tpoll_wait(filp, &dm_global_eventq, wait);\n\n\tif ((int)(atomic_read(&dm_global_event_nr) - priv->global_event_nr) > 0)\n\t\tmask |= EPOLLIN;\n\n\treturn mask;\n}\n\nstatic const struct file_operations _ctl_fops = {\n\t.open    = dm_open,\n\t.release = dm_release,\n\t.poll    = dm_poll,\n\t.unlocked_ioctl\t = dm_ctl_ioctl,\n\t.compat_ioctl = dm_compat_ctl_ioctl,\n\t.owner\t = THIS_MODULE,\n\t.llseek  = noop_llseek,\n};\n\nstatic struct miscdevice _dm_misc = {\n\t.minor\t\t= MAPPER_CTRL_MINOR,\n\t.name  \t\t= DM_NAME,\n\t.nodename\t= DM_DIR \"/\" DM_CONTROL_NODE,\n\t.fops  \t\t= &_ctl_fops\n};\n\nMODULE_ALIAS_MISCDEV(MAPPER_CTRL_MINOR);\nMODULE_ALIAS(\"devname:\" DM_DIR \"/\" DM_CONTROL_NODE);\n\n/*\n * Create misc character device and link to DM_DIR/control.\n */\nint __init dm_interface_init(void)\n{\n\tint r;\n\n\tr = dm_hash_init();\n\tif (r)\n\t\treturn r;\n\n\tr = misc_register(&_dm_misc);\n\tif (r) {\n\t\tDMERR(\"misc_register failed for control device\");\n\t\tdm_hash_exit();\n\t\treturn r;\n\t}\n\n\tDMINFO(\"%d.%d.%d%s initialised: %s\", DM_VERSION_MAJOR,\n\t       DM_VERSION_MINOR, DM_VERSION_PATCHLEVEL, DM_VERSION_EXTRA,\n\t       DM_DRIVER_EMAIL);\n\treturn 0;\n}\n\nvoid dm_interface_exit(void)\n{\n\tmisc_deregister(&_dm_misc);\n\tdm_hash_exit();\n}\n\n/**\n * dm_copy_name_and_uuid - Copy mapped device name & uuid into supplied buffers\n * @md: Pointer to mapped_device\n * @name: Buffer (size DM_NAME_LEN) for name\n * @uuid: Buffer (size DM_UUID_LEN) for uuid or empty string if uuid not defined\n */\nint dm_copy_name_and_uuid(struct mapped_device *md, char *name, char *uuid)\n{\n\tint r = 0;\n\tstruct hash_cell *hc;\n\n\tif (!md)\n\t\treturn -ENXIO;\n\n\tmutex_lock(&dm_hash_cells_mutex);\n\thc = dm_get_mdptr(md);\n\tif (!hc || hc->md != md) {\n\t\tr = -ENXIO;\n\t\tgoto out;\n\t}\n\n\tif (name)\n\t\tstrcpy(name, hc->name);\n\tif (uuid)\n\t\tstrcpy(uuid, hc->uuid ? : \"\");\n\nout:\n\tmutex_unlock(&dm_hash_cells_mutex);\n\n\treturn r;\n}\nEXPORT_SYMBOL_GPL(dm_copy_name_and_uuid);\n\n/**\n * dm_early_create - create a mapped device in early boot.\n *\n * @dmi: Contains main information of the device mapping to be created.\n * @spec_array: array of pointers to struct dm_target_spec. Describes the\n * mapping table of the device.\n * @target_params_array: array of strings with the parameters to a specific\n * target.\n *\n * Instead of having the struct dm_target_spec and the parameters for every\n * target embedded at the end of struct dm_ioctl (as performed in a normal\n * ioctl), pass them as arguments, so the caller doesn't need to serialize them.\n * The size of the spec_array and target_params_array is given by\n * @dmi->target_count.\n * This function is supposed to be called in early boot, so locking mechanisms\n * to protect against concurrent loads are not required.\n */\nint __init dm_early_create(struct dm_ioctl *dmi,\n\t\t\t   struct dm_target_spec **spec_array,\n\t\t\t   char **target_params_array)\n{\n\tint r, m = DM_ANY_MINOR;\n\tstruct dm_table *t, *old_map;\n\tstruct mapped_device *md;\n\tunsigned int i;\n\n\tif (!dmi->target_count)\n\t\treturn -EINVAL;\n\n\tr = check_name(dmi->name);\n\tif (r)\n\t\treturn r;\n\n\tif (dmi->flags & DM_PERSISTENT_DEV_FLAG)\n\t\tm = MINOR(huge_decode_dev(dmi->dev));\n\n\t/* alloc dm device */\n\tr = dm_create(m, &md);\n\tif (r)\n\t\treturn r;\n\n\t/* hash insert */\n\tr = dm_hash_insert(dmi->name, *dmi->uuid ? dmi->uuid : NULL, md);\n\tif (r)\n\t\tgoto err_destroy_dm;\n\n\t/* alloc table */\n\tr = dm_table_create(&t, get_mode(dmi), dmi->target_count, md);\n\tif (r)\n\t\tgoto err_hash_remove;\n\n\t/* add targets */\n\tfor (i = 0; i < dmi->target_count; i++) {\n\t\tr = dm_table_add_target(t, spec_array[i]->target_type,\n\t\t\t\t\t(sector_t) spec_array[i]->sector_start,\n\t\t\t\t\t(sector_t) spec_array[i]->length,\n\t\t\t\t\ttarget_params_array[i]);\n\t\tif (r) {\n\t\t\tDMWARN(\"error adding target to table\");\n\t\t\tgoto err_destroy_table;\n\t\t}\n\t}\n\n\t/* finish table */\n\tr = dm_table_complete(t);\n\tif (r)\n\t\tgoto err_destroy_table;\n\n\tmd->type = dm_table_get_type(t);\n\t/* setup md->queue to reflect md's type (may block) */\n\tr = dm_setup_md_queue(md, t);\n\tif (r) {\n\t\tDMWARN(\"unable to set up device queue for new table.\");\n\t\tgoto err_destroy_table;\n\t}\n\n\t/* Set new map */\n\tdm_suspend(md, 0);\n\told_map = dm_swap_table(md, t);\n\tif (IS_ERR(old_map)) {\n\t\tr = PTR_ERR(old_map);\n\t\tgoto err_destroy_table;\n\t}\n\tset_disk_ro(dm_disk(md), !!(dmi->flags & DM_READONLY_FLAG));\n\n\t/* resume device */\n\tr = dm_resume(md);\n\tif (r)\n\t\tgoto err_destroy_table;\n\n\tDMINFO(\"%s (%s) is ready\", md->disk->disk_name, dmi->name);\n\tdm_put(md);\n\treturn 0;\n\nerr_destroy_table:\n\tdm_table_destroy(t);\nerr_hash_remove:\n\t(void) __hash_remove(__get_name_cell(dmi->name));\n\t/* release reference from __get_name_cell */\n\tdm_put(md);\nerr_destroy_dm:\n\tdm_put(md);\n\tdm_destroy(md);\n\treturn r;\n}\n"], "filenames": ["drivers/md/dm-ioctl.c"], "buggy_code_start_loc": [532], "buggy_code_end_loc": [533], "fixing_code_start_loc": [532], "fixing_code_end_loc": [533], "type": "CWE-787", "message": "An out-of-bounds (OOB) memory write flaw was found in list_devices in drivers/md/dm-ioctl.c in the Multi-device driver module in the Linux kernel before 5.12. A bound check failure allows an attacker with special user (CAP_SYS_ADMIN) privilege to gain access to out-of-bounds memory leading to a system crash or a leak of internal kernel information. The highest threat from this vulnerability is to system availability.", "other": {"cve": {"id": "CVE-2021-31916", "sourceIdentifier": "secalert@redhat.com", "published": "2021-05-06T17:15:08.143", "lastModified": "2022-01-01T17:51:19.507", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "An out-of-bounds (OOB) memory write flaw was found in list_devices in drivers/md/dm-ioctl.c in the Multi-device driver module in the Linux kernel before 5.12. A bound check failure allows an attacker with special user (CAP_SYS_ADMIN) privilege to gain access to out-of-bounds memory leading to a system crash or a leak of internal kernel information. The highest threat from this vulnerability is to system availability."}, {"lang": "es", "value": "Se encontr\u00f3 un fallo de escritura de la memoria fuera de l\u00edmites (OOB) en la funci\u00f3n list_devices en el archivo drivers/md/dm-ioctl.c en el m\u00f3dulo de controlador Multi-device en el kernel de Linux versiones anteriores a 5.12.&#xa0;Un fallo de comprobaci\u00f3n limitada permite a un atacante con privilegios de usuario especial (CAP_SYS_ADMIN) conseguir acceso a la memoria fuera de l\u00edmites, conllevando a un bloqueo del sistema o una filtraci\u00f3n de informaci\u00f3n interna del kernel.&#xa0;La mayor amenaza de esta vulnerabilidad es la disponibilidad del sistema"}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:L/AC:L/PR:H/UI:N/S:U/C:H/I:H/A:H", "attackVector": "LOCAL", "attackComplexity": "LOW", "privilegesRequired": "HIGH", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "HIGH", "availabilityImpact": "HIGH", "baseScore": 6.7, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 0.8, "impactScore": 5.9}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:L/AC:L/Au:N/C:P/I:P/A:C", "accessVector": "LOCAL", "accessComplexity": "LOW", "authentication": "NONE", "confidentialityImpact": "PARTIAL", "integrityImpact": "PARTIAL", "availabilityImpact": "COMPLETE", "baseScore": 6.1}, "baseSeverity": "MEDIUM", "exploitabilityScore": 3.9, "impactScore": 8.5, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "secalert@redhat.com", "type": "Primary", "description": [{"lang": "en", "value": "CWE-787"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionEndExcluding": "5.12", "matchCriteriaId": "40362FFA-6C99-41DB-AC04-5B835E7DE052"}]}]}, {"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:redhat:enterprise_linux:7.0:*:*:*:*:*:*:*", "matchCriteriaId": "142AD0DD-4CF3-4D74-9442-459CE3347E3A"}, {"vulnerable": true, "criteria": "cpe:2.3:o:redhat:enterprise_linux:8.0:*:*:*:*:*:*:*", "matchCriteriaId": "F4CFF558-3C47-480D-A2F0-BABF26042943"}]}]}, {"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:debian:debian_linux:9.0:*:*:*:*:*:*:*", "matchCriteriaId": "DEECE5FC-CACF-4496-A3E7-164736409252"}]}]}], "references": [{"url": "https://bugzilla.redhat.com/show_bug.cgi?id=1946965", "source": "secalert@redhat.com", "tags": ["Issue Tracking", "Patch", "Third Party Advisory"]}, {"url": "https://github.com/torvalds/linux/commit/4edbe1d7bcffcd6269f3b5eb63f710393ff2ec7a", "source": "secalert@redhat.com", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://lists.debian.org/debian-lts-announce/2021/06/msg00019.html", "source": "secalert@redhat.com", "tags": ["Mailing List", "Third Party Advisory"]}, {"url": "https://lists.debian.org/debian-lts-announce/2021/06/msg00020.html", "source": "secalert@redhat.com", "tags": ["Mailing List", "Third Party Advisory"]}, {"url": "https://seclists.org/oss-sec/2021/q1/268", "source": "secalert@redhat.com", "tags": ["Mailing List", "Third Party Advisory"]}]}, "github_commit_url": "https://github.com/torvalds/linux/commit/4edbe1d7bcffcd6269f3b5eb63f710393ff2ec7a"}}
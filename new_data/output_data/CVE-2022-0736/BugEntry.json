{"buggy_code": ["import codecs\nimport errno\nimport gzip\nimport os\nimport posixpath\nimport shutil\nimport sys\nimport tarfile\nimport tempfile\nimport stat\n\nimport urllib.parse\nimport urllib.request\nfrom urllib.parse import unquote\nfrom urllib.request import pathname2url\n\nimport yaml\n\ntry:\n    from yaml import CSafeLoader as YamlSafeLoader, CSafeDumper as YamlSafeDumper\nexcept ImportError:\n    from yaml import SafeLoader as YamlSafeLoader, SafeDumper as YamlSafeDumper\n\nfrom mlflow.entities import FileInfo\nfrom mlflow.exceptions import MissingConfigException\nfrom mlflow.utils.rest_utils import cloud_storage_http_request, augmented_raise_for_status\n\nENCODING = \"utf-8\"\n\n\ndef is_directory(name):\n    return os.path.isdir(name)\n\n\ndef is_file(name):\n    return os.path.isfile(name)\n\n\ndef exists(name):\n    return os.path.exists(name)\n\n\ndef list_all(root, filter_func=lambda x: True, full_path=False):\n    \"\"\"\n    List all entities directly under 'dir_name' that satisfy 'filter_func'\n\n    :param root: Name of directory to start search\n    :param filter_func: function or lambda that takes path\n    :param full_path: If True will return results as full path including `root`\n\n    :return: list of all files or directories that satisfy the criteria.\n    \"\"\"\n    if not is_directory(root):\n        raise Exception(\"Invalid parent directory '%s'\" % root)\n    matches = [x for x in os.listdir(root) if filter_func(os.path.join(root, x))]\n    return [os.path.join(root, m) for m in matches] if full_path else matches\n\n\ndef list_subdirs(dir_name, full_path=False):\n    \"\"\"\n    Equivalent to UNIX command:\n      ``find $dir_name -depth 1 -type d``\n\n    :param dir_name: Name of directory to start search\n    :param full_path: If True will return results as full path including `root`\n\n    :return: list of all directories directly under 'dir_name'\n    \"\"\"\n    return list_all(dir_name, os.path.isdir, full_path)\n\n\ndef list_files(dir_name, full_path=False):\n    \"\"\"\n    Equivalent to UNIX command:\n      ``find $dir_name -depth 1 -type f``\n\n    :param dir_name: Name of directory to start search\n    :param full_path: If True will return results as full path including `root`\n\n    :return: list of all files directly under 'dir_name'\n    \"\"\"\n    return list_all(dir_name, os.path.isfile, full_path)\n\n\ndef find(root, name, full_path=False):\n    \"\"\"\n    Search for a file in a root directory. Equivalent to:\n      ``find $root -name \"$name\" -depth 1``\n\n    :param root: Name of root directory for find\n    :param name: Name of file or directory to find directly under root directory\n    :param full_path: If True will return results as full path including `root`\n\n    :return: list of matching files or directories\n    \"\"\"\n    path_name = os.path.join(root, name)\n    return list_all(root, lambda x: x == path_name, full_path)\n\n\ndef mkdir(root, name=None):\n    \"\"\"\n    Make directory with name \"root/name\", or just \"root\" if name is None.\n\n    :param root: Name of parent directory\n    :param name: Optional name of leaf directory\n\n    :return: Path to created directory\n    \"\"\"\n    target = os.path.join(root, name) if name is not None else root\n    try:\n        os.makedirs(target)\n    except OSError as e:\n        if e.errno != errno.EEXIST or not os.path.isdir(target):\n            raise e\n    return target\n\n\ndef make_containing_dirs(path):\n    \"\"\"\n    Create the base directory for a given file path if it does not exist; also creates parent\n    directories.\n    \"\"\"\n    dir_name = os.path.dirname(path)\n    if not os.path.exists(dir_name):\n        os.makedirs(dir_name)\n\n\ndef write_yaml(root, file_name, data, overwrite=False, sort_keys=True):\n    \"\"\"\n    Write dictionary data in yaml format.\n\n    :param root: Directory name.\n    :param file_name: Desired file name. Will automatically add .yaml extension if not given\n    :param data: data to be dumped as yaml format\n    :param overwrite: If True, will overwrite existing files\n    \"\"\"\n    if not exists(root):\n        raise MissingConfigException(\"Parent directory '%s' does not exist.\" % root)\n\n    file_path = os.path.join(root, file_name)\n    yaml_file_name = file_path if file_path.endswith(\".yaml\") else file_path + \".yaml\"\n\n    if exists(yaml_file_name) and not overwrite:\n        raise Exception(\"Yaml file '%s' exists as '%s\" % (file_path, yaml_file_name))\n\n    try:\n        with codecs.open(yaml_file_name, mode=\"w\", encoding=ENCODING) as yaml_file:\n            yaml.dump(\n                data,\n                yaml_file,\n                default_flow_style=False,\n                allow_unicode=True,\n                sort_keys=sort_keys,\n                Dumper=YamlSafeDumper,\n            )\n    except Exception as e:\n        raise e\n\n\ndef read_yaml(root, file_name):\n    \"\"\"\n    Read data from yaml file and return as dictionary\n\n    :param root: Directory name\n    :param file_name: File name. Expects to have '.yaml' extension\n\n    :return: Data in yaml file as dictionary\n    \"\"\"\n    if not exists(root):\n        raise MissingConfigException(\n            \"Cannot read '%s'. Parent dir '%s' does not exist.\" % (file_name, root)\n        )\n\n    file_path = os.path.join(root, file_name)\n    if not exists(file_path):\n        raise MissingConfigException(\"Yaml file '%s' does not exist.\" % file_path)\n    try:\n        with codecs.open(file_path, mode=\"r\", encoding=ENCODING) as yaml_file:\n            return yaml.load(yaml_file, Loader=YamlSafeLoader)\n    except Exception as e:\n        raise e\n\n\nclass TempDir:\n    def __init__(self, chdr=False, remove_on_exit=True):\n        self._dir = None\n        self._path = None\n        self._chdr = chdr\n        self._remove = remove_on_exit\n\n    def __enter__(self):\n        self._path = os.path.abspath(tempfile.mkdtemp())\n        assert os.path.exists(self._path)\n        if self._chdr:\n            self._dir = os.path.abspath(os.getcwd())\n            os.chdir(self._path)\n        return self\n\n    def __exit__(self, tp, val, traceback):\n        if self._chdr and self._dir:\n            os.chdir(self._dir)\n            self._dir = None\n        if self._remove and os.path.exists(self._path):\n            shutil.rmtree(self._path)\n\n        assert not self._remove or not os.path.exists(self._path)\n        assert os.path.exists(os.getcwd())\n\n    def path(self, *path):\n        return os.path.join(\"./\", *path) if self._chdr else os.path.join(self._path, *path)\n\n\ndef read_file_lines(parent_path, file_name):\n    \"\"\"\n    Return the contents of the file as an array where each element is a separate line.\n\n    :param parent_path: Full path to the directory that contains the file.\n    :param file_name: Leaf file name.\n\n    :return: All lines in the file as an array.\n    \"\"\"\n    file_path = os.path.join(parent_path, file_name)\n    with codecs.open(file_path, mode=\"r\", encoding=ENCODING) as f:\n        return f.readlines()\n\n\ndef read_file(parent_path, file_name):\n    \"\"\"\n    Return the contents of the file.\n\n    :param parent_path: Full path to the directory that contains the file.\n    :param file_name: Leaf file name.\n\n    :return: The contents of the file.\n    \"\"\"\n    file_path = os.path.join(parent_path, file_name)\n    with codecs.open(file_path, mode=\"r\", encoding=ENCODING) as f:\n        return f.read()\n\n\ndef get_file_info(path, rel_path):\n    \"\"\"\n    Returns file meta data : location, size, ... etc\n\n    :param path: Path to artifact\n\n    :return: `FileInfo` object\n    \"\"\"\n    if is_directory(path):\n        return FileInfo(rel_path, True, None)\n    else:\n        return FileInfo(rel_path, False, os.path.getsize(path))\n\n\ndef get_relative_path(root_path, target_path):\n    \"\"\"\n    Remove root path common prefix and return part of `path` relative to `root_path`.\n\n    :param root_path: Root path\n    :param target_path: Desired path for common prefix removal\n\n    :return: Path relative to root_path\n    \"\"\"\n    if len(root_path) > len(target_path):\n        raise Exception(\"Root path '%s' longer than target path '%s'\" % (root_path, target_path))\n    common_prefix = os.path.commonprefix([root_path, target_path])\n    return os.path.relpath(target_path, common_prefix)\n\n\ndef mv(target, new_parent):\n    shutil.move(target, new_parent)\n\n\ndef write_to(filename, data):\n    with codecs.open(filename, mode=\"w\", encoding=ENCODING) as handle:\n        handle.write(data)\n\n\ndef append_to(filename, data):\n    with open(filename, \"a\") as handle:\n        handle.write(data)\n\n\ndef make_tarfile(output_filename, source_dir, archive_name, custom_filter=None):\n    # Helper for filtering out modification timestamps\n    def _filter_timestamps(tar_info):\n        tar_info.mtime = 0\n        return tar_info if custom_filter is None else custom_filter(tar_info)\n\n    unzipped_filename = tempfile.mktemp()\n    try:\n        with tarfile.open(unzipped_filename, \"w\") as tar:\n            tar.add(source_dir, arcname=archive_name, filter=_filter_timestamps)\n        # When gzipping the tar, don't include the tar's filename or modification time in the\n        # zipped archive (see https://docs.python.org/3/library/gzip.html#gzip.GzipFile)\n        with gzip.GzipFile(\n            filename=\"\", fileobj=open(output_filename, \"wb\"), mode=\"wb\", mtime=0\n        ) as gzipped_tar, open(unzipped_filename, \"rb\") as tar:\n            gzipped_tar.write(tar.read())\n    finally:\n        os.remove(unzipped_filename)\n\n\ndef _copy_project(src_path, dst_path=\"\"):\n    \"\"\"\n    Internal function used to copy MLflow project during development.\n\n    Copies the content of the whole directory tree except patterns defined in .dockerignore.\n    The MLflow is assumed to be accessible as a local directory in this case.\n\n\n    :param dst_path: MLflow will be copied here\n    :return: name of the MLflow project directory\n    \"\"\"\n\n    def _docker_ignore(mlflow_root):\n        docker_ignore = os.path.join(mlflow_root, \".dockerignore\")\n        patterns = []\n        if os.path.exists(docker_ignore):\n            with open(docker_ignore, \"r\") as f:\n                patterns = [x.strip() for x in f.readlines()]\n\n        def ignore(_, names):\n            import fnmatch\n\n            res = set()\n            for p in patterns:\n                res.update(set(fnmatch.filter(names, p)))\n            return list(res)\n\n        return ignore if patterns else None\n\n    mlflow_dir = \"mlflow-project\"\n    # check if we have project root\n    assert os.path.isfile(os.path.join(src_path, \"setup.py\")), \"file not found \" + str(\n        os.path.abspath(os.path.join(src_path, \"setup.py\"))\n    )\n    shutil.copytree(src_path, os.path.join(dst_path, mlflow_dir), ignore=_docker_ignore(src_path))\n    return mlflow_dir\n\n\ndef _copy_file_or_tree(src, dst, dst_dir=None):\n    \"\"\"\n    :return: The path to the copied artifacts, relative to `dst`\n    \"\"\"\n    dst_subpath = os.path.basename(os.path.abspath(src))\n    if dst_dir is not None:\n        dst_subpath = os.path.join(dst_dir, dst_subpath)\n    dst_path = os.path.join(dst, dst_subpath)\n    if os.path.isfile(src):\n        dst_dirpath = os.path.dirname(dst_path)\n        if not os.path.exists(dst_dirpath):\n            os.makedirs(dst_dirpath)\n        shutil.copy(src=src, dst=dst_path)\n    else:\n        shutil.copytree(src=src, dst=dst_path)\n    return dst_subpath\n\n\ndef _get_local_project_dir_size(project_path):\n    \"\"\"\n    Internal function for reporting the size of a local project directory before copying to\n    destination for cli logging reporting to stdout.\n    :param project_path: local path of the project directory\n    :return: directory file sizes in KB, rounded to single decimal point for legibility\n    \"\"\"\n\n    total_size = 0\n    for root, _, files in os.walk(project_path):\n        for f in files:\n            path = os.path.join(root, f)\n            total_size += os.path.getsize(path)\n    return round(total_size / 1024.0, 1)\n\n\ndef _get_local_file_size(file):\n    \"\"\"\n    Get the size of a local file in KB\n    \"\"\"\n    return round(os.path.getsize(file) / 1024.0, 1)\n\n\ndef get_parent_dir(path):\n    return os.path.abspath(os.path.join(path, os.pardir))\n\n\ndef relative_path_to_artifact_path(path):\n    if os.path == posixpath:\n        return path\n    if os.path.abspath(path) == path:\n        raise Exception(\"This method only works with relative paths.\")\n    return unquote(pathname2url(path))\n\n\ndef path_to_local_file_uri(path):\n    \"\"\"\n    Convert local filesystem path to local file uri.\n    \"\"\"\n    path = pathname2url(path)\n    if path == posixpath.abspath(path):\n        return \"file://{path}\".format(path=path)\n    else:\n        return \"file:{path}\".format(path=path)\n\n\ndef path_to_local_sqlite_uri(path):\n    \"\"\"\n    Convert local filesystem path to sqlite uri.\n    \"\"\"\n    path = posixpath.abspath(pathname2url(os.path.abspath(path)))\n    prefix = \"sqlite://\" if sys.platform == \"win32\" else \"sqlite:///\"\n    return prefix + path\n\n\ndef local_file_uri_to_path(uri):\n    \"\"\"\n    Convert URI to local filesystem path.\n    No-op if the uri does not have the expected scheme.\n    \"\"\"\n    path = urllib.parse.urlparse(uri).path if uri.startswith(\"file:\") else uri\n    return urllib.request.url2pathname(path)\n\n\ndef get_local_path_or_none(path_or_uri):\n    \"\"\"Check if the argument is a local path (no scheme or file:///) and return local path if true,\n    None otherwise.\n    \"\"\"\n    parsed_uri = urllib.parse.urlparse(path_or_uri)\n    if len(parsed_uri.scheme) == 0 or parsed_uri.scheme == \"file\" and len(parsed_uri.netloc) == 0:\n        return local_file_uri_to_path(path_or_uri)\n    else:\n        return None\n\n\ndef yield_file_in_chunks(file, chunk_size=100000000):\n    \"\"\"\n    Generator to chunk-ify the inputted file based on the chunk-size.\n    \"\"\"\n    with open(file, \"rb\") as f:\n        while True:\n            chunk = f.read(chunk_size)\n            if chunk:\n                yield chunk\n            else:\n                break\n\n\ndef download_file_using_http_uri(http_uri, download_path, chunk_size=100000000):\n    \"\"\"\n    Downloads a file specified using the `http_uri` to a local `download_path`. This function\n    uses a `chunk_size` to ensure an OOM error is not raised a large file is downloaded.\n\n    Note : This function is meant to download files using presigned urls from various cloud\n            providers.\n    \"\"\"\n    with cloud_storage_http_request(\"get\", http_uri, stream=True) as response:\n        augmented_raise_for_status(response)\n        with open(download_path, \"wb\") as output_file:\n            for chunk in response.iter_content(chunk_size=chunk_size):\n                if not chunk:\n                    break\n                output_file.write(chunk)\n\n\ndef _handle_readonly_on_windows(func, path, exc_info):\n    \"\"\"\n    This function should not be called directly but should be passed to `onerror` of\n    `shutil.rmtree` in order to reattempt the removal of a read-only file after making\n    it writable on Windows.\n\n    References:\n    - https://bugs.python.org/issue19643\n    - https://bugs.python.org/issue43657\n    \"\"\"\n    exc_type, exc_value = exc_info[:2]\n    should_reattempt = (\n        os.name == \"nt\"\n        and func in (os.unlink, os.rmdir)\n        and issubclass(exc_type, PermissionError)\n        and exc_value.winerror == 5\n    )\n    if not should_reattempt:\n        raise exc_value\n    os.chmod(path, stat.S_IWRITE)\n    func(path)\n"], "fixing_code": ["import codecs\nimport errno\nimport gzip\nimport os\nimport posixpath\nimport shutil\nimport sys\nimport tarfile\nimport tempfile\nimport stat\n\nimport urllib.parse\nimport urllib.request\nfrom urllib.parse import unquote\nfrom urllib.request import pathname2url\n\nimport yaml\n\ntry:\n    from yaml import CSafeLoader as YamlSafeLoader, CSafeDumper as YamlSafeDumper\nexcept ImportError:\n    from yaml import SafeLoader as YamlSafeLoader, SafeDumper as YamlSafeDumper\n\nfrom mlflow.entities import FileInfo\nfrom mlflow.exceptions import MissingConfigException\nfrom mlflow.utils.rest_utils import cloud_storage_http_request, augmented_raise_for_status\n\nENCODING = \"utf-8\"\n\n\ndef is_directory(name):\n    return os.path.isdir(name)\n\n\ndef is_file(name):\n    return os.path.isfile(name)\n\n\ndef exists(name):\n    return os.path.exists(name)\n\n\ndef list_all(root, filter_func=lambda x: True, full_path=False):\n    \"\"\"\n    List all entities directly under 'dir_name' that satisfy 'filter_func'\n\n    :param root: Name of directory to start search\n    :param filter_func: function or lambda that takes path\n    :param full_path: If True will return results as full path including `root`\n\n    :return: list of all files or directories that satisfy the criteria.\n    \"\"\"\n    if not is_directory(root):\n        raise Exception(\"Invalid parent directory '%s'\" % root)\n    matches = [x for x in os.listdir(root) if filter_func(os.path.join(root, x))]\n    return [os.path.join(root, m) for m in matches] if full_path else matches\n\n\ndef list_subdirs(dir_name, full_path=False):\n    \"\"\"\n    Equivalent to UNIX command:\n      ``find $dir_name -depth 1 -type d``\n\n    :param dir_name: Name of directory to start search\n    :param full_path: If True will return results as full path including `root`\n\n    :return: list of all directories directly under 'dir_name'\n    \"\"\"\n    return list_all(dir_name, os.path.isdir, full_path)\n\n\ndef list_files(dir_name, full_path=False):\n    \"\"\"\n    Equivalent to UNIX command:\n      ``find $dir_name -depth 1 -type f``\n\n    :param dir_name: Name of directory to start search\n    :param full_path: If True will return results as full path including `root`\n\n    :return: list of all files directly under 'dir_name'\n    \"\"\"\n    return list_all(dir_name, os.path.isfile, full_path)\n\n\ndef find(root, name, full_path=False):\n    \"\"\"\n    Search for a file in a root directory. Equivalent to:\n      ``find $root -name \"$name\" -depth 1``\n\n    :param root: Name of root directory for find\n    :param name: Name of file or directory to find directly under root directory\n    :param full_path: If True will return results as full path including `root`\n\n    :return: list of matching files or directories\n    \"\"\"\n    path_name = os.path.join(root, name)\n    return list_all(root, lambda x: x == path_name, full_path)\n\n\ndef mkdir(root, name=None):\n    \"\"\"\n    Make directory with name \"root/name\", or just \"root\" if name is None.\n\n    :param root: Name of parent directory\n    :param name: Optional name of leaf directory\n\n    :return: Path to created directory\n    \"\"\"\n    target = os.path.join(root, name) if name is not None else root\n    try:\n        os.makedirs(target)\n    except OSError as e:\n        if e.errno != errno.EEXIST or not os.path.isdir(target):\n            raise e\n    return target\n\n\ndef make_containing_dirs(path):\n    \"\"\"\n    Create the base directory for a given file path if it does not exist; also creates parent\n    directories.\n    \"\"\"\n    dir_name = os.path.dirname(path)\n    if not os.path.exists(dir_name):\n        os.makedirs(dir_name)\n\n\ndef write_yaml(root, file_name, data, overwrite=False, sort_keys=True):\n    \"\"\"\n    Write dictionary data in yaml format.\n\n    :param root: Directory name.\n    :param file_name: Desired file name. Will automatically add .yaml extension if not given\n    :param data: data to be dumped as yaml format\n    :param overwrite: If True, will overwrite existing files\n    \"\"\"\n    if not exists(root):\n        raise MissingConfigException(\"Parent directory '%s' does not exist.\" % root)\n\n    file_path = os.path.join(root, file_name)\n    yaml_file_name = file_path if file_path.endswith(\".yaml\") else file_path + \".yaml\"\n\n    if exists(yaml_file_name) and not overwrite:\n        raise Exception(\"Yaml file '%s' exists as '%s\" % (file_path, yaml_file_name))\n\n    try:\n        with codecs.open(yaml_file_name, mode=\"w\", encoding=ENCODING) as yaml_file:\n            yaml.dump(\n                data,\n                yaml_file,\n                default_flow_style=False,\n                allow_unicode=True,\n                sort_keys=sort_keys,\n                Dumper=YamlSafeDumper,\n            )\n    except Exception as e:\n        raise e\n\n\ndef read_yaml(root, file_name):\n    \"\"\"\n    Read data from yaml file and return as dictionary\n\n    :param root: Directory name\n    :param file_name: File name. Expects to have '.yaml' extension\n\n    :return: Data in yaml file as dictionary\n    \"\"\"\n    if not exists(root):\n        raise MissingConfigException(\n            \"Cannot read '%s'. Parent dir '%s' does not exist.\" % (file_name, root)\n        )\n\n    file_path = os.path.join(root, file_name)\n    if not exists(file_path):\n        raise MissingConfigException(\"Yaml file '%s' does not exist.\" % file_path)\n    try:\n        with codecs.open(file_path, mode=\"r\", encoding=ENCODING) as yaml_file:\n            return yaml.load(yaml_file, Loader=YamlSafeLoader)\n    except Exception as e:\n        raise e\n\n\nclass TempDir:\n    def __init__(self, chdr=False, remove_on_exit=True):\n        self._dir = None\n        self._path = None\n        self._chdr = chdr\n        self._remove = remove_on_exit\n\n    def __enter__(self):\n        self._path = os.path.abspath(tempfile.mkdtemp())\n        assert os.path.exists(self._path)\n        if self._chdr:\n            self._dir = os.path.abspath(os.getcwd())\n            os.chdir(self._path)\n        return self\n\n    def __exit__(self, tp, val, traceback):\n        if self._chdr and self._dir:\n            os.chdir(self._dir)\n            self._dir = None\n        if self._remove and os.path.exists(self._path):\n            shutil.rmtree(self._path)\n\n        assert not self._remove or not os.path.exists(self._path)\n        assert os.path.exists(os.getcwd())\n\n    def path(self, *path):\n        return os.path.join(\"./\", *path) if self._chdr else os.path.join(self._path, *path)\n\n\ndef read_file_lines(parent_path, file_name):\n    \"\"\"\n    Return the contents of the file as an array where each element is a separate line.\n\n    :param parent_path: Full path to the directory that contains the file.\n    :param file_name: Leaf file name.\n\n    :return: All lines in the file as an array.\n    \"\"\"\n    file_path = os.path.join(parent_path, file_name)\n    with codecs.open(file_path, mode=\"r\", encoding=ENCODING) as f:\n        return f.readlines()\n\n\ndef read_file(parent_path, file_name):\n    \"\"\"\n    Return the contents of the file.\n\n    :param parent_path: Full path to the directory that contains the file.\n    :param file_name: Leaf file name.\n\n    :return: The contents of the file.\n    \"\"\"\n    file_path = os.path.join(parent_path, file_name)\n    with codecs.open(file_path, mode=\"r\", encoding=ENCODING) as f:\n        return f.read()\n\n\ndef get_file_info(path, rel_path):\n    \"\"\"\n    Returns file meta data : location, size, ... etc\n\n    :param path: Path to artifact\n\n    :return: `FileInfo` object\n    \"\"\"\n    if is_directory(path):\n        return FileInfo(rel_path, True, None)\n    else:\n        return FileInfo(rel_path, False, os.path.getsize(path))\n\n\ndef get_relative_path(root_path, target_path):\n    \"\"\"\n    Remove root path common prefix and return part of `path` relative to `root_path`.\n\n    :param root_path: Root path\n    :param target_path: Desired path for common prefix removal\n\n    :return: Path relative to root_path\n    \"\"\"\n    if len(root_path) > len(target_path):\n        raise Exception(\"Root path '%s' longer than target path '%s'\" % (root_path, target_path))\n    common_prefix = os.path.commonprefix([root_path, target_path])\n    return os.path.relpath(target_path, common_prefix)\n\n\ndef mv(target, new_parent):\n    shutil.move(target, new_parent)\n\n\ndef write_to(filename, data):\n    with codecs.open(filename, mode=\"w\", encoding=ENCODING) as handle:\n        handle.write(data)\n\n\ndef append_to(filename, data):\n    with open(filename, \"a\") as handle:\n        handle.write(data)\n\n\ndef make_tarfile(output_filename, source_dir, archive_name, custom_filter=None):\n    # Helper for filtering out modification timestamps\n    def _filter_timestamps(tar_info):\n        tar_info.mtime = 0\n        return tar_info if custom_filter is None else custom_filter(tar_info)\n\n    unzipped_file_handle, unzipped_filename = tempfile.mkstemp()\n    try:\n        with tarfile.open(unzipped_filename, \"w\") as tar:\n            tar.add(source_dir, arcname=archive_name, filter=_filter_timestamps)\n        # When gzipping the tar, don't include the tar's filename or modification time in the\n        # zipped archive (see https://docs.python.org/3/library/gzip.html#gzip.GzipFile)\n        with gzip.GzipFile(\n            filename=\"\", fileobj=open(output_filename, \"wb\"), mode=\"wb\", mtime=0\n        ) as gzipped_tar, open(unzipped_filename, \"rb\") as tar:\n            gzipped_tar.write(tar.read())\n    finally:\n        os.close(unzipped_file_handle)\n\n\ndef _copy_project(src_path, dst_path=\"\"):\n    \"\"\"\n    Internal function used to copy MLflow project during development.\n\n    Copies the content of the whole directory tree except patterns defined in .dockerignore.\n    The MLflow is assumed to be accessible as a local directory in this case.\n\n\n    :param dst_path: MLflow will be copied here\n    :return: name of the MLflow project directory\n    \"\"\"\n\n    def _docker_ignore(mlflow_root):\n        docker_ignore = os.path.join(mlflow_root, \".dockerignore\")\n        patterns = []\n        if os.path.exists(docker_ignore):\n            with open(docker_ignore, \"r\") as f:\n                patterns = [x.strip() for x in f.readlines()]\n\n        def ignore(_, names):\n            import fnmatch\n\n            res = set()\n            for p in patterns:\n                res.update(set(fnmatch.filter(names, p)))\n            return list(res)\n\n        return ignore if patterns else None\n\n    mlflow_dir = \"mlflow-project\"\n    # check if we have project root\n    assert os.path.isfile(os.path.join(src_path, \"setup.py\")), \"file not found \" + str(\n        os.path.abspath(os.path.join(src_path, \"setup.py\"))\n    )\n    shutil.copytree(src_path, os.path.join(dst_path, mlflow_dir), ignore=_docker_ignore(src_path))\n    return mlflow_dir\n\n\ndef _copy_file_or_tree(src, dst, dst_dir=None):\n    \"\"\"\n    :return: The path to the copied artifacts, relative to `dst`\n    \"\"\"\n    dst_subpath = os.path.basename(os.path.abspath(src))\n    if dst_dir is not None:\n        dst_subpath = os.path.join(dst_dir, dst_subpath)\n    dst_path = os.path.join(dst, dst_subpath)\n    if os.path.isfile(src):\n        dst_dirpath = os.path.dirname(dst_path)\n        if not os.path.exists(dst_dirpath):\n            os.makedirs(dst_dirpath)\n        shutil.copy(src=src, dst=dst_path)\n    else:\n        shutil.copytree(src=src, dst=dst_path)\n    return dst_subpath\n\n\ndef _get_local_project_dir_size(project_path):\n    \"\"\"\n    Internal function for reporting the size of a local project directory before copying to\n    destination for cli logging reporting to stdout.\n    :param project_path: local path of the project directory\n    :return: directory file sizes in KB, rounded to single decimal point for legibility\n    \"\"\"\n\n    total_size = 0\n    for root, _, files in os.walk(project_path):\n        for f in files:\n            path = os.path.join(root, f)\n            total_size += os.path.getsize(path)\n    return round(total_size / 1024.0, 1)\n\n\ndef _get_local_file_size(file):\n    \"\"\"\n    Get the size of a local file in KB\n    \"\"\"\n    return round(os.path.getsize(file) / 1024.0, 1)\n\n\ndef get_parent_dir(path):\n    return os.path.abspath(os.path.join(path, os.pardir))\n\n\ndef relative_path_to_artifact_path(path):\n    if os.path == posixpath:\n        return path\n    if os.path.abspath(path) == path:\n        raise Exception(\"This method only works with relative paths.\")\n    return unquote(pathname2url(path))\n\n\ndef path_to_local_file_uri(path):\n    \"\"\"\n    Convert local filesystem path to local file uri.\n    \"\"\"\n    path = pathname2url(path)\n    if path == posixpath.abspath(path):\n        return \"file://{path}\".format(path=path)\n    else:\n        return \"file:{path}\".format(path=path)\n\n\ndef path_to_local_sqlite_uri(path):\n    \"\"\"\n    Convert local filesystem path to sqlite uri.\n    \"\"\"\n    path = posixpath.abspath(pathname2url(os.path.abspath(path)))\n    prefix = \"sqlite://\" if sys.platform == \"win32\" else \"sqlite:///\"\n    return prefix + path\n\n\ndef local_file_uri_to_path(uri):\n    \"\"\"\n    Convert URI to local filesystem path.\n    No-op if the uri does not have the expected scheme.\n    \"\"\"\n    path = urllib.parse.urlparse(uri).path if uri.startswith(\"file:\") else uri\n    return urllib.request.url2pathname(path)\n\n\ndef get_local_path_or_none(path_or_uri):\n    \"\"\"Check if the argument is a local path (no scheme or file:///) and return local path if true,\n    None otherwise.\n    \"\"\"\n    parsed_uri = urllib.parse.urlparse(path_or_uri)\n    if len(parsed_uri.scheme) == 0 or parsed_uri.scheme == \"file\" and len(parsed_uri.netloc) == 0:\n        return local_file_uri_to_path(path_or_uri)\n    else:\n        return None\n\n\ndef yield_file_in_chunks(file, chunk_size=100000000):\n    \"\"\"\n    Generator to chunk-ify the inputted file based on the chunk-size.\n    \"\"\"\n    with open(file, \"rb\") as f:\n        while True:\n            chunk = f.read(chunk_size)\n            if chunk:\n                yield chunk\n            else:\n                break\n\n\ndef download_file_using_http_uri(http_uri, download_path, chunk_size=100000000):\n    \"\"\"\n    Downloads a file specified using the `http_uri` to a local `download_path`. This function\n    uses a `chunk_size` to ensure an OOM error is not raised a large file is downloaded.\n\n    Note : This function is meant to download files using presigned urls from various cloud\n            providers.\n    \"\"\"\n    with cloud_storage_http_request(\"get\", http_uri, stream=True) as response:\n        augmented_raise_for_status(response)\n        with open(download_path, \"wb\") as output_file:\n            for chunk in response.iter_content(chunk_size=chunk_size):\n                if not chunk:\n                    break\n                output_file.write(chunk)\n\n\ndef _handle_readonly_on_windows(func, path, exc_info):\n    \"\"\"\n    This function should not be called directly but should be passed to `onerror` of\n    `shutil.rmtree` in order to reattempt the removal of a read-only file after making\n    it writable on Windows.\n\n    References:\n    - https://bugs.python.org/issue19643\n    - https://bugs.python.org/issue43657\n    \"\"\"\n    exc_type, exc_value = exc_info[:2]\n    should_reattempt = (\n        os.name == \"nt\"\n        and func in (os.unlink, os.rmdir)\n        and issubclass(exc_type, PermissionError)\n        and exc_value.winerror == 5\n    )\n    if not should_reattempt:\n        raise exc_value\n    os.chmod(path, stat.S_IWRITE)\n    func(path)\n"], "filenames": ["mlflow/utils/file_utils.py"], "buggy_code_start_loc": [290], "buggy_code_end_loc": [302], "fixing_code_start_loc": [290], "fixing_code_end_loc": [302], "type": "CWE-668", "message": "Insecure Temporary File in GitHub repository mlflow/mlflow prior to 1.23.1.", "other": {"cve": {"id": "CVE-2022-0736", "sourceIdentifier": "security@huntr.dev", "published": "2022-02-23T09:15:14.420", "lastModified": "2022-03-02T02:58:33.750", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "Insecure Temporary File in GitHub repository mlflow/mlflow prior to 1.23.1."}, {"lang": "es", "value": "Un Archivo Temporal no Seguro en el repositorio de GitHub mlflow/mlflow versiones anteriores a 1.23.1"}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 7.5, "baseSeverity": "HIGH"}, "exploitabilityScore": 3.9, "impactScore": 3.6}], "cvssMetricV30": [{"source": "security@huntr.dev", "type": "Secondary", "cvssData": {"version": "3.0", "vectorString": "CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:L/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "LOW", "availabilityImpact": "HIGH", "baseScore": 8.2, "baseSeverity": "HIGH"}, "exploitabilityScore": 3.9, "impactScore": 4.2}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:N/AC:L/Au:N/C:N/I:N/A:P", "accessVector": "NETWORK", "accessComplexity": "LOW", "authentication": "NONE", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "PARTIAL", "baseScore": 5.0}, "baseSeverity": "MEDIUM", "exploitabilityScore": 10.0, "impactScore": 2.9, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-668"}]}, {"source": "security@huntr.dev", "type": "Secondary", "description": [{"lang": "en", "value": "CWE-377"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:lfprojects:mlflow:*:*:*:*:*:*:*:*", "versionEndExcluding": "1.23.1", "matchCriteriaId": "87034A10-6009-4B5C-85A6-C43CE4C745A2"}]}]}], "references": [{"url": "https://github.com/mlflow/mlflow/commit/61984e6843d2e59235d82a580c529920cd8f3711", "source": "security@huntr.dev", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://huntr.dev/bounties/e5384764-c583-4dec-a1d8-4697f4e12f75", "source": "security@huntr.dev", "tags": ["Exploit", "Patch", "Third Party Advisory"]}]}, "github_commit_url": "https://github.com/mlflow/mlflow/commit/61984e6843d2e59235d82a580c529920cd8f3711"}}
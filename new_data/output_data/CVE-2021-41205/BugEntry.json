{"buggy_code": ["/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n\n#include <algorithm>\n#include <ostream>\n\n#include \"tensorflow/core/framework/common_shape_fns.h\"\n#include \"tensorflow/core/framework/kernel_shape_util.h\"\n#include \"tensorflow/core/framework/op.h\"\n#include \"tensorflow/core/framework/shape_inference.h\"\n#include \"tensorflow/core/framework/tensor.pb.h\"\n#include \"tensorflow/core/framework/types.h\"\n#include \"tensorflow/core/framework/types.pb.h\"\n#include \"tensorflow/core/lib/core/errors.h\"\n#include \"tensorflow/core/util/mirror_pad_mode.h\"\n#include \"tensorflow/core/util/padding.h\"\n#include \"tensorflow/core/util/strided_slice_op.h\"\n#include \"tensorflow/core/util/tensor_format.h\"\n\nnamespace tensorflow {\n\nusing shape_inference::DimensionHandle;\nusing shape_inference::InferenceContext;\nusing shape_inference::ShapeHandle;\nusing shape_inference::UnchangedShape;\n\nnamespace {\n\nStatus GetAxisForPackAndUnpack(InferenceContext* c, int32_t rank_after_pack,\n                               int32* axis) {\n  TF_RETURN_IF_ERROR(c->GetAttr(\"axis\", axis));\n  if (*axis < -1 * rank_after_pack || *axis >= rank_after_pack) {\n    return errors::InvalidArgument(\"Invalid axis: \", *axis, \"; must be in [\",\n                                   -1 * rank_after_pack, \",\", rank_after_pack,\n                                   \")\");\n  }\n  if (*axis < 0) *axis = (rank_after_pack + *axis);\n  return Status::OK();\n}\n\ntemplate <typename T>\nstd::vector<int64_t> AsInt64(const Tensor* tensor, int64_t num_elements) {\n  std::vector<int64_t> ret(num_elements);\n  auto data = tensor->vec<T>();\n  for (int64_t i = 0; i < num_elements; ++i) {\n    ret[i] = data(i);\n  }\n  return ret;\n}\n\ntemplate <typename T>\nStatus PadKnown(InferenceContext* c, ShapeHandle input,\n                const Tensor* paddings_t, int64_t num_dims) {\n  // paddings_t is known.\n  std::vector<DimensionHandle> dims(num_dims);\n  auto paddings_data = paddings_t->matrix<T>();\n  for (int64_t i = 0; i < num_dims; ++i) {\n    const T pad0 = paddings_data(i, 0);\n    const T pad1 = paddings_data(i, 1);\n    if (pad0 < 0 || pad1 < 0) {\n      return errors::InvalidArgument(\"Paddings must be non-negative\");\n    }\n    TF_RETURN_IF_ERROR(c->Add(c->Dim(input, i), pad0 + pad1, &dims[i]));\n  }\n  c->set_output(0, c->MakeShape(dims));\n  return Status::OK();\n}\n\nStatus PadShapeFn(InferenceContext* c) {\n  // Paddings is a matrix of [input_rank, 2].\n  ShapeHandle paddings;\n  TF_RETURN_IF_ERROR(c->WithRank(c->input(1), 2, &paddings));\n  DimensionHandle unused;\n  TF_RETURN_IF_ERROR(c->WithValue(c->Dim(paddings, 1), 2, &unused));\n\n  // n_dim and input.rank are equivalent.\n  ShapeHandle input = c->input(0);\n  DimensionHandle n_dim = c->Dim(paddings, 0);\n  if (c->ValueKnown(n_dim)) {\n    TF_RETURN_IF_ERROR(c->WithRank(input, c->Value(n_dim), &input));\n  } else if (c->RankKnown(input)) {\n    TF_RETURN_IF_ERROR(c->WithValue(n_dim, c->Rank(input), &n_dim));\n  }\n\n  const Tensor* paddings_t = c->input_tensor(1);\n\n  // paddings_t is unknown\n  if (paddings_t == nullptr) {\n    if (c->ValueKnown(n_dim)) {\n      // Make output with n_dim unknown dims.\n      c->set_output(0, c->UnknownShapeOfRank(c->Value(n_dim)));\n    } else {\n      c->set_output(0, c->UnknownShape());\n    }\n    return Status::OK();\n  }\n\n  const int64_t num_dims = paddings_t->shape().dim_size(0);\n  TF_RETURN_IF_ERROR(c->WithRank(input, num_dims, &input));\n  TF_RETURN_IF_ERROR(c->WithValue(n_dim, num_dims, &n_dim));\n\n  if (paddings_t->dtype() == DT_INT32) {\n    return PadKnown<int32>(c, input, paddings_t, num_dims);\n  } else {\n    return PadKnown<int64_t>(c, input, paddings_t, num_dims);\n  }\n}\n\nStatus TransposeShapeFn(InferenceContext* c) {\n  ShapeHandle input = c->input(0);\n  ShapeHandle perm_shape = c->input(1);\n  const Tensor* perm = c->input_tensor(1);\n  DimensionHandle perm_elems = c->NumElements(perm_shape);\n  // If we don't have rank information on the input or value information on\n  // perm we can't return any shape information, otherwise we have enough\n  // information to at least find the rank of the output.\n  if (!c->RankKnown(input) && !c->ValueKnown(perm_elems) && perm == nullptr) {\n    c->set_output(0, c->UnknownShape());\n    return Status::OK();\n  }\n\n  // Find our value of the rank.\n  int64_t rank;\n  if (c->RankKnown(input)) {\n    rank = c->Rank(input);\n  } else if (c->ValueKnown(perm_elems)) {\n    rank = c->Value(perm_elems);\n  } else {\n    rank = perm->NumElements();\n  }\n  if (!c->RankKnown(input) && rank < 2) {\n    // A permutation array containing a single element is ambiguous. It could\n    // indicate either a scalar or a 1-dimensional array, both of which the\n    // transpose op returns unchanged.\n    c->set_output(0, input);\n    return Status::OK();\n  }\n\n  std::vector<DimensionHandle> dims;\n  dims.resize(rank);\n  TF_RETURN_IF_ERROR(c->WithRank(input, rank, &input));\n  // Ensure that perm is a vector and has rank elements.\n  TF_RETURN_IF_ERROR(c->WithRank(perm_shape, 1, &perm_shape));\n  TF_RETURN_IF_ERROR(c->WithValue(perm_elems, rank, &perm_elems));\n\n  // If we know the rank of the input and the value of perm, we can return\n  // all shape information, otherwise we can only return rank information,\n  // but no information for the dimensions.\n  if (perm != nullptr) {\n    std::vector<int64_t> data;\n    if (perm->dtype() == DT_INT32) {\n      data = AsInt64<int32>(perm, rank);\n    } else {\n      data = AsInt64<int64_t>(perm, rank);\n    }\n\n    for (int32_t i = 0; i < rank; ++i) {\n      int64_t in_idx = data[i];\n      if (in_idx >= rank) {\n        return errors::InvalidArgument(\"perm dim \", in_idx,\n                                       \" is out of range of input rank \", rank);\n      }\n      dims[i] = c->Dim(input, in_idx);\n    }\n  } else {\n    for (int i = 0; i < rank; ++i) {\n      dims[i] = c->UnknownDim();\n    }\n  }\n\n  c->set_output(0, c->MakeShape(dims));\n  return Status::OK();\n}\n\nStatus SetOutputShapeForReshape(InferenceContext* c) {\n  ShapeHandle in = c->input(0);\n  ShapeHandle out;\n  TF_RETURN_IF_ERROR(c->MakeShapeFromShapeTensor(1, &out));\n\n  if (!c->RankKnown(out)) {\n    // We have no information about the shape of the output.\n    c->set_output(0, out);\n    return Status::OK();\n  }\n  if (c->RankKnown(in)) {\n    // We don't know the number of output elements, but we can try to infer\n    // the missing dimension.\n    bool too_many_unknown = false;\n    int32_t out_unknown_idx = -1;\n\n    DimensionHandle known_out_elems = c->NumElements(out);\n    if (!c->ValueKnown(known_out_elems)) {\n      known_out_elems = c->MakeDim(1);\n      for (int32_t i = 0; i < c->Rank(out); ++i) {\n        DimensionHandle dim = c->Dim(out, i);\n        if (!c->ValueKnown(dim)) {\n          if (out_unknown_idx >= 0) {\n            too_many_unknown = true;\n            break;\n          }\n          out_unknown_idx = i;\n        } else {\n          TF_RETURN_IF_ERROR(\n              c->Multiply(known_out_elems, dim, &known_out_elems));\n        }\n      }\n    }\n    int32_t in_unknown_idx = -1;\n    DimensionHandle known_in_elems = c->NumElements(in);\n    if (!c->ValueKnown(known_in_elems)) {\n      known_in_elems = c->MakeDim(1);\n      for (int32_t i = 0; i < c->Rank(in); ++i) {\n        DimensionHandle dim = c->Dim(in, i);\n        if (!c->ValueKnown(dim)) {\n          if (in_unknown_idx >= 0) {\n            too_many_unknown = true;\n            break;\n          }\n          in_unknown_idx = i;\n        } else {\n          TF_RETURN_IF_ERROR(c->Multiply(known_in_elems, dim, &known_in_elems));\n        }\n      }\n    }\n\n    if (!too_many_unknown) {\n      if (in_unknown_idx < 0 && out_unknown_idx < 0) {\n        // Just check that the dimensions match.\n        if (c->Value(known_in_elems) != c->Value(known_out_elems)) {\n          return errors::InvalidArgument(\n              \"Cannot reshape a tensor with \", c->DebugString(known_in_elems),\n              \" elements to shape \", c->DebugString(out), \" (\",\n              c->DebugString(known_out_elems), \" elements)\");\n        }\n      } else if (in_unknown_idx < 0 && out_unknown_idx >= 0 &&\n                 c->Value(known_out_elems) > 0) {\n        // Input fully known, infer the one missing output dim\n        DimensionHandle inferred_dim;\n        TF_RETURN_IF_ERROR(c->Divide(known_in_elems, c->Value(known_out_elems),\n                                     true /* evenly_divisible */,\n                                     &inferred_dim));\n        TF_RETURN_IF_ERROR(\n            c->ReplaceDim(out, out_unknown_idx, inferred_dim, &out));\n\n      } else if (in_unknown_idx >= 0 && out_unknown_idx < 0 &&\n                 c->Value(known_in_elems) != 0) {\n        // Output fully known, infer the one missing input dim\n        DimensionHandle inferred_dim;\n        TF_RETURN_IF_ERROR(c->Divide(known_out_elems, c->Value(known_in_elems),\n                                     true /* evenly_divisible */,\n                                     &inferred_dim));\n        DimensionHandle unknown_in_dim = c->Dim(in, in_unknown_idx);\n        TF_RETURN_IF_ERROR(\n            c->Merge(unknown_in_dim, inferred_dim, &unknown_in_dim));\n      } else if (in_unknown_idx >= 0 && out_unknown_idx >= 0) {\n        // Exactly one unknown dimension in both input and output. These 2 are\n        // equal iff the known elements are equal.\n        if (c->Value(known_in_elems) == c->Value(known_out_elems)) {\n          DimensionHandle unknown_in_dim = c->Dim(in, in_unknown_idx);\n          TF_RETURN_IF_ERROR(\n              c->ReplaceDim(out, out_unknown_idx, unknown_in_dim, &out));\n        }\n      }\n    }\n  }\n  c->set_output(0, out);\n  return Status::OK();\n}\n\n}  // namespace\n\nREGISTER_OP(\"ParallelConcat\")\n    .Input(\"values: N * T\")\n    .Output(\"output: T\")\n    .Attr(\"N: int >= 1\")\n    .Attr(\"T: type\")\n    .Attr(\"shape: shape\")\n    .SetShapeFn([](InferenceContext* c) {\n      // Validate that the shape attr is correct.\n      PartialTensorShape shape;\n      TF_RETURN_IF_ERROR(c->GetAttr(\"shape\", &shape));\n      ShapeHandle passed_shape;\n      TF_RETURN_IF_ERROR(\n          c->MakeShapeFromPartialTensorShape(shape, &passed_shape));\n      if (!c->FullyDefined(passed_shape)) {\n        return errors::InvalidArgument(\"shape attr must be fully defined.\");\n      }\n      ShapeHandle cur;\n      TF_RETURN_IF_ERROR(c->ReplaceDim(\n          passed_shape, 0, c->MakeDim(shape_inference::DimensionOrConstant(1)),\n          &cur));\n      for (int i = 0; i < c->num_inputs(); ++i) {\n        if (!c->FullyDefined(c->input(i))) {\n          return errors::InvalidArgument(\n              \"All input shapes must be fully defined.\");\n        }\n        DimensionHandle unused;\n        if (!c->WithValue(c->Dim(c->input(i), 0), 1, &unused).ok()) {\n          return errors::InvalidArgument(\"Size of first dimension must be 1.\");\n        }\n        TF_RETURN_WITH_CONTEXT_IF_ERROR(c->Merge(c->input(i), cur, &cur),\n                                        \"From merging shape \", i,\n                                        \" with other shapes.\");\n      }\n\n      c->set_output(0, passed_shape);\n\n      return Status::OK();\n    });\n\nREGISTER_OP(\"Pack\")\n    .Input(\"values: N * T\")\n    .Output(\"output: T\")\n    .Attr(\"N: int >= 1\")\n    .Attr(\"T: type\")\n    .Attr(\"axis: int = 0\")\n    .SetShapeFn([](InferenceContext* c) {\n      // Validate shapes of all inputs are compatible\n      ShapeHandle cur = c->input(c->num_inputs() - 1);\n      for (int i = c->num_inputs() - 2; i >= 0; --i) {\n        TF_RETURN_WITH_CONTEXT_IF_ERROR(c->Merge(c->input(i), cur, &cur),\n                                        \"From merging shape \", i,\n                                        \" with other shapes.\");\n      }\n      if (!c->RankKnown(cur)) {\n        c->set_output(0, c->UnknownShape());\n        return Status::OK();\n      }\n      // Determine the axis that will be added, converting from negative\n      // axes to a positive point per negative indexing rules.\n      int32_t rank = c->Rank(cur);\n      int32_t axis;\n      TF_RETURN_IF_ERROR(GetAxisForPackAndUnpack(c, rank + 1, &axis));\n\n      // Copy all dimensions over, inserting a dimension of value #inputs\n      // at <axis>.\n      std::vector<DimensionHandle> dims;\n      int index = 0;\n      while (index < axis) dims.push_back(c->Dim(cur, index++));\n      dims.push_back(c->MakeDim(c->num_inputs()));\n      while (index < rank) dims.push_back(c->Dim(cur, index++));\n\n      c->set_output(0, c->MakeShape(dims));\n      for (int i = 0; i < c->num_inputs(); ++i) {\n        auto* shape_and_type = c->input_handle_shapes_and_types(i);\n        if (shape_and_type) {\n          if (!c->RelaxOutputHandleShapesAndMergeTypes(0, *shape_and_type)) {\n            c->set_output_handle_shapes_and_types(\n                0, std::vector<shape_inference::ShapeAndType>({}));\n            break;\n          }\n        }\n      }\n      return Status::OK();\n    });\n\nREGISTER_OP(\"DeepCopy\")\n    .Input(\"x: T\")\n    .Output(\"y: T\")\n    .Attr(\"T: type\")\n    .SetIsStateful()\n    .SetShapeFn(UnchangedShape);\n\nREGISTER_OP(\"InplaceUpdate\")\n    .Input(\"x: T\")\n    .Input(\"i: int32\")\n    .Input(\"v: T\")\n    .Output(\"y: T\")\n    .Attr(\"T: type\")\n    .SetShapeFn(UnchangedShape);\n\nREGISTER_OP(\"InplaceAdd\")\n    .Input(\"x: T\")\n    .Input(\"i: int32\")\n    .Input(\"v: T\")\n    .Output(\"y: T\")\n    .Attr(\"T: type\")\n    .SetShapeFn(UnchangedShape);\n\nREGISTER_OP(\"InplaceSub\")\n    .Input(\"x: T\")\n    .Input(\"i: int32\")\n    .Input(\"v: T\")\n    .Output(\"y: T\")\n    .Attr(\"T: type\")\n    .SetShapeFn(UnchangedShape);\n\nREGISTER_OP(\"Empty\")\n    .Input(\"shape: int32\")\n    .Output(\"output: dtype\")\n    .Attr(\"dtype: type\")\n    .Attr(\"init: bool = false\")\n    .SetDoNotOptimize()\n    .SetShapeFn([](InferenceContext* c) {\n      ShapeHandle out;\n      TF_RETURN_IF_ERROR(c->MakeShapeFromShapeTensor(0, &out));\n      c->set_output(0, out);\n      return Status::OK();\n    });\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"Unpack\")\n    .Input(\"value: T\")\n    .Output(\"output: num * T\")\n    .Attr(\"num: int >= 0\")\n    .Attr(\"T: type\")\n    .Attr(\"axis: int = 0\")\n    .SetShapeFn([](InferenceContext* c) {\n      ShapeHandle s = c->input(0);\n      ShapeHandle out;\n      if (c->RankKnown(s)) {\n        // Determine the axis that will be removed, converting from negative\n        // axes to a positive point per negative indexing rules.\n        int32_t rank = c->Rank(s);\n        int32_t axis;\n        TF_RETURN_IF_ERROR(GetAxisForPackAndUnpack(c, rank, &axis));\n\n        // The axis dim matches the number of outputs.\n        DimensionHandle unused;\n        TF_RETURN_IF_ERROR(\n            c->WithValue(c->Dim(s, axis), c->num_outputs(), &unused));\n\n        // Copy all dimensions, removing the <axis> dimension.\n        std::vector<DimensionHandle> dims;\n        for (int i = 0; i < rank; ++i) {\n          if (i != axis) dims.push_back(c->Dim(s, i));\n        }\n        out = c->MakeShape(dims);\n      } else {\n        // All outputs are the same shape, but it's not known.\n        out = c->UnknownShape();\n      }\n      for (int i = 0; i < c->num_outputs(); ++i) c->set_output(i, out);\n      return Status::OK();\n    });\n\nREGISTER_OP(\"UnravelIndex\")\n    .Input(\"indices: Tidx\")\n    .Input(\"dims: Tidx\")\n    .Output(\"output: Tidx\")\n    .Attr(\"Tidx: {int32, int64} = DT_INT32\")\n    .SetShapeFn([](InferenceContext* c) {\n      ShapeHandle indices = c->input(0);\n      ShapeHandle dims;\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(1), 1, &dims));\n      if (c->RankKnown(indices) && c->Rank(indices) == 0) {\n        c->set_output(0, c->Vector(c->Dim(dims, 0)));\n      } else if (c->RankKnown(indices)) {\n        c->set_output(0, c->Matrix(c->Dim(dims, 0), c->NumElements(indices)));\n      } else {\n        c->set_output(0, c->UnknownShape());\n      }\n      return Status::OK();\n    });\n\nREGISTER_OP(\"BroadcastTo\")\n    .Input(\"input: T\")\n    .Input(\"shape: Tidx\")\n    .Output(\"output: T\")\n    .Attr(\"T: type\")\n    .Attr(\"Tidx: {int32, int64} = DT_INT32\")\n    .SetShapeFn([](InferenceContext* c) {\n      ShapeHandle shape_in = c->input(1);\n      TF_RETURN_IF_ERROR(c->WithRank(shape_in, 1, &shape_in));\n      ShapeHandle out;\n      TF_RETURN_IF_ERROR(c->MakeShapeFromShapeTensor(1, &out));\n      if (!c->RankKnown(out)) {\n        // We have no information about the shape of the output.\n        c->set_output(0, out);\n        return Status::OK();\n      }\n\n      ShapeHandle in = c->input(0);\n      if (!c->RankKnown(in)) {\n        // We have no information about the shape of the input,\n        // nothing to do here.\n        c->set_output(0, out);\n        return Status::OK();\n      }\n      int out_rank = c->Rank(out);\n      TF_RETURN_IF_ERROR(c->WithRankAtMost(in, out_rank, &in));\n      int in_rank = c->Rank(in);\n      for (int i = 0; i < in_rank; ++i) {\n        auto in_dim = c->Dim(in, in_rank - i - 1);\n        if (c->Value(in_dim) > 1) {\n          // If the input dimension is greater than 1 then the output dimension\n          // must be equal to it, since we only broadcast \"from left to right\".\n          auto out_dim = c->Dim(out, out_rank - i - 1);\n          TF_RETURN_IF_ERROR(c->Merge(in_dim, out_dim, &out_dim));\n          TF_RETURN_IF_ERROR(\n              c->ReplaceDim(out, out_rank - i - 1, out_dim, &out));\n        }\n      }\n      c->set_output(0, out);\n      return Status::OK();\n    });\n\n// --------------------------------------------------------------------------\n// TODO(josh11b): Remove the >= 2 constraint, once we can rewrite the graph\n// in the N == 1 case to remove the node.\nREGISTER_OP(\"Concat\")\n    .Input(\"concat_dim: int32\")\n    .Input(\"values: N * T\")\n    .Output(\"output: T\")\n    .Attr(\"N: int >= 2\")\n    .Attr(\"T: type\")\n    .SetShapeFn([](InferenceContext* c) {\n      return shape_inference::ConcatShape(c, c->num_inputs() - 1);\n    });\n\nREGISTER_OP(\"ConcatV2\")\n    .Input(\"values: N * T\")\n    .Input(\"axis: Tidx\")\n    .Output(\"output: T\")\n    .Attr(\"N: int >= 2\")\n    .Attr(\"T: type\")\n    .Attr(\"Tidx: {int32, int64} = DT_INT32\")\n    .SetShapeFn(shape_inference::ConcatV2Shape);\n\n// TODO(vivek.v.rane@intel.com): Prefix the op names with underscore if the ops\n// are not to be made user-accessible.\n#ifdef INTEL_MKL\nREGISTER_OP(\"_MklConcatV2\")\n    .Input(\"values: N * T\")\n    .Input(\"axis: Tidx\")\n    .Input(\"mkl_values: N * uint8\")\n    .Input(\"mkl_axis: uint8\")\n    .Output(\"output: T\")\n    .Output(\"mkl_output: uint8\")\n    .Attr(\"N: int >= 2\")\n    .Attr(\"T: type\")\n    .Attr(\"Tidx: {int32, int64} = DT_INT32\")\n    .SetShapeFn(shape_inference::ConcatV2Shape)\n    .Doc(R\"doc(\nMKL version of ConcatV2 operator. Uses MKL DNN APIs to perform concatenation.\n\nNOTE Do not invoke this operator directly in Python. Graph rewrite pass is\nexpected to invoke these operators.\n)doc\");\n#endif\n\nREGISTER_OP(\"ConcatOffset\")\n    .Input(\"concat_dim: int32\")\n    .Input(\"shape: N * int32\")\n    .Output(\"offset: N * int32\")\n    .Attr(\"N: int >= 2\")\n    .SetShapeFn([](InferenceContext* c) {\n      for (int i = 1; i < c->num_inputs(); ++i) {\n        c->set_output(i - 1, c->input(i));\n      }\n      return Status::OK();\n    });\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"Split\")\n    .Input(\"split_dim: int32\")\n    .Input(\"value: T\")\n    .Output(\"output: num_split * T\")\n    .Attr(\"num_split: int >= 1\")\n    .Attr(\"T: type\")\n    .SetShapeFn([](InferenceContext* c) {\n      DimensionHandle split_dimension;\n      ShapeHandle input = c->input(1);\n      TF_RETURN_IF_ERROR(c->MakeDimForScalarInputWithNegativeIndexing(\n          0, c->Rank(input), &split_dimension));\n      int num_split = c->num_outputs();\n      ShapeHandle out;\n      if (!c->ValueKnown(split_dimension)) {\n        if (c->RankKnown(input)) {\n          out = c->UnknownShapeOfRank(c->Rank(input));\n        } else {\n          out = c->UnknownShape();\n        }\n      } else {\n        int64_t split_dim = c->Value(split_dimension);\n        TF_RETURN_IF_ERROR(c->WithRankAtLeast(input, split_dim + 1, &input));\n        DimensionHandle split_dim_size;\n        TF_RETURN_WITH_CONTEXT_IF_ERROR(\n            c->Divide(c->Dim(input, split_dim), num_split,\n                      true /* evenly_divisible */, &split_dim_size),\n            \"Number of ways to split should evenly divide the split dimension\");\n        TF_RETURN_IF_ERROR(\n            c->ReplaceDim(input, split_dim, split_dim_size, &out));\n      }\n      for (int i = 0; i < num_split; ++i) c->set_output(i, out);\n      return Status::OK();\n    });\n\nREGISTER_OP(\"SplitV\")\n    .Input(\"value: T\")\n    .Input(\"size_splits: Tlen\")\n    .Input(\"split_dim: int32\")\n    .Output(\"output: num_split * T\")\n    .Attr(\"num_split: int >= 1\")\n    .Attr(\"T: type\")\n    .Attr(\"Tlen: {int32, int64} = DT_INT64\")\n    .SetShapeFn([](InferenceContext* c) {\n      DimensionHandle split_dimension;\n      ShapeHandle input = c->input(0);\n      TF_RETURN_IF_ERROR(c->MakeDimForScalarInputWithNegativeIndexing(\n          2, c->Rank(input), &split_dimension));\n      int32_t num_outputs = c->num_outputs();\n      int32_t rank = c->Rank(input);\n      ShapeHandle output_shape;\n      const Tensor* size_splits = c->input_tensor(1);\n      if (rank == InferenceContext::kUnknownRank) {\n        // If the rank of input tensor is unknown, then return unknown shapes.\n        // Note that the shape of each output can be different.\n        for (int i = 0; i < num_outputs; ++i) {\n          c->set_output(i, c->UnknownShape());\n        }\n      } else if (rank == 0) {\n        // Throw error if input is a scalar.\n        return errors::InvalidArgument(\"Can't split scalars\");\n      } else if (size_splits == nullptr && c->ValueKnown(split_dimension)) {\n        // If split dimension is known, but the sizes are unknown, then\n        // only the split dimension is unknown\n        output_shape = input;\n        for (int i = 0; i < num_outputs; ++i) {\n          TF_RETURN_IF_ERROR(c->ReplaceDim(output_shape,\n                                           c->Value(split_dimension),\n                                           c->UnknownDim(), &output_shape));\n          c->set_output(i, output_shape);\n        }\n      } else if (size_splits == nullptr && !c->ValueKnown(split_dimension)) {\n        // If split dimension or tensor containing the split sizes is unknown,\n        // then return unknown shapes of same rank as input. Note that each\n        // output shape can be different since splitv doesn't always split\n        // tensors evenly.\n        for (int i = 0; i < num_outputs; ++i) {\n          c->set_output(i, c->UnknownShapeOfRank(rank));\n        }\n      } else {\n        // Determine the output shape if split dimension and split sizes are\n        // known.\n        int64_t split_dim = c->Value(split_dimension);\n        TF_RETURN_IF_ERROR(c->WithRankAtLeast(input, split_dim + 1, &input));\n        std::vector<int64_t> data;\n        if (size_splits->dtype() == DT_INT32) {\n          data = AsInt64<int32>(size_splits, size_splits->shape().dim_size(0));\n        } else {\n          data =\n              AsInt64<int64_t>(size_splits, size_splits->shape().dim_size(0));\n        }\n        if (num_outputs != data.size()) {\n          return errors::InvalidArgument(\n              \"Length of size_splits should be equal to num_outputs\");\n        }\n        int64_t total_size = 0;\n        bool has_neg_one = false;\n        for (const auto size : data) {\n          if (size == -1) {\n            if (has_neg_one) {\n              return errors::InvalidArgument(\n                  \"size_splits can only have one -1\");\n            }\n            has_neg_one = true;\n          } else {\n            total_size += size;\n          }\n        }\n        auto split_dim_size = c->Value(c->Dim(input, split_dim));\n        // If the sizes of the splits are known, then\n        // make sure that the sizes add up to the expected\n        // dimension size, with the possibility of a -1.\n        // Specify the full output shapes.\n        for (int i = 0; i < num_outputs; ++i) {\n          auto size = data[i];\n          if (data[i] == -1 && c->ValueKnown(split_dim_size)) {\n            size = split_dim_size - total_size;\n          }\n          // If we have a negative known size (either explicit, or computed\n          // via -1), then the split sizes are invalid.\n          if (size < -1 || (size == -1 && c->ValueKnown(split_dim_size))) {\n            return errors::InvalidArgument(\"Split size at index \", i,\n                                           \" must be >= 0. Got: \", size);\n          }\n          TF_RETURN_IF_ERROR(\n              c->ReplaceDim(input, split_dim, c->MakeDim(size), &output_shape));\n          c->set_output(i, output_shape);\n        }\n        if (c->ValueKnown(split_dim_size)) {\n          if (has_neg_one ? total_size > split_dim_size\n                          : total_size != split_dim_size) {\n            return errors::InvalidArgument(\n                \"can't split axis of size \", split_dim_size,\n                \" into pieces of size [\", absl::StrJoin(data, \",\"), \"]\");\n          }\n        }\n      }\n\n      return Status::OK();\n    });\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"Const\")\n    .Output(\"output: dtype\")\n    .Attr(\"value: tensor\")\n    .Attr(\"dtype: type\")\n    .SetShapeFn([](InferenceContext* c) {\n      const TensorProto* proto = nullptr;\n      TF_RETURN_IF_ERROR(c->GetAttr(\"value\", &proto));\n      TF_RETURN_IF_ERROR(TensorShape::IsValidShape(proto->tensor_shape()));\n      TensorShape shape(proto->tensor_shape());\n      std::vector<DimensionHandle> dims;\n      dims.reserve(shape.dims());\n      for (int i = 0; i < shape.dims(); ++i) {\n        dims.push_back(c->MakeDim(shape.dim_size(i)));\n      }\n      c->set_output(0, c->MakeShape(dims));\n      return Status::OK();\n    });\n\n// Returns a constant tensor on the host.  Useful for writing C++ tests\n// and benchmarks which run on GPU but require arguments pinned to the host.\n// Used by test::graph::HostConstant.\n// value: Attr `value` is the tensor to return.\nREGISTER_OP(\"HostConst\")\n    .Output(\"output: dtype\")\n    .Attr(\"value: tensor\")\n    .Attr(\"dtype: type\")\n    .SetShapeFn(shape_inference::UnknownShape);\n\n// Used executing op-by-op to copy constants to the current device without\n// serializing tensors as TensorProtos, after a host tensor has been\n// created. Same behavior as Identity, but no gradient and potentially relaxed\n// copy semantics.\nREGISTER_OP(\"_EagerConst\")\n    .Input(\"input: T\")\n    .Output(\"output: T\")\n    .Attr(\"T: type\")\n    .SetShapeFn(shape_inference::UnchangedShape);\n\n// --------------------------------------------------------------------------\n// TODO(mgubin): Update the doc when the freeze_graph script supports converting\n// into memmapped format.\nREGISTER_OP(\"ImmutableConst\")\n    .Attr(\"dtype: type\")\n    .Attr(\"shape: shape\")\n    .Attr(\"memory_region_name: string\")\n    .Output(\"tensor: dtype\")\n    .SetShapeFn(shape_inference::ExplicitShape);\n\nREGISTER_OP(\"GuaranteeConst\")\n    .Input(\"input: T\")\n    .Output(\"output: T\")\n    .Attr(\"T: type\")\n    .SetShapeFn([](shape_inference::InferenceContext* c) {\n      return UnchangedShape(c);\n    })\n    // We don't want this to be optimized away.\n    .SetDoNotOptimize();\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"ZerosLike\")\n    .Input(\"x: T\")\n    .Output(\"y: T\")\n    .Attr(\"T: type\")\n    .SetShapeFn(shape_inference::UnchangedShape);\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"OnesLike\")\n    .Input(\"x: T\")\n    .Output(\"y: T\")\n    .Attr(\n        \"T: {bfloat16, half, float, double, int8, uint8, int16, uint16, int32, \"\n        \"int64, complex64, complex128, bool}\")\n    .SetShapeFn(shape_inference::UnchangedShape);\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"Diag\")\n    .Input(\"diagonal: T\")\n    .Output(\"output: T\")\n    .Attr(\n        \"T: {bfloat16, half, float, double, int32, int64, complex64, \"\n        \"complex128}\")\n    .SetShapeFn([](InferenceContext* c) {\n      ShapeHandle in = c->input(0);\n      TF_RETURN_IF_ERROR(c->WithRankAtLeast(in, 1, &in));\n      // Output shape is original concatenated with itself.\n      ShapeHandle out;\n      TF_RETURN_IF_ERROR(c->Concatenate(in, in, &out));\n      c->set_output(0, out);\n      return Status::OK();\n    });\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"DiagPart\")\n    .Input(\"input: T\")\n    .Output(\"diagonal: T\")\n    .Attr(\n        \"T: {bfloat16, half, float, double, int32, int64, complex64, \"\n        \"complex128}\")\n    .SetShapeFn([](InferenceContext* c) {\n      ShapeHandle in = c->input(0);\n      if (!c->RankKnown(in)) {\n        c->set_output(0, c->UnknownShape());\n        return Status::OK();\n      }\n      // Rank must be even, and result will have rank <rank/2>.\n      const int32_t rank = c->Rank(in);\n      if ((rank % 2) != 0 || rank <= 0) {\n        return errors::InvalidArgument(\n            \"Input must have even and non-zero rank, input rank is \", rank);\n      }\n      const int32_t mid = rank / 2;\n\n      // output dim[i] is the merge of in.dim[i] and in.dim[i+mid].\n      std::vector<DimensionHandle> dims(mid);\n      for (int i = 0; i < mid; ++i) {\n        TF_RETURN_IF_ERROR(\n            c->Merge(c->Dim(in, i), c->Dim(in, i + mid), &dims[i]));\n      }\n      c->set_output(0, c->MakeShape(dims));\n      return Status::OK();\n    });\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"MatrixDiag\")\n    .Input(\"diagonal: T\")\n    .Output(\"output: T\")\n    .Attr(\"T: type\")\n    .SetShapeFn([](InferenceContext* c) {\n      ShapeHandle in;\n      TF_RETURN_IF_ERROR(c->WithRankAtLeast(c->input(0), 1, &in));\n      if (!c->RankKnown(in)) {\n        c->set_output(0, c->UnknownShape());\n        return Status::OK();\n      }\n      const int32_t rank = c->Rank(in);\n      ShapeHandle out;\n      TF_RETURN_IF_ERROR(\n          c->Concatenate(in, c->Vector(c->Dim(in, rank - 1)), &out));\n      c->set_output(0, out);\n      return Status::OK();\n    });\n\nREGISTER_OP(\"MatrixDiagV2\")\n    .Input(\"diagonal: T\")\n    .Input(\"k: int32\")\n    .Input(\"num_rows: int32\")\n    .Input(\"num_cols: int32\")\n    .Input(\"padding_value: T\")\n    .Output(\"output: T\")\n    .Attr(\"T: type\")\n    .SetShapeFn(shape_inference::MatrixDiagV2Shape);\n\nREGISTER_OP(\"MatrixDiagV3\")\n    .Input(\"diagonal: T\")\n    .Input(\"k: int32\")\n    .Input(\"num_rows: int32\")\n    .Input(\"num_cols: int32\")\n    .Input(\"padding_value: T\")\n    .Output(\"output: T\")\n    .Attr(\"T: type\")\n    .Attr(\n        \"align: {'LEFT_RIGHT', 'RIGHT_LEFT', 'LEFT_LEFT', 'RIGHT_RIGHT'} = \"\n        \"'RIGHT_LEFT'\")\n    .SetShapeFn(shape_inference::MatrixDiagV2Shape);\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"MatrixSetDiag\")\n    .Input(\"input: T\")\n    .Input(\"diagonal: T\")\n    .Output(\"output: T\")\n    .Attr(\"T: type\")\n    .SetShapeFn([](InferenceContext* c) {\n      ShapeHandle input;\n      ShapeHandle diag;\n      TF_RETURN_IF_ERROR(c->WithRankAtLeast(c->input(0), 2, &input));\n      TF_RETURN_IF_ERROR(c->WithRankAtLeast(c->input(1), 1, &diag));\n      if (c->RankKnown(input)) {\n        TF_RETURN_IF_ERROR(c->WithRank(c->input(1), c->Rank(input) - 1, &diag));\n      }\n      DimensionHandle smallest_dim;\n      TF_RETURN_IF_ERROR(\n          c->Min(c->Dim(input, -2), c->Dim(input, -1), &smallest_dim));\n      TF_RETURN_IF_ERROR(\n          c->Merge(smallest_dim, c->Dim(diag, -1), &smallest_dim));\n\n      ShapeHandle output = input;\n      if (c->RankKnown(diag) && !c->FullyDefined(input)) {\n        // Try to infer parts of shape from diag.\n        ShapeHandle diag_batch_shape;\n        TF_RETURN_IF_ERROR(c->Subshape(diag, 0, -1, &diag_batch_shape));\n        TF_RETURN_IF_ERROR(\n            c->Concatenate(diag_batch_shape, c->UnknownShapeOfRank(2), &diag));\n        TF_RETURN_IF_ERROR(c->Merge(input, diag, &output));\n      }\n      c->set_output(0, output);\n      return Status::OK();\n    });\n\nREGISTER_OP(\"MatrixSetDiagV2\")\n    .Input(\"input: T\")\n    .Input(\"diagonal: T\")\n    .Input(\"k: int32\")\n    .Output(\"output: T\")\n    .Attr(\"T: type\")\n    .SetShapeFn(shape_inference::MatrixSetDiagV2Shape);\n\nREGISTER_OP(\"MatrixSetDiagV3\")\n    .Input(\"input: T\")\n    .Input(\"diagonal: T\")\n    .Input(\"k: int32\")\n    .Output(\"output: T\")\n    .Attr(\"T: type\")\n    .Attr(\n        \"align: {'LEFT_RIGHT', 'RIGHT_LEFT', 'LEFT_LEFT', 'RIGHT_RIGHT'} = \"\n        \"'RIGHT_LEFT'\")\n    .SetShapeFn(shape_inference::MatrixSetDiagV2Shape);\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"MatrixDiagPart\")\n    .Input(\"input: T\")\n    .Output(\"diagonal: T\")\n    .Attr(\"T: type\")\n    .SetShapeFn([](InferenceContext* c) {\n      ShapeHandle in;\n      TF_RETURN_IF_ERROR(c->WithRankAtLeast(c->input(0), 2, &in));\n      if (!c->RankKnown(in)) {\n        c->set_output(0, c->UnknownShape());\n        return Status::OK();\n      }\n      const int32_t rank = c->Rank(in);\n      std::vector<DimensionHandle> dims;\n      dims.reserve(rank - 2);\n      for (int i = 0; i < rank - 2; ++i) dims.push_back(c->Dim(in, i));\n\n      DimensionHandle min_dim;\n      TF_RETURN_IF_ERROR(\n          c->Min(c->Dim(in, rank - 2), c->Dim(in, rank - 1), &min_dim));\n      dims.push_back(min_dim);\n      c->set_output(0, c->MakeShape(dims));\n      return Status::OK();\n    });\n\nREGISTER_OP(\"MatrixDiagPartV2\")\n    .Input(\"input: T\")\n    .Input(\"k: int32\")\n    .Input(\"padding_value: T\")\n    .Output(\"diagonal: T\")\n    .Attr(\"T: type\")\n    .SetShapeFn(shape_inference::MatrixDiagPartV2Shape);\n\nREGISTER_OP(\"MatrixDiagPartV3\")\n    .Input(\"input: T\")\n    .Input(\"k: int32\")\n    .Input(\"padding_value: T\")\n    .Output(\"diagonal: T\")\n    .Attr(\"T: type\")\n    .Attr(\n        \"align: {'LEFT_RIGHT', 'RIGHT_LEFT', 'LEFT_LEFT', 'RIGHT_RIGHT'} = \"\n        \"'RIGHT_LEFT'\")\n    .SetShapeFn(shape_inference::MatrixDiagPartV2Shape);\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"MatrixBandPart\")\n    .Input(\"input: T\")\n    .Input(\"num_lower: Tindex\")\n    .Input(\"num_upper: Tindex\")\n    .Output(\"band: T\")\n    .Attr(\"T: type\")\n    .Attr(\"Tindex: {int32, int64} = DT_INT64\")\n    .SetShapeFn(shape_inference::UnchangedShape);\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"Reverse\")\n    .Input(\"tensor: T\")\n    .Input(\"dims: bool\")\n    .Output(\"output: T\")\n    .Attr(\n        \"T: {uint8, int8, uint16, int16, uint32, int32, uint64, int64, bool, \"\n        \"bfloat16, half, float, double, complex64, complex128, string}\")\n    .SetShapeFn([](InferenceContext* c) {\n      ShapeHandle input = c->input(0);\n      ShapeHandle dims;\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(1), 1, &dims));\n      DimensionHandle dims_dim = c->Dim(dims, 0);\n      if (c->ValueKnown(dims_dim)) {\n        TF_RETURN_IF_ERROR(c->WithRank(input, c->Value(dims_dim), &input));\n      }\n      if (c->Rank(input) > 8) {\n        return errors::InvalidArgument(\n            \"reverse does not work on tensors with more than 8 dimensions\");\n      }\n      c->set_output(0, input);\n      return Status::OK();\n    });\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"ReverseV2\")\n    .Input(\"tensor: T\")\n    .Input(\"axis: Tidx\")\n    .Output(\"output: T\")\n    .Attr(\"Tidx: {int32, int64} = DT_INT32\")\n    .Attr(\n        \"T: {uint8, int8, uint16, int16, int32, uint32, int64, uint64, bool, \"\n        \"bfloat16, half, float, double, complex64, complex128, string}\")\n    .SetShapeFn([](InferenceContext* c) {\n      ShapeHandle input = c->input(0);\n      ShapeHandle axis;\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(1), 1, &axis));\n      if (c->Rank(input) > 8) {\n        return errors::InvalidArgument(\n            \"reverse does not work on tensors with more than 8 dimensions\");\n      }\n      const Tensor* axis_tensor = c->input_tensor(1);\n      if (axis_tensor != nullptr && c->RankKnown(input)) {\n        int32_t rank = c->Rank(input);\n        std::vector<int64_t> axis_value;\n        if (axis_tensor->dtype() == DT_INT32) {\n          axis_value = AsInt64<int32>(axis_tensor, axis_tensor->NumElements());\n        } else {\n          axis_value =\n              AsInt64<int64_t>(axis_tensor, axis_tensor->NumElements());\n        }\n        std::vector<bool> axes_dense(c->Rank(input), false);\n        for (int i = 0; i < axis_value.size(); i++) {\n          int64_t canonical_axis =\n              axis_value[i] < 0 ? rank + axis_value[i] : axis_value[i];\n          if (canonical_axis < 0 || canonical_axis >= rank) {\n            return errors::InvalidArgument(\"'axis'[\", i, \"] = \", axis_value[i],\n                                           \" is out of valid range [\", 0, \", \",\n                                           rank - 1);\n          }\n          if (axes_dense[canonical_axis]) {\n            return errors::InvalidArgument(\"axis \", canonical_axis,\n                                           \" specified more than once.\");\n          }\n          axes_dense[canonical_axis] = true;\n        }\n      }\n      c->set_output(0, input);\n      return Status::OK();\n    });\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"EditDistance\")\n    .Input(\"hypothesis_indices: int64\")\n    .Input(\"hypothesis_values: T\")\n    .Input(\"hypothesis_shape: int64\")\n    .Input(\"truth_indices: int64\")\n    .Input(\"truth_values: T\")\n    .Input(\"truth_shape: int64\")\n    .Attr(\"normalize: bool = true\")\n    .Attr(\"T: type\")\n    .Output(\"output: float\")\n    .SetShapeFn([](InferenceContext* c) {\n      TF_RETURN_IF_ERROR(shape_inference::ValidateSparseTensor(\n          c, c->input(0), c->input(1), c->input(2)));\n      TF_RETURN_IF_ERROR(shape_inference::ValidateSparseTensor(\n          c, c->input(3), c->input(4), c->input(5)));\n      const Tensor* hypothesis_shape_t = c->input_tensor(2);\n      const Tensor* truth_shape_t = c->input_tensor(5);\n      if (hypothesis_shape_t == nullptr || truth_shape_t == nullptr) {\n        // We need to know the runtime shape of the two tensors,\n        // or else the output shape is unknown.\n        return shape_inference::UnknownShape(c);\n      }\n\n      if (hypothesis_shape_t->NumElements() != truth_shape_t->NumElements()) {\n        return errors::InvalidArgument(\n            \"Num elements of hypothesis_shape does not match truth_shape: \",\n            hypothesis_shape_t->NumElements(), \" vs. \",\n            truth_shape_t->NumElements());\n      }\n\n      auto h_values = hypothesis_shape_t->flat<int64_t>();\n      auto t_values = truth_shape_t->flat<int64_t>();\n      std::vector<DimensionHandle> dims(hypothesis_shape_t->NumElements() - 1);\n      for (int i = 0; i < dims.size(); ++i) {\n        dims[i] = c->MakeDim(std::max(h_values(i), t_values(i)));\n      }\n\n      c->set_output(0, c->MakeShape(dims));\n      return Status::OK();\n    });\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"Fill\")\n    .Input(\"dims: index_type\")\n    .Input(\"value: T\")\n    .Output(\"output: T\")\n    .Attr(\"T: type\")\n    .Attr(\"index_type: {int32, int64} = DT_INT32\")\n    .SetShapeFn([](InferenceContext* c) {\n      DataType index_type = DT_INT32;\n      Status s = c->GetAttr(\"index_type\", &index_type);\n      if (!s.ok() && s.code() != error::NOT_FOUND) {\n        return s;\n      }\n      ShapeHandle unused;\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(0), 1, &unused));\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(1), 0, &unused));\n\n      const Tensor* t = c->input_tensor(0);\n      if (t != nullptr) {\n        for (int i = 0; i < t->NumElements(); ++i) {\n          if ((index_type == DT_INT32 && t->vec<int32>()(i) < 0) ||\n              (index_type == DT_INT64 && t->vec<int64_t>()(i) < 0)) {\n            return errors::InvalidArgument(\"Fill dimensions must be >= 0\");\n          }\n        }\n      }\n\n      ShapeHandle out;\n      TF_RETURN_IF_ERROR(c->MakeShapeFromShapeTensor(0, &out));\n      c->set_output(0, out);\n\n      auto* shape_and_type = c->input_handle_shapes_and_types(1);\n      if (shape_and_type) {\n        c->set_output_handle_shapes_and_types(0, *shape_and_type);\n      }\n\n      return Status::OK();\n    });\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"_ParallelConcatStart\")\n    .Output(\"output: dtype\")\n    .Attr(\"shape: shape\")\n    .Attr(\"dtype: type\")\n    .SetIsStateful()\n    .SetShapeFn(shape_inference::ExplicitShape)\n    .Doc(R\"doc(\nCreates an empty Tensor with shape `shape` and type `dtype`.\n\nThe memory can optionally be initialized. This is usually useful in\nconjunction with inplace operations.\n\nshape: 1-D `Tensor` indicating the shape of the output.\ndtype: The element type of the returned tensor.\noutput: An empty Tensor of the specified type.\n)doc\");\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"_ParallelConcatUpdate\")\n    .Input(\"value: T\")\n    .Input(\"update: T\")\n    .Output(\"output: T\")\n    .Attr(\"T: type\")\n    .Attr(\"loc: int\")\n    .SetShapeFn(shape_inference::UnchangedShape)\n    .Doc(R\"doc(\nUpdates input `value` at `loc` with `update`.\n\nIf you use this function you will almost certainly want to add\na control dependency as done in the implementation of parallel_stack to\navoid race conditions.\n\nvalue: A `Tensor` object that will be updated in-place.\nloc: A scalar indicating the index of the first dimension such that\n         value[loc, :] is updated.\nupdate: A `Tensor` of rank one less than `value` if `loc` is a scalar,\n        otherwise of rank equal to `value` that contains the new values\n        for `value`.\noutput: `value` that has been updated accordingly.\n)doc\");\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"Gather\")\n    .Input(\"params: Tparams\")\n    .Input(\"indices: Tindices\")\n    .Attr(\"validate_indices: bool = true\")\n    .Output(\"output: Tparams\")\n    .Attr(\"Tparams: type\")\n    .Attr(\"Tindices: {int32,int64}\")\n    .SetShapeFn([](InferenceContext* c) {\n      ShapeHandle unused;\n      TF_RETURN_IF_ERROR(c->WithRankAtLeast(c->input(0), 1, &unused));\n      ShapeHandle params_subshape;\n      TF_RETURN_IF_ERROR(c->Subshape(c->input(0), 1, &params_subshape));\n      ShapeHandle indices_shape = c->input(1);\n      ShapeHandle out;\n      TF_RETURN_IF_ERROR(c->Concatenate(indices_shape, params_subshape, &out));\n      c->set_output(0, out);\n      return Status::OK();\n    });\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"GatherV2\")\n    .Input(\"params: Tparams\")\n    .Input(\"indices: Tindices\")\n    .Input(\"axis: Taxis\")\n    .Attr(\"batch_dims: int = 0\")\n    .Output(\"output: Tparams\")\n    .Attr(\"Tparams: type\")\n    .Attr(\"Tindices: {int32,int64}\")\n    .Attr(\"Taxis: {int32,int64}\")\n    .SetShapeFn([](InferenceContext* c) {\n      ShapeHandle params_shape;\n      TF_RETURN_IF_ERROR(c->WithRankAtLeast(c->input(0), 1, &params_shape));\n\n      ShapeHandle indices_shape = c->input(1);\n      ShapeHandle unused_axis_shape;\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(2), 0, &unused_axis_shape));\n      const Tensor* axis_t = c->input_tensor(2);\n\n      // If axis is unknown, we can only infer that the result is params_rank +\n      // indices_rank - 1.\n      if (axis_t == nullptr) {\n        if (c->RankKnown(params_shape) && c->RankKnown(indices_shape)) {\n          int32_t batch_dims;\n          TF_RETURN_IF_ERROR(c->GetAttr(\"batch_dims\", &batch_dims));\n          c->set_output(0, c->UnknownShapeOfRank(c->Rank(params_shape) +\n                                                 c->Rank(indices_shape) - 1 -\n                                                 batch_dims));\n        } else {\n          c->set_output(0, c->UnknownShape());\n        }\n        return Status::OK();\n      }\n\n      // Note, axis can be negative.\n      int64_t axis = 0;\n      if (axis_t->dtype() == DT_INT32) {\n        axis = axis_t->scalar<int32>()();\n      } else {\n        axis = axis_t->scalar<int64_t>()();\n      }\n\n      // Check that params has rank of at least axis + 1.\n      ShapeHandle unused;\n      TF_RETURN_IF_ERROR(c->WithRankAtLeast(\n          params_shape, axis < 0 ? -axis : axis + 1, &unused));\n\n      // Note, batch_dims can be negative.\n      int32_t batch_dims;\n      TF_RETURN_IF_ERROR(c->GetAttr(\"batch_dims\", &batch_dims));\n      // -rank(indices) <= batch_dims <= rank(indices)\n      TF_RETURN_IF_ERROR(\n          c->WithRankAtLeast(indices_shape, std::abs(batch_dims), &unused));\n      if (batch_dims < 0) {\n        batch_dims += c->Rank(indices_shape);\n      }\n      // rank(params) > batch_dims\n      TF_RETURN_IF_ERROR(\n          c->WithRankAtLeast(params_shape, batch_dims + 1, &unused));\n\n      ShapeHandle params_outer_subshape;\n      TF_RETURN_IF_ERROR(\n          c->Subshape(params_shape, 0, axis, &params_outer_subshape));\n\n      ShapeHandle indices_inner_subshape;\n      TF_RETURN_IF_ERROR(\n          c->Subshape(indices_shape, batch_dims, &indices_inner_subshape));\n\n      ShapeHandle out;\n      TF_RETURN_IF_ERROR(\n          c->Concatenate(params_outer_subshape, indices_inner_subshape, &out));\n\n      // Slice from axis + 1 to the end of params_shape to collect the inner\n      // dimensions of the result. Special case -1 here since -1 + 1 wraps, and\n      // we slice from 0 to the end of shape. Subshape() handles all other\n      // out-of-bounds checking.\n      if (axis != -1) {\n        ShapeHandle params_inner_subshape;\n        TF_RETURN_IF_ERROR(\n            c->Subshape(params_shape, axis + 1, &params_inner_subshape));\n        TF_RETURN_IF_ERROR(c->Concatenate(out, params_inner_subshape, &out));\n      }\n\n      c->set_output(0, out);\n      return Status::OK();\n    });\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"GatherNd\")\n    .Input(\"params: Tparams\")\n    .Input(\"indices: Tindices\")\n    .Output(\"output: Tparams\")\n    .Attr(\"Tparams: type\")\n    .Attr(\"Tindices: {int32,int64}\")\n    .SetShapeFn(shape_inference::GatherNdShape);\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"Identity\")\n    .Input(\"input: T\")\n    .Output(\"output: T\")\n    .Attr(\"T: type\")\n    .SetForwardTypeFn(full_type::ReplicateInputs())\n    .SetShapeFn(shape_inference::UnchangedShape);\n\nREGISTER_OP(\"Snapshot\")\n    .Input(\"input: T\")\n    .Output(\"output: T\")\n    .Attr(\"T: type\")\n    .SetShapeFn(shape_inference::UnchangedShape);\n\n#ifdef INTEL_MKL\nREGISTER_OP(\"_MklIdentity\")\n    .Input(\"input: T\")\n    .Input(\"mkl_input: uint8\")\n    .Output(\"output: T\")\n    .Output(\"mkl_output: uint8\")\n    .Attr(\"T: type\")\n    .SetShapeFn(shape_inference::UnchangedShape)\n    .Doc(R\"Doc( Mkl implementation of IdentityOp\n)Doc\");\n#endif\n\nREGISTER_OP(\"IdentityN\")\n    .Input(\"input: T\")\n    .Output(\"output: T\")\n    .Attr(\"T: list(type)\")\n    .SetShapeFn([](shape_inference::InferenceContext* c) {\n      std::vector<ShapeHandle> input;\n      TF_RETURN_IF_ERROR(c->input(\"input\", &input));\n      TF_RETURN_IF_ERROR(c->set_output(\"output\", input));\n      // If any of the input shapes are not known, we should return error.\n      for (int i = 0; i < input.size(); i++) {\n        if (!input[i].Handle()) {\n          return errors::InvalidArgument(absl::StrCat(\n              \"Cannot infer output shape #\", i,\n              \" for IdentityN node because input shape #\", i, \" is unknown.\"));\n        }\n      }\n      return Status::OK();\n    });\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"RefIdentity\")\n    .Input(\"input: Ref(T)\")\n    .Output(\"output: Ref(T)\")\n    .Attr(\"T: type\")\n    .SetShapeFn(shape_inference::UnchangedShape)\n    .SetAllowsUninitializedInput();\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"DebugGradientIdentity\")\n    .Input(\"input: T\")\n    .Output(\"output: T\")\n    .Attr(\"T: type\")\n    .SetShapeFn(shape_inference::UnchangedShape)\n    .SetAllowsUninitializedInput();\n\nREGISTER_OP(\"DebugGradientRefIdentity\")\n    .Input(\"input: Ref(T)\")\n    .Output(\"output: Ref(T)\")\n    .Attr(\"T: type\")\n    .SetShapeFn(shape_inference::UnchangedShape)\n    .SetAllowsUninitializedInput();\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"StopGradient\")\n    .Input(\"input: T\")\n    .Output(\"output: T\")\n    .Attr(\"T: type\")\n    .SetShapeFn(shape_inference::UnchangedShape);\n\nREGISTER_OP(\"PreventGradient\")\n    .Input(\"input: T\")\n    .Output(\"output: T\")\n    .Attr(\"T: type\")\n    .Attr(\"message: string = ''\")\n    .SetShapeFn(shape_inference::UnchangedShape);\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"CheckNumerics\")\n    .Input(\"tensor: T\")\n    .Output(\"output: T\")\n    .Attr(\"T: {bfloat16, half, float, double}\")\n    .Attr(\"message: string\")\n    .SetIsStateful()\n    .SetShapeFn(shape_inference::UnchangedShape);\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"CheckNumericsV2\")\n    .Input(\"tensor: T\")\n    .Output(\"output: T\")\n    .Attr(\"T: {bfloat16, half, float, double}\")\n    .Attr(\"message: string\")\n    .SetIsStateful()\n    .SetShapeFn(shape_inference::UnchangedShape);\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"Reshape\")\n    .Input(\"tensor: T\")\n    .Input(\"shape: Tshape\")\n    .Output(\"output: T\")\n    .Attr(\"T: type\")\n    .Attr(\"Tshape: {int32, int64} = DT_INT32\")\n    .SetShapeFn([](InferenceContext* c) {\n      return SetOutputShapeForReshape(c);\n    });\n\n#ifdef INTEL_MKL\nREGISTER_OP(\"_MklReshape\")\n    .Input(\"tensor: T\")\n    .Input(\"shape: Tshape\")\n    .Input(\"mkl_tensor: uint8\")\n    .Input(\"mkl_shape: uint8\")\n    .Output(\"output: T\")\n    .Output(\"mkl_output: uint8\")\n    .Attr(\"T: type\")\n    .Attr(\"Tshape: {int32, int64} = DT_INT32\")\n    .SetShapeFn([](InferenceContext* c) { return SetOutputShapeForReshape(c); })\n    .Doc(R\"Doc( MKL implementation of ReshapeOp.\n)Doc\");\n#endif  // INTEL_MKL\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"InvertPermutation\")\n    .Input(\"x: T\")\n    .Output(\"y: T\")\n    .Attr(\"T: {int32, int64} = DT_INT32\")\n    .SetShapeFn([](InferenceContext* c) {\n      ShapeHandle x;\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(0), 1, &x));\n      c->set_output(0, x);\n      return Status::OK();\n    });\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"Transpose\")\n    .Input(\"x: T\")\n    .Input(\"perm: Tperm\")\n    .Output(\"y: T\")\n    .Attr(\"T: type\")\n    .Attr(\"Tperm: {int32, int64} = DT_INT32\")\n    .SetShapeFn(TransposeShapeFn);\n\n#ifdef INTEL_MKL\nREGISTER_OP(\"_MklTranspose\")\n    .Input(\"x: T\")\n    .Input(\"perm: Tperm\")\n    .Output(\"y: T\")\n    .Attr(\"T: type\")\n    .Attr(\"Tperm: {int32, int64} = DT_INT32\")\n    .SetShapeFn(TransposeShapeFn);\n#endif  // INTEL_MKL\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"ConjugateTranspose\")\n    .Input(\"x: T\")\n    .Input(\"perm: Tperm\")\n    .Output(\"y: T\")\n    .Attr(\"T: type\")\n    .Attr(\"Tperm: {int32, int64} = DT_INT32\")\n    .SetShapeFn(TransposeShapeFn);\n\n#ifdef INTEL_MKL\nREGISTER_OP(\"_MklConjugateTranspose\")\n    .Input(\"x: T\")\n    .Input(\"perm: Tperm\")\n    .Output(\"y: T\")\n    .Attr(\"T: type\")\n    .Attr(\"Tperm: {int32, int64} = DT_INT32\")\n    .SetShapeFn(TransposeShapeFn);\n#endif  // INTEL_MKL\n\n// --------------------------------------------------------------------------\nnamespace {\nStatus UniqueIdxShapeFn(InferenceContext* c) {\n  ShapeHandle input = c->input(0);\n  const Tensor* axis_t = c->input_tensor(1);\n  if (axis_t == nullptr || !c->RankKnown(input)) {\n    c->set_output(1, c->Vector(InferenceContext::kUnknownDim));\n    return Status::OK();\n  }\n\n  if (c->Rank(c->input(1)) != 1) {\n    return errors::InvalidArgument(\"axis expects a 1D vector.\");\n  }\n\n  int32_t n = axis_t->NumElements();\n  if (n == 0) {\n    if (c->Rank(input) != 1) {\n      return errors::InvalidArgument(\"x expects a 1D vector.\");\n    }\n    c->set_output(1, input);\n    return Status::OK();\n  } else if (n == 1) {\n    int64_t axis;\n    if (axis_t->dtype() == DT_INT32) {\n      axis = static_cast<int64_t>(axis_t->flat<int32>()(0));\n    } else {\n      axis = axis_t->flat<int64_t>()(0);\n    }\n\n    int64_t input_rank = c->Rank(input);\n    if (axis < -input_rank || axis >= input_rank) {\n      return errors::InvalidArgument(\"axis expects to be in the range [\",\n                                     -input_rank, \", \", input_rank, \")\");\n    }\n    if (axis < 0) {\n      axis += input_rank;\n    }\n    c->set_output(1, c->Vector(c->Dim(input, axis)));\n    return Status::OK();\n  }\n  return errors::InvalidArgument(\n      \"axis does not support input tensors larger than 1 elements.\");\n}\n}  // namespace\n\nREGISTER_OP(\"Unique\")\n    .Input(\"x: T\")\n    .Output(\"y: T\")\n    .Output(\"idx: out_idx\")\n    .Attr(\"T: type\")\n    .Attr(\"out_idx: {int32, int64} = DT_INT32\")\n    .SetShapeFn([](InferenceContext* c) {\n      c->set_output(0, c->Vector(InferenceContext::kUnknownDim));\n      c->set_output(1, c->input(0));\n      // Assert that the input rank is 1.\n      ShapeHandle dummy;\n      return c->WithRank(c->input(0), 1, &dummy);\n    });\n\nREGISTER_OP(\"UniqueV2\")\n    .Input(\"x: T\")\n    .Input(\"axis: Taxis\")\n    .Output(\"y: T\")\n    .Output(\"idx: out_idx\")\n    .Attr(\"T: type\")\n    .Attr(\"Taxis: {int32,int64} = DT_INT64\")\n    .Attr(\"out_idx: {int32, int64} = DT_INT32\")\n    .SetShapeFn([](InferenceContext* c) {\n      c->set_output(0, c->UnknownShapeOfRank(c->Rank(c->input(0))));\n      TF_RETURN_IF_ERROR(UniqueIdxShapeFn(c));\n      return Status::OK();\n    });\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"UniqueWithCounts\")\n    .Input(\"x: T\")\n    .Output(\"y: T\")\n    .Output(\"idx: out_idx\")\n    .Output(\"count: out_idx\")\n    .Attr(\"T: type\")\n    .Attr(\"out_idx: {int32, int64} = DT_INT32\")\n    .SetShapeFn([](InferenceContext* c) {\n      auto uniq = c->Vector(InferenceContext::kUnknownDim);\n      c->set_output(0, uniq);\n      c->set_output(1, c->input(0));\n      c->set_output(2, uniq);\n      return Status::OK();\n    });\n\nREGISTER_OP(\"UniqueWithCountsV2\")\n    .Input(\"x: T\")\n    .Input(\"axis: Taxis\")\n    .Output(\"y: T\")\n    .Output(\"idx: out_idx\")\n    .Output(\"count: out_idx\")\n    .Attr(\"T: type\")\n    .Attr(\"Taxis: {int32,int64} = DT_INT64\")\n    .Attr(\"out_idx: {int32, int64} = DT_INT32\")\n    .SetShapeFn([](InferenceContext* c) {\n      c->set_output(0, c->UnknownShapeOfRank(c->Rank(c->input(0))));\n      TF_RETURN_IF_ERROR(UniqueIdxShapeFn(c));\n      c->set_output(2, c->Vector(InferenceContext::kUnknownDim));\n      return Status::OK();\n    });\n\nnamespace {\n\nStatus ShapeShapeFn(InferenceContext* c) {\n  for (int i = 0; i < c->num_inputs(); ++i) {\n    DimensionHandle dim;\n    if (c->RankKnown(c->input(i))) {\n      dim = c->MakeDim(c->Rank(c->input(i)));\n    } else {\n      dim = c->UnknownDim();\n    }\n    c->set_output(i, c->Vector(dim));\n  }\n  return Status::OK();\n}\n\n}  // namespace\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"Shape\")\n    .Input(\"input: T\")\n    .Output(\"output: out_type\")\n    .Attr(\"T: type\")\n    .Attr(\"out_type: {int32, int64} = DT_INT32\")\n    .SetShapeFn(ShapeShapeFn);\n\nREGISTER_OP(\"ShapeN\")\n    .Input(\"input: N * T\")\n    .Output(\"output: N * out_type\")\n    .Attr(\"N: int\")\n    .Attr(\"T: type\")\n    .Attr(\"out_type: {int32, int64} = DT_INT32\")\n    .SetShapeFn(ShapeShapeFn);\n\nREGISTER_OP(\"EnsureShape\")\n    .Input(\"input: T\")\n    .Output(\"output: T\")\n    .Attr(\"shape: shape\")\n    .Attr(\"T: type\")\n    .SetShapeFn([](InferenceContext* c) {\n      // Merges desired shape and statically known shape of input\n      PartialTensorShape desired_shape;\n      TF_RETURN_IF_ERROR(c->GetAttr(\"shape\", &desired_shape));\n\n      int rank = desired_shape.dims();\n      ShapeHandle input_shape_handle;\n      ShapeHandle desired_shape_handle;\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(0), rank, &input_shape_handle));\n      TF_RETURN_IF_ERROR(c->MakeShapeFromPartialTensorShape(\n          desired_shape, &desired_shape_handle));\n\n      ShapeHandle merged_shape;\n      TF_RETURN_IF_ERROR(\n          c->Merge(desired_shape_handle, input_shape_handle, &merged_shape));\n      c->set_output(0, merged_shape);\n      return Status::OK();\n    });\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"ReverseSequence\")\n    .Input(\"input: T\")\n    .Input(\"seq_lengths: Tlen\")\n    .Output(\"output: T\")\n    .Attr(\"seq_dim: int\")\n    .Attr(\"batch_dim: int = 0\")\n    .Attr(\"T: type\")\n    .Attr(\"Tlen: {int32, int64} = DT_INT64\")\n    .SetShapeFn([](InferenceContext* c) {\n      ShapeHandle input = c->input(0);\n      ShapeHandle seq_lens_shape;\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(1), 1, &seq_lens_shape));\n\n      int64_t seq_dim;\n      TF_RETURN_IF_ERROR(c->GetAttr(\"seq_dim\", &seq_dim));\n      int64_t batch_dim;\n      TF_RETURN_IF_ERROR(c->GetAttr(\"batch_dim\", &batch_dim));\n\n      if (!c->RankKnown(input)) {\n        return shape_inference::UnknownShape(c);\n      }\n\n      // Validate batch_dim and seq_dim against input.\n      const int32_t input_rank = c->Rank(input);\n      if (batch_dim >= input_rank) {\n        return errors::InvalidArgument(\n            \"batch_dim must be < input rank: \", batch_dim, \" vs. \", input_rank);\n      }\n      if (seq_dim >= input_rank) {\n        return errors::InvalidArgument(\n            \"seq_dim must be < input rank: \", seq_dim, \" vs. \", input_rank);\n      }\n\n      DimensionHandle batch_dim_dim = c->Dim(input, batch_dim);\n      TF_RETURN_IF_ERROR(\n          c->Merge(batch_dim_dim, c->Dim(seq_lens_shape, 0), &batch_dim_dim));\n\n      // Replace batch_dim of input with batch_size\n      ShapeHandle output_shape;\n      TF_RETURN_IF_ERROR(\n          c->ReplaceDim(input, batch_dim, batch_dim_dim, &output_shape));\n      c->set_output(0, output_shape);\n      return Status::OK();\n    });\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"Rank\")\n    .Input(\"input: T\")\n    .Output(\"output: int32\")\n    .Attr(\"T: type\")\n    .SetShapeFn(shape_inference::ScalarShape);\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"Size\")\n    .Input(\"input: T\")\n    .Output(\"output: out_type\")\n    .Attr(\"T: type\")\n    .Attr(\"out_type: {int32, int64} = DT_INT32\")\n    .SetShapeFn(shape_inference::ScalarShape);\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"Slice\")\n    .Input(\"input: T\")\n    .Input(\"begin: Index\")\n    .Input(\"size: Index\")\n    .Output(\"output: T\")\n    .Attr(\"T: type\")\n    .Attr(\"Index: {int32,int64}\")\n    .SetShapeFn(shape_inference::SliceShape);\n\n#ifdef INTEL_MKL\nREGISTER_OP(\"_MklSlice\")\n    .Input(\"input: T\")\n    .Input(\"begin: Index\")\n    .Input(\"size: Index\")\n    .Input(\"mkl_input: uint8\")\n    .Input(\"mkl_begin: uint8\")\n    .Input(\"mkl_size: uint8\")\n    .Output(\"output: T\")\n    .Output(\"mkl_output: uint8\")\n    .Attr(\"T: type\")\n    .Attr(\"Index: {int32,int64}\")\n    .SetShapeFn(shape_inference::SliceShape);\n#endif\n\nREGISTER_OP(\"StridedSlice\")\n    .Input(\"input: T\")\n    .Input(\"begin: Index\")\n    .Input(\"end: Index\")\n    .Input(\"strides: Index\")\n    .Output(\"output: T\")\n    .Attr(\"T: type\")\n    .Attr(\"Index: {int32, int64}\")\n    .Attr(\"begin_mask: int = 0\")\n    .Attr(\"end_mask: int = 0\")\n    .Attr(\"ellipsis_mask: int = 0\")\n    .Attr(\"new_axis_mask: int = 0\")\n    .Attr(\"shrink_axis_mask: int = 0\")\n    .SetShapeFn([](InferenceContext* c) {\n      ShapeHandle input = c->input(0);\n      ShapeHandle begin_shape, end_shape, strides_shape;\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(1), 1, &begin_shape));\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(2), 1, &end_shape));\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(3), 1, &strides_shape));\n      TF_RETURN_IF_ERROR(c->Merge(begin_shape, end_shape, &begin_shape));\n      TF_RETURN_IF_ERROR(c->Merge(begin_shape, strides_shape, &begin_shape));\n      DimensionHandle sparse_dims_dim = c->Dim(begin_shape, 0);\n\n      const Tensor* strides_value = c->input_tensor(3);\n      // TODO(aselle,allenl): If we had a stride_mask it would be possible to do\n      // more shape inference here (e.g. for x[3, ::T]).\n      if (!c->RankKnown(input) || !c->ValueKnown(sparse_dims_dim) ||\n          strides_value == nullptr) {\n        c->set_output(0, c->UnknownShape());\n        return Status::OK();\n      }\n\n      PartialTensorShape input_shape({});\n      for (int i = 0; i < c->Rank(input); ++i) {\n        auto dim = c->Dim(input, i);\n        input_shape.AddDim(c->ValueKnown(dim) ? c->Value(dim) : -1);\n      }\n\n      int32_t begin_mask, end_mask, ellipsis_mask, new_axis_mask,\n          shrink_axis_mask;\n      TF_RETURN_IF_ERROR(c->GetAttr(\"begin_mask\", &begin_mask));\n      TF_RETURN_IF_ERROR(c->GetAttr(\"end_mask\", &end_mask));\n      TF_RETURN_IF_ERROR(c->GetAttr(\"ellipsis_mask\", &ellipsis_mask));\n      TF_RETURN_IF_ERROR(c->GetAttr(\"new_axis_mask\", &new_axis_mask));\n      TF_RETURN_IF_ERROR(c->GetAttr(\"shrink_axis_mask\", &shrink_axis_mask));\n\n      const Tensor* begin_value = c->input_tensor(1);\n      const Tensor* end_value = c->input_tensor(2);\n\n      PartialTensorShape processing_shape, final_shape;\n      bool is_identity, is_simple_slice, slice_dim0;\n      gtl::InlinedVector<int64, 4> begin, end, strides;\n      TF_RETURN_IF_ERROR(ValidateStridedSliceOp(\n          begin_value, end_value, *strides_value, input_shape, begin_mask,\n          end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask,\n          &processing_shape, &final_shape, &is_identity, &is_simple_slice,\n          &slice_dim0, &begin, &end, &strides));\n\n      ShapeHandle out;\n      TF_RETURN_IF_ERROR(c->MakeShapeFromPartialTensorShape(final_shape, &out));\n      c->set_output(0, out);\n\n      auto* shape_and_type = c->input_handle_shapes_and_types(0);\n      if (shape_and_type) {\n        c->set_output_handle_shapes_and_types(0, *shape_and_type);\n      }\n\n      return Status::OK();\n    });\n\nREGISTER_OP(\"StridedSliceGrad\")\n    .Input(\"shape: Index\")\n    .Input(\"begin: Index\")\n    .Input(\"end: Index\")\n    .Input(\"strides: Index\")\n    .Input(\"dy: T\")\n    .Output(\"output: T\")\n    .Attr(\"T: type\")\n    .Attr(\"Index: {int32, int64}\")\n    .Attr(\"begin_mask: int = 0\")\n    .Attr(\"end_mask: int = 0\")\n    .Attr(\"ellipsis_mask: int = 0\")\n    .Attr(\"new_axis_mask: int = 0\")\n    .Attr(\"shrink_axis_mask: int = 0\")\n    .SetShapeFn([](InferenceContext* c) {\n      ShapeHandle out;\n      TF_RETURN_IF_ERROR(c->MakeShapeFromShapeTensor(0, &out));\n      c->set_output(0, out);\n      return Status::OK();\n    });\n\nREGISTER_OP(\"StridedSliceAssign\")\n    .Input(\"ref: Ref(T)\")\n    .Input(\"begin: Index\")\n    .Input(\"end: Index\")\n    .Input(\"strides: Index\")\n    .Input(\"value: T\")\n    .Output(\"output_ref: Ref(T)\")\n    .Attr(\"T: type\")\n    .Attr(\"Index: {int32, int64}\")\n    .Attr(\"begin_mask: int = 0\")\n    .Attr(\"end_mask: int = 0\")\n    .Attr(\"ellipsis_mask: int = 0\")\n    .Attr(\"new_axis_mask: int = 0\")\n    .Attr(\"shrink_axis_mask: int = 0\")\n    .SetShapeFn(shape_inference::UnchangedShape);\n// TODO(aselle): Fix this documentation once StridedSliceAssign Supports\n// broadcasting.\n// --------------------------------------------------------------------------\n\nREGISTER_OP(\"ResourceStridedSliceAssign\")\n    .Input(\"ref: resource\")\n    .Input(\"begin: Index\")\n    .Input(\"end: Index\")\n    .Input(\"strides: Index\")\n    .Input(\"value: T\")\n    .Attr(\"T: type\")\n    .Attr(\"Index: {int32, int64}\")\n    .Attr(\"begin_mask: int = 0\")\n    .Attr(\"end_mask: int = 0\")\n    .Attr(\"ellipsis_mask: int = 0\")\n    .Attr(\"new_axis_mask: int = 0\")\n    .Attr(\"shrink_axis_mask: int = 0\")\n    .SetShapeFn(shape_inference::NoOutputs);\n\nREGISTER_OP(\"TensorStridedSliceUpdate\")\n    .Input(\"input: T\")\n    .Input(\"begin: Index\")\n    .Input(\"end: Index\")\n    .Input(\"strides: Index\")\n    .Input(\"value: T\")\n    .Output(\"output: T\")\n    .Attr(\"T: type\")\n    .Attr(\"Index: {int32, int64}\")\n    .Attr(\"begin_mask: int = 0\")\n    .Attr(\"end_mask: int = 0\")\n    .Attr(\"ellipsis_mask: int = 0\")\n    .Attr(\"new_axis_mask: int = 0\")\n    .Attr(\"shrink_axis_mask: int = 0\")\n    .SetShapeFn(shape_inference::UnchangedShape);\n\nREGISTER_OP(\"Tile\")\n    .Input(\"input: T\")\n    .Input(\"multiples: Tmultiples\")\n    .Output(\"output: T\")\n    .Attr(\"T: type\")\n    .Attr(\"Tmultiples: {int32, int64} = DT_INT32\")\n    .SetShapeFn([](InferenceContext* c) {\n      ShapeHandle input = c->input(0);\n      // NOTE(mrry): Represent `multiples` as a `TensorShape` because (i)\n      // it is a vector of non-negative integers, and (ii) doing so allows\n      // us to handle partially-known multiples.\n      ShapeHandle multiples;\n      TF_RETURN_IF_ERROR(c->MakeShapeFromShapeTensor(1, &multiples));\n      if (c->RankKnown(input)) {\n        TF_RETURN_IF_ERROR(c->WithRank(multiples, c->Rank(input), &multiples));\n        ShapeHandle dummy;\n        TF_RETURN_IF_ERROR(\n            c->Merge(c->input(1), c->Vector(c->Rank(input)), &dummy));\n      }\n\n      if (!c->RankKnown(multiples)) {\n        return shape_inference::UnknownShape(c);\n      }\n\n      int32_t rank = c->Rank(multiples);\n      TF_RETURN_IF_ERROR(c->WithRank(input, rank, &input));\n      std::vector<DimensionHandle> dims(rank);\n      for (int i = 0; i < rank; ++i) {\n        TF_RETURN_IF_ERROR(\n            c->Multiply(c->Dim(input, i), c->Dim(multiples, i), &dims[i]));\n      }\n      c->set_output(0, c->MakeShape(dims));\n      return Status::OK();\n    });\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"TileGrad\")\n    .Input(\"input: T\")\n    .Input(\"multiples: int32\")\n    .Output(\"output: T\")\n    .Attr(\"T: type\")\n    .Deprecated(3, \"TileGrad has been replaced with reduce_sum\")\n    .SetShapeFn(tensorflow::shape_inference::UnknownShape);\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"Where\")\n    .Input(\"input: T\")\n    .Attr(\"T: {numbertype, bool} = DT_BOOL\")\n    .Output(\"index: int64\")\n    .SetShapeFn([](InferenceContext* c) {\n      c->set_output(0, c->Matrix(c->UnknownDim(), c->Rank(c->input(0))));\n      return Status::OK();\n    });\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"BroadcastArgs\")\n    .Input(\"s0: T\")\n    .Input(\"s1: T\")\n    .Output(\"r0: T\")\n    .Attr(\"T: {int32, int64} = DT_INT32\")\n    .SetShapeFn([](InferenceContext* c) {\n      ShapeHandle unused;\n      ShapeHandle shape_x = c->input(0);\n      ShapeHandle shape_y = c->input(1);\n      TF_RETURN_IF_ERROR(c->WithRank(shape_x, 1, &unused));\n      TF_RETURN_IF_ERROR(c->WithRank(shape_y, 1, &unused));\n\n      if (!c->ValueKnown(c->Dim(shape_x, 0)) ||\n          !c->ValueKnown(c->Dim(shape_y, 0))) {\n        c->set_output(0, c->Vector(InferenceContext::kUnknownDim));\n        return Status::OK();\n      }\n\n      int64_t x_dim = c->Value(c->Dim(shape_x, 0));\n      int64_t y_dim = c->Value(c->Dim(shape_y, 0));\n\n      // Broadcasted shape is going to be as large as the largest dimension.\n      c->set_output(0, c->Vector(std::max(x_dim, y_dim)));\n      return Status::OK();\n    });\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"BroadcastGradientArgs\")\n    .Input(\"s0: T\")\n    .Input(\"s1: T\")\n    .Output(\"r0: T\")\n    .Output(\"r1: T\")\n    .Attr(\"T: {int32, int64} = DT_INT32\")\n    .SetShapeFn([](InferenceContext* c) {\n      // TODO(mrry): Implement constant_value for BroadcastGradientArgs?\n      ShapeHandle unused;\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(0), 1, &unused));\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(1), 1, &unused));\n      c->set_output(0, c->Vector(InferenceContext::kUnknownDim));\n      c->set_output(1, c->Vector(InferenceContext::kUnknownDim));\n      return Status::OK();\n    });\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"Pad\")\n    .Input(\"input: T\")\n    .Input(\"paddings: Tpaddings\")\n    .Output(\"output: T\")\n    .Attr(\"T: type\")\n    .Attr(\"Tpaddings: {int32, int64} = DT_INT32\")\n    .SetShapeFn(PadShapeFn);\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"PadV2\")\n    .Input(\"input: T\")\n    .Input(\"paddings: Tpaddings\")\n    .Input(\"constant_values: T\")\n    .Output(\"output: T\")\n    .Attr(\"T: type\")\n    .Attr(\"Tpaddings: {int32, int64} = DT_INT32\")\n    .SetShapeFn(PadShapeFn);\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"MirrorPad\")\n    .Input(\"input: T\")\n    .Input(\"paddings: Tpaddings\")\n    .Output(\"output: T\")\n    .Attr(\"T: type\")\n    .Attr(\"Tpaddings: {int32, int64} = DT_INT32\")\n    .Attr(GetMirrorPadModeAttrString())\n    .SetShapeFn(PadShapeFn);\n\n// --------------------------------------------------------------------------\nnamespace {\ntemplate <typename T>\nStatus MirrorPadKnown(InferenceContext* c, ShapeHandle input,\n                      const Tensor* paddings_t, int64_t input_rank) {\n  auto paddings_data = paddings_t->matrix<T>();\n  std::vector<DimensionHandle> dims(input_rank);\n  for (int64_t i = 0; i < input_rank; ++i) {\n    const int64_t pad0 = static_cast<int64_t>(paddings_data(i, 0));\n    const int64_t pad1 = static_cast<int64_t>(paddings_data(i, 1));\n    if (pad0 < 0 || pad1 < 0) {\n      return errors::InvalidArgument(\"Paddings must be non-negative\");\n    }\n\n    TF_RETURN_IF_ERROR(c->Subtract(c->Dim(input, i), pad0 + pad1, &dims[i]));\n  }\n  c->set_output(0, c->MakeShape(dims));\n  return Status::OK();\n}\n\n}  // namespace\n\nREGISTER_OP(\"MirrorPadGrad\")\n    .Input(\"input: T\")\n    .Input(\"paddings: Tpaddings\")\n    .Output(\"output: T\")\n    .Attr(\"T: type\")\n    .Attr(\"Tpaddings: {int32, int64} = DT_INT32\")\n    .Attr(GetMirrorPadModeAttrString())\n    .SetShapeFn([](InferenceContext* c) {\n      ShapeHandle paddings;\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(1), 2, &paddings));\n      DimensionHandle pad_0 = c->Dim(paddings, 0);\n      if (!c->ValueKnown(pad_0)) {\n        // We don't know the rank of the output since the first\n        // padding dimension is unknown.\n        c->set_output(0, c->UnknownShape());\n        return Status::OK();\n      }\n\n      int64_t input_rank = c->Value(pad_0);\n      ShapeHandle input;\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(0), input_rank, &input));\n      TF_RETURN_IF_ERROR(\n          c->Merge(paddings, c->Matrix(input_rank, 2), &paddings));\n\n      const Tensor* paddings_t = c->input_tensor(1);\n      if (paddings_t == nullptr) {\n        // Values of 'paddings' is not available, but we know the\n        // input rank, so return the rank of the output with unknown\n        // dimensions.\n        c->set_output(0, c->UnknownShapeOfRank(input_rank));\n        return Status::OK();\n      }\n\n      if (paddings_t->dtype() == DT_INT32) {\n        return MirrorPadKnown<int32>(c, input, paddings_t, input_rank);\n      } else {\n        return MirrorPadKnown<int64_t>(c, input, paddings_t, input_rank);\n      }\n    });\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"Placeholder\")\n    .Output(\"output: dtype\")\n    .Attr(\"dtype: type\")\n    .Attr(\"shape: shape = { unknown_rank: true }\")\n    .SetShapeFn([](InferenceContext* c) {\n      PartialTensorShape shape;\n      TF_RETURN_IF_ERROR(c->GetAttr(\"shape\", &shape));\n\n      // Placeholder has legacy behavior where we cannot tell the difference\n      // between a scalar shape attribute and 'unknown shape'.  So if the shape\n      // is a scalar, we return an unknown shape.\n      if (c->graph_def_version() <= 21 && shape.dims() <= 0) {\n        return shape_inference::UnknownShape(c);\n      }\n\n      ShapeHandle out;\n      TF_RETURN_IF_ERROR(c->MakeShapeFromPartialTensorShape(shape, &out));\n      c->set_output(0, out);\n      return Status::OK();\n    });\n\n// Placeholder was modified in a backwards compatible way to do what\n// PlaceholderV2 did, so we have deprecated V2 (no one was really\n// using it).\nREGISTER_OP(\"PlaceholderV2\")\n    .Output(\"output: dtype\")\n    .Attr(\"dtype: type\")\n    .Attr(\"shape: shape\")\n    .SetShapeFn(shape_inference::ExplicitShape)\n    .Deprecated(23, \"Placeholder now behaves the same as PlaceholderV2.\");\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"PlaceholderWithDefault\")\n    .Input(\"input: dtype\")\n    .Output(\"output: dtype\")\n    .Attr(\"dtype: type\")\n    .Attr(\"shape: shape\")\n    .SetShapeFn([](InferenceContext* c) {\n      ShapeHandle input = c->input(0);\n      PartialTensorShape shape;\n      TF_RETURN_IF_ERROR(c->GetAttr(\"shape\", &shape));\n      ShapeHandle out;\n      TF_RETURN_IF_ERROR(c->MakeShapeFromPartialTensorShape(shape, &out));\n\n      // We merge for compatibility checking, but return the output,\n      // since output_shape may be less precise than input_shape.\n      ShapeHandle unused;\n      TF_RETURN_IF_ERROR(c->Merge(input, out, &unused));\n      c->set_output(0, out);\n      return Status::OK();\n    });\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"ExpandDims\")\n    .Input(\"input: T\")\n    .Input(\"dim: Tdim\")\n    .Output(\"output: T\")\n    .Attr(\"T: type\")\n    .Attr(\"Tdim: {int32, int64} = DT_INT32\")\n    .SetShapeFn([](InferenceContext* c) {\n      ShapeHandle input = c->input(0);\n\n      const Tensor* dim_t = c->input_tensor(1);\n      if (dim_t != nullptr && dim_t->NumElements() != 1) {\n        return errors::InvalidArgument(\n            \"'dim' input must be a tensor with a single value\");\n      }\n      if (dim_t == nullptr || !c->RankKnown(input)) {\n        c->set_output(0, c->UnknownShape());\n        return Status::OK();\n      }\n\n      int64_t dim;\n      if (dim_t->dtype() == DT_INT32) {\n        dim = static_cast<int64_t>(dim_t->flat<int32>()(0));\n      } else {\n        dim = dim_t->flat<int64_t>()(0);\n      }\n\n      const int32_t rank = c->Rank(input);\n      const int32_t min_dim = -1 * rank - 1;\n      if (dim < min_dim || dim > rank) {\n        return errors::InvalidArgument(\"dim \", dim, \" not in the interval [\",\n                                       min_dim, \", \", rank, \"].\");\n      }\n\n      if (dim < 0) {\n        dim += rank + 1;\n      }\n\n      ShapeHandle end;\n      TF_RETURN_IF_ERROR(c->Subshape(input, dim, &end));\n\n      // Build output as start + 1 + end.\n      ShapeHandle output;\n      TF_RETURN_IF_ERROR(c->Subshape(input, 0, dim, &output));\n      TF_RETURN_IF_ERROR(c->Concatenate(output, c->Vector(1), &output));\n      TF_RETURN_IF_ERROR(c->Concatenate(output, end, &output));\n      c->set_output(0, output);\n      return Status::OK();\n    });\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"Squeeze\")\n    .Input(\"input: T\")\n    .Output(\"output: T\")\n    .Attr(\"T: type\")\n    .Attr(\"squeeze_dims: list(int) >= 0 = []\")\n    .SetShapeFn([](InferenceContext* c) {\n      ShapeHandle input = c->input(0);\n      if (!c->RankKnown(input)) {\n        // Input shape unknown.\n        return shape_inference::UnknownShape(c);\n      }\n\n      const int32_t input_rank = c->Rank(input);\n\n      // Validate and wrap squeeze dimensions.\n      std::vector<int32> squeeze_dims;\n      TF_RETURN_IF_ERROR(c->GetAttr(\"squeeze_dims\", &squeeze_dims));\n      for (int i = 0; i < squeeze_dims.size(); ++i) {\n        if (squeeze_dims[i] < -input_rank || squeeze_dims[i] >= input_rank) {\n          return errors::InvalidArgument(\"squeeze_dims[\", i, \"] not in [\",\n                                         -input_rank, \",\", input_rank, \").\");\n        }\n\n        if (squeeze_dims[i] < 0) {\n          squeeze_dims[i] += input_rank;\n        }\n      }\n\n      std::vector<DimensionHandle> result_shape;\n      for (int i = 0; i < input_rank; ++i) {\n        // True if squeeze_dims contains an entry to squeeze this\n        // dimension.\n        bool is_explicit_match =\n            std::find(squeeze_dims.begin(), squeeze_dims.end(), i) !=\n            squeeze_dims.end();\n\n        DimensionHandle dim = c->Dim(input, i);\n\n        if (!c->ValueKnown(dim)) {\n          // Assume that the squeezed dimension will be 1 at runtime.\n          if (is_explicit_match) continue;\n\n          // If squeezing all 1 dimensions, and we see an unknown value,\n          // give up and return Unknown Shape.\n          if (squeeze_dims.empty()) {\n            c->set_output(0, c->UnknownShape());\n            return Status::OK();\n          }\n        } else if (c->Value(dim) == 1) {\n          if (is_explicit_match || squeeze_dims.empty()) {\n            // If explicitly squeezing, or squeezing all 1s, remove\n            // this dimension.\n            continue;\n          }\n        } else if (is_explicit_match) {\n          return errors::InvalidArgument(\"Can not squeeze dim[\", i,\n                                         \"], expected a dimension of 1, got \",\n                                         c->Value(c->Dim(input, i)));\n        }\n\n        result_shape.emplace_back(dim);\n      }\n\n      c->set_output(0, c->MakeShape(result_shape));\n      return Status::OK();\n    });\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"ListDiff\")\n    .Input(\"x: T\")\n    .Input(\"y: T\")\n    .Output(\"out: T\")\n    .Output(\"idx: out_idx\")\n    .Attr(\"T: type\")\n    .Attr(\"out_idx: {int32, int64} = DT_INT32\")\n    .SetShapeFn([](InferenceContext* c) {\n      ShapeHandle unused;\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(0), 1, &unused));\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(1), 1, &unused));\n      // TODO(mrry): Indicate that the length falls within an interval?\n      ShapeHandle out = c->Vector(InferenceContext::kUnknownDim);\n      c->set_output(0, out);\n      c->set_output(1, out);\n      return Status::OK();\n    });\n\nnamespace {\n\n// Converts Tensor to flat std::vector<int64_t>.\ntemplate <typename InputType>\nstd::vector<int64_t> GetFlatInt64(const Tensor& t) {\n  std::vector<int64_t> output(t.shape().num_elements());\n  if (t.shape().num_elements() > 0) {\n    auto eigen_vec = t.flat<InputType>();\n    std::copy_n(&eigen_vec(0), output.size(), output.begin());\n  }\n  return output;\n}\n\n// Converts int32 or int64 Tensor to flat std::vector<int64_t>.\nstd::vector<int64_t> GetFlatInt64(const Tensor& t) {\n  if (t.dtype() == DT_INT32) {\n    return GetFlatInt64<int32>(t);\n  } else {\n    return GetFlatInt64<int64_t>(t);\n  }\n}\n\nStatus SpaceToBatchShapeHelper(InferenceContext* c, ShapeHandle input_shape,\n                               ShapeHandle block_shape_shape,\n                               const Tensor* block_shape_t,\n                               ShapeHandle paddings_shape,\n                               const Tensor* paddings_t) {\n  if (c->Rank(block_shape_shape) != 1) {\n    return errors::InvalidArgument(\"block_shape must have rank 1.\");\n  }\n\n  const DimensionHandle num_block_dims_handle = c->Dim(block_shape_shape, 0);\n  if (!c->ValueKnown(num_block_dims_handle)) {\n    return errors::InvalidArgument(\"block_shape must have known size.\");\n  }\n\n  const int64_t num_block_dims = c->Value(num_block_dims_handle);\n\n  TF_RETURN_IF_ERROR(\n      c->WithRankAtLeast(input_shape, num_block_dims + 1, &input_shape));\n\n  TF_RETURN_IF_ERROR(\n      c->Merge(paddings_shape, c->Matrix(num_block_dims, 2), &paddings_shape));\n\n  DimensionHandle batch_size = c->Dim(input_shape, 0);\n  std::vector<int64_t> block_shape_vec;\n  if (block_shape_t && (block_shape_t->NumElements() > 0)) {\n    block_shape_vec = GetFlatInt64(*block_shape_t);\n    for (int64_t dim = 0; dim < num_block_dims; ++dim) {\n      const int64_t block_shape_value = block_shape_vec[dim];\n      if (block_shape_value < 1) {\n        return errors::InvalidArgument(\"block_shape must be positive\");\n      }\n      if (c->ValueKnown(batch_size)) {\n        TF_RETURN_IF_ERROR(\n            c->Multiply(batch_size, block_shape_value, &batch_size));\n      } else {\n        batch_size = c->UnknownDim();\n      }\n    }\n  } else if (num_block_dims > 0) {\n    batch_size = c->UnknownDim();\n  }\n\n  std::vector<DimensionHandle> output_dims{batch_size};\n  output_dims.resize(num_block_dims + 1, c->UnknownDim());\n\n  if (paddings_t && (paddings_t->NumElements() > 0)) {\n    const std::vector<int64_t> paddings_vec = GetFlatInt64(*paddings_t);\n    for (int64_t dim = 0; dim < num_block_dims; ++dim) {\n      const int64_t pad_start = paddings_vec[dim * 2],\n                    pad_end = paddings_vec[dim * 2 + 1];\n      if (pad_start < 0 || pad_end < 0) {\n        return errors::InvalidArgument(\"paddings cannot be negative\");\n      }\n      if (block_shape_t) {\n        DimensionHandle padded_size;\n        TF_RETURN_IF_ERROR(\n            c->Add(c->Dim(input_shape, dim + 1), pad_start, &padded_size));\n        TF_RETURN_IF_ERROR(c->Add(padded_size, pad_end, &padded_size));\n        TF_RETURN_IF_ERROR(c->Divide(padded_size, block_shape_vec[dim],\n                                     /*evenly_divisible=*/true,\n                                     &output_dims[dim + 1]));\n      }\n    }\n  }\n\n  ShapeHandle remaining_input_shape;\n  TF_RETURN_IF_ERROR(\n      c->Subshape(input_shape, 1 + num_block_dims, &remaining_input_shape));\n\n  ShapeHandle result;\n  TF_RETURN_IF_ERROR(c->Concatenate(c->MakeShape(output_dims),\n                                    remaining_input_shape, &result));\n  c->set_output(0, result);\n  return Status::OK();\n}\n\nStatus BatchToSpaceShapeHelper(InferenceContext* c, ShapeHandle input_shape,\n                               ShapeHandle block_shape_shape,\n                               const Tensor* block_shape_t,\n                               ShapeHandle crops_shape, const Tensor* crops_t) {\n  if (c->Rank(block_shape_shape) != 1) {\n    return errors::InvalidArgument(\"block_shape must have rank 1.\");\n  }\n\n  const DimensionHandle num_block_dims_handle = c->Dim(block_shape_shape, 0);\n  if (!c->ValueKnown(num_block_dims_handle)) {\n    return errors::InvalidArgument(\"block_shape must have known size.\");\n  }\n\n  const int64_t num_block_dims = c->Value(num_block_dims_handle);\n\n  TF_RETURN_IF_ERROR(\n      c->WithRankAtLeast(input_shape, num_block_dims + 1, &input_shape));\n\n  TF_RETURN_IF_ERROR(\n      c->Merge(crops_shape, c->Matrix(num_block_dims, 2), &crops_shape));\n\n  DimensionHandle batch_size = c->Dim(input_shape, 0);\n  std::vector<int64_t> block_shape_vec;\n  if (block_shape_t) {\n    block_shape_vec = GetFlatInt64(*block_shape_t);\n    for (int64_t dim = 0; dim < num_block_dims; ++dim) {\n      const int64_t block_shape_value = block_shape_vec[dim];\n      if (block_shape_value < 1) {\n        return errors::InvalidArgument(\"block_shape must be positive\");\n      }\n      if (c->ValueKnown(batch_size)) {\n        TF_RETURN_IF_ERROR(c->Divide(batch_size, block_shape_value,\n                                     /*evenly_divisible=*/true, &batch_size));\n      } else {\n        batch_size = c->UnknownDim();\n      }\n    }\n  } else if (num_block_dims > 0) {\n    batch_size = c->UnknownDim();\n  }\n\n  std::vector<DimensionHandle> output_dims{batch_size};\n  output_dims.resize(num_block_dims + 1, c->UnknownDim());\n\n  if (crops_t) {\n    const std::vector<int64_t> crops_vec = GetFlatInt64(*crops_t);\n    for (int64_t dim = 0; dim < num_block_dims; ++dim) {\n      const int64_t crop_start = crops_vec[dim * 2],\n                    crop_end = crops_vec[dim * 2 + 1];\n      if (crop_start < 0 || crop_end < 0) {\n        return errors::InvalidArgument(\"crops cannot be negative\");\n      }\n      if (block_shape_t) {\n        DimensionHandle cropped_size;\n        TF_RETURN_IF_ERROR(c->Multiply(c->Dim(input_shape, dim + 1),\n                                       block_shape_vec[dim], &cropped_size));\n        TF_RETURN_IF_ERROR(\n            c->Subtract(cropped_size, crop_start, &cropped_size));\n        TF_RETURN_IF_ERROR(\n            c->Subtract(cropped_size, crop_end, &output_dims[dim + 1]));\n      }\n    }\n  }\n\n  ShapeHandle remaining_input_shape;\n  TF_RETURN_IF_ERROR(\n      c->Subshape(input_shape, 1 + num_block_dims, &remaining_input_shape));\n\n  ShapeHandle result;\n  TF_RETURN_IF_ERROR(c->Concatenate(c->MakeShape(output_dims),\n                                    remaining_input_shape, &result));\n  c->set_output(0, result);\n  return Status::OK();\n}\n\n}  // namespace\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"SpaceToBatchND\")\n    .Input(\"input: T\")\n    .Input(\"block_shape: Tblock_shape\")\n    .Input(\"paddings: Tpaddings\")\n    .Output(\"output: T\")\n    .Attr(\"T: type\")\n    .Attr(\"Tblock_shape: {int32, int64} = DT_INT32\")\n    .Attr(\"Tpaddings: {int32, int64} = DT_INT32\")\n    .SetShapeFn([](InferenceContext* c) {\n      return SpaceToBatchShapeHelper(c, c->input(0), c->input(1),\n                                     c->input_tensor(1), c->input(2),\n                                     c->input_tensor(2));\n    });\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"SpaceToBatch\")\n    .Input(\"input: T\")\n    .Input(\"paddings: Tpaddings\")\n    .Output(\"output: T\")\n    .Attr(\"T: type\")\n    .Attr(\"Tpaddings: {int32, int64} = DT_INT32\")\n    .Attr(\"block_size: int >= 2\")\n    .SetShapeFn([](InferenceContext* c) {\n      ShapeHandle input_shape;\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(0), 4, &input_shape));\n\n      int32_t block_size;\n      TF_RETURN_IF_ERROR(c->GetAttr(\"block_size\", &block_size));\n\n      Tensor block_shape(tensorflow::DT_INT64, TensorShape({2}));\n      auto block_shape_vec = block_shape.vec<int64_t>();\n      block_shape_vec(0) = block_size;\n      block_shape_vec(1) = block_size;\n\n      return SpaceToBatchShapeHelper(c, input_shape, c->MakeShape({2}),\n                                     &block_shape, c->input(1),\n                                     c->input_tensor(1));\n    });\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"BatchToSpaceND\")\n    .Input(\"input: T\")\n    .Input(\"block_shape: Tblock_shape\")\n    .Input(\"crops: Tcrops\")\n    .Output(\"output: T\")\n    .Attr(\"T: type\")\n    .Attr(\"Tblock_shape: {int32, int64} = DT_INT32\")\n    .Attr(\"Tcrops: {int32, int64} = DT_INT32\")\n    .SetShapeFn([](InferenceContext* c) {\n      return BatchToSpaceShapeHelper(c, c->input(0), c->input(1),\n                                     c->input_tensor(1), c->input(2),\n                                     c->input_tensor(2));\n    });\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"BatchToSpace\")\n    .Input(\"input: T\")\n    .Input(\"crops: Tidx\")\n    .Output(\"output: T\")\n    .Attr(\"T: type\")\n    .Attr(\"block_size: int >= 2\")\n    .Attr(\"Tidx: {int32, int64} = DT_INT32\")\n    .SetShapeFn([](InferenceContext* c) {\n      ShapeHandle input_shape;\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(0), 4, &input_shape));\n\n      int32_t block_size;\n      TF_RETURN_IF_ERROR(c->GetAttr(\"block_size\", &block_size));\n\n      Tensor block_shape(tensorflow::DT_INT64, TensorShape({2}));\n      auto block_shape_vec = block_shape.vec<int64_t>();\n      block_shape_vec(0) = block_size;\n      block_shape_vec(1) = block_size;\n\n      return BatchToSpaceShapeHelper(c, input_shape, c->MakeShape({2}),\n                                     &block_shape, c->input(1),\n                                     c->input_tensor(1));\n    });\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"SpaceToDepth\")\n    .Input(\"input: T\")\n    .Output(\"output: T\")\n    .Attr(\"T: type\")\n    .Attr(\"block_size: int >= 2\")\n    .Attr(\"data_format: {'NHWC', 'NCHW', 'NCHW_VECT_C'} = 'NHWC'\")\n    // TODO(pauldonnelly): Implement GPU kernels for NCHW_VECT_C.\n    .SetShapeFn([](InferenceContext* c) {\n      string data_format_str;\n      TF_RETURN_IF_ERROR(c->GetAttr(\"data_format\", &data_format_str));\n      TensorFormat data_format;\n      FormatFromString(data_format_str, &data_format);\n\n      constexpr int num_spatial_dims = 2;\n      const int dims =\n          GetTensorDimsFromSpatialDims(num_spatial_dims, data_format);\n      ShapeHandle input;\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(0), dims, &input));\n\n      int32_t block_size;\n      TF_RETURN_IF_ERROR(c->GetAttr(\"block_size\", &block_size));\n\n      DimensionHandle batch_size =\n          c->Dim(input, GetTensorDimIndex<num_spatial_dims>(data_format, 'N'));\n      DimensionHandle input_height =\n          c->Dim(input, GetTensorDimIndex<num_spatial_dims>(data_format, 'H'));\n      DimensionHandle input_width =\n          c->Dim(input, GetTensorDimIndex<num_spatial_dims>(data_format, 'W'));\n      DimensionHandle input_depth =\n          c->Dim(input, GetTensorDimIndex<num_spatial_dims>(data_format, 'C'));\n\n      DimensionHandle output_height;\n      DimensionHandle output_width;\n      DimensionHandle output_depth;\n      // Will return an error if input height or width are not evenly divisible.\n      TF_RETURN_IF_ERROR(c->Divide(input_height, block_size,\n                                   true /* evenly_divisible */,\n                                   &output_height));\n      TF_RETURN_IF_ERROR(c->Divide(input_width, block_size,\n                                   true /* evenly_divisible */, &output_width));\n\n      TF_RETURN_IF_ERROR(\n          c->Multiply(input_depth, block_size * block_size, &output_depth));\n\n      ShapeHandle output_shape;\n      TF_RETURN_IF_ERROR(MakeShapeFromFormat(data_format, batch_size,\n                                             {output_height, output_width},\n                                             output_depth, &output_shape, c));\n\n      c->set_output(0, output_shape);\n      return Status::OK();\n    });\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"DepthToSpace\")\n    .Input(\"input: T\")\n    .Output(\"output: T\")\n    .Attr(\"T: type\")\n    .Attr(\"block_size: int >= 2\")\n    .Attr(\"data_format: {'NHWC', 'NCHW', 'NCHW_VECT_C'} = 'NHWC'\")\n    // TODO(pauldonnelly): Implement GPU kernels for NCHW and NCHW_VECT_C.\n    .SetShapeFn([](InferenceContext* c) {\n      string data_format_str;\n      TF_RETURN_IF_ERROR(c->GetAttr(\"data_format\", &data_format_str));\n      TensorFormat data_format;\n      FormatFromString(data_format_str, &data_format);\n\n      constexpr int num_spatial_dims = 2;\n      const int dims =\n          GetTensorDimsFromSpatialDims(num_spatial_dims, data_format);\n\n      ShapeHandle input;\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(0), dims, &input));\n\n      int32_t block_size;\n      TF_RETURN_IF_ERROR(c->GetAttr(\"block_size\", &block_size));\n\n      DimensionHandle batch_size =\n          c->Dim(input, GetTensorDimIndex<num_spatial_dims>(data_format, 'N'));\n      DimensionHandle input_height =\n          c->Dim(input, GetTensorDimIndex<num_spatial_dims>(data_format, 'H'));\n      DimensionHandle input_width =\n          c->Dim(input, GetTensorDimIndex<num_spatial_dims>(data_format, 'W'));\n      DimensionHandle input_depth =\n          c->Dim(input, GetTensorDimIndex<num_spatial_dims>(data_format, 'C'));\n\n      DimensionHandle output_height;\n      DimensionHandle output_width;\n      DimensionHandle output_depth;\n      TF_RETURN_IF_ERROR(c->Multiply(input_height, block_size, &output_height));\n      TF_RETURN_IF_ERROR(c->Multiply(input_width, block_size, &output_width));\n\n      // Will return an error if input_depth is not evenly divisible.\n      TF_RETURN_IF_ERROR(c->Divide(input_depth, block_size * block_size,\n                                   true /* evenly_divisible */, &output_depth));\n\n      ShapeHandle output_shape;\n      TF_RETURN_IF_ERROR(MakeShapeFromFormat(data_format, batch_size,\n                                             {output_height, output_width},\n                                             output_depth, &output_shape, c));\n\n      c->set_output(0, output_shape);\n      return Status::OK();\n    });\n\n// --------------------------------------------------------------------------\n\nREGISTER_OP(\"ExtractImagePatches\")\n    .Input(\"images: T\")\n    .Output(\"patches: T\")\n    .Attr(\"ksizes: list(int) >= 4\")\n    .Attr(\"strides: list(int) >= 4\")\n    .Attr(\"rates: list(int) >= 4\")\n    .Attr(\n        \"T: {bfloat16, half, float, double, int8, int16, int32, int64, \"\n        \"uint8, uint16, uint32, uint64, complex64, complex128, bool}\")\n    .Attr(GetPaddingAttrString())\n    .SetShapeFn([](InferenceContext* c) {\n      ShapeHandle input_shape;\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(0), 4, &input_shape));\n\n      std::vector<int32> ksizes;\n      TF_RETURN_IF_ERROR(c->GetAttr(\"ksizes\", &ksizes));\n      if (ksizes.size() != 4) {\n        return errors::InvalidArgument(\n            \"ExtractImagePatches requires the ksizes attribute to contain 4 \"\n            \"values, but got: \",\n            ksizes.size());\n      }\n\n      std::vector<int32> strides;\n      TF_RETURN_IF_ERROR(c->GetAttr(\"strides\", &strides));\n      if (strides.size() != 4) {\n        return errors::InvalidArgument(\n            \"ExtractImagePatches requires the stride attribute to contain 4 \"\n            \"values, but got: \",\n            strides.size());\n      }\n\n      std::vector<int32> rates;\n      TF_RETURN_IF_ERROR(c->GetAttr(\"rates\", &rates));\n      if (rates.size() != 4) {\n        return errors::InvalidArgument(\n            \"ExtractImagePatches requires the rates attribute to contain 4 \"\n            \"values, but got: \",\n            rates.size());\n      }\n\n      int32_t ksize_rows = ksizes[1];\n      int32_t ksize_cols = ksizes[2];\n\n      int32_t stride_rows = strides[1];\n      int32_t stride_cols = strides[2];\n\n      int32_t rate_rows = rates[1];\n      int32_t rate_cols = rates[2];\n\n      int32_t ksize_rows_eff = ksize_rows + (ksize_rows - 1) * (rate_rows - 1);\n      int32_t ksize_cols_eff = ksize_cols + (ksize_cols - 1) * (rate_cols - 1);\n\n      DimensionHandle batch_size_dim = c->Dim(input_shape, 0);\n      DimensionHandle in_rows_dim = c->Dim(input_shape, 1);\n      DimensionHandle in_cols_dim = c->Dim(input_shape, 2);\n      DimensionHandle output_depth_dim;\n      TF_RETURN_IF_ERROR(c->Multiply(\n          c->Dim(input_shape, 3), ksize_rows * ksize_cols, &output_depth_dim));\n\n      if (!c->ValueKnown(in_rows_dim) || !c->ValueKnown(in_cols_dim)) {\n        ShapeHandle output_shape =\n            c->MakeShape({batch_size_dim, InferenceContext::kUnknownDim,\n                          InferenceContext::kUnknownDim, output_depth_dim});\n        c->set_output(0, output_shape);\n        return Status::OK();\n      }\n      auto in_rows = c->Value(in_rows_dim);\n      auto in_cols = c->Value(in_cols_dim);\n\n      Padding padding;\n      TF_RETURN_IF_ERROR(c->GetAttr(\"padding\", &padding));\n\n      int64_t output_rows, output_cols;\n      int64_t padding_before, padding_after;\n      TF_RETURN_IF_ERROR(GetWindowedOutputSizeVerbose(\n          in_rows, ksize_rows_eff, stride_rows, padding, &output_rows,\n          &padding_before, &padding_after));\n      TF_RETURN_IF_ERROR(GetWindowedOutputSizeVerbose(\n          in_cols, ksize_cols_eff, stride_cols, padding, &output_cols,\n          &padding_before, &padding_after));\n      ShapeHandle output_shape = c->MakeShape(\n          {batch_size_dim, output_rows, output_cols, output_depth_dim});\n      c->set_output(0, output_shape);\n      return Status::OK();\n    });\n\n// --------------------------------------------------------------------------\n\n// To enable rates, uncomment all lines commented below and use ksize_*_eff\n// as the second parameter of all GetWindowedOutputSizeVerbose calls instead\n// of ksize_*.\nREGISTER_OP(\"ExtractVolumePatches\")\n    .Input(\"input: T\")\n    .Output(\"patches: T\")\n    .Attr(\"ksizes: list(int) >= 5\")\n    .Attr(\"strides: list(int) >= 5\")\n    /* .Attr(\"rates: list(int) >= 5\") */\n    .Attr(\"T: realnumbertype\")\n    .Attr(GetPaddingAttrString())\n    .SetShapeFn([](InferenceContext* c) {\n      ShapeHandle input_shape;\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(0), 5, &input_shape));\n\n      std::vector<int32> ksizes;\n      TF_RETURN_IF_ERROR(c->GetAttr(\"ksizes\", &ksizes));\n      if (ksizes.size() != 5) {\n        return errors::InvalidArgument(\n            \"ExtractVolumePatches requires the ksizes attribute to contain 5 \"\n            \"values, but got: \",\n            ksizes.size());\n      }\n\n      std::vector<int32> strides;\n      TF_RETURN_IF_ERROR(c->GetAttr(\"strides\", &strides));\n      if (strides.size() != 5) {\n        return errors::InvalidArgument(\n            \"ExtractVolumePatches requires the stride attribute to contain 5 \"\n            \"values, but got: \",\n            strides.size());\n      }\n\n      /*\n      // TODO(hsgkim): Enable rates.\n      // See extract_volume_patches_op.cc for why rates are disabled now.\n\n      std::vector<int32> rates;\n      TF_RETURN_IF_ERROR(c->GetAttr(\"rates\", &rates));\n      if (rates.size() != 5) {\n        return errors::InvalidArgument(\n            \"ExtractVolumePatches requires the rates attribute to contain 5 \"\n            \"values, but got: \",\n            rates.size());\n      }\n      */\n\n      int32_t ksize_planes = ksizes[1];\n      int32_t ksize_rows = ksizes[2];\n      int32_t ksize_cols = ksizes[3];\n\n      int32_t stride_planes = strides[1];\n      int32_t stride_rows = strides[2];\n      int32_t stride_cols = strides[3];\n\n      /*\n      int32 rate_planes = rates[1];\n      int32 rate_rows = rates[2];\n      int32 rate_cols = rates[3];\n\n      int32 ksize_planes_eff = ksize_planes +\n                               (ksize_planes - 1) * (rate_planes - 1);\n      int32 ksize_rows_eff = ksize_rows + (ksize_rows - 1) * (rate_rows - 1);\n      int32 ksize_cols_eff = ksize_cols + (ksize_cols - 1) * (rate_cols - 1);\n      */\n\n      DimensionHandle batch_size_dim = c->Dim(input_shape, 0);\n      DimensionHandle in_planes_dim = c->Dim(input_shape, 1);\n      DimensionHandle in_rows_dim = c->Dim(input_shape, 2);\n      DimensionHandle in_cols_dim = c->Dim(input_shape, 3);\n      DimensionHandle output_depth_dim;\n      TF_RETURN_IF_ERROR(c->Multiply(c->Dim(input_shape, 4),\n                                     ksize_planes * ksize_rows * ksize_cols,\n                                     &output_depth_dim));\n\n      if (!c->ValueKnown(in_planes_dim) || !c->ValueKnown(in_rows_dim) ||\n          !c->ValueKnown(in_cols_dim)) {\n        ShapeHandle output_shape =\n            c->MakeShape({batch_size_dim, InferenceContext::kUnknownDim,\n                          InferenceContext::kUnknownDim, output_depth_dim});\n        c->set_output(0, output_shape);\n        return Status::OK();\n      }\n      auto in_planes = c->Value(in_planes_dim);\n      auto in_rows = c->Value(in_rows_dim);\n      auto in_cols = c->Value(in_cols_dim);\n\n      Padding padding;\n      TF_RETURN_IF_ERROR(c->GetAttr(\"padding\", &padding));\n\n      int64_t output_planes, output_rows, output_cols;\n      int64_t padding_before, padding_after;\n      TF_RETURN_IF_ERROR(GetWindowedOutputSizeVerbose(\n          in_planes, ksize_planes, stride_planes, padding, &output_planes,\n          &padding_before, &padding_after));\n      TF_RETURN_IF_ERROR(GetWindowedOutputSizeVerbose(\n          in_rows, ksize_rows, stride_rows, padding, &output_rows,\n          &padding_before, &padding_after));\n      TF_RETURN_IF_ERROR(GetWindowedOutputSizeVerbose(\n          in_cols, ksize_cols, stride_cols, padding, &output_cols,\n          &padding_before, &padding_after));\n      ShapeHandle output_shape =\n          c->MakeShape({batch_size_dim, output_planes, output_rows, output_cols,\n                        output_depth_dim});\n      c->set_output(0, output_shape);\n      return Status::OK();\n    });\n\n// --------------------------------------------------------------------------\n\nREGISTER_OP(\"OneHot\")\n    .Input(\"indices: TI\")\n    .Input(\"depth: int32\")\n    .Input(\"on_value: T\")\n    .Input(\"off_value: T\")\n    .Attr(\"axis: int = -1\")\n    .Output(\"output: T\")\n    .Attr(\"T: type\")\n    .Attr(\"TI: {uint8, int32, int64} = DT_INT64\")\n    .SetShapeFn([](InferenceContext* c) {\n      int32_t axis;\n      TF_RETURN_IF_ERROR(c->GetAttr(\"axis\", &axis));\n      if (axis < -1) return errors::InvalidArgument(\"axis must be >= -1\");\n\n      DimensionHandle depth;\n      TF_RETURN_IF_ERROR(c->MakeDimForScalarInput(1, &depth));\n\n      ShapeHandle indices = c->input(0);\n      if (!c->RankKnown(indices)) return shape_inference::UnknownShape(c);\n\n      int32_t new_rank = c->Rank(indices) + 1;\n      // We need to add new_rank to axis in the case the axis is -1 because\n      // C++ returns negative values from % if the dividend is negative.\n      int32_t depth_index = (axis + new_rank) % new_rank;\n      // Out shape is indices[0:depth_index] + [depth] + indices[depth_index:].\n      ShapeHandle front;\n      ShapeHandle back;\n      ShapeHandle out;\n      TF_RETURN_IF_ERROR(c->Subshape(indices, 0, depth_index, &front));\n      TF_RETURN_IF_ERROR(c->Subshape(indices, depth_index, &back));\n      TF_RETURN_IF_ERROR(c->Concatenate(front, c->Vector(depth), &front));\n      TF_RETURN_IF_ERROR(c->Concatenate(front, back, &out));\n      c->set_output(0, out);\n      return Status::OK();\n    });\n\n// EXPERIMENTAL. DO NOT USE OR DEPEND ON THIS YET.\nREGISTER_OP(\"QuantizeAndDequantize\")\n    .Input(\"input: T\")\n    .Attr(\"signed_input: bool = true\")\n    .Attr(\"num_bits: int = 8\")\n    .Attr(\"range_given: bool = false\")\n    .Attr(\"input_min: float = 0\")\n    .Attr(\"input_max: float = 0\")\n    .Output(\"output: T\")\n    .Attr(\"T: {bfloat16, half, float, double}\")\n    .SetShapeFn(shape_inference::UnchangedShape)\n    .Deprecated(22, \"Replaced by QuantizeAndDequantizeV2\");\n\n// TODO(suharshs): Deprecate QuantizeAndDequantizeV2.\nREGISTER_OP(\"QuantizeAndDequantizeV2\")\n    .Input(\"input: T\")\n    .Input(\"input_min: T\")\n    .Input(\"input_max: T\")\n    .Attr(\"signed_input: bool = true\")\n    .Attr(\"num_bits: int = 8\")\n    .Attr(\"range_given: bool = false\")\n    .Output(\"output: T\")\n    .Attr(\"T: {bfloat16, half, float, double}\")\n    .Attr(\n        \"round_mode: {'HALF_TO_EVEN', 'HALF_UP'} = \"\n        \"'HALF_TO_EVEN'\")\n    .Attr(\"narrow_range: bool = false\")\n    .Attr(\"axis: int = -1\")\n    .SetShapeFn([](InferenceContext* c) {\n      int axis;\n      TF_RETURN_IF_ERROR(c->GetAttr(\"axis\", &axis));\n      const int minmax_rank = (axis == -1) ? 0 : 1;\n      ShapeHandle minmax;\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(1), minmax_rank, &minmax));\n      TF_RETURN_IF_ERROR(c->Merge(c->input(2), minmax, &minmax));\n      if (axis != -1) {\n        ShapeHandle input;\n        TF_RETURN_IF_ERROR(c->WithRankAtLeast(c->input(0), axis + 1, &input));\n        DimensionHandle depth;\n        TF_RETURN_IF_ERROR(\n            c->Merge(c->Dim(minmax, 0), c->Dim(input, axis), &depth));\n      }\n      c->set_output(0, c->input(0));\n      return Status::OK();\n    });\n\nREGISTER_OP(\"QuantizeAndDequantizeV4\")\n    .Input(\"input: T\")\n    .Input(\"input_min: T\")\n    .Input(\"input_max: T\")\n    .Attr(\"signed_input: bool = true\")\n    .Attr(\"num_bits: int = 8\")\n    .Attr(\"range_given: bool = false\")\n    .Output(\"output: T\")\n    .Attr(\"T: {bfloat16, half, float, double}\")\n    .Attr(\n        \"round_mode: {'HALF_TO_EVEN', 'HALF_UP'} = \"\n        \"'HALF_TO_EVEN'\")\n    .Attr(\"narrow_range: bool = false\")\n    .Attr(\"axis: int = -1\")\n    .SetShapeFn([](InferenceContext* c) {\n      int axis;\n      TF_RETURN_IF_ERROR(c->GetAttr(\"axis\", &axis));\n      const int minmax_rank = (axis == -1) ? 0 : 1;\n      ShapeHandle minmax;\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(1), minmax_rank, &minmax));\n      TF_RETURN_IF_ERROR(c->Merge(c->input(2), minmax, &minmax));\n      if (axis != -1) {\n        ShapeHandle input;\n        TF_RETURN_IF_ERROR(c->WithRankAtLeast(c->input(0), axis + 1, &input));\n        DimensionHandle depth;\n        TF_RETURN_IF_ERROR(\n            c->Merge(c->Dim(minmax, 0), c->Dim(input, axis), &depth));\n      }\n      c->set_output(0, c->input(0));\n      return Status::OK();\n    });\n\nREGISTER_OP(\"QuantizeAndDequantizeV4Grad\")\n    .Input(\"gradients: T\")\n    .Input(\"input: T\")\n    .Input(\"input_min: T\")\n    .Input(\"input_max: T\")\n    .Output(\"input_backprop: T\")\n    .Output(\"input_min_backprop: T\")\n    .Output(\"input_max_backprop: T\")\n    .Attr(\"T: {bfloat16, half, float, double}\")\n    .Attr(\"axis: int = -1\")\n    .SetShapeFn([](InferenceContext* c) {\n      int axis;\n      TF_RETURN_IF_ERROR(c->GetAttr(\"axis\", &axis));\n      const int minmax_rank = (axis == -1) ? 0 : 1;\n      ShapeHandle minmax;\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(2), minmax_rank, &minmax));\n      TF_RETURN_IF_ERROR(c->Merge(c->input(3), minmax, &minmax));\n      if (axis != -1) {\n        ShapeHandle input;\n        TF_RETURN_IF_ERROR(c->WithRankAtLeast(c->input(0), axis + 1, &input));\n        DimensionHandle depth;\n        TF_RETURN_IF_ERROR(\n            c->Merge(c->Dim(minmax, 0), c->Dim(input, axis), &depth));\n      }\n      ShapeHandle inputs;\n      TF_RETURN_IF_ERROR(c->Merge(c->input(0), c->input(1), &inputs));\n      c->set_output(0, inputs);\n      c->set_output(1, minmax);\n      c->set_output(2, minmax);\n      return Status::OK();\n    });\n\nREGISTER_OP(\"QuantizeAndDequantizeV3\")\n    .Input(\"input: T\")\n    .Input(\"input_min: T\")\n    .Input(\"input_max: T\")\n    .Input(\"num_bits: int32\")\n    .Attr(\"signed_input: bool = true\")\n    .Attr(\"range_given: bool = true\")\n    .Output(\"output: T\")\n    .Attr(\"T: {bfloat16, half, float, double}\")\n    .Attr(\"narrow_range: bool = false\")\n    .Attr(\"axis: int = -1\")\n    .SetShapeFn([](InferenceContext* c) {\n      int axis;\n      TF_RETURN_IF_ERROR(c->GetAttr(\"axis\", &axis));\n      const int minmax_rank = (axis == -1) ? 0 : 1;\n      ShapeHandle minmax;\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(1), minmax_rank, &minmax));\n      TF_RETURN_IF_ERROR(c->Merge(c->input(2), minmax, &minmax));\n      if (axis != -1) {\n        ShapeHandle input;\n        TF_RETURN_IF_ERROR(c->WithRankAtLeast(c->input(0), axis + 1, &input));\n        DimensionHandle depth;\n        TF_RETURN_IF_ERROR(\n            c->Merge(c->Dim(minmax, 0), c->Dim(input, axis), &depth));\n      }\n      ShapeHandle unused;\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(3), 0, &unused));\n      c->set_output(0, c->input(0));\n      return Status::OK();\n    });\n\nREGISTER_OP(\"QuantizeV2\")\n    .Input(\"input: float\")\n    .Input(\"min_range: float\")\n    .Input(\"max_range: float\")\n    .Output(\"output: T\")\n    .Output(\"output_min: float\")\n    .Output(\"output_max: float\")\n    .Attr(\"T: quantizedtype\")\n    .Attr(\"mode: {'MIN_COMBINED', 'MIN_FIRST', 'SCALED'} = 'MIN_COMBINED'\")\n    .Attr(\n        \"round_mode: {'HALF_AWAY_FROM_ZERO', 'HALF_TO_EVEN'} = \"\n        \"'HALF_AWAY_FROM_ZERO'\")\n    .Attr(\"narrow_range: bool = false\")\n    .Attr(\"axis: int = -1\")\n    .Attr(\"ensure_minimum_range: float = 0.01\")\n    .SetShapeFn(shape_inference::QuantizeV2Shape);\n\nREGISTER_OP(\"Dequantize\")\n    .Input(\"input: T\")\n    .Input(\"min_range: float\")\n    .Input(\"max_range: float\")\n    .Output(\"output: dtype\")\n    .Attr(\"T: quantizedtype\")\n    .Attr(\"mode: {'MIN_COMBINED', 'MIN_FIRST', 'SCALED'} = 'MIN_COMBINED'\")\n    .Attr(\"narrow_range: bool = false\")\n    .Attr(\"axis: int = -1\")\n    .Attr(\"dtype: {bfloat16, float} = DT_FLOAT\")\n    .SetShapeFn([](InferenceContext* c) {\n      int axis = -1;\n      Status s = c->GetAttr(\"axis\", &axis);\n      if (!s.ok() && s.code() != error::NOT_FOUND) {\n        return s;\n      }\n      if (axis < -1) {\n        return errors::InvalidArgument(\"axis should be at least -1, got \",\n                                       axis);\n      }\n      const int minmax_rank = (axis == -1) ? 0 : 1;\n      TF_RETURN_IF_ERROR(shape_inference::UnchangedShape(c));\n      ShapeHandle minmax;\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(1), minmax_rank, &minmax));\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(2), minmax_rank, &minmax));\n      if (axis != -1) {\n        ShapeHandle input;\n        TF_RETURN_IF_ERROR(c->WithRankAtLeast(c->input(0), axis + 1, &input));\n        DimensionHandle depth;\n        TF_RETURN_IF_ERROR(\n            c->Merge(c->Dim(minmax, 0), c->Dim(input, axis), &depth));\n      }\n      return Status::OK();\n    });\n\nREGISTER_OP(\"QuantizedConcat\")\n    .Input(\"concat_dim: int32\")\n    .Input(\"values: N * T\")\n    .Input(\"input_mins: N * float32\")\n    .Input(\"input_maxes: N * float32\")\n    .Output(\"output: T\")\n    .Output(\"output_min: float\")\n    .Output(\"output_max: float\")\n    .Attr(\"N: int >= 2\")\n    .Attr(\"T: type\")\n    .SetShapeFn([](InferenceContext* c) {\n      const int n = (c->num_inputs() - 1) / 3;\n      TF_RETURN_IF_ERROR(shape_inference::ConcatShape(c, n));\n      ShapeHandle unused;\n      for (int i = n + 1; i < c->num_inputs(); ++i) {\n        TF_RETURN_IF_ERROR(c->WithRank(c->input(i), 0, &unused));\n      }\n      c->set_output(1, c->Scalar());\n      c->set_output(2, c->Scalar());\n      return Status::OK();\n    });\n\nREGISTER_OP(\"QuantizedReshape\")\n    .Input(\"tensor: T\")\n    .Input(\"shape: Tshape\")\n    .Input(\"input_min: float\")\n    .Input(\"input_max: float\")\n    .Output(\"output: T\")\n    .Output(\"output_min: float\")\n    .Output(\"output_max: float\")\n    .Attr(\"T: type\")\n    .Attr(\"Tshape: {int32, int64} = DT_INT32\")\n    .SetShapeFn([](InferenceContext* c) {\n      TF_RETURN_IF_ERROR(SetOutputShapeForReshape(c));\n      ShapeHandle unused;\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(2), 0, &unused));\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(3), 0, &unused));\n      c->set_output(1, c->Scalar());\n      c->set_output(2, c->Scalar());\n      return Status::OK();\n    });\n\nREGISTER_OP(\"QuantizedInstanceNorm\")\n    .Input(\"x: T\")\n    .Input(\"x_min: float\")\n    .Input(\"x_max: float\")\n    .Output(\"y: T\")\n    .Output(\"y_min: float\")\n    .Output(\"y_max: float\")\n    .Attr(\"T: quantizedtype\")\n    .Attr(\"output_range_given: bool = false\")\n    .Attr(\"given_y_min: float = 0\")\n    .Attr(\"given_y_max: float = 0\")\n    .Attr(\"variance_epsilon: float = 1e-5\")\n    .Attr(\"min_separation: float = 1e-3\")\n    .SetShapeFn([](shape_inference::InferenceContext* c) {\n      shape_inference::ShapeHandle unused;\n      // x should be a rank 4 tensor.\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(0), 4, &unused));\n      // Assert x_min and x_max are scalars (rank 0).\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(1), 0, &unused));\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(2), 0, &unused));\n      // y has the same shape as x.\n      TF_RETURN_IF_ERROR(shape_inference::UnchangedShape(c));\n      // y_min and y_max are scalars.\n      c->set_output(1, c->Scalar());\n      c->set_output(2, c->Scalar());\n      return Status::OK();\n    });\n\nnamespace {\n\nStatus ScatterNdTensorShape(InferenceContext* c) {\n  ShapeHandle output_shape;\n  TF_RETURN_IF_ERROR(c->WithRankAtLeast(c->input(0), 1, &output_shape));\n  ShapeHandle indices_shape;\n  TF_RETURN_IF_ERROR(c->WithRankAtLeast(c->input(1), 1, &indices_shape));\n  ShapeHandle updates_shape;\n  TF_RETURN_IF_ERROR(c->WithRankAtLeast(c->input(2), 1, &updates_shape));\n  return shape_inference::ScatterNdShapeHelper(c, indices_shape, updates_shape,\n                                               output_shape);\n}\n\n}  // namespace\n\nREGISTER_OP(\"UpperBound\")\n    .Input(\"sorted_inputs: T\")\n    .Input(\"values: T\")\n    .Output(\"output: out_type\")\n    .Attr(\"T: type\")\n    .Attr(\"out_type: {int32, int64} = DT_INT32\")\n    .SetShapeFn([](InferenceContext* c) {\n      ShapeHandle unused_shape;\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(0), 2, &unused_shape));\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(1), 2, &unused_shape));\n      c->set_output(0, c->input(1));\n      return Status::OK();\n    });\n\nREGISTER_OP(\"LowerBound\")\n    .Input(\"sorted_inputs: T\")\n    .Input(\"values: T\")\n    .Output(\"output: out_type\")\n    .Attr(\"T: type\")\n    .Attr(\"out_type: {int32, int64} = DT_INT32\")\n    .SetShapeFn([](InferenceContext* c) {\n      ShapeHandle unused_shape;\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(0), 2, &unused_shape));\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(1), 2, &unused_shape));\n      c->set_output(0, c->input(1));\n      return Status::OK();\n    });\n\nREGISTER_OP(\"ScatterNd\")\n    .Input(\"indices: Tindices\")\n    .Input(\"updates: T\")\n    .Input(\"shape: Tindices\")\n    .Output(\"output: T\")\n    .Attr(\"T: type\")\n    .Attr(\"Tindices: {int32, int64}\")\n    .SetShapeFn([](InferenceContext* c) {\n      ShapeHandle indices_shape;\n      TF_RETURN_IF_ERROR(c->WithRankAtLeast(c->input(0), 1, &indices_shape));\n      ShapeHandle updates_shape;\n      TF_RETURN_IF_ERROR(c->WithRankAtLeast(c->input(1), 1, &updates_shape));\n      ShapeHandle output_shape;\n      TF_RETURN_IF_ERROR(c->MakeShapeFromShapeTensor(2, &output_shape));\n      return shape_inference::ScatterNdShapeHelper(c, indices_shape,\n                                                   updates_shape, output_shape);\n    });\n\nREGISTER_OP(\"TensorScatterUpdate\")\n    .Input(\"tensor: T\")\n    .Input(\"indices: Tindices\")\n    .Input(\"updates: T\")\n    .Output(\"output: T\")\n    .Attr(\"T: type\")\n    .Attr(\"Tindices: {int32, int64}\")\n    .SetShapeFn(ScatterNdTensorShape);\n\nREGISTER_OP(\"TensorScatterAdd\")\n    .Input(\"tensor: T\")\n    .Input(\"indices: Tindices\")\n    .Input(\"updates: T\")\n    .Output(\"output: T\")\n    .Attr(\"T: type\")\n    .Attr(\"Tindices: {int32, int64}\")\n    .SetShapeFn(ScatterNdTensorShape);\n\nREGISTER_OP(\"TensorScatterSub\")\n    .Input(\"tensor: T\")\n    .Input(\"indices: Tindices\")\n    .Input(\"updates: T\")\n    .Output(\"output: T\")\n    .Attr(\"T: type\")\n    .Attr(\"Tindices: {int32, int64}\")\n    .SetShapeFn(ScatterNdTensorShape);\n\nREGISTER_OP(\"TensorScatterMin\")\n    .Input(\"tensor: T\")\n    .Input(\"indices: Tindices\")\n    .Input(\"updates: T\")\n    .Output(\"output: T\")\n    .Attr(\"T: type\")\n    .Attr(\"Tindices: {int32, int64}\")\n    .SetShapeFn(ScatterNdTensorShape);\n\nREGISTER_OP(\"TensorScatterMax\")\n    .Input(\"tensor: T\")\n    .Input(\"indices: Tindices\")\n    .Input(\"updates: T\")\n    .Output(\"output: T\")\n    .Attr(\"T: type\")\n    .Attr(\"Tindices: {int32, int64}\")\n    .SetShapeFn(ScatterNdTensorShape);\n\nREGISTER_OP(\"ScatterNdNonAliasingAdd\")\n    .Input(\"input: T\")\n    .Input(\"indices: Tindices\")\n    .Input(\"updates: T\")\n    .Output(\"output: T\")\n    .Attr(\"T: {numbertype, bool}\")\n    .Attr(\"Tindices: {int32, int64}\")\n    .SetShapeFn(ScatterNdTensorShape);\n\nREGISTER_OP(\"FakeQuantWithMinMaxArgs\")\n    .Attr(\"min: float = -6.0\")\n    .Attr(\"max: float = 6.0\")\n    .Attr(\"num_bits: int = 8\")\n    .Attr(\"narrow_range: bool = false\")\n    .Input(\"inputs: float\")\n    .Output(\"outputs: float\")\n    .SetShapeFn(shape_inference::UnchangedShape);\n\nREGISTER_OP(\"FakeQuantWithMinMaxArgsGradient\")\n    .Attr(\"min: float = -6.0\")\n    .Attr(\"max: float = 6.0\")\n    .Attr(\"num_bits: int = 8\")\n    .Attr(\"narrow_range: bool = false\")\n    .Input(\"gradients: float\")\n    .Input(\"inputs: float\")\n    .Output(\"backprops: float\")\n    .SetShapeFn(shape_inference::UnchangedShape);\n\nREGISTER_OP(\"FakeQuantWithMinMaxVars\")\n    .Attr(\"num_bits: int = 8\")\n    .Attr(\"narrow_range: bool = false\")\n    .Input(\"inputs: float\")\n    .Input(\"min: float\")\n    .Input(\"max: float\")\n    .Output(\"outputs: float\")\n    .SetShapeFn([](InferenceContext* c) {\n      TF_RETURN_IF_ERROR(shape_inference::UnchangedShape(c));\n      ShapeHandle unused;\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(1), 0, &unused));\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(2), 0, &unused));\n      return Status::OK();\n    });\n\nREGISTER_OP(\"FakeQuantWithMinMaxVarsGradient\")\n    .Attr(\"num_bits: int = 8\")\n    .Attr(\"narrow_range: bool = false\")\n    .Input(\"gradients: float\")\n    .Input(\"inputs: float\")\n    .Input(\"min: float\")\n    .Input(\"max: float\")\n    .Output(\"backprops_wrt_input: float\")\n    .Output(\"backprop_wrt_min: float\")\n    .Output(\"backprop_wrt_max: float\")\n    .SetShapeFn([](InferenceContext* c) {\n      // gradients and inputs are same size.\n      ShapeHandle inputs;\n      TF_RETURN_IF_ERROR(c->Merge(c->input(0), c->input(1), &inputs));\n\n      // min and max are scalars\n      ShapeHandle min_max;\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(2), 0, &min_max));\n      TF_RETURN_IF_ERROR(c->Merge(min_max, c->input(3), &min_max));\n\n      c->set_output(0, inputs);\n      c->set_output(1, min_max);\n      c->set_output(2, min_max);\n      return Status::OK();\n    });\n\nREGISTER_OP(\"FakeQuantWithMinMaxVarsPerChannel\")\n    .Attr(\"num_bits: int = 8\")\n    .Attr(\"narrow_range: bool = false\")\n    .Input(\"inputs: float\")\n    .Input(\"min: float\")\n    .Input(\"max: float\")\n    .Output(\"outputs: float\")\n    .SetShapeFn([](InferenceContext* c) {\n      ShapeHandle input, min, max;\n      TF_RETURN_IF_ERROR(c->WithRankAtLeast(c->input(0), 1, &input));\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(1), 1, &min));\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(2), 1, &max));\n\n      DimensionHandle unused;\n      TF_RETURN_IF_ERROR(c->Merge(c->Dim(input, -1), c->Dim(min, 0), &unused));\n      TF_RETURN_IF_ERROR(c->Merge(c->Dim(input, -1), c->Dim(max, 0), &unused));\n      TF_RETURN_IF_ERROR(c->Merge(c->Dim(min, 0), c->Dim(max, 0), &unused));\n\n      c->set_output(0, input);\n      return Status::OK();\n    });\n\nREGISTER_OP(\"FakeQuantWithMinMaxVarsPerChannelGradient\")\n    .Attr(\"num_bits: int = 8\")\n    .Attr(\"narrow_range: bool = false\")\n    .Input(\"gradients: float\")\n    .Input(\"inputs: float\")\n    .Input(\"min: float\")\n    .Input(\"max: float\")\n    .Output(\"backprops_wrt_input: float\")\n    .Output(\"backprop_wrt_min: float\")\n    .Output(\"backprop_wrt_max: float\")\n    .SetShapeFn([](InferenceContext* c) {\n      ShapeHandle inputs;\n      TF_RETURN_IF_ERROR(c->WithRankAtLeast(c->input(0), 1, &inputs));\n      TF_RETURN_IF_ERROR(c->WithRankAtMost(inputs, 4, &inputs));\n      TF_RETURN_IF_ERROR(c->Merge(inputs, c->input(1), &inputs));\n\n      ShapeHandle last_dim = c->Vector(c->Dim(inputs, -1));\n\n      ShapeHandle min_max;\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(2), 1, &min_max));\n      TF_RETURN_IF_ERROR(c->Merge(min_max, last_dim, &min_max));\n      TF_RETURN_IF_ERROR(c->Merge(c->input(3), min_max, &min_max));\n\n      c->set_output(0, inputs);\n      c->set_output(1, min_max);\n      c->set_output(2, min_max);\n      return Status::OK();\n    });\n\nREGISTER_OP(\"Fingerprint\")\n    .Input(\"data: T\")\n    .Input(\"method: string\")\n    .Output(\"fingerprint: uint8\")\n    .Attr(\"T: type\")\n    .SetShapeFn([](InferenceContext* c) {\n      ShapeHandle unused;\n      TF_RETURN_IF_ERROR(c->WithRankAtLeast(c->input(0), 1, &unused));\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(1), 0, &unused));\n\n      DimensionHandle fingerprint_size;\n      const Tensor* method = c->input_tensor(1);\n      if (method == nullptr) {\n        fingerprint_size = c->UnknownDim();\n      } else {\n        if (method->dims() != 0) {\n          return errors::InvalidArgument(\"`method` must be rank 0: \",\n                                         method->shape());\n        }\n        const string& method_string = method->scalar<tstring>()();\n        if (method_string != \"farmhash64\") {\n          return errors::InvalidArgument(\"Unsupported method: \", method_string);\n        }\n        fingerprint_size = c->MakeDim(sizeof(uint64));\n      }\n\n      DimensionHandle batch = c->Dim(c->input(0), 0);\n      c->set_output(0, c->MakeShape({batch, fingerprint_size}));\n      return Status::OK();\n    });\n\n#ifdef INTEL_MKL\nREGISTER_OP(\"_MklConcat\")\n    .Input(\"concat_dim: int32\")\n    .Input(\"values: N * T\")\n    .Input(\"mkl_concat_dim: uint8\")\n    .Input(\"mkl_values: N * uint8\")\n    .Output(\"output: T\")\n    .Output(\"mkl_output: uint8\")\n    .Attr(\"N: int >= 2\")\n    .Attr(\"T: type\")\n    .SetShapeFn([](InferenceContext* c) {\n      return shape_inference::ConcatShape(c, c->num_inputs() - 3);\n    })\n    .Doc(R\"doc(\nMKL version of Concat operator. Uses MKL DNN APIs to perform concatenation.\n\nNOTE Do not invoke this operator directly in Python. Graph rewrite pass is\nexpected to invoke these operators.\n)doc\");\n#endif\n\n// Deprecated op registrations:\n\n// The following can be deleted after 10mar2017.\nREGISTER_OP(\"BatchMatrixDiag\")\n    .Input(\"diagonal: T\")\n    .Output(\"output: T\")\n    .Attr(\"T: type\")\n    .Deprecated(14, \"Use MatrixDiag\")\n    .SetShapeFn(shape_inference::UnknownShape);\nREGISTER_OP(\"BatchMatrixSetDiag\")\n    .Input(\"input: T\")\n    .Input(\"diagonal: T\")\n    .Output(\"output: T\")\n    .Attr(\"T: type\")\n    .Deprecated(14, \"Use MatrixSetDiag\")\n    .SetShapeFn(shape_inference::UnknownShape);\nREGISTER_OP(\"BatchMatrixDiagPart\")\n    .Input(\"input: T\")\n    .Output(\"diagonal: T\")\n    .Attr(\"T: type\")\n    .Deprecated(14, \"Use MatrixDiagPart\")\n    .SetShapeFn(shape_inference::UnknownShape);\nREGISTER_OP(\"BatchMatrixBandPart\")\n    .Input(\"input: T\")\n    .Input(\"num_lower: int64\")\n    .Input(\"num_upper: int64\")\n    .Output(\"band: T\")\n    .Attr(\"T: type\")\n    .Deprecated(14, \"Use MatrixBandPart\")\n    .SetShapeFn(shape_inference::UnknownShape);\n\n}  // namespace tensorflow\n", "/* Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\n\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n\n#include \"tensorflow/core/framework/node_def_builder.h\"\n#include \"tensorflow/core/framework/node_def_util.h\"\n#include \"tensorflow/core/framework/op.h\"\n#include \"tensorflow/core/framework/shape_inference.h\"\n#include \"tensorflow/core/framework/shape_inference_testutil.h\"\n#include \"tensorflow/core/framework/tensor.pb.h\"\n#include \"tensorflow/core/framework/tensor_shape.pb.h\"\n#include \"tensorflow/core/framework/tensor_testutil.h\"\n#include \"tensorflow/core/lib/core/status_test_util.h\"\n#include \"tensorflow/core/platform/test.h\"\n#include \"tensorflow/core/public/version.h\"\n\nnamespace tensorflow {\n\nTEST(ArrayOpsTest, TensorScatterUpdate_ShapeFn) {\n  ShapeInferenceTestOp op(\"TensorScatterUpdate\");\n\n  INFER_OK(op, \"[4,3];[8,2];[8]\", \"in0\");\n  INFER_OK(op, \"[?,?];[?,2];[?]\", \"in0\");\n  INFER_OK(op, \"[?];[?];[?]\", \"in0\");\n\n  INFER_ERROR(\"Shape must be at least rank 1 but is rank 0\", op,\n              \"[];[?,2];[?]\");\n  INFER_ERROR(\"Indices and updates specified for empty input\", op,\n              \"[0,2,2];[8,2];[8]\");\n  INFER_ERROR(\n      \"Dimensions [0,1) of indices[shape=[8,2]] = [8] must match \"\n      \"dimensions [0,1) of updates[shape=[9]] = [9]\",\n      op, \"[?,?];[8,2];[9]\");\n  INFER_ERROR(\n      \"Dimensions [2,2) of input[shape=[?,?]] = [] must match \"\n      \"dimensions [1,2) of updates[shape=[?,1]] = [1]\",\n      op, \"[?,?];[?,2];[?,1]\");\n}\n\nTEST(ArrayOpsTest, ScatterNd_ShapeFn) {\n  ShapeInferenceTestOp op(\"ScatterNd\");\n\n  INFER_OK(op, \"[8,2];[8];[2]\", \"[?,?]\");\n\n  INFER_ERROR(\"Shape must be rank 1 but is rank 0\", op, \"[?,2];[?];[]\");\n  INFER_ERROR(\n      \"Dimensions [0,1) of indices[shape=[8,2]] = [8] must match \"\n      \"dimensions [0,1) of updates[shape=[9]] = [9]\",\n      op, \"[8,2];[9];[?]\");\n}\n\nTEST(ArrayOpsTest, UnravelIndex_ShapeFn) {\n  ShapeInferenceTestOp op(\"UnravelIndex\");\n\n  INFER_OK(op, \"?;?\", \"?\");\n\n  INFER_OK(op, \"[];[?]\", \"[d1_0]\");\n\n  INFER_OK(op, \"[4,5];[?]\", \"[d1_0,20]\");\n  INFER_OK(op, \"[2,3,4];[?]\", \"[d1_0,24]\");\n  INFER_OK(op, \"?;[?]\", \"?\");\n  INFER_OK(op, \"[?];[?]\", \"[d1_0,?]\");\n\n  INFER_ERROR(\"Shape must be rank 1 but is rank 2\", op, \"?;[1,1]\");\n}\n\nTEST(ArrayOpsTest, Pack_ShapeFn) {\n  ShapeInferenceTestOp op(\"Pack\");\n  auto set_axis = [&op](int axis) {\n    int n = 3;\n    std::vector<NodeDefBuilder::NodeOut> src_list;\n    src_list.reserve(n);\n    for (int i = 0; i < n; ++i) src_list.emplace_back(\"a\", 0, DT_FLOAT);\n    TF_ASSERT_OK(NodeDefBuilder(\"test\", \"Pack\")\n                     .Input(src_list)\n                     .Attr(\"N\", n)\n                     .Attr(\"axis\", axis)\n                     .Finalize(&op.node_def));\n  };\n\n  set_axis(0);\n  INFER_OK(op, \"?;?;?\", \"?\");\n\n  for (int axis : {0, -3}) {\n    set_axis(axis);\n    INFER_OK(op, \"?;?;?\", \"?\");\n    INFER_OK(op, \"[1,3];[1,3];?\", \"[3,d0_0|d1_0,d0_1|d1_1]\");\n    INFER_OK(op, \"[?,3];[1,3];?\", \"[3,d1_0,d0_1|d1_1]\");\n    INFER_OK(op, \"[?,?];[1,3];?\", \"[3,d1_0,d1_1]\");\n  }\n  for (int axis : {1, -2}) {\n    set_axis(axis);\n    INFER_OK(op, \"?;?;?\", \"?\");\n    INFER_OK(op, \"[1,3];[1,3];?\", \"[d0_0|d1_0,3,d0_1|d1_1]\");\n    INFER_OK(op, \"[?,3];[1,3];?\", \"[d1_0,3,d0_1|d1_1]\");\n    INFER_OK(op, \"[?,?];[1,3];?\", \"[d1_0,3,d1_1]\");\n  }\n  for (int axis : {2, -1}) {\n    set_axis(axis);\n    INFER_OK(op, \"?;?;?\", \"?\");\n    INFER_OK(op, \"[1,3];[1,3];?\", \"[d0_0|d1_0,d0_1|d1_1,3]\");\n    INFER_OK(op, \"[?,3];[1,3];?\", \"[d1_0,d0_1|d1_1,3]\");\n    INFER_OK(op, \"[?,?];[1,3];?\", \"[d1_0,d1_1,3]\");\n  }\n\n  set_axis(-4);\n  INFER_ERROR(\"Invalid axis: -4; must be in [-3,3)\", op, \"[1,3];[1,3];?\");\n  set_axis(3);\n  INFER_ERROR(\"Invalid axis: 3; must be in [-3,3)\", op, \"[1,3];[1,3];?\");\n\n  set_axis(0);\n\n  // Check that both components of error message are there.\n  INFER_ERROR(\"Shapes must be equal rank, but are 3 and 2\", op,\n              \"[1,2,3];?;[1,4]\");\n  INFER_ERROR(\"From merging shape 0 with other shapes.\", op, \"[1,2,3];?;[1,4]\");\n}\n\nTEST(ArrayOpsTest, UnPack_ShapeFn) {\n  ShapeInferenceTestOp op(\"Unpack\");\n  auto set_axis_and_num = [&op](int axis, int num) {\n    TF_ASSERT_OK(NodeDefBuilder(\"test\", \"Unpack\")\n                     .Input(\"a\", 0, DT_FLOAT)\n                     .Attr(\"axis\", axis)\n                     .Attr(\"num\", num)\n                     .Finalize(&op.node_def));\n  };\n\n  set_axis_and_num(0, 1);\n  INFER_OK(op, \"?\", \"?\");\n\n  for (int axis : {0, -3}) {\n    set_axis_and_num(axis, 1);\n    INFER_OK(op, \"?\", \"?\");\n    INFER_OK(op, \"[1,2,3]\", \"[d0_1,d0_2]\");\n    INFER_OK(op, \"[?,?,?]\", \"[d0_1,d0_2]\");\n  }\n  for (int axis : {1, -2}) {\n    set_axis_and_num(axis, 2);\n    INFER_OK(op, \"[1,2,3]\", \"[d0_0,d0_2];[d0_0,d0_2]\");\n    INFER_OK(op, \"[?,?,?]\", \"[d0_0,d0_2];[d0_0,d0_2]\");\n  }\n  for (int axis : {2, -1}) {\n    set_axis_and_num(axis, 3);\n    INFER_OK(op, \"[1,2,3]\", \"[d0_0,d0_1];[d0_0,d0_1];[d0_0,d0_1]\");\n    INFER_OK(op, \"[?,?,?]\", \"[d0_0,d0_1];[d0_0,d0_1];[d0_0,d0_1]\");\n  }\n\n  set_axis_and_num(2, 2);\n  INFER_ERROR(\"Dimension must be 2 but is 3\", op, \"[1,2,3]\");\n\n  set_axis_and_num(-4, 3);\n  INFER_ERROR(\"Invalid axis: -4; must be in [-3,3)\", op, \"[1,2,3]\");\n  set_axis_and_num(3, 3);\n  INFER_ERROR(\"Invalid axis: 3; must be in [-3,3)\", op, \"[1,2,3]\");\n}\n\nTEST(ArrayOpsTest, Const_ShapeFn) {\n  ShapeInferenceTestOp op(\"Const\");\n  TensorProto tensor_proto;\n  auto* shape_proto = tensor_proto.mutable_tensor_shape();\n  auto rebuild_node_def = [&op, &tensor_proto]() {\n    TF_ASSERT_OK(NodeDefBuilder(\"test\", \"Const\")\n                     .Attr(\"value\", tensor_proto)\n                     .Finalize(&op.node_def));\n  };\n\n  TensorShape{}.AsProto(shape_proto);\n  rebuild_node_def();\n  INFER_OK(op, \"\", \"[]\");\n  TensorShape{1, 2, 3, 4}.AsProto(shape_proto);\n  rebuild_node_def();\n  INFER_OK(op, \"\", \"[1,2,3,4]\");\n\n  shape_proto->add_dim()->set_size(-1);\n  rebuild_node_def();\n  INFER_ERROR(\"Shape [1,2,3,4,?] is not fully defined\", op, \"\");\n}\n\nTEST(ArrayOpsTest, UnchangedShapes_ShapeFn) {\n  for (const char* op_name : {\n           \"CheckNumerics\",\n           \"Identity\",\n           \"RefIdentity\",\n           \"QuantizeAndDequantize\",\n           \"StopGradient\",\n           \"ZerosLike\",\n           \"OnesLike\",\n       }) {\n    ShapeInferenceTestOp op(op_name);\n    INFER_OK(op, \"?\", \"in0\");\n    INFER_OK(op, \"[]\", \"in0\");\n    INFER_OK(op, \"[1,2,?,4,5]\", \"in0\");\n  }\n\n  // inputs 1 and 2 are ignored; input 0 is transferred to output 0.\n  ShapeInferenceTestOp op(\"MatrixBandPart\");\n  INFER_OK(op, \"?;?;?\", \"in0\");\n  INFER_OK(op, \"[];?;?\", \"in0\");\n  INFER_OK(op, \"[1,2,?,4,5];?;?\", \"in0\");\n}\n\nTEST(ArrayOpsTest, GuaranteeConst_ShapeFn) {\n  ShapeInferenceTestOp op(\"GuaranteeConst\");\n  INFER_OK(op, \"?\", \"in0\");\n  INFER_OK(op, \"[]\", \"in0\");\n  INFER_OK(op, \"[1,2,?,4,5]\", \"in0\");\n}\n\nTEST(ArrayOpsTest, Identity_ShapeFnHandles) {\n  const char* op_name = \"Identity\";\n  ShapeInferenceTestOp op(op_name);\n  // Check that handle dtypes are preserved.\n  const OpRegistrationData* op_reg_data;\n  TF_ASSERT_OK(OpRegistry::Global()->LookUp(op.name, &op_reg_data));\n  std::vector<\n      std::unique_ptr<std::vector<std::pair<PartialTensorShape, DataType>>>>\n      handle_data;\n  handle_data.emplace_back(\n      new std::vector<std::pair<PartialTensorShape, DataType>>(\n          {{PartialTensorShape(), DT_BOOL}}));\n  shape_inference::InferenceContext c(\n      TF_GRAPH_DEF_VERSION, op.node_def, op_reg_data->op_def,\n      {PartialTensorShape()}, {}, {}, handle_data);\n  TF_ASSERT_OK(c.construction_status());\n  ASSERT_TRUE(op_reg_data->shape_inference_fn != nullptr);\n  TF_ASSERT_OK(c.Run(op_reg_data->shape_inference_fn));\n\n  const auto* shapes_and_types = c.output_handle_shapes_and_types(0);\n  ASSERT_TRUE(shapes_and_types != nullptr);\n  ASSERT_EQ(1, shapes_and_types->size());\n  EXPECT_EQ((*shapes_and_types)[0].dtype, DT_BOOL);\n}\n\nTEST(ArrayOpsTest, Diag_ShapeFn) {\n  ShapeInferenceTestOp op(\"Diag\");\n  INFER_OK(op, \"?\", \"?\");\n  INFER_OK(op, \"[1,?,3]\", \"[d0_0,d0_1,d0_2,d0_0,d0_1,d0_2]\");\n  INFER_OK(op, \"[?,1,2,3]\", \"[d0_0,d0_1,d0_2,d0_3,d0_0,d0_1,d0_2,d0_3]\");\n  INFER_ERROR(\"Shape must be at least rank 1 but is rank 0\", op, \"[]\");\n}\n\nTEST(ArrayOpsTest, DiagPart_ShapeFn) {\n  ShapeInferenceTestOp op(\"DiagPart\");\n  INFER_OK(op, \"?\", \"?\");\n  INFER_OK(op, \"[1,?,?,4]\", \"[d0_0,d0_3]\");\n  INFER_OK(op, \"[1,?,3,?,4,3]\", \"[d0_0,d0_4,d0_2|d0_5]\");\n  INFER_OK(op, \"[1,2,3,?,?,?,?,4]\", \"[d0_0,d0_1,d0_2,d0_7]\");\n  INFER_ERROR(\"Input must have even and non-zero rank\", op, \"[]\");\n  INFER_ERROR(\"Input must have even and non-zero rank\", op, \"[?]\");\n  INFER_ERROR(\"Input must have even and non-zero rank\", op, \"[1,2,3]\");\n  INFER_ERROR(\"Dimensions must be equal, but are 2 and 10\", op, \"[1,2,?,10]\");\n}\n\nTEST(ArrayOpsTest, MatrixDiag_ShapeFn) {\n  ShapeInferenceTestOp op(\"MatrixDiag\");\n  INFER_OK(op, \"?\", \"?\");\n  INFER_ERROR(\"Shape must be at least rank 1 but is rank 0\", op, \"[]\");\n  INFER_OK(op, \"[?]\", \"[d0_0,d0_0]\");\n  INFER_OK(op, \"[1,?,?,4]\", \"[d0_0,d0_1,d0_2,d0_3,d0_3]\");\n}\n\nTEST(ArrayOpsTest, MatrixDiagPart_ShapeFn) {\n  ShapeInferenceTestOp op(\"MatrixDiagPart\");\n  INFER_OK(op, \"?\", \"?\");\n  INFER_ERROR(\"Shape must be at least rank 2 but is rank 1\", op, \"[?]\");\n  INFER_OK(op, \"[?,1,2,2]\", \"[d0_0,d0_1,d0_2|d0_3]\");\n  INFER_OK(op, \"[?,1,2,3]\", \"[d0_0,d0_1,d0_2]\");\n  INFER_OK(op, \"[?,1,3,2]\", \"[d0_0,d0_1,d0_3]\");\n}\n\nTEST(ArrayOpsTest, Reverse_ShapeFn) {\n  ShapeInferenceTestOp op(\"Reverse\");\n  INFER_OK(op, \"?;?\", \"in0\");\n  INFER_ERROR(\"Shape must be rank 1 but is rank 0\", op, \"?;[]\");\n  INFER_ERROR(\"Shape must be rank 1 but is rank 2\", op, \"?;[?,2]\");\n  INFER_ERROR(\"Shape must be rank 4 but is rank 3\", op, \"[1,2,3];[4]\");\n  INFER_ERROR(\"reverse does not work on tensors with more than 8 dimensions\",\n              op, \"[1,2,3,4,5,6,7,8,9];[9]\");\n  INFER_OK(op, \"[1,2,3,?];[4]\", \"in0\");\n  INFER_OK(op, \"[1,2,3,?,5,6,7,8];[8]\", \"in0\");\n}\n\nTEST(ArrayOpsTest, ReverseV2_ShapeFn) {\n  ShapeInferenceTestOp op(\"ReverseV2\");\n  INFER_OK(op, \"?;?\", \"in0\");\n  INFER_ERROR(\"Shape must be rank 1 but is rank 0\", op, \"?;[]\");\n  INFER_ERROR(\"Shape must be rank 1 but is rank 2\", op, \"?;[?,2]\");\n  INFER_OK(op, \"[1,2,3];[2]\", \"in0\");\n  INFER_ERROR(\"reverse does not work on tensors with more than 8 dimensions\",\n              op, \"[1,2,3,4,5,6,7,8,9];[9]\");\n  INFER_OK(op, \"[1,2,3,?];[4]\", \"in0\");\n  INFER_OK(op, \"[1,2,3,?,5,6,7,8];[8]\", \"in0\");\n}\n\nTEST(ArrayOpsTest, Fill_ShapeFn) {\n  ShapeInferenceTestOp op(\"Fill\");\n  AddNodeAttr(\"index_type\", DT_INT32, &op.node_def);\n  op.input_tensors.resize(2);\n  INFER_OK(op, \"?;?\", \"?\");\n  INFER_OK(op, \"[?];?\", \"?\");\n  INFER_OK(op, \"[4];?\", \"[?,?,?,?]\");\n\n  Tensor in_t = test::AsTensor<int32>({1, 2, 3, 4});\n  op.input_tensors[0] = &in_t;\n  INFER_OK(op, \"[4];?\", \"[1,2,3,4]\");\n}\n\nTEST(ArrayOpsTest, Gather_ShapeFn) {\n  ShapeInferenceTestOp op(\"Gather\");\n  INFER_OK(op, \"?;?\", \"?\");\n  INFER_OK(op, \"[1,?,2];[3]\", \"[d1_0,d0_1,d0_2]\");\n  INFER_ERROR(\"Shape must be at least rank 1 but is rank 0\", op, \"[];[1,2,3]\");\n}\n\nTEST(ArrayOpsTest, GatherV2_ShapeFn) {\n  ShapeInferenceTestOp op(\"GatherV2\");\n  AddNodeAttr(\"batch_dims\", 0, &op.node_def);\n\n  // Tests when axis is unknown.\n  INFER_OK(op, \"?;?;?\", \"?\");\n  INFER_OK(op, \"[1,2,3];[3];[]\", \"[?,?,?]\");\n  INFER_ERROR(\"Shape must be at least rank 1 but is rank 0\", op,\n              \"[];[1,2,3];[]\");\n\n  // Non-scalar axis.\n  INFER_ERROR(\"Shape must be rank 0 but is rank 1\", op, \"[1];[1,2,3];[1]\");\n\n  // Test when axis dim is known.\n  Tensor axis_dim_t;\n  op.input_tensors.resize(3);\n  op.input_tensors[2] = &axis_dim_t;\n\n  // Out of range axis.\n  axis_dim_t = test::AsScalar(1);\n  INFER_ERROR(\"Shape must be at least rank 2 but is rank 1\", op,\n              \"[1];[1,2];[]\");\n\n  // Rank 0 indices.\n  axis_dim_t = test::AsScalar(0);\n  INFER_OK(op, \"[1,2,3];[];[]\", \"[d0_1,d0_2]\");\n  axis_dim_t = test::AsScalar(1);\n  INFER_OK(op, \"[1,2,3];[];[]\", \"[d0_0,d0_2]\");\n  axis_dim_t = test::AsScalar(2);\n  INFER_OK(op, \"[1,2,3];[];[]\", \"[d0_0,d0_1]\");\n\n  // Rank 1 indices.\n  axis_dim_t = test::AsScalar(0);\n  INFER_OK(op, \"[1,2,3];[5];[]\", \"[d1_0,d0_1,d0_2]\");\n  axis_dim_t = test::AsScalar(1);\n  INFER_OK(op, \"[1,2,3];[5];[]\", \"[d0_0,d1_0,d0_2]\");\n  axis_dim_t = test::AsScalar(2);\n  INFER_OK(op, \"[1,2,3];[5];[]\", \"[d0_0,d0_1,d1_0]\");\n\n  // Rank 2 indices.\n  axis_dim_t = test::AsScalar(0);\n  INFER_OK(op, \"[1,2,3];[5,6];[]\", \"[d1_0,d1_1,d0_1,d0_2]\");\n  axis_dim_t = test::AsScalar(1);\n  INFER_OK(op, \"[1,2,3];[5,6];[]\", \"[d0_0,d1_0,d1_1,d0_2]\");\n  axis_dim_t = test::AsScalar(2);\n  INFER_OK(op, \"[1,2,3];[5,6];[]\", \"[d0_0,d0_1,d1_0,d1_1]\");\n\n  // Negative axis.\n  axis_dim_t = test::AsScalar(-3);\n  INFER_OK(op, \"[1,2,3];[5,6];[]\", \"[d1_0,d1_1,d0_1,d0_2]\");\n  axis_dim_t = test::AsScalar(-2);\n  INFER_OK(op, \"[1,2,3];[5,6];[]\", \"[d0_0,d1_0,d1_1,d0_2]\");\n  axis_dim_t = test::AsScalar(-1);\n  INFER_OK(op, \"[1,2,3];[5,6];[]\", \"[d0_0,d0_1,d1_0,d1_1]\");\n\n  // Batch dimensions > 0\n  // Create another node since we can't overwrite the original batch dims.\n  ShapeInferenceTestOp batch_op(\"GatherV2\");\n  AddNodeAttr(\"batch_dims\", 1, &batch_op.node_def);\n  INFER_OK(batch_op, \"[1,4800,8];[1,28400];[]\", \"[?,?,?]\");\n\n  ShapeInferenceTestOp batch_op_2(\"GatherV2\");\n  AddNodeAttr(\"batch_dims\", 2, &batch_op_2.node_def);\n  INFER_OK(batch_op_2, \"[1,2,3,4,5];[1,2,3];[]\", \"[?,?,?,?,?]\");\n}\n\nTEST(ArrayOpsTest, GatherNd_ShapeFn) {\n  ShapeInferenceTestOp op(\"GatherNd\");\n\n  // Inputs are (params, indices).\n  INFER_OK(op, \"?;?\", \"?\");\n  INFER_OK(op, \"[1,?,3,?];[?,0]\", \"[d1_0,d0_0,d0_1,d0_2,d0_3]\");\n  INFER_OK(op, \"[1,?,3,?];[?,4]\", \"[d1_0]\");\n\n  // params.rank >= indices.dim(-1).\n  INFER_ERROR(\"indices.shape[-1] must be <= params.rank\", op, \"[1,2,3];[4]\");\n}\n\nTEST(ArrayOpsTest, Shape_ShapeFn) {\n  ShapeInferenceTestOp op(\"Shape\");\n  INFER_OK(op, \"?\", \"[?]\");\n  INFER_OK(op, \"[?]\", \"[1]\");\n  INFER_OK(op, \"[?,2,3,4,5]\", \"[5]\");\n}\n\nTEST(ArrayOpsTest, ShapeN_ShapeFn) {\n  ShapeInferenceTestOp op(\"ShapeN\");\n  int n = 3;\n  std::vector<NodeDefBuilder::NodeOut> src_list;\n  src_list.reserve(n);\n  for (int i = 0; i < n; ++i) src_list.emplace_back(\"a\", 0, DT_FLOAT);\n  TF_ASSERT_OK(NodeDefBuilder(\"test\", \"ShapeN\")\n                   .Input(src_list)\n                   .Attr(\"N\", n)\n                   .Finalize(&op.node_def));\n  INFER_OK(op, \"?;?;?\", \"[?];[?];[?]\");\n  INFER_OK(op, \"[?];[?];[?]\", \"[1];[1];[1]\");\n  INFER_OK(op, \"[?,2,3,4,5];?;[1,?,3]\", \"[5];[?];[3]\");\n}\n\nTEST(ArrayOpsTest, Unique_ShapeFn) {\n  ShapeInferenceTestOp op(\"Unique\");\n  INFER_OK(op, \"?\", \"[?];in0\");\n  INFER_OK(op, \"[5]\", \"[?];in0\");\n  INFER_ERROR(\"Shape must be rank 1 but is rank 5\", op, \"[1,2,3,?,5]\");\n}\n\nTEST(ArrayOpsTest, UniqueWithCounts_ShapeFn) {\n  ShapeInferenceTestOp op(\"UniqueWithCounts\");\n  INFER_OK(op, \"?\", \"[?];in0;[?]\");\n  INFER_OK(op, \"[1,2,3,?,5]\", \"[?];in0;[?]\");\n}\n\nTEST(ArrayOpsTest, InvertPermutation_ShapeFn) {\n  ShapeInferenceTestOp op(\"InvertPermutation\");\n  INFER_OK(op, \"?\", \"[?]\");\n  INFER_OK(op, \"[1]\", \"in0\");\n  INFER_ERROR(\"Shape must be rank 1 but is rank 0\", op, \"[]\");\n}\n\nTEST(ArrayOpsTest, PadD_ShapeFn) {\n  for (const char* op_name : {\"Pad\", \"MirrorPad\"}) {\n    ShapeInferenceTestOp op(op_name);\n    op.input_tensors.resize(2);\n\n    // Inputs are input and paddings.\n\n    INFER_OK(op, \"?;?\", \"?\");\n\n    // Check shape of paddings.\n    INFER_ERROR(\"Shape must be rank 2 but is rank 3\", op, \"?;[1,2,3]\");\n    INFER_ERROR(\"Dimension must be 2 but is 4\", op, \"?;[1,4]\");\n\n    // input.rank and paddings.dim(0) are equal. This is the number of dims in\n    // output.\n    INFER_ERROR(\"Shape must be rank 4 but is rank 3\", op, \"[1,2,3];[4,2]\");\n    INFER_OK(op, \"[1,2,3];?\", \"[?,?,?]\");\n    INFER_OK(op, \"?;[3,2]\", \"[?,?,?]\");\n\n    // Make the paddings tensor known and verify padding values get added.\n    // E.g., if padding is ((1,10),(2,20),(3,30)) then values 11,22,23 are added\n    // to input dims to get output.\n    Tensor paddings_t(DT_INT64, TensorShape{3, 2});\n    test::FillValues<int64_t>(&paddings_t, {1, 10, 2, 20, 3, 30});\n    op.input_tensors[1] = &paddings_t;\n    INFER_OK(op, \"[100,200,300];[3,2]\", \"[111,222,333]\");\n    INFER_OK(op, \"[100,?,300];[3,2]\", \"[111,?,333]\");\n    INFER_OK(op, \"?;[3,2]\", \"[?,?,?]\");\n    INFER_OK(op, \"?;?\", \"[?,?,?]\");\n  }\n}\n\nTEST(ArrayOpsTest, PadV2_ShapeFn) {\n  ShapeInferenceTestOp op(\"PadV2\");\n  op.input_tensors.resize(3);\n\n  // Inputs are input, paddings and constant_values.\n\n  INFER_OK(op, \"?;?;?\", \"?\");\n\n  // Check shape of paddings.\n  INFER_ERROR(\"Shape must be rank 2 but is rank 3\", op, \"?;[1,2,3];?\");\n  INFER_ERROR(\"Dimension must be 2 but is 4\", op, \"?;[1,4];?\");\n\n  // input.rank and paddings.dim(0) are equal. This is the number of dims in\n  // output.\n  INFER_ERROR(\"Shape must be rank 4 but is rank 3\", op, \"[1,2,3];[4,2];[]\");\n  INFER_OK(op, \"[1,2,3];?;[]\", \"[?,?,?]\");\n  INFER_OK(op, \"?;[3,2];[]\", \"[?,?,?]\");\n\n  // Make the paddings tensor known and verify padding values get added.\n  // E.g., if padding is ((1,10),(2,20),(3,30)) then values 11,22,23 are added\n  // to input dims to get output.\n  Tensor paddings_t(DT_INT64, TensorShape{3, 2});\n  test::FillValues<int64_t>(&paddings_t, {1, 10, 2, 20, 3, 30});\n  op.input_tensors[1] = &paddings_t;\n  INFER_OK(op, \"[100,200,300];[3,2];[]\", \"[111,222,333]\");\n  INFER_OK(op, \"[100,?,300];[3,2];[]\", \"[111,?,333]\");\n  INFER_OK(op, \"?;[3,2];[]\", \"[?,?,?]\");\n  INFER_OK(op, \"?;?;[]\", \"[?,?,?]\");\n}\n\nTEST(ArrayOpsTest, MirrorPadGrad_ShapeFn) {\n  ShapeInferenceTestOp op(\"MirrorPadGrad\");\n  op.input_tensors.resize(2);\n\n  // Inputs are input and paddings.\n  INFER_OK(op, \"?;?\", \"?\");\n\n  // First padding dimension is unknown, so rank is unknown.\n  INFER_OK(op, \"?;[?,4]\", \"?\");\n\n  // Input tensor rank doesn't match paddings dimension.\n  INFER_ERROR(\"must be rank 3 but is rank 2\", op, \"[?,?];[3,2]\");\n\n  // Paddings tensor is not a [rank x 2] matrix.\n  INFER_ERROR(\"Dimension 1 in both shapes must be equal, but are 3 and 2\", op,\n              \"[?,?,?];[3,3]\");\n\n  // Paddings tensor is unknown, but rank is known, so the output\n  // shape is a rank 3 unknown shape.\n  INFER_OK(op, \"[?,?,?];[3,2]\", \"[?,?,?]\");\n\n  // Make the paddings tensor known and verify padding values get\n  // subtracted.  E.g., if padding is ((1,10),(2,20),(3,30)) then\n  // values 11,22,23 are subtracted to input dims to get output.\n  Tensor paddings_t(DT_INT64, TensorShape{3, 2});\n  test::FillValues<int64_t>(&paddings_t, {1, 10, 2, 20, 3, 30});\n  op.input_tensors[1] = &paddings_t;\n\n  INFER_OK(op, \"[111,222,333];[3,2]\", \"[100,200,300]\");\n  INFER_OK(op, \"[111,?,333];[3,2]\", \"[100,?,300]\");\n}\n\nTEST(ArrayOpsTest, BroadcastArgs_ShapeFn) {\n  ShapeInferenceTestOp op(\"BroadcastArgs\");\n  INFER_OK(op, \"?;?\", \"[?]\");\n  INFER_OK(op, \"[123];[1]\", \"[123]\");\n  INFER_OK(op, \"[1];[123]\", \"[123]\");\n  INFER_OK(op, \"[123];[121]\", \"[123]\");\n\n  // Rank checks\n  INFER_ERROR(\"Shape must be rank 1 but is rank 0\", op, \"[];?\");\n  INFER_ERROR(\"Shape must be rank 1 but is rank 0\", op, \"?;[]\");\n}\n\nTEST(ArrayOpsTest, BroadcastTo_ShapeFn) {\n  ShapeInferenceTestOp op(\"BroadcastTo\");\n  op.input_tensors.resize(2);\n\n  INFER_OK(op, \"?;[?]\", \"?\");\n  INFER_OK(op, \"[];[1]\", \"[?]\");\n  INFER_OK(op, \"[1];[1]\", \"[?]\");\n  INFER_OK(op, \"[1];[2]\", \"[?,?]\");\n  INFER_OK(op, \"[2,2];[3]\", \"[?,d0_0,d0_1]\");\n\n  // Rank checks\n  INFER_ERROR(\"Shape must be rank 1 but is rank 2\", op, \"?;[?,?]\");\n  INFER_ERROR(\"Shape must be rank 1 but is rank 0\", op, \"[2];[]\");\n  INFER_ERROR(\"Shape must be at most rank 1 but is rank 2\", op, \"[2,2];[1]\");\n\n  Tensor shape_t(DT_INT64, TensorShape{3});\n  test::FillValues<int64_t>(&shape_t, {2, 10, 3});\n  op.input_tensors[1] = &shape_t;\n  INFER_OK(op, \"[1,?,1];[3]\", \"[2,10,3]\");\n  INFER_OK(op, \"[1,1,1];[3]\", \"[2,10,3]\");\n  INFER_OK(op, \"[10,1];[3]\", \"[2,d0_0,3]\");\n  INFER_ERROR(\"Dimensions must be equal, but are 3 and 2 for\", op,\n              \"[3,1,1];[3]\");\n  INFER_ERROR(\"Dimensions must be equal, but are 2 and 10 for\", op,\n              \"[2,2,1];[3]\");\n}\n\nTEST(ArrayOpsTest, BroadcastGradientArgs_ShapeFn) {\n  ShapeInferenceTestOp op(\"BroadcastGradientArgs\");\n  // Output is always two unknown vectors.\n  INFER_OK(op, \"?;?\", \"[?];[?]\");\n  INFER_OK(op, \"[123];[456]\", \"[?];[?]\");\n\n  // Rank checks\n  INFER_ERROR(\"Shape must be rank 1 but is rank 0\", op, \"[];?\");\n  INFER_ERROR(\"Shape must be rank 1 but is rank 0\", op, \"?;[]\");\n}\n\nTEST(ArrayOpsTest, ListDiff_ShapeFn) {\n  ShapeInferenceTestOp op(\"BroadcastGradientArgs\");\n  // Output is always two matching unknown vectors.\n  INFER_OK(op, \"?;?\", \"[?];[?]\");\n  INFER_OK(op, \"[123];[456]\", \"[?];[?]\");\n\n  // Rank checks\n  INFER_ERROR(\"Shape must be rank 1 but is rank 0\", op, \"[];?\");\n  INFER_ERROR(\"Shape must be rank 1 but is rank 0\", op, \"?;[]\");\n}\n\nTEST(ArrayOpsTest, MatrixSetDiag_ShapeFn) {\n  ShapeInferenceTestOp op(\"MatrixSetDiag\");\n\n  // Inputs are input and diagonal.\n\n  // Rank checks.\n  INFER_ERROR(\"Shape must be at least rank 2 but is rank 1\", op, \"[1];?\");\n  INFER_ERROR(\"Shape must be at least rank 1 but is rank 0\", op, \"?;[]\");\n  INFER_ERROR(\"Shape must be at least rank 1 but is rank 0\", op, \"[2,2];[]\");\n  INFER_ERROR(\"Shape must be rank 1 but is rank 2\", op, \"[2,2];[2,2]\");\n\n  // diagonal[-1] must match smallest matrix dimension.\n  INFER_ERROR(\"Dimensions must be equal, but are 2 and 3\", op, \"[2,3];[3]\");\n\n  // Output matches input.\n  INFER_OK(op, \"?;?\", \"in0\");\n  INFER_OK(op, \"[1,2,2];[1,2]\", \"in0\");\n  INFER_OK(op, \"[1,2,3];?\", \"in0\");\n  INFER_OK(op, \"[1,3,2];?\", \"in0\");\n  INFER_OK(op, \"[1,?,2];[?,?]\", \"in0\");\n  INFER_OK(op, \"[1,?,?];[?,2]\", \"in0\");\n\n  // Infer batch shape from diag when input is not fully specified.\n  INFER_OK(op, \"?;[1,2]\", \"[d1_0,?,?]\");\n  INFER_OK(op, \"[?,?,3];[1,2]\", \"[d1_0,d0_1,d0_2]\");\n  INFER_OK(op, \"[?,3,?];[1,2]\", \"[d1_0,d0_1,d0_2]\");\n  INFER_OK(op, \"[?,3,2];[1,2]\", \"[d1_0,d0_1,d0_2]\");\n}\n\nTEST(ArrayOpsTest, ExpandDims_ShapeFn) {\n  ShapeInferenceTestOp op(\"ExpandDims\");\n  op.input_tensors.resize(2);\n\n  // With unknown dim tensor value, output is unknown.\n  INFER_OK(op, \"?;?\", \"?\");\n  Tensor dim_t;\n  op.input_tensors[1] = &dim_t;\n\n  // Expand at front of tensor.\n  for (int32_t idx : {0, -4}) {\n    dim_t = test::AsScalar<int32>(idx);\n    INFER_OK(op, \"?;?\", \"?\");\n    INFER_OK(op, \"[5,?,7];?\", \"[1,d0_0,d0_1,d0_2]\");\n  }\n\n  // Expand at middle of tensor.\n  for (int32_t idx : {1, -3}) {\n    dim_t = test::AsScalar<int32>(idx);\n    INFER_OK(op, \"?;?\", \"?\");\n    INFER_OK(op, \"[5,?,7];?\", \"[d0_0,1,d0_1,d0_2]\");\n\n    // Repeat with int64.\n    dim_t = test::AsScalar<int64_t>(idx);\n    INFER_OK(op, \"?;?\", \"?\");\n    INFER_OK(op, \"[5,?,7];?\", \"[d0_0,1,d0_1,d0_2]\");\n  }\n  for (int32_t idx : {2, -2}) {\n    dim_t = test::AsScalar<int32>(idx);\n    INFER_OK(op, \"?;?\", \"?\");\n    INFER_OK(op, \"[5,?,7];?\", \"[d0_0,d0_1,1,d0_2]\");\n\n    // Repeat with int64.\n    dim_t = test::AsScalar<int64_t>(idx);\n    INFER_OK(op, \"?;?\", \"?\");\n    INFER_OK(op, \"[5,?,7];?\", \"[d0_0,d0_1,1,d0_2]\");\n  }\n\n  for (int32_t idx : {3, -1}) {\n    // Expand at the end.\n    dim_t = test::AsScalar<int32>(idx);\n    INFER_OK(op, \"?;?\", \"?\");\n    INFER_OK(op, \"[5,?,7];?\", \"[d0_0,d0_1,d0_2,1]\");\n\n    // Repeat with int64.\n    dim_t = test::AsScalar<int64_t>(idx);\n    INFER_OK(op, \"?;?\", \"?\");\n    INFER_OK(op, \"[5,?,7];?\", \"[d0_0,d0_1,d0_2,1]\");\n  }\n  for (int32_t idx : {4, -5}) {\n    // Invalid idx.\n    dim_t = test::AsScalar<int32>(idx);\n    INFER_ERROR(\"not in the interval [-4, 3]\", op, \"[5,?,7];?\");\n    dim_t = test::AsScalar<int64_t>(idx);\n    INFER_ERROR(\"not in the interval [-4, 3]\", op, \"[5,?,7];?\");\n  }\n\n  // Expand using an input vector tensor.\n  std::vector<int32> dims;\n  dims.push_back(0);\n  dim_t = test::AsTensor<int32>(dims);\n  INFER_OK(op, \"?;?\", \"?\");\n  INFER_OK(op, \"[5,?,7];?\", \"[1,d0_0,d0_1,d0_2]\");\n\n  // Expand using too many input elements.\n  dims.push_back(1);\n  dim_t = test::AsTensor<int32>(dims);\n  INFER_ERROR(\"'dim' input must be a tensor with a single\", op, \"?;?\");\n  INFER_ERROR(\"'dim' input must be a tensor with a single\", op, \"[5,6,7];?\");\n\n  // Examples from ExpandDims doc.\n  dim_t = test::AsScalar<int32>(0);\n  INFER_OK(op, \"[2];[]\", \"[1,d0_0]\");\n  dim_t = test::AsScalar<int32>(1);\n  INFER_OK(op, \"[2];[]\", \"[d0_0,1]\");\n  dim_t = test::AsScalar<int32>(-1);\n  INFER_OK(op, \"[2];[]\", \"[d0_0,1]\");\n}\n\nTEST(ArrayOpsTest, ImmutableConst_ShapeFn) {\n  ShapeInferenceTestOp op(\"ImmutableConst\");\n\n  TF_ASSERT_OK(NodeDefBuilder(\"test\", \"ImmutableConst\")\n                   .Attr(\"dtype\", DT_FLOAT)\n                   .Attr(\"shape\", TensorShape({1, 2, 3}))\n                   .Attr(\"memory_region_name\", \"test_region\")\n                   .Finalize(&op.node_def));\n  INFER_OK(op, \"\", \"[1,2,3]\");\n\n  TF_ASSERT_OK(NodeDefBuilder(\"test\", \"ImmutableConst\")\n                   .Attr(\"dtype\", DT_FLOAT)\n                   .Attr(\"shape\", TensorShape({}))\n                   .Attr(\"memory_region_name\", \"test_region\")\n                   .Finalize(&op.node_def));\n  INFER_OK(op, \"\", \"[]\");\n\n  TF_ASSERT_OK(NodeDefBuilder(\"test\", \"ImmutableConst\")\n                   .Attr(\"dtype\", DT_FLOAT)\n                   .Attr(\"shape\", \"invalid\")\n                   .Attr(\"memory_region_name\", \"test_region\")\n                   .Finalize(&op.node_def));\n  INFER_ERROR(\"AttrValue had value with type 'string' when 'shape' expected\",\n              op, \"\");\n}\n\nTEST(ArrayOpsTest, Concat_ShapeFn) {\n  ShapeInferenceTestOp op(\"Concat\");\n  auto set_n = [&op](int n) {\n    std::vector<NodeDefBuilder::NodeOut> src_list;\n    src_list.reserve(n);\n    for (int i = 0; i < n; ++i) src_list.emplace_back(\"a\", 0, DT_FLOAT);\n    TF_ASSERT_OK(NodeDefBuilder(\"test\", \"Concat\")\n                     .Input({\"concat_dim\", 0, DT_INT32})\n                     .Input(src_list)\n                     .Attr(\"n\", n)\n                     .Finalize(&op.node_def));\n  };\n\n  // Confirm dimension[0] of the input (the concat_dim) is a scalar.\n  set_n(2);\n  INFER_ERROR(\"Shape must be rank 0 but is rank 1\", op, \"[1];?;?\");\n\n  // Test with the input concat_dim tensor not known. This takes the known rank\n  // of the inputs and makes a tensor of that many unknown dims.\n  set_n(7);\n  INFER_OK(op, \"?;?;?;?;[1,2,3];?;[3,2,1];?\", \"[?,?,?]\");\n  set_n(4);\n  INFER_OK(op, \"?;?;?;[1,2,3,4];[4,3,2,1]\", \"[?,?,?,?]\");\n  INFER_OK(op, \"?;?;?;?;?\", \"?\");  // output rank unknown\n  INFER_ERROR(\"Can't concatenate scalars (use tf.stack instead)\", op,\n              \"?;?;?;[];[]\");\n  INFER_ERROR(\"Shape must be rank 2 but is rank 3\", op, \"?;?;?;[1,2];[1,2,3]\");\n\n  // Test when the concat_dim tensor is known. The concatenated dimension is\n  // summed across all input tensors, and other dimensions are merged.\n  Tensor concat_dim_t;\n  op.input_tensors.push_back(&concat_dim_t);\n  set_n(2);\n\n  // Sum dim 0, merge the other two dims.\n  for (int concat_dim : {0, -3}) {\n    concat_dim_t = test::AsScalar(concat_dim);\n    INFER_OK(op, \"[];[100,2,?];[10,?,3]\", \"[110,d1_1,d2_2]\");\n    INFER_ERROR(\"Dimension 1 in both shapes must be equal, but are 5 and 3\", op,\n                \"[];[100,2,5];[10,?,3]\");\n    // concat_dim can't be summed, as one value is unknown.\n    INFER_OK(op, \"[];[100,2,?];[?,?,3]\", \"[?,d1_1,d2_2]\");\n    INFER_OK(op, \"[];[?,2,?];[10,?,3]\", \"[?,d1_1,d2_2]\");\n  }\n\n  // Test with a higher concat_dim.\n  for (bool use_negative : {false, true}) {\n    concat_dim_t = test::AsScalar(use_negative ? -2 : 1);\n    INFER_OK(op, \"[];[1,100,?];[?,10,3]\", \"[d1_0,110,d2_2]\");\n    concat_dim_t = test::AsScalar(use_negative ? -1 : 1);\n    INFER_OK(op, \"[];[1,100];[?,10]\", \"[d1_0,110]\");\n    INFER_OK(op, \"[];[?,100];[1,10]\", \"[d2_0,110]\");\n\n    // concat_dim is out of bounds.\n    concat_dim_t = test::AsScalar(use_negative ? -2 : 1);\n    INFER_ERROR(\"Shape must be at least rank 2 but is rank 1\", op,\n                \"[];[100];[10,?]\");\n    INFER_ERROR(\"Shape must be at least rank 2 but is rank 1\", op,\n                \"[];[100,5];[10]\");\n  }\n\n  // concat_dim is too low.\n  concat_dim_t = test::AsScalar(-2);\n  INFER_ERROR(\"Shape must be at least rank 2 but is rank 1\", op,\n              \"[];[100];[10,?]\");\n  INFER_ERROR(\"Shape must be at least rank 2 but is rank 1\", op,\n              \"[];[100,5];[10]\");\n\n  // Repeat successful case with several unknown inputs.\n  set_n(5);\n  concat_dim_t = test::AsScalar(1);\n  INFER_OK(op, \"[];?;[1,100,?];[?,?,?];[?,10,3];?\", \"[d2_0,?,d4_2]\");\n}\n\nTEST(ArrayOpsTest, ConcatV2_ShapeFn) {\n  ShapeInferenceTestOp op(\"ConcatV2\");\n  auto set_n = [&op](int n) {\n    std::vector<NodeDefBuilder::NodeOut> src_list;\n    src_list.reserve(n);\n    for (int i = 0; i < n; ++i) src_list.emplace_back(\"a\", 0, DT_FLOAT);\n    TF_ASSERT_OK(NodeDefBuilder(\"test\", \"ConcatV2\")\n                     .Input(src_list)\n                     .Input({\"axis\", 0, DT_INT32})\n                     .Attr(\"n\", n)\n                     .Finalize(&op.node_def));\n  };\n\n  // Confirm dimension[0] of the input (the concat_dim) is a scalar.\n  set_n(2);\n  INFER_ERROR(\"Shape must be rank 0 but is rank 1\", op, \"?;?;[1]\");\n\n  // Test with the input concat_dim tensor not known. This takes the known rank\n  // of the inputs and makes a tensor of that many unknown dims.\n  set_n(7);\n  INFER_OK(op, \"?;?;?;?;[1,2,3];?;[3,2,1];?\", \"[?,?,?]\");\n  set_n(4);\n  INFER_OK(op, \"?;?;[1,2,3,4];[4,3,2,1];?\", \"[?,?,?,?]\");\n  INFER_OK(op, \"?;?;?;?;?\", \"?\");  // output rank unknown\n  INFER_ERROR(\"Can't concatenate scalars (use tf.stack instead)\", op,\n              \"?;?;[];[];?\");\n  INFER_ERROR(\"Shape must be rank 2 but is rank 3\", op, \"?;?;[1,2];[1,2,3];?\");\n\n  // Test when the concat_dim tensor is known. The concatenated dimension is\n  // summed across all input tensors, and other dimensions are merged.\n  Tensor concat_dim_t;\n  op.input_tensors.resize(3);\n  op.input_tensors[2] = &concat_dim_t;\n\n  set_n(2);\n\n  // Invalid concat dim value.\n  // concat_dim_t = test::AsScalar(-1);\n  // INFER_ERROR(\"Expected concat_dim >= 0, but got -1\", op, \"?;?;?\");\n\n  // Sum dim 0, merge the other two dims.\n  concat_dim_t = test::AsScalar(0);\n  INFER_OK(op, \"[100,2,?];[10,?,3];[]\", \"[110,d0_1,d1_2]\");\n  INFER_ERROR(\"Dimension 1 in both shapes must be equal, but are 5 and 3\", op,\n              \"[100,2,5];[10,?,3];[]\");\n  // concat_dim can't be summed, as one value is unknown.\n  INFER_OK(op, \"[100,2,?];[?,?,3];[]\", \"[?,d0_1,d1_2]\");\n  INFER_OK(op, \"[?,2,?];[10,?,3];[]\", \"[?,d0_1,d1_2]\");\n\n  // Test with a higher concat_dim.\n  concat_dim_t = test::AsScalar(1);\n  INFER_OK(op, \"[1,100,?];[?,10,3];[]\", \"[d0_0,110,d1_2]\");\n  INFER_OK(op, \"[1,100];[?,10];[]\", \"[d0_0,110]\");\n  INFER_OK(op, \"[?,100];[1,10];[]\", \"[d1_0,110]\");\n  // concat_dim is too high.\n  INFER_ERROR(\"Shape must be at least rank 2 but is rank 1\", op,\n              \"[100];[10,?];[]\");\n  INFER_ERROR(\"Shape must be at least rank 2 but is rank 1\", op,\n              \"[100,5];[10];[]\");\n  // concat_dim is too low.\n  concat_dim_t = test::AsScalar(-2);\n  INFER_ERROR(\"Shape must be at least rank 2 but is rank 1\", op,\n              \"[100];[10,?];[]\");\n  INFER_ERROR(\"Shape must be at least rank 2 but is rank 1\", op,\n              \"[100,5];[10];[]\");\n\n  // Repeat successful case with several unknown inputs.\n  op.input_tensors.resize(6);\n  op.input_tensors[3] = nullptr;\n  op.input_tensors[5] = &concat_dim_t;\n  concat_dim_t = test::AsScalar(1);\n\n  set_n(5);\n  INFER_OK(op, \"?;[1,100,?];[?,?,?];[?,10,3];?;[]\", \"[d1_0,?,d3_2]\");\n}\n\nTEST(ArrayOpsTest, ConcatOffset_ShapeFn) {\n  ShapeInferenceTestOp op(\"ConcatOffset\");\n\n  const int n = 4;\n  std::vector<NodeDefBuilder::NodeOut> src_list;\n  src_list.reserve(n);\n  for (int i = 0; i < n; ++i) src_list.emplace_back(\"a\", 0, DT_INT32);\n  TF_ASSERT_OK(NodeDefBuilder(\"test\", \"ConcatOffset\")\n                   .Input({\"concat_dim\", 0, DT_INT32})\n                   .Input(src_list)\n                   .Attr(\"n\", n)\n                   .Finalize(&op.node_def));\n  INFER_OK(op, \"?;?;?;?;?\", \"in1;in2;in3;in4\");\n}\n\nTEST(ArrayOpsTest, Reshape_ShapeFn) {\n  ShapeInferenceTestOp op(\"Reshape\");\n  op.input_tensors.resize(2);\n\n  // No valid shape provided.\n  INFER_OK(op, \"?;?\", \"?\");\n  INFER_OK(op, \"[?];?\", \"?\");\n  INFER_OK(op, \"?;[?]\", \"?\");\n  INFER_OK(op, \"[?];[?]\", \"?\");\n  INFER_OK(op, \"[4];[?]\", \"?\");\n\n  // All dimensions provided.\n  Tensor new_shape = test::AsTensor<int32>({1, 2, 3});\n  op.input_tensors[1] = &new_shape;\n  INFER_OK(op, \"?;[3]\", \"[1,2,3]\");\n  INFER_OK(op, \"[?];[3]\", \"[1,2,3]\");\n  INFER_OK(op, \"[6];[3]\", \"[1,2,3]\");\n  // The number of elements should match for the reshape to succeed.\n  INFER_ERROR(\n      \"Cannot reshape a tensor with 12 elements to shape [1,2,3] (6 elements)\",\n      op, \"[3,4];[3]\");\n\n  // Unknown dimensions.\n  // Flatten:\n  new_shape = test::AsTensor<int32>({-1});\n  INFER_OK(op, \"?;[1]\", \"[?]\");\n  INFER_OK(op, \"[?];[1]\", \"[d0_0]\");\n  INFER_OK(op, \"[2,2];[1]\", \"[4]\");\n  // The first dimension is inferred:\n  new_shape = test::AsTensor<int32>({2, -1});\n  INFER_OK(op, \"[3,4];[2]\", \"[2,6]\");\n  // The total number of elements must be evenly divisible by the known\n  // dimensions.\n  INFER_ERROR(\"Dimension size must be evenly divisible by 2 but is 7\", op,\n              \"[7];[2]\");\n  // Multiple missing dimensions cannot be inferred.\n  new_shape = test::AsTensor<int32>({-1, -1, 2});\n  INFER_OK(op, \"[8];[3]\", \"[?,?,2]\");\n  INFER_OK(op, \"?;[3]\", \"[?,?,2]\");\n\n  // Symbolic shape propagation\n  new_shape = test::AsTensor<int32>({-1, 2, 3});\n  INFER_OK(op, \"[?,2,3];[3]\", \"[d0_0,2,3]\");\n\n  // Reshaping to a scalar.\n  new_shape = test::AsTensor<int32>({});\n  INFER_OK(op, \"[1];[0]\", \"[]\");\n  INFER_ERROR(\n      \"Cannot reshape a tensor with 2 elements to shape [] (1 elements)\", op,\n      \"[1,2];[0]\");\n\n  // Reshaping a tensor with no elements.\n  new_shape = test::AsTensor<int32>({-1});\n  INFER_OK(op, \"[0];[1]\", \"[0]\");\n  new_shape = test::AsTensor<int32>({-1, 6});\n  INFER_OK(op, \"[0,2];[1]\", \"[0,6]\");\n  new_shape = test::AsTensor<int32>({0, -1});\n  INFER_OK(op, \"[0,2];[1]\", \"[0,?]\");\n}\n\nTEST(ArrayOpsTest, QuantizedReshape_ShapeFn) {\n  ShapeInferenceTestOp op(\"QuantizedReshape\");\n  op.input_tensors.resize(2);\n\n  // First test a subset of the Reshape_ShapeFn tests. Not all are tested, as\n  // QuantizedReshape uses the same code for the reshape part of the operation.\n  INFER_OK(op, \"?;?;?;?\", \"?;[];[]\");\n  INFER_OK(op, \"[?];?;?;?\", \"?;[];[]\");\n  INFER_OK(op, \"[?];[?];?;?\", \"?;[];[]\");\n  INFER_OK(op, \"[4];[?];?;?\", \"?;[];[]\");\n  Tensor new_shape = test::AsTensor<int32>({1, 2, 3});\n  op.input_tensors[1] = &new_shape;\n  INFER_OK(op, \"[?];[3];?;?\", \"[1,2,3];[];[]\");\n  INFER_OK(op, \"[6];[3];?;?\", \"[1,2,3];[];[]\");\n  INFER_ERROR(\n      \"Cannot reshape a tensor with 12 elements to shape [1,2,3] (6 elements)\",\n      op, \"[3,4];[3];?;?\");\n\n  // Test the scalar rank checks on input_min and input_max.\n  INFER_ERROR(\"must be rank 0\", op, \"?;?;[1];?\");\n  INFER_ERROR(\"must be rank 0\", op, \"?;?;?;[1]\");\n}\n\nTEST(ArrayOpsTest, Placeholder_ShapeFn) {\n  {\n    // 2D shape\n    ShapeInferenceTestOp op(\"Placeholder\");\n    TensorShape shape({1, 2});\n    TF_ASSERT_OK(NodeDefBuilder(\"test\", \"Placeholder\")\n                     .Attr(\"shape\", shape)\n                     .Attr(\"dtype\", DT_FLOAT)\n                     .Finalize(&op.node_def));\n    INFER_OK(op, \"\", \"[1,2]\");\n  }\n\n  {\n    // Scalar shapes are supported\n    ShapeInferenceTestOp op(\"Placeholder\");\n    TensorShape shape({});\n    TF_ASSERT_OK(NodeDefBuilder(\"test\", \"Placeholder\")\n                     .Attr(\"shape\", shape)\n                     .Attr(\"dtype\", DT_FLOAT)\n                     .Finalize(&op.node_def));\n    INFER_OK(op, \"\", \"[]\");\n  }\n\n  {\n    // Partial shape\n    ShapeInferenceTestOp op(\"Placeholder\");\n    const int64_t dims[2] = {1, -1};\n    PartialTensorShape shape;\n    TF_ASSERT_OK(PartialTensorShape::MakePartialShape(dims, 2, &shape));\n    TF_ASSERT_OK(NodeDefBuilder(\"test\", \"Placeholder\")\n                     .Attr(\"shape\", shape)\n                     .Attr(\"dtype\", DT_FLOAT)\n                     .Finalize(&op.node_def));\n    INFER_OK(op, \"\", \"[1,?]\");\n  }\n\n  {\n    // Unknown shape\n    ShapeInferenceTestOp op(\"Placeholder\");\n    PartialTensorShape shape;\n    TF_ASSERT_OK(NodeDefBuilder(\"test\", \"Placeholder\")\n                     .Attr(\"shape\", shape)\n                     .Attr(\"dtype\", DT_FLOAT)\n                     .Finalize(&op.node_def));\n    INFER_OK(op, \"\", \"?\");\n  }\n}\n\nTEST(ArrayOpsTest, Transpose_ShapeFn) {\n  ShapeInferenceTestOp op(\"Transpose\");\n  op.input_tensors.resize(2);\n\n  // Missing shape information.\n  INFER_OK(op, \"?;?\", \"?\");\n  INFER_OK(op, \"?;[?]\", \"?\");\n  INFER_OK(op, \"?;[2]\", \"[?,?]\");\n  INFER_OK(op, \"[?];?\", \"[?]\");\n  INFER_OK(op, \"[?,?];[2]\", \"[?,?]\");\n  INFER_ERROR(\"Dimension must be 3 but is 2\", op, \"[1,2,3];[2]\");\n  Tensor perm = test::AsTensor<int32>({0});\n  op.input_tensors[1] = &perm;\n  INFER_OK(op, \"[?];[?]\", \"[d0_0]\");\n  perm = test::AsTensor<int32>({1, 0});\n  INFER_OK(op, \"?;[2]\", \"[?,?]\");\n  INFER_OK(op, \"[?,?];[2]\", \"[d0_1,d0_0]\");\n  INFER_OK(op, \"[1,?];[2]\", \"[d0_1,d0_0]\");\n  INFER_OK(op, \"?;[0]\", \"in0\");\n\n  // Invalid arguments.\n  perm = test::AsTensor<int32>({1, 2});\n  INFER_ERROR(\"perm dim 2 is out of range of input rank 2\", op, \"[1,2];[2]\");\n  perm = test::AsTensor<int32>({0});\n  INFER_ERROR(\"Dimension must be 2 but is 1\", op, \"[1,2];[1]\");\n\n  // Larger valid cases.\n  perm = test::AsTensor<int32>({1, 0, 3, 4, 2});\n  INFER_OK(op, \"[0,1,2,3,4];[5]\", \"[d0_1,d0_0,d0_3,d0_4,d0_2]\");\n  INFER_OK(op, \"[0,?,2,3,4];[5]\", \"[d0_1,d0_0,d0_3,d0_4,d0_2]\");\n}\n\nTEST(ArrayOpsTest, Bitcast_ShapeFn) {\n  ShapeInferenceTestOp op(\"Bitcast\");\n  auto rebuild_node_def = [&op](DataType input_type, DataType output_type) {\n    TF_ASSERT_OK(NodeDefBuilder(\"test\", \"Bitcast\")\n                     .Input(\"input\", 0, input_type)\n                     .Attr(\"type\", output_type)\n                     .Finalize(&op.node_def));\n  };\n\n  rebuild_node_def(DT_FLOAT, DT_INT32);\n  // No valid shape provided, so output is unknown.\n  INFER_OK(op, \"?\", \"?\");\n\n  // Bitcasting from two equal sizes propagates shape.\n  INFER_OK(op, \"[1,2]\", \"in0\");\n\n  // Bitcasting from smaller to larger reduces the size of the last dimension.\n  rebuild_node_def(DT_INT32, DT_INT64);\n  INFER_OK(op, \"[1,2]\", \"[d0_0]\");  // last dimension matches divisor.\n  // TODO(vrv): Seems like a bug, or at least, too lenient.\n  INFER_OK(op, \"[1,?]\", \"[d0_0]\");\n  // 4 is divisible by 2, but the shape function signature requires\n  // that the last dimension matches the last value exactly.\n  INFER_ERROR(\"does not match\", op, \"[1,4]\");\n  INFER_ERROR(\"does not match\", op, \"[1,3]\");\n\n  // Bitcasting from a larger type to a smaller type extends the dimension\n  rebuild_node_def(DT_INT64, DT_INT32);\n  INFER_OK(op, \"[4,5]\", \"[d0_0,d0_1,2]\");\n  rebuild_node_def(DT_COMPLEX128, DT_INT32);\n  INFER_OK(op, \"[4,5]\", \"[d0_0,d0_1,4]\");\n  rebuild_node_def(DT_COMPLEX128, DT_HALF);\n  INFER_OK(op, \"[4,5]\", \"[d0_0,d0_1,8]\");\n  rebuild_node_def(DT_COMPLEX128, DT_INT8);\n  INFER_OK(op, \"[4,5]\", \"[d0_0,d0_1,16]\");\n\n  // Bitcasting from a POD or quantized datatype is not allowed.\n  rebuild_node_def(DT_STRING, DT_INT32);\n  INFER_ERROR(\"one of the type sizes is zero\", op, \"[1,2,3]\");\n  rebuild_node_def(DT_INT32, DT_STRING);\n  INFER_ERROR(\"one of the type sizes is zero\", op, \"[1,2,3]\");\n}\n\nTEST(ArrayOpsTest, Squeeze_ShapeFn) {\n  ShapeInferenceTestOp op(\"Squeeze\");\n\n  auto rebuild_node_def = [&op](const std::vector<int32>& squeeze_dims) {\n    TF_ASSERT_OK(NodeDefBuilder(\"test\", \"Squeeze\")\n                     .Input(\"input\", 0, DT_FLOAT)\n                     .Attr(\"squeeze_dims\", squeeze_dims)\n                     .Finalize(&op.node_def));\n  };\n\n  // Default squeeze_dims = []\n  rebuild_node_def({});\n\n  // No valid shape provided, so output is unknown.\n  INFER_OK(op, \"?\", \"?\");\n\n  INFER_OK(op, \"[1,4,1,5,1]\", \"[d0_1,d0_3]\");\n\n  // Squeezing all dimensions, but see some unknown values.\n  INFER_OK(op, \"[1,?,1,?,1]\", \"?\");\n\n  // Test simple squeeze of an explicit dimension\n  rebuild_node_def({1});\n  INFER_OK(op, \"[4,1,5]\", \"[d0_0,d0_2]\");\n  // Squeezing unknown dim explicitly, assumes it's 1 at runtime.\n  INFER_OK(op, \"[4,?,5]\", \"[d0_0,d0_2]\");\n\n  // Attempt to squeeze non-one dimension\n  INFER_ERROR(\"Can not squeeze dim[1]\", op, \"[4,6,5]\");\n\n  // Squeeze multiple dimensions\n  rebuild_node_def({1, 2});\n  INFER_OK(op, \"[4,1,1,5]\", \"[d0_0,d0_3]\");\n  rebuild_node_def({1, -2});\n  INFER_OK(op, \"[4,1,1,5]\", \"[d0_0,d0_3]\");\n\n  // Negative squeeze dim\n  rebuild_node_def({-2});\n  INFER_OK(op, \"[4,1,5]\", \"[d0_0,d0_2]\");\n\n  // Test validation of squeeze dimensions\n  rebuild_node_def({-4});\n  INFER_ERROR(\"not in [-3,3)\", op, \"[1,2,3]\");\n  rebuild_node_def({3});\n  INFER_ERROR(\"not in [-3,3)\", op, \"[1,2,3]\");\n}\n\nTEST(ArrayOpsTest, ReverseSequence_ShapeFn) {\n  ShapeInferenceTestOp op(\"ReverseSequence\");\n  auto rebuild_node_def = [&op](const int32_t seq_dim,\n                                const int32_t batch_dim) {\n    TF_ASSERT_OK(NodeDefBuilder(\"test\", \"ReverseSequence\")\n                     .Input(\"input\", 0, DT_FLOAT)\n                     .Input(\"seq_lengths\", 1, DT_INT64)\n                     .Attr(\"seq_dim\", seq_dim)\n                     .Attr(\"batch_dim\", batch_dim)\n                     .Finalize(&op.node_def));\n  };\n\n  rebuild_node_def(1, 2);\n  // No valid shape provided, so output is unknown.\n  INFER_OK(op, \"?;[10]\", \"?\");\n\n  // Bad rank for seq_lengths\n  INFER_ERROR(\"Shape must be rank 1 but is rank 2\", op, \"?;[10,10]\");\n\n  // Validate seq_dim and batch_dim\n  rebuild_node_def(1, 4);\n  INFER_ERROR(\"batch_dim must be < input rank\", op, \"[1,2,3];[3]\");\n  rebuild_node_def(4, 1);\n  INFER_ERROR(\"seq_dim must be < input rank\", op, \"[1,2,3];[3]\");\n\n  rebuild_node_def(1, 2);\n  INFER_OK(op, \"[1,2,3];[3]\", \"[d0_0,d0_1,d0_2]\");\n  // Resolves uncertainty on batch dimension by merging.\n  INFER_OK(op, \"[1,2,?];[3]\", \"[d0_0,d0_1,d1_0]\");\n  INFER_OK(op, \"[1,2,3];[?]\", \"[d0_0,d0_1,d0_2]\");\n}\n\nTEST(ArrayOpsTest, Split_ShapeFn) {\n  ShapeInferenceTestOp op(\"Split\");\n  op.input_tensors.resize(2);\n\n  // No value for split_dim and no input.\n  TF_ASSERT_OK(NodeDefBuilder(\"test\", \"Split\")\n                   .Input(\"split_dim\", 0, DT_INT32)\n                   .Input(\"value\", 1, DT_FLOAT)\n                   .Attr(\"num_split\", 2)\n                   .Finalize(&op.node_def));\n  INFER_OK(op, \"?;?\", \"?;?\");\n  // If the rank is known, we know the rank of each output.\n  INFER_OK(op, \"?;[?,?]\", \"[?,?];[?,?]\");\n\n  // split_dim is unknown but other inputs are known.\n  INFER_OK(op, \"?;[1,4]\", \"[?,?];[?,?]\");\n\n  // split_dim is known.\n  Tensor split_dim = test::AsTensor<int32>({1, 2});\n  op.input_tensors[0] = &split_dim;\n  INFER_ERROR(\"Input must be scalar but has rank 1\", op, \"[?];[?,?]\");\n  split_dim = test::AsScalar<int32>(1);\n  INFER_OK(op, \"?;?\", \"?;?\");\n  INFER_OK(op, \"?;[?,?]\", \"[d1_0,?];[d1_0,?]\");\n  INFER_OK(op, \"?;[1,4]\", \"[d1_0,2];[d1_0,2]\");\n  INFER_OK(op, \"?;[1,?]\", \"[d1_0,?];[d1_0,?]\");\n  INFER_ERROR(\"Dimension size must be evenly divisible by 2 but is 5\", op,\n              \"?;[1,5]\");\n\n  // split_dim too large.\n  split_dim = test::AsScalar<int32>(3);\n  INFER_ERROR(\n      \"Dimension size, given by scalar input 3 must be in range [-3, 3)\", op,\n      \"?;[1,4,8]\");\n\n  // Negative split_dim.\n  split_dim = test::AsScalar<int32>(-1);\n  INFER_OK(op, \"?;?\", \"?;?\");\n  INFER_OK(op, \"?;[?,?]\", \"[d1_0,?];[d1_0,?]\");\n  INFER_OK(op, \"?;[1,?]\", \"[d1_0,?];[d1_0,?]\");\n  INFER_OK(op, \"?;[1,4]\", \"[d1_0,2];[d1_0,2]\");\n  INFER_OK(op, \"?;[1,4,8]\", \"[d1_0,d1_1,4];[d1_0,d1_1,4]\");\n  split_dim = test::AsScalar<int32>(-2);\n  INFER_OK(op, \"?;[1,4,8]\", \"[d1_0,2,d1_2];[d1_0,2,d1_2]\");\n  split_dim = test::AsScalar<int32>(-4);\n  INFER_ERROR(\n      \"Dimension size, given by scalar input -4 must be in range [-3, 3)\", op,\n      \"?;[1,4,8]\");\n}\n\nTEST(ArrayOpsTest, Tile_ShapeFn) {\n  ShapeInferenceTestOp op(\"Tile\");\n  op.input_tensors.resize(2);\n\n  // No value for split_dim and no input.\n  TF_ASSERT_OK(NodeDefBuilder(\"test\", \"Tile\")\n                   .Input(\"input\", 0, DT_FLOAT)\n                   .Input(\"multiples\", 1, DT_INT32)\n                   .Finalize(&op.node_def));\n\n  // If both are unknown, output is unknown.\n  INFER_OK(op, \"?;?\", \"?\");\n\n  // If multiples rank is unknown but input is, output rank is known.\n  INFER_OK(op, \"[2,3,1,4];?\", \"[?,?,?,?]\");\n\n  // Bad rank for 'multiples'\n  INFER_ERROR(\"Shape must be rank 1 but is rank 2\", op, \"[2,3,1,4];[4,1]\");\n\n  // No multiples tensor available, but output rank is known from multiples.\n  INFER_OK(op, \"?;[4]\", \"[?,?,?,?]\");\n\n  // Test a tile of a 4D input.\n  Tensor multiples = test::AsTensor<int32>({2, 3, 4, 5});\n  op.input_tensors[1] = &multiples;\n  INFER_OK(op, \"[2,3,1,4];[4]\", \"[4,9,4,20]\");\n  // Test 64-bit tensor type\n  multiples = test::AsTensor<int64_t>({2, 3, 4, 5});\n  INFER_OK(op, \"[2,3,1,4];[4]\", \"[4,9,4,20]\");\n}\n\nTEST(ArrayOpsTest, EditDistance_ShapeFn) {\n  ShapeInferenceTestOp op(\"EditDistance\");\n  op.input_tensors.resize(6);\n\n  // If the shape tensors are not available, the output shape is unknown.\n  INFER_OK(op, \"[?,?];[?];[4];[?,?];[?];[4]\", \"?\");\n\n  Tensor hypothesis_shape = test::AsTensor<int64_t>({2, 30, 4, 50});\n  op.input_tensors[2] = &hypothesis_shape;\n  Tensor truth_shape = test::AsTensor<int64_t>({20, 3, 40, 5});\n  op.input_tensors[5] = &truth_shape;\n  INFER_OK(op, \"[?,?];[?];[4];[?,?];[?];[4]\", \"[20,30,40]\");\n\n  // Shape elements don't match\n  hypothesis_shape = test::AsTensor<int64_t>({2});\n  op.input_tensors[2] = &hypothesis_shape;\n  INFER_ERROR(\"Num elements of hypothesis_shape does not match truth_shape\", op,\n              \"[?,?];[?];[1];[?,?];[?];[4]\");\n}\n\nTEST(ArrayOpsTest, OneHot_ShapeFn) {\n  ShapeInferenceTestOp op(\"OneHot\");\n  op.input_tensors.resize(4);\n  auto set_axis = [&op](int axis) {\n    TF_ASSERT_OK(NodeDefBuilder(\"test\", \"OneHot\")\n                     .Input(\"indices\", 0, DT_FLOAT)\n                     .Input(\"depth\", 1, DT_INT32)\n                     .Input(\"on_value\", 2, DT_FLOAT)\n                     .Input(\"off_value\", 3, DT_FLOAT)\n                     .Attr(\"axis\", axis)\n                     .Finalize(&op.node_def));\n  };\n\n  // Invalid axis value.\n  set_axis(-2);\n  INFER_ERROR(\"axis must be >= -1\", op, \"?;?;?;?\");\n  set_axis(1);\n\n  // If indices shape is unknown, we return an unknown shape.\n  INFER_OK(op, \"?;[];?;?\", \"?\");\n\n  // Depth must be scalar.\n  Tensor depth = test::AsTensor<int32>({1, 2});\n  op.input_tensors[1] = &depth;\n  INFER_ERROR(\"Input must be scalar but has rank 1\", op, \"?;[2];?;?\");\n\n  // Full information is available.\n  depth = test::AsScalar<int32>(2);\n  INFER_OK(op, \"[1,3,4];[];?;?\", \"[d0_0,2,d0_1,d0_2]\");\n  set_axis(-1);\n  INFER_OK(op, \"[1,3,4];[];?;?\", \"[d0_0,d0_1,d0_2,2]\");\n}\n\nTEST(ArrayOpsTest, ExtractImagePatchesShapeTest) {\n  ShapeInferenceTestOp op(\"ExtractImagePatches\");\n  auto set_op = [&op](const std::vector<int32>& ksizes,\n                      const std::vector<int32>& strides,\n                      const std::vector<int32>& rates, const string& padding) {\n    TF_ASSERT_OK(NodeDefBuilder(\"test\", \"ExtractImagePatches\")\n                     .Input(\"input\", 0, DT_FLOAT)\n                     .Attr(\"ksizes\", ksizes)\n                     .Attr(\"strides\", strides)\n                     .Attr(\"rates\", rates)\n                     .Attr(\"padding\", padding)\n                     .Finalize(&op.node_def));\n  };\n\n  // Just tests that the ksize calculation with rates works.  Most of\n  // the other code is boilerplate that is tested by a variety of\n  // other ops.\n  //\n  // ksizes is 2x2.  rate rows and cols is 2, so ksize_rows and\n  // cols are changed to be 2 + (2 - 1) = 3.  7x7 input with 3x3\n  // filter and 1x1 stride gives a 5x5 output.\n  set_op({1, 2, 2, 1}, {1, 1, 1, 1}, {1, 2, 2, 1}, \"VALID\");\n  INFER_OK(op, \"[1,7,7,2]\", \"[d0_0,5,5,8]\");\n  // With ksizes as 1x1, the output depth is now exactly the last value of the\n  // input and output spatial is reduced as well.\n  set_op({1, 1, 1, 1}, {1, 1, 1, 1}, {1, 2, 2, 1}, \"VALID\");\n  INFER_OK(op, \"[1,7,7,2]\", \"[d0_0,7,7,d0_3]\");\n\n  // Bad ksize rank\n  set_op({1, 2, 2, 1, 1}, {1, 1, 1, 1}, {1, 2, 2, 1}, \"VALID\");\n  INFER_ERROR(\n      \"ExtractImagePatches requires the ksizes attribute to contain 4 values, \"\n      \"but got: 5\",\n      op, \"[1,7,7,2]\");\n}\n\nTEST(ArrayOpsTest, QuantizeAndDequantizeV2_ShapeFn) {\n  ShapeInferenceTestOp op(\"QuantizeAndDequantizeV2\");\n  op.input_tensors.resize(3);\n  TF_ASSERT_OK(NodeDefBuilder(\"test\", \"QuantizeAndDequantizeV2\")\n                   .Input(\"input\", 0, DT_FLOAT)\n                   .Input(\"input_min\", 1, DT_FLOAT)\n                   .Input(\"input_max\", 2, DT_FLOAT)\n                   .Attr(\"signed_input\", true)\n                   .Attr(\"num_bits\", 8)\n                   .Attr(\"range_given\", false)\n                   .Attr(\"narrow_range\", false)\n                   .Attr(\"axis\", -1)\n                   .Finalize(&op.node_def));\n  INFER_OK(op, \"?;?;?\", \"in0\");\n  INFER_OK(op, \"[];?;?\", \"in0\");\n  INFER_OK(op, \"[1,2,?,4,5];?;?\", \"in0\");\n\n  INFER_ERROR(\"Shape must be rank 0 but is rank 1\", op, \"[1,2,?,4,5];[1];[]\");\n  INFER_ERROR(\"Shapes must be equal rank, but are 1 and 0\", op,\n              \"[1,2,?,4,5];[];[1]\");\n  INFER_ERROR(\"Shape must be rank 0 but is rank 1\", op, \"[1,2,?,4,5];[1];[1]\");\n}\n\nTEST(ArrayOpsTest, SpaceToBatch_ShapeFn) {\n  ShapeInferenceTestOp op(\"SpaceToBatch\");\n  op.input_tensors.resize(2);\n  TF_ASSERT_OK(NodeDefBuilder(\"test\", \"SpaceToBatch\")\n                   .Input(\"input\", 0, DT_FLOAT)\n                   .Input(\"paddings\", 1, DT_INT32)\n                   .Attr(\"block_size\", 2)\n                   .Finalize(&op.node_def));\n\n  // Paddings not known, but batch size can be computed.\n  INFER_OK(op, \"[1,10,10,3];[2,2]\", \"[4,?,?,d0_3]\");\n\n  // Unknown paddings means width and height.\n  INFER_OK(op, \"[1,10,10,3];?\", \"[4,?,?,d0_3]\");\n\n  // Paddings not correct shape\n  INFER_ERROR(\"rank\", op, \"[1,10,10,3];[4]\");\n  INFER_ERROR(\"3 and 2\", op, \"[1,10,10,3];[2,3]\");\n\n  Tensor paddings = test::AsTensor<int32>({4, 2, 2, 4}, {{2, 2}});\n  op.input_tensors[1] = &paddings;\n  INFER_OK(op, \"[1,10,10,3];[2,2]\", \"[4,8,8,d0_3]\");\n  paddings = test::AsTensor<int64_t>({4, 2, 2, 4}, {{2, 2}});\n  INFER_OK(op, \"[1,10,10,3];[2,2]\", \"[4,8,8,d0_3]\");\n\n  // Bad paddings values\n  paddings = test::AsTensor<int32>({1, 2, 3, 4}, {{2, 2}});\n  op.input_tensors[1] = &paddings;\n  INFER_ERROR(\"Dimension size must be evenly divisible by 2 but is 13\", op,\n              \"[1,10,10,3];[2,2]\");\n\n  // Negative paddings\n  paddings = test::AsTensor<int32>({1, -2, 3, 4}, {{2, 2}});\n  op.input_tensors[1] = &paddings;\n  INFER_ERROR(\"cannot be negative\", op, \"[1,10,10,3];[2,2]\");\n}\n\nTEST(ArrayOpsTest, SpaceToBatchND_ShapeFn) {\n  ShapeInferenceTestOp op(\"SpaceToBatchND\");\n  op.input_tensors.resize(3);\n  TF_ASSERT_OK(NodeDefBuilder(\"test\", \"SpaceToBatchND\")\n                   .Input(\"input\", 0, DT_FLOAT)\n                   .Input(\"block_shape\", 1, DT_INT32)\n                   .Input(\"paddings\", 2, DT_INT32)\n                   .Finalize(&op.node_def));\n\n  // Verify that input shape and paddings shape can be unknown.\n  INFER_OK(op, \"?;[2];?\", \"?\");\n\n  // Only number of input dimensions is known.\n  INFER_OK(op, \"[?,?,?,?];[2];?\", \"[?,?,?,d0_3]\");\n\n  // Dimensions are partially known.\n  INFER_OK(op, \"[?,?,?,2];[2];?\", \"[?,?,?,d0_3]\");\n\n  {\n    // Dimensions are partially known, block_shape known.\n    Tensor block_shape = test::AsTensor<int32>({2, 3});\n    op.input_tensors[1] = &block_shape;\n    INFER_OK(op, \"[3,?,?,2];[2];?\", \"[18,?,?,d0_3]\");\n\n    // Dimensions are partially known, block_shape and paddings known.\n    {\n      Tensor paddings = test::AsTensor<int32>({1, 1, 0, 1}, {{2, 2}});\n      op.input_tensors[2] = &paddings;\n      INFER_OK(op, \"[3,?,2,2];[2];[2,2]\", \"[18,?,1,d0_3]\");\n      op.input_tensors[2] = nullptr;\n    }\n\n    // Dimensions are fully known, block_shape and paddings are known.\n    {\n      Tensor paddings = test::AsTensor<int32>({1, 1, 0, 0}, {{2, 2}});\n      op.input_tensors[2] = &paddings;\n      INFER_OK(op, \"[3,2,3,2];[2];[2,2]\", \"[18,2,1,d0_3]\");\n      op.input_tensors[2] = nullptr;\n    }\n\n    op.input_tensors[1] = nullptr;\n  }\n\n  INFER_ERROR(\"block_shape must have rank 1\", op, \"?;[1,1];?\");\n  INFER_ERROR(\"block_shape must have known size\", op, \"?;[?];?\");\n\n  {\n    Tensor block_shape = test::AsTensor<int32>({0, 2});\n    op.input_tensors[1] = &block_shape;\n    INFER_ERROR(\"block_shape must be positive\", op, \"[1,2,2];[2];[2,2]\");\n    op.input_tensors[1] = nullptr;\n  }\n\n  {\n    Tensor block_shape = test::AsTensor<int32>({1, 1});\n    op.input_tensors[1] = &block_shape;\n    Tensor paddings = test::AsTensor<int32>({0, -1, 0, 0}, {{2, 2}});\n    op.input_tensors[2] = &paddings;\n    INFER_ERROR(\"paddings cannot be negative\", op, \"[1,2,2];[2];[2,2]\");\n    op.input_tensors[1] = nullptr;\n    op.input_tensors[2] = nullptr;\n  }\n\n  {\n    Tensor block_shape = test::AsTensor<int32>({3, 3});\n    op.input_tensors[1] = &block_shape;\n    Tensor paddings = test::AsTensor<int32>({0, 0, 0, 0}, {{2, 2}});\n    op.input_tensors[2] = &paddings;\n    INFER_ERROR(\"divisible\", op, \"[1,2,3,1];[2];[2,2]\");\n    op.input_tensors[1] = nullptr;\n    op.input_tensors[2] = nullptr;\n  }\n\n  {\n    Tensor block_shape = test::AsTensor<int32>({});\n    op.input_tensors[1] = &block_shape;\n    Tensor paddings = test::AsTensor<int32>({});\n    op.input_tensors[2] = &paddings;\n    INFER_OK(op, \"?;[0];[0,2]\", \"?\");\n    op.input_tensors[1] = nullptr;\n    op.input_tensors[2] = nullptr;\n  }\n\n  INFER_ERROR(\"rank\", op, \"[1,3,3,1];[2];[1]\");\n  INFER_ERROR(\"shape\", op, \"[1,3,3,1];[2];[1,2]\");\n}\n\nTEST(ArrayOpsTest, BatchToSpace_ShapeFn) {\n  ShapeInferenceTestOp op(\"BatchToSpace\");\n  op.input_tensors.resize(2);\n  TF_ASSERT_OK(NodeDefBuilder(\"test\", \"BatchToSpace\")\n                   .Input(\"input\", 0, DT_FLOAT)\n                   .Input(\"crops\", 1, DT_INT32)\n                   .Attr(\"block_size\", 2)\n                   .Finalize(&op.node_def));\n\n  // croppings not known, but batch size can be computed.\n  INFER_OK(op, \"[4,8,8,3];[2,2]\", \"[1,?,?,d0_3]\");\n\n  // block_size not compatible with batch size\n  INFER_ERROR(\"Dimension size must be evenly divisible by\", op,\n              \"[5,8,8,3];[2,2]\");\n\n  // Unknown croppings means unknown width and height.\n  INFER_OK(op, \"[4,8,8,3];?\", \"[1,?,?,d0_3]\");\n\n  // croppings not correct shape\n  INFER_ERROR(\"rank\", op, \"[4,8,8,3];[4]\");\n  INFER_ERROR(\"3 and 2\", op, \"[4,8,8,3];[2,3]\");\n\n  Tensor croppings = test::AsTensor<int64_t>({4, 2, 2, 4}, {{2, 2}});\n  op.input_tensors[1] = &croppings;\n  INFER_OK(op, \"[4,8,8,3];[2,2]\", \"[1,10,10,d0_3]\");\n\n  // Bad croppings values\n  croppings = test::AsTensor<int32>({100, 2, 3, 4}, {{2, 2}});\n  op.input_tensors[1] = &croppings;\n  INFER_ERROR(\"Negative dimension size caused by subtracting\", op,\n              \"[4,8,8,3];[2,2]\");\n  croppings = test::AsTensor<int32>({1, 2, 3, 400}, {{2, 2}});\n  op.input_tensors[1] = &croppings;\n  INFER_ERROR(\"Negative dimension size caused by subtracting\", op,\n              \"[4,8,8,3];[2,2]\");\n\n  // Negative paddings\n  croppings = test::AsTensor<int32>({1, -2, 3, 4}, {{2, 2}});\n  op.input_tensors[1] = &croppings;\n  INFER_ERROR(\"cannot be negative\", op, \"[4,8,8,3];[2,2]\");\n}\n\nTEST(ArrayOpsTest, BatchToSpaceND_ShapeFn) {\n  ShapeInferenceTestOp op(\"BatchToSpaceND\");\n  op.input_tensors.resize(3);\n  TF_ASSERT_OK(NodeDefBuilder(\"test\", \"BatchToSpaceND\")\n                   .Input(\"input\", 0, DT_FLOAT)\n                   .Input(\"block_shape\", 1, DT_INT32)\n                   .Input(\"crops\", 2, DT_INT32)\n                   .Finalize(&op.node_def));\n\n  // Verify that input shape and crops shape can be unknown.\n  INFER_OK(op, \"?;[2];?\", \"?\");\n\n  // Only number of input dimensions is known.\n  INFER_OK(op, \"[?,?,?,?];[2];?\", \"[?,?,?,d0_3]\");\n\n  {\n    // Dimensions are partially known, block_shape known.\n    Tensor block_shape = test::AsTensor<int32>({2, 3});\n    op.input_tensors[1] = &block_shape;\n    INFER_OK(op, \"[?,?,?,2];[2];?\", \"[?,?,?,d0_3]\");\n\n    INFER_OK(op, \"[18,?,?,2];[2];?\", \"[3,?,?,d0_3]\");\n\n    // Dimensions are partially known, block_shape and crops known.\n    {\n      Tensor crops = test::AsTensor<int32>({1, 1, 0, 1}, {{2, 2}});\n      op.input_tensors[2] = &crops;\n      INFER_OK(op, \"[18,?,2,2];[2];[2,2]\", \"[3,?,5,d0_3]\");\n      op.input_tensors[2] = nullptr;\n    }\n\n    // Dimensions are fully known, block_shape and crops are known.\n    {\n      Tensor crops = test::AsTensor<int32>({1, 1, 0, 0}, {{2, 2}});\n      op.input_tensors[2] = &crops;\n      INFER_OK(op, \"[18,2,1,2];[2];[2,2]\", \"[3,2,3,d0_3]\");\n      op.input_tensors[2] = nullptr;\n    }\n\n    op.input_tensors[1] = nullptr;\n  }\n\n  INFER_ERROR(\"block_shape must have rank 1\", op, \"?;[1,1];?\");\n  INFER_ERROR(\"block_shape must have known size\", op, \"?;[?];?\");\n  INFER_ERROR(\"rank\", op, \"[2,2];[2];[2,2]\");\n  INFER_ERROR(\"rank\", op, \"[2,2,3];[3];[3,2]\");\n\n  {\n    Tensor block_shape = test::AsTensor<int32>({0, 2});\n    op.input_tensors[1] = &block_shape;\n    INFER_ERROR(\"block_shape must be positive\", op, \"[1,2,2];[2];[2,2]\");\n    op.input_tensors[1] = nullptr;\n  }\n\n  {\n    Tensor block_shape = test::AsTensor<int32>({1, 1});\n    op.input_tensors[1] = &block_shape;\n    Tensor paddings = test::AsTensor<int32>({0, -1, 0, 0}, {{2, 2}});\n    op.input_tensors[2] = &paddings;\n    INFER_ERROR(\"crops cannot be negative\", op, \"[1,2,2];[2];[2,2]\");\n    op.input_tensors[1] = nullptr;\n    op.input_tensors[2] = nullptr;\n  }\n\n  // The amount to crop exceeds the padded size.\n  {\n    Tensor block_shape = test::AsTensor<int32>({2, 2});\n    op.input_tensors[1] = &block_shape;\n    Tensor crops = test::AsTensor<int32>({3, 2, 0, 0}, {{2, 2}});\n    op.input_tensors[2] = &crops;\n    INFER_ERROR(\"Negative\", op, \"[4,2,3,1];[2];[2,2]\");\n    op.input_tensors[1] = nullptr;\n    op.input_tensors[2] = nullptr;\n  }\n\n  // The batch size is not divisible by the product of the block_shape.\n  {\n    Tensor block_shape = test::AsTensor<int32>({2, 3});\n    op.input_tensors[1] = &block_shape;\n    INFER_ERROR(\"divisible\", op, \"[3,1,1,1];[2];[2,2]\");\n    op.input_tensors[1] = nullptr;\n  }\n}\n\nTEST(ArrayOpsTest, SpaceToDepth_ShapeFn) {\n  ShapeInferenceTestOp op(\"SpaceToDepth\");\n  TF_ASSERT_OK(NodeDefBuilder(\"test\", \"SpaceToDepth\")\n                   .Input(\"input\", 0, DT_FLOAT)\n                   .Attr(\"block_size\", 2)\n                   .Finalize(&op.node_def));\n\n  INFER_OK(op, \"[1,2,4,4]\", \"[d0_0,1,2,16]\");\n\n  // block_size not compatible with space\n  INFER_ERROR(\"Dimension size must be evenly divisible by 2 but is 3\", op,\n              \"[1,3,8,4]\");\n  INFER_ERROR(\"Dimension size must be evenly divisible by 2 but is 5\", op,\n              \"[1,2,5,4]\");\n\n  // Unknown depth --> Unknown depth.\n  INFER_OK(op, \"[1,2,4,?]\", \"[d0_0,1,2,?]\");\n}\n\nTEST(ArrayOpsTest, DepthToSpace_ShapeFn) {\n  ShapeInferenceTestOp op(\"DepthToSpace\");\n  TF_ASSERT_OK(NodeDefBuilder(\"test\", \"DepthToSpace\")\n                   .Input(\"input\", 0, DT_FLOAT)\n                   .Attr(\"block_size\", 2)\n                   .Finalize(&op.node_def));\n\n  INFER_OK(op, \"[1,1,2,16]\", \"[d0_0,2,4,4]\");\n\n  // Bad depth\n  INFER_ERROR(\"Dimension size must be evenly divisible by 4 but is 15\", op,\n              \"[1,1,2,15]\");\n\n  // Unknown depth --> Unknown depth.\n  INFER_OK(op, \"[1,2,4,?]\", \"[d0_0,4,8,?]\");\n\n  // Check another block size.\n  TF_ASSERT_OK(NodeDefBuilder(\"test\", \"DepthToSpace\")\n                   .Input(\"input\", 0, DT_FLOAT)\n                   .Attr(\"block_size\", 10)\n                   .Finalize(&op.node_def));\n  INFER_OK(op, \"[1,1,2,200]\", \"[d0_0,10,20,2]\");\n}\n\nTEST(ArrayOpsTest, Slice_ShapeFn) {\n  ShapeInferenceTestOp op(\"Slice\");\n  TF_ASSERT_OK(NodeDefBuilder(\"test\", \"Slice\")\n                   .Input(\"input\", 0, DT_FLOAT)\n                   .Input(\"begin\", 1, DT_INT64)\n                   .Input(\"sizes\", 2, DT_INT64)\n                   .Finalize(&op.node_def));\n\n  // Known rank of input and shape of begin/sizes, but unknown values.\n  // The best we know is the rank of the output.\n  INFER_OK(op, \"[2,3,4,5];[4];[4]\", \"[?,?,?,?]\");\n\n  // Unknown shape of begin/sizes, we still know the rank.\n  INFER_OK(op, \"[2,3,4,5];[?];[?]\", \"[?,?,?,?]\");\n  // Unknown all around\n  INFER_OK(op, \"?;[?];[?]\", \"?\");\n  // Can infer based on begin\n  INFER_OK(op, \"?;[4];[?]\", \"[?,?,?,?]\");\n\n  // Bad rank of begin, sizes\n  INFER_ERROR(\"must be rank 1\", op, \"[2,3,4,5];[2,3];[3]\");\n  INFER_ERROR(\"must be rank 1\", op, \"[2,3,4,5];[2];[3,4]\");\n  // Length of begin doesn't match input rank\n  INFER_ERROR(\"must be rank 2\", op, \"[2,3,4,5];[2];[2]\");\n\n  // Tests with known values.\n  op.input_tensors.resize(3);\n  Tensor begin = test::AsTensor<int32>({0, 1, 2, 1});\n  Tensor sizes = test::AsTensor<int32>({1, 2, 1, 3});\n  op.input_tensors[1] = &begin;\n  op.input_tensors[2] = &sizes;\n  INFER_OK(op, \"[2,3,4,5];[4];[4]\", \"[1,2,1,3]\");\n\n  // -1 in sizes means \"get the rest\"\n  sizes = test::AsTensor<int32>({-1, -1, 1, -1});\n  INFER_OK(op, \"[2,3,4,5];[4];[4]\", \"[d0_0,2,1,4]\");\n\n  begin = test::AsTensor<int32>({0, 1, 2, 6});\n  sizes = test::AsTensor<int32>({-1, -1, -1, -1});\n  INFER_ERROR(\"Negative dimension size\", op, \"[2,3,4,5];[4];[4]\");\n\n  begin = test::AsTensor<int32>({0, 1, 2, 5});\n  sizes = test::AsTensor<int32>({-1, -1, -1, -2});\n  INFER_ERROR(\"cannot be < -1\", op, \"[2,3,4,5];[4];[4]\");\n}\n\nTEST(ArrayOpsTest, StridedSlice_ShapeFn) {\n  ShapeInferenceTestOp op(\"StridedSlice\");\n  TF_ASSERT_OK(NodeDefBuilder(\"test\", \"StridedSlice\")\n                   .Input(\"input\", 0, DT_FLOAT)\n                   .Input(\"begin\", 1, DT_INT32)\n                   .Input(\"end\", 2, DT_INT32)\n                   .Input(\"strides\", 3, DT_INT32)\n                   .Attr(\"shrink_axis_mask\", 1)\n                   .Finalize(&op.node_def));\n  op.input_tensors.resize(4);\n  Tensor strides = test::AsTensor<int32>({1});\n  op.input_tensors[3] = &strides;\n  // Slicing on the 0-th dimension.\n  INFER_OK(op, \"[2,3,4,5];[1];[1];[1]\", \"[3,4,5]\");\n  // Slicing on the 0-th dimension. This time some of the result dimension is 0.\n  INFER_OK(op, \"[2,0,3,4];[1];[1];[1]\", \"[0,3,4]\");\n}\n\nTEST(ArrayOpsTest, StridedSliceGrad_ShapeFn) {\n  ShapeInferenceTestOp op(\"StridedSliceGrad\");\n  op.input_tensors.resize(5);\n  INFER_OK(op, \"?;?;?;?;?\", \"?\");\n  INFER_OK(op, \"[?];?;?;?;?\", \"?\");\n  INFER_OK(op, \"[4];?;?;?;?\", \"[?,?,?,?]\");\n\n  Tensor in_t = test::AsTensor<int32>({1, 2, 3, 4});\n  op.input_tensors[0] = &in_t;\n  INFER_OK(op, \"[4];?;?;?;?\", \"[1,2,3,4]\");\n}\n\nTEST(ArrayOpsTest, UnchangedWithQuantizationScalars_ShapeFn) {\n  for (const char* op_name : {\"Dequantize\", \"FakeQuantWithMinMaxVars\"}) {\n    ShapeInferenceTestOp op(op_name);\n    if (op_name[0] == 'D') {\n      TF_ASSERT_OK(NodeDefBuilder(\"test\", \"Dequantize\")\n                       .Input(\"input\", 0, DT_QINT8)\n                       .Input(\"input_min\", 1, DT_FLOAT)\n                       .Input(\"input_max\", 2, DT_FLOAT)\n                       .Attr(\"T\", DataTypeToEnum<qint8>::v())\n                       .Attr(\"mode\", \"SCALED\")\n                       .Attr(\"axis\", -1)\n                       .Finalize(&op.node_def));\n    }\n    INFER_OK(op, \"?;?;?\", \"in0\");\n    INFER_OK(op, \"[1,?,3];[];[]\", \"in0\");\n\n    // Rank check scalars.\n    INFER_ERROR(\"be rank 0\", op, \"[1,?,3];[1];[]\");\n    INFER_ERROR(\"be rank 0\", op, \"[1,?,3];[];[1]\");\n  }\n}\n\nTEST(ArrayOpsTest, FakeQuantWithMinMaxVarsPerChannel) {\n  ShapeInferenceTestOp op(\"FakeQuantWithMinMaxVarsPerChannel\");\n\n  INFER_OK(op, \"?;?;?\", \"in0\");\n  INFER_OK(op, \"[?];?;?\", \"in0\");\n  INFER_OK(op, \"[1,?,3];[3];[3]\", \"in0\");\n  INFER_OK(op, \"[3];[3];[3]\", \"in0\");\n\n  // Rank check vectors.\n  INFER_ERROR(\"be rank 1\", op, \"[1,?,3];[1];[]\");\n  INFER_ERROR(\"be rank 1\", op, \"[1,?,3];[];[1]\");\n\n  // Vectors must match each other, and match last dim of input.\n  INFER_ERROR(\"must be equal\", op, \"[1,?,3];[2];[?]\");\n  INFER_ERROR(\"must be equal\", op, \"[1,?,3];[?];[2]\");\n  INFER_ERROR(\"must be equal\", op, \"[1,?,?];[1];[2]\");\n  INFER_ERROR(\"must be equal\", op, \"[5];[4];[?]\");\n}\n\nTEST(ArrayOpsTest, FakeQuantWithMinMaxVarsPerChannelGradient) {\n  ShapeInferenceTestOp op(\"FakeQuantWithMinMaxVarsPerChannelGradient\");\n\n  INFER_OK(op, \"?;?;?;?\", \"in0;[?];[?]\");\n  INFER_OK(op, \"[3];[3];[3];[3]\", \"in0;in3;in3\");\n  INFER_OK(op, \"[1,3];[1,3];[3];[3]\", \"in0;in3;in3\");\n  INFER_OK(op, \"[1,2,3,4];[1,2,3,4];[4];[4]\", \"in0;in3;in3\");\n\n  // Rank check vectors.\n  INFER_ERROR(\"be equal rank\", op, \"[1,?,3];[1,?,3];[3];[]\");\n  INFER_ERROR(\"be rank 1\", op, \"[1,?,3];[1,?,3];[];[3]\");\n  INFER_ERROR(\"be at least rank 1\", op, \"[];[];[1];[1]\");\n  INFER_ERROR(\"be at most rank 4\", op, \"[1,2,3,4,5];[1,2,3,4,5];[1];[1]\");\n\n  // Vectors must match each other, and match last dim of input.\n  INFER_ERROR(\"must be equal\", op, \"[1,3];[1,3];[2];[3]\");\n  INFER_ERROR(\"must be equal\", op, \"[1,3];[1,3];[3];[2]\");\n}\n\nTEST(ArrayOpsTest, QuantizedConcat_ShapeFn) {\n  ShapeInferenceTestOp op(\"QuantizedConcat\");\n  auto set_n = [&op](int n) {\n    std::vector<NodeDefBuilder::NodeOut> src_list;\n    std::vector<NodeDefBuilder::NodeOut> limit_list;\n    for (int i = 0; i < n; ++i) {\n      src_list.emplace_back(\"a\", 0, DT_QUINT8);\n      limit_list.emplace_back(\"b\", 0, DT_FLOAT);\n    }\n    TF_ASSERT_OK(NodeDefBuilder(\"test\", \"QuantizedConcat\")\n                     .Input({\"concat_dim\", 0, DT_INT32})\n                     .Input(src_list)\n                     .Input(limit_list)\n                     .Input(limit_list)\n                     .Attr(\"N\", n)\n                     .Finalize(&op.node_def));\n  };\n\n  // Confirm dimension[0] of the input (the concat_dim) is a scalar.\n  set_n(1);\n  INFER_ERROR(\"Shape must be rank 0 but is rank 1\", op, \"[1];?;?;?\");\n\n  // Last 2*<N> are all scalars.\n  set_n(2);\n  INFER_ERROR(\"must be rank 0\", op, \"[];?;?;?;?;?;[1]\");\n  INFER_ERROR(\"must be rank 0\", op, \"[];?;?;?;?;[1];?\");\n  INFER_ERROR(\"must be rank 0\", op, \"[];?;?;?;[1];?;?\");\n  INFER_ERROR(\"must be rank 0\", op, \"[];?;?;[1];?;?;?\");\n\n  // First is concat dim; next N must be compatible for concat.\n  set_n(2);\n  INFER_ERROR(\"must be rank 2\", op, \"[];[1,2];[1,2,3];?;?;?;?\");\n  INFER_OK(op, \"[];[1,2];[1,3];?;?;?;?\", \"[?,?];[];[]\");\n\n  // Test when the concat_dim tensor is known. The concatenated dimension is\n  // summed across all input tensors, and other dimensions are merged.\n  Tensor concat_dim_t;\n  op.input_tensors.push_back(&concat_dim_t);\n  set_n(2);\n  concat_dim_t = test::AsScalar(0);  // Sum dim 0, merge the other two dims.\n  INFER_OK(op, \"[];[100,2,?];[10,?,3];?;?;?;?\", \"[110,d1_1,d2_2];[];[]\");\n  INFER_ERROR(\"Dimension 1 in both shapes must be equal, but are 5 and 3\", op,\n              \"[];[100,2,5];[10,?,3];?;?;?;?\");\n  // Note that other cases of concat are covered in the Concat tests.\n}\n\nTEST(StateOpsTest, _ParallelConcatStart_ShapeFn) {\n  ShapeInferenceTestOp op(\"_ParallelConcatStart\");\n  TensorShape shape({1, 2, 3});\n  TensorShapeProto shape_proto;\n  shape.AsProto(&shape_proto);\n  TF_ASSERT_OK(NodeDefBuilder(\"test\", \"_ParallelConcatStart\")\n                   .Attr(\"shape\", shape_proto)\n                   .Attr(\"dtype\", DT_FLOAT)\n                   .Finalize(&op.node_def));\n  INFER_OK(op, \"\", \"[1,2,3]\");\n}\n\n}  // end namespace tensorflow\n"], "fixing_code": ["/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n\n#include <algorithm>\n#include <ostream>\n\n#include \"tensorflow/core/framework/common_shape_fns.h\"\n#include \"tensorflow/core/framework/kernel_shape_util.h\"\n#include \"tensorflow/core/framework/op.h\"\n#include \"tensorflow/core/framework/shape_inference.h\"\n#include \"tensorflow/core/framework/tensor.pb.h\"\n#include \"tensorflow/core/framework/types.h\"\n#include \"tensorflow/core/framework/types.pb.h\"\n#include \"tensorflow/core/lib/core/errors.h\"\n#include \"tensorflow/core/util/mirror_pad_mode.h\"\n#include \"tensorflow/core/util/padding.h\"\n#include \"tensorflow/core/util/strided_slice_op.h\"\n#include \"tensorflow/core/util/tensor_format.h\"\n\nnamespace tensorflow {\n\nusing shape_inference::DimensionHandle;\nusing shape_inference::InferenceContext;\nusing shape_inference::ShapeHandle;\nusing shape_inference::UnchangedShape;\n\nnamespace {\n\nStatus GetAxisForPackAndUnpack(InferenceContext* c, int32_t rank_after_pack,\n                               int32* axis) {\n  TF_RETURN_IF_ERROR(c->GetAttr(\"axis\", axis));\n  if (*axis < -1 * rank_after_pack || *axis >= rank_after_pack) {\n    return errors::InvalidArgument(\"Invalid axis: \", *axis, \"; must be in [\",\n                                   -1 * rank_after_pack, \",\", rank_after_pack,\n                                   \")\");\n  }\n  if (*axis < 0) *axis = (rank_after_pack + *axis);\n  return Status::OK();\n}\n\ntemplate <typename T>\nstd::vector<int64_t> AsInt64(const Tensor* tensor, int64_t num_elements) {\n  std::vector<int64_t> ret(num_elements);\n  auto data = tensor->vec<T>();\n  for (int64_t i = 0; i < num_elements; ++i) {\n    ret[i] = data(i);\n  }\n  return ret;\n}\n\ntemplate <typename T>\nStatus PadKnown(InferenceContext* c, ShapeHandle input,\n                const Tensor* paddings_t, int64_t num_dims) {\n  // paddings_t is known.\n  std::vector<DimensionHandle> dims(num_dims);\n  auto paddings_data = paddings_t->matrix<T>();\n  for (int64_t i = 0; i < num_dims; ++i) {\n    const T pad0 = paddings_data(i, 0);\n    const T pad1 = paddings_data(i, 1);\n    if (pad0 < 0 || pad1 < 0) {\n      return errors::InvalidArgument(\"Paddings must be non-negative\");\n    }\n    TF_RETURN_IF_ERROR(c->Add(c->Dim(input, i), pad0 + pad1, &dims[i]));\n  }\n  c->set_output(0, c->MakeShape(dims));\n  return Status::OK();\n}\n\nStatus PadShapeFn(InferenceContext* c) {\n  // Paddings is a matrix of [input_rank, 2].\n  ShapeHandle paddings;\n  TF_RETURN_IF_ERROR(c->WithRank(c->input(1), 2, &paddings));\n  DimensionHandle unused;\n  TF_RETURN_IF_ERROR(c->WithValue(c->Dim(paddings, 1), 2, &unused));\n\n  // n_dim and input.rank are equivalent.\n  ShapeHandle input = c->input(0);\n  DimensionHandle n_dim = c->Dim(paddings, 0);\n  if (c->ValueKnown(n_dim)) {\n    TF_RETURN_IF_ERROR(c->WithRank(input, c->Value(n_dim), &input));\n  } else if (c->RankKnown(input)) {\n    TF_RETURN_IF_ERROR(c->WithValue(n_dim, c->Rank(input), &n_dim));\n  }\n\n  const Tensor* paddings_t = c->input_tensor(1);\n\n  // paddings_t is unknown\n  if (paddings_t == nullptr) {\n    if (c->ValueKnown(n_dim)) {\n      // Make output with n_dim unknown dims.\n      c->set_output(0, c->UnknownShapeOfRank(c->Value(n_dim)));\n    } else {\n      c->set_output(0, c->UnknownShape());\n    }\n    return Status::OK();\n  }\n\n  const int64_t num_dims = paddings_t->shape().dim_size(0);\n  TF_RETURN_IF_ERROR(c->WithRank(input, num_dims, &input));\n  TF_RETURN_IF_ERROR(c->WithValue(n_dim, num_dims, &n_dim));\n\n  if (paddings_t->dtype() == DT_INT32) {\n    return PadKnown<int32>(c, input, paddings_t, num_dims);\n  } else {\n    return PadKnown<int64_t>(c, input, paddings_t, num_dims);\n  }\n}\n\nStatus TransposeShapeFn(InferenceContext* c) {\n  ShapeHandle input = c->input(0);\n  ShapeHandle perm_shape = c->input(1);\n  const Tensor* perm = c->input_tensor(1);\n  DimensionHandle perm_elems = c->NumElements(perm_shape);\n  // If we don't have rank information on the input or value information on\n  // perm we can't return any shape information, otherwise we have enough\n  // information to at least find the rank of the output.\n  if (!c->RankKnown(input) && !c->ValueKnown(perm_elems) && perm == nullptr) {\n    c->set_output(0, c->UnknownShape());\n    return Status::OK();\n  }\n\n  // Find our value of the rank.\n  int64_t rank;\n  if (c->RankKnown(input)) {\n    rank = c->Rank(input);\n  } else if (c->ValueKnown(perm_elems)) {\n    rank = c->Value(perm_elems);\n  } else {\n    rank = perm->NumElements();\n  }\n  if (!c->RankKnown(input) && rank < 2) {\n    // A permutation array containing a single element is ambiguous. It could\n    // indicate either a scalar or a 1-dimensional array, both of which the\n    // transpose op returns unchanged.\n    c->set_output(0, input);\n    return Status::OK();\n  }\n\n  std::vector<DimensionHandle> dims;\n  dims.resize(rank);\n  TF_RETURN_IF_ERROR(c->WithRank(input, rank, &input));\n  // Ensure that perm is a vector and has rank elements.\n  TF_RETURN_IF_ERROR(c->WithRank(perm_shape, 1, &perm_shape));\n  TF_RETURN_IF_ERROR(c->WithValue(perm_elems, rank, &perm_elems));\n\n  // If we know the rank of the input and the value of perm, we can return\n  // all shape information, otherwise we can only return rank information,\n  // but no information for the dimensions.\n  if (perm != nullptr) {\n    std::vector<int64_t> data;\n    if (perm->dtype() == DT_INT32) {\n      data = AsInt64<int32>(perm, rank);\n    } else {\n      data = AsInt64<int64_t>(perm, rank);\n    }\n\n    for (int32_t i = 0; i < rank; ++i) {\n      int64_t in_idx = data[i];\n      if (in_idx >= rank) {\n        return errors::InvalidArgument(\"perm dim \", in_idx,\n                                       \" is out of range of input rank \", rank);\n      }\n      dims[i] = c->Dim(input, in_idx);\n    }\n  } else {\n    for (int i = 0; i < rank; ++i) {\n      dims[i] = c->UnknownDim();\n    }\n  }\n\n  c->set_output(0, c->MakeShape(dims));\n  return Status::OK();\n}\n\nStatus SetOutputShapeForReshape(InferenceContext* c) {\n  ShapeHandle in = c->input(0);\n  ShapeHandle out;\n  TF_RETURN_IF_ERROR(c->MakeShapeFromShapeTensor(1, &out));\n\n  if (!c->RankKnown(out)) {\n    // We have no information about the shape of the output.\n    c->set_output(0, out);\n    return Status::OK();\n  }\n  if (c->RankKnown(in)) {\n    // We don't know the number of output elements, but we can try to infer\n    // the missing dimension.\n    bool too_many_unknown = false;\n    int32_t out_unknown_idx = -1;\n\n    DimensionHandle known_out_elems = c->NumElements(out);\n    if (!c->ValueKnown(known_out_elems)) {\n      known_out_elems = c->MakeDim(1);\n      for (int32_t i = 0; i < c->Rank(out); ++i) {\n        DimensionHandle dim = c->Dim(out, i);\n        if (!c->ValueKnown(dim)) {\n          if (out_unknown_idx >= 0) {\n            too_many_unknown = true;\n            break;\n          }\n          out_unknown_idx = i;\n        } else {\n          TF_RETURN_IF_ERROR(\n              c->Multiply(known_out_elems, dim, &known_out_elems));\n        }\n      }\n    }\n    int32_t in_unknown_idx = -1;\n    DimensionHandle known_in_elems = c->NumElements(in);\n    if (!c->ValueKnown(known_in_elems)) {\n      known_in_elems = c->MakeDim(1);\n      for (int32_t i = 0; i < c->Rank(in); ++i) {\n        DimensionHandle dim = c->Dim(in, i);\n        if (!c->ValueKnown(dim)) {\n          if (in_unknown_idx >= 0) {\n            too_many_unknown = true;\n            break;\n          }\n          in_unknown_idx = i;\n        } else {\n          TF_RETURN_IF_ERROR(c->Multiply(known_in_elems, dim, &known_in_elems));\n        }\n      }\n    }\n\n    if (!too_many_unknown) {\n      if (in_unknown_idx < 0 && out_unknown_idx < 0) {\n        // Just check that the dimensions match.\n        if (c->Value(known_in_elems) != c->Value(known_out_elems)) {\n          return errors::InvalidArgument(\n              \"Cannot reshape a tensor with \", c->DebugString(known_in_elems),\n              \" elements to shape \", c->DebugString(out), \" (\",\n              c->DebugString(known_out_elems), \" elements)\");\n        }\n      } else if (in_unknown_idx < 0 && out_unknown_idx >= 0 &&\n                 c->Value(known_out_elems) > 0) {\n        // Input fully known, infer the one missing output dim\n        DimensionHandle inferred_dim;\n        TF_RETURN_IF_ERROR(c->Divide(known_in_elems, c->Value(known_out_elems),\n                                     true /* evenly_divisible */,\n                                     &inferred_dim));\n        TF_RETURN_IF_ERROR(\n            c->ReplaceDim(out, out_unknown_idx, inferred_dim, &out));\n\n      } else if (in_unknown_idx >= 0 && out_unknown_idx < 0 &&\n                 c->Value(known_in_elems) != 0) {\n        // Output fully known, infer the one missing input dim\n        DimensionHandle inferred_dim;\n        TF_RETURN_IF_ERROR(c->Divide(known_out_elems, c->Value(known_in_elems),\n                                     true /* evenly_divisible */,\n                                     &inferred_dim));\n        DimensionHandle unknown_in_dim = c->Dim(in, in_unknown_idx);\n        TF_RETURN_IF_ERROR(\n            c->Merge(unknown_in_dim, inferred_dim, &unknown_in_dim));\n      } else if (in_unknown_idx >= 0 && out_unknown_idx >= 0) {\n        // Exactly one unknown dimension in both input and output. These 2 are\n        // equal iff the known elements are equal.\n        if (c->Value(known_in_elems) == c->Value(known_out_elems)) {\n          DimensionHandle unknown_in_dim = c->Dim(in, in_unknown_idx);\n          TF_RETURN_IF_ERROR(\n              c->ReplaceDim(out, out_unknown_idx, unknown_in_dim, &out));\n        }\n      }\n    }\n  }\n  c->set_output(0, out);\n  return Status::OK();\n}\n\n}  // namespace\n\nREGISTER_OP(\"ParallelConcat\")\n    .Input(\"values: N * T\")\n    .Output(\"output: T\")\n    .Attr(\"N: int >= 1\")\n    .Attr(\"T: type\")\n    .Attr(\"shape: shape\")\n    .SetShapeFn([](InferenceContext* c) {\n      // Validate that the shape attr is correct.\n      PartialTensorShape shape;\n      TF_RETURN_IF_ERROR(c->GetAttr(\"shape\", &shape));\n      ShapeHandle passed_shape;\n      TF_RETURN_IF_ERROR(\n          c->MakeShapeFromPartialTensorShape(shape, &passed_shape));\n      if (!c->FullyDefined(passed_shape)) {\n        return errors::InvalidArgument(\"shape attr must be fully defined.\");\n      }\n      ShapeHandle cur;\n      TF_RETURN_IF_ERROR(c->ReplaceDim(\n          passed_shape, 0, c->MakeDim(shape_inference::DimensionOrConstant(1)),\n          &cur));\n      for (int i = 0; i < c->num_inputs(); ++i) {\n        if (!c->FullyDefined(c->input(i))) {\n          return errors::InvalidArgument(\n              \"All input shapes must be fully defined.\");\n        }\n        DimensionHandle unused;\n        if (!c->WithValue(c->Dim(c->input(i), 0), 1, &unused).ok()) {\n          return errors::InvalidArgument(\"Size of first dimension must be 1.\");\n        }\n        TF_RETURN_WITH_CONTEXT_IF_ERROR(c->Merge(c->input(i), cur, &cur),\n                                        \"From merging shape \", i,\n                                        \" with other shapes.\");\n      }\n\n      c->set_output(0, passed_shape);\n\n      return Status::OK();\n    });\n\nREGISTER_OP(\"Pack\")\n    .Input(\"values: N * T\")\n    .Output(\"output: T\")\n    .Attr(\"N: int >= 1\")\n    .Attr(\"T: type\")\n    .Attr(\"axis: int = 0\")\n    .SetShapeFn([](InferenceContext* c) {\n      // Validate shapes of all inputs are compatible\n      ShapeHandle cur = c->input(c->num_inputs() - 1);\n      for (int i = c->num_inputs() - 2; i >= 0; --i) {\n        TF_RETURN_WITH_CONTEXT_IF_ERROR(c->Merge(c->input(i), cur, &cur),\n                                        \"From merging shape \", i,\n                                        \" with other shapes.\");\n      }\n      if (!c->RankKnown(cur)) {\n        c->set_output(0, c->UnknownShape());\n        return Status::OK();\n      }\n      // Determine the axis that will be added, converting from negative\n      // axes to a positive point per negative indexing rules.\n      int32_t rank = c->Rank(cur);\n      int32_t axis;\n      TF_RETURN_IF_ERROR(GetAxisForPackAndUnpack(c, rank + 1, &axis));\n\n      // Copy all dimensions over, inserting a dimension of value #inputs\n      // at <axis>.\n      std::vector<DimensionHandle> dims;\n      int index = 0;\n      while (index < axis) dims.push_back(c->Dim(cur, index++));\n      dims.push_back(c->MakeDim(c->num_inputs()));\n      while (index < rank) dims.push_back(c->Dim(cur, index++));\n\n      c->set_output(0, c->MakeShape(dims));\n      for (int i = 0; i < c->num_inputs(); ++i) {\n        auto* shape_and_type = c->input_handle_shapes_and_types(i);\n        if (shape_and_type) {\n          if (!c->RelaxOutputHandleShapesAndMergeTypes(0, *shape_and_type)) {\n            c->set_output_handle_shapes_and_types(\n                0, std::vector<shape_inference::ShapeAndType>({}));\n            break;\n          }\n        }\n      }\n      return Status::OK();\n    });\n\nREGISTER_OP(\"DeepCopy\")\n    .Input(\"x: T\")\n    .Output(\"y: T\")\n    .Attr(\"T: type\")\n    .SetIsStateful()\n    .SetShapeFn(UnchangedShape);\n\nREGISTER_OP(\"InplaceUpdate\")\n    .Input(\"x: T\")\n    .Input(\"i: int32\")\n    .Input(\"v: T\")\n    .Output(\"y: T\")\n    .Attr(\"T: type\")\n    .SetShapeFn(UnchangedShape);\n\nREGISTER_OP(\"InplaceAdd\")\n    .Input(\"x: T\")\n    .Input(\"i: int32\")\n    .Input(\"v: T\")\n    .Output(\"y: T\")\n    .Attr(\"T: type\")\n    .SetShapeFn(UnchangedShape);\n\nREGISTER_OP(\"InplaceSub\")\n    .Input(\"x: T\")\n    .Input(\"i: int32\")\n    .Input(\"v: T\")\n    .Output(\"y: T\")\n    .Attr(\"T: type\")\n    .SetShapeFn(UnchangedShape);\n\nREGISTER_OP(\"Empty\")\n    .Input(\"shape: int32\")\n    .Output(\"output: dtype\")\n    .Attr(\"dtype: type\")\n    .Attr(\"init: bool = false\")\n    .SetDoNotOptimize()\n    .SetShapeFn([](InferenceContext* c) {\n      ShapeHandle out;\n      TF_RETURN_IF_ERROR(c->MakeShapeFromShapeTensor(0, &out));\n      c->set_output(0, out);\n      return Status::OK();\n    });\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"Unpack\")\n    .Input(\"value: T\")\n    .Output(\"output: num * T\")\n    .Attr(\"num: int >= 0\")\n    .Attr(\"T: type\")\n    .Attr(\"axis: int = 0\")\n    .SetShapeFn([](InferenceContext* c) {\n      ShapeHandle s = c->input(0);\n      ShapeHandle out;\n      if (c->RankKnown(s)) {\n        // Determine the axis that will be removed, converting from negative\n        // axes to a positive point per negative indexing rules.\n        int32_t rank = c->Rank(s);\n        int32_t axis;\n        TF_RETURN_IF_ERROR(GetAxisForPackAndUnpack(c, rank, &axis));\n\n        // The axis dim matches the number of outputs.\n        DimensionHandle unused;\n        TF_RETURN_IF_ERROR(\n            c->WithValue(c->Dim(s, axis), c->num_outputs(), &unused));\n\n        // Copy all dimensions, removing the <axis> dimension.\n        std::vector<DimensionHandle> dims;\n        for (int i = 0; i < rank; ++i) {\n          if (i != axis) dims.push_back(c->Dim(s, i));\n        }\n        out = c->MakeShape(dims);\n      } else {\n        // All outputs are the same shape, but it's not known.\n        out = c->UnknownShape();\n      }\n      for (int i = 0; i < c->num_outputs(); ++i) c->set_output(i, out);\n      return Status::OK();\n    });\n\nREGISTER_OP(\"UnravelIndex\")\n    .Input(\"indices: Tidx\")\n    .Input(\"dims: Tidx\")\n    .Output(\"output: Tidx\")\n    .Attr(\"Tidx: {int32, int64} = DT_INT32\")\n    .SetShapeFn([](InferenceContext* c) {\n      ShapeHandle indices = c->input(0);\n      ShapeHandle dims;\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(1), 1, &dims));\n      if (c->RankKnown(indices) && c->Rank(indices) == 0) {\n        c->set_output(0, c->Vector(c->Dim(dims, 0)));\n      } else if (c->RankKnown(indices)) {\n        c->set_output(0, c->Matrix(c->Dim(dims, 0), c->NumElements(indices)));\n      } else {\n        c->set_output(0, c->UnknownShape());\n      }\n      return Status::OK();\n    });\n\nREGISTER_OP(\"BroadcastTo\")\n    .Input(\"input: T\")\n    .Input(\"shape: Tidx\")\n    .Output(\"output: T\")\n    .Attr(\"T: type\")\n    .Attr(\"Tidx: {int32, int64} = DT_INT32\")\n    .SetShapeFn([](InferenceContext* c) {\n      ShapeHandle shape_in = c->input(1);\n      TF_RETURN_IF_ERROR(c->WithRank(shape_in, 1, &shape_in));\n      ShapeHandle out;\n      TF_RETURN_IF_ERROR(c->MakeShapeFromShapeTensor(1, &out));\n      if (!c->RankKnown(out)) {\n        // We have no information about the shape of the output.\n        c->set_output(0, out);\n        return Status::OK();\n      }\n\n      ShapeHandle in = c->input(0);\n      if (!c->RankKnown(in)) {\n        // We have no information about the shape of the input,\n        // nothing to do here.\n        c->set_output(0, out);\n        return Status::OK();\n      }\n      int out_rank = c->Rank(out);\n      TF_RETURN_IF_ERROR(c->WithRankAtMost(in, out_rank, &in));\n      int in_rank = c->Rank(in);\n      for (int i = 0; i < in_rank; ++i) {\n        auto in_dim = c->Dim(in, in_rank - i - 1);\n        if (c->Value(in_dim) > 1) {\n          // If the input dimension is greater than 1 then the output dimension\n          // must be equal to it, since we only broadcast \"from left to right\".\n          auto out_dim = c->Dim(out, out_rank - i - 1);\n          TF_RETURN_IF_ERROR(c->Merge(in_dim, out_dim, &out_dim));\n          TF_RETURN_IF_ERROR(\n              c->ReplaceDim(out, out_rank - i - 1, out_dim, &out));\n        }\n      }\n      c->set_output(0, out);\n      return Status::OK();\n    });\n\n// --------------------------------------------------------------------------\n// TODO(josh11b): Remove the >= 2 constraint, once we can rewrite the graph\n// in the N == 1 case to remove the node.\nREGISTER_OP(\"Concat\")\n    .Input(\"concat_dim: int32\")\n    .Input(\"values: N * T\")\n    .Output(\"output: T\")\n    .Attr(\"N: int >= 2\")\n    .Attr(\"T: type\")\n    .SetShapeFn([](InferenceContext* c) {\n      return shape_inference::ConcatShape(c, c->num_inputs() - 1);\n    });\n\nREGISTER_OP(\"ConcatV2\")\n    .Input(\"values: N * T\")\n    .Input(\"axis: Tidx\")\n    .Output(\"output: T\")\n    .Attr(\"N: int >= 2\")\n    .Attr(\"T: type\")\n    .Attr(\"Tidx: {int32, int64} = DT_INT32\")\n    .SetShapeFn(shape_inference::ConcatV2Shape);\n\n// TODO(vivek.v.rane@intel.com): Prefix the op names with underscore if the ops\n// are not to be made user-accessible.\n#ifdef INTEL_MKL\nREGISTER_OP(\"_MklConcatV2\")\n    .Input(\"values: N * T\")\n    .Input(\"axis: Tidx\")\n    .Input(\"mkl_values: N * uint8\")\n    .Input(\"mkl_axis: uint8\")\n    .Output(\"output: T\")\n    .Output(\"mkl_output: uint8\")\n    .Attr(\"N: int >= 2\")\n    .Attr(\"T: type\")\n    .Attr(\"Tidx: {int32, int64} = DT_INT32\")\n    .SetShapeFn(shape_inference::ConcatV2Shape)\n    .Doc(R\"doc(\nMKL version of ConcatV2 operator. Uses MKL DNN APIs to perform concatenation.\n\nNOTE Do not invoke this operator directly in Python. Graph rewrite pass is\nexpected to invoke these operators.\n)doc\");\n#endif\n\nREGISTER_OP(\"ConcatOffset\")\n    .Input(\"concat_dim: int32\")\n    .Input(\"shape: N * int32\")\n    .Output(\"offset: N * int32\")\n    .Attr(\"N: int >= 2\")\n    .SetShapeFn([](InferenceContext* c) {\n      for (int i = 1; i < c->num_inputs(); ++i) {\n        c->set_output(i - 1, c->input(i));\n      }\n      return Status::OK();\n    });\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"Split\")\n    .Input(\"split_dim: int32\")\n    .Input(\"value: T\")\n    .Output(\"output: num_split * T\")\n    .Attr(\"num_split: int >= 1\")\n    .Attr(\"T: type\")\n    .SetShapeFn([](InferenceContext* c) {\n      DimensionHandle split_dimension;\n      ShapeHandle input = c->input(1);\n      TF_RETURN_IF_ERROR(c->MakeDimForScalarInputWithNegativeIndexing(\n          0, c->Rank(input), &split_dimension));\n      int num_split = c->num_outputs();\n      ShapeHandle out;\n      if (!c->ValueKnown(split_dimension)) {\n        if (c->RankKnown(input)) {\n          out = c->UnknownShapeOfRank(c->Rank(input));\n        } else {\n          out = c->UnknownShape();\n        }\n      } else {\n        int64_t split_dim = c->Value(split_dimension);\n        TF_RETURN_IF_ERROR(c->WithRankAtLeast(input, split_dim + 1, &input));\n        DimensionHandle split_dim_size;\n        TF_RETURN_WITH_CONTEXT_IF_ERROR(\n            c->Divide(c->Dim(input, split_dim), num_split,\n                      true /* evenly_divisible */, &split_dim_size),\n            \"Number of ways to split should evenly divide the split dimension\");\n        TF_RETURN_IF_ERROR(\n            c->ReplaceDim(input, split_dim, split_dim_size, &out));\n      }\n      for (int i = 0; i < num_split; ++i) c->set_output(i, out);\n      return Status::OK();\n    });\n\nREGISTER_OP(\"SplitV\")\n    .Input(\"value: T\")\n    .Input(\"size_splits: Tlen\")\n    .Input(\"split_dim: int32\")\n    .Output(\"output: num_split * T\")\n    .Attr(\"num_split: int >= 1\")\n    .Attr(\"T: type\")\n    .Attr(\"Tlen: {int32, int64} = DT_INT64\")\n    .SetShapeFn([](InferenceContext* c) {\n      DimensionHandle split_dimension;\n      ShapeHandle input = c->input(0);\n      TF_RETURN_IF_ERROR(c->MakeDimForScalarInputWithNegativeIndexing(\n          2, c->Rank(input), &split_dimension));\n      int32_t num_outputs = c->num_outputs();\n      int32_t rank = c->Rank(input);\n      ShapeHandle output_shape;\n      const Tensor* size_splits = c->input_tensor(1);\n      if (rank == InferenceContext::kUnknownRank) {\n        // If the rank of input tensor is unknown, then return unknown shapes.\n        // Note that the shape of each output can be different.\n        for (int i = 0; i < num_outputs; ++i) {\n          c->set_output(i, c->UnknownShape());\n        }\n      } else if (rank == 0) {\n        // Throw error if input is a scalar.\n        return errors::InvalidArgument(\"Can't split scalars\");\n      } else if (size_splits == nullptr && c->ValueKnown(split_dimension)) {\n        // If split dimension is known, but the sizes are unknown, then\n        // only the split dimension is unknown\n        output_shape = input;\n        for (int i = 0; i < num_outputs; ++i) {\n          TF_RETURN_IF_ERROR(c->ReplaceDim(output_shape,\n                                           c->Value(split_dimension),\n                                           c->UnknownDim(), &output_shape));\n          c->set_output(i, output_shape);\n        }\n      } else if (size_splits == nullptr && !c->ValueKnown(split_dimension)) {\n        // If split dimension or tensor containing the split sizes is unknown,\n        // then return unknown shapes of same rank as input. Note that each\n        // output shape can be different since splitv doesn't always split\n        // tensors evenly.\n        for (int i = 0; i < num_outputs; ++i) {\n          c->set_output(i, c->UnknownShapeOfRank(rank));\n        }\n      } else {\n        // Determine the output shape if split dimension and split sizes are\n        // known.\n        int64_t split_dim = c->Value(split_dimension);\n        TF_RETURN_IF_ERROR(c->WithRankAtLeast(input, split_dim + 1, &input));\n        std::vector<int64_t> data;\n        if (size_splits->dtype() == DT_INT32) {\n          data = AsInt64<int32>(size_splits, size_splits->shape().dim_size(0));\n        } else {\n          data =\n              AsInt64<int64_t>(size_splits, size_splits->shape().dim_size(0));\n        }\n        if (num_outputs != data.size()) {\n          return errors::InvalidArgument(\n              \"Length of size_splits should be equal to num_outputs\");\n        }\n        int64_t total_size = 0;\n        bool has_neg_one = false;\n        for (const auto size : data) {\n          if (size == -1) {\n            if (has_neg_one) {\n              return errors::InvalidArgument(\n                  \"size_splits can only have one -1\");\n            }\n            has_neg_one = true;\n          } else {\n            total_size += size;\n          }\n        }\n        auto split_dim_size = c->Value(c->Dim(input, split_dim));\n        // If the sizes of the splits are known, then\n        // make sure that the sizes add up to the expected\n        // dimension size, with the possibility of a -1.\n        // Specify the full output shapes.\n        for (int i = 0; i < num_outputs; ++i) {\n          auto size = data[i];\n          if (data[i] == -1 && c->ValueKnown(split_dim_size)) {\n            size = split_dim_size - total_size;\n          }\n          // If we have a negative known size (either explicit, or computed\n          // via -1), then the split sizes are invalid.\n          if (size < -1 || (size == -1 && c->ValueKnown(split_dim_size))) {\n            return errors::InvalidArgument(\"Split size at index \", i,\n                                           \" must be >= 0. Got: \", size);\n          }\n          TF_RETURN_IF_ERROR(\n              c->ReplaceDim(input, split_dim, c->MakeDim(size), &output_shape));\n          c->set_output(i, output_shape);\n        }\n        if (c->ValueKnown(split_dim_size)) {\n          if (has_neg_one ? total_size > split_dim_size\n                          : total_size != split_dim_size) {\n            return errors::InvalidArgument(\n                \"can't split axis of size \", split_dim_size,\n                \" into pieces of size [\", absl::StrJoin(data, \",\"), \"]\");\n          }\n        }\n      }\n\n      return Status::OK();\n    });\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"Const\")\n    .Output(\"output: dtype\")\n    .Attr(\"value: tensor\")\n    .Attr(\"dtype: type\")\n    .SetShapeFn([](InferenceContext* c) {\n      const TensorProto* proto = nullptr;\n      TF_RETURN_IF_ERROR(c->GetAttr(\"value\", &proto));\n      TF_RETURN_IF_ERROR(TensorShape::IsValidShape(proto->tensor_shape()));\n      TensorShape shape(proto->tensor_shape());\n      std::vector<DimensionHandle> dims;\n      dims.reserve(shape.dims());\n      for (int i = 0; i < shape.dims(); ++i) {\n        dims.push_back(c->MakeDim(shape.dim_size(i)));\n      }\n      c->set_output(0, c->MakeShape(dims));\n      return Status::OK();\n    });\n\n// Returns a constant tensor on the host.  Useful for writing C++ tests\n// and benchmarks which run on GPU but require arguments pinned to the host.\n// Used by test::graph::HostConstant.\n// value: Attr `value` is the tensor to return.\nREGISTER_OP(\"HostConst\")\n    .Output(\"output: dtype\")\n    .Attr(\"value: tensor\")\n    .Attr(\"dtype: type\")\n    .SetShapeFn(shape_inference::UnknownShape);\n\n// Used executing op-by-op to copy constants to the current device without\n// serializing tensors as TensorProtos, after a host tensor has been\n// created. Same behavior as Identity, but no gradient and potentially relaxed\n// copy semantics.\nREGISTER_OP(\"_EagerConst\")\n    .Input(\"input: T\")\n    .Output(\"output: T\")\n    .Attr(\"T: type\")\n    .SetShapeFn(shape_inference::UnchangedShape);\n\n// --------------------------------------------------------------------------\n// TODO(mgubin): Update the doc when the freeze_graph script supports converting\n// into memmapped format.\nREGISTER_OP(\"ImmutableConst\")\n    .Attr(\"dtype: type\")\n    .Attr(\"shape: shape\")\n    .Attr(\"memory_region_name: string\")\n    .Output(\"tensor: dtype\")\n    .SetShapeFn(shape_inference::ExplicitShape);\n\nREGISTER_OP(\"GuaranteeConst\")\n    .Input(\"input: T\")\n    .Output(\"output: T\")\n    .Attr(\"T: type\")\n    .SetShapeFn([](shape_inference::InferenceContext* c) {\n      return UnchangedShape(c);\n    })\n    // We don't want this to be optimized away.\n    .SetDoNotOptimize();\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"ZerosLike\")\n    .Input(\"x: T\")\n    .Output(\"y: T\")\n    .Attr(\"T: type\")\n    .SetShapeFn(shape_inference::UnchangedShape);\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"OnesLike\")\n    .Input(\"x: T\")\n    .Output(\"y: T\")\n    .Attr(\n        \"T: {bfloat16, half, float, double, int8, uint8, int16, uint16, int32, \"\n        \"int64, complex64, complex128, bool}\")\n    .SetShapeFn(shape_inference::UnchangedShape);\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"Diag\")\n    .Input(\"diagonal: T\")\n    .Output(\"output: T\")\n    .Attr(\n        \"T: {bfloat16, half, float, double, int32, int64, complex64, \"\n        \"complex128}\")\n    .SetShapeFn([](InferenceContext* c) {\n      ShapeHandle in = c->input(0);\n      TF_RETURN_IF_ERROR(c->WithRankAtLeast(in, 1, &in));\n      // Output shape is original concatenated with itself.\n      ShapeHandle out;\n      TF_RETURN_IF_ERROR(c->Concatenate(in, in, &out));\n      c->set_output(0, out);\n      return Status::OK();\n    });\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"DiagPart\")\n    .Input(\"input: T\")\n    .Output(\"diagonal: T\")\n    .Attr(\n        \"T: {bfloat16, half, float, double, int32, int64, complex64, \"\n        \"complex128}\")\n    .SetShapeFn([](InferenceContext* c) {\n      ShapeHandle in = c->input(0);\n      if (!c->RankKnown(in)) {\n        c->set_output(0, c->UnknownShape());\n        return Status::OK();\n      }\n      // Rank must be even, and result will have rank <rank/2>.\n      const int32_t rank = c->Rank(in);\n      if ((rank % 2) != 0 || rank <= 0) {\n        return errors::InvalidArgument(\n            \"Input must have even and non-zero rank, input rank is \", rank);\n      }\n      const int32_t mid = rank / 2;\n\n      // output dim[i] is the merge of in.dim[i] and in.dim[i+mid].\n      std::vector<DimensionHandle> dims(mid);\n      for (int i = 0; i < mid; ++i) {\n        TF_RETURN_IF_ERROR(\n            c->Merge(c->Dim(in, i), c->Dim(in, i + mid), &dims[i]));\n      }\n      c->set_output(0, c->MakeShape(dims));\n      return Status::OK();\n    });\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"MatrixDiag\")\n    .Input(\"diagonal: T\")\n    .Output(\"output: T\")\n    .Attr(\"T: type\")\n    .SetShapeFn([](InferenceContext* c) {\n      ShapeHandle in;\n      TF_RETURN_IF_ERROR(c->WithRankAtLeast(c->input(0), 1, &in));\n      if (!c->RankKnown(in)) {\n        c->set_output(0, c->UnknownShape());\n        return Status::OK();\n      }\n      const int32_t rank = c->Rank(in);\n      ShapeHandle out;\n      TF_RETURN_IF_ERROR(\n          c->Concatenate(in, c->Vector(c->Dim(in, rank - 1)), &out));\n      c->set_output(0, out);\n      return Status::OK();\n    });\n\nREGISTER_OP(\"MatrixDiagV2\")\n    .Input(\"diagonal: T\")\n    .Input(\"k: int32\")\n    .Input(\"num_rows: int32\")\n    .Input(\"num_cols: int32\")\n    .Input(\"padding_value: T\")\n    .Output(\"output: T\")\n    .Attr(\"T: type\")\n    .SetShapeFn(shape_inference::MatrixDiagV2Shape);\n\nREGISTER_OP(\"MatrixDiagV3\")\n    .Input(\"diagonal: T\")\n    .Input(\"k: int32\")\n    .Input(\"num_rows: int32\")\n    .Input(\"num_cols: int32\")\n    .Input(\"padding_value: T\")\n    .Output(\"output: T\")\n    .Attr(\"T: type\")\n    .Attr(\n        \"align: {'LEFT_RIGHT', 'RIGHT_LEFT', 'LEFT_LEFT', 'RIGHT_RIGHT'} = \"\n        \"'RIGHT_LEFT'\")\n    .SetShapeFn(shape_inference::MatrixDiagV2Shape);\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"MatrixSetDiag\")\n    .Input(\"input: T\")\n    .Input(\"diagonal: T\")\n    .Output(\"output: T\")\n    .Attr(\"T: type\")\n    .SetShapeFn([](InferenceContext* c) {\n      ShapeHandle input;\n      ShapeHandle diag;\n      TF_RETURN_IF_ERROR(c->WithRankAtLeast(c->input(0), 2, &input));\n      TF_RETURN_IF_ERROR(c->WithRankAtLeast(c->input(1), 1, &diag));\n      if (c->RankKnown(input)) {\n        TF_RETURN_IF_ERROR(c->WithRank(c->input(1), c->Rank(input) - 1, &diag));\n      }\n      DimensionHandle smallest_dim;\n      TF_RETURN_IF_ERROR(\n          c->Min(c->Dim(input, -2), c->Dim(input, -1), &smallest_dim));\n      TF_RETURN_IF_ERROR(\n          c->Merge(smallest_dim, c->Dim(diag, -1), &smallest_dim));\n\n      ShapeHandle output = input;\n      if (c->RankKnown(diag) && !c->FullyDefined(input)) {\n        // Try to infer parts of shape from diag.\n        ShapeHandle diag_batch_shape;\n        TF_RETURN_IF_ERROR(c->Subshape(diag, 0, -1, &diag_batch_shape));\n        TF_RETURN_IF_ERROR(\n            c->Concatenate(diag_batch_shape, c->UnknownShapeOfRank(2), &diag));\n        TF_RETURN_IF_ERROR(c->Merge(input, diag, &output));\n      }\n      c->set_output(0, output);\n      return Status::OK();\n    });\n\nREGISTER_OP(\"MatrixSetDiagV2\")\n    .Input(\"input: T\")\n    .Input(\"diagonal: T\")\n    .Input(\"k: int32\")\n    .Output(\"output: T\")\n    .Attr(\"T: type\")\n    .SetShapeFn(shape_inference::MatrixSetDiagV2Shape);\n\nREGISTER_OP(\"MatrixSetDiagV3\")\n    .Input(\"input: T\")\n    .Input(\"diagonal: T\")\n    .Input(\"k: int32\")\n    .Output(\"output: T\")\n    .Attr(\"T: type\")\n    .Attr(\n        \"align: {'LEFT_RIGHT', 'RIGHT_LEFT', 'LEFT_LEFT', 'RIGHT_RIGHT'} = \"\n        \"'RIGHT_LEFT'\")\n    .SetShapeFn(shape_inference::MatrixSetDiagV2Shape);\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"MatrixDiagPart\")\n    .Input(\"input: T\")\n    .Output(\"diagonal: T\")\n    .Attr(\"T: type\")\n    .SetShapeFn([](InferenceContext* c) {\n      ShapeHandle in;\n      TF_RETURN_IF_ERROR(c->WithRankAtLeast(c->input(0), 2, &in));\n      if (!c->RankKnown(in)) {\n        c->set_output(0, c->UnknownShape());\n        return Status::OK();\n      }\n      const int32_t rank = c->Rank(in);\n      std::vector<DimensionHandle> dims;\n      dims.reserve(rank - 2);\n      for (int i = 0; i < rank - 2; ++i) dims.push_back(c->Dim(in, i));\n\n      DimensionHandle min_dim;\n      TF_RETURN_IF_ERROR(\n          c->Min(c->Dim(in, rank - 2), c->Dim(in, rank - 1), &min_dim));\n      dims.push_back(min_dim);\n      c->set_output(0, c->MakeShape(dims));\n      return Status::OK();\n    });\n\nREGISTER_OP(\"MatrixDiagPartV2\")\n    .Input(\"input: T\")\n    .Input(\"k: int32\")\n    .Input(\"padding_value: T\")\n    .Output(\"diagonal: T\")\n    .Attr(\"T: type\")\n    .SetShapeFn(shape_inference::MatrixDiagPartV2Shape);\n\nREGISTER_OP(\"MatrixDiagPartV3\")\n    .Input(\"input: T\")\n    .Input(\"k: int32\")\n    .Input(\"padding_value: T\")\n    .Output(\"diagonal: T\")\n    .Attr(\"T: type\")\n    .Attr(\n        \"align: {'LEFT_RIGHT', 'RIGHT_LEFT', 'LEFT_LEFT', 'RIGHT_RIGHT'} = \"\n        \"'RIGHT_LEFT'\")\n    .SetShapeFn(shape_inference::MatrixDiagPartV2Shape);\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"MatrixBandPart\")\n    .Input(\"input: T\")\n    .Input(\"num_lower: Tindex\")\n    .Input(\"num_upper: Tindex\")\n    .Output(\"band: T\")\n    .Attr(\"T: type\")\n    .Attr(\"Tindex: {int32, int64} = DT_INT64\")\n    .SetShapeFn(shape_inference::UnchangedShape);\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"Reverse\")\n    .Input(\"tensor: T\")\n    .Input(\"dims: bool\")\n    .Output(\"output: T\")\n    .Attr(\n        \"T: {uint8, int8, uint16, int16, uint32, int32, uint64, int64, bool, \"\n        \"bfloat16, half, float, double, complex64, complex128, string}\")\n    .SetShapeFn([](InferenceContext* c) {\n      ShapeHandle input = c->input(0);\n      ShapeHandle dims;\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(1), 1, &dims));\n      DimensionHandle dims_dim = c->Dim(dims, 0);\n      if (c->ValueKnown(dims_dim)) {\n        TF_RETURN_IF_ERROR(c->WithRank(input, c->Value(dims_dim), &input));\n      }\n      if (c->Rank(input) > 8) {\n        return errors::InvalidArgument(\n            \"reverse does not work on tensors with more than 8 dimensions\");\n      }\n      c->set_output(0, input);\n      return Status::OK();\n    });\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"ReverseV2\")\n    .Input(\"tensor: T\")\n    .Input(\"axis: Tidx\")\n    .Output(\"output: T\")\n    .Attr(\"Tidx: {int32, int64} = DT_INT32\")\n    .Attr(\n        \"T: {uint8, int8, uint16, int16, int32, uint32, int64, uint64, bool, \"\n        \"bfloat16, half, float, double, complex64, complex128, string}\")\n    .SetShapeFn([](InferenceContext* c) {\n      ShapeHandle input = c->input(0);\n      ShapeHandle axis;\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(1), 1, &axis));\n      if (c->Rank(input) > 8) {\n        return errors::InvalidArgument(\n            \"reverse does not work on tensors with more than 8 dimensions\");\n      }\n      const Tensor* axis_tensor = c->input_tensor(1);\n      if (axis_tensor != nullptr && c->RankKnown(input)) {\n        int32_t rank = c->Rank(input);\n        std::vector<int64_t> axis_value;\n        if (axis_tensor->dtype() == DT_INT32) {\n          axis_value = AsInt64<int32>(axis_tensor, axis_tensor->NumElements());\n        } else {\n          axis_value =\n              AsInt64<int64_t>(axis_tensor, axis_tensor->NumElements());\n        }\n        std::vector<bool> axes_dense(c->Rank(input), false);\n        for (int i = 0; i < axis_value.size(); i++) {\n          int64_t canonical_axis =\n              axis_value[i] < 0 ? rank + axis_value[i] : axis_value[i];\n          if (canonical_axis < 0 || canonical_axis >= rank) {\n            return errors::InvalidArgument(\"'axis'[\", i, \"] = \", axis_value[i],\n                                           \" is out of valid range [\", 0, \", \",\n                                           rank - 1);\n          }\n          if (axes_dense[canonical_axis]) {\n            return errors::InvalidArgument(\"axis \", canonical_axis,\n                                           \" specified more than once.\");\n          }\n          axes_dense[canonical_axis] = true;\n        }\n      }\n      c->set_output(0, input);\n      return Status::OK();\n    });\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"EditDistance\")\n    .Input(\"hypothesis_indices: int64\")\n    .Input(\"hypothesis_values: T\")\n    .Input(\"hypothesis_shape: int64\")\n    .Input(\"truth_indices: int64\")\n    .Input(\"truth_values: T\")\n    .Input(\"truth_shape: int64\")\n    .Attr(\"normalize: bool = true\")\n    .Attr(\"T: type\")\n    .Output(\"output: float\")\n    .SetShapeFn([](InferenceContext* c) {\n      TF_RETURN_IF_ERROR(shape_inference::ValidateSparseTensor(\n          c, c->input(0), c->input(1), c->input(2)));\n      TF_RETURN_IF_ERROR(shape_inference::ValidateSparseTensor(\n          c, c->input(3), c->input(4), c->input(5)));\n      const Tensor* hypothesis_shape_t = c->input_tensor(2);\n      const Tensor* truth_shape_t = c->input_tensor(5);\n      if (hypothesis_shape_t == nullptr || truth_shape_t == nullptr) {\n        // We need to know the runtime shape of the two tensors,\n        // or else the output shape is unknown.\n        return shape_inference::UnknownShape(c);\n      }\n\n      if (hypothesis_shape_t->NumElements() != truth_shape_t->NumElements()) {\n        return errors::InvalidArgument(\n            \"Num elements of hypothesis_shape does not match truth_shape: \",\n            hypothesis_shape_t->NumElements(), \" vs. \",\n            truth_shape_t->NumElements());\n      }\n\n      auto h_values = hypothesis_shape_t->flat<int64_t>();\n      auto t_values = truth_shape_t->flat<int64_t>();\n      std::vector<DimensionHandle> dims(hypothesis_shape_t->NumElements() - 1);\n      for (int i = 0; i < dims.size(); ++i) {\n        dims[i] = c->MakeDim(std::max(h_values(i), t_values(i)));\n      }\n\n      c->set_output(0, c->MakeShape(dims));\n      return Status::OK();\n    });\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"Fill\")\n    .Input(\"dims: index_type\")\n    .Input(\"value: T\")\n    .Output(\"output: T\")\n    .Attr(\"T: type\")\n    .Attr(\"index_type: {int32, int64} = DT_INT32\")\n    .SetShapeFn([](InferenceContext* c) {\n      DataType index_type = DT_INT32;\n      Status s = c->GetAttr(\"index_type\", &index_type);\n      if (!s.ok() && s.code() != error::NOT_FOUND) {\n        return s;\n      }\n      ShapeHandle unused;\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(0), 1, &unused));\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(1), 0, &unused));\n\n      const Tensor* t = c->input_tensor(0);\n      if (t != nullptr) {\n        for (int i = 0; i < t->NumElements(); ++i) {\n          if ((index_type == DT_INT32 && t->vec<int32>()(i) < 0) ||\n              (index_type == DT_INT64 && t->vec<int64_t>()(i) < 0)) {\n            return errors::InvalidArgument(\"Fill dimensions must be >= 0\");\n          }\n        }\n      }\n\n      ShapeHandle out;\n      TF_RETURN_IF_ERROR(c->MakeShapeFromShapeTensor(0, &out));\n      c->set_output(0, out);\n\n      auto* shape_and_type = c->input_handle_shapes_and_types(1);\n      if (shape_and_type) {\n        c->set_output_handle_shapes_and_types(0, *shape_and_type);\n      }\n\n      return Status::OK();\n    });\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"_ParallelConcatStart\")\n    .Output(\"output: dtype\")\n    .Attr(\"shape: shape\")\n    .Attr(\"dtype: type\")\n    .SetIsStateful()\n    .SetShapeFn(shape_inference::ExplicitShape)\n    .Doc(R\"doc(\nCreates an empty Tensor with shape `shape` and type `dtype`.\n\nThe memory can optionally be initialized. This is usually useful in\nconjunction with inplace operations.\n\nshape: 1-D `Tensor` indicating the shape of the output.\ndtype: The element type of the returned tensor.\noutput: An empty Tensor of the specified type.\n)doc\");\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"_ParallelConcatUpdate\")\n    .Input(\"value: T\")\n    .Input(\"update: T\")\n    .Output(\"output: T\")\n    .Attr(\"T: type\")\n    .Attr(\"loc: int\")\n    .SetShapeFn(shape_inference::UnchangedShape)\n    .Doc(R\"doc(\nUpdates input `value` at `loc` with `update`.\n\nIf you use this function you will almost certainly want to add\na control dependency as done in the implementation of parallel_stack to\navoid race conditions.\n\nvalue: A `Tensor` object that will be updated in-place.\nloc: A scalar indicating the index of the first dimension such that\n         value[loc, :] is updated.\nupdate: A `Tensor` of rank one less than `value` if `loc` is a scalar,\n        otherwise of rank equal to `value` that contains the new values\n        for `value`.\noutput: `value` that has been updated accordingly.\n)doc\");\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"Gather\")\n    .Input(\"params: Tparams\")\n    .Input(\"indices: Tindices\")\n    .Attr(\"validate_indices: bool = true\")\n    .Output(\"output: Tparams\")\n    .Attr(\"Tparams: type\")\n    .Attr(\"Tindices: {int32,int64}\")\n    .SetShapeFn([](InferenceContext* c) {\n      ShapeHandle unused;\n      TF_RETURN_IF_ERROR(c->WithRankAtLeast(c->input(0), 1, &unused));\n      ShapeHandle params_subshape;\n      TF_RETURN_IF_ERROR(c->Subshape(c->input(0), 1, &params_subshape));\n      ShapeHandle indices_shape = c->input(1);\n      ShapeHandle out;\n      TF_RETURN_IF_ERROR(c->Concatenate(indices_shape, params_subshape, &out));\n      c->set_output(0, out);\n      return Status::OK();\n    });\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"GatherV2\")\n    .Input(\"params: Tparams\")\n    .Input(\"indices: Tindices\")\n    .Input(\"axis: Taxis\")\n    .Attr(\"batch_dims: int = 0\")\n    .Output(\"output: Tparams\")\n    .Attr(\"Tparams: type\")\n    .Attr(\"Tindices: {int32,int64}\")\n    .Attr(\"Taxis: {int32,int64}\")\n    .SetShapeFn([](InferenceContext* c) {\n      ShapeHandle params_shape;\n      TF_RETURN_IF_ERROR(c->WithRankAtLeast(c->input(0), 1, &params_shape));\n\n      ShapeHandle indices_shape = c->input(1);\n      ShapeHandle unused_axis_shape;\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(2), 0, &unused_axis_shape));\n      const Tensor* axis_t = c->input_tensor(2);\n\n      // If axis is unknown, we can only infer that the result is params_rank +\n      // indices_rank - 1.\n      if (axis_t == nullptr) {\n        if (c->RankKnown(params_shape) && c->RankKnown(indices_shape)) {\n          int32_t batch_dims;\n          TF_RETURN_IF_ERROR(c->GetAttr(\"batch_dims\", &batch_dims));\n          c->set_output(0, c->UnknownShapeOfRank(c->Rank(params_shape) +\n                                                 c->Rank(indices_shape) - 1 -\n                                                 batch_dims));\n        } else {\n          c->set_output(0, c->UnknownShape());\n        }\n        return Status::OK();\n      }\n\n      // Note, axis can be negative.\n      int64_t axis = 0;\n      if (axis_t->dtype() == DT_INT32) {\n        axis = axis_t->scalar<int32>()();\n      } else {\n        axis = axis_t->scalar<int64_t>()();\n      }\n\n      // Check that params has rank of at least axis + 1.\n      ShapeHandle unused;\n      TF_RETURN_IF_ERROR(c->WithRankAtLeast(\n          params_shape, axis < 0 ? -axis : axis + 1, &unused));\n\n      // Note, batch_dims can be negative.\n      int32_t batch_dims;\n      TF_RETURN_IF_ERROR(c->GetAttr(\"batch_dims\", &batch_dims));\n      // -rank(indices) <= batch_dims <= rank(indices)\n      TF_RETURN_IF_ERROR(\n          c->WithRankAtLeast(indices_shape, std::abs(batch_dims), &unused));\n      if (batch_dims < 0) {\n        batch_dims += c->Rank(indices_shape);\n      }\n      // rank(params) > batch_dims\n      TF_RETURN_IF_ERROR(\n          c->WithRankAtLeast(params_shape, batch_dims + 1, &unused));\n\n      ShapeHandle params_outer_subshape;\n      TF_RETURN_IF_ERROR(\n          c->Subshape(params_shape, 0, axis, &params_outer_subshape));\n\n      ShapeHandle indices_inner_subshape;\n      TF_RETURN_IF_ERROR(\n          c->Subshape(indices_shape, batch_dims, &indices_inner_subshape));\n\n      ShapeHandle out;\n      TF_RETURN_IF_ERROR(\n          c->Concatenate(params_outer_subshape, indices_inner_subshape, &out));\n\n      // Slice from axis + 1 to the end of params_shape to collect the inner\n      // dimensions of the result. Special case -1 here since -1 + 1 wraps, and\n      // we slice from 0 to the end of shape. Subshape() handles all other\n      // out-of-bounds checking.\n      if (axis != -1) {\n        ShapeHandle params_inner_subshape;\n        TF_RETURN_IF_ERROR(\n            c->Subshape(params_shape, axis + 1, &params_inner_subshape));\n        TF_RETURN_IF_ERROR(c->Concatenate(out, params_inner_subshape, &out));\n      }\n\n      c->set_output(0, out);\n      return Status::OK();\n    });\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"GatherNd\")\n    .Input(\"params: Tparams\")\n    .Input(\"indices: Tindices\")\n    .Output(\"output: Tparams\")\n    .Attr(\"Tparams: type\")\n    .Attr(\"Tindices: {int32,int64}\")\n    .SetShapeFn(shape_inference::GatherNdShape);\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"Identity\")\n    .Input(\"input: T\")\n    .Output(\"output: T\")\n    .Attr(\"T: type\")\n    .SetForwardTypeFn(full_type::ReplicateInputs())\n    .SetShapeFn(shape_inference::UnchangedShape);\n\nREGISTER_OP(\"Snapshot\")\n    .Input(\"input: T\")\n    .Output(\"output: T\")\n    .Attr(\"T: type\")\n    .SetShapeFn(shape_inference::UnchangedShape);\n\n#ifdef INTEL_MKL\nREGISTER_OP(\"_MklIdentity\")\n    .Input(\"input: T\")\n    .Input(\"mkl_input: uint8\")\n    .Output(\"output: T\")\n    .Output(\"mkl_output: uint8\")\n    .Attr(\"T: type\")\n    .SetShapeFn(shape_inference::UnchangedShape)\n    .Doc(R\"Doc( Mkl implementation of IdentityOp\n)Doc\");\n#endif\n\nREGISTER_OP(\"IdentityN\")\n    .Input(\"input: T\")\n    .Output(\"output: T\")\n    .Attr(\"T: list(type)\")\n    .SetShapeFn([](shape_inference::InferenceContext* c) {\n      std::vector<ShapeHandle> input;\n      TF_RETURN_IF_ERROR(c->input(\"input\", &input));\n      TF_RETURN_IF_ERROR(c->set_output(\"output\", input));\n      // If any of the input shapes are not known, we should return error.\n      for (int i = 0; i < input.size(); i++) {\n        if (!input[i].Handle()) {\n          return errors::InvalidArgument(absl::StrCat(\n              \"Cannot infer output shape #\", i,\n              \" for IdentityN node because input shape #\", i, \" is unknown.\"));\n        }\n      }\n      return Status::OK();\n    });\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"RefIdentity\")\n    .Input(\"input: Ref(T)\")\n    .Output(\"output: Ref(T)\")\n    .Attr(\"T: type\")\n    .SetShapeFn(shape_inference::UnchangedShape)\n    .SetAllowsUninitializedInput();\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"DebugGradientIdentity\")\n    .Input(\"input: T\")\n    .Output(\"output: T\")\n    .Attr(\"T: type\")\n    .SetShapeFn(shape_inference::UnchangedShape)\n    .SetAllowsUninitializedInput();\n\nREGISTER_OP(\"DebugGradientRefIdentity\")\n    .Input(\"input: Ref(T)\")\n    .Output(\"output: Ref(T)\")\n    .Attr(\"T: type\")\n    .SetShapeFn(shape_inference::UnchangedShape)\n    .SetAllowsUninitializedInput();\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"StopGradient\")\n    .Input(\"input: T\")\n    .Output(\"output: T\")\n    .Attr(\"T: type\")\n    .SetShapeFn(shape_inference::UnchangedShape);\n\nREGISTER_OP(\"PreventGradient\")\n    .Input(\"input: T\")\n    .Output(\"output: T\")\n    .Attr(\"T: type\")\n    .Attr(\"message: string = ''\")\n    .SetShapeFn(shape_inference::UnchangedShape);\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"CheckNumerics\")\n    .Input(\"tensor: T\")\n    .Output(\"output: T\")\n    .Attr(\"T: {bfloat16, half, float, double}\")\n    .Attr(\"message: string\")\n    .SetIsStateful()\n    .SetShapeFn(shape_inference::UnchangedShape);\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"CheckNumericsV2\")\n    .Input(\"tensor: T\")\n    .Output(\"output: T\")\n    .Attr(\"T: {bfloat16, half, float, double}\")\n    .Attr(\"message: string\")\n    .SetIsStateful()\n    .SetShapeFn(shape_inference::UnchangedShape);\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"Reshape\")\n    .Input(\"tensor: T\")\n    .Input(\"shape: Tshape\")\n    .Output(\"output: T\")\n    .Attr(\"T: type\")\n    .Attr(\"Tshape: {int32, int64} = DT_INT32\")\n    .SetShapeFn([](InferenceContext* c) {\n      return SetOutputShapeForReshape(c);\n    });\n\n#ifdef INTEL_MKL\nREGISTER_OP(\"_MklReshape\")\n    .Input(\"tensor: T\")\n    .Input(\"shape: Tshape\")\n    .Input(\"mkl_tensor: uint8\")\n    .Input(\"mkl_shape: uint8\")\n    .Output(\"output: T\")\n    .Output(\"mkl_output: uint8\")\n    .Attr(\"T: type\")\n    .Attr(\"Tshape: {int32, int64} = DT_INT32\")\n    .SetShapeFn([](InferenceContext* c) { return SetOutputShapeForReshape(c); })\n    .Doc(R\"Doc( MKL implementation of ReshapeOp.\n)Doc\");\n#endif  // INTEL_MKL\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"InvertPermutation\")\n    .Input(\"x: T\")\n    .Output(\"y: T\")\n    .Attr(\"T: {int32, int64} = DT_INT32\")\n    .SetShapeFn([](InferenceContext* c) {\n      ShapeHandle x;\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(0), 1, &x));\n      c->set_output(0, x);\n      return Status::OK();\n    });\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"Transpose\")\n    .Input(\"x: T\")\n    .Input(\"perm: Tperm\")\n    .Output(\"y: T\")\n    .Attr(\"T: type\")\n    .Attr(\"Tperm: {int32, int64} = DT_INT32\")\n    .SetShapeFn(TransposeShapeFn);\n\n#ifdef INTEL_MKL\nREGISTER_OP(\"_MklTranspose\")\n    .Input(\"x: T\")\n    .Input(\"perm: Tperm\")\n    .Output(\"y: T\")\n    .Attr(\"T: type\")\n    .Attr(\"Tperm: {int32, int64} = DT_INT32\")\n    .SetShapeFn(TransposeShapeFn);\n#endif  // INTEL_MKL\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"ConjugateTranspose\")\n    .Input(\"x: T\")\n    .Input(\"perm: Tperm\")\n    .Output(\"y: T\")\n    .Attr(\"T: type\")\n    .Attr(\"Tperm: {int32, int64} = DT_INT32\")\n    .SetShapeFn(TransposeShapeFn);\n\n#ifdef INTEL_MKL\nREGISTER_OP(\"_MklConjugateTranspose\")\n    .Input(\"x: T\")\n    .Input(\"perm: Tperm\")\n    .Output(\"y: T\")\n    .Attr(\"T: type\")\n    .Attr(\"Tperm: {int32, int64} = DT_INT32\")\n    .SetShapeFn(TransposeShapeFn);\n#endif  // INTEL_MKL\n\n// --------------------------------------------------------------------------\nnamespace {\nStatus UniqueIdxShapeFn(InferenceContext* c) {\n  ShapeHandle input = c->input(0);\n  const Tensor* axis_t = c->input_tensor(1);\n  if (axis_t == nullptr || !c->RankKnown(input)) {\n    c->set_output(1, c->Vector(InferenceContext::kUnknownDim));\n    return Status::OK();\n  }\n\n  if (c->Rank(c->input(1)) != 1) {\n    return errors::InvalidArgument(\"axis expects a 1D vector.\");\n  }\n\n  int32_t n = axis_t->NumElements();\n  if (n == 0) {\n    if (c->Rank(input) != 1) {\n      return errors::InvalidArgument(\"x expects a 1D vector.\");\n    }\n    c->set_output(1, input);\n    return Status::OK();\n  } else if (n == 1) {\n    int64_t axis;\n    if (axis_t->dtype() == DT_INT32) {\n      axis = static_cast<int64_t>(axis_t->flat<int32>()(0));\n    } else {\n      axis = axis_t->flat<int64_t>()(0);\n    }\n\n    int64_t input_rank = c->Rank(input);\n    if (axis < -input_rank || axis >= input_rank) {\n      return errors::InvalidArgument(\"axis expects to be in the range [\",\n                                     -input_rank, \", \", input_rank, \")\");\n    }\n    if (axis < 0) {\n      axis += input_rank;\n    }\n    c->set_output(1, c->Vector(c->Dim(input, axis)));\n    return Status::OK();\n  }\n  return errors::InvalidArgument(\n      \"axis does not support input tensors larger than 1 elements.\");\n}\n}  // namespace\n\nREGISTER_OP(\"Unique\")\n    .Input(\"x: T\")\n    .Output(\"y: T\")\n    .Output(\"idx: out_idx\")\n    .Attr(\"T: type\")\n    .Attr(\"out_idx: {int32, int64} = DT_INT32\")\n    .SetShapeFn([](InferenceContext* c) {\n      c->set_output(0, c->Vector(InferenceContext::kUnknownDim));\n      c->set_output(1, c->input(0));\n      // Assert that the input rank is 1.\n      ShapeHandle dummy;\n      return c->WithRank(c->input(0), 1, &dummy);\n    });\n\nREGISTER_OP(\"UniqueV2\")\n    .Input(\"x: T\")\n    .Input(\"axis: Taxis\")\n    .Output(\"y: T\")\n    .Output(\"idx: out_idx\")\n    .Attr(\"T: type\")\n    .Attr(\"Taxis: {int32,int64} = DT_INT64\")\n    .Attr(\"out_idx: {int32, int64} = DT_INT32\")\n    .SetShapeFn([](InferenceContext* c) {\n      c->set_output(0, c->UnknownShapeOfRank(c->Rank(c->input(0))));\n      TF_RETURN_IF_ERROR(UniqueIdxShapeFn(c));\n      return Status::OK();\n    });\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"UniqueWithCounts\")\n    .Input(\"x: T\")\n    .Output(\"y: T\")\n    .Output(\"idx: out_idx\")\n    .Output(\"count: out_idx\")\n    .Attr(\"T: type\")\n    .Attr(\"out_idx: {int32, int64} = DT_INT32\")\n    .SetShapeFn([](InferenceContext* c) {\n      auto uniq = c->Vector(InferenceContext::kUnknownDim);\n      c->set_output(0, uniq);\n      c->set_output(1, c->input(0));\n      c->set_output(2, uniq);\n      return Status::OK();\n    });\n\nREGISTER_OP(\"UniqueWithCountsV2\")\n    .Input(\"x: T\")\n    .Input(\"axis: Taxis\")\n    .Output(\"y: T\")\n    .Output(\"idx: out_idx\")\n    .Output(\"count: out_idx\")\n    .Attr(\"T: type\")\n    .Attr(\"Taxis: {int32,int64} = DT_INT64\")\n    .Attr(\"out_idx: {int32, int64} = DT_INT32\")\n    .SetShapeFn([](InferenceContext* c) {\n      c->set_output(0, c->UnknownShapeOfRank(c->Rank(c->input(0))));\n      TF_RETURN_IF_ERROR(UniqueIdxShapeFn(c));\n      c->set_output(2, c->Vector(InferenceContext::kUnknownDim));\n      return Status::OK();\n    });\n\nnamespace {\n\nStatus ShapeShapeFn(InferenceContext* c) {\n  for (int i = 0; i < c->num_inputs(); ++i) {\n    DimensionHandle dim;\n    if (c->RankKnown(c->input(i))) {\n      dim = c->MakeDim(c->Rank(c->input(i)));\n    } else {\n      dim = c->UnknownDim();\n    }\n    c->set_output(i, c->Vector(dim));\n  }\n  return Status::OK();\n}\n\n}  // namespace\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"Shape\")\n    .Input(\"input: T\")\n    .Output(\"output: out_type\")\n    .Attr(\"T: type\")\n    .Attr(\"out_type: {int32, int64} = DT_INT32\")\n    .SetShapeFn(ShapeShapeFn);\n\nREGISTER_OP(\"ShapeN\")\n    .Input(\"input: N * T\")\n    .Output(\"output: N * out_type\")\n    .Attr(\"N: int\")\n    .Attr(\"T: type\")\n    .Attr(\"out_type: {int32, int64} = DT_INT32\")\n    .SetShapeFn(ShapeShapeFn);\n\nREGISTER_OP(\"EnsureShape\")\n    .Input(\"input: T\")\n    .Output(\"output: T\")\n    .Attr(\"shape: shape\")\n    .Attr(\"T: type\")\n    .SetShapeFn([](InferenceContext* c) {\n      // Merges desired shape and statically known shape of input\n      PartialTensorShape desired_shape;\n      TF_RETURN_IF_ERROR(c->GetAttr(\"shape\", &desired_shape));\n\n      int rank = desired_shape.dims();\n      ShapeHandle input_shape_handle;\n      ShapeHandle desired_shape_handle;\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(0), rank, &input_shape_handle));\n      TF_RETURN_IF_ERROR(c->MakeShapeFromPartialTensorShape(\n          desired_shape, &desired_shape_handle));\n\n      ShapeHandle merged_shape;\n      TF_RETURN_IF_ERROR(\n          c->Merge(desired_shape_handle, input_shape_handle, &merged_shape));\n      c->set_output(0, merged_shape);\n      return Status::OK();\n    });\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"ReverseSequence\")\n    .Input(\"input: T\")\n    .Input(\"seq_lengths: Tlen\")\n    .Output(\"output: T\")\n    .Attr(\"seq_dim: int\")\n    .Attr(\"batch_dim: int = 0\")\n    .Attr(\"T: type\")\n    .Attr(\"Tlen: {int32, int64} = DT_INT64\")\n    .SetShapeFn([](InferenceContext* c) {\n      ShapeHandle input = c->input(0);\n      ShapeHandle seq_lens_shape;\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(1), 1, &seq_lens_shape));\n\n      int64_t seq_dim;\n      TF_RETURN_IF_ERROR(c->GetAttr(\"seq_dim\", &seq_dim));\n      int64_t batch_dim;\n      TF_RETURN_IF_ERROR(c->GetAttr(\"batch_dim\", &batch_dim));\n\n      if (!c->RankKnown(input)) {\n        return shape_inference::UnknownShape(c);\n      }\n\n      // Validate batch_dim and seq_dim against input.\n      const int32_t input_rank = c->Rank(input);\n      if (batch_dim >= input_rank) {\n        return errors::InvalidArgument(\n            \"batch_dim must be < input rank: \", batch_dim, \" vs. \", input_rank);\n      }\n      if (seq_dim >= input_rank) {\n        return errors::InvalidArgument(\n            \"seq_dim must be < input rank: \", seq_dim, \" vs. \", input_rank);\n      }\n\n      DimensionHandle batch_dim_dim = c->Dim(input, batch_dim);\n      TF_RETURN_IF_ERROR(\n          c->Merge(batch_dim_dim, c->Dim(seq_lens_shape, 0), &batch_dim_dim));\n\n      // Replace batch_dim of input with batch_size\n      ShapeHandle output_shape;\n      TF_RETURN_IF_ERROR(\n          c->ReplaceDim(input, batch_dim, batch_dim_dim, &output_shape));\n      c->set_output(0, output_shape);\n      return Status::OK();\n    });\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"Rank\")\n    .Input(\"input: T\")\n    .Output(\"output: int32\")\n    .Attr(\"T: type\")\n    .SetShapeFn(shape_inference::ScalarShape);\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"Size\")\n    .Input(\"input: T\")\n    .Output(\"output: out_type\")\n    .Attr(\"T: type\")\n    .Attr(\"out_type: {int32, int64} = DT_INT32\")\n    .SetShapeFn(shape_inference::ScalarShape);\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"Slice\")\n    .Input(\"input: T\")\n    .Input(\"begin: Index\")\n    .Input(\"size: Index\")\n    .Output(\"output: T\")\n    .Attr(\"T: type\")\n    .Attr(\"Index: {int32,int64}\")\n    .SetShapeFn(shape_inference::SliceShape);\n\n#ifdef INTEL_MKL\nREGISTER_OP(\"_MklSlice\")\n    .Input(\"input: T\")\n    .Input(\"begin: Index\")\n    .Input(\"size: Index\")\n    .Input(\"mkl_input: uint8\")\n    .Input(\"mkl_begin: uint8\")\n    .Input(\"mkl_size: uint8\")\n    .Output(\"output: T\")\n    .Output(\"mkl_output: uint8\")\n    .Attr(\"T: type\")\n    .Attr(\"Index: {int32,int64}\")\n    .SetShapeFn(shape_inference::SliceShape);\n#endif\n\nREGISTER_OP(\"StridedSlice\")\n    .Input(\"input: T\")\n    .Input(\"begin: Index\")\n    .Input(\"end: Index\")\n    .Input(\"strides: Index\")\n    .Output(\"output: T\")\n    .Attr(\"T: type\")\n    .Attr(\"Index: {int32, int64}\")\n    .Attr(\"begin_mask: int = 0\")\n    .Attr(\"end_mask: int = 0\")\n    .Attr(\"ellipsis_mask: int = 0\")\n    .Attr(\"new_axis_mask: int = 0\")\n    .Attr(\"shrink_axis_mask: int = 0\")\n    .SetShapeFn([](InferenceContext* c) {\n      ShapeHandle input = c->input(0);\n      ShapeHandle begin_shape, end_shape, strides_shape;\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(1), 1, &begin_shape));\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(2), 1, &end_shape));\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(3), 1, &strides_shape));\n      TF_RETURN_IF_ERROR(c->Merge(begin_shape, end_shape, &begin_shape));\n      TF_RETURN_IF_ERROR(c->Merge(begin_shape, strides_shape, &begin_shape));\n      DimensionHandle sparse_dims_dim = c->Dim(begin_shape, 0);\n\n      const Tensor* strides_value = c->input_tensor(3);\n      // TODO(aselle,allenl): If we had a stride_mask it would be possible to do\n      // more shape inference here (e.g. for x[3, ::T]).\n      if (!c->RankKnown(input) || !c->ValueKnown(sparse_dims_dim) ||\n          strides_value == nullptr) {\n        c->set_output(0, c->UnknownShape());\n        return Status::OK();\n      }\n\n      PartialTensorShape input_shape({});\n      for (int i = 0; i < c->Rank(input); ++i) {\n        auto dim = c->Dim(input, i);\n        input_shape.AddDim(c->ValueKnown(dim) ? c->Value(dim) : -1);\n      }\n\n      int32_t begin_mask, end_mask, ellipsis_mask, new_axis_mask,\n          shrink_axis_mask;\n      TF_RETURN_IF_ERROR(c->GetAttr(\"begin_mask\", &begin_mask));\n      TF_RETURN_IF_ERROR(c->GetAttr(\"end_mask\", &end_mask));\n      TF_RETURN_IF_ERROR(c->GetAttr(\"ellipsis_mask\", &ellipsis_mask));\n      TF_RETURN_IF_ERROR(c->GetAttr(\"new_axis_mask\", &new_axis_mask));\n      TF_RETURN_IF_ERROR(c->GetAttr(\"shrink_axis_mask\", &shrink_axis_mask));\n\n      const Tensor* begin_value = c->input_tensor(1);\n      const Tensor* end_value = c->input_tensor(2);\n\n      PartialTensorShape processing_shape, final_shape;\n      bool is_identity, is_simple_slice, slice_dim0;\n      gtl::InlinedVector<int64, 4> begin, end, strides;\n      TF_RETURN_IF_ERROR(ValidateStridedSliceOp(\n          begin_value, end_value, *strides_value, input_shape, begin_mask,\n          end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask,\n          &processing_shape, &final_shape, &is_identity, &is_simple_slice,\n          &slice_dim0, &begin, &end, &strides));\n\n      ShapeHandle out;\n      TF_RETURN_IF_ERROR(c->MakeShapeFromPartialTensorShape(final_shape, &out));\n      c->set_output(0, out);\n\n      auto* shape_and_type = c->input_handle_shapes_and_types(0);\n      if (shape_and_type) {\n        c->set_output_handle_shapes_and_types(0, *shape_and_type);\n      }\n\n      return Status::OK();\n    });\n\nREGISTER_OP(\"StridedSliceGrad\")\n    .Input(\"shape: Index\")\n    .Input(\"begin: Index\")\n    .Input(\"end: Index\")\n    .Input(\"strides: Index\")\n    .Input(\"dy: T\")\n    .Output(\"output: T\")\n    .Attr(\"T: type\")\n    .Attr(\"Index: {int32, int64}\")\n    .Attr(\"begin_mask: int = 0\")\n    .Attr(\"end_mask: int = 0\")\n    .Attr(\"ellipsis_mask: int = 0\")\n    .Attr(\"new_axis_mask: int = 0\")\n    .Attr(\"shrink_axis_mask: int = 0\")\n    .SetShapeFn([](InferenceContext* c) {\n      ShapeHandle out;\n      TF_RETURN_IF_ERROR(c->MakeShapeFromShapeTensor(0, &out));\n      c->set_output(0, out);\n      return Status::OK();\n    });\n\nREGISTER_OP(\"StridedSliceAssign\")\n    .Input(\"ref: Ref(T)\")\n    .Input(\"begin: Index\")\n    .Input(\"end: Index\")\n    .Input(\"strides: Index\")\n    .Input(\"value: T\")\n    .Output(\"output_ref: Ref(T)\")\n    .Attr(\"T: type\")\n    .Attr(\"Index: {int32, int64}\")\n    .Attr(\"begin_mask: int = 0\")\n    .Attr(\"end_mask: int = 0\")\n    .Attr(\"ellipsis_mask: int = 0\")\n    .Attr(\"new_axis_mask: int = 0\")\n    .Attr(\"shrink_axis_mask: int = 0\")\n    .SetShapeFn(shape_inference::UnchangedShape);\n// TODO(aselle): Fix this documentation once StridedSliceAssign Supports\n// broadcasting.\n// --------------------------------------------------------------------------\n\nREGISTER_OP(\"ResourceStridedSliceAssign\")\n    .Input(\"ref: resource\")\n    .Input(\"begin: Index\")\n    .Input(\"end: Index\")\n    .Input(\"strides: Index\")\n    .Input(\"value: T\")\n    .Attr(\"T: type\")\n    .Attr(\"Index: {int32, int64}\")\n    .Attr(\"begin_mask: int = 0\")\n    .Attr(\"end_mask: int = 0\")\n    .Attr(\"ellipsis_mask: int = 0\")\n    .Attr(\"new_axis_mask: int = 0\")\n    .Attr(\"shrink_axis_mask: int = 0\")\n    .SetShapeFn(shape_inference::NoOutputs);\n\nREGISTER_OP(\"TensorStridedSliceUpdate\")\n    .Input(\"input: T\")\n    .Input(\"begin: Index\")\n    .Input(\"end: Index\")\n    .Input(\"strides: Index\")\n    .Input(\"value: T\")\n    .Output(\"output: T\")\n    .Attr(\"T: type\")\n    .Attr(\"Index: {int32, int64}\")\n    .Attr(\"begin_mask: int = 0\")\n    .Attr(\"end_mask: int = 0\")\n    .Attr(\"ellipsis_mask: int = 0\")\n    .Attr(\"new_axis_mask: int = 0\")\n    .Attr(\"shrink_axis_mask: int = 0\")\n    .SetShapeFn(shape_inference::UnchangedShape);\n\nREGISTER_OP(\"Tile\")\n    .Input(\"input: T\")\n    .Input(\"multiples: Tmultiples\")\n    .Output(\"output: T\")\n    .Attr(\"T: type\")\n    .Attr(\"Tmultiples: {int32, int64} = DT_INT32\")\n    .SetShapeFn([](InferenceContext* c) {\n      ShapeHandle input = c->input(0);\n      // NOTE(mrry): Represent `multiples` as a `TensorShape` because (i)\n      // it is a vector of non-negative integers, and (ii) doing so allows\n      // us to handle partially-known multiples.\n      ShapeHandle multiples;\n      TF_RETURN_IF_ERROR(c->MakeShapeFromShapeTensor(1, &multiples));\n      if (c->RankKnown(input)) {\n        TF_RETURN_IF_ERROR(c->WithRank(multiples, c->Rank(input), &multiples));\n        ShapeHandle dummy;\n        TF_RETURN_IF_ERROR(\n            c->Merge(c->input(1), c->Vector(c->Rank(input)), &dummy));\n      }\n\n      if (!c->RankKnown(multiples)) {\n        return shape_inference::UnknownShape(c);\n      }\n\n      int32_t rank = c->Rank(multiples);\n      TF_RETURN_IF_ERROR(c->WithRank(input, rank, &input));\n      std::vector<DimensionHandle> dims(rank);\n      for (int i = 0; i < rank; ++i) {\n        TF_RETURN_IF_ERROR(\n            c->Multiply(c->Dim(input, i), c->Dim(multiples, i), &dims[i]));\n      }\n      c->set_output(0, c->MakeShape(dims));\n      return Status::OK();\n    });\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"TileGrad\")\n    .Input(\"input: T\")\n    .Input(\"multiples: int32\")\n    .Output(\"output: T\")\n    .Attr(\"T: type\")\n    .Deprecated(3, \"TileGrad has been replaced with reduce_sum\")\n    .SetShapeFn(tensorflow::shape_inference::UnknownShape);\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"Where\")\n    .Input(\"input: T\")\n    .Attr(\"T: {numbertype, bool} = DT_BOOL\")\n    .Output(\"index: int64\")\n    .SetShapeFn([](InferenceContext* c) {\n      c->set_output(0, c->Matrix(c->UnknownDim(), c->Rank(c->input(0))));\n      return Status::OK();\n    });\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"BroadcastArgs\")\n    .Input(\"s0: T\")\n    .Input(\"s1: T\")\n    .Output(\"r0: T\")\n    .Attr(\"T: {int32, int64} = DT_INT32\")\n    .SetShapeFn([](InferenceContext* c) {\n      ShapeHandle unused;\n      ShapeHandle shape_x = c->input(0);\n      ShapeHandle shape_y = c->input(1);\n      TF_RETURN_IF_ERROR(c->WithRank(shape_x, 1, &unused));\n      TF_RETURN_IF_ERROR(c->WithRank(shape_y, 1, &unused));\n\n      if (!c->ValueKnown(c->Dim(shape_x, 0)) ||\n          !c->ValueKnown(c->Dim(shape_y, 0))) {\n        c->set_output(0, c->Vector(InferenceContext::kUnknownDim));\n        return Status::OK();\n      }\n\n      int64_t x_dim = c->Value(c->Dim(shape_x, 0));\n      int64_t y_dim = c->Value(c->Dim(shape_y, 0));\n\n      // Broadcasted shape is going to be as large as the largest dimension.\n      c->set_output(0, c->Vector(std::max(x_dim, y_dim)));\n      return Status::OK();\n    });\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"BroadcastGradientArgs\")\n    .Input(\"s0: T\")\n    .Input(\"s1: T\")\n    .Output(\"r0: T\")\n    .Output(\"r1: T\")\n    .Attr(\"T: {int32, int64} = DT_INT32\")\n    .SetShapeFn([](InferenceContext* c) {\n      // TODO(mrry): Implement constant_value for BroadcastGradientArgs?\n      ShapeHandle unused;\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(0), 1, &unused));\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(1), 1, &unused));\n      c->set_output(0, c->Vector(InferenceContext::kUnknownDim));\n      c->set_output(1, c->Vector(InferenceContext::kUnknownDim));\n      return Status::OK();\n    });\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"Pad\")\n    .Input(\"input: T\")\n    .Input(\"paddings: Tpaddings\")\n    .Output(\"output: T\")\n    .Attr(\"T: type\")\n    .Attr(\"Tpaddings: {int32, int64} = DT_INT32\")\n    .SetShapeFn(PadShapeFn);\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"PadV2\")\n    .Input(\"input: T\")\n    .Input(\"paddings: Tpaddings\")\n    .Input(\"constant_values: T\")\n    .Output(\"output: T\")\n    .Attr(\"T: type\")\n    .Attr(\"Tpaddings: {int32, int64} = DT_INT32\")\n    .SetShapeFn(PadShapeFn);\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"MirrorPad\")\n    .Input(\"input: T\")\n    .Input(\"paddings: Tpaddings\")\n    .Output(\"output: T\")\n    .Attr(\"T: type\")\n    .Attr(\"Tpaddings: {int32, int64} = DT_INT32\")\n    .Attr(GetMirrorPadModeAttrString())\n    .SetShapeFn(PadShapeFn);\n\n// --------------------------------------------------------------------------\nnamespace {\ntemplate <typename T>\nStatus MirrorPadKnown(InferenceContext* c, ShapeHandle input,\n                      const Tensor* paddings_t, int64_t input_rank) {\n  auto paddings_data = paddings_t->matrix<T>();\n  std::vector<DimensionHandle> dims(input_rank);\n  for (int64_t i = 0; i < input_rank; ++i) {\n    const int64_t pad0 = static_cast<int64_t>(paddings_data(i, 0));\n    const int64_t pad1 = static_cast<int64_t>(paddings_data(i, 1));\n    if (pad0 < 0 || pad1 < 0) {\n      return errors::InvalidArgument(\"Paddings must be non-negative\");\n    }\n\n    TF_RETURN_IF_ERROR(c->Subtract(c->Dim(input, i), pad0 + pad1, &dims[i]));\n  }\n  c->set_output(0, c->MakeShape(dims));\n  return Status::OK();\n}\n\n}  // namespace\n\nREGISTER_OP(\"MirrorPadGrad\")\n    .Input(\"input: T\")\n    .Input(\"paddings: Tpaddings\")\n    .Output(\"output: T\")\n    .Attr(\"T: type\")\n    .Attr(\"Tpaddings: {int32, int64} = DT_INT32\")\n    .Attr(GetMirrorPadModeAttrString())\n    .SetShapeFn([](InferenceContext* c) {\n      ShapeHandle paddings;\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(1), 2, &paddings));\n      DimensionHandle pad_0 = c->Dim(paddings, 0);\n      if (!c->ValueKnown(pad_0)) {\n        // We don't know the rank of the output since the first\n        // padding dimension is unknown.\n        c->set_output(0, c->UnknownShape());\n        return Status::OK();\n      }\n\n      int64_t input_rank = c->Value(pad_0);\n      ShapeHandle input;\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(0), input_rank, &input));\n      TF_RETURN_IF_ERROR(\n          c->Merge(paddings, c->Matrix(input_rank, 2), &paddings));\n\n      const Tensor* paddings_t = c->input_tensor(1);\n      if (paddings_t == nullptr) {\n        // Values of 'paddings' is not available, but we know the\n        // input rank, so return the rank of the output with unknown\n        // dimensions.\n        c->set_output(0, c->UnknownShapeOfRank(input_rank));\n        return Status::OK();\n      }\n\n      if (paddings_t->dtype() == DT_INT32) {\n        return MirrorPadKnown<int32>(c, input, paddings_t, input_rank);\n      } else {\n        return MirrorPadKnown<int64_t>(c, input, paddings_t, input_rank);\n      }\n    });\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"Placeholder\")\n    .Output(\"output: dtype\")\n    .Attr(\"dtype: type\")\n    .Attr(\"shape: shape = { unknown_rank: true }\")\n    .SetShapeFn([](InferenceContext* c) {\n      PartialTensorShape shape;\n      TF_RETURN_IF_ERROR(c->GetAttr(\"shape\", &shape));\n\n      // Placeholder has legacy behavior where we cannot tell the difference\n      // between a scalar shape attribute and 'unknown shape'.  So if the shape\n      // is a scalar, we return an unknown shape.\n      if (c->graph_def_version() <= 21 && shape.dims() <= 0) {\n        return shape_inference::UnknownShape(c);\n      }\n\n      ShapeHandle out;\n      TF_RETURN_IF_ERROR(c->MakeShapeFromPartialTensorShape(shape, &out));\n      c->set_output(0, out);\n      return Status::OK();\n    });\n\n// Placeholder was modified in a backwards compatible way to do what\n// PlaceholderV2 did, so we have deprecated V2 (no one was really\n// using it).\nREGISTER_OP(\"PlaceholderV2\")\n    .Output(\"output: dtype\")\n    .Attr(\"dtype: type\")\n    .Attr(\"shape: shape\")\n    .SetShapeFn(shape_inference::ExplicitShape)\n    .Deprecated(23, \"Placeholder now behaves the same as PlaceholderV2.\");\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"PlaceholderWithDefault\")\n    .Input(\"input: dtype\")\n    .Output(\"output: dtype\")\n    .Attr(\"dtype: type\")\n    .Attr(\"shape: shape\")\n    .SetShapeFn([](InferenceContext* c) {\n      ShapeHandle input = c->input(0);\n      PartialTensorShape shape;\n      TF_RETURN_IF_ERROR(c->GetAttr(\"shape\", &shape));\n      ShapeHandle out;\n      TF_RETURN_IF_ERROR(c->MakeShapeFromPartialTensorShape(shape, &out));\n\n      // We merge for compatibility checking, but return the output,\n      // since output_shape may be less precise than input_shape.\n      ShapeHandle unused;\n      TF_RETURN_IF_ERROR(c->Merge(input, out, &unused));\n      c->set_output(0, out);\n      return Status::OK();\n    });\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"ExpandDims\")\n    .Input(\"input: T\")\n    .Input(\"dim: Tdim\")\n    .Output(\"output: T\")\n    .Attr(\"T: type\")\n    .Attr(\"Tdim: {int32, int64} = DT_INT32\")\n    .SetShapeFn([](InferenceContext* c) {\n      ShapeHandle input = c->input(0);\n\n      const Tensor* dim_t = c->input_tensor(1);\n      if (dim_t != nullptr && dim_t->NumElements() != 1) {\n        return errors::InvalidArgument(\n            \"'dim' input must be a tensor with a single value\");\n      }\n      if (dim_t == nullptr || !c->RankKnown(input)) {\n        c->set_output(0, c->UnknownShape());\n        return Status::OK();\n      }\n\n      int64_t dim;\n      if (dim_t->dtype() == DT_INT32) {\n        dim = static_cast<int64_t>(dim_t->flat<int32>()(0));\n      } else {\n        dim = dim_t->flat<int64_t>()(0);\n      }\n\n      const int32_t rank = c->Rank(input);\n      const int32_t min_dim = -1 * rank - 1;\n      if (dim < min_dim || dim > rank) {\n        return errors::InvalidArgument(\"dim \", dim, \" not in the interval [\",\n                                       min_dim, \", \", rank, \"].\");\n      }\n\n      if (dim < 0) {\n        dim += rank + 1;\n      }\n\n      ShapeHandle end;\n      TF_RETURN_IF_ERROR(c->Subshape(input, dim, &end));\n\n      // Build output as start + 1 + end.\n      ShapeHandle output;\n      TF_RETURN_IF_ERROR(c->Subshape(input, 0, dim, &output));\n      TF_RETURN_IF_ERROR(c->Concatenate(output, c->Vector(1), &output));\n      TF_RETURN_IF_ERROR(c->Concatenate(output, end, &output));\n      c->set_output(0, output);\n      return Status::OK();\n    });\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"Squeeze\")\n    .Input(\"input: T\")\n    .Output(\"output: T\")\n    .Attr(\"T: type\")\n    .Attr(\"squeeze_dims: list(int) >= 0 = []\")\n    .SetShapeFn([](InferenceContext* c) {\n      ShapeHandle input = c->input(0);\n      if (!c->RankKnown(input)) {\n        // Input shape unknown.\n        return shape_inference::UnknownShape(c);\n      }\n\n      const int32_t input_rank = c->Rank(input);\n\n      // Validate and wrap squeeze dimensions.\n      std::vector<int32> squeeze_dims;\n      TF_RETURN_IF_ERROR(c->GetAttr(\"squeeze_dims\", &squeeze_dims));\n      for (int i = 0; i < squeeze_dims.size(); ++i) {\n        if (squeeze_dims[i] < -input_rank || squeeze_dims[i] >= input_rank) {\n          return errors::InvalidArgument(\"squeeze_dims[\", i, \"] not in [\",\n                                         -input_rank, \",\", input_rank, \").\");\n        }\n\n        if (squeeze_dims[i] < 0) {\n          squeeze_dims[i] += input_rank;\n        }\n      }\n\n      std::vector<DimensionHandle> result_shape;\n      for (int i = 0; i < input_rank; ++i) {\n        // True if squeeze_dims contains an entry to squeeze this\n        // dimension.\n        bool is_explicit_match =\n            std::find(squeeze_dims.begin(), squeeze_dims.end(), i) !=\n            squeeze_dims.end();\n\n        DimensionHandle dim = c->Dim(input, i);\n\n        if (!c->ValueKnown(dim)) {\n          // Assume that the squeezed dimension will be 1 at runtime.\n          if (is_explicit_match) continue;\n\n          // If squeezing all 1 dimensions, and we see an unknown value,\n          // give up and return Unknown Shape.\n          if (squeeze_dims.empty()) {\n            c->set_output(0, c->UnknownShape());\n            return Status::OK();\n          }\n        } else if (c->Value(dim) == 1) {\n          if (is_explicit_match || squeeze_dims.empty()) {\n            // If explicitly squeezing, or squeezing all 1s, remove\n            // this dimension.\n            continue;\n          }\n        } else if (is_explicit_match) {\n          return errors::InvalidArgument(\"Can not squeeze dim[\", i,\n                                         \"], expected a dimension of 1, got \",\n                                         c->Value(c->Dim(input, i)));\n        }\n\n        result_shape.emplace_back(dim);\n      }\n\n      c->set_output(0, c->MakeShape(result_shape));\n      return Status::OK();\n    });\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"ListDiff\")\n    .Input(\"x: T\")\n    .Input(\"y: T\")\n    .Output(\"out: T\")\n    .Output(\"idx: out_idx\")\n    .Attr(\"T: type\")\n    .Attr(\"out_idx: {int32, int64} = DT_INT32\")\n    .SetShapeFn([](InferenceContext* c) {\n      ShapeHandle unused;\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(0), 1, &unused));\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(1), 1, &unused));\n      // TODO(mrry): Indicate that the length falls within an interval?\n      ShapeHandle out = c->Vector(InferenceContext::kUnknownDim);\n      c->set_output(0, out);\n      c->set_output(1, out);\n      return Status::OK();\n    });\n\nnamespace {\n\n// Converts Tensor to flat std::vector<int64_t>.\ntemplate <typename InputType>\nstd::vector<int64_t> GetFlatInt64(const Tensor& t) {\n  std::vector<int64_t> output(t.shape().num_elements());\n  if (t.shape().num_elements() > 0) {\n    auto eigen_vec = t.flat<InputType>();\n    std::copy_n(&eigen_vec(0), output.size(), output.begin());\n  }\n  return output;\n}\n\n// Converts int32 or int64 Tensor to flat std::vector<int64_t>.\nstd::vector<int64_t> GetFlatInt64(const Tensor& t) {\n  if (t.dtype() == DT_INT32) {\n    return GetFlatInt64<int32>(t);\n  } else {\n    return GetFlatInt64<int64_t>(t);\n  }\n}\n\nStatus SpaceToBatchShapeHelper(InferenceContext* c, ShapeHandle input_shape,\n                               ShapeHandle block_shape_shape,\n                               const Tensor* block_shape_t,\n                               ShapeHandle paddings_shape,\n                               const Tensor* paddings_t) {\n  if (c->Rank(block_shape_shape) != 1) {\n    return errors::InvalidArgument(\"block_shape must have rank 1.\");\n  }\n\n  const DimensionHandle num_block_dims_handle = c->Dim(block_shape_shape, 0);\n  if (!c->ValueKnown(num_block_dims_handle)) {\n    return errors::InvalidArgument(\"block_shape must have known size.\");\n  }\n\n  const int64_t num_block_dims = c->Value(num_block_dims_handle);\n\n  TF_RETURN_IF_ERROR(\n      c->WithRankAtLeast(input_shape, num_block_dims + 1, &input_shape));\n\n  TF_RETURN_IF_ERROR(\n      c->Merge(paddings_shape, c->Matrix(num_block_dims, 2), &paddings_shape));\n\n  DimensionHandle batch_size = c->Dim(input_shape, 0);\n  std::vector<int64_t> block_shape_vec;\n  if (block_shape_t && (block_shape_t->NumElements() > 0)) {\n    block_shape_vec = GetFlatInt64(*block_shape_t);\n    for (int64_t dim = 0; dim < num_block_dims; ++dim) {\n      const int64_t block_shape_value = block_shape_vec[dim];\n      if (block_shape_value < 1) {\n        return errors::InvalidArgument(\"block_shape must be positive\");\n      }\n      if (c->ValueKnown(batch_size)) {\n        TF_RETURN_IF_ERROR(\n            c->Multiply(batch_size, block_shape_value, &batch_size));\n      } else {\n        batch_size = c->UnknownDim();\n      }\n    }\n  } else if (num_block_dims > 0) {\n    batch_size = c->UnknownDim();\n  }\n\n  std::vector<DimensionHandle> output_dims{batch_size};\n  output_dims.resize(num_block_dims + 1, c->UnknownDim());\n\n  if (paddings_t && (paddings_t->NumElements() > 0)) {\n    const std::vector<int64_t> paddings_vec = GetFlatInt64(*paddings_t);\n    for (int64_t dim = 0; dim < num_block_dims; ++dim) {\n      const int64_t pad_start = paddings_vec[dim * 2],\n                    pad_end = paddings_vec[dim * 2 + 1];\n      if (pad_start < 0 || pad_end < 0) {\n        return errors::InvalidArgument(\"paddings cannot be negative\");\n      }\n      if (block_shape_t) {\n        DimensionHandle padded_size;\n        TF_RETURN_IF_ERROR(\n            c->Add(c->Dim(input_shape, dim + 1), pad_start, &padded_size));\n        TF_RETURN_IF_ERROR(c->Add(padded_size, pad_end, &padded_size));\n        TF_RETURN_IF_ERROR(c->Divide(padded_size, block_shape_vec[dim],\n                                     /*evenly_divisible=*/true,\n                                     &output_dims[dim + 1]));\n      }\n    }\n  }\n\n  ShapeHandle remaining_input_shape;\n  TF_RETURN_IF_ERROR(\n      c->Subshape(input_shape, 1 + num_block_dims, &remaining_input_shape));\n\n  ShapeHandle result;\n  TF_RETURN_IF_ERROR(c->Concatenate(c->MakeShape(output_dims),\n                                    remaining_input_shape, &result));\n  c->set_output(0, result);\n  return Status::OK();\n}\n\nStatus BatchToSpaceShapeHelper(InferenceContext* c, ShapeHandle input_shape,\n                               ShapeHandle block_shape_shape,\n                               const Tensor* block_shape_t,\n                               ShapeHandle crops_shape, const Tensor* crops_t) {\n  if (c->Rank(block_shape_shape) != 1) {\n    return errors::InvalidArgument(\"block_shape must have rank 1.\");\n  }\n\n  const DimensionHandle num_block_dims_handle = c->Dim(block_shape_shape, 0);\n  if (!c->ValueKnown(num_block_dims_handle)) {\n    return errors::InvalidArgument(\"block_shape must have known size.\");\n  }\n\n  const int64_t num_block_dims = c->Value(num_block_dims_handle);\n\n  TF_RETURN_IF_ERROR(\n      c->WithRankAtLeast(input_shape, num_block_dims + 1, &input_shape));\n\n  TF_RETURN_IF_ERROR(\n      c->Merge(crops_shape, c->Matrix(num_block_dims, 2), &crops_shape));\n\n  DimensionHandle batch_size = c->Dim(input_shape, 0);\n  std::vector<int64_t> block_shape_vec;\n  if (block_shape_t) {\n    block_shape_vec = GetFlatInt64(*block_shape_t);\n    for (int64_t dim = 0; dim < num_block_dims; ++dim) {\n      const int64_t block_shape_value = block_shape_vec[dim];\n      if (block_shape_value < 1) {\n        return errors::InvalidArgument(\"block_shape must be positive\");\n      }\n      if (c->ValueKnown(batch_size)) {\n        TF_RETURN_IF_ERROR(c->Divide(batch_size, block_shape_value,\n                                     /*evenly_divisible=*/true, &batch_size));\n      } else {\n        batch_size = c->UnknownDim();\n      }\n    }\n  } else if (num_block_dims > 0) {\n    batch_size = c->UnknownDim();\n  }\n\n  std::vector<DimensionHandle> output_dims{batch_size};\n  output_dims.resize(num_block_dims + 1, c->UnknownDim());\n\n  if (crops_t) {\n    const std::vector<int64_t> crops_vec = GetFlatInt64(*crops_t);\n    for (int64_t dim = 0; dim < num_block_dims; ++dim) {\n      const int64_t crop_start = crops_vec[dim * 2],\n                    crop_end = crops_vec[dim * 2 + 1];\n      if (crop_start < 0 || crop_end < 0) {\n        return errors::InvalidArgument(\"crops cannot be negative\");\n      }\n      if (block_shape_t) {\n        DimensionHandle cropped_size;\n        TF_RETURN_IF_ERROR(c->Multiply(c->Dim(input_shape, dim + 1),\n                                       block_shape_vec[dim], &cropped_size));\n        TF_RETURN_IF_ERROR(\n            c->Subtract(cropped_size, crop_start, &cropped_size));\n        TF_RETURN_IF_ERROR(\n            c->Subtract(cropped_size, crop_end, &output_dims[dim + 1]));\n      }\n    }\n  }\n\n  ShapeHandle remaining_input_shape;\n  TF_RETURN_IF_ERROR(\n      c->Subshape(input_shape, 1 + num_block_dims, &remaining_input_shape));\n\n  ShapeHandle result;\n  TF_RETURN_IF_ERROR(c->Concatenate(c->MakeShape(output_dims),\n                                    remaining_input_shape, &result));\n  c->set_output(0, result);\n  return Status::OK();\n}\n\n}  // namespace\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"SpaceToBatchND\")\n    .Input(\"input: T\")\n    .Input(\"block_shape: Tblock_shape\")\n    .Input(\"paddings: Tpaddings\")\n    .Output(\"output: T\")\n    .Attr(\"T: type\")\n    .Attr(\"Tblock_shape: {int32, int64} = DT_INT32\")\n    .Attr(\"Tpaddings: {int32, int64} = DT_INT32\")\n    .SetShapeFn([](InferenceContext* c) {\n      return SpaceToBatchShapeHelper(c, c->input(0), c->input(1),\n                                     c->input_tensor(1), c->input(2),\n                                     c->input_tensor(2));\n    });\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"SpaceToBatch\")\n    .Input(\"input: T\")\n    .Input(\"paddings: Tpaddings\")\n    .Output(\"output: T\")\n    .Attr(\"T: type\")\n    .Attr(\"Tpaddings: {int32, int64} = DT_INT32\")\n    .Attr(\"block_size: int >= 2\")\n    .SetShapeFn([](InferenceContext* c) {\n      ShapeHandle input_shape;\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(0), 4, &input_shape));\n\n      int32_t block_size;\n      TF_RETURN_IF_ERROR(c->GetAttr(\"block_size\", &block_size));\n\n      Tensor block_shape(tensorflow::DT_INT64, TensorShape({2}));\n      auto block_shape_vec = block_shape.vec<int64_t>();\n      block_shape_vec(0) = block_size;\n      block_shape_vec(1) = block_size;\n\n      return SpaceToBatchShapeHelper(c, input_shape, c->MakeShape({2}),\n                                     &block_shape, c->input(1),\n                                     c->input_tensor(1));\n    });\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"BatchToSpaceND\")\n    .Input(\"input: T\")\n    .Input(\"block_shape: Tblock_shape\")\n    .Input(\"crops: Tcrops\")\n    .Output(\"output: T\")\n    .Attr(\"T: type\")\n    .Attr(\"Tblock_shape: {int32, int64} = DT_INT32\")\n    .Attr(\"Tcrops: {int32, int64} = DT_INT32\")\n    .SetShapeFn([](InferenceContext* c) {\n      return BatchToSpaceShapeHelper(c, c->input(0), c->input(1),\n                                     c->input_tensor(1), c->input(2),\n                                     c->input_tensor(2));\n    });\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"BatchToSpace\")\n    .Input(\"input: T\")\n    .Input(\"crops: Tidx\")\n    .Output(\"output: T\")\n    .Attr(\"T: type\")\n    .Attr(\"block_size: int >= 2\")\n    .Attr(\"Tidx: {int32, int64} = DT_INT32\")\n    .SetShapeFn([](InferenceContext* c) {\n      ShapeHandle input_shape;\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(0), 4, &input_shape));\n\n      int32_t block_size;\n      TF_RETURN_IF_ERROR(c->GetAttr(\"block_size\", &block_size));\n\n      Tensor block_shape(tensorflow::DT_INT64, TensorShape({2}));\n      auto block_shape_vec = block_shape.vec<int64_t>();\n      block_shape_vec(0) = block_size;\n      block_shape_vec(1) = block_size;\n\n      return BatchToSpaceShapeHelper(c, input_shape, c->MakeShape({2}),\n                                     &block_shape, c->input(1),\n                                     c->input_tensor(1));\n    });\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"SpaceToDepth\")\n    .Input(\"input: T\")\n    .Output(\"output: T\")\n    .Attr(\"T: type\")\n    .Attr(\"block_size: int >= 2\")\n    .Attr(\"data_format: {'NHWC', 'NCHW', 'NCHW_VECT_C'} = 'NHWC'\")\n    // TODO(pauldonnelly): Implement GPU kernels for NCHW_VECT_C.\n    .SetShapeFn([](InferenceContext* c) {\n      string data_format_str;\n      TF_RETURN_IF_ERROR(c->GetAttr(\"data_format\", &data_format_str));\n      TensorFormat data_format;\n      FormatFromString(data_format_str, &data_format);\n\n      constexpr int num_spatial_dims = 2;\n      const int dims =\n          GetTensorDimsFromSpatialDims(num_spatial_dims, data_format);\n      ShapeHandle input;\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(0), dims, &input));\n\n      int32_t block_size;\n      TF_RETURN_IF_ERROR(c->GetAttr(\"block_size\", &block_size));\n\n      DimensionHandle batch_size =\n          c->Dim(input, GetTensorDimIndex<num_spatial_dims>(data_format, 'N'));\n      DimensionHandle input_height =\n          c->Dim(input, GetTensorDimIndex<num_spatial_dims>(data_format, 'H'));\n      DimensionHandle input_width =\n          c->Dim(input, GetTensorDimIndex<num_spatial_dims>(data_format, 'W'));\n      DimensionHandle input_depth =\n          c->Dim(input, GetTensorDimIndex<num_spatial_dims>(data_format, 'C'));\n\n      DimensionHandle output_height;\n      DimensionHandle output_width;\n      DimensionHandle output_depth;\n      // Will return an error if input height or width are not evenly divisible.\n      TF_RETURN_IF_ERROR(c->Divide(input_height, block_size,\n                                   true /* evenly_divisible */,\n                                   &output_height));\n      TF_RETURN_IF_ERROR(c->Divide(input_width, block_size,\n                                   true /* evenly_divisible */, &output_width));\n\n      TF_RETURN_IF_ERROR(\n          c->Multiply(input_depth, block_size * block_size, &output_depth));\n\n      ShapeHandle output_shape;\n      TF_RETURN_IF_ERROR(MakeShapeFromFormat(data_format, batch_size,\n                                             {output_height, output_width},\n                                             output_depth, &output_shape, c));\n\n      c->set_output(0, output_shape);\n      return Status::OK();\n    });\n\n// --------------------------------------------------------------------------\nREGISTER_OP(\"DepthToSpace\")\n    .Input(\"input: T\")\n    .Output(\"output: T\")\n    .Attr(\"T: type\")\n    .Attr(\"block_size: int >= 2\")\n    .Attr(\"data_format: {'NHWC', 'NCHW', 'NCHW_VECT_C'} = 'NHWC'\")\n    // TODO(pauldonnelly): Implement GPU kernels for NCHW and NCHW_VECT_C.\n    .SetShapeFn([](InferenceContext* c) {\n      string data_format_str;\n      TF_RETURN_IF_ERROR(c->GetAttr(\"data_format\", &data_format_str));\n      TensorFormat data_format;\n      FormatFromString(data_format_str, &data_format);\n\n      constexpr int num_spatial_dims = 2;\n      const int dims =\n          GetTensorDimsFromSpatialDims(num_spatial_dims, data_format);\n\n      ShapeHandle input;\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(0), dims, &input));\n\n      int32_t block_size;\n      TF_RETURN_IF_ERROR(c->GetAttr(\"block_size\", &block_size));\n\n      DimensionHandle batch_size =\n          c->Dim(input, GetTensorDimIndex<num_spatial_dims>(data_format, 'N'));\n      DimensionHandle input_height =\n          c->Dim(input, GetTensorDimIndex<num_spatial_dims>(data_format, 'H'));\n      DimensionHandle input_width =\n          c->Dim(input, GetTensorDimIndex<num_spatial_dims>(data_format, 'W'));\n      DimensionHandle input_depth =\n          c->Dim(input, GetTensorDimIndex<num_spatial_dims>(data_format, 'C'));\n\n      DimensionHandle output_height;\n      DimensionHandle output_width;\n      DimensionHandle output_depth;\n      TF_RETURN_IF_ERROR(c->Multiply(input_height, block_size, &output_height));\n      TF_RETURN_IF_ERROR(c->Multiply(input_width, block_size, &output_width));\n\n      // Will return an error if input_depth is not evenly divisible.\n      TF_RETURN_IF_ERROR(c->Divide(input_depth, block_size * block_size,\n                                   true /* evenly_divisible */, &output_depth));\n\n      ShapeHandle output_shape;\n      TF_RETURN_IF_ERROR(MakeShapeFromFormat(data_format, batch_size,\n                                             {output_height, output_width},\n                                             output_depth, &output_shape, c));\n\n      c->set_output(0, output_shape);\n      return Status::OK();\n    });\n\n// --------------------------------------------------------------------------\n\nREGISTER_OP(\"ExtractImagePatches\")\n    .Input(\"images: T\")\n    .Output(\"patches: T\")\n    .Attr(\"ksizes: list(int) >= 4\")\n    .Attr(\"strides: list(int) >= 4\")\n    .Attr(\"rates: list(int) >= 4\")\n    .Attr(\n        \"T: {bfloat16, half, float, double, int8, int16, int32, int64, \"\n        \"uint8, uint16, uint32, uint64, complex64, complex128, bool}\")\n    .Attr(GetPaddingAttrString())\n    .SetShapeFn([](InferenceContext* c) {\n      ShapeHandle input_shape;\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(0), 4, &input_shape));\n\n      std::vector<int32> ksizes;\n      TF_RETURN_IF_ERROR(c->GetAttr(\"ksizes\", &ksizes));\n      if (ksizes.size() != 4) {\n        return errors::InvalidArgument(\n            \"ExtractImagePatches requires the ksizes attribute to contain 4 \"\n            \"values, but got: \",\n            ksizes.size());\n      }\n\n      std::vector<int32> strides;\n      TF_RETURN_IF_ERROR(c->GetAttr(\"strides\", &strides));\n      if (strides.size() != 4) {\n        return errors::InvalidArgument(\n            \"ExtractImagePatches requires the stride attribute to contain 4 \"\n            \"values, but got: \",\n            strides.size());\n      }\n\n      std::vector<int32> rates;\n      TF_RETURN_IF_ERROR(c->GetAttr(\"rates\", &rates));\n      if (rates.size() != 4) {\n        return errors::InvalidArgument(\n            \"ExtractImagePatches requires the rates attribute to contain 4 \"\n            \"values, but got: \",\n            rates.size());\n      }\n\n      int32_t ksize_rows = ksizes[1];\n      int32_t ksize_cols = ksizes[2];\n\n      int32_t stride_rows = strides[1];\n      int32_t stride_cols = strides[2];\n\n      int32_t rate_rows = rates[1];\n      int32_t rate_cols = rates[2];\n\n      int32_t ksize_rows_eff = ksize_rows + (ksize_rows - 1) * (rate_rows - 1);\n      int32_t ksize_cols_eff = ksize_cols + (ksize_cols - 1) * (rate_cols - 1);\n\n      DimensionHandle batch_size_dim = c->Dim(input_shape, 0);\n      DimensionHandle in_rows_dim = c->Dim(input_shape, 1);\n      DimensionHandle in_cols_dim = c->Dim(input_shape, 2);\n      DimensionHandle output_depth_dim;\n      TF_RETURN_IF_ERROR(c->Multiply(\n          c->Dim(input_shape, 3), ksize_rows * ksize_cols, &output_depth_dim));\n\n      if (!c->ValueKnown(in_rows_dim) || !c->ValueKnown(in_cols_dim)) {\n        ShapeHandle output_shape =\n            c->MakeShape({batch_size_dim, InferenceContext::kUnknownDim,\n                          InferenceContext::kUnknownDim, output_depth_dim});\n        c->set_output(0, output_shape);\n        return Status::OK();\n      }\n      auto in_rows = c->Value(in_rows_dim);\n      auto in_cols = c->Value(in_cols_dim);\n\n      Padding padding;\n      TF_RETURN_IF_ERROR(c->GetAttr(\"padding\", &padding));\n\n      int64_t output_rows, output_cols;\n      int64_t padding_before, padding_after;\n      TF_RETURN_IF_ERROR(GetWindowedOutputSizeVerbose(\n          in_rows, ksize_rows_eff, stride_rows, padding, &output_rows,\n          &padding_before, &padding_after));\n      TF_RETURN_IF_ERROR(GetWindowedOutputSizeVerbose(\n          in_cols, ksize_cols_eff, stride_cols, padding, &output_cols,\n          &padding_before, &padding_after));\n      ShapeHandle output_shape = c->MakeShape(\n          {batch_size_dim, output_rows, output_cols, output_depth_dim});\n      c->set_output(0, output_shape);\n      return Status::OK();\n    });\n\n// --------------------------------------------------------------------------\n\n// To enable rates, uncomment all lines commented below and use ksize_*_eff\n// as the second parameter of all GetWindowedOutputSizeVerbose calls instead\n// of ksize_*.\nREGISTER_OP(\"ExtractVolumePatches\")\n    .Input(\"input: T\")\n    .Output(\"patches: T\")\n    .Attr(\"ksizes: list(int) >= 5\")\n    .Attr(\"strides: list(int) >= 5\")\n    /* .Attr(\"rates: list(int) >= 5\") */\n    .Attr(\"T: realnumbertype\")\n    .Attr(GetPaddingAttrString())\n    .SetShapeFn([](InferenceContext* c) {\n      ShapeHandle input_shape;\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(0), 5, &input_shape));\n\n      std::vector<int32> ksizes;\n      TF_RETURN_IF_ERROR(c->GetAttr(\"ksizes\", &ksizes));\n      if (ksizes.size() != 5) {\n        return errors::InvalidArgument(\n            \"ExtractVolumePatches requires the ksizes attribute to contain 5 \"\n            \"values, but got: \",\n            ksizes.size());\n      }\n\n      std::vector<int32> strides;\n      TF_RETURN_IF_ERROR(c->GetAttr(\"strides\", &strides));\n      if (strides.size() != 5) {\n        return errors::InvalidArgument(\n            \"ExtractVolumePatches requires the stride attribute to contain 5 \"\n            \"values, but got: \",\n            strides.size());\n      }\n\n      /*\n      // TODO(hsgkim): Enable rates.\n      // See extract_volume_patches_op.cc for why rates are disabled now.\n\n      std::vector<int32> rates;\n      TF_RETURN_IF_ERROR(c->GetAttr(\"rates\", &rates));\n      if (rates.size() != 5) {\n        return errors::InvalidArgument(\n            \"ExtractVolumePatches requires the rates attribute to contain 5 \"\n            \"values, but got: \",\n            rates.size());\n      }\n      */\n\n      int32_t ksize_planes = ksizes[1];\n      int32_t ksize_rows = ksizes[2];\n      int32_t ksize_cols = ksizes[3];\n\n      int32_t stride_planes = strides[1];\n      int32_t stride_rows = strides[2];\n      int32_t stride_cols = strides[3];\n\n      /*\n      int32 rate_planes = rates[1];\n      int32 rate_rows = rates[2];\n      int32 rate_cols = rates[3];\n\n      int32 ksize_planes_eff = ksize_planes +\n                               (ksize_planes - 1) * (rate_planes - 1);\n      int32 ksize_rows_eff = ksize_rows + (ksize_rows - 1) * (rate_rows - 1);\n      int32 ksize_cols_eff = ksize_cols + (ksize_cols - 1) * (rate_cols - 1);\n      */\n\n      DimensionHandle batch_size_dim = c->Dim(input_shape, 0);\n      DimensionHandle in_planes_dim = c->Dim(input_shape, 1);\n      DimensionHandle in_rows_dim = c->Dim(input_shape, 2);\n      DimensionHandle in_cols_dim = c->Dim(input_shape, 3);\n      DimensionHandle output_depth_dim;\n      TF_RETURN_IF_ERROR(c->Multiply(c->Dim(input_shape, 4),\n                                     ksize_planes * ksize_rows * ksize_cols,\n                                     &output_depth_dim));\n\n      if (!c->ValueKnown(in_planes_dim) || !c->ValueKnown(in_rows_dim) ||\n          !c->ValueKnown(in_cols_dim)) {\n        ShapeHandle output_shape =\n            c->MakeShape({batch_size_dim, InferenceContext::kUnknownDim,\n                          InferenceContext::kUnknownDim, output_depth_dim});\n        c->set_output(0, output_shape);\n        return Status::OK();\n      }\n      auto in_planes = c->Value(in_planes_dim);\n      auto in_rows = c->Value(in_rows_dim);\n      auto in_cols = c->Value(in_cols_dim);\n\n      Padding padding;\n      TF_RETURN_IF_ERROR(c->GetAttr(\"padding\", &padding));\n\n      int64_t output_planes, output_rows, output_cols;\n      int64_t padding_before, padding_after;\n      TF_RETURN_IF_ERROR(GetWindowedOutputSizeVerbose(\n          in_planes, ksize_planes, stride_planes, padding, &output_planes,\n          &padding_before, &padding_after));\n      TF_RETURN_IF_ERROR(GetWindowedOutputSizeVerbose(\n          in_rows, ksize_rows, stride_rows, padding, &output_rows,\n          &padding_before, &padding_after));\n      TF_RETURN_IF_ERROR(GetWindowedOutputSizeVerbose(\n          in_cols, ksize_cols, stride_cols, padding, &output_cols,\n          &padding_before, &padding_after));\n      ShapeHandle output_shape =\n          c->MakeShape({batch_size_dim, output_planes, output_rows, output_cols,\n                        output_depth_dim});\n      c->set_output(0, output_shape);\n      return Status::OK();\n    });\n\n// --------------------------------------------------------------------------\n\nREGISTER_OP(\"OneHot\")\n    .Input(\"indices: TI\")\n    .Input(\"depth: int32\")\n    .Input(\"on_value: T\")\n    .Input(\"off_value: T\")\n    .Attr(\"axis: int = -1\")\n    .Output(\"output: T\")\n    .Attr(\"T: type\")\n    .Attr(\"TI: {uint8, int32, int64} = DT_INT64\")\n    .SetShapeFn([](InferenceContext* c) {\n      int32_t axis;\n      TF_RETURN_IF_ERROR(c->GetAttr(\"axis\", &axis));\n      if (axis < -1) return errors::InvalidArgument(\"axis must be >= -1\");\n\n      DimensionHandle depth;\n      TF_RETURN_IF_ERROR(c->MakeDimForScalarInput(1, &depth));\n\n      ShapeHandle indices = c->input(0);\n      if (!c->RankKnown(indices)) return shape_inference::UnknownShape(c);\n\n      int32_t new_rank = c->Rank(indices) + 1;\n      // We need to add new_rank to axis in the case the axis is -1 because\n      // C++ returns negative values from % if the dividend is negative.\n      int32_t depth_index = (axis + new_rank) % new_rank;\n      // Out shape is indices[0:depth_index] + [depth] + indices[depth_index:].\n      ShapeHandle front;\n      ShapeHandle back;\n      ShapeHandle out;\n      TF_RETURN_IF_ERROR(c->Subshape(indices, 0, depth_index, &front));\n      TF_RETURN_IF_ERROR(c->Subshape(indices, depth_index, &back));\n      TF_RETURN_IF_ERROR(c->Concatenate(front, c->Vector(depth), &front));\n      TF_RETURN_IF_ERROR(c->Concatenate(front, back, &out));\n      c->set_output(0, out);\n      return Status::OK();\n    });\n\n// EXPERIMENTAL. DO NOT USE OR DEPEND ON THIS YET.\nREGISTER_OP(\"QuantizeAndDequantize\")\n    .Input(\"input: T\")\n    .Attr(\"signed_input: bool = true\")\n    .Attr(\"num_bits: int = 8\")\n    .Attr(\"range_given: bool = false\")\n    .Attr(\"input_min: float = 0\")\n    .Attr(\"input_max: float = 0\")\n    .Output(\"output: T\")\n    .Attr(\"T: {bfloat16, half, float, double}\")\n    .SetShapeFn(shape_inference::UnchangedShape)\n    .Deprecated(22, \"Replaced by QuantizeAndDequantizeV2\");\n\n// TODO(suharshs): Deprecate QuantizeAndDequantizeV2.\nREGISTER_OP(\"QuantizeAndDequantizeV2\")\n    .Input(\"input: T\")\n    .Input(\"input_min: T\")\n    .Input(\"input_max: T\")\n    .Attr(\"signed_input: bool = true\")\n    .Attr(\"num_bits: int = 8\")\n    .Attr(\"range_given: bool = false\")\n    .Output(\"output: T\")\n    .Attr(\"T: {bfloat16, half, float, double}\")\n    .Attr(\n        \"round_mode: {'HALF_TO_EVEN', 'HALF_UP'} = \"\n        \"'HALF_TO_EVEN'\")\n    .Attr(\"narrow_range: bool = false\")\n    .Attr(\"axis: int = -1\")\n    .SetShapeFn([](InferenceContext* c) {\n      int axis;\n      TF_RETURN_IF_ERROR(c->GetAttr(\"axis\", &axis));\n      const int minmax_rank = (axis == -1) ? 0 : 1;\n      ShapeHandle minmax;\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(1), minmax_rank, &minmax));\n      TF_RETURN_IF_ERROR(c->Merge(c->input(2), minmax, &minmax));\n      if (axis < -1) {\n        return errors::InvalidArgument(\"axis should be at least -1, got \",\n                                       axis);\n      } else if (axis != -1) {\n        ShapeHandle input;\n        TF_RETURN_IF_ERROR(c->WithRankAtLeast(c->input(0), axis + 1, &input));\n        DimensionHandle depth;\n        TF_RETURN_IF_ERROR(\n            c->Merge(c->Dim(minmax, 0), c->Dim(input, axis), &depth));\n      }\n      c->set_output(0, c->input(0));\n      return Status::OK();\n    });\n\nREGISTER_OP(\"QuantizeAndDequantizeV4\")\n    .Input(\"input: T\")\n    .Input(\"input_min: T\")\n    .Input(\"input_max: T\")\n    .Attr(\"signed_input: bool = true\")\n    .Attr(\"num_bits: int = 8\")\n    .Attr(\"range_given: bool = false\")\n    .Output(\"output: T\")\n    .Attr(\"T: {bfloat16, half, float, double}\")\n    .Attr(\n        \"round_mode: {'HALF_TO_EVEN', 'HALF_UP'} = \"\n        \"'HALF_TO_EVEN'\")\n    .Attr(\"narrow_range: bool = false\")\n    .Attr(\"axis: int = -1\")\n    .SetShapeFn([](InferenceContext* c) {\n      int axis;\n      TF_RETURN_IF_ERROR(c->GetAttr(\"axis\", &axis));\n      const int minmax_rank = (axis == -1) ? 0 : 1;\n      ShapeHandle minmax;\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(1), minmax_rank, &minmax));\n      TF_RETURN_IF_ERROR(c->Merge(c->input(2), minmax, &minmax));\n      if (axis < -1) {\n        return errors::InvalidArgument(\"axis should be at least -1, got \",\n                                       axis);\n      } else if (axis != -1) {\n        ShapeHandle input;\n        TF_RETURN_IF_ERROR(c->WithRankAtLeast(c->input(0), axis + 1, &input));\n        DimensionHandle depth;\n        TF_RETURN_IF_ERROR(\n            c->Merge(c->Dim(minmax, 0), c->Dim(input, axis), &depth));\n      }\n      c->set_output(0, c->input(0));\n      return Status::OK();\n    });\n\nREGISTER_OP(\"QuantizeAndDequantizeV4Grad\")\n    .Input(\"gradients: T\")\n    .Input(\"input: T\")\n    .Input(\"input_min: T\")\n    .Input(\"input_max: T\")\n    .Output(\"input_backprop: T\")\n    .Output(\"input_min_backprop: T\")\n    .Output(\"input_max_backprop: T\")\n    .Attr(\"T: {bfloat16, half, float, double}\")\n    .Attr(\"axis: int = -1\")\n    .SetShapeFn([](InferenceContext* c) {\n      int axis;\n      TF_RETURN_IF_ERROR(c->GetAttr(\"axis\", &axis));\n      const int minmax_rank = (axis == -1) ? 0 : 1;\n      ShapeHandle minmax;\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(2), minmax_rank, &minmax));\n      TF_RETURN_IF_ERROR(c->Merge(c->input(3), minmax, &minmax));\n      if (axis < -1) {\n        return errors::InvalidArgument(\"axis should be at least -1, got \",\n                                       axis);\n      } else if (axis != -1) {\n        ShapeHandle input;\n        TF_RETURN_IF_ERROR(c->WithRankAtLeast(c->input(0), axis + 1, &input));\n        DimensionHandle depth;\n        TF_RETURN_IF_ERROR(\n            c->Merge(c->Dim(minmax, 0), c->Dim(input, axis), &depth));\n      }\n      ShapeHandle inputs;\n      TF_RETURN_IF_ERROR(c->Merge(c->input(0), c->input(1), &inputs));\n      c->set_output(0, inputs);\n      c->set_output(1, minmax);\n      c->set_output(2, minmax);\n      return Status::OK();\n    });\n\nREGISTER_OP(\"QuantizeAndDequantizeV3\")\n    .Input(\"input: T\")\n    .Input(\"input_min: T\")\n    .Input(\"input_max: T\")\n    .Input(\"num_bits: int32\")\n    .Attr(\"signed_input: bool = true\")\n    .Attr(\"range_given: bool = true\")\n    .Output(\"output: T\")\n    .Attr(\"T: {bfloat16, half, float, double}\")\n    .Attr(\"narrow_range: bool = false\")\n    .Attr(\"axis: int = -1\")\n    .SetShapeFn([](InferenceContext* c) {\n      int axis;\n      TF_RETURN_IF_ERROR(c->GetAttr(\"axis\", &axis));\n      const int minmax_rank = (axis == -1) ? 0 : 1;\n      ShapeHandle minmax;\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(1), minmax_rank, &minmax));\n      TF_RETURN_IF_ERROR(c->Merge(c->input(2), minmax, &minmax));\n      if (axis < -1) {\n        return errors::InvalidArgument(\"axis should be at least -1, got \",\n                                       axis);\n      } else if (axis != -1) {\n        ShapeHandle input;\n        TF_RETURN_IF_ERROR(c->WithRankAtLeast(c->input(0), axis + 1, &input));\n        DimensionHandle depth;\n        TF_RETURN_IF_ERROR(\n            c->Merge(c->Dim(minmax, 0), c->Dim(input, axis), &depth));\n      }\n      ShapeHandle unused;\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(3), 0, &unused));\n      c->set_output(0, c->input(0));\n      return Status::OK();\n    });\n\nREGISTER_OP(\"QuantizeV2\")\n    .Input(\"input: float\")\n    .Input(\"min_range: float\")\n    .Input(\"max_range: float\")\n    .Output(\"output: T\")\n    .Output(\"output_min: float\")\n    .Output(\"output_max: float\")\n    .Attr(\"T: quantizedtype\")\n    .Attr(\"mode: {'MIN_COMBINED', 'MIN_FIRST', 'SCALED'} = 'MIN_COMBINED'\")\n    .Attr(\n        \"round_mode: {'HALF_AWAY_FROM_ZERO', 'HALF_TO_EVEN'} = \"\n        \"'HALF_AWAY_FROM_ZERO'\")\n    .Attr(\"narrow_range: bool = false\")\n    .Attr(\"axis: int = -1\")\n    .Attr(\"ensure_minimum_range: float = 0.01\")\n    .SetShapeFn(shape_inference::QuantizeV2Shape);\n\nREGISTER_OP(\"Dequantize\")\n    .Input(\"input: T\")\n    .Input(\"min_range: float\")\n    .Input(\"max_range: float\")\n    .Output(\"output: dtype\")\n    .Attr(\"T: quantizedtype\")\n    .Attr(\"mode: {'MIN_COMBINED', 'MIN_FIRST', 'SCALED'} = 'MIN_COMBINED'\")\n    .Attr(\"narrow_range: bool = false\")\n    .Attr(\"axis: int = -1\")\n    .Attr(\"dtype: {bfloat16, float} = DT_FLOAT\")\n    .SetShapeFn([](InferenceContext* c) {\n      int axis = -1;\n      Status s = c->GetAttr(\"axis\", &axis);\n      if (!s.ok() && s.code() != error::NOT_FOUND) {\n        return s;\n      }\n      if (axis < -1) {\n        return errors::InvalidArgument(\"axis should be at least -1, got \",\n                                       axis);\n      }\n      const int minmax_rank = (axis == -1) ? 0 : 1;\n      TF_RETURN_IF_ERROR(shape_inference::UnchangedShape(c));\n      ShapeHandle minmax;\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(1), minmax_rank, &minmax));\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(2), minmax_rank, &minmax));\n      if (axis != -1) {\n        ShapeHandle input;\n        TF_RETURN_IF_ERROR(c->WithRankAtLeast(c->input(0), axis + 1, &input));\n        DimensionHandle depth;\n        TF_RETURN_IF_ERROR(\n            c->Merge(c->Dim(minmax, 0), c->Dim(input, axis), &depth));\n      }\n      return Status::OK();\n    });\n\nREGISTER_OP(\"QuantizedConcat\")\n    .Input(\"concat_dim: int32\")\n    .Input(\"values: N * T\")\n    .Input(\"input_mins: N * float32\")\n    .Input(\"input_maxes: N * float32\")\n    .Output(\"output: T\")\n    .Output(\"output_min: float\")\n    .Output(\"output_max: float\")\n    .Attr(\"N: int >= 2\")\n    .Attr(\"T: type\")\n    .SetShapeFn([](InferenceContext* c) {\n      const int n = (c->num_inputs() - 1) / 3;\n      TF_RETURN_IF_ERROR(shape_inference::ConcatShape(c, n));\n      ShapeHandle unused;\n      for (int i = n + 1; i < c->num_inputs(); ++i) {\n        TF_RETURN_IF_ERROR(c->WithRank(c->input(i), 0, &unused));\n      }\n      c->set_output(1, c->Scalar());\n      c->set_output(2, c->Scalar());\n      return Status::OK();\n    });\n\nREGISTER_OP(\"QuantizedReshape\")\n    .Input(\"tensor: T\")\n    .Input(\"shape: Tshape\")\n    .Input(\"input_min: float\")\n    .Input(\"input_max: float\")\n    .Output(\"output: T\")\n    .Output(\"output_min: float\")\n    .Output(\"output_max: float\")\n    .Attr(\"T: type\")\n    .Attr(\"Tshape: {int32, int64} = DT_INT32\")\n    .SetShapeFn([](InferenceContext* c) {\n      TF_RETURN_IF_ERROR(SetOutputShapeForReshape(c));\n      ShapeHandle unused;\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(2), 0, &unused));\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(3), 0, &unused));\n      c->set_output(1, c->Scalar());\n      c->set_output(2, c->Scalar());\n      return Status::OK();\n    });\n\nREGISTER_OP(\"QuantizedInstanceNorm\")\n    .Input(\"x: T\")\n    .Input(\"x_min: float\")\n    .Input(\"x_max: float\")\n    .Output(\"y: T\")\n    .Output(\"y_min: float\")\n    .Output(\"y_max: float\")\n    .Attr(\"T: quantizedtype\")\n    .Attr(\"output_range_given: bool = false\")\n    .Attr(\"given_y_min: float = 0\")\n    .Attr(\"given_y_max: float = 0\")\n    .Attr(\"variance_epsilon: float = 1e-5\")\n    .Attr(\"min_separation: float = 1e-3\")\n    .SetShapeFn([](shape_inference::InferenceContext* c) {\n      shape_inference::ShapeHandle unused;\n      // x should be a rank 4 tensor.\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(0), 4, &unused));\n      // Assert x_min and x_max are scalars (rank 0).\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(1), 0, &unused));\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(2), 0, &unused));\n      // y has the same shape as x.\n      TF_RETURN_IF_ERROR(shape_inference::UnchangedShape(c));\n      // y_min and y_max are scalars.\n      c->set_output(1, c->Scalar());\n      c->set_output(2, c->Scalar());\n      return Status::OK();\n    });\n\nnamespace {\n\nStatus ScatterNdTensorShape(InferenceContext* c) {\n  ShapeHandle output_shape;\n  TF_RETURN_IF_ERROR(c->WithRankAtLeast(c->input(0), 1, &output_shape));\n  ShapeHandle indices_shape;\n  TF_RETURN_IF_ERROR(c->WithRankAtLeast(c->input(1), 1, &indices_shape));\n  ShapeHandle updates_shape;\n  TF_RETURN_IF_ERROR(c->WithRankAtLeast(c->input(2), 1, &updates_shape));\n  return shape_inference::ScatterNdShapeHelper(c, indices_shape, updates_shape,\n                                               output_shape);\n}\n\n}  // namespace\n\nREGISTER_OP(\"UpperBound\")\n    .Input(\"sorted_inputs: T\")\n    .Input(\"values: T\")\n    .Output(\"output: out_type\")\n    .Attr(\"T: type\")\n    .Attr(\"out_type: {int32, int64} = DT_INT32\")\n    .SetShapeFn([](InferenceContext* c) {\n      ShapeHandle unused_shape;\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(0), 2, &unused_shape));\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(1), 2, &unused_shape));\n      c->set_output(0, c->input(1));\n      return Status::OK();\n    });\n\nREGISTER_OP(\"LowerBound\")\n    .Input(\"sorted_inputs: T\")\n    .Input(\"values: T\")\n    .Output(\"output: out_type\")\n    .Attr(\"T: type\")\n    .Attr(\"out_type: {int32, int64} = DT_INT32\")\n    .SetShapeFn([](InferenceContext* c) {\n      ShapeHandle unused_shape;\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(0), 2, &unused_shape));\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(1), 2, &unused_shape));\n      c->set_output(0, c->input(1));\n      return Status::OK();\n    });\n\nREGISTER_OP(\"ScatterNd\")\n    .Input(\"indices: Tindices\")\n    .Input(\"updates: T\")\n    .Input(\"shape: Tindices\")\n    .Output(\"output: T\")\n    .Attr(\"T: type\")\n    .Attr(\"Tindices: {int32, int64}\")\n    .SetShapeFn([](InferenceContext* c) {\n      ShapeHandle indices_shape;\n      TF_RETURN_IF_ERROR(c->WithRankAtLeast(c->input(0), 1, &indices_shape));\n      ShapeHandle updates_shape;\n      TF_RETURN_IF_ERROR(c->WithRankAtLeast(c->input(1), 1, &updates_shape));\n      ShapeHandle output_shape;\n      TF_RETURN_IF_ERROR(c->MakeShapeFromShapeTensor(2, &output_shape));\n      return shape_inference::ScatterNdShapeHelper(c, indices_shape,\n                                                   updates_shape, output_shape);\n    });\n\nREGISTER_OP(\"TensorScatterUpdate\")\n    .Input(\"tensor: T\")\n    .Input(\"indices: Tindices\")\n    .Input(\"updates: T\")\n    .Output(\"output: T\")\n    .Attr(\"T: type\")\n    .Attr(\"Tindices: {int32, int64}\")\n    .SetShapeFn(ScatterNdTensorShape);\n\nREGISTER_OP(\"TensorScatterAdd\")\n    .Input(\"tensor: T\")\n    .Input(\"indices: Tindices\")\n    .Input(\"updates: T\")\n    .Output(\"output: T\")\n    .Attr(\"T: type\")\n    .Attr(\"Tindices: {int32, int64}\")\n    .SetShapeFn(ScatterNdTensorShape);\n\nREGISTER_OP(\"TensorScatterSub\")\n    .Input(\"tensor: T\")\n    .Input(\"indices: Tindices\")\n    .Input(\"updates: T\")\n    .Output(\"output: T\")\n    .Attr(\"T: type\")\n    .Attr(\"Tindices: {int32, int64}\")\n    .SetShapeFn(ScatterNdTensorShape);\n\nREGISTER_OP(\"TensorScatterMin\")\n    .Input(\"tensor: T\")\n    .Input(\"indices: Tindices\")\n    .Input(\"updates: T\")\n    .Output(\"output: T\")\n    .Attr(\"T: type\")\n    .Attr(\"Tindices: {int32, int64}\")\n    .SetShapeFn(ScatterNdTensorShape);\n\nREGISTER_OP(\"TensorScatterMax\")\n    .Input(\"tensor: T\")\n    .Input(\"indices: Tindices\")\n    .Input(\"updates: T\")\n    .Output(\"output: T\")\n    .Attr(\"T: type\")\n    .Attr(\"Tindices: {int32, int64}\")\n    .SetShapeFn(ScatterNdTensorShape);\n\nREGISTER_OP(\"ScatterNdNonAliasingAdd\")\n    .Input(\"input: T\")\n    .Input(\"indices: Tindices\")\n    .Input(\"updates: T\")\n    .Output(\"output: T\")\n    .Attr(\"T: {numbertype, bool}\")\n    .Attr(\"Tindices: {int32, int64}\")\n    .SetShapeFn(ScatterNdTensorShape);\n\nREGISTER_OP(\"FakeQuantWithMinMaxArgs\")\n    .Attr(\"min: float = -6.0\")\n    .Attr(\"max: float = 6.0\")\n    .Attr(\"num_bits: int = 8\")\n    .Attr(\"narrow_range: bool = false\")\n    .Input(\"inputs: float\")\n    .Output(\"outputs: float\")\n    .SetShapeFn(shape_inference::UnchangedShape);\n\nREGISTER_OP(\"FakeQuantWithMinMaxArgsGradient\")\n    .Attr(\"min: float = -6.0\")\n    .Attr(\"max: float = 6.0\")\n    .Attr(\"num_bits: int = 8\")\n    .Attr(\"narrow_range: bool = false\")\n    .Input(\"gradients: float\")\n    .Input(\"inputs: float\")\n    .Output(\"backprops: float\")\n    .SetShapeFn(shape_inference::UnchangedShape);\n\nREGISTER_OP(\"FakeQuantWithMinMaxVars\")\n    .Attr(\"num_bits: int = 8\")\n    .Attr(\"narrow_range: bool = false\")\n    .Input(\"inputs: float\")\n    .Input(\"min: float\")\n    .Input(\"max: float\")\n    .Output(\"outputs: float\")\n    .SetShapeFn([](InferenceContext* c) {\n      TF_RETURN_IF_ERROR(shape_inference::UnchangedShape(c));\n      ShapeHandle unused;\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(1), 0, &unused));\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(2), 0, &unused));\n      return Status::OK();\n    });\n\nREGISTER_OP(\"FakeQuantWithMinMaxVarsGradient\")\n    .Attr(\"num_bits: int = 8\")\n    .Attr(\"narrow_range: bool = false\")\n    .Input(\"gradients: float\")\n    .Input(\"inputs: float\")\n    .Input(\"min: float\")\n    .Input(\"max: float\")\n    .Output(\"backprops_wrt_input: float\")\n    .Output(\"backprop_wrt_min: float\")\n    .Output(\"backprop_wrt_max: float\")\n    .SetShapeFn([](InferenceContext* c) {\n      // gradients and inputs are same size.\n      ShapeHandle inputs;\n      TF_RETURN_IF_ERROR(c->Merge(c->input(0), c->input(1), &inputs));\n\n      // min and max are scalars\n      ShapeHandle min_max;\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(2), 0, &min_max));\n      TF_RETURN_IF_ERROR(c->Merge(min_max, c->input(3), &min_max));\n\n      c->set_output(0, inputs);\n      c->set_output(1, min_max);\n      c->set_output(2, min_max);\n      return Status::OK();\n    });\n\nREGISTER_OP(\"FakeQuantWithMinMaxVarsPerChannel\")\n    .Attr(\"num_bits: int = 8\")\n    .Attr(\"narrow_range: bool = false\")\n    .Input(\"inputs: float\")\n    .Input(\"min: float\")\n    .Input(\"max: float\")\n    .Output(\"outputs: float\")\n    .SetShapeFn([](InferenceContext* c) {\n      ShapeHandle input, min, max;\n      TF_RETURN_IF_ERROR(c->WithRankAtLeast(c->input(0), 1, &input));\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(1), 1, &min));\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(2), 1, &max));\n\n      DimensionHandle unused;\n      TF_RETURN_IF_ERROR(c->Merge(c->Dim(input, -1), c->Dim(min, 0), &unused));\n      TF_RETURN_IF_ERROR(c->Merge(c->Dim(input, -1), c->Dim(max, 0), &unused));\n      TF_RETURN_IF_ERROR(c->Merge(c->Dim(min, 0), c->Dim(max, 0), &unused));\n\n      c->set_output(0, input);\n      return Status::OK();\n    });\n\nREGISTER_OP(\"FakeQuantWithMinMaxVarsPerChannelGradient\")\n    .Attr(\"num_bits: int = 8\")\n    .Attr(\"narrow_range: bool = false\")\n    .Input(\"gradients: float\")\n    .Input(\"inputs: float\")\n    .Input(\"min: float\")\n    .Input(\"max: float\")\n    .Output(\"backprops_wrt_input: float\")\n    .Output(\"backprop_wrt_min: float\")\n    .Output(\"backprop_wrt_max: float\")\n    .SetShapeFn([](InferenceContext* c) {\n      ShapeHandle inputs;\n      TF_RETURN_IF_ERROR(c->WithRankAtLeast(c->input(0), 1, &inputs));\n      TF_RETURN_IF_ERROR(c->WithRankAtMost(inputs, 4, &inputs));\n      TF_RETURN_IF_ERROR(c->Merge(inputs, c->input(1), &inputs));\n\n      ShapeHandle last_dim = c->Vector(c->Dim(inputs, -1));\n\n      ShapeHandle min_max;\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(2), 1, &min_max));\n      TF_RETURN_IF_ERROR(c->Merge(min_max, last_dim, &min_max));\n      TF_RETURN_IF_ERROR(c->Merge(c->input(3), min_max, &min_max));\n\n      c->set_output(0, inputs);\n      c->set_output(1, min_max);\n      c->set_output(2, min_max);\n      return Status::OK();\n    });\n\nREGISTER_OP(\"Fingerprint\")\n    .Input(\"data: T\")\n    .Input(\"method: string\")\n    .Output(\"fingerprint: uint8\")\n    .Attr(\"T: type\")\n    .SetShapeFn([](InferenceContext* c) {\n      ShapeHandle unused;\n      TF_RETURN_IF_ERROR(c->WithRankAtLeast(c->input(0), 1, &unused));\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(1), 0, &unused));\n\n      DimensionHandle fingerprint_size;\n      const Tensor* method = c->input_tensor(1);\n      if (method == nullptr) {\n        fingerprint_size = c->UnknownDim();\n      } else {\n        if (method->dims() != 0) {\n          return errors::InvalidArgument(\"`method` must be rank 0: \",\n                                         method->shape());\n        }\n        const string& method_string = method->scalar<tstring>()();\n        if (method_string != \"farmhash64\") {\n          return errors::InvalidArgument(\"Unsupported method: \", method_string);\n        }\n        fingerprint_size = c->MakeDim(sizeof(uint64));\n      }\n\n      DimensionHandle batch = c->Dim(c->input(0), 0);\n      c->set_output(0, c->MakeShape({batch, fingerprint_size}));\n      return Status::OK();\n    });\n\n#ifdef INTEL_MKL\nREGISTER_OP(\"_MklConcat\")\n    .Input(\"concat_dim: int32\")\n    .Input(\"values: N * T\")\n    .Input(\"mkl_concat_dim: uint8\")\n    .Input(\"mkl_values: N * uint8\")\n    .Output(\"output: T\")\n    .Output(\"mkl_output: uint8\")\n    .Attr(\"N: int >= 2\")\n    .Attr(\"T: type\")\n    .SetShapeFn([](InferenceContext* c) {\n      return shape_inference::ConcatShape(c, c->num_inputs() - 3);\n    })\n    .Doc(R\"doc(\nMKL version of Concat operator. Uses MKL DNN APIs to perform concatenation.\n\nNOTE Do not invoke this operator directly in Python. Graph rewrite pass is\nexpected to invoke these operators.\n)doc\");\n#endif\n\n// Deprecated op registrations:\n\n// The following can be deleted after 10mar2017.\nREGISTER_OP(\"BatchMatrixDiag\")\n    .Input(\"diagonal: T\")\n    .Output(\"output: T\")\n    .Attr(\"T: type\")\n    .Deprecated(14, \"Use MatrixDiag\")\n    .SetShapeFn(shape_inference::UnknownShape);\nREGISTER_OP(\"BatchMatrixSetDiag\")\n    .Input(\"input: T\")\n    .Input(\"diagonal: T\")\n    .Output(\"output: T\")\n    .Attr(\"T: type\")\n    .Deprecated(14, \"Use MatrixSetDiag\")\n    .SetShapeFn(shape_inference::UnknownShape);\nREGISTER_OP(\"BatchMatrixDiagPart\")\n    .Input(\"input: T\")\n    .Output(\"diagonal: T\")\n    .Attr(\"T: type\")\n    .Deprecated(14, \"Use MatrixDiagPart\")\n    .SetShapeFn(shape_inference::UnknownShape);\nREGISTER_OP(\"BatchMatrixBandPart\")\n    .Input(\"input: T\")\n    .Input(\"num_lower: int64\")\n    .Input(\"num_upper: int64\")\n    .Output(\"band: T\")\n    .Attr(\"T: type\")\n    .Deprecated(14, \"Use MatrixBandPart\")\n    .SetShapeFn(shape_inference::UnknownShape);\n\n}  // namespace tensorflow\n", "/* Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\n\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n\n#include \"tensorflow/core/framework/node_def_builder.h\"\n#include \"tensorflow/core/framework/node_def_util.h\"\n#include \"tensorflow/core/framework/op.h\"\n#include \"tensorflow/core/framework/shape_inference.h\"\n#include \"tensorflow/core/framework/shape_inference_testutil.h\"\n#include \"tensorflow/core/framework/tensor.pb.h\"\n#include \"tensorflow/core/framework/tensor_shape.pb.h\"\n#include \"tensorflow/core/framework/tensor_testutil.h\"\n#include \"tensorflow/core/lib/core/status_test_util.h\"\n#include \"tensorflow/core/platform/test.h\"\n#include \"tensorflow/core/public/version.h\"\n\nnamespace tensorflow {\n\nTEST(ArrayOpsTest, TensorScatterUpdate_ShapeFn) {\n  ShapeInferenceTestOp op(\"TensorScatterUpdate\");\n\n  INFER_OK(op, \"[4,3];[8,2];[8]\", \"in0\");\n  INFER_OK(op, \"[?,?];[?,2];[?]\", \"in0\");\n  INFER_OK(op, \"[?];[?];[?]\", \"in0\");\n\n  INFER_ERROR(\"Shape must be at least rank 1 but is rank 0\", op,\n              \"[];[?,2];[?]\");\n  INFER_ERROR(\"Indices and updates specified for empty input\", op,\n              \"[0,2,2];[8,2];[8]\");\n  INFER_ERROR(\n      \"Dimensions [0,1) of indices[shape=[8,2]] = [8] must match \"\n      \"dimensions [0,1) of updates[shape=[9]] = [9]\",\n      op, \"[?,?];[8,2];[9]\");\n  INFER_ERROR(\n      \"Dimensions [2,2) of input[shape=[?,?]] = [] must match \"\n      \"dimensions [1,2) of updates[shape=[?,1]] = [1]\",\n      op, \"[?,?];[?,2];[?,1]\");\n}\n\nTEST(ArrayOpsTest, ScatterNd_ShapeFn) {\n  ShapeInferenceTestOp op(\"ScatterNd\");\n\n  INFER_OK(op, \"[8,2];[8];[2]\", \"[?,?]\");\n\n  INFER_ERROR(\"Shape must be rank 1 but is rank 0\", op, \"[?,2];[?];[]\");\n  INFER_ERROR(\n      \"Dimensions [0,1) of indices[shape=[8,2]] = [8] must match \"\n      \"dimensions [0,1) of updates[shape=[9]] = [9]\",\n      op, \"[8,2];[9];[?]\");\n}\n\nTEST(ArrayOpsTest, UnravelIndex_ShapeFn) {\n  ShapeInferenceTestOp op(\"UnravelIndex\");\n\n  INFER_OK(op, \"?;?\", \"?\");\n\n  INFER_OK(op, \"[];[?]\", \"[d1_0]\");\n\n  INFER_OK(op, \"[4,5];[?]\", \"[d1_0,20]\");\n  INFER_OK(op, \"[2,3,4];[?]\", \"[d1_0,24]\");\n  INFER_OK(op, \"?;[?]\", \"?\");\n  INFER_OK(op, \"[?];[?]\", \"[d1_0,?]\");\n\n  INFER_ERROR(\"Shape must be rank 1 but is rank 2\", op, \"?;[1,1]\");\n}\n\nTEST(ArrayOpsTest, Pack_ShapeFn) {\n  ShapeInferenceTestOp op(\"Pack\");\n  auto set_axis = [&op](int axis) {\n    int n = 3;\n    std::vector<NodeDefBuilder::NodeOut> src_list;\n    src_list.reserve(n);\n    for (int i = 0; i < n; ++i) src_list.emplace_back(\"a\", 0, DT_FLOAT);\n    TF_ASSERT_OK(NodeDefBuilder(\"test\", \"Pack\")\n                     .Input(src_list)\n                     .Attr(\"N\", n)\n                     .Attr(\"axis\", axis)\n                     .Finalize(&op.node_def));\n  };\n\n  set_axis(0);\n  INFER_OK(op, \"?;?;?\", \"?\");\n\n  for (int axis : {0, -3}) {\n    set_axis(axis);\n    INFER_OK(op, \"?;?;?\", \"?\");\n    INFER_OK(op, \"[1,3];[1,3];?\", \"[3,d0_0|d1_0,d0_1|d1_1]\");\n    INFER_OK(op, \"[?,3];[1,3];?\", \"[3,d1_0,d0_1|d1_1]\");\n    INFER_OK(op, \"[?,?];[1,3];?\", \"[3,d1_0,d1_1]\");\n  }\n  for (int axis : {1, -2}) {\n    set_axis(axis);\n    INFER_OK(op, \"?;?;?\", \"?\");\n    INFER_OK(op, \"[1,3];[1,3];?\", \"[d0_0|d1_0,3,d0_1|d1_1]\");\n    INFER_OK(op, \"[?,3];[1,3];?\", \"[d1_0,3,d0_1|d1_1]\");\n    INFER_OK(op, \"[?,?];[1,3];?\", \"[d1_0,3,d1_1]\");\n  }\n  for (int axis : {2, -1}) {\n    set_axis(axis);\n    INFER_OK(op, \"?;?;?\", \"?\");\n    INFER_OK(op, \"[1,3];[1,3];?\", \"[d0_0|d1_0,d0_1|d1_1,3]\");\n    INFER_OK(op, \"[?,3];[1,3];?\", \"[d1_0,d0_1|d1_1,3]\");\n    INFER_OK(op, \"[?,?];[1,3];?\", \"[d1_0,d1_1,3]\");\n  }\n\n  set_axis(-4);\n  INFER_ERROR(\"Invalid axis: -4; must be in [-3,3)\", op, \"[1,3];[1,3];?\");\n  set_axis(3);\n  INFER_ERROR(\"Invalid axis: 3; must be in [-3,3)\", op, \"[1,3];[1,3];?\");\n\n  set_axis(0);\n\n  // Check that both components of error message are there.\n  INFER_ERROR(\"Shapes must be equal rank, but are 3 and 2\", op,\n              \"[1,2,3];?;[1,4]\");\n  INFER_ERROR(\"From merging shape 0 with other shapes.\", op, \"[1,2,3];?;[1,4]\");\n}\n\nTEST(ArrayOpsTest, UnPack_ShapeFn) {\n  ShapeInferenceTestOp op(\"Unpack\");\n  auto set_axis_and_num = [&op](int axis, int num) {\n    TF_ASSERT_OK(NodeDefBuilder(\"test\", \"Unpack\")\n                     .Input(\"a\", 0, DT_FLOAT)\n                     .Attr(\"axis\", axis)\n                     .Attr(\"num\", num)\n                     .Finalize(&op.node_def));\n  };\n\n  set_axis_and_num(0, 1);\n  INFER_OK(op, \"?\", \"?\");\n\n  for (int axis : {0, -3}) {\n    set_axis_and_num(axis, 1);\n    INFER_OK(op, \"?\", \"?\");\n    INFER_OK(op, \"[1,2,3]\", \"[d0_1,d0_2]\");\n    INFER_OK(op, \"[?,?,?]\", \"[d0_1,d0_2]\");\n  }\n  for (int axis : {1, -2}) {\n    set_axis_and_num(axis, 2);\n    INFER_OK(op, \"[1,2,3]\", \"[d0_0,d0_2];[d0_0,d0_2]\");\n    INFER_OK(op, \"[?,?,?]\", \"[d0_0,d0_2];[d0_0,d0_2]\");\n  }\n  for (int axis : {2, -1}) {\n    set_axis_and_num(axis, 3);\n    INFER_OK(op, \"[1,2,3]\", \"[d0_0,d0_1];[d0_0,d0_1];[d0_0,d0_1]\");\n    INFER_OK(op, \"[?,?,?]\", \"[d0_0,d0_1];[d0_0,d0_1];[d0_0,d0_1]\");\n  }\n\n  set_axis_and_num(2, 2);\n  INFER_ERROR(\"Dimension must be 2 but is 3\", op, \"[1,2,3]\");\n\n  set_axis_and_num(-4, 3);\n  INFER_ERROR(\"Invalid axis: -4; must be in [-3,3)\", op, \"[1,2,3]\");\n  set_axis_and_num(3, 3);\n  INFER_ERROR(\"Invalid axis: 3; must be in [-3,3)\", op, \"[1,2,3]\");\n}\n\nTEST(ArrayOpsTest, Const_ShapeFn) {\n  ShapeInferenceTestOp op(\"Const\");\n  TensorProto tensor_proto;\n  auto* shape_proto = tensor_proto.mutable_tensor_shape();\n  auto rebuild_node_def = [&op, &tensor_proto]() {\n    TF_ASSERT_OK(NodeDefBuilder(\"test\", \"Const\")\n                     .Attr(\"value\", tensor_proto)\n                     .Finalize(&op.node_def));\n  };\n\n  TensorShape{}.AsProto(shape_proto);\n  rebuild_node_def();\n  INFER_OK(op, \"\", \"[]\");\n  TensorShape{1, 2, 3, 4}.AsProto(shape_proto);\n  rebuild_node_def();\n  INFER_OK(op, \"\", \"[1,2,3,4]\");\n\n  shape_proto->add_dim()->set_size(-1);\n  rebuild_node_def();\n  INFER_ERROR(\"Shape [1,2,3,4,?] is not fully defined\", op, \"\");\n}\n\nTEST(ArrayOpsTest, UnchangedShapes_ShapeFn) {\n  for (const char* op_name : {\n           \"CheckNumerics\",\n           \"Identity\",\n           \"RefIdentity\",\n           \"QuantizeAndDequantize\",\n           \"StopGradient\",\n           \"ZerosLike\",\n           \"OnesLike\",\n       }) {\n    ShapeInferenceTestOp op(op_name);\n    INFER_OK(op, \"?\", \"in0\");\n    INFER_OK(op, \"[]\", \"in0\");\n    INFER_OK(op, \"[1,2,?,4,5]\", \"in0\");\n  }\n\n  // inputs 1 and 2 are ignored; input 0 is transferred to output 0.\n  ShapeInferenceTestOp op(\"MatrixBandPart\");\n  INFER_OK(op, \"?;?;?\", \"in0\");\n  INFER_OK(op, \"[];?;?\", \"in0\");\n  INFER_OK(op, \"[1,2,?,4,5];?;?\", \"in0\");\n}\n\nTEST(ArrayOpsTest, GuaranteeConst_ShapeFn) {\n  ShapeInferenceTestOp op(\"GuaranteeConst\");\n  INFER_OK(op, \"?\", \"in0\");\n  INFER_OK(op, \"[]\", \"in0\");\n  INFER_OK(op, \"[1,2,?,4,5]\", \"in0\");\n}\n\nTEST(ArrayOpsTest, Identity_ShapeFnHandles) {\n  const char* op_name = \"Identity\";\n  ShapeInferenceTestOp op(op_name);\n  // Check that handle dtypes are preserved.\n  const OpRegistrationData* op_reg_data;\n  TF_ASSERT_OK(OpRegistry::Global()->LookUp(op.name, &op_reg_data));\n  std::vector<\n      std::unique_ptr<std::vector<std::pair<PartialTensorShape, DataType>>>>\n      handle_data;\n  handle_data.emplace_back(\n      new std::vector<std::pair<PartialTensorShape, DataType>>(\n          {{PartialTensorShape(), DT_BOOL}}));\n  shape_inference::InferenceContext c(\n      TF_GRAPH_DEF_VERSION, op.node_def, op_reg_data->op_def,\n      {PartialTensorShape()}, {}, {}, handle_data);\n  TF_ASSERT_OK(c.construction_status());\n  ASSERT_TRUE(op_reg_data->shape_inference_fn != nullptr);\n  TF_ASSERT_OK(c.Run(op_reg_data->shape_inference_fn));\n\n  const auto* shapes_and_types = c.output_handle_shapes_and_types(0);\n  ASSERT_TRUE(shapes_and_types != nullptr);\n  ASSERT_EQ(1, shapes_and_types->size());\n  EXPECT_EQ((*shapes_and_types)[0].dtype, DT_BOOL);\n}\n\nTEST(ArrayOpsTest, Diag_ShapeFn) {\n  ShapeInferenceTestOp op(\"Diag\");\n  INFER_OK(op, \"?\", \"?\");\n  INFER_OK(op, \"[1,?,3]\", \"[d0_0,d0_1,d0_2,d0_0,d0_1,d0_2]\");\n  INFER_OK(op, \"[?,1,2,3]\", \"[d0_0,d0_1,d0_2,d0_3,d0_0,d0_1,d0_2,d0_3]\");\n  INFER_ERROR(\"Shape must be at least rank 1 but is rank 0\", op, \"[]\");\n}\n\nTEST(ArrayOpsTest, DiagPart_ShapeFn) {\n  ShapeInferenceTestOp op(\"DiagPart\");\n  INFER_OK(op, \"?\", \"?\");\n  INFER_OK(op, \"[1,?,?,4]\", \"[d0_0,d0_3]\");\n  INFER_OK(op, \"[1,?,3,?,4,3]\", \"[d0_0,d0_4,d0_2|d0_5]\");\n  INFER_OK(op, \"[1,2,3,?,?,?,?,4]\", \"[d0_0,d0_1,d0_2,d0_7]\");\n  INFER_ERROR(\"Input must have even and non-zero rank\", op, \"[]\");\n  INFER_ERROR(\"Input must have even and non-zero rank\", op, \"[?]\");\n  INFER_ERROR(\"Input must have even and non-zero rank\", op, \"[1,2,3]\");\n  INFER_ERROR(\"Dimensions must be equal, but are 2 and 10\", op, \"[1,2,?,10]\");\n}\n\nTEST(ArrayOpsTest, MatrixDiag_ShapeFn) {\n  ShapeInferenceTestOp op(\"MatrixDiag\");\n  INFER_OK(op, \"?\", \"?\");\n  INFER_ERROR(\"Shape must be at least rank 1 but is rank 0\", op, \"[]\");\n  INFER_OK(op, \"[?]\", \"[d0_0,d0_0]\");\n  INFER_OK(op, \"[1,?,?,4]\", \"[d0_0,d0_1,d0_2,d0_3,d0_3]\");\n}\n\nTEST(ArrayOpsTest, MatrixDiagPart_ShapeFn) {\n  ShapeInferenceTestOp op(\"MatrixDiagPart\");\n  INFER_OK(op, \"?\", \"?\");\n  INFER_ERROR(\"Shape must be at least rank 2 but is rank 1\", op, \"[?]\");\n  INFER_OK(op, \"[?,1,2,2]\", \"[d0_0,d0_1,d0_2|d0_3]\");\n  INFER_OK(op, \"[?,1,2,3]\", \"[d0_0,d0_1,d0_2]\");\n  INFER_OK(op, \"[?,1,3,2]\", \"[d0_0,d0_1,d0_3]\");\n}\n\nTEST(ArrayOpsTest, Reverse_ShapeFn) {\n  ShapeInferenceTestOp op(\"Reverse\");\n  INFER_OK(op, \"?;?\", \"in0\");\n  INFER_ERROR(\"Shape must be rank 1 but is rank 0\", op, \"?;[]\");\n  INFER_ERROR(\"Shape must be rank 1 but is rank 2\", op, \"?;[?,2]\");\n  INFER_ERROR(\"Shape must be rank 4 but is rank 3\", op, \"[1,2,3];[4]\");\n  INFER_ERROR(\"reverse does not work on tensors with more than 8 dimensions\",\n              op, \"[1,2,3,4,5,6,7,8,9];[9]\");\n  INFER_OK(op, \"[1,2,3,?];[4]\", \"in0\");\n  INFER_OK(op, \"[1,2,3,?,5,6,7,8];[8]\", \"in0\");\n}\n\nTEST(ArrayOpsTest, ReverseV2_ShapeFn) {\n  ShapeInferenceTestOp op(\"ReverseV2\");\n  INFER_OK(op, \"?;?\", \"in0\");\n  INFER_ERROR(\"Shape must be rank 1 but is rank 0\", op, \"?;[]\");\n  INFER_ERROR(\"Shape must be rank 1 but is rank 2\", op, \"?;[?,2]\");\n  INFER_OK(op, \"[1,2,3];[2]\", \"in0\");\n  INFER_ERROR(\"reverse does not work on tensors with more than 8 dimensions\",\n              op, \"[1,2,3,4,5,6,7,8,9];[9]\");\n  INFER_OK(op, \"[1,2,3,?];[4]\", \"in0\");\n  INFER_OK(op, \"[1,2,3,?,5,6,7,8];[8]\", \"in0\");\n}\n\nTEST(ArrayOpsTest, Fill_ShapeFn) {\n  ShapeInferenceTestOp op(\"Fill\");\n  AddNodeAttr(\"index_type\", DT_INT32, &op.node_def);\n  op.input_tensors.resize(2);\n  INFER_OK(op, \"?;?\", \"?\");\n  INFER_OK(op, \"[?];?\", \"?\");\n  INFER_OK(op, \"[4];?\", \"[?,?,?,?]\");\n\n  Tensor in_t = test::AsTensor<int32>({1, 2, 3, 4});\n  op.input_tensors[0] = &in_t;\n  INFER_OK(op, \"[4];?\", \"[1,2,3,4]\");\n}\n\nTEST(ArrayOpsTest, Gather_ShapeFn) {\n  ShapeInferenceTestOp op(\"Gather\");\n  INFER_OK(op, \"?;?\", \"?\");\n  INFER_OK(op, \"[1,?,2];[3]\", \"[d1_0,d0_1,d0_2]\");\n  INFER_ERROR(\"Shape must be at least rank 1 but is rank 0\", op, \"[];[1,2,3]\");\n}\n\nTEST(ArrayOpsTest, GatherV2_ShapeFn) {\n  ShapeInferenceTestOp op(\"GatherV2\");\n  AddNodeAttr(\"batch_dims\", 0, &op.node_def);\n\n  // Tests when axis is unknown.\n  INFER_OK(op, \"?;?;?\", \"?\");\n  INFER_OK(op, \"[1,2,3];[3];[]\", \"[?,?,?]\");\n  INFER_ERROR(\"Shape must be at least rank 1 but is rank 0\", op,\n              \"[];[1,2,3];[]\");\n\n  // Non-scalar axis.\n  INFER_ERROR(\"Shape must be rank 0 but is rank 1\", op, \"[1];[1,2,3];[1]\");\n\n  // Test when axis dim is known.\n  Tensor axis_dim_t;\n  op.input_tensors.resize(3);\n  op.input_tensors[2] = &axis_dim_t;\n\n  // Out of range axis.\n  axis_dim_t = test::AsScalar(1);\n  INFER_ERROR(\"Shape must be at least rank 2 but is rank 1\", op,\n              \"[1];[1,2];[]\");\n\n  // Rank 0 indices.\n  axis_dim_t = test::AsScalar(0);\n  INFER_OK(op, \"[1,2,3];[];[]\", \"[d0_1,d0_2]\");\n  axis_dim_t = test::AsScalar(1);\n  INFER_OK(op, \"[1,2,3];[];[]\", \"[d0_0,d0_2]\");\n  axis_dim_t = test::AsScalar(2);\n  INFER_OK(op, \"[1,2,3];[];[]\", \"[d0_0,d0_1]\");\n\n  // Rank 1 indices.\n  axis_dim_t = test::AsScalar(0);\n  INFER_OK(op, \"[1,2,3];[5];[]\", \"[d1_0,d0_1,d0_2]\");\n  axis_dim_t = test::AsScalar(1);\n  INFER_OK(op, \"[1,2,3];[5];[]\", \"[d0_0,d1_0,d0_2]\");\n  axis_dim_t = test::AsScalar(2);\n  INFER_OK(op, \"[1,2,3];[5];[]\", \"[d0_0,d0_1,d1_0]\");\n\n  // Rank 2 indices.\n  axis_dim_t = test::AsScalar(0);\n  INFER_OK(op, \"[1,2,3];[5,6];[]\", \"[d1_0,d1_1,d0_1,d0_2]\");\n  axis_dim_t = test::AsScalar(1);\n  INFER_OK(op, \"[1,2,3];[5,6];[]\", \"[d0_0,d1_0,d1_1,d0_2]\");\n  axis_dim_t = test::AsScalar(2);\n  INFER_OK(op, \"[1,2,3];[5,6];[]\", \"[d0_0,d0_1,d1_0,d1_1]\");\n\n  // Negative axis.\n  axis_dim_t = test::AsScalar(-3);\n  INFER_OK(op, \"[1,2,3];[5,6];[]\", \"[d1_0,d1_1,d0_1,d0_2]\");\n  axis_dim_t = test::AsScalar(-2);\n  INFER_OK(op, \"[1,2,3];[5,6];[]\", \"[d0_0,d1_0,d1_1,d0_2]\");\n  axis_dim_t = test::AsScalar(-1);\n  INFER_OK(op, \"[1,2,3];[5,6];[]\", \"[d0_0,d0_1,d1_0,d1_1]\");\n\n  // Batch dimensions > 0\n  // Create another node since we can't overwrite the original batch dims.\n  ShapeInferenceTestOp batch_op(\"GatherV2\");\n  AddNodeAttr(\"batch_dims\", 1, &batch_op.node_def);\n  INFER_OK(batch_op, \"[1,4800,8];[1,28400];[]\", \"[?,?,?]\");\n\n  ShapeInferenceTestOp batch_op_2(\"GatherV2\");\n  AddNodeAttr(\"batch_dims\", 2, &batch_op_2.node_def);\n  INFER_OK(batch_op_2, \"[1,2,3,4,5];[1,2,3];[]\", \"[?,?,?,?,?]\");\n}\n\nTEST(ArrayOpsTest, GatherNd_ShapeFn) {\n  ShapeInferenceTestOp op(\"GatherNd\");\n\n  // Inputs are (params, indices).\n  INFER_OK(op, \"?;?\", \"?\");\n  INFER_OK(op, \"[1,?,3,?];[?,0]\", \"[d1_0,d0_0,d0_1,d0_2,d0_3]\");\n  INFER_OK(op, \"[1,?,3,?];[?,4]\", \"[d1_0]\");\n\n  // params.rank >= indices.dim(-1).\n  INFER_ERROR(\"indices.shape[-1] must be <= params.rank\", op, \"[1,2,3];[4]\");\n}\n\nTEST(ArrayOpsTest, Shape_ShapeFn) {\n  ShapeInferenceTestOp op(\"Shape\");\n  INFER_OK(op, \"?\", \"[?]\");\n  INFER_OK(op, \"[?]\", \"[1]\");\n  INFER_OK(op, \"[?,2,3,4,5]\", \"[5]\");\n}\n\nTEST(ArrayOpsTest, ShapeN_ShapeFn) {\n  ShapeInferenceTestOp op(\"ShapeN\");\n  int n = 3;\n  std::vector<NodeDefBuilder::NodeOut> src_list;\n  src_list.reserve(n);\n  for (int i = 0; i < n; ++i) src_list.emplace_back(\"a\", 0, DT_FLOAT);\n  TF_ASSERT_OK(NodeDefBuilder(\"test\", \"ShapeN\")\n                   .Input(src_list)\n                   .Attr(\"N\", n)\n                   .Finalize(&op.node_def));\n  INFER_OK(op, \"?;?;?\", \"[?];[?];[?]\");\n  INFER_OK(op, \"[?];[?];[?]\", \"[1];[1];[1]\");\n  INFER_OK(op, \"[?,2,3,4,5];?;[1,?,3]\", \"[5];[?];[3]\");\n}\n\nTEST(ArrayOpsTest, Unique_ShapeFn) {\n  ShapeInferenceTestOp op(\"Unique\");\n  INFER_OK(op, \"?\", \"[?];in0\");\n  INFER_OK(op, \"[5]\", \"[?];in0\");\n  INFER_ERROR(\"Shape must be rank 1 but is rank 5\", op, \"[1,2,3,?,5]\");\n}\n\nTEST(ArrayOpsTest, UniqueWithCounts_ShapeFn) {\n  ShapeInferenceTestOp op(\"UniqueWithCounts\");\n  INFER_OK(op, \"?\", \"[?];in0;[?]\");\n  INFER_OK(op, \"[1,2,3,?,5]\", \"[?];in0;[?]\");\n}\n\nTEST(ArrayOpsTest, InvertPermutation_ShapeFn) {\n  ShapeInferenceTestOp op(\"InvertPermutation\");\n  INFER_OK(op, \"?\", \"[?]\");\n  INFER_OK(op, \"[1]\", \"in0\");\n  INFER_ERROR(\"Shape must be rank 1 but is rank 0\", op, \"[]\");\n}\n\nTEST(ArrayOpsTest, PadD_ShapeFn) {\n  for (const char* op_name : {\"Pad\", \"MirrorPad\"}) {\n    ShapeInferenceTestOp op(op_name);\n    op.input_tensors.resize(2);\n\n    // Inputs are input and paddings.\n\n    INFER_OK(op, \"?;?\", \"?\");\n\n    // Check shape of paddings.\n    INFER_ERROR(\"Shape must be rank 2 but is rank 3\", op, \"?;[1,2,3]\");\n    INFER_ERROR(\"Dimension must be 2 but is 4\", op, \"?;[1,4]\");\n\n    // input.rank and paddings.dim(0) are equal. This is the number of dims in\n    // output.\n    INFER_ERROR(\"Shape must be rank 4 but is rank 3\", op, \"[1,2,3];[4,2]\");\n    INFER_OK(op, \"[1,2,3];?\", \"[?,?,?]\");\n    INFER_OK(op, \"?;[3,2]\", \"[?,?,?]\");\n\n    // Make the paddings tensor known and verify padding values get added.\n    // E.g., if padding is ((1,10),(2,20),(3,30)) then values 11,22,23 are added\n    // to input dims to get output.\n    Tensor paddings_t(DT_INT64, TensorShape{3, 2});\n    test::FillValues<int64_t>(&paddings_t, {1, 10, 2, 20, 3, 30});\n    op.input_tensors[1] = &paddings_t;\n    INFER_OK(op, \"[100,200,300];[3,2]\", \"[111,222,333]\");\n    INFER_OK(op, \"[100,?,300];[3,2]\", \"[111,?,333]\");\n    INFER_OK(op, \"?;[3,2]\", \"[?,?,?]\");\n    INFER_OK(op, \"?;?\", \"[?,?,?]\");\n  }\n}\n\nTEST(ArrayOpsTest, PadV2_ShapeFn) {\n  ShapeInferenceTestOp op(\"PadV2\");\n  op.input_tensors.resize(3);\n\n  // Inputs are input, paddings and constant_values.\n\n  INFER_OK(op, \"?;?;?\", \"?\");\n\n  // Check shape of paddings.\n  INFER_ERROR(\"Shape must be rank 2 but is rank 3\", op, \"?;[1,2,3];?\");\n  INFER_ERROR(\"Dimension must be 2 but is 4\", op, \"?;[1,4];?\");\n\n  // input.rank and paddings.dim(0) are equal. This is the number of dims in\n  // output.\n  INFER_ERROR(\"Shape must be rank 4 but is rank 3\", op, \"[1,2,3];[4,2];[]\");\n  INFER_OK(op, \"[1,2,3];?;[]\", \"[?,?,?]\");\n  INFER_OK(op, \"?;[3,2];[]\", \"[?,?,?]\");\n\n  // Make the paddings tensor known and verify padding values get added.\n  // E.g., if padding is ((1,10),(2,20),(3,30)) then values 11,22,23 are added\n  // to input dims to get output.\n  Tensor paddings_t(DT_INT64, TensorShape{3, 2});\n  test::FillValues<int64_t>(&paddings_t, {1, 10, 2, 20, 3, 30});\n  op.input_tensors[1] = &paddings_t;\n  INFER_OK(op, \"[100,200,300];[3,2];[]\", \"[111,222,333]\");\n  INFER_OK(op, \"[100,?,300];[3,2];[]\", \"[111,?,333]\");\n  INFER_OK(op, \"?;[3,2];[]\", \"[?,?,?]\");\n  INFER_OK(op, \"?;?;[]\", \"[?,?,?]\");\n}\n\nTEST(ArrayOpsTest, MirrorPadGrad_ShapeFn) {\n  ShapeInferenceTestOp op(\"MirrorPadGrad\");\n  op.input_tensors.resize(2);\n\n  // Inputs are input and paddings.\n  INFER_OK(op, \"?;?\", \"?\");\n\n  // First padding dimension is unknown, so rank is unknown.\n  INFER_OK(op, \"?;[?,4]\", \"?\");\n\n  // Input tensor rank doesn't match paddings dimension.\n  INFER_ERROR(\"must be rank 3 but is rank 2\", op, \"[?,?];[3,2]\");\n\n  // Paddings tensor is not a [rank x 2] matrix.\n  INFER_ERROR(\"Dimension 1 in both shapes must be equal, but are 3 and 2\", op,\n              \"[?,?,?];[3,3]\");\n\n  // Paddings tensor is unknown, but rank is known, so the output\n  // shape is a rank 3 unknown shape.\n  INFER_OK(op, \"[?,?,?];[3,2]\", \"[?,?,?]\");\n\n  // Make the paddings tensor known and verify padding values get\n  // subtracted.  E.g., if padding is ((1,10),(2,20),(3,30)) then\n  // values 11,22,23 are subtracted to input dims to get output.\n  Tensor paddings_t(DT_INT64, TensorShape{3, 2});\n  test::FillValues<int64_t>(&paddings_t, {1, 10, 2, 20, 3, 30});\n  op.input_tensors[1] = &paddings_t;\n\n  INFER_OK(op, \"[111,222,333];[3,2]\", \"[100,200,300]\");\n  INFER_OK(op, \"[111,?,333];[3,2]\", \"[100,?,300]\");\n}\n\nTEST(ArrayOpsTest, BroadcastArgs_ShapeFn) {\n  ShapeInferenceTestOp op(\"BroadcastArgs\");\n  INFER_OK(op, \"?;?\", \"[?]\");\n  INFER_OK(op, \"[123];[1]\", \"[123]\");\n  INFER_OK(op, \"[1];[123]\", \"[123]\");\n  INFER_OK(op, \"[123];[121]\", \"[123]\");\n\n  // Rank checks\n  INFER_ERROR(\"Shape must be rank 1 but is rank 0\", op, \"[];?\");\n  INFER_ERROR(\"Shape must be rank 1 but is rank 0\", op, \"?;[]\");\n}\n\nTEST(ArrayOpsTest, BroadcastTo_ShapeFn) {\n  ShapeInferenceTestOp op(\"BroadcastTo\");\n  op.input_tensors.resize(2);\n\n  INFER_OK(op, \"?;[?]\", \"?\");\n  INFER_OK(op, \"[];[1]\", \"[?]\");\n  INFER_OK(op, \"[1];[1]\", \"[?]\");\n  INFER_OK(op, \"[1];[2]\", \"[?,?]\");\n  INFER_OK(op, \"[2,2];[3]\", \"[?,d0_0,d0_1]\");\n\n  // Rank checks\n  INFER_ERROR(\"Shape must be rank 1 but is rank 2\", op, \"?;[?,?]\");\n  INFER_ERROR(\"Shape must be rank 1 but is rank 0\", op, \"[2];[]\");\n  INFER_ERROR(\"Shape must be at most rank 1 but is rank 2\", op, \"[2,2];[1]\");\n\n  Tensor shape_t(DT_INT64, TensorShape{3});\n  test::FillValues<int64_t>(&shape_t, {2, 10, 3});\n  op.input_tensors[1] = &shape_t;\n  INFER_OK(op, \"[1,?,1];[3]\", \"[2,10,3]\");\n  INFER_OK(op, \"[1,1,1];[3]\", \"[2,10,3]\");\n  INFER_OK(op, \"[10,1];[3]\", \"[2,d0_0,3]\");\n  INFER_ERROR(\"Dimensions must be equal, but are 3 and 2 for\", op,\n              \"[3,1,1];[3]\");\n  INFER_ERROR(\"Dimensions must be equal, but are 2 and 10 for\", op,\n              \"[2,2,1];[3]\");\n}\n\nTEST(ArrayOpsTest, BroadcastGradientArgs_ShapeFn) {\n  ShapeInferenceTestOp op(\"BroadcastGradientArgs\");\n  // Output is always two unknown vectors.\n  INFER_OK(op, \"?;?\", \"[?];[?]\");\n  INFER_OK(op, \"[123];[456]\", \"[?];[?]\");\n\n  // Rank checks\n  INFER_ERROR(\"Shape must be rank 1 but is rank 0\", op, \"[];?\");\n  INFER_ERROR(\"Shape must be rank 1 but is rank 0\", op, \"?;[]\");\n}\n\nTEST(ArrayOpsTest, ListDiff_ShapeFn) {\n  ShapeInferenceTestOp op(\"BroadcastGradientArgs\");\n  // Output is always two matching unknown vectors.\n  INFER_OK(op, \"?;?\", \"[?];[?]\");\n  INFER_OK(op, \"[123];[456]\", \"[?];[?]\");\n\n  // Rank checks\n  INFER_ERROR(\"Shape must be rank 1 but is rank 0\", op, \"[];?\");\n  INFER_ERROR(\"Shape must be rank 1 but is rank 0\", op, \"?;[]\");\n}\n\nTEST(ArrayOpsTest, MatrixSetDiag_ShapeFn) {\n  ShapeInferenceTestOp op(\"MatrixSetDiag\");\n\n  // Inputs are input and diagonal.\n\n  // Rank checks.\n  INFER_ERROR(\"Shape must be at least rank 2 but is rank 1\", op, \"[1];?\");\n  INFER_ERROR(\"Shape must be at least rank 1 but is rank 0\", op, \"?;[]\");\n  INFER_ERROR(\"Shape must be at least rank 1 but is rank 0\", op, \"[2,2];[]\");\n  INFER_ERROR(\"Shape must be rank 1 but is rank 2\", op, \"[2,2];[2,2]\");\n\n  // diagonal[-1] must match smallest matrix dimension.\n  INFER_ERROR(\"Dimensions must be equal, but are 2 and 3\", op, \"[2,3];[3]\");\n\n  // Output matches input.\n  INFER_OK(op, \"?;?\", \"in0\");\n  INFER_OK(op, \"[1,2,2];[1,2]\", \"in0\");\n  INFER_OK(op, \"[1,2,3];?\", \"in0\");\n  INFER_OK(op, \"[1,3,2];?\", \"in0\");\n  INFER_OK(op, \"[1,?,2];[?,?]\", \"in0\");\n  INFER_OK(op, \"[1,?,?];[?,2]\", \"in0\");\n\n  // Infer batch shape from diag when input is not fully specified.\n  INFER_OK(op, \"?;[1,2]\", \"[d1_0,?,?]\");\n  INFER_OK(op, \"[?,?,3];[1,2]\", \"[d1_0,d0_1,d0_2]\");\n  INFER_OK(op, \"[?,3,?];[1,2]\", \"[d1_0,d0_1,d0_2]\");\n  INFER_OK(op, \"[?,3,2];[1,2]\", \"[d1_0,d0_1,d0_2]\");\n}\n\nTEST(ArrayOpsTest, ExpandDims_ShapeFn) {\n  ShapeInferenceTestOp op(\"ExpandDims\");\n  op.input_tensors.resize(2);\n\n  // With unknown dim tensor value, output is unknown.\n  INFER_OK(op, \"?;?\", \"?\");\n  Tensor dim_t;\n  op.input_tensors[1] = &dim_t;\n\n  // Expand at front of tensor.\n  for (int32_t idx : {0, -4}) {\n    dim_t = test::AsScalar<int32>(idx);\n    INFER_OK(op, \"?;?\", \"?\");\n    INFER_OK(op, \"[5,?,7];?\", \"[1,d0_0,d0_1,d0_2]\");\n  }\n\n  // Expand at middle of tensor.\n  for (int32_t idx : {1, -3}) {\n    dim_t = test::AsScalar<int32>(idx);\n    INFER_OK(op, \"?;?\", \"?\");\n    INFER_OK(op, \"[5,?,7];?\", \"[d0_0,1,d0_1,d0_2]\");\n\n    // Repeat with int64.\n    dim_t = test::AsScalar<int64_t>(idx);\n    INFER_OK(op, \"?;?\", \"?\");\n    INFER_OK(op, \"[5,?,7];?\", \"[d0_0,1,d0_1,d0_2]\");\n  }\n  for (int32_t idx : {2, -2}) {\n    dim_t = test::AsScalar<int32>(idx);\n    INFER_OK(op, \"?;?\", \"?\");\n    INFER_OK(op, \"[5,?,7];?\", \"[d0_0,d0_1,1,d0_2]\");\n\n    // Repeat with int64.\n    dim_t = test::AsScalar<int64_t>(idx);\n    INFER_OK(op, \"?;?\", \"?\");\n    INFER_OK(op, \"[5,?,7];?\", \"[d0_0,d0_1,1,d0_2]\");\n  }\n\n  for (int32_t idx : {3, -1}) {\n    // Expand at the end.\n    dim_t = test::AsScalar<int32>(idx);\n    INFER_OK(op, \"?;?\", \"?\");\n    INFER_OK(op, \"[5,?,7];?\", \"[d0_0,d0_1,d0_2,1]\");\n\n    // Repeat with int64.\n    dim_t = test::AsScalar<int64_t>(idx);\n    INFER_OK(op, \"?;?\", \"?\");\n    INFER_OK(op, \"[5,?,7];?\", \"[d0_0,d0_1,d0_2,1]\");\n  }\n  for (int32_t idx : {4, -5}) {\n    // Invalid idx.\n    dim_t = test::AsScalar<int32>(idx);\n    INFER_ERROR(\"not in the interval [-4, 3]\", op, \"[5,?,7];?\");\n    dim_t = test::AsScalar<int64_t>(idx);\n    INFER_ERROR(\"not in the interval [-4, 3]\", op, \"[5,?,7];?\");\n  }\n\n  // Expand using an input vector tensor.\n  std::vector<int32> dims;\n  dims.push_back(0);\n  dim_t = test::AsTensor<int32>(dims);\n  INFER_OK(op, \"?;?\", \"?\");\n  INFER_OK(op, \"[5,?,7];?\", \"[1,d0_0,d0_1,d0_2]\");\n\n  // Expand using too many input elements.\n  dims.push_back(1);\n  dim_t = test::AsTensor<int32>(dims);\n  INFER_ERROR(\"'dim' input must be a tensor with a single\", op, \"?;?\");\n  INFER_ERROR(\"'dim' input must be a tensor with a single\", op, \"[5,6,7];?\");\n\n  // Examples from ExpandDims doc.\n  dim_t = test::AsScalar<int32>(0);\n  INFER_OK(op, \"[2];[]\", \"[1,d0_0]\");\n  dim_t = test::AsScalar<int32>(1);\n  INFER_OK(op, \"[2];[]\", \"[d0_0,1]\");\n  dim_t = test::AsScalar<int32>(-1);\n  INFER_OK(op, \"[2];[]\", \"[d0_0,1]\");\n}\n\nTEST(ArrayOpsTest, ImmutableConst_ShapeFn) {\n  ShapeInferenceTestOp op(\"ImmutableConst\");\n\n  TF_ASSERT_OK(NodeDefBuilder(\"test\", \"ImmutableConst\")\n                   .Attr(\"dtype\", DT_FLOAT)\n                   .Attr(\"shape\", TensorShape({1, 2, 3}))\n                   .Attr(\"memory_region_name\", \"test_region\")\n                   .Finalize(&op.node_def));\n  INFER_OK(op, \"\", \"[1,2,3]\");\n\n  TF_ASSERT_OK(NodeDefBuilder(\"test\", \"ImmutableConst\")\n                   .Attr(\"dtype\", DT_FLOAT)\n                   .Attr(\"shape\", TensorShape({}))\n                   .Attr(\"memory_region_name\", \"test_region\")\n                   .Finalize(&op.node_def));\n  INFER_OK(op, \"\", \"[]\");\n\n  TF_ASSERT_OK(NodeDefBuilder(\"test\", \"ImmutableConst\")\n                   .Attr(\"dtype\", DT_FLOAT)\n                   .Attr(\"shape\", \"invalid\")\n                   .Attr(\"memory_region_name\", \"test_region\")\n                   .Finalize(&op.node_def));\n  INFER_ERROR(\"AttrValue had value with type 'string' when 'shape' expected\",\n              op, \"\");\n}\n\nTEST(ArrayOpsTest, Concat_ShapeFn) {\n  ShapeInferenceTestOp op(\"Concat\");\n  auto set_n = [&op](int n) {\n    std::vector<NodeDefBuilder::NodeOut> src_list;\n    src_list.reserve(n);\n    for (int i = 0; i < n; ++i) src_list.emplace_back(\"a\", 0, DT_FLOAT);\n    TF_ASSERT_OK(NodeDefBuilder(\"test\", \"Concat\")\n                     .Input({\"concat_dim\", 0, DT_INT32})\n                     .Input(src_list)\n                     .Attr(\"n\", n)\n                     .Finalize(&op.node_def));\n  };\n\n  // Confirm dimension[0] of the input (the concat_dim) is a scalar.\n  set_n(2);\n  INFER_ERROR(\"Shape must be rank 0 but is rank 1\", op, \"[1];?;?\");\n\n  // Test with the input concat_dim tensor not known. This takes the known rank\n  // of the inputs and makes a tensor of that many unknown dims.\n  set_n(7);\n  INFER_OK(op, \"?;?;?;?;[1,2,3];?;[3,2,1];?\", \"[?,?,?]\");\n  set_n(4);\n  INFER_OK(op, \"?;?;?;[1,2,3,4];[4,3,2,1]\", \"[?,?,?,?]\");\n  INFER_OK(op, \"?;?;?;?;?\", \"?\");  // output rank unknown\n  INFER_ERROR(\"Can't concatenate scalars (use tf.stack instead)\", op,\n              \"?;?;?;[];[]\");\n  INFER_ERROR(\"Shape must be rank 2 but is rank 3\", op, \"?;?;?;[1,2];[1,2,3]\");\n\n  // Test when the concat_dim tensor is known. The concatenated dimension is\n  // summed across all input tensors, and other dimensions are merged.\n  Tensor concat_dim_t;\n  op.input_tensors.push_back(&concat_dim_t);\n  set_n(2);\n\n  // Sum dim 0, merge the other two dims.\n  for (int concat_dim : {0, -3}) {\n    concat_dim_t = test::AsScalar(concat_dim);\n    INFER_OK(op, \"[];[100,2,?];[10,?,3]\", \"[110,d1_1,d2_2]\");\n    INFER_ERROR(\"Dimension 1 in both shapes must be equal, but are 5 and 3\", op,\n                \"[];[100,2,5];[10,?,3]\");\n    // concat_dim can't be summed, as one value is unknown.\n    INFER_OK(op, \"[];[100,2,?];[?,?,3]\", \"[?,d1_1,d2_2]\");\n    INFER_OK(op, \"[];[?,2,?];[10,?,3]\", \"[?,d1_1,d2_2]\");\n  }\n\n  // Test with a higher concat_dim.\n  for (bool use_negative : {false, true}) {\n    concat_dim_t = test::AsScalar(use_negative ? -2 : 1);\n    INFER_OK(op, \"[];[1,100,?];[?,10,3]\", \"[d1_0,110,d2_2]\");\n    concat_dim_t = test::AsScalar(use_negative ? -1 : 1);\n    INFER_OK(op, \"[];[1,100];[?,10]\", \"[d1_0,110]\");\n    INFER_OK(op, \"[];[?,100];[1,10]\", \"[d2_0,110]\");\n\n    // concat_dim is out of bounds.\n    concat_dim_t = test::AsScalar(use_negative ? -2 : 1);\n    INFER_ERROR(\"Shape must be at least rank 2 but is rank 1\", op,\n                \"[];[100];[10,?]\");\n    INFER_ERROR(\"Shape must be at least rank 2 but is rank 1\", op,\n                \"[];[100,5];[10]\");\n  }\n\n  // concat_dim is too low.\n  concat_dim_t = test::AsScalar(-2);\n  INFER_ERROR(\"Shape must be at least rank 2 but is rank 1\", op,\n              \"[];[100];[10,?]\");\n  INFER_ERROR(\"Shape must be at least rank 2 but is rank 1\", op,\n              \"[];[100,5];[10]\");\n\n  // Repeat successful case with several unknown inputs.\n  set_n(5);\n  concat_dim_t = test::AsScalar(1);\n  INFER_OK(op, \"[];?;[1,100,?];[?,?,?];[?,10,3];?\", \"[d2_0,?,d4_2]\");\n}\n\nTEST(ArrayOpsTest, ConcatV2_ShapeFn) {\n  ShapeInferenceTestOp op(\"ConcatV2\");\n  auto set_n = [&op](int n) {\n    std::vector<NodeDefBuilder::NodeOut> src_list;\n    src_list.reserve(n);\n    for (int i = 0; i < n; ++i) src_list.emplace_back(\"a\", 0, DT_FLOAT);\n    TF_ASSERT_OK(NodeDefBuilder(\"test\", \"ConcatV2\")\n                     .Input(src_list)\n                     .Input({\"axis\", 0, DT_INT32})\n                     .Attr(\"n\", n)\n                     .Finalize(&op.node_def));\n  };\n\n  // Confirm dimension[0] of the input (the concat_dim) is a scalar.\n  set_n(2);\n  INFER_ERROR(\"Shape must be rank 0 but is rank 1\", op, \"?;?;[1]\");\n\n  // Test with the input concat_dim tensor not known. This takes the known rank\n  // of the inputs and makes a tensor of that many unknown dims.\n  set_n(7);\n  INFER_OK(op, \"?;?;?;?;[1,2,3];?;[3,2,1];?\", \"[?,?,?]\");\n  set_n(4);\n  INFER_OK(op, \"?;?;[1,2,3,4];[4,3,2,1];?\", \"[?,?,?,?]\");\n  INFER_OK(op, \"?;?;?;?;?\", \"?\");  // output rank unknown\n  INFER_ERROR(\"Can't concatenate scalars (use tf.stack instead)\", op,\n              \"?;?;[];[];?\");\n  INFER_ERROR(\"Shape must be rank 2 but is rank 3\", op, \"?;?;[1,2];[1,2,3];?\");\n\n  // Test when the concat_dim tensor is known. The concatenated dimension is\n  // summed across all input tensors, and other dimensions are merged.\n  Tensor concat_dim_t;\n  op.input_tensors.resize(3);\n  op.input_tensors[2] = &concat_dim_t;\n\n  set_n(2);\n\n  // Invalid concat dim value.\n  // concat_dim_t = test::AsScalar(-1);\n  // INFER_ERROR(\"Expected concat_dim >= 0, but got -1\", op, \"?;?;?\");\n\n  // Sum dim 0, merge the other two dims.\n  concat_dim_t = test::AsScalar(0);\n  INFER_OK(op, \"[100,2,?];[10,?,3];[]\", \"[110,d0_1,d1_2]\");\n  INFER_ERROR(\"Dimension 1 in both shapes must be equal, but are 5 and 3\", op,\n              \"[100,2,5];[10,?,3];[]\");\n  // concat_dim can't be summed, as one value is unknown.\n  INFER_OK(op, \"[100,2,?];[?,?,3];[]\", \"[?,d0_1,d1_2]\");\n  INFER_OK(op, \"[?,2,?];[10,?,3];[]\", \"[?,d0_1,d1_2]\");\n\n  // Test with a higher concat_dim.\n  concat_dim_t = test::AsScalar(1);\n  INFER_OK(op, \"[1,100,?];[?,10,3];[]\", \"[d0_0,110,d1_2]\");\n  INFER_OK(op, \"[1,100];[?,10];[]\", \"[d0_0,110]\");\n  INFER_OK(op, \"[?,100];[1,10];[]\", \"[d1_0,110]\");\n  // concat_dim is too high.\n  INFER_ERROR(\"Shape must be at least rank 2 but is rank 1\", op,\n              \"[100];[10,?];[]\");\n  INFER_ERROR(\"Shape must be at least rank 2 but is rank 1\", op,\n              \"[100,5];[10];[]\");\n  // concat_dim is too low.\n  concat_dim_t = test::AsScalar(-2);\n  INFER_ERROR(\"Shape must be at least rank 2 but is rank 1\", op,\n              \"[100];[10,?];[]\");\n  INFER_ERROR(\"Shape must be at least rank 2 but is rank 1\", op,\n              \"[100,5];[10];[]\");\n\n  // Repeat successful case with several unknown inputs.\n  op.input_tensors.resize(6);\n  op.input_tensors[3] = nullptr;\n  op.input_tensors[5] = &concat_dim_t;\n  concat_dim_t = test::AsScalar(1);\n\n  set_n(5);\n  INFER_OK(op, \"?;[1,100,?];[?,?,?];[?,10,3];?;[]\", \"[d1_0,?,d3_2]\");\n}\n\nTEST(ArrayOpsTest, ConcatOffset_ShapeFn) {\n  ShapeInferenceTestOp op(\"ConcatOffset\");\n\n  const int n = 4;\n  std::vector<NodeDefBuilder::NodeOut> src_list;\n  src_list.reserve(n);\n  for (int i = 0; i < n; ++i) src_list.emplace_back(\"a\", 0, DT_INT32);\n  TF_ASSERT_OK(NodeDefBuilder(\"test\", \"ConcatOffset\")\n                   .Input({\"concat_dim\", 0, DT_INT32})\n                   .Input(src_list)\n                   .Attr(\"n\", n)\n                   .Finalize(&op.node_def));\n  INFER_OK(op, \"?;?;?;?;?\", \"in1;in2;in3;in4\");\n}\n\nTEST(ArrayOpsTest, Reshape_ShapeFn) {\n  ShapeInferenceTestOp op(\"Reshape\");\n  op.input_tensors.resize(2);\n\n  // No valid shape provided.\n  INFER_OK(op, \"?;?\", \"?\");\n  INFER_OK(op, \"[?];?\", \"?\");\n  INFER_OK(op, \"?;[?]\", \"?\");\n  INFER_OK(op, \"[?];[?]\", \"?\");\n  INFER_OK(op, \"[4];[?]\", \"?\");\n\n  // All dimensions provided.\n  Tensor new_shape = test::AsTensor<int32>({1, 2, 3});\n  op.input_tensors[1] = &new_shape;\n  INFER_OK(op, \"?;[3]\", \"[1,2,3]\");\n  INFER_OK(op, \"[?];[3]\", \"[1,2,3]\");\n  INFER_OK(op, \"[6];[3]\", \"[1,2,3]\");\n  // The number of elements should match for the reshape to succeed.\n  INFER_ERROR(\n      \"Cannot reshape a tensor with 12 elements to shape [1,2,3] (6 elements)\",\n      op, \"[3,4];[3]\");\n\n  // Unknown dimensions.\n  // Flatten:\n  new_shape = test::AsTensor<int32>({-1});\n  INFER_OK(op, \"?;[1]\", \"[?]\");\n  INFER_OK(op, \"[?];[1]\", \"[d0_0]\");\n  INFER_OK(op, \"[2,2];[1]\", \"[4]\");\n  // The first dimension is inferred:\n  new_shape = test::AsTensor<int32>({2, -1});\n  INFER_OK(op, \"[3,4];[2]\", \"[2,6]\");\n  // The total number of elements must be evenly divisible by the known\n  // dimensions.\n  INFER_ERROR(\"Dimension size must be evenly divisible by 2 but is 7\", op,\n              \"[7];[2]\");\n  // Multiple missing dimensions cannot be inferred.\n  new_shape = test::AsTensor<int32>({-1, -1, 2});\n  INFER_OK(op, \"[8];[3]\", \"[?,?,2]\");\n  INFER_OK(op, \"?;[3]\", \"[?,?,2]\");\n\n  // Symbolic shape propagation\n  new_shape = test::AsTensor<int32>({-1, 2, 3});\n  INFER_OK(op, \"[?,2,3];[3]\", \"[d0_0,2,3]\");\n\n  // Reshaping to a scalar.\n  new_shape = test::AsTensor<int32>({});\n  INFER_OK(op, \"[1];[0]\", \"[]\");\n  INFER_ERROR(\n      \"Cannot reshape a tensor with 2 elements to shape [] (1 elements)\", op,\n      \"[1,2];[0]\");\n\n  // Reshaping a tensor with no elements.\n  new_shape = test::AsTensor<int32>({-1});\n  INFER_OK(op, \"[0];[1]\", \"[0]\");\n  new_shape = test::AsTensor<int32>({-1, 6});\n  INFER_OK(op, \"[0,2];[1]\", \"[0,6]\");\n  new_shape = test::AsTensor<int32>({0, -1});\n  INFER_OK(op, \"[0,2];[1]\", \"[0,?]\");\n}\n\nTEST(ArrayOpsTest, QuantizedReshape_ShapeFn) {\n  ShapeInferenceTestOp op(\"QuantizedReshape\");\n  op.input_tensors.resize(2);\n\n  // First test a subset of the Reshape_ShapeFn tests. Not all are tested, as\n  // QuantizedReshape uses the same code for the reshape part of the operation.\n  INFER_OK(op, \"?;?;?;?\", \"?;[];[]\");\n  INFER_OK(op, \"[?];?;?;?\", \"?;[];[]\");\n  INFER_OK(op, \"[?];[?];?;?\", \"?;[];[]\");\n  INFER_OK(op, \"[4];[?];?;?\", \"?;[];[]\");\n  Tensor new_shape = test::AsTensor<int32>({1, 2, 3});\n  op.input_tensors[1] = &new_shape;\n  INFER_OK(op, \"[?];[3];?;?\", \"[1,2,3];[];[]\");\n  INFER_OK(op, \"[6];[3];?;?\", \"[1,2,3];[];[]\");\n  INFER_ERROR(\n      \"Cannot reshape a tensor with 12 elements to shape [1,2,3] (6 elements)\",\n      op, \"[3,4];[3];?;?\");\n\n  // Test the scalar rank checks on input_min and input_max.\n  INFER_ERROR(\"must be rank 0\", op, \"?;?;[1];?\");\n  INFER_ERROR(\"must be rank 0\", op, \"?;?;?;[1]\");\n}\n\nTEST(ArrayOpsTest, Placeholder_ShapeFn) {\n  {\n    // 2D shape\n    ShapeInferenceTestOp op(\"Placeholder\");\n    TensorShape shape({1, 2});\n    TF_ASSERT_OK(NodeDefBuilder(\"test\", \"Placeholder\")\n                     .Attr(\"shape\", shape)\n                     .Attr(\"dtype\", DT_FLOAT)\n                     .Finalize(&op.node_def));\n    INFER_OK(op, \"\", \"[1,2]\");\n  }\n\n  {\n    // Scalar shapes are supported\n    ShapeInferenceTestOp op(\"Placeholder\");\n    TensorShape shape({});\n    TF_ASSERT_OK(NodeDefBuilder(\"test\", \"Placeholder\")\n                     .Attr(\"shape\", shape)\n                     .Attr(\"dtype\", DT_FLOAT)\n                     .Finalize(&op.node_def));\n    INFER_OK(op, \"\", \"[]\");\n  }\n\n  {\n    // Partial shape\n    ShapeInferenceTestOp op(\"Placeholder\");\n    const int64_t dims[2] = {1, -1};\n    PartialTensorShape shape;\n    TF_ASSERT_OK(PartialTensorShape::MakePartialShape(dims, 2, &shape));\n    TF_ASSERT_OK(NodeDefBuilder(\"test\", \"Placeholder\")\n                     .Attr(\"shape\", shape)\n                     .Attr(\"dtype\", DT_FLOAT)\n                     .Finalize(&op.node_def));\n    INFER_OK(op, \"\", \"[1,?]\");\n  }\n\n  {\n    // Unknown shape\n    ShapeInferenceTestOp op(\"Placeholder\");\n    PartialTensorShape shape;\n    TF_ASSERT_OK(NodeDefBuilder(\"test\", \"Placeholder\")\n                     .Attr(\"shape\", shape)\n                     .Attr(\"dtype\", DT_FLOAT)\n                     .Finalize(&op.node_def));\n    INFER_OK(op, \"\", \"?\");\n  }\n}\n\nTEST(ArrayOpsTest, Transpose_ShapeFn) {\n  ShapeInferenceTestOp op(\"Transpose\");\n  op.input_tensors.resize(2);\n\n  // Missing shape information.\n  INFER_OK(op, \"?;?\", \"?\");\n  INFER_OK(op, \"?;[?]\", \"?\");\n  INFER_OK(op, \"?;[2]\", \"[?,?]\");\n  INFER_OK(op, \"[?];?\", \"[?]\");\n  INFER_OK(op, \"[?,?];[2]\", \"[?,?]\");\n  INFER_ERROR(\"Dimension must be 3 but is 2\", op, \"[1,2,3];[2]\");\n  Tensor perm = test::AsTensor<int32>({0});\n  op.input_tensors[1] = &perm;\n  INFER_OK(op, \"[?];[?]\", \"[d0_0]\");\n  perm = test::AsTensor<int32>({1, 0});\n  INFER_OK(op, \"?;[2]\", \"[?,?]\");\n  INFER_OK(op, \"[?,?];[2]\", \"[d0_1,d0_0]\");\n  INFER_OK(op, \"[1,?];[2]\", \"[d0_1,d0_0]\");\n  INFER_OK(op, \"?;[0]\", \"in0\");\n\n  // Invalid arguments.\n  perm = test::AsTensor<int32>({1, 2});\n  INFER_ERROR(\"perm dim 2 is out of range of input rank 2\", op, \"[1,2];[2]\");\n  perm = test::AsTensor<int32>({0});\n  INFER_ERROR(\"Dimension must be 2 but is 1\", op, \"[1,2];[1]\");\n\n  // Larger valid cases.\n  perm = test::AsTensor<int32>({1, 0, 3, 4, 2});\n  INFER_OK(op, \"[0,1,2,3,4];[5]\", \"[d0_1,d0_0,d0_3,d0_4,d0_2]\");\n  INFER_OK(op, \"[0,?,2,3,4];[5]\", \"[d0_1,d0_0,d0_3,d0_4,d0_2]\");\n}\n\nTEST(ArrayOpsTest, Bitcast_ShapeFn) {\n  ShapeInferenceTestOp op(\"Bitcast\");\n  auto rebuild_node_def = [&op](DataType input_type, DataType output_type) {\n    TF_ASSERT_OK(NodeDefBuilder(\"test\", \"Bitcast\")\n                     .Input(\"input\", 0, input_type)\n                     .Attr(\"type\", output_type)\n                     .Finalize(&op.node_def));\n  };\n\n  rebuild_node_def(DT_FLOAT, DT_INT32);\n  // No valid shape provided, so output is unknown.\n  INFER_OK(op, \"?\", \"?\");\n\n  // Bitcasting from two equal sizes propagates shape.\n  INFER_OK(op, \"[1,2]\", \"in0\");\n\n  // Bitcasting from smaller to larger reduces the size of the last dimension.\n  rebuild_node_def(DT_INT32, DT_INT64);\n  INFER_OK(op, \"[1,2]\", \"[d0_0]\");  // last dimension matches divisor.\n  // TODO(vrv): Seems like a bug, or at least, too lenient.\n  INFER_OK(op, \"[1,?]\", \"[d0_0]\");\n  // 4 is divisible by 2, but the shape function signature requires\n  // that the last dimension matches the last value exactly.\n  INFER_ERROR(\"does not match\", op, \"[1,4]\");\n  INFER_ERROR(\"does not match\", op, \"[1,3]\");\n\n  // Bitcasting from a larger type to a smaller type extends the dimension\n  rebuild_node_def(DT_INT64, DT_INT32);\n  INFER_OK(op, \"[4,5]\", \"[d0_0,d0_1,2]\");\n  rebuild_node_def(DT_COMPLEX128, DT_INT32);\n  INFER_OK(op, \"[4,5]\", \"[d0_0,d0_1,4]\");\n  rebuild_node_def(DT_COMPLEX128, DT_HALF);\n  INFER_OK(op, \"[4,5]\", \"[d0_0,d0_1,8]\");\n  rebuild_node_def(DT_COMPLEX128, DT_INT8);\n  INFER_OK(op, \"[4,5]\", \"[d0_0,d0_1,16]\");\n\n  // Bitcasting from a POD or quantized datatype is not allowed.\n  rebuild_node_def(DT_STRING, DT_INT32);\n  INFER_ERROR(\"one of the type sizes is zero\", op, \"[1,2,3]\");\n  rebuild_node_def(DT_INT32, DT_STRING);\n  INFER_ERROR(\"one of the type sizes is zero\", op, \"[1,2,3]\");\n}\n\nTEST(ArrayOpsTest, Squeeze_ShapeFn) {\n  ShapeInferenceTestOp op(\"Squeeze\");\n\n  auto rebuild_node_def = [&op](const std::vector<int32>& squeeze_dims) {\n    TF_ASSERT_OK(NodeDefBuilder(\"test\", \"Squeeze\")\n                     .Input(\"input\", 0, DT_FLOAT)\n                     .Attr(\"squeeze_dims\", squeeze_dims)\n                     .Finalize(&op.node_def));\n  };\n\n  // Default squeeze_dims = []\n  rebuild_node_def({});\n\n  // No valid shape provided, so output is unknown.\n  INFER_OK(op, \"?\", \"?\");\n\n  INFER_OK(op, \"[1,4,1,5,1]\", \"[d0_1,d0_3]\");\n\n  // Squeezing all dimensions, but see some unknown values.\n  INFER_OK(op, \"[1,?,1,?,1]\", \"?\");\n\n  // Test simple squeeze of an explicit dimension\n  rebuild_node_def({1});\n  INFER_OK(op, \"[4,1,5]\", \"[d0_0,d0_2]\");\n  // Squeezing unknown dim explicitly, assumes it's 1 at runtime.\n  INFER_OK(op, \"[4,?,5]\", \"[d0_0,d0_2]\");\n\n  // Attempt to squeeze non-one dimension\n  INFER_ERROR(\"Can not squeeze dim[1]\", op, \"[4,6,5]\");\n\n  // Squeeze multiple dimensions\n  rebuild_node_def({1, 2});\n  INFER_OK(op, \"[4,1,1,5]\", \"[d0_0,d0_3]\");\n  rebuild_node_def({1, -2});\n  INFER_OK(op, \"[4,1,1,5]\", \"[d0_0,d0_3]\");\n\n  // Negative squeeze dim\n  rebuild_node_def({-2});\n  INFER_OK(op, \"[4,1,5]\", \"[d0_0,d0_2]\");\n\n  // Test validation of squeeze dimensions\n  rebuild_node_def({-4});\n  INFER_ERROR(\"not in [-3,3)\", op, \"[1,2,3]\");\n  rebuild_node_def({3});\n  INFER_ERROR(\"not in [-3,3)\", op, \"[1,2,3]\");\n}\n\nTEST(ArrayOpsTest, ReverseSequence_ShapeFn) {\n  ShapeInferenceTestOp op(\"ReverseSequence\");\n  auto rebuild_node_def = [&op](const int32_t seq_dim,\n                                const int32_t batch_dim) {\n    TF_ASSERT_OK(NodeDefBuilder(\"test\", \"ReverseSequence\")\n                     .Input(\"input\", 0, DT_FLOAT)\n                     .Input(\"seq_lengths\", 1, DT_INT64)\n                     .Attr(\"seq_dim\", seq_dim)\n                     .Attr(\"batch_dim\", batch_dim)\n                     .Finalize(&op.node_def));\n  };\n\n  rebuild_node_def(1, 2);\n  // No valid shape provided, so output is unknown.\n  INFER_OK(op, \"?;[10]\", \"?\");\n\n  // Bad rank for seq_lengths\n  INFER_ERROR(\"Shape must be rank 1 but is rank 2\", op, \"?;[10,10]\");\n\n  // Validate seq_dim and batch_dim\n  rebuild_node_def(1, 4);\n  INFER_ERROR(\"batch_dim must be < input rank\", op, \"[1,2,3];[3]\");\n  rebuild_node_def(4, 1);\n  INFER_ERROR(\"seq_dim must be < input rank\", op, \"[1,2,3];[3]\");\n\n  rebuild_node_def(1, 2);\n  INFER_OK(op, \"[1,2,3];[3]\", \"[d0_0,d0_1,d0_2]\");\n  // Resolves uncertainty on batch dimension by merging.\n  INFER_OK(op, \"[1,2,?];[3]\", \"[d0_0,d0_1,d1_0]\");\n  INFER_OK(op, \"[1,2,3];[?]\", \"[d0_0,d0_1,d0_2]\");\n}\n\nTEST(ArrayOpsTest, Split_ShapeFn) {\n  ShapeInferenceTestOp op(\"Split\");\n  op.input_tensors.resize(2);\n\n  // No value for split_dim and no input.\n  TF_ASSERT_OK(NodeDefBuilder(\"test\", \"Split\")\n                   .Input(\"split_dim\", 0, DT_INT32)\n                   .Input(\"value\", 1, DT_FLOAT)\n                   .Attr(\"num_split\", 2)\n                   .Finalize(&op.node_def));\n  INFER_OK(op, \"?;?\", \"?;?\");\n  // If the rank is known, we know the rank of each output.\n  INFER_OK(op, \"?;[?,?]\", \"[?,?];[?,?]\");\n\n  // split_dim is unknown but other inputs are known.\n  INFER_OK(op, \"?;[1,4]\", \"[?,?];[?,?]\");\n\n  // split_dim is known.\n  Tensor split_dim = test::AsTensor<int32>({1, 2});\n  op.input_tensors[0] = &split_dim;\n  INFER_ERROR(\"Input must be scalar but has rank 1\", op, \"[?];[?,?]\");\n  split_dim = test::AsScalar<int32>(1);\n  INFER_OK(op, \"?;?\", \"?;?\");\n  INFER_OK(op, \"?;[?,?]\", \"[d1_0,?];[d1_0,?]\");\n  INFER_OK(op, \"?;[1,4]\", \"[d1_0,2];[d1_0,2]\");\n  INFER_OK(op, \"?;[1,?]\", \"[d1_0,?];[d1_0,?]\");\n  INFER_ERROR(\"Dimension size must be evenly divisible by 2 but is 5\", op,\n              \"?;[1,5]\");\n\n  // split_dim too large.\n  split_dim = test::AsScalar<int32>(3);\n  INFER_ERROR(\n      \"Dimension size, given by scalar input 3 must be in range [-3, 3)\", op,\n      \"?;[1,4,8]\");\n\n  // Negative split_dim.\n  split_dim = test::AsScalar<int32>(-1);\n  INFER_OK(op, \"?;?\", \"?;?\");\n  INFER_OK(op, \"?;[?,?]\", \"[d1_0,?];[d1_0,?]\");\n  INFER_OK(op, \"?;[1,?]\", \"[d1_0,?];[d1_0,?]\");\n  INFER_OK(op, \"?;[1,4]\", \"[d1_0,2];[d1_0,2]\");\n  INFER_OK(op, \"?;[1,4,8]\", \"[d1_0,d1_1,4];[d1_0,d1_1,4]\");\n  split_dim = test::AsScalar<int32>(-2);\n  INFER_OK(op, \"?;[1,4,8]\", \"[d1_0,2,d1_2];[d1_0,2,d1_2]\");\n  split_dim = test::AsScalar<int32>(-4);\n  INFER_ERROR(\n      \"Dimension size, given by scalar input -4 must be in range [-3, 3)\", op,\n      \"?;[1,4,8]\");\n}\n\nTEST(ArrayOpsTest, Tile_ShapeFn) {\n  ShapeInferenceTestOp op(\"Tile\");\n  op.input_tensors.resize(2);\n\n  // No value for split_dim and no input.\n  TF_ASSERT_OK(NodeDefBuilder(\"test\", \"Tile\")\n                   .Input(\"input\", 0, DT_FLOAT)\n                   .Input(\"multiples\", 1, DT_INT32)\n                   .Finalize(&op.node_def));\n\n  // If both are unknown, output is unknown.\n  INFER_OK(op, \"?;?\", \"?\");\n\n  // If multiples rank is unknown but input is, output rank is known.\n  INFER_OK(op, \"[2,3,1,4];?\", \"[?,?,?,?]\");\n\n  // Bad rank for 'multiples'\n  INFER_ERROR(\"Shape must be rank 1 but is rank 2\", op, \"[2,3,1,4];[4,1]\");\n\n  // No multiples tensor available, but output rank is known from multiples.\n  INFER_OK(op, \"?;[4]\", \"[?,?,?,?]\");\n\n  // Test a tile of a 4D input.\n  Tensor multiples = test::AsTensor<int32>({2, 3, 4, 5});\n  op.input_tensors[1] = &multiples;\n  INFER_OK(op, \"[2,3,1,4];[4]\", \"[4,9,4,20]\");\n  // Test 64-bit tensor type\n  multiples = test::AsTensor<int64_t>({2, 3, 4, 5});\n  INFER_OK(op, \"[2,3,1,4];[4]\", \"[4,9,4,20]\");\n}\n\nTEST(ArrayOpsTest, EditDistance_ShapeFn) {\n  ShapeInferenceTestOp op(\"EditDistance\");\n  op.input_tensors.resize(6);\n\n  // If the shape tensors are not available, the output shape is unknown.\n  INFER_OK(op, \"[?,?];[?];[4];[?,?];[?];[4]\", \"?\");\n\n  Tensor hypothesis_shape = test::AsTensor<int64_t>({2, 30, 4, 50});\n  op.input_tensors[2] = &hypothesis_shape;\n  Tensor truth_shape = test::AsTensor<int64_t>({20, 3, 40, 5});\n  op.input_tensors[5] = &truth_shape;\n  INFER_OK(op, \"[?,?];[?];[4];[?,?];[?];[4]\", \"[20,30,40]\");\n\n  // Shape elements don't match\n  hypothesis_shape = test::AsTensor<int64_t>({2});\n  op.input_tensors[2] = &hypothesis_shape;\n  INFER_ERROR(\"Num elements of hypothesis_shape does not match truth_shape\", op,\n              \"[?,?];[?];[1];[?,?];[?];[4]\");\n}\n\nTEST(ArrayOpsTest, OneHot_ShapeFn) {\n  ShapeInferenceTestOp op(\"OneHot\");\n  op.input_tensors.resize(4);\n  auto set_axis = [&op](int axis) {\n    TF_ASSERT_OK(NodeDefBuilder(\"test\", \"OneHot\")\n                     .Input(\"indices\", 0, DT_FLOAT)\n                     .Input(\"depth\", 1, DT_INT32)\n                     .Input(\"on_value\", 2, DT_FLOAT)\n                     .Input(\"off_value\", 3, DT_FLOAT)\n                     .Attr(\"axis\", axis)\n                     .Finalize(&op.node_def));\n  };\n\n  // Invalid axis value.\n  set_axis(-2);\n  INFER_ERROR(\"axis must be >= -1\", op, \"?;?;?;?\");\n  set_axis(1);\n\n  // If indices shape is unknown, we return an unknown shape.\n  INFER_OK(op, \"?;[];?;?\", \"?\");\n\n  // Depth must be scalar.\n  Tensor depth = test::AsTensor<int32>({1, 2});\n  op.input_tensors[1] = &depth;\n  INFER_ERROR(\"Input must be scalar but has rank 1\", op, \"?;[2];?;?\");\n\n  // Full information is available.\n  depth = test::AsScalar<int32>(2);\n  INFER_OK(op, \"[1,3,4];[];?;?\", \"[d0_0,2,d0_1,d0_2]\");\n  set_axis(-1);\n  INFER_OK(op, \"[1,3,4];[];?;?\", \"[d0_0,d0_1,d0_2,2]\");\n}\n\nTEST(ArrayOpsTest, ExtractImagePatchesShapeTest) {\n  ShapeInferenceTestOp op(\"ExtractImagePatches\");\n  auto set_op = [&op](const std::vector<int32>& ksizes,\n                      const std::vector<int32>& strides,\n                      const std::vector<int32>& rates, const string& padding) {\n    TF_ASSERT_OK(NodeDefBuilder(\"test\", \"ExtractImagePatches\")\n                     .Input(\"input\", 0, DT_FLOAT)\n                     .Attr(\"ksizes\", ksizes)\n                     .Attr(\"strides\", strides)\n                     .Attr(\"rates\", rates)\n                     .Attr(\"padding\", padding)\n                     .Finalize(&op.node_def));\n  };\n\n  // Just tests that the ksize calculation with rates works.  Most of\n  // the other code is boilerplate that is tested by a variety of\n  // other ops.\n  //\n  // ksizes is 2x2.  rate rows and cols is 2, so ksize_rows and\n  // cols are changed to be 2 + (2 - 1) = 3.  7x7 input with 3x3\n  // filter and 1x1 stride gives a 5x5 output.\n  set_op({1, 2, 2, 1}, {1, 1, 1, 1}, {1, 2, 2, 1}, \"VALID\");\n  INFER_OK(op, \"[1,7,7,2]\", \"[d0_0,5,5,8]\");\n  // With ksizes as 1x1, the output depth is now exactly the last value of the\n  // input and output spatial is reduced as well.\n  set_op({1, 1, 1, 1}, {1, 1, 1, 1}, {1, 2, 2, 1}, \"VALID\");\n  INFER_OK(op, \"[1,7,7,2]\", \"[d0_0,7,7,d0_3]\");\n\n  // Bad ksize rank\n  set_op({1, 2, 2, 1, 1}, {1, 1, 1, 1}, {1, 2, 2, 1}, \"VALID\");\n  INFER_ERROR(\n      \"ExtractImagePatches requires the ksizes attribute to contain 4 values, \"\n      \"but got: 5\",\n      op, \"[1,7,7,2]\");\n}\n\nTEST(ArrayOpsTest, QuantizeAndDequantizeV2_ShapeFn) {\n  ShapeInferenceTestOp op(\"QuantizeAndDequantizeV2\");\n  op.input_tensors.resize(3);\n  TF_ASSERT_OK(NodeDefBuilder(\"test\", \"QuantizeAndDequantizeV2\")\n                   .Input(\"input\", 0, DT_FLOAT)\n                   .Input(\"input_min\", 1, DT_FLOAT)\n                   .Input(\"input_max\", 2, DT_FLOAT)\n                   .Attr(\"signed_input\", true)\n                   .Attr(\"num_bits\", 8)\n                   .Attr(\"range_given\", false)\n                   .Attr(\"narrow_range\", false)\n                   .Attr(\"axis\", -1)\n                   .Finalize(&op.node_def));\n  INFER_OK(op, \"?;?;?\", \"in0\");\n  INFER_OK(op, \"[];?;?\", \"in0\");\n  INFER_OK(op, \"[1,2,?,4,5];?;?\", \"in0\");\n\n  INFER_ERROR(\"Shape must be rank 0 but is rank 1\", op, \"[1,2,?,4,5];[1];[]\");\n  INFER_ERROR(\"Shapes must be equal rank, but are 1 and 0\", op,\n              \"[1,2,?,4,5];[];[1]\");\n  INFER_ERROR(\"Shape must be rank 0 but is rank 1\", op, \"[1,2,?,4,5];[1];[1]\");\n  (*op.node_def.mutable_attr())[\"axis\"].set_i(-2);\n  INFER_ERROR(\"axis should be at least -1, got -2\", op, \"?;?;?\");\n}\n\nTEST(ArrayOpsTest, SpaceToBatch_ShapeFn) {\n  ShapeInferenceTestOp op(\"SpaceToBatch\");\n  op.input_tensors.resize(2);\n  TF_ASSERT_OK(NodeDefBuilder(\"test\", \"SpaceToBatch\")\n                   .Input(\"input\", 0, DT_FLOAT)\n                   .Input(\"paddings\", 1, DT_INT32)\n                   .Attr(\"block_size\", 2)\n                   .Finalize(&op.node_def));\n\n  // Paddings not known, but batch size can be computed.\n  INFER_OK(op, \"[1,10,10,3];[2,2]\", \"[4,?,?,d0_3]\");\n\n  // Unknown paddings means width and height.\n  INFER_OK(op, \"[1,10,10,3];?\", \"[4,?,?,d0_3]\");\n\n  // Paddings not correct shape\n  INFER_ERROR(\"rank\", op, \"[1,10,10,3];[4]\");\n  INFER_ERROR(\"3 and 2\", op, \"[1,10,10,3];[2,3]\");\n\n  Tensor paddings = test::AsTensor<int32>({4, 2, 2, 4}, {{2, 2}});\n  op.input_tensors[1] = &paddings;\n  INFER_OK(op, \"[1,10,10,3];[2,2]\", \"[4,8,8,d0_3]\");\n  paddings = test::AsTensor<int64_t>({4, 2, 2, 4}, {{2, 2}});\n  INFER_OK(op, \"[1,10,10,3];[2,2]\", \"[4,8,8,d0_3]\");\n\n  // Bad paddings values\n  paddings = test::AsTensor<int32>({1, 2, 3, 4}, {{2, 2}});\n  op.input_tensors[1] = &paddings;\n  INFER_ERROR(\"Dimension size must be evenly divisible by 2 but is 13\", op,\n              \"[1,10,10,3];[2,2]\");\n\n  // Negative paddings\n  paddings = test::AsTensor<int32>({1, -2, 3, 4}, {{2, 2}});\n  op.input_tensors[1] = &paddings;\n  INFER_ERROR(\"cannot be negative\", op, \"[1,10,10,3];[2,2]\");\n}\n\nTEST(ArrayOpsTest, SpaceToBatchND_ShapeFn) {\n  ShapeInferenceTestOp op(\"SpaceToBatchND\");\n  op.input_tensors.resize(3);\n  TF_ASSERT_OK(NodeDefBuilder(\"test\", \"SpaceToBatchND\")\n                   .Input(\"input\", 0, DT_FLOAT)\n                   .Input(\"block_shape\", 1, DT_INT32)\n                   .Input(\"paddings\", 2, DT_INT32)\n                   .Finalize(&op.node_def));\n\n  // Verify that input shape and paddings shape can be unknown.\n  INFER_OK(op, \"?;[2];?\", \"?\");\n\n  // Only number of input dimensions is known.\n  INFER_OK(op, \"[?,?,?,?];[2];?\", \"[?,?,?,d0_3]\");\n\n  // Dimensions are partially known.\n  INFER_OK(op, \"[?,?,?,2];[2];?\", \"[?,?,?,d0_3]\");\n\n  {\n    // Dimensions are partially known, block_shape known.\n    Tensor block_shape = test::AsTensor<int32>({2, 3});\n    op.input_tensors[1] = &block_shape;\n    INFER_OK(op, \"[3,?,?,2];[2];?\", \"[18,?,?,d0_3]\");\n\n    // Dimensions are partially known, block_shape and paddings known.\n    {\n      Tensor paddings = test::AsTensor<int32>({1, 1, 0, 1}, {{2, 2}});\n      op.input_tensors[2] = &paddings;\n      INFER_OK(op, \"[3,?,2,2];[2];[2,2]\", \"[18,?,1,d0_3]\");\n      op.input_tensors[2] = nullptr;\n    }\n\n    // Dimensions are fully known, block_shape and paddings are known.\n    {\n      Tensor paddings = test::AsTensor<int32>({1, 1, 0, 0}, {{2, 2}});\n      op.input_tensors[2] = &paddings;\n      INFER_OK(op, \"[3,2,3,2];[2];[2,2]\", \"[18,2,1,d0_3]\");\n      op.input_tensors[2] = nullptr;\n    }\n\n    op.input_tensors[1] = nullptr;\n  }\n\n  INFER_ERROR(\"block_shape must have rank 1\", op, \"?;[1,1];?\");\n  INFER_ERROR(\"block_shape must have known size\", op, \"?;[?];?\");\n\n  {\n    Tensor block_shape = test::AsTensor<int32>({0, 2});\n    op.input_tensors[1] = &block_shape;\n    INFER_ERROR(\"block_shape must be positive\", op, \"[1,2,2];[2];[2,2]\");\n    op.input_tensors[1] = nullptr;\n  }\n\n  {\n    Tensor block_shape = test::AsTensor<int32>({1, 1});\n    op.input_tensors[1] = &block_shape;\n    Tensor paddings = test::AsTensor<int32>({0, -1, 0, 0}, {{2, 2}});\n    op.input_tensors[2] = &paddings;\n    INFER_ERROR(\"paddings cannot be negative\", op, \"[1,2,2];[2];[2,2]\");\n    op.input_tensors[1] = nullptr;\n    op.input_tensors[2] = nullptr;\n  }\n\n  {\n    Tensor block_shape = test::AsTensor<int32>({3, 3});\n    op.input_tensors[1] = &block_shape;\n    Tensor paddings = test::AsTensor<int32>({0, 0, 0, 0}, {{2, 2}});\n    op.input_tensors[2] = &paddings;\n    INFER_ERROR(\"divisible\", op, \"[1,2,3,1];[2];[2,2]\");\n    op.input_tensors[1] = nullptr;\n    op.input_tensors[2] = nullptr;\n  }\n\n  {\n    Tensor block_shape = test::AsTensor<int32>({});\n    op.input_tensors[1] = &block_shape;\n    Tensor paddings = test::AsTensor<int32>({});\n    op.input_tensors[2] = &paddings;\n    INFER_OK(op, \"?;[0];[0,2]\", \"?\");\n    op.input_tensors[1] = nullptr;\n    op.input_tensors[2] = nullptr;\n  }\n\n  INFER_ERROR(\"rank\", op, \"[1,3,3,1];[2];[1]\");\n  INFER_ERROR(\"shape\", op, \"[1,3,3,1];[2];[1,2]\");\n}\n\nTEST(ArrayOpsTest, BatchToSpace_ShapeFn) {\n  ShapeInferenceTestOp op(\"BatchToSpace\");\n  op.input_tensors.resize(2);\n  TF_ASSERT_OK(NodeDefBuilder(\"test\", \"BatchToSpace\")\n                   .Input(\"input\", 0, DT_FLOAT)\n                   .Input(\"crops\", 1, DT_INT32)\n                   .Attr(\"block_size\", 2)\n                   .Finalize(&op.node_def));\n\n  // croppings not known, but batch size can be computed.\n  INFER_OK(op, \"[4,8,8,3];[2,2]\", \"[1,?,?,d0_3]\");\n\n  // block_size not compatible with batch size\n  INFER_ERROR(\"Dimension size must be evenly divisible by\", op,\n              \"[5,8,8,3];[2,2]\");\n\n  // Unknown croppings means unknown width and height.\n  INFER_OK(op, \"[4,8,8,3];?\", \"[1,?,?,d0_3]\");\n\n  // croppings not correct shape\n  INFER_ERROR(\"rank\", op, \"[4,8,8,3];[4]\");\n  INFER_ERROR(\"3 and 2\", op, \"[4,8,8,3];[2,3]\");\n\n  Tensor croppings = test::AsTensor<int64_t>({4, 2, 2, 4}, {{2, 2}});\n  op.input_tensors[1] = &croppings;\n  INFER_OK(op, \"[4,8,8,3];[2,2]\", \"[1,10,10,d0_3]\");\n\n  // Bad croppings values\n  croppings = test::AsTensor<int32>({100, 2, 3, 4}, {{2, 2}});\n  op.input_tensors[1] = &croppings;\n  INFER_ERROR(\"Negative dimension size caused by subtracting\", op,\n              \"[4,8,8,3];[2,2]\");\n  croppings = test::AsTensor<int32>({1, 2, 3, 400}, {{2, 2}});\n  op.input_tensors[1] = &croppings;\n  INFER_ERROR(\"Negative dimension size caused by subtracting\", op,\n              \"[4,8,8,3];[2,2]\");\n\n  // Negative paddings\n  croppings = test::AsTensor<int32>({1, -2, 3, 4}, {{2, 2}});\n  op.input_tensors[1] = &croppings;\n  INFER_ERROR(\"cannot be negative\", op, \"[4,8,8,3];[2,2]\");\n}\n\nTEST(ArrayOpsTest, BatchToSpaceND_ShapeFn) {\n  ShapeInferenceTestOp op(\"BatchToSpaceND\");\n  op.input_tensors.resize(3);\n  TF_ASSERT_OK(NodeDefBuilder(\"test\", \"BatchToSpaceND\")\n                   .Input(\"input\", 0, DT_FLOAT)\n                   .Input(\"block_shape\", 1, DT_INT32)\n                   .Input(\"crops\", 2, DT_INT32)\n                   .Finalize(&op.node_def));\n\n  // Verify that input shape and crops shape can be unknown.\n  INFER_OK(op, \"?;[2];?\", \"?\");\n\n  // Only number of input dimensions is known.\n  INFER_OK(op, \"[?,?,?,?];[2];?\", \"[?,?,?,d0_3]\");\n\n  {\n    // Dimensions are partially known, block_shape known.\n    Tensor block_shape = test::AsTensor<int32>({2, 3});\n    op.input_tensors[1] = &block_shape;\n    INFER_OK(op, \"[?,?,?,2];[2];?\", \"[?,?,?,d0_3]\");\n\n    INFER_OK(op, \"[18,?,?,2];[2];?\", \"[3,?,?,d0_3]\");\n\n    // Dimensions are partially known, block_shape and crops known.\n    {\n      Tensor crops = test::AsTensor<int32>({1, 1, 0, 1}, {{2, 2}});\n      op.input_tensors[2] = &crops;\n      INFER_OK(op, \"[18,?,2,2];[2];[2,2]\", \"[3,?,5,d0_3]\");\n      op.input_tensors[2] = nullptr;\n    }\n\n    // Dimensions are fully known, block_shape and crops are known.\n    {\n      Tensor crops = test::AsTensor<int32>({1, 1, 0, 0}, {{2, 2}});\n      op.input_tensors[2] = &crops;\n      INFER_OK(op, \"[18,2,1,2];[2];[2,2]\", \"[3,2,3,d0_3]\");\n      op.input_tensors[2] = nullptr;\n    }\n\n    op.input_tensors[1] = nullptr;\n  }\n\n  INFER_ERROR(\"block_shape must have rank 1\", op, \"?;[1,1];?\");\n  INFER_ERROR(\"block_shape must have known size\", op, \"?;[?];?\");\n  INFER_ERROR(\"rank\", op, \"[2,2];[2];[2,2]\");\n  INFER_ERROR(\"rank\", op, \"[2,2,3];[3];[3,2]\");\n\n  {\n    Tensor block_shape = test::AsTensor<int32>({0, 2});\n    op.input_tensors[1] = &block_shape;\n    INFER_ERROR(\"block_shape must be positive\", op, \"[1,2,2];[2];[2,2]\");\n    op.input_tensors[1] = nullptr;\n  }\n\n  {\n    Tensor block_shape = test::AsTensor<int32>({1, 1});\n    op.input_tensors[1] = &block_shape;\n    Tensor paddings = test::AsTensor<int32>({0, -1, 0, 0}, {{2, 2}});\n    op.input_tensors[2] = &paddings;\n    INFER_ERROR(\"crops cannot be negative\", op, \"[1,2,2];[2];[2,2]\");\n    op.input_tensors[1] = nullptr;\n    op.input_tensors[2] = nullptr;\n  }\n\n  // The amount to crop exceeds the padded size.\n  {\n    Tensor block_shape = test::AsTensor<int32>({2, 2});\n    op.input_tensors[1] = &block_shape;\n    Tensor crops = test::AsTensor<int32>({3, 2, 0, 0}, {{2, 2}});\n    op.input_tensors[2] = &crops;\n    INFER_ERROR(\"Negative\", op, \"[4,2,3,1];[2];[2,2]\");\n    op.input_tensors[1] = nullptr;\n    op.input_tensors[2] = nullptr;\n  }\n\n  // The batch size is not divisible by the product of the block_shape.\n  {\n    Tensor block_shape = test::AsTensor<int32>({2, 3});\n    op.input_tensors[1] = &block_shape;\n    INFER_ERROR(\"divisible\", op, \"[3,1,1,1];[2];[2,2]\");\n    op.input_tensors[1] = nullptr;\n  }\n}\n\nTEST(ArrayOpsTest, SpaceToDepth_ShapeFn) {\n  ShapeInferenceTestOp op(\"SpaceToDepth\");\n  TF_ASSERT_OK(NodeDefBuilder(\"test\", \"SpaceToDepth\")\n                   .Input(\"input\", 0, DT_FLOAT)\n                   .Attr(\"block_size\", 2)\n                   .Finalize(&op.node_def));\n\n  INFER_OK(op, \"[1,2,4,4]\", \"[d0_0,1,2,16]\");\n\n  // block_size not compatible with space\n  INFER_ERROR(\"Dimension size must be evenly divisible by 2 but is 3\", op,\n              \"[1,3,8,4]\");\n  INFER_ERROR(\"Dimension size must be evenly divisible by 2 but is 5\", op,\n              \"[1,2,5,4]\");\n\n  // Unknown depth --> Unknown depth.\n  INFER_OK(op, \"[1,2,4,?]\", \"[d0_0,1,2,?]\");\n}\n\nTEST(ArrayOpsTest, DepthToSpace_ShapeFn) {\n  ShapeInferenceTestOp op(\"DepthToSpace\");\n  TF_ASSERT_OK(NodeDefBuilder(\"test\", \"DepthToSpace\")\n                   .Input(\"input\", 0, DT_FLOAT)\n                   .Attr(\"block_size\", 2)\n                   .Finalize(&op.node_def));\n\n  INFER_OK(op, \"[1,1,2,16]\", \"[d0_0,2,4,4]\");\n\n  // Bad depth\n  INFER_ERROR(\"Dimension size must be evenly divisible by 4 but is 15\", op,\n              \"[1,1,2,15]\");\n\n  // Unknown depth --> Unknown depth.\n  INFER_OK(op, \"[1,2,4,?]\", \"[d0_0,4,8,?]\");\n\n  // Check another block size.\n  TF_ASSERT_OK(NodeDefBuilder(\"test\", \"DepthToSpace\")\n                   .Input(\"input\", 0, DT_FLOAT)\n                   .Attr(\"block_size\", 10)\n                   .Finalize(&op.node_def));\n  INFER_OK(op, \"[1,1,2,200]\", \"[d0_0,10,20,2]\");\n}\n\nTEST(ArrayOpsTest, Slice_ShapeFn) {\n  ShapeInferenceTestOp op(\"Slice\");\n  TF_ASSERT_OK(NodeDefBuilder(\"test\", \"Slice\")\n                   .Input(\"input\", 0, DT_FLOAT)\n                   .Input(\"begin\", 1, DT_INT64)\n                   .Input(\"sizes\", 2, DT_INT64)\n                   .Finalize(&op.node_def));\n\n  // Known rank of input and shape of begin/sizes, but unknown values.\n  // The best we know is the rank of the output.\n  INFER_OK(op, \"[2,3,4,5];[4];[4]\", \"[?,?,?,?]\");\n\n  // Unknown shape of begin/sizes, we still know the rank.\n  INFER_OK(op, \"[2,3,4,5];[?];[?]\", \"[?,?,?,?]\");\n  // Unknown all around\n  INFER_OK(op, \"?;[?];[?]\", \"?\");\n  // Can infer based on begin\n  INFER_OK(op, \"?;[4];[?]\", \"[?,?,?,?]\");\n\n  // Bad rank of begin, sizes\n  INFER_ERROR(\"must be rank 1\", op, \"[2,3,4,5];[2,3];[3]\");\n  INFER_ERROR(\"must be rank 1\", op, \"[2,3,4,5];[2];[3,4]\");\n  // Length of begin doesn't match input rank\n  INFER_ERROR(\"must be rank 2\", op, \"[2,3,4,5];[2];[2]\");\n\n  // Tests with known values.\n  op.input_tensors.resize(3);\n  Tensor begin = test::AsTensor<int32>({0, 1, 2, 1});\n  Tensor sizes = test::AsTensor<int32>({1, 2, 1, 3});\n  op.input_tensors[1] = &begin;\n  op.input_tensors[2] = &sizes;\n  INFER_OK(op, \"[2,3,4,5];[4];[4]\", \"[1,2,1,3]\");\n\n  // -1 in sizes means \"get the rest\"\n  sizes = test::AsTensor<int32>({-1, -1, 1, -1});\n  INFER_OK(op, \"[2,3,4,5];[4];[4]\", \"[d0_0,2,1,4]\");\n\n  begin = test::AsTensor<int32>({0, 1, 2, 6});\n  sizes = test::AsTensor<int32>({-1, -1, -1, -1});\n  INFER_ERROR(\"Negative dimension size\", op, \"[2,3,4,5];[4];[4]\");\n\n  begin = test::AsTensor<int32>({0, 1, 2, 5});\n  sizes = test::AsTensor<int32>({-1, -1, -1, -2});\n  INFER_ERROR(\"cannot be < -1\", op, \"[2,3,4,5];[4];[4]\");\n}\n\nTEST(ArrayOpsTest, StridedSlice_ShapeFn) {\n  ShapeInferenceTestOp op(\"StridedSlice\");\n  TF_ASSERT_OK(NodeDefBuilder(\"test\", \"StridedSlice\")\n                   .Input(\"input\", 0, DT_FLOAT)\n                   .Input(\"begin\", 1, DT_INT32)\n                   .Input(\"end\", 2, DT_INT32)\n                   .Input(\"strides\", 3, DT_INT32)\n                   .Attr(\"shrink_axis_mask\", 1)\n                   .Finalize(&op.node_def));\n  op.input_tensors.resize(4);\n  Tensor strides = test::AsTensor<int32>({1});\n  op.input_tensors[3] = &strides;\n  // Slicing on the 0-th dimension.\n  INFER_OK(op, \"[2,3,4,5];[1];[1];[1]\", \"[3,4,5]\");\n  // Slicing on the 0-th dimension. This time some of the result dimension is 0.\n  INFER_OK(op, \"[2,0,3,4];[1];[1];[1]\", \"[0,3,4]\");\n}\n\nTEST(ArrayOpsTest, StridedSliceGrad_ShapeFn) {\n  ShapeInferenceTestOp op(\"StridedSliceGrad\");\n  op.input_tensors.resize(5);\n  INFER_OK(op, \"?;?;?;?;?\", \"?\");\n  INFER_OK(op, \"[?];?;?;?;?\", \"?\");\n  INFER_OK(op, \"[4];?;?;?;?\", \"[?,?,?,?]\");\n\n  Tensor in_t = test::AsTensor<int32>({1, 2, 3, 4});\n  op.input_tensors[0] = &in_t;\n  INFER_OK(op, \"[4];?;?;?;?\", \"[1,2,3,4]\");\n}\n\nTEST(ArrayOpsTest, UnchangedWithQuantizationScalars_ShapeFn) {\n  for (const char* op_name : {\"Dequantize\", \"FakeQuantWithMinMaxVars\"}) {\n    ShapeInferenceTestOp op(op_name);\n    if (op_name[0] == 'D') {\n      TF_ASSERT_OK(NodeDefBuilder(\"test\", \"Dequantize\")\n                       .Input(\"input\", 0, DT_QINT8)\n                       .Input(\"input_min\", 1, DT_FLOAT)\n                       .Input(\"input_max\", 2, DT_FLOAT)\n                       .Attr(\"T\", DataTypeToEnum<qint8>::v())\n                       .Attr(\"mode\", \"SCALED\")\n                       .Attr(\"axis\", -1)\n                       .Finalize(&op.node_def));\n    }\n    INFER_OK(op, \"?;?;?\", \"in0\");\n    INFER_OK(op, \"[1,?,3];[];[]\", \"in0\");\n\n    // Rank check scalars.\n    INFER_ERROR(\"be rank 0\", op, \"[1,?,3];[1];[]\");\n    INFER_ERROR(\"be rank 0\", op, \"[1,?,3];[];[1]\");\n  }\n}\n\nTEST(ArrayOpsTest, FakeQuantWithMinMaxVarsPerChannel) {\n  ShapeInferenceTestOp op(\"FakeQuantWithMinMaxVarsPerChannel\");\n\n  INFER_OK(op, \"?;?;?\", \"in0\");\n  INFER_OK(op, \"[?];?;?\", \"in0\");\n  INFER_OK(op, \"[1,?,3];[3];[3]\", \"in0\");\n  INFER_OK(op, \"[3];[3];[3]\", \"in0\");\n\n  // Rank check vectors.\n  INFER_ERROR(\"be rank 1\", op, \"[1,?,3];[1];[]\");\n  INFER_ERROR(\"be rank 1\", op, \"[1,?,3];[];[1]\");\n\n  // Vectors must match each other, and match last dim of input.\n  INFER_ERROR(\"must be equal\", op, \"[1,?,3];[2];[?]\");\n  INFER_ERROR(\"must be equal\", op, \"[1,?,3];[?];[2]\");\n  INFER_ERROR(\"must be equal\", op, \"[1,?,?];[1];[2]\");\n  INFER_ERROR(\"must be equal\", op, \"[5];[4];[?]\");\n}\n\nTEST(ArrayOpsTest, FakeQuantWithMinMaxVarsPerChannelGradient) {\n  ShapeInferenceTestOp op(\"FakeQuantWithMinMaxVarsPerChannelGradient\");\n\n  INFER_OK(op, \"?;?;?;?\", \"in0;[?];[?]\");\n  INFER_OK(op, \"[3];[3];[3];[3]\", \"in0;in3;in3\");\n  INFER_OK(op, \"[1,3];[1,3];[3];[3]\", \"in0;in3;in3\");\n  INFER_OK(op, \"[1,2,3,4];[1,2,3,4];[4];[4]\", \"in0;in3;in3\");\n\n  // Rank check vectors.\n  INFER_ERROR(\"be equal rank\", op, \"[1,?,3];[1,?,3];[3];[]\");\n  INFER_ERROR(\"be rank 1\", op, \"[1,?,3];[1,?,3];[];[3]\");\n  INFER_ERROR(\"be at least rank 1\", op, \"[];[];[1];[1]\");\n  INFER_ERROR(\"be at most rank 4\", op, \"[1,2,3,4,5];[1,2,3,4,5];[1];[1]\");\n\n  // Vectors must match each other, and match last dim of input.\n  INFER_ERROR(\"must be equal\", op, \"[1,3];[1,3];[2];[3]\");\n  INFER_ERROR(\"must be equal\", op, \"[1,3];[1,3];[3];[2]\");\n}\n\nTEST(ArrayOpsTest, QuantizedConcat_ShapeFn) {\n  ShapeInferenceTestOp op(\"QuantizedConcat\");\n  auto set_n = [&op](int n) {\n    std::vector<NodeDefBuilder::NodeOut> src_list;\n    std::vector<NodeDefBuilder::NodeOut> limit_list;\n    for (int i = 0; i < n; ++i) {\n      src_list.emplace_back(\"a\", 0, DT_QUINT8);\n      limit_list.emplace_back(\"b\", 0, DT_FLOAT);\n    }\n    TF_ASSERT_OK(NodeDefBuilder(\"test\", \"QuantizedConcat\")\n                     .Input({\"concat_dim\", 0, DT_INT32})\n                     .Input(src_list)\n                     .Input(limit_list)\n                     .Input(limit_list)\n                     .Attr(\"N\", n)\n                     .Finalize(&op.node_def));\n  };\n\n  // Confirm dimension[0] of the input (the concat_dim) is a scalar.\n  set_n(1);\n  INFER_ERROR(\"Shape must be rank 0 but is rank 1\", op, \"[1];?;?;?\");\n\n  // Last 2*<N> are all scalars.\n  set_n(2);\n  INFER_ERROR(\"must be rank 0\", op, \"[];?;?;?;?;?;[1]\");\n  INFER_ERROR(\"must be rank 0\", op, \"[];?;?;?;?;[1];?\");\n  INFER_ERROR(\"must be rank 0\", op, \"[];?;?;?;[1];?;?\");\n  INFER_ERROR(\"must be rank 0\", op, \"[];?;?;[1];?;?;?\");\n\n  // First is concat dim; next N must be compatible for concat.\n  set_n(2);\n  INFER_ERROR(\"must be rank 2\", op, \"[];[1,2];[1,2,3];?;?;?;?\");\n  INFER_OK(op, \"[];[1,2];[1,3];?;?;?;?\", \"[?,?];[];[]\");\n\n  // Test when the concat_dim tensor is known. The concatenated dimension is\n  // summed across all input tensors, and other dimensions are merged.\n  Tensor concat_dim_t;\n  op.input_tensors.push_back(&concat_dim_t);\n  set_n(2);\n  concat_dim_t = test::AsScalar(0);  // Sum dim 0, merge the other two dims.\n  INFER_OK(op, \"[];[100,2,?];[10,?,3];?;?;?;?\", \"[110,d1_1,d2_2];[];[]\");\n  INFER_ERROR(\"Dimension 1 in both shapes must be equal, but are 5 and 3\", op,\n              \"[];[100,2,5];[10,?,3];?;?;?;?\");\n  // Note that other cases of concat are covered in the Concat tests.\n}\n\nTEST(StateOpsTest, _ParallelConcatStart_ShapeFn) {\n  ShapeInferenceTestOp op(\"_ParallelConcatStart\");\n  TensorShape shape({1, 2, 3});\n  TensorShapeProto shape_proto;\n  shape.AsProto(&shape_proto);\n  TF_ASSERT_OK(NodeDefBuilder(\"test\", \"_ParallelConcatStart\")\n                   .Attr(\"shape\", shape_proto)\n                   .Attr(\"dtype\", DT_FLOAT)\n                   .Finalize(&op.node_def));\n  INFER_OK(op, \"\", \"[1,2,3]\");\n}\n\n}  // end namespace tensorflow\n"], "filenames": ["tensorflow/core/ops/array_ops.cc", "tensorflow/core/ops/array_ops_test.cc"], "buggy_code_start_loc": [2866, 1376], "buggy_code_end_loc": [2960, 1376], "fixing_code_start_loc": [2866, 1377], "fixing_code_end_loc": [2972, 1379], "type": "CWE-125", "message": "TensorFlow is an open source platform for machine learning. In affected versions the shape inference functions for the `QuantizeAndDequantizeV*` operations can trigger a read outside of bounds of heap allocated array. The fix will be included in TensorFlow 2.7.0. We will also cherrypick this commit on TensorFlow 2.6.1, TensorFlow 2.5.2, and TensorFlow 2.4.4, as these are also affected and still in supported range.", "other": {"cve": {"id": "CVE-2021-41205", "sourceIdentifier": "security-advisories@github.com", "published": "2021-11-05T21:15:08.750", "lastModified": "2021-11-09T15:12:21.060", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "TensorFlow is an open source platform for machine learning. In affected versions the shape inference functions for the `QuantizeAndDequantizeV*` operations can trigger a read outside of bounds of heap allocated array. The fix will be included in TensorFlow 2.7.0. We will also cherrypick this commit on TensorFlow 2.6.1, TensorFlow 2.5.2, and TensorFlow 2.4.4, as these are also affected and still in supported range."}, {"lang": "es", "value": "TensorFlow es una plataforma de c\u00f3digo abierto para el aprendizaje autom\u00e1tico. En las versiones afectadas, las funciones de inferencia de forma para las operaciones \"QuantizeAndDequantizeV*\" pueden desencadenar una lectura fuera de l\u00edmites de la matriz asignada a la pila. La correcci\u00f3n ser\u00e1 incluida en TensorFlow versi\u00f3n 2.7.0. Tambi\u00e9n ser\u00e1 incluida este commit en TensorFlow versi\u00f3n 2.6.1, TensorFlow versi\u00f3n 2.5.2 y TensorFlow versi\u00f3n 2.4.4, ya que estos tambi\u00e9n est\u00e1n afectados y todav\u00eda est\u00e1n en el rango admitido"}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:L/AC:L/PR:L/UI:N/S:U/C:H/I:N/A:H", "attackVector": "LOCAL", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 7.1, "baseSeverity": "HIGH"}, "exploitabilityScore": 1.8, "impactScore": 5.2}, {"source": "security-advisories@github.com", "type": "Secondary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:L/AC:L/PR:L/UI:N/S:U/C:H/I:N/A:H", "attackVector": "LOCAL", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 7.1, "baseSeverity": "HIGH"}, "exploitabilityScore": 1.8, "impactScore": 5.2}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:L/AC:L/Au:N/C:P/I:N/A:P", "accessVector": "LOCAL", "accessComplexity": "LOW", "authentication": "NONE", "confidentialityImpact": "PARTIAL", "integrityImpact": "NONE", "availabilityImpact": "PARTIAL", "baseScore": 3.6}, "baseSeverity": "LOW", "exploitabilityScore": 3.9, "impactScore": 4.9, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-125"}]}, {"source": "security-advisories@github.com", "type": "Secondary", "description": [{"lang": "en", "value": "CWE-125"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:*:*:*:*:*:*:*:*", "versionEndExcluding": "2.4.4", "matchCriteriaId": "455FB550-4C9C-4BD6-9F76-A627B62AB332"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:*:*:*:*:*:*:*:*", "versionStartIncluding": "2.5.0", "versionEndExcluding": "2.5.2", "matchCriteriaId": "035CDF63-1548-4FB4-B8A9-B8D328FAF910"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:*:*:*:*:*:*:*:*", "versionStartIncluding": "2.6.0", "versionEndExcluding": "2.6.1", "matchCriteriaId": "5D68D8D1-DB27-4395-9D3D-2BED901B852C"}]}]}], "references": [{"url": "https://github.com/tensorflow/tensorflow/commit/7cf73a2274732c9d82af51c2bc2cf90d13cd7e6d", "source": "security-advisories@github.com", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-49rx-x2rw-pc6f", "source": "security-advisories@github.com", "tags": ["Third Party Advisory"]}]}, "github_commit_url": "https://github.com/tensorflow/tensorflow/commit/7cf73a2274732c9d82af51c2bc2cf90d13cd7e6d"}}
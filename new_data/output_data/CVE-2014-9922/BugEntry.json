{"buggy_code": ["/**\n * eCryptfs: Linux filesystem encryption layer\n *\n * Copyright (C) 1997-2003 Erez Zadok\n * Copyright (C) 2001-2003 Stony Brook University\n * Copyright (C) 2004-2007 International Business Machines Corp.\n *   Author(s): Michael A. Halcrow <mahalcro@us.ibm.com>\n *              Michael C. Thompson <mcthomps@us.ibm.com>\n *              Tyler Hicks <tyhicks@ou.edu>\n *\n * This program is free software; you can redistribute it and/or\n * modify it under the terms of the GNU General Public License as\n * published by the Free Software Foundation; either version 2 of the\n * License, or (at your option) any later version.\n *\n * This program is distributed in the hope that it will be useful, but\n * WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n * General Public License for more details.\n *\n * You should have received a copy of the GNU General Public License\n * along with this program; if not, write to the Free Software\n * Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA\n * 02111-1307, USA.\n */\n\n#include <linux/dcache.h>\n#include <linux/file.h>\n#include <linux/module.h>\n#include <linux/namei.h>\n#include <linux/skbuff.h>\n#include <linux/crypto.h>\n#include <linux/mount.h>\n#include <linux/pagemap.h>\n#include <linux/key.h>\n#include <linux/parser.h>\n#include <linux/fs_stack.h>\n#include <linux/slab.h>\n#include <linux/magic.h>\n#include \"ecryptfs_kernel.h\"\n\n/**\n * Module parameter that defines the ecryptfs_verbosity level.\n */\nint ecryptfs_verbosity = 0;\n\nmodule_param(ecryptfs_verbosity, int, 0);\nMODULE_PARM_DESC(ecryptfs_verbosity,\n\t\t \"Initial verbosity level (0 or 1; defaults to \"\n\t\t \"0, which is Quiet)\");\n\n/**\n * Module parameter that defines the number of message buffer elements\n */\nunsigned int ecryptfs_message_buf_len = ECRYPTFS_DEFAULT_MSG_CTX_ELEMS;\n\nmodule_param(ecryptfs_message_buf_len, uint, 0);\nMODULE_PARM_DESC(ecryptfs_message_buf_len,\n\t\t \"Number of message buffer elements\");\n\n/**\n * Module parameter that defines the maximum guaranteed amount of time to wait\n * for a response from ecryptfsd.  The actual sleep time will be, more than\n * likely, a small amount greater than this specified value, but only less if\n * the message successfully arrives.\n */\nsigned long ecryptfs_message_wait_timeout = ECRYPTFS_MAX_MSG_CTX_TTL / HZ;\n\nmodule_param(ecryptfs_message_wait_timeout, long, 0);\nMODULE_PARM_DESC(ecryptfs_message_wait_timeout,\n\t\t \"Maximum number of seconds that an operation will \"\n\t\t \"sleep while waiting for a message response from \"\n\t\t \"userspace\");\n\n/**\n * Module parameter that is an estimate of the maximum number of users\n * that will be concurrently using eCryptfs. Set this to the right\n * value to balance performance and memory use.\n */\nunsigned int ecryptfs_number_of_users = ECRYPTFS_DEFAULT_NUM_USERS;\n\nmodule_param(ecryptfs_number_of_users, uint, 0);\nMODULE_PARM_DESC(ecryptfs_number_of_users, \"An estimate of the number of \"\n\t\t \"concurrent users of eCryptfs\");\n\nvoid __ecryptfs_printk(const char *fmt, ...)\n{\n\tva_list args;\n\tva_start(args, fmt);\n\tif (fmt[1] == '7') { /* KERN_DEBUG */\n\t\tif (ecryptfs_verbosity >= 1)\n\t\t\tvprintk(fmt, args);\n\t} else\n\t\tvprintk(fmt, args);\n\tva_end(args);\n}\n\n/**\n * ecryptfs_init_lower_file\n * @ecryptfs_dentry: Fully initialized eCryptfs dentry object, with\n *                   the lower dentry and the lower mount set\n *\n * eCryptfs only ever keeps a single open file for every lower\n * inode. All I/O operations to the lower inode occur through that\n * file. When the first eCryptfs dentry that interposes with the first\n * lower dentry for that inode is created, this function creates the\n * lower file struct and associates it with the eCryptfs\n * inode. When all eCryptfs files associated with the inode are released, the\n * file is closed.\n *\n * The lower file will be opened with read/write permissions, if\n * possible. Otherwise, it is opened read-only.\n *\n * This function does nothing if a lower file is already\n * associated with the eCryptfs inode.\n *\n * Returns zero on success; non-zero otherwise\n */\nstatic int ecryptfs_init_lower_file(struct dentry *dentry,\n\t\t\t\t    struct file **lower_file)\n{\n\tconst struct cred *cred = current_cred();\n\tstruct path *path = ecryptfs_dentry_to_lower_path(dentry);\n\tint rc;\n\n\trc = ecryptfs_privileged_open(lower_file, path->dentry, path->mnt,\n\t\t\t\t      cred);\n\tif (rc) {\n\t\tprintk(KERN_ERR \"Error opening lower file \"\n\t\t       \"for lower_dentry [0x%p] and lower_mnt [0x%p]; \"\n\t\t       \"rc = [%d]\\n\", path->dentry, path->mnt, rc);\n\t\t(*lower_file) = NULL;\n\t}\n\treturn rc;\n}\n\nint ecryptfs_get_lower_file(struct dentry *dentry, struct inode *inode)\n{\n\tstruct ecryptfs_inode_info *inode_info;\n\tint count, rc = 0;\n\n\tinode_info = ecryptfs_inode_to_private(inode);\n\tmutex_lock(&inode_info->lower_file_mutex);\n\tcount = atomic_inc_return(&inode_info->lower_file_count);\n\tif (WARN_ON_ONCE(count < 1))\n\t\trc = -EINVAL;\n\telse if (count == 1) {\n\t\trc = ecryptfs_init_lower_file(dentry,\n\t\t\t\t\t      &inode_info->lower_file);\n\t\tif (rc)\n\t\t\tatomic_set(&inode_info->lower_file_count, 0);\n\t}\n\tmutex_unlock(&inode_info->lower_file_mutex);\n\treturn rc;\n}\n\nvoid ecryptfs_put_lower_file(struct inode *inode)\n{\n\tstruct ecryptfs_inode_info *inode_info;\n\n\tinode_info = ecryptfs_inode_to_private(inode);\n\tif (atomic_dec_and_mutex_lock(&inode_info->lower_file_count,\n\t\t\t\t      &inode_info->lower_file_mutex)) {\n\t\tfilemap_write_and_wait(inode->i_mapping);\n\t\tfput(inode_info->lower_file);\n\t\tinode_info->lower_file = NULL;\n\t\tmutex_unlock(&inode_info->lower_file_mutex);\n\t}\n}\n\nenum { ecryptfs_opt_sig, ecryptfs_opt_ecryptfs_sig,\n       ecryptfs_opt_cipher, ecryptfs_opt_ecryptfs_cipher,\n       ecryptfs_opt_ecryptfs_key_bytes,\n       ecryptfs_opt_passthrough, ecryptfs_opt_xattr_metadata,\n       ecryptfs_opt_encrypted_view, ecryptfs_opt_fnek_sig,\n       ecryptfs_opt_fn_cipher, ecryptfs_opt_fn_cipher_key_bytes,\n       ecryptfs_opt_unlink_sigs, ecryptfs_opt_mount_auth_tok_only,\n       ecryptfs_opt_check_dev_ruid,\n       ecryptfs_opt_err };\n\nstatic const match_table_t tokens = {\n\t{ecryptfs_opt_sig, \"sig=%s\"},\n\t{ecryptfs_opt_ecryptfs_sig, \"ecryptfs_sig=%s\"},\n\t{ecryptfs_opt_cipher, \"cipher=%s\"},\n\t{ecryptfs_opt_ecryptfs_cipher, \"ecryptfs_cipher=%s\"},\n\t{ecryptfs_opt_ecryptfs_key_bytes, \"ecryptfs_key_bytes=%u\"},\n\t{ecryptfs_opt_passthrough, \"ecryptfs_passthrough\"},\n\t{ecryptfs_opt_xattr_metadata, \"ecryptfs_xattr_metadata\"},\n\t{ecryptfs_opt_encrypted_view, \"ecryptfs_encrypted_view\"},\n\t{ecryptfs_opt_fnek_sig, \"ecryptfs_fnek_sig=%s\"},\n\t{ecryptfs_opt_fn_cipher, \"ecryptfs_fn_cipher=%s\"},\n\t{ecryptfs_opt_fn_cipher_key_bytes, \"ecryptfs_fn_key_bytes=%u\"},\n\t{ecryptfs_opt_unlink_sigs, \"ecryptfs_unlink_sigs\"},\n\t{ecryptfs_opt_mount_auth_tok_only, \"ecryptfs_mount_auth_tok_only\"},\n\t{ecryptfs_opt_check_dev_ruid, \"ecryptfs_check_dev_ruid\"},\n\t{ecryptfs_opt_err, NULL}\n};\n\nstatic int ecryptfs_init_global_auth_toks(\n\tstruct ecryptfs_mount_crypt_stat *mount_crypt_stat)\n{\n\tstruct ecryptfs_global_auth_tok *global_auth_tok;\n\tstruct ecryptfs_auth_tok *auth_tok;\n\tint rc = 0;\n\n\tlist_for_each_entry(global_auth_tok,\n\t\t\t    &mount_crypt_stat->global_auth_tok_list,\n\t\t\t    mount_crypt_stat_list) {\n\t\trc = ecryptfs_keyring_auth_tok_for_sig(\n\t\t\t&global_auth_tok->global_auth_tok_key, &auth_tok,\n\t\t\tglobal_auth_tok->sig);\n\t\tif (rc) {\n\t\t\tprintk(KERN_ERR \"Could not find valid key in user \"\n\t\t\t       \"session keyring for sig specified in mount \"\n\t\t\t       \"option: [%s]\\n\", global_auth_tok->sig);\n\t\t\tglobal_auth_tok->flags |= ECRYPTFS_AUTH_TOK_INVALID;\n\t\t\tgoto out;\n\t\t} else {\n\t\t\tglobal_auth_tok->flags &= ~ECRYPTFS_AUTH_TOK_INVALID;\n\t\t\tup_write(&(global_auth_tok->global_auth_tok_key)->sem);\n\t\t}\n\t}\nout:\n\treturn rc;\n}\n\nstatic void ecryptfs_init_mount_crypt_stat(\n\tstruct ecryptfs_mount_crypt_stat *mount_crypt_stat)\n{\n\tmemset((void *)mount_crypt_stat, 0,\n\t       sizeof(struct ecryptfs_mount_crypt_stat));\n\tINIT_LIST_HEAD(&mount_crypt_stat->global_auth_tok_list);\n\tmutex_init(&mount_crypt_stat->global_auth_tok_list_mutex);\n\tmount_crypt_stat->flags |= ECRYPTFS_MOUNT_CRYPT_STAT_INITIALIZED;\n}\n\n/**\n * ecryptfs_parse_options\n * @sb: The ecryptfs super block\n * @options: The options passed to the kernel\n * @check_ruid: set to 1 if device uid should be checked against the ruid\n *\n * Parse mount options:\n * debug=N \t   - ecryptfs_verbosity level for debug output\n * sig=XXX\t   - description(signature) of the key to use\n *\n * Returns the dentry object of the lower-level (lower/interposed)\n * directory; We want to mount our stackable file system on top of\n * that lower directory.\n *\n * The signature of the key to use must be the description of a key\n * already in the keyring. Mounting will fail if the key can not be\n * found.\n *\n * Returns zero on success; non-zero on error\n */\nstatic int ecryptfs_parse_options(struct ecryptfs_sb_info *sbi, char *options,\n\t\t\t\t  uid_t *check_ruid)\n{\n\tchar *p;\n\tint rc = 0;\n\tint sig_set = 0;\n\tint cipher_name_set = 0;\n\tint fn_cipher_name_set = 0;\n\tint cipher_key_bytes;\n\tint cipher_key_bytes_set = 0;\n\tint fn_cipher_key_bytes;\n\tint fn_cipher_key_bytes_set = 0;\n\tstruct ecryptfs_mount_crypt_stat *mount_crypt_stat =\n\t\t&sbi->mount_crypt_stat;\n\tsubstring_t args[MAX_OPT_ARGS];\n\tint token;\n\tchar *sig_src;\n\tchar *cipher_name_dst;\n\tchar *cipher_name_src;\n\tchar *fn_cipher_name_dst;\n\tchar *fn_cipher_name_src;\n\tchar *fnek_dst;\n\tchar *fnek_src;\n\tchar *cipher_key_bytes_src;\n\tchar *fn_cipher_key_bytes_src;\n\tu8 cipher_code;\n\n\t*check_ruid = 0;\n\n\tif (!options) {\n\t\trc = -EINVAL;\n\t\tgoto out;\n\t}\n\tecryptfs_init_mount_crypt_stat(mount_crypt_stat);\n\twhile ((p = strsep(&options, \",\")) != NULL) {\n\t\tif (!*p)\n\t\t\tcontinue;\n\t\ttoken = match_token(p, tokens, args);\n\t\tswitch (token) {\n\t\tcase ecryptfs_opt_sig:\n\t\tcase ecryptfs_opt_ecryptfs_sig:\n\t\t\tsig_src = args[0].from;\n\t\t\trc = ecryptfs_add_global_auth_tok(mount_crypt_stat,\n\t\t\t\t\t\t\t  sig_src, 0);\n\t\t\tif (rc) {\n\t\t\t\tprintk(KERN_ERR \"Error attempting to register \"\n\t\t\t\t       \"global sig; rc = [%d]\\n\", rc);\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\tsig_set = 1;\n\t\t\tbreak;\n\t\tcase ecryptfs_opt_cipher:\n\t\tcase ecryptfs_opt_ecryptfs_cipher:\n\t\t\tcipher_name_src = args[0].from;\n\t\t\tcipher_name_dst =\n\t\t\t\tmount_crypt_stat->\n\t\t\t\tglobal_default_cipher_name;\n\t\t\tstrncpy(cipher_name_dst, cipher_name_src,\n\t\t\t\tECRYPTFS_MAX_CIPHER_NAME_SIZE);\n\t\t\tcipher_name_dst[ECRYPTFS_MAX_CIPHER_NAME_SIZE] = '\\0';\n\t\t\tcipher_name_set = 1;\n\t\t\tbreak;\n\t\tcase ecryptfs_opt_ecryptfs_key_bytes:\n\t\t\tcipher_key_bytes_src = args[0].from;\n\t\t\tcipher_key_bytes =\n\t\t\t\t(int)simple_strtol(cipher_key_bytes_src,\n\t\t\t\t\t\t   &cipher_key_bytes_src, 0);\n\t\t\tmount_crypt_stat->global_default_cipher_key_size =\n\t\t\t\tcipher_key_bytes;\n\t\t\tcipher_key_bytes_set = 1;\n\t\t\tbreak;\n\t\tcase ecryptfs_opt_passthrough:\n\t\t\tmount_crypt_stat->flags |=\n\t\t\t\tECRYPTFS_PLAINTEXT_PASSTHROUGH_ENABLED;\n\t\t\tbreak;\n\t\tcase ecryptfs_opt_xattr_metadata:\n\t\t\tmount_crypt_stat->flags |=\n\t\t\t\tECRYPTFS_XATTR_METADATA_ENABLED;\n\t\t\tbreak;\n\t\tcase ecryptfs_opt_encrypted_view:\n\t\t\tmount_crypt_stat->flags |=\n\t\t\t\tECRYPTFS_XATTR_METADATA_ENABLED;\n\t\t\tmount_crypt_stat->flags |=\n\t\t\t\tECRYPTFS_ENCRYPTED_VIEW_ENABLED;\n\t\t\tbreak;\n\t\tcase ecryptfs_opt_fnek_sig:\n\t\t\tfnek_src = args[0].from;\n\t\t\tfnek_dst =\n\t\t\t\tmount_crypt_stat->global_default_fnek_sig;\n\t\t\tstrncpy(fnek_dst, fnek_src, ECRYPTFS_SIG_SIZE_HEX);\n\t\t\tmount_crypt_stat->global_default_fnek_sig[\n\t\t\t\tECRYPTFS_SIG_SIZE_HEX] = '\\0';\n\t\t\trc = ecryptfs_add_global_auth_tok(\n\t\t\t\tmount_crypt_stat,\n\t\t\t\tmount_crypt_stat->global_default_fnek_sig,\n\t\t\t\tECRYPTFS_AUTH_TOK_FNEK);\n\t\t\tif (rc) {\n\t\t\t\tprintk(KERN_ERR \"Error attempting to register \"\n\t\t\t\t       \"global fnek sig [%s]; rc = [%d]\\n\",\n\t\t\t\t       mount_crypt_stat->global_default_fnek_sig,\n\t\t\t\t       rc);\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\tmount_crypt_stat->flags |=\n\t\t\t\t(ECRYPTFS_GLOBAL_ENCRYPT_FILENAMES\n\t\t\t\t | ECRYPTFS_GLOBAL_ENCFN_USE_MOUNT_FNEK);\n\t\t\tbreak;\n\t\tcase ecryptfs_opt_fn_cipher:\n\t\t\tfn_cipher_name_src = args[0].from;\n\t\t\tfn_cipher_name_dst =\n\t\t\t\tmount_crypt_stat->global_default_fn_cipher_name;\n\t\t\tstrncpy(fn_cipher_name_dst, fn_cipher_name_src,\n\t\t\t\tECRYPTFS_MAX_CIPHER_NAME_SIZE);\n\t\t\tmount_crypt_stat->global_default_fn_cipher_name[\n\t\t\t\tECRYPTFS_MAX_CIPHER_NAME_SIZE] = '\\0';\n\t\t\tfn_cipher_name_set = 1;\n\t\t\tbreak;\n\t\tcase ecryptfs_opt_fn_cipher_key_bytes:\n\t\t\tfn_cipher_key_bytes_src = args[0].from;\n\t\t\tfn_cipher_key_bytes =\n\t\t\t\t(int)simple_strtol(fn_cipher_key_bytes_src,\n\t\t\t\t\t\t   &fn_cipher_key_bytes_src, 0);\n\t\t\tmount_crypt_stat->global_default_fn_cipher_key_bytes =\n\t\t\t\tfn_cipher_key_bytes;\n\t\t\tfn_cipher_key_bytes_set = 1;\n\t\t\tbreak;\n\t\tcase ecryptfs_opt_unlink_sigs:\n\t\t\tmount_crypt_stat->flags |= ECRYPTFS_UNLINK_SIGS;\n\t\t\tbreak;\n\t\tcase ecryptfs_opt_mount_auth_tok_only:\n\t\t\tmount_crypt_stat->flags |=\n\t\t\t\tECRYPTFS_GLOBAL_MOUNT_AUTH_TOK_ONLY;\n\t\t\tbreak;\n\t\tcase ecryptfs_opt_check_dev_ruid:\n\t\t\t*check_ruid = 1;\n\t\t\tbreak;\n\t\tcase ecryptfs_opt_err:\n\t\tdefault:\n\t\t\tprintk(KERN_WARNING\n\t\t\t       \"%s: eCryptfs: unrecognized option [%s]\\n\",\n\t\t\t       __func__, p);\n\t\t}\n\t}\n\tif (!sig_set) {\n\t\trc = -EINVAL;\n\t\tecryptfs_printk(KERN_ERR, \"You must supply at least one valid \"\n\t\t\t\t\"auth tok signature as a mount \"\n\t\t\t\t\"parameter; see the eCryptfs README\\n\");\n\t\tgoto out;\n\t}\n\tif (!cipher_name_set) {\n\t\tint cipher_name_len = strlen(ECRYPTFS_DEFAULT_CIPHER);\n\n\t\tBUG_ON(cipher_name_len >= ECRYPTFS_MAX_CIPHER_NAME_SIZE);\n\t\tstrcpy(mount_crypt_stat->global_default_cipher_name,\n\t\t       ECRYPTFS_DEFAULT_CIPHER);\n\t}\n\tif ((mount_crypt_stat->flags & ECRYPTFS_GLOBAL_ENCRYPT_FILENAMES)\n\t    && !fn_cipher_name_set)\n\t\tstrcpy(mount_crypt_stat->global_default_fn_cipher_name,\n\t\t       mount_crypt_stat->global_default_cipher_name);\n\tif (!cipher_key_bytes_set)\n\t\tmount_crypt_stat->global_default_cipher_key_size = 0;\n\tif ((mount_crypt_stat->flags & ECRYPTFS_GLOBAL_ENCRYPT_FILENAMES)\n\t    && !fn_cipher_key_bytes_set)\n\t\tmount_crypt_stat->global_default_fn_cipher_key_bytes =\n\t\t\tmount_crypt_stat->global_default_cipher_key_size;\n\n\tcipher_code = ecryptfs_code_for_cipher_string(\n\t\tmount_crypt_stat->global_default_cipher_name,\n\t\tmount_crypt_stat->global_default_cipher_key_size);\n\tif (!cipher_code) {\n\t\tecryptfs_printk(KERN_ERR,\n\t\t\t\t\"eCryptfs doesn't support cipher: %s\",\n\t\t\t\tmount_crypt_stat->global_default_cipher_name);\n\t\trc = -EINVAL;\n\t\tgoto out;\n\t}\n\n\tmutex_lock(&key_tfm_list_mutex);\n\tif (!ecryptfs_tfm_exists(mount_crypt_stat->global_default_cipher_name,\n\t\t\t\t NULL)) {\n\t\trc = ecryptfs_add_new_key_tfm(\n\t\t\tNULL, mount_crypt_stat->global_default_cipher_name,\n\t\t\tmount_crypt_stat->global_default_cipher_key_size);\n\t\tif (rc) {\n\t\t\tprintk(KERN_ERR \"Error attempting to initialize \"\n\t\t\t       \"cipher with name = [%s] and key size = [%td]; \"\n\t\t\t       \"rc = [%d]\\n\",\n\t\t\t       mount_crypt_stat->global_default_cipher_name,\n\t\t\t       mount_crypt_stat->global_default_cipher_key_size,\n\t\t\t       rc);\n\t\t\trc = -EINVAL;\n\t\t\tmutex_unlock(&key_tfm_list_mutex);\n\t\t\tgoto out;\n\t\t}\n\t}\n\tif ((mount_crypt_stat->flags & ECRYPTFS_GLOBAL_ENCRYPT_FILENAMES)\n\t    && !ecryptfs_tfm_exists(\n\t\t    mount_crypt_stat->global_default_fn_cipher_name, NULL)) {\n\t\trc = ecryptfs_add_new_key_tfm(\n\t\t\tNULL, mount_crypt_stat->global_default_fn_cipher_name,\n\t\t\tmount_crypt_stat->global_default_fn_cipher_key_bytes);\n\t\tif (rc) {\n\t\t\tprintk(KERN_ERR \"Error attempting to initialize \"\n\t\t\t       \"cipher with name = [%s] and key size = [%td]; \"\n\t\t\t       \"rc = [%d]\\n\",\n\t\t\t       mount_crypt_stat->global_default_fn_cipher_name,\n\t\t\t       mount_crypt_stat->global_default_fn_cipher_key_bytes,\n\t\t\t       rc);\n\t\t\trc = -EINVAL;\n\t\t\tmutex_unlock(&key_tfm_list_mutex);\n\t\t\tgoto out;\n\t\t}\n\t}\n\tmutex_unlock(&key_tfm_list_mutex);\n\trc = ecryptfs_init_global_auth_toks(mount_crypt_stat);\n\tif (rc)\n\t\tprintk(KERN_WARNING \"One or more global auth toks could not \"\n\t\t       \"properly register; rc = [%d]\\n\", rc);\nout:\n\treturn rc;\n}\n\nstruct kmem_cache *ecryptfs_sb_info_cache;\nstatic struct file_system_type ecryptfs_fs_type;\n\n/**\n * ecryptfs_get_sb\n * @fs_type\n * @flags\n * @dev_name: The path to mount over\n * @raw_data: The options passed into the kernel\n */\nstatic struct dentry *ecryptfs_mount(struct file_system_type *fs_type, int flags,\n\t\t\tconst char *dev_name, void *raw_data)\n{\n\tstruct super_block *s;\n\tstruct ecryptfs_sb_info *sbi;\n\tstruct ecryptfs_dentry_info *root_info;\n\tconst char *err = \"Getting sb failed\";\n\tstruct inode *inode;\n\tstruct path path;\n\tuid_t check_ruid;\n\tint rc;\n\n\tsbi = kmem_cache_zalloc(ecryptfs_sb_info_cache, GFP_KERNEL);\n\tif (!sbi) {\n\t\trc = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\trc = ecryptfs_parse_options(sbi, raw_data, &check_ruid);\n\tif (rc) {\n\t\terr = \"Error parsing options\";\n\t\tgoto out;\n\t}\n\n\ts = sget(fs_type, NULL, set_anon_super, flags, NULL);\n\tif (IS_ERR(s)) {\n\t\trc = PTR_ERR(s);\n\t\tgoto out;\n\t}\n\n\trc = bdi_setup_and_register(&sbi->bdi, \"ecryptfs\", BDI_CAP_MAP_COPY);\n\tif (rc)\n\t\tgoto out1;\n\n\tecryptfs_set_superblock_private(s, sbi);\n\ts->s_bdi = &sbi->bdi;\n\n\t/* ->kill_sb() will take care of sbi after that point */\n\tsbi = NULL;\n\ts->s_op = &ecryptfs_sops;\n\ts->s_d_op = &ecryptfs_dops;\n\n\terr = \"Reading sb failed\";\n\trc = kern_path(dev_name, LOOKUP_FOLLOW | LOOKUP_DIRECTORY, &path);\n\tif (rc) {\n\t\tecryptfs_printk(KERN_WARNING, \"kern_path() failed\\n\");\n\t\tgoto out1;\n\t}\n\tif (path.dentry->d_sb->s_type == &ecryptfs_fs_type) {\n\t\trc = -EINVAL;\n\t\tprintk(KERN_ERR \"Mount on filesystem of type \"\n\t\t\t\"eCryptfs explicitly disallowed due to \"\n\t\t\t\"known incompatibilities\\n\");\n\t\tgoto out_free;\n\t}\n\n\tif (check_ruid && !uid_eq(path.dentry->d_inode->i_uid, current_uid())) {\n\t\trc = -EPERM;\n\t\tprintk(KERN_ERR \"Mount of device (uid: %d) not owned by \"\n\t\t       \"requested user (uid: %d)\\n\",\n\t\t\ti_uid_read(path.dentry->d_inode),\n\t\t\tfrom_kuid(&init_user_ns, current_uid()));\n\t\tgoto out_free;\n\t}\n\n\tecryptfs_set_superblock_lower(s, path.dentry->d_sb);\n\n\t/**\n\t * Set the POSIX ACL flag based on whether they're enabled in the lower\n\t * mount. Force a read-only eCryptfs mount if the lower mount is ro.\n\t * Allow a ro eCryptfs mount even when the lower mount is rw.\n\t */\n\ts->s_flags = flags & ~MS_POSIXACL;\n\ts->s_flags |= path.dentry->d_sb->s_flags & (MS_RDONLY | MS_POSIXACL);\n\n\ts->s_maxbytes = path.dentry->d_sb->s_maxbytes;\n\ts->s_blocksize = path.dentry->d_sb->s_blocksize;\n\ts->s_magic = ECRYPTFS_SUPER_MAGIC;\n\n\tinode = ecryptfs_get_inode(path.dentry->d_inode, s);\n\trc = PTR_ERR(inode);\n\tif (IS_ERR(inode))\n\t\tgoto out_free;\n\n\ts->s_root = d_make_root(inode);\n\tif (!s->s_root) {\n\t\trc = -ENOMEM;\n\t\tgoto out_free;\n\t}\n\n\trc = -ENOMEM;\n\troot_info = kmem_cache_zalloc(ecryptfs_dentry_info_cache, GFP_KERNEL);\n\tif (!root_info)\n\t\tgoto out_free;\n\n\t/* ->kill_sb() will take care of root_info */\n\tecryptfs_set_dentry_private(s->s_root, root_info);\n\troot_info->lower_path = path;\n\n\ts->s_flags |= MS_ACTIVE;\n\treturn dget(s->s_root);\n\nout_free:\n\tpath_put(&path);\nout1:\n\tdeactivate_locked_super(s);\nout:\n\tif (sbi) {\n\t\tecryptfs_destroy_mount_crypt_stat(&sbi->mount_crypt_stat);\n\t\tkmem_cache_free(ecryptfs_sb_info_cache, sbi);\n\t}\n\tprintk(KERN_ERR \"%s; rc = [%d]\\n\", err, rc);\n\treturn ERR_PTR(rc);\n}\n\n/**\n * ecryptfs_kill_block_super\n * @sb: The ecryptfs super block\n *\n * Used to bring the superblock down and free the private data.\n */\nstatic void ecryptfs_kill_block_super(struct super_block *sb)\n{\n\tstruct ecryptfs_sb_info *sb_info = ecryptfs_superblock_to_private(sb);\n\tkill_anon_super(sb);\n\tif (!sb_info)\n\t\treturn;\n\tecryptfs_destroy_mount_crypt_stat(&sb_info->mount_crypt_stat);\n\tbdi_destroy(&sb_info->bdi);\n\tkmem_cache_free(ecryptfs_sb_info_cache, sb_info);\n}\n\nstatic struct file_system_type ecryptfs_fs_type = {\n\t.owner = THIS_MODULE,\n\t.name = \"ecryptfs\",\n\t.mount = ecryptfs_mount,\n\t.kill_sb = ecryptfs_kill_block_super,\n\t.fs_flags = 0\n};\nMODULE_ALIAS_FS(\"ecryptfs\");\n\n/**\n * inode_info_init_once\n *\n * Initializes the ecryptfs_inode_info_cache when it is created\n */\nstatic void\ninode_info_init_once(void *vptr)\n{\n\tstruct ecryptfs_inode_info *ei = (struct ecryptfs_inode_info *)vptr;\n\n\tinode_init_once(&ei->vfs_inode);\n}\n\nstatic struct ecryptfs_cache_info {\n\tstruct kmem_cache **cache;\n\tconst char *name;\n\tsize_t size;\n\tvoid (*ctor)(void *obj);\n} ecryptfs_cache_infos[] = {\n\t{\n\t\t.cache = &ecryptfs_auth_tok_list_item_cache,\n\t\t.name = \"ecryptfs_auth_tok_list_item\",\n\t\t.size = sizeof(struct ecryptfs_auth_tok_list_item),\n\t},\n\t{\n\t\t.cache = &ecryptfs_file_info_cache,\n\t\t.name = \"ecryptfs_file_cache\",\n\t\t.size = sizeof(struct ecryptfs_file_info),\n\t},\n\t{\n\t\t.cache = &ecryptfs_dentry_info_cache,\n\t\t.name = \"ecryptfs_dentry_info_cache\",\n\t\t.size = sizeof(struct ecryptfs_dentry_info),\n\t},\n\t{\n\t\t.cache = &ecryptfs_inode_info_cache,\n\t\t.name = \"ecryptfs_inode_cache\",\n\t\t.size = sizeof(struct ecryptfs_inode_info),\n\t\t.ctor = inode_info_init_once,\n\t},\n\t{\n\t\t.cache = &ecryptfs_sb_info_cache,\n\t\t.name = \"ecryptfs_sb_cache\",\n\t\t.size = sizeof(struct ecryptfs_sb_info),\n\t},\n\t{\n\t\t.cache = &ecryptfs_header_cache,\n\t\t.name = \"ecryptfs_headers\",\n\t\t.size = PAGE_CACHE_SIZE,\n\t},\n\t{\n\t\t.cache = &ecryptfs_xattr_cache,\n\t\t.name = \"ecryptfs_xattr_cache\",\n\t\t.size = PAGE_CACHE_SIZE,\n\t},\n\t{\n\t\t.cache = &ecryptfs_key_record_cache,\n\t\t.name = \"ecryptfs_key_record_cache\",\n\t\t.size = sizeof(struct ecryptfs_key_record),\n\t},\n\t{\n\t\t.cache = &ecryptfs_key_sig_cache,\n\t\t.name = \"ecryptfs_key_sig_cache\",\n\t\t.size = sizeof(struct ecryptfs_key_sig),\n\t},\n\t{\n\t\t.cache = &ecryptfs_global_auth_tok_cache,\n\t\t.name = \"ecryptfs_global_auth_tok_cache\",\n\t\t.size = sizeof(struct ecryptfs_global_auth_tok),\n\t},\n\t{\n\t\t.cache = &ecryptfs_key_tfm_cache,\n\t\t.name = \"ecryptfs_key_tfm_cache\",\n\t\t.size = sizeof(struct ecryptfs_key_tfm),\n\t},\n};\n\nstatic void ecryptfs_free_kmem_caches(void)\n{\n\tint i;\n\n\t/*\n\t * Make sure all delayed rcu free inodes are flushed before we\n\t * destroy cache.\n\t */\n\trcu_barrier();\n\n\tfor (i = 0; i < ARRAY_SIZE(ecryptfs_cache_infos); i++) {\n\t\tstruct ecryptfs_cache_info *info;\n\n\t\tinfo = &ecryptfs_cache_infos[i];\n\t\tif (*(info->cache))\n\t\t\tkmem_cache_destroy(*(info->cache));\n\t}\n}\n\n/**\n * ecryptfs_init_kmem_caches\n *\n * Returns zero on success; non-zero otherwise\n */\nstatic int ecryptfs_init_kmem_caches(void)\n{\n\tint i;\n\n\tfor (i = 0; i < ARRAY_SIZE(ecryptfs_cache_infos); i++) {\n\t\tstruct ecryptfs_cache_info *info;\n\n\t\tinfo = &ecryptfs_cache_infos[i];\n\t\t*(info->cache) = kmem_cache_create(info->name, info->size,\n\t\t\t\t0, SLAB_HWCACHE_ALIGN, info->ctor);\n\t\tif (!*(info->cache)) {\n\t\t\tecryptfs_free_kmem_caches();\n\t\t\tecryptfs_printk(KERN_WARNING, \"%s: \"\n\t\t\t\t\t\"kmem_cache_create failed\\n\",\n\t\t\t\t\tinfo->name);\n\t\t\treturn -ENOMEM;\n\t\t}\n\t}\n\treturn 0;\n}\n\nstatic struct kobject *ecryptfs_kobj;\n\nstatic ssize_t version_show(struct kobject *kobj,\n\t\t\t    struct kobj_attribute *attr, char *buff)\n{\n\treturn snprintf(buff, PAGE_SIZE, \"%d\\n\", ECRYPTFS_VERSIONING_MASK);\n}\n\nstatic struct kobj_attribute version_attr = __ATTR_RO(version);\n\nstatic struct attribute *attributes[] = {\n\t&version_attr.attr,\n\tNULL,\n};\n\nstatic struct attribute_group attr_group = {\n\t.attrs = attributes,\n};\n\nstatic int do_sysfs_registration(void)\n{\n\tint rc;\n\n\tecryptfs_kobj = kobject_create_and_add(\"ecryptfs\", fs_kobj);\n\tif (!ecryptfs_kobj) {\n\t\tprintk(KERN_ERR \"Unable to create ecryptfs kset\\n\");\n\t\trc = -ENOMEM;\n\t\tgoto out;\n\t}\n\trc = sysfs_create_group(ecryptfs_kobj, &attr_group);\n\tif (rc) {\n\t\tprintk(KERN_ERR\n\t\t       \"Unable to create ecryptfs version attributes\\n\");\n\t\tkobject_put(ecryptfs_kobj);\n\t}\nout:\n\treturn rc;\n}\n\nstatic void do_sysfs_unregistration(void)\n{\n\tsysfs_remove_group(ecryptfs_kobj, &attr_group);\n\tkobject_put(ecryptfs_kobj);\n}\n\nstatic int __init ecryptfs_init(void)\n{\n\tint rc;\n\n\tif (ECRYPTFS_DEFAULT_EXTENT_SIZE > PAGE_CACHE_SIZE) {\n\t\trc = -EINVAL;\n\t\tecryptfs_printk(KERN_ERR, \"The eCryptfs extent size is \"\n\t\t\t\t\"larger than the host's page size, and so \"\n\t\t\t\t\"eCryptfs cannot run on this system. The \"\n\t\t\t\t\"default eCryptfs extent size is [%u] bytes; \"\n\t\t\t\t\"the page size is [%lu] bytes.\\n\",\n\t\t\t\tECRYPTFS_DEFAULT_EXTENT_SIZE,\n\t\t\t\t(unsigned long)PAGE_CACHE_SIZE);\n\t\tgoto out;\n\t}\n\trc = ecryptfs_init_kmem_caches();\n\tif (rc) {\n\t\tprintk(KERN_ERR\n\t\t       \"Failed to allocate one or more kmem_cache objects\\n\");\n\t\tgoto out;\n\t}\n\trc = do_sysfs_registration();\n\tif (rc) {\n\t\tprintk(KERN_ERR \"sysfs registration failed\\n\");\n\t\tgoto out_free_kmem_caches;\n\t}\n\trc = ecryptfs_init_kthread();\n\tif (rc) {\n\t\tprintk(KERN_ERR \"%s: kthread initialization failed; \"\n\t\t       \"rc = [%d]\\n\", __func__, rc);\n\t\tgoto out_do_sysfs_unregistration;\n\t}\n\trc = ecryptfs_init_messaging();\n\tif (rc) {\n\t\tprintk(KERN_ERR \"Failure occurred while attempting to \"\n\t\t\t\t\"initialize the communications channel to \"\n\t\t\t\t\"ecryptfsd\\n\");\n\t\tgoto out_destroy_kthread;\n\t}\n\trc = ecryptfs_init_crypto();\n\tif (rc) {\n\t\tprintk(KERN_ERR \"Failure whilst attempting to init crypto; \"\n\t\t       \"rc = [%d]\\n\", rc);\n\t\tgoto out_release_messaging;\n\t}\n\trc = register_filesystem(&ecryptfs_fs_type);\n\tif (rc) {\n\t\tprintk(KERN_ERR \"Failed to register filesystem\\n\");\n\t\tgoto out_destroy_crypto;\n\t}\n\tif (ecryptfs_verbosity > 0)\n\t\tprintk(KERN_CRIT \"eCryptfs verbosity set to %d. Secret values \"\n\t\t\t\"will be written to the syslog!\\n\", ecryptfs_verbosity);\n\n\tgoto out;\nout_destroy_crypto:\n\tecryptfs_destroy_crypto();\nout_release_messaging:\n\tecryptfs_release_messaging();\nout_destroy_kthread:\n\tecryptfs_destroy_kthread();\nout_do_sysfs_unregistration:\n\tdo_sysfs_unregistration();\nout_free_kmem_caches:\n\tecryptfs_free_kmem_caches();\nout:\n\treturn rc;\n}\n\nstatic void __exit ecryptfs_exit(void)\n{\n\tint rc;\n\n\trc = ecryptfs_destroy_crypto();\n\tif (rc)\n\t\tprintk(KERN_ERR \"Failure whilst attempting to destroy crypto; \"\n\t\t       \"rc = [%d]\\n\", rc);\n\tecryptfs_release_messaging();\n\tecryptfs_destroy_kthread();\n\tdo_sysfs_unregistration();\n\tunregister_filesystem(&ecryptfs_fs_type);\n\tecryptfs_free_kmem_caches();\n}\n\nMODULE_AUTHOR(\"Michael A. Halcrow <mhalcrow@us.ibm.com>\");\nMODULE_DESCRIPTION(\"eCryptfs\");\n\nMODULE_LICENSE(\"GPL\");\n\nmodule_init(ecryptfs_init)\nmodule_exit(ecryptfs_exit)\n", "/*\n *\n * Copyright (C) 2011 Novell Inc.\n *\n * This program is free software; you can redistribute it and/or modify it\n * under the terms of the GNU General Public License version 2 as published by\n * the Free Software Foundation.\n */\n\n#include <linux/fs.h>\n#include <linux/namei.h>\n#include <linux/xattr.h>\n#include <linux/security.h>\n#include <linux/mount.h>\n#include <linux/slab.h>\n#include <linux/parser.h>\n#include <linux/module.h>\n#include <linux/sched.h>\n#include <linux/statfs.h>\n#include <linux/seq_file.h>\n#include \"overlayfs.h\"\n\nMODULE_AUTHOR(\"Miklos Szeredi <miklos@szeredi.hu>\");\nMODULE_DESCRIPTION(\"Overlay filesystem\");\nMODULE_LICENSE(\"GPL\");\n\n#define OVERLAYFS_SUPER_MAGIC 0x794c764f\n\nstruct ovl_config {\n\tchar *lowerdir;\n\tchar *upperdir;\n\tchar *workdir;\n};\n\n/* private information held for overlayfs's superblock */\nstruct ovl_fs {\n\tstruct vfsmount *upper_mnt;\n\tstruct vfsmount *lower_mnt;\n\tstruct dentry *workdir;\n\tlong lower_namelen;\n\t/* pathnames of lower and upper dirs, for show_options */\n\tstruct ovl_config config;\n};\n\nstruct ovl_dir_cache;\n\n/* private information held for every overlayfs dentry */\nstruct ovl_entry {\n\tstruct dentry *__upperdentry;\n\tstruct dentry *lowerdentry;\n\tstruct ovl_dir_cache *cache;\n\tunion {\n\t\tstruct {\n\t\t\tu64 version;\n\t\t\tbool opaque;\n\t\t};\n\t\tstruct rcu_head rcu;\n\t};\n};\n\nconst char *ovl_opaque_xattr = \"trusted.overlay.opaque\";\n\n\nenum ovl_path_type ovl_path_type(struct dentry *dentry)\n{\n\tstruct ovl_entry *oe = dentry->d_fsdata;\n\n\tif (oe->__upperdentry) {\n\t\tif (oe->lowerdentry) {\n\t\t\tif (S_ISDIR(dentry->d_inode->i_mode))\n\t\t\t\treturn OVL_PATH_MERGE;\n\t\t\telse\n\t\t\t\treturn OVL_PATH_UPPER;\n\t\t} else {\n\t\t\tif (oe->opaque)\n\t\t\t\treturn OVL_PATH_UPPER;\n\t\t\telse\n\t\t\t\treturn OVL_PATH_PURE_UPPER;\n\t\t}\n\t} else {\n\t\treturn OVL_PATH_LOWER;\n\t}\n}\n\nstatic struct dentry *ovl_upperdentry_dereference(struct ovl_entry *oe)\n{\n\tstruct dentry *upperdentry = ACCESS_ONCE(oe->__upperdentry);\n\t/*\n\t * Make sure to order reads to upperdentry wrt ovl_dentry_update()\n\t */\n\tsmp_read_barrier_depends();\n\treturn upperdentry;\n}\n\nvoid ovl_path_upper(struct dentry *dentry, struct path *path)\n{\n\tstruct ovl_fs *ofs = dentry->d_sb->s_fs_info;\n\tstruct ovl_entry *oe = dentry->d_fsdata;\n\n\tpath->mnt = ofs->upper_mnt;\n\tpath->dentry = ovl_upperdentry_dereference(oe);\n}\n\nenum ovl_path_type ovl_path_real(struct dentry *dentry, struct path *path)\n{\n\n\tenum ovl_path_type type = ovl_path_type(dentry);\n\n\tif (type == OVL_PATH_LOWER)\n\t\tovl_path_lower(dentry, path);\n\telse\n\t\tovl_path_upper(dentry, path);\n\n\treturn type;\n}\n\nstruct dentry *ovl_dentry_upper(struct dentry *dentry)\n{\n\tstruct ovl_entry *oe = dentry->d_fsdata;\n\n\treturn ovl_upperdentry_dereference(oe);\n}\n\nstruct dentry *ovl_dentry_lower(struct dentry *dentry)\n{\n\tstruct ovl_entry *oe = dentry->d_fsdata;\n\n\treturn oe->lowerdentry;\n}\n\nstruct dentry *ovl_dentry_real(struct dentry *dentry)\n{\n\tstruct ovl_entry *oe = dentry->d_fsdata;\n\tstruct dentry *realdentry;\n\n\trealdentry = ovl_upperdentry_dereference(oe);\n\tif (!realdentry)\n\t\trealdentry = oe->lowerdentry;\n\n\treturn realdentry;\n}\n\nstruct dentry *ovl_entry_real(struct ovl_entry *oe, bool *is_upper)\n{\n\tstruct dentry *realdentry;\n\n\trealdentry = ovl_upperdentry_dereference(oe);\n\tif (realdentry) {\n\t\t*is_upper = true;\n\t} else {\n\t\trealdentry = oe->lowerdentry;\n\t\t*is_upper = false;\n\t}\n\treturn realdentry;\n}\n\nstruct ovl_dir_cache *ovl_dir_cache(struct dentry *dentry)\n{\n\tstruct ovl_entry *oe = dentry->d_fsdata;\n\n\treturn oe->cache;\n}\n\nvoid ovl_set_dir_cache(struct dentry *dentry, struct ovl_dir_cache *cache)\n{\n\tstruct ovl_entry *oe = dentry->d_fsdata;\n\n\toe->cache = cache;\n}\n\nvoid ovl_path_lower(struct dentry *dentry, struct path *path)\n{\n\tstruct ovl_fs *ofs = dentry->d_sb->s_fs_info;\n\tstruct ovl_entry *oe = dentry->d_fsdata;\n\n\tpath->mnt = ofs->lower_mnt;\n\tpath->dentry = oe->lowerdentry;\n}\n\nint ovl_want_write(struct dentry *dentry)\n{\n\tstruct ovl_fs *ofs = dentry->d_sb->s_fs_info;\n\treturn mnt_want_write(ofs->upper_mnt);\n}\n\nvoid ovl_drop_write(struct dentry *dentry)\n{\n\tstruct ovl_fs *ofs = dentry->d_sb->s_fs_info;\n\tmnt_drop_write(ofs->upper_mnt);\n}\n\nstruct dentry *ovl_workdir(struct dentry *dentry)\n{\n\tstruct ovl_fs *ofs = dentry->d_sb->s_fs_info;\n\treturn ofs->workdir;\n}\n\nbool ovl_dentry_is_opaque(struct dentry *dentry)\n{\n\tstruct ovl_entry *oe = dentry->d_fsdata;\n\treturn oe->opaque;\n}\n\nvoid ovl_dentry_set_opaque(struct dentry *dentry, bool opaque)\n{\n\tstruct ovl_entry *oe = dentry->d_fsdata;\n\toe->opaque = opaque;\n}\n\nvoid ovl_dentry_update(struct dentry *dentry, struct dentry *upperdentry)\n{\n\tstruct ovl_entry *oe = dentry->d_fsdata;\n\n\tWARN_ON(!mutex_is_locked(&upperdentry->d_parent->d_inode->i_mutex));\n\tWARN_ON(oe->__upperdentry);\n\tBUG_ON(!upperdentry->d_inode);\n\t/*\n\t * Make sure upperdentry is consistent before making it visible to\n\t * ovl_upperdentry_dereference().\n\t */\n\tsmp_wmb();\n\toe->__upperdentry = upperdentry;\n}\n\nvoid ovl_dentry_version_inc(struct dentry *dentry)\n{\n\tstruct ovl_entry *oe = dentry->d_fsdata;\n\n\tWARN_ON(!mutex_is_locked(&dentry->d_inode->i_mutex));\n\toe->version++;\n}\n\nu64 ovl_dentry_version_get(struct dentry *dentry)\n{\n\tstruct ovl_entry *oe = dentry->d_fsdata;\n\n\tWARN_ON(!mutex_is_locked(&dentry->d_inode->i_mutex));\n\treturn oe->version;\n}\n\nbool ovl_is_whiteout(struct dentry *dentry)\n{\n\tstruct inode *inode = dentry->d_inode;\n\n\treturn inode && IS_WHITEOUT(inode);\n}\n\nstatic bool ovl_is_opaquedir(struct dentry *dentry)\n{\n\tint res;\n\tchar val;\n\tstruct inode *inode = dentry->d_inode;\n\n\tif (!S_ISDIR(inode->i_mode) || !inode->i_op->getxattr)\n\t\treturn false;\n\n\tres = inode->i_op->getxattr(dentry, ovl_opaque_xattr, &val, 1);\n\tif (res == 1 && val == 'y')\n\t\treturn true;\n\n\treturn false;\n}\n\nstatic void ovl_dentry_release(struct dentry *dentry)\n{\n\tstruct ovl_entry *oe = dentry->d_fsdata;\n\n\tif (oe) {\n\t\tdput(oe->__upperdentry);\n\t\tdput(oe->lowerdentry);\n\t\tkfree_rcu(oe, rcu);\n\t}\n}\n\nstatic const struct dentry_operations ovl_dentry_operations = {\n\t.d_release = ovl_dentry_release,\n};\n\nstatic struct ovl_entry *ovl_alloc_entry(void)\n{\n\treturn kzalloc(sizeof(struct ovl_entry), GFP_KERNEL);\n}\n\nstatic inline struct dentry *ovl_lookup_real(struct dentry *dir,\n\t\t\t\t\t     struct qstr *name)\n{\n\tstruct dentry *dentry;\n\n\tmutex_lock(&dir->d_inode->i_mutex);\n\tdentry = lookup_one_len(name->name, dir, name->len);\n\tmutex_unlock(&dir->d_inode->i_mutex);\n\n\tif (IS_ERR(dentry)) {\n\t\tif (PTR_ERR(dentry) == -ENOENT)\n\t\t\tdentry = NULL;\n\t} else if (!dentry->d_inode) {\n\t\tdput(dentry);\n\t\tdentry = NULL;\n\t}\n\treturn dentry;\n}\n\nstruct dentry *ovl_lookup(struct inode *dir, struct dentry *dentry,\n\t\t\t  unsigned int flags)\n{\n\tstruct ovl_entry *oe;\n\tstruct dentry *upperdir;\n\tstruct dentry *lowerdir;\n\tstruct dentry *upperdentry = NULL;\n\tstruct dentry *lowerdentry = NULL;\n\tstruct inode *inode = NULL;\n\tint err;\n\n\terr = -ENOMEM;\n\toe = ovl_alloc_entry();\n\tif (!oe)\n\t\tgoto out;\n\n\tupperdir = ovl_dentry_upper(dentry->d_parent);\n\tlowerdir = ovl_dentry_lower(dentry->d_parent);\n\n\tif (upperdir) {\n\t\tupperdentry = ovl_lookup_real(upperdir, &dentry->d_name);\n\t\terr = PTR_ERR(upperdentry);\n\t\tif (IS_ERR(upperdentry))\n\t\t\tgoto out_put_dir;\n\n\t\tif (lowerdir && upperdentry) {\n\t\t\tif (ovl_is_whiteout(upperdentry)) {\n\t\t\t\tdput(upperdentry);\n\t\t\t\tupperdentry = NULL;\n\t\t\t\toe->opaque = true;\n\t\t\t} else if (ovl_is_opaquedir(upperdentry)) {\n\t\t\t\toe->opaque = true;\n\t\t\t}\n\t\t}\n\t}\n\tif (lowerdir && !oe->opaque) {\n\t\tlowerdentry = ovl_lookup_real(lowerdir, &dentry->d_name);\n\t\terr = PTR_ERR(lowerdentry);\n\t\tif (IS_ERR(lowerdentry))\n\t\t\tgoto out_dput_upper;\n\t}\n\n\tif (lowerdentry && upperdentry &&\n\t    (!S_ISDIR(upperdentry->d_inode->i_mode) ||\n\t     !S_ISDIR(lowerdentry->d_inode->i_mode))) {\n\t\tdput(lowerdentry);\n\t\tlowerdentry = NULL;\n\t\toe->opaque = true;\n\t}\n\n\tif (lowerdentry || upperdentry) {\n\t\tstruct dentry *realdentry;\n\n\t\trealdentry = upperdentry ? upperdentry : lowerdentry;\n\t\terr = -ENOMEM;\n\t\tinode = ovl_new_inode(dentry->d_sb, realdentry->d_inode->i_mode,\n\t\t\t\t      oe);\n\t\tif (!inode)\n\t\t\tgoto out_dput;\n\t\tovl_copyattr(realdentry->d_inode, inode);\n\t}\n\n\toe->__upperdentry = upperdentry;\n\toe->lowerdentry = lowerdentry;\n\n\tdentry->d_fsdata = oe;\n\td_add(dentry, inode);\n\n\treturn NULL;\n\nout_dput:\n\tdput(lowerdentry);\nout_dput_upper:\n\tdput(upperdentry);\nout_put_dir:\n\tkfree(oe);\nout:\n\treturn ERR_PTR(err);\n}\n\nstruct file *ovl_path_open(struct path *path, int flags)\n{\n\treturn dentry_open(path, flags, current_cred());\n}\n\nstatic void ovl_put_super(struct super_block *sb)\n{\n\tstruct ovl_fs *ufs = sb->s_fs_info;\n\n\tdput(ufs->workdir);\n\tmntput(ufs->upper_mnt);\n\tmntput(ufs->lower_mnt);\n\n\tkfree(ufs->config.lowerdir);\n\tkfree(ufs->config.upperdir);\n\tkfree(ufs->config.workdir);\n\tkfree(ufs);\n}\n\n/**\n * ovl_statfs\n * @sb: The overlayfs super block\n * @buf: The struct kstatfs to fill in with stats\n *\n * Get the filesystem statistics.  As writes always target the upper layer\n * filesystem pass the statfs to the same filesystem.\n */\nstatic int ovl_statfs(struct dentry *dentry, struct kstatfs *buf)\n{\n\tstruct ovl_fs *ofs = dentry->d_sb->s_fs_info;\n\tstruct dentry *root_dentry = dentry->d_sb->s_root;\n\tstruct path path;\n\tint err;\n\n\tovl_path_upper(root_dentry, &path);\n\n\terr = vfs_statfs(&path, buf);\n\tif (!err) {\n\t\tbuf->f_namelen = max(buf->f_namelen, ofs->lower_namelen);\n\t\tbuf->f_type = OVERLAYFS_SUPER_MAGIC;\n\t}\n\n\treturn err;\n}\n\n/**\n * ovl_show_options\n *\n * Prints the mount options for a given superblock.\n * Returns zero; does not fail.\n */\nstatic int ovl_show_options(struct seq_file *m, struct dentry *dentry)\n{\n\tstruct super_block *sb = dentry->d_sb;\n\tstruct ovl_fs *ufs = sb->s_fs_info;\n\n\tseq_printf(m, \",lowerdir=%s\", ufs->config.lowerdir);\n\tseq_printf(m, \",upperdir=%s\", ufs->config.upperdir);\n\tseq_printf(m, \",workdir=%s\", ufs->config.workdir);\n\treturn 0;\n}\n\nstatic const struct super_operations ovl_super_operations = {\n\t.put_super\t= ovl_put_super,\n\t.statfs\t\t= ovl_statfs,\n\t.show_options\t= ovl_show_options,\n};\n\nenum {\n\tOPT_LOWERDIR,\n\tOPT_UPPERDIR,\n\tOPT_WORKDIR,\n\tOPT_ERR,\n};\n\nstatic const match_table_t ovl_tokens = {\n\t{OPT_LOWERDIR,\t\t\t\"lowerdir=%s\"},\n\t{OPT_UPPERDIR,\t\t\t\"upperdir=%s\"},\n\t{OPT_WORKDIR,\t\t\t\"workdir=%s\"},\n\t{OPT_ERR,\t\t\tNULL}\n};\n\nstatic int ovl_parse_opt(char *opt, struct ovl_config *config)\n{\n\tchar *p;\n\n\twhile ((p = strsep(&opt, \",\")) != NULL) {\n\t\tint token;\n\t\tsubstring_t args[MAX_OPT_ARGS];\n\n\t\tif (!*p)\n\t\t\tcontinue;\n\n\t\ttoken = match_token(p, ovl_tokens, args);\n\t\tswitch (token) {\n\t\tcase OPT_UPPERDIR:\n\t\t\tkfree(config->upperdir);\n\t\t\tconfig->upperdir = match_strdup(&args[0]);\n\t\t\tif (!config->upperdir)\n\t\t\t\treturn -ENOMEM;\n\t\t\tbreak;\n\n\t\tcase OPT_LOWERDIR:\n\t\t\tkfree(config->lowerdir);\n\t\t\tconfig->lowerdir = match_strdup(&args[0]);\n\t\t\tif (!config->lowerdir)\n\t\t\t\treturn -ENOMEM;\n\t\t\tbreak;\n\n\t\tcase OPT_WORKDIR:\n\t\t\tkfree(config->workdir);\n\t\t\tconfig->workdir = match_strdup(&args[0]);\n\t\t\tif (!config->workdir)\n\t\t\t\treturn -ENOMEM;\n\t\t\tbreak;\n\n\t\tdefault:\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\treturn 0;\n}\n\n#define OVL_WORKDIR_NAME \"work\"\n\nstatic struct dentry *ovl_workdir_create(struct vfsmount *mnt,\n\t\t\t\t\t struct dentry *dentry)\n{\n\tstruct inode *dir = dentry->d_inode;\n\tstruct dentry *work;\n\tint err;\n\tbool retried = false;\n\n\terr = mnt_want_write(mnt);\n\tif (err)\n\t\treturn ERR_PTR(err);\n\n\tmutex_lock_nested(&dir->i_mutex, I_MUTEX_PARENT);\nretry:\n\twork = lookup_one_len(OVL_WORKDIR_NAME, dentry,\n\t\t\t      strlen(OVL_WORKDIR_NAME));\n\n\tif (!IS_ERR(work)) {\n\t\tstruct kstat stat = {\n\t\t\t.mode = S_IFDIR | 0,\n\t\t};\n\n\t\tif (work->d_inode) {\n\t\t\terr = -EEXIST;\n\t\t\tif (retried)\n\t\t\t\tgoto out_dput;\n\n\t\t\tretried = true;\n\t\t\tovl_cleanup(dir, work);\n\t\t\tdput(work);\n\t\t\tgoto retry;\n\t\t}\n\n\t\terr = ovl_create_real(dir, work, &stat, NULL, NULL, true);\n\t\tif (err)\n\t\t\tgoto out_dput;\n\t}\nout_unlock:\n\tmutex_unlock(&dir->i_mutex);\n\tmnt_drop_write(mnt);\n\n\treturn work;\n\nout_dput:\n\tdput(work);\n\twork = ERR_PTR(err);\n\tgoto out_unlock;\n}\n\nstatic int ovl_mount_dir(const char *name, struct path *path)\n{\n\tint err;\n\n\terr = kern_path(name, LOOKUP_FOLLOW, path);\n\tif (err) {\n\t\tpr_err(\"overlayfs: failed to resolve '%s': %i\\n\", name, err);\n\t\terr = -EINVAL;\n\t}\n\treturn err;\n}\n\nstatic bool ovl_is_allowed_fs_type(struct dentry *root)\n{\n\tconst struct dentry_operations *dop = root->d_op;\n\n\t/*\n\t * We don't support:\n\t *  - automount filesystems\n\t *  - filesystems with revalidate (FIXME for lower layer)\n\t *  - filesystems with case insensitive names\n\t */\n\tif (dop &&\n\t    (dop->d_manage || dop->d_automount ||\n\t     dop->d_revalidate || dop->d_weak_revalidate ||\n\t     dop->d_compare || dop->d_hash)) {\n\t\treturn false;\n\t}\n\treturn true;\n}\n\n/* Workdir should not be subdir of upperdir and vice versa */\nstatic bool ovl_workdir_ok(struct dentry *workdir, struct dentry *upperdir)\n{\n\tbool ok = false;\n\n\tif (workdir != upperdir) {\n\t\tok = (lock_rename(workdir, upperdir) == NULL);\n\t\tunlock_rename(workdir, upperdir);\n\t}\n\treturn ok;\n}\n\nstatic int ovl_fill_super(struct super_block *sb, void *data, int silent)\n{\n\tstruct path lowerpath;\n\tstruct path upperpath;\n\tstruct path workpath;\n\tstruct inode *root_inode;\n\tstruct dentry *root_dentry;\n\tstruct ovl_entry *oe;\n\tstruct ovl_fs *ufs;\n\tstruct kstatfs statfs;\n\tint err;\n\n\terr = -ENOMEM;\n\tufs = kzalloc(sizeof(struct ovl_fs), GFP_KERNEL);\n\tif (!ufs)\n\t\tgoto out;\n\n\terr = ovl_parse_opt((char *) data, &ufs->config);\n\tif (err)\n\t\tgoto out_free_config;\n\n\t/* FIXME: workdir is not needed for a R/O mount */\n\terr = -EINVAL;\n\tif (!ufs->config.upperdir || !ufs->config.lowerdir ||\n\t    !ufs->config.workdir) {\n\t\tpr_err(\"overlayfs: missing upperdir or lowerdir or workdir\\n\");\n\t\tgoto out_free_config;\n\t}\n\n\terr = -ENOMEM;\n\toe = ovl_alloc_entry();\n\tif (oe == NULL)\n\t\tgoto out_free_config;\n\n\terr = ovl_mount_dir(ufs->config.upperdir, &upperpath);\n\tif (err)\n\t\tgoto out_free_oe;\n\n\terr = ovl_mount_dir(ufs->config.lowerdir, &lowerpath);\n\tif (err)\n\t\tgoto out_put_upperpath;\n\n\terr = ovl_mount_dir(ufs->config.workdir, &workpath);\n\tif (err)\n\t\tgoto out_put_lowerpath;\n\n\terr = -EINVAL;\n\tif (!S_ISDIR(upperpath.dentry->d_inode->i_mode) ||\n\t    !S_ISDIR(lowerpath.dentry->d_inode->i_mode) ||\n\t    !S_ISDIR(workpath.dentry->d_inode->i_mode)) {\n\t\tpr_err(\"overlayfs: upperdir or lowerdir or workdir not a directory\\n\");\n\t\tgoto out_put_workpath;\n\t}\n\n\tif (upperpath.mnt != workpath.mnt) {\n\t\tpr_err(\"overlayfs: workdir and upperdir must reside under the same mount\\n\");\n\t\tgoto out_put_workpath;\n\t}\n\tif (!ovl_workdir_ok(workpath.dentry, upperpath.dentry)) {\n\t\tpr_err(\"overlayfs: workdir and upperdir must be separate subtrees\\n\");\n\t\tgoto out_put_workpath;\n\t}\n\n\tif (!ovl_is_allowed_fs_type(upperpath.dentry)) {\n\t\tpr_err(\"overlayfs: filesystem of upperdir is not supported\\n\");\n\t\tgoto out_put_workpath;\n\t}\n\n\tif (!ovl_is_allowed_fs_type(lowerpath.dentry)) {\n\t\tpr_err(\"overlayfs: filesystem of lowerdir is not supported\\n\");\n\t\tgoto out_put_workpath;\n\t}\n\n\terr = vfs_statfs(&lowerpath, &statfs);\n\tif (err) {\n\t\tpr_err(\"overlayfs: statfs failed on lowerpath\\n\");\n\t\tgoto out_put_workpath;\n\t}\n\tufs->lower_namelen = statfs.f_namelen;\n\n\tufs->upper_mnt = clone_private_mount(&upperpath);\n\terr = PTR_ERR(ufs->upper_mnt);\n\tif (IS_ERR(ufs->upper_mnt)) {\n\t\tpr_err(\"overlayfs: failed to clone upperpath\\n\");\n\t\tgoto out_put_workpath;\n\t}\n\n\tufs->lower_mnt = clone_private_mount(&lowerpath);\n\terr = PTR_ERR(ufs->lower_mnt);\n\tif (IS_ERR(ufs->lower_mnt)) {\n\t\tpr_err(\"overlayfs: failed to clone lowerpath\\n\");\n\t\tgoto out_put_upper_mnt;\n\t}\n\n\tufs->workdir = ovl_workdir_create(ufs->upper_mnt, workpath.dentry);\n\terr = PTR_ERR(ufs->workdir);\n\tif (IS_ERR(ufs->workdir)) {\n\t\tpr_err(\"overlayfs: failed to create directory %s/%s\\n\",\n\t\t       ufs->config.workdir, OVL_WORKDIR_NAME);\n\t\tgoto out_put_lower_mnt;\n\t}\n\n\t/*\n\t * Make lower_mnt R/O.  That way fchmod/fchown on lower file\n\t * will fail instead of modifying lower fs.\n\t */\n\tufs->lower_mnt->mnt_flags |= MNT_READONLY;\n\n\t/* If the upper fs is r/o, we mark overlayfs r/o too */\n\tif (ufs->upper_mnt->mnt_sb->s_flags & MS_RDONLY)\n\t\tsb->s_flags |= MS_RDONLY;\n\n\tsb->s_d_op = &ovl_dentry_operations;\n\n\terr = -ENOMEM;\n\troot_inode = ovl_new_inode(sb, S_IFDIR, oe);\n\tif (!root_inode)\n\t\tgoto out_put_workdir;\n\n\troot_dentry = d_make_root(root_inode);\n\tif (!root_dentry)\n\t\tgoto out_put_workdir;\n\n\tmntput(upperpath.mnt);\n\tmntput(lowerpath.mnt);\n\tpath_put(&workpath);\n\n\toe->__upperdentry = upperpath.dentry;\n\toe->lowerdentry = lowerpath.dentry;\n\n\troot_dentry->d_fsdata = oe;\n\n\tsb->s_magic = OVERLAYFS_SUPER_MAGIC;\n\tsb->s_op = &ovl_super_operations;\n\tsb->s_root = root_dentry;\n\tsb->s_fs_info = ufs;\n\n\treturn 0;\n\nout_put_workdir:\n\tdput(ufs->workdir);\nout_put_lower_mnt:\n\tmntput(ufs->lower_mnt);\nout_put_upper_mnt:\n\tmntput(ufs->upper_mnt);\nout_put_workpath:\n\tpath_put(&workpath);\nout_put_lowerpath:\n\tpath_put(&lowerpath);\nout_put_upperpath:\n\tpath_put(&upperpath);\nout_free_oe:\n\tkfree(oe);\nout_free_config:\n\tkfree(ufs->config.lowerdir);\n\tkfree(ufs->config.upperdir);\n\tkfree(ufs->config.workdir);\n\tkfree(ufs);\nout:\n\treturn err;\n}\n\nstatic struct dentry *ovl_mount(struct file_system_type *fs_type, int flags,\n\t\t\t\tconst char *dev_name, void *raw_data)\n{\n\treturn mount_nodev(fs_type, flags, raw_data, ovl_fill_super);\n}\n\nstatic struct file_system_type ovl_fs_type = {\n\t.owner\t\t= THIS_MODULE,\n\t.name\t\t= \"overlayfs\",\n\t.mount\t\t= ovl_mount,\n\t.kill_sb\t= kill_anon_super,\n};\nMODULE_ALIAS_FS(\"overlayfs\");\n\nstatic int __init ovl_init(void)\n{\n\treturn register_filesystem(&ovl_fs_type);\n}\n\nstatic void __exit ovl_exit(void)\n{\n\tunregister_filesystem(&ovl_fs_type);\n}\n\nmodule_init(ovl_init);\nmodule_exit(ovl_exit);\n", "#ifndef _LINUX_FS_H\n#define _LINUX_FS_H\n\n\n#include <linux/linkage.h>\n#include <linux/wait.h>\n#include <linux/kdev_t.h>\n#include <linux/dcache.h>\n#include <linux/path.h>\n#include <linux/stat.h>\n#include <linux/cache.h>\n#include <linux/list.h>\n#include <linux/list_lru.h>\n#include <linux/llist.h>\n#include <linux/radix-tree.h>\n#include <linux/rbtree.h>\n#include <linux/init.h>\n#include <linux/pid.h>\n#include <linux/bug.h>\n#include <linux/mutex.h>\n#include <linux/capability.h>\n#include <linux/semaphore.h>\n#include <linux/fiemap.h>\n#include <linux/rculist_bl.h>\n#include <linux/atomic.h>\n#include <linux/shrinker.h>\n#include <linux/migrate_mode.h>\n#include <linux/uidgid.h>\n#include <linux/lockdep.h>\n#include <linux/percpu-rwsem.h>\n#include <linux/blk_types.h>\n\n#include <asm/byteorder.h>\n#include <uapi/linux/fs.h>\n\nstruct export_operations;\nstruct hd_geometry;\nstruct iovec;\nstruct nameidata;\nstruct kiocb;\nstruct kobject;\nstruct pipe_inode_info;\nstruct poll_table_struct;\nstruct kstatfs;\nstruct vm_area_struct;\nstruct vfsmount;\nstruct cred;\nstruct swap_info_struct;\nstruct seq_file;\nstruct workqueue_struct;\nstruct iov_iter;\n\nextern void __init inode_init(void);\nextern void __init inode_init_early(void);\nextern void __init files_init(unsigned long);\n\nextern struct files_stat_struct files_stat;\nextern unsigned long get_max_files(void);\nextern int sysctl_nr_open;\nextern struct inodes_stat_t inodes_stat;\nextern int leases_enable, lease_break_time;\nextern int sysctl_protected_symlinks;\nextern int sysctl_protected_hardlinks;\n\nstruct buffer_head;\ntypedef int (get_block_t)(struct inode *inode, sector_t iblock,\n\t\t\tstruct buffer_head *bh_result, int create);\ntypedef void (dio_iodone_t)(struct kiocb *iocb, loff_t offset,\n\t\t\tssize_t bytes, void *private);\n\n#define MAY_EXEC\t\t0x00000001\n#define MAY_WRITE\t\t0x00000002\n#define MAY_READ\t\t0x00000004\n#define MAY_APPEND\t\t0x00000008\n#define MAY_ACCESS\t\t0x00000010\n#define MAY_OPEN\t\t0x00000020\n#define MAY_CHDIR\t\t0x00000040\n/* called from RCU mode, don't block */\n#define MAY_NOT_BLOCK\t\t0x00000080\n\n/*\n * flags in file.f_mode.  Note that FMODE_READ and FMODE_WRITE must correspond\n * to O_WRONLY and O_RDWR via the strange trick in __dentry_open()\n */\n\n/* file is open for reading */\n#define FMODE_READ\t\t((__force fmode_t)0x1)\n/* file is open for writing */\n#define FMODE_WRITE\t\t((__force fmode_t)0x2)\n/* file is seekable */\n#define FMODE_LSEEK\t\t((__force fmode_t)0x4)\n/* file can be accessed using pread */\n#define FMODE_PREAD\t\t((__force fmode_t)0x8)\n/* file can be accessed using pwrite */\n#define FMODE_PWRITE\t\t((__force fmode_t)0x10)\n/* File is opened for execution with sys_execve / sys_uselib */\n#define FMODE_EXEC\t\t((__force fmode_t)0x20)\n/* File is opened with O_NDELAY (only set for block devices) */\n#define FMODE_NDELAY\t\t((__force fmode_t)0x40)\n/* File is opened with O_EXCL (only set for block devices) */\n#define FMODE_EXCL\t\t((__force fmode_t)0x80)\n/* File is opened using open(.., 3, ..) and is writeable only for ioctls\n   (specialy hack for floppy.c) */\n#define FMODE_WRITE_IOCTL\t((__force fmode_t)0x100)\n/* 32bit hashes as llseek() offset (for directories) */\n#define FMODE_32BITHASH         ((__force fmode_t)0x200)\n/* 64bit hashes as llseek() offset (for directories) */\n#define FMODE_64BITHASH         ((__force fmode_t)0x400)\n\n/*\n * Don't update ctime and mtime.\n *\n * Currently a special hack for the XFS open_by_handle ioctl, but we'll\n * hopefully graduate it to a proper O_CMTIME flag supported by open(2) soon.\n */\n#define FMODE_NOCMTIME\t\t((__force fmode_t)0x800)\n\n/* Expect random access pattern */\n#define FMODE_RANDOM\t\t((__force fmode_t)0x1000)\n\n/* File is huge (eg. /dev/kmem): treat loff_t as unsigned */\n#define FMODE_UNSIGNED_OFFSET\t((__force fmode_t)0x2000)\n\n/* File is opened with O_PATH; almost nothing can be done with it */\n#define FMODE_PATH\t\t((__force fmode_t)0x4000)\n\n/* File needs atomic accesses to f_pos */\n#define FMODE_ATOMIC_POS\t((__force fmode_t)0x8000)\n/* Write access to underlying fs */\n#define FMODE_WRITER\t\t((__force fmode_t)0x10000)\n/* Has read method(s) */\n#define FMODE_CAN_READ          ((__force fmode_t)0x20000)\n/* Has write method(s) */\n#define FMODE_CAN_WRITE         ((__force fmode_t)0x40000)\n\n/* File was opened by fanotify and shouldn't generate fanotify events */\n#define FMODE_NONOTIFY\t\t((__force fmode_t)0x1000000)\n\n/*\n * Flag for rw_copy_check_uvector and compat_rw_copy_check_uvector\n * that indicates that they should check the contents of the iovec are\n * valid, but not check the memory that the iovec elements\n * points too.\n */\n#define CHECK_IOVEC_ONLY -1\n\n/*\n * The below are the various read and write types that we support. Some of\n * them include behavioral modifiers that send information down to the\n * block layer and IO scheduler. Terminology:\n *\n *\tThe block layer uses device plugging to defer IO a little bit, in\n *\tthe hope that we will see more IO very shortly. This increases\n *\tcoalescing of adjacent IO and thus reduces the number of IOs we\n *\thave to send to the device. It also allows for better queuing,\n *\tif the IO isn't mergeable. If the caller is going to be waiting\n *\tfor the IO, then he must ensure that the device is unplugged so\n *\tthat the IO is dispatched to the driver.\n *\n *\tAll IO is handled async in Linux. This is fine for background\n *\twrites, but for reads or writes that someone waits for completion\n *\ton, we want to notify the block layer and IO scheduler so that they\n *\tknow about it. That allows them to make better scheduling\n *\tdecisions. So when the below references 'sync' and 'async', it\n *\tis referencing this priority hint.\n *\n * With that in mind, the available types are:\n *\n * READ\t\t\tA normal read operation. Device will be plugged.\n * READ_SYNC\t\tA synchronous read. Device is not plugged, caller can\n *\t\t\timmediately wait on this read without caring about\n *\t\t\tunplugging.\n * READA\t\tUsed for read-ahead operations. Lower priority, and the\n *\t\t\tblock layer could (in theory) choose to ignore this\n *\t\t\trequest if it runs into resource problems.\n * WRITE\t\tA normal async write. Device will be plugged.\n * WRITE_SYNC\t\tSynchronous write. Identical to WRITE, but passes down\n *\t\t\tthe hint that someone will be waiting on this IO\n *\t\t\tshortly. The write equivalent of READ_SYNC.\n * WRITE_ODIRECT\tSpecial case write for O_DIRECT only.\n * WRITE_FLUSH\t\tLike WRITE_SYNC but with preceding cache flush.\n * WRITE_FUA\t\tLike WRITE_SYNC but data is guaranteed to be on\n *\t\t\tnon-volatile media on completion.\n * WRITE_FLUSH_FUA\tCombination of WRITE_FLUSH and FUA. The IO is preceded\n *\t\t\tby a cache flush and data is guaranteed to be on\n *\t\t\tnon-volatile media on completion.\n *\n */\n#define RW_MASK\t\t\tREQ_WRITE\n#define RWA_MASK\t\tREQ_RAHEAD\n\n#define READ\t\t\t0\n#define WRITE\t\t\tRW_MASK\n#define READA\t\t\tRWA_MASK\n\n#define READ_SYNC\t\t(READ | REQ_SYNC)\n#define WRITE_SYNC\t\t(WRITE | REQ_SYNC | REQ_NOIDLE)\n#define WRITE_ODIRECT\t\t(WRITE | REQ_SYNC)\n#define WRITE_FLUSH\t\t(WRITE | REQ_SYNC | REQ_NOIDLE | REQ_FLUSH)\n#define WRITE_FUA\t\t(WRITE | REQ_SYNC | REQ_NOIDLE | REQ_FUA)\n#define WRITE_FLUSH_FUA\t\t(WRITE | REQ_SYNC | REQ_NOIDLE | REQ_FLUSH | REQ_FUA)\n\n/*\n * Attribute flags.  These should be or-ed together to figure out what\n * has been changed!\n */\n#define ATTR_MODE\t(1 << 0)\n#define ATTR_UID\t(1 << 1)\n#define ATTR_GID\t(1 << 2)\n#define ATTR_SIZE\t(1 << 3)\n#define ATTR_ATIME\t(1 << 4)\n#define ATTR_MTIME\t(1 << 5)\n#define ATTR_CTIME\t(1 << 6)\n#define ATTR_ATIME_SET\t(1 << 7)\n#define ATTR_MTIME_SET\t(1 << 8)\n#define ATTR_FORCE\t(1 << 9) /* Not a change, but a change it */\n#define ATTR_ATTR_FLAG\t(1 << 10)\n#define ATTR_KILL_SUID\t(1 << 11)\n#define ATTR_KILL_SGID\t(1 << 12)\n#define ATTR_FILE\t(1 << 13)\n#define ATTR_KILL_PRIV\t(1 << 14)\n#define ATTR_OPEN\t(1 << 15) /* Truncating from open(O_TRUNC) */\n#define ATTR_TIMES_SET\t(1 << 16)\n\n/*\n * Whiteout is represented by a char device.  The following constants define the\n * mode and device number to use.\n */\n#define WHITEOUT_MODE 0\n#define WHITEOUT_DEV 0\n\n/*\n * This is the Inode Attributes structure, used for notify_change().  It\n * uses the above definitions as flags, to know which values have changed.\n * Also, in this manner, a Filesystem can look at only the values it cares\n * about.  Basically, these are the attributes that the VFS layer can\n * request to change from the FS layer.\n *\n * Derek Atkins <warlord@MIT.EDU> 94-10-20\n */\nstruct iattr {\n\tunsigned int\tia_valid;\n\tumode_t\t\tia_mode;\n\tkuid_t\t\tia_uid;\n\tkgid_t\t\tia_gid;\n\tloff_t\t\tia_size;\n\tstruct timespec\tia_atime;\n\tstruct timespec\tia_mtime;\n\tstruct timespec\tia_ctime;\n\n\t/*\n\t * Not an attribute, but an auxiliary info for filesystems wanting to\n\t * implement an ftruncate() like method.  NOTE: filesystem should\n\t * check for (ia_valid & ATTR_FILE), and not for (ia_file != NULL).\n\t */\n\tstruct file\t*ia_file;\n};\n\n/*\n * Includes for diskquotas.\n */\n#include <linux/quota.h>\n\n/** \n * enum positive_aop_returns - aop return codes with specific semantics\n *\n * @AOP_WRITEPAGE_ACTIVATE: Informs the caller that page writeback has\n * \t\t\t    completed, that the page is still locked, and\n * \t\t\t    should be considered active.  The VM uses this hint\n * \t\t\t    to return the page to the active list -- it won't\n * \t\t\t    be a candidate for writeback again in the near\n * \t\t\t    future.  Other callers must be careful to unlock\n * \t\t\t    the page if they get this return.  Returned by\n * \t\t\t    writepage(); \n *\n * @AOP_TRUNCATED_PAGE: The AOP method that was handed a locked page has\n *  \t\t\tunlocked it and the page might have been truncated.\n *  \t\t\tThe caller should back up to acquiring a new page and\n *  \t\t\ttrying again.  The aop will be taking reasonable\n *  \t\t\tprecautions not to livelock.  If the caller held a page\n *  \t\t\treference, it should drop it before retrying.  Returned\n *  \t\t\tby readpage().\n *\n * address_space_operation functions return these large constants to indicate\n * special semantics to the caller.  These are much larger than the bytes in a\n * page to allow for functions that return the number of bytes operated on in a\n * given page.\n */\n\nenum positive_aop_returns {\n\tAOP_WRITEPAGE_ACTIVATE\t= 0x80000,\n\tAOP_TRUNCATED_PAGE\t= 0x80001,\n};\n\n#define AOP_FLAG_UNINTERRUPTIBLE\t0x0001 /* will not do a short write */\n#define AOP_FLAG_CONT_EXPAND\t\t0x0002 /* called from cont_expand */\n#define AOP_FLAG_NOFS\t\t\t0x0004 /* used by filesystem to direct\n\t\t\t\t\t\t* helper code (eg buffer layer)\n\t\t\t\t\t\t* to clear GFP_FS from alloc */\n\n/*\n * oh the beauties of C type declarations.\n */\nstruct page;\nstruct address_space;\nstruct writeback_control;\n\n/*\n * \"descriptor\" for what we're up to with a read.\n * This allows us to use the same read code yet\n * have multiple different users of the data that\n * we read from a file.\n *\n * The simplest case just copies the data to user\n * mode.\n */\ntypedef struct {\n\tsize_t written;\n\tsize_t count;\n\tunion {\n\t\tchar __user *buf;\n\t\tvoid *data;\n\t} arg;\n\tint error;\n} read_descriptor_t;\n\ntypedef int (*read_actor_t)(read_descriptor_t *, struct page *,\n\t\tunsigned long, unsigned long);\n\nstruct address_space_operations {\n\tint (*writepage)(struct page *page, struct writeback_control *wbc);\n\tint (*readpage)(struct file *, struct page *);\n\n\t/* Write back some dirty pages from this mapping. */\n\tint (*writepages)(struct address_space *, struct writeback_control *);\n\n\t/* Set a page dirty.  Return true if this dirtied it */\n\tint (*set_page_dirty)(struct page *page);\n\n\tint (*readpages)(struct file *filp, struct address_space *mapping,\n\t\t\tstruct list_head *pages, unsigned nr_pages);\n\n\tint (*write_begin)(struct file *, struct address_space *mapping,\n\t\t\t\tloff_t pos, unsigned len, unsigned flags,\n\t\t\t\tstruct page **pagep, void **fsdata);\n\tint (*write_end)(struct file *, struct address_space *mapping,\n\t\t\t\tloff_t pos, unsigned len, unsigned copied,\n\t\t\t\tstruct page *page, void *fsdata);\n\n\t/* Unfortunately this kludge is needed for FIBMAP. Don't use it */\n\tsector_t (*bmap)(struct address_space *, sector_t);\n\tvoid (*invalidatepage) (struct page *, unsigned int, unsigned int);\n\tint (*releasepage) (struct page *, gfp_t);\n\tvoid (*freepage)(struct page *);\n\tssize_t (*direct_IO)(int, struct kiocb *, struct iov_iter *iter, loff_t offset);\n\tint (*get_xip_mem)(struct address_space *, pgoff_t, int,\n\t\t\t\t\t\tvoid **, unsigned long *);\n\t/*\n\t * migrate the contents of a page to the specified target. If\n\t * migrate_mode is MIGRATE_ASYNC, it must not block.\n\t */\n\tint (*migratepage) (struct address_space *,\n\t\t\tstruct page *, struct page *, enum migrate_mode);\n\tint (*launder_page) (struct page *);\n\tint (*is_partially_uptodate) (struct page *, unsigned long,\n\t\t\t\t\tunsigned long);\n\tvoid (*is_dirty_writeback) (struct page *, bool *, bool *);\n\tint (*error_remove_page)(struct address_space *, struct page *);\n\n\t/* swapfile support */\n\tint (*swap_activate)(struct swap_info_struct *sis, struct file *file,\n\t\t\t\tsector_t *span);\n\tvoid (*swap_deactivate)(struct file *file);\n};\n\nextern const struct address_space_operations empty_aops;\n\n/*\n * pagecache_write_begin/pagecache_write_end must be used by general code\n * to write into the pagecache.\n */\nint pagecache_write_begin(struct file *, struct address_space *mapping,\n\t\t\t\tloff_t pos, unsigned len, unsigned flags,\n\t\t\t\tstruct page **pagep, void **fsdata);\n\nint pagecache_write_end(struct file *, struct address_space *mapping,\n\t\t\t\tloff_t pos, unsigned len, unsigned copied,\n\t\t\t\tstruct page *page, void *fsdata);\n\nstruct backing_dev_info;\nstruct address_space {\n\tstruct inode\t\t*host;\t\t/* owner: inode, block_device */\n\tstruct radix_tree_root\tpage_tree;\t/* radix tree of all pages */\n\tspinlock_t\t\ttree_lock;\t/* and lock protecting it */\n\tatomic_t\t\ti_mmap_writable;/* count VM_SHARED mappings */\n\tstruct rb_root\t\ti_mmap;\t\t/* tree of private and shared mappings */\n\tstruct list_head\ti_mmap_nonlinear;/*list VM_NONLINEAR mappings */\n\tstruct mutex\t\ti_mmap_mutex;\t/* protect tree, count, list */\n\t/* Protected by tree_lock together with the radix tree */\n\tunsigned long\t\tnrpages;\t/* number of total pages */\n\tunsigned long\t\tnrshadows;\t/* number of shadow entries */\n\tpgoff_t\t\t\twriteback_index;/* writeback starts here */\n\tconst struct address_space_operations *a_ops;\t/* methods */\n\tunsigned long\t\tflags;\t\t/* error bits/gfp mask */\n\tstruct backing_dev_info *backing_dev_info; /* device readahead, etc */\n\tspinlock_t\t\tprivate_lock;\t/* for use by the address_space */\n\tstruct list_head\tprivate_list;\t/* ditto */\n\tvoid\t\t\t*private_data;\t/* ditto */\n} __attribute__((aligned(sizeof(long))));\n\t/*\n\t * On most architectures that alignment is already the case; but\n\t * must be enforced here for CRIS, to let the least significant bit\n\t * of struct page's \"mapping\" pointer be used for PAGE_MAPPING_ANON.\n\t */\nstruct request_queue;\n\nstruct block_device {\n\tdev_t\t\t\tbd_dev;  /* not a kdev_t - it's a search key */\n\tint\t\t\tbd_openers;\n\tstruct inode *\t\tbd_inode;\t/* will die */\n\tstruct super_block *\tbd_super;\n\tstruct mutex\t\tbd_mutex;\t/* open/close mutex */\n\tstruct list_head\tbd_inodes;\n\tvoid *\t\t\tbd_claiming;\n\tvoid *\t\t\tbd_holder;\n\tint\t\t\tbd_holders;\n\tbool\t\t\tbd_write_holder;\n#ifdef CONFIG_SYSFS\n\tstruct list_head\tbd_holder_disks;\n#endif\n\tstruct block_device *\tbd_contains;\n\tunsigned\t\tbd_block_size;\n\tstruct hd_struct *\tbd_part;\n\t/* number of times partitions within this device have been opened. */\n\tunsigned\t\tbd_part_count;\n\tint\t\t\tbd_invalidated;\n\tstruct gendisk *\tbd_disk;\n\tstruct request_queue *  bd_queue;\n\tstruct list_head\tbd_list;\n\t/*\n\t * Private data.  You must have bd_claim'ed the block_device\n\t * to use this.  NOTE:  bd_claim allows an owner to claim\n\t * the same device multiple times, the owner must take special\n\t * care to not mess up bd_private for that case.\n\t */\n\tunsigned long\t\tbd_private;\n\n\t/* The counter of freeze processes */\n\tint\t\t\tbd_fsfreeze_count;\n\t/* Mutex for freeze */\n\tstruct mutex\t\tbd_fsfreeze_mutex;\n};\n\n/*\n * Radix-tree tags, for tagging dirty and writeback pages within the pagecache\n * radix trees\n */\n#define PAGECACHE_TAG_DIRTY\t0\n#define PAGECACHE_TAG_WRITEBACK\t1\n#define PAGECACHE_TAG_TOWRITE\t2\n\nint mapping_tagged(struct address_space *mapping, int tag);\n\n/*\n * Might pages of this file be mapped into userspace?\n */\nstatic inline int mapping_mapped(struct address_space *mapping)\n{\n\treturn\t!RB_EMPTY_ROOT(&mapping->i_mmap) ||\n\t\t!list_empty(&mapping->i_mmap_nonlinear);\n}\n\n/*\n * Might pages of this file have been modified in userspace?\n * Note that i_mmap_writable counts all VM_SHARED vmas: do_mmap_pgoff\n * marks vma as VM_SHARED if it is shared, and the file was opened for\n * writing i.e. vma may be mprotected writable even if now readonly.\n *\n * If i_mmap_writable is negative, no new writable mappings are allowed. You\n * can only deny writable mappings, if none exists right now.\n */\nstatic inline int mapping_writably_mapped(struct address_space *mapping)\n{\n\treturn atomic_read(&mapping->i_mmap_writable) > 0;\n}\n\nstatic inline int mapping_map_writable(struct address_space *mapping)\n{\n\treturn atomic_inc_unless_negative(&mapping->i_mmap_writable) ?\n\t\t0 : -EPERM;\n}\n\nstatic inline void mapping_unmap_writable(struct address_space *mapping)\n{\n\tatomic_dec(&mapping->i_mmap_writable);\n}\n\nstatic inline int mapping_deny_writable(struct address_space *mapping)\n{\n\treturn atomic_dec_unless_positive(&mapping->i_mmap_writable) ?\n\t\t0 : -EBUSY;\n}\n\nstatic inline void mapping_allow_writable(struct address_space *mapping)\n{\n\tatomic_inc(&mapping->i_mmap_writable);\n}\n\n/*\n * Use sequence counter to get consistent i_size on 32-bit processors.\n */\n#if BITS_PER_LONG==32 && defined(CONFIG_SMP)\n#include <linux/seqlock.h>\n#define __NEED_I_SIZE_ORDERED\n#define i_size_ordered_init(inode) seqcount_init(&inode->i_size_seqcount)\n#else\n#define i_size_ordered_init(inode) do { } while (0)\n#endif\n\nstruct posix_acl;\n#define ACL_NOT_CACHED ((void *)(-1))\n\n#define IOP_FASTPERM\t0x0001\n#define IOP_LOOKUP\t0x0002\n#define IOP_NOFOLLOW\t0x0004\n\n/*\n * Keep mostly read-only and often accessed (especially for\n * the RCU path lookup and 'stat' data) fields at the beginning\n * of the 'struct inode'\n */\nstruct inode {\n\tumode_t\t\t\ti_mode;\n\tunsigned short\t\ti_opflags;\n\tkuid_t\t\t\ti_uid;\n\tkgid_t\t\t\ti_gid;\n\tunsigned int\t\ti_flags;\n\n#ifdef CONFIG_FS_POSIX_ACL\n\tstruct posix_acl\t*i_acl;\n\tstruct posix_acl\t*i_default_acl;\n#endif\n\n\tconst struct inode_operations\t*i_op;\n\tstruct super_block\t*i_sb;\n\tstruct address_space\t*i_mapping;\n\n#ifdef CONFIG_SECURITY\n\tvoid\t\t\t*i_security;\n#endif\n\n\t/* Stat data, not accessed from path walking */\n\tunsigned long\t\ti_ino;\n\t/*\n\t * Filesystems may only read i_nlink directly.  They shall use the\n\t * following functions for modification:\n\t *\n\t *    (set|clear|inc|drop)_nlink\n\t *    inode_(inc|dec)_link_count\n\t */\n\tunion {\n\t\tconst unsigned int i_nlink;\n\t\tunsigned int __i_nlink;\n\t};\n\tdev_t\t\t\ti_rdev;\n\tloff_t\t\t\ti_size;\n\tstruct timespec\t\ti_atime;\n\tstruct timespec\t\ti_mtime;\n\tstruct timespec\t\ti_ctime;\n\tspinlock_t\t\ti_lock;\t/* i_blocks, i_bytes, maybe i_size */\n\tunsigned short          i_bytes;\n\tunsigned int\t\ti_blkbits;\n\tblkcnt_t\t\ti_blocks;\n\n#ifdef __NEED_I_SIZE_ORDERED\n\tseqcount_t\t\ti_size_seqcount;\n#endif\n\n\t/* Misc */\n\tunsigned long\t\ti_state;\n\tstruct mutex\t\ti_mutex;\n\n\tunsigned long\t\tdirtied_when;\t/* jiffies of first dirtying */\n\n\tstruct hlist_node\ti_hash;\n\tstruct list_head\ti_wb_list;\t/* backing dev IO list */\n\tstruct list_head\ti_lru;\t\t/* inode LRU list */\n\tstruct list_head\ti_sb_list;\n\tunion {\n\t\tstruct hlist_head\ti_dentry;\n\t\tstruct rcu_head\t\ti_rcu;\n\t};\n\tu64\t\t\ti_version;\n\tatomic_t\t\ti_count;\n\tatomic_t\t\ti_dio_count;\n\tatomic_t\t\ti_writecount;\n#ifdef CONFIG_IMA\n\tatomic_t\t\ti_readcount; /* struct files open RO */\n#endif\n\tconst struct file_operations\t*i_fop;\t/* former ->i_op->default_file_ops */\n\tstruct file_lock\t*i_flock;\n\tstruct address_space\ti_data;\n#ifdef CONFIG_QUOTA\n\tstruct dquot\t\t*i_dquot[MAXQUOTAS];\n#endif\n\tstruct list_head\ti_devices;\n\tunion {\n\t\tstruct pipe_inode_info\t*i_pipe;\n\t\tstruct block_device\t*i_bdev;\n\t\tstruct cdev\t\t*i_cdev;\n\t};\n\n\t__u32\t\t\ti_generation;\n\n#ifdef CONFIG_FSNOTIFY\n\t__u32\t\t\ti_fsnotify_mask; /* all events this inode cares about */\n\tstruct hlist_head\ti_fsnotify_marks;\n#endif\n\n\tvoid\t\t\t*i_private; /* fs or device private pointer */\n};\n\nstatic inline int inode_unhashed(struct inode *inode)\n{\n\treturn hlist_unhashed(&inode->i_hash);\n}\n\n/*\n * inode->i_mutex nesting subclasses for the lock validator:\n *\n * 0: the object of the current VFS operation\n * 1: parent\n * 2: child/target\n * 3: xattr\n * 4: second non-directory\n * The last is for certain operations (such as rename) which lock two\n * non-directories at once.\n *\n * The locking order between these classes is\n * parent -> child -> normal -> xattr -> second non-directory\n */\nenum inode_i_mutex_lock_class\n{\n\tI_MUTEX_NORMAL,\n\tI_MUTEX_PARENT,\n\tI_MUTEX_CHILD,\n\tI_MUTEX_XATTR,\n\tI_MUTEX_NONDIR2\n};\n\nvoid lock_two_nondirectories(struct inode *, struct inode*);\nvoid unlock_two_nondirectories(struct inode *, struct inode*);\n\n/*\n * NOTE: in a 32bit arch with a preemptable kernel and\n * an UP compile the i_size_read/write must be atomic\n * with respect to the local cpu (unlike with preempt disabled),\n * but they don't need to be atomic with respect to other cpus like in\n * true SMP (so they need either to either locally disable irq around\n * the read or for example on x86 they can be still implemented as a\n * cmpxchg8b without the need of the lock prefix). For SMP compiles\n * and 64bit archs it makes no difference if preempt is enabled or not.\n */\nstatic inline loff_t i_size_read(const struct inode *inode)\n{\n#if BITS_PER_LONG==32 && defined(CONFIG_SMP)\n\tloff_t i_size;\n\tunsigned int seq;\n\n\tdo {\n\t\tseq = read_seqcount_begin(&inode->i_size_seqcount);\n\t\ti_size = inode->i_size;\n\t} while (read_seqcount_retry(&inode->i_size_seqcount, seq));\n\treturn i_size;\n#elif BITS_PER_LONG==32 && defined(CONFIG_PREEMPT)\n\tloff_t i_size;\n\n\tpreempt_disable();\n\ti_size = inode->i_size;\n\tpreempt_enable();\n\treturn i_size;\n#else\n\treturn inode->i_size;\n#endif\n}\n\n/*\n * NOTE: unlike i_size_read(), i_size_write() does need locking around it\n * (normally i_mutex), otherwise on 32bit/SMP an update of i_size_seqcount\n * can be lost, resulting in subsequent i_size_read() calls spinning forever.\n */\nstatic inline void i_size_write(struct inode *inode, loff_t i_size)\n{\n#if BITS_PER_LONG==32 && defined(CONFIG_SMP)\n\tpreempt_disable();\n\twrite_seqcount_begin(&inode->i_size_seqcount);\n\tinode->i_size = i_size;\n\twrite_seqcount_end(&inode->i_size_seqcount);\n\tpreempt_enable();\n#elif BITS_PER_LONG==32 && defined(CONFIG_PREEMPT)\n\tpreempt_disable();\n\tinode->i_size = i_size;\n\tpreempt_enable();\n#else\n\tinode->i_size = i_size;\n#endif\n}\n\n/* Helper functions so that in most cases filesystems will\n * not need to deal directly with kuid_t and kgid_t and can\n * instead deal with the raw numeric values that are stored\n * in the filesystem.\n */\nstatic inline uid_t i_uid_read(const struct inode *inode)\n{\n\treturn from_kuid(&init_user_ns, inode->i_uid);\n}\n\nstatic inline gid_t i_gid_read(const struct inode *inode)\n{\n\treturn from_kgid(&init_user_ns, inode->i_gid);\n}\n\nstatic inline void i_uid_write(struct inode *inode, uid_t uid)\n{\n\tinode->i_uid = make_kuid(&init_user_ns, uid);\n}\n\nstatic inline void i_gid_write(struct inode *inode, gid_t gid)\n{\n\tinode->i_gid = make_kgid(&init_user_ns, gid);\n}\n\nstatic inline unsigned iminor(const struct inode *inode)\n{\n\treturn MINOR(inode->i_rdev);\n}\n\nstatic inline unsigned imajor(const struct inode *inode)\n{\n\treturn MAJOR(inode->i_rdev);\n}\n\nextern struct block_device *I_BDEV(struct inode *inode);\n\nstruct fown_struct {\n\trwlock_t lock;          /* protects pid, uid, euid fields */\n\tstruct pid *pid;\t/* pid or -pgrp where SIGIO should be sent */\n\tenum pid_type pid_type;\t/* Kind of process group SIGIO should be sent to */\n\tkuid_t uid, euid;\t/* uid/euid of process setting the owner */\n\tint signum;\t\t/* posix.1b rt signal to be delivered on IO */\n};\n\n/*\n * Track a single file's readahead state\n */\nstruct file_ra_state {\n\tpgoff_t start;\t\t\t/* where readahead started */\n\tunsigned int size;\t\t/* # of readahead pages */\n\tunsigned int async_size;\t/* do asynchronous readahead when\n\t\t\t\t\t   there are only # of pages ahead */\n\n\tunsigned int ra_pages;\t\t/* Maximum readahead window */\n\tunsigned int mmap_miss;\t\t/* Cache miss stat for mmap accesses */\n\tloff_t prev_pos;\t\t/* Cache last read() position */\n};\n\n/*\n * Check if @index falls in the readahead windows.\n */\nstatic inline int ra_has_index(struct file_ra_state *ra, pgoff_t index)\n{\n\treturn (index >= ra->start &&\n\t\tindex <  ra->start + ra->size);\n}\n\nstruct file {\n\tunion {\n\t\tstruct llist_node\tfu_llist;\n\t\tstruct rcu_head \tfu_rcuhead;\n\t} f_u;\n\tstruct path\t\tf_path;\n#define f_dentry\tf_path.dentry\n\tstruct inode\t\t*f_inode;\t/* cached value */\n\tconst struct file_operations\t*f_op;\n\n\t/*\n\t * Protects f_ep_links, f_flags.\n\t * Must not be taken from IRQ context.\n\t */\n\tspinlock_t\t\tf_lock;\n\tatomic_long_t\t\tf_count;\n\tunsigned int \t\tf_flags;\n\tfmode_t\t\t\tf_mode;\n\tstruct mutex\t\tf_pos_lock;\n\tloff_t\t\t\tf_pos;\n\tstruct fown_struct\tf_owner;\n\tconst struct cred\t*f_cred;\n\tstruct file_ra_state\tf_ra;\n\n\tu64\t\t\tf_version;\n#ifdef CONFIG_SECURITY\n\tvoid\t\t\t*f_security;\n#endif\n\t/* needed for tty driver, and maybe others */\n\tvoid\t\t\t*private_data;\n\n#ifdef CONFIG_EPOLL\n\t/* Used by fs/eventpoll.c to link all the hooks to this file */\n\tstruct list_head\tf_ep_links;\n\tstruct list_head\tf_tfile_llink;\n#endif /* #ifdef CONFIG_EPOLL */\n\tstruct address_space\t*f_mapping;\n} __attribute__((aligned(4)));\t/* lest something weird decides that 2 is OK */\n\nstruct file_handle {\n\t__u32 handle_bytes;\n\tint handle_type;\n\t/* file identifier */\n\tunsigned char f_handle[0];\n};\n\nstatic inline struct file *get_file(struct file *f)\n{\n\tatomic_long_inc(&f->f_count);\n\treturn f;\n}\n#define fput_atomic(x)\tatomic_long_add_unless(&(x)->f_count, -1, 1)\n#define file_count(x)\tatomic_long_read(&(x)->f_count)\n\n#define\tMAX_NON_LFS\t((1UL<<31) - 1)\n\n/* Page cache limit. The filesystems should put that into their s_maxbytes \n   limits, otherwise bad things can happen in VM. */ \n#if BITS_PER_LONG==32\n#define MAX_LFS_FILESIZE\t(((loff_t)PAGE_CACHE_SIZE << (BITS_PER_LONG-1))-1) \n#elif BITS_PER_LONG==64\n#define MAX_LFS_FILESIZE \t((loff_t)0x7fffffffffffffffLL)\n#endif\n\n#define FL_POSIX\t1\n#define FL_FLOCK\t2\n#define FL_DELEG\t4\t/* NFSv4 delegation */\n#define FL_ACCESS\t8\t/* not trying to lock, just looking */\n#define FL_EXISTS\t16\t/* when unlocking, test for existence */\n#define FL_LEASE\t32\t/* lease held on this file */\n#define FL_CLOSE\t64\t/* unlock on close */\n#define FL_SLEEP\t128\t/* A blocking lock */\n#define FL_DOWNGRADE_PENDING\t256 /* Lease is being downgraded */\n#define FL_UNLOCK_PENDING\t512 /* Lease is being broken */\n#define FL_OFDLCK\t1024\t/* lock is \"owned\" by struct file */\n\n/*\n * Special return value from posix_lock_file() and vfs_lock_file() for\n * asynchronous locking.\n */\n#define FILE_LOCK_DEFERRED 1\n\n/* legacy typedef, should eventually be removed */\ntypedef void *fl_owner_t;\n\nstruct file_lock_operations {\n\tvoid (*fl_copy_lock)(struct file_lock *, struct file_lock *);\n\tvoid (*fl_release_private)(struct file_lock *);\n};\n\nstruct lock_manager_operations {\n\tint (*lm_compare_owner)(struct file_lock *, struct file_lock *);\n\tunsigned long (*lm_owner_key)(struct file_lock *);\n\tvoid (*lm_get_owner)(struct file_lock *, struct file_lock *);\n\tvoid (*lm_put_owner)(struct file_lock *);\n\tvoid (*lm_notify)(struct file_lock *);\t/* unblock callback */\n\tint (*lm_grant)(struct file_lock *, int);\n\tbool (*lm_break)(struct file_lock *);\n\tint (*lm_change)(struct file_lock **, int, struct list_head *);\n\tvoid (*lm_setup)(struct file_lock *, void **);\n};\n\nstruct lock_manager {\n\tstruct list_head list;\n};\n\nstruct net;\nvoid locks_start_grace(struct net *, struct lock_manager *);\nvoid locks_end_grace(struct lock_manager *);\nint locks_in_grace(struct net *);\n\n/* that will die - we need it for nfs_lock_info */\n#include <linux/nfs_fs_i.h>\n\n/*\n * struct file_lock represents a generic \"file lock\". It's used to represent\n * POSIX byte range locks, BSD (flock) locks, and leases. It's important to\n * note that the same struct is used to represent both a request for a lock and\n * the lock itself, but the same object is never used for both.\n *\n * FIXME: should we create a separate \"struct lock_request\" to help distinguish\n * these two uses?\n *\n * The i_flock list is ordered by:\n *\n * 1) lock type -- FL_LEASEs first, then FL_FLOCK, and finally FL_POSIX\n * 2) lock owner\n * 3) lock range start\n * 4) lock range end\n *\n * Obviously, the last two criteria only matter for POSIX locks.\n */\nstruct file_lock {\n\tstruct file_lock *fl_next;\t/* singly linked list for this inode  */\n\tstruct hlist_node fl_link;\t/* node in global lists */\n\tstruct list_head fl_block;\t/* circular list of blocked processes */\n\tfl_owner_t fl_owner;\n\tunsigned int fl_flags;\n\tunsigned char fl_type;\n\tunsigned int fl_pid;\n\tint fl_link_cpu;\t\t/* what cpu's list is this on? */\n\tstruct pid *fl_nspid;\n\twait_queue_head_t fl_wait;\n\tstruct file *fl_file;\n\tloff_t fl_start;\n\tloff_t fl_end;\n\n\tstruct fasync_struct *\tfl_fasync; /* for lease break notifications */\n\t/* for lease breaks: */\n\tunsigned long fl_break_time;\n\tunsigned long fl_downgrade_time;\n\n\tconst struct file_lock_operations *fl_ops;\t/* Callbacks for filesystems */\n\tconst struct lock_manager_operations *fl_lmops;\t/* Callbacks for lockmanagers */\n\tunion {\n\t\tstruct nfs_lock_info\tnfs_fl;\n\t\tstruct nfs4_lock_info\tnfs4_fl;\n\t\tstruct {\n\t\t\tstruct list_head link;\t/* link in AFS vnode's pending_locks list */\n\t\t\tint state;\t\t/* state of grant or error if -ve */\n\t\t} afs;\n\t} fl_u;\n};\n\n/* The following constant reflects the upper bound of the file/locking space */\n#ifndef OFFSET_MAX\n#define INT_LIMIT(x)\t(~((x)1 << (sizeof(x)*8 - 1)))\n#define OFFSET_MAX\tINT_LIMIT(loff_t)\n#define OFFT_OFFSET_MAX\tINT_LIMIT(off_t)\n#endif\n\n#include <linux/fcntl.h>\n\nextern void send_sigio(struct fown_struct *fown, int fd, int band);\n\n#ifdef CONFIG_FILE_LOCKING\nextern int fcntl_getlk(struct file *, unsigned int, struct flock __user *);\nextern int fcntl_setlk(unsigned int, struct file *, unsigned int,\n\t\t\tstruct flock __user *);\n\n#if BITS_PER_LONG == 32\nextern int fcntl_getlk64(struct file *, unsigned int, struct flock64 __user *);\nextern int fcntl_setlk64(unsigned int, struct file *, unsigned int,\n\t\t\tstruct flock64 __user *);\n#endif\n\nextern int fcntl_setlease(unsigned int fd, struct file *filp, long arg);\nextern int fcntl_getlease(struct file *filp);\n\n/* fs/locks.c */\nvoid locks_free_lock(struct file_lock *fl);\nextern void locks_init_lock(struct file_lock *);\nextern struct file_lock * locks_alloc_lock(void);\nextern void locks_copy_lock(struct file_lock *, struct file_lock *);\nextern void locks_copy_conflock(struct file_lock *, struct file_lock *);\nextern void locks_remove_posix(struct file *, fl_owner_t);\nextern void locks_remove_file(struct file *);\nextern void locks_release_private(struct file_lock *);\nextern void posix_test_lock(struct file *, struct file_lock *);\nextern int posix_lock_file(struct file *, struct file_lock *, struct file_lock *);\nextern int posix_lock_file_wait(struct file *, struct file_lock *);\nextern int posix_unblock_lock(struct file_lock *);\nextern int vfs_test_lock(struct file *, struct file_lock *);\nextern int vfs_lock_file(struct file *, unsigned int, struct file_lock *, struct file_lock *);\nextern int vfs_cancel_lock(struct file *filp, struct file_lock *fl);\nextern int flock_lock_file_wait(struct file *filp, struct file_lock *fl);\nextern int __break_lease(struct inode *inode, unsigned int flags, unsigned int type);\nextern void lease_get_mtime(struct inode *, struct timespec *time);\nextern int generic_setlease(struct file *, long, struct file_lock **, void **priv);\nextern int vfs_setlease(struct file *, long, struct file_lock **, void **);\nextern int lease_modify(struct file_lock **, int, struct list_head *);\n#else /* !CONFIG_FILE_LOCKING */\nstatic inline int fcntl_getlk(struct file *file, unsigned int cmd,\n\t\t\t      struct flock __user *user)\n{\n\treturn -EINVAL;\n}\n\nstatic inline int fcntl_setlk(unsigned int fd, struct file *file,\n\t\t\t      unsigned int cmd, struct flock __user *user)\n{\n\treturn -EACCES;\n}\n\n#if BITS_PER_LONG == 32\nstatic inline int fcntl_getlk64(struct file *file, unsigned int cmd,\n\t\t\t\tstruct flock64 __user *user)\n{\n\treturn -EINVAL;\n}\n\nstatic inline int fcntl_setlk64(unsigned int fd, struct file *file,\n\t\t\t\tunsigned int cmd, struct flock64 __user *user)\n{\n\treturn -EACCES;\n}\n#endif\nstatic inline int fcntl_setlease(unsigned int fd, struct file *filp, long arg)\n{\n\treturn -EINVAL;\n}\n\nstatic inline int fcntl_getlease(struct file *filp)\n{\n\treturn F_UNLCK;\n}\n\nstatic inline void locks_init_lock(struct file_lock *fl)\n{\n\treturn;\n}\n\nstatic inline void locks_copy_conflock(struct file_lock *new, struct file_lock *fl)\n{\n\treturn;\n}\n\nstatic inline void locks_copy_lock(struct file_lock *new, struct file_lock *fl)\n{\n\treturn;\n}\n\nstatic inline void locks_remove_posix(struct file *filp, fl_owner_t owner)\n{\n\treturn;\n}\n\nstatic inline void locks_remove_file(struct file *filp)\n{\n\treturn;\n}\n\nstatic inline void posix_test_lock(struct file *filp, struct file_lock *fl)\n{\n\treturn;\n}\n\nstatic inline int posix_lock_file(struct file *filp, struct file_lock *fl,\n\t\t\t\t  struct file_lock *conflock)\n{\n\treturn -ENOLCK;\n}\n\nstatic inline int posix_lock_file_wait(struct file *filp, struct file_lock *fl)\n{\n\treturn -ENOLCK;\n}\n\nstatic inline int posix_unblock_lock(struct file_lock *waiter)\n{\n\treturn -ENOENT;\n}\n\nstatic inline int vfs_test_lock(struct file *filp, struct file_lock *fl)\n{\n\treturn 0;\n}\n\nstatic inline int vfs_lock_file(struct file *filp, unsigned int cmd,\n\t\t\t\tstruct file_lock *fl, struct file_lock *conf)\n{\n\treturn -ENOLCK;\n}\n\nstatic inline int vfs_cancel_lock(struct file *filp, struct file_lock *fl)\n{\n\treturn 0;\n}\n\nstatic inline int flock_lock_file_wait(struct file *filp,\n\t\t\t\t       struct file_lock *request)\n{\n\treturn -ENOLCK;\n}\n\nstatic inline int __break_lease(struct inode *inode, unsigned int mode, unsigned int type)\n{\n\treturn 0;\n}\n\nstatic inline void lease_get_mtime(struct inode *inode, struct timespec *time)\n{\n\treturn;\n}\n\nstatic inline int generic_setlease(struct file *filp, long arg,\n\t\t\t\t    struct file_lock **flp, void **priv)\n{\n\treturn -EINVAL;\n}\n\nstatic inline int vfs_setlease(struct file *filp, long arg,\n\t\t\t       struct file_lock **lease, void **priv)\n{\n\treturn -EINVAL;\n}\n\nstatic inline int lease_modify(struct file_lock **before, int arg,\n\t\t\t       struct list_head *dispose)\n{\n\treturn -EINVAL;\n}\n#endif /* !CONFIG_FILE_LOCKING */\n\n\nstruct fasync_struct {\n\tspinlock_t\t\tfa_lock;\n\tint\t\t\tmagic;\n\tint\t\t\tfa_fd;\n\tstruct fasync_struct\t*fa_next; /* singly linked list */\n\tstruct file\t\t*fa_file;\n\tstruct rcu_head\t\tfa_rcu;\n};\n\n#define FASYNC_MAGIC 0x4601\n\n/* SMP safe fasync helpers: */\nextern int fasync_helper(int, struct file *, int, struct fasync_struct **);\nextern struct fasync_struct *fasync_insert_entry(int, struct file *, struct fasync_struct **, struct fasync_struct *);\nextern int fasync_remove_entry(struct file *, struct fasync_struct **);\nextern struct fasync_struct *fasync_alloc(void);\nextern void fasync_free(struct fasync_struct *);\n\n/* can be called from interrupts */\nextern void kill_fasync(struct fasync_struct **, int, int);\n\nextern void __f_setown(struct file *filp, struct pid *, enum pid_type, int force);\nextern void f_setown(struct file *filp, unsigned long arg, int force);\nextern void f_delown(struct file *filp);\nextern pid_t f_getown(struct file *filp);\nextern int send_sigurg(struct fown_struct *fown);\n\nstruct mm_struct;\n\n/*\n *\tUmount options\n */\n\n#define MNT_FORCE\t0x00000001\t/* Attempt to forcibily umount */\n#define MNT_DETACH\t0x00000002\t/* Just detach from the tree */\n#define MNT_EXPIRE\t0x00000004\t/* Mark for expiry */\n#define UMOUNT_NOFOLLOW\t0x00000008\t/* Don't follow symlink on umount */\n#define UMOUNT_UNUSED\t0x80000000\t/* Flag guaranteed to be unused */\n\nextern struct list_head super_blocks;\nextern spinlock_t sb_lock;\n\n/* Possible states of 'frozen' field */\nenum {\n\tSB_UNFROZEN = 0,\t\t/* FS is unfrozen */\n\tSB_FREEZE_WRITE\t= 1,\t\t/* Writes, dir ops, ioctls frozen */\n\tSB_FREEZE_PAGEFAULT = 2,\t/* Page faults stopped as well */\n\tSB_FREEZE_FS = 3,\t\t/* For internal FS use (e.g. to stop\n\t\t\t\t\t * internal threads if needed) */\n\tSB_FREEZE_COMPLETE = 4,\t\t/* ->freeze_fs finished successfully */\n};\n\n#define SB_FREEZE_LEVELS (SB_FREEZE_COMPLETE - 1)\n\nstruct sb_writers {\n\t/* Counters for counting writers at each level */\n\tstruct percpu_counter\tcounter[SB_FREEZE_LEVELS];\n\twait_queue_head_t\twait;\t\t/* queue for waiting for\n\t\t\t\t\t\t   writers / faults to finish */\n\tint\t\t\tfrozen;\t\t/* Is sb frozen? */\n\twait_queue_head_t\twait_unfrozen;\t/* queue for waiting for\n\t\t\t\t\t\t   sb to be thawed */\n#ifdef CONFIG_DEBUG_LOCK_ALLOC\n\tstruct lockdep_map\tlock_map[SB_FREEZE_LEVELS];\n#endif\n};\n\nstruct super_block {\n\tstruct list_head\ts_list;\t\t/* Keep this first */\n\tdev_t\t\t\ts_dev;\t\t/* search index; _not_ kdev_t */\n\tunsigned char\t\ts_blocksize_bits;\n\tunsigned long\t\ts_blocksize;\n\tloff_t\t\t\ts_maxbytes;\t/* Max file size */\n\tstruct file_system_type\t*s_type;\n\tconst struct super_operations\t*s_op;\n\tconst struct dquot_operations\t*dq_op;\n\tconst struct quotactl_ops\t*s_qcop;\n\tconst struct export_operations *s_export_op;\n\tunsigned long\t\ts_flags;\n\tunsigned long\t\ts_magic;\n\tstruct dentry\t\t*s_root;\n\tstruct rw_semaphore\ts_umount;\n\tint\t\t\ts_count;\n\tatomic_t\t\ts_active;\n#ifdef CONFIG_SECURITY\n\tvoid                    *s_security;\n#endif\n\tconst struct xattr_handler **s_xattr;\n\n\tstruct list_head\ts_inodes;\t/* all inodes */\n\tstruct hlist_bl_head\ts_anon;\t\t/* anonymous dentries for (nfs) exporting */\n\tstruct list_head\ts_mounts;\t/* list of mounts; _not_ for fs use */\n\tstruct block_device\t*s_bdev;\n\tstruct backing_dev_info *s_bdi;\n\tstruct mtd_info\t\t*s_mtd;\n\tstruct hlist_node\ts_instances;\n\tstruct quota_info\ts_dquot;\t/* Diskquota specific options */\n\n\tstruct sb_writers\ts_writers;\n\n\tchar s_id[32];\t\t\t\t/* Informational name */\n\tu8 s_uuid[16];\t\t\t\t/* UUID */\n\n\tvoid \t\t\t*s_fs_info;\t/* Filesystem private info */\n\tunsigned int\t\ts_max_links;\n\tfmode_t\t\t\ts_mode;\n\n\t/* Granularity of c/m/atime in ns.\n\t   Cannot be worse than a second */\n\tu32\t\t   s_time_gran;\n\n\t/*\n\t * The next field is for VFS *only*. No filesystems have any business\n\t * even looking at it. You had been warned.\n\t */\n\tstruct mutex s_vfs_rename_mutex;\t/* Kludge */\n\n\t/*\n\t * Filesystem subtype.  If non-empty the filesystem type field\n\t * in /proc/mounts will be \"type.subtype\"\n\t */\n\tchar *s_subtype;\n\n\t/*\n\t * Saved mount options for lazy filesystems using\n\t * generic_show_options()\n\t */\n\tchar __rcu *s_options;\n\tconst struct dentry_operations *s_d_op; /* default d_op for dentries */\n\n\t/*\n\t * Saved pool identifier for cleancache (-1 means none)\n\t */\n\tint cleancache_poolid;\n\n\tstruct shrinker s_shrink;\t/* per-sb shrinker handle */\n\n\t/* Number of inodes with nlink == 0 but still referenced */\n\tatomic_long_t s_remove_count;\n\n\t/* Being remounted read-only */\n\tint s_readonly_remount;\n\n\t/* AIO completions deferred from interrupt context */\n\tstruct workqueue_struct *s_dio_done_wq;\n\tstruct hlist_head s_pins;\n\n\t/*\n\t * Keep the lru lists last in the structure so they always sit on their\n\t * own individual cachelines.\n\t */\n\tstruct list_lru\t\ts_dentry_lru ____cacheline_aligned_in_smp;\n\tstruct list_lru\t\ts_inode_lru ____cacheline_aligned_in_smp;\n\tstruct rcu_head\t\trcu;\n};\n\nextern struct timespec current_fs_time(struct super_block *sb);\n\n/*\n * Snapshotting support.\n */\n\nvoid __sb_end_write(struct super_block *sb, int level);\nint __sb_start_write(struct super_block *sb, int level, bool wait);\n\n/**\n * sb_end_write - drop write access to a superblock\n * @sb: the super we wrote to\n *\n * Decrement number of writers to the filesystem. Wake up possible waiters\n * wanting to freeze the filesystem.\n */\nstatic inline void sb_end_write(struct super_block *sb)\n{\n\t__sb_end_write(sb, SB_FREEZE_WRITE);\n}\n\n/**\n * sb_end_pagefault - drop write access to a superblock from a page fault\n * @sb: the super we wrote to\n *\n * Decrement number of processes handling write page fault to the filesystem.\n * Wake up possible waiters wanting to freeze the filesystem.\n */\nstatic inline void sb_end_pagefault(struct super_block *sb)\n{\n\t__sb_end_write(sb, SB_FREEZE_PAGEFAULT);\n}\n\n/**\n * sb_end_intwrite - drop write access to a superblock for internal fs purposes\n * @sb: the super we wrote to\n *\n * Decrement fs-internal number of writers to the filesystem.  Wake up possible\n * waiters wanting to freeze the filesystem.\n */\nstatic inline void sb_end_intwrite(struct super_block *sb)\n{\n\t__sb_end_write(sb, SB_FREEZE_FS);\n}\n\n/**\n * sb_start_write - get write access to a superblock\n * @sb: the super we write to\n *\n * When a process wants to write data or metadata to a file system (i.e. dirty\n * a page or an inode), it should embed the operation in a sb_start_write() -\n * sb_end_write() pair to get exclusion against file system freezing. This\n * function increments number of writers preventing freezing. If the file\n * system is already frozen, the function waits until the file system is\n * thawed.\n *\n * Since freeze protection behaves as a lock, users have to preserve\n * ordering of freeze protection and other filesystem locks. Generally,\n * freeze protection should be the outermost lock. In particular, we have:\n *\n * sb_start_write\n *   -> i_mutex\t\t\t(write path, truncate, directory ops, ...)\n *   -> s_umount\t\t(freeze_super, thaw_super)\n */\nstatic inline void sb_start_write(struct super_block *sb)\n{\n\t__sb_start_write(sb, SB_FREEZE_WRITE, true);\n}\n\nstatic inline int sb_start_write_trylock(struct super_block *sb)\n{\n\treturn __sb_start_write(sb, SB_FREEZE_WRITE, false);\n}\n\n/**\n * sb_start_pagefault - get write access to a superblock from a page fault\n * @sb: the super we write to\n *\n * When a process starts handling write page fault, it should embed the\n * operation into sb_start_pagefault() - sb_end_pagefault() pair to get\n * exclusion against file system freezing. This is needed since the page fault\n * is going to dirty a page. This function increments number of running page\n * faults preventing freezing. If the file system is already frozen, the\n * function waits until the file system is thawed.\n *\n * Since page fault freeze protection behaves as a lock, users have to preserve\n * ordering of freeze protection and other filesystem locks. It is advised to\n * put sb_start_pagefault() close to mmap_sem in lock ordering. Page fault\n * handling code implies lock dependency:\n *\n * mmap_sem\n *   -> sb_start_pagefault\n */\nstatic inline void sb_start_pagefault(struct super_block *sb)\n{\n\t__sb_start_write(sb, SB_FREEZE_PAGEFAULT, true);\n}\n\n/*\n * sb_start_intwrite - get write access to a superblock for internal fs purposes\n * @sb: the super we write to\n *\n * This is the third level of protection against filesystem freezing. It is\n * free for use by a filesystem. The only requirement is that it must rank\n * below sb_start_pagefault.\n *\n * For example filesystem can call sb_start_intwrite() when starting a\n * transaction which somewhat eases handling of freezing for internal sources\n * of filesystem changes (internal fs threads, discarding preallocation on file\n * close, etc.).\n */\nstatic inline void sb_start_intwrite(struct super_block *sb)\n{\n\t__sb_start_write(sb, SB_FREEZE_FS, true);\n}\n\n\nextern bool inode_owner_or_capable(const struct inode *inode);\n\n/*\n * VFS helper functions..\n */\nextern int vfs_create(struct inode *, struct dentry *, umode_t, bool);\nextern int vfs_mkdir(struct inode *, struct dentry *, umode_t);\nextern int vfs_mknod(struct inode *, struct dentry *, umode_t, dev_t);\nextern int vfs_symlink(struct inode *, struct dentry *, const char *);\nextern int vfs_link(struct dentry *, struct inode *, struct dentry *, struct inode **);\nextern int vfs_rmdir(struct inode *, struct dentry *);\nextern int vfs_unlink(struct inode *, struct dentry *, struct inode **);\nextern int vfs_rename(struct inode *, struct dentry *, struct inode *, struct dentry *, struct inode **, unsigned int);\nextern int vfs_whiteout(struct inode *, struct dentry *);\n\n/*\n * VFS dentry helper functions.\n */\nextern void dentry_unhash(struct dentry *dentry);\n\n/*\n * VFS file helper functions.\n */\nextern void inode_init_owner(struct inode *inode, const struct inode *dir,\n\t\t\tumode_t mode);\n/*\n * VFS FS_IOC_FIEMAP helper definitions.\n */\nstruct fiemap_extent_info {\n\tunsigned int fi_flags;\t\t/* Flags as passed from user */\n\tunsigned int fi_extents_mapped;\t/* Number of mapped extents */\n\tunsigned int fi_extents_max;\t/* Size of fiemap_extent array */\n\tstruct fiemap_extent __user *fi_extents_start; /* Start of\n\t\t\t\t\t\t\tfiemap_extent array */\n};\nint fiemap_fill_next_extent(struct fiemap_extent_info *info, u64 logical,\n\t\t\t    u64 phys, u64 len, u32 flags);\nint fiemap_check_flags(struct fiemap_extent_info *fieinfo, u32 fs_flags);\n\n/*\n * File types\n *\n * NOTE! These match bits 12..15 of stat.st_mode\n * (ie \"(i_mode >> 12) & 15\").\n */\n#define DT_UNKNOWN\t0\n#define DT_FIFO\t\t1\n#define DT_CHR\t\t2\n#define DT_DIR\t\t4\n#define DT_BLK\t\t6\n#define DT_REG\t\t8\n#define DT_LNK\t\t10\n#define DT_SOCK\t\t12\n#define DT_WHT\t\t14\n\n/*\n * This is the \"filldir\" function type, used by readdir() to let\n * the kernel specify what kind of dirent layout it wants to have.\n * This allows the kernel to read directories into kernel space or\n * to have different dirent layouts depending on the binary type.\n */\ntypedef int (*filldir_t)(void *, const char *, int, loff_t, u64, unsigned);\nstruct dir_context {\n\tconst filldir_t actor;\n\tloff_t pos;\n};\n\nstruct block_device_operations;\n\n/* These macros are for out of kernel modules to test that\n * the kernel supports the unlocked_ioctl and compat_ioctl\n * fields in struct file_operations. */\n#define HAVE_COMPAT_IOCTL 1\n#define HAVE_UNLOCKED_IOCTL 1\n\nstruct iov_iter;\n\nstruct file_operations {\n\tstruct module *owner;\n\tloff_t (*llseek) (struct file *, loff_t, int);\n\tssize_t (*read) (struct file *, char __user *, size_t, loff_t *);\n\tssize_t (*write) (struct file *, const char __user *, size_t, loff_t *);\n\tssize_t (*aio_read) (struct kiocb *, const struct iovec *, unsigned long, loff_t);\n\tssize_t (*aio_write) (struct kiocb *, const struct iovec *, unsigned long, loff_t);\n\tssize_t (*read_iter) (struct kiocb *, struct iov_iter *);\n\tssize_t (*write_iter) (struct kiocb *, struct iov_iter *);\n\tint (*iterate) (struct file *, struct dir_context *);\n\tunsigned int (*poll) (struct file *, struct poll_table_struct *);\n\tlong (*unlocked_ioctl) (struct file *, unsigned int, unsigned long);\n\tlong (*compat_ioctl) (struct file *, unsigned int, unsigned long);\n\tint (*mmap) (struct file *, struct vm_area_struct *);\n\tint (*open) (struct inode *, struct file *);\n\tint (*flush) (struct file *, fl_owner_t id);\n\tint (*release) (struct inode *, struct file *);\n\tint (*fsync) (struct file *, loff_t, loff_t, int datasync);\n\tint (*aio_fsync) (struct kiocb *, int datasync);\n\tint (*fasync) (int, struct file *, int);\n\tint (*lock) (struct file *, int, struct file_lock *);\n\tssize_t (*sendpage) (struct file *, struct page *, int, size_t, loff_t *, int);\n\tunsigned long (*get_unmapped_area)(struct file *, unsigned long, unsigned long, unsigned long, unsigned long);\n\tint (*check_flags)(int);\n\tint (*flock) (struct file *, int, struct file_lock *);\n\tssize_t (*splice_write)(struct pipe_inode_info *, struct file *, loff_t *, size_t, unsigned int);\n\tssize_t (*splice_read)(struct file *, loff_t *, struct pipe_inode_info *, size_t, unsigned int);\n\tint (*setlease)(struct file *, long, struct file_lock **, void **);\n\tlong (*fallocate)(struct file *file, int mode, loff_t offset,\n\t\t\t  loff_t len);\n\tint (*show_fdinfo)(struct seq_file *m, struct file *f);\n};\n\nstruct inode_operations {\n\tstruct dentry * (*lookup) (struct inode *,struct dentry *, unsigned int);\n\tvoid * (*follow_link) (struct dentry *, struct nameidata *);\n\tint (*permission) (struct inode *, int);\n\tstruct posix_acl * (*get_acl)(struct inode *, int);\n\n\tint (*readlink) (struct dentry *, char __user *,int);\n\tvoid (*put_link) (struct dentry *, struct nameidata *, void *);\n\n\tint (*create) (struct inode *,struct dentry *, umode_t, bool);\n\tint (*link) (struct dentry *,struct inode *,struct dentry *);\n\tint (*unlink) (struct inode *,struct dentry *);\n\tint (*symlink) (struct inode *,struct dentry *,const char *);\n\tint (*mkdir) (struct inode *,struct dentry *,umode_t);\n\tint (*rmdir) (struct inode *,struct dentry *);\n\tint (*mknod) (struct inode *,struct dentry *,umode_t,dev_t);\n\tint (*rename) (struct inode *, struct dentry *,\n\t\t\tstruct inode *, struct dentry *);\n\tint (*rename2) (struct inode *, struct dentry *,\n\t\t\tstruct inode *, struct dentry *, unsigned int);\n\tint (*setattr) (struct dentry *, struct iattr *);\n\tint (*getattr) (struct vfsmount *mnt, struct dentry *, struct kstat *);\n\tint (*setxattr) (struct dentry *, const char *,const void *,size_t,int);\n\tssize_t (*getxattr) (struct dentry *, const char *, void *, size_t);\n\tssize_t (*listxattr) (struct dentry *, char *, size_t);\n\tint (*removexattr) (struct dentry *, const char *);\n\tint (*fiemap)(struct inode *, struct fiemap_extent_info *, u64 start,\n\t\t      u64 len);\n\tint (*update_time)(struct inode *, struct timespec *, int);\n\tint (*atomic_open)(struct inode *, struct dentry *,\n\t\t\t   struct file *, unsigned open_flag,\n\t\t\t   umode_t create_mode, int *opened);\n\tint (*tmpfile) (struct inode *, struct dentry *, umode_t);\n\tint (*set_acl)(struct inode *, struct posix_acl *, int);\n\n\t/* WARNING: probably going away soon, do not use! */\n\tint (*dentry_open)(struct dentry *, struct file *, const struct cred *);\n} ____cacheline_aligned;\n\nssize_t rw_copy_check_uvector(int type, const struct iovec __user * uvector,\n\t\t\t      unsigned long nr_segs, unsigned long fast_segs,\n\t\t\t      struct iovec *fast_pointer,\n\t\t\t      struct iovec **ret_pointer);\n\nextern ssize_t vfs_read(struct file *, char __user *, size_t, loff_t *);\nextern ssize_t vfs_write(struct file *, const char __user *, size_t, loff_t *);\nextern ssize_t vfs_readv(struct file *, const struct iovec __user *,\n\t\tunsigned long, loff_t *);\nextern ssize_t vfs_writev(struct file *, const struct iovec __user *,\n\t\tunsigned long, loff_t *);\n\nstruct super_operations {\n   \tstruct inode *(*alloc_inode)(struct super_block *sb);\n\tvoid (*destroy_inode)(struct inode *);\n\n   \tvoid (*dirty_inode) (struct inode *, int flags);\n\tint (*write_inode) (struct inode *, struct writeback_control *wbc);\n\tint (*drop_inode) (struct inode *);\n\tvoid (*evict_inode) (struct inode *);\n\tvoid (*put_super) (struct super_block *);\n\tint (*sync_fs)(struct super_block *sb, int wait);\n\tint (*freeze_fs) (struct super_block *);\n\tint (*unfreeze_fs) (struct super_block *);\n\tint (*statfs) (struct dentry *, struct kstatfs *);\n\tint (*remount_fs) (struct super_block *, int *, char *);\n\tvoid (*umount_begin) (struct super_block *);\n\n\tint (*show_options)(struct seq_file *, struct dentry *);\n\tint (*show_devname)(struct seq_file *, struct dentry *);\n\tint (*show_path)(struct seq_file *, struct dentry *);\n\tint (*show_stats)(struct seq_file *, struct dentry *);\n#ifdef CONFIG_QUOTA\n\tssize_t (*quota_read)(struct super_block *, int, char *, size_t, loff_t);\n\tssize_t (*quota_write)(struct super_block *, int, const char *, size_t, loff_t);\n#endif\n\tint (*bdev_try_to_free_page)(struct super_block*, struct page*, gfp_t);\n\tlong (*nr_cached_objects)(struct super_block *, int);\n\tlong (*free_cached_objects)(struct super_block *, long, int);\n};\n\n/*\n * Inode flags - they have no relation to superblock flags now\n */\n#define S_SYNC\t\t1\t/* Writes are synced at once */\n#define S_NOATIME\t2\t/* Do not update access times */\n#define S_APPEND\t4\t/* Append-only file */\n#define S_IMMUTABLE\t8\t/* Immutable file */\n#define S_DEAD\t\t16\t/* removed, but still open directory */\n#define S_NOQUOTA\t32\t/* Inode is not counted to quota */\n#define S_DIRSYNC\t64\t/* Directory modifications are synchronous */\n#define S_NOCMTIME\t128\t/* Do not update file c/mtime */\n#define S_SWAPFILE\t256\t/* Do not truncate: swapon got its bmaps */\n#define S_PRIVATE\t512\t/* Inode is fs-internal */\n#define S_IMA\t\t1024\t/* Inode has an associated IMA struct */\n#define S_AUTOMOUNT\t2048\t/* Automount/referral quasi-directory */\n#define S_NOSEC\t\t4096\t/* no suid or xattr security attributes */\n\n/*\n * Note that nosuid etc flags are inode-specific: setting some file-system\n * flags just means all the inodes inherit those flags by default. It might be\n * possible to override it selectively if you really wanted to with some\n * ioctl() that is not currently implemented.\n *\n * Exception: MS_RDONLY is always applied to the entire file system.\n *\n * Unfortunately, it is possible to change a filesystems flags with it mounted\n * with files in use.  This means that all of the inodes will not have their\n * i_flags updated.  Hence, i_flags no longer inherit the superblock mount\n * flags, so these have to be checked separately. -- rmk@arm.uk.linux.org\n */\n#define __IS_FLG(inode, flg)\t((inode)->i_sb->s_flags & (flg))\n\n#define IS_RDONLY(inode)\t((inode)->i_sb->s_flags & MS_RDONLY)\n#define IS_SYNC(inode)\t\t(__IS_FLG(inode, MS_SYNCHRONOUS) || \\\n\t\t\t\t\t((inode)->i_flags & S_SYNC))\n#define IS_DIRSYNC(inode)\t(__IS_FLG(inode, MS_SYNCHRONOUS|MS_DIRSYNC) || \\\n\t\t\t\t\t((inode)->i_flags & (S_SYNC|S_DIRSYNC)))\n#define IS_MANDLOCK(inode)\t__IS_FLG(inode, MS_MANDLOCK)\n#define IS_NOATIME(inode)\t__IS_FLG(inode, MS_RDONLY|MS_NOATIME)\n#define IS_I_VERSION(inode)\t__IS_FLG(inode, MS_I_VERSION)\n\n#define IS_NOQUOTA(inode)\t((inode)->i_flags & S_NOQUOTA)\n#define IS_APPEND(inode)\t((inode)->i_flags & S_APPEND)\n#define IS_IMMUTABLE(inode)\t((inode)->i_flags & S_IMMUTABLE)\n#define IS_POSIXACL(inode)\t__IS_FLG(inode, MS_POSIXACL)\n\n#define IS_DEADDIR(inode)\t((inode)->i_flags & S_DEAD)\n#define IS_NOCMTIME(inode)\t((inode)->i_flags & S_NOCMTIME)\n#define IS_SWAPFILE(inode)\t((inode)->i_flags & S_SWAPFILE)\n#define IS_PRIVATE(inode)\t((inode)->i_flags & S_PRIVATE)\n#define IS_IMA(inode)\t\t((inode)->i_flags & S_IMA)\n#define IS_AUTOMOUNT(inode)\t((inode)->i_flags & S_AUTOMOUNT)\n#define IS_NOSEC(inode)\t\t((inode)->i_flags & S_NOSEC)\n\n#define IS_WHITEOUT(inode)\t(S_ISCHR(inode->i_mode) && \\\n\t\t\t\t (inode)->i_rdev == WHITEOUT_DEV)\n\n/*\n * Inode state bits.  Protected by inode->i_lock\n *\n * Three bits determine the dirty state of the inode, I_DIRTY_SYNC,\n * I_DIRTY_DATASYNC and I_DIRTY_PAGES.\n *\n * Four bits define the lifetime of an inode.  Initially, inodes are I_NEW,\n * until that flag is cleared.  I_WILL_FREE, I_FREEING and I_CLEAR are set at\n * various stages of removing an inode.\n *\n * Two bits are used for locking and completion notification, I_NEW and I_SYNC.\n *\n * I_DIRTY_SYNC\t\tInode is dirty, but doesn't have to be written on\n *\t\t\tfdatasync().  i_atime is the usual cause.\n * I_DIRTY_DATASYNC\tData-related inode changes pending. We keep track of\n *\t\t\tthese changes separately from I_DIRTY_SYNC so that we\n *\t\t\tdon't have to write inode on fdatasync() when only\n *\t\t\tmtime has changed in it.\n * I_DIRTY_PAGES\tInode has dirty pages.  Inode itself may be clean.\n * I_NEW\t\tServes as both a mutex and completion notification.\n *\t\t\tNew inodes set I_NEW.  If two processes both create\n *\t\t\tthe same inode, one of them will release its inode and\n *\t\t\twait for I_NEW to be released before returning.\n *\t\t\tInodes in I_WILL_FREE, I_FREEING or I_CLEAR state can\n *\t\t\talso cause waiting on I_NEW, without I_NEW actually\n *\t\t\tbeing set.  find_inode() uses this to prevent returning\n *\t\t\tnearly-dead inodes.\n * I_WILL_FREE\t\tMust be set when calling write_inode_now() if i_count\n *\t\t\tis zero.  I_FREEING must be set when I_WILL_FREE is\n *\t\t\tcleared.\n * I_FREEING\t\tSet when inode is about to be freed but still has dirty\n *\t\t\tpages or buffers attached or the inode itself is still\n *\t\t\tdirty.\n * I_CLEAR\t\tAdded by clear_inode().  In this state the inode is\n *\t\t\tclean and can be destroyed.  Inode keeps I_FREEING.\n *\n *\t\t\tInodes that are I_WILL_FREE, I_FREEING or I_CLEAR are\n *\t\t\tprohibited for many purposes.  iget() must wait for\n *\t\t\tthe inode to be completely released, then create it\n *\t\t\tanew.  Other functions will just ignore such inodes,\n *\t\t\tif appropriate.  I_NEW is used for waiting.\n *\n * I_SYNC\t\tWriteback of inode is running. The bit is set during\n *\t\t\tdata writeback, and cleared with a wakeup on the bit\n *\t\t\taddress once it is done. The bit is also used to pin\n *\t\t\tthe inode in memory for flusher thread.\n *\n * I_REFERENCED\t\tMarks the inode as recently references on the LRU list.\n *\n * I_DIO_WAKEUP\t\tNever set.  Only used as a key for wait_on_bit().\n *\n * Q: What is the difference between I_WILL_FREE and I_FREEING?\n */\n#define I_DIRTY_SYNC\t\t(1 << 0)\n#define I_DIRTY_DATASYNC\t(1 << 1)\n#define I_DIRTY_PAGES\t\t(1 << 2)\n#define __I_NEW\t\t\t3\n#define I_NEW\t\t\t(1 << __I_NEW)\n#define I_WILL_FREE\t\t(1 << 4)\n#define I_FREEING\t\t(1 << 5)\n#define I_CLEAR\t\t\t(1 << 6)\n#define __I_SYNC\t\t7\n#define I_SYNC\t\t\t(1 << __I_SYNC)\n#define I_REFERENCED\t\t(1 << 8)\n#define __I_DIO_WAKEUP\t\t9\n#define I_DIO_WAKEUP\t\t(1 << I_DIO_WAKEUP)\n#define I_LINKABLE\t\t(1 << 10)\n\n#define I_DIRTY (I_DIRTY_SYNC | I_DIRTY_DATASYNC | I_DIRTY_PAGES)\n\nextern void __mark_inode_dirty(struct inode *, int);\nstatic inline void mark_inode_dirty(struct inode *inode)\n{\n\t__mark_inode_dirty(inode, I_DIRTY);\n}\n\nstatic inline void mark_inode_dirty_sync(struct inode *inode)\n{\n\t__mark_inode_dirty(inode, I_DIRTY_SYNC);\n}\n\nextern void inc_nlink(struct inode *inode);\nextern void drop_nlink(struct inode *inode);\nextern void clear_nlink(struct inode *inode);\nextern void set_nlink(struct inode *inode, unsigned int nlink);\n\nstatic inline void inode_inc_link_count(struct inode *inode)\n{\n\tinc_nlink(inode);\n\tmark_inode_dirty(inode);\n}\n\nstatic inline void inode_dec_link_count(struct inode *inode)\n{\n\tdrop_nlink(inode);\n\tmark_inode_dirty(inode);\n}\n\n/**\n * inode_inc_iversion - increments i_version\n * @inode: inode that need to be updated\n *\n * Every time the inode is modified, the i_version field will be incremented.\n * The filesystem has to be mounted with i_version flag\n */\n\nstatic inline void inode_inc_iversion(struct inode *inode)\n{\n       spin_lock(&inode->i_lock);\n       inode->i_version++;\n       spin_unlock(&inode->i_lock);\n}\n\nenum file_time_flags {\n\tS_ATIME = 1,\n\tS_MTIME = 2,\n\tS_CTIME = 4,\n\tS_VERSION = 8,\n};\n\nextern void touch_atime(const struct path *);\nstatic inline void file_accessed(struct file *file)\n{\n\tif (!(file->f_flags & O_NOATIME))\n\t\ttouch_atime(&file->f_path);\n}\n\nint sync_inode(struct inode *inode, struct writeback_control *wbc);\nint sync_inode_metadata(struct inode *inode, int wait);\n\nstruct file_system_type {\n\tconst char *name;\n\tint fs_flags;\n#define FS_REQUIRES_DEV\t\t1 \n#define FS_BINARY_MOUNTDATA\t2\n#define FS_HAS_SUBTYPE\t\t4\n#define FS_USERNS_MOUNT\t\t8\t/* Can be mounted by userns root */\n#define FS_USERNS_DEV_MOUNT\t16 /* A userns mount does not imply MNT_NODEV */\n#define FS_RENAME_DOES_D_MOVE\t32768\t/* FS will handle d_move() during rename() internally. */\n\tstruct dentry *(*mount) (struct file_system_type *, int,\n\t\t       const char *, void *);\n\tvoid (*kill_sb) (struct super_block *);\n\tstruct module *owner;\n\tstruct file_system_type * next;\n\tstruct hlist_head fs_supers;\n\n\tstruct lock_class_key s_lock_key;\n\tstruct lock_class_key s_umount_key;\n\tstruct lock_class_key s_vfs_rename_key;\n\tstruct lock_class_key s_writers_key[SB_FREEZE_LEVELS];\n\n\tstruct lock_class_key i_lock_key;\n\tstruct lock_class_key i_mutex_key;\n\tstruct lock_class_key i_mutex_dir_key;\n};\n\n#define MODULE_ALIAS_FS(NAME) MODULE_ALIAS(\"fs-\" NAME)\n\nextern struct dentry *mount_ns(struct file_system_type *fs_type, int flags,\n\tvoid *data, int (*fill_super)(struct super_block *, void *, int));\nextern struct dentry *mount_bdev(struct file_system_type *fs_type,\n\tint flags, const char *dev_name, void *data,\n\tint (*fill_super)(struct super_block *, void *, int));\nextern struct dentry *mount_single(struct file_system_type *fs_type,\n\tint flags, void *data,\n\tint (*fill_super)(struct super_block *, void *, int));\nextern struct dentry *mount_nodev(struct file_system_type *fs_type,\n\tint flags, void *data,\n\tint (*fill_super)(struct super_block *, void *, int));\nextern struct dentry *mount_subtree(struct vfsmount *mnt, const char *path);\nvoid generic_shutdown_super(struct super_block *sb);\nvoid kill_block_super(struct super_block *sb);\nvoid kill_anon_super(struct super_block *sb);\nvoid kill_litter_super(struct super_block *sb);\nvoid deactivate_super(struct super_block *sb);\nvoid deactivate_locked_super(struct super_block *sb);\nint set_anon_super(struct super_block *s, void *data);\nint get_anon_bdev(dev_t *);\nvoid free_anon_bdev(dev_t);\nstruct super_block *sget(struct file_system_type *type,\n\t\t\tint (*test)(struct super_block *,void *),\n\t\t\tint (*set)(struct super_block *,void *),\n\t\t\tint flags, void *data);\nextern struct dentry *mount_pseudo(struct file_system_type *, char *,\n\tconst struct super_operations *ops,\n\tconst struct dentry_operations *dops,\n\tunsigned long);\n\n/* Alas, no aliases. Too much hassle with bringing module.h everywhere */\n#define fops_get(fops) \\\n\t(((fops) && try_module_get((fops)->owner) ? (fops) : NULL))\n#define fops_put(fops) \\\n\tdo { if (fops) module_put((fops)->owner); } while(0)\n/*\n * This one is to be used *ONLY* from ->open() instances.\n * fops must be non-NULL, pinned down *and* module dependencies\n * should be sufficient to pin the caller down as well.\n */\n#define replace_fops(f, fops) \\\n\tdo {\t\\\n\t\tstruct file *__file = (f); \\\n\t\tfops_put(__file->f_op); \\\n\t\tBUG_ON(!(__file->f_op = (fops))); \\\n\t} while(0)\n\nextern int register_filesystem(struct file_system_type *);\nextern int unregister_filesystem(struct file_system_type *);\nextern struct vfsmount *kern_mount_data(struct file_system_type *, void *data);\n#define kern_mount(type) kern_mount_data(type, NULL)\nextern void kern_unmount(struct vfsmount *mnt);\nextern int may_umount_tree(struct vfsmount *);\nextern int may_umount(struct vfsmount *);\nextern long do_mount(const char *, const char __user *,\n\t\t     const char *, unsigned long, void *);\nextern struct vfsmount *collect_mounts(struct path *);\nextern void drop_collected_mounts(struct vfsmount *);\nextern int iterate_mounts(int (*)(struct vfsmount *, void *), void *,\n\t\t\t  struct vfsmount *);\nextern int vfs_statfs(struct path *, struct kstatfs *);\nextern int user_statfs(const char __user *, struct kstatfs *);\nextern int fd_statfs(int, struct kstatfs *);\nextern int vfs_ustat(dev_t, struct kstatfs *);\nextern int freeze_super(struct super_block *super);\nextern int thaw_super(struct super_block *super);\nextern bool our_mnt(struct vfsmount *mnt);\nextern bool fs_fully_visible(struct file_system_type *);\n\nextern int current_umask(void);\n\nextern void ihold(struct inode * inode);\nextern void iput(struct inode *);\n\nstatic inline struct inode *file_inode(const struct file *f)\n{\n\treturn f->f_inode;\n}\n\n/* /sys/fs */\nextern struct kobject *fs_kobj;\n\n#define MAX_RW_COUNT (INT_MAX & PAGE_CACHE_MASK)\n\n#define FLOCK_VERIFY_READ  1\n#define FLOCK_VERIFY_WRITE 2\n\n#ifdef CONFIG_FILE_LOCKING\nextern int locks_mandatory_locked(struct file *);\nextern int locks_mandatory_area(int, struct inode *, struct file *, loff_t, size_t);\n\n/*\n * Candidates for mandatory locking have the setgid bit set\n * but no group execute bit -  an otherwise meaningless combination.\n */\n\nstatic inline int __mandatory_lock(struct inode *ino)\n{\n\treturn (ino->i_mode & (S_ISGID | S_IXGRP)) == S_ISGID;\n}\n\n/*\n * ... and these candidates should be on MS_MANDLOCK mounted fs,\n * otherwise these will be advisory locks\n */\n\nstatic inline int mandatory_lock(struct inode *ino)\n{\n\treturn IS_MANDLOCK(ino) && __mandatory_lock(ino);\n}\n\nstatic inline int locks_verify_locked(struct file *file)\n{\n\tif (mandatory_lock(file_inode(file)))\n\t\treturn locks_mandatory_locked(file);\n\treturn 0;\n}\n\nstatic inline int locks_verify_truncate(struct inode *inode,\n\t\t\t\t    struct file *filp,\n\t\t\t\t    loff_t size)\n{\n\tif (inode->i_flock && mandatory_lock(inode))\n\t\treturn locks_mandatory_area(\n\t\t\tFLOCK_VERIFY_WRITE, inode, filp,\n\t\t\tsize < inode->i_size ? size : inode->i_size,\n\t\t\t(size < inode->i_size ? inode->i_size - size\n\t\t\t : size - inode->i_size)\n\t\t);\n\treturn 0;\n}\n\nstatic inline int break_lease(struct inode *inode, unsigned int mode)\n{\n\t/*\n\t * Since this check is lockless, we must ensure that any refcounts\n\t * taken are done before checking inode->i_flock. Otherwise, we could\n\t * end up racing with tasks trying to set a new lease on this file.\n\t */\n\tsmp_mb();\n\tif (inode->i_flock)\n\t\treturn __break_lease(inode, mode, FL_LEASE);\n\treturn 0;\n}\n\nstatic inline int break_deleg(struct inode *inode, unsigned int mode)\n{\n\t/*\n\t * Since this check is lockless, we must ensure that any refcounts\n\t * taken are done before checking inode->i_flock. Otherwise, we could\n\t * end up racing with tasks trying to set a new lease on this file.\n\t */\n\tsmp_mb();\n\tif (inode->i_flock)\n\t\treturn __break_lease(inode, mode, FL_DELEG);\n\treturn 0;\n}\n\nstatic inline int try_break_deleg(struct inode *inode, struct inode **delegated_inode)\n{\n\tint ret;\n\n\tret = break_deleg(inode, O_WRONLY|O_NONBLOCK);\n\tif (ret == -EWOULDBLOCK && delegated_inode) {\n\t\t*delegated_inode = inode;\n\t\tihold(inode);\n\t}\n\treturn ret;\n}\n\nstatic inline int break_deleg_wait(struct inode **delegated_inode)\n{\n\tint ret;\n\n\tret = break_deleg(*delegated_inode, O_WRONLY);\n\tiput(*delegated_inode);\n\t*delegated_inode = NULL;\n\treturn ret;\n}\n\n#else /* !CONFIG_FILE_LOCKING */\nstatic inline int locks_mandatory_locked(struct file *file)\n{\n\treturn 0;\n}\n\nstatic inline int locks_mandatory_area(int rw, struct inode *inode,\n\t\t\t\t       struct file *filp, loff_t offset,\n\t\t\t\t       size_t count)\n{\n\treturn 0;\n}\n\nstatic inline int __mandatory_lock(struct inode *inode)\n{\n\treturn 0;\n}\n\nstatic inline int mandatory_lock(struct inode *inode)\n{\n\treturn 0;\n}\n\nstatic inline int locks_verify_locked(struct file *file)\n{\n\treturn 0;\n}\n\nstatic inline int locks_verify_truncate(struct inode *inode, struct file *filp,\n\t\t\t\t\tsize_t size)\n{\n\treturn 0;\n}\n\nstatic inline int break_lease(struct inode *inode, unsigned int mode)\n{\n\treturn 0;\n}\n\nstatic inline int break_deleg(struct inode *inode, unsigned int mode)\n{\n\treturn 0;\n}\n\nstatic inline int try_break_deleg(struct inode *inode, struct inode **delegated_inode)\n{\n\treturn 0;\n}\n\nstatic inline int break_deleg_wait(struct inode **delegated_inode)\n{\n\tBUG();\n\treturn 0;\n}\n\n#endif /* CONFIG_FILE_LOCKING */\n\n/* fs/open.c */\nstruct audit_names;\nstruct filename {\n\tconst char\t\t*name;\t/* pointer to actual string */\n\tconst __user char\t*uptr;\t/* original userland pointer */\n\tstruct audit_names\t*aname;\n\tbool\t\t\tseparate; /* should \"name\" be freed? */\n};\n\nextern long vfs_truncate(struct path *, loff_t);\nextern int do_truncate(struct dentry *, loff_t start, unsigned int time_attrs,\n\t\t       struct file *filp);\nextern int do_fallocate(struct file *file, int mode, loff_t offset,\n\t\t\tloff_t len);\nextern long do_sys_open(int dfd, const char __user *filename, int flags,\n\t\t\tumode_t mode);\nextern struct file *file_open_name(struct filename *, int, umode_t);\nextern struct file *filp_open(const char *, int, umode_t);\nextern struct file *file_open_root(struct dentry *, struct vfsmount *,\n\t\t\t\t   const char *, int);\nextern int vfs_open(const struct path *, struct file *, const struct cred *);\nextern struct file * dentry_open(const struct path *, int, const struct cred *);\nextern int filp_close(struct file *, fl_owner_t id);\n\nextern struct filename *getname(const char __user *);\nextern struct filename *getname_kernel(const char *);\n\nenum {\n\tFILE_CREATED = 1,\n\tFILE_OPENED = 2\n};\nextern int finish_open(struct file *file, struct dentry *dentry,\n\t\t\tint (*open)(struct inode *, struct file *),\n\t\t\tint *opened);\nextern int finish_no_open(struct file *file, struct dentry *dentry);\n\n/* fs/ioctl.c */\n\nextern int ioctl_preallocate(struct file *filp, void __user *argp);\n\n/* fs/dcache.c */\nextern void __init vfs_caches_init_early(void);\nextern void __init vfs_caches_init(unsigned long);\n\nextern struct kmem_cache *names_cachep;\n\nextern void final_putname(struct filename *name);\n\n#define __getname()\t\tkmem_cache_alloc(names_cachep, GFP_KERNEL)\n#define __putname(name)\t\tkmem_cache_free(names_cachep, (void *)(name))\n#ifndef CONFIG_AUDITSYSCALL\n#define putname(name)\t\tfinal_putname(name)\n#else\nextern void putname(struct filename *name);\n#endif\n\n#ifdef CONFIG_BLOCK\nextern int register_blkdev(unsigned int, const char *);\nextern void unregister_blkdev(unsigned int, const char *);\nextern struct block_device *bdget(dev_t);\nextern struct block_device *bdgrab(struct block_device *bdev);\nextern void bd_set_size(struct block_device *, loff_t size);\nextern void bd_forget(struct inode *inode);\nextern void bdput(struct block_device *);\nextern void invalidate_bdev(struct block_device *);\nextern void iterate_bdevs(void (*)(struct block_device *, void *), void *);\nextern int sync_blockdev(struct block_device *bdev);\nextern void kill_bdev(struct block_device *);\nextern struct super_block *freeze_bdev(struct block_device *);\nextern void emergency_thaw_all(void);\nextern int thaw_bdev(struct block_device *bdev, struct super_block *sb);\nextern int fsync_bdev(struct block_device *);\nextern int sb_is_blkdev_sb(struct super_block *sb);\n#else\nstatic inline void bd_forget(struct inode *inode) {}\nstatic inline int sync_blockdev(struct block_device *bdev) { return 0; }\nstatic inline void kill_bdev(struct block_device *bdev) {}\nstatic inline void invalidate_bdev(struct block_device *bdev) {}\n\nstatic inline struct super_block *freeze_bdev(struct block_device *sb)\n{\n\treturn NULL;\n}\n\nstatic inline int thaw_bdev(struct block_device *bdev, struct super_block *sb)\n{\n\treturn 0;\n}\n\nstatic inline void iterate_bdevs(void (*f)(struct block_device *, void *), void *arg)\n{\n}\n\nstatic inline int sb_is_blkdev_sb(struct super_block *sb)\n{\n\treturn 0;\n}\n#endif\nextern int sync_filesystem(struct super_block *);\nextern const struct file_operations def_blk_fops;\nextern const struct file_operations def_chr_fops;\nextern const struct file_operations bad_sock_fops;\n#ifdef CONFIG_BLOCK\nextern int ioctl_by_bdev(struct block_device *, unsigned, unsigned long);\nextern int blkdev_ioctl(struct block_device *, fmode_t, unsigned, unsigned long);\nextern long compat_blkdev_ioctl(struct file *, unsigned, unsigned long);\nextern int blkdev_get(struct block_device *bdev, fmode_t mode, void *holder);\nextern struct block_device *blkdev_get_by_path(const char *path, fmode_t mode,\n\t\t\t\t\t       void *holder);\nextern struct block_device *blkdev_get_by_dev(dev_t dev, fmode_t mode,\n\t\t\t\t\t      void *holder);\nextern void blkdev_put(struct block_device *bdev, fmode_t mode);\n#ifdef CONFIG_SYSFS\nextern int bd_link_disk_holder(struct block_device *bdev, struct gendisk *disk);\nextern void bd_unlink_disk_holder(struct block_device *bdev,\n\t\t\t\t  struct gendisk *disk);\n#else\nstatic inline int bd_link_disk_holder(struct block_device *bdev,\n\t\t\t\t      struct gendisk *disk)\n{\n\treturn 0;\n}\nstatic inline void bd_unlink_disk_holder(struct block_device *bdev,\n\t\t\t\t\t struct gendisk *disk)\n{\n}\n#endif\n#endif\n\n/* fs/char_dev.c */\n#define CHRDEV_MAJOR_HASH_SIZE\t255\nextern int alloc_chrdev_region(dev_t *, unsigned, unsigned, const char *);\nextern int register_chrdev_region(dev_t, unsigned, const char *);\nextern int __register_chrdev(unsigned int major, unsigned int baseminor,\n\t\t\t     unsigned int count, const char *name,\n\t\t\t     const struct file_operations *fops);\nextern void __unregister_chrdev(unsigned int major, unsigned int baseminor,\n\t\t\t\tunsigned int count, const char *name);\nextern void unregister_chrdev_region(dev_t, unsigned);\nextern void chrdev_show(struct seq_file *,off_t);\n\nstatic inline int register_chrdev(unsigned int major, const char *name,\n\t\t\t\t  const struct file_operations *fops)\n{\n\treturn __register_chrdev(major, 0, 256, name, fops);\n}\n\nstatic inline void unregister_chrdev(unsigned int major, const char *name)\n{\n\t__unregister_chrdev(major, 0, 256, name);\n}\n\n/* fs/block_dev.c */\n#define BDEVNAME_SIZE\t32\t/* Largest string for a blockdev identifier */\n#define BDEVT_SIZE\t10\t/* Largest string for MAJ:MIN for blkdev */\n\n#ifdef CONFIG_BLOCK\n#define BLKDEV_MAJOR_HASH_SIZE\t255\nextern const char *__bdevname(dev_t, char *buffer);\nextern const char *bdevname(struct block_device *bdev, char *buffer);\nextern struct block_device *lookup_bdev(const char *);\nextern void blkdev_show(struct seq_file *,off_t);\n\n#else\n#define BLKDEV_MAJOR_HASH_SIZE\t0\n#endif\n\nextern void init_special_inode(struct inode *, umode_t, dev_t);\n\n/* Invalid inode operations -- fs/bad_inode.c */\nextern void make_bad_inode(struct inode *);\nextern int is_bad_inode(struct inode *);\n\n#ifdef CONFIG_BLOCK\n/*\n * return READ, READA, or WRITE\n */\n#define bio_rw(bio)\t\t((bio)->bi_rw & (RW_MASK | RWA_MASK))\n\n/*\n * return data direction, READ or WRITE\n */\n#define bio_data_dir(bio)\t((bio)->bi_rw & 1)\n\nextern void check_disk_size_change(struct gendisk *disk,\n\t\t\t\t   struct block_device *bdev);\nextern int revalidate_disk(struct gendisk *);\nextern int check_disk_change(struct block_device *);\nextern int __invalidate_device(struct block_device *, bool);\nextern int invalidate_partition(struct gendisk *, int);\n#endif\nunsigned long invalidate_mapping_pages(struct address_space *mapping,\n\t\t\t\t\tpgoff_t start, pgoff_t end);\n\nstatic inline void invalidate_remote_inode(struct inode *inode)\n{\n\tif (S_ISREG(inode->i_mode) || S_ISDIR(inode->i_mode) ||\n\t    S_ISLNK(inode->i_mode))\n\t\tinvalidate_mapping_pages(inode->i_mapping, 0, -1);\n}\nextern int invalidate_inode_pages2(struct address_space *mapping);\nextern int invalidate_inode_pages2_range(struct address_space *mapping,\n\t\t\t\t\t pgoff_t start, pgoff_t end);\nextern int write_inode_now(struct inode *, int);\nextern int filemap_fdatawrite(struct address_space *);\nextern int filemap_flush(struct address_space *);\nextern int filemap_fdatawait(struct address_space *);\nextern int filemap_fdatawait_range(struct address_space *, loff_t lstart,\n\t\t\t\t   loff_t lend);\nextern int filemap_write_and_wait(struct address_space *mapping);\nextern int filemap_write_and_wait_range(struct address_space *mapping,\n\t\t\t\t        loff_t lstart, loff_t lend);\nextern int __filemap_fdatawrite_range(struct address_space *mapping,\n\t\t\t\tloff_t start, loff_t end, int sync_mode);\nextern int filemap_fdatawrite_range(struct address_space *mapping,\n\t\t\t\tloff_t start, loff_t end);\n\nextern int vfs_fsync_range(struct file *file, loff_t start, loff_t end,\n\t\t\t   int datasync);\nextern int vfs_fsync(struct file *file, int datasync);\nstatic inline int generic_write_sync(struct file *file, loff_t pos, loff_t count)\n{\n\tif (!(file->f_flags & O_DSYNC) && !IS_SYNC(file->f_mapping->host))\n\t\treturn 0;\n\treturn vfs_fsync_range(file, pos, pos + count - 1,\n\t\t\t       (file->f_flags & __O_SYNC) ? 0 : 1);\n}\nextern void emergency_sync(void);\nextern void emergency_remount(void);\n#ifdef CONFIG_BLOCK\nextern sector_t bmap(struct inode *, sector_t);\n#endif\nextern int notify_change(struct dentry *, struct iattr *, struct inode **);\nextern int inode_permission(struct inode *, int);\nextern int __inode_permission(struct inode *, int);\nextern int generic_permission(struct inode *, int);\nextern int __check_sticky(struct inode *dir, struct inode *inode);\n\nstatic inline bool execute_ok(struct inode *inode)\n{\n\treturn (inode->i_mode & S_IXUGO) || S_ISDIR(inode->i_mode);\n}\n\nstatic inline void file_start_write(struct file *file)\n{\n\tif (!S_ISREG(file_inode(file)->i_mode))\n\t\treturn;\n\t__sb_start_write(file_inode(file)->i_sb, SB_FREEZE_WRITE, true);\n}\n\nstatic inline bool file_start_write_trylock(struct file *file)\n{\n\tif (!S_ISREG(file_inode(file)->i_mode))\n\t\treturn true;\n\treturn __sb_start_write(file_inode(file)->i_sb, SB_FREEZE_WRITE, false);\n}\n\nstatic inline void file_end_write(struct file *file)\n{\n\tif (!S_ISREG(file_inode(file)->i_mode))\n\t\treturn;\n\t__sb_end_write(file_inode(file)->i_sb, SB_FREEZE_WRITE);\n}\n\n/*\n * get_write_access() gets write permission for a file.\n * put_write_access() releases this write permission.\n * This is used for regular files.\n * We cannot support write (and maybe mmap read-write shared) accesses and\n * MAP_DENYWRITE mmappings simultaneously. The i_writecount field of an inode\n * can have the following values:\n * 0: no writers, no VM_DENYWRITE mappings\n * < 0: (-i_writecount) vm_area_structs with VM_DENYWRITE set exist\n * > 0: (i_writecount) users are writing to the file.\n *\n * Normally we operate on that counter with atomic_{inc,dec} and it's safe\n * except for the cases where we don't hold i_writecount yet. Then we need to\n * use {get,deny}_write_access() - these functions check the sign and refuse\n * to do the change if sign is wrong.\n */\nstatic inline int get_write_access(struct inode *inode)\n{\n\treturn atomic_inc_unless_negative(&inode->i_writecount) ? 0 : -ETXTBSY;\n}\nstatic inline int deny_write_access(struct file *file)\n{\n\tstruct inode *inode = file_inode(file);\n\treturn atomic_dec_unless_positive(&inode->i_writecount) ? 0 : -ETXTBSY;\n}\nstatic inline void put_write_access(struct inode * inode)\n{\n\tatomic_dec(&inode->i_writecount);\n}\nstatic inline void allow_write_access(struct file *file)\n{\n\tif (file)\n\t\tatomic_inc(&file_inode(file)->i_writecount);\n}\nstatic inline bool inode_is_open_for_write(const struct inode *inode)\n{\n\treturn atomic_read(&inode->i_writecount) > 0;\n}\n\n#ifdef CONFIG_IMA\nstatic inline void i_readcount_dec(struct inode *inode)\n{\n\tBUG_ON(!atomic_read(&inode->i_readcount));\n\tatomic_dec(&inode->i_readcount);\n}\nstatic inline void i_readcount_inc(struct inode *inode)\n{\n\tatomic_inc(&inode->i_readcount);\n}\n#else\nstatic inline void i_readcount_dec(struct inode *inode)\n{\n\treturn;\n}\nstatic inline void i_readcount_inc(struct inode *inode)\n{\n\treturn;\n}\n#endif\nextern int do_pipe_flags(int *, int);\n\nextern int kernel_read(struct file *, loff_t, char *, unsigned long);\nextern ssize_t kernel_write(struct file *, const char *, size_t, loff_t);\nextern ssize_t __kernel_write(struct file *, const char *, size_t, loff_t *);\nextern struct file * open_exec(const char *);\n \n/* fs/dcache.c -- generic fs support functions */\nextern int is_subdir(struct dentry *, struct dentry *);\nextern int path_is_under(struct path *, struct path *);\n\n#include <linux/err.h>\n\n/* needed for stackable file system support */\nextern loff_t default_llseek(struct file *file, loff_t offset, int whence);\n\nextern loff_t vfs_llseek(struct file *file, loff_t offset, int whence);\n\nextern int inode_init_always(struct super_block *, struct inode *);\nextern void inode_init_once(struct inode *);\nextern void address_space_init_once(struct address_space *mapping);\nextern struct inode * igrab(struct inode *);\nextern ino_t iunique(struct super_block *, ino_t);\nextern int inode_needs_sync(struct inode *inode);\nextern int generic_delete_inode(struct inode *inode);\nstatic inline int generic_drop_inode(struct inode *inode)\n{\n\treturn !inode->i_nlink || inode_unhashed(inode);\n}\n\nextern struct inode *ilookup5_nowait(struct super_block *sb,\n\t\tunsigned long hashval, int (*test)(struct inode *, void *),\n\t\tvoid *data);\nextern struct inode *ilookup5(struct super_block *sb, unsigned long hashval,\n\t\tint (*test)(struct inode *, void *), void *data);\nextern struct inode *ilookup(struct super_block *sb, unsigned long ino);\n\nextern struct inode * iget5_locked(struct super_block *, unsigned long, int (*test)(struct inode *, void *), int (*set)(struct inode *, void *), void *);\nextern struct inode * iget_locked(struct super_block *, unsigned long);\nextern int insert_inode_locked4(struct inode *, unsigned long, int (*test)(struct inode *, void *), void *);\nextern int insert_inode_locked(struct inode *);\n#ifdef CONFIG_DEBUG_LOCK_ALLOC\nextern void lockdep_annotate_inode_mutex_key(struct inode *inode);\n#else\nstatic inline void lockdep_annotate_inode_mutex_key(struct inode *inode) { };\n#endif\nextern void unlock_new_inode(struct inode *);\nextern unsigned int get_next_ino(void);\n\nextern void __iget(struct inode * inode);\nextern void iget_failed(struct inode *);\nextern void clear_inode(struct inode *);\nextern void __destroy_inode(struct inode *);\nextern struct inode *new_inode_pseudo(struct super_block *sb);\nextern struct inode *new_inode(struct super_block *sb);\nextern void free_inode_nonrcu(struct inode *inode);\nextern int should_remove_suid(struct dentry *);\nextern int file_remove_suid(struct file *);\n\nextern void __insert_inode_hash(struct inode *, unsigned long hashval);\nstatic inline void insert_inode_hash(struct inode *inode)\n{\n\t__insert_inode_hash(inode, inode->i_ino);\n}\n\nextern void __remove_inode_hash(struct inode *);\nstatic inline void remove_inode_hash(struct inode *inode)\n{\n\tif (!inode_unhashed(inode))\n\t\t__remove_inode_hash(inode);\n}\n\nextern void inode_sb_list_add(struct inode *inode);\n\n#ifdef CONFIG_BLOCK\nextern void submit_bio(int, struct bio *);\nextern int bdev_read_only(struct block_device *);\n#endif\nextern int set_blocksize(struct block_device *, int);\nextern int sb_set_blocksize(struct super_block *, int);\nextern int sb_min_blocksize(struct super_block *, int);\n\nextern int generic_file_mmap(struct file *, struct vm_area_struct *);\nextern int generic_file_readonly_mmap(struct file *, struct vm_area_struct *);\nextern int generic_file_remap_pages(struct vm_area_struct *, unsigned long addr,\n\t\tunsigned long size, pgoff_t pgoff);\nint generic_write_checks(struct file *file, loff_t *pos, size_t *count, int isblk);\nextern ssize_t generic_file_read_iter(struct kiocb *, struct iov_iter *);\nextern ssize_t __generic_file_write_iter(struct kiocb *, struct iov_iter *);\nextern ssize_t generic_file_write_iter(struct kiocb *, struct iov_iter *);\nextern ssize_t generic_file_direct_write(struct kiocb *, struct iov_iter *, loff_t);\nextern ssize_t generic_perform_write(struct file *, struct iov_iter *, loff_t);\nextern ssize_t do_sync_read(struct file *filp, char __user *buf, size_t len, loff_t *ppos);\nextern ssize_t do_sync_write(struct file *filp, const char __user *buf, size_t len, loff_t *ppos);\nextern ssize_t new_sync_read(struct file *filp, char __user *buf, size_t len, loff_t *ppos);\nextern ssize_t new_sync_write(struct file *filp, const char __user *buf, size_t len, loff_t *ppos);\n\n/* fs/block_dev.c */\nextern ssize_t blkdev_write_iter(struct kiocb *iocb, struct iov_iter *from);\nextern int blkdev_fsync(struct file *filp, loff_t start, loff_t end,\n\t\t\tint datasync);\nextern void block_sync_page(struct page *page);\n\n/* fs/splice.c */\nextern ssize_t generic_file_splice_read(struct file *, loff_t *,\n\t\tstruct pipe_inode_info *, size_t, unsigned int);\nextern ssize_t default_file_splice_read(struct file *, loff_t *,\n\t\tstruct pipe_inode_info *, size_t, unsigned int);\nextern ssize_t iter_file_splice_write(struct pipe_inode_info *,\n\t\tstruct file *, loff_t *, size_t, unsigned int);\nextern ssize_t generic_splice_sendpage(struct pipe_inode_info *pipe,\n\t\tstruct file *out, loff_t *, size_t len, unsigned int flags);\nextern long do_splice_direct(struct file *in, loff_t *ppos, struct file *out,\n\t\tloff_t *opos, size_t len, unsigned int flags);\n\n\nextern void\nfile_ra_state_init(struct file_ra_state *ra, struct address_space *mapping);\nextern loff_t noop_llseek(struct file *file, loff_t offset, int whence);\nextern loff_t no_llseek(struct file *file, loff_t offset, int whence);\nextern loff_t vfs_setpos(struct file *file, loff_t offset, loff_t maxsize);\nextern loff_t generic_file_llseek(struct file *file, loff_t offset, int whence);\nextern loff_t generic_file_llseek_size(struct file *file, loff_t offset,\n\t\tint whence, loff_t maxsize, loff_t eof);\nextern loff_t fixed_size_llseek(struct file *file, loff_t offset,\n\t\tint whence, loff_t size);\nextern int generic_file_open(struct inode * inode, struct file * filp);\nextern int nonseekable_open(struct inode * inode, struct file * filp);\n\n#ifdef CONFIG_FS_XIP\nextern ssize_t xip_file_read(struct file *filp, char __user *buf, size_t len,\n\t\t\t     loff_t *ppos);\nextern int xip_file_mmap(struct file * file, struct vm_area_struct * vma);\nextern ssize_t xip_file_write(struct file *filp, const char __user *buf,\n\t\t\t      size_t len, loff_t *ppos);\nextern int xip_truncate_page(struct address_space *mapping, loff_t from);\n#else\nstatic inline int xip_truncate_page(struct address_space *mapping, loff_t from)\n{\n\treturn 0;\n}\n#endif\n\n#ifdef CONFIG_BLOCK\ntypedef void (dio_submit_t)(int rw, struct bio *bio, struct inode *inode,\n\t\t\t    loff_t file_offset);\n\nenum {\n\t/* need locking between buffered and direct access */\n\tDIO_LOCKING\t= 0x01,\n\n\t/* filesystem does not support filling holes */\n\tDIO_SKIP_HOLES\t= 0x02,\n\n\t/* filesystem can handle aio writes beyond i_size */\n\tDIO_ASYNC_EXTEND = 0x04,\n};\n\nvoid dio_end_io(struct bio *bio, int error);\n\nssize_t __blockdev_direct_IO(int rw, struct kiocb *iocb, struct inode *inode,\n\tstruct block_device *bdev, struct iov_iter *iter, loff_t offset,\n\tget_block_t get_block, dio_iodone_t end_io,\n\tdio_submit_t submit_io,\tint flags);\n\nstatic inline ssize_t blockdev_direct_IO(int rw, struct kiocb *iocb,\n\t\tstruct inode *inode, struct iov_iter *iter, loff_t offset,\n\t\tget_block_t get_block)\n{\n\treturn __blockdev_direct_IO(rw, iocb, inode, inode->i_sb->s_bdev, iter,\n\t\t\t\t    offset, get_block, NULL, NULL,\n\t\t\t\t    DIO_LOCKING | DIO_SKIP_HOLES);\n}\n#endif\n\nvoid inode_dio_wait(struct inode *inode);\nvoid inode_dio_done(struct inode *inode);\n\nextern void inode_set_flags(struct inode *inode, unsigned int flags,\n\t\t\t    unsigned int mask);\n\nextern const struct file_operations generic_ro_fops;\n\n#define special_file(m) (S_ISCHR(m)||S_ISBLK(m)||S_ISFIFO(m)||S_ISSOCK(m))\n\nextern int readlink_copy(char __user *, int, const char *);\nextern int page_readlink(struct dentry *, char __user *, int);\nextern void *page_follow_link_light(struct dentry *, struct nameidata *);\nextern void page_put_link(struct dentry *, struct nameidata *, void *);\nextern int __page_symlink(struct inode *inode, const char *symname, int len,\n\t\tint nofs);\nextern int page_symlink(struct inode *inode, const char *symname, int len);\nextern const struct inode_operations page_symlink_inode_operations;\nextern void kfree_put_link(struct dentry *, struct nameidata *, void *);\nextern int generic_readlink(struct dentry *, char __user *, int);\nextern void generic_fillattr(struct inode *, struct kstat *);\nint vfs_getattr_nosec(struct path *path, struct kstat *stat);\nextern int vfs_getattr(struct path *, struct kstat *);\nvoid __inode_add_bytes(struct inode *inode, loff_t bytes);\nvoid inode_add_bytes(struct inode *inode, loff_t bytes);\nvoid __inode_sub_bytes(struct inode *inode, loff_t bytes);\nvoid inode_sub_bytes(struct inode *inode, loff_t bytes);\nloff_t inode_get_bytes(struct inode *inode);\nvoid inode_set_bytes(struct inode *inode, loff_t bytes);\n\nextern int vfs_readdir(struct file *, filldir_t, void *);\nextern int iterate_dir(struct file *, struct dir_context *);\n\nextern int vfs_stat(const char __user *, struct kstat *);\nextern int vfs_lstat(const char __user *, struct kstat *);\nextern int vfs_fstat(unsigned int, struct kstat *);\nextern int vfs_fstatat(int , const char __user *, struct kstat *, int);\n\nextern int do_vfs_ioctl(struct file *filp, unsigned int fd, unsigned int cmd,\n\t\t    unsigned long arg);\nextern int __generic_block_fiemap(struct inode *inode,\n\t\t\t\t  struct fiemap_extent_info *fieinfo,\n\t\t\t\t  loff_t start, loff_t len,\n\t\t\t\t  get_block_t *get_block);\nextern int generic_block_fiemap(struct inode *inode,\n\t\t\t\tstruct fiemap_extent_info *fieinfo, u64 start,\n\t\t\t\tu64 len, get_block_t *get_block);\n\nextern void get_filesystem(struct file_system_type *fs);\nextern void put_filesystem(struct file_system_type *fs);\nextern struct file_system_type *get_fs_type(const char *name);\nextern struct super_block *get_super(struct block_device *);\nextern struct super_block *get_super_thawed(struct block_device *);\nextern struct super_block *get_active_super(struct block_device *bdev);\nextern void drop_super(struct super_block *sb);\nextern void iterate_supers(void (*)(struct super_block *, void *), void *);\nextern void iterate_supers_type(struct file_system_type *,\n\t\t\t        void (*)(struct super_block *, void *), void *);\n\nextern int dcache_dir_open(struct inode *, struct file *);\nextern int dcache_dir_close(struct inode *, struct file *);\nextern loff_t dcache_dir_lseek(struct file *, loff_t, int);\nextern int dcache_readdir(struct file *, struct dir_context *);\nextern int simple_setattr(struct dentry *, struct iattr *);\nextern int simple_getattr(struct vfsmount *, struct dentry *, struct kstat *);\nextern int simple_statfs(struct dentry *, struct kstatfs *);\nextern int simple_open(struct inode *inode, struct file *file);\nextern int simple_link(struct dentry *, struct inode *, struct dentry *);\nextern int simple_unlink(struct inode *, struct dentry *);\nextern int simple_rmdir(struct inode *, struct dentry *);\nextern int simple_rename(struct inode *, struct dentry *, struct inode *, struct dentry *);\nextern int noop_fsync(struct file *, loff_t, loff_t, int);\nextern int simple_empty(struct dentry *);\nextern int simple_readpage(struct file *file, struct page *page);\nextern int simple_write_begin(struct file *file, struct address_space *mapping,\n\t\t\tloff_t pos, unsigned len, unsigned flags,\n\t\t\tstruct page **pagep, void **fsdata);\nextern int simple_write_end(struct file *file, struct address_space *mapping,\n\t\t\tloff_t pos, unsigned len, unsigned copied,\n\t\t\tstruct page *page, void *fsdata);\nextern int always_delete_dentry(const struct dentry *);\nextern struct inode *alloc_anon_inode(struct super_block *);\nextern int simple_nosetlease(struct file *, long, struct file_lock **, void **);\nextern const struct dentry_operations simple_dentry_operations;\n\nextern struct dentry *simple_lookup(struct inode *, struct dentry *, unsigned int flags);\nextern ssize_t generic_read_dir(struct file *, char __user *, size_t, loff_t *);\nextern const struct file_operations simple_dir_operations;\nextern const struct inode_operations simple_dir_inode_operations;\nstruct tree_descr { char *name; const struct file_operations *ops; int mode; };\nstruct dentry *d_alloc_name(struct dentry *, const char *);\nextern int simple_fill_super(struct super_block *, unsigned long, struct tree_descr *);\nextern int simple_pin_fs(struct file_system_type *, struct vfsmount **mount, int *count);\nextern void simple_release_fs(struct vfsmount **mount, int *count);\n\nextern ssize_t simple_read_from_buffer(void __user *to, size_t count,\n\t\t\tloff_t *ppos, const void *from, size_t available);\nextern ssize_t simple_write_to_buffer(void *to, size_t available, loff_t *ppos,\n\t\tconst void __user *from, size_t count);\n\nextern int __generic_file_fsync(struct file *, loff_t, loff_t, int);\nextern int generic_file_fsync(struct file *, loff_t, loff_t, int);\n\nextern int generic_check_addressable(unsigned, u64);\n\n#ifdef CONFIG_MIGRATION\nextern int buffer_migrate_page(struct address_space *,\n\t\t\t\tstruct page *, struct page *,\n\t\t\t\tenum migrate_mode);\n#else\n#define buffer_migrate_page NULL\n#endif\n\nextern int inode_change_ok(const struct inode *, struct iattr *);\nextern int inode_newsize_ok(const struct inode *, loff_t offset);\nextern void setattr_copy(struct inode *inode, const struct iattr *attr);\n\nextern int file_update_time(struct file *file);\n\nextern int generic_show_options(struct seq_file *m, struct dentry *root);\nextern void save_mount_options(struct super_block *sb, char *options);\nextern void replace_mount_options(struct super_block *sb, char *options);\n\nstatic inline ino_t parent_ino(struct dentry *dentry)\n{\n\tino_t res;\n\n\t/*\n\t * Don't strictly need d_lock here? If the parent ino could change\n\t * then surely we'd have a deeper race in the caller?\n\t */\n\tspin_lock(&dentry->d_lock);\n\tres = dentry->d_parent->d_inode->i_ino;\n\tspin_unlock(&dentry->d_lock);\n\treturn res;\n}\n\n/* Transaction based IO helpers */\n\n/*\n * An argresp is stored in an allocated page and holds the\n * size of the argument or response, along with its content\n */\nstruct simple_transaction_argresp {\n\tssize_t size;\n\tchar data[0];\n};\n\n#define SIMPLE_TRANSACTION_LIMIT (PAGE_SIZE - sizeof(struct simple_transaction_argresp))\n\nchar *simple_transaction_get(struct file *file, const char __user *buf,\n\t\t\t\tsize_t size);\nssize_t simple_transaction_read(struct file *file, char __user *buf,\n\t\t\t\tsize_t size, loff_t *pos);\nint simple_transaction_release(struct inode *inode, struct file *file);\n\nvoid simple_transaction_set(struct file *file, size_t n);\n\n/*\n * simple attribute files\n *\n * These attributes behave similar to those in sysfs:\n *\n * Writing to an attribute immediately sets a value, an open file can be\n * written to multiple times.\n *\n * Reading from an attribute creates a buffer from the value that might get\n * read with multiple read calls. When the attribute has been read\n * completely, no further read calls are possible until the file is opened\n * again.\n *\n * All attributes contain a text representation of a numeric value\n * that are accessed with the get() and set() functions.\n */\n#define DEFINE_SIMPLE_ATTRIBUTE(__fops, __get, __set, __fmt)\t\t\\\nstatic int __fops ## _open(struct inode *inode, struct file *file)\t\\\n{\t\t\t\t\t\t\t\t\t\\\n\t__simple_attr_check_format(__fmt, 0ull);\t\t\t\\\n\treturn simple_attr_open(inode, file, __get, __set, __fmt);\t\\\n}\t\t\t\t\t\t\t\t\t\\\nstatic const struct file_operations __fops = {\t\t\t\t\\\n\t.owner\t = THIS_MODULE,\t\t\t\t\t\t\\\n\t.open\t = __fops ## _open,\t\t\t\t\t\\\n\t.release = simple_attr_release,\t\t\t\t\t\\\n\t.read\t = simple_attr_read,\t\t\t\t\t\\\n\t.write\t = simple_attr_write,\t\t\t\t\t\\\n\t.llseek\t = generic_file_llseek,\t\t\t\t\t\\\n}\n\nstatic inline __printf(1, 2)\nvoid __simple_attr_check_format(const char *fmt, ...)\n{\n\t/* don't do anything, just let the compiler check the arguments; */\n}\n\nint simple_attr_open(struct inode *inode, struct file *file,\n\t\t     int (*get)(void *, u64 *), int (*set)(void *, u64),\n\t\t     const char *fmt);\nint simple_attr_release(struct inode *inode, struct file *file);\nssize_t simple_attr_read(struct file *file, char __user *buf,\n\t\t\t size_t len, loff_t *ppos);\nssize_t simple_attr_write(struct file *file, const char __user *buf,\n\t\t\t  size_t len, loff_t *ppos);\n\nstruct ctl_table;\nint proc_nr_files(struct ctl_table *table, int write,\n\t\t  void __user *buffer, size_t *lenp, loff_t *ppos);\nint proc_nr_dentry(struct ctl_table *table, int write,\n\t\t  void __user *buffer, size_t *lenp, loff_t *ppos);\nint proc_nr_inodes(struct ctl_table *table, int write,\n\t\t   void __user *buffer, size_t *lenp, loff_t *ppos);\nint __init get_filesystem_list(char *buf);\n\n#define __FMODE_EXEC\t\t((__force int) FMODE_EXEC)\n#define __FMODE_NONOTIFY\t((__force int) FMODE_NONOTIFY)\n\n#define ACC_MODE(x) (\"\\004\\002\\006\\006\"[(x)&O_ACCMODE])\n#define OPEN_FMODE(flag) ((__force fmode_t)(((flag + 1) & O_ACCMODE) | \\\n\t\t\t\t\t    (flag & __FMODE_NONOTIFY)))\n\nstatic inline int is_sxid(umode_t mode)\n{\n\treturn (mode & S_ISUID) || ((mode & S_ISGID) && (mode & S_IXGRP));\n}\n\nstatic inline int check_sticky(struct inode *dir, struct inode *inode)\n{\n\tif (!(dir->i_mode & S_ISVTX))\n\t\treturn 0;\n\n\treturn __check_sticky(dir, inode);\n}\n\nstatic inline void inode_has_no_xattr(struct inode *inode)\n{\n\tif (!is_sxid(inode->i_mode) && (inode->i_sb->s_flags & MS_NOSEC))\n\t\tinode->i_flags |= S_NOSEC;\n}\n\nstatic inline bool dir_emit(struct dir_context *ctx,\n\t\t\t    const char *name, int namelen,\n\t\t\t    u64 ino, unsigned type)\n{\n\treturn ctx->actor(ctx, name, namelen, ctx->pos, ino, type) == 0;\n}\nstatic inline bool dir_emit_dot(struct file *file, struct dir_context *ctx)\n{\n\treturn ctx->actor(ctx, \".\", 1, ctx->pos,\n\t\t\t  file->f_path.dentry->d_inode->i_ino, DT_DIR) == 0;\n}\nstatic inline bool dir_emit_dotdot(struct file *file, struct dir_context *ctx)\n{\n\treturn ctx->actor(ctx, \"..\", 2, ctx->pos,\n\t\t\t  parent_ino(file->f_path.dentry), DT_DIR) == 0;\n}\nstatic inline bool dir_emit_dots(struct file *file, struct dir_context *ctx)\n{\n\tif (ctx->pos == 0) {\n\t\tif (!dir_emit_dot(file, ctx))\n\t\t\treturn false;\n\t\tctx->pos = 1;\n\t}\n\tif (ctx->pos == 1) {\n\t\tif (!dir_emit_dotdot(file, ctx))\n\t\t\treturn false;\n\t\tctx->pos = 2;\n\t}\n\treturn true;\n}\nstatic inline bool dir_relax(struct inode *inode)\n{\n\tmutex_unlock(&inode->i_mutex);\n\tmutex_lock(&inode->i_mutex);\n\treturn !IS_DEADDIR(inode);\n}\n\n#endif /* _LINUX_FS_H */\n"], "fixing_code": ["/**\n * eCryptfs: Linux filesystem encryption layer\n *\n * Copyright (C) 1997-2003 Erez Zadok\n * Copyright (C) 2001-2003 Stony Brook University\n * Copyright (C) 2004-2007 International Business Machines Corp.\n *   Author(s): Michael A. Halcrow <mahalcro@us.ibm.com>\n *              Michael C. Thompson <mcthomps@us.ibm.com>\n *              Tyler Hicks <tyhicks@ou.edu>\n *\n * This program is free software; you can redistribute it and/or\n * modify it under the terms of the GNU General Public License as\n * published by the Free Software Foundation; either version 2 of the\n * License, or (at your option) any later version.\n *\n * This program is distributed in the hope that it will be useful, but\n * WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n * General Public License for more details.\n *\n * You should have received a copy of the GNU General Public License\n * along with this program; if not, write to the Free Software\n * Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA\n * 02111-1307, USA.\n */\n\n#include <linux/dcache.h>\n#include <linux/file.h>\n#include <linux/module.h>\n#include <linux/namei.h>\n#include <linux/skbuff.h>\n#include <linux/crypto.h>\n#include <linux/mount.h>\n#include <linux/pagemap.h>\n#include <linux/key.h>\n#include <linux/parser.h>\n#include <linux/fs_stack.h>\n#include <linux/slab.h>\n#include <linux/magic.h>\n#include \"ecryptfs_kernel.h\"\n\n/**\n * Module parameter that defines the ecryptfs_verbosity level.\n */\nint ecryptfs_verbosity = 0;\n\nmodule_param(ecryptfs_verbosity, int, 0);\nMODULE_PARM_DESC(ecryptfs_verbosity,\n\t\t \"Initial verbosity level (0 or 1; defaults to \"\n\t\t \"0, which is Quiet)\");\n\n/**\n * Module parameter that defines the number of message buffer elements\n */\nunsigned int ecryptfs_message_buf_len = ECRYPTFS_DEFAULT_MSG_CTX_ELEMS;\n\nmodule_param(ecryptfs_message_buf_len, uint, 0);\nMODULE_PARM_DESC(ecryptfs_message_buf_len,\n\t\t \"Number of message buffer elements\");\n\n/**\n * Module parameter that defines the maximum guaranteed amount of time to wait\n * for a response from ecryptfsd.  The actual sleep time will be, more than\n * likely, a small amount greater than this specified value, but only less if\n * the message successfully arrives.\n */\nsigned long ecryptfs_message_wait_timeout = ECRYPTFS_MAX_MSG_CTX_TTL / HZ;\n\nmodule_param(ecryptfs_message_wait_timeout, long, 0);\nMODULE_PARM_DESC(ecryptfs_message_wait_timeout,\n\t\t \"Maximum number of seconds that an operation will \"\n\t\t \"sleep while waiting for a message response from \"\n\t\t \"userspace\");\n\n/**\n * Module parameter that is an estimate of the maximum number of users\n * that will be concurrently using eCryptfs. Set this to the right\n * value to balance performance and memory use.\n */\nunsigned int ecryptfs_number_of_users = ECRYPTFS_DEFAULT_NUM_USERS;\n\nmodule_param(ecryptfs_number_of_users, uint, 0);\nMODULE_PARM_DESC(ecryptfs_number_of_users, \"An estimate of the number of \"\n\t\t \"concurrent users of eCryptfs\");\n\nvoid __ecryptfs_printk(const char *fmt, ...)\n{\n\tva_list args;\n\tva_start(args, fmt);\n\tif (fmt[1] == '7') { /* KERN_DEBUG */\n\t\tif (ecryptfs_verbosity >= 1)\n\t\t\tvprintk(fmt, args);\n\t} else\n\t\tvprintk(fmt, args);\n\tva_end(args);\n}\n\n/**\n * ecryptfs_init_lower_file\n * @ecryptfs_dentry: Fully initialized eCryptfs dentry object, with\n *                   the lower dentry and the lower mount set\n *\n * eCryptfs only ever keeps a single open file for every lower\n * inode. All I/O operations to the lower inode occur through that\n * file. When the first eCryptfs dentry that interposes with the first\n * lower dentry for that inode is created, this function creates the\n * lower file struct and associates it with the eCryptfs\n * inode. When all eCryptfs files associated with the inode are released, the\n * file is closed.\n *\n * The lower file will be opened with read/write permissions, if\n * possible. Otherwise, it is opened read-only.\n *\n * This function does nothing if a lower file is already\n * associated with the eCryptfs inode.\n *\n * Returns zero on success; non-zero otherwise\n */\nstatic int ecryptfs_init_lower_file(struct dentry *dentry,\n\t\t\t\t    struct file **lower_file)\n{\n\tconst struct cred *cred = current_cred();\n\tstruct path *path = ecryptfs_dentry_to_lower_path(dentry);\n\tint rc;\n\n\trc = ecryptfs_privileged_open(lower_file, path->dentry, path->mnt,\n\t\t\t\t      cred);\n\tif (rc) {\n\t\tprintk(KERN_ERR \"Error opening lower file \"\n\t\t       \"for lower_dentry [0x%p] and lower_mnt [0x%p]; \"\n\t\t       \"rc = [%d]\\n\", path->dentry, path->mnt, rc);\n\t\t(*lower_file) = NULL;\n\t}\n\treturn rc;\n}\n\nint ecryptfs_get_lower_file(struct dentry *dentry, struct inode *inode)\n{\n\tstruct ecryptfs_inode_info *inode_info;\n\tint count, rc = 0;\n\n\tinode_info = ecryptfs_inode_to_private(inode);\n\tmutex_lock(&inode_info->lower_file_mutex);\n\tcount = atomic_inc_return(&inode_info->lower_file_count);\n\tif (WARN_ON_ONCE(count < 1))\n\t\trc = -EINVAL;\n\telse if (count == 1) {\n\t\trc = ecryptfs_init_lower_file(dentry,\n\t\t\t\t\t      &inode_info->lower_file);\n\t\tif (rc)\n\t\t\tatomic_set(&inode_info->lower_file_count, 0);\n\t}\n\tmutex_unlock(&inode_info->lower_file_mutex);\n\treturn rc;\n}\n\nvoid ecryptfs_put_lower_file(struct inode *inode)\n{\n\tstruct ecryptfs_inode_info *inode_info;\n\n\tinode_info = ecryptfs_inode_to_private(inode);\n\tif (atomic_dec_and_mutex_lock(&inode_info->lower_file_count,\n\t\t\t\t      &inode_info->lower_file_mutex)) {\n\t\tfilemap_write_and_wait(inode->i_mapping);\n\t\tfput(inode_info->lower_file);\n\t\tinode_info->lower_file = NULL;\n\t\tmutex_unlock(&inode_info->lower_file_mutex);\n\t}\n}\n\nenum { ecryptfs_opt_sig, ecryptfs_opt_ecryptfs_sig,\n       ecryptfs_opt_cipher, ecryptfs_opt_ecryptfs_cipher,\n       ecryptfs_opt_ecryptfs_key_bytes,\n       ecryptfs_opt_passthrough, ecryptfs_opt_xattr_metadata,\n       ecryptfs_opt_encrypted_view, ecryptfs_opt_fnek_sig,\n       ecryptfs_opt_fn_cipher, ecryptfs_opt_fn_cipher_key_bytes,\n       ecryptfs_opt_unlink_sigs, ecryptfs_opt_mount_auth_tok_only,\n       ecryptfs_opt_check_dev_ruid,\n       ecryptfs_opt_err };\n\nstatic const match_table_t tokens = {\n\t{ecryptfs_opt_sig, \"sig=%s\"},\n\t{ecryptfs_opt_ecryptfs_sig, \"ecryptfs_sig=%s\"},\n\t{ecryptfs_opt_cipher, \"cipher=%s\"},\n\t{ecryptfs_opt_ecryptfs_cipher, \"ecryptfs_cipher=%s\"},\n\t{ecryptfs_opt_ecryptfs_key_bytes, \"ecryptfs_key_bytes=%u\"},\n\t{ecryptfs_opt_passthrough, \"ecryptfs_passthrough\"},\n\t{ecryptfs_opt_xattr_metadata, \"ecryptfs_xattr_metadata\"},\n\t{ecryptfs_opt_encrypted_view, \"ecryptfs_encrypted_view\"},\n\t{ecryptfs_opt_fnek_sig, \"ecryptfs_fnek_sig=%s\"},\n\t{ecryptfs_opt_fn_cipher, \"ecryptfs_fn_cipher=%s\"},\n\t{ecryptfs_opt_fn_cipher_key_bytes, \"ecryptfs_fn_key_bytes=%u\"},\n\t{ecryptfs_opt_unlink_sigs, \"ecryptfs_unlink_sigs\"},\n\t{ecryptfs_opt_mount_auth_tok_only, \"ecryptfs_mount_auth_tok_only\"},\n\t{ecryptfs_opt_check_dev_ruid, \"ecryptfs_check_dev_ruid\"},\n\t{ecryptfs_opt_err, NULL}\n};\n\nstatic int ecryptfs_init_global_auth_toks(\n\tstruct ecryptfs_mount_crypt_stat *mount_crypt_stat)\n{\n\tstruct ecryptfs_global_auth_tok *global_auth_tok;\n\tstruct ecryptfs_auth_tok *auth_tok;\n\tint rc = 0;\n\n\tlist_for_each_entry(global_auth_tok,\n\t\t\t    &mount_crypt_stat->global_auth_tok_list,\n\t\t\t    mount_crypt_stat_list) {\n\t\trc = ecryptfs_keyring_auth_tok_for_sig(\n\t\t\t&global_auth_tok->global_auth_tok_key, &auth_tok,\n\t\t\tglobal_auth_tok->sig);\n\t\tif (rc) {\n\t\t\tprintk(KERN_ERR \"Could not find valid key in user \"\n\t\t\t       \"session keyring for sig specified in mount \"\n\t\t\t       \"option: [%s]\\n\", global_auth_tok->sig);\n\t\t\tglobal_auth_tok->flags |= ECRYPTFS_AUTH_TOK_INVALID;\n\t\t\tgoto out;\n\t\t} else {\n\t\t\tglobal_auth_tok->flags &= ~ECRYPTFS_AUTH_TOK_INVALID;\n\t\t\tup_write(&(global_auth_tok->global_auth_tok_key)->sem);\n\t\t}\n\t}\nout:\n\treturn rc;\n}\n\nstatic void ecryptfs_init_mount_crypt_stat(\n\tstruct ecryptfs_mount_crypt_stat *mount_crypt_stat)\n{\n\tmemset((void *)mount_crypt_stat, 0,\n\t       sizeof(struct ecryptfs_mount_crypt_stat));\n\tINIT_LIST_HEAD(&mount_crypt_stat->global_auth_tok_list);\n\tmutex_init(&mount_crypt_stat->global_auth_tok_list_mutex);\n\tmount_crypt_stat->flags |= ECRYPTFS_MOUNT_CRYPT_STAT_INITIALIZED;\n}\n\n/**\n * ecryptfs_parse_options\n * @sb: The ecryptfs super block\n * @options: The options passed to the kernel\n * @check_ruid: set to 1 if device uid should be checked against the ruid\n *\n * Parse mount options:\n * debug=N \t   - ecryptfs_verbosity level for debug output\n * sig=XXX\t   - description(signature) of the key to use\n *\n * Returns the dentry object of the lower-level (lower/interposed)\n * directory; We want to mount our stackable file system on top of\n * that lower directory.\n *\n * The signature of the key to use must be the description of a key\n * already in the keyring. Mounting will fail if the key can not be\n * found.\n *\n * Returns zero on success; non-zero on error\n */\nstatic int ecryptfs_parse_options(struct ecryptfs_sb_info *sbi, char *options,\n\t\t\t\t  uid_t *check_ruid)\n{\n\tchar *p;\n\tint rc = 0;\n\tint sig_set = 0;\n\tint cipher_name_set = 0;\n\tint fn_cipher_name_set = 0;\n\tint cipher_key_bytes;\n\tint cipher_key_bytes_set = 0;\n\tint fn_cipher_key_bytes;\n\tint fn_cipher_key_bytes_set = 0;\n\tstruct ecryptfs_mount_crypt_stat *mount_crypt_stat =\n\t\t&sbi->mount_crypt_stat;\n\tsubstring_t args[MAX_OPT_ARGS];\n\tint token;\n\tchar *sig_src;\n\tchar *cipher_name_dst;\n\tchar *cipher_name_src;\n\tchar *fn_cipher_name_dst;\n\tchar *fn_cipher_name_src;\n\tchar *fnek_dst;\n\tchar *fnek_src;\n\tchar *cipher_key_bytes_src;\n\tchar *fn_cipher_key_bytes_src;\n\tu8 cipher_code;\n\n\t*check_ruid = 0;\n\n\tif (!options) {\n\t\trc = -EINVAL;\n\t\tgoto out;\n\t}\n\tecryptfs_init_mount_crypt_stat(mount_crypt_stat);\n\twhile ((p = strsep(&options, \",\")) != NULL) {\n\t\tif (!*p)\n\t\t\tcontinue;\n\t\ttoken = match_token(p, tokens, args);\n\t\tswitch (token) {\n\t\tcase ecryptfs_opt_sig:\n\t\tcase ecryptfs_opt_ecryptfs_sig:\n\t\t\tsig_src = args[0].from;\n\t\t\trc = ecryptfs_add_global_auth_tok(mount_crypt_stat,\n\t\t\t\t\t\t\t  sig_src, 0);\n\t\t\tif (rc) {\n\t\t\t\tprintk(KERN_ERR \"Error attempting to register \"\n\t\t\t\t       \"global sig; rc = [%d]\\n\", rc);\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\tsig_set = 1;\n\t\t\tbreak;\n\t\tcase ecryptfs_opt_cipher:\n\t\tcase ecryptfs_opt_ecryptfs_cipher:\n\t\t\tcipher_name_src = args[0].from;\n\t\t\tcipher_name_dst =\n\t\t\t\tmount_crypt_stat->\n\t\t\t\tglobal_default_cipher_name;\n\t\t\tstrncpy(cipher_name_dst, cipher_name_src,\n\t\t\t\tECRYPTFS_MAX_CIPHER_NAME_SIZE);\n\t\t\tcipher_name_dst[ECRYPTFS_MAX_CIPHER_NAME_SIZE] = '\\0';\n\t\t\tcipher_name_set = 1;\n\t\t\tbreak;\n\t\tcase ecryptfs_opt_ecryptfs_key_bytes:\n\t\t\tcipher_key_bytes_src = args[0].from;\n\t\t\tcipher_key_bytes =\n\t\t\t\t(int)simple_strtol(cipher_key_bytes_src,\n\t\t\t\t\t\t   &cipher_key_bytes_src, 0);\n\t\t\tmount_crypt_stat->global_default_cipher_key_size =\n\t\t\t\tcipher_key_bytes;\n\t\t\tcipher_key_bytes_set = 1;\n\t\t\tbreak;\n\t\tcase ecryptfs_opt_passthrough:\n\t\t\tmount_crypt_stat->flags |=\n\t\t\t\tECRYPTFS_PLAINTEXT_PASSTHROUGH_ENABLED;\n\t\t\tbreak;\n\t\tcase ecryptfs_opt_xattr_metadata:\n\t\t\tmount_crypt_stat->flags |=\n\t\t\t\tECRYPTFS_XATTR_METADATA_ENABLED;\n\t\t\tbreak;\n\t\tcase ecryptfs_opt_encrypted_view:\n\t\t\tmount_crypt_stat->flags |=\n\t\t\t\tECRYPTFS_XATTR_METADATA_ENABLED;\n\t\t\tmount_crypt_stat->flags |=\n\t\t\t\tECRYPTFS_ENCRYPTED_VIEW_ENABLED;\n\t\t\tbreak;\n\t\tcase ecryptfs_opt_fnek_sig:\n\t\t\tfnek_src = args[0].from;\n\t\t\tfnek_dst =\n\t\t\t\tmount_crypt_stat->global_default_fnek_sig;\n\t\t\tstrncpy(fnek_dst, fnek_src, ECRYPTFS_SIG_SIZE_HEX);\n\t\t\tmount_crypt_stat->global_default_fnek_sig[\n\t\t\t\tECRYPTFS_SIG_SIZE_HEX] = '\\0';\n\t\t\trc = ecryptfs_add_global_auth_tok(\n\t\t\t\tmount_crypt_stat,\n\t\t\t\tmount_crypt_stat->global_default_fnek_sig,\n\t\t\t\tECRYPTFS_AUTH_TOK_FNEK);\n\t\t\tif (rc) {\n\t\t\t\tprintk(KERN_ERR \"Error attempting to register \"\n\t\t\t\t       \"global fnek sig [%s]; rc = [%d]\\n\",\n\t\t\t\t       mount_crypt_stat->global_default_fnek_sig,\n\t\t\t\t       rc);\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\tmount_crypt_stat->flags |=\n\t\t\t\t(ECRYPTFS_GLOBAL_ENCRYPT_FILENAMES\n\t\t\t\t | ECRYPTFS_GLOBAL_ENCFN_USE_MOUNT_FNEK);\n\t\t\tbreak;\n\t\tcase ecryptfs_opt_fn_cipher:\n\t\t\tfn_cipher_name_src = args[0].from;\n\t\t\tfn_cipher_name_dst =\n\t\t\t\tmount_crypt_stat->global_default_fn_cipher_name;\n\t\t\tstrncpy(fn_cipher_name_dst, fn_cipher_name_src,\n\t\t\t\tECRYPTFS_MAX_CIPHER_NAME_SIZE);\n\t\t\tmount_crypt_stat->global_default_fn_cipher_name[\n\t\t\t\tECRYPTFS_MAX_CIPHER_NAME_SIZE] = '\\0';\n\t\t\tfn_cipher_name_set = 1;\n\t\t\tbreak;\n\t\tcase ecryptfs_opt_fn_cipher_key_bytes:\n\t\t\tfn_cipher_key_bytes_src = args[0].from;\n\t\t\tfn_cipher_key_bytes =\n\t\t\t\t(int)simple_strtol(fn_cipher_key_bytes_src,\n\t\t\t\t\t\t   &fn_cipher_key_bytes_src, 0);\n\t\t\tmount_crypt_stat->global_default_fn_cipher_key_bytes =\n\t\t\t\tfn_cipher_key_bytes;\n\t\t\tfn_cipher_key_bytes_set = 1;\n\t\t\tbreak;\n\t\tcase ecryptfs_opt_unlink_sigs:\n\t\t\tmount_crypt_stat->flags |= ECRYPTFS_UNLINK_SIGS;\n\t\t\tbreak;\n\t\tcase ecryptfs_opt_mount_auth_tok_only:\n\t\t\tmount_crypt_stat->flags |=\n\t\t\t\tECRYPTFS_GLOBAL_MOUNT_AUTH_TOK_ONLY;\n\t\t\tbreak;\n\t\tcase ecryptfs_opt_check_dev_ruid:\n\t\t\t*check_ruid = 1;\n\t\t\tbreak;\n\t\tcase ecryptfs_opt_err:\n\t\tdefault:\n\t\t\tprintk(KERN_WARNING\n\t\t\t       \"%s: eCryptfs: unrecognized option [%s]\\n\",\n\t\t\t       __func__, p);\n\t\t}\n\t}\n\tif (!sig_set) {\n\t\trc = -EINVAL;\n\t\tecryptfs_printk(KERN_ERR, \"You must supply at least one valid \"\n\t\t\t\t\"auth tok signature as a mount \"\n\t\t\t\t\"parameter; see the eCryptfs README\\n\");\n\t\tgoto out;\n\t}\n\tif (!cipher_name_set) {\n\t\tint cipher_name_len = strlen(ECRYPTFS_DEFAULT_CIPHER);\n\n\t\tBUG_ON(cipher_name_len >= ECRYPTFS_MAX_CIPHER_NAME_SIZE);\n\t\tstrcpy(mount_crypt_stat->global_default_cipher_name,\n\t\t       ECRYPTFS_DEFAULT_CIPHER);\n\t}\n\tif ((mount_crypt_stat->flags & ECRYPTFS_GLOBAL_ENCRYPT_FILENAMES)\n\t    && !fn_cipher_name_set)\n\t\tstrcpy(mount_crypt_stat->global_default_fn_cipher_name,\n\t\t       mount_crypt_stat->global_default_cipher_name);\n\tif (!cipher_key_bytes_set)\n\t\tmount_crypt_stat->global_default_cipher_key_size = 0;\n\tif ((mount_crypt_stat->flags & ECRYPTFS_GLOBAL_ENCRYPT_FILENAMES)\n\t    && !fn_cipher_key_bytes_set)\n\t\tmount_crypt_stat->global_default_fn_cipher_key_bytes =\n\t\t\tmount_crypt_stat->global_default_cipher_key_size;\n\n\tcipher_code = ecryptfs_code_for_cipher_string(\n\t\tmount_crypt_stat->global_default_cipher_name,\n\t\tmount_crypt_stat->global_default_cipher_key_size);\n\tif (!cipher_code) {\n\t\tecryptfs_printk(KERN_ERR,\n\t\t\t\t\"eCryptfs doesn't support cipher: %s\",\n\t\t\t\tmount_crypt_stat->global_default_cipher_name);\n\t\trc = -EINVAL;\n\t\tgoto out;\n\t}\n\n\tmutex_lock(&key_tfm_list_mutex);\n\tif (!ecryptfs_tfm_exists(mount_crypt_stat->global_default_cipher_name,\n\t\t\t\t NULL)) {\n\t\trc = ecryptfs_add_new_key_tfm(\n\t\t\tNULL, mount_crypt_stat->global_default_cipher_name,\n\t\t\tmount_crypt_stat->global_default_cipher_key_size);\n\t\tif (rc) {\n\t\t\tprintk(KERN_ERR \"Error attempting to initialize \"\n\t\t\t       \"cipher with name = [%s] and key size = [%td]; \"\n\t\t\t       \"rc = [%d]\\n\",\n\t\t\t       mount_crypt_stat->global_default_cipher_name,\n\t\t\t       mount_crypt_stat->global_default_cipher_key_size,\n\t\t\t       rc);\n\t\t\trc = -EINVAL;\n\t\t\tmutex_unlock(&key_tfm_list_mutex);\n\t\t\tgoto out;\n\t\t}\n\t}\n\tif ((mount_crypt_stat->flags & ECRYPTFS_GLOBAL_ENCRYPT_FILENAMES)\n\t    && !ecryptfs_tfm_exists(\n\t\t    mount_crypt_stat->global_default_fn_cipher_name, NULL)) {\n\t\trc = ecryptfs_add_new_key_tfm(\n\t\t\tNULL, mount_crypt_stat->global_default_fn_cipher_name,\n\t\t\tmount_crypt_stat->global_default_fn_cipher_key_bytes);\n\t\tif (rc) {\n\t\t\tprintk(KERN_ERR \"Error attempting to initialize \"\n\t\t\t       \"cipher with name = [%s] and key size = [%td]; \"\n\t\t\t       \"rc = [%d]\\n\",\n\t\t\t       mount_crypt_stat->global_default_fn_cipher_name,\n\t\t\t       mount_crypt_stat->global_default_fn_cipher_key_bytes,\n\t\t\t       rc);\n\t\t\trc = -EINVAL;\n\t\t\tmutex_unlock(&key_tfm_list_mutex);\n\t\t\tgoto out;\n\t\t}\n\t}\n\tmutex_unlock(&key_tfm_list_mutex);\n\trc = ecryptfs_init_global_auth_toks(mount_crypt_stat);\n\tif (rc)\n\t\tprintk(KERN_WARNING \"One or more global auth toks could not \"\n\t\t       \"properly register; rc = [%d]\\n\", rc);\nout:\n\treturn rc;\n}\n\nstruct kmem_cache *ecryptfs_sb_info_cache;\nstatic struct file_system_type ecryptfs_fs_type;\n\n/**\n * ecryptfs_get_sb\n * @fs_type\n * @flags\n * @dev_name: The path to mount over\n * @raw_data: The options passed into the kernel\n */\nstatic struct dentry *ecryptfs_mount(struct file_system_type *fs_type, int flags,\n\t\t\tconst char *dev_name, void *raw_data)\n{\n\tstruct super_block *s;\n\tstruct ecryptfs_sb_info *sbi;\n\tstruct ecryptfs_dentry_info *root_info;\n\tconst char *err = \"Getting sb failed\";\n\tstruct inode *inode;\n\tstruct path path;\n\tuid_t check_ruid;\n\tint rc;\n\n\tsbi = kmem_cache_zalloc(ecryptfs_sb_info_cache, GFP_KERNEL);\n\tif (!sbi) {\n\t\trc = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\trc = ecryptfs_parse_options(sbi, raw_data, &check_ruid);\n\tif (rc) {\n\t\terr = \"Error parsing options\";\n\t\tgoto out;\n\t}\n\n\ts = sget(fs_type, NULL, set_anon_super, flags, NULL);\n\tif (IS_ERR(s)) {\n\t\trc = PTR_ERR(s);\n\t\tgoto out;\n\t}\n\n\trc = bdi_setup_and_register(&sbi->bdi, \"ecryptfs\", BDI_CAP_MAP_COPY);\n\tif (rc)\n\t\tgoto out1;\n\n\tecryptfs_set_superblock_private(s, sbi);\n\ts->s_bdi = &sbi->bdi;\n\n\t/* ->kill_sb() will take care of sbi after that point */\n\tsbi = NULL;\n\ts->s_op = &ecryptfs_sops;\n\ts->s_d_op = &ecryptfs_dops;\n\n\terr = \"Reading sb failed\";\n\trc = kern_path(dev_name, LOOKUP_FOLLOW | LOOKUP_DIRECTORY, &path);\n\tif (rc) {\n\t\tecryptfs_printk(KERN_WARNING, \"kern_path() failed\\n\");\n\t\tgoto out1;\n\t}\n\tif (path.dentry->d_sb->s_type == &ecryptfs_fs_type) {\n\t\trc = -EINVAL;\n\t\tprintk(KERN_ERR \"Mount on filesystem of type \"\n\t\t\t\"eCryptfs explicitly disallowed due to \"\n\t\t\t\"known incompatibilities\\n\");\n\t\tgoto out_free;\n\t}\n\n\tif (check_ruid && !uid_eq(path.dentry->d_inode->i_uid, current_uid())) {\n\t\trc = -EPERM;\n\t\tprintk(KERN_ERR \"Mount of device (uid: %d) not owned by \"\n\t\t       \"requested user (uid: %d)\\n\",\n\t\t\ti_uid_read(path.dentry->d_inode),\n\t\t\tfrom_kuid(&init_user_ns, current_uid()));\n\t\tgoto out_free;\n\t}\n\n\tecryptfs_set_superblock_lower(s, path.dentry->d_sb);\n\n\t/**\n\t * Set the POSIX ACL flag based on whether they're enabled in the lower\n\t * mount. Force a read-only eCryptfs mount if the lower mount is ro.\n\t * Allow a ro eCryptfs mount even when the lower mount is rw.\n\t */\n\ts->s_flags = flags & ~MS_POSIXACL;\n\ts->s_flags |= path.dentry->d_sb->s_flags & (MS_RDONLY | MS_POSIXACL);\n\n\ts->s_maxbytes = path.dentry->d_sb->s_maxbytes;\n\ts->s_blocksize = path.dentry->d_sb->s_blocksize;\n\ts->s_magic = ECRYPTFS_SUPER_MAGIC;\n\ts->s_stack_depth = path.dentry->d_sb->s_stack_depth + 1;\n\n\trc = -EINVAL;\n\tif (s->s_stack_depth > FILESYSTEM_MAX_STACK_DEPTH) {\n\t\tpr_err(\"eCryptfs: maximum fs stacking depth exceeded\\n\");\n\t\tgoto out_free;\n\t}\n\n\tinode = ecryptfs_get_inode(path.dentry->d_inode, s);\n\trc = PTR_ERR(inode);\n\tif (IS_ERR(inode))\n\t\tgoto out_free;\n\n\ts->s_root = d_make_root(inode);\n\tif (!s->s_root) {\n\t\trc = -ENOMEM;\n\t\tgoto out_free;\n\t}\n\n\trc = -ENOMEM;\n\troot_info = kmem_cache_zalloc(ecryptfs_dentry_info_cache, GFP_KERNEL);\n\tif (!root_info)\n\t\tgoto out_free;\n\n\t/* ->kill_sb() will take care of root_info */\n\tecryptfs_set_dentry_private(s->s_root, root_info);\n\troot_info->lower_path = path;\n\n\ts->s_flags |= MS_ACTIVE;\n\treturn dget(s->s_root);\n\nout_free:\n\tpath_put(&path);\nout1:\n\tdeactivate_locked_super(s);\nout:\n\tif (sbi) {\n\t\tecryptfs_destroy_mount_crypt_stat(&sbi->mount_crypt_stat);\n\t\tkmem_cache_free(ecryptfs_sb_info_cache, sbi);\n\t}\n\tprintk(KERN_ERR \"%s; rc = [%d]\\n\", err, rc);\n\treturn ERR_PTR(rc);\n}\n\n/**\n * ecryptfs_kill_block_super\n * @sb: The ecryptfs super block\n *\n * Used to bring the superblock down and free the private data.\n */\nstatic void ecryptfs_kill_block_super(struct super_block *sb)\n{\n\tstruct ecryptfs_sb_info *sb_info = ecryptfs_superblock_to_private(sb);\n\tkill_anon_super(sb);\n\tif (!sb_info)\n\t\treturn;\n\tecryptfs_destroy_mount_crypt_stat(&sb_info->mount_crypt_stat);\n\tbdi_destroy(&sb_info->bdi);\n\tkmem_cache_free(ecryptfs_sb_info_cache, sb_info);\n}\n\nstatic struct file_system_type ecryptfs_fs_type = {\n\t.owner = THIS_MODULE,\n\t.name = \"ecryptfs\",\n\t.mount = ecryptfs_mount,\n\t.kill_sb = ecryptfs_kill_block_super,\n\t.fs_flags = 0\n};\nMODULE_ALIAS_FS(\"ecryptfs\");\n\n/**\n * inode_info_init_once\n *\n * Initializes the ecryptfs_inode_info_cache when it is created\n */\nstatic void\ninode_info_init_once(void *vptr)\n{\n\tstruct ecryptfs_inode_info *ei = (struct ecryptfs_inode_info *)vptr;\n\n\tinode_init_once(&ei->vfs_inode);\n}\n\nstatic struct ecryptfs_cache_info {\n\tstruct kmem_cache **cache;\n\tconst char *name;\n\tsize_t size;\n\tvoid (*ctor)(void *obj);\n} ecryptfs_cache_infos[] = {\n\t{\n\t\t.cache = &ecryptfs_auth_tok_list_item_cache,\n\t\t.name = \"ecryptfs_auth_tok_list_item\",\n\t\t.size = sizeof(struct ecryptfs_auth_tok_list_item),\n\t},\n\t{\n\t\t.cache = &ecryptfs_file_info_cache,\n\t\t.name = \"ecryptfs_file_cache\",\n\t\t.size = sizeof(struct ecryptfs_file_info),\n\t},\n\t{\n\t\t.cache = &ecryptfs_dentry_info_cache,\n\t\t.name = \"ecryptfs_dentry_info_cache\",\n\t\t.size = sizeof(struct ecryptfs_dentry_info),\n\t},\n\t{\n\t\t.cache = &ecryptfs_inode_info_cache,\n\t\t.name = \"ecryptfs_inode_cache\",\n\t\t.size = sizeof(struct ecryptfs_inode_info),\n\t\t.ctor = inode_info_init_once,\n\t},\n\t{\n\t\t.cache = &ecryptfs_sb_info_cache,\n\t\t.name = \"ecryptfs_sb_cache\",\n\t\t.size = sizeof(struct ecryptfs_sb_info),\n\t},\n\t{\n\t\t.cache = &ecryptfs_header_cache,\n\t\t.name = \"ecryptfs_headers\",\n\t\t.size = PAGE_CACHE_SIZE,\n\t},\n\t{\n\t\t.cache = &ecryptfs_xattr_cache,\n\t\t.name = \"ecryptfs_xattr_cache\",\n\t\t.size = PAGE_CACHE_SIZE,\n\t},\n\t{\n\t\t.cache = &ecryptfs_key_record_cache,\n\t\t.name = \"ecryptfs_key_record_cache\",\n\t\t.size = sizeof(struct ecryptfs_key_record),\n\t},\n\t{\n\t\t.cache = &ecryptfs_key_sig_cache,\n\t\t.name = \"ecryptfs_key_sig_cache\",\n\t\t.size = sizeof(struct ecryptfs_key_sig),\n\t},\n\t{\n\t\t.cache = &ecryptfs_global_auth_tok_cache,\n\t\t.name = \"ecryptfs_global_auth_tok_cache\",\n\t\t.size = sizeof(struct ecryptfs_global_auth_tok),\n\t},\n\t{\n\t\t.cache = &ecryptfs_key_tfm_cache,\n\t\t.name = \"ecryptfs_key_tfm_cache\",\n\t\t.size = sizeof(struct ecryptfs_key_tfm),\n\t},\n};\n\nstatic void ecryptfs_free_kmem_caches(void)\n{\n\tint i;\n\n\t/*\n\t * Make sure all delayed rcu free inodes are flushed before we\n\t * destroy cache.\n\t */\n\trcu_barrier();\n\n\tfor (i = 0; i < ARRAY_SIZE(ecryptfs_cache_infos); i++) {\n\t\tstruct ecryptfs_cache_info *info;\n\n\t\tinfo = &ecryptfs_cache_infos[i];\n\t\tif (*(info->cache))\n\t\t\tkmem_cache_destroy(*(info->cache));\n\t}\n}\n\n/**\n * ecryptfs_init_kmem_caches\n *\n * Returns zero on success; non-zero otherwise\n */\nstatic int ecryptfs_init_kmem_caches(void)\n{\n\tint i;\n\n\tfor (i = 0; i < ARRAY_SIZE(ecryptfs_cache_infos); i++) {\n\t\tstruct ecryptfs_cache_info *info;\n\n\t\tinfo = &ecryptfs_cache_infos[i];\n\t\t*(info->cache) = kmem_cache_create(info->name, info->size,\n\t\t\t\t0, SLAB_HWCACHE_ALIGN, info->ctor);\n\t\tif (!*(info->cache)) {\n\t\t\tecryptfs_free_kmem_caches();\n\t\t\tecryptfs_printk(KERN_WARNING, \"%s: \"\n\t\t\t\t\t\"kmem_cache_create failed\\n\",\n\t\t\t\t\tinfo->name);\n\t\t\treturn -ENOMEM;\n\t\t}\n\t}\n\treturn 0;\n}\n\nstatic struct kobject *ecryptfs_kobj;\n\nstatic ssize_t version_show(struct kobject *kobj,\n\t\t\t    struct kobj_attribute *attr, char *buff)\n{\n\treturn snprintf(buff, PAGE_SIZE, \"%d\\n\", ECRYPTFS_VERSIONING_MASK);\n}\n\nstatic struct kobj_attribute version_attr = __ATTR_RO(version);\n\nstatic struct attribute *attributes[] = {\n\t&version_attr.attr,\n\tNULL,\n};\n\nstatic struct attribute_group attr_group = {\n\t.attrs = attributes,\n};\n\nstatic int do_sysfs_registration(void)\n{\n\tint rc;\n\n\tecryptfs_kobj = kobject_create_and_add(\"ecryptfs\", fs_kobj);\n\tif (!ecryptfs_kobj) {\n\t\tprintk(KERN_ERR \"Unable to create ecryptfs kset\\n\");\n\t\trc = -ENOMEM;\n\t\tgoto out;\n\t}\n\trc = sysfs_create_group(ecryptfs_kobj, &attr_group);\n\tif (rc) {\n\t\tprintk(KERN_ERR\n\t\t       \"Unable to create ecryptfs version attributes\\n\");\n\t\tkobject_put(ecryptfs_kobj);\n\t}\nout:\n\treturn rc;\n}\n\nstatic void do_sysfs_unregistration(void)\n{\n\tsysfs_remove_group(ecryptfs_kobj, &attr_group);\n\tkobject_put(ecryptfs_kobj);\n}\n\nstatic int __init ecryptfs_init(void)\n{\n\tint rc;\n\n\tif (ECRYPTFS_DEFAULT_EXTENT_SIZE > PAGE_CACHE_SIZE) {\n\t\trc = -EINVAL;\n\t\tecryptfs_printk(KERN_ERR, \"The eCryptfs extent size is \"\n\t\t\t\t\"larger than the host's page size, and so \"\n\t\t\t\t\"eCryptfs cannot run on this system. The \"\n\t\t\t\t\"default eCryptfs extent size is [%u] bytes; \"\n\t\t\t\t\"the page size is [%lu] bytes.\\n\",\n\t\t\t\tECRYPTFS_DEFAULT_EXTENT_SIZE,\n\t\t\t\t(unsigned long)PAGE_CACHE_SIZE);\n\t\tgoto out;\n\t}\n\trc = ecryptfs_init_kmem_caches();\n\tif (rc) {\n\t\tprintk(KERN_ERR\n\t\t       \"Failed to allocate one or more kmem_cache objects\\n\");\n\t\tgoto out;\n\t}\n\trc = do_sysfs_registration();\n\tif (rc) {\n\t\tprintk(KERN_ERR \"sysfs registration failed\\n\");\n\t\tgoto out_free_kmem_caches;\n\t}\n\trc = ecryptfs_init_kthread();\n\tif (rc) {\n\t\tprintk(KERN_ERR \"%s: kthread initialization failed; \"\n\t\t       \"rc = [%d]\\n\", __func__, rc);\n\t\tgoto out_do_sysfs_unregistration;\n\t}\n\trc = ecryptfs_init_messaging();\n\tif (rc) {\n\t\tprintk(KERN_ERR \"Failure occurred while attempting to \"\n\t\t\t\t\"initialize the communications channel to \"\n\t\t\t\t\"ecryptfsd\\n\");\n\t\tgoto out_destroy_kthread;\n\t}\n\trc = ecryptfs_init_crypto();\n\tif (rc) {\n\t\tprintk(KERN_ERR \"Failure whilst attempting to init crypto; \"\n\t\t       \"rc = [%d]\\n\", rc);\n\t\tgoto out_release_messaging;\n\t}\n\trc = register_filesystem(&ecryptfs_fs_type);\n\tif (rc) {\n\t\tprintk(KERN_ERR \"Failed to register filesystem\\n\");\n\t\tgoto out_destroy_crypto;\n\t}\n\tif (ecryptfs_verbosity > 0)\n\t\tprintk(KERN_CRIT \"eCryptfs verbosity set to %d. Secret values \"\n\t\t\t\"will be written to the syslog!\\n\", ecryptfs_verbosity);\n\n\tgoto out;\nout_destroy_crypto:\n\tecryptfs_destroy_crypto();\nout_release_messaging:\n\tecryptfs_release_messaging();\nout_destroy_kthread:\n\tecryptfs_destroy_kthread();\nout_do_sysfs_unregistration:\n\tdo_sysfs_unregistration();\nout_free_kmem_caches:\n\tecryptfs_free_kmem_caches();\nout:\n\treturn rc;\n}\n\nstatic void __exit ecryptfs_exit(void)\n{\n\tint rc;\n\n\trc = ecryptfs_destroy_crypto();\n\tif (rc)\n\t\tprintk(KERN_ERR \"Failure whilst attempting to destroy crypto; \"\n\t\t       \"rc = [%d]\\n\", rc);\n\tecryptfs_release_messaging();\n\tecryptfs_destroy_kthread();\n\tdo_sysfs_unregistration();\n\tunregister_filesystem(&ecryptfs_fs_type);\n\tecryptfs_free_kmem_caches();\n}\n\nMODULE_AUTHOR(\"Michael A. Halcrow <mhalcrow@us.ibm.com>\");\nMODULE_DESCRIPTION(\"eCryptfs\");\n\nMODULE_LICENSE(\"GPL\");\n\nmodule_init(ecryptfs_init)\nmodule_exit(ecryptfs_exit)\n", "/*\n *\n * Copyright (C) 2011 Novell Inc.\n *\n * This program is free software; you can redistribute it and/or modify it\n * under the terms of the GNU General Public License version 2 as published by\n * the Free Software Foundation.\n */\n\n#include <linux/fs.h>\n#include <linux/namei.h>\n#include <linux/xattr.h>\n#include <linux/security.h>\n#include <linux/mount.h>\n#include <linux/slab.h>\n#include <linux/parser.h>\n#include <linux/module.h>\n#include <linux/sched.h>\n#include <linux/statfs.h>\n#include <linux/seq_file.h>\n#include \"overlayfs.h\"\n\nMODULE_AUTHOR(\"Miklos Szeredi <miklos@szeredi.hu>\");\nMODULE_DESCRIPTION(\"Overlay filesystem\");\nMODULE_LICENSE(\"GPL\");\n\n#define OVERLAYFS_SUPER_MAGIC 0x794c764f\n\nstruct ovl_config {\n\tchar *lowerdir;\n\tchar *upperdir;\n\tchar *workdir;\n};\n\n/* private information held for overlayfs's superblock */\nstruct ovl_fs {\n\tstruct vfsmount *upper_mnt;\n\tstruct vfsmount *lower_mnt;\n\tstruct dentry *workdir;\n\tlong lower_namelen;\n\t/* pathnames of lower and upper dirs, for show_options */\n\tstruct ovl_config config;\n};\n\nstruct ovl_dir_cache;\n\n/* private information held for every overlayfs dentry */\nstruct ovl_entry {\n\tstruct dentry *__upperdentry;\n\tstruct dentry *lowerdentry;\n\tstruct ovl_dir_cache *cache;\n\tunion {\n\t\tstruct {\n\t\t\tu64 version;\n\t\t\tbool opaque;\n\t\t};\n\t\tstruct rcu_head rcu;\n\t};\n};\n\nconst char *ovl_opaque_xattr = \"trusted.overlay.opaque\";\n\n\nenum ovl_path_type ovl_path_type(struct dentry *dentry)\n{\n\tstruct ovl_entry *oe = dentry->d_fsdata;\n\n\tif (oe->__upperdentry) {\n\t\tif (oe->lowerdentry) {\n\t\t\tif (S_ISDIR(dentry->d_inode->i_mode))\n\t\t\t\treturn OVL_PATH_MERGE;\n\t\t\telse\n\t\t\t\treturn OVL_PATH_UPPER;\n\t\t} else {\n\t\t\tif (oe->opaque)\n\t\t\t\treturn OVL_PATH_UPPER;\n\t\t\telse\n\t\t\t\treturn OVL_PATH_PURE_UPPER;\n\t\t}\n\t} else {\n\t\treturn OVL_PATH_LOWER;\n\t}\n}\n\nstatic struct dentry *ovl_upperdentry_dereference(struct ovl_entry *oe)\n{\n\tstruct dentry *upperdentry = ACCESS_ONCE(oe->__upperdentry);\n\t/*\n\t * Make sure to order reads to upperdentry wrt ovl_dentry_update()\n\t */\n\tsmp_read_barrier_depends();\n\treturn upperdentry;\n}\n\nvoid ovl_path_upper(struct dentry *dentry, struct path *path)\n{\n\tstruct ovl_fs *ofs = dentry->d_sb->s_fs_info;\n\tstruct ovl_entry *oe = dentry->d_fsdata;\n\n\tpath->mnt = ofs->upper_mnt;\n\tpath->dentry = ovl_upperdentry_dereference(oe);\n}\n\nenum ovl_path_type ovl_path_real(struct dentry *dentry, struct path *path)\n{\n\n\tenum ovl_path_type type = ovl_path_type(dentry);\n\n\tif (type == OVL_PATH_LOWER)\n\t\tovl_path_lower(dentry, path);\n\telse\n\t\tovl_path_upper(dentry, path);\n\n\treturn type;\n}\n\nstruct dentry *ovl_dentry_upper(struct dentry *dentry)\n{\n\tstruct ovl_entry *oe = dentry->d_fsdata;\n\n\treturn ovl_upperdentry_dereference(oe);\n}\n\nstruct dentry *ovl_dentry_lower(struct dentry *dentry)\n{\n\tstruct ovl_entry *oe = dentry->d_fsdata;\n\n\treturn oe->lowerdentry;\n}\n\nstruct dentry *ovl_dentry_real(struct dentry *dentry)\n{\n\tstruct ovl_entry *oe = dentry->d_fsdata;\n\tstruct dentry *realdentry;\n\n\trealdentry = ovl_upperdentry_dereference(oe);\n\tif (!realdentry)\n\t\trealdentry = oe->lowerdentry;\n\n\treturn realdentry;\n}\n\nstruct dentry *ovl_entry_real(struct ovl_entry *oe, bool *is_upper)\n{\n\tstruct dentry *realdentry;\n\n\trealdentry = ovl_upperdentry_dereference(oe);\n\tif (realdentry) {\n\t\t*is_upper = true;\n\t} else {\n\t\trealdentry = oe->lowerdentry;\n\t\t*is_upper = false;\n\t}\n\treturn realdentry;\n}\n\nstruct ovl_dir_cache *ovl_dir_cache(struct dentry *dentry)\n{\n\tstruct ovl_entry *oe = dentry->d_fsdata;\n\n\treturn oe->cache;\n}\n\nvoid ovl_set_dir_cache(struct dentry *dentry, struct ovl_dir_cache *cache)\n{\n\tstruct ovl_entry *oe = dentry->d_fsdata;\n\n\toe->cache = cache;\n}\n\nvoid ovl_path_lower(struct dentry *dentry, struct path *path)\n{\n\tstruct ovl_fs *ofs = dentry->d_sb->s_fs_info;\n\tstruct ovl_entry *oe = dentry->d_fsdata;\n\n\tpath->mnt = ofs->lower_mnt;\n\tpath->dentry = oe->lowerdentry;\n}\n\nint ovl_want_write(struct dentry *dentry)\n{\n\tstruct ovl_fs *ofs = dentry->d_sb->s_fs_info;\n\treturn mnt_want_write(ofs->upper_mnt);\n}\n\nvoid ovl_drop_write(struct dentry *dentry)\n{\n\tstruct ovl_fs *ofs = dentry->d_sb->s_fs_info;\n\tmnt_drop_write(ofs->upper_mnt);\n}\n\nstruct dentry *ovl_workdir(struct dentry *dentry)\n{\n\tstruct ovl_fs *ofs = dentry->d_sb->s_fs_info;\n\treturn ofs->workdir;\n}\n\nbool ovl_dentry_is_opaque(struct dentry *dentry)\n{\n\tstruct ovl_entry *oe = dentry->d_fsdata;\n\treturn oe->opaque;\n}\n\nvoid ovl_dentry_set_opaque(struct dentry *dentry, bool opaque)\n{\n\tstruct ovl_entry *oe = dentry->d_fsdata;\n\toe->opaque = opaque;\n}\n\nvoid ovl_dentry_update(struct dentry *dentry, struct dentry *upperdentry)\n{\n\tstruct ovl_entry *oe = dentry->d_fsdata;\n\n\tWARN_ON(!mutex_is_locked(&upperdentry->d_parent->d_inode->i_mutex));\n\tWARN_ON(oe->__upperdentry);\n\tBUG_ON(!upperdentry->d_inode);\n\t/*\n\t * Make sure upperdentry is consistent before making it visible to\n\t * ovl_upperdentry_dereference().\n\t */\n\tsmp_wmb();\n\toe->__upperdentry = upperdentry;\n}\n\nvoid ovl_dentry_version_inc(struct dentry *dentry)\n{\n\tstruct ovl_entry *oe = dentry->d_fsdata;\n\n\tWARN_ON(!mutex_is_locked(&dentry->d_inode->i_mutex));\n\toe->version++;\n}\n\nu64 ovl_dentry_version_get(struct dentry *dentry)\n{\n\tstruct ovl_entry *oe = dentry->d_fsdata;\n\n\tWARN_ON(!mutex_is_locked(&dentry->d_inode->i_mutex));\n\treturn oe->version;\n}\n\nbool ovl_is_whiteout(struct dentry *dentry)\n{\n\tstruct inode *inode = dentry->d_inode;\n\n\treturn inode && IS_WHITEOUT(inode);\n}\n\nstatic bool ovl_is_opaquedir(struct dentry *dentry)\n{\n\tint res;\n\tchar val;\n\tstruct inode *inode = dentry->d_inode;\n\n\tif (!S_ISDIR(inode->i_mode) || !inode->i_op->getxattr)\n\t\treturn false;\n\n\tres = inode->i_op->getxattr(dentry, ovl_opaque_xattr, &val, 1);\n\tif (res == 1 && val == 'y')\n\t\treturn true;\n\n\treturn false;\n}\n\nstatic void ovl_dentry_release(struct dentry *dentry)\n{\n\tstruct ovl_entry *oe = dentry->d_fsdata;\n\n\tif (oe) {\n\t\tdput(oe->__upperdentry);\n\t\tdput(oe->lowerdentry);\n\t\tkfree_rcu(oe, rcu);\n\t}\n}\n\nstatic const struct dentry_operations ovl_dentry_operations = {\n\t.d_release = ovl_dentry_release,\n};\n\nstatic struct ovl_entry *ovl_alloc_entry(void)\n{\n\treturn kzalloc(sizeof(struct ovl_entry), GFP_KERNEL);\n}\n\nstatic inline struct dentry *ovl_lookup_real(struct dentry *dir,\n\t\t\t\t\t     struct qstr *name)\n{\n\tstruct dentry *dentry;\n\n\tmutex_lock(&dir->d_inode->i_mutex);\n\tdentry = lookup_one_len(name->name, dir, name->len);\n\tmutex_unlock(&dir->d_inode->i_mutex);\n\n\tif (IS_ERR(dentry)) {\n\t\tif (PTR_ERR(dentry) == -ENOENT)\n\t\t\tdentry = NULL;\n\t} else if (!dentry->d_inode) {\n\t\tdput(dentry);\n\t\tdentry = NULL;\n\t}\n\treturn dentry;\n}\n\nstruct dentry *ovl_lookup(struct inode *dir, struct dentry *dentry,\n\t\t\t  unsigned int flags)\n{\n\tstruct ovl_entry *oe;\n\tstruct dentry *upperdir;\n\tstruct dentry *lowerdir;\n\tstruct dentry *upperdentry = NULL;\n\tstruct dentry *lowerdentry = NULL;\n\tstruct inode *inode = NULL;\n\tint err;\n\n\terr = -ENOMEM;\n\toe = ovl_alloc_entry();\n\tif (!oe)\n\t\tgoto out;\n\n\tupperdir = ovl_dentry_upper(dentry->d_parent);\n\tlowerdir = ovl_dentry_lower(dentry->d_parent);\n\n\tif (upperdir) {\n\t\tupperdentry = ovl_lookup_real(upperdir, &dentry->d_name);\n\t\terr = PTR_ERR(upperdentry);\n\t\tif (IS_ERR(upperdentry))\n\t\t\tgoto out_put_dir;\n\n\t\tif (lowerdir && upperdentry) {\n\t\t\tif (ovl_is_whiteout(upperdentry)) {\n\t\t\t\tdput(upperdentry);\n\t\t\t\tupperdentry = NULL;\n\t\t\t\toe->opaque = true;\n\t\t\t} else if (ovl_is_opaquedir(upperdentry)) {\n\t\t\t\toe->opaque = true;\n\t\t\t}\n\t\t}\n\t}\n\tif (lowerdir && !oe->opaque) {\n\t\tlowerdentry = ovl_lookup_real(lowerdir, &dentry->d_name);\n\t\terr = PTR_ERR(lowerdentry);\n\t\tif (IS_ERR(lowerdentry))\n\t\t\tgoto out_dput_upper;\n\t}\n\n\tif (lowerdentry && upperdentry &&\n\t    (!S_ISDIR(upperdentry->d_inode->i_mode) ||\n\t     !S_ISDIR(lowerdentry->d_inode->i_mode))) {\n\t\tdput(lowerdentry);\n\t\tlowerdentry = NULL;\n\t\toe->opaque = true;\n\t}\n\n\tif (lowerdentry || upperdentry) {\n\t\tstruct dentry *realdentry;\n\n\t\trealdentry = upperdentry ? upperdentry : lowerdentry;\n\t\terr = -ENOMEM;\n\t\tinode = ovl_new_inode(dentry->d_sb, realdentry->d_inode->i_mode,\n\t\t\t\t      oe);\n\t\tif (!inode)\n\t\t\tgoto out_dput;\n\t\tovl_copyattr(realdentry->d_inode, inode);\n\t}\n\n\toe->__upperdentry = upperdentry;\n\toe->lowerdentry = lowerdentry;\n\n\tdentry->d_fsdata = oe;\n\td_add(dentry, inode);\n\n\treturn NULL;\n\nout_dput:\n\tdput(lowerdentry);\nout_dput_upper:\n\tdput(upperdentry);\nout_put_dir:\n\tkfree(oe);\nout:\n\treturn ERR_PTR(err);\n}\n\nstruct file *ovl_path_open(struct path *path, int flags)\n{\n\treturn dentry_open(path, flags, current_cred());\n}\n\nstatic void ovl_put_super(struct super_block *sb)\n{\n\tstruct ovl_fs *ufs = sb->s_fs_info;\n\n\tdput(ufs->workdir);\n\tmntput(ufs->upper_mnt);\n\tmntput(ufs->lower_mnt);\n\n\tkfree(ufs->config.lowerdir);\n\tkfree(ufs->config.upperdir);\n\tkfree(ufs->config.workdir);\n\tkfree(ufs);\n}\n\n/**\n * ovl_statfs\n * @sb: The overlayfs super block\n * @buf: The struct kstatfs to fill in with stats\n *\n * Get the filesystem statistics.  As writes always target the upper layer\n * filesystem pass the statfs to the same filesystem.\n */\nstatic int ovl_statfs(struct dentry *dentry, struct kstatfs *buf)\n{\n\tstruct ovl_fs *ofs = dentry->d_sb->s_fs_info;\n\tstruct dentry *root_dentry = dentry->d_sb->s_root;\n\tstruct path path;\n\tint err;\n\n\tovl_path_upper(root_dentry, &path);\n\n\terr = vfs_statfs(&path, buf);\n\tif (!err) {\n\t\tbuf->f_namelen = max(buf->f_namelen, ofs->lower_namelen);\n\t\tbuf->f_type = OVERLAYFS_SUPER_MAGIC;\n\t}\n\n\treturn err;\n}\n\n/**\n * ovl_show_options\n *\n * Prints the mount options for a given superblock.\n * Returns zero; does not fail.\n */\nstatic int ovl_show_options(struct seq_file *m, struct dentry *dentry)\n{\n\tstruct super_block *sb = dentry->d_sb;\n\tstruct ovl_fs *ufs = sb->s_fs_info;\n\n\tseq_printf(m, \",lowerdir=%s\", ufs->config.lowerdir);\n\tseq_printf(m, \",upperdir=%s\", ufs->config.upperdir);\n\tseq_printf(m, \",workdir=%s\", ufs->config.workdir);\n\treturn 0;\n}\n\nstatic const struct super_operations ovl_super_operations = {\n\t.put_super\t= ovl_put_super,\n\t.statfs\t\t= ovl_statfs,\n\t.show_options\t= ovl_show_options,\n};\n\nenum {\n\tOPT_LOWERDIR,\n\tOPT_UPPERDIR,\n\tOPT_WORKDIR,\n\tOPT_ERR,\n};\n\nstatic const match_table_t ovl_tokens = {\n\t{OPT_LOWERDIR,\t\t\t\"lowerdir=%s\"},\n\t{OPT_UPPERDIR,\t\t\t\"upperdir=%s\"},\n\t{OPT_WORKDIR,\t\t\t\"workdir=%s\"},\n\t{OPT_ERR,\t\t\tNULL}\n};\n\nstatic int ovl_parse_opt(char *opt, struct ovl_config *config)\n{\n\tchar *p;\n\n\twhile ((p = strsep(&opt, \",\")) != NULL) {\n\t\tint token;\n\t\tsubstring_t args[MAX_OPT_ARGS];\n\n\t\tif (!*p)\n\t\t\tcontinue;\n\n\t\ttoken = match_token(p, ovl_tokens, args);\n\t\tswitch (token) {\n\t\tcase OPT_UPPERDIR:\n\t\t\tkfree(config->upperdir);\n\t\t\tconfig->upperdir = match_strdup(&args[0]);\n\t\t\tif (!config->upperdir)\n\t\t\t\treturn -ENOMEM;\n\t\t\tbreak;\n\n\t\tcase OPT_LOWERDIR:\n\t\t\tkfree(config->lowerdir);\n\t\t\tconfig->lowerdir = match_strdup(&args[0]);\n\t\t\tif (!config->lowerdir)\n\t\t\t\treturn -ENOMEM;\n\t\t\tbreak;\n\n\t\tcase OPT_WORKDIR:\n\t\t\tkfree(config->workdir);\n\t\t\tconfig->workdir = match_strdup(&args[0]);\n\t\t\tif (!config->workdir)\n\t\t\t\treturn -ENOMEM;\n\t\t\tbreak;\n\n\t\tdefault:\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\treturn 0;\n}\n\n#define OVL_WORKDIR_NAME \"work\"\n\nstatic struct dentry *ovl_workdir_create(struct vfsmount *mnt,\n\t\t\t\t\t struct dentry *dentry)\n{\n\tstruct inode *dir = dentry->d_inode;\n\tstruct dentry *work;\n\tint err;\n\tbool retried = false;\n\n\terr = mnt_want_write(mnt);\n\tif (err)\n\t\treturn ERR_PTR(err);\n\n\tmutex_lock_nested(&dir->i_mutex, I_MUTEX_PARENT);\nretry:\n\twork = lookup_one_len(OVL_WORKDIR_NAME, dentry,\n\t\t\t      strlen(OVL_WORKDIR_NAME));\n\n\tif (!IS_ERR(work)) {\n\t\tstruct kstat stat = {\n\t\t\t.mode = S_IFDIR | 0,\n\t\t};\n\n\t\tif (work->d_inode) {\n\t\t\terr = -EEXIST;\n\t\t\tif (retried)\n\t\t\t\tgoto out_dput;\n\n\t\t\tretried = true;\n\t\t\tovl_cleanup(dir, work);\n\t\t\tdput(work);\n\t\t\tgoto retry;\n\t\t}\n\n\t\terr = ovl_create_real(dir, work, &stat, NULL, NULL, true);\n\t\tif (err)\n\t\t\tgoto out_dput;\n\t}\nout_unlock:\n\tmutex_unlock(&dir->i_mutex);\n\tmnt_drop_write(mnt);\n\n\treturn work;\n\nout_dput:\n\tdput(work);\n\twork = ERR_PTR(err);\n\tgoto out_unlock;\n}\n\nstatic int ovl_mount_dir(const char *name, struct path *path)\n{\n\tint err;\n\n\terr = kern_path(name, LOOKUP_FOLLOW, path);\n\tif (err) {\n\t\tpr_err(\"overlayfs: failed to resolve '%s': %i\\n\", name, err);\n\t\terr = -EINVAL;\n\t}\n\treturn err;\n}\n\nstatic bool ovl_is_allowed_fs_type(struct dentry *root)\n{\n\tconst struct dentry_operations *dop = root->d_op;\n\n\t/*\n\t * We don't support:\n\t *  - automount filesystems\n\t *  - filesystems with revalidate (FIXME for lower layer)\n\t *  - filesystems with case insensitive names\n\t */\n\tif (dop &&\n\t    (dop->d_manage || dop->d_automount ||\n\t     dop->d_revalidate || dop->d_weak_revalidate ||\n\t     dop->d_compare || dop->d_hash)) {\n\t\treturn false;\n\t}\n\treturn true;\n}\n\n/* Workdir should not be subdir of upperdir and vice versa */\nstatic bool ovl_workdir_ok(struct dentry *workdir, struct dentry *upperdir)\n{\n\tbool ok = false;\n\n\tif (workdir != upperdir) {\n\t\tok = (lock_rename(workdir, upperdir) == NULL);\n\t\tunlock_rename(workdir, upperdir);\n\t}\n\treturn ok;\n}\n\nstatic int ovl_fill_super(struct super_block *sb, void *data, int silent)\n{\n\tstruct path lowerpath;\n\tstruct path upperpath;\n\tstruct path workpath;\n\tstruct inode *root_inode;\n\tstruct dentry *root_dentry;\n\tstruct ovl_entry *oe;\n\tstruct ovl_fs *ufs;\n\tstruct kstatfs statfs;\n\tint err;\n\n\terr = -ENOMEM;\n\tufs = kzalloc(sizeof(struct ovl_fs), GFP_KERNEL);\n\tif (!ufs)\n\t\tgoto out;\n\n\terr = ovl_parse_opt((char *) data, &ufs->config);\n\tif (err)\n\t\tgoto out_free_config;\n\n\t/* FIXME: workdir is not needed for a R/O mount */\n\terr = -EINVAL;\n\tif (!ufs->config.upperdir || !ufs->config.lowerdir ||\n\t    !ufs->config.workdir) {\n\t\tpr_err(\"overlayfs: missing upperdir or lowerdir or workdir\\n\");\n\t\tgoto out_free_config;\n\t}\n\n\terr = -ENOMEM;\n\toe = ovl_alloc_entry();\n\tif (oe == NULL)\n\t\tgoto out_free_config;\n\n\terr = ovl_mount_dir(ufs->config.upperdir, &upperpath);\n\tif (err)\n\t\tgoto out_free_oe;\n\n\terr = ovl_mount_dir(ufs->config.lowerdir, &lowerpath);\n\tif (err)\n\t\tgoto out_put_upperpath;\n\n\terr = ovl_mount_dir(ufs->config.workdir, &workpath);\n\tif (err)\n\t\tgoto out_put_lowerpath;\n\n\terr = -EINVAL;\n\tif (!S_ISDIR(upperpath.dentry->d_inode->i_mode) ||\n\t    !S_ISDIR(lowerpath.dentry->d_inode->i_mode) ||\n\t    !S_ISDIR(workpath.dentry->d_inode->i_mode)) {\n\t\tpr_err(\"overlayfs: upperdir or lowerdir or workdir not a directory\\n\");\n\t\tgoto out_put_workpath;\n\t}\n\n\tif (upperpath.mnt != workpath.mnt) {\n\t\tpr_err(\"overlayfs: workdir and upperdir must reside under the same mount\\n\");\n\t\tgoto out_put_workpath;\n\t}\n\tif (!ovl_workdir_ok(workpath.dentry, upperpath.dentry)) {\n\t\tpr_err(\"overlayfs: workdir and upperdir must be separate subtrees\\n\");\n\t\tgoto out_put_workpath;\n\t}\n\n\tif (!ovl_is_allowed_fs_type(upperpath.dentry)) {\n\t\tpr_err(\"overlayfs: filesystem of upperdir is not supported\\n\");\n\t\tgoto out_put_workpath;\n\t}\n\n\tif (!ovl_is_allowed_fs_type(lowerpath.dentry)) {\n\t\tpr_err(\"overlayfs: filesystem of lowerdir is not supported\\n\");\n\t\tgoto out_put_workpath;\n\t}\n\n\terr = vfs_statfs(&lowerpath, &statfs);\n\tif (err) {\n\t\tpr_err(\"overlayfs: statfs failed on lowerpath\\n\");\n\t\tgoto out_put_workpath;\n\t}\n\tufs->lower_namelen = statfs.f_namelen;\n\n\tsb->s_stack_depth = max(upperpath.mnt->mnt_sb->s_stack_depth,\n\t\t\t\tlowerpath.mnt->mnt_sb->s_stack_depth) + 1;\n\n\terr = -EINVAL;\n\tif (sb->s_stack_depth > FILESYSTEM_MAX_STACK_DEPTH) {\n\t\tpr_err(\"overlayfs: maximum fs stacking depth exceeded\\n\");\n\t\tgoto out_put_workpath;\n\t}\n\n\tufs->upper_mnt = clone_private_mount(&upperpath);\n\terr = PTR_ERR(ufs->upper_mnt);\n\tif (IS_ERR(ufs->upper_mnt)) {\n\t\tpr_err(\"overlayfs: failed to clone upperpath\\n\");\n\t\tgoto out_put_workpath;\n\t}\n\n\tufs->lower_mnt = clone_private_mount(&lowerpath);\n\terr = PTR_ERR(ufs->lower_mnt);\n\tif (IS_ERR(ufs->lower_mnt)) {\n\t\tpr_err(\"overlayfs: failed to clone lowerpath\\n\");\n\t\tgoto out_put_upper_mnt;\n\t}\n\n\tufs->workdir = ovl_workdir_create(ufs->upper_mnt, workpath.dentry);\n\terr = PTR_ERR(ufs->workdir);\n\tif (IS_ERR(ufs->workdir)) {\n\t\tpr_err(\"overlayfs: failed to create directory %s/%s\\n\",\n\t\t       ufs->config.workdir, OVL_WORKDIR_NAME);\n\t\tgoto out_put_lower_mnt;\n\t}\n\n\t/*\n\t * Make lower_mnt R/O.  That way fchmod/fchown on lower file\n\t * will fail instead of modifying lower fs.\n\t */\n\tufs->lower_mnt->mnt_flags |= MNT_READONLY;\n\n\t/* If the upper fs is r/o, we mark overlayfs r/o too */\n\tif (ufs->upper_mnt->mnt_sb->s_flags & MS_RDONLY)\n\t\tsb->s_flags |= MS_RDONLY;\n\n\tsb->s_d_op = &ovl_dentry_operations;\n\n\terr = -ENOMEM;\n\troot_inode = ovl_new_inode(sb, S_IFDIR, oe);\n\tif (!root_inode)\n\t\tgoto out_put_workdir;\n\n\troot_dentry = d_make_root(root_inode);\n\tif (!root_dentry)\n\t\tgoto out_put_workdir;\n\n\tmntput(upperpath.mnt);\n\tmntput(lowerpath.mnt);\n\tpath_put(&workpath);\n\n\toe->__upperdentry = upperpath.dentry;\n\toe->lowerdentry = lowerpath.dentry;\n\n\troot_dentry->d_fsdata = oe;\n\n\tsb->s_magic = OVERLAYFS_SUPER_MAGIC;\n\tsb->s_op = &ovl_super_operations;\n\tsb->s_root = root_dentry;\n\tsb->s_fs_info = ufs;\n\n\treturn 0;\n\nout_put_workdir:\n\tdput(ufs->workdir);\nout_put_lower_mnt:\n\tmntput(ufs->lower_mnt);\nout_put_upper_mnt:\n\tmntput(ufs->upper_mnt);\nout_put_workpath:\n\tpath_put(&workpath);\nout_put_lowerpath:\n\tpath_put(&lowerpath);\nout_put_upperpath:\n\tpath_put(&upperpath);\nout_free_oe:\n\tkfree(oe);\nout_free_config:\n\tkfree(ufs->config.lowerdir);\n\tkfree(ufs->config.upperdir);\n\tkfree(ufs->config.workdir);\n\tkfree(ufs);\nout:\n\treturn err;\n}\n\nstatic struct dentry *ovl_mount(struct file_system_type *fs_type, int flags,\n\t\t\t\tconst char *dev_name, void *raw_data)\n{\n\treturn mount_nodev(fs_type, flags, raw_data, ovl_fill_super);\n}\n\nstatic struct file_system_type ovl_fs_type = {\n\t.owner\t\t= THIS_MODULE,\n\t.name\t\t= \"overlayfs\",\n\t.mount\t\t= ovl_mount,\n\t.kill_sb\t= kill_anon_super,\n};\nMODULE_ALIAS_FS(\"overlayfs\");\n\nstatic int __init ovl_init(void)\n{\n\treturn register_filesystem(&ovl_fs_type);\n}\n\nstatic void __exit ovl_exit(void)\n{\n\tunregister_filesystem(&ovl_fs_type);\n}\n\nmodule_init(ovl_init);\nmodule_exit(ovl_exit);\n", "#ifndef _LINUX_FS_H\n#define _LINUX_FS_H\n\n\n#include <linux/linkage.h>\n#include <linux/wait.h>\n#include <linux/kdev_t.h>\n#include <linux/dcache.h>\n#include <linux/path.h>\n#include <linux/stat.h>\n#include <linux/cache.h>\n#include <linux/list.h>\n#include <linux/list_lru.h>\n#include <linux/llist.h>\n#include <linux/radix-tree.h>\n#include <linux/rbtree.h>\n#include <linux/init.h>\n#include <linux/pid.h>\n#include <linux/bug.h>\n#include <linux/mutex.h>\n#include <linux/capability.h>\n#include <linux/semaphore.h>\n#include <linux/fiemap.h>\n#include <linux/rculist_bl.h>\n#include <linux/atomic.h>\n#include <linux/shrinker.h>\n#include <linux/migrate_mode.h>\n#include <linux/uidgid.h>\n#include <linux/lockdep.h>\n#include <linux/percpu-rwsem.h>\n#include <linux/blk_types.h>\n\n#include <asm/byteorder.h>\n#include <uapi/linux/fs.h>\n\nstruct export_operations;\nstruct hd_geometry;\nstruct iovec;\nstruct nameidata;\nstruct kiocb;\nstruct kobject;\nstruct pipe_inode_info;\nstruct poll_table_struct;\nstruct kstatfs;\nstruct vm_area_struct;\nstruct vfsmount;\nstruct cred;\nstruct swap_info_struct;\nstruct seq_file;\nstruct workqueue_struct;\nstruct iov_iter;\n\nextern void __init inode_init(void);\nextern void __init inode_init_early(void);\nextern void __init files_init(unsigned long);\n\nextern struct files_stat_struct files_stat;\nextern unsigned long get_max_files(void);\nextern int sysctl_nr_open;\nextern struct inodes_stat_t inodes_stat;\nextern int leases_enable, lease_break_time;\nextern int sysctl_protected_symlinks;\nextern int sysctl_protected_hardlinks;\n\nstruct buffer_head;\ntypedef int (get_block_t)(struct inode *inode, sector_t iblock,\n\t\t\tstruct buffer_head *bh_result, int create);\ntypedef void (dio_iodone_t)(struct kiocb *iocb, loff_t offset,\n\t\t\tssize_t bytes, void *private);\n\n#define MAY_EXEC\t\t0x00000001\n#define MAY_WRITE\t\t0x00000002\n#define MAY_READ\t\t0x00000004\n#define MAY_APPEND\t\t0x00000008\n#define MAY_ACCESS\t\t0x00000010\n#define MAY_OPEN\t\t0x00000020\n#define MAY_CHDIR\t\t0x00000040\n/* called from RCU mode, don't block */\n#define MAY_NOT_BLOCK\t\t0x00000080\n\n/*\n * flags in file.f_mode.  Note that FMODE_READ and FMODE_WRITE must correspond\n * to O_WRONLY and O_RDWR via the strange trick in __dentry_open()\n */\n\n/* file is open for reading */\n#define FMODE_READ\t\t((__force fmode_t)0x1)\n/* file is open for writing */\n#define FMODE_WRITE\t\t((__force fmode_t)0x2)\n/* file is seekable */\n#define FMODE_LSEEK\t\t((__force fmode_t)0x4)\n/* file can be accessed using pread */\n#define FMODE_PREAD\t\t((__force fmode_t)0x8)\n/* file can be accessed using pwrite */\n#define FMODE_PWRITE\t\t((__force fmode_t)0x10)\n/* File is opened for execution with sys_execve / sys_uselib */\n#define FMODE_EXEC\t\t((__force fmode_t)0x20)\n/* File is opened with O_NDELAY (only set for block devices) */\n#define FMODE_NDELAY\t\t((__force fmode_t)0x40)\n/* File is opened with O_EXCL (only set for block devices) */\n#define FMODE_EXCL\t\t((__force fmode_t)0x80)\n/* File is opened using open(.., 3, ..) and is writeable only for ioctls\n   (specialy hack for floppy.c) */\n#define FMODE_WRITE_IOCTL\t((__force fmode_t)0x100)\n/* 32bit hashes as llseek() offset (for directories) */\n#define FMODE_32BITHASH         ((__force fmode_t)0x200)\n/* 64bit hashes as llseek() offset (for directories) */\n#define FMODE_64BITHASH         ((__force fmode_t)0x400)\n\n/*\n * Don't update ctime and mtime.\n *\n * Currently a special hack for the XFS open_by_handle ioctl, but we'll\n * hopefully graduate it to a proper O_CMTIME flag supported by open(2) soon.\n */\n#define FMODE_NOCMTIME\t\t((__force fmode_t)0x800)\n\n/* Expect random access pattern */\n#define FMODE_RANDOM\t\t((__force fmode_t)0x1000)\n\n/* File is huge (eg. /dev/kmem): treat loff_t as unsigned */\n#define FMODE_UNSIGNED_OFFSET\t((__force fmode_t)0x2000)\n\n/* File is opened with O_PATH; almost nothing can be done with it */\n#define FMODE_PATH\t\t((__force fmode_t)0x4000)\n\n/* File needs atomic accesses to f_pos */\n#define FMODE_ATOMIC_POS\t((__force fmode_t)0x8000)\n/* Write access to underlying fs */\n#define FMODE_WRITER\t\t((__force fmode_t)0x10000)\n/* Has read method(s) */\n#define FMODE_CAN_READ          ((__force fmode_t)0x20000)\n/* Has write method(s) */\n#define FMODE_CAN_WRITE         ((__force fmode_t)0x40000)\n\n/* File was opened by fanotify and shouldn't generate fanotify events */\n#define FMODE_NONOTIFY\t\t((__force fmode_t)0x1000000)\n\n/*\n * Flag for rw_copy_check_uvector and compat_rw_copy_check_uvector\n * that indicates that they should check the contents of the iovec are\n * valid, but not check the memory that the iovec elements\n * points too.\n */\n#define CHECK_IOVEC_ONLY -1\n\n/*\n * The below are the various read and write types that we support. Some of\n * them include behavioral modifiers that send information down to the\n * block layer and IO scheduler. Terminology:\n *\n *\tThe block layer uses device plugging to defer IO a little bit, in\n *\tthe hope that we will see more IO very shortly. This increases\n *\tcoalescing of adjacent IO and thus reduces the number of IOs we\n *\thave to send to the device. It also allows for better queuing,\n *\tif the IO isn't mergeable. If the caller is going to be waiting\n *\tfor the IO, then he must ensure that the device is unplugged so\n *\tthat the IO is dispatched to the driver.\n *\n *\tAll IO is handled async in Linux. This is fine for background\n *\twrites, but for reads or writes that someone waits for completion\n *\ton, we want to notify the block layer and IO scheduler so that they\n *\tknow about it. That allows them to make better scheduling\n *\tdecisions. So when the below references 'sync' and 'async', it\n *\tis referencing this priority hint.\n *\n * With that in mind, the available types are:\n *\n * READ\t\t\tA normal read operation. Device will be plugged.\n * READ_SYNC\t\tA synchronous read. Device is not plugged, caller can\n *\t\t\timmediately wait on this read without caring about\n *\t\t\tunplugging.\n * READA\t\tUsed for read-ahead operations. Lower priority, and the\n *\t\t\tblock layer could (in theory) choose to ignore this\n *\t\t\trequest if it runs into resource problems.\n * WRITE\t\tA normal async write. Device will be plugged.\n * WRITE_SYNC\t\tSynchronous write. Identical to WRITE, but passes down\n *\t\t\tthe hint that someone will be waiting on this IO\n *\t\t\tshortly. The write equivalent of READ_SYNC.\n * WRITE_ODIRECT\tSpecial case write for O_DIRECT only.\n * WRITE_FLUSH\t\tLike WRITE_SYNC but with preceding cache flush.\n * WRITE_FUA\t\tLike WRITE_SYNC but data is guaranteed to be on\n *\t\t\tnon-volatile media on completion.\n * WRITE_FLUSH_FUA\tCombination of WRITE_FLUSH and FUA. The IO is preceded\n *\t\t\tby a cache flush and data is guaranteed to be on\n *\t\t\tnon-volatile media on completion.\n *\n */\n#define RW_MASK\t\t\tREQ_WRITE\n#define RWA_MASK\t\tREQ_RAHEAD\n\n#define READ\t\t\t0\n#define WRITE\t\t\tRW_MASK\n#define READA\t\t\tRWA_MASK\n\n#define READ_SYNC\t\t(READ | REQ_SYNC)\n#define WRITE_SYNC\t\t(WRITE | REQ_SYNC | REQ_NOIDLE)\n#define WRITE_ODIRECT\t\t(WRITE | REQ_SYNC)\n#define WRITE_FLUSH\t\t(WRITE | REQ_SYNC | REQ_NOIDLE | REQ_FLUSH)\n#define WRITE_FUA\t\t(WRITE | REQ_SYNC | REQ_NOIDLE | REQ_FUA)\n#define WRITE_FLUSH_FUA\t\t(WRITE | REQ_SYNC | REQ_NOIDLE | REQ_FLUSH | REQ_FUA)\n\n/*\n * Attribute flags.  These should be or-ed together to figure out what\n * has been changed!\n */\n#define ATTR_MODE\t(1 << 0)\n#define ATTR_UID\t(1 << 1)\n#define ATTR_GID\t(1 << 2)\n#define ATTR_SIZE\t(1 << 3)\n#define ATTR_ATIME\t(1 << 4)\n#define ATTR_MTIME\t(1 << 5)\n#define ATTR_CTIME\t(1 << 6)\n#define ATTR_ATIME_SET\t(1 << 7)\n#define ATTR_MTIME_SET\t(1 << 8)\n#define ATTR_FORCE\t(1 << 9) /* Not a change, but a change it */\n#define ATTR_ATTR_FLAG\t(1 << 10)\n#define ATTR_KILL_SUID\t(1 << 11)\n#define ATTR_KILL_SGID\t(1 << 12)\n#define ATTR_FILE\t(1 << 13)\n#define ATTR_KILL_PRIV\t(1 << 14)\n#define ATTR_OPEN\t(1 << 15) /* Truncating from open(O_TRUNC) */\n#define ATTR_TIMES_SET\t(1 << 16)\n\n/*\n * Whiteout is represented by a char device.  The following constants define the\n * mode and device number to use.\n */\n#define WHITEOUT_MODE 0\n#define WHITEOUT_DEV 0\n\n/*\n * This is the Inode Attributes structure, used for notify_change().  It\n * uses the above definitions as flags, to know which values have changed.\n * Also, in this manner, a Filesystem can look at only the values it cares\n * about.  Basically, these are the attributes that the VFS layer can\n * request to change from the FS layer.\n *\n * Derek Atkins <warlord@MIT.EDU> 94-10-20\n */\nstruct iattr {\n\tunsigned int\tia_valid;\n\tumode_t\t\tia_mode;\n\tkuid_t\t\tia_uid;\n\tkgid_t\t\tia_gid;\n\tloff_t\t\tia_size;\n\tstruct timespec\tia_atime;\n\tstruct timespec\tia_mtime;\n\tstruct timespec\tia_ctime;\n\n\t/*\n\t * Not an attribute, but an auxiliary info for filesystems wanting to\n\t * implement an ftruncate() like method.  NOTE: filesystem should\n\t * check for (ia_valid & ATTR_FILE), and not for (ia_file != NULL).\n\t */\n\tstruct file\t*ia_file;\n};\n\n/*\n * Includes for diskquotas.\n */\n#include <linux/quota.h>\n\n/*\n * Maximum number of layers of fs stack.  Needs to be limited to\n * prevent kernel stack overflow\n */\n#define FILESYSTEM_MAX_STACK_DEPTH 2\n\n/** \n * enum positive_aop_returns - aop return codes with specific semantics\n *\n * @AOP_WRITEPAGE_ACTIVATE: Informs the caller that page writeback has\n * \t\t\t    completed, that the page is still locked, and\n * \t\t\t    should be considered active.  The VM uses this hint\n * \t\t\t    to return the page to the active list -- it won't\n * \t\t\t    be a candidate for writeback again in the near\n * \t\t\t    future.  Other callers must be careful to unlock\n * \t\t\t    the page if they get this return.  Returned by\n * \t\t\t    writepage(); \n *\n * @AOP_TRUNCATED_PAGE: The AOP method that was handed a locked page has\n *  \t\t\tunlocked it and the page might have been truncated.\n *  \t\t\tThe caller should back up to acquiring a new page and\n *  \t\t\ttrying again.  The aop will be taking reasonable\n *  \t\t\tprecautions not to livelock.  If the caller held a page\n *  \t\t\treference, it should drop it before retrying.  Returned\n *  \t\t\tby readpage().\n *\n * address_space_operation functions return these large constants to indicate\n * special semantics to the caller.  These are much larger than the bytes in a\n * page to allow for functions that return the number of bytes operated on in a\n * given page.\n */\n\nenum positive_aop_returns {\n\tAOP_WRITEPAGE_ACTIVATE\t= 0x80000,\n\tAOP_TRUNCATED_PAGE\t= 0x80001,\n};\n\n#define AOP_FLAG_UNINTERRUPTIBLE\t0x0001 /* will not do a short write */\n#define AOP_FLAG_CONT_EXPAND\t\t0x0002 /* called from cont_expand */\n#define AOP_FLAG_NOFS\t\t\t0x0004 /* used by filesystem to direct\n\t\t\t\t\t\t* helper code (eg buffer layer)\n\t\t\t\t\t\t* to clear GFP_FS from alloc */\n\n/*\n * oh the beauties of C type declarations.\n */\nstruct page;\nstruct address_space;\nstruct writeback_control;\n\n/*\n * \"descriptor\" for what we're up to with a read.\n * This allows us to use the same read code yet\n * have multiple different users of the data that\n * we read from a file.\n *\n * The simplest case just copies the data to user\n * mode.\n */\ntypedef struct {\n\tsize_t written;\n\tsize_t count;\n\tunion {\n\t\tchar __user *buf;\n\t\tvoid *data;\n\t} arg;\n\tint error;\n} read_descriptor_t;\n\ntypedef int (*read_actor_t)(read_descriptor_t *, struct page *,\n\t\tunsigned long, unsigned long);\n\nstruct address_space_operations {\n\tint (*writepage)(struct page *page, struct writeback_control *wbc);\n\tint (*readpage)(struct file *, struct page *);\n\n\t/* Write back some dirty pages from this mapping. */\n\tint (*writepages)(struct address_space *, struct writeback_control *);\n\n\t/* Set a page dirty.  Return true if this dirtied it */\n\tint (*set_page_dirty)(struct page *page);\n\n\tint (*readpages)(struct file *filp, struct address_space *mapping,\n\t\t\tstruct list_head *pages, unsigned nr_pages);\n\n\tint (*write_begin)(struct file *, struct address_space *mapping,\n\t\t\t\tloff_t pos, unsigned len, unsigned flags,\n\t\t\t\tstruct page **pagep, void **fsdata);\n\tint (*write_end)(struct file *, struct address_space *mapping,\n\t\t\t\tloff_t pos, unsigned len, unsigned copied,\n\t\t\t\tstruct page *page, void *fsdata);\n\n\t/* Unfortunately this kludge is needed for FIBMAP. Don't use it */\n\tsector_t (*bmap)(struct address_space *, sector_t);\n\tvoid (*invalidatepage) (struct page *, unsigned int, unsigned int);\n\tint (*releasepage) (struct page *, gfp_t);\n\tvoid (*freepage)(struct page *);\n\tssize_t (*direct_IO)(int, struct kiocb *, struct iov_iter *iter, loff_t offset);\n\tint (*get_xip_mem)(struct address_space *, pgoff_t, int,\n\t\t\t\t\t\tvoid **, unsigned long *);\n\t/*\n\t * migrate the contents of a page to the specified target. If\n\t * migrate_mode is MIGRATE_ASYNC, it must not block.\n\t */\n\tint (*migratepage) (struct address_space *,\n\t\t\tstruct page *, struct page *, enum migrate_mode);\n\tint (*launder_page) (struct page *);\n\tint (*is_partially_uptodate) (struct page *, unsigned long,\n\t\t\t\t\tunsigned long);\n\tvoid (*is_dirty_writeback) (struct page *, bool *, bool *);\n\tint (*error_remove_page)(struct address_space *, struct page *);\n\n\t/* swapfile support */\n\tint (*swap_activate)(struct swap_info_struct *sis, struct file *file,\n\t\t\t\tsector_t *span);\n\tvoid (*swap_deactivate)(struct file *file);\n};\n\nextern const struct address_space_operations empty_aops;\n\n/*\n * pagecache_write_begin/pagecache_write_end must be used by general code\n * to write into the pagecache.\n */\nint pagecache_write_begin(struct file *, struct address_space *mapping,\n\t\t\t\tloff_t pos, unsigned len, unsigned flags,\n\t\t\t\tstruct page **pagep, void **fsdata);\n\nint pagecache_write_end(struct file *, struct address_space *mapping,\n\t\t\t\tloff_t pos, unsigned len, unsigned copied,\n\t\t\t\tstruct page *page, void *fsdata);\n\nstruct backing_dev_info;\nstruct address_space {\n\tstruct inode\t\t*host;\t\t/* owner: inode, block_device */\n\tstruct radix_tree_root\tpage_tree;\t/* radix tree of all pages */\n\tspinlock_t\t\ttree_lock;\t/* and lock protecting it */\n\tatomic_t\t\ti_mmap_writable;/* count VM_SHARED mappings */\n\tstruct rb_root\t\ti_mmap;\t\t/* tree of private and shared mappings */\n\tstruct list_head\ti_mmap_nonlinear;/*list VM_NONLINEAR mappings */\n\tstruct mutex\t\ti_mmap_mutex;\t/* protect tree, count, list */\n\t/* Protected by tree_lock together with the radix tree */\n\tunsigned long\t\tnrpages;\t/* number of total pages */\n\tunsigned long\t\tnrshadows;\t/* number of shadow entries */\n\tpgoff_t\t\t\twriteback_index;/* writeback starts here */\n\tconst struct address_space_operations *a_ops;\t/* methods */\n\tunsigned long\t\tflags;\t\t/* error bits/gfp mask */\n\tstruct backing_dev_info *backing_dev_info; /* device readahead, etc */\n\tspinlock_t\t\tprivate_lock;\t/* for use by the address_space */\n\tstruct list_head\tprivate_list;\t/* ditto */\n\tvoid\t\t\t*private_data;\t/* ditto */\n} __attribute__((aligned(sizeof(long))));\n\t/*\n\t * On most architectures that alignment is already the case; but\n\t * must be enforced here for CRIS, to let the least significant bit\n\t * of struct page's \"mapping\" pointer be used for PAGE_MAPPING_ANON.\n\t */\nstruct request_queue;\n\nstruct block_device {\n\tdev_t\t\t\tbd_dev;  /* not a kdev_t - it's a search key */\n\tint\t\t\tbd_openers;\n\tstruct inode *\t\tbd_inode;\t/* will die */\n\tstruct super_block *\tbd_super;\n\tstruct mutex\t\tbd_mutex;\t/* open/close mutex */\n\tstruct list_head\tbd_inodes;\n\tvoid *\t\t\tbd_claiming;\n\tvoid *\t\t\tbd_holder;\n\tint\t\t\tbd_holders;\n\tbool\t\t\tbd_write_holder;\n#ifdef CONFIG_SYSFS\n\tstruct list_head\tbd_holder_disks;\n#endif\n\tstruct block_device *\tbd_contains;\n\tunsigned\t\tbd_block_size;\n\tstruct hd_struct *\tbd_part;\n\t/* number of times partitions within this device have been opened. */\n\tunsigned\t\tbd_part_count;\n\tint\t\t\tbd_invalidated;\n\tstruct gendisk *\tbd_disk;\n\tstruct request_queue *  bd_queue;\n\tstruct list_head\tbd_list;\n\t/*\n\t * Private data.  You must have bd_claim'ed the block_device\n\t * to use this.  NOTE:  bd_claim allows an owner to claim\n\t * the same device multiple times, the owner must take special\n\t * care to not mess up bd_private for that case.\n\t */\n\tunsigned long\t\tbd_private;\n\n\t/* The counter of freeze processes */\n\tint\t\t\tbd_fsfreeze_count;\n\t/* Mutex for freeze */\n\tstruct mutex\t\tbd_fsfreeze_mutex;\n};\n\n/*\n * Radix-tree tags, for tagging dirty and writeback pages within the pagecache\n * radix trees\n */\n#define PAGECACHE_TAG_DIRTY\t0\n#define PAGECACHE_TAG_WRITEBACK\t1\n#define PAGECACHE_TAG_TOWRITE\t2\n\nint mapping_tagged(struct address_space *mapping, int tag);\n\n/*\n * Might pages of this file be mapped into userspace?\n */\nstatic inline int mapping_mapped(struct address_space *mapping)\n{\n\treturn\t!RB_EMPTY_ROOT(&mapping->i_mmap) ||\n\t\t!list_empty(&mapping->i_mmap_nonlinear);\n}\n\n/*\n * Might pages of this file have been modified in userspace?\n * Note that i_mmap_writable counts all VM_SHARED vmas: do_mmap_pgoff\n * marks vma as VM_SHARED if it is shared, and the file was opened for\n * writing i.e. vma may be mprotected writable even if now readonly.\n *\n * If i_mmap_writable is negative, no new writable mappings are allowed. You\n * can only deny writable mappings, if none exists right now.\n */\nstatic inline int mapping_writably_mapped(struct address_space *mapping)\n{\n\treturn atomic_read(&mapping->i_mmap_writable) > 0;\n}\n\nstatic inline int mapping_map_writable(struct address_space *mapping)\n{\n\treturn atomic_inc_unless_negative(&mapping->i_mmap_writable) ?\n\t\t0 : -EPERM;\n}\n\nstatic inline void mapping_unmap_writable(struct address_space *mapping)\n{\n\tatomic_dec(&mapping->i_mmap_writable);\n}\n\nstatic inline int mapping_deny_writable(struct address_space *mapping)\n{\n\treturn atomic_dec_unless_positive(&mapping->i_mmap_writable) ?\n\t\t0 : -EBUSY;\n}\n\nstatic inline void mapping_allow_writable(struct address_space *mapping)\n{\n\tatomic_inc(&mapping->i_mmap_writable);\n}\n\n/*\n * Use sequence counter to get consistent i_size on 32-bit processors.\n */\n#if BITS_PER_LONG==32 && defined(CONFIG_SMP)\n#include <linux/seqlock.h>\n#define __NEED_I_SIZE_ORDERED\n#define i_size_ordered_init(inode) seqcount_init(&inode->i_size_seqcount)\n#else\n#define i_size_ordered_init(inode) do { } while (0)\n#endif\n\nstruct posix_acl;\n#define ACL_NOT_CACHED ((void *)(-1))\n\n#define IOP_FASTPERM\t0x0001\n#define IOP_LOOKUP\t0x0002\n#define IOP_NOFOLLOW\t0x0004\n\n/*\n * Keep mostly read-only and often accessed (especially for\n * the RCU path lookup and 'stat' data) fields at the beginning\n * of the 'struct inode'\n */\nstruct inode {\n\tumode_t\t\t\ti_mode;\n\tunsigned short\t\ti_opflags;\n\tkuid_t\t\t\ti_uid;\n\tkgid_t\t\t\ti_gid;\n\tunsigned int\t\ti_flags;\n\n#ifdef CONFIG_FS_POSIX_ACL\n\tstruct posix_acl\t*i_acl;\n\tstruct posix_acl\t*i_default_acl;\n#endif\n\n\tconst struct inode_operations\t*i_op;\n\tstruct super_block\t*i_sb;\n\tstruct address_space\t*i_mapping;\n\n#ifdef CONFIG_SECURITY\n\tvoid\t\t\t*i_security;\n#endif\n\n\t/* Stat data, not accessed from path walking */\n\tunsigned long\t\ti_ino;\n\t/*\n\t * Filesystems may only read i_nlink directly.  They shall use the\n\t * following functions for modification:\n\t *\n\t *    (set|clear|inc|drop)_nlink\n\t *    inode_(inc|dec)_link_count\n\t */\n\tunion {\n\t\tconst unsigned int i_nlink;\n\t\tunsigned int __i_nlink;\n\t};\n\tdev_t\t\t\ti_rdev;\n\tloff_t\t\t\ti_size;\n\tstruct timespec\t\ti_atime;\n\tstruct timespec\t\ti_mtime;\n\tstruct timespec\t\ti_ctime;\n\tspinlock_t\t\ti_lock;\t/* i_blocks, i_bytes, maybe i_size */\n\tunsigned short          i_bytes;\n\tunsigned int\t\ti_blkbits;\n\tblkcnt_t\t\ti_blocks;\n\n#ifdef __NEED_I_SIZE_ORDERED\n\tseqcount_t\t\ti_size_seqcount;\n#endif\n\n\t/* Misc */\n\tunsigned long\t\ti_state;\n\tstruct mutex\t\ti_mutex;\n\n\tunsigned long\t\tdirtied_when;\t/* jiffies of first dirtying */\n\n\tstruct hlist_node\ti_hash;\n\tstruct list_head\ti_wb_list;\t/* backing dev IO list */\n\tstruct list_head\ti_lru;\t\t/* inode LRU list */\n\tstruct list_head\ti_sb_list;\n\tunion {\n\t\tstruct hlist_head\ti_dentry;\n\t\tstruct rcu_head\t\ti_rcu;\n\t};\n\tu64\t\t\ti_version;\n\tatomic_t\t\ti_count;\n\tatomic_t\t\ti_dio_count;\n\tatomic_t\t\ti_writecount;\n#ifdef CONFIG_IMA\n\tatomic_t\t\ti_readcount; /* struct files open RO */\n#endif\n\tconst struct file_operations\t*i_fop;\t/* former ->i_op->default_file_ops */\n\tstruct file_lock\t*i_flock;\n\tstruct address_space\ti_data;\n#ifdef CONFIG_QUOTA\n\tstruct dquot\t\t*i_dquot[MAXQUOTAS];\n#endif\n\tstruct list_head\ti_devices;\n\tunion {\n\t\tstruct pipe_inode_info\t*i_pipe;\n\t\tstruct block_device\t*i_bdev;\n\t\tstruct cdev\t\t*i_cdev;\n\t};\n\n\t__u32\t\t\ti_generation;\n\n#ifdef CONFIG_FSNOTIFY\n\t__u32\t\t\ti_fsnotify_mask; /* all events this inode cares about */\n\tstruct hlist_head\ti_fsnotify_marks;\n#endif\n\n\tvoid\t\t\t*i_private; /* fs or device private pointer */\n};\n\nstatic inline int inode_unhashed(struct inode *inode)\n{\n\treturn hlist_unhashed(&inode->i_hash);\n}\n\n/*\n * inode->i_mutex nesting subclasses for the lock validator:\n *\n * 0: the object of the current VFS operation\n * 1: parent\n * 2: child/target\n * 3: xattr\n * 4: second non-directory\n * The last is for certain operations (such as rename) which lock two\n * non-directories at once.\n *\n * The locking order between these classes is\n * parent -> child -> normal -> xattr -> second non-directory\n */\nenum inode_i_mutex_lock_class\n{\n\tI_MUTEX_NORMAL,\n\tI_MUTEX_PARENT,\n\tI_MUTEX_CHILD,\n\tI_MUTEX_XATTR,\n\tI_MUTEX_NONDIR2\n};\n\nvoid lock_two_nondirectories(struct inode *, struct inode*);\nvoid unlock_two_nondirectories(struct inode *, struct inode*);\n\n/*\n * NOTE: in a 32bit arch with a preemptable kernel and\n * an UP compile the i_size_read/write must be atomic\n * with respect to the local cpu (unlike with preempt disabled),\n * but they don't need to be atomic with respect to other cpus like in\n * true SMP (so they need either to either locally disable irq around\n * the read or for example on x86 they can be still implemented as a\n * cmpxchg8b without the need of the lock prefix). For SMP compiles\n * and 64bit archs it makes no difference if preempt is enabled or not.\n */\nstatic inline loff_t i_size_read(const struct inode *inode)\n{\n#if BITS_PER_LONG==32 && defined(CONFIG_SMP)\n\tloff_t i_size;\n\tunsigned int seq;\n\n\tdo {\n\t\tseq = read_seqcount_begin(&inode->i_size_seqcount);\n\t\ti_size = inode->i_size;\n\t} while (read_seqcount_retry(&inode->i_size_seqcount, seq));\n\treturn i_size;\n#elif BITS_PER_LONG==32 && defined(CONFIG_PREEMPT)\n\tloff_t i_size;\n\n\tpreempt_disable();\n\ti_size = inode->i_size;\n\tpreempt_enable();\n\treturn i_size;\n#else\n\treturn inode->i_size;\n#endif\n}\n\n/*\n * NOTE: unlike i_size_read(), i_size_write() does need locking around it\n * (normally i_mutex), otherwise on 32bit/SMP an update of i_size_seqcount\n * can be lost, resulting in subsequent i_size_read() calls spinning forever.\n */\nstatic inline void i_size_write(struct inode *inode, loff_t i_size)\n{\n#if BITS_PER_LONG==32 && defined(CONFIG_SMP)\n\tpreempt_disable();\n\twrite_seqcount_begin(&inode->i_size_seqcount);\n\tinode->i_size = i_size;\n\twrite_seqcount_end(&inode->i_size_seqcount);\n\tpreempt_enable();\n#elif BITS_PER_LONG==32 && defined(CONFIG_PREEMPT)\n\tpreempt_disable();\n\tinode->i_size = i_size;\n\tpreempt_enable();\n#else\n\tinode->i_size = i_size;\n#endif\n}\n\n/* Helper functions so that in most cases filesystems will\n * not need to deal directly with kuid_t and kgid_t and can\n * instead deal with the raw numeric values that are stored\n * in the filesystem.\n */\nstatic inline uid_t i_uid_read(const struct inode *inode)\n{\n\treturn from_kuid(&init_user_ns, inode->i_uid);\n}\n\nstatic inline gid_t i_gid_read(const struct inode *inode)\n{\n\treturn from_kgid(&init_user_ns, inode->i_gid);\n}\n\nstatic inline void i_uid_write(struct inode *inode, uid_t uid)\n{\n\tinode->i_uid = make_kuid(&init_user_ns, uid);\n}\n\nstatic inline void i_gid_write(struct inode *inode, gid_t gid)\n{\n\tinode->i_gid = make_kgid(&init_user_ns, gid);\n}\n\nstatic inline unsigned iminor(const struct inode *inode)\n{\n\treturn MINOR(inode->i_rdev);\n}\n\nstatic inline unsigned imajor(const struct inode *inode)\n{\n\treturn MAJOR(inode->i_rdev);\n}\n\nextern struct block_device *I_BDEV(struct inode *inode);\n\nstruct fown_struct {\n\trwlock_t lock;          /* protects pid, uid, euid fields */\n\tstruct pid *pid;\t/* pid or -pgrp where SIGIO should be sent */\n\tenum pid_type pid_type;\t/* Kind of process group SIGIO should be sent to */\n\tkuid_t uid, euid;\t/* uid/euid of process setting the owner */\n\tint signum;\t\t/* posix.1b rt signal to be delivered on IO */\n};\n\n/*\n * Track a single file's readahead state\n */\nstruct file_ra_state {\n\tpgoff_t start;\t\t\t/* where readahead started */\n\tunsigned int size;\t\t/* # of readahead pages */\n\tunsigned int async_size;\t/* do asynchronous readahead when\n\t\t\t\t\t   there are only # of pages ahead */\n\n\tunsigned int ra_pages;\t\t/* Maximum readahead window */\n\tunsigned int mmap_miss;\t\t/* Cache miss stat for mmap accesses */\n\tloff_t prev_pos;\t\t/* Cache last read() position */\n};\n\n/*\n * Check if @index falls in the readahead windows.\n */\nstatic inline int ra_has_index(struct file_ra_state *ra, pgoff_t index)\n{\n\treturn (index >= ra->start &&\n\t\tindex <  ra->start + ra->size);\n}\n\nstruct file {\n\tunion {\n\t\tstruct llist_node\tfu_llist;\n\t\tstruct rcu_head \tfu_rcuhead;\n\t} f_u;\n\tstruct path\t\tf_path;\n#define f_dentry\tf_path.dentry\n\tstruct inode\t\t*f_inode;\t/* cached value */\n\tconst struct file_operations\t*f_op;\n\n\t/*\n\t * Protects f_ep_links, f_flags.\n\t * Must not be taken from IRQ context.\n\t */\n\tspinlock_t\t\tf_lock;\n\tatomic_long_t\t\tf_count;\n\tunsigned int \t\tf_flags;\n\tfmode_t\t\t\tf_mode;\n\tstruct mutex\t\tf_pos_lock;\n\tloff_t\t\t\tf_pos;\n\tstruct fown_struct\tf_owner;\n\tconst struct cred\t*f_cred;\n\tstruct file_ra_state\tf_ra;\n\n\tu64\t\t\tf_version;\n#ifdef CONFIG_SECURITY\n\tvoid\t\t\t*f_security;\n#endif\n\t/* needed for tty driver, and maybe others */\n\tvoid\t\t\t*private_data;\n\n#ifdef CONFIG_EPOLL\n\t/* Used by fs/eventpoll.c to link all the hooks to this file */\n\tstruct list_head\tf_ep_links;\n\tstruct list_head\tf_tfile_llink;\n#endif /* #ifdef CONFIG_EPOLL */\n\tstruct address_space\t*f_mapping;\n} __attribute__((aligned(4)));\t/* lest something weird decides that 2 is OK */\n\nstruct file_handle {\n\t__u32 handle_bytes;\n\tint handle_type;\n\t/* file identifier */\n\tunsigned char f_handle[0];\n};\n\nstatic inline struct file *get_file(struct file *f)\n{\n\tatomic_long_inc(&f->f_count);\n\treturn f;\n}\n#define fput_atomic(x)\tatomic_long_add_unless(&(x)->f_count, -1, 1)\n#define file_count(x)\tatomic_long_read(&(x)->f_count)\n\n#define\tMAX_NON_LFS\t((1UL<<31) - 1)\n\n/* Page cache limit. The filesystems should put that into their s_maxbytes \n   limits, otherwise bad things can happen in VM. */ \n#if BITS_PER_LONG==32\n#define MAX_LFS_FILESIZE\t(((loff_t)PAGE_CACHE_SIZE << (BITS_PER_LONG-1))-1) \n#elif BITS_PER_LONG==64\n#define MAX_LFS_FILESIZE \t((loff_t)0x7fffffffffffffffLL)\n#endif\n\n#define FL_POSIX\t1\n#define FL_FLOCK\t2\n#define FL_DELEG\t4\t/* NFSv4 delegation */\n#define FL_ACCESS\t8\t/* not trying to lock, just looking */\n#define FL_EXISTS\t16\t/* when unlocking, test for existence */\n#define FL_LEASE\t32\t/* lease held on this file */\n#define FL_CLOSE\t64\t/* unlock on close */\n#define FL_SLEEP\t128\t/* A blocking lock */\n#define FL_DOWNGRADE_PENDING\t256 /* Lease is being downgraded */\n#define FL_UNLOCK_PENDING\t512 /* Lease is being broken */\n#define FL_OFDLCK\t1024\t/* lock is \"owned\" by struct file */\n\n/*\n * Special return value from posix_lock_file() and vfs_lock_file() for\n * asynchronous locking.\n */\n#define FILE_LOCK_DEFERRED 1\n\n/* legacy typedef, should eventually be removed */\ntypedef void *fl_owner_t;\n\nstruct file_lock_operations {\n\tvoid (*fl_copy_lock)(struct file_lock *, struct file_lock *);\n\tvoid (*fl_release_private)(struct file_lock *);\n};\n\nstruct lock_manager_operations {\n\tint (*lm_compare_owner)(struct file_lock *, struct file_lock *);\n\tunsigned long (*lm_owner_key)(struct file_lock *);\n\tvoid (*lm_get_owner)(struct file_lock *, struct file_lock *);\n\tvoid (*lm_put_owner)(struct file_lock *);\n\tvoid (*lm_notify)(struct file_lock *);\t/* unblock callback */\n\tint (*lm_grant)(struct file_lock *, int);\n\tbool (*lm_break)(struct file_lock *);\n\tint (*lm_change)(struct file_lock **, int, struct list_head *);\n\tvoid (*lm_setup)(struct file_lock *, void **);\n};\n\nstruct lock_manager {\n\tstruct list_head list;\n};\n\nstruct net;\nvoid locks_start_grace(struct net *, struct lock_manager *);\nvoid locks_end_grace(struct lock_manager *);\nint locks_in_grace(struct net *);\n\n/* that will die - we need it for nfs_lock_info */\n#include <linux/nfs_fs_i.h>\n\n/*\n * struct file_lock represents a generic \"file lock\". It's used to represent\n * POSIX byte range locks, BSD (flock) locks, and leases. It's important to\n * note that the same struct is used to represent both a request for a lock and\n * the lock itself, but the same object is never used for both.\n *\n * FIXME: should we create a separate \"struct lock_request\" to help distinguish\n * these two uses?\n *\n * The i_flock list is ordered by:\n *\n * 1) lock type -- FL_LEASEs first, then FL_FLOCK, and finally FL_POSIX\n * 2) lock owner\n * 3) lock range start\n * 4) lock range end\n *\n * Obviously, the last two criteria only matter for POSIX locks.\n */\nstruct file_lock {\n\tstruct file_lock *fl_next;\t/* singly linked list for this inode  */\n\tstruct hlist_node fl_link;\t/* node in global lists */\n\tstruct list_head fl_block;\t/* circular list of blocked processes */\n\tfl_owner_t fl_owner;\n\tunsigned int fl_flags;\n\tunsigned char fl_type;\n\tunsigned int fl_pid;\n\tint fl_link_cpu;\t\t/* what cpu's list is this on? */\n\tstruct pid *fl_nspid;\n\twait_queue_head_t fl_wait;\n\tstruct file *fl_file;\n\tloff_t fl_start;\n\tloff_t fl_end;\n\n\tstruct fasync_struct *\tfl_fasync; /* for lease break notifications */\n\t/* for lease breaks: */\n\tunsigned long fl_break_time;\n\tunsigned long fl_downgrade_time;\n\n\tconst struct file_lock_operations *fl_ops;\t/* Callbacks for filesystems */\n\tconst struct lock_manager_operations *fl_lmops;\t/* Callbacks for lockmanagers */\n\tunion {\n\t\tstruct nfs_lock_info\tnfs_fl;\n\t\tstruct nfs4_lock_info\tnfs4_fl;\n\t\tstruct {\n\t\t\tstruct list_head link;\t/* link in AFS vnode's pending_locks list */\n\t\t\tint state;\t\t/* state of grant or error if -ve */\n\t\t} afs;\n\t} fl_u;\n};\n\n/* The following constant reflects the upper bound of the file/locking space */\n#ifndef OFFSET_MAX\n#define INT_LIMIT(x)\t(~((x)1 << (sizeof(x)*8 - 1)))\n#define OFFSET_MAX\tINT_LIMIT(loff_t)\n#define OFFT_OFFSET_MAX\tINT_LIMIT(off_t)\n#endif\n\n#include <linux/fcntl.h>\n\nextern void send_sigio(struct fown_struct *fown, int fd, int band);\n\n#ifdef CONFIG_FILE_LOCKING\nextern int fcntl_getlk(struct file *, unsigned int, struct flock __user *);\nextern int fcntl_setlk(unsigned int, struct file *, unsigned int,\n\t\t\tstruct flock __user *);\n\n#if BITS_PER_LONG == 32\nextern int fcntl_getlk64(struct file *, unsigned int, struct flock64 __user *);\nextern int fcntl_setlk64(unsigned int, struct file *, unsigned int,\n\t\t\tstruct flock64 __user *);\n#endif\n\nextern int fcntl_setlease(unsigned int fd, struct file *filp, long arg);\nextern int fcntl_getlease(struct file *filp);\n\n/* fs/locks.c */\nvoid locks_free_lock(struct file_lock *fl);\nextern void locks_init_lock(struct file_lock *);\nextern struct file_lock * locks_alloc_lock(void);\nextern void locks_copy_lock(struct file_lock *, struct file_lock *);\nextern void locks_copy_conflock(struct file_lock *, struct file_lock *);\nextern void locks_remove_posix(struct file *, fl_owner_t);\nextern void locks_remove_file(struct file *);\nextern void locks_release_private(struct file_lock *);\nextern void posix_test_lock(struct file *, struct file_lock *);\nextern int posix_lock_file(struct file *, struct file_lock *, struct file_lock *);\nextern int posix_lock_file_wait(struct file *, struct file_lock *);\nextern int posix_unblock_lock(struct file_lock *);\nextern int vfs_test_lock(struct file *, struct file_lock *);\nextern int vfs_lock_file(struct file *, unsigned int, struct file_lock *, struct file_lock *);\nextern int vfs_cancel_lock(struct file *filp, struct file_lock *fl);\nextern int flock_lock_file_wait(struct file *filp, struct file_lock *fl);\nextern int __break_lease(struct inode *inode, unsigned int flags, unsigned int type);\nextern void lease_get_mtime(struct inode *, struct timespec *time);\nextern int generic_setlease(struct file *, long, struct file_lock **, void **priv);\nextern int vfs_setlease(struct file *, long, struct file_lock **, void **);\nextern int lease_modify(struct file_lock **, int, struct list_head *);\n#else /* !CONFIG_FILE_LOCKING */\nstatic inline int fcntl_getlk(struct file *file, unsigned int cmd,\n\t\t\t      struct flock __user *user)\n{\n\treturn -EINVAL;\n}\n\nstatic inline int fcntl_setlk(unsigned int fd, struct file *file,\n\t\t\t      unsigned int cmd, struct flock __user *user)\n{\n\treturn -EACCES;\n}\n\n#if BITS_PER_LONG == 32\nstatic inline int fcntl_getlk64(struct file *file, unsigned int cmd,\n\t\t\t\tstruct flock64 __user *user)\n{\n\treturn -EINVAL;\n}\n\nstatic inline int fcntl_setlk64(unsigned int fd, struct file *file,\n\t\t\t\tunsigned int cmd, struct flock64 __user *user)\n{\n\treturn -EACCES;\n}\n#endif\nstatic inline int fcntl_setlease(unsigned int fd, struct file *filp, long arg)\n{\n\treturn -EINVAL;\n}\n\nstatic inline int fcntl_getlease(struct file *filp)\n{\n\treturn F_UNLCK;\n}\n\nstatic inline void locks_init_lock(struct file_lock *fl)\n{\n\treturn;\n}\n\nstatic inline void locks_copy_conflock(struct file_lock *new, struct file_lock *fl)\n{\n\treturn;\n}\n\nstatic inline void locks_copy_lock(struct file_lock *new, struct file_lock *fl)\n{\n\treturn;\n}\n\nstatic inline void locks_remove_posix(struct file *filp, fl_owner_t owner)\n{\n\treturn;\n}\n\nstatic inline void locks_remove_file(struct file *filp)\n{\n\treturn;\n}\n\nstatic inline void posix_test_lock(struct file *filp, struct file_lock *fl)\n{\n\treturn;\n}\n\nstatic inline int posix_lock_file(struct file *filp, struct file_lock *fl,\n\t\t\t\t  struct file_lock *conflock)\n{\n\treturn -ENOLCK;\n}\n\nstatic inline int posix_lock_file_wait(struct file *filp, struct file_lock *fl)\n{\n\treturn -ENOLCK;\n}\n\nstatic inline int posix_unblock_lock(struct file_lock *waiter)\n{\n\treturn -ENOENT;\n}\n\nstatic inline int vfs_test_lock(struct file *filp, struct file_lock *fl)\n{\n\treturn 0;\n}\n\nstatic inline int vfs_lock_file(struct file *filp, unsigned int cmd,\n\t\t\t\tstruct file_lock *fl, struct file_lock *conf)\n{\n\treturn -ENOLCK;\n}\n\nstatic inline int vfs_cancel_lock(struct file *filp, struct file_lock *fl)\n{\n\treturn 0;\n}\n\nstatic inline int flock_lock_file_wait(struct file *filp,\n\t\t\t\t       struct file_lock *request)\n{\n\treturn -ENOLCK;\n}\n\nstatic inline int __break_lease(struct inode *inode, unsigned int mode, unsigned int type)\n{\n\treturn 0;\n}\n\nstatic inline void lease_get_mtime(struct inode *inode, struct timespec *time)\n{\n\treturn;\n}\n\nstatic inline int generic_setlease(struct file *filp, long arg,\n\t\t\t\t    struct file_lock **flp, void **priv)\n{\n\treturn -EINVAL;\n}\n\nstatic inline int vfs_setlease(struct file *filp, long arg,\n\t\t\t       struct file_lock **lease, void **priv)\n{\n\treturn -EINVAL;\n}\n\nstatic inline int lease_modify(struct file_lock **before, int arg,\n\t\t\t       struct list_head *dispose)\n{\n\treturn -EINVAL;\n}\n#endif /* !CONFIG_FILE_LOCKING */\n\n\nstruct fasync_struct {\n\tspinlock_t\t\tfa_lock;\n\tint\t\t\tmagic;\n\tint\t\t\tfa_fd;\n\tstruct fasync_struct\t*fa_next; /* singly linked list */\n\tstruct file\t\t*fa_file;\n\tstruct rcu_head\t\tfa_rcu;\n};\n\n#define FASYNC_MAGIC 0x4601\n\n/* SMP safe fasync helpers: */\nextern int fasync_helper(int, struct file *, int, struct fasync_struct **);\nextern struct fasync_struct *fasync_insert_entry(int, struct file *, struct fasync_struct **, struct fasync_struct *);\nextern int fasync_remove_entry(struct file *, struct fasync_struct **);\nextern struct fasync_struct *fasync_alloc(void);\nextern void fasync_free(struct fasync_struct *);\n\n/* can be called from interrupts */\nextern void kill_fasync(struct fasync_struct **, int, int);\n\nextern void __f_setown(struct file *filp, struct pid *, enum pid_type, int force);\nextern void f_setown(struct file *filp, unsigned long arg, int force);\nextern void f_delown(struct file *filp);\nextern pid_t f_getown(struct file *filp);\nextern int send_sigurg(struct fown_struct *fown);\n\nstruct mm_struct;\n\n/*\n *\tUmount options\n */\n\n#define MNT_FORCE\t0x00000001\t/* Attempt to forcibily umount */\n#define MNT_DETACH\t0x00000002\t/* Just detach from the tree */\n#define MNT_EXPIRE\t0x00000004\t/* Mark for expiry */\n#define UMOUNT_NOFOLLOW\t0x00000008\t/* Don't follow symlink on umount */\n#define UMOUNT_UNUSED\t0x80000000\t/* Flag guaranteed to be unused */\n\nextern struct list_head super_blocks;\nextern spinlock_t sb_lock;\n\n/* Possible states of 'frozen' field */\nenum {\n\tSB_UNFROZEN = 0,\t\t/* FS is unfrozen */\n\tSB_FREEZE_WRITE\t= 1,\t\t/* Writes, dir ops, ioctls frozen */\n\tSB_FREEZE_PAGEFAULT = 2,\t/* Page faults stopped as well */\n\tSB_FREEZE_FS = 3,\t\t/* For internal FS use (e.g. to stop\n\t\t\t\t\t * internal threads if needed) */\n\tSB_FREEZE_COMPLETE = 4,\t\t/* ->freeze_fs finished successfully */\n};\n\n#define SB_FREEZE_LEVELS (SB_FREEZE_COMPLETE - 1)\n\nstruct sb_writers {\n\t/* Counters for counting writers at each level */\n\tstruct percpu_counter\tcounter[SB_FREEZE_LEVELS];\n\twait_queue_head_t\twait;\t\t/* queue for waiting for\n\t\t\t\t\t\t   writers / faults to finish */\n\tint\t\t\tfrozen;\t\t/* Is sb frozen? */\n\twait_queue_head_t\twait_unfrozen;\t/* queue for waiting for\n\t\t\t\t\t\t   sb to be thawed */\n#ifdef CONFIG_DEBUG_LOCK_ALLOC\n\tstruct lockdep_map\tlock_map[SB_FREEZE_LEVELS];\n#endif\n};\n\nstruct super_block {\n\tstruct list_head\ts_list;\t\t/* Keep this first */\n\tdev_t\t\t\ts_dev;\t\t/* search index; _not_ kdev_t */\n\tunsigned char\t\ts_blocksize_bits;\n\tunsigned long\t\ts_blocksize;\n\tloff_t\t\t\ts_maxbytes;\t/* Max file size */\n\tstruct file_system_type\t*s_type;\n\tconst struct super_operations\t*s_op;\n\tconst struct dquot_operations\t*dq_op;\n\tconst struct quotactl_ops\t*s_qcop;\n\tconst struct export_operations *s_export_op;\n\tunsigned long\t\ts_flags;\n\tunsigned long\t\ts_magic;\n\tstruct dentry\t\t*s_root;\n\tstruct rw_semaphore\ts_umount;\n\tint\t\t\ts_count;\n\tatomic_t\t\ts_active;\n#ifdef CONFIG_SECURITY\n\tvoid                    *s_security;\n#endif\n\tconst struct xattr_handler **s_xattr;\n\n\tstruct list_head\ts_inodes;\t/* all inodes */\n\tstruct hlist_bl_head\ts_anon;\t\t/* anonymous dentries for (nfs) exporting */\n\tstruct list_head\ts_mounts;\t/* list of mounts; _not_ for fs use */\n\tstruct block_device\t*s_bdev;\n\tstruct backing_dev_info *s_bdi;\n\tstruct mtd_info\t\t*s_mtd;\n\tstruct hlist_node\ts_instances;\n\tstruct quota_info\ts_dquot;\t/* Diskquota specific options */\n\n\tstruct sb_writers\ts_writers;\n\n\tchar s_id[32];\t\t\t\t/* Informational name */\n\tu8 s_uuid[16];\t\t\t\t/* UUID */\n\n\tvoid \t\t\t*s_fs_info;\t/* Filesystem private info */\n\tunsigned int\t\ts_max_links;\n\tfmode_t\t\t\ts_mode;\n\n\t/* Granularity of c/m/atime in ns.\n\t   Cannot be worse than a second */\n\tu32\t\t   s_time_gran;\n\n\t/*\n\t * The next field is for VFS *only*. No filesystems have any business\n\t * even looking at it. You had been warned.\n\t */\n\tstruct mutex s_vfs_rename_mutex;\t/* Kludge */\n\n\t/*\n\t * Filesystem subtype.  If non-empty the filesystem type field\n\t * in /proc/mounts will be \"type.subtype\"\n\t */\n\tchar *s_subtype;\n\n\t/*\n\t * Saved mount options for lazy filesystems using\n\t * generic_show_options()\n\t */\n\tchar __rcu *s_options;\n\tconst struct dentry_operations *s_d_op; /* default d_op for dentries */\n\n\t/*\n\t * Saved pool identifier for cleancache (-1 means none)\n\t */\n\tint cleancache_poolid;\n\n\tstruct shrinker s_shrink;\t/* per-sb shrinker handle */\n\n\t/* Number of inodes with nlink == 0 but still referenced */\n\tatomic_long_t s_remove_count;\n\n\t/* Being remounted read-only */\n\tint s_readonly_remount;\n\n\t/* AIO completions deferred from interrupt context */\n\tstruct workqueue_struct *s_dio_done_wq;\n\tstruct hlist_head s_pins;\n\n\t/*\n\t * Keep the lru lists last in the structure so they always sit on their\n\t * own individual cachelines.\n\t */\n\tstruct list_lru\t\ts_dentry_lru ____cacheline_aligned_in_smp;\n\tstruct list_lru\t\ts_inode_lru ____cacheline_aligned_in_smp;\n\tstruct rcu_head\t\trcu;\n\n\t/*\n\t * Indicates how deep in a filesystem stack this SB is\n\t */\n\tint s_stack_depth;\n};\n\nextern struct timespec current_fs_time(struct super_block *sb);\n\n/*\n * Snapshotting support.\n */\n\nvoid __sb_end_write(struct super_block *sb, int level);\nint __sb_start_write(struct super_block *sb, int level, bool wait);\n\n/**\n * sb_end_write - drop write access to a superblock\n * @sb: the super we wrote to\n *\n * Decrement number of writers to the filesystem. Wake up possible waiters\n * wanting to freeze the filesystem.\n */\nstatic inline void sb_end_write(struct super_block *sb)\n{\n\t__sb_end_write(sb, SB_FREEZE_WRITE);\n}\n\n/**\n * sb_end_pagefault - drop write access to a superblock from a page fault\n * @sb: the super we wrote to\n *\n * Decrement number of processes handling write page fault to the filesystem.\n * Wake up possible waiters wanting to freeze the filesystem.\n */\nstatic inline void sb_end_pagefault(struct super_block *sb)\n{\n\t__sb_end_write(sb, SB_FREEZE_PAGEFAULT);\n}\n\n/**\n * sb_end_intwrite - drop write access to a superblock for internal fs purposes\n * @sb: the super we wrote to\n *\n * Decrement fs-internal number of writers to the filesystem.  Wake up possible\n * waiters wanting to freeze the filesystem.\n */\nstatic inline void sb_end_intwrite(struct super_block *sb)\n{\n\t__sb_end_write(sb, SB_FREEZE_FS);\n}\n\n/**\n * sb_start_write - get write access to a superblock\n * @sb: the super we write to\n *\n * When a process wants to write data or metadata to a file system (i.e. dirty\n * a page or an inode), it should embed the operation in a sb_start_write() -\n * sb_end_write() pair to get exclusion against file system freezing. This\n * function increments number of writers preventing freezing. If the file\n * system is already frozen, the function waits until the file system is\n * thawed.\n *\n * Since freeze protection behaves as a lock, users have to preserve\n * ordering of freeze protection and other filesystem locks. Generally,\n * freeze protection should be the outermost lock. In particular, we have:\n *\n * sb_start_write\n *   -> i_mutex\t\t\t(write path, truncate, directory ops, ...)\n *   -> s_umount\t\t(freeze_super, thaw_super)\n */\nstatic inline void sb_start_write(struct super_block *sb)\n{\n\t__sb_start_write(sb, SB_FREEZE_WRITE, true);\n}\n\nstatic inline int sb_start_write_trylock(struct super_block *sb)\n{\n\treturn __sb_start_write(sb, SB_FREEZE_WRITE, false);\n}\n\n/**\n * sb_start_pagefault - get write access to a superblock from a page fault\n * @sb: the super we write to\n *\n * When a process starts handling write page fault, it should embed the\n * operation into sb_start_pagefault() - sb_end_pagefault() pair to get\n * exclusion against file system freezing. This is needed since the page fault\n * is going to dirty a page. This function increments number of running page\n * faults preventing freezing. If the file system is already frozen, the\n * function waits until the file system is thawed.\n *\n * Since page fault freeze protection behaves as a lock, users have to preserve\n * ordering of freeze protection and other filesystem locks. It is advised to\n * put sb_start_pagefault() close to mmap_sem in lock ordering. Page fault\n * handling code implies lock dependency:\n *\n * mmap_sem\n *   -> sb_start_pagefault\n */\nstatic inline void sb_start_pagefault(struct super_block *sb)\n{\n\t__sb_start_write(sb, SB_FREEZE_PAGEFAULT, true);\n}\n\n/*\n * sb_start_intwrite - get write access to a superblock for internal fs purposes\n * @sb: the super we write to\n *\n * This is the third level of protection against filesystem freezing. It is\n * free for use by a filesystem. The only requirement is that it must rank\n * below sb_start_pagefault.\n *\n * For example filesystem can call sb_start_intwrite() when starting a\n * transaction which somewhat eases handling of freezing for internal sources\n * of filesystem changes (internal fs threads, discarding preallocation on file\n * close, etc.).\n */\nstatic inline void sb_start_intwrite(struct super_block *sb)\n{\n\t__sb_start_write(sb, SB_FREEZE_FS, true);\n}\n\n\nextern bool inode_owner_or_capable(const struct inode *inode);\n\n/*\n * VFS helper functions..\n */\nextern int vfs_create(struct inode *, struct dentry *, umode_t, bool);\nextern int vfs_mkdir(struct inode *, struct dentry *, umode_t);\nextern int vfs_mknod(struct inode *, struct dentry *, umode_t, dev_t);\nextern int vfs_symlink(struct inode *, struct dentry *, const char *);\nextern int vfs_link(struct dentry *, struct inode *, struct dentry *, struct inode **);\nextern int vfs_rmdir(struct inode *, struct dentry *);\nextern int vfs_unlink(struct inode *, struct dentry *, struct inode **);\nextern int vfs_rename(struct inode *, struct dentry *, struct inode *, struct dentry *, struct inode **, unsigned int);\nextern int vfs_whiteout(struct inode *, struct dentry *);\n\n/*\n * VFS dentry helper functions.\n */\nextern void dentry_unhash(struct dentry *dentry);\n\n/*\n * VFS file helper functions.\n */\nextern void inode_init_owner(struct inode *inode, const struct inode *dir,\n\t\t\tumode_t mode);\n/*\n * VFS FS_IOC_FIEMAP helper definitions.\n */\nstruct fiemap_extent_info {\n\tunsigned int fi_flags;\t\t/* Flags as passed from user */\n\tunsigned int fi_extents_mapped;\t/* Number of mapped extents */\n\tunsigned int fi_extents_max;\t/* Size of fiemap_extent array */\n\tstruct fiemap_extent __user *fi_extents_start; /* Start of\n\t\t\t\t\t\t\tfiemap_extent array */\n};\nint fiemap_fill_next_extent(struct fiemap_extent_info *info, u64 logical,\n\t\t\t    u64 phys, u64 len, u32 flags);\nint fiemap_check_flags(struct fiemap_extent_info *fieinfo, u32 fs_flags);\n\n/*\n * File types\n *\n * NOTE! These match bits 12..15 of stat.st_mode\n * (ie \"(i_mode >> 12) & 15\").\n */\n#define DT_UNKNOWN\t0\n#define DT_FIFO\t\t1\n#define DT_CHR\t\t2\n#define DT_DIR\t\t4\n#define DT_BLK\t\t6\n#define DT_REG\t\t8\n#define DT_LNK\t\t10\n#define DT_SOCK\t\t12\n#define DT_WHT\t\t14\n\n/*\n * This is the \"filldir\" function type, used by readdir() to let\n * the kernel specify what kind of dirent layout it wants to have.\n * This allows the kernel to read directories into kernel space or\n * to have different dirent layouts depending on the binary type.\n */\ntypedef int (*filldir_t)(void *, const char *, int, loff_t, u64, unsigned);\nstruct dir_context {\n\tconst filldir_t actor;\n\tloff_t pos;\n};\n\nstruct block_device_operations;\n\n/* These macros are for out of kernel modules to test that\n * the kernel supports the unlocked_ioctl and compat_ioctl\n * fields in struct file_operations. */\n#define HAVE_COMPAT_IOCTL 1\n#define HAVE_UNLOCKED_IOCTL 1\n\nstruct iov_iter;\n\nstruct file_operations {\n\tstruct module *owner;\n\tloff_t (*llseek) (struct file *, loff_t, int);\n\tssize_t (*read) (struct file *, char __user *, size_t, loff_t *);\n\tssize_t (*write) (struct file *, const char __user *, size_t, loff_t *);\n\tssize_t (*aio_read) (struct kiocb *, const struct iovec *, unsigned long, loff_t);\n\tssize_t (*aio_write) (struct kiocb *, const struct iovec *, unsigned long, loff_t);\n\tssize_t (*read_iter) (struct kiocb *, struct iov_iter *);\n\tssize_t (*write_iter) (struct kiocb *, struct iov_iter *);\n\tint (*iterate) (struct file *, struct dir_context *);\n\tunsigned int (*poll) (struct file *, struct poll_table_struct *);\n\tlong (*unlocked_ioctl) (struct file *, unsigned int, unsigned long);\n\tlong (*compat_ioctl) (struct file *, unsigned int, unsigned long);\n\tint (*mmap) (struct file *, struct vm_area_struct *);\n\tint (*open) (struct inode *, struct file *);\n\tint (*flush) (struct file *, fl_owner_t id);\n\tint (*release) (struct inode *, struct file *);\n\tint (*fsync) (struct file *, loff_t, loff_t, int datasync);\n\tint (*aio_fsync) (struct kiocb *, int datasync);\n\tint (*fasync) (int, struct file *, int);\n\tint (*lock) (struct file *, int, struct file_lock *);\n\tssize_t (*sendpage) (struct file *, struct page *, int, size_t, loff_t *, int);\n\tunsigned long (*get_unmapped_area)(struct file *, unsigned long, unsigned long, unsigned long, unsigned long);\n\tint (*check_flags)(int);\n\tint (*flock) (struct file *, int, struct file_lock *);\n\tssize_t (*splice_write)(struct pipe_inode_info *, struct file *, loff_t *, size_t, unsigned int);\n\tssize_t (*splice_read)(struct file *, loff_t *, struct pipe_inode_info *, size_t, unsigned int);\n\tint (*setlease)(struct file *, long, struct file_lock **, void **);\n\tlong (*fallocate)(struct file *file, int mode, loff_t offset,\n\t\t\t  loff_t len);\n\tint (*show_fdinfo)(struct seq_file *m, struct file *f);\n};\n\nstruct inode_operations {\n\tstruct dentry * (*lookup) (struct inode *,struct dentry *, unsigned int);\n\tvoid * (*follow_link) (struct dentry *, struct nameidata *);\n\tint (*permission) (struct inode *, int);\n\tstruct posix_acl * (*get_acl)(struct inode *, int);\n\n\tint (*readlink) (struct dentry *, char __user *,int);\n\tvoid (*put_link) (struct dentry *, struct nameidata *, void *);\n\n\tint (*create) (struct inode *,struct dentry *, umode_t, bool);\n\tint (*link) (struct dentry *,struct inode *,struct dentry *);\n\tint (*unlink) (struct inode *,struct dentry *);\n\tint (*symlink) (struct inode *,struct dentry *,const char *);\n\tint (*mkdir) (struct inode *,struct dentry *,umode_t);\n\tint (*rmdir) (struct inode *,struct dentry *);\n\tint (*mknod) (struct inode *,struct dentry *,umode_t,dev_t);\n\tint (*rename) (struct inode *, struct dentry *,\n\t\t\tstruct inode *, struct dentry *);\n\tint (*rename2) (struct inode *, struct dentry *,\n\t\t\tstruct inode *, struct dentry *, unsigned int);\n\tint (*setattr) (struct dentry *, struct iattr *);\n\tint (*getattr) (struct vfsmount *mnt, struct dentry *, struct kstat *);\n\tint (*setxattr) (struct dentry *, const char *,const void *,size_t,int);\n\tssize_t (*getxattr) (struct dentry *, const char *, void *, size_t);\n\tssize_t (*listxattr) (struct dentry *, char *, size_t);\n\tint (*removexattr) (struct dentry *, const char *);\n\tint (*fiemap)(struct inode *, struct fiemap_extent_info *, u64 start,\n\t\t      u64 len);\n\tint (*update_time)(struct inode *, struct timespec *, int);\n\tint (*atomic_open)(struct inode *, struct dentry *,\n\t\t\t   struct file *, unsigned open_flag,\n\t\t\t   umode_t create_mode, int *opened);\n\tint (*tmpfile) (struct inode *, struct dentry *, umode_t);\n\tint (*set_acl)(struct inode *, struct posix_acl *, int);\n\n\t/* WARNING: probably going away soon, do not use! */\n\tint (*dentry_open)(struct dentry *, struct file *, const struct cred *);\n} ____cacheline_aligned;\n\nssize_t rw_copy_check_uvector(int type, const struct iovec __user * uvector,\n\t\t\t      unsigned long nr_segs, unsigned long fast_segs,\n\t\t\t      struct iovec *fast_pointer,\n\t\t\t      struct iovec **ret_pointer);\n\nextern ssize_t vfs_read(struct file *, char __user *, size_t, loff_t *);\nextern ssize_t vfs_write(struct file *, const char __user *, size_t, loff_t *);\nextern ssize_t vfs_readv(struct file *, const struct iovec __user *,\n\t\tunsigned long, loff_t *);\nextern ssize_t vfs_writev(struct file *, const struct iovec __user *,\n\t\tunsigned long, loff_t *);\n\nstruct super_operations {\n   \tstruct inode *(*alloc_inode)(struct super_block *sb);\n\tvoid (*destroy_inode)(struct inode *);\n\n   \tvoid (*dirty_inode) (struct inode *, int flags);\n\tint (*write_inode) (struct inode *, struct writeback_control *wbc);\n\tint (*drop_inode) (struct inode *);\n\tvoid (*evict_inode) (struct inode *);\n\tvoid (*put_super) (struct super_block *);\n\tint (*sync_fs)(struct super_block *sb, int wait);\n\tint (*freeze_fs) (struct super_block *);\n\tint (*unfreeze_fs) (struct super_block *);\n\tint (*statfs) (struct dentry *, struct kstatfs *);\n\tint (*remount_fs) (struct super_block *, int *, char *);\n\tvoid (*umount_begin) (struct super_block *);\n\n\tint (*show_options)(struct seq_file *, struct dentry *);\n\tint (*show_devname)(struct seq_file *, struct dentry *);\n\tint (*show_path)(struct seq_file *, struct dentry *);\n\tint (*show_stats)(struct seq_file *, struct dentry *);\n#ifdef CONFIG_QUOTA\n\tssize_t (*quota_read)(struct super_block *, int, char *, size_t, loff_t);\n\tssize_t (*quota_write)(struct super_block *, int, const char *, size_t, loff_t);\n#endif\n\tint (*bdev_try_to_free_page)(struct super_block*, struct page*, gfp_t);\n\tlong (*nr_cached_objects)(struct super_block *, int);\n\tlong (*free_cached_objects)(struct super_block *, long, int);\n};\n\n/*\n * Inode flags - they have no relation to superblock flags now\n */\n#define S_SYNC\t\t1\t/* Writes are synced at once */\n#define S_NOATIME\t2\t/* Do not update access times */\n#define S_APPEND\t4\t/* Append-only file */\n#define S_IMMUTABLE\t8\t/* Immutable file */\n#define S_DEAD\t\t16\t/* removed, but still open directory */\n#define S_NOQUOTA\t32\t/* Inode is not counted to quota */\n#define S_DIRSYNC\t64\t/* Directory modifications are synchronous */\n#define S_NOCMTIME\t128\t/* Do not update file c/mtime */\n#define S_SWAPFILE\t256\t/* Do not truncate: swapon got its bmaps */\n#define S_PRIVATE\t512\t/* Inode is fs-internal */\n#define S_IMA\t\t1024\t/* Inode has an associated IMA struct */\n#define S_AUTOMOUNT\t2048\t/* Automount/referral quasi-directory */\n#define S_NOSEC\t\t4096\t/* no suid or xattr security attributes */\n\n/*\n * Note that nosuid etc flags are inode-specific: setting some file-system\n * flags just means all the inodes inherit those flags by default. It might be\n * possible to override it selectively if you really wanted to with some\n * ioctl() that is not currently implemented.\n *\n * Exception: MS_RDONLY is always applied to the entire file system.\n *\n * Unfortunately, it is possible to change a filesystems flags with it mounted\n * with files in use.  This means that all of the inodes will not have their\n * i_flags updated.  Hence, i_flags no longer inherit the superblock mount\n * flags, so these have to be checked separately. -- rmk@arm.uk.linux.org\n */\n#define __IS_FLG(inode, flg)\t((inode)->i_sb->s_flags & (flg))\n\n#define IS_RDONLY(inode)\t((inode)->i_sb->s_flags & MS_RDONLY)\n#define IS_SYNC(inode)\t\t(__IS_FLG(inode, MS_SYNCHRONOUS) || \\\n\t\t\t\t\t((inode)->i_flags & S_SYNC))\n#define IS_DIRSYNC(inode)\t(__IS_FLG(inode, MS_SYNCHRONOUS|MS_DIRSYNC) || \\\n\t\t\t\t\t((inode)->i_flags & (S_SYNC|S_DIRSYNC)))\n#define IS_MANDLOCK(inode)\t__IS_FLG(inode, MS_MANDLOCK)\n#define IS_NOATIME(inode)\t__IS_FLG(inode, MS_RDONLY|MS_NOATIME)\n#define IS_I_VERSION(inode)\t__IS_FLG(inode, MS_I_VERSION)\n\n#define IS_NOQUOTA(inode)\t((inode)->i_flags & S_NOQUOTA)\n#define IS_APPEND(inode)\t((inode)->i_flags & S_APPEND)\n#define IS_IMMUTABLE(inode)\t((inode)->i_flags & S_IMMUTABLE)\n#define IS_POSIXACL(inode)\t__IS_FLG(inode, MS_POSIXACL)\n\n#define IS_DEADDIR(inode)\t((inode)->i_flags & S_DEAD)\n#define IS_NOCMTIME(inode)\t((inode)->i_flags & S_NOCMTIME)\n#define IS_SWAPFILE(inode)\t((inode)->i_flags & S_SWAPFILE)\n#define IS_PRIVATE(inode)\t((inode)->i_flags & S_PRIVATE)\n#define IS_IMA(inode)\t\t((inode)->i_flags & S_IMA)\n#define IS_AUTOMOUNT(inode)\t((inode)->i_flags & S_AUTOMOUNT)\n#define IS_NOSEC(inode)\t\t((inode)->i_flags & S_NOSEC)\n\n#define IS_WHITEOUT(inode)\t(S_ISCHR(inode->i_mode) && \\\n\t\t\t\t (inode)->i_rdev == WHITEOUT_DEV)\n\n/*\n * Inode state bits.  Protected by inode->i_lock\n *\n * Three bits determine the dirty state of the inode, I_DIRTY_SYNC,\n * I_DIRTY_DATASYNC and I_DIRTY_PAGES.\n *\n * Four bits define the lifetime of an inode.  Initially, inodes are I_NEW,\n * until that flag is cleared.  I_WILL_FREE, I_FREEING and I_CLEAR are set at\n * various stages of removing an inode.\n *\n * Two bits are used for locking and completion notification, I_NEW and I_SYNC.\n *\n * I_DIRTY_SYNC\t\tInode is dirty, but doesn't have to be written on\n *\t\t\tfdatasync().  i_atime is the usual cause.\n * I_DIRTY_DATASYNC\tData-related inode changes pending. We keep track of\n *\t\t\tthese changes separately from I_DIRTY_SYNC so that we\n *\t\t\tdon't have to write inode on fdatasync() when only\n *\t\t\tmtime has changed in it.\n * I_DIRTY_PAGES\tInode has dirty pages.  Inode itself may be clean.\n * I_NEW\t\tServes as both a mutex and completion notification.\n *\t\t\tNew inodes set I_NEW.  If two processes both create\n *\t\t\tthe same inode, one of them will release its inode and\n *\t\t\twait for I_NEW to be released before returning.\n *\t\t\tInodes in I_WILL_FREE, I_FREEING or I_CLEAR state can\n *\t\t\talso cause waiting on I_NEW, without I_NEW actually\n *\t\t\tbeing set.  find_inode() uses this to prevent returning\n *\t\t\tnearly-dead inodes.\n * I_WILL_FREE\t\tMust be set when calling write_inode_now() if i_count\n *\t\t\tis zero.  I_FREEING must be set when I_WILL_FREE is\n *\t\t\tcleared.\n * I_FREEING\t\tSet when inode is about to be freed but still has dirty\n *\t\t\tpages or buffers attached or the inode itself is still\n *\t\t\tdirty.\n * I_CLEAR\t\tAdded by clear_inode().  In this state the inode is\n *\t\t\tclean and can be destroyed.  Inode keeps I_FREEING.\n *\n *\t\t\tInodes that are I_WILL_FREE, I_FREEING or I_CLEAR are\n *\t\t\tprohibited for many purposes.  iget() must wait for\n *\t\t\tthe inode to be completely released, then create it\n *\t\t\tanew.  Other functions will just ignore such inodes,\n *\t\t\tif appropriate.  I_NEW is used for waiting.\n *\n * I_SYNC\t\tWriteback of inode is running. The bit is set during\n *\t\t\tdata writeback, and cleared with a wakeup on the bit\n *\t\t\taddress once it is done. The bit is also used to pin\n *\t\t\tthe inode in memory for flusher thread.\n *\n * I_REFERENCED\t\tMarks the inode as recently references on the LRU list.\n *\n * I_DIO_WAKEUP\t\tNever set.  Only used as a key for wait_on_bit().\n *\n * Q: What is the difference between I_WILL_FREE and I_FREEING?\n */\n#define I_DIRTY_SYNC\t\t(1 << 0)\n#define I_DIRTY_DATASYNC\t(1 << 1)\n#define I_DIRTY_PAGES\t\t(1 << 2)\n#define __I_NEW\t\t\t3\n#define I_NEW\t\t\t(1 << __I_NEW)\n#define I_WILL_FREE\t\t(1 << 4)\n#define I_FREEING\t\t(1 << 5)\n#define I_CLEAR\t\t\t(1 << 6)\n#define __I_SYNC\t\t7\n#define I_SYNC\t\t\t(1 << __I_SYNC)\n#define I_REFERENCED\t\t(1 << 8)\n#define __I_DIO_WAKEUP\t\t9\n#define I_DIO_WAKEUP\t\t(1 << I_DIO_WAKEUP)\n#define I_LINKABLE\t\t(1 << 10)\n\n#define I_DIRTY (I_DIRTY_SYNC | I_DIRTY_DATASYNC | I_DIRTY_PAGES)\n\nextern void __mark_inode_dirty(struct inode *, int);\nstatic inline void mark_inode_dirty(struct inode *inode)\n{\n\t__mark_inode_dirty(inode, I_DIRTY);\n}\n\nstatic inline void mark_inode_dirty_sync(struct inode *inode)\n{\n\t__mark_inode_dirty(inode, I_DIRTY_SYNC);\n}\n\nextern void inc_nlink(struct inode *inode);\nextern void drop_nlink(struct inode *inode);\nextern void clear_nlink(struct inode *inode);\nextern void set_nlink(struct inode *inode, unsigned int nlink);\n\nstatic inline void inode_inc_link_count(struct inode *inode)\n{\n\tinc_nlink(inode);\n\tmark_inode_dirty(inode);\n}\n\nstatic inline void inode_dec_link_count(struct inode *inode)\n{\n\tdrop_nlink(inode);\n\tmark_inode_dirty(inode);\n}\n\n/**\n * inode_inc_iversion - increments i_version\n * @inode: inode that need to be updated\n *\n * Every time the inode is modified, the i_version field will be incremented.\n * The filesystem has to be mounted with i_version flag\n */\n\nstatic inline void inode_inc_iversion(struct inode *inode)\n{\n       spin_lock(&inode->i_lock);\n       inode->i_version++;\n       spin_unlock(&inode->i_lock);\n}\n\nenum file_time_flags {\n\tS_ATIME = 1,\n\tS_MTIME = 2,\n\tS_CTIME = 4,\n\tS_VERSION = 8,\n};\n\nextern void touch_atime(const struct path *);\nstatic inline void file_accessed(struct file *file)\n{\n\tif (!(file->f_flags & O_NOATIME))\n\t\ttouch_atime(&file->f_path);\n}\n\nint sync_inode(struct inode *inode, struct writeback_control *wbc);\nint sync_inode_metadata(struct inode *inode, int wait);\n\nstruct file_system_type {\n\tconst char *name;\n\tint fs_flags;\n#define FS_REQUIRES_DEV\t\t1 \n#define FS_BINARY_MOUNTDATA\t2\n#define FS_HAS_SUBTYPE\t\t4\n#define FS_USERNS_MOUNT\t\t8\t/* Can be mounted by userns root */\n#define FS_USERNS_DEV_MOUNT\t16 /* A userns mount does not imply MNT_NODEV */\n#define FS_RENAME_DOES_D_MOVE\t32768\t/* FS will handle d_move() during rename() internally. */\n\tstruct dentry *(*mount) (struct file_system_type *, int,\n\t\t       const char *, void *);\n\tvoid (*kill_sb) (struct super_block *);\n\tstruct module *owner;\n\tstruct file_system_type * next;\n\tstruct hlist_head fs_supers;\n\n\tstruct lock_class_key s_lock_key;\n\tstruct lock_class_key s_umount_key;\n\tstruct lock_class_key s_vfs_rename_key;\n\tstruct lock_class_key s_writers_key[SB_FREEZE_LEVELS];\n\n\tstruct lock_class_key i_lock_key;\n\tstruct lock_class_key i_mutex_key;\n\tstruct lock_class_key i_mutex_dir_key;\n};\n\n#define MODULE_ALIAS_FS(NAME) MODULE_ALIAS(\"fs-\" NAME)\n\nextern struct dentry *mount_ns(struct file_system_type *fs_type, int flags,\n\tvoid *data, int (*fill_super)(struct super_block *, void *, int));\nextern struct dentry *mount_bdev(struct file_system_type *fs_type,\n\tint flags, const char *dev_name, void *data,\n\tint (*fill_super)(struct super_block *, void *, int));\nextern struct dentry *mount_single(struct file_system_type *fs_type,\n\tint flags, void *data,\n\tint (*fill_super)(struct super_block *, void *, int));\nextern struct dentry *mount_nodev(struct file_system_type *fs_type,\n\tint flags, void *data,\n\tint (*fill_super)(struct super_block *, void *, int));\nextern struct dentry *mount_subtree(struct vfsmount *mnt, const char *path);\nvoid generic_shutdown_super(struct super_block *sb);\nvoid kill_block_super(struct super_block *sb);\nvoid kill_anon_super(struct super_block *sb);\nvoid kill_litter_super(struct super_block *sb);\nvoid deactivate_super(struct super_block *sb);\nvoid deactivate_locked_super(struct super_block *sb);\nint set_anon_super(struct super_block *s, void *data);\nint get_anon_bdev(dev_t *);\nvoid free_anon_bdev(dev_t);\nstruct super_block *sget(struct file_system_type *type,\n\t\t\tint (*test)(struct super_block *,void *),\n\t\t\tint (*set)(struct super_block *,void *),\n\t\t\tint flags, void *data);\nextern struct dentry *mount_pseudo(struct file_system_type *, char *,\n\tconst struct super_operations *ops,\n\tconst struct dentry_operations *dops,\n\tunsigned long);\n\n/* Alas, no aliases. Too much hassle with bringing module.h everywhere */\n#define fops_get(fops) \\\n\t(((fops) && try_module_get((fops)->owner) ? (fops) : NULL))\n#define fops_put(fops) \\\n\tdo { if (fops) module_put((fops)->owner); } while(0)\n/*\n * This one is to be used *ONLY* from ->open() instances.\n * fops must be non-NULL, pinned down *and* module dependencies\n * should be sufficient to pin the caller down as well.\n */\n#define replace_fops(f, fops) \\\n\tdo {\t\\\n\t\tstruct file *__file = (f); \\\n\t\tfops_put(__file->f_op); \\\n\t\tBUG_ON(!(__file->f_op = (fops))); \\\n\t} while(0)\n\nextern int register_filesystem(struct file_system_type *);\nextern int unregister_filesystem(struct file_system_type *);\nextern struct vfsmount *kern_mount_data(struct file_system_type *, void *data);\n#define kern_mount(type) kern_mount_data(type, NULL)\nextern void kern_unmount(struct vfsmount *mnt);\nextern int may_umount_tree(struct vfsmount *);\nextern int may_umount(struct vfsmount *);\nextern long do_mount(const char *, const char __user *,\n\t\t     const char *, unsigned long, void *);\nextern struct vfsmount *collect_mounts(struct path *);\nextern void drop_collected_mounts(struct vfsmount *);\nextern int iterate_mounts(int (*)(struct vfsmount *, void *), void *,\n\t\t\t  struct vfsmount *);\nextern int vfs_statfs(struct path *, struct kstatfs *);\nextern int user_statfs(const char __user *, struct kstatfs *);\nextern int fd_statfs(int, struct kstatfs *);\nextern int vfs_ustat(dev_t, struct kstatfs *);\nextern int freeze_super(struct super_block *super);\nextern int thaw_super(struct super_block *super);\nextern bool our_mnt(struct vfsmount *mnt);\nextern bool fs_fully_visible(struct file_system_type *);\n\nextern int current_umask(void);\n\nextern void ihold(struct inode * inode);\nextern void iput(struct inode *);\n\nstatic inline struct inode *file_inode(const struct file *f)\n{\n\treturn f->f_inode;\n}\n\n/* /sys/fs */\nextern struct kobject *fs_kobj;\n\n#define MAX_RW_COUNT (INT_MAX & PAGE_CACHE_MASK)\n\n#define FLOCK_VERIFY_READ  1\n#define FLOCK_VERIFY_WRITE 2\n\n#ifdef CONFIG_FILE_LOCKING\nextern int locks_mandatory_locked(struct file *);\nextern int locks_mandatory_area(int, struct inode *, struct file *, loff_t, size_t);\n\n/*\n * Candidates for mandatory locking have the setgid bit set\n * but no group execute bit -  an otherwise meaningless combination.\n */\n\nstatic inline int __mandatory_lock(struct inode *ino)\n{\n\treturn (ino->i_mode & (S_ISGID | S_IXGRP)) == S_ISGID;\n}\n\n/*\n * ... and these candidates should be on MS_MANDLOCK mounted fs,\n * otherwise these will be advisory locks\n */\n\nstatic inline int mandatory_lock(struct inode *ino)\n{\n\treturn IS_MANDLOCK(ino) && __mandatory_lock(ino);\n}\n\nstatic inline int locks_verify_locked(struct file *file)\n{\n\tif (mandatory_lock(file_inode(file)))\n\t\treturn locks_mandatory_locked(file);\n\treturn 0;\n}\n\nstatic inline int locks_verify_truncate(struct inode *inode,\n\t\t\t\t    struct file *filp,\n\t\t\t\t    loff_t size)\n{\n\tif (inode->i_flock && mandatory_lock(inode))\n\t\treturn locks_mandatory_area(\n\t\t\tFLOCK_VERIFY_WRITE, inode, filp,\n\t\t\tsize < inode->i_size ? size : inode->i_size,\n\t\t\t(size < inode->i_size ? inode->i_size - size\n\t\t\t : size - inode->i_size)\n\t\t);\n\treturn 0;\n}\n\nstatic inline int break_lease(struct inode *inode, unsigned int mode)\n{\n\t/*\n\t * Since this check is lockless, we must ensure that any refcounts\n\t * taken are done before checking inode->i_flock. Otherwise, we could\n\t * end up racing with tasks trying to set a new lease on this file.\n\t */\n\tsmp_mb();\n\tif (inode->i_flock)\n\t\treturn __break_lease(inode, mode, FL_LEASE);\n\treturn 0;\n}\n\nstatic inline int break_deleg(struct inode *inode, unsigned int mode)\n{\n\t/*\n\t * Since this check is lockless, we must ensure that any refcounts\n\t * taken are done before checking inode->i_flock. Otherwise, we could\n\t * end up racing with tasks trying to set a new lease on this file.\n\t */\n\tsmp_mb();\n\tif (inode->i_flock)\n\t\treturn __break_lease(inode, mode, FL_DELEG);\n\treturn 0;\n}\n\nstatic inline int try_break_deleg(struct inode *inode, struct inode **delegated_inode)\n{\n\tint ret;\n\n\tret = break_deleg(inode, O_WRONLY|O_NONBLOCK);\n\tif (ret == -EWOULDBLOCK && delegated_inode) {\n\t\t*delegated_inode = inode;\n\t\tihold(inode);\n\t}\n\treturn ret;\n}\n\nstatic inline int break_deleg_wait(struct inode **delegated_inode)\n{\n\tint ret;\n\n\tret = break_deleg(*delegated_inode, O_WRONLY);\n\tiput(*delegated_inode);\n\t*delegated_inode = NULL;\n\treturn ret;\n}\n\n#else /* !CONFIG_FILE_LOCKING */\nstatic inline int locks_mandatory_locked(struct file *file)\n{\n\treturn 0;\n}\n\nstatic inline int locks_mandatory_area(int rw, struct inode *inode,\n\t\t\t\t       struct file *filp, loff_t offset,\n\t\t\t\t       size_t count)\n{\n\treturn 0;\n}\n\nstatic inline int __mandatory_lock(struct inode *inode)\n{\n\treturn 0;\n}\n\nstatic inline int mandatory_lock(struct inode *inode)\n{\n\treturn 0;\n}\n\nstatic inline int locks_verify_locked(struct file *file)\n{\n\treturn 0;\n}\n\nstatic inline int locks_verify_truncate(struct inode *inode, struct file *filp,\n\t\t\t\t\tsize_t size)\n{\n\treturn 0;\n}\n\nstatic inline int break_lease(struct inode *inode, unsigned int mode)\n{\n\treturn 0;\n}\n\nstatic inline int break_deleg(struct inode *inode, unsigned int mode)\n{\n\treturn 0;\n}\n\nstatic inline int try_break_deleg(struct inode *inode, struct inode **delegated_inode)\n{\n\treturn 0;\n}\n\nstatic inline int break_deleg_wait(struct inode **delegated_inode)\n{\n\tBUG();\n\treturn 0;\n}\n\n#endif /* CONFIG_FILE_LOCKING */\n\n/* fs/open.c */\nstruct audit_names;\nstruct filename {\n\tconst char\t\t*name;\t/* pointer to actual string */\n\tconst __user char\t*uptr;\t/* original userland pointer */\n\tstruct audit_names\t*aname;\n\tbool\t\t\tseparate; /* should \"name\" be freed? */\n};\n\nextern long vfs_truncate(struct path *, loff_t);\nextern int do_truncate(struct dentry *, loff_t start, unsigned int time_attrs,\n\t\t       struct file *filp);\nextern int do_fallocate(struct file *file, int mode, loff_t offset,\n\t\t\tloff_t len);\nextern long do_sys_open(int dfd, const char __user *filename, int flags,\n\t\t\tumode_t mode);\nextern struct file *file_open_name(struct filename *, int, umode_t);\nextern struct file *filp_open(const char *, int, umode_t);\nextern struct file *file_open_root(struct dentry *, struct vfsmount *,\n\t\t\t\t   const char *, int);\nextern int vfs_open(const struct path *, struct file *, const struct cred *);\nextern struct file * dentry_open(const struct path *, int, const struct cred *);\nextern int filp_close(struct file *, fl_owner_t id);\n\nextern struct filename *getname(const char __user *);\nextern struct filename *getname_kernel(const char *);\n\nenum {\n\tFILE_CREATED = 1,\n\tFILE_OPENED = 2\n};\nextern int finish_open(struct file *file, struct dentry *dentry,\n\t\t\tint (*open)(struct inode *, struct file *),\n\t\t\tint *opened);\nextern int finish_no_open(struct file *file, struct dentry *dentry);\n\n/* fs/ioctl.c */\n\nextern int ioctl_preallocate(struct file *filp, void __user *argp);\n\n/* fs/dcache.c */\nextern void __init vfs_caches_init_early(void);\nextern void __init vfs_caches_init(unsigned long);\n\nextern struct kmem_cache *names_cachep;\n\nextern void final_putname(struct filename *name);\n\n#define __getname()\t\tkmem_cache_alloc(names_cachep, GFP_KERNEL)\n#define __putname(name)\t\tkmem_cache_free(names_cachep, (void *)(name))\n#ifndef CONFIG_AUDITSYSCALL\n#define putname(name)\t\tfinal_putname(name)\n#else\nextern void putname(struct filename *name);\n#endif\n\n#ifdef CONFIG_BLOCK\nextern int register_blkdev(unsigned int, const char *);\nextern void unregister_blkdev(unsigned int, const char *);\nextern struct block_device *bdget(dev_t);\nextern struct block_device *bdgrab(struct block_device *bdev);\nextern void bd_set_size(struct block_device *, loff_t size);\nextern void bd_forget(struct inode *inode);\nextern void bdput(struct block_device *);\nextern void invalidate_bdev(struct block_device *);\nextern void iterate_bdevs(void (*)(struct block_device *, void *), void *);\nextern int sync_blockdev(struct block_device *bdev);\nextern void kill_bdev(struct block_device *);\nextern struct super_block *freeze_bdev(struct block_device *);\nextern void emergency_thaw_all(void);\nextern int thaw_bdev(struct block_device *bdev, struct super_block *sb);\nextern int fsync_bdev(struct block_device *);\nextern int sb_is_blkdev_sb(struct super_block *sb);\n#else\nstatic inline void bd_forget(struct inode *inode) {}\nstatic inline int sync_blockdev(struct block_device *bdev) { return 0; }\nstatic inline void kill_bdev(struct block_device *bdev) {}\nstatic inline void invalidate_bdev(struct block_device *bdev) {}\n\nstatic inline struct super_block *freeze_bdev(struct block_device *sb)\n{\n\treturn NULL;\n}\n\nstatic inline int thaw_bdev(struct block_device *bdev, struct super_block *sb)\n{\n\treturn 0;\n}\n\nstatic inline void iterate_bdevs(void (*f)(struct block_device *, void *), void *arg)\n{\n}\n\nstatic inline int sb_is_blkdev_sb(struct super_block *sb)\n{\n\treturn 0;\n}\n#endif\nextern int sync_filesystem(struct super_block *);\nextern const struct file_operations def_blk_fops;\nextern const struct file_operations def_chr_fops;\nextern const struct file_operations bad_sock_fops;\n#ifdef CONFIG_BLOCK\nextern int ioctl_by_bdev(struct block_device *, unsigned, unsigned long);\nextern int blkdev_ioctl(struct block_device *, fmode_t, unsigned, unsigned long);\nextern long compat_blkdev_ioctl(struct file *, unsigned, unsigned long);\nextern int blkdev_get(struct block_device *bdev, fmode_t mode, void *holder);\nextern struct block_device *blkdev_get_by_path(const char *path, fmode_t mode,\n\t\t\t\t\t       void *holder);\nextern struct block_device *blkdev_get_by_dev(dev_t dev, fmode_t mode,\n\t\t\t\t\t      void *holder);\nextern void blkdev_put(struct block_device *bdev, fmode_t mode);\n#ifdef CONFIG_SYSFS\nextern int bd_link_disk_holder(struct block_device *bdev, struct gendisk *disk);\nextern void bd_unlink_disk_holder(struct block_device *bdev,\n\t\t\t\t  struct gendisk *disk);\n#else\nstatic inline int bd_link_disk_holder(struct block_device *bdev,\n\t\t\t\t      struct gendisk *disk)\n{\n\treturn 0;\n}\nstatic inline void bd_unlink_disk_holder(struct block_device *bdev,\n\t\t\t\t\t struct gendisk *disk)\n{\n}\n#endif\n#endif\n\n/* fs/char_dev.c */\n#define CHRDEV_MAJOR_HASH_SIZE\t255\nextern int alloc_chrdev_region(dev_t *, unsigned, unsigned, const char *);\nextern int register_chrdev_region(dev_t, unsigned, const char *);\nextern int __register_chrdev(unsigned int major, unsigned int baseminor,\n\t\t\t     unsigned int count, const char *name,\n\t\t\t     const struct file_operations *fops);\nextern void __unregister_chrdev(unsigned int major, unsigned int baseminor,\n\t\t\t\tunsigned int count, const char *name);\nextern void unregister_chrdev_region(dev_t, unsigned);\nextern void chrdev_show(struct seq_file *,off_t);\n\nstatic inline int register_chrdev(unsigned int major, const char *name,\n\t\t\t\t  const struct file_operations *fops)\n{\n\treturn __register_chrdev(major, 0, 256, name, fops);\n}\n\nstatic inline void unregister_chrdev(unsigned int major, const char *name)\n{\n\t__unregister_chrdev(major, 0, 256, name);\n}\n\n/* fs/block_dev.c */\n#define BDEVNAME_SIZE\t32\t/* Largest string for a blockdev identifier */\n#define BDEVT_SIZE\t10\t/* Largest string for MAJ:MIN for blkdev */\n\n#ifdef CONFIG_BLOCK\n#define BLKDEV_MAJOR_HASH_SIZE\t255\nextern const char *__bdevname(dev_t, char *buffer);\nextern const char *bdevname(struct block_device *bdev, char *buffer);\nextern struct block_device *lookup_bdev(const char *);\nextern void blkdev_show(struct seq_file *,off_t);\n\n#else\n#define BLKDEV_MAJOR_HASH_SIZE\t0\n#endif\n\nextern void init_special_inode(struct inode *, umode_t, dev_t);\n\n/* Invalid inode operations -- fs/bad_inode.c */\nextern void make_bad_inode(struct inode *);\nextern int is_bad_inode(struct inode *);\n\n#ifdef CONFIG_BLOCK\n/*\n * return READ, READA, or WRITE\n */\n#define bio_rw(bio)\t\t((bio)->bi_rw & (RW_MASK | RWA_MASK))\n\n/*\n * return data direction, READ or WRITE\n */\n#define bio_data_dir(bio)\t((bio)->bi_rw & 1)\n\nextern void check_disk_size_change(struct gendisk *disk,\n\t\t\t\t   struct block_device *bdev);\nextern int revalidate_disk(struct gendisk *);\nextern int check_disk_change(struct block_device *);\nextern int __invalidate_device(struct block_device *, bool);\nextern int invalidate_partition(struct gendisk *, int);\n#endif\nunsigned long invalidate_mapping_pages(struct address_space *mapping,\n\t\t\t\t\tpgoff_t start, pgoff_t end);\n\nstatic inline void invalidate_remote_inode(struct inode *inode)\n{\n\tif (S_ISREG(inode->i_mode) || S_ISDIR(inode->i_mode) ||\n\t    S_ISLNK(inode->i_mode))\n\t\tinvalidate_mapping_pages(inode->i_mapping, 0, -1);\n}\nextern int invalidate_inode_pages2(struct address_space *mapping);\nextern int invalidate_inode_pages2_range(struct address_space *mapping,\n\t\t\t\t\t pgoff_t start, pgoff_t end);\nextern int write_inode_now(struct inode *, int);\nextern int filemap_fdatawrite(struct address_space *);\nextern int filemap_flush(struct address_space *);\nextern int filemap_fdatawait(struct address_space *);\nextern int filemap_fdatawait_range(struct address_space *, loff_t lstart,\n\t\t\t\t   loff_t lend);\nextern int filemap_write_and_wait(struct address_space *mapping);\nextern int filemap_write_and_wait_range(struct address_space *mapping,\n\t\t\t\t        loff_t lstart, loff_t lend);\nextern int __filemap_fdatawrite_range(struct address_space *mapping,\n\t\t\t\tloff_t start, loff_t end, int sync_mode);\nextern int filemap_fdatawrite_range(struct address_space *mapping,\n\t\t\t\tloff_t start, loff_t end);\n\nextern int vfs_fsync_range(struct file *file, loff_t start, loff_t end,\n\t\t\t   int datasync);\nextern int vfs_fsync(struct file *file, int datasync);\nstatic inline int generic_write_sync(struct file *file, loff_t pos, loff_t count)\n{\n\tif (!(file->f_flags & O_DSYNC) && !IS_SYNC(file->f_mapping->host))\n\t\treturn 0;\n\treturn vfs_fsync_range(file, pos, pos + count - 1,\n\t\t\t       (file->f_flags & __O_SYNC) ? 0 : 1);\n}\nextern void emergency_sync(void);\nextern void emergency_remount(void);\n#ifdef CONFIG_BLOCK\nextern sector_t bmap(struct inode *, sector_t);\n#endif\nextern int notify_change(struct dentry *, struct iattr *, struct inode **);\nextern int inode_permission(struct inode *, int);\nextern int __inode_permission(struct inode *, int);\nextern int generic_permission(struct inode *, int);\nextern int __check_sticky(struct inode *dir, struct inode *inode);\n\nstatic inline bool execute_ok(struct inode *inode)\n{\n\treturn (inode->i_mode & S_IXUGO) || S_ISDIR(inode->i_mode);\n}\n\nstatic inline void file_start_write(struct file *file)\n{\n\tif (!S_ISREG(file_inode(file)->i_mode))\n\t\treturn;\n\t__sb_start_write(file_inode(file)->i_sb, SB_FREEZE_WRITE, true);\n}\n\nstatic inline bool file_start_write_trylock(struct file *file)\n{\n\tif (!S_ISREG(file_inode(file)->i_mode))\n\t\treturn true;\n\treturn __sb_start_write(file_inode(file)->i_sb, SB_FREEZE_WRITE, false);\n}\n\nstatic inline void file_end_write(struct file *file)\n{\n\tif (!S_ISREG(file_inode(file)->i_mode))\n\t\treturn;\n\t__sb_end_write(file_inode(file)->i_sb, SB_FREEZE_WRITE);\n}\n\n/*\n * get_write_access() gets write permission for a file.\n * put_write_access() releases this write permission.\n * This is used for regular files.\n * We cannot support write (and maybe mmap read-write shared) accesses and\n * MAP_DENYWRITE mmappings simultaneously. The i_writecount field of an inode\n * can have the following values:\n * 0: no writers, no VM_DENYWRITE mappings\n * < 0: (-i_writecount) vm_area_structs with VM_DENYWRITE set exist\n * > 0: (i_writecount) users are writing to the file.\n *\n * Normally we operate on that counter with atomic_{inc,dec} and it's safe\n * except for the cases where we don't hold i_writecount yet. Then we need to\n * use {get,deny}_write_access() - these functions check the sign and refuse\n * to do the change if sign is wrong.\n */\nstatic inline int get_write_access(struct inode *inode)\n{\n\treturn atomic_inc_unless_negative(&inode->i_writecount) ? 0 : -ETXTBSY;\n}\nstatic inline int deny_write_access(struct file *file)\n{\n\tstruct inode *inode = file_inode(file);\n\treturn atomic_dec_unless_positive(&inode->i_writecount) ? 0 : -ETXTBSY;\n}\nstatic inline void put_write_access(struct inode * inode)\n{\n\tatomic_dec(&inode->i_writecount);\n}\nstatic inline void allow_write_access(struct file *file)\n{\n\tif (file)\n\t\tatomic_inc(&file_inode(file)->i_writecount);\n}\nstatic inline bool inode_is_open_for_write(const struct inode *inode)\n{\n\treturn atomic_read(&inode->i_writecount) > 0;\n}\n\n#ifdef CONFIG_IMA\nstatic inline void i_readcount_dec(struct inode *inode)\n{\n\tBUG_ON(!atomic_read(&inode->i_readcount));\n\tatomic_dec(&inode->i_readcount);\n}\nstatic inline void i_readcount_inc(struct inode *inode)\n{\n\tatomic_inc(&inode->i_readcount);\n}\n#else\nstatic inline void i_readcount_dec(struct inode *inode)\n{\n\treturn;\n}\nstatic inline void i_readcount_inc(struct inode *inode)\n{\n\treturn;\n}\n#endif\nextern int do_pipe_flags(int *, int);\n\nextern int kernel_read(struct file *, loff_t, char *, unsigned long);\nextern ssize_t kernel_write(struct file *, const char *, size_t, loff_t);\nextern ssize_t __kernel_write(struct file *, const char *, size_t, loff_t *);\nextern struct file * open_exec(const char *);\n \n/* fs/dcache.c -- generic fs support functions */\nextern int is_subdir(struct dentry *, struct dentry *);\nextern int path_is_under(struct path *, struct path *);\n\n#include <linux/err.h>\n\n/* needed for stackable file system support */\nextern loff_t default_llseek(struct file *file, loff_t offset, int whence);\n\nextern loff_t vfs_llseek(struct file *file, loff_t offset, int whence);\n\nextern int inode_init_always(struct super_block *, struct inode *);\nextern void inode_init_once(struct inode *);\nextern void address_space_init_once(struct address_space *mapping);\nextern struct inode * igrab(struct inode *);\nextern ino_t iunique(struct super_block *, ino_t);\nextern int inode_needs_sync(struct inode *inode);\nextern int generic_delete_inode(struct inode *inode);\nstatic inline int generic_drop_inode(struct inode *inode)\n{\n\treturn !inode->i_nlink || inode_unhashed(inode);\n}\n\nextern struct inode *ilookup5_nowait(struct super_block *sb,\n\t\tunsigned long hashval, int (*test)(struct inode *, void *),\n\t\tvoid *data);\nextern struct inode *ilookup5(struct super_block *sb, unsigned long hashval,\n\t\tint (*test)(struct inode *, void *), void *data);\nextern struct inode *ilookup(struct super_block *sb, unsigned long ino);\n\nextern struct inode * iget5_locked(struct super_block *, unsigned long, int (*test)(struct inode *, void *), int (*set)(struct inode *, void *), void *);\nextern struct inode * iget_locked(struct super_block *, unsigned long);\nextern int insert_inode_locked4(struct inode *, unsigned long, int (*test)(struct inode *, void *), void *);\nextern int insert_inode_locked(struct inode *);\n#ifdef CONFIG_DEBUG_LOCK_ALLOC\nextern void lockdep_annotate_inode_mutex_key(struct inode *inode);\n#else\nstatic inline void lockdep_annotate_inode_mutex_key(struct inode *inode) { };\n#endif\nextern void unlock_new_inode(struct inode *);\nextern unsigned int get_next_ino(void);\n\nextern void __iget(struct inode * inode);\nextern void iget_failed(struct inode *);\nextern void clear_inode(struct inode *);\nextern void __destroy_inode(struct inode *);\nextern struct inode *new_inode_pseudo(struct super_block *sb);\nextern struct inode *new_inode(struct super_block *sb);\nextern void free_inode_nonrcu(struct inode *inode);\nextern int should_remove_suid(struct dentry *);\nextern int file_remove_suid(struct file *);\n\nextern void __insert_inode_hash(struct inode *, unsigned long hashval);\nstatic inline void insert_inode_hash(struct inode *inode)\n{\n\t__insert_inode_hash(inode, inode->i_ino);\n}\n\nextern void __remove_inode_hash(struct inode *);\nstatic inline void remove_inode_hash(struct inode *inode)\n{\n\tif (!inode_unhashed(inode))\n\t\t__remove_inode_hash(inode);\n}\n\nextern void inode_sb_list_add(struct inode *inode);\n\n#ifdef CONFIG_BLOCK\nextern void submit_bio(int, struct bio *);\nextern int bdev_read_only(struct block_device *);\n#endif\nextern int set_blocksize(struct block_device *, int);\nextern int sb_set_blocksize(struct super_block *, int);\nextern int sb_min_blocksize(struct super_block *, int);\n\nextern int generic_file_mmap(struct file *, struct vm_area_struct *);\nextern int generic_file_readonly_mmap(struct file *, struct vm_area_struct *);\nextern int generic_file_remap_pages(struct vm_area_struct *, unsigned long addr,\n\t\tunsigned long size, pgoff_t pgoff);\nint generic_write_checks(struct file *file, loff_t *pos, size_t *count, int isblk);\nextern ssize_t generic_file_read_iter(struct kiocb *, struct iov_iter *);\nextern ssize_t __generic_file_write_iter(struct kiocb *, struct iov_iter *);\nextern ssize_t generic_file_write_iter(struct kiocb *, struct iov_iter *);\nextern ssize_t generic_file_direct_write(struct kiocb *, struct iov_iter *, loff_t);\nextern ssize_t generic_perform_write(struct file *, struct iov_iter *, loff_t);\nextern ssize_t do_sync_read(struct file *filp, char __user *buf, size_t len, loff_t *ppos);\nextern ssize_t do_sync_write(struct file *filp, const char __user *buf, size_t len, loff_t *ppos);\nextern ssize_t new_sync_read(struct file *filp, char __user *buf, size_t len, loff_t *ppos);\nextern ssize_t new_sync_write(struct file *filp, const char __user *buf, size_t len, loff_t *ppos);\n\n/* fs/block_dev.c */\nextern ssize_t blkdev_write_iter(struct kiocb *iocb, struct iov_iter *from);\nextern int blkdev_fsync(struct file *filp, loff_t start, loff_t end,\n\t\t\tint datasync);\nextern void block_sync_page(struct page *page);\n\n/* fs/splice.c */\nextern ssize_t generic_file_splice_read(struct file *, loff_t *,\n\t\tstruct pipe_inode_info *, size_t, unsigned int);\nextern ssize_t default_file_splice_read(struct file *, loff_t *,\n\t\tstruct pipe_inode_info *, size_t, unsigned int);\nextern ssize_t iter_file_splice_write(struct pipe_inode_info *,\n\t\tstruct file *, loff_t *, size_t, unsigned int);\nextern ssize_t generic_splice_sendpage(struct pipe_inode_info *pipe,\n\t\tstruct file *out, loff_t *, size_t len, unsigned int flags);\nextern long do_splice_direct(struct file *in, loff_t *ppos, struct file *out,\n\t\tloff_t *opos, size_t len, unsigned int flags);\n\n\nextern void\nfile_ra_state_init(struct file_ra_state *ra, struct address_space *mapping);\nextern loff_t noop_llseek(struct file *file, loff_t offset, int whence);\nextern loff_t no_llseek(struct file *file, loff_t offset, int whence);\nextern loff_t vfs_setpos(struct file *file, loff_t offset, loff_t maxsize);\nextern loff_t generic_file_llseek(struct file *file, loff_t offset, int whence);\nextern loff_t generic_file_llseek_size(struct file *file, loff_t offset,\n\t\tint whence, loff_t maxsize, loff_t eof);\nextern loff_t fixed_size_llseek(struct file *file, loff_t offset,\n\t\tint whence, loff_t size);\nextern int generic_file_open(struct inode * inode, struct file * filp);\nextern int nonseekable_open(struct inode * inode, struct file * filp);\n\n#ifdef CONFIG_FS_XIP\nextern ssize_t xip_file_read(struct file *filp, char __user *buf, size_t len,\n\t\t\t     loff_t *ppos);\nextern int xip_file_mmap(struct file * file, struct vm_area_struct * vma);\nextern ssize_t xip_file_write(struct file *filp, const char __user *buf,\n\t\t\t      size_t len, loff_t *ppos);\nextern int xip_truncate_page(struct address_space *mapping, loff_t from);\n#else\nstatic inline int xip_truncate_page(struct address_space *mapping, loff_t from)\n{\n\treturn 0;\n}\n#endif\n\n#ifdef CONFIG_BLOCK\ntypedef void (dio_submit_t)(int rw, struct bio *bio, struct inode *inode,\n\t\t\t    loff_t file_offset);\n\nenum {\n\t/* need locking between buffered and direct access */\n\tDIO_LOCKING\t= 0x01,\n\n\t/* filesystem does not support filling holes */\n\tDIO_SKIP_HOLES\t= 0x02,\n\n\t/* filesystem can handle aio writes beyond i_size */\n\tDIO_ASYNC_EXTEND = 0x04,\n};\n\nvoid dio_end_io(struct bio *bio, int error);\n\nssize_t __blockdev_direct_IO(int rw, struct kiocb *iocb, struct inode *inode,\n\tstruct block_device *bdev, struct iov_iter *iter, loff_t offset,\n\tget_block_t get_block, dio_iodone_t end_io,\n\tdio_submit_t submit_io,\tint flags);\n\nstatic inline ssize_t blockdev_direct_IO(int rw, struct kiocb *iocb,\n\t\tstruct inode *inode, struct iov_iter *iter, loff_t offset,\n\t\tget_block_t get_block)\n{\n\treturn __blockdev_direct_IO(rw, iocb, inode, inode->i_sb->s_bdev, iter,\n\t\t\t\t    offset, get_block, NULL, NULL,\n\t\t\t\t    DIO_LOCKING | DIO_SKIP_HOLES);\n}\n#endif\n\nvoid inode_dio_wait(struct inode *inode);\nvoid inode_dio_done(struct inode *inode);\n\nextern void inode_set_flags(struct inode *inode, unsigned int flags,\n\t\t\t    unsigned int mask);\n\nextern const struct file_operations generic_ro_fops;\n\n#define special_file(m) (S_ISCHR(m)||S_ISBLK(m)||S_ISFIFO(m)||S_ISSOCK(m))\n\nextern int readlink_copy(char __user *, int, const char *);\nextern int page_readlink(struct dentry *, char __user *, int);\nextern void *page_follow_link_light(struct dentry *, struct nameidata *);\nextern void page_put_link(struct dentry *, struct nameidata *, void *);\nextern int __page_symlink(struct inode *inode, const char *symname, int len,\n\t\tint nofs);\nextern int page_symlink(struct inode *inode, const char *symname, int len);\nextern const struct inode_operations page_symlink_inode_operations;\nextern void kfree_put_link(struct dentry *, struct nameidata *, void *);\nextern int generic_readlink(struct dentry *, char __user *, int);\nextern void generic_fillattr(struct inode *, struct kstat *);\nint vfs_getattr_nosec(struct path *path, struct kstat *stat);\nextern int vfs_getattr(struct path *, struct kstat *);\nvoid __inode_add_bytes(struct inode *inode, loff_t bytes);\nvoid inode_add_bytes(struct inode *inode, loff_t bytes);\nvoid __inode_sub_bytes(struct inode *inode, loff_t bytes);\nvoid inode_sub_bytes(struct inode *inode, loff_t bytes);\nloff_t inode_get_bytes(struct inode *inode);\nvoid inode_set_bytes(struct inode *inode, loff_t bytes);\n\nextern int vfs_readdir(struct file *, filldir_t, void *);\nextern int iterate_dir(struct file *, struct dir_context *);\n\nextern int vfs_stat(const char __user *, struct kstat *);\nextern int vfs_lstat(const char __user *, struct kstat *);\nextern int vfs_fstat(unsigned int, struct kstat *);\nextern int vfs_fstatat(int , const char __user *, struct kstat *, int);\n\nextern int do_vfs_ioctl(struct file *filp, unsigned int fd, unsigned int cmd,\n\t\t    unsigned long arg);\nextern int __generic_block_fiemap(struct inode *inode,\n\t\t\t\t  struct fiemap_extent_info *fieinfo,\n\t\t\t\t  loff_t start, loff_t len,\n\t\t\t\t  get_block_t *get_block);\nextern int generic_block_fiemap(struct inode *inode,\n\t\t\t\tstruct fiemap_extent_info *fieinfo, u64 start,\n\t\t\t\tu64 len, get_block_t *get_block);\n\nextern void get_filesystem(struct file_system_type *fs);\nextern void put_filesystem(struct file_system_type *fs);\nextern struct file_system_type *get_fs_type(const char *name);\nextern struct super_block *get_super(struct block_device *);\nextern struct super_block *get_super_thawed(struct block_device *);\nextern struct super_block *get_active_super(struct block_device *bdev);\nextern void drop_super(struct super_block *sb);\nextern void iterate_supers(void (*)(struct super_block *, void *), void *);\nextern void iterate_supers_type(struct file_system_type *,\n\t\t\t        void (*)(struct super_block *, void *), void *);\n\nextern int dcache_dir_open(struct inode *, struct file *);\nextern int dcache_dir_close(struct inode *, struct file *);\nextern loff_t dcache_dir_lseek(struct file *, loff_t, int);\nextern int dcache_readdir(struct file *, struct dir_context *);\nextern int simple_setattr(struct dentry *, struct iattr *);\nextern int simple_getattr(struct vfsmount *, struct dentry *, struct kstat *);\nextern int simple_statfs(struct dentry *, struct kstatfs *);\nextern int simple_open(struct inode *inode, struct file *file);\nextern int simple_link(struct dentry *, struct inode *, struct dentry *);\nextern int simple_unlink(struct inode *, struct dentry *);\nextern int simple_rmdir(struct inode *, struct dentry *);\nextern int simple_rename(struct inode *, struct dentry *, struct inode *, struct dentry *);\nextern int noop_fsync(struct file *, loff_t, loff_t, int);\nextern int simple_empty(struct dentry *);\nextern int simple_readpage(struct file *file, struct page *page);\nextern int simple_write_begin(struct file *file, struct address_space *mapping,\n\t\t\tloff_t pos, unsigned len, unsigned flags,\n\t\t\tstruct page **pagep, void **fsdata);\nextern int simple_write_end(struct file *file, struct address_space *mapping,\n\t\t\tloff_t pos, unsigned len, unsigned copied,\n\t\t\tstruct page *page, void *fsdata);\nextern int always_delete_dentry(const struct dentry *);\nextern struct inode *alloc_anon_inode(struct super_block *);\nextern int simple_nosetlease(struct file *, long, struct file_lock **, void **);\nextern const struct dentry_operations simple_dentry_operations;\n\nextern struct dentry *simple_lookup(struct inode *, struct dentry *, unsigned int flags);\nextern ssize_t generic_read_dir(struct file *, char __user *, size_t, loff_t *);\nextern const struct file_operations simple_dir_operations;\nextern const struct inode_operations simple_dir_inode_operations;\nstruct tree_descr { char *name; const struct file_operations *ops; int mode; };\nstruct dentry *d_alloc_name(struct dentry *, const char *);\nextern int simple_fill_super(struct super_block *, unsigned long, struct tree_descr *);\nextern int simple_pin_fs(struct file_system_type *, struct vfsmount **mount, int *count);\nextern void simple_release_fs(struct vfsmount **mount, int *count);\n\nextern ssize_t simple_read_from_buffer(void __user *to, size_t count,\n\t\t\tloff_t *ppos, const void *from, size_t available);\nextern ssize_t simple_write_to_buffer(void *to, size_t available, loff_t *ppos,\n\t\tconst void __user *from, size_t count);\n\nextern int __generic_file_fsync(struct file *, loff_t, loff_t, int);\nextern int generic_file_fsync(struct file *, loff_t, loff_t, int);\n\nextern int generic_check_addressable(unsigned, u64);\n\n#ifdef CONFIG_MIGRATION\nextern int buffer_migrate_page(struct address_space *,\n\t\t\t\tstruct page *, struct page *,\n\t\t\t\tenum migrate_mode);\n#else\n#define buffer_migrate_page NULL\n#endif\n\nextern int inode_change_ok(const struct inode *, struct iattr *);\nextern int inode_newsize_ok(const struct inode *, loff_t offset);\nextern void setattr_copy(struct inode *inode, const struct iattr *attr);\n\nextern int file_update_time(struct file *file);\n\nextern int generic_show_options(struct seq_file *m, struct dentry *root);\nextern void save_mount_options(struct super_block *sb, char *options);\nextern void replace_mount_options(struct super_block *sb, char *options);\n\nstatic inline ino_t parent_ino(struct dentry *dentry)\n{\n\tino_t res;\n\n\t/*\n\t * Don't strictly need d_lock here? If the parent ino could change\n\t * then surely we'd have a deeper race in the caller?\n\t */\n\tspin_lock(&dentry->d_lock);\n\tres = dentry->d_parent->d_inode->i_ino;\n\tspin_unlock(&dentry->d_lock);\n\treturn res;\n}\n\n/* Transaction based IO helpers */\n\n/*\n * An argresp is stored in an allocated page and holds the\n * size of the argument or response, along with its content\n */\nstruct simple_transaction_argresp {\n\tssize_t size;\n\tchar data[0];\n};\n\n#define SIMPLE_TRANSACTION_LIMIT (PAGE_SIZE - sizeof(struct simple_transaction_argresp))\n\nchar *simple_transaction_get(struct file *file, const char __user *buf,\n\t\t\t\tsize_t size);\nssize_t simple_transaction_read(struct file *file, char __user *buf,\n\t\t\t\tsize_t size, loff_t *pos);\nint simple_transaction_release(struct inode *inode, struct file *file);\n\nvoid simple_transaction_set(struct file *file, size_t n);\n\n/*\n * simple attribute files\n *\n * These attributes behave similar to those in sysfs:\n *\n * Writing to an attribute immediately sets a value, an open file can be\n * written to multiple times.\n *\n * Reading from an attribute creates a buffer from the value that might get\n * read with multiple read calls. When the attribute has been read\n * completely, no further read calls are possible until the file is opened\n * again.\n *\n * All attributes contain a text representation of a numeric value\n * that are accessed with the get() and set() functions.\n */\n#define DEFINE_SIMPLE_ATTRIBUTE(__fops, __get, __set, __fmt)\t\t\\\nstatic int __fops ## _open(struct inode *inode, struct file *file)\t\\\n{\t\t\t\t\t\t\t\t\t\\\n\t__simple_attr_check_format(__fmt, 0ull);\t\t\t\\\n\treturn simple_attr_open(inode, file, __get, __set, __fmt);\t\\\n}\t\t\t\t\t\t\t\t\t\\\nstatic const struct file_operations __fops = {\t\t\t\t\\\n\t.owner\t = THIS_MODULE,\t\t\t\t\t\t\\\n\t.open\t = __fops ## _open,\t\t\t\t\t\\\n\t.release = simple_attr_release,\t\t\t\t\t\\\n\t.read\t = simple_attr_read,\t\t\t\t\t\\\n\t.write\t = simple_attr_write,\t\t\t\t\t\\\n\t.llseek\t = generic_file_llseek,\t\t\t\t\t\\\n}\n\nstatic inline __printf(1, 2)\nvoid __simple_attr_check_format(const char *fmt, ...)\n{\n\t/* don't do anything, just let the compiler check the arguments; */\n}\n\nint simple_attr_open(struct inode *inode, struct file *file,\n\t\t     int (*get)(void *, u64 *), int (*set)(void *, u64),\n\t\t     const char *fmt);\nint simple_attr_release(struct inode *inode, struct file *file);\nssize_t simple_attr_read(struct file *file, char __user *buf,\n\t\t\t size_t len, loff_t *ppos);\nssize_t simple_attr_write(struct file *file, const char __user *buf,\n\t\t\t  size_t len, loff_t *ppos);\n\nstruct ctl_table;\nint proc_nr_files(struct ctl_table *table, int write,\n\t\t  void __user *buffer, size_t *lenp, loff_t *ppos);\nint proc_nr_dentry(struct ctl_table *table, int write,\n\t\t  void __user *buffer, size_t *lenp, loff_t *ppos);\nint proc_nr_inodes(struct ctl_table *table, int write,\n\t\t   void __user *buffer, size_t *lenp, loff_t *ppos);\nint __init get_filesystem_list(char *buf);\n\n#define __FMODE_EXEC\t\t((__force int) FMODE_EXEC)\n#define __FMODE_NONOTIFY\t((__force int) FMODE_NONOTIFY)\n\n#define ACC_MODE(x) (\"\\004\\002\\006\\006\"[(x)&O_ACCMODE])\n#define OPEN_FMODE(flag) ((__force fmode_t)(((flag + 1) & O_ACCMODE) | \\\n\t\t\t\t\t    (flag & __FMODE_NONOTIFY)))\n\nstatic inline int is_sxid(umode_t mode)\n{\n\treturn (mode & S_ISUID) || ((mode & S_ISGID) && (mode & S_IXGRP));\n}\n\nstatic inline int check_sticky(struct inode *dir, struct inode *inode)\n{\n\tif (!(dir->i_mode & S_ISVTX))\n\t\treturn 0;\n\n\treturn __check_sticky(dir, inode);\n}\n\nstatic inline void inode_has_no_xattr(struct inode *inode)\n{\n\tif (!is_sxid(inode->i_mode) && (inode->i_sb->s_flags & MS_NOSEC))\n\t\tinode->i_flags |= S_NOSEC;\n}\n\nstatic inline bool dir_emit(struct dir_context *ctx,\n\t\t\t    const char *name, int namelen,\n\t\t\t    u64 ino, unsigned type)\n{\n\treturn ctx->actor(ctx, name, namelen, ctx->pos, ino, type) == 0;\n}\nstatic inline bool dir_emit_dot(struct file *file, struct dir_context *ctx)\n{\n\treturn ctx->actor(ctx, \".\", 1, ctx->pos,\n\t\t\t  file->f_path.dentry->d_inode->i_ino, DT_DIR) == 0;\n}\nstatic inline bool dir_emit_dotdot(struct file *file, struct dir_context *ctx)\n{\n\treturn ctx->actor(ctx, \"..\", 2, ctx->pos,\n\t\t\t  parent_ino(file->f_path.dentry), DT_DIR) == 0;\n}\nstatic inline bool dir_emit_dots(struct file *file, struct dir_context *ctx)\n{\n\tif (ctx->pos == 0) {\n\t\tif (!dir_emit_dot(file, ctx))\n\t\t\treturn false;\n\t\tctx->pos = 1;\n\t}\n\tif (ctx->pos == 1) {\n\t\tif (!dir_emit_dotdot(file, ctx))\n\t\t\treturn false;\n\t\tctx->pos = 2;\n\t}\n\treturn true;\n}\nstatic inline bool dir_relax(struct inode *inode)\n{\n\tmutex_unlock(&inode->i_mutex);\n\tmutex_lock(&inode->i_mutex);\n\treturn !IS_DEADDIR(inode);\n}\n\n#endif /* _LINUX_FS_H */\n"], "filenames": ["fs/ecryptfs/main.c", "fs/overlayfs/super.c", "include/linux/fs.h"], "buggy_code_start_loc": [568, 678, 263], "buggy_code_end_loc": [568, 678, 1275], "fixing_code_start_loc": [569, 679, 264], "fixing_code_end_loc": [576, 688, 1287], "type": "CWE-264", "message": "The eCryptfs subsystem in the Linux kernel before 3.18 allows local users to gain privileges via a large filesystem stack that includes an overlayfs layer, related to fs/ecryptfs/main.c and fs/overlayfs/super.c.", "other": {"cve": {"id": "CVE-2014-9922", "sourceIdentifier": "security@android.com", "published": "2017-04-04T05:59:00.203", "lastModified": "2017-07-11T01:33:21.377", "vulnStatus": "Modified", "descriptions": [{"lang": "en", "value": "The eCryptfs subsystem in the Linux kernel before 3.18 allows local users to gain privileges via a large filesystem stack that includes an overlayfs layer, related to fs/ecryptfs/main.c and fs/overlayfs/super.c."}, {"lang": "es", "value": "El subsistema eCryptfs en el kernel de Linux en versiones anteriores a 3.18 permite a los usuarios locales obtener privilegios a trav\u00e9s de una pila de archivos grande que incluye una capa de superposici\u00f3n, relacionada con fs/ecryptfs/main.c y fs/overlayfs/super.c."}], "metrics": {"cvssMetricV30": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.0", "vectorString": "CVSS:3.0/AV:L/AC:L/PR:N/UI:R/S:U/C:H/I:H/A:H", "attackVector": "LOCAL", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "REQUIRED", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "HIGH", "availabilityImpact": "HIGH", "baseScore": 7.8, "baseSeverity": "HIGH"}, "exploitabilityScore": 1.8, "impactScore": 5.9}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:N/AC:M/Au:N/C:C/I:C/A:C", "accessVector": "NETWORK", "accessComplexity": "MEDIUM", "authentication": "NONE", "confidentialityImpact": "COMPLETE", "integrityImpact": "COMPLETE", "availabilityImpact": "COMPLETE", "baseScore": 9.3}, "baseSeverity": "HIGH", "exploitabilityScore": 8.6, "impactScore": 10.0, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": true}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-264"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionEndIncluding": "3.17.8", "matchCriteriaId": "D096AE24-5BB5-4ED2-8D2B-DC2AE8012E40"}]}]}, {"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:google:android:*:*:*:*:*:*:*:*", "versionEndIncluding": "7.1.1", "matchCriteriaId": "0F11609D-D1B4-4DD6-8CC7-A224344E1E67"}]}]}], "references": [{"url": "http://git.kernel.org/cgit/linux/kernel/git/torvalds/linux.git/commit/?id=69c433ed2ecd2d3264efd7afec4439524b319121", "source": "security@android.com", "tags": ["Issue Tracking", "Patch", "Third Party Advisory"]}, {"url": "http://source.android.com/security/bulletin/2017-04-01.html", "source": "security@android.com", "tags": ["Patch", "Third Party Advisory"]}, {"url": "http://www.securityfocus.com/bid/97354", "source": "security@android.com", "tags": ["Third Party Advisory", "VDB Entry"]}, {"url": "http://www.securitytracker.com/id/1038201", "source": "security@android.com"}, {"url": "https://github.com/torvalds/linux/commit/69c433ed2ecd2d3264efd7afec4439524b319121", "source": "security@android.com", "tags": ["Issue Tracking", "Patch", "Third Party Advisory"]}]}, "github_commit_url": "https://github.com/torvalds/linux/commit/69c433ed2ecd2d3264efd7afec4439524b319121"}}
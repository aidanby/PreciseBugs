{"buggy_code": ["/*\n * MinIO Cloud Storage, (C) 2015-2018 MinIO, Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\npackage cmd\n\nimport (\n\t\"bytes\"\n\t\"context\"\n\t\"crypto/subtle\"\n\t\"encoding/base64\"\n\t\"encoding/hex\"\n\t\"errors\"\n\t\"io\"\n\t\"io/ioutil\"\n\t\"net/http\"\n\t\"strconv\"\n\t\"strings\"\n\t\"time\"\n\n\txhttp \"github.com/minio/minio/cmd/http\"\n\txjwt \"github.com/minio/minio/cmd/jwt\"\n\t\"github.com/minio/minio/cmd/logger\"\n\t\"github.com/minio/minio/pkg/auth\"\n\tobjectlock \"github.com/minio/minio/pkg/bucket/object/lock\"\n\t\"github.com/minio/minio/pkg/bucket/policy\"\n\t\"github.com/minio/minio/pkg/hash\"\n\tiampolicy \"github.com/minio/minio/pkg/iam/policy\"\n)\n\n// Verify if request has JWT.\nfunc isRequestJWT(r *http.Request) bool {\n\treturn strings.HasPrefix(r.Header.Get(xhttp.Authorization), jwtAlgorithm)\n}\n\n// Verify if request has AWS Signature Version '4'.\nfunc isRequestSignatureV4(r *http.Request) bool {\n\treturn strings.HasPrefix(r.Header.Get(xhttp.Authorization), signV4Algorithm)\n}\n\n// Verify if request has AWS Signature Version '2'.\nfunc isRequestSignatureV2(r *http.Request) bool {\n\treturn (!strings.HasPrefix(r.Header.Get(xhttp.Authorization), signV4Algorithm) &&\n\t\tstrings.HasPrefix(r.Header.Get(xhttp.Authorization), signV2Algorithm))\n}\n\n// Verify if request has AWS PreSign Version '4'.\nfunc isRequestPresignedSignatureV4(r *http.Request) bool {\n\t_, ok := r.URL.Query()[xhttp.AmzCredential]\n\treturn ok\n}\n\n// Verify request has AWS PreSign Version '2'.\nfunc isRequestPresignedSignatureV2(r *http.Request) bool {\n\t_, ok := r.URL.Query()[xhttp.AmzAccessKeyID]\n\treturn ok\n}\n\n// Verify if request has AWS Post policy Signature Version '4'.\nfunc isRequestPostPolicySignatureV4(r *http.Request) bool {\n\treturn strings.Contains(r.Header.Get(xhttp.ContentType), \"multipart/form-data\") &&\n\t\tr.Method == http.MethodPost\n}\n\n// Verify if the request has AWS Streaming Signature Version '4'. This is only valid for 'PUT' operation.\nfunc isRequestSignStreamingV4(r *http.Request) bool {\n\treturn r.Header.Get(xhttp.AmzContentSha256) == streamingContentSHA256 &&\n\t\tr.Method == http.MethodPut\n}\n\n// Authorization type.\ntype authType int\n\n// List of all supported auth types.\nconst (\n\tauthTypeUnknown authType = iota\n\tauthTypeAnonymous\n\tauthTypePresigned\n\tauthTypePresignedV2\n\tauthTypePostPolicy\n\tauthTypeStreamingSigned\n\tauthTypeSigned\n\tauthTypeSignedV2\n\tauthTypeJWT\n\tauthTypeSTS\n)\n\n// Get request authentication type.\nfunc getRequestAuthType(r *http.Request) authType {\n\tif isRequestSignatureV2(r) {\n\t\treturn authTypeSignedV2\n\t} else if isRequestPresignedSignatureV2(r) {\n\t\treturn authTypePresignedV2\n\t} else if isRequestSignStreamingV4(r) {\n\t\treturn authTypeStreamingSigned\n\t} else if isRequestSignatureV4(r) {\n\t\treturn authTypeSigned\n\t} else if isRequestPresignedSignatureV4(r) {\n\t\treturn authTypePresigned\n\t} else if isRequestJWT(r) {\n\t\treturn authTypeJWT\n\t} else if isRequestPostPolicySignatureV4(r) {\n\t\treturn authTypePostPolicy\n\t} else if _, ok := r.URL.Query()[xhttp.Action]; ok {\n\t\treturn authTypeSTS\n\t} else if _, ok := r.Header[xhttp.Authorization]; !ok {\n\t\treturn authTypeAnonymous\n\t}\n\treturn authTypeUnknown\n}\n\nfunc validateAdminSignature(ctx context.Context, r *http.Request, region string) (auth.Credentials, map[string]interface{}, bool, APIErrorCode) {\n\tvar cred auth.Credentials\n\tvar owner bool\n\ts3Err := ErrAccessDenied\n\tif _, ok := r.Header[xhttp.AmzContentSha256]; ok &&\n\t\tgetRequestAuthType(r) == authTypeSigned && !skipContentSha256Cksum(r) {\n\t\t// We only support admin credentials to access admin APIs.\n\t\tcred, owner, s3Err = getReqAccessKeyV4(r, region, serviceS3)\n\t\tif s3Err != ErrNone {\n\t\t\treturn cred, nil, owner, s3Err\n\t\t}\n\n\t\t// we only support V4 (no presign) with auth body\n\t\ts3Err = isReqAuthenticated(ctx, r, region, serviceS3)\n\t}\n\tif s3Err != ErrNone {\n\t\treqInfo := (&logger.ReqInfo{}).AppendTags(\"requestHeaders\", dumpRequest(r))\n\t\tctx := logger.SetReqInfo(ctx, reqInfo)\n\t\tlogger.LogIf(ctx, errors.New(getAPIError(s3Err).Description), logger.Application)\n\t\treturn cred, nil, owner, s3Err\n\t}\n\n\tclaims, s3Err := checkClaimsFromToken(r, cred)\n\tif s3Err != ErrNone {\n\t\treturn cred, nil, owner, s3Err\n\t}\n\n\treturn cred, claims, owner, ErrNone\n}\n\n// checkAdminRequestAuth checks for authentication and authorization for the incoming\n// request. It only accepts V2 and V4 requests. Presigned, JWT and anonymous requests\n// are automatically rejected.\nfunc checkAdminRequestAuth(ctx context.Context, r *http.Request, action iampolicy.AdminAction, region string) (auth.Credentials, APIErrorCode) {\n\tcred, claims, owner, s3Err := validateAdminSignature(ctx, r, region)\n\tif s3Err != ErrNone {\n\t\treturn cred, s3Err\n\t}\n\tif globalIAMSys.IsAllowed(iampolicy.Args{\n\t\tAccountName:     cred.AccessKey,\n\t\tAction:          iampolicy.Action(action),\n\t\tConditionValues: getConditionValues(r, \"\", cred.AccessKey, claims),\n\t\tIsOwner:         owner,\n\t\tClaims:          claims,\n\t}) {\n\t\t// Request is allowed return the appropriate access key.\n\t\treturn cred, ErrNone\n\t}\n\n\treturn cred, ErrAccessDenied\n}\n\n// Fetch the security token set by the client.\nfunc getSessionToken(r *http.Request) (token string) {\n\ttoken = r.Header.Get(xhttp.AmzSecurityToken)\n\tif token != \"\" {\n\t\treturn token\n\t}\n\treturn r.URL.Query().Get(xhttp.AmzSecurityToken)\n}\n\n// Fetch claims in the security token returned by the client, doesn't return\n// errors - upon errors the returned claims map will be empty.\nfunc mustGetClaimsFromToken(r *http.Request) map[string]interface{} {\n\tclaims, _ := getClaimsFromToken(r, getSessionToken(r))\n\treturn claims\n}\n\n// Fetch claims in the security token returned by the client.\nfunc getClaimsFromToken(r *http.Request, token string) (map[string]interface{}, error) {\n\tclaims := xjwt.NewMapClaims()\n\tif token == \"\" {\n\t\treturn claims.Map(), nil\n\t}\n\n\tstsTokenCallback := func(claims *xjwt.MapClaims) ([]byte, error) {\n\t\t// JWT token for x-amz-security-token is signed with admin\n\t\t// secret key, temporary credentials become invalid if\n\t\t// server admin credentials change. This is done to ensure\n\t\t// that clients cannot decode the token using the temp\n\t\t// secret keys and generate an entirely new claim by essentially\n\t\t// hijacking the policies. We need to make sure that this is\n\t\t// based an admin credential such that token cannot be decoded\n\t\t// on the client side and is treated like an opaque value.\n\t\treturn []byte(globalActiveCred.SecretKey), nil\n\t}\n\n\tif err := xjwt.ParseWithClaims(token, claims, stsTokenCallback); err != nil {\n\t\treturn nil, errAuthentication\n\t}\n\n\tif globalPolicyOPA == nil {\n\t\t// If OPA is not set and if ldap claim key is set, allow the claim.\n\t\tif _, ok := claims.MapClaims[ldapUser]; ok {\n\t\t\treturn claims.Map(), nil\n\t\t}\n\n\t\t// If OPA is not set, session token should\n\t\t// have a policy and its mandatory, reject\n\t\t// requests without policy claim.\n\t\t_, pokOpenID := claims.MapClaims[iamPolicyClaimNameOpenID()]\n\t\t_, pokSA := claims.MapClaims[iamPolicyClaimNameSA()]\n\t\tif !pokOpenID && !pokSA {\n\t\t\treturn nil, errAuthentication\n\t\t}\n\n\t\tsp, spok := claims.Lookup(iampolicy.SessionPolicyName)\n\t\tif !spok {\n\t\t\treturn claims.Map(), nil\n\t\t}\n\t\t// Looks like subpolicy is set and is a string, if set then its\n\t\t// base64 encoded, decode it. Decoding fails reject such requests.\n\t\tspBytes, err := base64.StdEncoding.DecodeString(sp)\n\t\tif err != nil {\n\t\t\t// Base64 decoding fails, we should log to indicate\n\t\t\t// something is malforming the request sent by client.\n\t\t\tlogger.LogIf(r.Context(), err, logger.Application)\n\t\t\treturn nil, errAuthentication\n\t\t}\n\t\tclaims.MapClaims[iampolicy.SessionPolicyName] = string(spBytes)\n\t}\n\n\treturn claims.Map(), nil\n}\n\n// Fetch claims in the security token returned by the client and validate the token.\nfunc checkClaimsFromToken(r *http.Request, cred auth.Credentials) (map[string]interface{}, APIErrorCode) {\n\ttoken := getSessionToken(r)\n\tif token != \"\" && cred.AccessKey == \"\" {\n\t\treturn nil, ErrNoAccessKey\n\t}\n\tif cred.IsServiceAccount() && token == \"\" {\n\t\ttoken = cred.SessionToken\n\t}\n\tif subtle.ConstantTimeCompare([]byte(token), []byte(cred.SessionToken)) != 1 {\n\t\treturn nil, ErrInvalidToken\n\t}\n\tclaims, err := getClaimsFromToken(r, token)\n\tif err != nil {\n\t\treturn nil, toAPIErrorCode(r.Context(), err)\n\t}\n\treturn claims, ErrNone\n}\n\n// Check request auth type verifies the incoming http request\n// - validates the request signature\n// - validates the policy action if anonymous tests bucket policies if any,\n//   for authenticated requests validates IAM policies.\n// returns APIErrorCode if any to be replied to the client.\nfunc checkRequestAuthType(ctx context.Context, r *http.Request, action policy.Action, bucketName, objectName string) (s3Err APIErrorCode) {\n\t_, _, s3Err = checkRequestAuthTypeToAccessKey(ctx, r, action, bucketName, objectName)\n\treturn s3Err\n}\n\n// Check request auth type verifies the incoming http request\n// - validates the request signature\n// - validates the policy action if anonymous tests bucket policies if any,\n//   for authenticated requests validates IAM policies.\n// returns APIErrorCode if any to be replied to the client.\n// Additionally returns the accessKey used in the request, and if this request is by an admin.\nfunc checkRequestAuthTypeToAccessKey(ctx context.Context, r *http.Request, action policy.Action, bucketName, objectName string) (accessKey string, owner bool, s3Err APIErrorCode) {\n\tvar cred auth.Credentials\n\tswitch getRequestAuthType(r) {\n\tcase authTypeUnknown, authTypeStreamingSigned:\n\t\treturn accessKey, owner, ErrSignatureVersionNotSupported\n\tcase authTypePresignedV2, authTypeSignedV2:\n\t\tif s3Err = isReqAuthenticatedV2(r); s3Err != ErrNone {\n\t\t\treturn accessKey, owner, s3Err\n\t\t}\n\t\tcred, owner, s3Err = getReqAccessKeyV2(r)\n\tcase authTypeSigned, authTypePresigned:\n\t\tregion := globalServerRegion\n\t\tswitch action {\n\t\tcase policy.GetBucketLocationAction, policy.ListAllMyBucketsAction:\n\t\t\tregion = \"\"\n\t\t}\n\t\tif s3Err = isReqAuthenticated(ctx, r, region, serviceS3); s3Err != ErrNone {\n\t\t\treturn accessKey, owner, s3Err\n\t\t}\n\t\tcred, owner, s3Err = getReqAccessKeyV4(r, region, serviceS3)\n\t}\n\tif s3Err != ErrNone {\n\t\treturn accessKey, owner, s3Err\n\t}\n\n\tvar claims map[string]interface{}\n\tclaims, s3Err = checkClaimsFromToken(r, cred)\n\tif s3Err != ErrNone {\n\t\treturn accessKey, owner, s3Err\n\t}\n\n\t// LocationConstraint is valid only for CreateBucketAction.\n\tvar locationConstraint string\n\tif action == policy.CreateBucketAction {\n\t\t// To extract region from XML in request body, get copy of request body.\n\t\tpayload, err := ioutil.ReadAll(io.LimitReader(r.Body, maxLocationConstraintSize))\n\t\tif err != nil {\n\t\t\tlogger.LogIf(ctx, err, logger.Application)\n\t\t\treturn accessKey, owner, ErrMalformedXML\n\t\t}\n\n\t\t// Populate payload to extract location constraint.\n\t\tr.Body = ioutil.NopCloser(bytes.NewReader(payload))\n\n\t\tvar s3Error APIErrorCode\n\t\tlocationConstraint, s3Error = parseLocationConstraint(r)\n\t\tif s3Error != ErrNone {\n\t\t\treturn accessKey, owner, s3Error\n\t\t}\n\n\t\t// Populate payload again to handle it in HTTP handler.\n\t\tr.Body = ioutil.NopCloser(bytes.NewReader(payload))\n\t}\n\tif cred.AccessKey != \"\" {\n\t\tlogger.GetReqInfo(ctx).AccessKey = cred.AccessKey\n\t}\n\n\tif action != policy.ListAllMyBucketsAction && cred.AccessKey == \"\" {\n\t\t// Anonymous checks are not meant for ListBuckets action\n\t\tif globalPolicySys.IsAllowed(policy.Args{\n\t\t\tAccountName:     cred.AccessKey,\n\t\t\tAction:          action,\n\t\t\tBucketName:      bucketName,\n\t\t\tConditionValues: getConditionValues(r, locationConstraint, \"\", nil),\n\t\t\tIsOwner:         false,\n\t\t\tObjectName:      objectName,\n\t\t}) {\n\t\t\t// Request is allowed return the appropriate access key.\n\t\t\treturn cred.AccessKey, owner, ErrNone\n\t\t}\n\n\t\tif action == policy.ListBucketVersionsAction {\n\t\t\t// In AWS S3 s3:ListBucket permission is same as s3:ListBucketVersions permission\n\t\t\t// verify as a fallback.\n\t\t\tif globalPolicySys.IsAllowed(policy.Args{\n\t\t\t\tAccountName:     cred.AccessKey,\n\t\t\t\tAction:          policy.ListBucketAction,\n\t\t\t\tBucketName:      bucketName,\n\t\t\t\tConditionValues: getConditionValues(r, locationConstraint, \"\", nil),\n\t\t\t\tIsOwner:         false,\n\t\t\t\tObjectName:      objectName,\n\t\t\t}) {\n\t\t\t\t// Request is allowed return the appropriate access key.\n\t\t\t\treturn cred.AccessKey, owner, ErrNone\n\t\t\t}\n\t\t}\n\n\t\treturn cred.AccessKey, owner, ErrAccessDenied\n\t}\n\n\tif globalIAMSys.IsAllowed(iampolicy.Args{\n\t\tAccountName:     cred.AccessKey,\n\t\tAction:          iampolicy.Action(action),\n\t\tBucketName:      bucketName,\n\t\tConditionValues: getConditionValues(r, \"\", cred.AccessKey, claims),\n\t\tObjectName:      objectName,\n\t\tIsOwner:         owner,\n\t\tClaims:          claims,\n\t}) {\n\t\t// Request is allowed return the appropriate access key.\n\t\treturn cred.AccessKey, owner, ErrNone\n\t}\n\n\tif action == policy.ListBucketVersionsAction {\n\t\t// In AWS S3 s3:ListBucket permission is same as s3:ListBucketVersions permission\n\t\t// verify as a fallback.\n\t\tif globalIAMSys.IsAllowed(iampolicy.Args{\n\t\t\tAccountName:     cred.AccessKey,\n\t\t\tAction:          iampolicy.ListBucketAction,\n\t\t\tBucketName:      bucketName,\n\t\t\tConditionValues: getConditionValues(r, \"\", cred.AccessKey, claims),\n\t\t\tObjectName:      objectName,\n\t\t\tIsOwner:         owner,\n\t\t\tClaims:          claims,\n\t\t}) {\n\t\t\t// Request is allowed return the appropriate access key.\n\t\t\treturn cred.AccessKey, owner, ErrNone\n\t\t}\n\t}\n\n\treturn cred.AccessKey, owner, ErrAccessDenied\n}\n\n// Verify if request has valid AWS Signature Version '2'.\nfunc isReqAuthenticatedV2(r *http.Request) (s3Error APIErrorCode) {\n\tif isRequestSignatureV2(r) {\n\t\treturn doesSignV2Match(r)\n\t}\n\treturn doesPresignV2SignatureMatch(r)\n}\n\nfunc reqSignatureV4Verify(r *http.Request, region string, stype serviceType) (s3Error APIErrorCode) {\n\tsha256sum := getContentSha256Cksum(r, stype)\n\tswitch {\n\tcase isRequestSignatureV4(r):\n\t\treturn doesSignatureMatch(sha256sum, r, region, stype)\n\tcase isRequestPresignedSignatureV4(r):\n\t\treturn doesPresignedSignatureMatch(sha256sum, r, region, stype)\n\tdefault:\n\t\treturn ErrAccessDenied\n\t}\n}\n\n// Verify if request has valid AWS Signature Version '4'.\nfunc isReqAuthenticated(ctx context.Context, r *http.Request, region string, stype serviceType) (s3Error APIErrorCode) {\n\tif errCode := reqSignatureV4Verify(r, region, stype); errCode != ErrNone {\n\t\treturn errCode\n\t}\n\n\tvar (\n\t\terr                       error\n\t\tcontentMD5, contentSHA256 []byte\n\t)\n\n\t// Extract 'Content-Md5' if present.\n\tcontentMD5, err = checkValidMD5(r.Header)\n\tif err != nil {\n\t\treturn ErrInvalidDigest\n\t}\n\n\t// Extract either 'X-Amz-Content-Sha256' header or 'X-Amz-Content-Sha256' query parameter (if V4 presigned)\n\t// Do not verify 'X-Amz-Content-Sha256' if skipSHA256.\n\tif skipSHA256 := skipContentSha256Cksum(r); !skipSHA256 && isRequestPresignedSignatureV4(r) {\n\t\tif sha256Sum, ok := r.URL.Query()[xhttp.AmzContentSha256]; ok && len(sha256Sum) > 0 {\n\t\t\tcontentSHA256, err = hex.DecodeString(sha256Sum[0])\n\t\t\tif err != nil {\n\t\t\t\treturn ErrContentSHA256Mismatch\n\t\t\t}\n\t\t}\n\t} else if _, ok := r.Header[xhttp.AmzContentSha256]; !skipSHA256 && ok {\n\t\tcontentSHA256, err = hex.DecodeString(r.Header.Get(xhttp.AmzContentSha256))\n\t\tif err != nil || len(contentSHA256) == 0 {\n\t\t\treturn ErrContentSHA256Mismatch\n\t\t}\n\t}\n\n\t// Verify 'Content-Md5' and/or 'X-Amz-Content-Sha256' if present.\n\t// The verification happens implicit during reading.\n\treader, err := hash.NewReader(r.Body, -1, hex.EncodeToString(contentMD5), hex.EncodeToString(contentSHA256), -1)\n\tif err != nil {\n\t\treturn toAPIErrorCode(ctx, err)\n\t}\n\tr.Body = reader\n\treturn ErrNone\n}\n\n// List of all support S3 auth types.\nvar supportedS3AuthTypes = map[authType]struct{}{\n\tauthTypeAnonymous:       {},\n\tauthTypePresigned:       {},\n\tauthTypePresignedV2:     {},\n\tauthTypeSigned:          {},\n\tauthTypeSignedV2:        {},\n\tauthTypePostPolicy:      {},\n\tauthTypeStreamingSigned: {},\n}\n\n// Validate if the authType is valid and supported.\nfunc isSupportedS3AuthType(aType authType) bool {\n\t_, ok := supportedS3AuthTypes[aType]\n\treturn ok\n}\n\n// setAuthHandler to validate authorization header for the incoming request.\nfunc setAuthHandler(h http.Handler) http.Handler {\n\t// handler for validating incoming authorization headers.\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\taType := getRequestAuthType(r)\n\t\tif isSupportedS3AuthType(aType) {\n\t\t\t// Let top level caller validate for anonymous and known signed requests.\n\t\t\th.ServeHTTP(w, r)\n\t\t\treturn\n\t\t} else if aType == authTypeJWT {\n\t\t\t// Validate Authorization header if its valid for JWT request.\n\t\t\tif _, _, authErr := webRequestAuthenticate(r); authErr != nil {\n\t\t\t\tw.WriteHeader(http.StatusUnauthorized)\n\t\t\t\tw.Write([]byte(authErr.Error()))\n\t\t\t\treturn\n\t\t\t}\n\t\t\th.ServeHTTP(w, r)\n\t\t\treturn\n\t\t} else if aType == authTypeSTS {\n\t\t\th.ServeHTTP(w, r)\n\t\t\treturn\n\t\t}\n\t\twriteErrorResponse(r.Context(), w, errorCodes.ToAPIErr(ErrSignatureVersionNotSupported), r.URL, guessIsBrowserReq(r))\n\t})\n}\n\nfunc validateSignature(atype authType, r *http.Request) (auth.Credentials, bool, map[string]interface{}, APIErrorCode) {\n\tvar cred auth.Credentials\n\tvar owner bool\n\tvar s3Err APIErrorCode\n\tswitch atype {\n\tcase authTypeUnknown, authTypeStreamingSigned:\n\t\treturn cred, owner, nil, ErrSignatureVersionNotSupported\n\tcase authTypeSignedV2, authTypePresignedV2:\n\t\tif s3Err = isReqAuthenticatedV2(r); s3Err != ErrNone {\n\t\t\treturn cred, owner, nil, s3Err\n\t\t}\n\t\tcred, owner, s3Err = getReqAccessKeyV2(r)\n\tcase authTypePresigned, authTypeSigned:\n\t\tregion := globalServerRegion\n\t\tif s3Err = isReqAuthenticated(GlobalContext, r, region, serviceS3); s3Err != ErrNone {\n\t\t\treturn cred, owner, nil, s3Err\n\t\t}\n\t\tcred, owner, s3Err = getReqAccessKeyV4(r, region, serviceS3)\n\t}\n\tif s3Err != ErrNone {\n\t\treturn cred, owner, nil, s3Err\n\t}\n\n\tclaims, s3Err := checkClaimsFromToken(r, cred)\n\tif s3Err != ErrNone {\n\t\treturn cred, owner, nil, s3Err\n\t}\n\n\treturn cred, owner, claims, ErrNone\n}\n\nfunc isPutRetentionAllowed(bucketName, objectName string, retDays int, retDate time.Time, retMode objectlock.RetMode, byPassSet bool, r *http.Request, cred auth.Credentials, owner bool, claims map[string]interface{}) (s3Err APIErrorCode) {\n\tvar retSet bool\n\tif cred.AccessKey == \"\" {\n\t\tconditions := getConditionValues(r, \"\", \"\", nil)\n\t\tconditions[\"object-lock-mode\"] = []string{string(retMode)}\n\t\tconditions[\"object-lock-retain-until-date\"] = []string{retDate.Format(time.RFC3339)}\n\t\tif retDays > 0 {\n\t\t\tconditions[\"object-lock-remaining-retention-days\"] = []string{strconv.Itoa(retDays)}\n\t\t}\n\t\tif retMode == objectlock.RetGovernance && byPassSet {\n\t\t\tbyPassSet = globalPolicySys.IsAllowed(policy.Args{\n\t\t\t\tAccountName:     cred.AccessKey,\n\t\t\t\tAction:          policy.BypassGovernanceRetentionAction,\n\t\t\t\tBucketName:      bucketName,\n\t\t\t\tConditionValues: conditions,\n\t\t\t\tIsOwner:         false,\n\t\t\t\tObjectName:      objectName,\n\t\t\t})\n\t\t}\n\t\tif globalPolicySys.IsAllowed(policy.Args{\n\t\t\tAccountName:     cred.AccessKey,\n\t\t\tAction:          policy.PutObjectRetentionAction,\n\t\t\tBucketName:      bucketName,\n\t\t\tConditionValues: conditions,\n\t\t\tIsOwner:         false,\n\t\t\tObjectName:      objectName,\n\t\t}) {\n\t\t\tretSet = true\n\t\t}\n\t\tif byPassSet || retSet {\n\t\t\treturn ErrNone\n\t\t}\n\t\treturn ErrAccessDenied\n\t}\n\n\tconditions := getConditionValues(r, \"\", cred.AccessKey, claims)\n\tconditions[\"object-lock-mode\"] = []string{string(retMode)}\n\tconditions[\"object-lock-retain-until-date\"] = []string{retDate.Format(time.RFC3339)}\n\tif retDays > 0 {\n\t\tconditions[\"object-lock-remaining-retention-days\"] = []string{strconv.Itoa(retDays)}\n\t}\n\tif retMode == objectlock.RetGovernance && byPassSet {\n\t\tbyPassSet = globalIAMSys.IsAllowed(iampolicy.Args{\n\t\t\tAccountName:     cred.AccessKey,\n\t\t\tAction:          iampolicy.BypassGovernanceRetentionAction,\n\t\t\tBucketName:      bucketName,\n\t\t\tObjectName:      objectName,\n\t\t\tConditionValues: conditions,\n\t\t\tIsOwner:         owner,\n\t\t\tClaims:          claims,\n\t\t})\n\t}\n\tif globalIAMSys.IsAllowed(iampolicy.Args{\n\t\tAccountName:     cred.AccessKey,\n\t\tAction:          iampolicy.PutObjectRetentionAction,\n\t\tBucketName:      bucketName,\n\t\tConditionValues: conditions,\n\t\tObjectName:      objectName,\n\t\tIsOwner:         owner,\n\t\tClaims:          claims,\n\t}) {\n\t\tretSet = true\n\t}\n\tif byPassSet || retSet {\n\t\treturn ErrNone\n\t}\n\treturn ErrAccessDenied\n}\n\n// isPutActionAllowed - check if PUT operation is allowed on the resource, this\n// call verifies bucket policies and IAM policies, supports multi user\n// checks etc.\nfunc isPutActionAllowed(ctx context.Context, atype authType, bucketName, objectName string, r *http.Request, action iampolicy.Action) (s3Err APIErrorCode) {\n\tvar cred auth.Credentials\n\tvar owner bool\n\tswitch atype {\n\tcase authTypeUnknown:\n\t\treturn ErrSignatureVersionNotSupported\n\tcase authTypeSignedV2, authTypePresignedV2:\n\t\tcred, owner, s3Err = getReqAccessKeyV2(r)\n\tcase authTypeStreamingSigned, authTypePresigned, authTypeSigned:\n\t\tregion := globalServerRegion\n\t\tcred, owner, s3Err = getReqAccessKeyV4(r, region, serviceS3)\n\t}\n\tif s3Err != ErrNone {\n\t\treturn s3Err\n\t}\n\n\tclaims, s3Err := checkClaimsFromToken(r, cred)\n\tif s3Err != ErrNone {\n\t\treturn s3Err\n\t}\n\n\tif cred.AccessKey != \"\" {\n\t\tlogger.GetReqInfo(ctx).AccessKey = cred.AccessKey\n\t}\n\n\t// Do not check for PutObjectRetentionAction permission,\n\t// if mode and retain until date are not set.\n\t// Can happen when bucket has default lock config set\n\tif action == iampolicy.PutObjectRetentionAction &&\n\t\tr.Header.Get(xhttp.AmzObjectLockMode) == \"\" &&\n\t\tr.Header.Get(xhttp.AmzObjectLockRetainUntilDate) == \"\" {\n\t\treturn ErrNone\n\t}\n\n\tif cred.AccessKey == \"\" {\n\t\tif globalPolicySys.IsAllowed(policy.Args{\n\t\t\tAccountName:     cred.AccessKey,\n\t\t\tAction:          policy.Action(action),\n\t\t\tBucketName:      bucketName,\n\t\t\tConditionValues: getConditionValues(r, \"\", \"\", nil),\n\t\t\tIsOwner:         false,\n\t\t\tObjectName:      objectName,\n\t\t}) {\n\t\t\treturn ErrNone\n\t\t}\n\t\treturn ErrAccessDenied\n\t}\n\n\tif globalIAMSys.IsAllowed(iampolicy.Args{\n\t\tAccountName:     cred.AccessKey,\n\t\tAction:          action,\n\t\tBucketName:      bucketName,\n\t\tConditionValues: getConditionValues(r, \"\", cred.AccessKey, claims),\n\t\tObjectName:      objectName,\n\t\tIsOwner:         owner,\n\t\tClaims:          claims,\n\t}) {\n\t\treturn ErrNone\n\t}\n\treturn ErrAccessDenied\n}\n", "/*\n * MinIO Cloud Storage, (C) 2015-2020 MinIO, Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\npackage cmd\n\nimport (\n\t\"encoding/base64\"\n\t\"encoding/xml\"\n\t\"fmt\"\n\t\"io\"\n\t\"net/http\"\n\t\"net/textproto\"\n\t\"net/url\"\n\t\"path\"\n\t\"path/filepath\"\n\t\"sort\"\n\t\"strconv\"\n\t\"strings\"\n\t\"sync\"\n\n\t\"github.com/google/uuid\"\n\t\"github.com/gorilla/mux\"\n\n\t\"github.com/minio/minio-go/v7/pkg/set\"\n\t\"github.com/minio/minio-go/v7/pkg/tags\"\n\t\"github.com/minio/minio/cmd/config/dns\"\n\t\"github.com/minio/minio/cmd/crypto\"\n\txhttp \"github.com/minio/minio/cmd/http\"\n\t\"github.com/minio/minio/cmd/logger\"\n\t\"github.com/minio/minio/pkg/bucket/lifecycle\"\n\tobjectlock \"github.com/minio/minio/pkg/bucket/object/lock\"\n\t\"github.com/minio/minio/pkg/bucket/policy\"\n\t\"github.com/minio/minio/pkg/bucket/replication\"\n\t\"github.com/minio/minio/pkg/event\"\n\t\"github.com/minio/minio/pkg/handlers\"\n\t\"github.com/minio/minio/pkg/hash\"\n\tiampolicy \"github.com/minio/minio/pkg/iam/policy\"\n\t\"github.com/minio/minio/pkg/sync/errgroup\"\n)\n\nconst (\n\tobjectLockConfig        = \"object-lock.xml\"\n\tbucketTaggingConfig     = \"tagging.xml\"\n\tbucketReplicationConfig = \"replication.xml\"\n)\n\n// Check if there are buckets on server without corresponding entry in etcd backend and\n// make entries. Here is the general flow\n// - Range over all the available buckets\n// - Check if a bucket has an entry in etcd backend\n// -- If no, make an entry\n// -- If yes, check if the entry matches local IP check if we\n//    need to update the entry then proceed to update\n// -- If yes, check if the IP of entry matches local IP.\n//    This means entry is for this instance.\n// -- If IP of the entry doesn't match, this means entry is\n//    for another instance. Log an error to console.\nfunc initFederatorBackend(buckets []BucketInfo, objLayer ObjectLayer) {\n\tif len(buckets) == 0 {\n\t\treturn\n\t}\n\n\t// Get buckets in the DNS\n\tdnsBuckets, err := globalDNSConfig.List()\n\tif err != nil && !IsErrIgnored(err, dns.ErrNoEntriesFound, dns.ErrNotImplemented, dns.ErrDomainMissing) {\n\t\tlogger.LogIf(GlobalContext, err)\n\t\treturn\n\t}\n\n\tbucketsSet := set.NewStringSet()\n\tbucketsToBeUpdated := set.NewStringSet()\n\tbucketsInConflict := set.NewStringSet()\n\n\t// This means that domain is updated, we should update\n\t// all bucket entries with new domain name.\n\tdomainMissing := err == dns.ErrDomainMissing\n\tif dnsBuckets != nil {\n\t\tfor _, bucket := range buckets {\n\t\t\tbucketsSet.Add(bucket.Name)\n\t\t\tr, ok := dnsBuckets[bucket.Name]\n\t\t\tif !ok {\n\t\t\t\tbucketsToBeUpdated.Add(bucket.Name)\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tif !globalDomainIPs.Intersection(set.CreateStringSet(getHostsSlice(r)...)).IsEmpty() {\n\t\t\t\tif globalDomainIPs.Difference(set.CreateStringSet(getHostsSlice(r)...)).IsEmpty() && !domainMissing {\n\t\t\t\t\t// No difference in terms of domainIPs and nothing\n\t\t\t\t\t// has changed so we don't change anything on the etcd.\n\t\t\t\t\t//\n\t\t\t\t\t// Additionally also check if domain is updated/missing with more\n\t\t\t\t\t// entries, if that is the case we should update the\n\t\t\t\t\t// new domain entries as well.\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\n\t\t\t\t// if domain IPs intersect then it won't be an empty set.\n\t\t\t\t// such an intersection means that bucket exists on etcd.\n\t\t\t\t// but if we do see a difference with local domain IPs with\n\t\t\t\t// hostSlice from etcd then we should update with newer\n\t\t\t\t// domainIPs, we proceed to do that here.\n\t\t\t\tbucketsToBeUpdated.Add(bucket.Name)\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\t// No IPs seem to intersect, this means that bucket exists but has\n\t\t\t// different IP addresses perhaps from a different deployment.\n\t\t\t// bucket names are globally unique in federation at a given\n\t\t\t// path prefix, name collision is not allowed. We simply log\n\t\t\t// an error and continue.\n\t\t\tbucketsInConflict.Add(bucket.Name)\n\t\t}\n\t}\n\n\t// Add/update buckets that are not registered with the DNS\n\tbucketsToBeUpdatedSlice := bucketsToBeUpdated.ToSlice()\n\tg := errgroup.WithNErrs(len(bucketsToBeUpdatedSlice)).WithConcurrency(50)\n\tctx, cancel := g.WithCancelOnError(GlobalContext)\n\tdefer cancel()\n\n\tfor index := range bucketsToBeUpdatedSlice {\n\t\tindex := index\n\t\tg.Go(func() error {\n\t\t\treturn globalDNSConfig.Put(bucketsToBeUpdatedSlice[index])\n\t\t}, index)\n\t}\n\n\tif err := g.WaitErr(); err != nil {\n\t\tlogger.LogIf(ctx, err)\n\t\treturn\n\t}\n\n\tfor _, bucket := range bucketsInConflict.ToSlice() {\n\t\tlogger.LogIf(ctx, fmt.Errorf(\"Unable to add bucket DNS entry for bucket %s, an entry exists for the same bucket by a different tenant. This local bucket will be ignored. Bucket names are globally unique in federated deployments. Use path style requests on following addresses '%v' to access this bucket\", bucket, globalDomainIPs.ToSlice()))\n\t}\n\n\tvar wg sync.WaitGroup\n\t// Remove buckets that are in DNS for this server, but aren't local\n\tfor bucket, records := range dnsBuckets {\n\t\tif bucketsSet.Contains(bucket) {\n\t\t\tcontinue\n\t\t}\n\n\t\tif globalDomainIPs.Intersection(set.CreateStringSet(getHostsSlice(records)...)).IsEmpty() {\n\t\t\t// This is not for our server, so we can continue\n\t\t\tcontinue\n\t\t}\n\n\t\twg.Add(1)\n\t\tgo func(bucket string) {\n\t\t\tdefer wg.Done()\n\t\t\t// We go to here, so we know the bucket no longer exists,\n\t\t\t// but is registered in DNS to this server\n\t\t\tif err := globalDNSConfig.Delete(bucket); err != nil {\n\t\t\t\tlogger.LogIf(GlobalContext, fmt.Errorf(\"Failed to remove DNS entry for %s due to %w\",\n\t\t\t\t\tbucket, err))\n\t\t\t}\n\t\t}(bucket)\n\t}\n\twg.Wait()\n}\n\n// GetBucketLocationHandler - GET Bucket location.\n// -------------------------\n// This operation returns bucket location.\nfunc (api objectAPIHandlers) GetBucketLocationHandler(w http.ResponseWriter, r *http.Request) {\n\tctx := newContext(r, w, \"GetBucketLocation\")\n\n\tdefer logger.AuditLog(ctx, w, r, mustGetClaimsFromToken(r))\n\n\tvars := mux.Vars(r)\n\tbucket := vars[\"bucket\"]\n\n\tobjectAPI := api.ObjectAPI()\n\tif objectAPI == nil {\n\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(ErrServerNotInitialized), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\tif s3Error := checkRequestAuthType(ctx, r, policy.GetBucketLocationAction, bucket, \"\"); s3Error != ErrNone {\n\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(s3Error), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\tgetBucketInfo := objectAPI.GetBucketInfo\n\n\tif _, err := getBucketInfo(ctx, bucket); err != nil {\n\t\twriteErrorResponse(ctx, w, toAPIError(ctx, err), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\t// Generate response.\n\tencodedSuccessResponse := encodeResponse(LocationResponse{})\n\t// Get current region.\n\tregion := globalServerRegion\n\tif region != globalMinioDefaultRegion {\n\t\tencodedSuccessResponse = encodeResponse(LocationResponse{\n\t\t\tLocation: region,\n\t\t})\n\t}\n\n\t// Write success response.\n\twriteSuccessResponseXML(w, encodedSuccessResponse)\n}\n\n// ListMultipartUploadsHandler - GET Bucket (List Multipart uploads)\n// -------------------------\n// This operation lists in-progress multipart uploads. An in-progress\n// multipart upload is a multipart upload that has been initiated,\n// using the Initiate Multipart Upload request, but has not yet been\n// completed or aborted. This operation returns at most 1,000 multipart\n// uploads in the response.\n//\nfunc (api objectAPIHandlers) ListMultipartUploadsHandler(w http.ResponseWriter, r *http.Request) {\n\tctx := newContext(r, w, \"ListMultipartUploads\")\n\n\tdefer logger.AuditLog(ctx, w, r, mustGetClaimsFromToken(r))\n\n\tvars := mux.Vars(r)\n\tbucket := vars[\"bucket\"]\n\n\tobjectAPI := api.ObjectAPI()\n\tif objectAPI == nil {\n\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(ErrServerNotInitialized), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\tif s3Error := checkRequestAuthType(ctx, r, policy.ListBucketMultipartUploadsAction, bucket, \"\"); s3Error != ErrNone {\n\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(s3Error), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\tprefix, keyMarker, uploadIDMarker, delimiter, maxUploads, encodingType, errCode := getBucketMultipartResources(r.URL.Query())\n\tif errCode != ErrNone {\n\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(errCode), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\tif maxUploads < 0 {\n\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(ErrInvalidMaxUploads), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\tif keyMarker != \"\" {\n\t\t// Marker not common with prefix is not implemented.\n\t\tif !HasPrefix(keyMarker, prefix) {\n\t\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(ErrNotImplemented), r.URL, guessIsBrowserReq(r))\n\t\t\treturn\n\t\t}\n\t}\n\n\tlistMultipartsInfo, err := objectAPI.ListMultipartUploads(ctx, bucket, prefix, keyMarker, uploadIDMarker, delimiter, maxUploads)\n\tif err != nil {\n\t\twriteErrorResponse(ctx, w, toAPIError(ctx, err), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\t// generate response\n\tresponse := generateListMultipartUploadsResponse(bucket, listMultipartsInfo, encodingType)\n\tencodedSuccessResponse := encodeResponse(response)\n\n\t// write success response.\n\twriteSuccessResponseXML(w, encodedSuccessResponse)\n}\n\n// ListBucketsHandler - GET Service.\n// -----------\n// This implementation of the GET operation returns a list of all buckets\n// owned by the authenticated sender of the request.\nfunc (api objectAPIHandlers) ListBucketsHandler(w http.ResponseWriter, r *http.Request) {\n\tctx := newContext(r, w, \"ListBuckets\")\n\n\tdefer logger.AuditLog(ctx, w, r, mustGetClaimsFromToken(r))\n\n\tobjectAPI := api.ObjectAPI()\n\tif objectAPI == nil {\n\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(ErrServerNotInitialized), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\tlistBuckets := objectAPI.ListBuckets\n\n\taccessKey, owner, s3Error := checkRequestAuthTypeToAccessKey(ctx, r, policy.ListAllMyBucketsAction, \"\", \"\")\n\tif s3Error != ErrNone && s3Error != ErrAccessDenied {\n\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(s3Error), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\t// If etcd, dns federation configured list buckets from etcd.\n\tvar bucketsInfo []BucketInfo\n\tif globalDNSConfig != nil && globalBucketFederation {\n\t\tdnsBuckets, err := globalDNSConfig.List()\n\t\tif err != nil && !IsErrIgnored(err,\n\t\t\tdns.ErrNoEntriesFound,\n\t\t\tdns.ErrDomainMissing) {\n\t\t\twriteErrorResponse(ctx, w, toAPIError(ctx, err), r.URL, guessIsBrowserReq(r))\n\t\t\treturn\n\t\t}\n\t\tfor _, dnsRecords := range dnsBuckets {\n\t\t\tbucketsInfo = append(bucketsInfo, BucketInfo{\n\t\t\t\tName:    dnsRecords[0].Key,\n\t\t\t\tCreated: dnsRecords[0].CreationDate,\n\t\t\t})\n\t\t}\n\n\t\tsort.Slice(bucketsInfo, func(i, j int) bool {\n\t\t\treturn bucketsInfo[i].Name < bucketsInfo[j].Name\n\t\t})\n\n\t} else {\n\t\t// Invoke the list buckets.\n\t\tvar err error\n\t\tbucketsInfo, err = listBuckets(ctx)\n\t\tif err != nil {\n\t\t\twriteErrorResponse(ctx, w, toAPIError(ctx, err), r.URL, guessIsBrowserReq(r))\n\t\t\treturn\n\t\t}\n\t}\n\n\tif s3Error == ErrAccessDenied {\n\t\t// Set prefix value for \"s3:prefix\" policy conditionals.\n\t\tr.Header.Set(\"prefix\", \"\")\n\n\t\t// Set delimiter value for \"s3:delimiter\" policy conditionals.\n\t\tr.Header.Set(\"delimiter\", SlashSeparator)\n\n\t\t// err will be nil here as we already called this function\n\t\t// earlier in this request.\n\t\tclaims, _ := getClaimsFromToken(r, getSessionToken(r))\n\t\tn := 0\n\t\t// Use the following trick to filter in place\n\t\t// https://github.com/golang/go/wiki/SliceTricks#filter-in-place\n\t\tfor _, bucketInfo := range bucketsInfo {\n\t\t\tif globalIAMSys.IsAllowed(iampolicy.Args{\n\t\t\t\tAccountName:     accessKey,\n\t\t\t\tAction:          iampolicy.ListBucketAction,\n\t\t\t\tBucketName:      bucketInfo.Name,\n\t\t\t\tConditionValues: getConditionValues(r, \"\", accessKey, claims),\n\t\t\t\tIsOwner:         owner,\n\t\t\t\tObjectName:      \"\",\n\t\t\t\tClaims:          claims,\n\t\t\t}) {\n\t\t\t\tbucketsInfo[n] = bucketInfo\n\t\t\t\tn++\n\t\t\t}\n\t\t}\n\t\tbucketsInfo = bucketsInfo[:n]\n\t\t// No buckets can be filtered return access denied error.\n\t\tif len(bucketsInfo) == 0 {\n\t\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(s3Error), r.URL, guessIsBrowserReq(r))\n\t\t\treturn\n\t\t}\n\t}\n\n\t// Generate response.\n\tresponse := generateListBucketsResponse(bucketsInfo)\n\tencodedSuccessResponse := encodeResponse(response)\n\n\t// Write response.\n\twriteSuccessResponseXML(w, encodedSuccessResponse)\n}\n\n// DeleteMultipleObjectsHandler - deletes multiple objects.\nfunc (api objectAPIHandlers) DeleteMultipleObjectsHandler(w http.ResponseWriter, r *http.Request) {\n\tctx := newContext(r, w, \"DeleteMultipleObjects\")\n\n\tdefer logger.AuditLog(ctx, w, r, mustGetClaimsFromToken(r))\n\n\tvars := mux.Vars(r)\n\tbucket := vars[\"bucket\"]\n\n\tobjectAPI := api.ObjectAPI()\n\tif objectAPI == nil {\n\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(ErrServerNotInitialized), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\t// Content-Md5 is requied should be set\n\t// http://docs.aws.amazon.com/AmazonS3/latest/API/multiobjectdeleteapi.html\n\tif _, ok := r.Header[xhttp.ContentMD5]; !ok {\n\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(ErrMissingContentMD5), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\t// Content-Length is required and should be non-zero\n\t// http://docs.aws.amazon.com/AmazonS3/latest/API/multiobjectdeleteapi.html\n\tif r.ContentLength <= 0 {\n\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(ErrMissingContentLength), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\t// The max. XML contains 100000 object names (each at most 1024 bytes long) + XML overhead\n\tconst maxBodySize = 2 * 100000 * 1024\n\n\t// Unmarshal list of keys to be deleted.\n\tdeleteObjects := &DeleteObjectsRequest{}\n\tif err := xmlDecoder(r.Body, deleteObjects, maxBodySize); err != nil {\n\t\tlogger.LogIf(ctx, err, logger.Application)\n\t\twriteErrorResponse(ctx, w, toAPIError(ctx, err), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\t// Call checkRequestAuthType to populate ReqInfo.AccessKey before GetBucketInfo()\n\t// Ignore errors here to preserve the S3 error behavior of GetBucketInfo()\n\tcheckRequestAuthType(ctx, r, policy.DeleteObjectAction, bucket, \"\")\n\n\t// Before proceeding validate if bucket exists.\n\t_, err := objectAPI.GetBucketInfo(ctx, bucket)\n\tif err != nil {\n\t\twriteErrorResponse(ctx, w, toAPIError(ctx, err), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\tdeleteObjectsFn := objectAPI.DeleteObjects\n\tif api.CacheAPI() != nil {\n\t\tdeleteObjectsFn = api.CacheAPI().DeleteObjects\n\t}\n\n\t// Return Malformed XML as S3 spec if the list of objects is empty\n\tif len(deleteObjects.Objects) == 0 {\n\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(ErrMalformedXML), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\tvar objectsToDelete = map[ObjectToDelete]int{}\n\tgetObjectInfoFn := objectAPI.GetObjectInfo\n\tif api.CacheAPI() != nil {\n\t\tgetObjectInfoFn = api.CacheAPI().GetObjectInfo\n\t}\n\tvar (\n\t\thasLockEnabled, hasLifecycleConfig, replicateSync bool\n\t\tgoi                                               ObjectInfo\n\t\tgerr                                              error\n\t)\n\treplicateDeletes := hasReplicationRules(ctx, bucket, deleteObjects.Objects)\n\tif rcfg, _ := globalBucketObjectLockSys.Get(bucket); rcfg.LockEnabled {\n\t\thasLockEnabled = true\n\t}\n\tif _, err := globalBucketMetadataSys.GetLifecycleConfig(bucket); err == nil {\n\t\thasLifecycleConfig = true\n\t}\n\tdErrs := make([]DeleteError, len(deleteObjects.Objects))\n\tfor index, object := range deleteObjects.Objects {\n\t\tif apiErrCode := checkRequestAuthType(ctx, r, policy.DeleteObjectAction, bucket, object.ObjectName); apiErrCode != ErrNone {\n\t\t\tif apiErrCode == ErrSignatureDoesNotMatch || apiErrCode == ErrInvalidAccessKeyID {\n\t\t\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(apiErrCode), r.URL, guessIsBrowserReq(r))\n\t\t\t\treturn\n\t\t\t}\n\t\t\tapiErr := errorCodes.ToAPIErr(apiErrCode)\n\t\t\tdErrs[index] = DeleteError{\n\t\t\t\tCode:      apiErr.Code,\n\t\t\t\tMessage:   apiErr.Description,\n\t\t\t\tKey:       object.ObjectName,\n\t\t\t\tVersionID: object.VersionID,\n\t\t\t}\n\t\t\tcontinue\n\t\t}\n\t\tif object.VersionID != \"\" && object.VersionID != nullVersionID {\n\t\t\tif _, err := uuid.Parse(object.VersionID); err != nil {\n\t\t\t\tlogger.LogIf(ctx, fmt.Errorf(\"invalid version-id specified %w\", err))\n\t\t\t\tapiErr := errorCodes.ToAPIErr(ErrNoSuchVersion)\n\t\t\t\tdErrs[index] = DeleteError{\n\t\t\t\t\tCode:      apiErr.Code,\n\t\t\t\t\tMessage:   apiErr.Description,\n\t\t\t\t\tKey:       object.ObjectName,\n\t\t\t\t\tVersionID: object.VersionID,\n\t\t\t\t}\n\t\t\t\tcontinue\n\t\t\t}\n\t\t}\n\n\t\tif replicateDeletes || hasLockEnabled || hasLifecycleConfig {\n\t\t\tgoi, gerr = getObjectInfoFn(ctx, bucket, object.ObjectName, ObjectOptions{\n\t\t\t\tVersionID: object.VersionID,\n\t\t\t})\n\t\t}\n\t\tif hasLifecycleConfig && gerr == nil {\n\t\t\tobject.PurgeTransitioned = goi.TransitionStatus\n\t\t}\n\t\tif replicateDeletes {\n\t\t\tdelMarker, replicate, repsync := checkReplicateDelete(ctx, bucket, ObjectToDelete{\n\t\t\t\tObjectName: object.ObjectName,\n\t\t\t\tVersionID:  object.VersionID,\n\t\t\t}, goi, gerr)\n\t\t\treplicateSync = repsync\n\t\t\tif replicate {\n\t\t\t\tif apiErrCode := checkRequestAuthType(ctx, r, policy.ReplicateDeleteAction, bucket, object.ObjectName); apiErrCode != ErrNone {\n\t\t\t\t\tif apiErrCode == ErrSignatureDoesNotMatch || apiErrCode == ErrInvalidAccessKeyID {\n\t\t\t\t\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(apiErrCode), r.URL, guessIsBrowserReq(r))\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tif object.VersionID != \"\" {\n\t\t\t\t\tobject.VersionPurgeStatus = Pending\n\t\t\t\t\tif delMarker {\n\t\t\t\t\t\tobject.DeleteMarkerVersionID = object.VersionID\n\t\t\t\t\t}\n\t\t\t\t} else {\n\t\t\t\t\tobject.DeleteMarkerReplicationStatus = string(replication.Pending)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tif object.VersionID != \"\" {\n\t\t\tif hasLockEnabled {\n\t\t\t\tif apiErrCode := enforceRetentionBypassForDelete(ctx, r, bucket, object, goi, gerr); apiErrCode != ErrNone {\n\t\t\t\t\tapiErr := errorCodes.ToAPIErr(apiErrCode)\n\t\t\t\t\tdErrs[index] = DeleteError{\n\t\t\t\t\t\tCode:      apiErr.Code,\n\t\t\t\t\t\tMessage:   apiErr.Description,\n\t\t\t\t\t\tKey:       object.ObjectName,\n\t\t\t\t\t\tVersionID: object.VersionID,\n\t\t\t\t\t}\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t// Avoid duplicate objects, we use map to filter them out.\n\t\tif _, ok := objectsToDelete[object]; !ok {\n\t\t\tobjectsToDelete[object] = index\n\t\t}\n\t}\n\n\ttoNames := func(input map[ObjectToDelete]int) (output []ObjectToDelete) {\n\t\toutput = make([]ObjectToDelete, len(input))\n\t\tidx := 0\n\t\tfor obj := range input {\n\t\t\toutput[idx] = obj\n\t\t\tidx++\n\t\t}\n\t\treturn\n\t}\n\n\tdeleteList := toNames(objectsToDelete)\n\tdObjects, errs := deleteObjectsFn(ctx, bucket, deleteList, ObjectOptions{\n\t\tVersioned:        globalBucketVersioningSys.Enabled(bucket),\n\t\tVersionSuspended: globalBucketVersioningSys.Suspended(bucket),\n\t})\n\tdeletedObjects := make([]DeletedObject, len(deleteObjects.Objects))\n\tfor i := range errs {\n\t\tdindex := objectsToDelete[ObjectToDelete{\n\t\t\tObjectName:                    dObjects[i].ObjectName,\n\t\t\tVersionID:                     dObjects[i].VersionID,\n\t\t\tVersionPurgeStatus:            dObjects[i].VersionPurgeStatus,\n\t\t\tDeleteMarkerReplicationStatus: dObjects[i].DeleteMarkerReplicationStatus,\n\t\t\tPurgeTransitioned:             dObjects[i].PurgeTransitioned,\n\t\t}]\n\t\tif errs[i] == nil || isErrObjectNotFound(errs[i]) || isErrVersionNotFound(errs[i]) {\n\t\t\tif replicateDeletes {\n\t\t\t\tdObjects[i].DeleteMarkerReplicationStatus = deleteList[i].DeleteMarkerReplicationStatus\n\t\t\t\tdObjects[i].VersionPurgeStatus = deleteList[i].VersionPurgeStatus\n\t\t\t}\n\t\t\tdeletedObjects[dindex] = dObjects[i]\n\t\t\tcontinue\n\t\t}\n\t\tapiErr := toAPIError(ctx, errs[i])\n\t\tdErrs[dindex] = DeleteError{\n\t\t\tCode:      apiErr.Code,\n\t\t\tMessage:   apiErr.Description,\n\t\t\tKey:       deleteList[i].ObjectName,\n\t\t\tVersionID: deleteList[i].VersionID,\n\t\t}\n\t}\n\n\tvar deleteErrors []DeleteError\n\tfor _, dErr := range dErrs {\n\t\tif dErr.Code != \"\" {\n\t\t\tdeleteErrors = append(deleteErrors, dErr)\n\t\t}\n\t}\n\n\t// Generate response\n\tresponse := generateMultiDeleteResponse(deleteObjects.Quiet, deletedObjects, deleteErrors)\n\tencodedSuccessResponse := encodeResponse(response)\n\n\t// Write success response.\n\twriteSuccessResponseXML(w, encodedSuccessResponse)\n\tfor _, dobj := range deletedObjects {\n\t\tif dobj.ObjectName == \"\" {\n\t\t\tcontinue\n\t\t}\n\n\t\tif replicateDeletes {\n\t\t\tif dobj.DeleteMarkerReplicationStatus == string(replication.Pending) || dobj.VersionPurgeStatus == Pending {\n\t\t\t\tdv := DeletedObjectVersionInfo{\n\t\t\t\t\tDeletedObject: dobj,\n\t\t\t\t\tBucket:        bucket,\n\t\t\t\t}\n\t\t\t\tscheduleReplicationDelete(ctx, dv, objectAPI, replicateSync)\n\t\t\t}\n\t\t}\n\n\t\tif hasLifecycleConfig && dobj.PurgeTransitioned == lifecycle.TransitionComplete { // clean up transitioned tier\n\t\t\tdeleteTransitionedObject(ctx, objectAPI, bucket, dobj.ObjectName, lifecycle.ObjectOpts{\n\t\t\t\tName:         dobj.ObjectName,\n\t\t\t\tVersionID:    dobj.VersionID,\n\t\t\t\tDeleteMarker: dobj.DeleteMarker,\n\t\t\t}, false, true)\n\t\t}\n\n\t\teventName := event.ObjectRemovedDelete\n\t\tobjInfo := ObjectInfo{\n\t\t\tName:      dobj.ObjectName,\n\t\t\tVersionID: dobj.VersionID,\n\t\t}\n\n\t\tif dobj.DeleteMarker {\n\t\t\tobjInfo.DeleteMarker = dobj.DeleteMarker\n\t\t\tobjInfo.VersionID = dobj.DeleteMarkerVersionID\n\t\t\teventName = event.ObjectRemovedDeleteMarkerCreated\n\t\t}\n\n\t\tsendEvent(eventArgs{\n\t\t\tEventName:    eventName,\n\t\t\tBucketName:   bucket,\n\t\t\tObject:       objInfo,\n\t\t\tReqParams:    extractReqParams(r),\n\t\t\tRespElements: extractRespElements(w),\n\t\t\tUserAgent:    r.UserAgent(),\n\t\t\tHost:         handlers.GetSourceIP(r),\n\t\t})\n\t}\n}\n\n// PutBucketHandler - PUT Bucket\n// ----------\n// This implementation of the PUT operation creates a new bucket for authenticated request\nfunc (api objectAPIHandlers) PutBucketHandler(w http.ResponseWriter, r *http.Request) {\n\tctx := newContext(r, w, \"PutBucket\")\n\n\tdefer logger.AuditLog(ctx, w, r, mustGetClaimsFromToken(r))\n\n\tobjectAPI := api.ObjectAPI()\n\tif objectAPI == nil {\n\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(ErrServerNotInitialized), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\tvars := mux.Vars(r)\n\tbucket := vars[\"bucket\"]\n\n\tobjectLockEnabled := false\n\tif vs, found := r.Header[http.CanonicalHeaderKey(\"x-amz-bucket-object-lock-enabled\")]; found {\n\t\tv := strings.ToLower(strings.Join(vs, \"\"))\n\t\tif v != \"true\" && v != \"false\" {\n\t\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(ErrInvalidRequest), r.URL, guessIsBrowserReq(r))\n\t\t\treturn\n\t\t}\n\t\tobjectLockEnabled = v == \"true\"\n\t}\n\n\tif s3Error := checkRequestAuthType(ctx, r, policy.CreateBucketAction, bucket, \"\"); s3Error != ErrNone {\n\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(s3Error), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\t// Parse incoming location constraint.\n\tlocation, s3Error := parseLocationConstraint(r)\n\tif s3Error != ErrNone {\n\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(s3Error), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\t// Validate if location sent by the client is valid, reject\n\t// requests which do not follow valid region requirements.\n\tif !isValidLocation(location) {\n\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(ErrInvalidRegion), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\topts := BucketOptions{\n\t\tLocation:    location,\n\t\tLockEnabled: objectLockEnabled,\n\t}\n\n\tif globalDNSConfig != nil {\n\t\tsr, err := globalDNSConfig.Get(bucket)\n\t\tif err != nil {\n\t\t\t// ErrNotImplemented indicates a DNS backend that doesn't need to check if bucket already\n\t\t\t// exists elsewhere\n\t\t\tif err == dns.ErrNoEntriesFound || err == dns.ErrNotImplemented {\n\t\t\t\t// Proceed to creating a bucket.\n\t\t\t\tif err = objectAPI.MakeBucketWithLocation(ctx, bucket, opts); err != nil {\n\t\t\t\t\twriteErrorResponse(ctx, w, toAPIError(ctx, err), r.URL, guessIsBrowserReq(r))\n\t\t\t\t\treturn\n\t\t\t\t}\n\n\t\t\t\tif err = globalDNSConfig.Put(bucket); err != nil {\n\t\t\t\t\tobjectAPI.DeleteBucket(ctx, bucket, false)\n\t\t\t\t\twriteErrorResponse(ctx, w, toAPIError(ctx, err), r.URL, guessIsBrowserReq(r))\n\t\t\t\t\treturn\n\t\t\t\t}\n\n\t\t\t\t// Load updated bucket metadata into memory.\n\t\t\t\tglobalNotificationSys.LoadBucketMetadata(GlobalContext, bucket)\n\n\t\t\t\t// Make sure to add Location information here only for bucket\n\t\t\t\tw.Header().Set(xhttp.Location,\n\t\t\t\t\tgetObjectLocation(r, globalDomainNames, bucket, \"\"))\n\n\t\t\t\twriteSuccessResponseHeadersOnly(w)\n\n\t\t\t\tsendEvent(eventArgs{\n\t\t\t\t\tEventName:    event.BucketCreated,\n\t\t\t\t\tBucketName:   bucket,\n\t\t\t\t\tReqParams:    extractReqParams(r),\n\t\t\t\t\tRespElements: extractRespElements(w),\n\t\t\t\t\tUserAgent:    r.UserAgent(),\n\t\t\t\t\tHost:         handlers.GetSourceIP(r),\n\t\t\t\t})\n\n\t\t\t\treturn\n\t\t\t}\n\t\t\twriteErrorResponse(ctx, w, toAPIError(ctx, err), r.URL, guessIsBrowserReq(r))\n\t\t\treturn\n\n\t\t}\n\t\tapiErr := ErrBucketAlreadyExists\n\t\tif !globalDomainIPs.Intersection(set.CreateStringSet(getHostsSlice(sr)...)).IsEmpty() {\n\t\t\tapiErr = ErrBucketAlreadyOwnedByYou\n\t\t}\n\t\t// No IPs seem to intersect, this means that bucket exists but has\n\t\t// different IP addresses perhaps from a different deployment.\n\t\t// bucket names are globally unique in federation at a given\n\t\t// path prefix, name collision is not allowed. Return appropriate error.\n\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(apiErr), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\t// Proceed to creating a bucket.\n\terr := objectAPI.MakeBucketWithLocation(ctx, bucket, opts)\n\tif err != nil {\n\t\twriteErrorResponse(ctx, w, toAPIError(ctx, err), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\t// Load updated bucket metadata into memory.\n\tglobalNotificationSys.LoadBucketMetadata(GlobalContext, bucket)\n\n\t// Make sure to add Location information here only for bucket\n\tw.Header().Set(xhttp.Location, path.Clean(r.URL.Path)) // Clean any trailing slashes.\n\n\twriteSuccessResponseHeadersOnly(w)\n\n\tsendEvent(eventArgs{\n\t\tEventName:    event.BucketCreated,\n\t\tBucketName:   bucket,\n\t\tReqParams:    extractReqParams(r),\n\t\tRespElements: extractRespElements(w),\n\t\tUserAgent:    r.UserAgent(),\n\t\tHost:         handlers.GetSourceIP(r),\n\t})\n}\n\n// PostPolicyBucketHandler - POST policy\n// ----------\n// This implementation of the POST operation handles object creation with a specified\n// signature policy in multipart/form-data\nfunc (api objectAPIHandlers) PostPolicyBucketHandler(w http.ResponseWriter, r *http.Request) {\n\tctx := newContext(r, w, \"PostPolicyBucket\")\n\n\tdefer logger.AuditLog(ctx, w, r, mustGetClaimsFromToken(r))\n\n\tobjectAPI := api.ObjectAPI()\n\tif objectAPI == nil {\n\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(ErrServerNotInitialized), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\tif crypto.S3KMS.IsRequested(r.Header) { // SSE-KMS is not supported\n\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(ErrNotImplemented), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\tif _, ok := crypto.IsRequested(r.Header); !objectAPI.IsEncryptionSupported() && ok {\n\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(ErrNotImplemented), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\tbucket := mux.Vars(r)[\"bucket\"]\n\n\t// Require Content-Length to be set in the request\n\tsize := r.ContentLength\n\tif size < 0 {\n\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(ErrMissingContentLength), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\tresource, err := getResource(r.URL.Path, r.Host, globalDomainNames)\n\tif err != nil {\n\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(ErrInvalidRequest), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\t// Make sure that the URL  does not contain object name.\n\tif bucket != filepath.Clean(resource[1:]) {\n\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(ErrMethodNotAllowed), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\t// Here the parameter is the size of the form data that should\n\t// be loaded in memory, the remaining being put in temporary files.\n\treader, err := r.MultipartReader()\n\tif err != nil {\n\t\tlogger.LogIf(ctx, err)\n\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(ErrMalformedPOSTRequest), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\t// Read multipart data and save in memory and in the disk if needed\n\tform, err := reader.ReadForm(maxFormMemory)\n\tif err != nil {\n\t\tlogger.LogIf(ctx, err, logger.Application)\n\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(ErrMalformedPOSTRequest), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\t// Remove all tmp files created during multipart upload\n\tdefer form.RemoveAll()\n\n\t// Extract all form fields\n\tfileBody, fileName, fileSize, formValues, err := extractPostPolicyFormValues(ctx, form)\n\tif err != nil {\n\t\tlogger.LogIf(ctx, err, logger.Application)\n\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(ErrMalformedPOSTRequest), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\t// Check if file is provided, error out otherwise.\n\tif fileBody == nil {\n\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(ErrPOSTFileRequired), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\t// Close multipart file\n\tdefer fileBody.Close()\n\n\tformValues.Set(\"Bucket\", bucket)\n\n\tif fileName != \"\" && strings.Contains(formValues.Get(\"Key\"), \"${filename}\") {\n\t\t// S3 feature to replace ${filename} found in Key form field\n\t\t// by the filename attribute passed in multipart\n\t\tformValues.Set(\"Key\", strings.Replace(formValues.Get(\"Key\"), \"${filename}\", fileName, -1))\n\t}\n\tobject := formValues.Get(\"Key\")\n\n\tsuccessRedirect := formValues.Get(\"success_action_redirect\")\n\tsuccessStatus := formValues.Get(\"success_action_status\")\n\tvar redirectURL *url.URL\n\tif successRedirect != \"\" {\n\t\tredirectURL, err = url.Parse(successRedirect)\n\t\tif err != nil {\n\t\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(ErrMalformedPOSTRequest), r.URL, guessIsBrowserReq(r))\n\t\t\treturn\n\t\t}\n\t}\n\n\t// Verify policy signature.\n\terrCode := doesPolicySignatureMatch(formValues)\n\tif errCode != ErrNone {\n\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(errCode), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\tpolicyBytes, err := base64.StdEncoding.DecodeString(formValues.Get(\"Policy\"))\n\tif err != nil {\n\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(ErrMalformedPOSTRequest), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\t// Handle policy if it is set.\n\tif len(policyBytes) > 0 {\n\n\t\tpostPolicyForm, err := parsePostPolicyForm(string(policyBytes))\n\t\tif err != nil {\n\t\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(ErrPostPolicyConditionInvalidFormat), r.URL, guessIsBrowserReq(r))\n\t\t\treturn\n\t\t}\n\n\t\t// Make sure formValues adhere to policy restrictions.\n\t\tif err = checkPostPolicy(formValues, postPolicyForm); err != nil {\n\t\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErrWithErr(ErrAccessDenied, err), r.URL, guessIsBrowserReq(r))\n\t\t\treturn\n\t\t}\n\n\t\t// Ensure that the object size is within expected range, also the file size\n\t\t// should not exceed the maximum single Put size (5 GiB)\n\t\tlengthRange := postPolicyForm.Conditions.ContentLengthRange\n\t\tif lengthRange.Valid {\n\t\t\tif fileSize < lengthRange.Min {\n\t\t\t\twriteErrorResponse(ctx, w, toAPIError(ctx, errDataTooSmall), r.URL, guessIsBrowserReq(r))\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\tif fileSize > lengthRange.Max || isMaxObjectSize(fileSize) {\n\t\t\t\twriteErrorResponse(ctx, w, toAPIError(ctx, errDataTooLarge), r.URL, guessIsBrowserReq(r))\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\t}\n\n\t// Extract metadata to be saved from received Form.\n\tmetadata := make(map[string]string)\n\terr = extractMetadataFromMime(ctx, textproto.MIMEHeader(formValues), metadata)\n\tif err != nil {\n\t\twriteErrorResponse(ctx, w, toAPIError(ctx, err), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\thashReader, err := hash.NewReader(fileBody, fileSize, \"\", \"\", fileSize)\n\tif err != nil {\n\t\tlogger.LogIf(ctx, err)\n\t\twriteErrorResponse(ctx, w, toAPIError(ctx, err), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\trawReader := hashReader\n\tpReader := NewPutObjReader(rawReader)\n\tvar objectEncryptionKey crypto.ObjectKey\n\n\t// Check if bucket encryption is enabled\n\tif _, err = globalBucketSSEConfigSys.Get(bucket); err == nil || globalAutoEncryption {\n\t\t// This request header needs to be set prior to setting ObjectOptions\n\t\tif !crypto.SSEC.IsRequested(r.Header) {\n\t\t\tr.Header.Set(xhttp.AmzServerSideEncryption, xhttp.AmzEncryptionAES)\n\t\t}\n\t}\n\n\t// get gateway encryption options\n\tvar opts ObjectOptions\n\topts, err = putOpts(ctx, r, bucket, object, metadata)\n\tif err != nil {\n\t\twriteErrorResponseHeadersOnly(w, toAPIError(ctx, err))\n\t\treturn\n\t}\n\tif objectAPI.IsEncryptionSupported() {\n\t\tif _, ok := crypto.IsRequested(formValues); ok && !HasSuffix(object, SlashSeparator) { // handle SSE requests\n\t\t\tif crypto.SSECopy.IsRequested(r.Header) {\n\t\t\t\twriteErrorResponse(ctx, w, toAPIError(ctx, errInvalidEncryptionParameters), r.URL, guessIsBrowserReq(r))\n\t\t\t\treturn\n\t\t\t}\n\t\t\tvar reader io.Reader\n\t\t\tvar key []byte\n\t\t\tif crypto.SSEC.IsRequested(formValues) {\n\t\t\t\tkey, err = ParseSSECustomerHeader(formValues)\n\t\t\t\tif err != nil {\n\t\t\t\t\twriteErrorResponse(ctx, w, toAPIError(ctx, err), r.URL, guessIsBrowserReq(r))\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t}\n\t\t\treader, objectEncryptionKey, err = newEncryptReader(hashReader, key, bucket, object, metadata, crypto.S3.IsRequested(formValues))\n\t\t\tif err != nil {\n\t\t\t\twriteErrorResponse(ctx, w, toAPIError(ctx, err), r.URL, guessIsBrowserReq(r))\n\t\t\t\treturn\n\t\t\t}\n\t\t\tinfo := ObjectInfo{Size: fileSize}\n\t\t\t// do not try to verify encrypted content\n\t\t\thashReader, err = hash.NewReader(reader, info.EncryptedSize(), \"\", \"\", fileSize)\n\t\t\tif err != nil {\n\t\t\t\twriteErrorResponse(ctx, w, toAPIError(ctx, err), r.URL, guessIsBrowserReq(r))\n\t\t\t\treturn\n\t\t\t}\n\t\t\tpReader, err = pReader.WithEncryption(hashReader, &objectEncryptionKey)\n\t\t\tif err != nil {\n\t\t\t\twriteErrorResponse(ctx, w, toAPIError(ctx, err), r.URL, guessIsBrowserReq(r))\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\t}\n\n\tobjInfo, err := objectAPI.PutObject(ctx, bucket, object, pReader, opts)\n\tif err != nil {\n\t\twriteErrorResponse(ctx, w, toAPIError(ctx, err), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\t// We must not use the http.Header().Set method here because some (broken)\n\t// clients expect the ETag header key to be literally \"ETag\" - not \"Etag\" (case-sensitive).\n\t// Therefore, we have to set the ETag directly as map entry.\n\tw.Header()[xhttp.ETag] = []string{`\"` + objInfo.ETag + `\"`}\n\n\t// Set the relevant version ID as part of the response header.\n\tif objInfo.VersionID != \"\" {\n\t\tw.Header()[xhttp.AmzVersionID] = []string{objInfo.VersionID}\n\t}\n\n\tw.Header().Set(xhttp.Location, getObjectLocation(r, globalDomainNames, bucket, object))\n\n\t// Notify object created event.\n\tdefer sendEvent(eventArgs{\n\t\tEventName:    event.ObjectCreatedPost,\n\t\tBucketName:   objInfo.Bucket,\n\t\tObject:       objInfo,\n\t\tReqParams:    extractReqParams(r),\n\t\tRespElements: extractRespElements(w),\n\t\tUserAgent:    r.UserAgent(),\n\t\tHost:         handlers.GetSourceIP(r),\n\t})\n\n\tif successRedirect != \"\" {\n\t\t// Replace raw query params..\n\t\tredirectURL.RawQuery = getRedirectPostRawQuery(objInfo)\n\t\twriteRedirectSeeOther(w, redirectURL.String())\n\t\treturn\n\t}\n\n\t// Decide what http response to send depending on success_action_status parameter\n\tswitch successStatus {\n\tcase \"201\":\n\t\tresp := encodeResponse(PostResponse{\n\t\t\tBucket:   objInfo.Bucket,\n\t\t\tKey:      objInfo.Name,\n\t\t\tETag:     `\"` + objInfo.ETag + `\"`,\n\t\t\tLocation: w.Header().Get(xhttp.Location),\n\t\t})\n\t\twriteResponse(w, http.StatusCreated, resp, mimeXML)\n\tcase \"200\":\n\t\twriteSuccessResponseHeadersOnly(w)\n\tdefault:\n\t\twriteSuccessNoContent(w)\n\t}\n}\n\n// GetBucketPolicyStatusHandler -  Retrieves the policy status\n// for an MinIO bucket, indicating whether the bucket is public.\nfunc (api objectAPIHandlers) GetBucketPolicyStatusHandler(w http.ResponseWriter, r *http.Request) {\n\tctx := newContext(r, w, \"GetBucketPolicyStatus\")\n\n\tdefer logger.AuditLog(ctx, w, r, mustGetClaimsFromToken(r))\n\n\tvars := mux.Vars(r)\n\tbucket := vars[\"bucket\"]\n\n\tobjectAPI := api.ObjectAPI()\n\tif objectAPI == nil {\n\t\twriteErrorResponseHeadersOnly(w, errorCodes.ToAPIErr(ErrServerNotInitialized))\n\t\treturn\n\t}\n\n\tif s3Error := checkRequestAuthType(ctx, r, policy.GetBucketPolicyStatusAction, bucket, \"\"); s3Error != ErrNone {\n\t\twriteErrorResponseHeadersOnly(w, errorCodes.ToAPIErr(s3Error))\n\t\treturn\n\t}\n\n\t// Check if bucket exists.\n\tif _, err := objectAPI.GetBucketInfo(ctx, bucket); err != nil {\n\t\twriteErrorResponse(ctx, w, toAPIError(ctx, err), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\t// Check if anonymous (non-owner) has access to list objects.\n\treadable := globalPolicySys.IsAllowed(policy.Args{\n\t\tAction:          policy.ListBucketAction,\n\t\tBucketName:      bucket,\n\t\tConditionValues: getConditionValues(r, \"\", \"\", nil),\n\t\tIsOwner:         false,\n\t})\n\n\t// Check if anonymous (non-owner) has access to upload objects.\n\twritable := globalPolicySys.IsAllowed(policy.Args{\n\t\tAction:          policy.PutObjectAction,\n\t\tBucketName:      bucket,\n\t\tConditionValues: getConditionValues(r, \"\", \"\", nil),\n\t\tIsOwner:         false,\n\t})\n\n\tencodedSuccessResponse := encodeResponse(PolicyStatus{\n\t\tIsPublic: func() string {\n\t\t\t// Silly to have special 'boolean' values yes\n\t\t\t// but complying with silly implementation\n\t\t\t// https://docs.aws.amazon.com/AmazonS3/latest/API/API_GetBucketPolicyStatus.html\n\t\t\tif readable && writable {\n\t\t\t\treturn \"TRUE\"\n\t\t\t}\n\t\t\treturn \"FALSE\"\n\t\t}(),\n\t})\n\n\twriteSuccessResponseXML(w, encodedSuccessResponse)\n}\n\n// HeadBucketHandler - HEAD Bucket\n// ----------\n// This operation is useful to determine if a bucket exists.\n// The operation returns a 200 OK if the bucket exists and you\n// have permission to access it. Otherwise, the operation might\n// return responses such as 404 Not Found and 403 Forbidden.\nfunc (api objectAPIHandlers) HeadBucketHandler(w http.ResponseWriter, r *http.Request) {\n\tctx := newContext(r, w, \"HeadBucket\")\n\n\tdefer logger.AuditLog(ctx, w, r, mustGetClaimsFromToken(r))\n\n\tvars := mux.Vars(r)\n\tbucket := vars[\"bucket\"]\n\n\tobjectAPI := api.ObjectAPI()\n\tif objectAPI == nil {\n\t\twriteErrorResponseHeadersOnly(w, errorCodes.ToAPIErr(ErrServerNotInitialized))\n\t\treturn\n\t}\n\n\tif s3Error := checkRequestAuthType(ctx, r, policy.ListBucketAction, bucket, \"\"); s3Error != ErrNone {\n\t\twriteErrorResponseHeadersOnly(w, errorCodes.ToAPIErr(s3Error))\n\t\treturn\n\t}\n\n\tgetBucketInfo := objectAPI.GetBucketInfo\n\n\tif _, err := getBucketInfo(ctx, bucket); err != nil {\n\t\twriteErrorResponseHeadersOnly(w, toAPIError(ctx, err))\n\t\treturn\n\t}\n\n\twriteSuccessResponseHeadersOnly(w)\n}\n\n// DeleteBucketHandler - Delete bucket\nfunc (api objectAPIHandlers) DeleteBucketHandler(w http.ResponseWriter, r *http.Request) {\n\tctx := newContext(r, w, \"DeleteBucket\")\n\n\tdefer logger.AuditLog(ctx, w, r, mustGetClaimsFromToken(r))\n\n\tvars := mux.Vars(r)\n\tbucket := vars[\"bucket\"]\n\n\tobjectAPI := api.ObjectAPI()\n\tif objectAPI == nil {\n\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(ErrServerNotInitialized), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\t// Verify if the caller has sufficient permissions.\n\tif s3Error := checkRequestAuthType(ctx, r, policy.DeleteBucketAction, bucket, \"\"); s3Error != ErrNone {\n\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(s3Error), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\tforceDelete := false\n\tif value := r.Header.Get(xhttp.MinIOForceDelete); value != \"\" {\n\t\tvar err error\n\t\tforceDelete, err = strconv.ParseBool(value)\n\t\tif err != nil {\n\t\t\tapiErr := errorCodes.ToAPIErr(ErrInvalidRequest)\n\t\t\tapiErr.Description = err.Error()\n\t\t\twriteErrorResponse(ctx, w, apiErr, r.URL, guessIsBrowserReq(r))\n\t\t\treturn\n\t\t}\n\n\t\t// if force delete header is set, we need to evaluate the policy anyways\n\t\t// regardless of it being true or not.\n\t\tif s3Error := checkRequestAuthType(ctx, r, policy.ForceDeleteBucketAction, bucket, \"\"); s3Error != ErrNone {\n\t\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(s3Error), r.URL, guessIsBrowserReq(r))\n\t\t\treturn\n\t\t}\n\n\t\tif forceDelete {\n\t\t\tif rcfg, _ := globalBucketObjectLockSys.Get(bucket); rcfg.LockEnabled {\n\t\t\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(ErrMethodNotAllowed), r.URL, guessIsBrowserReq(r))\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\t}\n\n\tdeleteBucket := objectAPI.DeleteBucket\n\n\t// Attempt to delete bucket.\n\tif err := deleteBucket(ctx, bucket, forceDelete); err != nil {\n\t\tif _, ok := err.(BucketNotEmpty); ok && (globalBucketVersioningSys.Enabled(bucket) || globalBucketVersioningSys.Suspended(bucket)) {\n\t\t\tapiErr := toAPIError(ctx, err)\n\t\t\tapiErr.Description = \"The bucket you tried to delete is not empty. You must delete all versions in the bucket.\"\n\t\t\twriteErrorResponse(ctx, w, apiErr, r.URL, guessIsBrowserReq(r))\n\t\t} else {\n\t\t\twriteErrorResponse(ctx, w, toAPIError(ctx, err), r.URL, guessIsBrowserReq(r))\n\t\t}\n\t\treturn\n\t}\n\n\tglobalNotificationSys.DeleteBucketMetadata(ctx, bucket)\n\n\tif globalDNSConfig != nil {\n\t\tif err := globalDNSConfig.Delete(bucket); err != nil {\n\t\t\tlogger.LogIf(ctx, fmt.Errorf(\"Unable to delete bucket DNS entry %w, please delete it manually\", err))\n\t\t\twriteErrorResponse(ctx, w, toAPIError(ctx, err), r.URL, guessIsBrowserReq(r))\n\t\t\treturn\n\t\t}\n\t}\n\n\t// Write success response.\n\twriteSuccessNoContent(w)\n\n\tsendEvent(eventArgs{\n\t\tEventName:    event.BucketRemoved,\n\t\tBucketName:   bucket,\n\t\tReqParams:    extractReqParams(r),\n\t\tRespElements: extractRespElements(w),\n\t\tUserAgent:    r.UserAgent(),\n\t\tHost:         handlers.GetSourceIP(r),\n\t})\n}\n\n// PutBucketObjectLockConfigHandler - PUT Bucket object lock configuration.\n// ----------\n// Places an Object Lock configuration on the specified bucket. The rule\n// specified in the Object Lock configuration will be applied by default\n// to every new object placed in the specified bucket.\nfunc (api objectAPIHandlers) PutBucketObjectLockConfigHandler(w http.ResponseWriter, r *http.Request) {\n\tctx := newContext(r, w, \"PutBucketObjectLockConfig\")\n\n\tdefer logger.AuditLog(ctx, w, r, mustGetClaimsFromToken(r))\n\n\tvars := mux.Vars(r)\n\tbucket := vars[\"bucket\"]\n\n\tobjectAPI := api.ObjectAPI()\n\tif objectAPI == nil {\n\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(ErrServerNotInitialized), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\tif !globalIsErasure {\n\t\twriteErrorResponseJSON(ctx, w, errorCodes.ToAPIErr(ErrNotImplemented), r.URL)\n\t\treturn\n\t}\n\tif s3Error := checkRequestAuthType(ctx, r, policy.PutBucketObjectLockConfigurationAction, bucket, \"\"); s3Error != ErrNone {\n\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(s3Error), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\tconfig, err := objectlock.ParseObjectLockConfig(r.Body)\n\tif err != nil {\n\t\tapiErr := errorCodes.ToAPIErr(ErrMalformedXML)\n\t\tapiErr.Description = err.Error()\n\t\twriteErrorResponse(ctx, w, apiErr, r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\tconfigData, err := xml.Marshal(config)\n\tif err != nil {\n\t\twriteErrorResponse(ctx, w, toAPIError(ctx, err), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\t// Deny object locking configuration settings on existing buckets without object lock enabled.\n\tif _, err = globalBucketMetadataSys.GetObjectLockConfig(bucket); err != nil {\n\t\twriteErrorResponse(ctx, w, toAPIError(ctx, err), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\tif err = globalBucketMetadataSys.Update(bucket, objectLockConfig, configData); err != nil {\n\t\twriteErrorResponse(ctx, w, toAPIError(ctx, err), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\t// Write success response.\n\twriteSuccessResponseHeadersOnly(w)\n}\n\n// GetBucketObjectLockConfigHandler - GET Bucket object lock configuration.\n// ----------\n// Gets the Object Lock configuration for a bucket. The rule specified in\n// the Object Lock configuration will be applied by default to every new\n// object placed in the specified bucket.\nfunc (api objectAPIHandlers) GetBucketObjectLockConfigHandler(w http.ResponseWriter, r *http.Request) {\n\tctx := newContext(r, w, \"GetBucketObjectLockConfig\")\n\n\tdefer logger.AuditLog(ctx, w, r, mustGetClaimsFromToken(r))\n\n\tvars := mux.Vars(r)\n\tbucket := vars[\"bucket\"]\n\n\tobjectAPI := api.ObjectAPI()\n\tif objectAPI == nil {\n\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(ErrServerNotInitialized), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\t// check if user has permissions to perform this operation\n\tif s3Error := checkRequestAuthType(ctx, r, policy.GetBucketObjectLockConfigurationAction, bucket, \"\"); s3Error != ErrNone {\n\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(s3Error), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\tconfig, err := globalBucketMetadataSys.GetObjectLockConfig(bucket)\n\tif err != nil {\n\t\twriteErrorResponse(ctx, w, toAPIError(ctx, err), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\tconfigData, err := xml.Marshal(config)\n\tif err != nil {\n\t\twriteErrorResponse(ctx, w, toAPIError(ctx, err), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\t// Write success response.\n\twriteSuccessResponseXML(w, configData)\n}\n\n// PutBucketTaggingHandler - PUT Bucket tagging.\n// ----------\nfunc (api objectAPIHandlers) PutBucketTaggingHandler(w http.ResponseWriter, r *http.Request) {\n\tctx := newContext(r, w, \"PutBucketTagging\")\n\n\tdefer logger.AuditLog(ctx, w, r, mustGetClaimsFromToken(r))\n\n\tvars := mux.Vars(r)\n\tbucket := vars[\"bucket\"]\n\n\tobjectAPI := api.ObjectAPI()\n\tif objectAPI == nil {\n\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(ErrServerNotInitialized), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\tif s3Error := checkRequestAuthType(ctx, r, policy.PutBucketTaggingAction, bucket, \"\"); s3Error != ErrNone {\n\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(s3Error), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\ttags, err := tags.ParseBucketXML(io.LimitReader(r.Body, r.ContentLength))\n\tif err != nil {\n\t\tapiErr := errorCodes.ToAPIErr(ErrMalformedXML)\n\t\tapiErr.Description = err.Error()\n\t\twriteErrorResponse(ctx, w, apiErr, r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\tconfigData, err := xml.Marshal(tags)\n\tif err != nil {\n\t\twriteErrorResponse(ctx, w, toAPIError(ctx, err), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\tif err = globalBucketMetadataSys.Update(bucket, bucketTaggingConfig, configData); err != nil {\n\t\twriteErrorResponse(ctx, w, toAPIError(ctx, err), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\t// Write success response.\n\twriteSuccessResponseHeadersOnly(w)\n}\n\n// GetBucketTaggingHandler - GET Bucket tagging.\n// ----------\nfunc (api objectAPIHandlers) GetBucketTaggingHandler(w http.ResponseWriter, r *http.Request) {\n\tctx := newContext(r, w, \"GetBucketTagging\")\n\n\tdefer logger.AuditLog(ctx, w, r, mustGetClaimsFromToken(r))\n\n\tvars := mux.Vars(r)\n\tbucket := vars[\"bucket\"]\n\n\tobjectAPI := api.ObjectAPI()\n\tif objectAPI == nil {\n\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(ErrServerNotInitialized), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\t// check if user has permissions to perform this operation\n\tif s3Error := checkRequestAuthType(ctx, r, policy.GetBucketTaggingAction, bucket, \"\"); s3Error != ErrNone {\n\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(s3Error), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\tconfig, err := globalBucketMetadataSys.GetTaggingConfig(bucket)\n\tif err != nil {\n\t\twriteErrorResponse(ctx, w, toAPIError(ctx, err), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\tconfigData, err := xml.Marshal(config)\n\tif err != nil {\n\t\twriteErrorResponse(ctx, w, toAPIError(ctx, err), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\t// Write success response.\n\twriteSuccessResponseXML(w, configData)\n}\n\n// DeleteBucketTaggingHandler - DELETE Bucket tagging.\n// ----------\nfunc (api objectAPIHandlers) DeleteBucketTaggingHandler(w http.ResponseWriter, r *http.Request) {\n\tctx := newContext(r, w, \"DeleteBucketTagging\")\n\n\tdefer logger.AuditLog(ctx, w, r, mustGetClaimsFromToken(r))\n\n\tvars := mux.Vars(r)\n\tbucket := vars[\"bucket\"]\n\n\tobjectAPI := api.ObjectAPI()\n\tif objectAPI == nil {\n\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(ErrServerNotInitialized), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\tif s3Error := checkRequestAuthType(ctx, r, policy.PutBucketTaggingAction, bucket, \"\"); s3Error != ErrNone {\n\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(s3Error), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\tif err := globalBucketMetadataSys.Update(bucket, bucketTaggingConfig, nil); err != nil {\n\t\twriteErrorResponse(ctx, w, toAPIError(ctx, err), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\t// Write success response.\n\twriteSuccessResponseHeadersOnly(w)\n}\n\n// PutBucketReplicationConfigHandler - PUT Bucket replication configuration.\n// ----------\n// Add a replication configuration on the specified bucket as specified in https://docs.aws.amazon.com/AmazonS3/latest/API/API_PutBucketReplication.html\nfunc (api objectAPIHandlers) PutBucketReplicationConfigHandler(w http.ResponseWriter, r *http.Request) {\n\tctx := newContext(r, w, \"PutBucketReplicationConfig\")\n\tdefer logger.AuditLog(ctx, w, r, mustGetClaimsFromToken(r))\n\n\tvars := mux.Vars(r)\n\tbucket := vars[\"bucket\"]\n\tobjectAPI := api.ObjectAPI()\n\tif objectAPI == nil {\n\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(ErrServerNotInitialized), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\tif !globalIsErasure {\n\t\twriteErrorResponseJSON(ctx, w, errorCodes.ToAPIErr(ErrNotImplemented), r.URL)\n\t\treturn\n\t}\n\tif s3Error := checkRequestAuthType(ctx, r, policy.PutReplicationConfigurationAction, bucket, \"\"); s3Error != ErrNone {\n\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(s3Error), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\t// Check if bucket exists.\n\tif _, err := objectAPI.GetBucketInfo(ctx, bucket); err != nil {\n\t\twriteErrorResponse(ctx, w, toAPIError(ctx, err), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\tif versioned := globalBucketVersioningSys.Enabled(bucket); !versioned {\n\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(ErrReplicationNeedsVersioningError), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\treplicationConfig, err := replication.ParseConfig(io.LimitReader(r.Body, r.ContentLength))\n\tif err != nil {\n\t\tapiErr := errorCodes.ToAPIErr(ErrMalformedXML)\n\t\tapiErr.Description = err.Error()\n\t\twriteErrorResponse(ctx, w, apiErr, r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\tsameTarget, err := validateReplicationDestination(ctx, bucket, replicationConfig)\n\tif err != nil {\n\t\twriteErrorResponse(ctx, w, toAPIError(ctx, err), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\t// Validate the received bucket replication config\n\tif err = replicationConfig.Validate(bucket, sameTarget); err != nil {\n\t\twriteErrorResponse(ctx, w, toAPIError(ctx, err), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\tconfigData, err := xml.Marshal(replicationConfig)\n\tif err != nil {\n\t\twriteErrorResponse(ctx, w, toAPIError(ctx, err), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\tif err = globalBucketMetadataSys.Update(bucket, bucketReplicationConfig, configData); err != nil {\n\t\twriteErrorResponse(ctx, w, toAPIError(ctx, err), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\t// Write success response.\n\twriteSuccessResponseHeadersOnly(w)\n}\n\n// GetBucketReplicationConfigHandler - GET Bucket replication configuration.\n// ----------\n// Gets the replication configuration for a bucket.\nfunc (api objectAPIHandlers) GetBucketReplicationConfigHandler(w http.ResponseWriter, r *http.Request) {\n\tctx := newContext(r, w, \"GetBucketReplicationConfig\")\n\n\tdefer logger.AuditLog(ctx, w, r, mustGetClaimsFromToken(r))\n\n\tvars := mux.Vars(r)\n\tbucket := vars[\"bucket\"]\n\n\tobjectAPI := api.ObjectAPI()\n\tif objectAPI == nil {\n\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(ErrServerNotInitialized), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\t// check if user has permissions to perform this operation\n\tif s3Error := checkRequestAuthType(ctx, r, policy.GetReplicationConfigurationAction, bucket, \"\"); s3Error != ErrNone {\n\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(s3Error), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\t// Check if bucket exists.\n\tif _, err := objectAPI.GetBucketInfo(ctx, bucket); err != nil {\n\t\twriteErrorResponse(ctx, w, toAPIError(ctx, err), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\tconfig, err := globalBucketMetadataSys.GetReplicationConfig(ctx, bucket)\n\tif err != nil {\n\t\twriteErrorResponse(ctx, w, toAPIError(ctx, err), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\tconfigData, err := xml.Marshal(config)\n\tif err != nil {\n\t\twriteErrorResponse(ctx, w, toAPIError(ctx, err), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\t// Write success response.\n\twriteSuccessResponseXML(w, configData)\n}\n\n// DeleteBucketReplicationConfigHandler - DELETE Bucket replication config.\n// ----------\nfunc (api objectAPIHandlers) DeleteBucketReplicationConfigHandler(w http.ResponseWriter, r *http.Request) {\n\tctx := newContext(r, w, \"DeleteBucketReplicationConfig\")\n\tdefer logger.AuditLog(ctx, w, r, mustGetClaimsFromToken(r))\n\tvars := mux.Vars(r)\n\tbucket := vars[\"bucket\"]\n\n\tobjectAPI := api.ObjectAPI()\n\tif objectAPI == nil {\n\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(ErrServerNotInitialized), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\tif s3Error := checkRequestAuthType(ctx, r, policy.PutReplicationConfigurationAction, bucket, \"\"); s3Error != ErrNone {\n\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(s3Error), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\t// Check if bucket exists.\n\tif _, err := objectAPI.GetBucketInfo(ctx, bucket); err != nil {\n\t\twriteErrorResponse(ctx, w, toAPIError(ctx, err), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\tif err := globalBucketMetadataSys.Update(bucket, bucketReplicationConfig, nil); err != nil {\n\t\twriteErrorResponse(ctx, w, toAPIError(ctx, err), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\t// Write success response.\n\twriteSuccessResponseHeadersOnly(w)\n}\n", "/*\n * MinIO Cloud Storage, (C) 2016, 2017 MinIO, Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\npackage cmd\n\nimport (\n\t\"crypto/hmac\"\n\t\"crypto/sha1\"\n\t\"crypto/subtle\"\n\t\"encoding/base64\"\n\t\"fmt\"\n\t\"net/http\"\n\t\"net/url\"\n\t\"sort\"\n\t\"strconv\"\n\t\"strings\"\n\n\txhttp \"github.com/minio/minio/cmd/http\"\n\n\t\"github.com/minio/minio/pkg/auth\"\n)\n\n// Whitelist resource list that will be used in query string for signature-V2 calculation.\n//\n// This list should be kept alphabetically sorted, do not hastily edit.\nvar resourceList = []string{\n\t\"acl\",\n\t\"cors\",\n\t\"delete\",\n\t\"encryption\",\n\t\"legal-hold\",\n\t\"lifecycle\",\n\t\"location\",\n\t\"logging\",\n\t\"notification\",\n\t\"partNumber\",\n\t\"policy\",\n\t\"requestPayment\",\n\t\"response-cache-control\",\n\t\"response-content-disposition\",\n\t\"response-content-encoding\",\n\t\"response-content-language\",\n\t\"response-content-type\",\n\t\"response-expires\",\n\t\"retention\",\n\t\"select\",\n\t\"select-type\",\n\t\"tagging\",\n\t\"torrent\",\n\t\"uploadId\",\n\t\"uploads\",\n\t\"versionId\",\n\t\"versioning\",\n\t\"versions\",\n\t\"website\",\n}\n\n// Signature and API related constants.\nconst (\n\tsignV2Algorithm = \"AWS\"\n)\n\n// AWS S3 Signature V2 calculation rule is give here:\n// http://docs.aws.amazon.com/AmazonS3/latest/dev/RESTAuthentication.html#RESTAuthenticationStringToSign\n\nfunc doesPolicySignatureV2Match(formValues http.Header) APIErrorCode {\n\tcred := globalActiveCred\n\taccessKey := formValues.Get(xhttp.AmzAccessKeyID)\n\tcred, _, s3Err := checkKeyValid(accessKey)\n\tif s3Err != ErrNone {\n\t\treturn s3Err\n\t}\n\tpolicy := formValues.Get(\"Policy\")\n\tsignature := formValues.Get(xhttp.AmzSignatureV2)\n\tif !compareSignatureV2(signature, calculateSignatureV2(policy, cred.SecretKey)) {\n\t\treturn ErrSignatureDoesNotMatch\n\t}\n\treturn ErrNone\n}\n\n// Escape encodedQuery string into unescaped list of query params, returns error\n// if any while unescaping the values.\nfunc unescapeQueries(encodedQuery string) (unescapedQueries []string, err error) {\n\tfor _, query := range strings.Split(encodedQuery, \"&\") {\n\t\tvar unescapedQuery string\n\t\tunescapedQuery, err = url.QueryUnescape(query)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tunescapedQueries = append(unescapedQueries, unescapedQuery)\n\t}\n\treturn unescapedQueries, nil\n}\n\n// doesPresignV2SignatureMatch - Verify query headers with presigned signature\n//     - http://docs.aws.amazon.com/AmazonS3/latest/dev/RESTAuthentication.html#RESTAuthenticationQueryStringAuth\n// returns ErrNone if matches. S3 errors otherwise.\nfunc doesPresignV2SignatureMatch(r *http.Request) APIErrorCode {\n\t// r.RequestURI will have raw encoded URI as sent by the client.\n\ttokens := strings.SplitN(r.RequestURI, \"?\", 2)\n\tencodedResource := tokens[0]\n\tencodedQuery := \"\"\n\tif len(tokens) == 2 {\n\t\tencodedQuery = tokens[1]\n\t}\n\n\tvar (\n\t\tfilteredQueries []string\n\t\tgotSignature    string\n\t\texpires         string\n\t\taccessKey       string\n\t\terr             error\n\t)\n\n\tvar unescapedQueries []string\n\tunescapedQueries, err = unescapeQueries(encodedQuery)\n\tif err != nil {\n\t\treturn ErrInvalidQueryParams\n\t}\n\n\t// Extract the necessary values from presigned query, construct a list of new filtered queries.\n\tfor _, query := range unescapedQueries {\n\t\tkeyval := strings.SplitN(query, \"=\", 2)\n\t\tif len(keyval) != 2 {\n\t\t\treturn ErrInvalidQueryParams\n\t\t}\n\t\tswitch keyval[0] {\n\t\tcase xhttp.AmzAccessKeyID:\n\t\t\taccessKey = keyval[1]\n\t\tcase xhttp.AmzSignatureV2:\n\t\t\tgotSignature = keyval[1]\n\t\tcase xhttp.Expires:\n\t\t\texpires = keyval[1]\n\t\tdefault:\n\t\t\tfilteredQueries = append(filteredQueries, query)\n\t\t}\n\t}\n\n\t// Invalid values returns error.\n\tif accessKey == \"\" || gotSignature == \"\" || expires == \"\" {\n\t\treturn ErrInvalidQueryParams\n\t}\n\n\tcred, _, s3Err := checkKeyValid(accessKey)\n\tif s3Err != ErrNone {\n\t\treturn s3Err\n\t}\n\n\t// Make sure the request has not expired.\n\texpiresInt, err := strconv.ParseInt(expires, 10, 64)\n\tif err != nil {\n\t\treturn ErrMalformedExpires\n\t}\n\n\t// Check if the presigned URL has expired.\n\tif expiresInt < UTCNow().Unix() {\n\t\treturn ErrExpiredPresignRequest\n\t}\n\n\tencodedResource, err = getResource(encodedResource, r.Host, globalDomainNames)\n\tif err != nil {\n\t\treturn ErrInvalidRequest\n\t}\n\n\texpectedSignature := preSignatureV2(cred, r.Method, encodedResource, strings.Join(filteredQueries, \"&\"), r.Header, expires)\n\tif !compareSignatureV2(gotSignature, expectedSignature) {\n\t\treturn ErrSignatureDoesNotMatch\n\t}\n\n\treturn ErrNone\n}\n\nfunc getReqAccessKeyV2(r *http.Request) (auth.Credentials, bool, APIErrorCode) {\n\tif accessKey := r.URL.Query().Get(xhttp.AmzAccessKeyID); accessKey != \"\" {\n\t\treturn checkKeyValid(accessKey)\n\t}\n\n\t// below is V2 Signed Auth header format, splitting on `space` (after the `AWS` string).\n\t// Authorization = \"AWS\" + \" \" + AWSAccessKeyId + \":\" + Signature\n\tauthFields := strings.Split(r.Header.Get(xhttp.Authorization), \" \")\n\tif len(authFields) != 2 {\n\t\treturn auth.Credentials{}, false, ErrMissingFields\n\t}\n\n\t// Then will be splitting on \":\", this will seprate `AWSAccessKeyId` and `Signature` string.\n\tkeySignFields := strings.Split(strings.TrimSpace(authFields[1]), \":\")\n\tif len(keySignFields) != 2 {\n\t\treturn auth.Credentials{}, false, ErrMissingFields\n\t}\n\n\treturn checkKeyValid(keySignFields[0])\n}\n\n// Authorization = \"AWS\" + \" \" + AWSAccessKeyId + \":\" + Signature;\n// Signature = Base64( HMAC-SHA1( YourSecretKey, UTF-8-Encoding-Of( StringToSign ) ) );\n//\n// StringToSign = HTTP-Verb + \"\\n\" +\n//  \tContent-Md5 + \"\\n\" +\n//  \tContent-Type + \"\\n\" +\n//  \tDate + \"\\n\" +\n//  \tCanonicalizedProtocolHeaders +\n//  \tCanonicalizedResource;\n//\n// CanonicalizedResource = [ SlashSeparator + Bucket ] +\n//  \t<HTTP-Request-URI, from the protocol name up to the query string> +\n//  \t[ subresource, if present. For example \"?acl\", \"?location\", \"?logging\", or \"?torrent\"];\n//\n// CanonicalizedProtocolHeaders = <described below>\n\n// doesSignV2Match - Verify authorization header with calculated header in accordance with\n//     - http://docs.aws.amazon.com/AmazonS3/latest/dev/auth-request-sig-v2.html\n// returns true if matches, false otherwise. if error is not nil then it is always false\n\nfunc validateV2AuthHeader(r *http.Request) (auth.Credentials, APIErrorCode) {\n\tvar cred auth.Credentials\n\tv2Auth := r.Header.Get(xhttp.Authorization)\n\tif v2Auth == \"\" {\n\t\treturn cred, ErrAuthHeaderEmpty\n\t}\n\n\t// Verify if the header algorithm is supported or not.\n\tif !strings.HasPrefix(v2Auth, signV2Algorithm) {\n\t\treturn cred, ErrSignatureVersionNotSupported\n\t}\n\n\tcred, _, apiErr := getReqAccessKeyV2(r)\n\tif apiErr != ErrNone {\n\t\treturn cred, apiErr\n\t}\n\n\treturn cred, ErrNone\n}\n\nfunc doesSignV2Match(r *http.Request) APIErrorCode {\n\tv2Auth := r.Header.Get(xhttp.Authorization)\n\tcred, apiError := validateV2AuthHeader(r)\n\tif apiError != ErrNone {\n\t\treturn apiError\n\t}\n\n\t// r.RequestURI will have raw encoded URI as sent by the client.\n\ttokens := strings.SplitN(r.RequestURI, \"?\", 2)\n\tencodedResource := tokens[0]\n\tencodedQuery := \"\"\n\tif len(tokens) == 2 {\n\t\tencodedQuery = tokens[1]\n\t}\n\n\tunescapedQueries, err := unescapeQueries(encodedQuery)\n\tif err != nil {\n\t\treturn ErrInvalidQueryParams\n\t}\n\n\tencodedResource, err = getResource(encodedResource, r.Host, globalDomainNames)\n\tif err != nil {\n\t\treturn ErrInvalidRequest\n\t}\n\n\tprefix := fmt.Sprintf(\"%s %s:\", signV2Algorithm, cred.AccessKey)\n\tif !strings.HasPrefix(v2Auth, prefix) {\n\t\treturn ErrSignatureDoesNotMatch\n\t}\n\tv2Auth = v2Auth[len(prefix):]\n\texpectedAuth := signatureV2(cred, r.Method, encodedResource, strings.Join(unescapedQueries, \"&\"), r.Header)\n\tif !compareSignatureV2(v2Auth, expectedAuth) {\n\t\treturn ErrSignatureDoesNotMatch\n\t}\n\treturn ErrNone\n}\n\nfunc calculateSignatureV2(stringToSign string, secret string) string {\n\thm := hmac.New(sha1.New, []byte(secret))\n\thm.Write([]byte(stringToSign))\n\treturn base64.StdEncoding.EncodeToString(hm.Sum(nil))\n}\n\n// Return signature-v2 for the presigned request.\nfunc preSignatureV2(cred auth.Credentials, method string, encodedResource string, encodedQuery string, headers http.Header, expires string) string {\n\tstringToSign := getStringToSignV2(method, encodedResource, encodedQuery, headers, expires)\n\treturn calculateSignatureV2(stringToSign, cred.SecretKey)\n}\n\n// Return the signature v2 of a given request.\nfunc signatureV2(cred auth.Credentials, method string, encodedResource string, encodedQuery string, headers http.Header) string {\n\tstringToSign := getStringToSignV2(method, encodedResource, encodedQuery, headers, \"\")\n\tsignature := calculateSignatureV2(stringToSign, cred.SecretKey)\n\treturn signature\n}\n\n// compareSignatureV2 returns true if and only if both signatures\n// are equal. The signatures are expected to be base64 encoded strings\n// according to the AWS S3 signature V2 spec.\nfunc compareSignatureV2(sig1, sig2 string) bool {\n\t// Decode signature string to binary byte-sequence representation is required\n\t// as Base64 encoding of a value is not unique:\n\t// For example \"aGVsbG8=\" and \"aGVsbG8=\\r\" will result in the same byte slice.\n\tsignature1, err := base64.StdEncoding.DecodeString(sig1)\n\tif err != nil {\n\t\treturn false\n\t}\n\tsignature2, err := base64.StdEncoding.DecodeString(sig2)\n\tif err != nil {\n\t\treturn false\n\t}\n\treturn subtle.ConstantTimeCompare(signature1, signature2) == 1\n}\n\n// Return canonical headers.\nfunc canonicalizedAmzHeadersV2(headers http.Header) string {\n\tvar keys []string\n\tkeyval := make(map[string]string, len(headers))\n\tfor key := range headers {\n\t\tlkey := strings.ToLower(key)\n\t\tif !strings.HasPrefix(lkey, \"x-amz-\") {\n\t\t\tcontinue\n\t\t}\n\t\tkeys = append(keys, lkey)\n\t\tkeyval[lkey] = strings.Join(headers[key], \",\")\n\t}\n\tsort.Strings(keys)\n\tvar canonicalHeaders []string\n\tfor _, key := range keys {\n\t\tcanonicalHeaders = append(canonicalHeaders, key+\":\"+keyval[key])\n\t}\n\treturn strings.Join(canonicalHeaders, \"\\n\")\n}\n\n// Return canonical resource string.\nfunc canonicalizedResourceV2(encodedResource, encodedQuery string) string {\n\tqueries := strings.Split(encodedQuery, \"&\")\n\tkeyval := make(map[string]string)\n\tfor _, query := range queries {\n\t\tkey := query\n\t\tval := \"\"\n\t\tindex := strings.Index(query, \"=\")\n\t\tif index != -1 {\n\t\t\tkey = query[:index]\n\t\t\tval = query[index+1:]\n\t\t}\n\t\tkeyval[key] = val\n\t}\n\n\tvar canonicalQueries []string\n\tfor _, key := range resourceList {\n\t\tval, ok := keyval[key]\n\t\tif !ok {\n\t\t\tcontinue\n\t\t}\n\t\tif val == \"\" {\n\t\t\tcanonicalQueries = append(canonicalQueries, key)\n\t\t\tcontinue\n\t\t}\n\t\tcanonicalQueries = append(canonicalQueries, key+\"=\"+val)\n\t}\n\n\t// The queries will be already sorted as resourceList is sorted, if canonicalQueries\n\t// is empty strings.Join returns empty.\n\tcanonicalQuery := strings.Join(canonicalQueries, \"&\")\n\tif canonicalQuery != \"\" {\n\t\treturn encodedResource + \"?\" + canonicalQuery\n\t}\n\treturn encodedResource\n}\n\n// Return string to sign under two different conditions.\n// - if expires string is set then string to sign includes date instead of the Date header.\n// - if expires string is empty then string to sign includes date header instead.\nfunc getStringToSignV2(method string, encodedResource, encodedQuery string, headers http.Header, expires string) string {\n\tcanonicalHeaders := canonicalizedAmzHeadersV2(headers)\n\tif len(canonicalHeaders) > 0 {\n\t\tcanonicalHeaders += \"\\n\"\n\t}\n\n\tdate := expires // Date is set to expires date for presign operations.\n\tif date == \"\" {\n\t\t// If expires date is empty then request header Date is used.\n\t\tdate = headers.Get(xhttp.Date)\n\t}\n\n\t// From the Amazon docs:\n\t//\n\t// StringToSign = HTTP-Verb + \"\\n\" +\n\t// \t Content-Md5 + \"\\n\" +\n\t//\t Content-Type + \"\\n\" +\n\t//\t Date/Expires + \"\\n\" +\n\t//\t CanonicalizedProtocolHeaders +\n\t//\t CanonicalizedResource;\n\tstringToSign := strings.Join([]string{\n\t\tmethod,\n\t\theaders.Get(xhttp.ContentMD5),\n\t\theaders.Get(xhttp.ContentType),\n\t\tdate,\n\t\tcanonicalHeaders,\n\t}, \"\\n\")\n\n\treturn stringToSign + canonicalizedResourceV2(encodedResource, encodedQuery)\n}\n", "/*\n * MinIO Cloud Storage, (C) 2016, 2017 MinIO, Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\npackage cmd\n\nimport (\n\t\"fmt\"\n\t\"net/http\"\n\t\"net/url\"\n\t\"os\"\n\t\"sort\"\n\t\"testing\"\n)\n\n// Tests for 'func TestResourceListSorting(t *testing.T)'.\nfunc TestResourceListSorting(t *testing.T) {\n\tsortedResourceList := make([]string, len(resourceList))\n\tcopy(sortedResourceList, resourceList)\n\tsort.Strings(sortedResourceList)\n\tfor i := 0; i < len(resourceList); i++ {\n\t\tif resourceList[i] != sortedResourceList[i] {\n\t\t\tt.Errorf(\"Expected resourceList[%d] = \\\"%s\\\", resourceList is not correctly sorted.\", i, sortedResourceList[i])\n\t\t\tbreak\n\t\t}\n\t}\n}\n\n// Tests presigned v2 signature.\nfunc TestDoesPresignedV2SignatureMatch(t *testing.T) {\n\tobj, fsDir, err := prepareFS()\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tdefer os.RemoveAll(fsDir)\n\tif err = newTestConfig(globalMinioDefaultRegion, obj); err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tnow := UTCNow()\n\n\tvar (\n\t\taccessKey = globalActiveCred.AccessKey\n\t\tsecretKey = globalActiveCred.SecretKey\n\t)\n\ttestCases := []struct {\n\t\tqueryParams map[string]string\n\t\texpected    APIErrorCode\n\t}{\n\t\t// (0) Should error without a set URL query.\n\t\t{\n\t\t\texpected: ErrInvalidQueryParams,\n\t\t},\n\t\t// (1) Should error on an invalid access key.\n\t\t{\n\t\t\tqueryParams: map[string]string{\n\t\t\t\t\"Expires\":        \"60\",\n\t\t\t\t\"Signature\":      \"badsignature\",\n\t\t\t\t\"AWSAccessKeyId\": \"Z7IXGOO6BZ0REAN1Q26I\",\n\t\t\t},\n\t\t\texpected: ErrInvalidAccessKeyID,\n\t\t},\n\t\t// (2) Should error with malformed expires.\n\t\t{\n\t\t\tqueryParams: map[string]string{\n\t\t\t\t\"Expires\":        \"60s\",\n\t\t\t\t\"Signature\":      \"badsignature\",\n\t\t\t\t\"AWSAccessKeyId\": accessKey,\n\t\t\t},\n\t\t\texpected: ErrMalformedExpires,\n\t\t},\n\t\t// (3) Should give an expired request if it has expired.\n\t\t{\n\t\t\tqueryParams: map[string]string{\n\t\t\t\t\"Expires\":        \"60\",\n\t\t\t\t\"Signature\":      \"badsignature\",\n\t\t\t\t\"AWSAccessKeyId\": accessKey,\n\t\t\t},\n\t\t\texpected: ErrExpiredPresignRequest,\n\t\t},\n\t\t// (4) Should error when the signature does not match.\n\t\t{\n\t\t\tqueryParams: map[string]string{\n\t\t\t\t\"Expires\":        fmt.Sprintf(\"%d\", now.Unix()+60),\n\t\t\t\t\"Signature\":      \"badsignature\",\n\t\t\t\t\"AWSAccessKeyId\": accessKey,\n\t\t\t},\n\t\t\texpected: ErrSignatureDoesNotMatch,\n\t\t},\n\t\t// (5) Should error when the signature does not match.\n\t\t{\n\t\t\tqueryParams: map[string]string{\n\t\t\t\t\"Expires\":        fmt.Sprintf(\"%d\", now.Unix()+60),\n\t\t\t\t\"Signature\":      \"zOM2YrY/yAQe15VWmT78OlBrK6g=\",\n\t\t\t\t\"AWSAccessKeyId\": accessKey,\n\t\t\t},\n\t\t\texpected: ErrSignatureDoesNotMatch,\n\t\t},\n\t\t// (6) Should not error signature matches with extra query params.\n\t\t{\n\t\t\tqueryParams: map[string]string{\n\t\t\t\t\"response-content-disposition\": \"attachment; filename=\\\"4K%2d4M.txt\\\"\",\n\t\t\t},\n\t\t\texpected: ErrNone,\n\t\t},\n\t\t// (7) Should not error signature matches with no special query params.\n\t\t{\n\t\t\tqueryParams: map[string]string{},\n\t\t\texpected:    ErrNone,\n\t\t},\n\t}\n\n\t// Run each test case individually.\n\tfor i, testCase := range testCases {\n\t\t// Turn the map[string]string into map[string][]string, because Go.\n\t\tquery := url.Values{}\n\t\tfor key, value := range testCase.queryParams {\n\t\t\tquery.Set(key, value)\n\t\t}\n\t\t// Create a request to use.\n\t\treq, err := http.NewRequest(http.MethodGet, \"http://host/a/b?\"+query.Encode(), nil)\n\t\tif err != nil {\n\t\t\tt.Errorf(\"(%d) failed to create http.Request, got %v\", i, err)\n\t\t}\n\t\tif testCase.expected != ErrNone {\n\t\t\t// Should be set since we are simulating a http server.\n\t\t\treq.RequestURI = req.URL.RequestURI()\n\t\t\t// Check if it matches!\n\t\t\terrCode := doesPresignV2SignatureMatch(req)\n\t\t\tif errCode != testCase.expected {\n\t\t\t\tt.Errorf(\"(%d) expected to get %s, instead got %s\", i, niceError(testCase.expected), niceError(errCode))\n\t\t\t}\n\t\t} else {\n\t\t\terr = preSignV2(req, accessKey, secretKey, now.Unix()+60)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatalf(\"(%d) failed to preSignV2 http request, got %v\", i, err)\n\t\t\t}\n\t\t\t// Should be set since we are simulating a http server.\n\t\t\treq.RequestURI = req.URL.RequestURI()\n\t\t\terrCode := doesPresignV2SignatureMatch(req)\n\t\t\tif errCode != testCase.expected {\n\t\t\t\tt.Errorf(\"(%d) expected to get success, instead got %s\", i, niceError(errCode))\n\t\t\t}\n\t\t}\n\n\t}\n}\n\n// TestValidateV2AuthHeader - Tests validate the logic of V2 Authorization header validator.\nfunc TestValidateV2AuthHeader(t *testing.T) {\n\tobj, fsDir, err := prepareFS()\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tdefer os.RemoveAll(fsDir)\n\tif err = newTestConfig(globalMinioDefaultRegion, obj); err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\taccessID := globalActiveCred.AccessKey\n\ttestCases := []struct {\n\t\tauthString    string\n\t\texpectedError APIErrorCode\n\t}{\n\t\t// Test case - 1.\n\t\t// Case with empty V2AuthString.\n\t\t{\n\n\t\t\tauthString:    \"\",\n\t\t\texpectedError: ErrAuthHeaderEmpty,\n\t\t},\n\t\t// Test case - 2.\n\t\t// Test case with `signV2Algorithm` (\"AWS\") not being the prefix.\n\t\t{\n\n\t\t\tauthString:    \"NoV2Prefix\",\n\t\t\texpectedError: ErrSignatureVersionNotSupported,\n\t\t},\n\t\t// Test case - 3.\n\t\t// Test case with missing parts in the Auth string.\n\t\t// below is the correct format of V2 Authorization header.\n\t\t// Authorization = \"AWS\" + \" \" + AWSAccessKeyId + \":\" + Signature\n\t\t{\n\n\t\t\tauthString:    signV2Algorithm,\n\t\t\texpectedError: ErrMissingFields,\n\t\t},\n\t\t// Test case - 4.\n\t\t// Test case with signature part missing.\n\t\t{\n\n\t\t\tauthString:    fmt.Sprintf(\"%s %s\", signV2Algorithm, accessID),\n\t\t\texpectedError: ErrMissingFields,\n\t\t},\n\t\t// Test case - 5.\n\t\t// Test case with wrong accessID.\n\t\t{\n\n\t\t\tauthString:    fmt.Sprintf(\"%s %s:%s\", signV2Algorithm, \"InvalidAccessID\", \"signature\"),\n\t\t\texpectedError: ErrInvalidAccessKeyID,\n\t\t},\n\t\t// Test case - 6.\n\t\t// Case with right accessID and format.\n\t\t{\n\n\t\t\tauthString:    fmt.Sprintf(\"%s %s:%s\", signV2Algorithm, accessID, \"signature\"),\n\t\t\texpectedError: ErrNone,\n\t\t},\n\t}\n\n\tfor i, testCase := range testCases {\n\t\tt.Run(fmt.Sprintf(\"Case %d AuthStr \\\"%s\\\".\", i+1, testCase.authString), func(t *testing.T) {\n\n\t\t\treq := &http.Request{\n\t\t\t\tHeader: make(http.Header),\n\t\t\t\tURL:    &url.URL{},\n\t\t\t}\n\t\t\treq.Header.Set(\"Authorization\", testCase.authString)\n\t\t\t_, actualErrCode := validateV2AuthHeader(req)\n\n\t\t\tif testCase.expectedError != actualErrCode {\n\t\t\t\tt.Errorf(\"Expected the error code to be %v, got %v.\", testCase.expectedError, actualErrCode)\n\t\t\t}\n\t\t})\n\t}\n\n}\n\nfunc TestDoesPolicySignatureV2Match(t *testing.T) {\n\tobj, fsDir, err := prepareFS()\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tdefer os.RemoveAll(fsDir)\n\tif err = newTestConfig(globalMinioDefaultRegion, obj); err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tcreds := globalActiveCred\n\tpolicy := \"policy\"\n\ttestCases := []struct {\n\t\taccessKey string\n\t\tpolicy    string\n\t\tsignature string\n\t\terrCode   APIErrorCode\n\t}{\n\t\t{\"invalidAccessKey\", policy, calculateSignatureV2(policy, creds.SecretKey), ErrInvalidAccessKeyID},\n\t\t{creds.AccessKey, policy, calculateSignatureV2(\"random\", creds.SecretKey), ErrSignatureDoesNotMatch},\n\t\t{creds.AccessKey, policy, calculateSignatureV2(policy, creds.SecretKey), ErrNone},\n\t}\n\tfor i, test := range testCases {\n\t\tformValues := make(http.Header)\n\t\tformValues.Set(\"Awsaccesskeyid\", test.accessKey)\n\t\tformValues.Set(\"Signature\", test.signature)\n\t\tformValues.Set(\"Policy\", test.policy)\n\t\terrCode := doesPolicySignatureV2Match(formValues)\n\t\tif errCode != test.errCode {\n\t\t\tt.Fatalf(\"(%d) expected to get %s, instead got %s\", i+1, niceError(test.errCode), niceError(errCode))\n\t\t}\n\t}\n}\n", "/*\n * MinIO Cloud Storage, (C) 2015, 2016, 2017 MinIO, Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n// Package cmd This file implements helper functions to validate AWS\n// Signature Version '4' authorization header.\n//\n// This package provides comprehensive helpers for following signature\n// types.\n// - Based on Authorization header.\n// - Based on Query parameters.\n// - Based on Form POST policy.\npackage cmd\n\nimport (\n\t\"bytes\"\n\t\"crypto/sha256\"\n\t\"crypto/subtle\"\n\t\"encoding/hex\"\n\t\"net/http\"\n\t\"net/url\"\n\t\"sort\"\n\t\"strconv\"\n\t\"strings\"\n\t\"time\"\n\n\t\"github.com/minio/minio-go/v7/pkg/s3utils\"\n\t\"github.com/minio/minio-go/v7/pkg/set\"\n\txhttp \"github.com/minio/minio/cmd/http\"\n)\n\n// AWS Signature Version '4' constants.\nconst (\n\tsignV4Algorithm = \"AWS4-HMAC-SHA256\"\n\tiso8601Format   = \"20060102T150405Z\"\n\tyyyymmdd        = \"20060102\"\n)\n\ntype serviceType string\n\nconst (\n\tserviceS3  serviceType = \"s3\"\n\tserviceSTS serviceType = \"sts\"\n)\n\n// getCanonicalHeaders generate a list of request headers with their values\nfunc getCanonicalHeaders(signedHeaders http.Header) string {\n\tvar headers []string\n\tvals := make(http.Header)\n\tfor k, vv := range signedHeaders {\n\t\theaders = append(headers, strings.ToLower(k))\n\t\tvals[strings.ToLower(k)] = vv\n\t}\n\tsort.Strings(headers)\n\n\tvar buf bytes.Buffer\n\tfor _, k := range headers {\n\t\tbuf.WriteString(k)\n\t\tbuf.WriteByte(':')\n\t\tfor idx, v := range vals[k] {\n\t\t\tif idx > 0 {\n\t\t\t\tbuf.WriteByte(',')\n\t\t\t}\n\t\t\tbuf.WriteString(signV4TrimAll(v))\n\t\t}\n\t\tbuf.WriteByte('\\n')\n\t}\n\treturn buf.String()\n}\n\n// getSignedHeaders generate a string i.e alphabetically sorted, semicolon-separated list of lowercase request header names\nfunc getSignedHeaders(signedHeaders http.Header) string {\n\tvar headers []string\n\tfor k := range signedHeaders {\n\t\theaders = append(headers, strings.ToLower(k))\n\t}\n\tsort.Strings(headers)\n\treturn strings.Join(headers, \";\")\n}\n\n// getCanonicalRequest generate a canonical request of style\n//\n// canonicalRequest =\n//  <HTTPMethod>\\n\n//  <CanonicalURI>\\n\n//  <CanonicalQueryString>\\n\n//  <CanonicalHeaders>\\n\n//  <SignedHeaders>\\n\n//  <HashedPayload>\n//\nfunc getCanonicalRequest(extractedSignedHeaders http.Header, payload, queryStr, urlPath, method string) string {\n\trawQuery := strings.Replace(queryStr, \"+\", \"%20\", -1)\n\tencodedPath := s3utils.EncodePath(urlPath)\n\tcanonicalRequest := strings.Join([]string{\n\t\tmethod,\n\t\tencodedPath,\n\t\trawQuery,\n\t\tgetCanonicalHeaders(extractedSignedHeaders),\n\t\tgetSignedHeaders(extractedSignedHeaders),\n\t\tpayload,\n\t}, \"\\n\")\n\treturn canonicalRequest\n}\n\n// getScope generate a string of a specific date, an AWS region, and a service.\nfunc getScope(t time.Time, region string) string {\n\tscope := strings.Join([]string{\n\t\tt.Format(yyyymmdd),\n\t\tregion,\n\t\tstring(serviceS3),\n\t\t\"aws4_request\",\n\t}, SlashSeparator)\n\treturn scope\n}\n\n// getStringToSign a string based on selected query values.\nfunc getStringToSign(canonicalRequest string, t time.Time, scope string) string {\n\tstringToSign := signV4Algorithm + \"\\n\" + t.Format(iso8601Format) + \"\\n\"\n\tstringToSign = stringToSign + scope + \"\\n\"\n\tcanonicalRequestBytes := sha256.Sum256([]byte(canonicalRequest))\n\tstringToSign = stringToSign + hex.EncodeToString(canonicalRequestBytes[:])\n\treturn stringToSign\n}\n\n// getSigningKey hmac seed to calculate final signature.\nfunc getSigningKey(secretKey string, t time.Time, region string, stype serviceType) []byte {\n\tdate := sumHMAC([]byte(\"AWS4\"+secretKey), []byte(t.Format(yyyymmdd)))\n\tregionBytes := sumHMAC(date, []byte(region))\n\tservice := sumHMAC(regionBytes, []byte(stype))\n\tsigningKey := sumHMAC(service, []byte(\"aws4_request\"))\n\treturn signingKey\n}\n\n// getSignature final signature in hexadecimal form.\nfunc getSignature(signingKey []byte, stringToSign string) string {\n\treturn hex.EncodeToString(sumHMAC(signingKey, []byte(stringToSign)))\n}\n\n// Check to see if Policy is signed correctly.\nfunc doesPolicySignatureMatch(formValues http.Header) APIErrorCode {\n\t// For SignV2 - Signature field will be valid\n\tif _, ok := formValues[\"Signature\"]; ok {\n\t\treturn doesPolicySignatureV2Match(formValues)\n\t}\n\treturn doesPolicySignatureV4Match(formValues)\n}\n\n// compareSignatureV4 returns true if and only if both signatures\n// are equal. The signatures are expected to be HEX encoded strings\n// according to the AWS S3 signature V4 spec.\nfunc compareSignatureV4(sig1, sig2 string) bool {\n\t// The CTC using []byte(str) works because the hex encoding\n\t// is unique for a sequence of bytes. See also compareSignatureV2.\n\treturn subtle.ConstantTimeCompare([]byte(sig1), []byte(sig2)) == 1\n}\n\n// doesPolicySignatureMatch - Verify query headers with post policy\n//     - http://docs.aws.amazon.com/AmazonS3/latest/API/sigv4-HTTPPOSTConstructPolicy.html\n// returns ErrNone if the signature matches.\nfunc doesPolicySignatureV4Match(formValues http.Header) APIErrorCode {\n\t// Server region.\n\tregion := globalServerRegion\n\n\t// Parse credential tag.\n\tcredHeader, s3Err := parseCredentialHeader(\"Credential=\"+formValues.Get(xhttp.AmzCredential), region, serviceS3)\n\tif s3Err != ErrNone {\n\t\treturn s3Err\n\t}\n\n\tcred, _, s3Err := checkKeyValid(credHeader.accessKey)\n\tif s3Err != ErrNone {\n\t\treturn s3Err\n\t}\n\n\t// Get signing key.\n\tsigningKey := getSigningKey(cred.SecretKey, credHeader.scope.date, credHeader.scope.region, serviceS3)\n\n\t// Get signature.\n\tnewSignature := getSignature(signingKey, formValues.Get(\"Policy\"))\n\n\t// Verify signature.\n\tif !compareSignatureV4(newSignature, formValues.Get(xhttp.AmzSignature)) {\n\t\treturn ErrSignatureDoesNotMatch\n\t}\n\n\t// Success.\n\treturn ErrNone\n}\n\n// doesPresignedSignatureMatch - Verify query headers with presigned signature\n//     - http://docs.aws.amazon.com/AmazonS3/latest/API/sigv4-query-string-auth.html\n// returns ErrNone if the signature matches.\nfunc doesPresignedSignatureMatch(hashedPayload string, r *http.Request, region string, stype serviceType) APIErrorCode {\n\t// Copy request\n\treq := *r\n\n\t// Parse request query string.\n\tpSignValues, err := parsePreSignV4(req.URL.Query(), region, stype)\n\tif err != ErrNone {\n\t\treturn err\n\t}\n\n\tcred, _, s3Err := checkKeyValid(pSignValues.Credential.accessKey)\n\tif s3Err != ErrNone {\n\t\treturn s3Err\n\t}\n\n\t// Extract all the signed headers along with its values.\n\textractedSignedHeaders, errCode := extractSignedHeaders(pSignValues.SignedHeaders, r)\n\tif errCode != ErrNone {\n\t\treturn errCode\n\t}\n\n\t// If the host which signed the request is slightly ahead in time (by less than globalMaxSkewTime) the\n\t// request should still be allowed.\n\tif pSignValues.Date.After(UTCNow().Add(globalMaxSkewTime)) {\n\t\treturn ErrRequestNotReadyYet\n\t}\n\n\tif UTCNow().Sub(pSignValues.Date) > pSignValues.Expires {\n\t\treturn ErrExpiredPresignRequest\n\t}\n\n\t// Save the date and expires.\n\tt := pSignValues.Date\n\texpireSeconds := int(pSignValues.Expires / time.Second)\n\n\t// Construct new query.\n\tquery := make(url.Values)\n\tclntHashedPayload := req.URL.Query().Get(xhttp.AmzContentSha256)\n\tif clntHashedPayload != \"\" {\n\t\tquery.Set(xhttp.AmzContentSha256, hashedPayload)\n\t}\n\n\ttoken := req.URL.Query().Get(xhttp.AmzSecurityToken)\n\tif token != \"\" {\n\t\tquery.Set(xhttp.AmzSecurityToken, cred.SessionToken)\n\t}\n\n\tquery.Set(xhttp.AmzAlgorithm, signV4Algorithm)\n\n\t// Construct the query.\n\tquery.Set(xhttp.AmzDate, t.Format(iso8601Format))\n\tquery.Set(xhttp.AmzExpires, strconv.Itoa(expireSeconds))\n\tquery.Set(xhttp.AmzSignedHeaders, getSignedHeaders(extractedSignedHeaders))\n\tquery.Set(xhttp.AmzCredential, cred.AccessKey+SlashSeparator+pSignValues.Credential.getScope())\n\n\tdefaultSigParams := set.CreateStringSet(\n\t\txhttp.AmzContentSha256,\n\t\txhttp.AmzSecurityToken,\n\t\txhttp.AmzAlgorithm,\n\t\txhttp.AmzDate,\n\t\txhttp.AmzExpires,\n\t\txhttp.AmzSignedHeaders,\n\t\txhttp.AmzCredential,\n\t\txhttp.AmzSignature,\n\t)\n\n\t// Add missing query parameters if any provided in the request URL\n\tfor k, v := range req.URL.Query() {\n\t\tif !defaultSigParams.Contains(k) {\n\t\t\tquery[k] = v\n\t\t}\n\t}\n\n\t// Get the encoded query.\n\tencodedQuery := query.Encode()\n\n\t// Verify if date query is same.\n\tif req.URL.Query().Get(xhttp.AmzDate) != query.Get(xhttp.AmzDate) {\n\t\treturn ErrSignatureDoesNotMatch\n\t}\n\t// Verify if expires query is same.\n\tif req.URL.Query().Get(xhttp.AmzExpires) != query.Get(xhttp.AmzExpires) {\n\t\treturn ErrSignatureDoesNotMatch\n\t}\n\t// Verify if signed headers query is same.\n\tif req.URL.Query().Get(xhttp.AmzSignedHeaders) != query.Get(xhttp.AmzSignedHeaders) {\n\t\treturn ErrSignatureDoesNotMatch\n\t}\n\t// Verify if credential query is same.\n\tif req.URL.Query().Get(xhttp.AmzCredential) != query.Get(xhttp.AmzCredential) {\n\t\treturn ErrSignatureDoesNotMatch\n\t}\n\t// Verify if sha256 payload query is same.\n\tif clntHashedPayload != \"\" && clntHashedPayload != query.Get(xhttp.AmzContentSha256) {\n\t\treturn ErrContentSHA256Mismatch\n\t}\n\t// Verify if security token is correct.\n\tif token != \"\" && subtle.ConstantTimeCompare([]byte(token), []byte(cred.SessionToken)) != 1 {\n\t\treturn ErrInvalidToken\n\t}\n\n\t/// Verify finally if signature is same.\n\n\t// Get canonical request.\n\tpresignedCanonicalReq := getCanonicalRequest(extractedSignedHeaders, hashedPayload, encodedQuery, req.URL.Path, req.Method)\n\n\t// Get string to sign from canonical request.\n\tpresignedStringToSign := getStringToSign(presignedCanonicalReq, t, pSignValues.Credential.getScope())\n\n\t// Get hmac presigned signing key.\n\tpresignedSigningKey := getSigningKey(cred.SecretKey, pSignValues.Credential.scope.date,\n\t\tpSignValues.Credential.scope.region, stype)\n\n\t// Get new signature.\n\tnewSignature := getSignature(presignedSigningKey, presignedStringToSign)\n\n\t// Verify signature.\n\tif !compareSignatureV4(req.URL.Query().Get(xhttp.AmzSignature), newSignature) {\n\t\treturn ErrSignatureDoesNotMatch\n\t}\n\treturn ErrNone\n}\n\n// doesSignatureMatch - Verify authorization header with calculated header in accordance with\n//     - http://docs.aws.amazon.com/AmazonS3/latest/API/sig-v4-authenticating-requests.html\n// returns ErrNone if signature matches.\nfunc doesSignatureMatch(hashedPayload string, r *http.Request, region string, stype serviceType) APIErrorCode {\n\t// Copy request.\n\treq := *r\n\n\t// Save authorization header.\n\tv4Auth := req.Header.Get(xhttp.Authorization)\n\n\t// Parse signature version '4' header.\n\tsignV4Values, err := parseSignV4(v4Auth, region, stype)\n\tif err != ErrNone {\n\t\treturn err\n\t}\n\n\t// Extract all the signed headers along with its values.\n\textractedSignedHeaders, errCode := extractSignedHeaders(signV4Values.SignedHeaders, r)\n\tif errCode != ErrNone {\n\t\treturn errCode\n\t}\n\n\tcred, _, s3Err := checkKeyValid(signV4Values.Credential.accessKey)\n\tif s3Err != ErrNone {\n\t\treturn s3Err\n\t}\n\n\t// Extract date, if not present throw error.\n\tvar date string\n\tif date = req.Header.Get(xhttp.AmzDate); date == \"\" {\n\t\tif date = r.Header.Get(xhttp.Date); date == \"\" {\n\t\t\treturn ErrMissingDateHeader\n\t\t}\n\t}\n\n\t// Parse date header.\n\tt, e := time.Parse(iso8601Format, date)\n\tif e != nil {\n\t\treturn ErrMalformedDate\n\t}\n\n\t// Query string.\n\tqueryStr := req.URL.Query().Encode()\n\n\t// Get canonical request.\n\tcanonicalRequest := getCanonicalRequest(extractedSignedHeaders, hashedPayload, queryStr, req.URL.Path, req.Method)\n\n\t// Get string to sign from canonical request.\n\tstringToSign := getStringToSign(canonicalRequest, t, signV4Values.Credential.getScope())\n\n\t// Get hmac signing key.\n\tsigningKey := getSigningKey(cred.SecretKey, signV4Values.Credential.scope.date,\n\t\tsignV4Values.Credential.scope.region, stype)\n\n\t// Calculate signature.\n\tnewSignature := getSignature(signingKey, stringToSign)\n\n\t// Verify if signature match.\n\tif !compareSignatureV4(newSignature, signV4Values.Signature) {\n\t\treturn ErrSignatureDoesNotMatch\n\t}\n\n\t// Return error none.\n\treturn ErrNone\n}\n", "/*\n * MinIO Cloud Storage, (C) 2016, 2017 MinIO, Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\npackage cmd\n\nimport (\n\t\"fmt\"\n\t\"net/http\"\n\t\"net/url\"\n\t\"os\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc niceError(code APIErrorCode) string {\n\t// Special-handle ErrNone\n\tif code == ErrNone {\n\t\treturn \"ErrNone\"\n\t}\n\n\treturn fmt.Sprintf(\"%s (%s)\", errorCodes[code].Code, errorCodes[code].Description)\n}\n\nfunc TestDoesPolicySignatureMatch(t *testing.T) {\n\tcredentialTemplate := \"%s/%s/%s/s3/aws4_request\"\n\tnow := UTCNow()\n\taccessKey := globalActiveCred.AccessKey\n\n\ttestCases := []struct {\n\t\tform     http.Header\n\t\texpected APIErrorCode\n\t}{\n\t\t// (0) It should fail if 'X-Amz-Credential' is missing.\n\t\t{\n\t\t\tform:     http.Header{},\n\t\t\texpected: ErrCredMalformed,\n\t\t},\n\t\t// (1) It should fail if the access key is incorrect.\n\t\t{\n\t\t\tform: http.Header{\n\t\t\t\t\"X-Amz-Credential\": []string{fmt.Sprintf(credentialTemplate, \"EXAMPLEINVALIDEXAMPL\", now.Format(yyyymmdd), globalMinioDefaultRegion)},\n\t\t\t},\n\t\t\texpected: ErrInvalidAccessKeyID,\n\t\t},\n\t\t// (2) It should fail with a bad signature.\n\t\t{\n\t\t\tform: http.Header{\n\t\t\t\t\"X-Amz-Credential\": []string{fmt.Sprintf(credentialTemplate, accessKey, now.Format(yyyymmdd), globalMinioDefaultRegion)},\n\t\t\t\t\"X-Amz-Date\":       []string{now.Format(iso8601Format)},\n\t\t\t\t\"X-Amz-Signature\":  []string{\"invalidsignature\"},\n\t\t\t\t\"Policy\":           []string{\"policy\"},\n\t\t\t},\n\t\t\texpected: ErrSignatureDoesNotMatch,\n\t\t},\n\t\t// (3) It should succeed if everything is correct.\n\t\t{\n\t\t\tform: http.Header{\n\t\t\t\t\"X-Amz-Credential\": []string{\n\t\t\t\t\tfmt.Sprintf(credentialTemplate, accessKey, now.Format(yyyymmdd), globalMinioDefaultRegion),\n\t\t\t\t},\n\t\t\t\t\"X-Amz-Date\": []string{now.Format(iso8601Format)},\n\t\t\t\t\"X-Amz-Signature\": []string{\n\t\t\t\t\tgetSignature(getSigningKey(globalActiveCred.SecretKey, now,\n\t\t\t\t\t\tglobalMinioDefaultRegion, serviceS3), \"policy\"),\n\t\t\t\t},\n\t\t\t\t\"Policy\": []string{\"policy\"},\n\t\t\t},\n\t\t\texpected: ErrNone,\n\t\t},\n\t}\n\n\t// Run each test case individually.\n\tfor i, testCase := range testCases {\n\t\tcode := doesPolicySignatureMatch(testCase.form)\n\t\tif code != testCase.expected {\n\t\t\tt.Errorf(\"(%d) expected to get %s, instead got %s\", i, niceError(testCase.expected), niceError(code))\n\t\t}\n\t}\n}\n\nfunc TestDoesPresignedSignatureMatch(t *testing.T) {\n\tobj, fsDir, err := prepareFS()\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tdefer os.RemoveAll(fsDir)\n\tif err = newTestConfig(globalMinioDefaultRegion, obj); err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\t// sha256 hash of \"payload\"\n\tpayloadSHA256 := \"239f59ed55e737c77147cf55ad0c1b030b6d7ee748a7426952f9b852d5a935e5\"\n\tnow := UTCNow()\n\tcredentialTemplate := \"%s/%s/%s/s3/aws4_request\"\n\n\tregion := globalServerRegion\n\taccessKeyID := globalActiveCred.AccessKey\n\ttestCases := []struct {\n\t\tqueryParams map[string]string\n\t\theaders     map[string]string\n\t\tregion      string\n\t\texpected    APIErrorCode\n\t}{\n\t\t// (0) Should error without a set URL query.\n\t\t{\n\t\t\tregion:   globalMinioDefaultRegion,\n\t\t\texpected: ErrInvalidQueryParams,\n\t\t},\n\t\t// (1) Should error on an invalid access key.\n\t\t{\n\t\t\tqueryParams: map[string]string{\n\t\t\t\t\"X-Amz-Algorithm\":     signV4Algorithm,\n\t\t\t\t\"X-Amz-Date\":          now.Format(iso8601Format),\n\t\t\t\t\"X-Amz-Expires\":       \"60\",\n\t\t\t\t\"X-Amz-Signature\":     \"badsignature\",\n\t\t\t\t\"X-Amz-SignedHeaders\": \"host;x-amz-content-sha256;x-amz-date\",\n\t\t\t\t\"X-Amz-Credential\":    fmt.Sprintf(credentialTemplate, \"Z7IXGOO6BZ0REAN1Q26I\", now.Format(yyyymmdd), \"us-west-1\"),\n\t\t\t},\n\t\t\tregion:   \"us-west-1\",\n\t\t\texpected: ErrInvalidAccessKeyID,\n\t\t},\n\t\t// (2) Should NOT fail with an invalid region if it doesn't verify it.\n\t\t{\n\t\t\tqueryParams: map[string]string{\n\t\t\t\t\"X-Amz-Algorithm\":      signV4Algorithm,\n\t\t\t\t\"X-Amz-Date\":           now.Format(iso8601Format),\n\t\t\t\t\"X-Amz-Expires\":        \"60\",\n\t\t\t\t\"X-Amz-Signature\":      \"badsignature\",\n\t\t\t\t\"X-Amz-SignedHeaders\":  \"host;x-amz-content-sha256;x-amz-date\",\n\t\t\t\t\"X-Amz-Credential\":     fmt.Sprintf(credentialTemplate, accessKeyID, now.Format(yyyymmdd), \"us-west-1\"),\n\t\t\t\t\"X-Amz-Content-Sha256\": payloadSHA256,\n\t\t\t},\n\t\t\tregion:   \"us-west-1\",\n\t\t\texpected: ErrUnsignedHeaders,\n\t\t},\n\t\t// (3) Should fail to extract headers if the host header is not signed.\n\t\t{\n\t\t\tqueryParams: map[string]string{\n\t\t\t\t\"X-Amz-Algorithm\":      signV4Algorithm,\n\t\t\t\t\"X-Amz-Date\":           now.Format(iso8601Format),\n\t\t\t\t\"X-Amz-Expires\":        \"60\",\n\t\t\t\t\"X-Amz-Signature\":      \"badsignature\",\n\t\t\t\t\"X-Amz-SignedHeaders\":  \"x-amz-content-sha256;x-amz-date\",\n\t\t\t\t\"X-Amz-Credential\":     fmt.Sprintf(credentialTemplate, accessKeyID, now.Format(yyyymmdd), region),\n\t\t\t\t\"X-Amz-Content-Sha256\": payloadSHA256,\n\t\t\t},\n\t\t\tregion:   region,\n\t\t\texpected: ErrUnsignedHeaders,\n\t\t},\n\t\t// (4) Should give an expired request if it has expired.\n\t\t{\n\t\t\tqueryParams: map[string]string{\n\t\t\t\t\"X-Amz-Algorithm\":      signV4Algorithm,\n\t\t\t\t\"X-Amz-Date\":           now.AddDate(0, 0, -2).Format(iso8601Format),\n\t\t\t\t\"X-Amz-Expires\":        \"60\",\n\t\t\t\t\"X-Amz-Signature\":      \"badsignature\",\n\t\t\t\t\"X-Amz-SignedHeaders\":  \"host;x-amz-content-sha256;x-amz-date\",\n\t\t\t\t\"X-Amz-Credential\":     fmt.Sprintf(credentialTemplate, accessKeyID, now.Format(yyyymmdd), region),\n\t\t\t\t\"X-Amz-Content-Sha256\": payloadSHA256,\n\t\t\t},\n\t\t\theaders: map[string]string{\n\t\t\t\t\"X-Amz-Date\":           now.AddDate(0, 0, -2).Format(iso8601Format),\n\t\t\t\t\"X-Amz-Content-Sha256\": payloadSHA256,\n\t\t\t},\n\t\t\tregion:   region,\n\t\t\texpected: ErrExpiredPresignRequest,\n\t\t},\n\t\t// (5) Should error if the signature is incorrect.\n\t\t{\n\t\t\tqueryParams: map[string]string{\n\t\t\t\t\"X-Amz-Algorithm\":      signV4Algorithm,\n\t\t\t\t\"X-Amz-Date\":           now.Format(iso8601Format),\n\t\t\t\t\"X-Amz-Expires\":        \"60\",\n\t\t\t\t\"X-Amz-Signature\":      \"badsignature\",\n\t\t\t\t\"X-Amz-SignedHeaders\":  \"host;x-amz-content-sha256;x-amz-date\",\n\t\t\t\t\"X-Amz-Credential\":     fmt.Sprintf(credentialTemplate, accessKeyID, now.Format(yyyymmdd), region),\n\t\t\t\t\"X-Amz-Content-Sha256\": payloadSHA256,\n\t\t\t},\n\t\t\theaders: map[string]string{\n\t\t\t\t\"X-Amz-Date\":           now.Format(iso8601Format),\n\t\t\t\t\"X-Amz-Content-Sha256\": payloadSHA256,\n\t\t\t},\n\t\t\tregion:   region,\n\t\t\texpected: ErrSignatureDoesNotMatch,\n\t\t},\n\t\t// (6) Should error if the request is not ready yet, ie X-Amz-Date is in the future.\n\t\t{\n\t\t\tqueryParams: map[string]string{\n\t\t\t\t\"X-Amz-Algorithm\":      signV4Algorithm,\n\t\t\t\t\"X-Amz-Date\":           now.Add(1 * time.Hour).Format(iso8601Format),\n\t\t\t\t\"X-Amz-Expires\":        \"60\",\n\t\t\t\t\"X-Amz-Signature\":      \"badsignature\",\n\t\t\t\t\"X-Amz-SignedHeaders\":  \"host;x-amz-content-sha256;x-amz-date\",\n\t\t\t\t\"X-Amz-Credential\":     fmt.Sprintf(credentialTemplate, accessKeyID, now.Format(yyyymmdd), region),\n\t\t\t\t\"X-Amz-Content-Sha256\": payloadSHA256,\n\t\t\t},\n\t\t\theaders: map[string]string{\n\t\t\t\t\"X-Amz-Date\":           now.Format(iso8601Format),\n\t\t\t\t\"X-Amz-Content-Sha256\": payloadSHA256,\n\t\t\t},\n\t\t\tregion:   region,\n\t\t\texpected: ErrRequestNotReadyYet,\n\t\t},\n\t\t// (7) Should not error with invalid region instead, call should proceed\n\t\t// with sigature does not match.\n\t\t{\n\t\t\tqueryParams: map[string]string{\n\t\t\t\t\"X-Amz-Algorithm\":      signV4Algorithm,\n\t\t\t\t\"X-Amz-Date\":           now.Format(iso8601Format),\n\t\t\t\t\"X-Amz-Expires\":        \"60\",\n\t\t\t\t\"X-Amz-Signature\":      \"badsignature\",\n\t\t\t\t\"X-Amz-SignedHeaders\":  \"host;x-amz-content-sha256;x-amz-date\",\n\t\t\t\t\"X-Amz-Credential\":     fmt.Sprintf(credentialTemplate, accessKeyID, now.Format(yyyymmdd), region),\n\t\t\t\t\"X-Amz-Content-Sha256\": payloadSHA256,\n\t\t\t},\n\t\t\theaders: map[string]string{\n\t\t\t\t\"X-Amz-Date\":           now.Format(iso8601Format),\n\t\t\t\t\"X-Amz-Content-Sha256\": payloadSHA256,\n\t\t\t},\n\t\t\tregion:   \"\",\n\t\t\texpected: ErrSignatureDoesNotMatch,\n\t\t},\n\t\t// (8) Should error with signature does not match. But handles\n\t\t// query params which do not precede with \"x-amz-\" header.\n\t\t{\n\t\t\tqueryParams: map[string]string{\n\t\t\t\t\"X-Amz-Algorithm\":       signV4Algorithm,\n\t\t\t\t\"X-Amz-Date\":            now.Format(iso8601Format),\n\t\t\t\t\"X-Amz-Expires\":         \"60\",\n\t\t\t\t\"X-Amz-Signature\":       \"badsignature\",\n\t\t\t\t\"X-Amz-SignedHeaders\":   \"host;x-amz-content-sha256;x-amz-date\",\n\t\t\t\t\"X-Amz-Credential\":      fmt.Sprintf(credentialTemplate, accessKeyID, now.Format(yyyymmdd), region),\n\t\t\t\t\"X-Amz-Content-Sha256\":  payloadSHA256,\n\t\t\t\t\"response-content-type\": \"application/json\",\n\t\t\t},\n\t\t\theaders: map[string]string{\n\t\t\t\t\"X-Amz-Date\":           now.Format(iso8601Format),\n\t\t\t\t\"X-Amz-Content-Sha256\": payloadSHA256,\n\t\t\t},\n\t\t\tregion:   \"\",\n\t\t\texpected: ErrSignatureDoesNotMatch,\n\t\t},\n\t\t// (9) Should error with unsigned headers.\n\t\t{\n\t\t\tqueryParams: map[string]string{\n\t\t\t\t\"X-Amz-Algorithm\":       signV4Algorithm,\n\t\t\t\t\"X-Amz-Date\":            now.Format(iso8601Format),\n\t\t\t\t\"X-Amz-Expires\":         \"60\",\n\t\t\t\t\"X-Amz-Signature\":       \"badsignature\",\n\t\t\t\t\"X-Amz-SignedHeaders\":   \"host;x-amz-content-sha256;x-amz-date\",\n\t\t\t\t\"X-Amz-Credential\":      fmt.Sprintf(credentialTemplate, accessKeyID, now.Format(yyyymmdd), region),\n\t\t\t\t\"X-Amz-Content-Sha256\":  payloadSHA256,\n\t\t\t\t\"response-content-type\": \"application/json\",\n\t\t\t},\n\t\t\theaders: map[string]string{\n\t\t\t\t\"X-Amz-Date\": now.Format(iso8601Format),\n\t\t\t},\n\t\t\tregion:   \"\",\n\t\t\texpected: ErrUnsignedHeaders,\n\t\t},\n\t}\n\n\t// Run each test case individually.\n\tfor i, testCase := range testCases {\n\t\t// Turn the map[string]string into map[string][]string, because Go.\n\t\tquery := url.Values{}\n\t\tfor key, value := range testCase.queryParams {\n\t\t\tquery.Set(key, value)\n\t\t}\n\n\t\t// Create a request to use.\n\t\treq, e := http.NewRequest(http.MethodGet, \"http://host/a/b?\"+query.Encode(), nil)\n\t\tif e != nil {\n\t\t\tt.Errorf(\"(%d) failed to create http.Request, got %v\", i, e)\n\t\t}\n\n\t\t// Do the same for the headers.\n\t\tfor key, value := range testCase.headers {\n\t\t\treq.Header.Set(key, value)\n\t\t}\n\n\t\t// Check if it matches!\n\t\terr := doesPresignedSignatureMatch(payloadSHA256, req, testCase.region, serviceS3)\n\t\tif err != testCase.expected {\n\t\t\tt.Errorf(\"(%d) expected to get %s, instead got %s\", i, niceError(testCase.expected), niceError(err))\n\t\t}\n\t}\n}\n"], "fixing_code": ["/*\n * MinIO Cloud Storage, (C) 2015-2018 MinIO, Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\npackage cmd\n\nimport (\n\t\"bytes\"\n\t\"context\"\n\t\"crypto/subtle\"\n\t\"encoding/base64\"\n\t\"encoding/hex\"\n\t\"errors\"\n\t\"io\"\n\t\"io/ioutil\"\n\t\"net/http\"\n\t\"strconv\"\n\t\"strings\"\n\t\"time\"\n\n\txhttp \"github.com/minio/minio/cmd/http\"\n\txjwt \"github.com/minio/minio/cmd/jwt\"\n\t\"github.com/minio/minio/cmd/logger\"\n\t\"github.com/minio/minio/pkg/auth\"\n\tobjectlock \"github.com/minio/minio/pkg/bucket/object/lock\"\n\t\"github.com/minio/minio/pkg/bucket/policy\"\n\t\"github.com/minio/minio/pkg/hash\"\n\tiampolicy \"github.com/minio/minio/pkg/iam/policy\"\n)\n\n// Verify if request has JWT.\nfunc isRequestJWT(r *http.Request) bool {\n\treturn strings.HasPrefix(r.Header.Get(xhttp.Authorization), jwtAlgorithm)\n}\n\n// Verify if request has AWS Signature Version '4'.\nfunc isRequestSignatureV4(r *http.Request) bool {\n\treturn strings.HasPrefix(r.Header.Get(xhttp.Authorization), signV4Algorithm)\n}\n\n// Verify if request has AWS Signature Version '2'.\nfunc isRequestSignatureV2(r *http.Request) bool {\n\treturn (!strings.HasPrefix(r.Header.Get(xhttp.Authorization), signV4Algorithm) &&\n\t\tstrings.HasPrefix(r.Header.Get(xhttp.Authorization), signV2Algorithm))\n}\n\n// Verify if request has AWS PreSign Version '4'.\nfunc isRequestPresignedSignatureV4(r *http.Request) bool {\n\t_, ok := r.URL.Query()[xhttp.AmzCredential]\n\treturn ok\n}\n\n// Verify request has AWS PreSign Version '2'.\nfunc isRequestPresignedSignatureV2(r *http.Request) bool {\n\t_, ok := r.URL.Query()[xhttp.AmzAccessKeyID]\n\treturn ok\n}\n\n// Verify if request has AWS Post policy Signature Version '4'.\nfunc isRequestPostPolicySignatureV4(r *http.Request) bool {\n\treturn strings.Contains(r.Header.Get(xhttp.ContentType), \"multipart/form-data\") &&\n\t\tr.Method == http.MethodPost\n}\n\n// Verify if the request has AWS Streaming Signature Version '4'. This is only valid for 'PUT' operation.\nfunc isRequestSignStreamingV4(r *http.Request) bool {\n\treturn r.Header.Get(xhttp.AmzContentSha256) == streamingContentSHA256 &&\n\t\tr.Method == http.MethodPut\n}\n\n// Authorization type.\ntype authType int\n\n// List of all supported auth types.\nconst (\n\tauthTypeUnknown authType = iota\n\tauthTypeAnonymous\n\tauthTypePresigned\n\tauthTypePresignedV2\n\tauthTypePostPolicy\n\tauthTypeStreamingSigned\n\tauthTypeSigned\n\tauthTypeSignedV2\n\tauthTypeJWT\n\tauthTypeSTS\n)\n\n// Get request authentication type.\nfunc getRequestAuthType(r *http.Request) authType {\n\tif isRequestSignatureV2(r) {\n\t\treturn authTypeSignedV2\n\t} else if isRequestPresignedSignatureV2(r) {\n\t\treturn authTypePresignedV2\n\t} else if isRequestSignStreamingV4(r) {\n\t\treturn authTypeStreamingSigned\n\t} else if isRequestSignatureV4(r) {\n\t\treturn authTypeSigned\n\t} else if isRequestPresignedSignatureV4(r) {\n\t\treturn authTypePresigned\n\t} else if isRequestJWT(r) {\n\t\treturn authTypeJWT\n\t} else if isRequestPostPolicySignatureV4(r) {\n\t\treturn authTypePostPolicy\n\t} else if _, ok := r.URL.Query()[xhttp.Action]; ok {\n\t\treturn authTypeSTS\n\t} else if _, ok := r.Header[xhttp.Authorization]; !ok {\n\t\treturn authTypeAnonymous\n\t}\n\treturn authTypeUnknown\n}\n\nfunc validateAdminSignature(ctx context.Context, r *http.Request, region string) (auth.Credentials, map[string]interface{}, bool, APIErrorCode) {\n\tvar cred auth.Credentials\n\tvar owner bool\n\ts3Err := ErrAccessDenied\n\tif _, ok := r.Header[xhttp.AmzContentSha256]; ok &&\n\t\tgetRequestAuthType(r) == authTypeSigned && !skipContentSha256Cksum(r) {\n\t\t// We only support admin credentials to access admin APIs.\n\t\tcred, owner, s3Err = getReqAccessKeyV4(r, region, serviceS3)\n\t\tif s3Err != ErrNone {\n\t\t\treturn cred, nil, owner, s3Err\n\t\t}\n\n\t\t// we only support V4 (no presign) with auth body\n\t\ts3Err = isReqAuthenticated(ctx, r, region, serviceS3)\n\t}\n\tif s3Err != ErrNone {\n\t\treqInfo := (&logger.ReqInfo{}).AppendTags(\"requestHeaders\", dumpRequest(r))\n\t\tctx := logger.SetReqInfo(ctx, reqInfo)\n\t\tlogger.LogIf(ctx, errors.New(getAPIError(s3Err).Description), logger.Application)\n\t\treturn cred, nil, owner, s3Err\n\t}\n\n\tclaims, s3Err := checkClaimsFromToken(r, cred)\n\tif s3Err != ErrNone {\n\t\treturn cred, nil, owner, s3Err\n\t}\n\n\treturn cred, claims, owner, ErrNone\n}\n\n// checkAdminRequestAuth checks for authentication and authorization for the incoming\n// request. It only accepts V2 and V4 requests. Presigned, JWT and anonymous requests\n// are automatically rejected.\nfunc checkAdminRequestAuth(ctx context.Context, r *http.Request, action iampolicy.AdminAction, region string) (auth.Credentials, APIErrorCode) {\n\tcred, claims, owner, s3Err := validateAdminSignature(ctx, r, region)\n\tif s3Err != ErrNone {\n\t\treturn cred, s3Err\n\t}\n\tif globalIAMSys.IsAllowed(iampolicy.Args{\n\t\tAccountName:     cred.AccessKey,\n\t\tAction:          iampolicy.Action(action),\n\t\tConditionValues: getConditionValues(r, \"\", cred.AccessKey, claims),\n\t\tIsOwner:         owner,\n\t\tClaims:          claims,\n\t}) {\n\t\t// Request is allowed return the appropriate access key.\n\t\treturn cred, ErrNone\n\t}\n\n\treturn cred, ErrAccessDenied\n}\n\n// Fetch the security token set by the client.\nfunc getSessionToken(r *http.Request) (token string) {\n\ttoken = r.Header.Get(xhttp.AmzSecurityToken)\n\tif token != \"\" {\n\t\treturn token\n\t}\n\treturn r.URL.Query().Get(xhttp.AmzSecurityToken)\n}\n\n// Fetch claims in the security token returned by the client, doesn't return\n// errors - upon errors the returned claims map will be empty.\nfunc mustGetClaimsFromToken(r *http.Request) map[string]interface{} {\n\tclaims, _ := getClaimsFromToken(getSessionToken(r))\n\treturn claims\n}\n\n// Fetch claims in the security token returned by the client.\nfunc getClaimsFromToken(token string) (map[string]interface{}, error) {\n\tclaims := xjwt.NewMapClaims()\n\tif token == \"\" {\n\t\treturn claims.Map(), nil\n\t}\n\n\tstsTokenCallback := func(claims *xjwt.MapClaims) ([]byte, error) {\n\t\t// JWT token for x-amz-security-token is signed with admin\n\t\t// secret key, temporary credentials become invalid if\n\t\t// server admin credentials change. This is done to ensure\n\t\t// that clients cannot decode the token using the temp\n\t\t// secret keys and generate an entirely new claim by essentially\n\t\t// hijacking the policies. We need to make sure that this is\n\t\t// based an admin credential such that token cannot be decoded\n\t\t// on the client side and is treated like an opaque value.\n\t\treturn []byte(globalActiveCred.SecretKey), nil\n\t}\n\n\tif err := xjwt.ParseWithClaims(token, claims, stsTokenCallback); err != nil {\n\t\treturn nil, errAuthentication\n\t}\n\n\tif globalPolicyOPA == nil {\n\t\t// If OPA is not set and if ldap claim key is set, allow the claim.\n\t\tif _, ok := claims.MapClaims[ldapUser]; ok {\n\t\t\treturn claims.Map(), nil\n\t\t}\n\n\t\t// If OPA is not set, session token should\n\t\t// have a policy and its mandatory, reject\n\t\t// requests without policy claim.\n\t\t_, pokOpenID := claims.MapClaims[iamPolicyClaimNameOpenID()]\n\t\t_, pokSA := claims.MapClaims[iamPolicyClaimNameSA()]\n\t\tif !pokOpenID && !pokSA {\n\t\t\treturn nil, errAuthentication\n\t\t}\n\n\t\tsp, spok := claims.Lookup(iampolicy.SessionPolicyName)\n\t\tif !spok {\n\t\t\treturn claims.Map(), nil\n\t\t}\n\t\t// Looks like subpolicy is set and is a string, if set then its\n\t\t// base64 encoded, decode it. Decoding fails reject such requests.\n\t\tspBytes, err := base64.StdEncoding.DecodeString(sp)\n\t\tif err != nil {\n\t\t\t// Base64 decoding fails, we should log to indicate\n\t\t\t// something is malforming the request sent by client.\n\t\t\tlogger.LogIf(GlobalContext, err, logger.Application)\n\t\t\treturn nil, errAuthentication\n\t\t}\n\t\tclaims.MapClaims[iampolicy.SessionPolicyName] = string(spBytes)\n\t}\n\n\treturn claims.Map(), nil\n}\n\n// Fetch claims in the security token returned by the client and validate the token.\nfunc checkClaimsFromToken(r *http.Request, cred auth.Credentials) (map[string]interface{}, APIErrorCode) {\n\ttoken := getSessionToken(r)\n\tif token != \"\" && cred.AccessKey == \"\" {\n\t\treturn nil, ErrNoAccessKey\n\t}\n\tif cred.IsServiceAccount() && token == \"\" {\n\t\ttoken = cred.SessionToken\n\t}\n\tif subtle.ConstantTimeCompare([]byte(token), []byte(cred.SessionToken)) != 1 {\n\t\treturn nil, ErrInvalidToken\n\t}\n\tclaims, err := getClaimsFromToken(token)\n\tif err != nil {\n\t\treturn nil, toAPIErrorCode(r.Context(), err)\n\t}\n\treturn claims, ErrNone\n}\n\n// Check request auth type verifies the incoming http request\n// - validates the request signature\n// - validates the policy action if anonymous tests bucket policies if any,\n//   for authenticated requests validates IAM policies.\n// returns APIErrorCode if any to be replied to the client.\nfunc checkRequestAuthType(ctx context.Context, r *http.Request, action policy.Action, bucketName, objectName string) (s3Err APIErrorCode) {\n\t_, _, s3Err = checkRequestAuthTypeToAccessKey(ctx, r, action, bucketName, objectName)\n\treturn s3Err\n}\n\n// Check request auth type verifies the incoming http request\n// - validates the request signature\n// - validates the policy action if anonymous tests bucket policies if any,\n//   for authenticated requests validates IAM policies.\n// returns APIErrorCode if any to be replied to the client.\n// Additionally returns the accessKey used in the request, and if this request is by an admin.\nfunc checkRequestAuthTypeToAccessKey(ctx context.Context, r *http.Request, action policy.Action, bucketName, objectName string) (accessKey string, owner bool, s3Err APIErrorCode) {\n\tvar cred auth.Credentials\n\tswitch getRequestAuthType(r) {\n\tcase authTypeUnknown, authTypeStreamingSigned:\n\t\treturn accessKey, owner, ErrSignatureVersionNotSupported\n\tcase authTypePresignedV2, authTypeSignedV2:\n\t\tif s3Err = isReqAuthenticatedV2(r); s3Err != ErrNone {\n\t\t\treturn accessKey, owner, s3Err\n\t\t}\n\t\tcred, owner, s3Err = getReqAccessKeyV2(r)\n\tcase authTypeSigned, authTypePresigned:\n\t\tregion := globalServerRegion\n\t\tswitch action {\n\t\tcase policy.GetBucketLocationAction, policy.ListAllMyBucketsAction:\n\t\t\tregion = \"\"\n\t\t}\n\t\tif s3Err = isReqAuthenticated(ctx, r, region, serviceS3); s3Err != ErrNone {\n\t\t\treturn accessKey, owner, s3Err\n\t\t}\n\t\tcred, owner, s3Err = getReqAccessKeyV4(r, region, serviceS3)\n\t}\n\tif s3Err != ErrNone {\n\t\treturn accessKey, owner, s3Err\n\t}\n\n\tvar claims map[string]interface{}\n\tclaims, s3Err = checkClaimsFromToken(r, cred)\n\tif s3Err != ErrNone {\n\t\treturn accessKey, owner, s3Err\n\t}\n\n\t// LocationConstraint is valid only for CreateBucketAction.\n\tvar locationConstraint string\n\tif action == policy.CreateBucketAction {\n\t\t// To extract region from XML in request body, get copy of request body.\n\t\tpayload, err := ioutil.ReadAll(io.LimitReader(r.Body, maxLocationConstraintSize))\n\t\tif err != nil {\n\t\t\tlogger.LogIf(ctx, err, logger.Application)\n\t\t\treturn accessKey, owner, ErrMalformedXML\n\t\t}\n\n\t\t// Populate payload to extract location constraint.\n\t\tr.Body = ioutil.NopCloser(bytes.NewReader(payload))\n\n\t\tvar s3Error APIErrorCode\n\t\tlocationConstraint, s3Error = parseLocationConstraint(r)\n\t\tif s3Error != ErrNone {\n\t\t\treturn accessKey, owner, s3Error\n\t\t}\n\n\t\t// Populate payload again to handle it in HTTP handler.\n\t\tr.Body = ioutil.NopCloser(bytes.NewReader(payload))\n\t}\n\tif cred.AccessKey != \"\" {\n\t\tlogger.GetReqInfo(ctx).AccessKey = cred.AccessKey\n\t}\n\n\tif action != policy.ListAllMyBucketsAction && cred.AccessKey == \"\" {\n\t\t// Anonymous checks are not meant for ListBuckets action\n\t\tif globalPolicySys.IsAllowed(policy.Args{\n\t\t\tAccountName:     cred.AccessKey,\n\t\t\tAction:          action,\n\t\t\tBucketName:      bucketName,\n\t\t\tConditionValues: getConditionValues(r, locationConstraint, \"\", nil),\n\t\t\tIsOwner:         false,\n\t\t\tObjectName:      objectName,\n\t\t}) {\n\t\t\t// Request is allowed return the appropriate access key.\n\t\t\treturn cred.AccessKey, owner, ErrNone\n\t\t}\n\n\t\tif action == policy.ListBucketVersionsAction {\n\t\t\t// In AWS S3 s3:ListBucket permission is same as s3:ListBucketVersions permission\n\t\t\t// verify as a fallback.\n\t\t\tif globalPolicySys.IsAllowed(policy.Args{\n\t\t\t\tAccountName:     cred.AccessKey,\n\t\t\t\tAction:          policy.ListBucketAction,\n\t\t\t\tBucketName:      bucketName,\n\t\t\t\tConditionValues: getConditionValues(r, locationConstraint, \"\", nil),\n\t\t\t\tIsOwner:         false,\n\t\t\t\tObjectName:      objectName,\n\t\t\t}) {\n\t\t\t\t// Request is allowed return the appropriate access key.\n\t\t\t\treturn cred.AccessKey, owner, ErrNone\n\t\t\t}\n\t\t}\n\n\t\treturn cred.AccessKey, owner, ErrAccessDenied\n\t}\n\n\tif globalIAMSys.IsAllowed(iampolicy.Args{\n\t\tAccountName:     cred.AccessKey,\n\t\tAction:          iampolicy.Action(action),\n\t\tBucketName:      bucketName,\n\t\tConditionValues: getConditionValues(r, \"\", cred.AccessKey, claims),\n\t\tObjectName:      objectName,\n\t\tIsOwner:         owner,\n\t\tClaims:          claims,\n\t}) {\n\t\t// Request is allowed return the appropriate access key.\n\t\treturn cred.AccessKey, owner, ErrNone\n\t}\n\n\tif action == policy.ListBucketVersionsAction {\n\t\t// In AWS S3 s3:ListBucket permission is same as s3:ListBucketVersions permission\n\t\t// verify as a fallback.\n\t\tif globalIAMSys.IsAllowed(iampolicy.Args{\n\t\t\tAccountName:     cred.AccessKey,\n\t\t\tAction:          iampolicy.ListBucketAction,\n\t\t\tBucketName:      bucketName,\n\t\t\tConditionValues: getConditionValues(r, \"\", cred.AccessKey, claims),\n\t\t\tObjectName:      objectName,\n\t\t\tIsOwner:         owner,\n\t\t\tClaims:          claims,\n\t\t}) {\n\t\t\t// Request is allowed return the appropriate access key.\n\t\t\treturn cred.AccessKey, owner, ErrNone\n\t\t}\n\t}\n\n\treturn cred.AccessKey, owner, ErrAccessDenied\n}\n\n// Verify if request has valid AWS Signature Version '2'.\nfunc isReqAuthenticatedV2(r *http.Request) (s3Error APIErrorCode) {\n\tif isRequestSignatureV2(r) {\n\t\treturn doesSignV2Match(r)\n\t}\n\treturn doesPresignV2SignatureMatch(r)\n}\n\nfunc reqSignatureV4Verify(r *http.Request, region string, stype serviceType) (s3Error APIErrorCode) {\n\tsha256sum := getContentSha256Cksum(r, stype)\n\tswitch {\n\tcase isRequestSignatureV4(r):\n\t\treturn doesSignatureMatch(sha256sum, r, region, stype)\n\tcase isRequestPresignedSignatureV4(r):\n\t\treturn doesPresignedSignatureMatch(sha256sum, r, region, stype)\n\tdefault:\n\t\treturn ErrAccessDenied\n\t}\n}\n\n// Verify if request has valid AWS Signature Version '4'.\nfunc isReqAuthenticated(ctx context.Context, r *http.Request, region string, stype serviceType) (s3Error APIErrorCode) {\n\tif errCode := reqSignatureV4Verify(r, region, stype); errCode != ErrNone {\n\t\treturn errCode\n\t}\n\n\tvar (\n\t\terr                       error\n\t\tcontentMD5, contentSHA256 []byte\n\t)\n\n\t// Extract 'Content-Md5' if present.\n\tcontentMD5, err = checkValidMD5(r.Header)\n\tif err != nil {\n\t\treturn ErrInvalidDigest\n\t}\n\n\t// Extract either 'X-Amz-Content-Sha256' header or 'X-Amz-Content-Sha256' query parameter (if V4 presigned)\n\t// Do not verify 'X-Amz-Content-Sha256' if skipSHA256.\n\tif skipSHA256 := skipContentSha256Cksum(r); !skipSHA256 && isRequestPresignedSignatureV4(r) {\n\t\tif sha256Sum, ok := r.URL.Query()[xhttp.AmzContentSha256]; ok && len(sha256Sum) > 0 {\n\t\t\tcontentSHA256, err = hex.DecodeString(sha256Sum[0])\n\t\t\tif err != nil {\n\t\t\t\treturn ErrContentSHA256Mismatch\n\t\t\t}\n\t\t}\n\t} else if _, ok := r.Header[xhttp.AmzContentSha256]; !skipSHA256 && ok {\n\t\tcontentSHA256, err = hex.DecodeString(r.Header.Get(xhttp.AmzContentSha256))\n\t\tif err != nil || len(contentSHA256) == 0 {\n\t\t\treturn ErrContentSHA256Mismatch\n\t\t}\n\t}\n\n\t// Verify 'Content-Md5' and/or 'X-Amz-Content-Sha256' if present.\n\t// The verification happens implicit during reading.\n\treader, err := hash.NewReader(r.Body, -1, hex.EncodeToString(contentMD5), hex.EncodeToString(contentSHA256), -1)\n\tif err != nil {\n\t\treturn toAPIErrorCode(ctx, err)\n\t}\n\tr.Body = reader\n\treturn ErrNone\n}\n\n// List of all support S3 auth types.\nvar supportedS3AuthTypes = map[authType]struct{}{\n\tauthTypeAnonymous:       {},\n\tauthTypePresigned:       {},\n\tauthTypePresignedV2:     {},\n\tauthTypeSigned:          {},\n\tauthTypeSignedV2:        {},\n\tauthTypePostPolicy:      {},\n\tauthTypeStreamingSigned: {},\n}\n\n// Validate if the authType is valid and supported.\nfunc isSupportedS3AuthType(aType authType) bool {\n\t_, ok := supportedS3AuthTypes[aType]\n\treturn ok\n}\n\n// setAuthHandler to validate authorization header for the incoming request.\nfunc setAuthHandler(h http.Handler) http.Handler {\n\t// handler for validating incoming authorization headers.\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\taType := getRequestAuthType(r)\n\t\tif isSupportedS3AuthType(aType) {\n\t\t\t// Let top level caller validate for anonymous and known signed requests.\n\t\t\th.ServeHTTP(w, r)\n\t\t\treturn\n\t\t} else if aType == authTypeJWT {\n\t\t\t// Validate Authorization header if its valid for JWT request.\n\t\t\tif _, _, authErr := webRequestAuthenticate(r); authErr != nil {\n\t\t\t\tw.WriteHeader(http.StatusUnauthorized)\n\t\t\t\tw.Write([]byte(authErr.Error()))\n\t\t\t\treturn\n\t\t\t}\n\t\t\th.ServeHTTP(w, r)\n\t\t\treturn\n\t\t} else if aType == authTypeSTS {\n\t\t\th.ServeHTTP(w, r)\n\t\t\treturn\n\t\t}\n\t\twriteErrorResponse(r.Context(), w, errorCodes.ToAPIErr(ErrSignatureVersionNotSupported), r.URL, guessIsBrowserReq(r))\n\t})\n}\n\nfunc validateSignature(atype authType, r *http.Request) (auth.Credentials, bool, map[string]interface{}, APIErrorCode) {\n\tvar cred auth.Credentials\n\tvar owner bool\n\tvar s3Err APIErrorCode\n\tswitch atype {\n\tcase authTypeUnknown, authTypeStreamingSigned:\n\t\treturn cred, owner, nil, ErrSignatureVersionNotSupported\n\tcase authTypeSignedV2, authTypePresignedV2:\n\t\tif s3Err = isReqAuthenticatedV2(r); s3Err != ErrNone {\n\t\t\treturn cred, owner, nil, s3Err\n\t\t}\n\t\tcred, owner, s3Err = getReqAccessKeyV2(r)\n\tcase authTypePresigned, authTypeSigned:\n\t\tregion := globalServerRegion\n\t\tif s3Err = isReqAuthenticated(GlobalContext, r, region, serviceS3); s3Err != ErrNone {\n\t\t\treturn cred, owner, nil, s3Err\n\t\t}\n\t\tcred, owner, s3Err = getReqAccessKeyV4(r, region, serviceS3)\n\t}\n\tif s3Err != ErrNone {\n\t\treturn cred, owner, nil, s3Err\n\t}\n\n\tclaims, s3Err := checkClaimsFromToken(r, cred)\n\tif s3Err != ErrNone {\n\t\treturn cred, owner, nil, s3Err\n\t}\n\n\treturn cred, owner, claims, ErrNone\n}\n\nfunc isPutRetentionAllowed(bucketName, objectName string, retDays int, retDate time.Time, retMode objectlock.RetMode, byPassSet bool, r *http.Request, cred auth.Credentials, owner bool, claims map[string]interface{}) (s3Err APIErrorCode) {\n\tvar retSet bool\n\tif cred.AccessKey == \"\" {\n\t\tconditions := getConditionValues(r, \"\", \"\", nil)\n\t\tconditions[\"object-lock-mode\"] = []string{string(retMode)}\n\t\tconditions[\"object-lock-retain-until-date\"] = []string{retDate.Format(time.RFC3339)}\n\t\tif retDays > 0 {\n\t\t\tconditions[\"object-lock-remaining-retention-days\"] = []string{strconv.Itoa(retDays)}\n\t\t}\n\t\tif retMode == objectlock.RetGovernance && byPassSet {\n\t\t\tbyPassSet = globalPolicySys.IsAllowed(policy.Args{\n\t\t\t\tAccountName:     cred.AccessKey,\n\t\t\t\tAction:          policy.BypassGovernanceRetentionAction,\n\t\t\t\tBucketName:      bucketName,\n\t\t\t\tConditionValues: conditions,\n\t\t\t\tIsOwner:         false,\n\t\t\t\tObjectName:      objectName,\n\t\t\t})\n\t\t}\n\t\tif globalPolicySys.IsAllowed(policy.Args{\n\t\t\tAccountName:     cred.AccessKey,\n\t\t\tAction:          policy.PutObjectRetentionAction,\n\t\t\tBucketName:      bucketName,\n\t\t\tConditionValues: conditions,\n\t\t\tIsOwner:         false,\n\t\t\tObjectName:      objectName,\n\t\t}) {\n\t\t\tretSet = true\n\t\t}\n\t\tif byPassSet || retSet {\n\t\t\treturn ErrNone\n\t\t}\n\t\treturn ErrAccessDenied\n\t}\n\n\tconditions := getConditionValues(r, \"\", cred.AccessKey, claims)\n\tconditions[\"object-lock-mode\"] = []string{string(retMode)}\n\tconditions[\"object-lock-retain-until-date\"] = []string{retDate.Format(time.RFC3339)}\n\tif retDays > 0 {\n\t\tconditions[\"object-lock-remaining-retention-days\"] = []string{strconv.Itoa(retDays)}\n\t}\n\tif retMode == objectlock.RetGovernance && byPassSet {\n\t\tbyPassSet = globalIAMSys.IsAllowed(iampolicy.Args{\n\t\t\tAccountName:     cred.AccessKey,\n\t\t\tAction:          iampolicy.BypassGovernanceRetentionAction,\n\t\t\tBucketName:      bucketName,\n\t\t\tObjectName:      objectName,\n\t\t\tConditionValues: conditions,\n\t\t\tIsOwner:         owner,\n\t\t\tClaims:          claims,\n\t\t})\n\t}\n\tif globalIAMSys.IsAllowed(iampolicy.Args{\n\t\tAccountName:     cred.AccessKey,\n\t\tAction:          iampolicy.PutObjectRetentionAction,\n\t\tBucketName:      bucketName,\n\t\tConditionValues: conditions,\n\t\tObjectName:      objectName,\n\t\tIsOwner:         owner,\n\t\tClaims:          claims,\n\t}) {\n\t\tretSet = true\n\t}\n\tif byPassSet || retSet {\n\t\treturn ErrNone\n\t}\n\treturn ErrAccessDenied\n}\n\n// isPutActionAllowed - check if PUT operation is allowed on the resource, this\n// call verifies bucket policies and IAM policies, supports multi user\n// checks etc.\nfunc isPutActionAllowed(ctx context.Context, atype authType, bucketName, objectName string, r *http.Request, action iampolicy.Action) (s3Err APIErrorCode) {\n\tvar cred auth.Credentials\n\tvar owner bool\n\tswitch atype {\n\tcase authTypeUnknown:\n\t\treturn ErrSignatureVersionNotSupported\n\tcase authTypeSignedV2, authTypePresignedV2:\n\t\tcred, owner, s3Err = getReqAccessKeyV2(r)\n\tcase authTypeStreamingSigned, authTypePresigned, authTypeSigned:\n\t\tregion := globalServerRegion\n\t\tcred, owner, s3Err = getReqAccessKeyV4(r, region, serviceS3)\n\t}\n\tif s3Err != ErrNone {\n\t\treturn s3Err\n\t}\n\n\tclaims, s3Err := checkClaimsFromToken(r, cred)\n\tif s3Err != ErrNone {\n\t\treturn s3Err\n\t}\n\n\tif cred.AccessKey != \"\" {\n\t\tlogger.GetReqInfo(ctx).AccessKey = cred.AccessKey\n\t}\n\n\t// Do not check for PutObjectRetentionAction permission,\n\t// if mode and retain until date are not set.\n\t// Can happen when bucket has default lock config set\n\tif action == iampolicy.PutObjectRetentionAction &&\n\t\tr.Header.Get(xhttp.AmzObjectLockMode) == \"\" &&\n\t\tr.Header.Get(xhttp.AmzObjectLockRetainUntilDate) == \"\" {\n\t\treturn ErrNone\n\t}\n\n\tif cred.AccessKey == \"\" {\n\t\tif globalPolicySys.IsAllowed(policy.Args{\n\t\t\tAccountName:     cred.AccessKey,\n\t\t\tAction:          policy.Action(action),\n\t\t\tBucketName:      bucketName,\n\t\t\tConditionValues: getConditionValues(r, \"\", \"\", nil),\n\t\t\tIsOwner:         false,\n\t\t\tObjectName:      objectName,\n\t\t}) {\n\t\t\treturn ErrNone\n\t\t}\n\t\treturn ErrAccessDenied\n\t}\n\n\tif globalIAMSys.IsAllowed(iampolicy.Args{\n\t\tAccountName:     cred.AccessKey,\n\t\tAction:          action,\n\t\tBucketName:      bucketName,\n\t\tConditionValues: getConditionValues(r, \"\", cred.AccessKey, claims),\n\t\tObjectName:      objectName,\n\t\tIsOwner:         owner,\n\t\tClaims:          claims,\n\t}) {\n\t\treturn ErrNone\n\t}\n\treturn ErrAccessDenied\n}\n", "/*\n * MinIO Cloud Storage, (C) 2015-2020 MinIO, Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\npackage cmd\n\nimport (\n\t\"crypto/subtle\"\n\t\"encoding/base64\"\n\t\"encoding/xml\"\n\t\"fmt\"\n\t\"io\"\n\t\"net/http\"\n\t\"net/textproto\"\n\t\"net/url\"\n\t\"path\"\n\t\"sort\"\n\t\"strconv\"\n\t\"strings\"\n\t\"sync\"\n\n\t\"github.com/google/uuid\"\n\t\"github.com/gorilla/mux\"\n\n\t\"github.com/minio/minio-go/v7/pkg/set\"\n\t\"github.com/minio/minio-go/v7/pkg/tags\"\n\t\"github.com/minio/minio/cmd/config/dns\"\n\t\"github.com/minio/minio/cmd/crypto\"\n\txhttp \"github.com/minio/minio/cmd/http\"\n\t\"github.com/minio/minio/cmd/logger\"\n\t\"github.com/minio/minio/pkg/bucket/lifecycle\"\n\tobjectlock \"github.com/minio/minio/pkg/bucket/object/lock\"\n\t\"github.com/minio/minio/pkg/bucket/policy\"\n\t\"github.com/minio/minio/pkg/bucket/replication\"\n\t\"github.com/minio/minio/pkg/event\"\n\t\"github.com/minio/minio/pkg/handlers\"\n\t\"github.com/minio/minio/pkg/hash\"\n\tiampolicy \"github.com/minio/minio/pkg/iam/policy\"\n\t\"github.com/minio/minio/pkg/sync/errgroup\"\n)\n\nconst (\n\tobjectLockConfig        = \"object-lock.xml\"\n\tbucketTaggingConfig     = \"tagging.xml\"\n\tbucketReplicationConfig = \"replication.xml\"\n)\n\n// Check if there are buckets on server without corresponding entry in etcd backend and\n// make entries. Here is the general flow\n// - Range over all the available buckets\n// - Check if a bucket has an entry in etcd backend\n// -- If no, make an entry\n// -- If yes, check if the entry matches local IP check if we\n//    need to update the entry then proceed to update\n// -- If yes, check if the IP of entry matches local IP.\n//    This means entry is for this instance.\n// -- If IP of the entry doesn't match, this means entry is\n//    for another instance. Log an error to console.\nfunc initFederatorBackend(buckets []BucketInfo, objLayer ObjectLayer) {\n\tif len(buckets) == 0 {\n\t\treturn\n\t}\n\n\t// Get buckets in the DNS\n\tdnsBuckets, err := globalDNSConfig.List()\n\tif err != nil && !IsErrIgnored(err, dns.ErrNoEntriesFound, dns.ErrNotImplemented, dns.ErrDomainMissing) {\n\t\tlogger.LogIf(GlobalContext, err)\n\t\treturn\n\t}\n\n\tbucketsSet := set.NewStringSet()\n\tbucketsToBeUpdated := set.NewStringSet()\n\tbucketsInConflict := set.NewStringSet()\n\n\t// This means that domain is updated, we should update\n\t// all bucket entries with new domain name.\n\tdomainMissing := err == dns.ErrDomainMissing\n\tif dnsBuckets != nil {\n\t\tfor _, bucket := range buckets {\n\t\t\tbucketsSet.Add(bucket.Name)\n\t\t\tr, ok := dnsBuckets[bucket.Name]\n\t\t\tif !ok {\n\t\t\t\tbucketsToBeUpdated.Add(bucket.Name)\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tif !globalDomainIPs.Intersection(set.CreateStringSet(getHostsSlice(r)...)).IsEmpty() {\n\t\t\t\tif globalDomainIPs.Difference(set.CreateStringSet(getHostsSlice(r)...)).IsEmpty() && !domainMissing {\n\t\t\t\t\t// No difference in terms of domainIPs and nothing\n\t\t\t\t\t// has changed so we don't change anything on the etcd.\n\t\t\t\t\t//\n\t\t\t\t\t// Additionally also check if domain is updated/missing with more\n\t\t\t\t\t// entries, if that is the case we should update the\n\t\t\t\t\t// new domain entries as well.\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\n\t\t\t\t// if domain IPs intersect then it won't be an empty set.\n\t\t\t\t// such an intersection means that bucket exists on etcd.\n\t\t\t\t// but if we do see a difference with local domain IPs with\n\t\t\t\t// hostSlice from etcd then we should update with newer\n\t\t\t\t// domainIPs, we proceed to do that here.\n\t\t\t\tbucketsToBeUpdated.Add(bucket.Name)\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\t// No IPs seem to intersect, this means that bucket exists but has\n\t\t\t// different IP addresses perhaps from a different deployment.\n\t\t\t// bucket names are globally unique in federation at a given\n\t\t\t// path prefix, name collision is not allowed. We simply log\n\t\t\t// an error and continue.\n\t\t\tbucketsInConflict.Add(bucket.Name)\n\t\t}\n\t}\n\n\t// Add/update buckets that are not registered with the DNS\n\tbucketsToBeUpdatedSlice := bucketsToBeUpdated.ToSlice()\n\tg := errgroup.WithNErrs(len(bucketsToBeUpdatedSlice)).WithConcurrency(50)\n\tctx, cancel := g.WithCancelOnError(GlobalContext)\n\tdefer cancel()\n\n\tfor index := range bucketsToBeUpdatedSlice {\n\t\tindex := index\n\t\tg.Go(func() error {\n\t\t\treturn globalDNSConfig.Put(bucketsToBeUpdatedSlice[index])\n\t\t}, index)\n\t}\n\n\tif err := g.WaitErr(); err != nil {\n\t\tlogger.LogIf(ctx, err)\n\t\treturn\n\t}\n\n\tfor _, bucket := range bucketsInConflict.ToSlice() {\n\t\tlogger.LogIf(ctx, fmt.Errorf(\"Unable to add bucket DNS entry for bucket %s, an entry exists for the same bucket by a different tenant. This local bucket will be ignored. Bucket names are globally unique in federated deployments. Use path style requests on following addresses '%v' to access this bucket\", bucket, globalDomainIPs.ToSlice()))\n\t}\n\n\tvar wg sync.WaitGroup\n\t// Remove buckets that are in DNS for this server, but aren't local\n\tfor bucket, records := range dnsBuckets {\n\t\tif bucketsSet.Contains(bucket) {\n\t\t\tcontinue\n\t\t}\n\n\t\tif globalDomainIPs.Intersection(set.CreateStringSet(getHostsSlice(records)...)).IsEmpty() {\n\t\t\t// This is not for our server, so we can continue\n\t\t\tcontinue\n\t\t}\n\n\t\twg.Add(1)\n\t\tgo func(bucket string) {\n\t\t\tdefer wg.Done()\n\t\t\t// We go to here, so we know the bucket no longer exists,\n\t\t\t// but is registered in DNS to this server\n\t\t\tif err := globalDNSConfig.Delete(bucket); err != nil {\n\t\t\t\tlogger.LogIf(GlobalContext, fmt.Errorf(\"Failed to remove DNS entry for %s due to %w\",\n\t\t\t\t\tbucket, err))\n\t\t\t}\n\t\t}(bucket)\n\t}\n\twg.Wait()\n}\n\n// GetBucketLocationHandler - GET Bucket location.\n// -------------------------\n// This operation returns bucket location.\nfunc (api objectAPIHandlers) GetBucketLocationHandler(w http.ResponseWriter, r *http.Request) {\n\tctx := newContext(r, w, \"GetBucketLocation\")\n\n\tdefer logger.AuditLog(ctx, w, r, mustGetClaimsFromToken(r))\n\n\tvars := mux.Vars(r)\n\tbucket := vars[\"bucket\"]\n\n\tobjectAPI := api.ObjectAPI()\n\tif objectAPI == nil {\n\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(ErrServerNotInitialized), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\tif s3Error := checkRequestAuthType(ctx, r, policy.GetBucketLocationAction, bucket, \"\"); s3Error != ErrNone {\n\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(s3Error), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\tgetBucketInfo := objectAPI.GetBucketInfo\n\n\tif _, err := getBucketInfo(ctx, bucket); err != nil {\n\t\twriteErrorResponse(ctx, w, toAPIError(ctx, err), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\t// Generate response.\n\tencodedSuccessResponse := encodeResponse(LocationResponse{})\n\t// Get current region.\n\tregion := globalServerRegion\n\tif region != globalMinioDefaultRegion {\n\t\tencodedSuccessResponse = encodeResponse(LocationResponse{\n\t\t\tLocation: region,\n\t\t})\n\t}\n\n\t// Write success response.\n\twriteSuccessResponseXML(w, encodedSuccessResponse)\n}\n\n// ListMultipartUploadsHandler - GET Bucket (List Multipart uploads)\n// -------------------------\n// This operation lists in-progress multipart uploads. An in-progress\n// multipart upload is a multipart upload that has been initiated,\n// using the Initiate Multipart Upload request, but has not yet been\n// completed or aborted. This operation returns at most 1,000 multipart\n// uploads in the response.\n//\nfunc (api objectAPIHandlers) ListMultipartUploadsHandler(w http.ResponseWriter, r *http.Request) {\n\tctx := newContext(r, w, \"ListMultipartUploads\")\n\n\tdefer logger.AuditLog(ctx, w, r, mustGetClaimsFromToken(r))\n\n\tvars := mux.Vars(r)\n\tbucket := vars[\"bucket\"]\n\n\tobjectAPI := api.ObjectAPI()\n\tif objectAPI == nil {\n\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(ErrServerNotInitialized), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\tif s3Error := checkRequestAuthType(ctx, r, policy.ListBucketMultipartUploadsAction, bucket, \"\"); s3Error != ErrNone {\n\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(s3Error), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\tprefix, keyMarker, uploadIDMarker, delimiter, maxUploads, encodingType, errCode := getBucketMultipartResources(r.URL.Query())\n\tif errCode != ErrNone {\n\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(errCode), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\tif maxUploads < 0 {\n\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(ErrInvalidMaxUploads), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\tif keyMarker != \"\" {\n\t\t// Marker not common with prefix is not implemented.\n\t\tif !HasPrefix(keyMarker, prefix) {\n\t\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(ErrNotImplemented), r.URL, guessIsBrowserReq(r))\n\t\t\treturn\n\t\t}\n\t}\n\n\tlistMultipartsInfo, err := objectAPI.ListMultipartUploads(ctx, bucket, prefix, keyMarker, uploadIDMarker, delimiter, maxUploads)\n\tif err != nil {\n\t\twriteErrorResponse(ctx, w, toAPIError(ctx, err), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\t// generate response\n\tresponse := generateListMultipartUploadsResponse(bucket, listMultipartsInfo, encodingType)\n\tencodedSuccessResponse := encodeResponse(response)\n\n\t// write success response.\n\twriteSuccessResponseXML(w, encodedSuccessResponse)\n}\n\n// ListBucketsHandler - GET Service.\n// -----------\n// This implementation of the GET operation returns a list of all buckets\n// owned by the authenticated sender of the request.\nfunc (api objectAPIHandlers) ListBucketsHandler(w http.ResponseWriter, r *http.Request) {\n\tctx := newContext(r, w, \"ListBuckets\")\n\n\tdefer logger.AuditLog(ctx, w, r, mustGetClaimsFromToken(r))\n\n\tobjectAPI := api.ObjectAPI()\n\tif objectAPI == nil {\n\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(ErrServerNotInitialized), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\tlistBuckets := objectAPI.ListBuckets\n\n\taccessKey, owner, s3Error := checkRequestAuthTypeToAccessKey(ctx, r, policy.ListAllMyBucketsAction, \"\", \"\")\n\tif s3Error != ErrNone && s3Error != ErrAccessDenied {\n\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(s3Error), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\t// If etcd, dns federation configured list buckets from etcd.\n\tvar bucketsInfo []BucketInfo\n\tif globalDNSConfig != nil && globalBucketFederation {\n\t\tdnsBuckets, err := globalDNSConfig.List()\n\t\tif err != nil && !IsErrIgnored(err,\n\t\t\tdns.ErrNoEntriesFound,\n\t\t\tdns.ErrDomainMissing) {\n\t\t\twriteErrorResponse(ctx, w, toAPIError(ctx, err), r.URL, guessIsBrowserReq(r))\n\t\t\treturn\n\t\t}\n\t\tfor _, dnsRecords := range dnsBuckets {\n\t\t\tbucketsInfo = append(bucketsInfo, BucketInfo{\n\t\t\t\tName:    dnsRecords[0].Key,\n\t\t\t\tCreated: dnsRecords[0].CreationDate,\n\t\t\t})\n\t\t}\n\n\t\tsort.Slice(bucketsInfo, func(i, j int) bool {\n\t\t\treturn bucketsInfo[i].Name < bucketsInfo[j].Name\n\t\t})\n\n\t} else {\n\t\t// Invoke the list buckets.\n\t\tvar err error\n\t\tbucketsInfo, err = listBuckets(ctx)\n\t\tif err != nil {\n\t\t\twriteErrorResponse(ctx, w, toAPIError(ctx, err), r.URL, guessIsBrowserReq(r))\n\t\t\treturn\n\t\t}\n\t}\n\n\tif s3Error == ErrAccessDenied {\n\t\t// Set prefix value for \"s3:prefix\" policy conditionals.\n\t\tr.Header.Set(\"prefix\", \"\")\n\n\t\t// Set delimiter value for \"s3:delimiter\" policy conditionals.\n\t\tr.Header.Set(\"delimiter\", SlashSeparator)\n\n\t\t// err will be nil here as we already called this function\n\t\t// earlier in this request.\n\t\tclaims, _ := getClaimsFromToken(getSessionToken(r))\n\t\tn := 0\n\t\t// Use the following trick to filter in place\n\t\t// https://github.com/golang/go/wiki/SliceTricks#filter-in-place\n\t\tfor _, bucketInfo := range bucketsInfo {\n\t\t\tif globalIAMSys.IsAllowed(iampolicy.Args{\n\t\t\t\tAccountName:     accessKey,\n\t\t\t\tAction:          iampolicy.ListBucketAction,\n\t\t\t\tBucketName:      bucketInfo.Name,\n\t\t\t\tConditionValues: getConditionValues(r, \"\", accessKey, claims),\n\t\t\t\tIsOwner:         owner,\n\t\t\t\tObjectName:      \"\",\n\t\t\t\tClaims:          claims,\n\t\t\t}) {\n\t\t\t\tbucketsInfo[n] = bucketInfo\n\t\t\t\tn++\n\t\t\t}\n\t\t}\n\t\tbucketsInfo = bucketsInfo[:n]\n\t\t// No buckets can be filtered return access denied error.\n\t\tif len(bucketsInfo) == 0 {\n\t\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(s3Error), r.URL, guessIsBrowserReq(r))\n\t\t\treturn\n\t\t}\n\t}\n\n\t// Generate response.\n\tresponse := generateListBucketsResponse(bucketsInfo)\n\tencodedSuccessResponse := encodeResponse(response)\n\n\t// Write response.\n\twriteSuccessResponseXML(w, encodedSuccessResponse)\n}\n\n// DeleteMultipleObjectsHandler - deletes multiple objects.\nfunc (api objectAPIHandlers) DeleteMultipleObjectsHandler(w http.ResponseWriter, r *http.Request) {\n\tctx := newContext(r, w, \"DeleteMultipleObjects\")\n\n\tdefer logger.AuditLog(ctx, w, r, mustGetClaimsFromToken(r))\n\n\tvars := mux.Vars(r)\n\tbucket := vars[\"bucket\"]\n\n\tobjectAPI := api.ObjectAPI()\n\tif objectAPI == nil {\n\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(ErrServerNotInitialized), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\t// Content-Md5 is requied should be set\n\t// http://docs.aws.amazon.com/AmazonS3/latest/API/multiobjectdeleteapi.html\n\tif _, ok := r.Header[xhttp.ContentMD5]; !ok {\n\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(ErrMissingContentMD5), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\t// Content-Length is required and should be non-zero\n\t// http://docs.aws.amazon.com/AmazonS3/latest/API/multiobjectdeleteapi.html\n\tif r.ContentLength <= 0 {\n\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(ErrMissingContentLength), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\t// The max. XML contains 100000 object names (each at most 1024 bytes long) + XML overhead\n\tconst maxBodySize = 2 * 100000 * 1024\n\n\t// Unmarshal list of keys to be deleted.\n\tdeleteObjects := &DeleteObjectsRequest{}\n\tif err := xmlDecoder(r.Body, deleteObjects, maxBodySize); err != nil {\n\t\tlogger.LogIf(ctx, err, logger.Application)\n\t\twriteErrorResponse(ctx, w, toAPIError(ctx, err), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\t// Call checkRequestAuthType to populate ReqInfo.AccessKey before GetBucketInfo()\n\t// Ignore errors here to preserve the S3 error behavior of GetBucketInfo()\n\tcheckRequestAuthType(ctx, r, policy.DeleteObjectAction, bucket, \"\")\n\n\t// Before proceeding validate if bucket exists.\n\t_, err := objectAPI.GetBucketInfo(ctx, bucket)\n\tif err != nil {\n\t\twriteErrorResponse(ctx, w, toAPIError(ctx, err), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\tdeleteObjectsFn := objectAPI.DeleteObjects\n\tif api.CacheAPI() != nil {\n\t\tdeleteObjectsFn = api.CacheAPI().DeleteObjects\n\t}\n\n\t// Return Malformed XML as S3 spec if the list of objects is empty\n\tif len(deleteObjects.Objects) == 0 {\n\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(ErrMalformedXML), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\tvar objectsToDelete = map[ObjectToDelete]int{}\n\tgetObjectInfoFn := objectAPI.GetObjectInfo\n\tif api.CacheAPI() != nil {\n\t\tgetObjectInfoFn = api.CacheAPI().GetObjectInfo\n\t}\n\tvar (\n\t\thasLockEnabled, hasLifecycleConfig, replicateSync bool\n\t\tgoi                                               ObjectInfo\n\t\tgerr                                              error\n\t)\n\treplicateDeletes := hasReplicationRules(ctx, bucket, deleteObjects.Objects)\n\tif rcfg, _ := globalBucketObjectLockSys.Get(bucket); rcfg.LockEnabled {\n\t\thasLockEnabled = true\n\t}\n\tif _, err := globalBucketMetadataSys.GetLifecycleConfig(bucket); err == nil {\n\t\thasLifecycleConfig = true\n\t}\n\tdErrs := make([]DeleteError, len(deleteObjects.Objects))\n\tfor index, object := range deleteObjects.Objects {\n\t\tif apiErrCode := checkRequestAuthType(ctx, r, policy.DeleteObjectAction, bucket, object.ObjectName); apiErrCode != ErrNone {\n\t\t\tif apiErrCode == ErrSignatureDoesNotMatch || apiErrCode == ErrInvalidAccessKeyID {\n\t\t\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(apiErrCode), r.URL, guessIsBrowserReq(r))\n\t\t\t\treturn\n\t\t\t}\n\t\t\tapiErr := errorCodes.ToAPIErr(apiErrCode)\n\t\t\tdErrs[index] = DeleteError{\n\t\t\t\tCode:      apiErr.Code,\n\t\t\t\tMessage:   apiErr.Description,\n\t\t\t\tKey:       object.ObjectName,\n\t\t\t\tVersionID: object.VersionID,\n\t\t\t}\n\t\t\tcontinue\n\t\t}\n\t\tif object.VersionID != \"\" && object.VersionID != nullVersionID {\n\t\t\tif _, err := uuid.Parse(object.VersionID); err != nil {\n\t\t\t\tlogger.LogIf(ctx, fmt.Errorf(\"invalid version-id specified %w\", err))\n\t\t\t\tapiErr := errorCodes.ToAPIErr(ErrNoSuchVersion)\n\t\t\t\tdErrs[index] = DeleteError{\n\t\t\t\t\tCode:      apiErr.Code,\n\t\t\t\t\tMessage:   apiErr.Description,\n\t\t\t\t\tKey:       object.ObjectName,\n\t\t\t\t\tVersionID: object.VersionID,\n\t\t\t\t}\n\t\t\t\tcontinue\n\t\t\t}\n\t\t}\n\n\t\tif replicateDeletes || hasLockEnabled || hasLifecycleConfig {\n\t\t\tgoi, gerr = getObjectInfoFn(ctx, bucket, object.ObjectName, ObjectOptions{\n\t\t\t\tVersionID: object.VersionID,\n\t\t\t})\n\t\t}\n\t\tif hasLifecycleConfig && gerr == nil {\n\t\t\tobject.PurgeTransitioned = goi.TransitionStatus\n\t\t}\n\t\tif replicateDeletes {\n\t\t\tdelMarker, replicate, repsync := checkReplicateDelete(ctx, bucket, ObjectToDelete{\n\t\t\t\tObjectName: object.ObjectName,\n\t\t\t\tVersionID:  object.VersionID,\n\t\t\t}, goi, gerr)\n\t\t\treplicateSync = repsync\n\t\t\tif replicate {\n\t\t\t\tif apiErrCode := checkRequestAuthType(ctx, r, policy.ReplicateDeleteAction, bucket, object.ObjectName); apiErrCode != ErrNone {\n\t\t\t\t\tif apiErrCode == ErrSignatureDoesNotMatch || apiErrCode == ErrInvalidAccessKeyID {\n\t\t\t\t\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(apiErrCode), r.URL, guessIsBrowserReq(r))\n\t\t\t\t\t\treturn\n\t\t\t\t\t}\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tif object.VersionID != \"\" {\n\t\t\t\t\tobject.VersionPurgeStatus = Pending\n\t\t\t\t\tif delMarker {\n\t\t\t\t\t\tobject.DeleteMarkerVersionID = object.VersionID\n\t\t\t\t\t}\n\t\t\t\t} else {\n\t\t\t\t\tobject.DeleteMarkerReplicationStatus = string(replication.Pending)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tif object.VersionID != \"\" {\n\t\t\tif hasLockEnabled {\n\t\t\t\tif apiErrCode := enforceRetentionBypassForDelete(ctx, r, bucket, object, goi, gerr); apiErrCode != ErrNone {\n\t\t\t\t\tapiErr := errorCodes.ToAPIErr(apiErrCode)\n\t\t\t\t\tdErrs[index] = DeleteError{\n\t\t\t\t\t\tCode:      apiErr.Code,\n\t\t\t\t\t\tMessage:   apiErr.Description,\n\t\t\t\t\t\tKey:       object.ObjectName,\n\t\t\t\t\t\tVersionID: object.VersionID,\n\t\t\t\t\t}\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t// Avoid duplicate objects, we use map to filter them out.\n\t\tif _, ok := objectsToDelete[object]; !ok {\n\t\t\tobjectsToDelete[object] = index\n\t\t}\n\t}\n\n\ttoNames := func(input map[ObjectToDelete]int) (output []ObjectToDelete) {\n\t\toutput = make([]ObjectToDelete, len(input))\n\t\tidx := 0\n\t\tfor obj := range input {\n\t\t\toutput[idx] = obj\n\t\t\tidx++\n\t\t}\n\t\treturn\n\t}\n\n\tdeleteList := toNames(objectsToDelete)\n\tdObjects, errs := deleteObjectsFn(ctx, bucket, deleteList, ObjectOptions{\n\t\tVersioned:        globalBucketVersioningSys.Enabled(bucket),\n\t\tVersionSuspended: globalBucketVersioningSys.Suspended(bucket),\n\t})\n\tdeletedObjects := make([]DeletedObject, len(deleteObjects.Objects))\n\tfor i := range errs {\n\t\tdindex := objectsToDelete[ObjectToDelete{\n\t\t\tObjectName:                    dObjects[i].ObjectName,\n\t\t\tVersionID:                     dObjects[i].VersionID,\n\t\t\tVersionPurgeStatus:            dObjects[i].VersionPurgeStatus,\n\t\t\tDeleteMarkerReplicationStatus: dObjects[i].DeleteMarkerReplicationStatus,\n\t\t\tPurgeTransitioned:             dObjects[i].PurgeTransitioned,\n\t\t}]\n\t\tif errs[i] == nil || isErrObjectNotFound(errs[i]) || isErrVersionNotFound(errs[i]) {\n\t\t\tif replicateDeletes {\n\t\t\t\tdObjects[i].DeleteMarkerReplicationStatus = deleteList[i].DeleteMarkerReplicationStatus\n\t\t\t\tdObjects[i].VersionPurgeStatus = deleteList[i].VersionPurgeStatus\n\t\t\t}\n\t\t\tdeletedObjects[dindex] = dObjects[i]\n\t\t\tcontinue\n\t\t}\n\t\tapiErr := toAPIError(ctx, errs[i])\n\t\tdErrs[dindex] = DeleteError{\n\t\t\tCode:      apiErr.Code,\n\t\t\tMessage:   apiErr.Description,\n\t\t\tKey:       deleteList[i].ObjectName,\n\t\t\tVersionID: deleteList[i].VersionID,\n\t\t}\n\t}\n\n\tvar deleteErrors []DeleteError\n\tfor _, dErr := range dErrs {\n\t\tif dErr.Code != \"\" {\n\t\t\tdeleteErrors = append(deleteErrors, dErr)\n\t\t}\n\t}\n\n\t// Generate response\n\tresponse := generateMultiDeleteResponse(deleteObjects.Quiet, deletedObjects, deleteErrors)\n\tencodedSuccessResponse := encodeResponse(response)\n\n\t// Write success response.\n\twriteSuccessResponseXML(w, encodedSuccessResponse)\n\tfor _, dobj := range deletedObjects {\n\t\tif dobj.ObjectName == \"\" {\n\t\t\tcontinue\n\t\t}\n\n\t\tif replicateDeletes {\n\t\t\tif dobj.DeleteMarkerReplicationStatus == string(replication.Pending) || dobj.VersionPurgeStatus == Pending {\n\t\t\t\tdv := DeletedObjectVersionInfo{\n\t\t\t\t\tDeletedObject: dobj,\n\t\t\t\t\tBucket:        bucket,\n\t\t\t\t}\n\t\t\t\tscheduleReplicationDelete(ctx, dv, objectAPI, replicateSync)\n\t\t\t}\n\t\t}\n\n\t\tif hasLifecycleConfig && dobj.PurgeTransitioned == lifecycle.TransitionComplete { // clean up transitioned tier\n\t\t\tdeleteTransitionedObject(ctx, objectAPI, bucket, dobj.ObjectName, lifecycle.ObjectOpts{\n\t\t\t\tName:         dobj.ObjectName,\n\t\t\t\tVersionID:    dobj.VersionID,\n\t\t\t\tDeleteMarker: dobj.DeleteMarker,\n\t\t\t}, false, true)\n\t\t}\n\n\t\teventName := event.ObjectRemovedDelete\n\t\tobjInfo := ObjectInfo{\n\t\t\tName:      dobj.ObjectName,\n\t\t\tVersionID: dobj.VersionID,\n\t\t}\n\n\t\tif dobj.DeleteMarker {\n\t\t\tobjInfo.DeleteMarker = dobj.DeleteMarker\n\t\t\tobjInfo.VersionID = dobj.DeleteMarkerVersionID\n\t\t\teventName = event.ObjectRemovedDeleteMarkerCreated\n\t\t}\n\n\t\tsendEvent(eventArgs{\n\t\t\tEventName:    eventName,\n\t\t\tBucketName:   bucket,\n\t\t\tObject:       objInfo,\n\t\t\tReqParams:    extractReqParams(r),\n\t\t\tRespElements: extractRespElements(w),\n\t\t\tUserAgent:    r.UserAgent(),\n\t\t\tHost:         handlers.GetSourceIP(r),\n\t\t})\n\t}\n}\n\n// PutBucketHandler - PUT Bucket\n// ----------\n// This implementation of the PUT operation creates a new bucket for authenticated request\nfunc (api objectAPIHandlers) PutBucketHandler(w http.ResponseWriter, r *http.Request) {\n\tctx := newContext(r, w, \"PutBucket\")\n\n\tdefer logger.AuditLog(ctx, w, r, mustGetClaimsFromToken(r))\n\n\tobjectAPI := api.ObjectAPI()\n\tif objectAPI == nil {\n\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(ErrServerNotInitialized), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\tvars := mux.Vars(r)\n\tbucket := vars[\"bucket\"]\n\n\tobjectLockEnabled := false\n\tif vs, found := r.Header[http.CanonicalHeaderKey(\"x-amz-bucket-object-lock-enabled\")]; found {\n\t\tv := strings.ToLower(strings.Join(vs, \"\"))\n\t\tif v != \"true\" && v != \"false\" {\n\t\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(ErrInvalidRequest), r.URL, guessIsBrowserReq(r))\n\t\t\treturn\n\t\t}\n\t\tobjectLockEnabled = v == \"true\"\n\t}\n\n\tif s3Error := checkRequestAuthType(ctx, r, policy.CreateBucketAction, bucket, \"\"); s3Error != ErrNone {\n\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(s3Error), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\t// Parse incoming location constraint.\n\tlocation, s3Error := parseLocationConstraint(r)\n\tif s3Error != ErrNone {\n\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(s3Error), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\t// Validate if location sent by the client is valid, reject\n\t// requests which do not follow valid region requirements.\n\tif !isValidLocation(location) {\n\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(ErrInvalidRegion), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\topts := BucketOptions{\n\t\tLocation:    location,\n\t\tLockEnabled: objectLockEnabled,\n\t}\n\n\tif globalDNSConfig != nil {\n\t\tsr, err := globalDNSConfig.Get(bucket)\n\t\tif err != nil {\n\t\t\t// ErrNotImplemented indicates a DNS backend that doesn't need to check if bucket already\n\t\t\t// exists elsewhere\n\t\t\tif err == dns.ErrNoEntriesFound || err == dns.ErrNotImplemented {\n\t\t\t\t// Proceed to creating a bucket.\n\t\t\t\tif err = objectAPI.MakeBucketWithLocation(ctx, bucket, opts); err != nil {\n\t\t\t\t\twriteErrorResponse(ctx, w, toAPIError(ctx, err), r.URL, guessIsBrowserReq(r))\n\t\t\t\t\treturn\n\t\t\t\t}\n\n\t\t\t\tif err = globalDNSConfig.Put(bucket); err != nil {\n\t\t\t\t\tobjectAPI.DeleteBucket(ctx, bucket, false)\n\t\t\t\t\twriteErrorResponse(ctx, w, toAPIError(ctx, err), r.URL, guessIsBrowserReq(r))\n\t\t\t\t\treturn\n\t\t\t\t}\n\n\t\t\t\t// Load updated bucket metadata into memory.\n\t\t\t\tglobalNotificationSys.LoadBucketMetadata(GlobalContext, bucket)\n\n\t\t\t\t// Make sure to add Location information here only for bucket\n\t\t\t\tw.Header().Set(xhttp.Location,\n\t\t\t\t\tgetObjectLocation(r, globalDomainNames, bucket, \"\"))\n\n\t\t\t\twriteSuccessResponseHeadersOnly(w)\n\n\t\t\t\tsendEvent(eventArgs{\n\t\t\t\t\tEventName:    event.BucketCreated,\n\t\t\t\t\tBucketName:   bucket,\n\t\t\t\t\tReqParams:    extractReqParams(r),\n\t\t\t\t\tRespElements: extractRespElements(w),\n\t\t\t\t\tUserAgent:    r.UserAgent(),\n\t\t\t\t\tHost:         handlers.GetSourceIP(r),\n\t\t\t\t})\n\n\t\t\t\treturn\n\t\t\t}\n\t\t\twriteErrorResponse(ctx, w, toAPIError(ctx, err), r.URL, guessIsBrowserReq(r))\n\t\t\treturn\n\n\t\t}\n\t\tapiErr := ErrBucketAlreadyExists\n\t\tif !globalDomainIPs.Intersection(set.CreateStringSet(getHostsSlice(sr)...)).IsEmpty() {\n\t\t\tapiErr = ErrBucketAlreadyOwnedByYou\n\t\t}\n\t\t// No IPs seem to intersect, this means that bucket exists but has\n\t\t// different IP addresses perhaps from a different deployment.\n\t\t// bucket names are globally unique in federation at a given\n\t\t// path prefix, name collision is not allowed. Return appropriate error.\n\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(apiErr), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\t// Proceed to creating a bucket.\n\terr := objectAPI.MakeBucketWithLocation(ctx, bucket, opts)\n\tif err != nil {\n\t\twriteErrorResponse(ctx, w, toAPIError(ctx, err), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\t// Load updated bucket metadata into memory.\n\tglobalNotificationSys.LoadBucketMetadata(GlobalContext, bucket)\n\n\t// Make sure to add Location information here only for bucket\n\tw.Header().Set(xhttp.Location, path.Clean(r.URL.Path)) // Clean any trailing slashes.\n\n\twriteSuccessResponseHeadersOnly(w)\n\n\tsendEvent(eventArgs{\n\t\tEventName:    event.BucketCreated,\n\t\tBucketName:   bucket,\n\t\tReqParams:    extractReqParams(r),\n\t\tRespElements: extractRespElements(w),\n\t\tUserAgent:    r.UserAgent(),\n\t\tHost:         handlers.GetSourceIP(r),\n\t})\n}\n\n// PostPolicyBucketHandler - POST policy\n// ----------\n// This implementation of the POST operation handles object creation with a specified\n// signature policy in multipart/form-data\nfunc (api objectAPIHandlers) PostPolicyBucketHandler(w http.ResponseWriter, r *http.Request) {\n\tctx := newContext(r, w, \"PostPolicyBucket\")\n\n\tdefer logger.AuditLog(ctx, w, r, mustGetClaimsFromToken(r))\n\n\tobjectAPI := api.ObjectAPI()\n\tif objectAPI == nil {\n\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(ErrServerNotInitialized), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\tif crypto.S3KMS.IsRequested(r.Header) { // SSE-KMS is not supported\n\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(ErrNotImplemented), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\tif _, ok := crypto.IsRequested(r.Header); !objectAPI.IsEncryptionSupported() && ok {\n\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(ErrNotImplemented), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\tbucket := mux.Vars(r)[\"bucket\"]\n\n\t// Require Content-Length to be set in the request\n\tsize := r.ContentLength\n\tif size < 0 {\n\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(ErrMissingContentLength), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\tresource, err := getResource(r.URL.Path, r.Host, globalDomainNames)\n\tif err != nil {\n\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(ErrInvalidRequest), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\t// Make sure that the URL does not contain object name.\n\tif bucket != path.Clean(resource[1:]) {\n\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(ErrMethodNotAllowed), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\t// Here the parameter is the size of the form data that should\n\t// be loaded in memory, the remaining being put in temporary files.\n\treader, err := r.MultipartReader()\n\tif err != nil {\n\t\tlogger.LogIf(ctx, err)\n\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(ErrMalformedPOSTRequest), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\t// Read multipart data and save in memory and in the disk if needed\n\tform, err := reader.ReadForm(maxFormMemory)\n\tif err != nil {\n\t\tlogger.LogIf(ctx, err, logger.Application)\n\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(ErrMalformedPOSTRequest), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\t// Remove all tmp files created during multipart upload\n\tdefer form.RemoveAll()\n\n\t// Extract all form fields\n\tfileBody, fileName, fileSize, formValues, err := extractPostPolicyFormValues(ctx, form)\n\tif err != nil {\n\t\tlogger.LogIf(ctx, err, logger.Application)\n\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(ErrMalformedPOSTRequest), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\t// Check if file is provided, error out otherwise.\n\tif fileBody == nil {\n\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(ErrPOSTFileRequired), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\t// Close multipart file\n\tdefer fileBody.Close()\n\n\tformValues.Set(\"Bucket\", bucket)\n\tif fileName != \"\" && strings.Contains(formValues.Get(\"Key\"), \"${filename}\") {\n\t\t// S3 feature to replace ${filename} found in Key form field\n\t\t// by the filename attribute passed in multipart\n\t\tformValues.Set(\"Key\", strings.Replace(formValues.Get(\"Key\"), \"${filename}\", fileName, -1))\n\t}\n\tobject := formValues.Get(\"Key\")\n\n\tsuccessRedirect := formValues.Get(\"success_action_redirect\")\n\tsuccessStatus := formValues.Get(\"success_action_status\")\n\tvar redirectURL *url.URL\n\tif successRedirect != \"\" {\n\t\tredirectURL, err = url.Parse(successRedirect)\n\t\tif err != nil {\n\t\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(ErrMalformedPOSTRequest), r.URL, guessIsBrowserReq(r))\n\t\t\treturn\n\t\t}\n\t}\n\n\t// Verify policy signature.\n\tcred, errCode := doesPolicySignatureMatch(formValues)\n\tif errCode != ErrNone {\n\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(errCode), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\t// Once signature is validated, check if the user has\n\t// explicit permissions for the user.\n\t{\n\t\ttoken := formValues.Get(xhttp.AmzSecurityToken)\n\t\tif token != \"\" && cred.AccessKey == \"\" {\n\t\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(ErrNoAccessKey), r.URL, guessIsBrowserReq(r))\n\t\t\treturn\n\t\t}\n\n\t\tif cred.IsServiceAccount() && token == \"\" {\n\t\t\ttoken = cred.SessionToken\n\t\t}\n\n\t\tif subtle.ConstantTimeCompare([]byte(token), []byte(cred.SessionToken)) != 1 {\n\t\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(ErrInvalidToken), r.URL, guessIsBrowserReq(r))\n\t\t\treturn\n\t\t}\n\n\t\t// Extract claims if any.\n\t\tclaims, err := getClaimsFromToken(token)\n\t\tif err != nil {\n\t\t\twriteErrorResponse(ctx, w, toAPIError(ctx, err), r.URL, guessIsBrowserReq(r))\n\t\t\treturn\n\t\t}\n\n\t\tif !globalIAMSys.IsAllowed(iampolicy.Args{\n\t\t\tAccountName:     cred.AccessKey,\n\t\t\tAction:          iampolicy.PutObjectAction,\n\t\t\tConditionValues: getConditionValues(r, \"\", cred.AccessKey, claims),\n\t\t\tBucketName:      bucket,\n\t\t\tObjectName:      object,\n\t\t\tIsOwner:         globalActiveCred.AccessKey == cred.AccessKey,\n\t\t\tClaims:          claims,\n\t\t}) {\n\t\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(ErrAccessDenied), r.URL, guessIsBrowserReq(r))\n\t\t\treturn\n\t\t}\n\t}\n\n\tpolicyBytes, err := base64.StdEncoding.DecodeString(formValues.Get(\"Policy\"))\n\tif err != nil {\n\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(ErrMalformedPOSTRequest), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\t// Handle policy if it is set.\n\tif len(policyBytes) > 0 {\n\n\t\tpostPolicyForm, err := parsePostPolicyForm(string(policyBytes))\n\t\tif err != nil {\n\t\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(ErrPostPolicyConditionInvalidFormat), r.URL, guessIsBrowserReq(r))\n\t\t\treturn\n\t\t}\n\n\t\t// Make sure formValues adhere to policy restrictions.\n\t\tif err = checkPostPolicy(formValues, postPolicyForm); err != nil {\n\t\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErrWithErr(ErrAccessDenied, err), r.URL, guessIsBrowserReq(r))\n\t\t\treturn\n\t\t}\n\n\t\t// Ensure that the object size is within expected range, also the file size\n\t\t// should not exceed the maximum single Put size (5 GiB)\n\t\tlengthRange := postPolicyForm.Conditions.ContentLengthRange\n\t\tif lengthRange.Valid {\n\t\t\tif fileSize < lengthRange.Min {\n\t\t\t\twriteErrorResponse(ctx, w, toAPIError(ctx, errDataTooSmall), r.URL, guessIsBrowserReq(r))\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\tif fileSize > lengthRange.Max || isMaxObjectSize(fileSize) {\n\t\t\t\twriteErrorResponse(ctx, w, toAPIError(ctx, errDataTooLarge), r.URL, guessIsBrowserReq(r))\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\t}\n\n\t// Extract metadata to be saved from received Form.\n\tmetadata := make(map[string]string)\n\terr = extractMetadataFromMime(ctx, textproto.MIMEHeader(formValues), metadata)\n\tif err != nil {\n\t\twriteErrorResponse(ctx, w, toAPIError(ctx, err), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\thashReader, err := hash.NewReader(fileBody, fileSize, \"\", \"\", fileSize)\n\tif err != nil {\n\t\tlogger.LogIf(ctx, err)\n\t\twriteErrorResponse(ctx, w, toAPIError(ctx, err), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\trawReader := hashReader\n\tpReader := NewPutObjReader(rawReader)\n\tvar objectEncryptionKey crypto.ObjectKey\n\n\t// Check if bucket encryption is enabled\n\tif _, err = globalBucketSSEConfigSys.Get(bucket); err == nil || globalAutoEncryption {\n\t\t// This request header needs to be set prior to setting ObjectOptions\n\t\tif !crypto.SSEC.IsRequested(r.Header) {\n\t\t\tr.Header.Set(xhttp.AmzServerSideEncryption, xhttp.AmzEncryptionAES)\n\t\t}\n\t}\n\n\t// get gateway encryption options\n\tvar opts ObjectOptions\n\topts, err = putOpts(ctx, r, bucket, object, metadata)\n\tif err != nil {\n\t\twriteErrorResponseHeadersOnly(w, toAPIError(ctx, err))\n\t\treturn\n\t}\n\tif objectAPI.IsEncryptionSupported() {\n\t\tif _, ok := crypto.IsRequested(formValues); ok && !HasSuffix(object, SlashSeparator) { // handle SSE requests\n\t\t\tif crypto.SSECopy.IsRequested(r.Header) {\n\t\t\t\twriteErrorResponse(ctx, w, toAPIError(ctx, errInvalidEncryptionParameters), r.URL, guessIsBrowserReq(r))\n\t\t\t\treturn\n\t\t\t}\n\t\t\tvar reader io.Reader\n\t\t\tvar key []byte\n\t\t\tif crypto.SSEC.IsRequested(formValues) {\n\t\t\t\tkey, err = ParseSSECustomerHeader(formValues)\n\t\t\t\tif err != nil {\n\t\t\t\t\twriteErrorResponse(ctx, w, toAPIError(ctx, err), r.URL, guessIsBrowserReq(r))\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t}\n\t\t\treader, objectEncryptionKey, err = newEncryptReader(hashReader, key, bucket, object, metadata, crypto.S3.IsRequested(formValues))\n\t\t\tif err != nil {\n\t\t\t\twriteErrorResponse(ctx, w, toAPIError(ctx, err), r.URL, guessIsBrowserReq(r))\n\t\t\t\treturn\n\t\t\t}\n\t\t\tinfo := ObjectInfo{Size: fileSize}\n\t\t\t// do not try to verify encrypted content\n\t\t\thashReader, err = hash.NewReader(reader, info.EncryptedSize(), \"\", \"\", fileSize)\n\t\t\tif err != nil {\n\t\t\t\twriteErrorResponse(ctx, w, toAPIError(ctx, err), r.URL, guessIsBrowserReq(r))\n\t\t\t\treturn\n\t\t\t}\n\t\t\tpReader, err = pReader.WithEncryption(hashReader, &objectEncryptionKey)\n\t\t\tif err != nil {\n\t\t\t\twriteErrorResponse(ctx, w, toAPIError(ctx, err), r.URL, guessIsBrowserReq(r))\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\t}\n\n\tobjInfo, err := objectAPI.PutObject(ctx, bucket, object, pReader, opts)\n\tif err != nil {\n\t\twriteErrorResponse(ctx, w, toAPIError(ctx, err), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\t// We must not use the http.Header().Set method here because some (broken)\n\t// clients expect the ETag header key to be literally \"ETag\" - not \"Etag\" (case-sensitive).\n\t// Therefore, we have to set the ETag directly as map entry.\n\tw.Header()[xhttp.ETag] = []string{`\"` + objInfo.ETag + `\"`}\n\n\t// Set the relevant version ID as part of the response header.\n\tif objInfo.VersionID != \"\" {\n\t\tw.Header()[xhttp.AmzVersionID] = []string{objInfo.VersionID}\n\t}\n\n\tw.Header().Set(xhttp.Location, getObjectLocation(r, globalDomainNames, bucket, object))\n\n\t// Notify object created event.\n\tdefer sendEvent(eventArgs{\n\t\tEventName:    event.ObjectCreatedPost,\n\t\tBucketName:   objInfo.Bucket,\n\t\tObject:       objInfo,\n\t\tReqParams:    extractReqParams(r),\n\t\tRespElements: extractRespElements(w),\n\t\tUserAgent:    r.UserAgent(),\n\t\tHost:         handlers.GetSourceIP(r),\n\t})\n\n\tif successRedirect != \"\" {\n\t\t// Replace raw query params..\n\t\tredirectURL.RawQuery = getRedirectPostRawQuery(objInfo)\n\t\twriteRedirectSeeOther(w, redirectURL.String())\n\t\treturn\n\t}\n\n\t// Decide what http response to send depending on success_action_status parameter\n\tswitch successStatus {\n\tcase \"201\":\n\t\tresp := encodeResponse(PostResponse{\n\t\t\tBucket:   objInfo.Bucket,\n\t\t\tKey:      objInfo.Name,\n\t\t\tETag:     `\"` + objInfo.ETag + `\"`,\n\t\t\tLocation: w.Header().Get(xhttp.Location),\n\t\t})\n\t\twriteResponse(w, http.StatusCreated, resp, mimeXML)\n\tcase \"200\":\n\t\twriteSuccessResponseHeadersOnly(w)\n\tdefault:\n\t\twriteSuccessNoContent(w)\n\t}\n}\n\n// GetBucketPolicyStatusHandler -  Retrieves the policy status\n// for an MinIO bucket, indicating whether the bucket is public.\nfunc (api objectAPIHandlers) GetBucketPolicyStatusHandler(w http.ResponseWriter, r *http.Request) {\n\tctx := newContext(r, w, \"GetBucketPolicyStatus\")\n\n\tdefer logger.AuditLog(ctx, w, r, mustGetClaimsFromToken(r))\n\n\tvars := mux.Vars(r)\n\tbucket := vars[\"bucket\"]\n\n\tobjectAPI := api.ObjectAPI()\n\tif objectAPI == nil {\n\t\twriteErrorResponseHeadersOnly(w, errorCodes.ToAPIErr(ErrServerNotInitialized))\n\t\treturn\n\t}\n\n\tif s3Error := checkRequestAuthType(ctx, r, policy.GetBucketPolicyStatusAction, bucket, \"\"); s3Error != ErrNone {\n\t\twriteErrorResponseHeadersOnly(w, errorCodes.ToAPIErr(s3Error))\n\t\treturn\n\t}\n\n\t// Check if bucket exists.\n\tif _, err := objectAPI.GetBucketInfo(ctx, bucket); err != nil {\n\t\twriteErrorResponse(ctx, w, toAPIError(ctx, err), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\t// Check if anonymous (non-owner) has access to list objects.\n\treadable := globalPolicySys.IsAllowed(policy.Args{\n\t\tAction:          policy.ListBucketAction,\n\t\tBucketName:      bucket,\n\t\tConditionValues: getConditionValues(r, \"\", \"\", nil),\n\t\tIsOwner:         false,\n\t})\n\n\t// Check if anonymous (non-owner) has access to upload objects.\n\twritable := globalPolicySys.IsAllowed(policy.Args{\n\t\tAction:          policy.PutObjectAction,\n\t\tBucketName:      bucket,\n\t\tConditionValues: getConditionValues(r, \"\", \"\", nil),\n\t\tIsOwner:         false,\n\t})\n\n\tencodedSuccessResponse := encodeResponse(PolicyStatus{\n\t\tIsPublic: func() string {\n\t\t\t// Silly to have special 'boolean' values yes\n\t\t\t// but complying with silly implementation\n\t\t\t// https://docs.aws.amazon.com/AmazonS3/latest/API/API_GetBucketPolicyStatus.html\n\t\t\tif readable && writable {\n\t\t\t\treturn \"TRUE\"\n\t\t\t}\n\t\t\treturn \"FALSE\"\n\t\t}(),\n\t})\n\n\twriteSuccessResponseXML(w, encodedSuccessResponse)\n}\n\n// HeadBucketHandler - HEAD Bucket\n// ----------\n// This operation is useful to determine if a bucket exists.\n// The operation returns a 200 OK if the bucket exists and you\n// have permission to access it. Otherwise, the operation might\n// return responses such as 404 Not Found and 403 Forbidden.\nfunc (api objectAPIHandlers) HeadBucketHandler(w http.ResponseWriter, r *http.Request) {\n\tctx := newContext(r, w, \"HeadBucket\")\n\n\tdefer logger.AuditLog(ctx, w, r, mustGetClaimsFromToken(r))\n\n\tvars := mux.Vars(r)\n\tbucket := vars[\"bucket\"]\n\n\tobjectAPI := api.ObjectAPI()\n\tif objectAPI == nil {\n\t\twriteErrorResponseHeadersOnly(w, errorCodes.ToAPIErr(ErrServerNotInitialized))\n\t\treturn\n\t}\n\n\tif s3Error := checkRequestAuthType(ctx, r, policy.ListBucketAction, bucket, \"\"); s3Error != ErrNone {\n\t\twriteErrorResponseHeadersOnly(w, errorCodes.ToAPIErr(s3Error))\n\t\treturn\n\t}\n\n\tgetBucketInfo := objectAPI.GetBucketInfo\n\n\tif _, err := getBucketInfo(ctx, bucket); err != nil {\n\t\twriteErrorResponseHeadersOnly(w, toAPIError(ctx, err))\n\t\treturn\n\t}\n\n\twriteSuccessResponseHeadersOnly(w)\n}\n\n// DeleteBucketHandler - Delete bucket\nfunc (api objectAPIHandlers) DeleteBucketHandler(w http.ResponseWriter, r *http.Request) {\n\tctx := newContext(r, w, \"DeleteBucket\")\n\n\tdefer logger.AuditLog(ctx, w, r, mustGetClaimsFromToken(r))\n\n\tvars := mux.Vars(r)\n\tbucket := vars[\"bucket\"]\n\n\tobjectAPI := api.ObjectAPI()\n\tif objectAPI == nil {\n\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(ErrServerNotInitialized), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\t// Verify if the caller has sufficient permissions.\n\tif s3Error := checkRequestAuthType(ctx, r, policy.DeleteBucketAction, bucket, \"\"); s3Error != ErrNone {\n\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(s3Error), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\tforceDelete := false\n\tif value := r.Header.Get(xhttp.MinIOForceDelete); value != \"\" {\n\t\tvar err error\n\t\tforceDelete, err = strconv.ParseBool(value)\n\t\tif err != nil {\n\t\t\tapiErr := errorCodes.ToAPIErr(ErrInvalidRequest)\n\t\t\tapiErr.Description = err.Error()\n\t\t\twriteErrorResponse(ctx, w, apiErr, r.URL, guessIsBrowserReq(r))\n\t\t\treturn\n\t\t}\n\n\t\t// if force delete header is set, we need to evaluate the policy anyways\n\t\t// regardless of it being true or not.\n\t\tif s3Error := checkRequestAuthType(ctx, r, policy.ForceDeleteBucketAction, bucket, \"\"); s3Error != ErrNone {\n\t\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(s3Error), r.URL, guessIsBrowserReq(r))\n\t\t\treturn\n\t\t}\n\n\t\tif forceDelete {\n\t\t\tif rcfg, _ := globalBucketObjectLockSys.Get(bucket); rcfg.LockEnabled {\n\t\t\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(ErrMethodNotAllowed), r.URL, guessIsBrowserReq(r))\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\t}\n\n\tdeleteBucket := objectAPI.DeleteBucket\n\n\t// Attempt to delete bucket.\n\tif err := deleteBucket(ctx, bucket, forceDelete); err != nil {\n\t\tif _, ok := err.(BucketNotEmpty); ok && (globalBucketVersioningSys.Enabled(bucket) || globalBucketVersioningSys.Suspended(bucket)) {\n\t\t\tapiErr := toAPIError(ctx, err)\n\t\t\tapiErr.Description = \"The bucket you tried to delete is not empty. You must delete all versions in the bucket.\"\n\t\t\twriteErrorResponse(ctx, w, apiErr, r.URL, guessIsBrowserReq(r))\n\t\t} else {\n\t\t\twriteErrorResponse(ctx, w, toAPIError(ctx, err), r.URL, guessIsBrowserReq(r))\n\t\t}\n\t\treturn\n\t}\n\n\tglobalNotificationSys.DeleteBucketMetadata(ctx, bucket)\n\n\tif globalDNSConfig != nil {\n\t\tif err := globalDNSConfig.Delete(bucket); err != nil {\n\t\t\tlogger.LogIf(ctx, fmt.Errorf(\"Unable to delete bucket DNS entry %w, please delete it manually\", err))\n\t\t\twriteErrorResponse(ctx, w, toAPIError(ctx, err), r.URL, guessIsBrowserReq(r))\n\t\t\treturn\n\t\t}\n\t}\n\n\t// Write success response.\n\twriteSuccessNoContent(w)\n\n\tsendEvent(eventArgs{\n\t\tEventName:    event.BucketRemoved,\n\t\tBucketName:   bucket,\n\t\tReqParams:    extractReqParams(r),\n\t\tRespElements: extractRespElements(w),\n\t\tUserAgent:    r.UserAgent(),\n\t\tHost:         handlers.GetSourceIP(r),\n\t})\n}\n\n// PutBucketObjectLockConfigHandler - PUT Bucket object lock configuration.\n// ----------\n// Places an Object Lock configuration on the specified bucket. The rule\n// specified in the Object Lock configuration will be applied by default\n// to every new object placed in the specified bucket.\nfunc (api objectAPIHandlers) PutBucketObjectLockConfigHandler(w http.ResponseWriter, r *http.Request) {\n\tctx := newContext(r, w, \"PutBucketObjectLockConfig\")\n\n\tdefer logger.AuditLog(ctx, w, r, mustGetClaimsFromToken(r))\n\n\tvars := mux.Vars(r)\n\tbucket := vars[\"bucket\"]\n\n\tobjectAPI := api.ObjectAPI()\n\tif objectAPI == nil {\n\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(ErrServerNotInitialized), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\tif !globalIsErasure {\n\t\twriteErrorResponseJSON(ctx, w, errorCodes.ToAPIErr(ErrNotImplemented), r.URL)\n\t\treturn\n\t}\n\tif s3Error := checkRequestAuthType(ctx, r, policy.PutBucketObjectLockConfigurationAction, bucket, \"\"); s3Error != ErrNone {\n\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(s3Error), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\tconfig, err := objectlock.ParseObjectLockConfig(r.Body)\n\tif err != nil {\n\t\tapiErr := errorCodes.ToAPIErr(ErrMalformedXML)\n\t\tapiErr.Description = err.Error()\n\t\twriteErrorResponse(ctx, w, apiErr, r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\tconfigData, err := xml.Marshal(config)\n\tif err != nil {\n\t\twriteErrorResponse(ctx, w, toAPIError(ctx, err), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\t// Deny object locking configuration settings on existing buckets without object lock enabled.\n\tif _, err = globalBucketMetadataSys.GetObjectLockConfig(bucket); err != nil {\n\t\twriteErrorResponse(ctx, w, toAPIError(ctx, err), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\tif err = globalBucketMetadataSys.Update(bucket, objectLockConfig, configData); err != nil {\n\t\twriteErrorResponse(ctx, w, toAPIError(ctx, err), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\t// Write success response.\n\twriteSuccessResponseHeadersOnly(w)\n}\n\n// GetBucketObjectLockConfigHandler - GET Bucket object lock configuration.\n// ----------\n// Gets the Object Lock configuration for a bucket. The rule specified in\n// the Object Lock configuration will be applied by default to every new\n// object placed in the specified bucket.\nfunc (api objectAPIHandlers) GetBucketObjectLockConfigHandler(w http.ResponseWriter, r *http.Request) {\n\tctx := newContext(r, w, \"GetBucketObjectLockConfig\")\n\n\tdefer logger.AuditLog(ctx, w, r, mustGetClaimsFromToken(r))\n\n\tvars := mux.Vars(r)\n\tbucket := vars[\"bucket\"]\n\n\tobjectAPI := api.ObjectAPI()\n\tif objectAPI == nil {\n\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(ErrServerNotInitialized), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\t// check if user has permissions to perform this operation\n\tif s3Error := checkRequestAuthType(ctx, r, policy.GetBucketObjectLockConfigurationAction, bucket, \"\"); s3Error != ErrNone {\n\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(s3Error), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\tconfig, err := globalBucketMetadataSys.GetObjectLockConfig(bucket)\n\tif err != nil {\n\t\twriteErrorResponse(ctx, w, toAPIError(ctx, err), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\tconfigData, err := xml.Marshal(config)\n\tif err != nil {\n\t\twriteErrorResponse(ctx, w, toAPIError(ctx, err), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\t// Write success response.\n\twriteSuccessResponseXML(w, configData)\n}\n\n// PutBucketTaggingHandler - PUT Bucket tagging.\n// ----------\nfunc (api objectAPIHandlers) PutBucketTaggingHandler(w http.ResponseWriter, r *http.Request) {\n\tctx := newContext(r, w, \"PutBucketTagging\")\n\n\tdefer logger.AuditLog(ctx, w, r, mustGetClaimsFromToken(r))\n\n\tvars := mux.Vars(r)\n\tbucket := vars[\"bucket\"]\n\n\tobjectAPI := api.ObjectAPI()\n\tif objectAPI == nil {\n\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(ErrServerNotInitialized), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\tif s3Error := checkRequestAuthType(ctx, r, policy.PutBucketTaggingAction, bucket, \"\"); s3Error != ErrNone {\n\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(s3Error), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\ttags, err := tags.ParseBucketXML(io.LimitReader(r.Body, r.ContentLength))\n\tif err != nil {\n\t\tapiErr := errorCodes.ToAPIErr(ErrMalformedXML)\n\t\tapiErr.Description = err.Error()\n\t\twriteErrorResponse(ctx, w, apiErr, r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\tconfigData, err := xml.Marshal(tags)\n\tif err != nil {\n\t\twriteErrorResponse(ctx, w, toAPIError(ctx, err), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\tif err = globalBucketMetadataSys.Update(bucket, bucketTaggingConfig, configData); err != nil {\n\t\twriteErrorResponse(ctx, w, toAPIError(ctx, err), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\t// Write success response.\n\twriteSuccessResponseHeadersOnly(w)\n}\n\n// GetBucketTaggingHandler - GET Bucket tagging.\n// ----------\nfunc (api objectAPIHandlers) GetBucketTaggingHandler(w http.ResponseWriter, r *http.Request) {\n\tctx := newContext(r, w, \"GetBucketTagging\")\n\n\tdefer logger.AuditLog(ctx, w, r, mustGetClaimsFromToken(r))\n\n\tvars := mux.Vars(r)\n\tbucket := vars[\"bucket\"]\n\n\tobjectAPI := api.ObjectAPI()\n\tif objectAPI == nil {\n\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(ErrServerNotInitialized), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\t// check if user has permissions to perform this operation\n\tif s3Error := checkRequestAuthType(ctx, r, policy.GetBucketTaggingAction, bucket, \"\"); s3Error != ErrNone {\n\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(s3Error), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\tconfig, err := globalBucketMetadataSys.GetTaggingConfig(bucket)\n\tif err != nil {\n\t\twriteErrorResponse(ctx, w, toAPIError(ctx, err), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\tconfigData, err := xml.Marshal(config)\n\tif err != nil {\n\t\twriteErrorResponse(ctx, w, toAPIError(ctx, err), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\t// Write success response.\n\twriteSuccessResponseXML(w, configData)\n}\n\n// DeleteBucketTaggingHandler - DELETE Bucket tagging.\n// ----------\nfunc (api objectAPIHandlers) DeleteBucketTaggingHandler(w http.ResponseWriter, r *http.Request) {\n\tctx := newContext(r, w, \"DeleteBucketTagging\")\n\n\tdefer logger.AuditLog(ctx, w, r, mustGetClaimsFromToken(r))\n\n\tvars := mux.Vars(r)\n\tbucket := vars[\"bucket\"]\n\n\tobjectAPI := api.ObjectAPI()\n\tif objectAPI == nil {\n\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(ErrServerNotInitialized), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\tif s3Error := checkRequestAuthType(ctx, r, policy.PutBucketTaggingAction, bucket, \"\"); s3Error != ErrNone {\n\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(s3Error), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\tif err := globalBucketMetadataSys.Update(bucket, bucketTaggingConfig, nil); err != nil {\n\t\twriteErrorResponse(ctx, w, toAPIError(ctx, err), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\t// Write success response.\n\twriteSuccessResponseHeadersOnly(w)\n}\n\n// PutBucketReplicationConfigHandler - PUT Bucket replication configuration.\n// ----------\n// Add a replication configuration on the specified bucket as specified in https://docs.aws.amazon.com/AmazonS3/latest/API/API_PutBucketReplication.html\nfunc (api objectAPIHandlers) PutBucketReplicationConfigHandler(w http.ResponseWriter, r *http.Request) {\n\tctx := newContext(r, w, \"PutBucketReplicationConfig\")\n\tdefer logger.AuditLog(ctx, w, r, mustGetClaimsFromToken(r))\n\n\tvars := mux.Vars(r)\n\tbucket := vars[\"bucket\"]\n\tobjectAPI := api.ObjectAPI()\n\tif objectAPI == nil {\n\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(ErrServerNotInitialized), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\tif !globalIsErasure {\n\t\twriteErrorResponseJSON(ctx, w, errorCodes.ToAPIErr(ErrNotImplemented), r.URL)\n\t\treturn\n\t}\n\tif s3Error := checkRequestAuthType(ctx, r, policy.PutReplicationConfigurationAction, bucket, \"\"); s3Error != ErrNone {\n\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(s3Error), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\t// Check if bucket exists.\n\tif _, err := objectAPI.GetBucketInfo(ctx, bucket); err != nil {\n\t\twriteErrorResponse(ctx, w, toAPIError(ctx, err), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\tif versioned := globalBucketVersioningSys.Enabled(bucket); !versioned {\n\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(ErrReplicationNeedsVersioningError), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\treplicationConfig, err := replication.ParseConfig(io.LimitReader(r.Body, r.ContentLength))\n\tif err != nil {\n\t\tapiErr := errorCodes.ToAPIErr(ErrMalformedXML)\n\t\tapiErr.Description = err.Error()\n\t\twriteErrorResponse(ctx, w, apiErr, r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\tsameTarget, err := validateReplicationDestination(ctx, bucket, replicationConfig)\n\tif err != nil {\n\t\twriteErrorResponse(ctx, w, toAPIError(ctx, err), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\t// Validate the received bucket replication config\n\tif err = replicationConfig.Validate(bucket, sameTarget); err != nil {\n\t\twriteErrorResponse(ctx, w, toAPIError(ctx, err), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\tconfigData, err := xml.Marshal(replicationConfig)\n\tif err != nil {\n\t\twriteErrorResponse(ctx, w, toAPIError(ctx, err), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\tif err = globalBucketMetadataSys.Update(bucket, bucketReplicationConfig, configData); err != nil {\n\t\twriteErrorResponse(ctx, w, toAPIError(ctx, err), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\t// Write success response.\n\twriteSuccessResponseHeadersOnly(w)\n}\n\n// GetBucketReplicationConfigHandler - GET Bucket replication configuration.\n// ----------\n// Gets the replication configuration for a bucket.\nfunc (api objectAPIHandlers) GetBucketReplicationConfigHandler(w http.ResponseWriter, r *http.Request) {\n\tctx := newContext(r, w, \"GetBucketReplicationConfig\")\n\n\tdefer logger.AuditLog(ctx, w, r, mustGetClaimsFromToken(r))\n\n\tvars := mux.Vars(r)\n\tbucket := vars[\"bucket\"]\n\n\tobjectAPI := api.ObjectAPI()\n\tif objectAPI == nil {\n\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(ErrServerNotInitialized), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\t// check if user has permissions to perform this operation\n\tif s3Error := checkRequestAuthType(ctx, r, policy.GetReplicationConfigurationAction, bucket, \"\"); s3Error != ErrNone {\n\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(s3Error), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\t// Check if bucket exists.\n\tif _, err := objectAPI.GetBucketInfo(ctx, bucket); err != nil {\n\t\twriteErrorResponse(ctx, w, toAPIError(ctx, err), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\tconfig, err := globalBucketMetadataSys.GetReplicationConfig(ctx, bucket)\n\tif err != nil {\n\t\twriteErrorResponse(ctx, w, toAPIError(ctx, err), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\tconfigData, err := xml.Marshal(config)\n\tif err != nil {\n\t\twriteErrorResponse(ctx, w, toAPIError(ctx, err), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\t// Write success response.\n\twriteSuccessResponseXML(w, configData)\n}\n\n// DeleteBucketReplicationConfigHandler - DELETE Bucket replication config.\n// ----------\nfunc (api objectAPIHandlers) DeleteBucketReplicationConfigHandler(w http.ResponseWriter, r *http.Request) {\n\tctx := newContext(r, w, \"DeleteBucketReplicationConfig\")\n\tdefer logger.AuditLog(ctx, w, r, mustGetClaimsFromToken(r))\n\tvars := mux.Vars(r)\n\tbucket := vars[\"bucket\"]\n\n\tobjectAPI := api.ObjectAPI()\n\tif objectAPI == nil {\n\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(ErrServerNotInitialized), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\tif s3Error := checkRequestAuthType(ctx, r, policy.PutReplicationConfigurationAction, bucket, \"\"); s3Error != ErrNone {\n\t\twriteErrorResponse(ctx, w, errorCodes.ToAPIErr(s3Error), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\t// Check if bucket exists.\n\tif _, err := objectAPI.GetBucketInfo(ctx, bucket); err != nil {\n\t\twriteErrorResponse(ctx, w, toAPIError(ctx, err), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\tif err := globalBucketMetadataSys.Update(bucket, bucketReplicationConfig, nil); err != nil {\n\t\twriteErrorResponse(ctx, w, toAPIError(ctx, err), r.URL, guessIsBrowserReq(r))\n\t\treturn\n\t}\n\n\t// Write success response.\n\twriteSuccessResponseHeadersOnly(w)\n}\n", "/*\n * MinIO Cloud Storage, (C) 2016, 2017 MinIO, Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\npackage cmd\n\nimport (\n\t\"crypto/hmac\"\n\t\"crypto/sha1\"\n\t\"crypto/subtle\"\n\t\"encoding/base64\"\n\t\"fmt\"\n\t\"net/http\"\n\t\"net/url\"\n\t\"sort\"\n\t\"strconv\"\n\t\"strings\"\n\n\txhttp \"github.com/minio/minio/cmd/http\"\n\n\t\"github.com/minio/minio/pkg/auth\"\n)\n\n// Whitelist resource list that will be used in query string for signature-V2 calculation.\n//\n// This list should be kept alphabetically sorted, do not hastily edit.\nvar resourceList = []string{\n\t\"acl\",\n\t\"cors\",\n\t\"delete\",\n\t\"encryption\",\n\t\"legal-hold\",\n\t\"lifecycle\",\n\t\"location\",\n\t\"logging\",\n\t\"notification\",\n\t\"partNumber\",\n\t\"policy\",\n\t\"requestPayment\",\n\t\"response-cache-control\",\n\t\"response-content-disposition\",\n\t\"response-content-encoding\",\n\t\"response-content-language\",\n\t\"response-content-type\",\n\t\"response-expires\",\n\t\"retention\",\n\t\"select\",\n\t\"select-type\",\n\t\"tagging\",\n\t\"torrent\",\n\t\"uploadId\",\n\t\"uploads\",\n\t\"versionId\",\n\t\"versioning\",\n\t\"versions\",\n\t\"website\",\n}\n\n// Signature and API related constants.\nconst (\n\tsignV2Algorithm = \"AWS\"\n)\n\n// AWS S3 Signature V2 calculation rule is give here:\n// http://docs.aws.amazon.com/AmazonS3/latest/dev/RESTAuthentication.html#RESTAuthenticationStringToSign\nfunc doesPolicySignatureV2Match(formValues http.Header) (auth.Credentials, APIErrorCode) {\n\taccessKey := formValues.Get(xhttp.AmzAccessKeyID)\n\tcred, _, s3Err := checkKeyValid(accessKey)\n\tif s3Err != ErrNone {\n\t\treturn cred, s3Err\n\t}\n\tpolicy := formValues.Get(\"Policy\")\n\tsignature := formValues.Get(xhttp.AmzSignatureV2)\n\tif !compareSignatureV2(signature, calculateSignatureV2(policy, cred.SecretKey)) {\n\t\treturn cred, ErrSignatureDoesNotMatch\n\t}\n\treturn cred, ErrNone\n}\n\n// Escape encodedQuery string into unescaped list of query params, returns error\n// if any while unescaping the values.\nfunc unescapeQueries(encodedQuery string) (unescapedQueries []string, err error) {\n\tfor _, query := range strings.Split(encodedQuery, \"&\") {\n\t\tvar unescapedQuery string\n\t\tunescapedQuery, err = url.QueryUnescape(query)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tunescapedQueries = append(unescapedQueries, unescapedQuery)\n\t}\n\treturn unescapedQueries, nil\n}\n\n// doesPresignV2SignatureMatch - Verify query headers with presigned signature\n//     - http://docs.aws.amazon.com/AmazonS3/latest/dev/RESTAuthentication.html#RESTAuthenticationQueryStringAuth\n// returns ErrNone if matches. S3 errors otherwise.\nfunc doesPresignV2SignatureMatch(r *http.Request) APIErrorCode {\n\t// r.RequestURI will have raw encoded URI as sent by the client.\n\ttokens := strings.SplitN(r.RequestURI, \"?\", 2)\n\tencodedResource := tokens[0]\n\tencodedQuery := \"\"\n\tif len(tokens) == 2 {\n\t\tencodedQuery = tokens[1]\n\t}\n\n\tvar (\n\t\tfilteredQueries []string\n\t\tgotSignature    string\n\t\texpires         string\n\t\taccessKey       string\n\t\terr             error\n\t)\n\n\tvar unescapedQueries []string\n\tunescapedQueries, err = unescapeQueries(encodedQuery)\n\tif err != nil {\n\t\treturn ErrInvalidQueryParams\n\t}\n\n\t// Extract the necessary values from presigned query, construct a list of new filtered queries.\n\tfor _, query := range unescapedQueries {\n\t\tkeyval := strings.SplitN(query, \"=\", 2)\n\t\tif len(keyval) != 2 {\n\t\t\treturn ErrInvalidQueryParams\n\t\t}\n\t\tswitch keyval[0] {\n\t\tcase xhttp.AmzAccessKeyID:\n\t\t\taccessKey = keyval[1]\n\t\tcase xhttp.AmzSignatureV2:\n\t\t\tgotSignature = keyval[1]\n\t\tcase xhttp.Expires:\n\t\t\texpires = keyval[1]\n\t\tdefault:\n\t\t\tfilteredQueries = append(filteredQueries, query)\n\t\t}\n\t}\n\n\t// Invalid values returns error.\n\tif accessKey == \"\" || gotSignature == \"\" || expires == \"\" {\n\t\treturn ErrInvalidQueryParams\n\t}\n\n\tcred, _, s3Err := checkKeyValid(accessKey)\n\tif s3Err != ErrNone {\n\t\treturn s3Err\n\t}\n\n\t// Make sure the request has not expired.\n\texpiresInt, err := strconv.ParseInt(expires, 10, 64)\n\tif err != nil {\n\t\treturn ErrMalformedExpires\n\t}\n\n\t// Check if the presigned URL has expired.\n\tif expiresInt < UTCNow().Unix() {\n\t\treturn ErrExpiredPresignRequest\n\t}\n\n\tencodedResource, err = getResource(encodedResource, r.Host, globalDomainNames)\n\tif err != nil {\n\t\treturn ErrInvalidRequest\n\t}\n\n\texpectedSignature := preSignatureV2(cred, r.Method, encodedResource, strings.Join(filteredQueries, \"&\"), r.Header, expires)\n\tif !compareSignatureV2(gotSignature, expectedSignature) {\n\t\treturn ErrSignatureDoesNotMatch\n\t}\n\n\treturn ErrNone\n}\n\nfunc getReqAccessKeyV2(r *http.Request) (auth.Credentials, bool, APIErrorCode) {\n\tif accessKey := r.URL.Query().Get(xhttp.AmzAccessKeyID); accessKey != \"\" {\n\t\treturn checkKeyValid(accessKey)\n\t}\n\n\t// below is V2 Signed Auth header format, splitting on `space` (after the `AWS` string).\n\t// Authorization = \"AWS\" + \" \" + AWSAccessKeyId + \":\" + Signature\n\tauthFields := strings.Split(r.Header.Get(xhttp.Authorization), \" \")\n\tif len(authFields) != 2 {\n\t\treturn auth.Credentials{}, false, ErrMissingFields\n\t}\n\n\t// Then will be splitting on \":\", this will seprate `AWSAccessKeyId` and `Signature` string.\n\tkeySignFields := strings.Split(strings.TrimSpace(authFields[1]), \":\")\n\tif len(keySignFields) != 2 {\n\t\treturn auth.Credentials{}, false, ErrMissingFields\n\t}\n\n\treturn checkKeyValid(keySignFields[0])\n}\n\n// Authorization = \"AWS\" + \" \" + AWSAccessKeyId + \":\" + Signature;\n// Signature = Base64( HMAC-SHA1( YourSecretKey, UTF-8-Encoding-Of( StringToSign ) ) );\n//\n// StringToSign = HTTP-Verb + \"\\n\" +\n//  \tContent-Md5 + \"\\n\" +\n//  \tContent-Type + \"\\n\" +\n//  \tDate + \"\\n\" +\n//  \tCanonicalizedProtocolHeaders +\n//  \tCanonicalizedResource;\n//\n// CanonicalizedResource = [ SlashSeparator + Bucket ] +\n//  \t<HTTP-Request-URI, from the protocol name up to the query string> +\n//  \t[ subresource, if present. For example \"?acl\", \"?location\", \"?logging\", or \"?torrent\"];\n//\n// CanonicalizedProtocolHeaders = <described below>\n\n// doesSignV2Match - Verify authorization header with calculated header in accordance with\n//     - http://docs.aws.amazon.com/AmazonS3/latest/dev/auth-request-sig-v2.html\n// returns true if matches, false otherwise. if error is not nil then it is always false\n\nfunc validateV2AuthHeader(r *http.Request) (auth.Credentials, APIErrorCode) {\n\tvar cred auth.Credentials\n\tv2Auth := r.Header.Get(xhttp.Authorization)\n\tif v2Auth == \"\" {\n\t\treturn cred, ErrAuthHeaderEmpty\n\t}\n\n\t// Verify if the header algorithm is supported or not.\n\tif !strings.HasPrefix(v2Auth, signV2Algorithm) {\n\t\treturn cred, ErrSignatureVersionNotSupported\n\t}\n\n\tcred, _, apiErr := getReqAccessKeyV2(r)\n\tif apiErr != ErrNone {\n\t\treturn cred, apiErr\n\t}\n\n\treturn cred, ErrNone\n}\n\nfunc doesSignV2Match(r *http.Request) APIErrorCode {\n\tv2Auth := r.Header.Get(xhttp.Authorization)\n\tcred, apiError := validateV2AuthHeader(r)\n\tif apiError != ErrNone {\n\t\treturn apiError\n\t}\n\n\t// r.RequestURI will have raw encoded URI as sent by the client.\n\ttokens := strings.SplitN(r.RequestURI, \"?\", 2)\n\tencodedResource := tokens[0]\n\tencodedQuery := \"\"\n\tif len(tokens) == 2 {\n\t\tencodedQuery = tokens[1]\n\t}\n\n\tunescapedQueries, err := unescapeQueries(encodedQuery)\n\tif err != nil {\n\t\treturn ErrInvalidQueryParams\n\t}\n\n\tencodedResource, err = getResource(encodedResource, r.Host, globalDomainNames)\n\tif err != nil {\n\t\treturn ErrInvalidRequest\n\t}\n\n\tprefix := fmt.Sprintf(\"%s %s:\", signV2Algorithm, cred.AccessKey)\n\tif !strings.HasPrefix(v2Auth, prefix) {\n\t\treturn ErrSignatureDoesNotMatch\n\t}\n\tv2Auth = v2Auth[len(prefix):]\n\texpectedAuth := signatureV2(cred, r.Method, encodedResource, strings.Join(unescapedQueries, \"&\"), r.Header)\n\tif !compareSignatureV2(v2Auth, expectedAuth) {\n\t\treturn ErrSignatureDoesNotMatch\n\t}\n\treturn ErrNone\n}\n\nfunc calculateSignatureV2(stringToSign string, secret string) string {\n\thm := hmac.New(sha1.New, []byte(secret))\n\thm.Write([]byte(stringToSign))\n\treturn base64.StdEncoding.EncodeToString(hm.Sum(nil))\n}\n\n// Return signature-v2 for the presigned request.\nfunc preSignatureV2(cred auth.Credentials, method string, encodedResource string, encodedQuery string, headers http.Header, expires string) string {\n\tstringToSign := getStringToSignV2(method, encodedResource, encodedQuery, headers, expires)\n\treturn calculateSignatureV2(stringToSign, cred.SecretKey)\n}\n\n// Return the signature v2 of a given request.\nfunc signatureV2(cred auth.Credentials, method string, encodedResource string, encodedQuery string, headers http.Header) string {\n\tstringToSign := getStringToSignV2(method, encodedResource, encodedQuery, headers, \"\")\n\tsignature := calculateSignatureV2(stringToSign, cred.SecretKey)\n\treturn signature\n}\n\n// compareSignatureV2 returns true if and only if both signatures\n// are equal. The signatures are expected to be base64 encoded strings\n// according to the AWS S3 signature V2 spec.\nfunc compareSignatureV2(sig1, sig2 string) bool {\n\t// Decode signature string to binary byte-sequence representation is required\n\t// as Base64 encoding of a value is not unique:\n\t// For example \"aGVsbG8=\" and \"aGVsbG8=\\r\" will result in the same byte slice.\n\tsignature1, err := base64.StdEncoding.DecodeString(sig1)\n\tif err != nil {\n\t\treturn false\n\t}\n\tsignature2, err := base64.StdEncoding.DecodeString(sig2)\n\tif err != nil {\n\t\treturn false\n\t}\n\treturn subtle.ConstantTimeCompare(signature1, signature2) == 1\n}\n\n// Return canonical headers.\nfunc canonicalizedAmzHeadersV2(headers http.Header) string {\n\tvar keys []string\n\tkeyval := make(map[string]string, len(headers))\n\tfor key := range headers {\n\t\tlkey := strings.ToLower(key)\n\t\tif !strings.HasPrefix(lkey, \"x-amz-\") {\n\t\t\tcontinue\n\t\t}\n\t\tkeys = append(keys, lkey)\n\t\tkeyval[lkey] = strings.Join(headers[key], \",\")\n\t}\n\tsort.Strings(keys)\n\tvar canonicalHeaders []string\n\tfor _, key := range keys {\n\t\tcanonicalHeaders = append(canonicalHeaders, key+\":\"+keyval[key])\n\t}\n\treturn strings.Join(canonicalHeaders, \"\\n\")\n}\n\n// Return canonical resource string.\nfunc canonicalizedResourceV2(encodedResource, encodedQuery string) string {\n\tqueries := strings.Split(encodedQuery, \"&\")\n\tkeyval := make(map[string]string)\n\tfor _, query := range queries {\n\t\tkey := query\n\t\tval := \"\"\n\t\tindex := strings.Index(query, \"=\")\n\t\tif index != -1 {\n\t\t\tkey = query[:index]\n\t\t\tval = query[index+1:]\n\t\t}\n\t\tkeyval[key] = val\n\t}\n\n\tvar canonicalQueries []string\n\tfor _, key := range resourceList {\n\t\tval, ok := keyval[key]\n\t\tif !ok {\n\t\t\tcontinue\n\t\t}\n\t\tif val == \"\" {\n\t\t\tcanonicalQueries = append(canonicalQueries, key)\n\t\t\tcontinue\n\t\t}\n\t\tcanonicalQueries = append(canonicalQueries, key+\"=\"+val)\n\t}\n\n\t// The queries will be already sorted as resourceList is sorted, if canonicalQueries\n\t// is empty strings.Join returns empty.\n\tcanonicalQuery := strings.Join(canonicalQueries, \"&\")\n\tif canonicalQuery != \"\" {\n\t\treturn encodedResource + \"?\" + canonicalQuery\n\t}\n\treturn encodedResource\n}\n\n// Return string to sign under two different conditions.\n// - if expires string is set then string to sign includes date instead of the Date header.\n// - if expires string is empty then string to sign includes date header instead.\nfunc getStringToSignV2(method string, encodedResource, encodedQuery string, headers http.Header, expires string) string {\n\tcanonicalHeaders := canonicalizedAmzHeadersV2(headers)\n\tif len(canonicalHeaders) > 0 {\n\t\tcanonicalHeaders += \"\\n\"\n\t}\n\n\tdate := expires // Date is set to expires date for presign operations.\n\tif date == \"\" {\n\t\t// If expires date is empty then request header Date is used.\n\t\tdate = headers.Get(xhttp.Date)\n\t}\n\n\t// From the Amazon docs:\n\t//\n\t// StringToSign = HTTP-Verb + \"\\n\" +\n\t// \t Content-Md5 + \"\\n\" +\n\t//\t Content-Type + \"\\n\" +\n\t//\t Date/Expires + \"\\n\" +\n\t//\t CanonicalizedProtocolHeaders +\n\t//\t CanonicalizedResource;\n\tstringToSign := strings.Join([]string{\n\t\tmethod,\n\t\theaders.Get(xhttp.ContentMD5),\n\t\theaders.Get(xhttp.ContentType),\n\t\tdate,\n\t\tcanonicalHeaders,\n\t}, \"\\n\")\n\n\treturn stringToSign + canonicalizedResourceV2(encodedResource, encodedQuery)\n}\n", "/*\n * MinIO Cloud Storage, (C) 2016, 2017 MinIO, Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\npackage cmd\n\nimport (\n\t\"fmt\"\n\t\"net/http\"\n\t\"net/url\"\n\t\"os\"\n\t\"sort\"\n\t\"testing\"\n)\n\n// Tests for 'func TestResourceListSorting(t *testing.T)'.\nfunc TestResourceListSorting(t *testing.T) {\n\tsortedResourceList := make([]string, len(resourceList))\n\tcopy(sortedResourceList, resourceList)\n\tsort.Strings(sortedResourceList)\n\tfor i := 0; i < len(resourceList); i++ {\n\t\tif resourceList[i] != sortedResourceList[i] {\n\t\t\tt.Errorf(\"Expected resourceList[%d] = \\\"%s\\\", resourceList is not correctly sorted.\", i, sortedResourceList[i])\n\t\t\tbreak\n\t\t}\n\t}\n}\n\n// Tests presigned v2 signature.\nfunc TestDoesPresignedV2SignatureMatch(t *testing.T) {\n\tobj, fsDir, err := prepareFS()\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tdefer os.RemoveAll(fsDir)\n\tif err = newTestConfig(globalMinioDefaultRegion, obj); err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tnow := UTCNow()\n\n\tvar (\n\t\taccessKey = globalActiveCred.AccessKey\n\t\tsecretKey = globalActiveCred.SecretKey\n\t)\n\ttestCases := []struct {\n\t\tqueryParams map[string]string\n\t\texpected    APIErrorCode\n\t}{\n\t\t// (0) Should error without a set URL query.\n\t\t{\n\t\t\texpected: ErrInvalidQueryParams,\n\t\t},\n\t\t// (1) Should error on an invalid access key.\n\t\t{\n\t\t\tqueryParams: map[string]string{\n\t\t\t\t\"Expires\":        \"60\",\n\t\t\t\t\"Signature\":      \"badsignature\",\n\t\t\t\t\"AWSAccessKeyId\": \"Z7IXGOO6BZ0REAN1Q26I\",\n\t\t\t},\n\t\t\texpected: ErrInvalidAccessKeyID,\n\t\t},\n\t\t// (2) Should error with malformed expires.\n\t\t{\n\t\t\tqueryParams: map[string]string{\n\t\t\t\t\"Expires\":        \"60s\",\n\t\t\t\t\"Signature\":      \"badsignature\",\n\t\t\t\t\"AWSAccessKeyId\": accessKey,\n\t\t\t},\n\t\t\texpected: ErrMalformedExpires,\n\t\t},\n\t\t// (3) Should give an expired request if it has expired.\n\t\t{\n\t\t\tqueryParams: map[string]string{\n\t\t\t\t\"Expires\":        \"60\",\n\t\t\t\t\"Signature\":      \"badsignature\",\n\t\t\t\t\"AWSAccessKeyId\": accessKey,\n\t\t\t},\n\t\t\texpected: ErrExpiredPresignRequest,\n\t\t},\n\t\t// (4) Should error when the signature does not match.\n\t\t{\n\t\t\tqueryParams: map[string]string{\n\t\t\t\t\"Expires\":        fmt.Sprintf(\"%d\", now.Unix()+60),\n\t\t\t\t\"Signature\":      \"badsignature\",\n\t\t\t\t\"AWSAccessKeyId\": accessKey,\n\t\t\t},\n\t\t\texpected: ErrSignatureDoesNotMatch,\n\t\t},\n\t\t// (5) Should error when the signature does not match.\n\t\t{\n\t\t\tqueryParams: map[string]string{\n\t\t\t\t\"Expires\":        fmt.Sprintf(\"%d\", now.Unix()+60),\n\t\t\t\t\"Signature\":      \"zOM2YrY/yAQe15VWmT78OlBrK6g=\",\n\t\t\t\t\"AWSAccessKeyId\": accessKey,\n\t\t\t},\n\t\t\texpected: ErrSignatureDoesNotMatch,\n\t\t},\n\t\t// (6) Should not error signature matches with extra query params.\n\t\t{\n\t\t\tqueryParams: map[string]string{\n\t\t\t\t\"response-content-disposition\": \"attachment; filename=\\\"4K%2d4M.txt\\\"\",\n\t\t\t},\n\t\t\texpected: ErrNone,\n\t\t},\n\t\t// (7) Should not error signature matches with no special query params.\n\t\t{\n\t\t\tqueryParams: map[string]string{},\n\t\t\texpected:    ErrNone,\n\t\t},\n\t}\n\n\t// Run each test case individually.\n\tfor i, testCase := range testCases {\n\t\t// Turn the map[string]string into map[string][]string, because Go.\n\t\tquery := url.Values{}\n\t\tfor key, value := range testCase.queryParams {\n\t\t\tquery.Set(key, value)\n\t\t}\n\t\t// Create a request to use.\n\t\treq, err := http.NewRequest(http.MethodGet, \"http://host/a/b?\"+query.Encode(), nil)\n\t\tif err != nil {\n\t\t\tt.Errorf(\"(%d) failed to create http.Request, got %v\", i, err)\n\t\t}\n\t\tif testCase.expected != ErrNone {\n\t\t\t// Should be set since we are simulating a http server.\n\t\t\treq.RequestURI = req.URL.RequestURI()\n\t\t\t// Check if it matches!\n\t\t\terrCode := doesPresignV2SignatureMatch(req)\n\t\t\tif errCode != testCase.expected {\n\t\t\t\tt.Errorf(\"(%d) expected to get %s, instead got %s\", i, niceError(testCase.expected), niceError(errCode))\n\t\t\t}\n\t\t} else {\n\t\t\terr = preSignV2(req, accessKey, secretKey, now.Unix()+60)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatalf(\"(%d) failed to preSignV2 http request, got %v\", i, err)\n\t\t\t}\n\t\t\t// Should be set since we are simulating a http server.\n\t\t\treq.RequestURI = req.URL.RequestURI()\n\t\t\terrCode := doesPresignV2SignatureMatch(req)\n\t\t\tif errCode != testCase.expected {\n\t\t\t\tt.Errorf(\"(%d) expected to get success, instead got %s\", i, niceError(errCode))\n\t\t\t}\n\t\t}\n\n\t}\n}\n\n// TestValidateV2AuthHeader - Tests validate the logic of V2 Authorization header validator.\nfunc TestValidateV2AuthHeader(t *testing.T) {\n\tobj, fsDir, err := prepareFS()\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tdefer os.RemoveAll(fsDir)\n\tif err = newTestConfig(globalMinioDefaultRegion, obj); err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\taccessID := globalActiveCred.AccessKey\n\ttestCases := []struct {\n\t\tauthString    string\n\t\texpectedError APIErrorCode\n\t}{\n\t\t// Test case - 1.\n\t\t// Case with empty V2AuthString.\n\t\t{\n\n\t\t\tauthString:    \"\",\n\t\t\texpectedError: ErrAuthHeaderEmpty,\n\t\t},\n\t\t// Test case - 2.\n\t\t// Test case with `signV2Algorithm` (\"AWS\") not being the prefix.\n\t\t{\n\n\t\t\tauthString:    \"NoV2Prefix\",\n\t\t\texpectedError: ErrSignatureVersionNotSupported,\n\t\t},\n\t\t// Test case - 3.\n\t\t// Test case with missing parts in the Auth string.\n\t\t// below is the correct format of V2 Authorization header.\n\t\t// Authorization = \"AWS\" + \" \" + AWSAccessKeyId + \":\" + Signature\n\t\t{\n\n\t\t\tauthString:    signV2Algorithm,\n\t\t\texpectedError: ErrMissingFields,\n\t\t},\n\t\t// Test case - 4.\n\t\t// Test case with signature part missing.\n\t\t{\n\n\t\t\tauthString:    fmt.Sprintf(\"%s %s\", signV2Algorithm, accessID),\n\t\t\texpectedError: ErrMissingFields,\n\t\t},\n\t\t// Test case - 5.\n\t\t// Test case with wrong accessID.\n\t\t{\n\n\t\t\tauthString:    fmt.Sprintf(\"%s %s:%s\", signV2Algorithm, \"InvalidAccessID\", \"signature\"),\n\t\t\texpectedError: ErrInvalidAccessKeyID,\n\t\t},\n\t\t// Test case - 6.\n\t\t// Case with right accessID and format.\n\t\t{\n\n\t\t\tauthString:    fmt.Sprintf(\"%s %s:%s\", signV2Algorithm, accessID, \"signature\"),\n\t\t\texpectedError: ErrNone,\n\t\t},\n\t}\n\n\tfor i, testCase := range testCases {\n\t\tt.Run(fmt.Sprintf(\"Case %d AuthStr \\\"%s\\\".\", i+1, testCase.authString), func(t *testing.T) {\n\n\t\t\treq := &http.Request{\n\t\t\t\tHeader: make(http.Header),\n\t\t\t\tURL:    &url.URL{},\n\t\t\t}\n\t\t\treq.Header.Set(\"Authorization\", testCase.authString)\n\t\t\t_, actualErrCode := validateV2AuthHeader(req)\n\n\t\t\tif testCase.expectedError != actualErrCode {\n\t\t\t\tt.Errorf(\"Expected the error code to be %v, got %v.\", testCase.expectedError, actualErrCode)\n\t\t\t}\n\t\t})\n\t}\n\n}\n\nfunc TestDoesPolicySignatureV2Match(t *testing.T) {\n\tobj, fsDir, err := prepareFS()\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tdefer os.RemoveAll(fsDir)\n\tif err = newTestConfig(globalMinioDefaultRegion, obj); err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tcreds := globalActiveCred\n\tpolicy := \"policy\"\n\ttestCases := []struct {\n\t\taccessKey string\n\t\tpolicy    string\n\t\tsignature string\n\t\terrCode   APIErrorCode\n\t}{\n\t\t{\"invalidAccessKey\", policy, calculateSignatureV2(policy, creds.SecretKey), ErrInvalidAccessKeyID},\n\t\t{creds.AccessKey, policy, calculateSignatureV2(\"random\", creds.SecretKey), ErrSignatureDoesNotMatch},\n\t\t{creds.AccessKey, policy, calculateSignatureV2(policy, creds.SecretKey), ErrNone},\n\t}\n\tfor i, test := range testCases {\n\t\tformValues := make(http.Header)\n\t\tformValues.Set(\"Awsaccesskeyid\", test.accessKey)\n\t\tformValues.Set(\"Signature\", test.signature)\n\t\tformValues.Set(\"Policy\", test.policy)\n\t\t_, errCode := doesPolicySignatureV2Match(formValues)\n\t\tif errCode != test.errCode {\n\t\t\tt.Fatalf(\"(%d) expected to get %s, instead got %s\", i+1, niceError(test.errCode), niceError(errCode))\n\t\t}\n\t}\n}\n", "/*\n * MinIO Cloud Storage, (C) 2015, 2016, 2017 MinIO, Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n// Package cmd This file implements helper functions to validate AWS\n// Signature Version '4' authorization header.\n//\n// This package provides comprehensive helpers for following signature\n// types.\n// - Based on Authorization header.\n// - Based on Query parameters.\n// - Based on Form POST policy.\npackage cmd\n\nimport (\n\t\"bytes\"\n\t\"crypto/sha256\"\n\t\"crypto/subtle\"\n\t\"encoding/hex\"\n\t\"net/http\"\n\t\"net/url\"\n\t\"sort\"\n\t\"strconv\"\n\t\"strings\"\n\t\"time\"\n\n\t\"github.com/minio/minio-go/v7/pkg/s3utils\"\n\t\"github.com/minio/minio-go/v7/pkg/set\"\n\txhttp \"github.com/minio/minio/cmd/http\"\n\t\"github.com/minio/minio/pkg/auth\"\n)\n\n// AWS Signature Version '4' constants.\nconst (\n\tsignV4Algorithm = \"AWS4-HMAC-SHA256\"\n\tiso8601Format   = \"20060102T150405Z\"\n\tyyyymmdd        = \"20060102\"\n)\n\ntype serviceType string\n\nconst (\n\tserviceS3  serviceType = \"s3\"\n\tserviceSTS serviceType = \"sts\"\n)\n\n// getCanonicalHeaders generate a list of request headers with their values\nfunc getCanonicalHeaders(signedHeaders http.Header) string {\n\tvar headers []string\n\tvals := make(http.Header)\n\tfor k, vv := range signedHeaders {\n\t\theaders = append(headers, strings.ToLower(k))\n\t\tvals[strings.ToLower(k)] = vv\n\t}\n\tsort.Strings(headers)\n\n\tvar buf bytes.Buffer\n\tfor _, k := range headers {\n\t\tbuf.WriteString(k)\n\t\tbuf.WriteByte(':')\n\t\tfor idx, v := range vals[k] {\n\t\t\tif idx > 0 {\n\t\t\t\tbuf.WriteByte(',')\n\t\t\t}\n\t\t\tbuf.WriteString(signV4TrimAll(v))\n\t\t}\n\t\tbuf.WriteByte('\\n')\n\t}\n\treturn buf.String()\n}\n\n// getSignedHeaders generate a string i.e alphabetically sorted, semicolon-separated list of lowercase request header names\nfunc getSignedHeaders(signedHeaders http.Header) string {\n\tvar headers []string\n\tfor k := range signedHeaders {\n\t\theaders = append(headers, strings.ToLower(k))\n\t}\n\tsort.Strings(headers)\n\treturn strings.Join(headers, \";\")\n}\n\n// getCanonicalRequest generate a canonical request of style\n//\n// canonicalRequest =\n//  <HTTPMethod>\\n\n//  <CanonicalURI>\\n\n//  <CanonicalQueryString>\\n\n//  <CanonicalHeaders>\\n\n//  <SignedHeaders>\\n\n//  <HashedPayload>\n//\nfunc getCanonicalRequest(extractedSignedHeaders http.Header, payload, queryStr, urlPath, method string) string {\n\trawQuery := strings.Replace(queryStr, \"+\", \"%20\", -1)\n\tencodedPath := s3utils.EncodePath(urlPath)\n\tcanonicalRequest := strings.Join([]string{\n\t\tmethod,\n\t\tencodedPath,\n\t\trawQuery,\n\t\tgetCanonicalHeaders(extractedSignedHeaders),\n\t\tgetSignedHeaders(extractedSignedHeaders),\n\t\tpayload,\n\t}, \"\\n\")\n\treturn canonicalRequest\n}\n\n// getScope generate a string of a specific date, an AWS region, and a service.\nfunc getScope(t time.Time, region string) string {\n\tscope := strings.Join([]string{\n\t\tt.Format(yyyymmdd),\n\t\tregion,\n\t\tstring(serviceS3),\n\t\t\"aws4_request\",\n\t}, SlashSeparator)\n\treturn scope\n}\n\n// getStringToSign a string based on selected query values.\nfunc getStringToSign(canonicalRequest string, t time.Time, scope string) string {\n\tstringToSign := signV4Algorithm + \"\\n\" + t.Format(iso8601Format) + \"\\n\"\n\tstringToSign = stringToSign + scope + \"\\n\"\n\tcanonicalRequestBytes := sha256.Sum256([]byte(canonicalRequest))\n\tstringToSign = stringToSign + hex.EncodeToString(canonicalRequestBytes[:])\n\treturn stringToSign\n}\n\n// getSigningKey hmac seed to calculate final signature.\nfunc getSigningKey(secretKey string, t time.Time, region string, stype serviceType) []byte {\n\tdate := sumHMAC([]byte(\"AWS4\"+secretKey), []byte(t.Format(yyyymmdd)))\n\tregionBytes := sumHMAC(date, []byte(region))\n\tservice := sumHMAC(regionBytes, []byte(stype))\n\tsigningKey := sumHMAC(service, []byte(\"aws4_request\"))\n\treturn signingKey\n}\n\n// getSignature final signature in hexadecimal form.\nfunc getSignature(signingKey []byte, stringToSign string) string {\n\treturn hex.EncodeToString(sumHMAC(signingKey, []byte(stringToSign)))\n}\n\n// Check to see if Policy is signed correctly.\nfunc doesPolicySignatureMatch(formValues http.Header) (auth.Credentials, APIErrorCode) {\n\t// For SignV2 - Signature field will be valid\n\tif _, ok := formValues[\"Signature\"]; ok {\n\t\treturn doesPolicySignatureV2Match(formValues)\n\t}\n\treturn doesPolicySignatureV4Match(formValues)\n}\n\n// compareSignatureV4 returns true if and only if both signatures\n// are equal. The signatures are expected to be HEX encoded strings\n// according to the AWS S3 signature V4 spec.\nfunc compareSignatureV4(sig1, sig2 string) bool {\n\t// The CTC using []byte(str) works because the hex encoding\n\t// is unique for a sequence of bytes. See also compareSignatureV2.\n\treturn subtle.ConstantTimeCompare([]byte(sig1), []byte(sig2)) == 1\n}\n\n// doesPolicySignatureMatch - Verify query headers with post policy\n//     - http://docs.aws.amazon.com/AmazonS3/latest/API/sigv4-HTTPPOSTConstructPolicy.html\n// returns ErrNone if the signature matches.\nfunc doesPolicySignatureV4Match(formValues http.Header) (auth.Credentials, APIErrorCode) {\n\t// Server region.\n\tregion := globalServerRegion\n\n\t// Parse credential tag.\n\tcredHeader, s3Err := parseCredentialHeader(\"Credential=\"+formValues.Get(xhttp.AmzCredential), region, serviceS3)\n\tif s3Err != ErrNone {\n\t\treturn auth.Credentials{}, s3Err\n\t}\n\n\tcred, _, s3Err := checkKeyValid(credHeader.accessKey)\n\tif s3Err != ErrNone {\n\t\treturn cred, s3Err\n\t}\n\n\t// Get signing key.\n\tsigningKey := getSigningKey(cred.SecretKey, credHeader.scope.date, credHeader.scope.region, serviceS3)\n\n\t// Get signature.\n\tnewSignature := getSignature(signingKey, formValues.Get(\"Policy\"))\n\n\t// Verify signature.\n\tif !compareSignatureV4(newSignature, formValues.Get(xhttp.AmzSignature)) {\n\t\treturn cred, ErrSignatureDoesNotMatch\n\t}\n\n\t// Success.\n\treturn cred, ErrNone\n}\n\n// doesPresignedSignatureMatch - Verify query headers with presigned signature\n//     - http://docs.aws.amazon.com/AmazonS3/latest/API/sigv4-query-string-auth.html\n// returns ErrNone if the signature matches.\nfunc doesPresignedSignatureMatch(hashedPayload string, r *http.Request, region string, stype serviceType) APIErrorCode {\n\t// Copy request\n\treq := *r\n\n\t// Parse request query string.\n\tpSignValues, err := parsePreSignV4(req.URL.Query(), region, stype)\n\tif err != ErrNone {\n\t\treturn err\n\t}\n\n\tcred, _, s3Err := checkKeyValid(pSignValues.Credential.accessKey)\n\tif s3Err != ErrNone {\n\t\treturn s3Err\n\t}\n\n\t// Extract all the signed headers along with its values.\n\textractedSignedHeaders, errCode := extractSignedHeaders(pSignValues.SignedHeaders, r)\n\tif errCode != ErrNone {\n\t\treturn errCode\n\t}\n\n\t// If the host which signed the request is slightly ahead in time (by less than globalMaxSkewTime) the\n\t// request should still be allowed.\n\tif pSignValues.Date.After(UTCNow().Add(globalMaxSkewTime)) {\n\t\treturn ErrRequestNotReadyYet\n\t}\n\n\tif UTCNow().Sub(pSignValues.Date) > pSignValues.Expires {\n\t\treturn ErrExpiredPresignRequest\n\t}\n\n\t// Save the date and expires.\n\tt := pSignValues.Date\n\texpireSeconds := int(pSignValues.Expires / time.Second)\n\n\t// Construct new query.\n\tquery := make(url.Values)\n\tclntHashedPayload := req.URL.Query().Get(xhttp.AmzContentSha256)\n\tif clntHashedPayload != \"\" {\n\t\tquery.Set(xhttp.AmzContentSha256, hashedPayload)\n\t}\n\n\ttoken := req.URL.Query().Get(xhttp.AmzSecurityToken)\n\tif token != \"\" {\n\t\tquery.Set(xhttp.AmzSecurityToken, cred.SessionToken)\n\t}\n\n\tquery.Set(xhttp.AmzAlgorithm, signV4Algorithm)\n\n\t// Construct the query.\n\tquery.Set(xhttp.AmzDate, t.Format(iso8601Format))\n\tquery.Set(xhttp.AmzExpires, strconv.Itoa(expireSeconds))\n\tquery.Set(xhttp.AmzSignedHeaders, getSignedHeaders(extractedSignedHeaders))\n\tquery.Set(xhttp.AmzCredential, cred.AccessKey+SlashSeparator+pSignValues.Credential.getScope())\n\n\tdefaultSigParams := set.CreateStringSet(\n\t\txhttp.AmzContentSha256,\n\t\txhttp.AmzSecurityToken,\n\t\txhttp.AmzAlgorithm,\n\t\txhttp.AmzDate,\n\t\txhttp.AmzExpires,\n\t\txhttp.AmzSignedHeaders,\n\t\txhttp.AmzCredential,\n\t\txhttp.AmzSignature,\n\t)\n\n\t// Add missing query parameters if any provided in the request URL\n\tfor k, v := range req.URL.Query() {\n\t\tif !defaultSigParams.Contains(k) {\n\t\t\tquery[k] = v\n\t\t}\n\t}\n\n\t// Get the encoded query.\n\tencodedQuery := query.Encode()\n\n\t// Verify if date query is same.\n\tif req.URL.Query().Get(xhttp.AmzDate) != query.Get(xhttp.AmzDate) {\n\t\treturn ErrSignatureDoesNotMatch\n\t}\n\t// Verify if expires query is same.\n\tif req.URL.Query().Get(xhttp.AmzExpires) != query.Get(xhttp.AmzExpires) {\n\t\treturn ErrSignatureDoesNotMatch\n\t}\n\t// Verify if signed headers query is same.\n\tif req.URL.Query().Get(xhttp.AmzSignedHeaders) != query.Get(xhttp.AmzSignedHeaders) {\n\t\treturn ErrSignatureDoesNotMatch\n\t}\n\t// Verify if credential query is same.\n\tif req.URL.Query().Get(xhttp.AmzCredential) != query.Get(xhttp.AmzCredential) {\n\t\treturn ErrSignatureDoesNotMatch\n\t}\n\t// Verify if sha256 payload query is same.\n\tif clntHashedPayload != \"\" && clntHashedPayload != query.Get(xhttp.AmzContentSha256) {\n\t\treturn ErrContentSHA256Mismatch\n\t}\n\t// Verify if security token is correct.\n\tif token != \"\" && subtle.ConstantTimeCompare([]byte(token), []byte(cred.SessionToken)) != 1 {\n\t\treturn ErrInvalidToken\n\t}\n\n\t/// Verify finally if signature is same.\n\n\t// Get canonical request.\n\tpresignedCanonicalReq := getCanonicalRequest(extractedSignedHeaders, hashedPayload, encodedQuery, req.URL.Path, req.Method)\n\n\t// Get string to sign from canonical request.\n\tpresignedStringToSign := getStringToSign(presignedCanonicalReq, t, pSignValues.Credential.getScope())\n\n\t// Get hmac presigned signing key.\n\tpresignedSigningKey := getSigningKey(cred.SecretKey, pSignValues.Credential.scope.date,\n\t\tpSignValues.Credential.scope.region, stype)\n\n\t// Get new signature.\n\tnewSignature := getSignature(presignedSigningKey, presignedStringToSign)\n\n\t// Verify signature.\n\tif !compareSignatureV4(req.URL.Query().Get(xhttp.AmzSignature), newSignature) {\n\t\treturn ErrSignatureDoesNotMatch\n\t}\n\treturn ErrNone\n}\n\n// doesSignatureMatch - Verify authorization header with calculated header in accordance with\n//     - http://docs.aws.amazon.com/AmazonS3/latest/API/sig-v4-authenticating-requests.html\n// returns ErrNone if signature matches.\nfunc doesSignatureMatch(hashedPayload string, r *http.Request, region string, stype serviceType) APIErrorCode {\n\t// Copy request.\n\treq := *r\n\n\t// Save authorization header.\n\tv4Auth := req.Header.Get(xhttp.Authorization)\n\n\t// Parse signature version '4' header.\n\tsignV4Values, err := parseSignV4(v4Auth, region, stype)\n\tif err != ErrNone {\n\t\treturn err\n\t}\n\n\t// Extract all the signed headers along with its values.\n\textractedSignedHeaders, errCode := extractSignedHeaders(signV4Values.SignedHeaders, r)\n\tif errCode != ErrNone {\n\t\treturn errCode\n\t}\n\n\tcred, _, s3Err := checkKeyValid(signV4Values.Credential.accessKey)\n\tif s3Err != ErrNone {\n\t\treturn s3Err\n\t}\n\n\t// Extract date, if not present throw error.\n\tvar date string\n\tif date = req.Header.Get(xhttp.AmzDate); date == \"\" {\n\t\tif date = r.Header.Get(xhttp.Date); date == \"\" {\n\t\t\treturn ErrMissingDateHeader\n\t\t}\n\t}\n\n\t// Parse date header.\n\tt, e := time.Parse(iso8601Format, date)\n\tif e != nil {\n\t\treturn ErrMalformedDate\n\t}\n\n\t// Query string.\n\tqueryStr := req.URL.Query().Encode()\n\n\t// Get canonical request.\n\tcanonicalRequest := getCanonicalRequest(extractedSignedHeaders, hashedPayload, queryStr, req.URL.Path, req.Method)\n\n\t// Get string to sign from canonical request.\n\tstringToSign := getStringToSign(canonicalRequest, t, signV4Values.Credential.getScope())\n\n\t// Get hmac signing key.\n\tsigningKey := getSigningKey(cred.SecretKey, signV4Values.Credential.scope.date,\n\t\tsignV4Values.Credential.scope.region, stype)\n\n\t// Calculate signature.\n\tnewSignature := getSignature(signingKey, stringToSign)\n\n\t// Verify if signature match.\n\tif !compareSignatureV4(newSignature, signV4Values.Signature) {\n\t\treturn ErrSignatureDoesNotMatch\n\t}\n\n\t// Return error none.\n\treturn ErrNone\n}\n", "/*\n * MinIO Cloud Storage, (C) 2016, 2017 MinIO, Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\npackage cmd\n\nimport (\n\t\"fmt\"\n\t\"net/http\"\n\t\"net/url\"\n\t\"os\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc niceError(code APIErrorCode) string {\n\t// Special-handle ErrNone\n\tif code == ErrNone {\n\t\treturn \"ErrNone\"\n\t}\n\n\treturn fmt.Sprintf(\"%s (%s)\", errorCodes[code].Code, errorCodes[code].Description)\n}\n\nfunc TestDoesPolicySignatureMatch(t *testing.T) {\n\tcredentialTemplate := \"%s/%s/%s/s3/aws4_request\"\n\tnow := UTCNow()\n\taccessKey := globalActiveCred.AccessKey\n\n\ttestCases := []struct {\n\t\tform     http.Header\n\t\texpected APIErrorCode\n\t}{\n\t\t// (0) It should fail if 'X-Amz-Credential' is missing.\n\t\t{\n\t\t\tform:     http.Header{},\n\t\t\texpected: ErrCredMalformed,\n\t\t},\n\t\t// (1) It should fail if the access key is incorrect.\n\t\t{\n\t\t\tform: http.Header{\n\t\t\t\t\"X-Amz-Credential\": []string{fmt.Sprintf(credentialTemplate, \"EXAMPLEINVALIDEXAMPL\", now.Format(yyyymmdd), globalMinioDefaultRegion)},\n\t\t\t},\n\t\t\texpected: ErrInvalidAccessKeyID,\n\t\t},\n\t\t// (2) It should fail with a bad signature.\n\t\t{\n\t\t\tform: http.Header{\n\t\t\t\t\"X-Amz-Credential\": []string{fmt.Sprintf(credentialTemplate, accessKey, now.Format(yyyymmdd), globalMinioDefaultRegion)},\n\t\t\t\t\"X-Amz-Date\":       []string{now.Format(iso8601Format)},\n\t\t\t\t\"X-Amz-Signature\":  []string{\"invalidsignature\"},\n\t\t\t\t\"Policy\":           []string{\"policy\"},\n\t\t\t},\n\t\t\texpected: ErrSignatureDoesNotMatch,\n\t\t},\n\t\t// (3) It should succeed if everything is correct.\n\t\t{\n\t\t\tform: http.Header{\n\t\t\t\t\"X-Amz-Credential\": []string{\n\t\t\t\t\tfmt.Sprintf(credentialTemplate, accessKey, now.Format(yyyymmdd), globalMinioDefaultRegion),\n\t\t\t\t},\n\t\t\t\t\"X-Amz-Date\": []string{now.Format(iso8601Format)},\n\t\t\t\t\"X-Amz-Signature\": []string{\n\t\t\t\t\tgetSignature(getSigningKey(globalActiveCred.SecretKey, now,\n\t\t\t\t\t\tglobalMinioDefaultRegion, serviceS3), \"policy\"),\n\t\t\t\t},\n\t\t\t\t\"Policy\": []string{\"policy\"},\n\t\t\t},\n\t\t\texpected: ErrNone,\n\t\t},\n\t}\n\n\t// Run each test case individually.\n\tfor i, testCase := range testCases {\n\t\t_, code := doesPolicySignatureMatch(testCase.form)\n\t\tif code != testCase.expected {\n\t\t\tt.Errorf(\"(%d) expected to get %s, instead got %s\", i, niceError(testCase.expected), niceError(code))\n\t\t}\n\t}\n}\n\nfunc TestDoesPresignedSignatureMatch(t *testing.T) {\n\tobj, fsDir, err := prepareFS()\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tdefer os.RemoveAll(fsDir)\n\tif err = newTestConfig(globalMinioDefaultRegion, obj); err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\t// sha256 hash of \"payload\"\n\tpayloadSHA256 := \"239f59ed55e737c77147cf55ad0c1b030b6d7ee748a7426952f9b852d5a935e5\"\n\tnow := UTCNow()\n\tcredentialTemplate := \"%s/%s/%s/s3/aws4_request\"\n\n\tregion := globalServerRegion\n\taccessKeyID := globalActiveCred.AccessKey\n\ttestCases := []struct {\n\t\tqueryParams map[string]string\n\t\theaders     map[string]string\n\t\tregion      string\n\t\texpected    APIErrorCode\n\t}{\n\t\t// (0) Should error without a set URL query.\n\t\t{\n\t\t\tregion:   globalMinioDefaultRegion,\n\t\t\texpected: ErrInvalidQueryParams,\n\t\t},\n\t\t// (1) Should error on an invalid access key.\n\t\t{\n\t\t\tqueryParams: map[string]string{\n\t\t\t\t\"X-Amz-Algorithm\":     signV4Algorithm,\n\t\t\t\t\"X-Amz-Date\":          now.Format(iso8601Format),\n\t\t\t\t\"X-Amz-Expires\":       \"60\",\n\t\t\t\t\"X-Amz-Signature\":     \"badsignature\",\n\t\t\t\t\"X-Amz-SignedHeaders\": \"host;x-amz-content-sha256;x-amz-date\",\n\t\t\t\t\"X-Amz-Credential\":    fmt.Sprintf(credentialTemplate, \"Z7IXGOO6BZ0REAN1Q26I\", now.Format(yyyymmdd), \"us-west-1\"),\n\t\t\t},\n\t\t\tregion:   \"us-west-1\",\n\t\t\texpected: ErrInvalidAccessKeyID,\n\t\t},\n\t\t// (2) Should NOT fail with an invalid region if it doesn't verify it.\n\t\t{\n\t\t\tqueryParams: map[string]string{\n\t\t\t\t\"X-Amz-Algorithm\":      signV4Algorithm,\n\t\t\t\t\"X-Amz-Date\":           now.Format(iso8601Format),\n\t\t\t\t\"X-Amz-Expires\":        \"60\",\n\t\t\t\t\"X-Amz-Signature\":      \"badsignature\",\n\t\t\t\t\"X-Amz-SignedHeaders\":  \"host;x-amz-content-sha256;x-amz-date\",\n\t\t\t\t\"X-Amz-Credential\":     fmt.Sprintf(credentialTemplate, accessKeyID, now.Format(yyyymmdd), \"us-west-1\"),\n\t\t\t\t\"X-Amz-Content-Sha256\": payloadSHA256,\n\t\t\t},\n\t\t\tregion:   \"us-west-1\",\n\t\t\texpected: ErrUnsignedHeaders,\n\t\t},\n\t\t// (3) Should fail to extract headers if the host header is not signed.\n\t\t{\n\t\t\tqueryParams: map[string]string{\n\t\t\t\t\"X-Amz-Algorithm\":      signV4Algorithm,\n\t\t\t\t\"X-Amz-Date\":           now.Format(iso8601Format),\n\t\t\t\t\"X-Amz-Expires\":        \"60\",\n\t\t\t\t\"X-Amz-Signature\":      \"badsignature\",\n\t\t\t\t\"X-Amz-SignedHeaders\":  \"x-amz-content-sha256;x-amz-date\",\n\t\t\t\t\"X-Amz-Credential\":     fmt.Sprintf(credentialTemplate, accessKeyID, now.Format(yyyymmdd), region),\n\t\t\t\t\"X-Amz-Content-Sha256\": payloadSHA256,\n\t\t\t},\n\t\t\tregion:   region,\n\t\t\texpected: ErrUnsignedHeaders,\n\t\t},\n\t\t// (4) Should give an expired request if it has expired.\n\t\t{\n\t\t\tqueryParams: map[string]string{\n\t\t\t\t\"X-Amz-Algorithm\":      signV4Algorithm,\n\t\t\t\t\"X-Amz-Date\":           now.AddDate(0, 0, -2).Format(iso8601Format),\n\t\t\t\t\"X-Amz-Expires\":        \"60\",\n\t\t\t\t\"X-Amz-Signature\":      \"badsignature\",\n\t\t\t\t\"X-Amz-SignedHeaders\":  \"host;x-amz-content-sha256;x-amz-date\",\n\t\t\t\t\"X-Amz-Credential\":     fmt.Sprintf(credentialTemplate, accessKeyID, now.Format(yyyymmdd), region),\n\t\t\t\t\"X-Amz-Content-Sha256\": payloadSHA256,\n\t\t\t},\n\t\t\theaders: map[string]string{\n\t\t\t\t\"X-Amz-Date\":           now.AddDate(0, 0, -2).Format(iso8601Format),\n\t\t\t\t\"X-Amz-Content-Sha256\": payloadSHA256,\n\t\t\t},\n\t\t\tregion:   region,\n\t\t\texpected: ErrExpiredPresignRequest,\n\t\t},\n\t\t// (5) Should error if the signature is incorrect.\n\t\t{\n\t\t\tqueryParams: map[string]string{\n\t\t\t\t\"X-Amz-Algorithm\":      signV4Algorithm,\n\t\t\t\t\"X-Amz-Date\":           now.Format(iso8601Format),\n\t\t\t\t\"X-Amz-Expires\":        \"60\",\n\t\t\t\t\"X-Amz-Signature\":      \"badsignature\",\n\t\t\t\t\"X-Amz-SignedHeaders\":  \"host;x-amz-content-sha256;x-amz-date\",\n\t\t\t\t\"X-Amz-Credential\":     fmt.Sprintf(credentialTemplate, accessKeyID, now.Format(yyyymmdd), region),\n\t\t\t\t\"X-Amz-Content-Sha256\": payloadSHA256,\n\t\t\t},\n\t\t\theaders: map[string]string{\n\t\t\t\t\"X-Amz-Date\":           now.Format(iso8601Format),\n\t\t\t\t\"X-Amz-Content-Sha256\": payloadSHA256,\n\t\t\t},\n\t\t\tregion:   region,\n\t\t\texpected: ErrSignatureDoesNotMatch,\n\t\t},\n\t\t// (6) Should error if the request is not ready yet, ie X-Amz-Date is in the future.\n\t\t{\n\t\t\tqueryParams: map[string]string{\n\t\t\t\t\"X-Amz-Algorithm\":      signV4Algorithm,\n\t\t\t\t\"X-Amz-Date\":           now.Add(1 * time.Hour).Format(iso8601Format),\n\t\t\t\t\"X-Amz-Expires\":        \"60\",\n\t\t\t\t\"X-Amz-Signature\":      \"badsignature\",\n\t\t\t\t\"X-Amz-SignedHeaders\":  \"host;x-amz-content-sha256;x-amz-date\",\n\t\t\t\t\"X-Amz-Credential\":     fmt.Sprintf(credentialTemplate, accessKeyID, now.Format(yyyymmdd), region),\n\t\t\t\t\"X-Amz-Content-Sha256\": payloadSHA256,\n\t\t\t},\n\t\t\theaders: map[string]string{\n\t\t\t\t\"X-Amz-Date\":           now.Format(iso8601Format),\n\t\t\t\t\"X-Amz-Content-Sha256\": payloadSHA256,\n\t\t\t},\n\t\t\tregion:   region,\n\t\t\texpected: ErrRequestNotReadyYet,\n\t\t},\n\t\t// (7) Should not error with invalid region instead, call should proceed\n\t\t// with sigature does not match.\n\t\t{\n\t\t\tqueryParams: map[string]string{\n\t\t\t\t\"X-Amz-Algorithm\":      signV4Algorithm,\n\t\t\t\t\"X-Amz-Date\":           now.Format(iso8601Format),\n\t\t\t\t\"X-Amz-Expires\":        \"60\",\n\t\t\t\t\"X-Amz-Signature\":      \"badsignature\",\n\t\t\t\t\"X-Amz-SignedHeaders\":  \"host;x-amz-content-sha256;x-amz-date\",\n\t\t\t\t\"X-Amz-Credential\":     fmt.Sprintf(credentialTemplate, accessKeyID, now.Format(yyyymmdd), region),\n\t\t\t\t\"X-Amz-Content-Sha256\": payloadSHA256,\n\t\t\t},\n\t\t\theaders: map[string]string{\n\t\t\t\t\"X-Amz-Date\":           now.Format(iso8601Format),\n\t\t\t\t\"X-Amz-Content-Sha256\": payloadSHA256,\n\t\t\t},\n\t\t\tregion:   \"\",\n\t\t\texpected: ErrSignatureDoesNotMatch,\n\t\t},\n\t\t// (8) Should error with signature does not match. But handles\n\t\t// query params which do not precede with \"x-amz-\" header.\n\t\t{\n\t\t\tqueryParams: map[string]string{\n\t\t\t\t\"X-Amz-Algorithm\":       signV4Algorithm,\n\t\t\t\t\"X-Amz-Date\":            now.Format(iso8601Format),\n\t\t\t\t\"X-Amz-Expires\":         \"60\",\n\t\t\t\t\"X-Amz-Signature\":       \"badsignature\",\n\t\t\t\t\"X-Amz-SignedHeaders\":   \"host;x-amz-content-sha256;x-amz-date\",\n\t\t\t\t\"X-Amz-Credential\":      fmt.Sprintf(credentialTemplate, accessKeyID, now.Format(yyyymmdd), region),\n\t\t\t\t\"X-Amz-Content-Sha256\":  payloadSHA256,\n\t\t\t\t\"response-content-type\": \"application/json\",\n\t\t\t},\n\t\t\theaders: map[string]string{\n\t\t\t\t\"X-Amz-Date\":           now.Format(iso8601Format),\n\t\t\t\t\"X-Amz-Content-Sha256\": payloadSHA256,\n\t\t\t},\n\t\t\tregion:   \"\",\n\t\t\texpected: ErrSignatureDoesNotMatch,\n\t\t},\n\t\t// (9) Should error with unsigned headers.\n\t\t{\n\t\t\tqueryParams: map[string]string{\n\t\t\t\t\"X-Amz-Algorithm\":       signV4Algorithm,\n\t\t\t\t\"X-Amz-Date\":            now.Format(iso8601Format),\n\t\t\t\t\"X-Amz-Expires\":         \"60\",\n\t\t\t\t\"X-Amz-Signature\":       \"badsignature\",\n\t\t\t\t\"X-Amz-SignedHeaders\":   \"host;x-amz-content-sha256;x-amz-date\",\n\t\t\t\t\"X-Amz-Credential\":      fmt.Sprintf(credentialTemplate, accessKeyID, now.Format(yyyymmdd), region),\n\t\t\t\t\"X-Amz-Content-Sha256\":  payloadSHA256,\n\t\t\t\t\"response-content-type\": \"application/json\",\n\t\t\t},\n\t\t\theaders: map[string]string{\n\t\t\t\t\"X-Amz-Date\": now.Format(iso8601Format),\n\t\t\t},\n\t\t\tregion:   \"\",\n\t\t\texpected: ErrUnsignedHeaders,\n\t\t},\n\t}\n\n\t// Run each test case individually.\n\tfor i, testCase := range testCases {\n\t\t// Turn the map[string]string into map[string][]string, because Go.\n\t\tquery := url.Values{}\n\t\tfor key, value := range testCase.queryParams {\n\t\t\tquery.Set(key, value)\n\t\t}\n\n\t\t// Create a request to use.\n\t\treq, e := http.NewRequest(http.MethodGet, \"http://host/a/b?\"+query.Encode(), nil)\n\t\tif e != nil {\n\t\t\tt.Errorf(\"(%d) failed to create http.Request, got %v\", i, e)\n\t\t}\n\n\t\t// Do the same for the headers.\n\t\tfor key, value := range testCase.headers {\n\t\t\treq.Header.Set(key, value)\n\t\t}\n\n\t\t// Check if it matches!\n\t\terr := doesPresignedSignatureMatch(payloadSHA256, req, testCase.region, serviceS3)\n\t\tif err != testCase.expected {\n\t\t\tt.Errorf(\"(%d) expected to get %s, instead got %s\", i, niceError(testCase.expected), niceError(err))\n\t\t}\n\t}\n}\n"], "filenames": ["cmd/auth-handler.go", "cmd/bucket-handlers.go", "cmd/signature-v2.go", "cmd/signature-v2_test.go", "cmd/signature-v4.go", "cmd/signature-v4_test.go"], "buggy_code_start_loc": [188, 19, 78, 268, 41, 87], "buggy_code_end_loc": [262, 872, 92, 269, 200, 88], "fixing_code_start_loc": [188, 20, 78, 268, 42, 87], "fixing_code_end_loc": [262, 913, 90, 269, 201, 88], "type": "CWE-863", "message": "MinIO is an open-source high performance object storage service and it is API compatible with Amazon S3 cloud storage service. In MinIO before version RELEASE.2021-03-04T00-53-13Z it is possible to bypass a readOnly policy by creating a temporary 'mc share upload' URL. Everyone is impacted who uses MinIO multi-users. This is fixed in version RELEASE.2021-03-04T00-53-13Z. As a workaround, one can disable uploads with `Content-Type: multipart/form-data` as mentioned in the S3 API RESTObjectPOST docs by using a proxy in front of MinIO.", "other": {"cve": {"id": "CVE-2021-21362", "sourceIdentifier": "security-advisories@github.com", "published": "2021-03-08T19:15:13.443", "lastModified": "2022-10-21T22:40:12.743", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "MinIO is an open-source high performance object storage service and it is API compatible with Amazon S3 cloud storage service. In MinIO before version RELEASE.2021-03-04T00-53-13Z it is possible to bypass a readOnly policy by creating a temporary 'mc share upload' URL. Everyone is impacted who uses MinIO multi-users. This is fixed in version RELEASE.2021-03-04T00-53-13Z. As a workaround, one can disable uploads with `Content-Type: multipart/form-data` as mentioned in the S3 API RESTObjectPOST docs by using a proxy in front of MinIO."}, {"lang": "es", "value": "MinIO es un servicio de almacenamiento de objetos de alto rendimiento de c\u00f3digo abierto y es compatible con la API con el servicio de almacenamiento en nube Amazon S3.&#xa0;En MinIO versiones anteriores a RELEASE.2021-03-04T00-53-13Z, es posible omitir una pol\u00edtica de solo lectura al crear una URL temporal \"mc share upload\".&#xa0;Todos los que usan MinIO multiusuario est\u00e1n afectados.&#xa0;Esto es corregido en versi\u00f3n RELEASE.2021-03-04T00-53-13Z.&#xa0;Como una soluci\u00f3n alternativa, puede ser deshabilitar las cargas con \"Content-Type: multipart/form-data\" como es mencionado en los documentos RESTObjectPOST de la API S3 al usar un proxy frente a MinIO"}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:N/I:H/A:N", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "HIGH", "availabilityImpact": "NONE", "baseScore": 6.5, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 2.8, "impactScore": 3.6}, {"source": "security-advisories@github.com", "type": "Secondary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:C/C:N/I:H/A:N", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "CHANGED", "confidentialityImpact": "NONE", "integrityImpact": "HIGH", "availabilityImpact": "NONE", "baseScore": 7.7, "baseSeverity": "HIGH"}, "exploitabilityScore": 3.1, "impactScore": 4.0}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:N/AC:L/Au:S/C:N/I:P/A:N", "accessVector": "NETWORK", "accessComplexity": "LOW", "authentication": "SINGLE", "confidentialityImpact": "NONE", "integrityImpact": "PARTIAL", "availabilityImpact": "NONE", "baseScore": 4.0}, "baseSeverity": "MEDIUM", "exploitabilityScore": 8.0, "impactScore": 2.9, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-863"}]}, {"source": "security-advisories@github.com", "type": "Secondary", "description": [{"lang": "en", "value": "CWE-285"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:minio:minio:*:*:*:*:*:*:*:*", "versionEndExcluding": "2021-03-04t00-53-13z", "matchCriteriaId": "D17AB9B3-22BB-48A4-8317-3EB80B812FFA"}]}]}], "references": [{"url": "https://github.com/minio/minio/commit/039f59b552319fcc2f83631bb421a7d4b82bc482", "source": "security-advisories@github.com", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/minio/minio/pull/11682", "source": "security-advisories@github.com", "tags": ["Exploit", "Third Party Advisory"]}, {"url": "https://github.com/minio/minio/releases/tag/RELEASE.2021-03-04T00-53-13Z", "source": "security-advisories@github.com", "tags": ["Release Notes", "Third Party Advisory"]}, {"url": "https://github.com/minio/minio/security/advisories/GHSA-hq5j-6r98-9m8v", "source": "security-advisories@github.com", "tags": ["Third Party Advisory"]}]}, "github_commit_url": "https://github.com/minio/minio/commit/039f59b552319fcc2f83631bb421a7d4b82bc482"}}
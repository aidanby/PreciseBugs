{"buggy_code": ["import os; os.environ['no_proxy'] = '*' # \u907f\u514d\u4ee3\u7406\u7f51\u7edc\u4ea7\u751f\u610f\u5916\u6c61\u67d3\r\n\r\ndef main():\r\n    import gradio as gr\r\n    if gr.__version__ not in ['3.28.3','3.32.2']: assert False, \"\u8bf7\u7528 pip install -r requirements.txt \u5b89\u88c5\u4f9d\u8d56\"\r\n    from request_llm.bridge_all import predict\r\n    from toolbox import format_io, find_free_port, on_file_uploaded, on_report_generated, get_conf, ArgsGeneralWrapper, DummyWith\r\n    # \u5efa\u8bae\u60a8\u590d\u5236\u4e00\u4e2aconfig_private.py\u653e\u81ea\u5df1\u7684\u79d8\u5bc6, \u5982API\u548c\u4ee3\u7406\u7f51\u5740, \u907f\u514d\u4e0d\u5c0f\u5fc3\u4f20github\u88ab\u522b\u4eba\u770b\u5230\r\n    proxies, WEB_PORT, LLM_MODEL, CONCURRENT_COUNT, AUTHENTICATION, CHATBOT_HEIGHT, LAYOUT, API_KEY, AVAIL_LLM_MODELS = \\\r\n        get_conf('proxies', 'WEB_PORT', 'LLM_MODEL', 'CONCURRENT_COUNT', 'AUTHENTICATION', 'CHATBOT_HEIGHT', 'LAYOUT', 'API_KEY', 'AVAIL_LLM_MODELS')\r\n\r\n    # \u5982\u679cWEB_PORT\u662f-1, \u5219\u968f\u673a\u9009\u53d6WEB\u7aef\u53e3\r\n    PORT = find_free_port() if WEB_PORT <= 0 else WEB_PORT\r\n    if not AUTHENTICATION: AUTHENTICATION = None\r\n\r\n    from check_proxy import get_current_version\r\n    initial_prompt = \"Serve me as a writing and programming assistant.\"\r\n    title_html = f\"<h1 align=\\\"center\\\">ChatGPT \u5b66\u672f\u4f18\u5316 {get_current_version()}</h1>\"\r\n    description =  \"\"\"\u4ee3\u7801\u5f00\u6e90\u548c\u66f4\u65b0[\u5730\u5740\ud83d\ude80](https://github.com/binary-husky/chatgpt_academic)\uff0c\u611f\u8c22\u70ed\u60c5\u7684[\u5f00\u53d1\u8005\u4eec\u2764\ufe0f](https://github.com/binary-husky/chatgpt_academic/graphs/contributors)\"\"\"\r\n\r\n    # \u95ee\u8be2\u8bb0\u5f55, python \u7248\u672c\u5efa\u8bae3.9+\uff08\u8d8a\u65b0\u8d8a\u597d\uff09\r\n    import logging\r\n    os.makedirs(\"gpt_log\", exist_ok=True)\r\n    try:logging.basicConfig(filename=\"gpt_log/chat_secrets.log\", level=logging.INFO, encoding=\"utf-8\")\r\n    except:logging.basicConfig(filename=\"gpt_log/chat_secrets.log\", level=logging.INFO)\r\n    print(\"\u6240\u6709\u95ee\u8be2\u8bb0\u5f55\u5c06\u81ea\u52a8\u4fdd\u5b58\u5728\u672c\u5730\u76ee\u5f55./gpt_log/chat_secrets.log, \u8bf7\u6ce8\u610f\u81ea\u6211\u9690\u79c1\u4fdd\u62a4\u54e6\uff01\")\r\n\r\n    # \u4e00\u4e9b\u666e\u901a\u529f\u80fd\u6a21\u5757\r\n    from core_functional import get_core_functions\r\n    functional = get_core_functions()\r\n\r\n    # \u9ad8\u7ea7\u51fd\u6570\u63d2\u4ef6\r\n    from crazy_functional import get_crazy_functions\r\n    crazy_fns = get_crazy_functions()\r\n\r\n    # \u5904\u7406markdown\u6587\u672c\u683c\u5f0f\u7684\u8f6c\u53d8\r\n    gr.Chatbot.postprocess = format_io\r\n\r\n    # \u505a\u4e00\u4e9b\u5916\u89c2\u8272\u5f69\u4e0a\u7684\u8c03\u6574\r\n    from theme import adjust_theme, advanced_css\r\n    set_theme = adjust_theme()\r\n\r\n    # \u4ee3\u7406\u4e0e\u81ea\u52a8\u66f4\u65b0\r\n    from check_proxy import check_proxy, auto_update, warm_up_modules\r\n    proxy_info = check_proxy(proxies)\r\n\r\n    gr_L1 = lambda: gr.Row().style()\r\n    gr_L2 = lambda scale: gr.Column(scale=scale)\r\n    if LAYOUT == \"TOP-DOWN\":\r\n        gr_L1 = lambda: DummyWith()\r\n        gr_L2 = lambda scale: gr.Row()\r\n        CHATBOT_HEIGHT /= 2\r\n\r\n    cancel_handles = []\r\n    with gr.Blocks(title=\"ChatGPT \u5b66\u672f\u4f18\u5316\", theme=set_theme, analytics_enabled=False, css=advanced_css) as demo:\r\n        gr.HTML(title_html)\r\n        cookies = gr.State({'api_key': API_KEY, 'llm_model': LLM_MODEL})\r\n        with gr_L1():\r\n            with gr_L2(scale=2):\r\n                chatbot = gr.Chatbot(label=f\"\u5f53\u524d\u6a21\u578b\uff1a{LLM_MODEL}\")\r\n                chatbot.style(height=CHATBOT_HEIGHT)\r\n                history = gr.State([])\r\n            with gr_L2(scale=1):\r\n                with gr.Accordion(\"\u8f93\u5165\u533a\", open=True) as area_input_primary:\r\n                    with gr.Row():\r\n                        txt = gr.Textbox(show_label=False, placeholder=\"Input question here.\").style(container=False)\r\n                    with gr.Row():\r\n                        submitBtn = gr.Button(\"\u63d0\u4ea4\", variant=\"primary\")\r\n                    with gr.Row():\r\n                        resetBtn = gr.Button(\"\u91cd\u7f6e\", variant=\"secondary\"); resetBtn.style(size=\"sm\")\r\n                        stopBtn = gr.Button(\"\u505c\u6b62\", variant=\"secondary\"); stopBtn.style(size=\"sm\")\r\n                        clearBtn = gr.Button(\"\u6e05\u9664\", variant=\"secondary\", visible=False); clearBtn.style(size=\"sm\")\r\n                    with gr.Row():\r\n                        status = gr.Markdown(f\"Tip: \u6309Enter\u63d0\u4ea4, \u6309Shift+Enter\u6362\u884c\u3002\u5f53\u524d\u6a21\u578b: {LLM_MODEL} \\n {proxy_info}\")\r\n                with gr.Accordion(\"\u57fa\u7840\u529f\u80fd\u533a\", open=True) as area_basic_fn:\r\n                    with gr.Row():\r\n                        for k in functional:\r\n                            if (\"Visible\" in functional[k]) and (not functional[k][\"Visible\"]): continue\r\n                            variant = functional[k][\"Color\"] if \"Color\" in functional[k] else \"secondary\"\r\n                            functional[k][\"Button\"] = gr.Button(k, variant=variant)\r\n                with gr.Accordion(\"\u51fd\u6570\u63d2\u4ef6\u533a\", open=True) as area_crazy_fn:\r\n                    with gr.Row():\r\n                        gr.Markdown(\"\u6ce8\u610f\uff1a\u4ee5\u4e0b\u201c\u7ea2\u989c\u8272\u201d\u6807\u8bc6\u7684\u51fd\u6570\u63d2\u4ef6\u9700\u4ece\u8f93\u5165\u533a\u8bfb\u53d6\u8def\u5f84\u4f5c\u4e3a\u53c2\u6570.\")\r\n                    with gr.Row():\r\n                        for k in crazy_fns:\r\n                            if not crazy_fns[k].get(\"AsButton\", True): continue\r\n                            variant = crazy_fns[k][\"Color\"] if \"Color\" in crazy_fns[k] else \"secondary\"\r\n                            crazy_fns[k][\"Button\"] = gr.Button(k, variant=variant)\r\n                            crazy_fns[k][\"Button\"].style(size=\"sm\")\r\n                    with gr.Row():\r\n                        with gr.Accordion(\"\u66f4\u591a\u51fd\u6570\u63d2\u4ef6\", open=True):\r\n                            dropdown_fn_list = [k for k in crazy_fns.keys() if not crazy_fns[k].get(\"AsButton\", True)]\r\n                            with gr.Row():\r\n                                dropdown = gr.Dropdown(dropdown_fn_list, value=r\"\u6253\u5f00\u63d2\u4ef6\u5217\u8868\", label=\"\").style(container=False)\r\n                            with gr.Row():\r\n                                plugin_advanced_arg = gr.Textbox(show_label=True, label=\"\u9ad8\u7ea7\u53c2\u6570\u8f93\u5165\u533a\", visible=False, \r\n                                                                 placeholder=\"\u8fd9\u91cc\u662f\u7279\u6b8a\u51fd\u6570\u63d2\u4ef6\u7684\u9ad8\u7ea7\u53c2\u6570\u8f93\u5165\u533a\").style(container=False)\r\n                            with gr.Row():\r\n                                switchy_bt = gr.Button(r\"\u8bf7\u5148\u4ece\u63d2\u4ef6\u5217\u8868\u4e2d\u9009\u62e9\", variant=\"secondary\")\r\n                    with gr.Row():\r\n                        with gr.Accordion(\"\u70b9\u51fb\u5c55\u5f00\u201c\u6587\u4ef6\u4e0a\u4f20\u533a\u201d\u3002\u4e0a\u4f20\u672c\u5730\u6587\u4ef6\u53ef\u4f9b\u7ea2\u8272\u51fd\u6570\u63d2\u4ef6\u8c03\u7528\u3002\", open=False) as area_file_up:\r\n                            file_upload = gr.Files(label=\"\u4efb\u4f55\u6587\u4ef6, \u4f46\u63a8\u8350\u4e0a\u4f20\u538b\u7f29\u6587\u4ef6(zip, tar)\", file_count=\"multiple\")\r\n                with gr.Accordion(\"\u66f4\u6362\u6a21\u578b & SysPrompt & \u4ea4\u4e92\u754c\u9762\u5e03\u5c40\", open=(LAYOUT == \"TOP-DOWN\")):\r\n                    system_prompt = gr.Textbox(show_label=True, placeholder=f\"System Prompt\", label=\"System prompt\", value=initial_prompt)\r\n                    top_p = gr.Slider(minimum=-0, maximum=1.0, value=1.0, step=0.01,interactive=True, label=\"Top-p (nucleus sampling)\",)\r\n                    temperature = gr.Slider(minimum=-0, maximum=2.0, value=1.0, step=0.01, interactive=True, label=\"Temperature\",)\r\n                    max_length_sl = gr.Slider(minimum=256, maximum=4096, value=512, step=1, interactive=True, label=\"Local LLM MaxLength\",)\r\n                    checkboxes = gr.CheckboxGroup([\"\u57fa\u7840\u529f\u80fd\u533a\", \"\u51fd\u6570\u63d2\u4ef6\u533a\", \"\u5e95\u90e8\u8f93\u5165\u533a\", \"\u8f93\u5165\u6e05\u9664\u952e\", \"\u63d2\u4ef6\u53c2\u6570\u533a\"], value=[\"\u57fa\u7840\u529f\u80fd\u533a\", \"\u51fd\u6570\u63d2\u4ef6\u533a\"], label=\"\u663e\u793a/\u9690\u85cf\u529f\u80fd\u533a\")\r\n                    md_dropdown = gr.Dropdown(AVAIL_LLM_MODELS, value=LLM_MODEL, label=\"\u66f4\u6362LLM\u6a21\u578b/\u8bf7\u6c42\u6e90\").style(container=False)\r\n\r\n                    gr.Markdown(description)\r\n                with gr.Accordion(\"\u5907\u9009\u8f93\u5165\u533a\", open=True, visible=False) as area_input_secondary:\r\n                    with gr.Row():\r\n                        txt2 = gr.Textbox(show_label=False, placeholder=\"Input question here.\", label=\"\u8f93\u5165\u533a2\").style(container=False)\r\n                    with gr.Row():\r\n                        submitBtn2 = gr.Button(\"\u63d0\u4ea4\", variant=\"primary\")\r\n                    with gr.Row():\r\n                        resetBtn2 = gr.Button(\"\u91cd\u7f6e\", variant=\"secondary\"); resetBtn2.style(size=\"sm\")\r\n                        stopBtn2 = gr.Button(\"\u505c\u6b62\", variant=\"secondary\"); stopBtn2.style(size=\"sm\")\r\n                        clearBtn2 = gr.Button(\"\u6e05\u9664\", variant=\"secondary\", visible=False); clearBtn2.style(size=\"sm\")\r\n        # \u529f\u80fd\u533a\u663e\u793a\u5f00\u5173\u4e0e\u529f\u80fd\u533a\u7684\u4e92\u52a8\r\n        def fn_area_visibility(a):\r\n            ret = {}\r\n            ret.update({area_basic_fn: gr.update(visible=(\"\u57fa\u7840\u529f\u80fd\u533a\" in a))})\r\n            ret.update({area_crazy_fn: gr.update(visible=(\"\u51fd\u6570\u63d2\u4ef6\u533a\" in a))})\r\n            ret.update({area_input_primary: gr.update(visible=(\"\u5e95\u90e8\u8f93\u5165\u533a\" not in a))})\r\n            ret.update({area_input_secondary: gr.update(visible=(\"\u5e95\u90e8\u8f93\u5165\u533a\" in a))})\r\n            ret.update({clearBtn: gr.update(visible=(\"\u8f93\u5165\u6e05\u9664\u952e\" in a))})\r\n            ret.update({clearBtn2: gr.update(visible=(\"\u8f93\u5165\u6e05\u9664\u952e\" in a))})\r\n            ret.update({plugin_advanced_arg: gr.update(visible=(\"\u63d2\u4ef6\u53c2\u6570\u533a\" in a))})\r\n            if \"\u5e95\u90e8\u8f93\u5165\u533a\" in a: ret.update({txt: gr.update(value=\"\")})\r\n            return ret\r\n        checkboxes.select(fn_area_visibility, [checkboxes], [area_basic_fn, area_crazy_fn, area_input_primary, area_input_secondary, txt, txt2, clearBtn, clearBtn2, plugin_advanced_arg] )\r\n        # \u6574\u7406\u53cd\u590d\u51fa\u73b0\u7684\u63a7\u4ef6\u53e5\u67c4\u7ec4\u5408\r\n        input_combo = [cookies, max_length_sl, md_dropdown, txt, txt2, top_p, temperature, chatbot, history, system_prompt, plugin_advanced_arg]\r\n        output_combo = [cookies, chatbot, history, status]\r\n        predict_args = dict(fn=ArgsGeneralWrapper(predict), inputs=input_combo, outputs=output_combo)\r\n        # \u63d0\u4ea4\u6309\u94ae\u3001\u91cd\u7f6e\u6309\u94ae\r\n        cancel_handles.append(txt.submit(**predict_args))\r\n        cancel_handles.append(txt2.submit(**predict_args))\r\n        cancel_handles.append(submitBtn.click(**predict_args))\r\n        cancel_handles.append(submitBtn2.click(**predict_args))\r\n        resetBtn.click(lambda: ([], [], \"\u5df2\u91cd\u7f6e\"), None, [chatbot, history, status])\r\n        resetBtn2.click(lambda: ([], [], \"\u5df2\u91cd\u7f6e\"), None, [chatbot, history, status])\r\n        clearBtn.click(lambda: (\"\",\"\"), None, [txt, txt2])\r\n        clearBtn2.click(lambda: (\"\",\"\"), None, [txt, txt2])\r\n        # \u57fa\u7840\u529f\u80fd\u533a\u7684\u56de\u8c03\u51fd\u6570\u6ce8\u518c\r\n        for k in functional:\r\n            if (\"Visible\" in functional[k]) and (not functional[k][\"Visible\"]): continue\r\n            click_handle = functional[k][\"Button\"].click(fn=ArgsGeneralWrapper(predict), inputs=[*input_combo, gr.State(True), gr.State(k)], outputs=output_combo)\r\n            cancel_handles.append(click_handle)\r\n        # \u6587\u4ef6\u4e0a\u4f20\u533a\uff0c\u63a5\u6536\u6587\u4ef6\u540e\u4e0echatbot\u7684\u4e92\u52a8\r\n        file_upload.upload(on_file_uploaded, [file_upload, chatbot, txt, txt2, checkboxes], [chatbot, txt, txt2])\r\n        # \u51fd\u6570\u63d2\u4ef6-\u56fa\u5b9a\u6309\u94ae\u533a\r\n        for k in crazy_fns:\r\n            if not crazy_fns[k].get(\"AsButton\", True): continue\r\n            click_handle = crazy_fns[k][\"Button\"].click(ArgsGeneralWrapper(crazy_fns[k][\"Function\"]), [*input_combo, gr.State(PORT)], output_combo)\r\n            click_handle.then(on_report_generated, [file_upload, chatbot], [file_upload, chatbot])\r\n            cancel_handles.append(click_handle)\r\n        # \u51fd\u6570\u63d2\u4ef6-\u4e0b\u62c9\u83dc\u5355\u4e0e\u968f\u53d8\u6309\u94ae\u7684\u4e92\u52a8\r\n        def on_dropdown_changed(k):\r\n            variant = crazy_fns[k][\"Color\"] if \"Color\" in crazy_fns[k] else \"secondary\"\r\n            ret = {switchy_bt: gr.update(value=k, variant=variant)}\r\n            if crazy_fns[k].get(\"AdvancedArgs\", False): # \u662f\u5426\u5524\u8d77\u9ad8\u7ea7\u63d2\u4ef6\u53c2\u6570\u533a\r\n                ret.update({plugin_advanced_arg: gr.update(visible=True,  label=f\"\u63d2\u4ef6[{k}]\u7684\u9ad8\u7ea7\u53c2\u6570\u8bf4\u660e\uff1a\" + crazy_fns[k].get(\"ArgsReminder\", [f\"\u6ca1\u6709\u63d0\u4f9b\u9ad8\u7ea7\u53c2\u6570\u529f\u80fd\u8bf4\u660e\"]))})\r\n            else:\r\n                ret.update({plugin_advanced_arg: gr.update(visible=False, label=f\"\u63d2\u4ef6[{k}]\u4e0d\u9700\u8981\u9ad8\u7ea7\u53c2\u6570\u3002\")})\r\n            return ret\r\n        dropdown.select(on_dropdown_changed, [dropdown], [switchy_bt, plugin_advanced_arg] )\r\n        def on_md_dropdown_changed(k):\r\n            return {chatbot: gr.update(label=\"\u5f53\u524d\u6a21\u578b\uff1a\"+k)}\r\n        md_dropdown.select(on_md_dropdown_changed, [md_dropdown], [chatbot] )\r\n        # \u968f\u53d8\u6309\u94ae\u7684\u56de\u8c03\u51fd\u6570\u6ce8\u518c\r\n        def route(k, *args, **kwargs):\r\n            if k in [r\"\u6253\u5f00\u63d2\u4ef6\u5217\u8868\", r\"\u8bf7\u5148\u4ece\u63d2\u4ef6\u5217\u8868\u4e2d\u9009\u62e9\"]: return\r\n            yield from ArgsGeneralWrapper(crazy_fns[k][\"Function\"])(*args, **kwargs)\r\n        click_handle = switchy_bt.click(route,[switchy_bt, *input_combo, gr.State(PORT)], output_combo)\r\n        click_handle.then(on_report_generated, [file_upload, chatbot], [file_upload, chatbot])\r\n        cancel_handles.append(click_handle)\r\n        # \u7ec8\u6b62\u6309\u94ae\u7684\u56de\u8c03\u51fd\u6570\u6ce8\u518c\r\n        stopBtn.click(fn=None, inputs=None, outputs=None, cancels=cancel_handles)\r\n        stopBtn2.click(fn=None, inputs=None, outputs=None, cancels=cancel_handles)\r\n\r\n    # gradio\u7684inbrowser\u89e6\u53d1\u4e0d\u592a\u7a33\u5b9a\uff0c\u56de\u6eda\u4ee3\u7801\u5230\u539f\u59cb\u7684\u6d4f\u89c8\u5668\u6253\u5f00\u51fd\u6570\r\n    def auto_opentab_delay():\r\n        import threading, webbrowser, time\r\n        print(f\"\u5982\u679c\u6d4f\u89c8\u5668\u6ca1\u6709\u81ea\u52a8\u6253\u5f00\uff0c\u8bf7\u590d\u5236\u5e76\u8f6c\u5230\u4ee5\u4e0bURL\uff1a\")\r\n        print(f\"\\t\uff08\u4eae\u8272\u4e3b\u9898\uff09: http://localhost:{PORT}\")\r\n        print(f\"\\t\uff08\u6697\u8272\u4e3b\u9898\uff09: http://localhost:{PORT}/?__theme=dark\")\r\n        def open():\r\n            time.sleep(2)       # \u6253\u5f00\u6d4f\u89c8\u5668\r\n            DARK_MODE, = get_conf('DARK_MODE')\r\n            if DARK_MODE: webbrowser.open_new_tab(f\"http://localhost:{PORT}/?__theme=dark\")\r\n            else: webbrowser.open_new_tab(f\"http://localhost:{PORT}\")\r\n        threading.Thread(target=open, name=\"open-browser\", daemon=True).start()\r\n        threading.Thread(target=auto_update, name=\"self-upgrade\", daemon=True).start()\r\n        threading.Thread(target=warm_up_modules, name=\"warm-up\", daemon=True).start()\r\n\r\n    auto_opentab_delay()\r\n    demo.queue(concurrency_count=CONCURRENT_COUNT).launch(server_name=\"0.0.0.0\", server_port=PORT, auth=AUTHENTICATION, favicon_path=\"docs/logo.png\")\r\n\r\n    # \u5982\u679c\u9700\u8981\u5728\u4e8c\u7ea7\u8def\u5f84\u4e0b\u8fd0\u884c\r\n    # CUSTOM_PATH, = get_conf('CUSTOM_PATH')\r\n    # if CUSTOM_PATH != \"/\": \r\n    #     from toolbox import run_gradio_in_subpath\r\n    #     run_gradio_in_subpath(demo, auth=AUTHENTICATION, port=PORT, custom_path=CUSTOM_PATH)\r\n    # else: \r\n    #     demo.launch(server_name=\"0.0.0.0\", server_port=PORT, auth=AUTHENTICATION, favicon_path=\"docs/logo.png\")\r\n\r\nif __name__ == \"__main__\":\r\n    main()\r\n"], "fixing_code": ["import os; os.environ['no_proxy'] = '*' # \u907f\u514d\u4ee3\u7406\u7f51\u7edc\u4ea7\u751f\u610f\u5916\u6c61\u67d3\r\n\r\ndef main():\r\n    import gradio as gr\r\n    if gr.__version__ not in ['3.28.3','3.32.2']: assert False, \"\u8bf7\u7528 pip install -r requirements.txt \u5b89\u88c5\u4f9d\u8d56\"\r\n    from request_llm.bridge_all import predict\r\n    from toolbox import format_io, find_free_port, on_file_uploaded, on_report_generated, get_conf, ArgsGeneralWrapper, DummyWith\r\n    # \u5efa\u8bae\u60a8\u590d\u5236\u4e00\u4e2aconfig_private.py\u653e\u81ea\u5df1\u7684\u79d8\u5bc6, \u5982API\u548c\u4ee3\u7406\u7f51\u5740, \u907f\u514d\u4e0d\u5c0f\u5fc3\u4f20github\u88ab\u522b\u4eba\u770b\u5230\r\n    proxies, WEB_PORT, LLM_MODEL, CONCURRENT_COUNT, AUTHENTICATION, CHATBOT_HEIGHT, LAYOUT, API_KEY, AVAIL_LLM_MODELS = \\\r\n        get_conf('proxies', 'WEB_PORT', 'LLM_MODEL', 'CONCURRENT_COUNT', 'AUTHENTICATION', 'CHATBOT_HEIGHT', 'LAYOUT', 'API_KEY', 'AVAIL_LLM_MODELS')\r\n\r\n    # \u5982\u679cWEB_PORT\u662f-1, \u5219\u968f\u673a\u9009\u53d6WEB\u7aef\u53e3\r\n    PORT = find_free_port() if WEB_PORT <= 0 else WEB_PORT\r\n    if not AUTHENTICATION: AUTHENTICATION = None\r\n\r\n    from check_proxy import get_current_version\r\n    initial_prompt = \"Serve me as a writing and programming assistant.\"\r\n    title_html = f\"<h1 align=\\\"center\\\">ChatGPT \u5b66\u672f\u4f18\u5316 {get_current_version()}</h1>\"\r\n    description =  \"\"\"\u4ee3\u7801\u5f00\u6e90\u548c\u66f4\u65b0[\u5730\u5740\ud83d\ude80](https://github.com/binary-husky/chatgpt_academic)\uff0c\u611f\u8c22\u70ed\u60c5\u7684[\u5f00\u53d1\u8005\u4eec\u2764\ufe0f](https://github.com/binary-husky/chatgpt_academic/graphs/contributors)\"\"\"\r\n\r\n    # \u95ee\u8be2\u8bb0\u5f55, python \u7248\u672c\u5efa\u8bae3.9+\uff08\u8d8a\u65b0\u8d8a\u597d\uff09\r\n    import logging\r\n    os.makedirs(\"gpt_log\", exist_ok=True)\r\n    try:logging.basicConfig(filename=\"gpt_log/chat_secrets.log\", level=logging.INFO, encoding=\"utf-8\")\r\n    except:logging.basicConfig(filename=\"gpt_log/chat_secrets.log\", level=logging.INFO)\r\n    print(\"\u6240\u6709\u95ee\u8be2\u8bb0\u5f55\u5c06\u81ea\u52a8\u4fdd\u5b58\u5728\u672c\u5730\u76ee\u5f55./gpt_log/chat_secrets.log, \u8bf7\u6ce8\u610f\u81ea\u6211\u9690\u79c1\u4fdd\u62a4\u54e6\uff01\")\r\n\r\n    # \u4e00\u4e9b\u666e\u901a\u529f\u80fd\u6a21\u5757\r\n    from core_functional import get_core_functions\r\n    functional = get_core_functions()\r\n\r\n    # \u9ad8\u7ea7\u51fd\u6570\u63d2\u4ef6\r\n    from crazy_functional import get_crazy_functions\r\n    crazy_fns = get_crazy_functions()\r\n\r\n    # \u5904\u7406markdown\u6587\u672c\u683c\u5f0f\u7684\u8f6c\u53d8\r\n    gr.Chatbot.postprocess = format_io\r\n\r\n    # \u505a\u4e00\u4e9b\u5916\u89c2\u8272\u5f69\u4e0a\u7684\u8c03\u6574\r\n    from theme import adjust_theme, advanced_css\r\n    set_theme = adjust_theme()\r\n\r\n    # \u4ee3\u7406\u4e0e\u81ea\u52a8\u66f4\u65b0\r\n    from check_proxy import check_proxy, auto_update, warm_up_modules\r\n    proxy_info = check_proxy(proxies)\r\n\r\n    gr_L1 = lambda: gr.Row().style()\r\n    gr_L2 = lambda scale: gr.Column(scale=scale)\r\n    if LAYOUT == \"TOP-DOWN\":\r\n        gr_L1 = lambda: DummyWith()\r\n        gr_L2 = lambda scale: gr.Row()\r\n        CHATBOT_HEIGHT /= 2\r\n\r\n    cancel_handles = []\r\n    with gr.Blocks(title=\"ChatGPT \u5b66\u672f\u4f18\u5316\", theme=set_theme, analytics_enabled=False, css=advanced_css) as demo:\r\n        gr.HTML(title_html)\r\n        cookies = gr.State({'api_key': API_KEY, 'llm_model': LLM_MODEL})\r\n        with gr_L1():\r\n            with gr_L2(scale=2):\r\n                chatbot = gr.Chatbot(label=f\"\u5f53\u524d\u6a21\u578b\uff1a{LLM_MODEL}\")\r\n                chatbot.style(height=CHATBOT_HEIGHT)\r\n                history = gr.State([])\r\n            with gr_L2(scale=1):\r\n                with gr.Accordion(\"\u8f93\u5165\u533a\", open=True) as area_input_primary:\r\n                    with gr.Row():\r\n                        txt = gr.Textbox(show_label=False, placeholder=\"Input question here.\").style(container=False)\r\n                    with gr.Row():\r\n                        submitBtn = gr.Button(\"\u63d0\u4ea4\", variant=\"primary\")\r\n                    with gr.Row():\r\n                        resetBtn = gr.Button(\"\u91cd\u7f6e\", variant=\"secondary\"); resetBtn.style(size=\"sm\")\r\n                        stopBtn = gr.Button(\"\u505c\u6b62\", variant=\"secondary\"); stopBtn.style(size=\"sm\")\r\n                        clearBtn = gr.Button(\"\u6e05\u9664\", variant=\"secondary\", visible=False); clearBtn.style(size=\"sm\")\r\n                    with gr.Row():\r\n                        status = gr.Markdown(f\"Tip: \u6309Enter\u63d0\u4ea4, \u6309Shift+Enter\u6362\u884c\u3002\u5f53\u524d\u6a21\u578b: {LLM_MODEL} \\n {proxy_info}\")\r\n                with gr.Accordion(\"\u57fa\u7840\u529f\u80fd\u533a\", open=True) as area_basic_fn:\r\n                    with gr.Row():\r\n                        for k in functional:\r\n                            if (\"Visible\" in functional[k]) and (not functional[k][\"Visible\"]): continue\r\n                            variant = functional[k][\"Color\"] if \"Color\" in functional[k] else \"secondary\"\r\n                            functional[k][\"Button\"] = gr.Button(k, variant=variant)\r\n                with gr.Accordion(\"\u51fd\u6570\u63d2\u4ef6\u533a\", open=True) as area_crazy_fn:\r\n                    with gr.Row():\r\n                        gr.Markdown(\"\u6ce8\u610f\uff1a\u4ee5\u4e0b\u201c\u7ea2\u989c\u8272\u201d\u6807\u8bc6\u7684\u51fd\u6570\u63d2\u4ef6\u9700\u4ece\u8f93\u5165\u533a\u8bfb\u53d6\u8def\u5f84\u4f5c\u4e3a\u53c2\u6570.\")\r\n                    with gr.Row():\r\n                        for k in crazy_fns:\r\n                            if not crazy_fns[k].get(\"AsButton\", True): continue\r\n                            variant = crazy_fns[k][\"Color\"] if \"Color\" in crazy_fns[k] else \"secondary\"\r\n                            crazy_fns[k][\"Button\"] = gr.Button(k, variant=variant)\r\n                            crazy_fns[k][\"Button\"].style(size=\"sm\")\r\n                    with gr.Row():\r\n                        with gr.Accordion(\"\u66f4\u591a\u51fd\u6570\u63d2\u4ef6\", open=True):\r\n                            dropdown_fn_list = [k for k in crazy_fns.keys() if not crazy_fns[k].get(\"AsButton\", True)]\r\n                            with gr.Row():\r\n                                dropdown = gr.Dropdown(dropdown_fn_list, value=r\"\u6253\u5f00\u63d2\u4ef6\u5217\u8868\", label=\"\").style(container=False)\r\n                            with gr.Row():\r\n                                plugin_advanced_arg = gr.Textbox(show_label=True, label=\"\u9ad8\u7ea7\u53c2\u6570\u8f93\u5165\u533a\", visible=False, \r\n                                                                 placeholder=\"\u8fd9\u91cc\u662f\u7279\u6b8a\u51fd\u6570\u63d2\u4ef6\u7684\u9ad8\u7ea7\u53c2\u6570\u8f93\u5165\u533a\").style(container=False)\r\n                            with gr.Row():\r\n                                switchy_bt = gr.Button(r\"\u8bf7\u5148\u4ece\u63d2\u4ef6\u5217\u8868\u4e2d\u9009\u62e9\", variant=\"secondary\")\r\n                    with gr.Row():\r\n                        with gr.Accordion(\"\u70b9\u51fb\u5c55\u5f00\u201c\u6587\u4ef6\u4e0a\u4f20\u533a\u201d\u3002\u4e0a\u4f20\u672c\u5730\u6587\u4ef6\u53ef\u4f9b\u7ea2\u8272\u51fd\u6570\u63d2\u4ef6\u8c03\u7528\u3002\", open=False) as area_file_up:\r\n                            file_upload = gr.Files(label=\"\u4efb\u4f55\u6587\u4ef6, \u4f46\u63a8\u8350\u4e0a\u4f20\u538b\u7f29\u6587\u4ef6(zip, tar)\", file_count=\"multiple\")\r\n                with gr.Accordion(\"\u66f4\u6362\u6a21\u578b & SysPrompt & \u4ea4\u4e92\u754c\u9762\u5e03\u5c40\", open=(LAYOUT == \"TOP-DOWN\")):\r\n                    system_prompt = gr.Textbox(show_label=True, placeholder=f\"System Prompt\", label=\"System prompt\", value=initial_prompt)\r\n                    top_p = gr.Slider(minimum=-0, maximum=1.0, value=1.0, step=0.01,interactive=True, label=\"Top-p (nucleus sampling)\",)\r\n                    temperature = gr.Slider(minimum=-0, maximum=2.0, value=1.0, step=0.01, interactive=True, label=\"Temperature\",)\r\n                    max_length_sl = gr.Slider(minimum=256, maximum=4096, value=512, step=1, interactive=True, label=\"Local LLM MaxLength\",)\r\n                    checkboxes = gr.CheckboxGroup([\"\u57fa\u7840\u529f\u80fd\u533a\", \"\u51fd\u6570\u63d2\u4ef6\u533a\", \"\u5e95\u90e8\u8f93\u5165\u533a\", \"\u8f93\u5165\u6e05\u9664\u952e\", \"\u63d2\u4ef6\u53c2\u6570\u533a\"], value=[\"\u57fa\u7840\u529f\u80fd\u533a\", \"\u51fd\u6570\u63d2\u4ef6\u533a\"], label=\"\u663e\u793a/\u9690\u85cf\u529f\u80fd\u533a\")\r\n                    md_dropdown = gr.Dropdown(AVAIL_LLM_MODELS, value=LLM_MODEL, label=\"\u66f4\u6362LLM\u6a21\u578b/\u8bf7\u6c42\u6e90\").style(container=False)\r\n\r\n                    gr.Markdown(description)\r\n                with gr.Accordion(\"\u5907\u9009\u8f93\u5165\u533a\", open=True, visible=False) as area_input_secondary:\r\n                    with gr.Row():\r\n                        txt2 = gr.Textbox(show_label=False, placeholder=\"Input question here.\", label=\"\u8f93\u5165\u533a2\").style(container=False)\r\n                    with gr.Row():\r\n                        submitBtn2 = gr.Button(\"\u63d0\u4ea4\", variant=\"primary\")\r\n                    with gr.Row():\r\n                        resetBtn2 = gr.Button(\"\u91cd\u7f6e\", variant=\"secondary\"); resetBtn2.style(size=\"sm\")\r\n                        stopBtn2 = gr.Button(\"\u505c\u6b62\", variant=\"secondary\"); stopBtn2.style(size=\"sm\")\r\n                        clearBtn2 = gr.Button(\"\u6e05\u9664\", variant=\"secondary\", visible=False); clearBtn2.style(size=\"sm\")\r\n        # \u529f\u80fd\u533a\u663e\u793a\u5f00\u5173\u4e0e\u529f\u80fd\u533a\u7684\u4e92\u52a8\r\n        def fn_area_visibility(a):\r\n            ret = {}\r\n            ret.update({area_basic_fn: gr.update(visible=(\"\u57fa\u7840\u529f\u80fd\u533a\" in a))})\r\n            ret.update({area_crazy_fn: gr.update(visible=(\"\u51fd\u6570\u63d2\u4ef6\u533a\" in a))})\r\n            ret.update({area_input_primary: gr.update(visible=(\"\u5e95\u90e8\u8f93\u5165\u533a\" not in a))})\r\n            ret.update({area_input_secondary: gr.update(visible=(\"\u5e95\u90e8\u8f93\u5165\u533a\" in a))})\r\n            ret.update({clearBtn: gr.update(visible=(\"\u8f93\u5165\u6e05\u9664\u952e\" in a))})\r\n            ret.update({clearBtn2: gr.update(visible=(\"\u8f93\u5165\u6e05\u9664\u952e\" in a))})\r\n            ret.update({plugin_advanced_arg: gr.update(visible=(\"\u63d2\u4ef6\u53c2\u6570\u533a\" in a))})\r\n            if \"\u5e95\u90e8\u8f93\u5165\u533a\" in a: ret.update({txt: gr.update(value=\"\")})\r\n            return ret\r\n        checkboxes.select(fn_area_visibility, [checkboxes], [area_basic_fn, area_crazy_fn, area_input_primary, area_input_secondary, txt, txt2, clearBtn, clearBtn2, plugin_advanced_arg] )\r\n        # \u6574\u7406\u53cd\u590d\u51fa\u73b0\u7684\u63a7\u4ef6\u53e5\u67c4\u7ec4\u5408\r\n        input_combo = [cookies, max_length_sl, md_dropdown, txt, txt2, top_p, temperature, chatbot, history, system_prompt, plugin_advanced_arg]\r\n        output_combo = [cookies, chatbot, history, status]\r\n        predict_args = dict(fn=ArgsGeneralWrapper(predict), inputs=input_combo, outputs=output_combo)\r\n        # \u63d0\u4ea4\u6309\u94ae\u3001\u91cd\u7f6e\u6309\u94ae\r\n        cancel_handles.append(txt.submit(**predict_args))\r\n        cancel_handles.append(txt2.submit(**predict_args))\r\n        cancel_handles.append(submitBtn.click(**predict_args))\r\n        cancel_handles.append(submitBtn2.click(**predict_args))\r\n        resetBtn.click(lambda: ([], [], \"\u5df2\u91cd\u7f6e\"), None, [chatbot, history, status])\r\n        resetBtn2.click(lambda: ([], [], \"\u5df2\u91cd\u7f6e\"), None, [chatbot, history, status])\r\n        clearBtn.click(lambda: (\"\",\"\"), None, [txt, txt2])\r\n        clearBtn2.click(lambda: (\"\",\"\"), None, [txt, txt2])\r\n        # \u57fa\u7840\u529f\u80fd\u533a\u7684\u56de\u8c03\u51fd\u6570\u6ce8\u518c\r\n        for k in functional:\r\n            if (\"Visible\" in functional[k]) and (not functional[k][\"Visible\"]): continue\r\n            click_handle = functional[k][\"Button\"].click(fn=ArgsGeneralWrapper(predict), inputs=[*input_combo, gr.State(True), gr.State(k)], outputs=output_combo)\r\n            cancel_handles.append(click_handle)\r\n        # \u6587\u4ef6\u4e0a\u4f20\u533a\uff0c\u63a5\u6536\u6587\u4ef6\u540e\u4e0echatbot\u7684\u4e92\u52a8\r\n        file_upload.upload(on_file_uploaded, [file_upload, chatbot, txt, txt2, checkboxes], [chatbot, txt, txt2])\r\n        # \u51fd\u6570\u63d2\u4ef6-\u56fa\u5b9a\u6309\u94ae\u533a\r\n        for k in crazy_fns:\r\n            if not crazy_fns[k].get(\"AsButton\", True): continue\r\n            click_handle = crazy_fns[k][\"Button\"].click(ArgsGeneralWrapper(crazy_fns[k][\"Function\"]), [*input_combo, gr.State(PORT)], output_combo)\r\n            click_handle.then(on_report_generated, [file_upload, chatbot], [file_upload, chatbot])\r\n            cancel_handles.append(click_handle)\r\n        # \u51fd\u6570\u63d2\u4ef6-\u4e0b\u62c9\u83dc\u5355\u4e0e\u968f\u53d8\u6309\u94ae\u7684\u4e92\u52a8\r\n        def on_dropdown_changed(k):\r\n            variant = crazy_fns[k][\"Color\"] if \"Color\" in crazy_fns[k] else \"secondary\"\r\n            ret = {switchy_bt: gr.update(value=k, variant=variant)}\r\n            if crazy_fns[k].get(\"AdvancedArgs\", False): # \u662f\u5426\u5524\u8d77\u9ad8\u7ea7\u63d2\u4ef6\u53c2\u6570\u533a\r\n                ret.update({plugin_advanced_arg: gr.update(visible=True,  label=f\"\u63d2\u4ef6[{k}]\u7684\u9ad8\u7ea7\u53c2\u6570\u8bf4\u660e\uff1a\" + crazy_fns[k].get(\"ArgsReminder\", [f\"\u6ca1\u6709\u63d0\u4f9b\u9ad8\u7ea7\u53c2\u6570\u529f\u80fd\u8bf4\u660e\"]))})\r\n            else:\r\n                ret.update({plugin_advanced_arg: gr.update(visible=False, label=f\"\u63d2\u4ef6[{k}]\u4e0d\u9700\u8981\u9ad8\u7ea7\u53c2\u6570\u3002\")})\r\n            return ret\r\n        dropdown.select(on_dropdown_changed, [dropdown], [switchy_bt, plugin_advanced_arg] )\r\n        def on_md_dropdown_changed(k):\r\n            return {chatbot: gr.update(label=\"\u5f53\u524d\u6a21\u578b\uff1a\"+k)}\r\n        md_dropdown.select(on_md_dropdown_changed, [md_dropdown], [chatbot] )\r\n        # \u968f\u53d8\u6309\u94ae\u7684\u56de\u8c03\u51fd\u6570\u6ce8\u518c\r\n        def route(k, *args, **kwargs):\r\n            if k in [r\"\u6253\u5f00\u63d2\u4ef6\u5217\u8868\", r\"\u8bf7\u5148\u4ece\u63d2\u4ef6\u5217\u8868\u4e2d\u9009\u62e9\"]: return\r\n            yield from ArgsGeneralWrapper(crazy_fns[k][\"Function\"])(*args, **kwargs)\r\n        click_handle = switchy_bt.click(route,[switchy_bt, *input_combo, gr.State(PORT)], output_combo)\r\n        click_handle.then(on_report_generated, [file_upload, chatbot], [file_upload, chatbot])\r\n        cancel_handles.append(click_handle)\r\n        # \u7ec8\u6b62\u6309\u94ae\u7684\u56de\u8c03\u51fd\u6570\u6ce8\u518c\r\n        stopBtn.click(fn=None, inputs=None, outputs=None, cancels=cancel_handles)\r\n        stopBtn2.click(fn=None, inputs=None, outputs=None, cancels=cancel_handles)\r\n\r\n    # gradio\u7684inbrowser\u89e6\u53d1\u4e0d\u592a\u7a33\u5b9a\uff0c\u56de\u6eda\u4ee3\u7801\u5230\u539f\u59cb\u7684\u6d4f\u89c8\u5668\u6253\u5f00\u51fd\u6570\r\n    def auto_opentab_delay():\r\n        import threading, webbrowser, time\r\n        print(f\"\u5982\u679c\u6d4f\u89c8\u5668\u6ca1\u6709\u81ea\u52a8\u6253\u5f00\uff0c\u8bf7\u590d\u5236\u5e76\u8f6c\u5230\u4ee5\u4e0bURL\uff1a\")\r\n        print(f\"\\t\uff08\u4eae\u8272\u4e3b\u9898\uff09: http://localhost:{PORT}\")\r\n        print(f\"\\t\uff08\u6697\u8272\u4e3b\u9898\uff09: http://localhost:{PORT}/?__theme=dark\")\r\n        def open():\r\n            time.sleep(2)       # \u6253\u5f00\u6d4f\u89c8\u5668\r\n            DARK_MODE, = get_conf('DARK_MODE')\r\n            if DARK_MODE: webbrowser.open_new_tab(f\"http://localhost:{PORT}/?__theme=dark\")\r\n            else: webbrowser.open_new_tab(f\"http://localhost:{PORT}\")\r\n        threading.Thread(target=open, name=\"open-browser\", daemon=True).start()\r\n        threading.Thread(target=auto_update, name=\"self-upgrade\", daemon=True).start()\r\n        threading.Thread(target=warm_up_modules, name=\"warm-up\", daemon=True).start()\r\n\r\n    auto_opentab_delay()\r\n    demo.queue(concurrency_count=CONCURRENT_COUNT).launch(\r\n        server_name=\"0.0.0.0\", server_port=PORT, auth=AUTHENTICATION,\r\n        favicon_path=\"docs/logo.png\", blocked_paths=[\"config.py\",\"config_private.py\",\"docker-compose.yml\",\"Dockerfile\"])\r\n\r\n    # \u5982\u679c\u9700\u8981\u5728\u4e8c\u7ea7\u8def\u5f84\u4e0b\u8fd0\u884c\r\n    # CUSTOM_PATH, = get_conf('CUSTOM_PATH')\r\n    # if CUSTOM_PATH != \"/\": \r\n    #     from toolbox import run_gradio_in_subpath\r\n    #     run_gradio_in_subpath(demo, auth=AUTHENTICATION, port=PORT, custom_path=CUSTOM_PATH)\r\n    # else: \r\n    #     demo.launch(server_name=\"0.0.0.0\", server_port=PORT, auth=AUTHENTICATION, favicon_path=\"docs/logo.png\")\r\n\r\nif __name__ == \"__main__\":\r\n    main()\r\n"], "filenames": ["main.py"], "buggy_code_start_loc": [200], "buggy_code_end_loc": [201], "fixing_code_start_loc": [200], "fixing_code_end_loc": [203], "type": "CWE-200", "message": "gpt_academic provides a graphical interface for ChatGPT/GLM. A vulnerability was found in gpt_academic 3.37 and prior. This issue affects some unknown processing of the component Configuration File Handler. The manipulation of the argument file leads to information disclosure. Since no sensitive files are configured to be off-limits, sensitive information files in some working directories can be read through the `/file` route, leading to sensitive information leakage. This affects users that uses file configurations via `config.py`, `config_private.py`, `Dockerfile`. A patch is available at commit 1dcc2873d2168ad2d3d70afcb453ac1695fbdf02. As a workaround, one may use environment variables instead of `config*.py` files to configure this project, or use docker-compose installation to configure this project.", "other": {"cve": {"id": "CVE-2023-33979", "sourceIdentifier": "security-advisories@github.com", "published": "2023-05-31T19:15:27.163", "lastModified": "2023-06-08T13:41:28.850", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "gpt_academic provides a graphical interface for ChatGPT/GLM. A vulnerability was found in gpt_academic 3.37 and prior. This issue affects some unknown processing of the component Configuration File Handler. The manipulation of the argument file leads to information disclosure. Since no sensitive files are configured to be off-limits, sensitive information files in some working directories can be read through the `/file` route, leading to sensitive information leakage. This affects users that uses file configurations via `config.py`, `config_private.py`, `Dockerfile`. A patch is available at commit 1dcc2873d2168ad2d3d70afcb453ac1695fbdf02. As a workaround, one may use environment variables instead of `config*.py` files to configure this project, or use docker-compose installation to configure this project."}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:H/I:N/A:N", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "NONE", "availabilityImpact": "NONE", "baseScore": 6.5, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 2.8, "impactScore": 3.6}, {"source": "security-advisories@github.com", "type": "Secondary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:H/I:N/A:N", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "NONE", "availabilityImpact": "NONE", "baseScore": 6.5, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 2.8, "impactScore": 3.6}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-200"}]}, {"source": "security-advisories@github.com", "type": "Secondary", "description": [{"lang": "en", "value": "CWE-200"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:gpt_academic_project:gpt_academic:*:*:*:*:*:*:*:*", "versionEndExcluding": "3.37", "matchCriteriaId": "F668B717-FBAD-4982-9C25-C725A580EC34"}]}]}], "references": [{"url": "https://github.com/binary-husky/gpt_academic/commit/1dcc2873d2168ad2d3d70afcb453ac1695fbdf02", "source": "security-advisories@github.com", "tags": ["Patch"]}, {"url": "https://github.com/binary-husky/gpt_academic/security/advisories/GHSA-pg65-p24m-wf5g", "source": "security-advisories@github.com", "tags": ["Patch", "Vendor Advisory"]}]}, "github_commit_url": "https://github.com/binary-husky/gpt_academic/commit/1dcc2873d2168ad2d3d70afcb453ac1695fbdf02"}}
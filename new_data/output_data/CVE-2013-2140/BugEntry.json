{"buggy_code": ["/******************************************************************************\n *\n * Back-end of the driver for virtual block devices. This portion of the\n * driver exports a 'unified' block-device interface that can be accessed\n * by any operating system that implements a compatible front end. A\n * reference front-end implementation can be found in:\n *  drivers/block/xen-blkfront.c\n *\n * Copyright (c) 2003-2004, Keir Fraser & Steve Hand\n * Copyright (c) 2005, Christopher Clark\n *\n * This program is free software; you can redistribute it and/or\n * modify it under the terms of the GNU General Public License version 2\n * as published by the Free Software Foundation; or, when distributed\n * separately from the Linux kernel or incorporated into other\n * software packages, subject to the following license:\n *\n * Permission is hereby granted, free of charge, to any person obtaining a copy\n * of this source file (the \"Software\"), to deal in the Software without\n * restriction, including without limitation the rights to use, copy, modify,\n * merge, publish, distribute, sublicense, and/or sell copies of the Software,\n * and to permit persons to whom the Software is furnished to do so, subject to\n * the following conditions:\n *\n * The above copyright notice and this permission notice shall be included in\n * all copies or substantial portions of the Software.\n *\n * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n * IN THE SOFTWARE.\n */\n\n#include <linux/spinlock.h>\n#include <linux/kthread.h>\n#include <linux/list.h>\n#include <linux/delay.h>\n#include <linux/freezer.h>\n#include <linux/bitmap.h>\n\n#include <xen/events.h>\n#include <xen/page.h>\n#include <xen/xen.h>\n#include <asm/xen/hypervisor.h>\n#include <asm/xen/hypercall.h>\n#include <xen/balloon.h>\n#include \"common.h\"\n\n/*\n * Maximum number of unused free pages to keep in the internal buffer.\n * Setting this to a value too low will reduce memory used in each backend,\n * but can have a performance penalty.\n *\n * A sane value is xen_blkif_reqs * BLKIF_MAX_SEGMENTS_PER_REQUEST, but can\n * be set to a lower value that might degrade performance on some intensive\n * IO workloads.\n */\n\nstatic int xen_blkif_max_buffer_pages = 1024;\nmodule_param_named(max_buffer_pages, xen_blkif_max_buffer_pages, int, 0644);\nMODULE_PARM_DESC(max_buffer_pages,\n\"Maximum number of free pages to keep in each block backend buffer\");\n\n/*\n * Maximum number of grants to map persistently in blkback. For maximum\n * performance this should be the total numbers of grants that can be used\n * to fill the ring, but since this might become too high, specially with\n * the use of indirect descriptors, we set it to a value that provides good\n * performance without using too much memory.\n *\n * When the list of persistent grants is full we clean it up using a LRU\n * algorithm.\n */\n\nstatic int xen_blkif_max_pgrants = 1056;\nmodule_param_named(max_persistent_grants, xen_blkif_max_pgrants, int, 0644);\nMODULE_PARM_DESC(max_persistent_grants,\n                 \"Maximum number of grants to map persistently\");\n\n/*\n * The LRU mechanism to clean the lists of persistent grants needs to\n * be executed periodically. The time interval between consecutive executions\n * of the purge mechanism is set in ms.\n */\n#define LRU_INTERVAL 100\n\n/*\n * When the persistent grants list is full we will remove unused grants\n * from the list. The percent number of grants to be removed at each LRU\n * execution.\n */\n#define LRU_PERCENT_CLEAN 5\n\n/* Run-time switchable: /sys/module/blkback/parameters/ */\nstatic unsigned int log_stats;\nmodule_param(log_stats, int, 0644);\n\n#define BLKBACK_INVALID_HANDLE (~0)\n\n/* Number of free pages to remove on each call to free_xenballooned_pages */\n#define NUM_BATCH_FREE_PAGES 10\n\nstatic inline int get_free_page(struct xen_blkif *blkif, struct page **page)\n{\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&blkif->free_pages_lock, flags);\n\tif (list_empty(&blkif->free_pages)) {\n\t\tBUG_ON(blkif->free_pages_num != 0);\n\t\tspin_unlock_irqrestore(&blkif->free_pages_lock, flags);\n\t\treturn alloc_xenballooned_pages(1, page, false);\n\t}\n\tBUG_ON(blkif->free_pages_num == 0);\n\tpage[0] = list_first_entry(&blkif->free_pages, struct page, lru);\n\tlist_del(&page[0]->lru);\n\tblkif->free_pages_num--;\n\tspin_unlock_irqrestore(&blkif->free_pages_lock, flags);\n\n\treturn 0;\n}\n\nstatic inline void put_free_pages(struct xen_blkif *blkif, struct page **page,\n                                  int num)\n{\n\tunsigned long flags;\n\tint i;\n\n\tspin_lock_irqsave(&blkif->free_pages_lock, flags);\n\tfor (i = 0; i < num; i++)\n\t\tlist_add(&page[i]->lru, &blkif->free_pages);\n\tblkif->free_pages_num += num;\n\tspin_unlock_irqrestore(&blkif->free_pages_lock, flags);\n}\n\nstatic inline void shrink_free_pagepool(struct xen_blkif *blkif, int num)\n{\n\t/* Remove requested pages in batches of NUM_BATCH_FREE_PAGES */\n\tstruct page *page[NUM_BATCH_FREE_PAGES];\n\tunsigned int num_pages = 0;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&blkif->free_pages_lock, flags);\n\twhile (blkif->free_pages_num > num) {\n\t\tBUG_ON(list_empty(&blkif->free_pages));\n\t\tpage[num_pages] = list_first_entry(&blkif->free_pages,\n\t\t                                   struct page, lru);\n\t\tlist_del(&page[num_pages]->lru);\n\t\tblkif->free_pages_num--;\n\t\tif (++num_pages == NUM_BATCH_FREE_PAGES) {\n\t\t\tspin_unlock_irqrestore(&blkif->free_pages_lock, flags);\n\t\t\tfree_xenballooned_pages(num_pages, page);\n\t\t\tspin_lock_irqsave(&blkif->free_pages_lock, flags);\n\t\t\tnum_pages = 0;\n\t\t}\n\t}\n\tspin_unlock_irqrestore(&blkif->free_pages_lock, flags);\n\tif (num_pages != 0)\n\t\tfree_xenballooned_pages(num_pages, page);\n}\n\n#define vaddr(page) ((unsigned long)pfn_to_kaddr(page_to_pfn(page)))\n\nstatic int do_block_io_op(struct xen_blkif *blkif);\nstatic int dispatch_rw_block_io(struct xen_blkif *blkif,\n\t\t\t\tstruct blkif_request *req,\n\t\t\t\tstruct pending_req *pending_req);\nstatic void make_response(struct xen_blkif *blkif, u64 id,\n\t\t\t  unsigned short op, int st);\n\n#define foreach_grant_safe(pos, n, rbtree, node) \\\n\tfor ((pos) = container_of(rb_first((rbtree)), typeof(*(pos)), node), \\\n\t     (n) = (&(pos)->node != NULL) ? rb_next(&(pos)->node) : NULL; \\\n\t     &(pos)->node != NULL; \\\n\t     (pos) = container_of(n, typeof(*(pos)), node), \\\n\t     (n) = (&(pos)->node != NULL) ? rb_next(&(pos)->node) : NULL)\n\n\n/*\n * We don't need locking around the persistent grant helpers\n * because blkback uses a single-thread for each backed, so we\n * can be sure that this functions will never be called recursively.\n *\n * The only exception to that is put_persistent_grant, that can be called\n * from interrupt context (by xen_blkbk_unmap), so we have to use atomic\n * bit operations to modify the flags of a persistent grant and to count\n * the number of used grants.\n */\nstatic int add_persistent_gnt(struct xen_blkif *blkif,\n\t\t\t       struct persistent_gnt *persistent_gnt)\n{\n\tstruct rb_node **new = NULL, *parent = NULL;\n\tstruct persistent_gnt *this;\n\n\tif (blkif->persistent_gnt_c >= xen_blkif_max_pgrants) {\n\t\tif (!blkif->vbd.overflow_max_grants)\n\t\t\tblkif->vbd.overflow_max_grants = 1;\n\t\treturn -EBUSY;\n\t}\n\t/* Figure out where to put new node */\n\tnew = &blkif->persistent_gnts.rb_node;\n\twhile (*new) {\n\t\tthis = container_of(*new, struct persistent_gnt, node);\n\n\t\tparent = *new;\n\t\tif (persistent_gnt->gnt < this->gnt)\n\t\t\tnew = &((*new)->rb_left);\n\t\telse if (persistent_gnt->gnt > this->gnt)\n\t\t\tnew = &((*new)->rb_right);\n\t\telse {\n\t\t\tpr_alert_ratelimited(DRV_PFX \" trying to add a gref that's already in the tree\\n\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\n\tbitmap_zero(persistent_gnt->flags, PERSISTENT_GNT_FLAGS_SIZE);\n\tset_bit(PERSISTENT_GNT_ACTIVE, persistent_gnt->flags);\n\t/* Add new node and rebalance tree. */\n\trb_link_node(&(persistent_gnt->node), parent, new);\n\trb_insert_color(&(persistent_gnt->node), &blkif->persistent_gnts);\n\tblkif->persistent_gnt_c++;\n\tatomic_inc(&blkif->persistent_gnt_in_use);\n\treturn 0;\n}\n\nstatic struct persistent_gnt *get_persistent_gnt(struct xen_blkif *blkif,\n\t\t\t\t\t\t grant_ref_t gref)\n{\n\tstruct persistent_gnt *data;\n\tstruct rb_node *node = NULL;\n\n\tnode = blkif->persistent_gnts.rb_node;\n\twhile (node) {\n\t\tdata = container_of(node, struct persistent_gnt, node);\n\n\t\tif (gref < data->gnt)\n\t\t\tnode = node->rb_left;\n\t\telse if (gref > data->gnt)\n\t\t\tnode = node->rb_right;\n\t\telse {\n\t\t\tif(test_bit(PERSISTENT_GNT_ACTIVE, data->flags)) {\n\t\t\t\tpr_alert_ratelimited(DRV_PFX \" requesting a grant already in use\\n\");\n\t\t\t\treturn NULL;\n\t\t\t}\n\t\t\tset_bit(PERSISTENT_GNT_ACTIVE, data->flags);\n\t\t\tatomic_inc(&blkif->persistent_gnt_in_use);\n\t\t\treturn data;\n\t\t}\n\t}\n\treturn NULL;\n}\n\nstatic void put_persistent_gnt(struct xen_blkif *blkif,\n                               struct persistent_gnt *persistent_gnt)\n{\n\tif(!test_bit(PERSISTENT_GNT_ACTIVE, persistent_gnt->flags))\n\t          pr_alert_ratelimited(DRV_PFX \" freeing a grant already unused\");\n\tset_bit(PERSISTENT_GNT_WAS_ACTIVE, persistent_gnt->flags);\n\tclear_bit(PERSISTENT_GNT_ACTIVE, persistent_gnt->flags);\n\tatomic_dec(&blkif->persistent_gnt_in_use);\n}\n\nstatic void free_persistent_gnts(struct xen_blkif *blkif, struct rb_root *root,\n                                 unsigned int num)\n{\n\tstruct gnttab_unmap_grant_ref unmap[BLKIF_MAX_SEGMENTS_PER_REQUEST];\n\tstruct page *pages[BLKIF_MAX_SEGMENTS_PER_REQUEST];\n\tstruct persistent_gnt *persistent_gnt;\n\tstruct rb_node *n;\n\tint ret = 0;\n\tint segs_to_unmap = 0;\n\n\tforeach_grant_safe(persistent_gnt, n, root, node) {\n\t\tBUG_ON(persistent_gnt->handle ==\n\t\t\tBLKBACK_INVALID_HANDLE);\n\t\tgnttab_set_unmap_op(&unmap[segs_to_unmap],\n\t\t\t(unsigned long) pfn_to_kaddr(page_to_pfn(\n\t\t\t\tpersistent_gnt->page)),\n\t\t\tGNTMAP_host_map,\n\t\t\tpersistent_gnt->handle);\n\n\t\tpages[segs_to_unmap] = persistent_gnt->page;\n\n\t\tif (++segs_to_unmap == BLKIF_MAX_SEGMENTS_PER_REQUEST ||\n\t\t\t!rb_next(&persistent_gnt->node)) {\n\t\t\tret = gnttab_unmap_refs(unmap, NULL, pages,\n\t\t\t\tsegs_to_unmap);\n\t\t\tBUG_ON(ret);\n\t\t\tput_free_pages(blkif, pages, segs_to_unmap);\n\t\t\tsegs_to_unmap = 0;\n\t\t}\n\n\t\trb_erase(&persistent_gnt->node, root);\n\t\tkfree(persistent_gnt);\n\t\tnum--;\n\t}\n\tBUG_ON(num != 0);\n}\n\nstatic void unmap_purged_grants(struct work_struct *work)\n{\n\tstruct gnttab_unmap_grant_ref unmap[BLKIF_MAX_SEGMENTS_PER_REQUEST];\n\tstruct page *pages[BLKIF_MAX_SEGMENTS_PER_REQUEST];\n\tstruct persistent_gnt *persistent_gnt;\n\tint ret, segs_to_unmap = 0;\n\tstruct xen_blkif *blkif = container_of(work, typeof(*blkif), persistent_purge_work);\n\n\twhile(!list_empty(&blkif->persistent_purge_list)) {\n\t\tpersistent_gnt = list_first_entry(&blkif->persistent_purge_list,\n\t\t                                  struct persistent_gnt,\n\t\t                                  remove_node);\n\t\tlist_del(&persistent_gnt->remove_node);\n\n\t\tgnttab_set_unmap_op(&unmap[segs_to_unmap],\n\t\t\tvaddr(persistent_gnt->page),\n\t\t\tGNTMAP_host_map,\n\t\t\tpersistent_gnt->handle);\n\n\t\tpages[segs_to_unmap] = persistent_gnt->page;\n\n\t\tif (++segs_to_unmap == BLKIF_MAX_SEGMENTS_PER_REQUEST) {\n\t\t\tret = gnttab_unmap_refs(unmap, NULL, pages,\n\t\t\t\tsegs_to_unmap);\n\t\t\tBUG_ON(ret);\n\t\t\tput_free_pages(blkif, pages, segs_to_unmap);\n\t\t\tsegs_to_unmap = 0;\n\t\t}\n\t\tkfree(persistent_gnt);\n\t}\n\tif (segs_to_unmap > 0) {\n\t\tret = gnttab_unmap_refs(unmap, NULL, pages, segs_to_unmap);\n\t\tBUG_ON(ret);\n\t\tput_free_pages(blkif, pages, segs_to_unmap);\n\t}\n}\n\nstatic void purge_persistent_gnt(struct xen_blkif *blkif)\n{\n\tstruct persistent_gnt *persistent_gnt;\n\tstruct rb_node *n;\n\tunsigned int num_clean, total;\n\tbool scan_used = false;\n\tstruct rb_root *root;\n\n\tif (blkif->persistent_gnt_c < xen_blkif_max_pgrants ||\n\t    (blkif->persistent_gnt_c == xen_blkif_max_pgrants &&\n\t    !blkif->vbd.overflow_max_grants)) {\n\t\treturn;\n\t}\n\n\tif (work_pending(&blkif->persistent_purge_work)) {\n\t\tpr_alert_ratelimited(DRV_PFX \"Scheduled work from previous purge is still pending, cannot purge list\\n\");\n\t\treturn;\n\t}\n\n\tnum_clean = (xen_blkif_max_pgrants / 100) * LRU_PERCENT_CLEAN;\n\tnum_clean = blkif->persistent_gnt_c - xen_blkif_max_pgrants + num_clean;\n\tnum_clean = min(blkif->persistent_gnt_c, num_clean);\n\tif (num_clean >\n\t    (blkif->persistent_gnt_c -\n\t    atomic_read(&blkif->persistent_gnt_in_use)))\n\t\treturn;\n\n\t/*\n\t * At this point, we can assure that there will be no calls\n         * to get_persistent_grant (because we are executing this code from\n         * xen_blkif_schedule), there can only be calls to put_persistent_gnt,\n         * which means that the number of currently used grants will go down,\n         * but never up, so we will always be able to remove the requested\n         * number of grants.\n\t */\n\n\ttotal = num_clean;\n\n\tpr_debug(DRV_PFX \"Going to purge %u persistent grants\\n\", num_clean);\n\n\tINIT_LIST_HEAD(&blkif->persistent_purge_list);\n\troot = &blkif->persistent_gnts;\npurge_list:\n\tforeach_grant_safe(persistent_gnt, n, root, node) {\n\t\tBUG_ON(persistent_gnt->handle ==\n\t\t\tBLKBACK_INVALID_HANDLE);\n\n\t\tif (test_bit(PERSISTENT_GNT_ACTIVE, persistent_gnt->flags))\n\t\t\tcontinue;\n\t\tif (!scan_used &&\n\t\t    (test_bit(PERSISTENT_GNT_WAS_ACTIVE, persistent_gnt->flags)))\n\t\t\tcontinue;\n\n\t\trb_erase(&persistent_gnt->node, root);\n\t\tlist_add(&persistent_gnt->remove_node,\n\t\t         &blkif->persistent_purge_list);\n\t\tif (--num_clean == 0)\n\t\t\tgoto finished;\n\t}\n\t/*\n\t * If we get here it means we also need to start cleaning\n\t * grants that were used since last purge in order to cope\n\t * with the requested num\n\t */\n\tif (!scan_used) {\n\t\tpr_debug(DRV_PFX \"Still missing %u purged frames\\n\", num_clean);\n\t\tscan_used = true;\n\t\tgoto purge_list;\n\t}\nfinished:\n\t/* Remove the \"used\" flag from all the persistent grants */\n\tforeach_grant_safe(persistent_gnt, n, root, node) {\n\t\tBUG_ON(persistent_gnt->handle ==\n\t\t\tBLKBACK_INVALID_HANDLE);\n\t\tclear_bit(PERSISTENT_GNT_WAS_ACTIVE, persistent_gnt->flags);\n\t}\n\tblkif->persistent_gnt_c -= (total - num_clean);\n\tblkif->vbd.overflow_max_grants = 0;\n\n\t/* We can defer this work */\n\tINIT_WORK(&blkif->persistent_purge_work, unmap_purged_grants);\n\tschedule_work(&blkif->persistent_purge_work);\n\tpr_debug(DRV_PFX \"Purged %u/%u\\n\", (total - num_clean), total);\n\treturn;\n}\n\n/*\n * Retrieve from the 'pending_reqs' a free pending_req structure to be used.\n */\nstatic struct pending_req *alloc_req(struct xen_blkif *blkif)\n{\n\tstruct pending_req *req = NULL;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&blkif->pending_free_lock, flags);\n\tif (!list_empty(&blkif->pending_free)) {\n\t\treq = list_entry(blkif->pending_free.next, struct pending_req,\n\t\t\t\t free_list);\n\t\tlist_del(&req->free_list);\n\t}\n\tspin_unlock_irqrestore(&blkif->pending_free_lock, flags);\n\treturn req;\n}\n\n/*\n * Return the 'pending_req' structure back to the freepool. We also\n * wake up the thread if it was waiting for a free page.\n */\nstatic void free_req(struct xen_blkif *blkif, struct pending_req *req)\n{\n\tunsigned long flags;\n\tint was_empty;\n\n\tspin_lock_irqsave(&blkif->pending_free_lock, flags);\n\twas_empty = list_empty(&blkif->pending_free);\n\tlist_add(&req->free_list, &blkif->pending_free);\n\tspin_unlock_irqrestore(&blkif->pending_free_lock, flags);\n\tif (was_empty)\n\t\twake_up(&blkif->pending_free_wq);\n}\n\n/*\n * Routines for managing virtual block devices (vbds).\n */\nstatic int xen_vbd_translate(struct phys_req *req, struct xen_blkif *blkif,\n\t\t\t     int operation)\n{\n\tstruct xen_vbd *vbd = &blkif->vbd;\n\tint rc = -EACCES;\n\n\tif ((operation != READ) && vbd->readonly)\n\t\tgoto out;\n\n\tif (likely(req->nr_sects)) {\n\t\tblkif_sector_t end = req->sector_number + req->nr_sects;\n\n\t\tif (unlikely(end < req->sector_number))\n\t\t\tgoto out;\n\t\tif (unlikely(end > vbd_sz(vbd)))\n\t\t\tgoto out;\n\t}\n\n\treq->dev  = vbd->pdevice;\n\treq->bdev = vbd->bdev;\n\trc = 0;\n\n out:\n\treturn rc;\n}\n\nstatic void xen_vbd_resize(struct xen_blkif *blkif)\n{\n\tstruct xen_vbd *vbd = &blkif->vbd;\n\tstruct xenbus_transaction xbt;\n\tint err;\n\tstruct xenbus_device *dev = xen_blkbk_xenbus(blkif->be);\n\tunsigned long long new_size = vbd_sz(vbd);\n\n\tpr_info(DRV_PFX \"VBD Resize: Domid: %d, Device: (%d, %d)\\n\",\n\t\tblkif->domid, MAJOR(vbd->pdevice), MINOR(vbd->pdevice));\n\tpr_info(DRV_PFX \"VBD Resize: new size %llu\\n\", new_size);\n\tvbd->size = new_size;\nagain:\n\terr = xenbus_transaction_start(&xbt);\n\tif (err) {\n\t\tpr_warn(DRV_PFX \"Error starting transaction\");\n\t\treturn;\n\t}\n\terr = xenbus_printf(xbt, dev->nodename, \"sectors\", \"%llu\",\n\t\t\t    (unsigned long long)vbd_sz(vbd));\n\tif (err) {\n\t\tpr_warn(DRV_PFX \"Error writing new size\");\n\t\tgoto abort;\n\t}\n\t/*\n\t * Write the current state; we will use this to synchronize\n\t * the front-end. If the current state is \"connected\" the\n\t * front-end will get the new size information online.\n\t */\n\terr = xenbus_printf(xbt, dev->nodename, \"state\", \"%d\", dev->state);\n\tif (err) {\n\t\tpr_warn(DRV_PFX \"Error writing the state\");\n\t\tgoto abort;\n\t}\n\n\terr = xenbus_transaction_end(xbt, 0);\n\tif (err == -EAGAIN)\n\t\tgoto again;\n\tif (err)\n\t\tpr_warn(DRV_PFX \"Error ending transaction\");\n\treturn;\nabort:\n\txenbus_transaction_end(xbt, 1);\n}\n\n/*\n * Notification from the guest OS.\n */\nstatic void blkif_notify_work(struct xen_blkif *blkif)\n{\n\tblkif->waiting_reqs = 1;\n\twake_up(&blkif->wq);\n}\n\nirqreturn_t xen_blkif_be_int(int irq, void *dev_id)\n{\n\tblkif_notify_work(dev_id);\n\treturn IRQ_HANDLED;\n}\n\n/*\n * SCHEDULER FUNCTIONS\n */\n\nstatic void print_stats(struct xen_blkif *blkif)\n{\n\tpr_info(\"xen-blkback (%s): oo %3llu  |  rd %4llu  |  wr %4llu  |  f %4llu\"\n\t\t \"  |  ds %4llu | pg: %4u/%4d\\n\",\n\t\t current->comm, blkif->st_oo_req,\n\t\t blkif->st_rd_req, blkif->st_wr_req,\n\t\t blkif->st_f_req, blkif->st_ds_req,\n\t\t blkif->persistent_gnt_c,\n\t\t xen_blkif_max_pgrants);\n\tblkif->st_print = jiffies + msecs_to_jiffies(10 * 1000);\n\tblkif->st_rd_req = 0;\n\tblkif->st_wr_req = 0;\n\tblkif->st_oo_req = 0;\n\tblkif->st_ds_req = 0;\n}\n\nint xen_blkif_schedule(void *arg)\n{\n\tstruct xen_blkif *blkif = arg;\n\tstruct xen_vbd *vbd = &blkif->vbd;\n\tunsigned long timeout;\n\n\txen_blkif_get(blkif);\n\n\twhile (!kthread_should_stop()) {\n\t\tif (try_to_freeze())\n\t\t\tcontinue;\n\t\tif (unlikely(vbd->size != vbd_sz(vbd)))\n\t\t\txen_vbd_resize(blkif);\n\n\t\ttimeout = msecs_to_jiffies(LRU_INTERVAL);\n\n\t\ttimeout = wait_event_interruptible_timeout(\n\t\t\tblkif->wq,\n\t\t\tblkif->waiting_reqs || kthread_should_stop(),\n\t\t\ttimeout);\n\t\tif (timeout == 0)\n\t\t\tgoto purge_gnt_list;\n\t\ttimeout = wait_event_interruptible_timeout(\n\t\t\tblkif->pending_free_wq,\n\t\t\t!list_empty(&blkif->pending_free) ||\n\t\t\tkthread_should_stop(),\n\t\t\ttimeout);\n\t\tif (timeout == 0)\n\t\t\tgoto purge_gnt_list;\n\n\t\tblkif->waiting_reqs = 0;\n\t\tsmp_mb(); /* clear flag *before* checking for work */\n\n\t\tif (do_block_io_op(blkif))\n\t\t\tblkif->waiting_reqs = 1;\n\npurge_gnt_list:\n\t\tif (blkif->vbd.feature_gnt_persistent &&\n\t\t    time_after(jiffies, blkif->next_lru)) {\n\t\t\tpurge_persistent_gnt(blkif);\n\t\t\tblkif->next_lru = jiffies + msecs_to_jiffies(LRU_INTERVAL);\n\t\t}\n\n\t\t/* Shrink if we have more than xen_blkif_max_buffer_pages */\n\t\tshrink_free_pagepool(blkif, xen_blkif_max_buffer_pages);\n\n\t\tif (log_stats && time_after(jiffies, blkif->st_print))\n\t\t\tprint_stats(blkif);\n\t}\n\n\t/* Since we are shutting down remove all pages from the buffer */\n\tshrink_free_pagepool(blkif, 0 /* All */);\n\n\t/* Free all persistent grant pages */\n\tif (!RB_EMPTY_ROOT(&blkif->persistent_gnts))\n\t\tfree_persistent_gnts(blkif, &blkif->persistent_gnts,\n\t\t\tblkif->persistent_gnt_c);\n\n\tBUG_ON(!RB_EMPTY_ROOT(&blkif->persistent_gnts));\n\tblkif->persistent_gnt_c = 0;\n\n\tif (log_stats)\n\t\tprint_stats(blkif);\n\n\tblkif->xenblkd = NULL;\n\txen_blkif_put(blkif);\n\n\treturn 0;\n}\n\n/*\n * Unmap the grant references, and also remove the M2P over-rides\n * used in the 'pending_req'.\n */\nstatic void xen_blkbk_unmap(struct xen_blkif *blkif,\n                            struct grant_page *pages[],\n                            int num)\n{\n\tstruct gnttab_unmap_grant_ref unmap[BLKIF_MAX_SEGMENTS_PER_REQUEST];\n\tstruct page *unmap_pages[BLKIF_MAX_SEGMENTS_PER_REQUEST];\n\tunsigned int i, invcount = 0;\n\tint ret;\n\n\tfor (i = 0; i < num; i++) {\n\t\tif (pages[i]->persistent_gnt != NULL) {\n\t\t\tput_persistent_gnt(blkif, pages[i]->persistent_gnt);\n\t\t\tcontinue;\n\t\t}\n\t\tif (pages[i]->handle == BLKBACK_INVALID_HANDLE)\n\t\t\tcontinue;\n\t\tunmap_pages[invcount] = pages[i]->page;\n\t\tgnttab_set_unmap_op(&unmap[invcount], vaddr(pages[i]->page),\n\t\t\t\t    GNTMAP_host_map, pages[i]->handle);\n\t\tpages[i]->handle = BLKBACK_INVALID_HANDLE;\n\t\tif (++invcount == BLKIF_MAX_SEGMENTS_PER_REQUEST) {\n\t\t\tret = gnttab_unmap_refs(unmap, NULL, unmap_pages,\n\t\t\t                        invcount);\n\t\t\tBUG_ON(ret);\n\t\t\tput_free_pages(blkif, unmap_pages, invcount);\n\t\t\tinvcount = 0;\n\t\t}\n\t}\n\tif (invcount) {\n\t\tret = gnttab_unmap_refs(unmap, NULL, unmap_pages, invcount);\n\t\tBUG_ON(ret);\n\t\tput_free_pages(blkif, unmap_pages, invcount);\n\t}\n}\n\nstatic int xen_blkbk_map(struct xen_blkif *blkif,\n\t\t\t struct grant_page *pages[],\n\t\t\t int num, bool ro)\n{\n\tstruct gnttab_map_grant_ref map[BLKIF_MAX_SEGMENTS_PER_REQUEST];\n\tstruct page *pages_to_gnt[BLKIF_MAX_SEGMENTS_PER_REQUEST];\n\tstruct persistent_gnt *persistent_gnt = NULL;\n\tphys_addr_t addr = 0;\n\tint i, seg_idx, new_map_idx;\n\tint segs_to_map = 0;\n\tint ret = 0;\n\tint last_map = 0, map_until = 0;\n\tint use_persistent_gnts;\n\n\tuse_persistent_gnts = (blkif->vbd.feature_gnt_persistent);\n\n\t/*\n\t * Fill out preq.nr_sects with proper amount of sectors, and setup\n\t * assign map[..] with the PFN of the page in our domain with the\n\t * corresponding grant reference for each page.\n\t */\nagain:\n\tfor (i = map_until; i < num; i++) {\n\t\tuint32_t flags;\n\n\t\tif (use_persistent_gnts)\n\t\t\tpersistent_gnt = get_persistent_gnt(\n\t\t\t\tblkif,\n\t\t\t\tpages[i]->gref);\n\n\t\tif (persistent_gnt) {\n\t\t\t/*\n\t\t\t * We are using persistent grants and\n\t\t\t * the grant is already mapped\n\t\t\t */\n\t\t\tpages[i]->page = persistent_gnt->page;\n\t\t\tpages[i]->persistent_gnt = persistent_gnt;\n\t\t} else {\n\t\t\tif (get_free_page(blkif, &pages[i]->page))\n\t\t\t\tgoto out_of_memory;\n\t\t\taddr = vaddr(pages[i]->page);\n\t\t\tpages_to_gnt[segs_to_map] = pages[i]->page;\n\t\t\tpages[i]->persistent_gnt = NULL;\n\t\t\tflags = GNTMAP_host_map;\n\t\t\tif (!use_persistent_gnts && ro)\n\t\t\t\tflags |= GNTMAP_readonly;\n\t\t\tgnttab_set_map_op(&map[segs_to_map++], addr,\n\t\t\t\t\t  flags, pages[i]->gref,\n\t\t\t\t\t  blkif->domid);\n\t\t}\n\t\tmap_until = i + 1;\n\t\tif (segs_to_map == BLKIF_MAX_SEGMENTS_PER_REQUEST)\n\t\t\tbreak;\n\t}\n\n\tif (segs_to_map) {\n\t\tret = gnttab_map_refs(map, NULL, pages_to_gnt, segs_to_map);\n\t\tBUG_ON(ret);\n\t}\n\n\t/*\n\t * Now swizzle the MFN in our domain with the MFN from the other domain\n\t * so that when we access vaddr(pending_req,i) it has the contents of\n\t * the page from the other domain.\n\t */\n\tfor (seg_idx = last_map, new_map_idx = 0; seg_idx < map_until; seg_idx++) {\n\t\tif (!pages[seg_idx]->persistent_gnt) {\n\t\t\t/* This is a newly mapped grant */\n\t\t\tBUG_ON(new_map_idx >= segs_to_map);\n\t\t\tif (unlikely(map[new_map_idx].status != 0)) {\n\t\t\t\tpr_debug(DRV_PFX \"invalid buffer -- could not remap it\\n\");\n\t\t\t\tpages[seg_idx]->handle = BLKBACK_INVALID_HANDLE;\n\t\t\t\tret |= 1;\n\t\t\t\tgoto next;\n\t\t\t}\n\t\t\tpages[seg_idx]->handle = map[new_map_idx].handle;\n\t\t} else {\n\t\t\tcontinue;\n\t\t}\n\t\tif (use_persistent_gnts &&\n\t\t    blkif->persistent_gnt_c < xen_blkif_max_pgrants) {\n\t\t\t/*\n\t\t\t * We are using persistent grants, the grant is\n\t\t\t * not mapped but we might have room for it.\n\t\t\t */\n\t\t\tpersistent_gnt = kmalloc(sizeof(struct persistent_gnt),\n\t\t\t\t                 GFP_KERNEL);\n\t\t\tif (!persistent_gnt) {\n\t\t\t\t/*\n\t\t\t\t * If we don't have enough memory to\n\t\t\t\t * allocate the persistent_gnt struct\n\t\t\t\t * map this grant non-persistenly\n\t\t\t\t */\n\t\t\t\tgoto next;\n\t\t\t}\n\t\t\tpersistent_gnt->gnt = map[new_map_idx].ref;\n\t\t\tpersistent_gnt->handle = map[new_map_idx].handle;\n\t\t\tpersistent_gnt->page = pages[seg_idx]->page;\n\t\t\tif (add_persistent_gnt(blkif,\n\t\t\t                       persistent_gnt)) {\n\t\t\t\tkfree(persistent_gnt);\n\t\t\t\tpersistent_gnt = NULL;\n\t\t\t\tgoto next;\n\t\t\t}\n\t\t\tpages[seg_idx]->persistent_gnt = persistent_gnt;\n\t\t\tpr_debug(DRV_PFX \" grant %u added to the tree of persistent grants, using %u/%u\\n\",\n\t\t\t\t persistent_gnt->gnt, blkif->persistent_gnt_c,\n\t\t\t\t xen_blkif_max_pgrants);\n\t\t\tgoto next;\n\t\t}\n\t\tif (use_persistent_gnts && !blkif->vbd.overflow_max_grants) {\n\t\t\tblkif->vbd.overflow_max_grants = 1;\n\t\t\tpr_debug(DRV_PFX \" domain %u, device %#x is using maximum number of persistent grants\\n\",\n\t\t\t         blkif->domid, blkif->vbd.handle);\n\t\t}\n\t\t/*\n\t\t * We could not map this grant persistently, so use it as\n\t\t * a non-persistent grant.\n\t\t */\nnext:\n\t\tnew_map_idx++;\n\t}\n\tsegs_to_map = 0;\n\tlast_map = map_until;\n\tif (map_until != num)\n\t\tgoto again;\n\n\treturn ret;\n\nout_of_memory:\n\tpr_alert(DRV_PFX \"%s: out of memory\\n\", __func__);\n\tput_free_pages(blkif, pages_to_gnt, segs_to_map);\n\treturn -ENOMEM;\n}\n\nstatic int xen_blkbk_map_seg(struct pending_req *pending_req)\n{\n\tint rc;\n\n\trc = xen_blkbk_map(pending_req->blkif, pending_req->segments,\n\t\t\t   pending_req->nr_pages,\n\t                   (pending_req->operation != BLKIF_OP_READ));\n\n\treturn rc;\n}\n\nstatic int xen_blkbk_parse_indirect(struct blkif_request *req,\n\t\t\t\t    struct pending_req *pending_req,\n\t\t\t\t    struct seg_buf seg[],\n\t\t\t\t    struct phys_req *preq)\n{\n\tstruct grant_page **pages = pending_req->indirect_pages;\n\tstruct xen_blkif *blkif = pending_req->blkif;\n\tint indirect_grefs, rc, n, nseg, i;\n\tstruct blkif_request_segment_aligned *segments = NULL;\n\n\tnseg = pending_req->nr_pages;\n\tindirect_grefs = INDIRECT_PAGES(nseg);\n\tBUG_ON(indirect_grefs > BLKIF_MAX_INDIRECT_PAGES_PER_REQUEST);\n\n\tfor (i = 0; i < indirect_grefs; i++)\n\t\tpages[i]->gref = req->u.indirect.indirect_grefs[i];\n\n\trc = xen_blkbk_map(blkif, pages, indirect_grefs, true);\n\tif (rc)\n\t\tgoto unmap;\n\n\tfor (n = 0, i = 0; n < nseg; n++) {\n\t\tif ((n % SEGS_PER_INDIRECT_FRAME) == 0) {\n\t\t\t/* Map indirect segments */\n\t\t\tif (segments)\n\t\t\t\tkunmap_atomic(segments);\n\t\t\tsegments = kmap_atomic(pages[n/SEGS_PER_INDIRECT_FRAME]->page);\n\t\t}\n\t\ti = n % SEGS_PER_INDIRECT_FRAME;\n\t\tpending_req->segments[n]->gref = segments[i].gref;\n\t\tseg[n].nsec = segments[i].last_sect -\n\t\t\tsegments[i].first_sect + 1;\n\t\tseg[n].offset = (segments[i].first_sect << 9);\n\t\tif ((segments[i].last_sect >= (PAGE_SIZE >> 9)) ||\n\t\t    (segments[i].last_sect < segments[i].first_sect)) {\n\t\t\trc = -EINVAL;\n\t\t\tgoto unmap;\n\t\t}\n\t\tpreq->nr_sects += seg[n].nsec;\n\t}\n\nunmap:\n\tif (segments)\n\t\tkunmap_atomic(segments);\n\txen_blkbk_unmap(blkif, pages, indirect_grefs);\n\treturn rc;\n}\n\nstatic int dispatch_discard_io(struct xen_blkif *blkif,\n\t\t\t\tstruct blkif_request *req)\n{\n\tint err = 0;\n\tint status = BLKIF_RSP_OKAY;\n\tstruct block_device *bdev = blkif->vbd.bdev;\n\tunsigned long secure;\n\n\tblkif->st_ds_req++;\n\n\txen_blkif_get(blkif);\n\tsecure = (blkif->vbd.discard_secure &&\n\t\t (req->u.discard.flag & BLKIF_DISCARD_SECURE)) ?\n\t\t BLKDEV_DISCARD_SECURE : 0;\n\n\terr = blkdev_issue_discard(bdev, req->u.discard.sector_number,\n\t\t\t\t   req->u.discard.nr_sectors,\n\t\t\t\t   GFP_KERNEL, secure);\n\n\tif (err == -EOPNOTSUPP) {\n\t\tpr_debug(DRV_PFX \"discard op failed, not supported\\n\");\n\t\tstatus = BLKIF_RSP_EOPNOTSUPP;\n\t} else if (err)\n\t\tstatus = BLKIF_RSP_ERROR;\n\n\tmake_response(blkif, req->u.discard.id, req->operation, status);\n\txen_blkif_put(blkif);\n\treturn err;\n}\n\nstatic int dispatch_other_io(struct xen_blkif *blkif,\n\t\t\t     struct blkif_request *req,\n\t\t\t     struct pending_req *pending_req)\n{\n\tfree_req(blkif, pending_req);\n\tmake_response(blkif, req->u.other.id, req->operation,\n\t\t      BLKIF_RSP_EOPNOTSUPP);\n\treturn -EIO;\n}\n\nstatic void xen_blk_drain_io(struct xen_blkif *blkif)\n{\n\tatomic_set(&blkif->drain, 1);\n\tdo {\n\t\t/* The initial value is one, and one refcnt taken at the\n\t\t * start of the xen_blkif_schedule thread. */\n\t\tif (atomic_read(&blkif->refcnt) <= 2)\n\t\t\tbreak;\n\t\twait_for_completion_interruptible_timeout(\n\t\t\t\t&blkif->drain_complete, HZ);\n\n\t\tif (!atomic_read(&blkif->drain))\n\t\t\tbreak;\n\t} while (!kthread_should_stop());\n\tatomic_set(&blkif->drain, 0);\n}\n\n/*\n * Completion callback on the bio's. Called as bh->b_end_io()\n */\n\nstatic void __end_block_io_op(struct pending_req *pending_req, int error)\n{\n\t/* An error fails the entire request. */\n\tif ((pending_req->operation == BLKIF_OP_FLUSH_DISKCACHE) &&\n\t    (error == -EOPNOTSUPP)) {\n\t\tpr_debug(DRV_PFX \"flush diskcache op failed, not supported\\n\");\n\t\txen_blkbk_flush_diskcache(XBT_NIL, pending_req->blkif->be, 0);\n\t\tpending_req->status = BLKIF_RSP_EOPNOTSUPP;\n\t} else if ((pending_req->operation == BLKIF_OP_WRITE_BARRIER) &&\n\t\t    (error == -EOPNOTSUPP)) {\n\t\tpr_debug(DRV_PFX \"write barrier op failed, not supported\\n\");\n\t\txen_blkbk_barrier(XBT_NIL, pending_req->blkif->be, 0);\n\t\tpending_req->status = BLKIF_RSP_EOPNOTSUPP;\n\t} else if (error) {\n\t\tpr_debug(DRV_PFX \"Buffer not up-to-date at end of operation,\"\n\t\t\t \" error=%d\\n\", error);\n\t\tpending_req->status = BLKIF_RSP_ERROR;\n\t}\n\n\t/*\n\t * If all of the bio's have completed it is time to unmap\n\t * the grant references associated with 'request' and provide\n\t * the proper response on the ring.\n\t */\n\tif (atomic_dec_and_test(&pending_req->pendcnt)) {\n\t\txen_blkbk_unmap(pending_req->blkif,\n\t\t                pending_req->segments,\n\t\t                pending_req->nr_pages);\n\t\tmake_response(pending_req->blkif, pending_req->id,\n\t\t\t      pending_req->operation, pending_req->status);\n\t\txen_blkif_put(pending_req->blkif);\n\t\tif (atomic_read(&pending_req->blkif->refcnt) <= 2) {\n\t\t\tif (atomic_read(&pending_req->blkif->drain))\n\t\t\t\tcomplete(&pending_req->blkif->drain_complete);\n\t\t}\n\t\tfree_req(pending_req->blkif, pending_req);\n\t}\n}\n\n/*\n * bio callback.\n */\nstatic void end_block_io_op(struct bio *bio, int error)\n{\n\t__end_block_io_op(bio->bi_private, error);\n\tbio_put(bio);\n}\n\n\n\n/*\n * Function to copy the from the ring buffer the 'struct blkif_request'\n * (which has the sectors we want, number of them, grant references, etc),\n * and transmute  it to the block API to hand it over to the proper block disk.\n */\nstatic int\n__do_block_io_op(struct xen_blkif *blkif)\n{\n\tunion blkif_back_rings *blk_rings = &blkif->blk_rings;\n\tstruct blkif_request req;\n\tstruct pending_req *pending_req;\n\tRING_IDX rc, rp;\n\tint more_to_do = 0;\n\n\trc = blk_rings->common.req_cons;\n\trp = blk_rings->common.sring->req_prod;\n\trmb(); /* Ensure we see queued requests up to 'rp'. */\n\n\twhile (rc != rp) {\n\n\t\tif (RING_REQUEST_CONS_OVERFLOW(&blk_rings->common, rc))\n\t\t\tbreak;\n\n\t\tif (kthread_should_stop()) {\n\t\t\tmore_to_do = 1;\n\t\t\tbreak;\n\t\t}\n\n\t\tpending_req = alloc_req(blkif);\n\t\tif (NULL == pending_req) {\n\t\t\tblkif->st_oo_req++;\n\t\t\tmore_to_do = 1;\n\t\t\tbreak;\n\t\t}\n\n\t\tswitch (blkif->blk_protocol) {\n\t\tcase BLKIF_PROTOCOL_NATIVE:\n\t\t\tmemcpy(&req, RING_GET_REQUEST(&blk_rings->native, rc), sizeof(req));\n\t\t\tbreak;\n\t\tcase BLKIF_PROTOCOL_X86_32:\n\t\t\tblkif_get_x86_32_req(&req, RING_GET_REQUEST(&blk_rings->x86_32, rc));\n\t\t\tbreak;\n\t\tcase BLKIF_PROTOCOL_X86_64:\n\t\t\tblkif_get_x86_64_req(&req, RING_GET_REQUEST(&blk_rings->x86_64, rc));\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tBUG();\n\t\t}\n\t\tblk_rings->common.req_cons = ++rc; /* before make_response() */\n\n\t\t/* Apply all sanity checks to /private copy/ of request. */\n\t\tbarrier();\n\n\t\tswitch (req.operation) {\n\t\tcase BLKIF_OP_READ:\n\t\tcase BLKIF_OP_WRITE:\n\t\tcase BLKIF_OP_WRITE_BARRIER:\n\t\tcase BLKIF_OP_FLUSH_DISKCACHE:\n\t\tcase BLKIF_OP_INDIRECT:\n\t\t\tif (dispatch_rw_block_io(blkif, &req, pending_req))\n\t\t\t\tgoto done;\n\t\t\tbreak;\n\t\tcase BLKIF_OP_DISCARD:\n\t\t\tfree_req(blkif, pending_req);\n\t\t\tif (dispatch_discard_io(blkif, &req))\n\t\t\t\tgoto done;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tif (dispatch_other_io(blkif, &req, pending_req))\n\t\t\t\tgoto done;\n\t\t\tbreak;\n\t\t}\n\n\t\t/* Yield point for this unbounded loop. */\n\t\tcond_resched();\n\t}\ndone:\n\treturn more_to_do;\n}\n\nstatic int\ndo_block_io_op(struct xen_blkif *blkif)\n{\n\tunion blkif_back_rings *blk_rings = &blkif->blk_rings;\n\tint more_to_do;\n\n\tdo {\n\t\tmore_to_do = __do_block_io_op(blkif);\n\t\tif (more_to_do)\n\t\t\tbreak;\n\n\t\tRING_FINAL_CHECK_FOR_REQUESTS(&blk_rings->common, more_to_do);\n\t} while (more_to_do);\n\n\treturn more_to_do;\n}\n/*\n * Transmutation of the 'struct blkif_request' to a proper 'struct bio'\n * and call the 'submit_bio' to pass it to the underlying storage.\n */\nstatic int dispatch_rw_block_io(struct xen_blkif *blkif,\n\t\t\t\tstruct blkif_request *req,\n\t\t\t\tstruct pending_req *pending_req)\n{\n\tstruct phys_req preq;\n\tstruct seg_buf *seg = pending_req->seg;\n\tunsigned int nseg;\n\tstruct bio *bio = NULL;\n\tstruct bio **biolist = pending_req->biolist;\n\tint i, nbio = 0;\n\tint operation;\n\tstruct blk_plug plug;\n\tbool drain = false;\n\tstruct grant_page **pages = pending_req->segments;\n\tunsigned short req_operation;\n\n\treq_operation = req->operation == BLKIF_OP_INDIRECT ?\n\t\t\treq->u.indirect.indirect_op : req->operation;\n\tif ((req->operation == BLKIF_OP_INDIRECT) &&\n\t    (req_operation != BLKIF_OP_READ) &&\n\t    (req_operation != BLKIF_OP_WRITE)) {\n\t\tpr_debug(DRV_PFX \"Invalid indirect operation (%u)\\n\",\n\t\t\t req_operation);\n\t\tgoto fail_response;\n\t}\n\n\tswitch (req_operation) {\n\tcase BLKIF_OP_READ:\n\t\tblkif->st_rd_req++;\n\t\toperation = READ;\n\t\tbreak;\n\tcase BLKIF_OP_WRITE:\n\t\tblkif->st_wr_req++;\n\t\toperation = WRITE_ODIRECT;\n\t\tbreak;\n\tcase BLKIF_OP_WRITE_BARRIER:\n\t\tdrain = true;\n\tcase BLKIF_OP_FLUSH_DISKCACHE:\n\t\tblkif->st_f_req++;\n\t\toperation = WRITE_FLUSH;\n\t\tbreak;\n\tdefault:\n\t\toperation = 0; /* make gcc happy */\n\t\tgoto fail_response;\n\t\tbreak;\n\t}\n\n\t/* Check that the number of segments is sane. */\n\tnseg = req->operation == BLKIF_OP_INDIRECT ?\n\t       req->u.indirect.nr_segments : req->u.rw.nr_segments;\n\n\tif (unlikely(nseg == 0 && operation != WRITE_FLUSH) ||\n\t    unlikely((req->operation != BLKIF_OP_INDIRECT) &&\n\t\t     (nseg > BLKIF_MAX_SEGMENTS_PER_REQUEST)) ||\n\t    unlikely((req->operation == BLKIF_OP_INDIRECT) &&\n\t\t     (nseg > MAX_INDIRECT_SEGMENTS))) {\n\t\tpr_debug(DRV_PFX \"Bad number of segments in request (%d)\\n\",\n\t\t\t nseg);\n\t\t/* Haven't submitted any bio's yet. */\n\t\tgoto fail_response;\n\t}\n\n\tpreq.nr_sects      = 0;\n\n\tpending_req->blkif     = blkif;\n\tpending_req->id        = req->u.rw.id;\n\tpending_req->operation = req_operation;\n\tpending_req->status    = BLKIF_RSP_OKAY;\n\tpending_req->nr_pages  = nseg;\n\n\tif (req->operation != BLKIF_OP_INDIRECT) {\n\t\tpreq.dev               = req->u.rw.handle;\n\t\tpreq.sector_number     = req->u.rw.sector_number;\n\t\tfor (i = 0; i < nseg; i++) {\n\t\t\tpages[i]->gref = req->u.rw.seg[i].gref;\n\t\t\tseg[i].nsec = req->u.rw.seg[i].last_sect -\n\t\t\t\treq->u.rw.seg[i].first_sect + 1;\n\t\t\tseg[i].offset = (req->u.rw.seg[i].first_sect << 9);\n\t\t\tif ((req->u.rw.seg[i].last_sect >= (PAGE_SIZE >> 9)) ||\n\t\t\t    (req->u.rw.seg[i].last_sect <\n\t\t\t     req->u.rw.seg[i].first_sect))\n\t\t\t\tgoto fail_response;\n\t\t\tpreq.nr_sects += seg[i].nsec;\n\t\t}\n\t} else {\n\t\tpreq.dev               = req->u.indirect.handle;\n\t\tpreq.sector_number     = req->u.indirect.sector_number;\n\t\tif (xen_blkbk_parse_indirect(req, pending_req, seg, &preq))\n\t\t\tgoto fail_response;\n\t}\n\n\tif (xen_vbd_translate(&preq, blkif, operation) != 0) {\n\t\tpr_debug(DRV_PFX \"access denied: %s of [%llu,%llu] on dev=%04x\\n\",\n\t\t\t operation == READ ? \"read\" : \"write\",\n\t\t\t preq.sector_number,\n\t\t\t preq.sector_number + preq.nr_sects,\n\t\t\t blkif->vbd.pdevice);\n\t\tgoto fail_response;\n\t}\n\n\t/*\n\t * This check _MUST_ be done after xen_vbd_translate as the preq.bdev\n\t * is set there.\n\t */\n\tfor (i = 0; i < nseg; i++) {\n\t\tif (((int)preq.sector_number|(int)seg[i].nsec) &\n\t\t    ((bdev_logical_block_size(preq.bdev) >> 9) - 1)) {\n\t\t\tpr_debug(DRV_PFX \"Misaligned I/O request from domain %d\",\n\t\t\t\t blkif->domid);\n\t\t\tgoto fail_response;\n\t\t}\n\t}\n\n\t/* Wait on all outstanding I/O's and once that has been completed\n\t * issue the WRITE_FLUSH.\n\t */\n\tif (drain)\n\t\txen_blk_drain_io(pending_req->blkif);\n\n\t/*\n\t * If we have failed at this point, we need to undo the M2P override,\n\t * set gnttab_set_unmap_op on all of the grant references and perform\n\t * the hypercall to unmap the grants - that is all done in\n\t * xen_blkbk_unmap.\n\t */\n\tif (xen_blkbk_map_seg(pending_req))\n\t\tgoto fail_flush;\n\n\t/*\n\t * This corresponding xen_blkif_put is done in __end_block_io_op, or\n\t * below (in \"!bio\") if we are handling a BLKIF_OP_DISCARD.\n\t */\n\txen_blkif_get(blkif);\n\n\tfor (i = 0; i < nseg; i++) {\n\t\twhile ((bio == NULL) ||\n\t\t       (bio_add_page(bio,\n\t\t\t\t     pages[i]->page,\n\t\t\t\t     seg[i].nsec << 9,\n\t\t\t\t     seg[i].offset) == 0)) {\n\n\t\t\tbio = bio_alloc(GFP_KERNEL, nseg-i);\n\t\t\tif (unlikely(bio == NULL))\n\t\t\t\tgoto fail_put_bio;\n\n\t\t\tbiolist[nbio++] = bio;\n\t\t\tbio->bi_bdev    = preq.bdev;\n\t\t\tbio->bi_private = pending_req;\n\t\t\tbio->bi_end_io  = end_block_io_op;\n\t\t\tbio->bi_sector  = preq.sector_number;\n\t\t}\n\n\t\tpreq.sector_number += seg[i].nsec;\n\t}\n\n\t/* This will be hit if the operation was a flush or discard. */\n\tif (!bio) {\n\t\tBUG_ON(operation != WRITE_FLUSH);\n\n\t\tbio = bio_alloc(GFP_KERNEL, 0);\n\t\tif (unlikely(bio == NULL))\n\t\t\tgoto fail_put_bio;\n\n\t\tbiolist[nbio++] = bio;\n\t\tbio->bi_bdev    = preq.bdev;\n\t\tbio->bi_private = pending_req;\n\t\tbio->bi_end_io  = end_block_io_op;\n\t}\n\n\tatomic_set(&pending_req->pendcnt, nbio);\n\tblk_start_plug(&plug);\n\n\tfor (i = 0; i < nbio; i++)\n\t\tsubmit_bio(operation, biolist[i]);\n\n\t/* Let the I/Os go.. */\n\tblk_finish_plug(&plug);\n\n\tif (operation == READ)\n\t\tblkif->st_rd_sect += preq.nr_sects;\n\telse if (operation & WRITE)\n\t\tblkif->st_wr_sect += preq.nr_sects;\n\n\treturn 0;\n\n fail_flush:\n\txen_blkbk_unmap(blkif, pending_req->segments,\n\t                pending_req->nr_pages);\n fail_response:\n\t/* Haven't submitted any bio's yet. */\n\tmake_response(blkif, req->u.rw.id, req_operation, BLKIF_RSP_ERROR);\n\tfree_req(blkif, pending_req);\n\tmsleep(1); /* back off a bit */\n\treturn -EIO;\n\n fail_put_bio:\n\tfor (i = 0; i < nbio; i++)\n\t\tbio_put(biolist[i]);\n\tatomic_set(&pending_req->pendcnt, 1);\n\t__end_block_io_op(pending_req, -EINVAL);\n\tmsleep(1); /* back off a bit */\n\treturn -EIO;\n}\n\n\n\n/*\n * Put a response on the ring on how the operation fared.\n */\nstatic void make_response(struct xen_blkif *blkif, u64 id,\n\t\t\t  unsigned short op, int st)\n{\n\tstruct blkif_response  resp;\n\tunsigned long     flags;\n\tunion blkif_back_rings *blk_rings = &blkif->blk_rings;\n\tint notify;\n\n\tresp.id        = id;\n\tresp.operation = op;\n\tresp.status    = st;\n\n\tspin_lock_irqsave(&blkif->blk_ring_lock, flags);\n\t/* Place on the response ring for the relevant domain. */\n\tswitch (blkif->blk_protocol) {\n\tcase BLKIF_PROTOCOL_NATIVE:\n\t\tmemcpy(RING_GET_RESPONSE(&blk_rings->native, blk_rings->native.rsp_prod_pvt),\n\t\t       &resp, sizeof(resp));\n\t\tbreak;\n\tcase BLKIF_PROTOCOL_X86_32:\n\t\tmemcpy(RING_GET_RESPONSE(&blk_rings->x86_32, blk_rings->x86_32.rsp_prod_pvt),\n\t\t       &resp, sizeof(resp));\n\t\tbreak;\n\tcase BLKIF_PROTOCOL_X86_64:\n\t\tmemcpy(RING_GET_RESPONSE(&blk_rings->x86_64, blk_rings->x86_64.rsp_prod_pvt),\n\t\t       &resp, sizeof(resp));\n\t\tbreak;\n\tdefault:\n\t\tBUG();\n\t}\n\tblk_rings->common.rsp_prod_pvt++;\n\tRING_PUSH_RESPONSES_AND_CHECK_NOTIFY(&blk_rings->common, notify);\n\tspin_unlock_irqrestore(&blkif->blk_ring_lock, flags);\n\tif (notify)\n\t\tnotify_remote_via_irq(blkif->irq);\n}\n\nstatic int __init xen_blkif_init(void)\n{\n\tint rc = 0;\n\n\tif (!xen_domain())\n\t\treturn -ENODEV;\n\n\trc = xen_blkif_interface_init();\n\tif (rc)\n\t\tgoto failed_init;\n\n\trc = xen_blkif_xenbus_init();\n\tif (rc)\n\t\tgoto failed_init;\n\n failed_init:\n\treturn rc;\n}\n\nmodule_init(xen_blkif_init);\n\nMODULE_LICENSE(\"Dual BSD/GPL\");\nMODULE_ALIAS(\"xen-backend:vbd\");\n"], "fixing_code": ["/******************************************************************************\n *\n * Back-end of the driver for virtual block devices. This portion of the\n * driver exports a 'unified' block-device interface that can be accessed\n * by any operating system that implements a compatible front end. A\n * reference front-end implementation can be found in:\n *  drivers/block/xen-blkfront.c\n *\n * Copyright (c) 2003-2004, Keir Fraser & Steve Hand\n * Copyright (c) 2005, Christopher Clark\n *\n * This program is free software; you can redistribute it and/or\n * modify it under the terms of the GNU General Public License version 2\n * as published by the Free Software Foundation; or, when distributed\n * separately from the Linux kernel or incorporated into other\n * software packages, subject to the following license:\n *\n * Permission is hereby granted, free of charge, to any person obtaining a copy\n * of this source file (the \"Software\"), to deal in the Software without\n * restriction, including without limitation the rights to use, copy, modify,\n * merge, publish, distribute, sublicense, and/or sell copies of the Software,\n * and to permit persons to whom the Software is furnished to do so, subject to\n * the following conditions:\n *\n * The above copyright notice and this permission notice shall be included in\n * all copies or substantial portions of the Software.\n *\n * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n * IN THE SOFTWARE.\n */\n\n#include <linux/spinlock.h>\n#include <linux/kthread.h>\n#include <linux/list.h>\n#include <linux/delay.h>\n#include <linux/freezer.h>\n#include <linux/bitmap.h>\n\n#include <xen/events.h>\n#include <xen/page.h>\n#include <xen/xen.h>\n#include <asm/xen/hypervisor.h>\n#include <asm/xen/hypercall.h>\n#include <xen/balloon.h>\n#include \"common.h\"\n\n/*\n * Maximum number of unused free pages to keep in the internal buffer.\n * Setting this to a value too low will reduce memory used in each backend,\n * but can have a performance penalty.\n *\n * A sane value is xen_blkif_reqs * BLKIF_MAX_SEGMENTS_PER_REQUEST, but can\n * be set to a lower value that might degrade performance on some intensive\n * IO workloads.\n */\n\nstatic int xen_blkif_max_buffer_pages = 1024;\nmodule_param_named(max_buffer_pages, xen_blkif_max_buffer_pages, int, 0644);\nMODULE_PARM_DESC(max_buffer_pages,\n\"Maximum number of free pages to keep in each block backend buffer\");\n\n/*\n * Maximum number of grants to map persistently in blkback. For maximum\n * performance this should be the total numbers of grants that can be used\n * to fill the ring, but since this might become too high, specially with\n * the use of indirect descriptors, we set it to a value that provides good\n * performance without using too much memory.\n *\n * When the list of persistent grants is full we clean it up using a LRU\n * algorithm.\n */\n\nstatic int xen_blkif_max_pgrants = 1056;\nmodule_param_named(max_persistent_grants, xen_blkif_max_pgrants, int, 0644);\nMODULE_PARM_DESC(max_persistent_grants,\n                 \"Maximum number of grants to map persistently\");\n\n/*\n * The LRU mechanism to clean the lists of persistent grants needs to\n * be executed periodically. The time interval between consecutive executions\n * of the purge mechanism is set in ms.\n */\n#define LRU_INTERVAL 100\n\n/*\n * When the persistent grants list is full we will remove unused grants\n * from the list. The percent number of grants to be removed at each LRU\n * execution.\n */\n#define LRU_PERCENT_CLEAN 5\n\n/* Run-time switchable: /sys/module/blkback/parameters/ */\nstatic unsigned int log_stats;\nmodule_param(log_stats, int, 0644);\n\n#define BLKBACK_INVALID_HANDLE (~0)\n\n/* Number of free pages to remove on each call to free_xenballooned_pages */\n#define NUM_BATCH_FREE_PAGES 10\n\nstatic inline int get_free_page(struct xen_blkif *blkif, struct page **page)\n{\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&blkif->free_pages_lock, flags);\n\tif (list_empty(&blkif->free_pages)) {\n\t\tBUG_ON(blkif->free_pages_num != 0);\n\t\tspin_unlock_irqrestore(&blkif->free_pages_lock, flags);\n\t\treturn alloc_xenballooned_pages(1, page, false);\n\t}\n\tBUG_ON(blkif->free_pages_num == 0);\n\tpage[0] = list_first_entry(&blkif->free_pages, struct page, lru);\n\tlist_del(&page[0]->lru);\n\tblkif->free_pages_num--;\n\tspin_unlock_irqrestore(&blkif->free_pages_lock, flags);\n\n\treturn 0;\n}\n\nstatic inline void put_free_pages(struct xen_blkif *blkif, struct page **page,\n                                  int num)\n{\n\tunsigned long flags;\n\tint i;\n\n\tspin_lock_irqsave(&blkif->free_pages_lock, flags);\n\tfor (i = 0; i < num; i++)\n\t\tlist_add(&page[i]->lru, &blkif->free_pages);\n\tblkif->free_pages_num += num;\n\tspin_unlock_irqrestore(&blkif->free_pages_lock, flags);\n}\n\nstatic inline void shrink_free_pagepool(struct xen_blkif *blkif, int num)\n{\n\t/* Remove requested pages in batches of NUM_BATCH_FREE_PAGES */\n\tstruct page *page[NUM_BATCH_FREE_PAGES];\n\tunsigned int num_pages = 0;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&blkif->free_pages_lock, flags);\n\twhile (blkif->free_pages_num > num) {\n\t\tBUG_ON(list_empty(&blkif->free_pages));\n\t\tpage[num_pages] = list_first_entry(&blkif->free_pages,\n\t\t                                   struct page, lru);\n\t\tlist_del(&page[num_pages]->lru);\n\t\tblkif->free_pages_num--;\n\t\tif (++num_pages == NUM_BATCH_FREE_PAGES) {\n\t\t\tspin_unlock_irqrestore(&blkif->free_pages_lock, flags);\n\t\t\tfree_xenballooned_pages(num_pages, page);\n\t\t\tspin_lock_irqsave(&blkif->free_pages_lock, flags);\n\t\t\tnum_pages = 0;\n\t\t}\n\t}\n\tspin_unlock_irqrestore(&blkif->free_pages_lock, flags);\n\tif (num_pages != 0)\n\t\tfree_xenballooned_pages(num_pages, page);\n}\n\n#define vaddr(page) ((unsigned long)pfn_to_kaddr(page_to_pfn(page)))\n\nstatic int do_block_io_op(struct xen_blkif *blkif);\nstatic int dispatch_rw_block_io(struct xen_blkif *blkif,\n\t\t\t\tstruct blkif_request *req,\n\t\t\t\tstruct pending_req *pending_req);\nstatic void make_response(struct xen_blkif *blkif, u64 id,\n\t\t\t  unsigned short op, int st);\n\n#define foreach_grant_safe(pos, n, rbtree, node) \\\n\tfor ((pos) = container_of(rb_first((rbtree)), typeof(*(pos)), node), \\\n\t     (n) = (&(pos)->node != NULL) ? rb_next(&(pos)->node) : NULL; \\\n\t     &(pos)->node != NULL; \\\n\t     (pos) = container_of(n, typeof(*(pos)), node), \\\n\t     (n) = (&(pos)->node != NULL) ? rb_next(&(pos)->node) : NULL)\n\n\n/*\n * We don't need locking around the persistent grant helpers\n * because blkback uses a single-thread for each backed, so we\n * can be sure that this functions will never be called recursively.\n *\n * The only exception to that is put_persistent_grant, that can be called\n * from interrupt context (by xen_blkbk_unmap), so we have to use atomic\n * bit operations to modify the flags of a persistent grant and to count\n * the number of used grants.\n */\nstatic int add_persistent_gnt(struct xen_blkif *blkif,\n\t\t\t       struct persistent_gnt *persistent_gnt)\n{\n\tstruct rb_node **new = NULL, *parent = NULL;\n\tstruct persistent_gnt *this;\n\n\tif (blkif->persistent_gnt_c >= xen_blkif_max_pgrants) {\n\t\tif (!blkif->vbd.overflow_max_grants)\n\t\t\tblkif->vbd.overflow_max_grants = 1;\n\t\treturn -EBUSY;\n\t}\n\t/* Figure out where to put new node */\n\tnew = &blkif->persistent_gnts.rb_node;\n\twhile (*new) {\n\t\tthis = container_of(*new, struct persistent_gnt, node);\n\n\t\tparent = *new;\n\t\tif (persistent_gnt->gnt < this->gnt)\n\t\t\tnew = &((*new)->rb_left);\n\t\telse if (persistent_gnt->gnt > this->gnt)\n\t\t\tnew = &((*new)->rb_right);\n\t\telse {\n\t\t\tpr_alert_ratelimited(DRV_PFX \" trying to add a gref that's already in the tree\\n\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\n\tbitmap_zero(persistent_gnt->flags, PERSISTENT_GNT_FLAGS_SIZE);\n\tset_bit(PERSISTENT_GNT_ACTIVE, persistent_gnt->flags);\n\t/* Add new node and rebalance tree. */\n\trb_link_node(&(persistent_gnt->node), parent, new);\n\trb_insert_color(&(persistent_gnt->node), &blkif->persistent_gnts);\n\tblkif->persistent_gnt_c++;\n\tatomic_inc(&blkif->persistent_gnt_in_use);\n\treturn 0;\n}\n\nstatic struct persistent_gnt *get_persistent_gnt(struct xen_blkif *blkif,\n\t\t\t\t\t\t grant_ref_t gref)\n{\n\tstruct persistent_gnt *data;\n\tstruct rb_node *node = NULL;\n\n\tnode = blkif->persistent_gnts.rb_node;\n\twhile (node) {\n\t\tdata = container_of(node, struct persistent_gnt, node);\n\n\t\tif (gref < data->gnt)\n\t\t\tnode = node->rb_left;\n\t\telse if (gref > data->gnt)\n\t\t\tnode = node->rb_right;\n\t\telse {\n\t\t\tif(test_bit(PERSISTENT_GNT_ACTIVE, data->flags)) {\n\t\t\t\tpr_alert_ratelimited(DRV_PFX \" requesting a grant already in use\\n\");\n\t\t\t\treturn NULL;\n\t\t\t}\n\t\t\tset_bit(PERSISTENT_GNT_ACTIVE, data->flags);\n\t\t\tatomic_inc(&blkif->persistent_gnt_in_use);\n\t\t\treturn data;\n\t\t}\n\t}\n\treturn NULL;\n}\n\nstatic void put_persistent_gnt(struct xen_blkif *blkif,\n                               struct persistent_gnt *persistent_gnt)\n{\n\tif(!test_bit(PERSISTENT_GNT_ACTIVE, persistent_gnt->flags))\n\t          pr_alert_ratelimited(DRV_PFX \" freeing a grant already unused\");\n\tset_bit(PERSISTENT_GNT_WAS_ACTIVE, persistent_gnt->flags);\n\tclear_bit(PERSISTENT_GNT_ACTIVE, persistent_gnt->flags);\n\tatomic_dec(&blkif->persistent_gnt_in_use);\n}\n\nstatic void free_persistent_gnts(struct xen_blkif *blkif, struct rb_root *root,\n                                 unsigned int num)\n{\n\tstruct gnttab_unmap_grant_ref unmap[BLKIF_MAX_SEGMENTS_PER_REQUEST];\n\tstruct page *pages[BLKIF_MAX_SEGMENTS_PER_REQUEST];\n\tstruct persistent_gnt *persistent_gnt;\n\tstruct rb_node *n;\n\tint ret = 0;\n\tint segs_to_unmap = 0;\n\n\tforeach_grant_safe(persistent_gnt, n, root, node) {\n\t\tBUG_ON(persistent_gnt->handle ==\n\t\t\tBLKBACK_INVALID_HANDLE);\n\t\tgnttab_set_unmap_op(&unmap[segs_to_unmap],\n\t\t\t(unsigned long) pfn_to_kaddr(page_to_pfn(\n\t\t\t\tpersistent_gnt->page)),\n\t\t\tGNTMAP_host_map,\n\t\t\tpersistent_gnt->handle);\n\n\t\tpages[segs_to_unmap] = persistent_gnt->page;\n\n\t\tif (++segs_to_unmap == BLKIF_MAX_SEGMENTS_PER_REQUEST ||\n\t\t\t!rb_next(&persistent_gnt->node)) {\n\t\t\tret = gnttab_unmap_refs(unmap, NULL, pages,\n\t\t\t\tsegs_to_unmap);\n\t\t\tBUG_ON(ret);\n\t\t\tput_free_pages(blkif, pages, segs_to_unmap);\n\t\t\tsegs_to_unmap = 0;\n\t\t}\n\n\t\trb_erase(&persistent_gnt->node, root);\n\t\tkfree(persistent_gnt);\n\t\tnum--;\n\t}\n\tBUG_ON(num != 0);\n}\n\nstatic void unmap_purged_grants(struct work_struct *work)\n{\n\tstruct gnttab_unmap_grant_ref unmap[BLKIF_MAX_SEGMENTS_PER_REQUEST];\n\tstruct page *pages[BLKIF_MAX_SEGMENTS_PER_REQUEST];\n\tstruct persistent_gnt *persistent_gnt;\n\tint ret, segs_to_unmap = 0;\n\tstruct xen_blkif *blkif = container_of(work, typeof(*blkif), persistent_purge_work);\n\n\twhile(!list_empty(&blkif->persistent_purge_list)) {\n\t\tpersistent_gnt = list_first_entry(&blkif->persistent_purge_list,\n\t\t                                  struct persistent_gnt,\n\t\t                                  remove_node);\n\t\tlist_del(&persistent_gnt->remove_node);\n\n\t\tgnttab_set_unmap_op(&unmap[segs_to_unmap],\n\t\t\tvaddr(persistent_gnt->page),\n\t\t\tGNTMAP_host_map,\n\t\t\tpersistent_gnt->handle);\n\n\t\tpages[segs_to_unmap] = persistent_gnt->page;\n\n\t\tif (++segs_to_unmap == BLKIF_MAX_SEGMENTS_PER_REQUEST) {\n\t\t\tret = gnttab_unmap_refs(unmap, NULL, pages,\n\t\t\t\tsegs_to_unmap);\n\t\t\tBUG_ON(ret);\n\t\t\tput_free_pages(blkif, pages, segs_to_unmap);\n\t\t\tsegs_to_unmap = 0;\n\t\t}\n\t\tkfree(persistent_gnt);\n\t}\n\tif (segs_to_unmap > 0) {\n\t\tret = gnttab_unmap_refs(unmap, NULL, pages, segs_to_unmap);\n\t\tBUG_ON(ret);\n\t\tput_free_pages(blkif, pages, segs_to_unmap);\n\t}\n}\n\nstatic void purge_persistent_gnt(struct xen_blkif *blkif)\n{\n\tstruct persistent_gnt *persistent_gnt;\n\tstruct rb_node *n;\n\tunsigned int num_clean, total;\n\tbool scan_used = false;\n\tstruct rb_root *root;\n\n\tif (blkif->persistent_gnt_c < xen_blkif_max_pgrants ||\n\t    (blkif->persistent_gnt_c == xen_blkif_max_pgrants &&\n\t    !blkif->vbd.overflow_max_grants)) {\n\t\treturn;\n\t}\n\n\tif (work_pending(&blkif->persistent_purge_work)) {\n\t\tpr_alert_ratelimited(DRV_PFX \"Scheduled work from previous purge is still pending, cannot purge list\\n\");\n\t\treturn;\n\t}\n\n\tnum_clean = (xen_blkif_max_pgrants / 100) * LRU_PERCENT_CLEAN;\n\tnum_clean = blkif->persistent_gnt_c - xen_blkif_max_pgrants + num_clean;\n\tnum_clean = min(blkif->persistent_gnt_c, num_clean);\n\tif (num_clean >\n\t    (blkif->persistent_gnt_c -\n\t    atomic_read(&blkif->persistent_gnt_in_use)))\n\t\treturn;\n\n\t/*\n\t * At this point, we can assure that there will be no calls\n         * to get_persistent_grant (because we are executing this code from\n         * xen_blkif_schedule), there can only be calls to put_persistent_gnt,\n         * which means that the number of currently used grants will go down,\n         * but never up, so we will always be able to remove the requested\n         * number of grants.\n\t */\n\n\ttotal = num_clean;\n\n\tpr_debug(DRV_PFX \"Going to purge %u persistent grants\\n\", num_clean);\n\n\tINIT_LIST_HEAD(&blkif->persistent_purge_list);\n\troot = &blkif->persistent_gnts;\npurge_list:\n\tforeach_grant_safe(persistent_gnt, n, root, node) {\n\t\tBUG_ON(persistent_gnt->handle ==\n\t\t\tBLKBACK_INVALID_HANDLE);\n\n\t\tif (test_bit(PERSISTENT_GNT_ACTIVE, persistent_gnt->flags))\n\t\t\tcontinue;\n\t\tif (!scan_used &&\n\t\t    (test_bit(PERSISTENT_GNT_WAS_ACTIVE, persistent_gnt->flags)))\n\t\t\tcontinue;\n\n\t\trb_erase(&persistent_gnt->node, root);\n\t\tlist_add(&persistent_gnt->remove_node,\n\t\t         &blkif->persistent_purge_list);\n\t\tif (--num_clean == 0)\n\t\t\tgoto finished;\n\t}\n\t/*\n\t * If we get here it means we also need to start cleaning\n\t * grants that were used since last purge in order to cope\n\t * with the requested num\n\t */\n\tif (!scan_used) {\n\t\tpr_debug(DRV_PFX \"Still missing %u purged frames\\n\", num_clean);\n\t\tscan_used = true;\n\t\tgoto purge_list;\n\t}\nfinished:\n\t/* Remove the \"used\" flag from all the persistent grants */\n\tforeach_grant_safe(persistent_gnt, n, root, node) {\n\t\tBUG_ON(persistent_gnt->handle ==\n\t\t\tBLKBACK_INVALID_HANDLE);\n\t\tclear_bit(PERSISTENT_GNT_WAS_ACTIVE, persistent_gnt->flags);\n\t}\n\tblkif->persistent_gnt_c -= (total - num_clean);\n\tblkif->vbd.overflow_max_grants = 0;\n\n\t/* We can defer this work */\n\tINIT_WORK(&blkif->persistent_purge_work, unmap_purged_grants);\n\tschedule_work(&blkif->persistent_purge_work);\n\tpr_debug(DRV_PFX \"Purged %u/%u\\n\", (total - num_clean), total);\n\treturn;\n}\n\n/*\n * Retrieve from the 'pending_reqs' a free pending_req structure to be used.\n */\nstatic struct pending_req *alloc_req(struct xen_blkif *blkif)\n{\n\tstruct pending_req *req = NULL;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&blkif->pending_free_lock, flags);\n\tif (!list_empty(&blkif->pending_free)) {\n\t\treq = list_entry(blkif->pending_free.next, struct pending_req,\n\t\t\t\t free_list);\n\t\tlist_del(&req->free_list);\n\t}\n\tspin_unlock_irqrestore(&blkif->pending_free_lock, flags);\n\treturn req;\n}\n\n/*\n * Return the 'pending_req' structure back to the freepool. We also\n * wake up the thread if it was waiting for a free page.\n */\nstatic void free_req(struct xen_blkif *blkif, struct pending_req *req)\n{\n\tunsigned long flags;\n\tint was_empty;\n\n\tspin_lock_irqsave(&blkif->pending_free_lock, flags);\n\twas_empty = list_empty(&blkif->pending_free);\n\tlist_add(&req->free_list, &blkif->pending_free);\n\tspin_unlock_irqrestore(&blkif->pending_free_lock, flags);\n\tif (was_empty)\n\t\twake_up(&blkif->pending_free_wq);\n}\n\n/*\n * Routines for managing virtual block devices (vbds).\n */\nstatic int xen_vbd_translate(struct phys_req *req, struct xen_blkif *blkif,\n\t\t\t     int operation)\n{\n\tstruct xen_vbd *vbd = &blkif->vbd;\n\tint rc = -EACCES;\n\n\tif ((operation != READ) && vbd->readonly)\n\t\tgoto out;\n\n\tif (likely(req->nr_sects)) {\n\t\tblkif_sector_t end = req->sector_number + req->nr_sects;\n\n\t\tif (unlikely(end < req->sector_number))\n\t\t\tgoto out;\n\t\tif (unlikely(end > vbd_sz(vbd)))\n\t\t\tgoto out;\n\t}\n\n\treq->dev  = vbd->pdevice;\n\treq->bdev = vbd->bdev;\n\trc = 0;\n\n out:\n\treturn rc;\n}\n\nstatic void xen_vbd_resize(struct xen_blkif *blkif)\n{\n\tstruct xen_vbd *vbd = &blkif->vbd;\n\tstruct xenbus_transaction xbt;\n\tint err;\n\tstruct xenbus_device *dev = xen_blkbk_xenbus(blkif->be);\n\tunsigned long long new_size = vbd_sz(vbd);\n\n\tpr_info(DRV_PFX \"VBD Resize: Domid: %d, Device: (%d, %d)\\n\",\n\t\tblkif->domid, MAJOR(vbd->pdevice), MINOR(vbd->pdevice));\n\tpr_info(DRV_PFX \"VBD Resize: new size %llu\\n\", new_size);\n\tvbd->size = new_size;\nagain:\n\terr = xenbus_transaction_start(&xbt);\n\tif (err) {\n\t\tpr_warn(DRV_PFX \"Error starting transaction\");\n\t\treturn;\n\t}\n\terr = xenbus_printf(xbt, dev->nodename, \"sectors\", \"%llu\",\n\t\t\t    (unsigned long long)vbd_sz(vbd));\n\tif (err) {\n\t\tpr_warn(DRV_PFX \"Error writing new size\");\n\t\tgoto abort;\n\t}\n\t/*\n\t * Write the current state; we will use this to synchronize\n\t * the front-end. If the current state is \"connected\" the\n\t * front-end will get the new size information online.\n\t */\n\terr = xenbus_printf(xbt, dev->nodename, \"state\", \"%d\", dev->state);\n\tif (err) {\n\t\tpr_warn(DRV_PFX \"Error writing the state\");\n\t\tgoto abort;\n\t}\n\n\terr = xenbus_transaction_end(xbt, 0);\n\tif (err == -EAGAIN)\n\t\tgoto again;\n\tif (err)\n\t\tpr_warn(DRV_PFX \"Error ending transaction\");\n\treturn;\nabort:\n\txenbus_transaction_end(xbt, 1);\n}\n\n/*\n * Notification from the guest OS.\n */\nstatic void blkif_notify_work(struct xen_blkif *blkif)\n{\n\tblkif->waiting_reqs = 1;\n\twake_up(&blkif->wq);\n}\n\nirqreturn_t xen_blkif_be_int(int irq, void *dev_id)\n{\n\tblkif_notify_work(dev_id);\n\treturn IRQ_HANDLED;\n}\n\n/*\n * SCHEDULER FUNCTIONS\n */\n\nstatic void print_stats(struct xen_blkif *blkif)\n{\n\tpr_info(\"xen-blkback (%s): oo %3llu  |  rd %4llu  |  wr %4llu  |  f %4llu\"\n\t\t \"  |  ds %4llu | pg: %4u/%4d\\n\",\n\t\t current->comm, blkif->st_oo_req,\n\t\t blkif->st_rd_req, blkif->st_wr_req,\n\t\t blkif->st_f_req, blkif->st_ds_req,\n\t\t blkif->persistent_gnt_c,\n\t\t xen_blkif_max_pgrants);\n\tblkif->st_print = jiffies + msecs_to_jiffies(10 * 1000);\n\tblkif->st_rd_req = 0;\n\tblkif->st_wr_req = 0;\n\tblkif->st_oo_req = 0;\n\tblkif->st_ds_req = 0;\n}\n\nint xen_blkif_schedule(void *arg)\n{\n\tstruct xen_blkif *blkif = arg;\n\tstruct xen_vbd *vbd = &blkif->vbd;\n\tunsigned long timeout;\n\n\txen_blkif_get(blkif);\n\n\twhile (!kthread_should_stop()) {\n\t\tif (try_to_freeze())\n\t\t\tcontinue;\n\t\tif (unlikely(vbd->size != vbd_sz(vbd)))\n\t\t\txen_vbd_resize(blkif);\n\n\t\ttimeout = msecs_to_jiffies(LRU_INTERVAL);\n\n\t\ttimeout = wait_event_interruptible_timeout(\n\t\t\tblkif->wq,\n\t\t\tblkif->waiting_reqs || kthread_should_stop(),\n\t\t\ttimeout);\n\t\tif (timeout == 0)\n\t\t\tgoto purge_gnt_list;\n\t\ttimeout = wait_event_interruptible_timeout(\n\t\t\tblkif->pending_free_wq,\n\t\t\t!list_empty(&blkif->pending_free) ||\n\t\t\tkthread_should_stop(),\n\t\t\ttimeout);\n\t\tif (timeout == 0)\n\t\t\tgoto purge_gnt_list;\n\n\t\tblkif->waiting_reqs = 0;\n\t\tsmp_mb(); /* clear flag *before* checking for work */\n\n\t\tif (do_block_io_op(blkif))\n\t\t\tblkif->waiting_reqs = 1;\n\npurge_gnt_list:\n\t\tif (blkif->vbd.feature_gnt_persistent &&\n\t\t    time_after(jiffies, blkif->next_lru)) {\n\t\t\tpurge_persistent_gnt(blkif);\n\t\t\tblkif->next_lru = jiffies + msecs_to_jiffies(LRU_INTERVAL);\n\t\t}\n\n\t\t/* Shrink if we have more than xen_blkif_max_buffer_pages */\n\t\tshrink_free_pagepool(blkif, xen_blkif_max_buffer_pages);\n\n\t\tif (log_stats && time_after(jiffies, blkif->st_print))\n\t\t\tprint_stats(blkif);\n\t}\n\n\t/* Since we are shutting down remove all pages from the buffer */\n\tshrink_free_pagepool(blkif, 0 /* All */);\n\n\t/* Free all persistent grant pages */\n\tif (!RB_EMPTY_ROOT(&blkif->persistent_gnts))\n\t\tfree_persistent_gnts(blkif, &blkif->persistent_gnts,\n\t\t\tblkif->persistent_gnt_c);\n\n\tBUG_ON(!RB_EMPTY_ROOT(&blkif->persistent_gnts));\n\tblkif->persistent_gnt_c = 0;\n\n\tif (log_stats)\n\t\tprint_stats(blkif);\n\n\tblkif->xenblkd = NULL;\n\txen_blkif_put(blkif);\n\n\treturn 0;\n}\n\n/*\n * Unmap the grant references, and also remove the M2P over-rides\n * used in the 'pending_req'.\n */\nstatic void xen_blkbk_unmap(struct xen_blkif *blkif,\n                            struct grant_page *pages[],\n                            int num)\n{\n\tstruct gnttab_unmap_grant_ref unmap[BLKIF_MAX_SEGMENTS_PER_REQUEST];\n\tstruct page *unmap_pages[BLKIF_MAX_SEGMENTS_PER_REQUEST];\n\tunsigned int i, invcount = 0;\n\tint ret;\n\n\tfor (i = 0; i < num; i++) {\n\t\tif (pages[i]->persistent_gnt != NULL) {\n\t\t\tput_persistent_gnt(blkif, pages[i]->persistent_gnt);\n\t\t\tcontinue;\n\t\t}\n\t\tif (pages[i]->handle == BLKBACK_INVALID_HANDLE)\n\t\t\tcontinue;\n\t\tunmap_pages[invcount] = pages[i]->page;\n\t\tgnttab_set_unmap_op(&unmap[invcount], vaddr(pages[i]->page),\n\t\t\t\t    GNTMAP_host_map, pages[i]->handle);\n\t\tpages[i]->handle = BLKBACK_INVALID_HANDLE;\n\t\tif (++invcount == BLKIF_MAX_SEGMENTS_PER_REQUEST) {\n\t\t\tret = gnttab_unmap_refs(unmap, NULL, unmap_pages,\n\t\t\t                        invcount);\n\t\t\tBUG_ON(ret);\n\t\t\tput_free_pages(blkif, unmap_pages, invcount);\n\t\t\tinvcount = 0;\n\t\t}\n\t}\n\tif (invcount) {\n\t\tret = gnttab_unmap_refs(unmap, NULL, unmap_pages, invcount);\n\t\tBUG_ON(ret);\n\t\tput_free_pages(blkif, unmap_pages, invcount);\n\t}\n}\n\nstatic int xen_blkbk_map(struct xen_blkif *blkif,\n\t\t\t struct grant_page *pages[],\n\t\t\t int num, bool ro)\n{\n\tstruct gnttab_map_grant_ref map[BLKIF_MAX_SEGMENTS_PER_REQUEST];\n\tstruct page *pages_to_gnt[BLKIF_MAX_SEGMENTS_PER_REQUEST];\n\tstruct persistent_gnt *persistent_gnt = NULL;\n\tphys_addr_t addr = 0;\n\tint i, seg_idx, new_map_idx;\n\tint segs_to_map = 0;\n\tint ret = 0;\n\tint last_map = 0, map_until = 0;\n\tint use_persistent_gnts;\n\n\tuse_persistent_gnts = (blkif->vbd.feature_gnt_persistent);\n\n\t/*\n\t * Fill out preq.nr_sects with proper amount of sectors, and setup\n\t * assign map[..] with the PFN of the page in our domain with the\n\t * corresponding grant reference for each page.\n\t */\nagain:\n\tfor (i = map_until; i < num; i++) {\n\t\tuint32_t flags;\n\n\t\tif (use_persistent_gnts)\n\t\t\tpersistent_gnt = get_persistent_gnt(\n\t\t\t\tblkif,\n\t\t\t\tpages[i]->gref);\n\n\t\tif (persistent_gnt) {\n\t\t\t/*\n\t\t\t * We are using persistent grants and\n\t\t\t * the grant is already mapped\n\t\t\t */\n\t\t\tpages[i]->page = persistent_gnt->page;\n\t\t\tpages[i]->persistent_gnt = persistent_gnt;\n\t\t} else {\n\t\t\tif (get_free_page(blkif, &pages[i]->page))\n\t\t\t\tgoto out_of_memory;\n\t\t\taddr = vaddr(pages[i]->page);\n\t\t\tpages_to_gnt[segs_to_map] = pages[i]->page;\n\t\t\tpages[i]->persistent_gnt = NULL;\n\t\t\tflags = GNTMAP_host_map;\n\t\t\tif (!use_persistent_gnts && ro)\n\t\t\t\tflags |= GNTMAP_readonly;\n\t\t\tgnttab_set_map_op(&map[segs_to_map++], addr,\n\t\t\t\t\t  flags, pages[i]->gref,\n\t\t\t\t\t  blkif->domid);\n\t\t}\n\t\tmap_until = i + 1;\n\t\tif (segs_to_map == BLKIF_MAX_SEGMENTS_PER_REQUEST)\n\t\t\tbreak;\n\t}\n\n\tif (segs_to_map) {\n\t\tret = gnttab_map_refs(map, NULL, pages_to_gnt, segs_to_map);\n\t\tBUG_ON(ret);\n\t}\n\n\t/*\n\t * Now swizzle the MFN in our domain with the MFN from the other domain\n\t * so that when we access vaddr(pending_req,i) it has the contents of\n\t * the page from the other domain.\n\t */\n\tfor (seg_idx = last_map, new_map_idx = 0; seg_idx < map_until; seg_idx++) {\n\t\tif (!pages[seg_idx]->persistent_gnt) {\n\t\t\t/* This is a newly mapped grant */\n\t\t\tBUG_ON(new_map_idx >= segs_to_map);\n\t\t\tif (unlikely(map[new_map_idx].status != 0)) {\n\t\t\t\tpr_debug(DRV_PFX \"invalid buffer -- could not remap it\\n\");\n\t\t\t\tpages[seg_idx]->handle = BLKBACK_INVALID_HANDLE;\n\t\t\t\tret |= 1;\n\t\t\t\tgoto next;\n\t\t\t}\n\t\t\tpages[seg_idx]->handle = map[new_map_idx].handle;\n\t\t} else {\n\t\t\tcontinue;\n\t\t}\n\t\tif (use_persistent_gnts &&\n\t\t    blkif->persistent_gnt_c < xen_blkif_max_pgrants) {\n\t\t\t/*\n\t\t\t * We are using persistent grants, the grant is\n\t\t\t * not mapped but we might have room for it.\n\t\t\t */\n\t\t\tpersistent_gnt = kmalloc(sizeof(struct persistent_gnt),\n\t\t\t\t                 GFP_KERNEL);\n\t\t\tif (!persistent_gnt) {\n\t\t\t\t/*\n\t\t\t\t * If we don't have enough memory to\n\t\t\t\t * allocate the persistent_gnt struct\n\t\t\t\t * map this grant non-persistenly\n\t\t\t\t */\n\t\t\t\tgoto next;\n\t\t\t}\n\t\t\tpersistent_gnt->gnt = map[new_map_idx].ref;\n\t\t\tpersistent_gnt->handle = map[new_map_idx].handle;\n\t\t\tpersistent_gnt->page = pages[seg_idx]->page;\n\t\t\tif (add_persistent_gnt(blkif,\n\t\t\t                       persistent_gnt)) {\n\t\t\t\tkfree(persistent_gnt);\n\t\t\t\tpersistent_gnt = NULL;\n\t\t\t\tgoto next;\n\t\t\t}\n\t\t\tpages[seg_idx]->persistent_gnt = persistent_gnt;\n\t\t\tpr_debug(DRV_PFX \" grant %u added to the tree of persistent grants, using %u/%u\\n\",\n\t\t\t\t persistent_gnt->gnt, blkif->persistent_gnt_c,\n\t\t\t\t xen_blkif_max_pgrants);\n\t\t\tgoto next;\n\t\t}\n\t\tif (use_persistent_gnts && !blkif->vbd.overflow_max_grants) {\n\t\t\tblkif->vbd.overflow_max_grants = 1;\n\t\t\tpr_debug(DRV_PFX \" domain %u, device %#x is using maximum number of persistent grants\\n\",\n\t\t\t         blkif->domid, blkif->vbd.handle);\n\t\t}\n\t\t/*\n\t\t * We could not map this grant persistently, so use it as\n\t\t * a non-persistent grant.\n\t\t */\nnext:\n\t\tnew_map_idx++;\n\t}\n\tsegs_to_map = 0;\n\tlast_map = map_until;\n\tif (map_until != num)\n\t\tgoto again;\n\n\treturn ret;\n\nout_of_memory:\n\tpr_alert(DRV_PFX \"%s: out of memory\\n\", __func__);\n\tput_free_pages(blkif, pages_to_gnt, segs_to_map);\n\treturn -ENOMEM;\n}\n\nstatic int xen_blkbk_map_seg(struct pending_req *pending_req)\n{\n\tint rc;\n\n\trc = xen_blkbk_map(pending_req->blkif, pending_req->segments,\n\t\t\t   pending_req->nr_pages,\n\t                   (pending_req->operation != BLKIF_OP_READ));\n\n\treturn rc;\n}\n\nstatic int xen_blkbk_parse_indirect(struct blkif_request *req,\n\t\t\t\t    struct pending_req *pending_req,\n\t\t\t\t    struct seg_buf seg[],\n\t\t\t\t    struct phys_req *preq)\n{\n\tstruct grant_page **pages = pending_req->indirect_pages;\n\tstruct xen_blkif *blkif = pending_req->blkif;\n\tint indirect_grefs, rc, n, nseg, i;\n\tstruct blkif_request_segment_aligned *segments = NULL;\n\n\tnseg = pending_req->nr_pages;\n\tindirect_grefs = INDIRECT_PAGES(nseg);\n\tBUG_ON(indirect_grefs > BLKIF_MAX_INDIRECT_PAGES_PER_REQUEST);\n\n\tfor (i = 0; i < indirect_grefs; i++)\n\t\tpages[i]->gref = req->u.indirect.indirect_grefs[i];\n\n\trc = xen_blkbk_map(blkif, pages, indirect_grefs, true);\n\tif (rc)\n\t\tgoto unmap;\n\n\tfor (n = 0, i = 0; n < nseg; n++) {\n\t\tif ((n % SEGS_PER_INDIRECT_FRAME) == 0) {\n\t\t\t/* Map indirect segments */\n\t\t\tif (segments)\n\t\t\t\tkunmap_atomic(segments);\n\t\t\tsegments = kmap_atomic(pages[n/SEGS_PER_INDIRECT_FRAME]->page);\n\t\t}\n\t\ti = n % SEGS_PER_INDIRECT_FRAME;\n\t\tpending_req->segments[n]->gref = segments[i].gref;\n\t\tseg[n].nsec = segments[i].last_sect -\n\t\t\tsegments[i].first_sect + 1;\n\t\tseg[n].offset = (segments[i].first_sect << 9);\n\t\tif ((segments[i].last_sect >= (PAGE_SIZE >> 9)) ||\n\t\t    (segments[i].last_sect < segments[i].first_sect)) {\n\t\t\trc = -EINVAL;\n\t\t\tgoto unmap;\n\t\t}\n\t\tpreq->nr_sects += seg[n].nsec;\n\t}\n\nunmap:\n\tif (segments)\n\t\tkunmap_atomic(segments);\n\txen_blkbk_unmap(blkif, pages, indirect_grefs);\n\treturn rc;\n}\n\nstatic int dispatch_discard_io(struct xen_blkif *blkif,\n\t\t\t\tstruct blkif_request *req)\n{\n\tint err = 0;\n\tint status = BLKIF_RSP_OKAY;\n\tstruct block_device *bdev = blkif->vbd.bdev;\n\tunsigned long secure;\n\tstruct phys_req preq;\n\n\tpreq.sector_number = req->u.discard.sector_number;\n\tpreq.nr_sects      = req->u.discard.nr_sectors;\n\n\terr = xen_vbd_translate(&preq, blkif, WRITE);\n\tif (err) {\n\t\tpr_warn(DRV_PFX \"access denied: DISCARD [%llu->%llu] on dev=%04x\\n\",\n\t\t\tpreq.sector_number,\n\t\t\tpreq.sector_number + preq.nr_sects, blkif->vbd.pdevice);\n\t\tgoto fail_response;\n\t}\n\tblkif->st_ds_req++;\n\n\txen_blkif_get(blkif);\n\tsecure = (blkif->vbd.discard_secure &&\n\t\t (req->u.discard.flag & BLKIF_DISCARD_SECURE)) ?\n\t\t BLKDEV_DISCARD_SECURE : 0;\n\n\terr = blkdev_issue_discard(bdev, req->u.discard.sector_number,\n\t\t\t\t   req->u.discard.nr_sectors,\n\t\t\t\t   GFP_KERNEL, secure);\nfail_response:\n\tif (err == -EOPNOTSUPP) {\n\t\tpr_debug(DRV_PFX \"discard op failed, not supported\\n\");\n\t\tstatus = BLKIF_RSP_EOPNOTSUPP;\n\t} else if (err)\n\t\tstatus = BLKIF_RSP_ERROR;\n\n\tmake_response(blkif, req->u.discard.id, req->operation, status);\n\txen_blkif_put(blkif);\n\treturn err;\n}\n\nstatic int dispatch_other_io(struct xen_blkif *blkif,\n\t\t\t     struct blkif_request *req,\n\t\t\t     struct pending_req *pending_req)\n{\n\tfree_req(blkif, pending_req);\n\tmake_response(blkif, req->u.other.id, req->operation,\n\t\t      BLKIF_RSP_EOPNOTSUPP);\n\treturn -EIO;\n}\n\nstatic void xen_blk_drain_io(struct xen_blkif *blkif)\n{\n\tatomic_set(&blkif->drain, 1);\n\tdo {\n\t\t/* The initial value is one, and one refcnt taken at the\n\t\t * start of the xen_blkif_schedule thread. */\n\t\tif (atomic_read(&blkif->refcnt) <= 2)\n\t\t\tbreak;\n\t\twait_for_completion_interruptible_timeout(\n\t\t\t\t&blkif->drain_complete, HZ);\n\n\t\tif (!atomic_read(&blkif->drain))\n\t\t\tbreak;\n\t} while (!kthread_should_stop());\n\tatomic_set(&blkif->drain, 0);\n}\n\n/*\n * Completion callback on the bio's. Called as bh->b_end_io()\n */\n\nstatic void __end_block_io_op(struct pending_req *pending_req, int error)\n{\n\t/* An error fails the entire request. */\n\tif ((pending_req->operation == BLKIF_OP_FLUSH_DISKCACHE) &&\n\t    (error == -EOPNOTSUPP)) {\n\t\tpr_debug(DRV_PFX \"flush diskcache op failed, not supported\\n\");\n\t\txen_blkbk_flush_diskcache(XBT_NIL, pending_req->blkif->be, 0);\n\t\tpending_req->status = BLKIF_RSP_EOPNOTSUPP;\n\t} else if ((pending_req->operation == BLKIF_OP_WRITE_BARRIER) &&\n\t\t    (error == -EOPNOTSUPP)) {\n\t\tpr_debug(DRV_PFX \"write barrier op failed, not supported\\n\");\n\t\txen_blkbk_barrier(XBT_NIL, pending_req->blkif->be, 0);\n\t\tpending_req->status = BLKIF_RSP_EOPNOTSUPP;\n\t} else if (error) {\n\t\tpr_debug(DRV_PFX \"Buffer not up-to-date at end of operation,\"\n\t\t\t \" error=%d\\n\", error);\n\t\tpending_req->status = BLKIF_RSP_ERROR;\n\t}\n\n\t/*\n\t * If all of the bio's have completed it is time to unmap\n\t * the grant references associated with 'request' and provide\n\t * the proper response on the ring.\n\t */\n\tif (atomic_dec_and_test(&pending_req->pendcnt)) {\n\t\txen_blkbk_unmap(pending_req->blkif,\n\t\t                pending_req->segments,\n\t\t                pending_req->nr_pages);\n\t\tmake_response(pending_req->blkif, pending_req->id,\n\t\t\t      pending_req->operation, pending_req->status);\n\t\txen_blkif_put(pending_req->blkif);\n\t\tif (atomic_read(&pending_req->blkif->refcnt) <= 2) {\n\t\t\tif (atomic_read(&pending_req->blkif->drain))\n\t\t\t\tcomplete(&pending_req->blkif->drain_complete);\n\t\t}\n\t\tfree_req(pending_req->blkif, pending_req);\n\t}\n}\n\n/*\n * bio callback.\n */\nstatic void end_block_io_op(struct bio *bio, int error)\n{\n\t__end_block_io_op(bio->bi_private, error);\n\tbio_put(bio);\n}\n\n\n\n/*\n * Function to copy the from the ring buffer the 'struct blkif_request'\n * (which has the sectors we want, number of them, grant references, etc),\n * and transmute  it to the block API to hand it over to the proper block disk.\n */\nstatic int\n__do_block_io_op(struct xen_blkif *blkif)\n{\n\tunion blkif_back_rings *blk_rings = &blkif->blk_rings;\n\tstruct blkif_request req;\n\tstruct pending_req *pending_req;\n\tRING_IDX rc, rp;\n\tint more_to_do = 0;\n\n\trc = blk_rings->common.req_cons;\n\trp = blk_rings->common.sring->req_prod;\n\trmb(); /* Ensure we see queued requests up to 'rp'. */\n\n\twhile (rc != rp) {\n\n\t\tif (RING_REQUEST_CONS_OVERFLOW(&blk_rings->common, rc))\n\t\t\tbreak;\n\n\t\tif (kthread_should_stop()) {\n\t\t\tmore_to_do = 1;\n\t\t\tbreak;\n\t\t}\n\n\t\tpending_req = alloc_req(blkif);\n\t\tif (NULL == pending_req) {\n\t\t\tblkif->st_oo_req++;\n\t\t\tmore_to_do = 1;\n\t\t\tbreak;\n\t\t}\n\n\t\tswitch (blkif->blk_protocol) {\n\t\tcase BLKIF_PROTOCOL_NATIVE:\n\t\t\tmemcpy(&req, RING_GET_REQUEST(&blk_rings->native, rc), sizeof(req));\n\t\t\tbreak;\n\t\tcase BLKIF_PROTOCOL_X86_32:\n\t\t\tblkif_get_x86_32_req(&req, RING_GET_REQUEST(&blk_rings->x86_32, rc));\n\t\t\tbreak;\n\t\tcase BLKIF_PROTOCOL_X86_64:\n\t\t\tblkif_get_x86_64_req(&req, RING_GET_REQUEST(&blk_rings->x86_64, rc));\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tBUG();\n\t\t}\n\t\tblk_rings->common.req_cons = ++rc; /* before make_response() */\n\n\t\t/* Apply all sanity checks to /private copy/ of request. */\n\t\tbarrier();\n\n\t\tswitch (req.operation) {\n\t\tcase BLKIF_OP_READ:\n\t\tcase BLKIF_OP_WRITE:\n\t\tcase BLKIF_OP_WRITE_BARRIER:\n\t\tcase BLKIF_OP_FLUSH_DISKCACHE:\n\t\tcase BLKIF_OP_INDIRECT:\n\t\t\tif (dispatch_rw_block_io(blkif, &req, pending_req))\n\t\t\t\tgoto done;\n\t\t\tbreak;\n\t\tcase BLKIF_OP_DISCARD:\n\t\t\tfree_req(blkif, pending_req);\n\t\t\tif (dispatch_discard_io(blkif, &req))\n\t\t\t\tgoto done;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tif (dispatch_other_io(blkif, &req, pending_req))\n\t\t\t\tgoto done;\n\t\t\tbreak;\n\t\t}\n\n\t\t/* Yield point for this unbounded loop. */\n\t\tcond_resched();\n\t}\ndone:\n\treturn more_to_do;\n}\n\nstatic int\ndo_block_io_op(struct xen_blkif *blkif)\n{\n\tunion blkif_back_rings *blk_rings = &blkif->blk_rings;\n\tint more_to_do;\n\n\tdo {\n\t\tmore_to_do = __do_block_io_op(blkif);\n\t\tif (more_to_do)\n\t\t\tbreak;\n\n\t\tRING_FINAL_CHECK_FOR_REQUESTS(&blk_rings->common, more_to_do);\n\t} while (more_to_do);\n\n\treturn more_to_do;\n}\n/*\n * Transmutation of the 'struct blkif_request' to a proper 'struct bio'\n * and call the 'submit_bio' to pass it to the underlying storage.\n */\nstatic int dispatch_rw_block_io(struct xen_blkif *blkif,\n\t\t\t\tstruct blkif_request *req,\n\t\t\t\tstruct pending_req *pending_req)\n{\n\tstruct phys_req preq;\n\tstruct seg_buf *seg = pending_req->seg;\n\tunsigned int nseg;\n\tstruct bio *bio = NULL;\n\tstruct bio **biolist = pending_req->biolist;\n\tint i, nbio = 0;\n\tint operation;\n\tstruct blk_plug plug;\n\tbool drain = false;\n\tstruct grant_page **pages = pending_req->segments;\n\tunsigned short req_operation;\n\n\treq_operation = req->operation == BLKIF_OP_INDIRECT ?\n\t\t\treq->u.indirect.indirect_op : req->operation;\n\tif ((req->operation == BLKIF_OP_INDIRECT) &&\n\t    (req_operation != BLKIF_OP_READ) &&\n\t    (req_operation != BLKIF_OP_WRITE)) {\n\t\tpr_debug(DRV_PFX \"Invalid indirect operation (%u)\\n\",\n\t\t\t req_operation);\n\t\tgoto fail_response;\n\t}\n\n\tswitch (req_operation) {\n\tcase BLKIF_OP_READ:\n\t\tblkif->st_rd_req++;\n\t\toperation = READ;\n\t\tbreak;\n\tcase BLKIF_OP_WRITE:\n\t\tblkif->st_wr_req++;\n\t\toperation = WRITE_ODIRECT;\n\t\tbreak;\n\tcase BLKIF_OP_WRITE_BARRIER:\n\t\tdrain = true;\n\tcase BLKIF_OP_FLUSH_DISKCACHE:\n\t\tblkif->st_f_req++;\n\t\toperation = WRITE_FLUSH;\n\t\tbreak;\n\tdefault:\n\t\toperation = 0; /* make gcc happy */\n\t\tgoto fail_response;\n\t\tbreak;\n\t}\n\n\t/* Check that the number of segments is sane. */\n\tnseg = req->operation == BLKIF_OP_INDIRECT ?\n\t       req->u.indirect.nr_segments : req->u.rw.nr_segments;\n\n\tif (unlikely(nseg == 0 && operation != WRITE_FLUSH) ||\n\t    unlikely((req->operation != BLKIF_OP_INDIRECT) &&\n\t\t     (nseg > BLKIF_MAX_SEGMENTS_PER_REQUEST)) ||\n\t    unlikely((req->operation == BLKIF_OP_INDIRECT) &&\n\t\t     (nseg > MAX_INDIRECT_SEGMENTS))) {\n\t\tpr_debug(DRV_PFX \"Bad number of segments in request (%d)\\n\",\n\t\t\t nseg);\n\t\t/* Haven't submitted any bio's yet. */\n\t\tgoto fail_response;\n\t}\n\n\tpreq.nr_sects      = 0;\n\n\tpending_req->blkif     = blkif;\n\tpending_req->id        = req->u.rw.id;\n\tpending_req->operation = req_operation;\n\tpending_req->status    = BLKIF_RSP_OKAY;\n\tpending_req->nr_pages  = nseg;\n\n\tif (req->operation != BLKIF_OP_INDIRECT) {\n\t\tpreq.dev               = req->u.rw.handle;\n\t\tpreq.sector_number     = req->u.rw.sector_number;\n\t\tfor (i = 0; i < nseg; i++) {\n\t\t\tpages[i]->gref = req->u.rw.seg[i].gref;\n\t\t\tseg[i].nsec = req->u.rw.seg[i].last_sect -\n\t\t\t\treq->u.rw.seg[i].first_sect + 1;\n\t\t\tseg[i].offset = (req->u.rw.seg[i].first_sect << 9);\n\t\t\tif ((req->u.rw.seg[i].last_sect >= (PAGE_SIZE >> 9)) ||\n\t\t\t    (req->u.rw.seg[i].last_sect <\n\t\t\t     req->u.rw.seg[i].first_sect))\n\t\t\t\tgoto fail_response;\n\t\t\tpreq.nr_sects += seg[i].nsec;\n\t\t}\n\t} else {\n\t\tpreq.dev               = req->u.indirect.handle;\n\t\tpreq.sector_number     = req->u.indirect.sector_number;\n\t\tif (xen_blkbk_parse_indirect(req, pending_req, seg, &preq))\n\t\t\tgoto fail_response;\n\t}\n\n\tif (xen_vbd_translate(&preq, blkif, operation) != 0) {\n\t\tpr_debug(DRV_PFX \"access denied: %s of [%llu,%llu] on dev=%04x\\n\",\n\t\t\t operation == READ ? \"read\" : \"write\",\n\t\t\t preq.sector_number,\n\t\t\t preq.sector_number + preq.nr_sects,\n\t\t\t blkif->vbd.pdevice);\n\t\tgoto fail_response;\n\t}\n\n\t/*\n\t * This check _MUST_ be done after xen_vbd_translate as the preq.bdev\n\t * is set there.\n\t */\n\tfor (i = 0; i < nseg; i++) {\n\t\tif (((int)preq.sector_number|(int)seg[i].nsec) &\n\t\t    ((bdev_logical_block_size(preq.bdev) >> 9) - 1)) {\n\t\t\tpr_debug(DRV_PFX \"Misaligned I/O request from domain %d\",\n\t\t\t\t blkif->domid);\n\t\t\tgoto fail_response;\n\t\t}\n\t}\n\n\t/* Wait on all outstanding I/O's and once that has been completed\n\t * issue the WRITE_FLUSH.\n\t */\n\tif (drain)\n\t\txen_blk_drain_io(pending_req->blkif);\n\n\t/*\n\t * If we have failed at this point, we need to undo the M2P override,\n\t * set gnttab_set_unmap_op on all of the grant references and perform\n\t * the hypercall to unmap the grants - that is all done in\n\t * xen_blkbk_unmap.\n\t */\n\tif (xen_blkbk_map_seg(pending_req))\n\t\tgoto fail_flush;\n\n\t/*\n\t * This corresponding xen_blkif_put is done in __end_block_io_op, or\n\t * below (in \"!bio\") if we are handling a BLKIF_OP_DISCARD.\n\t */\n\txen_blkif_get(blkif);\n\n\tfor (i = 0; i < nseg; i++) {\n\t\twhile ((bio == NULL) ||\n\t\t       (bio_add_page(bio,\n\t\t\t\t     pages[i]->page,\n\t\t\t\t     seg[i].nsec << 9,\n\t\t\t\t     seg[i].offset) == 0)) {\n\n\t\t\tbio = bio_alloc(GFP_KERNEL, nseg-i);\n\t\t\tif (unlikely(bio == NULL))\n\t\t\t\tgoto fail_put_bio;\n\n\t\t\tbiolist[nbio++] = bio;\n\t\t\tbio->bi_bdev    = preq.bdev;\n\t\t\tbio->bi_private = pending_req;\n\t\t\tbio->bi_end_io  = end_block_io_op;\n\t\t\tbio->bi_sector  = preq.sector_number;\n\t\t}\n\n\t\tpreq.sector_number += seg[i].nsec;\n\t}\n\n\t/* This will be hit if the operation was a flush or discard. */\n\tif (!bio) {\n\t\tBUG_ON(operation != WRITE_FLUSH);\n\n\t\tbio = bio_alloc(GFP_KERNEL, 0);\n\t\tif (unlikely(bio == NULL))\n\t\t\tgoto fail_put_bio;\n\n\t\tbiolist[nbio++] = bio;\n\t\tbio->bi_bdev    = preq.bdev;\n\t\tbio->bi_private = pending_req;\n\t\tbio->bi_end_io  = end_block_io_op;\n\t}\n\n\tatomic_set(&pending_req->pendcnt, nbio);\n\tblk_start_plug(&plug);\n\n\tfor (i = 0; i < nbio; i++)\n\t\tsubmit_bio(operation, biolist[i]);\n\n\t/* Let the I/Os go.. */\n\tblk_finish_plug(&plug);\n\n\tif (operation == READ)\n\t\tblkif->st_rd_sect += preq.nr_sects;\n\telse if (operation & WRITE)\n\t\tblkif->st_wr_sect += preq.nr_sects;\n\n\treturn 0;\n\n fail_flush:\n\txen_blkbk_unmap(blkif, pending_req->segments,\n\t                pending_req->nr_pages);\n fail_response:\n\t/* Haven't submitted any bio's yet. */\n\tmake_response(blkif, req->u.rw.id, req_operation, BLKIF_RSP_ERROR);\n\tfree_req(blkif, pending_req);\n\tmsleep(1); /* back off a bit */\n\treturn -EIO;\n\n fail_put_bio:\n\tfor (i = 0; i < nbio; i++)\n\t\tbio_put(biolist[i]);\n\tatomic_set(&pending_req->pendcnt, 1);\n\t__end_block_io_op(pending_req, -EINVAL);\n\tmsleep(1); /* back off a bit */\n\treturn -EIO;\n}\n\n\n\n/*\n * Put a response on the ring on how the operation fared.\n */\nstatic void make_response(struct xen_blkif *blkif, u64 id,\n\t\t\t  unsigned short op, int st)\n{\n\tstruct blkif_response  resp;\n\tunsigned long     flags;\n\tunion blkif_back_rings *blk_rings = &blkif->blk_rings;\n\tint notify;\n\n\tresp.id        = id;\n\tresp.operation = op;\n\tresp.status    = st;\n\n\tspin_lock_irqsave(&blkif->blk_ring_lock, flags);\n\t/* Place on the response ring for the relevant domain. */\n\tswitch (blkif->blk_protocol) {\n\tcase BLKIF_PROTOCOL_NATIVE:\n\t\tmemcpy(RING_GET_RESPONSE(&blk_rings->native, blk_rings->native.rsp_prod_pvt),\n\t\t       &resp, sizeof(resp));\n\t\tbreak;\n\tcase BLKIF_PROTOCOL_X86_32:\n\t\tmemcpy(RING_GET_RESPONSE(&blk_rings->x86_32, blk_rings->x86_32.rsp_prod_pvt),\n\t\t       &resp, sizeof(resp));\n\t\tbreak;\n\tcase BLKIF_PROTOCOL_X86_64:\n\t\tmemcpy(RING_GET_RESPONSE(&blk_rings->x86_64, blk_rings->x86_64.rsp_prod_pvt),\n\t\t       &resp, sizeof(resp));\n\t\tbreak;\n\tdefault:\n\t\tBUG();\n\t}\n\tblk_rings->common.rsp_prod_pvt++;\n\tRING_PUSH_RESPONSES_AND_CHECK_NOTIFY(&blk_rings->common, notify);\n\tspin_unlock_irqrestore(&blkif->blk_ring_lock, flags);\n\tif (notify)\n\t\tnotify_remote_via_irq(blkif->irq);\n}\n\nstatic int __init xen_blkif_init(void)\n{\n\tint rc = 0;\n\n\tif (!xen_domain())\n\t\treturn -ENODEV;\n\n\trc = xen_blkif_interface_init();\n\tif (rc)\n\t\tgoto failed_init;\n\n\trc = xen_blkif_xenbus_init();\n\tif (rc)\n\t\tgoto failed_init;\n\n failed_init:\n\treturn rc;\n}\n\nmodule_init(xen_blkif_init);\n\nMODULE_LICENSE(\"Dual BSD/GPL\");\nMODULE_ALIAS(\"xen-backend:vbd\");\n"], "filenames": ["drivers/block/xen-blkback/blkback.c"], "buggy_code_start_loc": [879], "buggy_code_end_loc": [891], "fixing_code_start_loc": [879], "fixing_code_end_loc": [902], "type": "CWE-20", "message": "The dispatch_discard_io function in drivers/block/xen-blkback/blkback.c in the Xen blkback implementation in the Linux kernel before 3.10.5 allows guest OS users to cause a denial of service (data loss) via filesystem write operations on a read-only disk that supports the (1) BLKIF_OP_DISCARD (aka discard or TRIM) or (2) SCSI UNMAP feature.", "other": {"cve": {"id": "CVE-2013-2140", "sourceIdentifier": "secalert@redhat.com", "published": "2013-09-25T10:31:29.067", "lastModified": "2023-02-13T04:42:55.813", "vulnStatus": "Modified", "descriptions": [{"lang": "en", "value": "The dispatch_discard_io function in drivers/block/xen-blkback/blkback.c in the Xen blkback implementation in the Linux kernel before 3.10.5 allows guest OS users to cause a denial of service (data loss) via filesystem write operations on a read-only disk that supports the (1) BLKIF_OP_DISCARD (aka discard or TRIM) or (2) SCSI UNMAP feature."}, {"lang": "es", "value": "La funci\u00f3n dispatch_discard_io en drivers/block/xen-blkback/blkback.c en la implementaci\u00f3n Xen blkback en el kernel de Linux anterior a v3.10.5 permite a usuarios invitados del sistema operativo provocar una denegaci\u00f3n de servicio (p\u00e9rdida de datos) a trav\u00e9s de operaciones de escritura del sistema de ficheros en un disco de s\u00f3lo lectura que soporte la funcionalidad BLKIF_OP_DISCARD (aka discard o TRIM) o SCSI UNMAP."}], "metrics": {"cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:A/AC:M/Au:S/C:N/I:P/A:P", "accessVector": "ADJACENT_NETWORK", "accessComplexity": "MEDIUM", "authentication": "SINGLE", "confidentialityImpact": "NONE", "integrityImpact": "PARTIAL", "availabilityImpact": "PARTIAL", "baseScore": 3.8}, "baseSeverity": "LOW", "exploitabilityScore": 4.4, "impactScore": 4.9, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-20"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionEndIncluding": "3.10.4", "matchCriteriaId": "CA7EE184-7C07-4C1A-A24F-27F56FF58A86"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.0:rc1:*:*:*:*:*:*", "matchCriteriaId": "D30AEC07-3CBD-4F4F-9646-BEAA1D98750B"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.0:rc2:*:*:*:*:*:*", "matchCriteriaId": "C2AA8E68-691B-499C-AEDD-3C0BFFE70044"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.0:rc3:*:*:*:*:*:*", "matchCriteriaId": "9440475B-5960-4066-A204-F30AAFC87846"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.0:rc4:*:*:*:*:*:*", "matchCriteriaId": "53BCFBFB-6AF0-4525-8623-7633CC5E17DB"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.0:rc5:*:*:*:*:*:*", "matchCriteriaId": "6ED4E86A-74F0-436A-BEB4-3F4EE93A5421"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.0:rc6:*:*:*:*:*:*", "matchCriteriaId": "BF0365B0-8E16-4F30-BD92-5DD538CC8135"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.0:rc7:*:*:*:*:*:*", "matchCriteriaId": "079505E8-2942-4C33-93D1-35ADA4C39E72"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.0.1:*:*:*:*:*:*:*", "matchCriteriaId": "38989541-2360-4E0A-AE5A-3D6144AA6114"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.0.2:*:*:*:*:*:*:*", "matchCriteriaId": "4E51646B-7A0E-40F3-B8C9-239C1DA81DD1"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.0.3:*:*:*:*:*:*:*", "matchCriteriaId": "42A8A507-F8E2-491C-A144-B2448A1DB26E"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.0.4:*:*:*:*:*:*:*", "matchCriteriaId": "901FC6F3-2C2A-4112-AE27-AB102BBE8DEE"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.0.5:*:*:*:*:*:*:*", "matchCriteriaId": "203AD334-DB9F-41B0-A4D1-A6C158EF8C40"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.0.6:*:*:*:*:*:*:*", "matchCriteriaId": "B3611753-E440-410F-8250-600C996A4B8E"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.0.7:*:*:*:*:*:*:*", "matchCriteriaId": "9739BB47-EEAF-42F1-A557-2AE2EA9526A3"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.0.8:*:*:*:*:*:*:*", "matchCriteriaId": "5A95E3BB-0AFC-4C2E-B9BE-C975E902A266"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.0.9:*:*:*:*:*:*:*", "matchCriteriaId": "482A6C9A-9B8E-4D1C-917A-F16370745E7C"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.0.10:*:*:*:*:*:*:*", "matchCriteriaId": "C6D87357-63E0-41D0-9F02-1BCBF9A77E63"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.0.11:*:*:*:*:*:*:*", "matchCriteriaId": "3765A2D6-2D78-4FB1-989E-D5106BFA3F5E"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.0.12:*:*:*:*:*:*:*", "matchCriteriaId": "F54257DB-7023-43C4-AC4D-9590B815CD92"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.0.13:*:*:*:*:*:*:*", "matchCriteriaId": "61FF5FCD-A4A1-4803-AC53-320A4C838AF6"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.0.14:*:*:*:*:*:*:*", "matchCriteriaId": "9F096553-064F-46A2-877B-F32F163A0F49"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.0.15:*:*:*:*:*:*:*", "matchCriteriaId": "C0D762D1-E3AD-40EA-8D39-83EEB51B5E85"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.0.16:*:*:*:*:*:*:*", "matchCriteriaId": "A6187D19-7148-4B87-AD7E-244FF9EE0FA6"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.0.17:*:*:*:*:*:*:*", "matchCriteriaId": "99AC64C2-E391-485C-9CD7-BA09C8FA5E63"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.0.18:*:*:*:*:*:*:*", "matchCriteriaId": "8CDA5E95-7805-441B-BEF7-4448EA45E964"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.0.19:*:*:*:*:*:*:*", "matchCriteriaId": "51561053-6C28-4F38-BC9B-3F7A7508EB72"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.0.20:*:*:*:*:*:*:*", "matchCriteriaId": "118F4A5B-C498-4FC3-BE28-50D18EBE4F22"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.0.21:*:*:*:*:*:*:*", "matchCriteriaId": "BD38EBE6-FE1A-4B55-9FB5-07952253B7A5"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.0.22:*:*:*:*:*:*:*", "matchCriteriaId": "3A491E47-82AD-4055-9444-2EC0D6715326"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.0.23:*:*:*:*:*:*:*", "matchCriteriaId": "13C5FD16-23B6-467F-9438-5B554922F974"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.0.24:*:*:*:*:*:*:*", "matchCriteriaId": "9C67235F-5B51-4BF7-89EC-4810F720246F"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.0.25:*:*:*:*:*:*:*", "matchCriteriaId": "08405DEF-05F4-45F0-AC95-DBF914A36D93"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.0.26:*:*:*:*:*:*:*", "matchCriteriaId": "1A7B9C4B-4A41-4175-9F07-191C1EE98C1F"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.0.27:*:*:*:*:*:*:*", "matchCriteriaId": "B306E0A8-4D4A-4895-8128-A500D30A7E0C"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.0.28:*:*:*:*:*:*:*", "matchCriteriaId": "295C839A-F34E-4853-A926-55EABC639412"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.0.29:*:*:*:*:*:*:*", "matchCriteriaId": "2AFD5F49-7EF9-4CFE-95BD-8FD19B500B0A"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.0.30:*:*:*:*:*:*:*", "matchCriteriaId": "00B3DDDD-B2F6-4753-BA38-65A24017857D"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.0.31:*:*:*:*:*:*:*", "matchCriteriaId": "33FCD39E-F4BF-432D-9CF9-F195CF5844F3"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.0.32:*:*:*:*:*:*:*", "matchCriteriaId": "C7308690-CB0D-4758-B80F-D2ADCD2A9D66"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.0.33:*:*:*:*:*:*:*", "matchCriteriaId": "313A470B-8A2B-478A-82B5-B27D2718331C"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.0.34:*:*:*:*:*:*:*", "matchCriteriaId": "83FF021E-07E3-41CC-AAE8-D99D7FF24B9D"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.0.35:*:*:*:*:*:*:*", "matchCriteriaId": "F72412E3-8DA9-4CC9-A426-B534202ADBA4"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.0.36:*:*:*:*:*:*:*", "matchCriteriaId": "FCAA9D7A-3C3E-4C0B-9D38-EA80E68C2E46"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.0.37:*:*:*:*:*:*:*", "matchCriteriaId": "4A9E3AE5-3FCF-4CBB-A30B-082BCFBFB0CB"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.0.38:*:*:*:*:*:*:*", "matchCriteriaId": "CF715657-4C3A-4392-B85D-1BBF4DE45D89"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.0.39:*:*:*:*:*:*:*", "matchCriteriaId": "4B63C618-AC3D-4EF7-AFDF-27B9BF482B78"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.0.40:*:*:*:*:*:*:*", "matchCriteriaId": "C33DA5A9-5E40-4365-9602-82FB4DCD15B2"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.0.41:*:*:*:*:*:*:*", "matchCriteriaId": "EFAFDB74-40BD-46FA-89AC-617EB2C7160B"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.0.42:*:*:*:*:*:*:*", "matchCriteriaId": "CF5F17DA-30A7-40CF-BD7C-CEDF06D64617"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.0.43:*:*:*:*:*:*:*", "matchCriteriaId": "71A276F5-BD9D-4C1B-90DF-9B0C15B6F7DF"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.0.44:*:*:*:*:*:*:*", "matchCriteriaId": "F8F6EBEC-3C29-444B-BB85-6EF239B59EC1"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.0.45:*:*:*:*:*:*:*", "matchCriteriaId": "FDB91302-FD18-44CF-A8A8-B31483328539"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.0.46:*:*:*:*:*:*:*", "matchCriteriaId": "9B81DC2B-46FA-4640-AD6C-2A404D94BA0B"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.0.47:*:*:*:*:*:*:*", "matchCriteriaId": "BA6A1663-BC4C-4FC9-B5EB-A52EDED17B26"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.0.48:*:*:*:*:*:*:*", "matchCriteriaId": "69C33D6C-6B9F-49F4-B505-E7B589CDEC50"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.0.49:*:*:*:*:*:*:*", "matchCriteriaId": "C464796B-2F31-4159-A132-82A0C74137B7"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.0.50:*:*:*:*:*:*:*", "matchCriteriaId": "1D6C6E46-FE29-4D2D-A0EC-43DA5112BCC3"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.0.51:*:*:*:*:*:*:*", "matchCriteriaId": "1A370E91-73A1-4D62-8E7B-696B920203F8"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.0.52:*:*:*:*:*:*:*", "matchCriteriaId": "340197CD-9645-4B7E-B976-F3F5A7D4C5BE"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.0.53:*:*:*:*:*:*:*", "matchCriteriaId": "96030636-0C4A-4A10-B768-525D6A0E18CB"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.0.54:*:*:*:*:*:*:*", "matchCriteriaId": "A42D8419-914F-4AD6-B0E9-C1290D514FF1"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.0.55:*:*:*:*:*:*:*", "matchCriteriaId": "F4E2C88B-42EA-4F4F-B1F6-A9332EC6888B"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.0.56:*:*:*:*:*:*:*", "matchCriteriaId": "2449D13B-3314-4182-832F-03F6B11AA31F"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.0.57:*:*:*:*:*:*:*", "matchCriteriaId": "9A35B66C-F050-4462-A58E-FEE061B5582E"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.0.58:*:*:*:*:*:*:*", "matchCriteriaId": "1B551164-0167-49BB-A3AE-4034BDA3DCB4"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.0.59:*:*:*:*:*:*:*", "matchCriteriaId": "7244278E-49B6-4405-A14C-F3540C8F5AF8"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.0.60:*:*:*:*:*:*:*", "matchCriteriaId": "B4C3E4B8-7274-4ABB-B7CE-6A39C183CE18"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.0.61:*:*:*:*:*:*:*", "matchCriteriaId": "6501EDB9-4847-47F8-90EE-B295626E4CDC"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.0.62:*:*:*:*:*:*:*", "matchCriteriaId": "2D676D48-7521-45E2-8563-6B966FF86A35"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.0.63:*:*:*:*:*:*:*", "matchCriteriaId": "3B69FA17-0AB9-4986-A5A7-2A4C1DD24222"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.0.64:*:*:*:*:*:*:*", "matchCriteriaId": "7BC35593-96C7-41F0-B738-1568F8129121"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.0.65:*:*:*:*:*:*:*", "matchCriteriaId": "38D23794-0E7C-4FA5-A7A8-CF940E3FA962"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.0.66:*:*:*:*:*:*:*", "matchCriteriaId": "008E1E7D-4C20-4560-9288-EF532ADB0029"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.0.67:*:*:*:*:*:*:*", "matchCriteriaId": "3B3A7044-A92E-47A9-A7BD-35E5B575F5FD"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.0.68:*:*:*:*:*:*:*", "matchCriteriaId": "783E2980-B6AB-489E-B157-B6A2E10A32CA"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.1:*:*:*:*:*:*:*", "matchCriteriaId": "3DFFE5A6-6A67-4992-84A3-C0F05FACDEAD"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.1:rc1:*:*:*:*:*:*", "matchCriteriaId": "13BBD2A3-AE10-48B9-8776-4FB1CAC37D44"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.1:rc2:*:*:*:*:*:*", "matchCriteriaId": "B25680CC-8918-4F27-8D7E-A6579215450B"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.1:rc3:*:*:*:*:*:*", "matchCriteriaId": "92C48B4C-410C-4BA8-A28A-B2E928320FCC"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.1:rc4:*:*:*:*:*:*", "matchCriteriaId": "CB447523-855B-461E-8197-95169BE86EB0"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.1.1:*:*:*:*:*:*:*", "matchCriteriaId": "B155BBDF-6DF6-4FF5-9C41-D8A5266DCC67"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.1.2:*:*:*:*:*:*:*", "matchCriteriaId": "28476DEC-9630-4B40-9D4D-9BC151DC4CA4"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.1.3:*:*:*:*:*:*:*", "matchCriteriaId": "5646880A-2355-4BDD-89E7-825863A0311F"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.1.4:*:*:*:*:*:*:*", "matchCriteriaId": "7FF99148-267A-46F8-9927-A9082269BAF6"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.1.5:*:*:*:*:*:*:*", "matchCriteriaId": "A783C083-5D9C-48F9-B5A6-A97A9604FB19"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.1.6:*:*:*:*:*:*:*", "matchCriteriaId": "2B817A24-03AC-46CD-BEFA-505457FD2A5D"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.1.7:*:*:*:*:*:*:*", "matchCriteriaId": "51CF1BCE-090E-4B70-BA16-ACB74411293B"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.1.8:*:*:*:*:*:*:*", "matchCriteriaId": "187AAD67-10D7-4B57-B4C6-00443E246AF3"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.1.9:*:*:*:*:*:*:*", "matchCriteriaId": "F341CE88-C5BC-4CDD-9CB5-B6BAD7152E63"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.1.10:*:*:*:*:*:*:*", "matchCriteriaId": "37ACE2A6-C229-4236-8E9F-235F008F3AA0"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.2:*:*:*:*:*:*:*", "matchCriteriaId": "D3220B70-917F-4F9F-8A3B-2BF581281E8D"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.2:rc2:*:*:*:*:*:*", "matchCriteriaId": "99372D07-C06A-41FA-9843-6D57F99AB5AF"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.2:rc3:*:*:*:*:*:*", "matchCriteriaId": "2B9DC110-D260-4DB4-B8B0-EF1D160ADA07"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.2:rc4:*:*:*:*:*:*", "matchCriteriaId": "6192FE84-4D53-40D4-AF61-78CE7136141A"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.2:rc5:*:*:*:*:*:*", "matchCriteriaId": "42FEF3CF-1302-45EB-89CC-3786FE4BAC1F"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.2:rc6:*:*:*:*:*:*", "matchCriteriaId": "AE6A6B58-2C89-4DE4-BA57-78100818095C"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.2:rc7:*:*:*:*:*:*", "matchCriteriaId": "1D467F87-2F13-4D26-9A93-E0BA526FEA24"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.2.1:*:*:*:*:*:*:*", "matchCriteriaId": "FE348F7B-02DE-47D5-8011-F83DA9426021"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.2.2:*:*:*:*:*:*:*", "matchCriteriaId": "E91594EA-F0A3-41B3-A9C6-F7864FC2F229"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.2.3:*:*:*:*:*:*:*", "matchCriteriaId": "9E1ECCDB-0208-48F6-B44F-16CC0ECE3503"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.2.4:*:*:*:*:*:*:*", "matchCriteriaId": "FBA8B5DE-372E-47E0-A0F6-BE286D509CC3"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.2.5:*:*:*:*:*:*:*", "matchCriteriaId": "9A1CA083-2CF8-45AE-9E15-1AA3A8352E3B"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.2.6:*:*:*:*:*:*:*", "matchCriteriaId": "19D69A49-5290-4C5F-8157-719AD58D253D"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.2.7:*:*:*:*:*:*:*", "matchCriteriaId": "290BD969-42E7-47B0-B21B-06DE4865432C"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.2.8:*:*:*:*:*:*:*", "matchCriteriaId": "23A9E29E-DE78-4C73-9FBD-C2410F5FC8B8"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.2.9:*:*:*:*:*:*:*", "matchCriteriaId": "018434C9-E75F-45CB-A169-DAB4B1D864D7"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.2.10:*:*:*:*:*:*:*", "matchCriteriaId": "DC0AC68F-EC58-4C4F-8CBC-A59ECC00CCDE"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.2.11:*:*:*:*:*:*:*", "matchCriteriaId": "C123C844-F6D7-471E-A62E-F756042FB1CD"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.2.12:*:*:*:*:*:*:*", "matchCriteriaId": "A11C38BB-7FA2-49B0-AAC9-83DB387A06DB"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.2.13:*:*:*:*:*:*:*", "matchCriteriaId": "61F3733C-E5F6-4855-B471-DF3FB823613B"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.2.14:*:*:*:*:*:*:*", "matchCriteriaId": "1DDCA75F-9A06-4457-9A45-38A38E7F7086"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.2.15:*:*:*:*:*:*:*", "matchCriteriaId": "7AEA837E-7864-4003-8DB7-111ED710A7E1"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.2.16:*:*:*:*:*:*:*", "matchCriteriaId": "B6FE471F-2D1F-4A1D-A197-7E46B75787E1"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.2.17:*:*:*:*:*:*:*", "matchCriteriaId": "FDA9E6AB-58DC-4EC5-A25C-11F9D0B38BF7"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.2.18:*:*:*:*:*:*:*", "matchCriteriaId": "DC6B8DB3-B05B-41A2-B091-342D66AAE8F5"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.2.19:*:*:*:*:*:*:*", "matchCriteriaId": "958F0FF8-33EF-4A71-A0BD-572C85211DBA"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.2.20:*:*:*:*:*:*:*", "matchCriteriaId": "FBA39F48-B02F-4C48-B304-DA9CCA055244"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.2.21:*:*:*:*:*:*:*", "matchCriteriaId": "1FF841F3-48A7-41D7-9C45-A8170435A5EB"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.2.22:*:*:*:*:*:*:*", "matchCriteriaId": "EF506916-A6DC-4B1E-90E5-959492AF55F4"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.2.23:*:*:*:*:*:*:*", "matchCriteriaId": "B3CDAD1F-2C6A-48C0-8FAB-C2659373FA25"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.2.24:*:*:*:*:*:*:*", "matchCriteriaId": "4FFE4B22-C96A-43D0-B993-F51EDD9C5E0E"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.2.25:*:*:*:*:*:*:*", "matchCriteriaId": "F571CC8B-B212-4553-B463-1DB01D616E8A"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.2.26:*:*:*:*:*:*:*", "matchCriteriaId": "84E3E151-D437-48ED-A529-731EEFF88567"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.2.27:*:*:*:*:*:*:*", "matchCriteriaId": "E9E3EA3C-CCA5-4433-86E0-3D02C4757A0A"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.2.28:*:*:*:*:*:*:*", "matchCriteriaId": "F7AC4F7D-9FA6-4CF1-B2E9-70BF7D4D177C"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.2.29:*:*:*:*:*:*:*", "matchCriteriaId": "3CE3A80D-9648-43CC-8F99-D741ED6552BF"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.2.30:*:*:*:*:*:*:*", "matchCriteriaId": "C8A98C03-A465-41B4-A551-A26FEC7FFD94"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.3:*:*:*:*:*:*:*", "matchCriteriaId": "AFB76697-1C2F-48C0-9B14-517EC053D4B3"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.3:rc1:*:*:*:*:*:*", "matchCriteriaId": "BED88DFD-1DC5-4505-A441-44ECDEF0252D"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.3:rc2:*:*:*:*:*:*", "matchCriteriaId": "DBFD2ACD-728A-4082-BB6A-A1EF6E58E47D"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.3:rc3:*:*:*:*:*:*", "matchCriteriaId": "C31B0E51-F62D-4053-B04F-FC4D5BC373D2"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.3:rc4:*:*:*:*:*:*", "matchCriteriaId": "A914303E-1CB6-4AAD-9F5F-DE5433C4E814"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.3:rc5:*:*:*:*:*:*", "matchCriteriaId": "203BBA69-90B2-4C5E-8023-C14180742421"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.3:rc6:*:*:*:*:*:*", "matchCriteriaId": "0DBFAB53-B889-4028-AC0E-7E165B152A18"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.3:rc7:*:*:*:*:*:*", "matchCriteriaId": "FE409AEC-F677-4DEF-8EB7-2C35809043CE"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.3.1:*:*:*:*:*:*:*", "matchCriteriaId": "578EC12B-402F-4AD4-B8F8-C9B2CAB06891"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.3.2:*:*:*:*:*:*:*", "matchCriteriaId": "877002ED-8097-4BB4-BB88-6FC6306C38B2"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.3.3:*:*:*:*:*:*:*", "matchCriteriaId": "76294CE3-D72C-41D5-9E0F-B693D0042699"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.3.4:*:*:*:*:*:*:*", "matchCriteriaId": "916E97D4-1FAB-42F5-826B-653B1C0909A8"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.3.5:*:*:*:*:*:*:*", "matchCriteriaId": "33FD2217-C5D0-48C1-AD74-3527127FEF9C"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.3.6:*:*:*:*:*:*:*", "matchCriteriaId": "2E92971F-B629-4E0A-9A50-8B235F9704B8"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.3.7:*:*:*:*:*:*:*", "matchCriteriaId": "EDD3A069-3829-4EE2-9D5A-29459F29D4C1"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.3.8:*:*:*:*:*:*:*", "matchCriteriaId": "A4A0964C-CEB2-41D7-A69C-1599B05B6171"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.4:*:*:*:*:*:*:*", "matchCriteriaId": "0F960FA6-F904-4A4E-B483-44C70090E9A1"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.4:rc1:*:*:*:*:*:*", "matchCriteriaId": "261C1B41-C9E0-414F-8368-51C0C0B8AD38"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.4:rc2:*:*:*:*:*:*", "matchCriteriaId": "5CCA261D-2B97-492F-89A0-5F209A804350"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.4:rc3:*:*:*:*:*:*", "matchCriteriaId": "1B1C0C68-9194-473F-BE5E-EC7F184899FA"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.4:rc4:*:*:*:*:*:*", "matchCriteriaId": "D7A6AC9E-BEA6-44B0-B3B3-F0F94E32424A"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.4:rc5:*:*:*:*:*:*", "matchCriteriaId": "16038328-9399-4B85-B777-BA4757D02C9B"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.4:rc6:*:*:*:*:*:*", "matchCriteriaId": "16CA2757-FA8D-43D9-96E8-D3C0EB6E1DEF"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.4:rc7:*:*:*:*:*:*", "matchCriteriaId": "E8CB5481-5EAE-401E-BD7E-D3095CCA9E94"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.4.1:*:*:*:*:*:*:*", "matchCriteriaId": "A0F36FAC-141D-476D-84C5-A558C199F904"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.4.2:*:*:*:*:*:*:*", "matchCriteriaId": "51D64824-25F6-4761-BD6A-29038A143744"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.4.3:*:*:*:*:*:*:*", "matchCriteriaId": "E284C8A1-740F-454D-A774-99CD3A21B594"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.4.4:*:*:*:*:*:*:*", "matchCriteriaId": "C70D72AE-0CBF-4324-9935-57E28EC6279C"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.4.5:*:*:*:*:*:*:*", "matchCriteriaId": "F674B06B-7E86-4E41-9126-8152D0DDABAE"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.4.6:*:*:*:*:*:*:*", "matchCriteriaId": "7039B3EC-8B22-413E-B582-B4BEC6181241"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.4.7:*:*:*:*:*:*:*", "matchCriteriaId": "35CF1DD2-80B9-4476-8963-5C3EF52B33F4"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.4.8:*:*:*:*:*:*:*", "matchCriteriaId": "BFB0B05B-A5CE-4B9C-AE7F-83062868D35B"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.4.10:*:*:*:*:*:*:*", "matchCriteriaId": "7DA94F50-2A62-4300-BF4D-A342AAE35629"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.4.11:*:*:*:*:*:*:*", "matchCriteriaId": "252D937B-50DC-444F-AE73-5FCF6203DF27"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.4.12:*:*:*:*:*:*:*", "matchCriteriaId": "F6D8EE51-02C1-47BC-A92C-0A8ABEFD28FF"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.4.13:*:*:*:*:*:*:*", "matchCriteriaId": "7F20A5D7-3B38-4911-861A-04C8310D5916"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.4.14:*:*:*:*:*:*:*", "matchCriteriaId": "D472DE3A-71D8-4F40-9DDE-85929A2B047D"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.4.15:*:*:*:*:*:*:*", "matchCriteriaId": "B2AED943-65A8-4FDB-BBD0-CCEF8682A48C"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.4.16:*:*:*:*:*:*:*", "matchCriteriaId": "D4640185-F3D8-4575-A71D-4C889A93DE2C"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.4.17:*:*:*:*:*:*:*", "matchCriteriaId": "144CCF7C-025E-4879-B2E7-ABB8E4390BE5"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.4.18:*:*:*:*:*:*:*", "matchCriteriaId": "B6FAA052-0B2B-40CE-8C98-919B8D08A5ED"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.4.19:*:*:*:*:*:*:*", "matchCriteriaId": "4B5A53DE-9C83-4A6B-96F3-23C03BF445D9"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.4.20:*:*:*:*:*:*:*", "matchCriteriaId": "063EB879-CB05-4E33-AA90-9E43516839B5"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.4.21:*:*:*:*:*:*:*", "matchCriteriaId": "2D25764F-4B02-4C65-954E-8C7D6632DE00"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.4.22:*:*:*:*:*:*:*", "matchCriteriaId": "F31F5BF3-CD0A-465C-857F-273841BCD28A"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.4.23:*:*:*:*:*:*:*", "matchCriteriaId": "FF302C8A-079B-42B9-B455-CD9083BFA067"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.4.24:*:*:*:*:*:*:*", "matchCriteriaId": "744999C0-33D3-4363-B3DB-E0D02CDD3918"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.4.25:*:*:*:*:*:*:*", "matchCriteriaId": "C2E77A76-2A60-45D8-9337-867BC22C5110"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.4.26:*:*:*:*:*:*:*", "matchCriteriaId": "C9F4AAE7-C870-46B7-B559-2949737BE777"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.4.27:*:*:*:*:*:*:*", "matchCriteriaId": "20FA2824-20B0-48B8-BB0A-4904C1D3E8AA"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.4.28:*:*:*:*:*:*:*", "matchCriteriaId": "9F9B347E-61AC-419F-9701-B862BBFA46F2"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.4.29:*:*:*:*:*:*:*", "matchCriteriaId": "989F351C-8B7C-4C1B-AFA2-AE9431576368"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.4.30:*:*:*:*:*:*:*", "matchCriteriaId": "8D22172A-9FA7-42E0-8451-165D8E47A573"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.4.31:*:*:*:*:*:*:*", "matchCriteriaId": "CE31624C-94F9-45D8-9B4A-D0028F10602F"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.4.32:*:*:*:*:*:*:*", "matchCriteriaId": "70967A83-28F6-4568-9ADA-6EF232E5BBC2"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.5.1:*:*:*:*:*:*:*", "matchCriteriaId": "962B0C45-AB29-4383-AC16-C6E8245D0FF7"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.5.2:*:*:*:*:*:*:*", "matchCriteriaId": "A0EE126B-74B2-4F79-BFE1-3DC169F3F9B2"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.5.3:*:*:*:*:*:*:*", "matchCriteriaId": "392075E0-A9C7-4B4A-90F9-7F1ADFF5EFA7"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.5.4:*:*:*:*:*:*:*", "matchCriteriaId": "ECC66968-06F0-4874-A95A-A292C36E45C1"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.5.5:*:*:*:*:*:*:*", "matchCriteriaId": "5FE986E6-1068-4E1B-8EAB-DF1EAF32B4E3"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.5.6:*:*:*:*:*:*:*", "matchCriteriaId": "543E8536-1A8E-4E76-B89F-1B1F9F26FAB8"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.5.7:*:*:*:*:*:*:*", "matchCriteriaId": "EC2B45E3-31E1-4B46-85FA-3A84E75B8F84"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.6:*:*:*:*:*:*:*", "matchCriteriaId": "DDB8CC75-D3EE-417C-A83D-CB6D666FE595"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.6.1:*:*:*:*:*:*:*", "matchCriteriaId": "09A072F1-7BEE-4236-ACBB-55DB8FEF4A03"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.6.2:*:*:*:*:*:*:*", "matchCriteriaId": "E19D5A58-17D6-4502-A57A-70B2F84817A4"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.6.3:*:*:*:*:*:*:*", "matchCriteriaId": "D58BA035-1204-4DFA-98A1-12111FB6222E"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.6.4:*:*:*:*:*:*:*", "matchCriteriaId": "A17F2E87-8EB8-476A-B5B5-9AE5CF53D9FE"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.6.5:*:*:*:*:*:*:*", "matchCriteriaId": "A8CCC101-5852-4299-9B67-EA1B149D58C0"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.6.6:*:*:*:*:*:*:*", "matchCriteriaId": "B8074D32-C252-4AD3-A579-1C5EDDD7014B"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.6.7:*:*:*:*:*:*:*", "matchCriteriaId": "962AA802-8179-4606-AAC0-9363BAEABC9F"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.6.8:*:*:*:*:*:*:*", "matchCriteriaId": "1286C858-D5A2-45F3-86D1-E50FE53FB23C"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.6.9:*:*:*:*:*:*:*", "matchCriteriaId": "5AC4A13E-F560-4D01-98A3-E2A2B82EB25B"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.6.10:*:*:*:*:*:*:*", "matchCriteriaId": "942C462A-5398-4BB9-A792-598682E1FEF2"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.6.11:*:*:*:*:*:*:*", "matchCriteriaId": "B852F7E0-0282-483D-BB4D-18CB7A4F1392"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.7:*:*:*:*:*:*:*", "matchCriteriaId": "53ED9A31-99CC-41C8-8B72-5B2A9B49AA6C"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.7.1:*:*:*:*:*:*:*", "matchCriteriaId": "EFD646BC-62F7-47CF-B0BE-768F701F7D9A"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.7.2:*:*:*:*:*:*:*", "matchCriteriaId": "F43D418E-87C1-4C83-9FF1-4F45B4F452DD"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.7.3:*:*:*:*:*:*:*", "matchCriteriaId": "680D0E00-F29A-487C-8770-8E7EAC672B7C"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.7.4:*:*:*:*:*:*:*", "matchCriteriaId": "2DCA96A4-A836-4E94-A39C-3AD3EA1D9611"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.7.5:*:*:*:*:*:*:*", "matchCriteriaId": "753C05E3-B603-4E36-B9BA-FAEDCBF62A7D"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.7.6:*:*:*:*:*:*:*", "matchCriteriaId": "E385C2E0-B9F1-4564-8E6D-56FD9E762405"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.7.7:*:*:*:*:*:*:*", "matchCriteriaId": "041335D4-05E1-4004-9381-28AAD5994B47"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.7.8:*:*:*:*:*:*:*", "matchCriteriaId": "370F2AE5-3DBC-46B9-AC70-F052C9229C00"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.7.9:*:*:*:*:*:*:*", "matchCriteriaId": "7A971BE3-259D-4494-BBC5-12793D92DB57"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.7.10:*:*:*:*:*:*:*", "matchCriteriaId": "8E4719A6-FDEA-4714-A830-E23A52AE90BC"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.8.0:*:*:*:*:*:*:*", "matchCriteriaId": "1A6E41FB-38CE-49F2-B796-9A5AA648E73F"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.8.1:*:*:*:*:*:*:*", "matchCriteriaId": "93523FE1-5993-46CB-9299-7C8C1A04E873"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.8.2:*:*:*:*:*:*:*", "matchCriteriaId": "27ADC356-6BE9-43A3-9E0B-393DC4B1559A"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.8.3:*:*:*:*:*:*:*", "matchCriteriaId": "4F543D23-1774-4D14-A7D1-AD49EDEA94DD"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.8.4:*:*:*:*:*:*:*", "matchCriteriaId": "FC323F58-CA00-4C3C-BA4D-CC2C0A6E5F43"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.8.5:*:*:*:*:*:*:*", "matchCriteriaId": "FEA0B2E3-668D-40ED-9D3D-709EB6449F8D"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.8.6:*:*:*:*:*:*:*", "matchCriteriaId": "3431B258-4EC8-4E7F-87BB-4D934880601E"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.8.7:*:*:*:*:*:*:*", "matchCriteriaId": "1B09FA1E-8B28-4F2A-BA7E-8E1C40365970"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.8.8:*:*:*:*:*:*:*", "matchCriteriaId": "91917120-9D68-41C0-8B5D-85C256BC6200"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.8.9:*:*:*:*:*:*:*", "matchCriteriaId": "AAD268A0-096C-4C31-BEC5-D47F5149D462"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.8.10:*:*:*:*:*:*:*", "matchCriteriaId": "32BD2427-C47F-4660-A1D9-448E500EF5B9"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.8.11:*:*:*:*:*:*:*", "matchCriteriaId": "02048CE5-81C7-4DFB-BC40-CE4C86B7E022"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.8.12:*:*:*:*:*:*:*", "matchCriteriaId": "934D2B37-0575-4A75-B00B-0028316D6DF0"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.8.13:*:*:*:*:*:*:*", "matchCriteriaId": "06754C21-995C-4850-A4DC-F21826C0F8C5"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.9:rc1:*:*:*:*:*:*", "matchCriteriaId": "42633FF9-FB0C-4095-B4A1-8D623A98683B"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.9:rc2:*:*:*:*:*:*", "matchCriteriaId": "08C04619-89A2-4B15-82A2-48BCC662C1F1"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.9:rc3:*:*:*:*:*:*", "matchCriteriaId": "5B039196-7159-476C-876A-C61242CC41DA"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.9:rc4:*:*:*:*:*:*", "matchCriteriaId": "3A9E0457-53C9-44DD-ACFB-31EE1D1E060E"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.9:rc5:*:*:*:*:*:*", "matchCriteriaId": "BEE406E7-87BA-44BA-BF61-673E6CC44A2F"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.9:rc6:*:*:*:*:*:*", "matchCriteriaId": "29FBA173-658F-45DC-8205-934CACD67166"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.9:rc7:*:*:*:*:*:*", "matchCriteriaId": "139700F0-BA32-40CF-B9DF-C9C450384FDE"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.9.0:*:*:*:*:*:*:*", "matchCriteriaId": "E578085C-3968-4543-BEBA-EE3C3CB4FA02"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.9.1:*:*:*:*:*:*:*", "matchCriteriaId": "4DCFA441-68FB-4559-A245-FF0B79DE43CA"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.9.2:*:*:*:*:*:*:*", "matchCriteriaId": "8C2508D8-6571-4B81-A0D7-E494CCD039CE"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.9.3:*:*:*:*:*:*:*", "matchCriteriaId": "8B516926-5E86-4C0A-85F3-F64E1FCDA249"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.9.4:*:*:*:*:*:*:*", "matchCriteriaId": "069D774D-79BE-479F-BF4E-F021AD808114"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.9.10:*:*:*:*:*:*:*", "matchCriteriaId": "C72FA8A6-60A6-4486-A245-7BEF8B2A2711"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.9.11:*:*:*:*:*:*:*", "matchCriteriaId": "0A498D90-BB99-405E-9FA6-1FBFE179787E"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.10.0:*:*:*:*:*:*:*", "matchCriteriaId": "A91DB1A2-8160-46FE-AB5F-ECABD9A384F4"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.10.1:*:*:*:*:*:*:*", "matchCriteriaId": "D0D32776-8ADB-4E79-846A-C0C99FED19E0"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.10.2:*:*:*:*:*:*:*", "matchCriteriaId": "B7D01673-D13F-487F-81B6-1279C187277E"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.10.3:*:*:*:*:*:*:*", "matchCriteriaId": "ADB27A3E-78E4-40F7-9716-A1099B0D85FB"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.10.5:*:*:*:*:*:*:*", "matchCriteriaId": "6FE127AC-E61D-427A-B998-D60DF5AABA21"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.10.6:*:*:*:*:*:*:*", "matchCriteriaId": "3819FF99-AEC5-4466-8542-D395419E4308"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.10.7:*:*:*:*:*:*:*", "matchCriteriaId": "E621FA1A-464B-4D2A-A0D6-EDA475A3709B"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.10.8:*:*:*:*:*:*:*", "matchCriteriaId": "B760B422-EA11-43AB-B6D2-CA54E7229663"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.10.9:*:*:*:*:*:*:*", "matchCriteriaId": "D2CA7BBC-917C-4F31-A442-465C30444836"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.10.10:*:*:*:*:*:*:*", "matchCriteriaId": "AE778000-4FD5-4032-86CE-5930EF4CB7C1"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.10.11:*:*:*:*:*:*:*", "matchCriteriaId": "B3344EEB-F037-48FE-81DC-67F6384F7D9A"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.10.12:*:*:*:*:*:*:*", "matchCriteriaId": "0244B0CA-9C67-4F06-BFBA-1F257112AC08"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.11:*:*:*:*:*:*:*", "matchCriteriaId": "639E3A57-A9E7-40E6-8929-81CCC0060EFB"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.11.1:*:*:*:*:*:*:*", "matchCriteriaId": "07012ADD-F521-40A8-B067-E87C2238A3D2"}]}]}], "references": [{"url": "http://git.kernel.org/?p=linux/kernel/git/torvalds/linux-2.6.git%3Ba=commit%3Bh=604c499cbbcc3d5fe5fb8d53306aa0fae1990109", "source": "secalert@redhat.com"}, {"url": "http://people.canonical.com/~ubuntu-security/cve/2013/CVE-2013-2140.html", "source": "secalert@redhat.com"}, {"url": "http://www.kernel.org/pub/linux/kernel/v3.x/ChangeLog-3.10.5", "source": "secalert@redhat.com"}, {"url": "http://www.openwall.com/lists/oss-security/2013/06/05/21", "source": "secalert@redhat.com"}, {"url": "http://www.ubuntu.com/usn/USN-1938-1", "source": "secalert@redhat.com"}, {"url": "http://www.ubuntu.com/usn/USN-1943-1", "source": "secalert@redhat.com"}, {"url": "http://www.ubuntu.com/usn/USN-1944-1", "source": "secalert@redhat.com"}, {"url": "http://www.ubuntu.com/usn/USN-1945-1", "source": "secalert@redhat.com"}, {"url": "http://www.ubuntu.com/usn/USN-1946-1", "source": "secalert@redhat.com"}, {"url": "http://www.ubuntu.com/usn/USN-1947-1", "source": "secalert@redhat.com"}, {"url": "http://www.ubuntu.com/usn/USN-2038-1", "source": "secalert@redhat.com"}, {"url": "http://www.ubuntu.com/usn/USN-2039-1", "source": "secalert@redhat.com"}, {"url": "https://bugzilla.redhat.com/show_bug.cgi?id=971146", "source": "secalert@redhat.com"}, {"url": "https://github.com/torvalds/linux/commit/604c499cbbcc3d5fe5fb8d53306aa0fae1990109", "source": "secalert@redhat.com", "tags": ["Exploit", "Patch"]}]}, "github_commit_url": "https://github.com/torvalds/linux/commit/604c499cbbcc3d5fe5fb8d53306aa0fae1990109"}}
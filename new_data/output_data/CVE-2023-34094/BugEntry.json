{"buggy_code": ["# -*- coding:utf-8 -*-\nimport os\nimport logging\nimport sys\n\nimport gradio as gr\n\nfrom modules import config\nfrom modules.config import *\nfrom modules.utils import *\nfrom modules.presets import *\nfrom modules.overwrites import *\nfrom modules.models.models import get_model\n\n\ngr.Chatbot._postprocess_chat_messages = postprocess_chat_messages\ngr.Chatbot.postprocess = postprocess\n\nwith open(\"assets/custom.css\", \"r\", encoding=\"utf-8\") as f:\n    customCSS = f.read()\n\ndef create_new_model():\n    return get_model(model_name = MODELS[DEFAULT_MODEL], access_key = my_api_key)[0]\n\nwith gr.Blocks(css=customCSS, theme=small_and_beautiful_theme) as demo:\n    user_name = gr.State(\"\")\n    promptTemplates = gr.State(load_template(get_template_names(plain=True)[0], mode=2))\n    user_question = gr.State(\"\")\n    assert type(my_api_key)==str\n    user_api_key = gr.State(my_api_key)\n    current_model = gr.State(create_new_model)\n\n    topic = gr.State(i18n(\"\u672a\u547d\u540d\u5bf9\u8bdd\u5386\u53f2\u8bb0\u5f55\"))\n\n    with gr.Row():\n        gr.HTML(CHUANHU_TITLE, elem_id=\"app_title\")\n        status_display = gr.Markdown(get_geoip(), elem_id=\"status_display\")\n    with gr.Row(elem_id=\"float_display\"):\n        user_info = gr.Markdown(value=\"getting user info...\", elem_id=\"user_info\")\n\n    with gr.Row().style(equal_height=True):\n        with gr.Column(scale=5):\n            with gr.Row():\n                chatbot = gr.Chatbot(label=\"Chuanhu Chat\", elem_id=\"chuanhu_chatbot\").style(height=\"100%\")\n            with gr.Row():\n                with gr.Column(min_width=225, scale=12):\n                    user_input = gr.Textbox(\n                        elem_id=\"user_input_tb\",\n                        show_label=False, placeholder=i18n(\"\u5728\u8fd9\u91cc\u8f93\u5165\")\n                    ).style(container=False)\n                with gr.Column(min_width=42, scale=1):\n                    submitBtn = gr.Button(value=\"\", variant=\"primary\", elem_id=\"submit_btn\")\n                    cancelBtn = gr.Button(value=\"\", variant=\"secondary\", visible=False, elem_id=\"cancel_btn\")\n            with gr.Row():\n                emptyBtn = gr.Button(\n                    i18n(\"\ud83e\uddf9 \u65b0\u7684\u5bf9\u8bdd\"), elem_id=\"empty_btn\"\n                )\n                retryBtn = gr.Button(i18n(\"\ud83d\udd04 \u91cd\u65b0\u751f\u6210\"))\n                delFirstBtn = gr.Button(i18n(\"\ud83d\uddd1\ufe0f \u5220\u9664\u6700\u65e7\u5bf9\u8bdd\"))\n                delLastBtn = gr.Button(i18n(\"\ud83d\uddd1\ufe0f \u5220\u9664\u6700\u65b0\u5bf9\u8bdd\"))\n                with gr.Row(visible=False) as like_dislike_area:\n                    with gr.Column(min_width=20, scale=1):\n                        likeBtn = gr.Button(i18n(\"\ud83d\udc4d\"))\n                    with gr.Column(min_width=20, scale=1):\n                        dislikeBtn = gr.Button(i18n(\"\ud83d\udc4e\"))\n\n        with gr.Column():\n            with gr.Column(min_width=50, scale=1):\n                with gr.Tab(label=i18n(\"\u6a21\u578b\")):\n                    keyTxt = gr.Textbox(\n                        show_label=True,\n                        placeholder=f\"Your API-key...\",\n                        value=hide_middle_chars(user_api_key.value),\n                        type=\"password\",\n                        visible=not HIDE_MY_KEY,\n                        label=\"API-Key\",\n                    )\n                    if multi_api_key:\n                        usageTxt = gr.Markdown(i18n(\"\u591a\u8d26\u53f7\u6a21\u5f0f\u5df2\u5f00\u542f\uff0c\u65e0\u9700\u8f93\u5165key\uff0c\u53ef\u76f4\u63a5\u5f00\u59cb\u5bf9\u8bdd\"), elem_id=\"usage_display\", elem_classes=\"insert_block\")\n                    else:\n                        usageTxt = gr.Markdown(i18n(\"**\u53d1\u9001\u6d88\u606f** \u6216 **\u63d0\u4ea4key** \u4ee5\u663e\u793a\u989d\u5ea6\"), elem_id=\"usage_display\", elem_classes=\"insert_block\")\n                    model_select_dropdown = gr.Dropdown(\n                        label=i18n(\"\u9009\u62e9\u6a21\u578b\"), choices=MODELS, multiselect=False, value=MODELS[DEFAULT_MODEL], interactive=True\n                    )\n                    lora_select_dropdown = gr.Dropdown(\n                        label=i18n(\"\u9009\u62e9LoRA\u6a21\u578b\"), choices=[], multiselect=False, interactive=True, visible=False\n                    )\n                    with gr.Row():\n                        single_turn_checkbox = gr.Checkbox(label=i18n(\"\u5355\u8f6e\u5bf9\u8bdd\"), value=False)\n                        use_websearch_checkbox = gr.Checkbox(label=i18n(\"\u4f7f\u7528\u5728\u7ebf\u641c\u7d22\"), value=False)\n                        # render_latex_checkbox = gr.Checkbox(label=i18n(\"\u6e32\u67d3LaTeX\u516c\u5f0f\"), value=render_latex, interactive=True, elem_id=\"render_latex_checkbox\")\n                    language_select_dropdown = gr.Dropdown(\n                        label=i18n(\"\u9009\u62e9\u56de\u590d\u8bed\u8a00\uff08\u9488\u5bf9\u641c\u7d22&\u7d22\u5f15\u529f\u80fd\uff09\"),\n                        choices=REPLY_LANGUAGES,\n                        multiselect=False,\n                        value=REPLY_LANGUAGES[0],\n                    )\n                    index_files = gr.Files(label=i18n(\"\u4e0a\u4f20\"), type=\"file\")\n                    two_column = gr.Checkbox(label=i18n(\"\u53cc\u680fpdf\"), value=advance_docs[\"pdf\"].get(\"two_column\", False))\n                    summarize_btn = gr.Button(i18n(\"\u603b\u7ed3\"))\n                    # TODO: \u516c\u5f0focr\n                    # formula_ocr = gr.Checkbox(label=i18n(\"\u8bc6\u522b\u516c\u5f0f\"), value=advance_docs[\"pdf\"].get(\"formula_ocr\", False))\n\n                with gr.Tab(label=\"Prompt\"):\n                    systemPromptTxt = gr.Textbox(\n                        show_label=True,\n                        placeholder=i18n(\"\u5728\u8fd9\u91cc\u8f93\u5165System Prompt...\"),\n                        label=\"System prompt\",\n                        value=INITIAL_SYSTEM_PROMPT,\n                        lines=10,\n                    ).style(container=False)\n                    with gr.Accordion(label=i18n(\"\u52a0\u8f7dPrompt\u6a21\u677f\"), open=True):\n                        with gr.Column():\n                            with gr.Row():\n                                with gr.Column(scale=6):\n                                    templateFileSelectDropdown = gr.Dropdown(\n                                        label=i18n(\"\u9009\u62e9Prompt\u6a21\u677f\u96c6\u5408\u6587\u4ef6\"),\n                                        choices=get_template_names(plain=True),\n                                        multiselect=False,\n                                        value=get_template_names(plain=True)[0],\n                                    ).style(container=False)\n                                with gr.Column(scale=1):\n                                    templateRefreshBtn = gr.Button(i18n(\"\ud83d\udd04 \u5237\u65b0\"))\n                            with gr.Row():\n                                with gr.Column():\n                                    templateSelectDropdown = gr.Dropdown(\n                                        label=i18n(\"\u4ecePrompt\u6a21\u677f\u4e2d\u52a0\u8f7d\"),\n                                        choices=load_template(\n                                            get_template_names(plain=True)[0], mode=1\n                                        ),\n                                        multiselect=False,\n                                    ).style(container=False)\n\n                with gr.Tab(label=i18n(\"\u4fdd\u5b58/\u52a0\u8f7d\")):\n                    with gr.Accordion(label=i18n(\"\u4fdd\u5b58/\u52a0\u8f7d\u5bf9\u8bdd\u5386\u53f2\u8bb0\u5f55\"), open=True):\n                        with gr.Column():\n                            with gr.Row():\n                                with gr.Column(scale=6):\n                                    historyFileSelectDropdown = gr.Dropdown(\n                                        label=i18n(\"\u4ece\u5217\u8868\u4e2d\u52a0\u8f7d\u5bf9\u8bdd\"),\n                                        choices=get_history_names(plain=True),\n                                        multiselect=False\n                                    )\n                                with gr.Column(scale=1):\n                                    historyRefreshBtn = gr.Button(i18n(\"\ud83d\udd04 \u5237\u65b0\"))\n                            with gr.Row():\n                                with gr.Column(scale=6):\n                                    saveFileName = gr.Textbox(\n                                        show_label=True,\n                                        placeholder=i18n(\"\u8bbe\u7f6e\u6587\u4ef6\u540d: \u9ed8\u8ba4\u4e3a.json\uff0c\u53ef\u9009\u4e3a.md\"),\n                                        label=i18n(\"\u8bbe\u7f6e\u4fdd\u5b58\u6587\u4ef6\u540d\"),\n                                        value=i18n(\"\u5bf9\u8bdd\u5386\u53f2\u8bb0\u5f55\"),\n                                    ).style(container=True)\n                                with gr.Column(scale=1):\n                                    saveHistoryBtn = gr.Button(i18n(\"\ud83d\udcbe \u4fdd\u5b58\u5bf9\u8bdd\"))\n                                    exportMarkdownBtn = gr.Button(i18n(\"\ud83d\udcdd \u5bfc\u51fa\u4e3aMarkdown\"))\n                                    gr.Markdown(i18n(\"\u9ed8\u8ba4\u4fdd\u5b58\u4e8ehistory\u6587\u4ef6\u5939\"))\n                            with gr.Row():\n                                with gr.Column():\n                                    downloadFile = gr.File(interactive=True)\n\n                with gr.Tab(label=i18n(\"\u9ad8\u7ea7\")):\n                    gr.Markdown(i18n(\"# \u26a0\ufe0f \u52a1\u5fc5\u8c28\u614e\u66f4\u6539 \u26a0\ufe0f\\n\\n\u5982\u679c\u65e0\u6cd5\u4f7f\u7528\u8bf7\u6062\u590d\u9ed8\u8ba4\u8bbe\u7f6e\"))\n                    gr.HTML(APPEARANCE_SWITCHER, elem_classes=\"insert_block\")\n                    use_streaming_checkbox = gr.Checkbox(\n                            label=i18n(\"\u5b9e\u65f6\u4f20\u8f93\u56de\u7b54\"), value=True, visible=ENABLE_STREAMING_OPTION\n                        )\n                    with gr.Accordion(i18n(\"\u53c2\u6570\"), open=False):\n                        temperature_slider = gr.Slider(\n                            minimum=-0,\n                            maximum=2.0,\n                            value=1.0,\n                            step=0.1,\n                            interactive=True,\n                            label=\"temperature\",\n                        )\n                        top_p_slider = gr.Slider(\n                            minimum=-0,\n                            maximum=1.0,\n                            value=1.0,\n                            step=0.05,\n                            interactive=True,\n                            label=\"top-p\",\n                        )\n                        n_choices_slider = gr.Slider(\n                            minimum=1,\n                            maximum=10,\n                            value=1,\n                            step=1,\n                            interactive=True,\n                            label=\"n choices\",\n                        )\n                        stop_sequence_txt = gr.Textbox(\n                            show_label=True,\n                            placeholder=i18n(\"\u5728\u8fd9\u91cc\u8f93\u5165\u505c\u6b62\u7b26\uff0c\u7528\u82f1\u6587\u9017\u53f7\u9694\u5f00...\"),\n                            label=\"stop\",\n                            value=\"\",\n                            lines=1,\n                        )\n                        max_context_length_slider = gr.Slider(\n                            minimum=1,\n                            maximum=32768,\n                            value=2000,\n                            step=1,\n                            interactive=True,\n                            label=\"max context\",\n                        )\n                        max_generation_slider = gr.Slider(\n                            minimum=1,\n                            maximum=32768,\n                            value=1000,\n                            step=1,\n                            interactive=True,\n                            label=\"max generations\",\n                        )\n                        presence_penalty_slider = gr.Slider(\n                            minimum=-2.0,\n                            maximum=2.0,\n                            value=0.0,\n                            step=0.01,\n                            interactive=True,\n                            label=\"presence penalty\",\n                        )\n                        frequency_penalty_slider = gr.Slider(\n                            minimum=-2.0,\n                            maximum=2.0,\n                            value=0.0,\n                            step=0.01,\n                            interactive=True,\n                            label=\"frequency penalty\",\n                        )\n                        logit_bias_txt = gr.Textbox(\n                            show_label=True,\n                            placeholder=f\"word:likelihood\",\n                            label=\"logit bias\",\n                            value=\"\",\n                            lines=1,\n                        )\n                        user_identifier_txt = gr.Textbox(\n                            show_label=True,\n                            placeholder=i18n(\"\u7528\u4e8e\u5b9a\u4f4d\u6ee5\u7528\u884c\u4e3a\"),\n                            label=i18n(\"\u7528\u6237\u540d\"),\n                            value=user_name.value,\n                            lines=1,\n                        )\n\n                    with gr.Accordion(i18n(\"\u7f51\u7edc\u8bbe\u7f6e\"), open=False):\n                        # \u4f18\u5148\u5c55\u793a\u81ea\u5b9a\u4e49\u7684api_host\n                        apihostTxt = gr.Textbox(\n                            show_label=True,\n                            placeholder=i18n(\"\u5728\u8fd9\u91cc\u8f93\u5165API-Host...\"),\n                            label=\"API-Host\",\n                            value=config.api_host or shared.API_HOST,\n                            lines=1,\n                        )\n                        changeAPIURLBtn = gr.Button(i18n(\"\ud83d\udd04 \u5207\u6362API\u5730\u5740\"))\n                        proxyTxt = gr.Textbox(\n                            show_label=True,\n                            placeholder=i18n(\"\u5728\u8fd9\u91cc\u8f93\u5165\u4ee3\u7406\u5730\u5740...\"),\n                            label=i18n(\"\u4ee3\u7406\u5730\u5740\uff08\u793a\u4f8b\uff1ahttp://127.0.0.1:10809\uff09\"),\n                            value=\"\",\n                            lines=2,\n                        )\n                        changeProxyBtn = gr.Button(i18n(\"\ud83d\udd04 \u8bbe\u7f6e\u4ee3\u7406\u5730\u5740\"))\n                        default_btn = gr.Button(i18n(\"\ud83d\udd19 \u6062\u590d\u9ed8\u8ba4\u8bbe\u7f6e\"))\n\n    gr.Markdown(CHUANHU_DESCRIPTION, elem_id=\"description\")\n    gr.HTML(FOOTER.format(versions=versions_html()), elem_id=\"footer\")\n\n    # https://github.com/gradio-app/gradio/pull/3296\n    def create_greeting(request: gr.Request):\n        if hasattr(request, \"username\") and request.username: # is not None or is not \"\"\n            logging.info(f\"Get User Name: {request.username}\")\n            user_info, user_name = gr.Markdown.update(value=f\"User: {request.username}\"), request.username\n        else:\n            user_info, user_name = gr.Markdown.update(value=f\"\", visible=False), \"\"\n        current_model = get_model(model_name = MODELS[DEFAULT_MODEL], access_key = my_api_key)[0]\n        current_model.set_user_identifier(user_name)\n        chatbot = gr.Chatbot.update(label=MODELS[DEFAULT_MODEL])\n        return user_info, user_name, current_model, toggle_like_btn_visibility(DEFAULT_MODEL), *current_model.auto_load(), get_history_names(False, user_name), chatbot\n    demo.load(create_greeting, inputs=None, outputs=[user_info, user_name, current_model, like_dislike_area, systemPromptTxt, chatbot, historyFileSelectDropdown, chatbot], api_name=\"load\")\n    chatgpt_predict_args = dict(\n        fn=predict,\n        inputs=[\n            current_model,\n            user_question,\n            chatbot,\n            use_streaming_checkbox,\n            use_websearch_checkbox,\n            index_files,\n            language_select_dropdown,\n        ],\n        outputs=[chatbot, status_display],\n        show_progress=True,\n    )\n\n    start_outputing_args = dict(\n        fn=start_outputing,\n        inputs=[],\n        outputs=[submitBtn, cancelBtn],\n        show_progress=True,\n    )\n\n    end_outputing_args = dict(\n        fn=end_outputing, inputs=[], outputs=[submitBtn, cancelBtn]\n    )\n\n    reset_textbox_args = dict(\n        fn=reset_textbox, inputs=[], outputs=[user_input]\n    )\n\n    transfer_input_args = dict(\n        fn=transfer_input, inputs=[user_input], outputs=[user_question, user_input, submitBtn, cancelBtn], show_progress=True\n    )\n\n    get_usage_args = dict(\n        fn=billing_info, inputs=[current_model], outputs=[usageTxt], show_progress=False\n    )\n\n    load_history_from_file_args = dict(\n        fn=load_chat_history,\n        inputs=[current_model, historyFileSelectDropdown, user_name],\n        outputs=[saveFileName, systemPromptTxt, chatbot]\n    )\n\n\n    # Chatbot\n    cancelBtn.click(interrupt, [current_model], [])\n\n    user_input.submit(**transfer_input_args).then(**chatgpt_predict_args).then(**end_outputing_args)\n    user_input.submit(**get_usage_args)\n\n    submitBtn.click(**transfer_input_args).then(**chatgpt_predict_args, api_name=\"predict\").then(**end_outputing_args)\n    submitBtn.click(**get_usage_args)\n\n    index_files.change(handle_file_upload, [current_model, index_files, chatbot, language_select_dropdown], [index_files, chatbot, status_display])\n    summarize_btn.click(handle_summarize_index, [current_model, index_files, chatbot, language_select_dropdown], [chatbot, status_display])\n\n    emptyBtn.click(\n        reset,\n        inputs=[current_model],\n        outputs=[chatbot, status_display],\n        show_progress=True,\n    )\n\n    retryBtn.click(**start_outputing_args).then(\n        retry,\n        [\n            current_model,\n            chatbot,\n            use_streaming_checkbox,\n            use_websearch_checkbox,\n            index_files,\n            language_select_dropdown,\n        ],\n        [chatbot, status_display],\n        show_progress=True,\n    ).then(**end_outputing_args)\n    retryBtn.click(**get_usage_args)\n\n    delFirstBtn.click(\n        delete_first_conversation,\n        [current_model],\n        [status_display],\n    )\n\n    delLastBtn.click(\n        delete_last_conversation,\n        [current_model, chatbot],\n        [chatbot, status_display],\n        show_progress=False\n    )\n\n    likeBtn.click(\n        like,\n        [current_model],\n        [status_display],\n        show_progress=False\n    )\n\n    dislikeBtn.click(\n        dislike,\n        [current_model],\n        [status_display],\n        show_progress=False\n    )\n\n    two_column.change(update_doc_config, [two_column], None)\n\n    # LLM Models\n    keyTxt.change(set_key, [current_model, keyTxt], [user_api_key, status_display], api_name=\"set_key\").then(**get_usage_args)\n    keyTxt.submit(**get_usage_args)\n    single_turn_checkbox.change(set_single_turn, [current_model, single_turn_checkbox], None)\n    model_select_dropdown.change(get_model, [model_select_dropdown, lora_select_dropdown, user_api_key, temperature_slider, top_p_slider, systemPromptTxt, user_name], [current_model, status_display, chatbot, lora_select_dropdown], show_progress=True, api_name=\"get_model\")\n    model_select_dropdown.change(toggle_like_btn_visibility, [model_select_dropdown], [like_dislike_area], show_progress=False)\n    lora_select_dropdown.change(get_model, [model_select_dropdown, lora_select_dropdown, user_api_key, temperature_slider, top_p_slider, systemPromptTxt, user_name], [current_model, status_display, chatbot], show_progress=True)\n\n    # Template\n    systemPromptTxt.change(set_system_prompt, [current_model, systemPromptTxt], None)\n    templateRefreshBtn.click(get_template_names, None, [templateFileSelectDropdown])\n    templateFileSelectDropdown.change(\n        load_template,\n        [templateFileSelectDropdown],\n        [promptTemplates, templateSelectDropdown],\n        show_progress=True,\n    )\n    templateSelectDropdown.change(\n        get_template_content,\n        [promptTemplates, templateSelectDropdown, systemPromptTxt],\n        [systemPromptTxt],\n        show_progress=True,\n    )\n\n    # S&L\n    saveHistoryBtn.click(\n        save_chat_history,\n        [current_model, saveFileName, chatbot, user_name],\n        downloadFile,\n        show_progress=True,\n    )\n    saveHistoryBtn.click(get_history_names, [gr.State(False), user_name], [historyFileSelectDropdown])\n    exportMarkdownBtn.click(\n        export_markdown,\n        [current_model, saveFileName, chatbot, user_name],\n        downloadFile,\n        show_progress=True,\n    )\n    historyRefreshBtn.click(get_history_names, [gr.State(False), user_name], [historyFileSelectDropdown])\n    historyFileSelectDropdown.change(**load_history_from_file_args)\n    downloadFile.change(upload_chat_history, [current_model, downloadFile, user_name], [saveFileName, systemPromptTxt, chatbot])\n\n    # Advanced\n    max_context_length_slider.change(set_token_upper_limit, [current_model, max_context_length_slider], None)\n    temperature_slider.change(set_temperature, [current_model, temperature_slider], None)\n    top_p_slider.change(set_top_p, [current_model, top_p_slider], None)\n    n_choices_slider.change(set_n_choices, [current_model, n_choices_slider], None)\n    stop_sequence_txt.change(set_stop_sequence, [current_model, stop_sequence_txt], None)\n    max_generation_slider.change(set_max_tokens, [current_model, max_generation_slider], None)\n    presence_penalty_slider.change(set_presence_penalty, [current_model, presence_penalty_slider], None)\n    frequency_penalty_slider.change(set_frequency_penalty, [current_model, frequency_penalty_slider], None)\n    logit_bias_txt.change(set_logit_bias, [current_model, logit_bias_txt], None)\n    user_identifier_txt.change(set_user_identifier, [current_model, user_identifier_txt], None)\n\n    default_btn.click(\n        reset_default, [], [apihostTxt, proxyTxt, status_display], show_progress=True\n    )\n    changeAPIURLBtn.click(\n        change_api_host,\n        [apihostTxt],\n        [status_display],\n        show_progress=True,\n    )\n    changeProxyBtn.click(\n        change_proxy,\n        [proxyTxt],\n        [status_display],\n        show_progress=True,\n    )\n\nlogging.info(\n    colorama.Back.GREEN\n    + \"\\n\u5ddd\u864e\u7684\u6e29\u99a8\u63d0\u793a\uff1a\u8bbf\u95ee http://localhost:7860 \u67e5\u770b\u754c\u9762\"\n    + colorama.Style.RESET_ALL\n)\n# \u9ed8\u8ba4\u5f00\u542f\u672c\u5730\u670d\u52a1\u5668\uff0c\u9ed8\u8ba4\u53ef\u4ee5\u76f4\u63a5\u4eceIP\u8bbf\u95ee\uff0c\u9ed8\u8ba4\u4e0d\u521b\u5efa\u516c\u5f00\u5206\u4eab\u94fe\u63a5\ndemo.title = i18n(\"\u5ddd\u864eChat \ud83d\ude80\")\n\nif __name__ == \"__main__\":\n    reload_javascript()\n    demo.queue(concurrency_count=CONCURRENT_COUNT).launch(\n        server_name=server_name,\n        server_port=server_port,\n        share=share,\n        auth=auth_list if authflag else None,\n        favicon_path=\"./assets/favicon.ico\",\n        inbrowser=not dockerflag, # \u7981\u6b62\u5728docker\u4e0b\u5f00\u542finbrowser\n    )\n    # demo.queue(concurrency_count=CONCURRENT_COUNT).launch(server_name=\"0.0.0.0\", server_port=7860, share=False) # \u53ef\u81ea\u5b9a\u4e49\u7aef\u53e3\n    # demo.queue(concurrency_count=CONCURRENT_COUNT).launch(server_name=\"0.0.0.0\", server_port=7860,auth=(\"\u5728\u8fd9\u91cc\u586b\u5199\u7528\u6237\u540d\", \"\u5728\u8fd9\u91cc\u586b\u5199\u5bc6\u7801\")) # \u53ef\u8bbe\u7f6e\u7528\u6237\u540d\u4e0e\u5bc6\u7801\n    # demo.queue(concurrency_count=CONCURRENT_COUNT).launch(auth=(\"\u5728\u8fd9\u91cc\u586b\u5199\u7528\u6237\u540d\", \"\u5728\u8fd9\u91cc\u586b\u5199\u5bc6\u7801\")) # \u9002\u5408Nginx\u53cd\u5411\u4ee3\u7406\n"], "fixing_code": ["# -*- coding:utf-8 -*-\nimport os\nimport logging\nimport sys\n\nimport gradio as gr\n\nfrom modules import config\nfrom modules.config import *\nfrom modules.utils import *\nfrom modules.presets import *\nfrom modules.overwrites import *\nfrom modules.models.models import get_model\n\n\ngr.Chatbot._postprocess_chat_messages = postprocess_chat_messages\ngr.Chatbot.postprocess = postprocess\n\nwith open(\"assets/custom.css\", \"r\", encoding=\"utf-8\") as f:\n    customCSS = f.read()\n\ndef create_new_model():\n    return get_model(model_name = MODELS[DEFAULT_MODEL], access_key = my_api_key)[0]\n\nwith gr.Blocks(css=customCSS, theme=small_and_beautiful_theme) as demo:\n    user_name = gr.State(\"\")\n    promptTemplates = gr.State(load_template(get_template_names(plain=True)[0], mode=2))\n    user_question = gr.State(\"\")\n    assert type(my_api_key)==str\n    user_api_key = gr.State(my_api_key)\n    current_model = gr.State(create_new_model)\n\n    topic = gr.State(i18n(\"\u672a\u547d\u540d\u5bf9\u8bdd\u5386\u53f2\u8bb0\u5f55\"))\n\n    with gr.Row():\n        gr.HTML(CHUANHU_TITLE, elem_id=\"app_title\")\n        status_display = gr.Markdown(get_geoip(), elem_id=\"status_display\")\n    with gr.Row(elem_id=\"float_display\"):\n        user_info = gr.Markdown(value=\"getting user info...\", elem_id=\"user_info\")\n\n    with gr.Row().style(equal_height=True):\n        with gr.Column(scale=5):\n            with gr.Row():\n                chatbot = gr.Chatbot(label=\"Chuanhu Chat\", elem_id=\"chuanhu_chatbot\").style(height=\"100%\")\n            with gr.Row():\n                with gr.Column(min_width=225, scale=12):\n                    user_input = gr.Textbox(\n                        elem_id=\"user_input_tb\",\n                        show_label=False, placeholder=i18n(\"\u5728\u8fd9\u91cc\u8f93\u5165\")\n                    ).style(container=False)\n                with gr.Column(min_width=42, scale=1):\n                    submitBtn = gr.Button(value=\"\", variant=\"primary\", elem_id=\"submit_btn\")\n                    cancelBtn = gr.Button(value=\"\", variant=\"secondary\", visible=False, elem_id=\"cancel_btn\")\n            with gr.Row():\n                emptyBtn = gr.Button(\n                    i18n(\"\ud83e\uddf9 \u65b0\u7684\u5bf9\u8bdd\"), elem_id=\"empty_btn\"\n                )\n                retryBtn = gr.Button(i18n(\"\ud83d\udd04 \u91cd\u65b0\u751f\u6210\"))\n                delFirstBtn = gr.Button(i18n(\"\ud83d\uddd1\ufe0f \u5220\u9664\u6700\u65e7\u5bf9\u8bdd\"))\n                delLastBtn = gr.Button(i18n(\"\ud83d\uddd1\ufe0f \u5220\u9664\u6700\u65b0\u5bf9\u8bdd\"))\n                with gr.Row(visible=False) as like_dislike_area:\n                    with gr.Column(min_width=20, scale=1):\n                        likeBtn = gr.Button(i18n(\"\ud83d\udc4d\"))\n                    with gr.Column(min_width=20, scale=1):\n                        dislikeBtn = gr.Button(i18n(\"\ud83d\udc4e\"))\n\n        with gr.Column():\n            with gr.Column(min_width=50, scale=1):\n                with gr.Tab(label=i18n(\"\u6a21\u578b\")):\n                    keyTxt = gr.Textbox(\n                        show_label=True,\n                        placeholder=f\"Your API-key...\",\n                        value=hide_middle_chars(user_api_key.value),\n                        type=\"password\",\n                        visible=not HIDE_MY_KEY,\n                        label=\"API-Key\",\n                    )\n                    if multi_api_key:\n                        usageTxt = gr.Markdown(i18n(\"\u591a\u8d26\u53f7\u6a21\u5f0f\u5df2\u5f00\u542f\uff0c\u65e0\u9700\u8f93\u5165key\uff0c\u53ef\u76f4\u63a5\u5f00\u59cb\u5bf9\u8bdd\"), elem_id=\"usage_display\", elem_classes=\"insert_block\")\n                    else:\n                        usageTxt = gr.Markdown(i18n(\"**\u53d1\u9001\u6d88\u606f** \u6216 **\u63d0\u4ea4key** \u4ee5\u663e\u793a\u989d\u5ea6\"), elem_id=\"usage_display\", elem_classes=\"insert_block\")\n                    model_select_dropdown = gr.Dropdown(\n                        label=i18n(\"\u9009\u62e9\u6a21\u578b\"), choices=MODELS, multiselect=False, value=MODELS[DEFAULT_MODEL], interactive=True\n                    )\n                    lora_select_dropdown = gr.Dropdown(\n                        label=i18n(\"\u9009\u62e9LoRA\u6a21\u578b\"), choices=[], multiselect=False, interactive=True, visible=False\n                    )\n                    with gr.Row():\n                        single_turn_checkbox = gr.Checkbox(label=i18n(\"\u5355\u8f6e\u5bf9\u8bdd\"), value=False)\n                        use_websearch_checkbox = gr.Checkbox(label=i18n(\"\u4f7f\u7528\u5728\u7ebf\u641c\u7d22\"), value=False)\n                        # render_latex_checkbox = gr.Checkbox(label=i18n(\"\u6e32\u67d3LaTeX\u516c\u5f0f\"), value=render_latex, interactive=True, elem_id=\"render_latex_checkbox\")\n                    language_select_dropdown = gr.Dropdown(\n                        label=i18n(\"\u9009\u62e9\u56de\u590d\u8bed\u8a00\uff08\u9488\u5bf9\u641c\u7d22&\u7d22\u5f15\u529f\u80fd\uff09\"),\n                        choices=REPLY_LANGUAGES,\n                        multiselect=False,\n                        value=REPLY_LANGUAGES[0],\n                    )\n                    index_files = gr.Files(label=i18n(\"\u4e0a\u4f20\"), type=\"file\")\n                    two_column = gr.Checkbox(label=i18n(\"\u53cc\u680fpdf\"), value=advance_docs[\"pdf\"].get(\"two_column\", False))\n                    summarize_btn = gr.Button(i18n(\"\u603b\u7ed3\"))\n                    # TODO: \u516c\u5f0focr\n                    # formula_ocr = gr.Checkbox(label=i18n(\"\u8bc6\u522b\u516c\u5f0f\"), value=advance_docs[\"pdf\"].get(\"formula_ocr\", False))\n\n                with gr.Tab(label=\"Prompt\"):\n                    systemPromptTxt = gr.Textbox(\n                        show_label=True,\n                        placeholder=i18n(\"\u5728\u8fd9\u91cc\u8f93\u5165System Prompt...\"),\n                        label=\"System prompt\",\n                        value=INITIAL_SYSTEM_PROMPT,\n                        lines=10,\n                    ).style(container=False)\n                    with gr.Accordion(label=i18n(\"\u52a0\u8f7dPrompt\u6a21\u677f\"), open=True):\n                        with gr.Column():\n                            with gr.Row():\n                                with gr.Column(scale=6):\n                                    templateFileSelectDropdown = gr.Dropdown(\n                                        label=i18n(\"\u9009\u62e9Prompt\u6a21\u677f\u96c6\u5408\u6587\u4ef6\"),\n                                        choices=get_template_names(plain=True),\n                                        multiselect=False,\n                                        value=get_template_names(plain=True)[0],\n                                    ).style(container=False)\n                                with gr.Column(scale=1):\n                                    templateRefreshBtn = gr.Button(i18n(\"\ud83d\udd04 \u5237\u65b0\"))\n                            with gr.Row():\n                                with gr.Column():\n                                    templateSelectDropdown = gr.Dropdown(\n                                        label=i18n(\"\u4ecePrompt\u6a21\u677f\u4e2d\u52a0\u8f7d\"),\n                                        choices=load_template(\n                                            get_template_names(plain=True)[0], mode=1\n                                        ),\n                                        multiselect=False,\n                                    ).style(container=False)\n\n                with gr.Tab(label=i18n(\"\u4fdd\u5b58/\u52a0\u8f7d\")):\n                    with gr.Accordion(label=i18n(\"\u4fdd\u5b58/\u52a0\u8f7d\u5bf9\u8bdd\u5386\u53f2\u8bb0\u5f55\"), open=True):\n                        with gr.Column():\n                            with gr.Row():\n                                with gr.Column(scale=6):\n                                    historyFileSelectDropdown = gr.Dropdown(\n                                        label=i18n(\"\u4ece\u5217\u8868\u4e2d\u52a0\u8f7d\u5bf9\u8bdd\"),\n                                        choices=get_history_names(plain=True),\n                                        multiselect=False\n                                    )\n                                with gr.Column(scale=1):\n                                    historyRefreshBtn = gr.Button(i18n(\"\ud83d\udd04 \u5237\u65b0\"))\n                            with gr.Row():\n                                with gr.Column(scale=6):\n                                    saveFileName = gr.Textbox(\n                                        show_label=True,\n                                        placeholder=i18n(\"\u8bbe\u7f6e\u6587\u4ef6\u540d: \u9ed8\u8ba4\u4e3a.json\uff0c\u53ef\u9009\u4e3a.md\"),\n                                        label=i18n(\"\u8bbe\u7f6e\u4fdd\u5b58\u6587\u4ef6\u540d\"),\n                                        value=i18n(\"\u5bf9\u8bdd\u5386\u53f2\u8bb0\u5f55\"),\n                                    ).style(container=True)\n                                with gr.Column(scale=1):\n                                    saveHistoryBtn = gr.Button(i18n(\"\ud83d\udcbe \u4fdd\u5b58\u5bf9\u8bdd\"))\n                                    exportMarkdownBtn = gr.Button(i18n(\"\ud83d\udcdd \u5bfc\u51fa\u4e3aMarkdown\"))\n                                    gr.Markdown(i18n(\"\u9ed8\u8ba4\u4fdd\u5b58\u4e8ehistory\u6587\u4ef6\u5939\"))\n                            with gr.Row():\n                                with gr.Column():\n                                    downloadFile = gr.File(interactive=True)\n\n                with gr.Tab(label=i18n(\"\u9ad8\u7ea7\")):\n                    gr.Markdown(i18n(\"# \u26a0\ufe0f \u52a1\u5fc5\u8c28\u614e\u66f4\u6539 \u26a0\ufe0f\\n\\n\u5982\u679c\u65e0\u6cd5\u4f7f\u7528\u8bf7\u6062\u590d\u9ed8\u8ba4\u8bbe\u7f6e\"))\n                    gr.HTML(APPEARANCE_SWITCHER, elem_classes=\"insert_block\")\n                    use_streaming_checkbox = gr.Checkbox(\n                            label=i18n(\"\u5b9e\u65f6\u4f20\u8f93\u56de\u7b54\"), value=True, visible=ENABLE_STREAMING_OPTION\n                        )\n                    with gr.Accordion(i18n(\"\u53c2\u6570\"), open=False):\n                        temperature_slider = gr.Slider(\n                            minimum=-0,\n                            maximum=2.0,\n                            value=1.0,\n                            step=0.1,\n                            interactive=True,\n                            label=\"temperature\",\n                        )\n                        top_p_slider = gr.Slider(\n                            minimum=-0,\n                            maximum=1.0,\n                            value=1.0,\n                            step=0.05,\n                            interactive=True,\n                            label=\"top-p\",\n                        )\n                        n_choices_slider = gr.Slider(\n                            minimum=1,\n                            maximum=10,\n                            value=1,\n                            step=1,\n                            interactive=True,\n                            label=\"n choices\",\n                        )\n                        stop_sequence_txt = gr.Textbox(\n                            show_label=True,\n                            placeholder=i18n(\"\u5728\u8fd9\u91cc\u8f93\u5165\u505c\u6b62\u7b26\uff0c\u7528\u82f1\u6587\u9017\u53f7\u9694\u5f00...\"),\n                            label=\"stop\",\n                            value=\"\",\n                            lines=1,\n                        )\n                        max_context_length_slider = gr.Slider(\n                            minimum=1,\n                            maximum=32768,\n                            value=2000,\n                            step=1,\n                            interactive=True,\n                            label=\"max context\",\n                        )\n                        max_generation_slider = gr.Slider(\n                            minimum=1,\n                            maximum=32768,\n                            value=1000,\n                            step=1,\n                            interactive=True,\n                            label=\"max generations\",\n                        )\n                        presence_penalty_slider = gr.Slider(\n                            minimum=-2.0,\n                            maximum=2.0,\n                            value=0.0,\n                            step=0.01,\n                            interactive=True,\n                            label=\"presence penalty\",\n                        )\n                        frequency_penalty_slider = gr.Slider(\n                            minimum=-2.0,\n                            maximum=2.0,\n                            value=0.0,\n                            step=0.01,\n                            interactive=True,\n                            label=\"frequency penalty\",\n                        )\n                        logit_bias_txt = gr.Textbox(\n                            show_label=True,\n                            placeholder=f\"word:likelihood\",\n                            label=\"logit bias\",\n                            value=\"\",\n                            lines=1,\n                        )\n                        user_identifier_txt = gr.Textbox(\n                            show_label=True,\n                            placeholder=i18n(\"\u7528\u4e8e\u5b9a\u4f4d\u6ee5\u7528\u884c\u4e3a\"),\n                            label=i18n(\"\u7528\u6237\u540d\"),\n                            value=user_name.value,\n                            lines=1,\n                        )\n\n                    with gr.Accordion(i18n(\"\u7f51\u7edc\u8bbe\u7f6e\"), open=False):\n                        # \u4f18\u5148\u5c55\u793a\u81ea\u5b9a\u4e49\u7684api_host\n                        apihostTxt = gr.Textbox(\n                            show_label=True,\n                            placeholder=i18n(\"\u5728\u8fd9\u91cc\u8f93\u5165API-Host...\"),\n                            label=\"API-Host\",\n                            value=config.api_host or shared.API_HOST,\n                            lines=1,\n                        )\n                        changeAPIURLBtn = gr.Button(i18n(\"\ud83d\udd04 \u5207\u6362API\u5730\u5740\"))\n                        proxyTxt = gr.Textbox(\n                            show_label=True,\n                            placeholder=i18n(\"\u5728\u8fd9\u91cc\u8f93\u5165\u4ee3\u7406\u5730\u5740...\"),\n                            label=i18n(\"\u4ee3\u7406\u5730\u5740\uff08\u793a\u4f8b\uff1ahttp://127.0.0.1:10809\uff09\"),\n                            value=\"\",\n                            lines=2,\n                        )\n                        changeProxyBtn = gr.Button(i18n(\"\ud83d\udd04 \u8bbe\u7f6e\u4ee3\u7406\u5730\u5740\"))\n                        default_btn = gr.Button(i18n(\"\ud83d\udd19 \u6062\u590d\u9ed8\u8ba4\u8bbe\u7f6e\"))\n\n    gr.Markdown(CHUANHU_DESCRIPTION, elem_id=\"description\")\n    gr.HTML(FOOTER.format(versions=versions_html()), elem_id=\"footer\")\n\n    # https://github.com/gradio-app/gradio/pull/3296\n    def create_greeting(request: gr.Request):\n        if hasattr(request, \"username\") and request.username: # is not None or is not \"\"\n            logging.info(f\"Get User Name: {request.username}\")\n            user_info, user_name = gr.Markdown.update(value=f\"User: {request.username}\"), request.username\n        else:\n            user_info, user_name = gr.Markdown.update(value=f\"\", visible=False), \"\"\n        current_model = get_model(model_name = MODELS[DEFAULT_MODEL], access_key = my_api_key)[0]\n        current_model.set_user_identifier(user_name)\n        chatbot = gr.Chatbot.update(label=MODELS[DEFAULT_MODEL])\n        return user_info, user_name, current_model, toggle_like_btn_visibility(DEFAULT_MODEL), *current_model.auto_load(), get_history_names(False, user_name), chatbot\n    demo.load(create_greeting, inputs=None, outputs=[user_info, user_name, current_model, like_dislike_area, systemPromptTxt, chatbot, historyFileSelectDropdown, chatbot], api_name=\"load\")\n    chatgpt_predict_args = dict(\n        fn=predict,\n        inputs=[\n            current_model,\n            user_question,\n            chatbot,\n            use_streaming_checkbox,\n            use_websearch_checkbox,\n            index_files,\n            language_select_dropdown,\n        ],\n        outputs=[chatbot, status_display],\n        show_progress=True,\n    )\n\n    start_outputing_args = dict(\n        fn=start_outputing,\n        inputs=[],\n        outputs=[submitBtn, cancelBtn],\n        show_progress=True,\n    )\n\n    end_outputing_args = dict(\n        fn=end_outputing, inputs=[], outputs=[submitBtn, cancelBtn]\n    )\n\n    reset_textbox_args = dict(\n        fn=reset_textbox, inputs=[], outputs=[user_input]\n    )\n\n    transfer_input_args = dict(\n        fn=transfer_input, inputs=[user_input], outputs=[user_question, user_input, submitBtn, cancelBtn], show_progress=True\n    )\n\n    get_usage_args = dict(\n        fn=billing_info, inputs=[current_model], outputs=[usageTxt], show_progress=False\n    )\n\n    load_history_from_file_args = dict(\n        fn=load_chat_history,\n        inputs=[current_model, historyFileSelectDropdown, user_name],\n        outputs=[saveFileName, systemPromptTxt, chatbot]\n    )\n\n\n    # Chatbot\n    cancelBtn.click(interrupt, [current_model], [])\n\n    user_input.submit(**transfer_input_args).then(**chatgpt_predict_args).then(**end_outputing_args)\n    user_input.submit(**get_usage_args)\n\n    submitBtn.click(**transfer_input_args).then(**chatgpt_predict_args, api_name=\"predict\").then(**end_outputing_args)\n    submitBtn.click(**get_usage_args)\n\n    index_files.change(handle_file_upload, [current_model, index_files, chatbot, language_select_dropdown], [index_files, chatbot, status_display])\n    summarize_btn.click(handle_summarize_index, [current_model, index_files, chatbot, language_select_dropdown], [chatbot, status_display])\n\n    emptyBtn.click(\n        reset,\n        inputs=[current_model],\n        outputs=[chatbot, status_display],\n        show_progress=True,\n    )\n\n    retryBtn.click(**start_outputing_args).then(\n        retry,\n        [\n            current_model,\n            chatbot,\n            use_streaming_checkbox,\n            use_websearch_checkbox,\n            index_files,\n            language_select_dropdown,\n        ],\n        [chatbot, status_display],\n        show_progress=True,\n    ).then(**end_outputing_args)\n    retryBtn.click(**get_usage_args)\n\n    delFirstBtn.click(\n        delete_first_conversation,\n        [current_model],\n        [status_display],\n    )\n\n    delLastBtn.click(\n        delete_last_conversation,\n        [current_model, chatbot],\n        [chatbot, status_display],\n        show_progress=False\n    )\n\n    likeBtn.click(\n        like,\n        [current_model],\n        [status_display],\n        show_progress=False\n    )\n\n    dislikeBtn.click(\n        dislike,\n        [current_model],\n        [status_display],\n        show_progress=False\n    )\n\n    two_column.change(update_doc_config, [two_column], None)\n\n    # LLM Models\n    keyTxt.change(set_key, [current_model, keyTxt], [user_api_key, status_display], api_name=\"set_key\").then(**get_usage_args)\n    keyTxt.submit(**get_usage_args)\n    single_turn_checkbox.change(set_single_turn, [current_model, single_turn_checkbox], None)\n    model_select_dropdown.change(get_model, [model_select_dropdown, lora_select_dropdown, user_api_key, temperature_slider, top_p_slider, systemPromptTxt, user_name], [current_model, status_display, chatbot, lora_select_dropdown], show_progress=True, api_name=\"get_model\")\n    model_select_dropdown.change(toggle_like_btn_visibility, [model_select_dropdown], [like_dislike_area], show_progress=False)\n    lora_select_dropdown.change(get_model, [model_select_dropdown, lora_select_dropdown, user_api_key, temperature_slider, top_p_slider, systemPromptTxt, user_name], [current_model, status_display, chatbot], show_progress=True)\n\n    # Template\n    systemPromptTxt.change(set_system_prompt, [current_model, systemPromptTxt], None)\n    templateRefreshBtn.click(get_template_names, None, [templateFileSelectDropdown])\n    templateFileSelectDropdown.change(\n        load_template,\n        [templateFileSelectDropdown],\n        [promptTemplates, templateSelectDropdown],\n        show_progress=True,\n    )\n    templateSelectDropdown.change(\n        get_template_content,\n        [promptTemplates, templateSelectDropdown, systemPromptTxt],\n        [systemPromptTxt],\n        show_progress=True,\n    )\n\n    # S&L\n    saveHistoryBtn.click(\n        save_chat_history,\n        [current_model, saveFileName, chatbot, user_name],\n        downloadFile,\n        show_progress=True,\n    )\n    saveHistoryBtn.click(get_history_names, [gr.State(False), user_name], [historyFileSelectDropdown])\n    exportMarkdownBtn.click(\n        export_markdown,\n        [current_model, saveFileName, chatbot, user_name],\n        downloadFile,\n        show_progress=True,\n    )\n    historyRefreshBtn.click(get_history_names, [gr.State(False), user_name], [historyFileSelectDropdown])\n    historyFileSelectDropdown.change(**load_history_from_file_args)\n    downloadFile.change(upload_chat_history, [current_model, downloadFile, user_name], [saveFileName, systemPromptTxt, chatbot])\n\n    # Advanced\n    max_context_length_slider.change(set_token_upper_limit, [current_model, max_context_length_slider], None)\n    temperature_slider.change(set_temperature, [current_model, temperature_slider], None)\n    top_p_slider.change(set_top_p, [current_model, top_p_slider], None)\n    n_choices_slider.change(set_n_choices, [current_model, n_choices_slider], None)\n    stop_sequence_txt.change(set_stop_sequence, [current_model, stop_sequence_txt], None)\n    max_generation_slider.change(set_max_tokens, [current_model, max_generation_slider], None)\n    presence_penalty_slider.change(set_presence_penalty, [current_model, presence_penalty_slider], None)\n    frequency_penalty_slider.change(set_frequency_penalty, [current_model, frequency_penalty_slider], None)\n    logit_bias_txt.change(set_logit_bias, [current_model, logit_bias_txt], None)\n    user_identifier_txt.change(set_user_identifier, [current_model, user_identifier_txt], None)\n\n    default_btn.click(\n        reset_default, [], [apihostTxt, proxyTxt, status_display], show_progress=True\n    )\n    changeAPIURLBtn.click(\n        change_api_host,\n        [apihostTxt],\n        [status_display],\n        show_progress=True,\n    )\n    changeProxyBtn.click(\n        change_proxy,\n        [proxyTxt],\n        [status_display],\n        show_progress=True,\n    )\n\nlogging.info(\n    colorama.Back.GREEN\n    + \"\\n\u5ddd\u864e\u7684\u6e29\u99a8\u63d0\u793a\uff1a\u8bbf\u95ee http://localhost:7860 \u67e5\u770b\u754c\u9762\"\n    + colorama.Style.RESET_ALL\n)\n# \u9ed8\u8ba4\u5f00\u542f\u672c\u5730\u670d\u52a1\u5668\uff0c\u9ed8\u8ba4\u53ef\u4ee5\u76f4\u63a5\u4eceIP\u8bbf\u95ee\uff0c\u9ed8\u8ba4\u4e0d\u521b\u5efa\u516c\u5f00\u5206\u4eab\u94fe\u63a5\ndemo.title = i18n(\"\u5ddd\u864eChat \ud83d\ude80\")\n\nif __name__ == \"__main__\":\n    reload_javascript()\n    demo.queue(concurrency_count=CONCURRENT_COUNT).launch(\n        blocked_paths=[\"config.json\"],\n        server_name=server_name,\n        server_port=server_port,\n        share=share,\n        auth=auth_list if authflag else None,\n        favicon_path=\"./assets/favicon.ico\",\n        inbrowser=not dockerflag, # \u7981\u6b62\u5728docker\u4e0b\u5f00\u542finbrowser\n    )\n    # demo.queue(concurrency_count=CONCURRENT_COUNT).launch(server_name=\"0.0.0.0\", server_port=7860, share=False) # \u53ef\u81ea\u5b9a\u4e49\u7aef\u53e3\n    # demo.queue(concurrency_count=CONCURRENT_COUNT).launch(server_name=\"0.0.0.0\", server_port=7860,auth=(\"\u5728\u8fd9\u91cc\u586b\u5199\u7528\u6237\u540d\", \"\u5728\u8fd9\u91cc\u586b\u5199\u5bc6\u7801\")) # \u53ef\u8bbe\u7f6e\u7528\u6237\u540d\u4e0e\u5bc6\u7801\n    # demo.queue(concurrency_count=CONCURRENT_COUNT).launch(auth=(\"\u5728\u8fd9\u91cc\u586b\u5199\u7528\u6237\u540d\", \"\u5728\u8fd9\u91cc\u586b\u5199\u5bc6\u7801\")) # \u9002\u5408Nginx\u53cd\u5411\u4ee3\u7406\n"], "filenames": ["ChuanhuChatbot.py"], "buggy_code_start_loc": [470], "buggy_code_end_loc": [470], "fixing_code_start_loc": [471], "fixing_code_end_loc": [472], "type": "CWE-306", "message": "ChuanhuChatGPT is a graphical user interface for ChatGPT and many large language models. A vulnerability in versions 20230526 and prior allows unauthorized access to the config.json file of the privately deployed ChuanghuChatGPT project, when authentication is not configured. The attacker can exploit this vulnerability to steal the API keys in the configuration file. The vulnerability has been fixed in commit bfac445. As a workaround, setting up access authentication can help mitigate the vulnerability.", "other": {"cve": {"id": "CVE-2023-34094", "sourceIdentifier": "security-advisories@github.com", "published": "2023-06-02T16:15:09.850", "lastModified": "2023-06-16T14:33:55.800", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "ChuanhuChatGPT is a graphical user interface for ChatGPT and many large language models. A vulnerability in versions 20230526 and prior allows unauthorized access to the config.json file of the privately deployed ChuanghuChatGPT project, when authentication is not configured. The attacker can exploit this vulnerability to steal the API keys in the configuration file. The vulnerability has been fixed in commit bfac445. As a workaround, setting up access authentication can help mitigate the vulnerability."}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:L/I:N/A:N", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "LOW", "integrityImpact": "NONE", "availabilityImpact": "NONE", "baseScore": 5.3, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 3.9, "impactScore": 1.4}, {"source": "security-advisories@github.com", "type": "Secondary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "NONE", "availabilityImpact": "NONE", "baseScore": 7.5, "baseSeverity": "HIGH"}, "exploitabilityScore": 3.9, "impactScore": 3.6}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-306"}]}, {"source": "security-advisories@github.com", "type": "Secondary", "description": [{"lang": "en", "value": "CWE-200"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:chuanhuchatgpt_project:chuanhuchatgpt:*:*:*:*:*:chatgpt:*:*", "versionEndIncluding": "2023-05-26", "matchCriteriaId": "478430FF-6104-45D4-87C4-A22E4CE73B45"}]}]}], "references": [{"url": "https://github.com/GaiZhenbiao/ChuanhuChatGPT/commit/bfac445e799c317b0f5e738ab394032a18de62eb", "source": "security-advisories@github.com", "tags": ["Patch"]}, {"url": "https://github.com/GaiZhenbiao/ChuanhuChatGPT/security/advisories/GHSA-j34w-9xr4-m9p8", "source": "security-advisories@github.com", "tags": ["Vendor Advisory"]}]}, "github_commit_url": "https://github.com/GaiZhenbiao/ChuanhuChatGPT/commit/bfac445e799c317b0f5e738ab394032a18de62eb"}}
{"buggy_code": ["package impl\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\n\t\"github.com/flyteorg/flyteadmin/pkg/clusterresource/interfaces\"\n\t\"github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/admin\"\n\t\"github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/service\"\n)\n\n// Implementation of an interfaces.FlyteAdminDataProvider which fetches data using a flyteadmin service client\ntype serviceAdminProvider struct {\n\tadminClient service.AdminServiceClient\n}\n\nfunc (p serviceAdminProvider) GetClusterResourceAttributes(ctx context.Context, project, domain string) (*admin.ClusterResourceAttributes, error) {\n\tresource, err := p.adminClient.GetProjectDomainAttributes(ctx, &admin.ProjectDomainAttributesGetRequest{\n\t\tProject:      project,\n\t\tDomain:       domain,\n\t\tResourceType: admin.MatchableResource_CLUSTER_RESOURCE,\n\t})\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif resource != nil && resource.Attributes != nil && resource.Attributes.MatchingAttributes != nil &&\n\t\tresource.Attributes.MatchingAttributes.GetClusterResourceAttributes() != nil {\n\t\treturn resource.Attributes.MatchingAttributes.GetClusterResourceAttributes(), nil\n\t}\n\treturn nil, NewMissingEntityError(\"cluster resource attributes\")\n}\n\nvar activeProjectsFilter = fmt.Sprintf(\"ne(state,%d)\", admin.Project_ARCHIVED)\n\nfunc (p serviceAdminProvider) GetProjects(ctx context.Context) (*admin.Projects, error) {\n\tprojects := make([]*admin.Project, 0)\n\tlistReq := &admin.ProjectListRequest{\n\t\tLimit:   100,\n\t\tFilters: activeProjectsFilter,\n\t\t// Prefer to sync projects most newly created to ensure their resources get created first when other resources exist.\n\t\tSortBy: &descCreatedAtSortParam,\n\t}\n\n\t// Iterate through all pages of projects\n\tfor {\n\t\tprojectResp, err := p.adminClient.ListProjects(ctx, listReq)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tprojects = append(projects, projectResp.Projects...)\n\t\tif len(projectResp.Token) == 0 {\n\t\t\tbreak\n\t\t}\n\t\tlistReq.Token = projectResp.Token\n\t}\n\treturn &admin.Projects{\n\t\tProjects: projects,\n\t}, nil\n}\n\nfunc NewAdminServiceDataProvider(\n\tadminClient service.AdminServiceClient) interfaces.FlyteAdminDataProvider {\n\treturn &serviceAdminProvider{\n\t\tadminClient: adminClient,\n\t}\n}\n", "package impl\n\nimport (\n\t\"github.com/flyteorg/flyteadmin/pkg/common\"\n\t\"github.com/flyteorg/flyteadmin/pkg/errors\"\n\t\"github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/admin\"\n\t\"google.golang.org/grpc/codes\"\n)\n\nfunc NewMissingEntityError(entity string) error {\n\treturn errors.NewFlyteAdminErrorf(codes.NotFound, \"Failed to find [%s]\", entity)\n}\n\nvar descCreatedAtSortParam = admin.Sort{\n\tDirection: admin.Sort_DESCENDING,\n\tKey:       \"created_at\",\n}\n\nvar descCreatedAtSortDBParam, _ = common.NewSortParameter(descCreatedAtSortParam)\n", "package common\n\nimport (\n\t\"fmt\"\n\n\t\"github.com/flyteorg/flyteadmin/pkg/errors\"\n\t\"github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/admin\"\n\t\"google.golang.org/grpc/codes\"\n)\n\nconst gormDescending = \"%s desc\"\nconst gormAscending = \"%s asc\"\n\ntype SortParameter interface {\n\tGetGormOrderExpr() string\n}\n\ntype sortParamImpl struct {\n\tgormOrderExpression string\n}\n\nfunc (s *sortParamImpl) GetGormOrderExpr() string {\n\treturn s.gormOrderExpression\n}\n\nfunc NewSortParameter(sort admin.Sort) (SortParameter, error) {\n\tvar gormOrderExpression string\n\tswitch sort.Direction {\n\tcase admin.Sort_DESCENDING:\n\t\tgormOrderExpression = fmt.Sprintf(gormDescending, sort.Key)\n\tcase admin.Sort_ASCENDING:\n\t\tgormOrderExpression = fmt.Sprintf(gormAscending, sort.Key)\n\tdefault:\n\t\treturn nil, errors.NewFlyteAdminErrorf(codes.InvalidArgument, \"invalid sort order specified: %v\", sort)\n\t}\n\treturn &sortParamImpl{\n\t\tgormOrderExpression: gormOrderExpression,\n\t}, nil\n}\n", "package common\n\nimport (\n\t\"testing\"\n\n\t\"github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/admin\"\n\t\"github.com/stretchr/testify/assert\"\n)\n\nfunc TestSortParameter_Ascending(t *testing.T) {\n\tsortParameter, err := NewSortParameter(admin.Sort{\n\t\tDirection: admin.Sort_ASCENDING,\n\t\tKey:       \"name\",\n\t})\n\tassert.Nil(t, err)\n\tassert.Equal(t, \"name asc\", sortParameter.GetGormOrderExpr())\n}\n\nfunc TestSortParameter_Descending(t *testing.T) {\n\tsortParameter, err := NewSortParameter(admin.Sort{\n\t\tDirection: admin.Sort_DESCENDING,\n\t\tKey:       \"project\",\n\t})\n\tassert.Nil(t, err)\n\tassert.Equal(t, \"project desc\", sortParameter.GetGormOrderExpr())\n}\n", "package impl\n\nimport (\n\t\"context\"\n\t\"strconv\"\n\n\t\"github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/core\"\n\n\t\"github.com/flyteorg/flyteadmin/pkg/common\"\n\n\t\"github.com/flyteorg/flyteadmin/pkg/errors\"\n\t\"github.com/flyteorg/flyteadmin/pkg/manager/impl/util\"\n\t\"github.com/flyteorg/flyteadmin/pkg/manager/impl/validation\"\n\t\"github.com/flyteorg/flyteadmin/pkg/manager/interfaces\"\n\trepoInterfaces \"github.com/flyteorg/flyteadmin/pkg/repositories/interfaces\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/transformers\"\n\truntimeInterfaces \"github.com/flyteorg/flyteadmin/pkg/runtime/interfaces\"\n\t\"github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/admin\"\n\t\"github.com/flyteorg/flytestdlib/contextutils\"\n\t\"github.com/flyteorg/flytestdlib/logger\"\n\t\"github.com/flyteorg/flytestdlib/promutils\"\n\t\"google.golang.org/grpc/codes\"\n)\n\ntype DescriptionEntityMetrics struct {\n\tScope promutils.Scope\n}\n\ntype DescriptionEntityManager struct {\n\tdb      repoInterfaces.Repository\n\tconfig  runtimeInterfaces.Configuration\n\tmetrics DescriptionEntityMetrics\n}\n\nfunc (d *DescriptionEntityManager) GetDescriptionEntity(ctx context.Context, request admin.ObjectGetRequest) (\n\t*admin.DescriptionEntity, error) {\n\tif err := validation.ValidateDescriptionEntityGetRequest(request); err != nil {\n\t\tlogger.Errorf(ctx, \"invalid request [%+v]: %v\", request, err)\n\t\treturn nil, err\n\t}\n\tctx = contextutils.WithProjectDomain(ctx, request.Id.Project, request.Id.Domain)\n\treturn util.GetDescriptionEntity(ctx, d.db, *request.Id)\n}\n\nfunc (d *DescriptionEntityManager) ListDescriptionEntity(ctx context.Context, request admin.DescriptionEntityListRequest) (*admin.DescriptionEntityList, error) {\n\t// Check required fields\n\tif err := validation.ValidateDescriptionEntityListRequest(request); err != nil {\n\t\treturn nil, err\n\t}\n\tctx = contextutils.WithProjectDomain(ctx, request.Id.Project, request.Id.Domain)\n\n\tif request.ResourceType == core.ResourceType_WORKFLOW {\n\t\tctx = contextutils.WithWorkflowID(ctx, request.Id.Name)\n\t} else {\n\t\tctx = contextutils.WithTaskID(ctx, request.Id.Name)\n\t}\n\n\tfilters, err := util.GetDbFilters(util.FilterSpec{\n\t\tProject:        request.Id.Project,\n\t\tDomain:         request.Id.Domain,\n\t\tName:           request.Id.Name,\n\t\tRequestFilters: request.Filters,\n\t}, common.ResourceTypeToEntity[request.ResourceType])\n\tif err != nil {\n\t\tlogger.Error(ctx, \"failed to get database filter\")\n\t\treturn nil, err\n\t}\n\tvar sortParameter common.SortParameter\n\tif request.SortBy != nil {\n\t\tsortParameter, err = common.NewSortParameter(*request.SortBy)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\toffset, err := validation.ValidateToken(request.Token)\n\tif err != nil {\n\t\treturn nil, errors.NewFlyteAdminErrorf(codes.InvalidArgument,\n\t\t\t\"invalid pagination token %s for ListWorkflows\", request.Token)\n\t}\n\tlistDescriptionEntitiesInput := repoInterfaces.ListResourceInput{\n\t\tLimit:         int(request.Limit),\n\t\tOffset:        offset,\n\t\tInlineFilters: filters,\n\t\tSortParameter: sortParameter,\n\t}\n\toutput, err := d.db.DescriptionEntityRepo().List(ctx, listDescriptionEntitiesInput)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"Failed to list workflows with [%+v] with err %v\", request.Id, err)\n\t\treturn nil, err\n\t}\n\tdescriptionEntityList, err := transformers.FromDescriptionEntityModels(output.Entities)\n\tif err != nil {\n\t\tlogger.Errorf(ctx,\n\t\t\t\"Failed to transform workflow models [%+v] with err: %v\", output.Entities, err)\n\t\treturn nil, err\n\t}\n\tvar token string\n\tif len(output.Entities) == int(request.Limit) {\n\t\ttoken = strconv.Itoa(offset + len(output.Entities))\n\t}\n\treturn &admin.DescriptionEntityList{\n\t\tDescriptionEntities: descriptionEntityList,\n\t\tToken:               token,\n\t}, nil\n}\n\nfunc NewDescriptionEntityManager(\n\tdb repoInterfaces.Repository,\n\tconfig runtimeInterfaces.Configuration,\n\tscope promutils.Scope) interfaces.DescriptionEntityInterface {\n\n\tmetrics := DescriptionEntityMetrics{\n\t\tScope: scope,\n\t}\n\treturn &DescriptionEntityManager{\n\t\tdb:      db,\n\t\tconfig:  config,\n\t\tmetrics: metrics,\n\t}\n}\n", "package impl\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"strconv\"\n\t\"time\"\n\n\t\"github.com/flyteorg/flytestdlib/promutils/labeled\"\n\n\t\"github.com/flyteorg/flyteadmin/plugins\"\n\n\t\"github.com/flyteorg/flyteplugins/go/tasks/pluginmachinery/flytek8s\"\n\n\t\"github.com/flyteorg/flyteadmin/auth\"\n\n\t\"github.com/flyteorg/flyteadmin/pkg/manager/impl/resources\"\n\n\tdataInterfaces \"github.com/flyteorg/flyteadmin/pkg/data/interfaces\"\n\t\"github.com/flyteorg/flytestdlib/contextutils\"\n\t\"github.com/flyteorg/flytestdlib/promutils\"\n\t\"github.com/golang/protobuf/ptypes\"\n\t\"github.com/golang/protobuf/ptypes/timestamp\"\n\t\"github.com/prometheus/client_golang/prometheus\"\n\n\t\"github.com/flyteorg/flyteadmin/pkg/common\"\n\n\t\"github.com/flyteorg/flytestdlib/logger\"\n\t\"github.com/flyteorg/flytestdlib/storage\"\n\n\tcloudeventInterfaces \"github.com/flyteorg/flyteadmin/pkg/async/cloudevent/interfaces\"\n\teventWriter \"github.com/flyteorg/flyteadmin/pkg/async/events/interfaces\"\n\t\"github.com/flyteorg/flyteadmin/pkg/async/notifications\"\n\tnotificationInterfaces \"github.com/flyteorg/flyteadmin/pkg/async/notifications/interfaces\"\n\t\"github.com/flyteorg/flyteadmin/pkg/errors\"\n\t\"github.com/flyteorg/flyteadmin/pkg/manager/impl/executions\"\n\t\"github.com/flyteorg/flyteadmin/pkg/manager/impl/util\"\n\t\"github.com/flyteorg/flyteadmin/pkg/manager/impl/validation\"\n\t\"github.com/flyteorg/flyteadmin/pkg/manager/interfaces\"\n\trepositoryInterfaces \"github.com/flyteorg/flyteadmin/pkg/repositories/interfaces\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/models\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/transformers\"\n\truntimeInterfaces \"github.com/flyteorg/flyteadmin/pkg/runtime/interfaces\"\n\tworkflowengineInterfaces \"github.com/flyteorg/flyteadmin/pkg/workflowengine/interfaces\"\n\t\"github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/admin\"\n\t\"github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/core\"\n\t\"google.golang.org/grpc/codes\"\n\n\t\"github.com/benbjohnson/clock\"\n\t\"github.com/flyteorg/flyteadmin/pkg/manager/impl/shared\"\n\t\"github.com/golang/protobuf/proto\"\n)\n\nconst childContainerQueueKey = \"child_queue\"\n\n// Map of [project] -> map of [domain] -> stop watch\ntype projectDomainScopedStopWatchMap = map[string]map[string]*promutils.StopWatch\n\ntype executionSystemMetrics struct {\n\tScope                      promutils.Scope\n\tActiveExecutions           prometheus.Gauge\n\tExecutionsCreated          prometheus.Counter\n\tExecutionsTerminated       labeled.Counter\n\tExecutionEventsCreated     prometheus.Counter\n\tPropellerFailures          prometheus.Counter\n\tPublishNotificationError   prometheus.Counter\n\tTransformerError           prometheus.Counter\n\tUnexpectedDataError        prometheus.Counter\n\tSpecSizeBytes              prometheus.Summary\n\tClosureSizeBytes           prometheus.Summary\n\tAcceptanceDelay            prometheus.Summary\n\tPublishEventError          prometheus.Counter\n\tTerminateExecutionFailures prometheus.Counter\n}\n\ntype executionUserMetrics struct {\n\tScope                        promutils.Scope\n\tScheduledExecutionDelays     projectDomainScopedStopWatchMap\n\tWorkflowExecutionDurations   projectDomainScopedStopWatchMap\n\tWorkflowExecutionInputBytes  prometheus.Summary\n\tWorkflowExecutionOutputBytes prometheus.Summary\n}\n\ntype ExecutionManager struct {\n\tdb                        repositoryInterfaces.Repository\n\tconfig                    runtimeInterfaces.Configuration\n\tstorageClient             *storage.DataStore\n\tqueueAllocator            executions.QueueAllocator\n\t_clock                    clock.Clock\n\tsystemMetrics             executionSystemMetrics\n\tuserMetrics               executionUserMetrics\n\tnotificationClient        notificationInterfaces.Publisher\n\turlData                   dataInterfaces.RemoteURLInterface\n\tworkflowManager           interfaces.WorkflowInterface\n\tnamedEntityManager        interfaces.NamedEntityInterface\n\tresourceManager           interfaces.ResourceInterface\n\tqualityOfServiceAllocator executions.QualityOfServiceAllocator\n\teventPublisher            notificationInterfaces.Publisher\n\tcloudEventPublisher       notificationInterfaces.Publisher\n\tdbEventWriter             eventWriter.WorkflowExecutionEventWriter\n\tpluginRegistry            *plugins.Registry\n}\n\nfunc getExecutionContext(ctx context.Context, id *core.WorkflowExecutionIdentifier) context.Context {\n\tctx = contextutils.WithExecutionID(ctx, id.Name)\n\treturn contextutils.WithProjectDomain(ctx, id.Project, id.Domain)\n}\n\n// Returns the unique string which identifies the authenticated end user (if any).\nfunc getUser(ctx context.Context) string {\n\tidentityContext := auth.IdentityContextFromContext(ctx)\n\treturn identityContext.UserID()\n}\n\nfunc (m *ExecutionManager) populateExecutionQueue(\n\tctx context.Context, identifier core.Identifier, compiledWorkflow *core.CompiledWorkflowClosure) {\n\tqueueConfig := m.queueAllocator.GetQueue(ctx, identifier)\n\tfor _, task := range compiledWorkflow.Tasks {\n\t\tcontainer := task.Template.GetContainer()\n\t\tif container == nil {\n\t\t\t// Unrecognized target type, nothing to do\n\t\t\tcontinue\n\t\t}\n\n\t\tif queueConfig.DynamicQueue != \"\" {\n\t\t\tlogger.Debugf(ctx, \"Assigning %s as child queue for task %+v\", queueConfig.DynamicQueue, task.Template.Id)\n\t\t\tcontainer.Config = append(container.Config, &core.KeyValuePair{\n\t\t\t\tKey:   childContainerQueueKey,\n\t\t\t\tValue: queueConfig.DynamicQueue,\n\t\t\t})\n\t\t}\n\t}\n}\n\nfunc validateMapSize(maxEntries int, candidate map[string]string, candidateName string) error {\n\tif maxEntries == 0 {\n\t\t// Treat the max as unset\n\t\treturn nil\n\t}\n\tif len(candidate) > maxEntries {\n\t\treturn errors.NewFlyteAdminErrorf(codes.InvalidArgument, \"%s has too many entries [%v > %v]\",\n\t\t\tcandidateName, len(candidate), maxEntries)\n\t}\n\treturn nil\n}\n\ntype mapWithValues interface {\n\tGetValues() map[string]string\n}\n\nfunc resolveStringMap(preferredValues, defaultValues mapWithValues, valueName string, maxEntries int) (map[string]string, error) {\n\tvar response = make(map[string]string)\n\tif preferredValues != nil && preferredValues.GetValues() != nil {\n\t\tresponse = preferredValues.GetValues()\n\t} else if defaultValues != nil && defaultValues.GetValues() != nil {\n\t\tresponse = defaultValues.GetValues()\n\t}\n\n\terr := validateMapSize(maxEntries, response, valueName)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn response, nil\n}\n\nfunc (m *ExecutionManager) addPluginOverrides(ctx context.Context, executionID *core.WorkflowExecutionIdentifier,\n\tworkflowName, launchPlanName string) ([]*admin.PluginOverride, error) {\n\toverride, err := m.resourceManager.GetResource(ctx, interfaces.ResourceRequest{\n\t\tProject:      executionID.Project,\n\t\tDomain:       executionID.Domain,\n\t\tWorkflow:     workflowName,\n\t\tLaunchPlan:   launchPlanName,\n\t\tResourceType: admin.MatchableResource_PLUGIN_OVERRIDE,\n\t})\n\tif err != nil {\n\t\tec, ok := err.(errors.FlyteAdminError)\n\t\tif !ok || ec.Code() != codes.NotFound {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\tif override != nil && override.Attributes != nil && override.Attributes.GetPluginOverrides() != nil {\n\t\treturn override.Attributes.GetPluginOverrides().Overrides, nil\n\t}\n\treturn nil, nil\n}\n\n// TODO: Delete this code usage after the flyte v0.17.0 release\n// Assumes input contains a compiled task with a valid container resource execConfig.\n//\n// Note: The system will assign a system-default value for request but for limit it will deduce it from the request\n// itself => Limit := Min([Some-Multiplier X Request], System-Max). For now we are using a multiplier of 1. In\n// general we recommend the users to set limits close to requests for more predictability in the system.\nfunc (m *ExecutionManager) setCompiledTaskDefaults(ctx context.Context, task *core.CompiledTask,\n\tplatformTaskResources workflowengineInterfaces.TaskResources) {\n\n\tif task == nil {\n\t\tlogger.Warningf(ctx, \"Can't set default resources for nil task.\")\n\t\treturn\n\t}\n\n\tif task.Template == nil || task.Template.GetContainer() == nil {\n\t\t// Nothing to do\n\t\tlogger.Debugf(ctx, \"Not setting default resources for task [%+v], no container resources found to check\", task)\n\t\treturn\n\t}\n\n\tif task.Template.GetContainer().Resources == nil {\n\t\t// In case of no resources on the container, create empty requests and limits\n\t\t// so the container will still have resources configure properly\n\t\ttask.Template.GetContainer().Resources = &core.Resources{\n\t\t\tRequests: []*core.Resources_ResourceEntry{},\n\t\t\tLimits:   []*core.Resources_ResourceEntry{},\n\t\t}\n\t}\n\n\tvar finalizedResourceRequests = make([]*core.Resources_ResourceEntry, 0)\n\tvar finalizedResourceLimits = make([]*core.Resources_ResourceEntry, 0)\n\n\t// The IDL representation for container-type tasks represents resources as a list with string quantities.\n\t// In order to easily reason about them we convert them to a set where we can O(1) fetch specific resources (e.g. CPU)\n\t// and represent them as comparable quantities rather than strings.\n\ttaskResourceRequirements := util.GetCompleteTaskResourceRequirements(ctx, task.Template.Id, task)\n\n\tcpu := flytek8s.AdjustOrDefaultResource(taskResourceRequirements.Defaults.CPU, taskResourceRequirements.Limits.CPU,\n\t\tplatformTaskResources.Defaults.CPU, platformTaskResources.Limits.CPU)\n\tfinalizedResourceRequests = append(finalizedResourceRequests, &core.Resources_ResourceEntry{\n\t\tName:  core.Resources_CPU,\n\t\tValue: cpu.Request.String(),\n\t})\n\tfinalizedResourceLimits = append(finalizedResourceLimits, &core.Resources_ResourceEntry{\n\t\tName:  core.Resources_CPU,\n\t\tValue: cpu.Limit.String(),\n\t})\n\n\tmemory := flytek8s.AdjustOrDefaultResource(taskResourceRequirements.Defaults.Memory, taskResourceRequirements.Limits.Memory,\n\t\tplatformTaskResources.Defaults.Memory, platformTaskResources.Limits.Memory)\n\tfinalizedResourceRequests = append(finalizedResourceRequests, &core.Resources_ResourceEntry{\n\t\tName:  core.Resources_MEMORY,\n\t\tValue: memory.Request.String(),\n\t})\n\tfinalizedResourceLimits = append(finalizedResourceLimits, &core.Resources_ResourceEntry{\n\t\tName:  core.Resources_MEMORY,\n\t\tValue: memory.Limit.String(),\n\t})\n\n\t// Only assign ephemeral storage when it is either requested or limited in the task definition, or a platform\n\t// default exists.\n\tif !taskResourceRequirements.Defaults.EphemeralStorage.IsZero() ||\n\t\t!taskResourceRequirements.Limits.EphemeralStorage.IsZero() ||\n\t\t!platformTaskResources.Defaults.EphemeralStorage.IsZero() {\n\t\tephemeralStorage := flytek8s.AdjustOrDefaultResource(taskResourceRequirements.Defaults.EphemeralStorage, taskResourceRequirements.Limits.EphemeralStorage,\n\t\t\tplatformTaskResources.Defaults.EphemeralStorage, platformTaskResources.Limits.EphemeralStorage)\n\t\tfinalizedResourceRequests = append(finalizedResourceRequests, &core.Resources_ResourceEntry{\n\t\t\tName:  core.Resources_EPHEMERAL_STORAGE,\n\t\t\tValue: ephemeralStorage.Request.String(),\n\t\t})\n\t\tfinalizedResourceLimits = append(finalizedResourceLimits, &core.Resources_ResourceEntry{\n\t\t\tName:  core.Resources_EPHEMERAL_STORAGE,\n\t\t\tValue: ephemeralStorage.Limit.String(),\n\t\t})\n\t}\n\n\t// Only assign storage when it is either requested or limited in the task definition, or a platform\n\t// default exists.\n\tif !taskResourceRequirements.Defaults.Storage.IsZero() ||\n\t\t!taskResourceRequirements.Limits.Storage.IsZero() ||\n\t\t!platformTaskResources.Defaults.Storage.IsZero() {\n\t\tstorageResource := flytek8s.AdjustOrDefaultResource(taskResourceRequirements.Defaults.Storage, taskResourceRequirements.Limits.Storage,\n\t\t\tplatformTaskResources.Defaults.Storage, platformTaskResources.Limits.Storage)\n\t\tfinalizedResourceRequests = append(finalizedResourceRequests, &core.Resources_ResourceEntry{\n\t\t\tName:  core.Resources_STORAGE,\n\t\t\tValue: storageResource.Request.String(),\n\t\t})\n\t\tfinalizedResourceLimits = append(finalizedResourceLimits, &core.Resources_ResourceEntry{\n\t\t\tName:  core.Resources_STORAGE,\n\t\t\tValue: storageResource.Limit.String(),\n\t\t})\n\t}\n\n\t// Only assign gpu when it is either requested or limited in the task definition, or a platform default exists.\n\tif !taskResourceRequirements.Defaults.GPU.IsZero() ||\n\t\t!taskResourceRequirements.Limits.GPU.IsZero() ||\n\t\t!platformTaskResources.Defaults.GPU.IsZero() {\n\t\tgpu := flytek8s.AdjustOrDefaultResource(taskResourceRequirements.Defaults.GPU, taskResourceRequirements.Limits.GPU,\n\t\t\tplatformTaskResources.Defaults.GPU, platformTaskResources.Limits.GPU)\n\t\tfinalizedResourceRequests = append(finalizedResourceRequests, &core.Resources_ResourceEntry{\n\t\t\tName:  core.Resources_GPU,\n\t\t\tValue: gpu.Request.String(),\n\t\t})\n\t\tfinalizedResourceLimits = append(finalizedResourceLimits, &core.Resources_ResourceEntry{\n\t\t\tName:  core.Resources_GPU,\n\t\t\tValue: gpu.Limit.String(),\n\t\t})\n\t}\n\n\ttask.Template.GetContainer().Resources = &core.Resources{\n\t\tRequests: finalizedResourceRequests,\n\t\tLimits:   finalizedResourceLimits,\n\t}\n}\n\n// Fetches inherited execution metadata including the parent node execution db model id and the source execution model id\n// as well as sets request spec metadata with the inherited principal and adjusted nesting data.\nfunc (m *ExecutionManager) getInheritedExecMetadata(ctx context.Context, requestSpec *admin.ExecutionSpec,\n\tworkflowExecutionID *core.WorkflowExecutionIdentifier) (parentNodeExecutionID uint, sourceExecutionID uint, err error) {\n\tif requestSpec.Metadata == nil || requestSpec.Metadata.ParentNodeExecution == nil {\n\t\treturn parentNodeExecutionID, sourceExecutionID, nil\n\t}\n\tparentNodeExecutionModel, err := util.GetNodeExecutionModel(ctx, m.db, requestSpec.Metadata.ParentNodeExecution)\n\tif err != nil {\n\t\tlogger.Errorf(ctx, \"Failed to get node execution [%+v] that launched this execution [%+v] with error %v\",\n\t\t\trequestSpec.Metadata.ParentNodeExecution, workflowExecutionID, err)\n\t\treturn parentNodeExecutionID, sourceExecutionID, err\n\t}\n\n\tparentNodeExecutionID = parentNodeExecutionModel.ID\n\n\tsourceExecutionModel, err := util.GetExecutionModel(ctx, m.db, *requestSpec.Metadata.ParentNodeExecution.ExecutionId)\n\tif err != nil {\n\t\tlogger.Errorf(ctx, \"Failed to get workflow execution [%+v] that launched this execution [%+v] with error %v\",\n\t\t\trequestSpec.Metadata.ParentNodeExecution, workflowExecutionID, err)\n\t\treturn parentNodeExecutionID, sourceExecutionID, err\n\t}\n\tsourceExecutionID = sourceExecutionModel.ID\n\trequestSpec.Metadata.Principal = sourceExecutionModel.User\n\tsourceExecution, err := transformers.FromExecutionModel(ctx, *sourceExecutionModel, transformers.DefaultExecutionTransformerOptions)\n\tif err != nil {\n\t\tlogger.Errorf(ctx, \"Failed transform parent execution model for child execution [%+v] with err: %v\", workflowExecutionID, err)\n\t\treturn parentNodeExecutionID, sourceExecutionID, err\n\t}\n\tif sourceExecution.Spec.Metadata != nil {\n\t\trequestSpec.Metadata.Nesting = sourceExecution.Spec.Metadata.Nesting + 1\n\t} else {\n\t\trequestSpec.Metadata.Nesting = 1\n\t}\n\treturn parentNodeExecutionID, sourceExecutionID, nil\n}\n\n// Produces execution-time attributes for workflow execution.\n// Defaults to overridable execution values set in the execution create request, then looks at the launch plan values\n// (if any) before defaulting to values set in the matchable resource db and further if matchable resources don't\n// exist then defaults to one set in application configuration\nfunc (m *ExecutionManager) getExecutionConfig(ctx context.Context, request *admin.ExecutionCreateRequest,\n\tlaunchPlan *admin.LaunchPlan) (*admin.WorkflowExecutionConfig, error) {\n\n\tworkflowExecConfig := admin.WorkflowExecutionConfig{}\n\t// Merge the request spec into workflowExecConfig\n\tworkflowExecConfig = util.MergeIntoExecConfig(workflowExecConfig, request.Spec)\n\n\tvar workflowName string\n\tif launchPlan != nil && launchPlan.Spec != nil {\n\t\t// Merge the launch plan spec into workflowExecConfig\n\t\tworkflowExecConfig = util.MergeIntoExecConfig(workflowExecConfig, launchPlan.Spec)\n\t\tif launchPlan.Spec.WorkflowId != nil {\n\t\t\tworkflowName = launchPlan.Spec.WorkflowId.Name\n\t\t}\n\t}\n\n\t// This will get the most specific Workflow Execution Config.\n\tmatchableResource, err := util.GetMatchableResource(ctx, m.resourceManager,\n\t\tadmin.MatchableResource_WORKFLOW_EXECUTION_CONFIG, request.Project, request.Domain, workflowName)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif matchableResource != nil && matchableResource.Attributes.GetWorkflowExecutionConfig() != nil {\n\t\t// merge the matchable resource workflow execution config into workflowExecConfig\n\t\tworkflowExecConfig = util.MergeIntoExecConfig(workflowExecConfig,\n\t\t\tmatchableResource.Attributes.GetWorkflowExecutionConfig())\n\t}\n\n\t// To match what the front-end will display to the user, we need to do the project level query too.\n\t// This searches only for a direct match, and will not merge in system config level defaults like the\n\t// GetProjectAttributes call does, since that's done below.\n\t// The reason we need to do the project level query is for the case where some configs (say max parallelism)\n\t// is set on the project level, but other items (say service account) is set on the project-domain level.\n\t// In this case you want to use the project-domain service account, the project-level max parallelism, and\n\t// system level defaults for the rest.\n\t// See FLYTE-2322 for more background information.\n\tprojectMatchableResource, err := util.GetMatchableResource(ctx, m.resourceManager,\n\t\tadmin.MatchableResource_WORKFLOW_EXECUTION_CONFIG, request.Project, \"\", \"\")\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif projectMatchableResource != nil && projectMatchableResource.Attributes.GetWorkflowExecutionConfig() != nil {\n\t\t// merge the matchable resource workflow execution config into workflowExecConfig\n\t\tworkflowExecConfig = util.MergeIntoExecConfig(workflowExecConfig,\n\t\t\tprojectMatchableResource.Attributes.GetWorkflowExecutionConfig())\n\t}\n\n\t// Backward compatibility changes to get security context from auth role.\n\t// Older authRole or auth fields in the launchplan spec or execution request need to be used over application defaults.\n\t// This portion of the code makes sure if newer way of setting security context is empty i.e\n\t// K8sServiceAccount and  IamRole is empty then get the values from the deprecated fields.\n\tresolvedAuthRole := resolveAuthRole(request, launchPlan)\n\tresolvedSecurityCtx := resolveSecurityCtx(ctx, workflowExecConfig.GetSecurityContext(), resolvedAuthRole)\n\tif workflowExecConfig.GetSecurityContext() == nil &&\n\t\t(len(resolvedSecurityCtx.GetRunAs().GetK8SServiceAccount()) > 0 ||\n\t\t\tlen(resolvedSecurityCtx.GetRunAs().GetIamRole()) > 0) {\n\t\tworkflowExecConfig.SecurityContext = resolvedSecurityCtx\n\t}\n\n\t// Merge the application config into workflowExecConfig. If even the deprecated fields are not set\n\tworkflowExecConfig = util.MergeIntoExecConfig(workflowExecConfig, m.config.ApplicationConfiguration().GetTopLevelConfig())\n\t// Explicitly set the security context if its nil since downstream we expect this settings to be available\n\tif workflowExecConfig.GetSecurityContext() == nil {\n\t\tworkflowExecConfig.SecurityContext = &core.SecurityContext{\n\t\t\tRunAs: &core.Identity{},\n\t\t}\n\t}\n\n\tif workflowExecConfig.GetSecurityContext().GetRunAs() == nil {\n\t\tworkflowExecConfig.SecurityContext.RunAs = &core.Identity{}\n\t}\n\n\t// In the case of reference_launch_plan subworkflow, the context comes from flytepropeller instead of the user side, so user auth is missing.\n\t// We skip getUserIdentityFromContext but can still get ExecUserId because flytepropeller passes it in the execution request.\n\t// https://github.com/flyteorg/flytepropeller/blob/03a6672960ed04e7687ba4f790fee9a02a4057fb/pkg/controller/nodes/subworkflow/launchplan/admin.go#L114\n\tif workflowExecConfig.GetSecurityContext().GetRunAs().GetExecutionIdentity() == \"\" {\n\t\tworkflowExecConfig.SecurityContext.RunAs.ExecutionIdentity = auth.IdentityContextFromContext(ctx).ExecutionIdentity()\n\t}\n\n\tlogger.Infof(ctx, \"getting the workflow execution config from application configuration\")\n\t// Defaults to one from the application config\n\treturn &workflowExecConfig, nil\n}\n\nfunc (m *ExecutionManager) getClusterAssignment(ctx context.Context, request *admin.ExecutionCreateRequest) (\n\t*admin.ClusterAssignment, error) {\n\tif request.Spec.ClusterAssignment != nil {\n\t\treturn request.Spec.ClusterAssignment, nil\n\t}\n\n\tresource, err := m.resourceManager.GetResource(ctx, interfaces.ResourceRequest{\n\t\tProject:      request.Project,\n\t\tDomain:       request.Domain,\n\t\tResourceType: admin.MatchableResource_CLUSTER_ASSIGNMENT,\n\t})\n\tif err != nil {\n\t\tif flyteAdminError, ok := err.(errors.FlyteAdminError); !ok || flyteAdminError.Code() != codes.NotFound {\n\t\t\tlogger.Errorf(ctx, \"Failed to get cluster assignment overrides with error: %v\", err)\n\t\t\treturn nil, err\n\t\t}\n\t}\n\tif resource != nil && resource.Attributes.GetClusterAssignment() != nil {\n\t\treturn resource.Attributes.GetClusterAssignment(), nil\n\t}\n\tclusterPoolAssignment := m.config.ClusterPoolAssignmentConfiguration().GetClusterPoolAssignments()[request.GetDomain()]\n\n\treturn &admin.ClusterAssignment{\n\t\tClusterPoolName: clusterPoolAssignment.Pool,\n\t}, nil\n}\n\nfunc (m *ExecutionManager) launchSingleTaskExecution(\n\tctx context.Context, request admin.ExecutionCreateRequest, requestedAt time.Time) (\n\tcontext.Context, *models.Execution, error) {\n\n\ttaskModel, err := m.db.TaskRepo().Get(ctx, repositoryInterfaces.Identifier{\n\t\tProject: request.Spec.LaunchPlan.Project,\n\t\tDomain:  request.Spec.LaunchPlan.Domain,\n\t\tName:    request.Spec.LaunchPlan.Name,\n\t\tVersion: request.Spec.LaunchPlan.Version,\n\t})\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\ttask, err := transformers.FromTaskModel(taskModel)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\n\t// Prepare a skeleton workflow\n\ttaskIdentifier := request.Spec.LaunchPlan\n\tworkflowModel, err :=\n\t\tutil.CreateOrGetWorkflowModel(ctx, request, m.db, m.workflowManager, m.namedEntityManager, taskIdentifier, &task)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"Failed to created skeleton workflow for [%+v] with err: %v\", taskIdentifier, err)\n\t\treturn nil, nil, err\n\t}\n\tworkflow, err := transformers.FromWorkflowModel(*workflowModel)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\tclosure, err := util.FetchAndGetWorkflowClosure(ctx, m.storageClient, workflowModel.RemoteClosureIdentifier)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\tclosure.CreatedAt = workflow.Closure.CreatedAt\n\tworkflow.Closure = closure\n\t// Also prepare a skeleton launch plan.\n\tlaunchPlan, err := util.CreateOrGetLaunchPlan(ctx, m.db, m.config, taskIdentifier,\n\t\tworkflow.Closure.CompiledWorkflow.Primary.Template.Interface, workflowModel.ID, request.Spec)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\n\texecutionInputs, err := validation.CheckAndFetchInputsForExecution(\n\t\trequest.Inputs,\n\t\tlaunchPlan.Spec.FixedInputs,\n\t\tlaunchPlan.Closure.ExpectedInputs,\n\t)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"Failed to CheckAndFetchInputsForExecution with request.Inputs: %+v\"+\n\t\t\t\"fixed inputs: %+v and expected inputs: %+v with err %v\",\n\t\t\trequest.Inputs, launchPlan.Spec.FixedInputs, launchPlan.Closure.ExpectedInputs, err)\n\t\treturn nil, nil, err\n\t}\n\n\tname := util.GetExecutionName(request)\n\tworkflowExecutionID := core.WorkflowExecutionIdentifier{\n\t\tProject: request.Project,\n\t\tDomain:  request.Domain,\n\t\tName:    name,\n\t}\n\tctx = getExecutionContext(ctx, &workflowExecutionID)\n\tnamespace := common.GetNamespaceName(\n\t\tm.config.NamespaceMappingConfiguration().GetNamespaceTemplate(), workflowExecutionID.Project, workflowExecutionID.Domain)\n\n\trequestSpec := request.Spec\n\tif requestSpec.Metadata == nil {\n\t\trequestSpec.Metadata = &admin.ExecutionMetadata{}\n\t}\n\trequestSpec.Metadata.Principal = getUser(ctx)\n\n\t// Get the node execution (if any) that launched this execution\n\tvar parentNodeExecutionID uint\n\tvar sourceExecutionID uint\n\tparentNodeExecutionID, sourceExecutionID, err = m.getInheritedExecMetadata(ctx, requestSpec, &workflowExecutionID)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\n\t// Dynamically assign task resource defaults.\n\tplatformTaskResources := util.GetTaskResources(ctx, workflow.Id, m.resourceManager, m.config.TaskResourceConfiguration())\n\tfor _, t := range workflow.Closure.CompiledWorkflow.Tasks {\n\t\tm.setCompiledTaskDefaults(ctx, t, platformTaskResources)\n\t}\n\n\t// Dynamically assign execution queues.\n\tm.populateExecutionQueue(ctx, *workflow.Id, workflow.Closure.CompiledWorkflow)\n\n\tinputsURI, err := common.OffloadLiteralMap(ctx, m.storageClient, request.Inputs, workflowExecutionID.Project, workflowExecutionID.Domain, workflowExecutionID.Name, shared.Inputs)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\tuserInputsURI, err := common.OffloadLiteralMap(ctx, m.storageClient, request.Inputs, workflowExecutionID.Project, workflowExecutionID.Domain, workflowExecutionID.Name, shared.UserInputs)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\texecutionConfig, err := m.getExecutionConfig(ctx, &request, nil)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\n\tvar labels map[string]string\n\tif executionConfig.Labels != nil {\n\t\tlabels = executionConfig.Labels.Values\n\t}\n\n\tlabels, err = m.addProjectLabels(ctx, request.Project, labels)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\n\tvar annotations map[string]string\n\tif executionConfig.Annotations != nil {\n\t\tannotations = executionConfig.Annotations.Values\n\t}\n\n\tvar rawOutputDataConfig *admin.RawOutputDataConfig\n\tif executionConfig.RawOutputDataConfig != nil {\n\t\trawOutputDataConfig = executionConfig.RawOutputDataConfig\n\t}\n\n\tclusterAssignment, err := m.getClusterAssignment(ctx, &request)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\n\texecutionParameters := workflowengineInterfaces.ExecutionParameters{\n\t\tInputs:              executionInputs,\n\t\tAcceptedAt:          requestedAt,\n\t\tLabels:              labels,\n\t\tAnnotations:         annotations,\n\t\tExecutionConfig:     executionConfig,\n\t\tTaskResources:       &platformTaskResources,\n\t\tEventVersion:        m.config.ApplicationConfiguration().GetTopLevelConfig().EventVersion,\n\t\tRoleNameKey:         m.config.ApplicationConfiguration().GetTopLevelConfig().RoleNameKey,\n\t\tRawOutputDataConfig: rawOutputDataConfig,\n\t\tClusterAssignment:   clusterAssignment,\n\t}\n\n\toverrides, err := m.addPluginOverrides(ctx, &workflowExecutionID, workflowExecutionID.Name, \"\")\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\tif overrides != nil {\n\t\texecutionParameters.TaskPluginOverrides = overrides\n\t}\n\tif request.Spec.Metadata != nil && request.Spec.Metadata.ReferenceExecution != nil &&\n\t\trequest.Spec.Metadata.Mode == admin.ExecutionMetadata_RECOVERED {\n\t\texecutionParameters.RecoveryExecution = request.Spec.Metadata.ReferenceExecution\n\t}\n\n\tworkflowExecutor := plugins.Get[workflowengineInterfaces.WorkflowExecutor](m.pluginRegistry, plugins.PluginIDWorkflowExecutor)\n\texecInfo, err := workflowExecutor.Execute(ctx, workflowengineInterfaces.ExecutionData{\n\t\tNamespace:                namespace,\n\t\tExecutionID:              &workflowExecutionID,\n\t\tReferenceWorkflowName:    workflow.Id.Name,\n\t\tReferenceLaunchPlanName:  launchPlan.Id.Name,\n\t\tWorkflowClosure:          workflow.Closure.CompiledWorkflow,\n\t\tWorkflowClosureReference: storage.DataReference(workflowModel.RemoteClosureIdentifier),\n\t\tExecutionParameters:      executionParameters,\n\t})\n\n\tif err != nil {\n\t\tm.systemMetrics.PropellerFailures.Inc()\n\t\tlogger.Infof(ctx, \"Failed to execute workflow %+v with execution id %+v and inputs %+v with err %v\",\n\t\t\trequest, workflowExecutionID, request.Inputs, err)\n\t\treturn nil, nil, err\n\t}\n\texecutionCreatedAt := time.Now()\n\tacceptanceDelay := executionCreatedAt.Sub(requestedAt)\n\tm.systemMetrics.AcceptanceDelay.Observe(acceptanceDelay.Seconds())\n\n\t// Request notification settings takes precedence over the launch plan settings.\n\t// If there is no notification in the request and DisableAll is not true, use the settings from the launch plan.\n\tvar notificationsSettings []*admin.Notification\n\tif launchPlan.Spec.GetEntityMetadata() != nil {\n\t\tnotificationsSettings = launchPlan.Spec.EntityMetadata.GetNotifications()\n\t}\n\tif request.Spec.GetNotifications() != nil && request.Spec.GetNotifications().Notifications != nil &&\n\t\tlen(request.Spec.GetNotifications().Notifications) > 0 {\n\t\tnotificationsSettings = request.Spec.GetNotifications().Notifications\n\t} else if request.Spec.GetDisableAll() {\n\t\tnotificationsSettings = make([]*admin.Notification, 0)\n\t}\n\n\texecutionModel, err := transformers.CreateExecutionModel(transformers.CreateExecutionModelInput{\n\t\tWorkflowExecutionID: workflowExecutionID,\n\t\tRequestSpec:         requestSpec,\n\t\tTaskID:              taskModel.ID,\n\t\tWorkflowID:          workflowModel.ID,\n\t\t// The execution is not considered running until the propeller sends a specific event saying so.\n\t\tPhase:                 core.WorkflowExecution_UNDEFINED,\n\t\tCreatedAt:             m._clock.Now(),\n\t\tNotifications:         notificationsSettings,\n\t\tWorkflowIdentifier:    workflow.Id,\n\t\tParentNodeExecutionID: parentNodeExecutionID,\n\t\tSourceExecutionID:     sourceExecutionID,\n\t\tCluster:               execInfo.Cluster,\n\t\tInputsURI:             inputsURI,\n\t\tUserInputsURI:         userInputsURI,\n\t\tSecurityContext:       executionConfig.SecurityContext,\n\t\tLaunchEntity:          taskIdentifier.ResourceType,\n\t\tNamespace:             namespace,\n\t})\n\tif err != nil {\n\t\tlogger.Infof(ctx, \"Failed to create execution model in transformer for id: [%+v] with err: %v\",\n\t\t\tworkflowExecutionID, err)\n\t\treturn nil, nil, err\n\t}\n\tm.userMetrics.WorkflowExecutionInputBytes.Observe(float64(proto.Size(request.Inputs)))\n\treturn ctx, executionModel, nil\n}\n\nfunc resolveAuthRole(request *admin.ExecutionCreateRequest, launchPlan *admin.LaunchPlan) *admin.AuthRole {\n\tif request.Spec.AuthRole != nil {\n\t\treturn request.Spec.AuthRole\n\t}\n\n\tif launchPlan == nil || launchPlan.Spec == nil {\n\t\treturn &admin.AuthRole{}\n\t}\n\n\t// Set role permissions based on launch plan Auth values.\n\t// The branched-ness of this check is due to the presence numerous deprecated fields\n\tif launchPlan.Spec.GetAuthRole() != nil {\n\t\treturn launchPlan.Spec.GetAuthRole()\n\t} else if launchPlan.GetSpec().GetAuth() != nil {\n\t\treturn &admin.AuthRole{\n\t\t\tAssumableIamRole:         launchPlan.GetSpec().GetAuth().AssumableIamRole,\n\t\t\tKubernetesServiceAccount: launchPlan.GetSpec().GetAuth().KubernetesServiceAccount,\n\t\t}\n\t} else if len(launchPlan.GetSpec().GetRole()) > 0 {\n\t\treturn &admin.AuthRole{\n\t\t\tAssumableIamRole: launchPlan.GetSpec().GetRole(),\n\t\t}\n\t}\n\n\treturn &admin.AuthRole{}\n}\n\nfunc resolveSecurityCtx(ctx context.Context, executionConfigSecurityCtx *core.SecurityContext,\n\tresolvedAuthRole *admin.AuthRole) *core.SecurityContext {\n\t// Use security context from the executionConfigSecurityCtx if its set and non empty or else resolve from authRole\n\tif executionConfigSecurityCtx != nil && executionConfigSecurityCtx.RunAs != nil &&\n\t\t(len(executionConfigSecurityCtx.RunAs.K8SServiceAccount) > 0 ||\n\t\t\tlen(executionConfigSecurityCtx.RunAs.IamRole) > 0 ||\n\t\t\tlen(executionConfigSecurityCtx.RunAs.ExecutionIdentity) > 0) {\n\t\treturn executionConfigSecurityCtx\n\t}\n\tlogger.Warn(ctx, \"Setting security context from auth Role\")\n\treturn &core.SecurityContext{\n\t\tRunAs: &core.Identity{\n\t\t\tIamRole:           resolvedAuthRole.AssumableIamRole,\n\t\t\tK8SServiceAccount: resolvedAuthRole.KubernetesServiceAccount,\n\t\t},\n\t}\n}\n\nfunc (m *ExecutionManager) launchExecutionAndPrepareModel(\n\tctx context.Context, request admin.ExecutionCreateRequest, requestedAt time.Time) (\n\tcontext.Context, *models.Execution, error) {\n\terr := validation.ValidateExecutionRequest(ctx, request, m.db, m.config.ApplicationConfiguration())\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"Failed to validate ExecutionCreateRequest %+v with err %v\", request, err)\n\t\treturn nil, nil, err\n\t}\n\tif request.Spec.LaunchPlan.ResourceType == core.ResourceType_TASK {\n\t\tlogger.Debugf(ctx, \"Launching single task execution with [%+v]\", request.Spec.LaunchPlan)\n\t\treturn m.launchSingleTaskExecution(ctx, request, requestedAt)\n\t}\n\n\tlaunchPlanModel, err := util.GetLaunchPlanModel(ctx, m.db, *request.Spec.LaunchPlan)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"Failed to get launch plan model for ExecutionCreateRequest %+v with err %v\", request, err)\n\t\treturn nil, nil, err\n\t}\n\tlaunchPlan, err := transformers.FromLaunchPlanModel(launchPlanModel)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"Failed to transform launch plan model %+v with err %v\", launchPlanModel, err)\n\t\treturn nil, nil, err\n\t}\n\texecutionInputs, err := validation.CheckAndFetchInputsForExecution(\n\t\trequest.Inputs,\n\t\tlaunchPlan.Spec.FixedInputs,\n\t\tlaunchPlan.Closure.ExpectedInputs,\n\t)\n\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"Failed to CheckAndFetchInputsForExecution with request.Inputs: %+v\"+\n\t\t\t\"fixed inputs: %+v and expected inputs: %+v with err %v\",\n\t\t\trequest.Inputs, launchPlan.Spec.FixedInputs, launchPlan.Closure.ExpectedInputs, err)\n\t\treturn nil, nil, err\n\t}\n\n\tworkflowModel, err := util.GetWorkflowModel(ctx, m.db, *launchPlan.Spec.WorkflowId)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"Failed to get workflow with id %+v with err %v\", launchPlan.Spec.WorkflowId, err)\n\t\treturn nil, nil, err\n\t}\n\tworkflow, err := transformers.FromWorkflowModel(workflowModel)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"Failed to get workflow with id %+v with err %v\", launchPlan.Spec.WorkflowId, err)\n\t\treturn nil, nil, err\n\t}\n\tclosure, err := util.FetchAndGetWorkflowClosure(ctx, m.storageClient, workflowModel.RemoteClosureIdentifier)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"Failed to get workflow with id %+v with err %v\", launchPlan.Spec.WorkflowId, err)\n\t\treturn nil, nil, err\n\t}\n\tclosure.CreatedAt = workflow.Closure.CreatedAt\n\tworkflow.Closure = closure\n\n\tname := util.GetExecutionName(request)\n\tworkflowExecutionID := core.WorkflowExecutionIdentifier{\n\t\tProject: request.Project,\n\t\tDomain:  request.Domain,\n\t\tName:    name,\n\t}\n\tctx = getExecutionContext(ctx, &workflowExecutionID)\n\tvar requestSpec = request.Spec\n\tif requestSpec.Metadata == nil {\n\t\trequestSpec.Metadata = &admin.ExecutionMetadata{}\n\t}\n\trequestSpec.Metadata.Principal = getUser(ctx)\n\n\t// Get the node and parent execution (if any) that launched this execution\n\tvar parentNodeExecutionID uint\n\tvar sourceExecutionID uint\n\tparentNodeExecutionID, sourceExecutionID, err = m.getInheritedExecMetadata(ctx, requestSpec, &workflowExecutionID)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\n\t// Dynamically assign task resource defaults.\n\tplatformTaskResources := util.GetTaskResources(ctx, workflow.Id, m.resourceManager, m.config.TaskResourceConfiguration())\n\tfor _, task := range workflow.Closure.CompiledWorkflow.Tasks {\n\t\tm.setCompiledTaskDefaults(ctx, task, platformTaskResources)\n\t}\n\n\t// Dynamically assign execution queues.\n\tm.populateExecutionQueue(ctx, *workflow.Id, workflow.Closure.CompiledWorkflow)\n\n\tinputsURI, err := common.OffloadLiteralMap(ctx, m.storageClient, executionInputs, workflowExecutionID.Project, workflowExecutionID.Domain, workflowExecutionID.Name, shared.Inputs)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\tuserInputsURI, err := common.OffloadLiteralMap(ctx, m.storageClient, request.Inputs, workflowExecutionID.Project, workflowExecutionID.Domain, workflowExecutionID.Name, shared.UserInputs)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\n\texecutionConfig, err := m.getExecutionConfig(ctx, &request, launchPlan)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\n\tnamespace := common.GetNamespaceName(\n\t\tm.config.NamespaceMappingConfiguration().GetNamespaceTemplate(), workflowExecutionID.Project, workflowExecutionID.Domain)\n\n\tlabels, err := resolveStringMap(executionConfig.GetLabels(), launchPlan.Spec.Labels, \"labels\", m.config.RegistrationValidationConfiguration().GetMaxLabelEntries())\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\tlabels, err = m.addProjectLabels(ctx, request.Project, labels)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\tannotations, err := resolveStringMap(executionConfig.GetAnnotations(), launchPlan.Spec.Annotations, \"annotations\", m.config.RegistrationValidationConfiguration().GetMaxAnnotationEntries())\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\tvar rawOutputDataConfig *admin.RawOutputDataConfig\n\tif executionConfig.RawOutputDataConfig != nil {\n\t\trawOutputDataConfig = executionConfig.RawOutputDataConfig\n\t}\n\n\tclusterAssignment, err := m.getClusterAssignment(ctx, &request)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\n\texecutionParameters := workflowengineInterfaces.ExecutionParameters{\n\t\tInputs:              executionInputs,\n\t\tAcceptedAt:          requestedAt,\n\t\tLabels:              labels,\n\t\tAnnotations:         annotations,\n\t\tExecutionConfig:     executionConfig,\n\t\tTaskResources:       &platformTaskResources,\n\t\tEventVersion:        m.config.ApplicationConfiguration().GetTopLevelConfig().EventVersion,\n\t\tRoleNameKey:         m.config.ApplicationConfiguration().GetTopLevelConfig().RoleNameKey,\n\t\tRawOutputDataConfig: rawOutputDataConfig,\n\t\tClusterAssignment:   clusterAssignment,\n\t}\n\n\toverrides, err := m.addPluginOverrides(ctx, &workflowExecutionID, launchPlan.GetSpec().WorkflowId.Name, launchPlan.Id.Name)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\tif overrides != nil {\n\t\texecutionParameters.TaskPluginOverrides = overrides\n\t}\n\n\tif request.Spec.Metadata != nil && request.Spec.Metadata.ReferenceExecution != nil &&\n\t\trequest.Spec.Metadata.Mode == admin.ExecutionMetadata_RECOVERED {\n\t\texecutionParameters.RecoveryExecution = request.Spec.Metadata.ReferenceExecution\n\t}\n\n\tworkflowExecutor := plugins.Get[workflowengineInterfaces.WorkflowExecutor](m.pluginRegistry, plugins.PluginIDWorkflowExecutor)\n\texecInfo, err := workflowExecutor.Execute(ctx, workflowengineInterfaces.ExecutionData{\n\t\tNamespace:                namespace,\n\t\tExecutionID:              &workflowExecutionID,\n\t\tReferenceWorkflowName:    workflow.Id.Name,\n\t\tReferenceLaunchPlanName:  launchPlan.Id.Name,\n\t\tWorkflowClosure:          workflow.Closure.CompiledWorkflow,\n\t\tWorkflowClosureReference: storage.DataReference(workflowModel.RemoteClosureIdentifier),\n\t\tExecutionParameters:      executionParameters,\n\t})\n\n\tif err != nil {\n\t\tm.systemMetrics.PropellerFailures.Inc()\n\t\tlogger.Infof(ctx, \"Failed to execute workflow %+v with execution id %+v and inputs %+v with err %v\",\n\t\t\trequest, workflowExecutionID, executionInputs, err)\n\t\treturn nil, nil, err\n\t}\n\texecutionCreatedAt := time.Now()\n\tacceptanceDelay := executionCreatedAt.Sub(requestedAt)\n\tm.systemMetrics.AcceptanceDelay.Observe(acceptanceDelay.Seconds())\n\n\t// Request notification settings takes precedence over the launch plan settings.\n\t// If there is no notification in the request and DisableAll is not true, use the settings from the launch plan.\n\tvar notificationsSettings []*admin.Notification\n\tif launchPlan.Spec.GetEntityMetadata() != nil {\n\t\tnotificationsSettings = launchPlan.Spec.EntityMetadata.GetNotifications()\n\t}\n\tif requestSpec.GetNotifications() != nil && requestSpec.GetNotifications().Notifications != nil &&\n\t\tlen(requestSpec.GetNotifications().Notifications) > 0 {\n\t\tnotificationsSettings = requestSpec.GetNotifications().Notifications\n\t} else if requestSpec.GetDisableAll() {\n\t\tnotificationsSettings = make([]*admin.Notification, 0)\n\t}\n\n\texecutionModel, err := transformers.CreateExecutionModel(transformers.CreateExecutionModelInput{\n\t\tWorkflowExecutionID: workflowExecutionID,\n\t\tRequestSpec:         requestSpec,\n\t\tLaunchPlanID:        launchPlanModel.ID,\n\t\tWorkflowID:          launchPlanModel.WorkflowID,\n\t\t// The execution is not considered running until the propeller sends a specific event saying so.\n\t\tPhase:                 core.WorkflowExecution_UNDEFINED,\n\t\tCreatedAt:             m._clock.Now(),\n\t\tNotifications:         notificationsSettings,\n\t\tWorkflowIdentifier:    workflow.Id,\n\t\tParentNodeExecutionID: parentNodeExecutionID,\n\t\tSourceExecutionID:     sourceExecutionID,\n\t\tCluster:               execInfo.Cluster,\n\t\tInputsURI:             inputsURI,\n\t\tUserInputsURI:         userInputsURI,\n\t\tSecurityContext:       executionConfig.SecurityContext,\n\t\tLaunchEntity:          launchPlan.Id.ResourceType,\n\t\tNamespace:             namespace,\n\t})\n\tif err != nil {\n\t\tlogger.Infof(ctx, \"Failed to create execution model in transformer for id: [%+v] with err: %v\",\n\t\t\tworkflowExecutionID, err)\n\t\treturn nil, nil, err\n\t}\n\n\treturn ctx, executionModel, nil\n}\n\n// Inserts an execution model into the database store and emits platform metrics.\nfunc (m *ExecutionManager) createExecutionModel(\n\tctx context.Context, executionModel *models.Execution) (*core.WorkflowExecutionIdentifier, error) {\n\tworkflowExecutionIdentifier := core.WorkflowExecutionIdentifier{\n\t\tProject: executionModel.ExecutionKey.Project,\n\t\tDomain:  executionModel.ExecutionKey.Domain,\n\t\tName:    executionModel.ExecutionKey.Name,\n\t}\n\terr := m.db.ExecutionRepo().Create(ctx, *executionModel)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"failed to save newly created execution [%+v] with id %+v to db with err %v\",\n\t\t\tworkflowExecutionIdentifier, workflowExecutionIdentifier, err)\n\t\treturn nil, err\n\t}\n\tm.systemMetrics.ActiveExecutions.Inc()\n\tm.systemMetrics.ExecutionsCreated.Inc()\n\tm.systemMetrics.SpecSizeBytes.Observe(float64(len(executionModel.Spec)))\n\tm.systemMetrics.ClosureSizeBytes.Observe(float64(len(executionModel.Closure)))\n\treturn &workflowExecutionIdentifier, nil\n}\n\nfunc (m *ExecutionManager) CreateExecution(\n\tctx context.Context, request admin.ExecutionCreateRequest, requestedAt time.Time) (\n\t*admin.ExecutionCreateResponse, error) {\n\t// Prior to  flyteidl v0.15.0, Inputs was held in ExecutionSpec. Ensure older clients continue to work.\n\tif request.Inputs == nil || len(request.Inputs.Literals) == 0 {\n\t\trequest.Inputs = request.GetSpec().GetInputs()\n\t}\n\tvar executionModel *models.Execution\n\tvar err error\n\tctx, executionModel, err = m.launchExecutionAndPrepareModel(ctx, request, requestedAt)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tworkflowExecutionIdentifier, err := m.createExecutionModel(ctx, executionModel)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn &admin.ExecutionCreateResponse{\n\t\tId: workflowExecutionIdentifier,\n\t}, nil\n}\n\nfunc (m *ExecutionManager) RelaunchExecution(\n\tctx context.Context, request admin.ExecutionRelaunchRequest, requestedAt time.Time) (\n\t*admin.ExecutionCreateResponse, error) {\n\texistingExecutionModel, err := util.GetExecutionModel(ctx, m.db, *request.Id)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"Failed to get execution model for request [%+v] with err %v\", request, err)\n\t\treturn nil, err\n\t}\n\texistingExecution, err := transformers.FromExecutionModel(ctx, *existingExecutionModel, transformers.DefaultExecutionTransformerOptions)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\texecutionSpec := existingExecution.Spec\n\tif executionSpec.Metadata == nil {\n\t\texecutionSpec.Metadata = &admin.ExecutionMetadata{}\n\t}\n\tvar inputs *core.LiteralMap\n\tif len(existingExecutionModel.UserInputsURI) > 0 {\n\t\tinputs = &core.LiteralMap{}\n\t\tif err := m.storageClient.ReadProtobuf(ctx, existingExecutionModel.UserInputsURI, inputs); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t} else {\n\t\t// For old data, inputs are held in the spec\n\t\tvar spec admin.ExecutionSpec\n\t\terr = proto.Unmarshal(existingExecutionModel.Spec, &spec)\n\t\tif err != nil {\n\t\t\treturn nil, errors.NewFlyteAdminErrorf(codes.Internal, \"failed to unmarshal spec\")\n\t\t}\n\t\tinputs = spec.Inputs\n\t}\n\texecutionSpec.Metadata.Mode = admin.ExecutionMetadata_RELAUNCH\n\texecutionSpec.Metadata.ReferenceExecution = existingExecution.Id\n\texecutionSpec.OverwriteCache = request.GetOverwriteCache()\n\tvar executionModel *models.Execution\n\tctx, executionModel, err = m.launchExecutionAndPrepareModel(ctx, admin.ExecutionCreateRequest{\n\t\tProject: request.Id.Project,\n\t\tDomain:  request.Id.Domain,\n\t\tName:    request.Name,\n\t\tSpec:    executionSpec,\n\t\tInputs:  inputs,\n\t}, requestedAt)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\texecutionModel.SourceExecutionID = existingExecutionModel.ID\n\tworkflowExecutionIdentifier, err := m.createExecutionModel(ctx, executionModel)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tlogger.Debugf(ctx, \"Successfully relaunched [%+v] as [%+v]\", request.Id, workflowExecutionIdentifier)\n\treturn &admin.ExecutionCreateResponse{\n\t\tId: workflowExecutionIdentifier,\n\t}, nil\n}\n\nfunc (m *ExecutionManager) RecoverExecution(\n\tctx context.Context, request admin.ExecutionRecoverRequest, requestedAt time.Time) (\n\t*admin.ExecutionCreateResponse, error) {\n\texistingExecutionModel, err := util.GetExecutionModel(ctx, m.db, *request.Id)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"Failed to get execution model for request [%+v] with err %v\", request, err)\n\t\treturn nil, err\n\t}\n\texistingExecution, err := transformers.FromExecutionModel(ctx, *existingExecutionModel, transformers.DefaultExecutionTransformerOptions)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\texecutionSpec := existingExecution.Spec\n\tif executionSpec.Metadata == nil {\n\t\texecutionSpec.Metadata = &admin.ExecutionMetadata{}\n\t}\n\tvar inputs *core.LiteralMap\n\tif len(existingExecutionModel.UserInputsURI) > 0 {\n\t\tinputs = &core.LiteralMap{}\n\t\tif err := m.storageClient.ReadProtobuf(ctx, existingExecutionModel.UserInputsURI, inputs); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\tif request.Metadata != nil {\n\t\texecutionSpec.Metadata.ParentNodeExecution = request.Metadata.ParentNodeExecution\n\t}\n\texecutionSpec.Metadata.Mode = admin.ExecutionMetadata_RECOVERED\n\texecutionSpec.Metadata.ReferenceExecution = existingExecution.Id\n\tvar executionModel *models.Execution\n\tctx, executionModel, err = m.launchExecutionAndPrepareModel(ctx, admin.ExecutionCreateRequest{\n\t\tProject: request.Id.Project,\n\t\tDomain:  request.Id.Domain,\n\t\tName:    request.Name,\n\t\tSpec:    executionSpec,\n\t\tInputs:  inputs,\n\t}, requestedAt)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\texecutionModel.SourceExecutionID = existingExecutionModel.ID\n\tworkflowExecutionIdentifier, err := m.createExecutionModel(ctx, executionModel)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tlogger.Infof(ctx, \"Successfully recovered [%+v] as [%+v]\", request.Id, workflowExecutionIdentifier)\n\treturn &admin.ExecutionCreateResponse{\n\t\tId: workflowExecutionIdentifier,\n\t}, nil\n}\n\nfunc (m *ExecutionManager) emitScheduledWorkflowMetrics(\n\tctx context.Context, executionModel *models.Execution, runningEventTimeProto *timestamp.Timestamp) {\n\tif executionModel == nil || runningEventTimeProto == nil {\n\t\tlogger.Warningf(context.Background(),\n\t\t\t\"tried to calculate scheduled workflow execution stats with a nil execution or event time\")\n\t\treturn\n\t}\n\t// Find the reference launch plan to get the kickoff time argument\n\texecution, err := transformers.FromExecutionModel(ctx, *executionModel, transformers.DefaultExecutionTransformerOptions)\n\tif err != nil {\n\t\tlogger.Warningf(context.Background(),\n\t\t\t\"failed to transform execution model when emitting scheduled workflow execution stats with for \"+\n\t\t\t\t\"[%s/%s/%s]\", executionModel.Project, executionModel.Domain, executionModel.Name)\n\t\treturn\n\t}\n\tlaunchPlan, err := util.GetLaunchPlan(context.Background(), m.db, *execution.Spec.LaunchPlan)\n\tif err != nil {\n\t\tlogger.Warningf(context.Background(),\n\t\t\t\"failed to find launch plan when emitting scheduled workflow execution stats with for \"+\n\t\t\t\t\"execution: [%+v] and launch plan [%+v]\", execution.Id, execution.Spec.LaunchPlan)\n\t\treturn\n\t}\n\n\tif launchPlan.Spec.EntityMetadata == nil ||\n\t\tlaunchPlan.Spec.EntityMetadata.Schedule == nil ||\n\t\tlaunchPlan.Spec.EntityMetadata.Schedule.KickoffTimeInputArg == \"\" {\n\t\t// Kickoff time arguments aren't always required for scheduled workflows.\n\t\tlogger.Debugf(context.Background(), \"no kickoff time to report for scheduled workflow execution [%+v]\",\n\t\t\texecution.Id)\n\t\treturn\n\t}\n\n\tvar inputs core.LiteralMap\n\terr = m.storageClient.ReadProtobuf(ctx, executionModel.InputsURI, &inputs)\n\tif err != nil {\n\t\tlogger.Errorf(ctx, \"Failed to find inputs for emitting schedule delay event from uri: [%v]\", executionModel.InputsURI)\n\t\treturn\n\t}\n\tscheduledKickoffTimeProto := inputs.Literals[launchPlan.Spec.EntityMetadata.Schedule.KickoffTimeInputArg]\n\tif scheduledKickoffTimeProto == nil || scheduledKickoffTimeProto.GetScalar() == nil ||\n\t\tscheduledKickoffTimeProto.GetScalar().GetPrimitive() == nil ||\n\t\tscheduledKickoffTimeProto.GetScalar().GetPrimitive().GetDatetime() == nil {\n\t\tlogger.Warningf(context.Background(),\n\t\t\t\"failed to find scheduled kickoff time datetime value for scheduled workflow execution [%+v] \"+\n\t\t\t\t\"although one was expected\", execution.Id)\n\t\treturn\n\t}\n\tscheduledKickoffTime, err := ptypes.Timestamp(scheduledKickoffTimeProto.GetScalar().GetPrimitive().GetDatetime())\n\tif err != nil {\n\t\t// Timestamps are serialized by flyteadmin and should always be valid\n\t\treturn\n\t}\n\trunningEventTime, err := ptypes.Timestamp(runningEventTimeProto)\n\tif err != nil {\n\t\t// Timestamps are always sent from propeller and should always be valid\n\t\treturn\n\t}\n\n\tdomainCounterMap, ok := m.userMetrics.ScheduledExecutionDelays[execution.Id.Project]\n\tif !ok {\n\t\tdomainCounterMap = make(map[string]*promutils.StopWatch)\n\t\tm.userMetrics.ScheduledExecutionDelays[execution.Id.Project] = domainCounterMap\n\t}\n\n\tvar watch *promutils.StopWatch\n\twatch, ok = domainCounterMap[execution.Id.Domain]\n\tif !ok {\n\t\tnewWatch, err := m.systemMetrics.Scope.NewSubScope(execution.Id.Project).NewSubScope(execution.Id.Domain).NewStopWatch(\n\t\t\t\"scheduled_execution_delay\",\n\t\t\t\"delay between scheduled execution time and time execution was observed running\",\n\t\t\ttime.Nanosecond)\n\t\tif err != nil {\n\t\t\t// Could be related to a concurrent exception.\n\t\t\tlogger.Debugf(context.Background(),\n\t\t\t\t\"failed to emit scheduled workflow execution delay stat, couldn't find or create counter\")\n\t\t\treturn\n\t\t}\n\t\twatch = &newWatch\n\t\tdomainCounterMap[execution.Id.Domain] = watch\n\t}\n\twatch.Observe(scheduledKickoffTime, runningEventTime)\n}\n\nfunc (m *ExecutionManager) emitOverallWorkflowExecutionTime(\n\texecutionModel *models.Execution, terminalEventTimeProto *timestamp.Timestamp) {\n\tif executionModel == nil || terminalEventTimeProto == nil {\n\t\tlogger.Warningf(context.Background(),\n\t\t\t\"tried to calculate scheduled workflow execution stats with a nil execution or event time\")\n\t\treturn\n\t}\n\n\tdomainCounterMap, ok := m.userMetrics.WorkflowExecutionDurations[executionModel.Project]\n\tif !ok {\n\t\tdomainCounterMap = make(map[string]*promutils.StopWatch)\n\t\tm.userMetrics.WorkflowExecutionDurations[executionModel.Project] = domainCounterMap\n\t}\n\n\tvar watch *promutils.StopWatch\n\twatch, ok = domainCounterMap[executionModel.Domain]\n\tif !ok {\n\t\tnewWatch, err := m.systemMetrics.Scope.NewSubScope(executionModel.Project).NewSubScope(executionModel.Domain).NewStopWatch(\n\t\t\t\"workflow_execution_duration\",\n\t\t\t\"overall time from when when a workflow create request was sent to k8s to the workflow terminating\",\n\t\t\ttime.Nanosecond)\n\t\tif err != nil {\n\t\t\t// Could be related to a concurrent exception.\n\t\t\tlogger.Debugf(context.Background(),\n\t\t\t\t\"failed to emit workflow execution duration stat, couldn't find or create counter\")\n\t\t\treturn\n\t\t}\n\t\twatch = &newWatch\n\t\tdomainCounterMap[executionModel.Domain] = watch\n\t}\n\n\tterminalEventTime, err := ptypes.Timestamp(terminalEventTimeProto)\n\tif err != nil {\n\t\t// Timestamps are always sent from propeller and should always be valid\n\t\treturn\n\t}\n\n\tif executionModel.ExecutionCreatedAt == nil {\n\t\tlogger.Warningf(context.Background(), \"found execution with nil ExecutionCreatedAt: [%s/%s/%s]\",\n\t\t\texecutionModel.Project, executionModel.Domain, executionModel.Name)\n\t\treturn\n\t}\n\twatch.Observe(*executionModel.ExecutionCreatedAt, terminalEventTime)\n}\n\nfunc (m *ExecutionManager) CreateWorkflowEvent(ctx context.Context, request admin.WorkflowExecutionEventRequest) (\n\t*admin.WorkflowExecutionEventResponse, error) {\n\terr := validation.ValidateCreateWorkflowEventRequest(request, m.config.ApplicationConfiguration().GetRemoteDataConfig().MaxSizeInBytes)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"received invalid CreateWorkflowEventRequest [%s]: %v\", request.RequestId, err)\n\t\treturn nil, err\n\t}\n\tctx = getExecutionContext(ctx, request.Event.ExecutionId)\n\tlogger.Debugf(ctx, \"Received workflow execution event for [%+v] transitioning to phase [%v]\",\n\t\trequest.Event.ExecutionId, request.Event.Phase)\n\n\texecutionModel, err := util.GetExecutionModel(ctx, m.db, *request.Event.ExecutionId)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"failed to find execution [%+v] for recorded event [%s]: %v\",\n\t\t\trequest.Event.ExecutionId, request.RequestId, err)\n\t\treturn nil, err\n\t}\n\n\twfExecPhase := core.WorkflowExecution_Phase(core.WorkflowExecution_Phase_value[executionModel.Phase])\n\t// Subsequent queued events announcing a cluster reassignment are permitted.\n\tif request.Event.Phase != core.WorkflowExecution_QUEUED {\n\t\tif wfExecPhase == request.Event.Phase {\n\t\t\tlogger.Debugf(ctx, \"This phase %s was already recorded for workflow execution %v\",\n\t\t\t\twfExecPhase.String(), request.Event.ExecutionId)\n\t\t\treturn nil, errors.NewFlyteAdminErrorf(codes.AlreadyExists,\n\t\t\t\t\"This phase %s was already recorded for workflow execution %v\",\n\t\t\t\twfExecPhase.String(), request.Event.ExecutionId)\n\t\t} else if err := validation.ValidateCluster(ctx, executionModel.Cluster, request.Event.ProducerId); err != nil {\n\t\t\t// Only perform event cluster validation **after** an execution has moved on from QUEUED.\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\tif common.IsExecutionTerminal(wfExecPhase) {\n\t\t// Cannot go backwards in time from a terminal state to anything else\n\t\tcurPhase := wfExecPhase.String()\n\t\terrorMsg := fmt.Sprintf(\"Invalid phase change from %s to %s for workflow execution %v\", curPhase, request.Event.Phase.String(), request.Event.ExecutionId)\n\t\treturn nil, errors.NewAlreadyInTerminalStateError(ctx, errorMsg, curPhase)\n\t} else if wfExecPhase == core.WorkflowExecution_RUNNING && request.Event.Phase == core.WorkflowExecution_QUEUED {\n\t\t// Cannot go back in time from RUNNING -> QUEUED\n\t\treturn nil, errors.NewFlyteAdminErrorf(codes.FailedPrecondition,\n\t\t\t\"Cannot go from %s to %s for workflow execution %v\",\n\t\t\twfExecPhase.String(), request.Event.Phase.String(), request.Event.ExecutionId)\n\t} else if wfExecPhase == core.WorkflowExecution_ABORTING && !common.IsExecutionTerminal(request.Event.Phase) {\n\t\treturn nil, errors.NewFlyteAdminErrorf(codes.FailedPrecondition,\n\t\t\t\"Invalid phase change from aborting to %s for workflow execution %v\", request.Event.Phase.String(), request.Event.ExecutionId)\n\t}\n\n\terr = transformers.UpdateExecutionModelState(ctx, executionModel, request, m.config.ApplicationConfiguration().GetRemoteDataConfig().InlineEventDataPolicy, m.storageClient)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"failed to transform updated workflow execution model [%+v] after receiving event with err: %v\",\n\t\t\trequest.Event.ExecutionId, err)\n\t\treturn nil, err\n\t}\n\terr = m.db.ExecutionRepo().Update(ctx, *executionModel)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"Failed to update execution with CreateWorkflowEvent [%+v] with err %v\",\n\t\t\trequest, err)\n\t\treturn nil, err\n\t}\n\tm.dbEventWriter.Write(request)\n\n\tif request.Event.Phase == core.WorkflowExecution_RUNNING {\n\t\t// Workflow executions are created in state \"UNDEFINED\". All the time up until a RUNNING event is received is\n\t\t// considered system-induced delay.\n\t\tif executionModel.Mode == int32(admin.ExecutionMetadata_SCHEDULED) {\n\t\t\tgo m.emitScheduledWorkflowMetrics(ctx, executionModel, request.Event.OccurredAt)\n\t\t}\n\t} else if common.IsExecutionTerminal(request.Event.Phase) {\n\t\tif request.Event.Phase == core.WorkflowExecution_FAILED {\n\t\t\t// request.Event is expected to be of type WorkflowExecutionEvent_Error when workflow fails.\n\t\t\t// if not, log the error and continue\n\t\t\tif err := request.Event.GetError(); err != nil {\n\t\t\t\tctx = context.WithValue(ctx, common.ErrorKindKey, err.Kind.String())\n\t\t\t} else {\n\t\t\t\tlogger.Warning(ctx, \"Failed to parse error for FAILED request [%+v]\", request)\n\t\t\t}\n\t\t}\n\n\t\tm.systemMetrics.ActiveExecutions.Dec()\n\t\tm.systemMetrics.ExecutionsTerminated.Inc(contextutils.WithPhase(ctx, request.Event.Phase.String()))\n\t\tgo m.emitOverallWorkflowExecutionTime(executionModel, request.Event.OccurredAt)\n\t\tif request.Event.GetOutputData() != nil {\n\t\t\tm.userMetrics.WorkflowExecutionOutputBytes.Observe(float64(proto.Size(request.Event.GetOutputData())))\n\t\t}\n\n\t\terr = m.publishNotifications(ctx, request, *executionModel)\n\t\tif err != nil {\n\t\t\t// The only errors that publishNotifications will forward are those related\n\t\t\t// to unexpected data and transformation errors.\n\t\t\tlogger.Debugf(ctx, \"failed to publish notifications for CreateWorkflowEvent [%+v] due to err: %v\",\n\t\t\t\trequest, err)\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\tif err := m.eventPublisher.Publish(ctx, proto.MessageName(&request), &request); err != nil {\n\t\tm.systemMetrics.PublishEventError.Inc()\n\t\tlogger.Infof(ctx, \"error publishing event [%+v] with err: [%v]\", request.RequestId, err)\n\t}\n\n\tgo func() {\n\t\tif err := m.cloudEventPublisher.Publish(ctx, proto.MessageName(&request), &request); err != nil {\n\t\t\tm.systemMetrics.PublishEventError.Inc()\n\t\t\tlogger.Infof(ctx, \"error publishing cloud event [%+v] with err: [%v]\", request.RequestId, err)\n\t\t}\n\t}()\n\n\treturn &admin.WorkflowExecutionEventResponse{}, nil\n}\n\nfunc (m *ExecutionManager) GetExecution(\n\tctx context.Context, request admin.WorkflowExecutionGetRequest) (*admin.Execution, error) {\n\tif err := validation.ValidateWorkflowExecutionIdentifier(request.Id); err != nil {\n\t\tlogger.Debugf(ctx, \"GetExecution request [%+v] failed validation with err: %v\", request, err)\n\t\treturn nil, err\n\t}\n\tctx = getExecutionContext(ctx, request.Id)\n\texecutionModel, err := util.GetExecutionModel(ctx, m.db, *request.Id)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"Failed to get execution model for request [%+v] with err: %v\", request, err)\n\t\treturn nil, err\n\t}\n\tnamespace := common.GetNamespaceName(\n\t\tm.config.NamespaceMappingConfiguration().GetNamespaceTemplate(), request.GetId().GetProject(), request.GetId().GetDomain())\n\texecution, transformerErr := transformers.FromExecutionModel(ctx, *executionModel, &transformers.ExecutionTransformerOptions{\n\t\tDefaultNamespace: namespace,\n\t})\n\tif transformerErr != nil {\n\t\tlogger.Debugf(ctx, \"Failed to transform execution model [%+v] to proto object with err: %v\", request.Id,\n\t\t\ttransformerErr)\n\t\treturn nil, transformerErr\n\t}\n\n\treturn execution, nil\n}\n\nfunc (m *ExecutionManager) UpdateExecution(ctx context.Context, request admin.ExecutionUpdateRequest,\n\trequestedAt time.Time) (*admin.ExecutionUpdateResponse, error) {\n\tif err := validation.ValidateWorkflowExecutionIdentifier(request.Id); err != nil {\n\t\tlogger.Debugf(ctx, \"UpdateExecution request [%+v] failed validation with err: %v\", request, err)\n\t\treturn nil, err\n\t}\n\tctx = getExecutionContext(ctx, request.Id)\n\texecutionModel, err := util.GetExecutionModel(ctx, m.db, *request.Id)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"Failed to get execution model for request [%+v] with err: %v\", request, err)\n\t\treturn nil, err\n\t}\n\n\tif err = transformers.UpdateExecutionModelStateChangeDetails(executionModel, request.State, requestedAt,\n\t\tgetUser(ctx)); err != nil {\n\t\treturn nil, err\n\t}\n\n\tif err := m.db.ExecutionRepo().Update(ctx, *executionModel); err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &admin.ExecutionUpdateResponse{}, nil\n}\n\nfunc (m *ExecutionManager) GetExecutionData(\n\tctx context.Context, request admin.WorkflowExecutionGetDataRequest) (*admin.WorkflowExecutionGetDataResponse, error) {\n\tctx = getExecutionContext(ctx, request.Id)\n\texecutionModel, err := util.GetExecutionModel(ctx, m.db, *request.Id)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"Failed to get execution model for request [%+v] with err: %v\", request, err)\n\t\treturn nil, err\n\t}\n\texecution, err := transformers.FromExecutionModel(ctx, *executionModel, transformers.DefaultExecutionTransformerOptions)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"Failed to transform execution model [%+v] to proto object with err: %v\", request.Id, err)\n\t\treturn nil, err\n\t}\n\t// Prior to flyteidl v0.15.0, Inputs were held in ExecutionClosure and were not offloaded. Ensure we can return the inputs as expected.\n\tif len(executionModel.InputsURI) == 0 {\n\t\tclosure := &admin.ExecutionClosure{}\n\t\t// We must not use the FromExecutionModel method because it empties deprecated fields.\n\t\tif err := proto.Unmarshal(executionModel.Closure, closure); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tnewInputsURI, err := common.OffloadLiteralMap(ctx, m.storageClient, closure.ComputedInputs, request.Id.Project, request.Id.Domain, request.Id.Name, shared.Inputs)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\t// Update model so as not to offload again.\n\t\texecutionModel.InputsURI = newInputsURI\n\t\tif err := m.db.ExecutionRepo().Update(ctx, *executionModel); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\tinputs, inputURLBlob, err := util.GetInputs(ctx, m.urlData, m.config.ApplicationConfiguration().GetRemoteDataConfig(),\n\t\tm.storageClient, executionModel.InputsURI.String())\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\toutputs, outputURLBlob, err := util.GetOutputs(ctx, m.urlData, m.config.ApplicationConfiguration().GetRemoteDataConfig(),\n\t\tm.storageClient, util.ToExecutionClosureInterface(execution.Closure))\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tresponse := &admin.WorkflowExecutionGetDataResponse{\n\t\tInputs:      inputURLBlob,\n\t\tOutputs:     outputURLBlob,\n\t\tFullInputs:  inputs,\n\t\tFullOutputs: outputs,\n\t}\n\n\tm.userMetrics.WorkflowExecutionInputBytes.Observe(float64(response.Inputs.Bytes))\n\tif response.Outputs.Bytes > 0 {\n\t\tm.userMetrics.WorkflowExecutionOutputBytes.Observe(float64(response.Outputs.Bytes))\n\t} else if response.FullOutputs != nil {\n\t\tm.userMetrics.WorkflowExecutionOutputBytes.Observe(float64(proto.Size(response.FullOutputs)))\n\t}\n\treturn response, nil\n}\n\nfunc (m *ExecutionManager) ListExecutions(\n\tctx context.Context, request admin.ResourceListRequest) (*admin.ExecutionList, error) {\n\t// Check required fields\n\tif err := validation.ValidateResourceListRequest(request); err != nil {\n\t\tlogger.Debugf(ctx, \"ListExecutions request [%+v] failed validation with err: %v\", request, err)\n\t\treturn nil, err\n\t}\n\tctx = contextutils.WithProjectDomain(ctx, request.Id.Project, request.Id.Domain)\n\tfilters, err := util.GetDbFilters(util.FilterSpec{\n\t\tProject:        request.Id.Project,\n\t\tDomain:         request.Id.Domain,\n\t\tName:           request.Id.Name, // Optional, may be empty.\n\t\tRequestFilters: request.Filters,\n\t}, common.Execution)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tvar sortParameter common.SortParameter\n\tif request.SortBy != nil {\n\t\tsortParameter, err = common.NewSortParameter(*request.SortBy)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\toffset, err := validation.ValidateToken(request.Token)\n\tif err != nil {\n\t\treturn nil, errors.NewFlyteAdminErrorf(codes.InvalidArgument, \"invalid pagination token %s for ListExecutions\",\n\t\t\trequest.Token)\n\t}\n\tjoinTableEntities := make(map[common.Entity]bool)\n\tfor _, filter := range filters {\n\t\tjoinTableEntities[filter.GetEntity()] = true\n\t}\n\n\t// Check if state filter exists and if not then add filter to fetch only ACTIVE executions\n\tif filters, err = addStateFilter(filters); err != nil {\n\t\treturn nil, err\n\t}\n\n\tlistExecutionsInput := repositoryInterfaces.ListResourceInput{\n\t\tLimit:             int(request.Limit),\n\t\tOffset:            offset,\n\t\tInlineFilters:     filters,\n\t\tSortParameter:     sortParameter,\n\t\tJoinTableEntities: joinTableEntities,\n\t}\n\toutput, err := m.db.ExecutionRepo().List(ctx, listExecutionsInput)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"Failed to list executions using input [%+v] with err %v\", listExecutionsInput, err)\n\t\treturn nil, err\n\t}\n\texecutionList, err := transformers.FromExecutionModels(ctx, output.Executions, transformers.ListExecutionTransformerOptions)\n\tif err != nil {\n\t\tlogger.Errorf(ctx,\n\t\t\t\"Failed to transform execution models [%+v] with err: %v\", output.Executions, err)\n\t\treturn nil, err\n\t}\n\t// TODO: TO BE DELETED\n\t// Clear deprecated fields during migration phase. Once migration is complete, these will be cleared in the database.\n\t// Thus this will be redundant\n\tfor _, execution := range executionList {\n\t\texecution.Spec.Inputs = nil\n\t\texecution.Closure.ComputedInputs = nil\n\t}\n\n\t// END TO BE DELETED\n\tvar token string\n\tif len(executionList) == int(request.Limit) {\n\t\ttoken = strconv.Itoa(offset + len(executionList))\n\t}\n\treturn &admin.ExecutionList{\n\t\tExecutions: executionList,\n\t\tToken:      token,\n\t}, nil\n}\n\n// publishNotifications will only forward major errors because the assumption made is all of the objects\n// that are being manipulated have already been validated/manipulated by Flyte itself.\n// Note: This method should be refactored somewhere else once the interaction with pushing to SNS.\nfunc (m *ExecutionManager) publishNotifications(ctx context.Context, request admin.WorkflowExecutionEventRequest,\n\texecution models.Execution) error {\n\t// Notifications are stored in the Spec object of an admin.Execution object.\n\tadminExecution, err := transformers.FromExecutionModel(ctx, execution, transformers.DefaultExecutionTransformerOptions)\n\tif err != nil {\n\t\t// This shouldn't happen because execution manager marshaled the data into models.Execution.\n\t\tm.systemMetrics.TransformerError.Inc()\n\t\treturn errors.NewFlyteAdminErrorf(codes.Internal, \"Failed to transform execution [%+v] with err: %v\", request.Event.ExecutionId, err)\n\t}\n\tvar notificationsList = adminExecution.Closure.Notifications\n\tlogger.Debugf(ctx, \"publishing notifications for execution [%+v] in state [%+v] for notifications [%+v]\",\n\t\trequest.Event.ExecutionId, request.Event.Phase, notificationsList)\n\tfor _, notification := range notificationsList {\n\t\t// Check if the notification phase matches the current one.\n\t\tvar matchPhase = false\n\t\tfor _, phase := range notification.Phases {\n\t\t\tif phase == request.Event.Phase {\n\t\t\t\tmatchPhase = true\n\t\t\t}\n\t\t}\n\n\t\t// The current phase doesn't match; no notifications will be sent for the current notification option.\n\t\tif !matchPhase {\n\t\t\tcontinue\n\t\t}\n\n\t\t// Currently all three supported notifications use email underneath to send the notification.\n\t\t// Convert Slack and PagerDuty into an EmailNotification type.\n\t\tvar emailNotification admin.EmailNotification\n\t\tif notification.GetEmail() != nil {\n\t\t\temailNotification.RecipientsEmail = notification.GetEmail().GetRecipientsEmail()\n\t\t} else if notification.GetPagerDuty() != nil {\n\t\t\temailNotification.RecipientsEmail = notification.GetPagerDuty().GetRecipientsEmail()\n\t\t} else if notification.GetSlack() != nil {\n\t\t\temailNotification.RecipientsEmail = notification.GetSlack().GetRecipientsEmail()\n\t\t} else {\n\t\t\tlogger.Debugf(ctx, \"failed to publish notification, encountered unrecognized type: %v\", notification.Type)\n\t\t\tm.systemMetrics.UnexpectedDataError.Inc()\n\t\t\t// Unsupported notification types should have been caught when the launch plan was being created.\n\t\t\treturn errors.NewFlyteAdminErrorf(codes.Internal, \"Unsupported notification type [%v] for execution [%+v]\",\n\t\t\t\tnotification.Type, request.Event.ExecutionId)\n\t\t}\n\n\t\t// Convert the email Notification into an email message to be published.\n\t\t// Currently there are no possible errors while creating an email message.\n\t\t// Once customizable content is specified, errors are possible.\n\t\temail := notifications.ToEmailMessageFromWorkflowExecutionEvent(\n\t\t\t*m.config.ApplicationConfiguration().GetNotificationsConfig(), emailNotification, request, adminExecution)\n\t\t// Errors seen while publishing a message are considered non-fatal to the method and will not result\n\t\t// in the method returning an error.\n\t\tif err = m.notificationClient.Publish(ctx, proto.MessageName(&emailNotification), email); err != nil {\n\t\t\tm.systemMetrics.PublishNotificationError.Inc()\n\t\t\tlogger.Infof(ctx, \"error publishing email notification [%+v] with err: [%v]\", notification, err)\n\t\t}\n\t}\n\treturn nil\n}\n\nfunc (m *ExecutionManager) TerminateExecution(\n\tctx context.Context, request admin.ExecutionTerminateRequest) (*admin.ExecutionTerminateResponse, error) {\n\tif err := validation.ValidateWorkflowExecutionIdentifier(request.Id); err != nil {\n\t\tlogger.Debugf(ctx, \"received terminate execution request: %v with invalid identifier: %v\", request, err)\n\t\treturn nil, err\n\t}\n\tctx = getExecutionContext(ctx, request.Id)\n\t// Save the abort reason (best effort)\n\texecutionModel, err := m.db.ExecutionRepo().Get(ctx, repositoryInterfaces.Identifier{\n\t\tProject: request.Id.Project,\n\t\tDomain:  request.Id.Domain,\n\t\tName:    request.Id.Name,\n\t})\n\tif err != nil {\n\t\tlogger.Infof(ctx, \"couldn't find execution [%+v] to save termination cause\", request.Id)\n\t\treturn nil, err\n\t}\n\n\tif common.IsExecutionTerminal(core.WorkflowExecution_Phase(core.WorkflowExecution_Phase_value[executionModel.Phase])) {\n\t\treturn nil, errors.NewAlreadyInTerminalStateError(ctx, \"Cannot abort an already terminate workflow execution\", executionModel.Phase)\n\t}\n\n\terr = transformers.SetExecutionAborting(&executionModel, request.Cause, getUser(ctx))\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"failed to add abort metadata for execution [%+v] with err: %v\", request.Id, err)\n\t\treturn nil, err\n\t}\n\n\terr = m.db.ExecutionRepo().Update(ctx, executionModel)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"failed to save abort cause for terminated execution: %+v with err: %v\", request.Id, err)\n\t\treturn nil, err\n\t}\n\n\tworkflowExecutor := plugins.Get[workflowengineInterfaces.WorkflowExecutor](m.pluginRegistry, plugins.PluginIDWorkflowExecutor)\n\terr = workflowExecutor.Abort(ctx, workflowengineInterfaces.AbortData{\n\t\tNamespace: common.GetNamespaceName(\n\t\t\tm.config.NamespaceMappingConfiguration().GetNamespaceTemplate(), request.Id.Project, request.Id.Domain),\n\n\t\tExecutionID: request.Id,\n\t\tCluster:     executionModel.Cluster,\n\t})\n\tif err != nil {\n\t\tm.systemMetrics.TerminateExecutionFailures.Inc()\n\t\treturn nil, err\n\t}\n\treturn &admin.ExecutionTerminateResponse{}, nil\n}\n\nfunc newExecutionSystemMetrics(scope promutils.Scope) executionSystemMetrics {\n\treturn executionSystemMetrics{\n\t\tScope: scope,\n\t\tActiveExecutions: scope.MustNewGauge(\"active_executions\",\n\t\t\t\"overall count of active workflow executions\"),\n\t\tExecutionsCreated: scope.MustNewCounter(\"executions_created\",\n\t\t\t\"overall count of successfully completed CreateExecutionRequests\"),\n\t\tExecutionsTerminated: labeled.NewCounter(\"executions_terminated\",\n\t\t\t\"overall count of terminated workflow executions\", scope),\n\t\tExecutionEventsCreated: scope.MustNewCounter(\"execution_events_created\",\n\t\t\t\"overall count of successfully completed WorkflowExecutionEventRequest\"),\n\t\tPropellerFailures: scope.MustNewCounter(\"propeller_failures\",\n\t\t\t\"propeller failures in creating workflow executions\"),\n\t\tTransformerError: scope.MustNewCounter(\"transformer_error\",\n\t\t\t\"overall count of errors when transforming models and messages\"),\n\t\tUnexpectedDataError: scope.MustNewCounter(\"unexpected_data_error\",\n\t\t\t\"overall count of unexpected data for previously validated objects\"),\n\t\tPublishNotificationError: scope.MustNewCounter(\"publish_error\",\n\t\t\t\"overall count of publish notification errors when invoking publish()\"),\n\t\tSpecSizeBytes:    scope.MustNewSummary(\"spec_size_bytes\", \"size in bytes of serialized execution spec\"),\n\t\tClosureSizeBytes: scope.MustNewSummary(\"closure_size_bytes\", \"size in bytes of serialized execution closure\"),\n\t\tAcceptanceDelay: scope.MustNewSummary(\"acceptance_delay\",\n\t\t\t\"delay in seconds from when an execution was requested to be created and when it actually was\"),\n\t\tPublishEventError: scope.MustNewCounter(\"publish_event_error\",\n\t\t\t\"overall count of publish event errors when invoking publish()\"),\n\t\tTerminateExecutionFailures: scope.MustNewCounter(\"execution_termination_failure\",\n\t\t\t\"count of failed workflow executions terminations\"),\n\t}\n}\n\nfunc NewExecutionManager(db repositoryInterfaces.Repository, pluginRegistry *plugins.Registry, config runtimeInterfaces.Configuration,\n\tstorageClient *storage.DataStore, systemScope promutils.Scope, userScope promutils.Scope,\n\tpublisher notificationInterfaces.Publisher, urlData dataInterfaces.RemoteURLInterface,\n\tworkflowManager interfaces.WorkflowInterface, namedEntityManager interfaces.NamedEntityInterface,\n\teventPublisher notificationInterfaces.Publisher, cloudEventPublisher cloudeventInterfaces.Publisher,\n\teventWriter eventWriter.WorkflowExecutionEventWriter) interfaces.ExecutionInterface {\n\tqueueAllocator := executions.NewQueueAllocator(config, db)\n\tsystemMetrics := newExecutionSystemMetrics(systemScope)\n\n\tuserMetrics := executionUserMetrics{\n\t\tScope:                      userScope,\n\t\tScheduledExecutionDelays:   make(map[string]map[string]*promutils.StopWatch),\n\t\tWorkflowExecutionDurations: make(map[string]map[string]*promutils.StopWatch),\n\t\tWorkflowExecutionInputBytes: userScope.MustNewSummary(\"input_size_bytes\",\n\t\t\t\"size in bytes of serialized execution inputs\"),\n\t\tWorkflowExecutionOutputBytes: userScope.MustNewSummary(\"output_size_bytes\",\n\t\t\t\"size in bytes of serialized execution outputs\"),\n\t}\n\n\tresourceManager := resources.NewResourceManager(db, config.ApplicationConfiguration())\n\treturn &ExecutionManager{\n\t\tdb:                        db,\n\t\tconfig:                    config,\n\t\tstorageClient:             storageClient,\n\t\tqueueAllocator:            queueAllocator,\n\t\t_clock:                    clock.New(),\n\t\tsystemMetrics:             systemMetrics,\n\t\tuserMetrics:               userMetrics,\n\t\tnotificationClient:        publisher,\n\t\turlData:                   urlData,\n\t\tworkflowManager:           workflowManager,\n\t\tnamedEntityManager:        namedEntityManager,\n\t\tresourceManager:           resourceManager,\n\t\tqualityOfServiceAllocator: executions.NewQualityOfServiceAllocator(config, resourceManager),\n\t\teventPublisher:            eventPublisher,\n\t\tcloudEventPublisher:       cloudEventPublisher,\n\t\tdbEventWriter:             eventWriter,\n\t\tpluginRegistry:            pluginRegistry,\n\t}\n}\n\n// Adds project labels with higher precedence to workflow labels. Project labels are ignored if a corresponding label is set on the workflow.\nfunc (m *ExecutionManager) addProjectLabels(ctx context.Context, projectName string, initialLabels map[string]string) (map[string]string, error) {\n\tproject, err := m.db.ProjectRepo().Get(ctx, projectName)\n\tif err != nil {\n\t\tlogger.Errorf(ctx, \"Failed to get project for [%+v] with error: %v\", project, err)\n\t\treturn nil, err\n\t}\n\t// passing nil domain as not needed to retrieve labels\n\tprojectLabels := transformers.FromProjectModel(project, nil).Labels.GetValues()\n\n\tif initialLabels == nil {\n\t\tinitialLabels = make(map[string]string)\n\t}\n\n\tfor k, v := range projectLabels {\n\t\tif _, ok := initialLabels[k]; !ok {\n\t\t\tinitialLabels[k] = v\n\t\t}\n\t}\n\treturn initialLabels, nil\n}\n\nfunc addStateFilter(filters []common.InlineFilter) ([]common.InlineFilter, error) {\n\tvar stateFilterExists bool\n\tfor _, inlineFilter := range filters {\n\t\tif inlineFilter.GetField() == shared.State {\n\t\t\tstateFilterExists = true\n\t\t}\n\t}\n\n\tif !stateFilterExists {\n\t\tstateFilter, err := common.NewSingleValueFilter(common.Execution, common.Equal, shared.State,\n\t\t\tadmin.ExecutionState_EXECUTION_ACTIVE)\n\t\tif err != nil {\n\t\t\treturn filters, err\n\t\t}\n\t\tfilters = append(filters, stateFilter)\n\t}\n\treturn filters, nil\n}\n", "package impl\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"strings\"\n\t\"testing\"\n\n\t\"github.com/flyteorg/flyteadmin/plugins\"\n\n\t\"google.golang.org/grpc/status\"\n\n\t\"google.golang.org/protobuf/types/known/timestamppb\"\n\n\t\"github.com/benbjohnson/clock\"\n\t\"github.com/flyteorg/flyteadmin/pkg/common\"\n\tcommonTestUtils \"github.com/flyteorg/flyteadmin/pkg/common/testutils\"\n\tflyteAdminErrors \"github.com/flyteorg/flyteadmin/pkg/errors\"\n\t\"github.com/flyteorg/flyteadmin/pkg/manager/impl/executions\"\n\t\"github.com/flyteorg/flyteadmin/pkg/manager/impl/shared\"\n\tmanagerInterfaces \"github.com/flyteorg/flyteadmin/pkg/manager/interfaces\"\n\tmanagerMocks \"github.com/flyteorg/flyteadmin/pkg/manager/mocks\"\n\t\"github.com/flyteorg/flyteadmin/pkg/runtime\"\n\t\"github.com/flyteorg/flyteidl/clients/go/coreutils\"\n\t\"github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/event\"\n\t\"github.com/gogo/protobuf/jsonpb\"\n\t\"github.com/golang/protobuf/ptypes\"\n\t\"github.com/stretchr/testify/mock\"\n\t\"google.golang.org/grpc/codes\"\n\n\t\"k8s.io/apimachinery/pkg/api/resource\"\n\n\teventWriterMocks \"github.com/flyteorg/flyteadmin/pkg/async/events/mocks\"\n\t\"k8s.io/apimachinery/pkg/util/sets\"\n\n\t\"github.com/flyteorg/flyteadmin/auth\"\n\n\tcommonMocks \"github.com/flyteorg/flyteadmin/pkg/common/mocks\"\n\n\t\"github.com/flyteorg/flytestdlib/storage\"\n\n\t\"time\"\n\n\t\"fmt\"\n\n\tnotificationMocks \"github.com/flyteorg/flyteadmin/pkg/async/notifications/mocks\"\n\tdataMocks \"github.com/flyteorg/flyteadmin/pkg/data/mocks\"\n\t\"github.com/flyteorg/flyteadmin/pkg/manager/impl/testutils\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/interfaces\"\n\trepositoryMocks \"github.com/flyteorg/flyteadmin/pkg/repositories/mocks\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/models\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/transformers\"\n\truntimeInterfaces \"github.com/flyteorg/flyteadmin/pkg/runtime/interfaces\"\n\truntimeIFaceMocks \"github.com/flyteorg/flyteadmin/pkg/runtime/interfaces/mocks\"\n\truntimeMocks \"github.com/flyteorg/flyteadmin/pkg/runtime/mocks\"\n\tworkflowengineInterfaces \"github.com/flyteorg/flyteadmin/pkg/workflowengine/interfaces\"\n\tworkflowengineMocks \"github.com/flyteorg/flyteadmin/pkg/workflowengine/mocks\"\n\t\"github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/admin\"\n\t\"github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/core\"\n\tmockScope \"github.com/flyteorg/flytestdlib/promutils\"\n\t\"github.com/golang/protobuf/proto\"\n\t\"github.com/golang/protobuf/ptypes/wrappers\"\n\t\"github.com/stretchr/testify/assert\"\n)\n\nvar spec = testutils.GetExecutionRequest().Spec\nvar specBytes, _ = proto.Marshal(spec)\nvar phase = core.WorkflowExecution_RUNNING.String()\nvar closure = admin.ExecutionClosure{\n\tPhase: core.WorkflowExecution_RUNNING,\n\tStateChangeDetails: &admin.ExecutionStateChangeDetails{\n\t\tState:      admin.ExecutionState_EXECUTION_ACTIVE,\n\t\tOccurredAt: testutils.MockCreatedAtProto,\n\t},\n}\nvar closureBytes, _ = proto.Marshal(&closure)\n\nvar executionIdentifier = core.WorkflowExecutionIdentifier{\n\tProject: \"project\",\n\tDomain:  \"domain\",\n\tName:    \"name\",\n}\nvar mockPublisher notificationMocks.MockPublisher\nvar mockExecutionRemoteURL = dataMocks.NewMockRemoteURL()\nvar requestedAt = time.Now()\nvar testCluster = \"C1\"\nvar outputURI = \"output uri\"\n\nvar resourceDefaults = runtimeInterfaces.TaskResourceSet{\n\tCPU:    resource.MustParse(\"200m\"),\n\tMemory: resource.MustParse(\"200Gi\"),\n}\nvar resourceLimits = runtimeInterfaces.TaskResourceSet{\n\tCPU:    resource.MustParse(\"300m\"),\n\tMemory: resource.MustParse(\"500Gi\"),\n}\n\nfunc getLegacySpec() *admin.ExecutionSpec {\n\texecutionRequest := testutils.GetExecutionRequest()\n\tlegacySpec := executionRequest.Spec\n\tlegacySpec.Inputs = executionRequest.Inputs\n\treturn legacySpec\n}\n\nfunc getLegacySpecBytes() []byte {\n\tb, _ := proto.Marshal(getLegacySpec())\n\treturn b\n}\n\nfunc getExpectedLegacySpec() *admin.ExecutionSpec {\n\texpectedLegacySpec := getLegacySpec()\n\texpectedLegacySpec.Metadata = &admin.ExecutionMetadata{\n\t\tSystemMetadata: &admin.SystemMetadata{\n\t\t\tNamespace: \"project-domain\",\n\t\t},\n\t}\n\treturn expectedLegacySpec\n}\n\nfunc getExpectedLegacySpecBytes() []byte {\n\texpectedLegacySpec := getExpectedLegacySpec()\n\tb, _ := proto.Marshal(expectedLegacySpec)\n\treturn b\n}\n\nfunc getExpectedSpec() *admin.ExecutionSpec {\n\texpectedSpec := testutils.GetExecutionRequest().Spec\n\texpectedSpec.Metadata = &admin.ExecutionMetadata{\n\t\tSystemMetadata: &admin.SystemMetadata{\n\t\t\tNamespace: \"project-domain\",\n\t\t},\n\t}\n\treturn expectedSpec\n}\n\nfunc getExpectedSpecBytes() []byte {\n\tspecBytes, _ := proto.Marshal(getExpectedSpec())\n\treturn specBytes\n}\n\nfunc getLegacyClosure() *admin.ExecutionClosure {\n\treturn &admin.ExecutionClosure{\n\t\tPhase:          core.WorkflowExecution_RUNNING,\n\t\tComputedInputs: getLegacySpec().Inputs,\n\t\tStateChangeDetails: &admin.ExecutionStateChangeDetails{\n\t\t\tState:      admin.ExecutionState_EXECUTION_ACTIVE,\n\t\t\tOccurredAt: testutils.MockCreatedAtProto,\n\t\t},\n\t}\n}\n\nfunc getLegacyClosureBytes() []byte {\n\tb, _ := proto.Marshal(getLegacyClosure())\n\treturn b\n}\n\nfunc getLegacyExecutionRequest() *admin.ExecutionCreateRequest {\n\tr := testutils.GetExecutionRequest()\n\tr.Spec.Inputs = r.Inputs\n\tr.Inputs = nil\n\treturn &r\n}\n\nfunc getMockNamespaceMappingConfig() runtimeInterfaces.NamespaceMappingConfiguration {\n\tmockNs := runtimeMocks.NamespaceMappingConfiguration{}\n\tmockNs.OnGetNamespaceTemplate().Return(\"{{ project }}-{{ domain }}\")\n\treturn &mockNs\n}\n\nfunc getMockExecutionsConfigProvider() runtimeInterfaces.Configuration {\n\tmockExecutionsConfigProvider := runtimeMocks.NewMockConfigurationProvider(\n\t\ttestutils.GetApplicationConfigWithDefaultDomains(),\n\t\truntimeMocks.NewMockQueueConfigurationProvider(\n\t\t\t[]runtimeInterfaces.ExecutionQueue{}, []runtimeInterfaces.WorkflowConfig{}),\n\t\tnil,\n\t\truntimeMocks.NewMockTaskResourceConfiguration(resourceDefaults, resourceLimits), nil, getMockNamespaceMappingConfig())\n\tmockExecutionsConfigProvider.(*runtimeMocks.MockConfigurationProvider).AddRegistrationValidationConfiguration(\n\t\truntimeMocks.NewMockRegistrationValidationProvider())\n\treturn mockExecutionsConfigProvider\n}\n\nfunc setDefaultLpCallbackForExecTest(repository interfaces.Repository) {\n\tlpSpec := testutils.GetSampleLpSpecForTest()\n\tlpSpec.Labels = &admin.Labels{\n\t\tValues: map[string]string{\n\t\t\t\"label1\": \"1\",\n\t\t\t\"label2\": \"2\",\n\t\t},\n\t}\n\tlpSpec.Annotations = &admin.Annotations{\n\t\tValues: map[string]string{\n\t\t\t\"annotation3\": \"3\",\n\t\t\t\"annotation4\": \"4\",\n\t\t},\n\t}\n\n\tlpSpecBytes, _ := proto.Marshal(&lpSpec)\n\tlpClosure := admin.LaunchPlanClosure{\n\t\tExpectedInputs: lpSpec.DefaultInputs,\n\t}\n\tlpClosureBytes, _ := proto.Marshal(&lpClosure)\n\n\tlpGetFunc := func(input interfaces.Identifier) (models.LaunchPlan, error) {\n\t\tlpModel := models.LaunchPlan{\n\t\t\tLaunchPlanKey: models.LaunchPlanKey{\n\t\t\t\tProject: input.Project,\n\t\t\t\tDomain:  input.Domain,\n\t\t\t\tName:    input.Name,\n\t\t\t\tVersion: input.Version,\n\t\t\t},\n\t\t\tBaseModel: models.BaseModel{\n\t\t\t\tID: uint(100),\n\t\t\t},\n\t\t\tSpec:    lpSpecBytes,\n\t\t\tClosure: lpClosureBytes,\n\t\t}\n\t\treturn lpModel, nil\n\t}\n\trepository.LaunchPlanRepo().(*repositoryMocks.MockLaunchPlanRepo).SetGetCallback(lpGetFunc)\n}\n\nfunc setDefaultTaskCallbackForExecTest(repository interfaces.Repository) {\n\ttaskGetFunc := func(input interfaces.Identifier) (models.Task, error) {\n\t\treturn models.Task{\n\t\t\tTaskKey: models.TaskKey{\n\t\t\t\tProject: input.Project,\n\t\t\t\tDomain:  input.Domain,\n\t\t\t\tName:    input.Name,\n\t\t\t\tVersion: input.Version,\n\t\t\t},\n\t\t\tBaseModel: models.BaseModel{\n\t\t\t\tID:        uint(123),\n\t\t\t\tCreatedAt: testutils.MockCreatedAtValue,\n\t\t\t},\n\t\t\tClosure: testutils.GetTaskClosureBytes(),\n\t\t\tDigest:  []byte(input.Name),\n\t\t\tType:    \"python\",\n\t\t}, nil\n\t}\n\trepository.TaskRepo().(*repositoryMocks.MockTaskRepo).SetGetCallback(taskGetFunc)\n}\n\nfunc getMockStorageForExecTest(ctx context.Context) *storage.DataStore {\n\tmockStorage := commonMocks.GetMockStorageClient()\n\tmockStorage.ComposedProtobufStore.(*commonMocks.TestDataStore).ReadProtobufCb = func(\n\t\tctx context.Context, reference storage.DataReference, msg proto.Message) error {\n\t\tif val, ok := mockStorage.ComposedProtobufStore.(*commonMocks.TestDataStore).Store[reference]; ok {\n\t\t\t_ = proto.Unmarshal(val, msg)\n\t\t\treturn nil\n\t\t}\n\t\treturn fmt.Errorf(\"could not find value in storage [%v]\", reference.String())\n\t}\n\tmockStorage.ComposedProtobufStore.(*commonMocks.TestDataStore).WriteProtobufCb = func(\n\t\tctx context.Context, reference storage.DataReference, opts storage.Options, msg proto.Message) error {\n\t\tbytes, err := proto.Marshal(msg)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tmockStorage.ComposedProtobufStore.(*commonMocks.TestDataStore).Store[reference] = bytes\n\t\treturn nil\n\t}\n\tworkflowClosure := testutils.GetWorkflowClosure()\n\tif err := mockStorage.WriteProtobuf(ctx, remoteClosureIdentifier, defaultStorageOptions, workflowClosure); err != nil {\n\t\treturn nil\n\t}\n\treturn mockStorage\n}\n\nfunc getMockRepositoryForExecTest() interfaces.Repository {\n\trepository := repositoryMocks.NewMockRepository()\n\trepository.WorkflowRepo().(*repositoryMocks.MockWorkflowRepo).SetGetCallback(\n\t\tfunc(input interfaces.Identifier) (models.Workflow, error) {\n\t\t\treturn models.Workflow{\n\t\t\t\tBaseModel: models.BaseModel{\n\t\t\t\t\tCreatedAt: testutils.MockCreatedAtValue,\n\t\t\t\t},\n\t\t\t\tWorkflowKey: models.WorkflowKey{\n\t\t\t\t\tProject: input.Project,\n\t\t\t\t\tDomain:  input.Domain,\n\t\t\t\t\tName:    input.Name,\n\t\t\t\t\tVersion: input.Version,\n\t\t\t\t},\n\t\t\t\tTypedInterface:          testutils.GetWorkflowRequestInterfaceBytes(),\n\t\t\t\tRemoteClosureIdentifier: remoteClosureIdentifier,\n\t\t\t}, nil\n\t\t})\n\treturn repository\n}\n\nvar defaultTestExecutor = workflowengineMocks.WorkflowExecutor{}\n\nfunc init() {\n\tdefaultTestExecutor.OnID().Return(\"testDefault\")\n}\n\nfunc TestCreateExecution(t *testing.T) {\n\trepository := getMockRepositoryForExecTest()\n\tlabels := admin.Labels{\n\t\tValues: map[string]string{\n\t\t\t\"label3\": \"3\",\n\t\t\t\"label2\": \"1\", // common label, will be dropped\n\t\t}}\n\trepository.ProjectRepo().(*repositoryMocks.MockProjectRepo).GetFunction = func(\n\t\tctx context.Context, projectID string) (models.Project, error) {\n\t\treturn transformers.CreateProjectModel(&admin.Project{\n\t\t\tLabels: &labels}), nil\n\t}\n\n\tprincipal := \"principal\"\n\trawOutput := \"raw_output\"\n\tclusterAssignment := admin.ClusterAssignment{ClusterPoolName: \"gpu\"}\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetCreateCallback(\n\t\tfunc(ctx context.Context, input models.Execution) error {\n\t\t\tvar spec admin.ExecutionSpec\n\t\t\terr := proto.Unmarshal(input.Spec, &spec)\n\t\t\tassert.NoError(t, err)\n\t\t\tassert.Equal(t, principal, spec.Metadata.Principal)\n\t\t\tassert.Equal(t, rawOutput, spec.RawOutputDataConfig.OutputLocationPrefix)\n\t\t\tassert.True(t, proto.Equal(spec.ClusterAssignment, &clusterAssignment))\n\t\t\tassert.Equal(t, \"launch_plan\", input.LaunchEntity)\n\t\t\tassert.Equal(t, spec.GetMetadata().GetSystemMetadata().Namespace, \"project-domain\")\n\t\t\treturn nil\n\t\t})\n\tsetDefaultLpCallbackForExecTest(repository)\n\tmockExecutor := workflowengineMocks.WorkflowExecutor{}\n\tresources := &core.Resources{\n\t\tRequests: []*core.Resources_ResourceEntry{\n\t\t\t{\n\t\t\t\tName:  core.Resources_CPU,\n\t\t\t\tValue: \"200m\",\n\t\t\t},\n\t\t\t{\n\t\t\t\tName:  core.Resources_MEMORY,\n\t\t\t\tValue: \"200Gi\",\n\t\t\t},\n\t\t},\n\t\tLimits: []*core.Resources_ResourceEntry{\n\t\t\t{\n\t\t\t\tName:  core.Resources_CPU,\n\t\t\t\tValue: \"300m\",\n\t\t\t},\n\t\t\t{\n\t\t\t\tName:  core.Resources_MEMORY,\n\t\t\t\tValue: \"500Gi\",\n\t\t\t},\n\t\t},\n\t}\n\tmockExecutor.OnExecuteMatch(mock.Anything, mock.MatchedBy(func(data workflowengineInterfaces.ExecutionData) bool {\n\t\ttasks := data.WorkflowClosure.GetTasks()\n\t\tfor _, task := range tasks {\n\t\t\tassert.EqualValues(t, resources.Requests,\n\t\t\t\ttask.Template.GetContainer().Resources.Requests)\n\t\t\tassert.EqualValues(t, resources.Requests,\n\t\t\t\ttask.Template.GetContainer().Resources.Limits)\n\t\t}\n\n\t\treturn true\n\t})).Return(workflowengineInterfaces.ExecutionResponse{\n\t\tCluster: testCluster,\n\t}, nil)\n\tmockExecutor.OnID().Return(\"customMockExecutor\")\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &mockExecutor)\n\n\tqosProvider := &runtimeIFaceMocks.QualityOfServiceConfiguration{}\n\tqosProvider.OnGetTierExecutionValues().Return(map[core.QualityOfService_Tier]core.QualityOfServiceSpec{\n\t\tcore.QualityOfService_HIGH: {\n\t\t\tQueueingBudget: ptypes.DurationProto(10 * time.Minute),\n\t\t},\n\t\tcore.QualityOfService_MEDIUM: {\n\t\t\tQueueingBudget: ptypes.DurationProto(20 * time.Minute),\n\t\t},\n\t\tcore.QualityOfService_LOW: {\n\t\t\tQueueingBudget: ptypes.DurationProto(30 * time.Minute),\n\t\t},\n\t})\n\n\tqosProvider.OnGetDefaultTiers().Return(map[string]core.QualityOfService_Tier{\n\t\t\"domain\": core.QualityOfService_HIGH,\n\t})\n\n\tmockConfig := getMockExecutionsConfigProvider()\n\tmockConfig.(*runtimeMocks.MockConfigurationProvider).AddQualityOfServiceConfiguration(qosProvider)\n\n\texecManager := NewExecutionManager(repository, r, mockConfig, getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, &mockPublisher, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\trequest := testutils.GetExecutionRequest()\n\trequest.Spec.Metadata = &admin.ExecutionMetadata{\n\t\tPrincipal: \"unused - populated from authenticated context\",\n\t}\n\trequest.Spec.RawOutputDataConfig = &admin.RawOutputDataConfig{OutputLocationPrefix: rawOutput}\n\trequest.Spec.ClusterAssignment = &clusterAssignment\n\n\tidentity, err := auth.NewIdentityContext(\"\", principal, \"\", time.Now(), sets.NewString(), nil, nil)\n\tassert.NoError(t, err)\n\tctx := identity.WithContext(context.Background())\n\tresponse, err := execManager.CreateExecution(ctx, request, requestedAt)\n\tassert.Nil(t, err)\n\n\texpectedResponse := &admin.ExecutionCreateResponse{\n\t\tId: &executionIdentifier,\n\t}\n\tassert.Nil(t, err)\n\tassert.Equal(t, expectedResponse, response)\n\n\t// TODO: Check for offloaded inputs\n}\n\nfunc TestCreateExecutionFromWorkflowNode(t *testing.T) {\n\trepository := getMockRepositoryForExecTest()\n\tsetDefaultLpCallbackForExecTest(repository)\n\n\tparentNodeExecutionID := core.NodeExecutionIdentifier{\n\t\tExecutionId: &core.WorkflowExecutionIdentifier{\n\t\t\tProject: \"project\",\n\t\t\tDomain:  \"domain\",\n\t\t\tName:    \"parent-name\",\n\t\t},\n\t\tNodeId: \"node-name\",\n\t}\n\n\tgetNodeExecutionCalled := false\n\trepository.NodeExecutionRepo().(*repositoryMocks.MockNodeExecutionRepo).SetGetCallback(\n\t\tfunc(ctx context.Context, input interfaces.NodeExecutionResource) (models.NodeExecution, error) {\n\t\t\tassert.EqualValues(t, input.NodeExecutionIdentifier, parentNodeExecutionID)\n\t\t\tgetNodeExecutionCalled = true\n\t\t\treturn models.NodeExecution{\n\t\t\t\tBaseModel: models.BaseModel{\n\t\t\t\t\tID: 1,\n\t\t\t\t},\n\t\t\t}, nil\n\t\t},\n\t)\n\n\tprincipal := \"feeny\"\n\tgetExecutionCalled := false\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetGetCallback(\n\t\tfunc(ctx context.Context, input interfaces.Identifier) (models.Execution, error) {\n\t\t\tassert.EqualValues(t, input.Project, parentNodeExecutionID.ExecutionId.Project)\n\t\t\tassert.EqualValues(t, input.Domain, parentNodeExecutionID.ExecutionId.Domain)\n\t\t\tassert.EqualValues(t, input.Name, parentNodeExecutionID.ExecutionId.Name)\n\t\t\tspec := &admin.ExecutionSpec{\n\t\t\t\tMetadata: &admin.ExecutionMetadata{\n\t\t\t\t\tNesting: 1,\n\t\t\t\t},\n\t\t\t}\n\t\t\tspecBytes, _ := proto.Marshal(spec)\n\t\t\tgetExecutionCalled = true\n\t\t\treturn models.Execution{\n\t\t\t\tBaseModel: models.BaseModel{\n\t\t\t\t\tID: 2,\n\t\t\t\t},\n\t\t\t\tSpec: specBytes,\n\t\t\t\tUser: principal,\n\t\t\t}, nil\n\t\t},\n\t)\n\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetCreateCallback(\n\t\tfunc(ctx context.Context, input models.Execution) error {\n\t\t\tassert.Equal(t, input.ParentNodeExecutionID, uint(1))\n\t\t\tvar spec admin.ExecutionSpec\n\t\t\terr := proto.Unmarshal(input.Spec, &spec)\n\t\t\tassert.NoError(t, err)\n\t\t\tassert.Equal(t, admin.ExecutionMetadata_CHILD_WORKFLOW, spec.Metadata.Mode)\n\t\t\tassert.True(t, proto.Equal(&parentNodeExecutionID, spec.Metadata.ParentNodeExecution))\n\t\t\tassert.EqualValues(t, input.ParentNodeExecutionID, 1)\n\t\t\tassert.EqualValues(t, input.SourceExecutionID, 2)\n\t\t\tassert.Equal(t, 2, int(spec.Metadata.Nesting))\n\t\t\tassert.Equal(t, principal, spec.Metadata.Principal)\n\t\t\tassert.Equal(t, principal, input.User)\n\t\t\treturn nil\n\t\t},\n\t)\n\n\tmockExecutor := workflowengineMocks.WorkflowExecutor{}\n\tmockExecutor.OnExecuteMatch(mock.Anything, mock.Anything, mock.Anything).Return(workflowengineInterfaces.ExecutionResponse{\n\t\tCluster: testCluster,\n\t}, nil)\n\tmockExecutor.OnID().Return(\"customMockExecutor\")\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &mockExecutor)\n\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\trequest := testutils.GetExecutionRequest()\n\trequest.Spec.Metadata = &admin.ExecutionMetadata{\n\t\tMode:                admin.ExecutionMetadata_CHILD_WORKFLOW,\n\t\tParentNodeExecution: &parentNodeExecutionID,\n\t}\n\tresponse, err := execManager.CreateExecution(context.Background(), request, requestedAt)\n\tassert.Nil(t, err)\n\tassert.True(t, getNodeExecutionCalled)\n\tassert.True(t, getExecutionCalled)\n\texpectedResponse := &admin.ExecutionCreateResponse{\n\t\tId: &executionIdentifier,\n\t}\n\tassert.Nil(t, err)\n\tassert.Equal(t, expectedResponse, response)\n}\n\nfunc TestCreateExecution_NoAssignedName(t *testing.T) {\n\trepository := getMockRepositoryForExecTest()\n\tsetDefaultLpCallbackForExecTest(repository)\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetCreateCallback(\n\t\tfunc(ctx context.Context, input models.Execution) error {\n\t\t\tassert.Equal(t, executionIdentifier.Project, input.Project)\n\t\t\tassert.Equal(t, executionIdentifier.Domain, input.Domain)\n\t\t\tassert.NotEmpty(t, input.Name)\n\t\t\treturn nil\n\t\t})\n\tmockExecutor := workflowengineMocks.WorkflowExecutor{}\n\tmockExecutor.OnExecuteMatch(mock.Anything, mock.MatchedBy(func(data workflowengineInterfaces.ExecutionData) bool {\n\t\treturn len(data.ExecutionID.Name) > 0\n\t})).Return(workflowengineInterfaces.ExecutionResponse{\n\t\tCluster: testCluster,\n\t}, nil)\n\tmockExecutor.OnID().Return(\"customMockExecutor\")\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &mockExecutor)\n\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\trequest := testutils.GetExecutionRequest()\n\trequest.Name = \"\"\n\tresponse, err := execManager.CreateExecution(context.Background(), request, requestedAt)\n\tassert.Nil(t, err)\n\n\texpectedResponse := &admin.ExecutionCreateResponse{\n\t\tId: &executionIdentifier,\n\t}\n\tassert.Nil(t, err)\n\tassert.Equal(t, expectedResponse.Id.Project, response.Id.Project)\n\tassert.Equal(t, expectedResponse.Id.Domain, response.Id.Domain)\n\tassert.NotEmpty(t, response.Id.Name)\n}\n\nfunc TestCreateExecution_TaggedQueue(t *testing.T) {\n\trepository := getMockRepositoryForExecTest()\n\tsetDefaultLpCallbackForExecTest(repository)\n\tconfigProvider := runtimeMocks.NewMockConfigurationProvider(\n\t\ttestutils.GetApplicationConfigWithDefaultDomains(),\n\t\truntimeMocks.NewMockQueueConfigurationProvider([]runtimeInterfaces.ExecutionQueue{\n\t\t\t{\n\t\t\t\tDynamic:    \"dynamic Q\",\n\t\t\t\tAttributes: []string{\"tag\"},\n\t\t\t},\n\t\t}, []runtimeInterfaces.WorkflowConfig{\n\t\t\t{\n\t\t\t\tDomain: \"domain\",\n\t\t\t\tTags:   []string{\"tag\"},\n\t\t\t},\n\t\t}),\n\t\tnil,\n\t\truntimeMocks.NewMockTaskResourceConfiguration(resourceDefaults, resourceLimits), nil, getMockNamespaceMappingConfig())\n\tconfigProvider.(*runtimeMocks.MockConfigurationProvider).AddRegistrationValidationConfiguration(\n\t\truntimeMocks.NewMockRegistrationValidationProvider())\n\n\tmockExecutor := workflowengineMocks.WorkflowExecutor{}\n\tmockExecutor.OnExecuteMatch(mock.Anything, mock.MatchedBy(func(data workflowengineInterfaces.ExecutionData) bool {\n\t\tassert.NotEmpty(t, data.WorkflowClosure.Tasks)\n\t\tfor _, task := range data.WorkflowClosure.Tasks {\n\t\t\tassert.Len(t, task.Template.GetContainer().Config, 1)\n\t\t\tassert.Contains(t, childContainerQueueKey, task.Template.GetContainer().Config[0].Key)\n\t\t\tassert.Contains(t, \"dynamic Q\", task.Template.GetContainer().Config[0].Value)\n\t\t}\n\t\treturn true\n\t})).Return(workflowengineInterfaces.ExecutionResponse{\n\t\tCluster: testCluster,\n\t}, nil)\n\tmockExecutor.OnID().Return(\"customMockExecutor\")\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &mockExecutor)\n\texecManager := NewExecutionManager(repository, r, configProvider, getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\n\trequest := testutils.GetExecutionRequest()\n\tresponse, err := execManager.CreateExecution(context.Background(), request, requestedAt)\n\tassert.Nil(t, err)\n\n\texpectedResponse := &admin.ExecutionCreateResponse{\n\t\tId: &executionIdentifier,\n\t}\n\tassert.Nil(t, err)\n\tassert.Equal(t, expectedResponse, response)\n}\n\nfunc TestCreateExecutionValidationError(t *testing.T) {\n\trepository := getMockRepositoryForExecTest()\n\tsetDefaultLpCallbackForExecTest(repository)\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &defaultTestExecutor)\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\n\trequest := testutils.GetExecutionRequest()\n\trequest.Domain = \"\"\n\tresponse, err := execManager.CreateExecution(context.Background(), request, requestedAt)\n\tassert.EqualError(t, err, \"missing domain\")\n\tassert.Nil(t, response)\n}\n\nfunc TestCreateExecution_InvalidLpIdentifier(t *testing.T) {\n\trepository := getMockRepositoryForExecTest()\n\tsetDefaultLpCallbackForExecTest(repository)\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &defaultTestExecutor)\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\n\trequest := testutils.GetExecutionRequest()\n\trequest.Spec.LaunchPlan = nil\n\tresponse, err := execManager.CreateExecution(context.Background(), request, requestedAt)\n\tassert.EqualError(t, err, \"missing id\")\n\tassert.Nil(t, response)\n}\n\nfunc TestCreateExecutionInCompatibleInputs(t *testing.T) {\n\trepository := getMockRepositoryForExecTest()\n\tsetDefaultLpCallbackForExecTest(repository)\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &defaultTestExecutor)\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\n\trequest := testutils.GetExecutionRequest()\n\trequest.Inputs = &core.LiteralMap{\n\t\tLiterals: map[string]*core.Literal{\n\t\t\t\"foo-1\": coreutils.MustMakeLiteral(\"foo-value-1\"),\n\t\t},\n\t}\n\tresponse, err := execManager.CreateExecution(context.Background(), request, requestedAt)\n\tassert.EqualError(t, err, \"invalid input foo-1\")\n\tassert.Nil(t, response)\n}\n\nfunc TestCreateExecutionPropellerFailure(t *testing.T) {\n\trepository := getMockRepositoryForExecTest()\n\tsetDefaultLpCallbackForExecTest(repository)\n\texpectedErr := flyteAdminErrors.NewFlyteAdminErrorf(codes.Internal, \"ABC\")\n\tmockExecutor := workflowengineMocks.WorkflowExecutor{}\n\tmockExecutor.OnExecuteMatch(mock.Anything, mock.Anything, mock.Anything).Return(workflowengineInterfaces.ExecutionResponse{}, expectedErr)\n\tmockExecutor.OnID().Return(\"customMockExecutor\")\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &mockExecutor)\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\n\trequest := testutils.GetExecutionRequest()\n\n\tresponse, err := execManager.CreateExecution(context.Background(), request, requestedAt)\n\tassert.EqualError(t, err, expectedErr.Error())\n\tassert.Nil(t, response)\n}\n\nfunc TestCreateExecutionDatabaseFailure(t *testing.T) {\n\tmockExecutor := workflowengineMocks.WorkflowExecutor{}\n\tmockExecutor.OnExecuteMatch(mock.Anything, mock.Anything, mock.Anything).Return(workflowengineInterfaces.ExecutionResponse{}, nil)\n\tmockExecutor.OnID().Return(\"customMockExecutor\")\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &mockExecutor)\n\trepository := getMockRepositoryForExecTest()\n\tsetDefaultLpCallbackForExecTest(repository)\n\texpectedErr := flyteAdminErrors.NewFlyteAdminErrorf(codes.Internal, \"ABCD\")\n\texCreateFunc := func(ctx context.Context, input models.Execution) error {\n\t\treturn expectedErr\n\t}\n\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetCreateCallback(exCreateFunc)\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\trequest := testutils.GetExecutionRequest()\n\n\tresponse, err := execManager.CreateExecution(context.Background(), request, requestedAt)\n\tassert.EqualError(t, err, expectedErr.Error())\n\tassert.Nil(t, response)\n}\n\nfunc TestCreateExecutionVerifyDbModel(t *testing.T) {\n\trequest := testutils.GetExecutionRequest()\n\trepository := getMockRepositoryForExecTest()\n\tstorageClient := getMockStorageForExecTest(context.Background())\n\tsetDefaultLpCallbackForExecTest(repository)\n\tmockClock := clock.NewMock()\n\tcreatedAt := time.Now()\n\tmockClock.Set(createdAt)\n\texCreateFunc := func(ctx context.Context, input models.Execution) error {\n\t\tassert.Equal(t, \"name\", input.Name)\n\t\tassert.Equal(t, \"domain\", input.Domain)\n\t\tassert.Equal(t, \"project\", input.Project)\n\t\tassert.Equal(t, uint(100), input.LaunchPlanID)\n\t\tassert.Equal(t, core.WorkflowExecution_UNDEFINED.String(), input.Phase)\n\n\t\tvar specValue admin.ExecutionSpec\n\t\terr := proto.Unmarshal(input.Spec, &specValue)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tassert.Nil(t, specValue.Inputs)\n\n\t\tvar closureValue admin.ExecutionClosure\n\t\terr = proto.Unmarshal(input.Closure, &closureValue)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tassert.Nil(t, closureValue.ComputedInputs)\n\n\t\tvar userInputs, inputs core.LiteralMap\n\t\tif err := storageClient.ReadProtobuf(ctx, input.UserInputsURI, &userInputs); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif err := storageClient.ReadProtobuf(ctx, input.InputsURI, &inputs); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tfooValue := coreutils.MustMakeLiteral(\"foo-value-1\")\n\t\tassert.Equal(t, 1, len(userInputs.Literals))\n\t\tassert.EqualValues(t, userInputs.Literals[\"foo\"], fooValue)\n\t\tbarValue := coreutils.MustMakeLiteral(\"bar-value\")\n\t\tassert.Equal(t, len(inputs.Literals), 2)\n\t\tassert.EqualValues(t, inputs.Literals[\"foo\"], fooValue)\n\t\tassert.EqualValues(t, inputs.Literals[\"bar\"], barValue)\n\t\tassert.Equal(t, core.WorkflowExecution_UNDEFINED, closureValue.Phase)\n\t\tassert.Equal(t, createdAt, *input.ExecutionCreatedAt)\n\t\tassert.Equal(t, 1, len(closureValue.Notifications))\n\t\tassert.Equal(t, 1, len(closureValue.Notifications[0].Phases))\n\t\tassert.Equal(t, request.Spec.GetNotifications().Notifications[0].Phases[0], closureValue.Notifications[0].Phases[0])\n\t\tassert.IsType(t, &admin.Notification_Slack{}, closureValue.Notifications[0].GetType())\n\t\tassert.Equal(t, request.Spec.GetNotifications().Notifications[0].GetSlack().RecipientsEmail, closureValue.Notifications[0].GetSlack().RecipientsEmail)\n\n\t\treturn nil\n\t}\n\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetCreateCallback(exCreateFunc)\n\tmockExecutor := workflowengineMocks.WorkflowExecutor{}\n\tmockExecutor.OnExecuteMatch(mock.Anything, mock.Anything, mock.Anything).Return(workflowengineInterfaces.ExecutionResponse{}, nil)\n\tmockExecutor.OnID().Return(\"testMockExecutor\")\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &mockExecutor)\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), storageClient, mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\n\texecManager.(*ExecutionManager)._clock = mockClock\n\n\tresponse, err := execManager.CreateExecution(context.Background(), request, requestedAt)\n\tassert.Nil(t, err)\n\tassert.True(t, proto.Equal(&executionIdentifier, response.Id))\n}\n\nfunc TestCreateExecutionDefaultNotifications(t *testing.T) {\n\t// Remove notifications settings for the CreateExecutionRequest.\n\trequest := testutils.GetExecutionRequest()\n\trequest.Spec.NotificationOverrides = &admin.ExecutionSpec_Notifications{\n\t\tNotifications: &admin.NotificationList{\n\t\t\tNotifications: []*admin.Notification{},\n\t\t},\n\t}\n\n\trepository := getMockRepositoryForExecTest()\n\tsetDefaultLpCallbackForExecTest(repository)\n\n\t// Create a callback method to ensure the default notification settings from the LaunchPlan is\n\t// stored in the resulting models.Execution.\n\texCreateFunc := func(ctx context.Context, input models.Execution) error {\n\t\tvar closureValue admin.ExecutionClosure\n\t\terr := proto.Unmarshal(input.Closure, &closureValue)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tassert.Equal(t, 1, len(closureValue.Notifications))\n\t\tassert.Equal(t, 1, len(closureValue.Notifications[0].Phases))\n\t\tassert.Equal(t, core.WorkflowExecution_SUCCEEDED, closureValue.Notifications[0].Phases[0])\n\t\tassert.IsType(t, &admin.Notification_Email{}, closureValue.Notifications[0].GetType())\n\n\t\treturn nil\n\t}\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetCreateCallback(exCreateFunc)\n\tmockExecutor := workflowengineMocks.WorkflowExecutor{}\n\tmockExecutor.OnExecuteMatch(mock.Anything, mock.Anything, mock.Anything).Return(workflowengineInterfaces.ExecutionResponse{}, nil)\n\tmockExecutor.OnID().Return(\"testMockExecutor\")\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &mockExecutor)\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\n\tresponse, err := execManager.CreateExecution(context.Background(), request, requestedAt)\n\tassert.Nil(t, err)\n\tassert.True(t, proto.Equal(&core.WorkflowExecutionIdentifier{\n\t\tProject: \"project\",\n\t\tDomain:  \"domain\",\n\t\tName:    \"name\",\n\t}, response.Id))\n}\n\nfunc TestCreateExecutionDisableNotifications(t *testing.T) {\n\t// Disable notifications for the CreateExecutionRequest.\n\trequest := testutils.GetExecutionRequest()\n\trequest.Spec.NotificationOverrides = &admin.ExecutionSpec_DisableAll{\n\t\tDisableAll: true,\n\t}\n\n\trepository := getMockRepositoryForExecTest()\n\tsetDefaultLpCallbackForExecTest(repository)\n\n\t// Create a callback method to ensure the default notification settings from the LaunchPlan is\n\t// stored in the resulting models.Execution.\n\texCreateFunc := func(ctx context.Context, input models.Execution) error {\n\t\tvar closureValue admin.ExecutionClosure\n\t\terr := proto.Unmarshal(input.Closure, &closureValue)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tassert.Empty(t, closureValue.Notifications)\n\t\treturn nil\n\t}\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetCreateCallback(exCreateFunc)\n\tmockExecutor := workflowengineMocks.WorkflowExecutor{}\n\tmockExecutor.OnExecuteMatch(mock.Anything, mock.Anything, mock.Anything).Return(workflowengineInterfaces.ExecutionResponse{}, nil)\n\tmockExecutor.OnID().Return(\"testMockExecutor\")\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &mockExecutor)\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\n\tresponse, err := execManager.CreateExecution(context.Background(), request, requestedAt)\n\tassert.Nil(t, err)\n\tassert.True(t, proto.Equal(&core.WorkflowExecutionIdentifier{\n\t\tProject: \"project\",\n\t\tDomain:  \"domain\",\n\t\tName:    \"name\",\n\t}, response.Id))\n}\n\nfunc TestCreateExecutionNoNotifications(t *testing.T) {\n\t// Remove notifications settings for the CreateExecutionRequest.\n\trequest := testutils.GetExecutionRequest()\n\trequest.Spec.NotificationOverrides = &admin.ExecutionSpec_Notifications{\n\t\tNotifications: &admin.NotificationList{\n\t\t\tNotifications: []*admin.Notification{},\n\t\t},\n\t}\n\n\t// Remove notifications settings for the LaunchPlan associated with the\n\t// CreateExecutionRequest.\n\tlpSpec := testutils.GetSampleLpSpecForTest()\n\tlpSpec.EntityMetadata.Notifications = nil\n\tlpSpecBytes, _ := proto.Marshal(&lpSpec)\n\tlpClosure := admin.LaunchPlanClosure{\n\t\tExpectedInputs: lpSpec.DefaultInputs,\n\t}\n\tlpClosureBytes, _ := proto.Marshal(&lpClosure)\n\n\t// The LaunchPlan is retrieved within the CreateExecution call to ExecutionManager.\n\t// Create a callback method used by the mock to retrieve a LaunchPlan.\n\tlpGetFunc := func(input interfaces.Identifier) (models.LaunchPlan, error) {\n\t\tlpModel := models.LaunchPlan{\n\t\t\tLaunchPlanKey: models.LaunchPlanKey{\n\t\t\t\tProject: input.Project,\n\t\t\t\tDomain:  input.Domain,\n\t\t\t\tName:    input.Name,\n\t\t\t\tVersion: input.Version,\n\t\t\t},\n\t\t\tBaseModel: models.BaseModel{\n\t\t\t\tID: uint(100),\n\t\t\t},\n\t\t\tSpec:    lpSpecBytes,\n\t\t\tClosure: lpClosureBytes,\n\t\t}\n\t\treturn lpModel, nil\n\t}\n\n\trepository := getMockRepositoryForExecTest()\n\trepository.LaunchPlanRepo().(*repositoryMocks.MockLaunchPlanRepo).SetGetCallback(lpGetFunc)\n\n\t// Create a callback method to validate no notifications are set when storing the\n\t// resulting models.Execution by CreateExecution.\n\texCreateFunc := func(ctx context.Context, input models.Execution) error {\n\n\t\tvar closureValue admin.ExecutionClosure\n\t\terr := proto.Unmarshal(input.Closure, &closureValue)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tassert.Nil(t, closureValue.GetNotifications())\n\t\treturn nil\n\t}\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetCreateCallback(exCreateFunc)\n\tmockExecutor := workflowengineMocks.WorkflowExecutor{}\n\tmockExecutor.OnExecuteMatch(mock.Anything, mock.Anything, mock.Anything).Return(workflowengineInterfaces.ExecutionResponse{}, nil)\n\tmockExecutor.OnID().Return(\"testMockExecutor\")\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &mockExecutor)\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\n\tresponse, err := execManager.CreateExecution(context.Background(), request, requestedAt)\n\tassert.Nil(t, err)\n\tassert.True(t, proto.Equal(&core.WorkflowExecutionIdentifier{\n\t\tProject: \"project\",\n\t\tDomain:  \"domain\",\n\t\tName:    \"name\",\n\t}, response.Id))\n}\n\nfunc TestCreateExecutionDynamicLabelsAndAnnotations(t *testing.T) {\n\trepository := getMockRepositoryForExecTest()\n\tsetDefaultLpCallbackForExecTest(repository)\n\tmockExecutor := workflowengineMocks.WorkflowExecutor{}\n\tmockExecutor.OnExecuteMatch(mock.Anything, mock.MatchedBy(func(executionData workflowengineInterfaces.ExecutionData) bool {\n\t\tassert.EqualValues(t, map[string]string{\n\t\t\t\"dynamiclabel1\": \"dynamic1\",\n\t\t\t\"dynamiclabel2\": \"dynamic2\",\n\t\t}, executionData.ExecutionParameters.Labels)\n\t\tassert.EqualValues(t, map[string]string{\n\t\t\t\"dynamicannotation3\": \"dynamic3\",\n\t\t\t\"dynamicannotation4\": \"dynamic4\",\n\t\t}, executionData.ExecutionParameters.Annotations)\n\t\treturn true\n\t})).Return(workflowengineInterfaces.ExecutionResponse{}, nil)\n\tmockExecutor.OnID().Return(\"customMockExecutor\")\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &mockExecutor)\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\trequest := testutils.GetExecutionRequest()\n\trequest.Spec.Labels = &admin.Labels{\n\t\tValues: map[string]string{\n\t\t\t\"dynamiclabel1\": \"dynamic1\",\n\t\t\t\"dynamiclabel2\": \"dynamic2\",\n\t\t},\n\t}\n\trequest.Spec.Annotations = &admin.Annotations{\n\t\tValues: map[string]string{\n\t\t\t\"dynamicannotation3\": \"dynamic3\",\n\t\t\t\"dynamicannotation4\": \"dynamic4\",\n\t\t},\n\t}\n\tresponse, err := execManager.CreateExecution(context.Background(), request, requestedAt)\n\tassert.Nil(t, err)\n\n\texpectedResponse := &admin.ExecutionCreateResponse{\n\t\tId: &executionIdentifier,\n\t}\n\tassert.Nil(t, err)\n\tassert.Equal(t, expectedResponse, response)\n}\n\nfunc TestCreateExecutionInterruptible(t *testing.T) {\n\tenable := true\n\tdisable := false\n\ttests := []struct {\n\t\tname          string\n\t\ttask          bool\n\t\tinterruptible *bool\n\t\twant          bool\n\t}{\n\t\t{\n\t\t\tname:          \"LaunchPlanDefault\",\n\t\t\ttask:          false,\n\t\t\tinterruptible: nil,\n\t\t\twant:          false,\n\t\t},\n\t\t{\n\t\t\tname:          \"LaunchPlanDisable\",\n\t\t\ttask:          false,\n\t\t\tinterruptible: &disable,\n\t\t\twant:          false,\n\t\t},\n\t\t{\n\t\t\tname:          \"LaunchPlanEnable\",\n\t\t\ttask:          false,\n\t\t\tinterruptible: &enable,\n\t\t\twant:          true,\n\t\t},\n\t\t{\n\t\t\tname:          \"TaskDefault\",\n\t\t\ttask:          true,\n\t\t\tinterruptible: nil,\n\t\t\twant:          false,\n\t\t},\n\t\t{\n\t\t\tname:          \"TaskDisable\",\n\t\t\ttask:          true,\n\t\t\tinterruptible: &disable,\n\t\t\twant:          false,\n\t\t},\n\t\t{\n\t\t\tname:          \"TaskEnable\",\n\t\t\ttask:          true,\n\t\t\tinterruptible: &enable,\n\t\t\twant:          true,\n\t\t},\n\t}\n\n\tfor _, tt := range tests {\n\t\ttt := tt\n\t\tt.Run(tt.name, func(t *testing.T) {\n\t\t\tt.Parallel()\n\n\t\t\trequest := testutils.GetExecutionRequest()\n\t\t\tif tt.task {\n\t\t\t\trequest.Spec.LaunchPlan.ResourceType = core.ResourceType_TASK\n\t\t\t}\n\t\t\tif tt.interruptible == nil {\n\t\t\t\trequest.Spec.Interruptible = nil\n\t\t\t} else {\n\t\t\t\trequest.Spec.Interruptible = &wrappers.BoolValue{Value: *tt.interruptible}\n\t\t\t}\n\n\t\t\trepository := getMockRepositoryForExecTest()\n\t\t\tsetDefaultLpCallbackForExecTest(repository)\n\t\t\tsetDefaultTaskCallbackForExecTest(repository)\n\n\t\t\texCreateFunc := func(ctx context.Context, input models.Execution) error {\n\t\t\t\tvar spec admin.ExecutionSpec\n\t\t\t\terr := proto.Unmarshal(input.Spec, &spec)\n\t\t\t\tassert.Nil(t, err)\n\n\t\t\t\tif tt.task {\n\t\t\t\t\tassert.Equal(t, uint(0), input.LaunchPlanID)\n\t\t\t\t\tassert.NotEqual(t, uint(0), input.TaskID)\n\t\t\t\t} else {\n\t\t\t\t\tassert.NotEqual(t, uint(0), input.LaunchPlanID)\n\t\t\t\t\tassert.Equal(t, uint(0), input.TaskID)\n\t\t\t\t}\n\n\t\t\t\tif tt.interruptible == nil {\n\t\t\t\t\tassert.Nil(t, spec.GetInterruptible())\n\t\t\t\t} else {\n\t\t\t\t\tassert.NotNil(t, spec.GetInterruptible())\n\t\t\t\t\tassert.Equal(t, *tt.interruptible, spec.GetInterruptible().GetValue())\n\t\t\t\t}\n\n\t\t\t\treturn nil\n\t\t\t}\n\n\t\t\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetCreateCallback(exCreateFunc)\n\t\t\tmockExecutor := workflowengineMocks.WorkflowExecutor{}\n\t\t\tmockExecutor.OnExecuteMatch(mock.Anything, mock.Anything, mock.Anything).Return(workflowengineInterfaces.ExecutionResponse{}, nil)\n\t\t\tmockExecutor.OnID().Return(\"testMockExecutor\")\n\t\t\tr := plugins.NewRegistry()\n\t\t\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &mockExecutor)\n\t\t\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\n\t\t\t_, err := execManager.CreateExecution(context.Background(), request, requestedAt)\n\t\t\tassert.Nil(t, err)\n\t\t})\n\t}\n}\n\nfunc TestCreateExecutionOverwriteCache(t *testing.T) {\n\ttests := []struct {\n\t\tname           string\n\t\ttask           bool\n\t\toverwriteCache bool\n\t\twant           bool\n\t}{\n\t\t{\n\t\t\tname:           \"LaunchPlanDefault\",\n\t\t\ttask:           false,\n\t\t\toverwriteCache: false,\n\t\t\twant:           false,\n\t\t},\n\t\t{\n\t\t\tname:           \"LaunchPlanEnable\",\n\t\t\ttask:           false,\n\t\t\toverwriteCache: true,\n\t\t\twant:           true,\n\t\t},\n\t\t{\n\t\t\tname:           \"TaskDefault\",\n\t\t\ttask:           false,\n\t\t\toverwriteCache: false,\n\t\t\twant:           false,\n\t\t},\n\t\t{\n\t\t\tname:           \"TaskEnable\",\n\t\t\ttask:           true,\n\t\t\toverwriteCache: true,\n\t\t\twant:           true,\n\t\t},\n\t}\n\n\tfor _, tt := range tests {\n\t\ttt := tt\n\t\tt.Run(tt.name, func(t *testing.T) {\n\t\t\tt.Parallel()\n\n\t\t\trequest := testutils.GetExecutionRequest()\n\t\t\tif tt.task {\n\t\t\t\trequest.Spec.LaunchPlan.ResourceType = core.ResourceType_TASK\n\t\t\t}\n\t\t\trequest.Spec.OverwriteCache = tt.overwriteCache\n\n\t\t\trepository := getMockRepositoryForExecTest()\n\t\t\tsetDefaultLpCallbackForExecTest(repository)\n\t\t\tsetDefaultTaskCallbackForExecTest(repository)\n\n\t\t\texCreateFunc := func(ctx context.Context, input models.Execution) error {\n\t\t\t\tvar spec admin.ExecutionSpec\n\t\t\t\terr := proto.Unmarshal(input.Spec, &spec)\n\t\t\t\tassert.Nil(t, err)\n\n\t\t\t\tif tt.task {\n\t\t\t\t\tassert.Equal(t, uint(0), input.LaunchPlanID)\n\t\t\t\t\tassert.NotEqual(t, uint(0), input.TaskID)\n\t\t\t\t} else {\n\t\t\t\t\tassert.NotEqual(t, uint(0), input.LaunchPlanID)\n\t\t\t\t\tassert.Equal(t, uint(0), input.TaskID)\n\t\t\t\t}\n\n\t\t\t\tassert.Equal(t, tt.overwriteCache, spec.GetOverwriteCache())\n\n\t\t\t\treturn nil\n\t\t\t}\n\n\t\t\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetCreateCallback(exCreateFunc)\n\t\t\tmockExecutor := workflowengineMocks.WorkflowExecutor{}\n\t\t\tmockExecutor.OnExecuteMatch(mock.Anything, mock.Anything, mock.Anything).Return(workflowengineInterfaces.ExecutionResponse{}, nil)\n\t\t\tmockExecutor.OnID().Return(\"testMockExecutor\")\n\t\t\tr := plugins.NewRegistry()\n\t\t\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &mockExecutor)\n\t\t\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\n\t\t\t_, err := execManager.CreateExecution(context.Background(), request, requestedAt)\n\t\t\tassert.Nil(t, err)\n\t\t})\n\t}\n}\n\nfunc TestCreateExecutionWithEnvs(t *testing.T) {\n\ttests := []struct {\n\t\tname string\n\t\ttask bool\n\t\tenvs []*core.KeyValuePair\n\t\twant []*core.KeyValuePair\n\t}{\n\t\t{\n\t\t\tname: \"LaunchPlanDefault\",\n\t\t\ttask: false,\n\t\t\tenvs: nil,\n\t\t\twant: nil,\n\t\t},\n\t\t{\n\t\t\tname: \"LaunchPlanEnable\",\n\t\t\ttask: false,\n\t\t\tenvs: []*core.KeyValuePair{{Key: \"foo\", Value: \"bar\"}},\n\t\t\twant: []*core.KeyValuePair{{Key: \"foo\", Value: \"bar\"}},\n\t\t},\n\t\t{\n\t\t\tname: \"TaskDefault\",\n\t\t\ttask: false,\n\t\t\tenvs: nil,\n\t\t\twant: nil,\n\t\t},\n\t\t{\n\t\t\tname: \"TaskEnable\",\n\t\t\ttask: true,\n\t\t\tenvs: []*core.KeyValuePair{{Key: \"foo\", Value: \"bar\"}},\n\t\t\twant: []*core.KeyValuePair{{Key: \"foo\", Value: \"bar\"}},\n\t\t},\n\t}\n\n\tfor _, tt := range tests {\n\t\ttt := tt\n\t\tt.Run(tt.name, func(t *testing.T) {\n\t\t\tt.Parallel()\n\n\t\t\trequest := testutils.GetExecutionRequest()\n\t\t\tif tt.task {\n\t\t\t\trequest.Spec.LaunchPlan.ResourceType = core.ResourceType_TASK\n\t\t\t}\n\t\t\trequest.Spec.Envs.Values = tt.envs\n\n\t\t\trepository := getMockRepositoryForExecTest()\n\t\t\tsetDefaultLpCallbackForExecTest(repository)\n\t\t\tsetDefaultTaskCallbackForExecTest(repository)\n\n\t\t\texCreateFunc := func(ctx context.Context, input models.Execution) error {\n\t\t\t\tvar spec admin.ExecutionSpec\n\t\t\t\terr := proto.Unmarshal(input.Spec, &spec)\n\t\t\t\tassert.Nil(t, err)\n\n\t\t\t\tif tt.task {\n\t\t\t\t\tassert.Equal(t, uint(0), input.LaunchPlanID)\n\t\t\t\t\tassert.NotEqual(t, uint(0), input.TaskID)\n\t\t\t\t} else {\n\t\t\t\t\tassert.NotEqual(t, uint(0), input.LaunchPlanID)\n\t\t\t\t\tassert.Equal(t, uint(0), input.TaskID)\n\t\t\t\t}\n\t\t\t\tif len(tt.envs) != 0 {\n\t\t\t\t\tassert.Equal(t, tt.envs[0].Key, spec.GetEnvs().Values[0].Key)\n\t\t\t\t\tassert.Equal(t, tt.envs[0].Value, spec.GetEnvs().Values[0].Value)\n\t\t\t\t} else {\n\t\t\t\t\tassert.Nil(t, spec.GetEnvs().GetValues())\n\t\t\t\t}\n\n\t\t\t\treturn nil\n\t\t\t}\n\n\t\t\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetCreateCallback(exCreateFunc)\n\t\t\tmockExecutor := workflowengineMocks.WorkflowExecutor{}\n\t\t\tmockExecutor.OnExecuteMatch(mock.Anything, mock.Anything, mock.Anything).Return(workflowengineInterfaces.ExecutionResponse{}, nil)\n\t\t\tmockExecutor.OnID().Return(\"testMockExecutor\")\n\t\t\tr := plugins.NewRegistry()\n\t\t\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &mockExecutor)\n\t\t\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\n\t\t\t_, err := execManager.CreateExecution(context.Background(), request, requestedAt)\n\t\t\tassert.Nil(t, err)\n\t\t})\n\t}\n}\n\nfunc TestCreateExecution_CustomNamespaceMappingConfig(t *testing.T) {\n\trequest := testutils.GetExecutionRequest()\n\trepository := getMockRepositoryForExecTest()\n\tstorageClient := getMockStorageForExecTest(context.Background())\n\tsetDefaultLpCallbackForExecTest(repository)\n\tmockClock := clock.NewMock()\n\tcreatedAt := time.Now()\n\tmockClock.Set(createdAt)\n\texCreateFunc := func(ctx context.Context, input models.Execution) error {\n\t\tvar spec admin.ExecutionSpec\n\t\terr := proto.Unmarshal(input.Spec, &spec)\n\t\tassert.NoError(t, err)\n\t\tassert.Equal(t, spec.GetMetadata().GetSystemMetadata().Namespace, \"project\")\n\t\treturn nil\n\t}\n\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetCreateCallback(exCreateFunc)\n\tmockExecutor := workflowengineMocks.WorkflowExecutor{}\n\tmockExecutor.OnExecuteMatch(mock.Anything, mock.Anything, mock.Anything).Return(workflowengineInterfaces.ExecutionResponse{}, nil)\n\tmockExecutor.OnID().Return(\"testMockExecutor\")\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &mockExecutor)\n\n\tmockNs := runtimeMocks.NamespaceMappingConfiguration{}\n\tmockNs.OnGetNamespaceTemplate().Return(\"{{ project }}\")\n\tmockExecutionsConfigProvider := runtimeMocks.NewMockConfigurationProvider(\n\t\ttestutils.GetApplicationConfigWithDefaultDomains(),\n\t\truntimeMocks.NewMockQueueConfigurationProvider(\n\t\t\t[]runtimeInterfaces.ExecutionQueue{}, []runtimeInterfaces.WorkflowConfig{}),\n\t\tnil,\n\t\truntimeMocks.NewMockTaskResourceConfiguration(resourceDefaults, resourceLimits), nil, &mockNs)\n\tmockExecutionsConfigProvider.(*runtimeMocks.MockConfigurationProvider).AddRegistrationValidationConfiguration(\n\t\truntimeMocks.NewMockRegistrationValidationProvider())\n\n\texecManager := NewExecutionManager(repository, r, mockExecutionsConfigProvider, storageClient, mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\n\texecManager.(*ExecutionManager)._clock = mockClock\n\n\tresponse, err := execManager.CreateExecution(context.Background(), request, requestedAt)\n\tassert.Nil(t, err)\n\tassert.True(t, proto.Equal(&executionIdentifier, response.Id))\n}\n\nfunc makeExecutionGetFunc(\n\tt *testing.T, closureBytes []byte, startTime *time.Time) repositoryMocks.GetExecutionFunc {\n\treturn func(ctx context.Context, input interfaces.Identifier) (models.Execution, error) {\n\t\tassert.Equal(t, \"project\", input.Project)\n\t\tassert.Equal(t, \"domain\", input.Domain)\n\t\tassert.Equal(t, \"name\", input.Name)\n\t\treturn models.Execution{\n\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\tProject: \"project\",\n\t\t\t\tDomain:  \"domain\",\n\t\t\t\tName:    \"name\",\n\t\t\t},\n\t\t\tBaseModel: models.BaseModel{\n\t\t\t\tID: uint(8),\n\t\t\t},\n\t\t\tSpec:         getExpectedSpecBytes(),\n\t\t\tPhase:        core.WorkflowExecution_QUEUED.String(),\n\t\t\tClosure:      closureBytes,\n\t\t\tLaunchPlanID: uint(1),\n\t\t\tWorkflowID:   uint(2),\n\t\t\tStartedAt:    startTime,\n\t\t\tCluster:      testCluster,\n\t\t}, nil\n\t}\n}\n\nfunc makeLegacyExecutionGetFunc(\n\tt *testing.T, closureBytes []byte, startTime *time.Time) repositoryMocks.GetExecutionFunc {\n\treturn func(ctx context.Context, input interfaces.Identifier) (models.Execution, error) {\n\t\tassert.Equal(t, \"project\", input.Project)\n\t\tassert.Equal(t, \"domain\", input.Domain)\n\t\tassert.Equal(t, \"name\", input.Name)\n\t\treturn models.Execution{\n\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\tProject: \"project\",\n\t\t\t\tDomain:  \"domain\",\n\t\t\t\tName:    \"name\",\n\t\t\t},\n\t\t\tBaseModel: models.BaseModel{\n\t\t\t\tID: uint(8),\n\t\t\t},\n\t\t\tSpec:         getLegacySpecBytes(),\n\t\t\tPhase:        core.WorkflowExecution_QUEUED.String(),\n\t\t\tClosure:      closureBytes,\n\t\t\tLaunchPlanID: uint(1),\n\t\t\tWorkflowID:   uint(2),\n\t\t\tStartedAt:    startTime,\n\t\t\tCluster:      testCluster,\n\t\t}, nil\n\t}\n}\n\nfunc makeExecutionInterruptibleGetFunc(\n\tt *testing.T, closureBytes []byte, startTime *time.Time, interruptible *bool) repositoryMocks.GetExecutionFunc {\n\treturn func(ctx context.Context, input interfaces.Identifier) (models.Execution, error) {\n\t\tassert.Equal(t, \"project\", input.Project)\n\t\tassert.Equal(t, \"domain\", input.Domain)\n\t\tassert.Equal(t, \"name\", input.Name)\n\n\t\trequest := testutils.GetExecutionRequest()\n\t\tif interruptible == nil {\n\t\t\trequest.Spec.Interruptible = nil\n\t\t} else {\n\t\t\trequest.Spec.Interruptible = &wrappers.BoolValue{Value: *interruptible}\n\t\t}\n\n\t\tspecBytes, err := proto.Marshal(request.Spec)\n\t\tassert.Nil(t, err)\n\n\t\treturn models.Execution{\n\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\tProject: \"project\",\n\t\t\t\tDomain:  \"domain\",\n\t\t\t\tName:    \"name\",\n\t\t\t},\n\t\t\tBaseModel: models.BaseModel{\n\t\t\t\tID: uint(8),\n\t\t\t},\n\t\t\tSpec:         specBytes,\n\t\t\tPhase:        core.WorkflowExecution_QUEUED.String(),\n\t\t\tClosure:      closureBytes,\n\t\t\tLaunchPlanID: uint(1),\n\t\t\tWorkflowID:   uint(2),\n\t\t\tStartedAt:    startTime,\n\t\t\tCluster:      testCluster,\n\t\t}, nil\n\t}\n}\n\nfunc makeExecutionOverwriteCacheGetFunc(\n\tt *testing.T, closureBytes []byte, startTime *time.Time, overwriteCache bool) repositoryMocks.GetExecutionFunc {\n\treturn func(ctx context.Context, input interfaces.Identifier) (models.Execution, error) {\n\t\tassert.Equal(t, \"project\", input.Project)\n\t\tassert.Equal(t, \"domain\", input.Domain)\n\t\tassert.Equal(t, \"name\", input.Name)\n\n\t\trequest := testutils.GetExecutionRequest()\n\t\trequest.Spec.OverwriteCache = overwriteCache\n\n\t\tspecBytes, err := proto.Marshal(request.Spec)\n\t\tassert.Nil(t, err)\n\n\t\treturn models.Execution{\n\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\tProject: \"project\",\n\t\t\t\tDomain:  \"domain\",\n\t\t\t\tName:    \"name\",\n\t\t\t},\n\t\t\tBaseModel: models.BaseModel{\n\t\t\t\tID: uint(8),\n\t\t\t},\n\t\t\tSpec:         specBytes,\n\t\t\tPhase:        core.WorkflowExecution_QUEUED.String(),\n\t\t\tClosure:      closureBytes,\n\t\t\tLaunchPlanID: uint(1),\n\t\t\tWorkflowID:   uint(2),\n\t\t\tStartedAt:    startTime,\n\t\t\tCluster:      testCluster,\n\t\t}, nil\n\t}\n}\n\nfunc makeExecutionWithEnvs(\n\tt *testing.T, closureBytes []byte, startTime *time.Time, envs []*core.KeyValuePair) repositoryMocks.GetExecutionFunc {\n\treturn func(ctx context.Context, input interfaces.Identifier) (models.Execution, error) {\n\t\tassert.Equal(t, \"project\", input.Project)\n\t\tassert.Equal(t, \"domain\", input.Domain)\n\t\tassert.Equal(t, \"name\", input.Name)\n\n\t\trequest := testutils.GetExecutionRequest()\n\t\trequest.Spec.Envs.Values = envs\n\n\t\tspecBytes, err := proto.Marshal(request.Spec)\n\t\tassert.Nil(t, err)\n\n\t\treturn models.Execution{\n\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\tProject: \"project\",\n\t\t\t\tDomain:  \"domain\",\n\t\t\t\tName:    \"name\",\n\t\t\t},\n\t\t\tBaseModel: models.BaseModel{\n\t\t\t\tID: uint(8),\n\t\t\t},\n\t\t\tSpec:         specBytes,\n\t\t\tPhase:        core.WorkflowExecution_QUEUED.String(),\n\t\t\tClosure:      closureBytes,\n\t\t\tLaunchPlanID: uint(1),\n\t\t\tWorkflowID:   uint(2),\n\t\t\tStartedAt:    startTime,\n\t\t\tCluster:      testCluster,\n\t\t}, nil\n\t}\n}\n\nfunc TestRelaunchExecution(t *testing.T) {\n\t// Set up mocks.\n\trepository := getMockRepositoryForExecTest()\n\tsetDefaultLpCallbackForExecTest(repository)\n\tmockExecutor := workflowengineMocks.WorkflowExecutor{}\n\tmockExecutor.OnExecuteMatch(mock.Anything, mock.Anything, mock.Anything).Return(workflowengineInterfaces.ExecutionResponse{}, nil)\n\tmockExecutor.OnID().Return(\"testMockExecutor\")\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &mockExecutor)\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\tstartTime := time.Now()\n\tstartTimeProto, _ := ptypes.TimestampProto(startTime)\n\texistingClosure := admin.ExecutionClosure{\n\t\tPhase:     core.WorkflowExecution_RUNNING,\n\t\tStartedAt: startTimeProto,\n\t}\n\texistingClosureBytes, _ := proto.Marshal(&existingClosure)\n\texecutionGetFunc := makeExecutionGetFunc(t, existingClosureBytes, &startTime)\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetGetCallback(executionGetFunc)\n\n\tvar createCalled bool\n\texCreateFunc := func(ctx context.Context, input models.Execution) error {\n\t\tcreateCalled = true\n\t\tassert.Equal(t, \"relaunchy\", input.Name)\n\t\tassert.Equal(t, \"domain\", input.Domain)\n\t\tassert.Equal(t, \"project\", input.Project)\n\t\tassert.Equal(t, uint(8), input.SourceExecutionID)\n\t\tvar spec admin.ExecutionSpec\n\t\terr := proto.Unmarshal(input.Spec, &spec)\n\t\tassert.Nil(t, err)\n\t\tassert.Equal(t, admin.ExecutionMetadata_RELAUNCH, spec.Metadata.Mode)\n\t\tassert.Equal(t, int32(admin.ExecutionMetadata_RELAUNCH), input.Mode)\n\t\treturn nil\n\t}\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetCreateCallback(exCreateFunc)\n\n\t// Issue request.\n\tresponse, err := execManager.RelaunchExecution(context.Background(), admin.ExecutionRelaunchRequest{\n\t\tId: &core.WorkflowExecutionIdentifier{\n\t\t\tProject: \"project\",\n\t\t\tDomain:  \"domain\",\n\t\t\tName:    \"name\",\n\t\t},\n\t\tName: \"relaunchy\",\n\t}, requestedAt)\n\n\t// And verify response.\n\tassert.Nil(t, err)\n\n\texpectedResponse := &admin.ExecutionCreateResponse{\n\t\tId: &core.WorkflowExecutionIdentifier{\n\t\t\tProject: \"project\",\n\t\t\tDomain:  \"domain\",\n\t\t\tName:    \"relaunchy\",\n\t\t},\n\t}\n\tassert.True(t, createCalled)\n\tassert.True(t, proto.Equal(expectedResponse, response))\n\n\t// TODO: Test with inputs\n}\n\nfunc TestRelaunchExecution_GetExistingFailure(t *testing.T) {\n\t// Set up mocks.\n\trepository := getMockRepositoryForExecTest()\n\tsetDefaultLpCallbackForExecTest(repository)\n\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &defaultTestExecutor)\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\n\texpectedErr := errors.New(\"expected error\")\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetGetCallback(\n\t\tfunc(ctx context.Context, input interfaces.Identifier) (models.Execution, error) {\n\t\t\treturn models.Execution{}, expectedErr\n\t\t})\n\n\tvar createCalled bool\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetCreateCallback(\n\t\tfunc(ctx context.Context, input models.Execution) error {\n\t\t\tcreateCalled = true\n\t\t\treturn nil\n\t\t})\n\n\t// Issue request.\n\t_, err := execManager.RelaunchExecution(context.Background(), admin.ExecutionRelaunchRequest{\n\t\tId: &core.WorkflowExecutionIdentifier{\n\t\t\tProject: \"project\",\n\t\t\tDomain:  \"domain\",\n\t\t\tName:    \"name\",\n\t\t},\n\t\tName: \"relaunchy\",\n\t}, requestedAt)\n\n\t// And verify response.\n\tassert.EqualError(t, err, expectedErr.Error())\n\tassert.False(t, createCalled)\n}\n\nfunc TestRelaunchExecution_CreateFailure(t *testing.T) {\n\t// Set up mocks.\n\trepository := getMockRepositoryForExecTest()\n\tsetDefaultLpCallbackForExecTest(repository)\n\tmockExecutor := workflowengineMocks.WorkflowExecutor{}\n\tmockExecutor.OnExecuteMatch(mock.Anything, mock.Anything, mock.Anything).Return(workflowengineInterfaces.ExecutionResponse{}, nil)\n\tmockExecutor.OnID().Return(\"testMockExecutor\")\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &mockExecutor)\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\tstartTime := time.Now()\n\tstartTimeProto, _ := ptypes.TimestampProto(startTime)\n\texistingClosure := admin.ExecutionClosure{\n\t\tPhase:     core.WorkflowExecution_RUNNING,\n\t\tStartedAt: startTimeProto,\n\t}\n\texistingClosureBytes, _ := proto.Marshal(&existingClosure)\n\texecutionGetFunc := makeExecutionGetFunc(t, existingClosureBytes, &startTime)\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetGetCallback(executionGetFunc)\n\n\texpectedErr := errors.New(\"expected error\")\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetCreateCallback(\n\t\tfunc(ctx context.Context, input models.Execution) error {\n\t\t\treturn expectedErr\n\t\t})\n\n\t// Issue request.\n\t_, err := execManager.RelaunchExecution(context.Background(), admin.ExecutionRelaunchRequest{\n\t\tId: &core.WorkflowExecutionIdentifier{\n\t\t\tProject: \"project\",\n\t\t\tDomain:  \"domain\",\n\t\t\tName:    \"name\",\n\t\t},\n\t\tName: \"relaunchy\",\n\t}, requestedAt)\n\n\t// And verify response.\n\tassert.EqualError(t, err, expectedErr.Error())\n}\n\nfunc TestRelaunchExecutionInterruptibleOverride(t *testing.T) {\n\t// Set up mocks.\n\trepository := getMockRepositoryForExecTest()\n\tsetDefaultLpCallbackForExecTest(repository)\n\tmockExecutor := workflowengineMocks.WorkflowExecutor{}\n\tmockExecutor.OnExecuteMatch(mock.Anything, mock.Anything, mock.Anything).Return(workflowengineInterfaces.ExecutionResponse{}, nil)\n\tmockExecutor.OnID().Return(\"testMockExecutor\")\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &mockExecutor)\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\tstartTime := time.Now()\n\tstartTimeProto, _ := ptypes.TimestampProto(startTime)\n\texistingClosure := admin.ExecutionClosure{\n\t\tPhase:     core.WorkflowExecution_RUNNING,\n\t\tStartedAt: startTimeProto,\n\t}\n\texistingClosureBytes, _ := proto.Marshal(&existingClosure)\n\tinterruptible := true\n\texecutionGetFunc := makeExecutionInterruptibleGetFunc(t, existingClosureBytes, &startTime, &interruptible)\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetGetCallback(executionGetFunc)\n\n\tvar createCalled bool\n\texCreateFunc := func(ctx context.Context, input models.Execution) error {\n\t\tcreateCalled = true\n\t\tassert.Equal(t, \"relaunchy\", input.Name)\n\t\tassert.Equal(t, \"domain\", input.Domain)\n\t\tassert.Equal(t, \"project\", input.Project)\n\t\tassert.Equal(t, uint(8), input.SourceExecutionID)\n\t\tvar spec admin.ExecutionSpec\n\t\terr := proto.Unmarshal(input.Spec, &spec)\n\t\tassert.Nil(t, err)\n\t\tassert.Equal(t, admin.ExecutionMetadata_RELAUNCH, spec.Metadata.Mode)\n\t\tassert.Equal(t, int32(admin.ExecutionMetadata_RELAUNCH), input.Mode)\n\t\tassert.NotNil(t, spec.GetInterruptible())\n\t\tassert.True(t, spec.GetInterruptible().GetValue())\n\t\treturn nil\n\t}\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetCreateCallback(exCreateFunc)\n\n\t_, err := execManager.RelaunchExecution(context.Background(), admin.ExecutionRelaunchRequest{\n\t\tId: &core.WorkflowExecutionIdentifier{\n\t\t\tProject: \"project\",\n\t\t\tDomain:  \"domain\",\n\t\t\tName:    \"name\",\n\t\t},\n\t\tName: \"relaunchy\",\n\t}, requestedAt)\n\tassert.Nil(t, err)\n\tassert.True(t, createCalled)\n}\n\nfunc TestRelaunchExecutionOverwriteCacheOverride(t *testing.T) {\n\t// Set up mocks.\n\trepository := getMockRepositoryForExecTest()\n\tsetDefaultLpCallbackForExecTest(repository)\n\tmockExecutor := workflowengineMocks.WorkflowExecutor{}\n\tmockExecutor.OnExecuteMatch(mock.Anything, mock.Anything, mock.Anything).Return(workflowengineInterfaces.ExecutionResponse{}, nil)\n\tmockExecutor.OnID().Return(\"testMockExecutor\")\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &mockExecutor)\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\tstartTime := time.Now()\n\tstartTimeProto, _ := ptypes.TimestampProto(startTime)\n\texistingClosure := admin.ExecutionClosure{\n\t\tPhase:     core.WorkflowExecution_RUNNING,\n\t\tStartedAt: startTimeProto,\n\t}\n\texistingClosureBytes, _ := proto.Marshal(&existingClosure)\n\n\tt.Run(\"override enable\", func(t *testing.T) {\n\t\texecutionGetFunc := makeExecutionOverwriteCacheGetFunc(t, existingClosureBytes, &startTime, false)\n\t\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetGetCallback(executionGetFunc)\n\n\t\tvar createCalled bool\n\t\texCreateFunc := func(ctx context.Context, input models.Execution) error {\n\t\t\tcreateCalled = true\n\t\t\tassert.Equal(t, \"relaunchy\", input.Name)\n\t\t\tassert.Equal(t, \"domain\", input.Domain)\n\t\t\tassert.Equal(t, \"project\", input.Project)\n\t\t\tassert.Equal(t, uint(8), input.SourceExecutionID)\n\t\t\tvar spec admin.ExecutionSpec\n\t\t\terr := proto.Unmarshal(input.Spec, &spec)\n\t\t\tassert.Nil(t, err)\n\t\t\tassert.Equal(t, admin.ExecutionMetadata_RELAUNCH, spec.Metadata.Mode)\n\t\t\tassert.Equal(t, int32(admin.ExecutionMetadata_RELAUNCH), input.Mode)\n\t\t\tassert.True(t, spec.GetOverwriteCache())\n\t\t\treturn nil\n\t\t}\n\t\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetCreateCallback(exCreateFunc)\n\n\t\tasd, err := execManager.RelaunchExecution(context.Background(), admin.ExecutionRelaunchRequest{\n\t\t\tId: &core.WorkflowExecutionIdentifier{\n\t\t\t\tProject: \"project\",\n\t\t\t\tDomain:  \"domain\",\n\t\t\t\tName:    \"name\",\n\t\t\t},\n\t\t\tName:           \"relaunchy\",\n\t\t\tOverwriteCache: true,\n\t\t}, requestedAt)\n\t\tassert.Nil(t, err)\n\t\tassert.NotNil(t, asd)\n\t\tassert.True(t, createCalled)\n\t})\n\n\tt.Run(\"override disable\", func(t *testing.T) {\n\t\texecutionGetFunc := makeExecutionOverwriteCacheGetFunc(t, existingClosureBytes, &startTime, true)\n\t\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetGetCallback(executionGetFunc)\n\n\t\tvar createCalled bool\n\t\texCreateFunc := func(ctx context.Context, input models.Execution) error {\n\t\t\tcreateCalled = true\n\t\t\tassert.Equal(t, \"relaunchy\", input.Name)\n\t\t\tassert.Equal(t, \"domain\", input.Domain)\n\t\t\tassert.Equal(t, \"project\", input.Project)\n\t\t\tassert.Equal(t, uint(8), input.SourceExecutionID)\n\t\t\tvar spec admin.ExecutionSpec\n\t\t\terr := proto.Unmarshal(input.Spec, &spec)\n\t\t\tassert.Nil(t, err)\n\t\t\tassert.Equal(t, admin.ExecutionMetadata_RELAUNCH, spec.Metadata.Mode)\n\t\t\tassert.Equal(t, int32(admin.ExecutionMetadata_RELAUNCH), input.Mode)\n\t\t\tassert.False(t, spec.GetOverwriteCache())\n\t\t\treturn nil\n\t\t}\n\t\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetCreateCallback(exCreateFunc)\n\n\t\tasd, err := execManager.RelaunchExecution(context.Background(), admin.ExecutionRelaunchRequest{\n\t\t\tId: &core.WorkflowExecutionIdentifier{\n\t\t\t\tProject: \"project\",\n\t\t\t\tDomain:  \"domain\",\n\t\t\t\tName:    \"name\",\n\t\t\t},\n\t\t\tName:           \"relaunchy\",\n\t\t\tOverwriteCache: false,\n\t\t}, requestedAt)\n\t\tassert.Nil(t, err)\n\t\tassert.NotNil(t, asd)\n\t\tassert.True(t, createCalled)\n\t})\n\n\tt.Run(\"override omitted\", func(t *testing.T) {\n\t\texecutionGetFunc := makeExecutionOverwriteCacheGetFunc(t, existingClosureBytes, &startTime, true)\n\t\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetGetCallback(executionGetFunc)\n\n\t\tvar createCalled bool\n\t\texCreateFunc := func(ctx context.Context, input models.Execution) error {\n\t\t\tcreateCalled = true\n\t\t\tassert.Equal(t, \"relaunchy\", input.Name)\n\t\t\tassert.Equal(t, \"domain\", input.Domain)\n\t\t\tassert.Equal(t, \"project\", input.Project)\n\t\t\tassert.Equal(t, uint(8), input.SourceExecutionID)\n\t\t\tvar spec admin.ExecutionSpec\n\t\t\terr := proto.Unmarshal(input.Spec, &spec)\n\t\t\tassert.Nil(t, err)\n\t\t\tassert.Equal(t, admin.ExecutionMetadata_RELAUNCH, spec.Metadata.Mode)\n\t\t\tassert.Equal(t, int32(admin.ExecutionMetadata_RELAUNCH), input.Mode)\n\t\t\tassert.False(t, spec.GetOverwriteCache())\n\t\t\treturn nil\n\t\t}\n\t\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetCreateCallback(exCreateFunc)\n\n\t\tasd, err := execManager.RelaunchExecution(context.Background(), admin.ExecutionRelaunchRequest{\n\t\t\tId: &core.WorkflowExecutionIdentifier{\n\t\t\t\tProject: \"project\",\n\t\t\t\tDomain:  \"domain\",\n\t\t\t\tName:    \"name\",\n\t\t\t},\n\t\t\tName: \"relaunchy\",\n\t\t}, requestedAt)\n\t\tassert.Nil(t, err)\n\t\tassert.NotNil(t, asd)\n\t\tassert.True(t, createCalled)\n\t})\n}\n\nfunc TestRelaunchExecutionEnvsOverride(t *testing.T) {\n\t// Set up mocks.\n\trepository := getMockRepositoryForExecTest()\n\tsetDefaultLpCallbackForExecTest(repository)\n\tmockExecutor := workflowengineMocks.WorkflowExecutor{}\n\tmockExecutor.OnExecuteMatch(mock.Anything, mock.Anything, mock.Anything).Return(workflowengineInterfaces.ExecutionResponse{}, nil)\n\tmockExecutor.OnID().Return(\"testMockExecutor\")\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &mockExecutor)\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\tstartTime := time.Now()\n\tstartTimeProto, _ := ptypes.TimestampProto(startTime)\n\texistingClosure := admin.ExecutionClosure{\n\t\tPhase:     core.WorkflowExecution_RUNNING,\n\t\tStartedAt: startTimeProto,\n\t}\n\texistingClosureBytes, _ := proto.Marshal(&existingClosure)\n\tenv := []*core.KeyValuePair{{Key: \"foo\", Value: \"bar\"}}\n\texecutionGetFunc := makeExecutionWithEnvs(t, existingClosureBytes, &startTime, env)\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetGetCallback(executionGetFunc)\n\n\tvar createCalled bool\n\texCreateFunc := func(ctx context.Context, input models.Execution) error {\n\t\tcreateCalled = true\n\t\tassert.Equal(t, \"relaunchy\", input.Name)\n\t\tassert.Equal(t, \"domain\", input.Domain)\n\t\tassert.Equal(t, \"project\", input.Project)\n\t\tassert.Equal(t, uint(8), input.SourceExecutionID)\n\t\tvar spec admin.ExecutionSpec\n\t\terr := proto.Unmarshal(input.Spec, &spec)\n\t\tassert.Nil(t, err)\n\t\tassert.Equal(t, admin.ExecutionMetadata_RELAUNCH, spec.Metadata.Mode)\n\t\tassert.Equal(t, int32(admin.ExecutionMetadata_RELAUNCH), input.Mode)\n\t\tassert.NotNil(t, spec.GetEnvs())\n\t\tassert.Equal(t, spec.GetEnvs().Values[0].Key, env[0].Key)\n\t\tassert.Equal(t, spec.GetEnvs().Values[0].Value, env[0].Value)\n\t\treturn nil\n\t}\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetCreateCallback(exCreateFunc)\n\n\t_, err := execManager.RelaunchExecution(context.Background(), admin.ExecutionRelaunchRequest{\n\t\tId: &core.WorkflowExecutionIdentifier{\n\t\t\tProject: \"project\",\n\t\t\tDomain:  \"domain\",\n\t\t\tName:    \"name\",\n\t\t},\n\t\tName: \"relaunchy\",\n\t}, requestedAt)\n\tassert.Nil(t, err)\n\tassert.True(t, createCalled)\n}\n\nfunc TestRecoverExecution(t *testing.T) {\n\t// Set up mocks.\n\trepository := getMockRepositoryForExecTest()\n\tsetDefaultLpCallbackForExecTest(repository)\n\tmockExecutor := workflowengineMocks.WorkflowExecutor{}\n\tmockExecutor.OnExecuteMatch(mock.Anything, mock.Anything, mock.Anything).Return(workflowengineInterfaces.ExecutionResponse{}, nil)\n\tmockExecutor.OnID().Return(\"testMockExecutor\")\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &mockExecutor)\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\tstartTime := time.Now()\n\tstartTimeProto, _ := ptypes.TimestampProto(startTime)\n\texistingClosure := admin.ExecutionClosure{\n\t\tPhase:     core.WorkflowExecution_SUCCEEDED,\n\t\tStartedAt: startTimeProto,\n\t}\n\texistingClosureBytes, _ := proto.Marshal(&existingClosure)\n\texecutionGetFunc := makeExecutionGetFunc(t, existingClosureBytes, &startTime)\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetGetCallback(executionGetFunc)\n\n\tvar createCalled bool\n\texCreateFunc := func(ctx context.Context, input models.Execution) error {\n\t\tcreateCalled = true\n\t\tassert.Equal(t, \"recovered\", input.Name)\n\t\tassert.Equal(t, \"domain\", input.Domain)\n\t\tassert.Equal(t, \"project\", input.Project)\n\t\tassert.Equal(t, uint(8), input.SourceExecutionID)\n\t\tvar spec admin.ExecutionSpec\n\t\terr := proto.Unmarshal(input.Spec, &spec)\n\t\tassert.Nil(t, err)\n\t\tassert.Equal(t, admin.ExecutionMetadata_RECOVERED, spec.Metadata.Mode)\n\t\tassert.Equal(t, int32(admin.ExecutionMetadata_RECOVERED), input.Mode)\n\t\treturn nil\n\t}\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetCreateCallback(exCreateFunc)\n\n\t// Issue request.\n\tresponse, err := execManager.RecoverExecution(context.Background(), admin.ExecutionRecoverRequest{\n\t\tId: &core.WorkflowExecutionIdentifier{\n\t\t\tProject: \"project\",\n\t\t\tDomain:  \"domain\",\n\t\t\tName:    \"name\",\n\t\t},\n\t\tName: \"recovered\",\n\t}, requestedAt)\n\n\t// And verify response.\n\tassert.Nil(t, err)\n\n\texpectedResponse := &admin.ExecutionCreateResponse{\n\t\tId: &core.WorkflowExecutionIdentifier{\n\t\t\tProject: \"project\",\n\t\t\tDomain:  \"domain\",\n\t\t\tName:    \"recovered\",\n\t\t},\n\t}\n\tassert.True(t, createCalled)\n\tassert.True(t, proto.Equal(expectedResponse, response))\n}\n\nfunc TestRecoverExecution_RecoveredChildNode(t *testing.T) {\n\trepository := getMockRepositoryForExecTest()\n\tsetDefaultLpCallbackForExecTest(repository)\n\tmockExecutor := workflowengineMocks.WorkflowExecutor{}\n\tmockExecutor.OnExecuteMatch(mock.Anything, mock.Anything, mock.Anything).Return(workflowengineInterfaces.ExecutionResponse{}, nil)\n\tmockExecutor.OnID().Return(\"testMockExecutor\")\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &mockExecutor)\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\tstartTime := time.Now()\n\tstartTimeProto, _ := ptypes.TimestampProto(startTime)\n\texistingClosure := admin.ExecutionClosure{\n\t\tPhase:     core.WorkflowExecution_SUCCEEDED,\n\t\tStartedAt: startTimeProto,\n\t}\n\texistingClosureBytes, _ := proto.Marshal(&existingClosure)\n\treferencedExecutionID := uint(123)\n\tignoredExecutionID := uint(456)\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetGetCallback(func(ctx context.Context, input interfaces.Identifier) (models.Execution, error) {\n\t\tswitch input.Name {\n\t\tcase \"name\":\n\t\t\treturn models.Execution{\n\t\t\t\tSpec:    getExpectedSpecBytes(),\n\t\t\t\tClosure: existingClosureBytes,\n\t\t\t\tBaseModel: models.BaseModel{\n\t\t\t\t\tID: referencedExecutionID,\n\t\t\t\t},\n\t\t\t}, nil\n\t\tcase \"orig\":\n\t\t\treturn models.Execution{\n\t\t\t\tBaseModel: models.BaseModel{\n\t\t\t\t\tID: ignoredExecutionID,\n\t\t\t\t},\n\t\t\t}, nil\n\t\tdefault:\n\t\t\treturn models.Execution{}, flyteAdminErrors.NewFlyteAdminErrorf(codes.InvalidArgument, \"unexpected get for execution %s\", input.Name)\n\t\t}\n\t})\n\n\tparentNodeDatabaseID := uint(12345)\n\tvar createCalled bool\n\texCreateFunc := func(ctx context.Context, input models.Execution) error {\n\t\tcreateCalled = true\n\t\tassert.Equal(t, \"recovered\", input.Name)\n\t\tassert.Equal(t, \"domain\", input.Domain)\n\t\tassert.Equal(t, \"project\", input.Project)\n\t\tvar spec admin.ExecutionSpec\n\t\terr := proto.Unmarshal(input.Spec, &spec)\n\t\tassert.Nil(t, err)\n\t\tassert.Equal(t, admin.ExecutionMetadata_RECOVERED, spec.Metadata.Mode)\n\t\tassert.Equal(t, int32(admin.ExecutionMetadata_RECOVERED), input.Mode)\n\t\tassert.Equal(t, parentNodeDatabaseID, input.ParentNodeExecutionID)\n\t\tassert.Equal(t, referencedExecutionID, input.SourceExecutionID)\n\n\t\treturn nil\n\t}\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetCreateCallback(exCreateFunc)\n\n\tparentNodeExecution := core.NodeExecutionIdentifier{\n\t\tExecutionId: &core.WorkflowExecutionIdentifier{\n\t\t\tProject: \"p\",\n\t\t\tDomain:  \"d\",\n\t\t\tName:    \"orig\",\n\t\t},\n\t\tNodeId: \"parent\",\n\t}\n\trepository.NodeExecutionRepo().(*repositoryMocks.MockNodeExecutionRepo).SetGetCallback(func(ctx context.Context, input interfaces.NodeExecutionResource) (models.NodeExecution, error) {\n\t\tassert.True(t, proto.Equal(&parentNodeExecution, &input.NodeExecutionIdentifier))\n\n\t\treturn models.NodeExecution{\n\t\t\tBaseModel: models.BaseModel{\n\t\t\t\tID: parentNodeDatabaseID,\n\t\t\t},\n\t\t}, nil\n\t})\n\n\t// Issue request.\n\tresponse, err := execManager.RecoverExecution(context.Background(), admin.ExecutionRecoverRequest{\n\t\tId: &core.WorkflowExecutionIdentifier{\n\t\t\tProject: \"project\",\n\t\t\tDomain:  \"domain\",\n\t\t\tName:    \"name\",\n\t\t},\n\t\tName: \"recovered\",\n\t\tMetadata: &admin.ExecutionMetadata{\n\t\t\tParentNodeExecution: &parentNodeExecution,\n\t\t},\n\t}, requestedAt)\n\n\t// And verify response.\n\tassert.Nil(t, err)\n\n\texpectedResponse := &admin.ExecutionCreateResponse{\n\t\tId: &core.WorkflowExecutionIdentifier{\n\t\t\tProject: \"project\",\n\t\t\tDomain:  \"domain\",\n\t\t\tName:    \"recovered\",\n\t\t},\n\t}\n\tassert.True(t, createCalled)\n\tassert.True(t, proto.Equal(expectedResponse, response))\n}\n\nfunc TestRecoverExecution_GetExistingFailure(t *testing.T) {\n\t// Set up mocks.\n\trepository := getMockRepositoryForExecTest()\n\tsetDefaultLpCallbackForExecTest(repository)\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &defaultTestExecutor)\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\n\texpectedErr := errors.New(\"expected error\")\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetGetCallback(\n\t\tfunc(ctx context.Context, input interfaces.Identifier) (models.Execution, error) {\n\t\t\treturn models.Execution{}, expectedErr\n\t\t})\n\n\tvar createCalled bool\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetCreateCallback(\n\t\tfunc(ctx context.Context, input models.Execution) error {\n\t\t\tcreateCalled = true\n\t\t\treturn nil\n\t\t})\n\n\t// Issue request.\n\t_, err := execManager.RecoverExecution(context.Background(), admin.ExecutionRecoverRequest{\n\t\tId: &core.WorkflowExecutionIdentifier{\n\t\t\tProject: \"project\",\n\t\t\tDomain:  \"domain\",\n\t\t\tName:    \"name\",\n\t\t},\n\t\tName: \"recovered\",\n\t}, requestedAt)\n\n\t// And verify response.\n\tassert.EqualError(t, err, expectedErr.Error())\n\tassert.False(t, createCalled)\n}\n\nfunc TestRecoverExecution_GetExistingInputsFailure(t *testing.T) {\n\t// Set up mocks.\n\trepository := getMockRepositoryForExecTest()\n\tsetDefaultLpCallbackForExecTest(repository)\n\n\texpectedErr := errors.New(\"foo\")\n\tmockStorage := commonMocks.GetMockStorageClient()\n\tmockStorage.ComposedProtobufStore.(*commonMocks.TestDataStore).ReadProtobufCb = func(\n\t\tctx context.Context, reference storage.DataReference, msg proto.Message) error {\n\t\treturn expectedErr\n\t}\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &defaultTestExecutor)\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), mockStorage, mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\tstartTime := time.Now()\n\tstartTimeProto, _ := ptypes.TimestampProto(startTime)\n\texistingClosure := admin.ExecutionClosure{\n\t\tPhase:     core.WorkflowExecution_SUCCEEDED,\n\t\tStartedAt: startTimeProto,\n\t}\n\texistingClosureBytes, _ := proto.Marshal(&existingClosure)\n\texecutionGetFunc := makeExecutionGetFunc(t, existingClosureBytes, &startTime)\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetGetCallback(executionGetFunc)\n\n\t// Issue request.\n\t_, err := execManager.RecoverExecution(context.Background(), admin.ExecutionRecoverRequest{\n\t\tId: &core.WorkflowExecutionIdentifier{\n\t\t\tProject: \"project\",\n\t\t\tDomain:  \"domain\",\n\t\t\tName:    \"name\",\n\t\t},\n\t\tName: \"recovered\",\n\t}, requestedAt)\n\n\t// And verify response.\n\tassert.EqualError(t, err, \"Unable to read WorkflowClosure from location s3://flyte/metadata/admin/remote closure id : foo\")\n}\n\nfunc TestRecoverExecutionInterruptibleOverride(t *testing.T) {\n\t// Set up mocks.\n\trepository := getMockRepositoryForExecTest()\n\tsetDefaultLpCallbackForExecTest(repository)\n\tmockExecutor := workflowengineMocks.WorkflowExecutor{}\n\tmockExecutor.OnExecuteMatch(mock.Anything, mock.Anything, mock.Anything).Return(workflowengineInterfaces.ExecutionResponse{}, nil)\n\tmockExecutor.OnID().Return(\"testMockExecutor\")\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &mockExecutor)\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\tstartTime := time.Now()\n\tstartTimeProto, _ := ptypes.TimestampProto(startTime)\n\texistingClosure := admin.ExecutionClosure{\n\t\tPhase:     core.WorkflowExecution_SUCCEEDED,\n\t\tStartedAt: startTimeProto,\n\t}\n\texistingClosureBytes, _ := proto.Marshal(&existingClosure)\n\tinterruptible := true\n\texecutionGetFunc := makeExecutionInterruptibleGetFunc(t, existingClosureBytes, &startTime, &interruptible)\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetGetCallback(executionGetFunc)\n\n\tvar createCalled bool\n\texCreateFunc := func(ctx context.Context, input models.Execution) error {\n\t\tcreateCalled = true\n\t\tassert.Equal(t, \"recovered\", input.Name)\n\t\tassert.Equal(t, \"domain\", input.Domain)\n\t\tassert.Equal(t, \"project\", input.Project)\n\t\tassert.Equal(t, uint(8), input.SourceExecutionID)\n\t\tvar spec admin.ExecutionSpec\n\t\terr := proto.Unmarshal(input.Spec, &spec)\n\t\tassert.Nil(t, err)\n\t\tassert.Equal(t, admin.ExecutionMetadata_RECOVERED, spec.Metadata.Mode)\n\t\tassert.Equal(t, int32(admin.ExecutionMetadata_RECOVERED), input.Mode)\n\t\tassert.NotNil(t, spec.GetInterruptible())\n\t\tassert.True(t, spec.GetInterruptible().GetValue())\n\t\treturn nil\n\t}\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetCreateCallback(exCreateFunc)\n\n\t// Issue request.\n\tresponse, err := execManager.RecoverExecution(context.Background(), admin.ExecutionRecoverRequest{\n\t\tId: &core.WorkflowExecutionIdentifier{\n\t\t\tProject: \"project\",\n\t\t\tDomain:  \"domain\",\n\t\t\tName:    \"name\",\n\t\t},\n\t\tName: \"recovered\",\n\t}, requestedAt)\n\n\t// And verify response.\n\tassert.Nil(t, err)\n\n\texpectedResponse := &admin.ExecutionCreateResponse{\n\t\tId: &core.WorkflowExecutionIdentifier{\n\t\t\tProject: \"project\",\n\t\t\tDomain:  \"domain\",\n\t\t\tName:    \"recovered\",\n\t\t},\n\t}\n\tassert.True(t, createCalled)\n\tassert.True(t, proto.Equal(expectedResponse, response))\n}\n\nfunc TestRecoverExecutionOverwriteCacheOverride(t *testing.T) {\n\t// Set up mocks.\n\trepository := getMockRepositoryForExecTest()\n\tsetDefaultLpCallbackForExecTest(repository)\n\tmockExecutor := workflowengineMocks.WorkflowExecutor{}\n\tmockExecutor.OnExecuteMatch(mock.Anything, mock.Anything, mock.Anything).Return(workflowengineInterfaces.ExecutionResponse{}, nil)\n\tmockExecutor.OnID().Return(\"testMockExecutor\")\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &mockExecutor)\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\tstartTime := time.Now()\n\tstartTimeProto, _ := ptypes.TimestampProto(startTime)\n\texistingClosure := admin.ExecutionClosure{\n\t\tPhase:     core.WorkflowExecution_SUCCEEDED,\n\t\tStartedAt: startTimeProto,\n\t}\n\texistingClosureBytes, _ := proto.Marshal(&existingClosure)\n\texecutionGetFunc := makeExecutionOverwriteCacheGetFunc(t, existingClosureBytes, &startTime, true)\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetGetCallback(executionGetFunc)\n\n\tvar createCalled bool\n\texCreateFunc := func(ctx context.Context, input models.Execution) error {\n\t\tcreateCalled = true\n\t\tassert.Equal(t, \"recovered\", input.Name)\n\t\tassert.Equal(t, \"domain\", input.Domain)\n\t\tassert.Equal(t, \"project\", input.Project)\n\t\tassert.Equal(t, uint(8), input.SourceExecutionID)\n\t\tvar spec admin.ExecutionSpec\n\t\terr := proto.Unmarshal(input.Spec, &spec)\n\t\tassert.Nil(t, err)\n\t\tassert.Equal(t, admin.ExecutionMetadata_RECOVERED, spec.Metadata.Mode)\n\t\tassert.Equal(t, int32(admin.ExecutionMetadata_RECOVERED), input.Mode)\n\t\tassert.True(t, spec.GetOverwriteCache())\n\t\treturn nil\n\t}\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetCreateCallback(exCreateFunc)\n\n\t// Issue request.\n\tresponse, err := execManager.RecoverExecution(context.Background(), admin.ExecutionRecoverRequest{\n\t\tId: &core.WorkflowExecutionIdentifier{\n\t\t\tProject: \"project\",\n\t\t\tDomain:  \"domain\",\n\t\t\tName:    \"name\",\n\t\t},\n\t\tName: \"recovered\",\n\t}, requestedAt)\n\n\t// And verify response.\n\tassert.Nil(t, err)\n\n\texpectedResponse := &admin.ExecutionCreateResponse{\n\t\tId: &core.WorkflowExecutionIdentifier{\n\t\t\tProject: \"project\",\n\t\t\tDomain:  \"domain\",\n\t\t\tName:    \"recovered\",\n\t\t},\n\t}\n\tassert.True(t, createCalled)\n\tassert.True(t, proto.Equal(expectedResponse, response))\n}\n\nfunc TestRecoverExecutionEnvsOverride(t *testing.T) {\n\t// Set up mocks.\n\trepository := getMockRepositoryForExecTest()\n\tsetDefaultLpCallbackForExecTest(repository)\n\tmockExecutor := workflowengineMocks.WorkflowExecutor{}\n\tmockExecutor.OnExecuteMatch(mock.Anything, mock.Anything, mock.Anything).Return(workflowengineInterfaces.ExecutionResponse{}, nil)\n\tmockExecutor.OnID().Return(\"testMockExecutor\")\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &mockExecutor)\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\tstartTime := time.Now()\n\tstartTimeProto, _ := ptypes.TimestampProto(startTime)\n\texistingClosure := admin.ExecutionClosure{\n\t\tPhase:     core.WorkflowExecution_SUCCEEDED,\n\t\tStartedAt: startTimeProto,\n\t}\n\texistingClosureBytes, _ := proto.Marshal(&existingClosure)\n\tenv := []*core.KeyValuePair{{Key: \"foo\", Value: \"bar\"}}\n\texecutionGetFunc := makeExecutionWithEnvs(t, existingClosureBytes, &startTime, env)\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetGetCallback(executionGetFunc)\n\n\texCreateFunc := func(ctx context.Context, input models.Execution) error {\n\t\tassert.Equal(t, \"recovered\", input.Name)\n\t\tassert.Equal(t, \"domain\", input.Domain)\n\t\tassert.Equal(t, \"project\", input.Project)\n\t\tassert.Equal(t, uint(8), input.SourceExecutionID)\n\t\tvar spec admin.ExecutionSpec\n\t\terr := proto.Unmarshal(input.Spec, &spec)\n\t\tassert.Nil(t, err)\n\t\tassert.Equal(t, admin.ExecutionMetadata_RECOVERED, spec.Metadata.Mode)\n\t\tassert.Equal(t, int32(admin.ExecutionMetadata_RECOVERED), input.Mode)\n\t\tassert.NotNil(t, spec.GetEnvs())\n\t\tassert.Equal(t, spec.GetEnvs().GetValues()[0].Key, env[0].Key)\n\t\tassert.Equal(t, spec.GetEnvs().GetValues()[0].Value, env[0].Value)\n\t\treturn nil\n\t}\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetCreateCallback(exCreateFunc)\n\n\t// Issue request.\n\tresponse, err := execManager.RecoverExecution(context.Background(), admin.ExecutionRecoverRequest{\n\t\tId: &core.WorkflowExecutionIdentifier{\n\t\t\tProject: \"project\",\n\t\t\tDomain:  \"domain\",\n\t\t\tName:    \"name\",\n\t\t},\n\t\tName: \"recovered\",\n\t}, requestedAt)\n\n\t// And verify response.\n\tassert.Nil(t, err)\n\n\texpectedResponse := &admin.ExecutionCreateResponse{\n\t\tId: &core.WorkflowExecutionIdentifier{\n\t\t\tProject: \"project\",\n\t\t\tDomain:  \"domain\",\n\t\t\tName:    \"recovered\",\n\t\t},\n\t}\n\tassert.True(t, proto.Equal(expectedResponse, response))\n}\n\nfunc TestCreateWorkflowEvent(t *testing.T) {\n\trepository := repositoryMocks.NewMockRepository()\n\tstartTime := time.Now()\n\tstartTimeProto, _ := ptypes.TimestampProto(startTime)\n\tduration := time.Second\n\tdurationProto := ptypes.DurationProto(duration)\n\texistingClosure := admin.ExecutionClosure{\n\t\tPhase:     core.WorkflowExecution_RUNNING,\n\t\tStartedAt: startTimeProto,\n\t}\n\texistingClosureBytes, _ := proto.Marshal(&existingClosure)\n\texecutionGetFunc := makeExecutionGetFunc(t, existingClosureBytes, &startTime)\n\texecutionError := core.ExecutionError{\n\t\tCode:    \"foo\",\n\t\tMessage: \"bar baz\",\n\t}\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetGetCallback(executionGetFunc)\n\tendTime := startTime.Add(duration)\n\toccurredAt, _ := ptypes.TimestampProto(endTime)\n\tclosure := admin.ExecutionClosure{\n\t\tPhase:     core.WorkflowExecution_FAILED,\n\t\tStartedAt: startTimeProto,\n\t\tUpdatedAt: occurredAt,\n\t\tDuration:  durationProto,\n\t\tOutputResult: &admin.ExecutionClosure_Error{\n\t\t\tError: &executionError,\n\t\t},\n\t}\n\tclosureBytes, _ := proto.Marshal(&closure)\n\tupdateExecutionFunc := func(\n\t\tcontext context.Context, execution models.Execution) error {\n\n\t\tassert.Equal(t, \"project\", execution.Project)\n\t\tassert.Equal(t, \"domain\", execution.Domain)\n\t\tassert.Equal(t, \"name\", execution.Name)\n\t\tassert.Equal(t, uint(1), execution.LaunchPlanID)\n\t\tassert.Equal(t, uint(2), execution.WorkflowID)\n\t\tassert.Equal(t, core.WorkflowExecution_FAILED.String(), execution.Phase)\n\t\tassert.Equal(t, closureBytes, execution.Closure)\n\t\tassert.Equal(t, getExpectedSpecBytes(), execution.Spec)\n\t\tassert.Equal(t, startTime, *execution.StartedAt)\n\t\tassert.Equal(t, duration, execution.Duration)\n\t\treturn nil\n\t}\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetUpdateCallback(updateExecutionFunc)\n\trequest := admin.WorkflowExecutionEventRequest{\n\t\tRequestId: \"1\",\n\t\tEvent: &event.WorkflowExecutionEvent{\n\t\t\tExecutionId: &executionIdentifier,\n\t\t\tOccurredAt:  occurredAt,\n\t\t\tPhase:       core.WorkflowExecution_FAILED,\n\t\t\tOutputResult: &event.WorkflowExecutionEvent_Error{\n\t\t\t\tError: &executionError,\n\t\t\t},\n\t\t\tProducerId: testCluster,\n\t\t},\n\t}\n\tmockDbEventWriter := &eventWriterMocks.WorkflowExecutionEventWriter{}\n\tmockDbEventWriter.On(\"Write\", request)\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &defaultTestExecutor)\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, &mockPublisher, &mockPublisher, mockDbEventWriter)\n\tresp, err := execManager.CreateWorkflowEvent(context.Background(), request)\n\tassert.Nil(t, err)\n\tassert.NotNil(t, resp)\n}\n\nfunc TestCreateWorkflowEvent_TerminalState(t *testing.T) {\n\trepository := repositoryMocks.NewMockRepository()\n\texecutionGetFunc := func(ctx context.Context, input interfaces.Identifier) (models.Execution, error) {\n\t\treturn models.Execution{\n\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\tProject: \"project\",\n\t\t\t\tDomain:  \"domain\",\n\t\t\t\tName:    \"name\",\n\t\t\t},\n\t\t\tBaseModel: models.BaseModel{\n\t\t\t\tID: uint(8),\n\t\t\t},\n\t\t\tSpec:  getExpectedSpecBytes(),\n\t\t\tPhase: core.WorkflowExecution_FAILED.String(),\n\t\t}, nil\n\t}\n\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetGetCallback(executionGetFunc)\n\tupdateExecutionFunc := func(context context.Context, execution models.Execution) error {\n\t\treturn nil\n\t}\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetUpdateCallback(updateExecutionFunc)\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &defaultTestExecutor)\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\n\tresp, err := execManager.CreateWorkflowEvent(context.Background(), admin.WorkflowExecutionEventRequest{\n\t\tRequestId: \"1\",\n\t\tEvent: &event.WorkflowExecutionEvent{\n\t\t\tExecutionId: &executionIdentifier,\n\t\t\tPhase:       core.WorkflowExecution_SUCCEEDED,\n\t\t},\n\t})\n\tassert.Nil(t, resp)\n\tassert.NotNil(t, err)\n\tadminError := err.(flyteAdminErrors.FlyteAdminError)\n\tassert.Equal(t, adminError.Code(), codes.FailedPrecondition)\n\tdetails, ok := adminError.GRPCStatus().Details()[0].(*admin.EventFailureReason)\n\tassert.True(t, ok)\n\t_, ok = details.GetReason().(*admin.EventFailureReason_AlreadyInTerminalState)\n\tassert.True(t, ok)\n}\n\nfunc TestCreateWorkflowEvent_NoRunningToQueued(t *testing.T) {\n\trepository := repositoryMocks.NewMockRepository()\n\texecutionGetFunc := func(ctx context.Context, input interfaces.Identifier) (models.Execution, error) {\n\t\treturn models.Execution{\n\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\tProject: \"project\",\n\t\t\t\tDomain:  \"domain\",\n\t\t\t\tName:    \"name\",\n\t\t\t},\n\t\t\tSpec:  getExpectedSpecBytes(),\n\t\t\tPhase: core.WorkflowExecution_RUNNING.String(),\n\t\t}, nil\n\t}\n\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetGetCallback(executionGetFunc)\n\tupdateExecutionFunc := func(context context.Context, execution models.Execution) error {\n\t\treturn nil\n\t}\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetUpdateCallback(updateExecutionFunc)\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &defaultTestExecutor)\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\n\tresp, err := execManager.CreateWorkflowEvent(context.Background(), admin.WorkflowExecutionEventRequest{\n\t\tRequestId: \"1\",\n\t\tEvent: &event.WorkflowExecutionEvent{\n\t\t\tExecutionId: &executionIdentifier,\n\t\t\tPhase:       core.WorkflowExecution_QUEUED,\n\t\t},\n\t})\n\tassert.Nil(t, resp)\n\tassert.NotNil(t, err)\n\tadminError := err.(flyteAdminErrors.FlyteAdminError)\n\tassert.Equal(t, adminError.Code(), codes.FailedPrecondition)\n}\n\nfunc TestCreateWorkflowEvent_CurrentlyAborting(t *testing.T) {\n\trepository := repositoryMocks.NewMockRepository()\n\texecutionGetFunc := func(ctx context.Context, input interfaces.Identifier) (models.Execution, error) {\n\t\treturn models.Execution{\n\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\tProject: \"project\",\n\t\t\t\tDomain:  \"domain\",\n\t\t\t\tName:    \"name\",\n\t\t\t},\n\t\t\tSpec:  getExpectedSpecBytes(),\n\t\t\tPhase: core.WorkflowExecution_ABORTING.String(),\n\t\t}, nil\n\t}\n\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetGetCallback(executionGetFunc)\n\tupdateExecutionFunc := func(context context.Context, execution models.Execution) error {\n\t\treturn nil\n\t}\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetUpdateCallback(updateExecutionFunc)\n\n\treq := admin.WorkflowExecutionEventRequest{\n\t\tRequestId: \"1\",\n\t\tEvent: &event.WorkflowExecutionEvent{\n\t\t\tExecutionId: &executionIdentifier,\n\t\t\tPhase:       core.WorkflowExecution_ABORTED,\n\t\t\tOccurredAt:  timestamppb.New(time.Now()),\n\t\t},\n\t}\n\n\tmockDbEventWriter := &eventWriterMocks.WorkflowExecutionEventWriter{}\n\tmockDbEventWriter.On(\"Write\", req)\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &defaultTestExecutor)\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, &mockPublisher, &mockPublisher, mockDbEventWriter)\n\n\tresp, err := execManager.CreateWorkflowEvent(context.Background(), req)\n\tassert.NotNil(t, resp)\n\tassert.NoError(t, err)\n\n\treq.Event.Phase = core.WorkflowExecution_QUEUED\n\tresp, err = execManager.CreateWorkflowEvent(context.Background(), req)\n\tassert.Nil(t, resp)\n\tassert.NotNil(t, err)\n\tadminError := err.(flyteAdminErrors.FlyteAdminError)\n\tassert.Equal(t, adminError.Code(), codes.FailedPrecondition)\n\n\treq.Event.Phase = core.WorkflowExecution_RUNNING\n\tresp, err = execManager.CreateWorkflowEvent(context.Background(), req)\n\tassert.Nil(t, resp)\n\tassert.NotNil(t, err)\n\tadminError = err.(flyteAdminErrors.FlyteAdminError)\n\tassert.Equal(t, adminError.Code(), codes.FailedPrecondition)\n}\n\nfunc TestCreateWorkflowEvent_StartedRunning(t *testing.T) {\n\trepository := repositoryMocks.NewMockRepository()\n\toccurredAt := time.Now().UTC()\n\toccurredAtProto, _ := ptypes.TimestampProto(occurredAt)\n\texecutionGetFunc := makeExecutionGetFunc(t, closureBytes, nil)\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetGetCallback(executionGetFunc)\n\n\tclosure := admin.ExecutionClosure{\n\t\tPhase:     core.WorkflowExecution_RUNNING,\n\t\tStartedAt: occurredAtProto,\n\t\tUpdatedAt: occurredAtProto,\n\t\tStateChangeDetails: &admin.ExecutionStateChangeDetails{\n\t\t\tState:      admin.ExecutionState_EXECUTION_ACTIVE,\n\t\t\tOccurredAt: testutils.MockCreatedAtProto,\n\t\t},\n\t}\n\tclosureBytes, _ := proto.Marshal(&closure)\n\tupdateExecutionFunc := func(\n\t\tcontext context.Context, execution models.Execution) error {\n\t\tassert.Equal(t, \"project\", execution.Project)\n\t\tassert.Equal(t, \"domain\", execution.Domain)\n\t\tassert.Equal(t, \"name\", execution.Name)\n\t\tassert.Equal(t, uint(1), execution.LaunchPlanID)\n\t\tassert.Equal(t, uint(2), execution.WorkflowID)\n\t\tassert.Equal(t, core.WorkflowExecution_RUNNING.String(), execution.Phase)\n\t\tassert.Equal(t, closureBytes, execution.Closure)\n\t\tassert.Equal(t, getExpectedSpecBytes(), execution.Spec)\n\t\tassert.Equal(t, occurredAt, *execution.StartedAt)\n\t\tassert.Equal(t, time.Duration(0), execution.Duration)\n\t\tassert.Equal(t, occurredAt, *execution.ExecutionUpdatedAt)\n\t\treturn nil\n\t}\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetUpdateCallback(updateExecutionFunc)\n\toccurredAtTimestamp, _ := ptypes.TimestampProto(occurredAt)\n\trequest := admin.WorkflowExecutionEventRequest{\n\t\tRequestId: \"1\",\n\t\tEvent: &event.WorkflowExecutionEvent{\n\t\t\tExecutionId: &executionIdentifier,\n\t\t\tOccurredAt:  occurredAtTimestamp,\n\t\t\tPhase:       core.WorkflowExecution_RUNNING,\n\t\t\tProducerId:  testCluster,\n\t\t},\n\t}\n\tmockDbEventWriter := &eventWriterMocks.WorkflowExecutionEventWriter{}\n\tmockDbEventWriter.On(\"Write\", request)\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &defaultTestExecutor)\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, &mockPublisher, &mockPublisher, mockDbEventWriter)\n\tresp, err := execManager.CreateWorkflowEvent(context.Background(), request)\n\tassert.Nil(t, err)\n\tassert.NotNil(t, resp)\n}\n\nfunc TestCreateWorkflowEvent_DuplicateRunning(t *testing.T) {\n\trepository := repositoryMocks.NewMockRepository()\n\toccurredAt := time.Now().UTC()\n\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetGetCallback(\n\t\tfunc(ctx context.Context, input interfaces.Identifier) (models.Execution, error) {\n\t\t\treturn models.Execution{\n\t\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\t\tProject: \"project\",\n\t\t\t\t\tDomain:  \"domain\",\n\t\t\t\t\tName:    \"name\",\n\t\t\t\t},\n\t\t\t\tBaseModel: models.BaseModel{\n\t\t\t\t\tID: uint(8),\n\t\t\t\t},\n\t\t\t\tSpec:         getExpectedSpecBytes(),\n\t\t\t\tPhase:        core.WorkflowExecution_RUNNING.String(),\n\t\t\t\tClosure:      closureBytes,\n\t\t\t\tLaunchPlanID: uint(1),\n\t\t\t\tWorkflowID:   uint(2),\n\t\t\t\tStartedAt:    &occurredAt,\n\t\t\t}, nil\n\t\t},\n\t)\n\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &defaultTestExecutor)\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\toccurredAtTimestamp, _ := ptypes.TimestampProto(occurredAt)\n\tresp, err := execManager.CreateWorkflowEvent(context.Background(), admin.WorkflowExecutionEventRequest{\n\t\tRequestId: \"1\",\n\t\tEvent: &event.WorkflowExecutionEvent{\n\t\t\tExecutionId: &executionIdentifier,\n\t\t\tOccurredAt:  occurredAtTimestamp,\n\t\t\tPhase:       core.WorkflowExecution_RUNNING,\n\t\t},\n\t})\n\tassert.NotNil(t, err)\n\tadminError := err.(flyteAdminErrors.FlyteAdminError)\n\tassert.Equal(t, adminError.Code(), codes.AlreadyExists)\n\tassert.Nil(t, resp)\n}\n\nfunc TestCreateWorkflowEvent_InvalidPhaseChange(t *testing.T) {\n\trepository := repositoryMocks.NewMockRepository()\n\toccurredAt := time.Now().UTC()\n\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetGetCallback(\n\t\tfunc(ctx context.Context, input interfaces.Identifier) (models.Execution, error) {\n\t\t\treturn models.Execution{\n\t\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\t\tProject: \"project\",\n\t\t\t\t\tDomain:  \"domain\",\n\t\t\t\t\tName:    \"name\",\n\t\t\t\t},\n\t\t\t\tBaseModel: models.BaseModel{\n\t\t\t\t\tID: uint(8),\n\t\t\t\t},\n\t\t\t\tSpec:         getExpectedSpecBytes(),\n\t\t\t\tPhase:        core.WorkflowExecution_SUCCEEDED.String(),\n\t\t\t\tClosure:      closureBytes,\n\t\t\t\tLaunchPlanID: uint(1),\n\t\t\t\tWorkflowID:   uint(2),\n\t\t\t\tStartedAt:    &occurredAt,\n\t\t\t}, nil\n\t\t},\n\t)\n\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &defaultTestExecutor)\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\toccurredAtTimestamp, _ := ptypes.TimestampProto(occurredAt)\n\tresp, err := execManager.CreateWorkflowEvent(context.Background(), admin.WorkflowExecutionEventRequest{\n\t\tRequestId: \"1\",\n\t\tEvent: &event.WorkflowExecutionEvent{\n\t\t\tExecutionId: &executionIdentifier,\n\t\t\tOccurredAt:  occurredAtTimestamp,\n\t\t\tPhase:       core.WorkflowExecution_RUNNING,\n\t\t},\n\t})\n\tassert.NotNil(t, err)\n\tadminError := err.(flyteAdminErrors.FlyteAdminError)\n\tassert.Equal(t, adminError.Code(), codes.FailedPrecondition)\n\tassert.Nil(t, resp)\n\tdetails, ok := adminError.GRPCStatus().Details()[0].(*admin.EventFailureReason)\n\tassert.True(t, ok)\n\t_, ok = details.GetReason().(*admin.EventFailureReason_AlreadyInTerminalState)\n\tassert.True(t, ok)\n}\n\nfunc TestCreateWorkflowEvent_ClusterReassignmentOnQueued(t *testing.T) {\n\trepository := repositoryMocks.NewMockRepository()\n\toccurredAt := time.Now().UTC()\n\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetGetCallback(\n\t\tfunc(ctx context.Context, input interfaces.Identifier) (models.Execution, error) {\n\t\t\treturn models.Execution{\n\t\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\t\tProject: \"project\",\n\t\t\t\t\tDomain:  \"domain\",\n\t\t\t\t\tName:    \"name\",\n\t\t\t\t},\n\t\t\t\tBaseModel: models.BaseModel{\n\t\t\t\t\tID: uint(8),\n\t\t\t\t},\n\t\t\t\tSpec:         getExpectedSpecBytes(),\n\t\t\t\tPhase:        core.WorkflowExecution_UNDEFINED.String(),\n\t\t\t\tClosure:      closureBytes,\n\t\t\t\tLaunchPlanID: uint(1),\n\t\t\t\tWorkflowID:   uint(2),\n\t\t\t\tStartedAt:    &occurredAt,\n\t\t\t}, nil\n\t\t},\n\t)\n\tnewCluster := \"C2\"\n\tupdateExecutionFunc := func(\n\t\tcontext context.Context, execution models.Execution) error {\n\t\tassert.Equal(t, core.WorkflowExecution_QUEUED.String(), execution.Phase)\n\t\tassert.Equal(t, newCluster, execution.Cluster)\n\t\treturn nil\n\t}\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetUpdateCallback(updateExecutionFunc)\n\n\toccurredAtTimestamp, _ := ptypes.TimestampProto(occurredAt)\n\tmockDbEventWriter := &eventWriterMocks.WorkflowExecutionEventWriter{}\n\trequest := admin.WorkflowExecutionEventRequest{\n\t\tRequestId: \"1\",\n\t\tEvent: &event.WorkflowExecutionEvent{\n\t\t\tExecutionId: &executionIdentifier,\n\t\t\tOccurredAt:  occurredAtTimestamp,\n\t\t\tPhase:       core.WorkflowExecution_QUEUED,\n\t\t\tProducerId:  newCluster,\n\t\t},\n\t}\n\tmockDbEventWriter.On(\"Write\", request)\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &defaultTestExecutor)\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, &mockPublisher, &mockPublisher, mockDbEventWriter)\n\n\tresp, err := execManager.CreateWorkflowEvent(context.Background(), request)\n\tassert.Nil(t, err)\n\tassert.NotNil(t, resp)\n}\n\nfunc TestCreateWorkflowEvent_InvalidEvent(t *testing.T) {\n\trepository := repositoryMocks.NewMockRepository()\n\tstartTime := time.Now()\n\texecutionGetFunc := makeExecutionGetFunc(t, closureBytes, &startTime)\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetGetCallback(executionGetFunc)\n\texecutionError := core.ExecutionError{\n\t\tCode:    \"foo\",\n\t\tMessage: \"bar baz\",\n\t}\n\tupdateExecutionFunc := func(\n\t\tcontext context.Context, execution models.Execution) error {\n\t\treturn nil\n\t}\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetUpdateCallback(updateExecutionFunc)\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &defaultTestExecutor)\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\tresp, err := execManager.CreateWorkflowEvent(context.Background(), admin.WorkflowExecutionEventRequest{\n\t\tRequestId: \"1\",\n\t\tEvent: &event.WorkflowExecutionEvent{\n\t\t\tExecutionId: &executionIdentifier,\n\t\t\tPhase:       core.WorkflowExecution_FAILED,\n\t\t\tOutputResult: &event.WorkflowExecutionEvent_Error{\n\t\t\t\tError: &executionError,\n\t\t\t},\n\t\t},\n\t})\n\tassert.NotNil(t, err)\n\tassert.Nil(t, resp)\n}\n\nfunc TestCreateWorkflowEvent_UpdateModelError(t *testing.T) {\n\trepository := repositoryMocks.NewMockRepository()\n\tstartTime := time.Now()\n\texecutionGetFunc := makeExecutionGetFunc(t, []byte(\"invalid serialized closure\"), &startTime)\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetGetCallback(executionGetFunc)\n\tduration := time.Second\n\tendTime := startTime.Add(duration)\n\toccurredAt, _ := ptypes.TimestampProto(endTime)\n\texecutionError := core.ExecutionError{\n\t\tCode:    \"foo\",\n\t\tMessage: \"bar baz\",\n\t}\n\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &defaultTestExecutor)\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\tresp, err := execManager.CreateWorkflowEvent(context.Background(), admin.WorkflowExecutionEventRequest{\n\t\tRequestId: \"1\",\n\t\tEvent: &event.WorkflowExecutionEvent{\n\t\t\tExecutionId: &executionIdentifier,\n\t\t\tOccurredAt:  occurredAt,\n\t\t\tPhase:       core.WorkflowExecution_FAILED,\n\t\t\tOutputResult: &event.WorkflowExecutionEvent_Error{\n\t\t\t\tError: &executionError,\n\t\t\t},\n\t\t\tProducerId: testCluster,\n\t\t},\n\t})\n\tassert.Nil(t, resp)\n\tassert.Equal(t, codes.Internal, err.(flyteAdminErrors.FlyteAdminError).Code())\n}\n\nfunc TestCreateWorkflowEvent_DatabaseGetError(t *testing.T) {\n\trepository := repositoryMocks.NewMockRepository()\n\tstartTime := time.Now()\n\n\texpectedErr := errors.New(\"expected error\")\n\texecutionGetFunc := func(ctx context.Context, input interfaces.Identifier) (models.Execution, error) {\n\t\treturn models.Execution{}, expectedErr\n\t}\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetGetCallback(executionGetFunc)\n\tduration := time.Second\n\tendTime := startTime.Add(duration)\n\toccurredAt, _ := ptypes.TimestampProto(endTime)\n\texecutionError := core.ExecutionError{\n\t\tCode:    \"foo\",\n\t\tMessage: \"bar baz\",\n\t}\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &defaultTestExecutor)\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\tresp, err := execManager.CreateWorkflowEvent(context.Background(), admin.WorkflowExecutionEventRequest{\n\t\tRequestId: \"1\",\n\t\tEvent: &event.WorkflowExecutionEvent{\n\t\t\tExecutionId: &executionIdentifier,\n\t\t\tOccurredAt:  occurredAt,\n\t\t\tPhase:       core.WorkflowExecution_FAILED,\n\t\t\tOutputResult: &event.WorkflowExecutionEvent_Error{\n\t\t\t\tError: &executionError,\n\t\t\t},\n\t\t},\n\t})\n\tassert.Nil(t, resp)\n\tassert.EqualError(t, expectedErr, err.Error())\n}\n\nfunc TestCreateWorkflowEvent_DatabaseUpdateError(t *testing.T) {\n\trepository := repositoryMocks.NewMockRepository()\n\tstartTime := time.Now()\n\texecutionGetFunc := makeExecutionGetFunc(t, closureBytes, &startTime)\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetGetCallback(executionGetFunc)\n\tduration := time.Second\n\tendTime := startTime.Add(duration)\n\toccurredAt, _ := ptypes.TimestampProto(endTime)\n\texecutionError := core.ExecutionError{\n\t\tCode:    \"foo\",\n\t\tMessage: \"bar baz\",\n\t}\n\texpectedErr := errors.New(\"expected error\")\n\tupdateExecutionFunc := func(\n\t\tcontext context.Context, execution models.Execution) error {\n\t\treturn expectedErr\n\t}\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetUpdateCallback(updateExecutionFunc)\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &defaultTestExecutor)\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\tresp, err := execManager.CreateWorkflowEvent(context.Background(), admin.WorkflowExecutionEventRequest{\n\t\tRequestId: \"1\",\n\t\tEvent: &event.WorkflowExecutionEvent{\n\t\t\tExecutionId: &executionIdentifier,\n\t\t\tOccurredAt:  occurredAt,\n\t\t\tPhase:       core.WorkflowExecution_FAILED,\n\t\t\tOutputResult: &event.WorkflowExecutionEvent_Error{\n\t\t\t\tError: &executionError,\n\t\t\t},\n\t\t\tProducerId: testCluster,\n\t\t},\n\t})\n\tassert.Nil(t, resp)\n\tassert.EqualError(t, expectedErr, err.Error())\n}\n\nfunc TestCreateWorkflowEvent_IncompatibleCluster(t *testing.T) {\n\trepository := repositoryMocks.NewMockRepository()\n\toccurredAt := time.Now().UTC()\n\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetGetCallback(\n\t\tfunc(ctx context.Context, input interfaces.Identifier) (models.Execution, error) {\n\t\t\treturn models.Execution{\n\t\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\t\tProject: \"project\",\n\t\t\t\t\tDomain:  \"domain\",\n\t\t\t\t\tName:    \"name\",\n\t\t\t\t},\n\t\t\t\tBaseModel: models.BaseModel{\n\t\t\t\t\tID: uint(8),\n\t\t\t\t},\n\t\t\t\tSpec:         getExpectedSpecBytes(),\n\t\t\t\tPhase:        core.WorkflowExecution_RUNNING.String(),\n\t\t\t\tClosure:      closureBytes,\n\t\t\t\tLaunchPlanID: uint(1),\n\t\t\t\tWorkflowID:   uint(2),\n\t\t\t\tStartedAt:    &occurredAt,\n\t\t\t\tCluster:      testCluster,\n\t\t\t}, nil\n\t\t},\n\t)\n\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &defaultTestExecutor)\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\toccurredAtTimestamp, _ := ptypes.TimestampProto(occurredAt)\n\tresp, err := execManager.CreateWorkflowEvent(context.Background(), admin.WorkflowExecutionEventRequest{\n\t\tRequestId: \"1\",\n\t\tEvent: &event.WorkflowExecutionEvent{\n\t\t\tExecutionId: &executionIdentifier,\n\t\t\tOccurredAt:  occurredAtTimestamp,\n\t\t\tPhase:       core.WorkflowExecution_ABORTING,\n\t\t\tProducerId:  \"C2\",\n\t\t},\n\t})\n\tassert.NotNil(t, err)\n\tadminError := err.(flyteAdminErrors.FlyteAdminError)\n\tassert.Equal(t, adminError.Code(), codes.FailedPrecondition)\n\ts, ok := status.FromError(err)\n\tassert.True(t, ok)\n\tvar seenIncompatibleClusterErr bool\n\tfor _, detail := range s.Details() {\n\t\tfailureReason, ok := detail.(*admin.EventFailureReason)\n\t\tif ok {\n\t\t\tif failureReason.GetIncompatibleCluster() != nil {\n\t\t\t\tseenIncompatibleClusterErr = true\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t}\n\tassert.True(t, seenIncompatibleClusterErr)\n\tassert.Nil(t, resp)\n}\n\nfunc TestGetExecution(t *testing.T) {\n\trepository := repositoryMocks.NewMockRepository()\n\tstartedAt := time.Date(2018, 8, 30, 0, 0, 0, 0, time.UTC)\n\texecutionGetFunc := func(ctx context.Context, input interfaces.Identifier) (models.Execution, error) {\n\t\tassert.Equal(t, \"project\", input.Project)\n\t\tassert.Equal(t, \"domain\", input.Domain)\n\t\tassert.Equal(t, \"name\", input.Name)\n\t\treturn models.Execution{\n\t\t\tBaseModel: models.BaseModel{\n\t\t\t\tCreatedAt: testutils.MockCreatedAtValue,\n\t\t\t},\n\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\tProject: \"project\",\n\t\t\t\tDomain:  \"domain\",\n\t\t\t\tName:    \"name\",\n\t\t\t},\n\t\t\tSpec:         getExpectedSpecBytes(),\n\t\t\tPhase:        phase,\n\t\t\tClosure:      closureBytes,\n\t\t\tLaunchPlanID: uint(1),\n\t\t\tWorkflowID:   uint(2),\n\t\t\tStartedAt:    &startedAt,\n\t\t\t// TODO: Input uri\n\t\t}, nil\n\t}\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetGetCallback(executionGetFunc)\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &defaultTestExecutor)\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\texecution, err := execManager.GetExecution(context.Background(), admin.WorkflowExecutionGetRequest{\n\t\tId: &executionIdentifier,\n\t})\n\tassert.NoError(t, err)\n\tassert.True(t, proto.Equal(&executionIdentifier, execution.Id))\n\tassert.True(t, proto.Equal(getExpectedSpec(), execution.Spec))\n\tassert.True(t, proto.Equal(&closure, execution.Closure))\n}\n\nfunc TestGetExecution_DatabaseError(t *testing.T) {\n\trepository := repositoryMocks.NewMockRepository()\n\texpectedErr := errors.New(\"expected error\")\n\n\texecutionGetFunc := func(ctx context.Context, input interfaces.Identifier) (models.Execution, error) {\n\t\tassert.Equal(t, \"project\", input.Project)\n\t\tassert.Equal(t, \"domain\", input.Domain)\n\t\tassert.Equal(t, \"name\", input.Name)\n\t\treturn models.Execution{}, expectedErr\n\t}\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetGetCallback(executionGetFunc)\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &defaultTestExecutor)\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\texecution, err := execManager.GetExecution(context.Background(), admin.WorkflowExecutionGetRequest{\n\t\tId: &executionIdentifier,\n\t})\n\tassert.Nil(t, execution)\n\tassert.Equal(t, expectedErr, err)\n}\n\nfunc TestGetExecution_TransformerError(t *testing.T) {\n\trepository := repositoryMocks.NewMockRepository()\n\tstartedAt := time.Date(2018, 8, 30, 0, 0, 0, 0, time.UTC)\n\texecutionGetFunc := func(ctx context.Context, input interfaces.Identifier) (models.Execution, error) {\n\t\tassert.Equal(t, \"project\", input.Project)\n\t\tassert.Equal(t, \"domain\", input.Domain)\n\t\tassert.Equal(t, \"name\", input.Name)\n\t\treturn models.Execution{\n\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\tProject: \"project\",\n\t\t\t\tDomain:  \"domain\",\n\t\t\t\tName:    \"name\",\n\t\t\t},\n\t\t\tSpec:         []byte(\"invalid spec\"),\n\t\t\tPhase:        phase,\n\t\t\tClosure:      closureBytes,\n\t\t\tLaunchPlanID: uint(1),\n\t\t\tWorkflowID:   uint(2),\n\t\t\tStartedAt:    &startedAt,\n\t\t}, nil\n\t}\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetGetCallback(executionGetFunc)\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &defaultTestExecutor)\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\texecution, err := execManager.GetExecution(context.Background(), admin.WorkflowExecutionGetRequest{\n\t\tId: &executionIdentifier,\n\t})\n\tassert.Nil(t, execution)\n\tassert.Equal(t, codes.Internal, err.(flyteAdminErrors.FlyteAdminError).Code())\n}\n\nfunc TestUpdateExecution(t *testing.T) {\n\tt.Run(\"invalid execution identifier\", func(t *testing.T) {\n\t\trepository := repositoryMocks.NewMockRepository()\n\t\tr := plugins.NewRegistry()\n\t\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &defaultTestExecutor)\n\t\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\t\t_, err := execManager.UpdateExecution(context.Background(), admin.ExecutionUpdateRequest{\n\t\t\tId: &core.WorkflowExecutionIdentifier{\n\t\t\t\tProject: \"project\",\n\t\t\t\tDomain:  \"domain\",\n\t\t\t},\n\t\t}, time.Now())\n\t\tassert.Error(t, err)\n\t})\n\n\tt.Run(\"empty status passed\", func(t *testing.T) {\n\t\trepository := repositoryMocks.NewMockRepository()\n\t\tupdateExecFuncCalled := false\n\t\tupdateExecFunc := func(ctx context.Context, execModel models.Execution) error {\n\t\t\tstateInt := int32(admin.ExecutionState_EXECUTION_ACTIVE)\n\t\t\tassert.Equal(t, stateInt, *execModel.State)\n\t\t\tupdateExecFuncCalled = true\n\t\t\treturn nil\n\t\t}\n\t\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetUpdateCallback(updateExecFunc)\n\t\tr := plugins.NewRegistry()\n\t\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &defaultTestExecutor)\n\t\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\t\tupdateResponse, err := execManager.UpdateExecution(context.Background(), admin.ExecutionUpdateRequest{\n\t\t\tId: &executionIdentifier,\n\t\t}, time.Now())\n\t\tassert.NoError(t, err)\n\t\tassert.NotNil(t, updateResponse)\n\t\tassert.True(t, updateExecFuncCalled)\n\t})\n\n\tt.Run(\"archive status passed\", func(t *testing.T) {\n\t\trepository := repositoryMocks.NewMockRepository()\n\t\tupdateExecFuncCalled := false\n\t\tupdateExecFunc := func(ctx context.Context, execModel models.Execution) error {\n\t\t\tstateInt := int32(admin.ExecutionState_EXECUTION_ARCHIVED)\n\t\t\tassert.Equal(t, stateInt, *execModel.State)\n\t\t\tupdateExecFuncCalled = true\n\t\t\treturn nil\n\t\t}\n\t\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetUpdateCallback(updateExecFunc)\n\t\tr := plugins.NewRegistry()\n\t\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &defaultTestExecutor)\n\t\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\t\tupdateResponse, err := execManager.UpdateExecution(context.Background(), admin.ExecutionUpdateRequest{\n\t\t\tId:    &executionIdentifier,\n\t\t\tState: admin.ExecutionState_EXECUTION_ARCHIVED,\n\t\t}, time.Now())\n\t\tassert.NoError(t, err)\n\t\tassert.NotNil(t, updateResponse)\n\t\tassert.True(t, updateExecFuncCalled)\n\t})\n\n\tt.Run(\"update error\", func(t *testing.T) {\n\t\trepository := repositoryMocks.NewMockRepository()\n\t\tupdateExecFunc := func(ctx context.Context, execModel models.Execution) error {\n\t\t\treturn fmt.Errorf(\"some db error\")\n\t\t}\n\t\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetUpdateCallback(updateExecFunc)\n\t\tr := plugins.NewRegistry()\n\t\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &defaultTestExecutor)\n\t\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\t\t_, err := execManager.UpdateExecution(context.Background(), admin.ExecutionUpdateRequest{\n\t\t\tId:    &executionIdentifier,\n\t\t\tState: admin.ExecutionState_EXECUTION_ARCHIVED,\n\t\t}, time.Now())\n\t\tassert.Error(t, err)\n\t\tassert.Equal(t, \"some db error\", err.Error())\n\t})\n\n\tt.Run(\"get execution error\", func(t *testing.T) {\n\t\trepository := repositoryMocks.NewMockRepository()\n\t\tgetExecFunc := func(ctx context.Context, input interfaces.Identifier) (models.Execution, error) {\n\t\t\treturn models.Execution{}, fmt.Errorf(\"some db error\")\n\t\t}\n\t\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetGetCallback(getExecFunc)\n\t\tr := plugins.NewRegistry()\n\t\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &defaultTestExecutor)\n\t\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\t\t_, err := execManager.UpdateExecution(context.Background(), admin.ExecutionUpdateRequest{\n\t\t\tId:    &executionIdentifier,\n\t\t\tState: admin.ExecutionState_EXECUTION_ARCHIVED,\n\t\t}, time.Now())\n\t\tassert.Error(t, err)\n\t\tassert.Equal(t, \"some db error\", err.Error())\n\t})\n}\n\nfunc TestListExecutions(t *testing.T) {\n\trepository := repositoryMocks.NewMockRepository()\n\texecutionListFunc := func(\n\t\tctx context.Context, input interfaces.ListResourceInput) (interfaces.ExecutionCollectionOutput, error) {\n\t\tvar projectFilter, domainFilter, nameFilter bool\n\t\tfor _, filter := range input.InlineFilters {\n\t\t\tassert.Equal(t, common.Execution, filter.GetEntity())\n\t\t\tqueryExpr, _ := filter.GetGormQueryExpr()\n\t\t\tif queryExpr.Args == projectValue && queryExpr.Query == \"execution_project = ?\" {\n\t\t\t\tprojectFilter = true\n\t\t\t}\n\t\t\tif queryExpr.Args == domainValue && queryExpr.Query == \"execution_domain = ?\" {\n\t\t\t\tdomainFilter = true\n\t\t\t}\n\t\t\tif queryExpr.Args == nameValue && queryExpr.Query == \"execution_name = ?\" {\n\t\t\t\tnameFilter = true\n\t\t\t}\n\t\t}\n\t\tassert.True(t, projectFilter, \"Missing project equality filter\")\n\t\tassert.True(t, domainFilter, \"Missing domain equality filter\")\n\t\tassert.False(t, nameFilter, \"Included name equality filter\")\n\t\tassert.Equal(t, limit, input.Limit)\n\t\tassert.Equal(t, \"domain asc\", input.SortParameter.GetGormOrderExpr())\n\t\tassert.Equal(t, 2, input.Offset)\n\t\tassert.EqualValues(t, map[common.Entity]bool{\n\t\t\tcommon.Execution: true,\n\t\t}, input.JoinTableEntities)\n\t\treturn interfaces.ExecutionCollectionOutput{\n\t\t\tExecutions: []models.Execution{\n\t\t\t\t{\n\t\t\t\t\tBaseModel: models.BaseModel{\n\t\t\t\t\t\tCreatedAt: testutils.MockCreatedAtValue,\n\t\t\t\t\t},\n\t\t\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\t\t\tProject: projectValue,\n\t\t\t\t\t\tDomain:  domainValue,\n\t\t\t\t\t\tName:    \"my awesome execution\",\n\t\t\t\t\t},\n\t\t\t\t\tSpec:    getExpectedSpecBytes(),\n\t\t\t\t\tClosure: closureBytes,\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\tBaseModel: models.BaseModel{\n\t\t\t\t\t\tCreatedAt: testutils.MockCreatedAtValue,\n\t\t\t\t\t},\n\t\t\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\t\t\tProject: projectValue,\n\t\t\t\t\t\tDomain:  domainValue,\n\t\t\t\t\t\tName:    \"my other execution\",\n\t\t\t\t\t},\n\t\t\t\t\tPhase:   core.WorkflowExecution_SUCCEEDED.String(),\n\t\t\t\t\tSpec:    getExpectedSpecBytes(),\n\t\t\t\t\tClosure: closureBytes,\n\t\t\t\t},\n\t\t\t},\n\t\t}, nil\n\t}\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetListCallback(executionListFunc)\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &defaultTestExecutor)\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\n\texecutionList, err := execManager.ListExecutions(context.Background(), admin.ResourceListRequest{\n\t\tId: &admin.NamedEntityIdentifier{\n\t\t\tProject: projectValue,\n\t\t\tDomain:  domainValue,\n\t\t},\n\t\tLimit: limit,\n\t\tSortBy: &admin.Sort{\n\t\t\tDirection: admin.Sort_ASCENDING,\n\t\t\tKey:       \"domain\",\n\t\t},\n\t\tToken: \"2\",\n\t})\n\tassert.NoError(t, err)\n\tassert.NotNil(t, executionList)\n\tassert.Len(t, executionList.Executions, 2)\n\n\tfor idx, execution := range executionList.Executions {\n\t\tassert.Equal(t, projectValue, execution.Id.Project)\n\t\tassert.Equal(t, domainValue, execution.Id.Domain)\n\t\tif idx == 0 {\n\t\t\tassert.Equal(t, \"my awesome execution\", execution.Id.Name)\n\t\t}\n\t\tassert.True(t, proto.Equal(getExpectedSpec(), execution.Spec))\n\t\tassert.True(t, proto.Equal(&closure, execution.Closure))\n\t}\n\tassert.Empty(t, executionList.Token)\n}\n\nfunc TestListExecutions_MissingParameters(t *testing.T) {\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &defaultTestExecutor)\n\texecManager := NewExecutionManager(repositoryMocks.NewMockRepository(), r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\t_, err := execManager.ListExecutions(context.Background(), admin.ResourceListRequest{\n\t\tId: &admin.NamedEntityIdentifier{\n\t\t\tDomain: domainValue,\n\t\t},\n\t\tLimit: limit,\n\t})\n\tassert.Error(t, err)\n\tassert.Equal(t, codes.InvalidArgument, err.(flyteAdminErrors.FlyteAdminError).Code())\n\n\t_, err = execManager.ListExecutions(context.Background(), admin.ResourceListRequest{\n\t\tId: &admin.NamedEntityIdentifier{\n\t\t\tProject: projectValue,\n\t\t},\n\t\tLimit: limit,\n\t})\n\tassert.Error(t, err)\n\tassert.Equal(t, codes.InvalidArgument, err.(flyteAdminErrors.FlyteAdminError).Code())\n\n\t_, err = execManager.ListExecutions(context.Background(), admin.ResourceListRequest{\n\t\tId: &admin.NamedEntityIdentifier{\n\t\t\tProject: projectValue,\n\t\t\tDomain:  domainValue,\n\t\t},\n\t})\n\tassert.Error(t, err)\n\tassert.Equal(t, codes.InvalidArgument, err.(flyteAdminErrors.FlyteAdminError).Code())\n}\n\nfunc TestListExecutions_DatabaseError(t *testing.T) {\n\trepository := repositoryMocks.NewMockRepository()\n\texpectedErr := errors.New(\"expected error\")\n\texecutionListFunc := func(\n\t\tctx context.Context, input interfaces.ListResourceInput) (interfaces.ExecutionCollectionOutput, error) {\n\t\treturn interfaces.ExecutionCollectionOutput{}, expectedErr\n\t}\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetListCallback(executionListFunc)\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &defaultTestExecutor)\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\t_, err := execManager.ListExecutions(context.Background(), admin.ResourceListRequest{\n\t\tId: &admin.NamedEntityIdentifier{\n\t\t\tProject: projectValue,\n\t\t\tDomain:  domainValue,\n\t\t\tName:    nameValue,\n\t\t},\n\t\tLimit: limit,\n\t})\n\tassert.EqualError(t, err, expectedErr.Error())\n}\n\nfunc TestListExecutions_TransformerError(t *testing.T) {\n\trepository := repositoryMocks.NewMockRepository()\n\texecutionListFunc := func(\n\t\tctx context.Context, input interfaces.ListResourceInput) (interfaces.ExecutionCollectionOutput, error) {\n\t\treturn interfaces.ExecutionCollectionOutput{\n\t\t\tExecutions: []models.Execution{\n\t\t\t\t{\n\t\t\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\t\t\tProject: projectValue,\n\t\t\t\t\t\tDomain:  domainValue,\n\t\t\t\t\t\tName:    \"my awesome execution\",\n\t\t\t\t\t},\n\t\t\t\t\tSpec:    []byte(\"I am invalid\"),\n\t\t\t\t\tClosure: closureBytes,\n\t\t\t\t},\n\t\t\t},\n\t\t}, nil\n\t}\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetListCallback(executionListFunc)\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &defaultTestExecutor)\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\n\texecutionList, err := execManager.ListExecutions(context.Background(), admin.ResourceListRequest{\n\t\tId: &admin.NamedEntityIdentifier{\n\t\t\tProject: projectValue,\n\t\t\tDomain:  domainValue,\n\t\t},\n\t\tLimit: limit,\n\t})\n\tassert.EqualError(t, err, \"failed to unmarshal spec\")\n\tassert.Nil(t, executionList)\n}\n\nfunc TestExecutionManager_PublishNotifications(t *testing.T) {\n\trepository := repositoryMocks.NewMockRepository()\n\tqueue := executions.NewQueueAllocator(getMockExecutionsConfigProvider(), repository)\n\n\tmockApplicationConfig := runtimeMocks.MockApplicationProvider{}\n\tmockApplicationConfig.SetNotificationsConfig(runtimeInterfaces.NotificationsConfig{\n\t\tNotificationsEmailerConfig: runtimeInterfaces.NotificationsEmailerConfig{\n\t\t\tBody: \"http://example.com/console/projects/%s/domains/%s/executions/%s\",\n\t\t},\n\t})\n\tmockRuntime := runtimeMocks.NewMockConfigurationProvider(\n\t\t&mockApplicationConfig,\n\t\truntimeMocks.NewMockQueueConfigurationProvider(\n\t\t\t[]runtimeInterfaces.ExecutionQueue{}, []runtimeInterfaces.WorkflowConfig{}),\n\t\tnil, nil, nil, nil)\n\n\tvar myExecManager = &ExecutionManager{\n\t\tdb:                 repository,\n\t\tconfig:             mockRuntime,\n\t\tstorageClient:      getMockStorageForExecTest(context.Background()),\n\t\tqueueAllocator:     queue,\n\t\t_clock:             clock.New(),\n\t\tsystemMetrics:      newExecutionSystemMetrics(mockScope.NewTestScope()),\n\t\tnotificationClient: &mockPublisher,\n\t}\n\t// Currently this doesn't do anything special as the code to invoke pushing to SNS isn't enabled yet.\n\t// This sets up the skeleton for it and appeases the go lint overlords.\n\tworkflowRequest := admin.WorkflowExecutionEventRequest{\n\t\tEvent: &event.WorkflowExecutionEvent{\n\t\t\tPhase: core.WorkflowExecution_FAILED,\n\t\t\tOutputResult: &event.WorkflowExecutionEvent_Error{\n\t\t\t\tError: &core.ExecutionError{\n\t\t\t\t\tCode:    \"CodeBad\",\n\t\t\t\t\tMessage: \"oopsie my bad\",\n\t\t\t\t},\n\t\t\t},\n\t\t\tExecutionId: &executionIdentifier,\n\t\t},\n\t}\n\tvar execClosure = admin.ExecutionClosure{\n\t\tNotifications: testutils.GetExecutionRequest().Spec.GetNotifications().Notifications,\n\t\tWorkflowId: &core.Identifier{\n\t\t\tResourceType: core.ResourceType_WORKFLOW,\n\t\t\tProject:      \"wf_project\",\n\t\t\tDomain:       \"wf_domain\",\n\t\t\tName:         \"wf_name\",\n\t\t\tVersion:      \"wf_version\",\n\t\t},\n\t}\n\tvar extraNotifications = []*admin.Notification{\n\t\t{\n\t\t\tPhases: []core.WorkflowExecution_Phase{\n\t\t\t\tcore.WorkflowExecution_FAILED,\n\t\t\t},\n\t\t\tType: &admin.Notification_PagerDuty{\n\t\t\t\tPagerDuty: &admin.PagerDutyNotification{\n\t\t\t\t\tRecipientsEmail: []string{\n\t\t\t\t\t\t\"pagerduty@example.com\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tPhases: []core.WorkflowExecution_Phase{\n\t\t\t\tcore.WorkflowExecution_SUCCEEDED,\n\t\t\t\tcore.WorkflowExecution_FAILED,\n\t\t\t},\n\t\t\tType: &admin.Notification_Email{\n\t\t\t\tEmail: &admin.EmailNotification{\n\t\t\t\t\tRecipientsEmail: []string{\n\t\t\t\t\t\t\"email@example.com\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t}\n\texecClosure.Notifications = append(execClosure.Notifications, extraNotifications[0])\n\texecClosure.Notifications = append(execClosure.Notifications, extraNotifications[1])\n\n\texecClosureBytes, _ := proto.Marshal(&execClosure)\n\texecutionModel := models.Execution{\n\t\tExecutionKey: models.ExecutionKey{\n\t\t\tProject: \"project\",\n\t\t\tDomain:  \"domain\",\n\t\t\tName:    \"name\",\n\t\t},\n\t\tPhase:        core.WorkflowExecution_FAILED.String(),\n\t\tLaunchPlanID: uint(1),\n\t\tWorkflowID:   uint(2),\n\t\tClosure:      execClosureBytes,\n\t\tSpec:         getExpectedSpecBytes(),\n\t}\n\tassert.Nil(t, myExecManager.publishNotifications(context.Background(), workflowRequest, executionModel))\n}\n\nfunc TestExecutionManager_PublishNotificationsTransformError(t *testing.T) {\n\trepository := repositoryMocks.NewMockRepository()\n\tqueue := executions.NewQueueAllocator(getMockExecutionsConfigProvider(), repository)\n\tvar execManager = &ExecutionManager{\n\t\tdb:                 repository,\n\t\tconfig:             getMockExecutionsConfigProvider(),\n\t\tstorageClient:      getMockStorageForExecTest(context.Background()),\n\t\tqueueAllocator:     queue,\n\t\t_clock:             clock.New(),\n\t\tsystemMetrics:      newExecutionSystemMetrics(mockScope.NewTestScope()),\n\t\tnotificationClient: &mockPublisher,\n\t}\n\n\tworkflowRequest := admin.WorkflowExecutionEventRequest{\n\t\tEvent: &event.WorkflowExecutionEvent{\n\t\t\tPhase: core.WorkflowExecution_FAILED,\n\t\t\tOutputResult: &event.WorkflowExecutionEvent_Error{\n\t\t\t\tError: &core.ExecutionError{\n\t\t\t\t\tCode:    \"CodeBad\",\n\t\t\t\t\tMessage: \"oopsie my bad\",\n\t\t\t\t},\n\t\t\t},\n\t\t\tExecutionId: &executionIdentifier,\n\t\t},\n\t}\n\t// Ensure that an error is thrown when transforming an incorrect models.Execution\n\texecutionModel := models.Execution{\n\t\tExecutionKey: models.ExecutionKey{\n\t\t\tProject: \"project\",\n\t\t\tDomain:  \"domain\",\n\t\t\tName:    \"name\",\n\t\t},\n\t\tPhase:        core.WorkflowExecution_FAILED.String(),\n\t\tLaunchPlanID: uint(1),\n\t\tWorkflowID:   uint(2),\n\t\tSpec:         []byte(\"I am invalid\"),\n\t}\n\tassert.Error(t, execManager.publishNotifications(context.Background(), workflowRequest, executionModel))\n}\n\nfunc TestExecutionManager_TestExecutionManager_PublishNotificationsTransformError(t *testing.T) {\n\trepository := repositoryMocks.NewMockRepository()\n\tqueue := executions.NewQueueAllocator(getMockExecutionsConfigProvider(), repository)\n\tpublishFunc := func(ctx context.Context, key string, msg proto.Message) error {\n\t\treturn errors.New(\"error publishing message\")\n\t}\n\n\tmockPublisher.SetPublishCallback(publishFunc)\n\tmockApplicationConfig := runtimeMocks.MockApplicationProvider{}\n\tmockApplicationConfig.SetNotificationsConfig(runtimeInterfaces.NotificationsConfig{\n\t\tNotificationsEmailerConfig: runtimeInterfaces.NotificationsEmailerConfig{\n\t\t\tBody: \"http://example.com/console/projects/%s/domains/%s/executions/%s\",\n\t\t},\n\t})\n\tmockRuntime := runtimeMocks.NewMockConfigurationProvider(\n\t\t&mockApplicationConfig,\n\t\truntimeMocks.NewMockQueueConfigurationProvider(\n\t\t\t[]runtimeInterfaces.ExecutionQueue{}, []runtimeInterfaces.WorkflowConfig{}),\n\t\tnil, nil, nil, nil)\n\n\tvar myExecManager = &ExecutionManager{\n\t\tdb:                 repository,\n\t\tconfig:             mockRuntime,\n\t\tstorageClient:      getMockStorageForExecTest(context.Background()),\n\t\tqueueAllocator:     queue,\n\t\t_clock:             clock.New(),\n\t\tsystemMetrics:      newExecutionSystemMetrics(mockScope.NewTestScope()),\n\t\tnotificationClient: &mockPublisher,\n\t}\n\t// Currently this doesn't do anything special as the code to invoke pushing to SNS isn't enabled yet.\n\t// This sets up the skeleton for it and appeases the go lint overlords.\n\tworkflowRequest := admin.WorkflowExecutionEventRequest{\n\t\tEvent: &event.WorkflowExecutionEvent{\n\t\t\tPhase: core.WorkflowExecution_FAILED,\n\t\t\tOutputResult: &event.WorkflowExecutionEvent_Error{\n\t\t\t\tError: &core.ExecutionError{\n\t\t\t\t\tCode:    \"CodeBad\",\n\t\t\t\t\tMessage: \"oopsie my bad\",\n\t\t\t\t},\n\t\t\t},\n\t\t\tExecutionId: &executionIdentifier,\n\t\t},\n\t}\n\tvar execClosure = admin.ExecutionClosure{\n\t\tNotifications: testutils.GetExecutionRequest().Spec.GetNotifications().Notifications,\n\t\tWorkflowId: &core.Identifier{\n\t\t\tResourceType: core.ResourceType_WORKFLOW,\n\t\t\tProject:      \"wf_project\",\n\t\t\tDomain:       \"wf_domain\",\n\t\t\tName:         \"wf_name\",\n\t\t\tVersion:      \"wf_version\",\n\t\t},\n\t}\n\texecClosureBytes, _ := proto.Marshal(&execClosure)\n\texecutionModel := models.Execution{\n\t\tExecutionKey: models.ExecutionKey{\n\t\t\tProject: \"project\",\n\t\t\tDomain:  \"domain\",\n\t\t\tName:    \"name\",\n\t\t},\n\t\tPhase:        core.WorkflowExecution_FAILED.String(),\n\t\tLaunchPlanID: uint(1),\n\t\tWorkflowID:   uint(2),\n\t\tClosure:      execClosureBytes,\n\t\tSpec:         getExpectedSpecBytes(),\n\t}\n\tassert.Nil(t, myExecManager.publishNotifications(context.Background(), workflowRequest, executionModel))\n\n}\n\nfunc TestExecutionManager_PublishNotificationsNoPhaseMatch(t *testing.T) {\n\trepository := repositoryMocks.NewMockRepository()\n\tqueue := executions.NewQueueAllocator(getMockExecutionsConfigProvider(), repository)\n\n\tvar myExecManager = &ExecutionManager{\n\t\tdb:                 repository,\n\t\tconfig:             getMockExecutionsConfigProvider(),\n\t\tstorageClient:      getMockStorageForExecTest(context.Background()),\n\t\tqueueAllocator:     queue,\n\t\t_clock:             clock.New(),\n\t\tsystemMetrics:      newExecutionSystemMetrics(mockScope.NewTestScope()),\n\t\tnotificationClient: &mockPublisher,\n\t}\n\t// Currently this doesn't do anything special as the code to invoke pushing to SNS isn't enabled yet.\n\t// This sets up the skeleton for it and appeases the go lint overlords.\n\tworkflowRequest := admin.WorkflowExecutionEventRequest{\n\t\tEvent: &event.WorkflowExecutionEvent{\n\t\t\tPhase: core.WorkflowExecution_SUCCEEDED,\n\t\t\tOutputResult: &event.WorkflowExecutionEvent_OutputUri{\n\t\t\t\tOutputUri: \"somestring\",\n\t\t\t},\n\t\t\tExecutionId: &executionIdentifier,\n\t\t},\n\t}\n\tvar execClosure = admin.ExecutionClosure{\n\t\tNotifications: testutils.GetExecutionRequest().Spec.GetNotifications().Notifications,\n\t}\n\texecClosureBytes, _ := proto.Marshal(&execClosure)\n\texecutionModel := models.Execution{\n\t\tExecutionKey: models.ExecutionKey{\n\t\t\tProject: \"project\",\n\t\t\tDomain:  \"domain\",\n\t\t\tName:    \"name\",\n\t\t},\n\t\tPhase:        core.WorkflowExecution_FAILED.String(),\n\t\tLaunchPlanID: uint(1),\n\t\tWorkflowID:   uint(2),\n\t\tClosure:      execClosureBytes,\n\t}\n\tassert.Nil(t, myExecManager.publishNotifications(context.Background(), workflowRequest, executionModel))\n}\n\nfunc TestTerminateExecution(t *testing.T) {\n\trepository := repositoryMocks.NewMockRepository()\n\tstartTime := time.Now()\n\texecutionGetFunc := makeExecutionGetFunc(t, []byte{}, &startTime)\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetGetCallback(executionGetFunc)\n\n\tabortCause := \"abort cause\"\n\tprincipal := \"principal\"\n\tupdateExecutionFunc := func(\n\t\tcontext context.Context, execution models.Execution) error {\n\t\tassert.Equal(t, \"project\", execution.Project)\n\t\tassert.Equal(t, \"domain\", execution.Domain)\n\t\tassert.Equal(t, \"name\", execution.Name)\n\t\tassert.Equal(t, uint(1), execution.LaunchPlanID)\n\t\tassert.Equal(t, uint(2), execution.WorkflowID)\n\t\tassert.Equal(t, core.WorkflowExecution_ABORTING.String(), execution.Phase)\n\t\tassert.Equal(t, execution.ExecutionCreatedAt, execution.ExecutionUpdatedAt,\n\t\t\t\"an abort call should not change ExecutionUpdatedAt until a corresponding execution event is received\")\n\t\tassert.Equal(t, abortCause, execution.AbortCause)\n\t\tassert.Equal(t, testCluster, execution.Cluster)\n\n\t\tvar unmarshaledClosure admin.ExecutionClosure\n\t\terr := proto.Unmarshal(execution.Closure, &unmarshaledClosure)\n\t\tassert.NoError(t, err)\n\t\tassert.True(t, proto.Equal(&admin.AbortMetadata{\n\t\t\tCause:     abortCause,\n\t\t\tPrincipal: principal,\n\t\t}, unmarshaledClosure.GetAbortMetadata()))\n\t\treturn nil\n\t}\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetUpdateCallback(updateExecutionFunc)\n\n\tmockExecutor := workflowengineMocks.WorkflowExecutor{}\n\tmockExecutor.OnAbortMatch(mock.Anything, mock.MatchedBy(func(data workflowengineInterfaces.AbortData) bool {\n\t\tassert.True(t, proto.Equal(&core.WorkflowExecutionIdentifier{\n\t\t\tProject: \"project\",\n\t\t\tDomain:  \"domain\",\n\t\t\tName:    \"name\",\n\t\t}, data.ExecutionID))\n\t\treturn true\n\t})).Return(nil)\n\tmockExecutor.OnID().Return(\"customMockExecutor\")\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &mockExecutor)\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\n\tidentity, err := auth.NewIdentityContext(\"\", principal, \"\", time.Now(), sets.NewString(), nil, nil)\n\tassert.NoError(t, err)\n\tctx := identity.WithContext(context.Background())\n\tresp, err := execManager.TerminateExecution(ctx, admin.ExecutionTerminateRequest{\n\t\tId: &core.WorkflowExecutionIdentifier{\n\t\t\tProject: \"project\",\n\t\t\tDomain:  \"domain\",\n\t\t\tName:    \"name\",\n\t\t},\n\t\tCause: abortCause,\n\t})\n\n\tassert.Nil(t, err)\n\tassert.NotNil(t, resp)\n}\n\nfunc TestTerminateExecution_PropellerError(t *testing.T) {\n\tvar expectedError = errors.New(\"expected error\")\n\n\tmockExecutor := workflowengineMocks.WorkflowExecutor{}\n\tmockExecutor.OnAbortMatch(mock.Anything, mock.Anything).Return(expectedError)\n\tmockExecutor.OnID().Return(\"customMockExecutor\")\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &mockExecutor)\n\n\tupdateCalled := false\n\trepository := repositoryMocks.NewMockRepository()\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetUpdateCallback(func(\n\t\tcontext context.Context, execution models.Execution) error {\n\t\tupdateCalled = true\n\t\tassert.Equal(t, core.WorkflowExecution_ABORTING.String(), execution.Phase)\n\t\treturn nil\n\t})\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\n\tresp, err := execManager.TerminateExecution(context.Background(), admin.ExecutionTerminateRequest{\n\t\tId: &core.WorkflowExecutionIdentifier{\n\t\t\tProject: \"project\",\n\t\t\tDomain:  \"domain\",\n\t\t\tName:    \"name\",\n\t\t},\n\t\tCause: \"abort cause\",\n\t})\n\tassert.Nil(t, resp)\n\tassert.EqualError(t, err, expectedError.Error())\n\tassert.True(t, updateCalled)\n}\n\nfunc TestTerminateExecution_DatabaseError(t *testing.T) {\n\trepository := repositoryMocks.NewMockRepository()\n\tstartTime := time.Now()\n\texecutionGetFunc := makeExecutionGetFunc(t, []byte{}, &startTime)\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetGetCallback(executionGetFunc)\n\n\tvar expectedError = errors.New(\"expected error\")\n\tupdateExecutionFunc := func(\n\t\tcontext context.Context, execution models.Execution) error {\n\t\treturn expectedError\n\t}\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetUpdateCallback(updateExecutionFunc)\n\tmockExecutor := workflowengineMocks.WorkflowExecutor{}\n\tmockExecutor.OnAbortMatch(mock.Anything, mock.Anything).Return(nil)\n\tmockExecutor.OnID().Return(\"testMockExecutor\")\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &mockExecutor)\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\tresp, err := execManager.TerminateExecution(context.Background(), admin.ExecutionTerminateRequest{\n\t\tId: &core.WorkflowExecutionIdentifier{\n\t\t\tProject: \"project\",\n\t\t\tDomain:  \"domain\",\n\t\t\tName:    \"name\",\n\t\t},\n\t\tCause: \"abort cause\",\n\t})\n\n\tassert.Nil(t, resp)\n\tassert.EqualError(t, err, expectedError.Error())\n}\n\nfunc TestTerminateExecution_AlreadyTerminated(t *testing.T) {\n\tvar expectedError = errors.New(\"expected error\")\n\n\tmockExecutor := workflowengineMocks.WorkflowExecutor{}\n\tmockExecutor.OnAbortMatch(mock.Anything, mock.Anything).Return(expectedError)\n\tmockExecutor.OnID().Return(\"customMockExecutor\")\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &mockExecutor)\n\n\trepository := repositoryMocks.NewMockRepository()\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetGetCallback(\n\t\tfunc(ctx context.Context, input interfaces.Identifier) (models.Execution, error) {\n\t\t\treturn models.Execution{\n\t\t\t\tPhase: core.WorkflowExecution_SUCCEEDED.String(),\n\t\t\t}, nil\n\t\t})\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\tresp, err := execManager.TerminateExecution(context.Background(), admin.ExecutionTerminateRequest{\n\t\tId: &core.WorkflowExecutionIdentifier{\n\t\t\tProject: \"project\",\n\t\t\tDomain:  \"domain\",\n\t\t\tName:    \"name\",\n\t\t},\n\t\tCause: \"abort cause\",\n\t})\n\n\tassert.Nil(t, resp)\n\ts, ok := status.FromError(err)\n\tassert.True(t, ok)\n\tassert.Equal(t, codes.FailedPrecondition, s.Code())\n}\n\nfunc TestGetExecutionData(t *testing.T) {\n\trepository := repositoryMocks.NewMockRepository()\n\tstartedAt := time.Date(2018, 8, 30, 0, 0, 0, 0, time.UTC)\n\tvar closure = admin.ExecutionClosure{\n\t\tPhase: core.WorkflowExecution_RUNNING,\n\t\tOutputResult: &admin.ExecutionClosure_Outputs{\n\t\t\tOutputs: &admin.LiteralMapBlob{\n\t\t\t\tData: &admin.LiteralMapBlob_Uri{\n\t\t\t\t\tUri: outputURI,\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t}\n\tvar closureBytes, _ = proto.Marshal(&closure)\n\n\texecutionGetFunc := func(ctx context.Context, input interfaces.Identifier) (models.Execution, error) {\n\t\treturn models.Execution{\n\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\tProject: \"project\",\n\t\t\t\tDomain:  \"domain\",\n\t\t\t\tName:    \"name\",\n\t\t\t},\n\t\t\tSpec:         getExpectedSpecBytes(),\n\t\t\tPhase:        phase,\n\t\t\tClosure:      closureBytes,\n\t\t\tLaunchPlanID: uint(1),\n\t\t\tWorkflowID:   uint(2),\n\t\t\tStartedAt:    &startedAt,\n\t\t\tInputsURI:    shared.Inputs,\n\t\t}, nil\n\t}\n\tmockExecutionRemoteURL := dataMocks.NewMockRemoteURL()\n\tmockExecutionRemoteURL.(*dataMocks.MockRemoteURL).GetCallback = func(\n\t\tctx context.Context, uri string) (admin.UrlBlob, error) {\n\t\tif uri == outputURI {\n\t\t\treturn admin.UrlBlob{\n\t\t\t\tUrl:   \"outputs\",\n\t\t\t\tBytes: 200,\n\t\t\t}, nil\n\t\t} else if strings.HasSuffix(uri, shared.Inputs) {\n\t\t\treturn admin.UrlBlob{\n\t\t\t\tUrl:   \"inputs\",\n\t\t\t\tBytes: 200,\n\t\t\t}, nil\n\t\t}\n\n\t\treturn admin.UrlBlob{}, errors.New(\"unexpected input\")\n\t}\n\tmockStorage := commonMocks.GetMockStorageClient()\n\tfullInputs := &core.LiteralMap{\n\t\tLiterals: map[string]*core.Literal{\n\t\t\t\"foo\": testutils.MakeStringLiteral(\"foo-value-1\"),\n\t\t},\n\t}\n\tfullOutputs := &core.LiteralMap{\n\t\tLiterals: map[string]*core.Literal{\n\t\t\t\"bar\": testutils.MakeStringLiteral(\"bar-value-1\"),\n\t\t},\n\t}\n\tmockStorage.ComposedProtobufStore.(*commonMocks.TestDataStore).ReadProtobufCb = func(\n\t\tctx context.Context, reference storage.DataReference, msg proto.Message) error {\n\t\tif reference.String() == \"inputs\" {\n\t\t\tmarshalled, _ := proto.Marshal(fullInputs)\n\t\t\t_ = proto.Unmarshal(marshalled, msg)\n\t\t\treturn nil\n\t\t} else if reference.String() == outputURI {\n\t\t\tmarshalled, _ := proto.Marshal(fullOutputs)\n\t\t\t_ = proto.Unmarshal(marshalled, msg)\n\t\t\treturn nil\n\t\t}\n\t\treturn fmt.Errorf(\"unexpected call to find value in storage [%v]\", reference.String())\n\t}\n\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetGetCallback(executionGetFunc)\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &defaultTestExecutor)\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), mockStorage, mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\tdataResponse, err := execManager.GetExecutionData(context.Background(), admin.WorkflowExecutionGetDataRequest{\n\t\tId: &executionIdentifier,\n\t})\n\tassert.Nil(t, err)\n\tassert.True(t, proto.Equal(&admin.WorkflowExecutionGetDataResponse{\n\t\tOutputs: &admin.UrlBlob{\n\t\t\tUrl:   \"outputs\",\n\t\t\tBytes: 200,\n\t\t},\n\t\tInputs: &admin.UrlBlob{\n\t\t\tUrl:   \"inputs\",\n\t\t\tBytes: 200,\n\t\t},\n\t\tFullInputs:  fullInputs,\n\t\tFullOutputs: fullOutputs,\n\t}, dataResponse))\n}\n\nfunc TestResolveStringMap_RuntimeLimitsObserved(t *testing.T) {\n\t_, err := resolveStringMap(&admin.Labels{\n\t\tValues: map[string]string{\n\t\t\t\"dynamiclabel1\": \"dynamic1\",\n\t\t\t\"dynamiclabel2\": \"dynamic2\",\n\t\t},\n\t}, &admin.Labels{\n\t\tValues: map[string]string{\n\t\t\t\"existing1\": \"value1\",\n\t\t},\n\t}, \"labels\", 1)\n\tassert.EqualError(t, err, \"labels has too many entries [2 > 1]\")\n}\n\nfunc TestAddPluginOverrides(t *testing.T) {\n\texecutionID := &core.WorkflowExecutionIdentifier{\n\t\tProject: project,\n\t\tDomain:  domain,\n\t\tName:    \"unused\",\n\t}\n\tworkflowName := \"workflow_name\"\n\tlaunchPlanName := \"launch_plan_name\"\n\n\tdb := repositoryMocks.NewMockRepository()\n\tdb.ResourceRepo().(*repositoryMocks.MockResourceRepo).GetFunction = func(ctx context.Context, ID interfaces.ResourceID) (\n\t\tmodels.Resource, error) {\n\t\tassert.Equal(t, project, ID.Project)\n\t\tassert.Equal(t, domain, ID.Domain)\n\t\tassert.Equal(t, workflowName, ID.Workflow)\n\t\tassert.Equal(t, launchPlanName, ID.LaunchPlan)\n\t\texistingAttributes := commonTestUtils.GetPluginOverridesAttributes(map[string][]string{\n\t\t\t\"python\": {\"plugin a\"},\n\t\t\t\"hive\":   {\"plugin b\"},\n\t\t})\n\t\tbytes, err := proto.Marshal(existingAttributes)\n\t\tif err != nil {\n\t\t\tt.Fatal(err)\n\t\t}\n\t\treturn models.Resource{\n\t\t\tProject:    project,\n\t\t\tDomain:     domain,\n\t\t\tAttributes: bytes,\n\t\t}, nil\n\t}\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &defaultTestExecutor)\n\texecManager := NewExecutionManager(db, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\n\ttaskPluginOverrides, err := execManager.(*ExecutionManager).addPluginOverrides(\n\t\tcontext.Background(), executionID, workflowName, launchPlanName)\n\tassert.NoError(t, err)\n\tassert.Len(t, taskPluginOverrides, 2)\n\tfor _, override := range taskPluginOverrides {\n\t\tif override.TaskType == \"python\" {\n\t\t\tassert.EqualValues(t, []string{\"plugin a\"}, override.PluginId)\n\t\t} else if override.TaskType == \"hive\" {\n\t\t\tassert.EqualValues(t, []string{\"plugin b\"}, override.PluginId)\n\t\t} else {\n\t\t\tt.Errorf(\"Unexpected task type [%s] plugin override committed to db\", override.TaskType)\n\t\t}\n\t}\n}\n\nfunc TestPluginOverrides_ResourceGetFailure(t *testing.T) {\n\texecutionID := &core.WorkflowExecutionIdentifier{\n\t\tProject: project,\n\t\tDomain:  domain,\n\t\tName:    \"unused\",\n\t}\n\tworkflowName := \"workflow_name\"\n\tlaunchPlanName := \"launch_plan_name\"\n\n\tdb := repositoryMocks.NewMockRepository()\n\tdb.ResourceRepo().(*repositoryMocks.MockResourceRepo).GetFunction = func(ctx context.Context, ID interfaces.ResourceID) (\n\t\tmodels.Resource, error) {\n\t\treturn models.Resource{}, flyteAdminErrors.NewFlyteAdminErrorf(codes.Aborted, \"uh oh\")\n\t}\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &defaultTestExecutor)\n\texecManager := NewExecutionManager(db, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\n\t_, err := execManager.(*ExecutionManager).addPluginOverrides(\n\t\tcontext.Background(), executionID, workflowName, launchPlanName)\n\tassert.Error(t, err, \"uh oh\")\n}\n\nfunc TestGetExecution_Legacy(t *testing.T) {\n\trepository := repositoryMocks.NewMockRepository()\n\tstartedAt := time.Date(2018, 8, 30, 0, 0, 0, 0, time.UTC)\n\texecutionGetFunc := func(ctx context.Context, input interfaces.Identifier) (models.Execution, error) {\n\t\tassert.Equal(t, \"project\", input.Project)\n\t\tassert.Equal(t, \"domain\", input.Domain)\n\t\tassert.Equal(t, \"name\", input.Name)\n\t\treturn models.Execution{\n\t\t\tBaseModel: models.BaseModel{\n\t\t\t\tCreatedAt: testutils.MockCreatedAtValue,\n\t\t\t},\n\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\tProject: \"project\",\n\t\t\t\tDomain:  \"domain\",\n\t\t\t\tName:    \"name\",\n\t\t\t},\n\t\t\tSpec:         getExpectedLegacySpecBytes(),\n\t\t\tPhase:        phase,\n\t\t\tClosure:      getLegacyClosureBytes(),\n\t\t\tLaunchPlanID: uint(1),\n\t\t\tWorkflowID:   uint(2),\n\t\t\tStartedAt:    &startedAt,\n\t\t}, nil\n\t}\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetGetCallback(executionGetFunc)\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &defaultTestExecutor)\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\texecution, err := execManager.GetExecution(context.Background(), admin.WorkflowExecutionGetRequest{\n\t\tId: &executionIdentifier,\n\t})\n\tassert.NoError(t, err)\n\tassert.True(t, proto.Equal(&executionIdentifier, execution.Id))\n\tassert.True(t, proto.Equal(getExpectedLegacySpec(), execution.Spec))\n\tassert.True(t, proto.Equal(getLegacyClosure(), execution.Closure))\n}\n\nfunc TestGetExecutionData_LegacyModel(t *testing.T) {\n\trepository := repositoryMocks.NewMockRepository()\n\tstartedAt := time.Date(2018, 8, 30, 0, 0, 0, 0, time.UTC)\n\tclosure := getLegacyClosure()\n\tclosure.OutputResult = &admin.ExecutionClosure_Outputs{\n\t\tOutputs: &admin.LiteralMapBlob{\n\t\t\tData: &admin.LiteralMapBlob_Uri{\n\t\t\t\tUri: outputURI,\n\t\t\t},\n\t\t},\n\t}\n\tvar closureBytes, _ = proto.Marshal(closure)\n\n\texecutionGetFunc := func(ctx context.Context, input interfaces.Identifier) (models.Execution, error) {\n\t\treturn models.Execution{\n\t\t\tBaseModel: models.BaseModel{\n\t\t\t\tCreatedAt: testutils.MockCreatedAtValue,\n\t\t\t},\n\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\tProject: \"project\",\n\t\t\t\tDomain:  \"domain\",\n\t\t\t\tName:    \"name\",\n\t\t\t},\n\t\t\tSpec:         getLegacySpecBytes(),\n\t\t\tPhase:        phase,\n\t\t\tClosure:      closureBytes,\n\t\t\tLaunchPlanID: uint(1),\n\t\t\tWorkflowID:   uint(2),\n\t\t\tStartedAt:    &startedAt,\n\t\t}, nil\n\t}\n\tmockExecutionRemoteURL := dataMocks.NewMockRemoteURL()\n\tmockExecutionRemoteURL.(*dataMocks.MockRemoteURL).GetCallback = func(\n\t\tctx context.Context, uri string) (admin.UrlBlob, error) {\n\t\tif uri == outputURI {\n\t\t\treturn admin.UrlBlob{\n\t\t\t\tUrl:   \"outputs\",\n\t\t\t\tBytes: 200,\n\t\t\t}, nil\n\t\t} else if strings.HasSuffix(uri, shared.Inputs) {\n\t\t\treturn admin.UrlBlob{\n\t\t\t\tUrl:   \"inputs\",\n\t\t\t\tBytes: 200,\n\t\t\t}, nil\n\t\t}\n\n\t\treturn admin.UrlBlob{}, errors.New(\"unexpected input\")\n\t}\n\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetGetCallback(executionGetFunc)\n\tstorageClient := getMockStorageForExecTest(context.Background())\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &defaultTestExecutor)\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), storageClient, mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\tdataResponse, err := execManager.GetExecutionData(context.Background(), admin.WorkflowExecutionGetDataRequest{\n\t\tId: &executionIdentifier,\n\t})\n\tassert.Nil(t, err)\n\tassert.True(t, proto.Equal(&admin.WorkflowExecutionGetDataResponse{\n\t\tOutputs: &admin.UrlBlob{\n\t\t\tUrl:   \"outputs\",\n\t\t\tBytes: 200,\n\t\t},\n\t\tInputs: &admin.UrlBlob{\n\t\t\tUrl:   \"inputs\",\n\t\t\tBytes: 200,\n\t\t},\n\t\tFullInputs: &core.LiteralMap{\n\t\t\tLiterals: map[string]*core.Literal{\n\t\t\t\t\"foo\": testutils.MakeStringLiteral(\"foo-value-1\"),\n\t\t\t},\n\t\t},\n\t\tFullOutputs: &core.LiteralMap{},\n\t}, dataResponse))\n\tvar inputs core.LiteralMap\n\terr = storageClient.ReadProtobuf(context.Background(), storage.DataReference(\"s3://bucket/metadata/project/domain/name/inputs\"), &inputs)\n\tassert.Nil(t, err)\n\tassert.True(t, proto.Equal(&inputs, closure.ComputedInputs))\n}\n\nfunc TestCreateExecution_LegacyClient(t *testing.T) {\n\trepository := getMockRepositoryForExecTest()\n\tsetDefaultLpCallbackForExecTest(repository)\n\n\tmockExecutor := workflowengineMocks.WorkflowExecutor{}\n\tmockExecutor.OnExecuteMatch(mock.Anything, mock.MatchedBy(func(execData workflowengineInterfaces.ExecutionData) bool {\n\t\tassert.EqualValues(t, map[string]string{\n\t\t\t\"label1\": \"1\",\n\t\t\t\"label2\": \"2\",\n\t\t}, execData.ExecutionParameters.Labels)\n\t\tassert.EqualValues(t, map[string]string{\n\t\t\t\"annotation3\": \"3\",\n\t\t\t\"annotation4\": \"4\",\n\t\t}, execData.ExecutionParameters.Annotations)\n\t\treturn true\n\t})).Return(workflowengineInterfaces.ExecutionResponse{\n\t\tCluster: testCluster,\n\t}, nil)\n\tmockExecutor.OnID().Return(\"customMockExecutor\")\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &mockExecutor)\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\tresponse, err := execManager.CreateExecution(context.Background(), *getLegacyExecutionRequest(), requestedAt)\n\tassert.Nil(t, err)\n\n\texpectedResponse := &admin.ExecutionCreateResponse{\n\t\tId: &executionIdentifier,\n\t}\n\tassert.Nil(t, err)\n\tassert.Equal(t, expectedResponse, response)\n}\n\nfunc TestRelaunchExecution_LegacyModel(t *testing.T) {\n\t// Set up mocks.\n\trepository := getMockRepositoryForExecTest()\n\tsetDefaultLpCallbackForExecTest(repository)\n\tstorageClient := getMockStorageForExecTest(context.Background())\n\n\tmockExecutor := workflowengineMocks.WorkflowExecutor{}\n\tmockExecutor.OnExecuteMatch(mock.Anything, mock.Anything, mock.Anything).Return(workflowengineInterfaces.ExecutionResponse{}, nil)\n\tmockExecutor.OnID().Return(\"testMockExecutor\")\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &mockExecutor)\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), storageClient, mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\tstartTime := time.Now()\n\tstartTimeProto, _ := ptypes.TimestampProto(startTime)\n\texistingClosure := getLegacyClosure()\n\texistingClosure.Phase = core.WorkflowExecution_RUNNING\n\texistingClosure.StartedAt = startTimeProto\n\texistingClosure.ComputedInputs.Literals[\"bar\"] = coreutils.MustMakeLiteral(\"bar-value\")\n\texistingClosureBytes, _ := proto.Marshal(existingClosure)\n\texecutionGetFunc := makeLegacyExecutionGetFunc(t, existingClosureBytes, &startTime)\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetGetCallback(executionGetFunc)\n\n\tvar createCalled bool\n\texCreateFunc := func(ctx context.Context, input models.Execution) error {\n\t\tcreateCalled = true\n\t\tassert.Equal(t, \"relaunchy\", input.Name)\n\t\tassert.Equal(t, \"domain\", input.Domain)\n\t\tassert.Equal(t, \"project\", input.Project)\n\t\tassert.Equal(t, uint(8), input.SourceExecutionID)\n\t\tvar spec admin.ExecutionSpec\n\t\terr := proto.Unmarshal(input.Spec, &spec)\n\t\tassert.Nil(t, err)\n\t\tassert.Equal(t, \"default_raw_output\", spec.RawOutputDataConfig.OutputLocationPrefix)\n\t\tassert.Equal(t, admin.ExecutionMetadata_RELAUNCH, spec.Metadata.Mode)\n\t\tassert.Equal(t, int32(admin.ExecutionMetadata_RELAUNCH), input.Mode)\n\t\tassert.True(t, proto.Equal(spec.Inputs, getLegacySpec().Inputs))\n\t\treturn nil\n\t}\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetCreateCallback(exCreateFunc)\n\n\t// Issue request.\n\tresponse, err := execManager.RelaunchExecution(context.Background(), admin.ExecutionRelaunchRequest{\n\t\tId: &core.WorkflowExecutionIdentifier{\n\t\t\tProject: \"project\",\n\t\t\tDomain:  \"domain\",\n\t\t\tName:    \"name\",\n\t\t},\n\t\tName: \"relaunchy\",\n\t}, requestedAt)\n\n\t// And verify response.\n\tassert.Nil(t, err)\n\n\texpectedResponse := &admin.ExecutionCreateResponse{\n\t\tId: &core.WorkflowExecutionIdentifier{\n\t\t\tProject: \"project\",\n\t\t\tDomain:  \"domain\",\n\t\t\tName:    \"relaunchy\",\n\t\t},\n\t}\n\tassert.True(t, createCalled)\n\tassert.True(t, proto.Equal(expectedResponse, response))\n\n\tvar userInputs core.LiteralMap\n\terr = storageClient.ReadProtobuf(context.Background(), \"s3://bucket/metadata/project/domain/relaunchy/user_inputs\", &userInputs)\n\tassert.Nil(t, err)\n\tassert.True(t, proto.Equal(&userInputs, getLegacySpec().Inputs))\n\n\tvar inputs core.LiteralMap\n\terr = storageClient.ReadProtobuf(context.Background(), \"s3://bucket/metadata/project/domain/relaunchy/inputs\", &inputs)\n\tassert.Nil(t, err)\n\tassert.True(t, proto.Equal(&inputs, existingClosure.ComputedInputs))\n}\n\nfunc TestListExecutions_LegacyModel(t *testing.T) {\n\trepository := repositoryMocks.NewMockRepository()\n\texecutionListFunc := func(\n\t\tctx context.Context, input interfaces.ListResourceInput) (interfaces.ExecutionCollectionOutput, error) {\n\t\tvar projectFilter, domainFilter, nameFilter bool\n\t\tfor _, filter := range input.InlineFilters {\n\t\t\tassert.Equal(t, common.Execution, filter.GetEntity())\n\t\t\tqueryExpr, _ := filter.GetGormQueryExpr()\n\t\t\tif queryExpr.Args == projectValue && queryExpr.Query == \"execution_project = ?\" {\n\t\t\t\tprojectFilter = true\n\t\t\t}\n\t\t\tif queryExpr.Args == domainValue && queryExpr.Query == \"execution_domain = ?\" {\n\t\t\t\tdomainFilter = true\n\t\t\t}\n\t\t\tif queryExpr.Args == nameValue && queryExpr.Query == \"execution_name = ?\" {\n\t\t\t\tnameFilter = true\n\t\t\t}\n\t\t}\n\t\tassert.True(t, projectFilter, \"Missing project equality filter\")\n\t\tassert.True(t, domainFilter, \"Missing domain equality filter\")\n\t\tassert.False(t, nameFilter, \"Included name equality filter\")\n\t\tassert.Equal(t, limit, input.Limit)\n\t\tassert.Equal(t, \"domain asc\", input.SortParameter.GetGormOrderExpr())\n\t\tassert.Equal(t, 2, input.Offset)\n\t\treturn interfaces.ExecutionCollectionOutput{\n\t\t\tExecutions: []models.Execution{\n\t\t\t\t{\n\t\t\t\t\tBaseModel: models.BaseModel{\n\t\t\t\t\t\tCreatedAt: testutils.MockCreatedAtValue,\n\t\t\t\t\t},\n\t\t\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\t\t\tProject: projectValue,\n\t\t\t\t\t\tDomain:  domainValue,\n\t\t\t\t\t\tName:    \"my awesome execution\",\n\t\t\t\t\t},\n\t\t\t\t\tSpec:    getLegacySpecBytes(),\n\t\t\t\t\tClosure: getLegacyClosureBytes(),\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\tBaseModel: models.BaseModel{\n\t\t\t\t\t\tCreatedAt: testutils.MockCreatedAtValue,\n\t\t\t\t\t},\n\t\t\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\t\t\tProject: projectValue,\n\t\t\t\t\t\tDomain:  domainValue,\n\t\t\t\t\t\tName:    \"my other execution\",\n\t\t\t\t\t},\n\t\t\t\t\tPhase:   core.WorkflowExecution_SUCCEEDED.String(),\n\t\t\t\t\tSpec:    specBytes,\n\t\t\t\t\tClosure: closureBytes,\n\t\t\t\t},\n\t\t\t},\n\t\t}, nil\n\t}\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetListCallback(executionListFunc)\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &defaultTestExecutor)\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\n\texecutionList, err := execManager.ListExecutions(context.Background(), admin.ResourceListRequest{\n\t\tId: &admin.NamedEntityIdentifier{\n\t\t\tProject: projectValue,\n\t\t\tDomain:  domainValue,\n\t\t},\n\t\tLimit: limit,\n\t\tSortBy: &admin.Sort{\n\t\t\tDirection: admin.Sort_ASCENDING,\n\t\t\tKey:       \"domain\",\n\t\t},\n\t\tToken: \"2\",\n\t})\n\tassert.NoError(t, err)\n\tassert.NotNil(t, executionList)\n\tassert.Len(t, executionList.Executions, 2)\n\n\tfor idx, execution := range executionList.Executions {\n\t\tassert.Equal(t, projectValue, execution.Id.Project)\n\t\tassert.Equal(t, domainValue, execution.Id.Domain)\n\t\tif idx == 0 {\n\t\t\tassert.Equal(t, \"my awesome execution\", execution.Id.Name)\n\t\t}\n\t\tassert.True(t, proto.Equal(spec, execution.Spec))\n\t\tassert.True(t, proto.Equal(&closure, execution.Closure))\n\t}\n\tassert.Empty(t, executionList.Token)\n}\n\nfunc TestSetDefaults(t *testing.T) {\n\ttask := &core.CompiledTask{\n\t\tTemplate: &core.TaskTemplate{\n\t\t\tTarget: &core.TaskTemplate_Container{\n\t\t\t\tContainer: &core.Container{\n\t\t\t\t\tResources: &core.Resources{\n\t\t\t\t\t\tRequests: []*core.Resources_ResourceEntry{\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\tName:  core.Resources_CPU,\n\t\t\t\t\t\t\t\tValue: \"250m\",\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\tId: &core.Identifier{\n\t\t\t\tProject: \"project\",\n\t\t\t\tDomain:  \"domain\",\n\t\t\t\tName:    \"task_name\",\n\t\t\t\tVersion: \"version\",\n\t\t\t},\n\t\t},\n\t}\n\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &defaultTestExecutor)\n\texecManager := NewExecutionManager(repositoryMocks.NewMockRepository(), r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\texecManager.(*ExecutionManager).setCompiledTaskDefaults(context.Background(), task, workflowengineInterfaces.TaskResources{\n\t\tDefaults: runtimeInterfaces.TaskResourceSet{\n\t\t\tCPU:              resource.MustParse(\"200m\"),\n\t\t\tGPU:              resource.MustParse(\"4\"),\n\t\t\tMemory:           resource.MustParse(\"200Gi\"),\n\t\t\tEphemeralStorage: resource.MustParse(\"500Mi\"),\n\t\t},\n\t\tLimits: runtimeInterfaces.TaskResourceSet{\n\t\t\tCPU:              resource.MustParse(\"300m\"),\n\t\t\tGPU:              resource.MustParse(\"8\"),\n\t\t\tMemory:           resource.MustParse(\"500Gi\"),\n\t\t\tEphemeralStorage: resource.MustParse(\"501Mi\"),\n\t\t},\n\t})\n\tassert.True(t, proto.Equal(\n\t\t&core.Container{\n\t\t\tResources: &core.Resources{\n\t\t\t\tRequests: []*core.Resources_ResourceEntry{\n\t\t\t\t\t{\n\t\t\t\t\t\tName:  core.Resources_CPU,\n\t\t\t\t\t\tValue: \"250m\",\n\t\t\t\t\t},\n\t\t\t\t\t{\n\t\t\t\t\t\tName:  core.Resources_MEMORY,\n\t\t\t\t\t\tValue: \"200Gi\",\n\t\t\t\t\t},\n\t\t\t\t\t{\n\t\t\t\t\t\tName:  core.Resources_EPHEMERAL_STORAGE,\n\t\t\t\t\t\tValue: \"500Mi\",\n\t\t\t\t\t},\n\t\t\t\t\t{\n\t\t\t\t\t\tName:  core.Resources_GPU,\n\t\t\t\t\t\tValue: \"4\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tLimits: []*core.Resources_ResourceEntry{\n\t\t\t\t\t{\n\t\t\t\t\t\tName:  core.Resources_CPU,\n\t\t\t\t\t\tValue: \"250m\",\n\t\t\t\t\t},\n\t\t\t\t\t{\n\t\t\t\t\t\tName:  core.Resources_MEMORY,\n\t\t\t\t\t\tValue: \"200Gi\",\n\t\t\t\t\t},\n\t\t\t\t\t{\n\t\t\t\t\t\tName:  core.Resources_EPHEMERAL_STORAGE,\n\t\t\t\t\t\tValue: \"500Mi\",\n\t\t\t\t\t},\n\t\t\t\t\t{\n\t\t\t\t\t\tName:  core.Resources_GPU,\n\t\t\t\t\t\tValue: \"4\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\ttask.Template.GetContainer()), fmt.Sprintf(\"%+v\", task.Template.GetContainer()))\n}\n\nfunc TestSetDefaults_MissingRequests_ExistingRequestsPreserved(t *testing.T) {\n\ttask := &core.CompiledTask{\n\t\tTemplate: &core.TaskTemplate{\n\t\t\tTarget: &core.TaskTemplate_Container{\n\t\t\t\tContainer: &core.Container{\n\t\t\t\t\tResources: &core.Resources{\n\t\t\t\t\t\tRequests: []*core.Resources_ResourceEntry{\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\tName:  core.Resources_CPU,\n\t\t\t\t\t\t\t\tValue: \"250m\",\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\tId: &core.Identifier{\n\t\t\t\tProject: \"project\",\n\t\t\t\tDomain:  \"domain\",\n\t\t\t\tName:    \"task_name\",\n\t\t\t\tVersion: \"version\",\n\t\t\t},\n\t\t},\n\t}\n\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &defaultTestExecutor)\n\texecManager := NewExecutionManager(repositoryMocks.NewMockRepository(), r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\texecManager.(*ExecutionManager).setCompiledTaskDefaults(context.Background(), task, workflowengineInterfaces.TaskResources{\n\t\tDefaults: runtimeInterfaces.TaskResourceSet{\n\t\t\tCPU:    resource.MustParse(\"200m\"),\n\t\t\tGPU:    resource.MustParse(\"4\"),\n\t\t\tMemory: resource.MustParse(\"200Gi\"),\n\t\t},\n\t\tLimits: runtimeInterfaces.TaskResourceSet{\n\t\t\tCPU: resource.MustParse(\"300m\"),\n\t\t\tGPU: resource.MustParse(\"8\"),\n\t\t\t// Because only the limit is set, this resource should not be injected.\n\t\t\tEphemeralStorage: resource.MustParse(\"100\"),\n\t\t},\n\t})\n\tassert.True(t, proto.Equal(\n\t\t&core.Container{\n\t\t\tResources: &core.Resources{\n\t\t\t\tRequests: []*core.Resources_ResourceEntry{\n\t\t\t\t\t{\n\t\t\t\t\t\tName:  core.Resources_CPU,\n\t\t\t\t\t\tValue: \"250m\",\n\t\t\t\t\t},\n\t\t\t\t\t{\n\t\t\t\t\t\tName:  core.Resources_MEMORY,\n\t\t\t\t\t\tValue: \"200Gi\",\n\t\t\t\t\t},\n\t\t\t\t\t{\n\t\t\t\t\t\tName:  core.Resources_GPU,\n\t\t\t\t\t\tValue: \"4\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tLimits: []*core.Resources_ResourceEntry{\n\t\t\t\t\t{\n\t\t\t\t\t\tName:  core.Resources_CPU,\n\t\t\t\t\t\tValue: \"250m\",\n\t\t\t\t\t},\n\t\t\t\t\t{\n\t\t\t\t\t\tName:  core.Resources_MEMORY,\n\t\t\t\t\t\tValue: \"200Gi\",\n\t\t\t\t\t},\n\t\t\t\t\t{\n\t\t\t\t\t\tName:  core.Resources_GPU,\n\t\t\t\t\t\tValue: \"4\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\ttask.Template.GetContainer()), fmt.Sprintf(\"%+v\", task.Template.GetContainer()))\n}\n\nfunc TestSetDefaults_OptionalRequiredResources(t *testing.T) {\n\ttaskConfigLimits := runtimeInterfaces.TaskResourceSet{\n\t\tCPU:              resource.MustParse(\"300m\"),\n\t\tGPU:              resource.MustParse(\"1\"),\n\t\tMemory:           resource.MustParse(\"500Gi\"),\n\t\tEphemeralStorage: resource.MustParse(\"501Mi\"),\n\t}\n\n\ttask := &core.CompiledTask{\n\t\tTemplate: &core.TaskTemplate{\n\t\t\tTarget: &core.TaskTemplate_Container{\n\t\t\t\tContainer: &core.Container{\n\t\t\t\t\tResources: &core.Resources{\n\t\t\t\t\t\tRequests: []*core.Resources_ResourceEntry{\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\tName:  core.Resources_CPU,\n\t\t\t\t\t\t\t\tValue: \"200m\",\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\tId: &taskIdentifier,\n\t\t},\n\t}\n\tt.Run(\"don't inject ephemeral storage or gpu when only the limit is set in config\", func(t *testing.T) {\n\t\tr := plugins.NewRegistry()\n\t\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &defaultTestExecutor)\n\t\texecManager := NewExecutionManager(repositoryMocks.NewMockRepository(), r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\t\texecManager.(*ExecutionManager).setCompiledTaskDefaults(context.Background(), task, workflowengineInterfaces.TaskResources{\n\t\t\tDefaults: runtimeInterfaces.TaskResourceSet{\n\t\t\t\tCPU:    resource.MustParse(\"200m\"),\n\t\t\t\tMemory: resource.MustParse(\"200Gi\"),\n\t\t\t},\n\t\t\tLimits: taskConfigLimits,\n\t\t})\n\t\tassert.True(t, proto.Equal(\n\t\t\t&core.Container{\n\t\t\t\tResources: &core.Resources{\n\t\t\t\t\tRequests: []*core.Resources_ResourceEntry{\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tName:  core.Resources_CPU,\n\t\t\t\t\t\t\tValue: \"200m\",\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tName:  core.Resources_MEMORY,\n\t\t\t\t\t\t\tValue: \"200Gi\",\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t\tLimits: []*core.Resources_ResourceEntry{\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tName:  core.Resources_CPU,\n\t\t\t\t\t\t\tValue: \"200m\",\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tName:  core.Resources_MEMORY,\n\t\t\t\t\t\t\tValue: \"200Gi\",\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\ttask.Template.GetContainer()), fmt.Sprintf(\"%+v\", task.Template.GetContainer()))\n\t})\n\n\tt.Run(\"respect non-required resources when defaults exist in config\", func(t *testing.T) {\n\t\tr := plugins.NewRegistry()\n\t\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &defaultTestExecutor)\n\t\texecManager := NewExecutionManager(repositoryMocks.NewMockRepository(), r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\t\texecManager.(*ExecutionManager).setCompiledTaskDefaults(context.Background(), task, workflowengineInterfaces.TaskResources{\n\t\t\tLimits: taskConfigLimits,\n\t\t\tDefaults: runtimeInterfaces.TaskResourceSet{\n\t\t\t\tCPU:              resource.MustParse(\"200m\"),\n\t\t\t\tMemory:           resource.MustParse(\"200Gi\"),\n\t\t\t\tEphemeralStorage: resource.MustParse(\"1\"),\n\t\t\t},\n\t\t})\n\t\tassert.True(t, proto.Equal(\n\t\t\t&core.Container{\n\t\t\t\tResources: &core.Resources{\n\t\t\t\t\tRequests: []*core.Resources_ResourceEntry{\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tName:  core.Resources_CPU,\n\t\t\t\t\t\t\tValue: \"200m\",\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tName:  core.Resources_MEMORY,\n\t\t\t\t\t\t\tValue: \"200Gi\",\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tName:  core.Resources_EPHEMERAL_STORAGE,\n\t\t\t\t\t\t\tValue: \"1\",\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t\tLimits: []*core.Resources_ResourceEntry{\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tName:  core.Resources_CPU,\n\t\t\t\t\t\t\tValue: \"200m\",\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tName:  core.Resources_MEMORY,\n\t\t\t\t\t\t\tValue: \"200Gi\",\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tName:  core.Resources_EPHEMERAL_STORAGE,\n\t\t\t\t\t\t\tValue: \"1\",\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\ttask.Template.GetContainer()), fmt.Sprintf(\"%+v\", task.Template.GetContainer()))\n\t})\n\n}\nfunc TestCreateSingleTaskExecution(t *testing.T) {\n\trepository := getMockRepositoryForExecTest()\n\tvar getCalledCount = 0\n\tvar newlyCreatedWorkflow models.Workflow\n\tworkflowCreateFunc := func(input models.Workflow, descriptionEntity *models.DescriptionEntity) error {\n\t\tnewlyCreatedWorkflow = input\n\t\treturn nil\n\t}\n\trepository.WorkflowRepo().(*repositoryMocks.MockWorkflowRepo).SetCreateCallback(workflowCreateFunc)\n\n\tworkflowGetFunc := func(input interfaces.Identifier) (models.Workflow, error) {\n\t\tif getCalledCount <= 1 {\n\t\t\tgetCalledCount++\n\t\t\treturn models.Workflow{}, flyteAdminErrors.NewFlyteAdminErrorf(codes.NotFound, \"not found\")\n\t\t}\n\t\tgetCalledCount++\n\t\treturn newlyCreatedWorkflow, nil\n\t}\n\trepository.WorkflowRepo().(*repositoryMocks.MockWorkflowRepo).SetGetCallback(workflowGetFunc)\n\ttaskIdentifier := &core.Identifier{\n\t\tResourceType: core.ResourceType_TASK,\n\t\tProject:      \"flytekit\",\n\t\tDomain:       \"production\",\n\t\tName:         \"simple_task\",\n\t\tVersion:      \"12345\",\n\t}\n\trepository.TaskRepo().(*repositoryMocks.MockTaskRepo).SetGetCallback(\n\t\tfunc(input interfaces.Identifier) (models.Task, error) {\n\t\t\tcreatedAt := time.Now()\n\t\t\tcreatedAtProto, _ := ptypes.TimestampProto(createdAt)\n\t\t\ttaskClosure := &admin.TaskClosure{\n\t\t\t\tCompiledTask: &core.CompiledTask{\n\t\t\t\t\tTemplate: &core.TaskTemplate{\n\t\t\t\t\t\tId:   taskIdentifier,\n\t\t\t\t\t\tType: \"python-task\",\n\t\t\t\t\t\tMetadata: &core.TaskMetadata{\n\t\t\t\t\t\t\tRuntime: &core.RuntimeMetadata{\n\t\t\t\t\t\t\t\tType:    core.RuntimeMetadata_FLYTE_SDK,\n\t\t\t\t\t\t\t\tVersion: \"0.6.2\",\n\t\t\t\t\t\t\t\tFlavor:  \"python\",\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\tTimeout: ptypes.DurationProto(time.Second),\n\t\t\t\t\t\t},\n\t\t\t\t\t\tInterface: &core.TypedInterface{\n\t\t\t\t\t\t\tInputs: &core.VariableMap{\n\t\t\t\t\t\t\t\tVariables: map[string]*core.Variable{\n\t\t\t\t\t\t\t\t\t\"a\": {\n\t\t\t\t\t\t\t\t\t\tType: &core.LiteralType{\n\t\t\t\t\t\t\t\t\t\t\tType: &core.LiteralType_Simple{\n\t\t\t\t\t\t\t\t\t\t\t\tSimple: core.SimpleType_INTEGER,\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\tOutputs: &core.VariableMap{\n\t\t\t\t\t\t\t\tVariables: map[string]*core.Variable{\n\t\t\t\t\t\t\t\t\t\"b\": {\n\t\t\t\t\t\t\t\t\t\tType: &core.LiteralType{\n\t\t\t\t\t\t\t\t\t\t\tType: &core.LiteralType_Simple{\n\t\t\t\t\t\t\t\t\t\t\t\tSimple: core.SimpleType_INTEGER,\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t\tCustom: nil,\n\t\t\t\t\t\tTarget: &core.TaskTemplate_Container{\n\t\t\t\t\t\t\tContainer: &core.Container{\n\t\t\t\t\t\t\t\tImage: \"docker.io/my:image\",\n\t\t\t\t\t\t\t\tArgs: []string{\n\t\t\t\t\t\t\t\t\t\"pyflyte-execute\",\n\t\t\t\t\t\t\t\t\t\"--task-module\",\n\t\t\t\t\t\t\t\t\t\"workflows.simple\",\n\t\t\t\t\t\t\t\t\t\"--task-name\",\n\t\t\t\t\t\t\t\t\t\"simple_task\",\n\t\t\t\t\t\t\t\t\t\"--inputs\",\n\t\t\t\t\t\t\t\t\t\"{{.input}}\",\n\t\t\t\t\t\t\t\t\t\"--output-prefix\",\n\t\t\t\t\t\t\t\t\t\"{{.outputPrefix}}\",\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\tEnv: []*core.KeyValuePair{\n\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\tKey:   \"FLYTE_INTERNAL_PROJECT\",\n\t\t\t\t\t\t\t\t\t\tValue: \"flytekit\",\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\tKey:   \"FLYTE_INTERNAL_DOMAIN\",\n\t\t\t\t\t\t\t\t\t\tValue: \"production\",\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\tKey:   \"FLYTE_INTERNAL_NAME\",\n\t\t\t\t\t\t\t\t\t\tValue: \"simple_task\",\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\tKey:   \"FLYTE_INTERNAL_VERSION\",\n\t\t\t\t\t\t\t\t\t\tValue: \"12345\",\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tCreatedAt: createdAtProto,\n\t\t\t}\n\t\t\tserializedTaskClosure, err := proto.Marshal(taskClosure)\n\t\t\tassert.NoError(t, err)\n\t\t\treturn models.Task{\n\t\t\t\tTaskKey: models.TaskKey{\n\t\t\t\t\tProject: \"flytekit\",\n\t\t\t\t\tDomain:  \"production\",\n\t\t\t\t\tName:    \"simple_task\",\n\t\t\t\t\tVersion: \"12345\",\n\t\t\t\t},\n\t\t\t\tClosure: serializedTaskClosure,\n\t\t\t\tDigest:  []byte(\"simple_task\"),\n\t\t\t\tType:    \"python\",\n\t\t\t}, nil\n\t\t})\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetCreateCallback(\n\t\tfunc(ctx context.Context, input models.Execution) error {\n\t\t\tvar spec admin.ExecutionSpec\n\t\t\terr := proto.Unmarshal(input.Spec, &spec)\n\t\t\tassert.NoError(t, err)\n\t\t\tassert.Equal(t, models.ExecutionKey{\n\t\t\t\tProject: \"flytekit\",\n\t\t\t\tDomain:  \"production\",\n\t\t\t\tName:    \"singletaskexec\",\n\t\t\t}, input.ExecutionKey)\n\t\t\tassert.Equal(t, \"task\", input.LaunchEntity)\n\t\t\tassert.Equal(t, \"UNDEFINED\", input.Phase)\n\t\t\tassert.True(t, proto.Equal(taskIdentifier, spec.LaunchPlan))\n\t\t\treturn nil\n\t\t})\n\n\tvar launchplan *models.LaunchPlan\n\trepository.LaunchPlanRepo().(*repositoryMocks.MockLaunchPlanRepo).SetCreateCallback(func(input models.LaunchPlan) error {\n\t\tlaunchplan = &input\n\t\treturn nil\n\t})\n\trepository.LaunchPlanRepo().(*repositoryMocks.MockLaunchPlanRepo).SetGetCallback(func(input interfaces.Identifier) (models.LaunchPlan, error) {\n\t\tif launchplan == nil {\n\t\t\treturn models.LaunchPlan{}, flyteAdminErrors.NewFlyteAdminError(codes.NotFound, \"launchplan not found\")\n\t\t}\n\t\treturn *launchplan, nil\n\t})\n\n\tmockStorage := getMockStorageForExecTest(context.Background())\n\tworkflowManager := NewWorkflowManager(\n\t\trepository,\n\t\tgetMockWorkflowConfigProvider(), getMockWorkflowCompiler(), mockStorage,\n\t\tstoragePrefix, mockScope.NewTestScope())\n\tnamedEntityManager := NewNamedEntityManager(repository, getMockConfigForNETest(), mockScope.NewTestScope())\n\n\tmockExecutor := workflowengineMocks.WorkflowExecutor{}\n\tmockExecutor.OnExecuteMatch(mock.Anything, mock.Anything, mock.Anything).Return(workflowengineInterfaces.ExecutionResponse{}, nil)\n\tmockExecutor.OnID().Return(\"testMockExecutor\")\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &mockExecutor)\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), mockStorage, mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, workflowManager, namedEntityManager, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\trequest := admin.ExecutionCreateRequest{\n\t\tProject: \"flytekit\",\n\t\tDomain:  \"production\",\n\t\tName:    \"singletaskexec\",\n\t\tSpec: &admin.ExecutionSpec{\n\t\t\tLaunchPlan: taskIdentifier,\n\t\t},\n\t\tInputs: &core.LiteralMap{\n\t\t\tLiterals: map[string]*core.Literal{\n\t\t\t\t\"a\": {\n\t\t\t\t\tValue: &core.Literal_Scalar{\n\t\t\t\t\t\tScalar: &core.Scalar{\n\t\t\t\t\t\t\tValue: &core.Scalar_Primitive{\n\t\t\t\t\t\t\t\tPrimitive: &core.Primitive{\n\t\t\t\t\t\t\t\t\tValue: &core.Primitive_Integer{\n\t\t\t\t\t\t\t\t\t\tInteger: 999,\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t}\n\n\tmarshaller := jsonpb.Marshaler{}\n\t_, ferr := marshaller.MarshalToString(&request)\n\tassert.NoError(t, ferr)\n\n\t// test once to create an initial launchplan\n\t_, err := execManager.CreateExecution(context.TODO(), request, time.Now())\n\tassert.NoError(t, err)\n\n\t// test again to ensure existing launchplan retrieval works\n\t_, err = execManager.CreateExecution(context.TODO(), request, time.Now())\n\tassert.NoError(t, err)\n}\n\nfunc TestGetExecutionConfigOverrides(t *testing.T) {\n\trequestLabels := map[string]string{\"requestLabelKey\": \"requestLabelValue\"}\n\trequestAnnotations := map[string]string{\"requestAnnotationKey\": \"requestAnnotationValue\"}\n\trequestOutputLocationPrefix := \"requestOutputLocationPrefix\"\n\trequestK8sServiceAccount := \"requestK8sServiceAccount\"\n\trequestMaxParallelism := int32(10)\n\trequestInterruptible := false\n\trequestOverwriteCache := false\n\trequestEnvironmentVariables := []*core.KeyValuePair{{Key: \"hello\", Value: \"world\"}}\n\n\tlaunchPlanLabels := map[string]string{\"launchPlanLabelKey\": \"launchPlanLabelValue\"}\n\tlaunchPlanAnnotations := map[string]string{\"launchPlanAnnotationKey\": \"launchPlanAnnotationValue\"}\n\tlaunchPlanOutputLocationPrefix := \"launchPlanOutputLocationPrefix\"\n\tlaunchPlanK8sServiceAccount := \"launchPlanK8sServiceAccount\"\n\tlaunchPlanAssumableIamRole := \"launchPlanAssumableIamRole\"\n\tlaunchPlanMaxParallelism := int32(50)\n\tlaunchPlanInterruptible := true\n\tlaunchPlanOverwriteCache := true\n\tlaunchPlanEnvironmentVariables := []*core.KeyValuePair{{Key: \"foo\", Value: \"bar\"}}\n\n\tapplicationConfig := runtime.NewConfigurationProvider()\n\n\tdefaultK8sServiceAccount := applicationConfig.ApplicationConfiguration().GetTopLevelConfig().K8SServiceAccount\n\tdefaultMaxParallelism := applicationConfig.ApplicationConfiguration().GetTopLevelConfig().MaxParallelism\n\n\tdeprecatedLaunchPlanK8sServiceAccount := \"deprecatedLaunchPlanK8sServiceAccount\"\n\trmLabels := map[string]string{\"rmLabelKey\": \"rmLabelValue\"}\n\trmAnnotations := map[string]string{\"rmAnnotationKey\": \"rmAnnotationValue\"}\n\trmOutputLocationPrefix := \"rmOutputLocationPrefix\"\n\trmK8sServiceAccount := \"rmK8sServiceAccount\"\n\trmMaxParallelism := int32(80)\n\trmInterruptible := false\n\trmOverwriteCache := false\n\n\tresourceManager := managerMocks.MockResourceManager{}\n\texecutionManager := ExecutionManager{\n\t\tresourceManager: &resourceManager,\n\t\tconfig:          applicationConfig,\n\t}\n\tresourceManager.GetResourceFunc = func(ctx context.Context,\n\t\trequest managerInterfaces.ResourceRequest) (*managerInterfaces.ResourceResponse, error) {\n\t\t// two requests will be made, one with empty domain and one with filled in domain\n\t\tassert.Contains(t, []managerInterfaces.ResourceRequest{{\n\t\t\tProject:      workflowIdentifier.Project,\n\t\t\tDomain:       workflowIdentifier.Domain,\n\t\t\tResourceType: admin.MatchableResource_WORKFLOW_EXECUTION_CONFIG,\n\t\t}, {Project: workflowIdentifier.Project,\n\t\t\tDomain:       \"\",\n\t\t\tResourceType: admin.MatchableResource_WORKFLOW_EXECUTION_CONFIG},\n\t\t}, request)\n\t\tprojectDomainResponse := &managerInterfaces.ResourceResponse{\n\t\t\tAttributes: &admin.MatchingAttributes{\n\t\t\t\tTarget: &admin.MatchingAttributes_WorkflowExecutionConfig{\n\t\t\t\t\tWorkflowExecutionConfig: &admin.WorkflowExecutionConfig{\n\t\t\t\t\t\tMaxParallelism: rmMaxParallelism,\n\t\t\t\t\t\tInterruptible:  &wrappers.BoolValue{Value: rmInterruptible},\n\t\t\t\t\t\tOverwriteCache: rmOverwriteCache,\n\t\t\t\t\t\tAnnotations:    &admin.Annotations{Values: rmAnnotations},\n\t\t\t\t\t\tRawOutputDataConfig: &admin.RawOutputDataConfig{\n\t\t\t\t\t\t\tOutputLocationPrefix: rmOutputLocationPrefix,\n\t\t\t\t\t\t},\n\t\t\t\t\t\tSecurityContext: &core.SecurityContext{\n\t\t\t\t\t\t\tRunAs: &core.Identity{\n\t\t\t\t\t\t\t\tK8SServiceAccount: rmK8sServiceAccount,\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t}\n\n\t\tprojectResponse := &managerInterfaces.ResourceResponse{\n\t\t\tAttributes: &admin.MatchingAttributes{\n\t\t\t\tTarget: &admin.MatchingAttributes_WorkflowExecutionConfig{\n\t\t\t\t\tWorkflowExecutionConfig: &admin.WorkflowExecutionConfig{\n\t\t\t\t\t\tLabels: &admin.Labels{Values: rmLabels},\n\t\t\t\t\t\tRawOutputDataConfig: &admin.RawOutputDataConfig{\n\t\t\t\t\t\t\tOutputLocationPrefix: \"shouldnotbeused\",\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t}\n\t\tif request.Domain == \"\" {\n\t\t\treturn projectResponse, nil\n\t\t}\n\t\treturn projectDomainResponse, nil\n\t}\n\n\tt.Run(\"request with full config\", func(t *testing.T) {\n\t\trequest := &admin.ExecutionCreateRequest{\n\t\t\tProject: workflowIdentifier.Project,\n\t\t\tDomain:  workflowIdentifier.Domain,\n\t\t\tSpec: &admin.ExecutionSpec{\n\t\t\t\tLabels:      &admin.Labels{Values: requestLabels},\n\t\t\t\tAnnotations: &admin.Annotations{Values: requestAnnotations},\n\t\t\t\tRawOutputDataConfig: &admin.RawOutputDataConfig{\n\t\t\t\t\tOutputLocationPrefix: requestOutputLocationPrefix,\n\t\t\t\t},\n\t\t\t\tSecurityContext: &core.SecurityContext{\n\t\t\t\t\tRunAs: &core.Identity{\n\t\t\t\t\t\tK8SServiceAccount: requestK8sServiceAccount,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tMaxParallelism: requestMaxParallelism,\n\t\t\t\tInterruptible:  &wrappers.BoolValue{Value: requestInterruptible},\n\t\t\t\tOverwriteCache: requestOverwriteCache,\n\t\t\t\tEnvs:           &admin.Envs{Values: requestEnvironmentVariables},\n\t\t\t},\n\t\t}\n\t\tidentityContext, err := auth.NewIdentityContext(\"\", \"\", \"\", time.Now(), sets.String{}, nil, nil)\n\t\tassert.NoError(t, err)\n\t\tidentityContext = identityContext.WithExecutionUserIdentifier(\"yeee\")\n\t\tctx := identityContext.WithContext(context.Background())\n\t\texecConfig, err := executionManager.getExecutionConfig(ctx, request, nil)\n\t\tassert.NoError(t, err)\n\t\tassert.Equal(t, requestMaxParallelism, execConfig.MaxParallelism)\n\t\tassert.Equal(t, requestK8sServiceAccount, execConfig.SecurityContext.RunAs.K8SServiceAccount)\n\t\tassert.Equal(t, requestInterruptible, execConfig.Interruptible.Value)\n\t\tassert.Equal(t, requestOverwriteCache, execConfig.OverwriteCache)\n\t\tassert.Equal(t, requestOutputLocationPrefix, execConfig.RawOutputDataConfig.OutputLocationPrefix)\n\t\tassert.Equal(t, requestLabels, execConfig.GetLabels().Values)\n\t\tassert.Equal(t, requestAnnotations, execConfig.GetAnnotations().Values)\n\t\tassert.Equal(t, \"yeee\", execConfig.GetSecurityContext().GetRunAs().GetExecutionIdentity())\n\t\tassert.Equal(t, requestEnvironmentVariables, execConfig.GetEnvs().Values)\n\t})\n\tt.Run(\"request with partial config\", func(t *testing.T) {\n\t\trequest := &admin.ExecutionCreateRequest{\n\t\t\tProject: workflowIdentifier.Project,\n\t\t\tDomain:  workflowIdentifier.Domain,\n\t\t\tSpec: &admin.ExecutionSpec{\n\t\t\t\tLabels: &admin.Labels{Values: requestLabels},\n\t\t\t\tRawOutputDataConfig: &admin.RawOutputDataConfig{\n\t\t\t\t\tOutputLocationPrefix: requestOutputLocationPrefix,\n\t\t\t\t},\n\t\t\t\tMaxParallelism: requestMaxParallelism,\n\t\t\t},\n\t\t}\n\t\tlaunchPlan := &admin.LaunchPlan{\n\t\t\tSpec: &admin.LaunchPlanSpec{\n\t\t\t\tAnnotations:         &admin.Annotations{Values: launchPlanAnnotations},\n\t\t\t\tLabels:              &admin.Labels{Values: launchPlanLabels},\n\t\t\t\tRawOutputDataConfig: &admin.RawOutputDataConfig{OutputLocationPrefix: launchPlanOutputLocationPrefix},\n\t\t\t\tSecurityContext: &core.SecurityContext{\n\t\t\t\t\tRunAs: &core.Identity{\n\t\t\t\t\t\tK8SServiceAccount: launchPlanK8sServiceAccount,\n\t\t\t\t\t\tIamRole:           launchPlanAssumableIamRole,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tMaxParallelism: launchPlanMaxParallelism,\n\t\t\t\tInterruptible:  &wrappers.BoolValue{Value: launchPlanInterruptible},\n\t\t\t\tOverwriteCache: launchPlanOverwriteCache,\n\t\t\t\tEnvs:           &admin.Envs{Values: launchPlanEnvironmentVariables},\n\t\t\t},\n\t\t}\n\t\texecConfig, err := executionManager.getExecutionConfig(context.TODO(), request, launchPlan)\n\t\tassert.NoError(t, err)\n\t\tassert.Equal(t, requestMaxParallelism, execConfig.MaxParallelism)\n\t\tassert.Equal(t, launchPlanInterruptible, execConfig.Interruptible.Value)\n\t\tassert.Equal(t, launchPlanOverwriteCache, execConfig.OverwriteCache)\n\t\tassert.True(t, proto.Equal(launchPlan.Spec.SecurityContext, execConfig.SecurityContext))\n\t\tassert.True(t, proto.Equal(launchPlan.Spec.Annotations, execConfig.Annotations))\n\t\tassert.Equal(t, requestOutputLocationPrefix, execConfig.RawOutputDataConfig.OutputLocationPrefix)\n\t\tassert.Equal(t, requestLabels, execConfig.GetLabels().Values)\n\t\tassert.Equal(t, launchPlanEnvironmentVariables, execConfig.GetEnvs().Values)\n\t})\n\tt.Run(\"request with empty security context\", func(t *testing.T) {\n\t\trequest := &admin.ExecutionCreateRequest{\n\t\t\tProject: workflowIdentifier.Project,\n\t\t\tDomain:  workflowIdentifier.Domain,\n\t\t\tSpec: &admin.ExecutionSpec{\n\t\t\t\tSecurityContext: &core.SecurityContext{\n\t\t\t\t\tRunAs: &core.Identity{\n\t\t\t\t\t\tK8SServiceAccount: \"\",\n\t\t\t\t\t\tIamRole:           \"\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t}\n\t\tlaunchPlan := &admin.LaunchPlan{\n\t\t\tSpec: &admin.LaunchPlanSpec{\n\t\t\t\tAnnotations:         &admin.Annotations{Values: launchPlanAnnotations},\n\t\t\t\tLabels:              &admin.Labels{Values: launchPlanLabels},\n\t\t\t\tRawOutputDataConfig: &admin.RawOutputDataConfig{OutputLocationPrefix: launchPlanOutputLocationPrefix},\n\t\t\t\tSecurityContext: &core.SecurityContext{\n\t\t\t\t\tRunAs: &core.Identity{\n\t\t\t\t\t\tK8SServiceAccount: launchPlanK8sServiceAccount,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tMaxParallelism: launchPlanMaxParallelism,\n\t\t\t\tInterruptible:  &wrappers.BoolValue{Value: launchPlanInterruptible},\n\t\t\t\tOverwriteCache: launchPlanOverwriteCache,\n\t\t\t\tEnvs:           &admin.Envs{Values: launchPlanEnvironmentVariables},\n\t\t\t},\n\t\t}\n\t\texecConfig, err := executionManager.getExecutionConfig(context.TODO(), request, launchPlan)\n\t\tassert.NoError(t, err)\n\t\tassert.Equal(t, launchPlanMaxParallelism, execConfig.MaxParallelism)\n\t\tassert.Equal(t, launchPlanInterruptible, execConfig.Interruptible.Value)\n\t\tassert.Equal(t, launchPlanOverwriteCache, execConfig.OverwriteCache)\n\t\tassert.Equal(t, launchPlanK8sServiceAccount, execConfig.SecurityContext.RunAs.K8SServiceAccount)\n\t\tassert.Equal(t, launchPlanOutputLocationPrefix, execConfig.RawOutputDataConfig.OutputLocationPrefix)\n\t\tassert.Equal(t, launchPlanLabels, execConfig.GetLabels().Values)\n\t\tassert.Equal(t, launchPlanEnvironmentVariables, execConfig.GetEnvs().Values)\n\t})\n\tt.Run(\"request with no config\", func(t *testing.T) {\n\t\trequest := &admin.ExecutionCreateRequest{\n\t\t\tProject: workflowIdentifier.Project,\n\t\t\tDomain:  workflowIdentifier.Domain,\n\t\t\tSpec:    &admin.ExecutionSpec{},\n\t\t}\n\t\tlaunchPlan := &admin.LaunchPlan{\n\t\t\tSpec: &admin.LaunchPlanSpec{\n\t\t\t\tLabels:      &admin.Labels{Values: launchPlanLabels},\n\t\t\t\tAnnotations: &admin.Annotations{Values: launchPlanAnnotations},\n\t\t\t\tRawOutputDataConfig: &admin.RawOutputDataConfig{\n\t\t\t\t\tOutputLocationPrefix: launchPlanOutputLocationPrefix,\n\t\t\t\t},\n\t\t\t\tSecurityContext: &core.SecurityContext{\n\t\t\t\t\tRunAs: &core.Identity{\n\t\t\t\t\t\tK8SServiceAccount: launchPlanK8sServiceAccount,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tMaxParallelism: launchPlanMaxParallelism,\n\t\t\t\tInterruptible:  &wrappers.BoolValue{Value: launchPlanInterruptible},\n\t\t\t\tOverwriteCache: launchPlanOverwriteCache,\n\t\t\t\tEnvs:           &admin.Envs{Values: launchPlanEnvironmentVariables},\n\t\t\t},\n\t\t}\n\t\texecConfig, err := executionManager.getExecutionConfig(context.TODO(), request, launchPlan)\n\t\tassert.NoError(t, err)\n\t\tassert.Equal(t, launchPlanMaxParallelism, execConfig.MaxParallelism)\n\t\tassert.Equal(t, launchPlanInterruptible, execConfig.Interruptible.Value)\n\t\tassert.Equal(t, launchPlanOverwriteCache, execConfig.OverwriteCache)\n\t\tassert.Equal(t, launchPlanK8sServiceAccount, execConfig.SecurityContext.RunAs.K8SServiceAccount)\n\t\tassert.Equal(t, launchPlanOutputLocationPrefix, execConfig.RawOutputDataConfig.OutputLocationPrefix)\n\t\tassert.Equal(t, launchPlanLabels, execConfig.GetLabels().Values)\n\t\tassert.Equal(t, launchPlanAnnotations, execConfig.GetAnnotations().Values)\n\t\tassert.Equal(t, launchPlanEnvironmentVariables, execConfig.GetEnvs().Values)\n\t})\n\tt.Run(\"launchplan with partial config\", func(t *testing.T) {\n\t\trequest := &admin.ExecutionCreateRequest{\n\t\t\tProject: workflowIdentifier.Project,\n\t\t\tDomain:  workflowIdentifier.Domain,\n\t\t\tSpec:    &admin.ExecutionSpec{},\n\t\t}\n\t\tlaunchPlan := &admin.LaunchPlan{\n\t\t\tSpec: &admin.LaunchPlanSpec{\n\t\t\t\tLabels:      &admin.Labels{Values: launchPlanLabels},\n\t\t\t\tAnnotations: &admin.Annotations{Values: launchPlanAnnotations},\n\t\t\t\tRawOutputDataConfig: &admin.RawOutputDataConfig{\n\t\t\t\t\tOutputLocationPrefix: launchPlanOutputLocationPrefix,\n\t\t\t\t},\n\t\t\t\tSecurityContext: &core.SecurityContext{\n\t\t\t\t\tRunAs: &core.Identity{\n\t\t\t\t\t\tK8SServiceAccount: launchPlanK8sServiceAccount,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tMaxParallelism: launchPlanMaxParallelism,\n\t\t\t},\n\t\t}\n\t\texecConfig, err := executionManager.getExecutionConfig(context.TODO(), request, launchPlan)\n\t\tassert.NoError(t, err)\n\t\tassert.Equal(t, launchPlanMaxParallelism, execConfig.MaxParallelism)\n\t\tassert.Equal(t, rmInterruptible, execConfig.Interruptible.Value)\n\t\tassert.Equal(t, rmOverwriteCache, execConfig.OverwriteCache)\n\t\tassert.Equal(t, launchPlanK8sServiceAccount, execConfig.SecurityContext.RunAs.K8SServiceAccount)\n\t\tassert.Equal(t, launchPlanOutputLocationPrefix, execConfig.RawOutputDataConfig.OutputLocationPrefix)\n\t\tassert.Equal(t, launchPlanLabels, execConfig.GetLabels().Values)\n\t\tassert.Equal(t, launchPlanAnnotations, execConfig.GetAnnotations().Values)\n\t})\n\tt.Run(\"launchplan with no config\", func(t *testing.T) {\n\t\trequest := &admin.ExecutionCreateRequest{\n\t\t\tProject: workflowIdentifier.Project,\n\t\t\tDomain:  workflowIdentifier.Domain,\n\t\t\tSpec:    &admin.ExecutionSpec{},\n\t\t}\n\t\tlaunchPlan := &admin.LaunchPlan{\n\t\t\tSpec: &admin.LaunchPlanSpec{},\n\t\t}\n\t\texecConfig, err := executionManager.getExecutionConfig(context.TODO(), request, launchPlan)\n\t\tassert.NoError(t, err)\n\t\tassert.Equal(t, rmMaxParallelism, execConfig.MaxParallelism)\n\t\tassert.Equal(t, rmInterruptible, execConfig.Interruptible.Value)\n\t\tassert.Equal(t, rmOverwriteCache, execConfig.OverwriteCache)\n\t\tassert.Equal(t, rmK8sServiceAccount, execConfig.SecurityContext.RunAs.K8SServiceAccount)\n\t\tassert.Equal(t, rmOutputLocationPrefix, execConfig.RawOutputDataConfig.OutputLocationPrefix)\n\t\tassert.Equal(t, rmLabels, execConfig.GetLabels().Values)\n\t\tassert.Equal(t, rmAnnotations, execConfig.GetAnnotations().Values)\n\t\tassert.Nil(t, execConfig.GetEnvs())\n\t})\n\tt.Run(\"matchable resource partial config\", func(t *testing.T) {\n\t\tresourceManager.GetResourceFunc = func(ctx context.Context,\n\t\t\trequest managerInterfaces.ResourceRequest) (*managerInterfaces.ResourceResponse, error) {\n\t\t\tassert.Contains(t, []managerInterfaces.ResourceRequest{{\n\t\t\t\tProject:      workflowIdentifier.Project,\n\t\t\t\tDomain:       workflowIdentifier.Domain,\n\t\t\t\tResourceType: admin.MatchableResource_WORKFLOW_EXECUTION_CONFIG,\n\t\t\t}, {Project: workflowIdentifier.Project,\n\t\t\t\tDomain:       \"\",\n\t\t\t\tResourceType: admin.MatchableResource_WORKFLOW_EXECUTION_CONFIG},\n\t\t\t}, request)\n\n\t\t\treturn &managerInterfaces.ResourceResponse{\n\t\t\t\tAttributes: &admin.MatchingAttributes{\n\t\t\t\t\tTarget: &admin.MatchingAttributes_WorkflowExecutionConfig{\n\t\t\t\t\t\tWorkflowExecutionConfig: &admin.WorkflowExecutionConfig{\n\t\t\t\t\t\t\tMaxParallelism: rmMaxParallelism,\n\t\t\t\t\t\t\tAnnotations:    &admin.Annotations{Values: rmAnnotations},\n\t\t\t\t\t\t\tSecurityContext: &core.SecurityContext{\n\t\t\t\t\t\t\t\tRunAs: &core.Identity{\n\t\t\t\t\t\t\t\t\tK8SServiceAccount: rmK8sServiceAccount,\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t}, nil\n\t\t}\n\t\trequest := &admin.ExecutionCreateRequest{\n\t\t\tProject: workflowIdentifier.Project,\n\t\t\tDomain:  workflowIdentifier.Domain,\n\t\t\tSpec:    &admin.ExecutionSpec{},\n\t\t}\n\t\tlaunchPlan := &admin.LaunchPlan{\n\t\t\tSpec: &admin.LaunchPlanSpec{},\n\t\t}\n\t\texecConfig, err := executionManager.getExecutionConfig(context.TODO(), request, launchPlan)\n\t\tassert.NoError(t, err)\n\t\tassert.Equal(t, rmMaxParallelism, execConfig.MaxParallelism)\n\t\tassert.Nil(t, execConfig.GetInterruptible())\n\t\tassert.False(t, execConfig.OverwriteCache)\n\t\tassert.Equal(t, rmK8sServiceAccount, execConfig.SecurityContext.RunAs.K8SServiceAccount)\n\t\tassert.Nil(t, execConfig.GetRawOutputDataConfig())\n\t\tassert.Nil(t, execConfig.GetLabels())\n\t\tassert.Equal(t, rmAnnotations, execConfig.GetAnnotations().Values)\n\t\tassert.Nil(t, execConfig.GetEnvs())\n\t})\n\tt.Run(\"matchable resource with no config\", func(t *testing.T) {\n\t\tresourceManager.GetResourceFunc = func(ctx context.Context,\n\t\t\trequest managerInterfaces.ResourceRequest) (*managerInterfaces.ResourceResponse, error) {\n\t\t\tassert.Contains(t, []managerInterfaces.ResourceRequest{{\n\t\t\t\tProject:      workflowIdentifier.Project,\n\t\t\t\tDomain:       workflowIdentifier.Domain,\n\t\t\t\tResourceType: admin.MatchableResource_WORKFLOW_EXECUTION_CONFIG,\n\t\t\t}, {Project: workflowIdentifier.Project,\n\t\t\t\tDomain:       \"\",\n\t\t\t\tResourceType: admin.MatchableResource_WORKFLOW_EXECUTION_CONFIG},\n\t\t\t}, request)\n\t\t\treturn &managerInterfaces.ResourceResponse{\n\t\t\t\tAttributes: &admin.MatchingAttributes{\n\t\t\t\t\tTarget: &admin.MatchingAttributes_WorkflowExecutionConfig{\n\t\t\t\t\t\tWorkflowExecutionConfig: &admin.WorkflowExecutionConfig{},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t}, nil\n\t\t}\n\t\trequest := &admin.ExecutionCreateRequest{\n\t\t\tProject: workflowIdentifier.Project,\n\t\t\tDomain:  workflowIdentifier.Domain,\n\t\t\tSpec:    &admin.ExecutionSpec{},\n\t\t}\n\t\tlaunchPlan := &admin.LaunchPlan{\n\t\t\tSpec: &admin.LaunchPlanSpec{},\n\t\t}\n\t\texecConfig, err := executionManager.getExecutionConfig(context.TODO(), request, launchPlan)\n\t\tassert.NoError(t, err)\n\t\tassert.Equal(t, defaultMaxParallelism, execConfig.MaxParallelism)\n\t\tassert.Nil(t, execConfig.GetInterruptible())\n\t\tassert.False(t, execConfig.OverwriteCache)\n\t\tassert.Equal(t, defaultK8sServiceAccount, execConfig.SecurityContext.RunAs.K8SServiceAccount)\n\t\tassert.Nil(t, execConfig.GetRawOutputDataConfig())\n\t\tassert.Nil(t, execConfig.GetLabels())\n\t\tassert.Nil(t, execConfig.GetAnnotations())\n\t\tassert.Nil(t, execConfig.GetEnvs())\n\t})\n\tt.Run(\"fetch security context from deprecated config\", func(t *testing.T) {\n\t\tresourceManager.GetResourceFunc = func(ctx context.Context,\n\t\t\trequest managerInterfaces.ResourceRequest) (*managerInterfaces.ResourceResponse, error) {\n\t\t\tassert.Contains(t, []managerInterfaces.ResourceRequest{{\n\t\t\t\tProject:      workflowIdentifier.Project,\n\t\t\t\tDomain:       workflowIdentifier.Domain,\n\t\t\t\tResourceType: admin.MatchableResource_WORKFLOW_EXECUTION_CONFIG,\n\t\t\t}, {Project: workflowIdentifier.Project,\n\t\t\t\tDomain:       \"\",\n\t\t\t\tResourceType: admin.MatchableResource_WORKFLOW_EXECUTION_CONFIG},\n\t\t\t}, request)\n\n\t\t\treturn &managerInterfaces.ResourceResponse{\n\t\t\t\tAttributes: &admin.MatchingAttributes{\n\t\t\t\t\tTarget: &admin.MatchingAttributes_WorkflowExecutionConfig{\n\t\t\t\t\t\tWorkflowExecutionConfig: &admin.WorkflowExecutionConfig{},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t}, nil\n\t\t}\n\t\trequest := &admin.ExecutionCreateRequest{\n\t\t\tProject: workflowIdentifier.Project,\n\t\t\tDomain:  workflowIdentifier.Domain,\n\t\t\tSpec:    &admin.ExecutionSpec{},\n\t\t}\n\t\tlaunchPlan := &admin.LaunchPlan{\n\t\t\tSpec: &admin.LaunchPlanSpec{\n\t\t\t\tAuthRole: &admin.AuthRole{\n\t\t\t\t\tKubernetesServiceAccount: deprecatedLaunchPlanK8sServiceAccount,\n\t\t\t\t},\n\t\t\t},\n\t\t}\n\t\texecConfig, err := executionManager.getExecutionConfig(context.TODO(), request, launchPlan)\n\t\tassert.NoError(t, err)\n\t\tassert.Equal(t, defaultMaxParallelism, execConfig.MaxParallelism)\n\t\tassert.Nil(t, execConfig.GetInterruptible())\n\t\tassert.False(t, execConfig.OverwriteCache)\n\t\tassert.Equal(t, deprecatedLaunchPlanK8sServiceAccount, execConfig.SecurityContext.RunAs.K8SServiceAccount)\n\t\tassert.Nil(t, execConfig.GetRawOutputDataConfig())\n\t\tassert.Nil(t, execConfig.GetLabels())\n\t\tassert.Nil(t, execConfig.GetAnnotations())\n\t\tassert.Nil(t, execConfig.GetEnvs())\n\t})\n\tt.Run(\"matchable resource workflow resource\", func(t *testing.T) {\n\t\tresourceManager.GetResourceFunc = func(ctx context.Context,\n\t\t\trequest managerInterfaces.ResourceRequest) (*managerInterfaces.ResourceResponse, error) {\n\t\t\tassert.Contains(t, []managerInterfaces.ResourceRequest{{\n\t\t\t\tProject:      workflowIdentifier.Project,\n\t\t\t\tDomain:       workflowIdentifier.Domain,\n\t\t\t\tResourceType: admin.MatchableResource_WORKFLOW_EXECUTION_CONFIG,\n\t\t\t\tWorkflow:     workflowIdentifier.Name,\n\t\t\t}, {Project: workflowIdentifier.Project,\n\t\t\t\tDomain:       \"\",\n\t\t\t\tWorkflow:     \"\",\n\t\t\t\tResourceType: admin.MatchableResource_WORKFLOW_EXECUTION_CONFIG},\n\t\t\t}, request)\n\n\t\t\treturn &managerInterfaces.ResourceResponse{\n\t\t\t\tAttributes: &admin.MatchingAttributes{\n\t\t\t\t\tTarget: &admin.MatchingAttributes_WorkflowExecutionConfig{\n\t\t\t\t\t\tWorkflowExecutionConfig: &admin.WorkflowExecutionConfig{\n\t\t\t\t\t\t\tMaxParallelism: 300,\n\t\t\t\t\t\t\tInterruptible:  &wrappers.BoolValue{Value: true},\n\t\t\t\t\t\t\tOverwriteCache: true,\n\t\t\t\t\t\t\tSecurityContext: &core.SecurityContext{\n\t\t\t\t\t\t\t\tRunAs: &core.Identity{\n\t\t\t\t\t\t\t\t\tK8SServiceAccount: \"workflowDefault\",\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t}, nil\n\t\t}\n\t\trequest := &admin.ExecutionCreateRequest{\n\t\t\tProject: workflowIdentifier.Project,\n\t\t\tDomain:  workflowIdentifier.Domain,\n\t\t\tSpec:    &admin.ExecutionSpec{},\n\t\t}\n\t\tlaunchPlan := &admin.LaunchPlan{\n\t\t\tSpec: &admin.LaunchPlanSpec{\n\t\t\t\tWorkflowId: &core.Identifier{\n\t\t\t\t\tName: workflowIdentifier.Name,\n\t\t\t\t},\n\t\t\t},\n\t\t}\n\t\texecConfig, err := executionManager.getExecutionConfig(context.TODO(), request, launchPlan)\n\t\tassert.NoError(t, err)\n\t\tassert.Equal(t, int32(300), execConfig.MaxParallelism)\n\t\tassert.True(t, execConfig.Interruptible.Value)\n\t\tassert.True(t, execConfig.OverwriteCache)\n\t\tassert.Equal(t, \"workflowDefault\", execConfig.SecurityContext.RunAs.K8SServiceAccount)\n\t\tassert.Nil(t, execConfig.GetRawOutputDataConfig())\n\t\tassert.Nil(t, execConfig.GetLabels())\n\t\tassert.Nil(t, execConfig.GetAnnotations())\n\t\tassert.Nil(t, execConfig.GetEnvs())\n\t})\n\tt.Run(\"matchable resource failure\", func(t *testing.T) {\n\t\tresourceManager.GetResourceFunc = func(ctx context.Context,\n\t\t\trequest managerInterfaces.ResourceRequest) (*managerInterfaces.ResourceResponse, error) {\n\t\t\tassert.Contains(t, []managerInterfaces.ResourceRequest{{\n\t\t\t\tProject:      workflowIdentifier.Project,\n\t\t\t\tDomain:       workflowIdentifier.Domain,\n\t\t\t\tResourceType: admin.MatchableResource_WORKFLOW_EXECUTION_CONFIG,\n\t\t\t}, {Project: workflowIdentifier.Project,\n\t\t\t\tDomain:       \"\",\n\t\t\t\tResourceType: admin.MatchableResource_WORKFLOW_EXECUTION_CONFIG},\n\t\t\t}, request)\n\t\t\treturn nil, fmt.Errorf(\"failed to fetch the resources\")\n\t\t}\n\t\trequest := &admin.ExecutionCreateRequest{\n\t\t\tProject: workflowIdentifier.Project,\n\t\t\tDomain:  workflowIdentifier.Domain,\n\t\t\tSpec:    &admin.ExecutionSpec{},\n\t\t}\n\t\tlaunchPlan := &admin.LaunchPlan{\n\t\t\tSpec: &admin.LaunchPlanSpec{},\n\t\t}\n\t\texecConfig, err := executionManager.getExecutionConfig(context.TODO(), request, launchPlan)\n\t\tassert.Equal(t, fmt.Errorf(\"failed to fetch the resources\"), err)\n\t\tassert.Nil(t, execConfig.GetInterruptible())\n\t\tassert.False(t, execConfig.GetOverwriteCache())\n\t\tassert.Nil(t, execConfig.GetSecurityContext())\n\t\tassert.Nil(t, execConfig.GetRawOutputDataConfig())\n\t\tassert.Nil(t, execConfig.GetLabels())\n\t\tassert.Nil(t, execConfig.GetAnnotations())\n\t\tassert.Nil(t, execConfig.GetEnvs())\n\t})\n\n\tt.Run(\"application configuration\", func(t *testing.T) {\n\t\tresourceManager.GetResourceFunc = func(ctx context.Context,\n\t\t\trequest managerInterfaces.ResourceRequest) (*managerInterfaces.ResourceResponse, error) {\n\t\t\tassert.Contains(t, []managerInterfaces.ResourceRequest{{\n\t\t\t\tProject:      workflowIdentifier.Project,\n\t\t\t\tDomain:       workflowIdentifier.Domain,\n\t\t\t\tResourceType: admin.MatchableResource_WORKFLOW_EXECUTION_CONFIG,\n\t\t\t}, {Project: workflowIdentifier.Project,\n\t\t\t\tDomain:       \"\",\n\t\t\t\tResourceType: admin.MatchableResource_WORKFLOW_EXECUTION_CONFIG},\n\t\t\t}, request)\n\t\t\treturn &managerInterfaces.ResourceResponse{\n\t\t\t\tAttributes: &admin.MatchingAttributes{\n\t\t\t\t\tTarget: &admin.MatchingAttributes_WorkflowExecutionConfig{\n\t\t\t\t\t\tWorkflowExecutionConfig: &admin.WorkflowExecutionConfig{},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t}, nil\n\t\t}\n\n\t\texecutionManager.config.ApplicationConfiguration().GetTopLevelConfig().Interruptible = true\n\t\texecutionManager.config.ApplicationConfiguration().GetTopLevelConfig().OverwriteCache = true\n\n\t\tt.Run(\"request with interruptible override disabled\", func(t *testing.T) {\n\t\t\trequest := &admin.ExecutionCreateRequest{\n\t\t\t\tProject: workflowIdentifier.Project,\n\t\t\t\tDomain:  workflowIdentifier.Domain,\n\t\t\t\tSpec: &admin.ExecutionSpec{\n\t\t\t\t\tInterruptible: &wrappers.BoolValue{Value: false},\n\t\t\t\t},\n\t\t\t}\n\n\t\t\texecConfig, err := executionManager.getExecutionConfig(context.TODO(), request, nil)\n\t\t\tassert.NoError(t, err)\n\t\t\tassert.Equal(t, defaultMaxParallelism, execConfig.MaxParallelism)\n\t\t\tassert.False(t, execConfig.Interruptible.Value)\n\t\t\tassert.Equal(t, defaultK8sServiceAccount, execConfig.SecurityContext.RunAs.K8SServiceAccount)\n\t\t\tassert.Nil(t, execConfig.GetRawOutputDataConfig())\n\t\t\tassert.Nil(t, execConfig.GetLabels())\n\t\t\tassert.Nil(t, execConfig.GetAnnotations())\n\t\t})\n\t\tt.Run(\"request with interruptible override enabled\", func(t *testing.T) {\n\t\t\trequest := &admin.ExecutionCreateRequest{\n\t\t\t\tProject: workflowIdentifier.Project,\n\t\t\t\tDomain:  workflowIdentifier.Domain,\n\t\t\t\tSpec: &admin.ExecutionSpec{\n\t\t\t\t\tInterruptible: &wrappers.BoolValue{Value: true},\n\t\t\t\t},\n\t\t\t}\n\n\t\t\texecConfig, err := executionManager.getExecutionConfig(context.TODO(), request, nil)\n\t\t\tassert.NoError(t, err)\n\t\t\tassert.Equal(t, defaultMaxParallelism, execConfig.MaxParallelism)\n\t\t\tassert.True(t, execConfig.Interruptible.Value)\n\t\t\tassert.Equal(t, defaultK8sServiceAccount, execConfig.SecurityContext.RunAs.K8SServiceAccount)\n\t\t\tassert.Nil(t, execConfig.GetRawOutputDataConfig())\n\t\t\tassert.Nil(t, execConfig.GetLabels())\n\t\t\tassert.Nil(t, execConfig.GetAnnotations())\n\t\t})\n\t\tt.Run(\"request with no interruptible override specified\", func(t *testing.T) {\n\t\t\trequest := &admin.ExecutionCreateRequest{\n\t\t\t\tProject: workflowIdentifier.Project,\n\t\t\t\tDomain:  workflowIdentifier.Domain,\n\t\t\t\tSpec:    &admin.ExecutionSpec{},\n\t\t\t}\n\n\t\t\texecConfig, err := executionManager.getExecutionConfig(context.TODO(), request, nil)\n\t\t\tassert.NoError(t, err)\n\t\t\tassert.Equal(t, defaultMaxParallelism, execConfig.MaxParallelism)\n\t\t\tassert.True(t, execConfig.Interruptible.Value)\n\t\t\tassert.Equal(t, defaultK8sServiceAccount, execConfig.SecurityContext.RunAs.K8SServiceAccount)\n\t\t\tassert.Nil(t, execConfig.GetRawOutputDataConfig())\n\t\t\tassert.Nil(t, execConfig.GetLabels())\n\t\t\tassert.Nil(t, execConfig.GetAnnotations())\n\t\t})\n\t\tt.Run(\"launch plan with interruptible override disabled\", func(t *testing.T) {\n\t\t\trequest := &admin.ExecutionCreateRequest{\n\t\t\t\tProject: workflowIdentifier.Project,\n\t\t\t\tDomain:  workflowIdentifier.Domain,\n\t\t\t\tSpec:    &admin.ExecutionSpec{},\n\t\t\t}\n\n\t\t\tlaunchPlan := &admin.LaunchPlan{\n\t\t\t\tSpec: &admin.LaunchPlanSpec{\n\t\t\t\t\tInterruptible: &wrappers.BoolValue{Value: false},\n\t\t\t\t},\n\t\t\t}\n\n\t\t\texecConfig, err := executionManager.getExecutionConfig(context.TODO(), request, launchPlan)\n\t\t\tassert.NoError(t, err)\n\t\t\tassert.Equal(t, defaultMaxParallelism, execConfig.MaxParallelism)\n\t\t\tassert.False(t, execConfig.Interruptible.Value)\n\t\t\tassert.Equal(t, defaultK8sServiceAccount, execConfig.SecurityContext.RunAs.K8SServiceAccount)\n\t\t\tassert.Nil(t, execConfig.GetRawOutputDataConfig())\n\t\t\tassert.Nil(t, execConfig.GetLabels())\n\t\t\tassert.Nil(t, execConfig.GetAnnotations())\n\t\t})\n\t\tt.Run(\"launch plan with interruptible override enabled\", func(t *testing.T) {\n\t\t\trequest := &admin.ExecutionCreateRequest{\n\t\t\t\tProject: workflowIdentifier.Project,\n\t\t\t\tDomain:  workflowIdentifier.Domain,\n\t\t\t\tSpec:    &admin.ExecutionSpec{},\n\t\t\t}\n\n\t\t\tlaunchPlan := &admin.LaunchPlan{\n\t\t\t\tSpec: &admin.LaunchPlanSpec{\n\t\t\t\t\tInterruptible: &wrappers.BoolValue{Value: true},\n\t\t\t\t\tEnvs:          &admin.Envs{Values: []*core.KeyValuePair{{Key: \"foo\", Value: \"bar\"}}},\n\t\t\t\t},\n\t\t\t}\n\n\t\t\texecConfig, err := executionManager.getExecutionConfig(context.TODO(), request, launchPlan)\n\t\t\tassert.NoError(t, err)\n\t\t\tassert.Equal(t, defaultMaxParallelism, execConfig.MaxParallelism)\n\t\t\tassert.True(t, execConfig.Interruptible.Value)\n\t\t\tassert.Equal(t, defaultK8sServiceAccount, execConfig.SecurityContext.RunAs.K8SServiceAccount)\n\t\t\tassert.Nil(t, execConfig.GetRawOutputDataConfig())\n\t\t\tassert.Nil(t, execConfig.GetLabels())\n\t\t\tassert.Nil(t, execConfig.GetAnnotations())\n\t\t\tassert.Equal(t, 1, len(execConfig.Envs.Values))\n\t\t\tassert.Equal(t, \"foo\", execConfig.Envs.Values[0].Key)\n\t\t\tassert.Equal(t, \"bar\", execConfig.Envs.Values[0].Value)\n\t\t})\n\t\tt.Run(\"launch plan with no interruptible override specified\", func(t *testing.T) {\n\t\t\trequest := &admin.ExecutionCreateRequest{\n\t\t\t\tProject: workflowIdentifier.Project,\n\t\t\t\tDomain:  workflowIdentifier.Domain,\n\t\t\t\tSpec:    &admin.ExecutionSpec{},\n\t\t\t}\n\n\t\t\tlaunchPlan := &admin.LaunchPlan{\n\t\t\t\tSpec: &admin.LaunchPlanSpec{},\n\t\t\t}\n\n\t\t\texecConfig, err := executionManager.getExecutionConfig(context.TODO(), request, launchPlan)\n\t\t\tassert.NoError(t, err)\n\t\t\tassert.Equal(t, defaultMaxParallelism, execConfig.MaxParallelism)\n\t\t\tassert.True(t, execConfig.Interruptible.Value)\n\t\t\tassert.Equal(t, defaultK8sServiceAccount, execConfig.SecurityContext.RunAs.K8SServiceAccount)\n\t\t\tassert.Nil(t, execConfig.GetRawOutputDataConfig())\n\t\t\tassert.Nil(t, execConfig.GetLabels())\n\t\t\tassert.Nil(t, execConfig.GetAnnotations())\n\t\t})\n\t\tt.Run(\"request and launch plan with different interruptible overrides\", func(t *testing.T) {\n\t\t\trequest := &admin.ExecutionCreateRequest{\n\t\t\t\tProject: workflowIdentifier.Project,\n\t\t\t\tDomain:  workflowIdentifier.Domain,\n\t\t\t\tSpec: &admin.ExecutionSpec{\n\t\t\t\t\tInterruptible: &wrappers.BoolValue{Value: true},\n\t\t\t\t},\n\t\t\t}\n\n\t\t\tlaunchPlan := &admin.LaunchPlan{\n\t\t\t\tSpec: &admin.LaunchPlanSpec{\n\t\t\t\t\tInterruptible: &wrappers.BoolValue{Value: false},\n\t\t\t\t},\n\t\t\t}\n\n\t\t\texecConfig, err := executionManager.getExecutionConfig(context.TODO(), request, launchPlan)\n\t\t\tassert.NoError(t, err)\n\t\t\tassert.Equal(t, defaultMaxParallelism, execConfig.MaxParallelism)\n\t\t\tassert.True(t, execConfig.Interruptible.Value)\n\t\t\tassert.Equal(t, defaultK8sServiceAccount, execConfig.SecurityContext.RunAs.K8SServiceAccount)\n\t\t\tassert.Nil(t, execConfig.GetRawOutputDataConfig())\n\t\t\tassert.Nil(t, execConfig.GetLabels())\n\t\t\tassert.Nil(t, execConfig.GetAnnotations())\n\t\t})\n\t\tt.Run(\"request with skip cache override enabled\", func(t *testing.T) {\n\t\t\trequest := &admin.ExecutionCreateRequest{\n\t\t\t\tProject: workflowIdentifier.Project,\n\t\t\t\tDomain:  workflowIdentifier.Domain,\n\t\t\t\tSpec: &admin.ExecutionSpec{\n\t\t\t\t\tOverwriteCache: true,\n\t\t\t\t},\n\t\t\t}\n\n\t\t\texecConfig, err := executionManager.getExecutionConfig(context.TODO(), request, nil)\n\t\t\tassert.NoError(t, err)\n\t\t\tassert.Equal(t, defaultMaxParallelism, execConfig.MaxParallelism)\n\t\t\tassert.True(t, execConfig.OverwriteCache)\n\t\t\tassert.Equal(t, defaultK8sServiceAccount, execConfig.SecurityContext.RunAs.K8SServiceAccount)\n\t\t\tassert.Nil(t, execConfig.GetRawOutputDataConfig())\n\t\t\tassert.Nil(t, execConfig.GetLabels())\n\t\t\tassert.Nil(t, execConfig.GetAnnotations())\n\t\t})\n\t\tt.Run(\"request with no skip cache override specified\", func(t *testing.T) {\n\t\t\trequest := &admin.ExecutionCreateRequest{\n\t\t\t\tProject: workflowIdentifier.Project,\n\t\t\t\tDomain:  workflowIdentifier.Domain,\n\t\t\t\tSpec:    &admin.ExecutionSpec{},\n\t\t\t}\n\n\t\t\texecConfig, err := executionManager.getExecutionConfig(context.TODO(), request, nil)\n\t\t\tassert.NoError(t, err)\n\t\t\tassert.Equal(t, defaultMaxParallelism, execConfig.MaxParallelism)\n\t\t\tassert.True(t, execConfig.OverwriteCache)\n\t\t\tassert.Equal(t, defaultK8sServiceAccount, execConfig.SecurityContext.RunAs.K8SServiceAccount)\n\t\t\tassert.Nil(t, execConfig.GetRawOutputDataConfig())\n\t\t\tassert.Nil(t, execConfig.GetLabels())\n\t\t\tassert.Nil(t, execConfig.GetAnnotations())\n\t\t})\n\t\tt.Run(\"launch plan with skip cache override enabled\", func(t *testing.T) {\n\t\t\trequest := &admin.ExecutionCreateRequest{\n\t\t\t\tProject: workflowIdentifier.Project,\n\t\t\t\tDomain:  workflowIdentifier.Domain,\n\t\t\t\tSpec:    &admin.ExecutionSpec{},\n\t\t\t}\n\n\t\t\tlaunchPlan := &admin.LaunchPlan{\n\t\t\t\tSpec: &admin.LaunchPlanSpec{\n\t\t\t\t\tOverwriteCache: true,\n\t\t\t\t},\n\t\t\t}\n\n\t\t\texecConfig, err := executionManager.getExecutionConfig(context.TODO(), request, launchPlan)\n\t\t\tassert.NoError(t, err)\n\t\t\tassert.Equal(t, defaultMaxParallelism, execConfig.MaxParallelism)\n\t\t\tassert.True(t, execConfig.OverwriteCache)\n\t\t\tassert.Equal(t, defaultK8sServiceAccount, execConfig.SecurityContext.RunAs.K8SServiceAccount)\n\t\t\tassert.Nil(t, execConfig.GetRawOutputDataConfig())\n\t\t\tassert.Nil(t, execConfig.GetLabels())\n\t\t\tassert.Nil(t, execConfig.GetAnnotations())\n\t\t})\n\t\tt.Run(\"launch plan with no skip cache override specified\", func(t *testing.T) {\n\t\t\trequest := &admin.ExecutionCreateRequest{\n\t\t\t\tProject: workflowIdentifier.Project,\n\t\t\t\tDomain:  workflowIdentifier.Domain,\n\t\t\t\tSpec:    &admin.ExecutionSpec{},\n\t\t\t}\n\n\t\t\tlaunchPlan := &admin.LaunchPlan{\n\t\t\t\tSpec: &admin.LaunchPlanSpec{},\n\t\t\t}\n\n\t\t\texecConfig, err := executionManager.getExecutionConfig(context.TODO(), request, launchPlan)\n\t\t\tassert.NoError(t, err)\n\t\t\tassert.Equal(t, defaultMaxParallelism, execConfig.MaxParallelism)\n\t\t\tassert.True(t, execConfig.OverwriteCache)\n\t\t\tassert.Equal(t, defaultK8sServiceAccount, execConfig.SecurityContext.RunAs.K8SServiceAccount)\n\t\t\tassert.Nil(t, execConfig.GetRawOutputDataConfig())\n\t\t\tassert.Nil(t, execConfig.GetLabels())\n\t\t\tassert.Nil(t, execConfig.GetAnnotations())\n\t\t})\n\t\tt.Run(\"request and launch plan with different skip cache overrides\", func(t *testing.T) {\n\t\t\trequest := &admin.ExecutionCreateRequest{\n\t\t\t\tProject: workflowIdentifier.Project,\n\t\t\t\tDomain:  workflowIdentifier.Domain,\n\t\t\t\tSpec: &admin.ExecutionSpec{\n\t\t\t\t\tOverwriteCache: true,\n\t\t\t\t},\n\t\t\t}\n\n\t\t\tlaunchPlan := &admin.LaunchPlan{\n\t\t\t\tSpec: &admin.LaunchPlanSpec{\n\t\t\t\t\tOverwriteCache: false,\n\t\t\t\t},\n\t\t\t}\n\n\t\t\texecConfig, err := executionManager.getExecutionConfig(context.TODO(), request, launchPlan)\n\t\t\tassert.NoError(t, err)\n\t\t\tassert.Equal(t, defaultMaxParallelism, execConfig.MaxParallelism)\n\t\t\tassert.True(t, execConfig.OverwriteCache)\n\t\t\tassert.Equal(t, defaultK8sServiceAccount, execConfig.SecurityContext.RunAs.K8SServiceAccount)\n\t\t\tassert.Nil(t, execConfig.GetRawOutputDataConfig())\n\t\t\tassert.Nil(t, execConfig.GetLabels())\n\t\t\tassert.Nil(t, execConfig.GetAnnotations())\n\t\t})\n\n\t\tt.Run(\"test pick up security context from admin system config\", func(t *testing.T) {\n\t\t\texecutionManager.config.ApplicationConfiguration().GetTopLevelConfig().K8SServiceAccount = \"flyte-test\"\n\t\t\trequest := &admin.ExecutionCreateRequest{\n\t\t\t\tProject: workflowIdentifier.Project,\n\t\t\t\tDomain:  workflowIdentifier.Domain,\n\t\t\t\tSpec:    &admin.ExecutionSpec{},\n\t\t\t}\n\t\t\texecConfig, err := executionManager.getExecutionConfig(context.TODO(), request, nil)\n\t\t\tassert.NoError(t, err)\n\t\t\tassert.Equal(t, \"flyte-test\", execConfig.SecurityContext.RunAs.K8SServiceAccount)\n\t\t\texecutionManager.config.ApplicationConfiguration().GetTopLevelConfig().K8SServiceAccount = defaultK8sServiceAccount\n\t\t})\n\t})\n}\n\nfunc TestGetExecutionConfig(t *testing.T) {\n\tresourceManager := managerMocks.MockResourceManager{}\n\tresourceManager.GetResourceFunc = func(ctx context.Context,\n\t\trequest managerInterfaces.ResourceRequest) (*managerInterfaces.ResourceResponse, error) {\n\t\tassert.Contains(t, []managerInterfaces.ResourceRequest{{\n\t\t\tProject:      workflowIdentifier.Project,\n\t\t\tDomain:       workflowIdentifier.Domain,\n\t\t\tResourceType: admin.MatchableResource_WORKFLOW_EXECUTION_CONFIG,\n\t\t}, {Project: workflowIdentifier.Project,\n\t\t\tDomain:       \"\",\n\t\t\tResourceType: admin.MatchableResource_WORKFLOW_EXECUTION_CONFIG},\n\t\t}, request)\n\t\treturn &managerInterfaces.ResourceResponse{\n\t\t\tAttributes: &admin.MatchingAttributes{\n\t\t\t\tTarget: &admin.MatchingAttributes_WorkflowExecutionConfig{\n\t\t\t\t\tWorkflowExecutionConfig: &admin.WorkflowExecutionConfig{\n\t\t\t\t\t\tMaxParallelism: 100,\n\t\t\t\t\t\tOverwriteCache: true,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t}, nil\n\t}\n\n\tapplicationConfig := runtime.NewConfigurationProvider()\n\texecutionManager := ExecutionManager{\n\t\tresourceManager: &resourceManager,\n\t\tconfig:          applicationConfig,\n\t}\n\texecConfig, err := executionManager.getExecutionConfig(context.TODO(), &admin.ExecutionCreateRequest{\n\t\tProject: workflowIdentifier.Project,\n\t\tDomain:  workflowIdentifier.Domain,\n\t\tSpec:    &admin.ExecutionSpec{},\n\t}, nil)\n\tassert.NoError(t, err)\n\tassert.Equal(t, execConfig.MaxParallelism, int32(100))\n\tassert.True(t, execConfig.OverwriteCache)\n}\n\nfunc TestGetExecutionConfig_Spec(t *testing.T) {\n\tresourceManager := managerMocks.MockResourceManager{}\n\tresourceManager.GetResourceFunc = func(ctx context.Context,\n\t\trequest managerInterfaces.ResourceRequest) (*managerInterfaces.ResourceResponse, error) {\n\t\treturn nil, nil\n\t}\n\tapplicationConfig := runtime.NewConfigurationProvider()\n\texecutionManager := ExecutionManager{\n\t\tresourceManager: &resourceManager,\n\t\tconfig:          applicationConfig,\n\t}\n\texecConfig, err := executionManager.getExecutionConfig(context.TODO(), &admin.ExecutionCreateRequest{\n\t\tProject: workflowIdentifier.Project,\n\t\tDomain:  workflowIdentifier.Domain,\n\t\tSpec: &admin.ExecutionSpec{\n\t\t\tMaxParallelism: 100,\n\t\t\tOverwriteCache: true,\n\t\t},\n\t}, &admin.LaunchPlan{\n\t\tSpec: &admin.LaunchPlanSpec{\n\t\t\tMaxParallelism: 50,\n\t\t\tOverwriteCache: false, // explicitly set to false for clarity\n\t\t},\n\t})\n\tassert.NoError(t, err)\n\tassert.Equal(t, int32(100), execConfig.MaxParallelism)\n\tassert.True(t, execConfig.OverwriteCache)\n\n\texecConfig, err = executionManager.getExecutionConfig(context.TODO(), &admin.ExecutionCreateRequest{\n\t\tProject: workflowIdentifier.Project,\n\t\tDomain:  workflowIdentifier.Domain,\n\t\tSpec:    &admin.ExecutionSpec{},\n\t}, &admin.LaunchPlan{\n\t\tSpec: &admin.LaunchPlanSpec{\n\t\t\tMaxParallelism: 50,\n\t\t\tOverwriteCache: true,\n\t\t},\n\t})\n\tassert.NoError(t, err)\n\tassert.Equal(t, int32(50), execConfig.MaxParallelism)\n\tassert.True(t, execConfig.OverwriteCache)\n\n\tresourceManager = managerMocks.MockResourceManager{}\n\tresourceManager.GetResourceFunc = func(ctx context.Context,\n\t\trequest managerInterfaces.ResourceRequest) (*managerInterfaces.ResourceResponse, error) {\n\t\treturn nil, nil\n\t}\n\texecutionManager = ExecutionManager{\n\t\tresourceManager: &resourceManager,\n\t\tconfig:          applicationConfig,\n\t}\n\n\texecutionManager.config.ApplicationConfiguration().GetTopLevelConfig().OverwriteCache = true\n\n\texecConfig, err = executionManager.getExecutionConfig(context.TODO(), &admin.ExecutionCreateRequest{\n\t\tProject: workflowIdentifier.Project,\n\t\tDomain:  workflowIdentifier.Domain,\n\t\tSpec:    &admin.ExecutionSpec{},\n\t}, &admin.LaunchPlan{\n\t\tSpec: &admin.LaunchPlanSpec{},\n\t})\n\tassert.NoError(t, err)\n\tassert.Equal(t, execConfig.MaxParallelism, int32(25))\n\tassert.True(t, execConfig.OverwriteCache)\n}\n\nfunc TestGetClusterAssignment(t *testing.T) {\n\tclusterAssignment := admin.ClusterAssignment{ClusterPoolName: \"gpu\"}\n\tresourceManager := managerMocks.MockResourceManager{}\n\tresourceManager.GetResourceFunc = func(ctx context.Context,\n\t\trequest managerInterfaces.ResourceRequest) (*managerInterfaces.ResourceResponse, error) {\n\t\tassert.EqualValues(t, request, managerInterfaces.ResourceRequest{\n\t\t\tProject:      workflowIdentifier.Project,\n\t\t\tDomain:       workflowIdentifier.Domain,\n\t\t\tResourceType: admin.MatchableResource_CLUSTER_ASSIGNMENT,\n\t\t})\n\t\treturn &managerInterfaces.ResourceResponse{\n\t\t\tAttributes: &admin.MatchingAttributes{\n\t\t\t\tTarget: &admin.MatchingAttributes_ClusterAssignment{\n\t\t\t\t\tClusterAssignment: &clusterAssignment,\n\t\t\t\t},\n\t\t\t},\n\t\t}, nil\n\t}\n\n\texecutionManager := ExecutionManager{\n\t\tresourceManager: &resourceManager,\n\t}\n\tt.Run(\"value from db\", func(t *testing.T) {\n\t\tca, err := executionManager.getClusterAssignment(context.TODO(), &admin.ExecutionCreateRequest{\n\t\t\tProject: workflowIdentifier.Project,\n\t\t\tDomain:  workflowIdentifier.Domain,\n\t\t\tSpec:    &admin.ExecutionSpec{},\n\t\t})\n\t\tassert.NoError(t, err)\n\t\tassert.True(t, proto.Equal(ca, &clusterAssignment))\n\t})\n\tt.Run(\"value from request\", func(t *testing.T) {\n\t\treqClusterAssignment := admin.ClusterAssignment{ClusterPoolName: \"swimming-pool\"}\n\t\tca, err := executionManager.getClusterAssignment(context.TODO(), &admin.ExecutionCreateRequest{\n\t\t\tProject: workflowIdentifier.Project,\n\t\t\tDomain:  workflowIdentifier.Domain,\n\t\t\tSpec: &admin.ExecutionSpec{\n\t\t\t\tClusterAssignment: &reqClusterAssignment,\n\t\t\t},\n\t\t})\n\t\tassert.NoError(t, err)\n\t\tassert.True(t, proto.Equal(ca, &reqClusterAssignment))\n\t})\n\tt.Run(\"value from config\", func(t *testing.T) {\n\t\tcustomCP := \"my_cp\"\n\t\tclusterPoolAsstProvider := &runtimeIFaceMocks.ClusterPoolAssignmentConfiguration{}\n\t\tclusterPoolAsstProvider.OnGetClusterPoolAssignments().Return(runtimeInterfaces.ClusterPoolAssignments{\n\t\t\tworkflowIdentifier.GetDomain(): runtimeInterfaces.ClusterPoolAssignment{\n\t\t\t\tPool: customCP,\n\t\t\t},\n\t\t})\n\t\tmockConfig := getMockExecutionsConfigProvider()\n\t\tmockConfig.(*runtimeMocks.MockConfigurationProvider).AddClusterPoolAssignmentConfiguration(clusterPoolAsstProvider)\n\n\t\texecutionManager := ExecutionManager{\n\t\t\tresourceManager: &managerMocks.MockResourceManager{},\n\t\t\tconfig:          mockConfig,\n\t\t}\n\n\t\tca, err := executionManager.getClusterAssignment(context.TODO(), &admin.ExecutionCreateRequest{\n\t\t\tProject: workflowIdentifier.Project,\n\t\t\tDomain:  workflowIdentifier.Domain,\n\t\t\tSpec:    &admin.ExecutionSpec{},\n\t\t})\n\t\tassert.NoError(t, err)\n\t\tassert.Equal(t, customCP, ca.GetClusterPoolName())\n\t})\n}\n\nfunc TestResolvePermissions(t *testing.T) {\n\tassumableIamRole := \"role\"\n\tk8sServiceAccount := \"sa\"\n\n\tassumableIamRoleLp := \"roleLp\"\n\tk8sServiceAccountLp := \"saLp\"\n\n\tassumableIamRoleSc := \"roleSc\"\n\tk8sServiceAccountSc := \"saSc\"\n\n\tt.Run(\"backward compat use request values from auth\", func(t *testing.T) {\n\t\texecRequest := &admin.ExecutionCreateRequest{\n\t\t\tSpec: &admin.ExecutionSpec{\n\t\t\t\tAuthRole: &admin.AuthRole{\n\t\t\t\t\tAssumableIamRole:         assumableIamRole,\n\t\t\t\t\tKubernetesServiceAccount: k8sServiceAccount,\n\t\t\t\t},\n\t\t\t},\n\t\t}\n\t\tlp := &admin.LaunchPlan{\n\t\t\tSpec: &admin.LaunchPlanSpec{\n\t\t\t\tAuthRole: &admin.AuthRole{\n\t\t\t\t\tAssumableIamRole:         \"lp role\",\n\t\t\t\t\tKubernetesServiceAccount: \"k8s sa\",\n\t\t\t\t},\n\t\t\t},\n\t\t}\n\t\texecConfigSecCtx := &core.SecurityContext{\n\t\t\tRunAs: &core.Identity{\n\t\t\t\tIamRole:           assumableIamRole,\n\t\t\t\tK8SServiceAccount: k8sServiceAccount,\n\t\t\t},\n\t\t}\n\t\tauthRole := resolveAuthRole(execRequest, lp)\n\t\tsc := resolveSecurityCtx(context.TODO(), execConfigSecCtx, authRole)\n\t\tassert.Equal(t, assumableIamRole, authRole.AssumableIamRole)\n\t\tassert.Equal(t, k8sServiceAccount, authRole.KubernetesServiceAccount)\n\t\tassert.Equal(t, &core.SecurityContext{\n\t\t\tRunAs: &core.Identity{\n\t\t\t\tIamRole:           assumableIamRole,\n\t\t\t\tK8SServiceAccount: k8sServiceAccount,\n\t\t\t}}, sc)\n\t})\n\tt.Run(\"use request values security context\", func(t *testing.T) {\n\t\texecRequest := &admin.ExecutionCreateRequest{\n\t\t\tSpec: &admin.ExecutionSpec{\n\t\t\t\tSecurityContext: &core.SecurityContext{\n\t\t\t\t\tRunAs: &core.Identity{\n\t\t\t\t\t\tIamRole:           assumableIamRoleSc,\n\t\t\t\t\t\tK8SServiceAccount: k8sServiceAccountSc,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t}\n\t\tlp := &admin.LaunchPlan{\n\t\t\tSpec: &admin.LaunchPlanSpec{\n\t\t\t\tSecurityContext: &core.SecurityContext{\n\t\t\t\t\tRunAs: &core.Identity{\n\t\t\t\t\t\tIamRole:           assumableIamRoleSc,\n\t\t\t\t\t\tK8SServiceAccount: k8sServiceAccountSc,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t}\n\t\tauthRole := resolveAuthRole(execRequest, lp)\n\t\texecConfigSecCtx := &core.SecurityContext{\n\t\t\tRunAs: &core.Identity{\n\t\t\t\tIamRole:           assumableIamRoleSc,\n\t\t\t\tK8SServiceAccount: k8sServiceAccountSc,\n\t\t\t},\n\t\t}\n\t\tsc := resolveSecurityCtx(context.TODO(), execConfigSecCtx, authRole)\n\t\tassert.Equal(t, \"\", authRole.AssumableIamRole)\n\t\tassert.Equal(t, \"\", authRole.KubernetesServiceAccount)\n\t\tassert.Equal(t, assumableIamRoleSc, sc.RunAs.IamRole)\n\t\tassert.Equal(t, k8sServiceAccountSc, sc.RunAs.K8SServiceAccount)\n\t})\n\tt.Run(\"prefer lp auth role over auth\", func(t *testing.T) {\n\t\texecRequest := &admin.ExecutionCreateRequest{\n\t\t\tSpec: &admin.ExecutionSpec{},\n\t\t}\n\t\tlp := &admin.LaunchPlan{\n\t\t\tSpec: &admin.LaunchPlanSpec{\n\t\t\t\tAuthRole: &admin.AuthRole{\n\t\t\t\t\tAssumableIamRole:         assumableIamRole,\n\t\t\t\t\tKubernetesServiceAccount: k8sServiceAccount,\n\t\t\t\t},\n\t\t\t\tAuth: &admin.Auth{\n\t\t\t\t\tAssumableIamRole:         \"lp role\",\n\t\t\t\t\tKubernetesServiceAccount: \"k8s sa\",\n\t\t\t\t},\n\t\t\t},\n\t\t}\n\t\tauthRole := resolveAuthRole(execRequest, lp)\n\t\texecConfigSecCtx := &core.SecurityContext{\n\t\t\tRunAs: &core.Identity{},\n\t\t}\n\t\tsc := resolveSecurityCtx(context.TODO(), execConfigSecCtx, authRole)\n\t\tassert.Equal(t, assumableIamRole, authRole.AssumableIamRole)\n\t\tassert.Equal(t, k8sServiceAccount, authRole.KubernetesServiceAccount)\n\t\tassert.Equal(t, &core.SecurityContext{\n\t\t\tRunAs: &core.Identity{\n\t\t\t\tIamRole:           assumableIamRole,\n\t\t\t\tK8SServiceAccount: k8sServiceAccount,\n\t\t\t},\n\t\t}, sc)\n\t})\n\tt.Run(\"prefer security context over auth context\", func(t *testing.T) {\n\t\texecRequest := &admin.ExecutionCreateRequest{\n\t\t\tSpec: &admin.ExecutionSpec{\n\t\t\t\tAuthRole: &admin.AuthRole{\n\t\t\t\t\tAssumableIamRole:         assumableIamRole,\n\t\t\t\t\tKubernetesServiceAccount: k8sServiceAccount,\n\t\t\t\t},\n\t\t\t\tSecurityContext: &core.SecurityContext{\n\t\t\t\t\tRunAs: &core.Identity{\n\t\t\t\t\t\tIamRole:           assumableIamRoleSc,\n\t\t\t\t\t\tK8SServiceAccount: k8sServiceAccountSc,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t}\n\t\tlp := &admin.LaunchPlan{\n\t\t\tSpec: &admin.LaunchPlanSpec{\n\t\t\t\tAuthRole: &admin.AuthRole{\n\t\t\t\t\tAssumableIamRole:         assumableIamRole,\n\t\t\t\t\tKubernetesServiceAccount: k8sServiceAccount,\n\t\t\t\t},\n\t\t\t\tSecurityContext: &core.SecurityContext{\n\t\t\t\t\tRunAs: &core.Identity{\n\t\t\t\t\t\tIamRole:           assumableIamRoleSc,\n\t\t\t\t\t\tK8SServiceAccount: k8sServiceAccountSc,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t}\n\t\tauthRole := resolveAuthRole(execRequest, lp)\n\t\texecConfigSecCtx := &core.SecurityContext{\n\t\t\tRunAs: &core.Identity{\n\t\t\t\tIamRole:           assumableIamRoleSc,\n\t\t\t\tK8SServiceAccount: k8sServiceAccountSc,\n\t\t\t},\n\t\t}\n\t\tsc := resolveSecurityCtx(context.TODO(), execConfigSecCtx, authRole)\n\t\tassert.Equal(t, assumableIamRole, authRole.AssumableIamRole)\n\t\tassert.Equal(t, k8sServiceAccount, authRole.KubernetesServiceAccount)\n\t\tassert.Equal(t, assumableIamRoleSc, sc.RunAs.IamRole)\n\t\tassert.Equal(t, k8sServiceAccountSc, sc.RunAs.K8SServiceAccount)\n\t})\n\tt.Run(\"prefer lp auth over role\", func(t *testing.T) {\n\t\texecRequest := &admin.ExecutionCreateRequest{\n\t\t\tSpec: &admin.ExecutionSpec{},\n\t\t}\n\t\tlp := &admin.LaunchPlan{\n\t\t\tSpec: &admin.LaunchPlanSpec{\n\t\t\t\tAuth: &admin.Auth{\n\t\t\t\t\tAssumableIamRole:         assumableIamRole,\n\t\t\t\t\tKubernetesServiceAccount: k8sServiceAccount,\n\t\t\t\t},\n\t\t\t\tRole: \"old role\",\n\t\t\t},\n\t\t}\n\t\tauthRole := resolveAuthRole(execRequest, lp)\n\t\texecConfigSecCtx := &core.SecurityContext{\n\t\t\tRunAs: &core.Identity{\n\t\t\t\tIamRole:           assumableIamRole,\n\t\t\t\tK8SServiceAccount: k8sServiceAccount,\n\t\t\t},\n\t\t}\n\t\tsc := resolveSecurityCtx(context.TODO(), execConfigSecCtx, authRole)\n\t\tassert.Equal(t, assumableIamRole, authRole.AssumableIamRole)\n\t\tassert.Equal(t, k8sServiceAccount, authRole.KubernetesServiceAccount)\n\t\tassert.Equal(t, &core.SecurityContext{\n\t\t\tRunAs: &core.Identity{\n\t\t\t\tIamRole:           assumableIamRole,\n\t\t\t\tK8SServiceAccount: k8sServiceAccount,\n\t\t\t},\n\t\t}, sc)\n\t})\n\tt.Run(\"prefer lp auth over role\", func(t *testing.T) {\n\t\tauthRole := resolveAuthRole(&admin.ExecutionCreateRequest{\n\t\t\tSpec: &admin.ExecutionSpec{},\n\t\t}, &admin.LaunchPlan{\n\t\t\tSpec: &admin.LaunchPlanSpec{\n\t\t\t\tAuth: &admin.Auth{\n\t\t\t\t\tAssumableIamRole:         assumableIamRoleLp,\n\t\t\t\t\tKubernetesServiceAccount: k8sServiceAccountLp,\n\t\t\t\t},\n\t\t\t\tRole: \"old role\",\n\t\t\t},\n\t\t})\n\t\tassert.Equal(t, assumableIamRoleLp, authRole.AssumableIamRole)\n\t\tassert.Equal(t, k8sServiceAccountLp, authRole.KubernetesServiceAccount)\n\t})\n}\n\nfunc TestAddStateFilter(t *testing.T) {\n\tt.Run(\"empty filters\", func(t *testing.T) {\n\t\tvar filters []common.InlineFilter\n\t\tupdatedFilters, err := addStateFilter(filters)\n\t\tassert.Nil(t, err)\n\t\tassert.NotNil(t, updatedFilters)\n\t\tassert.Equal(t, 1, len(updatedFilters))\n\n\t\tassert.Equal(t, shared.State, updatedFilters[0].GetField())\n\t\tassert.Equal(t, common.Execution, updatedFilters[0].GetEntity())\n\n\t\texpression, err := updatedFilters[0].GetGormQueryExpr()\n\t\tassert.NoError(t, err)\n\t\tassert.Equal(t, \"state = ?\", expression.Query)\n\t})\n\n\tt.Run(\"passed state filter\", func(t *testing.T) {\n\t\tfilter, err := common.NewSingleValueFilter(common.Execution, common.NotEqual, \"state\", \"0\")\n\t\tassert.NoError(t, err)\n\t\tfilters := []common.InlineFilter{filter}\n\n\t\tupdatedFilters, err := addStateFilter(filters)\n\t\tassert.Nil(t, err)\n\t\tassert.NotNil(t, updatedFilters)\n\t\tassert.Equal(t, 1, len(updatedFilters))\n\n\t\tassert.Equal(t, shared.State, updatedFilters[0].GetField())\n\t\tassert.Equal(t, common.Execution, updatedFilters[0].GetEntity())\n\n\t\texpression, err := updatedFilters[0].GetGormQueryExpr()\n\t\tassert.NoError(t, err)\n\t\tassert.Equal(t, \"state <> ?\", expression.Query)\n\t})\n\n}\n", "package impl\n\nimport (\n\t\"bytes\"\n\t\"context\"\n\t\"strconv\"\n\n\t\"github.com/flyteorg/flytestdlib/contextutils\"\n\n\t\"github.com/flyteorg/flytestdlib/promutils\"\n\t\"github.com/prometheus/client_golang/prometheus\"\n\n\tscheduleInterfaces \"github.com/flyteorg/flyteadmin/pkg/async/schedule/interfaces\"\n\n\t\"github.com/flyteorg/flytestdlib/logger\"\n\n\t\"github.com/flyteorg/flyteadmin/pkg/common\"\n\t\"github.com/flyteorg/flyteadmin/pkg/errors\"\n\t\"github.com/flyteorg/flyteadmin/pkg/manager/impl/util\"\n\t\"github.com/flyteorg/flyteadmin/pkg/manager/impl/validation\"\n\t\"github.com/flyteorg/flyteadmin/pkg/manager/interfaces\"\n\trepoInterfaces \"github.com/flyteorg/flyteadmin/pkg/repositories/interfaces\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/models\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/transformers\"\n\truntimeInterfaces \"github.com/flyteorg/flyteadmin/pkg/runtime/interfaces\"\n\t\"github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/admin\"\n\t\"github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/core\"\n\t\"github.com/golang/protobuf/proto\"\n\t\"google.golang.org/grpc/codes\"\n)\n\ntype launchPlanMetrics struct {\n\tScope                 promutils.Scope\n\tFailedScheduleUpdates prometheus.Counter\n\tSpecSizeBytes         prometheus.Summary\n\tClosureSizeBytes      prometheus.Summary\n}\n\ntype LaunchPlanManager struct {\n\tdb        repoInterfaces.Repository\n\tconfig    runtimeInterfaces.Configuration\n\tscheduler scheduleInterfaces.EventScheduler\n\tmetrics   launchPlanMetrics\n}\n\nfunc getLaunchPlanContext(ctx context.Context, identifier *core.Identifier) context.Context {\n\tctx = contextutils.WithProjectDomain(ctx, identifier.Project, identifier.Domain)\n\treturn contextutils.WithLaunchPlanID(ctx, identifier.Name)\n}\n\nfunc (m *LaunchPlanManager) getNamedEntityContext(ctx context.Context, identifier *admin.NamedEntityIdentifier) context.Context {\n\tctx = contextutils.WithProjectDomain(ctx, identifier.Project, identifier.Domain)\n\treturn contextutils.WithLaunchPlanID(ctx, identifier.Name)\n}\n\nfunc (m *LaunchPlanManager) CreateLaunchPlan(\n\tctx context.Context,\n\trequest admin.LaunchPlanCreateRequest) (*admin.LaunchPlanCreateResponse, error) {\n\tif err := validation.ValidateIdentifier(request.GetSpec().GetWorkflowId(), common.Workflow); err != nil {\n\t\tlogger.Debugf(ctx, \"Failed to validate provided workflow ID for CreateLaunchPlan with err: %v\", err)\n\t\treturn nil, err\n\t}\n\tworkflowModel, err := util.GetWorkflowModel(ctx, m.db, *request.Spec.WorkflowId)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"Failed to get workflow with id [%+v] for CreateLaunchPlan with id [%+v] with err %v\",\n\t\t\t*request.Spec.WorkflowId, request.Id)\n\t\treturn nil, err\n\t}\n\tvar workflowInterface core.TypedInterface\n\tif workflowModel.TypedInterface != nil && len(workflowModel.TypedInterface) > 0 {\n\t\terr = proto.Unmarshal(workflowModel.TypedInterface, &workflowInterface)\n\t\tif err != nil {\n\t\t\tlogger.Errorf(ctx,\n\t\t\t\t\"Failed to unmarshal TypedInterface for workflow [%+v] with err: %v\",\n\t\t\t\t*request.Spec.WorkflowId, err)\n\t\t\treturn nil, errors.NewFlyteAdminErrorf(codes.Internal, \"failed to unmarshal workflow inputs\")\n\t\t}\n\t}\n\tif err := validation.ValidateLaunchPlan(ctx, request, m.db, m.config.ApplicationConfiguration(), &workflowInterface); err != nil {\n\t\tlogger.Debugf(ctx, \"could not create launch plan: %+v, request failed validation with err: %v\", request.Id, err)\n\t\treturn nil, err\n\t}\n\tctx = getLaunchPlanContext(ctx, request.Id)\n\tlaunchPlan := transformers.CreateLaunchPlan(request, workflowInterface.Outputs)\n\tlaunchPlanDigest, err := util.GetLaunchPlanDigest(ctx, &launchPlan)\n\tif err != nil {\n\t\tlogger.Errorf(ctx, \"failed to compute launch plan digest for [%+v] with err: %v\", launchPlan.Id, err)\n\t\treturn nil, err\n\t}\n\n\texistingLaunchPlanModel, err := util.GetLaunchPlanModel(ctx, m.db, *request.Id)\n\tif err == nil {\n\t\tif bytes.Equal(existingLaunchPlanModel.Digest, launchPlanDigest) {\n\t\t\treturn nil, errors.NewFlyteAdminErrorf(codes.AlreadyExists,\n\t\t\t\t\"identical launch plan already exists with id %s\", request.Id)\n\t\t}\n\n\t\treturn nil, errors.NewFlyteAdminErrorf(codes.InvalidArgument,\n\t\t\t\"launch plan with different structure already exists with id %v\", request.Id)\n\t}\n\n\tlaunchPlanModel, err :=\n\t\ttransformers.CreateLaunchPlanModel(launchPlan, workflowModel.ID, launchPlanDigest, admin.LaunchPlanState_INACTIVE)\n\tif err != nil {\n\t\tlogger.Errorf(ctx,\n\t\t\t\"Failed to transform launch plan model [%+v], and workflow outputs [%+v] with err: %v\",\n\t\t\trequest, workflowInterface.Outputs, err)\n\t\treturn nil, err\n\t}\n\terr = m.db.LaunchPlanRepo().Create(ctx, launchPlanModel)\n\tif err != nil {\n\t\tlogger.Errorf(ctx, \"Failed to save launch plan model %+v with err: %v\", request.Id, err)\n\t\treturn nil, err\n\t}\n\tm.metrics.SpecSizeBytes.Observe(float64(len(launchPlanModel.Spec)))\n\tm.metrics.ClosureSizeBytes.Observe(float64(len(launchPlanModel.Closure)))\n\treturn &admin.LaunchPlanCreateResponse{}, nil\n}\n\nfunc (m *LaunchPlanManager) updateLaunchPlanModelState(launchPlan *models.LaunchPlan, state admin.LaunchPlanState) error {\n\tvar launchPlanClosure admin.LaunchPlanClosure\n\terr := proto.Unmarshal(launchPlan.Closure, &launchPlanClosure)\n\tif err != nil {\n\t\tlogger.Errorf(context.Background(), \"failed to unmarshal launch plan closure: %v\", err)\n\t\treturn errors.NewFlyteAdminErrorf(codes.Internal, \"Failed to unmarshal launch plan closure: %v\", err)\n\t}\n\t// Don't write the state in the closure - we store it only in the model column \"State\" and fill in the closure\n\t// value when transforming from a model to an admin.LaunchPlan object\n\tmarshalledClosure, err := proto.Marshal(&launchPlanClosure)\n\tif err != nil {\n\t\tlogger.Errorf(context.Background(), \"Failed to marshal launch plan closure: %v\", err)\n\t\treturn errors.NewFlyteAdminErrorf(codes.Internal, \"Failed to marshal launch plan closure: %v\", err)\n\t}\n\tlaunchPlan.Closure = marshalledClosure\n\tstateInt := int32(state)\n\tlaunchPlan.State = &stateInt\n\treturn nil\n}\n\nfunc isScheduleEmpty(launchPlanSpec admin.LaunchPlanSpec) bool {\n\tschedule := launchPlanSpec.GetEntityMetadata().GetSchedule()\n\tif schedule == nil {\n\t\treturn true\n\t}\n\tif schedule.GetCronSchedule() != nil && len(schedule.GetCronSchedule().Schedule) != 0 {\n\t\treturn false\n\t}\n\tif len(schedule.GetCronExpression()) != 0 {\n\t\treturn false\n\t}\n\tif schedule.GetRate().GetValue() != 0 {\n\t\treturn false\n\t}\n\treturn true\n}\n\nfunc (m *LaunchPlanManager) enableSchedule(ctx context.Context, launchPlanIdentifier core.Identifier,\n\tlaunchPlanSpec admin.LaunchPlanSpec) error {\n\n\taddScheduleInput, err := m.scheduler.CreateScheduleInput(ctx,\n\t\tm.config.ApplicationConfiguration().GetSchedulerConfig(), launchPlanIdentifier,\n\t\tlaunchPlanSpec.EntityMetadata.Schedule)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\treturn m.scheduler.AddSchedule(ctx, addScheduleInput)\n}\n\nfunc (m *LaunchPlanManager) disableSchedule(\n\tctx context.Context, launchPlanIdentifier core.Identifier) error {\n\treturn m.scheduler.RemoveSchedule(ctx, scheduleInterfaces.RemoveScheduleInput{\n\t\tIdentifier:         launchPlanIdentifier,\n\t\tScheduleNamePrefix: m.config.ApplicationConfiguration().GetSchedulerConfig().EventSchedulerConfig.ScheduleNamePrefix,\n\t})\n}\n\nfunc (m *LaunchPlanManager) updateSchedules(\n\tctx context.Context, newlyActiveLaunchPlan models.LaunchPlan, formerlyActiveLaunchPlan *models.LaunchPlan) error {\n\tvar newlyActiveLaunchPlanSpec admin.LaunchPlanSpec\n\terr := proto.Unmarshal(newlyActiveLaunchPlan.Spec, &newlyActiveLaunchPlanSpec)\n\tif err != nil {\n\t\tlogger.Errorf(ctx, \"failed to unmarshal newly enabled launch plan spec\")\n\t\treturn errors.NewFlyteAdminErrorf(codes.Internal, \"failed to unmarshal newly enabled launch plan spec\")\n\t}\n\tlaunchPlanIdentifier := core.Identifier{\n\t\tProject: newlyActiveLaunchPlan.Project,\n\t\tDomain:  newlyActiveLaunchPlan.Domain,\n\t\tName:    newlyActiveLaunchPlan.Name,\n\t\tVersion: newlyActiveLaunchPlan.Version,\n\t}\n\tvar formerlyActiveLaunchPlanSpec admin.LaunchPlanSpec\n\tif formerlyActiveLaunchPlan != nil {\n\t\terr = proto.Unmarshal(formerlyActiveLaunchPlan.Spec, &formerlyActiveLaunchPlanSpec)\n\t\tif err != nil {\n\t\t\treturn errors.NewFlyteAdminErrorf(codes.Internal, \"failed to unmarshal formerly enabled launch plan spec\")\n\t\t}\n\t}\n\n\tif !isScheduleEmpty(formerlyActiveLaunchPlanSpec) {\n\t\t// Disable previous schedule\n\t\tformerlyActiveLaunchPlanIdentifier := core.Identifier{\n\t\t\tProject: formerlyActiveLaunchPlan.Project,\n\t\t\tDomain:  formerlyActiveLaunchPlan.Domain,\n\t\t\tName:    formerlyActiveLaunchPlan.Name,\n\t\t\tVersion: formerlyActiveLaunchPlan.Version,\n\t\t}\n\t\tif err = m.disableSchedule(ctx, formerlyActiveLaunchPlanIdentifier); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tlogger.Infof(ctx, \"Disabled schedules for deactivated launch plan [%+v]\", launchPlanIdentifier)\n\t}\n\tif !isScheduleEmpty(newlyActiveLaunchPlanSpec) {\n\t\t// Enable new schedule\n\t\tif err = m.enableSchedule(ctx, launchPlanIdentifier, newlyActiveLaunchPlanSpec); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tlogger.Infof(ctx, \"Enabled schedules for activated launch plan [%+v]\", launchPlanIdentifier)\n\t}\n\treturn nil\n}\n\nfunc (m *LaunchPlanManager) disableLaunchPlan(ctx context.Context, request admin.LaunchPlanUpdateRequest) (\n\t*admin.LaunchPlanUpdateResponse, error) {\n\tif err := validation.ValidateIdentifier(request.Id, common.LaunchPlan); err != nil {\n\t\tlogger.Debugf(ctx, \"can't disable launch plan [%+v] with invalid identifier: %v\", request.Id, err)\n\t\treturn nil, err\n\t}\n\tlaunchPlanModel, err := util.GetLaunchPlanModel(ctx, m.db, *request.Id)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"couldn't find launch plan [%+v] to disable with err: %v\", request.Id, err)\n\t\treturn nil, err\n\t}\n\n\terr = m.updateLaunchPlanModelState(&launchPlanModel, admin.LaunchPlanState_INACTIVE)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"failed to disable launch plan [%+v] with err: %v\", request.Id, err)\n\t\treturn nil, err\n\t}\n\n\tvar launchPlanSpec admin.LaunchPlanSpec\n\terr = proto.Unmarshal(launchPlanModel.Spec, &launchPlanSpec)\n\tif err != nil {\n\t\tlogger.Errorf(ctx, \"failed to unmarshal launch plan spec when disabling schedule for %+v\", request.Id)\n\t\treturn nil, errors.NewFlyteAdminErrorf(codes.Internal,\n\t\t\t\"failed to unmarshal launch plan spec when disabling schedule for %+v\", request.Id)\n\t}\n\tif launchPlanSpec.EntityMetadata != nil && launchPlanSpec.EntityMetadata.Schedule != nil {\n\t\terr = m.disableSchedule(ctx, core.Identifier{\n\t\t\tProject: launchPlanModel.Project,\n\t\t\tDomain:  launchPlanModel.Domain,\n\t\t\tName:    launchPlanModel.Name,\n\t\t\tVersion: launchPlanModel.Version,\n\t\t})\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\terr = m.db.LaunchPlanRepo().Update(ctx, launchPlanModel)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"Failed to update launchPlanModel with ID [%+v] with err %v\", request.Id, err)\n\t\treturn nil, err\n\t}\n\tlogger.Debugf(ctx, \"disabled launch plan: [%+v]\", request.Id)\n\treturn &admin.LaunchPlanUpdateResponse{}, nil\n}\n\nfunc (m *LaunchPlanManager) enableLaunchPlan(ctx context.Context, request admin.LaunchPlanUpdateRequest) (\n\t*admin.LaunchPlanUpdateResponse, error) {\n\tnewlyActiveLaunchPlanModel, err := m.db.LaunchPlanRepo().Get(ctx, repoInterfaces.Identifier{\n\t\tProject: request.Id.Project,\n\t\tDomain:  request.Id.Domain,\n\t\tName:    request.Id.Name,\n\t\tVersion: request.Id.Version,\n\t})\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"Failed to find launch plan to enable with id [%+v] and err %v\", request.Id, err)\n\t\treturn nil, err\n\t}\n\t// Set desired launch plan version to active:\n\terr = m.updateLaunchPlanModelState(&newlyActiveLaunchPlanModel, admin.LaunchPlanState_ACTIVE)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// Find currently active version, if it exists.\n\tfilters, err := util.GetActiveLaunchPlanVersionFilters(newlyActiveLaunchPlanModel.Project, newlyActiveLaunchPlanModel.Domain, newlyActiveLaunchPlanModel.Name)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tformerlyActiveLaunchPlanModelOutput, err := m.db.LaunchPlanRepo().List(ctx, repoInterfaces.ListResourceInput{\n\t\tInlineFilters: filters,\n\t\tLimit:         1,\n\t})\n\tvar formerlyActiveLaunchPlanModel *models.LaunchPlan\n\tif err != nil {\n\t\t// Not found is fine, there isn't always a guaranteed active launch plan model.\n\t\tif err.(errors.FlyteAdminError).Code() != codes.NotFound {\n\t\t\tlogger.Infof(ctx, \"Failed to search for an active launch plan model with project: %s, domain: %s, name: %s and err %v\",\n\t\t\t\trequest.Id.Project, request.Id.Domain, request.Id.Name, err)\n\t\t\treturn nil, err\n\t\t}\n\t\tlogger.Debugf(ctx, \"No active launch plan model found to disable with project: %s, domain: %s, name: %s\",\n\t\t\trequest.Id.Project, request.Id.Domain, request.Id.Name)\n\t} else if formerlyActiveLaunchPlanModelOutput.LaunchPlans != nil &&\n\t\tlen(formerlyActiveLaunchPlanModelOutput.LaunchPlans) > 0 {\n\t\tformerlyActiveLaunchPlanModel = &formerlyActiveLaunchPlanModelOutput.LaunchPlans[0]\n\t\terr = m.updateLaunchPlanModelState(formerlyActiveLaunchPlanModel, admin.LaunchPlanState_INACTIVE)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\terr = m.updateSchedules(ctx, newlyActiveLaunchPlanModel, formerlyActiveLaunchPlanModel)\n\tif err != nil {\n\t\tm.metrics.FailedScheduleUpdates.Inc()\n\t\treturn nil, err\n\t}\n\n\t// This operation is takes in the (formerly) active launch plan version as only one version can be active at a time.\n\t// Setting the desired launch plan to active also requires disabling the existing active launch plan version.\n\terr = m.db.LaunchPlanRepo().SetActive(ctx, newlyActiveLaunchPlanModel, formerlyActiveLaunchPlanModel)\n\tif err != nil {\n\t\tlogger.Debugf(ctx,\n\t\t\t\"Failed to set launchPlanModel with ID [%+v] to active with err %v\", request.Id, err)\n\t\treturn nil, err\n\t}\n\treturn &admin.LaunchPlanUpdateResponse{}, nil\n\n}\n\nfunc (m *LaunchPlanManager) UpdateLaunchPlan(ctx context.Context, request admin.LaunchPlanUpdateRequest) (\n\t*admin.LaunchPlanUpdateResponse, error) {\n\tif err := validation.ValidateIdentifier(request.Id, common.LaunchPlan); err != nil {\n\t\tlogger.Debugf(ctx, \"can't update launch plan [%+v] state, invalid identifier: %v\", request.Id, err)\n\t}\n\tctx = getLaunchPlanContext(ctx, request.Id)\n\tswitch request.State {\n\tcase admin.LaunchPlanState_INACTIVE:\n\t\treturn m.disableLaunchPlan(ctx, request)\n\tcase admin.LaunchPlanState_ACTIVE:\n\t\treturn m.enableLaunchPlan(ctx, request)\n\tdefault:\n\t\treturn nil, errors.NewFlyteAdminErrorf(\n\t\t\tcodes.InvalidArgument, \"Unrecognized launch plan state %v for update for launch plan [%+v]\",\n\t\t\trequest.State, request.Id)\n\t}\n}\n\nfunc (m *LaunchPlanManager) GetLaunchPlan(ctx context.Context, request admin.ObjectGetRequest) (\n\t*admin.LaunchPlan, error) {\n\tif err := validation.ValidateIdentifier(request.Id, common.LaunchPlan); err != nil {\n\t\tlogger.Debugf(ctx, \"can't get launch plan [%+v] with invalid identifier: %v\", request.Id, err)\n\t\treturn nil, err\n\t}\n\tctx = getLaunchPlanContext(ctx, request.Id)\n\treturn util.GetLaunchPlan(ctx, m.db, *request.Id)\n}\n\nfunc (m *LaunchPlanManager) GetActiveLaunchPlan(ctx context.Context, request admin.ActiveLaunchPlanRequest) (\n\t*admin.LaunchPlan, error) {\n\tif err := validation.ValidateActiveLaunchPlanRequest(request); err != nil {\n\t\tlogger.Debugf(ctx, \"can't get active launch plan [%+v] with invalid request: %v\", request.Id, err)\n\t\treturn nil, err\n\t}\n\tctx = m.getNamedEntityContext(ctx, request.Id)\n\n\tfilters, err := util.GetActiveLaunchPlanVersionFilters(request.Id.Project, request.Id.Domain, request.Id.Name)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tlistLaunchPlansInput := repoInterfaces.ListResourceInput{\n\t\tLimit:         1,\n\t\tInlineFilters: filters,\n\t}\n\n\toutput, err := m.db.LaunchPlanRepo().List(ctx, listLaunchPlansInput)\n\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"Failed to list active launch plan id for request [%+v] with err %v\", request, err)\n\t\treturn nil, err\n\t}\n\n\tif len(output.LaunchPlans) != 1 {\n\t\treturn nil, errors.NewFlyteAdminErrorf(codes.NotFound, \"No active launch plan could be found: %s:%s:%s\", request.Id.Project, request.Id.Domain, request.Id.Name)\n\t}\n\n\treturn transformers.FromLaunchPlanModel(output.LaunchPlans[0])\n}\n\nfunc (m *LaunchPlanManager) ListLaunchPlans(ctx context.Context, request admin.ResourceListRequest) (\n\t*admin.LaunchPlanList, error) {\n\n\t// Check required fields\n\tif err := validation.ValidateResourceListRequest(request); err != nil {\n\t\tlogger.Debugf(ctx, \"\")\n\t\treturn nil, err\n\t}\n\tctx = m.getNamedEntityContext(ctx, request.Id)\n\n\tfilters, err := util.GetDbFilters(util.FilterSpec{\n\t\tProject:        request.Id.Project,\n\t\tDomain:         request.Id.Domain,\n\t\tName:           request.Id.Name,\n\t\tRequestFilters: request.Filters,\n\t}, common.LaunchPlan)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tvar sortParameter common.SortParameter\n\tif request.SortBy != nil {\n\t\tsortParameter, err = common.NewSortParameter(*request.SortBy)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\toffset, err := validation.ValidateToken(request.Token)\n\tif err != nil {\n\t\treturn nil, errors.NewFlyteAdminErrorf(codes.InvalidArgument,\n\t\t\t\"invalid pagination token %s for ListLaunchPlans\", request.Token)\n\t}\n\tlistLaunchPlansInput := repoInterfaces.ListResourceInput{\n\t\tLimit:         int(request.Limit),\n\t\tOffset:        offset,\n\t\tInlineFilters: filters,\n\t\tSortParameter: sortParameter,\n\t}\n\n\toutput, err := m.db.LaunchPlanRepo().List(ctx, listLaunchPlansInput)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"Failed to list launch plans for request [%+v] with err %v\", request, err)\n\t\treturn nil, err\n\t}\n\tlaunchPlanList, err := transformers.FromLaunchPlanModels(output.LaunchPlans)\n\tif err != nil {\n\t\tlogger.Errorf(ctx,\n\t\t\t\"Failed to transform launch plan models [%+v] with err: %v\", output.LaunchPlans, err)\n\t\treturn nil, err\n\t}\n\tvar token string\n\tif len(output.LaunchPlans) == int(request.Limit) {\n\t\ttoken = strconv.Itoa(offset + len(output.LaunchPlans))\n\t}\n\treturn &admin.LaunchPlanList{\n\t\tLaunchPlans: launchPlanList,\n\t\tToken:       token,\n\t}, nil\n}\n\nfunc (m *LaunchPlanManager) ListActiveLaunchPlans(ctx context.Context, request admin.ActiveLaunchPlanListRequest) (\n\t*admin.LaunchPlanList, error) {\n\n\t// Check required fields\n\tif err := validation.ValidateActiveLaunchPlanListRequest(request); err != nil {\n\t\tlogger.Debugf(ctx, \"\")\n\t\treturn nil, err\n\t}\n\tctx = contextutils.WithProjectDomain(ctx, request.Project, request.Domain)\n\n\tfilters, err := util.ListActiveLaunchPlanVersionsFilters(request.Project, request.Domain)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tvar sortParameter common.SortParameter\n\tif request.SortBy != nil {\n\t\tsortParameter, err = common.NewSortParameter(*request.SortBy)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\toffset, err := validation.ValidateToken(request.Token)\n\tif err != nil {\n\t\treturn nil, errors.NewFlyteAdminErrorf(codes.InvalidArgument,\n\t\t\t\"invalid pagination token %s for ListActiveLaunchPlans\", request.Token)\n\t}\n\tlistLaunchPlansInput := repoInterfaces.ListResourceInput{\n\t\tLimit:         int(request.Limit),\n\t\tOffset:        offset,\n\t\tInlineFilters: filters,\n\t\tSortParameter: sortParameter,\n\t}\n\n\toutput, err := m.db.LaunchPlanRepo().List(ctx, listLaunchPlansInput)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"Failed to list active launch plans for request [%+v] with err %v\", request, err)\n\t\treturn nil, err\n\t}\n\tlaunchPlanList, err := transformers.FromLaunchPlanModels(output.LaunchPlans)\n\tif err != nil {\n\t\tlogger.Errorf(ctx,\n\t\t\t\"Failed to transform active launch plan models [%+v] with err: %v\", output.LaunchPlans, err)\n\t\treturn nil, err\n\t}\n\tvar token string\n\tif len(output.LaunchPlans) == int(request.Limit) {\n\t\ttoken = strconv.Itoa(offset + len(output.LaunchPlans))\n\t}\n\treturn &admin.LaunchPlanList{\n\t\tLaunchPlans: launchPlanList,\n\t\tToken:       token,\n\t}, nil\n}\n\n// At least project name and domain must be specified along with limit.\nfunc (m *LaunchPlanManager) ListLaunchPlanIds(ctx context.Context, request admin.NamedEntityIdentifierListRequest) (\n\t*admin.NamedEntityIdentifierList, error) {\n\tctx = contextutils.WithProjectDomain(ctx, request.Project, request.Domain)\n\tfilters, err := util.GetDbFilters(util.FilterSpec{\n\t\tProject: request.Project,\n\t\tDomain:  request.Domain,\n\t}, common.LaunchPlan)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tvar sortParameter common.SortParameter\n\tif request.SortBy != nil {\n\t\tsortParameter, err = common.NewSortParameter(*request.SortBy)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\toffset, err := validation.ValidateToken(request.Token)\n\tif err != nil {\n\t\treturn nil, errors.NewFlyteAdminErrorf(codes.InvalidArgument, \"invalid pagination token %s\", request.Token)\n\t}\n\tlistLaunchPlansInput := repoInterfaces.ListResourceInput{\n\t\tLimit:         int(request.Limit),\n\t\tOffset:        offset,\n\t\tInlineFilters: filters,\n\t\tSortParameter: sortParameter,\n\t}\n\n\toutput, err := m.db.LaunchPlanRepo().ListLaunchPlanIdentifiers(ctx, listLaunchPlansInput)\n\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"Failed to list launch plan ids for request [%+v] with err %v\", request, err)\n\t\treturn nil, err\n\t}\n\tvar token string\n\tif len(output.LaunchPlans) == int(request.Limit) {\n\t\ttoken = strconv.Itoa(offset + len(output.LaunchPlans))\n\t}\n\treturn &admin.NamedEntityIdentifierList{\n\t\tEntities: transformers.FromLaunchPlanModelsToIdentifiers(output.LaunchPlans),\n\t\tToken:    token,\n\t}, nil\n}\n\nfunc NewLaunchPlanManager(\n\tdb repoInterfaces.Repository,\n\tconfig runtimeInterfaces.Configuration,\n\tscheduler scheduleInterfaces.EventScheduler,\n\tscope promutils.Scope) interfaces.LaunchPlanInterface {\n\n\tmetrics := launchPlanMetrics{\n\t\tScope: scope,\n\t\tFailedScheduleUpdates: scope.MustNewCounter(\"failed_schedule_updates\",\n\t\t\t\"count of unsuccessful attempts to update the schedules when updating launch plan version\"),\n\t\tSpecSizeBytes:    scope.MustNewSummary(\"spec_size_bytes\", \"size in bytes of serialized launch plan spec\"),\n\t\tClosureSizeBytes: scope.MustNewSummary(\"closure_size_bytes\", \"size in bytes of serialized launch plan closure\"),\n\t}\n\treturn &LaunchPlanManager{\n\t\tdb:        db,\n\t\tconfig:    config,\n\t\tscheduler: scheduler,\n\t\tmetrics:   metrics,\n\t}\n}\n", "package impl\n\nimport (\n\t\"context\"\n\t\"strconv\"\n\t\"strings\"\n\n\t\"github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/core\"\n\n\t\"github.com/flyteorg/flytestdlib/contextutils\"\n\n\t\"github.com/flyteorg/flyteadmin/pkg/common\"\n\t\"github.com/flyteorg/flyteadmin/pkg/errors\"\n\t\"google.golang.org/grpc/codes\"\n\n\t\"github.com/flyteorg/flyteadmin/pkg/manager/impl/util\"\n\t\"github.com/flyteorg/flyteadmin/pkg/manager/impl/validation\"\n\t\"github.com/flyteorg/flyteadmin/pkg/manager/interfaces\"\n\trepoInterfaces \"github.com/flyteorg/flyteadmin/pkg/repositories/interfaces\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/transformers\"\n\truntimeInterfaces \"github.com/flyteorg/flyteadmin/pkg/runtime/interfaces\"\n\t\"github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/admin\"\n\t\"github.com/flyteorg/flytestdlib/logger\"\n\t\"github.com/flyteorg/flytestdlib/promutils\"\n)\n\nconst state = \"state\"\n\n// System-generated workflows are meant to be hidden from the user by default. Therefore we always only show\n// workflow-type named entities that have been user generated only.\nvar nonSystemGeneratedWorkflowsFilter, _ = common.NewSingleValueFilter(\n\tcommon.NamedEntityMetadata, common.NotEqual, state, admin.NamedEntityState_SYSTEM_GENERATED)\nvar defaultWorkflowsFilter, _ = common.NewWithDefaultValueFilter(\n\tstrconv.Itoa(int(admin.NamedEntityState_NAMED_ENTITY_ACTIVE)), nonSystemGeneratedWorkflowsFilter)\n\ntype NamedEntityMetrics struct {\n\tScope promutils.Scope\n}\n\ntype NamedEntityManager struct {\n\tdb      repoInterfaces.Repository\n\tconfig  runtimeInterfaces.Configuration\n\tmetrics NamedEntityMetrics\n}\n\nfunc (m *NamedEntityManager) UpdateNamedEntity(ctx context.Context, request admin.NamedEntityUpdateRequest) (\n\t*admin.NamedEntityUpdateResponse, error) {\n\tif err := validation.ValidateNamedEntityUpdateRequest(request); err != nil {\n\t\tlogger.Debugf(ctx, \"invalid request [%+v]: %v\", request, err)\n\t\treturn nil, err\n\t}\n\tctx = contextutils.WithProjectDomain(ctx, request.Id.Project, request.Id.Domain)\n\n\t// Ensure entity exists before trying to update it\n\t_, err := util.GetNamedEntity(ctx, m.db, request.ResourceType, *request.Id)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tmetadataModel := transformers.CreateNamedEntityModel(&request)\n\terr = m.db.NamedEntityRepo().Update(ctx, metadataModel)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"Failed to update named_entity for [%+v] with err %v\", request.Id, err)\n\t\treturn nil, err\n\t}\n\treturn &admin.NamedEntityUpdateResponse{}, nil\n}\n\nfunc (m *NamedEntityManager) GetNamedEntity(ctx context.Context, request admin.NamedEntityGetRequest) (\n\t*admin.NamedEntity, error) {\n\tif err := validation.ValidateNamedEntityGetRequest(request); err != nil {\n\t\tlogger.Debugf(ctx, \"invalid request [%+v]: %v\", request, err)\n\t\treturn nil, err\n\t}\n\tctx = contextutils.WithProjectDomain(ctx, request.Id.Project, request.Id.Domain)\n\treturn util.GetNamedEntity(ctx, m.db, request.ResourceType, *request.Id)\n}\n\nfunc (m *NamedEntityManager) getQueryFilters(referenceEntity core.ResourceType, requestFilters string) ([]common.InlineFilter, error) {\n\tfilters := make([]common.InlineFilter, 0)\n\tif referenceEntity == core.ResourceType_WORKFLOW {\n\t\tfilters = append(filters, defaultWorkflowsFilter)\n\t}\n\n\tif len(requestFilters) == 0 {\n\t\treturn filters, nil\n\t}\n\tadditionalFilters, err := util.ParseFilters(requestFilters, common.NamedEntity)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tfor _, filter := range additionalFilters {\n\t\tif strings.Contains(filter.GetField(), state) {\n\t\t\tfilterWithDefaultValue, err := common.NewWithDefaultValueFilter(\n\t\t\t\tstrconv.Itoa(int(admin.NamedEntityState_NAMED_ENTITY_ACTIVE)), filter)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\tfilters = append(filters, filterWithDefaultValue)\n\t\t} else {\n\t\t\tfilters = append(filters, filter)\n\t\t}\n\t}\n\treturn filters, nil\n}\n\nfunc (m *NamedEntityManager) ListNamedEntities(ctx context.Context, request admin.NamedEntityListRequest) (\n\t*admin.NamedEntityList, error) {\n\tif err := validation.ValidateNamedEntityListRequest(request); err != nil {\n\t\tlogger.Debugf(ctx, \"invalid request [%+v]: %v\", request, err)\n\t\treturn nil, err\n\t}\n\tctx = contextutils.WithProjectDomain(ctx, request.Project, request.Domain)\n\n\t// HACK: In order to filter by state (if requested) - we need to amend the filter to use COALESCE\n\t// e.g. eq(state, 1) becomes 'WHERE (COALESCE(state, 0) = '1')' since not every NamedEntity necessarily\n\t// has an entry, and therefore the default state value '0' (active), should be assumed.\n\tfilters, err := m.getQueryFilters(request.ResourceType, request.Filters)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tvar sortParameter common.SortParameter\n\tif request.SortBy != nil {\n\t\tsortParameter, err = common.NewSortParameter(*request.SortBy)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\toffset, err := validation.ValidateToken(request.Token)\n\tif err != nil {\n\t\treturn nil, errors.NewFlyteAdminErrorf(codes.InvalidArgument,\n\t\t\t\"invalid pagination token %s for ListNamedEntities\", request.Token)\n\t}\n\tlistInput := repoInterfaces.ListNamedEntityInput{\n\t\tListResourceInput: repoInterfaces.ListResourceInput{\n\t\t\tLimit:         int(request.Limit),\n\t\t\tOffset:        offset,\n\t\t\tInlineFilters: filters,\n\t\t\tSortParameter: sortParameter,\n\t\t},\n\t\tProject:      request.Project,\n\t\tDomain:       request.Domain,\n\t\tResourceType: request.ResourceType,\n\t}\n\n\toutput, err := m.db.NamedEntityRepo().List(ctx, listInput)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"Failed to list named entities of type: %s with project: %s, domain: %s. Returned error was: %v\",\n\t\t\trequest.ResourceType, request.Project, request.Domain, err)\n\t\treturn nil, err\n\t}\n\n\tvar token string\n\tif len(output.Entities) == int(request.Limit) {\n\t\ttoken = strconv.Itoa(offset + len(output.Entities))\n\t}\n\tentities := transformers.FromNamedEntityModels(output.Entities)\n\treturn &admin.NamedEntityList{\n\t\tEntities: entities,\n\t\tToken:    token,\n\t}, nil\n\n}\n\nfunc NewNamedEntityManager(\n\tdb repoInterfaces.Repository,\n\tconfig runtimeInterfaces.Configuration,\n\tscope promutils.Scope) interfaces.NamedEntityInterface {\n\n\tmetrics := NamedEntityMetrics{\n\t\tScope: scope,\n\t}\n\treturn &NamedEntityManager{\n\t\tdb:      db,\n\t\tconfig:  config,\n\t\tmetrics: metrics,\n\t}\n}\n", "package impl\n\nimport (\n\t\"context\"\n\t\"strconv\"\n\n\tcloudeventInterfaces \"github.com/flyteorg/flyteadmin/pkg/async/cloudevent/interfaces\"\n\n\t\"github.com/flyteorg/flytestdlib/promutils/labeled\"\n\n\teventWriter \"github.com/flyteorg/flyteadmin/pkg/async/events/interfaces\"\n\n\tnotificationInterfaces \"github.com/flyteorg/flyteadmin/pkg/async/notifications/interfaces\"\n\t\"github.com/golang/protobuf/proto\"\n\n\t\"github.com/flyteorg/flytestdlib/storage\"\n\n\t\"github.com/flyteorg/flytestdlib/contextutils\"\n\n\t\"github.com/flyteorg/flyteadmin/pkg/manager/impl/shared\"\n\t\"github.com/flyteorg/flytestdlib/promutils\"\n\t\"github.com/prometheus/client_golang/prometheus\"\n\n\t\"github.com/flyteorg/flytestdlib/logger\"\n\n\t\"github.com/flyteorg/flyteadmin/pkg/common\"\n\t\"github.com/flyteorg/flyteadmin/pkg/manager/impl/validation\"\n\n\t\"fmt\"\n\n\tdataInterfaces \"github.com/flyteorg/flyteadmin/pkg/data/interfaces\"\n\t\"github.com/flyteorg/flyteadmin/pkg/errors\"\n\t\"github.com/flyteorg/flyteadmin/pkg/manager/impl/util\"\n\t\"github.com/flyteorg/flyteadmin/pkg/manager/interfaces\"\n\trepoInterfaces \"github.com/flyteorg/flyteadmin/pkg/repositories/interfaces\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/models\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/transformers\"\n\truntimeInterfaces \"github.com/flyteorg/flyteadmin/pkg/runtime/interfaces\"\n\t\"github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/admin\"\n\t\"github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/core\"\n\t\"google.golang.org/grpc/codes\"\n)\n\ntype nodeExecutionMetrics struct {\n\tScope                      promutils.Scope\n\tActiveNodeExecutions       prometheus.Gauge\n\tNodeExecutionsCreated      prometheus.Counter\n\tNodeExecutionsTerminated   labeled.Counter\n\tNodeExecutionEventsCreated prometheus.Counter\n\tMissingWorkflowExecution   prometheus.Counter\n\tClosureSizeBytes           prometheus.Summary\n\tNodeExecutionInputBytes    prometheus.Summary\n\tNodeExecutionOutputBytes   prometheus.Summary\n\tPublishEventError          prometheus.Counter\n}\n\ntype NodeExecutionManager struct {\n\tdb                  repoInterfaces.Repository\n\tconfig              runtimeInterfaces.Configuration\n\tstoragePrefix       []string\n\tstorageClient       *storage.DataStore\n\tmetrics             nodeExecutionMetrics\n\turlData             dataInterfaces.RemoteURLInterface\n\teventPublisher      notificationInterfaces.Publisher\n\tcloudEventPublisher cloudeventInterfaces.Publisher\n\tdbEventWriter       eventWriter.NodeExecutionEventWriter\n}\n\ntype updateNodeExecutionStatus int\n\nconst (\n\tupdateSucceeded updateNodeExecutionStatus = iota\n\tupdateFailed\n\talreadyInTerminalStatus\n)\n\nvar isParent = common.NewMapFilter(map[string]interface{}{\n\tshared.ParentTaskExecutionID: nil,\n\tshared.ParentID:              nil,\n})\n\nfunc getNodeExecutionContext(ctx context.Context, identifier *core.NodeExecutionIdentifier) context.Context {\n\tctx = contextutils.WithProjectDomain(ctx, identifier.ExecutionId.Project, identifier.ExecutionId.Domain)\n\tctx = contextutils.WithExecutionID(ctx, identifier.ExecutionId.Name)\n\treturn contextutils.WithNodeID(ctx, identifier.NodeId)\n}\n\nfunc (m *NodeExecutionManager) createNodeExecutionWithEvent(\n\tctx context.Context, request *admin.NodeExecutionEventRequest, dynamicWorkflowRemoteClosureReference string) error {\n\tvar parentTaskExecutionID *uint\n\tif request.Event.ParentTaskMetadata != nil {\n\t\ttaskExecutionModel, err := util.GetTaskExecutionModel(ctx, m.db, request.Event.ParentTaskMetadata.Id)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tparentTaskExecutionID = &taskExecutionModel.ID\n\t}\n\tvar parentID *uint\n\tif request.Event.ParentNodeMetadata != nil {\n\t\tparentNodeExecutionModel, err := util.GetNodeExecutionModel(ctx, m.db, &core.NodeExecutionIdentifier{\n\t\t\tExecutionId: request.Event.Id.ExecutionId,\n\t\t\tNodeId:      request.Event.ParentNodeMetadata.NodeId,\n\t\t})\n\t\tif err != nil {\n\t\t\tlogger.Errorf(ctx, \"failed to fetch node execution for the parent node: %v %s with err\",\n\t\t\t\trequest.Event.Id.ExecutionId, request.Event.ParentNodeMetadata.NodeId, err)\n\t\t\treturn err\n\t\t}\n\t\tparentID = &parentNodeExecutionModel.ID\n\t}\n\tnodeExecutionModel, err := transformers.CreateNodeExecutionModel(ctx, transformers.ToNodeExecutionModelInput{\n\t\tRequest:                      request,\n\t\tParentTaskExecutionID:        parentTaskExecutionID,\n\t\tParentID:                     parentID,\n\t\tDynamicWorkflowRemoteClosure: dynamicWorkflowRemoteClosureReference,\n\t\tInlineEventDataPolicy:        m.config.ApplicationConfiguration().GetRemoteDataConfig().InlineEventDataPolicy,\n\t\tStorageClient:                m.storageClient,\n\t})\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"failed to create node execution model for event request: %s with err: %v\",\n\t\t\trequest.RequestId, err)\n\t\treturn err\n\t}\n\tif err := m.db.NodeExecutionRepo().Create(ctx, nodeExecutionModel); err != nil {\n\t\tlogger.Debugf(ctx, \"Failed to create node execution with id [%+v] and model [%+v] \"+\n\t\t\t\"with err %v\", request.Event.Id, nodeExecutionModel, err)\n\t\treturn err\n\t}\n\tm.metrics.ClosureSizeBytes.Observe(float64(len(nodeExecutionModel.Closure)))\n\treturn nil\n}\n\nfunc (m *NodeExecutionManager) updateNodeExecutionWithEvent(\n\tctx context.Context, request *admin.NodeExecutionEventRequest, nodeExecutionModel *models.NodeExecution,\n\tdynamicWorkflowRemoteClosureReference string) (updateNodeExecutionStatus, error) {\n\t// If we have an existing execution, check if the phase change is valid\n\tnodeExecPhase := core.NodeExecution_Phase(core.NodeExecution_Phase_value[nodeExecutionModel.Phase])\n\tif nodeExecPhase == request.Event.Phase {\n\t\tlogger.Debugf(ctx, \"This phase was already recorded %v for %+v\", nodeExecPhase.String(), request.Event.Id)\n\t\treturn updateFailed, errors.NewFlyteAdminErrorf(codes.AlreadyExists,\n\t\t\t\"This phase was already recorded %v for %+v\", nodeExecPhase.String(), request.Event.Id)\n\t} else if common.IsNodeExecutionTerminal(nodeExecPhase) {\n\t\t// Cannot go from a terminal state to anything else\n\t\tlogger.Warnf(ctx, \"Invalid phase change from %v to %v for node execution %v\",\n\t\t\tnodeExecPhase.String(), request.Event.Phase.String(), request.Event.Id)\n\t\treturn alreadyInTerminalStatus, nil\n\t}\n\n\t// if this node execution kicked off a workflow, validate that the execution exists\n\tvar childExecutionID *core.WorkflowExecutionIdentifier\n\tif request.Event.GetWorkflowNodeMetadata() != nil {\n\t\tchildExecutionID = request.Event.GetWorkflowNodeMetadata().ExecutionId\n\t\terr := validation.ValidateWorkflowExecutionIdentifier(childExecutionID)\n\t\tif err != nil {\n\t\t\tlogger.Errorf(ctx, \"Invalid execution ID: %s with err: %v\",\n\t\t\t\tchildExecutionID, err)\n\t\t}\n\t\t_, err = util.GetExecutionModel(ctx, m.db, *childExecutionID)\n\t\tif err != nil {\n\t\t\tlogger.Errorf(ctx, \"The node execution launched an execution but it does not exist: %s with err: %v\",\n\t\t\t\tchildExecutionID, err)\n\t\t\treturn updateFailed, err\n\t\t}\n\t}\n\terr := transformers.UpdateNodeExecutionModel(ctx, request, nodeExecutionModel, childExecutionID,\n\t\tdynamicWorkflowRemoteClosureReference, m.config.ApplicationConfiguration().GetRemoteDataConfig().InlineEventDataPolicy,\n\t\tm.storageClient)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"failed to update node execution model: %+v with err: %v\", request.Event.Id, err)\n\t\treturn updateFailed, err\n\t}\n\terr = m.db.NodeExecutionRepo().Update(ctx, nodeExecutionModel)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"Failed to update node execution with id [%+v] with err %v\",\n\t\t\trequest.Event.Id, err)\n\t\treturn updateFailed, err\n\t}\n\n\treturn updateSucceeded, nil\n}\n\nfunc formatDynamicWorkflowID(identifier *core.Identifier) string {\n\treturn fmt.Sprintf(\"%s_%s_%s_%s\", identifier.Project, identifier.Domain, identifier.Name, identifier.Version)\n}\n\nfunc (m *NodeExecutionManager) uploadDynamicWorkflowClosure(\n\tctx context.Context, nodeID *core.NodeExecutionIdentifier, workflowID *core.Identifier,\n\tcompiledWorkflowClosure *core.CompiledWorkflowClosure) (storage.DataReference, error) {\n\tnestedSubKeys := []string{\n\t\tnodeID.ExecutionId.Project,\n\t\tnodeID.ExecutionId.Domain,\n\t\tnodeID.ExecutionId.Name,\n\t\tnodeID.NodeId,\n\t\tformatDynamicWorkflowID(workflowID),\n\t}\n\tnestedKeys := append(m.storagePrefix, nestedSubKeys...)\n\tremoteClosureDataRef, err := m.storageClient.ConstructReference(ctx, m.storageClient.GetBaseContainerFQN(ctx), nestedKeys...)\n\n\tif err != nil {\n\t\treturn \"\", errors.NewFlyteAdminErrorf(codes.Internal,\n\t\t\t\"Failed to produce remote closure data reference for dynamic workflow yielded by node id [%+v] with workflow id [%+v]; err: %v\", nodeID, workflowID, err)\n\t}\n\n\terr = m.storageClient.WriteProtobuf(ctx, remoteClosureDataRef, defaultStorageOptions, compiledWorkflowClosure)\n\tif err != nil {\n\t\treturn \"\", errors.NewFlyteAdminErrorf(codes.Internal,\n\t\t\t\"Failed to upload dynamic workflow closure for node id [%+v] and workflow id [%+v] with err: %v\", nodeID, workflowID, err)\n\t}\n\treturn remoteClosureDataRef, nil\n}\n\nfunc (m *NodeExecutionManager) CreateNodeEvent(ctx context.Context, request admin.NodeExecutionEventRequest) (\n\t*admin.NodeExecutionEventResponse, error) {\n\tif err := validation.ValidateNodeExecutionEventRequest(&request, m.config.ApplicationConfiguration().GetRemoteDataConfig().MaxSizeInBytes); err != nil {\n\t\tlogger.Debugf(ctx, \"CreateNodeEvent called with invalid identifier [%+v]: %v\", request.Event.Id, err)\n\t}\n\tctx = getNodeExecutionContext(ctx, request.Event.Id)\n\tlogger.Debugf(ctx, \"Received node execution event for Node Exec Id [%+v] transitioning to phase [%v], w/ Metadata [%v]\",\n\t\trequest.Event.Id, request.Event.Phase, request.Event.ParentTaskMetadata)\n\n\texecutionID := request.Event.Id.ExecutionId\n\tworkflowExecution, err := m.db.ExecutionRepo().Get(ctx, repoInterfaces.Identifier{\n\t\tProject: executionID.Project,\n\t\tDomain:  executionID.Domain,\n\t\tName:    executionID.Name,\n\t})\n\tif err != nil {\n\t\tm.metrics.MissingWorkflowExecution.Inc()\n\t\tlogger.Debugf(ctx, \"Failed to find existing execution with id [%+v] with err: %v\", executionID, err)\n\t\tif err != nil {\n\t\t\tif ferr, ok := err.(errors.FlyteAdminError); ok {\n\t\t\t\treturn nil, errors.NewFlyteAdminErrorf(ferr.Code(),\n\t\t\t\t\t\"Failed to get existing execution id: [%+v] with err: %v\", executionID, err)\n\t\t\t}\n\t\t}\n\t\treturn nil, fmt.Errorf(\"failed to get existing execution id: [%+v]\", executionID)\n\t}\n\n\tif err := validation.ValidateCluster(ctx, workflowExecution.Cluster, request.Event.ProducerId); err != nil {\n\t\treturn nil, err\n\t}\n\n\tvar dynamicWorkflowRemoteClosureReference string\n\tif request.Event.GetTaskNodeMetadata() != nil && request.Event.GetTaskNodeMetadata().DynamicWorkflow != nil {\n\t\tdynamicWorkflowRemoteClosureDataReference, err := m.uploadDynamicWorkflowClosure(\n\t\t\tctx, request.Event.Id, request.Event.GetTaskNodeMetadata().DynamicWorkflow.Id,\n\t\t\trequest.Event.GetTaskNodeMetadata().DynamicWorkflow.CompiledWorkflow)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tdynamicWorkflowRemoteClosureReference = dynamicWorkflowRemoteClosureDataReference.String()\n\t}\n\n\tnodeExecutionModel, err := m.db.NodeExecutionRepo().Get(ctx, repoInterfaces.NodeExecutionResource{\n\t\tNodeExecutionIdentifier: *request.Event.Id,\n\t})\n\tif err != nil {\n\t\tif err.(errors.FlyteAdminError).Code() != codes.NotFound {\n\t\t\tlogger.Debugf(ctx, \"Failed to retrieve existing node execution with id [%+v] with err: %v\",\n\t\t\t\trequest.Event.Id, err)\n\t\t\treturn nil, err\n\t\t}\n\t\terr = m.createNodeExecutionWithEvent(ctx, &request, dynamicWorkflowRemoteClosureReference)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tm.metrics.NodeExecutionsCreated.Inc()\n\t} else {\n\t\tphase := core.NodeExecution_Phase(core.NodeExecution_Phase_value[nodeExecutionModel.Phase])\n\t\tupdateStatus, err := m.updateNodeExecutionWithEvent(ctx, &request, &nodeExecutionModel, dynamicWorkflowRemoteClosureReference)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tif updateStatus == alreadyInTerminalStatus {\n\t\t\tcurPhase := request.Event.Phase.String()\n\t\t\terrorMsg := fmt.Sprintf(\"Invalid phase change from %s to %s for node execution %v\", phase.String(), curPhase, nodeExecutionModel.ID)\n\t\t\treturn nil, errors.NewAlreadyInTerminalStateError(ctx, errorMsg, curPhase)\n\t\t}\n\t}\n\tm.dbEventWriter.Write(request)\n\n\tif request.Event.Phase == core.NodeExecution_RUNNING {\n\t\tm.metrics.ActiveNodeExecutions.Inc()\n\t} else if common.IsNodeExecutionTerminal(request.Event.Phase) {\n\t\tm.metrics.ActiveNodeExecutions.Dec()\n\t\tm.metrics.NodeExecutionsTerminated.Inc(contextutils.WithPhase(ctx, request.Event.Phase.String()))\n\t\tif request.Event.GetOutputData() != nil {\n\t\t\tm.metrics.NodeExecutionOutputBytes.Observe(float64(proto.Size(request.Event.GetOutputData())))\n\t\t}\n\t}\n\tm.metrics.NodeExecutionEventsCreated.Inc()\n\n\tif err := m.eventPublisher.Publish(ctx, proto.MessageName(&request), &request); err != nil {\n\t\tm.metrics.PublishEventError.Inc()\n\t\tlogger.Infof(ctx, \"error publishing event [%+v] with err: [%v]\", request.RequestId, err)\n\t}\n\n\tgo func() {\n\t\tif err := m.cloudEventPublisher.Publish(ctx, proto.MessageName(&request), &request); err != nil {\n\t\t\tlogger.Infof(ctx, \"error publishing cloud event [%+v] with err: [%v]\", request.RequestId, err)\n\t\t}\n\t}()\n\n\treturn &admin.NodeExecutionEventResponse{}, nil\n}\n\n// Handles making additional database calls, if necessary, to populate IsParent & IsDynamic data using the historical pattern of\n// preloading child node executions. Otherwise, simply calls transform on the input model.\nfunc (m *NodeExecutionManager) transformNodeExecutionModel(ctx context.Context, nodeExecutionModel models.NodeExecution,\n\tnodeExecutionID *core.NodeExecutionIdentifier, opts *transformers.ExecutionTransformerOptions) (*admin.NodeExecution, error) {\n\tinternalData, err := transformers.GetNodeExecutionInternalData(nodeExecutionModel.InternalData)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif internalData.EventVersion == 0 {\n\t\t// Issue more expensive query to determine whether this node is a parent and/or dynamic node.\n\t\tnodeExecutionModel, err = m.db.NodeExecutionRepo().GetWithChildren(ctx, repoInterfaces.NodeExecutionResource{\n\t\t\tNodeExecutionIdentifier: *nodeExecutionID,\n\t\t})\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\tnodeExecution, err := transformers.FromNodeExecutionModel(nodeExecutionModel, opts)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"failed to transform node execution model [%+v] to proto with err: %v\", nodeExecutionID, err)\n\t\treturn nil, err\n\t}\n\treturn nodeExecution, nil\n}\n\nfunc (m *NodeExecutionManager) transformNodeExecutionModelList(ctx context.Context, nodeExecutionModels []models.NodeExecution) ([]*admin.NodeExecution, error) {\n\tnodeExecutions := make([]*admin.NodeExecution, len(nodeExecutionModels))\n\tfor idx, nodeExecutionModel := range nodeExecutionModels {\n\t\tnodeExecution, err := m.transformNodeExecutionModel(ctx, nodeExecutionModel, &core.NodeExecutionIdentifier{\n\t\t\tExecutionId: &core.WorkflowExecutionIdentifier{\n\t\t\t\tProject: nodeExecutionModel.Project,\n\t\t\t\tDomain:  nodeExecutionModel.Domain,\n\t\t\t\tName:    nodeExecutionModel.Name,\n\t\t\t},\n\t\t\tNodeId: nodeExecutionModel.NodeID,\n\t\t}, transformers.ListExecutionTransformerOptions)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tnodeExecutions[idx] = nodeExecution\n\t}\n\treturn nodeExecutions, nil\n}\n\nfunc (m *NodeExecutionManager) GetNodeExecution(\n\tctx context.Context, request admin.NodeExecutionGetRequest) (*admin.NodeExecution, error) {\n\tif err := validation.ValidateNodeExecutionIdentifier(request.Id); err != nil {\n\t\tlogger.Debugf(ctx, \"get node execution called with invalid identifier [%+v]: %v\", request.Id, err)\n\t}\n\tctx = getNodeExecutionContext(ctx, request.Id)\n\tnodeExecutionModel, err := util.GetNodeExecutionModel(ctx, m.db, request.Id)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"Failed to get node execution with id [%+v] with err %v\",\n\t\t\trequest.Id, err)\n\t\treturn nil, err\n\t}\n\tnodeExecution, err := m.transformNodeExecutionModel(ctx, *nodeExecutionModel, request.Id, nil)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn nodeExecution, nil\n}\n\nfunc (m *NodeExecutionManager) listNodeExecutions(\n\tctx context.Context, identifierFilters []common.InlineFilter,\n\trequestFilters string, limit uint32, requestToken string, sortBy *admin.Sort, mapFilters []common.MapFilter) (\n\t*admin.NodeExecutionList, error) {\n\n\tfilters, err := util.AddRequestFilters(requestFilters, common.NodeExecution, identifierFilters)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tvar sortParameter common.SortParameter\n\tif sortBy != nil {\n\t\tsortParameter, err = common.NewSortParameter(*sortBy)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\toffset, err := validation.ValidateToken(requestToken)\n\tif err != nil {\n\t\treturn nil, errors.NewFlyteAdminErrorf(codes.InvalidArgument,\n\t\t\t\"invalid pagination token %s for ListNodeExecutions\", requestToken)\n\t}\n\tlistInput := repoInterfaces.ListResourceInput{\n\t\tLimit:         int(limit),\n\t\tOffset:        offset,\n\t\tInlineFilters: filters,\n\t\tSortParameter: sortParameter,\n\t}\n\n\tlistInput.MapFilters = mapFilters\n\toutput, err := m.db.NodeExecutionRepo().List(ctx, listInput)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"Failed to list node executions for request with err %v\", err)\n\t\treturn nil, err\n\t}\n\n\tvar token string\n\tif len(output.NodeExecutions) == int(limit) {\n\t\ttoken = strconv.Itoa(offset + len(output.NodeExecutions))\n\t}\n\tnodeExecutionList, err := m.transformNodeExecutionModelList(ctx, output.NodeExecutions)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"failed to transform node execution models for request with err: %v\", err)\n\t\treturn nil, err\n\t}\n\n\treturn &admin.NodeExecutionList{\n\t\tNodeExecutions: nodeExecutionList,\n\t\tToken:          token,\n\t}, nil\n}\n\nfunc (m *NodeExecutionManager) ListNodeExecutions(\n\tctx context.Context, request admin.NodeExecutionListRequest) (*admin.NodeExecutionList, error) {\n\t// Check required fields\n\tif err := validation.ValidateNodeExecutionListRequest(request); err != nil {\n\t\treturn nil, err\n\t}\n\tctx = getExecutionContext(ctx, request.WorkflowExecutionId)\n\n\tidentifierFilters, err := util.GetWorkflowExecutionIdentifierFilters(ctx, *request.WorkflowExecutionId)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tvar mapFilters []common.MapFilter\n\tif request.UniqueParentId != \"\" {\n\t\tparentNodeExecution, err := util.GetNodeExecutionModel(ctx, m.db, &core.NodeExecutionIdentifier{\n\t\t\tExecutionId: request.WorkflowExecutionId,\n\t\t\tNodeId:      request.UniqueParentId,\n\t\t})\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tparentIDFilter, err := common.NewSingleValueFilter(\n\t\t\tcommon.NodeExecution, common.Equal, shared.ParentID, parentNodeExecution.ID)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tidentifierFilters = append(identifierFilters, parentIDFilter)\n\t} else {\n\t\tmapFilters = []common.MapFilter{\n\t\t\tisParent,\n\t\t}\n\t}\n\treturn m.listNodeExecutions(\n\t\tctx, identifierFilters, request.Filters, request.Limit, request.Token, request.SortBy, mapFilters)\n}\n\n// Filters on node executions matching the execution parameters (execution project, domain, and name) as well as the\n// parent task execution id corresponding to the task execution identified in the request params.\nfunc (m *NodeExecutionManager) ListNodeExecutionsForTask(\n\tctx context.Context, request admin.NodeExecutionForTaskListRequest) (*admin.NodeExecutionList, error) {\n\t// Check required fields\n\tif err := validation.ValidateNodeExecutionForTaskListRequest(request); err != nil {\n\t\treturn nil, err\n\t}\n\tctx = getTaskExecutionContext(ctx, request.TaskExecutionId)\n\tidentifierFilters, err := util.GetWorkflowExecutionIdentifierFilters(\n\t\tctx, *request.TaskExecutionId.NodeExecutionId.ExecutionId)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tparentTaskExecutionModel, err := util.GetTaskExecutionModel(ctx, m.db, request.TaskExecutionId)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tnodeIDFilter, err := common.NewSingleValueFilter(\n\t\tcommon.NodeExecution, common.Equal, shared.ParentTaskExecutionID, parentTaskExecutionModel.ID)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tidentifierFilters = append(identifierFilters, nodeIDFilter)\n\treturn m.listNodeExecutions(\n\t\tctx, identifierFilters, request.Filters, request.Limit, request.Token, request.SortBy, nil)\n}\n\nfunc (m *NodeExecutionManager) GetNodeExecutionData(\n\tctx context.Context, request admin.NodeExecutionGetDataRequest) (*admin.NodeExecutionGetDataResponse, error) {\n\tif err := validation.ValidateNodeExecutionIdentifier(request.Id); err != nil {\n\t\tlogger.Debugf(ctx, \"can't get node execution data with invalid identifier [%+v]: %v\", request.Id, err)\n\t}\n\n\tctx = getNodeExecutionContext(ctx, request.Id)\n\tnodeExecutionModel, err := util.GetNodeExecutionModel(ctx, m.db, request.Id)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"Failed to get node execution with id [%+v] with err %v\",\n\t\t\trequest.Id, err)\n\t\treturn nil, err\n\t}\n\n\tnodeExecution, err := transformers.FromNodeExecutionModel(*nodeExecutionModel, transformers.DefaultExecutionTransformerOptions)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"failed to transform node execution model [%+v] when fetching data: %v\", request.Id, err)\n\t\treturn nil, err\n\t}\n\n\tinputs, inputURLBlob, err := util.GetInputs(ctx, m.urlData, m.config.ApplicationConfiguration().GetRemoteDataConfig(),\n\t\tm.storageClient, nodeExecution.InputUri)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\toutputs, outputURLBlob, err := util.GetOutputs(ctx, m.urlData, m.config.ApplicationConfiguration().GetRemoteDataConfig(),\n\t\tm.storageClient, nodeExecution.Closure)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tresponse := &admin.NodeExecutionGetDataResponse{\n\t\tInputs:      inputURLBlob,\n\t\tOutputs:     outputURLBlob,\n\t\tFullInputs:  inputs,\n\t\tFullOutputs: outputs,\n\t\tFlyteUrls:   common.FlyteURLsFromNodeExecutionID(*request.Id, nodeExecution.GetClosure() != nil && nodeExecution.GetClosure().GetDeckUri() != \"\"),\n\t}\n\n\tif len(nodeExecutionModel.DynamicWorkflowRemoteClosureReference) > 0 {\n\t\tclosure := &core.CompiledWorkflowClosure{}\n\t\terr := m.storageClient.ReadProtobuf(ctx, storage.DataReference(nodeExecutionModel.DynamicWorkflowRemoteClosureReference), closure)\n\t\tif err != nil {\n\t\t\treturn nil, errors.NewFlyteAdminErrorf(codes.Internal,\n\t\t\t\t\"Unable to read WorkflowClosure from location %s : %v\", nodeExecutionModel.DynamicWorkflowRemoteClosureReference, err)\n\t\t}\n\n\t\tif wf := closure.Primary; wf == nil {\n\t\t\treturn nil, errors.NewFlyteAdminErrorf(codes.Internal, \"Empty primary workflow definition in loaded dynamic workflow model.\")\n\t\t} else if template := wf.Template; template == nil {\n\t\t\treturn nil, errors.NewFlyteAdminErrorf(codes.Internal, \"Empty primary workflow template in loaded dynamic workflow model.\")\n\t\t} else {\n\t\t\tresponse.DynamicWorkflow = &admin.DynamicWorkflowNodeMetadata{\n\t\t\t\tId:                closure.Primary.Template.Id,\n\t\t\t\tCompiledWorkflow:  closure,\n\t\t\t\tDynamicJobSpecUri: nodeExecution.Closure.DynamicJobSpecUri,\n\t\t\t}\n\t\t}\n\t}\n\n\tm.metrics.NodeExecutionInputBytes.Observe(float64(response.Inputs.Bytes))\n\tif response.Outputs.Bytes > 0 {\n\t\tm.metrics.NodeExecutionOutputBytes.Observe(float64(response.Outputs.Bytes))\n\t} else if response.FullOutputs != nil {\n\t\tm.metrics.NodeExecutionOutputBytes.Observe(float64(proto.Size(response.FullOutputs)))\n\t}\n\n\treturn response, nil\n}\n\nfunc NewNodeExecutionManager(db repoInterfaces.Repository, config runtimeInterfaces.Configuration,\n\tstoragePrefix []string, storageClient *storage.DataStore, scope promutils.Scope, urlData dataInterfaces.RemoteURLInterface,\n\teventPublisher notificationInterfaces.Publisher, cloudEventPublisher cloudeventInterfaces.Publisher,\n\teventWriter eventWriter.NodeExecutionEventWriter) interfaces.NodeExecutionInterface {\n\tmetrics := nodeExecutionMetrics{\n\t\tScope: scope,\n\t\tActiveNodeExecutions: scope.MustNewGauge(\"active_node_executions\",\n\t\t\t\"overall count of active node executions\"),\n\t\tNodeExecutionsCreated: scope.MustNewCounter(\"node_executions_created\",\n\t\t\t\"overall count of node executions created\"),\n\t\tNodeExecutionsTerminated: labeled.NewCounter(\"node_executions_terminated\",\n\t\t\t\"overall count of terminated node executions\", scope),\n\t\tNodeExecutionEventsCreated: scope.MustNewCounter(\"node_execution_events_created\",\n\t\t\t\"overall count of successfully completed NodeExecutionEventRequest\"),\n\t\tMissingWorkflowExecution: scope.MustNewCounter(\"missing_workflow_execution\",\n\t\t\t\"overall count of node execution events received that are missing a parent workflow execution\"),\n\t\tClosureSizeBytes: scope.MustNewSummary(\"closure_size_bytes\",\n\t\t\t\"size in bytes of serialized node execution closure\"),\n\t\tNodeExecutionInputBytes: scope.MustNewSummary(\"input_size_bytes\",\n\t\t\t\"size in bytes of serialized node execution inputs\"),\n\t\tNodeExecutionOutputBytes: scope.MustNewSummary(\"output_size_bytes\",\n\t\t\t\"size in bytes of serialized node execution outputs\"),\n\t\tPublishEventError: scope.MustNewCounter(\"publish_event_error\",\n\t\t\t\"overall count of publish event errors when invoking publish()\"),\n\t}\n\treturn &NodeExecutionManager{\n\t\tdb:                  db,\n\t\tconfig:              config,\n\t\tstoragePrefix:       storagePrefix,\n\t\tstorageClient:       storageClient,\n\t\tmetrics:             metrics,\n\t\turlData:             urlData,\n\t\teventPublisher:      eventPublisher,\n\t\tdbEventWriter:       eventWriter,\n\t\tcloudEventPublisher: cloudEventPublisher,\n\t}\n}\n", "package impl\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"fmt\"\n\t\"testing\"\n\t\"time\"\n\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/transformers\"\n\n\t\"github.com/flyteorg/flyteadmin/pkg/manager/impl/util\"\n\n\tgenModel \"github.com/flyteorg/flyteadmin/pkg/repositories/gen/models\"\n\n\teventWriterMocks \"github.com/flyteorg/flyteadmin/pkg/async/events/mocks\"\n\n\t\"github.com/flyteorg/flyteadmin/pkg/manager/impl/testutils\"\n\t\"github.com/flyteorg/flytestdlib/storage\"\n\n\t\"github.com/flyteorg/flyteadmin/pkg/common\"\n\tcommonMocks \"github.com/flyteorg/flyteadmin/pkg/common/mocks\"\n\tdataMocks \"github.com/flyteorg/flyteadmin/pkg/data/mocks\"\n\tflyteAdminErrors \"github.com/flyteorg/flyteadmin/pkg/errors\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/interfaces\"\n\trepositoryMocks \"github.com/flyteorg/flyteadmin/pkg/repositories/mocks\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/models\"\n\t\"github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/admin\"\n\t\"github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/core\"\n\t\"github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/event\"\n\tmockScope \"github.com/flyteorg/flytestdlib/promutils\"\n\t\"github.com/golang/protobuf/proto\"\n\t\"github.com/golang/protobuf/ptypes\"\n\t\"github.com/stretchr/testify/assert\"\n\t\"google.golang.org/grpc/codes\"\n)\n\nvar occurredAt = time.Now().UTC()\nvar occurredAtProto, _ = ptypes.TimestampProto(occurredAt)\n\nvar dynamicWorkflowClosure = core.CompiledWorkflowClosure{\n\tPrimary: &core.CompiledWorkflow{\n\t\tTemplate: &core.WorkflowTemplate{\n\t\t\tId: &core.Identifier{\n\t\t\t\tResourceType: core.ResourceType_WORKFLOW,\n\t\t\t\tProject:      \"proj\",\n\t\t\t\tDomain:       \"domain\",\n\t\t\t\tName:         \"dynamic_wf\",\n\t\t\t\tVersion:      \"abc123\",\n\t\t\t},\n\t\t},\n\t},\n}\n\nvar request = admin.NodeExecutionEventRequest{\n\tRequestId: \"request id\",\n\tEvent: &event.NodeExecutionEvent{\n\t\tProducerId: \"propeller\",\n\t\tId: &core.NodeExecutionIdentifier{\n\t\t\tNodeId: \"node id\",\n\t\t\tExecutionId: &core.WorkflowExecutionIdentifier{\n\t\t\t\tProject: \"project\",\n\t\t\t\tDomain:  \"domain\",\n\t\t\t\tName:    \"name\",\n\t\t\t},\n\t\t},\n\t\tOccurredAt: occurredAtProto,\n\t\tPhase:      core.NodeExecution_RUNNING,\n\t\tInputValue: &event.NodeExecutionEvent_InputUri{\n\t\t\tInputUri: \"input uri\",\n\t\t},\n\t\tTargetMetadata: &event.NodeExecutionEvent_TaskNodeMetadata{\n\t\t\tTaskNodeMetadata: &event.TaskNodeMetadata{\n\t\t\t\tDynamicWorkflow: &event.DynamicWorkflowNodeMetadata{\n\t\t\t\t\tId:               dynamicWorkflowClosure.Primary.Template.Id,\n\t\t\t\t\tCompiledWorkflow: &dynamicWorkflowClosure,\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\tEventVersion: 2,\n\t},\n}\nvar internalData = genModel.NodeExecutionInternalData{\n\tEventVersion: 2,\n}\nvar internalDataBytes, _ = proto.Marshal(&internalData)\nvar nodeExecutionIdentifier = core.NodeExecutionIdentifier{\n\tNodeId: \"node id\",\n\tExecutionId: &core.WorkflowExecutionIdentifier{\n\t\tProject: \"project\",\n\t\tDomain:  \"domain\",\n\t\tName:    \"name\",\n\t},\n}\nvar workflowExecutionIdentifier = core.WorkflowExecutionIdentifier{\n\tProject: \"project\",\n\tDomain:  \"domain\",\n\tName:    \"name\",\n}\n\nvar mockNodeExecutionRemoteURL = dataMocks.NewMockRemoteURL()\n\nfunc addGetExecutionCallback(t *testing.T, repository interfaces.Repository) {\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetGetCallback(\n\t\tfunc(ctx context.Context, input interfaces.Identifier) (models.Execution, error) {\n\t\t\tassert.Equal(t, \"project\", input.Project)\n\t\t\tassert.Equal(t, \"domain\", input.Domain)\n\t\t\tassert.Equal(t, \"name\", input.Name)\n\t\t\treturn models.Execution{\n\t\t\t\tBaseModel: models.BaseModel{\n\t\t\t\t\tID: uint(8),\n\t\t\t\t},\n\t\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\t\tProject: \"project\",\n\t\t\t\t\tDomain:  \"domain\",\n\t\t\t\t\tName:    \"name\",\n\t\t\t\t},\n\t\t\t\tCluster: \"propeller\",\n\t\t\t}, nil\n\t\t})\n}\n\nfunc TestCreateNodeEvent(t *testing.T) {\n\trepository := repositoryMocks.NewMockRepository()\n\taddGetExecutionCallback(t, repository)\n\trepository.NodeExecutionRepo().(*repositoryMocks.MockNodeExecutionRepo).SetGetCallback(\n\t\tfunc(ctx context.Context, input interfaces.NodeExecutionResource) (models.NodeExecution, error) {\n\t\t\tassert.True(t, proto.Equal(&core.NodeExecutionIdentifier{\n\t\t\t\tNodeId:      \"node id\",\n\t\t\t\tExecutionId: &workflowExecutionIdentifier,\n\t\t\t}, &input.NodeExecutionIdentifier))\n\t\t\treturn models.NodeExecution{}, flyteAdminErrors.NewFlyteAdminError(codes.NotFound, \"foo\")\n\t\t})\n\texpectedClosure := admin.NodeExecutionClosure{\n\t\tPhase:     request.Event.Phase,\n\t\tStartedAt: occurredAtProto,\n\t\tCreatedAt: occurredAtProto,\n\t\tUpdatedAt: occurredAtProto,\n\t\tTargetMetadata: &admin.NodeExecutionClosure_TaskNodeMetadata{\n\t\t\tTaskNodeMetadata: &admin.TaskNodeMetadata{},\n\t\t},\n\t}\n\tclosureBytes, _ := proto.Marshal(&expectedClosure)\n\trepository.NodeExecutionRepo().(*repositoryMocks.MockNodeExecutionRepo).SetCreateCallback(\n\t\tfunc(ctx context.Context, input *models.NodeExecution) error {\n\t\t\tassert.Equal(t, models.NodeExecution{\n\t\t\t\tNodeExecutionKey: models.NodeExecutionKey{\n\t\t\t\t\tNodeID: \"node id\",\n\t\t\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\t\t\tProject: \"project\",\n\t\t\t\t\t\tDomain:  \"domain\",\n\t\t\t\t\t\tName:    \"name\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tPhase:                                 core.NodeExecution_RUNNING.String(),\n\t\t\t\tInputURI:                              \"input uri\",\n\t\t\t\tStartedAt:                             &occurredAt,\n\t\t\t\tClosure:                               closureBytes,\n\t\t\t\tNodeExecutionMetadata:                 []byte{},\n\t\t\t\tNodeExecutionCreatedAt:                &occurredAt,\n\t\t\t\tNodeExecutionUpdatedAt:                &occurredAt,\n\t\t\t\tDynamicWorkflowRemoteClosureReference: \"s3://bucket/admin/metadata/project/domain/name/node id/proj_domain_dynamic_wf_abc123\",\n\t\t\t\tInternalData:                          internalDataBytes,\n\t\t\t}, *input)\n\t\t\treturn nil\n\t\t})\n\n\tmockDbEventWriter := &eventWriterMocks.NodeExecutionEventWriter{}\n\tmockDbEventWriter.On(\"Write\", request)\n\tnodeExecManager := NewNodeExecutionManager(repository, getMockExecutionsConfigProvider(),\n\t\t[]string{\"admin\", \"metadata\"}, getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockNodeExecutionRemoteURL,\n\t\t&mockPublisher, &mockPublisher, mockDbEventWriter)\n\tresp, err := nodeExecManager.CreateNodeEvent(context.Background(), request)\n\tassert.Nil(t, err)\n\tassert.NotNil(t, resp)\n}\n\nfunc TestCreateNodeEvent_Update(t *testing.T) {\n\trepository := repositoryMocks.NewMockRepository()\n\taddGetExecutionCallback(t, repository)\n\trepository.NodeExecutionRepo().(*repositoryMocks.MockNodeExecutionRepo).SetGetCallback(\n\t\tfunc(ctx context.Context, input interfaces.NodeExecutionResource) (models.NodeExecution, error) {\n\t\t\tassert.True(t, proto.Equal(&core.NodeExecutionIdentifier{\n\t\t\t\tNodeId:      \"node id\",\n\t\t\t\tExecutionId: &workflowExecutionIdentifier,\n\t\t\t}, &input.NodeExecutionIdentifier))\n\t\t\treturn models.NodeExecution{\n\t\t\t\tNodeExecutionKey: models.NodeExecutionKey{\n\t\t\t\t\tNodeID: \"node id\",\n\t\t\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\t\t\tProject: \"project\",\n\t\t\t\t\t\tDomain:  \"domain\",\n\t\t\t\t\t\tName:    \"name\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tPhase:     core.NodeExecution_UNDEFINED.String(),\n\t\t\t\tInputURI:  \"input uri\",\n\t\t\t\tStartedAt: &occurredAt,\n\t\t\t}, nil\n\t\t})\n\trepository.NodeExecutionRepo().(*repositoryMocks.MockNodeExecutionRepo).SetUpdateCallback(\n\t\tfunc(ctx context.Context, nodeExecution *models.NodeExecution) error {\n\t\t\texpectedClosure := admin.NodeExecutionClosure{\n\t\t\t\tStartedAt: occurredAtProto,\n\t\t\t\tPhase:     core.NodeExecution_RUNNING,\n\t\t\t\tUpdatedAt: occurredAtProto,\n\t\t\t\tTargetMetadata: &admin.NodeExecutionClosure_TaskNodeMetadata{\n\t\t\t\t\tTaskNodeMetadata: &admin.TaskNodeMetadata{},\n\t\t\t\t},\n\t\t\t}\n\t\t\texpectedClosureBytes, _ := proto.Marshal(&expectedClosure)\n\t\t\tactualClosure := admin.NodeExecutionClosure{}\n\t\t\t_ = proto.Unmarshal(nodeExecution.Closure, &actualClosure)\n\t\t\tassert.Equal(t, models.NodeExecution{\n\t\t\t\tNodeExecutionKey: models.NodeExecutionKey{\n\t\t\t\t\tNodeID: \"node id\",\n\t\t\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\t\t\tProject: \"project\",\n\t\t\t\t\t\tDomain:  \"domain\",\n\t\t\t\t\t\tName:    \"name\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tPhase:                                 core.NodeExecution_RUNNING.String(),\n\t\t\t\tInputURI:                              \"input uri\",\n\t\t\t\tStartedAt:                             &occurredAt,\n\t\t\t\tClosure:                               expectedClosureBytes,\n\t\t\t\tNodeExecutionUpdatedAt:                &occurredAt,\n\t\t\t\tDynamicWorkflowRemoteClosureReference: \"s3://bucket/admin/metadata/project/domain/name/node id/proj_domain_dynamic_wf_abc123\",\n\t\t\t}, *nodeExecution)\n\n\t\t\treturn nil\n\t\t})\n\n\tmockDbEventWriter := &eventWriterMocks.NodeExecutionEventWriter{}\n\tmockDbEventWriter.On(\"Write\", request)\n\tnodeExecManager := NewNodeExecutionManager(repository, getMockExecutionsConfigProvider(),\n\t\t[]string{\"admin\", \"metadata\"}, getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockNodeExecutionRemoteURL, &mockPublisher, &mockPublisher, mockDbEventWriter)\n\tresp, err := nodeExecManager.CreateNodeEvent(context.Background(), request)\n\tassert.Nil(t, err)\n\tassert.NotNil(t, resp)\n}\n\nfunc TestCreateNodeEvent_MissingExecution(t *testing.T) {\n\trepository := repositoryMocks.NewMockRepository()\n\texpectedErr := flyteAdminErrors.NewFlyteAdminErrorf(codes.Internal, \"expected error\")\n\trepository.NodeExecutionRepo().(*repositoryMocks.MockNodeExecutionRepo).SetGetCallback(\n\t\tfunc(ctx context.Context, input interfaces.NodeExecutionResource) (models.NodeExecution, error) {\n\t\t\treturn models.NodeExecution{}, expectedErr\n\t\t})\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetGetCallback(\n\t\tfunc(ctx context.Context, input interfaces.Identifier) (models.Execution, error) {\n\t\t\treturn models.Execution{}, expectedErr\n\t\t})\n\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetGetCallback(func(ctx context.Context, input interfaces.Identifier) (models.Execution, error) {\n\t\treturn models.Execution{}, expectedErr\n\t})\n\tnodeExecManager := NewNodeExecutionManager(repository, getMockExecutionsConfigProvider(), make([]string, 0), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockNodeExecutionRemoteURL, &mockPublisher, &mockPublisher, &eventWriterMocks.NodeExecutionEventWriter{})\n\tresp, err := nodeExecManager.CreateNodeEvent(context.Background(), request)\n\tassert.EqualError(t, err, \"Failed to get existing execution id: [project:\\\"project\\\" domain:\\\"domain\\\" name:\\\"name\\\" ] with err: expected error\")\n\tassert.Nil(t, resp)\n}\n\nfunc TestCreateNodeEvent_CreateDatabaseError(t *testing.T) {\n\trepository := repositoryMocks.NewMockRepository()\n\taddGetExecutionCallback(t, repository)\n\trepository.NodeExecutionRepo().(*repositoryMocks.MockNodeExecutionRepo).SetGetCallback(\n\t\tfunc(ctx context.Context, input interfaces.NodeExecutionResource) (models.NodeExecution, error) {\n\t\t\treturn models.NodeExecution{}, flyteAdminErrors.NewFlyteAdminError(codes.NotFound, \"foo\")\n\t\t})\n\n\texpectedErr := errors.New(\"expected error\")\n\trepository.NodeExecutionRepo().(*repositoryMocks.MockNodeExecutionRepo).SetCreateCallback(\n\t\tfunc(ctx context.Context, input *models.NodeExecution) error {\n\t\t\treturn expectedErr\n\t\t})\n\tnodeExecManager := NewNodeExecutionManager(repository, getMockExecutionsConfigProvider(), make([]string, 0), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockNodeExecutionRemoteURL, nil, nil, &eventWriterMocks.NodeExecutionEventWriter{})\n\tresp, err := nodeExecManager.CreateNodeEvent(context.Background(), request)\n\tassert.EqualError(t, err, expectedErr.Error())\n\tassert.Nil(t, resp)\n}\n\nfunc TestCreateNodeEvent_UpdateDatabaseError(t *testing.T) {\n\trepository := repositoryMocks.NewMockRepository()\n\taddGetExecutionCallback(t, repository)\n\trepository.NodeExecutionRepo().(*repositoryMocks.MockNodeExecutionRepo).SetGetCallback(\n\t\tfunc(ctx context.Context, input interfaces.NodeExecutionResource) (models.NodeExecution, error) {\n\t\t\tassert.True(t, proto.Equal(&core.NodeExecutionIdentifier{\n\t\t\t\tNodeId:      \"node id\",\n\t\t\t\tExecutionId: &workflowExecutionIdentifier,\n\t\t\t}, &input.NodeExecutionIdentifier))\n\t\t\treturn models.NodeExecution{\n\t\t\t\tNodeExecutionKey: models.NodeExecutionKey{\n\t\t\t\t\tNodeID: \"node id\",\n\t\t\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\t\t\tProject: \"project\",\n\t\t\t\t\t\tDomain:  \"domain\",\n\t\t\t\t\t\tName:    \"name\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tPhase:     core.NodeExecution_UNDEFINED.String(),\n\t\t\t\tInputURI:  \"input uri\",\n\t\t\t\tStartedAt: &occurredAt,\n\t\t\t}, nil\n\t\t})\n\n\texpectedErr := errors.New(\"expected error\")\n\trepository.NodeExecutionRepo().(*repositoryMocks.MockNodeExecutionRepo).SetUpdateCallback(\n\t\tfunc(ctx context.Context, nodeExecution *models.NodeExecution) error {\n\t\t\treturn expectedErr\n\t\t})\n\tnodeExecManager := NewNodeExecutionManager(repository, getMockExecutionsConfigProvider(), make([]string, 0), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockNodeExecutionRemoteURL, nil, nil, &eventWriterMocks.NodeExecutionEventWriter{})\n\tresp, err := nodeExecManager.CreateNodeEvent(context.Background(), request)\n\tassert.EqualError(t, err, expectedErr.Error())\n\tassert.Nil(t, resp)\n}\n\nfunc TestCreateNodeEvent_UpdateTerminalEventError(t *testing.T) {\n\trepository := repositoryMocks.NewMockRepository()\n\taddGetExecutionCallback(t, repository)\n\trepository.NodeExecutionRepo().(*repositoryMocks.MockNodeExecutionRepo).SetGetCallback(\n\t\tfunc(ctx context.Context, input interfaces.NodeExecutionResource) (models.NodeExecution, error) {\n\t\t\tassert.True(t, proto.Equal(&core.NodeExecutionIdentifier{\n\t\t\t\tNodeId:      \"node id\",\n\t\t\t\tExecutionId: &workflowExecutionIdentifier,\n\t\t\t}, &input.NodeExecutionIdentifier))\n\t\t\treturn models.NodeExecution{\n\t\t\t\tNodeExecutionKey: models.NodeExecutionKey{\n\t\t\t\t\tNodeID: \"node id\",\n\t\t\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\t\t\tProject: \"project\",\n\t\t\t\t\t\tDomain:  \"domain\",\n\t\t\t\t\t\tName:    \"name\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tPhase:     core.NodeExecution_SUCCEEDED.String(),\n\t\t\t\tInputURI:  \"input uri\",\n\t\t\t\tStartedAt: &occurredAt,\n\t\t\t}, nil\n\t\t})\n\tnodeExecManager := NewNodeExecutionManager(repository, getMockExecutionsConfigProvider(), make([]string, 0), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockNodeExecutionRemoteURL, nil, nil, &eventWriterMocks.NodeExecutionEventWriter{})\n\tresp, err := nodeExecManager.CreateNodeEvent(context.Background(), request)\n\tassert.Nil(t, resp)\n\tassert.NotNil(t, err)\n\tadminError := err.(flyteAdminErrors.FlyteAdminError)\n\tassert.Equal(t, codes.FailedPrecondition, adminError.GRPCStatus().Code())\n\tdetails, ok := adminError.GRPCStatus().Details()[0].(*admin.EventFailureReason)\n\tassert.True(t, ok)\n\t_, ok = details.GetReason().(*admin.EventFailureReason_AlreadyInTerminalState)\n\tassert.True(t, ok)\n}\n\nfunc TestCreateNodeEvent_UpdateDuplicateEventError(t *testing.T) {\n\trepository := repositoryMocks.NewMockRepository()\n\taddGetExecutionCallback(t, repository)\n\trepository.NodeExecutionRepo().(*repositoryMocks.MockNodeExecutionRepo).SetGetCallback(\n\t\tfunc(ctx context.Context, input interfaces.NodeExecutionResource) (models.NodeExecution, error) {\n\t\t\tassert.True(t, proto.Equal(&core.NodeExecutionIdentifier{\n\t\t\t\tNodeId:      \"node id\",\n\t\t\t\tExecutionId: &workflowExecutionIdentifier,\n\t\t\t}, &input.NodeExecutionIdentifier))\n\t\t\treturn models.NodeExecution{\n\t\t\t\tNodeExecutionKey: models.NodeExecutionKey{\n\t\t\t\t\tNodeID: \"node id\",\n\t\t\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\t\t\tProject: \"project\",\n\t\t\t\t\t\tDomain:  \"domain\",\n\t\t\t\t\t\tName:    \"name\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tPhase:     core.NodeExecution_RUNNING.String(),\n\t\t\t\tInputURI:  \"input uri\",\n\t\t\t\tStartedAt: &occurredAt,\n\t\t\t}, nil\n\t\t})\n\tnodeExecManager := NewNodeExecutionManager(repository, getMockExecutionsConfigProvider(), make([]string, 0), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockNodeExecutionRemoteURL, nil, nil, &eventWriterMocks.NodeExecutionEventWriter{})\n\tresp, err := nodeExecManager.CreateNodeEvent(context.Background(), request)\n\tassert.Equal(t, codes.AlreadyExists, err.(flyteAdminErrors.FlyteAdminError).Code())\n\tassert.Nil(t, resp)\n}\n\nfunc TestCreateNodeEvent_FirstEventIsTerminal(t *testing.T) {\n\trepository := repositoryMocks.NewMockRepository()\n\taddGetExecutionCallback(t, repository)\n\trepository.NodeExecutionRepo().(*repositoryMocks.MockNodeExecutionRepo).SetGetCallback(\n\t\tfunc(ctx context.Context, input interfaces.NodeExecutionResource) (models.NodeExecution, error) {\n\t\t\treturn models.NodeExecution{}, flyteAdminErrors.NewFlyteAdminError(codes.NotFound, \"foo\")\n\t\t})\n\n\tsucceededRequest := admin.NodeExecutionEventRequest{\n\t\tRequestId: \"request id\",\n\t\tEvent: &event.NodeExecutionEvent{\n\t\t\tProducerId: \"propeller\",\n\t\t\tId: &core.NodeExecutionIdentifier{\n\t\t\t\tNodeId: \"node id\",\n\t\t\t\tExecutionId: &core.WorkflowExecutionIdentifier{\n\t\t\t\t\tProject: \"project\",\n\t\t\t\t\tDomain:  \"domain\",\n\t\t\t\t\tName:    \"name\",\n\t\t\t\t},\n\t\t\t},\n\t\t\tOccurredAt: occurredAtProto,\n\t\t\tPhase:      core.NodeExecution_SUCCEEDED,\n\t\t\tInputValue: &event.NodeExecutionEvent_InputUri{\n\t\t\t\tInputUri: \"input uri\",\n\t\t\t},\n\t\t},\n\t}\n\tmockDbEventWriter := &eventWriterMocks.NodeExecutionEventWriter{}\n\tmockDbEventWriter.On(\"Write\", succeededRequest)\n\tnodeExecManager := NewNodeExecutionManager(repository, getMockExecutionsConfigProvider(), make([]string, 0), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockNodeExecutionRemoteURL, &mockPublisher, &mockPublisher, mockDbEventWriter)\n\tresp, err := nodeExecManager.CreateNodeEvent(context.Background(), succeededRequest)\n\tassert.NotNil(t, resp)\n\tassert.Nil(t, err)\n}\n\nfunc TestTransformNodeExecutionModel(t *testing.T) {\n\tctx := context.TODO()\n\trepository := repositoryMocks.NewMockRepository()\n\tnodeExecID := &core.NodeExecutionIdentifier{\n\t\tNodeId:      \"node id\",\n\t\tExecutionId: &workflowExecutionIdentifier,\n\t}\n\tt.Run(\"event version 0\", func(t *testing.T) {\n\t\trepository.NodeExecutionRepo().(*repositoryMocks.MockNodeExecutionRepo).SetGetWithChildrenCallback(\n\t\t\tfunc(ctx context.Context, input interfaces.NodeExecutionResource) (models.NodeExecution, error) {\n\t\t\t\tassert.True(t, proto.Equal(nodeExecID, &input.NodeExecutionIdentifier))\n\t\t\t\treturn models.NodeExecution{\n\t\t\t\t\tNodeExecutionKey: models.NodeExecutionKey{\n\t\t\t\t\t\tNodeID: \"node id\",\n\t\t\t\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\t\t\t\tProject: \"project\",\n\t\t\t\t\t\t\tDomain:  \"domain\",\n\t\t\t\t\t\t\tName:    \"name\",\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t\tPhase:     core.NodeExecution_SUCCEEDED.String(),\n\t\t\t\t\tInputURI:  \"input uri\",\n\t\t\t\t\tStartedAt: &occurredAt,\n\t\t\t\t\tClosure:   closureBytes,\n\t\t\t\t\tChildNodeExecutions: []models.NodeExecution{\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tPhase: \"unknown\",\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t}, nil\n\t\t\t})\n\n\t\tmanager := NodeExecutionManager{\n\t\t\tdb: repository,\n\t\t}\n\t\tnodeExecution, err := manager.transformNodeExecutionModel(ctx, models.NodeExecution{}, nodeExecID, transformers.DefaultExecutionTransformerOptions)\n\t\tassert.NoError(t, err)\n\t\tassert.True(t, proto.Equal(nodeExecID, nodeExecution.Id))\n\t\tassert.True(t, nodeExecution.Metadata.IsParentNode)\n\t})\n\tt.Run(\"event version > 0\", func(t *testing.T) {\n\t\tmanager := NodeExecutionManager{\n\t\t\tdb: repository,\n\t\t}\n\t\tnodeExecutionMetadata := &admin.NodeExecutionMetaData{\n\t\t\tIsParentNode: true,\n\t\t\tIsDynamic:    true,\n\t\t\tSpecNodeId:   \"spec\",\n\t\t}\n\t\tnodeExecutionMetadataBytes, _ := proto.Marshal(nodeExecutionMetadata)\n\t\tnodeExecution, err := manager.transformNodeExecutionModel(ctx, models.NodeExecution{\n\t\t\tNodeExecutionKey: models.NodeExecutionKey{\n\t\t\t\tNodeID: \"node id\",\n\t\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\t\tProject: \"project\",\n\t\t\t\t\tDomain:  \"domain\",\n\t\t\t\t\tName:    \"name\",\n\t\t\t\t},\n\t\t\t},\n\t\t\tPhase:                 core.NodeExecution_SUCCEEDED.String(),\n\t\t\tInputURI:              \"input uri\",\n\t\t\tStartedAt:             &occurredAt,\n\t\t\tClosure:               closureBytes,\n\t\t\tNodeExecutionMetadata: nodeExecutionMetadataBytes,\n\t\t\tInternalData:          internalDataBytes,\n\t\t}, nodeExecID, transformers.DefaultExecutionTransformerOptions)\n\t\tassert.NoError(t, err)\n\t\tassert.True(t, nodeExecution.Metadata.IsParentNode)\n\t\tassert.True(t, nodeExecution.Metadata.IsDynamic)\n\t})\n\tt.Run(\"transform internal data err\", func(t *testing.T) {\n\t\tmanager := NodeExecutionManager{\n\t\t\tdb: repository,\n\t\t}\n\t\t_, err := manager.transformNodeExecutionModel(ctx, models.NodeExecution{\n\t\t\tInternalData: []byte(\"i'm invalid\"),\n\t\t}, nodeExecID, transformers.DefaultExecutionTransformerOptions)\n\t\tassert.NotNil(t, err)\n\t\tassert.Equal(t, err.(flyteAdminErrors.FlyteAdminError).Code(), codes.Internal)\n\t})\n\tt.Run(\"get with children err\", func(t *testing.T) {\n\t\texpectedErr := flyteAdminErrors.NewFlyteAdminError(codes.Internal, \"foo\")\n\t\trepository.NodeExecutionRepo().(*repositoryMocks.MockNodeExecutionRepo).SetGetWithChildrenCallback(\n\t\t\tfunc(ctx context.Context, input interfaces.NodeExecutionResource) (models.NodeExecution, error) {\n\t\t\t\tassert.True(t, proto.Equal(nodeExecID, &input.NodeExecutionIdentifier))\n\t\t\t\treturn models.NodeExecution{}, expectedErr\n\t\t\t})\n\n\t\tmanager := NodeExecutionManager{\n\t\t\tdb: repository,\n\t\t}\n\t\t_, err := manager.transformNodeExecutionModel(ctx, models.NodeExecution{}, nodeExecID, transformers.DefaultExecutionTransformerOptions)\n\t\tassert.Equal(t, err, expectedErr)\n\t})\n}\n\nfunc TestTransformNodeExecutionModelList(t *testing.T) {\n\tctx := context.TODO()\n\trepository := repositoryMocks.NewMockRepository()\n\trepository.NodeExecutionRepo().(*repositoryMocks.MockNodeExecutionRepo).SetGetWithChildrenCallback(\n\t\tfunc(ctx context.Context, input interfaces.NodeExecutionResource) (models.NodeExecution, error) {\n\t\t\treturn models.NodeExecution{\n\t\t\t\tNodeExecutionKey: models.NodeExecutionKey{\n\t\t\t\t\tNodeID: \"node id\",\n\t\t\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\t\t\tProject: \"project\",\n\t\t\t\t\t\tDomain:  \"domain\",\n\t\t\t\t\t\tName:    \"name\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tPhase:     core.NodeExecution_SUCCEEDED.String(),\n\t\t\t\tInputURI:  \"input uri\",\n\t\t\t\tStartedAt: &occurredAt,\n\t\t\t\tClosure:   closureBytes,\n\t\t\t\tChildNodeExecutions: []models.NodeExecution{\n\t\t\t\t\t{\n\t\t\t\t\t\tPhase: \"unknown\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t}, nil\n\t\t})\n\n\tmanager := NodeExecutionManager{\n\t\tdb: repository,\n\t}\n\tnodeExecutions, err := manager.transformNodeExecutionModelList(ctx, []models.NodeExecution{\n\t\t{\n\t\t\tPhase: \"unknown\",\n\t\t},\n\t})\n\tassert.NoError(t, err)\n\tassert.Len(t, nodeExecutions, 1)\n\n}\n\nfunc TestGetNodeExecution(t *testing.T) {\n\trepository := repositoryMocks.NewMockRepository()\n\texpectedClosure := admin.NodeExecutionClosure{\n\t\tPhase: core.NodeExecution_SUCCEEDED,\n\t\tTargetMetadata: &admin.NodeExecutionClosure_TaskNodeMetadata{\n\t\t\tTaskNodeMetadata: &admin.TaskNodeMetadata{\n\t\t\t\tCheckpointUri: \"last checkpoint uri\",\n\t\t\t},\n\t\t},\n\t}\n\texpectedMetadata := admin.NodeExecutionMetaData{\n\t\tSpecNodeId: \"spec_node_id\",\n\t\tRetryGroup: \"retry_group\",\n\t}\n\tmetadataBytes, _ := proto.Marshal(&expectedMetadata)\n\tclosureBytes, _ := proto.Marshal(&expectedClosure)\n\trepository.NodeExecutionRepo().(*repositoryMocks.MockNodeExecutionRepo).SetGetCallback(\n\t\tfunc(ctx context.Context, input interfaces.NodeExecutionResource) (models.NodeExecution, error) {\n\t\t\tworkflowExecutionIdentifier := core.WorkflowExecutionIdentifier{\n\t\t\t\tProject: \"project\",\n\t\t\t\tDomain:  \"domain\",\n\t\t\t\tName:    \"name\",\n\t\t\t}\n\t\t\tassert.True(t, proto.Equal(&core.NodeExecutionIdentifier{\n\t\t\t\tNodeId:      \"node id\",\n\t\t\t\tExecutionId: &workflowExecutionIdentifier,\n\t\t\t}, &input.NodeExecutionIdentifier))\n\t\t\treturn models.NodeExecution{\n\t\t\t\tNodeExecutionKey: models.NodeExecutionKey{\n\t\t\t\t\tNodeID: \"node id\",\n\t\t\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\t\t\tProject: \"project\",\n\t\t\t\t\t\tDomain:  \"domain\",\n\t\t\t\t\t\tName:    \"name\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tPhase:                 core.NodeExecution_SUCCEEDED.String(),\n\t\t\t\tInputURI:              \"input uri\",\n\t\t\t\tStartedAt:             &occurredAt,\n\t\t\t\tClosure:               closureBytes,\n\t\t\t\tNodeExecutionMetadata: metadataBytes,\n\t\t\t\tInternalData:          internalDataBytes,\n\t\t\t}, nil\n\t\t})\n\tnodeExecManager := NewNodeExecutionManager(repository, getMockExecutionsConfigProvider(), make([]string, 0), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockNodeExecutionRemoteURL, nil, nil, &eventWriterMocks.NodeExecutionEventWriter{})\n\tnodeExecution, err := nodeExecManager.GetNodeExecution(context.Background(), admin.NodeExecutionGetRequest{\n\t\tId: &nodeExecutionIdentifier,\n\t})\n\tassert.Nil(t, err)\n\tassert.True(t, proto.Equal(&admin.NodeExecution{\n\t\tId:       &nodeExecutionIdentifier,\n\t\tInputUri: \"input uri\",\n\t\tClosure:  &expectedClosure,\n\t\tMetadata: &expectedMetadata,\n\t}, nodeExecution))\n}\n\nfunc TestGetNodeExecutionParentNode(t *testing.T) {\n\trepository := repositoryMocks.NewMockRepository()\n\texpectedClosure := admin.NodeExecutionClosure{\n\t\tPhase: core.NodeExecution_SUCCEEDED,\n\t}\n\texpectedMetadata := admin.NodeExecutionMetaData{\n\t\tSpecNodeId: \"spec_node_id\",\n\t\tRetryGroup: \"retry_group\",\n\t}\n\tmetadataBytes, _ := proto.Marshal(&expectedMetadata)\n\tclosureBytes, _ := proto.Marshal(&expectedClosure)\n\trepository.NodeExecutionRepo().(*repositoryMocks.MockNodeExecutionRepo).SetGetWithChildrenCallback(\n\t\tfunc(\n\t\t\tctx context.Context, input interfaces.NodeExecutionResource) (models.NodeExecution, error) {\n\t\t\tworkflowExecutionIdentifier := core.WorkflowExecutionIdentifier{\n\t\t\t\tProject: \"project\",\n\t\t\t\tDomain:  \"domain\",\n\t\t\t\tName:    \"name\",\n\t\t\t}\n\t\t\tassert.True(t, proto.Equal(&core.NodeExecutionIdentifier{\n\t\t\t\tNodeId:      \"node id\",\n\t\t\t\tExecutionId: &workflowExecutionIdentifier,\n\t\t\t}, &input.NodeExecutionIdentifier))\n\t\t\treturn models.NodeExecution{\n\t\t\t\tNodeExecutionKey: models.NodeExecutionKey{\n\t\t\t\t\tNodeID: \"node id\",\n\t\t\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\t\t\tProject: \"project\",\n\t\t\t\t\t\tDomain:  \"domain\",\n\t\t\t\t\t\tName:    \"name\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tPhase:                 core.NodeExecution_SUCCEEDED.String(),\n\t\t\t\tInputURI:              \"input uri\",\n\t\t\t\tStartedAt:             &occurredAt,\n\t\t\t\tClosure:               closureBytes,\n\t\t\t\tNodeExecutionMetadata: metadataBytes,\n\t\t\t\tChildNodeExecutions: []models.NodeExecution{\n\t\t\t\t\t{\n\t\t\t\t\t\tNodeExecutionKey: models.NodeExecutionKey{\n\t\t\t\t\t\t\tNodeID: \"node-child\",\n\t\t\t\t\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\t\t\t\t\tProject: \"project\",\n\t\t\t\t\t\t\t\tDomain:  \"domain\",\n\t\t\t\t\t\t\t\tName:    \"name\",\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t}, nil\n\t\t})\n\tnodeExecManager := NewNodeExecutionManager(repository, getMockExecutionsConfigProvider(), make([]string, 0), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockNodeExecutionRemoteURL, nil, nil, &eventWriterMocks.NodeExecutionEventWriter{})\n\tnodeExecution, err := nodeExecManager.GetNodeExecution(context.Background(), admin.NodeExecutionGetRequest{\n\t\tId: &nodeExecutionIdentifier,\n\t})\n\tassert.Nil(t, err)\n\texpectedMetadata.IsParentNode = true\n\tassert.True(t, proto.Equal(&admin.NodeExecution{\n\t\tId:       &nodeExecutionIdentifier,\n\t\tInputUri: \"input uri\",\n\t\tClosure:  &expectedClosure,\n\t\tMetadata: &expectedMetadata,\n\t}, nodeExecution))\n}\n\nfunc TestGetNodeExecutionEventVersion0(t *testing.T) {\n\trepository := repositoryMocks.NewMockRepository()\n\texpectedClosure := admin.NodeExecutionClosure{\n\t\tPhase: core.NodeExecution_SUCCEEDED,\n\t}\n\texpectedMetadata := admin.NodeExecutionMetaData{\n\t\tSpecNodeId: \"spec_node_id\",\n\t\tRetryGroup: \"retry_group\",\n\t}\n\tmetadataBytes, _ := proto.Marshal(&expectedMetadata)\n\tclosureBytes, _ := proto.Marshal(&expectedClosure)\n\trepository.NodeExecutionRepo().(*repositoryMocks.MockNodeExecutionRepo).SetGetWithChildrenCallback(\n\t\tfunc(\n\t\t\tctx context.Context, input interfaces.NodeExecutionResource) (models.NodeExecution, error) {\n\t\t\tworkflowExecutionIdentifier := core.WorkflowExecutionIdentifier{\n\t\t\t\tProject: \"project\",\n\t\t\t\tDomain:  \"domain\",\n\t\t\t\tName:    \"name\",\n\t\t\t}\n\t\t\tassert.True(t, proto.Equal(&core.NodeExecutionIdentifier{\n\t\t\t\tNodeId:      \"node id\",\n\t\t\t\tExecutionId: &workflowExecutionIdentifier,\n\t\t\t}, &input.NodeExecutionIdentifier))\n\t\t\treturn models.NodeExecution{\n\t\t\t\tNodeExecutionKey: models.NodeExecutionKey{\n\t\t\t\t\tNodeID: \"node id\",\n\t\t\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\t\t\tProject: \"project\",\n\t\t\t\t\t\tDomain:  \"domain\",\n\t\t\t\t\t\tName:    \"name\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tPhase:                 core.NodeExecution_SUCCEEDED.String(),\n\t\t\t\tInputURI:              \"input uri\",\n\t\t\t\tStartedAt:             &occurredAt,\n\t\t\t\tClosure:               closureBytes,\n\t\t\t\tNodeExecutionMetadata: metadataBytes,\n\t\t\t}, nil\n\t\t})\n\n\tnodeExecManager := NewNodeExecutionManager(repository, getMockExecutionsConfigProvider(), make([]string, 0), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockNodeExecutionRemoteURL, nil, nil, &eventWriterMocks.NodeExecutionEventWriter{})\n\tnodeExecution, err := nodeExecManager.GetNodeExecution(context.Background(), admin.NodeExecutionGetRequest{\n\t\tId: &nodeExecutionIdentifier,\n\t})\n\tassert.Nil(t, err)\n\tassert.True(t, proto.Equal(&admin.NodeExecution{\n\t\tId:       &nodeExecutionIdentifier,\n\t\tInputUri: \"input uri\",\n\t\tClosure:  &expectedClosure,\n\t\tMetadata: &expectedMetadata,\n\t}, nodeExecution))\n}\n\nfunc TestGetNodeExecution_DatabaseError(t *testing.T) {\n\trepository := repositoryMocks.NewMockRepository()\n\texpectedErr := errors.New(\"expected error\")\n\trepository.NodeExecutionRepo().(*repositoryMocks.MockNodeExecutionRepo).SetGetCallback(\n\t\tfunc(ctx context.Context, input interfaces.NodeExecutionResource) (models.NodeExecution, error) {\n\t\t\treturn models.NodeExecution{}, expectedErr\n\t\t})\n\tnodeExecManager := NewNodeExecutionManager(repository, getMockExecutionsConfigProvider(), make([]string, 0), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockNodeExecutionRemoteURL, nil, nil, &eventWriterMocks.NodeExecutionEventWriter{})\n\tnodeExecution, err := nodeExecManager.GetNodeExecution(context.Background(), admin.NodeExecutionGetRequest{\n\t\tId: &nodeExecutionIdentifier,\n\t})\n\tassert.Nil(t, nodeExecution)\n\tassert.EqualError(t, err, expectedErr.Error())\n}\n\nfunc TestGetNodeExecution_TransformerError(t *testing.T) {\n\trepository := repositoryMocks.NewMockRepository()\n\trepository.NodeExecutionRepo().(*repositoryMocks.MockNodeExecutionRepo).SetGetCallback(\n\t\tfunc(ctx context.Context, input interfaces.NodeExecutionResource) (models.NodeExecution, error) {\n\t\t\treturn models.NodeExecution{\n\t\t\t\tNodeExecutionKey: models.NodeExecutionKey{\n\t\t\t\t\tNodeID: \"node id\",\n\t\t\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\t\t\tProject: \"project\",\n\t\t\t\t\t\tDomain:  \"domain\",\n\t\t\t\t\t\tName:    \"name\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tPhase:        core.NodeExecution_SUCCEEDED.String(),\n\t\t\t\tInputURI:     \"input uri\",\n\t\t\t\tStartedAt:    &occurredAt,\n\t\t\t\tClosure:      []byte(\"i'm invalid\"),\n\t\t\t\tInternalData: internalDataBytes,\n\t\t\t}, nil\n\t\t})\n\tnodeExecManager := NewNodeExecutionManager(repository, getMockExecutionsConfigProvider(), make([]string, 0), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockNodeExecutionRemoteURL, nil, nil, &eventWriterMocks.NodeExecutionEventWriter{})\n\tnodeExecution, err := nodeExecManager.GetNodeExecution(context.Background(), admin.NodeExecutionGetRequest{\n\t\tId: &nodeExecutionIdentifier,\n\t})\n\tassert.Nil(t, nodeExecution)\n\tassert.Equal(t, err.(flyteAdminErrors.FlyteAdminError).Code(), codes.Internal)\n}\n\nfunc TestListNodeExecutionsLevelZero(t *testing.T) {\n\trepository := repositoryMocks.NewMockRepository()\n\texpectedClosure := admin.NodeExecutionClosure{\n\t\tPhase: core.NodeExecution_SUCCEEDED,\n\t}\n\texpectedMetadata := admin.NodeExecutionMetaData{\n\t\tSpecNodeId: \"spec_node_id\",\n\t\tRetryGroup: \"retry_group\",\n\t}\n\tmetadataBytes, _ := proto.Marshal(&expectedMetadata)\n\tclosureBytes, _ := proto.Marshal(&expectedClosure)\n\n\trepository.NodeExecutionRepo().(*repositoryMocks.MockNodeExecutionRepo).SetListCallback(\n\t\tfunc(ctx context.Context, input interfaces.ListResourceInput) (\n\t\t\tinterfaces.NodeExecutionCollectionOutput, error) {\n\t\t\tassert.Equal(t, 1, input.Limit)\n\t\t\tassert.Equal(t, 2, input.Offset)\n\t\t\tassert.Len(t, input.InlineFilters, 3)\n\t\t\tassert.Equal(t, common.Execution, input.InlineFilters[0].GetEntity())\n\t\t\tqueryExpr, _ := input.InlineFilters[0].GetGormQueryExpr()\n\t\t\tassert.Equal(t, \"project\", queryExpr.Args)\n\t\t\tassert.Equal(t, \"execution_project = ?\", queryExpr.Query)\n\n\t\t\tassert.Equal(t, common.Execution, input.InlineFilters[1].GetEntity())\n\t\t\tqueryExpr, _ = input.InlineFilters[1].GetGormQueryExpr()\n\t\t\tassert.Equal(t, \"domain\", queryExpr.Args)\n\t\t\tassert.Equal(t, \"execution_domain = ?\", queryExpr.Query)\n\n\t\t\tassert.Equal(t, common.Execution, input.InlineFilters[2].GetEntity())\n\t\t\tqueryExpr, _ = input.InlineFilters[2].GetGormQueryExpr()\n\t\t\tassert.Equal(t, \"name\", queryExpr.Args)\n\t\t\tassert.Equal(t, \"execution_name = ?\", queryExpr.Query)\n\n\t\t\tassert.Len(t, input.MapFilters, 1)\n\t\t\tfilter := input.MapFilters[0].GetFilter()\n\t\t\tassert.Equal(t, map[string]interface{}{\n\t\t\t\t\"parent_id\":                nil,\n\t\t\t\t\"parent_task_execution_id\": nil,\n\t\t\t}, filter)\n\n\t\t\tassert.Equal(t, \"domain asc\", input.SortParameter.GetGormOrderExpr())\n\t\t\treturn interfaces.NodeExecutionCollectionOutput{\n\t\t\t\tNodeExecutions: []models.NodeExecution{\n\t\t\t\t\t{\n\t\t\t\t\t\tNodeExecutionKey: models.NodeExecutionKey{\n\t\t\t\t\t\t\tNodeID: \"node id\",\n\t\t\t\t\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\t\t\t\t\tProject: \"project\",\n\t\t\t\t\t\t\t\tDomain:  \"domain\",\n\t\t\t\t\t\t\t\tName:    \"name\",\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t\tPhase:                 core.NodeExecution_SUCCEEDED.String(),\n\t\t\t\t\t\tInputURI:              \"input uri\",\n\t\t\t\t\t\tStartedAt:             &occurredAt,\n\t\t\t\t\t\tClosure:               closureBytes,\n\t\t\t\t\t\tNodeExecutionMetadata: metadataBytes,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t}, nil\n\t\t})\n\trepository.NodeExecutionRepo().(*repositoryMocks.MockNodeExecutionRepo).SetGetWithChildrenCallback(\n\t\tfunc(\n\t\t\tctx context.Context, input interfaces.NodeExecutionResource) (models.NodeExecution, error) {\n\t\t\treturn models.NodeExecution{\n\t\t\t\tNodeExecutionKey: models.NodeExecutionKey{\n\t\t\t\t\tNodeID: \"node id\",\n\t\t\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\t\t\tProject: \"project\",\n\t\t\t\t\t\tDomain:  \"domain\",\n\t\t\t\t\t\tName:    \"name\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tPhase:                 core.NodeExecution_SUCCEEDED.String(),\n\t\t\t\tInputURI:              \"input uri\",\n\t\t\t\tStartedAt:             &occurredAt,\n\t\t\t\tClosure:               closureBytes,\n\t\t\t\tNodeExecutionMetadata: metadataBytes,\n\t\t\t}, nil\n\t\t})\n\tnodeExecManager := NewNodeExecutionManager(repository, getMockExecutionsConfigProvider(), make([]string, 0), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockNodeExecutionRemoteURL, nil, nil, &eventWriterMocks.NodeExecutionEventWriter{})\n\tnodeExecutions, err := nodeExecManager.ListNodeExecutions(context.Background(), admin.NodeExecutionListRequest{\n\t\tWorkflowExecutionId: &core.WorkflowExecutionIdentifier{\n\t\t\tProject: \"project\",\n\t\t\tDomain:  \"domain\",\n\t\t\tName:    \"name\",\n\t\t},\n\t\tLimit: 1,\n\t\tToken: \"2\",\n\t\tSortBy: &admin.Sort{\n\t\t\tDirection: admin.Sort_ASCENDING,\n\t\t\tKey:       \"domain\",\n\t\t},\n\t})\n\tassert.Nil(t, err)\n\tassert.Len(t, nodeExecutions.NodeExecutions, 1)\n\tassert.True(t, proto.Equal(&admin.NodeExecution{\n\t\tId: &core.NodeExecutionIdentifier{\n\t\t\tNodeId: \"node id\",\n\t\t\tExecutionId: &core.WorkflowExecutionIdentifier{\n\t\t\t\tProject: \"project\",\n\t\t\t\tDomain:  \"domain\",\n\t\t\t\tName:    \"name\",\n\t\t\t},\n\t\t},\n\t\tInputUri: \"input uri\",\n\t\tClosure:  &expectedClosure,\n\t\tMetadata: &expectedMetadata,\n\t}, nodeExecutions.NodeExecutions[0]))\n\tassert.Equal(t, \"3\", nodeExecutions.Token)\n}\n\nfunc TestListNodeExecutionsWithParent(t *testing.T) {\n\trepository := repositoryMocks.NewMockRepository()\n\texpectedClosure := admin.NodeExecutionClosure{\n\t\tPhase: core.NodeExecution_SUCCEEDED,\n\t}\n\texpectedMetadata := admin.NodeExecutionMetaData{\n\t\tSpecNodeId: \"spec_node_id\",\n\t\tRetryGroup: \"retry_group\",\n\t}\n\tmetadataBytes, _ := proto.Marshal(&expectedMetadata)\n\tclosureBytes, _ := proto.Marshal(&expectedClosure)\n\tparentID := uint(12)\n\trepository.NodeExecutionRepo().(*repositoryMocks.MockNodeExecutionRepo).SetGetCallback(func(ctx context.Context, input interfaces.NodeExecutionResource) (execution models.NodeExecution, e error) {\n\t\tassert.Equal(t, \"parent_1\", input.NodeExecutionIdentifier.NodeId)\n\t\treturn models.NodeExecution{\n\t\t\tBaseModel: models.BaseModel{\n\t\t\t\tID: parentID,\n\t\t\t},\n\t\t}, nil\n\t})\n\trepository.NodeExecutionRepo().(*repositoryMocks.MockNodeExecutionRepo).SetListCallback(\n\t\tfunc(ctx context.Context, input interfaces.ListResourceInput) (\n\t\t\tinterfaces.NodeExecutionCollectionOutput, error) {\n\t\t\tassert.Equal(t, 1, input.Limit)\n\t\t\tassert.Equal(t, 2, input.Offset)\n\t\t\tassert.Len(t, input.InlineFilters, 4)\n\t\t\tassert.Equal(t, common.Execution, input.InlineFilters[0].GetEntity())\n\t\t\tqueryExpr, _ := input.InlineFilters[0].GetGormQueryExpr()\n\t\t\tassert.Equal(t, \"project\", queryExpr.Args)\n\t\t\tassert.Equal(t, \"execution_project = ?\", queryExpr.Query)\n\n\t\t\tassert.Equal(t, common.Execution, input.InlineFilters[1].GetEntity())\n\t\t\tqueryExpr, _ = input.InlineFilters[1].GetGormQueryExpr()\n\t\t\tassert.Equal(t, \"domain\", queryExpr.Args)\n\t\t\tassert.Equal(t, \"execution_domain = ?\", queryExpr.Query)\n\n\t\t\tassert.Equal(t, common.Execution, input.InlineFilters[2].GetEntity())\n\t\t\tqueryExpr, _ = input.InlineFilters[2].GetGormQueryExpr()\n\t\t\tassert.Equal(t, \"name\", queryExpr.Args)\n\t\t\tassert.Equal(t, \"execution_name = ?\", queryExpr.Query)\n\n\t\t\tassert.Equal(t, common.NodeExecution, input.InlineFilters[3].GetEntity())\n\t\t\tqueryExpr, _ = input.InlineFilters[3].GetGormQueryExpr()\n\t\t\tassert.Equal(t, parentID, queryExpr.Args)\n\t\t\tassert.Equal(t, \"parent_id = ?\", queryExpr.Query)\n\n\t\t\tassert.Equal(t, \"domain asc\", input.SortParameter.GetGormOrderExpr())\n\t\t\treturn interfaces.NodeExecutionCollectionOutput{\n\t\t\t\tNodeExecutions: []models.NodeExecution{\n\t\t\t\t\t{\n\t\t\t\t\t\tNodeExecutionKey: models.NodeExecutionKey{\n\t\t\t\t\t\t\tNodeID: \"node id\",\n\t\t\t\t\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\t\t\t\t\tProject: \"project\",\n\t\t\t\t\t\t\t\tDomain:  \"domain\",\n\t\t\t\t\t\t\t\tName:    \"name\",\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t\tPhase:                 core.NodeExecution_SUCCEEDED.String(),\n\t\t\t\t\t\tInputURI:              \"input uri\",\n\t\t\t\t\t\tStartedAt:             &occurredAt,\n\t\t\t\t\t\tClosure:               closureBytes,\n\t\t\t\t\t\tNodeExecutionMetadata: metadataBytes,\n\t\t\t\t\t\tInternalData:          internalDataBytes,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t}, nil\n\t\t})\n\tnodeExecManager := NewNodeExecutionManager(repository, getMockExecutionsConfigProvider(), make([]string, 0), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockNodeExecutionRemoteURL, nil, nil, &eventWriterMocks.NodeExecutionEventWriter{})\n\tnodeExecutions, err := nodeExecManager.ListNodeExecutions(context.Background(), admin.NodeExecutionListRequest{\n\t\tWorkflowExecutionId: &core.WorkflowExecutionIdentifier{\n\t\t\tProject: \"project\",\n\t\t\tDomain:  \"domain\",\n\t\t\tName:    \"name\",\n\t\t},\n\t\tLimit: 1,\n\t\tToken: \"2\",\n\t\tSortBy: &admin.Sort{\n\t\t\tDirection: admin.Sort_ASCENDING,\n\t\t\tKey:       \"domain\",\n\t\t},\n\t\tUniqueParentId: \"parent_1\",\n\t})\n\tassert.Nil(t, err)\n\tassert.Len(t, nodeExecutions.NodeExecutions, 1)\n\tassert.True(t, proto.Equal(&admin.NodeExecution{\n\t\tId: &core.NodeExecutionIdentifier{\n\t\t\tNodeId: \"node id\",\n\t\t\tExecutionId: &core.WorkflowExecutionIdentifier{\n\t\t\t\tProject: \"project\",\n\t\t\t\tDomain:  \"domain\",\n\t\t\t\tName:    \"name\",\n\t\t\t},\n\t\t},\n\t\tInputUri: \"input uri\",\n\t\tClosure:  &expectedClosure,\n\t\tMetadata: &expectedMetadata,\n\t}, nodeExecutions.NodeExecutions[0]))\n\tassert.Equal(t, \"3\", nodeExecutions.Token)\n}\n\nfunc TestListNodeExecutions_InvalidParams(t *testing.T) {\n\tnodeExecManager := NewNodeExecutionManager(nil, getMockExecutionsConfigProvider(), make([]string, 0), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockNodeExecutionRemoteURL, nil, nil, &eventWriterMocks.NodeExecutionEventWriter{})\n\t_, err := nodeExecManager.ListNodeExecutions(context.Background(), admin.NodeExecutionListRequest{\n\t\tFilters: \"eq(execution.project, project)\",\n\t})\n\tassert.Equal(t, codes.InvalidArgument, err.(flyteAdminErrors.FlyteAdminError).Code())\n\n\t_, err = nodeExecManager.ListNodeExecutions(context.Background(), admin.NodeExecutionListRequest{\n\t\tLimit: 1,\n\t})\n\tassert.Equal(t, codes.InvalidArgument, err.(flyteAdminErrors.FlyteAdminError).Code())\n\n\t_, err = nodeExecManager.ListNodeExecutions(context.Background(), admin.NodeExecutionListRequest{\n\t\tLimit:   1,\n\t\tFilters: \"foo\",\n\t})\n\tassert.Equal(t, codes.InvalidArgument, err.(flyteAdminErrors.FlyteAdminError).Code())\n}\n\nfunc TestListNodeExecutions_DatabaseError(t *testing.T) {\n\trepository := repositoryMocks.NewMockRepository()\n\texpectedErr := errors.New(\"expected error\")\n\trepository.NodeExecutionRepo().(*repositoryMocks.MockNodeExecutionRepo).SetListCallback(\n\t\tfunc(ctx context.Context, input interfaces.ListResourceInput) (\n\t\t\tinterfaces.NodeExecutionCollectionOutput, error) {\n\t\t\treturn interfaces.NodeExecutionCollectionOutput{}, expectedErr\n\t\t})\n\tnodeExecManager := NewNodeExecutionManager(repository, getMockExecutionsConfigProvider(), make([]string, 0), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockNodeExecutionRemoteURL, nil, nil, &eventWriterMocks.NodeExecutionEventWriter{})\n\tnodeExecutions, err := nodeExecManager.ListNodeExecutions(context.Background(), admin.NodeExecutionListRequest{\n\t\tWorkflowExecutionId: &core.WorkflowExecutionIdentifier{\n\t\t\tProject: \"project\",\n\t\t\tDomain:  \"domain\",\n\t\t\tName:    \"name\",\n\t\t},\n\t\tLimit: 1,\n\t\tToken: \"2\",\n\t})\n\tassert.Nil(t, nodeExecutions)\n\tassert.EqualError(t, err, expectedErr.Error())\n}\n\nfunc TestListNodeExecutions_TransformerError(t *testing.T) {\n\trepository := repositoryMocks.NewMockRepository()\n\trepository.NodeExecutionRepo().(*repositoryMocks.MockNodeExecutionRepo).SetListCallback(\n\t\tfunc(ctx context.Context, input interfaces.ListResourceInput) (\n\t\t\tinterfaces.NodeExecutionCollectionOutput, error) {\n\t\t\treturn interfaces.NodeExecutionCollectionOutput{\n\t\t\t\tNodeExecutions: []models.NodeExecution{\n\t\t\t\t\t{\n\t\t\t\t\t\tNodeExecutionKey: models.NodeExecutionKey{\n\t\t\t\t\t\t\tNodeID: \"node id\",\n\t\t\t\t\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\t\t\t\t\tProject: \"project\",\n\t\t\t\t\t\t\t\tDomain:  \"domain\",\n\t\t\t\t\t\t\t\tName:    \"name\",\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t\tPhase:        core.NodeExecution_SUCCEEDED.String(),\n\t\t\t\t\t\tInputURI:     \"input uri\",\n\t\t\t\t\t\tStartedAt:    &occurredAt,\n\t\t\t\t\t\tClosure:      []byte(\"i'm invalid\"),\n\t\t\t\t\t\tInternalData: internalDataBytes,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t}, nil\n\t\t})\n\tnodeExecManager := NewNodeExecutionManager(repository, getMockExecutionsConfigProvider(), make([]string, 0), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockNodeExecutionRemoteURL, nil, nil, &eventWriterMocks.NodeExecutionEventWriter{})\n\tnodeExecutions, err := nodeExecManager.ListNodeExecutions(context.Background(), admin.NodeExecutionListRequest{\n\t\tWorkflowExecutionId: &core.WorkflowExecutionIdentifier{\n\t\t\tProject: \"project\",\n\t\t\tDomain:  \"domain\",\n\t\t\tName:    \"name\",\n\t\t},\n\t\tLimit: 1,\n\t\tToken: \"2\",\n\t})\n\tassert.Nil(t, nodeExecutions)\n\tassert.Equal(t, err.(flyteAdminErrors.FlyteAdminError).Code(), codes.Internal)\n}\n\nfunc TestListNodeExecutions_NothingToReturn(t *testing.T) {\n\trepository := repositoryMocks.NewMockRepository()\n\trepository.NodeExecutionRepo().(*repositoryMocks.MockNodeExecutionRepo).SetListCallback(\n\t\tfunc(ctx context.Context, input interfaces.ListResourceInput) (\n\t\t\tinterfaces.NodeExecutionCollectionOutput, error) {\n\t\t\treturn interfaces.NodeExecutionCollectionOutput{}, nil\n\t\t})\n\tvar listExecutionsCalled bool\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetListCallback(\n\t\tfunc(ctx context.Context, input interfaces.ListResourceInput) (\n\t\t\tinterfaces.ExecutionCollectionOutput, error) {\n\t\t\tlistExecutionsCalled = true\n\t\t\treturn interfaces.ExecutionCollectionOutput{}, nil\n\t\t})\n\tnodeExecManager := NewNodeExecutionManager(repository, getMockExecutionsConfigProvider(), make([]string, 0), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockNodeExecutionRemoteURL, nil, nil, &eventWriterMocks.NodeExecutionEventWriter{})\n\t_, err := nodeExecManager.ListNodeExecutions(context.Background(), admin.NodeExecutionListRequest{\n\t\tWorkflowExecutionId: &core.WorkflowExecutionIdentifier{\n\t\t\tProject: \"project\",\n\t\t\tDomain:  \"domain\",\n\t\t\tName:    \"name\",\n\t\t},\n\t\tLimit: 1,\n\t\tToken: \"2\",\n\t\tSortBy: &admin.Sort{\n\t\t\tDirection: admin.Sort_ASCENDING,\n\t\t\tKey:       \"domain\",\n\t\t},\n\t})\n\tassert.Nil(t, err)\n\tassert.False(t, listExecutionsCalled)\n}\n\nfunc TestListNodeExecutionsForTask(t *testing.T) {\n\trepository := repositoryMocks.NewMockRepository()\n\texpectedClosure := admin.NodeExecutionClosure{\n\t\tPhase: core.NodeExecution_SUCCEEDED,\n\t}\n\texecMetadata := admin.NodeExecutionMetaData{\n\t\tSpecNodeId:   \"spec-n1\",\n\t\tIsParentNode: true,\n\t}\n\n\tclosureBytes, _ := proto.Marshal(&expectedClosure)\n\texecMetadataBytes, _ := proto.Marshal(&execMetadata)\n\n\trepository.TaskExecutionRepo().(*repositoryMocks.MockTaskExecutionRepo).SetGetCallback(\n\t\tfunc(ctx context.Context, input interfaces.GetTaskExecutionInput) (models.TaskExecution, error) {\n\t\t\treturn models.TaskExecution{\n\t\t\t\tBaseModel: models.BaseModel{\n\t\t\t\t\tID: uint(8),\n\t\t\t\t},\n\t\t\t}, nil\n\t\t})\n\trepository.NodeExecutionRepo().(*repositoryMocks.MockNodeExecutionRepo).SetListCallback(\n\t\tfunc(ctx context.Context, input interfaces.ListResourceInput) (\n\t\t\tinterfaces.NodeExecutionCollectionOutput, error) {\n\t\t\tassert.Equal(t, 1, input.Limit)\n\t\t\tassert.Equal(t, 2, input.Offset)\n\t\t\tassert.Len(t, input.InlineFilters, 4)\n\t\t\tassert.Equal(t, common.Execution, input.InlineFilters[0].GetEntity())\n\t\t\tqueryExpr, _ := input.InlineFilters[0].GetGormQueryExpr()\n\t\t\tassert.Equal(t, \"project\", queryExpr.Args)\n\t\t\tassert.Equal(t, \"execution_project = ?\", queryExpr.Query)\n\n\t\t\tassert.Equal(t, common.Execution, input.InlineFilters[1].GetEntity())\n\t\t\tqueryExpr, _ = input.InlineFilters[1].GetGormQueryExpr()\n\t\t\tassert.Equal(t, \"domain\", queryExpr.Args)\n\t\t\tassert.Equal(t, \"execution_domain = ?\", queryExpr.Query)\n\n\t\t\tassert.Equal(t, common.Execution, input.InlineFilters[2].GetEntity())\n\t\t\tqueryExpr, _ = input.InlineFilters[2].GetGormQueryExpr()\n\t\t\tassert.Equal(t, \"name\", queryExpr.Args)\n\t\t\tassert.Equal(t, \"execution_name = ?\", queryExpr.Query)\n\n\t\t\tassert.Equal(t, common.NodeExecution, input.InlineFilters[3].GetEntity())\n\t\t\tqueryExpr, _ = input.InlineFilters[3].GetGormQueryExpr()\n\t\t\tassert.Equal(t, uint(8), queryExpr.Args)\n\t\t\tassert.Equal(t, \"parent_task_execution_id = ?\", queryExpr.Query)\n\n\t\t\tassert.Equal(t, \"domain asc\", input.SortParameter.GetGormOrderExpr())\n\t\t\treturn interfaces.NodeExecutionCollectionOutput{\n\t\t\t\tNodeExecutions: []models.NodeExecution{\n\t\t\t\t\t{\n\t\t\t\t\t\tNodeExecutionKey: models.NodeExecutionKey{\n\t\t\t\t\t\t\tNodeID: \"node id\",\n\t\t\t\t\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\t\t\t\t\tProject: \"project\",\n\t\t\t\t\t\t\t\tDomain:  \"domain\",\n\t\t\t\t\t\t\t\tName:    \"name\",\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t\tPhase:                 core.NodeExecution_SUCCEEDED.String(),\n\t\t\t\t\t\tInputURI:              \"input uri\",\n\t\t\t\t\t\tStartedAt:             &occurredAt,\n\t\t\t\t\t\tClosure:               closureBytes,\n\t\t\t\t\t\tNodeExecutionMetadata: execMetadataBytes,\n\t\t\t\t\t\tInternalData:          internalDataBytes,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t}, nil\n\t\t})\n\tnodeExecManager := NewNodeExecutionManager(repository, getMockExecutionsConfigProvider(), make([]string, 0), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockNodeExecutionRemoteURL, nil, nil, &eventWriterMocks.NodeExecutionEventWriter{})\n\tnodeExecutions, err := nodeExecManager.ListNodeExecutionsForTask(context.Background(), admin.NodeExecutionForTaskListRequest{\n\t\tTaskExecutionId: &core.TaskExecutionIdentifier{\n\t\t\tNodeExecutionId: &core.NodeExecutionIdentifier{\n\t\t\t\tExecutionId: &core.WorkflowExecutionIdentifier{\n\t\t\t\t\tProject: \"project\",\n\t\t\t\t\tDomain:  \"domain\",\n\t\t\t\t\tName:    \"name\",\n\t\t\t\t},\n\t\t\t\tNodeId: \"node_id\",\n\t\t\t},\n\t\t\tTaskId: &core.Identifier{\n\t\t\t\tResourceType: core.ResourceType_TASK,\n\t\t\t\tProject:      \"project\",\n\t\t\t\tDomain:       \"domain\",\n\t\t\t\tName:         \"name\",\n\t\t\t\tVersion:      \"version\",\n\t\t\t},\n\t\t},\n\t\tLimit: 1,\n\t\tToken: \"2\",\n\t\tSortBy: &admin.Sort{\n\t\t\tDirection: admin.Sort_ASCENDING,\n\t\t\tKey:       \"domain\",\n\t\t},\n\t})\n\tassert.Nil(t, err)\n\tassert.Len(t, nodeExecutions.NodeExecutions, 1)\n\texpectedMetadata := admin.NodeExecutionMetaData{\n\t\tSpecNodeId:   \"spec-n1\",\n\t\tIsParentNode: true,\n\t}\n\tassert.True(t, proto.Equal(&admin.NodeExecution{\n\t\tId: &core.NodeExecutionIdentifier{\n\t\t\tNodeId: \"node id\",\n\t\t\tExecutionId: &core.WorkflowExecutionIdentifier{\n\t\t\t\tProject: \"project\",\n\t\t\t\tDomain:  \"domain\",\n\t\t\t\tName:    \"name\",\n\t\t\t},\n\t\t},\n\t\tInputUri: \"input uri\",\n\t\tClosure:  &expectedClosure,\n\t\tMetadata: &expectedMetadata,\n\t}, nodeExecutions.NodeExecutions[0]))\n\tassert.Equal(t, \"3\", nodeExecutions.Token)\n}\n\nfunc TestGetNodeExecutionData(t *testing.T) {\n\trepository := repositoryMocks.NewMockRepository()\n\texpectedClosure := admin.NodeExecutionClosure{\n\t\tPhase: core.NodeExecution_SUCCEEDED,\n\t\tOutputResult: &admin.NodeExecutionClosure_OutputUri{\n\t\t\tOutputUri: util.OutputsFile,\n\t\t},\n\t\tDeckUri: util.DeckFile,\n\t}\n\tdynamicWorkflowClosureRef := \"s3://my-s3-bucket/foo/bar/dynamic.pb\"\n\n\tclosureBytes, _ := proto.Marshal(&expectedClosure)\n\trepository.NodeExecutionRepo().(*repositoryMocks.MockNodeExecutionRepo).SetGetCallback(\n\t\tfunc(ctx context.Context, input interfaces.NodeExecutionResource) (models.NodeExecution, error) {\n\t\t\tworkflowExecutionIdentifier := core.WorkflowExecutionIdentifier{\n\t\t\t\tProject: \"project\",\n\t\t\t\tDomain:  \"domain\",\n\t\t\t\tName:    \"name\",\n\t\t\t}\n\t\t\tassert.True(t, proto.Equal(&core.NodeExecutionIdentifier{\n\t\t\t\tNodeId:      \"node id\",\n\t\t\t\tExecutionId: &workflowExecutionIdentifier,\n\t\t\t}, &input.NodeExecutionIdentifier))\n\t\t\treturn models.NodeExecution{\n\t\t\t\tNodeExecutionKey: models.NodeExecutionKey{\n\t\t\t\t\tNodeID: \"node id\",\n\t\t\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\t\t\tProject: \"project\",\n\t\t\t\t\t\tDomain:  \"domain\",\n\t\t\t\t\t\tName:    \"name\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tPhase:                                 core.NodeExecution_SUCCEEDED.String(),\n\t\t\t\tInputURI:                              \"input uri\",\n\t\t\t\tStartedAt:                             &occurredAt,\n\t\t\t\tClosure:                               closureBytes,\n\t\t\t\tDynamicWorkflowRemoteClosureReference: dynamicWorkflowClosureRef,\n\t\t\t}, nil\n\t\t})\n\n\tmockNodeExecutionRemoteURL := dataMocks.NewMockRemoteURL()\n\tmockNodeExecutionRemoteURL.(*dataMocks.MockRemoteURL).GetCallback = func(ctx context.Context, uri string) (admin.UrlBlob, error) {\n\t\tif uri == \"input uri\" {\n\t\t\treturn admin.UrlBlob{\n\t\t\t\tUrl:   \"inputs\",\n\t\t\t\tBytes: 100,\n\t\t\t}, nil\n\t\t} else if uri == util.OutputsFile {\n\t\t\treturn admin.UrlBlob{\n\t\t\t\tUrl:   \"outputs\",\n\t\t\t\tBytes: 200,\n\t\t\t}, nil\n\t\t}\n\n\t\treturn admin.UrlBlob{}, errors.New(\"unexpected input\")\n\t}\n\tmockStorage := commonMocks.GetMockStorageClient()\n\tfullInputs := &core.LiteralMap{\n\t\tLiterals: map[string]*core.Literal{\n\t\t\t\"foo\": testutils.MakeStringLiteral(\"foo-value-1\"),\n\t\t},\n\t}\n\tfullOutputs := &core.LiteralMap{\n\t\tLiterals: map[string]*core.Literal{\n\t\t\t\"bar\": testutils.MakeStringLiteral(\"bar-value-1\"),\n\t\t},\n\t}\n\n\tmockStorage.ComposedProtobufStore.(*commonMocks.TestDataStore).ReadProtobufCb = func(\n\t\tctx context.Context, reference storage.DataReference, msg proto.Message) error {\n\t\tif reference.String() == \"input uri\" {\n\t\t\tmarshalled, _ := proto.Marshal(fullInputs)\n\t\t\t_ = proto.Unmarshal(marshalled, msg)\n\t\t\treturn nil\n\t\t} else if reference.String() == util.OutputsFile {\n\t\t\tmarshalled, _ := proto.Marshal(fullOutputs)\n\t\t\t_ = proto.Unmarshal(marshalled, msg)\n\t\t\treturn nil\n\t\t} else if reference.String() == dynamicWorkflowClosureRef {\n\t\t\tmarshalled, _ := proto.Marshal(&dynamicWorkflowClosure)\n\t\t\t_ = proto.Unmarshal(marshalled, msg)\n\t\t\treturn nil\n\t\t}\n\t\treturn fmt.Errorf(\"unexpected call to find value in storage [%v]\", reference.String())\n\t}\n\tnodeExecManager := NewNodeExecutionManager(repository, getMockExecutionsConfigProvider(), make([]string, 0), mockStorage, mockScope.NewTestScope(), mockNodeExecutionRemoteURL, nil, nil, &eventWriterMocks.NodeExecutionEventWriter{})\n\tdataResponse, err := nodeExecManager.GetNodeExecutionData(context.Background(), admin.NodeExecutionGetDataRequest{\n\t\tId: &nodeExecutionIdentifier,\n\t})\n\tassert.NoError(t, err)\n\tassert.True(t, proto.Equal(&admin.NodeExecutionGetDataResponse{\n\t\tInputs: &admin.UrlBlob{\n\t\t\tUrl:   \"inputs\",\n\t\t\tBytes: 100,\n\t\t},\n\t\tOutputs: &admin.UrlBlob{\n\t\t\tUrl:   \"outputs\",\n\t\t\tBytes: 200,\n\t\t},\n\t\tFullInputs:  fullInputs,\n\t\tFullOutputs: fullOutputs,\n\t\tDynamicWorkflow: &admin.DynamicWorkflowNodeMetadata{\n\t\t\tId:               dynamicWorkflowClosure.Primary.Template.Id,\n\t\t\tCompiledWorkflow: &dynamicWorkflowClosure,\n\t\t},\n\t\tFlyteUrls: &admin.FlyteURLs{\n\t\t\tInputs:  \"flyte://v1/project/domain/name/node id/i\",\n\t\t\tOutputs: \"flyte://v1/project/domain/name/node id/o\",\n\t\t\tDeck:    \"flyte://v1/project/domain/name/node id/d\",\n\t\t},\n\t}, dataResponse))\n}\n", "package impl\n\nimport (\n\t\"context\"\n\t\"strconv\"\n\n\t\"github.com/flyteorg/flyteadmin/pkg/common\"\n\t\"github.com/flyteorg/flyteadmin/pkg/errors\"\n\t\"github.com/flyteorg/flyteadmin/pkg/manager/impl/util\"\n\t\"github.com/flyteorg/flyteadmin/pkg/manager/impl/validation\"\n\t\"github.com/flyteorg/flyteadmin/pkg/manager/interfaces\"\n\trepoInterfaces \"github.com/flyteorg/flyteadmin/pkg/repositories/interfaces\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/transformers\"\n\truntimeInterfaces \"github.com/flyteorg/flyteadmin/pkg/runtime/interfaces\"\n\t\"github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/admin\"\n\t\"google.golang.org/grpc/codes\"\n)\n\ntype ProjectManager struct {\n\tdb     repoInterfaces.Repository\n\tconfig runtimeInterfaces.Configuration\n}\n\nvar alphabeticalSortParam, _ = common.NewSortParameter(admin.Sort{\n\tDirection: admin.Sort_ASCENDING,\n\tKey:       \"identifier\",\n})\n\nfunc (m *ProjectManager) CreateProject(ctx context.Context, request admin.ProjectRegisterRequest) (\n\t*admin.ProjectRegisterResponse, error) {\n\tif err := validation.ValidateProjectRegisterRequest(request); err != nil {\n\t\treturn nil, err\n\t}\n\tprojectModel := transformers.CreateProjectModel(request.Project)\n\terr := m.db.ProjectRepo().Create(ctx, projectModel)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &admin.ProjectRegisterResponse{}, nil\n}\n\nfunc (m *ProjectManager) getDomains() []*admin.Domain {\n\tconfigDomains := m.config.ApplicationConfiguration().GetDomainsConfig()\n\tvar domains = make([]*admin.Domain, len(*configDomains))\n\tfor index, configDomain := range *configDomains {\n\t\tdomains[index] = &admin.Domain{\n\t\t\tId:   configDomain.ID,\n\t\t\tName: configDomain.Name,\n\t\t}\n\t}\n\treturn domains\n}\n\nfunc (m *ProjectManager) ListProjects(ctx context.Context, request admin.ProjectListRequest) (*admin.Projects, error) {\n\tspec := util.FilterSpec{\n\t\tRequestFilters: request.Filters,\n\t}\n\tfilters, err := util.GetDbFilters(spec, common.Project)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tvar sortParameter common.SortParameter\n\tif request.SortBy != nil {\n\t\tsortParameter, err = common.NewSortParameter(*request.SortBy)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t} else {\n\t\tsortParameter = alphabeticalSortParam\n\t}\n\n\toffset, err := validation.ValidateToken(request.Token)\n\tif err != nil {\n\t\treturn nil, errors.NewFlyteAdminErrorf(codes.InvalidArgument,\n\t\t\t\"invalid pagination token %s for ListProjects\", request.Token)\n\t}\n\n\t// And finally, query the database\n\tlistProjectsInput := repoInterfaces.ListResourceInput{\n\t\tLimit:         int(request.Limit),\n\t\tOffset:        offset,\n\t\tInlineFilters: filters,\n\t\tSortParameter: sortParameter,\n\t}\n\tprojectModels, err := m.db.ProjectRepo().List(ctx, listProjectsInput)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tprojects := transformers.FromProjectModels(projectModels, m.getDomains())\n\n\tvar token string\n\tif len(projects) == int(request.Limit) {\n\t\ttoken = strconv.Itoa(offset + len(projects))\n\t}\n\n\treturn &admin.Projects{\n\t\tProjects: projects,\n\t\tToken:    token,\n\t}, nil\n}\n\nfunc (m *ProjectManager) UpdateProject(ctx context.Context, projectUpdate admin.Project) (*admin.ProjectUpdateResponse, error) {\n\tvar response admin.ProjectUpdateResponse\n\tprojectRepo := m.db.ProjectRepo()\n\n\t// Fetch the existing project if exists. If not, return err and do not update.\n\t_, err := projectRepo.Get(ctx, projectUpdate.Id)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// Run validation on the request and return err if validation does not succeed.\n\tif err := validation.ValidateProject(projectUpdate); err != nil {\n\t\treturn nil, err\n\t}\n\n\t// Transform the provided project into a model and apply to the DB.\n\tprojectUpdateModel := transformers.CreateProjectModel(&projectUpdate)\n\terr = projectRepo.UpdateProject(ctx, projectUpdateModel)\n\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &response, nil\n}\n\nfunc NewProjectManager(db repoInterfaces.Repository, config runtimeInterfaces.Configuration) interfaces.ProjectInterface {\n\treturn &ProjectManager{\n\t\tdb:     db,\n\t\tconfig: config,\n\t}\n}\n", "package impl\n\nimport (\n\t\"context\"\n\t\"strconv\"\n\n\t\"github.com/flyteorg/flytestdlib/contextutils\"\n\n\t\"github.com/flyteorg/flyteadmin/pkg/common\"\n\t\"github.com/flyteorg/flyteadmin/pkg/errors\"\n\t\"github.com/flyteorg/flyteadmin/pkg/manager/impl/util\"\n\t\"github.com/flyteorg/flyteadmin/pkg/manager/impl/validation\"\n\t\"github.com/flyteorg/flyteadmin/pkg/manager/interfaces\"\n\trepoInterfaces \"github.com/flyteorg/flyteadmin/pkg/repositories/interfaces\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/transformers\"\n\n\t\"github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/admin\"\n\t\"github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/core\"\n\n\t\"github.com/flyteorg/flytestdlib/logger\"\n\t\"github.com/flyteorg/flytestdlib/promutils\"\n\t\"github.com/flyteorg/flytestdlib/promutils/labeled\"\n\n\t\"google.golang.org/grpc/codes\"\n)\n\ntype signalMetrics struct {\n\tScope promutils.Scope\n\tSet   labeled.Counter\n}\n\ntype SignalManager struct {\n\tdb      repoInterfaces.Repository\n\tmetrics signalMetrics\n}\n\nfunc getSignalContext(ctx context.Context, identifier *core.SignalIdentifier) context.Context {\n\tctx = contextutils.WithProjectDomain(ctx, identifier.ExecutionId.Project, identifier.ExecutionId.Domain)\n\tctx = contextutils.WithWorkflowID(ctx, identifier.ExecutionId.Name)\n\treturn contextutils.WithSignalID(ctx, identifier.SignalId)\n}\n\nfunc (s *SignalManager) GetOrCreateSignal(ctx context.Context, request admin.SignalGetOrCreateRequest) (*admin.Signal, error) {\n\tif err := validation.ValidateSignalGetOrCreateRequest(ctx, request); err != nil {\n\t\tlogger.Debugf(ctx, \"invalid request [%+v]: %v\", request, err)\n\t\treturn nil, err\n\t}\n\tctx = getSignalContext(ctx, request.Id)\n\n\tsignalModel, err := transformers.CreateSignalModel(request.Id, request.Type, nil)\n\tif err != nil {\n\t\tlogger.Errorf(ctx, \"Failed to transform signal with id [%+v] and type [+%v] with err: %v\", request.Id, request.Type, err)\n\t\treturn nil, err\n\t}\n\n\terr = s.db.SignalRepo().GetOrCreate(ctx, &signalModel)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tsignal, err := transformers.FromSignalModel(signalModel)\n\tif err != nil {\n\t\tlogger.Errorf(ctx, \"Failed to transform signal model [%+v] with err: %v\", signalModel, err)\n\t\treturn nil, err\n\t}\n\n\treturn &signal, nil\n}\n\nfunc (s *SignalManager) ListSignals(ctx context.Context, request admin.SignalListRequest) (*admin.SignalList, error) {\n\tif err := validation.ValidateSignalListRequest(ctx, request); err != nil {\n\t\tlogger.Debugf(ctx, \"ListSignals request [%+v] is invalid: %v\", request, err)\n\t\treturn nil, err\n\t}\n\tctx = getExecutionContext(ctx, request.WorkflowExecutionId)\n\n\tidentifierFilters, err := util.GetWorkflowExecutionIdentifierFilters(ctx, *request.WorkflowExecutionId)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tfilters, err := util.AddRequestFilters(request.Filters, common.Signal, identifierFilters)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tvar sortParameter common.SortParameter\n\tif request.SortBy != nil {\n\t\tsortParameter, err = common.NewSortParameter(*request.SortBy)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\toffset, err := validation.ValidateToken(request.Token)\n\tif err != nil {\n\t\treturn nil, errors.NewFlyteAdminErrorf(codes.InvalidArgument,\n\t\t\t\"invalid pagination token %s for ListSignals\", request.Token)\n\t}\n\n\tsignalModelList, err := s.db.SignalRepo().List(ctx, repoInterfaces.ListResourceInput{\n\t\tInlineFilters: filters,\n\t\tOffset:        offset,\n\t\tLimit:         int(request.Limit),\n\t\tSortParameter: sortParameter,\n\t})\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"Failed to list signals with request [%+v] with err %v\",\n\t\t\trequest, err)\n\t\treturn nil, err\n\t}\n\n\tsignalList, err := transformers.FromSignalModels(signalModelList)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"failed to transform signal models for request [%+v] with err: %v\", request, err)\n\t\treturn nil, err\n\t}\n\tvar token string\n\tif len(signalList) == int(request.Limit) {\n\t\ttoken = strconv.Itoa(offset + len(signalList))\n\t}\n\treturn &admin.SignalList{\n\t\tSignals: signalList,\n\t\tToken:   token,\n\t}, nil\n}\n\nfunc (s *SignalManager) SetSignal(ctx context.Context, request admin.SignalSetRequest) (*admin.SignalSetResponse, error) {\n\tif err := validation.ValidateSignalSetRequest(ctx, s.db, request); err != nil {\n\t\treturn nil, err\n\t}\n\tctx = getSignalContext(ctx, request.Id)\n\n\tsignalModel, err := transformers.CreateSignalModel(request.Id, nil, request.Value)\n\tif err != nil {\n\t\tlogger.Errorf(ctx, \"Failed to transform signal with id [%+v] and value [+%v] with err: %v\", request.Id, request.Value, err)\n\t\treturn nil, err\n\t}\n\n\terr = s.db.SignalRepo().Update(ctx, signalModel.SignalKey, signalModel.Value)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\ts.metrics.Set.Inc(ctx)\n\treturn &admin.SignalSetResponse{}, nil\n}\n\nfunc NewSignalManager(\n\tdb repoInterfaces.Repository,\n\tscope promutils.Scope) interfaces.SignalInterface {\n\tmetrics := signalMetrics{\n\t\tScope: scope,\n\t\tSet:   labeled.NewCounter(\"num_set\", \"count of set signals\", scope),\n\t}\n\n\treturn &SignalManager{\n\t\tdb:      db,\n\t\tmetrics: metrics,\n\t}\n}\n", "package impl\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"strconv\"\n\n\tcloudeventInterfaces \"github.com/flyteorg/flyteadmin/pkg/async/cloudevent/interfaces\"\n\n\t\"github.com/flyteorg/flytestdlib/promutils/labeled\"\n\n\tnotificationInterfaces \"github.com/flyteorg/flyteadmin/pkg/async/notifications/interfaces\"\n\t\"github.com/golang/protobuf/proto\"\n\n\t\"github.com/flyteorg/flytestdlib/storage\"\n\n\t\"github.com/flyteorg/flytestdlib/contextutils\"\n\n\t\"github.com/flyteorg/flytestdlib/promutils\"\n\t\"github.com/prometheus/client_golang/prometheus\"\n\n\t\"github.com/flyteorg/flyteadmin/pkg/common\"\n\tdataInterfaces \"github.com/flyteorg/flyteadmin/pkg/data/interfaces\"\n\t\"github.com/flyteorg/flyteadmin/pkg/errors\"\n\t\"github.com/flyteorg/flyteadmin/pkg/manager/impl/util\"\n\t\"github.com/flyteorg/flyteadmin/pkg/manager/impl/validation\"\n\t\"github.com/flyteorg/flyteadmin/pkg/manager/interfaces\"\n\trepoInterfaces \"github.com/flyteorg/flyteadmin/pkg/repositories/interfaces\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/models\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/transformers\"\n\truntimeInterfaces \"github.com/flyteorg/flyteadmin/pkg/runtime/interfaces\"\n\t\"github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/admin\"\n\t\"github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/core\"\n\t\"github.com/flyteorg/flytestdlib/logger\"\n\t\"google.golang.org/grpc/codes\"\n)\n\ntype taskExecutionMetrics struct {\n\tScope                      promutils.Scope\n\tActiveTaskExecutions       prometheus.Gauge\n\tTaskExecutionsCreated      prometheus.Counter\n\tTaskExecutionsTerminated   labeled.Counter\n\tTaskExecutionEventsCreated prometheus.Counter\n\tMissingTaskExecution       prometheus.Counter\n\tMissingTaskDefinition      prometheus.Counter\n\tClosureSizeBytes           prometheus.Summary\n\tTaskExecutionInputBytes    prometheus.Summary\n\tTaskExecutionOutputBytes   prometheus.Summary\n\tPublishEventError          prometheus.Counter\n}\n\ntype TaskExecutionManager struct {\n\tdb                   repoInterfaces.Repository\n\tconfig               runtimeInterfaces.Configuration\n\tstorageClient        *storage.DataStore\n\tmetrics              taskExecutionMetrics\n\turlData              dataInterfaces.RemoteURLInterface\n\tnotificationClient   notificationInterfaces.Publisher\n\tcloudEventsPublisher cloudeventInterfaces.Publisher\n}\n\nfunc getTaskExecutionContext(ctx context.Context, identifier *core.TaskExecutionIdentifier) context.Context {\n\tctx = getNodeExecutionContext(ctx, identifier.NodeExecutionId)\n\treturn contextutils.WithTaskID(ctx, fmt.Sprintf(\"%s-%v\", identifier.TaskId.Name, identifier.RetryAttempt))\n}\n\nfunc (m *TaskExecutionManager) createTaskExecution(\n\tctx context.Context, request *admin.TaskExecutionEventRequest) (\n\tmodels.TaskExecution, error) {\n\n\tnodeExecutionID := request.Event.ParentNodeExecutionId\n\tnodeExecutionExists, err := m.db.NodeExecutionRepo().Exists(ctx, repoInterfaces.NodeExecutionResource{\n\t\tNodeExecutionIdentifier: *nodeExecutionID,\n\t})\n\tif err != nil || !nodeExecutionExists {\n\t\tm.metrics.MissingTaskExecution.Inc()\n\t\tlogger.Debugf(ctx, \"Failed to get existing node execution [%+v] with err %v\", nodeExecutionID, err)\n\t\tif err != nil {\n\t\t\tif ferr, ok := err.(errors.FlyteAdminError); ok {\n\t\t\t\treturn models.TaskExecution{}, errors.NewFlyteAdminErrorf(ferr.Code(),\n\t\t\t\t\t\"Failed to get existing node execution id: [%+v] with err: %v\", nodeExecutionID, err)\n\t\t\t}\n\t\t}\n\t\treturn models.TaskExecution{}, fmt.Errorf(\"failed to get existing node execution id: [%+v]\", nodeExecutionID)\n\t}\n\n\ttaskExecutionModel, err := transformers.CreateTaskExecutionModel(\n\t\tctx,\n\t\ttransformers.CreateTaskExecutionModelInput{\n\t\t\tRequest:               request,\n\t\t\tInlineEventDataPolicy: m.config.ApplicationConfiguration().GetRemoteDataConfig().InlineEventDataPolicy,\n\t\t\tStorageClient:         m.storageClient,\n\t\t})\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"failed to transform task execution %+v into database model: %v\", request.Event.TaskId, err)\n\t\treturn models.TaskExecution{}, err\n\t}\n\n\tif err := m.db.TaskExecutionRepo().Create(ctx, *taskExecutionModel); err != nil {\n\t\tlogger.Debugf(ctx, \"Failed to create task execution with task id [%+v] with err %v\",\n\t\t\trequest.Event.TaskId, err)\n\t\treturn models.TaskExecution{}, err\n\t}\n\n\tm.metrics.TaskExecutionsCreated.Inc()\n\tm.metrics.ClosureSizeBytes.Observe(float64(len(taskExecutionModel.Closure)))\n\tlogger.Debugf(ctx, \"created task execution: %+v\", request.Event.TaskId)\n\treturn *taskExecutionModel, nil\n}\n\nfunc (m *TaskExecutionManager) updateTaskExecutionModelState(\n\tctx context.Context, request *admin.TaskExecutionEventRequest, existingTaskExecution *models.TaskExecution) (\n\tmodels.TaskExecution, error) {\n\n\terr := transformers.UpdateTaskExecutionModel(ctx, request, existingTaskExecution,\n\t\tm.config.ApplicationConfiguration().GetRemoteDataConfig().InlineEventDataPolicy, m.storageClient)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"failed to update task execution model [%+v] with err: %v\", request.Event.TaskId, err)\n\t\treturn models.TaskExecution{}, err\n\t}\n\n\terr = m.db.TaskExecutionRepo().Update(ctx, *existingTaskExecution)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"Failed to update task execution with task id [%+v] and task execution model [%+v] with err %v\",\n\t\t\trequest.Event.TaskId, existingTaskExecution, err)\n\t\treturn models.TaskExecution{}, err\n\t}\n\n\treturn *existingTaskExecution, nil\n}\n\nfunc (m *TaskExecutionManager) CreateTaskExecutionEvent(ctx context.Context, request admin.TaskExecutionEventRequest) (\n\t*admin.TaskExecutionEventResponse, error) {\n\tif err := validation.ValidateTaskExecutionRequest(request, m.config.ApplicationConfiguration().GetRemoteDataConfig().MaxSizeInBytes); err != nil {\n\t\treturn nil, err\n\t}\n\n\tif err := validation.ValidateClusterForExecutionID(ctx, m.db, request.Event.ParentNodeExecutionId.ExecutionId, request.Event.ProducerId); err != nil {\n\t\treturn nil, err\n\t}\n\n\t// Get the parent node execution, if none found a MissingEntityError will be returned\n\tnodeExecutionID := request.Event.ParentNodeExecutionId\n\ttaskExecutionID := core.TaskExecutionIdentifier{\n\t\tTaskId:          request.Event.TaskId,\n\t\tNodeExecutionId: nodeExecutionID,\n\t\tRetryAttempt:    request.Event.RetryAttempt,\n\t}\n\tctx = getTaskExecutionContext(ctx, &taskExecutionID)\n\tlogger.Debugf(ctx, \"Received task execution event for [%+v] transitioning to phase [%v]\",\n\t\ttaskExecutionID, request.Event.Phase)\n\n\t// See if the task execution exists\n\t// - if it does check if the new phase is applicable and then update\n\t// - if it doesn't, create a task execution\n\ttaskExecutionModel, err := m.db.TaskExecutionRepo().Get(ctx, repoInterfaces.GetTaskExecutionInput{\n\t\tTaskExecutionID: taskExecutionID,\n\t})\n\n\tif err != nil {\n\t\tif err.(errors.FlyteAdminError).Code() != codes.NotFound {\n\t\t\tlogger.Debugf(ctx, \"Failed to find existing task execution [%+v] with err %v\", taskExecutionID, err)\n\t\t\treturn nil, err\n\t\t}\n\t\t_, err := m.createTaskExecution(ctx, &request)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\treturn &admin.TaskExecutionEventResponse{}, nil\n\t}\n\tif taskExecutionModel.Phase == request.Event.Phase.String() &&\n\t\ttaskExecutionModel.PhaseVersion >= request.Event.PhaseVersion {\n\t\tlogger.Debugf(ctx, \"have already recorded task execution phase %s (version: %d) for %v\",\n\t\t\trequest.Event.Phase.String(), request.Event.PhaseVersion, taskExecutionID)\n\t\treturn nil, errors.NewFlyteAdminErrorf(codes.AlreadyExists,\n\t\t\t\"have already recorded task execution phase %s (version: %d) for %v\",\n\t\t\trequest.Event.Phase.String(), request.Event.PhaseVersion, taskExecutionID)\n\t}\n\n\tcurrentPhase := core.TaskExecution_Phase(core.TaskExecution_Phase_value[taskExecutionModel.Phase])\n\tif common.IsTaskExecutionTerminal(currentPhase) {\n\t\t// Cannot update a terminal execution.\n\t\tcurPhase := request.Event.Phase.String()\n\t\terrorMsg := fmt.Sprintf(\"invalid phase change from %v to %v for task execution %v\", taskExecutionModel.Phase, request.Event.Phase, taskExecutionID)\n\t\tlogger.Warnf(ctx, errorMsg)\n\t\treturn nil, errors.NewAlreadyInTerminalStateError(ctx, errorMsg, curPhase)\n\t}\n\n\ttaskExecutionModel, err = m.updateTaskExecutionModelState(ctx, &request, &taskExecutionModel)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"Failed to update task execution with id [%+v] with err %v\",\n\t\t\ttaskExecutionID, err)\n\t\treturn nil, err\n\t}\n\n\tif request.Event.Phase == core.TaskExecution_RUNNING && request.Event.PhaseVersion == 0 {\n\t\tm.metrics.ActiveTaskExecutions.Inc()\n\t} else if common.IsTaskExecutionTerminal(request.Event.Phase) && request.Event.PhaseVersion == 0 {\n\t\tm.metrics.ActiveTaskExecutions.Dec()\n\t\tm.metrics.TaskExecutionsTerminated.Inc(contextutils.WithPhase(ctx, request.Event.Phase.String()))\n\t\tif request.Event.GetOutputData() != nil {\n\t\t\tm.metrics.TaskExecutionOutputBytes.Observe(float64(proto.Size(request.Event.GetOutputData())))\n\t\t}\n\t}\n\n\tif err = m.notificationClient.Publish(ctx, proto.MessageName(&request), &request); err != nil {\n\t\tm.metrics.PublishEventError.Inc()\n\t\tlogger.Infof(ctx, \"error publishing event [%+v] with err: [%v]\", request.RequestId, err)\n\t}\n\n\tgo func() {\n\t\tif err := m.cloudEventsPublisher.Publish(ctx, proto.MessageName(&request), &request); err != nil {\n\t\t\tlogger.Infof(ctx, \"error publishing cloud event [%+v] with err: [%v]\", request.RequestId, err)\n\t\t}\n\t}()\n\n\tm.metrics.TaskExecutionEventsCreated.Inc()\n\tlogger.Debugf(ctx, \"Successfully recorded task execution event [%v]\", request.Event)\n\t// TODO: we will want to return some scope information here soon!\n\treturn &admin.TaskExecutionEventResponse{}, nil\n}\n\nfunc (m *TaskExecutionManager) GetTaskExecution(\n\tctx context.Context, request admin.TaskExecutionGetRequest) (*admin.TaskExecution, error) {\n\terr := validation.ValidateTaskExecutionIdentifier(request.Id)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"Failed to validate GetTaskExecution [%+v] with err: %v\", request.Id, err)\n\t\treturn nil, err\n\t}\n\tctx = getTaskExecutionContext(ctx, request.Id)\n\ttaskExecutionModel, err := util.GetTaskExecutionModel(ctx, m.db, request.Id)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\ttaskExecution, err := transformers.FromTaskExecutionModel(*taskExecutionModel, transformers.DefaultExecutionTransformerOptions)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"Failed to transform task execution model [%+v] to proto: %v\", request.Id, err)\n\t\treturn nil, err\n\t}\n\treturn taskExecution, nil\n}\n\nfunc (m *TaskExecutionManager) ListTaskExecutions(\n\tctx context.Context, request admin.TaskExecutionListRequest) (*admin.TaskExecutionList, error) {\n\tif err := validation.ValidateTaskExecutionListRequest(request); err != nil {\n\t\tlogger.Debugf(ctx, \"ListTaskExecutions request [%+v] is invalid: %v\", request, err)\n\t\treturn nil, err\n\t}\n\tctx = getNodeExecutionContext(ctx, request.NodeExecutionId)\n\n\tidentifierFilters, err := util.GetNodeExecutionIdentifierFilters(ctx, *request.NodeExecutionId)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tfilters, err := util.AddRequestFilters(request.Filters, common.TaskExecution, identifierFilters)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tvar sortParameter common.SortParameter\n\tif request.SortBy != nil {\n\t\tsortParameter, err = common.NewSortParameter(*request.SortBy)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\toffset, err := validation.ValidateToken(request.Token)\n\tif err != nil {\n\t\treturn nil, errors.NewFlyteAdminErrorf(codes.InvalidArgument,\n\t\t\t\"invalid pagination token %s for ListTaskExecutions\", request.Token)\n\t}\n\n\toutput, err := m.db.TaskExecutionRepo().List(ctx, repoInterfaces.ListResourceInput{\n\t\tInlineFilters: filters,\n\t\tOffset:        offset,\n\t\tLimit:         int(request.Limit),\n\t\tSortParameter: sortParameter,\n\t})\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"Failed to list task executions with request [%+v] with err %v\",\n\t\t\trequest, err)\n\t\treturn nil, err\n\t}\n\n\t// Use default transformer options so that error messages shown for task execution attempts in the console sidebar show the full error stack trace.\n\ttaskExecutionList, err := transformers.FromTaskExecutionModels(output.TaskExecutions, transformers.DefaultExecutionTransformerOptions)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"failed to transform task execution models for request [%+v] with err: %v\", request, err)\n\t\treturn nil, err\n\t}\n\tvar token string\n\tif len(taskExecutionList) == int(request.Limit) {\n\t\ttoken = strconv.Itoa(offset + len(taskExecutionList))\n\t}\n\treturn &admin.TaskExecutionList{\n\t\tTaskExecutions: taskExecutionList,\n\t\tToken:          token,\n\t}, nil\n}\n\nfunc (m *TaskExecutionManager) GetTaskExecutionData(\n\tctx context.Context, request admin.TaskExecutionGetDataRequest) (*admin.TaskExecutionGetDataResponse, error) {\n\tif err := validation.ValidateTaskExecutionIdentifier(request.Id); err != nil {\n\t\tlogger.Debugf(ctx, \"Invalid identifier [%+v]: %v\", request.Id, err)\n\t}\n\tctx = getTaskExecutionContext(ctx, request.Id)\n\ttaskExecution, err := m.GetTaskExecution(ctx, admin.TaskExecutionGetRequest{\n\t\tId: request.Id,\n\t})\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"Failed to get task execution with id [%+v] with err %v\",\n\t\t\trequest.Id, err)\n\t\treturn nil, err\n\t}\n\n\tinputs, inputURLBlob, err := util.GetInputs(ctx, m.urlData, m.config.ApplicationConfiguration().GetRemoteDataConfig(),\n\t\tm.storageClient, taskExecution.InputUri)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\toutputs, outputURLBlob, err := util.GetOutputs(ctx, m.urlData, m.config.ApplicationConfiguration().GetRemoteDataConfig(),\n\t\tm.storageClient, taskExecution.Closure)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tresponse := &admin.TaskExecutionGetDataResponse{\n\t\tInputs:      inputURLBlob,\n\t\tOutputs:     outputURLBlob,\n\t\tFullInputs:  inputs,\n\t\tFullOutputs: outputs,\n\t\tFlyteUrls:   common.FlyteURLsFromTaskExecutionID(*request.Id, false),\n\t}\n\n\tm.metrics.TaskExecutionInputBytes.Observe(float64(response.Inputs.Bytes))\n\tif response.Outputs.Bytes > 0 {\n\t\tm.metrics.TaskExecutionOutputBytes.Observe(float64(response.Outputs.Bytes))\n\t} else if response.FullOutputs != nil {\n\t\tm.metrics.TaskExecutionOutputBytes.Observe(float64(proto.Size(response.FullOutputs)))\n\t}\n\treturn response, nil\n}\n\nfunc NewTaskExecutionManager(db repoInterfaces.Repository, config runtimeInterfaces.Configuration,\n\tstorageClient *storage.DataStore, scope promutils.Scope, urlData dataInterfaces.RemoteURLInterface,\n\tpublisher notificationInterfaces.Publisher, cloudEventsPublisher cloudeventInterfaces.Publisher) interfaces.TaskExecutionInterface {\n\n\tmetrics := taskExecutionMetrics{\n\t\tScope: scope,\n\t\tActiveTaskExecutions: scope.MustNewGauge(\"active_executions\",\n\t\t\t\"overall count of active task executions\"),\n\t\tMissingTaskExecution: scope.MustNewCounter(\"missing_node_execution\",\n\t\t\t\"overall count of task execution events received that are missing a parent node execution\"),\n\t\tTaskExecutionsCreated: scope.MustNewCounter(\"task_executions_created\",\n\t\t\t\"overall count of successfully completed CreateExecutionRequests\"),\n\t\tTaskExecutionsTerminated: labeled.NewCounter(\"task_executions_terminated\",\n\t\t\t\"overall count of terminated workflow executions\", scope),\n\t\tTaskExecutionEventsCreated: scope.MustNewCounter(\"task_execution_events_created\",\n\t\t\t\"overall count of successfully completed WorkflowExecutionEventRequest\"),\n\t\tMissingTaskDefinition: scope.MustNewCounter(\"missing_task_definition\",\n\t\t\t\"overall count of task execution events received that are missing a task definition\"),\n\t\tClosureSizeBytes: scope.MustNewSummary(\"closure_size_bytes\",\n\t\t\t\"size in bytes of serialized task execution closure\"),\n\t\tTaskExecutionInputBytes: scope.MustNewSummary(\"input_size_bytes\",\n\t\t\t\"size in bytes of serialized node execution inputs\"),\n\t\tTaskExecutionOutputBytes: scope.MustNewSummary(\"output_size_bytes\",\n\t\t\t\"size in bytes of serialized node execution outputs\"),\n\t\tPublishEventError: scope.MustNewCounter(\"publish_event_error\",\n\t\t\t\"overall count of publish event errors when invoking publish()\"),\n\t}\n\treturn &TaskExecutionManager{\n\t\tdb:                   db,\n\t\tconfig:               config,\n\t\tstorageClient:        storageClient,\n\t\tmetrics:              metrics,\n\t\turlData:              urlData,\n\t\tnotificationClient:   publisher,\n\t\tcloudEventsPublisher: cloudEventsPublisher,\n\t}\n}\n", "package impl\n\nimport (\n\t\"bytes\"\n\t\"context\"\n\t\"strconv\"\n\t\"time\"\n\n\t\"github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/core\"\n\t\"github.com/flyteorg/flytestdlib/contextutils\"\n\n\t\"github.com/prometheus/client_golang/prometheus\"\n\n\t\"github.com/flyteorg/flytestdlib/promutils\"\n\t\"github.com/flyteorg/flytestdlib/promutils/labeled\"\n\n\t\"github.com/golang/protobuf/ptypes\"\n\n\t\"github.com/flyteorg/flytestdlib/logger\"\n\n\t\"github.com/flyteorg/flyteadmin/pkg/common\"\n\t\"github.com/flyteorg/flyteadmin/pkg/errors\"\n\t\"github.com/flyteorg/flyteadmin/pkg/manager/impl/resources\"\n\t\"github.com/flyteorg/flyteadmin/pkg/manager/impl/util\"\n\t\"github.com/flyteorg/flyteadmin/pkg/manager/impl/validation\"\n\t\"github.com/flyteorg/flyteadmin/pkg/manager/interfaces\"\n\trepoInterfaces \"github.com/flyteorg/flyteadmin/pkg/repositories/interfaces\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/transformers\"\n\truntimeInterfaces \"github.com/flyteorg/flyteadmin/pkg/runtime/interfaces\"\n\tworkflowengine \"github.com/flyteorg/flyteadmin/pkg/workflowengine/interfaces\"\n\t\"github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/admin\"\n\t\"google.golang.org/grpc/codes\"\n)\n\ntype taskMetrics struct {\n\tScope            promutils.Scope\n\tClosureSizeBytes prometheus.Summary\n\tRegistered       labeled.Counter\n}\n\ntype TaskManager struct {\n\tdb              repoInterfaces.Repository\n\tconfig          runtimeInterfaces.Configuration\n\tcompiler        workflowengine.Compiler\n\tmetrics         taskMetrics\n\tresourceManager interfaces.ResourceInterface\n}\n\nfunc getTaskContext(ctx context.Context, identifier *core.Identifier) context.Context {\n\tctx = contextutils.WithProjectDomain(ctx, identifier.Project, identifier.Domain)\n\treturn contextutils.WithTaskID(ctx, identifier.Name)\n}\n\nfunc setDefaults(request admin.TaskCreateRequest) (admin.TaskCreateRequest, error) {\n\tif request.Id == nil {\n\t\treturn request, errors.NewFlyteAdminError(codes.InvalidArgument,\n\t\t\t\"missing identifier for TaskCreateRequest\")\n\t}\n\n\trequest.Spec.Template.Id = request.Id\n\treturn request, nil\n}\n\nfunc (t *TaskManager) CreateTask(\n\tctx context.Context,\n\trequest admin.TaskCreateRequest) (*admin.TaskCreateResponse, error) {\n\tplatformTaskResources := util.GetTaskResources(ctx, request.Id, t.resourceManager, t.config.TaskResourceConfiguration())\n\tif err := validation.ValidateTask(ctx, request, t.db, platformTaskResources,\n\t\tt.config.WhitelistConfiguration(), t.config.ApplicationConfiguration()); err != nil {\n\t\tlogger.Debugf(ctx, \"Task [%+v] failed validation with err: %v\", request.Id, err)\n\t\treturn nil, err\n\t}\n\tctx = getTaskContext(ctx, request.Id)\n\tfinalizedRequest, err := setDefaults(request)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\t// Compile task and store the compiled version in the database.\n\tcompiledTask, err := t.compiler.CompileTask(finalizedRequest.Spec.Template)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"Failed to compile task with id [%+v] with err %v\", request.Id, err)\n\t\treturn nil, err\n\t}\n\tcreatedAt, err := ptypes.TimestampProto(time.Now())\n\tif err != nil {\n\t\treturn nil, errors.NewFlyteAdminErrorf(codes.Internal,\n\t\t\t\"Failed to serialize CreatedAt: %v when creating task: %+v\", err, request.Id)\n\t}\n\ttaskDigest, err := util.GetTaskDigest(ctx, compiledTask)\n\tif err != nil {\n\t\tlogger.Errorf(ctx, \"failed to compute task digest with err %v\", err)\n\t\treturn nil, err\n\t}\n\t// See if a task exists and confirm whether it's an identical task or one that with a separate definition.\n\texistingTask, err := util.GetTaskModel(ctx, t.db, request.Spec.Template.Id)\n\tif err == nil {\n\t\tif bytes.Equal(taskDigest, existingTask.Digest) {\n\t\t\treturn nil, errors.NewFlyteAdminErrorf(codes.AlreadyExists,\n\t\t\t\t\"identical task already exists with id %s\", request.Id)\n\t\t}\n\t\treturn nil, errors.NewFlyteAdminErrorf(codes.InvalidArgument,\n\t\t\t\"task with different structure already exists with id %v\", request.Id)\n\t}\n\ttaskModel, err := transformers.CreateTaskModel(finalizedRequest, admin.TaskClosure{\n\t\tCompiledTask: compiledTask,\n\t\tCreatedAt:    createdAt,\n\t}, taskDigest)\n\tif err != nil {\n\t\tlogger.Errorf(ctx,\n\t\t\t\"Failed to transform task model [%+v] with err: %v\", finalizedRequest, err)\n\t\treturn nil, err\n\t}\n\n\tdescriptionModel, err := transformers.CreateDescriptionEntityModel(request.Spec.Description, *request.Id)\n\tif err != nil {\n\t\tlogger.Errorf(ctx,\n\t\t\t\"Failed to transform description model [%+v] with err: %v\", request.Spec.Description, err)\n\t\treturn nil, err\n\t}\n\tif descriptionModel != nil {\n\t\ttaskModel.ShortDescription = descriptionModel.ShortDescription\n\t}\n\terr = t.db.TaskRepo().Create(ctx, taskModel, descriptionModel)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"Failed to create task model with id [%+v] with err %v\", request.Id, err)\n\t\treturn nil, err\n\t}\n\tt.metrics.ClosureSizeBytes.Observe(float64(len(taskModel.Closure)))\n\tif finalizedRequest.Spec.Template.Metadata != nil {\n\t\tcontextWithRuntimeMeta := context.WithValue(\n\t\t\tctx, common.RuntimeTypeKey, finalizedRequest.Spec.Template.Metadata.Runtime.Type.String())\n\t\tcontextWithRuntimeMeta = context.WithValue(\n\t\t\tcontextWithRuntimeMeta, common.RuntimeVersionKey, finalizedRequest.Spec.Template.Metadata.Runtime.Version)\n\t\tt.metrics.Registered.Inc(contextWithRuntimeMeta)\n\t}\n\n\treturn &admin.TaskCreateResponse{}, nil\n}\n\nfunc (t *TaskManager) GetTask(ctx context.Context, request admin.ObjectGetRequest) (*admin.Task, error) {\n\tif err := validation.ValidateIdentifier(request.Id, common.Task); err != nil {\n\t\tlogger.Debugf(ctx, \"invalid identifier [%+v]: %v\", request.Id, err)\n\t}\n\tctx = getTaskContext(ctx, request.Id)\n\ttask, err := util.GetTask(ctx, t.db, *request.Id)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"Failed to get task with id [%+v] with err %v\", err, request.Id)\n\t\treturn nil, err\n\t}\n\treturn task, nil\n}\n\nfunc (t *TaskManager) ListTasks(ctx context.Context, request admin.ResourceListRequest) (*admin.TaskList, error) {\n\t// Check required fields\n\tif err := validation.ValidateResourceListRequest(request); err != nil {\n\t\tlogger.Debugf(ctx, \"Invalid request [%+v]: %v\", request, err)\n\t\treturn nil, err\n\t}\n\tctx = contextutils.WithProjectDomain(ctx, request.Id.Project, request.Id.Domain)\n\tctx = contextutils.WithTaskID(ctx, request.Id.Name)\n\tspec := util.FilterSpec{\n\t\tProject:        request.Id.Project,\n\t\tDomain:         request.Id.Domain,\n\t\tName:           request.Id.Name,\n\t\tRequestFilters: request.Filters,\n\t}\n\n\tfilters, err := util.GetDbFilters(spec, common.Task)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tvar sortParameter common.SortParameter\n\tif request.SortBy != nil {\n\t\tsortParameter, err = common.NewSortParameter(*request.SortBy)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\toffset, err := validation.ValidateToken(request.Token)\n\tif err != nil {\n\t\treturn nil, errors.NewFlyteAdminErrorf(codes.InvalidArgument,\n\t\t\t\"invalid pagination token %s for ListTasks\", request.Token)\n\t}\n\t// And finally, query the database\n\tlistTasksInput := repoInterfaces.ListResourceInput{\n\t\tLimit:         int(request.Limit),\n\t\tOffset:        offset,\n\t\tInlineFilters: filters,\n\t\tSortParameter: sortParameter,\n\t}\n\toutput, err := t.db.TaskRepo().List(ctx, listTasksInput)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"Failed to list tasks with id [%+v] with err %v\", request.Id, err)\n\t\treturn nil, err\n\t}\n\ttaskList, err := transformers.FromTaskModels(output.Tasks)\n\tif err != nil {\n\t\tlogger.Errorf(ctx,\n\t\t\t\"Failed to transform task models [%+v] with err: %v\", output.Tasks, err)\n\t\treturn nil, err\n\t}\n\n\tvar token string\n\tif len(taskList) == int(request.Limit) {\n\t\ttoken = strconv.Itoa(offset + len(taskList))\n\t}\n\treturn &admin.TaskList{\n\t\tTasks: taskList,\n\t\tToken: token,\n\t}, nil\n}\n\n// This queries the unique tasks for the given query parameters.  At least the project and domain must be specified.\n// It will return all tasks, but only the one of each even if there are multiple versions.\nfunc (t *TaskManager) ListUniqueTaskIdentifiers(ctx context.Context, request admin.NamedEntityIdentifierListRequest) (\n\t*admin.NamedEntityIdentifierList, error) {\n\tif err := validation.ValidateNamedEntityIdentifierListRequest(request); err != nil {\n\t\tlogger.Debugf(ctx, \"invalid request [%+v]: %v\", request, err)\n\t\treturn nil, err\n\t}\n\tctx = contextutils.WithProjectDomain(ctx, request.Project, request.Domain)\n\tfilters, err := util.GetDbFilters(util.FilterSpec{\n\t\tProject: request.Project,\n\t\tDomain:  request.Domain,\n\t}, common.Task)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tvar sortParameter common.SortParameter\n\tif request.SortBy != nil {\n\t\tsortParameter, err = common.NewSortParameter(*request.SortBy)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\toffset, err := validation.ValidateToken(request.Token)\n\tif err != nil {\n\t\treturn nil, errors.NewFlyteAdminErrorf(codes.InvalidArgument,\n\t\t\t\"invalid pagination token %s for ListUniqueTaskIdentifiers\", request.Token)\n\t}\n\tlistTasksInput := repoInterfaces.ListResourceInput{\n\t\tLimit:         int(request.Limit),\n\t\tOffset:        offset,\n\t\tInlineFilters: filters,\n\t\tSortParameter: sortParameter,\n\t}\n\n\toutput, err := t.db.TaskRepo().ListTaskIdentifiers(ctx, listTasksInput)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"Failed to list tasks ids with project: %s and domain: %s with err %v\",\n\t\t\trequest.Project, request.Domain, err)\n\t\treturn nil, err\n\t}\n\n\tidList := transformers.FromTaskModelsToIdentifiers(output.Tasks)\n\tvar token string\n\tif len(idList) == int(request.Limit) {\n\t\ttoken = strconv.Itoa(offset + len(idList))\n\t}\n\treturn &admin.NamedEntityIdentifierList{\n\t\tEntities: idList,\n\t\tToken:    token,\n\t}, nil\n}\n\nfunc NewTaskManager(\n\tdb repoInterfaces.Repository,\n\tconfig runtimeInterfaces.Configuration, compiler workflowengine.Compiler,\n\tscope promutils.Scope) interfaces.TaskInterface {\n\tmetrics := taskMetrics{\n\t\tScope:            scope,\n\t\tClosureSizeBytes: scope.MustNewSummary(\"closure_size_bytes\", \"size in bytes of serialized task closure\"),\n\t\tRegistered:       labeled.NewCounter(\"num_registered\", \"count of registered tasks\", scope),\n\t}\n\tresourceManager := resources.NewResourceManager(db, config.ApplicationConfiguration())\n\treturn &TaskManager{\n\t\tdb:              db,\n\t\tconfig:          config,\n\t\tcompiler:        compiler,\n\t\tmetrics:         metrics,\n\t\tresourceManager: resourceManager,\n\t}\n}\n", "// Util around parsing request filters\npackage util\n\nimport (\n\t\"context\"\n\t\"regexp\"\n\t\"strconv\"\n\t\"strings\"\n\t\"time\"\n\n\t\"github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/core\"\n\t\"github.com/flyteorg/flytestdlib/logger\"\n\n\t\"github.com/flyteorg/flyteadmin/pkg/errors\"\n\t\"google.golang.org/grpc/codes\"\n\n\t\"fmt\"\n\n\t\"github.com/flyteorg/flyteadmin/pkg/common\"\n\t\"github.com/flyteorg/flyteadmin/pkg/manager/impl/shared\"\n)\n\nconst (\n\tfilterExpressionSeperator = \"+\"\n\tlistValueSeparator        = \";\"\n)\n\n// Matches filters of the form `func(field,value)` or `func(field, value)`\nvar filterRegex = regexp.MustCompile(`(.+)\\((.+),\\s?(.+)\\)`)\n\n// InlineFilter parsing consts. For example, matching on the filter string \"contains(Name, foo)\"\n// will return a slice consisting of: [\"contains(Name, foo)\", \"contains\", \"Name\", \"foo\"]\nconst (\n\tfuncMatchIndex           = 1\n\tfieldMatchIndex          = 2\n\tvalueMatchIndex          = 3\n\texpectedMatchGroupLength = 4\n)\n\nvar timestampFields = map[string]bool{\n\t\"CreatedAt\": true,\n\t\"UpdatedAt\": true,\n\t\"DeletedAt\": true,\n\t\"StartedAt\": true,\n}\n\nvar durationFields = map[string]bool{\n\t\"duration\": true,\n}\n\nconst filterFieldEntityPrefixFmt = \"%s.\"\nconst secondsFormat = \"%vs\"\n\nvar filterFieldEntityPrefix = map[string]common.Entity{\n\t\"task\":                  common.Task,\n\t\"workflow\":              common.Workflow,\n\t\"launch_plan\":           common.LaunchPlan,\n\t\"execution\":             common.Execution,\n\t\"node_execution\":        common.NodeExecution,\n\t\"task_execution\":        common.TaskExecution,\n\t\"entities\":              common.NamedEntity,\n\t\"named_entity_metadata\": common.NamedEntityMetadata,\n\t\"project\":               common.Project,\n\t\"signal\":                common.Signal,\n\t\"admin_tag\":             common.AdminTag,\n\t\"execution_admin_tag\":   common.ExecutionAdminTag,\n}\n\nfunc parseField(field string, primaryEntity common.Entity) (common.Entity, string) {\n\tfor prefix, entity := range filterFieldEntityPrefix {\n\t\totherEntityPrefix := fmt.Sprintf(filterFieldEntityPrefixFmt, prefix)\n\t\tif strings.HasPrefix(field, otherEntityPrefix) {\n\t\t\t// Strip the referenced entity prefix from the field name.\n\t\t\t// e.g. workflow_name becomes simply \"name\"\n\t\t\treturn entity, field[len(otherEntityPrefix):]\n\t\t}\n\t}\n\n\treturn primaryEntity, field\n}\n\nfunc parseRepeatedValues(parsedValues string) []string {\n\treturn strings.Split(parsedValues, listValueSeparator)\n}\n\n// Handles parsing repeated values and non-string values such as time fields.\nfunc prepareValues(field string, values []string) (interface{}, error) {\n\tpreparedValues := make([]interface{}, len(values))\n\tif isTimestampField := timestampFields[field]; isTimestampField {\n\t\tfor idx, value := range values {\n\t\t\ttimestamp, err := time.Parse(time.RFC3339Nano, value)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, errors.NewFlyteAdminErrorf(codes.InvalidArgument,\n\t\t\t\t\t\"Timestamp %s must conform to RFC3339 Nano spec\", value)\n\t\t\t}\n\t\t\tpreparedValues[idx] = timestamp\n\t\t}\n\t} else if isDurationField := durationFields[strings.ToLower(field)]; isDurationField {\n\t\tfor idx, value := range values {\n\t\t\tfloatValue, err := strconv.ParseFloat(value, 64)\n\t\t\tif err == nil {\n\t\t\t\t// The value is an float. By default purely float values are assumed to represent durations in seconds.\n\t\t\t\tvalue = fmt.Sprintf(secondsFormat, floatValue)\n\t\t\t}\n\t\t\tduration, err := time.ParseDuration(value)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, errors.NewFlyteAdminErrorf(codes.InvalidArgument,\n\t\t\t\t\t\"Failed to parse duration [%s]\", value)\n\t\t\t}\n\t\t\tpreparedValues[idx] = duration\n\t\t}\n\t} else {\n\t\tfor idx, value := range values {\n\t\t\tpreparedValues[idx] = value\n\t\t}\n\t}\n\tif len(preparedValues) == 1 {\n\t\treturn preparedValues[0], nil\n\t}\n\treturn preparedValues, nil\n}\n\nfunc ParseFilters(filterParams string, primaryEntity common.Entity) ([]common.InlineFilter, error) {\n\t// Multiple filters can be appended as URI-escaped strings joined by filterExpressionSeperator\n\tfilterExpressions := strings.Split(filterParams, filterExpressionSeperator)\n\tparsedFilters := make([]common.InlineFilter, 0)\n\tfor _, filterExpression := range filterExpressions {\n\t\t// Parse string expression\n\t\tmatches := filterRegex.FindStringSubmatch(filterExpression)\n\t\tif len(matches) != expectedMatchGroupLength {\n\t\t\t// Poorly formatted filter string doesn't match expected regex.\n\t\t\treturn nil, shared.GetInvalidArgumentError(shared.Filters)\n\t\t}\n\t\treferencedEntity, field := parseField(matches[fieldMatchIndex], primaryEntity)\n\n\t\t// Parse and transform values\n\t\tparsedValues := parseRepeatedValues(matches[valueMatchIndex])\n\t\tpreparedValues, err := prepareValues(field, parsedValues)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\t// Create InlineFilter object.\n\t\tfilter, err := common.NewInlineFilter(referencedEntity, matches[funcMatchIndex], field, preparedValues)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tparsedFilters = append(parsedFilters, filter)\n\t}\n\treturn parsedFilters, nil\n}\n\nfunc GetSingleValueEqualityFilter(entity common.Entity, field, value string) (common.InlineFilter, error) {\n\treturn common.NewSingleValueFilter(entity, common.Equal, field, value)\n}\n\ntype FilterSpec struct {\n\t// All of these fields are optional (although they should not *all* be empty).\n\tProject        string\n\tDomain         string\n\tName           string\n\tRequestFilters string\n}\n\n// Returns equality filters initialized for identifier attributes (project, domain & name)\n// which can be optionally specified in requests.\nfunc getIdentifierFilters(entity common.Entity, spec FilterSpec) ([]common.InlineFilter, error) {\n\tfilters := make([]common.InlineFilter, 0)\n\tif spec.Project != \"\" {\n\t\tprojectFilter, err := GetSingleValueEqualityFilter(entity, shared.Project, spec.Project)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tfilters = append(filters, projectFilter)\n\t}\n\tif spec.Domain != \"\" {\n\t\tdomainFilter, err := GetSingleValueEqualityFilter(entity, shared.Domain, spec.Domain)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tfilters = append(filters, domainFilter)\n\t}\n\n\tif spec.Name != \"\" {\n\t\tnameFilter, err := GetSingleValueEqualityFilter(entity, shared.Name, spec.Name)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tfilters = append(filters, nameFilter)\n\t}\n\treturn filters, nil\n}\n\nfunc AddRequestFilters(requestFilters string, primaryEntity common.Entity, existingFilters []common.InlineFilter) (\n\t[]common.InlineFilter, error) {\n\n\tif requestFilters == \"\" {\n\t\treturn existingFilters, nil\n\t}\n\tvar additionalFilters []common.InlineFilter\n\tadditionalFilters, err := ParseFilters(requestFilters, primaryEntity)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tupdatedFilters := append(existingFilters, additionalFilters...)\n\treturn updatedFilters, nil\n}\n\n// Consolidates request params and filters to a single list of filters. This consolidation is necessary since the db is\n// agnostic to required request parameters and additional filter arguments.\nfunc GetDbFilters(spec FilterSpec, primaryEntity common.Entity) ([]common.InlineFilter, error) {\n\tfilters, err := getIdentifierFilters(primaryEntity, spec)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// Append any request filters.\n\tif spec.RequestFilters != \"\" {\n\t\tfilters, err = AddRequestFilters(spec.RequestFilters, primaryEntity, filters)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\treturn filters, nil\n}\n\nfunc GetWorkflowExecutionIdentifierFilters(\n\tctx context.Context, workflowExecutionIdentifier core.WorkflowExecutionIdentifier) ([]common.InlineFilter, error) {\n\tidentifierFilters := make([]common.InlineFilter, 3)\n\tidentifierProjectFilter, err := GetSingleValueEqualityFilter(\n\t\tcommon.Execution, shared.Project, workflowExecutionIdentifier.Project)\n\tif err != nil {\n\t\tlogger.Warningf(ctx, \"Failed to create execution identifier filter for project: %s with identifier [%+v]\",\n\t\t\tworkflowExecutionIdentifier.Project, workflowExecutionIdentifier)\n\t\treturn nil, err\n\t}\n\tidentifierFilters[0] = identifierProjectFilter\n\n\tidentifierDomainFilter, err := GetSingleValueEqualityFilter(\n\t\tcommon.Execution, shared.Domain, workflowExecutionIdentifier.Domain)\n\tif err != nil {\n\t\tlogger.Warningf(ctx, \"Failed to create execution identifier filter for domain: %s with identifier [%+v]\",\n\t\t\tworkflowExecutionIdentifier.Domain, workflowExecutionIdentifier)\n\t\treturn nil, err\n\t}\n\tidentifierFilters[1] = identifierDomainFilter\n\n\tidentifierNameFilter, err := GetSingleValueEqualityFilter(\n\t\tcommon.Execution, shared.Name, workflowExecutionIdentifier.Name)\n\tif err != nil {\n\t\tlogger.Warningf(ctx, \"Failed to create execution identifier filter for domain: %s with identifier [%+v]\",\n\t\t\tworkflowExecutionIdentifier.Name, workflowExecutionIdentifier)\n\t\treturn nil, err\n\t}\n\tidentifierFilters[2] = identifierNameFilter\n\treturn identifierFilters, nil\n}\n\n// All inputs to this function must be validated.\nfunc GetNodeExecutionIdentifierFilters(\n\tctx context.Context, nodeExecutionIdentifier core.NodeExecutionIdentifier) ([]common.InlineFilter, error) {\n\tworkflowExecutionIdentifierFilters, err :=\n\t\tGetWorkflowExecutionIdentifierFilters(ctx, *nodeExecutionIdentifier.ExecutionId)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tnodeIDFilter, err := GetSingleValueEqualityFilter(\n\t\tcommon.NodeExecution, shared.NodeID, nodeExecutionIdentifier.NodeId)\n\tif err != nil {\n\t\tlogger.Warningf(ctx, \"Failed to create node execution identifier filter for node id: %s with identifier [%+v]\",\n\t\t\tnodeExecutionIdentifier.NodeId, nodeExecutionIdentifier)\n\t}\n\treturn append(workflowExecutionIdentifierFilters, nodeIDFilter), nil\n}\n", "package util\n\nimport (\n\t\"context\"\n\t\"testing\"\n\t\"time\"\n\n\t\"github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/core\"\n\n\t\"github.com/flyteorg/flyteadmin/pkg/common\"\n\t\"github.com/flyteorg/flyteadmin/pkg/manager/impl/shared\"\n\t\"github.com/flyteorg/flyteadmin/pkg/manager/impl/testutils\"\n\t\"github.com/stretchr/testify/assert\"\n)\n\nfunc TestParseRepeatedValues(t *testing.T) {\n\tassert.EqualValues(t, []string{\"foo\", \"bar\"}, parseRepeatedValues(\"foo;bar\"))\n}\n\nfunc TestPrepareValues_WithTimestamp(t *testing.T) {\n\ttimestampValue := \"2018-07-27T00:30:31Z\"\n\tvalues, err := prepareValues(\"CreatedAt\", []string{timestampValue})\n\tif err != nil {\n\t\tt.Fatalf(\"failed to prepare value for CreatedAt: %+v with err %v\", timestampValue, err)\n\t}\n\texpectedTime, err := time.Parse(time.RFC3339Nano, timestampValue)\n\tif err != nil {\n\t\tt.Fatalf(\"Native time library failed to parse test timestamp %s with err %v\", timestampValue, err)\n\t}\n\tassert.EqualValues(t, expectedTime, values)\n\n\tbadTimestampValue := \"not a valid timestamp\"\n\t_, err = prepareValues(\"CreatedAt\", []string{badTimestampValue})\n\tassert.Error(t, err)\n}\n\nfunc TestPrepareValues_WithDuration(t *testing.T) {\n\tduration := \"3600.5s\"\n\tvalues, err := prepareValues(\"duration\", []string{duration})\n\tassert.Nil(t, err)\n\texpectedDuration, err := time.ParseDuration(duration)\n\tif err != nil {\n\t\tt.Fatalf(\"Native time library failed to parse test timestamp %s with err %v\", duration, err)\n\t}\n\tassert.EqualValues(t, expectedDuration, values)\n\n\tduration = \"3600.5\"\n\tvalues, err = prepareValues(\"duration\", []string{duration})\n\tassert.Nil(t, err)\n\tassert.EqualValues(t, expectedDuration, values)\n\n\tbadDurationValue := \"not a valid duration\"\n\t_, err = prepareValues(\"duration\", []string{badDurationValue})\n\tassert.Error(t, err)\n}\n\nfunc TestPrepareValues_RepeatedValues(t *testing.T) {\n\tvalues, err := prepareValues(\"field\", []string{\"value\"})\n\tassert.NoError(t, err)\n\tassert.Equal(t, \"value\", values)\n\n\tvalues, err = prepareValues(\"field\", []string{\"value a\", \"value b\"})\n\tassert.NoError(t, err)\n\tassert.Equal(t, []interface{}{\"value a\", \"value b\"}, values)\n}\n\nfunc TestParseFilters(t *testing.T) {\n\tfilterExpression := \"eq(foo, 123)+ne(version, TheWorst)+value_in(bar, 4;5;6)\"\n\ttaskFilters, err := ParseFilters(filterExpression, common.Task)\n\tassert.NoError(t, err)\n\n\tassert.Len(t, taskFilters, 3)\n\tactualFilterExpression, _ := taskFilters[0].GetGormQueryExpr()\n\tassert.Equal(t, \"foo = ?\", actualFilterExpression.Query)\n\tassert.Equal(t, \"123\", actualFilterExpression.Args)\n\n\tactualFilterExpression, _ = taskFilters[1].GetGormQueryExpr()\n\tassert.Equal(t, \"version <> ?\", actualFilterExpression.Query)\n\tassert.Equal(t, \"TheWorst\", actualFilterExpression.Args)\n\n\tactualFilterExpression, _ = taskFilters[2].GetGormQueryExpr()\n\tassert.Equal(t, \"bar in (?)\", actualFilterExpression.Query)\n\tassert.Equal(t, []interface{}{\"4\", \"5\", \"6\"}, actualFilterExpression.Args)\n\n\tfilterExpression = \"invalid_function(foo,bar)\"\n\t_, err = ParseFilters(filterExpression, common.Task)\n\tassert.Error(t, err)\n\tassert.EqualError(t, err, \"unrecognized filter function: invalid_function\")\n}\n\nfunc TestGetEqualityFilter(t *testing.T) {\n\tfilter, err := GetSingleValueEqualityFilter(common.Task, \"field\", \"value\")\n\tassert.NoError(t, err)\n\n\tactualFilterExpression, _ := filter.GetGormQueryExpr()\n\tassert.Equal(t, \"field = ?\", actualFilterExpression.Query)\n\tassert.Equal(t, \"value\", actualFilterExpression.Args)\n}\n\nfunc TestAddRequestFilters(t *testing.T) {\n\tfilters, err := AddRequestFilters(\n\t\t\"ne(version, TheWorst)+eq(workflow.name, workflow)\", common.Execution, make([]common.InlineFilter, 0))\n\tassert.Nil(t, err)\n\tassert.Len(t, filters, 2)\n\texpression, err := filters[0].GetGormQueryExpr()\n\tassert.Nil(t, err)\n\tassert.Equal(t, \"version <> ?\", expression.Query)\n\tassert.Equal(t, \"TheWorst\", expression.Args)\n\n\texpression, err = filters[1].GetGormQueryExpr()\n\tassert.Nil(t, err)\n\tassert.Equal(t, testutils.NameQueryPattern, expression.Query)\n\tassert.Equal(t, \"workflow\", expression.Args)\n}\n\nfunc TestGetDbFilters(t *testing.T) {\n\tactualFilters, err := GetDbFilters(FilterSpec{\n\t\tProject:        \"project\",\n\t\tDomain:         \"domain\",\n\t\tName:           \"name\",\n\t\tRequestFilters: \"ne(version, TheWorst)+eq(workflow.name, workflow)\",\n\t}, common.LaunchPlan)\n\tassert.NoError(t, err)\n\n\t// Init expected values for filters.\n\tprojectFilter, _ := GetSingleValueEqualityFilter(common.LaunchPlan, shared.Project, \"project\")\n\tdomainFilter, _ := GetSingleValueEqualityFilter(common.LaunchPlan, shared.Domain, \"domain\")\n\tnameFilter, _ := GetSingleValueEqualityFilter(common.LaunchPlan, shared.Name, \"name\")\n\tversionFilter, _ := common.NewSingleValueFilter(common.LaunchPlan, common.NotEqual, shared.Version, \"TheWorst\")\n\tworkflowNameFilter, _ := common.NewSingleValueFilter(common.Workflow, common.Equal, shared.Name, \"workflow\")\n\texpectedFilters := []common.InlineFilter{\n\t\tprojectFilter,\n\t\tdomainFilter,\n\t\tnameFilter,\n\t\tversionFilter,\n\t\tworkflowNameFilter,\n\t}\n\tassert.EqualValues(t, expectedFilters, actualFilters)\n}\n\nfunc TestGetWorkflowExecutionIdentifierFilters(t *testing.T) {\n\tidentifierFilters, err := GetWorkflowExecutionIdentifierFilters(\n\t\tcontext.Background(), core.WorkflowExecutionIdentifier{\n\t\t\tProject: \"ex project\",\n\t\t\tDomain:  \"ex domain\",\n\t\t\tName:    \"ex name\",\n\t\t})\n\tassert.Nil(t, err)\n\n\tassert.Len(t, identifierFilters, 3)\n\tassert.Equal(t, common.Execution, identifierFilters[0].GetEntity())\n\tqueryExpr, _ := identifierFilters[0].GetGormQueryExpr()\n\tassert.Equal(t, \"ex project\", queryExpr.Args)\n\tassert.Equal(t, \"execution_project = ?\", queryExpr.Query)\n\n\tassert.Equal(t, common.Execution, identifierFilters[1].GetEntity())\n\tqueryExpr, _ = identifierFilters[1].GetGormQueryExpr()\n\tassert.Equal(t, \"ex domain\", queryExpr.Args)\n\tassert.Equal(t, \"execution_domain = ?\", queryExpr.Query)\n\n\tassert.Equal(t, common.Execution, identifierFilters[2].GetEntity())\n\tqueryExpr, _ = identifierFilters[2].GetGormQueryExpr()\n\tassert.Equal(t, \"ex name\", queryExpr.Args)\n\tassert.Equal(t, \"execution_name = ?\", queryExpr.Query)\n}\n\nfunc TestGetNodeExecutionIdentifierFilters(t *testing.T) {\n\tidentifierFilters, err := GetNodeExecutionIdentifierFilters(\n\t\tcontext.Background(), core.NodeExecutionIdentifier{\n\t\t\tExecutionId: &core.WorkflowExecutionIdentifier{\n\t\t\t\tProject: \"ex project\",\n\t\t\t\tDomain:  \"ex domain\",\n\t\t\t\tName:    \"ex name\",\n\t\t\t},\n\t\t\tNodeId: \"nodey\",\n\t\t})\n\tassert.Nil(t, err)\n\n\tassert.Len(t, identifierFilters, 4)\n\tassert.Equal(t, common.Execution, identifierFilters[0].GetEntity())\n\tqueryExpr, _ := identifierFilters[0].GetGormQueryExpr()\n\tassert.Equal(t, \"ex project\", queryExpr.Args)\n\tassert.Equal(t, \"execution_project = ?\", queryExpr.Query)\n\n\tassert.Equal(t, common.Execution, identifierFilters[1].GetEntity())\n\tqueryExpr, _ = identifierFilters[1].GetGormQueryExpr()\n\tassert.Equal(t, \"ex domain\", queryExpr.Args)\n\tassert.Equal(t, \"execution_domain = ?\", queryExpr.Query)\n\n\tassert.Equal(t, common.Execution, identifierFilters[2].GetEntity())\n\tqueryExpr, _ = identifierFilters[2].GetGormQueryExpr()\n\tassert.Equal(t, \"ex name\", queryExpr.Args)\n\tassert.Equal(t, \"execution_name = ?\", queryExpr.Query)\n\n\tassert.Equal(t, common.NodeExecution, identifierFilters[3].GetEntity())\n\tqueryExpr, _ = identifierFilters[3].GetGormQueryExpr()\n\tassert.Equal(t, \"nodey\", queryExpr.Args)\n\tassert.Equal(t, \"node_id = ?\", queryExpr.Query)\n}\n", "package impl\n\nimport (\n\t\"bytes\"\n\t\"context\"\n\t\"strconv\"\n\t\"time\"\n\n\t\"github.com/flyteorg/flytestdlib/contextutils\"\n\n\t\"github.com/flyteorg/flyteadmin/pkg/common\"\n\t\"github.com/flyteorg/flyteadmin/pkg/errors\"\n\t\"github.com/flyteorg/flyteadmin/pkg/manager/impl/util\"\n\t\"github.com/flyteorg/flyteadmin/pkg/manager/impl/validation\"\n\t\"github.com/flyteorg/flyteadmin/pkg/manager/interfaces\"\n\trepoInterfaces \"github.com/flyteorg/flyteadmin/pkg/repositories/interfaces\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/models\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/transformers\"\n\truntimeInterfaces \"github.com/flyteorg/flyteadmin/pkg/runtime/interfaces\"\n\tworkflowengine \"github.com/flyteorg/flyteadmin/pkg/workflowengine/impl\"\n\tworkflowengineInterfaces \"github.com/flyteorg/flyteadmin/pkg/workflowengine/interfaces\"\n\t\"github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/admin\"\n\t\"github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/core\"\n\tcompiler \"github.com/flyteorg/flytepropeller/pkg/compiler/common\"\n\t\"github.com/flyteorg/flytestdlib/logger\"\n\t\"github.com/flyteorg/flytestdlib/promutils\"\n\t\"github.com/flyteorg/flytestdlib/storage\"\n\t\"github.com/golang/protobuf/ptypes\"\n\t\"github.com/prometheus/client_golang/prometheus\"\n\t\"google.golang.org/grpc/codes\"\n)\n\nvar defaultStorageOptions = storage.Options{}\n\ntype workflowMetrics struct {\n\tScope                   promutils.Scope\n\tCompilationFailures     prometheus.Counter\n\tTypedInterfaceSizeBytes prometheus.Summary\n}\n\ntype WorkflowManager struct {\n\tdb            repoInterfaces.Repository\n\tconfig        runtimeInterfaces.Configuration\n\tcompiler      workflowengineInterfaces.Compiler\n\tstorageClient *storage.DataStore\n\tstoragePrefix []string\n\tmetrics       workflowMetrics\n}\n\nfunc getWorkflowContext(ctx context.Context, identifier *core.Identifier) context.Context {\n\tctx = contextutils.WithProjectDomain(ctx, identifier.Project, identifier.Domain)\n\treturn contextutils.WithWorkflowID(ctx, identifier.Name)\n}\n\nfunc (w *WorkflowManager) setDefaults(request admin.WorkflowCreateRequest) (admin.WorkflowCreateRequest, error) {\n\t// TODO: Also add environment and configuration defaults once those have been determined.\n\tif request.Id == nil {\n\t\treturn request, errors.NewFlyteAdminError(codes.InvalidArgument, \"missing identifier for WorkflowCreateRequest\")\n\t}\n\trequest.Spec.Template.Id = request.Id\n\treturn request, nil\n}\n\nfunc (w *WorkflowManager) getCompiledWorkflow(\n\tctx context.Context, request admin.WorkflowCreateRequest) (admin.WorkflowClosure, error) {\n\treqs, err := w.compiler.GetRequirements(request.Spec.Template, request.Spec.SubWorkflows)\n\tif err != nil {\n\t\tw.metrics.CompilationFailures.Inc()\n\t\tlogger.Errorf(ctx, \"Failed to get workflow requirements for template [%+v] with err %v\",\n\t\t\trequest.Spec.Template, err)\n\t\treturn admin.WorkflowClosure{}, err\n\t}\n\n\tvar tasks = make([]*core.CompiledTask, len(reqs.GetRequiredTaskIds()))\n\tfor idx, taskID := range reqs.GetRequiredTaskIds() {\n\t\ttask, err := util.GetTask(ctx, w.db, taskID)\n\t\tif err != nil {\n\t\t\tlogger.Debugf(ctx, \"Failed to get task with id [%+v] when compiling workflow with id [%+v] with err %v\",\n\t\t\t\ttaskID, request.Id, err)\n\t\t\treturn admin.WorkflowClosure{}, err\n\t\t}\n\t\ttasks[idx] = task.Closure.CompiledTask\n\t}\n\n\tvar launchPlans = make([]compiler.InterfaceProvider, len(reqs.GetRequiredLaunchPlanIds()))\n\tfor idx, launchPlanID := range reqs.GetRequiredLaunchPlanIds() {\n\t\tvar launchPlanModel models.LaunchPlan\n\t\tlaunchPlanModel, err = util.GetLaunchPlanModel(ctx, w.db, launchPlanID)\n\t\tif err != nil {\n\t\t\tlogger.Debugf(ctx, \"Failed to get launch plan with id [%+v] when compiling workflow with id [%+v] with err %v\",\n\t\t\t\tlaunchPlanID, request.Id, err)\n\t\t\treturn admin.WorkflowClosure{}, err\n\t\t}\n\t\tvar launchPlanInterfaceProvider workflowengine.InterfaceProvider\n\t\tlaunchPlanInterfaceProvider, err = workflowengine.NewLaunchPlanInterfaceProvider(launchPlanModel, launchPlanID)\n\t\tif err != nil {\n\t\t\tlogger.Debugf(ctx, \"Failed to create LaunchPlanInterfaceProvider for launch plan [%+v] with err %v\",\n\t\t\t\tlaunchPlanModel, err)\n\t\t\treturn admin.WorkflowClosure{}, err\n\t\t}\n\t\tlaunchPlans[idx] = launchPlanInterfaceProvider\n\t}\n\n\tclosure, err := w.compiler.CompileWorkflow(request.Spec.Template, request.Spec.SubWorkflows, tasks, launchPlans)\n\tif err != nil {\n\t\tw.metrics.CompilationFailures.Inc()\n\t\tlogger.Debugf(ctx, \"Failed to compile workflow with id [%+v] with err %v\", request.Id, err)\n\t\treturn admin.WorkflowClosure{}, err\n\t}\n\tcreatedAt, err := ptypes.TimestampProto(time.Now())\n\tif err != nil {\n\t\treturn admin.WorkflowClosure{}, errors.NewFlyteAdminErrorf(codes.Internal,\n\t\t\t\"Failed to serialize CreatedAt: %v when saving compiled workflow %+v\", err, request.Id)\n\t}\n\treturn admin.WorkflowClosure{\n\t\tCompiledWorkflow: closure,\n\t\tCreatedAt:        createdAt,\n\t}, nil\n}\n\nfunc (w *WorkflowManager) createDataReference(\n\tctx context.Context, identifier *core.Identifier) (storage.DataReference, error) {\n\tnestedSubKeys := []string{\n\t\tidentifier.Project,\n\t\tidentifier.Domain,\n\t\tidentifier.Name,\n\t\tidentifier.Version,\n\t}\n\tnestedKeys := append(w.storagePrefix, nestedSubKeys...)\n\treturn w.storageClient.ConstructReference(ctx, w.storageClient.GetBaseContainerFQN(ctx), nestedKeys...)\n}\n\nfunc (w *WorkflowManager) CreateWorkflow(\n\tctx context.Context,\n\trequest admin.WorkflowCreateRequest) (*admin.WorkflowCreateResponse, error) {\n\tif err := validation.ValidateWorkflow(ctx, request, w.db, w.config.ApplicationConfiguration()); err != nil {\n\t\treturn nil, err\n\t}\n\tctx = getWorkflowContext(ctx, request.Id)\n\tfinalizedRequest, err := w.setDefaults(request)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"Failed to set defaults for workflow with id [%+v] with err %v\", request.Id, err)\n\t\treturn nil, err\n\t}\n\t// Validate that the workflow compiles.\n\tworkflowClosure, err := w.getCompiledWorkflow(ctx, finalizedRequest)\n\tif err != nil {\n\t\tlogger.Errorf(ctx, \"Failed to compile workflow with err: %v\", err)\n\t\treturn nil, errors.NewFlyteAdminErrorf(codes.Internal,\n\t\t\t\"failed to compile workflow for [%+v] with err %v\", request.Id, err)\n\t}\n\terr = validation.ValidateCompiledWorkflow(\n\t\t*request.Id, workflowClosure, w.config.RegistrationValidationConfiguration())\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tworkflowDigest, err := util.GetWorkflowDigest(ctx, workflowClosure.CompiledWorkflow)\n\tif err != nil {\n\t\tlogger.Errorf(ctx, \"failed to compute workflow digest with err %v\", err)\n\t\treturn nil, err\n\t}\n\n\t// Assert that a matching workflow doesn't already exist before uploading the workflow closure.\n\texistingWorkflowModel, err := util.GetWorkflowModel(ctx, w.db, *request.Id)\n\t// Check that no identical or conflicting workflows exist.\n\tif err == nil {\n\t\t// A workflow's structure is uniquely defined by its collection of nodes.\n\t\tif bytes.Equal(workflowDigest, existingWorkflowModel.Digest) {\n\t\t\treturn nil, errors.NewWorkflowExistsIdenticalStructureError(ctx, &request)\n\t\t}\n\t\t// A workflow exists with different structure\n\t\treturn nil, errors.NewWorkflowExistsDifferentStructureError(ctx, &request)\n\t} else if flyteAdminError, ok := err.(errors.FlyteAdminError); !ok || flyteAdminError.Code() != codes.NotFound {\n\t\tlogger.Debugf(ctx, \"Failed to get workflow for comparison in CreateWorkflow with ID [%+v] with err %v\",\n\t\t\trequest.Id, err)\n\t\treturn nil, err\n\t}\n\n\tremoteClosureDataRef, err := w.createDataReference(ctx, request.Spec.Template.Id)\n\tif err != nil {\n\t\tlogger.Infof(ctx, \"failed to construct data reference for workflow closure with id [%+v] with err %v\",\n\t\t\trequest.Id, err)\n\t\treturn nil, errors.NewFlyteAdminErrorf(codes.Internal,\n\t\t\t\"failed to construct data reference for workflow closure with id [%+v] and err %v\", request.Id, err)\n\t}\n\terr = w.storageClient.WriteProtobuf(ctx, remoteClosureDataRef, defaultStorageOptions, &workflowClosure)\n\n\tif err != nil {\n\t\tlogger.Infof(ctx,\n\t\t\t\"failed to write marshaled workflow with id [%+v] to storage %s with err %v and base container: %s\",\n\t\t\trequest.Id, remoteClosureDataRef.String(), err, w.storageClient.GetBaseContainerFQN(ctx))\n\t\treturn nil, errors.NewFlyteAdminErrorf(codes.Internal,\n\t\t\t\"failed to write marshaled workflow [%+v] to storage %s with err %v and base container: %s\",\n\t\t\trequest.Id, remoteClosureDataRef.String(), err, w.storageClient.GetBaseContainerFQN(ctx))\n\t}\n\t// Save the workflow & its reference to the offloaded, compiled workflow in the database.\n\tworkflowModel, err := transformers.CreateWorkflowModel(\n\t\tfinalizedRequest, remoteClosureDataRef.String(), workflowDigest)\n\tif err != nil {\n\t\tlogger.Errorf(ctx,\n\t\t\t\"Failed to transform workflow model for request [%+v] and remoteClosureIdentifier [%s] with err: %v\",\n\t\t\tfinalizedRequest, remoteClosureDataRef.String(), err)\n\t\treturn nil, err\n\t}\n\tdescriptionModel, err := transformers.CreateDescriptionEntityModel(request.Spec.Description, *request.Id)\n\tif err != nil {\n\t\tlogger.Errorf(ctx,\n\t\t\t\"Failed to transform description model [%+v] with err: %v\", request.Spec.Description, err)\n\t\treturn nil, err\n\t}\n\tif descriptionModel != nil {\n\t\tworkflowModel.ShortDescription = descriptionModel.ShortDescription\n\t}\n\tif err = w.db.WorkflowRepo().Create(ctx, workflowModel, descriptionModel); err != nil {\n\t\tlogger.Infof(ctx, \"Failed to create workflow model [%+v] with err %v\", request.Id, err)\n\t\treturn nil, err\n\t}\n\tw.metrics.TypedInterfaceSizeBytes.Observe(float64(len(workflowModel.TypedInterface)))\n\n\treturn &admin.WorkflowCreateResponse{}, nil\n}\n\nfunc (w *WorkflowManager) GetWorkflow(ctx context.Context, request admin.ObjectGetRequest) (*admin.Workflow, error) {\n\tif err := validation.ValidateIdentifier(request.Id, common.Workflow); err != nil {\n\t\tlogger.Debugf(ctx, \"invalid identifier [%+v]: %v\", request.Id, err)\n\t\treturn nil, err\n\t}\n\tctx = getWorkflowContext(ctx, request.Id)\n\tworkflow, err := util.GetWorkflow(ctx, w.db, w.storageClient, *request.Id)\n\tif err != nil {\n\t\tlogger.Infof(ctx, \"Failed to get workflow with id [%+v] with err %v\", request.Id, err)\n\t\treturn nil, err\n\t}\n\treturn workflow, nil\n}\n\n// Returns workflows *without* a populated workflow closure.\nfunc (w *WorkflowManager) ListWorkflows(\n\tctx context.Context, request admin.ResourceListRequest) (*admin.WorkflowList, error) {\n\t// Check required fields\n\tif err := validation.ValidateResourceListRequest(request); err != nil {\n\t\treturn nil, err\n\t}\n\tctx = contextutils.WithProjectDomain(ctx, request.Id.Project, request.Id.Domain)\n\tctx = contextutils.WithWorkflowID(ctx, request.Id.Name)\n\tfilters, err := util.GetDbFilters(util.FilterSpec{\n\t\tProject:        request.Id.Project,\n\t\tDomain:         request.Id.Domain,\n\t\tName:           request.Id.Name,\n\t\tRequestFilters: request.Filters,\n\t}, common.Workflow)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tvar sortParameter common.SortParameter\n\tif request.SortBy != nil {\n\t\tsortParameter, err = common.NewSortParameter(*request.SortBy)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\toffset, err := validation.ValidateToken(request.Token)\n\tif err != nil {\n\t\treturn nil, errors.NewFlyteAdminErrorf(codes.InvalidArgument,\n\t\t\t\"invalid pagination token %s for ListWorkflows\", request.Token)\n\t}\n\tlistWorkflowsInput := repoInterfaces.ListResourceInput{\n\t\tLimit:         int(request.Limit),\n\t\tOffset:        offset,\n\t\tInlineFilters: filters,\n\t\tSortParameter: sortParameter,\n\t}\n\toutput, err := w.db.WorkflowRepo().List(ctx, listWorkflowsInput)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"Failed to list workflows with [%+v] with err %v\", request.Id, err)\n\t\treturn nil, err\n\t}\n\tworkflowList, err := transformers.FromWorkflowModels(output.Workflows)\n\tif err != nil {\n\t\tlogger.Errorf(ctx,\n\t\t\t\"Failed to transform workflow models [%+v] with err: %v\", output.Workflows, err)\n\t\treturn nil, err\n\t}\n\tvar token string\n\tif len(output.Workflows) == int(request.Limit) {\n\t\ttoken = strconv.Itoa(offset + len(output.Workflows))\n\t}\n\treturn &admin.WorkflowList{\n\t\tWorkflows: workflowList,\n\t\tToken:     token,\n\t}, nil\n}\n\nfunc (w *WorkflowManager) ListWorkflowIdentifiers(ctx context.Context, request admin.NamedEntityIdentifierListRequest) (\n\t*admin.NamedEntityIdentifierList, error) {\n\tif err := validation.ValidateNamedEntityIdentifierListRequest(request); err != nil {\n\t\tlogger.Debugf(ctx, \"invalid request [%+v]: %v\", request, err)\n\t\treturn nil, err\n\t}\n\tctx = contextutils.WithProjectDomain(ctx, request.Project, request.Domain)\n\n\tfilters, err := util.GetDbFilters(util.FilterSpec{\n\t\tProject: request.Project,\n\t\tDomain:  request.Domain,\n\t}, common.Workflow)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tvar sortParameter common.SortParameter\n\tif request.SortBy != nil {\n\t\tsortParameter, err = common.NewSortParameter(*request.SortBy)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\toffset, err := validation.ValidateToken(request.Token)\n\tif err != nil {\n\t\treturn nil, errors.NewFlyteAdminErrorf(codes.InvalidArgument,\n\t\t\t\"invalid pagination token %s for ListWorkflowIdentifiers\", request.Token)\n\t}\n\tlistWorkflowsInput := repoInterfaces.ListResourceInput{\n\t\tLimit:         int(request.Limit),\n\t\tOffset:        offset,\n\t\tInlineFilters: filters,\n\t\tSortParameter: sortParameter,\n\t}\n\n\toutput, err := w.db.WorkflowRepo().ListIdentifiers(ctx, listWorkflowsInput)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"Failed to list workflow ids with project: %s and domain: %s with err %v\",\n\t\t\trequest.Project, request.Domain, err)\n\t\treturn nil, err\n\t}\n\n\tvar token string\n\tif len(output.Workflows) == int(request.Limit) {\n\t\ttoken = strconv.Itoa(offset + len(output.Workflows))\n\t}\n\tentities := transformers.FromWorkflowModelsToIdentifiers(output.Workflows)\n\treturn &admin.NamedEntityIdentifierList{\n\t\tEntities: entities,\n\t\tToken:    token,\n\t}, nil\n\n}\n\nfunc NewWorkflowManager(\n\tdb repoInterfaces.Repository,\n\tconfig runtimeInterfaces.Configuration,\n\tcompiler workflowengineInterfaces.Compiler,\n\tstorageClient *storage.DataStore,\n\tstoragePrefix []string,\n\tscope promutils.Scope) interfaces.WorkflowInterface {\n\tmetrics := workflowMetrics{\n\t\tScope: scope,\n\t\tCompilationFailures: scope.MustNewCounter(\n\t\t\t\"compilation_failures\", \"any observed failures when compiling a workflow\"),\n\t\tTypedInterfaceSizeBytes: scope.MustNewSummary(\"typed_interface_size_bytes\",\n\t\t\t\"size in bytes of serialized workflow TypedInterface\"),\n\t}\n\treturn &WorkflowManager{\n\t\tdb:            db,\n\t\tconfig:        config,\n\t\tcompiler:      compiler,\n\t\tstorageClient: storageClient,\n\t\tstoragePrefix: storagePrefix,\n\t\tmetrics:       metrics,\n\t}\n}\n", "package gormimpl\n\nimport (\n\t\"fmt\"\n\n\t\"github.com/flyteorg/flyteadmin/pkg/common\"\n\tadminErrors \"github.com/flyteorg/flyteadmin/pkg/errors\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/errors\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/interfaces\"\n\n\t\"google.golang.org/grpc/codes\"\n\t\"gorm.io/gorm\"\n)\n\nconst Project = \"project\"\nconst Domain = \"domain\"\nconst Name = \"name\"\nconst Version = \"version\"\nconst Description = \"description\"\nconst ResourceType = \"resource_type\"\nconst State = \"state\"\nconst ID = \"id\"\n\nconst executionTableName = \"executions\"\nconst namedEntityMetadataTableName = \"named_entity_metadata\"\nconst nodeExecutionTableName = \"node_executions\"\nconst taskExecutionTableName = \"task_executions\"\nconst taskTableName = \"tasks\"\nconst workflowTableName = \"workflows\"\nconst descriptionEntityTableName = \"description_entities\"\nconst AdminTagsTableName = \"admin_tags\"\nconst executionAdminTagsTableName = \"execution_admin_tags\"\n\nconst limit = \"limit\"\nconst filters = \"filters\"\n\nvar identifierGroupBy = fmt.Sprintf(\"%s, %s, %s\", Project, Domain, Name)\n\nvar entityToTableName = map[common.Entity]string{\n\tcommon.Execution:           \"executions\",\n\tcommon.LaunchPlan:          \"launch_plans\",\n\tcommon.NodeExecution:       \"node_executions\",\n\tcommon.NodeExecutionEvent:  \"node_execution_events\",\n\tcommon.Task:                \"tasks\",\n\tcommon.TaskExecution:       \"task_executions\",\n\tcommon.Workflow:            \"workflows\",\n\tcommon.NamedEntity:         \"entities\",\n\tcommon.NamedEntityMetadata: \"named_entity_metadata\",\n\tcommon.Signal:              \"signals\",\n\tcommon.AdminTag:            \"admin_tags\",\n\tcommon.ExecutionAdminTag:   \"execution_admin_tags\",\n}\n\nvar innerJoinExecToNodeExec = fmt.Sprintf(\n\t\"INNER JOIN %s ON %s.execution_project = %s.execution_project AND \"+\n\t\t\"%s.execution_domain = %s.execution_domain AND %s.execution_name = %s.execution_name\",\n\texecutionTableName, nodeExecutionTableName, executionTableName, nodeExecutionTableName, executionTableName,\n\tnodeExecutionTableName, executionTableName)\n\nvar innerJoinNodeExecToTaskExec = fmt.Sprintf(\n\t\"INNER JOIN %s ON %s.node_id = %s.node_id AND %s.execution_project = %s.execution_project AND \"+\n\t\t\"%s.execution_domain = %s.execution_domain AND %s.execution_name = %s.execution_name\",\n\tnodeExecutionTableName, taskExecutionTableName, nodeExecutionTableName, taskExecutionTableName,\n\tnodeExecutionTableName, taskExecutionTableName, nodeExecutionTableName, taskExecutionTableName,\n\tnodeExecutionTableName)\n\n// Because dynamic tasks do NOT necessarily register static task definitions, we use a left join to not exclude\n// dynamic tasks from list queries.\nvar leftJoinTaskToTaskExec = fmt.Sprintf(\n\t\"LEFT JOIN %s ON %s.project = %s.project AND %s.domain = %s.domain AND %s.name = %s.name AND \"+\n\t\t\"%s.version = %s.version\",\n\ttaskTableName, taskExecutionTableName, taskTableName, taskExecutionTableName, taskTableName,\n\ttaskExecutionTableName, taskTableName, taskExecutionTableName, taskTableName)\n\n// Validates there are no missing but required parameters in ListResourceInput\nfunc ValidateListInput(input interfaces.ListResourceInput) adminErrors.FlyteAdminError {\n\tif input.Limit == 0 {\n\t\treturn errors.GetInvalidInputError(limit)\n\t}\n\tif len(input.InlineFilters) == 0 {\n\t\treturn errors.GetInvalidInputError(filters)\n\t}\n\treturn nil\n}\n\nfunc applyFilters(tx *gorm.DB, inlineFilters []common.InlineFilter, mapFilters []common.MapFilter) (*gorm.DB, error) {\n\tfor _, filter := range inlineFilters {\n\t\tgormQueryExpr, err := filter.GetGormQueryExpr()\n\t\tif err != nil {\n\t\t\treturn nil, errors.GetInvalidInputError(err.Error())\n\t\t}\n\t\ttx = tx.Where(gormQueryExpr.Query, gormQueryExpr.Args)\n\t}\n\tfor _, mapFilter := range mapFilters {\n\t\ttx = tx.Where(mapFilter.GetFilter())\n\t}\n\treturn tx, nil\n}\n\nfunc applyScopedFilters(tx *gorm.DB, inlineFilters []common.InlineFilter, mapFilters []common.MapFilter) (*gorm.DB, error) {\n\tfor _, filter := range inlineFilters {\n\t\ttableName, ok := entityToTableName[filter.GetEntity()]\n\t\tif !ok {\n\t\t\treturn nil, adminErrors.NewFlyteAdminErrorf(codes.InvalidArgument,\n\t\t\t\t\"unrecognized entity in filter expression: %v\", filter.GetEntity())\n\t\t}\n\t\tgormQueryExpr, err := filter.GetGormJoinTableQueryExpr(tableName)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\ttx = tx.Where(gormQueryExpr.Query, gormQueryExpr.Args)\n\t}\n\tfor _, mapFilter := range mapFilters {\n\t\ttx = tx.Where(mapFilter.GetFilter())\n\t}\n\treturn tx, nil\n}\n", "package gormimpl\n\nimport (\n\t\"context\"\n\n\t\"github.com/flyteorg/flyteadmin/pkg/common\"\n\t\"github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/core\"\n\t\"github.com/flyteorg/flytestdlib/promutils\"\n\n\tflyteAdminDbErrors \"github.com/flyteorg/flyteadmin/pkg/repositories/errors\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/interfaces\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/models\"\n\t\"gorm.io/gorm\"\n)\n\n// DescriptionEntityRepo Implementation of DescriptionEntityRepoInterface.\ntype DescriptionEntityRepo struct {\n\tdb               *gorm.DB\n\terrorTransformer flyteAdminDbErrors.ErrorTransformer\n\tmetrics          gormMetrics\n}\n\nfunc (r *DescriptionEntityRepo) Get(ctx context.Context, input interfaces.GetDescriptionEntityInput) (models.DescriptionEntity, error) {\n\tvar descriptionEntity models.DescriptionEntity\n\n\tfilters, err := getDescriptionEntityFilters(input.ResourceType, input.Project, input.Domain, input.Name, input.Version)\n\tif err != nil {\n\t\treturn models.DescriptionEntity{}, err\n\t}\n\n\ttx := r.db.Table(descriptionEntityTableName)\n\t// Apply filters\n\ttx, err = applyFilters(tx, filters, nil)\n\tif err != nil {\n\t\treturn models.DescriptionEntity{}, err\n\t}\n\n\ttimer := r.metrics.GetDuration.Start()\n\ttx = tx.Take(&descriptionEntity)\n\ttimer.Stop()\n\n\tif tx.Error != nil {\n\t\treturn models.DescriptionEntity{}, r.errorTransformer.ToFlyteAdminError(tx.Error)\n\t}\n\n\treturn descriptionEntity, nil\n}\n\nfunc (r *DescriptionEntityRepo) List(\n\tctx context.Context, input interfaces.ListResourceInput) (interfaces.DescriptionEntityCollectionOutput, error) {\n\t// First validate input.\n\tif err := ValidateListInput(input); err != nil {\n\t\treturn interfaces.DescriptionEntityCollectionOutput{}, err\n\t}\n\tvar descriptionEntities []models.DescriptionEntity\n\ttx := r.db.Limit(input.Limit).Offset(input.Offset)\n\n\t// Apply filters\n\ttx, err := applyFilters(tx, input.InlineFilters, input.MapFilters)\n\tif err != nil {\n\t\treturn interfaces.DescriptionEntityCollectionOutput{}, err\n\t}\n\t// Apply sort ordering.\n\tif input.SortParameter != nil {\n\t\ttx = tx.Order(input.SortParameter.GetGormOrderExpr())\n\t}\n\ttimer := r.metrics.ListDuration.Start()\n\ttx.Find(&descriptionEntities)\n\ttimer.Stop()\n\tif tx.Error != nil {\n\t\treturn interfaces.DescriptionEntityCollectionOutput{}, r.errorTransformer.ToFlyteAdminError(tx.Error)\n\t}\n\treturn interfaces.DescriptionEntityCollectionOutput{\n\t\tEntities: descriptionEntities,\n\t}, nil\n}\n\nfunc getDescriptionEntityFilters(resourceType core.ResourceType, project string, domain string, name string, version string) ([]common.InlineFilter, error) {\n\tentity := common.ResourceTypeToEntity[resourceType]\n\n\tfilters := make([]common.InlineFilter, 0)\n\tprojectFilter, err := common.NewSingleValueFilter(entity, common.Equal, Project, project)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tfilters = append(filters, projectFilter)\n\tdomainFilter, err := common.NewSingleValueFilter(entity, common.Equal, Domain, domain)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tfilters = append(filters, domainFilter)\n\tnameFilter, err := common.NewSingleValueFilter(entity, common.Equal, Name, name)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tfilters = append(filters, nameFilter)\n\tversionFilter, err := common.NewSingleValueFilter(entity, common.Equal, Version, version)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tfilters = append(filters, versionFilter)\n\n\treturn filters, nil\n}\n\n// NewDescriptionEntityRepo Returns an instance of DescriptionRepoInterface\nfunc NewDescriptionEntityRepo(\n\tdb *gorm.DB, errorTransformer flyteAdminDbErrors.ErrorTransformer, scope promutils.Scope) interfaces.DescriptionEntityRepoInterface {\n\tmetrics := newMetrics(scope)\n\treturn &DescriptionEntityRepo{\n\t\tdb:               db,\n\t\terrorTransformer: errorTransformer,\n\t\tmetrics:          metrics,\n\t}\n}\n", "package gormimpl\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"fmt\"\n\n\t\"github.com/flyteorg/flyteadmin/pkg/common\"\n\tadminErrors \"github.com/flyteorg/flyteadmin/pkg/repositories/errors\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/interfaces\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/models\"\n\t\"github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/core\"\n\t\"github.com/flyteorg/flytestdlib/promutils\"\n\n\t\"gorm.io/gorm\"\n)\n\n// Implementation of ExecutionInterface.\ntype ExecutionRepo struct {\n\tdb               *gorm.DB\n\terrorTransformer adminErrors.ErrorTransformer\n\tmetrics          gormMetrics\n}\n\nfunc (r *ExecutionRepo) Create(ctx context.Context, input models.Execution) error {\n\ttimer := r.metrics.CreateDuration.Start()\n\ttx := r.db.Omit(\"id\").Create(&input)\n\ttimer.Stop()\n\tif tx.Error != nil {\n\t\treturn r.errorTransformer.ToFlyteAdminError(tx.Error)\n\t}\n\treturn nil\n}\n\nfunc (r *ExecutionRepo) Get(_ context.Context, input interfaces.Identifier) (models.Execution, error) {\n\tvar execution models.Execution\n\ttimer := r.metrics.GetDuration.Start()\n\ttx := r.db.Where(&models.Execution{\n\t\tExecutionKey: models.ExecutionKey{\n\t\t\tProject: input.Project,\n\t\t\tDomain:  input.Domain,\n\t\t\tName:    input.Name,\n\t\t},\n\t}).Take(&execution)\n\ttimer.Stop()\n\n\tif tx.Error != nil && errors.Is(tx.Error, gorm.ErrRecordNotFound) {\n\t\treturn models.Execution{}, adminErrors.GetMissingEntityError(\"execution\", &core.Identifier{\n\t\t\tProject: input.Project,\n\t\t\tDomain:  input.Domain,\n\t\t\tName:    input.Name,\n\t\t})\n\t} else if tx.Error != nil {\n\t\treturn models.Execution{}, r.errorTransformer.ToFlyteAdminError(tx.Error)\n\t}\n\treturn execution, nil\n}\n\nfunc (r *ExecutionRepo) Update(ctx context.Context, execution models.Execution) error {\n\ttimer := r.metrics.UpdateDuration.Start()\n\ttx := r.db.Model(&execution).Updates(execution)\n\ttimer.Stop()\n\tif err := tx.Error; err != nil {\n\t\treturn r.errorTransformer.ToFlyteAdminError(err)\n\t}\n\treturn nil\n}\n\nfunc (r *ExecutionRepo) List(_ context.Context, input interfaces.ListResourceInput) (\n\tinterfaces.ExecutionCollectionOutput, error) {\n\tvar err error\n\t// First validate input.\n\tif err = ValidateListInput(input); err != nil {\n\t\treturn interfaces.ExecutionCollectionOutput{}, err\n\t}\n\tvar executions []models.Execution\n\ttx := r.db.Limit(input.Limit).Offset(input.Offset)\n\t// And add join condition as required by user-specified filters (which can potentially include join table attrs).\n\tif ok := input.JoinTableEntities[common.LaunchPlan]; ok {\n\t\ttx = tx.Joins(fmt.Sprintf(\"INNER JOIN %s ON %s.launch_plan_id = %s.id\",\n\t\t\tlaunchPlanTableName, executionTableName, launchPlanTableName))\n\t}\n\tif ok := input.JoinTableEntities[common.Workflow]; ok {\n\t\ttx = tx.Joins(fmt.Sprintf(\"INNER JOIN %s ON %s.workflow_id = %s.id\",\n\t\t\tworkflowTableName, executionTableName, workflowTableName))\n\t}\n\tif ok := input.JoinTableEntities[common.Task]; ok {\n\t\ttx = tx.Joins(fmt.Sprintf(\"INNER JOIN %s ON %s.task_id = %s.id\",\n\t\t\ttaskTableName, executionTableName, taskTableName))\n\t}\n\n\tif ok := input.JoinTableEntities[common.AdminTag]; ok {\n\t\ttx = tx.Joins(fmt.Sprintf(\"INNER JOIN %s ON %s.execution_name = %s.execution_name\",\n\t\t\texecutionAdminTagsTableName, executionTableName, executionAdminTagsTableName))\n\t\ttx = tx.Joins(fmt.Sprintf(\"INNER JOIN %s ON %s.id = %s.admin_tag_id\",\n\t\t\tAdminTagsTableName, AdminTagsTableName, executionAdminTagsTableName))\n\t}\n\n\t// Apply filters\n\ttx, err = applyScopedFilters(tx, input.InlineFilters, input.MapFilters)\n\tif err != nil {\n\t\treturn interfaces.ExecutionCollectionOutput{}, err\n\t}\n\t// Apply sort ordering.\n\tif input.SortParameter != nil {\n\t\ttx = tx.Order(input.SortParameter.GetGormOrderExpr())\n\t}\n\n\ttimer := r.metrics.ListDuration.Start()\n\ttx = tx.Find(&executions)\n\ttimer.Stop()\n\tif tx.Error != nil {\n\t\treturn interfaces.ExecutionCollectionOutput{}, r.errorTransformer.ToFlyteAdminError(tx.Error)\n\t}\n\treturn interfaces.ExecutionCollectionOutput{\n\t\tExecutions: executions,\n\t}, nil\n}\n\nfunc (r *ExecutionRepo) Count(ctx context.Context, input interfaces.CountResourceInput) (int64, error) {\n\tvar err error\n\ttx := r.db.Model(&models.Execution{})\n\n\t// Add join condition as required by user-specified filters (which can potentially include join table attrs).\n\tif ok := input.JoinTableEntities[common.LaunchPlan]; ok {\n\t\ttx = tx.Joins(fmt.Sprintf(\"INNER JOIN %s ON %s.launch_plan_id = %s.id\",\n\t\t\tlaunchPlanTableName, executionTableName, launchPlanTableName))\n\t}\n\tif ok := input.JoinTableEntities[common.Workflow]; ok {\n\t\ttx = tx.Joins(fmt.Sprintf(\"INNER JOIN %s ON %s.workflow_id = %s.id\",\n\t\t\tworkflowTableName, executionTableName, workflowTableName))\n\t}\n\tif ok := input.JoinTableEntities[common.Task]; ok {\n\t\ttx = tx.Joins(fmt.Sprintf(\"INNER JOIN %s ON %s.task_id = %s.id\",\n\t\t\ttaskTableName, executionTableName, taskTableName))\n\t}\n\n\t// Apply filters\n\ttx, err = applyScopedFilters(tx, input.InlineFilters, input.MapFilters)\n\tif err != nil {\n\t\treturn 0, err\n\t}\n\n\t// Run the query\n\ttimer := r.metrics.CountDuration.Start()\n\tvar count int64\n\ttx = tx.Count(&count)\n\ttimer.Stop()\n\tif tx.Error != nil {\n\t\treturn 0, r.errorTransformer.ToFlyteAdminError(tx.Error)\n\t}\n\treturn count, nil\n}\n\n// Returns an instance of ExecutionRepoInterface\nfunc NewExecutionRepo(\n\tdb *gorm.DB, errorTransformer adminErrors.ErrorTransformer, scope promutils.Scope) interfaces.ExecutionRepoInterface {\n\tmetrics := newMetrics(scope)\n\treturn &ExecutionRepo{\n\t\tdb:               db,\n\t\terrorTransformer: errorTransformer,\n\t\tmetrics:          metrics,\n\t}\n}\n", "package gormimpl\n\nimport (\n\t\"context\"\n\t\"database/sql/driver\"\n\t\"testing\"\n\t\"time\"\n\n\t\"github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/core\"\n\n\tmockScope \"github.com/flyteorg/flytestdlib/promutils\"\n\n\t\"github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/admin\"\n\n\tmocket \"github.com/Selvatico/go-mocket\"\n\t\"github.com/flyteorg/flyteadmin/pkg/common\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/errors\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/interfaces\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/models\"\n\t\"github.com/stretchr/testify/assert\"\n)\n\nvar createdAt = time.Date(2018, time.February, 17, 00, 00, 00, 00, time.UTC).UTC()\nvar executionStartedAt = time.Date(2018, time.February, 17, 00, 01, 00, 00, time.UTC).UTC()\nvar executionUpdatedAt = time.Date(2018, time.February, 17, 00, 01, 00, 00, time.UTC).UTC()\n\nfunc TestCreateExecution(t *testing.T) {\n\texecutionRepo := NewExecutionRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\terr := executionRepo.Create(context.Background(), models.Execution{\n\t\tExecutionKey: models.ExecutionKey{\n\t\t\tProject: \"project\",\n\t\t\tDomain:  \"domain\",\n\t\t\tName:    \"1\",\n\t\t},\n\t\tLaunchPlanID:       uint(2),\n\t\tPhase:              core.WorkflowExecution_SUCCEEDED.String(),\n\t\tClosure:            []byte{1, 2},\n\t\tSpec:               []byte{3, 4},\n\t\tStartedAt:          &executionStartedAt,\n\t\tExecutionCreatedAt: &createdAt,\n\t})\n\tassert.NoError(t, err)\n}\n\nfunc TestUpdateExecution(t *testing.T) {\n\tGlobalMock := mocket.Catcher.Reset()\n\tGlobalMock.Logging = true\n\tupdated := false\n\n\t// Only match on queries that append expected filters\n\tGlobalMock.NewMock().WithQuery(`UPDATE \"executions\" SET \"updated_at\"=$1,\"execution_project\"=$2,` +\n\t\t`\"execution_domain\"=$3,\"execution_name\"=$4,\"launch_plan_id\"=$5,\"workflow_id\"=$6,\"phase\"=$7,\"closure\"=$8,` +\n\t\t`\"spec\"=$9,\"started_at\"=$10,\"execution_created_at\"=$11,\"execution_updated_at\"=$12,\"duration\"=$13 WHERE \"` +\n\t\t`execution_project\" = $14 AND \"execution_domain\" = $15 AND \"execution_name\" = $16`).WithCallback(\n\t\tfunc(s string, values []driver.NamedValue) {\n\t\t\tupdated = true\n\t\t},\n\t)\n\n\texecutionRepo := NewExecutionRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\t//\t`WHERE \"executions\".\"deleted_at\" IS NULL`)\n\terr := executionRepo.Update(context.Background(),\n\t\tmodels.Execution{\n\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\tProject: \"project\",\n\t\t\t\tDomain:  \"domain\",\n\t\t\t\tName:    \"1\",\n\t\t\t},\n\t\t\tLaunchPlanID:       uint(2),\n\t\t\tWorkflowID:         uint(3),\n\t\t\tPhase:              core.WorkflowExecution_SUCCEEDED.String(),\n\t\t\tClosure:            []byte{1, 2},\n\t\t\tSpec:               []byte{3, 4},\n\t\t\tStartedAt:          &executionStartedAt,\n\t\t\tExecutionCreatedAt: &createdAt,\n\t\t\tExecutionUpdatedAt: &executionUpdatedAt,\n\t\t\tDuration:           time.Hour,\n\t\t})\n\tassert.NoError(t, err)\n\tassert.True(t, updated)\n}\n\nfunc getMockExecutionResponseFromDb(expected models.Execution) map[string]interface{} {\n\texecution := make(map[string]interface{})\n\texecution[\"id\"] = expected.ID\n\texecution[\"execution_project\"] = expected.Project\n\texecution[\"execution_domain\"] = expected.Domain\n\texecution[\"execution_name\"] = expected.Name\n\texecution[\"launch_plan_id\"] = expected.LaunchPlanID\n\texecution[\"workflow_id\"] = expected.WorkflowID\n\texecution[\"phase\"] = expected.Phase\n\texecution[\"closure\"] = expected.Closure\n\texecution[\"spec\"] = expected.Spec\n\texecution[\"started_at\"] = expected.StartedAt\n\texecution[\"execution_created_at\"] = expected.ExecutionCreatedAt\n\texecution[\"execution_updated_at\"] = expected.ExecutionUpdatedAt\n\texecution[\"duration\"] = expected.Duration\n\texecution[\"mode\"] = expected.Mode\n\texecution[\"launch_entity\"] = expected.LaunchEntity\n\treturn execution\n}\n\nfunc TestGetExecution(t *testing.T) {\n\texecutionRepo := NewExecutionRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\texpectedExecution := models.Execution{\n\t\tBaseModel: models.BaseModel{\n\t\t\tID: uint(20),\n\t\t},\n\t\tExecutionKey: models.ExecutionKey{\n\t\t\tProject: \"project\",\n\t\t\tDomain:  \"domain\",\n\t\t\tName:    \"1\",\n\t\t},\n\t\tLaunchPlanID:       uint(2),\n\t\tPhase:              core.WorkflowExecution_SUCCEEDED.String(),\n\t\tClosure:            []byte{1, 2},\n\t\tWorkflowID:         uint(3),\n\t\tSpec:               []byte{3, 4},\n\t\tStartedAt:          &executionStartedAt,\n\t\tExecutionCreatedAt: &createdAt,\n\t\tExecutionUpdatedAt: &executionUpdatedAt,\n\t\tLaunchEntity:       \"task\",\n\t}\n\n\texecutions := make([]map[string]interface{}, 0)\n\texecution := getMockExecutionResponseFromDb(expectedExecution)\n\texecutions = append(executions, execution)\n\n\tGlobalMock := mocket.Catcher.Reset()\n\tGlobalMock.Logging = true\n\n\t// Only match on queries that append expected filters\n\tGlobalMock.NewMock().WithQuery(`SELECT * FROM \"executions\" WHERE \"executions\".\"execution_project\" = $1 AND \"executions\".\"execution_domain\" = $2 AND \"executions\".\"execution_name\" = $3 LIMIT 1`).WithReply(executions)\n\n\toutput, err := executionRepo.Get(context.Background(), interfaces.Identifier{\n\t\tProject: \"project\",\n\t\tDomain:  \"domain\",\n\t\tName:    \"1\",\n\t})\n\tassert.NoError(t, err)\n\tassert.EqualValues(t, expectedExecution, output)\n}\n\nfunc TestListExecutions(t *testing.T) {\n\texecutionRepo := NewExecutionRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\n\texecutions := make([]map[string]interface{}, 0)\n\tnames := []string{\"ABC\", \"XYZ\"}\n\tfor _, name := range names {\n\t\texecution := getMockExecutionResponseFromDb(models.Execution{\n\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\tProject: \"project\",\n\t\t\t\tDomain:  \"domain\",\n\t\t\t\tName:    name,\n\t\t\t},\n\t\t\tLaunchPlanID: uint(2),\n\t\t\tWorkflowID:   uint(3),\n\t\t\tPhase:        core.WorkflowExecution_SUCCEEDED.String(),\n\t\t\tClosure:      []byte{1, 2},\n\t\t\tSpec:         []byte{3, 4},\n\t\t\tStartedAt:    &executionStartedAt,\n\t\t\tDuration:     time.Hour,\n\t\t})\n\t\texecutions = append(executions, execution)\n\t}\n\n\tGlobalMock := mocket.Catcher.Reset()\n\tGlobalMock.NewMock().WithReply(executions)\n\n\tcollection, err := executionRepo.List(context.Background(), interfaces.ListResourceInput{\n\t\tInlineFilters: []common.InlineFilter{\n\t\t\tgetEqualityFilter(common.Task, \"project\", project),\n\t\t\tgetEqualityFilter(common.Task, \"domain\", domain),\n\t\t\tgetEqualityFilter(common.Task, \"name\", name),\n\t\t},\n\t\tLimit: 20,\n\t})\n\tassert.NoError(t, err)\n\tassert.NotEmpty(t, collection)\n\tassert.NotEmpty(t, collection.Executions)\n\tassert.Len(t, collection.Executions, 2)\n\tfor _, execution := range collection.Executions {\n\t\tassert.Equal(t, project, execution.Project)\n\t\tassert.Equal(t, domain, execution.Domain)\n\t\tassert.Contains(t, names, execution.Name)\n\t\tassert.Equal(t, uint(2), execution.LaunchPlanID)\n\t\tassert.Equal(t, uint(3), execution.WorkflowID)\n\t\tassert.Equal(t, core.WorkflowExecution_SUCCEEDED.String(), execution.Phase)\n\t\tassert.Equal(t, []byte{1, 2}, execution.Closure)\n\t\tassert.Equal(t, []byte{3, 4}, execution.Spec)\n\t\tassert.Equal(t, executionStartedAt, *execution.StartedAt)\n\t\tassert.Equal(t, time.Hour, execution.Duration)\n\t}\n}\n\nfunc TestListExecutions_Filters(t *testing.T) {\n\texecutionRepo := NewExecutionRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\n\texecutions := make([]map[string]interface{}, 0)\n\texecution := getMockExecutionResponseFromDb(models.Execution{\n\t\tExecutionKey: models.ExecutionKey{\n\t\t\tProject: \"project\",\n\t\t\tDomain:  \"domain\",\n\t\t\tName:    \"1\",\n\t\t},\n\t\tLaunchPlanID: uint(2),\n\t\tWorkflowID:   uint(3),\n\t\tPhase:        core.WorkflowExecution_SUCCEEDED.String(),\n\t\tClosure:      []byte{1, 2},\n\t\tSpec:         []byte{3, 4},\n\t\tStartedAt:    &executionStartedAt,\n\t\tDuration:     time.Hour,\n\t})\n\texecutions = append(executions, execution)\n\n\tGlobalMock := mocket.Catcher.Reset()\n\t// Only match on queries that append the name filter\n\tGlobalMock.NewMock().WithQuery(`SELECT * FROM \"executions\" WHERE executions.execution_project = $1 AND executions.execution_domain = $2 AND executions.execution_name = $3 AND executions.workflow_id = $4 LIMIT 20`).WithReply(executions[0:1])\n\n\tcollection, err := executionRepo.List(context.Background(), interfaces.ListResourceInput{\n\t\tInlineFilters: []common.InlineFilter{\n\t\t\tgetEqualityFilter(common.Execution, \"project\", project),\n\t\t\tgetEqualityFilter(common.Execution, \"domain\", domain),\n\t\t\tgetEqualityFilter(common.Execution, \"name\", \"1\"),\n\t\t\tgetEqualityFilter(common.Execution, \"workflow_id\", workflowID),\n\t\t},\n\t\tLimit: 20,\n\t})\n\tassert.NoError(t, err)\n\tassert.NotEmpty(t, collection)\n\tassert.NotEmpty(t, collection.Executions)\n\tassert.Len(t, collection.Executions, 1)\n\n\tresult := collection.Executions[0]\n\tassert.Equal(t, project, result.Project)\n\tassert.Equal(t, domain, result.Domain)\n\tassert.Equal(t, \"1\", result.Name)\n\tassert.Equal(t, uint(2), result.LaunchPlanID)\n\tassert.Equal(t, uint(3), result.WorkflowID)\n\tassert.Equal(t, core.WorkflowExecution_SUCCEEDED.String(), result.Phase)\n\tassert.Equal(t, []byte{1, 2}, result.Closure)\n\tassert.Equal(t, []byte{3, 4}, result.Spec)\n\tassert.Equal(t, executionStartedAt, *result.StartedAt)\n\tassert.Equal(t, time.Hour, result.Duration)\n}\n\nfunc TestListExecutions_Order(t *testing.T) {\n\texecutionRepo := NewExecutionRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\n\texecutions := make([]map[string]interface{}, 0)\n\tGlobalMock := mocket.Catcher.Reset()\n\t// Only match on queries that include ordering by name\n\tmockQuery := GlobalMock.NewMock().WithQuery(`name asc`)\n\tmockQuery.WithReply(executions)\n\n\tsortParameter, _ := common.NewSortParameter(admin.Sort{\n\t\tDirection: admin.Sort_ASCENDING,\n\t\tKey:       \"name\",\n\t})\n\t_, err := executionRepo.List(context.Background(), interfaces.ListResourceInput{\n\t\tSortParameter: sortParameter,\n\t\tInlineFilters: []common.InlineFilter{\n\t\t\tgetEqualityFilter(common.Task, \"project\", project),\n\t\t\tgetEqualityFilter(common.Task, \"domain\", domain),\n\t\t\tgetEqualityFilter(common.Task, \"name\", name),\n\t\t},\n\t\tLimit: 20,\n\t})\n\tassert.NoError(t, err)\n\tassert.True(t, mockQuery.Triggered)\n}\n\nfunc TestListExecutions_WithTags(t *testing.T) {\n\texecutionRepo := NewExecutionRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\n\texecutions := make([]map[string]interface{}, 0)\n\tGlobalMock := mocket.Catcher.Reset()\n\t// Only match on queries that include ordering by name\n\tmockQuery := GlobalMock.NewMock().WithQuery(`name asc`)\n\tmockQuery.WithReply(executions)\n\n\tsortParameter, _ := common.NewSortParameter(admin.Sort{\n\t\tDirection: admin.Sort_ASCENDING,\n\t\tKey:       \"name\",\n\t})\n\tvals := []string{\"tag1\", \"tag2\"}\n\ttagFilter, err := common.NewRepeatedValueFilter(common.ExecutionAdminTag, common.ValueIn, \"admin_tag_name\", vals)\n\tassert.NoError(t, err)\n\t_, err = executionRepo.List(context.Background(), interfaces.ListResourceInput{\n\t\tSortParameter: sortParameter,\n\t\tInlineFilters: []common.InlineFilter{\n\t\t\tgetEqualityFilter(common.Task, \"project\", project),\n\t\t\tgetEqualityFilter(common.Task, \"domain\", domain),\n\t\t\tgetEqualityFilter(common.Task, \"name\", name),\n\t\t\ttagFilter,\n\t\t},\n\t\tLimit: 20,\n\t})\n\tassert.NoError(t, err)\n\tassert.True(t, mockQuery.Triggered)\n}\n\nfunc TestListExecutions_MissingParameters(t *testing.T) {\n\texecutionRepo := NewExecutionRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\t_, err := executionRepo.List(context.Background(), interfaces.ListResourceInput{\n\t\tInlineFilters: []common.InlineFilter{\n\t\t\tgetEqualityFilter(common.Execution, \"project\", project),\n\t\t\tgetEqualityFilter(common.Execution, \"domain\", domain),\n\t\t\tgetEqualityFilter(common.Execution, \"name\", name),\n\t\t\tgetEqualityFilter(common.Execution, \"workflow_id\", workflowID),\n\t\t},\n\t})\n\tassert.EqualError(t, err, \"missing and/or invalid parameters: limit\")\n\n\t_, err = executionRepo.List(context.Background(), interfaces.ListResourceInput{\n\t\tLimit: 20,\n\t})\n\tassert.EqualError(t, err, \"missing and/or invalid parameters: filters\")\n}\n\nfunc TestListExecutionsForWorkflow(t *testing.T) {\n\texecutionRepo := NewExecutionRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\n\texecutions := make([]map[string]interface{}, 0)\n\texecution := getMockExecutionResponseFromDb(models.Execution{\n\t\tExecutionKey: models.ExecutionKey{\n\t\t\tProject: \"project\",\n\t\t\tDomain:  \"domain\",\n\t\t\tName:    \"1\",\n\t\t},\n\t\tLaunchPlanID: uint(2),\n\t\tWorkflowID:   uint(3),\n\t\tPhase:        core.WorkflowExecution_SUCCEEDED.String(),\n\t\tClosure:      []byte{1, 2},\n\t\tSpec:         []byte{3, 4},\n\t\tStartedAt:    &executionStartedAt,\n\t\tDuration:     time.Hour,\n\t\tLaunchEntity: \"launch_plan\",\n\t\tTags:         []models.AdminTag{{Name: \"tag1\"}, {Name: \"tag2\"}},\n\t})\n\texecutions = append(executions, execution)\n\n\tGlobalMock := mocket.Catcher.Reset()\n\tGlobalMock.Logging = true\n\t// Only match on queries that append expected filters\n\tGlobalMock.NewMock().WithQuery(`SELECT \"executions\".\"id\",\"executions\".\"created_at\",\"executions\".\"updated_at\",\"executions\".\"deleted_at\",\"executions\".\"execution_project\",\"executions\".\"execution_domain\",\"executions\".\"execution_name\",\"executions\".\"launch_plan_id\",\"executions\".\"workflow_id\",\"executions\".\"task_id\",\"executions\".\"phase\",\"executions\".\"closure\",\"executions\".\"spec\",\"executions\".\"started_at\",\"executions\".\"execution_created_at\",\"executions\".\"execution_updated_at\",\"executions\".\"duration\",\"executions\".\"abort_cause\",\"executions\".\"mode\",\"executions\".\"source_execution_id\",\"executions\".\"parent_node_execution_id\",\"executions\".\"cluster\",\"executions\".\"inputs_uri\",\"executions\".\"user_inputs_uri\",\"executions\".\"error_kind\",\"executions\".\"error_code\",\"executions\".\"user\",\"executions\".\"state\",\"executions\".\"launch_entity\" FROM \"executions\" INNER JOIN workflows ON executions.workflow_id = workflows.id INNER JOIN tasks ON executions.task_id = tasks.id WHERE executions.execution_project = $1 AND executions.execution_domain = $2 AND executions.execution_name = $3 AND workflows.name = $4 AND tasks.name = $5 AND execution_admin_tags.execution_tag_name in ($6,$7) LIMIT 20`).WithReply(executions)\n\tvals := []string{\"tag1\", \"tag2\"}\n\ttagFilter, err := common.NewRepeatedValueFilter(common.ExecutionAdminTag, common.ValueIn, \"execution_tag_name\", vals)\n\tassert.NoError(t, err)\n\tcollection, err := executionRepo.List(context.Background(), interfaces.ListResourceInput{\n\t\tInlineFilters: []common.InlineFilter{\n\t\t\tgetEqualityFilter(common.Execution, \"project\", project),\n\t\t\tgetEqualityFilter(common.Execution, \"domain\", domain),\n\t\t\tgetEqualityFilter(common.Execution, \"name\", \"1\"),\n\t\t\tgetEqualityFilter(common.Workflow, \"name\", \"workflow_name\"),\n\t\t\tgetEqualityFilter(common.Task, \"name\", \"task_name\"),\n\t\t\ttagFilter,\n\t\t},\n\t\tLimit: 20,\n\t\tJoinTableEntities: map[common.Entity]bool{\n\t\t\tcommon.Workflow: true,\n\t\t\tcommon.Task:     true,\n\t\t},\n\t})\n\n\tassert.NoError(t, err)\n\tassert.NotEmpty(t, collection)\n\tassert.NotEmpty(t, collection.Executions)\n\tassert.Len(t, collection.Executions, 1)\n\tfor _, execution := range collection.Executions {\n\t\tassert.Equal(t, project, execution.Project)\n\t\tassert.Equal(t, domain, execution.Domain)\n\t\tassert.Equal(t, \"1\", execution.Name)\n\t\tassert.Equal(t, uint(2), execution.LaunchPlanID)\n\t\tassert.Equal(t, uint(3), execution.WorkflowID)\n\t\tassert.Equal(t, core.WorkflowExecution_SUCCEEDED.String(), execution.Phase)\n\t\tassert.Equal(t, []byte{1, 2}, execution.Closure)\n\t\tassert.Equal(t, []byte{3, 4}, execution.Spec)\n\t\tassert.Equal(t, executionStartedAt, *execution.StartedAt)\n\t\tassert.Equal(t, time.Hour, execution.Duration)\n\t\tassert.Equal(t, \"launch_plan\", execution.LaunchEntity)\n\t}\n}\n\nfunc TestCountExecutions(t *testing.T) {\n\texecutionRepo := NewExecutionRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\n\tGlobalMock := mocket.Catcher.Reset()\n\tGlobalMock.NewMock().WithQuery(\n\t\t`SELECT count(*) FROM \"executions\"`).WithReply([]map[string]interface{}{{\"rows\": 2}})\n\n\tcount, err := executionRepo.Count(context.Background(), interfaces.CountResourceInput{})\n\tassert.NoError(t, err)\n\tassert.Equal(t, int64(2), count)\n}\n\nfunc TestCountExecutions_Filters(t *testing.T) {\n\texecutionRepo := NewExecutionRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\n\tGlobalMock := mocket.Catcher.Reset()\n\tGlobalMock.NewMock().WithQuery(\n\t\t`SELECT count(*) FROM \"executions\" INNER JOIN workflows ON executions.workflow_id = workflows.id INNER JOIN tasks ON executions.task_id = tasks.id WHERE executions.phase = $1 AND \"error_code\" IS NULL`,\n\t).WithReply([]map[string]interface{}{{\"rows\": 3}})\n\n\tcount, err := executionRepo.Count(context.Background(), interfaces.CountResourceInput{\n\t\tInlineFilters: []common.InlineFilter{\n\t\t\tgetEqualityFilter(common.Execution, \"phase\", core.WorkflowExecution_FAILED.String()),\n\t\t},\n\t\tMapFilters: []common.MapFilter{\n\t\t\tcommon.NewMapFilter(map[string]interface{}{\n\t\t\t\t\"error_code\": nil,\n\t\t\t}),\n\t\t},\n\t\tJoinTableEntities: map[common.Entity]bool{\n\t\t\tcommon.Workflow: true,\n\t\t\tcommon.Task:     true,\n\t\t},\n\t})\n\tassert.NoError(t, err)\n\tassert.Equal(t, int64(3), count)\n}\n", "package gormimpl\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"time\"\n\n\t\"github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/core\"\n\t\"github.com/flyteorg/flytestdlib/promutils\"\n\n\tadminErrors \"github.com/flyteorg/flyteadmin/pkg/repositories/errors\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/interfaces\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/models\"\n\t\"github.com/flyteorg/flytestdlib/logger\"\n\t\"gorm.io/gorm\"\n)\n\nconst launchPlanTableName = \"launch_plans\"\n\ntype launchPlanMetrics struct {\n\tSetActiveDuration promutils.StopWatch\n}\n\n// Implementation of LaunchPlanRepoInterface.\ntype LaunchPlanRepo struct {\n\tdb                *gorm.DB\n\terrorTransformer  adminErrors.ErrorTransformer\n\tmetrics           gormMetrics\n\tlaunchPlanMetrics launchPlanMetrics\n}\n\nfunc (r *LaunchPlanRepo) Create(ctx context.Context, input models.LaunchPlan) error {\n\ttimer := r.metrics.CreateDuration.Start()\n\ttx := r.db.Omit(\"id\").Create(&input)\n\ttimer.Stop()\n\tif tx.Error != nil {\n\t\treturn r.errorTransformer.ToFlyteAdminError(tx.Error)\n\t}\n\treturn nil\n}\n\nfunc (r *LaunchPlanRepo) Update(ctx context.Context, input models.LaunchPlan) error {\n\ttimer := r.metrics.UpdateDuration.Start()\n\ttx := r.db.Model(&input).Updates(input)\n\ttimer.Stop()\n\tif err := tx.Error; err != nil {\n\t\treturn r.errorTransformer.ToFlyteAdminError(err)\n\t}\n\treturn nil\n}\n\nfunc (r *LaunchPlanRepo) Get(ctx context.Context, input interfaces.Identifier) (models.LaunchPlan, error) {\n\tvar launchPlan models.LaunchPlan\n\ttimer := r.metrics.GetDuration.Start()\n\ttx := r.db.Where(&models.LaunchPlan{\n\t\tLaunchPlanKey: models.LaunchPlanKey{\n\t\t\tProject: input.Project,\n\t\t\tDomain:  input.Domain,\n\t\t\tName:    input.Name,\n\t\t\tVersion: input.Version,\n\t\t},\n\t}).Take(&launchPlan)\n\ttimer.Stop()\n\n\tif tx.Error != nil && errors.Is(tx.Error, gorm.ErrRecordNotFound) {\n\t\treturn models.LaunchPlan{},\n\t\t\tadminErrors.GetMissingEntityError(core.ResourceType_LAUNCH_PLAN.String(), &core.Identifier{\n\t\t\t\tProject: input.Project,\n\t\t\t\tDomain:  input.Domain,\n\t\t\t\tName:    input.Name,\n\t\t\t\tVersion: input.Version,\n\t\t\t})\n\t} else if tx.Error != nil {\n\t\treturn models.LaunchPlan{}, r.errorTransformer.ToFlyteAdminError(tx.Error)\n\t}\n\treturn launchPlan, nil\n}\n\n// This operation is performed as a two-step transaction because only one launch plan version can be active at a time.\n// Transactional semantics are used to guarantee that setting the desired launch plan to active also disables\n// the existing launch plan version (if any).\nfunc (r *LaunchPlanRepo) SetActive(\n\tctx context.Context, toEnable models.LaunchPlan, toDisable *models.LaunchPlan) error {\n\ttimer := r.launchPlanMetrics.SetActiveDuration.Start()\n\tdefer timer.Stop()\n\t// Use a transaction to guarantee no partial updates.\n\ttx := r.db.Begin()\n\n\t// There is a launch plan to disable as part of this transaction\n\tif toDisable != nil {\n\t\ttx.Model(&toDisable).UpdateColumns(toDisable)\n\t\tif err := tx.Error; err != nil {\n\t\t\ttx.Rollback()\n\t\t\treturn r.errorTransformer.ToFlyteAdminError(err)\n\t\t}\n\t}\n\n\t// And update the desired version.\n\ttx.Model(&toEnable).UpdateColumns(toEnable)\n\tif err := tx.Error; err != nil {\n\t\ttx.Rollback()\n\t\treturn r.errorTransformer.ToFlyteAdminError(err)\n\t}\n\tif err := tx.Commit().Error; err != nil {\n\t\treturn r.errorTransformer.ToFlyteAdminError(err)\n\t}\n\treturn nil\n}\n\nfunc (r *LaunchPlanRepo) List(ctx context.Context, input interfaces.ListResourceInput) (\n\tinterfaces.LaunchPlanCollectionOutput, error) {\n\t// First validate input.\n\tif err := ValidateListInput(input); err != nil {\n\t\treturn interfaces.LaunchPlanCollectionOutput{}, err\n\t}\n\tvar launchPlans []models.LaunchPlan\n\ttx := r.db.Limit(input.Limit).Offset(input.Offset)\n\n\t// Add join conditions\n\ttx = tx.Joins(\"inner join workflows on launch_plans.workflow_id = workflows.id\")\n\n\t// Apply filters\n\ttx, err := applyScopedFilters(tx, input.InlineFilters, input.MapFilters)\n\tif err != nil {\n\t\treturn interfaces.LaunchPlanCollectionOutput{}, err\n\t}\n\t// Apply sort ordering.\n\tif input.SortParameter != nil {\n\t\ttx = tx.Order(input.SortParameter.GetGormOrderExpr())\n\t}\n\n\ttimer := r.metrics.ListDuration.Start()\n\ttx.Find(&launchPlans)\n\ttimer.Stop()\n\tif tx.Error != nil {\n\t\tlogger.Warningf(ctx,\n\t\t\t\"Failed to list launch plans by workflow with input [%+v] with err: %+v\", input, tx.Error)\n\t\treturn interfaces.LaunchPlanCollectionOutput{}, r.errorTransformer.ToFlyteAdminError(tx.Error)\n\t}\n\n\treturn interfaces.LaunchPlanCollectionOutput{\n\t\tLaunchPlans: launchPlans,\n\t}, nil\n}\n\nfunc (r *LaunchPlanRepo) ListLaunchPlanIdentifiers(ctx context.Context, input interfaces.ListResourceInput) (\n\tinterfaces.LaunchPlanCollectionOutput, error) {\n\n\t// Validate input, input must have a limit\n\tif err := ValidateListInput(input); err != nil {\n\t\treturn interfaces.LaunchPlanCollectionOutput{}, err\n\t}\n\n\ttx := r.db.Model(models.LaunchPlan{}).Limit(input.Limit).Offset(input.Offset)\n\n\t// Apply filters\n\ttx, err := applyFilters(tx, input.InlineFilters, input.MapFilters)\n\tif err != nil {\n\t\treturn interfaces.LaunchPlanCollectionOutput{}, err\n\t}\n\t// Apply sort ordering.\n\tif input.SortParameter != nil {\n\t\ttx = tx.Order(input.SortParameter.GetGormOrderExpr())\n\t}\n\n\t// Scan the results into a list of launch plans\n\tvar launchPlans []models.LaunchPlan\n\ttimer := r.metrics.ListIdentifiersDuration.Start()\n\ttx.Select([]string{Project, Domain, Name}).Group(identifierGroupBy).Scan(&launchPlans)\n\ttimer.Stop()\n\tif tx.Error != nil {\n\t\treturn interfaces.LaunchPlanCollectionOutput{}, r.errorTransformer.ToFlyteAdminError(tx.Error)\n\t}\n\n\treturn interfaces.LaunchPlanCollectionOutput{\n\t\tLaunchPlans: launchPlans,\n\t}, nil\n\n}\n\n// Returns an instance of LaunchPlanRepoInterface\nfunc NewLaunchPlanRepo(\n\tdb *gorm.DB, errorTransformer adminErrors.ErrorTransformer, scope promutils.Scope) interfaces.LaunchPlanRepoInterface {\n\tmetrics := newMetrics(scope)\n\tlaunchPlanMetrics := launchPlanMetrics{\n\t\tSetActiveDuration: scope.MustNewStopWatch(\n\t\t\t\"set_active\",\n\t\t\t\"time taken to set a launch plan to active (and disable the currently active version)\", time.Millisecond),\n\t}\n\n\treturn &LaunchPlanRepo{\n\t\tdb:                db,\n\t\terrorTransformer:  errorTransformer,\n\t\tmetrics:           metrics,\n\t\tlaunchPlanMetrics: launchPlanMetrics,\n\t}\n}\n", "package gormimpl\n\nimport (\n\t\"context\"\n\t\"database/sql/driver\"\n\t\"testing\"\n\n\tmockScope \"github.com/flyteorg/flytestdlib/promutils\"\n\n\tmocket \"github.com/Selvatico/go-mocket\"\n\t\"github.com/flyteorg/flyteadmin/pkg/common\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/errors\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/interfaces\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/models\"\n\t\"github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/admin\"\n\t\"github.com/stretchr/testify/assert\"\n)\n\nconst workflowID = uint(1)\n\nvar launchPlanSpec = []byte{1, 2}\nvar launchPlanClosure = []byte{3, 4}\nvar inactive = int32(admin.LaunchPlanState_INACTIVE)\nvar active = int32(admin.LaunchPlanState_ACTIVE)\n\nfunc TestCreateLaunchPlan(t *testing.T) {\n\tlaunchPlanRepo := NewLaunchPlanRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\terr := launchPlanRepo.Create(context.Background(), models.LaunchPlan{\n\t\tLaunchPlanKey: models.LaunchPlanKey{\n\t\t\tProject: project,\n\t\t\tDomain:  domain,\n\t\t\tName:    name,\n\t\t\tVersion: version,\n\t\t},\n\t\tSpec:       launchPlanSpec,\n\t\tWorkflowID: workflowID,\n\t\tClosure:    launchPlanClosure,\n\t\tState:      &inactive,\n\t})\n\tassert.NoError(t, err)\n}\n\nfunc getMockLaunchPlanResponseFromDb(expected models.LaunchPlan) map[string]interface{} {\n\tlaunchPlan := make(map[string]interface{})\n\tlaunchPlan[\"project\"] = expected.Project\n\tlaunchPlan[\"domain\"] = expected.Domain\n\tlaunchPlan[\"name\"] = expected.Name\n\tlaunchPlan[\"version\"] = expected.Version\n\tlaunchPlan[\"spec\"] = expected.Spec\n\tlaunchPlan[\"workflow_id\"] = expected.WorkflowID\n\tlaunchPlan[\"closure\"] = expected.Closure\n\tlaunchPlan[\"state\"] = expected.State\n\treturn launchPlan\n}\n\nfunc TestGetLaunchPlan(t *testing.T) {\n\tlaunchPlanRepo := NewLaunchPlanRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\n\tlaunchPlans := make([]map[string]interface{}, 0)\n\tlaunchPlan := getMockLaunchPlanResponseFromDb(models.LaunchPlan{\n\t\tLaunchPlanKey: models.LaunchPlanKey{\n\t\t\tProject: project,\n\t\t\tDomain:  domain,\n\t\t\tName:    name,\n\t\t\tVersion: version,\n\t\t},\n\t\tSpec:       launchPlanSpec,\n\t\tWorkflowID: workflowID,\n\t\tClosure:    launchPlanClosure,\n\t\tState:      &inactive,\n\t})\n\tlaunchPlans = append(launchPlans, launchPlan)\n\n\tGlobalMock := mocket.Catcher.Reset()\n\tGlobalMock.Logging = true\n\t// Only match on queries that append expected filters\n\tGlobalMock.NewMock().WithQuery(\n\t\t`SELECT * FROM \"launch_plans\" WHERE \"launch_plans\".\"project\" = $1 AND \"launch_plans\".\"domain\" = $2 AND \"launch_plans\".\"name\" = $3 AND \"launch_plans\".\"version\" = $4 LIMIT 1`).WithReply(launchPlans)\n\toutput, err := launchPlanRepo.Get(context.Background(), interfaces.Identifier{\n\t\tProject: project,\n\t\tDomain:  domain,\n\t\tName:    name,\n\t\tVersion: version,\n\t})\n\tassert.NoError(t, err)\n\tassert.Equal(t, project, output.Project)\n\tassert.Equal(t, domain, output.Domain)\n\tassert.Equal(t, name, output.Name)\n\tassert.Equal(t, version, output.Version)\n\tassert.Equal(t, launchPlanSpec, output.Spec)\n}\n\nfunc TestSetInactiveLaunchPlan(t *testing.T) {\n\tlaunchPlanRepo := NewLaunchPlanRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\n\tGlobalMock := mocket.Catcher.Reset()\n\tGlobalMock.Logging = true\n\tmockDb := GlobalMock.NewMock()\n\tupdated := false\n\tmockDb.WithQuery(\n\t\t`UPDATE \"launch_plans\" SET \"id\"=$1,\"updated_at\"=$2,\"project\"=$3,\"domain\"=$4,\"name\"=$5,\"version\"=$6,\"closure\"=$7,\"state\"=$8 WHERE \"project\" = $9 AND \"domain\" = $10 AND \"name\" = $11 AND \"version\" = $12`).WithCallback(\n\t\tfunc(s string, values []driver.NamedValue) {\n\t\t\tupdated = true\n\t\t},\n\t)\n\n\terr := launchPlanRepo.Update(context.Background(), models.LaunchPlan{\n\t\tBaseModel: models.BaseModel{\n\t\t\tID: 1,\n\t\t},\n\t\tLaunchPlanKey: models.LaunchPlanKey{\n\t\t\tProject: project,\n\t\t\tDomain:  domain,\n\t\t\tName:    name,\n\t\t\tVersion: version,\n\t\t},\n\t\tClosure: []byte{5, 6},\n\t\tState:   &inactive,\n\t})\n\tassert.NoError(t, err)\n\tassert.True(t, updated)\n}\n\nfunc TestSetActiveLaunchPlan(t *testing.T) {\n\tlaunchPlanRepo := NewLaunchPlanRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\n\tGlobalMock := mocket.Catcher.Reset()\n\tGlobalMock.Logging = true\n\tmockQuery := GlobalMock.NewMock()\n\tupdated := false\n\tmockQuery.WithQuery(\n\t\t`UPDATE \"launch_plans\" SET \"id\"=$1,\"project\"=$2,\"domain\"=$3,\"name\"=$4,\"version\"=$5,\"closure\"=$6,\"state\"=$7 WHERE \"project\" = $8 AND \"domain\" = $9 AND \"name\" = $10 AND \"version\" = $11`).WithCallback(\n\t\tfunc(s string, values []driver.NamedValue) {\n\t\t\tupdated = true\n\t\t},\n\t)\n\n\terr := launchPlanRepo.SetActive(context.Background(), models.LaunchPlan{\n\t\tBaseModel: models.BaseModel{\n\t\t\tID: 1,\n\t\t},\n\t\tLaunchPlanKey: models.LaunchPlanKey{\n\t\t\tProject: project,\n\t\t\tDomain:  domain,\n\t\t\tName:    name,\n\t\t\tVersion: \"new version\",\n\t\t},\n\t\tClosure: []byte{5, 6},\n\t\tState:   &active,\n\t}, &models.LaunchPlan{\n\t\tBaseModel: models.BaseModel{\n\t\t\tID: 2,\n\t\t},\n\t\tLaunchPlanKey: models.LaunchPlanKey{\n\t\t\tProject: project,\n\t\t\tDomain:  domain,\n\t\t\tName:    name,\n\t\t\tVersion: \"old version\",\n\t\t},\n\t\tClosure: []byte{5, 6},\n\t\tState:   &inactive,\n\t})\n\tassert.NoError(t, err)\n\tassert.True(t, updated)\n}\n\nfunc TestSetActiveLaunchPlan_NoCurrentlyActiveLaunchPlan(t *testing.T) {\n\tlaunchPlanRepo := NewLaunchPlanRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\n\tGlobalMock := mocket.Catcher.Reset()\n\tGlobalMock.Logging = true\n\tmockQuery := GlobalMock.NewMock()\n\tupdated := false\n\tmockQuery.WithQuery(\n\t\t`UPDATE \"launch_plans\" SET \"id\"=$1,\"project\"=$2,\"domain\"=$3,\"name\"=$4,\"version\"=$5,\"closure\"=$6,\"state\"=$7 WHERE \"project\" = $8 AND \"domain\" = $9 AND \"name\" = $10 AND \"version\" = $11`).WithCallback(\n\t\tfunc(s string, values []driver.NamedValue) {\n\t\t\tupdated = true\n\t\t},\n\t)\n\terr := launchPlanRepo.SetActive(context.Background(), models.LaunchPlan{\n\t\tBaseModel: models.BaseModel{\n\t\t\tID: 1,\n\t\t},\n\t\tLaunchPlanKey: models.LaunchPlanKey{\n\t\t\tProject: project,\n\t\t\tDomain:  domain,\n\t\t\tName:    name,\n\t\t\tVersion: \"new version\",\n\t\t},\n\t\tClosure: []byte{5, 6},\n\t\tState:   &active,\n\t}, nil)\n\tassert.NoError(t, err)\n\tassert.True(t, updated)\n}\n\nfunc TestListLaunchPlans(t *testing.T) {\n\tlaunchPlanRepo := NewLaunchPlanRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\n\tlaunchPlans := make([]map[string]interface{}, 0)\n\tversions := []string{\"ABC\", \"XYZ\"}\n\tfor _, version := range versions {\n\t\tlaunchPlan := getMockLaunchPlanResponseFromDb(models.LaunchPlan{\n\t\t\tLaunchPlanKey: models.LaunchPlanKey{\n\t\t\t\tProject: project,\n\t\t\t\tDomain:  domain,\n\t\t\t\tName:    name,\n\t\t\t\tVersion: version,\n\t\t\t},\n\t\t\tSpec:       launchPlanSpec,\n\t\t\tWorkflowID: workflowID,\n\t\t\tClosure:    launchPlanClosure,\n\t\t\tState:      &inactive,\n\t\t})\n\t\tlaunchPlans = append(launchPlans, launchPlan)\n\t}\n\n\tGlobalMock := mocket.Catcher.Reset()\n\tGlobalMock.NewMock().WithReply(launchPlans)\n\n\tcollection, err := launchPlanRepo.List(context.Background(), interfaces.ListResourceInput{\n\t\tInlineFilters: []common.InlineFilter{\n\t\t\tgetEqualityFilter(common.LaunchPlan, \"project\", project),\n\t\t\tgetEqualityFilter(common.LaunchPlan, \"domain\", domain),\n\t\t\tgetEqualityFilter(common.LaunchPlan, \"name\", name),\n\t\t},\n\t\tLimit: 20,\n\t})\n\tassert.NoError(t, err)\n\tassert.NotEmpty(t, collection)\n\tassert.NotEmpty(t, collection.LaunchPlans)\n\tassert.Len(t, collection.LaunchPlans, 2)\n\tfor _, launchPlan := range collection.LaunchPlans {\n\t\tassert.Equal(t, project, launchPlan.Project)\n\t\tassert.Equal(t, domain, launchPlan.Domain)\n\t\tassert.Equal(t, name, launchPlan.Name)\n\t\tassert.Contains(t, versions, launchPlan.Version)\n\t\tassert.Equal(t, launchPlanSpec, launchPlan.Spec)\n\t\tassert.Equal(t, workflowID, launchPlan.WorkflowID)\n\t}\n}\n\nfunc TestListLaunchPlans_Pagination(t *testing.T) {\n\tlaunchPlanRepo := NewLaunchPlanRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\n\tlaunchPlans := make([]map[string]interface{}, 0)\n\tversions := []string{\"ABC\", \"DEF\"}\n\tfor _, version := range versions {\n\t\tlaunchPlan := getMockLaunchPlanResponseFromDb(models.LaunchPlan{\n\t\t\tLaunchPlanKey: models.LaunchPlanKey{\n\t\t\t\tProject: project,\n\t\t\t\tDomain:  domain,\n\t\t\t\tName:    name,\n\t\t\t\tVersion: version,\n\t\t\t},\n\t\t\tSpec:       launchPlanSpec,\n\t\t\tWorkflowID: workflowID,\n\t\t\tClosure:    launchPlanClosure,\n\t\t\tState:      &inactive,\n\t\t})\n\t\tlaunchPlans = append(launchPlans, launchPlan)\n\t}\n\n\tGlobalMock := mocket.Catcher.Reset()\n\n\tGlobalMock.NewMock().WithQuery(\n\t\t`SELECT \"launch_plans\".\"id\",\"launch_plans\".\"created_at\",\"launch_plans\".\"updated_at\",\"launch_plans\".\"deleted_at\",\"launch_plans\".\"project\",\"launch_plans\".\"domain\",\"launch_plans\".\"name\",\"launch_plans\".\"version\",\"launch_plans\".\"spec\",\"launch_plans\".\"workflow_id\",\"launch_plans\".\"closure\",\"launch_plans\".\"state\",\"launch_plans\".\"digest\",\"launch_plans\".\"schedule_type\" FROM \"launch_plans\" inner join workflows on launch_plans.workflow_id = workflows.id WHERE launch_plans.project = $1 AND launch_plans.domain = $2 AND launch_plans.name = $3 LIMIT 2 OFFSET 1`).WithReply(launchPlans)\n\n\tcollection, err := launchPlanRepo.List(context.Background(), interfaces.ListResourceInput{\n\t\tInlineFilters: []common.InlineFilter{\n\t\t\tgetEqualityFilter(common.LaunchPlan, \"project\", project),\n\t\t\tgetEqualityFilter(common.LaunchPlan, \"domain\", domain),\n\t\t\tgetEqualityFilter(common.LaunchPlan, \"name\", name),\n\t\t},\n\t\tLimit:  2,\n\t\tOffset: 1,\n\t})\n\tassert.NoError(t, err)\n\tassert.NotEmpty(t, collection)\n\tassert.NotEmpty(t, collection.LaunchPlans)\n\tassert.Len(t, collection.LaunchPlans, 2)\n\tfor idx, launchPlan := range collection.LaunchPlans {\n\t\tassert.Equal(t, project, launchPlan.Project)\n\t\tassert.Equal(t, domain, launchPlan.Domain)\n\t\tassert.Equal(t, name, launchPlan.Name)\n\t\tassert.Equal(t, versions[idx], launchPlan.Version)\n\t\tassert.Equal(t, launchPlanSpec, launchPlan.Spec)\n\t\tassert.Equal(t, workflowID, launchPlan.WorkflowID)\n\t\tassert.Equal(t, launchPlanClosure, launchPlan.Closure)\n\t}\n}\n\nfunc TestListLaunchPlans_Filters(t *testing.T) {\n\tlaunchPlanRepo := NewLaunchPlanRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\n\tlaunchPlans := make([]map[string]interface{}, 0)\n\tlaunchPlan := getMockLaunchPlanResponseFromDb(models.LaunchPlan{\n\t\tLaunchPlanKey: models.LaunchPlanKey{\n\t\t\tProject: project,\n\t\t\tDomain:  domain,\n\t\t\tName:    name,\n\t\t\tVersion: \"ABC\",\n\t\t},\n\t\tSpec:       launchPlanSpec,\n\t\tWorkflowID: workflowID,\n\t\tClosure:    launchPlanClosure,\n\t\tState:      &inactive,\n\t})\n\tlaunchPlans = append(launchPlans, launchPlan)\n\n\tGlobalMock := mocket.Catcher.Reset()\n\tGlobalMock.Logging = true\n\t// Only match on queries that append the name filter\n\tGlobalMock.NewMock().WithQuery(`SELECT \"launch_plans\".\"id\",\"launch_plans\".\"created_at\",\"launch_plans\".\"updated_at\",\"launch_plans\".\"deleted_at\",\"launch_plans\".\"project\",\"launch_plans\".\"domain\",\"launch_plans\".\"name\",\"launch_plans\".\"version\",\"launch_plans\".\"spec\",\"launch_plans\".\"workflow_id\",\"launch_plans\".\"closure\",\"launch_plans\".\"state\",\"launch_plans\".\"digest\",\"launch_plans\".\"schedule_type\" FROM \"launch_plans\" inner join workflows on launch_plans.workflow_id = workflows.id WHERE launch_plans.project = $1 AND launch_plans.domain = $2 AND launch_plans.name = $3 AND launch_plans.version = $4 LIMIT 20`).WithReply(launchPlans[0:1])\n\n\tcollection, err := launchPlanRepo.List(context.Background(), interfaces.ListResourceInput{\n\t\tInlineFilters: []common.InlineFilter{\n\t\t\tgetEqualityFilter(common.LaunchPlan, \"project\", project),\n\t\t\tgetEqualityFilter(common.LaunchPlan, \"domain\", domain),\n\t\t\tgetEqualityFilter(common.LaunchPlan, \"name\", name),\n\t\t\tgetEqualityFilter(common.LaunchPlan, \"version\", \"ABC\"),\n\t\t},\n\t\tLimit: 20,\n\t})\n\tassert.NoError(t, err)\n\tassert.NotEmpty(t, collection)\n\tassert.NotEmpty(t, collection.LaunchPlans)\n\tassert.Len(t, collection.LaunchPlans, 1)\n\tassert.Equal(t, project, collection.LaunchPlans[0].Project)\n\tassert.Equal(t, domain, collection.LaunchPlans[0].Domain)\n\tassert.Equal(t, name, collection.LaunchPlans[0].Name)\n\tassert.Equal(t, \"ABC\", collection.LaunchPlans[0].Version)\n\tassert.Equal(t, launchPlanSpec, collection.LaunchPlans[0].Spec)\n\tassert.Equal(t, workflowID, collection.LaunchPlans[0].WorkflowID)\n\tassert.Equal(t, launchPlanClosure, collection.LaunchPlans[0].Closure)\n}\n\nfunc TestListLaunchPlans_Order(t *testing.T) {\n\tlaunchPlanRepo := NewLaunchPlanRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\tlaunchPlans := make([]map[string]interface{}, 0)\n\n\tGlobalMock := mocket.Catcher.Reset()\n\t// Only match on queries that include ordering by project\n\tmockQuery := GlobalMock.NewMock()\n\tmockQuery.WithQuery(`project desc`)\n\tmockQuery.WithReply(launchPlans)\n\n\tsortParameter, _ := common.NewSortParameter(admin.Sort{\n\t\tDirection: admin.Sort_DESCENDING,\n\t\tKey:       \"project\",\n\t})\n\t_, err := launchPlanRepo.List(context.Background(), interfaces.ListResourceInput{\n\t\tSortParameter: sortParameter,\n\t\tInlineFilters: []common.InlineFilter{\n\t\t\tgetEqualityFilter(common.LaunchPlan, \"project\", project),\n\t\t\tgetEqualityFilter(common.LaunchPlan, \"domain\", domain),\n\t\t\tgetEqualityFilter(common.LaunchPlan, \"name\", name),\n\t\t\tgetEqualityFilter(common.LaunchPlan, \"version\", version),\n\t\t},\n\t\tLimit: 20,\n\t})\n\tassert.NoError(t, err)\n\tassert.True(t, mockQuery.Triggered)\n}\n\nfunc TestListLaunchPlans_MissingParameters(t *testing.T) {\n\tlaunchPlanRepo := NewLaunchPlanRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\t_, err := launchPlanRepo.List(context.Background(), interfaces.ListResourceInput{\n\t\tInlineFilters: []common.InlineFilter{\n\t\t\tgetEqualityFilter(common.LaunchPlan, \"project\", project),\n\t\t\tgetEqualityFilter(common.LaunchPlan, \"domain\", domain),\n\t\t\tgetEqualityFilter(common.LaunchPlan, \"name\", name),\n\t\t\tgetEqualityFilter(common.LaunchPlan, \"version\", version),\n\t\t},\n\t})\n\tassert.EqualError(t, err, \"missing and/or invalid parameters: limit\")\n\n\t_, err = launchPlanRepo.List(context.Background(), interfaces.ListResourceInput{\n\t\tLimit: 20,\n\t})\n\tassert.EqualError(t, err, \"missing and/or invalid parameters: filters\")\n}\n\nfunc TestListLaunchPlansForWorkflow(t *testing.T) {\n\tlaunchPlanRepo := NewLaunchPlanRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\n\tlaunchPlans := make([]map[string]interface{}, 0)\n\tlaunchPlan := getMockLaunchPlanResponseFromDb(models.LaunchPlan{\n\t\tLaunchPlanKey: models.LaunchPlanKey{\n\t\t\tProject: project,\n\t\t\tDomain:  domain,\n\t\t\tName:    name,\n\t\t\tVersion: version,\n\t\t},\n\t\tSpec:       launchPlanSpec,\n\t\tWorkflowID: workflowID,\n\t\tClosure:    launchPlanClosure,\n\t\tState:      &inactive,\n\t})\n\tlaunchPlans = append(launchPlans, launchPlan)\n\n\tGlobalMock := mocket.Catcher.Reset()\n\t// HACK: gorm orders the filters on join clauses non-deterministically. Ordering of filters doesn't affect\n\t// correctness, but because the mocket library only pattern matches on substrings, both variations of the (valid)\n\t// SQL that gorm produces are checked below.\n\tquery := `SELECT \"launch_plans\".\"id\",\"launch_plans\".\"created_at\",\"launch_plans\".\"updated_at\",\"launch_plans\".\"deleted_at\",\"launch_plans\".\"project\",\"launch_plans\".\"domain\",\"launch_plans\".\"name\",\"launch_plans\".\"version\",\"launch_plans\".\"spec\",\"launch_plans\".\"workflow_id\",\"launch_plans\".\"closure\",\"launch_plans\".\"state\",\"launch_plans\".\"digest\",\"launch_plans\".\"schedule_type\" FROM \"launch_plans\" inner join workflows on launch_plans.workflow_id = workflows.id WHERE launch_plans.project = $1 AND launch_plans.domain = $2 AND launch_plans.name = $3 AND workflows.deleted_at = $4 LIMIT 20`\n\talternateQuery := `SELECT \"launch_plans\".\"id\",\"launch_plans\".\"created_at\",\"launch_plans\".\"updated_at\",\"launch_plans\".\"deleted_at\",\"launch_plans\".\"project\",\"launch_plans\".\"domain\",\"launch_plans\".\"name\",\"launch_plans\".\"version\",\"launch_plans\".\"spec\",\"launch_plans\".\"workflow_id\",\"launch_plans\".\"closure\",\"launch_plans\".\"state\",\"launch_plans\".\"digest\",\"launch_plans\".\"schedule_type\" FROM \"launch_plans\" inner join workflows on launch_plans.workflow_id = workflows.id WHERE launch_plans.project = $1 AND launch_plans.domain = $2 AND launch_plans.name = $3 AND workflows.deleted_at = $4 LIMIT 20`\n\tGlobalMock.NewMock().WithQuery(query).WithReply(launchPlans)\n\tGlobalMock.NewMock().WithQuery(alternateQuery).WithReply(launchPlans)\n\n\tcollection, err := launchPlanRepo.List(context.Background(), interfaces.ListResourceInput{\n\t\tInlineFilters: []common.InlineFilter{\n\t\t\tgetEqualityFilter(common.LaunchPlan, \"project\", project),\n\t\t\tgetEqualityFilter(common.LaunchPlan, \"domain\", domain),\n\t\t\tgetEqualityFilter(common.LaunchPlan, \"name\", name),\n\t\t\tgetEqualityFilter(common.Workflow, \"deleted_at\", \"foo\"),\n\t\t},\n\t\tLimit: 20,\n\t})\n\tassert.NoError(t, err)\n\tassert.NotEmpty(t, collection)\n\tassert.NotEmpty(t, collection.LaunchPlans)\n\tassert.Len(t, collection.LaunchPlans, 1)\n\tfor _, launchPlan := range collection.LaunchPlans {\n\t\tassert.Equal(t, project, launchPlan.Project)\n\t\tassert.Equal(t, domain, launchPlan.Domain)\n\t\tassert.Equal(t, name, launchPlan.Name)\n\t\tassert.Contains(t, version, launchPlan.Version)\n\t\tassert.Equal(t, launchPlanSpec, launchPlan.Spec)\n\t\tassert.Equal(t, workflowID, launchPlan.WorkflowID)\n\t\tassert.Equal(t, launchPlanClosure, launchPlan.Closure)\n\t}\n}\n\nfunc TestListLaunchPlanIds(t *testing.T) {\n\tlaunchPlanRepo := NewLaunchPlanRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\n\tlaunchPlans := make([]map[string]interface{}, 0)\n\tversions := []string{\"ABC\", \"XYZ\"}\n\tfor _, version := range versions {\n\t\tlaunchPlan := getMockLaunchPlanResponseFromDb(models.LaunchPlan{\n\t\t\tLaunchPlanKey: models.LaunchPlanKey{\n\t\t\t\tProject: project,\n\t\t\t\tDomain:  domain,\n\t\t\t\tName:    name,\n\t\t\t\tVersion: version,\n\t\t\t},\n\t\t\tSpec:       launchPlanSpec,\n\t\t\tWorkflowID: workflowID,\n\t\t\tClosure:    launchPlanClosure,\n\t\t\tState:      &inactive,\n\t\t})\n\t\tlaunchPlans = append(launchPlans, launchPlan)\n\t\tlaunchPlan = getMockLaunchPlanResponseFromDb(models.LaunchPlan{\n\t\t\tLaunchPlanKey: models.LaunchPlanKey{\n\t\t\t\tProject: project,\n\t\t\t\tDomain:  domain,\n\t\t\t\tName:    \"app.workflows.MyWorkflow\",\n\t\t\t\tVersion: version,\n\t\t\t},\n\t\t\tSpec:       launchPlanSpec,\n\t\t\tWorkflowID: uint(2),\n\t\t\tClosure:    launchPlanClosure,\n\t\t\tState:      &inactive,\n\t\t})\n\t\tlaunchPlans = append(launchPlans, launchPlan)\n\t}\n\n\tGlobalMock := mocket.Catcher.Reset()\n\tGlobalMock.NewMock().WithReply(launchPlans)\n\n\tcollection, err := launchPlanRepo.ListLaunchPlanIdentifiers(context.Background(), interfaces.ListResourceInput{\n\t\tInlineFilters: []common.InlineFilter{\n\t\t\tgetEqualityFilter(common.LaunchPlan, \"project\", project),\n\t\t\tgetEqualityFilter(common.LaunchPlan, \"domain\", domain),\n\t\t\tgetEqualityFilter(common.LaunchPlan, \"name\", name),\n\t\t},\n\t\tLimit: 20,\n\t})\n\tassert.NoError(t, err)\n\tassert.NotEmpty(t, collection)\n\tassert.NotEmpty(t, collection.LaunchPlans)\n\tassert.Len(t, collection.LaunchPlans, 4)\n\tfor _, launchPlan := range collection.LaunchPlans {\n\t\tassert.Equal(t, project, launchPlan.Project)\n\t\tassert.Equal(t, domain, launchPlan.Domain)\n\t\tassert.True(t, launchPlan.Name == name || launchPlan.Name == \"app.workflows.MyWorkflow\")\n\t\tassert.Contains(t, versions, launchPlan.Version)\n\t\tassert.Equal(t, launchPlanSpec, launchPlan.Spec)\n\t\tassert.True(t, launchPlan.WorkflowID == workflowID || launchPlan.WorkflowID == uint(2))\n\t}\n}\n", "package gormimpl\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\n\t\"github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/core\"\n\t\"google.golang.org/grpc/codes\"\n\n\t\"github.com/flyteorg/flyteadmin/pkg/common\"\n\tadminErrors \"github.com/flyteorg/flyteadmin/pkg/errors\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/errors\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/interfaces\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/models\"\n\t\"github.com/flyteorg/flytestdlib/promutils\"\n\t\"gorm.io/gorm\"\n)\n\nconst innerJoinTableAlias = \"entities\"\n\nvar resourceTypeToTableName = map[core.ResourceType]string{\n\tcore.ResourceType_LAUNCH_PLAN: launchPlanTableName,\n\tcore.ResourceType_WORKFLOW:    workflowTableName,\n\tcore.ResourceType_TASK:        taskTableName,\n}\n\nvar joinString = \"RIGHT JOIN (?) AS entities ON named_entity_metadata.resource_type = %d AND \" +\n\t\"named_entity_metadata.project = entities.project AND named_entity_metadata.domain = entities.domain AND \" +\n\t\"named_entity_metadata.name = entities.name\"\n\nfunc getSubQueryJoin(db *gorm.DB, tableName string, input interfaces.ListNamedEntityInput) *gorm.DB {\n\ttx := db.Select([]string{Project, Domain, Name}).\n\t\tTable(tableName).\n\t\tWhere(map[string]interface{}{Project: input.Project, Domain: input.Domain}).\n\t\tLimit(input.Limit).\n\t\tOffset(input.Offset).\n\t\tGroup(identifierGroupBy)\n\n\t// Apply consistent sort ordering.\n\tif input.SortParameter != nil {\n\t\ttx = tx.Order(input.SortParameter.GetGormOrderExpr())\n\t}\n\n\treturn db.Joins(fmt.Sprintf(joinString, input.ResourceType), tx)\n}\n\nvar leftJoinWorkflowNameToMetadata = fmt.Sprintf(\n\t\"LEFT JOIN %s ON %s.resource_type = %d AND %s.project = %s.project AND %s.domain = %s.domain AND %s.name = %s.name\", namedEntityMetadataTableName, namedEntityMetadataTableName, core.ResourceType_WORKFLOW, namedEntityMetadataTableName, workflowTableName,\n\tnamedEntityMetadataTableName, workflowTableName,\n\tnamedEntityMetadataTableName, workflowTableName)\n\nvar leftJoinLaunchPlanNameToMetadata = fmt.Sprintf(\n\t\"LEFT JOIN %s ON %s.resource_type = %d AND %s.project = %s.project AND %s.domain = %s.domain AND %s.name = %s.name\", namedEntityMetadataTableName, namedEntityMetadataTableName, core.ResourceType_LAUNCH_PLAN, namedEntityMetadataTableName, launchPlanTableName,\n\tnamedEntityMetadataTableName, launchPlanTableName,\n\tnamedEntityMetadataTableName, launchPlanTableName)\n\nvar leftJoinTaskNameToMetadata = fmt.Sprintf(\n\t\"LEFT JOIN %s ON %s.resource_type = %d AND %s.project = %s.project AND %s.domain = %s.domain AND %s.name = %s.name\", namedEntityMetadataTableName, namedEntityMetadataTableName, core.ResourceType_TASK, namedEntityMetadataTableName, taskTableName,\n\tnamedEntityMetadataTableName, taskTableName,\n\tnamedEntityMetadataTableName, taskTableName)\n\nvar resourceTypeToMetadataJoin = map[core.ResourceType]string{\n\tcore.ResourceType_LAUNCH_PLAN: leftJoinLaunchPlanNameToMetadata,\n\tcore.ResourceType_WORKFLOW:    leftJoinWorkflowNameToMetadata,\n\tcore.ResourceType_TASK:        leftJoinTaskNameToMetadata,\n}\n\nvar getGroupByForNamedEntity = fmt.Sprintf(\"%s.%s, %s.%s, %s.%s, %s.%s, %s.%s\",\n\tinnerJoinTableAlias, Project, innerJoinTableAlias, Domain, innerJoinTableAlias, Name, namedEntityMetadataTableName,\n\tDescription,\n\tnamedEntityMetadataTableName, State)\n\nfunc getSelectForNamedEntity(tableName string, resourceType core.ResourceType) []string {\n\treturn []string{\n\t\tfmt.Sprintf(\"%s.%s\", tableName, Project),\n\t\tfmt.Sprintf(\"%s.%s\", tableName, Domain),\n\t\tfmt.Sprintf(\"%s.%s\", tableName, Name),\n\t\tfmt.Sprintf(\"'%d' AS %s\", resourceType, ResourceType),\n\t\tfmt.Sprintf(\"%s.%s\", namedEntityMetadataTableName, Description),\n\t\tfmt.Sprintf(\"%s.%s\", namedEntityMetadataTableName, State),\n\t}\n}\n\nfunc getNamedEntityFilters(resourceType core.ResourceType, project string, domain string, name string) ([]common.InlineFilter, error) {\n\tentity := common.ResourceTypeToEntity[resourceType]\n\n\tfilters := make([]common.InlineFilter, 0)\n\tprojectFilter, err := common.NewSingleValueFilter(entity, common.Equal, Project, project)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tfilters = append(filters, projectFilter)\n\tdomainFilter, err := common.NewSingleValueFilter(entity, common.Equal, Domain, domain)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tfilters = append(filters, domainFilter)\n\tnameFilter, err := common.NewSingleValueFilter(entity, common.Equal, Name, name)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tfilters = append(filters, nameFilter)\n\n\treturn filters, nil\n}\n\n// Implementation of NamedEntityRepoInterface.\ntype NamedEntityRepo struct {\n\tdb               *gorm.DB\n\terrorTransformer errors.ErrorTransformer\n\tmetrics          gormMetrics\n}\n\nfunc (r *NamedEntityRepo) Update(ctx context.Context, input models.NamedEntity) error {\n\ttimer := r.metrics.UpdateDuration.Start()\n\tvar metadata models.NamedEntityMetadata\n\ttx := r.db.Where(&models.NamedEntityMetadata{\n\t\tNamedEntityMetadataKey: models.NamedEntityMetadataKey{\n\t\t\tResourceType: input.ResourceType,\n\t\t\tProject:      input.Project,\n\t\t\tDomain:       input.Domain,\n\t\t\tName:         input.Name,\n\t\t},\n\t}).Assign(input.NamedEntityMetadataFields).Omit(\"id\").FirstOrCreate(&metadata)\n\ttimer.Stop()\n\tif tx.Error != nil {\n\t\treturn r.errorTransformer.ToFlyteAdminError(tx.Error)\n\t}\n\treturn nil\n}\n\nfunc (r *NamedEntityRepo) Get(ctx context.Context, input interfaces.GetNamedEntityInput) (models.NamedEntity, error) {\n\tvar namedEntity models.NamedEntity\n\n\tfilters, err := getNamedEntityFilters(input.ResourceType, input.Project, input.Domain, input.Name)\n\tif err != nil {\n\t\treturn models.NamedEntity{}, err\n\t}\n\n\ttableName, tableFound := resourceTypeToTableName[input.ResourceType]\n\tjoinString, joinFound := resourceTypeToMetadataJoin[input.ResourceType]\n\tif !tableFound || !joinFound {\n\t\treturn models.NamedEntity{}, adminErrors.NewFlyteAdminErrorf(codes.InvalidArgument, \"Cannot get NamedEntityMetadata for resource type: %v\", input.ResourceType)\n\t}\n\n\ttx := r.db.Table(tableName).Joins(joinString)\n\n\t// Apply filters\n\ttx, err = applyScopedFilters(tx, filters, nil)\n\tif err != nil {\n\t\treturn models.NamedEntity{}, err\n\t}\n\n\ttimer := r.metrics.GetDuration.Start()\n\ttx = tx.Select(getSelectForNamedEntity(tableName, input.ResourceType)).Take(&namedEntity)\n\ttimer.Stop()\n\n\tif tx.Error != nil {\n\t\treturn models.NamedEntity{}, r.errorTransformer.ToFlyteAdminError(tx.Error)\n\t}\n\n\treturn namedEntity, nil\n}\n\nfunc (r *NamedEntityRepo) List(ctx context.Context, input interfaces.ListNamedEntityInput) (\n\tinterfaces.NamedEntityCollectionOutput, error) {\n\n\t// Validate input. Filters aren't required because they're implicit in the Project & Domain specified by the input.\n\tif len(input.Project) == 0 {\n\t\treturn interfaces.NamedEntityCollectionOutput{}, errors.GetInvalidInputError(Project)\n\t}\n\tif len(input.Domain) == 0 {\n\t\treturn interfaces.NamedEntityCollectionOutput{}, errors.GetInvalidInputError(Domain)\n\t}\n\tif input.Limit == 0 {\n\t\treturn interfaces.NamedEntityCollectionOutput{}, errors.GetInvalidInputError(limit)\n\t}\n\n\ttableName, tableFound := resourceTypeToTableName[input.ResourceType]\n\tif !tableFound {\n\t\treturn interfaces.NamedEntityCollectionOutput{}, adminErrors.NewFlyteAdminErrorf(codes.InvalidArgument,\n\t\t\t\"Cannot list entity names for resource type: %v\", input.ResourceType)\n\t}\n\n\ttx := getSubQueryJoin(r.db, tableName, input)\n\n\t// Apply filters\n\ttx, err := applyScopedFilters(tx, input.InlineFilters, input.MapFilters)\n\tif err != nil {\n\t\treturn interfaces.NamedEntityCollectionOutput{}, err\n\t}\n\t// Apply sort ordering.\n\tif input.SortParameter != nil {\n\t\ttx = tx.Order(input.SortParameter.GetGormOrderExpr())\n\t}\n\n\t// Scan the results into a list of named entities\n\tvar entities []models.NamedEntity\n\ttimer := r.metrics.ListDuration.Start()\n\n\ttx.Select(getSelectForNamedEntity(innerJoinTableAlias, input.ResourceType)).Table(namedEntityMetadataTableName).Group(getGroupByForNamedEntity).Scan(&entities)\n\n\ttimer.Stop()\n\n\tif tx.Error != nil {\n\t\treturn interfaces.NamedEntityCollectionOutput{}, r.errorTransformer.ToFlyteAdminError(tx.Error)\n\t}\n\n\treturn interfaces.NamedEntityCollectionOutput{\n\t\tEntities: entities,\n\t}, nil\n}\n\n// Returns an instance of NamedEntityRepoInterface\nfunc NewNamedEntityRepo(\n\tdb *gorm.DB, errorTransformer errors.ErrorTransformer, scope promutils.Scope) interfaces.NamedEntityRepoInterface {\n\tmetrics := newMetrics(scope)\n\n\treturn &NamedEntityRepo{\n\t\tdb:               db,\n\t\terrorTransformer: errorTransformer,\n\t\tmetrics:          metrics,\n\t}\n}\n", "package gormimpl\n\nimport (\n\t\"context\"\n\t\"testing\"\n\n\t\"github.com/flyteorg/flyteadmin/pkg/common\"\n\n\t\"github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/admin\"\n\n\tmocket \"github.com/Selvatico/go-mocket\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/errors\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/interfaces\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/models\"\n\tmockScope \"github.com/flyteorg/flytestdlib/promutils\"\n\t\"github.com/stretchr/testify/assert\"\n)\n\nfunc getMockNamedEntityResponseFromDb(expected models.NamedEntity) map[string]interface{} {\n\tmetadata := make(map[string]interface{})\n\tmetadata[\"resource_type\"] = expected.ResourceType\n\tmetadata[\"project\"] = expected.Project\n\tmetadata[\"domain\"] = expected.Domain\n\tmetadata[\"name\"] = expected.Name\n\tmetadata[\"description\"] = expected.Description\n\tmetadata[\"state\"] = expected.State\n\treturn metadata\n}\n\nfunc TestGetNamedEntity(t *testing.T) {\n\tmetadataRepo := NewNamedEntityRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\n\tresults := make([]map[string]interface{}, 0)\n\tmetadata := getMockNamedEntityResponseFromDb(models.NamedEntity{\n\t\tNamedEntityKey: models.NamedEntityKey{\n\t\t\tResourceType: resourceType,\n\t\t\tProject:      project,\n\t\t\tDomain:       domain,\n\t\t\tName:         name,\n\t\t},\n\t\tNamedEntityMetadataFields: models.NamedEntityMetadataFields{\n\t\t\tDescription: description,\n\t\t},\n\t})\n\tresults = append(results, metadata)\n\n\tGlobalMock := mocket.Catcher.Reset()\n\tGlobalMock.Logging = true\n\tGlobalMock.NewMock().WithQuery(\n\t\t`SELECT workflows.project,workflows.domain,workflows.name,'2' AS resource_type,named_entity_metadata.description,named_entity_metadata.state FROM \"workflows\" LEFT JOIN named_entity_metadata ON named_entity_metadata.resource_type = 2 AND named_entity_metadata.project = workflows.project AND named_entity_metadata.domain = workflows.domain AND named_entity_metadata.name = workflows.name WHERE workflows.project = $1 AND workflows.domain = $2 AND workflows.name = $3 LIMIT 1`).WithReply(results)\n\toutput, err := metadataRepo.Get(context.Background(), interfaces.GetNamedEntityInput{\n\t\tResourceType: resourceType,\n\t\tProject:      project,\n\t\tDomain:       domain,\n\t\tName:         name,\n\t})\n\tassert.NoError(t, err)\n\tassert.Equal(t, project, output.Project)\n\tassert.Equal(t, domain, output.Domain)\n\tassert.Equal(t, name, output.Name)\n\tassert.Equal(t, resourceType, output.ResourceType)\n\tassert.Equal(t, description, output.Description)\n}\n\nfunc TestUpdateNamedEntity_WithExisting(t *testing.T) {\n\tmetadataRepo := NewNamedEntityRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\tconst updatedDescription = \"updated description\"\n\n\tresults := make([]map[string]interface{}, 0)\n\tactiveState := int32(admin.NamedEntityState_NAMED_ENTITY_ACTIVE)\n\tmetadata := getMockNamedEntityResponseFromDb(models.NamedEntity{\n\t\tNamedEntityKey: models.NamedEntityKey{\n\t\t\tResourceType: resourceType,\n\t\t\tProject:      project,\n\t\t\tDomain:       domain,\n\t\t\tName:         name,\n\t\t},\n\t\tNamedEntityMetadataFields: models.NamedEntityMetadataFields{\n\t\t\tDescription: description,\n\t\t\tState:       &activeState,\n\t\t},\n\t})\n\tresults = append(results, metadata)\n\n\tGlobalMock := mocket.Catcher.Reset()\n\tGlobalMock.Logging = true\n\tGlobalMock.NewMock().WithQuery(\n\t\t`SELECT \"named_entity_metadata\".\"created_at\",\"named_entity_metadata\".\"updated_at\",\"named_entity_metadata\".\"deleted_at\",\"named_entity_metadata\".\"resource_type\",\"named_entity_metadata\".\"project\",\"named_entity_metadata\".\"domain\",\"named_entity_metadata\".\"name\",\"named_entity_metadata\".\"description\",\"named_entity_metadata\".\"state\" FROM \"named_entity_metadata\" WHERE \"named_entity_metadata\".\"resource_type\" = $1 AND \"named_entity_metadata\".\"project\" = $2 AND \"named_entity_metadata\".\"domain\" = $3 AND \"named_entity_metadata\".\"name\" = $4 ORDER BY \"named_entity_metadata\".\"id\" LIMIT 1`).WithReply(results)\n\n\tmockQuery := GlobalMock.NewMock()\n\tmockQuery.WithQuery(\n\t\t`UPDATE \"named_entity_metadata\" SET \"description\"=$1,\"state\"=$2,\"updated_at\"=$3 WHERE \"named_entity_metadata\".\"resource_type\" = $4 AND \"named_entity_metadata\".\"project\" = $5 AND \"named_entity_metadata\".\"domain\" = $6 AND \"named_entity_metadata\".\"name\" = $7 AND \"resource_type\" = $8 AND \"project\" = $9 AND \"domain\" = $10 AND \"name\" = $11`)\n\n\terr := metadataRepo.Update(context.Background(), models.NamedEntity{\n\t\tNamedEntityKey: models.NamedEntityKey{\n\t\t\tResourceType: resourceType,\n\t\t\tProject:      project,\n\t\t\tDomain:       domain,\n\t\t\tName:         name,\n\t\t},\n\t\tNamedEntityMetadataFields: models.NamedEntityMetadataFields{\n\t\t\tDescription: updatedDescription,\n\t\t\tState:       &activeState,\n\t\t},\n\t})\n\tassert.NoError(t, err)\n\tassert.True(t, mockQuery.Triggered)\n}\n\nfunc TestUpdateNamedEntity_CreateNew(t *testing.T) {\n\tmetadataRepo := NewNamedEntityRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\tconst updatedDescription = \"updated description\"\n\n\tGlobalMock := mocket.Catcher.Reset()\n\tGlobalMock.Logging = true\n\n\tmockQuery := GlobalMock.NewMock()\n\tmockQuery.WithQuery(\n\t\t`INSERT INTO \"named_entity_metadata\" (\"created_at\",\"updated_at\",\"deleted_at\",\"resource_type\",\"project\",\"domain\",\"name\",\"description\",\"state\") VALUES ($1,$2,$3,$4,$5,$6,$7,$8,$9)`)\n\n\terr := metadataRepo.Update(context.Background(), models.NamedEntity{\n\t\tNamedEntityKey: models.NamedEntityKey{\n\t\t\tResourceType: resourceType,\n\t\t\tProject:      project,\n\t\t\tDomain:       domain,\n\t\t\tName:         name,\n\t\t},\n\t\tNamedEntityMetadataFields: models.NamedEntityMetadataFields{\n\t\t\tDescription: updatedDescription,\n\t\t},\n\t})\n\tassert.NoError(t, err)\n\tassert.True(t, mockQuery.Triggered)\n}\n\nfunc TestListNamedEntity(t *testing.T) {\n\tmetadataRepo := NewNamedEntityRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\n\tresults := make([]map[string]interface{}, 0)\n\tmetadata := getMockNamedEntityResponseFromDb(models.NamedEntity{\n\t\tNamedEntityKey: models.NamedEntityKey{\n\t\t\tResourceType: resourceType,\n\t\t\tProject:      project,\n\t\t\tDomain:       domain,\n\t\t\tName:         name,\n\t\t},\n\t\tNamedEntityMetadataFields: models.NamedEntityMetadataFields{\n\t\t\tDescription: description,\n\t\t},\n\t})\n\tresults = append(results, metadata)\n\n\tGlobalMock := mocket.Catcher.Reset()\n\tGlobalMock.Logging = true\n\tmockQuery := GlobalMock.NewMock()\n\n\tmockQuery.WithQuery(\n\t\t`SELECT entities.project,entities.domain,entities.name,'2' AS resource_type,named_entity_metadata.description,named_entity_metadata.state FROM \"named_entity_metadata\" RIGHT JOIN (SELECT project,domain,name FROM \"workflows\" WHERE \"domain\" = $1 AND \"project\" = $2 GROUP BY project, domain, name ORDER BY name desc LIMIT 20) AS entities ON named_entity_metadata.resource_type = 2 AND named_entity_metadata.project = entities.project AND named_entity_metadata.domain = entities.domain AND named_entity_metadata.name = entities.name GROUP BY entities.project, entities.domain, entities.name, named_entity_metadata.description, named_entity_metadata.state ORDER BY name desc`).WithReply(results)\n\n\tsortParameter, _ := common.NewSortParameter(admin.Sort{\n\t\tDirection: admin.Sort_DESCENDING,\n\t\tKey:       \"name\",\n\t})\n\toutput, err := metadataRepo.List(context.Background(), interfaces.ListNamedEntityInput{\n\t\tResourceType: resourceType,\n\t\tProject:      \"admintests\",\n\t\tDomain:       \"development\",\n\t\tListResourceInput: interfaces.ListResourceInput{\n\t\t\tLimit:         20,\n\t\t\tSortParameter: sortParameter,\n\t\t},\n\t})\n\tassert.NoError(t, err)\n\tassert.Len(t, output.Entities, 1)\n}\n", "package gormimpl\n\nimport (\n\t\"context\"\n\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/errors\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/interfaces\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/models\"\n\t\"github.com/flyteorg/flytestdlib/promutils\"\n\t\"gorm.io/gorm\"\n)\n\ntype NodeExecutionEventRepo struct {\n\tdb               *gorm.DB\n\terrorTransformer errors.ErrorTransformer\n\tmetrics          gormMetrics\n}\n\nfunc (r *NodeExecutionEventRepo) Create(ctx context.Context, input models.NodeExecutionEvent) error {\n\ttimer := r.metrics.CreateDuration.Start()\n\ttx := r.db.Omit(\"id\").Create(&input)\n\ttimer.Stop()\n\tif tx.Error != nil {\n\t\treturn r.errorTransformer.ToFlyteAdminError(tx.Error)\n\t}\n\treturn nil\n}\n\n// Returns an instance of NodeExecutionRepoInterface\nfunc NewNodeExecutionEventRepo(\n\tdb *gorm.DB, errorTransformer errors.ErrorTransformer, scope promutils.Scope) interfaces.NodeExecutionEventRepoInterface {\n\tmetrics := newMetrics(scope)\n\treturn &NodeExecutionEventRepo{\n\t\tdb:               db,\n\t\terrorTransformer: errorTransformer,\n\t\tmetrics:          metrics,\n\t}\n}\n", "package gormimpl\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"fmt\"\n\n\t\"github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/core\"\n\n\t\"github.com/flyteorg/flytestdlib/promutils\"\n\n\tadminErrors \"github.com/flyteorg/flyteadmin/pkg/repositories/errors\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/interfaces\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/models\"\n\t\"gorm.io/gorm\"\n)\n\n// Implementation of NodeExecutionInterface.\ntype NodeExecutionRepo struct {\n\tdb               *gorm.DB\n\terrorTransformer adminErrors.ErrorTransformer\n\tmetrics          gormMetrics\n}\n\nfunc (r *NodeExecutionRepo) Create(ctx context.Context, execution *models.NodeExecution) error {\n\ttimer := r.metrics.CreateDuration.Start()\n\ttx := r.db.Omit(\"id\").Create(&execution)\n\ttimer.Stop()\n\tif tx.Error != nil {\n\t\treturn r.errorTransformer.ToFlyteAdminError(tx.Error)\n\t}\n\treturn nil\n}\n\nfunc (r *NodeExecutionRepo) Get(ctx context.Context, input interfaces.NodeExecutionResource) (models.NodeExecution, error) {\n\tvar nodeExecution models.NodeExecution\n\ttimer := r.metrics.GetDuration.Start()\n\ttx := r.db.Where(&models.NodeExecution{\n\t\tNodeExecutionKey: models.NodeExecutionKey{\n\t\t\tNodeID: input.NodeExecutionIdentifier.NodeId,\n\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\tProject: input.NodeExecutionIdentifier.ExecutionId.Project,\n\t\t\t\tDomain:  input.NodeExecutionIdentifier.ExecutionId.Domain,\n\t\t\t\tName:    input.NodeExecutionIdentifier.ExecutionId.Name,\n\t\t\t},\n\t\t},\n\t}).Take(&nodeExecution)\n\ttimer.Stop()\n\n\tif tx.Error != nil && errors.Is(tx.Error, gorm.ErrRecordNotFound) {\n\t\treturn models.NodeExecution{},\n\t\t\tadminErrors.GetMissingEntityError(\"node execution\", &core.NodeExecutionIdentifier{\n\t\t\t\tNodeId: input.NodeExecutionIdentifier.NodeId,\n\t\t\t\tExecutionId: &core.WorkflowExecutionIdentifier{\n\t\t\t\t\tProject: input.NodeExecutionIdentifier.ExecutionId.Project,\n\t\t\t\t\tDomain:  input.NodeExecutionIdentifier.ExecutionId.Domain,\n\t\t\t\t\tName:    input.NodeExecutionIdentifier.ExecutionId.Name,\n\t\t\t\t},\n\t\t\t})\n\t} else if tx.Error != nil {\n\t\treturn models.NodeExecution{}, r.errorTransformer.ToFlyteAdminError(tx.Error)\n\t}\n\n\treturn nodeExecution, nil\n}\n\nfunc (r *NodeExecutionRepo) GetWithChildren(ctx context.Context, input interfaces.NodeExecutionResource) (models.NodeExecution, error) {\n\tvar nodeExecution models.NodeExecution\n\ttimer := r.metrics.GetDuration.Start()\n\ttx := r.db.Where(&models.NodeExecution{\n\t\tNodeExecutionKey: models.NodeExecutionKey{\n\t\t\tNodeID: input.NodeExecutionIdentifier.NodeId,\n\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\tProject: input.NodeExecutionIdentifier.ExecutionId.Project,\n\t\t\t\tDomain:  input.NodeExecutionIdentifier.ExecutionId.Domain,\n\t\t\t\tName:    input.NodeExecutionIdentifier.ExecutionId.Name,\n\t\t\t},\n\t\t},\n\t}).Preload(\"ChildNodeExecutions\").Take(&nodeExecution)\n\ttimer.Stop()\n\n\tif tx.Error != nil && errors.Is(tx.Error, gorm.ErrRecordNotFound) {\n\t\treturn models.NodeExecution{},\n\t\t\tadminErrors.GetMissingEntityError(\"node execution\", &core.NodeExecutionIdentifier{\n\t\t\t\tNodeId: input.NodeExecutionIdentifier.NodeId,\n\t\t\t\tExecutionId: &core.WorkflowExecutionIdentifier{\n\t\t\t\t\tProject: input.NodeExecutionIdentifier.ExecutionId.Project,\n\t\t\t\t\tDomain:  input.NodeExecutionIdentifier.ExecutionId.Domain,\n\t\t\t\t\tName:    input.NodeExecutionIdentifier.ExecutionId.Name,\n\t\t\t\t},\n\t\t\t})\n\t} else if tx.Error != nil {\n\t\treturn models.NodeExecution{}, r.errorTransformer.ToFlyteAdminError(tx.Error)\n\t}\n\n\treturn nodeExecution, nil\n}\n\nfunc (r *NodeExecutionRepo) Update(ctx context.Context, nodeExecution *models.NodeExecution) error {\n\ttimer := r.metrics.UpdateDuration.Start()\n\ttx := r.db.Model(&nodeExecution).Updates(nodeExecution)\n\ttimer.Stop()\n\tif err := tx.Error; err != nil {\n\t\treturn r.errorTransformer.ToFlyteAdminError(err)\n\t}\n\treturn nil\n}\n\nfunc (r *NodeExecutionRepo) List(ctx context.Context, input interfaces.ListResourceInput) (\n\tinterfaces.NodeExecutionCollectionOutput, error) {\n\t// First validate input.\n\tif err := ValidateListInput(input); err != nil {\n\t\treturn interfaces.NodeExecutionCollectionOutput{}, err\n\t}\n\tvar nodeExecutions []models.NodeExecution\n\ttx := r.db.Limit(input.Limit).Offset(input.Offset).Preload(\"ChildNodeExecutions\")\n\t// And add join condition (joining multiple tables is fine even we only filter on a subset of table attributes).\n\t// (this query isn't called for deletes).\n\ttx = tx.Joins(fmt.Sprintf(\"INNER JOIN %s ON %s.execution_project = %s.execution_project AND \"+\n\t\t\"%s.execution_domain = %s.execution_domain AND %s.execution_name = %s.execution_name\",\n\t\texecutionTableName, nodeExecutionTableName, executionTableName,\n\t\tnodeExecutionTableName, executionTableName, nodeExecutionTableName, executionTableName))\n\n\t// Apply filters\n\ttx, err := applyScopedFilters(tx, input.InlineFilters, input.MapFilters)\n\tif err != nil {\n\t\treturn interfaces.NodeExecutionCollectionOutput{}, err\n\t}\n\t// Apply sort ordering.\n\tif input.SortParameter != nil {\n\t\ttx = tx.Order(input.SortParameter.GetGormOrderExpr())\n\t}\n\n\ttimer := r.metrics.ListDuration.Start()\n\ttx = tx.Find(&nodeExecutions)\n\ttimer.Stop()\n\tif tx.Error != nil {\n\t\treturn interfaces.NodeExecutionCollectionOutput{}, r.errorTransformer.ToFlyteAdminError(tx.Error)\n\t}\n\treturn interfaces.NodeExecutionCollectionOutput{\n\t\tNodeExecutions: nodeExecutions,\n\t}, nil\n}\n\nfunc (r *NodeExecutionRepo) Exists(ctx context.Context, input interfaces.NodeExecutionResource) (bool, error) {\n\tvar nodeExecution models.NodeExecution\n\ttimer := r.metrics.ExistsDuration.Start()\n\ttx := r.db.Select(ID).Where(&models.NodeExecution{\n\t\tNodeExecutionKey: models.NodeExecutionKey{\n\t\t\tNodeID: input.NodeExecutionIdentifier.NodeId,\n\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\tProject: input.NodeExecutionIdentifier.ExecutionId.Project,\n\t\t\t\tDomain:  input.NodeExecutionIdentifier.ExecutionId.Domain,\n\t\t\t\tName:    input.NodeExecutionIdentifier.ExecutionId.Name,\n\t\t\t},\n\t\t},\n\t}).Take(&nodeExecution)\n\ttimer.Stop()\n\tif tx.Error != nil {\n\t\treturn false, r.errorTransformer.ToFlyteAdminError(tx.Error)\n\t}\n\treturn true, nil\n}\n\nfunc (r *NodeExecutionRepo) Count(ctx context.Context, input interfaces.CountResourceInput) (int64, error) {\n\tvar err error\n\ttx := r.db.Model(&models.NodeExecution{}).Preload(\"ChildNodeExecutions\")\n\n\t// Add join condition (joining multiple tables is fine even we only filter on a subset of table attributes).\n\t// (this query isn't called for deletes).\n\ttx = tx.Joins(fmt.Sprintf(\"INNER JOIN %s ON %s.execution_project = %s.execution_project AND \"+\n\t\t\"%s.execution_domain = %s.execution_domain AND %s.execution_name = %s.execution_name\",\n\t\texecutionTableName, nodeExecutionTableName, executionTableName,\n\t\tnodeExecutionTableName, executionTableName, nodeExecutionTableName, executionTableName))\n\n\t// Apply filters\n\ttx, err = applyScopedFilters(tx, input.InlineFilters, input.MapFilters)\n\tif err != nil {\n\t\treturn 0, err\n\t}\n\n\t// Run the query\n\ttimer := r.metrics.CountDuration.Start()\n\tvar count int64\n\ttx = tx.Count(&count)\n\ttimer.Stop()\n\tif tx.Error != nil {\n\t\treturn 0, r.errorTransformer.ToFlyteAdminError(tx.Error)\n\t}\n\treturn count, nil\n}\n\n// Returns an instance of NodeExecutionRepoInterface\nfunc NewNodeExecutionRepo(\n\tdb *gorm.DB, errorTransformer adminErrors.ErrorTransformer,\n\tscope promutils.Scope) interfaces.NodeExecutionRepoInterface {\n\tmetrics := newMetrics(scope)\n\treturn &NodeExecutionRepo{\n\t\tdb:               db,\n\t\terrorTransformer: errorTransformer,\n\t\tmetrics:          metrics,\n\t}\n}\n", "package gormimpl\n\nimport (\n\t\"context\"\n\t\"testing\"\n\t\"time\"\n\n\tflyteAdminErrors \"github.com/flyteorg/flyteadmin/pkg/errors\"\n\t\"google.golang.org/grpc/codes\"\n\t\"gorm.io/gorm\"\n\n\tmockScope \"github.com/flyteorg/flytestdlib/promutils\"\n\n\t\"github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/admin\"\n\t\"github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/core\"\n\n\tmocket \"github.com/Selvatico/go-mocket\"\n\t\"github.com/flyteorg/flyteadmin/pkg/common\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/errors\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/interfaces\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/models\"\n\t\"github.com/stretchr/testify/assert\"\n)\n\nvar nodePhase = core.NodeExecution_RUNNING.String()\n\nvar nodeStartedAt = time.Date(2018, time.February, 17, 00, 00, 00, 00, time.UTC)\n\nvar nodeCreatedAt = time.Date(2018, time.February, 17, 00, 00, 00, 00, time.UTC).UTC()\nvar nodePlanUpdatedAt = time.Date(2018, time.February, 17, 00, 01, 00, 00, time.UTC).UTC()\n\nfunc TestCreateNodeExecution(t *testing.T) {\n\tnodeExecutionRepo := NewNodeExecutionRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\tGlobalMock := mocket.Catcher.Reset()\n\n\tnodeExecutionQuery := GlobalMock.NewMock()\n\tnodeExecutionQuery.WithQuery(`INSERT INTO \"node_executions\" (\"created_at\",\"updated_at\",\"deleted_at\",\"execution_project\",\"execution_domain\",\"execution_name\",\"node_id\",\"phase\",\"input_uri\",\"closure\",\"started_at\",\"node_execution_created_at\",\"node_execution_updated_at\",\"duration\",\"node_execution_metadata\",\"parent_id\",\"parent_task_execution_id\",\"error_kind\",\"error_code\",\"cache_status\",\"dynamic_workflow_remote_closure_reference\",\"internal_data\") VALUES ($1,$2,$3,$4,$5,$6,$7,$8,$9,$10,$11,$12,$13,$14,$15,$16,$17,$18,$19,$20,$21,$22)`)\n\tparentID := uint(10)\n\tnodeExecution := models.NodeExecution{\n\t\tNodeExecutionKey: models.NodeExecutionKey{\n\t\t\tNodeID: \"1\",\n\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\tProject: \"project\",\n\t\t\t\tDomain:  \"domain\",\n\t\t\t\tName:    \"1\",\n\t\t\t},\n\t\t},\n\t\tPhase:                  nodePhase,\n\t\tClosure:                []byte(\"closure\"),\n\t\tNodeExecutionMetadata:  []byte(\"closure\"),\n\t\tInputURI:               \"input uri\",\n\t\tStartedAt:              &nodeStartedAt,\n\t\tDuration:               time.Hour,\n\t\tNodeExecutionCreatedAt: &nodeCreatedAt,\n\t\tNodeExecutionUpdatedAt: &nodeCreatedAt,\n\t\tParentID:               &parentID,\n\t}\n\terr := nodeExecutionRepo.Create(context.Background(), &nodeExecution)\n\tassert.NoError(t, err)\n\tassert.True(t, nodeExecutionQuery.Triggered)\n}\n\nfunc TestUpdateNodeExecution(t *testing.T) {\n\tnodeExecutionRepo := NewNodeExecutionRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\tGlobalMock := mocket.Catcher.Reset()\n\t// Only match on queries that append the name filter\n\tnodeExecutionQuery := GlobalMock.NewMock()\n\tnodeExecutionQuery.WithQuery(`UPDATE \"node_executions\" SET \"id\"=$1,\"updated_at\"=$2,\"execution_project\"=$3,\"execution_domain\"=$4,\"execution_name\"=$5,\"node_id\"=$6,\"phase\"=$7,\"input_uri\"=$8,\"closure\"=$9,\"started_at\"=$10,\"node_execution_created_at\"=$11,\"node_execution_updated_at\"=$12,\"duration\"=$13 WHERE \"execution_project\" = $14 AND \"execution_domain\" = $15 AND \"execution_name\" = $16 AND \"node_id\" = $17`)\n\terr := nodeExecutionRepo.Update(context.Background(),\n\t\t&models.NodeExecution{\n\t\t\tBaseModel: models.BaseModel{ID: 1},\n\t\t\tNodeExecutionKey: models.NodeExecutionKey{\n\t\t\t\tNodeID: \"1\",\n\t\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\t\tProject: \"project\",\n\t\t\t\t\tDomain:  \"domain\",\n\t\t\t\t\tName:    \"1\",\n\t\t\t\t},\n\t\t\t},\n\t\t\tPhase:                  nodePhase,\n\t\t\tClosure:                []byte(\"closure\"),\n\t\t\tInputURI:               \"input uri\",\n\t\t\tStartedAt:              &nodeStartedAt,\n\t\t\tDuration:               time.Hour,\n\t\t\tNodeExecutionCreatedAt: &nodeCreatedAt,\n\t\t\tNodeExecutionUpdatedAt: &nodePlanUpdatedAt,\n\t\t})\n\tassert.NoError(t, err)\n\tassert.True(t, nodeExecutionQuery.Triggered)\n}\n\nfunc getMockNodeExecutionResponseFromDb(expected models.NodeExecution) map[string]interface{} {\n\tnodeExecution := make(map[string]interface{})\n\tnodeExecution[\"execution_project\"] = expected.ExecutionKey.Project\n\tnodeExecution[\"execution_domain\"] = expected.ExecutionKey.Domain\n\tnodeExecution[\"execution_name\"] = expected.ExecutionKey.Name\n\tnodeExecution[\"node_id\"] = expected.NodeExecutionKey.NodeID\n\tnodeExecution[\"phase\"] = expected.Phase\n\tnodeExecution[\"closure\"] = expected.Closure\n\tnodeExecution[\"input_uri\"] = expected.InputURI\n\tnodeExecution[\"started_at\"] = expected.StartedAt\n\tnodeExecution[\"duration\"] = expected.Duration\n\tnodeExecution[\"node_execution_created_at\"] = expected.NodeExecutionCreatedAt\n\tnodeExecution[\"node_execution_updated_at\"] = expected.NodeExecutionUpdatedAt\n\tnodeExecution[\"parent_id\"] = expected.ParentID\n\tif expected.NodeExecutionMetadata != nil {\n\t\tnodeExecution[\"node_execution_metadata\"] = expected.NodeExecutionMetadata\n\t}\n\treturn nodeExecution\n}\n\nfunc TestGetNodeExecution(t *testing.T) {\n\tnodeExecutionRepo := NewNodeExecutionRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\tparentID := uint(10)\n\texpectedNodeExecution := models.NodeExecution{\n\t\tNodeExecutionKey: models.NodeExecutionKey{\n\t\t\tNodeID: \"1\",\n\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\tProject: \"project\",\n\t\t\t\tDomain:  \"domain\",\n\t\t\t\tName:    \"1\",\n\t\t\t},\n\t\t},\n\t\tPhase:                  nodePhase,\n\t\tClosure:                []byte(\"closure\"),\n\t\tInputURI:               \"input uri\",\n\t\tStartedAt:              &nodeStartedAt,\n\t\tDuration:               time.Hour,\n\t\tNodeExecutionCreatedAt: &nodeCreatedAt,\n\t\tNodeExecutionUpdatedAt: &nodePlanUpdatedAt,\n\t\tNodeExecutionMetadata:  []byte(\"NodeExecutionMetadata\"),\n\t\tParentID:               &parentID,\n\t}\n\n\tnodeExecutions := make([]map[string]interface{}, 0)\n\tnodeExecution := getMockNodeExecutionResponseFromDb(expectedNodeExecution)\n\tnodeExecutions = append(nodeExecutions, nodeExecution)\n\n\tGlobalMock := mocket.Catcher.Reset()\n\tGlobalMock.NewMock().WithQuery(\n\t\t`SELECT * FROM \"node_executions\" WHERE \"node_executions\".\"execution_project\" = $1 AND \"node_executions\".\"execution_domain\" = $2 AND \"node_executions\".\"execution_name\" = $3 AND \"node_executions\".\"node_id\" = $4 LIMIT 1`).WithReply(nodeExecutions)\n\toutput, err := nodeExecutionRepo.Get(context.Background(), interfaces.NodeExecutionResource{\n\t\tNodeExecutionIdentifier: core.NodeExecutionIdentifier{\n\t\t\tNodeId: \"1\",\n\t\t\tExecutionId: &core.WorkflowExecutionIdentifier{\n\t\t\t\tProject: \"execution_project\",\n\t\t\t\tDomain:  \"execution_domain\",\n\t\t\t\tName:    \"execution_name\",\n\t\t\t},\n\t\t},\n\t})\n\tassert.NoError(t, err)\n\tassert.EqualValues(t, expectedNodeExecution, output)\n}\n\nfunc TestGetNodeExecutionErr(t *testing.T) {\n\tnodeExecutionRepo := NewNodeExecutionRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\n\tt.Run(\"not found\", func(t *testing.T) {\n\t\tGlobalMock := mocket.Catcher.Reset()\n\t\tGlobalMock.NewMock().WithError(gorm.ErrRecordNotFound)\n\n\t\t_, err := nodeExecutionRepo.Get(context.Background(), interfaces.NodeExecutionResource{\n\t\t\tNodeExecutionIdentifier: core.NodeExecutionIdentifier{\n\t\t\t\tNodeId: \"1\",\n\t\t\t\tExecutionId: &core.WorkflowExecutionIdentifier{\n\t\t\t\t\tProject: \"execution_project\",\n\t\t\t\t\tDomain:  \"execution_domain\",\n\t\t\t\t\tName:    \"execution_name\",\n\t\t\t\t},\n\t\t\t},\n\t\t})\n\t\tassert.Equal(t, err.(flyteAdminErrors.FlyteAdminError).Code(), codes.NotFound)\n\t})\n\tt.Run(\"other error\", func(t *testing.T) {\n\t\tGlobalMock := mocket.Catcher.Reset()\n\t\tGlobalMock.NewMock().WithError(gorm.ErrInvalidData)\n\n\t\t_, err := nodeExecutionRepo.Get(context.Background(), interfaces.NodeExecutionResource{\n\t\t\tNodeExecutionIdentifier: core.NodeExecutionIdentifier{\n\t\t\t\tNodeId: \"1\",\n\t\t\t\tExecutionId: &core.WorkflowExecutionIdentifier{\n\t\t\t\t\tProject: \"execution_project\",\n\t\t\t\t\tDomain:  \"execution_domain\",\n\t\t\t\t\tName:    \"execution_name\",\n\t\t\t\t},\n\t\t\t},\n\t\t})\n\t\tassert.Equal(t, err.(flyteAdminErrors.FlyteAdminError).Code(), codes.Unknown)\n\t})\n}\n\nfunc TestListNodeExecutions(t *testing.T) {\n\tnodeExecutionRepo := NewNodeExecutionRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\n\tnodeExecutions := make([]map[string]interface{}, 0)\n\texecutionIDs := []string{\"100\", \"200\"}\n\tfor _, executionID := range executionIDs {\n\t\tnodeExecution := getMockNodeExecutionResponseFromDb(models.NodeExecution{\n\t\t\tNodeExecutionKey: models.NodeExecutionKey{\n\t\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\t\tProject: \"project\",\n\t\t\t\t\tDomain:  \"domain\",\n\t\t\t\t\tName:    executionID,\n\t\t\t\t},\n\t\t\t},\n\t\t\tPhase:                  nodePhase,\n\t\t\tClosure:                []byte(\"closure\"),\n\t\t\tInputURI:               \"input uri\",\n\t\t\tStartedAt:              &nodeStartedAt,\n\t\t\tDuration:               time.Hour,\n\t\t\tNodeExecutionCreatedAt: &nodeCreatedAt,\n\t\t\tNodeExecutionUpdatedAt: &nodePlanUpdatedAt,\n\t\t})\n\t\tnodeExecutions = append(nodeExecutions, nodeExecution)\n\t}\n\n\tGlobalMock := mocket.Catcher.Reset()\n\tGlobalMock.NewMock().WithQuery(`SELECT \"node_executions\".\"id\",\"node_executions\".\"created_at\",\"node_executions\".\"updated_at\",\"node_executions\".\"deleted_at\",\"node_executions\".\"execution_project\",\"node_executions\".\"execution_domain\",\"node_executions\".\"execution_name\",\"node_executions\".\"node_id\",\"node_executions\".\"phase\",\"node_executions\".\"input_uri\",\"node_executions\".\"closure\",\"node_executions\".\"started_at\",\"node_executions\".\"node_execution_created_at\",\"node_executions\".\"node_execution_updated_at\",\"node_executions\".\"duration\",\"node_executions\".\"node_execution_metadata\",\"node_executions\".\"parent_id\",\"node_executions\".\"parent_task_execution_id\",\"node_executions\".\"error_kind\",\"node_executions\".\"error_code\",\"node_executions\".\"cache_status\",\"node_executions\".\"dynamic_workflow_remote_closure_reference\",\"node_executions\".\"internal_data\" FROM \"node_executions\" INNER JOIN executions ON node_executions.execution_project = executions.execution_project AND node_executions.execution_domain = executions.execution_domain AND node_executions.execution_name = executions.execution_name WHERE node_executions.phase = $1 LIMIT 20%`).\n\t\tWithReply(nodeExecutions)\n\n\tcollection, err := nodeExecutionRepo.List(context.Background(), interfaces.ListResourceInput{\n\t\tInlineFilters: []common.InlineFilter{\n\t\t\tgetEqualityFilter(common.NodeExecution, \"phase\", nodePhase),\n\t\t},\n\t\tLimit: 20,\n\t})\n\tassert.NoError(t, err)\n\tassert.NotEmpty(t, collection)\n\tassert.NotEmpty(t, collection.NodeExecutions)\n\tassert.Len(t, collection.NodeExecutions, 2)\n\tfor _, nodeExecution := range collection.NodeExecutions {\n\t\tassert.Equal(t, \"project\", nodeExecution.ExecutionKey.Project)\n\t\tassert.Equal(t, \"domain\", nodeExecution.ExecutionKey.Domain)\n\t\tassert.Contains(t, executionIDs, nodeExecution.ExecutionKey.Name)\n\t\tassert.Equal(t, nodePhase, nodeExecution.Phase)\n\t\tassert.Equal(t, []byte(\"closure\"), nodeExecution.Closure)\n\t\tassert.Equal(t, \"input uri\", nodeExecution.InputURI)\n\t\tassert.Equal(t, nodeStartedAt, *nodeExecution.StartedAt)\n\t\tassert.Equal(t, time.Hour, nodeExecution.Duration)\n\t}\n}\n\nfunc TestListNodeExecutions_Order(t *testing.T) {\n\tnodeExecutionRepo := NewNodeExecutionRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\tnodeExecutions := make([]map[string]interface{}, 0)\n\n\tGlobalMock := mocket.Catcher.Reset()\n\t// Only match on queries that include ordering by project\n\tmockQuery := GlobalMock.NewMock()\n\tmockQuery.WithQuery(`project desc`)\n\tmockQuery.WithReply(nodeExecutions)\n\n\tsortParameter, _ := common.NewSortParameter(admin.Sort{\n\t\tDirection: admin.Sort_DESCENDING,\n\t\tKey:       \"project\",\n\t})\n\t_, err := nodeExecutionRepo.List(context.Background(), interfaces.ListResourceInput{\n\t\tSortParameter: sortParameter,\n\t\tInlineFilters: []common.InlineFilter{\n\t\t\tgetEqualityFilter(common.NodeExecution, \"phase\", nodePhase),\n\t\t},\n\t\tLimit: 20,\n\t})\n\tassert.NoError(t, err)\n\tassert.True(t, mockQuery.Triggered)\n}\n\nfunc TestListNodeExecutions_MissingParameters(t *testing.T) {\n\tnodeExecutionRepo := NewNodeExecutionRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\t_, err := nodeExecutionRepo.List(context.Background(), interfaces.ListResourceInput{\n\t\tInlineFilters: []common.InlineFilter{\n\t\t\tgetEqualityFilter(common.NodeExecution, \"execution_id\", \"1234\"),\n\t\t},\n\t})\n\tassert.EqualError(t, err, \"missing and/or invalid parameters: limit\")\n\n\t_, err = nodeExecutionRepo.List(context.Background(), interfaces.ListResourceInput{\n\t\tLimit: 20,\n\t})\n\tassert.EqualError(t, err, \"missing and/or invalid parameters: filters\")\n}\n\nfunc TestListNodeExecutionsForExecution(t *testing.T) {\n\tnodeExecutionRepo := NewNodeExecutionRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\n\tnodeExecutions := make([]map[string]interface{}, 0)\n\tnodeExecution := getMockNodeExecutionResponseFromDb(models.NodeExecution{\n\t\tNodeExecutionKey: models.NodeExecutionKey{\n\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\tProject: \"project\",\n\t\t\t\tDomain:  \"domain\",\n\t\t\t\tName:    \"1\",\n\t\t\t},\n\t\t},\n\t\tPhase:                 nodePhase,\n\t\tClosure:               []byte(\"closure\"),\n\t\tInputURI:              \"input uri\",\n\t\tStartedAt:             &nodeStartedAt,\n\t\tDuration:              time.Hour,\n\t\tNodeExecutionMetadata: []byte(\"NodeExecutionMetadata\"),\n\t})\n\tnodeExecutions = append(nodeExecutions, nodeExecution)\n\n\tGlobalMock := mocket.Catcher.Reset()\n\tquery := `SELECT \"node_executions\".\"id\",\"node_executions\".\"created_at\",\"node_executions\".\"updated_at\",\"node_executions\".\"deleted_at\",\"node_executions\".\"execution_project\",\"node_executions\".\"execution_domain\",\"node_executions\".\"execution_name\",\"node_executions\".\"node_id\",\"node_executions\".\"phase\",\"node_executions\".\"input_uri\",\"node_executions\".\"closure\",\"node_executions\".\"started_at\",\"node_executions\".\"node_execution_created_at\",\"node_executions\".\"node_execution_updated_at\",\"node_executions\".\"duration\",\"node_executions\".\"node_execution_metadata\",\"node_executions\".\"parent_id\",\"node_executions\".\"parent_task_execution_id\",\"node_executions\".\"error_kind\",\"node_executions\".\"error_code\",\"node_executions\".\"cache_status\",\"node_executions\".\"dynamic_workflow_remote_closure_reference\",\"node_executions\".\"internal_data\" FROM \"node_executions\" INNER JOIN executions ON node_executions.execution_project = executions.execution_project AND node_executions.execution_domain = executions.execution_domain AND node_executions.execution_name = executions.execution_name WHERE node_executions.phase = $1 AND executions.execution_name = $2 LIMIT 20%`\n\tGlobalMock.NewMock().WithQuery(query).WithReply(nodeExecutions)\n\n\tcollection, err := nodeExecutionRepo.List(context.Background(), interfaces.ListResourceInput{\n\t\tInlineFilters: []common.InlineFilter{\n\t\t\tgetEqualityFilter(common.NodeExecution, \"phase\", nodePhase),\n\t\t\tgetEqualityFilter(common.Execution, \"name\", \"execution_name\"),\n\t\t},\n\n\t\tLimit: 20,\n\t})\n\tassert.NoError(t, err)\n\tassert.NotEmpty(t, collection)\n\tassert.NotEmpty(t, collection.NodeExecutions)\n\tassert.Len(t, collection.NodeExecutions, 1)\n\tfor _, nodeExecution := range collection.NodeExecutions {\n\t\tassert.Equal(t, \"project\", nodeExecution.ExecutionKey.Project)\n\t\tassert.Equal(t, \"domain\", nodeExecution.ExecutionKey.Domain)\n\t\tassert.Equal(t, \"1\", nodeExecution.ExecutionKey.Name)\n\t\tassert.Equal(t, nodePhase, nodeExecution.Phase)\n\t\tassert.Equal(t, []byte(\"closure\"), nodeExecution.Closure)\n\t\tassert.Equal(t, \"input uri\", nodeExecution.InputURI)\n\t\tassert.Equal(t, nodeStartedAt, *nodeExecution.StartedAt)\n\t\tassert.Equal(t, time.Hour, nodeExecution.Duration)\n\t\tassert.Equal(t, []byte(\"NodeExecutionMetadata\"), nodeExecution.NodeExecutionMetadata)\n\t\tassert.Empty(t, nodeExecution.ChildNodeExecutions)\n\t\tassert.Empty(t, nodeExecution.ParentID)\n\t}\n}\n\nfunc TestNodeExecutionExists(t *testing.T) {\n\tnodeExecutionRepo := NewNodeExecutionRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\tid := uint(10)\n\texpectedNodeExecution := models.NodeExecution{\n\t\tNodeExecutionKey: models.NodeExecutionKey{\n\t\t\tNodeID: \"1\",\n\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\tProject: \"project\",\n\t\t\t\tDomain:  \"domain\",\n\t\t\t\tName:    \"1\",\n\t\t\t},\n\t\t},\n\t\tBaseModel: models.BaseModel{\n\t\t\tID: id,\n\t\t},\n\t\tPhase:   nodePhase,\n\t\tClosure: []byte(\"closure\"),\n\t}\n\n\tnodeExecutions := make([]map[string]interface{}, 0)\n\tnodeExecution := getMockNodeExecutionResponseFromDb(expectedNodeExecution)\n\tnodeExecutions = append(nodeExecutions, nodeExecution)\n\n\tGlobalMock := mocket.Catcher.Reset()\n\tGlobalMock.NewMock().WithQuery(\n\t\t`SELECT \"id\" FROM \"node_executions\" WHERE \"node_executions\".\"execution_project\" = $1 AND \"node_executions\".\"execution_domain\" = $2 AND \"node_executions\".\"execution_name\" = $3 AND \"node_executions\".\"node_id\" = $4 LIMIT 1`).WithReply(nodeExecutions)\n\texists, err := nodeExecutionRepo.Exists(context.Background(), interfaces.NodeExecutionResource{\n\t\tNodeExecutionIdentifier: core.NodeExecutionIdentifier{\n\t\t\tNodeId: \"1\",\n\t\t\tExecutionId: &core.WorkflowExecutionIdentifier{\n\t\t\t\tProject: \"execution_project\",\n\t\t\t\tDomain:  \"execution_domain\",\n\t\t\t\tName:    \"execution_name\",\n\t\t\t},\n\t\t},\n\t})\n\tassert.NoError(t, err)\n\tassert.True(t, exists)\n}\n\nfunc TestCountNodeExecutions(t *testing.T) {\n\tnodeExecutionRepo := NewNodeExecutionRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\n\tGlobalMock := mocket.Catcher.Reset()\n\tGlobalMock.NewMock().WithQuery(\n\t\t`SELECT count(*) FROM \"node_executions\"`).WithReply([]map[string]interface{}{{\"rows\": 2}})\n\n\tcount, err := nodeExecutionRepo.Count(context.Background(), interfaces.CountResourceInput{})\n\tassert.NoError(t, err)\n\tassert.Equal(t, int64(2), count)\n}\n\nfunc TestCountNodeExecutions_Filters(t *testing.T) {\n\tnodeExecutionRepo := NewNodeExecutionRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\n\tGlobalMock := mocket.Catcher.Reset()\n\tGlobalMock.NewMock().WithQuery(\n\t\t`SELECT count(*) FROM \"node_executions\" INNER JOIN executions ON node_executions.execution_project = executions.execution_project AND node_executions.execution_domain = executions.execution_domain AND node_executions.execution_name = executions.execution_name WHERE node_executions.phase = $1 AND \"node_executions\".\"error_code\" IS NULL`).WithReply([]map[string]interface{}{{\"rows\": 3}})\n\n\tcount, err := nodeExecutionRepo.Count(context.Background(), interfaces.CountResourceInput{\n\t\tInlineFilters: []common.InlineFilter{\n\t\t\tgetEqualityFilter(common.NodeExecution, \"phase\", core.NodeExecution_FAILED.String()),\n\t\t},\n\t\tMapFilters: []common.MapFilter{\n\t\t\tcommon.NewMapFilter(map[string]interface{}{\n\t\t\t\t\"\\\"node_executions\\\".\\\"error_code\\\"\": nil,\n\t\t\t}),\n\t\t},\n\t})\n\tassert.NoError(t, err)\n\tassert.Equal(t, int64(3), count)\n}\n", "package gormimpl\n\nimport (\n\t\"context\"\n\t\"errors\"\n\n\tflyteAdminErrors \"github.com/flyteorg/flyteadmin/pkg/errors\"\n\t\"google.golang.org/grpc/codes\"\n\n\t\"github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/admin\"\n\t\"github.com/flyteorg/flytestdlib/promutils\"\n\n\t\"gorm.io/gorm\"\n\n\tflyteAdminDbErrors \"github.com/flyteorg/flyteadmin/pkg/repositories/errors\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/interfaces\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/models\"\n)\n\ntype ProjectRepo struct {\n\tdb               *gorm.DB\n\terrorTransformer flyteAdminDbErrors.ErrorTransformer\n\tmetrics          gormMetrics\n}\n\nfunc (r *ProjectRepo) Create(ctx context.Context, project models.Project) error {\n\ttimer := r.metrics.CreateDuration.Start()\n\ttx := r.db.Omit(\"id\").Create(&project)\n\ttimer.Stop()\n\tif tx.Error != nil {\n\t\treturn r.errorTransformer.ToFlyteAdminError(tx.Error)\n\t}\n\treturn nil\n}\n\nfunc (r *ProjectRepo) Get(ctx context.Context, projectID string) (models.Project, error) {\n\tvar project models.Project\n\ttimer := r.metrics.GetDuration.Start()\n\ttx := r.db.Where(&models.Project{\n\t\tIdentifier: projectID,\n\t}).Take(&project)\n\ttimer.Stop()\n\tif errors.Is(tx.Error, gorm.ErrRecordNotFound) {\n\t\treturn models.Project{}, flyteAdminErrors.NewFlyteAdminErrorf(codes.NotFound, \"project [%s] not found\", projectID)\n\t}\n\n\tif tx.Error != nil {\n\t\treturn models.Project{}, r.errorTransformer.ToFlyteAdminError(tx.Error)\n\t}\n\n\treturn project, nil\n}\n\nfunc (r *ProjectRepo) List(ctx context.Context, input interfaces.ListResourceInput) ([]models.Project, error) {\n\tvar projects []models.Project\n\n\ttx := r.db.Offset(input.Offset)\n\tif input.Limit != 0 {\n\t\ttx = tx.Limit(input.Limit)\n\t}\n\n\t// Apply filters\n\t// If no filter provided, default to filtering out archived projects\n\tif len(input.InlineFilters) == 0 && len(input.MapFilters) == 0 {\n\t\ttx = tx.Where(\"state != ?\", int32(admin.Project_ARCHIVED))\n\t} else {\n\t\tvar err error\n\t\ttx, err = applyFilters(tx, input.InlineFilters, input.MapFilters)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\t// Apply sort ordering\n\tif input.SortParameter != nil {\n\t\ttx = tx.Order(input.SortParameter.GetGormOrderExpr())\n\t}\n\n\ttimer := r.metrics.ListDuration.Start()\n\ttx.Find(&projects)\n\ttimer.Stop()\n\n\tif tx.Error != nil {\n\t\treturn nil, r.errorTransformer.ToFlyteAdminError(tx.Error)\n\t}\n\treturn projects, nil\n}\n\nfunc NewProjectRepo(db *gorm.DB, errorTransformer flyteAdminDbErrors.ErrorTransformer,\n\tscope promutils.Scope) interfaces.ProjectRepoInterface {\n\tmetrics := newMetrics(scope)\n\treturn &ProjectRepo{\n\t\tdb:               db,\n\t\terrorTransformer: errorTransformer,\n\t\tmetrics:          metrics,\n\t}\n}\n\nfunc (r *ProjectRepo) UpdateProject(ctx context.Context, projectUpdate models.Project) error {\n\t// Use gorm client to update the two fields that are changed.\n\twriteTx := r.db.Model(&projectUpdate).Updates(projectUpdate)\n\n\t// Return error if applies.\n\tif writeTx.Error != nil {\n\t\treturn r.errorTransformer.ToFlyteAdminError(writeTx.Error)\n\t}\n\n\treturn nil\n}\n", "package gormimpl\n\nimport (\n\t\"context\"\n\t\"testing\"\n\n\tmocket \"github.com/Selvatico/go-mocket\"\n\t\"github.com/flyteorg/flyteadmin/pkg/common\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/errors\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/interfaces\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/models\"\n\t\"github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/admin\"\n\tmockScope \"github.com/flyteorg/flytestdlib/promutils\"\n\t\"github.com/stretchr/testify/assert\"\n)\n\nvar alphabeticalSortParam, _ = common.NewSortParameter(admin.Sort{\n\tDirection: admin.Sort_ASCENDING,\n\tKey:       \"identifier\",\n})\n\nfunc TestCreateProject(t *testing.T) {\n\tprojectRepo := NewProjectRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\tGlobalMock := mocket.Catcher.Reset()\n\n\tquery := GlobalMock.NewMock()\n\tGlobalMock.Logging = true\n\tquery.WithQuery(\n\t\t`INSERT INTO \"projects\" (\"created_at\",\"updated_at\",\"deleted_at\",\"name\",\"description\",\"labels\",\"state\",\"identifier\") VALUES ($1,$2,$3,$4,$5,$6,$7,$8)`)\n\n\tactiveState := int32(admin.Project_ACTIVE)\n\terr := projectRepo.Create(context.Background(), models.Project{\n\t\tIdentifier:  \"proj\",\n\t\tName:        \"proj\",\n\t\tDescription: \"projDescription\",\n\t\tState:       &activeState,\n\t})\n\tassert.NoError(t, err)\n\tassert.True(t, query.Triggered)\n}\n\nfunc TestGetProject(t *testing.T) {\n\tprojectRepo := NewProjectRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\tGlobalMock := mocket.Catcher.Reset()\n\n\tresponse := make(map[string]interface{})\n\tresponse[\"identifier\"] = \"project_id\"\n\tresponse[\"name\"] = \"project_name\"\n\tresponse[\"description\"] = \"project_description\"\n\tresponse[\"state\"] = admin.Project_ACTIVE\n\n\toutput, err := projectRepo.Get(context.Background(), \"project_id\")\n\tassert.Empty(t, output)\n\tassert.EqualError(t, err, \"project [project_id] not found\")\n\n\tquery := GlobalMock.NewMock()\n\tGlobalMock.Logging = true\n\tquery.WithQuery(`SELECT * FROM \"projects\" WHERE \"projects\".\"identifier\" = $1 LIMIT 1`).WithReply(\n\t\t[]map[string]interface{}{\n\t\t\tresponse,\n\t\t})\n\n\toutput, err = projectRepo.Get(context.Background(), \"project_id\")\n\tassert.Nil(t, err)\n\tassert.Equal(t, \"project_id\", output.Identifier)\n\tassert.Equal(t, \"project_name\", output.Name)\n\tassert.Equal(t, \"project_description\", output.Description)\n\tassert.Equal(t, int32(admin.Project_ACTIVE), *output.State)\n}\n\nfunc testListProjects(input interfaces.ListResourceInput, sql string, t *testing.T) {\n\tprojectRepo := NewProjectRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\tprojects := make([]map[string]interface{}, 1)\n\tfooProject := make(map[string]interface{})\n\tfooProject[\"identifier\"] = \"foo\"\n\tfooProject[\"name\"] = \"foo =)\"\n\tfooProject[\"description\"] = \"foo description\"\n\tfooProject[\"state\"] = admin.Project_ACTIVE\n\tprojects[0] = fooProject\n\n\tGlobalMock := mocket.Catcher.Reset()\n\tGlobalMock.Logging = true\n\tGlobalMock.NewMock().WithQuery(sql).\n\t\tWithReply(projects)\n\n\toutput, err := projectRepo.List(context.Background(), input)\n\tassert.Nil(t, err)\n\tassert.Len(t, output, 1)\n\tassert.Equal(t, \"foo\", output[0].Identifier)\n\tassert.Equal(t, \"foo =)\", output[0].Name)\n\tassert.Equal(t, \"foo description\", output[0].Description)\n\tassert.Equal(t, int32(admin.Project_ACTIVE), *output[0].State)\n}\n\nfunc TestListProjects(t *testing.T) {\n\tfilter, err := common.NewSingleValueFilter(common.Project, common.Equal, \"name\", \"foo\")\n\tassert.Nil(t, err)\n\ttestListProjects(interfaces.ListResourceInput{\n\t\tOffset:        0,\n\t\tLimit:         1,\n\t\tInlineFilters: []common.InlineFilter{filter},\n\t\tSortParameter: alphabeticalSortParam,\n\t}, `SELECT * FROM \"projects\" WHERE name = $1 ORDER BY identifier asc LIMIT 1`, t)\n}\n\nfunc TestListProjects_NoFilters(t *testing.T) {\n\ttestListProjects(interfaces.ListResourceInput{\n\t\tOffset:        0,\n\t\tLimit:         1,\n\t\tSortParameter: alphabeticalSortParam,\n\t}, `SELECT * FROM \"projects\" WHERE state != $1 ORDER BY identifier asc`, t)\n}\n\nfunc TestListProjects_NoLimit(t *testing.T) {\n\ttestListProjects(interfaces.ListResourceInput{\n\t\tOffset:        0,\n\t\tSortParameter: alphabeticalSortParam,\n\t}, `SELECT * FROM \"projects\" WHERE state != $1 ORDER BY identifier asc`, t)\n}\n\nfunc TestUpdateProject(t *testing.T) {\n\tprojectRepo := NewProjectRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\tGlobalMock := mocket.Catcher.Reset()\n\n\tquery := GlobalMock.NewMock()\n\tGlobalMock.Logging = true\n\tquery.WithQuery(`UPDATE \"projects\" SET \"updated_at\"=$1,\"identifier\"=$2,\"name\"=$3,\"description\"=$4,\"state\"=$5 WHERE \"identifier\" = $6`)\n\n\tactiveState := int32(admin.Project_ACTIVE)\n\terr := projectRepo.UpdateProject(context.Background(), models.Project{\n\t\tIdentifier:  \"project_id\",\n\t\tName:        \"project_name\",\n\t\tDescription: \"project_description\",\n\t\tState:       &activeState,\n\t})\n\tassert.Nil(t, err)\n\tassert.True(t, query.Triggered)\n}\n", "package gormimpl\n\nimport (\n\t\"context\"\n\t\"testing\"\n\n\t\"gorm.io/gorm\"\n\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/interfaces\"\n\n\tmocket \"github.com/Selvatico/go-mocket\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/errors\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/models\"\n\tmockScope \"github.com/flyteorg/flytestdlib/promutils\"\n\t\"github.com/stretchr/testify/assert\"\n)\n\nconst resourceTestWorkflowName = \"workflow\"\nconst resourceTypeStr = \"resource-type\"\n\nfunc TestCreateWorkflowAttributes(t *testing.T) {\n\tresourceRepo := NewResourceRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\tGlobalMock := mocket.Catcher.Reset()\n\n\tquery := GlobalMock.NewMock()\n\tGlobalMock.Logging = true\n\tquery.WithQuery(\n\t\t`INSERT INTO \"resources\" (\"created_at\",\"updated_at\",\"deleted_at\",\"project\",\"domain\",\"workflow\",\"launch_plan\",\"resource_type\",\"priority\",\"attributes\") VALUES ($1,$2,$3,$4,$5,$6,$7,$8,$9,$10) RETURNING \"id\"`)\n\n\terr := resourceRepo.CreateOrUpdate(context.Background(), models.Resource{\n\t\tProject:      \"project\",\n\t\tDomain:       \"domain\",\n\t\tWorkflow:     resourceTestWorkflowName,\n\t\tResourceType: \"resource\",\n\t\tPriority:     models.ResourcePriorityLaunchPlanLevel,\n\t\tAttributes:   []byte(\"attrs\"),\n\t})\n\tassert.NoError(t, err)\n\tassert.True(t, query.Triggered)\n}\n\nfunc getMockResourceResponseFromDb(expected models.Resource) map[string]interface{} {\n\tmetadata := make(map[string]interface{})\n\tmetadata[\"resource_type\"] = expected.ResourceType\n\tmetadata[\"project\"] = expected.Project\n\tmetadata[\"domain\"] = expected.Domain\n\tmetadata[\"priority\"] = 2\n\treturn metadata\n}\n\nfunc TestUpdateWorkflowAttributes_WithExisting(t *testing.T) {\n\tresourceRepo := NewResourceRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\tresults := make([]map[string]interface{}, 0)\n\tmetadata := getMockResourceResponseFromDb(models.Resource{\n\t\tResourceType: resourceType.String(),\n\t\tProject:      project,\n\t\tDomain:       domain,\n\t\tPriority:     2,\n\t})\n\tresults = append(results, metadata)\n\n\tGlobalMock := mocket.Catcher.Reset()\n\tGlobalMock.Logging = true\n\n\tmockSelectQuery := GlobalMock.NewMock()\n\tmockSelectQuery.WithQuery(\n\t\t`SELECT * FROM \"resources\" WHERE \"resources\".\"project\" = $1 AND \"resources\".\"domain\" = $2 AND \"resources\".\"resource_type\" = $3 AND \"resources\".\"priority\" = $4 ORDER BY \"resources\".\"id\" LIMIT 1`).WithReply(results)\n\n\tmockSaveQuery := GlobalMock.NewMock()\n\tmockSaveQuery.WithQuery(\n\t\t`INSERT INTO \"resources\" (\"created_at\",\"updated_at\",\"deleted_at\",\"project\",\"domain\",\"workflow\",\"launch_plan\",\"resource_type\",\"priority\",\"attributes\") VALUES ($1,$2,$3,$4,$5,$6,$7,$8,$9,$10)`)\n\n\terr := resourceRepo.CreateOrUpdate(context.Background(), models.Resource{\n\t\tResourceType: resourceType.String(),\n\t\tProject:      project,\n\t\tDomain:       domain,\n\t\tPriority:     2,\n\t})\n\tassert.NoError(t, err)\n\tassert.True(t, mockSelectQuery.Triggered)\n\tassert.True(t, mockSaveQuery.Triggered)\n}\n\nfunc TestGetWorkflowAttributes(t *testing.T) {\n\tresourceRepo := NewResourceRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\tGlobalMock := mocket.Catcher.Reset()\n\tGlobalMock.Logging = true\n\tresponse := make(map[string]interface{})\n\tresponse[\"project\"] = \"project\"\n\tresponse[\"domain\"] = \"domain\"\n\tresponse[\"workflow\"] = resourceTestWorkflowName\n\tresponse[\"resource_type\"] = resourceTypeStr\n\tresponse[\"attributes\"] = []byte(\"attrs\")\n\n\tquery := GlobalMock.NewMock()\n\tquery.WithQuery(`SELECT * FROM \"resources\" WHERE resource_type = $1 AND domain IN ($2,$3) AND project IN ($4,$5) AND workflow IN ($6,$7) AND launch_plan IN ($8) ORDER BY priority desc,\"resources\".\"id\" LIMIT 1`).WithReply(\n\t\t[]map[string]interface{}{\n\t\t\tresponse,\n\t\t})\n\n\toutput, err := resourceRepo.Get(context.Background(), interfaces.ResourceID{Project: \"project\", Domain: \"domain\", Workflow: \"workflow\", ResourceType: \"resource\"})\n\tassert.Nil(t, err)\n\tassert.Equal(t, \"project\", output.Project)\n\tassert.Equal(t, \"domain\", output.Domain)\n\tassert.Equal(t, \"workflow\", output.Workflow)\n\tassert.Equal(t, resourceTypeStr, output.ResourceType)\n\tassert.Equal(t, []byte(\"attrs\"), output.Attributes)\n}\n\nfunc TestProjectDomainAttributes(t *testing.T) {\n\tresourceRepo := NewResourceRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\tGlobalMock := mocket.Catcher.Reset()\n\tGlobalMock.Logging = true\n\tresponse := make(map[string]interface{})\n\tresponse[project] = project\n\tresponse[domain] = domain\n\tresponse[\"resource_type\"] = resourceTypeStr\n\tresponse[\"attributes\"] = []byte(\"attrs\")\n\n\tquery := GlobalMock.NewMock()\n\tquery.WithQuery(`SELECT * FROM \"resources\" WHERE resource_type = $1 AND domain IN ($2,$3) AND project IN ($4,$5) AND workflow IN ($6) AND launch_plan IN ($7) ORDER BY priority desc,\"resources\".\"id\" LIMIT 1`).WithReply(\n\t\t[]map[string]interface{}{\n\t\t\tresponse,\n\t\t})\n\n\toutput, err := resourceRepo.Get(context.Background(), interfaces.ResourceID{Project: \"project\", Domain: \"domain\", ResourceType: \"resource\"})\n\tassert.Nil(t, err)\n\tassert.Equal(t, project, output.Project)\n\tassert.Equal(t, domain, output.Domain)\n\tassert.Equal(t, \"\", output.Workflow)\n\tassert.Equal(t, \"resource-type\", output.ResourceType)\n\tassert.Equal(t, []byte(\"attrs\"), output.Attributes)\n}\n\nfunc TestProjectLevelAttributes(t *testing.T) {\n\tresourceRepo := NewResourceRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\tGlobalMock := mocket.Catcher.Reset()\n\tGlobalMock.Logging = true\n\tresponse := make(map[string]interface{})\n\tresponse[project] = project\n\tresponse[domain] = \"\"\n\tresponse[\"resource_type\"] = \"resource-type\"\n\tresponse[\"attributes\"] = []byte(\"attrs\")\n\n\tquery := GlobalMock.NewMock()\n\tquery.WithQuery(`SELECT * FROM \"resources\" WHERE resource_type = $1 AND domain = '' AND project = $2 AND workflow = '' AND launch_plan = '' ORDER BY priority desc,\"resources\".\"id\" LIMIT 1`).WithReply(\n\t\t[]map[string]interface{}{\n\t\t\tresponse,\n\t\t})\n\n\toutput, err := resourceRepo.GetProjectLevel(context.Background(), interfaces.ResourceID{Project: \"project\", Domain: \"\", ResourceType: \"resource\"})\n\tassert.Nil(t, err)\n\tassert.Equal(t, project, output.Project)\n\tassert.Equal(t, \"\", output.Domain)\n\tassert.Equal(t, \"\", output.Workflow)\n\tassert.Equal(t, \"resource-type\", output.ResourceType)\n\tassert.Equal(t, []byte(\"attrs\"), output.Attributes)\n\n\t// Must have a project defined\n\t_, err = resourceRepo.GetProjectLevel(context.Background(), interfaces.ResourceID{Project: \"\", Domain: \"\", ResourceType: \"resource\"})\n\tassert.Error(t, err)\n}\n\nfunc TestGetRawWorkflowAttributes(t *testing.T) {\n\tresourceRepo := NewResourceRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\tGlobalMock := mocket.Catcher.Reset()\n\tGlobalMock.Logging = true\n\tresponse := make(map[string]interface{})\n\tresponse[project] = project\n\tresponse[domain] = domain\n\tresponse[\"workflow\"] = resourceTestWorkflowName\n\tresponse[\"resource_type\"] = \"resource\"\n\tresponse[\"launch_plan\"] = \"launch_plan\"\n\tresponse[\"attributes\"] = []byte(\"attrs\")\n\n\tquery := GlobalMock.NewMock()\n\tquery.WithQuery(`SELECT * FROM \"resources\" WHERE \"resources\".\"project\" = $1 AND \"resources\".\"domain\" = $2 AND \"resources\".\"workflow\" = $3 AND \"resources\".\"launch_plan\" = $4 AND \"resources\".\"resource_type\" = $5 ORDER BY \"resources\".\"id\" LIMIT 1`).WithReply(\n\t\t[]map[string]interface{}{\n\t\t\tresponse,\n\t\t})\n\n\toutput, err := resourceRepo.GetRaw(context.Background(), interfaces.ResourceID{Project: \"project\", Domain: \"domain\", Workflow: \"workflow\", LaunchPlan: \"launch_plan\", ResourceType: \"resource\"})\n\tassert.Nil(t, err)\n\tassert.Equal(t, project, output.Project)\n\tassert.Equal(t, domain, output.Domain)\n\tassert.Equal(t, \"workflow\", output.Workflow)\n\tassert.Equal(t, \"launch_plan\", output.LaunchPlan)\n\tassert.Equal(t, \"resource\", output.ResourceType)\n\tassert.Equal(t, []byte(\"attrs\"), output.Attributes)\n}\n\nfunc TestDeleteWorkflowAttributes(t *testing.T) {\n\tresourceRepo := NewResourceRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\tGlobalMock := mocket.Catcher.Reset()\n\tGlobalMock.Logging = true\n\tquery := GlobalMock.NewMock()\n\tfakeResponse := query.WithQuery(\n\t\t`DELETE FROM \"resources\" WHERE \"resources\".\"project\" = $1 AND \"resources\".\"domain\" = $2 AND \"resources\".\"workflow\" = $3 AND \"resources\".\"launch_plan\" = $4 AND \"resources\".\"resource_type\" = $5`)\n\n\terr := resourceRepo.Delete(context.Background(), interfaces.ResourceID{Project: \"project\", Domain: \"domain\", Workflow: \"workflow\", LaunchPlan: \"launch_plan\", ResourceType: \"resource\"})\n\tassert.Nil(t, err)\n\tassert.True(t, fakeResponse.Triggered)\n}\n\nfunc TestListAll(t *testing.T) {\n\tresourceRepo := NewResourceRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\tGlobalMock := mocket.Catcher.Reset()\n\tGlobalMock.Logging = true\n\n\tquery := GlobalMock.NewMock()\n\n\tresponse := make(map[string]interface{})\n\tresponse[project] = project\n\tresponse[domain] = domain\n\tresponse[\"workflow\"] = resourceTestWorkflowName\n\tresponse[\"resource_type\"] = \"resource\"\n\tresponse[\"launch_plan\"] = \"launch_plan\"\n\tresponse[\"attributes\"] = []byte(\"attrs\")\n\n\tfakeResponse := query.WithQuery(`SELECT * FROM \"resources\" WHERE \"resources\".\"resource_type\" = $1 ORDER BY priority desc`).WithReply(\n\t\t[]map[string]interface{}{response})\n\toutput, err := resourceRepo.ListAll(context.Background(), \"resource\")\n\tassert.Nil(t, err)\n\tassert.Len(t, output, 1)\n\tassert.Equal(t, project, output[0].Project)\n\tassert.Equal(t, domain, output[0].Domain)\n\tassert.Equal(t, \"workflow\", output[0].Workflow)\n\tassert.Equal(t, \"launch_plan\", output[0].LaunchPlan)\n\tassert.Equal(t, \"resource\", output[0].ResourceType)\n\tassert.Equal(t, []byte(\"attrs\"), output[0].Attributes)\n\tassert.True(t, fakeResponse.Triggered)\n}\n\nfunc TestGetError(t *testing.T) {\n\tresourceRepo := NewResourceRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\tGlobalMock := mocket.Catcher.Reset()\n\tGlobalMock.Logging = true\n\n\tquery := GlobalMock.NewMock()\n\tquery.WithQuery(`SELECT * FROM \"resources\" WHERE resource_type = $1 AND domain IN ($2,$3) AND project IN ($4,$5) AND workflow IN ($6,$7) AND launch_plan IN ($8) ORDER BY priority desc,\"resources\".\"id\" LIMIT 1`).WithError(gorm.ErrRecordNotFound)\n\n\toutput, err := resourceRepo.Get(context.Background(), interfaces.ResourceID{Project: \"project\", Domain: \"domain\", Workflow: \"workflow\", ResourceType: \"resource\"})\n\tassert.Error(t, err)\n\tassert.Equal(t, \"\", output.Project)\n\tassert.Equal(t, \"\", output.Domain)\n\tassert.Equal(t, \"\", output.Workflow)\n}\n", "package gormimpl\n\nimport (\n\t\"context\"\n\t\"errors\"\n\n\tadminerrors \"github.com/flyteorg/flyteadmin/pkg/errors\"\n\tflyteAdminDbErrors \"github.com/flyteorg/flyteadmin/pkg/repositories/errors\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/interfaces\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/models\"\n\n\t\"github.com/flyteorg/flytestdlib/promutils\"\n\n\t\"google.golang.org/grpc/codes\"\n\n\t\"gorm.io/gorm\"\n)\n\n// SignalRepo is an implementation of SignalRepoInterface.\ntype SignalRepo struct {\n\tdb               *gorm.DB\n\terrorTransformer flyteAdminDbErrors.ErrorTransformer\n\tmetrics          gormMetrics\n}\n\n// Get retrieves a signal model from the database store.\nfunc (s *SignalRepo) Get(ctx context.Context, input models.SignalKey) (models.Signal, error) {\n\tvar signal models.Signal\n\ttimer := s.metrics.GetDuration.Start()\n\ttx := s.db.Where(&models.Signal{\n\t\tSignalKey: input,\n\t}).Take(&signal)\n\ttimer.Stop()\n\tif errors.Is(tx.Error, gorm.ErrRecordNotFound) {\n\t\treturn models.Signal{}, adminerrors.NewFlyteAdminError(codes.NotFound, \"signal does not exist\")\n\t}\n\tif tx.Error != nil {\n\t\treturn models.Signal{}, s.errorTransformer.ToFlyteAdminError(tx.Error)\n\t}\n\treturn signal, nil\n}\n\n// GetOrCreate returns a signal if it already exists, if not it creates a new one given the input\nfunc (s *SignalRepo) GetOrCreate(ctx context.Context, input *models.Signal) error {\n\ttimer := s.metrics.CreateDuration.Start()\n\ttx := s.db.FirstOrCreate(&input, input)\n\ttimer.Stop()\n\tif tx.Error != nil {\n\t\treturn s.errorTransformer.ToFlyteAdminError(tx.Error)\n\t}\n\treturn nil\n}\n\n// List fetches all signals that match the provided input\nfunc (s *SignalRepo) List(ctx context.Context, input interfaces.ListResourceInput) ([]models.Signal, error) {\n\t// First validate input.\n\tif err := ValidateListInput(input); err != nil {\n\t\treturn nil, err\n\t}\n\tvar signals []models.Signal\n\ttx := s.db.Limit(input.Limit).Offset(input.Offset)\n\n\t// Apply filters\n\ttx, err := applyFilters(tx, input.InlineFilters, input.MapFilters)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\t// Apply sort ordering.\n\tif input.SortParameter != nil {\n\t\ttx = tx.Order(input.SortParameter.GetGormOrderExpr())\n\t}\n\ttimer := s.metrics.ListDuration.Start()\n\ttx.Find(&signals)\n\ttimer.Stop()\n\tif tx.Error != nil {\n\t\treturn nil, s.errorTransformer.ToFlyteAdminError(tx.Error)\n\t}\n\n\treturn signals, nil\n}\n\n// Update sets the value field on the specified signal model\nfunc (s *SignalRepo) Update(ctx context.Context, input models.SignalKey, value []byte) error {\n\tsignal := models.Signal{\n\t\tSignalKey: input,\n\t\tValue:     value,\n\t}\n\n\ttimer := s.metrics.GetDuration.Start()\n\ttx := s.db.Model(&signal).Select(\"value\").Updates(signal)\n\ttimer.Stop()\n\tif tx.Error != nil {\n\t\treturn s.errorTransformer.ToFlyteAdminError(tx.Error)\n\t}\n\tif tx.RowsAffected == 0 {\n\t\treturn adminerrors.NewFlyteAdminError(codes.NotFound, \"signal does not exist\")\n\t}\n\treturn nil\n}\n\n// Returns an instance of SignalRepoInterface\nfunc NewSignalRepo(\n\tdb *gorm.DB, errorTransformer flyteAdminDbErrors.ErrorTransformer, scope promutils.Scope) interfaces.SignalRepoInterface {\n\tmetrics := newMetrics(scope)\n\treturn &SignalRepo{\n\t\tdb:               db,\n\t\terrorTransformer: errorTransformer,\n\t\tmetrics:          metrics,\n\t}\n}\n", "package gormimpl\n\nimport (\n\t\"context\"\n\t\"errors\"\n\n\t\"github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/core\"\n\n\t\"github.com/flyteorg/flytestdlib/promutils\"\n\n\tflyteAdminDbErrors \"github.com/flyteorg/flyteadmin/pkg/repositories/errors\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/interfaces\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/models\"\n\t\"gorm.io/gorm\"\n)\n\n// Implementation of TaskExecutionInterface.\ntype TaskExecutionRepo struct {\n\tdb               *gorm.DB\n\terrorTransformer flyteAdminDbErrors.ErrorTransformer\n\tmetrics          gormMetrics\n}\n\nfunc (r *TaskExecutionRepo) Create(ctx context.Context, input models.TaskExecution) error {\n\ttimer := r.metrics.CreateDuration.Start()\n\ttx := r.db.Omit(\"id\").Create(&input)\n\ttimer.Stop()\n\tif tx.Error != nil {\n\t\treturn r.errorTransformer.ToFlyteAdminError(tx.Error)\n\t}\n\treturn nil\n}\n\nfunc (r *TaskExecutionRepo) Get(ctx context.Context, input interfaces.GetTaskExecutionInput) (models.TaskExecution, error) {\n\tvar taskExecution models.TaskExecution\n\ttimer := r.metrics.GetDuration.Start()\n\ttx := r.db.Where(&models.TaskExecution{\n\t\tTaskExecutionKey: models.TaskExecutionKey{\n\t\t\tTaskKey: models.TaskKey{\n\t\t\t\tProject: input.TaskExecutionID.TaskId.Project,\n\t\t\t\tDomain:  input.TaskExecutionID.TaskId.Domain,\n\t\t\t\tName:    input.TaskExecutionID.TaskId.Name,\n\t\t\t\tVersion: input.TaskExecutionID.TaskId.Version,\n\t\t\t},\n\t\t\tNodeExecutionKey: models.NodeExecutionKey{\n\t\t\t\tNodeID: input.TaskExecutionID.NodeExecutionId.NodeId,\n\t\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\t\tProject: input.TaskExecutionID.NodeExecutionId.ExecutionId.Project,\n\t\t\t\t\tDomain:  input.TaskExecutionID.NodeExecutionId.ExecutionId.Domain,\n\t\t\t\t\tName:    input.TaskExecutionID.NodeExecutionId.ExecutionId.Name,\n\t\t\t\t},\n\t\t\t},\n\t\t\tRetryAttempt: &input.TaskExecutionID.RetryAttempt,\n\t\t},\n\t}).Preload(\"ChildNodeExecution\").Take(&taskExecution)\n\ttimer.Stop()\n\n\tif tx.Error != nil && errors.Is(tx.Error, gorm.ErrRecordNotFound) {\n\t\treturn models.TaskExecution{},\n\t\t\tflyteAdminDbErrors.GetMissingEntityError(\"task execution\", &core.TaskExecutionIdentifier{\n\t\t\t\tTaskId: &core.Identifier{\n\t\t\t\t\tProject: input.TaskExecutionID.TaskId.Project,\n\t\t\t\t\tDomain:  input.TaskExecutionID.TaskId.Domain,\n\t\t\t\t\tName:    input.TaskExecutionID.TaskId.Name,\n\t\t\t\t\tVersion: input.TaskExecutionID.TaskId.Version,\n\t\t\t\t},\n\t\t\t\tNodeExecutionId: &core.NodeExecutionIdentifier{\n\t\t\t\t\tNodeId: input.TaskExecutionID.NodeExecutionId.NodeId,\n\t\t\t\t\tExecutionId: &core.WorkflowExecutionIdentifier{\n\t\t\t\t\t\tProject: input.TaskExecutionID.NodeExecutionId.ExecutionId.Project,\n\t\t\t\t\t\tDomain:  input.TaskExecutionID.NodeExecutionId.ExecutionId.Domain,\n\t\t\t\t\t\tName:    input.TaskExecutionID.NodeExecutionId.ExecutionId.Name,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t})\n\t} else if tx.Error != nil {\n\t\treturn models.TaskExecution{}, r.errorTransformer.ToFlyteAdminError(tx.Error)\n\t}\n\treturn taskExecution, nil\n}\n\nfunc (r *TaskExecutionRepo) Update(ctx context.Context, execution models.TaskExecution) error {\n\ttimer := r.metrics.UpdateDuration.Start()\n\ttx := r.db.Save(&execution)\n\ttimer.Stop()\n\n\tif err := tx.Error; err != nil {\n\t\treturn r.errorTransformer.ToFlyteAdminError(err)\n\t}\n\treturn nil\n}\n\nfunc (r *TaskExecutionRepo) List(ctx context.Context, input interfaces.ListResourceInput) (interfaces.TaskExecutionCollectionOutput, error) {\n\tif err := ValidateListInput(input); err != nil {\n\t\treturn interfaces.TaskExecutionCollectionOutput{}, err\n\t}\n\n\tvar taskExecutions []models.TaskExecution\n\ttx := r.db.Limit(input.Limit).Offset(input.Offset).Preload(\"ChildNodeExecution\")\n\n\t// And add three join conditions (joining multiple tables is fine even we only filter on a subset of table attributes).\n\t// We are joining on task -> taskExec -> NodeExec -> Exec.\n\t// NOTE: the order in which the joins are called below are important because postgres will only know about certain\n\t// tables as they are joined. So we should do it in the order specified above.\n\ttx = tx.Joins(leftJoinTaskToTaskExec)\n\ttx = tx.Joins(innerJoinNodeExecToTaskExec)\n\ttx = tx.Joins(innerJoinExecToNodeExec)\n\n\t// Apply filters\n\ttx, err := applyScopedFilters(tx, input.InlineFilters, input.MapFilters)\n\tif err != nil {\n\t\treturn interfaces.TaskExecutionCollectionOutput{}, err\n\t}\n\n\t// Apply sort ordering.\n\tif input.SortParameter != nil {\n\t\ttx = tx.Order(input.SortParameter.GetGormOrderExpr())\n\t}\n\n\ttimer := r.metrics.ListDuration.Start()\n\ttx = tx.Find(&taskExecutions)\n\ttimer.Stop()\n\tif tx.Error != nil {\n\t\treturn interfaces.TaskExecutionCollectionOutput{}, r.errorTransformer.ToFlyteAdminError(tx.Error)\n\t}\n\n\treturn interfaces.TaskExecutionCollectionOutput{\n\t\tTaskExecutions: taskExecutions,\n\t}, nil\n}\n\nfunc (r *TaskExecutionRepo) Count(ctx context.Context, input interfaces.CountResourceInput) (int64, error) {\n\tvar err error\n\ttx := r.db.Model(&models.TaskExecution{})\n\n\t// Add three join conditions (joining multiple tables is fine even we only filter on a subset of table attributes).\n\t// We are joining on task -> taskExec -> NodeExec -> Exec.\n\t// NOTE: the order in which the joins are called below are important because postgres will only know about certain\n\t// tables as they are joined. So we should do it in the order specified above.\n\ttx = tx.Joins(leftJoinTaskToTaskExec)\n\ttx = tx.Joins(innerJoinNodeExecToTaskExec)\n\ttx = tx.Joins(innerJoinExecToNodeExec)\n\n\t// Apply filters\n\ttx, err = applyScopedFilters(tx, input.InlineFilters, input.MapFilters)\n\tif err != nil {\n\t\treturn 0, err\n\t}\n\n\t// Run the query\n\ttimer := r.metrics.CountDuration.Start()\n\tvar count int64\n\ttx = tx.Count(&count)\n\ttimer.Stop()\n\tif tx.Error != nil {\n\t\treturn 0, r.errorTransformer.ToFlyteAdminError(tx.Error)\n\t}\n\treturn count, nil\n}\n\n// Returns an instance of TaskExecutionRepoInterface\nfunc NewTaskExecutionRepo(\n\tdb *gorm.DB, errorTransformer flyteAdminDbErrors.ErrorTransformer, scope promutils.Scope) interfaces.TaskExecutionRepoInterface {\n\tmetrics := newMetrics(scope)\n\treturn &TaskExecutionRepo{\n\t\tdb:               db,\n\t\terrorTransformer: errorTransformer,\n\t\tmetrics:          metrics,\n\t}\n}\n", "package gormimpl\n\nimport (\n\t\"context\"\n\t\"testing\"\n\t\"time\"\n\n\tmockScope \"github.com/flyteorg/flytestdlib/promutils\"\n\n\tmocket \"github.com/Selvatico/go-mocket\"\n\t\"github.com/flyteorg/flyteadmin/pkg/common\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/errors\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/interfaces\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/models\"\n\t\"github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/core\"\n\t\"github.com/stretchr/testify/assert\"\n)\n\nvar taskPhase = core.TaskExecution_ABORTED.String()\n\nvar taskCreatedAt = time.Date(2018, time.January, 1, 00, 00, 00, 00, time.UTC)\nvar taskUpdatedAt = time.Date(2018, time.January, 1, 02, 00, 00, 00, time.UTC)\nvar taskStartedAt = time.Date(2018, time.January, 1, 01, 00, 00, 00, time.UTC)\n\nvar retryAttemptValue = uint32(4)\n\nvar testTaskExecution = models.TaskExecution{\n\tTaskExecutionKey: models.TaskExecutionKey{\n\t\tTaskKey: models.TaskKey{\n\t\t\tProject: \"task project\",\n\t\t\tDomain:  \"task domain\",\n\t\t\tName:    \"task name\",\n\t\t\tVersion: \"task version\",\n\t\t},\n\t\tNodeExecutionKey: models.NodeExecutionKey{\n\t\t\tNodeID: \"2\",\n\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\tProject: \"exec project\",\n\t\t\t\tDomain:  \"exec domain\",\n\t\t\t\tName:    \"exec name\",\n\t\t\t},\n\t\t},\n\t\tRetryAttempt: &retryAttemptValue,\n\t},\n\tPhase:                  taskPhase,\n\tInputURI:               \"testInput.pb\",\n\tStartedAt:              &taskStartedAt,\n\tDuration:               time.Hour,\n\tClosure:                []byte(\"Test\"),\n\tTaskExecutionCreatedAt: &taskCreatedAt,\n\tTaskExecutionUpdatedAt: &taskUpdatedAt,\n}\n\nfunc getMockTaskExecutionResponseFromDb(expected models.TaskExecution) map[string]interface{} {\n\ttaskExecution := make(map[string]interface{})\n\ttaskExecution[\"project\"] = expected.TaskKey.Project\n\ttaskExecution[\"domain\"] = expected.TaskKey.Domain\n\ttaskExecution[\"name\"] = expected.TaskKey.Name\n\ttaskExecution[\"version\"] = expected.TaskKey.Version\n\ttaskExecution[\"node_id\"] = expected.NodeExecutionKey.NodeID\n\ttaskExecution[\"execution_project\"] = expected.NodeExecutionKey.ExecutionKey.Project\n\ttaskExecution[\"execution_domain\"] = expected.NodeExecutionKey.ExecutionKey.Domain\n\ttaskExecution[\"execution_name\"] = expected.NodeExecutionKey.ExecutionKey.Name\n\ttaskExecution[\"retry_attempt\"] = expected.TaskExecutionKey.RetryAttempt\n\n\ttaskExecution[\"phase\"] = expected.Phase\n\ttaskExecution[\"input_uri\"] = expected.InputURI\n\ttaskExecution[\"started_at\"] = expected.StartedAt\n\ttaskExecution[\"duration\"] = expected.Duration\n\ttaskExecution[\"closure\"] = expected.Closure\n\ttaskExecution[\"task_execution_created_at\"] = expected.TaskExecutionCreatedAt\n\ttaskExecution[\"task_execution_updated_at\"] = expected.TaskExecutionUpdatedAt\n\treturn taskExecution\n}\n\nfunc TestCreateTaskExecution(t *testing.T) {\n\ttaskExecutionRepo := NewTaskExecutionRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\terr := taskExecutionRepo.Create(context.Background(), testTaskExecution)\n\tassert.NoError(t, err)\n}\n\nfunc TestUpdateTaskExecution(t *testing.T) {\n\ttaskExecutionRepo := NewTaskExecutionRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\tGlobalMock := mocket.Catcher.Reset()\n\tGlobalMock.Logging = true\n\n\ttaskExecutionQuery := GlobalMock.NewMock()\n\ttaskExecutionQuery.WithQuery(`UPDATE \"task_executions\" SET \"id\"=$1,\"created_at\"=$2,\"updated_at\"=$3,\"deleted_at\"=$4,\"phase\"=$5,\"phase_version\"=$6,\"input_uri\"=$7,\"closure\"=$8,\"started_at\"=$9,\"task_execution_created_at\"=$10,\"task_execution_updated_at\"=$11,\"duration\"=$12 WHERE \"project\" = $13 AND \"domain\" = $14 AND \"name\" = $15 AND \"version\" = $16 AND \"execution_project\" = $17 AND \"execution_domain\" = $18 AND \"execution_name\" = $19 AND \"node_id\" = $20 AND \"retry_attempt\" = $21`)\n\terr := taskExecutionRepo.Update(context.Background(), testTaskExecution)\n\tassert.NoError(t, err)\n\tassert.True(t, taskExecutionQuery.Triggered)\n}\n\nfunc TestGetTaskExecution(t *testing.T) {\n\ttaskExecutionRepo := NewTaskExecutionRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\n\ttaskExecutions := make([]map[string]interface{}, 0)\n\ttaskExecution := getMockTaskExecutionResponseFromDb(testTaskExecution)\n\ttaskExecutions = append(taskExecutions, taskExecution)\n\tGlobalMock := mocket.Catcher.Reset()\n\tGlobalMock.Logging = true\n\tGlobalMock.NewMock().WithQuery(\n\t\t`SELECT * FROM \"task_executions\" WHERE \"task_executions\".\"project\" = $1 AND \"task_executions\".\"domain\" = $2 AND \"task_executions\".\"name\" = $3 AND \"task_executions\".\"version\" = $4 AND \"task_executions\".\"execution_project\" = $5 AND \"task_executions\".\"execution_domain\" = $6 AND \"task_executions\".\"execution_name\" = $7 AND \"task_executions\".\"node_id\" = $8 AND \"task_executions\".\"retry_attempt\" = $9 LIMIT 1`).\n\t\tWithReply(taskExecutions)\n\n\toutput, err := taskExecutionRepo.Get(context.Background(), interfaces.GetTaskExecutionInput{\n\t\tTaskExecutionID: core.TaskExecutionIdentifier{\n\t\t\tTaskId: &core.Identifier{\n\t\t\t\tResourceType: core.ResourceType_TASK,\n\t\t\t\tProject:      \"project\",\n\t\t\t\tDomain:       \"domain\",\n\t\t\t\tName:         \"task-id\",\n\t\t\t\tVersion:      \"task-version\",\n\t\t\t},\n\t\t\tNodeExecutionId: &core.NodeExecutionIdentifier{\n\t\t\t\tNodeId: \"node-id\",\n\t\t\t\tExecutionId: &core.WorkflowExecutionIdentifier{\n\t\t\t\t\tProject: \"project\",\n\t\t\t\t\tDomain:  \"domain\",\n\t\t\t\t\tName:    \"name\",\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t})\n\tassert.NoError(t, err)\n\tassert.EqualValues(t, testTaskExecution, output)\n}\n\nfunc TestListTaskExecutionForExecution(t *testing.T) {\n\ttaskExecutionRepo := NewTaskExecutionRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\n\ttaskExecutions := make([]map[string]interface{}, 0)\n\ttaskExecution := getMockTaskExecutionResponseFromDb(testTaskExecution)\n\ttaskExecutions = append(taskExecutions, taskExecution)\n\tGlobalMock := mocket.Catcher.Reset()\n\tGlobalMock.Logging = true\n\tGlobalMock.NewMock().WithQuery(`SELECT \"task_executions\".\"id\",\"task_executions\".\"created_at\",\"task_executions\".\"updated_at\",\"task_executions\".\"deleted_at\",\"task_executions\".\"project\",\"task_executions\".\"domain\",\"task_executions\".\"name\",\"task_executions\".\"version\",\"task_executions\".\"execution_project\",\"task_executions\".\"execution_domain\",\"task_executions\".\"execution_name\",\"task_executions\".\"node_id\",\"task_executions\".\"retry_attempt\",\"task_executions\".\"phase\",\"task_executions\".\"phase_version\",\"task_executions\".\"input_uri\",\"task_executions\".\"closure\",\"task_executions\".\"started_at\",\"task_executions\".\"task_execution_created_at\",\"task_executions\".\"task_execution_updated_at\",\"task_executions\".\"duration\" FROM \"task_executions\" LEFT JOIN tasks ON task_executions.project = tasks.project AND task_executions.domain = tasks.domain AND task_executions.name = tasks.name AND task_executions.version = tasks.version INNER JOIN node_executions ON task_executions.node_id = node_executions.node_id AND task_executions.execution_project = node_executions.execution_project AND task_executions.execution_domain = node_executions.execution_domain AND task_executions.execution_name = node_executions.execution_name INNER JOIN executions ON node_executions.execution_project = executions.execution_project AND node_executions.execution_domain = executions.execution_domain AND node_executions.execution_name = executions.execution_name WHERE executions.execution_project = $1 AND executions.execution_domain = $2 AND executions.execution_name = $3 LIMIT 20`).WithReply(taskExecutions)\n\n\tcollection, err := taskExecutionRepo.List(context.Background(), interfaces.ListResourceInput{\n\t\tInlineFilters: []common.InlineFilter{\n\t\t\tgetEqualityFilter(common.Execution, \"project\", \"project_name\"),\n\t\t\tgetEqualityFilter(common.Execution, \"domain\", \"domain_name\"),\n\t\t\tgetEqualityFilter(common.Execution, \"name\", \"execution_name\"),\n\t\t},\n\t\tLimit: 20,\n\t})\n\n\tassert.NoError(t, err)\n\tassert.NotEmpty(t, collection)\n\tassert.NotEmpty(t, collection.TaskExecutions)\n\tassert.Len(t, collection.TaskExecutions, 1)\n\n\tfor _, taskExecution := range collection.TaskExecutions {\n\t\tassert.Equal(t, testTaskExecution.TaskExecutionKey, taskExecution.TaskExecutionKey)\n\t\tassert.Equal(t, taskPhase, taskExecution.Phase)\n\t\tassert.Equal(t, []byte(\"Test\"), taskExecution.Closure)\n\t\tassert.Equal(t, \"testInput.pb\", taskExecution.InputURI)\n\t\tassert.Equal(t, taskStartedAt, *taskExecution.StartedAt)\n\t\tassert.Equal(t, time.Hour, taskExecution.Duration)\n\t}\n}\n\nfunc TestListTaskExecutionsForTaskExecution(t *testing.T) {\n\ttaskExecutionRepo := NewTaskExecutionRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\n\ttaskExecutions := make([]map[string]interface{}, 0)\n\ttaskExecution := getMockTaskExecutionResponseFromDb(testTaskExecution)\n\ttaskExecutions = append(taskExecutions, taskExecution)\n\n\tGlobalMock := mocket.Catcher.Reset()\n\tGlobalMock.Logging = true\n\n\tGlobalMock.NewMock().WithQuery(`SELECT \"task_executions\".\"id\",\"task_executions\".\"created_at\",\"task_executions\".\"updated_at\",\"task_executions\".\"deleted_at\",\"task_executions\".\"project\",\"task_executions\".\"domain\",\"task_executions\".\"name\",\"task_executions\".\"version\",\"task_executions\".\"execution_project\",\"task_executions\".\"execution_domain\",\"task_executions\".\"execution_name\",\"task_executions\".\"node_id\",\"task_executions\".\"retry_attempt\",\"task_executions\".\"phase\",\"task_executions\".\"phase_version\",\"task_executions\".\"input_uri\",\"task_executions\".\"closure\",\"task_executions\".\"started_at\",\"task_executions\".\"task_execution_created_at\",\"task_executions\".\"task_execution_updated_at\",\"task_executions\".\"duration\" FROM \"task_executions\" LEFT JOIN tasks ON task_executions.project = tasks.project AND task_executions.domain = tasks.domain AND task_executions.name = tasks.name AND task_executions.version = tasks.version INNER JOIN node_executions ON task_executions.node_id = node_executions.node_id AND task_executions.execution_project = node_executions.execution_project AND task_executions.execution_domain = node_executions.execution_domain AND task_executions.execution_name = node_executions.execution_name INNER JOIN executions ON node_executions.execution_project = executions.execution_project AND node_executions.execution_domain = executions.execution_domain AND node_executions.execution_name = executions.execution_name WHERE tasks.project = $1 AND tasks.domain = $2 AND tasks.name = $3 AND tasks.version = $4 AND node_executions.phase = $5 AND executions.execution_project = $6 AND executions.execution_domain = $7 AND executions.execution_name = $8 LIMIT 20`).WithReply(taskExecutions)\n\n\tcollection, err := taskExecutionRepo.List(context.Background(), interfaces.ListResourceInput{\n\t\tInlineFilters: []common.InlineFilter{\n\t\t\tgetEqualityFilter(common.Task, \"project\", \"project_tn\"),\n\t\t\tgetEqualityFilter(common.Task, \"domain\", \"domain_t\"),\n\t\t\tgetEqualityFilter(common.Task, \"name\", \"domain_t\"),\n\t\t\tgetEqualityFilter(common.Task, \"version\", \"version_t\"),\n\n\t\t\tgetEqualityFilter(common.NodeExecution, \"phase\", nodePhase),\n\t\t\tgetEqualityFilter(common.Execution, \"project\", \"project_name\"),\n\t\t\tgetEqualityFilter(common.Execution, \"domain\", \"domain_name\"),\n\t\t\tgetEqualityFilter(common.Execution, \"name\", \"execution_name\"),\n\t\t},\n\t\tLimit: 20,\n\t})\n\tassert.NoError(t, err)\n\tassert.NotEmpty(t, collection)\n\tassert.NotEmpty(t, collection.TaskExecutions)\n\tassert.Len(t, collection.TaskExecutions, 1)\n\n\tfor _, taskExecution := range collection.TaskExecutions {\n\t\tassert.Equal(t, testTaskExecution.TaskExecutionKey, taskExecution.TaskExecutionKey)\n\t\tassert.Equal(t, &retryAttemptValue, taskExecution.RetryAttempt)\n\t\tassert.Equal(t, taskPhase, taskExecution.Phase)\n\t\tassert.Equal(t, []byte(\"Test\"), taskExecution.Closure)\n\t\tassert.Equal(t, \"testInput.pb\", taskExecution.InputURI)\n\t\tassert.Equal(t, taskStartedAt, *taskExecution.StartedAt)\n\t\tassert.Equal(t, time.Hour, taskExecution.Duration)\n\t}\n}\n\nfunc TestCountTaskExecutions(t *testing.T) {\n\ttaskExecutionRepo := NewTaskExecutionRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\n\tGlobalMock := mocket.Catcher.Reset()\n\tGlobalMock.NewMock().WithQuery(\n\t\t`SELECT count(*) FROM \"task_executions\"`).WithReply([]map[string]interface{}{{\"rows\": 2}})\n\n\tcount, err := taskExecutionRepo.Count(context.Background(), interfaces.CountResourceInput{})\n\tassert.NoError(t, err)\n\tassert.Equal(t, int64(2), count)\n}\n\nfunc TestCountTaskExecutions_Filters(t *testing.T) {\n\ttaskExecutionRepo := NewTaskExecutionRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\n\tGlobalMock := mocket.Catcher.Reset()\n\tGlobalMock.NewMock().WithQuery(\n\t\t`SELECT count(*) FROM \"task_executions\" LEFT JOIN tasks ON task_executions.project = tasks.project AND task_executions.domain = tasks.domain AND task_executions.name = tasks.name AND task_executions.version = tasks.version INNER JOIN node_executions ON task_executions.node_id = node_executions.node_id AND task_executions.execution_project = node_executions.execution_project AND task_executions.execution_domain = node_executions.execution_domain AND task_executions.execution_name = node_executions.execution_name INNER JOIN executions ON node_executions.execution_project = executions.execution_project AND node_executions.execution_domain = executions.execution_domain AND node_executions.execution_name = executions.execution_name WHERE task_executions.phase = $1 AND \"task_execution_updated_at\" IS NULL`).WithReply([]map[string]interface{}{{\"rows\": 3}})\n\n\tcount, err := taskExecutionRepo.Count(context.Background(), interfaces.CountResourceInput{\n\t\tInlineFilters: []common.InlineFilter{\n\t\t\tgetEqualityFilter(common.TaskExecution, \"phase\", core.TaskExecution_FAILED.String()),\n\t\t},\n\t\tMapFilters: []common.MapFilter{\n\t\t\tcommon.NewMapFilter(map[string]interface{}{\n\t\t\t\t\"task_execution_updated_at\": nil,\n\t\t\t}),\n\t\t},\n\t})\n\tassert.NoError(t, err)\n\tassert.Equal(t, int64(3), count)\n}\n", "package gormimpl\n\nimport (\n\t\"context\"\n\t\"errors\"\n\n\t\"github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/core\"\n\n\t\"github.com/flyteorg/flytestdlib/promutils\"\n\n\tflyteAdminDbErrors \"github.com/flyteorg/flyteadmin/pkg/repositories/errors\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/interfaces\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/models\"\n\t\"gorm.io/gorm\"\n)\n\n// Implementation of TaskRepoInterface.\ntype TaskRepo struct {\n\tdb               *gorm.DB\n\terrorTransformer flyteAdminDbErrors.ErrorTransformer\n\tmetrics          gormMetrics\n}\n\nfunc (r *TaskRepo) Create(_ context.Context, input models.Task, descriptionEntity *models.DescriptionEntity) error {\n\ttimer := r.metrics.CreateDuration.Start()\n\terr := r.db.Transaction(func(_ *gorm.DB) error {\n\t\tif descriptionEntity == nil {\n\t\t\ttx := r.db.Omit(\"id\").Create(&input)\n\t\t\tif tx.Error != nil {\n\t\t\t\treturn r.errorTransformer.ToFlyteAdminError(tx.Error)\n\t\t\t}\n\t\t\treturn nil\n\t\t}\n\t\ttx := r.db.Omit(\"id\").Create(descriptionEntity)\n\t\tif tx.Error != nil {\n\t\t\treturn r.errorTransformer.ToFlyteAdminError(tx.Error)\n\t\t}\n\n\t\ttx = r.db.Omit(\"id\").Create(&input)\n\t\tif tx.Error != nil {\n\t\t\treturn r.errorTransformer.ToFlyteAdminError(tx.Error)\n\t\t}\n\n\t\treturn nil\n\t})\n\ttimer.Stop()\n\treturn err\n}\n\nfunc (r *TaskRepo) Get(ctx context.Context, input interfaces.Identifier) (models.Task, error) {\n\tvar task models.Task\n\ttimer := r.metrics.GetDuration.Start()\n\ttx := r.db.Where(&models.Task{\n\t\tTaskKey: models.TaskKey{\n\t\t\tProject: input.Project,\n\t\t\tDomain:  input.Domain,\n\t\t\tName:    input.Name,\n\t\t\tVersion: input.Version,\n\t\t},\n\t}).Take(&task)\n\ttimer.Stop()\n\tif errors.Is(tx.Error, gorm.ErrRecordNotFound) {\n\t\treturn models.Task{}, flyteAdminDbErrors.GetMissingEntityError(core.ResourceType_TASK.String(), &core.Identifier{\n\t\t\tProject: input.Project,\n\t\t\tDomain:  input.Domain,\n\t\t\tName:    input.Name,\n\t\t\tVersion: input.Version,\n\t\t})\n\t}\n\n\tif tx.Error != nil {\n\t\treturn models.Task{}, r.errorTransformer.ToFlyteAdminError(tx.Error)\n\t}\n\treturn task, nil\n}\n\nfunc (r *TaskRepo) List(\n\tctx context.Context, input interfaces.ListResourceInput) (interfaces.TaskCollectionOutput, error) {\n\t// First validate input.\n\tif err := ValidateListInput(input); err != nil {\n\t\treturn interfaces.TaskCollectionOutput{}, err\n\t}\n\tvar tasks []models.Task\n\ttx := r.db.Limit(input.Limit).Offset(input.Offset)\n\t// Apply filters\n\ttx, err := applyFilters(tx, input.InlineFilters, input.MapFilters)\n\tif err != nil {\n\t\treturn interfaces.TaskCollectionOutput{}, err\n\t}\n\t// Apply sort ordering.\n\tif input.SortParameter != nil {\n\t\ttx = tx.Order(input.SortParameter.GetGormOrderExpr())\n\t}\n\ttimer := r.metrics.ListDuration.Start()\n\ttx.Find(&tasks)\n\ttimer.Stop()\n\tif tx.Error != nil {\n\t\treturn interfaces.TaskCollectionOutput{}, r.errorTransformer.ToFlyteAdminError(tx.Error)\n\t}\n\n\treturn interfaces.TaskCollectionOutput{\n\t\tTasks: tasks,\n\t}, nil\n}\n\nfunc (r *TaskRepo) ListTaskIdentifiers(ctx context.Context, input interfaces.ListResourceInput) (\n\tinterfaces.TaskCollectionOutput, error) {\n\n\t// Validate input.\n\tif err := ValidateListInput(input); err != nil {\n\t\treturn interfaces.TaskCollectionOutput{}, err\n\t}\n\n\ttx := r.db.Model(models.Task{}).Limit(input.Limit).Offset(input.Offset)\n\n\t// Apply filters\n\ttx, err := applyFilters(tx, input.InlineFilters, input.MapFilters)\n\tif err != nil {\n\t\treturn interfaces.TaskCollectionOutput{}, err\n\t}\n\tfor _, mapFilter := range input.MapFilters {\n\t\ttx = tx.Where(mapFilter.GetFilter())\n\t}\n\t// Apply sort ordering.\n\tif input.SortParameter != nil {\n\t\ttx = tx.Order(input.SortParameter.GetGormOrderExpr())\n\t}\n\n\t// Scan the results into a list of tasks\n\tvar tasks []models.Task\n\ttimer := r.metrics.ListIdentifiersDuration.Start()\n\ttx.Select([]string{Project, Domain, Name}).Group(identifierGroupBy).Scan(&tasks)\n\ttimer.Stop()\n\tif tx.Error != nil {\n\t\treturn interfaces.TaskCollectionOutput{}, r.errorTransformer.ToFlyteAdminError(tx.Error)\n\t}\n\n\treturn interfaces.TaskCollectionOutput{\n\t\tTasks: tasks,\n\t}, nil\n}\n\n// Returns an instance of TaskRepoInterface\nfunc NewTaskRepo(\n\tdb *gorm.DB, errorTransformer flyteAdminDbErrors.ErrorTransformer, scope promutils.Scope) interfaces.TaskRepoInterface {\n\tmetrics := newMetrics(scope)\n\treturn &TaskRepo{\n\t\tdb:               db,\n\t\terrorTransformer: errorTransformer,\n\t\tmetrics:          metrics,\n\t}\n}\n", "package gormimpl\n\nimport (\n\t\"context\"\n\t\"testing\"\n\n\tmockScope \"github.com/flyteorg/flytestdlib/promutils\"\n\n\t\"github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/admin\"\n\n\tmocket \"github.com/Selvatico/go-mocket\"\n\t\"github.com/flyteorg/flyteadmin/pkg/common\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/errors\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/interfaces\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/models\"\n\t\"github.com/stretchr/testify/assert\"\n)\n\nconst pythonTestTaskType = \"python-task\"\n\nfunc TestCreateTask(t *testing.T) {\n\ttaskRepo := NewTaskRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\terr := taskRepo.Create(context.Background(), models.Task{\n\t\tTaskKey: models.TaskKey{\n\t\t\tProject: project,\n\t\t\tDomain:  domain,\n\t\t\tName:    name,\n\t\t\tVersion: version,\n\t\t},\n\t\tClosure: []byte{1, 2},\n\t\tType:    pythonTestTaskType,\n\t}, &models.DescriptionEntity{ShortDescription: \"hello\"})\n\tassert.NoError(t, err)\n}\n\nfunc getMockTaskResponseFromDb(version string, spec []byte) map[string]interface{} {\n\ttask := make(map[string]interface{})\n\ttask[\"project\"] = project\n\ttask[\"domain\"] = domain\n\ttask[\"name\"] = name\n\ttask[\"version\"] = version\n\ttask[\"closure\"] = spec\n\ttask[\"type\"] = pythonTestTaskType\n\treturn task\n}\n\nfunc TestGetTask(t *testing.T) {\n\ttaskRepo := NewTaskRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\n\ttasks := make([]map[string]interface{}, 0)\n\ttask := getMockTaskResponseFromDb(version, []byte{1, 2})\n\ttasks = append(tasks, task)\n\n\toutput, err := taskRepo.Get(context.Background(), interfaces.Identifier{\n\t\tProject: project,\n\t\tDomain:  domain,\n\t\tName:    name,\n\t\tVersion: version,\n\t})\n\tassert.Empty(t, output)\n\tassert.EqualError(t, err, \"missing entity of type TASK with identifier project:\\\"project\\\" domain:\\\"domain\\\" name:\\\"name\\\" version:\\\"XYZ\\\" \")\n\n\tGlobalMock := mocket.Catcher.Reset()\n\tGlobalMock.Logging = true\n\t// Only match on queries that append expected filters\n\tGlobalMock.NewMock().WithQuery(\n\t\t`SELECT * FROM \"tasks\" WHERE \"tasks\".\"project\" = $1 AND \"tasks\".\"domain\" = $2 AND \"tasks\".\"name\" = $3 AND \"tasks\".\"version\" = $4 LIMIT 1`).\n\t\tWithReply(tasks)\n\toutput, err = taskRepo.Get(context.Background(), interfaces.Identifier{\n\t\tProject: project,\n\t\tDomain:  domain,\n\t\tName:    name,\n\t\tVersion: version,\n\t})\n\tassert.Empty(t, err)\n\tassert.Equal(t, project, output.Project)\n\tassert.Equal(t, domain, output.Domain)\n\tassert.Equal(t, name, output.Name)\n\tassert.Equal(t, version, output.Version)\n\tassert.Equal(t, []byte{1, 2}, output.Closure)\n\tassert.Equal(t, pythonTestTaskType, output.Type)\n}\n\nfunc TestListTasks(t *testing.T) {\n\ttaskRepo := NewTaskRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\n\ttasks := make([]map[string]interface{}, 0)\n\tversions := []string{\"ABC\", \"XYZ\"}\n\tspec := []byte{1, 2}\n\tfor _, version := range versions {\n\t\ttask := getMockTaskResponseFromDb(version, spec)\n\t\ttasks = append(tasks, task)\n\t}\n\n\tGlobalMock := mocket.Catcher.Reset()\n\tGlobalMock.NewMock().WithReply(tasks)\n\n\tcollection, err := taskRepo.List(context.Background(), interfaces.ListResourceInput{\n\t\tInlineFilters: []common.InlineFilter{\n\t\t\tgetEqualityFilter(common.Task, \"project\", project),\n\t\t\tgetEqualityFilter(common.Task, \"domain\", domain),\n\t\t\tgetEqualityFilter(common.Task, \"name\", name),\n\t\t},\n\t\tLimit: 20,\n\t})\n\tassert.Empty(t, err)\n\tassert.NotEmpty(t, collection)\n\tassert.NotEmpty(t, collection.Tasks)\n\tassert.Len(t, collection.Tasks, 2)\n\tfor _, task := range collection.Tasks {\n\t\tassert.Equal(t, project, task.Project)\n\t\tassert.Equal(t, domain, task.Domain)\n\t\tassert.Equal(t, name, task.Name)\n\t\tassert.Contains(t, versions, task.Version)\n\t\tassert.Equal(t, spec, task.Closure)\n\t\tassert.Equal(t, pythonTestTaskType, task.Type)\n\t}\n}\n\nfunc TestListTasks_Pagination(t *testing.T) {\n\ttaskRepo := NewTaskRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\n\ttasks := make([]map[string]interface{}, 0)\n\tversions := []string{\"ABC\", \"DEF\"}\n\tspec := []byte{1, 2}\n\tfor _, version := range versions {\n\t\ttask := getMockTaskResponseFromDb(version, spec)\n\t\ttasks = append(tasks, task)\n\t}\n\n\tGlobalMock := mocket.Catcher.Reset()\n\tGlobalMock.NewMock().WithReply(tasks)\n\n\tcollection, err := taskRepo.List(context.Background(), interfaces.ListResourceInput{\n\t\tInlineFilters: []common.InlineFilter{\n\t\t\tgetEqualityFilter(common.Task, \"project\", project),\n\t\t\tgetEqualityFilter(common.Task, \"domain\", domain),\n\t\t\tgetEqualityFilter(common.Task, \"name\", name),\n\t\t},\n\t\tLimit: 2,\n\t})\n\tassert.Empty(t, err)\n\tassert.NotEmpty(t, collection)\n\tassert.NotEmpty(t, collection.Tasks)\n\tassert.Len(t, collection.Tasks, 2)\n\tfor idx, task := range collection.Tasks {\n\t\tassert.Equal(t, project, task.Project)\n\t\tassert.Equal(t, domain, task.Domain)\n\t\tassert.Equal(t, name, task.Name)\n\t\tassert.Equal(t, versions[idx], task.Version)\n\t\tassert.Equal(t, spec, task.Closure)\n\t\tassert.Equal(t, pythonTestTaskType, task.Type)\n\t}\n}\n\nfunc TestListTasks_Filters(t *testing.T) {\n\ttaskRepo := NewTaskRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\n\ttasks := make([]map[string]interface{}, 0)\n\ttask := getMockTaskResponseFromDb(\"ABC\", []byte{1, 2})\n\ttasks = append(tasks, task)\n\n\tGlobalMock := mocket.Catcher.Reset()\n\tGlobalMock.Logging = true\n\t// Only match on queries that append the name filter\n\tGlobalMock.NewMock().WithQuery(`SELECT * FROM \"tasks\" WHERE project = $1 AND domain = $2 AND name = $3 AND version = $4 LIMIT 20`).WithReply(tasks[0:1])\n\n\tcollection, err := taskRepo.List(context.Background(), interfaces.ListResourceInput{\n\t\tInlineFilters: []common.InlineFilter{\n\t\t\tgetEqualityFilter(common.Task, \"project\", project),\n\t\t\tgetEqualityFilter(common.Task, \"domain\", domain),\n\t\t\tgetEqualityFilter(common.Task, \"name\", name),\n\t\t\tgetEqualityFilter(common.Task, \"version\", \"ABC\"),\n\t\t},\n\t\tLimit: 20,\n\t})\n\tassert.Empty(t, err)\n\tassert.NotEmpty(t, collection)\n\tassert.NotEmpty(t, collection.Tasks)\n\tassert.Len(t, collection.Tasks, 1)\n\tassert.Equal(t, project, collection.Tasks[0].Project)\n\tassert.Equal(t, domain, collection.Tasks[0].Domain)\n\tassert.Equal(t, name, collection.Tasks[0].Name)\n\tassert.Equal(t, \"ABC\", collection.Tasks[0].Version)\n\tassert.Equal(t, []byte{1, 2}, collection.Tasks[0].Closure)\n\tassert.Equal(t, pythonTestTaskType, collection.Tasks[0].Type)\n}\n\nfunc TestListTasks_Order(t *testing.T) {\n\ttaskRepo := NewTaskRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\ttasks := make([]map[string]interface{}, 0)\n\n\tGlobalMock := mocket.Catcher.Reset()\n\tGlobalMock.Logging = true\n\t// Only match on queries that include ordering by project\n\tmockQuery := GlobalMock.NewMock()\n\tmockQuery.WithQuery(`project desc`)\n\tmockQuery.WithReply(tasks)\n\n\tsortParameter, _ := common.NewSortParameter(admin.Sort{\n\t\tDirection: admin.Sort_DESCENDING,\n\t\tKey:       \"project\",\n\t})\n\t_, err := taskRepo.List(context.Background(), interfaces.ListResourceInput{\n\t\tSortParameter: sortParameter,\n\t\tInlineFilters: []common.InlineFilter{\n\t\t\tgetEqualityFilter(common.Task, \"project\", project),\n\t\t\tgetEqualityFilter(common.Task, \"domain\", domain),\n\t\t\tgetEqualityFilter(common.Task, \"name\", name),\n\t\t\tgetEqualityFilter(common.Task, \"version\", \"ABC\"),\n\t\t},\n\t\tLimit: 20,\n\t})\n\tassert.Empty(t, err)\n\tassert.True(t, mockQuery.Triggered)\n}\n\nfunc TestListTasks_MissingParameters(t *testing.T) {\n\ttaskRepo := NewTaskRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\t_, err := taskRepo.List(context.Background(), interfaces.ListResourceInput{\n\t\tInlineFilters: []common.InlineFilter{\n\t\t\tgetEqualityFilter(common.Task, \"project\", project),\n\t\t\tgetEqualityFilter(common.Task, \"domain\", domain),\n\t\t\tgetEqualityFilter(common.Task, \"name\", name),\n\t\t\tgetEqualityFilter(common.Task, \"version\", version),\n\t\t},\n\t})\n\tassert.Equal(t, err.Error(), \"missing and/or invalid parameters: limit\")\n\n\t_, err = taskRepo.List(context.Background(), interfaces.ListResourceInput{\n\t\tLimit: 20,\n\t})\n\tassert.Equal(t, err.Error(), \"missing and/or invalid parameters: filters\")\n}\n\nfunc TestListTaskIds(t *testing.T) {\n\ttaskRepo := NewTaskRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\n\ttasks := make([]map[string]interface{}, 0)\n\tversions := []string{\"v3\", \"v4\"}\n\tspec := []byte{1, 2}\n\tfor _, version := range versions {\n\t\ttask := getMockTaskResponseFromDb(version, spec)\n\t\ttasks = append(tasks, task)\n\t}\n\n\tGlobalMock := mocket.Catcher.Reset()\n\tGlobalMock.NewMock().WithQuery(`GROUP BY project, domain, name`).WithReply(tasks)\n\n\tcollection, err := taskRepo.ListTaskIdentifiers(context.Background(), interfaces.ListResourceInput{\n\t\tInlineFilters: []common.InlineFilter{\n\t\t\tgetEqualityFilter(common.Task, \"project\", project),\n\t\t\tgetEqualityFilter(common.Task, \"domain\", domain),\n\t\t},\n\t\tLimit: 20,\n\t})\n\tassert.NoError(t, err)\n\tassert.NotEmpty(t, collection)\n\tassert.NotEmpty(t, collection.Tasks)\n\tassert.Len(t, collection.Tasks, 2)\n\tfor idx, task := range collection.Tasks {\n\t\tassert.Equal(t, project, task.Project)\n\t\tassert.Equal(t, domain, task.Domain)\n\t\tassert.Equal(t, name, task.Name)\n\t\tassert.Equal(t, versions[idx], task.Version)\n\t\tassert.Equal(t, spec, task.Closure)\n\t\tassert.Equal(t, pythonTestTaskType, task.Type)\n\t}\n}\n\nfunc TestListTaskIds_MissingParameters(t *testing.T) {\n\ttaskRepo := NewTaskRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\n\t_, err := taskRepo.ListTaskIdentifiers(context.Background(), interfaces.ListResourceInput{\n\t\tInlineFilters: []common.InlineFilter{\n\t\t\tgetEqualityFilter(common.Task, \"project\", project),\n\t\t\tgetEqualityFilter(common.Task, \"domain\", domain),\n\t\t},\n\t})\n\n\t// Limit must be specified\n\tassert.Equal(t, \"missing and/or invalid parameters: limit\", err.Error())\n}\n", "package gormimpl\n\nimport (\n\t\"context\"\n\t\"errors\"\n\n\tflyteAdminDbErrors \"github.com/flyteorg/flyteadmin/pkg/repositories/errors\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/interfaces\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/models\"\n\t\"github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/core\"\n\t\"github.com/flyteorg/flytestdlib/promutils\"\n\t\"gorm.io/gorm\"\n)\n\n// Implementation of WorkflowRepoInterface.\ntype WorkflowRepo struct {\n\tdb               *gorm.DB\n\terrorTransformer flyteAdminDbErrors.ErrorTransformer\n\tmetrics          gormMetrics\n}\n\nfunc (r *WorkflowRepo) Create(_ context.Context, input models.Workflow, descriptionEntity *models.DescriptionEntity) error {\n\ttimer := r.metrics.CreateDuration.Start()\n\terr := r.db.Transaction(func(_ *gorm.DB) error {\n\t\tif descriptionEntity != nil {\n\t\t\ttx := r.db.Omit(\"id\").Create(descriptionEntity)\n\t\t\tif tx.Error != nil {\n\t\t\t\treturn r.errorTransformer.ToFlyteAdminError(tx.Error)\n\t\t\t}\n\t\t}\n\t\ttx := r.db.Omit(\"id\").Create(&input)\n\t\tif tx.Error != nil {\n\t\t\treturn r.errorTransformer.ToFlyteAdminError(tx.Error)\n\t\t}\n\n\t\treturn nil\n\t})\n\ttimer.Stop()\n\treturn err\n}\n\nfunc (r *WorkflowRepo) Get(ctx context.Context, input interfaces.Identifier) (models.Workflow, error) {\n\tvar workflow models.Workflow\n\ttimer := r.metrics.GetDuration.Start()\n\ttx := r.db.Where(&models.Workflow{\n\t\tWorkflowKey: models.WorkflowKey{\n\t\t\tProject: input.Project,\n\t\t\tDomain:  input.Domain,\n\t\t\tName:    input.Name,\n\t\t\tVersion: input.Version,\n\t\t},\n\t}).Take(&workflow)\n\ttimer.Stop()\n\n\tif tx.Error != nil && errors.Is(tx.Error, gorm.ErrRecordNotFound) {\n\t\treturn models.Workflow{}, flyteAdminDbErrors.GetMissingEntityError(core.ResourceType_WORKFLOW.String(), &core.Identifier{\n\t\t\tProject: input.Project,\n\t\t\tDomain:  input.Domain,\n\t\t\tName:    input.Name,\n\t\t\tVersion: input.Version,\n\t\t})\n\t} else if tx.Error != nil {\n\t\treturn models.Workflow{}, r.errorTransformer.ToFlyteAdminError(tx.Error)\n\t}\n\treturn workflow, nil\n}\n\nfunc (r *WorkflowRepo) List(\n\tctx context.Context, input interfaces.ListResourceInput) (interfaces.WorkflowCollectionOutput, error) {\n\t// First validate input.\n\tif err := ValidateListInput(input); err != nil {\n\t\treturn interfaces.WorkflowCollectionOutput{}, err\n\t}\n\tvar workflows []models.Workflow\n\ttx := r.db.Limit(input.Limit).Offset(input.Offset)\n\n\t// Apply filters\n\ttx, err := applyFilters(tx, input.InlineFilters, input.MapFilters)\n\tif err != nil {\n\t\treturn interfaces.WorkflowCollectionOutput{}, err\n\t}\n\t// Apply sort ordering.\n\tif input.SortParameter != nil {\n\t\ttx = tx.Order(input.SortParameter.GetGormOrderExpr())\n\t}\n\ttimer := r.metrics.ListDuration.Start()\n\ttx.Find(&workflows)\n\ttimer.Stop()\n\tif tx.Error != nil {\n\t\treturn interfaces.WorkflowCollectionOutput{}, r.errorTransformer.ToFlyteAdminError(tx.Error)\n\t}\n\treturn interfaces.WorkflowCollectionOutput{\n\t\tWorkflows: workflows,\n\t}, nil\n}\n\nfunc (r *WorkflowRepo) ListIdentifiers(ctx context.Context, input interfaces.ListResourceInput) (\n\tinterfaces.WorkflowCollectionOutput, error) {\n\n\t// Validate input.\n\tif err := ValidateListInput(input); err != nil {\n\t\treturn interfaces.WorkflowCollectionOutput{}, err\n\t}\n\n\ttx := r.db.Model(models.Workflow{}).Limit(input.Limit).Offset(input.Offset)\n\n\t// Apply filters\n\ttx, err := applyFilters(tx, input.InlineFilters, input.MapFilters)\n\tif err != nil {\n\t\treturn interfaces.WorkflowCollectionOutput{}, err\n\t}\n\n\t// Apply sort ordering.\n\tif input.SortParameter != nil {\n\t\ttx = tx.Order(input.SortParameter.GetGormOrderExpr())\n\t}\n\n\t// Scan the results into a list of workflows\n\tvar workflows []models.Workflow\n\ttimer := r.metrics.ListIdentifiersDuration.Start()\n\ttx.Select([]string{Project, Domain, Name}).Group(identifierGroupBy).Scan(&workflows)\n\ttimer.Stop()\n\tif tx.Error != nil {\n\t\treturn interfaces.WorkflowCollectionOutput{}, r.errorTransformer.ToFlyteAdminError(tx.Error)\n\t}\n\n\treturn interfaces.WorkflowCollectionOutput{\n\t\tWorkflows: workflows,\n\t}, nil\n}\n\n// Returns an instance of WorkflowRepoInterface\nfunc NewWorkflowRepo(\n\tdb *gorm.DB, errorTransformer flyteAdminDbErrors.ErrorTransformer, scope promutils.Scope) interfaces.WorkflowRepoInterface {\n\tmetrics := newMetrics(scope)\n\treturn &WorkflowRepo{\n\t\tdb:               db,\n\t\terrorTransformer: errorTransformer,\n\t\tmetrics:          metrics,\n\t}\n}\n", "package gormimpl\n\nimport (\n\t\"context\"\n\t\"testing\"\n\n\tmocket \"github.com/Selvatico/go-mocket\"\n\t\"github.com/flyteorg/flyteadmin/pkg/common\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/errors\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/interfaces\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/models\"\n\t\"github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/admin\"\n\tmockScope \"github.com/flyteorg/flytestdlib/promutils\"\n\t\"github.com/stretchr/testify/assert\"\n)\n\nvar typedInterface = []byte{1, 2, 3}\n\nconst remoteSpecIdentifier = \"remote spec id\"\n\nfunc TestCreateWorkflow(t *testing.T) {\n\tworkflowRepo := NewWorkflowRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\terr := workflowRepo.Create(context.Background(), models.Workflow{\n\t\tWorkflowKey: models.WorkflowKey{\n\t\t\tProject: project,\n\t\t\tDomain:  domain,\n\t\t\tName:    name,\n\t\t\tVersion: version,\n\t\t},\n\t\tTypedInterface:          typedInterface,\n\t\tRemoteClosureIdentifier: remoteSpecIdentifier,\n\t}, &models.DescriptionEntity{ShortDescription: \"hello\"})\n\tassert.NoError(t, err)\n}\n\nfunc getMockWorkflowResponseFromDb(version string, typedInterface []byte) map[string]interface{} {\n\tworkflow := make(map[string]interface{})\n\tworkflow[\"project\"] = project\n\tworkflow[\"domain\"] = domain\n\tworkflow[\"name\"] = name\n\tworkflow[\"version\"] = version\n\tworkflow[\"typed_interface\"] = typedInterface\n\tworkflow[\"remote_closure_identifier\"] = remoteSpecIdentifier\n\treturn workflow\n}\n\nfunc TestGetWorkflow(t *testing.T) {\n\tworkflowRepo := NewWorkflowRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\n\tworkflows := make([]map[string]interface{}, 0)\n\tworkflow := getMockWorkflowResponseFromDb(version, typedInterface)\n\tworkflows = append(workflows, workflow)\n\n\tGlobalMock := mocket.Catcher.Reset()\n\t// Only match on queries that append expected filters\n\tGlobalMock.NewMock().WithQuery(\n\t\t`SELECT * FROM \"workflows\" WHERE \"workflows\".\"project\" = $1 AND \"workflows\".\"domain\" = $2 AND \"workflows\".\"name\" = $3 AND \"workflows\".\"version\" = $4 LIMIT 1`).WithReply(workflows)\n\toutput, err := workflowRepo.Get(context.Background(), interfaces.Identifier{\n\t\tProject: project,\n\t\tDomain:  domain,\n\t\tName:    name,\n\t\tVersion: version,\n\t})\n\tassert.Empty(t, err)\n\tassert.Equal(t, project, output.Project)\n\tassert.Equal(t, domain, output.Domain)\n\tassert.Equal(t, name, output.Name)\n\tassert.Equal(t, version, output.Version)\n\tassert.Equal(t, typedInterface, output.TypedInterface)\n\tassert.Equal(t, remoteSpecIdentifier, output.RemoteClosureIdentifier)\n}\n\nfunc TestListWorkflows(t *testing.T) {\n\tworkflowRepo := NewWorkflowRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\n\tworkflows := make([]map[string]interface{}, 0)\n\tversions := []string{\"ABC\", \"XYZ\"}\n\tfor _, version := range versions {\n\t\tworkflow := getMockWorkflowResponseFromDb(version, typedInterface)\n\t\tworkflows = append(workflows, workflow)\n\t}\n\n\tGlobalMock := mocket.Catcher.Reset()\n\tGlobalMock.NewMock().WithReply(workflows)\n\n\tcollection, err := workflowRepo.List(context.Background(), interfaces.ListResourceInput{\n\t\tInlineFilters: []common.InlineFilter{\n\t\t\tgetEqualityFilter(common.Workflow, \"project\", project),\n\t\t\tgetEqualityFilter(common.Workflow, \"domain\", domain),\n\t\t\tgetEqualityFilter(common.Workflow, \"name\", name),\n\t\t},\n\t\tLimit: 20,\n\t})\n\tassert.Empty(t, err)\n\tassert.NotEmpty(t, collection)\n\tassert.NotEmpty(t, collection.Workflows)\n\tassert.Len(t, collection.Workflows, 2)\n\tfor _, workflow := range collection.Workflows {\n\t\tassert.Equal(t, project, workflow.Project)\n\t\tassert.Equal(t, domain, workflow.Domain)\n\t\tassert.Equal(t, name, workflow.Name)\n\t\tassert.Contains(t, versions, workflow.Version)\n\t\tassert.Equal(t, typedInterface, workflow.TypedInterface)\n\t\tassert.Equal(t, remoteSpecIdentifier, workflow.RemoteClosureIdentifier)\n\t}\n}\n\nfunc TestListWorkflows_Pagination(t *testing.T) {\n\tworkflowRepo := NewWorkflowRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\n\tworkflows := make([]map[string]interface{}, 0)\n\tversions := []string{\"ABC\", \"DEF\"}\n\tfor _, version := range versions {\n\t\tworkflow := getMockWorkflowResponseFromDb(version, typedInterface)\n\t\tworkflows = append(workflows, workflow)\n\t}\n\n\tGlobalMock := mocket.Catcher.Reset()\n\tGlobalMock.NewMock().WithReply(workflows)\n\n\tcollection, err := workflowRepo.List(context.Background(), interfaces.ListResourceInput{\n\t\tInlineFilters: []common.InlineFilter{\n\t\t\tgetEqualityFilter(common.Workflow, \"project\", project),\n\t\t\tgetEqualityFilter(common.Workflow, \"domain\", domain),\n\t\t\tgetEqualityFilter(common.Workflow, \"name\", name),\n\t\t},\n\t\tLimit: 2,\n\t})\n\tassert.Empty(t, err)\n\tassert.NotEmpty(t, collection)\n\tassert.NotEmpty(t, collection.Workflows)\n\tassert.Len(t, collection.Workflows, 2)\n\tfor idx, workflow := range collection.Workflows {\n\t\tassert.Equal(t, project, workflow.Project)\n\t\tassert.Equal(t, domain, workflow.Domain)\n\t\tassert.Equal(t, name, workflow.Name)\n\t\tassert.Equal(t, versions[idx], workflow.Version)\n\t\tassert.Equal(t, typedInterface, workflow.TypedInterface)\n\t\tassert.Equal(t, remoteSpecIdentifier, workflow.RemoteClosureIdentifier)\n\t}\n}\n\nfunc TestListWorkflows_Filters(t *testing.T) {\n\tworkflowRepo := NewWorkflowRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\n\tworkflows := make([]map[string]interface{}, 0)\n\tworkflow := getMockWorkflowResponseFromDb(\"ABC\", typedInterface)\n\tworkflows = append(workflows, workflow)\n\n\tGlobalMock := mocket.Catcher.Reset()\n\t// Only match on queries that append the name filter\n\tGlobalMock.NewMock().WithQuery(`SELECT * FROM \"workflows\" WHERE project = $1 AND domain = $2 AND name = $3 AND version = $4 LIMIT 20`).WithReply(workflows[0:1])\n\n\tcollection, err := workflowRepo.List(context.Background(), interfaces.ListResourceInput{\n\t\tInlineFilters: []common.InlineFilter{\n\t\t\tgetEqualityFilter(common.Workflow, \"project\", project),\n\t\t\tgetEqualityFilter(common.Workflow, \"domain\", domain),\n\t\t\tgetEqualityFilter(common.Workflow, \"name\", name),\n\t\t\tgetEqualityFilter(common.Workflow, \"version\", \"ABC\"),\n\t\t},\n\t\tLimit: 20,\n\t})\n\tassert.Empty(t, err)\n\tassert.NotEmpty(t, collection)\n\tassert.NotEmpty(t, collection.Workflows)\n\tassert.Len(t, collection.Workflows, 1)\n\tassert.Equal(t, project, collection.Workflows[0].Project)\n\tassert.Equal(t, domain, collection.Workflows[0].Domain)\n\tassert.Equal(t, name, collection.Workflows[0].Name)\n\tassert.Equal(t, \"ABC\", collection.Workflows[0].Version)\n\tassert.Equal(t, typedInterface, collection.Workflows[0].TypedInterface)\n\tassert.Equal(t, remoteSpecIdentifier, collection.Workflows[0].RemoteClosureIdentifier)\n}\n\nfunc TestListWorkflows_Order(t *testing.T) {\n\tworkflowRepo := NewWorkflowRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\tworkflows := make([]map[string]interface{}, 0)\n\n\tGlobalMock := mocket.Catcher.Reset()\n\t// Only match on queries that include ordering by project\n\tmockQuery := GlobalMock.NewMock()\n\tmockQuery.WithQuery(`project desc`)\n\tmockQuery.WithReply(workflows)\n\n\tsortParameter, _ := common.NewSortParameter(admin.Sort{\n\t\tDirection: admin.Sort_DESCENDING,\n\t\tKey:       \"project\",\n\t})\n\t_, err := workflowRepo.List(context.Background(), interfaces.ListResourceInput{\n\t\tSortParameter: sortParameter,\n\t\tInlineFilters: []common.InlineFilter{\n\t\t\tgetEqualityFilter(common.Workflow, \"project\", project),\n\t\t\tgetEqualityFilter(common.Workflow, \"domain\", domain),\n\t\t\tgetEqualityFilter(common.Workflow, \"name\", name),\n\t\t\tgetEqualityFilter(common.Workflow, \"version\", \"ABC\"),\n\t\t},\n\t\tLimit: 20,\n\t})\n\tassert.Empty(t, err)\n\tassert.True(t, mockQuery.Triggered)\n}\n\nfunc TestListWorkflows_MissingParameters(t *testing.T) {\n\tworkflowRepo := NewWorkflowRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\t_, err := workflowRepo.List(context.Background(), interfaces.ListResourceInput{\n\t\tInlineFilters: []common.InlineFilter{\n\t\t\tgetEqualityFilter(common.Workflow, \"project\", project),\n\t\t\tgetEqualityFilter(common.Workflow, \"domain\", domain),\n\t\t\tgetEqualityFilter(common.Workflow, \"name\", name),\n\t\t\tgetEqualityFilter(common.Workflow, \"version\", version),\n\t\t},\n\t})\n\tassert.Equal(t, err.Error(), \"missing and/or invalid parameters: limit\")\n\n\t_, err = workflowRepo.List(context.Background(), interfaces.ListResourceInput{\n\t\tLimit: 20,\n\t})\n\tassert.Equal(t, err.Error(), \"missing and/or invalid parameters: filters\")\n}\n\nfunc TestListWorkflowIds(t *testing.T) {\n\tworkflowRepo := NewWorkflowRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\n\tworkflows := make([]map[string]interface{}, 0)\n\tversions := []string{\"ABC\", \"DEF\"}\n\t// Instead of different versions, we should be returning different identifiers since the point of this list ids\n\t// function is to group away the versions, but for the purpose of this unit test, different versions will suffice.\n\tfor _, version := range versions {\n\t\tworkflow := getMockWorkflowResponseFromDb(version, typedInterface)\n\t\tworkflows = append(workflows, workflow)\n\t}\n\n\tGlobalMock := mocket.Catcher.Reset()\n\tGlobalMock.NewMock().WithReply(workflows)\n\n\tcollection, err := workflowRepo.ListIdentifiers(context.Background(), interfaces.ListResourceInput{\n\t\tInlineFilters: []common.InlineFilter{\n\t\t\tgetEqualityFilter(common.Workflow, \"project\", project),\n\t\t\tgetEqualityFilter(common.Workflow, \"domain\", domain),\n\t\t},\n\t\tLimit: 2,\n\t})\n\tassert.Empty(t, err)\n\tassert.NotEmpty(t, collection)\n\tassert.NotEmpty(t, collection.Workflows)\n\tassert.Len(t, collection.Workflows, 2)\n\tfor idx, workflow := range collection.Workflows {\n\t\tassert.Equal(t, project, workflow.Project)\n\t\tassert.Equal(t, domain, workflow.Domain)\n\t\tassert.Equal(t, name, workflow.Name)\n\t\tassert.Equal(t, versions[idx], workflow.Version)\n\t\tassert.Equal(t, typedInterface, workflow.TypedInterface)\n\t\tassert.Equal(t, remoteSpecIdentifier, workflow.RemoteClosureIdentifier)\n\t}\n}\n\nfunc TestListWorkflowIds_MissingParameters(t *testing.T) {\n\tworkflowRepo := NewWorkflowRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\t_, err := workflowRepo.ListIdentifiers(context.Background(), interfaces.ListResourceInput{\n\t\tInlineFilters: []common.InlineFilter{\n\t\t\tgetEqualityFilter(common.Workflow, \"project\", project),\n\t\t\tgetEqualityFilter(common.Workflow, \"domain\", domain),\n\t\t},\n\t})\n\n\tassert.Equal(t, err.Error(), \"missing and/or invalid parameters: limit\")\n}\n", "package models\n\nimport \"time\"\n\n// This is the base model definition every flyteadmin model embeds.\n// This is nearly identical to http://doc.gorm.io/models.html#conventions except that flyteadmin models define their\n// own primary keys rather than use the ID as the primary key\ntype BaseModel struct {\n\tID        uint `gorm:\"index;autoIncrement\"`\n\tCreatedAt time.Time\n\tUpdatedAt time.Time\n\tDeletedAt *time.Time `gorm:\"index\"`\n}\n", "package models\n\nimport \"github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/core\"\n\n// DescriptionEntityKey DescriptionEntity primary key\ntype DescriptionEntityKey struct {\n\tResourceType core.ResourceType `gorm:\"primary_key;index:description_entity_project_domain_name_version_idx\" valid:\"length(0|255)\"`\n\tProject      string            `gorm:\"primary_key;index:description_entity_project_domain_name_version_idx\" valid:\"length(0|255)\"`\n\tDomain       string            `gorm:\"primary_key;index:description_entity_project_domain_name_version_idx\" valid:\"length(0|255)\"`\n\tName         string            `gorm:\"primary_key;index:description_entity_project_domain_name_version_idx\" valid:\"length(0|255)\"`\n\tVersion      string            `gorm:\"primary_key;index:description_entity_project_domain_name_version_idx\" valid:\"length(0|255)\"`\n}\n\n// SourceCode Database model to encapsulate a SourceCode.\ntype SourceCode struct {\n\tLink string `valid:\"length(0|255)\"`\n}\n\n// DescriptionEntity Database model to encapsulate a DescriptionEntity.\ntype DescriptionEntity struct {\n\tDescriptionEntityKey\n\n\tBaseModel\n\n\tShortDescription string\n\n\tLongDescription []byte\n\n\tSourceCode\n}\n", "package models\n\nimport (\n\t\"time\"\n\n\t\"gorm.io/gorm/clause\"\n\n\t\"gorm.io/gorm\"\n\n\t\"github.com/flyteorg/flytestdlib/storage\"\n)\n\n// IMPORTANT: If you update the model below, be sure to double check model definitions in\n// pkg/repositories/config/migration_models.go\n\n// Execution primary key\ntype ExecutionKey struct {\n\tProject string `gorm:\"primary_key;column:execution_project\" valid:\"length(0|255)\"`\n\tDomain  string `gorm:\"primary_key;column:execution_domain\" valid:\"length(0|255)\"`\n\tName    string `gorm:\"primary_key;column:execution_name\" valid:\"length(0|255)\"`\n}\n\n// Database model to encapsulate a (workflow) execution.\ntype Execution struct {\n\tBaseModel\n\tExecutionKey\n\tLaunchPlanID uint   `gorm:\"index\"`\n\tWorkflowID   uint   `gorm:\"index\"`\n\tTaskID       uint   `gorm:\"index\"`\n\tPhase        string `valid:\"length(0|255)\"`\n\tClosure      []byte\n\tSpec         []byte `gorm:\"not null\"`\n\tStartedAt    *time.Time\n\t// Corresponds to the CreatedAt field in the Execution closure.\n\t// Prefixed with Execution to avoid clashes with gorm.Model CreatedAt\n\tExecutionCreatedAt *time.Time `gorm:\"index:idx_executions_created_at\"`\n\t// Corresponds to the UpdatedAt field in the Execution closure\n\t// Prefixed with Execution to avoid clashes with gorm.Model UpdatedAt\n\tExecutionUpdatedAt *time.Time\n\tDuration           time.Duration\n\t// In the case of an aborted execution this string may be non-empty.\n\t// It should be ignored for any other value of phase other than aborted.\n\tAbortCause string `valid:\"length(0|255)\"`\n\t// Corresponds to the execution mode used to trigger this execution\n\tMode int32\n\t// The \"parent\" execution (if there is one) that is related to this execution.\n\tSourceExecutionID uint\n\t// The parent node execution if this was launched by a node\n\tParentNodeExecutionID uint\n\t// Cluster where execution was triggered\n\tCluster string `valid:\"length(0|255)\"`\n\t// Offloaded location of inputs LiteralMap. These are the inputs evaluated and contain applied defaults.\n\tInputsURI storage.DataReference\n\t// User specified inputs. This map might be incomplete and not include defaults applied\n\tUserInputsURI storage.DataReference\n\t// Execution Error Kind. nullable\n\tErrorKind *string `gorm:\"index\"`\n\t// Execution Error Code nullable\n\tErrorCode *string `valid:\"length(0|255)\"`\n\t// The user responsible for launching this execution.\n\t// This is also stored in the spec but promoted as a column for filtering.\n\tUser string `gorm:\"index\" valid:\"length(0|255)\"`\n\t// GORM doesn't save the zero value for ints, so we use a pointer for the State field\n\tState *int32 `gorm:\"index;default:0\"`\n\t// The resource type of the entity used to launch the execution, one of 'launch_plan' or 'task'\n\tLaunchEntity string\n\t// Tags associated with the execution\n\tTags []AdminTag `gorm:\"many2many:execution_admin_tags;\"`\n}\n\ntype AdminTag struct {\n\tgorm.Model\n\tName string `gorm:\"index:,unique;size:255\"`\n}\n\nfunc (b *AdminTag) BeforeCreate(tx *gorm.DB) (err error) {\n\ttx.Statement.AddClause(clause.OnConflict{\n\t\tColumns:   []clause.Column{{Name: \"name\"}},            // key column\n\t\tDoUpdates: clause.AssignmentColumns([]string{\"name\"}), // column needed to be updated\n\t})\n\treturn nil\n}\n", "package models\n\n// Launch plan primary key\ntype LaunchPlanKey struct {\n\tProject string `gorm:\"primary_key;index:lp_project_domain_name_idx,lp_project_domain_idx\" valid:\"length(0|255)\"`\n\tDomain  string `gorm:\"primary_key;index:lp_project_domain_name_idx,lp_project_domain_idx\" valid:\"length(0|255)\"`\n\tName    string `gorm:\"primary_key;index:lp_project_domain_name_idx\" valid:\"length(0|255)\"`\n\tVersion string `gorm:\"primary_key\" valid:\"length(0|255)\"`\n}\n\ntype LaunchPlanScheduleType string\n\nconst (\n\t// LaunchPlanScheduleTypeNONE is the const representing the launch plan does not have a schedule\n\tLaunchPlanScheduleTypeNONE LaunchPlanScheduleType = \"NONE\"\n\t// LaunchPlanScheduleTypeCRON is the const representing the launch plan has a CRON type of schedule\n\tLaunchPlanScheduleTypeCRON LaunchPlanScheduleType = \"CRON\"\n\t// LaunchPlanScheduleTypeRATE is the launch plan has a RATE type of schedule\n\tLaunchPlanScheduleTypeRATE LaunchPlanScheduleType = \"RATE\"\n)\n\n// Database model to encapsulate a launch plan.\ntype LaunchPlan struct {\n\tBaseModel\n\tLaunchPlanKey\n\tSpec       []byte `gorm:\"not null\"`\n\tWorkflowID uint   `gorm:\"index\"`\n\tClosure    []byte `gorm:\"not null\"`\n\t// GORM doesn't save the zero value for ints, so we use a pointer for the State field\n\tState *int32 `gorm:\"default:0\"`\n\t// Hash of the launch plan\n\tDigest       []byte\n\tScheduleType LaunchPlanScheduleType\n}\n", "package models\n\nimport (\n\t\"github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/core\"\n)\n\n// NamedEntityMetadata primary key\ntype NamedEntityMetadataKey struct {\n\tResourceType core.ResourceType `gorm:\"primary_key;index:named_entity_metadata_type_project_domain_name_idx\" valid:\"length(0|255)\"`\n\tProject      string            `gorm:\"primary_key;index:named_entity_metadata_type_project_domain_name_idx\" valid:\"length(0|255)\"`\n\tDomain       string            `gorm:\"primary_key;index:named_entity_metadata_type_project_domain_name_idx\" valid:\"length(0|255)\"`\n\tName         string            `gorm:\"primary_key;index:named_entity_metadata_type_project_domain_name_idx\" valid:\"length(0|255)\"`\n}\n\n// Fields to be composed into any named entity\ntype NamedEntityMetadataFields struct {\n\tDescription string `gorm:\"type:varchar(300)\"`\n\t// GORM doesn't save the zero value for ints, so we use a pointer for the State field\n\tState *int32 `gorm:\"default:0\"`\n}\n\n// Database model to encapsulate metadata associated with a NamedEntity\ntype NamedEntityMetadata struct {\n\tBaseModel\n\tNamedEntityMetadataKey\n\tNamedEntityMetadataFields\n}\n\n// NamedEntity key. This is used as a lookup for NamedEntityMetadata, so the\n// fields here should match the ones in NamedEntityMetadataKey.\ntype NamedEntityKey struct {\n\tResourceType core.ResourceType\n\tProject      string `valid:\"length(0|255)\"`\n\tDomain       string `valid:\"length(0|255)\"`\n\tName         string `valid:\"length(0|255)\"`\n}\n\n// Composes an identifier (NamedEntity) and its associated metadata fields\ntype NamedEntity struct {\n\tNamedEntityKey\n\tNamedEntityMetadataFields\n}\n", "package models\n\nimport (\n\t\"time\"\n)\n\n// IMPORTANT: If you update the model below, be sure to double check model definitions in\n// pkg/repositories/config/migration_models.go\n\ntype NodeExecutionKey struct {\n\tExecutionKey\n\tNodeID string `gorm:\"primary_key;index\" valid:\"length(0|255)\"`\n}\n\n// By convention, gorm foreign key references are of the form {ModelName}ID\ntype NodeExecution struct {\n\tBaseModel\n\tNodeExecutionKey\n\t// Also stored in the closure, but defined as a separate column because it's useful for filtering and sorting.\n\tPhase     string\n\tInputURI  string\n\tClosure   []byte\n\tStartedAt *time.Time\n\t// Corresponds to the CreatedAt field in the NodeExecution closure\n\t// Prefixed with NodeExecution to avoid clashes with gorm.Model CreatedAt\n\tNodeExecutionCreatedAt *time.Time\n\t// Corresponds to the UpdatedAt field in the NodeExecution closure\n\t// Prefixed with NodeExecution to avoid clashes with gorm.Model UpdatedAt\n\tNodeExecutionUpdatedAt *time.Time\n\tDuration               time.Duration\n\t// Metadata about the node execution.\n\tNodeExecutionMetadata []byte\n\t// Parent that spawned this node execution - value is empty for executions at level 0\n\tParentID *uint `sql:\"default:null\" gorm:\"index\"`\n\t// List of child node executions - for cases like Dynamic task, sub workflow, etc\n\tChildNodeExecutions []NodeExecution `gorm:\"foreignKey:ParentID;references:ID\"`\n\t// The task execution (if any) which launched this node execution.\n\t// TO BE DEPRECATED - as we have now introduced ParentID\n\tParentTaskExecutionID *uint `sql:\"default:null\" gorm:\"index\"`\n\t// The workflow execution (if any) which this node execution launched\n\t// NOTE: LaunchedExecution[foreignkey:ParentNodeExecutionID] refers to Workflow execution launched and is different from ParentID\n\tLaunchedExecution Execution `gorm:\"foreignKey:ParentNodeExecutionID;references:ID\"`\n\t// Execution Error Kind. nullable, can be one of core.ExecutionError_ErrorKind\n\tErrorKind *string `gorm:\"index\"`\n\t// Execution Error Code nullable. string value, but finite set determined by the execution engine and plugins\n\tErrorCode *string\n\t// If the node is of Type Task, this should always exist for a successful execution, indicating the cache status for the execution\n\tCacheStatus *string\n\t// In the case of dynamic workflow nodes, the remote closure is uploaded to the path specified here.\n\tDynamicWorkflowRemoteClosureReference string\n\t// Metadata that is only relevant to the flyteadmin service that is used to parse the model and track additional attributes.\n\tInternalData []byte\n}\n", "package models\n\nimport (\n\t\"time\"\n)\n\ntype NodeExecutionEvent struct {\n\tBaseModel\n\tNodeExecutionKey\n\tRequestID  string\n\tOccurredAt time.Time\n\tPhase      string `gorm:\"primary_key\"`\n}\n", "package models\n\ntype Project struct {\n\tBaseModel\n\tIdentifier  string `gorm:\"primary_key\"`\n\tName        string `valid:\"length(0|255)\"` // Human-readable name, not a unique identifier.\n\tDescription string `gorm:\"type:varchar(300)\"`\n\tLabels      []byte\n\t// GORM doesn't save the zero value for ints, so we use a pointer for the State field\n\tState *int32 `gorm:\"default:0;index\"`\n}\n", "package models\n\n// Signal primary key\ntype SignalKey struct {\n\tExecutionKey\n\tSignalID string `gorm:\"primary_key;index\" valid:\"length(0|255)\"`\n}\n\n// Database model to encapsulate a signal.\ntype Signal struct {\n\tBaseModel\n\tSignalKey\n\tType  []byte `gorm:\"not null\"`\n\tValue []byte\n}\n", "package models\n\n// IMPORTANT: If you update the model below, be sure to double check model definitions in\n// pkg/repositories/config/migration_models.go\n\n// Task primary key\ntype TaskKey struct {\n\tProject string `gorm:\"primary_key;index:task_project_domain_name_idx;index:task_project_domain_idx\" valid:\"length(0|255)\"`\n\tDomain  string `gorm:\"primary_key;index:task_project_domain_name_idx;index:task_project_domain_idx\" valid:\"length(0|255)\"`\n\tName    string `gorm:\"primary_key;index:task_project_domain_name_idx\" valid:\"length(0|255)\"`\n\tVersion string `gorm:\"primary_key\" valid:\"length(0|255)\"`\n}\n\n// Database model to encapsulate a task.\ntype Task struct {\n\tBaseModel\n\tTaskKey\n\tClosure []byte `gorm:\"not null\"`\n\t// Hash of the compiled task closure\n\tDigest []byte\n\t// Task type (also stored in the closure put promoted as a column for filtering).\n\tType string `valid:\"length(0|255)\"`\n\t// ShortDescription for the task.\n\tShortDescription string\n}\n", "package models\n\nimport (\n\t\"time\"\n)\n\n// IMPORTANT: If you update the model below, be sure to double check model definitions in\n// pkg/repositories/config/migration_models.go\n\n// Task execution primary key\ntype TaskExecutionKey struct {\n\tTaskKey\n\tNodeExecutionKey\n\t// *IMPORTANT* This is a pointer to an int in order to allow setting an empty (\"0\") value according to gorm convention.\n\t// Because RetryAttempt is part of the TaskExecution primary key is should *never* be null.\n\tRetryAttempt *uint32 `gorm:\"primary_key\"`\n}\n\n// By convention, gorm foreign key references are of the form {ModelName}ID\ntype TaskExecution struct {\n\tBaseModel\n\tTaskExecutionKey\n\tPhase        string `valid:\"length(0|255)\"`\n\tPhaseVersion uint32\n\tInputURI     string `valid:\"length(0|255)\"`\n\tClosure      []byte\n\tStartedAt    *time.Time\n\t// Corresponds to the CreatedAt field in the TaskExecution closure\n\t// This field is prefixed with TaskExecution because it signifies when\n\t// the execution was createdAt, not to be confused with gorm.Model.CreatedAt\n\tTaskExecutionCreatedAt *time.Time\n\t// Corresponds to the UpdatedAt field in the TaskExecution closure\n\t// This field is prefixed with TaskExecution because it signifies when\n\t// the execution was UpdatedAt, not to be confused with gorm.Model.UpdatedAt\n\tTaskExecutionUpdatedAt *time.Time\n\tDuration               time.Duration\n\t// The child node executions (if any) launched by this task execution.\n\tChildNodeExecution []NodeExecution `gorm:\"foreignkey:ParentTaskExecutionID;references:ID\"`\n}\n", "package models\n\n// Workflow primary key\ntype WorkflowKey struct {\n\tProject string `gorm:\"primary_key;index:workflow_project_domain_name_idx;index:workflow_project_domain_idx\"  valid:\"length(0|255)\"`\n\tDomain  string `gorm:\"primary_key;index:workflow_project_domain_name_idx;index:workflow_project_domain_idx\"  valid:\"length(0|255)\"`\n\tName    string `gorm:\"primary_key;index:workflow_project_domain_name_idx\"  valid:\"length(0|255)\"`\n\tVersion string `gorm:\"primary_key\"`\n}\n\n// Database model to encapsulate a workflow.\ntype Workflow struct {\n\tBaseModel\n\tWorkflowKey\n\tTypedInterface          []byte\n\tRemoteClosureIdentifier string `gorm:\"not null\" valid:\"length(0|255)\"`\n\t// Hash of the compiled workflow closure\n\tDigest []byte\n\t// ShortDescription for the workflow.\n\tShortDescription string\n}\n"], "fixing_code": ["package impl\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\n\t\"github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/admin\"\n\t\"github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/service\"\n\n\t\"github.com/flyteorg/flyteadmin/pkg/clusterresource/interfaces\"\n\t\"github.com/flyteorg/flyteadmin/pkg/common\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/models\"\n)\n\n// Implementation of an interfaces.FlyteAdminDataProvider which fetches data using a flyteadmin service client\ntype serviceAdminProvider struct {\n\tadminClient service.AdminServiceClient\n}\n\nfunc (p serviceAdminProvider) GetClusterResourceAttributes(ctx context.Context, project, domain string) (*admin.ClusterResourceAttributes, error) {\n\tresource, err := p.adminClient.GetProjectDomainAttributes(ctx, &admin.ProjectDomainAttributesGetRequest{\n\t\tProject:      project,\n\t\tDomain:       domain,\n\t\tResourceType: admin.MatchableResource_CLUSTER_RESOURCE,\n\t})\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif resource != nil && resource.Attributes != nil && resource.Attributes.MatchingAttributes != nil &&\n\t\tresource.Attributes.MatchingAttributes.GetClusterResourceAttributes() != nil {\n\t\treturn resource.Attributes.MatchingAttributes.GetClusterResourceAttributes(), nil\n\t}\n\treturn nil, NewMissingEntityError(\"cluster resource attributes\")\n}\n\nvar activeProjectsFilter = fmt.Sprintf(\"ne(state,%d)\", admin.Project_ARCHIVED)\n\nvar descCreatedAtSortParam = admin.Sort{\n\tDirection: admin.Sort_DESCENDING,\n\tKey:       \"created_at\",\n}\n\nvar descCreatedAtSortDBParam, _ = common.NewSortParameter(&descCreatedAtSortParam, models.ProjectColumns)\n\nfunc (p serviceAdminProvider) GetProjects(ctx context.Context) (*admin.Projects, error) {\n\tprojects := make([]*admin.Project, 0)\n\tlistReq := &admin.ProjectListRequest{\n\t\tLimit:   100,\n\t\tFilters: activeProjectsFilter,\n\t\t// Prefer to sync projects most newly created to ensure their resources get created first when other resources exist.\n\t\tSortBy: &descCreatedAtSortParam,\n\t}\n\n\t// Iterate through all pages of projects\n\tfor {\n\t\tprojectResp, err := p.adminClient.ListProjects(ctx, listReq)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tprojects = append(projects, projectResp.Projects...)\n\t\tif len(projectResp.Token) == 0 {\n\t\t\tbreak\n\t\t}\n\t\tlistReq.Token = projectResp.Token\n\t}\n\treturn &admin.Projects{\n\t\tProjects: projects,\n\t}, nil\n}\n\nfunc NewAdminServiceDataProvider(\n\tadminClient service.AdminServiceClient) interfaces.FlyteAdminDataProvider {\n\treturn &serviceAdminProvider{\n\t\tadminClient: adminClient,\n\t}\n}\n", "package impl\n\nimport (\n\t\"github.com/flyteorg/flyteadmin/pkg/errors\"\n\t\"google.golang.org/grpc/codes\"\n)\n\nfunc NewMissingEntityError(entity string) error {\n\treturn errors.NewFlyteAdminErrorf(codes.NotFound, \"Failed to find [%s]\", entity)\n}\n", "package common\n\nimport (\n\t\"fmt\"\n\t\"k8s.io/apimachinery/pkg/util/sets\"\n\n\t\"github.com/flyteorg/flyteadmin/pkg/errors\"\n\t\"github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/admin\"\n\t\"google.golang.org/grpc/codes\"\n)\n\nconst gormDescending = \"%s desc\"\nconst gormAscending = \"%s asc\"\n\ntype SortParameter interface {\n\tGetGormOrderExpr() string\n}\n\ntype sortParamImpl struct {\n\tgormOrderExpression string\n}\n\nfunc (s *sortParamImpl) GetGormOrderExpr() string {\n\treturn s.gormOrderExpression\n}\n\nfunc NewSortParameter(sort *admin.Sort, allowed sets.String) (SortParameter, error) {\n\tif sort == nil {\n\t\treturn nil, nil\n\t}\n\n\tkey := sort.Key\n\tif !allowed.Has(key) {\n\t\treturn nil, errors.NewFlyteAdminErrorf(codes.InvalidArgument, \"invalid sort key '%s'\", key)\n\t}\n\n\tvar gormOrderExpression string\n\tswitch sort.Direction {\n\tcase admin.Sort_DESCENDING:\n\t\tgormOrderExpression = fmt.Sprintf(gormDescending, key)\n\tcase admin.Sort_ASCENDING:\n\t\tgormOrderExpression = fmt.Sprintf(gormAscending, key)\n\tdefault:\n\t\treturn nil, errors.NewFlyteAdminErrorf(codes.InvalidArgument, \"invalid sort order specified: %v\", sort)\n\t}\n\treturn &sortParamImpl{\n\t\tgormOrderExpression: gormOrderExpression,\n\t}, nil\n}\n", "package common\n\nimport (\n\t\"testing\"\n\n\t\"k8s.io/apimachinery/pkg/util/sets\"\n\n\t\"github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/admin\"\n\t\"github.com/stretchr/testify/assert\"\n)\n\nfunc TestSortParameter_Nil(t *testing.T) {\n\tsortParameter, err := NewSortParameter(nil, nil)\n\n\tassert.NoError(t, err)\n\tassert.Nil(t, sortParameter)\n}\n\nfunc TestSortParameter_InvalidSortKey(t *testing.T) {\n\t_, err := NewSortParameter(&admin.Sort{\n\t\tDirection: admin.Sort_ASCENDING,\n\t\tKey:       \"wrong\",\n\t}, sets.NewString(\"name\"))\n\n\tassert.EqualError(t, err, \"invalid sort key 'wrong'\")\n}\n\nfunc TestSortParameter_InvalidSortDirection(t *testing.T) {\n\t_, err := NewSortParameter(&admin.Sort{\n\t\tDirection: 2,\n\t\tKey:       \"name\",\n\t}, sets.NewString(\"name\"))\n\n\tassert.EqualError(t, err, `invalid sort order specified: key:\"name\" direction:2 `)\n}\n\nfunc TestSortParameter_Ascending(t *testing.T) {\n\tsortParameter, err := NewSortParameter(&admin.Sort{\n\t\tDirection: admin.Sort_ASCENDING,\n\t\tKey:       \"name\",\n\t}, sets.NewString(\"name\"))\n\n\tassert.NoError(t, err)\n\tassert.Equal(t, \"name asc\", sortParameter.GetGormOrderExpr())\n}\n\nfunc TestSortParameter_Descending(t *testing.T) {\n\tsortParameter, err := NewSortParameter(&admin.Sort{\n\t\tDirection: admin.Sort_DESCENDING,\n\t\tKey:       \"project\",\n\t}, sets.NewString(\"project\"))\n\n\tassert.NoError(t, err)\n\tassert.Equal(t, \"project desc\", sortParameter.GetGormOrderExpr())\n}\n", "package impl\n\nimport (\n\t\"context\"\n\t\"strconv\"\n\n\t\"github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/admin\"\n\t\"github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/core\"\n\t\"github.com/flyteorg/flytestdlib/contextutils\"\n\t\"github.com/flyteorg/flytestdlib/logger\"\n\t\"github.com/flyteorg/flytestdlib/promutils\"\n\t\"google.golang.org/grpc/codes\"\n\n\t\"github.com/flyteorg/flyteadmin/pkg/common\"\n\t\"github.com/flyteorg/flyteadmin/pkg/errors\"\n\t\"github.com/flyteorg/flyteadmin/pkg/manager/impl/util\"\n\t\"github.com/flyteorg/flyteadmin/pkg/manager/impl/validation\"\n\t\"github.com/flyteorg/flyteadmin/pkg/manager/interfaces\"\n\trepoInterfaces \"github.com/flyteorg/flyteadmin/pkg/repositories/interfaces\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/models\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/transformers\"\n\truntimeInterfaces \"github.com/flyteorg/flyteadmin/pkg/runtime/interfaces\"\n)\n\ntype DescriptionEntityMetrics struct {\n\tScope promutils.Scope\n}\n\ntype DescriptionEntityManager struct {\n\tdb      repoInterfaces.Repository\n\tconfig  runtimeInterfaces.Configuration\n\tmetrics DescriptionEntityMetrics\n}\n\nfunc (d *DescriptionEntityManager) GetDescriptionEntity(ctx context.Context, request admin.ObjectGetRequest) (\n\t*admin.DescriptionEntity, error) {\n\tif err := validation.ValidateDescriptionEntityGetRequest(request); err != nil {\n\t\tlogger.Errorf(ctx, \"invalid request [%+v]: %v\", request, err)\n\t\treturn nil, err\n\t}\n\tctx = contextutils.WithProjectDomain(ctx, request.Id.Project, request.Id.Domain)\n\treturn util.GetDescriptionEntity(ctx, d.db, *request.Id)\n}\n\nfunc (d *DescriptionEntityManager) ListDescriptionEntity(ctx context.Context, request admin.DescriptionEntityListRequest) (*admin.DescriptionEntityList, error) {\n\t// Check required fields\n\tif err := validation.ValidateDescriptionEntityListRequest(request); err != nil {\n\t\treturn nil, err\n\t}\n\tctx = contextutils.WithProjectDomain(ctx, request.Id.Project, request.Id.Domain)\n\n\tif request.ResourceType == core.ResourceType_WORKFLOW {\n\t\tctx = contextutils.WithWorkflowID(ctx, request.Id.Name)\n\t} else {\n\t\tctx = contextutils.WithTaskID(ctx, request.Id.Name)\n\t}\n\n\tfilters, err := util.GetDbFilters(util.FilterSpec{\n\t\tProject:        request.Id.Project,\n\t\tDomain:         request.Id.Domain,\n\t\tName:           request.Id.Name,\n\t\tRequestFilters: request.Filters,\n\t}, common.ResourceTypeToEntity[request.ResourceType])\n\tif err != nil {\n\t\tlogger.Error(ctx, \"failed to get database filter\")\n\t\treturn nil, err\n\t}\n\n\tsortParameter, err := common.NewSortParameter(request.SortBy, models.DescriptionEntityColumns)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\toffset, err := validation.ValidateToken(request.Token)\n\tif err != nil {\n\t\treturn nil, errors.NewFlyteAdminErrorf(codes.InvalidArgument,\n\t\t\t\"invalid pagination token %s for ListWorkflows\", request.Token)\n\t}\n\tlistDescriptionEntitiesInput := repoInterfaces.ListResourceInput{\n\t\tLimit:         int(request.Limit),\n\t\tOffset:        offset,\n\t\tInlineFilters: filters,\n\t\tSortParameter: sortParameter,\n\t}\n\toutput, err := d.db.DescriptionEntityRepo().List(ctx, listDescriptionEntitiesInput)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"Failed to list workflows with [%+v] with err %v\", request.Id, err)\n\t\treturn nil, err\n\t}\n\tdescriptionEntityList, err := transformers.FromDescriptionEntityModels(output.Entities)\n\tif err != nil {\n\t\tlogger.Errorf(ctx,\n\t\t\t\"Failed to transform workflow models [%+v] with err: %v\", output.Entities, err)\n\t\treturn nil, err\n\t}\n\tvar token string\n\tif len(output.Entities) == int(request.Limit) {\n\t\ttoken = strconv.Itoa(offset + len(output.Entities))\n\t}\n\treturn &admin.DescriptionEntityList{\n\t\tDescriptionEntities: descriptionEntityList,\n\t\tToken:               token,\n\t}, nil\n}\n\nfunc NewDescriptionEntityManager(\n\tdb repoInterfaces.Repository,\n\tconfig runtimeInterfaces.Configuration,\n\tscope promutils.Scope) interfaces.DescriptionEntityInterface {\n\n\tmetrics := DescriptionEntityMetrics{\n\t\tScope: scope,\n\t}\n\treturn &DescriptionEntityManager{\n\t\tdb:      db,\n\t\tconfig:  config,\n\t\tmetrics: metrics,\n\t}\n}\n", "package impl\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"strconv\"\n\t\"time\"\n\n\t\"github.com/benbjohnson/clock\"\n\t\"github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/admin\"\n\t\"github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/core\"\n\t\"github.com/flyteorg/flyteplugins/go/tasks/pluginmachinery/flytek8s\"\n\t\"github.com/flyteorg/flytestdlib/contextutils\"\n\t\"github.com/flyteorg/flytestdlib/logger\"\n\t\"github.com/flyteorg/flytestdlib/promutils\"\n\t\"github.com/flyteorg/flytestdlib/promutils/labeled\"\n\t\"github.com/flyteorg/flytestdlib/storage\"\n\t\"github.com/golang/protobuf/proto\"\n\t\"github.com/golang/protobuf/ptypes\"\n\t\"github.com/golang/protobuf/ptypes/timestamp\"\n\t\"github.com/prometheus/client_golang/prometheus\"\n\t\"google.golang.org/grpc/codes\"\n\n\t\"github.com/flyteorg/flyteadmin/auth\"\n\tcloudeventInterfaces \"github.com/flyteorg/flyteadmin/pkg/async/cloudevent/interfaces\"\n\teventWriter \"github.com/flyteorg/flyteadmin/pkg/async/events/interfaces\"\n\t\"github.com/flyteorg/flyteadmin/pkg/async/notifications\"\n\tnotificationInterfaces \"github.com/flyteorg/flyteadmin/pkg/async/notifications/interfaces\"\n\t\"github.com/flyteorg/flyteadmin/pkg/common\"\n\tdataInterfaces \"github.com/flyteorg/flyteadmin/pkg/data/interfaces\"\n\t\"github.com/flyteorg/flyteadmin/pkg/errors\"\n\t\"github.com/flyteorg/flyteadmin/pkg/manager/impl/executions\"\n\t\"github.com/flyteorg/flyteadmin/pkg/manager/impl/resources\"\n\t\"github.com/flyteorg/flyteadmin/pkg/manager/impl/shared\"\n\t\"github.com/flyteorg/flyteadmin/pkg/manager/impl/util\"\n\t\"github.com/flyteorg/flyteadmin/pkg/manager/impl/validation\"\n\t\"github.com/flyteorg/flyteadmin/pkg/manager/interfaces\"\n\trepositoryInterfaces \"github.com/flyteorg/flyteadmin/pkg/repositories/interfaces\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/models\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/transformers\"\n\truntimeInterfaces \"github.com/flyteorg/flyteadmin/pkg/runtime/interfaces\"\n\tworkflowengineInterfaces \"github.com/flyteorg/flyteadmin/pkg/workflowengine/interfaces\"\n\t\"github.com/flyteorg/flyteadmin/plugins\"\n)\n\nconst childContainerQueueKey = \"child_queue\"\n\n// Map of [project] -> map of [domain] -> stop watch\ntype projectDomainScopedStopWatchMap = map[string]map[string]*promutils.StopWatch\n\ntype executionSystemMetrics struct {\n\tScope                      promutils.Scope\n\tActiveExecutions           prometheus.Gauge\n\tExecutionsCreated          prometheus.Counter\n\tExecutionsTerminated       labeled.Counter\n\tExecutionEventsCreated     prometheus.Counter\n\tPropellerFailures          prometheus.Counter\n\tPublishNotificationError   prometheus.Counter\n\tTransformerError           prometheus.Counter\n\tUnexpectedDataError        prometheus.Counter\n\tSpecSizeBytes              prometheus.Summary\n\tClosureSizeBytes           prometheus.Summary\n\tAcceptanceDelay            prometheus.Summary\n\tPublishEventError          prometheus.Counter\n\tTerminateExecutionFailures prometheus.Counter\n}\n\ntype executionUserMetrics struct {\n\tScope                        promutils.Scope\n\tScheduledExecutionDelays     projectDomainScopedStopWatchMap\n\tWorkflowExecutionDurations   projectDomainScopedStopWatchMap\n\tWorkflowExecutionInputBytes  prometheus.Summary\n\tWorkflowExecutionOutputBytes prometheus.Summary\n}\n\ntype ExecutionManager struct {\n\tdb                        repositoryInterfaces.Repository\n\tconfig                    runtimeInterfaces.Configuration\n\tstorageClient             *storage.DataStore\n\tqueueAllocator            executions.QueueAllocator\n\t_clock                    clock.Clock\n\tsystemMetrics             executionSystemMetrics\n\tuserMetrics               executionUserMetrics\n\tnotificationClient        notificationInterfaces.Publisher\n\turlData                   dataInterfaces.RemoteURLInterface\n\tworkflowManager           interfaces.WorkflowInterface\n\tnamedEntityManager        interfaces.NamedEntityInterface\n\tresourceManager           interfaces.ResourceInterface\n\tqualityOfServiceAllocator executions.QualityOfServiceAllocator\n\teventPublisher            notificationInterfaces.Publisher\n\tcloudEventPublisher       notificationInterfaces.Publisher\n\tdbEventWriter             eventWriter.WorkflowExecutionEventWriter\n\tpluginRegistry            *plugins.Registry\n}\n\nfunc getExecutionContext(ctx context.Context, id *core.WorkflowExecutionIdentifier) context.Context {\n\tctx = contextutils.WithExecutionID(ctx, id.Name)\n\treturn contextutils.WithProjectDomain(ctx, id.Project, id.Domain)\n}\n\n// Returns the unique string which identifies the authenticated end user (if any).\nfunc getUser(ctx context.Context) string {\n\tidentityContext := auth.IdentityContextFromContext(ctx)\n\treturn identityContext.UserID()\n}\n\nfunc (m *ExecutionManager) populateExecutionQueue(\n\tctx context.Context, identifier core.Identifier, compiledWorkflow *core.CompiledWorkflowClosure) {\n\tqueueConfig := m.queueAllocator.GetQueue(ctx, identifier)\n\tfor _, task := range compiledWorkflow.Tasks {\n\t\tcontainer := task.Template.GetContainer()\n\t\tif container == nil {\n\t\t\t// Unrecognized target type, nothing to do\n\t\t\tcontinue\n\t\t}\n\n\t\tif queueConfig.DynamicQueue != \"\" {\n\t\t\tlogger.Debugf(ctx, \"Assigning %s as child queue for task %+v\", queueConfig.DynamicQueue, task.Template.Id)\n\t\t\tcontainer.Config = append(container.Config, &core.KeyValuePair{\n\t\t\t\tKey:   childContainerQueueKey,\n\t\t\t\tValue: queueConfig.DynamicQueue,\n\t\t\t})\n\t\t}\n\t}\n}\n\nfunc validateMapSize(maxEntries int, candidate map[string]string, candidateName string) error {\n\tif maxEntries == 0 {\n\t\t// Treat the max as unset\n\t\treturn nil\n\t}\n\tif len(candidate) > maxEntries {\n\t\treturn errors.NewFlyteAdminErrorf(codes.InvalidArgument, \"%s has too many entries [%v > %v]\",\n\t\t\tcandidateName, len(candidate), maxEntries)\n\t}\n\treturn nil\n}\n\ntype mapWithValues interface {\n\tGetValues() map[string]string\n}\n\nfunc resolveStringMap(preferredValues, defaultValues mapWithValues, valueName string, maxEntries int) (map[string]string, error) {\n\tvar response = make(map[string]string)\n\tif preferredValues != nil && preferredValues.GetValues() != nil {\n\t\tresponse = preferredValues.GetValues()\n\t} else if defaultValues != nil && defaultValues.GetValues() != nil {\n\t\tresponse = defaultValues.GetValues()\n\t}\n\n\terr := validateMapSize(maxEntries, response, valueName)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn response, nil\n}\n\nfunc (m *ExecutionManager) addPluginOverrides(ctx context.Context, executionID *core.WorkflowExecutionIdentifier,\n\tworkflowName, launchPlanName string) ([]*admin.PluginOverride, error) {\n\toverride, err := m.resourceManager.GetResource(ctx, interfaces.ResourceRequest{\n\t\tProject:      executionID.Project,\n\t\tDomain:       executionID.Domain,\n\t\tWorkflow:     workflowName,\n\t\tLaunchPlan:   launchPlanName,\n\t\tResourceType: admin.MatchableResource_PLUGIN_OVERRIDE,\n\t})\n\tif err != nil {\n\t\tec, ok := err.(errors.FlyteAdminError)\n\t\tif !ok || ec.Code() != codes.NotFound {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\tif override != nil && override.Attributes != nil && override.Attributes.GetPluginOverrides() != nil {\n\t\treturn override.Attributes.GetPluginOverrides().Overrides, nil\n\t}\n\treturn nil, nil\n}\n\n// TODO: Delete this code usage after the flyte v0.17.0 release\n// Assumes input contains a compiled task with a valid container resource execConfig.\n//\n// Note: The system will assign a system-default value for request but for limit it will deduce it from the request\n// itself => Limit := Min([Some-Multiplier X Request], System-Max). For now we are using a multiplier of 1. In\n// general we recommend the users to set limits close to requests for more predictability in the system.\nfunc (m *ExecutionManager) setCompiledTaskDefaults(ctx context.Context, task *core.CompiledTask,\n\tplatformTaskResources workflowengineInterfaces.TaskResources) {\n\n\tif task == nil {\n\t\tlogger.Warningf(ctx, \"Can't set default resources for nil task.\")\n\t\treturn\n\t}\n\n\tif task.Template == nil || task.Template.GetContainer() == nil {\n\t\t// Nothing to do\n\t\tlogger.Debugf(ctx, \"Not setting default resources for task [%+v], no container resources found to check\", task)\n\t\treturn\n\t}\n\n\tif task.Template.GetContainer().Resources == nil {\n\t\t// In case of no resources on the container, create empty requests and limits\n\t\t// so the container will still have resources configure properly\n\t\ttask.Template.GetContainer().Resources = &core.Resources{\n\t\t\tRequests: []*core.Resources_ResourceEntry{},\n\t\t\tLimits:   []*core.Resources_ResourceEntry{},\n\t\t}\n\t}\n\n\tvar finalizedResourceRequests = make([]*core.Resources_ResourceEntry, 0)\n\tvar finalizedResourceLimits = make([]*core.Resources_ResourceEntry, 0)\n\n\t// The IDL representation for container-type tasks represents resources as a list with string quantities.\n\t// In order to easily reason about them we convert them to a set where we can O(1) fetch specific resources (e.g. CPU)\n\t// and represent them as comparable quantities rather than strings.\n\ttaskResourceRequirements := util.GetCompleteTaskResourceRequirements(ctx, task.Template.Id, task)\n\n\tcpu := flytek8s.AdjustOrDefaultResource(taskResourceRequirements.Defaults.CPU, taskResourceRequirements.Limits.CPU,\n\t\tplatformTaskResources.Defaults.CPU, platformTaskResources.Limits.CPU)\n\tfinalizedResourceRequests = append(finalizedResourceRequests, &core.Resources_ResourceEntry{\n\t\tName:  core.Resources_CPU,\n\t\tValue: cpu.Request.String(),\n\t})\n\tfinalizedResourceLimits = append(finalizedResourceLimits, &core.Resources_ResourceEntry{\n\t\tName:  core.Resources_CPU,\n\t\tValue: cpu.Limit.String(),\n\t})\n\n\tmemory := flytek8s.AdjustOrDefaultResource(taskResourceRequirements.Defaults.Memory, taskResourceRequirements.Limits.Memory,\n\t\tplatformTaskResources.Defaults.Memory, platformTaskResources.Limits.Memory)\n\tfinalizedResourceRequests = append(finalizedResourceRequests, &core.Resources_ResourceEntry{\n\t\tName:  core.Resources_MEMORY,\n\t\tValue: memory.Request.String(),\n\t})\n\tfinalizedResourceLimits = append(finalizedResourceLimits, &core.Resources_ResourceEntry{\n\t\tName:  core.Resources_MEMORY,\n\t\tValue: memory.Limit.String(),\n\t})\n\n\t// Only assign ephemeral storage when it is either requested or limited in the task definition, or a platform\n\t// default exists.\n\tif !taskResourceRequirements.Defaults.EphemeralStorage.IsZero() ||\n\t\t!taskResourceRequirements.Limits.EphemeralStorage.IsZero() ||\n\t\t!platformTaskResources.Defaults.EphemeralStorage.IsZero() {\n\t\tephemeralStorage := flytek8s.AdjustOrDefaultResource(taskResourceRequirements.Defaults.EphemeralStorage, taskResourceRequirements.Limits.EphemeralStorage,\n\t\t\tplatformTaskResources.Defaults.EphemeralStorage, platformTaskResources.Limits.EphemeralStorage)\n\t\tfinalizedResourceRequests = append(finalizedResourceRequests, &core.Resources_ResourceEntry{\n\t\t\tName:  core.Resources_EPHEMERAL_STORAGE,\n\t\t\tValue: ephemeralStorage.Request.String(),\n\t\t})\n\t\tfinalizedResourceLimits = append(finalizedResourceLimits, &core.Resources_ResourceEntry{\n\t\t\tName:  core.Resources_EPHEMERAL_STORAGE,\n\t\t\tValue: ephemeralStorage.Limit.String(),\n\t\t})\n\t}\n\n\t// Only assign storage when it is either requested or limited in the task definition, or a platform\n\t// default exists.\n\tif !taskResourceRequirements.Defaults.Storage.IsZero() ||\n\t\t!taskResourceRequirements.Limits.Storage.IsZero() ||\n\t\t!platformTaskResources.Defaults.Storage.IsZero() {\n\t\tstorageResource := flytek8s.AdjustOrDefaultResource(taskResourceRequirements.Defaults.Storage, taskResourceRequirements.Limits.Storage,\n\t\t\tplatformTaskResources.Defaults.Storage, platformTaskResources.Limits.Storage)\n\t\tfinalizedResourceRequests = append(finalizedResourceRequests, &core.Resources_ResourceEntry{\n\t\t\tName:  core.Resources_STORAGE,\n\t\t\tValue: storageResource.Request.String(),\n\t\t})\n\t\tfinalizedResourceLimits = append(finalizedResourceLimits, &core.Resources_ResourceEntry{\n\t\t\tName:  core.Resources_STORAGE,\n\t\t\tValue: storageResource.Limit.String(),\n\t\t})\n\t}\n\n\t// Only assign gpu when it is either requested or limited in the task definition, or a platform default exists.\n\tif !taskResourceRequirements.Defaults.GPU.IsZero() ||\n\t\t!taskResourceRequirements.Limits.GPU.IsZero() ||\n\t\t!platformTaskResources.Defaults.GPU.IsZero() {\n\t\tgpu := flytek8s.AdjustOrDefaultResource(taskResourceRequirements.Defaults.GPU, taskResourceRequirements.Limits.GPU,\n\t\t\tplatformTaskResources.Defaults.GPU, platformTaskResources.Limits.GPU)\n\t\tfinalizedResourceRequests = append(finalizedResourceRequests, &core.Resources_ResourceEntry{\n\t\t\tName:  core.Resources_GPU,\n\t\t\tValue: gpu.Request.String(),\n\t\t})\n\t\tfinalizedResourceLimits = append(finalizedResourceLimits, &core.Resources_ResourceEntry{\n\t\t\tName:  core.Resources_GPU,\n\t\t\tValue: gpu.Limit.String(),\n\t\t})\n\t}\n\n\ttask.Template.GetContainer().Resources = &core.Resources{\n\t\tRequests: finalizedResourceRequests,\n\t\tLimits:   finalizedResourceLimits,\n\t}\n}\n\n// Fetches inherited execution metadata including the parent node execution db model id and the source execution model id\n// as well as sets request spec metadata with the inherited principal and adjusted nesting data.\nfunc (m *ExecutionManager) getInheritedExecMetadata(ctx context.Context, requestSpec *admin.ExecutionSpec,\n\tworkflowExecutionID *core.WorkflowExecutionIdentifier) (parentNodeExecutionID uint, sourceExecutionID uint, err error) {\n\tif requestSpec.Metadata == nil || requestSpec.Metadata.ParentNodeExecution == nil {\n\t\treturn parentNodeExecutionID, sourceExecutionID, nil\n\t}\n\tparentNodeExecutionModel, err := util.GetNodeExecutionModel(ctx, m.db, requestSpec.Metadata.ParentNodeExecution)\n\tif err != nil {\n\t\tlogger.Errorf(ctx, \"Failed to get node execution [%+v] that launched this execution [%+v] with error %v\",\n\t\t\trequestSpec.Metadata.ParentNodeExecution, workflowExecutionID, err)\n\t\treturn parentNodeExecutionID, sourceExecutionID, err\n\t}\n\n\tparentNodeExecutionID = parentNodeExecutionModel.ID\n\n\tsourceExecutionModel, err := util.GetExecutionModel(ctx, m.db, *requestSpec.Metadata.ParentNodeExecution.ExecutionId)\n\tif err != nil {\n\t\tlogger.Errorf(ctx, \"Failed to get workflow execution [%+v] that launched this execution [%+v] with error %v\",\n\t\t\trequestSpec.Metadata.ParentNodeExecution, workflowExecutionID, err)\n\t\treturn parentNodeExecutionID, sourceExecutionID, err\n\t}\n\tsourceExecutionID = sourceExecutionModel.ID\n\trequestSpec.Metadata.Principal = sourceExecutionModel.User\n\tsourceExecution, err := transformers.FromExecutionModel(ctx, *sourceExecutionModel, transformers.DefaultExecutionTransformerOptions)\n\tif err != nil {\n\t\tlogger.Errorf(ctx, \"Failed transform parent execution model for child execution [%+v] with err: %v\", workflowExecutionID, err)\n\t\treturn parentNodeExecutionID, sourceExecutionID, err\n\t}\n\tif sourceExecution.Spec.Metadata != nil {\n\t\trequestSpec.Metadata.Nesting = sourceExecution.Spec.Metadata.Nesting + 1\n\t} else {\n\t\trequestSpec.Metadata.Nesting = 1\n\t}\n\treturn parentNodeExecutionID, sourceExecutionID, nil\n}\n\n// Produces execution-time attributes for workflow execution.\n// Defaults to overridable execution values set in the execution create request, then looks at the launch plan values\n// (if any) before defaulting to values set in the matchable resource db and further if matchable resources don't\n// exist then defaults to one set in application configuration\nfunc (m *ExecutionManager) getExecutionConfig(ctx context.Context, request *admin.ExecutionCreateRequest,\n\tlaunchPlan *admin.LaunchPlan) (*admin.WorkflowExecutionConfig, error) {\n\n\tworkflowExecConfig := admin.WorkflowExecutionConfig{}\n\t// Merge the request spec into workflowExecConfig\n\tworkflowExecConfig = util.MergeIntoExecConfig(workflowExecConfig, request.Spec)\n\n\tvar workflowName string\n\tif launchPlan != nil && launchPlan.Spec != nil {\n\t\t// Merge the launch plan spec into workflowExecConfig\n\t\tworkflowExecConfig = util.MergeIntoExecConfig(workflowExecConfig, launchPlan.Spec)\n\t\tif launchPlan.Spec.WorkflowId != nil {\n\t\t\tworkflowName = launchPlan.Spec.WorkflowId.Name\n\t\t}\n\t}\n\n\t// This will get the most specific Workflow Execution Config.\n\tmatchableResource, err := util.GetMatchableResource(ctx, m.resourceManager,\n\t\tadmin.MatchableResource_WORKFLOW_EXECUTION_CONFIG, request.Project, request.Domain, workflowName)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif matchableResource != nil && matchableResource.Attributes.GetWorkflowExecutionConfig() != nil {\n\t\t// merge the matchable resource workflow execution config into workflowExecConfig\n\t\tworkflowExecConfig = util.MergeIntoExecConfig(workflowExecConfig,\n\t\t\tmatchableResource.Attributes.GetWorkflowExecutionConfig())\n\t}\n\n\t// To match what the front-end will display to the user, we need to do the project level query too.\n\t// This searches only for a direct match, and will not merge in system config level defaults like the\n\t// GetProjectAttributes call does, since that's done below.\n\t// The reason we need to do the project level query is for the case where some configs (say max parallelism)\n\t// is set on the project level, but other items (say service account) is set on the project-domain level.\n\t// In this case you want to use the project-domain service account, the project-level max parallelism, and\n\t// system level defaults for the rest.\n\t// See FLYTE-2322 for more background information.\n\tprojectMatchableResource, err := util.GetMatchableResource(ctx, m.resourceManager,\n\t\tadmin.MatchableResource_WORKFLOW_EXECUTION_CONFIG, request.Project, \"\", \"\")\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif projectMatchableResource != nil && projectMatchableResource.Attributes.GetWorkflowExecutionConfig() != nil {\n\t\t// merge the matchable resource workflow execution config into workflowExecConfig\n\t\tworkflowExecConfig = util.MergeIntoExecConfig(workflowExecConfig,\n\t\t\tprojectMatchableResource.Attributes.GetWorkflowExecutionConfig())\n\t}\n\n\t// Backward compatibility changes to get security context from auth role.\n\t// Older authRole or auth fields in the launchplan spec or execution request need to be used over application defaults.\n\t// This portion of the code makes sure if newer way of setting security context is empty i.e\n\t// K8sServiceAccount and  IamRole is empty then get the values from the deprecated fields.\n\tresolvedAuthRole := resolveAuthRole(request, launchPlan)\n\tresolvedSecurityCtx := resolveSecurityCtx(ctx, workflowExecConfig.GetSecurityContext(), resolvedAuthRole)\n\tif workflowExecConfig.GetSecurityContext() == nil &&\n\t\t(len(resolvedSecurityCtx.GetRunAs().GetK8SServiceAccount()) > 0 ||\n\t\t\tlen(resolvedSecurityCtx.GetRunAs().GetIamRole()) > 0) {\n\t\tworkflowExecConfig.SecurityContext = resolvedSecurityCtx\n\t}\n\n\t// Merge the application config into workflowExecConfig. If even the deprecated fields are not set\n\tworkflowExecConfig = util.MergeIntoExecConfig(workflowExecConfig, m.config.ApplicationConfiguration().GetTopLevelConfig())\n\t// Explicitly set the security context if its nil since downstream we expect this settings to be available\n\tif workflowExecConfig.GetSecurityContext() == nil {\n\t\tworkflowExecConfig.SecurityContext = &core.SecurityContext{\n\t\t\tRunAs: &core.Identity{},\n\t\t}\n\t}\n\n\tif workflowExecConfig.GetSecurityContext().GetRunAs() == nil {\n\t\tworkflowExecConfig.SecurityContext.RunAs = &core.Identity{}\n\t}\n\n\t// In the case of reference_launch_plan subworkflow, the context comes from flytepropeller instead of the user side, so user auth is missing.\n\t// We skip getUserIdentityFromContext but can still get ExecUserId because flytepropeller passes it in the execution request.\n\t// https://github.com/flyteorg/flytepropeller/blob/03a6672960ed04e7687ba4f790fee9a02a4057fb/pkg/controller/nodes/subworkflow/launchplan/admin.go#L114\n\tif workflowExecConfig.GetSecurityContext().GetRunAs().GetExecutionIdentity() == \"\" {\n\t\tworkflowExecConfig.SecurityContext.RunAs.ExecutionIdentity = auth.IdentityContextFromContext(ctx).ExecutionIdentity()\n\t}\n\n\tlogger.Infof(ctx, \"getting the workflow execution config from application configuration\")\n\t// Defaults to one from the application config\n\treturn &workflowExecConfig, nil\n}\n\nfunc (m *ExecutionManager) getClusterAssignment(ctx context.Context, request *admin.ExecutionCreateRequest) (\n\t*admin.ClusterAssignment, error) {\n\tif request.Spec.ClusterAssignment != nil {\n\t\treturn request.Spec.ClusterAssignment, nil\n\t}\n\n\tresource, err := m.resourceManager.GetResource(ctx, interfaces.ResourceRequest{\n\t\tProject:      request.Project,\n\t\tDomain:       request.Domain,\n\t\tResourceType: admin.MatchableResource_CLUSTER_ASSIGNMENT,\n\t})\n\tif err != nil {\n\t\tif flyteAdminError, ok := err.(errors.FlyteAdminError); !ok || flyteAdminError.Code() != codes.NotFound {\n\t\t\tlogger.Errorf(ctx, \"Failed to get cluster assignment overrides with error: %v\", err)\n\t\t\treturn nil, err\n\t\t}\n\t}\n\tif resource != nil && resource.Attributes.GetClusterAssignment() != nil {\n\t\treturn resource.Attributes.GetClusterAssignment(), nil\n\t}\n\tclusterPoolAssignment := m.config.ClusterPoolAssignmentConfiguration().GetClusterPoolAssignments()[request.GetDomain()]\n\n\treturn &admin.ClusterAssignment{\n\t\tClusterPoolName: clusterPoolAssignment.Pool,\n\t}, nil\n}\n\nfunc (m *ExecutionManager) launchSingleTaskExecution(\n\tctx context.Context, request admin.ExecutionCreateRequest, requestedAt time.Time) (\n\tcontext.Context, *models.Execution, error) {\n\n\ttaskModel, err := m.db.TaskRepo().Get(ctx, repositoryInterfaces.Identifier{\n\t\tProject: request.Spec.LaunchPlan.Project,\n\t\tDomain:  request.Spec.LaunchPlan.Domain,\n\t\tName:    request.Spec.LaunchPlan.Name,\n\t\tVersion: request.Spec.LaunchPlan.Version,\n\t})\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\ttask, err := transformers.FromTaskModel(taskModel)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\n\t// Prepare a skeleton workflow\n\ttaskIdentifier := request.Spec.LaunchPlan\n\tworkflowModel, err :=\n\t\tutil.CreateOrGetWorkflowModel(ctx, request, m.db, m.workflowManager, m.namedEntityManager, taskIdentifier, &task)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"Failed to created skeleton workflow for [%+v] with err: %v\", taskIdentifier, err)\n\t\treturn nil, nil, err\n\t}\n\tworkflow, err := transformers.FromWorkflowModel(*workflowModel)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\tclosure, err := util.FetchAndGetWorkflowClosure(ctx, m.storageClient, workflowModel.RemoteClosureIdentifier)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\tclosure.CreatedAt = workflow.Closure.CreatedAt\n\tworkflow.Closure = closure\n\t// Also prepare a skeleton launch plan.\n\tlaunchPlan, err := util.CreateOrGetLaunchPlan(ctx, m.db, m.config, taskIdentifier,\n\t\tworkflow.Closure.CompiledWorkflow.Primary.Template.Interface, workflowModel.ID, request.Spec)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\n\texecutionInputs, err := validation.CheckAndFetchInputsForExecution(\n\t\trequest.Inputs,\n\t\tlaunchPlan.Spec.FixedInputs,\n\t\tlaunchPlan.Closure.ExpectedInputs,\n\t)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"Failed to CheckAndFetchInputsForExecution with request.Inputs: %+v\"+\n\t\t\t\"fixed inputs: %+v and expected inputs: %+v with err %v\",\n\t\t\trequest.Inputs, launchPlan.Spec.FixedInputs, launchPlan.Closure.ExpectedInputs, err)\n\t\treturn nil, nil, err\n\t}\n\n\tname := util.GetExecutionName(request)\n\tworkflowExecutionID := core.WorkflowExecutionIdentifier{\n\t\tProject: request.Project,\n\t\tDomain:  request.Domain,\n\t\tName:    name,\n\t}\n\tctx = getExecutionContext(ctx, &workflowExecutionID)\n\tnamespace := common.GetNamespaceName(\n\t\tm.config.NamespaceMappingConfiguration().GetNamespaceTemplate(), workflowExecutionID.Project, workflowExecutionID.Domain)\n\n\trequestSpec := request.Spec\n\tif requestSpec.Metadata == nil {\n\t\trequestSpec.Metadata = &admin.ExecutionMetadata{}\n\t}\n\trequestSpec.Metadata.Principal = getUser(ctx)\n\n\t// Get the node execution (if any) that launched this execution\n\tvar parentNodeExecutionID uint\n\tvar sourceExecutionID uint\n\tparentNodeExecutionID, sourceExecutionID, err = m.getInheritedExecMetadata(ctx, requestSpec, &workflowExecutionID)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\n\t// Dynamically assign task resource defaults.\n\tplatformTaskResources := util.GetTaskResources(ctx, workflow.Id, m.resourceManager, m.config.TaskResourceConfiguration())\n\tfor _, t := range workflow.Closure.CompiledWorkflow.Tasks {\n\t\tm.setCompiledTaskDefaults(ctx, t, platformTaskResources)\n\t}\n\n\t// Dynamically assign execution queues.\n\tm.populateExecutionQueue(ctx, *workflow.Id, workflow.Closure.CompiledWorkflow)\n\n\tinputsURI, err := common.OffloadLiteralMap(ctx, m.storageClient, request.Inputs, workflowExecutionID.Project, workflowExecutionID.Domain, workflowExecutionID.Name, shared.Inputs)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\tuserInputsURI, err := common.OffloadLiteralMap(ctx, m.storageClient, request.Inputs, workflowExecutionID.Project, workflowExecutionID.Domain, workflowExecutionID.Name, shared.UserInputs)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\texecutionConfig, err := m.getExecutionConfig(ctx, &request, nil)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\n\tvar labels map[string]string\n\tif executionConfig.Labels != nil {\n\t\tlabels = executionConfig.Labels.Values\n\t}\n\n\tlabels, err = m.addProjectLabels(ctx, request.Project, labels)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\n\tvar annotations map[string]string\n\tif executionConfig.Annotations != nil {\n\t\tannotations = executionConfig.Annotations.Values\n\t}\n\n\tvar rawOutputDataConfig *admin.RawOutputDataConfig\n\tif executionConfig.RawOutputDataConfig != nil {\n\t\trawOutputDataConfig = executionConfig.RawOutputDataConfig\n\t}\n\n\tclusterAssignment, err := m.getClusterAssignment(ctx, &request)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\n\texecutionParameters := workflowengineInterfaces.ExecutionParameters{\n\t\tInputs:              executionInputs,\n\t\tAcceptedAt:          requestedAt,\n\t\tLabels:              labels,\n\t\tAnnotations:         annotations,\n\t\tExecutionConfig:     executionConfig,\n\t\tTaskResources:       &platformTaskResources,\n\t\tEventVersion:        m.config.ApplicationConfiguration().GetTopLevelConfig().EventVersion,\n\t\tRoleNameKey:         m.config.ApplicationConfiguration().GetTopLevelConfig().RoleNameKey,\n\t\tRawOutputDataConfig: rawOutputDataConfig,\n\t\tClusterAssignment:   clusterAssignment,\n\t}\n\n\toverrides, err := m.addPluginOverrides(ctx, &workflowExecutionID, workflowExecutionID.Name, \"\")\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\tif overrides != nil {\n\t\texecutionParameters.TaskPluginOverrides = overrides\n\t}\n\tif request.Spec.Metadata != nil && request.Spec.Metadata.ReferenceExecution != nil &&\n\t\trequest.Spec.Metadata.Mode == admin.ExecutionMetadata_RECOVERED {\n\t\texecutionParameters.RecoveryExecution = request.Spec.Metadata.ReferenceExecution\n\t}\n\n\tworkflowExecutor := plugins.Get[workflowengineInterfaces.WorkflowExecutor](m.pluginRegistry, plugins.PluginIDWorkflowExecutor)\n\texecInfo, err := workflowExecutor.Execute(ctx, workflowengineInterfaces.ExecutionData{\n\t\tNamespace:                namespace,\n\t\tExecutionID:              &workflowExecutionID,\n\t\tReferenceWorkflowName:    workflow.Id.Name,\n\t\tReferenceLaunchPlanName:  launchPlan.Id.Name,\n\t\tWorkflowClosure:          workflow.Closure.CompiledWorkflow,\n\t\tWorkflowClosureReference: storage.DataReference(workflowModel.RemoteClosureIdentifier),\n\t\tExecutionParameters:      executionParameters,\n\t})\n\n\tif err != nil {\n\t\tm.systemMetrics.PropellerFailures.Inc()\n\t\tlogger.Infof(ctx, \"Failed to execute workflow %+v with execution id %+v and inputs %+v with err %v\",\n\t\t\trequest, workflowExecutionID, request.Inputs, err)\n\t\treturn nil, nil, err\n\t}\n\texecutionCreatedAt := time.Now()\n\tacceptanceDelay := executionCreatedAt.Sub(requestedAt)\n\tm.systemMetrics.AcceptanceDelay.Observe(acceptanceDelay.Seconds())\n\n\t// Request notification settings takes precedence over the launch plan settings.\n\t// If there is no notification in the request and DisableAll is not true, use the settings from the launch plan.\n\tvar notificationsSettings []*admin.Notification\n\tif launchPlan.Spec.GetEntityMetadata() != nil {\n\t\tnotificationsSettings = launchPlan.Spec.EntityMetadata.GetNotifications()\n\t}\n\tif request.Spec.GetNotifications() != nil && request.Spec.GetNotifications().Notifications != nil &&\n\t\tlen(request.Spec.GetNotifications().Notifications) > 0 {\n\t\tnotificationsSettings = request.Spec.GetNotifications().Notifications\n\t} else if request.Spec.GetDisableAll() {\n\t\tnotificationsSettings = make([]*admin.Notification, 0)\n\t}\n\n\texecutionModel, err := transformers.CreateExecutionModel(transformers.CreateExecutionModelInput{\n\t\tWorkflowExecutionID: workflowExecutionID,\n\t\tRequestSpec:         requestSpec,\n\t\tTaskID:              taskModel.ID,\n\t\tWorkflowID:          workflowModel.ID,\n\t\t// The execution is not considered running until the propeller sends a specific event saying so.\n\t\tPhase:                 core.WorkflowExecution_UNDEFINED,\n\t\tCreatedAt:             m._clock.Now(),\n\t\tNotifications:         notificationsSettings,\n\t\tWorkflowIdentifier:    workflow.Id,\n\t\tParentNodeExecutionID: parentNodeExecutionID,\n\t\tSourceExecutionID:     sourceExecutionID,\n\t\tCluster:               execInfo.Cluster,\n\t\tInputsURI:             inputsURI,\n\t\tUserInputsURI:         userInputsURI,\n\t\tSecurityContext:       executionConfig.SecurityContext,\n\t\tLaunchEntity:          taskIdentifier.ResourceType,\n\t\tNamespace:             namespace,\n\t})\n\tif err != nil {\n\t\tlogger.Infof(ctx, \"Failed to create execution model in transformer for id: [%+v] with err: %v\",\n\t\t\tworkflowExecutionID, err)\n\t\treturn nil, nil, err\n\t}\n\tm.userMetrics.WorkflowExecutionInputBytes.Observe(float64(proto.Size(request.Inputs)))\n\treturn ctx, executionModel, nil\n}\n\nfunc resolveAuthRole(request *admin.ExecutionCreateRequest, launchPlan *admin.LaunchPlan) *admin.AuthRole {\n\tif request.Spec.AuthRole != nil {\n\t\treturn request.Spec.AuthRole\n\t}\n\n\tif launchPlan == nil || launchPlan.Spec == nil {\n\t\treturn &admin.AuthRole{}\n\t}\n\n\t// Set role permissions based on launch plan Auth values.\n\t// The branched-ness of this check is due to the presence numerous deprecated fields\n\tif launchPlan.Spec.GetAuthRole() != nil {\n\t\treturn launchPlan.Spec.GetAuthRole()\n\t} else if launchPlan.GetSpec().GetAuth() != nil {\n\t\treturn &admin.AuthRole{\n\t\t\tAssumableIamRole:         launchPlan.GetSpec().GetAuth().AssumableIamRole,\n\t\t\tKubernetesServiceAccount: launchPlan.GetSpec().GetAuth().KubernetesServiceAccount,\n\t\t}\n\t} else if len(launchPlan.GetSpec().GetRole()) > 0 {\n\t\treturn &admin.AuthRole{\n\t\t\tAssumableIamRole: launchPlan.GetSpec().GetRole(),\n\t\t}\n\t}\n\n\treturn &admin.AuthRole{}\n}\n\nfunc resolveSecurityCtx(ctx context.Context, executionConfigSecurityCtx *core.SecurityContext,\n\tresolvedAuthRole *admin.AuthRole) *core.SecurityContext {\n\t// Use security context from the executionConfigSecurityCtx if its set and non empty or else resolve from authRole\n\tif executionConfigSecurityCtx != nil && executionConfigSecurityCtx.RunAs != nil &&\n\t\t(len(executionConfigSecurityCtx.RunAs.K8SServiceAccount) > 0 ||\n\t\t\tlen(executionConfigSecurityCtx.RunAs.IamRole) > 0 ||\n\t\t\tlen(executionConfigSecurityCtx.RunAs.ExecutionIdentity) > 0) {\n\t\treturn executionConfigSecurityCtx\n\t}\n\tlogger.Warn(ctx, \"Setting security context from auth Role\")\n\treturn &core.SecurityContext{\n\t\tRunAs: &core.Identity{\n\t\t\tIamRole:           resolvedAuthRole.AssumableIamRole,\n\t\t\tK8SServiceAccount: resolvedAuthRole.KubernetesServiceAccount,\n\t\t},\n\t}\n}\n\nfunc (m *ExecutionManager) launchExecutionAndPrepareModel(\n\tctx context.Context, request admin.ExecutionCreateRequest, requestedAt time.Time) (\n\tcontext.Context, *models.Execution, error) {\n\terr := validation.ValidateExecutionRequest(ctx, request, m.db, m.config.ApplicationConfiguration())\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"Failed to validate ExecutionCreateRequest %+v with err %v\", request, err)\n\t\treturn nil, nil, err\n\t}\n\tif request.Spec.LaunchPlan.ResourceType == core.ResourceType_TASK {\n\t\tlogger.Debugf(ctx, \"Launching single task execution with [%+v]\", request.Spec.LaunchPlan)\n\t\treturn m.launchSingleTaskExecution(ctx, request, requestedAt)\n\t}\n\n\tlaunchPlanModel, err := util.GetLaunchPlanModel(ctx, m.db, *request.Spec.LaunchPlan)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"Failed to get launch plan model for ExecutionCreateRequest %+v with err %v\", request, err)\n\t\treturn nil, nil, err\n\t}\n\tlaunchPlan, err := transformers.FromLaunchPlanModel(launchPlanModel)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"Failed to transform launch plan model %+v with err %v\", launchPlanModel, err)\n\t\treturn nil, nil, err\n\t}\n\texecutionInputs, err := validation.CheckAndFetchInputsForExecution(\n\t\trequest.Inputs,\n\t\tlaunchPlan.Spec.FixedInputs,\n\t\tlaunchPlan.Closure.ExpectedInputs,\n\t)\n\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"Failed to CheckAndFetchInputsForExecution with request.Inputs: %+v\"+\n\t\t\t\"fixed inputs: %+v and expected inputs: %+v with err %v\",\n\t\t\trequest.Inputs, launchPlan.Spec.FixedInputs, launchPlan.Closure.ExpectedInputs, err)\n\t\treturn nil, nil, err\n\t}\n\n\tworkflowModel, err := util.GetWorkflowModel(ctx, m.db, *launchPlan.Spec.WorkflowId)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"Failed to get workflow with id %+v with err %v\", launchPlan.Spec.WorkflowId, err)\n\t\treturn nil, nil, err\n\t}\n\tworkflow, err := transformers.FromWorkflowModel(workflowModel)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"Failed to get workflow with id %+v with err %v\", launchPlan.Spec.WorkflowId, err)\n\t\treturn nil, nil, err\n\t}\n\tclosure, err := util.FetchAndGetWorkflowClosure(ctx, m.storageClient, workflowModel.RemoteClosureIdentifier)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"Failed to get workflow with id %+v with err %v\", launchPlan.Spec.WorkflowId, err)\n\t\treturn nil, nil, err\n\t}\n\tclosure.CreatedAt = workflow.Closure.CreatedAt\n\tworkflow.Closure = closure\n\n\tname := util.GetExecutionName(request)\n\tworkflowExecutionID := core.WorkflowExecutionIdentifier{\n\t\tProject: request.Project,\n\t\tDomain:  request.Domain,\n\t\tName:    name,\n\t}\n\tctx = getExecutionContext(ctx, &workflowExecutionID)\n\tvar requestSpec = request.Spec\n\tif requestSpec.Metadata == nil {\n\t\trequestSpec.Metadata = &admin.ExecutionMetadata{}\n\t}\n\trequestSpec.Metadata.Principal = getUser(ctx)\n\n\t// Get the node and parent execution (if any) that launched this execution\n\tvar parentNodeExecutionID uint\n\tvar sourceExecutionID uint\n\tparentNodeExecutionID, sourceExecutionID, err = m.getInheritedExecMetadata(ctx, requestSpec, &workflowExecutionID)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\n\t// Dynamically assign task resource defaults.\n\tplatformTaskResources := util.GetTaskResources(ctx, workflow.Id, m.resourceManager, m.config.TaskResourceConfiguration())\n\tfor _, task := range workflow.Closure.CompiledWorkflow.Tasks {\n\t\tm.setCompiledTaskDefaults(ctx, task, platformTaskResources)\n\t}\n\n\t// Dynamically assign execution queues.\n\tm.populateExecutionQueue(ctx, *workflow.Id, workflow.Closure.CompiledWorkflow)\n\n\tinputsURI, err := common.OffloadLiteralMap(ctx, m.storageClient, executionInputs, workflowExecutionID.Project, workflowExecutionID.Domain, workflowExecutionID.Name, shared.Inputs)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\tuserInputsURI, err := common.OffloadLiteralMap(ctx, m.storageClient, request.Inputs, workflowExecutionID.Project, workflowExecutionID.Domain, workflowExecutionID.Name, shared.UserInputs)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\n\texecutionConfig, err := m.getExecutionConfig(ctx, &request, launchPlan)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\n\tnamespace := common.GetNamespaceName(\n\t\tm.config.NamespaceMappingConfiguration().GetNamespaceTemplate(), workflowExecutionID.Project, workflowExecutionID.Domain)\n\n\tlabels, err := resolveStringMap(executionConfig.GetLabels(), launchPlan.Spec.Labels, \"labels\", m.config.RegistrationValidationConfiguration().GetMaxLabelEntries())\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\tlabels, err = m.addProjectLabels(ctx, request.Project, labels)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\tannotations, err := resolveStringMap(executionConfig.GetAnnotations(), launchPlan.Spec.Annotations, \"annotations\", m.config.RegistrationValidationConfiguration().GetMaxAnnotationEntries())\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\tvar rawOutputDataConfig *admin.RawOutputDataConfig\n\tif executionConfig.RawOutputDataConfig != nil {\n\t\trawOutputDataConfig = executionConfig.RawOutputDataConfig\n\t}\n\n\tclusterAssignment, err := m.getClusterAssignment(ctx, &request)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\n\texecutionParameters := workflowengineInterfaces.ExecutionParameters{\n\t\tInputs:              executionInputs,\n\t\tAcceptedAt:          requestedAt,\n\t\tLabels:              labels,\n\t\tAnnotations:         annotations,\n\t\tExecutionConfig:     executionConfig,\n\t\tTaskResources:       &platformTaskResources,\n\t\tEventVersion:        m.config.ApplicationConfiguration().GetTopLevelConfig().EventVersion,\n\t\tRoleNameKey:         m.config.ApplicationConfiguration().GetTopLevelConfig().RoleNameKey,\n\t\tRawOutputDataConfig: rawOutputDataConfig,\n\t\tClusterAssignment:   clusterAssignment,\n\t}\n\n\toverrides, err := m.addPluginOverrides(ctx, &workflowExecutionID, launchPlan.GetSpec().WorkflowId.Name, launchPlan.Id.Name)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\tif overrides != nil {\n\t\texecutionParameters.TaskPluginOverrides = overrides\n\t}\n\n\tif request.Spec.Metadata != nil && request.Spec.Metadata.ReferenceExecution != nil &&\n\t\trequest.Spec.Metadata.Mode == admin.ExecutionMetadata_RECOVERED {\n\t\texecutionParameters.RecoveryExecution = request.Spec.Metadata.ReferenceExecution\n\t}\n\n\tworkflowExecutor := plugins.Get[workflowengineInterfaces.WorkflowExecutor](m.pluginRegistry, plugins.PluginIDWorkflowExecutor)\n\texecInfo, err := workflowExecutor.Execute(ctx, workflowengineInterfaces.ExecutionData{\n\t\tNamespace:                namespace,\n\t\tExecutionID:              &workflowExecutionID,\n\t\tReferenceWorkflowName:    workflow.Id.Name,\n\t\tReferenceLaunchPlanName:  launchPlan.Id.Name,\n\t\tWorkflowClosure:          workflow.Closure.CompiledWorkflow,\n\t\tWorkflowClosureReference: storage.DataReference(workflowModel.RemoteClosureIdentifier),\n\t\tExecutionParameters:      executionParameters,\n\t})\n\n\tif err != nil {\n\t\tm.systemMetrics.PropellerFailures.Inc()\n\t\tlogger.Infof(ctx, \"Failed to execute workflow %+v with execution id %+v and inputs %+v with err %v\",\n\t\t\trequest, workflowExecutionID, executionInputs, err)\n\t\treturn nil, nil, err\n\t}\n\texecutionCreatedAt := time.Now()\n\tacceptanceDelay := executionCreatedAt.Sub(requestedAt)\n\tm.systemMetrics.AcceptanceDelay.Observe(acceptanceDelay.Seconds())\n\n\t// Request notification settings takes precedence over the launch plan settings.\n\t// If there is no notification in the request and DisableAll is not true, use the settings from the launch plan.\n\tvar notificationsSettings []*admin.Notification\n\tif launchPlan.Spec.GetEntityMetadata() != nil {\n\t\tnotificationsSettings = launchPlan.Spec.EntityMetadata.GetNotifications()\n\t}\n\tif requestSpec.GetNotifications() != nil && requestSpec.GetNotifications().Notifications != nil &&\n\t\tlen(requestSpec.GetNotifications().Notifications) > 0 {\n\t\tnotificationsSettings = requestSpec.GetNotifications().Notifications\n\t} else if requestSpec.GetDisableAll() {\n\t\tnotificationsSettings = make([]*admin.Notification, 0)\n\t}\n\n\texecutionModel, err := transformers.CreateExecutionModel(transformers.CreateExecutionModelInput{\n\t\tWorkflowExecutionID: workflowExecutionID,\n\t\tRequestSpec:         requestSpec,\n\t\tLaunchPlanID:        launchPlanModel.ID,\n\t\tWorkflowID:          launchPlanModel.WorkflowID,\n\t\t// The execution is not considered running until the propeller sends a specific event saying so.\n\t\tPhase:                 core.WorkflowExecution_UNDEFINED,\n\t\tCreatedAt:             m._clock.Now(),\n\t\tNotifications:         notificationsSettings,\n\t\tWorkflowIdentifier:    workflow.Id,\n\t\tParentNodeExecutionID: parentNodeExecutionID,\n\t\tSourceExecutionID:     sourceExecutionID,\n\t\tCluster:               execInfo.Cluster,\n\t\tInputsURI:             inputsURI,\n\t\tUserInputsURI:         userInputsURI,\n\t\tSecurityContext:       executionConfig.SecurityContext,\n\t\tLaunchEntity:          launchPlan.Id.ResourceType,\n\t\tNamespace:             namespace,\n\t})\n\tif err != nil {\n\t\tlogger.Infof(ctx, \"Failed to create execution model in transformer for id: [%+v] with err: %v\",\n\t\t\tworkflowExecutionID, err)\n\t\treturn nil, nil, err\n\t}\n\n\treturn ctx, executionModel, nil\n}\n\n// Inserts an execution model into the database store and emits platform metrics.\nfunc (m *ExecutionManager) createExecutionModel(\n\tctx context.Context, executionModel *models.Execution) (*core.WorkflowExecutionIdentifier, error) {\n\tworkflowExecutionIdentifier := core.WorkflowExecutionIdentifier{\n\t\tProject: executionModel.ExecutionKey.Project,\n\t\tDomain:  executionModel.ExecutionKey.Domain,\n\t\tName:    executionModel.ExecutionKey.Name,\n\t}\n\terr := m.db.ExecutionRepo().Create(ctx, *executionModel)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"failed to save newly created execution [%+v] with id %+v to db with err %v\",\n\t\t\tworkflowExecutionIdentifier, workflowExecutionIdentifier, err)\n\t\treturn nil, err\n\t}\n\tm.systemMetrics.ActiveExecutions.Inc()\n\tm.systemMetrics.ExecutionsCreated.Inc()\n\tm.systemMetrics.SpecSizeBytes.Observe(float64(len(executionModel.Spec)))\n\tm.systemMetrics.ClosureSizeBytes.Observe(float64(len(executionModel.Closure)))\n\treturn &workflowExecutionIdentifier, nil\n}\n\nfunc (m *ExecutionManager) CreateExecution(\n\tctx context.Context, request admin.ExecutionCreateRequest, requestedAt time.Time) (\n\t*admin.ExecutionCreateResponse, error) {\n\t// Prior to  flyteidl v0.15.0, Inputs was held in ExecutionSpec. Ensure older clients continue to work.\n\tif request.Inputs == nil || len(request.Inputs.Literals) == 0 {\n\t\trequest.Inputs = request.GetSpec().GetInputs()\n\t}\n\tvar executionModel *models.Execution\n\tvar err error\n\tctx, executionModel, err = m.launchExecutionAndPrepareModel(ctx, request, requestedAt)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tworkflowExecutionIdentifier, err := m.createExecutionModel(ctx, executionModel)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn &admin.ExecutionCreateResponse{\n\t\tId: workflowExecutionIdentifier,\n\t}, nil\n}\n\nfunc (m *ExecutionManager) RelaunchExecution(\n\tctx context.Context, request admin.ExecutionRelaunchRequest, requestedAt time.Time) (\n\t*admin.ExecutionCreateResponse, error) {\n\texistingExecutionModel, err := util.GetExecutionModel(ctx, m.db, *request.Id)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"Failed to get execution model for request [%+v] with err %v\", request, err)\n\t\treturn nil, err\n\t}\n\texistingExecution, err := transformers.FromExecutionModel(ctx, *existingExecutionModel, transformers.DefaultExecutionTransformerOptions)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\texecutionSpec := existingExecution.Spec\n\tif executionSpec.Metadata == nil {\n\t\texecutionSpec.Metadata = &admin.ExecutionMetadata{}\n\t}\n\tvar inputs *core.LiteralMap\n\tif len(existingExecutionModel.UserInputsURI) > 0 {\n\t\tinputs = &core.LiteralMap{}\n\t\tif err := m.storageClient.ReadProtobuf(ctx, existingExecutionModel.UserInputsURI, inputs); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t} else {\n\t\t// For old data, inputs are held in the spec\n\t\tvar spec admin.ExecutionSpec\n\t\terr = proto.Unmarshal(existingExecutionModel.Spec, &spec)\n\t\tif err != nil {\n\t\t\treturn nil, errors.NewFlyteAdminErrorf(codes.Internal, \"failed to unmarshal spec\")\n\t\t}\n\t\tinputs = spec.Inputs\n\t}\n\texecutionSpec.Metadata.Mode = admin.ExecutionMetadata_RELAUNCH\n\texecutionSpec.Metadata.ReferenceExecution = existingExecution.Id\n\texecutionSpec.OverwriteCache = request.GetOverwriteCache()\n\tvar executionModel *models.Execution\n\tctx, executionModel, err = m.launchExecutionAndPrepareModel(ctx, admin.ExecutionCreateRequest{\n\t\tProject: request.Id.Project,\n\t\tDomain:  request.Id.Domain,\n\t\tName:    request.Name,\n\t\tSpec:    executionSpec,\n\t\tInputs:  inputs,\n\t}, requestedAt)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\texecutionModel.SourceExecutionID = existingExecutionModel.ID\n\tworkflowExecutionIdentifier, err := m.createExecutionModel(ctx, executionModel)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tlogger.Debugf(ctx, \"Successfully relaunched [%+v] as [%+v]\", request.Id, workflowExecutionIdentifier)\n\treturn &admin.ExecutionCreateResponse{\n\t\tId: workflowExecutionIdentifier,\n\t}, nil\n}\n\nfunc (m *ExecutionManager) RecoverExecution(\n\tctx context.Context, request admin.ExecutionRecoverRequest, requestedAt time.Time) (\n\t*admin.ExecutionCreateResponse, error) {\n\texistingExecutionModel, err := util.GetExecutionModel(ctx, m.db, *request.Id)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"Failed to get execution model for request [%+v] with err %v\", request, err)\n\t\treturn nil, err\n\t}\n\texistingExecution, err := transformers.FromExecutionModel(ctx, *existingExecutionModel, transformers.DefaultExecutionTransformerOptions)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\texecutionSpec := existingExecution.Spec\n\tif executionSpec.Metadata == nil {\n\t\texecutionSpec.Metadata = &admin.ExecutionMetadata{}\n\t}\n\tvar inputs *core.LiteralMap\n\tif len(existingExecutionModel.UserInputsURI) > 0 {\n\t\tinputs = &core.LiteralMap{}\n\t\tif err := m.storageClient.ReadProtobuf(ctx, existingExecutionModel.UserInputsURI, inputs); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\tif request.Metadata != nil {\n\t\texecutionSpec.Metadata.ParentNodeExecution = request.Metadata.ParentNodeExecution\n\t}\n\texecutionSpec.Metadata.Mode = admin.ExecutionMetadata_RECOVERED\n\texecutionSpec.Metadata.ReferenceExecution = existingExecution.Id\n\tvar executionModel *models.Execution\n\tctx, executionModel, err = m.launchExecutionAndPrepareModel(ctx, admin.ExecutionCreateRequest{\n\t\tProject: request.Id.Project,\n\t\tDomain:  request.Id.Domain,\n\t\tName:    request.Name,\n\t\tSpec:    executionSpec,\n\t\tInputs:  inputs,\n\t}, requestedAt)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\texecutionModel.SourceExecutionID = existingExecutionModel.ID\n\tworkflowExecutionIdentifier, err := m.createExecutionModel(ctx, executionModel)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tlogger.Infof(ctx, \"Successfully recovered [%+v] as [%+v]\", request.Id, workflowExecutionIdentifier)\n\treturn &admin.ExecutionCreateResponse{\n\t\tId: workflowExecutionIdentifier,\n\t}, nil\n}\n\nfunc (m *ExecutionManager) emitScheduledWorkflowMetrics(\n\tctx context.Context, executionModel *models.Execution, runningEventTimeProto *timestamp.Timestamp) {\n\tif executionModel == nil || runningEventTimeProto == nil {\n\t\tlogger.Warningf(context.Background(),\n\t\t\t\"tried to calculate scheduled workflow execution stats with a nil execution or event time\")\n\t\treturn\n\t}\n\t// Find the reference launch plan to get the kickoff time argument\n\texecution, err := transformers.FromExecutionModel(ctx, *executionModel, transformers.DefaultExecutionTransformerOptions)\n\tif err != nil {\n\t\tlogger.Warningf(context.Background(),\n\t\t\t\"failed to transform execution model when emitting scheduled workflow execution stats with for \"+\n\t\t\t\t\"[%s/%s/%s]\", executionModel.Project, executionModel.Domain, executionModel.Name)\n\t\treturn\n\t}\n\tlaunchPlan, err := util.GetLaunchPlan(context.Background(), m.db, *execution.Spec.LaunchPlan)\n\tif err != nil {\n\t\tlogger.Warningf(context.Background(),\n\t\t\t\"failed to find launch plan when emitting scheduled workflow execution stats with for \"+\n\t\t\t\t\"execution: [%+v] and launch plan [%+v]\", execution.Id, execution.Spec.LaunchPlan)\n\t\treturn\n\t}\n\n\tif launchPlan.Spec.EntityMetadata == nil ||\n\t\tlaunchPlan.Spec.EntityMetadata.Schedule == nil ||\n\t\tlaunchPlan.Spec.EntityMetadata.Schedule.KickoffTimeInputArg == \"\" {\n\t\t// Kickoff time arguments aren't always required for scheduled workflows.\n\t\tlogger.Debugf(context.Background(), \"no kickoff time to report for scheduled workflow execution [%+v]\",\n\t\t\texecution.Id)\n\t\treturn\n\t}\n\n\tvar inputs core.LiteralMap\n\terr = m.storageClient.ReadProtobuf(ctx, executionModel.InputsURI, &inputs)\n\tif err != nil {\n\t\tlogger.Errorf(ctx, \"Failed to find inputs for emitting schedule delay event from uri: [%v]\", executionModel.InputsURI)\n\t\treturn\n\t}\n\tscheduledKickoffTimeProto := inputs.Literals[launchPlan.Spec.EntityMetadata.Schedule.KickoffTimeInputArg]\n\tif scheduledKickoffTimeProto == nil || scheduledKickoffTimeProto.GetScalar() == nil ||\n\t\tscheduledKickoffTimeProto.GetScalar().GetPrimitive() == nil ||\n\t\tscheduledKickoffTimeProto.GetScalar().GetPrimitive().GetDatetime() == nil {\n\t\tlogger.Warningf(context.Background(),\n\t\t\t\"failed to find scheduled kickoff time datetime value for scheduled workflow execution [%+v] \"+\n\t\t\t\t\"although one was expected\", execution.Id)\n\t\treturn\n\t}\n\tscheduledKickoffTime, err := ptypes.Timestamp(scheduledKickoffTimeProto.GetScalar().GetPrimitive().GetDatetime())\n\tif err != nil {\n\t\t// Timestamps are serialized by flyteadmin and should always be valid\n\t\treturn\n\t}\n\trunningEventTime, err := ptypes.Timestamp(runningEventTimeProto)\n\tif err != nil {\n\t\t// Timestamps are always sent from propeller and should always be valid\n\t\treturn\n\t}\n\n\tdomainCounterMap, ok := m.userMetrics.ScheduledExecutionDelays[execution.Id.Project]\n\tif !ok {\n\t\tdomainCounterMap = make(map[string]*promutils.StopWatch)\n\t\tm.userMetrics.ScheduledExecutionDelays[execution.Id.Project] = domainCounterMap\n\t}\n\n\tvar watch *promutils.StopWatch\n\twatch, ok = domainCounterMap[execution.Id.Domain]\n\tif !ok {\n\t\tnewWatch, err := m.systemMetrics.Scope.NewSubScope(execution.Id.Project).NewSubScope(execution.Id.Domain).NewStopWatch(\n\t\t\t\"scheduled_execution_delay\",\n\t\t\t\"delay between scheduled execution time and time execution was observed running\",\n\t\t\ttime.Nanosecond)\n\t\tif err != nil {\n\t\t\t// Could be related to a concurrent exception.\n\t\t\tlogger.Debugf(context.Background(),\n\t\t\t\t\"failed to emit scheduled workflow execution delay stat, couldn't find or create counter\")\n\t\t\treturn\n\t\t}\n\t\twatch = &newWatch\n\t\tdomainCounterMap[execution.Id.Domain] = watch\n\t}\n\twatch.Observe(scheduledKickoffTime, runningEventTime)\n}\n\nfunc (m *ExecutionManager) emitOverallWorkflowExecutionTime(\n\texecutionModel *models.Execution, terminalEventTimeProto *timestamp.Timestamp) {\n\tif executionModel == nil || terminalEventTimeProto == nil {\n\t\tlogger.Warningf(context.Background(),\n\t\t\t\"tried to calculate scheduled workflow execution stats with a nil execution or event time\")\n\t\treturn\n\t}\n\n\tdomainCounterMap, ok := m.userMetrics.WorkflowExecutionDurations[executionModel.Project]\n\tif !ok {\n\t\tdomainCounterMap = make(map[string]*promutils.StopWatch)\n\t\tm.userMetrics.WorkflowExecutionDurations[executionModel.Project] = domainCounterMap\n\t}\n\n\tvar watch *promutils.StopWatch\n\twatch, ok = domainCounterMap[executionModel.Domain]\n\tif !ok {\n\t\tnewWatch, err := m.systemMetrics.Scope.NewSubScope(executionModel.Project).NewSubScope(executionModel.Domain).NewStopWatch(\n\t\t\t\"workflow_execution_duration\",\n\t\t\t\"overall time from when when a workflow create request was sent to k8s to the workflow terminating\",\n\t\t\ttime.Nanosecond)\n\t\tif err != nil {\n\t\t\t// Could be related to a concurrent exception.\n\t\t\tlogger.Debugf(context.Background(),\n\t\t\t\t\"failed to emit workflow execution duration stat, couldn't find or create counter\")\n\t\t\treturn\n\t\t}\n\t\twatch = &newWatch\n\t\tdomainCounterMap[executionModel.Domain] = watch\n\t}\n\n\tterminalEventTime, err := ptypes.Timestamp(terminalEventTimeProto)\n\tif err != nil {\n\t\t// Timestamps are always sent from propeller and should always be valid\n\t\treturn\n\t}\n\n\tif executionModel.ExecutionCreatedAt == nil {\n\t\tlogger.Warningf(context.Background(), \"found execution with nil ExecutionCreatedAt: [%s/%s/%s]\",\n\t\t\texecutionModel.Project, executionModel.Domain, executionModel.Name)\n\t\treturn\n\t}\n\twatch.Observe(*executionModel.ExecutionCreatedAt, terminalEventTime)\n}\n\nfunc (m *ExecutionManager) CreateWorkflowEvent(ctx context.Context, request admin.WorkflowExecutionEventRequest) (\n\t*admin.WorkflowExecutionEventResponse, error) {\n\terr := validation.ValidateCreateWorkflowEventRequest(request, m.config.ApplicationConfiguration().GetRemoteDataConfig().MaxSizeInBytes)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"received invalid CreateWorkflowEventRequest [%s]: %v\", request.RequestId, err)\n\t\treturn nil, err\n\t}\n\tctx = getExecutionContext(ctx, request.Event.ExecutionId)\n\tlogger.Debugf(ctx, \"Received workflow execution event for [%+v] transitioning to phase [%v]\",\n\t\trequest.Event.ExecutionId, request.Event.Phase)\n\n\texecutionModel, err := util.GetExecutionModel(ctx, m.db, *request.Event.ExecutionId)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"failed to find execution [%+v] for recorded event [%s]: %v\",\n\t\t\trequest.Event.ExecutionId, request.RequestId, err)\n\t\treturn nil, err\n\t}\n\n\twfExecPhase := core.WorkflowExecution_Phase(core.WorkflowExecution_Phase_value[executionModel.Phase])\n\t// Subsequent queued events announcing a cluster reassignment are permitted.\n\tif request.Event.Phase != core.WorkflowExecution_QUEUED {\n\t\tif wfExecPhase == request.Event.Phase {\n\t\t\tlogger.Debugf(ctx, \"This phase %s was already recorded for workflow execution %v\",\n\t\t\t\twfExecPhase.String(), request.Event.ExecutionId)\n\t\t\treturn nil, errors.NewFlyteAdminErrorf(codes.AlreadyExists,\n\t\t\t\t\"This phase %s was already recorded for workflow execution %v\",\n\t\t\t\twfExecPhase.String(), request.Event.ExecutionId)\n\t\t} else if err := validation.ValidateCluster(ctx, executionModel.Cluster, request.Event.ProducerId); err != nil {\n\t\t\t// Only perform event cluster validation **after** an execution has moved on from QUEUED.\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\tif common.IsExecutionTerminal(wfExecPhase) {\n\t\t// Cannot go backwards in time from a terminal state to anything else\n\t\tcurPhase := wfExecPhase.String()\n\t\terrorMsg := fmt.Sprintf(\"Invalid phase change from %s to %s for workflow execution %v\", curPhase, request.Event.Phase.String(), request.Event.ExecutionId)\n\t\treturn nil, errors.NewAlreadyInTerminalStateError(ctx, errorMsg, curPhase)\n\t} else if wfExecPhase == core.WorkflowExecution_RUNNING && request.Event.Phase == core.WorkflowExecution_QUEUED {\n\t\t// Cannot go back in time from RUNNING -> QUEUED\n\t\treturn nil, errors.NewFlyteAdminErrorf(codes.FailedPrecondition,\n\t\t\t\"Cannot go from %s to %s for workflow execution %v\",\n\t\t\twfExecPhase.String(), request.Event.Phase.String(), request.Event.ExecutionId)\n\t} else if wfExecPhase == core.WorkflowExecution_ABORTING && !common.IsExecutionTerminal(request.Event.Phase) {\n\t\treturn nil, errors.NewFlyteAdminErrorf(codes.FailedPrecondition,\n\t\t\t\"Invalid phase change from aborting to %s for workflow execution %v\", request.Event.Phase.String(), request.Event.ExecutionId)\n\t}\n\n\terr = transformers.UpdateExecutionModelState(ctx, executionModel, request, m.config.ApplicationConfiguration().GetRemoteDataConfig().InlineEventDataPolicy, m.storageClient)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"failed to transform updated workflow execution model [%+v] after receiving event with err: %v\",\n\t\t\trequest.Event.ExecutionId, err)\n\t\treturn nil, err\n\t}\n\terr = m.db.ExecutionRepo().Update(ctx, *executionModel)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"Failed to update execution with CreateWorkflowEvent [%+v] with err %v\",\n\t\t\trequest, err)\n\t\treturn nil, err\n\t}\n\tm.dbEventWriter.Write(request)\n\n\tif request.Event.Phase == core.WorkflowExecution_RUNNING {\n\t\t// Workflow executions are created in state \"UNDEFINED\". All the time up until a RUNNING event is received is\n\t\t// considered system-induced delay.\n\t\tif executionModel.Mode == int32(admin.ExecutionMetadata_SCHEDULED) {\n\t\t\tgo m.emitScheduledWorkflowMetrics(ctx, executionModel, request.Event.OccurredAt)\n\t\t}\n\t} else if common.IsExecutionTerminal(request.Event.Phase) {\n\t\tif request.Event.Phase == core.WorkflowExecution_FAILED {\n\t\t\t// request.Event is expected to be of type WorkflowExecutionEvent_Error when workflow fails.\n\t\t\t// if not, log the error and continue\n\t\t\tif err := request.Event.GetError(); err != nil {\n\t\t\t\tctx = context.WithValue(ctx, common.ErrorKindKey, err.Kind.String())\n\t\t\t} else {\n\t\t\t\tlogger.Warning(ctx, \"Failed to parse error for FAILED request [%+v]\", request)\n\t\t\t}\n\t\t}\n\n\t\tm.systemMetrics.ActiveExecutions.Dec()\n\t\tm.systemMetrics.ExecutionsTerminated.Inc(contextutils.WithPhase(ctx, request.Event.Phase.String()))\n\t\tgo m.emitOverallWorkflowExecutionTime(executionModel, request.Event.OccurredAt)\n\t\tif request.Event.GetOutputData() != nil {\n\t\t\tm.userMetrics.WorkflowExecutionOutputBytes.Observe(float64(proto.Size(request.Event.GetOutputData())))\n\t\t}\n\n\t\terr = m.publishNotifications(ctx, request, *executionModel)\n\t\tif err != nil {\n\t\t\t// The only errors that publishNotifications will forward are those related\n\t\t\t// to unexpected data and transformation errors.\n\t\t\tlogger.Debugf(ctx, \"failed to publish notifications for CreateWorkflowEvent [%+v] due to err: %v\",\n\t\t\t\trequest, err)\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\tif err := m.eventPublisher.Publish(ctx, proto.MessageName(&request), &request); err != nil {\n\t\tm.systemMetrics.PublishEventError.Inc()\n\t\tlogger.Infof(ctx, \"error publishing event [%+v] with err: [%v]\", request.RequestId, err)\n\t}\n\n\tgo func() {\n\t\tif err := m.cloudEventPublisher.Publish(ctx, proto.MessageName(&request), &request); err != nil {\n\t\t\tm.systemMetrics.PublishEventError.Inc()\n\t\t\tlogger.Infof(ctx, \"error publishing cloud event [%+v] with err: [%v]\", request.RequestId, err)\n\t\t}\n\t}()\n\n\treturn &admin.WorkflowExecutionEventResponse{}, nil\n}\n\nfunc (m *ExecutionManager) GetExecution(\n\tctx context.Context, request admin.WorkflowExecutionGetRequest) (*admin.Execution, error) {\n\tif err := validation.ValidateWorkflowExecutionIdentifier(request.Id); err != nil {\n\t\tlogger.Debugf(ctx, \"GetExecution request [%+v] failed validation with err: %v\", request, err)\n\t\treturn nil, err\n\t}\n\tctx = getExecutionContext(ctx, request.Id)\n\texecutionModel, err := util.GetExecutionModel(ctx, m.db, *request.Id)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"Failed to get execution model for request [%+v] with err: %v\", request, err)\n\t\treturn nil, err\n\t}\n\tnamespace := common.GetNamespaceName(\n\t\tm.config.NamespaceMappingConfiguration().GetNamespaceTemplate(), request.GetId().GetProject(), request.GetId().GetDomain())\n\texecution, transformerErr := transformers.FromExecutionModel(ctx, *executionModel, &transformers.ExecutionTransformerOptions{\n\t\tDefaultNamespace: namespace,\n\t})\n\tif transformerErr != nil {\n\t\tlogger.Debugf(ctx, \"Failed to transform execution model [%+v] to proto object with err: %v\", request.Id,\n\t\t\ttransformerErr)\n\t\treturn nil, transformerErr\n\t}\n\n\treturn execution, nil\n}\n\nfunc (m *ExecutionManager) UpdateExecution(ctx context.Context, request admin.ExecutionUpdateRequest,\n\trequestedAt time.Time) (*admin.ExecutionUpdateResponse, error) {\n\tif err := validation.ValidateWorkflowExecutionIdentifier(request.Id); err != nil {\n\t\tlogger.Debugf(ctx, \"UpdateExecution request [%+v] failed validation with err: %v\", request, err)\n\t\treturn nil, err\n\t}\n\tctx = getExecutionContext(ctx, request.Id)\n\texecutionModel, err := util.GetExecutionModel(ctx, m.db, *request.Id)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"Failed to get execution model for request [%+v] with err: %v\", request, err)\n\t\treturn nil, err\n\t}\n\n\tif err = transformers.UpdateExecutionModelStateChangeDetails(executionModel, request.State, requestedAt,\n\t\tgetUser(ctx)); err != nil {\n\t\treturn nil, err\n\t}\n\n\tif err := m.db.ExecutionRepo().Update(ctx, *executionModel); err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &admin.ExecutionUpdateResponse{}, nil\n}\n\nfunc (m *ExecutionManager) GetExecutionData(\n\tctx context.Context, request admin.WorkflowExecutionGetDataRequest) (*admin.WorkflowExecutionGetDataResponse, error) {\n\tctx = getExecutionContext(ctx, request.Id)\n\texecutionModel, err := util.GetExecutionModel(ctx, m.db, *request.Id)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"Failed to get execution model for request [%+v] with err: %v\", request, err)\n\t\treturn nil, err\n\t}\n\texecution, err := transformers.FromExecutionModel(ctx, *executionModel, transformers.DefaultExecutionTransformerOptions)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"Failed to transform execution model [%+v] to proto object with err: %v\", request.Id, err)\n\t\treturn nil, err\n\t}\n\t// Prior to flyteidl v0.15.0, Inputs were held in ExecutionClosure and were not offloaded. Ensure we can return the inputs as expected.\n\tif len(executionModel.InputsURI) == 0 {\n\t\tclosure := &admin.ExecutionClosure{}\n\t\t// We must not use the FromExecutionModel method because it empties deprecated fields.\n\t\tif err := proto.Unmarshal(executionModel.Closure, closure); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tnewInputsURI, err := common.OffloadLiteralMap(ctx, m.storageClient, closure.ComputedInputs, request.Id.Project, request.Id.Domain, request.Id.Name, shared.Inputs)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\t// Update model so as not to offload again.\n\t\texecutionModel.InputsURI = newInputsURI\n\t\tif err := m.db.ExecutionRepo().Update(ctx, *executionModel); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\tinputs, inputURLBlob, err := util.GetInputs(ctx, m.urlData, m.config.ApplicationConfiguration().GetRemoteDataConfig(),\n\t\tm.storageClient, executionModel.InputsURI.String())\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\toutputs, outputURLBlob, err := util.GetOutputs(ctx, m.urlData, m.config.ApplicationConfiguration().GetRemoteDataConfig(),\n\t\tm.storageClient, util.ToExecutionClosureInterface(execution.Closure))\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tresponse := &admin.WorkflowExecutionGetDataResponse{\n\t\tInputs:      inputURLBlob,\n\t\tOutputs:     outputURLBlob,\n\t\tFullInputs:  inputs,\n\t\tFullOutputs: outputs,\n\t}\n\n\tm.userMetrics.WorkflowExecutionInputBytes.Observe(float64(response.Inputs.Bytes))\n\tif response.Outputs.Bytes > 0 {\n\t\tm.userMetrics.WorkflowExecutionOutputBytes.Observe(float64(response.Outputs.Bytes))\n\t} else if response.FullOutputs != nil {\n\t\tm.userMetrics.WorkflowExecutionOutputBytes.Observe(float64(proto.Size(response.FullOutputs)))\n\t}\n\treturn response, nil\n}\n\nfunc (m *ExecutionManager) ListExecutions(\n\tctx context.Context, request admin.ResourceListRequest) (*admin.ExecutionList, error) {\n\t// Check required fields\n\tif err := validation.ValidateResourceListRequest(request); err != nil {\n\t\tlogger.Debugf(ctx, \"ListExecutions request [%+v] failed validation with err: %v\", request, err)\n\t\treturn nil, err\n\t}\n\tctx = contextutils.WithProjectDomain(ctx, request.Id.Project, request.Id.Domain)\n\tfilters, err := util.GetDbFilters(util.FilterSpec{\n\t\tProject:        request.Id.Project,\n\t\tDomain:         request.Id.Domain,\n\t\tName:           request.Id.Name, // Optional, may be empty.\n\t\tRequestFilters: request.Filters,\n\t}, common.Execution)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tsortParameter, err := common.NewSortParameter(request.SortBy, models.ExecutionColumns)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\toffset, err := validation.ValidateToken(request.Token)\n\tif err != nil {\n\t\treturn nil, errors.NewFlyteAdminErrorf(codes.InvalidArgument, \"invalid pagination token %s for ListExecutions\",\n\t\t\trequest.Token)\n\t}\n\tjoinTableEntities := make(map[common.Entity]bool)\n\tfor _, filter := range filters {\n\t\tjoinTableEntities[filter.GetEntity()] = true\n\t}\n\n\t// Check if state filter exists and if not then add filter to fetch only ACTIVE executions\n\tif filters, err = addStateFilter(filters); err != nil {\n\t\treturn nil, err\n\t}\n\n\tlistExecutionsInput := repositoryInterfaces.ListResourceInput{\n\t\tLimit:             int(request.Limit),\n\t\tOffset:            offset,\n\t\tInlineFilters:     filters,\n\t\tSortParameter:     sortParameter,\n\t\tJoinTableEntities: joinTableEntities,\n\t}\n\toutput, err := m.db.ExecutionRepo().List(ctx, listExecutionsInput)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"Failed to list executions using input [%+v] with err %v\", listExecutionsInput, err)\n\t\treturn nil, err\n\t}\n\texecutionList, err := transformers.FromExecutionModels(ctx, output.Executions, transformers.ListExecutionTransformerOptions)\n\tif err != nil {\n\t\tlogger.Errorf(ctx,\n\t\t\t\"Failed to transform execution models [%+v] with err: %v\", output.Executions, err)\n\t\treturn nil, err\n\t}\n\t// TODO: TO BE DELETED\n\t// Clear deprecated fields during migration phase. Once migration is complete, these will be cleared in the database.\n\t// Thus this will be redundant\n\tfor _, execution := range executionList {\n\t\texecution.Spec.Inputs = nil\n\t\texecution.Closure.ComputedInputs = nil\n\t}\n\n\t// END TO BE DELETED\n\tvar token string\n\tif len(executionList) == int(request.Limit) {\n\t\ttoken = strconv.Itoa(offset + len(executionList))\n\t}\n\treturn &admin.ExecutionList{\n\t\tExecutions: executionList,\n\t\tToken:      token,\n\t}, nil\n}\n\n// publishNotifications will only forward major errors because the assumption made is all of the objects\n// that are being manipulated have already been validated/manipulated by Flyte itself.\n// Note: This method should be refactored somewhere else once the interaction with pushing to SNS.\nfunc (m *ExecutionManager) publishNotifications(ctx context.Context, request admin.WorkflowExecutionEventRequest,\n\texecution models.Execution) error {\n\t// Notifications are stored in the Spec object of an admin.Execution object.\n\tadminExecution, err := transformers.FromExecutionModel(ctx, execution, transformers.DefaultExecutionTransformerOptions)\n\tif err != nil {\n\t\t// This shouldn't happen because execution manager marshaled the data into models.Execution.\n\t\tm.systemMetrics.TransformerError.Inc()\n\t\treturn errors.NewFlyteAdminErrorf(codes.Internal, \"Failed to transform execution [%+v] with err: %v\", request.Event.ExecutionId, err)\n\t}\n\tvar notificationsList = adminExecution.Closure.Notifications\n\tlogger.Debugf(ctx, \"publishing notifications for execution [%+v] in state [%+v] for notifications [%+v]\",\n\t\trequest.Event.ExecutionId, request.Event.Phase, notificationsList)\n\tfor _, notification := range notificationsList {\n\t\t// Check if the notification phase matches the current one.\n\t\tvar matchPhase = false\n\t\tfor _, phase := range notification.Phases {\n\t\t\tif phase == request.Event.Phase {\n\t\t\t\tmatchPhase = true\n\t\t\t}\n\t\t}\n\n\t\t// The current phase doesn't match; no notifications will be sent for the current notification option.\n\t\tif !matchPhase {\n\t\t\tcontinue\n\t\t}\n\n\t\t// Currently all three supported notifications use email underneath to send the notification.\n\t\t// Convert Slack and PagerDuty into an EmailNotification type.\n\t\tvar emailNotification admin.EmailNotification\n\t\tif notification.GetEmail() != nil {\n\t\t\temailNotification.RecipientsEmail = notification.GetEmail().GetRecipientsEmail()\n\t\t} else if notification.GetPagerDuty() != nil {\n\t\t\temailNotification.RecipientsEmail = notification.GetPagerDuty().GetRecipientsEmail()\n\t\t} else if notification.GetSlack() != nil {\n\t\t\temailNotification.RecipientsEmail = notification.GetSlack().GetRecipientsEmail()\n\t\t} else {\n\t\t\tlogger.Debugf(ctx, \"failed to publish notification, encountered unrecognized type: %v\", notification.Type)\n\t\t\tm.systemMetrics.UnexpectedDataError.Inc()\n\t\t\t// Unsupported notification types should have been caught when the launch plan was being created.\n\t\t\treturn errors.NewFlyteAdminErrorf(codes.Internal, \"Unsupported notification type [%v] for execution [%+v]\",\n\t\t\t\tnotification.Type, request.Event.ExecutionId)\n\t\t}\n\n\t\t// Convert the email Notification into an email message to be published.\n\t\t// Currently there are no possible errors while creating an email message.\n\t\t// Once customizable content is specified, errors are possible.\n\t\temail := notifications.ToEmailMessageFromWorkflowExecutionEvent(\n\t\t\t*m.config.ApplicationConfiguration().GetNotificationsConfig(), emailNotification, request, adminExecution)\n\t\t// Errors seen while publishing a message are considered non-fatal to the method and will not result\n\t\t// in the method returning an error.\n\t\tif err = m.notificationClient.Publish(ctx, proto.MessageName(&emailNotification), email); err != nil {\n\t\t\tm.systemMetrics.PublishNotificationError.Inc()\n\t\t\tlogger.Infof(ctx, \"error publishing email notification [%+v] with err: [%v]\", notification, err)\n\t\t}\n\t}\n\treturn nil\n}\n\nfunc (m *ExecutionManager) TerminateExecution(\n\tctx context.Context, request admin.ExecutionTerminateRequest) (*admin.ExecutionTerminateResponse, error) {\n\tif err := validation.ValidateWorkflowExecutionIdentifier(request.Id); err != nil {\n\t\tlogger.Debugf(ctx, \"received terminate execution request: %v with invalid identifier: %v\", request, err)\n\t\treturn nil, err\n\t}\n\tctx = getExecutionContext(ctx, request.Id)\n\t// Save the abort reason (best effort)\n\texecutionModel, err := m.db.ExecutionRepo().Get(ctx, repositoryInterfaces.Identifier{\n\t\tProject: request.Id.Project,\n\t\tDomain:  request.Id.Domain,\n\t\tName:    request.Id.Name,\n\t})\n\tif err != nil {\n\t\tlogger.Infof(ctx, \"couldn't find execution [%+v] to save termination cause\", request.Id)\n\t\treturn nil, err\n\t}\n\n\tif common.IsExecutionTerminal(core.WorkflowExecution_Phase(core.WorkflowExecution_Phase_value[executionModel.Phase])) {\n\t\treturn nil, errors.NewAlreadyInTerminalStateError(ctx, \"Cannot abort an already terminate workflow execution\", executionModel.Phase)\n\t}\n\n\terr = transformers.SetExecutionAborting(&executionModel, request.Cause, getUser(ctx))\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"failed to add abort metadata for execution [%+v] with err: %v\", request.Id, err)\n\t\treturn nil, err\n\t}\n\n\terr = m.db.ExecutionRepo().Update(ctx, executionModel)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"failed to save abort cause for terminated execution: %+v with err: %v\", request.Id, err)\n\t\treturn nil, err\n\t}\n\n\tworkflowExecutor := plugins.Get[workflowengineInterfaces.WorkflowExecutor](m.pluginRegistry, plugins.PluginIDWorkflowExecutor)\n\terr = workflowExecutor.Abort(ctx, workflowengineInterfaces.AbortData{\n\t\tNamespace: common.GetNamespaceName(\n\t\t\tm.config.NamespaceMappingConfiguration().GetNamespaceTemplate(), request.Id.Project, request.Id.Domain),\n\n\t\tExecutionID: request.Id,\n\t\tCluster:     executionModel.Cluster,\n\t})\n\tif err != nil {\n\t\tm.systemMetrics.TerminateExecutionFailures.Inc()\n\t\treturn nil, err\n\t}\n\treturn &admin.ExecutionTerminateResponse{}, nil\n}\n\nfunc newExecutionSystemMetrics(scope promutils.Scope) executionSystemMetrics {\n\treturn executionSystemMetrics{\n\t\tScope: scope,\n\t\tActiveExecutions: scope.MustNewGauge(\"active_executions\",\n\t\t\t\"overall count of active workflow executions\"),\n\t\tExecutionsCreated: scope.MustNewCounter(\"executions_created\",\n\t\t\t\"overall count of successfully completed CreateExecutionRequests\"),\n\t\tExecutionsTerminated: labeled.NewCounter(\"executions_terminated\",\n\t\t\t\"overall count of terminated workflow executions\", scope),\n\t\tExecutionEventsCreated: scope.MustNewCounter(\"execution_events_created\",\n\t\t\t\"overall count of successfully completed WorkflowExecutionEventRequest\"),\n\t\tPropellerFailures: scope.MustNewCounter(\"propeller_failures\",\n\t\t\t\"propeller failures in creating workflow executions\"),\n\t\tTransformerError: scope.MustNewCounter(\"transformer_error\",\n\t\t\t\"overall count of errors when transforming models and messages\"),\n\t\tUnexpectedDataError: scope.MustNewCounter(\"unexpected_data_error\",\n\t\t\t\"overall count of unexpected data for previously validated objects\"),\n\t\tPublishNotificationError: scope.MustNewCounter(\"publish_error\",\n\t\t\t\"overall count of publish notification errors when invoking publish()\"),\n\t\tSpecSizeBytes:    scope.MustNewSummary(\"spec_size_bytes\", \"size in bytes of serialized execution spec\"),\n\t\tClosureSizeBytes: scope.MustNewSummary(\"closure_size_bytes\", \"size in bytes of serialized execution closure\"),\n\t\tAcceptanceDelay: scope.MustNewSummary(\"acceptance_delay\",\n\t\t\t\"delay in seconds from when an execution was requested to be created and when it actually was\"),\n\t\tPublishEventError: scope.MustNewCounter(\"publish_event_error\",\n\t\t\t\"overall count of publish event errors when invoking publish()\"),\n\t\tTerminateExecutionFailures: scope.MustNewCounter(\"execution_termination_failure\",\n\t\t\t\"count of failed workflow executions terminations\"),\n\t}\n}\n\nfunc NewExecutionManager(db repositoryInterfaces.Repository, pluginRegistry *plugins.Registry, config runtimeInterfaces.Configuration,\n\tstorageClient *storage.DataStore, systemScope promutils.Scope, userScope promutils.Scope,\n\tpublisher notificationInterfaces.Publisher, urlData dataInterfaces.RemoteURLInterface,\n\tworkflowManager interfaces.WorkflowInterface, namedEntityManager interfaces.NamedEntityInterface,\n\teventPublisher notificationInterfaces.Publisher, cloudEventPublisher cloudeventInterfaces.Publisher,\n\teventWriter eventWriter.WorkflowExecutionEventWriter) interfaces.ExecutionInterface {\n\tqueueAllocator := executions.NewQueueAllocator(config, db)\n\tsystemMetrics := newExecutionSystemMetrics(systemScope)\n\n\tuserMetrics := executionUserMetrics{\n\t\tScope:                      userScope,\n\t\tScheduledExecutionDelays:   make(map[string]map[string]*promutils.StopWatch),\n\t\tWorkflowExecutionDurations: make(map[string]map[string]*promutils.StopWatch),\n\t\tWorkflowExecutionInputBytes: userScope.MustNewSummary(\"input_size_bytes\",\n\t\t\t\"size in bytes of serialized execution inputs\"),\n\t\tWorkflowExecutionOutputBytes: userScope.MustNewSummary(\"output_size_bytes\",\n\t\t\t\"size in bytes of serialized execution outputs\"),\n\t}\n\n\tresourceManager := resources.NewResourceManager(db, config.ApplicationConfiguration())\n\treturn &ExecutionManager{\n\t\tdb:                        db,\n\t\tconfig:                    config,\n\t\tstorageClient:             storageClient,\n\t\tqueueAllocator:            queueAllocator,\n\t\t_clock:                    clock.New(),\n\t\tsystemMetrics:             systemMetrics,\n\t\tuserMetrics:               userMetrics,\n\t\tnotificationClient:        publisher,\n\t\turlData:                   urlData,\n\t\tworkflowManager:           workflowManager,\n\t\tnamedEntityManager:        namedEntityManager,\n\t\tresourceManager:           resourceManager,\n\t\tqualityOfServiceAllocator: executions.NewQualityOfServiceAllocator(config, resourceManager),\n\t\teventPublisher:            eventPublisher,\n\t\tcloudEventPublisher:       cloudEventPublisher,\n\t\tdbEventWriter:             eventWriter,\n\t\tpluginRegistry:            pluginRegistry,\n\t}\n}\n\n// Adds project labels with higher precedence to workflow labels. Project labels are ignored if a corresponding label is set on the workflow.\nfunc (m *ExecutionManager) addProjectLabels(ctx context.Context, projectName string, initialLabels map[string]string) (map[string]string, error) {\n\tproject, err := m.db.ProjectRepo().Get(ctx, projectName)\n\tif err != nil {\n\t\tlogger.Errorf(ctx, \"Failed to get project for [%+v] with error: %v\", project, err)\n\t\treturn nil, err\n\t}\n\t// passing nil domain as not needed to retrieve labels\n\tprojectLabels := transformers.FromProjectModel(project, nil).Labels.GetValues()\n\n\tif initialLabels == nil {\n\t\tinitialLabels = make(map[string]string)\n\t}\n\n\tfor k, v := range projectLabels {\n\t\tif _, ok := initialLabels[k]; !ok {\n\t\t\tinitialLabels[k] = v\n\t\t}\n\t}\n\treturn initialLabels, nil\n}\n\nfunc addStateFilter(filters []common.InlineFilter) ([]common.InlineFilter, error) {\n\tvar stateFilterExists bool\n\tfor _, inlineFilter := range filters {\n\t\tif inlineFilter.GetField() == shared.State {\n\t\t\tstateFilterExists = true\n\t\t}\n\t}\n\n\tif !stateFilterExists {\n\t\tstateFilter, err := common.NewSingleValueFilter(common.Execution, common.Equal, shared.State,\n\t\t\tadmin.ExecutionState_EXECUTION_ACTIVE)\n\t\tif err != nil {\n\t\t\treturn filters, err\n\t\t}\n\t\tfilters = append(filters, stateFilter)\n\t}\n\treturn filters, nil\n}\n", "package impl\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"fmt\"\n\t\"strings\"\n\t\"testing\"\n\t\"time\"\n\n\t\"github.com/benbjohnson/clock\"\n\t\"github.com/flyteorg/flyteidl/clients/go/coreutils\"\n\t\"github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/admin\"\n\t\"github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/core\"\n\t\"github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/event\"\n\tmockScope \"github.com/flyteorg/flytestdlib/promutils\"\n\t\"github.com/flyteorg/flytestdlib/storage\"\n\t\"github.com/gogo/protobuf/jsonpb\"\n\t\"github.com/golang/protobuf/proto\"\n\t\"github.com/golang/protobuf/ptypes\"\n\t\"github.com/golang/protobuf/ptypes/wrappers\"\n\t\"github.com/stretchr/testify/assert\"\n\t\"github.com/stretchr/testify/mock\"\n\t\"google.golang.org/grpc/codes\"\n\t\"google.golang.org/grpc/status\"\n\t\"google.golang.org/protobuf/types/known/timestamppb\"\n\t\"k8s.io/apimachinery/pkg/api/resource\"\n\t\"k8s.io/apimachinery/pkg/util/sets\"\n\n\t\"github.com/flyteorg/flyteadmin/auth\"\n\teventWriterMocks \"github.com/flyteorg/flyteadmin/pkg/async/events/mocks\"\n\tnotificationMocks \"github.com/flyteorg/flyteadmin/pkg/async/notifications/mocks\"\n\t\"github.com/flyteorg/flyteadmin/pkg/common\"\n\tcommonMocks \"github.com/flyteorg/flyteadmin/pkg/common/mocks\"\n\tcommonTestUtils \"github.com/flyteorg/flyteadmin/pkg/common/testutils\"\n\tdataMocks \"github.com/flyteorg/flyteadmin/pkg/data/mocks\"\n\tflyteAdminErrors \"github.com/flyteorg/flyteadmin/pkg/errors\"\n\t\"github.com/flyteorg/flyteadmin/pkg/manager/impl/executions\"\n\t\"github.com/flyteorg/flyteadmin/pkg/manager/impl/shared\"\n\t\"github.com/flyteorg/flyteadmin/pkg/manager/impl/testutils\"\n\tmanagerInterfaces \"github.com/flyteorg/flyteadmin/pkg/manager/interfaces\"\n\tmanagerMocks \"github.com/flyteorg/flyteadmin/pkg/manager/mocks\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/interfaces\"\n\trepositoryMocks \"github.com/flyteorg/flyteadmin/pkg/repositories/mocks\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/models\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/transformers\"\n\t\"github.com/flyteorg/flyteadmin/pkg/runtime\"\n\truntimeInterfaces \"github.com/flyteorg/flyteadmin/pkg/runtime/interfaces\"\n\truntimeIFaceMocks \"github.com/flyteorg/flyteadmin/pkg/runtime/interfaces/mocks\"\n\truntimeMocks \"github.com/flyteorg/flyteadmin/pkg/runtime/mocks\"\n\tworkflowengineInterfaces \"github.com/flyteorg/flyteadmin/pkg/workflowengine/interfaces\"\n\tworkflowengineMocks \"github.com/flyteorg/flyteadmin/pkg/workflowengine/mocks\"\n\t\"github.com/flyteorg/flyteadmin/plugins\"\n)\n\nvar spec = testutils.GetExecutionRequest().Spec\nvar specBytes, _ = proto.Marshal(spec)\nvar phase = core.WorkflowExecution_RUNNING.String()\nvar closure = admin.ExecutionClosure{\n\tPhase: core.WorkflowExecution_RUNNING,\n\tStateChangeDetails: &admin.ExecutionStateChangeDetails{\n\t\tState:      admin.ExecutionState_EXECUTION_ACTIVE,\n\t\tOccurredAt: testutils.MockCreatedAtProto,\n\t},\n}\nvar closureBytes, _ = proto.Marshal(&closure)\n\nvar executionIdentifier = core.WorkflowExecutionIdentifier{\n\tProject: \"project\",\n\tDomain:  \"domain\",\n\tName:    \"name\",\n}\nvar mockPublisher notificationMocks.MockPublisher\nvar mockExecutionRemoteURL = dataMocks.NewMockRemoteURL()\nvar requestedAt = time.Now()\nvar testCluster = \"C1\"\nvar outputURI = \"output uri\"\n\nvar resourceDefaults = runtimeInterfaces.TaskResourceSet{\n\tCPU:    resource.MustParse(\"200m\"),\n\tMemory: resource.MustParse(\"200Gi\"),\n}\nvar resourceLimits = runtimeInterfaces.TaskResourceSet{\n\tCPU:    resource.MustParse(\"300m\"),\n\tMemory: resource.MustParse(\"500Gi\"),\n}\n\nfunc getLegacySpec() *admin.ExecutionSpec {\n\texecutionRequest := testutils.GetExecutionRequest()\n\tlegacySpec := executionRequest.Spec\n\tlegacySpec.Inputs = executionRequest.Inputs\n\treturn legacySpec\n}\n\nfunc getLegacySpecBytes() []byte {\n\tb, _ := proto.Marshal(getLegacySpec())\n\treturn b\n}\n\nfunc getExpectedLegacySpec() *admin.ExecutionSpec {\n\texpectedLegacySpec := getLegacySpec()\n\texpectedLegacySpec.Metadata = &admin.ExecutionMetadata{\n\t\tSystemMetadata: &admin.SystemMetadata{\n\t\t\tNamespace: \"project-domain\",\n\t\t},\n\t}\n\treturn expectedLegacySpec\n}\n\nfunc getExpectedLegacySpecBytes() []byte {\n\texpectedLegacySpec := getExpectedLegacySpec()\n\tb, _ := proto.Marshal(expectedLegacySpec)\n\treturn b\n}\n\nfunc getExpectedSpec() *admin.ExecutionSpec {\n\texpectedSpec := testutils.GetExecutionRequest().Spec\n\texpectedSpec.Metadata = &admin.ExecutionMetadata{\n\t\tSystemMetadata: &admin.SystemMetadata{\n\t\t\tNamespace: \"project-domain\",\n\t\t},\n\t}\n\treturn expectedSpec\n}\n\nfunc getExpectedSpecBytes() []byte {\n\tspecBytes, _ := proto.Marshal(getExpectedSpec())\n\treturn specBytes\n}\n\nfunc getLegacyClosure() *admin.ExecutionClosure {\n\treturn &admin.ExecutionClosure{\n\t\tPhase:          core.WorkflowExecution_RUNNING,\n\t\tComputedInputs: getLegacySpec().Inputs,\n\t\tStateChangeDetails: &admin.ExecutionStateChangeDetails{\n\t\t\tState:      admin.ExecutionState_EXECUTION_ACTIVE,\n\t\t\tOccurredAt: testutils.MockCreatedAtProto,\n\t\t},\n\t}\n}\n\nfunc getLegacyClosureBytes() []byte {\n\tb, _ := proto.Marshal(getLegacyClosure())\n\treturn b\n}\n\nfunc getLegacyExecutionRequest() *admin.ExecutionCreateRequest {\n\tr := testutils.GetExecutionRequest()\n\tr.Spec.Inputs = r.Inputs\n\tr.Inputs = nil\n\treturn &r\n}\n\nfunc getMockNamespaceMappingConfig() runtimeInterfaces.NamespaceMappingConfiguration {\n\tmockNs := runtimeMocks.NamespaceMappingConfiguration{}\n\tmockNs.OnGetNamespaceTemplate().Return(\"{{ project }}-{{ domain }}\")\n\treturn &mockNs\n}\n\nfunc getMockExecutionsConfigProvider() runtimeInterfaces.Configuration {\n\tmockExecutionsConfigProvider := runtimeMocks.NewMockConfigurationProvider(\n\t\ttestutils.GetApplicationConfigWithDefaultDomains(),\n\t\truntimeMocks.NewMockQueueConfigurationProvider(\n\t\t\t[]runtimeInterfaces.ExecutionQueue{}, []runtimeInterfaces.WorkflowConfig{}),\n\t\tnil,\n\t\truntimeMocks.NewMockTaskResourceConfiguration(resourceDefaults, resourceLimits), nil, getMockNamespaceMappingConfig())\n\tmockExecutionsConfigProvider.(*runtimeMocks.MockConfigurationProvider).AddRegistrationValidationConfiguration(\n\t\truntimeMocks.NewMockRegistrationValidationProvider())\n\treturn mockExecutionsConfigProvider\n}\n\nfunc setDefaultLpCallbackForExecTest(repository interfaces.Repository) {\n\tlpSpec := testutils.GetSampleLpSpecForTest()\n\tlpSpec.Labels = &admin.Labels{\n\t\tValues: map[string]string{\n\t\t\t\"label1\": \"1\",\n\t\t\t\"label2\": \"2\",\n\t\t},\n\t}\n\tlpSpec.Annotations = &admin.Annotations{\n\t\tValues: map[string]string{\n\t\t\t\"annotation3\": \"3\",\n\t\t\t\"annotation4\": \"4\",\n\t\t},\n\t}\n\n\tlpSpecBytes, _ := proto.Marshal(&lpSpec)\n\tlpClosure := admin.LaunchPlanClosure{\n\t\tExpectedInputs: lpSpec.DefaultInputs,\n\t}\n\tlpClosureBytes, _ := proto.Marshal(&lpClosure)\n\n\tlpGetFunc := func(input interfaces.Identifier) (models.LaunchPlan, error) {\n\t\tlpModel := models.LaunchPlan{\n\t\t\tLaunchPlanKey: models.LaunchPlanKey{\n\t\t\t\tProject: input.Project,\n\t\t\t\tDomain:  input.Domain,\n\t\t\t\tName:    input.Name,\n\t\t\t\tVersion: input.Version,\n\t\t\t},\n\t\t\tBaseModel: models.BaseModel{\n\t\t\t\tID: uint(100),\n\t\t\t},\n\t\t\tSpec:    lpSpecBytes,\n\t\t\tClosure: lpClosureBytes,\n\t\t}\n\t\treturn lpModel, nil\n\t}\n\trepository.LaunchPlanRepo().(*repositoryMocks.MockLaunchPlanRepo).SetGetCallback(lpGetFunc)\n}\n\nfunc setDefaultTaskCallbackForExecTest(repository interfaces.Repository) {\n\ttaskGetFunc := func(input interfaces.Identifier) (models.Task, error) {\n\t\treturn models.Task{\n\t\t\tTaskKey: models.TaskKey{\n\t\t\t\tProject: input.Project,\n\t\t\t\tDomain:  input.Domain,\n\t\t\t\tName:    input.Name,\n\t\t\t\tVersion: input.Version,\n\t\t\t},\n\t\t\tBaseModel: models.BaseModel{\n\t\t\t\tID:        uint(123),\n\t\t\t\tCreatedAt: testutils.MockCreatedAtValue,\n\t\t\t},\n\t\t\tClosure: testutils.GetTaskClosureBytes(),\n\t\t\tDigest:  []byte(input.Name),\n\t\t\tType:    \"python\",\n\t\t}, nil\n\t}\n\trepository.TaskRepo().(*repositoryMocks.MockTaskRepo).SetGetCallback(taskGetFunc)\n}\n\nfunc getMockStorageForExecTest(ctx context.Context) *storage.DataStore {\n\tmockStorage := commonMocks.GetMockStorageClient()\n\tmockStorage.ComposedProtobufStore.(*commonMocks.TestDataStore).ReadProtobufCb = func(\n\t\tctx context.Context, reference storage.DataReference, msg proto.Message) error {\n\t\tif val, ok := mockStorage.ComposedProtobufStore.(*commonMocks.TestDataStore).Store[reference]; ok {\n\t\t\t_ = proto.Unmarshal(val, msg)\n\t\t\treturn nil\n\t\t}\n\t\treturn fmt.Errorf(\"could not find value in storage [%v]\", reference.String())\n\t}\n\tmockStorage.ComposedProtobufStore.(*commonMocks.TestDataStore).WriteProtobufCb = func(\n\t\tctx context.Context, reference storage.DataReference, opts storage.Options, msg proto.Message) error {\n\t\tbytes, err := proto.Marshal(msg)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tmockStorage.ComposedProtobufStore.(*commonMocks.TestDataStore).Store[reference] = bytes\n\t\treturn nil\n\t}\n\tworkflowClosure := testutils.GetWorkflowClosure()\n\tif err := mockStorage.WriteProtobuf(ctx, remoteClosureIdentifier, defaultStorageOptions, workflowClosure); err != nil {\n\t\treturn nil\n\t}\n\treturn mockStorage\n}\n\nfunc getMockRepositoryForExecTest() interfaces.Repository {\n\trepository := repositoryMocks.NewMockRepository()\n\trepository.WorkflowRepo().(*repositoryMocks.MockWorkflowRepo).SetGetCallback(\n\t\tfunc(input interfaces.Identifier) (models.Workflow, error) {\n\t\t\treturn models.Workflow{\n\t\t\t\tBaseModel: models.BaseModel{\n\t\t\t\t\tCreatedAt: testutils.MockCreatedAtValue,\n\t\t\t\t},\n\t\t\t\tWorkflowKey: models.WorkflowKey{\n\t\t\t\t\tProject: input.Project,\n\t\t\t\t\tDomain:  input.Domain,\n\t\t\t\t\tName:    input.Name,\n\t\t\t\t\tVersion: input.Version,\n\t\t\t\t},\n\t\t\t\tTypedInterface:          testutils.GetWorkflowRequestInterfaceBytes(),\n\t\t\t\tRemoteClosureIdentifier: remoteClosureIdentifier,\n\t\t\t}, nil\n\t\t})\n\treturn repository\n}\n\nvar defaultTestExecutor = workflowengineMocks.WorkflowExecutor{}\n\nfunc init() {\n\tdefaultTestExecutor.OnID().Return(\"testDefault\")\n}\n\nfunc TestCreateExecution(t *testing.T) {\n\trepository := getMockRepositoryForExecTest()\n\tlabels := admin.Labels{\n\t\tValues: map[string]string{\n\t\t\t\"label3\": \"3\",\n\t\t\t\"label2\": \"1\", // common label, will be dropped\n\t\t}}\n\trepository.ProjectRepo().(*repositoryMocks.MockProjectRepo).GetFunction = func(\n\t\tctx context.Context, projectID string) (models.Project, error) {\n\t\treturn transformers.CreateProjectModel(&admin.Project{\n\t\t\tLabels: &labels}), nil\n\t}\n\n\tprincipal := \"principal\"\n\trawOutput := \"raw_output\"\n\tclusterAssignment := admin.ClusterAssignment{ClusterPoolName: \"gpu\"}\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetCreateCallback(\n\t\tfunc(ctx context.Context, input models.Execution) error {\n\t\t\tvar spec admin.ExecutionSpec\n\t\t\terr := proto.Unmarshal(input.Spec, &spec)\n\t\t\tassert.NoError(t, err)\n\t\t\tassert.Equal(t, principal, spec.Metadata.Principal)\n\t\t\tassert.Equal(t, rawOutput, spec.RawOutputDataConfig.OutputLocationPrefix)\n\t\t\tassert.True(t, proto.Equal(spec.ClusterAssignment, &clusterAssignment))\n\t\t\tassert.Equal(t, \"launch_plan\", input.LaunchEntity)\n\t\t\tassert.Equal(t, spec.GetMetadata().GetSystemMetadata().Namespace, \"project-domain\")\n\t\t\treturn nil\n\t\t})\n\tsetDefaultLpCallbackForExecTest(repository)\n\tmockExecutor := workflowengineMocks.WorkflowExecutor{}\n\tresources := &core.Resources{\n\t\tRequests: []*core.Resources_ResourceEntry{\n\t\t\t{\n\t\t\t\tName:  core.Resources_CPU,\n\t\t\t\tValue: \"200m\",\n\t\t\t},\n\t\t\t{\n\t\t\t\tName:  core.Resources_MEMORY,\n\t\t\t\tValue: \"200Gi\",\n\t\t\t},\n\t\t},\n\t\tLimits: []*core.Resources_ResourceEntry{\n\t\t\t{\n\t\t\t\tName:  core.Resources_CPU,\n\t\t\t\tValue: \"300m\",\n\t\t\t},\n\t\t\t{\n\t\t\t\tName:  core.Resources_MEMORY,\n\t\t\t\tValue: \"500Gi\",\n\t\t\t},\n\t\t},\n\t}\n\tmockExecutor.OnExecuteMatch(mock.Anything, mock.MatchedBy(func(data workflowengineInterfaces.ExecutionData) bool {\n\t\ttasks := data.WorkflowClosure.GetTasks()\n\t\tfor _, task := range tasks {\n\t\t\tassert.EqualValues(t, resources.Requests,\n\t\t\t\ttask.Template.GetContainer().Resources.Requests)\n\t\t\tassert.EqualValues(t, resources.Requests,\n\t\t\t\ttask.Template.GetContainer().Resources.Limits)\n\t\t}\n\n\t\treturn true\n\t})).Return(workflowengineInterfaces.ExecutionResponse{\n\t\tCluster: testCluster,\n\t}, nil)\n\tmockExecutor.OnID().Return(\"customMockExecutor\")\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &mockExecutor)\n\n\tqosProvider := &runtimeIFaceMocks.QualityOfServiceConfiguration{}\n\tqosProvider.OnGetTierExecutionValues().Return(map[core.QualityOfService_Tier]core.QualityOfServiceSpec{\n\t\tcore.QualityOfService_HIGH: {\n\t\t\tQueueingBudget: ptypes.DurationProto(10 * time.Minute),\n\t\t},\n\t\tcore.QualityOfService_MEDIUM: {\n\t\t\tQueueingBudget: ptypes.DurationProto(20 * time.Minute),\n\t\t},\n\t\tcore.QualityOfService_LOW: {\n\t\t\tQueueingBudget: ptypes.DurationProto(30 * time.Minute),\n\t\t},\n\t})\n\n\tqosProvider.OnGetDefaultTiers().Return(map[string]core.QualityOfService_Tier{\n\t\t\"domain\": core.QualityOfService_HIGH,\n\t})\n\n\tmockConfig := getMockExecutionsConfigProvider()\n\tmockConfig.(*runtimeMocks.MockConfigurationProvider).AddQualityOfServiceConfiguration(qosProvider)\n\n\texecManager := NewExecutionManager(repository, r, mockConfig, getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, &mockPublisher, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\trequest := testutils.GetExecutionRequest()\n\trequest.Spec.Metadata = &admin.ExecutionMetadata{\n\t\tPrincipal: \"unused - populated from authenticated context\",\n\t}\n\trequest.Spec.RawOutputDataConfig = &admin.RawOutputDataConfig{OutputLocationPrefix: rawOutput}\n\trequest.Spec.ClusterAssignment = &clusterAssignment\n\n\tidentity, err := auth.NewIdentityContext(\"\", principal, \"\", time.Now(), sets.NewString(), nil, nil)\n\tassert.NoError(t, err)\n\tctx := identity.WithContext(context.Background())\n\tresponse, err := execManager.CreateExecution(ctx, request, requestedAt)\n\tassert.Nil(t, err)\n\n\texpectedResponse := &admin.ExecutionCreateResponse{\n\t\tId: &executionIdentifier,\n\t}\n\tassert.Nil(t, err)\n\tassert.Equal(t, expectedResponse, response)\n\n\t// TODO: Check for offloaded inputs\n}\n\nfunc TestCreateExecutionFromWorkflowNode(t *testing.T) {\n\trepository := getMockRepositoryForExecTest()\n\tsetDefaultLpCallbackForExecTest(repository)\n\n\tparentNodeExecutionID := core.NodeExecutionIdentifier{\n\t\tExecutionId: &core.WorkflowExecutionIdentifier{\n\t\t\tProject: \"project\",\n\t\t\tDomain:  \"domain\",\n\t\t\tName:    \"parent-name\",\n\t\t},\n\t\tNodeId: \"node-name\",\n\t}\n\n\tgetNodeExecutionCalled := false\n\trepository.NodeExecutionRepo().(*repositoryMocks.MockNodeExecutionRepo).SetGetCallback(\n\t\tfunc(ctx context.Context, input interfaces.NodeExecutionResource) (models.NodeExecution, error) {\n\t\t\tassert.EqualValues(t, input.NodeExecutionIdentifier, parentNodeExecutionID)\n\t\t\tgetNodeExecutionCalled = true\n\t\t\treturn models.NodeExecution{\n\t\t\t\tBaseModel: models.BaseModel{\n\t\t\t\t\tID: 1,\n\t\t\t\t},\n\t\t\t}, nil\n\t\t},\n\t)\n\n\tprincipal := \"feeny\"\n\tgetExecutionCalled := false\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetGetCallback(\n\t\tfunc(ctx context.Context, input interfaces.Identifier) (models.Execution, error) {\n\t\t\tassert.EqualValues(t, input.Project, parentNodeExecutionID.ExecutionId.Project)\n\t\t\tassert.EqualValues(t, input.Domain, parentNodeExecutionID.ExecutionId.Domain)\n\t\t\tassert.EqualValues(t, input.Name, parentNodeExecutionID.ExecutionId.Name)\n\t\t\tspec := &admin.ExecutionSpec{\n\t\t\t\tMetadata: &admin.ExecutionMetadata{\n\t\t\t\t\tNesting: 1,\n\t\t\t\t},\n\t\t\t}\n\t\t\tspecBytes, _ := proto.Marshal(spec)\n\t\t\tgetExecutionCalled = true\n\t\t\treturn models.Execution{\n\t\t\t\tBaseModel: models.BaseModel{\n\t\t\t\t\tID: 2,\n\t\t\t\t},\n\t\t\t\tSpec: specBytes,\n\t\t\t\tUser: principal,\n\t\t\t}, nil\n\t\t},\n\t)\n\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetCreateCallback(\n\t\tfunc(ctx context.Context, input models.Execution) error {\n\t\t\tassert.Equal(t, input.ParentNodeExecutionID, uint(1))\n\t\t\tvar spec admin.ExecutionSpec\n\t\t\terr := proto.Unmarshal(input.Spec, &spec)\n\t\t\tassert.NoError(t, err)\n\t\t\tassert.Equal(t, admin.ExecutionMetadata_CHILD_WORKFLOW, spec.Metadata.Mode)\n\t\t\tassert.True(t, proto.Equal(&parentNodeExecutionID, spec.Metadata.ParentNodeExecution))\n\t\t\tassert.EqualValues(t, input.ParentNodeExecutionID, 1)\n\t\t\tassert.EqualValues(t, input.SourceExecutionID, 2)\n\t\t\tassert.Equal(t, 2, int(spec.Metadata.Nesting))\n\t\t\tassert.Equal(t, principal, spec.Metadata.Principal)\n\t\t\tassert.Equal(t, principal, input.User)\n\t\t\treturn nil\n\t\t},\n\t)\n\n\tmockExecutor := workflowengineMocks.WorkflowExecutor{}\n\tmockExecutor.OnExecuteMatch(mock.Anything, mock.Anything, mock.Anything).Return(workflowengineInterfaces.ExecutionResponse{\n\t\tCluster: testCluster,\n\t}, nil)\n\tmockExecutor.OnID().Return(\"customMockExecutor\")\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &mockExecutor)\n\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\trequest := testutils.GetExecutionRequest()\n\trequest.Spec.Metadata = &admin.ExecutionMetadata{\n\t\tMode:                admin.ExecutionMetadata_CHILD_WORKFLOW,\n\t\tParentNodeExecution: &parentNodeExecutionID,\n\t}\n\tresponse, err := execManager.CreateExecution(context.Background(), request, requestedAt)\n\tassert.Nil(t, err)\n\tassert.True(t, getNodeExecutionCalled)\n\tassert.True(t, getExecutionCalled)\n\texpectedResponse := &admin.ExecutionCreateResponse{\n\t\tId: &executionIdentifier,\n\t}\n\tassert.Nil(t, err)\n\tassert.Equal(t, expectedResponse, response)\n}\n\nfunc TestCreateExecution_NoAssignedName(t *testing.T) {\n\trepository := getMockRepositoryForExecTest()\n\tsetDefaultLpCallbackForExecTest(repository)\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetCreateCallback(\n\t\tfunc(ctx context.Context, input models.Execution) error {\n\t\t\tassert.Equal(t, executionIdentifier.Project, input.Project)\n\t\t\tassert.Equal(t, executionIdentifier.Domain, input.Domain)\n\t\t\tassert.NotEmpty(t, input.Name)\n\t\t\treturn nil\n\t\t})\n\tmockExecutor := workflowengineMocks.WorkflowExecutor{}\n\tmockExecutor.OnExecuteMatch(mock.Anything, mock.MatchedBy(func(data workflowengineInterfaces.ExecutionData) bool {\n\t\treturn len(data.ExecutionID.Name) > 0\n\t})).Return(workflowengineInterfaces.ExecutionResponse{\n\t\tCluster: testCluster,\n\t}, nil)\n\tmockExecutor.OnID().Return(\"customMockExecutor\")\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &mockExecutor)\n\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\trequest := testutils.GetExecutionRequest()\n\trequest.Name = \"\"\n\tresponse, err := execManager.CreateExecution(context.Background(), request, requestedAt)\n\tassert.Nil(t, err)\n\n\texpectedResponse := &admin.ExecutionCreateResponse{\n\t\tId: &executionIdentifier,\n\t}\n\tassert.Nil(t, err)\n\tassert.Equal(t, expectedResponse.Id.Project, response.Id.Project)\n\tassert.Equal(t, expectedResponse.Id.Domain, response.Id.Domain)\n\tassert.NotEmpty(t, response.Id.Name)\n}\n\nfunc TestCreateExecution_TaggedQueue(t *testing.T) {\n\trepository := getMockRepositoryForExecTest()\n\tsetDefaultLpCallbackForExecTest(repository)\n\tconfigProvider := runtimeMocks.NewMockConfigurationProvider(\n\t\ttestutils.GetApplicationConfigWithDefaultDomains(),\n\t\truntimeMocks.NewMockQueueConfigurationProvider([]runtimeInterfaces.ExecutionQueue{\n\t\t\t{\n\t\t\t\tDynamic:    \"dynamic Q\",\n\t\t\t\tAttributes: []string{\"tag\"},\n\t\t\t},\n\t\t}, []runtimeInterfaces.WorkflowConfig{\n\t\t\t{\n\t\t\t\tDomain: \"domain\",\n\t\t\t\tTags:   []string{\"tag\"},\n\t\t\t},\n\t\t}),\n\t\tnil,\n\t\truntimeMocks.NewMockTaskResourceConfiguration(resourceDefaults, resourceLimits), nil, getMockNamespaceMappingConfig())\n\tconfigProvider.(*runtimeMocks.MockConfigurationProvider).AddRegistrationValidationConfiguration(\n\t\truntimeMocks.NewMockRegistrationValidationProvider())\n\n\tmockExecutor := workflowengineMocks.WorkflowExecutor{}\n\tmockExecutor.OnExecuteMatch(mock.Anything, mock.MatchedBy(func(data workflowengineInterfaces.ExecutionData) bool {\n\t\tassert.NotEmpty(t, data.WorkflowClosure.Tasks)\n\t\tfor _, task := range data.WorkflowClosure.Tasks {\n\t\t\tassert.Len(t, task.Template.GetContainer().Config, 1)\n\t\t\tassert.Contains(t, childContainerQueueKey, task.Template.GetContainer().Config[0].Key)\n\t\t\tassert.Contains(t, \"dynamic Q\", task.Template.GetContainer().Config[0].Value)\n\t\t}\n\t\treturn true\n\t})).Return(workflowengineInterfaces.ExecutionResponse{\n\t\tCluster: testCluster,\n\t}, nil)\n\tmockExecutor.OnID().Return(\"customMockExecutor\")\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &mockExecutor)\n\texecManager := NewExecutionManager(repository, r, configProvider, getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\n\trequest := testutils.GetExecutionRequest()\n\tresponse, err := execManager.CreateExecution(context.Background(), request, requestedAt)\n\tassert.Nil(t, err)\n\n\texpectedResponse := &admin.ExecutionCreateResponse{\n\t\tId: &executionIdentifier,\n\t}\n\tassert.Nil(t, err)\n\tassert.Equal(t, expectedResponse, response)\n}\n\nfunc TestCreateExecutionValidationError(t *testing.T) {\n\trepository := getMockRepositoryForExecTest()\n\tsetDefaultLpCallbackForExecTest(repository)\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &defaultTestExecutor)\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\n\trequest := testutils.GetExecutionRequest()\n\trequest.Domain = \"\"\n\tresponse, err := execManager.CreateExecution(context.Background(), request, requestedAt)\n\tassert.EqualError(t, err, \"missing domain\")\n\tassert.Nil(t, response)\n}\n\nfunc TestCreateExecution_InvalidLpIdentifier(t *testing.T) {\n\trepository := getMockRepositoryForExecTest()\n\tsetDefaultLpCallbackForExecTest(repository)\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &defaultTestExecutor)\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\n\trequest := testutils.GetExecutionRequest()\n\trequest.Spec.LaunchPlan = nil\n\tresponse, err := execManager.CreateExecution(context.Background(), request, requestedAt)\n\tassert.EqualError(t, err, \"missing id\")\n\tassert.Nil(t, response)\n}\n\nfunc TestCreateExecutionInCompatibleInputs(t *testing.T) {\n\trepository := getMockRepositoryForExecTest()\n\tsetDefaultLpCallbackForExecTest(repository)\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &defaultTestExecutor)\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\n\trequest := testutils.GetExecutionRequest()\n\trequest.Inputs = &core.LiteralMap{\n\t\tLiterals: map[string]*core.Literal{\n\t\t\t\"foo-1\": coreutils.MustMakeLiteral(\"foo-value-1\"),\n\t\t},\n\t}\n\tresponse, err := execManager.CreateExecution(context.Background(), request, requestedAt)\n\tassert.EqualError(t, err, \"invalid input foo-1\")\n\tassert.Nil(t, response)\n}\n\nfunc TestCreateExecutionPropellerFailure(t *testing.T) {\n\trepository := getMockRepositoryForExecTest()\n\tsetDefaultLpCallbackForExecTest(repository)\n\texpectedErr := flyteAdminErrors.NewFlyteAdminErrorf(codes.Internal, \"ABC\")\n\tmockExecutor := workflowengineMocks.WorkflowExecutor{}\n\tmockExecutor.OnExecuteMatch(mock.Anything, mock.Anything, mock.Anything).Return(workflowengineInterfaces.ExecutionResponse{}, expectedErr)\n\tmockExecutor.OnID().Return(\"customMockExecutor\")\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &mockExecutor)\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\n\trequest := testutils.GetExecutionRequest()\n\n\tresponse, err := execManager.CreateExecution(context.Background(), request, requestedAt)\n\tassert.EqualError(t, err, expectedErr.Error())\n\tassert.Nil(t, response)\n}\n\nfunc TestCreateExecutionDatabaseFailure(t *testing.T) {\n\tmockExecutor := workflowengineMocks.WorkflowExecutor{}\n\tmockExecutor.OnExecuteMatch(mock.Anything, mock.Anything, mock.Anything).Return(workflowengineInterfaces.ExecutionResponse{}, nil)\n\tmockExecutor.OnID().Return(\"customMockExecutor\")\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &mockExecutor)\n\trepository := getMockRepositoryForExecTest()\n\tsetDefaultLpCallbackForExecTest(repository)\n\texpectedErr := flyteAdminErrors.NewFlyteAdminErrorf(codes.Internal, \"ABCD\")\n\texCreateFunc := func(ctx context.Context, input models.Execution) error {\n\t\treturn expectedErr\n\t}\n\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetCreateCallback(exCreateFunc)\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\trequest := testutils.GetExecutionRequest()\n\n\tresponse, err := execManager.CreateExecution(context.Background(), request, requestedAt)\n\tassert.EqualError(t, err, expectedErr.Error())\n\tassert.Nil(t, response)\n}\n\nfunc TestCreateExecutionVerifyDbModel(t *testing.T) {\n\trequest := testutils.GetExecutionRequest()\n\trepository := getMockRepositoryForExecTest()\n\tstorageClient := getMockStorageForExecTest(context.Background())\n\tsetDefaultLpCallbackForExecTest(repository)\n\tmockClock := clock.NewMock()\n\tcreatedAt := time.Now()\n\tmockClock.Set(createdAt)\n\texCreateFunc := func(ctx context.Context, input models.Execution) error {\n\t\tassert.Equal(t, \"name\", input.Name)\n\t\tassert.Equal(t, \"domain\", input.Domain)\n\t\tassert.Equal(t, \"project\", input.Project)\n\t\tassert.Equal(t, uint(100), input.LaunchPlanID)\n\t\tassert.Equal(t, core.WorkflowExecution_UNDEFINED.String(), input.Phase)\n\n\t\tvar specValue admin.ExecutionSpec\n\t\terr := proto.Unmarshal(input.Spec, &specValue)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tassert.Nil(t, specValue.Inputs)\n\n\t\tvar closureValue admin.ExecutionClosure\n\t\terr = proto.Unmarshal(input.Closure, &closureValue)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tassert.Nil(t, closureValue.ComputedInputs)\n\n\t\tvar userInputs, inputs core.LiteralMap\n\t\tif err := storageClient.ReadProtobuf(ctx, input.UserInputsURI, &userInputs); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif err := storageClient.ReadProtobuf(ctx, input.InputsURI, &inputs); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tfooValue := coreutils.MustMakeLiteral(\"foo-value-1\")\n\t\tassert.Equal(t, 1, len(userInputs.Literals))\n\t\tassert.EqualValues(t, userInputs.Literals[\"foo\"], fooValue)\n\t\tbarValue := coreutils.MustMakeLiteral(\"bar-value\")\n\t\tassert.Equal(t, len(inputs.Literals), 2)\n\t\tassert.EqualValues(t, inputs.Literals[\"foo\"], fooValue)\n\t\tassert.EqualValues(t, inputs.Literals[\"bar\"], barValue)\n\t\tassert.Equal(t, core.WorkflowExecution_UNDEFINED, closureValue.Phase)\n\t\tassert.Equal(t, createdAt, *input.ExecutionCreatedAt)\n\t\tassert.Equal(t, 1, len(closureValue.Notifications))\n\t\tassert.Equal(t, 1, len(closureValue.Notifications[0].Phases))\n\t\tassert.Equal(t, request.Spec.GetNotifications().Notifications[0].Phases[0], closureValue.Notifications[0].Phases[0])\n\t\tassert.IsType(t, &admin.Notification_Slack{}, closureValue.Notifications[0].GetType())\n\t\tassert.Equal(t, request.Spec.GetNotifications().Notifications[0].GetSlack().RecipientsEmail, closureValue.Notifications[0].GetSlack().RecipientsEmail)\n\n\t\treturn nil\n\t}\n\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetCreateCallback(exCreateFunc)\n\tmockExecutor := workflowengineMocks.WorkflowExecutor{}\n\tmockExecutor.OnExecuteMatch(mock.Anything, mock.Anything, mock.Anything).Return(workflowengineInterfaces.ExecutionResponse{}, nil)\n\tmockExecutor.OnID().Return(\"testMockExecutor\")\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &mockExecutor)\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), storageClient, mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\n\texecManager.(*ExecutionManager)._clock = mockClock\n\n\tresponse, err := execManager.CreateExecution(context.Background(), request, requestedAt)\n\tassert.Nil(t, err)\n\tassert.True(t, proto.Equal(&executionIdentifier, response.Id))\n}\n\nfunc TestCreateExecutionDefaultNotifications(t *testing.T) {\n\t// Remove notifications settings for the CreateExecutionRequest.\n\trequest := testutils.GetExecutionRequest()\n\trequest.Spec.NotificationOverrides = &admin.ExecutionSpec_Notifications{\n\t\tNotifications: &admin.NotificationList{\n\t\t\tNotifications: []*admin.Notification{},\n\t\t},\n\t}\n\n\trepository := getMockRepositoryForExecTest()\n\tsetDefaultLpCallbackForExecTest(repository)\n\n\t// Create a callback method to ensure the default notification settings from the LaunchPlan is\n\t// stored in the resulting models.Execution.\n\texCreateFunc := func(ctx context.Context, input models.Execution) error {\n\t\tvar closureValue admin.ExecutionClosure\n\t\terr := proto.Unmarshal(input.Closure, &closureValue)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tassert.Equal(t, 1, len(closureValue.Notifications))\n\t\tassert.Equal(t, 1, len(closureValue.Notifications[0].Phases))\n\t\tassert.Equal(t, core.WorkflowExecution_SUCCEEDED, closureValue.Notifications[0].Phases[0])\n\t\tassert.IsType(t, &admin.Notification_Email{}, closureValue.Notifications[0].GetType())\n\n\t\treturn nil\n\t}\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetCreateCallback(exCreateFunc)\n\tmockExecutor := workflowengineMocks.WorkflowExecutor{}\n\tmockExecutor.OnExecuteMatch(mock.Anything, mock.Anything, mock.Anything).Return(workflowengineInterfaces.ExecutionResponse{}, nil)\n\tmockExecutor.OnID().Return(\"testMockExecutor\")\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &mockExecutor)\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\n\tresponse, err := execManager.CreateExecution(context.Background(), request, requestedAt)\n\tassert.Nil(t, err)\n\tassert.True(t, proto.Equal(&core.WorkflowExecutionIdentifier{\n\t\tProject: \"project\",\n\t\tDomain:  \"domain\",\n\t\tName:    \"name\",\n\t}, response.Id))\n}\n\nfunc TestCreateExecutionDisableNotifications(t *testing.T) {\n\t// Disable notifications for the CreateExecutionRequest.\n\trequest := testutils.GetExecutionRequest()\n\trequest.Spec.NotificationOverrides = &admin.ExecutionSpec_DisableAll{\n\t\tDisableAll: true,\n\t}\n\n\trepository := getMockRepositoryForExecTest()\n\tsetDefaultLpCallbackForExecTest(repository)\n\n\t// Create a callback method to ensure the default notification settings from the LaunchPlan is\n\t// stored in the resulting models.Execution.\n\texCreateFunc := func(ctx context.Context, input models.Execution) error {\n\t\tvar closureValue admin.ExecutionClosure\n\t\terr := proto.Unmarshal(input.Closure, &closureValue)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tassert.Empty(t, closureValue.Notifications)\n\t\treturn nil\n\t}\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetCreateCallback(exCreateFunc)\n\tmockExecutor := workflowengineMocks.WorkflowExecutor{}\n\tmockExecutor.OnExecuteMatch(mock.Anything, mock.Anything, mock.Anything).Return(workflowengineInterfaces.ExecutionResponse{}, nil)\n\tmockExecutor.OnID().Return(\"testMockExecutor\")\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &mockExecutor)\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\n\tresponse, err := execManager.CreateExecution(context.Background(), request, requestedAt)\n\tassert.Nil(t, err)\n\tassert.True(t, proto.Equal(&core.WorkflowExecutionIdentifier{\n\t\tProject: \"project\",\n\t\tDomain:  \"domain\",\n\t\tName:    \"name\",\n\t}, response.Id))\n}\n\nfunc TestCreateExecutionNoNotifications(t *testing.T) {\n\t// Remove notifications settings for the CreateExecutionRequest.\n\trequest := testutils.GetExecutionRequest()\n\trequest.Spec.NotificationOverrides = &admin.ExecutionSpec_Notifications{\n\t\tNotifications: &admin.NotificationList{\n\t\t\tNotifications: []*admin.Notification{},\n\t\t},\n\t}\n\n\t// Remove notifications settings for the LaunchPlan associated with the\n\t// CreateExecutionRequest.\n\tlpSpec := testutils.GetSampleLpSpecForTest()\n\tlpSpec.EntityMetadata.Notifications = nil\n\tlpSpecBytes, _ := proto.Marshal(&lpSpec)\n\tlpClosure := admin.LaunchPlanClosure{\n\t\tExpectedInputs: lpSpec.DefaultInputs,\n\t}\n\tlpClosureBytes, _ := proto.Marshal(&lpClosure)\n\n\t// The LaunchPlan is retrieved within the CreateExecution call to ExecutionManager.\n\t// Create a callback method used by the mock to retrieve a LaunchPlan.\n\tlpGetFunc := func(input interfaces.Identifier) (models.LaunchPlan, error) {\n\t\tlpModel := models.LaunchPlan{\n\t\t\tLaunchPlanKey: models.LaunchPlanKey{\n\t\t\t\tProject: input.Project,\n\t\t\t\tDomain:  input.Domain,\n\t\t\t\tName:    input.Name,\n\t\t\t\tVersion: input.Version,\n\t\t\t},\n\t\t\tBaseModel: models.BaseModel{\n\t\t\t\tID: uint(100),\n\t\t\t},\n\t\t\tSpec:    lpSpecBytes,\n\t\t\tClosure: lpClosureBytes,\n\t\t}\n\t\treturn lpModel, nil\n\t}\n\n\trepository := getMockRepositoryForExecTest()\n\trepository.LaunchPlanRepo().(*repositoryMocks.MockLaunchPlanRepo).SetGetCallback(lpGetFunc)\n\n\t// Create a callback method to validate no notifications are set when storing the\n\t// resulting models.Execution by CreateExecution.\n\texCreateFunc := func(ctx context.Context, input models.Execution) error {\n\n\t\tvar closureValue admin.ExecutionClosure\n\t\terr := proto.Unmarshal(input.Closure, &closureValue)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tassert.Nil(t, closureValue.GetNotifications())\n\t\treturn nil\n\t}\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetCreateCallback(exCreateFunc)\n\tmockExecutor := workflowengineMocks.WorkflowExecutor{}\n\tmockExecutor.OnExecuteMatch(mock.Anything, mock.Anything, mock.Anything).Return(workflowengineInterfaces.ExecutionResponse{}, nil)\n\tmockExecutor.OnID().Return(\"testMockExecutor\")\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &mockExecutor)\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\n\tresponse, err := execManager.CreateExecution(context.Background(), request, requestedAt)\n\tassert.Nil(t, err)\n\tassert.True(t, proto.Equal(&core.WorkflowExecutionIdentifier{\n\t\tProject: \"project\",\n\t\tDomain:  \"domain\",\n\t\tName:    \"name\",\n\t}, response.Id))\n}\n\nfunc TestCreateExecutionDynamicLabelsAndAnnotations(t *testing.T) {\n\trepository := getMockRepositoryForExecTest()\n\tsetDefaultLpCallbackForExecTest(repository)\n\tmockExecutor := workflowengineMocks.WorkflowExecutor{}\n\tmockExecutor.OnExecuteMatch(mock.Anything, mock.MatchedBy(func(executionData workflowengineInterfaces.ExecutionData) bool {\n\t\tassert.EqualValues(t, map[string]string{\n\t\t\t\"dynamiclabel1\": \"dynamic1\",\n\t\t\t\"dynamiclabel2\": \"dynamic2\",\n\t\t}, executionData.ExecutionParameters.Labels)\n\t\tassert.EqualValues(t, map[string]string{\n\t\t\t\"dynamicannotation3\": \"dynamic3\",\n\t\t\t\"dynamicannotation4\": \"dynamic4\",\n\t\t}, executionData.ExecutionParameters.Annotations)\n\t\treturn true\n\t})).Return(workflowengineInterfaces.ExecutionResponse{}, nil)\n\tmockExecutor.OnID().Return(\"customMockExecutor\")\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &mockExecutor)\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\trequest := testutils.GetExecutionRequest()\n\trequest.Spec.Labels = &admin.Labels{\n\t\tValues: map[string]string{\n\t\t\t\"dynamiclabel1\": \"dynamic1\",\n\t\t\t\"dynamiclabel2\": \"dynamic2\",\n\t\t},\n\t}\n\trequest.Spec.Annotations = &admin.Annotations{\n\t\tValues: map[string]string{\n\t\t\t\"dynamicannotation3\": \"dynamic3\",\n\t\t\t\"dynamicannotation4\": \"dynamic4\",\n\t\t},\n\t}\n\tresponse, err := execManager.CreateExecution(context.Background(), request, requestedAt)\n\tassert.Nil(t, err)\n\n\texpectedResponse := &admin.ExecutionCreateResponse{\n\t\tId: &executionIdentifier,\n\t}\n\tassert.Nil(t, err)\n\tassert.Equal(t, expectedResponse, response)\n}\n\nfunc TestCreateExecutionInterruptible(t *testing.T) {\n\tenable := true\n\tdisable := false\n\ttests := []struct {\n\t\tname          string\n\t\ttask          bool\n\t\tinterruptible *bool\n\t\twant          bool\n\t}{\n\t\t{\n\t\t\tname:          \"LaunchPlanDefault\",\n\t\t\ttask:          false,\n\t\t\tinterruptible: nil,\n\t\t\twant:          false,\n\t\t},\n\t\t{\n\t\t\tname:          \"LaunchPlanDisable\",\n\t\t\ttask:          false,\n\t\t\tinterruptible: &disable,\n\t\t\twant:          false,\n\t\t},\n\t\t{\n\t\t\tname:          \"LaunchPlanEnable\",\n\t\t\ttask:          false,\n\t\t\tinterruptible: &enable,\n\t\t\twant:          true,\n\t\t},\n\t\t{\n\t\t\tname:          \"TaskDefault\",\n\t\t\ttask:          true,\n\t\t\tinterruptible: nil,\n\t\t\twant:          false,\n\t\t},\n\t\t{\n\t\t\tname:          \"TaskDisable\",\n\t\t\ttask:          true,\n\t\t\tinterruptible: &disable,\n\t\t\twant:          false,\n\t\t},\n\t\t{\n\t\t\tname:          \"TaskEnable\",\n\t\t\ttask:          true,\n\t\t\tinterruptible: &enable,\n\t\t\twant:          true,\n\t\t},\n\t}\n\n\tfor _, tt := range tests {\n\t\ttt := tt\n\t\tt.Run(tt.name, func(t *testing.T) {\n\t\t\tt.Parallel()\n\n\t\t\trequest := testutils.GetExecutionRequest()\n\t\t\tif tt.task {\n\t\t\t\trequest.Spec.LaunchPlan.ResourceType = core.ResourceType_TASK\n\t\t\t}\n\t\t\tif tt.interruptible == nil {\n\t\t\t\trequest.Spec.Interruptible = nil\n\t\t\t} else {\n\t\t\t\trequest.Spec.Interruptible = &wrappers.BoolValue{Value: *tt.interruptible}\n\t\t\t}\n\n\t\t\trepository := getMockRepositoryForExecTest()\n\t\t\tsetDefaultLpCallbackForExecTest(repository)\n\t\t\tsetDefaultTaskCallbackForExecTest(repository)\n\n\t\t\texCreateFunc := func(ctx context.Context, input models.Execution) error {\n\t\t\t\tvar spec admin.ExecutionSpec\n\t\t\t\terr := proto.Unmarshal(input.Spec, &spec)\n\t\t\t\tassert.Nil(t, err)\n\n\t\t\t\tif tt.task {\n\t\t\t\t\tassert.Equal(t, uint(0), input.LaunchPlanID)\n\t\t\t\t\tassert.NotEqual(t, uint(0), input.TaskID)\n\t\t\t\t} else {\n\t\t\t\t\tassert.NotEqual(t, uint(0), input.LaunchPlanID)\n\t\t\t\t\tassert.Equal(t, uint(0), input.TaskID)\n\t\t\t\t}\n\n\t\t\t\tif tt.interruptible == nil {\n\t\t\t\t\tassert.Nil(t, spec.GetInterruptible())\n\t\t\t\t} else {\n\t\t\t\t\tassert.NotNil(t, spec.GetInterruptible())\n\t\t\t\t\tassert.Equal(t, *tt.interruptible, spec.GetInterruptible().GetValue())\n\t\t\t\t}\n\n\t\t\t\treturn nil\n\t\t\t}\n\n\t\t\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetCreateCallback(exCreateFunc)\n\t\t\tmockExecutor := workflowengineMocks.WorkflowExecutor{}\n\t\t\tmockExecutor.OnExecuteMatch(mock.Anything, mock.Anything, mock.Anything).Return(workflowengineInterfaces.ExecutionResponse{}, nil)\n\t\t\tmockExecutor.OnID().Return(\"testMockExecutor\")\n\t\t\tr := plugins.NewRegistry()\n\t\t\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &mockExecutor)\n\t\t\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\n\t\t\t_, err := execManager.CreateExecution(context.Background(), request, requestedAt)\n\t\t\tassert.Nil(t, err)\n\t\t})\n\t}\n}\n\nfunc TestCreateExecutionOverwriteCache(t *testing.T) {\n\ttests := []struct {\n\t\tname           string\n\t\ttask           bool\n\t\toverwriteCache bool\n\t\twant           bool\n\t}{\n\t\t{\n\t\t\tname:           \"LaunchPlanDefault\",\n\t\t\ttask:           false,\n\t\t\toverwriteCache: false,\n\t\t\twant:           false,\n\t\t},\n\t\t{\n\t\t\tname:           \"LaunchPlanEnable\",\n\t\t\ttask:           false,\n\t\t\toverwriteCache: true,\n\t\t\twant:           true,\n\t\t},\n\t\t{\n\t\t\tname:           \"TaskDefault\",\n\t\t\ttask:           false,\n\t\t\toverwriteCache: false,\n\t\t\twant:           false,\n\t\t},\n\t\t{\n\t\t\tname:           \"TaskEnable\",\n\t\t\ttask:           true,\n\t\t\toverwriteCache: true,\n\t\t\twant:           true,\n\t\t},\n\t}\n\n\tfor _, tt := range tests {\n\t\ttt := tt\n\t\tt.Run(tt.name, func(t *testing.T) {\n\t\t\tt.Parallel()\n\n\t\t\trequest := testutils.GetExecutionRequest()\n\t\t\tif tt.task {\n\t\t\t\trequest.Spec.LaunchPlan.ResourceType = core.ResourceType_TASK\n\t\t\t}\n\t\t\trequest.Spec.OverwriteCache = tt.overwriteCache\n\n\t\t\trepository := getMockRepositoryForExecTest()\n\t\t\tsetDefaultLpCallbackForExecTest(repository)\n\t\t\tsetDefaultTaskCallbackForExecTest(repository)\n\n\t\t\texCreateFunc := func(ctx context.Context, input models.Execution) error {\n\t\t\t\tvar spec admin.ExecutionSpec\n\t\t\t\terr := proto.Unmarshal(input.Spec, &spec)\n\t\t\t\tassert.Nil(t, err)\n\n\t\t\t\tif tt.task {\n\t\t\t\t\tassert.Equal(t, uint(0), input.LaunchPlanID)\n\t\t\t\t\tassert.NotEqual(t, uint(0), input.TaskID)\n\t\t\t\t} else {\n\t\t\t\t\tassert.NotEqual(t, uint(0), input.LaunchPlanID)\n\t\t\t\t\tassert.Equal(t, uint(0), input.TaskID)\n\t\t\t\t}\n\n\t\t\t\tassert.Equal(t, tt.overwriteCache, spec.GetOverwriteCache())\n\n\t\t\t\treturn nil\n\t\t\t}\n\n\t\t\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetCreateCallback(exCreateFunc)\n\t\t\tmockExecutor := workflowengineMocks.WorkflowExecutor{}\n\t\t\tmockExecutor.OnExecuteMatch(mock.Anything, mock.Anything, mock.Anything).Return(workflowengineInterfaces.ExecutionResponse{}, nil)\n\t\t\tmockExecutor.OnID().Return(\"testMockExecutor\")\n\t\t\tr := plugins.NewRegistry()\n\t\t\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &mockExecutor)\n\t\t\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\n\t\t\t_, err := execManager.CreateExecution(context.Background(), request, requestedAt)\n\t\t\tassert.Nil(t, err)\n\t\t})\n\t}\n}\n\nfunc TestCreateExecutionWithEnvs(t *testing.T) {\n\ttests := []struct {\n\t\tname string\n\t\ttask bool\n\t\tenvs []*core.KeyValuePair\n\t\twant []*core.KeyValuePair\n\t}{\n\t\t{\n\t\t\tname: \"LaunchPlanDefault\",\n\t\t\ttask: false,\n\t\t\tenvs: nil,\n\t\t\twant: nil,\n\t\t},\n\t\t{\n\t\t\tname: \"LaunchPlanEnable\",\n\t\t\ttask: false,\n\t\t\tenvs: []*core.KeyValuePair{{Key: \"foo\", Value: \"bar\"}},\n\t\t\twant: []*core.KeyValuePair{{Key: \"foo\", Value: \"bar\"}},\n\t\t},\n\t\t{\n\t\t\tname: \"TaskDefault\",\n\t\t\ttask: false,\n\t\t\tenvs: nil,\n\t\t\twant: nil,\n\t\t},\n\t\t{\n\t\t\tname: \"TaskEnable\",\n\t\t\ttask: true,\n\t\t\tenvs: []*core.KeyValuePair{{Key: \"foo\", Value: \"bar\"}},\n\t\t\twant: []*core.KeyValuePair{{Key: \"foo\", Value: \"bar\"}},\n\t\t},\n\t}\n\n\tfor _, tt := range tests {\n\t\ttt := tt\n\t\tt.Run(tt.name, func(t *testing.T) {\n\t\t\tt.Parallel()\n\n\t\t\trequest := testutils.GetExecutionRequest()\n\t\t\tif tt.task {\n\t\t\t\trequest.Spec.LaunchPlan.ResourceType = core.ResourceType_TASK\n\t\t\t}\n\t\t\trequest.Spec.Envs.Values = tt.envs\n\n\t\t\trepository := getMockRepositoryForExecTest()\n\t\t\tsetDefaultLpCallbackForExecTest(repository)\n\t\t\tsetDefaultTaskCallbackForExecTest(repository)\n\n\t\t\texCreateFunc := func(ctx context.Context, input models.Execution) error {\n\t\t\t\tvar spec admin.ExecutionSpec\n\t\t\t\terr := proto.Unmarshal(input.Spec, &spec)\n\t\t\t\tassert.Nil(t, err)\n\n\t\t\t\tif tt.task {\n\t\t\t\t\tassert.Equal(t, uint(0), input.LaunchPlanID)\n\t\t\t\t\tassert.NotEqual(t, uint(0), input.TaskID)\n\t\t\t\t} else {\n\t\t\t\t\tassert.NotEqual(t, uint(0), input.LaunchPlanID)\n\t\t\t\t\tassert.Equal(t, uint(0), input.TaskID)\n\t\t\t\t}\n\t\t\t\tif len(tt.envs) != 0 {\n\t\t\t\t\tassert.Equal(t, tt.envs[0].Key, spec.GetEnvs().Values[0].Key)\n\t\t\t\t\tassert.Equal(t, tt.envs[0].Value, spec.GetEnvs().Values[0].Value)\n\t\t\t\t} else {\n\t\t\t\t\tassert.Nil(t, spec.GetEnvs().GetValues())\n\t\t\t\t}\n\n\t\t\t\treturn nil\n\t\t\t}\n\n\t\t\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetCreateCallback(exCreateFunc)\n\t\t\tmockExecutor := workflowengineMocks.WorkflowExecutor{}\n\t\t\tmockExecutor.OnExecuteMatch(mock.Anything, mock.Anything, mock.Anything).Return(workflowengineInterfaces.ExecutionResponse{}, nil)\n\t\t\tmockExecutor.OnID().Return(\"testMockExecutor\")\n\t\t\tr := plugins.NewRegistry()\n\t\t\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &mockExecutor)\n\t\t\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\n\t\t\t_, err := execManager.CreateExecution(context.Background(), request, requestedAt)\n\t\t\tassert.Nil(t, err)\n\t\t})\n\t}\n}\n\nfunc TestCreateExecution_CustomNamespaceMappingConfig(t *testing.T) {\n\trequest := testutils.GetExecutionRequest()\n\trepository := getMockRepositoryForExecTest()\n\tstorageClient := getMockStorageForExecTest(context.Background())\n\tsetDefaultLpCallbackForExecTest(repository)\n\tmockClock := clock.NewMock()\n\tcreatedAt := time.Now()\n\tmockClock.Set(createdAt)\n\texCreateFunc := func(ctx context.Context, input models.Execution) error {\n\t\tvar spec admin.ExecutionSpec\n\t\terr := proto.Unmarshal(input.Spec, &spec)\n\t\tassert.NoError(t, err)\n\t\tassert.Equal(t, spec.GetMetadata().GetSystemMetadata().Namespace, \"project\")\n\t\treturn nil\n\t}\n\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetCreateCallback(exCreateFunc)\n\tmockExecutor := workflowengineMocks.WorkflowExecutor{}\n\tmockExecutor.OnExecuteMatch(mock.Anything, mock.Anything, mock.Anything).Return(workflowengineInterfaces.ExecutionResponse{}, nil)\n\tmockExecutor.OnID().Return(\"testMockExecutor\")\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &mockExecutor)\n\n\tmockNs := runtimeMocks.NamespaceMappingConfiguration{}\n\tmockNs.OnGetNamespaceTemplate().Return(\"{{ project }}\")\n\tmockExecutionsConfigProvider := runtimeMocks.NewMockConfigurationProvider(\n\t\ttestutils.GetApplicationConfigWithDefaultDomains(),\n\t\truntimeMocks.NewMockQueueConfigurationProvider(\n\t\t\t[]runtimeInterfaces.ExecutionQueue{}, []runtimeInterfaces.WorkflowConfig{}),\n\t\tnil,\n\t\truntimeMocks.NewMockTaskResourceConfiguration(resourceDefaults, resourceLimits), nil, &mockNs)\n\tmockExecutionsConfigProvider.(*runtimeMocks.MockConfigurationProvider).AddRegistrationValidationConfiguration(\n\t\truntimeMocks.NewMockRegistrationValidationProvider())\n\n\texecManager := NewExecutionManager(repository, r, mockExecutionsConfigProvider, storageClient, mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\n\texecManager.(*ExecutionManager)._clock = mockClock\n\n\tresponse, err := execManager.CreateExecution(context.Background(), request, requestedAt)\n\tassert.Nil(t, err)\n\tassert.True(t, proto.Equal(&executionIdentifier, response.Id))\n}\n\nfunc makeExecutionGetFunc(\n\tt *testing.T, closureBytes []byte, startTime *time.Time) repositoryMocks.GetExecutionFunc {\n\treturn func(ctx context.Context, input interfaces.Identifier) (models.Execution, error) {\n\t\tassert.Equal(t, \"project\", input.Project)\n\t\tassert.Equal(t, \"domain\", input.Domain)\n\t\tassert.Equal(t, \"name\", input.Name)\n\t\treturn models.Execution{\n\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\tProject: \"project\",\n\t\t\t\tDomain:  \"domain\",\n\t\t\t\tName:    \"name\",\n\t\t\t},\n\t\t\tBaseModel: models.BaseModel{\n\t\t\t\tID: uint(8),\n\t\t\t},\n\t\t\tSpec:         getExpectedSpecBytes(),\n\t\t\tPhase:        core.WorkflowExecution_QUEUED.String(),\n\t\t\tClosure:      closureBytes,\n\t\t\tLaunchPlanID: uint(1),\n\t\t\tWorkflowID:   uint(2),\n\t\t\tStartedAt:    startTime,\n\t\t\tCluster:      testCluster,\n\t\t}, nil\n\t}\n}\n\nfunc makeLegacyExecutionGetFunc(\n\tt *testing.T, closureBytes []byte, startTime *time.Time) repositoryMocks.GetExecutionFunc {\n\treturn func(ctx context.Context, input interfaces.Identifier) (models.Execution, error) {\n\t\tassert.Equal(t, \"project\", input.Project)\n\t\tassert.Equal(t, \"domain\", input.Domain)\n\t\tassert.Equal(t, \"name\", input.Name)\n\t\treturn models.Execution{\n\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\tProject: \"project\",\n\t\t\t\tDomain:  \"domain\",\n\t\t\t\tName:    \"name\",\n\t\t\t},\n\t\t\tBaseModel: models.BaseModel{\n\t\t\t\tID: uint(8),\n\t\t\t},\n\t\t\tSpec:         getLegacySpecBytes(),\n\t\t\tPhase:        core.WorkflowExecution_QUEUED.String(),\n\t\t\tClosure:      closureBytes,\n\t\t\tLaunchPlanID: uint(1),\n\t\t\tWorkflowID:   uint(2),\n\t\t\tStartedAt:    startTime,\n\t\t\tCluster:      testCluster,\n\t\t}, nil\n\t}\n}\n\nfunc makeExecutionInterruptibleGetFunc(\n\tt *testing.T, closureBytes []byte, startTime *time.Time, interruptible *bool) repositoryMocks.GetExecutionFunc {\n\treturn func(ctx context.Context, input interfaces.Identifier) (models.Execution, error) {\n\t\tassert.Equal(t, \"project\", input.Project)\n\t\tassert.Equal(t, \"domain\", input.Domain)\n\t\tassert.Equal(t, \"name\", input.Name)\n\n\t\trequest := testutils.GetExecutionRequest()\n\t\tif interruptible == nil {\n\t\t\trequest.Spec.Interruptible = nil\n\t\t} else {\n\t\t\trequest.Spec.Interruptible = &wrappers.BoolValue{Value: *interruptible}\n\t\t}\n\n\t\tspecBytes, err := proto.Marshal(request.Spec)\n\t\tassert.Nil(t, err)\n\n\t\treturn models.Execution{\n\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\tProject: \"project\",\n\t\t\t\tDomain:  \"domain\",\n\t\t\t\tName:    \"name\",\n\t\t\t},\n\t\t\tBaseModel: models.BaseModel{\n\t\t\t\tID: uint(8),\n\t\t\t},\n\t\t\tSpec:         specBytes,\n\t\t\tPhase:        core.WorkflowExecution_QUEUED.String(),\n\t\t\tClosure:      closureBytes,\n\t\t\tLaunchPlanID: uint(1),\n\t\t\tWorkflowID:   uint(2),\n\t\t\tStartedAt:    startTime,\n\t\t\tCluster:      testCluster,\n\t\t}, nil\n\t}\n}\n\nfunc makeExecutionOverwriteCacheGetFunc(\n\tt *testing.T, closureBytes []byte, startTime *time.Time, overwriteCache bool) repositoryMocks.GetExecutionFunc {\n\treturn func(ctx context.Context, input interfaces.Identifier) (models.Execution, error) {\n\t\tassert.Equal(t, \"project\", input.Project)\n\t\tassert.Equal(t, \"domain\", input.Domain)\n\t\tassert.Equal(t, \"name\", input.Name)\n\n\t\trequest := testutils.GetExecutionRequest()\n\t\trequest.Spec.OverwriteCache = overwriteCache\n\n\t\tspecBytes, err := proto.Marshal(request.Spec)\n\t\tassert.Nil(t, err)\n\n\t\treturn models.Execution{\n\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\tProject: \"project\",\n\t\t\t\tDomain:  \"domain\",\n\t\t\t\tName:    \"name\",\n\t\t\t},\n\t\t\tBaseModel: models.BaseModel{\n\t\t\t\tID: uint(8),\n\t\t\t},\n\t\t\tSpec:         specBytes,\n\t\t\tPhase:        core.WorkflowExecution_QUEUED.String(),\n\t\t\tClosure:      closureBytes,\n\t\t\tLaunchPlanID: uint(1),\n\t\t\tWorkflowID:   uint(2),\n\t\t\tStartedAt:    startTime,\n\t\t\tCluster:      testCluster,\n\t\t}, nil\n\t}\n}\n\nfunc makeExecutionWithEnvs(\n\tt *testing.T, closureBytes []byte, startTime *time.Time, envs []*core.KeyValuePair) repositoryMocks.GetExecutionFunc {\n\treturn func(ctx context.Context, input interfaces.Identifier) (models.Execution, error) {\n\t\tassert.Equal(t, \"project\", input.Project)\n\t\tassert.Equal(t, \"domain\", input.Domain)\n\t\tassert.Equal(t, \"name\", input.Name)\n\n\t\trequest := testutils.GetExecutionRequest()\n\t\trequest.Spec.Envs.Values = envs\n\n\t\tspecBytes, err := proto.Marshal(request.Spec)\n\t\tassert.Nil(t, err)\n\n\t\treturn models.Execution{\n\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\tProject: \"project\",\n\t\t\t\tDomain:  \"domain\",\n\t\t\t\tName:    \"name\",\n\t\t\t},\n\t\t\tBaseModel: models.BaseModel{\n\t\t\t\tID: uint(8),\n\t\t\t},\n\t\t\tSpec:         specBytes,\n\t\t\tPhase:        core.WorkflowExecution_QUEUED.String(),\n\t\t\tClosure:      closureBytes,\n\t\t\tLaunchPlanID: uint(1),\n\t\t\tWorkflowID:   uint(2),\n\t\t\tStartedAt:    startTime,\n\t\t\tCluster:      testCluster,\n\t\t}, nil\n\t}\n}\n\nfunc TestRelaunchExecution(t *testing.T) {\n\t// Set up mocks.\n\trepository := getMockRepositoryForExecTest()\n\tsetDefaultLpCallbackForExecTest(repository)\n\tmockExecutor := workflowengineMocks.WorkflowExecutor{}\n\tmockExecutor.OnExecuteMatch(mock.Anything, mock.Anything, mock.Anything).Return(workflowengineInterfaces.ExecutionResponse{}, nil)\n\tmockExecutor.OnID().Return(\"testMockExecutor\")\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &mockExecutor)\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\tstartTime := time.Now()\n\tstartTimeProto, _ := ptypes.TimestampProto(startTime)\n\texistingClosure := admin.ExecutionClosure{\n\t\tPhase:     core.WorkflowExecution_RUNNING,\n\t\tStartedAt: startTimeProto,\n\t}\n\texistingClosureBytes, _ := proto.Marshal(&existingClosure)\n\texecutionGetFunc := makeExecutionGetFunc(t, existingClosureBytes, &startTime)\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetGetCallback(executionGetFunc)\n\n\tvar createCalled bool\n\texCreateFunc := func(ctx context.Context, input models.Execution) error {\n\t\tcreateCalled = true\n\t\tassert.Equal(t, \"relaunchy\", input.Name)\n\t\tassert.Equal(t, \"domain\", input.Domain)\n\t\tassert.Equal(t, \"project\", input.Project)\n\t\tassert.Equal(t, uint(8), input.SourceExecutionID)\n\t\tvar spec admin.ExecutionSpec\n\t\terr := proto.Unmarshal(input.Spec, &spec)\n\t\tassert.Nil(t, err)\n\t\tassert.Equal(t, admin.ExecutionMetadata_RELAUNCH, spec.Metadata.Mode)\n\t\tassert.Equal(t, int32(admin.ExecutionMetadata_RELAUNCH), input.Mode)\n\t\treturn nil\n\t}\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetCreateCallback(exCreateFunc)\n\n\t// Issue request.\n\tresponse, err := execManager.RelaunchExecution(context.Background(), admin.ExecutionRelaunchRequest{\n\t\tId: &core.WorkflowExecutionIdentifier{\n\t\t\tProject: \"project\",\n\t\t\tDomain:  \"domain\",\n\t\t\tName:    \"name\",\n\t\t},\n\t\tName: \"relaunchy\",\n\t}, requestedAt)\n\n\t// And verify response.\n\tassert.Nil(t, err)\n\n\texpectedResponse := &admin.ExecutionCreateResponse{\n\t\tId: &core.WorkflowExecutionIdentifier{\n\t\t\tProject: \"project\",\n\t\t\tDomain:  \"domain\",\n\t\t\tName:    \"relaunchy\",\n\t\t},\n\t}\n\tassert.True(t, createCalled)\n\tassert.True(t, proto.Equal(expectedResponse, response))\n\n\t// TODO: Test with inputs\n}\n\nfunc TestRelaunchExecution_GetExistingFailure(t *testing.T) {\n\t// Set up mocks.\n\trepository := getMockRepositoryForExecTest()\n\tsetDefaultLpCallbackForExecTest(repository)\n\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &defaultTestExecutor)\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\n\texpectedErr := errors.New(\"expected error\")\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetGetCallback(\n\t\tfunc(ctx context.Context, input interfaces.Identifier) (models.Execution, error) {\n\t\t\treturn models.Execution{}, expectedErr\n\t\t})\n\n\tvar createCalled bool\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetCreateCallback(\n\t\tfunc(ctx context.Context, input models.Execution) error {\n\t\t\tcreateCalled = true\n\t\t\treturn nil\n\t\t})\n\n\t// Issue request.\n\t_, err := execManager.RelaunchExecution(context.Background(), admin.ExecutionRelaunchRequest{\n\t\tId: &core.WorkflowExecutionIdentifier{\n\t\t\tProject: \"project\",\n\t\t\tDomain:  \"domain\",\n\t\t\tName:    \"name\",\n\t\t},\n\t\tName: \"relaunchy\",\n\t}, requestedAt)\n\n\t// And verify response.\n\tassert.EqualError(t, err, expectedErr.Error())\n\tassert.False(t, createCalled)\n}\n\nfunc TestRelaunchExecution_CreateFailure(t *testing.T) {\n\t// Set up mocks.\n\trepository := getMockRepositoryForExecTest()\n\tsetDefaultLpCallbackForExecTest(repository)\n\tmockExecutor := workflowengineMocks.WorkflowExecutor{}\n\tmockExecutor.OnExecuteMatch(mock.Anything, mock.Anything, mock.Anything).Return(workflowengineInterfaces.ExecutionResponse{}, nil)\n\tmockExecutor.OnID().Return(\"testMockExecutor\")\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &mockExecutor)\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\tstartTime := time.Now()\n\tstartTimeProto, _ := ptypes.TimestampProto(startTime)\n\texistingClosure := admin.ExecutionClosure{\n\t\tPhase:     core.WorkflowExecution_RUNNING,\n\t\tStartedAt: startTimeProto,\n\t}\n\texistingClosureBytes, _ := proto.Marshal(&existingClosure)\n\texecutionGetFunc := makeExecutionGetFunc(t, existingClosureBytes, &startTime)\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetGetCallback(executionGetFunc)\n\n\texpectedErr := errors.New(\"expected error\")\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetCreateCallback(\n\t\tfunc(ctx context.Context, input models.Execution) error {\n\t\t\treturn expectedErr\n\t\t})\n\n\t// Issue request.\n\t_, err := execManager.RelaunchExecution(context.Background(), admin.ExecutionRelaunchRequest{\n\t\tId: &core.WorkflowExecutionIdentifier{\n\t\t\tProject: \"project\",\n\t\t\tDomain:  \"domain\",\n\t\t\tName:    \"name\",\n\t\t},\n\t\tName: \"relaunchy\",\n\t}, requestedAt)\n\n\t// And verify response.\n\tassert.EqualError(t, err, expectedErr.Error())\n}\n\nfunc TestRelaunchExecutionInterruptibleOverride(t *testing.T) {\n\t// Set up mocks.\n\trepository := getMockRepositoryForExecTest()\n\tsetDefaultLpCallbackForExecTest(repository)\n\tmockExecutor := workflowengineMocks.WorkflowExecutor{}\n\tmockExecutor.OnExecuteMatch(mock.Anything, mock.Anything, mock.Anything).Return(workflowengineInterfaces.ExecutionResponse{}, nil)\n\tmockExecutor.OnID().Return(\"testMockExecutor\")\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &mockExecutor)\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\tstartTime := time.Now()\n\tstartTimeProto, _ := ptypes.TimestampProto(startTime)\n\texistingClosure := admin.ExecutionClosure{\n\t\tPhase:     core.WorkflowExecution_RUNNING,\n\t\tStartedAt: startTimeProto,\n\t}\n\texistingClosureBytes, _ := proto.Marshal(&existingClosure)\n\tinterruptible := true\n\texecutionGetFunc := makeExecutionInterruptibleGetFunc(t, existingClosureBytes, &startTime, &interruptible)\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetGetCallback(executionGetFunc)\n\n\tvar createCalled bool\n\texCreateFunc := func(ctx context.Context, input models.Execution) error {\n\t\tcreateCalled = true\n\t\tassert.Equal(t, \"relaunchy\", input.Name)\n\t\tassert.Equal(t, \"domain\", input.Domain)\n\t\tassert.Equal(t, \"project\", input.Project)\n\t\tassert.Equal(t, uint(8), input.SourceExecutionID)\n\t\tvar spec admin.ExecutionSpec\n\t\terr := proto.Unmarshal(input.Spec, &spec)\n\t\tassert.Nil(t, err)\n\t\tassert.Equal(t, admin.ExecutionMetadata_RELAUNCH, spec.Metadata.Mode)\n\t\tassert.Equal(t, int32(admin.ExecutionMetadata_RELAUNCH), input.Mode)\n\t\tassert.NotNil(t, spec.GetInterruptible())\n\t\tassert.True(t, spec.GetInterruptible().GetValue())\n\t\treturn nil\n\t}\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetCreateCallback(exCreateFunc)\n\n\t_, err := execManager.RelaunchExecution(context.Background(), admin.ExecutionRelaunchRequest{\n\t\tId: &core.WorkflowExecutionIdentifier{\n\t\t\tProject: \"project\",\n\t\t\tDomain:  \"domain\",\n\t\t\tName:    \"name\",\n\t\t},\n\t\tName: \"relaunchy\",\n\t}, requestedAt)\n\tassert.Nil(t, err)\n\tassert.True(t, createCalled)\n}\n\nfunc TestRelaunchExecutionOverwriteCacheOverride(t *testing.T) {\n\t// Set up mocks.\n\trepository := getMockRepositoryForExecTest()\n\tsetDefaultLpCallbackForExecTest(repository)\n\tmockExecutor := workflowengineMocks.WorkflowExecutor{}\n\tmockExecutor.OnExecuteMatch(mock.Anything, mock.Anything, mock.Anything).Return(workflowengineInterfaces.ExecutionResponse{}, nil)\n\tmockExecutor.OnID().Return(\"testMockExecutor\")\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &mockExecutor)\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\tstartTime := time.Now()\n\tstartTimeProto, _ := ptypes.TimestampProto(startTime)\n\texistingClosure := admin.ExecutionClosure{\n\t\tPhase:     core.WorkflowExecution_RUNNING,\n\t\tStartedAt: startTimeProto,\n\t}\n\texistingClosureBytes, _ := proto.Marshal(&existingClosure)\n\n\tt.Run(\"override enable\", func(t *testing.T) {\n\t\texecutionGetFunc := makeExecutionOverwriteCacheGetFunc(t, existingClosureBytes, &startTime, false)\n\t\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetGetCallback(executionGetFunc)\n\n\t\tvar createCalled bool\n\t\texCreateFunc := func(ctx context.Context, input models.Execution) error {\n\t\t\tcreateCalled = true\n\t\t\tassert.Equal(t, \"relaunchy\", input.Name)\n\t\t\tassert.Equal(t, \"domain\", input.Domain)\n\t\t\tassert.Equal(t, \"project\", input.Project)\n\t\t\tassert.Equal(t, uint(8), input.SourceExecutionID)\n\t\t\tvar spec admin.ExecutionSpec\n\t\t\terr := proto.Unmarshal(input.Spec, &spec)\n\t\t\tassert.Nil(t, err)\n\t\t\tassert.Equal(t, admin.ExecutionMetadata_RELAUNCH, spec.Metadata.Mode)\n\t\t\tassert.Equal(t, int32(admin.ExecutionMetadata_RELAUNCH), input.Mode)\n\t\t\tassert.True(t, spec.GetOverwriteCache())\n\t\t\treturn nil\n\t\t}\n\t\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetCreateCallback(exCreateFunc)\n\n\t\tasd, err := execManager.RelaunchExecution(context.Background(), admin.ExecutionRelaunchRequest{\n\t\t\tId: &core.WorkflowExecutionIdentifier{\n\t\t\t\tProject: \"project\",\n\t\t\t\tDomain:  \"domain\",\n\t\t\t\tName:    \"name\",\n\t\t\t},\n\t\t\tName:           \"relaunchy\",\n\t\t\tOverwriteCache: true,\n\t\t}, requestedAt)\n\t\tassert.Nil(t, err)\n\t\tassert.NotNil(t, asd)\n\t\tassert.True(t, createCalled)\n\t})\n\n\tt.Run(\"override disable\", func(t *testing.T) {\n\t\texecutionGetFunc := makeExecutionOverwriteCacheGetFunc(t, existingClosureBytes, &startTime, true)\n\t\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetGetCallback(executionGetFunc)\n\n\t\tvar createCalled bool\n\t\texCreateFunc := func(ctx context.Context, input models.Execution) error {\n\t\t\tcreateCalled = true\n\t\t\tassert.Equal(t, \"relaunchy\", input.Name)\n\t\t\tassert.Equal(t, \"domain\", input.Domain)\n\t\t\tassert.Equal(t, \"project\", input.Project)\n\t\t\tassert.Equal(t, uint(8), input.SourceExecutionID)\n\t\t\tvar spec admin.ExecutionSpec\n\t\t\terr := proto.Unmarshal(input.Spec, &spec)\n\t\t\tassert.Nil(t, err)\n\t\t\tassert.Equal(t, admin.ExecutionMetadata_RELAUNCH, spec.Metadata.Mode)\n\t\t\tassert.Equal(t, int32(admin.ExecutionMetadata_RELAUNCH), input.Mode)\n\t\t\tassert.False(t, spec.GetOverwriteCache())\n\t\t\treturn nil\n\t\t}\n\t\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetCreateCallback(exCreateFunc)\n\n\t\tasd, err := execManager.RelaunchExecution(context.Background(), admin.ExecutionRelaunchRequest{\n\t\t\tId: &core.WorkflowExecutionIdentifier{\n\t\t\t\tProject: \"project\",\n\t\t\t\tDomain:  \"domain\",\n\t\t\t\tName:    \"name\",\n\t\t\t},\n\t\t\tName:           \"relaunchy\",\n\t\t\tOverwriteCache: false,\n\t\t}, requestedAt)\n\t\tassert.Nil(t, err)\n\t\tassert.NotNil(t, asd)\n\t\tassert.True(t, createCalled)\n\t})\n\n\tt.Run(\"override omitted\", func(t *testing.T) {\n\t\texecutionGetFunc := makeExecutionOverwriteCacheGetFunc(t, existingClosureBytes, &startTime, true)\n\t\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetGetCallback(executionGetFunc)\n\n\t\tvar createCalled bool\n\t\texCreateFunc := func(ctx context.Context, input models.Execution) error {\n\t\t\tcreateCalled = true\n\t\t\tassert.Equal(t, \"relaunchy\", input.Name)\n\t\t\tassert.Equal(t, \"domain\", input.Domain)\n\t\t\tassert.Equal(t, \"project\", input.Project)\n\t\t\tassert.Equal(t, uint(8), input.SourceExecutionID)\n\t\t\tvar spec admin.ExecutionSpec\n\t\t\terr := proto.Unmarshal(input.Spec, &spec)\n\t\t\tassert.Nil(t, err)\n\t\t\tassert.Equal(t, admin.ExecutionMetadata_RELAUNCH, spec.Metadata.Mode)\n\t\t\tassert.Equal(t, int32(admin.ExecutionMetadata_RELAUNCH), input.Mode)\n\t\t\tassert.False(t, spec.GetOverwriteCache())\n\t\t\treturn nil\n\t\t}\n\t\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetCreateCallback(exCreateFunc)\n\n\t\tasd, err := execManager.RelaunchExecution(context.Background(), admin.ExecutionRelaunchRequest{\n\t\t\tId: &core.WorkflowExecutionIdentifier{\n\t\t\t\tProject: \"project\",\n\t\t\t\tDomain:  \"domain\",\n\t\t\t\tName:    \"name\",\n\t\t\t},\n\t\t\tName: \"relaunchy\",\n\t\t}, requestedAt)\n\t\tassert.Nil(t, err)\n\t\tassert.NotNil(t, asd)\n\t\tassert.True(t, createCalled)\n\t})\n}\n\nfunc TestRelaunchExecutionEnvsOverride(t *testing.T) {\n\t// Set up mocks.\n\trepository := getMockRepositoryForExecTest()\n\tsetDefaultLpCallbackForExecTest(repository)\n\tmockExecutor := workflowengineMocks.WorkflowExecutor{}\n\tmockExecutor.OnExecuteMatch(mock.Anything, mock.Anything, mock.Anything).Return(workflowengineInterfaces.ExecutionResponse{}, nil)\n\tmockExecutor.OnID().Return(\"testMockExecutor\")\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &mockExecutor)\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\tstartTime := time.Now()\n\tstartTimeProto, _ := ptypes.TimestampProto(startTime)\n\texistingClosure := admin.ExecutionClosure{\n\t\tPhase:     core.WorkflowExecution_RUNNING,\n\t\tStartedAt: startTimeProto,\n\t}\n\texistingClosureBytes, _ := proto.Marshal(&existingClosure)\n\tenv := []*core.KeyValuePair{{Key: \"foo\", Value: \"bar\"}}\n\texecutionGetFunc := makeExecutionWithEnvs(t, existingClosureBytes, &startTime, env)\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetGetCallback(executionGetFunc)\n\n\tvar createCalled bool\n\texCreateFunc := func(ctx context.Context, input models.Execution) error {\n\t\tcreateCalled = true\n\t\tassert.Equal(t, \"relaunchy\", input.Name)\n\t\tassert.Equal(t, \"domain\", input.Domain)\n\t\tassert.Equal(t, \"project\", input.Project)\n\t\tassert.Equal(t, uint(8), input.SourceExecutionID)\n\t\tvar spec admin.ExecutionSpec\n\t\terr := proto.Unmarshal(input.Spec, &spec)\n\t\tassert.Nil(t, err)\n\t\tassert.Equal(t, admin.ExecutionMetadata_RELAUNCH, spec.Metadata.Mode)\n\t\tassert.Equal(t, int32(admin.ExecutionMetadata_RELAUNCH), input.Mode)\n\t\tassert.NotNil(t, spec.GetEnvs())\n\t\tassert.Equal(t, spec.GetEnvs().Values[0].Key, env[0].Key)\n\t\tassert.Equal(t, spec.GetEnvs().Values[0].Value, env[0].Value)\n\t\treturn nil\n\t}\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetCreateCallback(exCreateFunc)\n\n\t_, err := execManager.RelaunchExecution(context.Background(), admin.ExecutionRelaunchRequest{\n\t\tId: &core.WorkflowExecutionIdentifier{\n\t\t\tProject: \"project\",\n\t\t\tDomain:  \"domain\",\n\t\t\tName:    \"name\",\n\t\t},\n\t\tName: \"relaunchy\",\n\t}, requestedAt)\n\tassert.Nil(t, err)\n\tassert.True(t, createCalled)\n}\n\nfunc TestRecoverExecution(t *testing.T) {\n\t// Set up mocks.\n\trepository := getMockRepositoryForExecTest()\n\tsetDefaultLpCallbackForExecTest(repository)\n\tmockExecutor := workflowengineMocks.WorkflowExecutor{}\n\tmockExecutor.OnExecuteMatch(mock.Anything, mock.Anything, mock.Anything).Return(workflowengineInterfaces.ExecutionResponse{}, nil)\n\tmockExecutor.OnID().Return(\"testMockExecutor\")\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &mockExecutor)\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\tstartTime := time.Now()\n\tstartTimeProto, _ := ptypes.TimestampProto(startTime)\n\texistingClosure := admin.ExecutionClosure{\n\t\tPhase:     core.WorkflowExecution_SUCCEEDED,\n\t\tStartedAt: startTimeProto,\n\t}\n\texistingClosureBytes, _ := proto.Marshal(&existingClosure)\n\texecutionGetFunc := makeExecutionGetFunc(t, existingClosureBytes, &startTime)\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetGetCallback(executionGetFunc)\n\n\tvar createCalled bool\n\texCreateFunc := func(ctx context.Context, input models.Execution) error {\n\t\tcreateCalled = true\n\t\tassert.Equal(t, \"recovered\", input.Name)\n\t\tassert.Equal(t, \"domain\", input.Domain)\n\t\tassert.Equal(t, \"project\", input.Project)\n\t\tassert.Equal(t, uint(8), input.SourceExecutionID)\n\t\tvar spec admin.ExecutionSpec\n\t\terr := proto.Unmarshal(input.Spec, &spec)\n\t\tassert.Nil(t, err)\n\t\tassert.Equal(t, admin.ExecutionMetadata_RECOVERED, spec.Metadata.Mode)\n\t\tassert.Equal(t, int32(admin.ExecutionMetadata_RECOVERED), input.Mode)\n\t\treturn nil\n\t}\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetCreateCallback(exCreateFunc)\n\n\t// Issue request.\n\tresponse, err := execManager.RecoverExecution(context.Background(), admin.ExecutionRecoverRequest{\n\t\tId: &core.WorkflowExecutionIdentifier{\n\t\t\tProject: \"project\",\n\t\t\tDomain:  \"domain\",\n\t\t\tName:    \"name\",\n\t\t},\n\t\tName: \"recovered\",\n\t}, requestedAt)\n\n\t// And verify response.\n\tassert.Nil(t, err)\n\n\texpectedResponse := &admin.ExecutionCreateResponse{\n\t\tId: &core.WorkflowExecutionIdentifier{\n\t\t\tProject: \"project\",\n\t\t\tDomain:  \"domain\",\n\t\t\tName:    \"recovered\",\n\t\t},\n\t}\n\tassert.True(t, createCalled)\n\tassert.True(t, proto.Equal(expectedResponse, response))\n}\n\nfunc TestRecoverExecution_RecoveredChildNode(t *testing.T) {\n\trepository := getMockRepositoryForExecTest()\n\tsetDefaultLpCallbackForExecTest(repository)\n\tmockExecutor := workflowengineMocks.WorkflowExecutor{}\n\tmockExecutor.OnExecuteMatch(mock.Anything, mock.Anything, mock.Anything).Return(workflowengineInterfaces.ExecutionResponse{}, nil)\n\tmockExecutor.OnID().Return(\"testMockExecutor\")\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &mockExecutor)\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\tstartTime := time.Now()\n\tstartTimeProto, _ := ptypes.TimestampProto(startTime)\n\texistingClosure := admin.ExecutionClosure{\n\t\tPhase:     core.WorkflowExecution_SUCCEEDED,\n\t\tStartedAt: startTimeProto,\n\t}\n\texistingClosureBytes, _ := proto.Marshal(&existingClosure)\n\treferencedExecutionID := uint(123)\n\tignoredExecutionID := uint(456)\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetGetCallback(func(ctx context.Context, input interfaces.Identifier) (models.Execution, error) {\n\t\tswitch input.Name {\n\t\tcase \"name\":\n\t\t\treturn models.Execution{\n\t\t\t\tSpec:    getExpectedSpecBytes(),\n\t\t\t\tClosure: existingClosureBytes,\n\t\t\t\tBaseModel: models.BaseModel{\n\t\t\t\t\tID: referencedExecutionID,\n\t\t\t\t},\n\t\t\t}, nil\n\t\tcase \"orig\":\n\t\t\treturn models.Execution{\n\t\t\t\tBaseModel: models.BaseModel{\n\t\t\t\t\tID: ignoredExecutionID,\n\t\t\t\t},\n\t\t\t}, nil\n\t\tdefault:\n\t\t\treturn models.Execution{}, flyteAdminErrors.NewFlyteAdminErrorf(codes.InvalidArgument, \"unexpected get for execution %s\", input.Name)\n\t\t}\n\t})\n\n\tparentNodeDatabaseID := uint(12345)\n\tvar createCalled bool\n\texCreateFunc := func(ctx context.Context, input models.Execution) error {\n\t\tcreateCalled = true\n\t\tassert.Equal(t, \"recovered\", input.Name)\n\t\tassert.Equal(t, \"domain\", input.Domain)\n\t\tassert.Equal(t, \"project\", input.Project)\n\t\tvar spec admin.ExecutionSpec\n\t\terr := proto.Unmarshal(input.Spec, &spec)\n\t\tassert.Nil(t, err)\n\t\tassert.Equal(t, admin.ExecutionMetadata_RECOVERED, spec.Metadata.Mode)\n\t\tassert.Equal(t, int32(admin.ExecutionMetadata_RECOVERED), input.Mode)\n\t\tassert.Equal(t, parentNodeDatabaseID, input.ParentNodeExecutionID)\n\t\tassert.Equal(t, referencedExecutionID, input.SourceExecutionID)\n\n\t\treturn nil\n\t}\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetCreateCallback(exCreateFunc)\n\n\tparentNodeExecution := core.NodeExecutionIdentifier{\n\t\tExecutionId: &core.WorkflowExecutionIdentifier{\n\t\t\tProject: \"p\",\n\t\t\tDomain:  \"d\",\n\t\t\tName:    \"orig\",\n\t\t},\n\t\tNodeId: \"parent\",\n\t}\n\trepository.NodeExecutionRepo().(*repositoryMocks.MockNodeExecutionRepo).SetGetCallback(func(ctx context.Context, input interfaces.NodeExecutionResource) (models.NodeExecution, error) {\n\t\tassert.True(t, proto.Equal(&parentNodeExecution, &input.NodeExecutionIdentifier))\n\n\t\treturn models.NodeExecution{\n\t\t\tBaseModel: models.BaseModel{\n\t\t\t\tID: parentNodeDatabaseID,\n\t\t\t},\n\t\t}, nil\n\t})\n\n\t// Issue request.\n\tresponse, err := execManager.RecoverExecution(context.Background(), admin.ExecutionRecoverRequest{\n\t\tId: &core.WorkflowExecutionIdentifier{\n\t\t\tProject: \"project\",\n\t\t\tDomain:  \"domain\",\n\t\t\tName:    \"name\",\n\t\t},\n\t\tName: \"recovered\",\n\t\tMetadata: &admin.ExecutionMetadata{\n\t\t\tParentNodeExecution: &parentNodeExecution,\n\t\t},\n\t}, requestedAt)\n\n\t// And verify response.\n\tassert.Nil(t, err)\n\n\texpectedResponse := &admin.ExecutionCreateResponse{\n\t\tId: &core.WorkflowExecutionIdentifier{\n\t\t\tProject: \"project\",\n\t\t\tDomain:  \"domain\",\n\t\t\tName:    \"recovered\",\n\t\t},\n\t}\n\tassert.True(t, createCalled)\n\tassert.True(t, proto.Equal(expectedResponse, response))\n}\n\nfunc TestRecoverExecution_GetExistingFailure(t *testing.T) {\n\t// Set up mocks.\n\trepository := getMockRepositoryForExecTest()\n\tsetDefaultLpCallbackForExecTest(repository)\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &defaultTestExecutor)\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\n\texpectedErr := errors.New(\"expected error\")\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetGetCallback(\n\t\tfunc(ctx context.Context, input interfaces.Identifier) (models.Execution, error) {\n\t\t\treturn models.Execution{}, expectedErr\n\t\t})\n\n\tvar createCalled bool\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetCreateCallback(\n\t\tfunc(ctx context.Context, input models.Execution) error {\n\t\t\tcreateCalled = true\n\t\t\treturn nil\n\t\t})\n\n\t// Issue request.\n\t_, err := execManager.RecoverExecution(context.Background(), admin.ExecutionRecoverRequest{\n\t\tId: &core.WorkflowExecutionIdentifier{\n\t\t\tProject: \"project\",\n\t\t\tDomain:  \"domain\",\n\t\t\tName:    \"name\",\n\t\t},\n\t\tName: \"recovered\",\n\t}, requestedAt)\n\n\t// And verify response.\n\tassert.EqualError(t, err, expectedErr.Error())\n\tassert.False(t, createCalled)\n}\n\nfunc TestRecoverExecution_GetExistingInputsFailure(t *testing.T) {\n\t// Set up mocks.\n\trepository := getMockRepositoryForExecTest()\n\tsetDefaultLpCallbackForExecTest(repository)\n\n\texpectedErr := errors.New(\"foo\")\n\tmockStorage := commonMocks.GetMockStorageClient()\n\tmockStorage.ComposedProtobufStore.(*commonMocks.TestDataStore).ReadProtobufCb = func(\n\t\tctx context.Context, reference storage.DataReference, msg proto.Message) error {\n\t\treturn expectedErr\n\t}\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &defaultTestExecutor)\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), mockStorage, mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\tstartTime := time.Now()\n\tstartTimeProto, _ := ptypes.TimestampProto(startTime)\n\texistingClosure := admin.ExecutionClosure{\n\t\tPhase:     core.WorkflowExecution_SUCCEEDED,\n\t\tStartedAt: startTimeProto,\n\t}\n\texistingClosureBytes, _ := proto.Marshal(&existingClosure)\n\texecutionGetFunc := makeExecutionGetFunc(t, existingClosureBytes, &startTime)\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetGetCallback(executionGetFunc)\n\n\t// Issue request.\n\t_, err := execManager.RecoverExecution(context.Background(), admin.ExecutionRecoverRequest{\n\t\tId: &core.WorkflowExecutionIdentifier{\n\t\t\tProject: \"project\",\n\t\t\tDomain:  \"domain\",\n\t\t\tName:    \"name\",\n\t\t},\n\t\tName: \"recovered\",\n\t}, requestedAt)\n\n\t// And verify response.\n\tassert.EqualError(t, err, \"Unable to read WorkflowClosure from location s3://flyte/metadata/admin/remote closure id : foo\")\n}\n\nfunc TestRecoverExecutionInterruptibleOverride(t *testing.T) {\n\t// Set up mocks.\n\trepository := getMockRepositoryForExecTest()\n\tsetDefaultLpCallbackForExecTest(repository)\n\tmockExecutor := workflowengineMocks.WorkflowExecutor{}\n\tmockExecutor.OnExecuteMatch(mock.Anything, mock.Anything, mock.Anything).Return(workflowengineInterfaces.ExecutionResponse{}, nil)\n\tmockExecutor.OnID().Return(\"testMockExecutor\")\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &mockExecutor)\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\tstartTime := time.Now()\n\tstartTimeProto, _ := ptypes.TimestampProto(startTime)\n\texistingClosure := admin.ExecutionClosure{\n\t\tPhase:     core.WorkflowExecution_SUCCEEDED,\n\t\tStartedAt: startTimeProto,\n\t}\n\texistingClosureBytes, _ := proto.Marshal(&existingClosure)\n\tinterruptible := true\n\texecutionGetFunc := makeExecutionInterruptibleGetFunc(t, existingClosureBytes, &startTime, &interruptible)\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetGetCallback(executionGetFunc)\n\n\tvar createCalled bool\n\texCreateFunc := func(ctx context.Context, input models.Execution) error {\n\t\tcreateCalled = true\n\t\tassert.Equal(t, \"recovered\", input.Name)\n\t\tassert.Equal(t, \"domain\", input.Domain)\n\t\tassert.Equal(t, \"project\", input.Project)\n\t\tassert.Equal(t, uint(8), input.SourceExecutionID)\n\t\tvar spec admin.ExecutionSpec\n\t\terr := proto.Unmarshal(input.Spec, &spec)\n\t\tassert.Nil(t, err)\n\t\tassert.Equal(t, admin.ExecutionMetadata_RECOVERED, spec.Metadata.Mode)\n\t\tassert.Equal(t, int32(admin.ExecutionMetadata_RECOVERED), input.Mode)\n\t\tassert.NotNil(t, spec.GetInterruptible())\n\t\tassert.True(t, spec.GetInterruptible().GetValue())\n\t\treturn nil\n\t}\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetCreateCallback(exCreateFunc)\n\n\t// Issue request.\n\tresponse, err := execManager.RecoverExecution(context.Background(), admin.ExecutionRecoverRequest{\n\t\tId: &core.WorkflowExecutionIdentifier{\n\t\t\tProject: \"project\",\n\t\t\tDomain:  \"domain\",\n\t\t\tName:    \"name\",\n\t\t},\n\t\tName: \"recovered\",\n\t}, requestedAt)\n\n\t// And verify response.\n\tassert.Nil(t, err)\n\n\texpectedResponse := &admin.ExecutionCreateResponse{\n\t\tId: &core.WorkflowExecutionIdentifier{\n\t\t\tProject: \"project\",\n\t\t\tDomain:  \"domain\",\n\t\t\tName:    \"recovered\",\n\t\t},\n\t}\n\tassert.True(t, createCalled)\n\tassert.True(t, proto.Equal(expectedResponse, response))\n}\n\nfunc TestRecoverExecutionOverwriteCacheOverride(t *testing.T) {\n\t// Set up mocks.\n\trepository := getMockRepositoryForExecTest()\n\tsetDefaultLpCallbackForExecTest(repository)\n\tmockExecutor := workflowengineMocks.WorkflowExecutor{}\n\tmockExecutor.OnExecuteMatch(mock.Anything, mock.Anything, mock.Anything).Return(workflowengineInterfaces.ExecutionResponse{}, nil)\n\tmockExecutor.OnID().Return(\"testMockExecutor\")\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &mockExecutor)\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\tstartTime := time.Now()\n\tstartTimeProto, _ := ptypes.TimestampProto(startTime)\n\texistingClosure := admin.ExecutionClosure{\n\t\tPhase:     core.WorkflowExecution_SUCCEEDED,\n\t\tStartedAt: startTimeProto,\n\t}\n\texistingClosureBytes, _ := proto.Marshal(&existingClosure)\n\texecutionGetFunc := makeExecutionOverwriteCacheGetFunc(t, existingClosureBytes, &startTime, true)\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetGetCallback(executionGetFunc)\n\n\tvar createCalled bool\n\texCreateFunc := func(ctx context.Context, input models.Execution) error {\n\t\tcreateCalled = true\n\t\tassert.Equal(t, \"recovered\", input.Name)\n\t\tassert.Equal(t, \"domain\", input.Domain)\n\t\tassert.Equal(t, \"project\", input.Project)\n\t\tassert.Equal(t, uint(8), input.SourceExecutionID)\n\t\tvar spec admin.ExecutionSpec\n\t\terr := proto.Unmarshal(input.Spec, &spec)\n\t\tassert.Nil(t, err)\n\t\tassert.Equal(t, admin.ExecutionMetadata_RECOVERED, spec.Metadata.Mode)\n\t\tassert.Equal(t, int32(admin.ExecutionMetadata_RECOVERED), input.Mode)\n\t\tassert.True(t, spec.GetOverwriteCache())\n\t\treturn nil\n\t}\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetCreateCallback(exCreateFunc)\n\n\t// Issue request.\n\tresponse, err := execManager.RecoverExecution(context.Background(), admin.ExecutionRecoverRequest{\n\t\tId: &core.WorkflowExecutionIdentifier{\n\t\t\tProject: \"project\",\n\t\t\tDomain:  \"domain\",\n\t\t\tName:    \"name\",\n\t\t},\n\t\tName: \"recovered\",\n\t}, requestedAt)\n\n\t// And verify response.\n\tassert.Nil(t, err)\n\n\texpectedResponse := &admin.ExecutionCreateResponse{\n\t\tId: &core.WorkflowExecutionIdentifier{\n\t\t\tProject: \"project\",\n\t\t\tDomain:  \"domain\",\n\t\t\tName:    \"recovered\",\n\t\t},\n\t}\n\tassert.True(t, createCalled)\n\tassert.True(t, proto.Equal(expectedResponse, response))\n}\n\nfunc TestRecoverExecutionEnvsOverride(t *testing.T) {\n\t// Set up mocks.\n\trepository := getMockRepositoryForExecTest()\n\tsetDefaultLpCallbackForExecTest(repository)\n\tmockExecutor := workflowengineMocks.WorkflowExecutor{}\n\tmockExecutor.OnExecuteMatch(mock.Anything, mock.Anything, mock.Anything).Return(workflowengineInterfaces.ExecutionResponse{}, nil)\n\tmockExecutor.OnID().Return(\"testMockExecutor\")\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &mockExecutor)\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\tstartTime := time.Now()\n\tstartTimeProto, _ := ptypes.TimestampProto(startTime)\n\texistingClosure := admin.ExecutionClosure{\n\t\tPhase:     core.WorkflowExecution_SUCCEEDED,\n\t\tStartedAt: startTimeProto,\n\t}\n\texistingClosureBytes, _ := proto.Marshal(&existingClosure)\n\tenv := []*core.KeyValuePair{{Key: \"foo\", Value: \"bar\"}}\n\texecutionGetFunc := makeExecutionWithEnvs(t, existingClosureBytes, &startTime, env)\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetGetCallback(executionGetFunc)\n\n\texCreateFunc := func(ctx context.Context, input models.Execution) error {\n\t\tassert.Equal(t, \"recovered\", input.Name)\n\t\tassert.Equal(t, \"domain\", input.Domain)\n\t\tassert.Equal(t, \"project\", input.Project)\n\t\tassert.Equal(t, uint(8), input.SourceExecutionID)\n\t\tvar spec admin.ExecutionSpec\n\t\terr := proto.Unmarshal(input.Spec, &spec)\n\t\tassert.Nil(t, err)\n\t\tassert.Equal(t, admin.ExecutionMetadata_RECOVERED, spec.Metadata.Mode)\n\t\tassert.Equal(t, int32(admin.ExecutionMetadata_RECOVERED), input.Mode)\n\t\tassert.NotNil(t, spec.GetEnvs())\n\t\tassert.Equal(t, spec.GetEnvs().GetValues()[0].Key, env[0].Key)\n\t\tassert.Equal(t, spec.GetEnvs().GetValues()[0].Value, env[0].Value)\n\t\treturn nil\n\t}\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetCreateCallback(exCreateFunc)\n\n\t// Issue request.\n\tresponse, err := execManager.RecoverExecution(context.Background(), admin.ExecutionRecoverRequest{\n\t\tId: &core.WorkflowExecutionIdentifier{\n\t\t\tProject: \"project\",\n\t\t\tDomain:  \"domain\",\n\t\t\tName:    \"name\",\n\t\t},\n\t\tName: \"recovered\",\n\t}, requestedAt)\n\n\t// And verify response.\n\tassert.Nil(t, err)\n\n\texpectedResponse := &admin.ExecutionCreateResponse{\n\t\tId: &core.WorkflowExecutionIdentifier{\n\t\t\tProject: \"project\",\n\t\t\tDomain:  \"domain\",\n\t\t\tName:    \"recovered\",\n\t\t},\n\t}\n\tassert.True(t, proto.Equal(expectedResponse, response))\n}\n\nfunc TestCreateWorkflowEvent(t *testing.T) {\n\trepository := repositoryMocks.NewMockRepository()\n\tstartTime := time.Now()\n\tstartTimeProto, _ := ptypes.TimestampProto(startTime)\n\tduration := time.Second\n\tdurationProto := ptypes.DurationProto(duration)\n\texistingClosure := admin.ExecutionClosure{\n\t\tPhase:     core.WorkflowExecution_RUNNING,\n\t\tStartedAt: startTimeProto,\n\t}\n\texistingClosureBytes, _ := proto.Marshal(&existingClosure)\n\texecutionGetFunc := makeExecutionGetFunc(t, existingClosureBytes, &startTime)\n\texecutionError := core.ExecutionError{\n\t\tCode:    \"foo\",\n\t\tMessage: \"bar baz\",\n\t}\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetGetCallback(executionGetFunc)\n\tendTime := startTime.Add(duration)\n\toccurredAt, _ := ptypes.TimestampProto(endTime)\n\tclosure := admin.ExecutionClosure{\n\t\tPhase:     core.WorkflowExecution_FAILED,\n\t\tStartedAt: startTimeProto,\n\t\tUpdatedAt: occurredAt,\n\t\tDuration:  durationProto,\n\t\tOutputResult: &admin.ExecutionClosure_Error{\n\t\t\tError: &executionError,\n\t\t},\n\t}\n\tclosureBytes, _ := proto.Marshal(&closure)\n\tupdateExecutionFunc := func(\n\t\tcontext context.Context, execution models.Execution) error {\n\n\t\tassert.Equal(t, \"project\", execution.Project)\n\t\tassert.Equal(t, \"domain\", execution.Domain)\n\t\tassert.Equal(t, \"name\", execution.Name)\n\t\tassert.Equal(t, uint(1), execution.LaunchPlanID)\n\t\tassert.Equal(t, uint(2), execution.WorkflowID)\n\t\tassert.Equal(t, core.WorkflowExecution_FAILED.String(), execution.Phase)\n\t\tassert.Equal(t, closureBytes, execution.Closure)\n\t\tassert.Equal(t, getExpectedSpecBytes(), execution.Spec)\n\t\tassert.Equal(t, startTime, *execution.StartedAt)\n\t\tassert.Equal(t, duration, execution.Duration)\n\t\treturn nil\n\t}\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetUpdateCallback(updateExecutionFunc)\n\trequest := admin.WorkflowExecutionEventRequest{\n\t\tRequestId: \"1\",\n\t\tEvent: &event.WorkflowExecutionEvent{\n\t\t\tExecutionId: &executionIdentifier,\n\t\t\tOccurredAt:  occurredAt,\n\t\t\tPhase:       core.WorkflowExecution_FAILED,\n\t\t\tOutputResult: &event.WorkflowExecutionEvent_Error{\n\t\t\t\tError: &executionError,\n\t\t\t},\n\t\t\tProducerId: testCluster,\n\t\t},\n\t}\n\tmockDbEventWriter := &eventWriterMocks.WorkflowExecutionEventWriter{}\n\tmockDbEventWriter.On(\"Write\", request)\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &defaultTestExecutor)\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, &mockPublisher, &mockPublisher, mockDbEventWriter)\n\tresp, err := execManager.CreateWorkflowEvent(context.Background(), request)\n\tassert.Nil(t, err)\n\tassert.NotNil(t, resp)\n}\n\nfunc TestCreateWorkflowEvent_TerminalState(t *testing.T) {\n\trepository := repositoryMocks.NewMockRepository()\n\texecutionGetFunc := func(ctx context.Context, input interfaces.Identifier) (models.Execution, error) {\n\t\treturn models.Execution{\n\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\tProject: \"project\",\n\t\t\t\tDomain:  \"domain\",\n\t\t\t\tName:    \"name\",\n\t\t\t},\n\t\t\tBaseModel: models.BaseModel{\n\t\t\t\tID: uint(8),\n\t\t\t},\n\t\t\tSpec:  getExpectedSpecBytes(),\n\t\t\tPhase: core.WorkflowExecution_FAILED.String(),\n\t\t}, nil\n\t}\n\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetGetCallback(executionGetFunc)\n\tupdateExecutionFunc := func(context context.Context, execution models.Execution) error {\n\t\treturn nil\n\t}\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetUpdateCallback(updateExecutionFunc)\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &defaultTestExecutor)\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\n\tresp, err := execManager.CreateWorkflowEvent(context.Background(), admin.WorkflowExecutionEventRequest{\n\t\tRequestId: \"1\",\n\t\tEvent: &event.WorkflowExecutionEvent{\n\t\t\tExecutionId: &executionIdentifier,\n\t\t\tPhase:       core.WorkflowExecution_SUCCEEDED,\n\t\t},\n\t})\n\tassert.Nil(t, resp)\n\tassert.NotNil(t, err)\n\tadminError := err.(flyteAdminErrors.FlyteAdminError)\n\tassert.Equal(t, adminError.Code(), codes.FailedPrecondition)\n\tdetails, ok := adminError.GRPCStatus().Details()[0].(*admin.EventFailureReason)\n\tassert.True(t, ok)\n\t_, ok = details.GetReason().(*admin.EventFailureReason_AlreadyInTerminalState)\n\tassert.True(t, ok)\n}\n\nfunc TestCreateWorkflowEvent_NoRunningToQueued(t *testing.T) {\n\trepository := repositoryMocks.NewMockRepository()\n\texecutionGetFunc := func(ctx context.Context, input interfaces.Identifier) (models.Execution, error) {\n\t\treturn models.Execution{\n\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\tProject: \"project\",\n\t\t\t\tDomain:  \"domain\",\n\t\t\t\tName:    \"name\",\n\t\t\t},\n\t\t\tSpec:  getExpectedSpecBytes(),\n\t\t\tPhase: core.WorkflowExecution_RUNNING.String(),\n\t\t}, nil\n\t}\n\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetGetCallback(executionGetFunc)\n\tupdateExecutionFunc := func(context context.Context, execution models.Execution) error {\n\t\treturn nil\n\t}\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetUpdateCallback(updateExecutionFunc)\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &defaultTestExecutor)\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\n\tresp, err := execManager.CreateWorkflowEvent(context.Background(), admin.WorkflowExecutionEventRequest{\n\t\tRequestId: \"1\",\n\t\tEvent: &event.WorkflowExecutionEvent{\n\t\t\tExecutionId: &executionIdentifier,\n\t\t\tPhase:       core.WorkflowExecution_QUEUED,\n\t\t},\n\t})\n\tassert.Nil(t, resp)\n\tassert.NotNil(t, err)\n\tadminError := err.(flyteAdminErrors.FlyteAdminError)\n\tassert.Equal(t, adminError.Code(), codes.FailedPrecondition)\n}\n\nfunc TestCreateWorkflowEvent_CurrentlyAborting(t *testing.T) {\n\trepository := repositoryMocks.NewMockRepository()\n\texecutionGetFunc := func(ctx context.Context, input interfaces.Identifier) (models.Execution, error) {\n\t\treturn models.Execution{\n\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\tProject: \"project\",\n\t\t\t\tDomain:  \"domain\",\n\t\t\t\tName:    \"name\",\n\t\t\t},\n\t\t\tSpec:  getExpectedSpecBytes(),\n\t\t\tPhase: core.WorkflowExecution_ABORTING.String(),\n\t\t}, nil\n\t}\n\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetGetCallback(executionGetFunc)\n\tupdateExecutionFunc := func(context context.Context, execution models.Execution) error {\n\t\treturn nil\n\t}\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetUpdateCallback(updateExecutionFunc)\n\n\treq := admin.WorkflowExecutionEventRequest{\n\t\tRequestId: \"1\",\n\t\tEvent: &event.WorkflowExecutionEvent{\n\t\t\tExecutionId: &executionIdentifier,\n\t\t\tPhase:       core.WorkflowExecution_ABORTED,\n\t\t\tOccurredAt:  timestamppb.New(time.Now()),\n\t\t},\n\t}\n\n\tmockDbEventWriter := &eventWriterMocks.WorkflowExecutionEventWriter{}\n\tmockDbEventWriter.On(\"Write\", req)\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &defaultTestExecutor)\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, &mockPublisher, &mockPublisher, mockDbEventWriter)\n\n\tresp, err := execManager.CreateWorkflowEvent(context.Background(), req)\n\tassert.NotNil(t, resp)\n\tassert.NoError(t, err)\n\n\treq.Event.Phase = core.WorkflowExecution_QUEUED\n\tresp, err = execManager.CreateWorkflowEvent(context.Background(), req)\n\tassert.Nil(t, resp)\n\tassert.NotNil(t, err)\n\tadminError := err.(flyteAdminErrors.FlyteAdminError)\n\tassert.Equal(t, adminError.Code(), codes.FailedPrecondition)\n\n\treq.Event.Phase = core.WorkflowExecution_RUNNING\n\tresp, err = execManager.CreateWorkflowEvent(context.Background(), req)\n\tassert.Nil(t, resp)\n\tassert.NotNil(t, err)\n\tadminError = err.(flyteAdminErrors.FlyteAdminError)\n\tassert.Equal(t, adminError.Code(), codes.FailedPrecondition)\n}\n\nfunc TestCreateWorkflowEvent_StartedRunning(t *testing.T) {\n\trepository := repositoryMocks.NewMockRepository()\n\toccurredAt := time.Now().UTC()\n\toccurredAtProto, _ := ptypes.TimestampProto(occurredAt)\n\texecutionGetFunc := makeExecutionGetFunc(t, closureBytes, nil)\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetGetCallback(executionGetFunc)\n\n\tclosure := admin.ExecutionClosure{\n\t\tPhase:     core.WorkflowExecution_RUNNING,\n\t\tStartedAt: occurredAtProto,\n\t\tUpdatedAt: occurredAtProto,\n\t\tStateChangeDetails: &admin.ExecutionStateChangeDetails{\n\t\t\tState:      admin.ExecutionState_EXECUTION_ACTIVE,\n\t\t\tOccurredAt: testutils.MockCreatedAtProto,\n\t\t},\n\t}\n\tclosureBytes, _ := proto.Marshal(&closure)\n\tupdateExecutionFunc := func(\n\t\tcontext context.Context, execution models.Execution) error {\n\t\tassert.Equal(t, \"project\", execution.Project)\n\t\tassert.Equal(t, \"domain\", execution.Domain)\n\t\tassert.Equal(t, \"name\", execution.Name)\n\t\tassert.Equal(t, uint(1), execution.LaunchPlanID)\n\t\tassert.Equal(t, uint(2), execution.WorkflowID)\n\t\tassert.Equal(t, core.WorkflowExecution_RUNNING.String(), execution.Phase)\n\t\tassert.Equal(t, closureBytes, execution.Closure)\n\t\tassert.Equal(t, getExpectedSpecBytes(), execution.Spec)\n\t\tassert.Equal(t, occurredAt, *execution.StartedAt)\n\t\tassert.Equal(t, time.Duration(0), execution.Duration)\n\t\tassert.Equal(t, occurredAt, *execution.ExecutionUpdatedAt)\n\t\treturn nil\n\t}\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetUpdateCallback(updateExecutionFunc)\n\toccurredAtTimestamp, _ := ptypes.TimestampProto(occurredAt)\n\trequest := admin.WorkflowExecutionEventRequest{\n\t\tRequestId: \"1\",\n\t\tEvent: &event.WorkflowExecutionEvent{\n\t\t\tExecutionId: &executionIdentifier,\n\t\t\tOccurredAt:  occurredAtTimestamp,\n\t\t\tPhase:       core.WorkflowExecution_RUNNING,\n\t\t\tProducerId:  testCluster,\n\t\t},\n\t}\n\tmockDbEventWriter := &eventWriterMocks.WorkflowExecutionEventWriter{}\n\tmockDbEventWriter.On(\"Write\", request)\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &defaultTestExecutor)\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, &mockPublisher, &mockPublisher, mockDbEventWriter)\n\tresp, err := execManager.CreateWorkflowEvent(context.Background(), request)\n\tassert.Nil(t, err)\n\tassert.NotNil(t, resp)\n}\n\nfunc TestCreateWorkflowEvent_DuplicateRunning(t *testing.T) {\n\trepository := repositoryMocks.NewMockRepository()\n\toccurredAt := time.Now().UTC()\n\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetGetCallback(\n\t\tfunc(ctx context.Context, input interfaces.Identifier) (models.Execution, error) {\n\t\t\treturn models.Execution{\n\t\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\t\tProject: \"project\",\n\t\t\t\t\tDomain:  \"domain\",\n\t\t\t\t\tName:    \"name\",\n\t\t\t\t},\n\t\t\t\tBaseModel: models.BaseModel{\n\t\t\t\t\tID: uint(8),\n\t\t\t\t},\n\t\t\t\tSpec:         getExpectedSpecBytes(),\n\t\t\t\tPhase:        core.WorkflowExecution_RUNNING.String(),\n\t\t\t\tClosure:      closureBytes,\n\t\t\t\tLaunchPlanID: uint(1),\n\t\t\t\tWorkflowID:   uint(2),\n\t\t\t\tStartedAt:    &occurredAt,\n\t\t\t}, nil\n\t\t},\n\t)\n\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &defaultTestExecutor)\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\toccurredAtTimestamp, _ := ptypes.TimestampProto(occurredAt)\n\tresp, err := execManager.CreateWorkflowEvent(context.Background(), admin.WorkflowExecutionEventRequest{\n\t\tRequestId: \"1\",\n\t\tEvent: &event.WorkflowExecutionEvent{\n\t\t\tExecutionId: &executionIdentifier,\n\t\t\tOccurredAt:  occurredAtTimestamp,\n\t\t\tPhase:       core.WorkflowExecution_RUNNING,\n\t\t},\n\t})\n\tassert.NotNil(t, err)\n\tadminError := err.(flyteAdminErrors.FlyteAdminError)\n\tassert.Equal(t, adminError.Code(), codes.AlreadyExists)\n\tassert.Nil(t, resp)\n}\n\nfunc TestCreateWorkflowEvent_InvalidPhaseChange(t *testing.T) {\n\trepository := repositoryMocks.NewMockRepository()\n\toccurredAt := time.Now().UTC()\n\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetGetCallback(\n\t\tfunc(ctx context.Context, input interfaces.Identifier) (models.Execution, error) {\n\t\t\treturn models.Execution{\n\t\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\t\tProject: \"project\",\n\t\t\t\t\tDomain:  \"domain\",\n\t\t\t\t\tName:    \"name\",\n\t\t\t\t},\n\t\t\t\tBaseModel: models.BaseModel{\n\t\t\t\t\tID: uint(8),\n\t\t\t\t},\n\t\t\t\tSpec:         getExpectedSpecBytes(),\n\t\t\t\tPhase:        core.WorkflowExecution_SUCCEEDED.String(),\n\t\t\t\tClosure:      closureBytes,\n\t\t\t\tLaunchPlanID: uint(1),\n\t\t\t\tWorkflowID:   uint(2),\n\t\t\t\tStartedAt:    &occurredAt,\n\t\t\t}, nil\n\t\t},\n\t)\n\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &defaultTestExecutor)\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\toccurredAtTimestamp, _ := ptypes.TimestampProto(occurredAt)\n\tresp, err := execManager.CreateWorkflowEvent(context.Background(), admin.WorkflowExecutionEventRequest{\n\t\tRequestId: \"1\",\n\t\tEvent: &event.WorkflowExecutionEvent{\n\t\t\tExecutionId: &executionIdentifier,\n\t\t\tOccurredAt:  occurredAtTimestamp,\n\t\t\tPhase:       core.WorkflowExecution_RUNNING,\n\t\t},\n\t})\n\tassert.NotNil(t, err)\n\tadminError := err.(flyteAdminErrors.FlyteAdminError)\n\tassert.Equal(t, adminError.Code(), codes.FailedPrecondition)\n\tassert.Nil(t, resp)\n\tdetails, ok := adminError.GRPCStatus().Details()[0].(*admin.EventFailureReason)\n\tassert.True(t, ok)\n\t_, ok = details.GetReason().(*admin.EventFailureReason_AlreadyInTerminalState)\n\tassert.True(t, ok)\n}\n\nfunc TestCreateWorkflowEvent_ClusterReassignmentOnQueued(t *testing.T) {\n\trepository := repositoryMocks.NewMockRepository()\n\toccurredAt := time.Now().UTC()\n\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetGetCallback(\n\t\tfunc(ctx context.Context, input interfaces.Identifier) (models.Execution, error) {\n\t\t\treturn models.Execution{\n\t\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\t\tProject: \"project\",\n\t\t\t\t\tDomain:  \"domain\",\n\t\t\t\t\tName:    \"name\",\n\t\t\t\t},\n\t\t\t\tBaseModel: models.BaseModel{\n\t\t\t\t\tID: uint(8),\n\t\t\t\t},\n\t\t\t\tSpec:         getExpectedSpecBytes(),\n\t\t\t\tPhase:        core.WorkflowExecution_UNDEFINED.String(),\n\t\t\t\tClosure:      closureBytes,\n\t\t\t\tLaunchPlanID: uint(1),\n\t\t\t\tWorkflowID:   uint(2),\n\t\t\t\tStartedAt:    &occurredAt,\n\t\t\t}, nil\n\t\t},\n\t)\n\tnewCluster := \"C2\"\n\tupdateExecutionFunc := func(\n\t\tcontext context.Context, execution models.Execution) error {\n\t\tassert.Equal(t, core.WorkflowExecution_QUEUED.String(), execution.Phase)\n\t\tassert.Equal(t, newCluster, execution.Cluster)\n\t\treturn nil\n\t}\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetUpdateCallback(updateExecutionFunc)\n\n\toccurredAtTimestamp, _ := ptypes.TimestampProto(occurredAt)\n\tmockDbEventWriter := &eventWriterMocks.WorkflowExecutionEventWriter{}\n\trequest := admin.WorkflowExecutionEventRequest{\n\t\tRequestId: \"1\",\n\t\tEvent: &event.WorkflowExecutionEvent{\n\t\t\tExecutionId: &executionIdentifier,\n\t\t\tOccurredAt:  occurredAtTimestamp,\n\t\t\tPhase:       core.WorkflowExecution_QUEUED,\n\t\t\tProducerId:  newCluster,\n\t\t},\n\t}\n\tmockDbEventWriter.On(\"Write\", request)\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &defaultTestExecutor)\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, &mockPublisher, &mockPublisher, mockDbEventWriter)\n\n\tresp, err := execManager.CreateWorkflowEvent(context.Background(), request)\n\tassert.Nil(t, err)\n\tassert.NotNil(t, resp)\n}\n\nfunc TestCreateWorkflowEvent_InvalidEvent(t *testing.T) {\n\trepository := repositoryMocks.NewMockRepository()\n\tstartTime := time.Now()\n\texecutionGetFunc := makeExecutionGetFunc(t, closureBytes, &startTime)\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetGetCallback(executionGetFunc)\n\texecutionError := core.ExecutionError{\n\t\tCode:    \"foo\",\n\t\tMessage: \"bar baz\",\n\t}\n\tupdateExecutionFunc := func(\n\t\tcontext context.Context, execution models.Execution) error {\n\t\treturn nil\n\t}\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetUpdateCallback(updateExecutionFunc)\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &defaultTestExecutor)\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\tresp, err := execManager.CreateWorkflowEvent(context.Background(), admin.WorkflowExecutionEventRequest{\n\t\tRequestId: \"1\",\n\t\tEvent: &event.WorkflowExecutionEvent{\n\t\t\tExecutionId: &executionIdentifier,\n\t\t\tPhase:       core.WorkflowExecution_FAILED,\n\t\t\tOutputResult: &event.WorkflowExecutionEvent_Error{\n\t\t\t\tError: &executionError,\n\t\t\t},\n\t\t},\n\t})\n\tassert.NotNil(t, err)\n\tassert.Nil(t, resp)\n}\n\nfunc TestCreateWorkflowEvent_UpdateModelError(t *testing.T) {\n\trepository := repositoryMocks.NewMockRepository()\n\tstartTime := time.Now()\n\texecutionGetFunc := makeExecutionGetFunc(t, []byte(\"invalid serialized closure\"), &startTime)\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetGetCallback(executionGetFunc)\n\tduration := time.Second\n\tendTime := startTime.Add(duration)\n\toccurredAt, _ := ptypes.TimestampProto(endTime)\n\texecutionError := core.ExecutionError{\n\t\tCode:    \"foo\",\n\t\tMessage: \"bar baz\",\n\t}\n\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &defaultTestExecutor)\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\tresp, err := execManager.CreateWorkflowEvent(context.Background(), admin.WorkflowExecutionEventRequest{\n\t\tRequestId: \"1\",\n\t\tEvent: &event.WorkflowExecutionEvent{\n\t\t\tExecutionId: &executionIdentifier,\n\t\t\tOccurredAt:  occurredAt,\n\t\t\tPhase:       core.WorkflowExecution_FAILED,\n\t\t\tOutputResult: &event.WorkflowExecutionEvent_Error{\n\t\t\t\tError: &executionError,\n\t\t\t},\n\t\t\tProducerId: testCluster,\n\t\t},\n\t})\n\tassert.Nil(t, resp)\n\tassert.Equal(t, codes.Internal, err.(flyteAdminErrors.FlyteAdminError).Code())\n}\n\nfunc TestCreateWorkflowEvent_DatabaseGetError(t *testing.T) {\n\trepository := repositoryMocks.NewMockRepository()\n\tstartTime := time.Now()\n\n\texpectedErr := errors.New(\"expected error\")\n\texecutionGetFunc := func(ctx context.Context, input interfaces.Identifier) (models.Execution, error) {\n\t\treturn models.Execution{}, expectedErr\n\t}\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetGetCallback(executionGetFunc)\n\tduration := time.Second\n\tendTime := startTime.Add(duration)\n\toccurredAt, _ := ptypes.TimestampProto(endTime)\n\texecutionError := core.ExecutionError{\n\t\tCode:    \"foo\",\n\t\tMessage: \"bar baz\",\n\t}\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &defaultTestExecutor)\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\tresp, err := execManager.CreateWorkflowEvent(context.Background(), admin.WorkflowExecutionEventRequest{\n\t\tRequestId: \"1\",\n\t\tEvent: &event.WorkflowExecutionEvent{\n\t\t\tExecutionId: &executionIdentifier,\n\t\t\tOccurredAt:  occurredAt,\n\t\t\tPhase:       core.WorkflowExecution_FAILED,\n\t\t\tOutputResult: &event.WorkflowExecutionEvent_Error{\n\t\t\t\tError: &executionError,\n\t\t\t},\n\t\t},\n\t})\n\tassert.Nil(t, resp)\n\tassert.EqualError(t, expectedErr, err.Error())\n}\n\nfunc TestCreateWorkflowEvent_DatabaseUpdateError(t *testing.T) {\n\trepository := repositoryMocks.NewMockRepository()\n\tstartTime := time.Now()\n\texecutionGetFunc := makeExecutionGetFunc(t, closureBytes, &startTime)\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetGetCallback(executionGetFunc)\n\tduration := time.Second\n\tendTime := startTime.Add(duration)\n\toccurredAt, _ := ptypes.TimestampProto(endTime)\n\texecutionError := core.ExecutionError{\n\t\tCode:    \"foo\",\n\t\tMessage: \"bar baz\",\n\t}\n\texpectedErr := errors.New(\"expected error\")\n\tupdateExecutionFunc := func(\n\t\tcontext context.Context, execution models.Execution) error {\n\t\treturn expectedErr\n\t}\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetUpdateCallback(updateExecutionFunc)\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &defaultTestExecutor)\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\tresp, err := execManager.CreateWorkflowEvent(context.Background(), admin.WorkflowExecutionEventRequest{\n\t\tRequestId: \"1\",\n\t\tEvent: &event.WorkflowExecutionEvent{\n\t\t\tExecutionId: &executionIdentifier,\n\t\t\tOccurredAt:  occurredAt,\n\t\t\tPhase:       core.WorkflowExecution_FAILED,\n\t\t\tOutputResult: &event.WorkflowExecutionEvent_Error{\n\t\t\t\tError: &executionError,\n\t\t\t},\n\t\t\tProducerId: testCluster,\n\t\t},\n\t})\n\tassert.Nil(t, resp)\n\tassert.EqualError(t, expectedErr, err.Error())\n}\n\nfunc TestCreateWorkflowEvent_IncompatibleCluster(t *testing.T) {\n\trepository := repositoryMocks.NewMockRepository()\n\toccurredAt := time.Now().UTC()\n\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetGetCallback(\n\t\tfunc(ctx context.Context, input interfaces.Identifier) (models.Execution, error) {\n\t\t\treturn models.Execution{\n\t\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\t\tProject: \"project\",\n\t\t\t\t\tDomain:  \"domain\",\n\t\t\t\t\tName:    \"name\",\n\t\t\t\t},\n\t\t\t\tBaseModel: models.BaseModel{\n\t\t\t\t\tID: uint(8),\n\t\t\t\t},\n\t\t\t\tSpec:         getExpectedSpecBytes(),\n\t\t\t\tPhase:        core.WorkflowExecution_RUNNING.String(),\n\t\t\t\tClosure:      closureBytes,\n\t\t\t\tLaunchPlanID: uint(1),\n\t\t\t\tWorkflowID:   uint(2),\n\t\t\t\tStartedAt:    &occurredAt,\n\t\t\t\tCluster:      testCluster,\n\t\t\t}, nil\n\t\t},\n\t)\n\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &defaultTestExecutor)\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\toccurredAtTimestamp, _ := ptypes.TimestampProto(occurredAt)\n\tresp, err := execManager.CreateWorkflowEvent(context.Background(), admin.WorkflowExecutionEventRequest{\n\t\tRequestId: \"1\",\n\t\tEvent: &event.WorkflowExecutionEvent{\n\t\t\tExecutionId: &executionIdentifier,\n\t\t\tOccurredAt:  occurredAtTimestamp,\n\t\t\tPhase:       core.WorkflowExecution_ABORTING,\n\t\t\tProducerId:  \"C2\",\n\t\t},\n\t})\n\tassert.NotNil(t, err)\n\tadminError := err.(flyteAdminErrors.FlyteAdminError)\n\tassert.Equal(t, adminError.Code(), codes.FailedPrecondition)\n\ts, ok := status.FromError(err)\n\tassert.True(t, ok)\n\tvar seenIncompatibleClusterErr bool\n\tfor _, detail := range s.Details() {\n\t\tfailureReason, ok := detail.(*admin.EventFailureReason)\n\t\tif ok {\n\t\t\tif failureReason.GetIncompatibleCluster() != nil {\n\t\t\t\tseenIncompatibleClusterErr = true\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t}\n\tassert.True(t, seenIncompatibleClusterErr)\n\tassert.Nil(t, resp)\n}\n\nfunc TestGetExecution(t *testing.T) {\n\trepository := repositoryMocks.NewMockRepository()\n\tstartedAt := time.Date(2018, 8, 30, 0, 0, 0, 0, time.UTC)\n\texecutionGetFunc := func(ctx context.Context, input interfaces.Identifier) (models.Execution, error) {\n\t\tassert.Equal(t, \"project\", input.Project)\n\t\tassert.Equal(t, \"domain\", input.Domain)\n\t\tassert.Equal(t, \"name\", input.Name)\n\t\treturn models.Execution{\n\t\t\tBaseModel: models.BaseModel{\n\t\t\t\tCreatedAt: testutils.MockCreatedAtValue,\n\t\t\t},\n\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\tProject: \"project\",\n\t\t\t\tDomain:  \"domain\",\n\t\t\t\tName:    \"name\",\n\t\t\t},\n\t\t\tSpec:         getExpectedSpecBytes(),\n\t\t\tPhase:        phase,\n\t\t\tClosure:      closureBytes,\n\t\t\tLaunchPlanID: uint(1),\n\t\t\tWorkflowID:   uint(2),\n\t\t\tStartedAt:    &startedAt,\n\t\t\t// TODO: Input uri\n\t\t}, nil\n\t}\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetGetCallback(executionGetFunc)\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &defaultTestExecutor)\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\texecution, err := execManager.GetExecution(context.Background(), admin.WorkflowExecutionGetRequest{\n\t\tId: &executionIdentifier,\n\t})\n\tassert.NoError(t, err)\n\tassert.True(t, proto.Equal(&executionIdentifier, execution.Id))\n\tassert.True(t, proto.Equal(getExpectedSpec(), execution.Spec))\n\tassert.True(t, proto.Equal(&closure, execution.Closure))\n}\n\nfunc TestGetExecution_DatabaseError(t *testing.T) {\n\trepository := repositoryMocks.NewMockRepository()\n\texpectedErr := errors.New(\"expected error\")\n\n\texecutionGetFunc := func(ctx context.Context, input interfaces.Identifier) (models.Execution, error) {\n\t\tassert.Equal(t, \"project\", input.Project)\n\t\tassert.Equal(t, \"domain\", input.Domain)\n\t\tassert.Equal(t, \"name\", input.Name)\n\t\treturn models.Execution{}, expectedErr\n\t}\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetGetCallback(executionGetFunc)\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &defaultTestExecutor)\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\texecution, err := execManager.GetExecution(context.Background(), admin.WorkflowExecutionGetRequest{\n\t\tId: &executionIdentifier,\n\t})\n\tassert.Nil(t, execution)\n\tassert.Equal(t, expectedErr, err)\n}\n\nfunc TestGetExecution_TransformerError(t *testing.T) {\n\trepository := repositoryMocks.NewMockRepository()\n\tstartedAt := time.Date(2018, 8, 30, 0, 0, 0, 0, time.UTC)\n\texecutionGetFunc := func(ctx context.Context, input interfaces.Identifier) (models.Execution, error) {\n\t\tassert.Equal(t, \"project\", input.Project)\n\t\tassert.Equal(t, \"domain\", input.Domain)\n\t\tassert.Equal(t, \"name\", input.Name)\n\t\treturn models.Execution{\n\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\tProject: \"project\",\n\t\t\t\tDomain:  \"domain\",\n\t\t\t\tName:    \"name\",\n\t\t\t},\n\t\t\tSpec:         []byte(\"invalid spec\"),\n\t\t\tPhase:        phase,\n\t\t\tClosure:      closureBytes,\n\t\t\tLaunchPlanID: uint(1),\n\t\t\tWorkflowID:   uint(2),\n\t\t\tStartedAt:    &startedAt,\n\t\t}, nil\n\t}\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetGetCallback(executionGetFunc)\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &defaultTestExecutor)\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\texecution, err := execManager.GetExecution(context.Background(), admin.WorkflowExecutionGetRequest{\n\t\tId: &executionIdentifier,\n\t})\n\tassert.Nil(t, execution)\n\tassert.Equal(t, codes.Internal, err.(flyteAdminErrors.FlyteAdminError).Code())\n}\n\nfunc TestUpdateExecution(t *testing.T) {\n\tt.Run(\"invalid execution identifier\", func(t *testing.T) {\n\t\trepository := repositoryMocks.NewMockRepository()\n\t\tr := plugins.NewRegistry()\n\t\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &defaultTestExecutor)\n\t\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\t\t_, err := execManager.UpdateExecution(context.Background(), admin.ExecutionUpdateRequest{\n\t\t\tId: &core.WorkflowExecutionIdentifier{\n\t\t\t\tProject: \"project\",\n\t\t\t\tDomain:  \"domain\",\n\t\t\t},\n\t\t}, time.Now())\n\t\tassert.Error(t, err)\n\t})\n\n\tt.Run(\"empty status passed\", func(t *testing.T) {\n\t\trepository := repositoryMocks.NewMockRepository()\n\t\tupdateExecFuncCalled := false\n\t\tupdateExecFunc := func(ctx context.Context, execModel models.Execution) error {\n\t\t\tstateInt := int32(admin.ExecutionState_EXECUTION_ACTIVE)\n\t\t\tassert.Equal(t, stateInt, *execModel.State)\n\t\t\tupdateExecFuncCalled = true\n\t\t\treturn nil\n\t\t}\n\t\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetUpdateCallback(updateExecFunc)\n\t\tr := plugins.NewRegistry()\n\t\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &defaultTestExecutor)\n\t\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\t\tupdateResponse, err := execManager.UpdateExecution(context.Background(), admin.ExecutionUpdateRequest{\n\t\t\tId: &executionIdentifier,\n\t\t}, time.Now())\n\t\tassert.NoError(t, err)\n\t\tassert.NotNil(t, updateResponse)\n\t\tassert.True(t, updateExecFuncCalled)\n\t})\n\n\tt.Run(\"archive status passed\", func(t *testing.T) {\n\t\trepository := repositoryMocks.NewMockRepository()\n\t\tupdateExecFuncCalled := false\n\t\tupdateExecFunc := func(ctx context.Context, execModel models.Execution) error {\n\t\t\tstateInt := int32(admin.ExecutionState_EXECUTION_ARCHIVED)\n\t\t\tassert.Equal(t, stateInt, *execModel.State)\n\t\t\tupdateExecFuncCalled = true\n\t\t\treturn nil\n\t\t}\n\t\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetUpdateCallback(updateExecFunc)\n\t\tr := plugins.NewRegistry()\n\t\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &defaultTestExecutor)\n\t\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\t\tupdateResponse, err := execManager.UpdateExecution(context.Background(), admin.ExecutionUpdateRequest{\n\t\t\tId:    &executionIdentifier,\n\t\t\tState: admin.ExecutionState_EXECUTION_ARCHIVED,\n\t\t}, time.Now())\n\t\tassert.NoError(t, err)\n\t\tassert.NotNil(t, updateResponse)\n\t\tassert.True(t, updateExecFuncCalled)\n\t})\n\n\tt.Run(\"update error\", func(t *testing.T) {\n\t\trepository := repositoryMocks.NewMockRepository()\n\t\tupdateExecFunc := func(ctx context.Context, execModel models.Execution) error {\n\t\t\treturn fmt.Errorf(\"some db error\")\n\t\t}\n\t\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetUpdateCallback(updateExecFunc)\n\t\tr := plugins.NewRegistry()\n\t\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &defaultTestExecutor)\n\t\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\t\t_, err := execManager.UpdateExecution(context.Background(), admin.ExecutionUpdateRequest{\n\t\t\tId:    &executionIdentifier,\n\t\t\tState: admin.ExecutionState_EXECUTION_ARCHIVED,\n\t\t}, time.Now())\n\t\tassert.Error(t, err)\n\t\tassert.Equal(t, \"some db error\", err.Error())\n\t})\n\n\tt.Run(\"get execution error\", func(t *testing.T) {\n\t\trepository := repositoryMocks.NewMockRepository()\n\t\tgetExecFunc := func(ctx context.Context, input interfaces.Identifier) (models.Execution, error) {\n\t\t\treturn models.Execution{}, fmt.Errorf(\"some db error\")\n\t\t}\n\t\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetGetCallback(getExecFunc)\n\t\tr := plugins.NewRegistry()\n\t\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &defaultTestExecutor)\n\t\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\t\t_, err := execManager.UpdateExecution(context.Background(), admin.ExecutionUpdateRequest{\n\t\t\tId:    &executionIdentifier,\n\t\t\tState: admin.ExecutionState_EXECUTION_ARCHIVED,\n\t\t}, time.Now())\n\t\tassert.Error(t, err)\n\t\tassert.Equal(t, \"some db error\", err.Error())\n\t})\n}\n\nfunc TestListExecutions(t *testing.T) {\n\trepository := repositoryMocks.NewMockRepository()\n\texecutionListFunc := func(\n\t\tctx context.Context, input interfaces.ListResourceInput) (interfaces.ExecutionCollectionOutput, error) {\n\t\tvar projectFilter, domainFilter, nameFilter bool\n\t\tfor _, filter := range input.InlineFilters {\n\t\t\tassert.Equal(t, common.Execution, filter.GetEntity())\n\t\t\tqueryExpr, _ := filter.GetGormQueryExpr()\n\t\t\tif queryExpr.Args == projectValue && queryExpr.Query == \"execution_project = ?\" {\n\t\t\t\tprojectFilter = true\n\t\t\t}\n\t\t\tif queryExpr.Args == domainValue && queryExpr.Query == \"execution_domain = ?\" {\n\t\t\t\tdomainFilter = true\n\t\t\t}\n\t\t\tif queryExpr.Args == nameValue && queryExpr.Query == \"execution_name = ?\" {\n\t\t\t\tnameFilter = true\n\t\t\t}\n\t\t}\n\t\tassert.True(t, projectFilter, \"Missing project equality filter\")\n\t\tassert.True(t, domainFilter, \"Missing domain equality filter\")\n\t\tassert.False(t, nameFilter, \"Included name equality filter\")\n\t\tassert.Equal(t, limit, input.Limit)\n\t\tassert.Equal(t, \"execution_domain asc\", input.SortParameter.GetGormOrderExpr())\n\t\tassert.Equal(t, 2, input.Offset)\n\t\tassert.EqualValues(t, map[common.Entity]bool{\n\t\t\tcommon.Execution: true,\n\t\t}, input.JoinTableEntities)\n\t\treturn interfaces.ExecutionCollectionOutput{\n\t\t\tExecutions: []models.Execution{\n\t\t\t\t{\n\t\t\t\t\tBaseModel: models.BaseModel{\n\t\t\t\t\t\tCreatedAt: testutils.MockCreatedAtValue,\n\t\t\t\t\t},\n\t\t\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\t\t\tProject: projectValue,\n\t\t\t\t\t\tDomain:  domainValue,\n\t\t\t\t\t\tName:    \"my awesome execution\",\n\t\t\t\t\t},\n\t\t\t\t\tSpec:    getExpectedSpecBytes(),\n\t\t\t\t\tClosure: closureBytes,\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\tBaseModel: models.BaseModel{\n\t\t\t\t\t\tCreatedAt: testutils.MockCreatedAtValue,\n\t\t\t\t\t},\n\t\t\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\t\t\tProject: projectValue,\n\t\t\t\t\t\tDomain:  domainValue,\n\t\t\t\t\t\tName:    \"my other execution\",\n\t\t\t\t\t},\n\t\t\t\t\tPhase:   core.WorkflowExecution_SUCCEEDED.String(),\n\t\t\t\t\tSpec:    getExpectedSpecBytes(),\n\t\t\t\t\tClosure: closureBytes,\n\t\t\t\t},\n\t\t\t},\n\t\t}, nil\n\t}\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetListCallback(executionListFunc)\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &defaultTestExecutor)\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\n\texecutionList, err := execManager.ListExecutions(context.Background(), admin.ResourceListRequest{\n\t\tId: &admin.NamedEntityIdentifier{\n\t\t\tProject: projectValue,\n\t\t\tDomain:  domainValue,\n\t\t},\n\t\tLimit: limit,\n\t\tSortBy: &admin.Sort{\n\t\t\tDirection: admin.Sort_ASCENDING,\n\t\t\tKey:       \"execution_domain\",\n\t\t},\n\t\tToken: \"2\",\n\t})\n\tassert.NoError(t, err)\n\tassert.NotNil(t, executionList)\n\tassert.Len(t, executionList.Executions, 2)\n\n\tfor idx, execution := range executionList.Executions {\n\t\tassert.Equal(t, projectValue, execution.Id.Project)\n\t\tassert.Equal(t, domainValue, execution.Id.Domain)\n\t\tif idx == 0 {\n\t\t\tassert.Equal(t, \"my awesome execution\", execution.Id.Name)\n\t\t}\n\t\tassert.True(t, proto.Equal(getExpectedSpec(), execution.Spec))\n\t\tassert.True(t, proto.Equal(&closure, execution.Closure))\n\t}\n\tassert.Empty(t, executionList.Token)\n}\n\nfunc TestListExecutions_MissingParameters(t *testing.T) {\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &defaultTestExecutor)\n\texecManager := NewExecutionManager(repositoryMocks.NewMockRepository(), r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\t_, err := execManager.ListExecutions(context.Background(), admin.ResourceListRequest{\n\t\tId: &admin.NamedEntityIdentifier{\n\t\t\tDomain: domainValue,\n\t\t},\n\t\tLimit: limit,\n\t})\n\tassert.Error(t, err)\n\tassert.Equal(t, codes.InvalidArgument, err.(flyteAdminErrors.FlyteAdminError).Code())\n\n\t_, err = execManager.ListExecutions(context.Background(), admin.ResourceListRequest{\n\t\tId: &admin.NamedEntityIdentifier{\n\t\t\tProject: projectValue,\n\t\t},\n\t\tLimit: limit,\n\t})\n\tassert.Error(t, err)\n\tassert.Equal(t, codes.InvalidArgument, err.(flyteAdminErrors.FlyteAdminError).Code())\n\n\t_, err = execManager.ListExecutions(context.Background(), admin.ResourceListRequest{\n\t\tId: &admin.NamedEntityIdentifier{\n\t\t\tProject: projectValue,\n\t\t\tDomain:  domainValue,\n\t\t},\n\t})\n\tassert.Error(t, err)\n\tassert.Equal(t, codes.InvalidArgument, err.(flyteAdminErrors.FlyteAdminError).Code())\n}\n\nfunc TestListExecutions_DatabaseError(t *testing.T) {\n\trepository := repositoryMocks.NewMockRepository()\n\texpectedErr := errors.New(\"expected error\")\n\texecutionListFunc := func(\n\t\tctx context.Context, input interfaces.ListResourceInput) (interfaces.ExecutionCollectionOutput, error) {\n\t\treturn interfaces.ExecutionCollectionOutput{}, expectedErr\n\t}\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetListCallback(executionListFunc)\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &defaultTestExecutor)\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\t_, err := execManager.ListExecutions(context.Background(), admin.ResourceListRequest{\n\t\tId: &admin.NamedEntityIdentifier{\n\t\t\tProject: projectValue,\n\t\t\tDomain:  domainValue,\n\t\t\tName:    nameValue,\n\t\t},\n\t\tLimit: limit,\n\t})\n\tassert.EqualError(t, err, expectedErr.Error())\n}\n\nfunc TestListExecutions_TransformerError(t *testing.T) {\n\trepository := repositoryMocks.NewMockRepository()\n\texecutionListFunc := func(\n\t\tctx context.Context, input interfaces.ListResourceInput) (interfaces.ExecutionCollectionOutput, error) {\n\t\treturn interfaces.ExecutionCollectionOutput{\n\t\t\tExecutions: []models.Execution{\n\t\t\t\t{\n\t\t\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\t\t\tProject: projectValue,\n\t\t\t\t\t\tDomain:  domainValue,\n\t\t\t\t\t\tName:    \"my awesome execution\",\n\t\t\t\t\t},\n\t\t\t\t\tSpec:    []byte(\"I am invalid\"),\n\t\t\t\t\tClosure: closureBytes,\n\t\t\t\t},\n\t\t\t},\n\t\t}, nil\n\t}\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetListCallback(executionListFunc)\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &defaultTestExecutor)\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\n\texecutionList, err := execManager.ListExecutions(context.Background(), admin.ResourceListRequest{\n\t\tId: &admin.NamedEntityIdentifier{\n\t\t\tProject: projectValue,\n\t\t\tDomain:  domainValue,\n\t\t},\n\t\tLimit: limit,\n\t})\n\tassert.EqualError(t, err, \"failed to unmarshal spec\")\n\tassert.Nil(t, executionList)\n}\n\nfunc TestExecutionManager_PublishNotifications(t *testing.T) {\n\trepository := repositoryMocks.NewMockRepository()\n\tqueue := executions.NewQueueAllocator(getMockExecutionsConfigProvider(), repository)\n\n\tmockApplicationConfig := runtimeMocks.MockApplicationProvider{}\n\tmockApplicationConfig.SetNotificationsConfig(runtimeInterfaces.NotificationsConfig{\n\t\tNotificationsEmailerConfig: runtimeInterfaces.NotificationsEmailerConfig{\n\t\t\tBody: \"http://example.com/console/projects/%s/domains/%s/executions/%s\",\n\t\t},\n\t})\n\tmockRuntime := runtimeMocks.NewMockConfigurationProvider(\n\t\t&mockApplicationConfig,\n\t\truntimeMocks.NewMockQueueConfigurationProvider(\n\t\t\t[]runtimeInterfaces.ExecutionQueue{}, []runtimeInterfaces.WorkflowConfig{}),\n\t\tnil, nil, nil, nil)\n\n\tvar myExecManager = &ExecutionManager{\n\t\tdb:                 repository,\n\t\tconfig:             mockRuntime,\n\t\tstorageClient:      getMockStorageForExecTest(context.Background()),\n\t\tqueueAllocator:     queue,\n\t\t_clock:             clock.New(),\n\t\tsystemMetrics:      newExecutionSystemMetrics(mockScope.NewTestScope()),\n\t\tnotificationClient: &mockPublisher,\n\t}\n\t// Currently this doesn't do anything special as the code to invoke pushing to SNS isn't enabled yet.\n\t// This sets up the skeleton for it and appeases the go lint overlords.\n\tworkflowRequest := admin.WorkflowExecutionEventRequest{\n\t\tEvent: &event.WorkflowExecutionEvent{\n\t\t\tPhase: core.WorkflowExecution_FAILED,\n\t\t\tOutputResult: &event.WorkflowExecutionEvent_Error{\n\t\t\t\tError: &core.ExecutionError{\n\t\t\t\t\tCode:    \"CodeBad\",\n\t\t\t\t\tMessage: \"oopsie my bad\",\n\t\t\t\t},\n\t\t\t},\n\t\t\tExecutionId: &executionIdentifier,\n\t\t},\n\t}\n\tvar execClosure = admin.ExecutionClosure{\n\t\tNotifications: testutils.GetExecutionRequest().Spec.GetNotifications().Notifications,\n\t\tWorkflowId: &core.Identifier{\n\t\t\tResourceType: core.ResourceType_WORKFLOW,\n\t\t\tProject:      \"wf_project\",\n\t\t\tDomain:       \"wf_domain\",\n\t\t\tName:         \"wf_name\",\n\t\t\tVersion:      \"wf_version\",\n\t\t},\n\t}\n\tvar extraNotifications = []*admin.Notification{\n\t\t{\n\t\t\tPhases: []core.WorkflowExecution_Phase{\n\t\t\t\tcore.WorkflowExecution_FAILED,\n\t\t\t},\n\t\t\tType: &admin.Notification_PagerDuty{\n\t\t\t\tPagerDuty: &admin.PagerDutyNotification{\n\t\t\t\t\tRecipientsEmail: []string{\n\t\t\t\t\t\t\"pagerduty@example.com\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tPhases: []core.WorkflowExecution_Phase{\n\t\t\t\tcore.WorkflowExecution_SUCCEEDED,\n\t\t\t\tcore.WorkflowExecution_FAILED,\n\t\t\t},\n\t\t\tType: &admin.Notification_Email{\n\t\t\t\tEmail: &admin.EmailNotification{\n\t\t\t\t\tRecipientsEmail: []string{\n\t\t\t\t\t\t\"email@example.com\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t}\n\texecClosure.Notifications = append(execClosure.Notifications, extraNotifications[0])\n\texecClosure.Notifications = append(execClosure.Notifications, extraNotifications[1])\n\n\texecClosureBytes, _ := proto.Marshal(&execClosure)\n\texecutionModel := models.Execution{\n\t\tExecutionKey: models.ExecutionKey{\n\t\t\tProject: \"project\",\n\t\t\tDomain:  \"domain\",\n\t\t\tName:    \"name\",\n\t\t},\n\t\tPhase:        core.WorkflowExecution_FAILED.String(),\n\t\tLaunchPlanID: uint(1),\n\t\tWorkflowID:   uint(2),\n\t\tClosure:      execClosureBytes,\n\t\tSpec:         getExpectedSpecBytes(),\n\t}\n\tassert.Nil(t, myExecManager.publishNotifications(context.Background(), workflowRequest, executionModel))\n}\n\nfunc TestExecutionManager_PublishNotificationsTransformError(t *testing.T) {\n\trepository := repositoryMocks.NewMockRepository()\n\tqueue := executions.NewQueueAllocator(getMockExecutionsConfigProvider(), repository)\n\tvar execManager = &ExecutionManager{\n\t\tdb:                 repository,\n\t\tconfig:             getMockExecutionsConfigProvider(),\n\t\tstorageClient:      getMockStorageForExecTest(context.Background()),\n\t\tqueueAllocator:     queue,\n\t\t_clock:             clock.New(),\n\t\tsystemMetrics:      newExecutionSystemMetrics(mockScope.NewTestScope()),\n\t\tnotificationClient: &mockPublisher,\n\t}\n\n\tworkflowRequest := admin.WorkflowExecutionEventRequest{\n\t\tEvent: &event.WorkflowExecutionEvent{\n\t\t\tPhase: core.WorkflowExecution_FAILED,\n\t\t\tOutputResult: &event.WorkflowExecutionEvent_Error{\n\t\t\t\tError: &core.ExecutionError{\n\t\t\t\t\tCode:    \"CodeBad\",\n\t\t\t\t\tMessage: \"oopsie my bad\",\n\t\t\t\t},\n\t\t\t},\n\t\t\tExecutionId: &executionIdentifier,\n\t\t},\n\t}\n\t// Ensure that an error is thrown when transforming an incorrect models.Execution\n\texecutionModel := models.Execution{\n\t\tExecutionKey: models.ExecutionKey{\n\t\t\tProject: \"project\",\n\t\t\tDomain:  \"domain\",\n\t\t\tName:    \"name\",\n\t\t},\n\t\tPhase:        core.WorkflowExecution_FAILED.String(),\n\t\tLaunchPlanID: uint(1),\n\t\tWorkflowID:   uint(2),\n\t\tSpec:         []byte(\"I am invalid\"),\n\t}\n\tassert.Error(t, execManager.publishNotifications(context.Background(), workflowRequest, executionModel))\n}\n\nfunc TestExecutionManager_TestExecutionManager_PublishNotificationsTransformError(t *testing.T) {\n\trepository := repositoryMocks.NewMockRepository()\n\tqueue := executions.NewQueueAllocator(getMockExecutionsConfigProvider(), repository)\n\tpublishFunc := func(ctx context.Context, key string, msg proto.Message) error {\n\t\treturn errors.New(\"error publishing message\")\n\t}\n\n\tmockPublisher.SetPublishCallback(publishFunc)\n\tmockApplicationConfig := runtimeMocks.MockApplicationProvider{}\n\tmockApplicationConfig.SetNotificationsConfig(runtimeInterfaces.NotificationsConfig{\n\t\tNotificationsEmailerConfig: runtimeInterfaces.NotificationsEmailerConfig{\n\t\t\tBody: \"http://example.com/console/projects/%s/domains/%s/executions/%s\",\n\t\t},\n\t})\n\tmockRuntime := runtimeMocks.NewMockConfigurationProvider(\n\t\t&mockApplicationConfig,\n\t\truntimeMocks.NewMockQueueConfigurationProvider(\n\t\t\t[]runtimeInterfaces.ExecutionQueue{}, []runtimeInterfaces.WorkflowConfig{}),\n\t\tnil, nil, nil, nil)\n\n\tvar myExecManager = &ExecutionManager{\n\t\tdb:                 repository,\n\t\tconfig:             mockRuntime,\n\t\tstorageClient:      getMockStorageForExecTest(context.Background()),\n\t\tqueueAllocator:     queue,\n\t\t_clock:             clock.New(),\n\t\tsystemMetrics:      newExecutionSystemMetrics(mockScope.NewTestScope()),\n\t\tnotificationClient: &mockPublisher,\n\t}\n\t// Currently this doesn't do anything special as the code to invoke pushing to SNS isn't enabled yet.\n\t// This sets up the skeleton for it and appeases the go lint overlords.\n\tworkflowRequest := admin.WorkflowExecutionEventRequest{\n\t\tEvent: &event.WorkflowExecutionEvent{\n\t\t\tPhase: core.WorkflowExecution_FAILED,\n\t\t\tOutputResult: &event.WorkflowExecutionEvent_Error{\n\t\t\t\tError: &core.ExecutionError{\n\t\t\t\t\tCode:    \"CodeBad\",\n\t\t\t\t\tMessage: \"oopsie my bad\",\n\t\t\t\t},\n\t\t\t},\n\t\t\tExecutionId: &executionIdentifier,\n\t\t},\n\t}\n\tvar execClosure = admin.ExecutionClosure{\n\t\tNotifications: testutils.GetExecutionRequest().Spec.GetNotifications().Notifications,\n\t\tWorkflowId: &core.Identifier{\n\t\t\tResourceType: core.ResourceType_WORKFLOW,\n\t\t\tProject:      \"wf_project\",\n\t\t\tDomain:       \"wf_domain\",\n\t\t\tName:         \"wf_name\",\n\t\t\tVersion:      \"wf_version\",\n\t\t},\n\t}\n\texecClosureBytes, _ := proto.Marshal(&execClosure)\n\texecutionModel := models.Execution{\n\t\tExecutionKey: models.ExecutionKey{\n\t\t\tProject: \"project\",\n\t\t\tDomain:  \"domain\",\n\t\t\tName:    \"name\",\n\t\t},\n\t\tPhase:        core.WorkflowExecution_FAILED.String(),\n\t\tLaunchPlanID: uint(1),\n\t\tWorkflowID:   uint(2),\n\t\tClosure:      execClosureBytes,\n\t\tSpec:         getExpectedSpecBytes(),\n\t}\n\tassert.Nil(t, myExecManager.publishNotifications(context.Background(), workflowRequest, executionModel))\n\n}\n\nfunc TestExecutionManager_PublishNotificationsNoPhaseMatch(t *testing.T) {\n\trepository := repositoryMocks.NewMockRepository()\n\tqueue := executions.NewQueueAllocator(getMockExecutionsConfigProvider(), repository)\n\n\tvar myExecManager = &ExecutionManager{\n\t\tdb:                 repository,\n\t\tconfig:             getMockExecutionsConfigProvider(),\n\t\tstorageClient:      getMockStorageForExecTest(context.Background()),\n\t\tqueueAllocator:     queue,\n\t\t_clock:             clock.New(),\n\t\tsystemMetrics:      newExecutionSystemMetrics(mockScope.NewTestScope()),\n\t\tnotificationClient: &mockPublisher,\n\t}\n\t// Currently this doesn't do anything special as the code to invoke pushing to SNS isn't enabled yet.\n\t// This sets up the skeleton for it and appeases the go lint overlords.\n\tworkflowRequest := admin.WorkflowExecutionEventRequest{\n\t\tEvent: &event.WorkflowExecutionEvent{\n\t\t\tPhase: core.WorkflowExecution_SUCCEEDED,\n\t\t\tOutputResult: &event.WorkflowExecutionEvent_OutputUri{\n\t\t\t\tOutputUri: \"somestring\",\n\t\t\t},\n\t\t\tExecutionId: &executionIdentifier,\n\t\t},\n\t}\n\tvar execClosure = admin.ExecutionClosure{\n\t\tNotifications: testutils.GetExecutionRequest().Spec.GetNotifications().Notifications,\n\t}\n\texecClosureBytes, _ := proto.Marshal(&execClosure)\n\texecutionModel := models.Execution{\n\t\tExecutionKey: models.ExecutionKey{\n\t\t\tProject: \"project\",\n\t\t\tDomain:  \"domain\",\n\t\t\tName:    \"name\",\n\t\t},\n\t\tPhase:        core.WorkflowExecution_FAILED.String(),\n\t\tLaunchPlanID: uint(1),\n\t\tWorkflowID:   uint(2),\n\t\tClosure:      execClosureBytes,\n\t}\n\tassert.Nil(t, myExecManager.publishNotifications(context.Background(), workflowRequest, executionModel))\n}\n\nfunc TestTerminateExecution(t *testing.T) {\n\trepository := repositoryMocks.NewMockRepository()\n\tstartTime := time.Now()\n\texecutionGetFunc := makeExecutionGetFunc(t, []byte{}, &startTime)\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetGetCallback(executionGetFunc)\n\n\tabortCause := \"abort cause\"\n\tprincipal := \"principal\"\n\tupdateExecutionFunc := func(\n\t\tcontext context.Context, execution models.Execution) error {\n\t\tassert.Equal(t, \"project\", execution.Project)\n\t\tassert.Equal(t, \"domain\", execution.Domain)\n\t\tassert.Equal(t, \"name\", execution.Name)\n\t\tassert.Equal(t, uint(1), execution.LaunchPlanID)\n\t\tassert.Equal(t, uint(2), execution.WorkflowID)\n\t\tassert.Equal(t, core.WorkflowExecution_ABORTING.String(), execution.Phase)\n\t\tassert.Equal(t, execution.ExecutionCreatedAt, execution.ExecutionUpdatedAt,\n\t\t\t\"an abort call should not change ExecutionUpdatedAt until a corresponding execution event is received\")\n\t\tassert.Equal(t, abortCause, execution.AbortCause)\n\t\tassert.Equal(t, testCluster, execution.Cluster)\n\n\t\tvar unmarshaledClosure admin.ExecutionClosure\n\t\terr := proto.Unmarshal(execution.Closure, &unmarshaledClosure)\n\t\tassert.NoError(t, err)\n\t\tassert.True(t, proto.Equal(&admin.AbortMetadata{\n\t\t\tCause:     abortCause,\n\t\t\tPrincipal: principal,\n\t\t}, unmarshaledClosure.GetAbortMetadata()))\n\t\treturn nil\n\t}\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetUpdateCallback(updateExecutionFunc)\n\n\tmockExecutor := workflowengineMocks.WorkflowExecutor{}\n\tmockExecutor.OnAbortMatch(mock.Anything, mock.MatchedBy(func(data workflowengineInterfaces.AbortData) bool {\n\t\tassert.True(t, proto.Equal(&core.WorkflowExecutionIdentifier{\n\t\t\tProject: \"project\",\n\t\t\tDomain:  \"domain\",\n\t\t\tName:    \"name\",\n\t\t}, data.ExecutionID))\n\t\treturn true\n\t})).Return(nil)\n\tmockExecutor.OnID().Return(\"customMockExecutor\")\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &mockExecutor)\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\n\tidentity, err := auth.NewIdentityContext(\"\", principal, \"\", time.Now(), sets.NewString(), nil, nil)\n\tassert.NoError(t, err)\n\tctx := identity.WithContext(context.Background())\n\tresp, err := execManager.TerminateExecution(ctx, admin.ExecutionTerminateRequest{\n\t\tId: &core.WorkflowExecutionIdentifier{\n\t\t\tProject: \"project\",\n\t\t\tDomain:  \"domain\",\n\t\t\tName:    \"name\",\n\t\t},\n\t\tCause: abortCause,\n\t})\n\n\tassert.Nil(t, err)\n\tassert.NotNil(t, resp)\n}\n\nfunc TestTerminateExecution_PropellerError(t *testing.T) {\n\tvar expectedError = errors.New(\"expected error\")\n\n\tmockExecutor := workflowengineMocks.WorkflowExecutor{}\n\tmockExecutor.OnAbortMatch(mock.Anything, mock.Anything).Return(expectedError)\n\tmockExecutor.OnID().Return(\"customMockExecutor\")\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &mockExecutor)\n\n\tupdateCalled := false\n\trepository := repositoryMocks.NewMockRepository()\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetUpdateCallback(func(\n\t\tcontext context.Context, execution models.Execution) error {\n\t\tupdateCalled = true\n\t\tassert.Equal(t, core.WorkflowExecution_ABORTING.String(), execution.Phase)\n\t\treturn nil\n\t})\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\n\tresp, err := execManager.TerminateExecution(context.Background(), admin.ExecutionTerminateRequest{\n\t\tId: &core.WorkflowExecutionIdentifier{\n\t\t\tProject: \"project\",\n\t\t\tDomain:  \"domain\",\n\t\t\tName:    \"name\",\n\t\t},\n\t\tCause: \"abort cause\",\n\t})\n\tassert.Nil(t, resp)\n\tassert.EqualError(t, err, expectedError.Error())\n\tassert.True(t, updateCalled)\n}\n\nfunc TestTerminateExecution_DatabaseError(t *testing.T) {\n\trepository := repositoryMocks.NewMockRepository()\n\tstartTime := time.Now()\n\texecutionGetFunc := makeExecutionGetFunc(t, []byte{}, &startTime)\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetGetCallback(executionGetFunc)\n\n\tvar expectedError = errors.New(\"expected error\")\n\tupdateExecutionFunc := func(\n\t\tcontext context.Context, execution models.Execution) error {\n\t\treturn expectedError\n\t}\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetUpdateCallback(updateExecutionFunc)\n\tmockExecutor := workflowengineMocks.WorkflowExecutor{}\n\tmockExecutor.OnAbortMatch(mock.Anything, mock.Anything).Return(nil)\n\tmockExecutor.OnID().Return(\"testMockExecutor\")\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &mockExecutor)\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\tresp, err := execManager.TerminateExecution(context.Background(), admin.ExecutionTerminateRequest{\n\t\tId: &core.WorkflowExecutionIdentifier{\n\t\t\tProject: \"project\",\n\t\t\tDomain:  \"domain\",\n\t\t\tName:    \"name\",\n\t\t},\n\t\tCause: \"abort cause\",\n\t})\n\n\tassert.Nil(t, resp)\n\tassert.EqualError(t, err, expectedError.Error())\n}\n\nfunc TestTerminateExecution_AlreadyTerminated(t *testing.T) {\n\tvar expectedError = errors.New(\"expected error\")\n\n\tmockExecutor := workflowengineMocks.WorkflowExecutor{}\n\tmockExecutor.OnAbortMatch(mock.Anything, mock.Anything).Return(expectedError)\n\tmockExecutor.OnID().Return(\"customMockExecutor\")\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &mockExecutor)\n\n\trepository := repositoryMocks.NewMockRepository()\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetGetCallback(\n\t\tfunc(ctx context.Context, input interfaces.Identifier) (models.Execution, error) {\n\t\t\treturn models.Execution{\n\t\t\t\tPhase: core.WorkflowExecution_SUCCEEDED.String(),\n\t\t\t}, nil\n\t\t})\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\tresp, err := execManager.TerminateExecution(context.Background(), admin.ExecutionTerminateRequest{\n\t\tId: &core.WorkflowExecutionIdentifier{\n\t\t\tProject: \"project\",\n\t\t\tDomain:  \"domain\",\n\t\t\tName:    \"name\",\n\t\t},\n\t\tCause: \"abort cause\",\n\t})\n\n\tassert.Nil(t, resp)\n\ts, ok := status.FromError(err)\n\tassert.True(t, ok)\n\tassert.Equal(t, codes.FailedPrecondition, s.Code())\n}\n\nfunc TestGetExecutionData(t *testing.T) {\n\trepository := repositoryMocks.NewMockRepository()\n\tstartedAt := time.Date(2018, 8, 30, 0, 0, 0, 0, time.UTC)\n\tvar closure = admin.ExecutionClosure{\n\t\tPhase: core.WorkflowExecution_RUNNING,\n\t\tOutputResult: &admin.ExecutionClosure_Outputs{\n\t\t\tOutputs: &admin.LiteralMapBlob{\n\t\t\t\tData: &admin.LiteralMapBlob_Uri{\n\t\t\t\t\tUri: outputURI,\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t}\n\tvar closureBytes, _ = proto.Marshal(&closure)\n\n\texecutionGetFunc := func(ctx context.Context, input interfaces.Identifier) (models.Execution, error) {\n\t\treturn models.Execution{\n\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\tProject: \"project\",\n\t\t\t\tDomain:  \"domain\",\n\t\t\t\tName:    \"name\",\n\t\t\t},\n\t\t\tSpec:         getExpectedSpecBytes(),\n\t\t\tPhase:        phase,\n\t\t\tClosure:      closureBytes,\n\t\t\tLaunchPlanID: uint(1),\n\t\t\tWorkflowID:   uint(2),\n\t\t\tStartedAt:    &startedAt,\n\t\t\tInputsURI:    shared.Inputs,\n\t\t}, nil\n\t}\n\tmockExecutionRemoteURL := dataMocks.NewMockRemoteURL()\n\tmockExecutionRemoteURL.(*dataMocks.MockRemoteURL).GetCallback = func(\n\t\tctx context.Context, uri string) (admin.UrlBlob, error) {\n\t\tif uri == outputURI {\n\t\t\treturn admin.UrlBlob{\n\t\t\t\tUrl:   \"outputs\",\n\t\t\t\tBytes: 200,\n\t\t\t}, nil\n\t\t} else if strings.HasSuffix(uri, shared.Inputs) {\n\t\t\treturn admin.UrlBlob{\n\t\t\t\tUrl:   \"inputs\",\n\t\t\t\tBytes: 200,\n\t\t\t}, nil\n\t\t}\n\n\t\treturn admin.UrlBlob{}, errors.New(\"unexpected input\")\n\t}\n\tmockStorage := commonMocks.GetMockStorageClient()\n\tfullInputs := &core.LiteralMap{\n\t\tLiterals: map[string]*core.Literal{\n\t\t\t\"foo\": testutils.MakeStringLiteral(\"foo-value-1\"),\n\t\t},\n\t}\n\tfullOutputs := &core.LiteralMap{\n\t\tLiterals: map[string]*core.Literal{\n\t\t\t\"bar\": testutils.MakeStringLiteral(\"bar-value-1\"),\n\t\t},\n\t}\n\tmockStorage.ComposedProtobufStore.(*commonMocks.TestDataStore).ReadProtobufCb = func(\n\t\tctx context.Context, reference storage.DataReference, msg proto.Message) error {\n\t\tif reference.String() == \"inputs\" {\n\t\t\tmarshalled, _ := proto.Marshal(fullInputs)\n\t\t\t_ = proto.Unmarshal(marshalled, msg)\n\t\t\treturn nil\n\t\t} else if reference.String() == outputURI {\n\t\t\tmarshalled, _ := proto.Marshal(fullOutputs)\n\t\t\t_ = proto.Unmarshal(marshalled, msg)\n\t\t\treturn nil\n\t\t}\n\t\treturn fmt.Errorf(\"unexpected call to find value in storage [%v]\", reference.String())\n\t}\n\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetGetCallback(executionGetFunc)\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &defaultTestExecutor)\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), mockStorage, mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\tdataResponse, err := execManager.GetExecutionData(context.Background(), admin.WorkflowExecutionGetDataRequest{\n\t\tId: &executionIdentifier,\n\t})\n\tassert.Nil(t, err)\n\tassert.True(t, proto.Equal(&admin.WorkflowExecutionGetDataResponse{\n\t\tOutputs: &admin.UrlBlob{\n\t\t\tUrl:   \"outputs\",\n\t\t\tBytes: 200,\n\t\t},\n\t\tInputs: &admin.UrlBlob{\n\t\t\tUrl:   \"inputs\",\n\t\t\tBytes: 200,\n\t\t},\n\t\tFullInputs:  fullInputs,\n\t\tFullOutputs: fullOutputs,\n\t}, dataResponse))\n}\n\nfunc TestResolveStringMap_RuntimeLimitsObserved(t *testing.T) {\n\t_, err := resolveStringMap(&admin.Labels{\n\t\tValues: map[string]string{\n\t\t\t\"dynamiclabel1\": \"dynamic1\",\n\t\t\t\"dynamiclabel2\": \"dynamic2\",\n\t\t},\n\t}, &admin.Labels{\n\t\tValues: map[string]string{\n\t\t\t\"existing1\": \"value1\",\n\t\t},\n\t}, \"labels\", 1)\n\tassert.EqualError(t, err, \"labels has too many entries [2 > 1]\")\n}\n\nfunc TestAddPluginOverrides(t *testing.T) {\n\texecutionID := &core.WorkflowExecutionIdentifier{\n\t\tProject: project,\n\t\tDomain:  domain,\n\t\tName:    \"unused\",\n\t}\n\tworkflowName := \"workflow_name\"\n\tlaunchPlanName := \"launch_plan_name\"\n\n\tdb := repositoryMocks.NewMockRepository()\n\tdb.ResourceRepo().(*repositoryMocks.MockResourceRepo).GetFunction = func(ctx context.Context, ID interfaces.ResourceID) (\n\t\tmodels.Resource, error) {\n\t\tassert.Equal(t, project, ID.Project)\n\t\tassert.Equal(t, domain, ID.Domain)\n\t\tassert.Equal(t, workflowName, ID.Workflow)\n\t\tassert.Equal(t, launchPlanName, ID.LaunchPlan)\n\t\texistingAttributes := commonTestUtils.GetPluginOverridesAttributes(map[string][]string{\n\t\t\t\"python\": {\"plugin a\"},\n\t\t\t\"hive\":   {\"plugin b\"},\n\t\t})\n\t\tbytes, err := proto.Marshal(existingAttributes)\n\t\tif err != nil {\n\t\t\tt.Fatal(err)\n\t\t}\n\t\treturn models.Resource{\n\t\t\tProject:    project,\n\t\t\tDomain:     domain,\n\t\t\tAttributes: bytes,\n\t\t}, nil\n\t}\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &defaultTestExecutor)\n\texecManager := NewExecutionManager(db, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\n\ttaskPluginOverrides, err := execManager.(*ExecutionManager).addPluginOverrides(\n\t\tcontext.Background(), executionID, workflowName, launchPlanName)\n\tassert.NoError(t, err)\n\tassert.Len(t, taskPluginOverrides, 2)\n\tfor _, override := range taskPluginOverrides {\n\t\tif override.TaskType == \"python\" {\n\t\t\tassert.EqualValues(t, []string{\"plugin a\"}, override.PluginId)\n\t\t} else if override.TaskType == \"hive\" {\n\t\t\tassert.EqualValues(t, []string{\"plugin b\"}, override.PluginId)\n\t\t} else {\n\t\t\tt.Errorf(\"Unexpected task type [%s] plugin override committed to db\", override.TaskType)\n\t\t}\n\t}\n}\n\nfunc TestPluginOverrides_ResourceGetFailure(t *testing.T) {\n\texecutionID := &core.WorkflowExecutionIdentifier{\n\t\tProject: project,\n\t\tDomain:  domain,\n\t\tName:    \"unused\",\n\t}\n\tworkflowName := \"workflow_name\"\n\tlaunchPlanName := \"launch_plan_name\"\n\n\tdb := repositoryMocks.NewMockRepository()\n\tdb.ResourceRepo().(*repositoryMocks.MockResourceRepo).GetFunction = func(ctx context.Context, ID interfaces.ResourceID) (\n\t\tmodels.Resource, error) {\n\t\treturn models.Resource{}, flyteAdminErrors.NewFlyteAdminErrorf(codes.Aborted, \"uh oh\")\n\t}\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &defaultTestExecutor)\n\texecManager := NewExecutionManager(db, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\n\t_, err := execManager.(*ExecutionManager).addPluginOverrides(\n\t\tcontext.Background(), executionID, workflowName, launchPlanName)\n\tassert.Error(t, err, \"uh oh\")\n}\n\nfunc TestGetExecution_Legacy(t *testing.T) {\n\trepository := repositoryMocks.NewMockRepository()\n\tstartedAt := time.Date(2018, 8, 30, 0, 0, 0, 0, time.UTC)\n\texecutionGetFunc := func(ctx context.Context, input interfaces.Identifier) (models.Execution, error) {\n\t\tassert.Equal(t, \"project\", input.Project)\n\t\tassert.Equal(t, \"domain\", input.Domain)\n\t\tassert.Equal(t, \"name\", input.Name)\n\t\treturn models.Execution{\n\t\t\tBaseModel: models.BaseModel{\n\t\t\t\tCreatedAt: testutils.MockCreatedAtValue,\n\t\t\t},\n\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\tProject: \"project\",\n\t\t\t\tDomain:  \"domain\",\n\t\t\t\tName:    \"name\",\n\t\t\t},\n\t\t\tSpec:         getExpectedLegacySpecBytes(),\n\t\t\tPhase:        phase,\n\t\t\tClosure:      getLegacyClosureBytes(),\n\t\t\tLaunchPlanID: uint(1),\n\t\t\tWorkflowID:   uint(2),\n\t\t\tStartedAt:    &startedAt,\n\t\t}, nil\n\t}\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetGetCallback(executionGetFunc)\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &defaultTestExecutor)\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\texecution, err := execManager.GetExecution(context.Background(), admin.WorkflowExecutionGetRequest{\n\t\tId: &executionIdentifier,\n\t})\n\tassert.NoError(t, err)\n\tassert.True(t, proto.Equal(&executionIdentifier, execution.Id))\n\tassert.True(t, proto.Equal(getExpectedLegacySpec(), execution.Spec))\n\tassert.True(t, proto.Equal(getLegacyClosure(), execution.Closure))\n}\n\nfunc TestGetExecutionData_LegacyModel(t *testing.T) {\n\trepository := repositoryMocks.NewMockRepository()\n\tstartedAt := time.Date(2018, 8, 30, 0, 0, 0, 0, time.UTC)\n\tclosure := getLegacyClosure()\n\tclosure.OutputResult = &admin.ExecutionClosure_Outputs{\n\t\tOutputs: &admin.LiteralMapBlob{\n\t\t\tData: &admin.LiteralMapBlob_Uri{\n\t\t\t\tUri: outputURI,\n\t\t\t},\n\t\t},\n\t}\n\tvar closureBytes, _ = proto.Marshal(closure)\n\n\texecutionGetFunc := func(ctx context.Context, input interfaces.Identifier) (models.Execution, error) {\n\t\treturn models.Execution{\n\t\t\tBaseModel: models.BaseModel{\n\t\t\t\tCreatedAt: testutils.MockCreatedAtValue,\n\t\t\t},\n\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\tProject: \"project\",\n\t\t\t\tDomain:  \"domain\",\n\t\t\t\tName:    \"name\",\n\t\t\t},\n\t\t\tSpec:         getLegacySpecBytes(),\n\t\t\tPhase:        phase,\n\t\t\tClosure:      closureBytes,\n\t\t\tLaunchPlanID: uint(1),\n\t\t\tWorkflowID:   uint(2),\n\t\t\tStartedAt:    &startedAt,\n\t\t}, nil\n\t}\n\tmockExecutionRemoteURL := dataMocks.NewMockRemoteURL()\n\tmockExecutionRemoteURL.(*dataMocks.MockRemoteURL).GetCallback = func(\n\t\tctx context.Context, uri string) (admin.UrlBlob, error) {\n\t\tif uri == outputURI {\n\t\t\treturn admin.UrlBlob{\n\t\t\t\tUrl:   \"outputs\",\n\t\t\t\tBytes: 200,\n\t\t\t}, nil\n\t\t} else if strings.HasSuffix(uri, shared.Inputs) {\n\t\t\treturn admin.UrlBlob{\n\t\t\t\tUrl:   \"inputs\",\n\t\t\t\tBytes: 200,\n\t\t\t}, nil\n\t\t}\n\n\t\treturn admin.UrlBlob{}, errors.New(\"unexpected input\")\n\t}\n\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetGetCallback(executionGetFunc)\n\tstorageClient := getMockStorageForExecTest(context.Background())\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &defaultTestExecutor)\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), storageClient, mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\tdataResponse, err := execManager.GetExecutionData(context.Background(), admin.WorkflowExecutionGetDataRequest{\n\t\tId: &executionIdentifier,\n\t})\n\tassert.Nil(t, err)\n\tassert.True(t, proto.Equal(&admin.WorkflowExecutionGetDataResponse{\n\t\tOutputs: &admin.UrlBlob{\n\t\t\tUrl:   \"outputs\",\n\t\t\tBytes: 200,\n\t\t},\n\t\tInputs: &admin.UrlBlob{\n\t\t\tUrl:   \"inputs\",\n\t\t\tBytes: 200,\n\t\t},\n\t\tFullInputs: &core.LiteralMap{\n\t\t\tLiterals: map[string]*core.Literal{\n\t\t\t\t\"foo\": testutils.MakeStringLiteral(\"foo-value-1\"),\n\t\t\t},\n\t\t},\n\t\tFullOutputs: &core.LiteralMap{},\n\t}, dataResponse))\n\tvar inputs core.LiteralMap\n\terr = storageClient.ReadProtobuf(context.Background(), storage.DataReference(\"s3://bucket/metadata/project/domain/name/inputs\"), &inputs)\n\tassert.Nil(t, err)\n\tassert.True(t, proto.Equal(&inputs, closure.ComputedInputs))\n}\n\nfunc TestCreateExecution_LegacyClient(t *testing.T) {\n\trepository := getMockRepositoryForExecTest()\n\tsetDefaultLpCallbackForExecTest(repository)\n\n\tmockExecutor := workflowengineMocks.WorkflowExecutor{}\n\tmockExecutor.OnExecuteMatch(mock.Anything, mock.MatchedBy(func(execData workflowengineInterfaces.ExecutionData) bool {\n\t\tassert.EqualValues(t, map[string]string{\n\t\t\t\"label1\": \"1\",\n\t\t\t\"label2\": \"2\",\n\t\t}, execData.ExecutionParameters.Labels)\n\t\tassert.EqualValues(t, map[string]string{\n\t\t\t\"annotation3\": \"3\",\n\t\t\t\"annotation4\": \"4\",\n\t\t}, execData.ExecutionParameters.Annotations)\n\t\treturn true\n\t})).Return(workflowengineInterfaces.ExecutionResponse{\n\t\tCluster: testCluster,\n\t}, nil)\n\tmockExecutor.OnID().Return(\"customMockExecutor\")\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &mockExecutor)\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\tresponse, err := execManager.CreateExecution(context.Background(), *getLegacyExecutionRequest(), requestedAt)\n\tassert.Nil(t, err)\n\n\texpectedResponse := &admin.ExecutionCreateResponse{\n\t\tId: &executionIdentifier,\n\t}\n\tassert.Nil(t, err)\n\tassert.Equal(t, expectedResponse, response)\n}\n\nfunc TestRelaunchExecution_LegacyModel(t *testing.T) {\n\t// Set up mocks.\n\trepository := getMockRepositoryForExecTest()\n\tsetDefaultLpCallbackForExecTest(repository)\n\tstorageClient := getMockStorageForExecTest(context.Background())\n\n\tmockExecutor := workflowengineMocks.WorkflowExecutor{}\n\tmockExecutor.OnExecuteMatch(mock.Anything, mock.Anything, mock.Anything).Return(workflowengineInterfaces.ExecutionResponse{}, nil)\n\tmockExecutor.OnID().Return(\"testMockExecutor\")\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &mockExecutor)\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), storageClient, mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\tstartTime := time.Now()\n\tstartTimeProto, _ := ptypes.TimestampProto(startTime)\n\texistingClosure := getLegacyClosure()\n\texistingClosure.Phase = core.WorkflowExecution_RUNNING\n\texistingClosure.StartedAt = startTimeProto\n\texistingClosure.ComputedInputs.Literals[\"bar\"] = coreutils.MustMakeLiteral(\"bar-value\")\n\texistingClosureBytes, _ := proto.Marshal(existingClosure)\n\texecutionGetFunc := makeLegacyExecutionGetFunc(t, existingClosureBytes, &startTime)\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetGetCallback(executionGetFunc)\n\n\tvar createCalled bool\n\texCreateFunc := func(ctx context.Context, input models.Execution) error {\n\t\tcreateCalled = true\n\t\tassert.Equal(t, \"relaunchy\", input.Name)\n\t\tassert.Equal(t, \"domain\", input.Domain)\n\t\tassert.Equal(t, \"project\", input.Project)\n\t\tassert.Equal(t, uint(8), input.SourceExecutionID)\n\t\tvar spec admin.ExecutionSpec\n\t\terr := proto.Unmarshal(input.Spec, &spec)\n\t\tassert.Nil(t, err)\n\t\tassert.Equal(t, \"default_raw_output\", spec.RawOutputDataConfig.OutputLocationPrefix)\n\t\tassert.Equal(t, admin.ExecutionMetadata_RELAUNCH, spec.Metadata.Mode)\n\t\tassert.Equal(t, int32(admin.ExecutionMetadata_RELAUNCH), input.Mode)\n\t\tassert.True(t, proto.Equal(spec.Inputs, getLegacySpec().Inputs))\n\t\treturn nil\n\t}\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetCreateCallback(exCreateFunc)\n\n\t// Issue request.\n\tresponse, err := execManager.RelaunchExecution(context.Background(), admin.ExecutionRelaunchRequest{\n\t\tId: &core.WorkflowExecutionIdentifier{\n\t\t\tProject: \"project\",\n\t\t\tDomain:  \"domain\",\n\t\t\tName:    \"name\",\n\t\t},\n\t\tName: \"relaunchy\",\n\t}, requestedAt)\n\n\t// And verify response.\n\tassert.Nil(t, err)\n\n\texpectedResponse := &admin.ExecutionCreateResponse{\n\t\tId: &core.WorkflowExecutionIdentifier{\n\t\t\tProject: \"project\",\n\t\t\tDomain:  \"domain\",\n\t\t\tName:    \"relaunchy\",\n\t\t},\n\t}\n\tassert.True(t, createCalled)\n\tassert.True(t, proto.Equal(expectedResponse, response))\n\n\tvar userInputs core.LiteralMap\n\terr = storageClient.ReadProtobuf(context.Background(), \"s3://bucket/metadata/project/domain/relaunchy/user_inputs\", &userInputs)\n\tassert.Nil(t, err)\n\tassert.True(t, proto.Equal(&userInputs, getLegacySpec().Inputs))\n\n\tvar inputs core.LiteralMap\n\terr = storageClient.ReadProtobuf(context.Background(), \"s3://bucket/metadata/project/domain/relaunchy/inputs\", &inputs)\n\tassert.Nil(t, err)\n\tassert.True(t, proto.Equal(&inputs, existingClosure.ComputedInputs))\n}\n\nfunc TestListExecutions_LegacyModel(t *testing.T) {\n\trepository := repositoryMocks.NewMockRepository()\n\texecutionListFunc := func(\n\t\tctx context.Context, input interfaces.ListResourceInput) (interfaces.ExecutionCollectionOutput, error) {\n\t\tvar projectFilter, domainFilter, nameFilter bool\n\t\tfor _, filter := range input.InlineFilters {\n\t\t\tassert.Equal(t, common.Execution, filter.GetEntity())\n\t\t\tqueryExpr, _ := filter.GetGormQueryExpr()\n\t\t\tif queryExpr.Args == projectValue && queryExpr.Query == \"execution_project = ?\" {\n\t\t\t\tprojectFilter = true\n\t\t\t}\n\t\t\tif queryExpr.Args == domainValue && queryExpr.Query == \"execution_domain = ?\" {\n\t\t\t\tdomainFilter = true\n\t\t\t}\n\t\t\tif queryExpr.Args == nameValue && queryExpr.Query == \"execution_name = ?\" {\n\t\t\t\tnameFilter = true\n\t\t\t}\n\t\t}\n\t\tassert.True(t, projectFilter, \"Missing project equality filter\")\n\t\tassert.True(t, domainFilter, \"Missing domain equality filter\")\n\t\tassert.False(t, nameFilter, \"Included name equality filter\")\n\t\tassert.Equal(t, limit, input.Limit)\n\t\tassert.Equal(t, \"execution_domain asc\", input.SortParameter.GetGormOrderExpr())\n\t\tassert.Equal(t, 2, input.Offset)\n\t\treturn interfaces.ExecutionCollectionOutput{\n\t\t\tExecutions: []models.Execution{\n\t\t\t\t{\n\t\t\t\t\tBaseModel: models.BaseModel{\n\t\t\t\t\t\tCreatedAt: testutils.MockCreatedAtValue,\n\t\t\t\t\t},\n\t\t\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\t\t\tProject: projectValue,\n\t\t\t\t\t\tDomain:  domainValue,\n\t\t\t\t\t\tName:    \"my awesome execution\",\n\t\t\t\t\t},\n\t\t\t\t\tSpec:    getLegacySpecBytes(),\n\t\t\t\t\tClosure: getLegacyClosureBytes(),\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\tBaseModel: models.BaseModel{\n\t\t\t\t\t\tCreatedAt: testutils.MockCreatedAtValue,\n\t\t\t\t\t},\n\t\t\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\t\t\tProject: projectValue,\n\t\t\t\t\t\tDomain:  domainValue,\n\t\t\t\t\t\tName:    \"my other execution\",\n\t\t\t\t\t},\n\t\t\t\t\tPhase:   core.WorkflowExecution_SUCCEEDED.String(),\n\t\t\t\t\tSpec:    specBytes,\n\t\t\t\t\tClosure: closureBytes,\n\t\t\t\t},\n\t\t\t},\n\t\t}, nil\n\t}\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetListCallback(executionListFunc)\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &defaultTestExecutor)\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\n\texecutionList, err := execManager.ListExecutions(context.Background(), admin.ResourceListRequest{\n\t\tId: &admin.NamedEntityIdentifier{\n\t\t\tProject: projectValue,\n\t\t\tDomain:  domainValue,\n\t\t},\n\t\tLimit: limit,\n\t\tSortBy: &admin.Sort{\n\t\t\tDirection: admin.Sort_ASCENDING,\n\t\t\tKey:       \"execution_domain\",\n\t\t},\n\t\tToken: \"2\",\n\t})\n\tassert.NoError(t, err)\n\tassert.NotNil(t, executionList)\n\tassert.Len(t, executionList.Executions, 2)\n\n\tfor idx, execution := range executionList.Executions {\n\t\tassert.Equal(t, projectValue, execution.Id.Project)\n\t\tassert.Equal(t, domainValue, execution.Id.Domain)\n\t\tif idx == 0 {\n\t\t\tassert.Equal(t, \"my awesome execution\", execution.Id.Name)\n\t\t}\n\t\tassert.True(t, proto.Equal(spec, execution.Spec))\n\t\tassert.True(t, proto.Equal(&closure, execution.Closure))\n\t}\n\tassert.Empty(t, executionList.Token)\n}\n\nfunc TestSetDefaults(t *testing.T) {\n\ttask := &core.CompiledTask{\n\t\tTemplate: &core.TaskTemplate{\n\t\t\tTarget: &core.TaskTemplate_Container{\n\t\t\t\tContainer: &core.Container{\n\t\t\t\t\tResources: &core.Resources{\n\t\t\t\t\t\tRequests: []*core.Resources_ResourceEntry{\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\tName:  core.Resources_CPU,\n\t\t\t\t\t\t\t\tValue: \"250m\",\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\tId: &core.Identifier{\n\t\t\t\tProject: \"project\",\n\t\t\t\tDomain:  \"domain\",\n\t\t\t\tName:    \"task_name\",\n\t\t\t\tVersion: \"version\",\n\t\t\t},\n\t\t},\n\t}\n\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &defaultTestExecutor)\n\texecManager := NewExecutionManager(repositoryMocks.NewMockRepository(), r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\texecManager.(*ExecutionManager).setCompiledTaskDefaults(context.Background(), task, workflowengineInterfaces.TaskResources{\n\t\tDefaults: runtimeInterfaces.TaskResourceSet{\n\t\t\tCPU:              resource.MustParse(\"200m\"),\n\t\t\tGPU:              resource.MustParse(\"4\"),\n\t\t\tMemory:           resource.MustParse(\"200Gi\"),\n\t\t\tEphemeralStorage: resource.MustParse(\"500Mi\"),\n\t\t},\n\t\tLimits: runtimeInterfaces.TaskResourceSet{\n\t\t\tCPU:              resource.MustParse(\"300m\"),\n\t\t\tGPU:              resource.MustParse(\"8\"),\n\t\t\tMemory:           resource.MustParse(\"500Gi\"),\n\t\t\tEphemeralStorage: resource.MustParse(\"501Mi\"),\n\t\t},\n\t})\n\tassert.True(t, proto.Equal(\n\t\t&core.Container{\n\t\t\tResources: &core.Resources{\n\t\t\t\tRequests: []*core.Resources_ResourceEntry{\n\t\t\t\t\t{\n\t\t\t\t\t\tName:  core.Resources_CPU,\n\t\t\t\t\t\tValue: \"250m\",\n\t\t\t\t\t},\n\t\t\t\t\t{\n\t\t\t\t\t\tName:  core.Resources_MEMORY,\n\t\t\t\t\t\tValue: \"200Gi\",\n\t\t\t\t\t},\n\t\t\t\t\t{\n\t\t\t\t\t\tName:  core.Resources_EPHEMERAL_STORAGE,\n\t\t\t\t\t\tValue: \"500Mi\",\n\t\t\t\t\t},\n\t\t\t\t\t{\n\t\t\t\t\t\tName:  core.Resources_GPU,\n\t\t\t\t\t\tValue: \"4\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tLimits: []*core.Resources_ResourceEntry{\n\t\t\t\t\t{\n\t\t\t\t\t\tName:  core.Resources_CPU,\n\t\t\t\t\t\tValue: \"250m\",\n\t\t\t\t\t},\n\t\t\t\t\t{\n\t\t\t\t\t\tName:  core.Resources_MEMORY,\n\t\t\t\t\t\tValue: \"200Gi\",\n\t\t\t\t\t},\n\t\t\t\t\t{\n\t\t\t\t\t\tName:  core.Resources_EPHEMERAL_STORAGE,\n\t\t\t\t\t\tValue: \"500Mi\",\n\t\t\t\t\t},\n\t\t\t\t\t{\n\t\t\t\t\t\tName:  core.Resources_GPU,\n\t\t\t\t\t\tValue: \"4\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\ttask.Template.GetContainer()), fmt.Sprintf(\"%+v\", task.Template.GetContainer()))\n}\n\nfunc TestSetDefaults_MissingRequests_ExistingRequestsPreserved(t *testing.T) {\n\ttask := &core.CompiledTask{\n\t\tTemplate: &core.TaskTemplate{\n\t\t\tTarget: &core.TaskTemplate_Container{\n\t\t\t\tContainer: &core.Container{\n\t\t\t\t\tResources: &core.Resources{\n\t\t\t\t\t\tRequests: []*core.Resources_ResourceEntry{\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\tName:  core.Resources_CPU,\n\t\t\t\t\t\t\t\tValue: \"250m\",\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\tId: &core.Identifier{\n\t\t\t\tProject: \"project\",\n\t\t\t\tDomain:  \"domain\",\n\t\t\t\tName:    \"task_name\",\n\t\t\t\tVersion: \"version\",\n\t\t\t},\n\t\t},\n\t}\n\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &defaultTestExecutor)\n\texecManager := NewExecutionManager(repositoryMocks.NewMockRepository(), r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\texecManager.(*ExecutionManager).setCompiledTaskDefaults(context.Background(), task, workflowengineInterfaces.TaskResources{\n\t\tDefaults: runtimeInterfaces.TaskResourceSet{\n\t\t\tCPU:    resource.MustParse(\"200m\"),\n\t\t\tGPU:    resource.MustParse(\"4\"),\n\t\t\tMemory: resource.MustParse(\"200Gi\"),\n\t\t},\n\t\tLimits: runtimeInterfaces.TaskResourceSet{\n\t\t\tCPU: resource.MustParse(\"300m\"),\n\t\t\tGPU: resource.MustParse(\"8\"),\n\t\t\t// Because only the limit is set, this resource should not be injected.\n\t\t\tEphemeralStorage: resource.MustParse(\"100\"),\n\t\t},\n\t})\n\tassert.True(t, proto.Equal(\n\t\t&core.Container{\n\t\t\tResources: &core.Resources{\n\t\t\t\tRequests: []*core.Resources_ResourceEntry{\n\t\t\t\t\t{\n\t\t\t\t\t\tName:  core.Resources_CPU,\n\t\t\t\t\t\tValue: \"250m\",\n\t\t\t\t\t},\n\t\t\t\t\t{\n\t\t\t\t\t\tName:  core.Resources_MEMORY,\n\t\t\t\t\t\tValue: \"200Gi\",\n\t\t\t\t\t},\n\t\t\t\t\t{\n\t\t\t\t\t\tName:  core.Resources_GPU,\n\t\t\t\t\t\tValue: \"4\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tLimits: []*core.Resources_ResourceEntry{\n\t\t\t\t\t{\n\t\t\t\t\t\tName:  core.Resources_CPU,\n\t\t\t\t\t\tValue: \"250m\",\n\t\t\t\t\t},\n\t\t\t\t\t{\n\t\t\t\t\t\tName:  core.Resources_MEMORY,\n\t\t\t\t\t\tValue: \"200Gi\",\n\t\t\t\t\t},\n\t\t\t\t\t{\n\t\t\t\t\t\tName:  core.Resources_GPU,\n\t\t\t\t\t\tValue: \"4\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\ttask.Template.GetContainer()), fmt.Sprintf(\"%+v\", task.Template.GetContainer()))\n}\n\nfunc TestSetDefaults_OptionalRequiredResources(t *testing.T) {\n\ttaskConfigLimits := runtimeInterfaces.TaskResourceSet{\n\t\tCPU:              resource.MustParse(\"300m\"),\n\t\tGPU:              resource.MustParse(\"1\"),\n\t\tMemory:           resource.MustParse(\"500Gi\"),\n\t\tEphemeralStorage: resource.MustParse(\"501Mi\"),\n\t}\n\n\ttask := &core.CompiledTask{\n\t\tTemplate: &core.TaskTemplate{\n\t\t\tTarget: &core.TaskTemplate_Container{\n\t\t\t\tContainer: &core.Container{\n\t\t\t\t\tResources: &core.Resources{\n\t\t\t\t\t\tRequests: []*core.Resources_ResourceEntry{\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\tName:  core.Resources_CPU,\n\t\t\t\t\t\t\t\tValue: \"200m\",\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\tId: &taskIdentifier,\n\t\t},\n\t}\n\tt.Run(\"don't inject ephemeral storage or gpu when only the limit is set in config\", func(t *testing.T) {\n\t\tr := plugins.NewRegistry()\n\t\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &defaultTestExecutor)\n\t\texecManager := NewExecutionManager(repositoryMocks.NewMockRepository(), r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\t\texecManager.(*ExecutionManager).setCompiledTaskDefaults(context.Background(), task, workflowengineInterfaces.TaskResources{\n\t\t\tDefaults: runtimeInterfaces.TaskResourceSet{\n\t\t\t\tCPU:    resource.MustParse(\"200m\"),\n\t\t\t\tMemory: resource.MustParse(\"200Gi\"),\n\t\t\t},\n\t\t\tLimits: taskConfigLimits,\n\t\t})\n\t\tassert.True(t, proto.Equal(\n\t\t\t&core.Container{\n\t\t\t\tResources: &core.Resources{\n\t\t\t\t\tRequests: []*core.Resources_ResourceEntry{\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tName:  core.Resources_CPU,\n\t\t\t\t\t\t\tValue: \"200m\",\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tName:  core.Resources_MEMORY,\n\t\t\t\t\t\t\tValue: \"200Gi\",\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t\tLimits: []*core.Resources_ResourceEntry{\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tName:  core.Resources_CPU,\n\t\t\t\t\t\t\tValue: \"200m\",\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tName:  core.Resources_MEMORY,\n\t\t\t\t\t\t\tValue: \"200Gi\",\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\ttask.Template.GetContainer()), fmt.Sprintf(\"%+v\", task.Template.GetContainer()))\n\t})\n\n\tt.Run(\"respect non-required resources when defaults exist in config\", func(t *testing.T) {\n\t\tr := plugins.NewRegistry()\n\t\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &defaultTestExecutor)\n\t\texecManager := NewExecutionManager(repositoryMocks.NewMockRepository(), r, getMockExecutionsConfigProvider(), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, nil, nil, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\t\texecManager.(*ExecutionManager).setCompiledTaskDefaults(context.Background(), task, workflowengineInterfaces.TaskResources{\n\t\t\tLimits: taskConfigLimits,\n\t\t\tDefaults: runtimeInterfaces.TaskResourceSet{\n\t\t\t\tCPU:              resource.MustParse(\"200m\"),\n\t\t\t\tMemory:           resource.MustParse(\"200Gi\"),\n\t\t\t\tEphemeralStorage: resource.MustParse(\"1\"),\n\t\t\t},\n\t\t})\n\t\tassert.True(t, proto.Equal(\n\t\t\t&core.Container{\n\t\t\t\tResources: &core.Resources{\n\t\t\t\t\tRequests: []*core.Resources_ResourceEntry{\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tName:  core.Resources_CPU,\n\t\t\t\t\t\t\tValue: \"200m\",\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tName:  core.Resources_MEMORY,\n\t\t\t\t\t\t\tValue: \"200Gi\",\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tName:  core.Resources_EPHEMERAL_STORAGE,\n\t\t\t\t\t\t\tValue: \"1\",\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t\tLimits: []*core.Resources_ResourceEntry{\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tName:  core.Resources_CPU,\n\t\t\t\t\t\t\tValue: \"200m\",\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tName:  core.Resources_MEMORY,\n\t\t\t\t\t\t\tValue: \"200Gi\",\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tName:  core.Resources_EPHEMERAL_STORAGE,\n\t\t\t\t\t\t\tValue: \"1\",\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\ttask.Template.GetContainer()), fmt.Sprintf(\"%+v\", task.Template.GetContainer()))\n\t})\n\n}\nfunc TestCreateSingleTaskExecution(t *testing.T) {\n\trepository := getMockRepositoryForExecTest()\n\tvar getCalledCount = 0\n\tvar newlyCreatedWorkflow models.Workflow\n\tworkflowCreateFunc := func(input models.Workflow, descriptionEntity *models.DescriptionEntity) error {\n\t\tnewlyCreatedWorkflow = input\n\t\treturn nil\n\t}\n\trepository.WorkflowRepo().(*repositoryMocks.MockWorkflowRepo).SetCreateCallback(workflowCreateFunc)\n\n\tworkflowGetFunc := func(input interfaces.Identifier) (models.Workflow, error) {\n\t\tif getCalledCount <= 1 {\n\t\t\tgetCalledCount++\n\t\t\treturn models.Workflow{}, flyteAdminErrors.NewFlyteAdminErrorf(codes.NotFound, \"not found\")\n\t\t}\n\t\tgetCalledCount++\n\t\treturn newlyCreatedWorkflow, nil\n\t}\n\trepository.WorkflowRepo().(*repositoryMocks.MockWorkflowRepo).SetGetCallback(workflowGetFunc)\n\ttaskIdentifier := &core.Identifier{\n\t\tResourceType: core.ResourceType_TASK,\n\t\tProject:      \"flytekit\",\n\t\tDomain:       \"production\",\n\t\tName:         \"simple_task\",\n\t\tVersion:      \"12345\",\n\t}\n\trepository.TaskRepo().(*repositoryMocks.MockTaskRepo).SetGetCallback(\n\t\tfunc(input interfaces.Identifier) (models.Task, error) {\n\t\t\tcreatedAt := time.Now()\n\t\t\tcreatedAtProto, _ := ptypes.TimestampProto(createdAt)\n\t\t\ttaskClosure := &admin.TaskClosure{\n\t\t\t\tCompiledTask: &core.CompiledTask{\n\t\t\t\t\tTemplate: &core.TaskTemplate{\n\t\t\t\t\t\tId:   taskIdentifier,\n\t\t\t\t\t\tType: \"python-task\",\n\t\t\t\t\t\tMetadata: &core.TaskMetadata{\n\t\t\t\t\t\t\tRuntime: &core.RuntimeMetadata{\n\t\t\t\t\t\t\t\tType:    core.RuntimeMetadata_FLYTE_SDK,\n\t\t\t\t\t\t\t\tVersion: \"0.6.2\",\n\t\t\t\t\t\t\t\tFlavor:  \"python\",\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\tTimeout: ptypes.DurationProto(time.Second),\n\t\t\t\t\t\t},\n\t\t\t\t\t\tInterface: &core.TypedInterface{\n\t\t\t\t\t\t\tInputs: &core.VariableMap{\n\t\t\t\t\t\t\t\tVariables: map[string]*core.Variable{\n\t\t\t\t\t\t\t\t\t\"a\": {\n\t\t\t\t\t\t\t\t\t\tType: &core.LiteralType{\n\t\t\t\t\t\t\t\t\t\t\tType: &core.LiteralType_Simple{\n\t\t\t\t\t\t\t\t\t\t\t\tSimple: core.SimpleType_INTEGER,\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\tOutputs: &core.VariableMap{\n\t\t\t\t\t\t\t\tVariables: map[string]*core.Variable{\n\t\t\t\t\t\t\t\t\t\"b\": {\n\t\t\t\t\t\t\t\t\t\tType: &core.LiteralType{\n\t\t\t\t\t\t\t\t\t\t\tType: &core.LiteralType_Simple{\n\t\t\t\t\t\t\t\t\t\t\t\tSimple: core.SimpleType_INTEGER,\n\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t\tCustom: nil,\n\t\t\t\t\t\tTarget: &core.TaskTemplate_Container{\n\t\t\t\t\t\t\tContainer: &core.Container{\n\t\t\t\t\t\t\t\tImage: \"docker.io/my:image\",\n\t\t\t\t\t\t\t\tArgs: []string{\n\t\t\t\t\t\t\t\t\t\"pyflyte-execute\",\n\t\t\t\t\t\t\t\t\t\"--task-module\",\n\t\t\t\t\t\t\t\t\t\"workflows.simple\",\n\t\t\t\t\t\t\t\t\t\"--task-name\",\n\t\t\t\t\t\t\t\t\t\"simple_task\",\n\t\t\t\t\t\t\t\t\t\"--inputs\",\n\t\t\t\t\t\t\t\t\t\"{{.input}}\",\n\t\t\t\t\t\t\t\t\t\"--output-prefix\",\n\t\t\t\t\t\t\t\t\t\"{{.outputPrefix}}\",\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\tEnv: []*core.KeyValuePair{\n\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\tKey:   \"FLYTE_INTERNAL_PROJECT\",\n\t\t\t\t\t\t\t\t\t\tValue: \"flytekit\",\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\tKey:   \"FLYTE_INTERNAL_DOMAIN\",\n\t\t\t\t\t\t\t\t\t\tValue: \"production\",\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\tKey:   \"FLYTE_INTERNAL_NAME\",\n\t\t\t\t\t\t\t\t\t\tValue: \"simple_task\",\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\tKey:   \"FLYTE_INTERNAL_VERSION\",\n\t\t\t\t\t\t\t\t\t\tValue: \"12345\",\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tCreatedAt: createdAtProto,\n\t\t\t}\n\t\t\tserializedTaskClosure, err := proto.Marshal(taskClosure)\n\t\t\tassert.NoError(t, err)\n\t\t\treturn models.Task{\n\t\t\t\tTaskKey: models.TaskKey{\n\t\t\t\t\tProject: \"flytekit\",\n\t\t\t\t\tDomain:  \"production\",\n\t\t\t\t\tName:    \"simple_task\",\n\t\t\t\t\tVersion: \"12345\",\n\t\t\t\t},\n\t\t\t\tClosure: serializedTaskClosure,\n\t\t\t\tDigest:  []byte(\"simple_task\"),\n\t\t\t\tType:    \"python\",\n\t\t\t}, nil\n\t\t})\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetCreateCallback(\n\t\tfunc(ctx context.Context, input models.Execution) error {\n\t\t\tvar spec admin.ExecutionSpec\n\t\t\terr := proto.Unmarshal(input.Spec, &spec)\n\t\t\tassert.NoError(t, err)\n\t\t\tassert.Equal(t, models.ExecutionKey{\n\t\t\t\tProject: \"flytekit\",\n\t\t\t\tDomain:  \"production\",\n\t\t\t\tName:    \"singletaskexec\",\n\t\t\t}, input.ExecutionKey)\n\t\t\tassert.Equal(t, \"task\", input.LaunchEntity)\n\t\t\tassert.Equal(t, \"UNDEFINED\", input.Phase)\n\t\t\tassert.True(t, proto.Equal(taskIdentifier, spec.LaunchPlan))\n\t\t\treturn nil\n\t\t})\n\n\tvar launchplan *models.LaunchPlan\n\trepository.LaunchPlanRepo().(*repositoryMocks.MockLaunchPlanRepo).SetCreateCallback(func(input models.LaunchPlan) error {\n\t\tlaunchplan = &input\n\t\treturn nil\n\t})\n\trepository.LaunchPlanRepo().(*repositoryMocks.MockLaunchPlanRepo).SetGetCallback(func(input interfaces.Identifier) (models.LaunchPlan, error) {\n\t\tif launchplan == nil {\n\t\t\treturn models.LaunchPlan{}, flyteAdminErrors.NewFlyteAdminError(codes.NotFound, \"launchplan not found\")\n\t\t}\n\t\treturn *launchplan, nil\n\t})\n\n\tmockStorage := getMockStorageForExecTest(context.Background())\n\tworkflowManager := NewWorkflowManager(\n\t\trepository,\n\t\tgetMockWorkflowConfigProvider(), getMockWorkflowCompiler(), mockStorage,\n\t\tstoragePrefix, mockScope.NewTestScope())\n\tnamedEntityManager := NewNamedEntityManager(repository, getMockConfigForNETest(), mockScope.NewTestScope())\n\n\tmockExecutor := workflowengineMocks.WorkflowExecutor{}\n\tmockExecutor.OnExecuteMatch(mock.Anything, mock.Anything, mock.Anything).Return(workflowengineInterfaces.ExecutionResponse{}, nil)\n\tmockExecutor.OnID().Return(\"testMockExecutor\")\n\tr := plugins.NewRegistry()\n\tr.RegisterDefault(plugins.PluginIDWorkflowExecutor, &mockExecutor)\n\texecManager := NewExecutionManager(repository, r, getMockExecutionsConfigProvider(), mockStorage, mockScope.NewTestScope(), mockScope.NewTestScope(), &mockPublisher, mockExecutionRemoteURL, workflowManager, namedEntityManager, nil, nil, &eventWriterMocks.WorkflowExecutionEventWriter{})\n\trequest := admin.ExecutionCreateRequest{\n\t\tProject: \"flytekit\",\n\t\tDomain:  \"production\",\n\t\tName:    \"singletaskexec\",\n\t\tSpec: &admin.ExecutionSpec{\n\t\t\tLaunchPlan: taskIdentifier,\n\t\t},\n\t\tInputs: &core.LiteralMap{\n\t\t\tLiterals: map[string]*core.Literal{\n\t\t\t\t\"a\": {\n\t\t\t\t\tValue: &core.Literal_Scalar{\n\t\t\t\t\t\tScalar: &core.Scalar{\n\t\t\t\t\t\t\tValue: &core.Scalar_Primitive{\n\t\t\t\t\t\t\t\tPrimitive: &core.Primitive{\n\t\t\t\t\t\t\t\t\tValue: &core.Primitive_Integer{\n\t\t\t\t\t\t\t\t\t\tInteger: 999,\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t}\n\n\tmarshaller := jsonpb.Marshaler{}\n\t_, ferr := marshaller.MarshalToString(&request)\n\tassert.NoError(t, ferr)\n\n\t// test once to create an initial launchplan\n\t_, err := execManager.CreateExecution(context.TODO(), request, time.Now())\n\tassert.NoError(t, err)\n\n\t// test again to ensure existing launchplan retrieval works\n\t_, err = execManager.CreateExecution(context.TODO(), request, time.Now())\n\tassert.NoError(t, err)\n}\n\nfunc TestGetExecutionConfigOverrides(t *testing.T) {\n\trequestLabels := map[string]string{\"requestLabelKey\": \"requestLabelValue\"}\n\trequestAnnotations := map[string]string{\"requestAnnotationKey\": \"requestAnnotationValue\"}\n\trequestOutputLocationPrefix := \"requestOutputLocationPrefix\"\n\trequestK8sServiceAccount := \"requestK8sServiceAccount\"\n\trequestMaxParallelism := int32(10)\n\trequestInterruptible := false\n\trequestOverwriteCache := false\n\trequestEnvironmentVariables := []*core.KeyValuePair{{Key: \"hello\", Value: \"world\"}}\n\n\tlaunchPlanLabels := map[string]string{\"launchPlanLabelKey\": \"launchPlanLabelValue\"}\n\tlaunchPlanAnnotations := map[string]string{\"launchPlanAnnotationKey\": \"launchPlanAnnotationValue\"}\n\tlaunchPlanOutputLocationPrefix := \"launchPlanOutputLocationPrefix\"\n\tlaunchPlanK8sServiceAccount := \"launchPlanK8sServiceAccount\"\n\tlaunchPlanAssumableIamRole := \"launchPlanAssumableIamRole\"\n\tlaunchPlanMaxParallelism := int32(50)\n\tlaunchPlanInterruptible := true\n\tlaunchPlanOverwriteCache := true\n\tlaunchPlanEnvironmentVariables := []*core.KeyValuePair{{Key: \"foo\", Value: \"bar\"}}\n\n\tapplicationConfig := runtime.NewConfigurationProvider()\n\n\tdefaultK8sServiceAccount := applicationConfig.ApplicationConfiguration().GetTopLevelConfig().K8SServiceAccount\n\tdefaultMaxParallelism := applicationConfig.ApplicationConfiguration().GetTopLevelConfig().MaxParallelism\n\n\tdeprecatedLaunchPlanK8sServiceAccount := \"deprecatedLaunchPlanK8sServiceAccount\"\n\trmLabels := map[string]string{\"rmLabelKey\": \"rmLabelValue\"}\n\trmAnnotations := map[string]string{\"rmAnnotationKey\": \"rmAnnotationValue\"}\n\trmOutputLocationPrefix := \"rmOutputLocationPrefix\"\n\trmK8sServiceAccount := \"rmK8sServiceAccount\"\n\trmMaxParallelism := int32(80)\n\trmInterruptible := false\n\trmOverwriteCache := false\n\n\tresourceManager := managerMocks.MockResourceManager{}\n\texecutionManager := ExecutionManager{\n\t\tresourceManager: &resourceManager,\n\t\tconfig:          applicationConfig,\n\t}\n\tresourceManager.GetResourceFunc = func(ctx context.Context,\n\t\trequest managerInterfaces.ResourceRequest) (*managerInterfaces.ResourceResponse, error) {\n\t\t// two requests will be made, one with empty domain and one with filled in domain\n\t\tassert.Contains(t, []managerInterfaces.ResourceRequest{{\n\t\t\tProject:      workflowIdentifier.Project,\n\t\t\tDomain:       workflowIdentifier.Domain,\n\t\t\tResourceType: admin.MatchableResource_WORKFLOW_EXECUTION_CONFIG,\n\t\t}, {Project: workflowIdentifier.Project,\n\t\t\tDomain:       \"\",\n\t\t\tResourceType: admin.MatchableResource_WORKFLOW_EXECUTION_CONFIG},\n\t\t}, request)\n\t\tprojectDomainResponse := &managerInterfaces.ResourceResponse{\n\t\t\tAttributes: &admin.MatchingAttributes{\n\t\t\t\tTarget: &admin.MatchingAttributes_WorkflowExecutionConfig{\n\t\t\t\t\tWorkflowExecutionConfig: &admin.WorkflowExecutionConfig{\n\t\t\t\t\t\tMaxParallelism: rmMaxParallelism,\n\t\t\t\t\t\tInterruptible:  &wrappers.BoolValue{Value: rmInterruptible},\n\t\t\t\t\t\tOverwriteCache: rmOverwriteCache,\n\t\t\t\t\t\tAnnotations:    &admin.Annotations{Values: rmAnnotations},\n\t\t\t\t\t\tRawOutputDataConfig: &admin.RawOutputDataConfig{\n\t\t\t\t\t\t\tOutputLocationPrefix: rmOutputLocationPrefix,\n\t\t\t\t\t\t},\n\t\t\t\t\t\tSecurityContext: &core.SecurityContext{\n\t\t\t\t\t\t\tRunAs: &core.Identity{\n\t\t\t\t\t\t\t\tK8SServiceAccount: rmK8sServiceAccount,\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t}\n\n\t\tprojectResponse := &managerInterfaces.ResourceResponse{\n\t\t\tAttributes: &admin.MatchingAttributes{\n\t\t\t\tTarget: &admin.MatchingAttributes_WorkflowExecutionConfig{\n\t\t\t\t\tWorkflowExecutionConfig: &admin.WorkflowExecutionConfig{\n\t\t\t\t\t\tLabels: &admin.Labels{Values: rmLabels},\n\t\t\t\t\t\tRawOutputDataConfig: &admin.RawOutputDataConfig{\n\t\t\t\t\t\t\tOutputLocationPrefix: \"shouldnotbeused\",\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t}\n\t\tif request.Domain == \"\" {\n\t\t\treturn projectResponse, nil\n\t\t}\n\t\treturn projectDomainResponse, nil\n\t}\n\n\tt.Run(\"request with full config\", func(t *testing.T) {\n\t\trequest := &admin.ExecutionCreateRequest{\n\t\t\tProject: workflowIdentifier.Project,\n\t\t\tDomain:  workflowIdentifier.Domain,\n\t\t\tSpec: &admin.ExecutionSpec{\n\t\t\t\tLabels:      &admin.Labels{Values: requestLabels},\n\t\t\t\tAnnotations: &admin.Annotations{Values: requestAnnotations},\n\t\t\t\tRawOutputDataConfig: &admin.RawOutputDataConfig{\n\t\t\t\t\tOutputLocationPrefix: requestOutputLocationPrefix,\n\t\t\t\t},\n\t\t\t\tSecurityContext: &core.SecurityContext{\n\t\t\t\t\tRunAs: &core.Identity{\n\t\t\t\t\t\tK8SServiceAccount: requestK8sServiceAccount,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tMaxParallelism: requestMaxParallelism,\n\t\t\t\tInterruptible:  &wrappers.BoolValue{Value: requestInterruptible},\n\t\t\t\tOverwriteCache: requestOverwriteCache,\n\t\t\t\tEnvs:           &admin.Envs{Values: requestEnvironmentVariables},\n\t\t\t},\n\t\t}\n\t\tidentityContext, err := auth.NewIdentityContext(\"\", \"\", \"\", time.Now(), sets.String{}, nil, nil)\n\t\tassert.NoError(t, err)\n\t\tidentityContext = identityContext.WithExecutionUserIdentifier(\"yeee\")\n\t\tctx := identityContext.WithContext(context.Background())\n\t\texecConfig, err := executionManager.getExecutionConfig(ctx, request, nil)\n\t\tassert.NoError(t, err)\n\t\tassert.Equal(t, requestMaxParallelism, execConfig.MaxParallelism)\n\t\tassert.Equal(t, requestK8sServiceAccount, execConfig.SecurityContext.RunAs.K8SServiceAccount)\n\t\tassert.Equal(t, requestInterruptible, execConfig.Interruptible.Value)\n\t\tassert.Equal(t, requestOverwriteCache, execConfig.OverwriteCache)\n\t\tassert.Equal(t, requestOutputLocationPrefix, execConfig.RawOutputDataConfig.OutputLocationPrefix)\n\t\tassert.Equal(t, requestLabels, execConfig.GetLabels().Values)\n\t\tassert.Equal(t, requestAnnotations, execConfig.GetAnnotations().Values)\n\t\tassert.Equal(t, \"yeee\", execConfig.GetSecurityContext().GetRunAs().GetExecutionIdentity())\n\t\tassert.Equal(t, requestEnvironmentVariables, execConfig.GetEnvs().Values)\n\t})\n\tt.Run(\"request with partial config\", func(t *testing.T) {\n\t\trequest := &admin.ExecutionCreateRequest{\n\t\t\tProject: workflowIdentifier.Project,\n\t\t\tDomain:  workflowIdentifier.Domain,\n\t\t\tSpec: &admin.ExecutionSpec{\n\t\t\t\tLabels: &admin.Labels{Values: requestLabels},\n\t\t\t\tRawOutputDataConfig: &admin.RawOutputDataConfig{\n\t\t\t\t\tOutputLocationPrefix: requestOutputLocationPrefix,\n\t\t\t\t},\n\t\t\t\tMaxParallelism: requestMaxParallelism,\n\t\t\t},\n\t\t}\n\t\tlaunchPlan := &admin.LaunchPlan{\n\t\t\tSpec: &admin.LaunchPlanSpec{\n\t\t\t\tAnnotations:         &admin.Annotations{Values: launchPlanAnnotations},\n\t\t\t\tLabels:              &admin.Labels{Values: launchPlanLabels},\n\t\t\t\tRawOutputDataConfig: &admin.RawOutputDataConfig{OutputLocationPrefix: launchPlanOutputLocationPrefix},\n\t\t\t\tSecurityContext: &core.SecurityContext{\n\t\t\t\t\tRunAs: &core.Identity{\n\t\t\t\t\t\tK8SServiceAccount: launchPlanK8sServiceAccount,\n\t\t\t\t\t\tIamRole:           launchPlanAssumableIamRole,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tMaxParallelism: launchPlanMaxParallelism,\n\t\t\t\tInterruptible:  &wrappers.BoolValue{Value: launchPlanInterruptible},\n\t\t\t\tOverwriteCache: launchPlanOverwriteCache,\n\t\t\t\tEnvs:           &admin.Envs{Values: launchPlanEnvironmentVariables},\n\t\t\t},\n\t\t}\n\t\texecConfig, err := executionManager.getExecutionConfig(context.TODO(), request, launchPlan)\n\t\tassert.NoError(t, err)\n\t\tassert.Equal(t, requestMaxParallelism, execConfig.MaxParallelism)\n\t\tassert.Equal(t, launchPlanInterruptible, execConfig.Interruptible.Value)\n\t\tassert.Equal(t, launchPlanOverwriteCache, execConfig.OverwriteCache)\n\t\tassert.True(t, proto.Equal(launchPlan.Spec.SecurityContext, execConfig.SecurityContext))\n\t\tassert.True(t, proto.Equal(launchPlan.Spec.Annotations, execConfig.Annotations))\n\t\tassert.Equal(t, requestOutputLocationPrefix, execConfig.RawOutputDataConfig.OutputLocationPrefix)\n\t\tassert.Equal(t, requestLabels, execConfig.GetLabels().Values)\n\t\tassert.Equal(t, launchPlanEnvironmentVariables, execConfig.GetEnvs().Values)\n\t})\n\tt.Run(\"request with empty security context\", func(t *testing.T) {\n\t\trequest := &admin.ExecutionCreateRequest{\n\t\t\tProject: workflowIdentifier.Project,\n\t\t\tDomain:  workflowIdentifier.Domain,\n\t\t\tSpec: &admin.ExecutionSpec{\n\t\t\t\tSecurityContext: &core.SecurityContext{\n\t\t\t\t\tRunAs: &core.Identity{\n\t\t\t\t\t\tK8SServiceAccount: \"\",\n\t\t\t\t\t\tIamRole:           \"\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t}\n\t\tlaunchPlan := &admin.LaunchPlan{\n\t\t\tSpec: &admin.LaunchPlanSpec{\n\t\t\t\tAnnotations:         &admin.Annotations{Values: launchPlanAnnotations},\n\t\t\t\tLabels:              &admin.Labels{Values: launchPlanLabels},\n\t\t\t\tRawOutputDataConfig: &admin.RawOutputDataConfig{OutputLocationPrefix: launchPlanOutputLocationPrefix},\n\t\t\t\tSecurityContext: &core.SecurityContext{\n\t\t\t\t\tRunAs: &core.Identity{\n\t\t\t\t\t\tK8SServiceAccount: launchPlanK8sServiceAccount,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tMaxParallelism: launchPlanMaxParallelism,\n\t\t\t\tInterruptible:  &wrappers.BoolValue{Value: launchPlanInterruptible},\n\t\t\t\tOverwriteCache: launchPlanOverwriteCache,\n\t\t\t\tEnvs:           &admin.Envs{Values: launchPlanEnvironmentVariables},\n\t\t\t},\n\t\t}\n\t\texecConfig, err := executionManager.getExecutionConfig(context.TODO(), request, launchPlan)\n\t\tassert.NoError(t, err)\n\t\tassert.Equal(t, launchPlanMaxParallelism, execConfig.MaxParallelism)\n\t\tassert.Equal(t, launchPlanInterruptible, execConfig.Interruptible.Value)\n\t\tassert.Equal(t, launchPlanOverwriteCache, execConfig.OverwriteCache)\n\t\tassert.Equal(t, launchPlanK8sServiceAccount, execConfig.SecurityContext.RunAs.K8SServiceAccount)\n\t\tassert.Equal(t, launchPlanOutputLocationPrefix, execConfig.RawOutputDataConfig.OutputLocationPrefix)\n\t\tassert.Equal(t, launchPlanLabels, execConfig.GetLabels().Values)\n\t\tassert.Equal(t, launchPlanEnvironmentVariables, execConfig.GetEnvs().Values)\n\t})\n\tt.Run(\"request with no config\", func(t *testing.T) {\n\t\trequest := &admin.ExecutionCreateRequest{\n\t\t\tProject: workflowIdentifier.Project,\n\t\t\tDomain:  workflowIdentifier.Domain,\n\t\t\tSpec:    &admin.ExecutionSpec{},\n\t\t}\n\t\tlaunchPlan := &admin.LaunchPlan{\n\t\t\tSpec: &admin.LaunchPlanSpec{\n\t\t\t\tLabels:      &admin.Labels{Values: launchPlanLabels},\n\t\t\t\tAnnotations: &admin.Annotations{Values: launchPlanAnnotations},\n\t\t\t\tRawOutputDataConfig: &admin.RawOutputDataConfig{\n\t\t\t\t\tOutputLocationPrefix: launchPlanOutputLocationPrefix,\n\t\t\t\t},\n\t\t\t\tSecurityContext: &core.SecurityContext{\n\t\t\t\t\tRunAs: &core.Identity{\n\t\t\t\t\t\tK8SServiceAccount: launchPlanK8sServiceAccount,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tMaxParallelism: launchPlanMaxParallelism,\n\t\t\t\tInterruptible:  &wrappers.BoolValue{Value: launchPlanInterruptible},\n\t\t\t\tOverwriteCache: launchPlanOverwriteCache,\n\t\t\t\tEnvs:           &admin.Envs{Values: launchPlanEnvironmentVariables},\n\t\t\t},\n\t\t}\n\t\texecConfig, err := executionManager.getExecutionConfig(context.TODO(), request, launchPlan)\n\t\tassert.NoError(t, err)\n\t\tassert.Equal(t, launchPlanMaxParallelism, execConfig.MaxParallelism)\n\t\tassert.Equal(t, launchPlanInterruptible, execConfig.Interruptible.Value)\n\t\tassert.Equal(t, launchPlanOverwriteCache, execConfig.OverwriteCache)\n\t\tassert.Equal(t, launchPlanK8sServiceAccount, execConfig.SecurityContext.RunAs.K8SServiceAccount)\n\t\tassert.Equal(t, launchPlanOutputLocationPrefix, execConfig.RawOutputDataConfig.OutputLocationPrefix)\n\t\tassert.Equal(t, launchPlanLabels, execConfig.GetLabels().Values)\n\t\tassert.Equal(t, launchPlanAnnotations, execConfig.GetAnnotations().Values)\n\t\tassert.Equal(t, launchPlanEnvironmentVariables, execConfig.GetEnvs().Values)\n\t})\n\tt.Run(\"launchplan with partial config\", func(t *testing.T) {\n\t\trequest := &admin.ExecutionCreateRequest{\n\t\t\tProject: workflowIdentifier.Project,\n\t\t\tDomain:  workflowIdentifier.Domain,\n\t\t\tSpec:    &admin.ExecutionSpec{},\n\t\t}\n\t\tlaunchPlan := &admin.LaunchPlan{\n\t\t\tSpec: &admin.LaunchPlanSpec{\n\t\t\t\tLabels:      &admin.Labels{Values: launchPlanLabels},\n\t\t\t\tAnnotations: &admin.Annotations{Values: launchPlanAnnotations},\n\t\t\t\tRawOutputDataConfig: &admin.RawOutputDataConfig{\n\t\t\t\t\tOutputLocationPrefix: launchPlanOutputLocationPrefix,\n\t\t\t\t},\n\t\t\t\tSecurityContext: &core.SecurityContext{\n\t\t\t\t\tRunAs: &core.Identity{\n\t\t\t\t\t\tK8SServiceAccount: launchPlanK8sServiceAccount,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tMaxParallelism: launchPlanMaxParallelism,\n\t\t\t},\n\t\t}\n\t\texecConfig, err := executionManager.getExecutionConfig(context.TODO(), request, launchPlan)\n\t\tassert.NoError(t, err)\n\t\tassert.Equal(t, launchPlanMaxParallelism, execConfig.MaxParallelism)\n\t\tassert.Equal(t, rmInterruptible, execConfig.Interruptible.Value)\n\t\tassert.Equal(t, rmOverwriteCache, execConfig.OverwriteCache)\n\t\tassert.Equal(t, launchPlanK8sServiceAccount, execConfig.SecurityContext.RunAs.K8SServiceAccount)\n\t\tassert.Equal(t, launchPlanOutputLocationPrefix, execConfig.RawOutputDataConfig.OutputLocationPrefix)\n\t\tassert.Equal(t, launchPlanLabels, execConfig.GetLabels().Values)\n\t\tassert.Equal(t, launchPlanAnnotations, execConfig.GetAnnotations().Values)\n\t})\n\tt.Run(\"launchplan with no config\", func(t *testing.T) {\n\t\trequest := &admin.ExecutionCreateRequest{\n\t\t\tProject: workflowIdentifier.Project,\n\t\t\tDomain:  workflowIdentifier.Domain,\n\t\t\tSpec:    &admin.ExecutionSpec{},\n\t\t}\n\t\tlaunchPlan := &admin.LaunchPlan{\n\t\t\tSpec: &admin.LaunchPlanSpec{},\n\t\t}\n\t\texecConfig, err := executionManager.getExecutionConfig(context.TODO(), request, launchPlan)\n\t\tassert.NoError(t, err)\n\t\tassert.Equal(t, rmMaxParallelism, execConfig.MaxParallelism)\n\t\tassert.Equal(t, rmInterruptible, execConfig.Interruptible.Value)\n\t\tassert.Equal(t, rmOverwriteCache, execConfig.OverwriteCache)\n\t\tassert.Equal(t, rmK8sServiceAccount, execConfig.SecurityContext.RunAs.K8SServiceAccount)\n\t\tassert.Equal(t, rmOutputLocationPrefix, execConfig.RawOutputDataConfig.OutputLocationPrefix)\n\t\tassert.Equal(t, rmLabels, execConfig.GetLabels().Values)\n\t\tassert.Equal(t, rmAnnotations, execConfig.GetAnnotations().Values)\n\t\tassert.Nil(t, execConfig.GetEnvs())\n\t})\n\tt.Run(\"matchable resource partial config\", func(t *testing.T) {\n\t\tresourceManager.GetResourceFunc = func(ctx context.Context,\n\t\t\trequest managerInterfaces.ResourceRequest) (*managerInterfaces.ResourceResponse, error) {\n\t\t\tassert.Contains(t, []managerInterfaces.ResourceRequest{{\n\t\t\t\tProject:      workflowIdentifier.Project,\n\t\t\t\tDomain:       workflowIdentifier.Domain,\n\t\t\t\tResourceType: admin.MatchableResource_WORKFLOW_EXECUTION_CONFIG,\n\t\t\t}, {Project: workflowIdentifier.Project,\n\t\t\t\tDomain:       \"\",\n\t\t\t\tResourceType: admin.MatchableResource_WORKFLOW_EXECUTION_CONFIG},\n\t\t\t}, request)\n\n\t\t\treturn &managerInterfaces.ResourceResponse{\n\t\t\t\tAttributes: &admin.MatchingAttributes{\n\t\t\t\t\tTarget: &admin.MatchingAttributes_WorkflowExecutionConfig{\n\t\t\t\t\t\tWorkflowExecutionConfig: &admin.WorkflowExecutionConfig{\n\t\t\t\t\t\t\tMaxParallelism: rmMaxParallelism,\n\t\t\t\t\t\t\tAnnotations:    &admin.Annotations{Values: rmAnnotations},\n\t\t\t\t\t\t\tSecurityContext: &core.SecurityContext{\n\t\t\t\t\t\t\t\tRunAs: &core.Identity{\n\t\t\t\t\t\t\t\t\tK8SServiceAccount: rmK8sServiceAccount,\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t}, nil\n\t\t}\n\t\trequest := &admin.ExecutionCreateRequest{\n\t\t\tProject: workflowIdentifier.Project,\n\t\t\tDomain:  workflowIdentifier.Domain,\n\t\t\tSpec:    &admin.ExecutionSpec{},\n\t\t}\n\t\tlaunchPlan := &admin.LaunchPlan{\n\t\t\tSpec: &admin.LaunchPlanSpec{},\n\t\t}\n\t\texecConfig, err := executionManager.getExecutionConfig(context.TODO(), request, launchPlan)\n\t\tassert.NoError(t, err)\n\t\tassert.Equal(t, rmMaxParallelism, execConfig.MaxParallelism)\n\t\tassert.Nil(t, execConfig.GetInterruptible())\n\t\tassert.False(t, execConfig.OverwriteCache)\n\t\tassert.Equal(t, rmK8sServiceAccount, execConfig.SecurityContext.RunAs.K8SServiceAccount)\n\t\tassert.Nil(t, execConfig.GetRawOutputDataConfig())\n\t\tassert.Nil(t, execConfig.GetLabels())\n\t\tassert.Equal(t, rmAnnotations, execConfig.GetAnnotations().Values)\n\t\tassert.Nil(t, execConfig.GetEnvs())\n\t})\n\tt.Run(\"matchable resource with no config\", func(t *testing.T) {\n\t\tresourceManager.GetResourceFunc = func(ctx context.Context,\n\t\t\trequest managerInterfaces.ResourceRequest) (*managerInterfaces.ResourceResponse, error) {\n\t\t\tassert.Contains(t, []managerInterfaces.ResourceRequest{{\n\t\t\t\tProject:      workflowIdentifier.Project,\n\t\t\t\tDomain:       workflowIdentifier.Domain,\n\t\t\t\tResourceType: admin.MatchableResource_WORKFLOW_EXECUTION_CONFIG,\n\t\t\t}, {Project: workflowIdentifier.Project,\n\t\t\t\tDomain:       \"\",\n\t\t\t\tResourceType: admin.MatchableResource_WORKFLOW_EXECUTION_CONFIG},\n\t\t\t}, request)\n\t\t\treturn &managerInterfaces.ResourceResponse{\n\t\t\t\tAttributes: &admin.MatchingAttributes{\n\t\t\t\t\tTarget: &admin.MatchingAttributes_WorkflowExecutionConfig{\n\t\t\t\t\t\tWorkflowExecutionConfig: &admin.WorkflowExecutionConfig{},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t}, nil\n\t\t}\n\t\trequest := &admin.ExecutionCreateRequest{\n\t\t\tProject: workflowIdentifier.Project,\n\t\t\tDomain:  workflowIdentifier.Domain,\n\t\t\tSpec:    &admin.ExecutionSpec{},\n\t\t}\n\t\tlaunchPlan := &admin.LaunchPlan{\n\t\t\tSpec: &admin.LaunchPlanSpec{},\n\t\t}\n\t\texecConfig, err := executionManager.getExecutionConfig(context.TODO(), request, launchPlan)\n\t\tassert.NoError(t, err)\n\t\tassert.Equal(t, defaultMaxParallelism, execConfig.MaxParallelism)\n\t\tassert.Nil(t, execConfig.GetInterruptible())\n\t\tassert.False(t, execConfig.OverwriteCache)\n\t\tassert.Equal(t, defaultK8sServiceAccount, execConfig.SecurityContext.RunAs.K8SServiceAccount)\n\t\tassert.Nil(t, execConfig.GetRawOutputDataConfig())\n\t\tassert.Nil(t, execConfig.GetLabels())\n\t\tassert.Nil(t, execConfig.GetAnnotations())\n\t\tassert.Nil(t, execConfig.GetEnvs())\n\t})\n\tt.Run(\"fetch security context from deprecated config\", func(t *testing.T) {\n\t\tresourceManager.GetResourceFunc = func(ctx context.Context,\n\t\t\trequest managerInterfaces.ResourceRequest) (*managerInterfaces.ResourceResponse, error) {\n\t\t\tassert.Contains(t, []managerInterfaces.ResourceRequest{{\n\t\t\t\tProject:      workflowIdentifier.Project,\n\t\t\t\tDomain:       workflowIdentifier.Domain,\n\t\t\t\tResourceType: admin.MatchableResource_WORKFLOW_EXECUTION_CONFIG,\n\t\t\t}, {Project: workflowIdentifier.Project,\n\t\t\t\tDomain:       \"\",\n\t\t\t\tResourceType: admin.MatchableResource_WORKFLOW_EXECUTION_CONFIG},\n\t\t\t}, request)\n\n\t\t\treturn &managerInterfaces.ResourceResponse{\n\t\t\t\tAttributes: &admin.MatchingAttributes{\n\t\t\t\t\tTarget: &admin.MatchingAttributes_WorkflowExecutionConfig{\n\t\t\t\t\t\tWorkflowExecutionConfig: &admin.WorkflowExecutionConfig{},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t}, nil\n\t\t}\n\t\trequest := &admin.ExecutionCreateRequest{\n\t\t\tProject: workflowIdentifier.Project,\n\t\t\tDomain:  workflowIdentifier.Domain,\n\t\t\tSpec:    &admin.ExecutionSpec{},\n\t\t}\n\t\tlaunchPlan := &admin.LaunchPlan{\n\t\t\tSpec: &admin.LaunchPlanSpec{\n\t\t\t\tAuthRole: &admin.AuthRole{\n\t\t\t\t\tKubernetesServiceAccount: deprecatedLaunchPlanK8sServiceAccount,\n\t\t\t\t},\n\t\t\t},\n\t\t}\n\t\texecConfig, err := executionManager.getExecutionConfig(context.TODO(), request, launchPlan)\n\t\tassert.NoError(t, err)\n\t\tassert.Equal(t, defaultMaxParallelism, execConfig.MaxParallelism)\n\t\tassert.Nil(t, execConfig.GetInterruptible())\n\t\tassert.False(t, execConfig.OverwriteCache)\n\t\tassert.Equal(t, deprecatedLaunchPlanK8sServiceAccount, execConfig.SecurityContext.RunAs.K8SServiceAccount)\n\t\tassert.Nil(t, execConfig.GetRawOutputDataConfig())\n\t\tassert.Nil(t, execConfig.GetLabels())\n\t\tassert.Nil(t, execConfig.GetAnnotations())\n\t\tassert.Nil(t, execConfig.GetEnvs())\n\t})\n\tt.Run(\"matchable resource workflow resource\", func(t *testing.T) {\n\t\tresourceManager.GetResourceFunc = func(ctx context.Context,\n\t\t\trequest managerInterfaces.ResourceRequest) (*managerInterfaces.ResourceResponse, error) {\n\t\t\tassert.Contains(t, []managerInterfaces.ResourceRequest{{\n\t\t\t\tProject:      workflowIdentifier.Project,\n\t\t\t\tDomain:       workflowIdentifier.Domain,\n\t\t\t\tResourceType: admin.MatchableResource_WORKFLOW_EXECUTION_CONFIG,\n\t\t\t\tWorkflow:     workflowIdentifier.Name,\n\t\t\t}, {Project: workflowIdentifier.Project,\n\t\t\t\tDomain:       \"\",\n\t\t\t\tWorkflow:     \"\",\n\t\t\t\tResourceType: admin.MatchableResource_WORKFLOW_EXECUTION_CONFIG},\n\t\t\t}, request)\n\n\t\t\treturn &managerInterfaces.ResourceResponse{\n\t\t\t\tAttributes: &admin.MatchingAttributes{\n\t\t\t\t\tTarget: &admin.MatchingAttributes_WorkflowExecutionConfig{\n\t\t\t\t\t\tWorkflowExecutionConfig: &admin.WorkflowExecutionConfig{\n\t\t\t\t\t\t\tMaxParallelism: 300,\n\t\t\t\t\t\t\tInterruptible:  &wrappers.BoolValue{Value: true},\n\t\t\t\t\t\t\tOverwriteCache: true,\n\t\t\t\t\t\t\tSecurityContext: &core.SecurityContext{\n\t\t\t\t\t\t\t\tRunAs: &core.Identity{\n\t\t\t\t\t\t\t\t\tK8SServiceAccount: \"workflowDefault\",\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t}, nil\n\t\t}\n\t\trequest := &admin.ExecutionCreateRequest{\n\t\t\tProject: workflowIdentifier.Project,\n\t\t\tDomain:  workflowIdentifier.Domain,\n\t\t\tSpec:    &admin.ExecutionSpec{},\n\t\t}\n\t\tlaunchPlan := &admin.LaunchPlan{\n\t\t\tSpec: &admin.LaunchPlanSpec{\n\t\t\t\tWorkflowId: &core.Identifier{\n\t\t\t\t\tName: workflowIdentifier.Name,\n\t\t\t\t},\n\t\t\t},\n\t\t}\n\t\texecConfig, err := executionManager.getExecutionConfig(context.TODO(), request, launchPlan)\n\t\tassert.NoError(t, err)\n\t\tassert.Equal(t, int32(300), execConfig.MaxParallelism)\n\t\tassert.True(t, execConfig.Interruptible.Value)\n\t\tassert.True(t, execConfig.OverwriteCache)\n\t\tassert.Equal(t, \"workflowDefault\", execConfig.SecurityContext.RunAs.K8SServiceAccount)\n\t\tassert.Nil(t, execConfig.GetRawOutputDataConfig())\n\t\tassert.Nil(t, execConfig.GetLabels())\n\t\tassert.Nil(t, execConfig.GetAnnotations())\n\t\tassert.Nil(t, execConfig.GetEnvs())\n\t})\n\tt.Run(\"matchable resource failure\", func(t *testing.T) {\n\t\tresourceManager.GetResourceFunc = func(ctx context.Context,\n\t\t\trequest managerInterfaces.ResourceRequest) (*managerInterfaces.ResourceResponse, error) {\n\t\t\tassert.Contains(t, []managerInterfaces.ResourceRequest{{\n\t\t\t\tProject:      workflowIdentifier.Project,\n\t\t\t\tDomain:       workflowIdentifier.Domain,\n\t\t\t\tResourceType: admin.MatchableResource_WORKFLOW_EXECUTION_CONFIG,\n\t\t\t}, {Project: workflowIdentifier.Project,\n\t\t\t\tDomain:       \"\",\n\t\t\t\tResourceType: admin.MatchableResource_WORKFLOW_EXECUTION_CONFIG},\n\t\t\t}, request)\n\t\t\treturn nil, fmt.Errorf(\"failed to fetch the resources\")\n\t\t}\n\t\trequest := &admin.ExecutionCreateRequest{\n\t\t\tProject: workflowIdentifier.Project,\n\t\t\tDomain:  workflowIdentifier.Domain,\n\t\t\tSpec:    &admin.ExecutionSpec{},\n\t\t}\n\t\tlaunchPlan := &admin.LaunchPlan{\n\t\t\tSpec: &admin.LaunchPlanSpec{},\n\t\t}\n\t\texecConfig, err := executionManager.getExecutionConfig(context.TODO(), request, launchPlan)\n\t\tassert.Equal(t, fmt.Errorf(\"failed to fetch the resources\"), err)\n\t\tassert.Nil(t, execConfig.GetInterruptible())\n\t\tassert.False(t, execConfig.GetOverwriteCache())\n\t\tassert.Nil(t, execConfig.GetSecurityContext())\n\t\tassert.Nil(t, execConfig.GetRawOutputDataConfig())\n\t\tassert.Nil(t, execConfig.GetLabels())\n\t\tassert.Nil(t, execConfig.GetAnnotations())\n\t\tassert.Nil(t, execConfig.GetEnvs())\n\t})\n\n\tt.Run(\"application configuration\", func(t *testing.T) {\n\t\tresourceManager.GetResourceFunc = func(ctx context.Context,\n\t\t\trequest managerInterfaces.ResourceRequest) (*managerInterfaces.ResourceResponse, error) {\n\t\t\tassert.Contains(t, []managerInterfaces.ResourceRequest{{\n\t\t\t\tProject:      workflowIdentifier.Project,\n\t\t\t\tDomain:       workflowIdentifier.Domain,\n\t\t\t\tResourceType: admin.MatchableResource_WORKFLOW_EXECUTION_CONFIG,\n\t\t\t}, {Project: workflowIdentifier.Project,\n\t\t\t\tDomain:       \"\",\n\t\t\t\tResourceType: admin.MatchableResource_WORKFLOW_EXECUTION_CONFIG},\n\t\t\t}, request)\n\t\t\treturn &managerInterfaces.ResourceResponse{\n\t\t\t\tAttributes: &admin.MatchingAttributes{\n\t\t\t\t\tTarget: &admin.MatchingAttributes_WorkflowExecutionConfig{\n\t\t\t\t\t\tWorkflowExecutionConfig: &admin.WorkflowExecutionConfig{},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t}, nil\n\t\t}\n\n\t\texecutionManager.config.ApplicationConfiguration().GetTopLevelConfig().Interruptible = true\n\t\texecutionManager.config.ApplicationConfiguration().GetTopLevelConfig().OverwriteCache = true\n\n\t\tt.Run(\"request with interruptible override disabled\", func(t *testing.T) {\n\t\t\trequest := &admin.ExecutionCreateRequest{\n\t\t\t\tProject: workflowIdentifier.Project,\n\t\t\t\tDomain:  workflowIdentifier.Domain,\n\t\t\t\tSpec: &admin.ExecutionSpec{\n\t\t\t\t\tInterruptible: &wrappers.BoolValue{Value: false},\n\t\t\t\t},\n\t\t\t}\n\n\t\t\texecConfig, err := executionManager.getExecutionConfig(context.TODO(), request, nil)\n\t\t\tassert.NoError(t, err)\n\t\t\tassert.Equal(t, defaultMaxParallelism, execConfig.MaxParallelism)\n\t\t\tassert.False(t, execConfig.Interruptible.Value)\n\t\t\tassert.Equal(t, defaultK8sServiceAccount, execConfig.SecurityContext.RunAs.K8SServiceAccount)\n\t\t\tassert.Nil(t, execConfig.GetRawOutputDataConfig())\n\t\t\tassert.Nil(t, execConfig.GetLabels())\n\t\t\tassert.Nil(t, execConfig.GetAnnotations())\n\t\t})\n\t\tt.Run(\"request with interruptible override enabled\", func(t *testing.T) {\n\t\t\trequest := &admin.ExecutionCreateRequest{\n\t\t\t\tProject: workflowIdentifier.Project,\n\t\t\t\tDomain:  workflowIdentifier.Domain,\n\t\t\t\tSpec: &admin.ExecutionSpec{\n\t\t\t\t\tInterruptible: &wrappers.BoolValue{Value: true},\n\t\t\t\t},\n\t\t\t}\n\n\t\t\texecConfig, err := executionManager.getExecutionConfig(context.TODO(), request, nil)\n\t\t\tassert.NoError(t, err)\n\t\t\tassert.Equal(t, defaultMaxParallelism, execConfig.MaxParallelism)\n\t\t\tassert.True(t, execConfig.Interruptible.Value)\n\t\t\tassert.Equal(t, defaultK8sServiceAccount, execConfig.SecurityContext.RunAs.K8SServiceAccount)\n\t\t\tassert.Nil(t, execConfig.GetRawOutputDataConfig())\n\t\t\tassert.Nil(t, execConfig.GetLabels())\n\t\t\tassert.Nil(t, execConfig.GetAnnotations())\n\t\t})\n\t\tt.Run(\"request with no interruptible override specified\", func(t *testing.T) {\n\t\t\trequest := &admin.ExecutionCreateRequest{\n\t\t\t\tProject: workflowIdentifier.Project,\n\t\t\t\tDomain:  workflowIdentifier.Domain,\n\t\t\t\tSpec:    &admin.ExecutionSpec{},\n\t\t\t}\n\n\t\t\texecConfig, err := executionManager.getExecutionConfig(context.TODO(), request, nil)\n\t\t\tassert.NoError(t, err)\n\t\t\tassert.Equal(t, defaultMaxParallelism, execConfig.MaxParallelism)\n\t\t\tassert.True(t, execConfig.Interruptible.Value)\n\t\t\tassert.Equal(t, defaultK8sServiceAccount, execConfig.SecurityContext.RunAs.K8SServiceAccount)\n\t\t\tassert.Nil(t, execConfig.GetRawOutputDataConfig())\n\t\t\tassert.Nil(t, execConfig.GetLabels())\n\t\t\tassert.Nil(t, execConfig.GetAnnotations())\n\t\t})\n\t\tt.Run(\"launch plan with interruptible override disabled\", func(t *testing.T) {\n\t\t\trequest := &admin.ExecutionCreateRequest{\n\t\t\t\tProject: workflowIdentifier.Project,\n\t\t\t\tDomain:  workflowIdentifier.Domain,\n\t\t\t\tSpec:    &admin.ExecutionSpec{},\n\t\t\t}\n\n\t\t\tlaunchPlan := &admin.LaunchPlan{\n\t\t\t\tSpec: &admin.LaunchPlanSpec{\n\t\t\t\t\tInterruptible: &wrappers.BoolValue{Value: false},\n\t\t\t\t},\n\t\t\t}\n\n\t\t\texecConfig, err := executionManager.getExecutionConfig(context.TODO(), request, launchPlan)\n\t\t\tassert.NoError(t, err)\n\t\t\tassert.Equal(t, defaultMaxParallelism, execConfig.MaxParallelism)\n\t\t\tassert.False(t, execConfig.Interruptible.Value)\n\t\t\tassert.Equal(t, defaultK8sServiceAccount, execConfig.SecurityContext.RunAs.K8SServiceAccount)\n\t\t\tassert.Nil(t, execConfig.GetRawOutputDataConfig())\n\t\t\tassert.Nil(t, execConfig.GetLabels())\n\t\t\tassert.Nil(t, execConfig.GetAnnotations())\n\t\t})\n\t\tt.Run(\"launch plan with interruptible override enabled\", func(t *testing.T) {\n\t\t\trequest := &admin.ExecutionCreateRequest{\n\t\t\t\tProject: workflowIdentifier.Project,\n\t\t\t\tDomain:  workflowIdentifier.Domain,\n\t\t\t\tSpec:    &admin.ExecutionSpec{},\n\t\t\t}\n\n\t\t\tlaunchPlan := &admin.LaunchPlan{\n\t\t\t\tSpec: &admin.LaunchPlanSpec{\n\t\t\t\t\tInterruptible: &wrappers.BoolValue{Value: true},\n\t\t\t\t\tEnvs:          &admin.Envs{Values: []*core.KeyValuePair{{Key: \"foo\", Value: \"bar\"}}},\n\t\t\t\t},\n\t\t\t}\n\n\t\t\texecConfig, err := executionManager.getExecutionConfig(context.TODO(), request, launchPlan)\n\t\t\tassert.NoError(t, err)\n\t\t\tassert.Equal(t, defaultMaxParallelism, execConfig.MaxParallelism)\n\t\t\tassert.True(t, execConfig.Interruptible.Value)\n\t\t\tassert.Equal(t, defaultK8sServiceAccount, execConfig.SecurityContext.RunAs.K8SServiceAccount)\n\t\t\tassert.Nil(t, execConfig.GetRawOutputDataConfig())\n\t\t\tassert.Nil(t, execConfig.GetLabels())\n\t\t\tassert.Nil(t, execConfig.GetAnnotations())\n\t\t\tassert.Equal(t, 1, len(execConfig.Envs.Values))\n\t\t\tassert.Equal(t, \"foo\", execConfig.Envs.Values[0].Key)\n\t\t\tassert.Equal(t, \"bar\", execConfig.Envs.Values[0].Value)\n\t\t})\n\t\tt.Run(\"launch plan with no interruptible override specified\", func(t *testing.T) {\n\t\t\trequest := &admin.ExecutionCreateRequest{\n\t\t\t\tProject: workflowIdentifier.Project,\n\t\t\t\tDomain:  workflowIdentifier.Domain,\n\t\t\t\tSpec:    &admin.ExecutionSpec{},\n\t\t\t}\n\n\t\t\tlaunchPlan := &admin.LaunchPlan{\n\t\t\t\tSpec: &admin.LaunchPlanSpec{},\n\t\t\t}\n\n\t\t\texecConfig, err := executionManager.getExecutionConfig(context.TODO(), request, launchPlan)\n\t\t\tassert.NoError(t, err)\n\t\t\tassert.Equal(t, defaultMaxParallelism, execConfig.MaxParallelism)\n\t\t\tassert.True(t, execConfig.Interruptible.Value)\n\t\t\tassert.Equal(t, defaultK8sServiceAccount, execConfig.SecurityContext.RunAs.K8SServiceAccount)\n\t\t\tassert.Nil(t, execConfig.GetRawOutputDataConfig())\n\t\t\tassert.Nil(t, execConfig.GetLabels())\n\t\t\tassert.Nil(t, execConfig.GetAnnotations())\n\t\t})\n\t\tt.Run(\"request and launch plan with different interruptible overrides\", func(t *testing.T) {\n\t\t\trequest := &admin.ExecutionCreateRequest{\n\t\t\t\tProject: workflowIdentifier.Project,\n\t\t\t\tDomain:  workflowIdentifier.Domain,\n\t\t\t\tSpec: &admin.ExecutionSpec{\n\t\t\t\t\tInterruptible: &wrappers.BoolValue{Value: true},\n\t\t\t\t},\n\t\t\t}\n\n\t\t\tlaunchPlan := &admin.LaunchPlan{\n\t\t\t\tSpec: &admin.LaunchPlanSpec{\n\t\t\t\t\tInterruptible: &wrappers.BoolValue{Value: false},\n\t\t\t\t},\n\t\t\t}\n\n\t\t\texecConfig, err := executionManager.getExecutionConfig(context.TODO(), request, launchPlan)\n\t\t\tassert.NoError(t, err)\n\t\t\tassert.Equal(t, defaultMaxParallelism, execConfig.MaxParallelism)\n\t\t\tassert.True(t, execConfig.Interruptible.Value)\n\t\t\tassert.Equal(t, defaultK8sServiceAccount, execConfig.SecurityContext.RunAs.K8SServiceAccount)\n\t\t\tassert.Nil(t, execConfig.GetRawOutputDataConfig())\n\t\t\tassert.Nil(t, execConfig.GetLabels())\n\t\t\tassert.Nil(t, execConfig.GetAnnotations())\n\t\t})\n\t\tt.Run(\"request with skip cache override enabled\", func(t *testing.T) {\n\t\t\trequest := &admin.ExecutionCreateRequest{\n\t\t\t\tProject: workflowIdentifier.Project,\n\t\t\t\tDomain:  workflowIdentifier.Domain,\n\t\t\t\tSpec: &admin.ExecutionSpec{\n\t\t\t\t\tOverwriteCache: true,\n\t\t\t\t},\n\t\t\t}\n\n\t\t\texecConfig, err := executionManager.getExecutionConfig(context.TODO(), request, nil)\n\t\t\tassert.NoError(t, err)\n\t\t\tassert.Equal(t, defaultMaxParallelism, execConfig.MaxParallelism)\n\t\t\tassert.True(t, execConfig.OverwriteCache)\n\t\t\tassert.Equal(t, defaultK8sServiceAccount, execConfig.SecurityContext.RunAs.K8SServiceAccount)\n\t\t\tassert.Nil(t, execConfig.GetRawOutputDataConfig())\n\t\t\tassert.Nil(t, execConfig.GetLabels())\n\t\t\tassert.Nil(t, execConfig.GetAnnotations())\n\t\t})\n\t\tt.Run(\"request with no skip cache override specified\", func(t *testing.T) {\n\t\t\trequest := &admin.ExecutionCreateRequest{\n\t\t\t\tProject: workflowIdentifier.Project,\n\t\t\t\tDomain:  workflowIdentifier.Domain,\n\t\t\t\tSpec:    &admin.ExecutionSpec{},\n\t\t\t}\n\n\t\t\texecConfig, err := executionManager.getExecutionConfig(context.TODO(), request, nil)\n\t\t\tassert.NoError(t, err)\n\t\t\tassert.Equal(t, defaultMaxParallelism, execConfig.MaxParallelism)\n\t\t\tassert.True(t, execConfig.OverwriteCache)\n\t\t\tassert.Equal(t, defaultK8sServiceAccount, execConfig.SecurityContext.RunAs.K8SServiceAccount)\n\t\t\tassert.Nil(t, execConfig.GetRawOutputDataConfig())\n\t\t\tassert.Nil(t, execConfig.GetLabels())\n\t\t\tassert.Nil(t, execConfig.GetAnnotations())\n\t\t})\n\t\tt.Run(\"launch plan with skip cache override enabled\", func(t *testing.T) {\n\t\t\trequest := &admin.ExecutionCreateRequest{\n\t\t\t\tProject: workflowIdentifier.Project,\n\t\t\t\tDomain:  workflowIdentifier.Domain,\n\t\t\t\tSpec:    &admin.ExecutionSpec{},\n\t\t\t}\n\n\t\t\tlaunchPlan := &admin.LaunchPlan{\n\t\t\t\tSpec: &admin.LaunchPlanSpec{\n\t\t\t\t\tOverwriteCache: true,\n\t\t\t\t},\n\t\t\t}\n\n\t\t\texecConfig, err := executionManager.getExecutionConfig(context.TODO(), request, launchPlan)\n\t\t\tassert.NoError(t, err)\n\t\t\tassert.Equal(t, defaultMaxParallelism, execConfig.MaxParallelism)\n\t\t\tassert.True(t, execConfig.OverwriteCache)\n\t\t\tassert.Equal(t, defaultK8sServiceAccount, execConfig.SecurityContext.RunAs.K8SServiceAccount)\n\t\t\tassert.Nil(t, execConfig.GetRawOutputDataConfig())\n\t\t\tassert.Nil(t, execConfig.GetLabels())\n\t\t\tassert.Nil(t, execConfig.GetAnnotations())\n\t\t})\n\t\tt.Run(\"launch plan with no skip cache override specified\", func(t *testing.T) {\n\t\t\trequest := &admin.ExecutionCreateRequest{\n\t\t\t\tProject: workflowIdentifier.Project,\n\t\t\t\tDomain:  workflowIdentifier.Domain,\n\t\t\t\tSpec:    &admin.ExecutionSpec{},\n\t\t\t}\n\n\t\t\tlaunchPlan := &admin.LaunchPlan{\n\t\t\t\tSpec: &admin.LaunchPlanSpec{},\n\t\t\t}\n\n\t\t\texecConfig, err := executionManager.getExecutionConfig(context.TODO(), request, launchPlan)\n\t\t\tassert.NoError(t, err)\n\t\t\tassert.Equal(t, defaultMaxParallelism, execConfig.MaxParallelism)\n\t\t\tassert.True(t, execConfig.OverwriteCache)\n\t\t\tassert.Equal(t, defaultK8sServiceAccount, execConfig.SecurityContext.RunAs.K8SServiceAccount)\n\t\t\tassert.Nil(t, execConfig.GetRawOutputDataConfig())\n\t\t\tassert.Nil(t, execConfig.GetLabels())\n\t\t\tassert.Nil(t, execConfig.GetAnnotations())\n\t\t})\n\t\tt.Run(\"request and launch plan with different skip cache overrides\", func(t *testing.T) {\n\t\t\trequest := &admin.ExecutionCreateRequest{\n\t\t\t\tProject: workflowIdentifier.Project,\n\t\t\t\tDomain:  workflowIdentifier.Domain,\n\t\t\t\tSpec: &admin.ExecutionSpec{\n\t\t\t\t\tOverwriteCache: true,\n\t\t\t\t},\n\t\t\t}\n\n\t\t\tlaunchPlan := &admin.LaunchPlan{\n\t\t\t\tSpec: &admin.LaunchPlanSpec{\n\t\t\t\t\tOverwriteCache: false,\n\t\t\t\t},\n\t\t\t}\n\n\t\t\texecConfig, err := executionManager.getExecutionConfig(context.TODO(), request, launchPlan)\n\t\t\tassert.NoError(t, err)\n\t\t\tassert.Equal(t, defaultMaxParallelism, execConfig.MaxParallelism)\n\t\t\tassert.True(t, execConfig.OverwriteCache)\n\t\t\tassert.Equal(t, defaultK8sServiceAccount, execConfig.SecurityContext.RunAs.K8SServiceAccount)\n\t\t\tassert.Nil(t, execConfig.GetRawOutputDataConfig())\n\t\t\tassert.Nil(t, execConfig.GetLabels())\n\t\t\tassert.Nil(t, execConfig.GetAnnotations())\n\t\t})\n\n\t\tt.Run(\"test pick up security context from admin system config\", func(t *testing.T) {\n\t\t\texecutionManager.config.ApplicationConfiguration().GetTopLevelConfig().K8SServiceAccount = \"flyte-test\"\n\t\t\trequest := &admin.ExecutionCreateRequest{\n\t\t\t\tProject: workflowIdentifier.Project,\n\t\t\t\tDomain:  workflowIdentifier.Domain,\n\t\t\t\tSpec:    &admin.ExecutionSpec{},\n\t\t\t}\n\t\t\texecConfig, err := executionManager.getExecutionConfig(context.TODO(), request, nil)\n\t\t\tassert.NoError(t, err)\n\t\t\tassert.Equal(t, \"flyte-test\", execConfig.SecurityContext.RunAs.K8SServiceAccount)\n\t\t\texecutionManager.config.ApplicationConfiguration().GetTopLevelConfig().K8SServiceAccount = defaultK8sServiceAccount\n\t\t})\n\t})\n}\n\nfunc TestGetExecutionConfig(t *testing.T) {\n\tresourceManager := managerMocks.MockResourceManager{}\n\tresourceManager.GetResourceFunc = func(ctx context.Context,\n\t\trequest managerInterfaces.ResourceRequest) (*managerInterfaces.ResourceResponse, error) {\n\t\tassert.Contains(t, []managerInterfaces.ResourceRequest{{\n\t\t\tProject:      workflowIdentifier.Project,\n\t\t\tDomain:       workflowIdentifier.Domain,\n\t\t\tResourceType: admin.MatchableResource_WORKFLOW_EXECUTION_CONFIG,\n\t\t}, {Project: workflowIdentifier.Project,\n\t\t\tDomain:       \"\",\n\t\t\tResourceType: admin.MatchableResource_WORKFLOW_EXECUTION_CONFIG},\n\t\t}, request)\n\t\treturn &managerInterfaces.ResourceResponse{\n\t\t\tAttributes: &admin.MatchingAttributes{\n\t\t\t\tTarget: &admin.MatchingAttributes_WorkflowExecutionConfig{\n\t\t\t\t\tWorkflowExecutionConfig: &admin.WorkflowExecutionConfig{\n\t\t\t\t\t\tMaxParallelism: 100,\n\t\t\t\t\t\tOverwriteCache: true,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t}, nil\n\t}\n\n\tapplicationConfig := runtime.NewConfigurationProvider()\n\texecutionManager := ExecutionManager{\n\t\tresourceManager: &resourceManager,\n\t\tconfig:          applicationConfig,\n\t}\n\texecConfig, err := executionManager.getExecutionConfig(context.TODO(), &admin.ExecutionCreateRequest{\n\t\tProject: workflowIdentifier.Project,\n\t\tDomain:  workflowIdentifier.Domain,\n\t\tSpec:    &admin.ExecutionSpec{},\n\t}, nil)\n\tassert.NoError(t, err)\n\tassert.Equal(t, execConfig.MaxParallelism, int32(100))\n\tassert.True(t, execConfig.OverwriteCache)\n}\n\nfunc TestGetExecutionConfig_Spec(t *testing.T) {\n\tresourceManager := managerMocks.MockResourceManager{}\n\tresourceManager.GetResourceFunc = func(ctx context.Context,\n\t\trequest managerInterfaces.ResourceRequest) (*managerInterfaces.ResourceResponse, error) {\n\t\treturn nil, nil\n\t}\n\tapplicationConfig := runtime.NewConfigurationProvider()\n\texecutionManager := ExecutionManager{\n\t\tresourceManager: &resourceManager,\n\t\tconfig:          applicationConfig,\n\t}\n\texecConfig, err := executionManager.getExecutionConfig(context.TODO(), &admin.ExecutionCreateRequest{\n\t\tProject: workflowIdentifier.Project,\n\t\tDomain:  workflowIdentifier.Domain,\n\t\tSpec: &admin.ExecutionSpec{\n\t\t\tMaxParallelism: 100,\n\t\t\tOverwriteCache: true,\n\t\t},\n\t}, &admin.LaunchPlan{\n\t\tSpec: &admin.LaunchPlanSpec{\n\t\t\tMaxParallelism: 50,\n\t\t\tOverwriteCache: false, // explicitly set to false for clarity\n\t\t},\n\t})\n\tassert.NoError(t, err)\n\tassert.Equal(t, int32(100), execConfig.MaxParallelism)\n\tassert.True(t, execConfig.OverwriteCache)\n\n\texecConfig, err = executionManager.getExecutionConfig(context.TODO(), &admin.ExecutionCreateRequest{\n\t\tProject: workflowIdentifier.Project,\n\t\tDomain:  workflowIdentifier.Domain,\n\t\tSpec:    &admin.ExecutionSpec{},\n\t}, &admin.LaunchPlan{\n\t\tSpec: &admin.LaunchPlanSpec{\n\t\t\tMaxParallelism: 50,\n\t\t\tOverwriteCache: true,\n\t\t},\n\t})\n\tassert.NoError(t, err)\n\tassert.Equal(t, int32(50), execConfig.MaxParallelism)\n\tassert.True(t, execConfig.OverwriteCache)\n\n\tresourceManager = managerMocks.MockResourceManager{}\n\tresourceManager.GetResourceFunc = func(ctx context.Context,\n\t\trequest managerInterfaces.ResourceRequest) (*managerInterfaces.ResourceResponse, error) {\n\t\treturn nil, nil\n\t}\n\texecutionManager = ExecutionManager{\n\t\tresourceManager: &resourceManager,\n\t\tconfig:          applicationConfig,\n\t}\n\n\texecutionManager.config.ApplicationConfiguration().GetTopLevelConfig().OverwriteCache = true\n\n\texecConfig, err = executionManager.getExecutionConfig(context.TODO(), &admin.ExecutionCreateRequest{\n\t\tProject: workflowIdentifier.Project,\n\t\tDomain:  workflowIdentifier.Domain,\n\t\tSpec:    &admin.ExecutionSpec{},\n\t}, &admin.LaunchPlan{\n\t\tSpec: &admin.LaunchPlanSpec{},\n\t})\n\tassert.NoError(t, err)\n\tassert.Equal(t, execConfig.MaxParallelism, int32(25))\n\tassert.True(t, execConfig.OverwriteCache)\n}\n\nfunc TestGetClusterAssignment(t *testing.T) {\n\tclusterAssignment := admin.ClusterAssignment{ClusterPoolName: \"gpu\"}\n\tresourceManager := managerMocks.MockResourceManager{}\n\tresourceManager.GetResourceFunc = func(ctx context.Context,\n\t\trequest managerInterfaces.ResourceRequest) (*managerInterfaces.ResourceResponse, error) {\n\t\tassert.EqualValues(t, request, managerInterfaces.ResourceRequest{\n\t\t\tProject:      workflowIdentifier.Project,\n\t\t\tDomain:       workflowIdentifier.Domain,\n\t\t\tResourceType: admin.MatchableResource_CLUSTER_ASSIGNMENT,\n\t\t})\n\t\treturn &managerInterfaces.ResourceResponse{\n\t\t\tAttributes: &admin.MatchingAttributes{\n\t\t\t\tTarget: &admin.MatchingAttributes_ClusterAssignment{\n\t\t\t\t\tClusterAssignment: &clusterAssignment,\n\t\t\t\t},\n\t\t\t},\n\t\t}, nil\n\t}\n\n\texecutionManager := ExecutionManager{\n\t\tresourceManager: &resourceManager,\n\t}\n\tt.Run(\"value from db\", func(t *testing.T) {\n\t\tca, err := executionManager.getClusterAssignment(context.TODO(), &admin.ExecutionCreateRequest{\n\t\t\tProject: workflowIdentifier.Project,\n\t\t\tDomain:  workflowIdentifier.Domain,\n\t\t\tSpec:    &admin.ExecutionSpec{},\n\t\t})\n\t\tassert.NoError(t, err)\n\t\tassert.True(t, proto.Equal(ca, &clusterAssignment))\n\t})\n\tt.Run(\"value from request\", func(t *testing.T) {\n\t\treqClusterAssignment := admin.ClusterAssignment{ClusterPoolName: \"swimming-pool\"}\n\t\tca, err := executionManager.getClusterAssignment(context.TODO(), &admin.ExecutionCreateRequest{\n\t\t\tProject: workflowIdentifier.Project,\n\t\t\tDomain:  workflowIdentifier.Domain,\n\t\t\tSpec: &admin.ExecutionSpec{\n\t\t\t\tClusterAssignment: &reqClusterAssignment,\n\t\t\t},\n\t\t})\n\t\tassert.NoError(t, err)\n\t\tassert.True(t, proto.Equal(ca, &reqClusterAssignment))\n\t})\n\tt.Run(\"value from config\", func(t *testing.T) {\n\t\tcustomCP := \"my_cp\"\n\t\tclusterPoolAsstProvider := &runtimeIFaceMocks.ClusterPoolAssignmentConfiguration{}\n\t\tclusterPoolAsstProvider.OnGetClusterPoolAssignments().Return(runtimeInterfaces.ClusterPoolAssignments{\n\t\t\tworkflowIdentifier.GetDomain(): runtimeInterfaces.ClusterPoolAssignment{\n\t\t\t\tPool: customCP,\n\t\t\t},\n\t\t})\n\t\tmockConfig := getMockExecutionsConfigProvider()\n\t\tmockConfig.(*runtimeMocks.MockConfigurationProvider).AddClusterPoolAssignmentConfiguration(clusterPoolAsstProvider)\n\n\t\texecutionManager := ExecutionManager{\n\t\t\tresourceManager: &managerMocks.MockResourceManager{},\n\t\t\tconfig:          mockConfig,\n\t\t}\n\n\t\tca, err := executionManager.getClusterAssignment(context.TODO(), &admin.ExecutionCreateRequest{\n\t\t\tProject: workflowIdentifier.Project,\n\t\t\tDomain:  workflowIdentifier.Domain,\n\t\t\tSpec:    &admin.ExecutionSpec{},\n\t\t})\n\t\tassert.NoError(t, err)\n\t\tassert.Equal(t, customCP, ca.GetClusterPoolName())\n\t})\n}\n\nfunc TestResolvePermissions(t *testing.T) {\n\tassumableIamRole := \"role\"\n\tk8sServiceAccount := \"sa\"\n\n\tassumableIamRoleLp := \"roleLp\"\n\tk8sServiceAccountLp := \"saLp\"\n\n\tassumableIamRoleSc := \"roleSc\"\n\tk8sServiceAccountSc := \"saSc\"\n\n\tt.Run(\"backward compat use request values from auth\", func(t *testing.T) {\n\t\texecRequest := &admin.ExecutionCreateRequest{\n\t\t\tSpec: &admin.ExecutionSpec{\n\t\t\t\tAuthRole: &admin.AuthRole{\n\t\t\t\t\tAssumableIamRole:         assumableIamRole,\n\t\t\t\t\tKubernetesServiceAccount: k8sServiceAccount,\n\t\t\t\t},\n\t\t\t},\n\t\t}\n\t\tlp := &admin.LaunchPlan{\n\t\t\tSpec: &admin.LaunchPlanSpec{\n\t\t\t\tAuthRole: &admin.AuthRole{\n\t\t\t\t\tAssumableIamRole:         \"lp role\",\n\t\t\t\t\tKubernetesServiceAccount: \"k8s sa\",\n\t\t\t\t},\n\t\t\t},\n\t\t}\n\t\texecConfigSecCtx := &core.SecurityContext{\n\t\t\tRunAs: &core.Identity{\n\t\t\t\tIamRole:           assumableIamRole,\n\t\t\t\tK8SServiceAccount: k8sServiceAccount,\n\t\t\t},\n\t\t}\n\t\tauthRole := resolveAuthRole(execRequest, lp)\n\t\tsc := resolveSecurityCtx(context.TODO(), execConfigSecCtx, authRole)\n\t\tassert.Equal(t, assumableIamRole, authRole.AssumableIamRole)\n\t\tassert.Equal(t, k8sServiceAccount, authRole.KubernetesServiceAccount)\n\t\tassert.Equal(t, &core.SecurityContext{\n\t\t\tRunAs: &core.Identity{\n\t\t\t\tIamRole:           assumableIamRole,\n\t\t\t\tK8SServiceAccount: k8sServiceAccount,\n\t\t\t}}, sc)\n\t})\n\tt.Run(\"use request values security context\", func(t *testing.T) {\n\t\texecRequest := &admin.ExecutionCreateRequest{\n\t\t\tSpec: &admin.ExecutionSpec{\n\t\t\t\tSecurityContext: &core.SecurityContext{\n\t\t\t\t\tRunAs: &core.Identity{\n\t\t\t\t\t\tIamRole:           assumableIamRoleSc,\n\t\t\t\t\t\tK8SServiceAccount: k8sServiceAccountSc,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t}\n\t\tlp := &admin.LaunchPlan{\n\t\t\tSpec: &admin.LaunchPlanSpec{\n\t\t\t\tSecurityContext: &core.SecurityContext{\n\t\t\t\t\tRunAs: &core.Identity{\n\t\t\t\t\t\tIamRole:           assumableIamRoleSc,\n\t\t\t\t\t\tK8SServiceAccount: k8sServiceAccountSc,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t}\n\t\tauthRole := resolveAuthRole(execRequest, lp)\n\t\texecConfigSecCtx := &core.SecurityContext{\n\t\t\tRunAs: &core.Identity{\n\t\t\t\tIamRole:           assumableIamRoleSc,\n\t\t\t\tK8SServiceAccount: k8sServiceAccountSc,\n\t\t\t},\n\t\t}\n\t\tsc := resolveSecurityCtx(context.TODO(), execConfigSecCtx, authRole)\n\t\tassert.Equal(t, \"\", authRole.AssumableIamRole)\n\t\tassert.Equal(t, \"\", authRole.KubernetesServiceAccount)\n\t\tassert.Equal(t, assumableIamRoleSc, sc.RunAs.IamRole)\n\t\tassert.Equal(t, k8sServiceAccountSc, sc.RunAs.K8SServiceAccount)\n\t})\n\tt.Run(\"prefer lp auth role over auth\", func(t *testing.T) {\n\t\texecRequest := &admin.ExecutionCreateRequest{\n\t\t\tSpec: &admin.ExecutionSpec{},\n\t\t}\n\t\tlp := &admin.LaunchPlan{\n\t\t\tSpec: &admin.LaunchPlanSpec{\n\t\t\t\tAuthRole: &admin.AuthRole{\n\t\t\t\t\tAssumableIamRole:         assumableIamRole,\n\t\t\t\t\tKubernetesServiceAccount: k8sServiceAccount,\n\t\t\t\t},\n\t\t\t\tAuth: &admin.Auth{\n\t\t\t\t\tAssumableIamRole:         \"lp role\",\n\t\t\t\t\tKubernetesServiceAccount: \"k8s sa\",\n\t\t\t\t},\n\t\t\t},\n\t\t}\n\t\tauthRole := resolveAuthRole(execRequest, lp)\n\t\texecConfigSecCtx := &core.SecurityContext{\n\t\t\tRunAs: &core.Identity{},\n\t\t}\n\t\tsc := resolveSecurityCtx(context.TODO(), execConfigSecCtx, authRole)\n\t\tassert.Equal(t, assumableIamRole, authRole.AssumableIamRole)\n\t\tassert.Equal(t, k8sServiceAccount, authRole.KubernetesServiceAccount)\n\t\tassert.Equal(t, &core.SecurityContext{\n\t\t\tRunAs: &core.Identity{\n\t\t\t\tIamRole:           assumableIamRole,\n\t\t\t\tK8SServiceAccount: k8sServiceAccount,\n\t\t\t},\n\t\t}, sc)\n\t})\n\tt.Run(\"prefer security context over auth context\", func(t *testing.T) {\n\t\texecRequest := &admin.ExecutionCreateRequest{\n\t\t\tSpec: &admin.ExecutionSpec{\n\t\t\t\tAuthRole: &admin.AuthRole{\n\t\t\t\t\tAssumableIamRole:         assumableIamRole,\n\t\t\t\t\tKubernetesServiceAccount: k8sServiceAccount,\n\t\t\t\t},\n\t\t\t\tSecurityContext: &core.SecurityContext{\n\t\t\t\t\tRunAs: &core.Identity{\n\t\t\t\t\t\tIamRole:           assumableIamRoleSc,\n\t\t\t\t\t\tK8SServiceAccount: k8sServiceAccountSc,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t}\n\t\tlp := &admin.LaunchPlan{\n\t\t\tSpec: &admin.LaunchPlanSpec{\n\t\t\t\tAuthRole: &admin.AuthRole{\n\t\t\t\t\tAssumableIamRole:         assumableIamRole,\n\t\t\t\t\tKubernetesServiceAccount: k8sServiceAccount,\n\t\t\t\t},\n\t\t\t\tSecurityContext: &core.SecurityContext{\n\t\t\t\t\tRunAs: &core.Identity{\n\t\t\t\t\t\tIamRole:           assumableIamRoleSc,\n\t\t\t\t\t\tK8SServiceAccount: k8sServiceAccountSc,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t}\n\t\tauthRole := resolveAuthRole(execRequest, lp)\n\t\texecConfigSecCtx := &core.SecurityContext{\n\t\t\tRunAs: &core.Identity{\n\t\t\t\tIamRole:           assumableIamRoleSc,\n\t\t\t\tK8SServiceAccount: k8sServiceAccountSc,\n\t\t\t},\n\t\t}\n\t\tsc := resolveSecurityCtx(context.TODO(), execConfigSecCtx, authRole)\n\t\tassert.Equal(t, assumableIamRole, authRole.AssumableIamRole)\n\t\tassert.Equal(t, k8sServiceAccount, authRole.KubernetesServiceAccount)\n\t\tassert.Equal(t, assumableIamRoleSc, sc.RunAs.IamRole)\n\t\tassert.Equal(t, k8sServiceAccountSc, sc.RunAs.K8SServiceAccount)\n\t})\n\tt.Run(\"prefer lp auth over role\", func(t *testing.T) {\n\t\texecRequest := &admin.ExecutionCreateRequest{\n\t\t\tSpec: &admin.ExecutionSpec{},\n\t\t}\n\t\tlp := &admin.LaunchPlan{\n\t\t\tSpec: &admin.LaunchPlanSpec{\n\t\t\t\tAuth: &admin.Auth{\n\t\t\t\t\tAssumableIamRole:         assumableIamRole,\n\t\t\t\t\tKubernetesServiceAccount: k8sServiceAccount,\n\t\t\t\t},\n\t\t\t\tRole: \"old role\",\n\t\t\t},\n\t\t}\n\t\tauthRole := resolveAuthRole(execRequest, lp)\n\t\texecConfigSecCtx := &core.SecurityContext{\n\t\t\tRunAs: &core.Identity{\n\t\t\t\tIamRole:           assumableIamRole,\n\t\t\t\tK8SServiceAccount: k8sServiceAccount,\n\t\t\t},\n\t\t}\n\t\tsc := resolveSecurityCtx(context.TODO(), execConfigSecCtx, authRole)\n\t\tassert.Equal(t, assumableIamRole, authRole.AssumableIamRole)\n\t\tassert.Equal(t, k8sServiceAccount, authRole.KubernetesServiceAccount)\n\t\tassert.Equal(t, &core.SecurityContext{\n\t\t\tRunAs: &core.Identity{\n\t\t\t\tIamRole:           assumableIamRole,\n\t\t\t\tK8SServiceAccount: k8sServiceAccount,\n\t\t\t},\n\t\t}, sc)\n\t})\n\tt.Run(\"prefer lp auth over role\", func(t *testing.T) {\n\t\tauthRole := resolveAuthRole(&admin.ExecutionCreateRequest{\n\t\t\tSpec: &admin.ExecutionSpec{},\n\t\t}, &admin.LaunchPlan{\n\t\t\tSpec: &admin.LaunchPlanSpec{\n\t\t\t\tAuth: &admin.Auth{\n\t\t\t\t\tAssumableIamRole:         assumableIamRoleLp,\n\t\t\t\t\tKubernetesServiceAccount: k8sServiceAccountLp,\n\t\t\t\t},\n\t\t\t\tRole: \"old role\",\n\t\t\t},\n\t\t})\n\t\tassert.Equal(t, assumableIamRoleLp, authRole.AssumableIamRole)\n\t\tassert.Equal(t, k8sServiceAccountLp, authRole.KubernetesServiceAccount)\n\t})\n}\n\nfunc TestAddStateFilter(t *testing.T) {\n\tt.Run(\"empty filters\", func(t *testing.T) {\n\t\tvar filters []common.InlineFilter\n\t\tupdatedFilters, err := addStateFilter(filters)\n\t\tassert.Nil(t, err)\n\t\tassert.NotNil(t, updatedFilters)\n\t\tassert.Equal(t, 1, len(updatedFilters))\n\n\t\tassert.Equal(t, shared.State, updatedFilters[0].GetField())\n\t\tassert.Equal(t, common.Execution, updatedFilters[0].GetEntity())\n\n\t\texpression, err := updatedFilters[0].GetGormQueryExpr()\n\t\tassert.NoError(t, err)\n\t\tassert.Equal(t, \"state = ?\", expression.Query)\n\t})\n\n\tt.Run(\"passed state filter\", func(t *testing.T) {\n\t\tfilter, err := common.NewSingleValueFilter(common.Execution, common.NotEqual, \"state\", \"0\")\n\t\tassert.NoError(t, err)\n\t\tfilters := []common.InlineFilter{filter}\n\n\t\tupdatedFilters, err := addStateFilter(filters)\n\t\tassert.Nil(t, err)\n\t\tassert.NotNil(t, updatedFilters)\n\t\tassert.Equal(t, 1, len(updatedFilters))\n\n\t\tassert.Equal(t, shared.State, updatedFilters[0].GetField())\n\t\tassert.Equal(t, common.Execution, updatedFilters[0].GetEntity())\n\n\t\texpression, err := updatedFilters[0].GetGormQueryExpr()\n\t\tassert.NoError(t, err)\n\t\tassert.Equal(t, \"state <> ?\", expression.Query)\n\t})\n\n}\n", "package impl\n\nimport (\n\t\"bytes\"\n\t\"context\"\n\t\"strconv\"\n\n\t\"github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/admin\"\n\t\"github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/core\"\n\t\"github.com/flyteorg/flytestdlib/contextutils\"\n\t\"github.com/flyteorg/flytestdlib/logger\"\n\t\"github.com/flyteorg/flytestdlib/promutils\"\n\t\"github.com/golang/protobuf/proto\"\n\t\"github.com/prometheus/client_golang/prometheus\"\n\t\"google.golang.org/grpc/codes\"\n\n\tscheduleInterfaces \"github.com/flyteorg/flyteadmin/pkg/async/schedule/interfaces\"\n\t\"github.com/flyteorg/flyteadmin/pkg/common\"\n\t\"github.com/flyteorg/flyteadmin/pkg/errors\"\n\t\"github.com/flyteorg/flyteadmin/pkg/manager/impl/util\"\n\t\"github.com/flyteorg/flyteadmin/pkg/manager/impl/validation\"\n\t\"github.com/flyteorg/flyteadmin/pkg/manager/interfaces\"\n\trepoInterfaces \"github.com/flyteorg/flyteadmin/pkg/repositories/interfaces\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/models\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/transformers\"\n\truntimeInterfaces \"github.com/flyteorg/flyteadmin/pkg/runtime/interfaces\"\n)\n\ntype launchPlanMetrics struct {\n\tScope                 promutils.Scope\n\tFailedScheduleUpdates prometheus.Counter\n\tSpecSizeBytes         prometheus.Summary\n\tClosureSizeBytes      prometheus.Summary\n}\n\ntype LaunchPlanManager struct {\n\tdb        repoInterfaces.Repository\n\tconfig    runtimeInterfaces.Configuration\n\tscheduler scheduleInterfaces.EventScheduler\n\tmetrics   launchPlanMetrics\n}\n\nfunc getLaunchPlanContext(ctx context.Context, identifier *core.Identifier) context.Context {\n\tctx = contextutils.WithProjectDomain(ctx, identifier.Project, identifier.Domain)\n\treturn contextutils.WithLaunchPlanID(ctx, identifier.Name)\n}\n\nfunc (m *LaunchPlanManager) getNamedEntityContext(ctx context.Context, identifier *admin.NamedEntityIdentifier) context.Context {\n\tctx = contextutils.WithProjectDomain(ctx, identifier.Project, identifier.Domain)\n\treturn contextutils.WithLaunchPlanID(ctx, identifier.Name)\n}\n\nfunc (m *LaunchPlanManager) CreateLaunchPlan(\n\tctx context.Context,\n\trequest admin.LaunchPlanCreateRequest) (*admin.LaunchPlanCreateResponse, error) {\n\tif err := validation.ValidateIdentifier(request.GetSpec().GetWorkflowId(), common.Workflow); err != nil {\n\t\tlogger.Debugf(ctx, \"Failed to validate provided workflow ID for CreateLaunchPlan with err: %v\", err)\n\t\treturn nil, err\n\t}\n\tworkflowModel, err := util.GetWorkflowModel(ctx, m.db, *request.Spec.WorkflowId)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"Failed to get workflow with id [%+v] for CreateLaunchPlan with id [%+v] with err %v\",\n\t\t\t*request.Spec.WorkflowId, request.Id)\n\t\treturn nil, err\n\t}\n\tvar workflowInterface core.TypedInterface\n\tif workflowModel.TypedInterface != nil && len(workflowModel.TypedInterface) > 0 {\n\t\terr = proto.Unmarshal(workflowModel.TypedInterface, &workflowInterface)\n\t\tif err != nil {\n\t\t\tlogger.Errorf(ctx,\n\t\t\t\t\"Failed to unmarshal TypedInterface for workflow [%+v] with err: %v\",\n\t\t\t\t*request.Spec.WorkflowId, err)\n\t\t\treturn nil, errors.NewFlyteAdminErrorf(codes.Internal, \"failed to unmarshal workflow inputs\")\n\t\t}\n\t}\n\tif err := validation.ValidateLaunchPlan(ctx, request, m.db, m.config.ApplicationConfiguration(), &workflowInterface); err != nil {\n\t\tlogger.Debugf(ctx, \"could not create launch plan: %+v, request failed validation with err: %v\", request.Id, err)\n\t\treturn nil, err\n\t}\n\tctx = getLaunchPlanContext(ctx, request.Id)\n\tlaunchPlan := transformers.CreateLaunchPlan(request, workflowInterface.Outputs)\n\tlaunchPlanDigest, err := util.GetLaunchPlanDigest(ctx, &launchPlan)\n\tif err != nil {\n\t\tlogger.Errorf(ctx, \"failed to compute launch plan digest for [%+v] with err: %v\", launchPlan.Id, err)\n\t\treturn nil, err\n\t}\n\n\texistingLaunchPlanModel, err := util.GetLaunchPlanModel(ctx, m.db, *request.Id)\n\tif err == nil {\n\t\tif bytes.Equal(existingLaunchPlanModel.Digest, launchPlanDigest) {\n\t\t\treturn nil, errors.NewFlyteAdminErrorf(codes.AlreadyExists,\n\t\t\t\t\"identical launch plan already exists with id %s\", request.Id)\n\t\t}\n\n\t\treturn nil, errors.NewFlyteAdminErrorf(codes.InvalidArgument,\n\t\t\t\"launch plan with different structure already exists with id %v\", request.Id)\n\t}\n\n\tlaunchPlanModel, err :=\n\t\ttransformers.CreateLaunchPlanModel(launchPlan, workflowModel.ID, launchPlanDigest, admin.LaunchPlanState_INACTIVE)\n\tif err != nil {\n\t\tlogger.Errorf(ctx,\n\t\t\t\"Failed to transform launch plan model [%+v], and workflow outputs [%+v] with err: %v\",\n\t\t\trequest, workflowInterface.Outputs, err)\n\t\treturn nil, err\n\t}\n\terr = m.db.LaunchPlanRepo().Create(ctx, launchPlanModel)\n\tif err != nil {\n\t\tlogger.Errorf(ctx, \"Failed to save launch plan model %+v with err: %v\", request.Id, err)\n\t\treturn nil, err\n\t}\n\tm.metrics.SpecSizeBytes.Observe(float64(len(launchPlanModel.Spec)))\n\tm.metrics.ClosureSizeBytes.Observe(float64(len(launchPlanModel.Closure)))\n\treturn &admin.LaunchPlanCreateResponse{}, nil\n}\n\nfunc (m *LaunchPlanManager) updateLaunchPlanModelState(launchPlan *models.LaunchPlan, state admin.LaunchPlanState) error {\n\tvar launchPlanClosure admin.LaunchPlanClosure\n\terr := proto.Unmarshal(launchPlan.Closure, &launchPlanClosure)\n\tif err != nil {\n\t\tlogger.Errorf(context.Background(), \"failed to unmarshal launch plan closure: %v\", err)\n\t\treturn errors.NewFlyteAdminErrorf(codes.Internal, \"Failed to unmarshal launch plan closure: %v\", err)\n\t}\n\t// Don't write the state in the closure - we store it only in the model column \"State\" and fill in the closure\n\t// value when transforming from a model to an admin.LaunchPlan object\n\tmarshalledClosure, err := proto.Marshal(&launchPlanClosure)\n\tif err != nil {\n\t\tlogger.Errorf(context.Background(), \"Failed to marshal launch plan closure: %v\", err)\n\t\treturn errors.NewFlyteAdminErrorf(codes.Internal, \"Failed to marshal launch plan closure: %v\", err)\n\t}\n\tlaunchPlan.Closure = marshalledClosure\n\tstateInt := int32(state)\n\tlaunchPlan.State = &stateInt\n\treturn nil\n}\n\nfunc isScheduleEmpty(launchPlanSpec admin.LaunchPlanSpec) bool {\n\tschedule := launchPlanSpec.GetEntityMetadata().GetSchedule()\n\tif schedule == nil {\n\t\treturn true\n\t}\n\tif schedule.GetCronSchedule() != nil && len(schedule.GetCronSchedule().Schedule) != 0 {\n\t\treturn false\n\t}\n\tif len(schedule.GetCronExpression()) != 0 {\n\t\treturn false\n\t}\n\tif schedule.GetRate().GetValue() != 0 {\n\t\treturn false\n\t}\n\treturn true\n}\n\nfunc (m *LaunchPlanManager) enableSchedule(ctx context.Context, launchPlanIdentifier core.Identifier,\n\tlaunchPlanSpec admin.LaunchPlanSpec) error {\n\n\taddScheduleInput, err := m.scheduler.CreateScheduleInput(ctx,\n\t\tm.config.ApplicationConfiguration().GetSchedulerConfig(), launchPlanIdentifier,\n\t\tlaunchPlanSpec.EntityMetadata.Schedule)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\treturn m.scheduler.AddSchedule(ctx, addScheduleInput)\n}\n\nfunc (m *LaunchPlanManager) disableSchedule(\n\tctx context.Context, launchPlanIdentifier core.Identifier) error {\n\treturn m.scheduler.RemoveSchedule(ctx, scheduleInterfaces.RemoveScheduleInput{\n\t\tIdentifier:         launchPlanIdentifier,\n\t\tScheduleNamePrefix: m.config.ApplicationConfiguration().GetSchedulerConfig().EventSchedulerConfig.ScheduleNamePrefix,\n\t})\n}\n\nfunc (m *LaunchPlanManager) updateSchedules(\n\tctx context.Context, newlyActiveLaunchPlan models.LaunchPlan, formerlyActiveLaunchPlan *models.LaunchPlan) error {\n\tvar newlyActiveLaunchPlanSpec admin.LaunchPlanSpec\n\terr := proto.Unmarshal(newlyActiveLaunchPlan.Spec, &newlyActiveLaunchPlanSpec)\n\tif err != nil {\n\t\tlogger.Errorf(ctx, \"failed to unmarshal newly enabled launch plan spec\")\n\t\treturn errors.NewFlyteAdminErrorf(codes.Internal, \"failed to unmarshal newly enabled launch plan spec\")\n\t}\n\tlaunchPlanIdentifier := core.Identifier{\n\t\tProject: newlyActiveLaunchPlan.Project,\n\t\tDomain:  newlyActiveLaunchPlan.Domain,\n\t\tName:    newlyActiveLaunchPlan.Name,\n\t\tVersion: newlyActiveLaunchPlan.Version,\n\t}\n\tvar formerlyActiveLaunchPlanSpec admin.LaunchPlanSpec\n\tif formerlyActiveLaunchPlan != nil {\n\t\terr = proto.Unmarshal(formerlyActiveLaunchPlan.Spec, &formerlyActiveLaunchPlanSpec)\n\t\tif err != nil {\n\t\t\treturn errors.NewFlyteAdminErrorf(codes.Internal, \"failed to unmarshal formerly enabled launch plan spec\")\n\t\t}\n\t}\n\n\tif !isScheduleEmpty(formerlyActiveLaunchPlanSpec) {\n\t\t// Disable previous schedule\n\t\tformerlyActiveLaunchPlanIdentifier := core.Identifier{\n\t\t\tProject: formerlyActiveLaunchPlan.Project,\n\t\t\tDomain:  formerlyActiveLaunchPlan.Domain,\n\t\t\tName:    formerlyActiveLaunchPlan.Name,\n\t\t\tVersion: formerlyActiveLaunchPlan.Version,\n\t\t}\n\t\tif err = m.disableSchedule(ctx, formerlyActiveLaunchPlanIdentifier); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tlogger.Infof(ctx, \"Disabled schedules for deactivated launch plan [%+v]\", launchPlanIdentifier)\n\t}\n\tif !isScheduleEmpty(newlyActiveLaunchPlanSpec) {\n\t\t// Enable new schedule\n\t\tif err = m.enableSchedule(ctx, launchPlanIdentifier, newlyActiveLaunchPlanSpec); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tlogger.Infof(ctx, \"Enabled schedules for activated launch plan [%+v]\", launchPlanIdentifier)\n\t}\n\treturn nil\n}\n\nfunc (m *LaunchPlanManager) disableLaunchPlan(ctx context.Context, request admin.LaunchPlanUpdateRequest) (\n\t*admin.LaunchPlanUpdateResponse, error) {\n\tif err := validation.ValidateIdentifier(request.Id, common.LaunchPlan); err != nil {\n\t\tlogger.Debugf(ctx, \"can't disable launch plan [%+v] with invalid identifier: %v\", request.Id, err)\n\t\treturn nil, err\n\t}\n\tlaunchPlanModel, err := util.GetLaunchPlanModel(ctx, m.db, *request.Id)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"couldn't find launch plan [%+v] to disable with err: %v\", request.Id, err)\n\t\treturn nil, err\n\t}\n\n\terr = m.updateLaunchPlanModelState(&launchPlanModel, admin.LaunchPlanState_INACTIVE)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"failed to disable launch plan [%+v] with err: %v\", request.Id, err)\n\t\treturn nil, err\n\t}\n\n\tvar launchPlanSpec admin.LaunchPlanSpec\n\terr = proto.Unmarshal(launchPlanModel.Spec, &launchPlanSpec)\n\tif err != nil {\n\t\tlogger.Errorf(ctx, \"failed to unmarshal launch plan spec when disabling schedule for %+v\", request.Id)\n\t\treturn nil, errors.NewFlyteAdminErrorf(codes.Internal,\n\t\t\t\"failed to unmarshal launch plan spec when disabling schedule for %+v\", request.Id)\n\t}\n\tif launchPlanSpec.EntityMetadata != nil && launchPlanSpec.EntityMetadata.Schedule != nil {\n\t\terr = m.disableSchedule(ctx, core.Identifier{\n\t\t\tProject: launchPlanModel.Project,\n\t\t\tDomain:  launchPlanModel.Domain,\n\t\t\tName:    launchPlanModel.Name,\n\t\t\tVersion: launchPlanModel.Version,\n\t\t})\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\terr = m.db.LaunchPlanRepo().Update(ctx, launchPlanModel)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"Failed to update launchPlanModel with ID [%+v] with err %v\", request.Id, err)\n\t\treturn nil, err\n\t}\n\tlogger.Debugf(ctx, \"disabled launch plan: [%+v]\", request.Id)\n\treturn &admin.LaunchPlanUpdateResponse{}, nil\n}\n\nfunc (m *LaunchPlanManager) enableLaunchPlan(ctx context.Context, request admin.LaunchPlanUpdateRequest) (\n\t*admin.LaunchPlanUpdateResponse, error) {\n\tnewlyActiveLaunchPlanModel, err := m.db.LaunchPlanRepo().Get(ctx, repoInterfaces.Identifier{\n\t\tProject: request.Id.Project,\n\t\tDomain:  request.Id.Domain,\n\t\tName:    request.Id.Name,\n\t\tVersion: request.Id.Version,\n\t})\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"Failed to find launch plan to enable with id [%+v] and err %v\", request.Id, err)\n\t\treturn nil, err\n\t}\n\t// Set desired launch plan version to active:\n\terr = m.updateLaunchPlanModelState(&newlyActiveLaunchPlanModel, admin.LaunchPlanState_ACTIVE)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// Find currently active version, if it exists.\n\tfilters, err := util.GetActiveLaunchPlanVersionFilters(newlyActiveLaunchPlanModel.Project, newlyActiveLaunchPlanModel.Domain, newlyActiveLaunchPlanModel.Name)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tformerlyActiveLaunchPlanModelOutput, err := m.db.LaunchPlanRepo().List(ctx, repoInterfaces.ListResourceInput{\n\t\tInlineFilters: filters,\n\t\tLimit:         1,\n\t})\n\tvar formerlyActiveLaunchPlanModel *models.LaunchPlan\n\tif err != nil {\n\t\t// Not found is fine, there isn't always a guaranteed active launch plan model.\n\t\tif err.(errors.FlyteAdminError).Code() != codes.NotFound {\n\t\t\tlogger.Infof(ctx, \"Failed to search for an active launch plan model with project: %s, domain: %s, name: %s and err %v\",\n\t\t\t\trequest.Id.Project, request.Id.Domain, request.Id.Name, err)\n\t\t\treturn nil, err\n\t\t}\n\t\tlogger.Debugf(ctx, \"No active launch plan model found to disable with project: %s, domain: %s, name: %s\",\n\t\t\trequest.Id.Project, request.Id.Domain, request.Id.Name)\n\t} else if formerlyActiveLaunchPlanModelOutput.LaunchPlans != nil &&\n\t\tlen(formerlyActiveLaunchPlanModelOutput.LaunchPlans) > 0 {\n\t\tformerlyActiveLaunchPlanModel = &formerlyActiveLaunchPlanModelOutput.LaunchPlans[0]\n\t\terr = m.updateLaunchPlanModelState(formerlyActiveLaunchPlanModel, admin.LaunchPlanState_INACTIVE)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\terr = m.updateSchedules(ctx, newlyActiveLaunchPlanModel, formerlyActiveLaunchPlanModel)\n\tif err != nil {\n\t\tm.metrics.FailedScheduleUpdates.Inc()\n\t\treturn nil, err\n\t}\n\n\t// This operation is takes in the (formerly) active launch plan version as only one version can be active at a time.\n\t// Setting the desired launch plan to active also requires disabling the existing active launch plan version.\n\terr = m.db.LaunchPlanRepo().SetActive(ctx, newlyActiveLaunchPlanModel, formerlyActiveLaunchPlanModel)\n\tif err != nil {\n\t\tlogger.Debugf(ctx,\n\t\t\t\"Failed to set launchPlanModel with ID [%+v] to active with err %v\", request.Id, err)\n\t\treturn nil, err\n\t}\n\treturn &admin.LaunchPlanUpdateResponse{}, nil\n\n}\n\nfunc (m *LaunchPlanManager) UpdateLaunchPlan(ctx context.Context, request admin.LaunchPlanUpdateRequest) (\n\t*admin.LaunchPlanUpdateResponse, error) {\n\tif err := validation.ValidateIdentifier(request.Id, common.LaunchPlan); err != nil {\n\t\tlogger.Debugf(ctx, \"can't update launch plan [%+v] state, invalid identifier: %v\", request.Id, err)\n\t}\n\tctx = getLaunchPlanContext(ctx, request.Id)\n\tswitch request.State {\n\tcase admin.LaunchPlanState_INACTIVE:\n\t\treturn m.disableLaunchPlan(ctx, request)\n\tcase admin.LaunchPlanState_ACTIVE:\n\t\treturn m.enableLaunchPlan(ctx, request)\n\tdefault:\n\t\treturn nil, errors.NewFlyteAdminErrorf(\n\t\t\tcodes.InvalidArgument, \"Unrecognized launch plan state %v for update for launch plan [%+v]\",\n\t\t\trequest.State, request.Id)\n\t}\n}\n\nfunc (m *LaunchPlanManager) GetLaunchPlan(ctx context.Context, request admin.ObjectGetRequest) (\n\t*admin.LaunchPlan, error) {\n\tif err := validation.ValidateIdentifier(request.Id, common.LaunchPlan); err != nil {\n\t\tlogger.Debugf(ctx, \"can't get launch plan [%+v] with invalid identifier: %v\", request.Id, err)\n\t\treturn nil, err\n\t}\n\tctx = getLaunchPlanContext(ctx, request.Id)\n\treturn util.GetLaunchPlan(ctx, m.db, *request.Id)\n}\n\nfunc (m *LaunchPlanManager) GetActiveLaunchPlan(ctx context.Context, request admin.ActiveLaunchPlanRequest) (\n\t*admin.LaunchPlan, error) {\n\tif err := validation.ValidateActiveLaunchPlanRequest(request); err != nil {\n\t\tlogger.Debugf(ctx, \"can't get active launch plan [%+v] with invalid request: %v\", request.Id, err)\n\t\treturn nil, err\n\t}\n\tctx = m.getNamedEntityContext(ctx, request.Id)\n\n\tfilters, err := util.GetActiveLaunchPlanVersionFilters(request.Id.Project, request.Id.Domain, request.Id.Name)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tlistLaunchPlansInput := repoInterfaces.ListResourceInput{\n\t\tLimit:         1,\n\t\tInlineFilters: filters,\n\t}\n\n\toutput, err := m.db.LaunchPlanRepo().List(ctx, listLaunchPlansInput)\n\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"Failed to list active launch plan id for request [%+v] with err %v\", request, err)\n\t\treturn nil, err\n\t}\n\n\tif len(output.LaunchPlans) != 1 {\n\t\treturn nil, errors.NewFlyteAdminErrorf(codes.NotFound, \"No active launch plan could be found: %s:%s:%s\", request.Id.Project, request.Id.Domain, request.Id.Name)\n\t}\n\n\treturn transformers.FromLaunchPlanModel(output.LaunchPlans[0])\n}\n\nfunc (m *LaunchPlanManager) ListLaunchPlans(ctx context.Context, request admin.ResourceListRequest) (\n\t*admin.LaunchPlanList, error) {\n\n\t// Check required fields\n\tif err := validation.ValidateResourceListRequest(request); err != nil {\n\t\tlogger.Debugf(ctx, \"\")\n\t\treturn nil, err\n\t}\n\tctx = m.getNamedEntityContext(ctx, request.Id)\n\n\tfilters, err := util.GetDbFilters(util.FilterSpec{\n\t\tProject:        request.Id.Project,\n\t\tDomain:         request.Id.Domain,\n\t\tName:           request.Id.Name,\n\t\tRequestFilters: request.Filters,\n\t}, common.LaunchPlan)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tsortParameter, err := common.NewSortParameter(request.SortBy, models.LaunchPlanColumns)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\toffset, err := validation.ValidateToken(request.Token)\n\tif err != nil {\n\t\treturn nil, errors.NewFlyteAdminErrorf(codes.InvalidArgument,\n\t\t\t\"invalid pagination token %s for ListLaunchPlans\", request.Token)\n\t}\n\tlistLaunchPlansInput := repoInterfaces.ListResourceInput{\n\t\tLimit:         int(request.Limit),\n\t\tOffset:        offset,\n\t\tInlineFilters: filters,\n\t\tSortParameter: sortParameter,\n\t}\n\n\toutput, err := m.db.LaunchPlanRepo().List(ctx, listLaunchPlansInput)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"Failed to list launch plans for request [%+v] with err %v\", request, err)\n\t\treturn nil, err\n\t}\n\tlaunchPlanList, err := transformers.FromLaunchPlanModels(output.LaunchPlans)\n\tif err != nil {\n\t\tlogger.Errorf(ctx,\n\t\t\t\"Failed to transform launch plan models [%+v] with err: %v\", output.LaunchPlans, err)\n\t\treturn nil, err\n\t}\n\tvar token string\n\tif len(output.LaunchPlans) == int(request.Limit) {\n\t\ttoken = strconv.Itoa(offset + len(output.LaunchPlans))\n\t}\n\treturn &admin.LaunchPlanList{\n\t\tLaunchPlans: launchPlanList,\n\t\tToken:       token,\n\t}, nil\n}\n\nfunc (m *LaunchPlanManager) ListActiveLaunchPlans(ctx context.Context, request admin.ActiveLaunchPlanListRequest) (\n\t*admin.LaunchPlanList, error) {\n\n\t// Check required fields\n\tif err := validation.ValidateActiveLaunchPlanListRequest(request); err != nil {\n\t\tlogger.Debugf(ctx, \"\")\n\t\treturn nil, err\n\t}\n\tctx = contextutils.WithProjectDomain(ctx, request.Project, request.Domain)\n\n\tfilters, err := util.ListActiveLaunchPlanVersionsFilters(request.Project, request.Domain)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tsortParameter, err := common.NewSortParameter(request.SortBy, models.LaunchPlanColumns)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\toffset, err := validation.ValidateToken(request.Token)\n\tif err != nil {\n\t\treturn nil, errors.NewFlyteAdminErrorf(codes.InvalidArgument,\n\t\t\t\"invalid pagination token %s for ListActiveLaunchPlans\", request.Token)\n\t}\n\tlistLaunchPlansInput := repoInterfaces.ListResourceInput{\n\t\tLimit:         int(request.Limit),\n\t\tOffset:        offset,\n\t\tInlineFilters: filters,\n\t\tSortParameter: sortParameter,\n\t}\n\n\toutput, err := m.db.LaunchPlanRepo().List(ctx, listLaunchPlansInput)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"Failed to list active launch plans for request [%+v] with err %v\", request, err)\n\t\treturn nil, err\n\t}\n\tlaunchPlanList, err := transformers.FromLaunchPlanModels(output.LaunchPlans)\n\tif err != nil {\n\t\tlogger.Errorf(ctx,\n\t\t\t\"Failed to transform active launch plan models [%+v] with err: %v\", output.LaunchPlans, err)\n\t\treturn nil, err\n\t}\n\tvar token string\n\tif len(output.LaunchPlans) == int(request.Limit) {\n\t\ttoken = strconv.Itoa(offset + len(output.LaunchPlans))\n\t}\n\treturn &admin.LaunchPlanList{\n\t\tLaunchPlans: launchPlanList,\n\t\tToken:       token,\n\t}, nil\n}\n\n// At least project name and domain must be specified along with limit.\nfunc (m *LaunchPlanManager) ListLaunchPlanIds(ctx context.Context, request admin.NamedEntityIdentifierListRequest) (\n\t*admin.NamedEntityIdentifierList, error) {\n\tctx = contextutils.WithProjectDomain(ctx, request.Project, request.Domain)\n\tfilters, err := util.GetDbFilters(util.FilterSpec{\n\t\tProject: request.Project,\n\t\tDomain:  request.Domain,\n\t}, common.LaunchPlan)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tsortParameter, err := common.NewSortParameter(request.SortBy, models.LaunchPlanColumns)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\toffset, err := validation.ValidateToken(request.Token)\n\tif err != nil {\n\t\treturn nil, errors.NewFlyteAdminErrorf(codes.InvalidArgument, \"invalid pagination token %s\", request.Token)\n\t}\n\tlistLaunchPlansInput := repoInterfaces.ListResourceInput{\n\t\tLimit:         int(request.Limit),\n\t\tOffset:        offset,\n\t\tInlineFilters: filters,\n\t\tSortParameter: sortParameter,\n\t}\n\n\toutput, err := m.db.LaunchPlanRepo().ListLaunchPlanIdentifiers(ctx, listLaunchPlansInput)\n\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"Failed to list launch plan ids for request [%+v] with err %v\", request, err)\n\t\treturn nil, err\n\t}\n\tvar token string\n\tif len(output.LaunchPlans) == int(request.Limit) {\n\t\ttoken = strconv.Itoa(offset + len(output.LaunchPlans))\n\t}\n\treturn &admin.NamedEntityIdentifierList{\n\t\tEntities: transformers.FromLaunchPlanModelsToIdentifiers(output.LaunchPlans),\n\t\tToken:    token,\n\t}, nil\n}\n\nfunc NewLaunchPlanManager(\n\tdb repoInterfaces.Repository,\n\tconfig runtimeInterfaces.Configuration,\n\tscheduler scheduleInterfaces.EventScheduler,\n\tscope promutils.Scope) interfaces.LaunchPlanInterface {\n\n\tmetrics := launchPlanMetrics{\n\t\tScope: scope,\n\t\tFailedScheduleUpdates: scope.MustNewCounter(\"failed_schedule_updates\",\n\t\t\t\"count of unsuccessful attempts to update the schedules when updating launch plan version\"),\n\t\tSpecSizeBytes:    scope.MustNewSummary(\"spec_size_bytes\", \"size in bytes of serialized launch plan spec\"),\n\t\tClosureSizeBytes: scope.MustNewSummary(\"closure_size_bytes\", \"size in bytes of serialized launch plan closure\"),\n\t}\n\treturn &LaunchPlanManager{\n\t\tdb:        db,\n\t\tconfig:    config,\n\t\tscheduler: scheduler,\n\t\tmetrics:   metrics,\n\t}\n}\n", "package impl\n\nimport (\n\t\"context\"\n\t\"strconv\"\n\t\"strings\"\n\n\t\"github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/admin\"\n\t\"github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/core\"\n\t\"github.com/flyteorg/flytestdlib/contextutils\"\n\t\"github.com/flyteorg/flytestdlib/logger\"\n\t\"github.com/flyteorg/flytestdlib/promutils\"\n\t\"google.golang.org/grpc/codes\"\n\n\t\"github.com/flyteorg/flyteadmin/pkg/common\"\n\t\"github.com/flyteorg/flyteadmin/pkg/errors\"\n\t\"github.com/flyteorg/flyteadmin/pkg/manager/impl/util\"\n\t\"github.com/flyteorg/flyteadmin/pkg/manager/impl/validation\"\n\t\"github.com/flyteorg/flyteadmin/pkg/manager/interfaces\"\n\trepoInterfaces \"github.com/flyteorg/flyteadmin/pkg/repositories/interfaces\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/models\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/transformers\"\n\truntimeInterfaces \"github.com/flyteorg/flyteadmin/pkg/runtime/interfaces\"\n)\n\nconst state = \"state\"\n\n// System-generated workflows are meant to be hidden from the user by default. Therefore we always only show\n// workflow-type named entities that have been user generated only.\nvar nonSystemGeneratedWorkflowsFilter, _ = common.NewSingleValueFilter(\n\tcommon.NamedEntityMetadata, common.NotEqual, state, admin.NamedEntityState_SYSTEM_GENERATED)\nvar defaultWorkflowsFilter, _ = common.NewWithDefaultValueFilter(\n\tstrconv.Itoa(int(admin.NamedEntityState_NAMED_ENTITY_ACTIVE)), nonSystemGeneratedWorkflowsFilter)\n\ntype NamedEntityMetrics struct {\n\tScope promutils.Scope\n}\n\ntype NamedEntityManager struct {\n\tdb      repoInterfaces.Repository\n\tconfig  runtimeInterfaces.Configuration\n\tmetrics NamedEntityMetrics\n}\n\nfunc (m *NamedEntityManager) UpdateNamedEntity(ctx context.Context, request admin.NamedEntityUpdateRequest) (\n\t*admin.NamedEntityUpdateResponse, error) {\n\tif err := validation.ValidateNamedEntityUpdateRequest(request); err != nil {\n\t\tlogger.Debugf(ctx, \"invalid request [%+v]: %v\", request, err)\n\t\treturn nil, err\n\t}\n\tctx = contextutils.WithProjectDomain(ctx, request.Id.Project, request.Id.Domain)\n\n\t// Ensure entity exists before trying to update it\n\t_, err := util.GetNamedEntity(ctx, m.db, request.ResourceType, *request.Id)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tmetadataModel := transformers.CreateNamedEntityModel(&request)\n\terr = m.db.NamedEntityRepo().Update(ctx, metadataModel)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"Failed to update named_entity for [%+v] with err %v\", request.Id, err)\n\t\treturn nil, err\n\t}\n\treturn &admin.NamedEntityUpdateResponse{}, nil\n}\n\nfunc (m *NamedEntityManager) GetNamedEntity(ctx context.Context, request admin.NamedEntityGetRequest) (\n\t*admin.NamedEntity, error) {\n\tif err := validation.ValidateNamedEntityGetRequest(request); err != nil {\n\t\tlogger.Debugf(ctx, \"invalid request [%+v]: %v\", request, err)\n\t\treturn nil, err\n\t}\n\tctx = contextutils.WithProjectDomain(ctx, request.Id.Project, request.Id.Domain)\n\treturn util.GetNamedEntity(ctx, m.db, request.ResourceType, *request.Id)\n}\n\nfunc (m *NamedEntityManager) getQueryFilters(referenceEntity core.ResourceType, requestFilters string) ([]common.InlineFilter, error) {\n\tfilters := make([]common.InlineFilter, 0)\n\tif referenceEntity == core.ResourceType_WORKFLOW {\n\t\tfilters = append(filters, defaultWorkflowsFilter)\n\t}\n\n\tif len(requestFilters) == 0 {\n\t\treturn filters, nil\n\t}\n\tadditionalFilters, err := util.ParseFilters(requestFilters, common.NamedEntity)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tfor _, filter := range additionalFilters {\n\t\tif strings.Contains(filter.GetField(), state) {\n\t\t\tfilterWithDefaultValue, err := common.NewWithDefaultValueFilter(\n\t\t\t\tstrconv.Itoa(int(admin.NamedEntityState_NAMED_ENTITY_ACTIVE)), filter)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\tfilters = append(filters, filterWithDefaultValue)\n\t\t} else {\n\t\t\tfilters = append(filters, filter)\n\t\t}\n\t}\n\treturn filters, nil\n}\n\nfunc (m *NamedEntityManager) ListNamedEntities(ctx context.Context, request admin.NamedEntityListRequest) (\n\t*admin.NamedEntityList, error) {\n\tif err := validation.ValidateNamedEntityListRequest(request); err != nil {\n\t\tlogger.Debugf(ctx, \"invalid request [%+v]: %v\", request, err)\n\t\treturn nil, err\n\t}\n\tctx = contextutils.WithProjectDomain(ctx, request.Project, request.Domain)\n\n\t// HACK: In order to filter by state (if requested) - we need to amend the filter to use COALESCE\n\t// e.g. eq(state, 1) becomes 'WHERE (COALESCE(state, 0) = '1')' since not every NamedEntity necessarily\n\t// has an entry, and therefore the default state value '0' (active), should be assumed.\n\tfilters, err := m.getQueryFilters(request.ResourceType, request.Filters)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tsortParameter, err := common.NewSortParameter(request.SortBy, models.NamedEntityColumns)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\toffset, err := validation.ValidateToken(request.Token)\n\tif err != nil {\n\t\treturn nil, errors.NewFlyteAdminErrorf(codes.InvalidArgument,\n\t\t\t\"invalid pagination token %s for ListNamedEntities\", request.Token)\n\t}\n\tlistInput := repoInterfaces.ListNamedEntityInput{\n\t\tListResourceInput: repoInterfaces.ListResourceInput{\n\t\t\tLimit:         int(request.Limit),\n\t\t\tOffset:        offset,\n\t\t\tInlineFilters: filters,\n\t\t\tSortParameter: sortParameter,\n\t\t},\n\t\tProject:      request.Project,\n\t\tDomain:       request.Domain,\n\t\tResourceType: request.ResourceType,\n\t}\n\n\toutput, err := m.db.NamedEntityRepo().List(ctx, listInput)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"Failed to list named entities of type: %s with project: %s, domain: %s. Returned error was: %v\",\n\t\t\trequest.ResourceType, request.Project, request.Domain, err)\n\t\treturn nil, err\n\t}\n\n\tvar token string\n\tif len(output.Entities) == int(request.Limit) {\n\t\ttoken = strconv.Itoa(offset + len(output.Entities))\n\t}\n\tentities := transformers.FromNamedEntityModels(output.Entities)\n\treturn &admin.NamedEntityList{\n\t\tEntities: entities,\n\t\tToken:    token,\n\t}, nil\n\n}\n\nfunc NewNamedEntityManager(\n\tdb repoInterfaces.Repository,\n\tconfig runtimeInterfaces.Configuration,\n\tscope promutils.Scope) interfaces.NamedEntityInterface {\n\n\tmetrics := NamedEntityMetrics{\n\t\tScope: scope,\n\t}\n\treturn &NamedEntityManager{\n\t\tdb:      db,\n\t\tconfig:  config,\n\t\tmetrics: metrics,\n\t}\n}\n", "package impl\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"strconv\"\n\n\t\"github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/admin\"\n\t\"github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/core\"\n\t\"github.com/flyteorg/flytestdlib/contextutils\"\n\t\"github.com/flyteorg/flytestdlib/logger\"\n\t\"github.com/flyteorg/flytestdlib/promutils\"\n\t\"github.com/flyteorg/flytestdlib/promutils/labeled\"\n\t\"github.com/flyteorg/flytestdlib/storage\"\n\t\"github.com/golang/protobuf/proto\"\n\t\"github.com/prometheus/client_golang/prometheus\"\n\t\"google.golang.org/grpc/codes\"\n\n\tcloudeventInterfaces \"github.com/flyteorg/flyteadmin/pkg/async/cloudevent/interfaces\"\n\teventWriter \"github.com/flyteorg/flyteadmin/pkg/async/events/interfaces\"\n\tnotificationInterfaces \"github.com/flyteorg/flyteadmin/pkg/async/notifications/interfaces\"\n\t\"github.com/flyteorg/flyteadmin/pkg/common\"\n\tdataInterfaces \"github.com/flyteorg/flyteadmin/pkg/data/interfaces\"\n\t\"github.com/flyteorg/flyteadmin/pkg/errors\"\n\t\"github.com/flyteorg/flyteadmin/pkg/manager/impl/shared\"\n\t\"github.com/flyteorg/flyteadmin/pkg/manager/impl/util\"\n\t\"github.com/flyteorg/flyteadmin/pkg/manager/impl/validation\"\n\t\"github.com/flyteorg/flyteadmin/pkg/manager/interfaces\"\n\trepoInterfaces \"github.com/flyteorg/flyteadmin/pkg/repositories/interfaces\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/models\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/transformers\"\n\truntimeInterfaces \"github.com/flyteorg/flyteadmin/pkg/runtime/interfaces\"\n)\n\ntype nodeExecutionMetrics struct {\n\tScope                      promutils.Scope\n\tActiveNodeExecutions       prometheus.Gauge\n\tNodeExecutionsCreated      prometheus.Counter\n\tNodeExecutionsTerminated   labeled.Counter\n\tNodeExecutionEventsCreated prometheus.Counter\n\tMissingWorkflowExecution   prometheus.Counter\n\tClosureSizeBytes           prometheus.Summary\n\tNodeExecutionInputBytes    prometheus.Summary\n\tNodeExecutionOutputBytes   prometheus.Summary\n\tPublishEventError          prometheus.Counter\n}\n\ntype NodeExecutionManager struct {\n\tdb                  repoInterfaces.Repository\n\tconfig              runtimeInterfaces.Configuration\n\tstoragePrefix       []string\n\tstorageClient       *storage.DataStore\n\tmetrics             nodeExecutionMetrics\n\turlData             dataInterfaces.RemoteURLInterface\n\teventPublisher      notificationInterfaces.Publisher\n\tcloudEventPublisher cloudeventInterfaces.Publisher\n\tdbEventWriter       eventWriter.NodeExecutionEventWriter\n}\n\ntype updateNodeExecutionStatus int\n\nconst (\n\tupdateSucceeded updateNodeExecutionStatus = iota\n\tupdateFailed\n\talreadyInTerminalStatus\n)\n\nvar isParent = common.NewMapFilter(map[string]interface{}{\n\tshared.ParentTaskExecutionID: nil,\n\tshared.ParentID:              nil,\n})\n\nfunc getNodeExecutionContext(ctx context.Context, identifier *core.NodeExecutionIdentifier) context.Context {\n\tctx = contextutils.WithProjectDomain(ctx, identifier.ExecutionId.Project, identifier.ExecutionId.Domain)\n\tctx = contextutils.WithExecutionID(ctx, identifier.ExecutionId.Name)\n\treturn contextutils.WithNodeID(ctx, identifier.NodeId)\n}\n\nfunc (m *NodeExecutionManager) createNodeExecutionWithEvent(\n\tctx context.Context, request *admin.NodeExecutionEventRequest, dynamicWorkflowRemoteClosureReference string) error {\n\tvar parentTaskExecutionID *uint\n\tif request.Event.ParentTaskMetadata != nil {\n\t\ttaskExecutionModel, err := util.GetTaskExecutionModel(ctx, m.db, request.Event.ParentTaskMetadata.Id)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tparentTaskExecutionID = &taskExecutionModel.ID\n\t}\n\tvar parentID *uint\n\tif request.Event.ParentNodeMetadata != nil {\n\t\tparentNodeExecutionModel, err := util.GetNodeExecutionModel(ctx, m.db, &core.NodeExecutionIdentifier{\n\t\t\tExecutionId: request.Event.Id.ExecutionId,\n\t\t\tNodeId:      request.Event.ParentNodeMetadata.NodeId,\n\t\t})\n\t\tif err != nil {\n\t\t\tlogger.Errorf(ctx, \"failed to fetch node execution for the parent node: %v %s with err\",\n\t\t\t\trequest.Event.Id.ExecutionId, request.Event.ParentNodeMetadata.NodeId, err)\n\t\t\treturn err\n\t\t}\n\t\tparentID = &parentNodeExecutionModel.ID\n\t}\n\tnodeExecutionModel, err := transformers.CreateNodeExecutionModel(ctx, transformers.ToNodeExecutionModelInput{\n\t\tRequest:                      request,\n\t\tParentTaskExecutionID:        parentTaskExecutionID,\n\t\tParentID:                     parentID,\n\t\tDynamicWorkflowRemoteClosure: dynamicWorkflowRemoteClosureReference,\n\t\tInlineEventDataPolicy:        m.config.ApplicationConfiguration().GetRemoteDataConfig().InlineEventDataPolicy,\n\t\tStorageClient:                m.storageClient,\n\t})\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"failed to create node execution model for event request: %s with err: %v\",\n\t\t\trequest.RequestId, err)\n\t\treturn err\n\t}\n\tif err := m.db.NodeExecutionRepo().Create(ctx, nodeExecutionModel); err != nil {\n\t\tlogger.Debugf(ctx, \"Failed to create node execution with id [%+v] and model [%+v] \"+\n\t\t\t\"with err %v\", request.Event.Id, nodeExecutionModel, err)\n\t\treturn err\n\t}\n\tm.metrics.ClosureSizeBytes.Observe(float64(len(nodeExecutionModel.Closure)))\n\treturn nil\n}\n\nfunc (m *NodeExecutionManager) updateNodeExecutionWithEvent(\n\tctx context.Context, request *admin.NodeExecutionEventRequest, nodeExecutionModel *models.NodeExecution,\n\tdynamicWorkflowRemoteClosureReference string) (updateNodeExecutionStatus, error) {\n\t// If we have an existing execution, check if the phase change is valid\n\tnodeExecPhase := core.NodeExecution_Phase(core.NodeExecution_Phase_value[nodeExecutionModel.Phase])\n\tif nodeExecPhase == request.Event.Phase {\n\t\tlogger.Debugf(ctx, \"This phase was already recorded %v for %+v\", nodeExecPhase.String(), request.Event.Id)\n\t\treturn updateFailed, errors.NewFlyteAdminErrorf(codes.AlreadyExists,\n\t\t\t\"This phase was already recorded %v for %+v\", nodeExecPhase.String(), request.Event.Id)\n\t} else if common.IsNodeExecutionTerminal(nodeExecPhase) {\n\t\t// Cannot go from a terminal state to anything else\n\t\tlogger.Warnf(ctx, \"Invalid phase change from %v to %v for node execution %v\",\n\t\t\tnodeExecPhase.String(), request.Event.Phase.String(), request.Event.Id)\n\t\treturn alreadyInTerminalStatus, nil\n\t}\n\n\t// if this node execution kicked off a workflow, validate that the execution exists\n\tvar childExecutionID *core.WorkflowExecutionIdentifier\n\tif request.Event.GetWorkflowNodeMetadata() != nil {\n\t\tchildExecutionID = request.Event.GetWorkflowNodeMetadata().ExecutionId\n\t\terr := validation.ValidateWorkflowExecutionIdentifier(childExecutionID)\n\t\tif err != nil {\n\t\t\tlogger.Errorf(ctx, \"Invalid execution ID: %s with err: %v\",\n\t\t\t\tchildExecutionID, err)\n\t\t}\n\t\t_, err = util.GetExecutionModel(ctx, m.db, *childExecutionID)\n\t\tif err != nil {\n\t\t\tlogger.Errorf(ctx, \"The node execution launched an execution but it does not exist: %s with err: %v\",\n\t\t\t\tchildExecutionID, err)\n\t\t\treturn updateFailed, err\n\t\t}\n\t}\n\terr := transformers.UpdateNodeExecutionModel(ctx, request, nodeExecutionModel, childExecutionID,\n\t\tdynamicWorkflowRemoteClosureReference, m.config.ApplicationConfiguration().GetRemoteDataConfig().InlineEventDataPolicy,\n\t\tm.storageClient)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"failed to update node execution model: %+v with err: %v\", request.Event.Id, err)\n\t\treturn updateFailed, err\n\t}\n\terr = m.db.NodeExecutionRepo().Update(ctx, nodeExecutionModel)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"Failed to update node execution with id [%+v] with err %v\",\n\t\t\trequest.Event.Id, err)\n\t\treturn updateFailed, err\n\t}\n\n\treturn updateSucceeded, nil\n}\n\nfunc formatDynamicWorkflowID(identifier *core.Identifier) string {\n\treturn fmt.Sprintf(\"%s_%s_%s_%s\", identifier.Project, identifier.Domain, identifier.Name, identifier.Version)\n}\n\nfunc (m *NodeExecutionManager) uploadDynamicWorkflowClosure(\n\tctx context.Context, nodeID *core.NodeExecutionIdentifier, workflowID *core.Identifier,\n\tcompiledWorkflowClosure *core.CompiledWorkflowClosure) (storage.DataReference, error) {\n\tnestedSubKeys := []string{\n\t\tnodeID.ExecutionId.Project,\n\t\tnodeID.ExecutionId.Domain,\n\t\tnodeID.ExecutionId.Name,\n\t\tnodeID.NodeId,\n\t\tformatDynamicWorkflowID(workflowID),\n\t}\n\tnestedKeys := append(m.storagePrefix, nestedSubKeys...)\n\tremoteClosureDataRef, err := m.storageClient.ConstructReference(ctx, m.storageClient.GetBaseContainerFQN(ctx), nestedKeys...)\n\n\tif err != nil {\n\t\treturn \"\", errors.NewFlyteAdminErrorf(codes.Internal,\n\t\t\t\"Failed to produce remote closure data reference for dynamic workflow yielded by node id [%+v] with workflow id [%+v]; err: %v\", nodeID, workflowID, err)\n\t}\n\n\terr = m.storageClient.WriteProtobuf(ctx, remoteClosureDataRef, defaultStorageOptions, compiledWorkflowClosure)\n\tif err != nil {\n\t\treturn \"\", errors.NewFlyteAdminErrorf(codes.Internal,\n\t\t\t\"Failed to upload dynamic workflow closure for node id [%+v] and workflow id [%+v] with err: %v\", nodeID, workflowID, err)\n\t}\n\treturn remoteClosureDataRef, nil\n}\n\nfunc (m *NodeExecutionManager) CreateNodeEvent(ctx context.Context, request admin.NodeExecutionEventRequest) (\n\t*admin.NodeExecutionEventResponse, error) {\n\tif err := validation.ValidateNodeExecutionEventRequest(&request, m.config.ApplicationConfiguration().GetRemoteDataConfig().MaxSizeInBytes); err != nil {\n\t\tlogger.Debugf(ctx, \"CreateNodeEvent called with invalid identifier [%+v]: %v\", request.Event.Id, err)\n\t}\n\tctx = getNodeExecutionContext(ctx, request.Event.Id)\n\tlogger.Debugf(ctx, \"Received node execution event for Node Exec Id [%+v] transitioning to phase [%v], w/ Metadata [%v]\",\n\t\trequest.Event.Id, request.Event.Phase, request.Event.ParentTaskMetadata)\n\n\texecutionID := request.Event.Id.ExecutionId\n\tworkflowExecution, err := m.db.ExecutionRepo().Get(ctx, repoInterfaces.Identifier{\n\t\tProject: executionID.Project,\n\t\tDomain:  executionID.Domain,\n\t\tName:    executionID.Name,\n\t})\n\tif err != nil {\n\t\tm.metrics.MissingWorkflowExecution.Inc()\n\t\tlogger.Debugf(ctx, \"Failed to find existing execution with id [%+v] with err: %v\", executionID, err)\n\t\tif err != nil {\n\t\t\tif ferr, ok := err.(errors.FlyteAdminError); ok {\n\t\t\t\treturn nil, errors.NewFlyteAdminErrorf(ferr.Code(),\n\t\t\t\t\t\"Failed to get existing execution id: [%+v] with err: %v\", executionID, err)\n\t\t\t}\n\t\t}\n\t\treturn nil, fmt.Errorf(\"failed to get existing execution id: [%+v]\", executionID)\n\t}\n\n\tif err := validation.ValidateCluster(ctx, workflowExecution.Cluster, request.Event.ProducerId); err != nil {\n\t\treturn nil, err\n\t}\n\n\tvar dynamicWorkflowRemoteClosureReference string\n\tif request.Event.GetTaskNodeMetadata() != nil && request.Event.GetTaskNodeMetadata().DynamicWorkflow != nil {\n\t\tdynamicWorkflowRemoteClosureDataReference, err := m.uploadDynamicWorkflowClosure(\n\t\t\tctx, request.Event.Id, request.Event.GetTaskNodeMetadata().DynamicWorkflow.Id,\n\t\t\trequest.Event.GetTaskNodeMetadata().DynamicWorkflow.CompiledWorkflow)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tdynamicWorkflowRemoteClosureReference = dynamicWorkflowRemoteClosureDataReference.String()\n\t}\n\n\tnodeExecutionModel, err := m.db.NodeExecutionRepo().Get(ctx, repoInterfaces.NodeExecutionResource{\n\t\tNodeExecutionIdentifier: *request.Event.Id,\n\t})\n\tif err != nil {\n\t\tif err.(errors.FlyteAdminError).Code() != codes.NotFound {\n\t\t\tlogger.Debugf(ctx, \"Failed to retrieve existing node execution with id [%+v] with err: %v\",\n\t\t\t\trequest.Event.Id, err)\n\t\t\treturn nil, err\n\t\t}\n\t\terr = m.createNodeExecutionWithEvent(ctx, &request, dynamicWorkflowRemoteClosureReference)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tm.metrics.NodeExecutionsCreated.Inc()\n\t} else {\n\t\tphase := core.NodeExecution_Phase(core.NodeExecution_Phase_value[nodeExecutionModel.Phase])\n\t\tupdateStatus, err := m.updateNodeExecutionWithEvent(ctx, &request, &nodeExecutionModel, dynamicWorkflowRemoteClosureReference)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tif updateStatus == alreadyInTerminalStatus {\n\t\t\tcurPhase := request.Event.Phase.String()\n\t\t\terrorMsg := fmt.Sprintf(\"Invalid phase change from %s to %s for node execution %v\", phase.String(), curPhase, nodeExecutionModel.ID)\n\t\t\treturn nil, errors.NewAlreadyInTerminalStateError(ctx, errorMsg, curPhase)\n\t\t}\n\t}\n\tm.dbEventWriter.Write(request)\n\n\tif request.Event.Phase == core.NodeExecution_RUNNING {\n\t\tm.metrics.ActiveNodeExecutions.Inc()\n\t} else if common.IsNodeExecutionTerminal(request.Event.Phase) {\n\t\tm.metrics.ActiveNodeExecutions.Dec()\n\t\tm.metrics.NodeExecutionsTerminated.Inc(contextutils.WithPhase(ctx, request.Event.Phase.String()))\n\t\tif request.Event.GetOutputData() != nil {\n\t\t\tm.metrics.NodeExecutionOutputBytes.Observe(float64(proto.Size(request.Event.GetOutputData())))\n\t\t}\n\t}\n\tm.metrics.NodeExecutionEventsCreated.Inc()\n\n\tif err := m.eventPublisher.Publish(ctx, proto.MessageName(&request), &request); err != nil {\n\t\tm.metrics.PublishEventError.Inc()\n\t\tlogger.Infof(ctx, \"error publishing event [%+v] with err: [%v]\", request.RequestId, err)\n\t}\n\n\tgo func() {\n\t\tif err := m.cloudEventPublisher.Publish(ctx, proto.MessageName(&request), &request); err != nil {\n\t\t\tlogger.Infof(ctx, \"error publishing cloud event [%+v] with err: [%v]\", request.RequestId, err)\n\t\t}\n\t}()\n\n\treturn &admin.NodeExecutionEventResponse{}, nil\n}\n\n// Handles making additional database calls, if necessary, to populate IsParent & IsDynamic data using the historical pattern of\n// preloading child node executions. Otherwise, simply calls transform on the input model.\nfunc (m *NodeExecutionManager) transformNodeExecutionModel(ctx context.Context, nodeExecutionModel models.NodeExecution,\n\tnodeExecutionID *core.NodeExecutionIdentifier, opts *transformers.ExecutionTransformerOptions) (*admin.NodeExecution, error) {\n\tinternalData, err := transformers.GetNodeExecutionInternalData(nodeExecutionModel.InternalData)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif internalData.EventVersion == 0 {\n\t\t// Issue more expensive query to determine whether this node is a parent and/or dynamic node.\n\t\tnodeExecutionModel, err = m.db.NodeExecutionRepo().GetWithChildren(ctx, repoInterfaces.NodeExecutionResource{\n\t\t\tNodeExecutionIdentifier: *nodeExecutionID,\n\t\t})\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\tnodeExecution, err := transformers.FromNodeExecutionModel(nodeExecutionModel, opts)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"failed to transform node execution model [%+v] to proto with err: %v\", nodeExecutionID, err)\n\t\treturn nil, err\n\t}\n\treturn nodeExecution, nil\n}\n\nfunc (m *NodeExecutionManager) transformNodeExecutionModelList(ctx context.Context, nodeExecutionModels []models.NodeExecution) ([]*admin.NodeExecution, error) {\n\tnodeExecutions := make([]*admin.NodeExecution, len(nodeExecutionModels))\n\tfor idx, nodeExecutionModel := range nodeExecutionModels {\n\t\tnodeExecution, err := m.transformNodeExecutionModel(ctx, nodeExecutionModel, &core.NodeExecutionIdentifier{\n\t\t\tExecutionId: &core.WorkflowExecutionIdentifier{\n\t\t\t\tProject: nodeExecutionModel.Project,\n\t\t\t\tDomain:  nodeExecutionModel.Domain,\n\t\t\t\tName:    nodeExecutionModel.Name,\n\t\t\t},\n\t\t\tNodeId: nodeExecutionModel.NodeID,\n\t\t}, transformers.ListExecutionTransformerOptions)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tnodeExecutions[idx] = nodeExecution\n\t}\n\treturn nodeExecutions, nil\n}\n\nfunc (m *NodeExecutionManager) GetNodeExecution(\n\tctx context.Context, request admin.NodeExecutionGetRequest) (*admin.NodeExecution, error) {\n\tif err := validation.ValidateNodeExecutionIdentifier(request.Id); err != nil {\n\t\tlogger.Debugf(ctx, \"get node execution called with invalid identifier [%+v]: %v\", request.Id, err)\n\t}\n\tctx = getNodeExecutionContext(ctx, request.Id)\n\tnodeExecutionModel, err := util.GetNodeExecutionModel(ctx, m.db, request.Id)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"Failed to get node execution with id [%+v] with err %v\",\n\t\t\trequest.Id, err)\n\t\treturn nil, err\n\t}\n\tnodeExecution, err := m.transformNodeExecutionModel(ctx, *nodeExecutionModel, request.Id, nil)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn nodeExecution, nil\n}\n\nfunc (m *NodeExecutionManager) listNodeExecutions(\n\tctx context.Context, identifierFilters []common.InlineFilter,\n\trequestFilters string, limit uint32, requestToken string, sortBy *admin.Sort, mapFilters []common.MapFilter) (\n\t*admin.NodeExecutionList, error) {\n\n\tfilters, err := util.AddRequestFilters(requestFilters, common.NodeExecution, identifierFilters)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tsortParameter, err := common.NewSortParameter(sortBy, models.NodeExecutionColumns)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\toffset, err := validation.ValidateToken(requestToken)\n\tif err != nil {\n\t\treturn nil, errors.NewFlyteAdminErrorf(codes.InvalidArgument,\n\t\t\t\"invalid pagination token %s for ListNodeExecutions\", requestToken)\n\t}\n\tlistInput := repoInterfaces.ListResourceInput{\n\t\tLimit:         int(limit),\n\t\tOffset:        offset,\n\t\tInlineFilters: filters,\n\t\tSortParameter: sortParameter,\n\t}\n\n\tlistInput.MapFilters = mapFilters\n\toutput, err := m.db.NodeExecutionRepo().List(ctx, listInput)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"Failed to list node executions for request with err %v\", err)\n\t\treturn nil, err\n\t}\n\n\tvar token string\n\tif len(output.NodeExecutions) == int(limit) {\n\t\ttoken = strconv.Itoa(offset + len(output.NodeExecutions))\n\t}\n\tnodeExecutionList, err := m.transformNodeExecutionModelList(ctx, output.NodeExecutions)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"failed to transform node execution models for request with err: %v\", err)\n\t\treturn nil, err\n\t}\n\n\treturn &admin.NodeExecutionList{\n\t\tNodeExecutions: nodeExecutionList,\n\t\tToken:          token,\n\t}, nil\n}\n\nfunc (m *NodeExecutionManager) ListNodeExecutions(\n\tctx context.Context, request admin.NodeExecutionListRequest) (*admin.NodeExecutionList, error) {\n\t// Check required fields\n\tif err := validation.ValidateNodeExecutionListRequest(request); err != nil {\n\t\treturn nil, err\n\t}\n\tctx = getExecutionContext(ctx, request.WorkflowExecutionId)\n\n\tidentifierFilters, err := util.GetWorkflowExecutionIdentifierFilters(ctx, *request.WorkflowExecutionId)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tvar mapFilters []common.MapFilter\n\tif request.UniqueParentId != \"\" {\n\t\tparentNodeExecution, err := util.GetNodeExecutionModel(ctx, m.db, &core.NodeExecutionIdentifier{\n\t\t\tExecutionId: request.WorkflowExecutionId,\n\t\t\tNodeId:      request.UniqueParentId,\n\t\t})\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tparentIDFilter, err := common.NewSingleValueFilter(\n\t\t\tcommon.NodeExecution, common.Equal, shared.ParentID, parentNodeExecution.ID)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tidentifierFilters = append(identifierFilters, parentIDFilter)\n\t} else {\n\t\tmapFilters = []common.MapFilter{\n\t\t\tisParent,\n\t\t}\n\t}\n\treturn m.listNodeExecutions(\n\t\tctx, identifierFilters, request.Filters, request.Limit, request.Token, request.SortBy, mapFilters)\n}\n\n// Filters on node executions matching the execution parameters (execution project, domain, and name) as well as the\n// parent task execution id corresponding to the task execution identified in the request params.\nfunc (m *NodeExecutionManager) ListNodeExecutionsForTask(\n\tctx context.Context, request admin.NodeExecutionForTaskListRequest) (*admin.NodeExecutionList, error) {\n\t// Check required fields\n\tif err := validation.ValidateNodeExecutionForTaskListRequest(request); err != nil {\n\t\treturn nil, err\n\t}\n\tctx = getTaskExecutionContext(ctx, request.TaskExecutionId)\n\tidentifierFilters, err := util.GetWorkflowExecutionIdentifierFilters(\n\t\tctx, *request.TaskExecutionId.NodeExecutionId.ExecutionId)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tparentTaskExecutionModel, err := util.GetTaskExecutionModel(ctx, m.db, request.TaskExecutionId)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tnodeIDFilter, err := common.NewSingleValueFilter(\n\t\tcommon.NodeExecution, common.Equal, shared.ParentTaskExecutionID, parentTaskExecutionModel.ID)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tidentifierFilters = append(identifierFilters, nodeIDFilter)\n\treturn m.listNodeExecutions(\n\t\tctx, identifierFilters, request.Filters, request.Limit, request.Token, request.SortBy, nil)\n}\n\nfunc (m *NodeExecutionManager) GetNodeExecutionData(\n\tctx context.Context, request admin.NodeExecutionGetDataRequest) (*admin.NodeExecutionGetDataResponse, error) {\n\tif err := validation.ValidateNodeExecutionIdentifier(request.Id); err != nil {\n\t\tlogger.Debugf(ctx, \"can't get node execution data with invalid identifier [%+v]: %v\", request.Id, err)\n\t}\n\n\tctx = getNodeExecutionContext(ctx, request.Id)\n\tnodeExecutionModel, err := util.GetNodeExecutionModel(ctx, m.db, request.Id)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"Failed to get node execution with id [%+v] with err %v\",\n\t\t\trequest.Id, err)\n\t\treturn nil, err\n\t}\n\n\tnodeExecution, err := transformers.FromNodeExecutionModel(*nodeExecutionModel, transformers.DefaultExecutionTransformerOptions)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"failed to transform node execution model [%+v] when fetching data: %v\", request.Id, err)\n\t\treturn nil, err\n\t}\n\n\tinputs, inputURLBlob, err := util.GetInputs(ctx, m.urlData, m.config.ApplicationConfiguration().GetRemoteDataConfig(),\n\t\tm.storageClient, nodeExecution.InputUri)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\toutputs, outputURLBlob, err := util.GetOutputs(ctx, m.urlData, m.config.ApplicationConfiguration().GetRemoteDataConfig(),\n\t\tm.storageClient, nodeExecution.Closure)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tresponse := &admin.NodeExecutionGetDataResponse{\n\t\tInputs:      inputURLBlob,\n\t\tOutputs:     outputURLBlob,\n\t\tFullInputs:  inputs,\n\t\tFullOutputs: outputs,\n\t\tFlyteUrls:   common.FlyteURLsFromNodeExecutionID(*request.Id, nodeExecution.GetClosure() != nil && nodeExecution.GetClosure().GetDeckUri() != \"\"),\n\t}\n\n\tif len(nodeExecutionModel.DynamicWorkflowRemoteClosureReference) > 0 {\n\t\tclosure := &core.CompiledWorkflowClosure{}\n\t\terr := m.storageClient.ReadProtobuf(ctx, storage.DataReference(nodeExecutionModel.DynamicWorkflowRemoteClosureReference), closure)\n\t\tif err != nil {\n\t\t\treturn nil, errors.NewFlyteAdminErrorf(codes.Internal,\n\t\t\t\t\"Unable to read WorkflowClosure from location %s : %v\", nodeExecutionModel.DynamicWorkflowRemoteClosureReference, err)\n\t\t}\n\n\t\tif wf := closure.Primary; wf == nil {\n\t\t\treturn nil, errors.NewFlyteAdminErrorf(codes.Internal, \"Empty primary workflow definition in loaded dynamic workflow model.\")\n\t\t} else if template := wf.Template; template == nil {\n\t\t\treturn nil, errors.NewFlyteAdminErrorf(codes.Internal, \"Empty primary workflow template in loaded dynamic workflow model.\")\n\t\t} else {\n\t\t\tresponse.DynamicWorkflow = &admin.DynamicWorkflowNodeMetadata{\n\t\t\t\tId:                closure.Primary.Template.Id,\n\t\t\t\tCompiledWorkflow:  closure,\n\t\t\t\tDynamicJobSpecUri: nodeExecution.Closure.DynamicJobSpecUri,\n\t\t\t}\n\t\t}\n\t}\n\n\tm.metrics.NodeExecutionInputBytes.Observe(float64(response.Inputs.Bytes))\n\tif response.Outputs.Bytes > 0 {\n\t\tm.metrics.NodeExecutionOutputBytes.Observe(float64(response.Outputs.Bytes))\n\t} else if response.FullOutputs != nil {\n\t\tm.metrics.NodeExecutionOutputBytes.Observe(float64(proto.Size(response.FullOutputs)))\n\t}\n\n\treturn response, nil\n}\n\nfunc NewNodeExecutionManager(db repoInterfaces.Repository, config runtimeInterfaces.Configuration,\n\tstoragePrefix []string, storageClient *storage.DataStore, scope promutils.Scope, urlData dataInterfaces.RemoteURLInterface,\n\teventPublisher notificationInterfaces.Publisher, cloudEventPublisher cloudeventInterfaces.Publisher,\n\teventWriter eventWriter.NodeExecutionEventWriter) interfaces.NodeExecutionInterface {\n\tmetrics := nodeExecutionMetrics{\n\t\tScope: scope,\n\t\tActiveNodeExecutions: scope.MustNewGauge(\"active_node_executions\",\n\t\t\t\"overall count of active node executions\"),\n\t\tNodeExecutionsCreated: scope.MustNewCounter(\"node_executions_created\",\n\t\t\t\"overall count of node executions created\"),\n\t\tNodeExecutionsTerminated: labeled.NewCounter(\"node_executions_terminated\",\n\t\t\t\"overall count of terminated node executions\", scope),\n\t\tNodeExecutionEventsCreated: scope.MustNewCounter(\"node_execution_events_created\",\n\t\t\t\"overall count of successfully completed NodeExecutionEventRequest\"),\n\t\tMissingWorkflowExecution: scope.MustNewCounter(\"missing_workflow_execution\",\n\t\t\t\"overall count of node execution events received that are missing a parent workflow execution\"),\n\t\tClosureSizeBytes: scope.MustNewSummary(\"closure_size_bytes\",\n\t\t\t\"size in bytes of serialized node execution closure\"),\n\t\tNodeExecutionInputBytes: scope.MustNewSummary(\"input_size_bytes\",\n\t\t\t\"size in bytes of serialized node execution inputs\"),\n\t\tNodeExecutionOutputBytes: scope.MustNewSummary(\"output_size_bytes\",\n\t\t\t\"size in bytes of serialized node execution outputs\"),\n\t\tPublishEventError: scope.MustNewCounter(\"publish_event_error\",\n\t\t\t\"overall count of publish event errors when invoking publish()\"),\n\t}\n\treturn &NodeExecutionManager{\n\t\tdb:                  db,\n\t\tconfig:              config,\n\t\tstoragePrefix:       storagePrefix,\n\t\tstorageClient:       storageClient,\n\t\tmetrics:             metrics,\n\t\turlData:             urlData,\n\t\teventPublisher:      eventPublisher,\n\t\tdbEventWriter:       eventWriter,\n\t\tcloudEventPublisher: cloudEventPublisher,\n\t}\n}\n", "package impl\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"fmt\"\n\t\"testing\"\n\t\"time\"\n\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/transformers\"\n\n\t\"github.com/flyteorg/flyteadmin/pkg/manager/impl/util\"\n\n\tgenModel \"github.com/flyteorg/flyteadmin/pkg/repositories/gen/models\"\n\n\teventWriterMocks \"github.com/flyteorg/flyteadmin/pkg/async/events/mocks\"\n\n\t\"github.com/flyteorg/flytestdlib/storage\"\n\n\t\"github.com/flyteorg/flyteadmin/pkg/manager/impl/testutils\"\n\n\t\"github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/admin\"\n\t\"github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/core\"\n\t\"github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/event\"\n\tmockScope \"github.com/flyteorg/flytestdlib/promutils\"\n\t\"github.com/golang/protobuf/proto\"\n\t\"github.com/golang/protobuf/ptypes\"\n\t\"github.com/stretchr/testify/assert\"\n\t\"google.golang.org/grpc/codes\"\n\n\t\"github.com/flyteorg/flyteadmin/pkg/common\"\n\tcommonMocks \"github.com/flyteorg/flyteadmin/pkg/common/mocks\"\n\tdataMocks \"github.com/flyteorg/flyteadmin/pkg/data/mocks\"\n\tflyteAdminErrors \"github.com/flyteorg/flyteadmin/pkg/errors\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/interfaces\"\n\trepositoryMocks \"github.com/flyteorg/flyteadmin/pkg/repositories/mocks\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/models\"\n)\n\nvar occurredAt = time.Now().UTC()\nvar occurredAtProto, _ = ptypes.TimestampProto(occurredAt)\n\nvar dynamicWorkflowClosure = core.CompiledWorkflowClosure{\n\tPrimary: &core.CompiledWorkflow{\n\t\tTemplate: &core.WorkflowTemplate{\n\t\t\tId: &core.Identifier{\n\t\t\t\tResourceType: core.ResourceType_WORKFLOW,\n\t\t\t\tProject:      \"proj\",\n\t\t\t\tDomain:       \"domain\",\n\t\t\t\tName:         \"dynamic_wf\",\n\t\t\t\tVersion:      \"abc123\",\n\t\t\t},\n\t\t},\n\t},\n}\n\nvar request = admin.NodeExecutionEventRequest{\n\tRequestId: \"request id\",\n\tEvent: &event.NodeExecutionEvent{\n\t\tProducerId: \"propeller\",\n\t\tId: &core.NodeExecutionIdentifier{\n\t\t\tNodeId: \"node id\",\n\t\t\tExecutionId: &core.WorkflowExecutionIdentifier{\n\t\t\t\tProject: \"project\",\n\t\t\t\tDomain:  \"domain\",\n\t\t\t\tName:    \"name\",\n\t\t\t},\n\t\t},\n\t\tOccurredAt: occurredAtProto,\n\t\tPhase:      core.NodeExecution_RUNNING,\n\t\tInputValue: &event.NodeExecutionEvent_InputUri{\n\t\t\tInputUri: \"input uri\",\n\t\t},\n\t\tTargetMetadata: &event.NodeExecutionEvent_TaskNodeMetadata{\n\t\t\tTaskNodeMetadata: &event.TaskNodeMetadata{\n\t\t\t\tDynamicWorkflow: &event.DynamicWorkflowNodeMetadata{\n\t\t\t\t\tId:               dynamicWorkflowClosure.Primary.Template.Id,\n\t\t\t\t\tCompiledWorkflow: &dynamicWorkflowClosure,\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\tEventVersion: 2,\n\t},\n}\nvar internalData = genModel.NodeExecutionInternalData{\n\tEventVersion: 2,\n}\nvar internalDataBytes, _ = proto.Marshal(&internalData)\nvar nodeExecutionIdentifier = core.NodeExecutionIdentifier{\n\tNodeId: \"node id\",\n\tExecutionId: &core.WorkflowExecutionIdentifier{\n\t\tProject: \"project\",\n\t\tDomain:  \"domain\",\n\t\tName:    \"name\",\n\t},\n}\nvar workflowExecutionIdentifier = core.WorkflowExecutionIdentifier{\n\tProject: \"project\",\n\tDomain:  \"domain\",\n\tName:    \"name\",\n}\n\nvar mockNodeExecutionRemoteURL = dataMocks.NewMockRemoteURL()\n\nfunc addGetExecutionCallback(t *testing.T, repository interfaces.Repository) {\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetGetCallback(\n\t\tfunc(ctx context.Context, input interfaces.Identifier) (models.Execution, error) {\n\t\t\tassert.Equal(t, \"project\", input.Project)\n\t\t\tassert.Equal(t, \"domain\", input.Domain)\n\t\t\tassert.Equal(t, \"name\", input.Name)\n\t\t\treturn models.Execution{\n\t\t\t\tBaseModel: models.BaseModel{\n\t\t\t\t\tID: uint(8),\n\t\t\t\t},\n\t\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\t\tProject: \"project\",\n\t\t\t\t\tDomain:  \"domain\",\n\t\t\t\t\tName:    \"name\",\n\t\t\t\t},\n\t\t\t\tCluster: \"propeller\",\n\t\t\t}, nil\n\t\t})\n}\n\nfunc TestCreateNodeEvent(t *testing.T) {\n\trepository := repositoryMocks.NewMockRepository()\n\taddGetExecutionCallback(t, repository)\n\trepository.NodeExecutionRepo().(*repositoryMocks.MockNodeExecutionRepo).SetGetCallback(\n\t\tfunc(ctx context.Context, input interfaces.NodeExecutionResource) (models.NodeExecution, error) {\n\t\t\tassert.True(t, proto.Equal(&core.NodeExecutionIdentifier{\n\t\t\t\tNodeId:      \"node id\",\n\t\t\t\tExecutionId: &workflowExecutionIdentifier,\n\t\t\t}, &input.NodeExecutionIdentifier))\n\t\t\treturn models.NodeExecution{}, flyteAdminErrors.NewFlyteAdminError(codes.NotFound, \"foo\")\n\t\t})\n\texpectedClosure := admin.NodeExecutionClosure{\n\t\tPhase:     request.Event.Phase,\n\t\tStartedAt: occurredAtProto,\n\t\tCreatedAt: occurredAtProto,\n\t\tUpdatedAt: occurredAtProto,\n\t\tTargetMetadata: &admin.NodeExecutionClosure_TaskNodeMetadata{\n\t\t\tTaskNodeMetadata: &admin.TaskNodeMetadata{},\n\t\t},\n\t}\n\tclosureBytes, _ := proto.Marshal(&expectedClosure)\n\trepository.NodeExecutionRepo().(*repositoryMocks.MockNodeExecutionRepo).SetCreateCallback(\n\t\tfunc(ctx context.Context, input *models.NodeExecution) error {\n\t\t\tassert.Equal(t, models.NodeExecution{\n\t\t\t\tNodeExecutionKey: models.NodeExecutionKey{\n\t\t\t\t\tNodeID: \"node id\",\n\t\t\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\t\t\tProject: \"project\",\n\t\t\t\t\t\tDomain:  \"domain\",\n\t\t\t\t\t\tName:    \"name\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tPhase:                                 core.NodeExecution_RUNNING.String(),\n\t\t\t\tInputURI:                              \"input uri\",\n\t\t\t\tStartedAt:                             &occurredAt,\n\t\t\t\tClosure:                               closureBytes,\n\t\t\t\tNodeExecutionMetadata:                 []byte{},\n\t\t\t\tNodeExecutionCreatedAt:                &occurredAt,\n\t\t\t\tNodeExecutionUpdatedAt:                &occurredAt,\n\t\t\t\tDynamicWorkflowRemoteClosureReference: \"s3://bucket/admin/metadata/project/domain/name/node id/proj_domain_dynamic_wf_abc123\",\n\t\t\t\tInternalData:                          internalDataBytes,\n\t\t\t}, *input)\n\t\t\treturn nil\n\t\t})\n\n\tmockDbEventWriter := &eventWriterMocks.NodeExecutionEventWriter{}\n\tmockDbEventWriter.On(\"Write\", request)\n\tnodeExecManager := NewNodeExecutionManager(repository, getMockExecutionsConfigProvider(),\n\t\t[]string{\"admin\", \"metadata\"}, getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockNodeExecutionRemoteURL,\n\t\t&mockPublisher, &mockPublisher, mockDbEventWriter)\n\tresp, err := nodeExecManager.CreateNodeEvent(context.Background(), request)\n\tassert.Nil(t, err)\n\tassert.NotNil(t, resp)\n}\n\nfunc TestCreateNodeEvent_Update(t *testing.T) {\n\trepository := repositoryMocks.NewMockRepository()\n\taddGetExecutionCallback(t, repository)\n\trepository.NodeExecutionRepo().(*repositoryMocks.MockNodeExecutionRepo).SetGetCallback(\n\t\tfunc(ctx context.Context, input interfaces.NodeExecutionResource) (models.NodeExecution, error) {\n\t\t\tassert.True(t, proto.Equal(&core.NodeExecutionIdentifier{\n\t\t\t\tNodeId:      \"node id\",\n\t\t\t\tExecutionId: &workflowExecutionIdentifier,\n\t\t\t}, &input.NodeExecutionIdentifier))\n\t\t\treturn models.NodeExecution{\n\t\t\t\tNodeExecutionKey: models.NodeExecutionKey{\n\t\t\t\t\tNodeID: \"node id\",\n\t\t\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\t\t\tProject: \"project\",\n\t\t\t\t\t\tDomain:  \"domain\",\n\t\t\t\t\t\tName:    \"name\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tPhase:     core.NodeExecution_UNDEFINED.String(),\n\t\t\t\tInputURI:  \"input uri\",\n\t\t\t\tStartedAt: &occurredAt,\n\t\t\t}, nil\n\t\t})\n\trepository.NodeExecutionRepo().(*repositoryMocks.MockNodeExecutionRepo).SetUpdateCallback(\n\t\tfunc(ctx context.Context, nodeExecution *models.NodeExecution) error {\n\t\t\texpectedClosure := admin.NodeExecutionClosure{\n\t\t\t\tStartedAt: occurredAtProto,\n\t\t\t\tPhase:     core.NodeExecution_RUNNING,\n\t\t\t\tUpdatedAt: occurredAtProto,\n\t\t\t\tTargetMetadata: &admin.NodeExecutionClosure_TaskNodeMetadata{\n\t\t\t\t\tTaskNodeMetadata: &admin.TaskNodeMetadata{},\n\t\t\t\t},\n\t\t\t}\n\t\t\texpectedClosureBytes, _ := proto.Marshal(&expectedClosure)\n\t\t\tactualClosure := admin.NodeExecutionClosure{}\n\t\t\t_ = proto.Unmarshal(nodeExecution.Closure, &actualClosure)\n\t\t\tassert.Equal(t, models.NodeExecution{\n\t\t\t\tNodeExecutionKey: models.NodeExecutionKey{\n\t\t\t\t\tNodeID: \"node id\",\n\t\t\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\t\t\tProject: \"project\",\n\t\t\t\t\t\tDomain:  \"domain\",\n\t\t\t\t\t\tName:    \"name\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tPhase:                                 core.NodeExecution_RUNNING.String(),\n\t\t\t\tInputURI:                              \"input uri\",\n\t\t\t\tStartedAt:                             &occurredAt,\n\t\t\t\tClosure:                               expectedClosureBytes,\n\t\t\t\tNodeExecutionUpdatedAt:                &occurredAt,\n\t\t\t\tDynamicWorkflowRemoteClosureReference: \"s3://bucket/admin/metadata/project/domain/name/node id/proj_domain_dynamic_wf_abc123\",\n\t\t\t}, *nodeExecution)\n\n\t\t\treturn nil\n\t\t})\n\n\tmockDbEventWriter := &eventWriterMocks.NodeExecutionEventWriter{}\n\tmockDbEventWriter.On(\"Write\", request)\n\tnodeExecManager := NewNodeExecutionManager(repository, getMockExecutionsConfigProvider(),\n\t\t[]string{\"admin\", \"metadata\"}, getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockNodeExecutionRemoteURL, &mockPublisher, &mockPublisher, mockDbEventWriter)\n\tresp, err := nodeExecManager.CreateNodeEvent(context.Background(), request)\n\tassert.Nil(t, err)\n\tassert.NotNil(t, resp)\n}\n\nfunc TestCreateNodeEvent_MissingExecution(t *testing.T) {\n\trepository := repositoryMocks.NewMockRepository()\n\texpectedErr := flyteAdminErrors.NewFlyteAdminErrorf(codes.Internal, \"expected error\")\n\trepository.NodeExecutionRepo().(*repositoryMocks.MockNodeExecutionRepo).SetGetCallback(\n\t\tfunc(ctx context.Context, input interfaces.NodeExecutionResource) (models.NodeExecution, error) {\n\t\t\treturn models.NodeExecution{}, expectedErr\n\t\t})\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetGetCallback(\n\t\tfunc(ctx context.Context, input interfaces.Identifier) (models.Execution, error) {\n\t\t\treturn models.Execution{}, expectedErr\n\t\t})\n\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetGetCallback(func(ctx context.Context, input interfaces.Identifier) (models.Execution, error) {\n\t\treturn models.Execution{}, expectedErr\n\t})\n\tnodeExecManager := NewNodeExecutionManager(repository, getMockExecutionsConfigProvider(), make([]string, 0), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockNodeExecutionRemoteURL, &mockPublisher, &mockPublisher, &eventWriterMocks.NodeExecutionEventWriter{})\n\tresp, err := nodeExecManager.CreateNodeEvent(context.Background(), request)\n\tassert.EqualError(t, err, \"Failed to get existing execution id: [project:\\\"project\\\" domain:\\\"domain\\\" name:\\\"name\\\" ] with err: expected error\")\n\tassert.Nil(t, resp)\n}\n\nfunc TestCreateNodeEvent_CreateDatabaseError(t *testing.T) {\n\trepository := repositoryMocks.NewMockRepository()\n\taddGetExecutionCallback(t, repository)\n\trepository.NodeExecutionRepo().(*repositoryMocks.MockNodeExecutionRepo).SetGetCallback(\n\t\tfunc(ctx context.Context, input interfaces.NodeExecutionResource) (models.NodeExecution, error) {\n\t\t\treturn models.NodeExecution{}, flyteAdminErrors.NewFlyteAdminError(codes.NotFound, \"foo\")\n\t\t})\n\n\texpectedErr := errors.New(\"expected error\")\n\trepository.NodeExecutionRepo().(*repositoryMocks.MockNodeExecutionRepo).SetCreateCallback(\n\t\tfunc(ctx context.Context, input *models.NodeExecution) error {\n\t\t\treturn expectedErr\n\t\t})\n\tnodeExecManager := NewNodeExecutionManager(repository, getMockExecutionsConfigProvider(), make([]string, 0), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockNodeExecutionRemoteURL, nil, nil, &eventWriterMocks.NodeExecutionEventWriter{})\n\tresp, err := nodeExecManager.CreateNodeEvent(context.Background(), request)\n\tassert.EqualError(t, err, expectedErr.Error())\n\tassert.Nil(t, resp)\n}\n\nfunc TestCreateNodeEvent_UpdateDatabaseError(t *testing.T) {\n\trepository := repositoryMocks.NewMockRepository()\n\taddGetExecutionCallback(t, repository)\n\trepository.NodeExecutionRepo().(*repositoryMocks.MockNodeExecutionRepo).SetGetCallback(\n\t\tfunc(ctx context.Context, input interfaces.NodeExecutionResource) (models.NodeExecution, error) {\n\t\t\tassert.True(t, proto.Equal(&core.NodeExecutionIdentifier{\n\t\t\t\tNodeId:      \"node id\",\n\t\t\t\tExecutionId: &workflowExecutionIdentifier,\n\t\t\t}, &input.NodeExecutionIdentifier))\n\t\t\treturn models.NodeExecution{\n\t\t\t\tNodeExecutionKey: models.NodeExecutionKey{\n\t\t\t\t\tNodeID: \"node id\",\n\t\t\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\t\t\tProject: \"project\",\n\t\t\t\t\t\tDomain:  \"domain\",\n\t\t\t\t\t\tName:    \"name\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tPhase:     core.NodeExecution_UNDEFINED.String(),\n\t\t\t\tInputURI:  \"input uri\",\n\t\t\t\tStartedAt: &occurredAt,\n\t\t\t}, nil\n\t\t})\n\n\texpectedErr := errors.New(\"expected error\")\n\trepository.NodeExecutionRepo().(*repositoryMocks.MockNodeExecutionRepo).SetUpdateCallback(\n\t\tfunc(ctx context.Context, nodeExecution *models.NodeExecution) error {\n\t\t\treturn expectedErr\n\t\t})\n\tnodeExecManager := NewNodeExecutionManager(repository, getMockExecutionsConfigProvider(), make([]string, 0), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockNodeExecutionRemoteURL, nil, nil, &eventWriterMocks.NodeExecutionEventWriter{})\n\tresp, err := nodeExecManager.CreateNodeEvent(context.Background(), request)\n\tassert.EqualError(t, err, expectedErr.Error())\n\tassert.Nil(t, resp)\n}\n\nfunc TestCreateNodeEvent_UpdateTerminalEventError(t *testing.T) {\n\trepository := repositoryMocks.NewMockRepository()\n\taddGetExecutionCallback(t, repository)\n\trepository.NodeExecutionRepo().(*repositoryMocks.MockNodeExecutionRepo).SetGetCallback(\n\t\tfunc(ctx context.Context, input interfaces.NodeExecutionResource) (models.NodeExecution, error) {\n\t\t\tassert.True(t, proto.Equal(&core.NodeExecutionIdentifier{\n\t\t\t\tNodeId:      \"node id\",\n\t\t\t\tExecutionId: &workflowExecutionIdentifier,\n\t\t\t}, &input.NodeExecutionIdentifier))\n\t\t\treturn models.NodeExecution{\n\t\t\t\tNodeExecutionKey: models.NodeExecutionKey{\n\t\t\t\t\tNodeID: \"node id\",\n\t\t\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\t\t\tProject: \"project\",\n\t\t\t\t\t\tDomain:  \"domain\",\n\t\t\t\t\t\tName:    \"name\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tPhase:     core.NodeExecution_SUCCEEDED.String(),\n\t\t\t\tInputURI:  \"input uri\",\n\t\t\t\tStartedAt: &occurredAt,\n\t\t\t}, nil\n\t\t})\n\tnodeExecManager := NewNodeExecutionManager(repository, getMockExecutionsConfigProvider(), make([]string, 0), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockNodeExecutionRemoteURL, nil, nil, &eventWriterMocks.NodeExecutionEventWriter{})\n\tresp, err := nodeExecManager.CreateNodeEvent(context.Background(), request)\n\tassert.Nil(t, resp)\n\tassert.NotNil(t, err)\n\tadminError := err.(flyteAdminErrors.FlyteAdminError)\n\tassert.Equal(t, codes.FailedPrecondition, adminError.GRPCStatus().Code())\n\tdetails, ok := adminError.GRPCStatus().Details()[0].(*admin.EventFailureReason)\n\tassert.True(t, ok)\n\t_, ok = details.GetReason().(*admin.EventFailureReason_AlreadyInTerminalState)\n\tassert.True(t, ok)\n}\n\nfunc TestCreateNodeEvent_UpdateDuplicateEventError(t *testing.T) {\n\trepository := repositoryMocks.NewMockRepository()\n\taddGetExecutionCallback(t, repository)\n\trepository.NodeExecutionRepo().(*repositoryMocks.MockNodeExecutionRepo).SetGetCallback(\n\t\tfunc(ctx context.Context, input interfaces.NodeExecutionResource) (models.NodeExecution, error) {\n\t\t\tassert.True(t, proto.Equal(&core.NodeExecutionIdentifier{\n\t\t\t\tNodeId:      \"node id\",\n\t\t\t\tExecutionId: &workflowExecutionIdentifier,\n\t\t\t}, &input.NodeExecutionIdentifier))\n\t\t\treturn models.NodeExecution{\n\t\t\t\tNodeExecutionKey: models.NodeExecutionKey{\n\t\t\t\t\tNodeID: \"node id\",\n\t\t\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\t\t\tProject: \"project\",\n\t\t\t\t\t\tDomain:  \"domain\",\n\t\t\t\t\t\tName:    \"name\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tPhase:     core.NodeExecution_RUNNING.String(),\n\t\t\t\tInputURI:  \"input uri\",\n\t\t\t\tStartedAt: &occurredAt,\n\t\t\t}, nil\n\t\t})\n\tnodeExecManager := NewNodeExecutionManager(repository, getMockExecutionsConfigProvider(), make([]string, 0), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockNodeExecutionRemoteURL, nil, nil, &eventWriterMocks.NodeExecutionEventWriter{})\n\tresp, err := nodeExecManager.CreateNodeEvent(context.Background(), request)\n\tassert.Equal(t, codes.AlreadyExists, err.(flyteAdminErrors.FlyteAdminError).Code())\n\tassert.Nil(t, resp)\n}\n\nfunc TestCreateNodeEvent_FirstEventIsTerminal(t *testing.T) {\n\trepository := repositoryMocks.NewMockRepository()\n\taddGetExecutionCallback(t, repository)\n\trepository.NodeExecutionRepo().(*repositoryMocks.MockNodeExecutionRepo).SetGetCallback(\n\t\tfunc(ctx context.Context, input interfaces.NodeExecutionResource) (models.NodeExecution, error) {\n\t\t\treturn models.NodeExecution{}, flyteAdminErrors.NewFlyteAdminError(codes.NotFound, \"foo\")\n\t\t})\n\n\tsucceededRequest := admin.NodeExecutionEventRequest{\n\t\tRequestId: \"request id\",\n\t\tEvent: &event.NodeExecutionEvent{\n\t\t\tProducerId: \"propeller\",\n\t\t\tId: &core.NodeExecutionIdentifier{\n\t\t\t\tNodeId: \"node id\",\n\t\t\t\tExecutionId: &core.WorkflowExecutionIdentifier{\n\t\t\t\t\tProject: \"project\",\n\t\t\t\t\tDomain:  \"domain\",\n\t\t\t\t\tName:    \"name\",\n\t\t\t\t},\n\t\t\t},\n\t\t\tOccurredAt: occurredAtProto,\n\t\t\tPhase:      core.NodeExecution_SUCCEEDED,\n\t\t\tInputValue: &event.NodeExecutionEvent_InputUri{\n\t\t\t\tInputUri: \"input uri\",\n\t\t\t},\n\t\t},\n\t}\n\tmockDbEventWriter := &eventWriterMocks.NodeExecutionEventWriter{}\n\tmockDbEventWriter.On(\"Write\", succeededRequest)\n\tnodeExecManager := NewNodeExecutionManager(repository, getMockExecutionsConfigProvider(), make([]string, 0), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockNodeExecutionRemoteURL, &mockPublisher, &mockPublisher, mockDbEventWriter)\n\tresp, err := nodeExecManager.CreateNodeEvent(context.Background(), succeededRequest)\n\tassert.NotNil(t, resp)\n\tassert.Nil(t, err)\n}\n\nfunc TestTransformNodeExecutionModel(t *testing.T) {\n\tctx := context.TODO()\n\trepository := repositoryMocks.NewMockRepository()\n\tnodeExecID := &core.NodeExecutionIdentifier{\n\t\tNodeId:      \"node id\",\n\t\tExecutionId: &workflowExecutionIdentifier,\n\t}\n\tt.Run(\"event version 0\", func(t *testing.T) {\n\t\trepository.NodeExecutionRepo().(*repositoryMocks.MockNodeExecutionRepo).SetGetWithChildrenCallback(\n\t\t\tfunc(ctx context.Context, input interfaces.NodeExecutionResource) (models.NodeExecution, error) {\n\t\t\t\tassert.True(t, proto.Equal(nodeExecID, &input.NodeExecutionIdentifier))\n\t\t\t\treturn models.NodeExecution{\n\t\t\t\t\tNodeExecutionKey: models.NodeExecutionKey{\n\t\t\t\t\t\tNodeID: \"node id\",\n\t\t\t\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\t\t\t\tProject: \"project\",\n\t\t\t\t\t\t\tDomain:  \"domain\",\n\t\t\t\t\t\t\tName:    \"name\",\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t\tPhase:     core.NodeExecution_SUCCEEDED.String(),\n\t\t\t\t\tInputURI:  \"input uri\",\n\t\t\t\t\tStartedAt: &occurredAt,\n\t\t\t\t\tClosure:   closureBytes,\n\t\t\t\t\tChildNodeExecutions: []models.NodeExecution{\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tPhase: \"unknown\",\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t}, nil\n\t\t\t})\n\n\t\tmanager := NodeExecutionManager{\n\t\t\tdb: repository,\n\t\t}\n\t\tnodeExecution, err := manager.transformNodeExecutionModel(ctx, models.NodeExecution{}, nodeExecID, transformers.DefaultExecutionTransformerOptions)\n\t\tassert.NoError(t, err)\n\t\tassert.True(t, proto.Equal(nodeExecID, nodeExecution.Id))\n\t\tassert.True(t, nodeExecution.Metadata.IsParentNode)\n\t})\n\tt.Run(\"event version > 0\", func(t *testing.T) {\n\t\tmanager := NodeExecutionManager{\n\t\t\tdb: repository,\n\t\t}\n\t\tnodeExecutionMetadata := &admin.NodeExecutionMetaData{\n\t\t\tIsParentNode: true,\n\t\t\tIsDynamic:    true,\n\t\t\tSpecNodeId:   \"spec\",\n\t\t}\n\t\tnodeExecutionMetadataBytes, _ := proto.Marshal(nodeExecutionMetadata)\n\t\tnodeExecution, err := manager.transformNodeExecutionModel(ctx, models.NodeExecution{\n\t\t\tNodeExecutionKey: models.NodeExecutionKey{\n\t\t\t\tNodeID: \"node id\",\n\t\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\t\tProject: \"project\",\n\t\t\t\t\tDomain:  \"domain\",\n\t\t\t\t\tName:    \"name\",\n\t\t\t\t},\n\t\t\t},\n\t\t\tPhase:                 core.NodeExecution_SUCCEEDED.String(),\n\t\t\tInputURI:              \"input uri\",\n\t\t\tStartedAt:             &occurredAt,\n\t\t\tClosure:               closureBytes,\n\t\t\tNodeExecutionMetadata: nodeExecutionMetadataBytes,\n\t\t\tInternalData:          internalDataBytes,\n\t\t}, nodeExecID, transformers.DefaultExecutionTransformerOptions)\n\t\tassert.NoError(t, err)\n\t\tassert.True(t, nodeExecution.Metadata.IsParentNode)\n\t\tassert.True(t, nodeExecution.Metadata.IsDynamic)\n\t})\n\tt.Run(\"transform internal data err\", func(t *testing.T) {\n\t\tmanager := NodeExecutionManager{\n\t\t\tdb: repository,\n\t\t}\n\t\t_, err := manager.transformNodeExecutionModel(ctx, models.NodeExecution{\n\t\t\tInternalData: []byte(\"i'm invalid\"),\n\t\t}, nodeExecID, transformers.DefaultExecutionTransformerOptions)\n\t\tassert.NotNil(t, err)\n\t\tassert.Equal(t, err.(flyteAdminErrors.FlyteAdminError).Code(), codes.Internal)\n\t})\n\tt.Run(\"get with children err\", func(t *testing.T) {\n\t\texpectedErr := flyteAdminErrors.NewFlyteAdminError(codes.Internal, \"foo\")\n\t\trepository.NodeExecutionRepo().(*repositoryMocks.MockNodeExecutionRepo).SetGetWithChildrenCallback(\n\t\t\tfunc(ctx context.Context, input interfaces.NodeExecutionResource) (models.NodeExecution, error) {\n\t\t\t\tassert.True(t, proto.Equal(nodeExecID, &input.NodeExecutionIdentifier))\n\t\t\t\treturn models.NodeExecution{}, expectedErr\n\t\t\t})\n\n\t\tmanager := NodeExecutionManager{\n\t\t\tdb: repository,\n\t\t}\n\t\t_, err := manager.transformNodeExecutionModel(ctx, models.NodeExecution{}, nodeExecID, transformers.DefaultExecutionTransformerOptions)\n\t\tassert.Equal(t, err, expectedErr)\n\t})\n}\n\nfunc TestTransformNodeExecutionModelList(t *testing.T) {\n\tctx := context.TODO()\n\trepository := repositoryMocks.NewMockRepository()\n\trepository.NodeExecutionRepo().(*repositoryMocks.MockNodeExecutionRepo).SetGetWithChildrenCallback(\n\t\tfunc(ctx context.Context, input interfaces.NodeExecutionResource) (models.NodeExecution, error) {\n\t\t\treturn models.NodeExecution{\n\t\t\t\tNodeExecutionKey: models.NodeExecutionKey{\n\t\t\t\t\tNodeID: \"node id\",\n\t\t\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\t\t\tProject: \"project\",\n\t\t\t\t\t\tDomain:  \"domain\",\n\t\t\t\t\t\tName:    \"name\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tPhase:     core.NodeExecution_SUCCEEDED.String(),\n\t\t\t\tInputURI:  \"input uri\",\n\t\t\t\tStartedAt: &occurredAt,\n\t\t\t\tClosure:   closureBytes,\n\t\t\t\tChildNodeExecutions: []models.NodeExecution{\n\t\t\t\t\t{\n\t\t\t\t\t\tPhase: \"unknown\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t}, nil\n\t\t})\n\n\tmanager := NodeExecutionManager{\n\t\tdb: repository,\n\t}\n\tnodeExecutions, err := manager.transformNodeExecutionModelList(ctx, []models.NodeExecution{\n\t\t{\n\t\t\tPhase: \"unknown\",\n\t\t},\n\t})\n\tassert.NoError(t, err)\n\tassert.Len(t, nodeExecutions, 1)\n\n}\n\nfunc TestGetNodeExecution(t *testing.T) {\n\trepository := repositoryMocks.NewMockRepository()\n\texpectedClosure := admin.NodeExecutionClosure{\n\t\tPhase: core.NodeExecution_SUCCEEDED,\n\t\tTargetMetadata: &admin.NodeExecutionClosure_TaskNodeMetadata{\n\t\t\tTaskNodeMetadata: &admin.TaskNodeMetadata{\n\t\t\t\tCheckpointUri: \"last checkpoint uri\",\n\t\t\t},\n\t\t},\n\t}\n\texpectedMetadata := admin.NodeExecutionMetaData{\n\t\tSpecNodeId: \"spec_node_id\",\n\t\tRetryGroup: \"retry_group\",\n\t}\n\tmetadataBytes, _ := proto.Marshal(&expectedMetadata)\n\tclosureBytes, _ := proto.Marshal(&expectedClosure)\n\trepository.NodeExecutionRepo().(*repositoryMocks.MockNodeExecutionRepo).SetGetCallback(\n\t\tfunc(ctx context.Context, input interfaces.NodeExecutionResource) (models.NodeExecution, error) {\n\t\t\tworkflowExecutionIdentifier := core.WorkflowExecutionIdentifier{\n\t\t\t\tProject: \"project\",\n\t\t\t\tDomain:  \"domain\",\n\t\t\t\tName:    \"name\",\n\t\t\t}\n\t\t\tassert.True(t, proto.Equal(&core.NodeExecutionIdentifier{\n\t\t\t\tNodeId:      \"node id\",\n\t\t\t\tExecutionId: &workflowExecutionIdentifier,\n\t\t\t}, &input.NodeExecutionIdentifier))\n\t\t\treturn models.NodeExecution{\n\t\t\t\tNodeExecutionKey: models.NodeExecutionKey{\n\t\t\t\t\tNodeID: \"node id\",\n\t\t\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\t\t\tProject: \"project\",\n\t\t\t\t\t\tDomain:  \"domain\",\n\t\t\t\t\t\tName:    \"name\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tPhase:                 core.NodeExecution_SUCCEEDED.String(),\n\t\t\t\tInputURI:              \"input uri\",\n\t\t\t\tStartedAt:             &occurredAt,\n\t\t\t\tClosure:               closureBytes,\n\t\t\t\tNodeExecutionMetadata: metadataBytes,\n\t\t\t\tInternalData:          internalDataBytes,\n\t\t\t}, nil\n\t\t})\n\tnodeExecManager := NewNodeExecutionManager(repository, getMockExecutionsConfigProvider(), make([]string, 0), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockNodeExecutionRemoteURL, nil, nil, &eventWriterMocks.NodeExecutionEventWriter{})\n\tnodeExecution, err := nodeExecManager.GetNodeExecution(context.Background(), admin.NodeExecutionGetRequest{\n\t\tId: &nodeExecutionIdentifier,\n\t})\n\tassert.Nil(t, err)\n\tassert.True(t, proto.Equal(&admin.NodeExecution{\n\t\tId:       &nodeExecutionIdentifier,\n\t\tInputUri: \"input uri\",\n\t\tClosure:  &expectedClosure,\n\t\tMetadata: &expectedMetadata,\n\t}, nodeExecution))\n}\n\nfunc TestGetNodeExecutionParentNode(t *testing.T) {\n\trepository := repositoryMocks.NewMockRepository()\n\texpectedClosure := admin.NodeExecutionClosure{\n\t\tPhase: core.NodeExecution_SUCCEEDED,\n\t}\n\texpectedMetadata := admin.NodeExecutionMetaData{\n\t\tSpecNodeId: \"spec_node_id\",\n\t\tRetryGroup: \"retry_group\",\n\t}\n\tmetadataBytes, _ := proto.Marshal(&expectedMetadata)\n\tclosureBytes, _ := proto.Marshal(&expectedClosure)\n\trepository.NodeExecutionRepo().(*repositoryMocks.MockNodeExecutionRepo).SetGetWithChildrenCallback(\n\t\tfunc(\n\t\t\tctx context.Context, input interfaces.NodeExecutionResource) (models.NodeExecution, error) {\n\t\t\tworkflowExecutionIdentifier := core.WorkflowExecutionIdentifier{\n\t\t\t\tProject: \"project\",\n\t\t\t\tDomain:  \"domain\",\n\t\t\t\tName:    \"name\",\n\t\t\t}\n\t\t\tassert.True(t, proto.Equal(&core.NodeExecutionIdentifier{\n\t\t\t\tNodeId:      \"node id\",\n\t\t\t\tExecutionId: &workflowExecutionIdentifier,\n\t\t\t}, &input.NodeExecutionIdentifier))\n\t\t\treturn models.NodeExecution{\n\t\t\t\tNodeExecutionKey: models.NodeExecutionKey{\n\t\t\t\t\tNodeID: \"node id\",\n\t\t\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\t\t\tProject: \"project\",\n\t\t\t\t\t\tDomain:  \"domain\",\n\t\t\t\t\t\tName:    \"name\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tPhase:                 core.NodeExecution_SUCCEEDED.String(),\n\t\t\t\tInputURI:              \"input uri\",\n\t\t\t\tStartedAt:             &occurredAt,\n\t\t\t\tClosure:               closureBytes,\n\t\t\t\tNodeExecutionMetadata: metadataBytes,\n\t\t\t\tChildNodeExecutions: []models.NodeExecution{\n\t\t\t\t\t{\n\t\t\t\t\t\tNodeExecutionKey: models.NodeExecutionKey{\n\t\t\t\t\t\t\tNodeID: \"node-child\",\n\t\t\t\t\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\t\t\t\t\tProject: \"project\",\n\t\t\t\t\t\t\t\tDomain:  \"domain\",\n\t\t\t\t\t\t\t\tName:    \"name\",\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t}, nil\n\t\t})\n\tnodeExecManager := NewNodeExecutionManager(repository, getMockExecutionsConfigProvider(), make([]string, 0), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockNodeExecutionRemoteURL, nil, nil, &eventWriterMocks.NodeExecutionEventWriter{})\n\tnodeExecution, err := nodeExecManager.GetNodeExecution(context.Background(), admin.NodeExecutionGetRequest{\n\t\tId: &nodeExecutionIdentifier,\n\t})\n\tassert.Nil(t, err)\n\texpectedMetadata.IsParentNode = true\n\tassert.True(t, proto.Equal(&admin.NodeExecution{\n\t\tId:       &nodeExecutionIdentifier,\n\t\tInputUri: \"input uri\",\n\t\tClosure:  &expectedClosure,\n\t\tMetadata: &expectedMetadata,\n\t}, nodeExecution))\n}\n\nfunc TestGetNodeExecutionEventVersion0(t *testing.T) {\n\trepository := repositoryMocks.NewMockRepository()\n\texpectedClosure := admin.NodeExecutionClosure{\n\t\tPhase: core.NodeExecution_SUCCEEDED,\n\t}\n\texpectedMetadata := admin.NodeExecutionMetaData{\n\t\tSpecNodeId: \"spec_node_id\",\n\t\tRetryGroup: \"retry_group\",\n\t}\n\tmetadataBytes, _ := proto.Marshal(&expectedMetadata)\n\tclosureBytes, _ := proto.Marshal(&expectedClosure)\n\trepository.NodeExecutionRepo().(*repositoryMocks.MockNodeExecutionRepo).SetGetWithChildrenCallback(\n\t\tfunc(\n\t\t\tctx context.Context, input interfaces.NodeExecutionResource) (models.NodeExecution, error) {\n\t\t\tworkflowExecutionIdentifier := core.WorkflowExecutionIdentifier{\n\t\t\t\tProject: \"project\",\n\t\t\t\tDomain:  \"domain\",\n\t\t\t\tName:    \"name\",\n\t\t\t}\n\t\t\tassert.True(t, proto.Equal(&core.NodeExecutionIdentifier{\n\t\t\t\tNodeId:      \"node id\",\n\t\t\t\tExecutionId: &workflowExecutionIdentifier,\n\t\t\t}, &input.NodeExecutionIdentifier))\n\t\t\treturn models.NodeExecution{\n\t\t\t\tNodeExecutionKey: models.NodeExecutionKey{\n\t\t\t\t\tNodeID: \"node id\",\n\t\t\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\t\t\tProject: \"project\",\n\t\t\t\t\t\tDomain:  \"domain\",\n\t\t\t\t\t\tName:    \"name\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tPhase:                 core.NodeExecution_SUCCEEDED.String(),\n\t\t\t\tInputURI:              \"input uri\",\n\t\t\t\tStartedAt:             &occurredAt,\n\t\t\t\tClosure:               closureBytes,\n\t\t\t\tNodeExecutionMetadata: metadataBytes,\n\t\t\t}, nil\n\t\t})\n\n\tnodeExecManager := NewNodeExecutionManager(repository, getMockExecutionsConfigProvider(), make([]string, 0), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockNodeExecutionRemoteURL, nil, nil, &eventWriterMocks.NodeExecutionEventWriter{})\n\tnodeExecution, err := nodeExecManager.GetNodeExecution(context.Background(), admin.NodeExecutionGetRequest{\n\t\tId: &nodeExecutionIdentifier,\n\t})\n\tassert.Nil(t, err)\n\tassert.True(t, proto.Equal(&admin.NodeExecution{\n\t\tId:       &nodeExecutionIdentifier,\n\t\tInputUri: \"input uri\",\n\t\tClosure:  &expectedClosure,\n\t\tMetadata: &expectedMetadata,\n\t}, nodeExecution))\n}\n\nfunc TestGetNodeExecution_DatabaseError(t *testing.T) {\n\trepository := repositoryMocks.NewMockRepository()\n\texpectedErr := errors.New(\"expected error\")\n\trepository.NodeExecutionRepo().(*repositoryMocks.MockNodeExecutionRepo).SetGetCallback(\n\t\tfunc(ctx context.Context, input interfaces.NodeExecutionResource) (models.NodeExecution, error) {\n\t\t\treturn models.NodeExecution{}, expectedErr\n\t\t})\n\tnodeExecManager := NewNodeExecutionManager(repository, getMockExecutionsConfigProvider(), make([]string, 0), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockNodeExecutionRemoteURL, nil, nil, &eventWriterMocks.NodeExecutionEventWriter{})\n\tnodeExecution, err := nodeExecManager.GetNodeExecution(context.Background(), admin.NodeExecutionGetRequest{\n\t\tId: &nodeExecutionIdentifier,\n\t})\n\tassert.Nil(t, nodeExecution)\n\tassert.EqualError(t, err, expectedErr.Error())\n}\n\nfunc TestGetNodeExecution_TransformerError(t *testing.T) {\n\trepository := repositoryMocks.NewMockRepository()\n\trepository.NodeExecutionRepo().(*repositoryMocks.MockNodeExecutionRepo).SetGetCallback(\n\t\tfunc(ctx context.Context, input interfaces.NodeExecutionResource) (models.NodeExecution, error) {\n\t\t\treturn models.NodeExecution{\n\t\t\t\tNodeExecutionKey: models.NodeExecutionKey{\n\t\t\t\t\tNodeID: \"node id\",\n\t\t\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\t\t\tProject: \"project\",\n\t\t\t\t\t\tDomain:  \"domain\",\n\t\t\t\t\t\tName:    \"name\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tPhase:        core.NodeExecution_SUCCEEDED.String(),\n\t\t\t\tInputURI:     \"input uri\",\n\t\t\t\tStartedAt:    &occurredAt,\n\t\t\t\tClosure:      []byte(\"i'm invalid\"),\n\t\t\t\tInternalData: internalDataBytes,\n\t\t\t}, nil\n\t\t})\n\tnodeExecManager := NewNodeExecutionManager(repository, getMockExecutionsConfigProvider(), make([]string, 0), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockNodeExecutionRemoteURL, nil, nil, &eventWriterMocks.NodeExecutionEventWriter{})\n\tnodeExecution, err := nodeExecManager.GetNodeExecution(context.Background(), admin.NodeExecutionGetRequest{\n\t\tId: &nodeExecutionIdentifier,\n\t})\n\tassert.Nil(t, nodeExecution)\n\tassert.Equal(t, err.(flyteAdminErrors.FlyteAdminError).Code(), codes.Internal)\n}\n\nfunc TestListNodeExecutionsLevelZero(t *testing.T) {\n\trepository := repositoryMocks.NewMockRepository()\n\texpectedClosure := admin.NodeExecutionClosure{\n\t\tPhase: core.NodeExecution_SUCCEEDED,\n\t}\n\texpectedMetadata := admin.NodeExecutionMetaData{\n\t\tSpecNodeId: \"spec_node_id\",\n\t\tRetryGroup: \"retry_group\",\n\t}\n\tmetadataBytes, _ := proto.Marshal(&expectedMetadata)\n\tclosureBytes, _ := proto.Marshal(&expectedClosure)\n\n\trepository.NodeExecutionRepo().(*repositoryMocks.MockNodeExecutionRepo).SetListCallback(\n\t\tfunc(ctx context.Context, input interfaces.ListResourceInput) (\n\t\t\tinterfaces.NodeExecutionCollectionOutput, error) {\n\t\t\tassert.Equal(t, 1, input.Limit)\n\t\t\tassert.Equal(t, 2, input.Offset)\n\t\t\tassert.Len(t, input.InlineFilters, 3)\n\t\t\tassert.Equal(t, common.Execution, input.InlineFilters[0].GetEntity())\n\t\t\tqueryExpr, _ := input.InlineFilters[0].GetGormQueryExpr()\n\t\t\tassert.Equal(t, \"project\", queryExpr.Args)\n\t\t\tassert.Equal(t, \"execution_project = ?\", queryExpr.Query)\n\n\t\t\tassert.Equal(t, common.Execution, input.InlineFilters[1].GetEntity())\n\t\t\tqueryExpr, _ = input.InlineFilters[1].GetGormQueryExpr()\n\t\t\tassert.Equal(t, \"domain\", queryExpr.Args)\n\t\t\tassert.Equal(t, \"execution_domain = ?\", queryExpr.Query)\n\n\t\t\tassert.Equal(t, common.Execution, input.InlineFilters[2].GetEntity())\n\t\t\tqueryExpr, _ = input.InlineFilters[2].GetGormQueryExpr()\n\t\t\tassert.Equal(t, \"name\", queryExpr.Args)\n\t\t\tassert.Equal(t, \"execution_name = ?\", queryExpr.Query)\n\n\t\t\tassert.Len(t, input.MapFilters, 1)\n\t\t\tfilter := input.MapFilters[0].GetFilter()\n\t\t\tassert.Equal(t, map[string]interface{}{\n\t\t\t\t\"parent_id\":                nil,\n\t\t\t\t\"parent_task_execution_id\": nil,\n\t\t\t}, filter)\n\n\t\t\tassert.Equal(t, \"execution_domain asc\", input.SortParameter.GetGormOrderExpr())\n\t\t\treturn interfaces.NodeExecutionCollectionOutput{\n\t\t\t\tNodeExecutions: []models.NodeExecution{\n\t\t\t\t\t{\n\t\t\t\t\t\tNodeExecutionKey: models.NodeExecutionKey{\n\t\t\t\t\t\t\tNodeID: \"node id\",\n\t\t\t\t\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\t\t\t\t\tProject: \"project\",\n\t\t\t\t\t\t\t\tDomain:  \"domain\",\n\t\t\t\t\t\t\t\tName:    \"name\",\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t\tPhase:                 core.NodeExecution_SUCCEEDED.String(),\n\t\t\t\t\t\tInputURI:              \"input uri\",\n\t\t\t\t\t\tStartedAt:             &occurredAt,\n\t\t\t\t\t\tClosure:               closureBytes,\n\t\t\t\t\t\tNodeExecutionMetadata: metadataBytes,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t}, nil\n\t\t})\n\trepository.NodeExecutionRepo().(*repositoryMocks.MockNodeExecutionRepo).SetGetWithChildrenCallback(\n\t\tfunc(\n\t\t\tctx context.Context, input interfaces.NodeExecutionResource) (models.NodeExecution, error) {\n\t\t\treturn models.NodeExecution{\n\t\t\t\tNodeExecutionKey: models.NodeExecutionKey{\n\t\t\t\t\tNodeID: \"node id\",\n\t\t\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\t\t\tProject: \"project\",\n\t\t\t\t\t\tDomain:  \"domain\",\n\t\t\t\t\t\tName:    \"name\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tPhase:                 core.NodeExecution_SUCCEEDED.String(),\n\t\t\t\tInputURI:              \"input uri\",\n\t\t\t\tStartedAt:             &occurredAt,\n\t\t\t\tClosure:               closureBytes,\n\t\t\t\tNodeExecutionMetadata: metadataBytes,\n\t\t\t}, nil\n\t\t})\n\tnodeExecManager := NewNodeExecutionManager(repository, getMockExecutionsConfigProvider(), make([]string, 0), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockNodeExecutionRemoteURL, nil, nil, &eventWriterMocks.NodeExecutionEventWriter{})\n\tnodeExecutions, err := nodeExecManager.ListNodeExecutions(context.Background(), admin.NodeExecutionListRequest{\n\t\tWorkflowExecutionId: &core.WorkflowExecutionIdentifier{\n\t\t\tProject: \"project\",\n\t\t\tDomain:  \"domain\",\n\t\t\tName:    \"name\",\n\t\t},\n\t\tLimit: 1,\n\t\tToken: \"2\",\n\t\tSortBy: &admin.Sort{\n\t\t\tDirection: admin.Sort_ASCENDING,\n\t\t\tKey:       \"execution_domain\",\n\t\t},\n\t})\n\tassert.NoError(t, err)\n\tassert.Len(t, nodeExecutions.NodeExecutions, 1)\n\tassert.True(t, proto.Equal(&admin.NodeExecution{\n\t\tId: &core.NodeExecutionIdentifier{\n\t\t\tNodeId: \"node id\",\n\t\t\tExecutionId: &core.WorkflowExecutionIdentifier{\n\t\t\t\tProject: \"project\",\n\t\t\t\tDomain:  \"domain\",\n\t\t\t\tName:    \"name\",\n\t\t\t},\n\t\t},\n\t\tInputUri: \"input uri\",\n\t\tClosure:  &expectedClosure,\n\t\tMetadata: &expectedMetadata,\n\t}, nodeExecutions.NodeExecutions[0]))\n\tassert.Equal(t, \"3\", nodeExecutions.Token)\n}\n\nfunc TestListNodeExecutionsWithParent(t *testing.T) {\n\trepository := repositoryMocks.NewMockRepository()\n\texpectedClosure := admin.NodeExecutionClosure{\n\t\tPhase: core.NodeExecution_SUCCEEDED,\n\t}\n\texpectedMetadata := admin.NodeExecutionMetaData{\n\t\tSpecNodeId: \"spec_node_id\",\n\t\tRetryGroup: \"retry_group\",\n\t}\n\tmetadataBytes, _ := proto.Marshal(&expectedMetadata)\n\tclosureBytes, _ := proto.Marshal(&expectedClosure)\n\tparentID := uint(12)\n\trepository.NodeExecutionRepo().(*repositoryMocks.MockNodeExecutionRepo).SetGetCallback(func(ctx context.Context, input interfaces.NodeExecutionResource) (execution models.NodeExecution, e error) {\n\t\tassert.Equal(t, \"parent_1\", input.NodeExecutionIdentifier.NodeId)\n\t\treturn models.NodeExecution{\n\t\t\tBaseModel: models.BaseModel{\n\t\t\t\tID: parentID,\n\t\t\t},\n\t\t}, nil\n\t})\n\trepository.NodeExecutionRepo().(*repositoryMocks.MockNodeExecutionRepo).SetListCallback(\n\t\tfunc(ctx context.Context, input interfaces.ListResourceInput) (\n\t\t\tinterfaces.NodeExecutionCollectionOutput, error) {\n\t\t\tassert.Equal(t, 1, input.Limit)\n\t\t\tassert.Equal(t, 2, input.Offset)\n\t\t\tassert.Len(t, input.InlineFilters, 4)\n\t\t\tassert.Equal(t, common.Execution, input.InlineFilters[0].GetEntity())\n\t\t\tqueryExpr, _ := input.InlineFilters[0].GetGormQueryExpr()\n\t\t\tassert.Equal(t, \"project\", queryExpr.Args)\n\t\t\tassert.Equal(t, \"execution_project = ?\", queryExpr.Query)\n\n\t\t\tassert.Equal(t, common.Execution, input.InlineFilters[1].GetEntity())\n\t\t\tqueryExpr, _ = input.InlineFilters[1].GetGormQueryExpr()\n\t\t\tassert.Equal(t, \"domain\", queryExpr.Args)\n\t\t\tassert.Equal(t, \"execution_domain = ?\", queryExpr.Query)\n\n\t\t\tassert.Equal(t, common.Execution, input.InlineFilters[2].GetEntity())\n\t\t\tqueryExpr, _ = input.InlineFilters[2].GetGormQueryExpr()\n\t\t\tassert.Equal(t, \"name\", queryExpr.Args)\n\t\t\tassert.Equal(t, \"execution_name = ?\", queryExpr.Query)\n\n\t\t\tassert.Equal(t, common.NodeExecution, input.InlineFilters[3].GetEntity())\n\t\t\tqueryExpr, _ = input.InlineFilters[3].GetGormQueryExpr()\n\t\t\tassert.Equal(t, parentID, queryExpr.Args)\n\t\t\tassert.Equal(t, \"parent_id = ?\", queryExpr.Query)\n\n\t\t\tassert.Equal(t, \"execution_domain asc\", input.SortParameter.GetGormOrderExpr())\n\t\t\treturn interfaces.NodeExecutionCollectionOutput{\n\t\t\t\tNodeExecutions: []models.NodeExecution{\n\t\t\t\t\t{\n\t\t\t\t\t\tNodeExecutionKey: models.NodeExecutionKey{\n\t\t\t\t\t\t\tNodeID: \"node id\",\n\t\t\t\t\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\t\t\t\t\tProject: \"project\",\n\t\t\t\t\t\t\t\tDomain:  \"domain\",\n\t\t\t\t\t\t\t\tName:    \"name\",\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t\tPhase:                 core.NodeExecution_SUCCEEDED.String(),\n\t\t\t\t\t\tInputURI:              \"input uri\",\n\t\t\t\t\t\tStartedAt:             &occurredAt,\n\t\t\t\t\t\tClosure:               closureBytes,\n\t\t\t\t\t\tNodeExecutionMetadata: metadataBytes,\n\t\t\t\t\t\tInternalData:          internalDataBytes,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t}, nil\n\t\t})\n\tnodeExecManager := NewNodeExecutionManager(repository, getMockExecutionsConfigProvider(), make([]string, 0), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockNodeExecutionRemoteURL, nil, nil, &eventWriterMocks.NodeExecutionEventWriter{})\n\tnodeExecutions, err := nodeExecManager.ListNodeExecutions(context.Background(), admin.NodeExecutionListRequest{\n\t\tWorkflowExecutionId: &core.WorkflowExecutionIdentifier{\n\t\t\tProject: \"project\",\n\t\t\tDomain:  \"domain\",\n\t\t\tName:    \"name\",\n\t\t},\n\t\tLimit: 1,\n\t\tToken: \"2\",\n\t\tSortBy: &admin.Sort{\n\t\t\tDirection: admin.Sort_ASCENDING,\n\t\t\tKey:       \"execution_domain\",\n\t\t},\n\t\tUniqueParentId: \"parent_1\",\n\t})\n\tassert.Nil(t, err)\n\tassert.Len(t, nodeExecutions.NodeExecutions, 1)\n\tassert.True(t, proto.Equal(&admin.NodeExecution{\n\t\tId: &core.NodeExecutionIdentifier{\n\t\t\tNodeId: \"node id\",\n\t\t\tExecutionId: &core.WorkflowExecutionIdentifier{\n\t\t\t\tProject: \"project\",\n\t\t\t\tDomain:  \"domain\",\n\t\t\t\tName:    \"name\",\n\t\t\t},\n\t\t},\n\t\tInputUri: \"input uri\",\n\t\tClosure:  &expectedClosure,\n\t\tMetadata: &expectedMetadata,\n\t}, nodeExecutions.NodeExecutions[0]))\n\tassert.Equal(t, \"3\", nodeExecutions.Token)\n}\n\nfunc TestListNodeExecutions_InvalidParams(t *testing.T) {\n\tnodeExecManager := NewNodeExecutionManager(nil, getMockExecutionsConfigProvider(), make([]string, 0), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockNodeExecutionRemoteURL, nil, nil, &eventWriterMocks.NodeExecutionEventWriter{})\n\t_, err := nodeExecManager.ListNodeExecutions(context.Background(), admin.NodeExecutionListRequest{\n\t\tFilters: \"eq(execution.project, project)\",\n\t})\n\tassert.Equal(t, codes.InvalidArgument, err.(flyteAdminErrors.FlyteAdminError).Code())\n\n\t_, err = nodeExecManager.ListNodeExecutions(context.Background(), admin.NodeExecutionListRequest{\n\t\tLimit: 1,\n\t})\n\tassert.Equal(t, codes.InvalidArgument, err.(flyteAdminErrors.FlyteAdminError).Code())\n\n\t_, err = nodeExecManager.ListNodeExecutions(context.Background(), admin.NodeExecutionListRequest{\n\t\tLimit:   1,\n\t\tFilters: \"foo\",\n\t})\n\tassert.Equal(t, codes.InvalidArgument, err.(flyteAdminErrors.FlyteAdminError).Code())\n}\n\nfunc TestListNodeExecutions_DatabaseError(t *testing.T) {\n\trepository := repositoryMocks.NewMockRepository()\n\texpectedErr := errors.New(\"expected error\")\n\trepository.NodeExecutionRepo().(*repositoryMocks.MockNodeExecutionRepo).SetListCallback(\n\t\tfunc(ctx context.Context, input interfaces.ListResourceInput) (\n\t\t\tinterfaces.NodeExecutionCollectionOutput, error) {\n\t\t\treturn interfaces.NodeExecutionCollectionOutput{}, expectedErr\n\t\t})\n\tnodeExecManager := NewNodeExecutionManager(repository, getMockExecutionsConfigProvider(), make([]string, 0), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockNodeExecutionRemoteURL, nil, nil, &eventWriterMocks.NodeExecutionEventWriter{})\n\tnodeExecutions, err := nodeExecManager.ListNodeExecutions(context.Background(), admin.NodeExecutionListRequest{\n\t\tWorkflowExecutionId: &core.WorkflowExecutionIdentifier{\n\t\t\tProject: \"project\",\n\t\t\tDomain:  \"domain\",\n\t\t\tName:    \"name\",\n\t\t},\n\t\tLimit: 1,\n\t\tToken: \"2\",\n\t})\n\tassert.Nil(t, nodeExecutions)\n\tassert.EqualError(t, err, expectedErr.Error())\n}\n\nfunc TestListNodeExecutions_TransformerError(t *testing.T) {\n\trepository := repositoryMocks.NewMockRepository()\n\trepository.NodeExecutionRepo().(*repositoryMocks.MockNodeExecutionRepo).SetListCallback(\n\t\tfunc(ctx context.Context, input interfaces.ListResourceInput) (\n\t\t\tinterfaces.NodeExecutionCollectionOutput, error) {\n\t\t\treturn interfaces.NodeExecutionCollectionOutput{\n\t\t\t\tNodeExecutions: []models.NodeExecution{\n\t\t\t\t\t{\n\t\t\t\t\t\tNodeExecutionKey: models.NodeExecutionKey{\n\t\t\t\t\t\t\tNodeID: \"node id\",\n\t\t\t\t\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\t\t\t\t\tProject: \"project\",\n\t\t\t\t\t\t\t\tDomain:  \"domain\",\n\t\t\t\t\t\t\t\tName:    \"name\",\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t\tPhase:        core.NodeExecution_SUCCEEDED.String(),\n\t\t\t\t\t\tInputURI:     \"input uri\",\n\t\t\t\t\t\tStartedAt:    &occurredAt,\n\t\t\t\t\t\tClosure:      []byte(\"i'm invalid\"),\n\t\t\t\t\t\tInternalData: internalDataBytes,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t}, nil\n\t\t})\n\tnodeExecManager := NewNodeExecutionManager(repository, getMockExecutionsConfigProvider(), make([]string, 0), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockNodeExecutionRemoteURL, nil, nil, &eventWriterMocks.NodeExecutionEventWriter{})\n\tnodeExecutions, err := nodeExecManager.ListNodeExecutions(context.Background(), admin.NodeExecutionListRequest{\n\t\tWorkflowExecutionId: &core.WorkflowExecutionIdentifier{\n\t\t\tProject: \"project\",\n\t\t\tDomain:  \"domain\",\n\t\t\tName:    \"name\",\n\t\t},\n\t\tLimit: 1,\n\t\tToken: \"2\",\n\t})\n\tassert.Nil(t, nodeExecutions)\n\tassert.Equal(t, err.(flyteAdminErrors.FlyteAdminError).Code(), codes.Internal)\n}\n\nfunc TestListNodeExecutions_NothingToReturn(t *testing.T) {\n\trepository := repositoryMocks.NewMockRepository()\n\trepository.NodeExecutionRepo().(*repositoryMocks.MockNodeExecutionRepo).SetListCallback(\n\t\tfunc(ctx context.Context, input interfaces.ListResourceInput) (\n\t\t\tinterfaces.NodeExecutionCollectionOutput, error) {\n\t\t\treturn interfaces.NodeExecutionCollectionOutput{}, nil\n\t\t})\n\tvar listExecutionsCalled bool\n\trepository.ExecutionRepo().(*repositoryMocks.MockExecutionRepo).SetListCallback(\n\t\tfunc(ctx context.Context, input interfaces.ListResourceInput) (\n\t\t\tinterfaces.ExecutionCollectionOutput, error) {\n\t\t\tlistExecutionsCalled = true\n\t\t\treturn interfaces.ExecutionCollectionOutput{}, nil\n\t\t})\n\tnodeExecManager := NewNodeExecutionManager(repository, getMockExecutionsConfigProvider(), make([]string, 0), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockNodeExecutionRemoteURL, nil, nil, &eventWriterMocks.NodeExecutionEventWriter{})\n\n\t_, err := nodeExecManager.ListNodeExecutions(context.Background(), admin.NodeExecutionListRequest{\n\t\tWorkflowExecutionId: &core.WorkflowExecutionIdentifier{\n\t\t\tProject: \"project\",\n\t\t\tDomain:  \"domain\",\n\t\t\tName:    \"name\",\n\t\t},\n\t\tLimit: 1,\n\t\tToken: \"2\",\n\t\tSortBy: &admin.Sort{\n\t\t\tDirection: admin.Sort_ASCENDING,\n\t\t\tKey:       \"execution_domain\",\n\t\t},\n\t})\n\n\tassert.NoError(t, err)\n\tassert.False(t, listExecutionsCalled)\n}\n\nfunc TestListNodeExecutionsForTask(t *testing.T) {\n\trepository := repositoryMocks.NewMockRepository()\n\texpectedClosure := admin.NodeExecutionClosure{\n\t\tPhase: core.NodeExecution_SUCCEEDED,\n\t}\n\texecMetadata := admin.NodeExecutionMetaData{\n\t\tSpecNodeId:   \"spec-n1\",\n\t\tIsParentNode: true,\n\t}\n\n\tclosureBytes, _ := proto.Marshal(&expectedClosure)\n\texecMetadataBytes, _ := proto.Marshal(&execMetadata)\n\n\trepository.TaskExecutionRepo().(*repositoryMocks.MockTaskExecutionRepo).SetGetCallback(\n\t\tfunc(ctx context.Context, input interfaces.GetTaskExecutionInput) (models.TaskExecution, error) {\n\t\t\treturn models.TaskExecution{\n\t\t\t\tBaseModel: models.BaseModel{\n\t\t\t\t\tID: uint(8),\n\t\t\t\t},\n\t\t\t}, nil\n\t\t})\n\trepository.NodeExecutionRepo().(*repositoryMocks.MockNodeExecutionRepo).SetListCallback(\n\t\tfunc(ctx context.Context, input interfaces.ListResourceInput) (\n\t\t\tinterfaces.NodeExecutionCollectionOutput, error) {\n\t\t\tassert.Equal(t, 1, input.Limit)\n\t\t\tassert.Equal(t, 2, input.Offset)\n\t\t\tassert.Len(t, input.InlineFilters, 4)\n\t\t\tassert.Equal(t, common.Execution, input.InlineFilters[0].GetEntity())\n\t\t\tqueryExpr, _ := input.InlineFilters[0].GetGormQueryExpr()\n\t\t\tassert.Equal(t, \"project\", queryExpr.Args)\n\t\t\tassert.Equal(t, \"execution_project = ?\", queryExpr.Query)\n\n\t\t\tassert.Equal(t, common.Execution, input.InlineFilters[1].GetEntity())\n\t\t\tqueryExpr, _ = input.InlineFilters[1].GetGormQueryExpr()\n\t\t\tassert.Equal(t, \"domain\", queryExpr.Args)\n\t\t\tassert.Equal(t, \"execution_domain = ?\", queryExpr.Query)\n\n\t\t\tassert.Equal(t, common.Execution, input.InlineFilters[2].GetEntity())\n\t\t\tqueryExpr, _ = input.InlineFilters[2].GetGormQueryExpr()\n\t\t\tassert.Equal(t, \"name\", queryExpr.Args)\n\t\t\tassert.Equal(t, \"execution_name = ?\", queryExpr.Query)\n\n\t\t\tassert.Equal(t, common.NodeExecution, input.InlineFilters[3].GetEntity())\n\t\t\tqueryExpr, _ = input.InlineFilters[3].GetGormQueryExpr()\n\t\t\tassert.Equal(t, uint(8), queryExpr.Args)\n\t\t\tassert.Equal(t, \"parent_task_execution_id = ?\", queryExpr.Query)\n\n\t\t\tassert.Equal(t, \"execution_domain asc\", input.SortParameter.GetGormOrderExpr())\n\t\t\treturn interfaces.NodeExecutionCollectionOutput{\n\t\t\t\tNodeExecutions: []models.NodeExecution{\n\t\t\t\t\t{\n\t\t\t\t\t\tNodeExecutionKey: models.NodeExecutionKey{\n\t\t\t\t\t\t\tNodeID: \"node id\",\n\t\t\t\t\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\t\t\t\t\tProject: \"project\",\n\t\t\t\t\t\t\t\tDomain:  \"domain\",\n\t\t\t\t\t\t\t\tName:    \"name\",\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t},\n\t\t\t\t\t\tPhase:                 core.NodeExecution_SUCCEEDED.String(),\n\t\t\t\t\t\tInputURI:              \"input uri\",\n\t\t\t\t\t\tStartedAt:             &occurredAt,\n\t\t\t\t\t\tClosure:               closureBytes,\n\t\t\t\t\t\tNodeExecutionMetadata: execMetadataBytes,\n\t\t\t\t\t\tInternalData:          internalDataBytes,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t}, nil\n\t\t})\n\tnodeExecManager := NewNodeExecutionManager(repository, getMockExecutionsConfigProvider(), make([]string, 0), getMockStorageForExecTest(context.Background()), mockScope.NewTestScope(), mockNodeExecutionRemoteURL, nil, nil, &eventWriterMocks.NodeExecutionEventWriter{})\n\tnodeExecutions, err := nodeExecManager.ListNodeExecutionsForTask(context.Background(), admin.NodeExecutionForTaskListRequest{\n\t\tTaskExecutionId: &core.TaskExecutionIdentifier{\n\t\t\tNodeExecutionId: &core.NodeExecutionIdentifier{\n\t\t\t\tExecutionId: &core.WorkflowExecutionIdentifier{\n\t\t\t\t\tProject: \"project\",\n\t\t\t\t\tDomain:  \"domain\",\n\t\t\t\t\tName:    \"name\",\n\t\t\t\t},\n\t\t\t\tNodeId: \"node_id\",\n\t\t\t},\n\t\t\tTaskId: &core.Identifier{\n\t\t\t\tResourceType: core.ResourceType_TASK,\n\t\t\t\tProject:      \"project\",\n\t\t\t\tDomain:       \"domain\",\n\t\t\t\tName:         \"name\",\n\t\t\t\tVersion:      \"version\",\n\t\t\t},\n\t\t},\n\t\tLimit: 1,\n\t\tToken: \"2\",\n\t\tSortBy: &admin.Sort{\n\t\t\tDirection: admin.Sort_ASCENDING,\n\t\t\tKey:       \"execution_domain\",\n\t\t},\n\t})\n\tassert.Nil(t, err)\n\tassert.Len(t, nodeExecutions.NodeExecutions, 1)\n\texpectedMetadata := admin.NodeExecutionMetaData{\n\t\tSpecNodeId:   \"spec-n1\",\n\t\tIsParentNode: true,\n\t}\n\tassert.True(t, proto.Equal(&admin.NodeExecution{\n\t\tId: &core.NodeExecutionIdentifier{\n\t\t\tNodeId: \"node id\",\n\t\t\tExecutionId: &core.WorkflowExecutionIdentifier{\n\t\t\t\tProject: \"project\",\n\t\t\t\tDomain:  \"domain\",\n\t\t\t\tName:    \"name\",\n\t\t\t},\n\t\t},\n\t\tInputUri: \"input uri\",\n\t\tClosure:  &expectedClosure,\n\t\tMetadata: &expectedMetadata,\n\t}, nodeExecutions.NodeExecutions[0]))\n\tassert.Equal(t, \"3\", nodeExecutions.Token)\n}\n\nfunc TestGetNodeExecutionData(t *testing.T) {\n\trepository := repositoryMocks.NewMockRepository()\n\texpectedClosure := admin.NodeExecutionClosure{\n\t\tPhase: core.NodeExecution_SUCCEEDED,\n\t\tOutputResult: &admin.NodeExecutionClosure_OutputUri{\n\t\t\tOutputUri: util.OutputsFile,\n\t\t},\n\t\tDeckUri: util.DeckFile,\n\t}\n\tdynamicWorkflowClosureRef := \"s3://my-s3-bucket/foo/bar/dynamic.pb\"\n\n\tclosureBytes, _ := proto.Marshal(&expectedClosure)\n\trepository.NodeExecutionRepo().(*repositoryMocks.MockNodeExecutionRepo).SetGetCallback(\n\t\tfunc(ctx context.Context, input interfaces.NodeExecutionResource) (models.NodeExecution, error) {\n\t\t\tworkflowExecutionIdentifier := core.WorkflowExecutionIdentifier{\n\t\t\t\tProject: \"project\",\n\t\t\t\tDomain:  \"domain\",\n\t\t\t\tName:    \"name\",\n\t\t\t}\n\t\t\tassert.True(t, proto.Equal(&core.NodeExecutionIdentifier{\n\t\t\t\tNodeId:      \"node id\",\n\t\t\t\tExecutionId: &workflowExecutionIdentifier,\n\t\t\t}, &input.NodeExecutionIdentifier))\n\t\t\treturn models.NodeExecution{\n\t\t\t\tNodeExecutionKey: models.NodeExecutionKey{\n\t\t\t\t\tNodeID: \"node id\",\n\t\t\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\t\t\tProject: \"project\",\n\t\t\t\t\t\tDomain:  \"domain\",\n\t\t\t\t\t\tName:    \"name\",\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\tPhase:                                 core.NodeExecution_SUCCEEDED.String(),\n\t\t\t\tInputURI:                              \"input uri\",\n\t\t\t\tStartedAt:                             &occurredAt,\n\t\t\t\tClosure:                               closureBytes,\n\t\t\t\tDynamicWorkflowRemoteClosureReference: dynamicWorkflowClosureRef,\n\t\t\t}, nil\n\t\t})\n\n\tmockNodeExecutionRemoteURL := dataMocks.NewMockRemoteURL()\n\tmockNodeExecutionRemoteURL.(*dataMocks.MockRemoteURL).GetCallback = func(ctx context.Context, uri string) (admin.UrlBlob, error) {\n\t\tif uri == \"input uri\" {\n\t\t\treturn admin.UrlBlob{\n\t\t\t\tUrl:   \"inputs\",\n\t\t\t\tBytes: 100,\n\t\t\t}, nil\n\t\t} else if uri == util.OutputsFile {\n\t\t\treturn admin.UrlBlob{\n\t\t\t\tUrl:   \"outputs\",\n\t\t\t\tBytes: 200,\n\t\t\t}, nil\n\t\t}\n\n\t\treturn admin.UrlBlob{}, errors.New(\"unexpected input\")\n\t}\n\tmockStorage := commonMocks.GetMockStorageClient()\n\tfullInputs := &core.LiteralMap{\n\t\tLiterals: map[string]*core.Literal{\n\t\t\t\"foo\": testutils.MakeStringLiteral(\"foo-value-1\"),\n\t\t},\n\t}\n\tfullOutputs := &core.LiteralMap{\n\t\tLiterals: map[string]*core.Literal{\n\t\t\t\"bar\": testutils.MakeStringLiteral(\"bar-value-1\"),\n\t\t},\n\t}\n\n\tmockStorage.ComposedProtobufStore.(*commonMocks.TestDataStore).ReadProtobufCb = func(\n\t\tctx context.Context, reference storage.DataReference, msg proto.Message) error {\n\t\tif reference.String() == \"input uri\" {\n\t\t\tmarshalled, _ := proto.Marshal(fullInputs)\n\t\t\t_ = proto.Unmarshal(marshalled, msg)\n\t\t\treturn nil\n\t\t} else if reference.String() == util.OutputsFile {\n\t\t\tmarshalled, _ := proto.Marshal(fullOutputs)\n\t\t\t_ = proto.Unmarshal(marshalled, msg)\n\t\t\treturn nil\n\t\t} else if reference.String() == dynamicWorkflowClosureRef {\n\t\t\tmarshalled, _ := proto.Marshal(&dynamicWorkflowClosure)\n\t\t\t_ = proto.Unmarshal(marshalled, msg)\n\t\t\treturn nil\n\t\t}\n\t\treturn fmt.Errorf(\"unexpected call to find value in storage [%v]\", reference.String())\n\t}\n\tnodeExecManager := NewNodeExecutionManager(repository, getMockExecutionsConfigProvider(), make([]string, 0), mockStorage, mockScope.NewTestScope(), mockNodeExecutionRemoteURL, nil, nil, &eventWriterMocks.NodeExecutionEventWriter{})\n\tdataResponse, err := nodeExecManager.GetNodeExecutionData(context.Background(), admin.NodeExecutionGetDataRequest{\n\t\tId: &nodeExecutionIdentifier,\n\t})\n\tassert.NoError(t, err)\n\tassert.True(t, proto.Equal(&admin.NodeExecutionGetDataResponse{\n\t\tInputs: &admin.UrlBlob{\n\t\t\tUrl:   \"inputs\",\n\t\t\tBytes: 100,\n\t\t},\n\t\tOutputs: &admin.UrlBlob{\n\t\t\tUrl:   \"outputs\",\n\t\t\tBytes: 200,\n\t\t},\n\t\tFullInputs:  fullInputs,\n\t\tFullOutputs: fullOutputs,\n\t\tDynamicWorkflow: &admin.DynamicWorkflowNodeMetadata{\n\t\t\tId:               dynamicWorkflowClosure.Primary.Template.Id,\n\t\t\tCompiledWorkflow: &dynamicWorkflowClosure,\n\t\t},\n\t\tFlyteUrls: &admin.FlyteURLs{\n\t\t\tInputs:  \"flyte://v1/project/domain/name/node id/i\",\n\t\t\tOutputs: \"flyte://v1/project/domain/name/node id/o\",\n\t\t\tDeck:    \"flyte://v1/project/domain/name/node id/d\",\n\t\t},\n\t}, dataResponse))\n}\n", "package impl\n\nimport (\n\t\"context\"\n\t\"strconv\"\n\n\t\"github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/admin\"\n\t\"google.golang.org/grpc/codes\"\n\n\t\"github.com/flyteorg/flyteadmin/pkg/common\"\n\t\"github.com/flyteorg/flyteadmin/pkg/errors\"\n\t\"github.com/flyteorg/flyteadmin/pkg/manager/impl/util\"\n\t\"github.com/flyteorg/flyteadmin/pkg/manager/impl/validation\"\n\t\"github.com/flyteorg/flyteadmin/pkg/manager/interfaces\"\n\trepoInterfaces \"github.com/flyteorg/flyteadmin/pkg/repositories/interfaces\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/models\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/transformers\"\n\truntimeInterfaces \"github.com/flyteorg/flyteadmin/pkg/runtime/interfaces\"\n)\n\ntype ProjectManager struct {\n\tdb     repoInterfaces.Repository\n\tconfig runtimeInterfaces.Configuration\n}\n\nvar alphabeticalSortParam, _ = common.NewSortParameter(&admin.Sort{\n\tDirection: admin.Sort_ASCENDING,\n\tKey:       \"identifier\",\n}, models.ProjectColumns)\n\nfunc (m *ProjectManager) CreateProject(ctx context.Context, request admin.ProjectRegisterRequest) (\n\t*admin.ProjectRegisterResponse, error) {\n\tif err := validation.ValidateProjectRegisterRequest(request); err != nil {\n\t\treturn nil, err\n\t}\n\tprojectModel := transformers.CreateProjectModel(request.Project)\n\terr := m.db.ProjectRepo().Create(ctx, projectModel)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &admin.ProjectRegisterResponse{}, nil\n}\n\nfunc (m *ProjectManager) getDomains() []*admin.Domain {\n\tconfigDomains := m.config.ApplicationConfiguration().GetDomainsConfig()\n\tvar domains = make([]*admin.Domain, len(*configDomains))\n\tfor index, configDomain := range *configDomains {\n\t\tdomains[index] = &admin.Domain{\n\t\t\tId:   configDomain.ID,\n\t\t\tName: configDomain.Name,\n\t\t}\n\t}\n\treturn domains\n}\n\nfunc (m *ProjectManager) ListProjects(ctx context.Context, request admin.ProjectListRequest) (*admin.Projects, error) {\n\tspec := util.FilterSpec{\n\t\tRequestFilters: request.Filters,\n\t}\n\tfilters, err := util.GetDbFilters(spec, common.Project)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tsortParameter, err := common.NewSortParameter(request.SortBy, models.ProjectColumns)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif sortParameter == nil {\n\t\tsortParameter = alphabeticalSortParam\n\t}\n\n\toffset, err := validation.ValidateToken(request.Token)\n\tif err != nil {\n\t\treturn nil, errors.NewFlyteAdminErrorf(codes.InvalidArgument,\n\t\t\t\"invalid pagination token %s for ListProjects\", request.Token)\n\t}\n\n\t// And finally, query the database\n\tlistProjectsInput := repoInterfaces.ListResourceInput{\n\t\tLimit:         int(request.Limit),\n\t\tOffset:        offset,\n\t\tInlineFilters: filters,\n\t\tSortParameter: sortParameter,\n\t}\n\tprojectModels, err := m.db.ProjectRepo().List(ctx, listProjectsInput)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tprojects := transformers.FromProjectModels(projectModels, m.getDomains())\n\n\tvar token string\n\tif len(projects) == int(request.Limit) {\n\t\ttoken = strconv.Itoa(offset + len(projects))\n\t}\n\n\treturn &admin.Projects{\n\t\tProjects: projects,\n\t\tToken:    token,\n\t}, nil\n}\n\nfunc (m *ProjectManager) UpdateProject(ctx context.Context, projectUpdate admin.Project) (*admin.ProjectUpdateResponse, error) {\n\tvar response admin.ProjectUpdateResponse\n\tprojectRepo := m.db.ProjectRepo()\n\n\t// Fetch the existing project if exists. If not, return err and do not update.\n\t_, err := projectRepo.Get(ctx, projectUpdate.Id)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// Run validation on the request and return err if validation does not succeed.\n\tif err := validation.ValidateProject(projectUpdate); err != nil {\n\t\treturn nil, err\n\t}\n\n\t// Transform the provided project into a model and apply to the DB.\n\tprojectUpdateModel := transformers.CreateProjectModel(&projectUpdate)\n\terr = projectRepo.UpdateProject(ctx, projectUpdateModel)\n\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &response, nil\n}\n\nfunc NewProjectManager(db repoInterfaces.Repository, config runtimeInterfaces.Configuration) interfaces.ProjectInterface {\n\treturn &ProjectManager{\n\t\tdb:     db,\n\t\tconfig: config,\n\t}\n}\n", "package impl\n\nimport (\n\t\"context\"\n\t\"strconv\"\n\n\t\"github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/admin\"\n\t\"github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/core\"\n\t\"github.com/flyteorg/flytestdlib/contextutils\"\n\t\"github.com/flyteorg/flytestdlib/logger\"\n\t\"github.com/flyteorg/flytestdlib/promutils\"\n\t\"github.com/flyteorg/flytestdlib/promutils/labeled\"\n\t\"google.golang.org/grpc/codes\"\n\n\t\"github.com/flyteorg/flyteadmin/pkg/common\"\n\t\"github.com/flyteorg/flyteadmin/pkg/errors\"\n\t\"github.com/flyteorg/flyteadmin/pkg/manager/impl/util\"\n\t\"github.com/flyteorg/flyteadmin/pkg/manager/impl/validation\"\n\t\"github.com/flyteorg/flyteadmin/pkg/manager/interfaces\"\n\trepoInterfaces \"github.com/flyteorg/flyteadmin/pkg/repositories/interfaces\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/models\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/transformers\"\n)\n\ntype signalMetrics struct {\n\tScope promutils.Scope\n\tSet   labeled.Counter\n}\n\ntype SignalManager struct {\n\tdb      repoInterfaces.Repository\n\tmetrics signalMetrics\n}\n\nfunc getSignalContext(ctx context.Context, identifier *core.SignalIdentifier) context.Context {\n\tctx = contextutils.WithProjectDomain(ctx, identifier.ExecutionId.Project, identifier.ExecutionId.Domain)\n\tctx = contextutils.WithWorkflowID(ctx, identifier.ExecutionId.Name)\n\treturn contextutils.WithSignalID(ctx, identifier.SignalId)\n}\n\nfunc (s *SignalManager) GetOrCreateSignal(ctx context.Context, request admin.SignalGetOrCreateRequest) (*admin.Signal, error) {\n\tif err := validation.ValidateSignalGetOrCreateRequest(ctx, request); err != nil {\n\t\tlogger.Debugf(ctx, \"invalid request [%+v]: %v\", request, err)\n\t\treturn nil, err\n\t}\n\tctx = getSignalContext(ctx, request.Id)\n\n\tsignalModel, err := transformers.CreateSignalModel(request.Id, request.Type, nil)\n\tif err != nil {\n\t\tlogger.Errorf(ctx, \"Failed to transform signal with id [%+v] and type [+%v] with err: %v\", request.Id, request.Type, err)\n\t\treturn nil, err\n\t}\n\n\terr = s.db.SignalRepo().GetOrCreate(ctx, &signalModel)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tsignal, err := transformers.FromSignalModel(signalModel)\n\tif err != nil {\n\t\tlogger.Errorf(ctx, \"Failed to transform signal model [%+v] with err: %v\", signalModel, err)\n\t\treturn nil, err\n\t}\n\n\treturn &signal, nil\n}\n\nfunc (s *SignalManager) ListSignals(ctx context.Context, request admin.SignalListRequest) (*admin.SignalList, error) {\n\tif err := validation.ValidateSignalListRequest(ctx, request); err != nil {\n\t\tlogger.Debugf(ctx, \"ListSignals request [%+v] is invalid: %v\", request, err)\n\t\treturn nil, err\n\t}\n\tctx = getExecutionContext(ctx, request.WorkflowExecutionId)\n\n\tidentifierFilters, err := util.GetWorkflowExecutionIdentifierFilters(ctx, *request.WorkflowExecutionId)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tfilters, err := util.AddRequestFilters(request.Filters, common.Signal, identifierFilters)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tsortParameter, err := common.NewSortParameter(request.SortBy, models.SignalColumns)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\toffset, err := validation.ValidateToken(request.Token)\n\tif err != nil {\n\t\treturn nil, errors.NewFlyteAdminErrorf(codes.InvalidArgument,\n\t\t\t\"invalid pagination token %s for ListSignals\", request.Token)\n\t}\n\n\tsignalModelList, err := s.db.SignalRepo().List(ctx, repoInterfaces.ListResourceInput{\n\t\tInlineFilters: filters,\n\t\tOffset:        offset,\n\t\tLimit:         int(request.Limit),\n\t\tSortParameter: sortParameter,\n\t})\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"Failed to list signals with request [%+v] with err %v\",\n\t\t\trequest, err)\n\t\treturn nil, err\n\t}\n\n\tsignalList, err := transformers.FromSignalModels(signalModelList)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"failed to transform signal models for request [%+v] with err: %v\", request, err)\n\t\treturn nil, err\n\t}\n\tvar token string\n\tif len(signalList) == int(request.Limit) {\n\t\ttoken = strconv.Itoa(offset + len(signalList))\n\t}\n\treturn &admin.SignalList{\n\t\tSignals: signalList,\n\t\tToken:   token,\n\t}, nil\n}\n\nfunc (s *SignalManager) SetSignal(ctx context.Context, request admin.SignalSetRequest) (*admin.SignalSetResponse, error) {\n\tif err := validation.ValidateSignalSetRequest(ctx, s.db, request); err != nil {\n\t\treturn nil, err\n\t}\n\tctx = getSignalContext(ctx, request.Id)\n\n\tsignalModel, err := transformers.CreateSignalModel(request.Id, nil, request.Value)\n\tif err != nil {\n\t\tlogger.Errorf(ctx, \"Failed to transform signal with id [%+v] and value [+%v] with err: %v\", request.Id, request.Value, err)\n\t\treturn nil, err\n\t}\n\n\terr = s.db.SignalRepo().Update(ctx, signalModel.SignalKey, signalModel.Value)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\ts.metrics.Set.Inc(ctx)\n\treturn &admin.SignalSetResponse{}, nil\n}\n\nfunc NewSignalManager(\n\tdb repoInterfaces.Repository,\n\tscope promutils.Scope) interfaces.SignalInterface {\n\tmetrics := signalMetrics{\n\t\tScope: scope,\n\t\tSet:   labeled.NewCounter(\"num_set\", \"count of set signals\", scope),\n\t}\n\n\treturn &SignalManager{\n\t\tdb:      db,\n\t\tmetrics: metrics,\n\t}\n}\n", "package impl\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"strconv\"\n\n\t\"github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/admin\"\n\t\"github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/core\"\n\t\"github.com/flyteorg/flytestdlib/contextutils\"\n\t\"github.com/flyteorg/flytestdlib/logger\"\n\t\"github.com/flyteorg/flytestdlib/promutils\"\n\t\"github.com/flyteorg/flytestdlib/promutils/labeled\"\n\t\"github.com/flyteorg/flytestdlib/storage\"\n\t\"github.com/golang/protobuf/proto\"\n\t\"github.com/prometheus/client_golang/prometheus\"\n\t\"google.golang.org/grpc/codes\"\n\n\tcloudeventInterfaces \"github.com/flyteorg/flyteadmin/pkg/async/cloudevent/interfaces\"\n\tnotificationInterfaces \"github.com/flyteorg/flyteadmin/pkg/async/notifications/interfaces\"\n\t\"github.com/flyteorg/flyteadmin/pkg/common\"\n\tdataInterfaces \"github.com/flyteorg/flyteadmin/pkg/data/interfaces\"\n\t\"github.com/flyteorg/flyteadmin/pkg/errors\"\n\t\"github.com/flyteorg/flyteadmin/pkg/manager/impl/util\"\n\t\"github.com/flyteorg/flyteadmin/pkg/manager/impl/validation\"\n\t\"github.com/flyteorg/flyteadmin/pkg/manager/interfaces\"\n\trepoInterfaces \"github.com/flyteorg/flyteadmin/pkg/repositories/interfaces\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/models\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/transformers\"\n\truntimeInterfaces \"github.com/flyteorg/flyteadmin/pkg/runtime/interfaces\"\n)\n\ntype taskExecutionMetrics struct {\n\tScope                      promutils.Scope\n\tActiveTaskExecutions       prometheus.Gauge\n\tTaskExecutionsCreated      prometheus.Counter\n\tTaskExecutionsTerminated   labeled.Counter\n\tTaskExecutionEventsCreated prometheus.Counter\n\tMissingTaskExecution       prometheus.Counter\n\tMissingTaskDefinition      prometheus.Counter\n\tClosureSizeBytes           prometheus.Summary\n\tTaskExecutionInputBytes    prometheus.Summary\n\tTaskExecutionOutputBytes   prometheus.Summary\n\tPublishEventError          prometheus.Counter\n}\n\ntype TaskExecutionManager struct {\n\tdb                   repoInterfaces.Repository\n\tconfig               runtimeInterfaces.Configuration\n\tstorageClient        *storage.DataStore\n\tmetrics              taskExecutionMetrics\n\turlData              dataInterfaces.RemoteURLInterface\n\tnotificationClient   notificationInterfaces.Publisher\n\tcloudEventsPublisher cloudeventInterfaces.Publisher\n}\n\nfunc getTaskExecutionContext(ctx context.Context, identifier *core.TaskExecutionIdentifier) context.Context {\n\tctx = getNodeExecutionContext(ctx, identifier.NodeExecutionId)\n\treturn contextutils.WithTaskID(ctx, fmt.Sprintf(\"%s-%v\", identifier.TaskId.Name, identifier.RetryAttempt))\n}\n\nfunc (m *TaskExecutionManager) createTaskExecution(\n\tctx context.Context, request *admin.TaskExecutionEventRequest) (\n\tmodels.TaskExecution, error) {\n\n\tnodeExecutionID := request.Event.ParentNodeExecutionId\n\tnodeExecutionExists, err := m.db.NodeExecutionRepo().Exists(ctx, repoInterfaces.NodeExecutionResource{\n\t\tNodeExecutionIdentifier: *nodeExecutionID,\n\t})\n\tif err != nil || !nodeExecutionExists {\n\t\tm.metrics.MissingTaskExecution.Inc()\n\t\tlogger.Debugf(ctx, \"Failed to get existing node execution [%+v] with err %v\", nodeExecutionID, err)\n\t\tif err != nil {\n\t\t\tif ferr, ok := err.(errors.FlyteAdminError); ok {\n\t\t\t\treturn models.TaskExecution{}, errors.NewFlyteAdminErrorf(ferr.Code(),\n\t\t\t\t\t\"Failed to get existing node execution id: [%+v] with err: %v\", nodeExecutionID, err)\n\t\t\t}\n\t\t}\n\t\treturn models.TaskExecution{}, fmt.Errorf(\"failed to get existing node execution id: [%+v]\", nodeExecutionID)\n\t}\n\n\ttaskExecutionModel, err := transformers.CreateTaskExecutionModel(\n\t\tctx,\n\t\ttransformers.CreateTaskExecutionModelInput{\n\t\t\tRequest:               request,\n\t\t\tInlineEventDataPolicy: m.config.ApplicationConfiguration().GetRemoteDataConfig().InlineEventDataPolicy,\n\t\t\tStorageClient:         m.storageClient,\n\t\t})\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"failed to transform task execution %+v into database model: %v\", request.Event.TaskId, err)\n\t\treturn models.TaskExecution{}, err\n\t}\n\n\tif err := m.db.TaskExecutionRepo().Create(ctx, *taskExecutionModel); err != nil {\n\t\tlogger.Debugf(ctx, \"Failed to create task execution with task id [%+v] with err %v\",\n\t\t\trequest.Event.TaskId, err)\n\t\treturn models.TaskExecution{}, err\n\t}\n\n\tm.metrics.TaskExecutionsCreated.Inc()\n\tm.metrics.ClosureSizeBytes.Observe(float64(len(taskExecutionModel.Closure)))\n\tlogger.Debugf(ctx, \"created task execution: %+v\", request.Event.TaskId)\n\treturn *taskExecutionModel, nil\n}\n\nfunc (m *TaskExecutionManager) updateTaskExecutionModelState(\n\tctx context.Context, request *admin.TaskExecutionEventRequest, existingTaskExecution *models.TaskExecution) (\n\tmodels.TaskExecution, error) {\n\n\terr := transformers.UpdateTaskExecutionModel(ctx, request, existingTaskExecution,\n\t\tm.config.ApplicationConfiguration().GetRemoteDataConfig().InlineEventDataPolicy, m.storageClient)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"failed to update task execution model [%+v] with err: %v\", request.Event.TaskId, err)\n\t\treturn models.TaskExecution{}, err\n\t}\n\n\terr = m.db.TaskExecutionRepo().Update(ctx, *existingTaskExecution)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"Failed to update task execution with task id [%+v] and task execution model [%+v] with err %v\",\n\t\t\trequest.Event.TaskId, existingTaskExecution, err)\n\t\treturn models.TaskExecution{}, err\n\t}\n\n\treturn *existingTaskExecution, nil\n}\n\nfunc (m *TaskExecutionManager) CreateTaskExecutionEvent(ctx context.Context, request admin.TaskExecutionEventRequest) (\n\t*admin.TaskExecutionEventResponse, error) {\n\tif err := validation.ValidateTaskExecutionRequest(request, m.config.ApplicationConfiguration().GetRemoteDataConfig().MaxSizeInBytes); err != nil {\n\t\treturn nil, err\n\t}\n\n\tif err := validation.ValidateClusterForExecutionID(ctx, m.db, request.Event.ParentNodeExecutionId.ExecutionId, request.Event.ProducerId); err != nil {\n\t\treturn nil, err\n\t}\n\n\t// Get the parent node execution, if none found a MissingEntityError will be returned\n\tnodeExecutionID := request.Event.ParentNodeExecutionId\n\ttaskExecutionID := core.TaskExecutionIdentifier{\n\t\tTaskId:          request.Event.TaskId,\n\t\tNodeExecutionId: nodeExecutionID,\n\t\tRetryAttempt:    request.Event.RetryAttempt,\n\t}\n\tctx = getTaskExecutionContext(ctx, &taskExecutionID)\n\tlogger.Debugf(ctx, \"Received task execution event for [%+v] transitioning to phase [%v]\",\n\t\ttaskExecutionID, request.Event.Phase)\n\n\t// See if the task execution exists\n\t// - if it does check if the new phase is applicable and then update\n\t// - if it doesn't, create a task execution\n\ttaskExecutionModel, err := m.db.TaskExecutionRepo().Get(ctx, repoInterfaces.GetTaskExecutionInput{\n\t\tTaskExecutionID: taskExecutionID,\n\t})\n\n\tif err != nil {\n\t\tif err.(errors.FlyteAdminError).Code() != codes.NotFound {\n\t\t\tlogger.Debugf(ctx, \"Failed to find existing task execution [%+v] with err %v\", taskExecutionID, err)\n\t\t\treturn nil, err\n\t\t}\n\t\t_, err := m.createTaskExecution(ctx, &request)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\treturn &admin.TaskExecutionEventResponse{}, nil\n\t}\n\tif taskExecutionModel.Phase == request.Event.Phase.String() &&\n\t\ttaskExecutionModel.PhaseVersion >= request.Event.PhaseVersion {\n\t\tlogger.Debugf(ctx, \"have already recorded task execution phase %s (version: %d) for %v\",\n\t\t\trequest.Event.Phase.String(), request.Event.PhaseVersion, taskExecutionID)\n\t\treturn nil, errors.NewFlyteAdminErrorf(codes.AlreadyExists,\n\t\t\t\"have already recorded task execution phase %s (version: %d) for %v\",\n\t\t\trequest.Event.Phase.String(), request.Event.PhaseVersion, taskExecutionID)\n\t}\n\n\tcurrentPhase := core.TaskExecution_Phase(core.TaskExecution_Phase_value[taskExecutionModel.Phase])\n\tif common.IsTaskExecutionTerminal(currentPhase) {\n\t\t// Cannot update a terminal execution.\n\t\tcurPhase := request.Event.Phase.String()\n\t\terrorMsg := fmt.Sprintf(\"invalid phase change from %v to %v for task execution %v\", taskExecutionModel.Phase, request.Event.Phase, taskExecutionID)\n\t\tlogger.Warnf(ctx, errorMsg)\n\t\treturn nil, errors.NewAlreadyInTerminalStateError(ctx, errorMsg, curPhase)\n\t}\n\n\ttaskExecutionModel, err = m.updateTaskExecutionModelState(ctx, &request, &taskExecutionModel)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"Failed to update task execution with id [%+v] with err %v\",\n\t\t\ttaskExecutionID, err)\n\t\treturn nil, err\n\t}\n\n\tif request.Event.Phase == core.TaskExecution_RUNNING && request.Event.PhaseVersion == 0 {\n\t\tm.metrics.ActiveTaskExecutions.Inc()\n\t} else if common.IsTaskExecutionTerminal(request.Event.Phase) && request.Event.PhaseVersion == 0 {\n\t\tm.metrics.ActiveTaskExecutions.Dec()\n\t\tm.metrics.TaskExecutionsTerminated.Inc(contextutils.WithPhase(ctx, request.Event.Phase.String()))\n\t\tif request.Event.GetOutputData() != nil {\n\t\t\tm.metrics.TaskExecutionOutputBytes.Observe(float64(proto.Size(request.Event.GetOutputData())))\n\t\t}\n\t}\n\n\tif err = m.notificationClient.Publish(ctx, proto.MessageName(&request), &request); err != nil {\n\t\tm.metrics.PublishEventError.Inc()\n\t\tlogger.Infof(ctx, \"error publishing event [%+v] with err: [%v]\", request.RequestId, err)\n\t}\n\n\tgo func() {\n\t\tif err := m.cloudEventsPublisher.Publish(ctx, proto.MessageName(&request), &request); err != nil {\n\t\t\tlogger.Infof(ctx, \"error publishing cloud event [%+v] with err: [%v]\", request.RequestId, err)\n\t\t}\n\t}()\n\n\tm.metrics.TaskExecutionEventsCreated.Inc()\n\tlogger.Debugf(ctx, \"Successfully recorded task execution event [%v]\", request.Event)\n\t// TODO: we will want to return some scope information here soon!\n\treturn &admin.TaskExecutionEventResponse{}, nil\n}\n\nfunc (m *TaskExecutionManager) GetTaskExecution(\n\tctx context.Context, request admin.TaskExecutionGetRequest) (*admin.TaskExecution, error) {\n\terr := validation.ValidateTaskExecutionIdentifier(request.Id)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"Failed to validate GetTaskExecution [%+v] with err: %v\", request.Id, err)\n\t\treturn nil, err\n\t}\n\tctx = getTaskExecutionContext(ctx, request.Id)\n\ttaskExecutionModel, err := util.GetTaskExecutionModel(ctx, m.db, request.Id)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\ttaskExecution, err := transformers.FromTaskExecutionModel(*taskExecutionModel, transformers.DefaultExecutionTransformerOptions)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"Failed to transform task execution model [%+v] to proto: %v\", request.Id, err)\n\t\treturn nil, err\n\t}\n\treturn taskExecution, nil\n}\n\nfunc (m *TaskExecutionManager) ListTaskExecutions(\n\tctx context.Context, request admin.TaskExecutionListRequest) (*admin.TaskExecutionList, error) {\n\tif err := validation.ValidateTaskExecutionListRequest(request); err != nil {\n\t\tlogger.Debugf(ctx, \"ListTaskExecutions request [%+v] is invalid: %v\", request, err)\n\t\treturn nil, err\n\t}\n\tctx = getNodeExecutionContext(ctx, request.NodeExecutionId)\n\n\tidentifierFilters, err := util.GetNodeExecutionIdentifierFilters(ctx, *request.NodeExecutionId)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tfilters, err := util.AddRequestFilters(request.Filters, common.TaskExecution, identifierFilters)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tsortParameter, err := common.NewSortParameter(request.SortBy, models.TaskExecutionColumns)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\toffset, err := validation.ValidateToken(request.Token)\n\tif err != nil {\n\t\treturn nil, errors.NewFlyteAdminErrorf(codes.InvalidArgument,\n\t\t\t\"invalid pagination token %s for ListTaskExecutions\", request.Token)\n\t}\n\n\toutput, err := m.db.TaskExecutionRepo().List(ctx, repoInterfaces.ListResourceInput{\n\t\tInlineFilters: filters,\n\t\tOffset:        offset,\n\t\tLimit:         int(request.Limit),\n\t\tSortParameter: sortParameter,\n\t})\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"Failed to list task executions with request [%+v] with err %v\",\n\t\t\trequest, err)\n\t\treturn nil, err\n\t}\n\n\t// Use default transformer options so that error messages shown for task execution attempts in the console sidebar show the full error stack trace.\n\ttaskExecutionList, err := transformers.FromTaskExecutionModels(output.TaskExecutions, transformers.DefaultExecutionTransformerOptions)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"failed to transform task execution models for request [%+v] with err: %v\", request, err)\n\t\treturn nil, err\n\t}\n\tvar token string\n\tif len(taskExecutionList) == int(request.Limit) {\n\t\ttoken = strconv.Itoa(offset + len(taskExecutionList))\n\t}\n\treturn &admin.TaskExecutionList{\n\t\tTaskExecutions: taskExecutionList,\n\t\tToken:          token,\n\t}, nil\n}\n\nfunc (m *TaskExecutionManager) GetTaskExecutionData(\n\tctx context.Context, request admin.TaskExecutionGetDataRequest) (*admin.TaskExecutionGetDataResponse, error) {\n\tif err := validation.ValidateTaskExecutionIdentifier(request.Id); err != nil {\n\t\tlogger.Debugf(ctx, \"Invalid identifier [%+v]: %v\", request.Id, err)\n\t}\n\tctx = getTaskExecutionContext(ctx, request.Id)\n\ttaskExecution, err := m.GetTaskExecution(ctx, admin.TaskExecutionGetRequest{\n\t\tId: request.Id,\n\t})\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"Failed to get task execution with id [%+v] with err %v\",\n\t\t\trequest.Id, err)\n\t\treturn nil, err\n\t}\n\n\tinputs, inputURLBlob, err := util.GetInputs(ctx, m.urlData, m.config.ApplicationConfiguration().GetRemoteDataConfig(),\n\t\tm.storageClient, taskExecution.InputUri)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\toutputs, outputURLBlob, err := util.GetOutputs(ctx, m.urlData, m.config.ApplicationConfiguration().GetRemoteDataConfig(),\n\t\tm.storageClient, taskExecution.Closure)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tresponse := &admin.TaskExecutionGetDataResponse{\n\t\tInputs:      inputURLBlob,\n\t\tOutputs:     outputURLBlob,\n\t\tFullInputs:  inputs,\n\t\tFullOutputs: outputs,\n\t\tFlyteUrls:   common.FlyteURLsFromTaskExecutionID(*request.Id, false),\n\t}\n\n\tm.metrics.TaskExecutionInputBytes.Observe(float64(response.Inputs.Bytes))\n\tif response.Outputs.Bytes > 0 {\n\t\tm.metrics.TaskExecutionOutputBytes.Observe(float64(response.Outputs.Bytes))\n\t} else if response.FullOutputs != nil {\n\t\tm.metrics.TaskExecutionOutputBytes.Observe(float64(proto.Size(response.FullOutputs)))\n\t}\n\treturn response, nil\n}\n\nfunc NewTaskExecutionManager(db repoInterfaces.Repository, config runtimeInterfaces.Configuration,\n\tstorageClient *storage.DataStore, scope promutils.Scope, urlData dataInterfaces.RemoteURLInterface,\n\tpublisher notificationInterfaces.Publisher, cloudEventsPublisher cloudeventInterfaces.Publisher) interfaces.TaskExecutionInterface {\n\n\tmetrics := taskExecutionMetrics{\n\t\tScope: scope,\n\t\tActiveTaskExecutions: scope.MustNewGauge(\"active_executions\",\n\t\t\t\"overall count of active task executions\"),\n\t\tMissingTaskExecution: scope.MustNewCounter(\"missing_node_execution\",\n\t\t\t\"overall count of task execution events received that are missing a parent node execution\"),\n\t\tTaskExecutionsCreated: scope.MustNewCounter(\"task_executions_created\",\n\t\t\t\"overall count of successfully completed CreateExecutionRequests\"),\n\t\tTaskExecutionsTerminated: labeled.NewCounter(\"task_executions_terminated\",\n\t\t\t\"overall count of terminated workflow executions\", scope),\n\t\tTaskExecutionEventsCreated: scope.MustNewCounter(\"task_execution_events_created\",\n\t\t\t\"overall count of successfully completed WorkflowExecutionEventRequest\"),\n\t\tMissingTaskDefinition: scope.MustNewCounter(\"missing_task_definition\",\n\t\t\t\"overall count of task execution events received that are missing a task definition\"),\n\t\tClosureSizeBytes: scope.MustNewSummary(\"closure_size_bytes\",\n\t\t\t\"size in bytes of serialized task execution closure\"),\n\t\tTaskExecutionInputBytes: scope.MustNewSummary(\"input_size_bytes\",\n\t\t\t\"size in bytes of serialized node execution inputs\"),\n\t\tTaskExecutionOutputBytes: scope.MustNewSummary(\"output_size_bytes\",\n\t\t\t\"size in bytes of serialized node execution outputs\"),\n\t\tPublishEventError: scope.MustNewCounter(\"publish_event_error\",\n\t\t\t\"overall count of publish event errors when invoking publish()\"),\n\t}\n\treturn &TaskExecutionManager{\n\t\tdb:                   db,\n\t\tconfig:               config,\n\t\tstorageClient:        storageClient,\n\t\tmetrics:              metrics,\n\t\turlData:              urlData,\n\t\tnotificationClient:   publisher,\n\t\tcloudEventsPublisher: cloudEventsPublisher,\n\t}\n}\n", "package impl\n\nimport (\n\t\"bytes\"\n\t\"context\"\n\t\"strconv\"\n\t\"time\"\n\n\t\"github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/admin\"\n\t\"github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/core\"\n\t\"github.com/flyteorg/flytestdlib/contextutils\"\n\t\"github.com/flyteorg/flytestdlib/logger\"\n\t\"github.com/flyteorg/flytestdlib/promutils\"\n\t\"github.com/flyteorg/flytestdlib/promutils/labeled\"\n\t\"github.com/golang/protobuf/ptypes\"\n\t\"github.com/prometheus/client_golang/prometheus\"\n\t\"google.golang.org/grpc/codes\"\n\n\t\"github.com/flyteorg/flyteadmin/pkg/common\"\n\t\"github.com/flyteorg/flyteadmin/pkg/errors\"\n\t\"github.com/flyteorg/flyteadmin/pkg/manager/impl/resources\"\n\t\"github.com/flyteorg/flyteadmin/pkg/manager/impl/util\"\n\t\"github.com/flyteorg/flyteadmin/pkg/manager/impl/validation\"\n\t\"github.com/flyteorg/flyteadmin/pkg/manager/interfaces\"\n\trepoInterfaces \"github.com/flyteorg/flyteadmin/pkg/repositories/interfaces\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/models\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/transformers\"\n\truntimeInterfaces \"github.com/flyteorg/flyteadmin/pkg/runtime/interfaces\"\n\tworkflowengine \"github.com/flyteorg/flyteadmin/pkg/workflowengine/interfaces\"\n)\n\ntype taskMetrics struct {\n\tScope            promutils.Scope\n\tClosureSizeBytes prometheus.Summary\n\tRegistered       labeled.Counter\n}\n\ntype TaskManager struct {\n\tdb              repoInterfaces.Repository\n\tconfig          runtimeInterfaces.Configuration\n\tcompiler        workflowengine.Compiler\n\tmetrics         taskMetrics\n\tresourceManager interfaces.ResourceInterface\n}\n\nfunc getTaskContext(ctx context.Context, identifier *core.Identifier) context.Context {\n\tctx = contextutils.WithProjectDomain(ctx, identifier.Project, identifier.Domain)\n\treturn contextutils.WithTaskID(ctx, identifier.Name)\n}\n\nfunc setDefaults(request admin.TaskCreateRequest) (admin.TaskCreateRequest, error) {\n\tif request.Id == nil {\n\t\treturn request, errors.NewFlyteAdminError(codes.InvalidArgument,\n\t\t\t\"missing identifier for TaskCreateRequest\")\n\t}\n\n\trequest.Spec.Template.Id = request.Id\n\treturn request, nil\n}\n\nfunc (t *TaskManager) CreateTask(\n\tctx context.Context,\n\trequest admin.TaskCreateRequest) (*admin.TaskCreateResponse, error) {\n\tplatformTaskResources := util.GetTaskResources(ctx, request.Id, t.resourceManager, t.config.TaskResourceConfiguration())\n\tif err := validation.ValidateTask(ctx, request, t.db, platformTaskResources,\n\t\tt.config.WhitelistConfiguration(), t.config.ApplicationConfiguration()); err != nil {\n\t\tlogger.Debugf(ctx, \"Task [%+v] failed validation with err: %v\", request.Id, err)\n\t\treturn nil, err\n\t}\n\tctx = getTaskContext(ctx, request.Id)\n\tfinalizedRequest, err := setDefaults(request)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\t// Compile task and store the compiled version in the database.\n\tcompiledTask, err := t.compiler.CompileTask(finalizedRequest.Spec.Template)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"Failed to compile task with id [%+v] with err %v\", request.Id, err)\n\t\treturn nil, err\n\t}\n\tcreatedAt, err := ptypes.TimestampProto(time.Now())\n\tif err != nil {\n\t\treturn nil, errors.NewFlyteAdminErrorf(codes.Internal,\n\t\t\t\"Failed to serialize CreatedAt: %v when creating task: %+v\", err, request.Id)\n\t}\n\ttaskDigest, err := util.GetTaskDigest(ctx, compiledTask)\n\tif err != nil {\n\t\tlogger.Errorf(ctx, \"failed to compute task digest with err %v\", err)\n\t\treturn nil, err\n\t}\n\t// See if a task exists and confirm whether it's an identical task or one that with a separate definition.\n\texistingTask, err := util.GetTaskModel(ctx, t.db, request.Spec.Template.Id)\n\tif err == nil {\n\t\tif bytes.Equal(taskDigest, existingTask.Digest) {\n\t\t\treturn nil, errors.NewFlyteAdminErrorf(codes.AlreadyExists,\n\t\t\t\t\"identical task already exists with id %s\", request.Id)\n\t\t}\n\t\treturn nil, errors.NewFlyteAdminErrorf(codes.InvalidArgument,\n\t\t\t\"task with different structure already exists with id %v\", request.Id)\n\t}\n\ttaskModel, err := transformers.CreateTaskModel(finalizedRequest, admin.TaskClosure{\n\t\tCompiledTask: compiledTask,\n\t\tCreatedAt:    createdAt,\n\t}, taskDigest)\n\tif err != nil {\n\t\tlogger.Errorf(ctx,\n\t\t\t\"Failed to transform task model [%+v] with err: %v\", finalizedRequest, err)\n\t\treturn nil, err\n\t}\n\n\tdescriptionModel, err := transformers.CreateDescriptionEntityModel(request.Spec.Description, *request.Id)\n\tif err != nil {\n\t\tlogger.Errorf(ctx,\n\t\t\t\"Failed to transform description model [%+v] with err: %v\", request.Spec.Description, err)\n\t\treturn nil, err\n\t}\n\tif descriptionModel != nil {\n\t\ttaskModel.ShortDescription = descriptionModel.ShortDescription\n\t}\n\terr = t.db.TaskRepo().Create(ctx, taskModel, descriptionModel)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"Failed to create task model with id [%+v] with err %v\", request.Id, err)\n\t\treturn nil, err\n\t}\n\tt.metrics.ClosureSizeBytes.Observe(float64(len(taskModel.Closure)))\n\tif finalizedRequest.Spec.Template.Metadata != nil {\n\t\tcontextWithRuntimeMeta := context.WithValue(\n\t\t\tctx, common.RuntimeTypeKey, finalizedRequest.Spec.Template.Metadata.Runtime.Type.String())\n\t\tcontextWithRuntimeMeta = context.WithValue(\n\t\t\tcontextWithRuntimeMeta, common.RuntimeVersionKey, finalizedRequest.Spec.Template.Metadata.Runtime.Version)\n\t\tt.metrics.Registered.Inc(contextWithRuntimeMeta)\n\t}\n\n\treturn &admin.TaskCreateResponse{}, nil\n}\n\nfunc (t *TaskManager) GetTask(ctx context.Context, request admin.ObjectGetRequest) (*admin.Task, error) {\n\tif err := validation.ValidateIdentifier(request.Id, common.Task); err != nil {\n\t\tlogger.Debugf(ctx, \"invalid identifier [%+v]: %v\", request.Id, err)\n\t}\n\tctx = getTaskContext(ctx, request.Id)\n\ttask, err := util.GetTask(ctx, t.db, *request.Id)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"Failed to get task with id [%+v] with err %v\", err, request.Id)\n\t\treturn nil, err\n\t}\n\treturn task, nil\n}\n\nfunc (t *TaskManager) ListTasks(ctx context.Context, request admin.ResourceListRequest) (*admin.TaskList, error) {\n\t// Check required fields\n\tif err := validation.ValidateResourceListRequest(request); err != nil {\n\t\tlogger.Debugf(ctx, \"Invalid request [%+v]: %v\", request, err)\n\t\treturn nil, err\n\t}\n\tctx = contextutils.WithProjectDomain(ctx, request.Id.Project, request.Id.Domain)\n\tctx = contextutils.WithTaskID(ctx, request.Id.Name)\n\tspec := util.FilterSpec{\n\t\tProject:        request.Id.Project,\n\t\tDomain:         request.Id.Domain,\n\t\tName:           request.Id.Name,\n\t\tRequestFilters: request.Filters,\n\t}\n\n\tfilters, err := util.GetDbFilters(spec, common.Task)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tsortParameter, err := common.NewSortParameter(request.SortBy, models.TaskColumns)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\toffset, err := validation.ValidateToken(request.Token)\n\tif err != nil {\n\t\treturn nil, errors.NewFlyteAdminErrorf(codes.InvalidArgument,\n\t\t\t\"invalid pagination token %s for ListTasks\", request.Token)\n\t}\n\t// And finally, query the database\n\tlistTasksInput := repoInterfaces.ListResourceInput{\n\t\tLimit:         int(request.Limit),\n\t\tOffset:        offset,\n\t\tInlineFilters: filters,\n\t\tSortParameter: sortParameter,\n\t}\n\toutput, err := t.db.TaskRepo().List(ctx, listTasksInput)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"Failed to list tasks with id [%+v] with err %v\", request.Id, err)\n\t\treturn nil, err\n\t}\n\ttaskList, err := transformers.FromTaskModels(output.Tasks)\n\tif err != nil {\n\t\tlogger.Errorf(ctx,\n\t\t\t\"Failed to transform task models [%+v] with err: %v\", output.Tasks, err)\n\t\treturn nil, err\n\t}\n\n\tvar token string\n\tif len(taskList) == int(request.Limit) {\n\t\ttoken = strconv.Itoa(offset + len(taskList))\n\t}\n\treturn &admin.TaskList{\n\t\tTasks: taskList,\n\t\tToken: token,\n\t}, nil\n}\n\n// This queries the unique tasks for the given query parameters.  At least the project and domain must be specified.\n// It will return all tasks, but only the one of each even if there are multiple versions.\nfunc (t *TaskManager) ListUniqueTaskIdentifiers(ctx context.Context, request admin.NamedEntityIdentifierListRequest) (\n\t*admin.NamedEntityIdentifierList, error) {\n\tif err := validation.ValidateNamedEntityIdentifierListRequest(request); err != nil {\n\t\tlogger.Debugf(ctx, \"invalid request [%+v]: %v\", request, err)\n\t\treturn nil, err\n\t}\n\tctx = contextutils.WithProjectDomain(ctx, request.Project, request.Domain)\n\tfilters, err := util.GetDbFilters(util.FilterSpec{\n\t\tProject: request.Project,\n\t\tDomain:  request.Domain,\n\t}, common.Task)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tsortParameter, err := common.NewSortParameter(request.SortBy, models.TaskColumns)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\toffset, err := validation.ValidateToken(request.Token)\n\tif err != nil {\n\t\treturn nil, errors.NewFlyteAdminErrorf(codes.InvalidArgument,\n\t\t\t\"invalid pagination token %s for ListUniqueTaskIdentifiers\", request.Token)\n\t}\n\tlistTasksInput := repoInterfaces.ListResourceInput{\n\t\tLimit:         int(request.Limit),\n\t\tOffset:        offset,\n\t\tInlineFilters: filters,\n\t\tSortParameter: sortParameter,\n\t}\n\n\toutput, err := t.db.TaskRepo().ListTaskIdentifiers(ctx, listTasksInput)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"Failed to list tasks ids with project: %s and domain: %s with err %v\",\n\t\t\trequest.Project, request.Domain, err)\n\t\treturn nil, err\n\t}\n\n\tidList := transformers.FromTaskModelsToIdentifiers(output.Tasks)\n\tvar token string\n\tif len(idList) == int(request.Limit) {\n\t\ttoken = strconv.Itoa(offset + len(idList))\n\t}\n\treturn &admin.NamedEntityIdentifierList{\n\t\tEntities: idList,\n\t\tToken:    token,\n\t}, nil\n}\n\nfunc NewTaskManager(\n\tdb repoInterfaces.Repository,\n\tconfig runtimeInterfaces.Configuration, compiler workflowengine.Compiler,\n\tscope promutils.Scope) interfaces.TaskInterface {\n\tmetrics := taskMetrics{\n\t\tScope:            scope,\n\t\tClosureSizeBytes: scope.MustNewSummary(\"closure_size_bytes\", \"size in bytes of serialized task closure\"),\n\t\tRegistered:       labeled.NewCounter(\"num_registered\", \"count of registered tasks\", scope),\n\t}\n\tresourceManager := resources.NewResourceManager(db, config.ApplicationConfiguration())\n\treturn &TaskManager{\n\t\tdb:              db,\n\t\tconfig:          config,\n\t\tcompiler:        compiler,\n\t\tmetrics:         metrics,\n\t\tresourceManager: resourceManager,\n\t}\n}\n", "// Util around parsing request filters\npackage util\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"regexp\"\n\t\"strconv\"\n\t\"strings\"\n\t\"time\"\n\n\t\"github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/core\"\n\t\"github.com/flyteorg/flytestdlib/logger\"\n\t\"google.golang.org/grpc/codes\"\n\t\"k8s.io/apimachinery/pkg/util/sets\"\n\n\t\"github.com/flyteorg/flyteadmin/pkg/common\"\n\t\"github.com/flyteorg/flyteadmin/pkg/errors\"\n\t\"github.com/flyteorg/flyteadmin/pkg/manager/impl/shared\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/models\"\n)\n\nconst (\n\tfilterExpressionSeperator = \"+\"\n\tlistValueSeparator        = \";\"\n)\n\n// Matches filters of the form `func(field,value)` or `func(field, value)`\nvar filterRegex = regexp.MustCompile(`(.+)\\((.+),\\s?(.+)\\)`)\n\n// InlineFilter parsing consts. For example, matching on the filter string \"contains(Name, foo)\"\n// will return a slice consisting of: [\"contains(Name, foo)\", \"contains\", \"Name\", \"foo\"]\nconst (\n\tfuncMatchIndex           = 1\n\tfieldMatchIndex          = 2\n\tvalueMatchIndex          = 3\n\texpectedMatchGroupLength = 4\n)\n\nvar timestampFields = map[string]bool{\n\t\"CreatedAt\": true,\n\t\"UpdatedAt\": true,\n\t\"DeletedAt\": true,\n\t\"StartedAt\": true,\n}\n\nvar durationFields = map[string]bool{\n\t\"duration\": true,\n}\n\nconst filterFieldEntityPrefixFmt = \"%s.\"\nconst secondsFormat = \"%vs\"\n\nvar filterFieldEntityPrefix = map[string]common.Entity{\n\t\"task\":                  common.Task,\n\t\"workflow\":              common.Workflow,\n\t\"launch_plan\":           common.LaunchPlan,\n\t\"execution\":             common.Execution,\n\t\"node_execution\":        common.NodeExecution,\n\t\"task_execution\":        common.TaskExecution,\n\t\"entities\":              common.NamedEntity,\n\t\"named_entity_metadata\": common.NamedEntityMetadata,\n\t\"project\":               common.Project,\n\t\"signal\":                common.Signal,\n\t\"admin_tag\":             common.AdminTag,\n\t\"execution_admin_tag\":   common.ExecutionAdminTag,\n}\n\nfunc parseField(field string, primaryEntity common.Entity) (common.Entity, string) {\n\tfor prefix, entity := range filterFieldEntityPrefix {\n\t\totherEntityPrefix := fmt.Sprintf(filterFieldEntityPrefixFmt, prefix)\n\t\tif strings.HasPrefix(field, otherEntityPrefix) {\n\t\t\t// Strip the referenced entity prefix from the field name.\n\t\t\t// e.g. workflow_name becomes simply \"name\"\n\t\t\treturn entity, field[len(otherEntityPrefix):]\n\t\t}\n\t}\n\n\treturn primaryEntity, field\n}\n\nfunc parseRepeatedValues(parsedValues string) []string {\n\treturn strings.Split(parsedValues, listValueSeparator)\n}\n\n// Handles parsing repeated values and non-string values such as time fields.\nfunc prepareValues(field string, values []string) (interface{}, error) {\n\tpreparedValues := make([]interface{}, len(values))\n\tif isTimestampField := timestampFields[field]; isTimestampField {\n\t\tfor idx, value := range values {\n\t\t\ttimestamp, err := time.Parse(time.RFC3339Nano, value)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, errors.NewFlyteAdminErrorf(codes.InvalidArgument,\n\t\t\t\t\t\"Timestamp %s must conform to RFC3339 Nano spec\", value)\n\t\t\t}\n\t\t\tpreparedValues[idx] = timestamp\n\t\t}\n\t} else if isDurationField := durationFields[strings.ToLower(field)]; isDurationField {\n\t\tfor idx, value := range values {\n\t\t\tfloatValue, err := strconv.ParseFloat(value, 64)\n\t\t\tif err == nil {\n\t\t\t\t// The value is an float. By default purely float values are assumed to represent durations in seconds.\n\t\t\t\tvalue = fmt.Sprintf(secondsFormat, floatValue)\n\t\t\t}\n\t\t\tduration, err := time.ParseDuration(value)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, errors.NewFlyteAdminErrorf(codes.InvalidArgument,\n\t\t\t\t\t\"Failed to parse duration [%s]\", value)\n\t\t\t}\n\t\t\tpreparedValues[idx] = duration\n\t\t}\n\t} else {\n\t\tfor idx, value := range values {\n\t\t\tpreparedValues[idx] = value\n\t\t}\n\t}\n\tif len(preparedValues) == 1 {\n\t\treturn preparedValues[0], nil\n\t}\n\treturn preparedValues, nil\n}\n\nvar allowedJoinEntities = map[common.Entity]sets.String{\n\tcommon.Execution:           sets.NewString(common.Execution, common.LaunchPlan, common.Workflow, common.Task, common.AdminTag),\n\tcommon.LaunchPlan:          sets.NewString(common.LaunchPlan, common.Workflow),\n\tcommon.NodeExecution:       sets.NewString(common.NodeExecution, common.Execution),\n\tcommon.NodeExecutionEvent:  sets.NewString(common.NodeExecutionEvent),\n\tcommon.Task:                sets.NewString(common.Task),\n\tcommon.TaskExecution:       sets.NewString(common.TaskExecution, common.Task, common.Execution, common.NodeExecution),\n\tcommon.Workflow:            sets.NewString(common.Workflow),\n\tcommon.NamedEntity:         sets.NewString(common.NamedEntity),\n\tcommon.NamedEntityMetadata: sets.NewString(common.NamedEntityMetadata),\n\tcommon.Project:             sets.NewString(common.Project),\n\tcommon.Signal:              sets.NewString(common.Signal),\n\tcommon.AdminTag:            sets.NewString(common.AdminTag),\n}\n\nvar entityColumns = map[common.Entity]sets.String{\n\tcommon.Execution:           models.ExecutionColumns,\n\tcommon.LaunchPlan:          models.LaunchPlanColumns,\n\tcommon.NodeExecution:       models.NodeExecutionColumns,\n\tcommon.NodeExecutionEvent:  models.NodeExecutionEventColumns,\n\tcommon.Task:                models.TaskColumns,\n\tcommon.TaskExecution:       models.TaskExecutionColumns,\n\tcommon.Workflow:            models.WorkflowColumns,\n\tcommon.NamedEntity:         models.NamedEntityColumns,\n\tcommon.NamedEntityMetadata: models.NamedEntityMetadataColumns,\n\tcommon.Project:             models.ProjectColumns,\n\tcommon.Signal:              models.SignalColumns,\n\tcommon.AdminTag:            models.AdminTagColumns,\n}\n\nfunc ParseFilters(filterParams string, primaryEntity common.Entity) ([]common.InlineFilter, error) {\n\t// Multiple filters can be appended as URI-escaped strings joined by filterExpressionSeperator\n\tfilterExpressions := strings.Split(filterParams, filterExpressionSeperator)\n\tparsedFilters := make([]common.InlineFilter, 0)\n\tfor _, filterExpression := range filterExpressions {\n\t\t// Parse string expression\n\t\tmatches := filterRegex.FindStringSubmatch(filterExpression)\n\t\tif len(matches) != expectedMatchGroupLength {\n\t\t\t// Poorly formatted filter string doesn't match expected regex.\n\t\t\treturn nil, shared.GetInvalidArgumentError(shared.Filters)\n\t\t}\n\t\treferencedEntity, field := parseField(matches[fieldMatchIndex], primaryEntity)\n\n\t\tjoinEntities, ok := allowedJoinEntities[primaryEntity]\n\t\tif !ok {\n\t\t\treturn nil, fmt.Errorf(\"unsupported entity '%s'\", primaryEntity)\n\t\t}\n\n\t\tif !joinEntities.Has(referencedEntity) {\n\t\t\treturn nil, errors.NewFlyteAdminErrorf(codes.InvalidArgument, \"'%s' entity is not allowed in filters\", referencedEntity)\n\t\t}\n\n\t\tif !entityColumns[referencedEntity].Has(field) {\n\t\t\treturn nil, errors.NewFlyteAdminErrorf(codes.InvalidArgument, \"'%s.%s' is invalid filter\", referencedEntity, field)\n\t\t}\n\n\t\t// Parse and transform values\n\t\tparsedValues := parseRepeatedValues(matches[valueMatchIndex])\n\t\tpreparedValues, err := prepareValues(field, parsedValues)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\t// Create InlineFilter object.\n\t\tfilter, err := common.NewInlineFilter(referencedEntity, matches[funcMatchIndex], field, preparedValues)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tparsedFilters = append(parsedFilters, filter)\n\t}\n\treturn parsedFilters, nil\n}\n\nfunc GetSingleValueEqualityFilter(entity common.Entity, field, value string) (common.InlineFilter, error) {\n\treturn common.NewSingleValueFilter(entity, common.Equal, field, value)\n}\n\ntype FilterSpec struct {\n\t// All of these fields are optional (although they should not *all* be empty).\n\tProject        string\n\tDomain         string\n\tName           string\n\tRequestFilters string\n}\n\n// Returns equality filters initialized for identifier attributes (project, domain & name)\n// which can be optionally specified in requests.\nfunc getIdentifierFilters(entity common.Entity, spec FilterSpec) ([]common.InlineFilter, error) {\n\tfilters := make([]common.InlineFilter, 0)\n\tif spec.Project != \"\" {\n\t\tprojectFilter, err := GetSingleValueEqualityFilter(entity, shared.Project, spec.Project)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tfilters = append(filters, projectFilter)\n\t}\n\tif spec.Domain != \"\" {\n\t\tdomainFilter, err := GetSingleValueEqualityFilter(entity, shared.Domain, spec.Domain)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tfilters = append(filters, domainFilter)\n\t}\n\n\tif spec.Name != \"\" {\n\t\tnameFilter, err := GetSingleValueEqualityFilter(entity, shared.Name, spec.Name)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tfilters = append(filters, nameFilter)\n\t}\n\treturn filters, nil\n}\n\nfunc AddRequestFilters(requestFilters string, primaryEntity common.Entity, existingFilters []common.InlineFilter) (\n\t[]common.InlineFilter, error) {\n\n\tif requestFilters == \"\" {\n\t\treturn existingFilters, nil\n\t}\n\tvar additionalFilters []common.InlineFilter\n\tadditionalFilters, err := ParseFilters(requestFilters, primaryEntity)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tupdatedFilters := append(existingFilters, additionalFilters...)\n\treturn updatedFilters, nil\n}\n\n// Consolidates request params and filters to a single list of filters. This consolidation is necessary since the db is\n// agnostic to required request parameters and additional filter arguments.\nfunc GetDbFilters(spec FilterSpec, primaryEntity common.Entity) ([]common.InlineFilter, error) {\n\tfilters, err := getIdentifierFilters(primaryEntity, spec)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// Append any request filters.\n\tif spec.RequestFilters != \"\" {\n\t\tfilters, err = AddRequestFilters(spec.RequestFilters, primaryEntity, filters)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\treturn filters, nil\n}\n\nfunc GetWorkflowExecutionIdentifierFilters(\n\tctx context.Context, workflowExecutionIdentifier core.WorkflowExecutionIdentifier) ([]common.InlineFilter, error) {\n\tidentifierFilters := make([]common.InlineFilter, 3)\n\tidentifierProjectFilter, err := GetSingleValueEqualityFilter(\n\t\tcommon.Execution, shared.Project, workflowExecutionIdentifier.Project)\n\tif err != nil {\n\t\tlogger.Warningf(ctx, \"Failed to create execution identifier filter for project: %s with identifier [%+v]\",\n\t\t\tworkflowExecutionIdentifier.Project, workflowExecutionIdentifier)\n\t\treturn nil, err\n\t}\n\tidentifierFilters[0] = identifierProjectFilter\n\n\tidentifierDomainFilter, err := GetSingleValueEqualityFilter(\n\t\tcommon.Execution, shared.Domain, workflowExecutionIdentifier.Domain)\n\tif err != nil {\n\t\tlogger.Warningf(ctx, \"Failed to create execution identifier filter for domain: %s with identifier [%+v]\",\n\t\t\tworkflowExecutionIdentifier.Domain, workflowExecutionIdentifier)\n\t\treturn nil, err\n\t}\n\tidentifierFilters[1] = identifierDomainFilter\n\n\tidentifierNameFilter, err := GetSingleValueEqualityFilter(\n\t\tcommon.Execution, shared.Name, workflowExecutionIdentifier.Name)\n\tif err != nil {\n\t\tlogger.Warningf(ctx, \"Failed to create execution identifier filter for domain: %s with identifier [%+v]\",\n\t\t\tworkflowExecutionIdentifier.Name, workflowExecutionIdentifier)\n\t\treturn nil, err\n\t}\n\tidentifierFilters[2] = identifierNameFilter\n\treturn identifierFilters, nil\n}\n\n// All inputs to this function must be validated.\nfunc GetNodeExecutionIdentifierFilters(\n\tctx context.Context, nodeExecutionIdentifier core.NodeExecutionIdentifier) ([]common.InlineFilter, error) {\n\tworkflowExecutionIdentifierFilters, err :=\n\t\tGetWorkflowExecutionIdentifierFilters(ctx, *nodeExecutionIdentifier.ExecutionId)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tnodeIDFilter, err := GetSingleValueEqualityFilter(\n\t\tcommon.NodeExecution, shared.NodeID, nodeExecutionIdentifier.NodeId)\n\tif err != nil {\n\t\tlogger.Warningf(ctx, \"Failed to create node execution identifier filter for node id: %s with identifier [%+v]\",\n\t\t\tnodeExecutionIdentifier.NodeId, nodeExecutionIdentifier)\n\t}\n\treturn append(workflowExecutionIdentifierFilters, nodeIDFilter), nil\n}\n", "package util\n\nimport (\n\t\"context\"\n\t\"testing\"\n\t\"time\"\n\n\t\"github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/core\"\n\t\"github.com/stretchr/testify/assert\"\n\t\"github.com/stretchr/testify/require\"\n\n\t\"github.com/flyteorg/flyteadmin/pkg/common\"\n\t\"github.com/flyteorg/flyteadmin/pkg/manager/impl/shared\"\n\t\"github.com/flyteorg/flyteadmin/pkg/manager/impl/testutils\"\n)\n\nfunc TestParseRepeatedValues(t *testing.T) {\n\tassert.EqualValues(t, []string{\"foo\", \"bar\"}, parseRepeatedValues(\"foo;bar\"))\n}\n\nfunc TestPrepareValues_WithTimestamp(t *testing.T) {\n\ttimestampValue := \"2018-07-27T00:30:31Z\"\n\tvalues, err := prepareValues(\"CreatedAt\", []string{timestampValue})\n\tif err != nil {\n\t\tt.Fatalf(\"failed to prepare value for CreatedAt: %+v with err %v\", timestampValue, err)\n\t}\n\texpectedTime, err := time.Parse(time.RFC3339Nano, timestampValue)\n\tif err != nil {\n\t\tt.Fatalf(\"Native time library failed to parse test timestamp %s with err %v\", timestampValue, err)\n\t}\n\tassert.EqualValues(t, expectedTime, values)\n\n\tbadTimestampValue := \"not a valid timestamp\"\n\t_, err = prepareValues(\"CreatedAt\", []string{badTimestampValue})\n\tassert.Error(t, err)\n}\n\nfunc TestPrepareValues_WithDuration(t *testing.T) {\n\tduration := \"3600.5s\"\n\tvalues, err := prepareValues(\"duration\", []string{duration})\n\tassert.Nil(t, err)\n\texpectedDuration, err := time.ParseDuration(duration)\n\tif err != nil {\n\t\tt.Fatalf(\"Native time library failed to parse test timestamp %s with err %v\", duration, err)\n\t}\n\tassert.EqualValues(t, expectedDuration, values)\n\n\tduration = \"3600.5\"\n\tvalues, err = prepareValues(\"duration\", []string{duration})\n\tassert.Nil(t, err)\n\tassert.EqualValues(t, expectedDuration, values)\n\n\tbadDurationValue := \"not a valid duration\"\n\t_, err = prepareValues(\"duration\", []string{badDurationValue})\n\tassert.Error(t, err)\n}\n\nfunc TestPrepareValues_RepeatedValues(t *testing.T) {\n\tvalues, err := prepareValues(\"field\", []string{\"value\"})\n\tassert.NoError(t, err)\n\tassert.Equal(t, \"value\", values)\n\n\tvalues, err = prepareValues(\"field\", []string{\"value a\", \"value b\"})\n\tassert.NoError(t, err)\n\tassert.Equal(t, []interface{}{\"value a\", \"value b\"}, values)\n}\n\nfunc Test_ParseFilters_Success(t *testing.T) {\n\tfilterExpression := \"eq(project, flytesnacks)+ne(domain, development)+value_in(type, 4;5;6)\"\n\n\ttaskFilters, err := ParseFilters(filterExpression, common.Task)\n\n\tassert.NoError(t, err)\n\trequire.Len(t, taskFilters, 3)\n\n\tactualFilterExpression, _ := taskFilters[0].GetGormQueryExpr()\n\tassert.Equal(t, \"project = ?\", actualFilterExpression.Query)\n\tassert.Equal(t, \"flytesnacks\", actualFilterExpression.Args)\n\n\tactualFilterExpression, _ = taskFilters[1].GetGormQueryExpr()\n\tassert.Equal(t, \"domain <> ?\", actualFilterExpression.Query)\n\tassert.Equal(t, \"development\", actualFilterExpression.Args)\n\n\tactualFilterExpression, _ = taskFilters[2].GetGormQueryExpr()\n\tassert.Equal(t, \"type in (?)\", actualFilterExpression.Query)\n\tassert.Equal(t, []interface{}{\"4\", \"5\", \"6\"}, actualFilterExpression.Args)\n}\n\nfunc Test_ParseFilters_InvalidFunction(t *testing.T) {\n\tfilterExpression := \"invalid_function(type,bar)\"\n\n\t_, err := ParseFilters(filterExpression, common.Task)\n\n\tassert.EqualError(t, err, \"unrecognized filter function: invalid_function\")\n}\n\nfunc Test_ParseFilters_UnsupportedEntity(t *testing.T) {\n\tfilterExpression := \"eq(foo, 123)\"\n\n\t_, err := ParseFilters(filterExpression, \"wrong\")\n\n\tassert.EqualError(t, err, \"unsupported entity 'wrong'\")\n}\n\nfunc Test_ParseFilters_InvalidJoinEntity(t *testing.T) {\n\tfilterExpression := \"eq(project.name, 123)\"\n\n\t_, err := ParseFilters(filterExpression, common.Workflow)\n\n\tassert.EqualError(t, err, \"'p' entity is not allowed in filters\")\n}\n\nfunc Test_ParseFilters_InvalidFilter(t *testing.T) {\n\tfilterExpression := \"eq(foo, 123)\"\n\n\t_, err := ParseFilters(filterExpression, common.Task)\n\n\tassert.EqualError(t, err, \"'t.foo' is invalid filter\")\n}\n\nfunc TestGetEqualityFilter(t *testing.T) {\n\tfilter, err := GetSingleValueEqualityFilter(common.Task, \"field\", \"value\")\n\tassert.NoError(t, err)\n\n\tactualFilterExpression, _ := filter.GetGormQueryExpr()\n\tassert.Equal(t, \"field = ?\", actualFilterExpression.Query)\n\tassert.Equal(t, \"value\", actualFilterExpression.Args)\n}\n\nfunc Test_AddRequestFilters(t *testing.T) {\n\tfilters, err := AddRequestFilters(\n\t\t\"ne(cluster, TheWorst)+eq(workflow.name, workflow)\", common.Execution, make([]common.InlineFilter, 0))\n\n\tassert.NoError(t, err)\n\trequire.Len(t, filters, 2)\n\n\texpression, err := filters[0].GetGormQueryExpr()\n\tassert.NoError(t, err)\n\tassert.Equal(t, \"cluster <> ?\", expression.Query)\n\tassert.Equal(t, \"TheWorst\", expression.Args)\n\n\texpression, err = filters[1].GetGormQueryExpr()\n\tassert.NoError(t, err)\n\tassert.Equal(t, testutils.NameQueryPattern, expression.Query)\n\tassert.Equal(t, \"workflow\", expression.Args)\n}\n\nfunc TestGetDbFilters(t *testing.T) {\n\tactualFilters, err := GetDbFilters(FilterSpec{\n\t\tProject:        \"project\",\n\t\tDomain:         \"domain\",\n\t\tName:           \"name\",\n\t\tRequestFilters: \"ne(version, TheWorst)+eq(workflow.name, workflow)\",\n\t}, common.LaunchPlan)\n\tassert.NoError(t, err)\n\n\t// Init expected values for filters.\n\tprojectFilter, _ := GetSingleValueEqualityFilter(common.LaunchPlan, shared.Project, \"project\")\n\tdomainFilter, _ := GetSingleValueEqualityFilter(common.LaunchPlan, shared.Domain, \"domain\")\n\tnameFilter, _ := GetSingleValueEqualityFilter(common.LaunchPlan, shared.Name, \"name\")\n\tversionFilter, _ := common.NewSingleValueFilter(common.LaunchPlan, common.NotEqual, shared.Version, \"TheWorst\")\n\tworkflowNameFilter, _ := common.NewSingleValueFilter(common.Workflow, common.Equal, shared.Name, \"workflow\")\n\texpectedFilters := []common.InlineFilter{\n\t\tprojectFilter,\n\t\tdomainFilter,\n\t\tnameFilter,\n\t\tversionFilter,\n\t\tworkflowNameFilter,\n\t}\n\tassert.EqualValues(t, expectedFilters, actualFilters)\n}\n\nfunc TestGetWorkflowExecutionIdentifierFilters(t *testing.T) {\n\tidentifierFilters, err := GetWorkflowExecutionIdentifierFilters(\n\t\tcontext.Background(), core.WorkflowExecutionIdentifier{\n\t\t\tProject: \"ex project\",\n\t\t\tDomain:  \"ex domain\",\n\t\t\tName:    \"ex name\",\n\t\t})\n\tassert.Nil(t, err)\n\n\tassert.Len(t, identifierFilters, 3)\n\tassert.Equal(t, common.Execution, identifierFilters[0].GetEntity())\n\tqueryExpr, _ := identifierFilters[0].GetGormQueryExpr()\n\tassert.Equal(t, \"ex project\", queryExpr.Args)\n\tassert.Equal(t, \"execution_project = ?\", queryExpr.Query)\n\n\tassert.Equal(t, common.Execution, identifierFilters[1].GetEntity())\n\tqueryExpr, _ = identifierFilters[1].GetGormQueryExpr()\n\tassert.Equal(t, \"ex domain\", queryExpr.Args)\n\tassert.Equal(t, \"execution_domain = ?\", queryExpr.Query)\n\n\tassert.Equal(t, common.Execution, identifierFilters[2].GetEntity())\n\tqueryExpr, _ = identifierFilters[2].GetGormQueryExpr()\n\tassert.Equal(t, \"ex name\", queryExpr.Args)\n\tassert.Equal(t, \"execution_name = ?\", queryExpr.Query)\n}\n\nfunc TestGetNodeExecutionIdentifierFilters(t *testing.T) {\n\tidentifierFilters, err := GetNodeExecutionIdentifierFilters(\n\t\tcontext.Background(), core.NodeExecutionIdentifier{\n\t\t\tExecutionId: &core.WorkflowExecutionIdentifier{\n\t\t\t\tProject: \"ex project\",\n\t\t\t\tDomain:  \"ex domain\",\n\t\t\t\tName:    \"ex name\",\n\t\t\t},\n\t\t\tNodeId: \"nodey\",\n\t\t})\n\tassert.Nil(t, err)\n\n\tassert.Len(t, identifierFilters, 4)\n\tassert.Equal(t, common.Execution, identifierFilters[0].GetEntity())\n\tqueryExpr, _ := identifierFilters[0].GetGormQueryExpr()\n\tassert.Equal(t, \"ex project\", queryExpr.Args)\n\tassert.Equal(t, \"execution_project = ?\", queryExpr.Query)\n\n\tassert.Equal(t, common.Execution, identifierFilters[1].GetEntity())\n\tqueryExpr, _ = identifierFilters[1].GetGormQueryExpr()\n\tassert.Equal(t, \"ex domain\", queryExpr.Args)\n\tassert.Equal(t, \"execution_domain = ?\", queryExpr.Query)\n\n\tassert.Equal(t, common.Execution, identifierFilters[2].GetEntity())\n\tqueryExpr, _ = identifierFilters[2].GetGormQueryExpr()\n\tassert.Equal(t, \"ex name\", queryExpr.Args)\n\tassert.Equal(t, \"execution_name = ?\", queryExpr.Query)\n\n\tassert.Equal(t, common.NodeExecution, identifierFilters[3].GetEntity())\n\tqueryExpr, _ = identifierFilters[3].GetGormQueryExpr()\n\tassert.Equal(t, \"nodey\", queryExpr.Args)\n\tassert.Equal(t, \"node_id = ?\", queryExpr.Query)\n}\n", "package impl\n\nimport (\n\t\"bytes\"\n\t\"context\"\n\t\"strconv\"\n\t\"time\"\n\n\t\"github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/admin\"\n\t\"github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/core\"\n\tcompiler \"github.com/flyteorg/flytepropeller/pkg/compiler/common\"\n\t\"github.com/flyteorg/flytestdlib/contextutils\"\n\t\"github.com/flyteorg/flytestdlib/logger\"\n\t\"github.com/flyteorg/flytestdlib/promutils\"\n\t\"github.com/flyteorg/flytestdlib/storage\"\n\t\"github.com/golang/protobuf/ptypes\"\n\t\"github.com/prometheus/client_golang/prometheus\"\n\t\"google.golang.org/grpc/codes\"\n\n\t\"github.com/flyteorg/flyteadmin/pkg/common\"\n\t\"github.com/flyteorg/flyteadmin/pkg/errors\"\n\t\"github.com/flyteorg/flyteadmin/pkg/manager/impl/util\"\n\t\"github.com/flyteorg/flyteadmin/pkg/manager/impl/validation\"\n\t\"github.com/flyteorg/flyteadmin/pkg/manager/interfaces\"\n\trepoInterfaces \"github.com/flyteorg/flyteadmin/pkg/repositories/interfaces\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/models\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/transformers\"\n\truntimeInterfaces \"github.com/flyteorg/flyteadmin/pkg/runtime/interfaces\"\n\tworkflowengine \"github.com/flyteorg/flyteadmin/pkg/workflowengine/impl\"\n\tworkflowengineInterfaces \"github.com/flyteorg/flyteadmin/pkg/workflowengine/interfaces\"\n)\n\nvar defaultStorageOptions = storage.Options{}\n\ntype workflowMetrics struct {\n\tScope                   promutils.Scope\n\tCompilationFailures     prometheus.Counter\n\tTypedInterfaceSizeBytes prometheus.Summary\n}\n\ntype WorkflowManager struct {\n\tdb            repoInterfaces.Repository\n\tconfig        runtimeInterfaces.Configuration\n\tcompiler      workflowengineInterfaces.Compiler\n\tstorageClient *storage.DataStore\n\tstoragePrefix []string\n\tmetrics       workflowMetrics\n}\n\nfunc getWorkflowContext(ctx context.Context, identifier *core.Identifier) context.Context {\n\tctx = contextutils.WithProjectDomain(ctx, identifier.Project, identifier.Domain)\n\treturn contextutils.WithWorkflowID(ctx, identifier.Name)\n}\n\nfunc (w *WorkflowManager) setDefaults(request admin.WorkflowCreateRequest) (admin.WorkflowCreateRequest, error) {\n\t// TODO: Also add environment and configuration defaults once those have been determined.\n\tif request.Id == nil {\n\t\treturn request, errors.NewFlyteAdminError(codes.InvalidArgument, \"missing identifier for WorkflowCreateRequest\")\n\t}\n\trequest.Spec.Template.Id = request.Id\n\treturn request, nil\n}\n\nfunc (w *WorkflowManager) getCompiledWorkflow(\n\tctx context.Context, request admin.WorkflowCreateRequest) (admin.WorkflowClosure, error) {\n\treqs, err := w.compiler.GetRequirements(request.Spec.Template, request.Spec.SubWorkflows)\n\tif err != nil {\n\t\tw.metrics.CompilationFailures.Inc()\n\t\tlogger.Errorf(ctx, \"Failed to get workflow requirements for template [%+v] with err %v\",\n\t\t\trequest.Spec.Template, err)\n\t\treturn admin.WorkflowClosure{}, err\n\t}\n\n\tvar tasks = make([]*core.CompiledTask, len(reqs.GetRequiredTaskIds()))\n\tfor idx, taskID := range reqs.GetRequiredTaskIds() {\n\t\ttask, err := util.GetTask(ctx, w.db, taskID)\n\t\tif err != nil {\n\t\t\tlogger.Debugf(ctx, \"Failed to get task with id [%+v] when compiling workflow with id [%+v] with err %v\",\n\t\t\t\ttaskID, request.Id, err)\n\t\t\treturn admin.WorkflowClosure{}, err\n\t\t}\n\t\ttasks[idx] = task.Closure.CompiledTask\n\t}\n\n\tvar launchPlans = make([]compiler.InterfaceProvider, len(reqs.GetRequiredLaunchPlanIds()))\n\tfor idx, launchPlanID := range reqs.GetRequiredLaunchPlanIds() {\n\t\tvar launchPlanModel models.LaunchPlan\n\t\tlaunchPlanModel, err = util.GetLaunchPlanModel(ctx, w.db, launchPlanID)\n\t\tif err != nil {\n\t\t\tlogger.Debugf(ctx, \"Failed to get launch plan with id [%+v] when compiling workflow with id [%+v] with err %v\",\n\t\t\t\tlaunchPlanID, request.Id, err)\n\t\t\treturn admin.WorkflowClosure{}, err\n\t\t}\n\t\tvar launchPlanInterfaceProvider workflowengine.InterfaceProvider\n\t\tlaunchPlanInterfaceProvider, err = workflowengine.NewLaunchPlanInterfaceProvider(launchPlanModel, launchPlanID)\n\t\tif err != nil {\n\t\t\tlogger.Debugf(ctx, \"Failed to create LaunchPlanInterfaceProvider for launch plan [%+v] with err %v\",\n\t\t\t\tlaunchPlanModel, err)\n\t\t\treturn admin.WorkflowClosure{}, err\n\t\t}\n\t\tlaunchPlans[idx] = launchPlanInterfaceProvider\n\t}\n\n\tclosure, err := w.compiler.CompileWorkflow(request.Spec.Template, request.Spec.SubWorkflows, tasks, launchPlans)\n\tif err != nil {\n\t\tw.metrics.CompilationFailures.Inc()\n\t\tlogger.Debugf(ctx, \"Failed to compile workflow with id [%+v] with err %v\", request.Id, err)\n\t\treturn admin.WorkflowClosure{}, err\n\t}\n\tcreatedAt, err := ptypes.TimestampProto(time.Now())\n\tif err != nil {\n\t\treturn admin.WorkflowClosure{}, errors.NewFlyteAdminErrorf(codes.Internal,\n\t\t\t\"Failed to serialize CreatedAt: %v when saving compiled workflow %+v\", err, request.Id)\n\t}\n\treturn admin.WorkflowClosure{\n\t\tCompiledWorkflow: closure,\n\t\tCreatedAt:        createdAt,\n\t}, nil\n}\n\nfunc (w *WorkflowManager) createDataReference(\n\tctx context.Context, identifier *core.Identifier) (storage.DataReference, error) {\n\tnestedSubKeys := []string{\n\t\tidentifier.Project,\n\t\tidentifier.Domain,\n\t\tidentifier.Name,\n\t\tidentifier.Version,\n\t}\n\tnestedKeys := append(w.storagePrefix, nestedSubKeys...)\n\treturn w.storageClient.ConstructReference(ctx, w.storageClient.GetBaseContainerFQN(ctx), nestedKeys...)\n}\n\nfunc (w *WorkflowManager) CreateWorkflow(\n\tctx context.Context,\n\trequest admin.WorkflowCreateRequest) (*admin.WorkflowCreateResponse, error) {\n\tif err := validation.ValidateWorkflow(ctx, request, w.db, w.config.ApplicationConfiguration()); err != nil {\n\t\treturn nil, err\n\t}\n\tctx = getWorkflowContext(ctx, request.Id)\n\tfinalizedRequest, err := w.setDefaults(request)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"Failed to set defaults for workflow with id [%+v] with err %v\", request.Id, err)\n\t\treturn nil, err\n\t}\n\t// Validate that the workflow compiles.\n\tworkflowClosure, err := w.getCompiledWorkflow(ctx, finalizedRequest)\n\tif err != nil {\n\t\tlogger.Errorf(ctx, \"Failed to compile workflow with err: %v\", err)\n\t\treturn nil, errors.NewFlyteAdminErrorf(codes.Internal,\n\t\t\t\"failed to compile workflow for [%+v] with err %v\", request.Id, err)\n\t}\n\terr = validation.ValidateCompiledWorkflow(\n\t\t*request.Id, workflowClosure, w.config.RegistrationValidationConfiguration())\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tworkflowDigest, err := util.GetWorkflowDigest(ctx, workflowClosure.CompiledWorkflow)\n\tif err != nil {\n\t\tlogger.Errorf(ctx, \"failed to compute workflow digest with err %v\", err)\n\t\treturn nil, err\n\t}\n\n\t// Assert that a matching workflow doesn't already exist before uploading the workflow closure.\n\texistingWorkflowModel, err := util.GetWorkflowModel(ctx, w.db, *request.Id)\n\t// Check that no identical or conflicting workflows exist.\n\tif err == nil {\n\t\t// A workflow's structure is uniquely defined by its collection of nodes.\n\t\tif bytes.Equal(workflowDigest, existingWorkflowModel.Digest) {\n\t\t\treturn nil, errors.NewWorkflowExistsIdenticalStructureError(ctx, &request)\n\t\t}\n\t\t// A workflow exists with different structure\n\t\treturn nil, errors.NewWorkflowExistsDifferentStructureError(ctx, &request)\n\t} else if flyteAdminError, ok := err.(errors.FlyteAdminError); !ok || flyteAdminError.Code() != codes.NotFound {\n\t\tlogger.Debugf(ctx, \"Failed to get workflow for comparison in CreateWorkflow with ID [%+v] with err %v\",\n\t\t\trequest.Id, err)\n\t\treturn nil, err\n\t}\n\n\tremoteClosureDataRef, err := w.createDataReference(ctx, request.Spec.Template.Id)\n\tif err != nil {\n\t\tlogger.Infof(ctx, \"failed to construct data reference for workflow closure with id [%+v] with err %v\",\n\t\t\trequest.Id, err)\n\t\treturn nil, errors.NewFlyteAdminErrorf(codes.Internal,\n\t\t\t\"failed to construct data reference for workflow closure with id [%+v] and err %v\", request.Id, err)\n\t}\n\terr = w.storageClient.WriteProtobuf(ctx, remoteClosureDataRef, defaultStorageOptions, &workflowClosure)\n\n\tif err != nil {\n\t\tlogger.Infof(ctx,\n\t\t\t\"failed to write marshaled workflow with id [%+v] to storage %s with err %v and base container: %s\",\n\t\t\trequest.Id, remoteClosureDataRef.String(), err, w.storageClient.GetBaseContainerFQN(ctx))\n\t\treturn nil, errors.NewFlyteAdminErrorf(codes.Internal,\n\t\t\t\"failed to write marshaled workflow [%+v] to storage %s with err %v and base container: %s\",\n\t\t\trequest.Id, remoteClosureDataRef.String(), err, w.storageClient.GetBaseContainerFQN(ctx))\n\t}\n\t// Save the workflow & its reference to the offloaded, compiled workflow in the database.\n\tworkflowModel, err := transformers.CreateWorkflowModel(\n\t\tfinalizedRequest, remoteClosureDataRef.String(), workflowDigest)\n\tif err != nil {\n\t\tlogger.Errorf(ctx,\n\t\t\t\"Failed to transform workflow model for request [%+v] and remoteClosureIdentifier [%s] with err: %v\",\n\t\t\tfinalizedRequest, remoteClosureDataRef.String(), err)\n\t\treturn nil, err\n\t}\n\tdescriptionModel, err := transformers.CreateDescriptionEntityModel(request.Spec.Description, *request.Id)\n\tif err != nil {\n\t\tlogger.Errorf(ctx,\n\t\t\t\"Failed to transform description model [%+v] with err: %v\", request.Spec.Description, err)\n\t\treturn nil, err\n\t}\n\tif descriptionModel != nil {\n\t\tworkflowModel.ShortDescription = descriptionModel.ShortDescription\n\t}\n\tif err = w.db.WorkflowRepo().Create(ctx, workflowModel, descriptionModel); err != nil {\n\t\tlogger.Infof(ctx, \"Failed to create workflow model [%+v] with err %v\", request.Id, err)\n\t\treturn nil, err\n\t}\n\tw.metrics.TypedInterfaceSizeBytes.Observe(float64(len(workflowModel.TypedInterface)))\n\n\treturn &admin.WorkflowCreateResponse{}, nil\n}\n\nfunc (w *WorkflowManager) GetWorkflow(ctx context.Context, request admin.ObjectGetRequest) (*admin.Workflow, error) {\n\tif err := validation.ValidateIdentifier(request.Id, common.Workflow); err != nil {\n\t\tlogger.Debugf(ctx, \"invalid identifier [%+v]: %v\", request.Id, err)\n\t\treturn nil, err\n\t}\n\tctx = getWorkflowContext(ctx, request.Id)\n\tworkflow, err := util.GetWorkflow(ctx, w.db, w.storageClient, *request.Id)\n\tif err != nil {\n\t\tlogger.Infof(ctx, \"Failed to get workflow with id [%+v] with err %v\", request.Id, err)\n\t\treturn nil, err\n\t}\n\treturn workflow, nil\n}\n\n// Returns workflows *without* a populated workflow closure.\nfunc (w *WorkflowManager) ListWorkflows(\n\tctx context.Context, request admin.ResourceListRequest) (*admin.WorkflowList, error) {\n\t// Check required fields\n\tif err := validation.ValidateResourceListRequest(request); err != nil {\n\t\treturn nil, err\n\t}\n\tctx = contextutils.WithProjectDomain(ctx, request.Id.Project, request.Id.Domain)\n\tctx = contextutils.WithWorkflowID(ctx, request.Id.Name)\n\tfilters, err := util.GetDbFilters(util.FilterSpec{\n\t\tProject:        request.Id.Project,\n\t\tDomain:         request.Id.Domain,\n\t\tName:           request.Id.Name,\n\t\tRequestFilters: request.Filters,\n\t}, common.Workflow)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tsortParameter, err := common.NewSortParameter(request.SortBy, models.WorkflowColumns)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\toffset, err := validation.ValidateToken(request.Token)\n\tif err != nil {\n\t\treturn nil, errors.NewFlyteAdminErrorf(codes.InvalidArgument,\n\t\t\t\"invalid pagination token %s for ListWorkflows\", request.Token)\n\t}\n\tlistWorkflowsInput := repoInterfaces.ListResourceInput{\n\t\tLimit:         int(request.Limit),\n\t\tOffset:        offset,\n\t\tInlineFilters: filters,\n\t\tSortParameter: sortParameter,\n\t}\n\toutput, err := w.db.WorkflowRepo().List(ctx, listWorkflowsInput)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"Failed to list workflows with [%+v] with err %v\", request.Id, err)\n\t\treturn nil, err\n\t}\n\tworkflowList, err := transformers.FromWorkflowModels(output.Workflows)\n\tif err != nil {\n\t\tlogger.Errorf(ctx,\n\t\t\t\"Failed to transform workflow models [%+v] with err: %v\", output.Workflows, err)\n\t\treturn nil, err\n\t}\n\tvar token string\n\tif len(output.Workflows) == int(request.Limit) {\n\t\ttoken = strconv.Itoa(offset + len(output.Workflows))\n\t}\n\treturn &admin.WorkflowList{\n\t\tWorkflows: workflowList,\n\t\tToken:     token,\n\t}, nil\n}\n\nfunc (w *WorkflowManager) ListWorkflowIdentifiers(ctx context.Context, request admin.NamedEntityIdentifierListRequest) (\n\t*admin.NamedEntityIdentifierList, error) {\n\tif err := validation.ValidateNamedEntityIdentifierListRequest(request); err != nil {\n\t\tlogger.Debugf(ctx, \"invalid request [%+v]: %v\", request, err)\n\t\treturn nil, err\n\t}\n\tctx = contextutils.WithProjectDomain(ctx, request.Project, request.Domain)\n\n\tfilters, err := util.GetDbFilters(util.FilterSpec{\n\t\tProject: request.Project,\n\t\tDomain:  request.Domain,\n\t}, common.Workflow)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tsortParameter, err := common.NewSortParameter(request.SortBy, models.WorkflowColumns)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\toffset, err := validation.ValidateToken(request.Token)\n\tif err != nil {\n\t\treturn nil, errors.NewFlyteAdminErrorf(codes.InvalidArgument,\n\t\t\t\"invalid pagination token %s for ListWorkflowIdentifiers\", request.Token)\n\t}\n\tlistWorkflowsInput := repoInterfaces.ListResourceInput{\n\t\tLimit:         int(request.Limit),\n\t\tOffset:        offset,\n\t\tInlineFilters: filters,\n\t\tSortParameter: sortParameter,\n\t}\n\n\toutput, err := w.db.WorkflowRepo().ListIdentifiers(ctx, listWorkflowsInput)\n\tif err != nil {\n\t\tlogger.Debugf(ctx, \"Failed to list workflow ids with project: %s and domain: %s with err %v\",\n\t\t\trequest.Project, request.Domain, err)\n\t\treturn nil, err\n\t}\n\n\tvar token string\n\tif len(output.Workflows) == int(request.Limit) {\n\t\ttoken = strconv.Itoa(offset + len(output.Workflows))\n\t}\n\tentities := transformers.FromWorkflowModelsToIdentifiers(output.Workflows)\n\treturn &admin.NamedEntityIdentifierList{\n\t\tEntities: entities,\n\t\tToken:    token,\n\t}, nil\n\n}\n\nfunc NewWorkflowManager(\n\tdb repoInterfaces.Repository,\n\tconfig runtimeInterfaces.Configuration,\n\tcompiler workflowengineInterfaces.Compiler,\n\tstorageClient *storage.DataStore,\n\tstoragePrefix []string,\n\tscope promutils.Scope) interfaces.WorkflowInterface {\n\tmetrics := workflowMetrics{\n\t\tScope: scope,\n\t\tCompilationFailures: scope.MustNewCounter(\n\t\t\t\"compilation_failures\", \"any observed failures when compiling a workflow\"),\n\t\tTypedInterfaceSizeBytes: scope.MustNewSummary(\"typed_interface_size_bytes\",\n\t\t\t\"size in bytes of serialized workflow TypedInterface\"),\n\t}\n\treturn &WorkflowManager{\n\t\tdb:            db,\n\t\tconfig:        config,\n\t\tcompiler:      compiler,\n\t\tstorageClient: storageClient,\n\t\tstoragePrefix: storagePrefix,\n\t\tmetrics:       metrics,\n\t}\n}\n", "package gormimpl\n\nimport (\n\t\"fmt\"\n\t\"sync\"\n\n\t\"google.golang.org/grpc/codes\"\n\t\"gorm.io/gorm\"\n\t\"gorm.io/gorm/schema\"\n\t\"k8s.io/apimachinery/pkg/util/sets\"\n\n\t\"github.com/flyteorg/flyteadmin/pkg/common\"\n\tadminErrors \"github.com/flyteorg/flyteadmin/pkg/errors\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/errors\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/interfaces\"\n)\n\nconst Project = \"project\"\nconst Domain = \"domain\"\nconst Name = \"name\"\nconst Version = \"version\"\nconst Description = \"description\"\nconst ResourceType = \"resource_type\"\nconst State = \"state\"\nconst ID = \"id\"\n\nconst executionTableName = \"executions\"\nconst namedEntityMetadataTableName = \"named_entity_metadata\"\nconst nodeExecutionTableName = \"node_executions\"\nconst taskExecutionTableName = \"task_executions\"\nconst taskTableName = \"tasks\"\nconst workflowTableName = \"workflows\"\nconst descriptionEntityTableName = \"description_entities\"\nconst AdminTagsTableName = \"admin_tags\"\nconst executionAdminTagsTableName = \"execution_admin_tags\"\n\nconst limit = \"limit\"\nconst filters = \"filters\"\n\nvar identifierGroupBy = fmt.Sprintf(\"%s, %s, %s\", Project, Domain, Name)\n\nvar entityToTableName = map[common.Entity]string{\n\tcommon.Execution:           \"executions\",\n\tcommon.LaunchPlan:          \"launch_plans\",\n\tcommon.NodeExecution:       \"node_executions\",\n\tcommon.NodeExecutionEvent:  \"node_execution_events\",\n\tcommon.Task:                \"tasks\",\n\tcommon.TaskExecution:       \"task_executions\",\n\tcommon.Workflow:            \"workflows\",\n\tcommon.NamedEntity:         \"entities\",\n\tcommon.NamedEntityMetadata: \"named_entity_metadata\",\n\tcommon.Signal:              \"signals\",\n\tcommon.AdminTag:            \"admin_tags\",\n\tcommon.ExecutionAdminTag:   \"execution_admin_tags\",\n}\n\nvar innerJoinExecToNodeExec = fmt.Sprintf(\n\t\"INNER JOIN %s ON %s.execution_project = %s.execution_project AND \"+\n\t\t\"%s.execution_domain = %s.execution_domain AND %s.execution_name = %s.execution_name\",\n\texecutionTableName, nodeExecutionTableName, executionTableName, nodeExecutionTableName, executionTableName,\n\tnodeExecutionTableName, executionTableName)\n\nvar innerJoinNodeExecToTaskExec = fmt.Sprintf(\n\t\"INNER JOIN %s ON %s.node_id = %s.node_id AND %s.execution_project = %s.execution_project AND \"+\n\t\t\"%s.execution_domain = %s.execution_domain AND %s.execution_name = %s.execution_name\",\n\tnodeExecutionTableName, taskExecutionTableName, nodeExecutionTableName, taskExecutionTableName,\n\tnodeExecutionTableName, taskExecutionTableName, nodeExecutionTableName, taskExecutionTableName,\n\tnodeExecutionTableName)\n\n// Because dynamic tasks do NOT necessarily register static task definitions, we use a left join to not exclude\n// dynamic tasks from list queries.\nvar leftJoinTaskToTaskExec = fmt.Sprintf(\n\t\"LEFT JOIN %s ON %s.project = %s.project AND %s.domain = %s.domain AND %s.name = %s.name AND \"+\n\t\t\"%s.version = %s.version\",\n\ttaskTableName, taskExecutionTableName, taskTableName, taskExecutionTableName, taskTableName,\n\ttaskExecutionTableName, taskTableName, taskExecutionTableName, taskTableName)\n\n// Validates there are no missing but required parameters in ListResourceInput\nfunc ValidateListInput(input interfaces.ListResourceInput) adminErrors.FlyteAdminError {\n\tif input.Limit == 0 {\n\t\treturn errors.GetInvalidInputError(limit)\n\t}\n\tif len(input.InlineFilters) == 0 {\n\t\treturn errors.GetInvalidInputError(filters)\n\t}\n\treturn nil\n}\n\nfunc applyFilters(tx *gorm.DB, inlineFilters []common.InlineFilter, mapFilters []common.MapFilter) (*gorm.DB, error) {\n\tfor _, filter := range inlineFilters {\n\t\tgormQueryExpr, err := filter.GetGormQueryExpr()\n\t\tif err != nil {\n\t\t\treturn nil, errors.GetInvalidInputError(err.Error())\n\t\t}\n\t\ttx = tx.Where(gormQueryExpr.Query, gormQueryExpr.Args)\n\t}\n\tfor _, mapFilter := range mapFilters {\n\t\ttx = tx.Where(mapFilter.GetFilter())\n\t}\n\treturn tx, nil\n}\n\nfunc applyScopedFilters(tx *gorm.DB, inlineFilters []common.InlineFilter, mapFilters []common.MapFilter) (*gorm.DB, error) {\n\tfor _, filter := range inlineFilters {\n\t\ttableName, ok := entityToTableName[filter.GetEntity()]\n\t\tif !ok {\n\t\t\treturn nil, adminErrors.NewFlyteAdminErrorf(codes.InvalidArgument,\n\t\t\t\t\"unrecognized entity in filter expression: %v\", filter.GetEntity())\n\t\t}\n\t\tgormQueryExpr, err := filter.GetGormJoinTableQueryExpr(tableName)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\ttx = tx.Where(gormQueryExpr.Query, gormQueryExpr.Args)\n\t}\n\tfor _, mapFilter := range mapFilters {\n\t\ttx = tx.Where(mapFilter.GetFilter())\n\t}\n\treturn tx, nil\n}\n\nfunc modelColumns(v any) sets.String {\n\ts, err := schema.Parse(v, &sync.Map{}, schema.NamingStrategy{})\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\treturn sets.NewString(s.DBNames...)\n}\n", "package gormimpl\n\nimport (\n\t\"context\"\n\n\t\"github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/core\"\n\t\"github.com/flyteorg/flytestdlib/promutils\"\n\t\"gorm.io/gorm\"\n\n\t\"github.com/flyteorg/flyteadmin/pkg/common\"\n\tflyteAdminDbErrors \"github.com/flyteorg/flyteadmin/pkg/repositories/errors\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/interfaces\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/models\"\n)\n\n// DescriptionEntityRepo Implementation of DescriptionEntityRepoInterface.\ntype DescriptionEntityRepo struct {\n\tdb               *gorm.DB\n\terrorTransformer flyteAdminDbErrors.ErrorTransformer\n\tmetrics          gormMetrics\n}\n\nfunc (r *DescriptionEntityRepo) Get(ctx context.Context, input interfaces.GetDescriptionEntityInput) (models.DescriptionEntity, error) {\n\tvar descriptionEntity models.DescriptionEntity\n\n\tfilters, err := getDescriptionEntityFilters(input.ResourceType, input.Project, input.Domain, input.Name, input.Version)\n\tif err != nil {\n\t\treturn models.DescriptionEntity{}, err\n\t}\n\n\ttx := r.db.Table(descriptionEntityTableName)\n\t// Apply filters\n\ttx, err = applyFilters(tx, filters, nil)\n\tif err != nil {\n\t\treturn models.DescriptionEntity{}, err\n\t}\n\n\ttimer := r.metrics.GetDuration.Start()\n\ttx = tx.Take(&descriptionEntity)\n\ttimer.Stop()\n\n\tif tx.Error != nil {\n\t\treturn models.DescriptionEntity{}, r.errorTransformer.ToFlyteAdminError(tx.Error)\n\t}\n\n\treturn descriptionEntity, nil\n}\n\nfunc (r *DescriptionEntityRepo) List(\n\tctx context.Context, input interfaces.ListResourceInput) (interfaces.DescriptionEntityCollectionOutput, error) {\n\t// First validate input.\n\tif err := ValidateListInput(input); err != nil {\n\t\treturn interfaces.DescriptionEntityCollectionOutput{}, err\n\t}\n\tvar descriptionEntities []models.DescriptionEntity\n\ttx := r.db.Limit(input.Limit).Offset(input.Offset)\n\n\t// Apply filters\n\ttx, err := applyFilters(tx, input.InlineFilters, input.MapFilters)\n\tif err != nil {\n\t\treturn interfaces.DescriptionEntityCollectionOutput{}, err\n\t}\n\t// Apply sort ordering.\n\tif input.SortParameter != nil {\n\t\ttx = tx.Order(input.SortParameter.GetGormOrderExpr())\n\t}\n\ttimer := r.metrics.ListDuration.Start()\n\ttx.Find(&descriptionEntities)\n\ttimer.Stop()\n\tif tx.Error != nil {\n\t\treturn interfaces.DescriptionEntityCollectionOutput{}, r.errorTransformer.ToFlyteAdminError(tx.Error)\n\t}\n\treturn interfaces.DescriptionEntityCollectionOutput{\n\t\tEntities: descriptionEntities,\n\t}, nil\n}\n\nfunc getDescriptionEntityFilters(resourceType core.ResourceType, project string, domain string, name string, version string) ([]common.InlineFilter, error) {\n\tentity := common.ResourceTypeToEntity[resourceType]\n\n\tfilters := make([]common.InlineFilter, 0)\n\tprojectFilter, err := common.NewSingleValueFilter(entity, common.Equal, Project, project)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tfilters = append(filters, projectFilter)\n\tdomainFilter, err := common.NewSingleValueFilter(entity, common.Equal, Domain, domain)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tfilters = append(filters, domainFilter)\n\tnameFilter, err := common.NewSingleValueFilter(entity, common.Equal, Name, name)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tfilters = append(filters, nameFilter)\n\tversionFilter, err := common.NewSingleValueFilter(entity, common.Equal, Version, version)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tfilters = append(filters, versionFilter)\n\n\treturn filters, nil\n}\n\n// NewDescriptionEntityRepo Returns an instance of DescriptionRepoInterface\nfunc NewDescriptionEntityRepo(\n\tdb *gorm.DB, errorTransformer flyteAdminDbErrors.ErrorTransformer, scope promutils.Scope) interfaces.DescriptionEntityRepoInterface {\n\tmetrics := newMetrics(scope)\n\treturn &DescriptionEntityRepo{\n\t\tdb:               db,\n\t\terrorTransformer: errorTransformer,\n\t\tmetrics:          metrics,\n\t}\n}\n", "package gormimpl\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"fmt\"\n\n\t\"github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/core\"\n\t\"github.com/flyteorg/flytestdlib/promutils\"\n\n\t\"github.com/flyteorg/flyteadmin/pkg/common\"\n\tadminErrors \"github.com/flyteorg/flyteadmin/pkg/repositories/errors\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/interfaces\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/models\"\n\n\t\"gorm.io/gorm\"\n)\n\n// Implementation of ExecutionInterface.\ntype ExecutionRepo struct {\n\tdb               *gorm.DB\n\terrorTransformer adminErrors.ErrorTransformer\n\tmetrics          gormMetrics\n}\n\nfunc (r *ExecutionRepo) Create(ctx context.Context, input models.Execution) error {\n\ttimer := r.metrics.CreateDuration.Start()\n\ttx := r.db.Omit(\"id\").Create(&input)\n\ttimer.Stop()\n\tif tx.Error != nil {\n\t\treturn r.errorTransformer.ToFlyteAdminError(tx.Error)\n\t}\n\treturn nil\n}\n\nfunc (r *ExecutionRepo) Get(_ context.Context, input interfaces.Identifier) (models.Execution, error) {\n\tvar execution models.Execution\n\ttimer := r.metrics.GetDuration.Start()\n\ttx := r.db.Where(&models.Execution{\n\t\tExecutionKey: models.ExecutionKey{\n\t\t\tProject: input.Project,\n\t\t\tDomain:  input.Domain,\n\t\t\tName:    input.Name,\n\t\t},\n\t}).Take(&execution)\n\ttimer.Stop()\n\n\tif tx.Error != nil && errors.Is(tx.Error, gorm.ErrRecordNotFound) {\n\t\treturn models.Execution{}, adminErrors.GetMissingEntityError(\"execution\", &core.Identifier{\n\t\t\tProject: input.Project,\n\t\t\tDomain:  input.Domain,\n\t\t\tName:    input.Name,\n\t\t})\n\t} else if tx.Error != nil {\n\t\treturn models.Execution{}, r.errorTransformer.ToFlyteAdminError(tx.Error)\n\t}\n\treturn execution, nil\n}\n\nfunc (r *ExecutionRepo) Update(ctx context.Context, execution models.Execution) error {\n\ttimer := r.metrics.UpdateDuration.Start()\n\ttx := r.db.Model(&execution).Updates(execution)\n\ttimer.Stop()\n\tif err := tx.Error; err != nil {\n\t\treturn r.errorTransformer.ToFlyteAdminError(err)\n\t}\n\treturn nil\n}\n\nfunc (r *ExecutionRepo) List(_ context.Context, input interfaces.ListResourceInput) (\n\tinterfaces.ExecutionCollectionOutput, error) {\n\tvar err error\n\t// First validate input.\n\tif err = ValidateListInput(input); err != nil {\n\t\treturn interfaces.ExecutionCollectionOutput{}, err\n\t}\n\tvar executions []models.Execution\n\ttx := r.db.Limit(input.Limit).Offset(input.Offset)\n\t// And add join condition as required by user-specified filters (which can potentially include join table attrs).\n\tif ok := input.JoinTableEntities[common.LaunchPlan]; ok {\n\t\ttx = tx.Joins(fmt.Sprintf(\"INNER JOIN %s ON %s.launch_plan_id = %s.id\",\n\t\t\tlaunchPlanTableName, executionTableName, launchPlanTableName))\n\t}\n\tif ok := input.JoinTableEntities[common.Workflow]; ok {\n\t\ttx = tx.Joins(fmt.Sprintf(\"INNER JOIN %s ON %s.workflow_id = %s.id\",\n\t\t\tworkflowTableName, executionTableName, workflowTableName))\n\t}\n\tif ok := input.JoinTableEntities[common.Task]; ok {\n\t\ttx = tx.Joins(fmt.Sprintf(\"INNER JOIN %s ON %s.task_id = %s.id\",\n\t\t\ttaskTableName, executionTableName, taskTableName))\n\t}\n\n\tif ok := input.JoinTableEntities[common.AdminTag]; ok {\n\t\ttx = tx.Joins(fmt.Sprintf(\"INNER JOIN %s ON %s.execution_name = %s.execution_name\",\n\t\t\texecutionAdminTagsTableName, executionTableName, executionAdminTagsTableName))\n\t\ttx = tx.Joins(fmt.Sprintf(\"INNER JOIN %s ON %s.id = %s.admin_tag_id\",\n\t\t\tAdminTagsTableName, AdminTagsTableName, executionAdminTagsTableName))\n\t}\n\n\t// Apply filters\n\ttx, err = applyScopedFilters(tx, input.InlineFilters, input.MapFilters)\n\tif err != nil {\n\t\treturn interfaces.ExecutionCollectionOutput{}, err\n\t}\n\t// Apply sort ordering.\n\tif input.SortParameter != nil {\n\t\ttx = tx.Order(input.SortParameter.GetGormOrderExpr())\n\t}\n\n\ttimer := r.metrics.ListDuration.Start()\n\ttx = tx.Find(&executions)\n\ttimer.Stop()\n\tif tx.Error != nil {\n\t\treturn interfaces.ExecutionCollectionOutput{}, r.errorTransformer.ToFlyteAdminError(tx.Error)\n\t}\n\treturn interfaces.ExecutionCollectionOutput{\n\t\tExecutions: executions,\n\t}, nil\n}\n\nfunc (r *ExecutionRepo) Count(ctx context.Context, input interfaces.CountResourceInput) (int64, error) {\n\tvar err error\n\ttx := r.db.Model(&models.Execution{})\n\n\t// Add join condition as required by user-specified filters (which can potentially include join table attrs).\n\tif ok := input.JoinTableEntities[common.LaunchPlan]; ok {\n\t\ttx = tx.Joins(fmt.Sprintf(\"INNER JOIN %s ON %s.launch_plan_id = %s.id\",\n\t\t\tlaunchPlanTableName, executionTableName, launchPlanTableName))\n\t}\n\tif ok := input.JoinTableEntities[common.Workflow]; ok {\n\t\ttx = tx.Joins(fmt.Sprintf(\"INNER JOIN %s ON %s.workflow_id = %s.id\",\n\t\t\tworkflowTableName, executionTableName, workflowTableName))\n\t}\n\tif ok := input.JoinTableEntities[common.Task]; ok {\n\t\ttx = tx.Joins(fmt.Sprintf(\"INNER JOIN %s ON %s.task_id = %s.id\",\n\t\t\ttaskTableName, executionTableName, taskTableName))\n\t}\n\n\t// Apply filters\n\ttx, err = applyScopedFilters(tx, input.InlineFilters, input.MapFilters)\n\tif err != nil {\n\t\treturn 0, err\n\t}\n\n\t// Run the query\n\ttimer := r.metrics.CountDuration.Start()\n\tvar count int64\n\ttx = tx.Count(&count)\n\ttimer.Stop()\n\tif tx.Error != nil {\n\t\treturn 0, r.errorTransformer.ToFlyteAdminError(tx.Error)\n\t}\n\treturn count, nil\n}\n\n// Returns an instance of ExecutionRepoInterface\nfunc NewExecutionRepo(\n\tdb *gorm.DB, errorTransformer adminErrors.ErrorTransformer, scope promutils.Scope) interfaces.ExecutionRepoInterface {\n\tmetrics := newMetrics(scope)\n\treturn &ExecutionRepo{\n\t\tdb:               db,\n\t\terrorTransformer: errorTransformer,\n\t\tmetrics:          metrics,\n\t}\n}\n", "package gormimpl\n\nimport (\n\t\"context\"\n\t\"database/sql/driver\"\n\t\"testing\"\n\t\"time\"\n\n\tmocket \"github.com/Selvatico/go-mocket\"\n\t\"github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/admin\"\n\t\"github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/core\"\n\tmockScope \"github.com/flyteorg/flytestdlib/promutils\"\n\t\"github.com/stretchr/testify/assert\"\n\t\"github.com/stretchr/testify/require\"\n\n\t\"github.com/flyteorg/flyteadmin/pkg/common\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/errors\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/interfaces\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/models\"\n)\n\nvar createdAt = time.Date(2018, time.February, 17, 00, 00, 00, 00, time.UTC).UTC()\nvar executionStartedAt = time.Date(2018, time.February, 17, 00, 01, 00, 00, time.UTC).UTC()\nvar executionUpdatedAt = time.Date(2018, time.February, 17, 00, 01, 00, 00, time.UTC).UTC()\n\nfunc TestCreateExecution(t *testing.T) {\n\texecutionRepo := NewExecutionRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\terr := executionRepo.Create(context.Background(), models.Execution{\n\t\tExecutionKey: models.ExecutionKey{\n\t\t\tProject: \"project\",\n\t\t\tDomain:  \"domain\",\n\t\t\tName:    \"1\",\n\t\t},\n\t\tLaunchPlanID:       uint(2),\n\t\tPhase:              core.WorkflowExecution_SUCCEEDED.String(),\n\t\tClosure:            []byte{1, 2},\n\t\tSpec:               []byte{3, 4},\n\t\tStartedAt:          &executionStartedAt,\n\t\tExecutionCreatedAt: &createdAt,\n\t})\n\tassert.NoError(t, err)\n}\n\nfunc TestUpdateExecution(t *testing.T) {\n\tGlobalMock := mocket.Catcher.Reset()\n\tGlobalMock.Logging = true\n\tupdated := false\n\n\t// Only match on queries that append expected filters\n\tGlobalMock.NewMock().WithQuery(`UPDATE \"executions\" SET \"updated_at\"=$1,\"execution_project\"=$2,` +\n\t\t`\"execution_domain\"=$3,\"execution_name\"=$4,\"launch_plan_id\"=$5,\"workflow_id\"=$6,\"phase\"=$7,\"closure\"=$8,` +\n\t\t`\"spec\"=$9,\"started_at\"=$10,\"execution_created_at\"=$11,\"execution_updated_at\"=$12,\"duration\"=$13 WHERE \"` +\n\t\t`execution_project\" = $14 AND \"execution_domain\" = $15 AND \"execution_name\" = $16`).WithCallback(\n\t\tfunc(s string, values []driver.NamedValue) {\n\t\t\tupdated = true\n\t\t},\n\t)\n\n\texecutionRepo := NewExecutionRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\t//\t`WHERE \"executions\".\"deleted_at\" IS NULL`)\n\terr := executionRepo.Update(context.Background(),\n\t\tmodels.Execution{\n\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\tProject: \"project\",\n\t\t\t\tDomain:  \"domain\",\n\t\t\t\tName:    \"1\",\n\t\t\t},\n\t\t\tLaunchPlanID:       uint(2),\n\t\t\tWorkflowID:         uint(3),\n\t\t\tPhase:              core.WorkflowExecution_SUCCEEDED.String(),\n\t\t\tClosure:            []byte{1, 2},\n\t\t\tSpec:               []byte{3, 4},\n\t\t\tStartedAt:          &executionStartedAt,\n\t\t\tExecutionCreatedAt: &createdAt,\n\t\t\tExecutionUpdatedAt: &executionUpdatedAt,\n\t\t\tDuration:           time.Hour,\n\t\t})\n\tassert.NoError(t, err)\n\tassert.True(t, updated)\n}\n\nfunc getMockExecutionResponseFromDb(expected models.Execution) map[string]interface{} {\n\texecution := make(map[string]interface{})\n\texecution[\"id\"] = expected.ID\n\texecution[\"execution_project\"] = expected.Project\n\texecution[\"execution_domain\"] = expected.Domain\n\texecution[\"execution_name\"] = expected.Name\n\texecution[\"launch_plan_id\"] = expected.LaunchPlanID\n\texecution[\"workflow_id\"] = expected.WorkflowID\n\texecution[\"phase\"] = expected.Phase\n\texecution[\"closure\"] = expected.Closure\n\texecution[\"spec\"] = expected.Spec\n\texecution[\"started_at\"] = expected.StartedAt\n\texecution[\"execution_created_at\"] = expected.ExecutionCreatedAt\n\texecution[\"execution_updated_at\"] = expected.ExecutionUpdatedAt\n\texecution[\"duration\"] = expected.Duration\n\texecution[\"mode\"] = expected.Mode\n\texecution[\"launch_entity\"] = expected.LaunchEntity\n\treturn execution\n}\n\nfunc TestGetExecution(t *testing.T) {\n\texecutionRepo := NewExecutionRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\texpectedExecution := models.Execution{\n\t\tBaseModel: models.BaseModel{\n\t\t\tID: uint(20),\n\t\t},\n\t\tExecutionKey: models.ExecutionKey{\n\t\t\tProject: \"project\",\n\t\t\tDomain:  \"domain\",\n\t\t\tName:    \"1\",\n\t\t},\n\t\tLaunchPlanID:       uint(2),\n\t\tPhase:              core.WorkflowExecution_SUCCEEDED.String(),\n\t\tClosure:            []byte{1, 2},\n\t\tWorkflowID:         uint(3),\n\t\tSpec:               []byte{3, 4},\n\t\tStartedAt:          &executionStartedAt,\n\t\tExecutionCreatedAt: &createdAt,\n\t\tExecutionUpdatedAt: &executionUpdatedAt,\n\t\tLaunchEntity:       \"task\",\n\t}\n\n\texecutions := make([]map[string]interface{}, 0)\n\texecution := getMockExecutionResponseFromDb(expectedExecution)\n\texecutions = append(executions, execution)\n\n\tGlobalMock := mocket.Catcher.Reset()\n\tGlobalMock.Logging = true\n\n\t// Only match on queries that append expected filters\n\tGlobalMock.NewMock().WithQuery(`SELECT * FROM \"executions\" WHERE \"executions\".\"execution_project\" = $1 AND \"executions\".\"execution_domain\" = $2 AND \"executions\".\"execution_name\" = $3 LIMIT 1`).WithReply(executions)\n\n\toutput, err := executionRepo.Get(context.Background(), interfaces.Identifier{\n\t\tProject: \"project\",\n\t\tDomain:  \"domain\",\n\t\tName:    \"1\",\n\t})\n\tassert.NoError(t, err)\n\tassert.EqualValues(t, expectedExecution, output)\n}\n\nfunc TestListExecutions(t *testing.T) {\n\texecutionRepo := NewExecutionRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\n\texecutions := make([]map[string]interface{}, 0)\n\tnames := []string{\"ABC\", \"XYZ\"}\n\tfor _, name := range names {\n\t\texecution := getMockExecutionResponseFromDb(models.Execution{\n\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\tProject: \"project\",\n\t\t\t\tDomain:  \"domain\",\n\t\t\t\tName:    name,\n\t\t\t},\n\t\t\tLaunchPlanID: uint(2),\n\t\t\tWorkflowID:   uint(3),\n\t\t\tPhase:        core.WorkflowExecution_SUCCEEDED.String(),\n\t\t\tClosure:      []byte{1, 2},\n\t\t\tSpec:         []byte{3, 4},\n\t\t\tStartedAt:    &executionStartedAt,\n\t\t\tDuration:     time.Hour,\n\t\t})\n\t\texecutions = append(executions, execution)\n\t}\n\n\tGlobalMock := mocket.Catcher.Reset()\n\tGlobalMock.NewMock().WithReply(executions)\n\n\tcollection, err := executionRepo.List(context.Background(), interfaces.ListResourceInput{\n\t\tInlineFilters: []common.InlineFilter{\n\t\t\tgetEqualityFilter(common.Task, \"project\", project),\n\t\t\tgetEqualityFilter(common.Task, \"domain\", domain),\n\t\t\tgetEqualityFilter(common.Task, \"name\", name),\n\t\t},\n\t\tLimit: 20,\n\t})\n\tassert.NoError(t, err)\n\tassert.NotEmpty(t, collection)\n\tassert.NotEmpty(t, collection.Executions)\n\tassert.Len(t, collection.Executions, 2)\n\tfor _, execution := range collection.Executions {\n\t\tassert.Equal(t, project, execution.Project)\n\t\tassert.Equal(t, domain, execution.Domain)\n\t\tassert.Contains(t, names, execution.Name)\n\t\tassert.Equal(t, uint(2), execution.LaunchPlanID)\n\t\tassert.Equal(t, uint(3), execution.WorkflowID)\n\t\tassert.Equal(t, core.WorkflowExecution_SUCCEEDED.String(), execution.Phase)\n\t\tassert.Equal(t, []byte{1, 2}, execution.Closure)\n\t\tassert.Equal(t, []byte{3, 4}, execution.Spec)\n\t\tassert.Equal(t, executionStartedAt, *execution.StartedAt)\n\t\tassert.Equal(t, time.Hour, execution.Duration)\n\t}\n}\n\nfunc TestListExecutions_Filters(t *testing.T) {\n\texecutionRepo := NewExecutionRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\n\texecutions := make([]map[string]interface{}, 0)\n\texecution := getMockExecutionResponseFromDb(models.Execution{\n\t\tExecutionKey: models.ExecutionKey{\n\t\t\tProject: \"project\",\n\t\t\tDomain:  \"domain\",\n\t\t\tName:    \"1\",\n\t\t},\n\t\tLaunchPlanID: uint(2),\n\t\tWorkflowID:   uint(3),\n\t\tPhase:        core.WorkflowExecution_SUCCEEDED.String(),\n\t\tClosure:      []byte{1, 2},\n\t\tSpec:         []byte{3, 4},\n\t\tStartedAt:    &executionStartedAt,\n\t\tDuration:     time.Hour,\n\t})\n\texecutions = append(executions, execution)\n\n\tGlobalMock := mocket.Catcher.Reset()\n\t// Only match on queries that append the name filter\n\tGlobalMock.NewMock().WithQuery(`SELECT * FROM \"executions\" WHERE executions.execution_project = $1 AND executions.execution_domain = $2 AND executions.execution_name = $3 AND executions.workflow_id = $4 LIMIT 20`).WithReply(executions[0:1])\n\n\tcollection, err := executionRepo.List(context.Background(), interfaces.ListResourceInput{\n\t\tInlineFilters: []common.InlineFilter{\n\t\t\tgetEqualityFilter(common.Execution, \"project\", project),\n\t\t\tgetEqualityFilter(common.Execution, \"domain\", domain),\n\t\t\tgetEqualityFilter(common.Execution, \"name\", \"1\"),\n\t\t\tgetEqualityFilter(common.Execution, \"workflow_id\", workflowID),\n\t\t},\n\t\tLimit: 20,\n\t})\n\tassert.NoError(t, err)\n\tassert.NotEmpty(t, collection)\n\tassert.NotEmpty(t, collection.Executions)\n\tassert.Len(t, collection.Executions, 1)\n\n\tresult := collection.Executions[0]\n\tassert.Equal(t, project, result.Project)\n\tassert.Equal(t, domain, result.Domain)\n\tassert.Equal(t, \"1\", result.Name)\n\tassert.Equal(t, uint(2), result.LaunchPlanID)\n\tassert.Equal(t, uint(3), result.WorkflowID)\n\tassert.Equal(t, core.WorkflowExecution_SUCCEEDED.String(), result.Phase)\n\tassert.Equal(t, []byte{1, 2}, result.Closure)\n\tassert.Equal(t, []byte{3, 4}, result.Spec)\n\tassert.Equal(t, executionStartedAt, *result.StartedAt)\n\tassert.Equal(t, time.Hour, result.Duration)\n}\n\nfunc TestListExecutions_Order(t *testing.T) {\n\texecutionRepo := NewExecutionRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\n\texecutions := make([]map[string]interface{}, 0)\n\tGlobalMock := mocket.Catcher.Reset()\n\t// Only match on queries that include ordering by name\n\tmockQuery := GlobalMock.NewMock().WithQuery(`execution_name asc`)\n\tmockQuery.WithReply(executions)\n\n\tsortParameter, err := common.NewSortParameter(&admin.Sort{\n\t\tDirection: admin.Sort_ASCENDING,\n\t\tKey:       \"execution_name\",\n\t}, models.ExecutionColumns)\n\trequire.NoError(t, err)\n\n\t_, err = executionRepo.List(context.Background(), interfaces.ListResourceInput{\n\t\tSortParameter: sortParameter,\n\t\tInlineFilters: []common.InlineFilter{\n\t\t\tgetEqualityFilter(common.Task, \"project\", project),\n\t\t\tgetEqualityFilter(common.Task, \"domain\", domain),\n\t\t\tgetEqualityFilter(common.Task, \"name\", name),\n\t\t},\n\t\tLimit: 20,\n\t})\n\n\tassert.NoError(t, err)\n\tassert.True(t, mockQuery.Triggered)\n}\n\nfunc TestListExecutions_WithTags(t *testing.T) {\n\texecutionRepo := NewExecutionRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\n\texecutions := make([]map[string]interface{}, 0)\n\tGlobalMock := mocket.Catcher.Reset()\n\t// Only match on queries that include ordering by name\n\tmockQuery := GlobalMock.NewMock().WithQuery(`execution_name asc`)\n\tmockQuery.WithReply(executions)\n\n\tsortParameter, err := common.NewSortParameter(&admin.Sort{\n\t\tDirection: admin.Sort_ASCENDING,\n\t\tKey:       \"execution_name\",\n\t}, models.ExecutionColumns)\n\trequire.NoError(t, err)\n\n\tvals := []string{\"tag1\", \"tag2\"}\n\ttagFilter, err := common.NewRepeatedValueFilter(common.ExecutionAdminTag, common.ValueIn, \"admin_tag_name\", vals)\n\tassert.NoError(t, err)\n\n\t_, err = executionRepo.List(context.Background(), interfaces.ListResourceInput{\n\t\tSortParameter: sortParameter,\n\t\tInlineFilters: []common.InlineFilter{\n\t\t\tgetEqualityFilter(common.Task, \"project\", project),\n\t\t\tgetEqualityFilter(common.Task, \"domain\", domain),\n\t\t\tgetEqualityFilter(common.Task, \"name\", name),\n\t\t\ttagFilter,\n\t\t},\n\t\tLimit: 20,\n\t})\n\tassert.NoError(t, err)\n\tassert.True(t, mockQuery.Triggered)\n}\n\nfunc TestListExecutions_MissingParameters(t *testing.T) {\n\texecutionRepo := NewExecutionRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\t_, err := executionRepo.List(context.Background(), interfaces.ListResourceInput{\n\t\tInlineFilters: []common.InlineFilter{\n\t\t\tgetEqualityFilter(common.Execution, \"project\", project),\n\t\t\tgetEqualityFilter(common.Execution, \"domain\", domain),\n\t\t\tgetEqualityFilter(common.Execution, \"name\", name),\n\t\t\tgetEqualityFilter(common.Execution, \"workflow_id\", workflowID),\n\t\t},\n\t})\n\tassert.EqualError(t, err, \"missing and/or invalid parameters: limit\")\n\n\t_, err = executionRepo.List(context.Background(), interfaces.ListResourceInput{\n\t\tLimit: 20,\n\t})\n\tassert.EqualError(t, err, \"missing and/or invalid parameters: filters\")\n}\n\nfunc TestListExecutionsForWorkflow(t *testing.T) {\n\texecutionRepo := NewExecutionRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\n\texecutions := make([]map[string]interface{}, 0)\n\texecution := getMockExecutionResponseFromDb(models.Execution{\n\t\tExecutionKey: models.ExecutionKey{\n\t\t\tProject: \"project\",\n\t\t\tDomain:  \"domain\",\n\t\t\tName:    \"1\",\n\t\t},\n\t\tLaunchPlanID: uint(2),\n\t\tWorkflowID:   uint(3),\n\t\tPhase:        core.WorkflowExecution_SUCCEEDED.String(),\n\t\tClosure:      []byte{1, 2},\n\t\tSpec:         []byte{3, 4},\n\t\tStartedAt:    &executionStartedAt,\n\t\tDuration:     time.Hour,\n\t\tLaunchEntity: \"launch_plan\",\n\t\tTags:         []models.AdminTag{{Name: \"tag1\"}, {Name: \"tag2\"}},\n\t})\n\texecutions = append(executions, execution)\n\n\tGlobalMock := mocket.Catcher.Reset()\n\tGlobalMock.Logging = true\n\t// Only match on queries that append expected filters\n\tGlobalMock.NewMock().WithQuery(`SELECT \"executions\".\"id\",\"executions\".\"created_at\",\"executions\".\"updated_at\",\"executions\".\"deleted_at\",\"executions\".\"execution_project\",\"executions\".\"execution_domain\",\"executions\".\"execution_name\",\"executions\".\"launch_plan_id\",\"executions\".\"workflow_id\",\"executions\".\"task_id\",\"executions\".\"phase\",\"executions\".\"closure\",\"executions\".\"spec\",\"executions\".\"started_at\",\"executions\".\"execution_created_at\",\"executions\".\"execution_updated_at\",\"executions\".\"duration\",\"executions\".\"abort_cause\",\"executions\".\"mode\",\"executions\".\"source_execution_id\",\"executions\".\"parent_node_execution_id\",\"executions\".\"cluster\",\"executions\".\"inputs_uri\",\"executions\".\"user_inputs_uri\",\"executions\".\"error_kind\",\"executions\".\"error_code\",\"executions\".\"user\",\"executions\".\"state\",\"executions\".\"launch_entity\" FROM \"executions\" INNER JOIN workflows ON executions.workflow_id = workflows.id INNER JOIN tasks ON executions.task_id = tasks.id WHERE executions.execution_project = $1 AND executions.execution_domain = $2 AND executions.execution_name = $3 AND workflows.name = $4 AND tasks.name = $5 AND execution_admin_tags.execution_tag_name in ($6,$7) LIMIT 20`).WithReply(executions)\n\tvals := []string{\"tag1\", \"tag2\"}\n\ttagFilter, err := common.NewRepeatedValueFilter(common.ExecutionAdminTag, common.ValueIn, \"execution_tag_name\", vals)\n\tassert.NoError(t, err)\n\tcollection, err := executionRepo.List(context.Background(), interfaces.ListResourceInput{\n\t\tInlineFilters: []common.InlineFilter{\n\t\t\tgetEqualityFilter(common.Execution, \"project\", project),\n\t\t\tgetEqualityFilter(common.Execution, \"domain\", domain),\n\t\t\tgetEqualityFilter(common.Execution, \"name\", \"1\"),\n\t\t\tgetEqualityFilter(common.Workflow, \"name\", \"workflow_name\"),\n\t\t\tgetEqualityFilter(common.Task, \"name\", \"task_name\"),\n\t\t\ttagFilter,\n\t\t},\n\t\tLimit: 20,\n\t\tJoinTableEntities: map[common.Entity]bool{\n\t\t\tcommon.Workflow: true,\n\t\t\tcommon.Task:     true,\n\t\t},\n\t})\n\n\tassert.NoError(t, err)\n\tassert.NotEmpty(t, collection)\n\tassert.NotEmpty(t, collection.Executions)\n\tassert.Len(t, collection.Executions, 1)\n\tfor _, execution := range collection.Executions {\n\t\tassert.Equal(t, project, execution.Project)\n\t\tassert.Equal(t, domain, execution.Domain)\n\t\tassert.Equal(t, \"1\", execution.Name)\n\t\tassert.Equal(t, uint(2), execution.LaunchPlanID)\n\t\tassert.Equal(t, uint(3), execution.WorkflowID)\n\t\tassert.Equal(t, core.WorkflowExecution_SUCCEEDED.String(), execution.Phase)\n\t\tassert.Equal(t, []byte{1, 2}, execution.Closure)\n\t\tassert.Equal(t, []byte{3, 4}, execution.Spec)\n\t\tassert.Equal(t, executionStartedAt, *execution.StartedAt)\n\t\tassert.Equal(t, time.Hour, execution.Duration)\n\t\tassert.Equal(t, \"launch_plan\", execution.LaunchEntity)\n\t}\n}\n\nfunc TestCountExecutions(t *testing.T) {\n\texecutionRepo := NewExecutionRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\n\tGlobalMock := mocket.Catcher.Reset()\n\tGlobalMock.NewMock().WithQuery(\n\t\t`SELECT count(*) FROM \"executions\"`).WithReply([]map[string]interface{}{{\"rows\": 2}})\n\n\tcount, err := executionRepo.Count(context.Background(), interfaces.CountResourceInput{})\n\tassert.NoError(t, err)\n\tassert.Equal(t, int64(2), count)\n}\n\nfunc TestCountExecutions_Filters(t *testing.T) {\n\texecutionRepo := NewExecutionRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\n\tGlobalMock := mocket.Catcher.Reset()\n\tGlobalMock.NewMock().WithQuery(\n\t\t`SELECT count(*) FROM \"executions\" INNER JOIN workflows ON executions.workflow_id = workflows.id INNER JOIN tasks ON executions.task_id = tasks.id WHERE executions.phase = $1 AND \"error_code\" IS NULL`,\n\t).WithReply([]map[string]interface{}{{\"rows\": 3}})\n\n\tcount, err := executionRepo.Count(context.Background(), interfaces.CountResourceInput{\n\t\tInlineFilters: []common.InlineFilter{\n\t\t\tgetEqualityFilter(common.Execution, \"phase\", core.WorkflowExecution_FAILED.String()),\n\t\t},\n\t\tMapFilters: []common.MapFilter{\n\t\t\tcommon.NewMapFilter(map[string]interface{}{\n\t\t\t\t\"error_code\": nil,\n\t\t\t}),\n\t\t},\n\t\tJoinTableEntities: map[common.Entity]bool{\n\t\t\tcommon.Workflow: true,\n\t\t\tcommon.Task:     true,\n\t\t},\n\t})\n\tassert.NoError(t, err)\n\tassert.Equal(t, int64(3), count)\n}\n", "package gormimpl\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"time\"\n\n\t\"github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/core\"\n\t\"github.com/flyteorg/flytestdlib/promutils\"\n\n\t\"github.com/flyteorg/flytestdlib/logger\"\n\t\"gorm.io/gorm\"\n\n\tadminErrors \"github.com/flyteorg/flyteadmin/pkg/repositories/errors\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/interfaces\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/models\"\n)\n\nconst launchPlanTableName = \"launch_plans\"\n\ntype launchPlanMetrics struct {\n\tSetActiveDuration promutils.StopWatch\n}\n\n// Implementation of LaunchPlanRepoInterface.\ntype LaunchPlanRepo struct {\n\tdb                *gorm.DB\n\terrorTransformer  adminErrors.ErrorTransformer\n\tmetrics           gormMetrics\n\tlaunchPlanMetrics launchPlanMetrics\n}\n\nfunc (r *LaunchPlanRepo) Create(ctx context.Context, input models.LaunchPlan) error {\n\ttimer := r.metrics.CreateDuration.Start()\n\ttx := r.db.Omit(\"id\").Create(&input)\n\ttimer.Stop()\n\tif tx.Error != nil {\n\t\treturn r.errorTransformer.ToFlyteAdminError(tx.Error)\n\t}\n\treturn nil\n}\n\nfunc (r *LaunchPlanRepo) Update(ctx context.Context, input models.LaunchPlan) error {\n\ttimer := r.metrics.UpdateDuration.Start()\n\ttx := r.db.Model(&input).Updates(input)\n\ttimer.Stop()\n\tif err := tx.Error; err != nil {\n\t\treturn r.errorTransformer.ToFlyteAdminError(err)\n\t}\n\treturn nil\n}\n\nfunc (r *LaunchPlanRepo) Get(ctx context.Context, input interfaces.Identifier) (models.LaunchPlan, error) {\n\tvar launchPlan models.LaunchPlan\n\ttimer := r.metrics.GetDuration.Start()\n\ttx := r.db.Where(&models.LaunchPlan{\n\t\tLaunchPlanKey: models.LaunchPlanKey{\n\t\t\tProject: input.Project,\n\t\t\tDomain:  input.Domain,\n\t\t\tName:    input.Name,\n\t\t\tVersion: input.Version,\n\t\t},\n\t}).Take(&launchPlan)\n\ttimer.Stop()\n\n\tif tx.Error != nil && errors.Is(tx.Error, gorm.ErrRecordNotFound) {\n\t\treturn models.LaunchPlan{},\n\t\t\tadminErrors.GetMissingEntityError(core.ResourceType_LAUNCH_PLAN.String(), &core.Identifier{\n\t\t\t\tProject: input.Project,\n\t\t\t\tDomain:  input.Domain,\n\t\t\t\tName:    input.Name,\n\t\t\t\tVersion: input.Version,\n\t\t\t})\n\t} else if tx.Error != nil {\n\t\treturn models.LaunchPlan{}, r.errorTransformer.ToFlyteAdminError(tx.Error)\n\t}\n\treturn launchPlan, nil\n}\n\n// This operation is performed as a two-step transaction because only one launch plan version can be active at a time.\n// Transactional semantics are used to guarantee that setting the desired launch plan to active also disables\n// the existing launch plan version (if any).\nfunc (r *LaunchPlanRepo) SetActive(\n\tctx context.Context, toEnable models.LaunchPlan, toDisable *models.LaunchPlan) error {\n\ttimer := r.launchPlanMetrics.SetActiveDuration.Start()\n\tdefer timer.Stop()\n\t// Use a transaction to guarantee no partial updates.\n\ttx := r.db.Begin()\n\n\t// There is a launch plan to disable as part of this transaction\n\tif toDisable != nil {\n\t\ttx.Model(&toDisable).UpdateColumns(toDisable)\n\t\tif err := tx.Error; err != nil {\n\t\t\ttx.Rollback()\n\t\t\treturn r.errorTransformer.ToFlyteAdminError(err)\n\t\t}\n\t}\n\n\t// And update the desired version.\n\ttx.Model(&toEnable).UpdateColumns(toEnable)\n\tif err := tx.Error; err != nil {\n\t\ttx.Rollback()\n\t\treturn r.errorTransformer.ToFlyteAdminError(err)\n\t}\n\tif err := tx.Commit().Error; err != nil {\n\t\treturn r.errorTransformer.ToFlyteAdminError(err)\n\t}\n\treturn nil\n}\n\nfunc (r *LaunchPlanRepo) List(ctx context.Context, input interfaces.ListResourceInput) (\n\tinterfaces.LaunchPlanCollectionOutput, error) {\n\t// First validate input.\n\tif err := ValidateListInput(input); err != nil {\n\t\treturn interfaces.LaunchPlanCollectionOutput{}, err\n\t}\n\tvar launchPlans []models.LaunchPlan\n\ttx := r.db.Limit(input.Limit).Offset(input.Offset)\n\n\t// Add join conditions\n\ttx = tx.Joins(\"inner join workflows on launch_plans.workflow_id = workflows.id\")\n\n\t// Apply filters\n\ttx, err := applyScopedFilters(tx, input.InlineFilters, input.MapFilters)\n\tif err != nil {\n\t\treturn interfaces.LaunchPlanCollectionOutput{}, err\n\t}\n\t// Apply sort ordering.\n\tif input.SortParameter != nil {\n\t\ttx = tx.Order(input.SortParameter.GetGormOrderExpr())\n\t}\n\n\ttimer := r.metrics.ListDuration.Start()\n\ttx.Find(&launchPlans)\n\ttimer.Stop()\n\tif tx.Error != nil {\n\t\tlogger.Warningf(ctx,\n\t\t\t\"Failed to list launch plans by workflow with input [%+v] with err: %+v\", input, tx.Error)\n\t\treturn interfaces.LaunchPlanCollectionOutput{}, r.errorTransformer.ToFlyteAdminError(tx.Error)\n\t}\n\n\treturn interfaces.LaunchPlanCollectionOutput{\n\t\tLaunchPlans: launchPlans,\n\t}, nil\n}\n\nfunc (r *LaunchPlanRepo) ListLaunchPlanIdentifiers(ctx context.Context, input interfaces.ListResourceInput) (\n\tinterfaces.LaunchPlanCollectionOutput, error) {\n\n\t// Validate input, input must have a limit\n\tif err := ValidateListInput(input); err != nil {\n\t\treturn interfaces.LaunchPlanCollectionOutput{}, err\n\t}\n\n\ttx := r.db.Model(models.LaunchPlan{}).Limit(input.Limit).Offset(input.Offset)\n\n\t// Apply filters\n\ttx, err := applyFilters(tx, input.InlineFilters, input.MapFilters)\n\tif err != nil {\n\t\treturn interfaces.LaunchPlanCollectionOutput{}, err\n\t}\n\t// Apply sort ordering.\n\tif input.SortParameter != nil {\n\t\ttx = tx.Order(input.SortParameter.GetGormOrderExpr())\n\t}\n\n\t// Scan the results into a list of launch plans\n\tvar launchPlans []models.LaunchPlan\n\ttimer := r.metrics.ListIdentifiersDuration.Start()\n\ttx.Select([]string{Project, Domain, Name}).Group(identifierGroupBy).Scan(&launchPlans)\n\ttimer.Stop()\n\tif tx.Error != nil {\n\t\treturn interfaces.LaunchPlanCollectionOutput{}, r.errorTransformer.ToFlyteAdminError(tx.Error)\n\t}\n\n\treturn interfaces.LaunchPlanCollectionOutput{\n\t\tLaunchPlans: launchPlans,\n\t}, nil\n\n}\n\n// Returns an instance of LaunchPlanRepoInterface\nfunc NewLaunchPlanRepo(\n\tdb *gorm.DB, errorTransformer adminErrors.ErrorTransformer, scope promutils.Scope) interfaces.LaunchPlanRepoInterface {\n\tmetrics := newMetrics(scope)\n\tlaunchPlanMetrics := launchPlanMetrics{\n\t\tSetActiveDuration: scope.MustNewStopWatch(\n\t\t\t\"set_active\",\n\t\t\t\"time taken to set a launch plan to active (and disable the currently active version)\", time.Millisecond),\n\t}\n\n\treturn &LaunchPlanRepo{\n\t\tdb:                db,\n\t\terrorTransformer:  errorTransformer,\n\t\tmetrics:           metrics,\n\t\tlaunchPlanMetrics: launchPlanMetrics,\n\t}\n}\n", "package gormimpl\n\nimport (\n\t\"context\"\n\t\"database/sql/driver\"\n\t\"testing\"\n\n\tmocket \"github.com/Selvatico/go-mocket\"\n\t\"github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/admin\"\n\tmockScope \"github.com/flyteorg/flytestdlib/promutils\"\n\t\"github.com/stretchr/testify/assert\"\n\n\t\"github.com/flyteorg/flyteadmin/pkg/common\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/errors\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/interfaces\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/models\"\n)\n\nconst workflowID = uint(1)\n\nvar launchPlanSpec = []byte{1, 2}\nvar launchPlanClosure = []byte{3, 4}\nvar inactive = int32(admin.LaunchPlanState_INACTIVE)\nvar active = int32(admin.LaunchPlanState_ACTIVE)\n\nfunc TestCreateLaunchPlan(t *testing.T) {\n\tlaunchPlanRepo := NewLaunchPlanRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\terr := launchPlanRepo.Create(context.Background(), models.LaunchPlan{\n\t\tLaunchPlanKey: models.LaunchPlanKey{\n\t\t\tProject: project,\n\t\t\tDomain:  domain,\n\t\t\tName:    name,\n\t\t\tVersion: version,\n\t\t},\n\t\tSpec:       launchPlanSpec,\n\t\tWorkflowID: workflowID,\n\t\tClosure:    launchPlanClosure,\n\t\tState:      &inactive,\n\t})\n\tassert.NoError(t, err)\n}\n\nfunc getMockLaunchPlanResponseFromDb(expected models.LaunchPlan) map[string]interface{} {\n\tlaunchPlan := make(map[string]interface{})\n\tlaunchPlan[\"project\"] = expected.Project\n\tlaunchPlan[\"domain\"] = expected.Domain\n\tlaunchPlan[\"name\"] = expected.Name\n\tlaunchPlan[\"version\"] = expected.Version\n\tlaunchPlan[\"spec\"] = expected.Spec\n\tlaunchPlan[\"workflow_id\"] = expected.WorkflowID\n\tlaunchPlan[\"closure\"] = expected.Closure\n\tlaunchPlan[\"state\"] = expected.State\n\treturn launchPlan\n}\n\nfunc TestGetLaunchPlan(t *testing.T) {\n\tlaunchPlanRepo := NewLaunchPlanRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\n\tlaunchPlans := make([]map[string]interface{}, 0)\n\tlaunchPlan := getMockLaunchPlanResponseFromDb(models.LaunchPlan{\n\t\tLaunchPlanKey: models.LaunchPlanKey{\n\t\t\tProject: project,\n\t\t\tDomain:  domain,\n\t\t\tName:    name,\n\t\t\tVersion: version,\n\t\t},\n\t\tSpec:       launchPlanSpec,\n\t\tWorkflowID: workflowID,\n\t\tClosure:    launchPlanClosure,\n\t\tState:      &inactive,\n\t})\n\tlaunchPlans = append(launchPlans, launchPlan)\n\n\tGlobalMock := mocket.Catcher.Reset()\n\tGlobalMock.Logging = true\n\t// Only match on queries that append expected filters\n\tGlobalMock.NewMock().WithQuery(\n\t\t`SELECT * FROM \"launch_plans\" WHERE \"launch_plans\".\"project\" = $1 AND \"launch_plans\".\"domain\" = $2 AND \"launch_plans\".\"name\" = $3 AND \"launch_plans\".\"version\" = $4 LIMIT 1`).WithReply(launchPlans)\n\toutput, err := launchPlanRepo.Get(context.Background(), interfaces.Identifier{\n\t\tProject: project,\n\t\tDomain:  domain,\n\t\tName:    name,\n\t\tVersion: version,\n\t})\n\tassert.NoError(t, err)\n\tassert.Equal(t, project, output.Project)\n\tassert.Equal(t, domain, output.Domain)\n\tassert.Equal(t, name, output.Name)\n\tassert.Equal(t, version, output.Version)\n\tassert.Equal(t, launchPlanSpec, output.Spec)\n}\n\nfunc TestSetInactiveLaunchPlan(t *testing.T) {\n\tlaunchPlanRepo := NewLaunchPlanRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\n\tGlobalMock := mocket.Catcher.Reset()\n\tGlobalMock.Logging = true\n\tmockDb := GlobalMock.NewMock()\n\tupdated := false\n\tmockDb.WithQuery(\n\t\t`UPDATE \"launch_plans\" SET \"id\"=$1,\"updated_at\"=$2,\"project\"=$3,\"domain\"=$4,\"name\"=$5,\"version\"=$6,\"closure\"=$7,\"state\"=$8 WHERE \"project\" = $9 AND \"domain\" = $10 AND \"name\" = $11 AND \"version\" = $12`).WithCallback(\n\t\tfunc(s string, values []driver.NamedValue) {\n\t\t\tupdated = true\n\t\t},\n\t)\n\n\terr := launchPlanRepo.Update(context.Background(), models.LaunchPlan{\n\t\tBaseModel: models.BaseModel{\n\t\t\tID: 1,\n\t\t},\n\t\tLaunchPlanKey: models.LaunchPlanKey{\n\t\t\tProject: project,\n\t\t\tDomain:  domain,\n\t\t\tName:    name,\n\t\t\tVersion: version,\n\t\t},\n\t\tClosure: []byte{5, 6},\n\t\tState:   &inactive,\n\t})\n\tassert.NoError(t, err)\n\tassert.True(t, updated)\n}\n\nfunc TestSetActiveLaunchPlan(t *testing.T) {\n\tlaunchPlanRepo := NewLaunchPlanRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\n\tGlobalMock := mocket.Catcher.Reset()\n\tGlobalMock.Logging = true\n\tmockQuery := GlobalMock.NewMock()\n\tupdated := false\n\tmockQuery.WithQuery(\n\t\t`UPDATE \"launch_plans\" SET \"id\"=$1,\"project\"=$2,\"domain\"=$3,\"name\"=$4,\"version\"=$5,\"closure\"=$6,\"state\"=$7 WHERE \"project\" = $8 AND \"domain\" = $9 AND \"name\" = $10 AND \"version\" = $11`).WithCallback(\n\t\tfunc(s string, values []driver.NamedValue) {\n\t\t\tupdated = true\n\t\t},\n\t)\n\n\terr := launchPlanRepo.SetActive(context.Background(), models.LaunchPlan{\n\t\tBaseModel: models.BaseModel{\n\t\t\tID: 1,\n\t\t},\n\t\tLaunchPlanKey: models.LaunchPlanKey{\n\t\t\tProject: project,\n\t\t\tDomain:  domain,\n\t\t\tName:    name,\n\t\t\tVersion: \"new version\",\n\t\t},\n\t\tClosure: []byte{5, 6},\n\t\tState:   &active,\n\t}, &models.LaunchPlan{\n\t\tBaseModel: models.BaseModel{\n\t\t\tID: 2,\n\t\t},\n\t\tLaunchPlanKey: models.LaunchPlanKey{\n\t\t\tProject: project,\n\t\t\tDomain:  domain,\n\t\t\tName:    name,\n\t\t\tVersion: \"old version\",\n\t\t},\n\t\tClosure: []byte{5, 6},\n\t\tState:   &inactive,\n\t})\n\tassert.NoError(t, err)\n\tassert.True(t, updated)\n}\n\nfunc TestSetActiveLaunchPlan_NoCurrentlyActiveLaunchPlan(t *testing.T) {\n\tlaunchPlanRepo := NewLaunchPlanRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\n\tGlobalMock := mocket.Catcher.Reset()\n\tGlobalMock.Logging = true\n\tmockQuery := GlobalMock.NewMock()\n\tupdated := false\n\tmockQuery.WithQuery(\n\t\t`UPDATE \"launch_plans\" SET \"id\"=$1,\"project\"=$2,\"domain\"=$3,\"name\"=$4,\"version\"=$5,\"closure\"=$6,\"state\"=$7 WHERE \"project\" = $8 AND \"domain\" = $9 AND \"name\" = $10 AND \"version\" = $11`).WithCallback(\n\t\tfunc(s string, values []driver.NamedValue) {\n\t\t\tupdated = true\n\t\t},\n\t)\n\terr := launchPlanRepo.SetActive(context.Background(), models.LaunchPlan{\n\t\tBaseModel: models.BaseModel{\n\t\t\tID: 1,\n\t\t},\n\t\tLaunchPlanKey: models.LaunchPlanKey{\n\t\t\tProject: project,\n\t\t\tDomain:  domain,\n\t\t\tName:    name,\n\t\t\tVersion: \"new version\",\n\t\t},\n\t\tClosure: []byte{5, 6},\n\t\tState:   &active,\n\t}, nil)\n\tassert.NoError(t, err)\n\tassert.True(t, updated)\n}\n\nfunc TestListLaunchPlans(t *testing.T) {\n\tlaunchPlanRepo := NewLaunchPlanRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\n\tlaunchPlans := make([]map[string]interface{}, 0)\n\tversions := []string{\"ABC\", \"XYZ\"}\n\tfor _, version := range versions {\n\t\tlaunchPlan := getMockLaunchPlanResponseFromDb(models.LaunchPlan{\n\t\t\tLaunchPlanKey: models.LaunchPlanKey{\n\t\t\t\tProject: project,\n\t\t\t\tDomain:  domain,\n\t\t\t\tName:    name,\n\t\t\t\tVersion: version,\n\t\t\t},\n\t\t\tSpec:       launchPlanSpec,\n\t\t\tWorkflowID: workflowID,\n\t\t\tClosure:    launchPlanClosure,\n\t\t\tState:      &inactive,\n\t\t})\n\t\tlaunchPlans = append(launchPlans, launchPlan)\n\t}\n\n\tGlobalMock := mocket.Catcher.Reset()\n\tGlobalMock.NewMock().WithReply(launchPlans)\n\n\tcollection, err := launchPlanRepo.List(context.Background(), interfaces.ListResourceInput{\n\t\tInlineFilters: []common.InlineFilter{\n\t\t\tgetEqualityFilter(common.LaunchPlan, \"project\", project),\n\t\t\tgetEqualityFilter(common.LaunchPlan, \"domain\", domain),\n\t\t\tgetEqualityFilter(common.LaunchPlan, \"name\", name),\n\t\t},\n\t\tLimit: 20,\n\t})\n\tassert.NoError(t, err)\n\tassert.NotEmpty(t, collection)\n\tassert.NotEmpty(t, collection.LaunchPlans)\n\tassert.Len(t, collection.LaunchPlans, 2)\n\tfor _, launchPlan := range collection.LaunchPlans {\n\t\tassert.Equal(t, project, launchPlan.Project)\n\t\tassert.Equal(t, domain, launchPlan.Domain)\n\t\tassert.Equal(t, name, launchPlan.Name)\n\t\tassert.Contains(t, versions, launchPlan.Version)\n\t\tassert.Equal(t, launchPlanSpec, launchPlan.Spec)\n\t\tassert.Equal(t, workflowID, launchPlan.WorkflowID)\n\t}\n}\n\nfunc TestListLaunchPlans_Pagination(t *testing.T) {\n\tlaunchPlanRepo := NewLaunchPlanRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\n\tlaunchPlans := make([]map[string]interface{}, 0)\n\tversions := []string{\"ABC\", \"DEF\"}\n\tfor _, version := range versions {\n\t\tlaunchPlan := getMockLaunchPlanResponseFromDb(models.LaunchPlan{\n\t\t\tLaunchPlanKey: models.LaunchPlanKey{\n\t\t\t\tProject: project,\n\t\t\t\tDomain:  domain,\n\t\t\t\tName:    name,\n\t\t\t\tVersion: version,\n\t\t\t},\n\t\t\tSpec:       launchPlanSpec,\n\t\t\tWorkflowID: workflowID,\n\t\t\tClosure:    launchPlanClosure,\n\t\t\tState:      &inactive,\n\t\t})\n\t\tlaunchPlans = append(launchPlans, launchPlan)\n\t}\n\n\tGlobalMock := mocket.Catcher.Reset()\n\n\tGlobalMock.NewMock().WithQuery(\n\t\t`SELECT \"launch_plans\".\"id\",\"launch_plans\".\"created_at\",\"launch_plans\".\"updated_at\",\"launch_plans\".\"deleted_at\",\"launch_plans\".\"project\",\"launch_plans\".\"domain\",\"launch_plans\".\"name\",\"launch_plans\".\"version\",\"launch_plans\".\"spec\",\"launch_plans\".\"workflow_id\",\"launch_plans\".\"closure\",\"launch_plans\".\"state\",\"launch_plans\".\"digest\",\"launch_plans\".\"schedule_type\" FROM \"launch_plans\" inner join workflows on launch_plans.workflow_id = workflows.id WHERE launch_plans.project = $1 AND launch_plans.domain = $2 AND launch_plans.name = $3 LIMIT 2 OFFSET 1`).WithReply(launchPlans)\n\n\tcollection, err := launchPlanRepo.List(context.Background(), interfaces.ListResourceInput{\n\t\tInlineFilters: []common.InlineFilter{\n\t\t\tgetEqualityFilter(common.LaunchPlan, \"project\", project),\n\t\t\tgetEqualityFilter(common.LaunchPlan, \"domain\", domain),\n\t\t\tgetEqualityFilter(common.LaunchPlan, \"name\", name),\n\t\t},\n\t\tLimit:  2,\n\t\tOffset: 1,\n\t})\n\tassert.NoError(t, err)\n\tassert.NotEmpty(t, collection)\n\tassert.NotEmpty(t, collection.LaunchPlans)\n\tassert.Len(t, collection.LaunchPlans, 2)\n\tfor idx, launchPlan := range collection.LaunchPlans {\n\t\tassert.Equal(t, project, launchPlan.Project)\n\t\tassert.Equal(t, domain, launchPlan.Domain)\n\t\tassert.Equal(t, name, launchPlan.Name)\n\t\tassert.Equal(t, versions[idx], launchPlan.Version)\n\t\tassert.Equal(t, launchPlanSpec, launchPlan.Spec)\n\t\tassert.Equal(t, workflowID, launchPlan.WorkflowID)\n\t\tassert.Equal(t, launchPlanClosure, launchPlan.Closure)\n\t}\n}\n\nfunc TestListLaunchPlans_Filters(t *testing.T) {\n\tlaunchPlanRepo := NewLaunchPlanRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\n\tlaunchPlans := make([]map[string]interface{}, 0)\n\tlaunchPlan := getMockLaunchPlanResponseFromDb(models.LaunchPlan{\n\t\tLaunchPlanKey: models.LaunchPlanKey{\n\t\t\tProject: project,\n\t\t\tDomain:  domain,\n\t\t\tName:    name,\n\t\t\tVersion: \"ABC\",\n\t\t},\n\t\tSpec:       launchPlanSpec,\n\t\tWorkflowID: workflowID,\n\t\tClosure:    launchPlanClosure,\n\t\tState:      &inactive,\n\t})\n\tlaunchPlans = append(launchPlans, launchPlan)\n\n\tGlobalMock := mocket.Catcher.Reset()\n\tGlobalMock.Logging = true\n\t// Only match on queries that append the name filter\n\tGlobalMock.NewMock().WithQuery(`SELECT \"launch_plans\".\"id\",\"launch_plans\".\"created_at\",\"launch_plans\".\"updated_at\",\"launch_plans\".\"deleted_at\",\"launch_plans\".\"project\",\"launch_plans\".\"domain\",\"launch_plans\".\"name\",\"launch_plans\".\"version\",\"launch_plans\".\"spec\",\"launch_plans\".\"workflow_id\",\"launch_plans\".\"closure\",\"launch_plans\".\"state\",\"launch_plans\".\"digest\",\"launch_plans\".\"schedule_type\" FROM \"launch_plans\" inner join workflows on launch_plans.workflow_id = workflows.id WHERE launch_plans.project = $1 AND launch_plans.domain = $2 AND launch_plans.name = $3 AND launch_plans.version = $4 LIMIT 20`).WithReply(launchPlans[0:1])\n\n\tcollection, err := launchPlanRepo.List(context.Background(), interfaces.ListResourceInput{\n\t\tInlineFilters: []common.InlineFilter{\n\t\t\tgetEqualityFilter(common.LaunchPlan, \"project\", project),\n\t\t\tgetEqualityFilter(common.LaunchPlan, \"domain\", domain),\n\t\t\tgetEqualityFilter(common.LaunchPlan, \"name\", name),\n\t\t\tgetEqualityFilter(common.LaunchPlan, \"version\", \"ABC\"),\n\t\t},\n\t\tLimit: 20,\n\t})\n\tassert.NoError(t, err)\n\tassert.NotEmpty(t, collection)\n\tassert.NotEmpty(t, collection.LaunchPlans)\n\tassert.Len(t, collection.LaunchPlans, 1)\n\tassert.Equal(t, project, collection.LaunchPlans[0].Project)\n\tassert.Equal(t, domain, collection.LaunchPlans[0].Domain)\n\tassert.Equal(t, name, collection.LaunchPlans[0].Name)\n\tassert.Equal(t, \"ABC\", collection.LaunchPlans[0].Version)\n\tassert.Equal(t, launchPlanSpec, collection.LaunchPlans[0].Spec)\n\tassert.Equal(t, workflowID, collection.LaunchPlans[0].WorkflowID)\n\tassert.Equal(t, launchPlanClosure, collection.LaunchPlans[0].Closure)\n}\n\nfunc TestListLaunchPlans_Order(t *testing.T) {\n\tlaunchPlanRepo := NewLaunchPlanRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\tlaunchPlans := make([]map[string]interface{}, 0)\n\n\tGlobalMock := mocket.Catcher.Reset()\n\t// Only match on queries that include ordering by project\n\tmockQuery := GlobalMock.NewMock()\n\tmockQuery.WithQuery(`project desc`)\n\tmockQuery.WithReply(launchPlans)\n\n\tsortParameter, _ := common.NewSortParameter(&admin.Sort{\n\t\tDirection: admin.Sort_DESCENDING,\n\t\tKey:       \"project\",\n\t}, models.LaunchPlanColumns)\n\t_, err := launchPlanRepo.List(context.Background(), interfaces.ListResourceInput{\n\t\tSortParameter: sortParameter,\n\t\tInlineFilters: []common.InlineFilter{\n\t\t\tgetEqualityFilter(common.LaunchPlan, \"project\", project),\n\t\t\tgetEqualityFilter(common.LaunchPlan, \"domain\", domain),\n\t\t\tgetEqualityFilter(common.LaunchPlan, \"name\", name),\n\t\t\tgetEqualityFilter(common.LaunchPlan, \"version\", version),\n\t\t},\n\t\tLimit: 20,\n\t})\n\tassert.NoError(t, err)\n\tassert.True(t, mockQuery.Triggered)\n}\n\nfunc TestListLaunchPlans_MissingParameters(t *testing.T) {\n\tlaunchPlanRepo := NewLaunchPlanRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\t_, err := launchPlanRepo.List(context.Background(), interfaces.ListResourceInput{\n\t\tInlineFilters: []common.InlineFilter{\n\t\t\tgetEqualityFilter(common.LaunchPlan, \"project\", project),\n\t\t\tgetEqualityFilter(common.LaunchPlan, \"domain\", domain),\n\t\t\tgetEqualityFilter(common.LaunchPlan, \"name\", name),\n\t\t\tgetEqualityFilter(common.LaunchPlan, \"version\", version),\n\t\t},\n\t})\n\tassert.EqualError(t, err, \"missing and/or invalid parameters: limit\")\n\n\t_, err = launchPlanRepo.List(context.Background(), interfaces.ListResourceInput{\n\t\tLimit: 20,\n\t})\n\tassert.EqualError(t, err, \"missing and/or invalid parameters: filters\")\n}\n\nfunc TestListLaunchPlansForWorkflow(t *testing.T) {\n\tlaunchPlanRepo := NewLaunchPlanRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\n\tlaunchPlans := make([]map[string]interface{}, 0)\n\tlaunchPlan := getMockLaunchPlanResponseFromDb(models.LaunchPlan{\n\t\tLaunchPlanKey: models.LaunchPlanKey{\n\t\t\tProject: project,\n\t\t\tDomain:  domain,\n\t\t\tName:    name,\n\t\t\tVersion: version,\n\t\t},\n\t\tSpec:       launchPlanSpec,\n\t\tWorkflowID: workflowID,\n\t\tClosure:    launchPlanClosure,\n\t\tState:      &inactive,\n\t})\n\tlaunchPlans = append(launchPlans, launchPlan)\n\n\tGlobalMock := mocket.Catcher.Reset()\n\t// HACK: gorm orders the filters on join clauses non-deterministically. Ordering of filters doesn't affect\n\t// correctness, but because the mocket library only pattern matches on substrings, both variations of the (valid)\n\t// SQL that gorm produces are checked below.\n\tquery := `SELECT \"launch_plans\".\"id\",\"launch_plans\".\"created_at\",\"launch_plans\".\"updated_at\",\"launch_plans\".\"deleted_at\",\"launch_plans\".\"project\",\"launch_plans\".\"domain\",\"launch_plans\".\"name\",\"launch_plans\".\"version\",\"launch_plans\".\"spec\",\"launch_plans\".\"workflow_id\",\"launch_plans\".\"closure\",\"launch_plans\".\"state\",\"launch_plans\".\"digest\",\"launch_plans\".\"schedule_type\" FROM \"launch_plans\" inner join workflows on launch_plans.workflow_id = workflows.id WHERE launch_plans.project = $1 AND launch_plans.domain = $2 AND launch_plans.name = $3 AND workflows.deleted_at = $4 LIMIT 20`\n\talternateQuery := `SELECT \"launch_plans\".\"id\",\"launch_plans\".\"created_at\",\"launch_plans\".\"updated_at\",\"launch_plans\".\"deleted_at\",\"launch_plans\".\"project\",\"launch_plans\".\"domain\",\"launch_plans\".\"name\",\"launch_plans\".\"version\",\"launch_plans\".\"spec\",\"launch_plans\".\"workflow_id\",\"launch_plans\".\"closure\",\"launch_plans\".\"state\",\"launch_plans\".\"digest\",\"launch_plans\".\"schedule_type\" FROM \"launch_plans\" inner join workflows on launch_plans.workflow_id = workflows.id WHERE launch_plans.project = $1 AND launch_plans.domain = $2 AND launch_plans.name = $3 AND workflows.deleted_at = $4 LIMIT 20`\n\tGlobalMock.NewMock().WithQuery(query).WithReply(launchPlans)\n\tGlobalMock.NewMock().WithQuery(alternateQuery).WithReply(launchPlans)\n\n\tcollection, err := launchPlanRepo.List(context.Background(), interfaces.ListResourceInput{\n\t\tInlineFilters: []common.InlineFilter{\n\t\t\tgetEqualityFilter(common.LaunchPlan, \"project\", project),\n\t\t\tgetEqualityFilter(common.LaunchPlan, \"domain\", domain),\n\t\t\tgetEqualityFilter(common.LaunchPlan, \"name\", name),\n\t\t\tgetEqualityFilter(common.Workflow, \"deleted_at\", \"foo\"),\n\t\t},\n\t\tLimit: 20,\n\t})\n\tassert.NoError(t, err)\n\tassert.NotEmpty(t, collection)\n\tassert.NotEmpty(t, collection.LaunchPlans)\n\tassert.Len(t, collection.LaunchPlans, 1)\n\tfor _, launchPlan := range collection.LaunchPlans {\n\t\tassert.Equal(t, project, launchPlan.Project)\n\t\tassert.Equal(t, domain, launchPlan.Domain)\n\t\tassert.Equal(t, name, launchPlan.Name)\n\t\tassert.Contains(t, version, launchPlan.Version)\n\t\tassert.Equal(t, launchPlanSpec, launchPlan.Spec)\n\t\tassert.Equal(t, workflowID, launchPlan.WorkflowID)\n\t\tassert.Equal(t, launchPlanClosure, launchPlan.Closure)\n\t}\n}\n\nfunc TestListLaunchPlanIds(t *testing.T) {\n\tlaunchPlanRepo := NewLaunchPlanRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\n\tlaunchPlans := make([]map[string]interface{}, 0)\n\tversions := []string{\"ABC\", \"XYZ\"}\n\tfor _, version := range versions {\n\t\tlaunchPlan := getMockLaunchPlanResponseFromDb(models.LaunchPlan{\n\t\t\tLaunchPlanKey: models.LaunchPlanKey{\n\t\t\t\tProject: project,\n\t\t\t\tDomain:  domain,\n\t\t\t\tName:    name,\n\t\t\t\tVersion: version,\n\t\t\t},\n\t\t\tSpec:       launchPlanSpec,\n\t\t\tWorkflowID: workflowID,\n\t\t\tClosure:    launchPlanClosure,\n\t\t\tState:      &inactive,\n\t\t})\n\t\tlaunchPlans = append(launchPlans, launchPlan)\n\t\tlaunchPlan = getMockLaunchPlanResponseFromDb(models.LaunchPlan{\n\t\t\tLaunchPlanKey: models.LaunchPlanKey{\n\t\t\t\tProject: project,\n\t\t\t\tDomain:  domain,\n\t\t\t\tName:    \"app.workflows.MyWorkflow\",\n\t\t\t\tVersion: version,\n\t\t\t},\n\t\t\tSpec:       launchPlanSpec,\n\t\t\tWorkflowID: uint(2),\n\t\t\tClosure:    launchPlanClosure,\n\t\t\tState:      &inactive,\n\t\t})\n\t\tlaunchPlans = append(launchPlans, launchPlan)\n\t}\n\n\tGlobalMock := mocket.Catcher.Reset()\n\tGlobalMock.NewMock().WithReply(launchPlans)\n\n\tcollection, err := launchPlanRepo.ListLaunchPlanIdentifiers(context.Background(), interfaces.ListResourceInput{\n\t\tInlineFilters: []common.InlineFilter{\n\t\t\tgetEqualityFilter(common.LaunchPlan, \"project\", project),\n\t\t\tgetEqualityFilter(common.LaunchPlan, \"domain\", domain),\n\t\t\tgetEqualityFilter(common.LaunchPlan, \"name\", name),\n\t\t},\n\t\tLimit: 20,\n\t})\n\tassert.NoError(t, err)\n\tassert.NotEmpty(t, collection)\n\tassert.NotEmpty(t, collection.LaunchPlans)\n\tassert.Len(t, collection.LaunchPlans, 4)\n\tfor _, launchPlan := range collection.LaunchPlans {\n\t\tassert.Equal(t, project, launchPlan.Project)\n\t\tassert.Equal(t, domain, launchPlan.Domain)\n\t\tassert.True(t, launchPlan.Name == name || launchPlan.Name == \"app.workflows.MyWorkflow\")\n\t\tassert.Contains(t, versions, launchPlan.Version)\n\t\tassert.Equal(t, launchPlanSpec, launchPlan.Spec)\n\t\tassert.True(t, launchPlan.WorkflowID == workflowID || launchPlan.WorkflowID == uint(2))\n\t}\n}\n", "package gormimpl\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\n\t\"github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/core\"\n\t\"github.com/flyteorg/flytestdlib/promutils\"\n\t\"google.golang.org/grpc/codes\"\n\t\"gorm.io/gorm\"\n\n\t\"github.com/flyteorg/flyteadmin/pkg/common\"\n\tadminErrors \"github.com/flyteorg/flyteadmin/pkg/errors\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/errors\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/interfaces\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/models\"\n)\n\nconst innerJoinTableAlias = \"entities\"\n\nvar resourceTypeToTableName = map[core.ResourceType]string{\n\tcore.ResourceType_LAUNCH_PLAN: launchPlanTableName,\n\tcore.ResourceType_WORKFLOW:    workflowTableName,\n\tcore.ResourceType_TASK:        taskTableName,\n}\n\nvar joinString = \"RIGHT JOIN (?) AS entities ON named_entity_metadata.resource_type = %d AND \" +\n\t\"named_entity_metadata.project = entities.project AND named_entity_metadata.domain = entities.domain AND \" +\n\t\"named_entity_metadata.name = entities.name\"\n\nfunc getSubQueryJoin(db *gorm.DB, tableName string, input interfaces.ListNamedEntityInput) *gorm.DB {\n\ttx := db.Select([]string{Project, Domain, Name}).\n\t\tTable(tableName).\n\t\tWhere(map[string]interface{}{Project: input.Project, Domain: input.Domain}).\n\t\tLimit(input.Limit).\n\t\tOffset(input.Offset).\n\t\tGroup(identifierGroupBy)\n\n\t// Apply consistent sort ordering.\n\tif input.SortParameter != nil {\n\t\ttx = tx.Order(input.SortParameter.GetGormOrderExpr())\n\t}\n\n\treturn db.Joins(fmt.Sprintf(joinString, input.ResourceType), tx)\n}\n\nvar leftJoinWorkflowNameToMetadata = fmt.Sprintf(\n\t\"LEFT JOIN %s ON %s.resource_type = %d AND %s.project = %s.project AND %s.domain = %s.domain AND %s.name = %s.name\", namedEntityMetadataTableName, namedEntityMetadataTableName, core.ResourceType_WORKFLOW, namedEntityMetadataTableName, workflowTableName,\n\tnamedEntityMetadataTableName, workflowTableName,\n\tnamedEntityMetadataTableName, workflowTableName)\n\nvar leftJoinLaunchPlanNameToMetadata = fmt.Sprintf(\n\t\"LEFT JOIN %s ON %s.resource_type = %d AND %s.project = %s.project AND %s.domain = %s.domain AND %s.name = %s.name\", namedEntityMetadataTableName, namedEntityMetadataTableName, core.ResourceType_LAUNCH_PLAN, namedEntityMetadataTableName, launchPlanTableName,\n\tnamedEntityMetadataTableName, launchPlanTableName,\n\tnamedEntityMetadataTableName, launchPlanTableName)\n\nvar leftJoinTaskNameToMetadata = fmt.Sprintf(\n\t\"LEFT JOIN %s ON %s.resource_type = %d AND %s.project = %s.project AND %s.domain = %s.domain AND %s.name = %s.name\", namedEntityMetadataTableName, namedEntityMetadataTableName, core.ResourceType_TASK, namedEntityMetadataTableName, taskTableName,\n\tnamedEntityMetadataTableName, taskTableName,\n\tnamedEntityMetadataTableName, taskTableName)\n\nvar resourceTypeToMetadataJoin = map[core.ResourceType]string{\n\tcore.ResourceType_LAUNCH_PLAN: leftJoinLaunchPlanNameToMetadata,\n\tcore.ResourceType_WORKFLOW:    leftJoinWorkflowNameToMetadata,\n\tcore.ResourceType_TASK:        leftJoinTaskNameToMetadata,\n}\n\nvar getGroupByForNamedEntity = fmt.Sprintf(\"%s.%s, %s.%s, %s.%s, %s.%s, %s.%s\",\n\tinnerJoinTableAlias, Project, innerJoinTableAlias, Domain, innerJoinTableAlias, Name, namedEntityMetadataTableName,\n\tDescription,\n\tnamedEntityMetadataTableName, State)\n\nfunc getSelectForNamedEntity(tableName string, resourceType core.ResourceType) []string {\n\treturn []string{\n\t\tfmt.Sprintf(\"%s.%s\", tableName, Project),\n\t\tfmt.Sprintf(\"%s.%s\", tableName, Domain),\n\t\tfmt.Sprintf(\"%s.%s\", tableName, Name),\n\t\tfmt.Sprintf(\"'%d' AS %s\", resourceType, ResourceType),\n\t\tfmt.Sprintf(\"%s.%s\", namedEntityMetadataTableName, Description),\n\t\tfmt.Sprintf(\"%s.%s\", namedEntityMetadataTableName, State),\n\t}\n}\n\nfunc getNamedEntityFilters(resourceType core.ResourceType, project string, domain string, name string) ([]common.InlineFilter, error) {\n\tentity := common.ResourceTypeToEntity[resourceType]\n\n\tfilters := make([]common.InlineFilter, 0)\n\tprojectFilter, err := common.NewSingleValueFilter(entity, common.Equal, Project, project)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tfilters = append(filters, projectFilter)\n\tdomainFilter, err := common.NewSingleValueFilter(entity, common.Equal, Domain, domain)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tfilters = append(filters, domainFilter)\n\tnameFilter, err := common.NewSingleValueFilter(entity, common.Equal, Name, name)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tfilters = append(filters, nameFilter)\n\n\treturn filters, nil\n}\n\n// Implementation of NamedEntityRepoInterface.\ntype NamedEntityRepo struct {\n\tdb               *gorm.DB\n\terrorTransformer errors.ErrorTransformer\n\tmetrics          gormMetrics\n}\n\nfunc (r *NamedEntityRepo) Update(ctx context.Context, input models.NamedEntity) error {\n\ttimer := r.metrics.UpdateDuration.Start()\n\tvar metadata models.NamedEntityMetadata\n\ttx := r.db.Where(&models.NamedEntityMetadata{\n\t\tNamedEntityMetadataKey: models.NamedEntityMetadataKey{\n\t\t\tResourceType: input.ResourceType,\n\t\t\tProject:      input.Project,\n\t\t\tDomain:       input.Domain,\n\t\t\tName:         input.Name,\n\t\t},\n\t}).Assign(input.NamedEntityMetadataFields).Omit(\"id\").FirstOrCreate(&metadata)\n\ttimer.Stop()\n\tif tx.Error != nil {\n\t\treturn r.errorTransformer.ToFlyteAdminError(tx.Error)\n\t}\n\treturn nil\n}\n\nfunc (r *NamedEntityRepo) Get(ctx context.Context, input interfaces.GetNamedEntityInput) (models.NamedEntity, error) {\n\tvar namedEntity models.NamedEntity\n\n\tfilters, err := getNamedEntityFilters(input.ResourceType, input.Project, input.Domain, input.Name)\n\tif err != nil {\n\t\treturn models.NamedEntity{}, err\n\t}\n\n\ttableName, tableFound := resourceTypeToTableName[input.ResourceType]\n\tjoinString, joinFound := resourceTypeToMetadataJoin[input.ResourceType]\n\tif !tableFound || !joinFound {\n\t\treturn models.NamedEntity{}, adminErrors.NewFlyteAdminErrorf(codes.InvalidArgument, \"Cannot get NamedEntityMetadata for resource type: %v\", input.ResourceType)\n\t}\n\n\ttx := r.db.Table(tableName).Joins(joinString)\n\n\t// Apply filters\n\ttx, err = applyScopedFilters(tx, filters, nil)\n\tif err != nil {\n\t\treturn models.NamedEntity{}, err\n\t}\n\n\ttimer := r.metrics.GetDuration.Start()\n\ttx = tx.Select(getSelectForNamedEntity(tableName, input.ResourceType)).Take(&namedEntity)\n\ttimer.Stop()\n\n\tif tx.Error != nil {\n\t\treturn models.NamedEntity{}, r.errorTransformer.ToFlyteAdminError(tx.Error)\n\t}\n\n\treturn namedEntity, nil\n}\n\nfunc (r *NamedEntityRepo) List(ctx context.Context, input interfaces.ListNamedEntityInput) (\n\tinterfaces.NamedEntityCollectionOutput, error) {\n\n\t// Validate input. Filters aren't required because they're implicit in the Project & Domain specified by the input.\n\tif len(input.Project) == 0 {\n\t\treturn interfaces.NamedEntityCollectionOutput{}, errors.GetInvalidInputError(Project)\n\t}\n\tif len(input.Domain) == 0 {\n\t\treturn interfaces.NamedEntityCollectionOutput{}, errors.GetInvalidInputError(Domain)\n\t}\n\tif input.Limit == 0 {\n\t\treturn interfaces.NamedEntityCollectionOutput{}, errors.GetInvalidInputError(limit)\n\t}\n\n\ttableName, tableFound := resourceTypeToTableName[input.ResourceType]\n\tif !tableFound {\n\t\treturn interfaces.NamedEntityCollectionOutput{}, adminErrors.NewFlyteAdminErrorf(codes.InvalidArgument,\n\t\t\t\"Cannot list entity names for resource type: %v\", input.ResourceType)\n\t}\n\n\ttx := getSubQueryJoin(r.db, tableName, input)\n\n\t// Apply filters\n\ttx, err := applyScopedFilters(tx, input.InlineFilters, input.MapFilters)\n\tif err != nil {\n\t\treturn interfaces.NamedEntityCollectionOutput{}, err\n\t}\n\t// Apply sort ordering.\n\tif input.SortParameter != nil {\n\t\ttx = tx.Order(input.SortParameter.GetGormOrderExpr())\n\t}\n\n\t// Scan the results into a list of named entities\n\tvar entities []models.NamedEntity\n\ttimer := r.metrics.ListDuration.Start()\n\n\ttx.Select(getSelectForNamedEntity(innerJoinTableAlias, input.ResourceType)).Table(namedEntityMetadataTableName).Group(getGroupByForNamedEntity).Scan(&entities)\n\n\ttimer.Stop()\n\n\tif tx.Error != nil {\n\t\treturn interfaces.NamedEntityCollectionOutput{}, r.errorTransformer.ToFlyteAdminError(tx.Error)\n\t}\n\n\treturn interfaces.NamedEntityCollectionOutput{\n\t\tEntities: entities,\n\t}, nil\n}\n\n// Returns an instance of NamedEntityRepoInterface\nfunc NewNamedEntityRepo(\n\tdb *gorm.DB, errorTransformer errors.ErrorTransformer, scope promutils.Scope) interfaces.NamedEntityRepoInterface {\n\tmetrics := newMetrics(scope)\n\n\treturn &NamedEntityRepo{\n\t\tdb:               db,\n\t\terrorTransformer: errorTransformer,\n\t\tmetrics:          metrics,\n\t}\n}\n", "package gormimpl\n\nimport (\n\t\"context\"\n\t\"testing\"\n\n\t\"github.com/flyteorg/flyteadmin/pkg/common\"\n\n\t\"github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/admin\"\n\n\tmocket \"github.com/Selvatico/go-mocket\"\n\tmockScope \"github.com/flyteorg/flytestdlib/promutils\"\n\t\"github.com/stretchr/testify/assert\"\n\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/errors\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/interfaces\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/models\"\n)\n\nfunc getMockNamedEntityResponseFromDb(expected models.NamedEntity) map[string]interface{} {\n\tmetadata := make(map[string]interface{})\n\tmetadata[\"resource_type\"] = expected.ResourceType\n\tmetadata[\"project\"] = expected.Project\n\tmetadata[\"domain\"] = expected.Domain\n\tmetadata[\"name\"] = expected.Name\n\tmetadata[\"description\"] = expected.Description\n\tmetadata[\"state\"] = expected.State\n\treturn metadata\n}\n\nfunc TestGetNamedEntity(t *testing.T) {\n\tmetadataRepo := NewNamedEntityRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\n\tresults := make([]map[string]interface{}, 0)\n\tmetadata := getMockNamedEntityResponseFromDb(models.NamedEntity{\n\t\tNamedEntityKey: models.NamedEntityKey{\n\t\t\tResourceType: resourceType,\n\t\t\tProject:      project,\n\t\t\tDomain:       domain,\n\t\t\tName:         name,\n\t\t},\n\t\tNamedEntityMetadataFields: models.NamedEntityMetadataFields{\n\t\t\tDescription: description,\n\t\t},\n\t})\n\tresults = append(results, metadata)\n\n\tGlobalMock := mocket.Catcher.Reset()\n\tGlobalMock.Logging = true\n\tGlobalMock.NewMock().WithQuery(\n\t\t`SELECT workflows.project,workflows.domain,workflows.name,'2' AS resource_type,named_entity_metadata.description,named_entity_metadata.state FROM \"workflows\" LEFT JOIN named_entity_metadata ON named_entity_metadata.resource_type = 2 AND named_entity_metadata.project = workflows.project AND named_entity_metadata.domain = workflows.domain AND named_entity_metadata.name = workflows.name WHERE workflows.project = $1 AND workflows.domain = $2 AND workflows.name = $3 LIMIT 1`).WithReply(results)\n\toutput, err := metadataRepo.Get(context.Background(), interfaces.GetNamedEntityInput{\n\t\tResourceType: resourceType,\n\t\tProject:      project,\n\t\tDomain:       domain,\n\t\tName:         name,\n\t})\n\tassert.NoError(t, err)\n\tassert.Equal(t, project, output.Project)\n\tassert.Equal(t, domain, output.Domain)\n\tassert.Equal(t, name, output.Name)\n\tassert.Equal(t, resourceType, output.ResourceType)\n\tassert.Equal(t, description, output.Description)\n}\n\nfunc TestUpdateNamedEntity_WithExisting(t *testing.T) {\n\tmetadataRepo := NewNamedEntityRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\tconst updatedDescription = \"updated description\"\n\n\tresults := make([]map[string]interface{}, 0)\n\tactiveState := int32(admin.NamedEntityState_NAMED_ENTITY_ACTIVE)\n\tmetadata := getMockNamedEntityResponseFromDb(models.NamedEntity{\n\t\tNamedEntityKey: models.NamedEntityKey{\n\t\t\tResourceType: resourceType,\n\t\t\tProject:      project,\n\t\t\tDomain:       domain,\n\t\t\tName:         name,\n\t\t},\n\t\tNamedEntityMetadataFields: models.NamedEntityMetadataFields{\n\t\t\tDescription: description,\n\t\t\tState:       &activeState,\n\t\t},\n\t})\n\tresults = append(results, metadata)\n\n\tGlobalMock := mocket.Catcher.Reset()\n\tGlobalMock.Logging = true\n\tGlobalMock.NewMock().WithQuery(\n\t\t`SELECT \"named_entity_metadata\".\"created_at\",\"named_entity_metadata\".\"updated_at\",\"named_entity_metadata\".\"deleted_at\",\"named_entity_metadata\".\"resource_type\",\"named_entity_metadata\".\"project\",\"named_entity_metadata\".\"domain\",\"named_entity_metadata\".\"name\",\"named_entity_metadata\".\"description\",\"named_entity_metadata\".\"state\" FROM \"named_entity_metadata\" WHERE \"named_entity_metadata\".\"resource_type\" = $1 AND \"named_entity_metadata\".\"project\" = $2 AND \"named_entity_metadata\".\"domain\" = $3 AND \"named_entity_metadata\".\"name\" = $4 ORDER BY \"named_entity_metadata\".\"id\" LIMIT 1`).WithReply(results)\n\n\tmockQuery := GlobalMock.NewMock()\n\tmockQuery.WithQuery(\n\t\t`UPDATE \"named_entity_metadata\" SET \"description\"=$1,\"state\"=$2,\"updated_at\"=$3 WHERE \"named_entity_metadata\".\"resource_type\" = $4 AND \"named_entity_metadata\".\"project\" = $5 AND \"named_entity_metadata\".\"domain\" = $6 AND \"named_entity_metadata\".\"name\" = $7 AND \"resource_type\" = $8 AND \"project\" = $9 AND \"domain\" = $10 AND \"name\" = $11`)\n\n\terr := metadataRepo.Update(context.Background(), models.NamedEntity{\n\t\tNamedEntityKey: models.NamedEntityKey{\n\t\t\tResourceType: resourceType,\n\t\t\tProject:      project,\n\t\t\tDomain:       domain,\n\t\t\tName:         name,\n\t\t},\n\t\tNamedEntityMetadataFields: models.NamedEntityMetadataFields{\n\t\t\tDescription: updatedDescription,\n\t\t\tState:       &activeState,\n\t\t},\n\t})\n\tassert.NoError(t, err)\n\tassert.True(t, mockQuery.Triggered)\n}\n\nfunc TestUpdateNamedEntity_CreateNew(t *testing.T) {\n\tmetadataRepo := NewNamedEntityRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\tconst updatedDescription = \"updated description\"\n\n\tGlobalMock := mocket.Catcher.Reset()\n\tGlobalMock.Logging = true\n\n\tmockQuery := GlobalMock.NewMock()\n\tmockQuery.WithQuery(\n\t\t`INSERT INTO \"named_entity_metadata\" (\"created_at\",\"updated_at\",\"deleted_at\",\"resource_type\",\"project\",\"domain\",\"name\",\"description\",\"state\") VALUES ($1,$2,$3,$4,$5,$6,$7,$8,$9)`)\n\n\terr := metadataRepo.Update(context.Background(), models.NamedEntity{\n\t\tNamedEntityKey: models.NamedEntityKey{\n\t\t\tResourceType: resourceType,\n\t\t\tProject:      project,\n\t\t\tDomain:       domain,\n\t\t\tName:         name,\n\t\t},\n\t\tNamedEntityMetadataFields: models.NamedEntityMetadataFields{\n\t\t\tDescription: updatedDescription,\n\t\t},\n\t})\n\tassert.NoError(t, err)\n\tassert.True(t, mockQuery.Triggered)\n}\n\nfunc TestListNamedEntity(t *testing.T) {\n\tmetadataRepo := NewNamedEntityRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\n\tresults := make([]map[string]interface{}, 0)\n\tmetadata := getMockNamedEntityResponseFromDb(models.NamedEntity{\n\t\tNamedEntityKey: models.NamedEntityKey{\n\t\t\tResourceType: resourceType,\n\t\t\tProject:      project,\n\t\t\tDomain:       domain,\n\t\t\tName:         name,\n\t\t},\n\t\tNamedEntityMetadataFields: models.NamedEntityMetadataFields{\n\t\t\tDescription: description,\n\t\t},\n\t})\n\tresults = append(results, metadata)\n\n\tGlobalMock := mocket.Catcher.Reset()\n\tGlobalMock.Logging = true\n\tmockQuery := GlobalMock.NewMock()\n\n\tmockQuery.WithQuery(\n\t\t`SELECT entities.project,entities.domain,entities.name,'2' AS resource_type,named_entity_metadata.description,named_entity_metadata.state FROM \"named_entity_metadata\" RIGHT JOIN (SELECT project,domain,name FROM \"workflows\" WHERE \"domain\" = $1 AND \"project\" = $2 GROUP BY project, domain, name ORDER BY name desc LIMIT 20) AS entities ON named_entity_metadata.resource_type = 2 AND named_entity_metadata.project = entities.project AND named_entity_metadata.domain = entities.domain AND named_entity_metadata.name = entities.name GROUP BY entities.project, entities.domain, entities.name, named_entity_metadata.description, named_entity_metadata.state ORDER BY name desc`).WithReply(results)\n\n\tsortParameter, _ := common.NewSortParameter(&admin.Sort{\n\t\tDirection: admin.Sort_DESCENDING,\n\t\tKey:       \"name\",\n\t}, models.NamedEntityColumns)\n\toutput, err := metadataRepo.List(context.Background(), interfaces.ListNamedEntityInput{\n\t\tResourceType: resourceType,\n\t\tProject:      \"admintests\",\n\t\tDomain:       \"development\",\n\t\tListResourceInput: interfaces.ListResourceInput{\n\t\t\tLimit:         20,\n\t\t\tSortParameter: sortParameter,\n\t\t},\n\t})\n\tassert.NoError(t, err)\n\tassert.Len(t, output.Entities, 1)\n}\n", "package gormimpl\n\nimport (\n\t\"context\"\n\n\t\"github.com/flyteorg/flytestdlib/promutils\"\n\t\"gorm.io/gorm\"\n\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/errors\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/interfaces\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/models\"\n)\n\ntype NodeExecutionEventRepo struct {\n\tdb               *gorm.DB\n\terrorTransformer errors.ErrorTransformer\n\tmetrics          gormMetrics\n}\n\nfunc (r *NodeExecutionEventRepo) Create(ctx context.Context, input models.NodeExecutionEvent) error {\n\ttimer := r.metrics.CreateDuration.Start()\n\ttx := r.db.Omit(\"id\").Create(&input)\n\ttimer.Stop()\n\tif tx.Error != nil {\n\t\treturn r.errorTransformer.ToFlyteAdminError(tx.Error)\n\t}\n\treturn nil\n}\n\n// Returns an instance of NodeExecutionRepoInterface\nfunc NewNodeExecutionEventRepo(\n\tdb *gorm.DB, errorTransformer errors.ErrorTransformer, scope promutils.Scope) interfaces.NodeExecutionEventRepoInterface {\n\tmetrics := newMetrics(scope)\n\treturn &NodeExecutionEventRepo{\n\t\tdb:               db,\n\t\terrorTransformer: errorTransformer,\n\t\tmetrics:          metrics,\n\t}\n}\n", "package gormimpl\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"fmt\"\n\n\t\"github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/core\"\n\t\"github.com/flyteorg/flytestdlib/promutils\"\n\t\"gorm.io/gorm\"\n\n\tadminErrors \"github.com/flyteorg/flyteadmin/pkg/repositories/errors\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/interfaces\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/models\"\n)\n\n// Implementation of NodeExecutionInterface.\ntype NodeExecutionRepo struct {\n\tdb               *gorm.DB\n\terrorTransformer adminErrors.ErrorTransformer\n\tmetrics          gormMetrics\n}\n\nfunc (r *NodeExecutionRepo) Create(ctx context.Context, execution *models.NodeExecution) error {\n\ttimer := r.metrics.CreateDuration.Start()\n\ttx := r.db.Omit(\"id\").Create(&execution)\n\ttimer.Stop()\n\tif tx.Error != nil {\n\t\treturn r.errorTransformer.ToFlyteAdminError(tx.Error)\n\t}\n\treturn nil\n}\n\nfunc (r *NodeExecutionRepo) Get(ctx context.Context, input interfaces.NodeExecutionResource) (models.NodeExecution, error) {\n\tvar nodeExecution models.NodeExecution\n\ttimer := r.metrics.GetDuration.Start()\n\ttx := r.db.Where(&models.NodeExecution{\n\t\tNodeExecutionKey: models.NodeExecutionKey{\n\t\t\tNodeID: input.NodeExecutionIdentifier.NodeId,\n\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\tProject: input.NodeExecutionIdentifier.ExecutionId.Project,\n\t\t\t\tDomain:  input.NodeExecutionIdentifier.ExecutionId.Domain,\n\t\t\t\tName:    input.NodeExecutionIdentifier.ExecutionId.Name,\n\t\t\t},\n\t\t},\n\t}).Take(&nodeExecution)\n\ttimer.Stop()\n\n\tif tx.Error != nil && errors.Is(tx.Error, gorm.ErrRecordNotFound) {\n\t\treturn models.NodeExecution{},\n\t\t\tadminErrors.GetMissingEntityError(\"node execution\", &core.NodeExecutionIdentifier{\n\t\t\t\tNodeId: input.NodeExecutionIdentifier.NodeId,\n\t\t\t\tExecutionId: &core.WorkflowExecutionIdentifier{\n\t\t\t\t\tProject: input.NodeExecutionIdentifier.ExecutionId.Project,\n\t\t\t\t\tDomain:  input.NodeExecutionIdentifier.ExecutionId.Domain,\n\t\t\t\t\tName:    input.NodeExecutionIdentifier.ExecutionId.Name,\n\t\t\t\t},\n\t\t\t})\n\t} else if tx.Error != nil {\n\t\treturn models.NodeExecution{}, r.errorTransformer.ToFlyteAdminError(tx.Error)\n\t}\n\n\treturn nodeExecution, nil\n}\n\nfunc (r *NodeExecutionRepo) GetWithChildren(ctx context.Context, input interfaces.NodeExecutionResource) (models.NodeExecution, error) {\n\tvar nodeExecution models.NodeExecution\n\ttimer := r.metrics.GetDuration.Start()\n\ttx := r.db.Where(&models.NodeExecution{\n\t\tNodeExecutionKey: models.NodeExecutionKey{\n\t\t\tNodeID: input.NodeExecutionIdentifier.NodeId,\n\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\tProject: input.NodeExecutionIdentifier.ExecutionId.Project,\n\t\t\t\tDomain:  input.NodeExecutionIdentifier.ExecutionId.Domain,\n\t\t\t\tName:    input.NodeExecutionIdentifier.ExecutionId.Name,\n\t\t\t},\n\t\t},\n\t}).Preload(\"ChildNodeExecutions\").Take(&nodeExecution)\n\ttimer.Stop()\n\n\tif tx.Error != nil && errors.Is(tx.Error, gorm.ErrRecordNotFound) {\n\t\treturn models.NodeExecution{},\n\t\t\tadminErrors.GetMissingEntityError(\"node execution\", &core.NodeExecutionIdentifier{\n\t\t\t\tNodeId: input.NodeExecutionIdentifier.NodeId,\n\t\t\t\tExecutionId: &core.WorkflowExecutionIdentifier{\n\t\t\t\t\tProject: input.NodeExecutionIdentifier.ExecutionId.Project,\n\t\t\t\t\tDomain:  input.NodeExecutionIdentifier.ExecutionId.Domain,\n\t\t\t\t\tName:    input.NodeExecutionIdentifier.ExecutionId.Name,\n\t\t\t\t},\n\t\t\t})\n\t} else if tx.Error != nil {\n\t\treturn models.NodeExecution{}, r.errorTransformer.ToFlyteAdminError(tx.Error)\n\t}\n\n\treturn nodeExecution, nil\n}\n\nfunc (r *NodeExecutionRepo) Update(ctx context.Context, nodeExecution *models.NodeExecution) error {\n\ttimer := r.metrics.UpdateDuration.Start()\n\ttx := r.db.Model(&nodeExecution).Updates(nodeExecution)\n\ttimer.Stop()\n\tif err := tx.Error; err != nil {\n\t\treturn r.errorTransformer.ToFlyteAdminError(err)\n\t}\n\treturn nil\n}\n\nfunc (r *NodeExecutionRepo) List(ctx context.Context, input interfaces.ListResourceInput) (\n\tinterfaces.NodeExecutionCollectionOutput, error) {\n\t// First validate input.\n\tif err := ValidateListInput(input); err != nil {\n\t\treturn interfaces.NodeExecutionCollectionOutput{}, err\n\t}\n\tvar nodeExecutions []models.NodeExecution\n\ttx := r.db.Limit(input.Limit).Offset(input.Offset).Preload(\"ChildNodeExecutions\")\n\t// And add join condition (joining multiple tables is fine even we only filter on a subset of table attributes).\n\t// (this query isn't called for deletes).\n\ttx = tx.Joins(fmt.Sprintf(\"INNER JOIN %s ON %s.execution_project = %s.execution_project AND \"+\n\t\t\"%s.execution_domain = %s.execution_domain AND %s.execution_name = %s.execution_name\",\n\t\texecutionTableName, nodeExecutionTableName, executionTableName,\n\t\tnodeExecutionTableName, executionTableName, nodeExecutionTableName, executionTableName))\n\n\t// Apply filters\n\ttx, err := applyScopedFilters(tx, input.InlineFilters, input.MapFilters)\n\tif err != nil {\n\t\treturn interfaces.NodeExecutionCollectionOutput{}, err\n\t}\n\t// Apply sort ordering.\n\tif input.SortParameter != nil {\n\t\ttx = tx.Order(input.SortParameter.GetGormOrderExpr())\n\t}\n\n\ttimer := r.metrics.ListDuration.Start()\n\ttx = tx.Find(&nodeExecutions)\n\ttimer.Stop()\n\tif tx.Error != nil {\n\t\treturn interfaces.NodeExecutionCollectionOutput{}, r.errorTransformer.ToFlyteAdminError(tx.Error)\n\t}\n\treturn interfaces.NodeExecutionCollectionOutput{\n\t\tNodeExecutions: nodeExecutions,\n\t}, nil\n}\n\nfunc (r *NodeExecutionRepo) Exists(ctx context.Context, input interfaces.NodeExecutionResource) (bool, error) {\n\tvar nodeExecution models.NodeExecution\n\ttimer := r.metrics.ExistsDuration.Start()\n\ttx := r.db.Select(ID).Where(&models.NodeExecution{\n\t\tNodeExecutionKey: models.NodeExecutionKey{\n\t\t\tNodeID: input.NodeExecutionIdentifier.NodeId,\n\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\tProject: input.NodeExecutionIdentifier.ExecutionId.Project,\n\t\t\t\tDomain:  input.NodeExecutionIdentifier.ExecutionId.Domain,\n\t\t\t\tName:    input.NodeExecutionIdentifier.ExecutionId.Name,\n\t\t\t},\n\t\t},\n\t}).Take(&nodeExecution)\n\ttimer.Stop()\n\tif tx.Error != nil {\n\t\treturn false, r.errorTransformer.ToFlyteAdminError(tx.Error)\n\t}\n\treturn true, nil\n}\n\nfunc (r *NodeExecutionRepo) Count(ctx context.Context, input interfaces.CountResourceInput) (int64, error) {\n\tvar err error\n\ttx := r.db.Model(&models.NodeExecution{}).Preload(\"ChildNodeExecutions\")\n\n\t// Add join condition (joining multiple tables is fine even we only filter on a subset of table attributes).\n\t// (this query isn't called for deletes).\n\ttx = tx.Joins(fmt.Sprintf(\"INNER JOIN %s ON %s.execution_project = %s.execution_project AND \"+\n\t\t\"%s.execution_domain = %s.execution_domain AND %s.execution_name = %s.execution_name\",\n\t\texecutionTableName, nodeExecutionTableName, executionTableName,\n\t\tnodeExecutionTableName, executionTableName, nodeExecutionTableName, executionTableName))\n\n\t// Apply filters\n\ttx, err = applyScopedFilters(tx, input.InlineFilters, input.MapFilters)\n\tif err != nil {\n\t\treturn 0, err\n\t}\n\n\t// Run the query\n\ttimer := r.metrics.CountDuration.Start()\n\tvar count int64\n\ttx = tx.Count(&count)\n\ttimer.Stop()\n\tif tx.Error != nil {\n\t\treturn 0, r.errorTransformer.ToFlyteAdminError(tx.Error)\n\t}\n\treturn count, nil\n}\n\n// Returns an instance of NodeExecutionRepoInterface\nfunc NewNodeExecutionRepo(\n\tdb *gorm.DB, errorTransformer adminErrors.ErrorTransformer,\n\tscope promutils.Scope) interfaces.NodeExecutionRepoInterface {\n\tmetrics := newMetrics(scope)\n\treturn &NodeExecutionRepo{\n\t\tdb:               db,\n\t\terrorTransformer: errorTransformer,\n\t\tmetrics:          metrics,\n\t}\n}\n", "package gormimpl\n\nimport (\n\t\"context\"\n\t\"testing\"\n\t\"time\"\n\n\tmocket \"github.com/Selvatico/go-mocket\"\n\t\"github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/admin\"\n\t\"github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/core\"\n\tmockScope \"github.com/flyteorg/flytestdlib/promutils\"\n\t\"github.com/stretchr/testify/assert\"\n\t\"github.com/stretchr/testify/require\"\n\t\"google.golang.org/grpc/codes\"\n\t\"gorm.io/gorm\"\n\n\t\"github.com/flyteorg/flyteadmin/pkg/common\"\n\tflyteAdminErrors \"github.com/flyteorg/flyteadmin/pkg/errors\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/errors\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/interfaces\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/models\"\n)\n\nvar nodePhase = core.NodeExecution_RUNNING.String()\n\nvar nodeStartedAt = time.Date(2018, time.February, 17, 00, 00, 00, 00, time.UTC)\n\nvar nodeCreatedAt = time.Date(2018, time.February, 17, 00, 00, 00, 00, time.UTC).UTC()\nvar nodePlanUpdatedAt = time.Date(2018, time.February, 17, 00, 01, 00, 00, time.UTC).UTC()\n\nfunc TestCreateNodeExecution(t *testing.T) {\n\tnodeExecutionRepo := NewNodeExecutionRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\tGlobalMock := mocket.Catcher.Reset()\n\n\tnodeExecutionQuery := GlobalMock.NewMock()\n\tnodeExecutionQuery.WithQuery(`INSERT INTO \"node_executions\" (\"created_at\",\"updated_at\",\"deleted_at\",\"execution_project\",\"execution_domain\",\"execution_name\",\"node_id\",\"phase\",\"input_uri\",\"closure\",\"started_at\",\"node_execution_created_at\",\"node_execution_updated_at\",\"duration\",\"node_execution_metadata\",\"parent_id\",\"parent_task_execution_id\",\"error_kind\",\"error_code\",\"cache_status\",\"dynamic_workflow_remote_closure_reference\",\"internal_data\") VALUES ($1,$2,$3,$4,$5,$6,$7,$8,$9,$10,$11,$12,$13,$14,$15,$16,$17,$18,$19,$20,$21,$22)`)\n\tparentID := uint(10)\n\tnodeExecution := models.NodeExecution{\n\t\tNodeExecutionKey: models.NodeExecutionKey{\n\t\t\tNodeID: \"1\",\n\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\tProject: \"project\",\n\t\t\t\tDomain:  \"domain\",\n\t\t\t\tName:    \"1\",\n\t\t\t},\n\t\t},\n\t\tPhase:                  nodePhase,\n\t\tClosure:                []byte(\"closure\"),\n\t\tNodeExecutionMetadata:  []byte(\"closure\"),\n\t\tInputURI:               \"input uri\",\n\t\tStartedAt:              &nodeStartedAt,\n\t\tDuration:               time.Hour,\n\t\tNodeExecutionCreatedAt: &nodeCreatedAt,\n\t\tNodeExecutionUpdatedAt: &nodeCreatedAt,\n\t\tParentID:               &parentID,\n\t}\n\terr := nodeExecutionRepo.Create(context.Background(), &nodeExecution)\n\tassert.NoError(t, err)\n\tassert.True(t, nodeExecutionQuery.Triggered)\n}\n\nfunc TestUpdateNodeExecution(t *testing.T) {\n\tnodeExecutionRepo := NewNodeExecutionRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\tGlobalMock := mocket.Catcher.Reset()\n\t// Only match on queries that append the name filter\n\tnodeExecutionQuery := GlobalMock.NewMock()\n\tnodeExecutionQuery.WithQuery(`UPDATE \"node_executions\" SET \"id\"=$1,\"updated_at\"=$2,\"execution_project\"=$3,\"execution_domain\"=$4,\"execution_name\"=$5,\"node_id\"=$6,\"phase\"=$7,\"input_uri\"=$8,\"closure\"=$9,\"started_at\"=$10,\"node_execution_created_at\"=$11,\"node_execution_updated_at\"=$12,\"duration\"=$13 WHERE \"execution_project\" = $14 AND \"execution_domain\" = $15 AND \"execution_name\" = $16 AND \"node_id\" = $17`)\n\terr := nodeExecutionRepo.Update(context.Background(),\n\t\t&models.NodeExecution{\n\t\t\tBaseModel: models.BaseModel{ID: 1},\n\t\t\tNodeExecutionKey: models.NodeExecutionKey{\n\t\t\t\tNodeID: \"1\",\n\t\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\t\tProject: \"project\",\n\t\t\t\t\tDomain:  \"domain\",\n\t\t\t\t\tName:    \"1\",\n\t\t\t\t},\n\t\t\t},\n\t\t\tPhase:                  nodePhase,\n\t\t\tClosure:                []byte(\"closure\"),\n\t\t\tInputURI:               \"input uri\",\n\t\t\tStartedAt:              &nodeStartedAt,\n\t\t\tDuration:               time.Hour,\n\t\t\tNodeExecutionCreatedAt: &nodeCreatedAt,\n\t\t\tNodeExecutionUpdatedAt: &nodePlanUpdatedAt,\n\t\t})\n\tassert.NoError(t, err)\n\tassert.True(t, nodeExecutionQuery.Triggered)\n}\n\nfunc getMockNodeExecutionResponseFromDb(expected models.NodeExecution) map[string]interface{} {\n\tnodeExecution := make(map[string]interface{})\n\tnodeExecution[\"execution_project\"] = expected.ExecutionKey.Project\n\tnodeExecution[\"execution_domain\"] = expected.ExecutionKey.Domain\n\tnodeExecution[\"execution_name\"] = expected.ExecutionKey.Name\n\tnodeExecution[\"node_id\"] = expected.NodeExecutionKey.NodeID\n\tnodeExecution[\"phase\"] = expected.Phase\n\tnodeExecution[\"closure\"] = expected.Closure\n\tnodeExecution[\"input_uri\"] = expected.InputURI\n\tnodeExecution[\"started_at\"] = expected.StartedAt\n\tnodeExecution[\"duration\"] = expected.Duration\n\tnodeExecution[\"node_execution_created_at\"] = expected.NodeExecutionCreatedAt\n\tnodeExecution[\"node_execution_updated_at\"] = expected.NodeExecutionUpdatedAt\n\tnodeExecution[\"parent_id\"] = expected.ParentID\n\tif expected.NodeExecutionMetadata != nil {\n\t\tnodeExecution[\"node_execution_metadata\"] = expected.NodeExecutionMetadata\n\t}\n\treturn nodeExecution\n}\n\nfunc TestGetNodeExecution(t *testing.T) {\n\tnodeExecutionRepo := NewNodeExecutionRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\tparentID := uint(10)\n\texpectedNodeExecution := models.NodeExecution{\n\t\tNodeExecutionKey: models.NodeExecutionKey{\n\t\t\tNodeID: \"1\",\n\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\tProject: \"project\",\n\t\t\t\tDomain:  \"domain\",\n\t\t\t\tName:    \"1\",\n\t\t\t},\n\t\t},\n\t\tPhase:                  nodePhase,\n\t\tClosure:                []byte(\"closure\"),\n\t\tInputURI:               \"input uri\",\n\t\tStartedAt:              &nodeStartedAt,\n\t\tDuration:               time.Hour,\n\t\tNodeExecutionCreatedAt: &nodeCreatedAt,\n\t\tNodeExecutionUpdatedAt: &nodePlanUpdatedAt,\n\t\tNodeExecutionMetadata:  []byte(\"NodeExecutionMetadata\"),\n\t\tParentID:               &parentID,\n\t}\n\n\tnodeExecutions := make([]map[string]interface{}, 0)\n\tnodeExecution := getMockNodeExecutionResponseFromDb(expectedNodeExecution)\n\tnodeExecutions = append(nodeExecutions, nodeExecution)\n\n\tGlobalMock := mocket.Catcher.Reset()\n\tGlobalMock.NewMock().WithQuery(\n\t\t`SELECT * FROM \"node_executions\" WHERE \"node_executions\".\"execution_project\" = $1 AND \"node_executions\".\"execution_domain\" = $2 AND \"node_executions\".\"execution_name\" = $3 AND \"node_executions\".\"node_id\" = $4 LIMIT 1`).WithReply(nodeExecutions)\n\toutput, err := nodeExecutionRepo.Get(context.Background(), interfaces.NodeExecutionResource{\n\t\tNodeExecutionIdentifier: core.NodeExecutionIdentifier{\n\t\t\tNodeId: \"1\",\n\t\t\tExecutionId: &core.WorkflowExecutionIdentifier{\n\t\t\t\tProject: \"execution_project\",\n\t\t\t\tDomain:  \"execution_domain\",\n\t\t\t\tName:    \"execution_name\",\n\t\t\t},\n\t\t},\n\t})\n\tassert.NoError(t, err)\n\tassert.EqualValues(t, expectedNodeExecution, output)\n}\n\nfunc TestGetNodeExecutionErr(t *testing.T) {\n\tnodeExecutionRepo := NewNodeExecutionRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\n\tt.Run(\"not found\", func(t *testing.T) {\n\t\tGlobalMock := mocket.Catcher.Reset()\n\t\tGlobalMock.NewMock().WithError(gorm.ErrRecordNotFound)\n\n\t\t_, err := nodeExecutionRepo.Get(context.Background(), interfaces.NodeExecutionResource{\n\t\t\tNodeExecutionIdentifier: core.NodeExecutionIdentifier{\n\t\t\t\tNodeId: \"1\",\n\t\t\t\tExecutionId: &core.WorkflowExecutionIdentifier{\n\t\t\t\t\tProject: \"execution_project\",\n\t\t\t\t\tDomain:  \"execution_domain\",\n\t\t\t\t\tName:    \"execution_name\",\n\t\t\t\t},\n\t\t\t},\n\t\t})\n\t\tassert.Equal(t, err.(flyteAdminErrors.FlyteAdminError).Code(), codes.NotFound)\n\t})\n\tt.Run(\"other error\", func(t *testing.T) {\n\t\tGlobalMock := mocket.Catcher.Reset()\n\t\tGlobalMock.NewMock().WithError(gorm.ErrInvalidData)\n\n\t\t_, err := nodeExecutionRepo.Get(context.Background(), interfaces.NodeExecutionResource{\n\t\t\tNodeExecutionIdentifier: core.NodeExecutionIdentifier{\n\t\t\t\tNodeId: \"1\",\n\t\t\t\tExecutionId: &core.WorkflowExecutionIdentifier{\n\t\t\t\t\tProject: \"execution_project\",\n\t\t\t\t\tDomain:  \"execution_domain\",\n\t\t\t\t\tName:    \"execution_name\",\n\t\t\t\t},\n\t\t\t},\n\t\t})\n\t\tassert.Equal(t, err.(flyteAdminErrors.FlyteAdminError).Code(), codes.Unknown)\n\t})\n}\n\nfunc TestListNodeExecutions(t *testing.T) {\n\tnodeExecutionRepo := NewNodeExecutionRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\n\tnodeExecutions := make([]map[string]interface{}, 0)\n\texecutionIDs := []string{\"100\", \"200\"}\n\tfor _, executionID := range executionIDs {\n\t\tnodeExecution := getMockNodeExecutionResponseFromDb(models.NodeExecution{\n\t\t\tNodeExecutionKey: models.NodeExecutionKey{\n\t\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\t\tProject: \"project\",\n\t\t\t\t\tDomain:  \"domain\",\n\t\t\t\t\tName:    executionID,\n\t\t\t\t},\n\t\t\t},\n\t\t\tPhase:                  nodePhase,\n\t\t\tClosure:                []byte(\"closure\"),\n\t\t\tInputURI:               \"input uri\",\n\t\t\tStartedAt:              &nodeStartedAt,\n\t\t\tDuration:               time.Hour,\n\t\t\tNodeExecutionCreatedAt: &nodeCreatedAt,\n\t\t\tNodeExecutionUpdatedAt: &nodePlanUpdatedAt,\n\t\t})\n\t\tnodeExecutions = append(nodeExecutions, nodeExecution)\n\t}\n\n\tGlobalMock := mocket.Catcher.Reset()\n\tGlobalMock.NewMock().WithQuery(`SELECT \"node_executions\".\"id\",\"node_executions\".\"created_at\",\"node_executions\".\"updated_at\",\"node_executions\".\"deleted_at\",\"node_executions\".\"execution_project\",\"node_executions\".\"execution_domain\",\"node_executions\".\"execution_name\",\"node_executions\".\"node_id\",\"node_executions\".\"phase\",\"node_executions\".\"input_uri\",\"node_executions\".\"closure\",\"node_executions\".\"started_at\",\"node_executions\".\"node_execution_created_at\",\"node_executions\".\"node_execution_updated_at\",\"node_executions\".\"duration\",\"node_executions\".\"node_execution_metadata\",\"node_executions\".\"parent_id\",\"node_executions\".\"parent_task_execution_id\",\"node_executions\".\"error_kind\",\"node_executions\".\"error_code\",\"node_executions\".\"cache_status\",\"node_executions\".\"dynamic_workflow_remote_closure_reference\",\"node_executions\".\"internal_data\" FROM \"node_executions\" INNER JOIN executions ON node_executions.execution_project = executions.execution_project AND node_executions.execution_domain = executions.execution_domain AND node_executions.execution_name = executions.execution_name WHERE node_executions.phase = $1 LIMIT 20%`).\n\t\tWithReply(nodeExecutions)\n\n\tcollection, err := nodeExecutionRepo.List(context.Background(), interfaces.ListResourceInput{\n\t\tInlineFilters: []common.InlineFilter{\n\t\t\tgetEqualityFilter(common.NodeExecution, \"phase\", nodePhase),\n\t\t},\n\t\tLimit: 20,\n\t})\n\tassert.NoError(t, err)\n\tassert.NotEmpty(t, collection)\n\tassert.NotEmpty(t, collection.NodeExecutions)\n\tassert.Len(t, collection.NodeExecutions, 2)\n\tfor _, nodeExecution := range collection.NodeExecutions {\n\t\tassert.Equal(t, \"project\", nodeExecution.ExecutionKey.Project)\n\t\tassert.Equal(t, \"domain\", nodeExecution.ExecutionKey.Domain)\n\t\tassert.Contains(t, executionIDs, nodeExecution.ExecutionKey.Name)\n\t\tassert.Equal(t, nodePhase, nodeExecution.Phase)\n\t\tassert.Equal(t, []byte(\"closure\"), nodeExecution.Closure)\n\t\tassert.Equal(t, \"input uri\", nodeExecution.InputURI)\n\t\tassert.Equal(t, nodeStartedAt, *nodeExecution.StartedAt)\n\t\tassert.Equal(t, time.Hour, nodeExecution.Duration)\n\t}\n}\n\nfunc TestListNodeExecutions_Order(t *testing.T) {\n\tnodeExecutionRepo := NewNodeExecutionRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\tnodeExecutions := make([]map[string]interface{}, 0)\n\n\tGlobalMock := mocket.Catcher.Reset()\n\t// Only match on queries that include ordering by project\n\tmockQuery := GlobalMock.NewMock()\n\tmockQuery.WithQuery(`execution_project desc`)\n\tmockQuery.WithReply(nodeExecutions)\n\n\tsortParameter, err := common.NewSortParameter(&admin.Sort{\n\t\tDirection: admin.Sort_DESCENDING,\n\t\tKey:       \"execution_project\",\n\t}, models.NodeExecutionColumns)\n\trequire.NoError(t, err)\n\n\t_, err = nodeExecutionRepo.List(context.Background(), interfaces.ListResourceInput{\n\t\tSortParameter: sortParameter,\n\t\tInlineFilters: []common.InlineFilter{\n\t\t\tgetEqualityFilter(common.NodeExecution, \"phase\", nodePhase),\n\t\t},\n\t\tLimit: 20,\n\t})\n\n\tassert.NoError(t, err)\n\tassert.True(t, mockQuery.Triggered)\n}\n\nfunc TestListNodeExecutions_MissingParameters(t *testing.T) {\n\tnodeExecutionRepo := NewNodeExecutionRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\t_, err := nodeExecutionRepo.List(context.Background(), interfaces.ListResourceInput{\n\t\tInlineFilters: []common.InlineFilter{\n\t\t\tgetEqualityFilter(common.NodeExecution, \"execution_id\", \"1234\"),\n\t\t},\n\t})\n\tassert.EqualError(t, err, \"missing and/or invalid parameters: limit\")\n\n\t_, err = nodeExecutionRepo.List(context.Background(), interfaces.ListResourceInput{\n\t\tLimit: 20,\n\t})\n\tassert.EqualError(t, err, \"missing and/or invalid parameters: filters\")\n}\n\nfunc TestListNodeExecutionsForExecution(t *testing.T) {\n\tnodeExecutionRepo := NewNodeExecutionRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\n\tnodeExecutions := make([]map[string]interface{}, 0)\n\tnodeExecution := getMockNodeExecutionResponseFromDb(models.NodeExecution{\n\t\tNodeExecutionKey: models.NodeExecutionKey{\n\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\tProject: \"project\",\n\t\t\t\tDomain:  \"domain\",\n\t\t\t\tName:    \"1\",\n\t\t\t},\n\t\t},\n\t\tPhase:                 nodePhase,\n\t\tClosure:               []byte(\"closure\"),\n\t\tInputURI:              \"input uri\",\n\t\tStartedAt:             &nodeStartedAt,\n\t\tDuration:              time.Hour,\n\t\tNodeExecutionMetadata: []byte(\"NodeExecutionMetadata\"),\n\t})\n\tnodeExecutions = append(nodeExecutions, nodeExecution)\n\n\tGlobalMock := mocket.Catcher.Reset()\n\tquery := `SELECT \"node_executions\".\"id\",\"node_executions\".\"created_at\",\"node_executions\".\"updated_at\",\"node_executions\".\"deleted_at\",\"node_executions\".\"execution_project\",\"node_executions\".\"execution_domain\",\"node_executions\".\"execution_name\",\"node_executions\".\"node_id\",\"node_executions\".\"phase\",\"node_executions\".\"input_uri\",\"node_executions\".\"closure\",\"node_executions\".\"started_at\",\"node_executions\".\"node_execution_created_at\",\"node_executions\".\"node_execution_updated_at\",\"node_executions\".\"duration\",\"node_executions\".\"node_execution_metadata\",\"node_executions\".\"parent_id\",\"node_executions\".\"parent_task_execution_id\",\"node_executions\".\"error_kind\",\"node_executions\".\"error_code\",\"node_executions\".\"cache_status\",\"node_executions\".\"dynamic_workflow_remote_closure_reference\",\"node_executions\".\"internal_data\" FROM \"node_executions\" INNER JOIN executions ON node_executions.execution_project = executions.execution_project AND node_executions.execution_domain = executions.execution_domain AND node_executions.execution_name = executions.execution_name WHERE node_executions.phase = $1 AND executions.execution_name = $2 LIMIT 20%`\n\tGlobalMock.NewMock().WithQuery(query).WithReply(nodeExecutions)\n\n\tcollection, err := nodeExecutionRepo.List(context.Background(), interfaces.ListResourceInput{\n\t\tInlineFilters: []common.InlineFilter{\n\t\t\tgetEqualityFilter(common.NodeExecution, \"phase\", nodePhase),\n\t\t\tgetEqualityFilter(common.Execution, \"name\", \"execution_name\"),\n\t\t},\n\n\t\tLimit: 20,\n\t})\n\tassert.NoError(t, err)\n\tassert.NotEmpty(t, collection)\n\tassert.NotEmpty(t, collection.NodeExecutions)\n\tassert.Len(t, collection.NodeExecutions, 1)\n\tfor _, nodeExecution := range collection.NodeExecutions {\n\t\tassert.Equal(t, \"project\", nodeExecution.ExecutionKey.Project)\n\t\tassert.Equal(t, \"domain\", nodeExecution.ExecutionKey.Domain)\n\t\tassert.Equal(t, \"1\", nodeExecution.ExecutionKey.Name)\n\t\tassert.Equal(t, nodePhase, nodeExecution.Phase)\n\t\tassert.Equal(t, []byte(\"closure\"), nodeExecution.Closure)\n\t\tassert.Equal(t, \"input uri\", nodeExecution.InputURI)\n\t\tassert.Equal(t, nodeStartedAt, *nodeExecution.StartedAt)\n\t\tassert.Equal(t, time.Hour, nodeExecution.Duration)\n\t\tassert.Equal(t, []byte(\"NodeExecutionMetadata\"), nodeExecution.NodeExecutionMetadata)\n\t\tassert.Empty(t, nodeExecution.ChildNodeExecutions)\n\t\tassert.Empty(t, nodeExecution.ParentID)\n\t}\n}\n\nfunc TestNodeExecutionExists(t *testing.T) {\n\tnodeExecutionRepo := NewNodeExecutionRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\tid := uint(10)\n\texpectedNodeExecution := models.NodeExecution{\n\t\tNodeExecutionKey: models.NodeExecutionKey{\n\t\t\tNodeID: \"1\",\n\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\tProject: \"project\",\n\t\t\t\tDomain:  \"domain\",\n\t\t\t\tName:    \"1\",\n\t\t\t},\n\t\t},\n\t\tBaseModel: models.BaseModel{\n\t\t\tID: id,\n\t\t},\n\t\tPhase:   nodePhase,\n\t\tClosure: []byte(\"closure\"),\n\t}\n\n\tnodeExecutions := make([]map[string]interface{}, 0)\n\tnodeExecution := getMockNodeExecutionResponseFromDb(expectedNodeExecution)\n\tnodeExecutions = append(nodeExecutions, nodeExecution)\n\n\tGlobalMock := mocket.Catcher.Reset()\n\tGlobalMock.NewMock().WithQuery(\n\t\t`SELECT \"id\" FROM \"node_executions\" WHERE \"node_executions\".\"execution_project\" = $1 AND \"node_executions\".\"execution_domain\" = $2 AND \"node_executions\".\"execution_name\" = $3 AND \"node_executions\".\"node_id\" = $4 LIMIT 1`).WithReply(nodeExecutions)\n\texists, err := nodeExecutionRepo.Exists(context.Background(), interfaces.NodeExecutionResource{\n\t\tNodeExecutionIdentifier: core.NodeExecutionIdentifier{\n\t\t\tNodeId: \"1\",\n\t\t\tExecutionId: &core.WorkflowExecutionIdentifier{\n\t\t\t\tProject: \"execution_project\",\n\t\t\t\tDomain:  \"execution_domain\",\n\t\t\t\tName:    \"execution_name\",\n\t\t\t},\n\t\t},\n\t})\n\tassert.NoError(t, err)\n\tassert.True(t, exists)\n}\n\nfunc TestCountNodeExecutions(t *testing.T) {\n\tnodeExecutionRepo := NewNodeExecutionRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\n\tGlobalMock := mocket.Catcher.Reset()\n\tGlobalMock.NewMock().WithQuery(\n\t\t`SELECT count(*) FROM \"node_executions\"`).WithReply([]map[string]interface{}{{\"rows\": 2}})\n\n\tcount, err := nodeExecutionRepo.Count(context.Background(), interfaces.CountResourceInput{})\n\tassert.NoError(t, err)\n\tassert.Equal(t, int64(2), count)\n}\n\nfunc TestCountNodeExecutions_Filters(t *testing.T) {\n\tnodeExecutionRepo := NewNodeExecutionRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\n\tGlobalMock := mocket.Catcher.Reset()\n\tGlobalMock.NewMock().WithQuery(\n\t\t`SELECT count(*) FROM \"node_executions\" INNER JOIN executions ON node_executions.execution_project = executions.execution_project AND node_executions.execution_domain = executions.execution_domain AND node_executions.execution_name = executions.execution_name WHERE node_executions.phase = $1 AND \"node_executions\".\"error_code\" IS NULL`).WithReply([]map[string]interface{}{{\"rows\": 3}})\n\n\tcount, err := nodeExecutionRepo.Count(context.Background(), interfaces.CountResourceInput{\n\t\tInlineFilters: []common.InlineFilter{\n\t\t\tgetEqualityFilter(common.NodeExecution, \"phase\", core.NodeExecution_FAILED.String()),\n\t\t},\n\t\tMapFilters: []common.MapFilter{\n\t\t\tcommon.NewMapFilter(map[string]interface{}{\n\t\t\t\t\"\\\"node_executions\\\".\\\"error_code\\\"\": nil,\n\t\t\t}),\n\t\t},\n\t})\n\tassert.NoError(t, err)\n\tassert.Equal(t, int64(3), count)\n}\n", "package gormimpl\n\nimport (\n\t\"context\"\n\t\"errors\"\n\n\t\"github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/admin\"\n\t\"github.com/flyteorg/flytestdlib/promutils\"\n\t\"google.golang.org/grpc/codes\"\n\t\"gorm.io/gorm\"\n\n\tflyteAdminErrors \"github.com/flyteorg/flyteadmin/pkg/errors\"\n\tflyteAdminDbErrors \"github.com/flyteorg/flyteadmin/pkg/repositories/errors\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/interfaces\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/models\"\n)\n\ntype ProjectRepo struct {\n\tdb               *gorm.DB\n\terrorTransformer flyteAdminDbErrors.ErrorTransformer\n\tmetrics          gormMetrics\n}\n\nfunc (r *ProjectRepo) Create(ctx context.Context, project models.Project) error {\n\ttimer := r.metrics.CreateDuration.Start()\n\ttx := r.db.Omit(\"id\").Create(&project)\n\ttimer.Stop()\n\tif tx.Error != nil {\n\t\treturn r.errorTransformer.ToFlyteAdminError(tx.Error)\n\t}\n\treturn nil\n}\n\nfunc (r *ProjectRepo) Get(ctx context.Context, projectID string) (models.Project, error) {\n\tvar project models.Project\n\ttimer := r.metrics.GetDuration.Start()\n\ttx := r.db.Where(&models.Project{\n\t\tIdentifier: projectID,\n\t}).Take(&project)\n\ttimer.Stop()\n\tif errors.Is(tx.Error, gorm.ErrRecordNotFound) {\n\t\treturn models.Project{}, flyteAdminErrors.NewFlyteAdminErrorf(codes.NotFound, \"project [%s] not found\", projectID)\n\t}\n\n\tif tx.Error != nil {\n\t\treturn models.Project{}, r.errorTransformer.ToFlyteAdminError(tx.Error)\n\t}\n\n\treturn project, nil\n}\n\nfunc (r *ProjectRepo) List(ctx context.Context, input interfaces.ListResourceInput) ([]models.Project, error) {\n\tvar projects []models.Project\n\n\ttx := r.db.Offset(input.Offset)\n\tif input.Limit != 0 {\n\t\ttx = tx.Limit(input.Limit)\n\t}\n\n\t// Apply filters\n\t// If no filter provided, default to filtering out archived projects\n\tif len(input.InlineFilters) == 0 && len(input.MapFilters) == 0 {\n\t\ttx = tx.Where(\"state != ?\", int32(admin.Project_ARCHIVED))\n\t} else {\n\t\tvar err error\n\t\ttx, err = applyFilters(tx, input.InlineFilters, input.MapFilters)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\t// Apply sort ordering\n\tif input.SortParameter != nil {\n\t\ttx = tx.Order(input.SortParameter.GetGormOrderExpr())\n\t}\n\n\ttimer := r.metrics.ListDuration.Start()\n\ttx.Find(&projects)\n\ttimer.Stop()\n\n\tif tx.Error != nil {\n\t\treturn nil, r.errorTransformer.ToFlyteAdminError(tx.Error)\n\t}\n\treturn projects, nil\n}\n\nfunc NewProjectRepo(db *gorm.DB, errorTransformer flyteAdminDbErrors.ErrorTransformer,\n\tscope promutils.Scope) interfaces.ProjectRepoInterface {\n\tmetrics := newMetrics(scope)\n\treturn &ProjectRepo{\n\t\tdb:               db,\n\t\terrorTransformer: errorTransformer,\n\t\tmetrics:          metrics,\n\t}\n}\n\nfunc (r *ProjectRepo) UpdateProject(ctx context.Context, projectUpdate models.Project) error {\n\t// Use gorm client to update the two fields that are changed.\n\twriteTx := r.db.Model(&projectUpdate).Updates(projectUpdate)\n\n\t// Return error if applies.\n\tif writeTx.Error != nil {\n\t\treturn r.errorTransformer.ToFlyteAdminError(writeTx.Error)\n\t}\n\n\treturn nil\n}\n", "package gormimpl\n\nimport (\n\t\"context\"\n\t\"testing\"\n\n\tmocket \"github.com/Selvatico/go-mocket\"\n\t\"github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/admin\"\n\tmockScope \"github.com/flyteorg/flytestdlib/promutils\"\n\t\"github.com/stretchr/testify/assert\"\n\n\t\"github.com/flyteorg/flyteadmin/pkg/common\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/errors\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/interfaces\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/models\"\n)\n\nvar alphabeticalSortParam, _ = common.NewSortParameter(&admin.Sort{\n\tDirection: admin.Sort_ASCENDING,\n\tKey:       \"identifier\",\n}, models.ProjectColumns)\n\nfunc TestCreateProject(t *testing.T) {\n\tprojectRepo := NewProjectRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\tGlobalMock := mocket.Catcher.Reset()\n\n\tquery := GlobalMock.NewMock()\n\tGlobalMock.Logging = true\n\tquery.WithQuery(\n\t\t`INSERT INTO \"projects\" (\"created_at\",\"updated_at\",\"deleted_at\",\"name\",\"description\",\"labels\",\"state\",\"identifier\") VALUES ($1,$2,$3,$4,$5,$6,$7,$8)`)\n\n\tactiveState := int32(admin.Project_ACTIVE)\n\terr := projectRepo.Create(context.Background(), models.Project{\n\t\tIdentifier:  \"proj\",\n\t\tName:        \"proj\",\n\t\tDescription: \"projDescription\",\n\t\tState:       &activeState,\n\t})\n\tassert.NoError(t, err)\n\tassert.True(t, query.Triggered)\n}\n\nfunc TestGetProject(t *testing.T) {\n\tprojectRepo := NewProjectRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\tGlobalMock := mocket.Catcher.Reset()\n\n\tresponse := make(map[string]interface{})\n\tresponse[\"identifier\"] = \"project_id\"\n\tresponse[\"name\"] = \"project_name\"\n\tresponse[\"description\"] = \"project_description\"\n\tresponse[\"state\"] = admin.Project_ACTIVE\n\n\toutput, err := projectRepo.Get(context.Background(), \"project_id\")\n\tassert.Empty(t, output)\n\tassert.EqualError(t, err, \"project [project_id] not found\")\n\n\tquery := GlobalMock.NewMock()\n\tGlobalMock.Logging = true\n\tquery.WithQuery(`SELECT * FROM \"projects\" WHERE \"projects\".\"identifier\" = $1 LIMIT 1`).WithReply(\n\t\t[]map[string]interface{}{\n\t\t\tresponse,\n\t\t})\n\n\toutput, err = projectRepo.Get(context.Background(), \"project_id\")\n\tassert.Nil(t, err)\n\tassert.Equal(t, \"project_id\", output.Identifier)\n\tassert.Equal(t, \"project_name\", output.Name)\n\tassert.Equal(t, \"project_description\", output.Description)\n\tassert.Equal(t, int32(admin.Project_ACTIVE), *output.State)\n}\n\nfunc testListProjects(input interfaces.ListResourceInput, sql string, t *testing.T) {\n\tprojectRepo := NewProjectRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\tprojects := make([]map[string]interface{}, 1)\n\tfooProject := make(map[string]interface{})\n\tfooProject[\"identifier\"] = \"foo\"\n\tfooProject[\"name\"] = \"foo =)\"\n\tfooProject[\"description\"] = \"foo description\"\n\tfooProject[\"state\"] = admin.Project_ACTIVE\n\tprojects[0] = fooProject\n\n\tGlobalMock := mocket.Catcher.Reset()\n\tGlobalMock.Logging = true\n\tGlobalMock.NewMock().WithQuery(sql).\n\t\tWithReply(projects)\n\n\toutput, err := projectRepo.List(context.Background(), input)\n\tassert.Nil(t, err)\n\tassert.Len(t, output, 1)\n\tassert.Equal(t, \"foo\", output[0].Identifier)\n\tassert.Equal(t, \"foo =)\", output[0].Name)\n\tassert.Equal(t, \"foo description\", output[0].Description)\n\tassert.Equal(t, int32(admin.Project_ACTIVE), *output[0].State)\n}\n\nfunc TestListProjects(t *testing.T) {\n\tfilter, err := common.NewSingleValueFilter(common.Project, common.Equal, \"name\", \"foo\")\n\n\tassert.NoError(t, err)\n\ttestListProjects(interfaces.ListResourceInput{\n\t\tOffset:        0,\n\t\tLimit:         1,\n\t\tInlineFilters: []common.InlineFilter{filter},\n\t\tSortParameter: alphabeticalSortParam,\n\t}, `SELECT * FROM \"projects\" WHERE name = $1 ORDER BY identifier asc LIMIT 1`, t)\n}\n\nfunc TestListProjects_NoFilters(t *testing.T) {\n\ttestListProjects(interfaces.ListResourceInput{\n\t\tOffset:        0,\n\t\tLimit:         1,\n\t\tSortParameter: alphabeticalSortParam,\n\t}, `SELECT * FROM \"projects\" WHERE state != $1 ORDER BY identifier asc`, t)\n}\n\nfunc TestListProjects_NoLimit(t *testing.T) {\n\ttestListProjects(interfaces.ListResourceInput{\n\t\tOffset:        0,\n\t\tSortParameter: alphabeticalSortParam,\n\t}, `SELECT * FROM \"projects\" WHERE state != $1 ORDER BY identifier asc`, t)\n}\n\nfunc TestUpdateProject(t *testing.T) {\n\tprojectRepo := NewProjectRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\tGlobalMock := mocket.Catcher.Reset()\n\n\tquery := GlobalMock.NewMock()\n\tGlobalMock.Logging = true\n\tquery.WithQuery(`UPDATE \"projects\" SET \"updated_at\"=$1,\"identifier\"=$2,\"name\"=$3,\"description\"=$4,\"state\"=$5 WHERE \"identifier\" = $6`)\n\n\tactiveState := int32(admin.Project_ACTIVE)\n\terr := projectRepo.UpdateProject(context.Background(), models.Project{\n\t\tIdentifier:  \"project_id\",\n\t\tName:        \"project_name\",\n\t\tDescription: \"project_description\",\n\t\tState:       &activeState,\n\t})\n\tassert.Nil(t, err)\n\tassert.True(t, query.Triggered)\n}\n", "package gormimpl\n\nimport (\n\t\"context\"\n\t\"testing\"\n\n\tmocket \"github.com/Selvatico/go-mocket\"\n\tmockScope \"github.com/flyteorg/flytestdlib/promutils\"\n\t\"github.com/stretchr/testify/assert\"\n\t\"gorm.io/gorm\"\n\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/errors\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/interfaces\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/models\"\n)\n\nconst resourceTestWorkflowName = \"workflow\"\nconst resourceTypeStr = \"resource-type\"\n\nfunc TestCreateWorkflowAttributes(t *testing.T) {\n\tresourceRepo := NewResourceRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\tGlobalMock := mocket.Catcher.Reset()\n\n\tquery := GlobalMock.NewMock()\n\tGlobalMock.Logging = true\n\tquery.WithQuery(\n\t\t`INSERT INTO \"resources\" (\"created_at\",\"updated_at\",\"deleted_at\",\"project\",\"domain\",\"workflow\",\"launch_plan\",\"resource_type\",\"priority\",\"attributes\") VALUES ($1,$2,$3,$4,$5,$6,$7,$8,$9,$10) RETURNING \"id\"`)\n\n\terr := resourceRepo.CreateOrUpdate(context.Background(), models.Resource{\n\t\tProject:      \"project\",\n\t\tDomain:       \"domain\",\n\t\tWorkflow:     resourceTestWorkflowName,\n\t\tResourceType: \"resource\",\n\t\tPriority:     models.ResourcePriorityLaunchPlanLevel,\n\t\tAttributes:   []byte(\"attrs\"),\n\t})\n\tassert.NoError(t, err)\n\tassert.True(t, query.Triggered)\n}\n\nfunc getMockResourceResponseFromDb(expected models.Resource) map[string]interface{} {\n\tmetadata := make(map[string]interface{})\n\tmetadata[\"resource_type\"] = expected.ResourceType\n\tmetadata[\"project\"] = expected.Project\n\tmetadata[\"domain\"] = expected.Domain\n\tmetadata[\"priority\"] = 2\n\treturn metadata\n}\n\nfunc TestUpdateWorkflowAttributes_WithExisting(t *testing.T) {\n\tresourceRepo := NewResourceRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\tresults := make([]map[string]interface{}, 0)\n\tmetadata := getMockResourceResponseFromDb(models.Resource{\n\t\tResourceType: resourceType.String(),\n\t\tProject:      project,\n\t\tDomain:       domain,\n\t\tPriority:     2,\n\t})\n\tresults = append(results, metadata)\n\n\tGlobalMock := mocket.Catcher.Reset()\n\tGlobalMock.Logging = true\n\n\tmockSelectQuery := GlobalMock.NewMock()\n\tmockSelectQuery.WithQuery(\n\t\t`SELECT * FROM \"resources\" WHERE \"resources\".\"project\" = $1 AND \"resources\".\"domain\" = $2 AND \"resources\".\"resource_type\" = $3 AND \"resources\".\"priority\" = $4 ORDER BY \"resources\".\"id\" LIMIT 1`).WithReply(results)\n\n\tmockSaveQuery := GlobalMock.NewMock()\n\tmockSaveQuery.WithQuery(\n\t\t`INSERT INTO \"resources\" (\"created_at\",\"updated_at\",\"deleted_at\",\"project\",\"domain\",\"workflow\",\"launch_plan\",\"resource_type\",\"priority\",\"attributes\") VALUES ($1,$2,$3,$4,$5,$6,$7,$8,$9,$10)`)\n\n\terr := resourceRepo.CreateOrUpdate(context.Background(), models.Resource{\n\t\tResourceType: resourceType.String(),\n\t\tProject:      project,\n\t\tDomain:       domain,\n\t\tPriority:     2,\n\t})\n\tassert.NoError(t, err)\n\tassert.True(t, mockSelectQuery.Triggered)\n\tassert.True(t, mockSaveQuery.Triggered)\n}\n\nfunc TestGetWorkflowAttributes(t *testing.T) {\n\tresourceRepo := NewResourceRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\tGlobalMock := mocket.Catcher.Reset()\n\tGlobalMock.Logging = true\n\tresponse := make(map[string]interface{})\n\tresponse[\"project\"] = \"project\"\n\tresponse[\"domain\"] = \"domain\"\n\tresponse[\"workflow\"] = resourceTestWorkflowName\n\tresponse[\"resource_type\"] = resourceTypeStr\n\tresponse[\"attributes\"] = []byte(\"attrs\")\n\n\tquery := GlobalMock.NewMock()\n\tquery.WithQuery(`SELECT * FROM \"resources\" WHERE resource_type = $1 AND domain IN ($2,$3) AND project IN ($4,$5) AND workflow IN ($6,$7) AND launch_plan IN ($8) ORDER BY priority desc,\"resources\".\"id\" LIMIT 1`).WithReply(\n\t\t[]map[string]interface{}{\n\t\t\tresponse,\n\t\t})\n\n\toutput, err := resourceRepo.Get(context.Background(), interfaces.ResourceID{Project: \"project\", Domain: \"domain\", Workflow: \"workflow\", ResourceType: \"resource\"})\n\tassert.Nil(t, err)\n\tassert.Equal(t, \"project\", output.Project)\n\tassert.Equal(t, \"domain\", output.Domain)\n\tassert.Equal(t, \"workflow\", output.Workflow)\n\tassert.Equal(t, resourceTypeStr, output.ResourceType)\n\tassert.Equal(t, []byte(\"attrs\"), output.Attributes)\n}\n\nfunc TestProjectDomainAttributes(t *testing.T) {\n\tresourceRepo := NewResourceRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\tGlobalMock := mocket.Catcher.Reset()\n\tGlobalMock.Logging = true\n\tresponse := make(map[string]interface{})\n\tresponse[project] = project\n\tresponse[domain] = domain\n\tresponse[\"resource_type\"] = resourceTypeStr\n\tresponse[\"attributes\"] = []byte(\"attrs\")\n\n\tquery := GlobalMock.NewMock()\n\tquery.WithQuery(`SELECT * FROM \"resources\" WHERE resource_type = $1 AND domain IN ($2,$3) AND project IN ($4,$5) AND workflow IN ($6) AND launch_plan IN ($7) ORDER BY priority desc,\"resources\".\"id\" LIMIT 1`).WithReply(\n\t\t[]map[string]interface{}{\n\t\t\tresponse,\n\t\t})\n\n\toutput, err := resourceRepo.Get(context.Background(), interfaces.ResourceID{Project: \"project\", Domain: \"domain\", ResourceType: \"resource\"})\n\tassert.Nil(t, err)\n\tassert.Equal(t, project, output.Project)\n\tassert.Equal(t, domain, output.Domain)\n\tassert.Equal(t, \"\", output.Workflow)\n\tassert.Equal(t, \"resource-type\", output.ResourceType)\n\tassert.Equal(t, []byte(\"attrs\"), output.Attributes)\n}\n\nfunc TestProjectLevelAttributes(t *testing.T) {\n\tresourceRepo := NewResourceRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\tGlobalMock := mocket.Catcher.Reset()\n\tGlobalMock.Logging = true\n\tresponse := make(map[string]interface{})\n\tresponse[project] = project\n\tresponse[domain] = \"\"\n\tresponse[\"resource_type\"] = \"resource-type\"\n\tresponse[\"attributes\"] = []byte(\"attrs\")\n\n\tquery := GlobalMock.NewMock()\n\tquery.WithQuery(`SELECT * FROM \"resources\" WHERE resource_type = $1 AND domain = '' AND project = $2 AND workflow = '' AND launch_plan = '' ORDER BY priority desc,\"resources\".\"id\" LIMIT 1`).WithReply(\n\t\t[]map[string]interface{}{\n\t\t\tresponse,\n\t\t})\n\n\toutput, err := resourceRepo.GetProjectLevel(context.Background(), interfaces.ResourceID{Project: \"project\", Domain: \"\", ResourceType: \"resource\"})\n\tassert.Nil(t, err)\n\tassert.Equal(t, project, output.Project)\n\tassert.Equal(t, \"\", output.Domain)\n\tassert.Equal(t, \"\", output.Workflow)\n\tassert.Equal(t, \"resource-type\", output.ResourceType)\n\tassert.Equal(t, []byte(\"attrs\"), output.Attributes)\n\n\t// Must have a project defined\n\t_, err = resourceRepo.GetProjectLevel(context.Background(), interfaces.ResourceID{Project: \"\", Domain: \"\", ResourceType: \"resource\"})\n\tassert.Error(t, err)\n}\n\nfunc TestGetRawWorkflowAttributes(t *testing.T) {\n\tresourceRepo := NewResourceRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\tGlobalMock := mocket.Catcher.Reset()\n\tGlobalMock.Logging = true\n\tresponse := make(map[string]interface{})\n\tresponse[project] = project\n\tresponse[domain] = domain\n\tresponse[\"workflow\"] = resourceTestWorkflowName\n\tresponse[\"resource_type\"] = \"resource\"\n\tresponse[\"launch_plan\"] = \"launch_plan\"\n\tresponse[\"attributes\"] = []byte(\"attrs\")\n\n\tquery := GlobalMock.NewMock()\n\tquery.WithQuery(`SELECT * FROM \"resources\" WHERE \"resources\".\"project\" = $1 AND \"resources\".\"domain\" = $2 AND \"resources\".\"workflow\" = $3 AND \"resources\".\"launch_plan\" = $4 AND \"resources\".\"resource_type\" = $5 ORDER BY \"resources\".\"id\" LIMIT 1`).WithReply(\n\t\t[]map[string]interface{}{\n\t\t\tresponse,\n\t\t})\n\n\toutput, err := resourceRepo.GetRaw(context.Background(), interfaces.ResourceID{Project: \"project\", Domain: \"domain\", Workflow: \"workflow\", LaunchPlan: \"launch_plan\", ResourceType: \"resource\"})\n\tassert.Nil(t, err)\n\tassert.Equal(t, project, output.Project)\n\tassert.Equal(t, domain, output.Domain)\n\tassert.Equal(t, \"workflow\", output.Workflow)\n\tassert.Equal(t, \"launch_plan\", output.LaunchPlan)\n\tassert.Equal(t, \"resource\", output.ResourceType)\n\tassert.Equal(t, []byte(\"attrs\"), output.Attributes)\n}\n\nfunc TestDeleteWorkflowAttributes(t *testing.T) {\n\tresourceRepo := NewResourceRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\tGlobalMock := mocket.Catcher.Reset()\n\tGlobalMock.Logging = true\n\tquery := GlobalMock.NewMock()\n\tfakeResponse := query.WithQuery(\n\t\t`DELETE FROM \"resources\" WHERE \"resources\".\"project\" = $1 AND \"resources\".\"domain\" = $2 AND \"resources\".\"workflow\" = $3 AND \"resources\".\"launch_plan\" = $4 AND \"resources\".\"resource_type\" = $5`)\n\n\terr := resourceRepo.Delete(context.Background(), interfaces.ResourceID{Project: \"project\", Domain: \"domain\", Workflow: \"workflow\", LaunchPlan: \"launch_plan\", ResourceType: \"resource\"})\n\tassert.Nil(t, err)\n\tassert.True(t, fakeResponse.Triggered)\n}\n\nfunc TestListAll(t *testing.T) {\n\tresourceRepo := NewResourceRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\tGlobalMock := mocket.Catcher.Reset()\n\tGlobalMock.Logging = true\n\n\tquery := GlobalMock.NewMock()\n\n\tresponse := make(map[string]interface{})\n\tresponse[project] = project\n\tresponse[domain] = domain\n\tresponse[\"workflow\"] = resourceTestWorkflowName\n\tresponse[\"resource_type\"] = \"resource\"\n\tresponse[\"launch_plan\"] = \"launch_plan\"\n\tresponse[\"attributes\"] = []byte(\"attrs\")\n\n\tfakeResponse := query.WithQuery(`SELECT * FROM \"resources\" WHERE \"resources\".\"resource_type\" = $1 ORDER BY priority desc`).WithReply(\n\t\t[]map[string]interface{}{response})\n\toutput, err := resourceRepo.ListAll(context.Background(), \"resource\")\n\tassert.Nil(t, err)\n\tassert.Len(t, output, 1)\n\tassert.Equal(t, project, output[0].Project)\n\tassert.Equal(t, domain, output[0].Domain)\n\tassert.Equal(t, \"workflow\", output[0].Workflow)\n\tassert.Equal(t, \"launch_plan\", output[0].LaunchPlan)\n\tassert.Equal(t, \"resource\", output[0].ResourceType)\n\tassert.Equal(t, []byte(\"attrs\"), output[0].Attributes)\n\tassert.True(t, fakeResponse.Triggered)\n}\n\nfunc TestGetError(t *testing.T) {\n\tresourceRepo := NewResourceRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\tGlobalMock := mocket.Catcher.Reset()\n\tGlobalMock.Logging = true\n\n\tquery := GlobalMock.NewMock()\n\tquery.WithQuery(`SELECT * FROM \"resources\" WHERE resource_type = $1 AND domain IN ($2,$3) AND project IN ($4,$5) AND workflow IN ($6,$7) AND launch_plan IN ($8) ORDER BY priority desc,\"resources\".\"id\" LIMIT 1`).WithError(gorm.ErrRecordNotFound)\n\n\toutput, err := resourceRepo.Get(context.Background(), interfaces.ResourceID{Project: \"project\", Domain: \"domain\", Workflow: \"workflow\", ResourceType: \"resource\"})\n\tassert.Error(t, err)\n\tassert.Equal(t, \"\", output.Project)\n\tassert.Equal(t, \"\", output.Domain)\n\tassert.Equal(t, \"\", output.Workflow)\n}\n", "package gormimpl\n\nimport (\n\t\"context\"\n\t\"errors\"\n\n\t\"github.com/flyteorg/flytestdlib/promutils\"\n\t\"google.golang.org/grpc/codes\"\n\t\"gorm.io/gorm\"\n\n\tadminerrors \"github.com/flyteorg/flyteadmin/pkg/errors\"\n\tflyteAdminDbErrors \"github.com/flyteorg/flyteadmin/pkg/repositories/errors\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/interfaces\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/models\"\n)\n\n// SignalRepo is an implementation of SignalRepoInterface.\ntype SignalRepo struct {\n\tdb               *gorm.DB\n\terrorTransformer flyteAdminDbErrors.ErrorTransformer\n\tmetrics          gormMetrics\n}\n\n// Get retrieves a signal model from the database store.\nfunc (s *SignalRepo) Get(ctx context.Context, input models.SignalKey) (models.Signal, error) {\n\tvar signal models.Signal\n\ttimer := s.metrics.GetDuration.Start()\n\ttx := s.db.Where(&models.Signal{\n\t\tSignalKey: input,\n\t}).Take(&signal)\n\ttimer.Stop()\n\tif errors.Is(tx.Error, gorm.ErrRecordNotFound) {\n\t\treturn models.Signal{}, adminerrors.NewFlyteAdminError(codes.NotFound, \"signal does not exist\")\n\t}\n\tif tx.Error != nil {\n\t\treturn models.Signal{}, s.errorTransformer.ToFlyteAdminError(tx.Error)\n\t}\n\treturn signal, nil\n}\n\n// GetOrCreate returns a signal if it already exists, if not it creates a new one given the input\nfunc (s *SignalRepo) GetOrCreate(ctx context.Context, input *models.Signal) error {\n\ttimer := s.metrics.CreateDuration.Start()\n\ttx := s.db.FirstOrCreate(&input, input)\n\ttimer.Stop()\n\tif tx.Error != nil {\n\t\treturn s.errorTransformer.ToFlyteAdminError(tx.Error)\n\t}\n\treturn nil\n}\n\n// List fetches all signals that match the provided input\nfunc (s *SignalRepo) List(ctx context.Context, input interfaces.ListResourceInput) ([]models.Signal, error) {\n\t// First validate input.\n\tif err := ValidateListInput(input); err != nil {\n\t\treturn nil, err\n\t}\n\tvar signals []models.Signal\n\ttx := s.db.Limit(input.Limit).Offset(input.Offset)\n\n\t// Apply filters\n\ttx, err := applyFilters(tx, input.InlineFilters, input.MapFilters)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\t// Apply sort ordering.\n\tif input.SortParameter != nil {\n\t\ttx = tx.Order(input.SortParameter.GetGormOrderExpr())\n\t}\n\ttimer := s.metrics.ListDuration.Start()\n\ttx.Find(&signals)\n\ttimer.Stop()\n\tif tx.Error != nil {\n\t\treturn nil, s.errorTransformer.ToFlyteAdminError(tx.Error)\n\t}\n\n\treturn signals, nil\n}\n\n// Update sets the value field on the specified signal model\nfunc (s *SignalRepo) Update(ctx context.Context, input models.SignalKey, value []byte) error {\n\tsignal := models.Signal{\n\t\tSignalKey: input,\n\t\tValue:     value,\n\t}\n\n\ttimer := s.metrics.GetDuration.Start()\n\ttx := s.db.Model(&signal).Select(\"value\").Updates(signal)\n\ttimer.Stop()\n\tif tx.Error != nil {\n\t\treturn s.errorTransformer.ToFlyteAdminError(tx.Error)\n\t}\n\tif tx.RowsAffected == 0 {\n\t\treturn adminerrors.NewFlyteAdminError(codes.NotFound, \"signal does not exist\")\n\t}\n\treturn nil\n}\n\n// Returns an instance of SignalRepoInterface\nfunc NewSignalRepo(\n\tdb *gorm.DB, errorTransformer flyteAdminDbErrors.ErrorTransformer, scope promutils.Scope) interfaces.SignalRepoInterface {\n\tmetrics := newMetrics(scope)\n\treturn &SignalRepo{\n\t\tdb:               db,\n\t\terrorTransformer: errorTransformer,\n\t\tmetrics:          metrics,\n\t}\n}\n", "package gormimpl\n\nimport (\n\t\"context\"\n\t\"errors\"\n\n\t\"github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/core\"\n\t\"github.com/flyteorg/flytestdlib/promutils\"\n\t\"gorm.io/gorm\"\n\n\tflyteAdminDbErrors \"github.com/flyteorg/flyteadmin/pkg/repositories/errors\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/interfaces\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/models\"\n)\n\n// Implementation of TaskExecutionInterface.\ntype TaskExecutionRepo struct {\n\tdb               *gorm.DB\n\terrorTransformer flyteAdminDbErrors.ErrorTransformer\n\tmetrics          gormMetrics\n}\n\nfunc (r *TaskExecutionRepo) Create(ctx context.Context, input models.TaskExecution) error {\n\ttimer := r.metrics.CreateDuration.Start()\n\ttx := r.db.Omit(\"id\").Create(&input)\n\ttimer.Stop()\n\tif tx.Error != nil {\n\t\treturn r.errorTransformer.ToFlyteAdminError(tx.Error)\n\t}\n\treturn nil\n}\n\nfunc (r *TaskExecutionRepo) Get(ctx context.Context, input interfaces.GetTaskExecutionInput) (models.TaskExecution, error) {\n\tvar taskExecution models.TaskExecution\n\ttimer := r.metrics.GetDuration.Start()\n\ttx := r.db.Where(&models.TaskExecution{\n\t\tTaskExecutionKey: models.TaskExecutionKey{\n\t\t\tTaskKey: models.TaskKey{\n\t\t\t\tProject: input.TaskExecutionID.TaskId.Project,\n\t\t\t\tDomain:  input.TaskExecutionID.TaskId.Domain,\n\t\t\t\tName:    input.TaskExecutionID.TaskId.Name,\n\t\t\t\tVersion: input.TaskExecutionID.TaskId.Version,\n\t\t\t},\n\t\t\tNodeExecutionKey: models.NodeExecutionKey{\n\t\t\t\tNodeID: input.TaskExecutionID.NodeExecutionId.NodeId,\n\t\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\t\tProject: input.TaskExecutionID.NodeExecutionId.ExecutionId.Project,\n\t\t\t\t\tDomain:  input.TaskExecutionID.NodeExecutionId.ExecutionId.Domain,\n\t\t\t\t\tName:    input.TaskExecutionID.NodeExecutionId.ExecutionId.Name,\n\t\t\t\t},\n\t\t\t},\n\t\t\tRetryAttempt: &input.TaskExecutionID.RetryAttempt,\n\t\t},\n\t}).Preload(\"ChildNodeExecution\").Take(&taskExecution)\n\ttimer.Stop()\n\n\tif tx.Error != nil && errors.Is(tx.Error, gorm.ErrRecordNotFound) {\n\t\treturn models.TaskExecution{},\n\t\t\tflyteAdminDbErrors.GetMissingEntityError(\"task execution\", &core.TaskExecutionIdentifier{\n\t\t\t\tTaskId: &core.Identifier{\n\t\t\t\t\tProject: input.TaskExecutionID.TaskId.Project,\n\t\t\t\t\tDomain:  input.TaskExecutionID.TaskId.Domain,\n\t\t\t\t\tName:    input.TaskExecutionID.TaskId.Name,\n\t\t\t\t\tVersion: input.TaskExecutionID.TaskId.Version,\n\t\t\t\t},\n\t\t\t\tNodeExecutionId: &core.NodeExecutionIdentifier{\n\t\t\t\t\tNodeId: input.TaskExecutionID.NodeExecutionId.NodeId,\n\t\t\t\t\tExecutionId: &core.WorkflowExecutionIdentifier{\n\t\t\t\t\t\tProject: input.TaskExecutionID.NodeExecutionId.ExecutionId.Project,\n\t\t\t\t\t\tDomain:  input.TaskExecutionID.NodeExecutionId.ExecutionId.Domain,\n\t\t\t\t\t\tName:    input.TaskExecutionID.NodeExecutionId.ExecutionId.Name,\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t})\n\t} else if tx.Error != nil {\n\t\treturn models.TaskExecution{}, r.errorTransformer.ToFlyteAdminError(tx.Error)\n\t}\n\treturn taskExecution, nil\n}\n\nfunc (r *TaskExecutionRepo) Update(ctx context.Context, execution models.TaskExecution) error {\n\ttimer := r.metrics.UpdateDuration.Start()\n\ttx := r.db.Save(&execution)\n\ttimer.Stop()\n\n\tif err := tx.Error; err != nil {\n\t\treturn r.errorTransformer.ToFlyteAdminError(err)\n\t}\n\treturn nil\n}\n\nfunc (r *TaskExecutionRepo) List(ctx context.Context, input interfaces.ListResourceInput) (interfaces.TaskExecutionCollectionOutput, error) {\n\tif err := ValidateListInput(input); err != nil {\n\t\treturn interfaces.TaskExecutionCollectionOutput{}, err\n\t}\n\n\tvar taskExecutions []models.TaskExecution\n\ttx := r.db.Limit(input.Limit).Offset(input.Offset).Preload(\"ChildNodeExecution\")\n\n\t// And add three join conditions (joining multiple tables is fine even we only filter on a subset of table attributes).\n\t// We are joining on task -> taskExec -> NodeExec -> Exec.\n\t// NOTE: the order in which the joins are called below are important because postgres will only know about certain\n\t// tables as they are joined. So we should do it in the order specified above.\n\ttx = tx.Joins(leftJoinTaskToTaskExec)\n\ttx = tx.Joins(innerJoinNodeExecToTaskExec)\n\ttx = tx.Joins(innerJoinExecToNodeExec)\n\n\t// Apply filters\n\ttx, err := applyScopedFilters(tx, input.InlineFilters, input.MapFilters)\n\tif err != nil {\n\t\treturn interfaces.TaskExecutionCollectionOutput{}, err\n\t}\n\n\t// Apply sort ordering.\n\tif input.SortParameter != nil {\n\t\ttx = tx.Order(input.SortParameter.GetGormOrderExpr())\n\t}\n\n\ttimer := r.metrics.ListDuration.Start()\n\ttx = tx.Find(&taskExecutions)\n\ttimer.Stop()\n\tif tx.Error != nil {\n\t\treturn interfaces.TaskExecutionCollectionOutput{}, r.errorTransformer.ToFlyteAdminError(tx.Error)\n\t}\n\n\treturn interfaces.TaskExecutionCollectionOutput{\n\t\tTaskExecutions: taskExecutions,\n\t}, nil\n}\n\nfunc (r *TaskExecutionRepo) Count(ctx context.Context, input interfaces.CountResourceInput) (int64, error) {\n\tvar err error\n\ttx := r.db.Model(&models.TaskExecution{})\n\n\t// Add three join conditions (joining multiple tables is fine even we only filter on a subset of table attributes).\n\t// We are joining on task -> taskExec -> NodeExec -> Exec.\n\t// NOTE: the order in which the joins are called below are important because postgres will only know about certain\n\t// tables as they are joined. So we should do it in the order specified above.\n\ttx = tx.Joins(leftJoinTaskToTaskExec)\n\ttx = tx.Joins(innerJoinNodeExecToTaskExec)\n\ttx = tx.Joins(innerJoinExecToNodeExec)\n\n\t// Apply filters\n\ttx, err = applyScopedFilters(tx, input.InlineFilters, input.MapFilters)\n\tif err != nil {\n\t\treturn 0, err\n\t}\n\n\t// Run the query\n\ttimer := r.metrics.CountDuration.Start()\n\tvar count int64\n\ttx = tx.Count(&count)\n\ttimer.Stop()\n\tif tx.Error != nil {\n\t\treturn 0, r.errorTransformer.ToFlyteAdminError(tx.Error)\n\t}\n\treturn count, nil\n}\n\n// Returns an instance of TaskExecutionRepoInterface\nfunc NewTaskExecutionRepo(\n\tdb *gorm.DB, errorTransformer flyteAdminDbErrors.ErrorTransformer, scope promutils.Scope) interfaces.TaskExecutionRepoInterface {\n\tmetrics := newMetrics(scope)\n\treturn &TaskExecutionRepo{\n\t\tdb:               db,\n\t\terrorTransformer: errorTransformer,\n\t\tmetrics:          metrics,\n\t}\n}\n", "package gormimpl\n\nimport (\n\t\"context\"\n\t\"testing\"\n\t\"time\"\n\n\tmocket \"github.com/Selvatico/go-mocket\"\n\t\"github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/core\"\n\tmockScope \"github.com/flyteorg/flytestdlib/promutils\"\n\t\"github.com/stretchr/testify/assert\"\n\n\t\"github.com/flyteorg/flyteadmin/pkg/common\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/errors\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/interfaces\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/models\"\n)\n\nvar taskPhase = core.TaskExecution_ABORTED.String()\n\nvar taskCreatedAt = time.Date(2018, time.January, 1, 00, 00, 00, 00, time.UTC)\nvar taskUpdatedAt = time.Date(2018, time.January, 1, 02, 00, 00, 00, time.UTC)\nvar taskStartedAt = time.Date(2018, time.January, 1, 01, 00, 00, 00, time.UTC)\n\nvar retryAttemptValue = uint32(4)\n\nvar testTaskExecution = models.TaskExecution{\n\tTaskExecutionKey: models.TaskExecutionKey{\n\t\tTaskKey: models.TaskKey{\n\t\t\tProject: \"task project\",\n\t\t\tDomain:  \"task domain\",\n\t\t\tName:    \"task name\",\n\t\t\tVersion: \"task version\",\n\t\t},\n\t\tNodeExecutionKey: models.NodeExecutionKey{\n\t\t\tNodeID: \"2\",\n\t\t\tExecutionKey: models.ExecutionKey{\n\t\t\t\tProject: \"exec project\",\n\t\t\t\tDomain:  \"exec domain\",\n\t\t\t\tName:    \"exec name\",\n\t\t\t},\n\t\t},\n\t\tRetryAttempt: &retryAttemptValue,\n\t},\n\tPhase:                  taskPhase,\n\tInputURI:               \"testInput.pb\",\n\tStartedAt:              &taskStartedAt,\n\tDuration:               time.Hour,\n\tClosure:                []byte(\"Test\"),\n\tTaskExecutionCreatedAt: &taskCreatedAt,\n\tTaskExecutionUpdatedAt: &taskUpdatedAt,\n}\n\nfunc getMockTaskExecutionResponseFromDb(expected models.TaskExecution) map[string]interface{} {\n\ttaskExecution := make(map[string]interface{})\n\ttaskExecution[\"project\"] = expected.TaskKey.Project\n\ttaskExecution[\"domain\"] = expected.TaskKey.Domain\n\ttaskExecution[\"name\"] = expected.TaskKey.Name\n\ttaskExecution[\"version\"] = expected.TaskKey.Version\n\ttaskExecution[\"node_id\"] = expected.NodeExecutionKey.NodeID\n\ttaskExecution[\"execution_project\"] = expected.NodeExecutionKey.ExecutionKey.Project\n\ttaskExecution[\"execution_domain\"] = expected.NodeExecutionKey.ExecutionKey.Domain\n\ttaskExecution[\"execution_name\"] = expected.NodeExecutionKey.ExecutionKey.Name\n\ttaskExecution[\"retry_attempt\"] = expected.TaskExecutionKey.RetryAttempt\n\n\ttaskExecution[\"phase\"] = expected.Phase\n\ttaskExecution[\"input_uri\"] = expected.InputURI\n\ttaskExecution[\"started_at\"] = expected.StartedAt\n\ttaskExecution[\"duration\"] = expected.Duration\n\ttaskExecution[\"closure\"] = expected.Closure\n\ttaskExecution[\"task_execution_created_at\"] = expected.TaskExecutionCreatedAt\n\ttaskExecution[\"task_execution_updated_at\"] = expected.TaskExecutionUpdatedAt\n\treturn taskExecution\n}\n\nfunc TestCreateTaskExecution(t *testing.T) {\n\ttaskExecutionRepo := NewTaskExecutionRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\terr := taskExecutionRepo.Create(context.Background(), testTaskExecution)\n\tassert.NoError(t, err)\n}\n\nfunc TestUpdateTaskExecution(t *testing.T) {\n\ttaskExecutionRepo := NewTaskExecutionRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\tGlobalMock := mocket.Catcher.Reset()\n\tGlobalMock.Logging = true\n\n\ttaskExecutionQuery := GlobalMock.NewMock()\n\ttaskExecutionQuery.WithQuery(`UPDATE \"task_executions\" SET \"id\"=$1,\"created_at\"=$2,\"updated_at\"=$3,\"deleted_at\"=$4,\"phase\"=$5,\"phase_version\"=$6,\"input_uri\"=$7,\"closure\"=$8,\"started_at\"=$9,\"task_execution_created_at\"=$10,\"task_execution_updated_at\"=$11,\"duration\"=$12 WHERE \"project\" = $13 AND \"domain\" = $14 AND \"name\" = $15 AND \"version\" = $16 AND \"execution_project\" = $17 AND \"execution_domain\" = $18 AND \"execution_name\" = $19 AND \"node_id\" = $20 AND \"retry_attempt\" = $21`)\n\terr := taskExecutionRepo.Update(context.Background(), testTaskExecution)\n\tassert.NoError(t, err)\n\tassert.True(t, taskExecutionQuery.Triggered)\n}\n\nfunc TestGetTaskExecution(t *testing.T) {\n\ttaskExecutionRepo := NewTaskExecutionRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\n\ttaskExecutions := make([]map[string]interface{}, 0)\n\ttaskExecution := getMockTaskExecutionResponseFromDb(testTaskExecution)\n\ttaskExecutions = append(taskExecutions, taskExecution)\n\tGlobalMock := mocket.Catcher.Reset()\n\tGlobalMock.Logging = true\n\tGlobalMock.NewMock().WithQuery(\n\t\t`SELECT * FROM \"task_executions\" WHERE \"task_executions\".\"project\" = $1 AND \"task_executions\".\"domain\" = $2 AND \"task_executions\".\"name\" = $3 AND \"task_executions\".\"version\" = $4 AND \"task_executions\".\"execution_project\" = $5 AND \"task_executions\".\"execution_domain\" = $6 AND \"task_executions\".\"execution_name\" = $7 AND \"task_executions\".\"node_id\" = $8 AND \"task_executions\".\"retry_attempt\" = $9 LIMIT 1`).\n\t\tWithReply(taskExecutions)\n\n\toutput, err := taskExecutionRepo.Get(context.Background(), interfaces.GetTaskExecutionInput{\n\t\tTaskExecutionID: core.TaskExecutionIdentifier{\n\t\t\tTaskId: &core.Identifier{\n\t\t\t\tResourceType: core.ResourceType_TASK,\n\t\t\t\tProject:      \"project\",\n\t\t\t\tDomain:       \"domain\",\n\t\t\t\tName:         \"task-id\",\n\t\t\t\tVersion:      \"task-version\",\n\t\t\t},\n\t\t\tNodeExecutionId: &core.NodeExecutionIdentifier{\n\t\t\t\tNodeId: \"node-id\",\n\t\t\t\tExecutionId: &core.WorkflowExecutionIdentifier{\n\t\t\t\t\tProject: \"project\",\n\t\t\t\t\tDomain:  \"domain\",\n\t\t\t\t\tName:    \"name\",\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t})\n\tassert.NoError(t, err)\n\tassert.EqualValues(t, testTaskExecution, output)\n}\n\nfunc TestListTaskExecutionForExecution(t *testing.T) {\n\ttaskExecutionRepo := NewTaskExecutionRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\n\ttaskExecutions := make([]map[string]interface{}, 0)\n\ttaskExecution := getMockTaskExecutionResponseFromDb(testTaskExecution)\n\ttaskExecutions = append(taskExecutions, taskExecution)\n\tGlobalMock := mocket.Catcher.Reset()\n\tGlobalMock.Logging = true\n\tGlobalMock.NewMock().WithQuery(`SELECT \"task_executions\".\"id\",\"task_executions\".\"created_at\",\"task_executions\".\"updated_at\",\"task_executions\".\"deleted_at\",\"task_executions\".\"project\",\"task_executions\".\"domain\",\"task_executions\".\"name\",\"task_executions\".\"version\",\"task_executions\".\"execution_project\",\"task_executions\".\"execution_domain\",\"task_executions\".\"execution_name\",\"task_executions\".\"node_id\",\"task_executions\".\"retry_attempt\",\"task_executions\".\"phase\",\"task_executions\".\"phase_version\",\"task_executions\".\"input_uri\",\"task_executions\".\"closure\",\"task_executions\".\"started_at\",\"task_executions\".\"task_execution_created_at\",\"task_executions\".\"task_execution_updated_at\",\"task_executions\".\"duration\" FROM \"task_executions\" LEFT JOIN tasks ON task_executions.project = tasks.project AND task_executions.domain = tasks.domain AND task_executions.name = tasks.name AND task_executions.version = tasks.version INNER JOIN node_executions ON task_executions.node_id = node_executions.node_id AND task_executions.execution_project = node_executions.execution_project AND task_executions.execution_domain = node_executions.execution_domain AND task_executions.execution_name = node_executions.execution_name INNER JOIN executions ON node_executions.execution_project = executions.execution_project AND node_executions.execution_domain = executions.execution_domain AND node_executions.execution_name = executions.execution_name WHERE executions.execution_project = $1 AND executions.execution_domain = $2 AND executions.execution_name = $3 LIMIT 20`).WithReply(taskExecutions)\n\n\tcollection, err := taskExecutionRepo.List(context.Background(), interfaces.ListResourceInput{\n\t\tInlineFilters: []common.InlineFilter{\n\t\t\tgetEqualityFilter(common.Execution, \"project\", \"project_name\"),\n\t\t\tgetEqualityFilter(common.Execution, \"domain\", \"domain_name\"),\n\t\t\tgetEqualityFilter(common.Execution, \"name\", \"execution_name\"),\n\t\t},\n\t\tLimit: 20,\n\t})\n\n\tassert.NoError(t, err)\n\tassert.NotEmpty(t, collection)\n\tassert.NotEmpty(t, collection.TaskExecutions)\n\tassert.Len(t, collection.TaskExecutions, 1)\n\n\tfor _, taskExecution := range collection.TaskExecutions {\n\t\tassert.Equal(t, testTaskExecution.TaskExecutionKey, taskExecution.TaskExecutionKey)\n\t\tassert.Equal(t, taskPhase, taskExecution.Phase)\n\t\tassert.Equal(t, []byte(\"Test\"), taskExecution.Closure)\n\t\tassert.Equal(t, \"testInput.pb\", taskExecution.InputURI)\n\t\tassert.Equal(t, taskStartedAt, *taskExecution.StartedAt)\n\t\tassert.Equal(t, time.Hour, taskExecution.Duration)\n\t}\n}\n\nfunc TestListTaskExecutionsForTaskExecution(t *testing.T) {\n\ttaskExecutionRepo := NewTaskExecutionRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\n\ttaskExecutions := make([]map[string]interface{}, 0)\n\ttaskExecution := getMockTaskExecutionResponseFromDb(testTaskExecution)\n\ttaskExecutions = append(taskExecutions, taskExecution)\n\n\tGlobalMock := mocket.Catcher.Reset()\n\tGlobalMock.Logging = true\n\n\tGlobalMock.NewMock().WithQuery(`SELECT \"task_executions\".\"id\",\"task_executions\".\"created_at\",\"task_executions\".\"updated_at\",\"task_executions\".\"deleted_at\",\"task_executions\".\"project\",\"task_executions\".\"domain\",\"task_executions\".\"name\",\"task_executions\".\"version\",\"task_executions\".\"execution_project\",\"task_executions\".\"execution_domain\",\"task_executions\".\"execution_name\",\"task_executions\".\"node_id\",\"task_executions\".\"retry_attempt\",\"task_executions\".\"phase\",\"task_executions\".\"phase_version\",\"task_executions\".\"input_uri\",\"task_executions\".\"closure\",\"task_executions\".\"started_at\",\"task_executions\".\"task_execution_created_at\",\"task_executions\".\"task_execution_updated_at\",\"task_executions\".\"duration\" FROM \"task_executions\" LEFT JOIN tasks ON task_executions.project = tasks.project AND task_executions.domain = tasks.domain AND task_executions.name = tasks.name AND task_executions.version = tasks.version INNER JOIN node_executions ON task_executions.node_id = node_executions.node_id AND task_executions.execution_project = node_executions.execution_project AND task_executions.execution_domain = node_executions.execution_domain AND task_executions.execution_name = node_executions.execution_name INNER JOIN executions ON node_executions.execution_project = executions.execution_project AND node_executions.execution_domain = executions.execution_domain AND node_executions.execution_name = executions.execution_name WHERE tasks.project = $1 AND tasks.domain = $2 AND tasks.name = $3 AND tasks.version = $4 AND node_executions.phase = $5 AND executions.execution_project = $6 AND executions.execution_domain = $7 AND executions.execution_name = $8 LIMIT 20`).WithReply(taskExecutions)\n\n\tcollection, err := taskExecutionRepo.List(context.Background(), interfaces.ListResourceInput{\n\t\tInlineFilters: []common.InlineFilter{\n\t\t\tgetEqualityFilter(common.Task, \"project\", \"project_tn\"),\n\t\t\tgetEqualityFilter(common.Task, \"domain\", \"domain_t\"),\n\t\t\tgetEqualityFilter(common.Task, \"name\", \"domain_t\"),\n\t\t\tgetEqualityFilter(common.Task, \"version\", \"version_t\"),\n\n\t\t\tgetEqualityFilter(common.NodeExecution, \"phase\", nodePhase),\n\t\t\tgetEqualityFilter(common.Execution, \"project\", \"project_name\"),\n\t\t\tgetEqualityFilter(common.Execution, \"domain\", \"domain_name\"),\n\t\t\tgetEqualityFilter(common.Execution, \"name\", \"execution_name\"),\n\t\t},\n\t\tLimit: 20,\n\t})\n\tassert.NoError(t, err)\n\tassert.NotEmpty(t, collection)\n\tassert.NotEmpty(t, collection.TaskExecutions)\n\tassert.Len(t, collection.TaskExecutions, 1)\n\n\tfor _, taskExecution := range collection.TaskExecutions {\n\t\tassert.Equal(t, testTaskExecution.TaskExecutionKey, taskExecution.TaskExecutionKey)\n\t\tassert.Equal(t, &retryAttemptValue, taskExecution.RetryAttempt)\n\t\tassert.Equal(t, taskPhase, taskExecution.Phase)\n\t\tassert.Equal(t, []byte(\"Test\"), taskExecution.Closure)\n\t\tassert.Equal(t, \"testInput.pb\", taskExecution.InputURI)\n\t\tassert.Equal(t, taskStartedAt, *taskExecution.StartedAt)\n\t\tassert.Equal(t, time.Hour, taskExecution.Duration)\n\t}\n}\n\nfunc TestCountTaskExecutions(t *testing.T) {\n\ttaskExecutionRepo := NewTaskExecutionRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\n\tGlobalMock := mocket.Catcher.Reset()\n\tGlobalMock.NewMock().WithQuery(\n\t\t`SELECT count(*) FROM \"task_executions\"`).WithReply([]map[string]interface{}{{\"rows\": 2}})\n\n\tcount, err := taskExecutionRepo.Count(context.Background(), interfaces.CountResourceInput{})\n\tassert.NoError(t, err)\n\tassert.Equal(t, int64(2), count)\n}\n\nfunc TestCountTaskExecutions_Filters(t *testing.T) {\n\ttaskExecutionRepo := NewTaskExecutionRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\n\tGlobalMock := mocket.Catcher.Reset()\n\tGlobalMock.NewMock().WithQuery(\n\t\t`SELECT count(*) FROM \"task_executions\" LEFT JOIN tasks ON task_executions.project = tasks.project AND task_executions.domain = tasks.domain AND task_executions.name = tasks.name AND task_executions.version = tasks.version INNER JOIN node_executions ON task_executions.node_id = node_executions.node_id AND task_executions.execution_project = node_executions.execution_project AND task_executions.execution_domain = node_executions.execution_domain AND task_executions.execution_name = node_executions.execution_name INNER JOIN executions ON node_executions.execution_project = executions.execution_project AND node_executions.execution_domain = executions.execution_domain AND node_executions.execution_name = executions.execution_name WHERE task_executions.phase = $1 AND \"task_execution_updated_at\" IS NULL`).WithReply([]map[string]interface{}{{\"rows\": 3}})\n\n\tcount, err := taskExecutionRepo.Count(context.Background(), interfaces.CountResourceInput{\n\t\tInlineFilters: []common.InlineFilter{\n\t\t\tgetEqualityFilter(common.TaskExecution, \"phase\", core.TaskExecution_FAILED.String()),\n\t\t},\n\t\tMapFilters: []common.MapFilter{\n\t\t\tcommon.NewMapFilter(map[string]interface{}{\n\t\t\t\t\"task_execution_updated_at\": nil,\n\t\t\t}),\n\t\t},\n\t})\n\tassert.NoError(t, err)\n\tassert.Equal(t, int64(3), count)\n}\n", "package gormimpl\n\nimport (\n\t\"context\"\n\t\"errors\"\n\n\t\"github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/core\"\n\t\"github.com/flyteorg/flytestdlib/promutils\"\n\t\"gorm.io/gorm\"\n\n\tflyteAdminDbErrors \"github.com/flyteorg/flyteadmin/pkg/repositories/errors\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/interfaces\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/models\"\n)\n\n// Implementation of TaskRepoInterface.\ntype TaskRepo struct {\n\tdb               *gorm.DB\n\terrorTransformer flyteAdminDbErrors.ErrorTransformer\n\tmetrics          gormMetrics\n}\n\nfunc (r *TaskRepo) Create(_ context.Context, input models.Task, descriptionEntity *models.DescriptionEntity) error {\n\ttimer := r.metrics.CreateDuration.Start()\n\terr := r.db.Transaction(func(_ *gorm.DB) error {\n\t\tif descriptionEntity == nil {\n\t\t\ttx := r.db.Omit(\"id\").Create(&input)\n\t\t\tif tx.Error != nil {\n\t\t\t\treturn r.errorTransformer.ToFlyteAdminError(tx.Error)\n\t\t\t}\n\t\t\treturn nil\n\t\t}\n\t\ttx := r.db.Omit(\"id\").Create(descriptionEntity)\n\t\tif tx.Error != nil {\n\t\t\treturn r.errorTransformer.ToFlyteAdminError(tx.Error)\n\t\t}\n\n\t\ttx = r.db.Omit(\"id\").Create(&input)\n\t\tif tx.Error != nil {\n\t\t\treturn r.errorTransformer.ToFlyteAdminError(tx.Error)\n\t\t}\n\n\t\treturn nil\n\t})\n\ttimer.Stop()\n\treturn err\n}\n\nfunc (r *TaskRepo) Get(ctx context.Context, input interfaces.Identifier) (models.Task, error) {\n\tvar task models.Task\n\ttimer := r.metrics.GetDuration.Start()\n\ttx := r.db.Where(&models.Task{\n\t\tTaskKey: models.TaskKey{\n\t\t\tProject: input.Project,\n\t\t\tDomain:  input.Domain,\n\t\t\tName:    input.Name,\n\t\t\tVersion: input.Version,\n\t\t},\n\t}).Take(&task)\n\ttimer.Stop()\n\tif errors.Is(tx.Error, gorm.ErrRecordNotFound) {\n\t\treturn models.Task{}, flyteAdminDbErrors.GetMissingEntityError(core.ResourceType_TASK.String(), &core.Identifier{\n\t\t\tProject: input.Project,\n\t\t\tDomain:  input.Domain,\n\t\t\tName:    input.Name,\n\t\t\tVersion: input.Version,\n\t\t})\n\t}\n\n\tif tx.Error != nil {\n\t\treturn models.Task{}, r.errorTransformer.ToFlyteAdminError(tx.Error)\n\t}\n\treturn task, nil\n}\n\nfunc (r *TaskRepo) List(\n\tctx context.Context, input interfaces.ListResourceInput) (interfaces.TaskCollectionOutput, error) {\n\t// First validate input.\n\tif err := ValidateListInput(input); err != nil {\n\t\treturn interfaces.TaskCollectionOutput{}, err\n\t}\n\tvar tasks []models.Task\n\ttx := r.db.Limit(input.Limit).Offset(input.Offset)\n\t// Apply filters\n\ttx, err := applyFilters(tx, input.InlineFilters, input.MapFilters)\n\tif err != nil {\n\t\treturn interfaces.TaskCollectionOutput{}, err\n\t}\n\t// Apply sort ordering.\n\tif input.SortParameter != nil {\n\t\ttx = tx.Order(input.SortParameter.GetGormOrderExpr())\n\t}\n\ttimer := r.metrics.ListDuration.Start()\n\ttx.Find(&tasks)\n\ttimer.Stop()\n\tif tx.Error != nil {\n\t\treturn interfaces.TaskCollectionOutput{}, r.errorTransformer.ToFlyteAdminError(tx.Error)\n\t}\n\n\treturn interfaces.TaskCollectionOutput{\n\t\tTasks: tasks,\n\t}, nil\n}\n\nfunc (r *TaskRepo) ListTaskIdentifiers(ctx context.Context, input interfaces.ListResourceInput) (\n\tinterfaces.TaskCollectionOutput, error) {\n\n\t// Validate input.\n\tif err := ValidateListInput(input); err != nil {\n\t\treturn interfaces.TaskCollectionOutput{}, err\n\t}\n\n\ttx := r.db.Model(models.Task{}).Limit(input.Limit).Offset(input.Offset)\n\n\t// Apply filters\n\ttx, err := applyFilters(tx, input.InlineFilters, input.MapFilters)\n\tif err != nil {\n\t\treturn interfaces.TaskCollectionOutput{}, err\n\t}\n\tfor _, mapFilter := range input.MapFilters {\n\t\ttx = tx.Where(mapFilter.GetFilter())\n\t}\n\t// Apply sort ordering.\n\tif input.SortParameter != nil {\n\t\ttx = tx.Order(input.SortParameter.GetGormOrderExpr())\n\t}\n\n\t// Scan the results into a list of tasks\n\tvar tasks []models.Task\n\ttimer := r.metrics.ListIdentifiersDuration.Start()\n\ttx.Select([]string{Project, Domain, Name}).Group(identifierGroupBy).Scan(&tasks)\n\ttimer.Stop()\n\tif tx.Error != nil {\n\t\treturn interfaces.TaskCollectionOutput{}, r.errorTransformer.ToFlyteAdminError(tx.Error)\n\t}\n\n\treturn interfaces.TaskCollectionOutput{\n\t\tTasks: tasks,\n\t}, nil\n}\n\n// Returns an instance of TaskRepoInterface\nfunc NewTaskRepo(\n\tdb *gorm.DB, errorTransformer flyteAdminDbErrors.ErrorTransformer, scope promutils.Scope) interfaces.TaskRepoInterface {\n\tmetrics := newMetrics(scope)\n\treturn &TaskRepo{\n\t\tdb:               db,\n\t\terrorTransformer: errorTransformer,\n\t\tmetrics:          metrics,\n\t}\n}\n", "package gormimpl\n\nimport (\n\t\"context\"\n\t\"testing\"\n\n\tmockScope \"github.com/flyteorg/flytestdlib/promutils\"\n\n\t\"github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/admin\"\n\n\tmocket \"github.com/Selvatico/go-mocket\"\n\t\"github.com/stretchr/testify/assert\"\n\n\t\"github.com/flyteorg/flyteadmin/pkg/common\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/errors\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/interfaces\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/models\"\n)\n\nconst pythonTestTaskType = \"python-task\"\n\nfunc TestCreateTask(t *testing.T) {\n\ttaskRepo := NewTaskRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\terr := taskRepo.Create(context.Background(), models.Task{\n\t\tTaskKey: models.TaskKey{\n\t\t\tProject: project,\n\t\t\tDomain:  domain,\n\t\t\tName:    name,\n\t\t\tVersion: version,\n\t\t},\n\t\tClosure: []byte{1, 2},\n\t\tType:    pythonTestTaskType,\n\t}, &models.DescriptionEntity{ShortDescription: \"hello\"})\n\tassert.NoError(t, err)\n}\n\nfunc getMockTaskResponseFromDb(version string, spec []byte) map[string]interface{} {\n\ttask := make(map[string]interface{})\n\ttask[\"project\"] = project\n\ttask[\"domain\"] = domain\n\ttask[\"name\"] = name\n\ttask[\"version\"] = version\n\ttask[\"closure\"] = spec\n\ttask[\"type\"] = pythonTestTaskType\n\treturn task\n}\n\nfunc TestGetTask(t *testing.T) {\n\ttaskRepo := NewTaskRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\n\ttasks := make([]map[string]interface{}, 0)\n\ttask := getMockTaskResponseFromDb(version, []byte{1, 2})\n\ttasks = append(tasks, task)\n\n\toutput, err := taskRepo.Get(context.Background(), interfaces.Identifier{\n\t\tProject: project,\n\t\tDomain:  domain,\n\t\tName:    name,\n\t\tVersion: version,\n\t})\n\tassert.Empty(t, output)\n\tassert.EqualError(t, err, \"missing entity of type TASK with identifier project:\\\"project\\\" domain:\\\"domain\\\" name:\\\"name\\\" version:\\\"XYZ\\\" \")\n\n\tGlobalMock := mocket.Catcher.Reset()\n\tGlobalMock.Logging = true\n\t// Only match on queries that append expected filters\n\tGlobalMock.NewMock().WithQuery(\n\t\t`SELECT * FROM \"tasks\" WHERE \"tasks\".\"project\" = $1 AND \"tasks\".\"domain\" = $2 AND \"tasks\".\"name\" = $3 AND \"tasks\".\"version\" = $4 LIMIT 1`).\n\t\tWithReply(tasks)\n\toutput, err = taskRepo.Get(context.Background(), interfaces.Identifier{\n\t\tProject: project,\n\t\tDomain:  domain,\n\t\tName:    name,\n\t\tVersion: version,\n\t})\n\tassert.Empty(t, err)\n\tassert.Equal(t, project, output.Project)\n\tassert.Equal(t, domain, output.Domain)\n\tassert.Equal(t, name, output.Name)\n\tassert.Equal(t, version, output.Version)\n\tassert.Equal(t, []byte{1, 2}, output.Closure)\n\tassert.Equal(t, pythonTestTaskType, output.Type)\n}\n\nfunc TestListTasks(t *testing.T) {\n\ttaskRepo := NewTaskRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\n\ttasks := make([]map[string]interface{}, 0)\n\tversions := []string{\"ABC\", \"XYZ\"}\n\tspec := []byte{1, 2}\n\tfor _, version := range versions {\n\t\ttask := getMockTaskResponseFromDb(version, spec)\n\t\ttasks = append(tasks, task)\n\t}\n\n\tGlobalMock := mocket.Catcher.Reset()\n\tGlobalMock.NewMock().WithReply(tasks)\n\n\tcollection, err := taskRepo.List(context.Background(), interfaces.ListResourceInput{\n\t\tInlineFilters: []common.InlineFilter{\n\t\t\tgetEqualityFilter(common.Task, \"project\", project),\n\t\t\tgetEqualityFilter(common.Task, \"domain\", domain),\n\t\t\tgetEqualityFilter(common.Task, \"name\", name),\n\t\t},\n\t\tLimit: 20,\n\t})\n\tassert.Empty(t, err)\n\tassert.NotEmpty(t, collection)\n\tassert.NotEmpty(t, collection.Tasks)\n\tassert.Len(t, collection.Tasks, 2)\n\tfor _, task := range collection.Tasks {\n\t\tassert.Equal(t, project, task.Project)\n\t\tassert.Equal(t, domain, task.Domain)\n\t\tassert.Equal(t, name, task.Name)\n\t\tassert.Contains(t, versions, task.Version)\n\t\tassert.Equal(t, spec, task.Closure)\n\t\tassert.Equal(t, pythonTestTaskType, task.Type)\n\t}\n}\n\nfunc TestListTasks_Pagination(t *testing.T) {\n\ttaskRepo := NewTaskRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\n\ttasks := make([]map[string]interface{}, 0)\n\tversions := []string{\"ABC\", \"DEF\"}\n\tspec := []byte{1, 2}\n\tfor _, version := range versions {\n\t\ttask := getMockTaskResponseFromDb(version, spec)\n\t\ttasks = append(tasks, task)\n\t}\n\n\tGlobalMock := mocket.Catcher.Reset()\n\tGlobalMock.NewMock().WithReply(tasks)\n\n\tcollection, err := taskRepo.List(context.Background(), interfaces.ListResourceInput{\n\t\tInlineFilters: []common.InlineFilter{\n\t\t\tgetEqualityFilter(common.Task, \"project\", project),\n\t\t\tgetEqualityFilter(common.Task, \"domain\", domain),\n\t\t\tgetEqualityFilter(common.Task, \"name\", name),\n\t\t},\n\t\tLimit: 2,\n\t})\n\tassert.Empty(t, err)\n\tassert.NotEmpty(t, collection)\n\tassert.NotEmpty(t, collection.Tasks)\n\tassert.Len(t, collection.Tasks, 2)\n\tfor idx, task := range collection.Tasks {\n\t\tassert.Equal(t, project, task.Project)\n\t\tassert.Equal(t, domain, task.Domain)\n\t\tassert.Equal(t, name, task.Name)\n\t\tassert.Equal(t, versions[idx], task.Version)\n\t\tassert.Equal(t, spec, task.Closure)\n\t\tassert.Equal(t, pythonTestTaskType, task.Type)\n\t}\n}\n\nfunc TestListTasks_Filters(t *testing.T) {\n\ttaskRepo := NewTaskRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\n\ttasks := make([]map[string]interface{}, 0)\n\ttask := getMockTaskResponseFromDb(\"ABC\", []byte{1, 2})\n\ttasks = append(tasks, task)\n\n\tGlobalMock := mocket.Catcher.Reset()\n\tGlobalMock.Logging = true\n\t// Only match on queries that append the name filter\n\tGlobalMock.NewMock().WithQuery(`SELECT * FROM \"tasks\" WHERE project = $1 AND domain = $2 AND name = $3 AND version = $4 LIMIT 20`).WithReply(tasks[0:1])\n\n\tcollection, err := taskRepo.List(context.Background(), interfaces.ListResourceInput{\n\t\tInlineFilters: []common.InlineFilter{\n\t\t\tgetEqualityFilter(common.Task, \"project\", project),\n\t\t\tgetEqualityFilter(common.Task, \"domain\", domain),\n\t\t\tgetEqualityFilter(common.Task, \"name\", name),\n\t\t\tgetEqualityFilter(common.Task, \"version\", \"ABC\"),\n\t\t},\n\t\tLimit: 20,\n\t})\n\tassert.Empty(t, err)\n\tassert.NotEmpty(t, collection)\n\tassert.NotEmpty(t, collection.Tasks)\n\tassert.Len(t, collection.Tasks, 1)\n\tassert.Equal(t, project, collection.Tasks[0].Project)\n\tassert.Equal(t, domain, collection.Tasks[0].Domain)\n\tassert.Equal(t, name, collection.Tasks[0].Name)\n\tassert.Equal(t, \"ABC\", collection.Tasks[0].Version)\n\tassert.Equal(t, []byte{1, 2}, collection.Tasks[0].Closure)\n\tassert.Equal(t, pythonTestTaskType, collection.Tasks[0].Type)\n}\n\nfunc TestListTasks_Order(t *testing.T) {\n\ttaskRepo := NewTaskRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\ttasks := make([]map[string]interface{}, 0)\n\n\tGlobalMock := mocket.Catcher.Reset()\n\tGlobalMock.Logging = true\n\t// Only match on queries that include ordering by project\n\tmockQuery := GlobalMock.NewMock()\n\tmockQuery.WithQuery(`project desc`)\n\tmockQuery.WithReply(tasks)\n\n\tsortParameter, _ := common.NewSortParameter(&admin.Sort{\n\t\tDirection: admin.Sort_DESCENDING,\n\t\tKey:       \"project\",\n\t}, models.TaskColumns)\n\t_, err := taskRepo.List(context.Background(), interfaces.ListResourceInput{\n\t\tSortParameter: sortParameter,\n\t\tInlineFilters: []common.InlineFilter{\n\t\t\tgetEqualityFilter(common.Task, \"project\", project),\n\t\t\tgetEqualityFilter(common.Task, \"domain\", domain),\n\t\t\tgetEqualityFilter(common.Task, \"name\", name),\n\t\t\tgetEqualityFilter(common.Task, \"version\", \"ABC\"),\n\t\t},\n\t\tLimit: 20,\n\t})\n\tassert.Empty(t, err)\n\tassert.True(t, mockQuery.Triggered)\n}\n\nfunc TestListTasks_MissingParameters(t *testing.T) {\n\ttaskRepo := NewTaskRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\t_, err := taskRepo.List(context.Background(), interfaces.ListResourceInput{\n\t\tInlineFilters: []common.InlineFilter{\n\t\t\tgetEqualityFilter(common.Task, \"project\", project),\n\t\t\tgetEqualityFilter(common.Task, \"domain\", domain),\n\t\t\tgetEqualityFilter(common.Task, \"name\", name),\n\t\t\tgetEqualityFilter(common.Task, \"version\", version),\n\t\t},\n\t})\n\tassert.Equal(t, err.Error(), \"missing and/or invalid parameters: limit\")\n\n\t_, err = taskRepo.List(context.Background(), interfaces.ListResourceInput{\n\t\tLimit: 20,\n\t})\n\tassert.Equal(t, err.Error(), \"missing and/or invalid parameters: filters\")\n}\n\nfunc TestListTaskIds(t *testing.T) {\n\ttaskRepo := NewTaskRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\n\ttasks := make([]map[string]interface{}, 0)\n\tversions := []string{\"v3\", \"v4\"}\n\tspec := []byte{1, 2}\n\tfor _, version := range versions {\n\t\ttask := getMockTaskResponseFromDb(version, spec)\n\t\ttasks = append(tasks, task)\n\t}\n\n\tGlobalMock := mocket.Catcher.Reset()\n\tGlobalMock.NewMock().WithQuery(`GROUP BY project, domain, name`).WithReply(tasks)\n\n\tcollection, err := taskRepo.ListTaskIdentifiers(context.Background(), interfaces.ListResourceInput{\n\t\tInlineFilters: []common.InlineFilter{\n\t\t\tgetEqualityFilter(common.Task, \"project\", project),\n\t\t\tgetEqualityFilter(common.Task, \"domain\", domain),\n\t\t},\n\t\tLimit: 20,\n\t})\n\tassert.NoError(t, err)\n\tassert.NotEmpty(t, collection)\n\tassert.NotEmpty(t, collection.Tasks)\n\tassert.Len(t, collection.Tasks, 2)\n\tfor idx, task := range collection.Tasks {\n\t\tassert.Equal(t, project, task.Project)\n\t\tassert.Equal(t, domain, task.Domain)\n\t\tassert.Equal(t, name, task.Name)\n\t\tassert.Equal(t, versions[idx], task.Version)\n\t\tassert.Equal(t, spec, task.Closure)\n\t\tassert.Equal(t, pythonTestTaskType, task.Type)\n\t}\n}\n\nfunc TestListTaskIds_MissingParameters(t *testing.T) {\n\ttaskRepo := NewTaskRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\n\t_, err := taskRepo.ListTaskIdentifiers(context.Background(), interfaces.ListResourceInput{\n\t\tInlineFilters: []common.InlineFilter{\n\t\t\tgetEqualityFilter(common.Task, \"project\", project),\n\t\t\tgetEqualityFilter(common.Task, \"domain\", domain),\n\t\t},\n\t})\n\n\t// Limit must be specified\n\tassert.Equal(t, \"missing and/or invalid parameters: limit\", err.Error())\n}\n", "package gormimpl\n\nimport (\n\t\"context\"\n\t\"errors\"\n\n\t\"github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/core\"\n\t\"github.com/flyteorg/flytestdlib/promutils\"\n\t\"gorm.io/gorm\"\n\n\tflyteAdminDbErrors \"github.com/flyteorg/flyteadmin/pkg/repositories/errors\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/interfaces\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/models\"\n)\n\n// Implementation of WorkflowRepoInterface.\ntype WorkflowRepo struct {\n\tdb               *gorm.DB\n\terrorTransformer flyteAdminDbErrors.ErrorTransformer\n\tmetrics          gormMetrics\n}\n\nfunc (r *WorkflowRepo) Create(_ context.Context, input models.Workflow, descriptionEntity *models.DescriptionEntity) error {\n\ttimer := r.metrics.CreateDuration.Start()\n\terr := r.db.Transaction(func(_ *gorm.DB) error {\n\t\tif descriptionEntity != nil {\n\t\t\ttx := r.db.Omit(\"id\").Create(descriptionEntity)\n\t\t\tif tx.Error != nil {\n\t\t\t\treturn r.errorTransformer.ToFlyteAdminError(tx.Error)\n\t\t\t}\n\t\t}\n\t\ttx := r.db.Omit(\"id\").Create(&input)\n\t\tif tx.Error != nil {\n\t\t\treturn r.errorTransformer.ToFlyteAdminError(tx.Error)\n\t\t}\n\n\t\treturn nil\n\t})\n\ttimer.Stop()\n\treturn err\n}\n\nfunc (r *WorkflowRepo) Get(ctx context.Context, input interfaces.Identifier) (models.Workflow, error) {\n\tvar workflow models.Workflow\n\ttimer := r.metrics.GetDuration.Start()\n\ttx := r.db.Where(&models.Workflow{\n\t\tWorkflowKey: models.WorkflowKey{\n\t\t\tProject: input.Project,\n\t\t\tDomain:  input.Domain,\n\t\t\tName:    input.Name,\n\t\t\tVersion: input.Version,\n\t\t},\n\t}).Take(&workflow)\n\ttimer.Stop()\n\n\tif tx.Error != nil && errors.Is(tx.Error, gorm.ErrRecordNotFound) {\n\t\treturn models.Workflow{}, flyteAdminDbErrors.GetMissingEntityError(core.ResourceType_WORKFLOW.String(), &core.Identifier{\n\t\t\tProject: input.Project,\n\t\t\tDomain:  input.Domain,\n\t\t\tName:    input.Name,\n\t\t\tVersion: input.Version,\n\t\t})\n\t} else if tx.Error != nil {\n\t\treturn models.Workflow{}, r.errorTransformer.ToFlyteAdminError(tx.Error)\n\t}\n\treturn workflow, nil\n}\n\nfunc (r *WorkflowRepo) List(\n\tctx context.Context, input interfaces.ListResourceInput) (interfaces.WorkflowCollectionOutput, error) {\n\t// First validate input.\n\tif err := ValidateListInput(input); err != nil {\n\t\treturn interfaces.WorkflowCollectionOutput{}, err\n\t}\n\tvar workflows []models.Workflow\n\ttx := r.db.Limit(input.Limit).Offset(input.Offset)\n\n\t// Apply filters\n\ttx, err := applyFilters(tx, input.InlineFilters, input.MapFilters)\n\tif err != nil {\n\t\treturn interfaces.WorkflowCollectionOutput{}, err\n\t}\n\t// Apply sort ordering.\n\tif input.SortParameter != nil {\n\t\ttx = tx.Order(input.SortParameter.GetGormOrderExpr())\n\t}\n\ttimer := r.metrics.ListDuration.Start()\n\ttx.Find(&workflows)\n\ttimer.Stop()\n\tif tx.Error != nil {\n\t\treturn interfaces.WorkflowCollectionOutput{}, r.errorTransformer.ToFlyteAdminError(tx.Error)\n\t}\n\treturn interfaces.WorkflowCollectionOutput{\n\t\tWorkflows: workflows,\n\t}, nil\n}\n\nfunc (r *WorkflowRepo) ListIdentifiers(ctx context.Context, input interfaces.ListResourceInput) (\n\tinterfaces.WorkflowCollectionOutput, error) {\n\n\t// Validate input.\n\tif err := ValidateListInput(input); err != nil {\n\t\treturn interfaces.WorkflowCollectionOutput{}, err\n\t}\n\n\ttx := r.db.Model(models.Workflow{}).Limit(input.Limit).Offset(input.Offset)\n\n\t// Apply filters\n\ttx, err := applyFilters(tx, input.InlineFilters, input.MapFilters)\n\tif err != nil {\n\t\treturn interfaces.WorkflowCollectionOutput{}, err\n\t}\n\n\t// Apply sort ordering.\n\tif input.SortParameter != nil {\n\t\ttx = tx.Order(input.SortParameter.GetGormOrderExpr())\n\t}\n\n\t// Scan the results into a list of workflows\n\tvar workflows []models.Workflow\n\ttimer := r.metrics.ListIdentifiersDuration.Start()\n\ttx.Select([]string{Project, Domain, Name}).Group(identifierGroupBy).Scan(&workflows)\n\ttimer.Stop()\n\tif tx.Error != nil {\n\t\treturn interfaces.WorkflowCollectionOutput{}, r.errorTransformer.ToFlyteAdminError(tx.Error)\n\t}\n\n\treturn interfaces.WorkflowCollectionOutput{\n\t\tWorkflows: workflows,\n\t}, nil\n}\n\n// Returns an instance of WorkflowRepoInterface\nfunc NewWorkflowRepo(\n\tdb *gorm.DB, errorTransformer flyteAdminDbErrors.ErrorTransformer, scope promutils.Scope) interfaces.WorkflowRepoInterface {\n\tmetrics := newMetrics(scope)\n\treturn &WorkflowRepo{\n\t\tdb:               db,\n\t\terrorTransformer: errorTransformer,\n\t\tmetrics:          metrics,\n\t}\n}\n", "package gormimpl\n\nimport (\n\t\"context\"\n\t\"testing\"\n\n\tmocket \"github.com/Selvatico/go-mocket\"\n\t\"github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/admin\"\n\tmockScope \"github.com/flyteorg/flytestdlib/promutils\"\n\t\"github.com/stretchr/testify/assert\"\n\n\t\"github.com/flyteorg/flyteadmin/pkg/common\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/errors\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/interfaces\"\n\t\"github.com/flyteorg/flyteadmin/pkg/repositories/models\"\n)\n\nvar typedInterface = []byte{1, 2, 3}\n\nconst remoteSpecIdentifier = \"remote spec id\"\n\nfunc TestCreateWorkflow(t *testing.T) {\n\tworkflowRepo := NewWorkflowRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\terr := workflowRepo.Create(context.Background(), models.Workflow{\n\t\tWorkflowKey: models.WorkflowKey{\n\t\t\tProject: project,\n\t\t\tDomain:  domain,\n\t\t\tName:    name,\n\t\t\tVersion: version,\n\t\t},\n\t\tTypedInterface:          typedInterface,\n\t\tRemoteClosureIdentifier: remoteSpecIdentifier,\n\t}, &models.DescriptionEntity{ShortDescription: \"hello\"})\n\tassert.NoError(t, err)\n}\n\nfunc getMockWorkflowResponseFromDb(version string, typedInterface []byte) map[string]interface{} {\n\tworkflow := make(map[string]interface{})\n\tworkflow[\"project\"] = project\n\tworkflow[\"domain\"] = domain\n\tworkflow[\"name\"] = name\n\tworkflow[\"version\"] = version\n\tworkflow[\"typed_interface\"] = typedInterface\n\tworkflow[\"remote_closure_identifier\"] = remoteSpecIdentifier\n\treturn workflow\n}\n\nfunc TestGetWorkflow(t *testing.T) {\n\tworkflowRepo := NewWorkflowRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\n\tworkflows := make([]map[string]interface{}, 0)\n\tworkflow := getMockWorkflowResponseFromDb(version, typedInterface)\n\tworkflows = append(workflows, workflow)\n\n\tGlobalMock := mocket.Catcher.Reset()\n\t// Only match on queries that append expected filters\n\tGlobalMock.NewMock().WithQuery(\n\t\t`SELECT * FROM \"workflows\" WHERE \"workflows\".\"project\" = $1 AND \"workflows\".\"domain\" = $2 AND \"workflows\".\"name\" = $3 AND \"workflows\".\"version\" = $4 LIMIT 1`).WithReply(workflows)\n\toutput, err := workflowRepo.Get(context.Background(), interfaces.Identifier{\n\t\tProject: project,\n\t\tDomain:  domain,\n\t\tName:    name,\n\t\tVersion: version,\n\t})\n\tassert.Empty(t, err)\n\tassert.Equal(t, project, output.Project)\n\tassert.Equal(t, domain, output.Domain)\n\tassert.Equal(t, name, output.Name)\n\tassert.Equal(t, version, output.Version)\n\tassert.Equal(t, typedInterface, output.TypedInterface)\n\tassert.Equal(t, remoteSpecIdentifier, output.RemoteClosureIdentifier)\n}\n\nfunc TestListWorkflows(t *testing.T) {\n\tworkflowRepo := NewWorkflowRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\n\tworkflows := make([]map[string]interface{}, 0)\n\tversions := []string{\"ABC\", \"XYZ\"}\n\tfor _, version := range versions {\n\t\tworkflow := getMockWorkflowResponseFromDb(version, typedInterface)\n\t\tworkflows = append(workflows, workflow)\n\t}\n\n\tGlobalMock := mocket.Catcher.Reset()\n\tGlobalMock.NewMock().WithReply(workflows)\n\n\tcollection, err := workflowRepo.List(context.Background(), interfaces.ListResourceInput{\n\t\tInlineFilters: []common.InlineFilter{\n\t\t\tgetEqualityFilter(common.Workflow, \"project\", project),\n\t\t\tgetEqualityFilter(common.Workflow, \"domain\", domain),\n\t\t\tgetEqualityFilter(common.Workflow, \"name\", name),\n\t\t},\n\t\tLimit: 20,\n\t})\n\tassert.Empty(t, err)\n\tassert.NotEmpty(t, collection)\n\tassert.NotEmpty(t, collection.Workflows)\n\tassert.Len(t, collection.Workflows, 2)\n\tfor _, workflow := range collection.Workflows {\n\t\tassert.Equal(t, project, workflow.Project)\n\t\tassert.Equal(t, domain, workflow.Domain)\n\t\tassert.Equal(t, name, workflow.Name)\n\t\tassert.Contains(t, versions, workflow.Version)\n\t\tassert.Equal(t, typedInterface, workflow.TypedInterface)\n\t\tassert.Equal(t, remoteSpecIdentifier, workflow.RemoteClosureIdentifier)\n\t}\n}\n\nfunc TestListWorkflows_Pagination(t *testing.T) {\n\tworkflowRepo := NewWorkflowRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\n\tworkflows := make([]map[string]interface{}, 0)\n\tversions := []string{\"ABC\", \"DEF\"}\n\tfor _, version := range versions {\n\t\tworkflow := getMockWorkflowResponseFromDb(version, typedInterface)\n\t\tworkflows = append(workflows, workflow)\n\t}\n\n\tGlobalMock := mocket.Catcher.Reset()\n\tGlobalMock.NewMock().WithReply(workflows)\n\n\tcollection, err := workflowRepo.List(context.Background(), interfaces.ListResourceInput{\n\t\tInlineFilters: []common.InlineFilter{\n\t\t\tgetEqualityFilter(common.Workflow, \"project\", project),\n\t\t\tgetEqualityFilter(common.Workflow, \"domain\", domain),\n\t\t\tgetEqualityFilter(common.Workflow, \"name\", name),\n\t\t},\n\t\tLimit: 2,\n\t})\n\tassert.Empty(t, err)\n\tassert.NotEmpty(t, collection)\n\tassert.NotEmpty(t, collection.Workflows)\n\tassert.Len(t, collection.Workflows, 2)\n\tfor idx, workflow := range collection.Workflows {\n\t\tassert.Equal(t, project, workflow.Project)\n\t\tassert.Equal(t, domain, workflow.Domain)\n\t\tassert.Equal(t, name, workflow.Name)\n\t\tassert.Equal(t, versions[idx], workflow.Version)\n\t\tassert.Equal(t, typedInterface, workflow.TypedInterface)\n\t\tassert.Equal(t, remoteSpecIdentifier, workflow.RemoteClosureIdentifier)\n\t}\n}\n\nfunc TestListWorkflows_Filters(t *testing.T) {\n\tworkflowRepo := NewWorkflowRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\n\tworkflows := make([]map[string]interface{}, 0)\n\tworkflow := getMockWorkflowResponseFromDb(\"ABC\", typedInterface)\n\tworkflows = append(workflows, workflow)\n\n\tGlobalMock := mocket.Catcher.Reset()\n\t// Only match on queries that append the name filter\n\tGlobalMock.NewMock().WithQuery(`SELECT * FROM \"workflows\" WHERE project = $1 AND domain = $2 AND name = $3 AND version = $4 LIMIT 20`).WithReply(workflows[0:1])\n\n\tcollection, err := workflowRepo.List(context.Background(), interfaces.ListResourceInput{\n\t\tInlineFilters: []common.InlineFilter{\n\t\t\tgetEqualityFilter(common.Workflow, \"project\", project),\n\t\t\tgetEqualityFilter(common.Workflow, \"domain\", domain),\n\t\t\tgetEqualityFilter(common.Workflow, \"name\", name),\n\t\t\tgetEqualityFilter(common.Workflow, \"version\", \"ABC\"),\n\t\t},\n\t\tLimit: 20,\n\t})\n\tassert.Empty(t, err)\n\tassert.NotEmpty(t, collection)\n\tassert.NotEmpty(t, collection.Workflows)\n\tassert.Len(t, collection.Workflows, 1)\n\tassert.Equal(t, project, collection.Workflows[0].Project)\n\tassert.Equal(t, domain, collection.Workflows[0].Domain)\n\tassert.Equal(t, name, collection.Workflows[0].Name)\n\tassert.Equal(t, \"ABC\", collection.Workflows[0].Version)\n\tassert.Equal(t, typedInterface, collection.Workflows[0].TypedInterface)\n\tassert.Equal(t, remoteSpecIdentifier, collection.Workflows[0].RemoteClosureIdentifier)\n}\n\nfunc TestListWorkflows_Order(t *testing.T) {\n\tworkflowRepo := NewWorkflowRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\tworkflows := make([]map[string]interface{}, 0)\n\n\tGlobalMock := mocket.Catcher.Reset()\n\t// Only match on queries that include ordering by project\n\tmockQuery := GlobalMock.NewMock()\n\tmockQuery.WithQuery(`project desc`)\n\tmockQuery.WithReply(workflows)\n\n\tsortParameter, _ := common.NewSortParameter(&admin.Sort{\n\t\tDirection: admin.Sort_DESCENDING,\n\t\tKey:       \"project\",\n\t}, models.WorkflowColumns)\n\t_, err := workflowRepo.List(context.Background(), interfaces.ListResourceInput{\n\t\tSortParameter: sortParameter,\n\t\tInlineFilters: []common.InlineFilter{\n\t\t\tgetEqualityFilter(common.Workflow, \"project\", project),\n\t\t\tgetEqualityFilter(common.Workflow, \"domain\", domain),\n\t\t\tgetEqualityFilter(common.Workflow, \"name\", name),\n\t\t\tgetEqualityFilter(common.Workflow, \"version\", \"ABC\"),\n\t\t},\n\t\tLimit: 20,\n\t})\n\tassert.Empty(t, err)\n\tassert.True(t, mockQuery.Triggered)\n}\n\nfunc TestListWorkflows_MissingParameters(t *testing.T) {\n\tworkflowRepo := NewWorkflowRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\t_, err := workflowRepo.List(context.Background(), interfaces.ListResourceInput{\n\t\tInlineFilters: []common.InlineFilter{\n\t\t\tgetEqualityFilter(common.Workflow, \"project\", project),\n\t\t\tgetEqualityFilter(common.Workflow, \"domain\", domain),\n\t\t\tgetEqualityFilter(common.Workflow, \"name\", name),\n\t\t\tgetEqualityFilter(common.Workflow, \"version\", version),\n\t\t},\n\t})\n\tassert.Equal(t, err.Error(), \"missing and/or invalid parameters: limit\")\n\n\t_, err = workflowRepo.List(context.Background(), interfaces.ListResourceInput{\n\t\tLimit: 20,\n\t})\n\tassert.Equal(t, err.Error(), \"missing and/or invalid parameters: filters\")\n}\n\nfunc TestListWorkflowIds(t *testing.T) {\n\tworkflowRepo := NewWorkflowRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\n\tworkflows := make([]map[string]interface{}, 0)\n\tversions := []string{\"ABC\", \"DEF\"}\n\t// Instead of different versions, we should be returning different identifiers since the point of this list ids\n\t// function is to group away the versions, but for the purpose of this unit test, different versions will suffice.\n\tfor _, version := range versions {\n\t\tworkflow := getMockWorkflowResponseFromDb(version, typedInterface)\n\t\tworkflows = append(workflows, workflow)\n\t}\n\n\tGlobalMock := mocket.Catcher.Reset()\n\tGlobalMock.NewMock().WithReply(workflows)\n\n\tcollection, err := workflowRepo.ListIdentifiers(context.Background(), interfaces.ListResourceInput{\n\t\tInlineFilters: []common.InlineFilter{\n\t\t\tgetEqualityFilter(common.Workflow, \"project\", project),\n\t\t\tgetEqualityFilter(common.Workflow, \"domain\", domain),\n\t\t},\n\t\tLimit: 2,\n\t})\n\tassert.Empty(t, err)\n\tassert.NotEmpty(t, collection)\n\tassert.NotEmpty(t, collection.Workflows)\n\tassert.Len(t, collection.Workflows, 2)\n\tfor idx, workflow := range collection.Workflows {\n\t\tassert.Equal(t, project, workflow.Project)\n\t\tassert.Equal(t, domain, workflow.Domain)\n\t\tassert.Equal(t, name, workflow.Name)\n\t\tassert.Equal(t, versions[idx], workflow.Version)\n\t\tassert.Equal(t, typedInterface, workflow.TypedInterface)\n\t\tassert.Equal(t, remoteSpecIdentifier, workflow.RemoteClosureIdentifier)\n\t}\n}\n\nfunc TestListWorkflowIds_MissingParameters(t *testing.T) {\n\tworkflowRepo := NewWorkflowRepo(GetDbForTest(t), errors.NewTestErrorTransformer(), mockScope.NewTestScope())\n\t_, err := workflowRepo.ListIdentifiers(context.Background(), interfaces.ListResourceInput{\n\t\tInlineFilters: []common.InlineFilter{\n\t\t\tgetEqualityFilter(common.Workflow, \"project\", project),\n\t\t\tgetEqualityFilter(common.Workflow, \"domain\", domain),\n\t\t},\n\t})\n\n\tassert.Equal(t, err.Error(), \"missing and/or invalid parameters: limit\")\n}\n", "package models\n\nimport (\n\t\"sync\"\n\t\"time\"\n\n\t\"gorm.io/gorm/schema\"\n\t\"k8s.io/apimachinery/pkg/util/sets\"\n)\n\n// This is the base model definition every flyteadmin model embeds.\n// This is nearly identical to http://doc.gorm.io/models.html#conventions except that flyteadmin models define their\n// own primary keys rather than use the ID as the primary key\ntype BaseModel struct {\n\tID        uint `gorm:\"index;autoIncrement\"`\n\tCreatedAt time.Time\n\tUpdatedAt time.Time\n\tDeletedAt *time.Time `gorm:\"index\"`\n}\n\nfunc modelColumns(v any) sets.String {\n\ts, err := schema.Parse(v, &sync.Map{}, schema.NamingStrategy{})\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\treturn sets.NewString(s.DBNames...)\n}\n", "package models\n\nimport \"github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/core\"\n\n// DescriptionEntityKey DescriptionEntity primary key\ntype DescriptionEntityKey struct {\n\tResourceType core.ResourceType `gorm:\"primary_key;index:description_entity_project_domain_name_version_idx\" valid:\"length(0|255)\"`\n\tProject      string            `gorm:\"primary_key;index:description_entity_project_domain_name_version_idx\" valid:\"length(0|255)\"`\n\tDomain       string            `gorm:\"primary_key;index:description_entity_project_domain_name_version_idx\" valid:\"length(0|255)\"`\n\tName         string            `gorm:\"primary_key;index:description_entity_project_domain_name_version_idx\" valid:\"length(0|255)\"`\n\tVersion      string            `gorm:\"primary_key;index:description_entity_project_domain_name_version_idx\" valid:\"length(0|255)\"`\n}\n\n// SourceCode Database model to encapsulate a SourceCode.\ntype SourceCode struct {\n\tLink string `valid:\"length(0|255)\"`\n}\n\n// DescriptionEntity Database model to encapsulate a DescriptionEntity.\ntype DescriptionEntity struct {\n\tDescriptionEntityKey\n\n\tBaseModel\n\n\tShortDescription string\n\n\tLongDescription []byte\n\n\tSourceCode\n}\n\nvar DescriptionEntityColumns = modelColumns(DescriptionEntity{})\n", "package models\n\nimport (\n\t\"time\"\n\n\t\"gorm.io/gorm/clause\"\n\n\t\"gorm.io/gorm\"\n\n\t\"github.com/flyteorg/flytestdlib/storage\"\n)\n\n// IMPORTANT: If you update the model below, be sure to double check model definitions in\n// pkg/repositories/config/migration_models.go\n\n// Execution primary key\ntype ExecutionKey struct {\n\tProject string `gorm:\"primary_key;column:execution_project\" valid:\"length(0|255)\"`\n\tDomain  string `gorm:\"primary_key;column:execution_domain\" valid:\"length(0|255)\"`\n\tName    string `gorm:\"primary_key;column:execution_name\" valid:\"length(0|255)\"`\n}\n\n// Database model to encapsulate a (workflow) execution.\ntype Execution struct {\n\tBaseModel\n\tExecutionKey\n\tLaunchPlanID uint   `gorm:\"index\"`\n\tWorkflowID   uint   `gorm:\"index\"`\n\tTaskID       uint   `gorm:\"index\"`\n\tPhase        string `valid:\"length(0|255)\"`\n\tClosure      []byte\n\tSpec         []byte `gorm:\"not null\"`\n\tStartedAt    *time.Time\n\t// Corresponds to the CreatedAt field in the Execution closure.\n\t// Prefixed with Execution to avoid clashes with gorm.Model CreatedAt\n\tExecutionCreatedAt *time.Time `gorm:\"index:idx_executions_created_at\"`\n\t// Corresponds to the UpdatedAt field in the Execution closure\n\t// Prefixed with Execution to avoid clashes with gorm.Model UpdatedAt\n\tExecutionUpdatedAt *time.Time\n\tDuration           time.Duration\n\t// In the case of an aborted execution this string may be non-empty.\n\t// It should be ignored for any other value of phase other than aborted.\n\tAbortCause string `valid:\"length(0|255)\"`\n\t// Corresponds to the execution mode used to trigger this execution\n\tMode int32\n\t// The \"parent\" execution (if there is one) that is related to this execution.\n\tSourceExecutionID uint\n\t// The parent node execution if this was launched by a node\n\tParentNodeExecutionID uint\n\t// Cluster where execution was triggered\n\tCluster string `valid:\"length(0|255)\"`\n\t// Offloaded location of inputs LiteralMap. These are the inputs evaluated and contain applied defaults.\n\tInputsURI storage.DataReference\n\t// User specified inputs. This map might be incomplete and not include defaults applied\n\tUserInputsURI storage.DataReference\n\t// Execution Error Kind. nullable\n\tErrorKind *string `gorm:\"index\"`\n\t// Execution Error Code nullable\n\tErrorCode *string `valid:\"length(0|255)\"`\n\t// The user responsible for launching this execution.\n\t// This is also stored in the spec but promoted as a column for filtering.\n\tUser string `gorm:\"index\" valid:\"length(0|255)\"`\n\t// GORM doesn't save the zero value for ints, so we use a pointer for the State field\n\tState *int32 `gorm:\"index;default:0\"`\n\t// The resource type of the entity used to launch the execution, one of 'launch_plan' or 'task'\n\tLaunchEntity string\n\t// Tags associated with the execution\n\tTags []AdminTag `gorm:\"many2many:execution_admin_tags;\"`\n}\n\ntype AdminTag struct {\n\tgorm.Model\n\tName string `gorm:\"index:,unique;size:255\"`\n}\n\nfunc (b *AdminTag) BeforeCreate(tx *gorm.DB) (err error) {\n\ttx.Statement.AddClause(clause.OnConflict{\n\t\tColumns:   []clause.Column{{Name: \"name\"}},            // key column\n\t\tDoUpdates: clause.AssignmentColumns([]string{\"name\"}), // column needed to be updated\n\t})\n\treturn nil\n}\n\nvar (\n\tExecutionColumns = modelColumns(Execution{})\n\tAdminTagColumns  = modelColumns(AdminTag{})\n)\n", "package models\n\n// Launch plan primary key\ntype LaunchPlanKey struct {\n\tProject string `gorm:\"primary_key;index:lp_project_domain_name_idx,lp_project_domain_idx\" valid:\"length(0|255)\"`\n\tDomain  string `gorm:\"primary_key;index:lp_project_domain_name_idx,lp_project_domain_idx\" valid:\"length(0|255)\"`\n\tName    string `gorm:\"primary_key;index:lp_project_domain_name_idx\" valid:\"length(0|255)\"`\n\tVersion string `gorm:\"primary_key\" valid:\"length(0|255)\"`\n}\n\ntype LaunchPlanScheduleType string\n\nconst (\n\t// LaunchPlanScheduleTypeNONE is the const representing the launch plan does not have a schedule\n\tLaunchPlanScheduleTypeNONE LaunchPlanScheduleType = \"NONE\"\n\t// LaunchPlanScheduleTypeCRON is the const representing the launch plan has a CRON type of schedule\n\tLaunchPlanScheduleTypeCRON LaunchPlanScheduleType = \"CRON\"\n\t// LaunchPlanScheduleTypeRATE is the launch plan has a RATE type of schedule\n\tLaunchPlanScheduleTypeRATE LaunchPlanScheduleType = \"RATE\"\n)\n\n// Database model to encapsulate a launch plan.\ntype LaunchPlan struct {\n\tBaseModel\n\tLaunchPlanKey\n\tSpec       []byte `gorm:\"not null\"`\n\tWorkflowID uint   `gorm:\"index\"`\n\tClosure    []byte `gorm:\"not null\"`\n\t// GORM doesn't save the zero value for ints, so we use a pointer for the State field\n\tState *int32 `gorm:\"default:0\"`\n\t// Hash of the launch plan\n\tDigest       []byte\n\tScheduleType LaunchPlanScheduleType\n}\n\nvar LaunchPlanColumns = modelColumns(LaunchPlan{})\n", "package models\n\nimport (\n\t\"github.com/flyteorg/flyteidl/gen/pb-go/flyteidl/core\"\n)\n\n// NamedEntityMetadata primary key\ntype NamedEntityMetadataKey struct {\n\tResourceType core.ResourceType `gorm:\"primary_key;index:named_entity_metadata_type_project_domain_name_idx\" valid:\"length(0|255)\"`\n\tProject      string            `gorm:\"primary_key;index:named_entity_metadata_type_project_domain_name_idx\" valid:\"length(0|255)\"`\n\tDomain       string            `gorm:\"primary_key;index:named_entity_metadata_type_project_domain_name_idx\" valid:\"length(0|255)\"`\n\tName         string            `gorm:\"primary_key;index:named_entity_metadata_type_project_domain_name_idx\" valid:\"length(0|255)\"`\n}\n\n// Fields to be composed into any named entity\ntype NamedEntityMetadataFields struct {\n\tDescription string `gorm:\"type:varchar(300)\"`\n\t// GORM doesn't save the zero value for ints, so we use a pointer for the State field\n\tState *int32 `gorm:\"default:0\"`\n}\n\n// Database model to encapsulate metadata associated with a NamedEntity\ntype NamedEntityMetadata struct {\n\tBaseModel\n\tNamedEntityMetadataKey\n\tNamedEntityMetadataFields\n}\n\n// NamedEntity key. This is used as a lookup for NamedEntityMetadata, so the\n// fields here should match the ones in NamedEntityMetadataKey.\ntype NamedEntityKey struct {\n\tResourceType core.ResourceType\n\tProject      string `valid:\"length(0|255)\"`\n\tDomain       string `valid:\"length(0|255)\"`\n\tName         string `valid:\"length(0|255)\"`\n}\n\n// Composes an identifier (NamedEntity) and its associated metadata fields\ntype NamedEntity struct {\n\tNamedEntityKey\n\tNamedEntityMetadataFields\n}\n\nvar (\n\tNamedEntityColumns         = modelColumns(NamedEntity{})\n\tNamedEntityMetadataColumns = modelColumns(NamedEntityMetadata{})\n)\n", "package models\n\nimport (\n\t\"time\"\n)\n\n// IMPORTANT: If you update the model below, be sure to double check model definitions in\n// pkg/repositories/config/migration_models.go\n\ntype NodeExecutionKey struct {\n\tExecutionKey\n\tNodeID string `gorm:\"primary_key;index\" valid:\"length(0|255)\"`\n}\n\n// By convention, gorm foreign key references are of the form {ModelName}ID\ntype NodeExecution struct {\n\tBaseModel\n\tNodeExecutionKey\n\t// Also stored in the closure, but defined as a separate column because it's useful for filtering and sorting.\n\tPhase     string\n\tInputURI  string\n\tClosure   []byte\n\tStartedAt *time.Time\n\t// Corresponds to the CreatedAt field in the NodeExecution closure\n\t// Prefixed with NodeExecution to avoid clashes with gorm.Model CreatedAt\n\tNodeExecutionCreatedAt *time.Time\n\t// Corresponds to the UpdatedAt field in the NodeExecution closure\n\t// Prefixed with NodeExecution to avoid clashes with gorm.Model UpdatedAt\n\tNodeExecutionUpdatedAt *time.Time\n\tDuration               time.Duration\n\t// Metadata about the node execution.\n\tNodeExecutionMetadata []byte\n\t// Parent that spawned this node execution - value is empty for executions at level 0\n\tParentID *uint `sql:\"default:null\" gorm:\"index\"`\n\t// List of child node executions - for cases like Dynamic task, sub workflow, etc\n\tChildNodeExecutions []NodeExecution `gorm:\"foreignKey:ParentID;references:ID\"`\n\t// The task execution (if any) which launched this node execution.\n\t// TO BE DEPRECATED - as we have now introduced ParentID\n\tParentTaskExecutionID *uint `sql:\"default:null\" gorm:\"index\"`\n\t// The workflow execution (if any) which this node execution launched\n\t// NOTE: LaunchedExecution[foreignkey:ParentNodeExecutionID] refers to Workflow execution launched and is different from ParentID\n\tLaunchedExecution Execution `gorm:\"foreignKey:ParentNodeExecutionID;references:ID\"`\n\t// Execution Error Kind. nullable, can be one of core.ExecutionError_ErrorKind\n\tErrorKind *string `gorm:\"index\"`\n\t// Execution Error Code nullable. string value, but finite set determined by the execution engine and plugins\n\tErrorCode *string\n\t// If the node is of Type Task, this should always exist for a successful execution, indicating the cache status for the execution\n\tCacheStatus *string\n\t// In the case of dynamic workflow nodes, the remote closure is uploaded to the path specified here.\n\tDynamicWorkflowRemoteClosureReference string\n\t// Metadata that is only relevant to the flyteadmin service that is used to parse the model and track additional attributes.\n\tInternalData []byte\n}\n\nvar NodeExecutionColumns = modelColumns(NodeExecution{})\n", "package models\n\nimport (\n\t\"time\"\n)\n\ntype NodeExecutionEvent struct {\n\tBaseModel\n\tNodeExecutionKey\n\tRequestID  string\n\tOccurredAt time.Time\n\tPhase      string `gorm:\"primary_key\"`\n}\n\nvar NodeExecutionEventColumns = modelColumns(NodeExecutionEvent{})\n", "package models\n\ntype Project struct {\n\tBaseModel\n\tIdentifier  string `gorm:\"primary_key\"`\n\tName        string `valid:\"length(0|255)\"` // Human-readable name, not a unique identifier.\n\tDescription string `gorm:\"type:varchar(300)\"`\n\tLabels      []byte\n\t// GORM doesn't save the zero value for ints, so we use a pointer for the State field\n\tState *int32 `gorm:\"default:0;index\"`\n}\n\nvar ProjectColumns = modelColumns(Project{})\n", "package models\n\n// Signal primary key\ntype SignalKey struct {\n\tExecutionKey\n\tSignalID string `gorm:\"primary_key;index\" valid:\"length(0|255)\"`\n}\n\n// Database model to encapsulate a signal.\ntype Signal struct {\n\tBaseModel\n\tSignalKey\n\tType  []byte `gorm:\"not null\"`\n\tValue []byte\n}\n\nvar SignalColumns = modelColumns(Signal{})\n", "package models\n\n// IMPORTANT: If you update the model below, be sure to double check model definitions in\n// pkg/repositories/config/migration_models.go\n\n// Task primary key\ntype TaskKey struct {\n\tProject string `gorm:\"primary_key;index:task_project_domain_name_idx;index:task_project_domain_idx\" valid:\"length(0|255)\"`\n\tDomain  string `gorm:\"primary_key;index:task_project_domain_name_idx;index:task_project_domain_idx\" valid:\"length(0|255)\"`\n\tName    string `gorm:\"primary_key;index:task_project_domain_name_idx\" valid:\"length(0|255)\"`\n\tVersion string `gorm:\"primary_key\" valid:\"length(0|255)\"`\n}\n\n// Database model to encapsulate a task.\ntype Task struct {\n\tBaseModel\n\tTaskKey\n\tClosure []byte `gorm:\"not null\"`\n\t// Hash of the compiled task closure\n\tDigest []byte\n\t// Task type (also stored in the closure put promoted as a column for filtering).\n\tType string `valid:\"length(0|255)\"`\n\t// ShortDescription for the task.\n\tShortDescription string\n}\n\nvar TaskColumns = modelColumns(Task{})\n", "package models\n\nimport (\n\t\"time\"\n)\n\n// IMPORTANT: If you update the model below, be sure to double check model definitions in\n// pkg/repositories/config/migration_models.go\n\n// Task execution primary key\ntype TaskExecutionKey struct {\n\tTaskKey\n\tNodeExecutionKey\n\t// *IMPORTANT* This is a pointer to an int in order to allow setting an empty (\"0\") value according to gorm convention.\n\t// Because RetryAttempt is part of the TaskExecution primary key is should *never* be null.\n\tRetryAttempt *uint32 `gorm:\"primary_key\"`\n}\n\n// By convention, gorm foreign key references are of the form {ModelName}ID\ntype TaskExecution struct {\n\tBaseModel\n\tTaskExecutionKey\n\tPhase        string `valid:\"length(0|255)\"`\n\tPhaseVersion uint32\n\tInputURI     string `valid:\"length(0|255)\"`\n\tClosure      []byte\n\tStartedAt    *time.Time\n\t// Corresponds to the CreatedAt field in the TaskExecution closure\n\t// This field is prefixed with TaskExecution because it signifies when\n\t// the execution was createdAt, not to be confused with gorm.Model.CreatedAt\n\tTaskExecutionCreatedAt *time.Time\n\t// Corresponds to the UpdatedAt field in the TaskExecution closure\n\t// This field is prefixed with TaskExecution because it signifies when\n\t// the execution was UpdatedAt, not to be confused with gorm.Model.UpdatedAt\n\tTaskExecutionUpdatedAt *time.Time\n\tDuration               time.Duration\n\t// The child node executions (if any) launched by this task execution.\n\tChildNodeExecution []NodeExecution `gorm:\"foreignkey:ParentTaskExecutionID;references:ID\"`\n}\n\nvar TaskExecutionColumns = modelColumns(TaskExecution{})\n", "package models\n\n// Workflow primary key\ntype WorkflowKey struct {\n\tProject string `gorm:\"primary_key;index:workflow_project_domain_name_idx;index:workflow_project_domain_idx\"  valid:\"length(0|255)\"`\n\tDomain  string `gorm:\"primary_key;index:workflow_project_domain_name_idx;index:workflow_project_domain_idx\"  valid:\"length(0|255)\"`\n\tName    string `gorm:\"primary_key;index:workflow_project_domain_name_idx\"  valid:\"length(0|255)\"`\n\tVersion string `gorm:\"primary_key\"`\n}\n\n// Database model to encapsulate a workflow.\ntype Workflow struct {\n\tBaseModel\n\tWorkflowKey\n\tTypedInterface          []byte\n\tRemoteClosureIdentifier string `gorm:\"not null\" valid:\"length(0|255)\"`\n\t// Hash of the compiled workflow closure\n\tDigest []byte\n\t// ShortDescription for the workflow.\n\tShortDescription string\n}\n\nvar WorkflowColumns = modelColumns(Workflow{})\n"], "filenames": ["pkg/clusterresource/impl/admin_service_data_provider.go", "pkg/clusterresource/impl/shared.go", "pkg/common/sorting.go", "pkg/common/sorting_test.go", "pkg/manager/impl/description_entity_manager.go", "pkg/manager/impl/execution_manager.go", "pkg/manager/impl/execution_manager_test.go", "pkg/manager/impl/launch_plan_manager.go", "pkg/manager/impl/named_entity_manager.go", "pkg/manager/impl/node_execution_manager.go", "pkg/manager/impl/node_execution_manager_test.go", "pkg/manager/impl/project_manager.go", "pkg/manager/impl/signal_manager.go", "pkg/manager/impl/task_execution_manager.go", "pkg/manager/impl/task_manager.go", "pkg/manager/impl/util/filters.go", "pkg/manager/impl/util/filters_test.go", "pkg/manager/impl/workflow_manager.go", "pkg/repositories/gormimpl/common.go", "pkg/repositories/gormimpl/description_entity_repo.go", "pkg/repositories/gormimpl/execution_repo.go", "pkg/repositories/gormimpl/execution_repo_test.go", "pkg/repositories/gormimpl/launch_plan_repo.go", "pkg/repositories/gormimpl/launch_plan_repo_test.go", "pkg/repositories/gormimpl/named_entity_repo.go", "pkg/repositories/gormimpl/named_entity_repo_test.go", "pkg/repositories/gormimpl/node_execution_event_repo.go", "pkg/repositories/gormimpl/node_execution_repo.go", "pkg/repositories/gormimpl/node_execution_repo_test.go", "pkg/repositories/gormimpl/project_repo.go", "pkg/repositories/gormimpl/project_repo_test.go", "pkg/repositories/gormimpl/resource_repo_test.go", "pkg/repositories/gormimpl/signal_repo.go", "pkg/repositories/gormimpl/task_execution_repo.go", "pkg/repositories/gormimpl/task_execution_repo_test.go", "pkg/repositories/gormimpl/task_repo.go", "pkg/repositories/gormimpl/task_repo_test.go", "pkg/repositories/gormimpl/workflow_repo.go", "pkg/repositories/gormimpl/workflow_repo_test.go", "pkg/repositories/models/base_model.go", "pkg/repositories/models/description_entity.go", "pkg/repositories/models/execution.go", "pkg/repositories/models/launch_plan.go", "pkg/repositories/models/named_entity.go", "pkg/repositories/models/node_execution.go", "pkg/repositories/models/node_execution_event.go", "pkg/repositories/models/project.go", "pkg/repositories/models/signal.go", "pkg/repositories/models/task.go", "pkg/repositories/models/task_execution.go", "pkg/repositories/models/workflow.go"], "buggy_code_start_loc": [7, 4, 4, 5, 6, 8, 5, 7, 7, 4, 17, 5, 6, 7, 8, 5, 8, 8, 4, 6, 7, 8, 10, 7, 7, 11, 5, 9, 8, 7, 7, 7, 6, 8, 7, 8, 11, 6, 7, 3, 30, 82, 34, 42, 53, 13, 11, 15, 25, 39, 21], "buggy_code_end_loc": [33, 20, 33, 25, 74, 1443, 4014, 524, 128, 388, 1188, 71, 92, 267, 236, 135, 112, 316, 117, 14, 14, 288, 16, 352, 17, 164, 11, 16, 264, 14, 98, 15, 17, 15, 17, 15, 204, 13, 189, 13, 30, 82, 34, 42, 53, 13, 11, 15, 25, 39, 21], "fixing_code_start_loc": [6, 3, 5, 6, 7, 9, 6, 8, 8, 5, 18, 6, 7, 8, 9, 6, 9, 9, 5, 5, 8, 9, 11, 8, 8, 12, 6, 8, 8, 6, 8, 6, 7, 7, 8, 7, 12, 7, 8, 3, 31, 83, 35, 43, 54, 14, 12, 16, 26, 40, 22], "fixing_code_end_loc": [44, 10, 43, 54, 74, 1433, 4004, 516, 127, 378, 1192, 71, 88, 260, 231, 179, 144, 314, 129, 13, 14, 294, 16, 352, 16, 165, 11, 14, 267, 13, 100, 15, 14, 13, 16, 13, 205, 13, 190, 28, 33, 88, 37, 48, 56, 16, 14, 18, 28, 42, 24], "type": "CWE-89", "message": "FlyteAdmin is the control plane for Flyte responsible for managing entities and administering workflow executions. Prior to version 1.1.124, list endpoints on FlyteAdmin have a SQL vulnerability where a malicious user can send a REST request with custom SQL statements as list filters. The attacker needs to have access to the FlyteAdmin installation, typically either behind a VPN or authentication. Version 1.1.124 contains a patch for this issue.", "other": {"cve": {"id": "CVE-2023-41891", "sourceIdentifier": "security-advisories@github.com", "published": "2023-10-30T19:15:07.883", "lastModified": "2023-11-07T23:26:21.683", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "FlyteAdmin is the control plane for Flyte responsible for managing entities and administering workflow executions. Prior to version 1.1.124, list endpoints on FlyteAdmin have a SQL vulnerability where a malicious user can send a REST request with custom SQL statements as list filters. The attacker needs to have access to the FlyteAdmin installation, typically either behind a VPN or authentication. Version 1.1.124 contains a patch for this issue."}, {"lang": "es", "value": "FlyteAdmin es el plano de control de Flyte responsable de gestionar entidades y administrar ejecuciones de flujo de trabajo. Antes de la versi\u00f3n 1.1.124, los endpoints de lista en FlyteAdmin ten\u00edan una vulnerabilidad SQL donde un usuario malintencionado pod\u00eda enviar una solicitud REST con declaraciones SQL personalizadas como filtros de lista. El atacante debe tener acceso a la instalaci\u00f3n de FlyteAdmin, normalmente mediante una VPN o mediante autenticaci\u00f3n. La versi\u00f3n 1.1.124 contiene un parche para este problema."}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:H/I:H/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "HIGH", "availabilityImpact": "HIGH", "baseScore": 8.8, "baseSeverity": "HIGH"}, "exploitabilityScore": 2.8, "impactScore": 5.9}, {"source": "security-advisories@github.com", "type": "Secondary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:A/AC:L/PR:L/UI:N/S:U/C:L/I:N/A:N", "attackVector": "ADJACENT_NETWORK", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "LOW", "integrityImpact": "NONE", "availabilityImpact": "NONE", "baseScore": 3.5, "baseSeverity": "LOW"}, "exploitabilityScore": 2.1, "impactScore": 1.4}]}, "weaknesses": [{"source": "security-advisories@github.com", "type": "Primary", "description": [{"lang": "en", "value": "CWE-89"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:flyte:flyteadmin:*:*:*:*:*:*:*:*", "versionEndExcluding": "1.1.124", "matchCriteriaId": "9CB20F8F-3916-4352-95AE-447581F07EFC"}]}]}], "references": [{"url": "https://github.com/flyteorg/flyteadmin/commit/b3177ef70f068e908140b8a4a9913dfa74f289fd", "source": "security-advisories@github.com", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/flyteorg/flyteadmin/security/advisories/GHSA-r847-6w6h-r8g4", "source": "security-advisories@github.com", "tags": ["Third Party Advisory"]}, {"url": "https://owasp.org/www-community/attacks/SQL_Injection#", "source": "security-advisories@github.com", "tags": ["Third Party Advisory"]}]}, "github_commit_url": "https://github.com/flyteorg/flyteadmin/commit/b3177ef70f068e908140b8a4a9913dfa74f289fd"}}
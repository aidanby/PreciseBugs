{"buggy_code": ["/*\n *  linux/fs/ext4/super.c\n *\n * Copyright (C) 1992, 1993, 1994, 1995\n * Remy Card (card@masi.ibp.fr)\n * Laboratoire MASI - Institut Blaise Pascal\n * Universite Pierre et Marie Curie (Paris VI)\n *\n *  from\n *\n *  linux/fs/minix/inode.c\n *\n *  Copyright (C) 1991, 1992  Linus Torvalds\n *\n *  Big-endian to little-endian byte-swapping/bitmaps by\n *        David S. Miller (davem@caip.rutgers.edu), 1995\n */\n\n#include <linux/module.h>\n#include <linux/string.h>\n#include <linux/fs.h>\n#include <linux/time.h>\n#include <linux/vmalloc.h>\n#include <linux/slab.h>\n#include <linux/init.h>\n#include <linux/blkdev.h>\n#include <linux/backing-dev.h>\n#include <linux/parser.h>\n#include <linux/buffer_head.h>\n#include <linux/exportfs.h>\n#include <linux/vfs.h>\n#include <linux/random.h>\n#include <linux/mount.h>\n#include <linux/namei.h>\n#include <linux/quotaops.h>\n#include <linux/seq_file.h>\n#include <linux/ctype.h>\n#include <linux/log2.h>\n#include <linux/crc16.h>\n#include <linux/cleancache.h>\n#include <asm/uaccess.h>\n\n#include <linux/kthread.h>\n#include <linux/freezer.h>\n\n#include \"ext4.h\"\n#include \"ext4_extents.h\"\t/* Needed for trace points definition */\n#include \"ext4_jbd2.h\"\n#include \"xattr.h\"\n#include \"acl.h\"\n#include \"mballoc.h\"\n\n#define CREATE_TRACE_POINTS\n#include <trace/events/ext4.h>\n\nstatic struct ext4_lazy_init *ext4_li_info;\nstatic struct mutex ext4_li_mtx;\nstatic struct ratelimit_state ext4_mount_msg_ratelimit;\n\nstatic int ext4_load_journal(struct super_block *, struct ext4_super_block *,\n\t\t\t     unsigned long journal_devnum);\nstatic int ext4_show_options(struct seq_file *seq, struct dentry *root);\nstatic int ext4_commit_super(struct super_block *sb, int sync);\nstatic void ext4_mark_recovery_complete(struct super_block *sb,\n\t\t\t\t\tstruct ext4_super_block *es);\nstatic void ext4_clear_journal_err(struct super_block *sb,\n\t\t\t\t   struct ext4_super_block *es);\nstatic int ext4_sync_fs(struct super_block *sb, int wait);\nstatic int ext4_remount(struct super_block *sb, int *flags, char *data);\nstatic int ext4_statfs(struct dentry *dentry, struct kstatfs *buf);\nstatic int ext4_unfreeze(struct super_block *sb);\nstatic int ext4_freeze(struct super_block *sb);\nstatic struct dentry *ext4_mount(struct file_system_type *fs_type, int flags,\n\t\t       const char *dev_name, void *data);\nstatic inline int ext2_feature_set_ok(struct super_block *sb);\nstatic inline int ext3_feature_set_ok(struct super_block *sb);\nstatic int ext4_feature_set_ok(struct super_block *sb, int readonly);\nstatic void ext4_destroy_lazyinit_thread(void);\nstatic void ext4_unregister_li_request(struct super_block *sb);\nstatic void ext4_clear_request_list(void);\nstatic struct inode *ext4_get_journal_inode(struct super_block *sb,\n\t\t\t\t\t    unsigned int journal_inum);\n\n/*\n * Lock ordering\n *\n * Note the difference between i_mmap_sem (EXT4_I(inode)->i_mmap_sem) and\n * i_mmap_rwsem (inode->i_mmap_rwsem)!\n *\n * page fault path:\n * mmap_sem -> sb_start_pagefault -> i_mmap_sem (r) -> transaction start ->\n *   page lock -> i_data_sem (rw)\n *\n * buffered write path:\n * sb_start_write -> i_mutex -> mmap_sem\n * sb_start_write -> i_mutex -> transaction start -> page lock ->\n *   i_data_sem (rw)\n *\n * truncate:\n * sb_start_write -> i_mutex -> EXT4_STATE_DIOREAD_LOCK (w) -> i_mmap_sem (w) ->\n *   i_mmap_rwsem (w) -> page lock\n * sb_start_write -> i_mutex -> EXT4_STATE_DIOREAD_LOCK (w) -> i_mmap_sem (w) ->\n *   transaction start -> i_data_sem (rw)\n *\n * direct IO:\n * sb_start_write -> i_mutex -> EXT4_STATE_DIOREAD_LOCK (r) -> mmap_sem\n * sb_start_write -> i_mutex -> EXT4_STATE_DIOREAD_LOCK (r) ->\n *   transaction start -> i_data_sem (rw)\n *\n * writepages:\n * transaction start -> page lock(s) -> i_data_sem (rw)\n */\n\n#if !defined(CONFIG_EXT2_FS) && !defined(CONFIG_EXT2_FS_MODULE) && defined(CONFIG_EXT4_USE_FOR_EXT2)\nstatic struct file_system_type ext2_fs_type = {\n\t.owner\t\t= THIS_MODULE,\n\t.name\t\t= \"ext2\",\n\t.mount\t\t= ext4_mount,\n\t.kill_sb\t= kill_block_super,\n\t.fs_flags\t= FS_REQUIRES_DEV,\n};\nMODULE_ALIAS_FS(\"ext2\");\nMODULE_ALIAS(\"ext2\");\n#define IS_EXT2_SB(sb) ((sb)->s_bdev->bd_holder == &ext2_fs_type)\n#else\n#define IS_EXT2_SB(sb) (0)\n#endif\n\n\nstatic struct file_system_type ext3_fs_type = {\n\t.owner\t\t= THIS_MODULE,\n\t.name\t\t= \"ext3\",\n\t.mount\t\t= ext4_mount,\n\t.kill_sb\t= kill_block_super,\n\t.fs_flags\t= FS_REQUIRES_DEV,\n};\nMODULE_ALIAS_FS(\"ext3\");\nMODULE_ALIAS(\"ext3\");\n#define IS_EXT3_SB(sb) ((sb)->s_bdev->bd_holder == &ext3_fs_type)\n\nstatic int ext4_verify_csum_type(struct super_block *sb,\n\t\t\t\t struct ext4_super_block *es)\n{\n\tif (!ext4_has_feature_metadata_csum(sb))\n\t\treturn 1;\n\n\treturn es->s_checksum_type == EXT4_CRC32C_CHKSUM;\n}\n\nstatic __le32 ext4_superblock_csum(struct super_block *sb,\n\t\t\t\t   struct ext4_super_block *es)\n{\n\tstruct ext4_sb_info *sbi = EXT4_SB(sb);\n\tint offset = offsetof(struct ext4_super_block, s_checksum);\n\t__u32 csum;\n\n\tcsum = ext4_chksum(sbi, ~0, (char *)es, offset);\n\n\treturn cpu_to_le32(csum);\n}\n\nstatic int ext4_superblock_csum_verify(struct super_block *sb,\n\t\t\t\t       struct ext4_super_block *es)\n{\n\tif (!ext4_has_metadata_csum(sb))\n\t\treturn 1;\n\n\treturn es->s_checksum == ext4_superblock_csum(sb, es);\n}\n\nvoid ext4_superblock_csum_set(struct super_block *sb)\n{\n\tstruct ext4_super_block *es = EXT4_SB(sb)->s_es;\n\n\tif (!ext4_has_metadata_csum(sb))\n\t\treturn;\n\n\tes->s_checksum = ext4_superblock_csum(sb, es);\n}\n\nvoid *ext4_kvmalloc(size_t size, gfp_t flags)\n{\n\tvoid *ret;\n\n\tret = kmalloc(size, flags | __GFP_NOWARN);\n\tif (!ret)\n\t\tret = __vmalloc(size, flags, PAGE_KERNEL);\n\treturn ret;\n}\n\nvoid *ext4_kvzalloc(size_t size, gfp_t flags)\n{\n\tvoid *ret;\n\n\tret = kzalloc(size, flags | __GFP_NOWARN);\n\tif (!ret)\n\t\tret = __vmalloc(size, flags | __GFP_ZERO, PAGE_KERNEL);\n\treturn ret;\n}\n\next4_fsblk_t ext4_block_bitmap(struct super_block *sb,\n\t\t\t       struct ext4_group_desc *bg)\n{\n\treturn le32_to_cpu(bg->bg_block_bitmap_lo) |\n\t\t(EXT4_DESC_SIZE(sb) >= EXT4_MIN_DESC_SIZE_64BIT ?\n\t\t (ext4_fsblk_t)le32_to_cpu(bg->bg_block_bitmap_hi) << 32 : 0);\n}\n\next4_fsblk_t ext4_inode_bitmap(struct super_block *sb,\n\t\t\t       struct ext4_group_desc *bg)\n{\n\treturn le32_to_cpu(bg->bg_inode_bitmap_lo) |\n\t\t(EXT4_DESC_SIZE(sb) >= EXT4_MIN_DESC_SIZE_64BIT ?\n\t\t (ext4_fsblk_t)le32_to_cpu(bg->bg_inode_bitmap_hi) << 32 : 0);\n}\n\next4_fsblk_t ext4_inode_table(struct super_block *sb,\n\t\t\t      struct ext4_group_desc *bg)\n{\n\treturn le32_to_cpu(bg->bg_inode_table_lo) |\n\t\t(EXT4_DESC_SIZE(sb) >= EXT4_MIN_DESC_SIZE_64BIT ?\n\t\t (ext4_fsblk_t)le32_to_cpu(bg->bg_inode_table_hi) << 32 : 0);\n}\n\n__u32 ext4_free_group_clusters(struct super_block *sb,\n\t\t\t       struct ext4_group_desc *bg)\n{\n\treturn le16_to_cpu(bg->bg_free_blocks_count_lo) |\n\t\t(EXT4_DESC_SIZE(sb) >= EXT4_MIN_DESC_SIZE_64BIT ?\n\t\t (__u32)le16_to_cpu(bg->bg_free_blocks_count_hi) << 16 : 0);\n}\n\n__u32 ext4_free_inodes_count(struct super_block *sb,\n\t\t\t      struct ext4_group_desc *bg)\n{\n\treturn le16_to_cpu(bg->bg_free_inodes_count_lo) |\n\t\t(EXT4_DESC_SIZE(sb) >= EXT4_MIN_DESC_SIZE_64BIT ?\n\t\t (__u32)le16_to_cpu(bg->bg_free_inodes_count_hi) << 16 : 0);\n}\n\n__u32 ext4_used_dirs_count(struct super_block *sb,\n\t\t\t      struct ext4_group_desc *bg)\n{\n\treturn le16_to_cpu(bg->bg_used_dirs_count_lo) |\n\t\t(EXT4_DESC_SIZE(sb) >= EXT4_MIN_DESC_SIZE_64BIT ?\n\t\t (__u32)le16_to_cpu(bg->bg_used_dirs_count_hi) << 16 : 0);\n}\n\n__u32 ext4_itable_unused_count(struct super_block *sb,\n\t\t\t      struct ext4_group_desc *bg)\n{\n\treturn le16_to_cpu(bg->bg_itable_unused_lo) |\n\t\t(EXT4_DESC_SIZE(sb) >= EXT4_MIN_DESC_SIZE_64BIT ?\n\t\t (__u32)le16_to_cpu(bg->bg_itable_unused_hi) << 16 : 0);\n}\n\nvoid ext4_block_bitmap_set(struct super_block *sb,\n\t\t\t   struct ext4_group_desc *bg, ext4_fsblk_t blk)\n{\n\tbg->bg_block_bitmap_lo = cpu_to_le32((u32)blk);\n\tif (EXT4_DESC_SIZE(sb) >= EXT4_MIN_DESC_SIZE_64BIT)\n\t\tbg->bg_block_bitmap_hi = cpu_to_le32(blk >> 32);\n}\n\nvoid ext4_inode_bitmap_set(struct super_block *sb,\n\t\t\t   struct ext4_group_desc *bg, ext4_fsblk_t blk)\n{\n\tbg->bg_inode_bitmap_lo  = cpu_to_le32((u32)blk);\n\tif (EXT4_DESC_SIZE(sb) >= EXT4_MIN_DESC_SIZE_64BIT)\n\t\tbg->bg_inode_bitmap_hi = cpu_to_le32(blk >> 32);\n}\n\nvoid ext4_inode_table_set(struct super_block *sb,\n\t\t\t  struct ext4_group_desc *bg, ext4_fsblk_t blk)\n{\n\tbg->bg_inode_table_lo = cpu_to_le32((u32)blk);\n\tif (EXT4_DESC_SIZE(sb) >= EXT4_MIN_DESC_SIZE_64BIT)\n\t\tbg->bg_inode_table_hi = cpu_to_le32(blk >> 32);\n}\n\nvoid ext4_free_group_clusters_set(struct super_block *sb,\n\t\t\t\t  struct ext4_group_desc *bg, __u32 count)\n{\n\tbg->bg_free_blocks_count_lo = cpu_to_le16((__u16)count);\n\tif (EXT4_DESC_SIZE(sb) >= EXT4_MIN_DESC_SIZE_64BIT)\n\t\tbg->bg_free_blocks_count_hi = cpu_to_le16(count >> 16);\n}\n\nvoid ext4_free_inodes_set(struct super_block *sb,\n\t\t\t  struct ext4_group_desc *bg, __u32 count)\n{\n\tbg->bg_free_inodes_count_lo = cpu_to_le16((__u16)count);\n\tif (EXT4_DESC_SIZE(sb) >= EXT4_MIN_DESC_SIZE_64BIT)\n\t\tbg->bg_free_inodes_count_hi = cpu_to_le16(count >> 16);\n}\n\nvoid ext4_used_dirs_set(struct super_block *sb,\n\t\t\t  struct ext4_group_desc *bg, __u32 count)\n{\n\tbg->bg_used_dirs_count_lo = cpu_to_le16((__u16)count);\n\tif (EXT4_DESC_SIZE(sb) >= EXT4_MIN_DESC_SIZE_64BIT)\n\t\tbg->bg_used_dirs_count_hi = cpu_to_le16(count >> 16);\n}\n\nvoid ext4_itable_unused_set(struct super_block *sb,\n\t\t\t  struct ext4_group_desc *bg, __u32 count)\n{\n\tbg->bg_itable_unused_lo = cpu_to_le16((__u16)count);\n\tif (EXT4_DESC_SIZE(sb) >= EXT4_MIN_DESC_SIZE_64BIT)\n\t\tbg->bg_itable_unused_hi = cpu_to_le16(count >> 16);\n}\n\n\nstatic void __save_error_info(struct super_block *sb, const char *func,\n\t\t\t    unsigned int line)\n{\n\tstruct ext4_super_block *es = EXT4_SB(sb)->s_es;\n\n\tEXT4_SB(sb)->s_mount_state |= EXT4_ERROR_FS;\n\tif (bdev_read_only(sb->s_bdev))\n\t\treturn;\n\tes->s_state |= cpu_to_le16(EXT4_ERROR_FS);\n\tes->s_last_error_time = cpu_to_le32(get_seconds());\n\tstrncpy(es->s_last_error_func, func, sizeof(es->s_last_error_func));\n\tes->s_last_error_line = cpu_to_le32(line);\n\tif (!es->s_first_error_time) {\n\t\tes->s_first_error_time = es->s_last_error_time;\n\t\tstrncpy(es->s_first_error_func, func,\n\t\t\tsizeof(es->s_first_error_func));\n\t\tes->s_first_error_line = cpu_to_le32(line);\n\t\tes->s_first_error_ino = es->s_last_error_ino;\n\t\tes->s_first_error_block = es->s_last_error_block;\n\t}\n\t/*\n\t * Start the daily error reporting function if it hasn't been\n\t * started already\n\t */\n\tif (!es->s_error_count)\n\t\tmod_timer(&EXT4_SB(sb)->s_err_report, jiffies + 24*60*60*HZ);\n\tle32_add_cpu(&es->s_error_count, 1);\n}\n\nstatic void save_error_info(struct super_block *sb, const char *func,\n\t\t\t    unsigned int line)\n{\n\t__save_error_info(sb, func, line);\n\text4_commit_super(sb, 1);\n}\n\n/*\n * The del_gendisk() function uninitializes the disk-specific data\n * structures, including the bdi structure, without telling anyone\n * else.  Once this happens, any attempt to call mark_buffer_dirty()\n * (for example, by ext4_commit_super), will cause a kernel OOPS.\n * This is a kludge to prevent these oops until we can put in a proper\n * hook in del_gendisk() to inform the VFS and file system layers.\n */\nstatic int block_device_ejected(struct super_block *sb)\n{\n\tstruct inode *bd_inode = sb->s_bdev->bd_inode;\n\tstruct backing_dev_info *bdi = inode_to_bdi(bd_inode);\n\n\treturn bdi->dev == NULL;\n}\n\nstatic void ext4_journal_commit_callback(journal_t *journal, transaction_t *txn)\n{\n\tstruct super_block\t\t*sb = journal->j_private;\n\tstruct ext4_sb_info\t\t*sbi = EXT4_SB(sb);\n\tint\t\t\t\terror = is_journal_aborted(journal);\n\tstruct ext4_journal_cb_entry\t*jce;\n\n\tBUG_ON(txn->t_state == T_FINISHED);\n\tspin_lock(&sbi->s_md_lock);\n\twhile (!list_empty(&txn->t_private_list)) {\n\t\tjce = list_entry(txn->t_private_list.next,\n\t\t\t\t struct ext4_journal_cb_entry, jce_list);\n\t\tlist_del_init(&jce->jce_list);\n\t\tspin_unlock(&sbi->s_md_lock);\n\t\tjce->jce_func(sb, jce, error);\n\t\tspin_lock(&sbi->s_md_lock);\n\t}\n\tspin_unlock(&sbi->s_md_lock);\n}\n\n/* Deal with the reporting of failure conditions on a filesystem such as\n * inconsistencies detected or read IO failures.\n *\n * On ext2, we can store the error state of the filesystem in the\n * superblock.  That is not possible on ext4, because we may have other\n * write ordering constraints on the superblock which prevent us from\n * writing it out straight away; and given that the journal is about to\n * be aborted, we can't rely on the current, or future, transactions to\n * write out the superblock safely.\n *\n * We'll just use the jbd2_journal_abort() error code to record an error in\n * the journal instead.  On recovery, the journal will complain about\n * that error until we've noted it down and cleared it.\n */\n\nstatic void ext4_handle_error(struct super_block *sb)\n{\n\tif (sb->s_flags & MS_RDONLY)\n\t\treturn;\n\n\tif (!test_opt(sb, ERRORS_CONT)) {\n\t\tjournal_t *journal = EXT4_SB(sb)->s_journal;\n\n\t\tEXT4_SB(sb)->s_mount_flags |= EXT4_MF_FS_ABORTED;\n\t\tif (journal)\n\t\t\tjbd2_journal_abort(journal, -EIO);\n\t}\n\tif (test_opt(sb, ERRORS_RO)) {\n\t\text4_msg(sb, KERN_CRIT, \"Remounting filesystem read-only\");\n\t\t/*\n\t\t * Make sure updated value of ->s_mount_flags will be visible\n\t\t * before ->s_flags update\n\t\t */\n\t\tsmp_wmb();\n\t\tsb->s_flags |= MS_RDONLY;\n\t}\n\tif (test_opt(sb, ERRORS_PANIC)) {\n\t\tif (EXT4_SB(sb)->s_journal &&\n\t\t  !(EXT4_SB(sb)->s_journal->j_flags & JBD2_REC_ERR))\n\t\t\treturn;\n\t\tpanic(\"EXT4-fs (device %s): panic forced after error\\n\",\n\t\t\tsb->s_id);\n\t}\n}\n\n#define ext4_error_ratelimit(sb)\t\t\t\t\t\\\n\t\t___ratelimit(&(EXT4_SB(sb)->s_err_ratelimit_state),\t\\\n\t\t\t     \"EXT4-fs error\")\n\nvoid __ext4_error(struct super_block *sb, const char *function,\n\t\t  unsigned int line, const char *fmt, ...)\n{\n\tstruct va_format vaf;\n\tva_list args;\n\n\tif (ext4_error_ratelimit(sb)) {\n\t\tva_start(args, fmt);\n\t\tvaf.fmt = fmt;\n\t\tvaf.va = &args;\n\t\tprintk(KERN_CRIT\n\t\t       \"EXT4-fs error (device %s): %s:%d: comm %s: %pV\\n\",\n\t\t       sb->s_id, function, line, current->comm, &vaf);\n\t\tva_end(args);\n\t}\n\tsave_error_info(sb, function, line);\n\text4_handle_error(sb);\n}\n\nvoid __ext4_error_inode(struct inode *inode, const char *function,\n\t\t\tunsigned int line, ext4_fsblk_t block,\n\t\t\tconst char *fmt, ...)\n{\n\tva_list args;\n\tstruct va_format vaf;\n\tstruct ext4_super_block *es = EXT4_SB(inode->i_sb)->s_es;\n\n\tes->s_last_error_ino = cpu_to_le32(inode->i_ino);\n\tes->s_last_error_block = cpu_to_le64(block);\n\tif (ext4_error_ratelimit(inode->i_sb)) {\n\t\tva_start(args, fmt);\n\t\tvaf.fmt = fmt;\n\t\tvaf.va = &args;\n\t\tif (block)\n\t\t\tprintk(KERN_CRIT \"EXT4-fs error (device %s): %s:%d: \"\n\t\t\t       \"inode #%lu: block %llu: comm %s: %pV\\n\",\n\t\t\t       inode->i_sb->s_id, function, line, inode->i_ino,\n\t\t\t       block, current->comm, &vaf);\n\t\telse\n\t\t\tprintk(KERN_CRIT \"EXT4-fs error (device %s): %s:%d: \"\n\t\t\t       \"inode #%lu: comm %s: %pV\\n\",\n\t\t\t       inode->i_sb->s_id, function, line, inode->i_ino,\n\t\t\t       current->comm, &vaf);\n\t\tva_end(args);\n\t}\n\tsave_error_info(inode->i_sb, function, line);\n\text4_handle_error(inode->i_sb);\n}\n\nvoid __ext4_error_file(struct file *file, const char *function,\n\t\t       unsigned int line, ext4_fsblk_t block,\n\t\t       const char *fmt, ...)\n{\n\tva_list args;\n\tstruct va_format vaf;\n\tstruct ext4_super_block *es;\n\tstruct inode *inode = file_inode(file);\n\tchar pathname[80], *path;\n\n\tes = EXT4_SB(inode->i_sb)->s_es;\n\tes->s_last_error_ino = cpu_to_le32(inode->i_ino);\n\tif (ext4_error_ratelimit(inode->i_sb)) {\n\t\tpath = file_path(file, pathname, sizeof(pathname));\n\t\tif (IS_ERR(path))\n\t\t\tpath = \"(unknown)\";\n\t\tva_start(args, fmt);\n\t\tvaf.fmt = fmt;\n\t\tvaf.va = &args;\n\t\tif (block)\n\t\t\tprintk(KERN_CRIT\n\t\t\t       \"EXT4-fs error (device %s): %s:%d: inode #%lu: \"\n\t\t\t       \"block %llu: comm %s: path %s: %pV\\n\",\n\t\t\t       inode->i_sb->s_id, function, line, inode->i_ino,\n\t\t\t       block, current->comm, path, &vaf);\n\t\telse\n\t\t\tprintk(KERN_CRIT\n\t\t\t       \"EXT4-fs error (device %s): %s:%d: inode #%lu: \"\n\t\t\t       \"comm %s: path %s: %pV\\n\",\n\t\t\t       inode->i_sb->s_id, function, line, inode->i_ino,\n\t\t\t       current->comm, path, &vaf);\n\t\tva_end(args);\n\t}\n\tsave_error_info(inode->i_sb, function, line);\n\text4_handle_error(inode->i_sb);\n}\n\nconst char *ext4_decode_error(struct super_block *sb, int errno,\n\t\t\t      char nbuf[16])\n{\n\tchar *errstr = NULL;\n\n\tswitch (errno) {\n\tcase -EFSCORRUPTED:\n\t\terrstr = \"Corrupt filesystem\";\n\t\tbreak;\n\tcase -EFSBADCRC:\n\t\terrstr = \"Filesystem failed CRC\";\n\t\tbreak;\n\tcase -EIO:\n\t\terrstr = \"IO failure\";\n\t\tbreak;\n\tcase -ENOMEM:\n\t\terrstr = \"Out of memory\";\n\t\tbreak;\n\tcase -EROFS:\n\t\tif (!sb || (EXT4_SB(sb)->s_journal &&\n\t\t\t    EXT4_SB(sb)->s_journal->j_flags & JBD2_ABORT))\n\t\t\terrstr = \"Journal has aborted\";\n\t\telse\n\t\t\terrstr = \"Readonly filesystem\";\n\t\tbreak;\n\tdefault:\n\t\t/* If the caller passed in an extra buffer for unknown\n\t\t * errors, textualise them now.  Else we just return\n\t\t * NULL. */\n\t\tif (nbuf) {\n\t\t\t/* Check for truncated error codes... */\n\t\t\tif (snprintf(nbuf, 16, \"error %d\", -errno) >= 0)\n\t\t\t\terrstr = nbuf;\n\t\t}\n\t\tbreak;\n\t}\n\n\treturn errstr;\n}\n\n/* __ext4_std_error decodes expected errors from journaling functions\n * automatically and invokes the appropriate error response.  */\n\nvoid __ext4_std_error(struct super_block *sb, const char *function,\n\t\t      unsigned int line, int errno)\n{\n\tchar nbuf[16];\n\tconst char *errstr;\n\n\t/* Special case: if the error is EROFS, and we're not already\n\t * inside a transaction, then there's really no point in logging\n\t * an error. */\n\tif (errno == -EROFS && journal_current_handle() == NULL &&\n\t    (sb->s_flags & MS_RDONLY))\n\t\treturn;\n\n\tif (ext4_error_ratelimit(sb)) {\n\t\terrstr = ext4_decode_error(sb, errno, nbuf);\n\t\tprintk(KERN_CRIT \"EXT4-fs error (device %s) in %s:%d: %s\\n\",\n\t\t       sb->s_id, function, line, errstr);\n\t}\n\n\tsave_error_info(sb, function, line);\n\text4_handle_error(sb);\n}\n\n/*\n * ext4_abort is a much stronger failure handler than ext4_error.  The\n * abort function may be used to deal with unrecoverable failures such\n * as journal IO errors or ENOMEM at a critical moment in log management.\n *\n * We unconditionally force the filesystem into an ABORT|READONLY state,\n * unless the error response on the fs has been set to panic in which\n * case we take the easy way out and panic immediately.\n */\n\nvoid __ext4_abort(struct super_block *sb, const char *function,\n\t\tunsigned int line, const char *fmt, ...)\n{\n\tstruct va_format vaf;\n\tva_list args;\n\n\tsave_error_info(sb, function, line);\n\tva_start(args, fmt);\n\tvaf.fmt = fmt;\n\tvaf.va = &args;\n\tprintk(KERN_CRIT \"EXT4-fs error (device %s): %s:%d: %pV\\n\",\n\t       sb->s_id, function, line, &vaf);\n\tva_end(args);\n\n\tif ((sb->s_flags & MS_RDONLY) == 0) {\n\t\text4_msg(sb, KERN_CRIT, \"Remounting filesystem read-only\");\n\t\tEXT4_SB(sb)->s_mount_flags |= EXT4_MF_FS_ABORTED;\n\t\t/*\n\t\t * Make sure updated value of ->s_mount_flags will be visible\n\t\t * before ->s_flags update\n\t\t */\n\t\tsmp_wmb();\n\t\tsb->s_flags |= MS_RDONLY;\n\t\tif (EXT4_SB(sb)->s_journal)\n\t\t\tjbd2_journal_abort(EXT4_SB(sb)->s_journal, -EIO);\n\t\tsave_error_info(sb, function, line);\n\t}\n\tif (test_opt(sb, ERRORS_PANIC)) {\n\t\tif (EXT4_SB(sb)->s_journal &&\n\t\t  !(EXT4_SB(sb)->s_journal->j_flags & JBD2_REC_ERR))\n\t\t\treturn;\n\t\tpanic(\"EXT4-fs panic from previous error\\n\");\n\t}\n}\n\nvoid __ext4_msg(struct super_block *sb,\n\t\tconst char *prefix, const char *fmt, ...)\n{\n\tstruct va_format vaf;\n\tva_list args;\n\n\tif (!___ratelimit(&(EXT4_SB(sb)->s_msg_ratelimit_state), \"EXT4-fs\"))\n\t\treturn;\n\n\tva_start(args, fmt);\n\tvaf.fmt = fmt;\n\tvaf.va = &args;\n\tprintk(\"%sEXT4-fs (%s): %pV\\n\", prefix, sb->s_id, &vaf);\n\tva_end(args);\n}\n\n#define ext4_warning_ratelimit(sb)\t\t\t\t\t\\\n\t\t___ratelimit(&(EXT4_SB(sb)->s_warning_ratelimit_state),\t\\\n\t\t\t     \"EXT4-fs warning\")\n\nvoid __ext4_warning(struct super_block *sb, const char *function,\n\t\t    unsigned int line, const char *fmt, ...)\n{\n\tstruct va_format vaf;\n\tva_list args;\n\n\tif (!ext4_warning_ratelimit(sb))\n\t\treturn;\n\n\tva_start(args, fmt);\n\tvaf.fmt = fmt;\n\tvaf.va = &args;\n\tprintk(KERN_WARNING \"EXT4-fs warning (device %s): %s:%d: %pV\\n\",\n\t       sb->s_id, function, line, &vaf);\n\tva_end(args);\n}\n\nvoid __ext4_warning_inode(const struct inode *inode, const char *function,\n\t\t\t  unsigned int line, const char *fmt, ...)\n{\n\tstruct va_format vaf;\n\tva_list args;\n\n\tif (!ext4_warning_ratelimit(inode->i_sb))\n\t\treturn;\n\n\tva_start(args, fmt);\n\tvaf.fmt = fmt;\n\tvaf.va = &args;\n\tprintk(KERN_WARNING \"EXT4-fs warning (device %s): %s:%d: \"\n\t       \"inode #%lu: comm %s: %pV\\n\", inode->i_sb->s_id,\n\t       function, line, inode->i_ino, current->comm, &vaf);\n\tva_end(args);\n}\n\nvoid __ext4_grp_locked_error(const char *function, unsigned int line,\n\t\t\t     struct super_block *sb, ext4_group_t grp,\n\t\t\t     unsigned long ino, ext4_fsblk_t block,\n\t\t\t     const char *fmt, ...)\n__releases(bitlock)\n__acquires(bitlock)\n{\n\tstruct va_format vaf;\n\tva_list args;\n\tstruct ext4_super_block *es = EXT4_SB(sb)->s_es;\n\n\tes->s_last_error_ino = cpu_to_le32(ino);\n\tes->s_last_error_block = cpu_to_le64(block);\n\t__save_error_info(sb, function, line);\n\n\tif (ext4_error_ratelimit(sb)) {\n\t\tva_start(args, fmt);\n\t\tvaf.fmt = fmt;\n\t\tvaf.va = &args;\n\t\tprintk(KERN_CRIT \"EXT4-fs error (device %s): %s:%d: group %u, \",\n\t\t       sb->s_id, function, line, grp);\n\t\tif (ino)\n\t\t\tprintk(KERN_CONT \"inode %lu: \", ino);\n\t\tif (block)\n\t\t\tprintk(KERN_CONT \"block %llu:\",\n\t\t\t       (unsigned long long) block);\n\t\tprintk(KERN_CONT \"%pV\\n\", &vaf);\n\t\tva_end(args);\n\t}\n\n\tif (test_opt(sb, ERRORS_CONT)) {\n\t\text4_commit_super(sb, 0);\n\t\treturn;\n\t}\n\n\text4_unlock_group(sb, grp);\n\text4_handle_error(sb);\n\t/*\n\t * We only get here in the ERRORS_RO case; relocking the group\n\t * may be dangerous, but nothing bad will happen since the\n\t * filesystem will have already been marked read/only and the\n\t * journal has been aborted.  We return 1 as a hint to callers\n\t * who might what to use the return value from\n\t * ext4_grp_locked_error() to distinguish between the\n\t * ERRORS_CONT and ERRORS_RO case, and perhaps return more\n\t * aggressively from the ext4 function in question, with a\n\t * more appropriate error code.\n\t */\n\text4_lock_group(sb, grp);\n\treturn;\n}\n\nvoid ext4_update_dynamic_rev(struct super_block *sb)\n{\n\tstruct ext4_super_block *es = EXT4_SB(sb)->s_es;\n\n\tif (le32_to_cpu(es->s_rev_level) > EXT4_GOOD_OLD_REV)\n\t\treturn;\n\n\text4_warning(sb,\n\t\t     \"updating to rev %d because of new feature flag, \"\n\t\t     \"running e2fsck is recommended\",\n\t\t     EXT4_DYNAMIC_REV);\n\n\tes->s_first_ino = cpu_to_le32(EXT4_GOOD_OLD_FIRST_INO);\n\tes->s_inode_size = cpu_to_le16(EXT4_GOOD_OLD_INODE_SIZE);\n\tes->s_rev_level = cpu_to_le32(EXT4_DYNAMIC_REV);\n\t/* leave es->s_feature_*compat flags alone */\n\t/* es->s_uuid will be set by e2fsck if empty */\n\n\t/*\n\t * The rest of the superblock fields should be zero, and if not it\n\t * means they are likely already in use, so leave them alone.  We\n\t * can leave it up to e2fsck to clean up any inconsistencies there.\n\t */\n}\n\n/*\n * Open the external journal device\n */\nstatic struct block_device *ext4_blkdev_get(dev_t dev, struct super_block *sb)\n{\n\tstruct block_device *bdev;\n\tchar b[BDEVNAME_SIZE];\n\n\tbdev = blkdev_get_by_dev(dev, FMODE_READ|FMODE_WRITE|FMODE_EXCL, sb);\n\tif (IS_ERR(bdev))\n\t\tgoto fail;\n\treturn bdev;\n\nfail:\n\text4_msg(sb, KERN_ERR, \"failed to open journal device %s: %ld\",\n\t\t\t__bdevname(dev, b), PTR_ERR(bdev));\n\treturn NULL;\n}\n\n/*\n * Release the journal device\n */\nstatic void ext4_blkdev_put(struct block_device *bdev)\n{\n\tblkdev_put(bdev, FMODE_READ|FMODE_WRITE|FMODE_EXCL);\n}\n\nstatic void ext4_blkdev_remove(struct ext4_sb_info *sbi)\n{\n\tstruct block_device *bdev;\n\tbdev = sbi->journal_bdev;\n\tif (bdev) {\n\t\text4_blkdev_put(bdev);\n\t\tsbi->journal_bdev = NULL;\n\t}\n}\n\nstatic inline struct inode *orphan_list_entry(struct list_head *l)\n{\n\treturn &list_entry(l, struct ext4_inode_info, i_orphan)->vfs_inode;\n}\n\nstatic void dump_orphan_list(struct super_block *sb, struct ext4_sb_info *sbi)\n{\n\tstruct list_head *l;\n\n\text4_msg(sb, KERN_ERR, \"sb orphan head is %d\",\n\t\t le32_to_cpu(sbi->s_es->s_last_orphan));\n\n\tprintk(KERN_ERR \"sb_info orphan list:\\n\");\n\tlist_for_each(l, &sbi->s_orphan) {\n\t\tstruct inode *inode = orphan_list_entry(l);\n\t\tprintk(KERN_ERR \"  \"\n\t\t       \"inode %s:%lu at %p: mode %o, nlink %d, next %d\\n\",\n\t\t       inode->i_sb->s_id, inode->i_ino, inode,\n\t\t       inode->i_mode, inode->i_nlink,\n\t\t       NEXT_ORPHAN(inode));\n\t}\n}\n\nstatic void ext4_put_super(struct super_block *sb)\n{\n\tstruct ext4_sb_info *sbi = EXT4_SB(sb);\n\tstruct ext4_super_block *es = sbi->s_es;\n\tint i, err;\n\n\text4_unregister_li_request(sb);\n\tdquot_disable(sb, -1, DQUOT_USAGE_ENABLED | DQUOT_LIMITS_ENABLED);\n\n\tflush_workqueue(sbi->rsv_conversion_wq);\n\tdestroy_workqueue(sbi->rsv_conversion_wq);\n\n\tif (sbi->s_journal) {\n\t\terr = jbd2_journal_destroy(sbi->s_journal);\n\t\tsbi->s_journal = NULL;\n\t\tif (err < 0)\n\t\t\text4_abort(sb, \"Couldn't clean up the journal\");\n\t}\n\n\text4_unregister_sysfs(sb);\n\text4_es_unregister_shrinker(sbi);\n\tdel_timer_sync(&sbi->s_err_report);\n\text4_release_system_zone(sb);\n\text4_mb_release(sb);\n\text4_ext_release(sb);\n\n\tif (!(sb->s_flags & MS_RDONLY)) {\n\t\text4_clear_feature_journal_needs_recovery(sb);\n\t\tes->s_state = cpu_to_le16(sbi->s_mount_state);\n\t}\n\tif (!(sb->s_flags & MS_RDONLY))\n\t\text4_commit_super(sb, 1);\n\n\tfor (i = 0; i < sbi->s_gdb_count; i++)\n\t\tbrelse(sbi->s_group_desc[i]);\n\tkvfree(sbi->s_group_desc);\n\tkvfree(sbi->s_flex_groups);\n\tpercpu_counter_destroy(&sbi->s_freeclusters_counter);\n\tpercpu_counter_destroy(&sbi->s_freeinodes_counter);\n\tpercpu_counter_destroy(&sbi->s_dirs_counter);\n\tpercpu_counter_destroy(&sbi->s_dirtyclusters_counter);\n\tpercpu_free_rwsem(&sbi->s_journal_flag_rwsem);\n#ifdef CONFIG_QUOTA\n\tfor (i = 0; i < EXT4_MAXQUOTAS; i++)\n\t\tkfree(sbi->s_qf_names[i]);\n#endif\n\n\t/* Debugging code just in case the in-memory inode orphan list\n\t * isn't empty.  The on-disk one can be non-empty if we've\n\t * detected an error and taken the fs readonly, but the\n\t * in-memory list had better be clean by this point. */\n\tif (!list_empty(&sbi->s_orphan))\n\t\tdump_orphan_list(sb, sbi);\n\tJ_ASSERT(list_empty(&sbi->s_orphan));\n\n\tsync_blockdev(sb->s_bdev);\n\tinvalidate_bdev(sb->s_bdev);\n\tif (sbi->journal_bdev && sbi->journal_bdev != sb->s_bdev) {\n\t\t/*\n\t\t * Invalidate the journal device's buffers.  We don't want them\n\t\t * floating about in memory - the physical journal device may\n\t\t * hotswapped, and it breaks the `ro-after' testing code.\n\t\t */\n\t\tsync_blockdev(sbi->journal_bdev);\n\t\tinvalidate_bdev(sbi->journal_bdev);\n\t\text4_blkdev_remove(sbi);\n\t}\n\tif (sbi->s_mb_cache) {\n\t\text4_xattr_destroy_cache(sbi->s_mb_cache);\n\t\tsbi->s_mb_cache = NULL;\n\t}\n\tif (sbi->s_mmp_tsk)\n\t\tkthread_stop(sbi->s_mmp_tsk);\n\tbrelse(sbi->s_sbh);\n\tsb->s_fs_info = NULL;\n\t/*\n\t * Now that we are completely done shutting down the\n\t * superblock, we need to actually destroy the kobject.\n\t */\n\tkobject_put(&sbi->s_kobj);\n\twait_for_completion(&sbi->s_kobj_unregister);\n\tif (sbi->s_chksum_driver)\n\t\tcrypto_free_shash(sbi->s_chksum_driver);\n\tkfree(sbi->s_blockgroup_lock);\n\tkfree(sbi);\n}\n\nstatic struct kmem_cache *ext4_inode_cachep;\n\n/*\n * Called inside transaction, so use GFP_NOFS\n */\nstatic struct inode *ext4_alloc_inode(struct super_block *sb)\n{\n\tstruct ext4_inode_info *ei;\n\n\tei = kmem_cache_alloc(ext4_inode_cachep, GFP_NOFS);\n\tif (!ei)\n\t\treturn NULL;\n\n\tei->vfs_inode.i_version = 1;\n\tspin_lock_init(&ei->i_raw_lock);\n\tINIT_LIST_HEAD(&ei->i_prealloc_list);\n\tspin_lock_init(&ei->i_prealloc_lock);\n\text4_es_init_tree(&ei->i_es_tree);\n\trwlock_init(&ei->i_es_lock);\n\tINIT_LIST_HEAD(&ei->i_es_list);\n\tei->i_es_all_nr = 0;\n\tei->i_es_shk_nr = 0;\n\tei->i_es_shrink_lblk = 0;\n\tei->i_reserved_data_blocks = 0;\n\tei->i_reserved_meta_blocks = 0;\n\tei->i_allocated_meta_blocks = 0;\n\tei->i_da_metadata_calc_len = 0;\n\tei->i_da_metadata_calc_last_lblock = 0;\n\tspin_lock_init(&(ei->i_block_reservation_lock));\n#ifdef CONFIG_QUOTA\n\tei->i_reserved_quota = 0;\n\tmemset(&ei->i_dquot, 0, sizeof(ei->i_dquot));\n#endif\n\tei->jinode = NULL;\n\tINIT_LIST_HEAD(&ei->i_rsv_conversion_list);\n\tspin_lock_init(&ei->i_completed_io_lock);\n\tei->i_sync_tid = 0;\n\tei->i_datasync_tid = 0;\n\tatomic_set(&ei->i_unwritten, 0);\n\tINIT_WORK(&ei->i_rsv_conversion_work, ext4_end_io_rsv_work);\n\treturn &ei->vfs_inode;\n}\n\nstatic int ext4_drop_inode(struct inode *inode)\n{\n\tint drop = generic_drop_inode(inode);\n\n\ttrace_ext4_drop_inode(inode, drop);\n\treturn drop;\n}\n\nstatic void ext4_i_callback(struct rcu_head *head)\n{\n\tstruct inode *inode = container_of(head, struct inode, i_rcu);\n\tkmem_cache_free(ext4_inode_cachep, EXT4_I(inode));\n}\n\nstatic void ext4_destroy_inode(struct inode *inode)\n{\n\tif (!list_empty(&(EXT4_I(inode)->i_orphan))) {\n\t\text4_msg(inode->i_sb, KERN_ERR,\n\t\t\t \"Inode %lu (%p): orphan list check failed!\",\n\t\t\t inode->i_ino, EXT4_I(inode));\n\t\tprint_hex_dump(KERN_INFO, \"\", DUMP_PREFIX_ADDRESS, 16, 4,\n\t\t\t\tEXT4_I(inode), sizeof(struct ext4_inode_info),\n\t\t\t\ttrue);\n\t\tdump_stack();\n\t}\n\tcall_rcu(&inode->i_rcu, ext4_i_callback);\n}\n\nstatic void init_once(void *foo)\n{\n\tstruct ext4_inode_info *ei = (struct ext4_inode_info *) foo;\n\n\tINIT_LIST_HEAD(&ei->i_orphan);\n\tinit_rwsem(&ei->xattr_sem);\n\tinit_rwsem(&ei->i_data_sem);\n\tinit_rwsem(&ei->i_mmap_sem);\n\tinode_init_once(&ei->vfs_inode);\n}\n\nstatic int __init init_inodecache(void)\n{\n\text4_inode_cachep = kmem_cache_create(\"ext4_inode_cache\",\n\t\t\t\t\t     sizeof(struct ext4_inode_info),\n\t\t\t\t\t     0, (SLAB_RECLAIM_ACCOUNT|\n\t\t\t\t\t\tSLAB_MEM_SPREAD|SLAB_ACCOUNT),\n\t\t\t\t\t     init_once);\n\tif (ext4_inode_cachep == NULL)\n\t\treturn -ENOMEM;\n\treturn 0;\n}\n\nstatic void destroy_inodecache(void)\n{\n\t/*\n\t * Make sure all delayed rcu free inodes are flushed before we\n\t * destroy cache.\n\t */\n\trcu_barrier();\n\tkmem_cache_destroy(ext4_inode_cachep);\n}\n\nvoid ext4_clear_inode(struct inode *inode)\n{\n\tinvalidate_inode_buffers(inode);\n\tclear_inode(inode);\n\tdquot_drop(inode);\n\text4_discard_preallocations(inode);\n\text4_es_remove_extent(inode, 0, EXT_MAX_BLOCKS);\n\tif (EXT4_I(inode)->jinode) {\n\t\tjbd2_journal_release_jbd_inode(EXT4_JOURNAL(inode),\n\t\t\t\t\t       EXT4_I(inode)->jinode);\n\t\tjbd2_free_inode(EXT4_I(inode)->jinode);\n\t\tEXT4_I(inode)->jinode = NULL;\n\t}\n#ifdef CONFIG_EXT4_FS_ENCRYPTION\n\tfscrypt_put_encryption_info(inode, NULL);\n#endif\n}\n\nstatic struct inode *ext4_nfs_get_inode(struct super_block *sb,\n\t\t\t\t\tu64 ino, u32 generation)\n{\n\tstruct inode *inode;\n\n\tif (ino < EXT4_FIRST_INO(sb) && ino != EXT4_ROOT_INO)\n\t\treturn ERR_PTR(-ESTALE);\n\tif (ino > le32_to_cpu(EXT4_SB(sb)->s_es->s_inodes_count))\n\t\treturn ERR_PTR(-ESTALE);\n\n\t/* iget isn't really right if the inode is currently unallocated!!\n\t *\n\t * ext4_read_inode will return a bad_inode if the inode had been\n\t * deleted, so we should be safe.\n\t *\n\t * Currently we don't know the generation for parent directory, so\n\t * a generation of 0 means \"accept any\"\n\t */\n\tinode = ext4_iget_normal(sb, ino);\n\tif (IS_ERR(inode))\n\t\treturn ERR_CAST(inode);\n\tif (generation && inode->i_generation != generation) {\n\t\tiput(inode);\n\t\treturn ERR_PTR(-ESTALE);\n\t}\n\n\treturn inode;\n}\n\nstatic struct dentry *ext4_fh_to_dentry(struct super_block *sb, struct fid *fid,\n\t\t\t\t\tint fh_len, int fh_type)\n{\n\treturn generic_fh_to_dentry(sb, fid, fh_len, fh_type,\n\t\t\t\t    ext4_nfs_get_inode);\n}\n\nstatic struct dentry *ext4_fh_to_parent(struct super_block *sb, struct fid *fid,\n\t\t\t\t\tint fh_len, int fh_type)\n{\n\treturn generic_fh_to_parent(sb, fid, fh_len, fh_type,\n\t\t\t\t    ext4_nfs_get_inode);\n}\n\n/*\n * Try to release metadata pages (indirect blocks, directories) which are\n * mapped via the block device.  Since these pages could have journal heads\n * which would prevent try_to_free_buffers() from freeing them, we must use\n * jbd2 layer's try_to_free_buffers() function to release them.\n */\nstatic int bdev_try_to_free_page(struct super_block *sb, struct page *page,\n\t\t\t\t gfp_t wait)\n{\n\tjournal_t *journal = EXT4_SB(sb)->s_journal;\n\n\tWARN_ON(PageChecked(page));\n\tif (!page_has_buffers(page))\n\t\treturn 0;\n\tif (journal)\n\t\treturn jbd2_journal_try_to_free_buffers(journal, page,\n\t\t\t\t\t\twait & ~__GFP_DIRECT_RECLAIM);\n\treturn try_to_free_buffers(page);\n}\n\n#ifdef CONFIG_EXT4_FS_ENCRYPTION\nstatic int ext4_get_context(struct inode *inode, void *ctx, size_t len)\n{\n\treturn ext4_xattr_get(inode, EXT4_XATTR_INDEX_ENCRYPTION,\n\t\t\t\t EXT4_XATTR_NAME_ENCRYPTION_CONTEXT, ctx, len);\n}\n\nstatic int ext4_key_prefix(struct inode *inode, u8 **key)\n{\n\t*key = EXT4_SB(inode->i_sb)->key_prefix;\n\treturn EXT4_SB(inode->i_sb)->key_prefix_size;\n}\n\nstatic int ext4_prepare_context(struct inode *inode)\n{\n\treturn ext4_convert_inline_data(inode);\n}\n\nstatic int ext4_set_context(struct inode *inode, const void *ctx, size_t len,\n\t\t\t\t\t\t\tvoid *fs_data)\n{\n\thandle_t *handle = fs_data;\n\tint res, res2, retries = 0;\n\n\t/*\n\t * If a journal handle was specified, then the encryption context is\n\t * being set on a new inode via inheritance and is part of a larger\n\t * transaction to create the inode.  Otherwise the encryption context is\n\t * being set on an existing inode in its own transaction.  Only in the\n\t * latter case should the \"retry on ENOSPC\" logic be used.\n\t */\n\n\tif (handle) {\n\t\tres = ext4_xattr_set_handle(handle, inode,\n\t\t\t\t\t    EXT4_XATTR_INDEX_ENCRYPTION,\n\t\t\t\t\t    EXT4_XATTR_NAME_ENCRYPTION_CONTEXT,\n\t\t\t\t\t    ctx, len, 0);\n\t\tif (!res) {\n\t\t\text4_set_inode_flag(inode, EXT4_INODE_ENCRYPT);\n\t\t\text4_clear_inode_state(inode,\n\t\t\t\t\tEXT4_STATE_MAY_INLINE_DATA);\n\t\t\t/*\n\t\t\t * Update inode->i_flags - e.g. S_DAX may get disabled\n\t\t\t */\n\t\t\text4_set_inode_flags(inode);\n\t\t}\n\t\treturn res;\n\t}\n\nretry:\n\thandle = ext4_journal_start(inode, EXT4_HT_MISC,\n\t\t\text4_jbd2_credits_xattr(inode));\n\tif (IS_ERR(handle))\n\t\treturn PTR_ERR(handle);\n\n\tres = ext4_xattr_set_handle(handle, inode, EXT4_XATTR_INDEX_ENCRYPTION,\n\t\t\t\t    EXT4_XATTR_NAME_ENCRYPTION_CONTEXT,\n\t\t\t\t    ctx, len, 0);\n\tif (!res) {\n\t\text4_set_inode_flag(inode, EXT4_INODE_ENCRYPT);\n\t\t/* Update inode->i_flags - e.g. S_DAX may get disabled */\n\t\text4_set_inode_flags(inode);\n\t\tres = ext4_mark_inode_dirty(handle, inode);\n\t\tif (res)\n\t\t\tEXT4_ERROR_INODE(inode, \"Failed to mark inode dirty\");\n\t}\n\tres2 = ext4_journal_stop(handle);\n\n\tif (res == -ENOSPC && ext4_should_retry_alloc(inode->i_sb, &retries))\n\t\tgoto retry;\n\tif (!res)\n\t\tres = res2;\n\treturn res;\n}\n\nstatic int ext4_dummy_context(struct inode *inode)\n{\n\treturn DUMMY_ENCRYPTION_ENABLED(EXT4_SB(inode->i_sb));\n}\n\nstatic unsigned ext4_max_namelen(struct inode *inode)\n{\n\treturn S_ISLNK(inode->i_mode) ? inode->i_sb->s_blocksize :\n\t\tEXT4_NAME_LEN;\n}\n\nstatic struct fscrypt_operations ext4_cryptops = {\n\t.get_context\t\t= ext4_get_context,\n\t.key_prefix\t\t= ext4_key_prefix,\n\t.prepare_context\t= ext4_prepare_context,\n\t.set_context\t\t= ext4_set_context,\n\t.dummy_context\t\t= ext4_dummy_context,\n\t.is_encrypted\t\t= ext4_encrypted_inode,\n\t.empty_dir\t\t= ext4_empty_dir,\n\t.max_namelen\t\t= ext4_max_namelen,\n};\n#else\nstatic struct fscrypt_operations ext4_cryptops = {\n\t.is_encrypted\t\t= ext4_encrypted_inode,\n};\n#endif\n\n#ifdef CONFIG_QUOTA\nstatic char *quotatypes[] = INITQFNAMES;\n#define QTYPE2NAME(t) (quotatypes[t])\n\nstatic int ext4_write_dquot(struct dquot *dquot);\nstatic int ext4_acquire_dquot(struct dquot *dquot);\nstatic int ext4_release_dquot(struct dquot *dquot);\nstatic int ext4_mark_dquot_dirty(struct dquot *dquot);\nstatic int ext4_write_info(struct super_block *sb, int type);\nstatic int ext4_quota_on(struct super_block *sb, int type, int format_id,\n\t\t\t struct path *path);\nstatic int ext4_quota_off(struct super_block *sb, int type);\nstatic int ext4_quota_on_mount(struct super_block *sb, int type);\nstatic ssize_t ext4_quota_read(struct super_block *sb, int type, char *data,\n\t\t\t       size_t len, loff_t off);\nstatic ssize_t ext4_quota_write(struct super_block *sb, int type,\n\t\t\t\tconst char *data, size_t len, loff_t off);\nstatic int ext4_quota_enable(struct super_block *sb, int type, int format_id,\n\t\t\t     unsigned int flags);\nstatic int ext4_enable_quotas(struct super_block *sb);\nstatic int ext4_get_next_id(struct super_block *sb, struct kqid *qid);\n\nstatic struct dquot **ext4_get_dquots(struct inode *inode)\n{\n\treturn EXT4_I(inode)->i_dquot;\n}\n\nstatic const struct dquot_operations ext4_quota_operations = {\n\t.get_reserved_space = ext4_get_reserved_space,\n\t.write_dquot\t= ext4_write_dquot,\n\t.acquire_dquot\t= ext4_acquire_dquot,\n\t.release_dquot\t= ext4_release_dquot,\n\t.mark_dirty\t= ext4_mark_dquot_dirty,\n\t.write_info\t= ext4_write_info,\n\t.alloc_dquot\t= dquot_alloc,\n\t.destroy_dquot\t= dquot_destroy,\n\t.get_projid\t= ext4_get_projid,\n\t.get_next_id\t= ext4_get_next_id,\n};\n\nstatic const struct quotactl_ops ext4_qctl_operations = {\n\t.quota_on\t= ext4_quota_on,\n\t.quota_off\t= ext4_quota_off,\n\t.quota_sync\t= dquot_quota_sync,\n\t.get_state\t= dquot_get_state,\n\t.set_info\t= dquot_set_dqinfo,\n\t.get_dqblk\t= dquot_get_dqblk,\n\t.set_dqblk\t= dquot_set_dqblk,\n\t.get_nextdqblk\t= dquot_get_next_dqblk,\n};\n#endif\n\nstatic const struct super_operations ext4_sops = {\n\t.alloc_inode\t= ext4_alloc_inode,\n\t.destroy_inode\t= ext4_destroy_inode,\n\t.write_inode\t= ext4_write_inode,\n\t.dirty_inode\t= ext4_dirty_inode,\n\t.drop_inode\t= ext4_drop_inode,\n\t.evict_inode\t= ext4_evict_inode,\n\t.put_super\t= ext4_put_super,\n\t.sync_fs\t= ext4_sync_fs,\n\t.freeze_fs\t= ext4_freeze,\n\t.unfreeze_fs\t= ext4_unfreeze,\n\t.statfs\t\t= ext4_statfs,\n\t.remount_fs\t= ext4_remount,\n\t.show_options\t= ext4_show_options,\n#ifdef CONFIG_QUOTA\n\t.quota_read\t= ext4_quota_read,\n\t.quota_write\t= ext4_quota_write,\n\t.get_dquots\t= ext4_get_dquots,\n#endif\n\t.bdev_try_to_free_page = bdev_try_to_free_page,\n};\n\nstatic const struct export_operations ext4_export_ops = {\n\t.fh_to_dentry = ext4_fh_to_dentry,\n\t.fh_to_parent = ext4_fh_to_parent,\n\t.get_parent = ext4_get_parent,\n};\n\nenum {\n\tOpt_bsd_df, Opt_minix_df, Opt_grpid, Opt_nogrpid,\n\tOpt_resgid, Opt_resuid, Opt_sb, Opt_err_cont, Opt_err_panic, Opt_err_ro,\n\tOpt_nouid32, Opt_debug, Opt_removed,\n\tOpt_user_xattr, Opt_nouser_xattr, Opt_acl, Opt_noacl,\n\tOpt_auto_da_alloc, Opt_noauto_da_alloc, Opt_noload,\n\tOpt_commit, Opt_min_batch_time, Opt_max_batch_time, Opt_journal_dev,\n\tOpt_journal_path, Opt_journal_checksum, Opt_journal_async_commit,\n\tOpt_abort, Opt_data_journal, Opt_data_ordered, Opt_data_writeback,\n\tOpt_data_err_abort, Opt_data_err_ignore, Opt_test_dummy_encryption,\n\tOpt_usrjquota, Opt_grpjquota, Opt_offusrjquota, Opt_offgrpjquota,\n\tOpt_jqfmt_vfsold, Opt_jqfmt_vfsv0, Opt_jqfmt_vfsv1, Opt_quota,\n\tOpt_noquota, Opt_barrier, Opt_nobarrier, Opt_err,\n\tOpt_usrquota, Opt_grpquota, Opt_prjquota, Opt_i_version, Opt_dax,\n\tOpt_stripe, Opt_delalloc, Opt_nodelalloc, Opt_mblk_io_submit,\n\tOpt_lazytime, Opt_nolazytime,\n\tOpt_nomblk_io_submit, Opt_block_validity, Opt_noblock_validity,\n\tOpt_inode_readahead_blks, Opt_journal_ioprio,\n\tOpt_dioread_nolock, Opt_dioread_lock,\n\tOpt_discard, Opt_nodiscard, Opt_init_itable, Opt_noinit_itable,\n\tOpt_max_dir_size_kb, Opt_nojournal_checksum,\n};\n\nstatic const match_table_t tokens = {\n\t{Opt_bsd_df, \"bsddf\"},\n\t{Opt_minix_df, \"minixdf\"},\n\t{Opt_grpid, \"grpid\"},\n\t{Opt_grpid, \"bsdgroups\"},\n\t{Opt_nogrpid, \"nogrpid\"},\n\t{Opt_nogrpid, \"sysvgroups\"},\n\t{Opt_resgid, \"resgid=%u\"},\n\t{Opt_resuid, \"resuid=%u\"},\n\t{Opt_sb, \"sb=%u\"},\n\t{Opt_err_cont, \"errors=continue\"},\n\t{Opt_err_panic, \"errors=panic\"},\n\t{Opt_err_ro, \"errors=remount-ro\"},\n\t{Opt_nouid32, \"nouid32\"},\n\t{Opt_debug, \"debug\"},\n\t{Opt_removed, \"oldalloc\"},\n\t{Opt_removed, \"orlov\"},\n\t{Opt_user_xattr, \"user_xattr\"},\n\t{Opt_nouser_xattr, \"nouser_xattr\"},\n\t{Opt_acl, \"acl\"},\n\t{Opt_noacl, \"noacl\"},\n\t{Opt_noload, \"norecovery\"},\n\t{Opt_noload, \"noload\"},\n\t{Opt_removed, \"nobh\"},\n\t{Opt_removed, \"bh\"},\n\t{Opt_commit, \"commit=%u\"},\n\t{Opt_min_batch_time, \"min_batch_time=%u\"},\n\t{Opt_max_batch_time, \"max_batch_time=%u\"},\n\t{Opt_journal_dev, \"journal_dev=%u\"},\n\t{Opt_journal_path, \"journal_path=%s\"},\n\t{Opt_journal_checksum, \"journal_checksum\"},\n\t{Opt_nojournal_checksum, \"nojournal_checksum\"},\n\t{Opt_journal_async_commit, \"journal_async_commit\"},\n\t{Opt_abort, \"abort\"},\n\t{Opt_data_journal, \"data=journal\"},\n\t{Opt_data_ordered, \"data=ordered\"},\n\t{Opt_data_writeback, \"data=writeback\"},\n\t{Opt_data_err_abort, \"data_err=abort\"},\n\t{Opt_data_err_ignore, \"data_err=ignore\"},\n\t{Opt_offusrjquota, \"usrjquota=\"},\n\t{Opt_usrjquota, \"usrjquota=%s\"},\n\t{Opt_offgrpjquota, \"grpjquota=\"},\n\t{Opt_grpjquota, \"grpjquota=%s\"},\n\t{Opt_jqfmt_vfsold, \"jqfmt=vfsold\"},\n\t{Opt_jqfmt_vfsv0, \"jqfmt=vfsv0\"},\n\t{Opt_jqfmt_vfsv1, \"jqfmt=vfsv1\"},\n\t{Opt_grpquota, \"grpquota\"},\n\t{Opt_noquota, \"noquota\"},\n\t{Opt_quota, \"quota\"},\n\t{Opt_usrquota, \"usrquota\"},\n\t{Opt_prjquota, \"prjquota\"},\n\t{Opt_barrier, \"barrier=%u\"},\n\t{Opt_barrier, \"barrier\"},\n\t{Opt_nobarrier, \"nobarrier\"},\n\t{Opt_i_version, \"i_version\"},\n\t{Opt_dax, \"dax\"},\n\t{Opt_stripe, \"stripe=%u\"},\n\t{Opt_delalloc, \"delalloc\"},\n\t{Opt_lazytime, \"lazytime\"},\n\t{Opt_nolazytime, \"nolazytime\"},\n\t{Opt_nodelalloc, \"nodelalloc\"},\n\t{Opt_removed, \"mblk_io_submit\"},\n\t{Opt_removed, \"nomblk_io_submit\"},\n\t{Opt_block_validity, \"block_validity\"},\n\t{Opt_noblock_validity, \"noblock_validity\"},\n\t{Opt_inode_readahead_blks, \"inode_readahead_blks=%u\"},\n\t{Opt_journal_ioprio, \"journal_ioprio=%u\"},\n\t{Opt_auto_da_alloc, \"auto_da_alloc=%u\"},\n\t{Opt_auto_da_alloc, \"auto_da_alloc\"},\n\t{Opt_noauto_da_alloc, \"noauto_da_alloc\"},\n\t{Opt_dioread_nolock, \"dioread_nolock\"},\n\t{Opt_dioread_lock, \"dioread_lock\"},\n\t{Opt_discard, \"discard\"},\n\t{Opt_nodiscard, \"nodiscard\"},\n\t{Opt_init_itable, \"init_itable=%u\"},\n\t{Opt_init_itable, \"init_itable\"},\n\t{Opt_noinit_itable, \"noinit_itable\"},\n\t{Opt_max_dir_size_kb, \"max_dir_size_kb=%u\"},\n\t{Opt_test_dummy_encryption, \"test_dummy_encryption\"},\n\t{Opt_removed, \"check=none\"},\t/* mount option from ext2/3 */\n\t{Opt_removed, \"nocheck\"},\t/* mount option from ext2/3 */\n\t{Opt_removed, \"reservation\"},\t/* mount option from ext2/3 */\n\t{Opt_removed, \"noreservation\"}, /* mount option from ext2/3 */\n\t{Opt_removed, \"journal=%u\"},\t/* mount option from ext2/3 */\n\t{Opt_err, NULL},\n};\n\nstatic ext4_fsblk_t get_sb_block(void **data)\n{\n\text4_fsblk_t\tsb_block;\n\tchar\t\t*options = (char *) *data;\n\n\tif (!options || strncmp(options, \"sb=\", 3) != 0)\n\t\treturn 1;\t/* Default location */\n\n\toptions += 3;\n\t/* TODO: use simple_strtoll with >32bit ext4 */\n\tsb_block = simple_strtoul(options, &options, 0);\n\tif (*options && *options != ',') {\n\t\tprintk(KERN_ERR \"EXT4-fs: Invalid sb specification: %s\\n\",\n\t\t       (char *) *data);\n\t\treturn 1;\n\t}\n\tif (*options == ',')\n\t\toptions++;\n\t*data = (void *) options;\n\n\treturn sb_block;\n}\n\n#define DEFAULT_JOURNAL_IOPRIO (IOPRIO_PRIO_VALUE(IOPRIO_CLASS_BE, 3))\nstatic char deprecated_msg[] = \"Mount option \\\"%s\\\" will be removed by %s\\n\"\n\t\"Contact linux-ext4@vger.kernel.org if you think we should keep it.\\n\";\n\n#ifdef CONFIG_QUOTA\nstatic int set_qf_name(struct super_block *sb, int qtype, substring_t *args)\n{\n\tstruct ext4_sb_info *sbi = EXT4_SB(sb);\n\tchar *qname;\n\tint ret = -1;\n\n\tif (sb_any_quota_loaded(sb) &&\n\t\t!sbi->s_qf_names[qtype]) {\n\t\text4_msg(sb, KERN_ERR,\n\t\t\t\"Cannot change journaled \"\n\t\t\t\"quota options when quota turned on\");\n\t\treturn -1;\n\t}\n\tif (ext4_has_feature_quota(sb)) {\n\t\text4_msg(sb, KERN_INFO, \"Journaled quota options \"\n\t\t\t \"ignored when QUOTA feature is enabled\");\n\t\treturn 1;\n\t}\n\tqname = match_strdup(args);\n\tif (!qname) {\n\t\text4_msg(sb, KERN_ERR,\n\t\t\t\"Not enough memory for storing quotafile name\");\n\t\treturn -1;\n\t}\n\tif (sbi->s_qf_names[qtype]) {\n\t\tif (strcmp(sbi->s_qf_names[qtype], qname) == 0)\n\t\t\tret = 1;\n\t\telse\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t\t \"%s quota file already specified\",\n\t\t\t\t QTYPE2NAME(qtype));\n\t\tgoto errout;\n\t}\n\tif (strchr(qname, '/')) {\n\t\text4_msg(sb, KERN_ERR,\n\t\t\t\"quotafile must be on filesystem root\");\n\t\tgoto errout;\n\t}\n\tsbi->s_qf_names[qtype] = qname;\n\tset_opt(sb, QUOTA);\n\treturn 1;\nerrout:\n\tkfree(qname);\n\treturn ret;\n}\n\nstatic int clear_qf_name(struct super_block *sb, int qtype)\n{\n\n\tstruct ext4_sb_info *sbi = EXT4_SB(sb);\n\n\tif (sb_any_quota_loaded(sb) &&\n\t\tsbi->s_qf_names[qtype]) {\n\t\text4_msg(sb, KERN_ERR, \"Cannot change journaled quota options\"\n\t\t\t\" when quota turned on\");\n\t\treturn -1;\n\t}\n\tkfree(sbi->s_qf_names[qtype]);\n\tsbi->s_qf_names[qtype] = NULL;\n\treturn 1;\n}\n#endif\n\n#define MOPT_SET\t0x0001\n#define MOPT_CLEAR\t0x0002\n#define MOPT_NOSUPPORT\t0x0004\n#define MOPT_EXPLICIT\t0x0008\n#define MOPT_CLEAR_ERR\t0x0010\n#define MOPT_GTE0\t0x0020\n#ifdef CONFIG_QUOTA\n#define MOPT_Q\t\t0\n#define MOPT_QFMT\t0x0040\n#else\n#define MOPT_Q\t\tMOPT_NOSUPPORT\n#define MOPT_QFMT\tMOPT_NOSUPPORT\n#endif\n#define MOPT_DATAJ\t0x0080\n#define MOPT_NO_EXT2\t0x0100\n#define MOPT_NO_EXT3\t0x0200\n#define MOPT_EXT4_ONLY\t(MOPT_NO_EXT2 | MOPT_NO_EXT3)\n#define MOPT_STRING\t0x0400\n\nstatic const struct mount_opts {\n\tint\ttoken;\n\tint\tmount_opt;\n\tint\tflags;\n} ext4_mount_opts[] = {\n\t{Opt_minix_df, EXT4_MOUNT_MINIX_DF, MOPT_SET},\n\t{Opt_bsd_df, EXT4_MOUNT_MINIX_DF, MOPT_CLEAR},\n\t{Opt_grpid, EXT4_MOUNT_GRPID, MOPT_SET},\n\t{Opt_nogrpid, EXT4_MOUNT_GRPID, MOPT_CLEAR},\n\t{Opt_block_validity, EXT4_MOUNT_BLOCK_VALIDITY, MOPT_SET},\n\t{Opt_noblock_validity, EXT4_MOUNT_BLOCK_VALIDITY, MOPT_CLEAR},\n\t{Opt_dioread_nolock, EXT4_MOUNT_DIOREAD_NOLOCK,\n\t MOPT_EXT4_ONLY | MOPT_SET},\n\t{Opt_dioread_lock, EXT4_MOUNT_DIOREAD_NOLOCK,\n\t MOPT_EXT4_ONLY | MOPT_CLEAR},\n\t{Opt_discard, EXT4_MOUNT_DISCARD, MOPT_SET},\n\t{Opt_nodiscard, EXT4_MOUNT_DISCARD, MOPT_CLEAR},\n\t{Opt_delalloc, EXT4_MOUNT_DELALLOC,\n\t MOPT_EXT4_ONLY | MOPT_SET | MOPT_EXPLICIT},\n\t{Opt_nodelalloc, EXT4_MOUNT_DELALLOC,\n\t MOPT_EXT4_ONLY | MOPT_CLEAR},\n\t{Opt_nojournal_checksum, EXT4_MOUNT_JOURNAL_CHECKSUM,\n\t MOPT_EXT4_ONLY | MOPT_CLEAR},\n\t{Opt_journal_checksum, EXT4_MOUNT_JOURNAL_CHECKSUM,\n\t MOPT_EXT4_ONLY | MOPT_SET | MOPT_EXPLICIT},\n\t{Opt_journal_async_commit, (EXT4_MOUNT_JOURNAL_ASYNC_COMMIT |\n\t\t\t\t    EXT4_MOUNT_JOURNAL_CHECKSUM),\n\t MOPT_EXT4_ONLY | MOPT_SET | MOPT_EXPLICIT},\n\t{Opt_noload, EXT4_MOUNT_NOLOAD, MOPT_NO_EXT2 | MOPT_SET},\n\t{Opt_err_panic, EXT4_MOUNT_ERRORS_PANIC, MOPT_SET | MOPT_CLEAR_ERR},\n\t{Opt_err_ro, EXT4_MOUNT_ERRORS_RO, MOPT_SET | MOPT_CLEAR_ERR},\n\t{Opt_err_cont, EXT4_MOUNT_ERRORS_CONT, MOPT_SET | MOPT_CLEAR_ERR},\n\t{Opt_data_err_abort, EXT4_MOUNT_DATA_ERR_ABORT,\n\t MOPT_NO_EXT2},\n\t{Opt_data_err_ignore, EXT4_MOUNT_DATA_ERR_ABORT,\n\t MOPT_NO_EXT2},\n\t{Opt_barrier, EXT4_MOUNT_BARRIER, MOPT_SET},\n\t{Opt_nobarrier, EXT4_MOUNT_BARRIER, MOPT_CLEAR},\n\t{Opt_noauto_da_alloc, EXT4_MOUNT_NO_AUTO_DA_ALLOC, MOPT_SET},\n\t{Opt_auto_da_alloc, EXT4_MOUNT_NO_AUTO_DA_ALLOC, MOPT_CLEAR},\n\t{Opt_noinit_itable, EXT4_MOUNT_INIT_INODE_TABLE, MOPT_CLEAR},\n\t{Opt_commit, 0, MOPT_GTE0},\n\t{Opt_max_batch_time, 0, MOPT_GTE0},\n\t{Opt_min_batch_time, 0, MOPT_GTE0},\n\t{Opt_inode_readahead_blks, 0, MOPT_GTE0},\n\t{Opt_init_itable, 0, MOPT_GTE0},\n\t{Opt_dax, EXT4_MOUNT_DAX, MOPT_SET},\n\t{Opt_stripe, 0, MOPT_GTE0},\n\t{Opt_resuid, 0, MOPT_GTE0},\n\t{Opt_resgid, 0, MOPT_GTE0},\n\t{Opt_journal_dev, 0, MOPT_NO_EXT2 | MOPT_GTE0},\n\t{Opt_journal_path, 0, MOPT_NO_EXT2 | MOPT_STRING},\n\t{Opt_journal_ioprio, 0, MOPT_NO_EXT2 | MOPT_GTE0},\n\t{Opt_data_journal, EXT4_MOUNT_JOURNAL_DATA, MOPT_NO_EXT2 | MOPT_DATAJ},\n\t{Opt_data_ordered, EXT4_MOUNT_ORDERED_DATA, MOPT_NO_EXT2 | MOPT_DATAJ},\n\t{Opt_data_writeback, EXT4_MOUNT_WRITEBACK_DATA,\n\t MOPT_NO_EXT2 | MOPT_DATAJ},\n\t{Opt_user_xattr, EXT4_MOUNT_XATTR_USER, MOPT_SET},\n\t{Opt_nouser_xattr, EXT4_MOUNT_XATTR_USER, MOPT_CLEAR},\n#ifdef CONFIG_EXT4_FS_POSIX_ACL\n\t{Opt_acl, EXT4_MOUNT_POSIX_ACL, MOPT_SET},\n\t{Opt_noacl, EXT4_MOUNT_POSIX_ACL, MOPT_CLEAR},\n#else\n\t{Opt_acl, 0, MOPT_NOSUPPORT},\n\t{Opt_noacl, 0, MOPT_NOSUPPORT},\n#endif\n\t{Opt_nouid32, EXT4_MOUNT_NO_UID32, MOPT_SET},\n\t{Opt_debug, EXT4_MOUNT_DEBUG, MOPT_SET},\n\t{Opt_quota, EXT4_MOUNT_QUOTA | EXT4_MOUNT_USRQUOTA, MOPT_SET | MOPT_Q},\n\t{Opt_usrquota, EXT4_MOUNT_QUOTA | EXT4_MOUNT_USRQUOTA,\n\t\t\t\t\t\t\tMOPT_SET | MOPT_Q},\n\t{Opt_grpquota, EXT4_MOUNT_QUOTA | EXT4_MOUNT_GRPQUOTA,\n\t\t\t\t\t\t\tMOPT_SET | MOPT_Q},\n\t{Opt_prjquota, EXT4_MOUNT_QUOTA | EXT4_MOUNT_PRJQUOTA,\n\t\t\t\t\t\t\tMOPT_SET | MOPT_Q},\n\t{Opt_noquota, (EXT4_MOUNT_QUOTA | EXT4_MOUNT_USRQUOTA |\n\t\t       EXT4_MOUNT_GRPQUOTA | EXT4_MOUNT_PRJQUOTA),\n\t\t\t\t\t\t\tMOPT_CLEAR | MOPT_Q},\n\t{Opt_usrjquota, 0, MOPT_Q},\n\t{Opt_grpjquota, 0, MOPT_Q},\n\t{Opt_offusrjquota, 0, MOPT_Q},\n\t{Opt_offgrpjquota, 0, MOPT_Q},\n\t{Opt_jqfmt_vfsold, QFMT_VFS_OLD, MOPT_QFMT},\n\t{Opt_jqfmt_vfsv0, QFMT_VFS_V0, MOPT_QFMT},\n\t{Opt_jqfmt_vfsv1, QFMT_VFS_V1, MOPT_QFMT},\n\t{Opt_max_dir_size_kb, 0, MOPT_GTE0},\n\t{Opt_test_dummy_encryption, 0, MOPT_GTE0},\n\t{Opt_err, 0, 0}\n};\n\nstatic int handle_mount_opt(struct super_block *sb, char *opt, int token,\n\t\t\t    substring_t *args, unsigned long *journal_devnum,\n\t\t\t    unsigned int *journal_ioprio, int is_remount)\n{\n\tstruct ext4_sb_info *sbi = EXT4_SB(sb);\n\tconst struct mount_opts *m;\n\tkuid_t uid;\n\tkgid_t gid;\n\tint arg = 0;\n\n#ifdef CONFIG_QUOTA\n\tif (token == Opt_usrjquota)\n\t\treturn set_qf_name(sb, USRQUOTA, &args[0]);\n\telse if (token == Opt_grpjquota)\n\t\treturn set_qf_name(sb, GRPQUOTA, &args[0]);\n\telse if (token == Opt_offusrjquota)\n\t\treturn clear_qf_name(sb, USRQUOTA);\n\telse if (token == Opt_offgrpjquota)\n\t\treturn clear_qf_name(sb, GRPQUOTA);\n#endif\n\tswitch (token) {\n\tcase Opt_noacl:\n\tcase Opt_nouser_xattr:\n\t\text4_msg(sb, KERN_WARNING, deprecated_msg, opt, \"3.5\");\n\t\tbreak;\n\tcase Opt_sb:\n\t\treturn 1;\t/* handled by get_sb_block() */\n\tcase Opt_removed:\n\t\text4_msg(sb, KERN_WARNING, \"Ignoring removed %s option\", opt);\n\t\treturn 1;\n\tcase Opt_abort:\n\t\tsbi->s_mount_flags |= EXT4_MF_FS_ABORTED;\n\t\treturn 1;\n\tcase Opt_i_version:\n\t\tsb->s_flags |= MS_I_VERSION;\n\t\treturn 1;\n\tcase Opt_lazytime:\n\t\tsb->s_flags |= MS_LAZYTIME;\n\t\treturn 1;\n\tcase Opt_nolazytime:\n\t\tsb->s_flags &= ~MS_LAZYTIME;\n\t\treturn 1;\n\t}\n\n\tfor (m = ext4_mount_opts; m->token != Opt_err; m++)\n\t\tif (token == m->token)\n\t\t\tbreak;\n\n\tif (m->token == Opt_err) {\n\t\text4_msg(sb, KERN_ERR, \"Unrecognized mount option \\\"%s\\\" \"\n\t\t\t \"or missing value\", opt);\n\t\treturn -1;\n\t}\n\n\tif ((m->flags & MOPT_NO_EXT2) && IS_EXT2_SB(sb)) {\n\t\text4_msg(sb, KERN_ERR,\n\t\t\t \"Mount option \\\"%s\\\" incompatible with ext2\", opt);\n\t\treturn -1;\n\t}\n\tif ((m->flags & MOPT_NO_EXT3) && IS_EXT3_SB(sb)) {\n\t\text4_msg(sb, KERN_ERR,\n\t\t\t \"Mount option \\\"%s\\\" incompatible with ext3\", opt);\n\t\treturn -1;\n\t}\n\n\tif (args->from && !(m->flags & MOPT_STRING) && match_int(args, &arg))\n\t\treturn -1;\n\tif (args->from && (m->flags & MOPT_GTE0) && (arg < 0))\n\t\treturn -1;\n\tif (m->flags & MOPT_EXPLICIT) {\n\t\tif (m->mount_opt & EXT4_MOUNT_DELALLOC) {\n\t\t\tset_opt2(sb, EXPLICIT_DELALLOC);\n\t\t} else if (m->mount_opt & EXT4_MOUNT_JOURNAL_CHECKSUM) {\n\t\t\tset_opt2(sb, EXPLICIT_JOURNAL_CHECKSUM);\n\t\t} else\n\t\t\treturn -1;\n\t}\n\tif (m->flags & MOPT_CLEAR_ERR)\n\t\tclear_opt(sb, ERRORS_MASK);\n\tif (token == Opt_noquota && sb_any_quota_loaded(sb)) {\n\t\text4_msg(sb, KERN_ERR, \"Cannot change quota \"\n\t\t\t \"options when quota turned on\");\n\t\treturn -1;\n\t}\n\n\tif (m->flags & MOPT_NOSUPPORT) {\n\t\text4_msg(sb, KERN_ERR, \"%s option not supported\", opt);\n\t} else if (token == Opt_commit) {\n\t\tif (arg == 0)\n\t\t\targ = JBD2_DEFAULT_MAX_COMMIT_AGE;\n\t\tsbi->s_commit_interval = HZ * arg;\n\t} else if (token == Opt_max_batch_time) {\n\t\tsbi->s_max_batch_time = arg;\n\t} else if (token == Opt_min_batch_time) {\n\t\tsbi->s_min_batch_time = arg;\n\t} else if (token == Opt_inode_readahead_blks) {\n\t\tif (arg && (arg > (1 << 30) || !is_power_of_2(arg))) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t\t \"EXT4-fs: inode_readahead_blks must be \"\n\t\t\t\t \"0 or a power of 2 smaller than 2^31\");\n\t\t\treturn -1;\n\t\t}\n\t\tsbi->s_inode_readahead_blks = arg;\n\t} else if (token == Opt_init_itable) {\n\t\tset_opt(sb, INIT_INODE_TABLE);\n\t\tif (!args->from)\n\t\t\targ = EXT4_DEF_LI_WAIT_MULT;\n\t\tsbi->s_li_wait_mult = arg;\n\t} else if (token == Opt_max_dir_size_kb) {\n\t\tsbi->s_max_dir_size_kb = arg;\n\t} else if (token == Opt_stripe) {\n\t\tsbi->s_stripe = arg;\n\t} else if (token == Opt_resuid) {\n\t\tuid = make_kuid(current_user_ns(), arg);\n\t\tif (!uid_valid(uid)) {\n\t\t\text4_msg(sb, KERN_ERR, \"Invalid uid value %d\", arg);\n\t\t\treturn -1;\n\t\t}\n\t\tsbi->s_resuid = uid;\n\t} else if (token == Opt_resgid) {\n\t\tgid = make_kgid(current_user_ns(), arg);\n\t\tif (!gid_valid(gid)) {\n\t\t\text4_msg(sb, KERN_ERR, \"Invalid gid value %d\", arg);\n\t\t\treturn -1;\n\t\t}\n\t\tsbi->s_resgid = gid;\n\t} else if (token == Opt_journal_dev) {\n\t\tif (is_remount) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t\t \"Cannot specify journal on remount\");\n\t\t\treturn -1;\n\t\t}\n\t\t*journal_devnum = arg;\n\t} else if (token == Opt_journal_path) {\n\t\tchar *journal_path;\n\t\tstruct inode *journal_inode;\n\t\tstruct path path;\n\t\tint error;\n\n\t\tif (is_remount) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t\t \"Cannot specify journal on remount\");\n\t\t\treturn -1;\n\t\t}\n\t\tjournal_path = match_strdup(&args[0]);\n\t\tif (!journal_path) {\n\t\t\text4_msg(sb, KERN_ERR, \"error: could not dup \"\n\t\t\t\t\"journal device string\");\n\t\t\treturn -1;\n\t\t}\n\n\t\terror = kern_path(journal_path, LOOKUP_FOLLOW, &path);\n\t\tif (error) {\n\t\t\text4_msg(sb, KERN_ERR, \"error: could not find \"\n\t\t\t\t\"journal device path: error %d\", error);\n\t\t\tkfree(journal_path);\n\t\t\treturn -1;\n\t\t}\n\n\t\tjournal_inode = d_inode(path.dentry);\n\t\tif (!S_ISBLK(journal_inode->i_mode)) {\n\t\t\text4_msg(sb, KERN_ERR, \"error: journal path %s \"\n\t\t\t\t\"is not a block device\", journal_path);\n\t\t\tpath_put(&path);\n\t\t\tkfree(journal_path);\n\t\t\treturn -1;\n\t\t}\n\n\t\t*journal_devnum = new_encode_dev(journal_inode->i_rdev);\n\t\tpath_put(&path);\n\t\tkfree(journal_path);\n\t} else if (token == Opt_journal_ioprio) {\n\t\tif (arg > 7) {\n\t\t\text4_msg(sb, KERN_ERR, \"Invalid journal IO priority\"\n\t\t\t\t \" (must be 0-7)\");\n\t\t\treturn -1;\n\t\t}\n\t\t*journal_ioprio =\n\t\t\tIOPRIO_PRIO_VALUE(IOPRIO_CLASS_BE, arg);\n\t} else if (token == Opt_test_dummy_encryption) {\n#ifdef CONFIG_EXT4_FS_ENCRYPTION\n\t\tsbi->s_mount_flags |= EXT4_MF_TEST_DUMMY_ENCRYPTION;\n\t\text4_msg(sb, KERN_WARNING,\n\t\t\t \"Test dummy encryption mode enabled\");\n#else\n\t\text4_msg(sb, KERN_WARNING,\n\t\t\t \"Test dummy encryption mount option ignored\");\n#endif\n\t} else if (m->flags & MOPT_DATAJ) {\n\t\tif (is_remount) {\n\t\t\tif (!sbi->s_journal)\n\t\t\t\text4_msg(sb, KERN_WARNING, \"Remounting file system with no journal so ignoring journalled data option\");\n\t\t\telse if (test_opt(sb, DATA_FLAGS) != m->mount_opt) {\n\t\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t\t\t \"Cannot change data mode on remount\");\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t} else {\n\t\t\tclear_opt(sb, DATA_FLAGS);\n\t\t\tsbi->s_mount_opt |= m->mount_opt;\n\t\t}\n#ifdef CONFIG_QUOTA\n\t} else if (m->flags & MOPT_QFMT) {\n\t\tif (sb_any_quota_loaded(sb) &&\n\t\t    sbi->s_jquota_fmt != m->mount_opt) {\n\t\t\text4_msg(sb, KERN_ERR, \"Cannot change journaled \"\n\t\t\t\t \"quota options when quota turned on\");\n\t\t\treturn -1;\n\t\t}\n\t\tif (ext4_has_feature_quota(sb)) {\n\t\t\text4_msg(sb, KERN_INFO,\n\t\t\t\t \"Quota format mount options ignored \"\n\t\t\t\t \"when QUOTA feature is enabled\");\n\t\t\treturn 1;\n\t\t}\n\t\tsbi->s_jquota_fmt = m->mount_opt;\n#endif\n\t} else if (token == Opt_dax) {\n#ifdef CONFIG_FS_DAX\n\t\text4_msg(sb, KERN_WARNING,\n\t\t\"DAX enabled. Warning: EXPERIMENTAL, use at your own risk\");\n\t\t\tsbi->s_mount_opt |= m->mount_opt;\n#else\n\t\text4_msg(sb, KERN_INFO, \"dax option not supported\");\n\t\treturn -1;\n#endif\n\t} else if (token == Opt_data_err_abort) {\n\t\tsbi->s_mount_opt |= m->mount_opt;\n\t} else if (token == Opt_data_err_ignore) {\n\t\tsbi->s_mount_opt &= ~m->mount_opt;\n\t} else {\n\t\tif (!args->from)\n\t\t\targ = 1;\n\t\tif (m->flags & MOPT_CLEAR)\n\t\t\targ = !arg;\n\t\telse if (unlikely(!(m->flags & MOPT_SET))) {\n\t\t\text4_msg(sb, KERN_WARNING,\n\t\t\t\t \"buggy handling of option %s\", opt);\n\t\t\tWARN_ON(1);\n\t\t\treturn -1;\n\t\t}\n\t\tif (arg != 0)\n\t\t\tsbi->s_mount_opt |= m->mount_opt;\n\t\telse\n\t\t\tsbi->s_mount_opt &= ~m->mount_opt;\n\t}\n\treturn 1;\n}\n\nstatic int parse_options(char *options, struct super_block *sb,\n\t\t\t unsigned long *journal_devnum,\n\t\t\t unsigned int *journal_ioprio,\n\t\t\t int is_remount)\n{\n\tstruct ext4_sb_info *sbi = EXT4_SB(sb);\n\tchar *p;\n\tsubstring_t args[MAX_OPT_ARGS];\n\tint token;\n\n\tif (!options)\n\t\treturn 1;\n\n\twhile ((p = strsep(&options, \",\")) != NULL) {\n\t\tif (!*p)\n\t\t\tcontinue;\n\t\t/*\n\t\t * Initialize args struct so we know whether arg was\n\t\t * found; some options take optional arguments.\n\t\t */\n\t\targs[0].to = args[0].from = NULL;\n\t\ttoken = match_token(p, tokens, args);\n\t\tif (handle_mount_opt(sb, p, token, args, journal_devnum,\n\t\t\t\t     journal_ioprio, is_remount) < 0)\n\t\t\treturn 0;\n\t}\n#ifdef CONFIG_QUOTA\n\t/*\n\t * We do the test below only for project quotas. 'usrquota' and\n\t * 'grpquota' mount options are allowed even without quota feature\n\t * to support legacy quotas in quota files.\n\t */\n\tif (test_opt(sb, PRJQUOTA) && !ext4_has_feature_project(sb)) {\n\t\text4_msg(sb, KERN_ERR, \"Project quota feature not enabled. \"\n\t\t\t \"Cannot enable project quota enforcement.\");\n\t\treturn 0;\n\t}\n\tif (sbi->s_qf_names[USRQUOTA] || sbi->s_qf_names[GRPQUOTA]) {\n\t\tif (test_opt(sb, USRQUOTA) && sbi->s_qf_names[USRQUOTA])\n\t\t\tclear_opt(sb, USRQUOTA);\n\n\t\tif (test_opt(sb, GRPQUOTA) && sbi->s_qf_names[GRPQUOTA])\n\t\t\tclear_opt(sb, GRPQUOTA);\n\n\t\tif (test_opt(sb, GRPQUOTA) || test_opt(sb, USRQUOTA)) {\n\t\t\text4_msg(sb, KERN_ERR, \"old and new quota \"\n\t\t\t\t\t\"format mixing\");\n\t\t\treturn 0;\n\t\t}\n\n\t\tif (!sbi->s_jquota_fmt) {\n\t\t\text4_msg(sb, KERN_ERR, \"journaled quota format \"\n\t\t\t\t\t\"not specified\");\n\t\t\treturn 0;\n\t\t}\n\t}\n#endif\n\tif (test_opt(sb, DIOREAD_NOLOCK)) {\n\t\tint blocksize =\n\t\t\tBLOCK_SIZE << le32_to_cpu(sbi->s_es->s_log_block_size);\n\n\t\tif (blocksize < PAGE_SIZE) {\n\t\t\text4_msg(sb, KERN_ERR, \"can't mount with \"\n\t\t\t\t \"dioread_nolock if block size != PAGE_SIZE\");\n\t\t\treturn 0;\n\t\t}\n\t}\n\tif (test_opt(sb, DATA_FLAGS) == EXT4_MOUNT_ORDERED_DATA &&\n\t    test_opt(sb, JOURNAL_ASYNC_COMMIT)) {\n\t\text4_msg(sb, KERN_ERR, \"can't mount with journal_async_commit \"\n\t\t\t \"in data=ordered mode\");\n\t\treturn 0;\n\t}\n\treturn 1;\n}\n\nstatic inline void ext4_show_quota_options(struct seq_file *seq,\n\t\t\t\t\t   struct super_block *sb)\n{\n#if defined(CONFIG_QUOTA)\n\tstruct ext4_sb_info *sbi = EXT4_SB(sb);\n\n\tif (sbi->s_jquota_fmt) {\n\t\tchar *fmtname = \"\";\n\n\t\tswitch (sbi->s_jquota_fmt) {\n\t\tcase QFMT_VFS_OLD:\n\t\t\tfmtname = \"vfsold\";\n\t\t\tbreak;\n\t\tcase QFMT_VFS_V0:\n\t\t\tfmtname = \"vfsv0\";\n\t\t\tbreak;\n\t\tcase QFMT_VFS_V1:\n\t\t\tfmtname = \"vfsv1\";\n\t\t\tbreak;\n\t\t}\n\t\tseq_printf(seq, \",jqfmt=%s\", fmtname);\n\t}\n\n\tif (sbi->s_qf_names[USRQUOTA])\n\t\tseq_show_option(seq, \"usrjquota\", sbi->s_qf_names[USRQUOTA]);\n\n\tif (sbi->s_qf_names[GRPQUOTA])\n\t\tseq_show_option(seq, \"grpjquota\", sbi->s_qf_names[GRPQUOTA]);\n#endif\n}\n\nstatic const char *token2str(int token)\n{\n\tconst struct match_token *t;\n\n\tfor (t = tokens; t->token != Opt_err; t++)\n\t\tif (t->token == token && !strchr(t->pattern, '='))\n\t\t\tbreak;\n\treturn t->pattern;\n}\n\n/*\n * Show an option if\n *  - it's set to a non-default value OR\n *  - if the per-sb default is different from the global default\n */\nstatic int _ext4_show_options(struct seq_file *seq, struct super_block *sb,\n\t\t\t      int nodefs)\n{\n\tstruct ext4_sb_info *sbi = EXT4_SB(sb);\n\tstruct ext4_super_block *es = sbi->s_es;\n\tint def_errors, def_mount_opt = nodefs ? 0 : sbi->s_def_mount_opt;\n\tconst struct mount_opts *m;\n\tchar sep = nodefs ? '\\n' : ',';\n\n#define SEQ_OPTS_PUTS(str) seq_printf(seq, \"%c\" str, sep)\n#define SEQ_OPTS_PRINT(str, arg) seq_printf(seq, \"%c\" str, sep, arg)\n\n\tif (sbi->s_sb_block != 1)\n\t\tSEQ_OPTS_PRINT(\"sb=%llu\", sbi->s_sb_block);\n\n\tfor (m = ext4_mount_opts; m->token != Opt_err; m++) {\n\t\tint want_set = m->flags & MOPT_SET;\n\t\tif (((m->flags & (MOPT_SET|MOPT_CLEAR)) == 0) ||\n\t\t    (m->flags & MOPT_CLEAR_ERR))\n\t\t\tcontinue;\n\t\tif (!(m->mount_opt & (sbi->s_mount_opt ^ def_mount_opt)))\n\t\t\tcontinue; /* skip if same as the default */\n\t\tif ((want_set &&\n\t\t     (sbi->s_mount_opt & m->mount_opt) != m->mount_opt) ||\n\t\t    (!want_set && (sbi->s_mount_opt & m->mount_opt)))\n\t\t\tcontinue; /* select Opt_noFoo vs Opt_Foo */\n\t\tSEQ_OPTS_PRINT(\"%s\", token2str(m->token));\n\t}\n\n\tif (nodefs || !uid_eq(sbi->s_resuid, make_kuid(&init_user_ns, EXT4_DEF_RESUID)) ||\n\t    le16_to_cpu(es->s_def_resuid) != EXT4_DEF_RESUID)\n\t\tSEQ_OPTS_PRINT(\"resuid=%u\",\n\t\t\t\tfrom_kuid_munged(&init_user_ns, sbi->s_resuid));\n\tif (nodefs || !gid_eq(sbi->s_resgid, make_kgid(&init_user_ns, EXT4_DEF_RESGID)) ||\n\t    le16_to_cpu(es->s_def_resgid) != EXT4_DEF_RESGID)\n\t\tSEQ_OPTS_PRINT(\"resgid=%u\",\n\t\t\t\tfrom_kgid_munged(&init_user_ns, sbi->s_resgid));\n\tdef_errors = nodefs ? -1 : le16_to_cpu(es->s_errors);\n\tif (test_opt(sb, ERRORS_RO) && def_errors != EXT4_ERRORS_RO)\n\t\tSEQ_OPTS_PUTS(\"errors=remount-ro\");\n\tif (test_opt(sb, ERRORS_CONT) && def_errors != EXT4_ERRORS_CONTINUE)\n\t\tSEQ_OPTS_PUTS(\"errors=continue\");\n\tif (test_opt(sb, ERRORS_PANIC) && def_errors != EXT4_ERRORS_PANIC)\n\t\tSEQ_OPTS_PUTS(\"errors=panic\");\n\tif (nodefs || sbi->s_commit_interval != JBD2_DEFAULT_MAX_COMMIT_AGE*HZ)\n\t\tSEQ_OPTS_PRINT(\"commit=%lu\", sbi->s_commit_interval / HZ);\n\tif (nodefs || sbi->s_min_batch_time != EXT4_DEF_MIN_BATCH_TIME)\n\t\tSEQ_OPTS_PRINT(\"min_batch_time=%u\", sbi->s_min_batch_time);\n\tif (nodefs || sbi->s_max_batch_time != EXT4_DEF_MAX_BATCH_TIME)\n\t\tSEQ_OPTS_PRINT(\"max_batch_time=%u\", sbi->s_max_batch_time);\n\tif (sb->s_flags & MS_I_VERSION)\n\t\tSEQ_OPTS_PUTS(\"i_version\");\n\tif (nodefs || sbi->s_stripe)\n\t\tSEQ_OPTS_PRINT(\"stripe=%lu\", sbi->s_stripe);\n\tif (EXT4_MOUNT_DATA_FLAGS & (sbi->s_mount_opt ^ def_mount_opt)) {\n\t\tif (test_opt(sb, DATA_FLAGS) == EXT4_MOUNT_JOURNAL_DATA)\n\t\t\tSEQ_OPTS_PUTS(\"data=journal\");\n\t\telse if (test_opt(sb, DATA_FLAGS) == EXT4_MOUNT_ORDERED_DATA)\n\t\t\tSEQ_OPTS_PUTS(\"data=ordered\");\n\t\telse if (test_opt(sb, DATA_FLAGS) == EXT4_MOUNT_WRITEBACK_DATA)\n\t\t\tSEQ_OPTS_PUTS(\"data=writeback\");\n\t}\n\tif (nodefs ||\n\t    sbi->s_inode_readahead_blks != EXT4_DEF_INODE_READAHEAD_BLKS)\n\t\tSEQ_OPTS_PRINT(\"inode_readahead_blks=%u\",\n\t\t\t       sbi->s_inode_readahead_blks);\n\n\tif (nodefs || (test_opt(sb, INIT_INODE_TABLE) &&\n\t\t       (sbi->s_li_wait_mult != EXT4_DEF_LI_WAIT_MULT)))\n\t\tSEQ_OPTS_PRINT(\"init_itable=%u\", sbi->s_li_wait_mult);\n\tif (nodefs || sbi->s_max_dir_size_kb)\n\t\tSEQ_OPTS_PRINT(\"max_dir_size_kb=%u\", sbi->s_max_dir_size_kb);\n\tif (test_opt(sb, DATA_ERR_ABORT))\n\t\tSEQ_OPTS_PUTS(\"data_err=abort\");\n\n\text4_show_quota_options(seq, sb);\n\treturn 0;\n}\n\nstatic int ext4_show_options(struct seq_file *seq, struct dentry *root)\n{\n\treturn _ext4_show_options(seq, root->d_sb, 0);\n}\n\nint ext4_seq_options_show(struct seq_file *seq, void *offset)\n{\n\tstruct super_block *sb = seq->private;\n\tint rc;\n\n\tseq_puts(seq, (sb->s_flags & MS_RDONLY) ? \"ro\" : \"rw\");\n\trc = _ext4_show_options(seq, sb, 1);\n\tseq_puts(seq, \"\\n\");\n\treturn rc;\n}\n\nstatic int ext4_setup_super(struct super_block *sb, struct ext4_super_block *es,\n\t\t\t    int read_only)\n{\n\tstruct ext4_sb_info *sbi = EXT4_SB(sb);\n\tint res = 0;\n\n\tif (le32_to_cpu(es->s_rev_level) > EXT4_MAX_SUPP_REV) {\n\t\text4_msg(sb, KERN_ERR, \"revision level too high, \"\n\t\t\t \"forcing read-only mode\");\n\t\tres = MS_RDONLY;\n\t}\n\tif (read_only)\n\t\tgoto done;\n\tif (!(sbi->s_mount_state & EXT4_VALID_FS))\n\t\text4_msg(sb, KERN_WARNING, \"warning: mounting unchecked fs, \"\n\t\t\t \"running e2fsck is recommended\");\n\telse if (sbi->s_mount_state & EXT4_ERROR_FS)\n\t\text4_msg(sb, KERN_WARNING,\n\t\t\t \"warning: mounting fs with errors, \"\n\t\t\t \"running e2fsck is recommended\");\n\telse if ((__s16) le16_to_cpu(es->s_max_mnt_count) > 0 &&\n\t\t le16_to_cpu(es->s_mnt_count) >=\n\t\t (unsigned short) (__s16) le16_to_cpu(es->s_max_mnt_count))\n\t\text4_msg(sb, KERN_WARNING,\n\t\t\t \"warning: maximal mount count reached, \"\n\t\t\t \"running e2fsck is recommended\");\n\telse if (le32_to_cpu(es->s_checkinterval) &&\n\t\t(le32_to_cpu(es->s_lastcheck) +\n\t\t\tle32_to_cpu(es->s_checkinterval) <= get_seconds()))\n\t\text4_msg(sb, KERN_WARNING,\n\t\t\t \"warning: checktime reached, \"\n\t\t\t \"running e2fsck is recommended\");\n\tif (!sbi->s_journal)\n\t\tes->s_state &= cpu_to_le16(~EXT4_VALID_FS);\n\tif (!(__s16) le16_to_cpu(es->s_max_mnt_count))\n\t\tes->s_max_mnt_count = cpu_to_le16(EXT4_DFL_MAX_MNT_COUNT);\n\tle16_add_cpu(&es->s_mnt_count, 1);\n\tes->s_mtime = cpu_to_le32(get_seconds());\n\text4_update_dynamic_rev(sb);\n\tif (sbi->s_journal)\n\t\text4_set_feature_journal_needs_recovery(sb);\n\n\text4_commit_super(sb, 1);\ndone:\n\tif (test_opt(sb, DEBUG))\n\t\tprintk(KERN_INFO \"[EXT4 FS bs=%lu, gc=%u, \"\n\t\t\t\t\"bpg=%lu, ipg=%lu, mo=%04x, mo2=%04x]\\n\",\n\t\t\tsb->s_blocksize,\n\t\t\tsbi->s_groups_count,\n\t\t\tEXT4_BLOCKS_PER_GROUP(sb),\n\t\t\tEXT4_INODES_PER_GROUP(sb),\n\t\t\tsbi->s_mount_opt, sbi->s_mount_opt2);\n\n\tcleancache_init_fs(sb);\n\treturn res;\n}\n\nint ext4_alloc_flex_bg_array(struct super_block *sb, ext4_group_t ngroup)\n{\n\tstruct ext4_sb_info *sbi = EXT4_SB(sb);\n\tstruct flex_groups *new_groups;\n\tint size;\n\n\tif (!sbi->s_log_groups_per_flex)\n\t\treturn 0;\n\n\tsize = ext4_flex_group(sbi, ngroup - 1) + 1;\n\tif (size <= sbi->s_flex_groups_allocated)\n\t\treturn 0;\n\n\tsize = roundup_pow_of_two(size * sizeof(struct flex_groups));\n\tnew_groups = ext4_kvzalloc(size, GFP_KERNEL);\n\tif (!new_groups) {\n\t\text4_msg(sb, KERN_ERR, \"not enough memory for %d flex groups\",\n\t\t\t size / (int) sizeof(struct flex_groups));\n\t\treturn -ENOMEM;\n\t}\n\n\tif (sbi->s_flex_groups) {\n\t\tmemcpy(new_groups, sbi->s_flex_groups,\n\t\t       (sbi->s_flex_groups_allocated *\n\t\t\tsizeof(struct flex_groups)));\n\t\tkvfree(sbi->s_flex_groups);\n\t}\n\tsbi->s_flex_groups = new_groups;\n\tsbi->s_flex_groups_allocated = size / sizeof(struct flex_groups);\n\treturn 0;\n}\n\nstatic int ext4_fill_flex_info(struct super_block *sb)\n{\n\tstruct ext4_sb_info *sbi = EXT4_SB(sb);\n\tstruct ext4_group_desc *gdp = NULL;\n\text4_group_t flex_group;\n\tint i, err;\n\n\tsbi->s_log_groups_per_flex = sbi->s_es->s_log_groups_per_flex;\n\tif (sbi->s_log_groups_per_flex < 1 || sbi->s_log_groups_per_flex > 31) {\n\t\tsbi->s_log_groups_per_flex = 0;\n\t\treturn 1;\n\t}\n\n\terr = ext4_alloc_flex_bg_array(sb, sbi->s_groups_count);\n\tif (err)\n\t\tgoto failed;\n\n\tfor (i = 0; i < sbi->s_groups_count; i++) {\n\t\tgdp = ext4_get_group_desc(sb, i, NULL);\n\n\t\tflex_group = ext4_flex_group(sbi, i);\n\t\tatomic_add(ext4_free_inodes_count(sb, gdp),\n\t\t\t   &sbi->s_flex_groups[flex_group].free_inodes);\n\t\tatomic64_add(ext4_free_group_clusters(sb, gdp),\n\t\t\t     &sbi->s_flex_groups[flex_group].free_clusters);\n\t\tatomic_add(ext4_used_dirs_count(sb, gdp),\n\t\t\t   &sbi->s_flex_groups[flex_group].used_dirs);\n\t}\n\n\treturn 1;\nfailed:\n\treturn 0;\n}\n\nstatic __le16 ext4_group_desc_csum(struct super_block *sb, __u32 block_group,\n\t\t\t\t   struct ext4_group_desc *gdp)\n{\n\tint offset = offsetof(struct ext4_group_desc, bg_checksum);\n\t__u16 crc = 0;\n\t__le32 le_group = cpu_to_le32(block_group);\n\tstruct ext4_sb_info *sbi = EXT4_SB(sb);\n\n\tif (ext4_has_metadata_csum(sbi->s_sb)) {\n\t\t/* Use new metadata_csum algorithm */\n\t\t__u32 csum32;\n\t\t__u16 dummy_csum = 0;\n\n\t\tcsum32 = ext4_chksum(sbi, sbi->s_csum_seed, (__u8 *)&le_group,\n\t\t\t\t     sizeof(le_group));\n\t\tcsum32 = ext4_chksum(sbi, csum32, (__u8 *)gdp, offset);\n\t\tcsum32 = ext4_chksum(sbi, csum32, (__u8 *)&dummy_csum,\n\t\t\t\t     sizeof(dummy_csum));\n\t\toffset += sizeof(dummy_csum);\n\t\tif (offset < sbi->s_desc_size)\n\t\t\tcsum32 = ext4_chksum(sbi, csum32, (__u8 *)gdp + offset,\n\t\t\t\t\t     sbi->s_desc_size - offset);\n\n\t\tcrc = csum32 & 0xFFFF;\n\t\tgoto out;\n\t}\n\n\t/* old crc16 code */\n\tif (!ext4_has_feature_gdt_csum(sb))\n\t\treturn 0;\n\n\tcrc = crc16(~0, sbi->s_es->s_uuid, sizeof(sbi->s_es->s_uuid));\n\tcrc = crc16(crc, (__u8 *)&le_group, sizeof(le_group));\n\tcrc = crc16(crc, (__u8 *)gdp, offset);\n\toffset += sizeof(gdp->bg_checksum); /* skip checksum */\n\t/* for checksum of struct ext4_group_desc do the rest...*/\n\tif (ext4_has_feature_64bit(sb) &&\n\t    offset < le16_to_cpu(sbi->s_es->s_desc_size))\n\t\tcrc = crc16(crc, (__u8 *)gdp + offset,\n\t\t\t    le16_to_cpu(sbi->s_es->s_desc_size) -\n\t\t\t\toffset);\n\nout:\n\treturn cpu_to_le16(crc);\n}\n\nint ext4_group_desc_csum_verify(struct super_block *sb, __u32 block_group,\n\t\t\t\tstruct ext4_group_desc *gdp)\n{\n\tif (ext4_has_group_desc_csum(sb) &&\n\t    (gdp->bg_checksum != ext4_group_desc_csum(sb, block_group, gdp)))\n\t\treturn 0;\n\n\treturn 1;\n}\n\nvoid ext4_group_desc_csum_set(struct super_block *sb, __u32 block_group,\n\t\t\t      struct ext4_group_desc *gdp)\n{\n\tif (!ext4_has_group_desc_csum(sb))\n\t\treturn;\n\tgdp->bg_checksum = ext4_group_desc_csum(sb, block_group, gdp);\n}\n\n/* Called at mount-time, super-block is locked */\nstatic int ext4_check_descriptors(struct super_block *sb,\n\t\t\t\t  ext4_fsblk_t sb_block,\n\t\t\t\t  ext4_group_t *first_not_zeroed)\n{\n\tstruct ext4_sb_info *sbi = EXT4_SB(sb);\n\text4_fsblk_t first_block = le32_to_cpu(sbi->s_es->s_first_data_block);\n\text4_fsblk_t last_block;\n\text4_fsblk_t block_bitmap;\n\text4_fsblk_t inode_bitmap;\n\text4_fsblk_t inode_table;\n\tint flexbg_flag = 0;\n\text4_group_t i, grp = sbi->s_groups_count;\n\n\tif (ext4_has_feature_flex_bg(sb))\n\t\tflexbg_flag = 1;\n\n\text4_debug(\"Checking group descriptors\");\n\n\tfor (i = 0; i < sbi->s_groups_count; i++) {\n\t\tstruct ext4_group_desc *gdp = ext4_get_group_desc(sb, i, NULL);\n\n\t\tif (i == sbi->s_groups_count - 1 || flexbg_flag)\n\t\t\tlast_block = ext4_blocks_count(sbi->s_es) - 1;\n\t\telse\n\t\t\tlast_block = first_block +\n\t\t\t\t(EXT4_BLOCKS_PER_GROUP(sb) - 1);\n\n\t\tif ((grp == sbi->s_groups_count) &&\n\t\t   !(gdp->bg_flags & cpu_to_le16(EXT4_BG_INODE_ZEROED)))\n\t\t\tgrp = i;\n\n\t\tblock_bitmap = ext4_block_bitmap(sb, gdp);\n\t\tif (block_bitmap == sb_block) {\n\t\t\text4_msg(sb, KERN_ERR, \"ext4_check_descriptors: \"\n\t\t\t\t \"Block bitmap for group %u overlaps \"\n\t\t\t\t \"superblock\", i);\n\t\t}\n\t\tif (block_bitmap < first_block || block_bitmap > last_block) {\n\t\t\text4_msg(sb, KERN_ERR, \"ext4_check_descriptors: \"\n\t\t\t       \"Block bitmap for group %u not in group \"\n\t\t\t       \"(block %llu)!\", i, block_bitmap);\n\t\t\treturn 0;\n\t\t}\n\t\tinode_bitmap = ext4_inode_bitmap(sb, gdp);\n\t\tif (inode_bitmap == sb_block) {\n\t\t\text4_msg(sb, KERN_ERR, \"ext4_check_descriptors: \"\n\t\t\t\t \"Inode bitmap for group %u overlaps \"\n\t\t\t\t \"superblock\", i);\n\t\t}\n\t\tif (inode_bitmap < first_block || inode_bitmap > last_block) {\n\t\t\text4_msg(sb, KERN_ERR, \"ext4_check_descriptors: \"\n\t\t\t       \"Inode bitmap for group %u not in group \"\n\t\t\t       \"(block %llu)!\", i, inode_bitmap);\n\t\t\treturn 0;\n\t\t}\n\t\tinode_table = ext4_inode_table(sb, gdp);\n\t\tif (inode_table == sb_block) {\n\t\t\text4_msg(sb, KERN_ERR, \"ext4_check_descriptors: \"\n\t\t\t\t \"Inode table for group %u overlaps \"\n\t\t\t\t \"superblock\", i);\n\t\t}\n\t\tif (inode_table < first_block ||\n\t\t    inode_table + sbi->s_itb_per_group - 1 > last_block) {\n\t\t\text4_msg(sb, KERN_ERR, \"ext4_check_descriptors: \"\n\t\t\t       \"Inode table for group %u not in group \"\n\t\t\t       \"(block %llu)!\", i, inode_table);\n\t\t\treturn 0;\n\t\t}\n\t\text4_lock_group(sb, i);\n\t\tif (!ext4_group_desc_csum_verify(sb, i, gdp)) {\n\t\t\text4_msg(sb, KERN_ERR, \"ext4_check_descriptors: \"\n\t\t\t\t \"Checksum for group %u failed (%u!=%u)\",\n\t\t\t\t i, le16_to_cpu(ext4_group_desc_csum(sb, i,\n\t\t\t\t     gdp)), le16_to_cpu(gdp->bg_checksum));\n\t\t\tif (!(sb->s_flags & MS_RDONLY)) {\n\t\t\t\text4_unlock_group(sb, i);\n\t\t\t\treturn 0;\n\t\t\t}\n\t\t}\n\t\text4_unlock_group(sb, i);\n\t\tif (!flexbg_flag)\n\t\t\tfirst_block += EXT4_BLOCKS_PER_GROUP(sb);\n\t}\n\tif (NULL != first_not_zeroed)\n\t\t*first_not_zeroed = grp;\n\treturn 1;\n}\n\n/* ext4_orphan_cleanup() walks a singly-linked list of inodes (starting at\n * the superblock) which were deleted from all directories, but held open by\n * a process at the time of a crash.  We walk the list and try to delete these\n * inodes at recovery time (only with a read-write filesystem).\n *\n * In order to keep the orphan inode chain consistent during traversal (in\n * case of crash during recovery), we link each inode into the superblock\n * orphan list_head and handle it the same way as an inode deletion during\n * normal operation (which journals the operations for us).\n *\n * We only do an iget() and an iput() on each inode, which is very safe if we\n * accidentally point at an in-use or already deleted inode.  The worst that\n * can happen in this case is that we get a \"bit already cleared\" message from\n * ext4_free_inode().  The only reason we would point at a wrong inode is if\n * e2fsck was run on this filesystem, and it must have already done the orphan\n * inode cleanup for us, so we can safely abort without any further action.\n */\nstatic void ext4_orphan_cleanup(struct super_block *sb,\n\t\t\t\tstruct ext4_super_block *es)\n{\n\tunsigned int s_flags = sb->s_flags;\n\tint ret, nr_orphans = 0, nr_truncates = 0;\n#ifdef CONFIG_QUOTA\n\tint i;\n#endif\n\tif (!es->s_last_orphan) {\n\t\tjbd_debug(4, \"no orphan inodes to clean up\\n\");\n\t\treturn;\n\t}\n\n\tif (bdev_read_only(sb->s_bdev)) {\n\t\text4_msg(sb, KERN_ERR, \"write access \"\n\t\t\t\"unavailable, skipping orphan cleanup\");\n\t\treturn;\n\t}\n\n\t/* Check if feature set would not allow a r/w mount */\n\tif (!ext4_feature_set_ok(sb, 0)) {\n\t\text4_msg(sb, KERN_INFO, \"Skipping orphan cleanup due to \"\n\t\t\t \"unknown ROCOMPAT features\");\n\t\treturn;\n\t}\n\n\tif (EXT4_SB(sb)->s_mount_state & EXT4_ERROR_FS) {\n\t\t/* don't clear list on RO mount w/ errors */\n\t\tif (es->s_last_orphan && !(s_flags & MS_RDONLY)) {\n\t\t\text4_msg(sb, KERN_INFO, \"Errors on filesystem, \"\n\t\t\t\t  \"clearing orphan list.\\n\");\n\t\t\tes->s_last_orphan = 0;\n\t\t}\n\t\tjbd_debug(1, \"Skipping orphan recovery on fs with errors.\\n\");\n\t\treturn;\n\t}\n\n\tif (s_flags & MS_RDONLY) {\n\t\text4_msg(sb, KERN_INFO, \"orphan cleanup on readonly fs\");\n\t\tsb->s_flags &= ~MS_RDONLY;\n\t}\n#ifdef CONFIG_QUOTA\n\t/* Needed for iput() to work correctly and not trash data */\n\tsb->s_flags |= MS_ACTIVE;\n\t/* Turn on quotas so that they are updated correctly */\n\tfor (i = 0; i < EXT4_MAXQUOTAS; i++) {\n\t\tif (EXT4_SB(sb)->s_qf_names[i]) {\n\t\t\tint ret = ext4_quota_on_mount(sb, i);\n\t\t\tif (ret < 0)\n\t\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t\t\t\"Cannot turn on journaled \"\n\t\t\t\t\t\"quota: error %d\", ret);\n\t\t}\n\t}\n#endif\n\n\twhile (es->s_last_orphan) {\n\t\tstruct inode *inode;\n\n\t\t/*\n\t\t * We may have encountered an error during cleanup; if\n\t\t * so, skip the rest.\n\t\t */\n\t\tif (EXT4_SB(sb)->s_mount_state & EXT4_ERROR_FS) {\n\t\t\tjbd_debug(1, \"Skipping orphan recovery on fs with errors.\\n\");\n\t\t\tes->s_last_orphan = 0;\n\t\t\tbreak;\n\t\t}\n\n\t\tinode = ext4_orphan_get(sb, le32_to_cpu(es->s_last_orphan));\n\t\tif (IS_ERR(inode)) {\n\t\t\tes->s_last_orphan = 0;\n\t\t\tbreak;\n\t\t}\n\n\t\tlist_add(&EXT4_I(inode)->i_orphan, &EXT4_SB(sb)->s_orphan);\n\t\tdquot_initialize(inode);\n\t\tif (inode->i_nlink) {\n\t\t\tif (test_opt(sb, DEBUG))\n\t\t\t\text4_msg(sb, KERN_DEBUG,\n\t\t\t\t\t\"%s: truncating inode %lu to %lld bytes\",\n\t\t\t\t\t__func__, inode->i_ino, inode->i_size);\n\t\t\tjbd_debug(2, \"truncating inode %lu to %lld bytes\\n\",\n\t\t\t\t  inode->i_ino, inode->i_size);\n\t\t\tinode_lock(inode);\n\t\t\ttruncate_inode_pages(inode->i_mapping, inode->i_size);\n\t\t\tret = ext4_truncate(inode);\n\t\t\tif (ret)\n\t\t\t\text4_std_error(inode->i_sb, ret);\n\t\t\tinode_unlock(inode);\n\t\t\tnr_truncates++;\n\t\t} else {\n\t\t\tif (test_opt(sb, DEBUG))\n\t\t\t\text4_msg(sb, KERN_DEBUG,\n\t\t\t\t\t\"%s: deleting unreferenced inode %lu\",\n\t\t\t\t\t__func__, inode->i_ino);\n\t\t\tjbd_debug(2, \"deleting unreferenced inode %lu\\n\",\n\t\t\t\t  inode->i_ino);\n\t\t\tnr_orphans++;\n\t\t}\n\t\tiput(inode);  /* The delete magic happens here! */\n\t}\n\n#define PLURAL(x) (x), ((x) == 1) ? \"\" : \"s\"\n\n\tif (nr_orphans)\n\t\text4_msg(sb, KERN_INFO, \"%d orphan inode%s deleted\",\n\t\t       PLURAL(nr_orphans));\n\tif (nr_truncates)\n\t\text4_msg(sb, KERN_INFO, \"%d truncate%s cleaned up\",\n\t\t       PLURAL(nr_truncates));\n#ifdef CONFIG_QUOTA\n\t/* Turn quotas off */\n\tfor (i = 0; i < EXT4_MAXQUOTAS; i++) {\n\t\tif (sb_dqopt(sb)->files[i])\n\t\t\tdquot_quota_off(sb, i);\n\t}\n#endif\n\tsb->s_flags = s_flags; /* Restore MS_RDONLY status */\n}\n\n/*\n * Maximal extent format file size.\n * Resulting logical blkno at s_maxbytes must fit in our on-disk\n * extent format containers, within a sector_t, and within i_blocks\n * in the vfs.  ext4 inode has 48 bits of i_block in fsblock units,\n * so that won't be a limiting factor.\n *\n * However there is other limiting factor. We do store extents in the form\n * of starting block and length, hence the resulting length of the extent\n * covering maximum file size must fit into on-disk format containers as\n * well. Given that length is always by 1 unit bigger than max unit (because\n * we count 0 as well) we have to lower the s_maxbytes by one fs block.\n *\n * Note, this does *not* consider any metadata overhead for vfs i_blocks.\n */\nstatic loff_t ext4_max_size(int blkbits, int has_huge_files)\n{\n\tloff_t res;\n\tloff_t upper_limit = MAX_LFS_FILESIZE;\n\n\t/* small i_blocks in vfs inode? */\n\tif (!has_huge_files || sizeof(blkcnt_t) < sizeof(u64)) {\n\t\t/*\n\t\t * CONFIG_LBDAF is not enabled implies the inode\n\t\t * i_block represent total blocks in 512 bytes\n\t\t * 32 == size of vfs inode i_blocks * 8\n\t\t */\n\t\tupper_limit = (1LL << 32) - 1;\n\n\t\t/* total blocks in file system block size */\n\t\tupper_limit >>= (blkbits - 9);\n\t\tupper_limit <<= blkbits;\n\t}\n\n\t/*\n\t * 32-bit extent-start container, ee_block. We lower the maxbytes\n\t * by one fs block, so ee_len can cover the extent of maximum file\n\t * size\n\t */\n\tres = (1LL << 32) - 1;\n\tres <<= blkbits;\n\n\t/* Sanity check against vm- & vfs- imposed limits */\n\tif (res > upper_limit)\n\t\tres = upper_limit;\n\n\treturn res;\n}\n\n/*\n * Maximal bitmap file size.  There is a direct, and {,double-,triple-}indirect\n * block limit, and also a limit of (2^48 - 1) 512-byte sectors in i_blocks.\n * We need to be 1 filesystem block less than the 2^48 sector limit.\n */\nstatic loff_t ext4_max_bitmap_size(int bits, int has_huge_files)\n{\n\tloff_t res = EXT4_NDIR_BLOCKS;\n\tint meta_blocks;\n\tloff_t upper_limit;\n\t/* This is calculated to be the largest file size for a dense, block\n\t * mapped file such that the file's total number of 512-byte sectors,\n\t * including data and all indirect blocks, does not exceed (2^48 - 1).\n\t *\n\t * __u32 i_blocks_lo and _u16 i_blocks_high represent the total\n\t * number of 512-byte sectors of the file.\n\t */\n\n\tif (!has_huge_files || sizeof(blkcnt_t) < sizeof(u64)) {\n\t\t/*\n\t\t * !has_huge_files or CONFIG_LBDAF not enabled implies that\n\t\t * the inode i_block field represents total file blocks in\n\t\t * 2^32 512-byte sectors == size of vfs inode i_blocks * 8\n\t\t */\n\t\tupper_limit = (1LL << 32) - 1;\n\n\t\t/* total blocks in file system block size */\n\t\tupper_limit >>= (bits - 9);\n\n\t} else {\n\t\t/*\n\t\t * We use 48 bit ext4_inode i_blocks\n\t\t * With EXT4_HUGE_FILE_FL set the i_blocks\n\t\t * represent total number of blocks in\n\t\t * file system block size\n\t\t */\n\t\tupper_limit = (1LL << 48) - 1;\n\n\t}\n\n\t/* indirect blocks */\n\tmeta_blocks = 1;\n\t/* double indirect blocks */\n\tmeta_blocks += 1 + (1LL << (bits-2));\n\t/* tripple indirect blocks */\n\tmeta_blocks += 1 + (1LL << (bits-2)) + (1LL << (2*(bits-2)));\n\n\tupper_limit -= meta_blocks;\n\tupper_limit <<= bits;\n\n\tres += 1LL << (bits-2);\n\tres += 1LL << (2*(bits-2));\n\tres += 1LL << (3*(bits-2));\n\tres <<= bits;\n\tif (res > upper_limit)\n\t\tres = upper_limit;\n\n\tif (res > MAX_LFS_FILESIZE)\n\t\tres = MAX_LFS_FILESIZE;\n\n\treturn res;\n}\n\nstatic ext4_fsblk_t descriptor_loc(struct super_block *sb,\n\t\t\t\t   ext4_fsblk_t logical_sb_block, int nr)\n{\n\tstruct ext4_sb_info *sbi = EXT4_SB(sb);\n\text4_group_t bg, first_meta_bg;\n\tint has_super = 0;\n\n\tfirst_meta_bg = le32_to_cpu(sbi->s_es->s_first_meta_bg);\n\n\tif (!ext4_has_feature_meta_bg(sb) || nr < first_meta_bg)\n\t\treturn logical_sb_block + nr + 1;\n\tbg = sbi->s_desc_per_block * nr;\n\tif (ext4_bg_has_super(sb, bg))\n\t\thas_super = 1;\n\n\t/*\n\t * If we have a meta_bg fs with 1k blocks, group 0's GDT is at\n\t * block 2, not 1.  If s_first_data_block == 0 (bigalloc is enabled\n\t * on modern mke2fs or blksize > 1k on older mke2fs) then we must\n\t * compensate.\n\t */\n\tif (sb->s_blocksize == 1024 && nr == 0 &&\n\t    le32_to_cpu(EXT4_SB(sb)->s_es->s_first_data_block) == 0)\n\t\thas_super++;\n\n\treturn (has_super + ext4_group_first_block_no(sb, bg));\n}\n\n/**\n * ext4_get_stripe_size: Get the stripe size.\n * @sbi: In memory super block info\n *\n * If we have specified it via mount option, then\n * use the mount option value. If the value specified at mount time is\n * greater than the blocks per group use the super block value.\n * If the super block value is greater than blocks per group return 0.\n * Allocator needs it be less than blocks per group.\n *\n */\nstatic unsigned long ext4_get_stripe_size(struct ext4_sb_info *sbi)\n{\n\tunsigned long stride = le16_to_cpu(sbi->s_es->s_raid_stride);\n\tunsigned long stripe_width =\n\t\t\tle32_to_cpu(sbi->s_es->s_raid_stripe_width);\n\tint ret;\n\n\tif (sbi->s_stripe && sbi->s_stripe <= sbi->s_blocks_per_group)\n\t\tret = sbi->s_stripe;\n\telse if (stripe_width <= sbi->s_blocks_per_group)\n\t\tret = stripe_width;\n\telse if (stride <= sbi->s_blocks_per_group)\n\t\tret = stride;\n\telse\n\t\tret = 0;\n\n\t/*\n\t * If the stripe width is 1, this makes no sense and\n\t * we set it to 0 to turn off stripe handling code.\n\t */\n\tif (ret <= 1)\n\t\tret = 0;\n\n\treturn ret;\n}\n\n/*\n * Check whether this filesystem can be mounted based on\n * the features present and the RDONLY/RDWR mount requested.\n * Returns 1 if this filesystem can be mounted as requested,\n * 0 if it cannot be.\n */\nstatic int ext4_feature_set_ok(struct super_block *sb, int readonly)\n{\n\tif (ext4_has_unknown_ext4_incompat_features(sb)) {\n\t\text4_msg(sb, KERN_ERR,\n\t\t\t\"Couldn't mount because of \"\n\t\t\t\"unsupported optional features (%x)\",\n\t\t\t(le32_to_cpu(EXT4_SB(sb)->s_es->s_feature_incompat) &\n\t\t\t~EXT4_FEATURE_INCOMPAT_SUPP));\n\t\treturn 0;\n\t}\n\n\tif (readonly)\n\t\treturn 1;\n\n\tif (ext4_has_feature_readonly(sb)) {\n\t\text4_msg(sb, KERN_INFO, \"filesystem is read-only\");\n\t\tsb->s_flags |= MS_RDONLY;\n\t\treturn 1;\n\t}\n\n\t/* Check that feature set is OK for a read-write mount */\n\tif (ext4_has_unknown_ext4_ro_compat_features(sb)) {\n\t\text4_msg(sb, KERN_ERR, \"couldn't mount RDWR because of \"\n\t\t\t \"unsupported optional features (%x)\",\n\t\t\t (le32_to_cpu(EXT4_SB(sb)->s_es->s_feature_ro_compat) &\n\t\t\t\t~EXT4_FEATURE_RO_COMPAT_SUPP));\n\t\treturn 0;\n\t}\n\t/*\n\t * Large file size enabled file system can only be mounted\n\t * read-write on 32-bit systems if kernel is built with CONFIG_LBDAF\n\t */\n\tif (ext4_has_feature_huge_file(sb)) {\n\t\tif (sizeof(blkcnt_t) < sizeof(u64)) {\n\t\t\text4_msg(sb, KERN_ERR, \"Filesystem with huge files \"\n\t\t\t\t \"cannot be mounted RDWR without \"\n\t\t\t\t \"CONFIG_LBDAF\");\n\t\t\treturn 0;\n\t\t}\n\t}\n\tif (ext4_has_feature_bigalloc(sb) && !ext4_has_feature_extents(sb)) {\n\t\text4_msg(sb, KERN_ERR,\n\t\t\t \"Can't support bigalloc feature without \"\n\t\t\t \"extents feature\\n\");\n\t\treturn 0;\n\t}\n\n#ifndef CONFIG_QUOTA\n\tif (ext4_has_feature_quota(sb) && !readonly) {\n\t\text4_msg(sb, KERN_ERR,\n\t\t\t \"Filesystem with quota feature cannot be mounted RDWR \"\n\t\t\t \"without CONFIG_QUOTA\");\n\t\treturn 0;\n\t}\n\tif (ext4_has_feature_project(sb) && !readonly) {\n\t\text4_msg(sb, KERN_ERR,\n\t\t\t \"Filesystem with project quota feature cannot be mounted RDWR \"\n\t\t\t \"without CONFIG_QUOTA\");\n\t\treturn 0;\n\t}\n#endif  /* CONFIG_QUOTA */\n\treturn 1;\n}\n\n/*\n * This function is called once a day if we have errors logged\n * on the file system\n */\nstatic void print_daily_error_info(unsigned long arg)\n{\n\tstruct super_block *sb = (struct super_block *) arg;\n\tstruct ext4_sb_info *sbi;\n\tstruct ext4_super_block *es;\n\n\tsbi = EXT4_SB(sb);\n\tes = sbi->s_es;\n\n\tif (es->s_error_count)\n\t\t/* fsck newer than v1.41.13 is needed to clean this condition. */\n\t\text4_msg(sb, KERN_NOTICE, \"error count since last fsck: %u\",\n\t\t\t le32_to_cpu(es->s_error_count));\n\tif (es->s_first_error_time) {\n\t\tprintk(KERN_NOTICE \"EXT4-fs (%s): initial error at time %u: %.*s:%d\",\n\t\t       sb->s_id, le32_to_cpu(es->s_first_error_time),\n\t\t       (int) sizeof(es->s_first_error_func),\n\t\t       es->s_first_error_func,\n\t\t       le32_to_cpu(es->s_first_error_line));\n\t\tif (es->s_first_error_ino)\n\t\t\tprintk(KERN_CONT \": inode %u\",\n\t\t\t       le32_to_cpu(es->s_first_error_ino));\n\t\tif (es->s_first_error_block)\n\t\t\tprintk(KERN_CONT \": block %llu\", (unsigned long long)\n\t\t\t       le64_to_cpu(es->s_first_error_block));\n\t\tprintk(KERN_CONT \"\\n\");\n\t}\n\tif (es->s_last_error_time) {\n\t\tprintk(KERN_NOTICE \"EXT4-fs (%s): last error at time %u: %.*s:%d\",\n\t\t       sb->s_id, le32_to_cpu(es->s_last_error_time),\n\t\t       (int) sizeof(es->s_last_error_func),\n\t\t       es->s_last_error_func,\n\t\t       le32_to_cpu(es->s_last_error_line));\n\t\tif (es->s_last_error_ino)\n\t\t\tprintk(KERN_CONT \": inode %u\",\n\t\t\t       le32_to_cpu(es->s_last_error_ino));\n\t\tif (es->s_last_error_block)\n\t\t\tprintk(KERN_CONT \": block %llu\", (unsigned long long)\n\t\t\t       le64_to_cpu(es->s_last_error_block));\n\t\tprintk(KERN_CONT \"\\n\");\n\t}\n\tmod_timer(&sbi->s_err_report, jiffies + 24*60*60*HZ);  /* Once a day */\n}\n\n/* Find next suitable group and run ext4_init_inode_table */\nstatic int ext4_run_li_request(struct ext4_li_request *elr)\n{\n\tstruct ext4_group_desc *gdp = NULL;\n\text4_group_t group, ngroups;\n\tstruct super_block *sb;\n\tunsigned long timeout = 0;\n\tint ret = 0;\n\n\tsb = elr->lr_super;\n\tngroups = EXT4_SB(sb)->s_groups_count;\n\n\tfor (group = elr->lr_next_group; group < ngroups; group++) {\n\t\tgdp = ext4_get_group_desc(sb, group, NULL);\n\t\tif (!gdp) {\n\t\t\tret = 1;\n\t\t\tbreak;\n\t\t}\n\n\t\tif (!(gdp->bg_flags & cpu_to_le16(EXT4_BG_INODE_ZEROED)))\n\t\t\tbreak;\n\t}\n\n\tif (group >= ngroups)\n\t\tret = 1;\n\n\tif (!ret) {\n\t\ttimeout = jiffies;\n\t\tret = ext4_init_inode_table(sb, group,\n\t\t\t\t\t    elr->lr_timeout ? 0 : 1);\n\t\tif (elr->lr_timeout == 0) {\n\t\t\ttimeout = (jiffies - timeout) *\n\t\t\t\t  elr->lr_sbi->s_li_wait_mult;\n\t\t\telr->lr_timeout = timeout;\n\t\t}\n\t\telr->lr_next_sched = jiffies + elr->lr_timeout;\n\t\telr->lr_next_group = group + 1;\n\t}\n\treturn ret;\n}\n\n/*\n * Remove lr_request from the list_request and free the\n * request structure. Should be called with li_list_mtx held\n */\nstatic void ext4_remove_li_request(struct ext4_li_request *elr)\n{\n\tstruct ext4_sb_info *sbi;\n\n\tif (!elr)\n\t\treturn;\n\n\tsbi = elr->lr_sbi;\n\n\tlist_del(&elr->lr_request);\n\tsbi->s_li_request = NULL;\n\tkfree(elr);\n}\n\nstatic void ext4_unregister_li_request(struct super_block *sb)\n{\n\tmutex_lock(&ext4_li_mtx);\n\tif (!ext4_li_info) {\n\t\tmutex_unlock(&ext4_li_mtx);\n\t\treturn;\n\t}\n\n\tmutex_lock(&ext4_li_info->li_list_mtx);\n\text4_remove_li_request(EXT4_SB(sb)->s_li_request);\n\tmutex_unlock(&ext4_li_info->li_list_mtx);\n\tmutex_unlock(&ext4_li_mtx);\n}\n\nstatic struct task_struct *ext4_lazyinit_task;\n\n/*\n * This is the function where ext4lazyinit thread lives. It walks\n * through the request list searching for next scheduled filesystem.\n * When such a fs is found, run the lazy initialization request\n * (ext4_rn_li_request) and keep track of the time spend in this\n * function. Based on that time we compute next schedule time of\n * the request. When walking through the list is complete, compute\n * next waking time and put itself into sleep.\n */\nstatic int ext4_lazyinit_thread(void *arg)\n{\n\tstruct ext4_lazy_init *eli = (struct ext4_lazy_init *)arg;\n\tstruct list_head *pos, *n;\n\tstruct ext4_li_request *elr;\n\tunsigned long next_wakeup, cur;\n\n\tBUG_ON(NULL == eli);\n\ncont_thread:\n\twhile (true) {\n\t\tnext_wakeup = MAX_JIFFY_OFFSET;\n\n\t\tmutex_lock(&eli->li_list_mtx);\n\t\tif (list_empty(&eli->li_request_list)) {\n\t\t\tmutex_unlock(&eli->li_list_mtx);\n\t\t\tgoto exit_thread;\n\t\t}\n\t\tlist_for_each_safe(pos, n, &eli->li_request_list) {\n\t\t\tint err = 0;\n\t\t\tint progress = 0;\n\t\t\telr = list_entry(pos, struct ext4_li_request,\n\t\t\t\t\t lr_request);\n\n\t\t\tif (time_before(jiffies, elr->lr_next_sched)) {\n\t\t\t\tif (time_before(elr->lr_next_sched, next_wakeup))\n\t\t\t\t\tnext_wakeup = elr->lr_next_sched;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tif (down_read_trylock(&elr->lr_super->s_umount)) {\n\t\t\t\tif (sb_start_write_trylock(elr->lr_super)) {\n\t\t\t\t\tprogress = 1;\n\t\t\t\t\t/*\n\t\t\t\t\t * We hold sb->s_umount, sb can not\n\t\t\t\t\t * be removed from the list, it is\n\t\t\t\t\t * now safe to drop li_list_mtx\n\t\t\t\t\t */\n\t\t\t\t\tmutex_unlock(&eli->li_list_mtx);\n\t\t\t\t\terr = ext4_run_li_request(elr);\n\t\t\t\t\tsb_end_write(elr->lr_super);\n\t\t\t\t\tmutex_lock(&eli->li_list_mtx);\n\t\t\t\t\tn = pos->next;\n\t\t\t\t}\n\t\t\t\tup_read((&elr->lr_super->s_umount));\n\t\t\t}\n\t\t\t/* error, remove the lazy_init job */\n\t\t\tif (err) {\n\t\t\t\text4_remove_li_request(elr);\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tif (!progress) {\n\t\t\t\telr->lr_next_sched = jiffies +\n\t\t\t\t\t(prandom_u32()\n\t\t\t\t\t % (EXT4_DEF_LI_MAX_START_DELAY * HZ));\n\t\t\t}\n\t\t\tif (time_before(elr->lr_next_sched, next_wakeup))\n\t\t\t\tnext_wakeup = elr->lr_next_sched;\n\t\t}\n\t\tmutex_unlock(&eli->li_list_mtx);\n\n\t\ttry_to_freeze();\n\n\t\tcur = jiffies;\n\t\tif ((time_after_eq(cur, next_wakeup)) ||\n\t\t    (MAX_JIFFY_OFFSET == next_wakeup)) {\n\t\t\tcond_resched();\n\t\t\tcontinue;\n\t\t}\n\n\t\tschedule_timeout_interruptible(next_wakeup - cur);\n\n\t\tif (kthread_should_stop()) {\n\t\t\text4_clear_request_list();\n\t\t\tgoto exit_thread;\n\t\t}\n\t}\n\nexit_thread:\n\t/*\n\t * It looks like the request list is empty, but we need\n\t * to check it under the li_list_mtx lock, to prevent any\n\t * additions into it, and of course we should lock ext4_li_mtx\n\t * to atomically free the list and ext4_li_info, because at\n\t * this point another ext4 filesystem could be registering\n\t * new one.\n\t */\n\tmutex_lock(&ext4_li_mtx);\n\tmutex_lock(&eli->li_list_mtx);\n\tif (!list_empty(&eli->li_request_list)) {\n\t\tmutex_unlock(&eli->li_list_mtx);\n\t\tmutex_unlock(&ext4_li_mtx);\n\t\tgoto cont_thread;\n\t}\n\tmutex_unlock(&eli->li_list_mtx);\n\tkfree(ext4_li_info);\n\text4_li_info = NULL;\n\tmutex_unlock(&ext4_li_mtx);\n\n\treturn 0;\n}\n\nstatic void ext4_clear_request_list(void)\n{\n\tstruct list_head *pos, *n;\n\tstruct ext4_li_request *elr;\n\n\tmutex_lock(&ext4_li_info->li_list_mtx);\n\tlist_for_each_safe(pos, n, &ext4_li_info->li_request_list) {\n\t\telr = list_entry(pos, struct ext4_li_request,\n\t\t\t\t lr_request);\n\t\text4_remove_li_request(elr);\n\t}\n\tmutex_unlock(&ext4_li_info->li_list_mtx);\n}\n\nstatic int ext4_run_lazyinit_thread(void)\n{\n\text4_lazyinit_task = kthread_run(ext4_lazyinit_thread,\n\t\t\t\t\t ext4_li_info, \"ext4lazyinit\");\n\tif (IS_ERR(ext4_lazyinit_task)) {\n\t\tint err = PTR_ERR(ext4_lazyinit_task);\n\t\text4_clear_request_list();\n\t\tkfree(ext4_li_info);\n\t\text4_li_info = NULL;\n\t\tprintk(KERN_CRIT \"EXT4-fs: error %d creating inode table \"\n\t\t\t\t \"initialization thread\\n\",\n\t\t\t\t err);\n\t\treturn err;\n\t}\n\text4_li_info->li_state |= EXT4_LAZYINIT_RUNNING;\n\treturn 0;\n}\n\n/*\n * Check whether it make sense to run itable init. thread or not.\n * If there is at least one uninitialized inode table, return\n * corresponding group number, else the loop goes through all\n * groups and return total number of groups.\n */\nstatic ext4_group_t ext4_has_uninit_itable(struct super_block *sb)\n{\n\text4_group_t group, ngroups = EXT4_SB(sb)->s_groups_count;\n\tstruct ext4_group_desc *gdp = NULL;\n\n\tfor (group = 0; group < ngroups; group++) {\n\t\tgdp = ext4_get_group_desc(sb, group, NULL);\n\t\tif (!gdp)\n\t\t\tcontinue;\n\n\t\tif (!(gdp->bg_flags & cpu_to_le16(EXT4_BG_INODE_ZEROED)))\n\t\t\tbreak;\n\t}\n\n\treturn group;\n}\n\nstatic int ext4_li_info_new(void)\n{\n\tstruct ext4_lazy_init *eli = NULL;\n\n\teli = kzalloc(sizeof(*eli), GFP_KERNEL);\n\tif (!eli)\n\t\treturn -ENOMEM;\n\n\tINIT_LIST_HEAD(&eli->li_request_list);\n\tmutex_init(&eli->li_list_mtx);\n\n\teli->li_state |= EXT4_LAZYINIT_QUIT;\n\n\text4_li_info = eli;\n\n\treturn 0;\n}\n\nstatic struct ext4_li_request *ext4_li_request_new(struct super_block *sb,\n\t\t\t\t\t    ext4_group_t start)\n{\n\tstruct ext4_sb_info *sbi = EXT4_SB(sb);\n\tstruct ext4_li_request *elr;\n\n\telr = kzalloc(sizeof(*elr), GFP_KERNEL);\n\tif (!elr)\n\t\treturn NULL;\n\n\telr->lr_super = sb;\n\telr->lr_sbi = sbi;\n\telr->lr_next_group = start;\n\n\t/*\n\t * Randomize first schedule time of the request to\n\t * spread the inode table initialization requests\n\t * better.\n\t */\n\telr->lr_next_sched = jiffies + (prandom_u32() %\n\t\t\t\t(EXT4_DEF_LI_MAX_START_DELAY * HZ));\n\treturn elr;\n}\n\nint ext4_register_li_request(struct super_block *sb,\n\t\t\t     ext4_group_t first_not_zeroed)\n{\n\tstruct ext4_sb_info *sbi = EXT4_SB(sb);\n\tstruct ext4_li_request *elr = NULL;\n\text4_group_t ngroups = EXT4_SB(sb)->s_groups_count;\n\tint ret = 0;\n\n\tmutex_lock(&ext4_li_mtx);\n\tif (sbi->s_li_request != NULL) {\n\t\t/*\n\t\t * Reset timeout so it can be computed again, because\n\t\t * s_li_wait_mult might have changed.\n\t\t */\n\t\tsbi->s_li_request->lr_timeout = 0;\n\t\tgoto out;\n\t}\n\n\tif (first_not_zeroed == ngroups ||\n\t    (sb->s_flags & MS_RDONLY) ||\n\t    !test_opt(sb, INIT_INODE_TABLE))\n\t\tgoto out;\n\n\telr = ext4_li_request_new(sb, first_not_zeroed);\n\tif (!elr) {\n\t\tret = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\tif (NULL == ext4_li_info) {\n\t\tret = ext4_li_info_new();\n\t\tif (ret)\n\t\t\tgoto out;\n\t}\n\n\tmutex_lock(&ext4_li_info->li_list_mtx);\n\tlist_add(&elr->lr_request, &ext4_li_info->li_request_list);\n\tmutex_unlock(&ext4_li_info->li_list_mtx);\n\n\tsbi->s_li_request = elr;\n\t/*\n\t * set elr to NULL here since it has been inserted to\n\t * the request_list and the removal and free of it is\n\t * handled by ext4_clear_request_list from now on.\n\t */\n\telr = NULL;\n\n\tif (!(ext4_li_info->li_state & EXT4_LAZYINIT_RUNNING)) {\n\t\tret = ext4_run_lazyinit_thread();\n\t\tif (ret)\n\t\t\tgoto out;\n\t}\nout:\n\tmutex_unlock(&ext4_li_mtx);\n\tif (ret)\n\t\tkfree(elr);\n\treturn ret;\n}\n\n/*\n * We do not need to lock anything since this is called on\n * module unload.\n */\nstatic void ext4_destroy_lazyinit_thread(void)\n{\n\t/*\n\t * If thread exited earlier\n\t * there's nothing to be done.\n\t */\n\tif (!ext4_li_info || !ext4_lazyinit_task)\n\t\treturn;\n\n\tkthread_stop(ext4_lazyinit_task);\n}\n\nstatic int set_journal_csum_feature_set(struct super_block *sb)\n{\n\tint ret = 1;\n\tint compat, incompat;\n\tstruct ext4_sb_info *sbi = EXT4_SB(sb);\n\n\tif (ext4_has_metadata_csum(sb)) {\n\t\t/* journal checksum v3 */\n\t\tcompat = 0;\n\t\tincompat = JBD2_FEATURE_INCOMPAT_CSUM_V3;\n\t} else {\n\t\t/* journal checksum v1 */\n\t\tcompat = JBD2_FEATURE_COMPAT_CHECKSUM;\n\t\tincompat = 0;\n\t}\n\n\tjbd2_journal_clear_features(sbi->s_journal,\n\t\t\tJBD2_FEATURE_COMPAT_CHECKSUM, 0,\n\t\t\tJBD2_FEATURE_INCOMPAT_CSUM_V3 |\n\t\t\tJBD2_FEATURE_INCOMPAT_CSUM_V2);\n\tif (test_opt(sb, JOURNAL_ASYNC_COMMIT)) {\n\t\tret = jbd2_journal_set_features(sbi->s_journal,\n\t\t\t\tcompat, 0,\n\t\t\t\tJBD2_FEATURE_INCOMPAT_ASYNC_COMMIT |\n\t\t\t\tincompat);\n\t} else if (test_opt(sb, JOURNAL_CHECKSUM)) {\n\t\tret = jbd2_journal_set_features(sbi->s_journal,\n\t\t\t\tcompat, 0,\n\t\t\t\tincompat);\n\t\tjbd2_journal_clear_features(sbi->s_journal, 0, 0,\n\t\t\t\tJBD2_FEATURE_INCOMPAT_ASYNC_COMMIT);\n\t} else {\n\t\tjbd2_journal_clear_features(sbi->s_journal, 0, 0,\n\t\t\t\tJBD2_FEATURE_INCOMPAT_ASYNC_COMMIT);\n\t}\n\n\treturn ret;\n}\n\n/*\n * Note: calculating the overhead so we can be compatible with\n * historical BSD practice is quite difficult in the face of\n * clusters/bigalloc.  This is because multiple metadata blocks from\n * different block group can end up in the same allocation cluster.\n * Calculating the exact overhead in the face of clustered allocation\n * requires either O(all block bitmaps) in memory or O(number of block\n * groups**2) in time.  We will still calculate the superblock for\n * older file systems --- and if we come across with a bigalloc file\n * system with zero in s_overhead_clusters the estimate will be close to\n * correct especially for very large cluster sizes --- but for newer\n * file systems, it's better to calculate this figure once at mkfs\n * time, and store it in the superblock.  If the superblock value is\n * present (even for non-bigalloc file systems), we will use it.\n */\nstatic int count_overhead(struct super_block *sb, ext4_group_t grp,\n\t\t\t  char *buf)\n{\n\tstruct ext4_sb_info\t*sbi = EXT4_SB(sb);\n\tstruct ext4_group_desc\t*gdp;\n\text4_fsblk_t\t\tfirst_block, last_block, b;\n\text4_group_t\t\ti, ngroups = ext4_get_groups_count(sb);\n\tint\t\t\ts, j, count = 0;\n\n\tif (!ext4_has_feature_bigalloc(sb))\n\t\treturn (ext4_bg_has_super(sb, grp) + ext4_bg_num_gdb(sb, grp) +\n\t\t\tsbi->s_itb_per_group + 2);\n\n\tfirst_block = le32_to_cpu(sbi->s_es->s_first_data_block) +\n\t\t(grp * EXT4_BLOCKS_PER_GROUP(sb));\n\tlast_block = first_block + EXT4_BLOCKS_PER_GROUP(sb) - 1;\n\tfor (i = 0; i < ngroups; i++) {\n\t\tgdp = ext4_get_group_desc(sb, i, NULL);\n\t\tb = ext4_block_bitmap(sb, gdp);\n\t\tif (b >= first_block && b <= last_block) {\n\t\t\text4_set_bit(EXT4_B2C(sbi, b - first_block), buf);\n\t\t\tcount++;\n\t\t}\n\t\tb = ext4_inode_bitmap(sb, gdp);\n\t\tif (b >= first_block && b <= last_block) {\n\t\t\text4_set_bit(EXT4_B2C(sbi, b - first_block), buf);\n\t\t\tcount++;\n\t\t}\n\t\tb = ext4_inode_table(sb, gdp);\n\t\tif (b >= first_block && b + sbi->s_itb_per_group <= last_block)\n\t\t\tfor (j = 0; j < sbi->s_itb_per_group; j++, b++) {\n\t\t\t\tint c = EXT4_B2C(sbi, b - first_block);\n\t\t\t\text4_set_bit(c, buf);\n\t\t\t\tcount++;\n\t\t\t}\n\t\tif (i != grp)\n\t\t\tcontinue;\n\t\ts = 0;\n\t\tif (ext4_bg_has_super(sb, grp)) {\n\t\t\text4_set_bit(s++, buf);\n\t\t\tcount++;\n\t\t}\n\t\tj = ext4_bg_num_gdb(sb, grp);\n\t\tif (s + j > EXT4_BLOCKS_PER_GROUP(sb)) {\n\t\t\text4_error(sb, \"Invalid number of block group \"\n\t\t\t\t   \"descriptor blocks: %d\", j);\n\t\t\tj = EXT4_BLOCKS_PER_GROUP(sb) - s;\n\t\t}\n\t\tcount += j;\n\t\tfor (; j > 0; j--)\n\t\t\text4_set_bit(EXT4_B2C(sbi, s++), buf);\n\t}\n\tif (!count)\n\t\treturn 0;\n\treturn EXT4_CLUSTERS_PER_GROUP(sb) -\n\t\text4_count_free(buf, EXT4_CLUSTERS_PER_GROUP(sb) / 8);\n}\n\n/*\n * Compute the overhead and stash it in sbi->s_overhead\n */\nint ext4_calculate_overhead(struct super_block *sb)\n{\n\tstruct ext4_sb_info *sbi = EXT4_SB(sb);\n\tstruct ext4_super_block *es = sbi->s_es;\n\tstruct inode *j_inode;\n\tunsigned int j_blocks, j_inum = le32_to_cpu(es->s_journal_inum);\n\text4_group_t i, ngroups = ext4_get_groups_count(sb);\n\text4_fsblk_t overhead = 0;\n\tchar *buf = (char *) get_zeroed_page(GFP_NOFS);\n\n\tif (!buf)\n\t\treturn -ENOMEM;\n\n\t/*\n\t * Compute the overhead (FS structures).  This is constant\n\t * for a given filesystem unless the number of block groups\n\t * changes so we cache the previous value until it does.\n\t */\n\n\t/*\n\t * All of the blocks before first_data_block are overhead\n\t */\n\toverhead = EXT4_B2C(sbi, le32_to_cpu(es->s_first_data_block));\n\n\t/*\n\t * Add the overhead found in each block group\n\t */\n\tfor (i = 0; i < ngroups; i++) {\n\t\tint blks;\n\n\t\tblks = count_overhead(sb, i, buf);\n\t\toverhead += blks;\n\t\tif (blks)\n\t\t\tmemset(buf, 0, PAGE_SIZE);\n\t\tcond_resched();\n\t}\n\n\t/*\n\t * Add the internal journal blocks whether the journal has been\n\t * loaded or not\n\t */\n\tif (sbi->s_journal && !sbi->journal_bdev)\n\t\toverhead += EXT4_NUM_B2C(sbi, sbi->s_journal->j_maxlen);\n\telse if (ext4_has_feature_journal(sb) && !sbi->s_journal) {\n\t\tj_inode = ext4_get_journal_inode(sb, j_inum);\n\t\tif (j_inode) {\n\t\t\tj_blocks = j_inode->i_size >> sb->s_blocksize_bits;\n\t\t\toverhead += EXT4_NUM_B2C(sbi, j_blocks);\n\t\t\tiput(j_inode);\n\t\t} else {\n\t\t\text4_msg(sb, KERN_ERR, \"can't get journal size\");\n\t\t}\n\t}\n\tsbi->s_overhead = overhead;\n\tsmp_wmb();\n\tfree_page((unsigned long) buf);\n\treturn 0;\n}\n\nstatic void ext4_set_resv_clusters(struct super_block *sb)\n{\n\text4_fsblk_t resv_clusters;\n\tstruct ext4_sb_info *sbi = EXT4_SB(sb);\n\n\t/*\n\t * There's no need to reserve anything when we aren't using extents.\n\t * The space estimates are exact, there are no unwritten extents,\n\t * hole punching doesn't need new metadata... This is needed especially\n\t * to keep ext2/3 backward compatibility.\n\t */\n\tif (!ext4_has_feature_extents(sb))\n\t\treturn;\n\t/*\n\t * By default we reserve 2% or 4096 clusters, whichever is smaller.\n\t * This should cover the situations where we can not afford to run\n\t * out of space like for example punch hole, or converting\n\t * unwritten extents in delalloc path. In most cases such\n\t * allocation would require 1, or 2 blocks, higher numbers are\n\t * very rare.\n\t */\n\tresv_clusters = (ext4_blocks_count(sbi->s_es) >>\n\t\t\t sbi->s_cluster_bits);\n\n\tdo_div(resv_clusters, 50);\n\tresv_clusters = min_t(ext4_fsblk_t, resv_clusters, 4096);\n\n\tatomic64_set(&sbi->s_resv_clusters, resv_clusters);\n}\n\nstatic int ext4_fill_super(struct super_block *sb, void *data, int silent)\n{\n\tchar *orig_data = kstrdup(data, GFP_KERNEL);\n\tstruct buffer_head *bh;\n\tstruct ext4_super_block *es = NULL;\n\tstruct ext4_sb_info *sbi = kzalloc(sizeof(*sbi), GFP_KERNEL);\n\text4_fsblk_t block;\n\text4_fsblk_t sb_block = get_sb_block(&data);\n\text4_fsblk_t logical_sb_block;\n\tunsigned long offset = 0;\n\tunsigned long journal_devnum = 0;\n\tunsigned long def_mount_opts;\n\tstruct inode *root;\n\tconst char *descr;\n\tint ret = -ENOMEM;\n\tint blocksize, clustersize;\n\tunsigned int db_count;\n\tunsigned int i;\n\tint needs_recovery, has_huge_files, has_bigalloc;\n\t__u64 blocks_count;\n\tint err = 0;\n\tunsigned int journal_ioprio = DEFAULT_JOURNAL_IOPRIO;\n\text4_group_t first_not_zeroed;\n\n\tif ((data && !orig_data) || !sbi)\n\t\tgoto out_free_base;\n\n\tsbi->s_blockgroup_lock =\n\t\tkzalloc(sizeof(struct blockgroup_lock), GFP_KERNEL);\n\tif (!sbi->s_blockgroup_lock)\n\t\tgoto out_free_base;\n\n\tsb->s_fs_info = sbi;\n\tsbi->s_sb = sb;\n\tsbi->s_inode_readahead_blks = EXT4_DEF_INODE_READAHEAD_BLKS;\n\tsbi->s_sb_block = sb_block;\n\tif (sb->s_bdev->bd_part)\n\t\tsbi->s_sectors_written_start =\n\t\t\tpart_stat_read(sb->s_bdev->bd_part, sectors[1]);\n\n\t/* Cleanup superblock name */\n\tstrreplace(sb->s_id, '/', '!');\n\n\t/* -EINVAL is default */\n\tret = -EINVAL;\n\tblocksize = sb_min_blocksize(sb, EXT4_MIN_BLOCK_SIZE);\n\tif (!blocksize) {\n\t\text4_msg(sb, KERN_ERR, \"unable to set blocksize\");\n\t\tgoto out_fail;\n\t}\n\n\t/*\n\t * The ext4 superblock will not be buffer aligned for other than 1kB\n\t * block sizes.  We need to calculate the offset from buffer start.\n\t */\n\tif (blocksize != EXT4_MIN_BLOCK_SIZE) {\n\t\tlogical_sb_block = sb_block * EXT4_MIN_BLOCK_SIZE;\n\t\toffset = do_div(logical_sb_block, blocksize);\n\t} else {\n\t\tlogical_sb_block = sb_block;\n\t}\n\n\tif (!(bh = sb_bread_unmovable(sb, logical_sb_block))) {\n\t\text4_msg(sb, KERN_ERR, \"unable to read superblock\");\n\t\tgoto out_fail;\n\t}\n\t/*\n\t * Note: s_es must be initialized as soon as possible because\n\t *       some ext4 macro-instructions depend on its value\n\t */\n\tes = (struct ext4_super_block *) (bh->b_data + offset);\n\tsbi->s_es = es;\n\tsb->s_magic = le16_to_cpu(es->s_magic);\n\tif (sb->s_magic != EXT4_SUPER_MAGIC)\n\t\tgoto cantfind_ext4;\n\tsbi->s_kbytes_written = le64_to_cpu(es->s_kbytes_written);\n\n\t/* Warn if metadata_csum and gdt_csum are both set. */\n\tif (ext4_has_feature_metadata_csum(sb) &&\n\t    ext4_has_feature_gdt_csum(sb))\n\t\text4_warning(sb, \"metadata_csum and uninit_bg are \"\n\t\t\t     \"redundant flags; please run fsck.\");\n\n\t/* Check for a known checksum algorithm */\n\tif (!ext4_verify_csum_type(sb, es)) {\n\t\text4_msg(sb, KERN_ERR, \"VFS: Found ext4 filesystem with \"\n\t\t\t \"unknown checksum algorithm.\");\n\t\tsilent = 1;\n\t\tgoto cantfind_ext4;\n\t}\n\n\t/* Load the checksum driver */\n\tif (ext4_has_feature_metadata_csum(sb)) {\n\t\tsbi->s_chksum_driver = crypto_alloc_shash(\"crc32c\", 0, 0);\n\t\tif (IS_ERR(sbi->s_chksum_driver)) {\n\t\t\text4_msg(sb, KERN_ERR, \"Cannot load crc32c driver.\");\n\t\t\tret = PTR_ERR(sbi->s_chksum_driver);\n\t\t\tsbi->s_chksum_driver = NULL;\n\t\t\tgoto failed_mount;\n\t\t}\n\t}\n\n\t/* Check superblock checksum */\n\tif (!ext4_superblock_csum_verify(sb, es)) {\n\t\text4_msg(sb, KERN_ERR, \"VFS: Found ext4 filesystem with \"\n\t\t\t \"invalid superblock checksum.  Run e2fsck?\");\n\t\tsilent = 1;\n\t\tret = -EFSBADCRC;\n\t\tgoto cantfind_ext4;\n\t}\n\n\t/* Precompute checksum seed for all metadata */\n\tif (ext4_has_feature_csum_seed(sb))\n\t\tsbi->s_csum_seed = le32_to_cpu(es->s_checksum_seed);\n\telse if (ext4_has_metadata_csum(sb))\n\t\tsbi->s_csum_seed = ext4_chksum(sbi, ~0, es->s_uuid,\n\t\t\t\t\t       sizeof(es->s_uuid));\n\n\t/* Set defaults before we parse the mount options */\n\tdef_mount_opts = le32_to_cpu(es->s_default_mount_opts);\n\tset_opt(sb, INIT_INODE_TABLE);\n\tif (def_mount_opts & EXT4_DEFM_DEBUG)\n\t\tset_opt(sb, DEBUG);\n\tif (def_mount_opts & EXT4_DEFM_BSDGROUPS)\n\t\tset_opt(sb, GRPID);\n\tif (def_mount_opts & EXT4_DEFM_UID16)\n\t\tset_opt(sb, NO_UID32);\n\t/* xattr user namespace & acls are now defaulted on */\n\tset_opt(sb, XATTR_USER);\n#ifdef CONFIG_EXT4_FS_POSIX_ACL\n\tset_opt(sb, POSIX_ACL);\n#endif\n\t/* don't forget to enable journal_csum when metadata_csum is enabled. */\n\tif (ext4_has_metadata_csum(sb))\n\t\tset_opt(sb, JOURNAL_CHECKSUM);\n\n\tif ((def_mount_opts & EXT4_DEFM_JMODE) == EXT4_DEFM_JMODE_DATA)\n\t\tset_opt(sb, JOURNAL_DATA);\n\telse if ((def_mount_opts & EXT4_DEFM_JMODE) == EXT4_DEFM_JMODE_ORDERED)\n\t\tset_opt(sb, ORDERED_DATA);\n\telse if ((def_mount_opts & EXT4_DEFM_JMODE) == EXT4_DEFM_JMODE_WBACK)\n\t\tset_opt(sb, WRITEBACK_DATA);\n\n\tif (le16_to_cpu(sbi->s_es->s_errors) == EXT4_ERRORS_PANIC)\n\t\tset_opt(sb, ERRORS_PANIC);\n\telse if (le16_to_cpu(sbi->s_es->s_errors) == EXT4_ERRORS_CONTINUE)\n\t\tset_opt(sb, ERRORS_CONT);\n\telse\n\t\tset_opt(sb, ERRORS_RO);\n\t/* block_validity enabled by default; disable with noblock_validity */\n\tset_opt(sb, BLOCK_VALIDITY);\n\tif (def_mount_opts & EXT4_DEFM_DISCARD)\n\t\tset_opt(sb, DISCARD);\n\n\tsbi->s_resuid = make_kuid(&init_user_ns, le16_to_cpu(es->s_def_resuid));\n\tsbi->s_resgid = make_kgid(&init_user_ns, le16_to_cpu(es->s_def_resgid));\n\tsbi->s_commit_interval = JBD2_DEFAULT_MAX_COMMIT_AGE * HZ;\n\tsbi->s_min_batch_time = EXT4_DEF_MIN_BATCH_TIME;\n\tsbi->s_max_batch_time = EXT4_DEF_MAX_BATCH_TIME;\n\n\tif ((def_mount_opts & EXT4_DEFM_NOBARRIER) == 0)\n\t\tset_opt(sb, BARRIER);\n\n\t/*\n\t * enable delayed allocation by default\n\t * Use -o nodelalloc to turn it off\n\t */\n\tif (!IS_EXT3_SB(sb) && !IS_EXT2_SB(sb) &&\n\t    ((def_mount_opts & EXT4_DEFM_NODELALLOC) == 0))\n\t\tset_opt(sb, DELALLOC);\n\n\t/*\n\t * set default s_li_wait_mult for lazyinit, for the case there is\n\t * no mount option specified.\n\t */\n\tsbi->s_li_wait_mult = EXT4_DEF_LI_WAIT_MULT;\n\n\tif (sbi->s_es->s_mount_opts[0]) {\n\t\tchar *s_mount_opts = kstrndup(sbi->s_es->s_mount_opts,\n\t\t\t\t\t      sizeof(sbi->s_es->s_mount_opts),\n\t\t\t\t\t      GFP_KERNEL);\n\t\tif (!s_mount_opts)\n\t\t\tgoto failed_mount;\n\t\tif (!parse_options(s_mount_opts, sb, &journal_devnum,\n\t\t\t\t   &journal_ioprio, 0)) {\n\t\t\text4_msg(sb, KERN_WARNING,\n\t\t\t\t \"failed to parse options in superblock: %s\",\n\t\t\t\t s_mount_opts);\n\t\t}\n\t\tkfree(s_mount_opts);\n\t}\n\tsbi->s_def_mount_opt = sbi->s_mount_opt;\n\tif (!parse_options((char *) data, sb, &journal_devnum,\n\t\t\t   &journal_ioprio, 0))\n\t\tgoto failed_mount;\n\n\tif (test_opt(sb, DATA_FLAGS) == EXT4_MOUNT_JOURNAL_DATA) {\n\t\tprintk_once(KERN_WARNING \"EXT4-fs: Warning: mounting \"\n\t\t\t    \"with data=journal disables delayed \"\n\t\t\t    \"allocation and O_DIRECT support!\\n\");\n\t\tif (test_opt2(sb, EXPLICIT_DELALLOC)) {\n\t\t\text4_msg(sb, KERN_ERR, \"can't mount with \"\n\t\t\t\t \"both data=journal and delalloc\");\n\t\t\tgoto failed_mount;\n\t\t}\n\t\tif (test_opt(sb, DIOREAD_NOLOCK)) {\n\t\t\text4_msg(sb, KERN_ERR, \"can't mount with \"\n\t\t\t\t \"both data=journal and dioread_nolock\");\n\t\t\tgoto failed_mount;\n\t\t}\n\t\tif (test_opt(sb, DAX)) {\n\t\t\text4_msg(sb, KERN_ERR, \"can't mount with \"\n\t\t\t\t \"both data=journal and dax\");\n\t\t\tgoto failed_mount;\n\t\t}\n\t\tif (test_opt(sb, DELALLOC))\n\t\t\tclear_opt(sb, DELALLOC);\n\t} else {\n\t\tsb->s_iflags |= SB_I_CGROUPWB;\n\t}\n\n\tsb->s_flags = (sb->s_flags & ~MS_POSIXACL) |\n\t\t(test_opt(sb, POSIX_ACL) ? MS_POSIXACL : 0);\n\n\tif (le32_to_cpu(es->s_rev_level) == EXT4_GOOD_OLD_REV &&\n\t    (ext4_has_compat_features(sb) ||\n\t     ext4_has_ro_compat_features(sb) ||\n\t     ext4_has_incompat_features(sb)))\n\t\text4_msg(sb, KERN_WARNING,\n\t\t       \"feature flags set on rev 0 fs, \"\n\t\t       \"running e2fsck is recommended\");\n\n\tif (es->s_creator_os == cpu_to_le32(EXT4_OS_HURD)) {\n\t\tset_opt2(sb, HURD_COMPAT);\n\t\tif (ext4_has_feature_64bit(sb)) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t\t \"The Hurd can't support 64-bit file systems\");\n\t\t\tgoto failed_mount;\n\t\t}\n\t}\n\n\tif (IS_EXT2_SB(sb)) {\n\t\tif (ext2_feature_set_ok(sb))\n\t\t\text4_msg(sb, KERN_INFO, \"mounting ext2 file system \"\n\t\t\t\t \"using the ext4 subsystem\");\n\t\telse {\n\t\t\text4_msg(sb, KERN_ERR, \"couldn't mount as ext2 due \"\n\t\t\t\t \"to feature incompatibilities\");\n\t\t\tgoto failed_mount;\n\t\t}\n\t}\n\n\tif (IS_EXT3_SB(sb)) {\n\t\tif (ext3_feature_set_ok(sb))\n\t\t\text4_msg(sb, KERN_INFO, \"mounting ext3 file system \"\n\t\t\t\t \"using the ext4 subsystem\");\n\t\telse {\n\t\t\text4_msg(sb, KERN_ERR, \"couldn't mount as ext3 due \"\n\t\t\t\t \"to feature incompatibilities\");\n\t\t\tgoto failed_mount;\n\t\t}\n\t}\n\n\t/*\n\t * Check feature flags regardless of the revision level, since we\n\t * previously didn't change the revision level when setting the flags,\n\t * so there is a chance incompat flags are set on a rev 0 filesystem.\n\t */\n\tif (!ext4_feature_set_ok(sb, (sb->s_flags & MS_RDONLY)))\n\t\tgoto failed_mount;\n\n\tblocksize = BLOCK_SIZE << le32_to_cpu(es->s_log_block_size);\n\tif (blocksize < EXT4_MIN_BLOCK_SIZE ||\n\t    blocksize > EXT4_MAX_BLOCK_SIZE) {\n\t\text4_msg(sb, KERN_ERR,\n\t\t       \"Unsupported filesystem blocksize %d (%d log_block_size)\",\n\t\t\t blocksize, le32_to_cpu(es->s_log_block_size));\n\t\tgoto failed_mount;\n\t}\n\tif (le32_to_cpu(es->s_log_block_size) >\n\t    (EXT4_MAX_BLOCK_LOG_SIZE - EXT4_MIN_BLOCK_LOG_SIZE)) {\n\t\text4_msg(sb, KERN_ERR,\n\t\t\t \"Invalid log block size: %u\",\n\t\t\t le32_to_cpu(es->s_log_block_size));\n\t\tgoto failed_mount;\n\t}\n\n\tif (le16_to_cpu(sbi->s_es->s_reserved_gdt_blocks) > (blocksize / 4)) {\n\t\text4_msg(sb, KERN_ERR,\n\t\t\t \"Number of reserved GDT blocks insanely large: %d\",\n\t\t\t le16_to_cpu(sbi->s_es->s_reserved_gdt_blocks));\n\t\tgoto failed_mount;\n\t}\n\n\tif (sbi->s_mount_opt & EXT4_MOUNT_DAX) {\n\t\terr = bdev_dax_supported(sb, blocksize);\n\t\tif (err)\n\t\t\tgoto failed_mount;\n\t}\n\n\tif (ext4_has_feature_encrypt(sb) && es->s_encryption_level) {\n\t\text4_msg(sb, KERN_ERR, \"Unsupported encryption level %d\",\n\t\t\t es->s_encryption_level);\n\t\tgoto failed_mount;\n\t}\n\n\tif (sb->s_blocksize != blocksize) {\n\t\t/* Validate the filesystem blocksize */\n\t\tif (!sb_set_blocksize(sb, blocksize)) {\n\t\t\text4_msg(sb, KERN_ERR, \"bad block size %d\",\n\t\t\t\t\tblocksize);\n\t\t\tgoto failed_mount;\n\t\t}\n\n\t\tbrelse(bh);\n\t\tlogical_sb_block = sb_block * EXT4_MIN_BLOCK_SIZE;\n\t\toffset = do_div(logical_sb_block, blocksize);\n\t\tbh = sb_bread_unmovable(sb, logical_sb_block);\n\t\tif (!bh) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t       \"Can't read superblock on 2nd try\");\n\t\t\tgoto failed_mount;\n\t\t}\n\t\tes = (struct ext4_super_block *)(bh->b_data + offset);\n\t\tsbi->s_es = es;\n\t\tif (es->s_magic != cpu_to_le16(EXT4_SUPER_MAGIC)) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t       \"Magic mismatch, very weird!\");\n\t\t\tgoto failed_mount;\n\t\t}\n\t}\n\n\thas_huge_files = ext4_has_feature_huge_file(sb);\n\tsbi->s_bitmap_maxbytes = ext4_max_bitmap_size(sb->s_blocksize_bits,\n\t\t\t\t\t\t      has_huge_files);\n\tsb->s_maxbytes = ext4_max_size(sb->s_blocksize_bits, has_huge_files);\n\n\tif (le32_to_cpu(es->s_rev_level) == EXT4_GOOD_OLD_REV) {\n\t\tsbi->s_inode_size = EXT4_GOOD_OLD_INODE_SIZE;\n\t\tsbi->s_first_ino = EXT4_GOOD_OLD_FIRST_INO;\n\t} else {\n\t\tsbi->s_inode_size = le16_to_cpu(es->s_inode_size);\n\t\tsbi->s_first_ino = le32_to_cpu(es->s_first_ino);\n\t\tif ((sbi->s_inode_size < EXT4_GOOD_OLD_INODE_SIZE) ||\n\t\t    (!is_power_of_2(sbi->s_inode_size)) ||\n\t\t    (sbi->s_inode_size > blocksize)) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t       \"unsupported inode size: %d\",\n\t\t\t       sbi->s_inode_size);\n\t\t\tgoto failed_mount;\n\t\t}\n\t\tif (sbi->s_inode_size > EXT4_GOOD_OLD_INODE_SIZE)\n\t\t\tsb->s_time_gran = 1 << (EXT4_EPOCH_BITS - 2);\n\t}\n\n\tsbi->s_desc_size = le16_to_cpu(es->s_desc_size);\n\tif (ext4_has_feature_64bit(sb)) {\n\t\tif (sbi->s_desc_size < EXT4_MIN_DESC_SIZE_64BIT ||\n\t\t    sbi->s_desc_size > EXT4_MAX_DESC_SIZE ||\n\t\t    !is_power_of_2(sbi->s_desc_size)) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t       \"unsupported descriptor size %lu\",\n\t\t\t       sbi->s_desc_size);\n\t\t\tgoto failed_mount;\n\t\t}\n\t} else\n\t\tsbi->s_desc_size = EXT4_MIN_DESC_SIZE;\n\n\tsbi->s_blocks_per_group = le32_to_cpu(es->s_blocks_per_group);\n\tsbi->s_inodes_per_group = le32_to_cpu(es->s_inodes_per_group);\n\n\tsbi->s_inodes_per_block = blocksize / EXT4_INODE_SIZE(sb);\n\tif (sbi->s_inodes_per_block == 0)\n\t\tgoto cantfind_ext4;\n\tif (sbi->s_inodes_per_group < sbi->s_inodes_per_block ||\n\t    sbi->s_inodes_per_group > blocksize * 8) {\n\t\text4_msg(sb, KERN_ERR, \"invalid inodes per group: %lu\\n\",\n\t\t\t sbi->s_blocks_per_group);\n\t\tgoto failed_mount;\n\t}\n\tsbi->s_itb_per_group = sbi->s_inodes_per_group /\n\t\t\t\t\tsbi->s_inodes_per_block;\n\tsbi->s_desc_per_block = blocksize / EXT4_DESC_SIZE(sb);\n\tsbi->s_sbh = bh;\n\tsbi->s_mount_state = le16_to_cpu(es->s_state);\n\tsbi->s_addr_per_block_bits = ilog2(EXT4_ADDR_PER_BLOCK(sb));\n\tsbi->s_desc_per_block_bits = ilog2(EXT4_DESC_PER_BLOCK(sb));\n\n\tfor (i = 0; i < 4; i++)\n\t\tsbi->s_hash_seed[i] = le32_to_cpu(es->s_hash_seed[i]);\n\tsbi->s_def_hash_version = es->s_def_hash_version;\n\tif (ext4_has_feature_dir_index(sb)) {\n\t\ti = le32_to_cpu(es->s_flags);\n\t\tif (i & EXT2_FLAGS_UNSIGNED_HASH)\n\t\t\tsbi->s_hash_unsigned = 3;\n\t\telse if ((i & EXT2_FLAGS_SIGNED_HASH) == 0) {\n#ifdef __CHAR_UNSIGNED__\n\t\t\tif (!(sb->s_flags & MS_RDONLY))\n\t\t\t\tes->s_flags |=\n\t\t\t\t\tcpu_to_le32(EXT2_FLAGS_UNSIGNED_HASH);\n\t\t\tsbi->s_hash_unsigned = 3;\n#else\n\t\t\tif (!(sb->s_flags & MS_RDONLY))\n\t\t\t\tes->s_flags |=\n\t\t\t\t\tcpu_to_le32(EXT2_FLAGS_SIGNED_HASH);\n#endif\n\t\t}\n\t}\n\n\t/* Handle clustersize */\n\tclustersize = BLOCK_SIZE << le32_to_cpu(es->s_log_cluster_size);\n\thas_bigalloc = ext4_has_feature_bigalloc(sb);\n\tif (has_bigalloc) {\n\t\tif (clustersize < blocksize) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t\t \"cluster size (%d) smaller than \"\n\t\t\t\t \"block size (%d)\", clustersize, blocksize);\n\t\t\tgoto failed_mount;\n\t\t}\n\t\tif (le32_to_cpu(es->s_log_cluster_size) >\n\t\t    (EXT4_MAX_CLUSTER_LOG_SIZE - EXT4_MIN_BLOCK_LOG_SIZE)) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t\t \"Invalid log cluster size: %u\",\n\t\t\t\t le32_to_cpu(es->s_log_cluster_size));\n\t\t\tgoto failed_mount;\n\t\t}\n\t\tsbi->s_cluster_bits = le32_to_cpu(es->s_log_cluster_size) -\n\t\t\tle32_to_cpu(es->s_log_block_size);\n\t\tsbi->s_clusters_per_group =\n\t\t\tle32_to_cpu(es->s_clusters_per_group);\n\t\tif (sbi->s_clusters_per_group > blocksize * 8) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t\t \"#clusters per group too big: %lu\",\n\t\t\t\t sbi->s_clusters_per_group);\n\t\t\tgoto failed_mount;\n\t\t}\n\t\tif (sbi->s_blocks_per_group !=\n\t\t    (sbi->s_clusters_per_group * (clustersize / blocksize))) {\n\t\t\text4_msg(sb, KERN_ERR, \"blocks per group (%lu) and \"\n\t\t\t\t \"clusters per group (%lu) inconsistent\",\n\t\t\t\t sbi->s_blocks_per_group,\n\t\t\t\t sbi->s_clusters_per_group);\n\t\t\tgoto failed_mount;\n\t\t}\n\t} else {\n\t\tif (clustersize != blocksize) {\n\t\t\text4_warning(sb, \"fragment/cluster size (%d) != \"\n\t\t\t\t     \"block size (%d)\", clustersize,\n\t\t\t\t     blocksize);\n\t\t\tclustersize = blocksize;\n\t\t}\n\t\tif (sbi->s_blocks_per_group > blocksize * 8) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t\t \"#blocks per group too big: %lu\",\n\t\t\t\t sbi->s_blocks_per_group);\n\t\t\tgoto failed_mount;\n\t\t}\n\t\tsbi->s_clusters_per_group = sbi->s_blocks_per_group;\n\t\tsbi->s_cluster_bits = 0;\n\t}\n\tsbi->s_cluster_ratio = clustersize / blocksize;\n\n\t/* Do we have standard group size of clustersize * 8 blocks ? */\n\tif (sbi->s_blocks_per_group == clustersize << 3)\n\t\tset_opt2(sb, STD_GROUP_SIZE);\n\n\t/*\n\t * Test whether we have more sectors than will fit in sector_t,\n\t * and whether the max offset is addressable by the page cache.\n\t */\n\terr = generic_check_addressable(sb->s_blocksize_bits,\n\t\t\t\t\text4_blocks_count(es));\n\tif (err) {\n\t\text4_msg(sb, KERN_ERR, \"filesystem\"\n\t\t\t \" too large to mount safely on this system\");\n\t\tif (sizeof(sector_t) < 8)\n\t\t\text4_msg(sb, KERN_WARNING, \"CONFIG_LBDAF not enabled\");\n\t\tgoto failed_mount;\n\t}\n\n\tif (EXT4_BLOCKS_PER_GROUP(sb) == 0)\n\t\tgoto cantfind_ext4;\n\n\t/* check blocks count against device size */\n\tblocks_count = sb->s_bdev->bd_inode->i_size >> sb->s_blocksize_bits;\n\tif (blocks_count && ext4_blocks_count(es) > blocks_count) {\n\t\text4_msg(sb, KERN_WARNING, \"bad geometry: block count %llu \"\n\t\t       \"exceeds size of device (%llu blocks)\",\n\t\t       ext4_blocks_count(es), blocks_count);\n\t\tgoto failed_mount;\n\t}\n\n\t/*\n\t * It makes no sense for the first data block to be beyond the end\n\t * of the filesystem.\n\t */\n\tif (le32_to_cpu(es->s_first_data_block) >= ext4_blocks_count(es)) {\n\t\text4_msg(sb, KERN_WARNING, \"bad geometry: first data \"\n\t\t\t \"block %u is beyond end of filesystem (%llu)\",\n\t\t\t le32_to_cpu(es->s_first_data_block),\n\t\t\t ext4_blocks_count(es));\n\t\tgoto failed_mount;\n\t}\n\tblocks_count = (ext4_blocks_count(es) -\n\t\t\tle32_to_cpu(es->s_first_data_block) +\n\t\t\tEXT4_BLOCKS_PER_GROUP(sb) - 1);\n\tdo_div(blocks_count, EXT4_BLOCKS_PER_GROUP(sb));\n\tif (blocks_count > ((uint64_t)1<<32) - EXT4_DESC_PER_BLOCK(sb)) {\n\t\text4_msg(sb, KERN_WARNING, \"groups count too large: %u \"\n\t\t       \"(block count %llu, first data block %u, \"\n\t\t       \"blocks per group %lu)\", sbi->s_groups_count,\n\t\t       ext4_blocks_count(es),\n\t\t       le32_to_cpu(es->s_first_data_block),\n\t\t       EXT4_BLOCKS_PER_GROUP(sb));\n\t\tgoto failed_mount;\n\t}\n\tsbi->s_groups_count = blocks_count;\n\tsbi->s_blockfile_groups = min_t(ext4_group_t, sbi->s_groups_count,\n\t\t\t(EXT4_MAX_BLOCK_FILE_PHYS / EXT4_BLOCKS_PER_GROUP(sb)));\n\tdb_count = (sbi->s_groups_count + EXT4_DESC_PER_BLOCK(sb) - 1) /\n\t\t   EXT4_DESC_PER_BLOCK(sb);\n\tsbi->s_group_desc = ext4_kvmalloc(db_count *\n\t\t\t\t\t  sizeof(struct buffer_head *),\n\t\t\t\t\t  GFP_KERNEL);\n\tif (sbi->s_group_desc == NULL) {\n\t\text4_msg(sb, KERN_ERR, \"not enough memory\");\n\t\tret = -ENOMEM;\n\t\tgoto failed_mount;\n\t}\n\n\tbgl_lock_init(sbi->s_blockgroup_lock);\n\n\tfor (i = 0; i < db_count; i++) {\n\t\tblock = descriptor_loc(sb, logical_sb_block, i);\n\t\tsbi->s_group_desc[i] = sb_bread_unmovable(sb, block);\n\t\tif (!sbi->s_group_desc[i]) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t       \"can't read group descriptor %d\", i);\n\t\t\tdb_count = i;\n\t\t\tgoto failed_mount2;\n\t\t}\n\t}\n\tif (!ext4_check_descriptors(sb, logical_sb_block, &first_not_zeroed)) {\n\t\text4_msg(sb, KERN_ERR, \"group descriptors corrupted!\");\n\t\tret = -EFSCORRUPTED;\n\t\tgoto failed_mount2;\n\t}\n\n\tsbi->s_gdb_count = db_count;\n\tget_random_bytes(&sbi->s_next_generation, sizeof(u32));\n\tspin_lock_init(&sbi->s_next_gen_lock);\n\n\tsetup_timer(&sbi->s_err_report, print_daily_error_info,\n\t\t(unsigned long) sb);\n\n\t/* Register extent status tree shrinker */\n\tif (ext4_es_register_shrinker(sbi))\n\t\tgoto failed_mount3;\n\n\tsbi->s_stripe = ext4_get_stripe_size(sbi);\n\tsbi->s_extent_max_zeroout_kb = 32;\n\n\t/*\n\t * set up enough so that it can read an inode\n\t */\n\tsb->s_op = &ext4_sops;\n\tsb->s_export_op = &ext4_export_ops;\n\tsb->s_xattr = ext4_xattr_handlers;\n\tsb->s_cop = &ext4_cryptops;\n#ifdef CONFIG_QUOTA\n\tsb->dq_op = &ext4_quota_operations;\n\tif (ext4_has_feature_quota(sb))\n\t\tsb->s_qcop = &dquot_quotactl_sysfile_ops;\n\telse\n\t\tsb->s_qcop = &ext4_qctl_operations;\n\tsb->s_quota_types = QTYPE_MASK_USR | QTYPE_MASK_GRP | QTYPE_MASK_PRJ;\n#endif\n\tmemcpy(sb->s_uuid, es->s_uuid, sizeof(es->s_uuid));\n\n\tINIT_LIST_HEAD(&sbi->s_orphan); /* unlinked but open files */\n\tmutex_init(&sbi->s_orphan_lock);\n\n\tsb->s_root = NULL;\n\n\tneeds_recovery = (es->s_last_orphan != 0 ||\n\t\t\t  ext4_has_feature_journal_needs_recovery(sb));\n\n\tif (ext4_has_feature_mmp(sb) && !(sb->s_flags & MS_RDONLY))\n\t\tif (ext4_multi_mount_protect(sb, le64_to_cpu(es->s_mmp_block)))\n\t\t\tgoto failed_mount3a;\n\n\t/*\n\t * The first inode we look at is the journal inode.  Don't try\n\t * root first: it may be modified in the journal!\n\t */\n\tif (!test_opt(sb, NOLOAD) && ext4_has_feature_journal(sb)) {\n\t\tif (ext4_load_journal(sb, es, journal_devnum))\n\t\t\tgoto failed_mount3a;\n\t} else if (test_opt(sb, NOLOAD) && !(sb->s_flags & MS_RDONLY) &&\n\t\t   ext4_has_feature_journal_needs_recovery(sb)) {\n\t\text4_msg(sb, KERN_ERR, \"required journal recovery \"\n\t\t       \"suppressed and not mounted read-only\");\n\t\tgoto failed_mount_wq;\n\t} else {\n\t\t/* Nojournal mode, all journal mount options are illegal */\n\t\tif (test_opt2(sb, EXPLICIT_JOURNAL_CHECKSUM)) {\n\t\t\text4_msg(sb, KERN_ERR, \"can't mount with \"\n\t\t\t\t \"journal_checksum, fs mounted w/o journal\");\n\t\t\tgoto failed_mount_wq;\n\t\t}\n\t\tif (test_opt(sb, JOURNAL_ASYNC_COMMIT)) {\n\t\t\text4_msg(sb, KERN_ERR, \"can't mount with \"\n\t\t\t\t \"journal_async_commit, fs mounted w/o journal\");\n\t\t\tgoto failed_mount_wq;\n\t\t}\n\t\tif (sbi->s_commit_interval != JBD2_DEFAULT_MAX_COMMIT_AGE*HZ) {\n\t\t\text4_msg(sb, KERN_ERR, \"can't mount with \"\n\t\t\t\t \"commit=%lu, fs mounted w/o journal\",\n\t\t\t\t sbi->s_commit_interval / HZ);\n\t\t\tgoto failed_mount_wq;\n\t\t}\n\t\tif (EXT4_MOUNT_DATA_FLAGS &\n\t\t    (sbi->s_mount_opt ^ sbi->s_def_mount_opt)) {\n\t\t\text4_msg(sb, KERN_ERR, \"can't mount with \"\n\t\t\t\t \"data=, fs mounted w/o journal\");\n\t\t\tgoto failed_mount_wq;\n\t\t}\n\t\tsbi->s_def_mount_opt &= EXT4_MOUNT_JOURNAL_CHECKSUM;\n\t\tclear_opt(sb, JOURNAL_CHECKSUM);\n\t\tclear_opt(sb, DATA_FLAGS);\n\t\tsbi->s_journal = NULL;\n\t\tneeds_recovery = 0;\n\t\tgoto no_journal;\n\t}\n\n\tif (ext4_has_feature_64bit(sb) &&\n\t    !jbd2_journal_set_features(EXT4_SB(sb)->s_journal, 0, 0,\n\t\t\t\t       JBD2_FEATURE_INCOMPAT_64BIT)) {\n\t\text4_msg(sb, KERN_ERR, \"Failed to set 64-bit journal feature\");\n\t\tgoto failed_mount_wq;\n\t}\n\n\tif (!set_journal_csum_feature_set(sb)) {\n\t\text4_msg(sb, KERN_ERR, \"Failed to set journal checksum \"\n\t\t\t \"feature set\");\n\t\tgoto failed_mount_wq;\n\t}\n\n\t/* We have now updated the journal if required, so we can\n\t * validate the data journaling mode. */\n\tswitch (test_opt(sb, DATA_FLAGS)) {\n\tcase 0:\n\t\t/* No mode set, assume a default based on the journal\n\t\t * capabilities: ORDERED_DATA if the journal can\n\t\t * cope, else JOURNAL_DATA\n\t\t */\n\t\tif (jbd2_journal_check_available_features\n\t\t    (sbi->s_journal, 0, 0, JBD2_FEATURE_INCOMPAT_REVOKE))\n\t\t\tset_opt(sb, ORDERED_DATA);\n\t\telse\n\t\t\tset_opt(sb, JOURNAL_DATA);\n\t\tbreak;\n\n\tcase EXT4_MOUNT_ORDERED_DATA:\n\tcase EXT4_MOUNT_WRITEBACK_DATA:\n\t\tif (!jbd2_journal_check_available_features\n\t\t    (sbi->s_journal, 0, 0, JBD2_FEATURE_INCOMPAT_REVOKE)) {\n\t\t\text4_msg(sb, KERN_ERR, \"Journal does not support \"\n\t\t\t       \"requested data journaling mode\");\n\t\t\tgoto failed_mount_wq;\n\t\t}\n\tdefault:\n\t\tbreak;\n\t}\n\tset_task_ioprio(sbi->s_journal->j_task, journal_ioprio);\n\n\tsbi->s_journal->j_commit_callback = ext4_journal_commit_callback;\n\nno_journal:\n\tsbi->s_mb_cache = ext4_xattr_create_cache();\n\tif (!sbi->s_mb_cache) {\n\t\text4_msg(sb, KERN_ERR, \"Failed to create an mb_cache\");\n\t\tgoto failed_mount_wq;\n\t}\n\n\tif ((DUMMY_ENCRYPTION_ENABLED(sbi) || ext4_has_feature_encrypt(sb)) &&\n\t    (blocksize != PAGE_SIZE)) {\n\t\text4_msg(sb, KERN_ERR,\n\t\t\t \"Unsupported blocksize for fs encryption\");\n\t\tgoto failed_mount_wq;\n\t}\n\n\tif (DUMMY_ENCRYPTION_ENABLED(sbi) && !(sb->s_flags & MS_RDONLY) &&\n\t    !ext4_has_feature_encrypt(sb)) {\n\t\text4_set_feature_encrypt(sb);\n\t\text4_commit_super(sb, 1);\n\t}\n\n\t/*\n\t * Get the # of file system overhead blocks from the\n\t * superblock if present.\n\t */\n\tif (es->s_overhead_clusters)\n\t\tsbi->s_overhead = le32_to_cpu(es->s_overhead_clusters);\n\telse {\n\t\terr = ext4_calculate_overhead(sb);\n\t\tif (err)\n\t\t\tgoto failed_mount_wq;\n\t}\n\n\t/*\n\t * The maximum number of concurrent works can be high and\n\t * concurrency isn't really necessary.  Limit it to 1.\n\t */\n\tEXT4_SB(sb)->rsv_conversion_wq =\n\t\talloc_workqueue(\"ext4-rsv-conversion\", WQ_MEM_RECLAIM | WQ_UNBOUND, 1);\n\tif (!EXT4_SB(sb)->rsv_conversion_wq) {\n\t\tprintk(KERN_ERR \"EXT4-fs: failed to create workqueue\\n\");\n\t\tret = -ENOMEM;\n\t\tgoto failed_mount4;\n\t}\n\n\t/*\n\t * The jbd2_journal_load will have done any necessary log recovery,\n\t * so we can safely mount the rest of the filesystem now.\n\t */\n\n\troot = ext4_iget(sb, EXT4_ROOT_INO);\n\tif (IS_ERR(root)) {\n\t\text4_msg(sb, KERN_ERR, \"get root inode failed\");\n\t\tret = PTR_ERR(root);\n\t\troot = NULL;\n\t\tgoto failed_mount4;\n\t}\n\tif (!S_ISDIR(root->i_mode) || !root->i_blocks || !root->i_size) {\n\t\text4_msg(sb, KERN_ERR, \"corrupt root inode, run e2fsck\");\n\t\tiput(root);\n\t\tgoto failed_mount4;\n\t}\n\tsb->s_root = d_make_root(root);\n\tif (!sb->s_root) {\n\t\text4_msg(sb, KERN_ERR, \"get root dentry failed\");\n\t\tret = -ENOMEM;\n\t\tgoto failed_mount4;\n\t}\n\n\tif (ext4_setup_super(sb, es, sb->s_flags & MS_RDONLY))\n\t\tsb->s_flags |= MS_RDONLY;\n\n\t/* determine the minimum size of new large inodes, if present */\n\tif (sbi->s_inode_size > EXT4_GOOD_OLD_INODE_SIZE) {\n\t\tsbi->s_want_extra_isize = sizeof(struct ext4_inode) -\n\t\t\t\t\t\t     EXT4_GOOD_OLD_INODE_SIZE;\n\t\tif (ext4_has_feature_extra_isize(sb)) {\n\t\t\tif (sbi->s_want_extra_isize <\n\t\t\t    le16_to_cpu(es->s_want_extra_isize))\n\t\t\t\tsbi->s_want_extra_isize =\n\t\t\t\t\tle16_to_cpu(es->s_want_extra_isize);\n\t\t\tif (sbi->s_want_extra_isize <\n\t\t\t    le16_to_cpu(es->s_min_extra_isize))\n\t\t\t\tsbi->s_want_extra_isize =\n\t\t\t\t\tle16_to_cpu(es->s_min_extra_isize);\n\t\t}\n\t}\n\t/* Check if enough inode space is available */\n\tif (EXT4_GOOD_OLD_INODE_SIZE + sbi->s_want_extra_isize >\n\t\t\t\t\t\t\tsbi->s_inode_size) {\n\t\tsbi->s_want_extra_isize = sizeof(struct ext4_inode) -\n\t\t\t\t\t\t       EXT4_GOOD_OLD_INODE_SIZE;\n\t\text4_msg(sb, KERN_INFO, \"required extra inode space not\"\n\t\t\t \"available\");\n\t}\n\n\text4_set_resv_clusters(sb);\n\n\terr = ext4_setup_system_zone(sb);\n\tif (err) {\n\t\text4_msg(sb, KERN_ERR, \"failed to initialize system \"\n\t\t\t \"zone (%d)\", err);\n\t\tgoto failed_mount4a;\n\t}\n\n\text4_ext_init(sb);\n\terr = ext4_mb_init(sb);\n\tif (err) {\n\t\text4_msg(sb, KERN_ERR, \"failed to initialize mballoc (%d)\",\n\t\t\t err);\n\t\tgoto failed_mount5;\n\t}\n\n\tblock = ext4_count_free_clusters(sb);\n\text4_free_blocks_count_set(sbi->s_es, \n\t\t\t\t   EXT4_C2B(sbi, block));\n\terr = percpu_counter_init(&sbi->s_freeclusters_counter, block,\n\t\t\t\t  GFP_KERNEL);\n\tif (!err) {\n\t\tunsigned long freei = ext4_count_free_inodes(sb);\n\t\tsbi->s_es->s_free_inodes_count = cpu_to_le32(freei);\n\t\terr = percpu_counter_init(&sbi->s_freeinodes_counter, freei,\n\t\t\t\t\t  GFP_KERNEL);\n\t}\n\tif (!err)\n\t\terr = percpu_counter_init(&sbi->s_dirs_counter,\n\t\t\t\t\t  ext4_count_dirs(sb), GFP_KERNEL);\n\tif (!err)\n\t\terr = percpu_counter_init(&sbi->s_dirtyclusters_counter, 0,\n\t\t\t\t\t  GFP_KERNEL);\n\tif (!err)\n\t\terr = percpu_init_rwsem(&sbi->s_journal_flag_rwsem);\n\n\tif (err) {\n\t\text4_msg(sb, KERN_ERR, \"insufficient memory\");\n\t\tgoto failed_mount6;\n\t}\n\n\tif (ext4_has_feature_flex_bg(sb))\n\t\tif (!ext4_fill_flex_info(sb)) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t       \"unable to initialize \"\n\t\t\t       \"flex_bg meta info!\");\n\t\t\tgoto failed_mount6;\n\t\t}\n\n\terr = ext4_register_li_request(sb, first_not_zeroed);\n\tif (err)\n\t\tgoto failed_mount6;\n\n\terr = ext4_register_sysfs(sb);\n\tif (err)\n\t\tgoto failed_mount7;\n\n#ifdef CONFIG_QUOTA\n\t/* Enable quota usage during mount. */\n\tif (ext4_has_feature_quota(sb) && !(sb->s_flags & MS_RDONLY)) {\n\t\terr = ext4_enable_quotas(sb);\n\t\tif (err)\n\t\t\tgoto failed_mount8;\n\t}\n#endif  /* CONFIG_QUOTA */\n\n\tEXT4_SB(sb)->s_mount_state |= EXT4_ORPHAN_FS;\n\text4_orphan_cleanup(sb, es);\n\tEXT4_SB(sb)->s_mount_state &= ~EXT4_ORPHAN_FS;\n\tif (needs_recovery) {\n\t\text4_msg(sb, KERN_INFO, \"recovery complete\");\n\t\text4_mark_recovery_complete(sb, es);\n\t}\n\tif (EXT4_SB(sb)->s_journal) {\n\t\tif (test_opt(sb, DATA_FLAGS) == EXT4_MOUNT_JOURNAL_DATA)\n\t\t\tdescr = \" journalled data mode\";\n\t\telse if (test_opt(sb, DATA_FLAGS) == EXT4_MOUNT_ORDERED_DATA)\n\t\t\tdescr = \" ordered data mode\";\n\t\telse\n\t\t\tdescr = \" writeback data mode\";\n\t} else\n\t\tdescr = \"out journal\";\n\n\tif (test_opt(sb, DISCARD)) {\n\t\tstruct request_queue *q = bdev_get_queue(sb->s_bdev);\n\t\tif (!blk_queue_discard(q))\n\t\t\text4_msg(sb, KERN_WARNING,\n\t\t\t\t \"mounting with \\\"discard\\\" option, but \"\n\t\t\t\t \"the device does not support discard\");\n\t}\n\n\tif (___ratelimit(&ext4_mount_msg_ratelimit, \"EXT4-fs mount\"))\n\t\text4_msg(sb, KERN_INFO, \"mounted filesystem with%s. \"\n\t\t\t \"Opts: %.*s%s%s\", descr,\n\t\t\t (int) sizeof(sbi->s_es->s_mount_opts),\n\t\t\t sbi->s_es->s_mount_opts,\n\t\t\t *sbi->s_es->s_mount_opts ? \"; \" : \"\", orig_data);\n\n\tif (es->s_error_count)\n\t\tmod_timer(&sbi->s_err_report, jiffies + 300*HZ); /* 5 minutes */\n\n\t/* Enable message ratelimiting. Default is 10 messages per 5 secs. */\n\tratelimit_state_init(&sbi->s_err_ratelimit_state, 5 * HZ, 10);\n\tratelimit_state_init(&sbi->s_warning_ratelimit_state, 5 * HZ, 10);\n\tratelimit_state_init(&sbi->s_msg_ratelimit_state, 5 * HZ, 10);\n\n\tkfree(orig_data);\n#ifdef CONFIG_EXT4_FS_ENCRYPTION\n\tmemcpy(sbi->key_prefix, EXT4_KEY_DESC_PREFIX,\n\t\t\t\tEXT4_KEY_DESC_PREFIX_SIZE);\n\tsbi->key_prefix_size = EXT4_KEY_DESC_PREFIX_SIZE;\n#endif\n\treturn 0;\n\ncantfind_ext4:\n\tif (!silent)\n\t\text4_msg(sb, KERN_ERR, \"VFS: Can't find ext4 filesystem\");\n\tgoto failed_mount;\n\n#ifdef CONFIG_QUOTA\nfailed_mount8:\n\text4_unregister_sysfs(sb);\n#endif\nfailed_mount7:\n\text4_unregister_li_request(sb);\nfailed_mount6:\n\text4_mb_release(sb);\n\tif (sbi->s_flex_groups)\n\t\tkvfree(sbi->s_flex_groups);\n\tpercpu_counter_destroy(&sbi->s_freeclusters_counter);\n\tpercpu_counter_destroy(&sbi->s_freeinodes_counter);\n\tpercpu_counter_destroy(&sbi->s_dirs_counter);\n\tpercpu_counter_destroy(&sbi->s_dirtyclusters_counter);\nfailed_mount5:\n\text4_ext_release(sb);\n\text4_release_system_zone(sb);\nfailed_mount4a:\n\tdput(sb->s_root);\n\tsb->s_root = NULL;\nfailed_mount4:\n\text4_msg(sb, KERN_ERR, \"mount failed\");\n\tif (EXT4_SB(sb)->rsv_conversion_wq)\n\t\tdestroy_workqueue(EXT4_SB(sb)->rsv_conversion_wq);\nfailed_mount_wq:\n\tif (sbi->s_mb_cache) {\n\t\text4_xattr_destroy_cache(sbi->s_mb_cache);\n\t\tsbi->s_mb_cache = NULL;\n\t}\n\tif (sbi->s_journal) {\n\t\tjbd2_journal_destroy(sbi->s_journal);\n\t\tsbi->s_journal = NULL;\n\t}\nfailed_mount3a:\n\text4_es_unregister_shrinker(sbi);\nfailed_mount3:\n\tdel_timer_sync(&sbi->s_err_report);\n\tif (sbi->s_mmp_tsk)\n\t\tkthread_stop(sbi->s_mmp_tsk);\nfailed_mount2:\n\tfor (i = 0; i < db_count; i++)\n\t\tbrelse(sbi->s_group_desc[i]);\n\tkvfree(sbi->s_group_desc);\nfailed_mount:\n\tif (sbi->s_chksum_driver)\n\t\tcrypto_free_shash(sbi->s_chksum_driver);\n#ifdef CONFIG_QUOTA\n\tfor (i = 0; i < EXT4_MAXQUOTAS; i++)\n\t\tkfree(sbi->s_qf_names[i]);\n#endif\n\text4_blkdev_remove(sbi);\n\tbrelse(bh);\nout_fail:\n\tsb->s_fs_info = NULL;\n\tkfree(sbi->s_blockgroup_lock);\nout_free_base:\n\tkfree(sbi);\n\tkfree(orig_data);\n\treturn err ? err : ret;\n}\n\n/*\n * Setup any per-fs journal parameters now.  We'll do this both on\n * initial mount, once the journal has been initialised but before we've\n * done any recovery; and again on any subsequent remount.\n */\nstatic void ext4_init_journal_params(struct super_block *sb, journal_t *journal)\n{\n\tstruct ext4_sb_info *sbi = EXT4_SB(sb);\n\n\tjournal->j_commit_interval = sbi->s_commit_interval;\n\tjournal->j_min_batch_time = sbi->s_min_batch_time;\n\tjournal->j_max_batch_time = sbi->s_max_batch_time;\n\n\twrite_lock(&journal->j_state_lock);\n\tif (test_opt(sb, BARRIER))\n\t\tjournal->j_flags |= JBD2_BARRIER;\n\telse\n\t\tjournal->j_flags &= ~JBD2_BARRIER;\n\tif (test_opt(sb, DATA_ERR_ABORT))\n\t\tjournal->j_flags |= JBD2_ABORT_ON_SYNCDATA_ERR;\n\telse\n\t\tjournal->j_flags &= ~JBD2_ABORT_ON_SYNCDATA_ERR;\n\twrite_unlock(&journal->j_state_lock);\n}\n\nstatic struct inode *ext4_get_journal_inode(struct super_block *sb,\n\t\t\t\t\t     unsigned int journal_inum)\n{\n\tstruct inode *journal_inode;\n\n\t/*\n\t * Test for the existence of a valid inode on disk.  Bad things\n\t * happen if we iget() an unused inode, as the subsequent iput()\n\t * will try to delete it.\n\t */\n\tjournal_inode = ext4_iget(sb, journal_inum);\n\tif (IS_ERR(journal_inode)) {\n\t\text4_msg(sb, KERN_ERR, \"no journal found\");\n\t\treturn NULL;\n\t}\n\tif (!journal_inode->i_nlink) {\n\t\tmake_bad_inode(journal_inode);\n\t\tiput(journal_inode);\n\t\text4_msg(sb, KERN_ERR, \"journal inode is deleted\");\n\t\treturn NULL;\n\t}\n\n\tjbd_debug(2, \"Journal inode found at %p: %lld bytes\\n\",\n\t\t  journal_inode, journal_inode->i_size);\n\tif (!S_ISREG(journal_inode->i_mode)) {\n\t\text4_msg(sb, KERN_ERR, \"invalid journal inode\");\n\t\tiput(journal_inode);\n\t\treturn NULL;\n\t}\n\treturn journal_inode;\n}\n\nstatic journal_t *ext4_get_journal(struct super_block *sb,\n\t\t\t\t   unsigned int journal_inum)\n{\n\tstruct inode *journal_inode;\n\tjournal_t *journal;\n\n\tBUG_ON(!ext4_has_feature_journal(sb));\n\n\tjournal_inode = ext4_get_journal_inode(sb, journal_inum);\n\tif (!journal_inode)\n\t\treturn NULL;\n\n\tjournal = jbd2_journal_init_inode(journal_inode);\n\tif (!journal) {\n\t\text4_msg(sb, KERN_ERR, \"Could not load journal inode\");\n\t\tiput(journal_inode);\n\t\treturn NULL;\n\t}\n\tjournal->j_private = sb;\n\text4_init_journal_params(sb, journal);\n\treturn journal;\n}\n\nstatic journal_t *ext4_get_dev_journal(struct super_block *sb,\n\t\t\t\t       dev_t j_dev)\n{\n\tstruct buffer_head *bh;\n\tjournal_t *journal;\n\text4_fsblk_t start;\n\text4_fsblk_t len;\n\tint hblock, blocksize;\n\text4_fsblk_t sb_block;\n\tunsigned long offset;\n\tstruct ext4_super_block *es;\n\tstruct block_device *bdev;\n\n\tBUG_ON(!ext4_has_feature_journal(sb));\n\n\tbdev = ext4_blkdev_get(j_dev, sb);\n\tif (bdev == NULL)\n\t\treturn NULL;\n\n\tblocksize = sb->s_blocksize;\n\thblock = bdev_logical_block_size(bdev);\n\tif (blocksize < hblock) {\n\t\text4_msg(sb, KERN_ERR,\n\t\t\t\"blocksize too small for journal device\");\n\t\tgoto out_bdev;\n\t}\n\n\tsb_block = EXT4_MIN_BLOCK_SIZE / blocksize;\n\toffset = EXT4_MIN_BLOCK_SIZE % blocksize;\n\tset_blocksize(bdev, blocksize);\n\tif (!(bh = __bread(bdev, sb_block, blocksize))) {\n\t\text4_msg(sb, KERN_ERR, \"couldn't read superblock of \"\n\t\t       \"external journal\");\n\t\tgoto out_bdev;\n\t}\n\n\tes = (struct ext4_super_block *) (bh->b_data + offset);\n\tif ((le16_to_cpu(es->s_magic) != EXT4_SUPER_MAGIC) ||\n\t    !(le32_to_cpu(es->s_feature_incompat) &\n\t      EXT4_FEATURE_INCOMPAT_JOURNAL_DEV)) {\n\t\text4_msg(sb, KERN_ERR, \"external journal has \"\n\t\t\t\t\t\"bad superblock\");\n\t\tbrelse(bh);\n\t\tgoto out_bdev;\n\t}\n\n\tif ((le32_to_cpu(es->s_feature_ro_compat) &\n\t     EXT4_FEATURE_RO_COMPAT_METADATA_CSUM) &&\n\t    es->s_checksum != ext4_superblock_csum(sb, es)) {\n\t\text4_msg(sb, KERN_ERR, \"external journal has \"\n\t\t\t\t       \"corrupt superblock\");\n\t\tbrelse(bh);\n\t\tgoto out_bdev;\n\t}\n\n\tif (memcmp(EXT4_SB(sb)->s_es->s_journal_uuid, es->s_uuid, 16)) {\n\t\text4_msg(sb, KERN_ERR, \"journal UUID does not match\");\n\t\tbrelse(bh);\n\t\tgoto out_bdev;\n\t}\n\n\tlen = ext4_blocks_count(es);\n\tstart = sb_block + 1;\n\tbrelse(bh);\t/* we're done with the superblock */\n\n\tjournal = jbd2_journal_init_dev(bdev, sb->s_bdev,\n\t\t\t\t\tstart, len, blocksize);\n\tif (!journal) {\n\t\text4_msg(sb, KERN_ERR, \"failed to create device journal\");\n\t\tgoto out_bdev;\n\t}\n\tjournal->j_private = sb;\n\tll_rw_block(REQ_OP_READ, REQ_META | REQ_PRIO, 1, &journal->j_sb_buffer);\n\twait_on_buffer(journal->j_sb_buffer);\n\tif (!buffer_uptodate(journal->j_sb_buffer)) {\n\t\text4_msg(sb, KERN_ERR, \"I/O error on journal device\");\n\t\tgoto out_journal;\n\t}\n\tif (be32_to_cpu(journal->j_superblock->s_nr_users) != 1) {\n\t\text4_msg(sb, KERN_ERR, \"External journal has more than one \"\n\t\t\t\t\t\"user (unsupported) - %d\",\n\t\t\tbe32_to_cpu(journal->j_superblock->s_nr_users));\n\t\tgoto out_journal;\n\t}\n\tEXT4_SB(sb)->journal_bdev = bdev;\n\text4_init_journal_params(sb, journal);\n\treturn journal;\n\nout_journal:\n\tjbd2_journal_destroy(journal);\nout_bdev:\n\text4_blkdev_put(bdev);\n\treturn NULL;\n}\n\nstatic int ext4_load_journal(struct super_block *sb,\n\t\t\t     struct ext4_super_block *es,\n\t\t\t     unsigned long journal_devnum)\n{\n\tjournal_t *journal;\n\tunsigned int journal_inum = le32_to_cpu(es->s_journal_inum);\n\tdev_t journal_dev;\n\tint err = 0;\n\tint really_read_only;\n\n\tBUG_ON(!ext4_has_feature_journal(sb));\n\n\tif (journal_devnum &&\n\t    journal_devnum != le32_to_cpu(es->s_journal_dev)) {\n\t\text4_msg(sb, KERN_INFO, \"external journal device major/minor \"\n\t\t\t\"numbers have changed\");\n\t\tjournal_dev = new_decode_dev(journal_devnum);\n\t} else\n\t\tjournal_dev = new_decode_dev(le32_to_cpu(es->s_journal_dev));\n\n\treally_read_only = bdev_read_only(sb->s_bdev);\n\n\t/*\n\t * Are we loading a blank journal or performing recovery after a\n\t * crash?  For recovery, we need to check in advance whether we\n\t * can get read-write access to the device.\n\t */\n\tif (ext4_has_feature_journal_needs_recovery(sb)) {\n\t\tif (sb->s_flags & MS_RDONLY) {\n\t\t\text4_msg(sb, KERN_INFO, \"INFO: recovery \"\n\t\t\t\t\t\"required on readonly filesystem\");\n\t\t\tif (really_read_only) {\n\t\t\t\text4_msg(sb, KERN_ERR, \"write access \"\n\t\t\t\t\t\"unavailable, cannot proceed\");\n\t\t\t\treturn -EROFS;\n\t\t\t}\n\t\t\text4_msg(sb, KERN_INFO, \"write access will \"\n\t\t\t       \"be enabled during recovery\");\n\t\t}\n\t}\n\n\tif (journal_inum && journal_dev) {\n\t\text4_msg(sb, KERN_ERR, \"filesystem has both journal \"\n\t\t       \"and inode journals!\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (journal_inum) {\n\t\tif (!(journal = ext4_get_journal(sb, journal_inum)))\n\t\t\treturn -EINVAL;\n\t} else {\n\t\tif (!(journal = ext4_get_dev_journal(sb, journal_dev)))\n\t\t\treturn -EINVAL;\n\t}\n\n\tif (!(journal->j_flags & JBD2_BARRIER))\n\t\text4_msg(sb, KERN_INFO, \"barriers disabled\");\n\n\tif (!ext4_has_feature_journal_needs_recovery(sb))\n\t\terr = jbd2_journal_wipe(journal, !really_read_only);\n\tif (!err) {\n\t\tchar *save = kmalloc(EXT4_S_ERR_LEN, GFP_KERNEL);\n\t\tif (save)\n\t\t\tmemcpy(save, ((char *) es) +\n\t\t\t       EXT4_S_ERR_START, EXT4_S_ERR_LEN);\n\t\terr = jbd2_journal_load(journal);\n\t\tif (save)\n\t\t\tmemcpy(((char *) es) + EXT4_S_ERR_START,\n\t\t\t       save, EXT4_S_ERR_LEN);\n\t\tkfree(save);\n\t}\n\n\tif (err) {\n\t\text4_msg(sb, KERN_ERR, \"error loading journal\");\n\t\tjbd2_journal_destroy(journal);\n\t\treturn err;\n\t}\n\n\tEXT4_SB(sb)->s_journal = journal;\n\text4_clear_journal_err(sb, es);\n\n\tif (!really_read_only && journal_devnum &&\n\t    journal_devnum != le32_to_cpu(es->s_journal_dev)) {\n\t\tes->s_journal_dev = cpu_to_le32(journal_devnum);\n\n\t\t/* Make sure we flush the recovery flag to disk. */\n\t\text4_commit_super(sb, 1);\n\t}\n\n\treturn 0;\n}\n\nstatic int ext4_commit_super(struct super_block *sb, int sync)\n{\n\tstruct ext4_super_block *es = EXT4_SB(sb)->s_es;\n\tstruct buffer_head *sbh = EXT4_SB(sb)->s_sbh;\n\tint error = 0;\n\n\tif (!sbh || block_device_ejected(sb))\n\t\treturn error;\n\t/*\n\t * If the file system is mounted read-only, don't update the\n\t * superblock write time.  This avoids updating the superblock\n\t * write time when we are mounting the root file system\n\t * read/only but we need to replay the journal; at that point,\n\t * for people who are east of GMT and who make their clock\n\t * tick in localtime for Windows bug-for-bug compatibility,\n\t * the clock is set in the future, and this will cause e2fsck\n\t * to complain and force a full file system check.\n\t */\n\tif (!(sb->s_flags & MS_RDONLY))\n\t\tes->s_wtime = cpu_to_le32(get_seconds());\n\tif (sb->s_bdev->bd_part)\n\t\tes->s_kbytes_written =\n\t\t\tcpu_to_le64(EXT4_SB(sb)->s_kbytes_written +\n\t\t\t    ((part_stat_read(sb->s_bdev->bd_part, sectors[1]) -\n\t\t\t      EXT4_SB(sb)->s_sectors_written_start) >> 1));\n\telse\n\t\tes->s_kbytes_written =\n\t\t\tcpu_to_le64(EXT4_SB(sb)->s_kbytes_written);\n\tif (percpu_counter_initialized(&EXT4_SB(sb)->s_freeclusters_counter))\n\t\text4_free_blocks_count_set(es,\n\t\t\tEXT4_C2B(EXT4_SB(sb), percpu_counter_sum_positive(\n\t\t\t\t&EXT4_SB(sb)->s_freeclusters_counter)));\n\tif (percpu_counter_initialized(&EXT4_SB(sb)->s_freeinodes_counter))\n\t\tes->s_free_inodes_count =\n\t\t\tcpu_to_le32(percpu_counter_sum_positive(\n\t\t\t\t&EXT4_SB(sb)->s_freeinodes_counter));\n\tBUFFER_TRACE(sbh, \"marking dirty\");\n\text4_superblock_csum_set(sb);\n\tif (sync)\n\t\tlock_buffer(sbh);\n\tif (buffer_write_io_error(sbh)) {\n\t\t/*\n\t\t * Oh, dear.  A previous attempt to write the\n\t\t * superblock failed.  This could happen because the\n\t\t * USB device was yanked out.  Or it could happen to\n\t\t * be a transient write error and maybe the block will\n\t\t * be remapped.  Nothing we can do but to retry the\n\t\t * write and hope for the best.\n\t\t */\n\t\text4_msg(sb, KERN_ERR, \"previous I/O error to \"\n\t\t       \"superblock detected\");\n\t\tclear_buffer_write_io_error(sbh);\n\t\tset_buffer_uptodate(sbh);\n\t}\n\tmark_buffer_dirty(sbh);\n\tif (sync) {\n\t\tunlock_buffer(sbh);\n\t\terror = __sync_dirty_buffer(sbh,\n\t\t\ttest_opt(sb, BARRIER) ? WRITE_FUA : WRITE_SYNC);\n\t\tif (error)\n\t\t\treturn error;\n\n\t\terror = buffer_write_io_error(sbh);\n\t\tif (error) {\n\t\t\text4_msg(sb, KERN_ERR, \"I/O error while writing \"\n\t\t\t       \"superblock\");\n\t\t\tclear_buffer_write_io_error(sbh);\n\t\t\tset_buffer_uptodate(sbh);\n\t\t}\n\t}\n\treturn error;\n}\n\n/*\n * Have we just finished recovery?  If so, and if we are mounting (or\n * remounting) the filesystem readonly, then we will end up with a\n * consistent fs on disk.  Record that fact.\n */\nstatic void ext4_mark_recovery_complete(struct super_block *sb,\n\t\t\t\t\tstruct ext4_super_block *es)\n{\n\tjournal_t *journal = EXT4_SB(sb)->s_journal;\n\n\tif (!ext4_has_feature_journal(sb)) {\n\t\tBUG_ON(journal != NULL);\n\t\treturn;\n\t}\n\tjbd2_journal_lock_updates(journal);\n\tif (jbd2_journal_flush(journal) < 0)\n\t\tgoto out;\n\n\tif (ext4_has_feature_journal_needs_recovery(sb) &&\n\t    sb->s_flags & MS_RDONLY) {\n\t\text4_clear_feature_journal_needs_recovery(sb);\n\t\text4_commit_super(sb, 1);\n\t}\n\nout:\n\tjbd2_journal_unlock_updates(journal);\n}\n\n/*\n * If we are mounting (or read-write remounting) a filesystem whose journal\n * has recorded an error from a previous lifetime, move that error to the\n * main filesystem now.\n */\nstatic void ext4_clear_journal_err(struct super_block *sb,\n\t\t\t\t   struct ext4_super_block *es)\n{\n\tjournal_t *journal;\n\tint j_errno;\n\tconst char *errstr;\n\n\tBUG_ON(!ext4_has_feature_journal(sb));\n\n\tjournal = EXT4_SB(sb)->s_journal;\n\n\t/*\n\t * Now check for any error status which may have been recorded in the\n\t * journal by a prior ext4_error() or ext4_abort()\n\t */\n\n\tj_errno = jbd2_journal_errno(journal);\n\tif (j_errno) {\n\t\tchar nbuf[16];\n\n\t\terrstr = ext4_decode_error(sb, j_errno, nbuf);\n\t\text4_warning(sb, \"Filesystem error recorded \"\n\t\t\t     \"from previous mount: %s\", errstr);\n\t\text4_warning(sb, \"Marking fs in need of filesystem check.\");\n\n\t\tEXT4_SB(sb)->s_mount_state |= EXT4_ERROR_FS;\n\t\tes->s_state |= cpu_to_le16(EXT4_ERROR_FS);\n\t\text4_commit_super(sb, 1);\n\n\t\tjbd2_journal_clear_err(journal);\n\t\tjbd2_journal_update_sb_errno(journal);\n\t}\n}\n\n/*\n * Force the running and committing transactions to commit,\n * and wait on the commit.\n */\nint ext4_force_commit(struct super_block *sb)\n{\n\tjournal_t *journal;\n\n\tif (sb->s_flags & MS_RDONLY)\n\t\treturn 0;\n\n\tjournal = EXT4_SB(sb)->s_journal;\n\treturn ext4_journal_force_commit(journal);\n}\n\nstatic int ext4_sync_fs(struct super_block *sb, int wait)\n{\n\tint ret = 0;\n\ttid_t target;\n\tbool needs_barrier = false;\n\tstruct ext4_sb_info *sbi = EXT4_SB(sb);\n\n\ttrace_ext4_sync_fs(sb, wait);\n\tflush_workqueue(sbi->rsv_conversion_wq);\n\t/*\n\t * Writeback quota in non-journalled quota case - journalled quota has\n\t * no dirty dquots\n\t */\n\tdquot_writeback_dquots(sb, -1);\n\t/*\n\t * Data writeback is possible w/o journal transaction, so barrier must\n\t * being sent at the end of the function. But we can skip it if\n\t * transaction_commit will do it for us.\n\t */\n\tif (sbi->s_journal) {\n\t\ttarget = jbd2_get_latest_transaction(sbi->s_journal);\n\t\tif (wait && sbi->s_journal->j_flags & JBD2_BARRIER &&\n\t\t    !jbd2_trans_will_send_data_barrier(sbi->s_journal, target))\n\t\t\tneeds_barrier = true;\n\n\t\tif (jbd2_journal_start_commit(sbi->s_journal, &target)) {\n\t\t\tif (wait)\n\t\t\t\tret = jbd2_log_wait_commit(sbi->s_journal,\n\t\t\t\t\t\t\t   target);\n\t\t}\n\t} else if (wait && test_opt(sb, BARRIER))\n\t\tneeds_barrier = true;\n\tif (needs_barrier) {\n\t\tint err;\n\t\terr = blkdev_issue_flush(sb->s_bdev, GFP_KERNEL, NULL);\n\t\tif (!ret)\n\t\t\tret = err;\n\t}\n\n\treturn ret;\n}\n\n/*\n * LVM calls this function before a (read-only) snapshot is created.  This\n * gives us a chance to flush the journal completely and mark the fs clean.\n *\n * Note that only this function cannot bring a filesystem to be in a clean\n * state independently. It relies on upper layer to stop all data & metadata\n * modifications.\n */\nstatic int ext4_freeze(struct super_block *sb)\n{\n\tint error = 0;\n\tjournal_t *journal;\n\n\tif (sb->s_flags & MS_RDONLY)\n\t\treturn 0;\n\n\tjournal = EXT4_SB(sb)->s_journal;\n\n\tif (journal) {\n\t\t/* Now we set up the journal barrier. */\n\t\tjbd2_journal_lock_updates(journal);\n\n\t\t/*\n\t\t * Don't clear the needs_recovery flag if we failed to\n\t\t * flush the journal.\n\t\t */\n\t\terror = jbd2_journal_flush(journal);\n\t\tif (error < 0)\n\t\t\tgoto out;\n\n\t\t/* Journal blocked and flushed, clear needs_recovery flag. */\n\t\text4_clear_feature_journal_needs_recovery(sb);\n\t}\n\n\terror = ext4_commit_super(sb, 1);\nout:\n\tif (journal)\n\t\t/* we rely on upper layer to stop further updates */\n\t\tjbd2_journal_unlock_updates(journal);\n\treturn error;\n}\n\n/*\n * Called by LVM after the snapshot is done.  We need to reset the RECOVER\n * flag here, even though the filesystem is not technically dirty yet.\n */\nstatic int ext4_unfreeze(struct super_block *sb)\n{\n\tif (sb->s_flags & MS_RDONLY)\n\t\treturn 0;\n\n\tif (EXT4_SB(sb)->s_journal) {\n\t\t/* Reset the needs_recovery flag before the fs is unlocked. */\n\t\text4_set_feature_journal_needs_recovery(sb);\n\t}\n\n\text4_commit_super(sb, 1);\n\treturn 0;\n}\n\n/*\n * Structure to save mount options for ext4_remount's benefit\n */\nstruct ext4_mount_options {\n\tunsigned long s_mount_opt;\n\tunsigned long s_mount_opt2;\n\tkuid_t s_resuid;\n\tkgid_t s_resgid;\n\tunsigned long s_commit_interval;\n\tu32 s_min_batch_time, s_max_batch_time;\n#ifdef CONFIG_QUOTA\n\tint s_jquota_fmt;\n\tchar *s_qf_names[EXT4_MAXQUOTAS];\n#endif\n};\n\nstatic int ext4_remount(struct super_block *sb, int *flags, char *data)\n{\n\tstruct ext4_super_block *es;\n\tstruct ext4_sb_info *sbi = EXT4_SB(sb);\n\tunsigned long old_sb_flags;\n\tstruct ext4_mount_options old_opts;\n\tint enable_quota = 0;\n\text4_group_t g;\n\tunsigned int journal_ioprio = DEFAULT_JOURNAL_IOPRIO;\n\tint err = 0;\n#ifdef CONFIG_QUOTA\n\tint i, j;\n#endif\n\tchar *orig_data = kstrdup(data, GFP_KERNEL);\n\n\t/* Store the original options */\n\told_sb_flags = sb->s_flags;\n\told_opts.s_mount_opt = sbi->s_mount_opt;\n\told_opts.s_mount_opt2 = sbi->s_mount_opt2;\n\told_opts.s_resuid = sbi->s_resuid;\n\told_opts.s_resgid = sbi->s_resgid;\n\told_opts.s_commit_interval = sbi->s_commit_interval;\n\told_opts.s_min_batch_time = sbi->s_min_batch_time;\n\told_opts.s_max_batch_time = sbi->s_max_batch_time;\n#ifdef CONFIG_QUOTA\n\told_opts.s_jquota_fmt = sbi->s_jquota_fmt;\n\tfor (i = 0; i < EXT4_MAXQUOTAS; i++)\n\t\tif (sbi->s_qf_names[i]) {\n\t\t\told_opts.s_qf_names[i] = kstrdup(sbi->s_qf_names[i],\n\t\t\t\t\t\t\t GFP_KERNEL);\n\t\t\tif (!old_opts.s_qf_names[i]) {\n\t\t\t\tfor (j = 0; j < i; j++)\n\t\t\t\t\tkfree(old_opts.s_qf_names[j]);\n\t\t\t\tkfree(orig_data);\n\t\t\t\treturn -ENOMEM;\n\t\t\t}\n\t\t} else\n\t\t\told_opts.s_qf_names[i] = NULL;\n#endif\n\tif (sbi->s_journal && sbi->s_journal->j_task->io_context)\n\t\tjournal_ioprio = sbi->s_journal->j_task->io_context->ioprio;\n\n\tif (!parse_options(data, sb, NULL, &journal_ioprio, 1)) {\n\t\terr = -EINVAL;\n\t\tgoto restore_opts;\n\t}\n\n\tif ((old_opts.s_mount_opt & EXT4_MOUNT_JOURNAL_CHECKSUM) ^\n\t    test_opt(sb, JOURNAL_CHECKSUM)) {\n\t\text4_msg(sb, KERN_ERR, \"changing journal_checksum \"\n\t\t\t \"during remount not supported; ignoring\");\n\t\tsbi->s_mount_opt ^= EXT4_MOUNT_JOURNAL_CHECKSUM;\n\t}\n\n\tif (test_opt(sb, DATA_FLAGS) == EXT4_MOUNT_JOURNAL_DATA) {\n\t\tif (test_opt2(sb, EXPLICIT_DELALLOC)) {\n\t\t\text4_msg(sb, KERN_ERR, \"can't mount with \"\n\t\t\t\t \"both data=journal and delalloc\");\n\t\t\terr = -EINVAL;\n\t\t\tgoto restore_opts;\n\t\t}\n\t\tif (test_opt(sb, DIOREAD_NOLOCK)) {\n\t\t\text4_msg(sb, KERN_ERR, \"can't mount with \"\n\t\t\t\t \"both data=journal and dioread_nolock\");\n\t\t\terr = -EINVAL;\n\t\t\tgoto restore_opts;\n\t\t}\n\t\tif (test_opt(sb, DAX)) {\n\t\t\text4_msg(sb, KERN_ERR, \"can't mount with \"\n\t\t\t\t \"both data=journal and dax\");\n\t\t\terr = -EINVAL;\n\t\t\tgoto restore_opts;\n\t\t}\n\t}\n\n\tif ((sbi->s_mount_opt ^ old_opts.s_mount_opt) & EXT4_MOUNT_DAX) {\n\t\text4_msg(sb, KERN_WARNING, \"warning: refusing change of \"\n\t\t\t\"dax flag with busy inodes while remounting\");\n\t\tsbi->s_mount_opt ^= EXT4_MOUNT_DAX;\n\t}\n\n\tif (sbi->s_mount_flags & EXT4_MF_FS_ABORTED)\n\t\text4_abort(sb, \"Abort forced by user\");\n\n\tsb->s_flags = (sb->s_flags & ~MS_POSIXACL) |\n\t\t(test_opt(sb, POSIX_ACL) ? MS_POSIXACL : 0);\n\n\tes = sbi->s_es;\n\n\tif (sbi->s_journal) {\n\t\text4_init_journal_params(sb, sbi->s_journal);\n\t\tset_task_ioprio(sbi->s_journal->j_task, journal_ioprio);\n\t}\n\n\tif (*flags & MS_LAZYTIME)\n\t\tsb->s_flags |= MS_LAZYTIME;\n\n\tif ((*flags & MS_RDONLY) != (sb->s_flags & MS_RDONLY)) {\n\t\tif (sbi->s_mount_flags & EXT4_MF_FS_ABORTED) {\n\t\t\terr = -EROFS;\n\t\t\tgoto restore_opts;\n\t\t}\n\n\t\tif (*flags & MS_RDONLY) {\n\t\t\terr = sync_filesystem(sb);\n\t\t\tif (err < 0)\n\t\t\t\tgoto restore_opts;\n\t\t\terr = dquot_suspend(sb, -1);\n\t\t\tif (err < 0)\n\t\t\t\tgoto restore_opts;\n\n\t\t\t/*\n\t\t\t * First of all, the unconditional stuff we have to do\n\t\t\t * to disable replay of the journal when we next remount\n\t\t\t */\n\t\t\tsb->s_flags |= MS_RDONLY;\n\n\t\t\t/*\n\t\t\t * OK, test if we are remounting a valid rw partition\n\t\t\t * readonly, and if so set the rdonly flag and then\n\t\t\t * mark the partition as valid again.\n\t\t\t */\n\t\t\tif (!(es->s_state & cpu_to_le16(EXT4_VALID_FS)) &&\n\t\t\t    (sbi->s_mount_state & EXT4_VALID_FS))\n\t\t\t\tes->s_state = cpu_to_le16(sbi->s_mount_state);\n\n\t\t\tif (sbi->s_journal)\n\t\t\t\text4_mark_recovery_complete(sb, es);\n\t\t} else {\n\t\t\t/* Make sure we can mount this feature set readwrite */\n\t\t\tif (ext4_has_feature_readonly(sb) ||\n\t\t\t    !ext4_feature_set_ok(sb, 0)) {\n\t\t\t\terr = -EROFS;\n\t\t\t\tgoto restore_opts;\n\t\t\t}\n\t\t\t/*\n\t\t\t * Make sure the group descriptor checksums\n\t\t\t * are sane.  If they aren't, refuse to remount r/w.\n\t\t\t */\n\t\t\tfor (g = 0; g < sbi->s_groups_count; g++) {\n\t\t\t\tstruct ext4_group_desc *gdp =\n\t\t\t\t\text4_get_group_desc(sb, g, NULL);\n\n\t\t\t\tif (!ext4_group_desc_csum_verify(sb, g, gdp)) {\n\t\t\t\t\text4_msg(sb, KERN_ERR,\n\t       \"ext4_remount: Checksum for group %u failed (%u!=%u)\",\n\t\tg, le16_to_cpu(ext4_group_desc_csum(sb, g, gdp)),\n\t\t\t\t\t       le16_to_cpu(gdp->bg_checksum));\n\t\t\t\t\terr = -EFSBADCRC;\n\t\t\t\t\tgoto restore_opts;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t/*\n\t\t\t * If we have an unprocessed orphan list hanging\n\t\t\t * around from a previously readonly bdev mount,\n\t\t\t * require a full umount/remount for now.\n\t\t\t */\n\t\t\tif (es->s_last_orphan) {\n\t\t\t\text4_msg(sb, KERN_WARNING, \"Couldn't \"\n\t\t\t\t       \"remount RDWR because of unprocessed \"\n\t\t\t\t       \"orphan inode list.  Please \"\n\t\t\t\t       \"umount/remount instead\");\n\t\t\t\terr = -EINVAL;\n\t\t\t\tgoto restore_opts;\n\t\t\t}\n\n\t\t\t/*\n\t\t\t * Mounting a RDONLY partition read-write, so reread\n\t\t\t * and store the current valid flag.  (It may have\n\t\t\t * been changed by e2fsck since we originally mounted\n\t\t\t * the partition.)\n\t\t\t */\n\t\t\tif (sbi->s_journal)\n\t\t\t\text4_clear_journal_err(sb, es);\n\t\t\tsbi->s_mount_state = le16_to_cpu(es->s_state);\n\t\t\tif (!ext4_setup_super(sb, es, 0))\n\t\t\t\tsb->s_flags &= ~MS_RDONLY;\n\t\t\tif (ext4_has_feature_mmp(sb))\n\t\t\t\tif (ext4_multi_mount_protect(sb,\n\t\t\t\t\t\tle64_to_cpu(es->s_mmp_block))) {\n\t\t\t\t\terr = -EROFS;\n\t\t\t\t\tgoto restore_opts;\n\t\t\t\t}\n\t\t\tenable_quota = 1;\n\t\t}\n\t}\n\n\t/*\n\t * Reinitialize lazy itable initialization thread based on\n\t * current settings\n\t */\n\tif ((sb->s_flags & MS_RDONLY) || !test_opt(sb, INIT_INODE_TABLE))\n\t\text4_unregister_li_request(sb);\n\telse {\n\t\text4_group_t first_not_zeroed;\n\t\tfirst_not_zeroed = ext4_has_uninit_itable(sb);\n\t\text4_register_li_request(sb, first_not_zeroed);\n\t}\n\n\text4_setup_system_zone(sb);\n\tif (sbi->s_journal == NULL && !(old_sb_flags & MS_RDONLY))\n\t\text4_commit_super(sb, 1);\n\n#ifdef CONFIG_QUOTA\n\t/* Release old quota file names */\n\tfor (i = 0; i < EXT4_MAXQUOTAS; i++)\n\t\tkfree(old_opts.s_qf_names[i]);\n\tif (enable_quota) {\n\t\tif (sb_any_quota_suspended(sb))\n\t\t\tdquot_resume(sb, -1);\n\t\telse if (ext4_has_feature_quota(sb)) {\n\t\t\terr = ext4_enable_quotas(sb);\n\t\t\tif (err)\n\t\t\t\tgoto restore_opts;\n\t\t}\n\t}\n#endif\n\n\t*flags = (*flags & ~MS_LAZYTIME) | (sb->s_flags & MS_LAZYTIME);\n\text4_msg(sb, KERN_INFO, \"re-mounted. Opts: %s\", orig_data);\n\tkfree(orig_data);\n\treturn 0;\n\nrestore_opts:\n\tsb->s_flags = old_sb_flags;\n\tsbi->s_mount_opt = old_opts.s_mount_opt;\n\tsbi->s_mount_opt2 = old_opts.s_mount_opt2;\n\tsbi->s_resuid = old_opts.s_resuid;\n\tsbi->s_resgid = old_opts.s_resgid;\n\tsbi->s_commit_interval = old_opts.s_commit_interval;\n\tsbi->s_min_batch_time = old_opts.s_min_batch_time;\n\tsbi->s_max_batch_time = old_opts.s_max_batch_time;\n#ifdef CONFIG_QUOTA\n\tsbi->s_jquota_fmt = old_opts.s_jquota_fmt;\n\tfor (i = 0; i < EXT4_MAXQUOTAS; i++) {\n\t\tkfree(sbi->s_qf_names[i]);\n\t\tsbi->s_qf_names[i] = old_opts.s_qf_names[i];\n\t}\n#endif\n\tkfree(orig_data);\n\treturn err;\n}\n\n#ifdef CONFIG_QUOTA\nstatic int ext4_statfs_project(struct super_block *sb,\n\t\t\t       kprojid_t projid, struct kstatfs *buf)\n{\n\tstruct kqid qid;\n\tstruct dquot *dquot;\n\tu64 limit;\n\tu64 curblock;\n\n\tqid = make_kqid_projid(projid);\n\tdquot = dqget(sb, qid);\n\tif (IS_ERR(dquot))\n\t\treturn PTR_ERR(dquot);\n\tspin_lock(&dq_data_lock);\n\n\tlimit = (dquot->dq_dqb.dqb_bsoftlimit ?\n\t\t dquot->dq_dqb.dqb_bsoftlimit :\n\t\t dquot->dq_dqb.dqb_bhardlimit) >> sb->s_blocksize_bits;\n\tif (limit && buf->f_blocks > limit) {\n\t\tcurblock = dquot->dq_dqb.dqb_curspace >> sb->s_blocksize_bits;\n\t\tbuf->f_blocks = limit;\n\t\tbuf->f_bfree = buf->f_bavail =\n\t\t\t(buf->f_blocks > curblock) ?\n\t\t\t (buf->f_blocks - curblock) : 0;\n\t}\n\n\tlimit = dquot->dq_dqb.dqb_isoftlimit ?\n\t\tdquot->dq_dqb.dqb_isoftlimit :\n\t\tdquot->dq_dqb.dqb_ihardlimit;\n\tif (limit && buf->f_files > limit) {\n\t\tbuf->f_files = limit;\n\t\tbuf->f_ffree =\n\t\t\t(buf->f_files > dquot->dq_dqb.dqb_curinodes) ?\n\t\t\t (buf->f_files - dquot->dq_dqb.dqb_curinodes) : 0;\n\t}\n\n\tspin_unlock(&dq_data_lock);\n\tdqput(dquot);\n\treturn 0;\n}\n#endif\n\nstatic int ext4_statfs(struct dentry *dentry, struct kstatfs *buf)\n{\n\tstruct super_block *sb = dentry->d_sb;\n\tstruct ext4_sb_info *sbi = EXT4_SB(sb);\n\tstruct ext4_super_block *es = sbi->s_es;\n\text4_fsblk_t overhead = 0, resv_blocks;\n\tu64 fsid;\n\ts64 bfree;\n\tresv_blocks = EXT4_C2B(sbi, atomic64_read(&sbi->s_resv_clusters));\n\n\tif (!test_opt(sb, MINIX_DF))\n\t\toverhead = sbi->s_overhead;\n\n\tbuf->f_type = EXT4_SUPER_MAGIC;\n\tbuf->f_bsize = sb->s_blocksize;\n\tbuf->f_blocks = ext4_blocks_count(es) - EXT4_C2B(sbi, overhead);\n\tbfree = percpu_counter_sum_positive(&sbi->s_freeclusters_counter) -\n\t\tpercpu_counter_sum_positive(&sbi->s_dirtyclusters_counter);\n\t/* prevent underflow in case that few free space is available */\n\tbuf->f_bfree = EXT4_C2B(sbi, max_t(s64, bfree, 0));\n\tbuf->f_bavail = buf->f_bfree -\n\t\t\t(ext4_r_blocks_count(es) + resv_blocks);\n\tif (buf->f_bfree < (ext4_r_blocks_count(es) + resv_blocks))\n\t\tbuf->f_bavail = 0;\n\tbuf->f_files = le32_to_cpu(es->s_inodes_count);\n\tbuf->f_ffree = percpu_counter_sum_positive(&sbi->s_freeinodes_counter);\n\tbuf->f_namelen = EXT4_NAME_LEN;\n\tfsid = le64_to_cpup((void *)es->s_uuid) ^\n\t       le64_to_cpup((void *)es->s_uuid + sizeof(u64));\n\tbuf->f_fsid.val[0] = fsid & 0xFFFFFFFFUL;\n\tbuf->f_fsid.val[1] = (fsid >> 32) & 0xFFFFFFFFUL;\n\n#ifdef CONFIG_QUOTA\n\tif (ext4_test_inode_flag(dentry->d_inode, EXT4_INODE_PROJINHERIT) &&\n\t    sb_has_quota_limits_enabled(sb, PRJQUOTA))\n\t\text4_statfs_project(sb, EXT4_I(dentry->d_inode)->i_projid, buf);\n#endif\n\treturn 0;\n}\n\n/* Helper function for writing quotas on sync - we need to start transaction\n * before quota file is locked for write. Otherwise the are possible deadlocks:\n * Process 1                         Process 2\n * ext4_create()                     quota_sync()\n *   jbd2_journal_start()                  write_dquot()\n *   dquot_initialize()                         down(dqio_mutex)\n *     down(dqio_mutex)                    jbd2_journal_start()\n *\n */\n\n#ifdef CONFIG_QUOTA\n\nstatic inline struct inode *dquot_to_inode(struct dquot *dquot)\n{\n\treturn sb_dqopt(dquot->dq_sb)->files[dquot->dq_id.type];\n}\n\nstatic int ext4_write_dquot(struct dquot *dquot)\n{\n\tint ret, err;\n\thandle_t *handle;\n\tstruct inode *inode;\n\n\tinode = dquot_to_inode(dquot);\n\thandle = ext4_journal_start(inode, EXT4_HT_QUOTA,\n\t\t\t\t    EXT4_QUOTA_TRANS_BLOCKS(dquot->dq_sb));\n\tif (IS_ERR(handle))\n\t\treturn PTR_ERR(handle);\n\tret = dquot_commit(dquot);\n\terr = ext4_journal_stop(handle);\n\tif (!ret)\n\t\tret = err;\n\treturn ret;\n}\n\nstatic int ext4_acquire_dquot(struct dquot *dquot)\n{\n\tint ret, err;\n\thandle_t *handle;\n\n\thandle = ext4_journal_start(dquot_to_inode(dquot), EXT4_HT_QUOTA,\n\t\t\t\t    EXT4_QUOTA_INIT_BLOCKS(dquot->dq_sb));\n\tif (IS_ERR(handle))\n\t\treturn PTR_ERR(handle);\n\tret = dquot_acquire(dquot);\n\terr = ext4_journal_stop(handle);\n\tif (!ret)\n\t\tret = err;\n\treturn ret;\n}\n\nstatic int ext4_release_dquot(struct dquot *dquot)\n{\n\tint ret, err;\n\thandle_t *handle;\n\n\thandle = ext4_journal_start(dquot_to_inode(dquot), EXT4_HT_QUOTA,\n\t\t\t\t    EXT4_QUOTA_DEL_BLOCKS(dquot->dq_sb));\n\tif (IS_ERR(handle)) {\n\t\t/* Release dquot anyway to avoid endless cycle in dqput() */\n\t\tdquot_release(dquot);\n\t\treturn PTR_ERR(handle);\n\t}\n\tret = dquot_release(dquot);\n\terr = ext4_journal_stop(handle);\n\tif (!ret)\n\t\tret = err;\n\treturn ret;\n}\n\nstatic int ext4_mark_dquot_dirty(struct dquot *dquot)\n{\n\tstruct super_block *sb = dquot->dq_sb;\n\tstruct ext4_sb_info *sbi = EXT4_SB(sb);\n\n\t/* Are we journaling quotas? */\n\tif (ext4_has_feature_quota(sb) ||\n\t    sbi->s_qf_names[USRQUOTA] || sbi->s_qf_names[GRPQUOTA]) {\n\t\tdquot_mark_dquot_dirty(dquot);\n\t\treturn ext4_write_dquot(dquot);\n\t} else {\n\t\treturn dquot_mark_dquot_dirty(dquot);\n\t}\n}\n\nstatic int ext4_write_info(struct super_block *sb, int type)\n{\n\tint ret, err;\n\thandle_t *handle;\n\n\t/* Data block + inode block */\n\thandle = ext4_journal_start(d_inode(sb->s_root), EXT4_HT_QUOTA, 2);\n\tif (IS_ERR(handle))\n\t\treturn PTR_ERR(handle);\n\tret = dquot_commit_info(sb, type);\n\terr = ext4_journal_stop(handle);\n\tif (!ret)\n\t\tret = err;\n\treturn ret;\n}\n\n/*\n * Turn on quotas during mount time - we need to find\n * the quota file and such...\n */\nstatic int ext4_quota_on_mount(struct super_block *sb, int type)\n{\n\treturn dquot_quota_on_mount(sb, EXT4_SB(sb)->s_qf_names[type],\n\t\t\t\t\tEXT4_SB(sb)->s_jquota_fmt, type);\n}\n\nstatic void lockdep_set_quota_inode(struct inode *inode, int subclass)\n{\n\tstruct ext4_inode_info *ei = EXT4_I(inode);\n\n\t/* The first argument of lockdep_set_subclass has to be\n\t * *exactly* the same as the argument to init_rwsem() --- in\n\t * this case, in init_once() --- or lockdep gets unhappy\n\t * because the name of the lock is set using the\n\t * stringification of the argument to init_rwsem().\n\t */\n\t(void) ei;\t/* shut up clang warning if !CONFIG_LOCKDEP */\n\tlockdep_set_subclass(&ei->i_data_sem, subclass);\n}\n\n/*\n * Standard function to be called on quota_on\n */\nstatic int ext4_quota_on(struct super_block *sb, int type, int format_id,\n\t\t\t struct path *path)\n{\n\tint err;\n\n\tif (!test_opt(sb, QUOTA))\n\t\treturn -EINVAL;\n\n\t/* Quotafile not on the same filesystem? */\n\tif (path->dentry->d_sb != sb)\n\t\treturn -EXDEV;\n\t/* Journaling quota? */\n\tif (EXT4_SB(sb)->s_qf_names[type]) {\n\t\t/* Quotafile not in fs root? */\n\t\tif (path->dentry->d_parent != sb->s_root)\n\t\t\text4_msg(sb, KERN_WARNING,\n\t\t\t\t\"Quota file not on filesystem root. \"\n\t\t\t\t\"Journaled quota will not work\");\n\t}\n\n\t/*\n\t * When we journal data on quota file, we have to flush journal to see\n\t * all updates to the file when we bypass pagecache...\n\t */\n\tif (EXT4_SB(sb)->s_journal &&\n\t    ext4_should_journal_data(d_inode(path->dentry))) {\n\t\t/*\n\t\t * We don't need to lock updates but journal_flush() could\n\t\t * otherwise be livelocked...\n\t\t */\n\t\tjbd2_journal_lock_updates(EXT4_SB(sb)->s_journal);\n\t\terr = jbd2_journal_flush(EXT4_SB(sb)->s_journal);\n\t\tjbd2_journal_unlock_updates(EXT4_SB(sb)->s_journal);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\tlockdep_set_quota_inode(path->dentry->d_inode, I_DATA_SEM_QUOTA);\n\terr = dquot_quota_on(sb, type, format_id, path);\n\tif (err)\n\t\tlockdep_set_quota_inode(path->dentry->d_inode,\n\t\t\t\t\t     I_DATA_SEM_NORMAL);\n\treturn err;\n}\n\nstatic int ext4_quota_enable(struct super_block *sb, int type, int format_id,\n\t\t\t     unsigned int flags)\n{\n\tint err;\n\tstruct inode *qf_inode;\n\tunsigned long qf_inums[EXT4_MAXQUOTAS] = {\n\t\tle32_to_cpu(EXT4_SB(sb)->s_es->s_usr_quota_inum),\n\t\tle32_to_cpu(EXT4_SB(sb)->s_es->s_grp_quota_inum),\n\t\tle32_to_cpu(EXT4_SB(sb)->s_es->s_prj_quota_inum)\n\t};\n\n\tBUG_ON(!ext4_has_feature_quota(sb));\n\n\tif (!qf_inums[type])\n\t\treturn -EPERM;\n\n\tqf_inode = ext4_iget(sb, qf_inums[type]);\n\tif (IS_ERR(qf_inode)) {\n\t\text4_error(sb, \"Bad quota inode # %lu\", qf_inums[type]);\n\t\treturn PTR_ERR(qf_inode);\n\t}\n\n\t/* Don't account quota for quota files to avoid recursion */\n\tqf_inode->i_flags |= S_NOQUOTA;\n\tlockdep_set_quota_inode(qf_inode, I_DATA_SEM_QUOTA);\n\terr = dquot_enable(qf_inode, type, format_id, flags);\n\tiput(qf_inode);\n\tif (err)\n\t\tlockdep_set_quota_inode(qf_inode, I_DATA_SEM_NORMAL);\n\n\treturn err;\n}\n\n/* Enable usage tracking for all quota types. */\nstatic int ext4_enable_quotas(struct super_block *sb)\n{\n\tint type, err = 0;\n\tunsigned long qf_inums[EXT4_MAXQUOTAS] = {\n\t\tle32_to_cpu(EXT4_SB(sb)->s_es->s_usr_quota_inum),\n\t\tle32_to_cpu(EXT4_SB(sb)->s_es->s_grp_quota_inum),\n\t\tle32_to_cpu(EXT4_SB(sb)->s_es->s_prj_quota_inum)\n\t};\n\tbool quota_mopt[EXT4_MAXQUOTAS] = {\n\t\ttest_opt(sb, USRQUOTA),\n\t\ttest_opt(sb, GRPQUOTA),\n\t\ttest_opt(sb, PRJQUOTA),\n\t};\n\n\tsb_dqopt(sb)->flags |= DQUOT_QUOTA_SYS_FILE;\n\tfor (type = 0; type < EXT4_MAXQUOTAS; type++) {\n\t\tif (qf_inums[type]) {\n\t\t\terr = ext4_quota_enable(sb, type, QFMT_VFS_V1,\n\t\t\t\tDQUOT_USAGE_ENABLED |\n\t\t\t\t(quota_mopt[type] ? DQUOT_LIMITS_ENABLED : 0));\n\t\t\tif (err) {\n\t\t\t\text4_warning(sb,\n\t\t\t\t\t\"Failed to enable quota tracking \"\n\t\t\t\t\t\"(type=%d, err=%d). Please run \"\n\t\t\t\t\t\"e2fsck to fix.\", type, err);\n\t\t\t\treturn err;\n\t\t\t}\n\t\t}\n\t}\n\treturn 0;\n}\n\nstatic int ext4_quota_off(struct super_block *sb, int type)\n{\n\tstruct inode *inode = sb_dqopt(sb)->files[type];\n\thandle_t *handle;\n\n\t/* Force all delayed allocation blocks to be allocated.\n\t * Caller already holds s_umount sem */\n\tif (test_opt(sb, DELALLOC))\n\t\tsync_filesystem(sb);\n\n\tif (!inode)\n\t\tgoto out;\n\n\t/* Update modification times of quota files when userspace can\n\t * start looking at them */\n\thandle = ext4_journal_start(inode, EXT4_HT_QUOTA, 1);\n\tif (IS_ERR(handle))\n\t\tgoto out;\n\tinode->i_mtime = inode->i_ctime = current_time(inode);\n\text4_mark_inode_dirty(handle, inode);\n\text4_journal_stop(handle);\n\nout:\n\treturn dquot_quota_off(sb, type);\n}\n\n/* Read data from quotafile - avoid pagecache and such because we cannot afford\n * acquiring the locks... As quota files are never truncated and quota code\n * itself serializes the operations (and no one else should touch the files)\n * we don't have to be afraid of races */\nstatic ssize_t ext4_quota_read(struct super_block *sb, int type, char *data,\n\t\t\t       size_t len, loff_t off)\n{\n\tstruct inode *inode = sb_dqopt(sb)->files[type];\n\text4_lblk_t blk = off >> EXT4_BLOCK_SIZE_BITS(sb);\n\tint offset = off & (sb->s_blocksize - 1);\n\tint tocopy;\n\tsize_t toread;\n\tstruct buffer_head *bh;\n\tloff_t i_size = i_size_read(inode);\n\n\tif (off > i_size)\n\t\treturn 0;\n\tif (off+len > i_size)\n\t\tlen = i_size-off;\n\ttoread = len;\n\twhile (toread > 0) {\n\t\ttocopy = sb->s_blocksize - offset < toread ?\n\t\t\t\tsb->s_blocksize - offset : toread;\n\t\tbh = ext4_bread(NULL, inode, blk, 0);\n\t\tif (IS_ERR(bh))\n\t\t\treturn PTR_ERR(bh);\n\t\tif (!bh)\t/* A hole? */\n\t\t\tmemset(data, 0, tocopy);\n\t\telse\n\t\t\tmemcpy(data, bh->b_data+offset, tocopy);\n\t\tbrelse(bh);\n\t\toffset = 0;\n\t\ttoread -= tocopy;\n\t\tdata += tocopy;\n\t\tblk++;\n\t}\n\treturn len;\n}\n\n/* Write to quotafile (we know the transaction is already started and has\n * enough credits) */\nstatic ssize_t ext4_quota_write(struct super_block *sb, int type,\n\t\t\t\tconst char *data, size_t len, loff_t off)\n{\n\tstruct inode *inode = sb_dqopt(sb)->files[type];\n\text4_lblk_t blk = off >> EXT4_BLOCK_SIZE_BITS(sb);\n\tint err, offset = off & (sb->s_blocksize - 1);\n\tint retries = 0;\n\tstruct buffer_head *bh;\n\thandle_t *handle = journal_current_handle();\n\n\tif (EXT4_SB(sb)->s_journal && !handle) {\n\t\text4_msg(sb, KERN_WARNING, \"Quota write (off=%llu, len=%llu)\"\n\t\t\t\" cancelled because transaction is not started\",\n\t\t\t(unsigned long long)off, (unsigned long long)len);\n\t\treturn -EIO;\n\t}\n\t/*\n\t * Since we account only one data block in transaction credits,\n\t * then it is impossible to cross a block boundary.\n\t */\n\tif (sb->s_blocksize - offset < len) {\n\t\text4_msg(sb, KERN_WARNING, \"Quota write (off=%llu, len=%llu)\"\n\t\t\t\" cancelled because not block aligned\",\n\t\t\t(unsigned long long)off, (unsigned long long)len);\n\t\treturn -EIO;\n\t}\n\n\tdo {\n\t\tbh = ext4_bread(handle, inode, blk,\n\t\t\t\tEXT4_GET_BLOCKS_CREATE |\n\t\t\t\tEXT4_GET_BLOCKS_METADATA_NOFAIL);\n\t} while (IS_ERR(bh) && (PTR_ERR(bh) == -ENOSPC) &&\n\t\t ext4_should_retry_alloc(inode->i_sb, &retries));\n\tif (IS_ERR(bh))\n\t\treturn PTR_ERR(bh);\n\tif (!bh)\n\t\tgoto out;\n\tBUFFER_TRACE(bh, \"get write access\");\n\terr = ext4_journal_get_write_access(handle, bh);\n\tif (err) {\n\t\tbrelse(bh);\n\t\treturn err;\n\t}\n\tlock_buffer(bh);\n\tmemcpy(bh->b_data+offset, data, len);\n\tflush_dcache_page(bh->b_page);\n\tunlock_buffer(bh);\n\terr = ext4_handle_dirty_metadata(handle, NULL, bh);\n\tbrelse(bh);\nout:\n\tif (inode->i_size < off + len) {\n\t\ti_size_write(inode, off + len);\n\t\tEXT4_I(inode)->i_disksize = inode->i_size;\n\t\text4_mark_inode_dirty(handle, inode);\n\t}\n\treturn len;\n}\n\nstatic int ext4_get_next_id(struct super_block *sb, struct kqid *qid)\n{\n\tconst struct quota_format_ops\t*ops;\n\n\tif (!sb_has_quota_loaded(sb, qid->type))\n\t\treturn -ESRCH;\n\tops = sb_dqopt(sb)->ops[qid->type];\n\tif (!ops || !ops->get_next_id)\n\t\treturn -ENOSYS;\n\treturn dquot_get_next_id(sb, qid);\n}\n#endif\n\nstatic struct dentry *ext4_mount(struct file_system_type *fs_type, int flags,\n\t\t       const char *dev_name, void *data)\n{\n\treturn mount_bdev(fs_type, flags, dev_name, data, ext4_fill_super);\n}\n\n#if !defined(CONFIG_EXT2_FS) && !defined(CONFIG_EXT2_FS_MODULE) && defined(CONFIG_EXT4_USE_FOR_EXT2)\nstatic inline void register_as_ext2(void)\n{\n\tint err = register_filesystem(&ext2_fs_type);\n\tif (err)\n\t\tprintk(KERN_WARNING\n\t\t       \"EXT4-fs: Unable to register as ext2 (%d)\\n\", err);\n}\n\nstatic inline void unregister_as_ext2(void)\n{\n\tunregister_filesystem(&ext2_fs_type);\n}\n\nstatic inline int ext2_feature_set_ok(struct super_block *sb)\n{\n\tif (ext4_has_unknown_ext2_incompat_features(sb))\n\t\treturn 0;\n\tif (sb->s_flags & MS_RDONLY)\n\t\treturn 1;\n\tif (ext4_has_unknown_ext2_ro_compat_features(sb))\n\t\treturn 0;\n\treturn 1;\n}\n#else\nstatic inline void register_as_ext2(void) { }\nstatic inline void unregister_as_ext2(void) { }\nstatic inline int ext2_feature_set_ok(struct super_block *sb) { return 0; }\n#endif\n\nstatic inline void register_as_ext3(void)\n{\n\tint err = register_filesystem(&ext3_fs_type);\n\tif (err)\n\t\tprintk(KERN_WARNING\n\t\t       \"EXT4-fs: Unable to register as ext3 (%d)\\n\", err);\n}\n\nstatic inline void unregister_as_ext3(void)\n{\n\tunregister_filesystem(&ext3_fs_type);\n}\n\nstatic inline int ext3_feature_set_ok(struct super_block *sb)\n{\n\tif (ext4_has_unknown_ext3_incompat_features(sb))\n\t\treturn 0;\n\tif (!ext4_has_feature_journal(sb))\n\t\treturn 0;\n\tif (sb->s_flags & MS_RDONLY)\n\t\treturn 1;\n\tif (ext4_has_unknown_ext3_ro_compat_features(sb))\n\t\treturn 0;\n\treturn 1;\n}\n\nstatic struct file_system_type ext4_fs_type = {\n\t.owner\t\t= THIS_MODULE,\n\t.name\t\t= \"ext4\",\n\t.mount\t\t= ext4_mount,\n\t.kill_sb\t= kill_block_super,\n\t.fs_flags\t= FS_REQUIRES_DEV,\n};\nMODULE_ALIAS_FS(\"ext4\");\n\n/* Shared across all ext4 file systems */\nwait_queue_head_t ext4__ioend_wq[EXT4_WQ_HASH_SZ];\n\nstatic int __init ext4_init_fs(void)\n{\n\tint i, err;\n\n\tratelimit_state_init(&ext4_mount_msg_ratelimit, 30 * HZ, 64);\n\text4_li_info = NULL;\n\tmutex_init(&ext4_li_mtx);\n\n\t/* Build-time check for flags consistency */\n\text4_check_flag_values();\n\n\tfor (i = 0; i < EXT4_WQ_HASH_SZ; i++)\n\t\tinit_waitqueue_head(&ext4__ioend_wq[i]);\n\n\terr = ext4_init_es();\n\tif (err)\n\t\treturn err;\n\n\terr = ext4_init_pageio();\n\tif (err)\n\t\tgoto out5;\n\n\terr = ext4_init_system_zone();\n\tif (err)\n\t\tgoto out4;\n\n\terr = ext4_init_sysfs();\n\tif (err)\n\t\tgoto out3;\n\n\terr = ext4_init_mballoc();\n\tif (err)\n\t\tgoto out2;\n\terr = init_inodecache();\n\tif (err)\n\t\tgoto out1;\n\tregister_as_ext3();\n\tregister_as_ext2();\n\terr = register_filesystem(&ext4_fs_type);\n\tif (err)\n\t\tgoto out;\n\n\treturn 0;\nout:\n\tunregister_as_ext2();\n\tunregister_as_ext3();\n\tdestroy_inodecache();\nout1:\n\text4_exit_mballoc();\nout2:\n\text4_exit_sysfs();\nout3:\n\text4_exit_system_zone();\nout4:\n\text4_exit_pageio();\nout5:\n\text4_exit_es();\n\n\treturn err;\n}\n\nstatic void __exit ext4_exit_fs(void)\n{\n\text4_destroy_lazyinit_thread();\n\tunregister_as_ext2();\n\tunregister_as_ext3();\n\tunregister_filesystem(&ext4_fs_type);\n\tdestroy_inodecache();\n\text4_exit_mballoc();\n\text4_exit_sysfs();\n\text4_exit_system_zone();\n\text4_exit_pageio();\n\text4_exit_es();\n}\n\nMODULE_AUTHOR(\"Remy Card, Stephen Tweedie, Andrew Morton, Andreas Dilger, Theodore Ts'o and others\");\nMODULE_DESCRIPTION(\"Fourth Extended Filesystem\");\nMODULE_LICENSE(\"GPL\");\nmodule_init(ext4_init_fs)\nmodule_exit(ext4_exit_fs)\n"], "fixing_code": ["/*\n *  linux/fs/ext4/super.c\n *\n * Copyright (C) 1992, 1993, 1994, 1995\n * Remy Card (card@masi.ibp.fr)\n * Laboratoire MASI - Institut Blaise Pascal\n * Universite Pierre et Marie Curie (Paris VI)\n *\n *  from\n *\n *  linux/fs/minix/inode.c\n *\n *  Copyright (C) 1991, 1992  Linus Torvalds\n *\n *  Big-endian to little-endian byte-swapping/bitmaps by\n *        David S. Miller (davem@caip.rutgers.edu), 1995\n */\n\n#include <linux/module.h>\n#include <linux/string.h>\n#include <linux/fs.h>\n#include <linux/time.h>\n#include <linux/vmalloc.h>\n#include <linux/slab.h>\n#include <linux/init.h>\n#include <linux/blkdev.h>\n#include <linux/backing-dev.h>\n#include <linux/parser.h>\n#include <linux/buffer_head.h>\n#include <linux/exportfs.h>\n#include <linux/vfs.h>\n#include <linux/random.h>\n#include <linux/mount.h>\n#include <linux/namei.h>\n#include <linux/quotaops.h>\n#include <linux/seq_file.h>\n#include <linux/ctype.h>\n#include <linux/log2.h>\n#include <linux/crc16.h>\n#include <linux/cleancache.h>\n#include <asm/uaccess.h>\n\n#include <linux/kthread.h>\n#include <linux/freezer.h>\n\n#include \"ext4.h\"\n#include \"ext4_extents.h\"\t/* Needed for trace points definition */\n#include \"ext4_jbd2.h\"\n#include \"xattr.h\"\n#include \"acl.h\"\n#include \"mballoc.h\"\n\n#define CREATE_TRACE_POINTS\n#include <trace/events/ext4.h>\n\nstatic struct ext4_lazy_init *ext4_li_info;\nstatic struct mutex ext4_li_mtx;\nstatic struct ratelimit_state ext4_mount_msg_ratelimit;\n\nstatic int ext4_load_journal(struct super_block *, struct ext4_super_block *,\n\t\t\t     unsigned long journal_devnum);\nstatic int ext4_show_options(struct seq_file *seq, struct dentry *root);\nstatic int ext4_commit_super(struct super_block *sb, int sync);\nstatic void ext4_mark_recovery_complete(struct super_block *sb,\n\t\t\t\t\tstruct ext4_super_block *es);\nstatic void ext4_clear_journal_err(struct super_block *sb,\n\t\t\t\t   struct ext4_super_block *es);\nstatic int ext4_sync_fs(struct super_block *sb, int wait);\nstatic int ext4_remount(struct super_block *sb, int *flags, char *data);\nstatic int ext4_statfs(struct dentry *dentry, struct kstatfs *buf);\nstatic int ext4_unfreeze(struct super_block *sb);\nstatic int ext4_freeze(struct super_block *sb);\nstatic struct dentry *ext4_mount(struct file_system_type *fs_type, int flags,\n\t\t       const char *dev_name, void *data);\nstatic inline int ext2_feature_set_ok(struct super_block *sb);\nstatic inline int ext3_feature_set_ok(struct super_block *sb);\nstatic int ext4_feature_set_ok(struct super_block *sb, int readonly);\nstatic void ext4_destroy_lazyinit_thread(void);\nstatic void ext4_unregister_li_request(struct super_block *sb);\nstatic void ext4_clear_request_list(void);\nstatic struct inode *ext4_get_journal_inode(struct super_block *sb,\n\t\t\t\t\t    unsigned int journal_inum);\n\n/*\n * Lock ordering\n *\n * Note the difference between i_mmap_sem (EXT4_I(inode)->i_mmap_sem) and\n * i_mmap_rwsem (inode->i_mmap_rwsem)!\n *\n * page fault path:\n * mmap_sem -> sb_start_pagefault -> i_mmap_sem (r) -> transaction start ->\n *   page lock -> i_data_sem (rw)\n *\n * buffered write path:\n * sb_start_write -> i_mutex -> mmap_sem\n * sb_start_write -> i_mutex -> transaction start -> page lock ->\n *   i_data_sem (rw)\n *\n * truncate:\n * sb_start_write -> i_mutex -> EXT4_STATE_DIOREAD_LOCK (w) -> i_mmap_sem (w) ->\n *   i_mmap_rwsem (w) -> page lock\n * sb_start_write -> i_mutex -> EXT4_STATE_DIOREAD_LOCK (w) -> i_mmap_sem (w) ->\n *   transaction start -> i_data_sem (rw)\n *\n * direct IO:\n * sb_start_write -> i_mutex -> EXT4_STATE_DIOREAD_LOCK (r) -> mmap_sem\n * sb_start_write -> i_mutex -> EXT4_STATE_DIOREAD_LOCK (r) ->\n *   transaction start -> i_data_sem (rw)\n *\n * writepages:\n * transaction start -> page lock(s) -> i_data_sem (rw)\n */\n\n#if !defined(CONFIG_EXT2_FS) && !defined(CONFIG_EXT2_FS_MODULE) && defined(CONFIG_EXT4_USE_FOR_EXT2)\nstatic struct file_system_type ext2_fs_type = {\n\t.owner\t\t= THIS_MODULE,\n\t.name\t\t= \"ext2\",\n\t.mount\t\t= ext4_mount,\n\t.kill_sb\t= kill_block_super,\n\t.fs_flags\t= FS_REQUIRES_DEV,\n};\nMODULE_ALIAS_FS(\"ext2\");\nMODULE_ALIAS(\"ext2\");\n#define IS_EXT2_SB(sb) ((sb)->s_bdev->bd_holder == &ext2_fs_type)\n#else\n#define IS_EXT2_SB(sb) (0)\n#endif\n\n\nstatic struct file_system_type ext3_fs_type = {\n\t.owner\t\t= THIS_MODULE,\n\t.name\t\t= \"ext3\",\n\t.mount\t\t= ext4_mount,\n\t.kill_sb\t= kill_block_super,\n\t.fs_flags\t= FS_REQUIRES_DEV,\n};\nMODULE_ALIAS_FS(\"ext3\");\nMODULE_ALIAS(\"ext3\");\n#define IS_EXT3_SB(sb) ((sb)->s_bdev->bd_holder == &ext3_fs_type)\n\nstatic int ext4_verify_csum_type(struct super_block *sb,\n\t\t\t\t struct ext4_super_block *es)\n{\n\tif (!ext4_has_feature_metadata_csum(sb))\n\t\treturn 1;\n\n\treturn es->s_checksum_type == EXT4_CRC32C_CHKSUM;\n}\n\nstatic __le32 ext4_superblock_csum(struct super_block *sb,\n\t\t\t\t   struct ext4_super_block *es)\n{\n\tstruct ext4_sb_info *sbi = EXT4_SB(sb);\n\tint offset = offsetof(struct ext4_super_block, s_checksum);\n\t__u32 csum;\n\n\tcsum = ext4_chksum(sbi, ~0, (char *)es, offset);\n\n\treturn cpu_to_le32(csum);\n}\n\nstatic int ext4_superblock_csum_verify(struct super_block *sb,\n\t\t\t\t       struct ext4_super_block *es)\n{\n\tif (!ext4_has_metadata_csum(sb))\n\t\treturn 1;\n\n\treturn es->s_checksum == ext4_superblock_csum(sb, es);\n}\n\nvoid ext4_superblock_csum_set(struct super_block *sb)\n{\n\tstruct ext4_super_block *es = EXT4_SB(sb)->s_es;\n\n\tif (!ext4_has_metadata_csum(sb))\n\t\treturn;\n\n\tes->s_checksum = ext4_superblock_csum(sb, es);\n}\n\nvoid *ext4_kvmalloc(size_t size, gfp_t flags)\n{\n\tvoid *ret;\n\n\tret = kmalloc(size, flags | __GFP_NOWARN);\n\tif (!ret)\n\t\tret = __vmalloc(size, flags, PAGE_KERNEL);\n\treturn ret;\n}\n\nvoid *ext4_kvzalloc(size_t size, gfp_t flags)\n{\n\tvoid *ret;\n\n\tret = kzalloc(size, flags | __GFP_NOWARN);\n\tif (!ret)\n\t\tret = __vmalloc(size, flags | __GFP_ZERO, PAGE_KERNEL);\n\treturn ret;\n}\n\next4_fsblk_t ext4_block_bitmap(struct super_block *sb,\n\t\t\t       struct ext4_group_desc *bg)\n{\n\treturn le32_to_cpu(bg->bg_block_bitmap_lo) |\n\t\t(EXT4_DESC_SIZE(sb) >= EXT4_MIN_DESC_SIZE_64BIT ?\n\t\t (ext4_fsblk_t)le32_to_cpu(bg->bg_block_bitmap_hi) << 32 : 0);\n}\n\next4_fsblk_t ext4_inode_bitmap(struct super_block *sb,\n\t\t\t       struct ext4_group_desc *bg)\n{\n\treturn le32_to_cpu(bg->bg_inode_bitmap_lo) |\n\t\t(EXT4_DESC_SIZE(sb) >= EXT4_MIN_DESC_SIZE_64BIT ?\n\t\t (ext4_fsblk_t)le32_to_cpu(bg->bg_inode_bitmap_hi) << 32 : 0);\n}\n\next4_fsblk_t ext4_inode_table(struct super_block *sb,\n\t\t\t      struct ext4_group_desc *bg)\n{\n\treturn le32_to_cpu(bg->bg_inode_table_lo) |\n\t\t(EXT4_DESC_SIZE(sb) >= EXT4_MIN_DESC_SIZE_64BIT ?\n\t\t (ext4_fsblk_t)le32_to_cpu(bg->bg_inode_table_hi) << 32 : 0);\n}\n\n__u32 ext4_free_group_clusters(struct super_block *sb,\n\t\t\t       struct ext4_group_desc *bg)\n{\n\treturn le16_to_cpu(bg->bg_free_blocks_count_lo) |\n\t\t(EXT4_DESC_SIZE(sb) >= EXT4_MIN_DESC_SIZE_64BIT ?\n\t\t (__u32)le16_to_cpu(bg->bg_free_blocks_count_hi) << 16 : 0);\n}\n\n__u32 ext4_free_inodes_count(struct super_block *sb,\n\t\t\t      struct ext4_group_desc *bg)\n{\n\treturn le16_to_cpu(bg->bg_free_inodes_count_lo) |\n\t\t(EXT4_DESC_SIZE(sb) >= EXT4_MIN_DESC_SIZE_64BIT ?\n\t\t (__u32)le16_to_cpu(bg->bg_free_inodes_count_hi) << 16 : 0);\n}\n\n__u32 ext4_used_dirs_count(struct super_block *sb,\n\t\t\t      struct ext4_group_desc *bg)\n{\n\treturn le16_to_cpu(bg->bg_used_dirs_count_lo) |\n\t\t(EXT4_DESC_SIZE(sb) >= EXT4_MIN_DESC_SIZE_64BIT ?\n\t\t (__u32)le16_to_cpu(bg->bg_used_dirs_count_hi) << 16 : 0);\n}\n\n__u32 ext4_itable_unused_count(struct super_block *sb,\n\t\t\t      struct ext4_group_desc *bg)\n{\n\treturn le16_to_cpu(bg->bg_itable_unused_lo) |\n\t\t(EXT4_DESC_SIZE(sb) >= EXT4_MIN_DESC_SIZE_64BIT ?\n\t\t (__u32)le16_to_cpu(bg->bg_itable_unused_hi) << 16 : 0);\n}\n\nvoid ext4_block_bitmap_set(struct super_block *sb,\n\t\t\t   struct ext4_group_desc *bg, ext4_fsblk_t blk)\n{\n\tbg->bg_block_bitmap_lo = cpu_to_le32((u32)blk);\n\tif (EXT4_DESC_SIZE(sb) >= EXT4_MIN_DESC_SIZE_64BIT)\n\t\tbg->bg_block_bitmap_hi = cpu_to_le32(blk >> 32);\n}\n\nvoid ext4_inode_bitmap_set(struct super_block *sb,\n\t\t\t   struct ext4_group_desc *bg, ext4_fsblk_t blk)\n{\n\tbg->bg_inode_bitmap_lo  = cpu_to_le32((u32)blk);\n\tif (EXT4_DESC_SIZE(sb) >= EXT4_MIN_DESC_SIZE_64BIT)\n\t\tbg->bg_inode_bitmap_hi = cpu_to_le32(blk >> 32);\n}\n\nvoid ext4_inode_table_set(struct super_block *sb,\n\t\t\t  struct ext4_group_desc *bg, ext4_fsblk_t blk)\n{\n\tbg->bg_inode_table_lo = cpu_to_le32((u32)blk);\n\tif (EXT4_DESC_SIZE(sb) >= EXT4_MIN_DESC_SIZE_64BIT)\n\t\tbg->bg_inode_table_hi = cpu_to_le32(blk >> 32);\n}\n\nvoid ext4_free_group_clusters_set(struct super_block *sb,\n\t\t\t\t  struct ext4_group_desc *bg, __u32 count)\n{\n\tbg->bg_free_blocks_count_lo = cpu_to_le16((__u16)count);\n\tif (EXT4_DESC_SIZE(sb) >= EXT4_MIN_DESC_SIZE_64BIT)\n\t\tbg->bg_free_blocks_count_hi = cpu_to_le16(count >> 16);\n}\n\nvoid ext4_free_inodes_set(struct super_block *sb,\n\t\t\t  struct ext4_group_desc *bg, __u32 count)\n{\n\tbg->bg_free_inodes_count_lo = cpu_to_le16((__u16)count);\n\tif (EXT4_DESC_SIZE(sb) >= EXT4_MIN_DESC_SIZE_64BIT)\n\t\tbg->bg_free_inodes_count_hi = cpu_to_le16(count >> 16);\n}\n\nvoid ext4_used_dirs_set(struct super_block *sb,\n\t\t\t  struct ext4_group_desc *bg, __u32 count)\n{\n\tbg->bg_used_dirs_count_lo = cpu_to_le16((__u16)count);\n\tif (EXT4_DESC_SIZE(sb) >= EXT4_MIN_DESC_SIZE_64BIT)\n\t\tbg->bg_used_dirs_count_hi = cpu_to_le16(count >> 16);\n}\n\nvoid ext4_itable_unused_set(struct super_block *sb,\n\t\t\t  struct ext4_group_desc *bg, __u32 count)\n{\n\tbg->bg_itable_unused_lo = cpu_to_le16((__u16)count);\n\tif (EXT4_DESC_SIZE(sb) >= EXT4_MIN_DESC_SIZE_64BIT)\n\t\tbg->bg_itable_unused_hi = cpu_to_le16(count >> 16);\n}\n\n\nstatic void __save_error_info(struct super_block *sb, const char *func,\n\t\t\t    unsigned int line)\n{\n\tstruct ext4_super_block *es = EXT4_SB(sb)->s_es;\n\n\tEXT4_SB(sb)->s_mount_state |= EXT4_ERROR_FS;\n\tif (bdev_read_only(sb->s_bdev))\n\t\treturn;\n\tes->s_state |= cpu_to_le16(EXT4_ERROR_FS);\n\tes->s_last_error_time = cpu_to_le32(get_seconds());\n\tstrncpy(es->s_last_error_func, func, sizeof(es->s_last_error_func));\n\tes->s_last_error_line = cpu_to_le32(line);\n\tif (!es->s_first_error_time) {\n\t\tes->s_first_error_time = es->s_last_error_time;\n\t\tstrncpy(es->s_first_error_func, func,\n\t\t\tsizeof(es->s_first_error_func));\n\t\tes->s_first_error_line = cpu_to_le32(line);\n\t\tes->s_first_error_ino = es->s_last_error_ino;\n\t\tes->s_first_error_block = es->s_last_error_block;\n\t}\n\t/*\n\t * Start the daily error reporting function if it hasn't been\n\t * started already\n\t */\n\tif (!es->s_error_count)\n\t\tmod_timer(&EXT4_SB(sb)->s_err_report, jiffies + 24*60*60*HZ);\n\tle32_add_cpu(&es->s_error_count, 1);\n}\n\nstatic void save_error_info(struct super_block *sb, const char *func,\n\t\t\t    unsigned int line)\n{\n\t__save_error_info(sb, func, line);\n\text4_commit_super(sb, 1);\n}\n\n/*\n * The del_gendisk() function uninitializes the disk-specific data\n * structures, including the bdi structure, without telling anyone\n * else.  Once this happens, any attempt to call mark_buffer_dirty()\n * (for example, by ext4_commit_super), will cause a kernel OOPS.\n * This is a kludge to prevent these oops until we can put in a proper\n * hook in del_gendisk() to inform the VFS and file system layers.\n */\nstatic int block_device_ejected(struct super_block *sb)\n{\n\tstruct inode *bd_inode = sb->s_bdev->bd_inode;\n\tstruct backing_dev_info *bdi = inode_to_bdi(bd_inode);\n\n\treturn bdi->dev == NULL;\n}\n\nstatic void ext4_journal_commit_callback(journal_t *journal, transaction_t *txn)\n{\n\tstruct super_block\t\t*sb = journal->j_private;\n\tstruct ext4_sb_info\t\t*sbi = EXT4_SB(sb);\n\tint\t\t\t\terror = is_journal_aborted(journal);\n\tstruct ext4_journal_cb_entry\t*jce;\n\n\tBUG_ON(txn->t_state == T_FINISHED);\n\tspin_lock(&sbi->s_md_lock);\n\twhile (!list_empty(&txn->t_private_list)) {\n\t\tjce = list_entry(txn->t_private_list.next,\n\t\t\t\t struct ext4_journal_cb_entry, jce_list);\n\t\tlist_del_init(&jce->jce_list);\n\t\tspin_unlock(&sbi->s_md_lock);\n\t\tjce->jce_func(sb, jce, error);\n\t\tspin_lock(&sbi->s_md_lock);\n\t}\n\tspin_unlock(&sbi->s_md_lock);\n}\n\n/* Deal with the reporting of failure conditions on a filesystem such as\n * inconsistencies detected or read IO failures.\n *\n * On ext2, we can store the error state of the filesystem in the\n * superblock.  That is not possible on ext4, because we may have other\n * write ordering constraints on the superblock which prevent us from\n * writing it out straight away; and given that the journal is about to\n * be aborted, we can't rely on the current, or future, transactions to\n * write out the superblock safely.\n *\n * We'll just use the jbd2_journal_abort() error code to record an error in\n * the journal instead.  On recovery, the journal will complain about\n * that error until we've noted it down and cleared it.\n */\n\nstatic void ext4_handle_error(struct super_block *sb)\n{\n\tif (sb->s_flags & MS_RDONLY)\n\t\treturn;\n\n\tif (!test_opt(sb, ERRORS_CONT)) {\n\t\tjournal_t *journal = EXT4_SB(sb)->s_journal;\n\n\t\tEXT4_SB(sb)->s_mount_flags |= EXT4_MF_FS_ABORTED;\n\t\tif (journal)\n\t\t\tjbd2_journal_abort(journal, -EIO);\n\t}\n\tif (test_opt(sb, ERRORS_RO)) {\n\t\text4_msg(sb, KERN_CRIT, \"Remounting filesystem read-only\");\n\t\t/*\n\t\t * Make sure updated value of ->s_mount_flags will be visible\n\t\t * before ->s_flags update\n\t\t */\n\t\tsmp_wmb();\n\t\tsb->s_flags |= MS_RDONLY;\n\t}\n\tif (test_opt(sb, ERRORS_PANIC)) {\n\t\tif (EXT4_SB(sb)->s_journal &&\n\t\t  !(EXT4_SB(sb)->s_journal->j_flags & JBD2_REC_ERR))\n\t\t\treturn;\n\t\tpanic(\"EXT4-fs (device %s): panic forced after error\\n\",\n\t\t\tsb->s_id);\n\t}\n}\n\n#define ext4_error_ratelimit(sb)\t\t\t\t\t\\\n\t\t___ratelimit(&(EXT4_SB(sb)->s_err_ratelimit_state),\t\\\n\t\t\t     \"EXT4-fs error\")\n\nvoid __ext4_error(struct super_block *sb, const char *function,\n\t\t  unsigned int line, const char *fmt, ...)\n{\n\tstruct va_format vaf;\n\tva_list args;\n\n\tif (ext4_error_ratelimit(sb)) {\n\t\tva_start(args, fmt);\n\t\tvaf.fmt = fmt;\n\t\tvaf.va = &args;\n\t\tprintk(KERN_CRIT\n\t\t       \"EXT4-fs error (device %s): %s:%d: comm %s: %pV\\n\",\n\t\t       sb->s_id, function, line, current->comm, &vaf);\n\t\tva_end(args);\n\t}\n\tsave_error_info(sb, function, line);\n\text4_handle_error(sb);\n}\n\nvoid __ext4_error_inode(struct inode *inode, const char *function,\n\t\t\tunsigned int line, ext4_fsblk_t block,\n\t\t\tconst char *fmt, ...)\n{\n\tva_list args;\n\tstruct va_format vaf;\n\tstruct ext4_super_block *es = EXT4_SB(inode->i_sb)->s_es;\n\n\tes->s_last_error_ino = cpu_to_le32(inode->i_ino);\n\tes->s_last_error_block = cpu_to_le64(block);\n\tif (ext4_error_ratelimit(inode->i_sb)) {\n\t\tva_start(args, fmt);\n\t\tvaf.fmt = fmt;\n\t\tvaf.va = &args;\n\t\tif (block)\n\t\t\tprintk(KERN_CRIT \"EXT4-fs error (device %s): %s:%d: \"\n\t\t\t       \"inode #%lu: block %llu: comm %s: %pV\\n\",\n\t\t\t       inode->i_sb->s_id, function, line, inode->i_ino,\n\t\t\t       block, current->comm, &vaf);\n\t\telse\n\t\t\tprintk(KERN_CRIT \"EXT4-fs error (device %s): %s:%d: \"\n\t\t\t       \"inode #%lu: comm %s: %pV\\n\",\n\t\t\t       inode->i_sb->s_id, function, line, inode->i_ino,\n\t\t\t       current->comm, &vaf);\n\t\tva_end(args);\n\t}\n\tsave_error_info(inode->i_sb, function, line);\n\text4_handle_error(inode->i_sb);\n}\n\nvoid __ext4_error_file(struct file *file, const char *function,\n\t\t       unsigned int line, ext4_fsblk_t block,\n\t\t       const char *fmt, ...)\n{\n\tva_list args;\n\tstruct va_format vaf;\n\tstruct ext4_super_block *es;\n\tstruct inode *inode = file_inode(file);\n\tchar pathname[80], *path;\n\n\tes = EXT4_SB(inode->i_sb)->s_es;\n\tes->s_last_error_ino = cpu_to_le32(inode->i_ino);\n\tif (ext4_error_ratelimit(inode->i_sb)) {\n\t\tpath = file_path(file, pathname, sizeof(pathname));\n\t\tif (IS_ERR(path))\n\t\t\tpath = \"(unknown)\";\n\t\tva_start(args, fmt);\n\t\tvaf.fmt = fmt;\n\t\tvaf.va = &args;\n\t\tif (block)\n\t\t\tprintk(KERN_CRIT\n\t\t\t       \"EXT4-fs error (device %s): %s:%d: inode #%lu: \"\n\t\t\t       \"block %llu: comm %s: path %s: %pV\\n\",\n\t\t\t       inode->i_sb->s_id, function, line, inode->i_ino,\n\t\t\t       block, current->comm, path, &vaf);\n\t\telse\n\t\t\tprintk(KERN_CRIT\n\t\t\t       \"EXT4-fs error (device %s): %s:%d: inode #%lu: \"\n\t\t\t       \"comm %s: path %s: %pV\\n\",\n\t\t\t       inode->i_sb->s_id, function, line, inode->i_ino,\n\t\t\t       current->comm, path, &vaf);\n\t\tva_end(args);\n\t}\n\tsave_error_info(inode->i_sb, function, line);\n\text4_handle_error(inode->i_sb);\n}\n\nconst char *ext4_decode_error(struct super_block *sb, int errno,\n\t\t\t      char nbuf[16])\n{\n\tchar *errstr = NULL;\n\n\tswitch (errno) {\n\tcase -EFSCORRUPTED:\n\t\terrstr = \"Corrupt filesystem\";\n\t\tbreak;\n\tcase -EFSBADCRC:\n\t\terrstr = \"Filesystem failed CRC\";\n\t\tbreak;\n\tcase -EIO:\n\t\terrstr = \"IO failure\";\n\t\tbreak;\n\tcase -ENOMEM:\n\t\terrstr = \"Out of memory\";\n\t\tbreak;\n\tcase -EROFS:\n\t\tif (!sb || (EXT4_SB(sb)->s_journal &&\n\t\t\t    EXT4_SB(sb)->s_journal->j_flags & JBD2_ABORT))\n\t\t\terrstr = \"Journal has aborted\";\n\t\telse\n\t\t\terrstr = \"Readonly filesystem\";\n\t\tbreak;\n\tdefault:\n\t\t/* If the caller passed in an extra buffer for unknown\n\t\t * errors, textualise them now.  Else we just return\n\t\t * NULL. */\n\t\tif (nbuf) {\n\t\t\t/* Check for truncated error codes... */\n\t\t\tif (snprintf(nbuf, 16, \"error %d\", -errno) >= 0)\n\t\t\t\terrstr = nbuf;\n\t\t}\n\t\tbreak;\n\t}\n\n\treturn errstr;\n}\n\n/* __ext4_std_error decodes expected errors from journaling functions\n * automatically and invokes the appropriate error response.  */\n\nvoid __ext4_std_error(struct super_block *sb, const char *function,\n\t\t      unsigned int line, int errno)\n{\n\tchar nbuf[16];\n\tconst char *errstr;\n\n\t/* Special case: if the error is EROFS, and we're not already\n\t * inside a transaction, then there's really no point in logging\n\t * an error. */\n\tif (errno == -EROFS && journal_current_handle() == NULL &&\n\t    (sb->s_flags & MS_RDONLY))\n\t\treturn;\n\n\tif (ext4_error_ratelimit(sb)) {\n\t\terrstr = ext4_decode_error(sb, errno, nbuf);\n\t\tprintk(KERN_CRIT \"EXT4-fs error (device %s) in %s:%d: %s\\n\",\n\t\t       sb->s_id, function, line, errstr);\n\t}\n\n\tsave_error_info(sb, function, line);\n\text4_handle_error(sb);\n}\n\n/*\n * ext4_abort is a much stronger failure handler than ext4_error.  The\n * abort function may be used to deal with unrecoverable failures such\n * as journal IO errors or ENOMEM at a critical moment in log management.\n *\n * We unconditionally force the filesystem into an ABORT|READONLY state,\n * unless the error response on the fs has been set to panic in which\n * case we take the easy way out and panic immediately.\n */\n\nvoid __ext4_abort(struct super_block *sb, const char *function,\n\t\tunsigned int line, const char *fmt, ...)\n{\n\tstruct va_format vaf;\n\tva_list args;\n\n\tsave_error_info(sb, function, line);\n\tva_start(args, fmt);\n\tvaf.fmt = fmt;\n\tvaf.va = &args;\n\tprintk(KERN_CRIT \"EXT4-fs error (device %s): %s:%d: %pV\\n\",\n\t       sb->s_id, function, line, &vaf);\n\tva_end(args);\n\n\tif ((sb->s_flags & MS_RDONLY) == 0) {\n\t\text4_msg(sb, KERN_CRIT, \"Remounting filesystem read-only\");\n\t\tEXT4_SB(sb)->s_mount_flags |= EXT4_MF_FS_ABORTED;\n\t\t/*\n\t\t * Make sure updated value of ->s_mount_flags will be visible\n\t\t * before ->s_flags update\n\t\t */\n\t\tsmp_wmb();\n\t\tsb->s_flags |= MS_RDONLY;\n\t\tif (EXT4_SB(sb)->s_journal)\n\t\t\tjbd2_journal_abort(EXT4_SB(sb)->s_journal, -EIO);\n\t\tsave_error_info(sb, function, line);\n\t}\n\tif (test_opt(sb, ERRORS_PANIC)) {\n\t\tif (EXT4_SB(sb)->s_journal &&\n\t\t  !(EXT4_SB(sb)->s_journal->j_flags & JBD2_REC_ERR))\n\t\t\treturn;\n\t\tpanic(\"EXT4-fs panic from previous error\\n\");\n\t}\n}\n\nvoid __ext4_msg(struct super_block *sb,\n\t\tconst char *prefix, const char *fmt, ...)\n{\n\tstruct va_format vaf;\n\tva_list args;\n\n\tif (!___ratelimit(&(EXT4_SB(sb)->s_msg_ratelimit_state), \"EXT4-fs\"))\n\t\treturn;\n\n\tva_start(args, fmt);\n\tvaf.fmt = fmt;\n\tvaf.va = &args;\n\tprintk(\"%sEXT4-fs (%s): %pV\\n\", prefix, sb->s_id, &vaf);\n\tva_end(args);\n}\n\n#define ext4_warning_ratelimit(sb)\t\t\t\t\t\\\n\t\t___ratelimit(&(EXT4_SB(sb)->s_warning_ratelimit_state),\t\\\n\t\t\t     \"EXT4-fs warning\")\n\nvoid __ext4_warning(struct super_block *sb, const char *function,\n\t\t    unsigned int line, const char *fmt, ...)\n{\n\tstruct va_format vaf;\n\tva_list args;\n\n\tif (!ext4_warning_ratelimit(sb))\n\t\treturn;\n\n\tva_start(args, fmt);\n\tvaf.fmt = fmt;\n\tvaf.va = &args;\n\tprintk(KERN_WARNING \"EXT4-fs warning (device %s): %s:%d: %pV\\n\",\n\t       sb->s_id, function, line, &vaf);\n\tva_end(args);\n}\n\nvoid __ext4_warning_inode(const struct inode *inode, const char *function,\n\t\t\t  unsigned int line, const char *fmt, ...)\n{\n\tstruct va_format vaf;\n\tva_list args;\n\n\tif (!ext4_warning_ratelimit(inode->i_sb))\n\t\treturn;\n\n\tva_start(args, fmt);\n\tvaf.fmt = fmt;\n\tvaf.va = &args;\n\tprintk(KERN_WARNING \"EXT4-fs warning (device %s): %s:%d: \"\n\t       \"inode #%lu: comm %s: %pV\\n\", inode->i_sb->s_id,\n\t       function, line, inode->i_ino, current->comm, &vaf);\n\tva_end(args);\n}\n\nvoid __ext4_grp_locked_error(const char *function, unsigned int line,\n\t\t\t     struct super_block *sb, ext4_group_t grp,\n\t\t\t     unsigned long ino, ext4_fsblk_t block,\n\t\t\t     const char *fmt, ...)\n__releases(bitlock)\n__acquires(bitlock)\n{\n\tstruct va_format vaf;\n\tva_list args;\n\tstruct ext4_super_block *es = EXT4_SB(sb)->s_es;\n\n\tes->s_last_error_ino = cpu_to_le32(ino);\n\tes->s_last_error_block = cpu_to_le64(block);\n\t__save_error_info(sb, function, line);\n\n\tif (ext4_error_ratelimit(sb)) {\n\t\tva_start(args, fmt);\n\t\tvaf.fmt = fmt;\n\t\tvaf.va = &args;\n\t\tprintk(KERN_CRIT \"EXT4-fs error (device %s): %s:%d: group %u, \",\n\t\t       sb->s_id, function, line, grp);\n\t\tif (ino)\n\t\t\tprintk(KERN_CONT \"inode %lu: \", ino);\n\t\tif (block)\n\t\t\tprintk(KERN_CONT \"block %llu:\",\n\t\t\t       (unsigned long long) block);\n\t\tprintk(KERN_CONT \"%pV\\n\", &vaf);\n\t\tva_end(args);\n\t}\n\n\tif (test_opt(sb, ERRORS_CONT)) {\n\t\text4_commit_super(sb, 0);\n\t\treturn;\n\t}\n\n\text4_unlock_group(sb, grp);\n\text4_handle_error(sb);\n\t/*\n\t * We only get here in the ERRORS_RO case; relocking the group\n\t * may be dangerous, but nothing bad will happen since the\n\t * filesystem will have already been marked read/only and the\n\t * journal has been aborted.  We return 1 as a hint to callers\n\t * who might what to use the return value from\n\t * ext4_grp_locked_error() to distinguish between the\n\t * ERRORS_CONT and ERRORS_RO case, and perhaps return more\n\t * aggressively from the ext4 function in question, with a\n\t * more appropriate error code.\n\t */\n\text4_lock_group(sb, grp);\n\treturn;\n}\n\nvoid ext4_update_dynamic_rev(struct super_block *sb)\n{\n\tstruct ext4_super_block *es = EXT4_SB(sb)->s_es;\n\n\tif (le32_to_cpu(es->s_rev_level) > EXT4_GOOD_OLD_REV)\n\t\treturn;\n\n\text4_warning(sb,\n\t\t     \"updating to rev %d because of new feature flag, \"\n\t\t     \"running e2fsck is recommended\",\n\t\t     EXT4_DYNAMIC_REV);\n\n\tes->s_first_ino = cpu_to_le32(EXT4_GOOD_OLD_FIRST_INO);\n\tes->s_inode_size = cpu_to_le16(EXT4_GOOD_OLD_INODE_SIZE);\n\tes->s_rev_level = cpu_to_le32(EXT4_DYNAMIC_REV);\n\t/* leave es->s_feature_*compat flags alone */\n\t/* es->s_uuid will be set by e2fsck if empty */\n\n\t/*\n\t * The rest of the superblock fields should be zero, and if not it\n\t * means they are likely already in use, so leave them alone.  We\n\t * can leave it up to e2fsck to clean up any inconsistencies there.\n\t */\n}\n\n/*\n * Open the external journal device\n */\nstatic struct block_device *ext4_blkdev_get(dev_t dev, struct super_block *sb)\n{\n\tstruct block_device *bdev;\n\tchar b[BDEVNAME_SIZE];\n\n\tbdev = blkdev_get_by_dev(dev, FMODE_READ|FMODE_WRITE|FMODE_EXCL, sb);\n\tif (IS_ERR(bdev))\n\t\tgoto fail;\n\treturn bdev;\n\nfail:\n\text4_msg(sb, KERN_ERR, \"failed to open journal device %s: %ld\",\n\t\t\t__bdevname(dev, b), PTR_ERR(bdev));\n\treturn NULL;\n}\n\n/*\n * Release the journal device\n */\nstatic void ext4_blkdev_put(struct block_device *bdev)\n{\n\tblkdev_put(bdev, FMODE_READ|FMODE_WRITE|FMODE_EXCL);\n}\n\nstatic void ext4_blkdev_remove(struct ext4_sb_info *sbi)\n{\n\tstruct block_device *bdev;\n\tbdev = sbi->journal_bdev;\n\tif (bdev) {\n\t\text4_blkdev_put(bdev);\n\t\tsbi->journal_bdev = NULL;\n\t}\n}\n\nstatic inline struct inode *orphan_list_entry(struct list_head *l)\n{\n\treturn &list_entry(l, struct ext4_inode_info, i_orphan)->vfs_inode;\n}\n\nstatic void dump_orphan_list(struct super_block *sb, struct ext4_sb_info *sbi)\n{\n\tstruct list_head *l;\n\n\text4_msg(sb, KERN_ERR, \"sb orphan head is %d\",\n\t\t le32_to_cpu(sbi->s_es->s_last_orphan));\n\n\tprintk(KERN_ERR \"sb_info orphan list:\\n\");\n\tlist_for_each(l, &sbi->s_orphan) {\n\t\tstruct inode *inode = orphan_list_entry(l);\n\t\tprintk(KERN_ERR \"  \"\n\t\t       \"inode %s:%lu at %p: mode %o, nlink %d, next %d\\n\",\n\t\t       inode->i_sb->s_id, inode->i_ino, inode,\n\t\t       inode->i_mode, inode->i_nlink,\n\t\t       NEXT_ORPHAN(inode));\n\t}\n}\n\nstatic void ext4_put_super(struct super_block *sb)\n{\n\tstruct ext4_sb_info *sbi = EXT4_SB(sb);\n\tstruct ext4_super_block *es = sbi->s_es;\n\tint i, err;\n\n\text4_unregister_li_request(sb);\n\tdquot_disable(sb, -1, DQUOT_USAGE_ENABLED | DQUOT_LIMITS_ENABLED);\n\n\tflush_workqueue(sbi->rsv_conversion_wq);\n\tdestroy_workqueue(sbi->rsv_conversion_wq);\n\n\tif (sbi->s_journal) {\n\t\terr = jbd2_journal_destroy(sbi->s_journal);\n\t\tsbi->s_journal = NULL;\n\t\tif (err < 0)\n\t\t\text4_abort(sb, \"Couldn't clean up the journal\");\n\t}\n\n\text4_unregister_sysfs(sb);\n\text4_es_unregister_shrinker(sbi);\n\tdel_timer_sync(&sbi->s_err_report);\n\text4_release_system_zone(sb);\n\text4_mb_release(sb);\n\text4_ext_release(sb);\n\n\tif (!(sb->s_flags & MS_RDONLY)) {\n\t\text4_clear_feature_journal_needs_recovery(sb);\n\t\tes->s_state = cpu_to_le16(sbi->s_mount_state);\n\t}\n\tif (!(sb->s_flags & MS_RDONLY))\n\t\text4_commit_super(sb, 1);\n\n\tfor (i = 0; i < sbi->s_gdb_count; i++)\n\t\tbrelse(sbi->s_group_desc[i]);\n\tkvfree(sbi->s_group_desc);\n\tkvfree(sbi->s_flex_groups);\n\tpercpu_counter_destroy(&sbi->s_freeclusters_counter);\n\tpercpu_counter_destroy(&sbi->s_freeinodes_counter);\n\tpercpu_counter_destroy(&sbi->s_dirs_counter);\n\tpercpu_counter_destroy(&sbi->s_dirtyclusters_counter);\n\tpercpu_free_rwsem(&sbi->s_journal_flag_rwsem);\n#ifdef CONFIG_QUOTA\n\tfor (i = 0; i < EXT4_MAXQUOTAS; i++)\n\t\tkfree(sbi->s_qf_names[i]);\n#endif\n\n\t/* Debugging code just in case the in-memory inode orphan list\n\t * isn't empty.  The on-disk one can be non-empty if we've\n\t * detected an error and taken the fs readonly, but the\n\t * in-memory list had better be clean by this point. */\n\tif (!list_empty(&sbi->s_orphan))\n\t\tdump_orphan_list(sb, sbi);\n\tJ_ASSERT(list_empty(&sbi->s_orphan));\n\n\tsync_blockdev(sb->s_bdev);\n\tinvalidate_bdev(sb->s_bdev);\n\tif (sbi->journal_bdev && sbi->journal_bdev != sb->s_bdev) {\n\t\t/*\n\t\t * Invalidate the journal device's buffers.  We don't want them\n\t\t * floating about in memory - the physical journal device may\n\t\t * hotswapped, and it breaks the `ro-after' testing code.\n\t\t */\n\t\tsync_blockdev(sbi->journal_bdev);\n\t\tinvalidate_bdev(sbi->journal_bdev);\n\t\text4_blkdev_remove(sbi);\n\t}\n\tif (sbi->s_mb_cache) {\n\t\text4_xattr_destroy_cache(sbi->s_mb_cache);\n\t\tsbi->s_mb_cache = NULL;\n\t}\n\tif (sbi->s_mmp_tsk)\n\t\tkthread_stop(sbi->s_mmp_tsk);\n\tbrelse(sbi->s_sbh);\n\tsb->s_fs_info = NULL;\n\t/*\n\t * Now that we are completely done shutting down the\n\t * superblock, we need to actually destroy the kobject.\n\t */\n\tkobject_put(&sbi->s_kobj);\n\twait_for_completion(&sbi->s_kobj_unregister);\n\tif (sbi->s_chksum_driver)\n\t\tcrypto_free_shash(sbi->s_chksum_driver);\n\tkfree(sbi->s_blockgroup_lock);\n\tkfree(sbi);\n}\n\nstatic struct kmem_cache *ext4_inode_cachep;\n\n/*\n * Called inside transaction, so use GFP_NOFS\n */\nstatic struct inode *ext4_alloc_inode(struct super_block *sb)\n{\n\tstruct ext4_inode_info *ei;\n\n\tei = kmem_cache_alloc(ext4_inode_cachep, GFP_NOFS);\n\tif (!ei)\n\t\treturn NULL;\n\n\tei->vfs_inode.i_version = 1;\n\tspin_lock_init(&ei->i_raw_lock);\n\tINIT_LIST_HEAD(&ei->i_prealloc_list);\n\tspin_lock_init(&ei->i_prealloc_lock);\n\text4_es_init_tree(&ei->i_es_tree);\n\trwlock_init(&ei->i_es_lock);\n\tINIT_LIST_HEAD(&ei->i_es_list);\n\tei->i_es_all_nr = 0;\n\tei->i_es_shk_nr = 0;\n\tei->i_es_shrink_lblk = 0;\n\tei->i_reserved_data_blocks = 0;\n\tei->i_reserved_meta_blocks = 0;\n\tei->i_allocated_meta_blocks = 0;\n\tei->i_da_metadata_calc_len = 0;\n\tei->i_da_metadata_calc_last_lblock = 0;\n\tspin_lock_init(&(ei->i_block_reservation_lock));\n#ifdef CONFIG_QUOTA\n\tei->i_reserved_quota = 0;\n\tmemset(&ei->i_dquot, 0, sizeof(ei->i_dquot));\n#endif\n\tei->jinode = NULL;\n\tINIT_LIST_HEAD(&ei->i_rsv_conversion_list);\n\tspin_lock_init(&ei->i_completed_io_lock);\n\tei->i_sync_tid = 0;\n\tei->i_datasync_tid = 0;\n\tatomic_set(&ei->i_unwritten, 0);\n\tINIT_WORK(&ei->i_rsv_conversion_work, ext4_end_io_rsv_work);\n\treturn &ei->vfs_inode;\n}\n\nstatic int ext4_drop_inode(struct inode *inode)\n{\n\tint drop = generic_drop_inode(inode);\n\n\ttrace_ext4_drop_inode(inode, drop);\n\treturn drop;\n}\n\nstatic void ext4_i_callback(struct rcu_head *head)\n{\n\tstruct inode *inode = container_of(head, struct inode, i_rcu);\n\tkmem_cache_free(ext4_inode_cachep, EXT4_I(inode));\n}\n\nstatic void ext4_destroy_inode(struct inode *inode)\n{\n\tif (!list_empty(&(EXT4_I(inode)->i_orphan))) {\n\t\text4_msg(inode->i_sb, KERN_ERR,\n\t\t\t \"Inode %lu (%p): orphan list check failed!\",\n\t\t\t inode->i_ino, EXT4_I(inode));\n\t\tprint_hex_dump(KERN_INFO, \"\", DUMP_PREFIX_ADDRESS, 16, 4,\n\t\t\t\tEXT4_I(inode), sizeof(struct ext4_inode_info),\n\t\t\t\ttrue);\n\t\tdump_stack();\n\t}\n\tcall_rcu(&inode->i_rcu, ext4_i_callback);\n}\n\nstatic void init_once(void *foo)\n{\n\tstruct ext4_inode_info *ei = (struct ext4_inode_info *) foo;\n\n\tINIT_LIST_HEAD(&ei->i_orphan);\n\tinit_rwsem(&ei->xattr_sem);\n\tinit_rwsem(&ei->i_data_sem);\n\tinit_rwsem(&ei->i_mmap_sem);\n\tinode_init_once(&ei->vfs_inode);\n}\n\nstatic int __init init_inodecache(void)\n{\n\text4_inode_cachep = kmem_cache_create(\"ext4_inode_cache\",\n\t\t\t\t\t     sizeof(struct ext4_inode_info),\n\t\t\t\t\t     0, (SLAB_RECLAIM_ACCOUNT|\n\t\t\t\t\t\tSLAB_MEM_SPREAD|SLAB_ACCOUNT),\n\t\t\t\t\t     init_once);\n\tif (ext4_inode_cachep == NULL)\n\t\treturn -ENOMEM;\n\treturn 0;\n}\n\nstatic void destroy_inodecache(void)\n{\n\t/*\n\t * Make sure all delayed rcu free inodes are flushed before we\n\t * destroy cache.\n\t */\n\trcu_barrier();\n\tkmem_cache_destroy(ext4_inode_cachep);\n}\n\nvoid ext4_clear_inode(struct inode *inode)\n{\n\tinvalidate_inode_buffers(inode);\n\tclear_inode(inode);\n\tdquot_drop(inode);\n\text4_discard_preallocations(inode);\n\text4_es_remove_extent(inode, 0, EXT_MAX_BLOCKS);\n\tif (EXT4_I(inode)->jinode) {\n\t\tjbd2_journal_release_jbd_inode(EXT4_JOURNAL(inode),\n\t\t\t\t\t       EXT4_I(inode)->jinode);\n\t\tjbd2_free_inode(EXT4_I(inode)->jinode);\n\t\tEXT4_I(inode)->jinode = NULL;\n\t}\n#ifdef CONFIG_EXT4_FS_ENCRYPTION\n\tfscrypt_put_encryption_info(inode, NULL);\n#endif\n}\n\nstatic struct inode *ext4_nfs_get_inode(struct super_block *sb,\n\t\t\t\t\tu64 ino, u32 generation)\n{\n\tstruct inode *inode;\n\n\tif (ino < EXT4_FIRST_INO(sb) && ino != EXT4_ROOT_INO)\n\t\treturn ERR_PTR(-ESTALE);\n\tif (ino > le32_to_cpu(EXT4_SB(sb)->s_es->s_inodes_count))\n\t\treturn ERR_PTR(-ESTALE);\n\n\t/* iget isn't really right if the inode is currently unallocated!!\n\t *\n\t * ext4_read_inode will return a bad_inode if the inode had been\n\t * deleted, so we should be safe.\n\t *\n\t * Currently we don't know the generation for parent directory, so\n\t * a generation of 0 means \"accept any\"\n\t */\n\tinode = ext4_iget_normal(sb, ino);\n\tif (IS_ERR(inode))\n\t\treturn ERR_CAST(inode);\n\tif (generation && inode->i_generation != generation) {\n\t\tiput(inode);\n\t\treturn ERR_PTR(-ESTALE);\n\t}\n\n\treturn inode;\n}\n\nstatic struct dentry *ext4_fh_to_dentry(struct super_block *sb, struct fid *fid,\n\t\t\t\t\tint fh_len, int fh_type)\n{\n\treturn generic_fh_to_dentry(sb, fid, fh_len, fh_type,\n\t\t\t\t    ext4_nfs_get_inode);\n}\n\nstatic struct dentry *ext4_fh_to_parent(struct super_block *sb, struct fid *fid,\n\t\t\t\t\tint fh_len, int fh_type)\n{\n\treturn generic_fh_to_parent(sb, fid, fh_len, fh_type,\n\t\t\t\t    ext4_nfs_get_inode);\n}\n\n/*\n * Try to release metadata pages (indirect blocks, directories) which are\n * mapped via the block device.  Since these pages could have journal heads\n * which would prevent try_to_free_buffers() from freeing them, we must use\n * jbd2 layer's try_to_free_buffers() function to release them.\n */\nstatic int bdev_try_to_free_page(struct super_block *sb, struct page *page,\n\t\t\t\t gfp_t wait)\n{\n\tjournal_t *journal = EXT4_SB(sb)->s_journal;\n\n\tWARN_ON(PageChecked(page));\n\tif (!page_has_buffers(page))\n\t\treturn 0;\n\tif (journal)\n\t\treturn jbd2_journal_try_to_free_buffers(journal, page,\n\t\t\t\t\t\twait & ~__GFP_DIRECT_RECLAIM);\n\treturn try_to_free_buffers(page);\n}\n\n#ifdef CONFIG_EXT4_FS_ENCRYPTION\nstatic int ext4_get_context(struct inode *inode, void *ctx, size_t len)\n{\n\treturn ext4_xattr_get(inode, EXT4_XATTR_INDEX_ENCRYPTION,\n\t\t\t\t EXT4_XATTR_NAME_ENCRYPTION_CONTEXT, ctx, len);\n}\n\nstatic int ext4_key_prefix(struct inode *inode, u8 **key)\n{\n\t*key = EXT4_SB(inode->i_sb)->key_prefix;\n\treturn EXT4_SB(inode->i_sb)->key_prefix_size;\n}\n\nstatic int ext4_prepare_context(struct inode *inode)\n{\n\treturn ext4_convert_inline_data(inode);\n}\n\nstatic int ext4_set_context(struct inode *inode, const void *ctx, size_t len,\n\t\t\t\t\t\t\tvoid *fs_data)\n{\n\thandle_t *handle = fs_data;\n\tint res, res2, retries = 0;\n\n\t/*\n\t * If a journal handle was specified, then the encryption context is\n\t * being set on a new inode via inheritance and is part of a larger\n\t * transaction to create the inode.  Otherwise the encryption context is\n\t * being set on an existing inode in its own transaction.  Only in the\n\t * latter case should the \"retry on ENOSPC\" logic be used.\n\t */\n\n\tif (handle) {\n\t\tres = ext4_xattr_set_handle(handle, inode,\n\t\t\t\t\t    EXT4_XATTR_INDEX_ENCRYPTION,\n\t\t\t\t\t    EXT4_XATTR_NAME_ENCRYPTION_CONTEXT,\n\t\t\t\t\t    ctx, len, 0);\n\t\tif (!res) {\n\t\t\text4_set_inode_flag(inode, EXT4_INODE_ENCRYPT);\n\t\t\text4_clear_inode_state(inode,\n\t\t\t\t\tEXT4_STATE_MAY_INLINE_DATA);\n\t\t\t/*\n\t\t\t * Update inode->i_flags - e.g. S_DAX may get disabled\n\t\t\t */\n\t\t\text4_set_inode_flags(inode);\n\t\t}\n\t\treturn res;\n\t}\n\nretry:\n\thandle = ext4_journal_start(inode, EXT4_HT_MISC,\n\t\t\text4_jbd2_credits_xattr(inode));\n\tif (IS_ERR(handle))\n\t\treturn PTR_ERR(handle);\n\n\tres = ext4_xattr_set_handle(handle, inode, EXT4_XATTR_INDEX_ENCRYPTION,\n\t\t\t\t    EXT4_XATTR_NAME_ENCRYPTION_CONTEXT,\n\t\t\t\t    ctx, len, 0);\n\tif (!res) {\n\t\text4_set_inode_flag(inode, EXT4_INODE_ENCRYPT);\n\t\t/* Update inode->i_flags - e.g. S_DAX may get disabled */\n\t\text4_set_inode_flags(inode);\n\t\tres = ext4_mark_inode_dirty(handle, inode);\n\t\tif (res)\n\t\t\tEXT4_ERROR_INODE(inode, \"Failed to mark inode dirty\");\n\t}\n\tres2 = ext4_journal_stop(handle);\n\n\tif (res == -ENOSPC && ext4_should_retry_alloc(inode->i_sb, &retries))\n\t\tgoto retry;\n\tif (!res)\n\t\tres = res2;\n\treturn res;\n}\n\nstatic int ext4_dummy_context(struct inode *inode)\n{\n\treturn DUMMY_ENCRYPTION_ENABLED(EXT4_SB(inode->i_sb));\n}\n\nstatic unsigned ext4_max_namelen(struct inode *inode)\n{\n\treturn S_ISLNK(inode->i_mode) ? inode->i_sb->s_blocksize :\n\t\tEXT4_NAME_LEN;\n}\n\nstatic struct fscrypt_operations ext4_cryptops = {\n\t.get_context\t\t= ext4_get_context,\n\t.key_prefix\t\t= ext4_key_prefix,\n\t.prepare_context\t= ext4_prepare_context,\n\t.set_context\t\t= ext4_set_context,\n\t.dummy_context\t\t= ext4_dummy_context,\n\t.is_encrypted\t\t= ext4_encrypted_inode,\n\t.empty_dir\t\t= ext4_empty_dir,\n\t.max_namelen\t\t= ext4_max_namelen,\n};\n#else\nstatic struct fscrypt_operations ext4_cryptops = {\n\t.is_encrypted\t\t= ext4_encrypted_inode,\n};\n#endif\n\n#ifdef CONFIG_QUOTA\nstatic char *quotatypes[] = INITQFNAMES;\n#define QTYPE2NAME(t) (quotatypes[t])\n\nstatic int ext4_write_dquot(struct dquot *dquot);\nstatic int ext4_acquire_dquot(struct dquot *dquot);\nstatic int ext4_release_dquot(struct dquot *dquot);\nstatic int ext4_mark_dquot_dirty(struct dquot *dquot);\nstatic int ext4_write_info(struct super_block *sb, int type);\nstatic int ext4_quota_on(struct super_block *sb, int type, int format_id,\n\t\t\t struct path *path);\nstatic int ext4_quota_off(struct super_block *sb, int type);\nstatic int ext4_quota_on_mount(struct super_block *sb, int type);\nstatic ssize_t ext4_quota_read(struct super_block *sb, int type, char *data,\n\t\t\t       size_t len, loff_t off);\nstatic ssize_t ext4_quota_write(struct super_block *sb, int type,\n\t\t\t\tconst char *data, size_t len, loff_t off);\nstatic int ext4_quota_enable(struct super_block *sb, int type, int format_id,\n\t\t\t     unsigned int flags);\nstatic int ext4_enable_quotas(struct super_block *sb);\nstatic int ext4_get_next_id(struct super_block *sb, struct kqid *qid);\n\nstatic struct dquot **ext4_get_dquots(struct inode *inode)\n{\n\treturn EXT4_I(inode)->i_dquot;\n}\n\nstatic const struct dquot_operations ext4_quota_operations = {\n\t.get_reserved_space = ext4_get_reserved_space,\n\t.write_dquot\t= ext4_write_dquot,\n\t.acquire_dquot\t= ext4_acquire_dquot,\n\t.release_dquot\t= ext4_release_dquot,\n\t.mark_dirty\t= ext4_mark_dquot_dirty,\n\t.write_info\t= ext4_write_info,\n\t.alloc_dquot\t= dquot_alloc,\n\t.destroy_dquot\t= dquot_destroy,\n\t.get_projid\t= ext4_get_projid,\n\t.get_next_id\t= ext4_get_next_id,\n};\n\nstatic const struct quotactl_ops ext4_qctl_operations = {\n\t.quota_on\t= ext4_quota_on,\n\t.quota_off\t= ext4_quota_off,\n\t.quota_sync\t= dquot_quota_sync,\n\t.get_state\t= dquot_get_state,\n\t.set_info\t= dquot_set_dqinfo,\n\t.get_dqblk\t= dquot_get_dqblk,\n\t.set_dqblk\t= dquot_set_dqblk,\n\t.get_nextdqblk\t= dquot_get_next_dqblk,\n};\n#endif\n\nstatic const struct super_operations ext4_sops = {\n\t.alloc_inode\t= ext4_alloc_inode,\n\t.destroy_inode\t= ext4_destroy_inode,\n\t.write_inode\t= ext4_write_inode,\n\t.dirty_inode\t= ext4_dirty_inode,\n\t.drop_inode\t= ext4_drop_inode,\n\t.evict_inode\t= ext4_evict_inode,\n\t.put_super\t= ext4_put_super,\n\t.sync_fs\t= ext4_sync_fs,\n\t.freeze_fs\t= ext4_freeze,\n\t.unfreeze_fs\t= ext4_unfreeze,\n\t.statfs\t\t= ext4_statfs,\n\t.remount_fs\t= ext4_remount,\n\t.show_options\t= ext4_show_options,\n#ifdef CONFIG_QUOTA\n\t.quota_read\t= ext4_quota_read,\n\t.quota_write\t= ext4_quota_write,\n\t.get_dquots\t= ext4_get_dquots,\n#endif\n\t.bdev_try_to_free_page = bdev_try_to_free_page,\n};\n\nstatic const struct export_operations ext4_export_ops = {\n\t.fh_to_dentry = ext4_fh_to_dentry,\n\t.fh_to_parent = ext4_fh_to_parent,\n\t.get_parent = ext4_get_parent,\n};\n\nenum {\n\tOpt_bsd_df, Opt_minix_df, Opt_grpid, Opt_nogrpid,\n\tOpt_resgid, Opt_resuid, Opt_sb, Opt_err_cont, Opt_err_panic, Opt_err_ro,\n\tOpt_nouid32, Opt_debug, Opt_removed,\n\tOpt_user_xattr, Opt_nouser_xattr, Opt_acl, Opt_noacl,\n\tOpt_auto_da_alloc, Opt_noauto_da_alloc, Opt_noload,\n\tOpt_commit, Opt_min_batch_time, Opt_max_batch_time, Opt_journal_dev,\n\tOpt_journal_path, Opt_journal_checksum, Opt_journal_async_commit,\n\tOpt_abort, Opt_data_journal, Opt_data_ordered, Opt_data_writeback,\n\tOpt_data_err_abort, Opt_data_err_ignore, Opt_test_dummy_encryption,\n\tOpt_usrjquota, Opt_grpjquota, Opt_offusrjquota, Opt_offgrpjquota,\n\tOpt_jqfmt_vfsold, Opt_jqfmt_vfsv0, Opt_jqfmt_vfsv1, Opt_quota,\n\tOpt_noquota, Opt_barrier, Opt_nobarrier, Opt_err,\n\tOpt_usrquota, Opt_grpquota, Opt_prjquota, Opt_i_version, Opt_dax,\n\tOpt_stripe, Opt_delalloc, Opt_nodelalloc, Opt_mblk_io_submit,\n\tOpt_lazytime, Opt_nolazytime,\n\tOpt_nomblk_io_submit, Opt_block_validity, Opt_noblock_validity,\n\tOpt_inode_readahead_blks, Opt_journal_ioprio,\n\tOpt_dioread_nolock, Opt_dioread_lock,\n\tOpt_discard, Opt_nodiscard, Opt_init_itable, Opt_noinit_itable,\n\tOpt_max_dir_size_kb, Opt_nojournal_checksum,\n};\n\nstatic const match_table_t tokens = {\n\t{Opt_bsd_df, \"bsddf\"},\n\t{Opt_minix_df, \"minixdf\"},\n\t{Opt_grpid, \"grpid\"},\n\t{Opt_grpid, \"bsdgroups\"},\n\t{Opt_nogrpid, \"nogrpid\"},\n\t{Opt_nogrpid, \"sysvgroups\"},\n\t{Opt_resgid, \"resgid=%u\"},\n\t{Opt_resuid, \"resuid=%u\"},\n\t{Opt_sb, \"sb=%u\"},\n\t{Opt_err_cont, \"errors=continue\"},\n\t{Opt_err_panic, \"errors=panic\"},\n\t{Opt_err_ro, \"errors=remount-ro\"},\n\t{Opt_nouid32, \"nouid32\"},\n\t{Opt_debug, \"debug\"},\n\t{Opt_removed, \"oldalloc\"},\n\t{Opt_removed, \"orlov\"},\n\t{Opt_user_xattr, \"user_xattr\"},\n\t{Opt_nouser_xattr, \"nouser_xattr\"},\n\t{Opt_acl, \"acl\"},\n\t{Opt_noacl, \"noacl\"},\n\t{Opt_noload, \"norecovery\"},\n\t{Opt_noload, \"noload\"},\n\t{Opt_removed, \"nobh\"},\n\t{Opt_removed, \"bh\"},\n\t{Opt_commit, \"commit=%u\"},\n\t{Opt_min_batch_time, \"min_batch_time=%u\"},\n\t{Opt_max_batch_time, \"max_batch_time=%u\"},\n\t{Opt_journal_dev, \"journal_dev=%u\"},\n\t{Opt_journal_path, \"journal_path=%s\"},\n\t{Opt_journal_checksum, \"journal_checksum\"},\n\t{Opt_nojournal_checksum, \"nojournal_checksum\"},\n\t{Opt_journal_async_commit, \"journal_async_commit\"},\n\t{Opt_abort, \"abort\"},\n\t{Opt_data_journal, \"data=journal\"},\n\t{Opt_data_ordered, \"data=ordered\"},\n\t{Opt_data_writeback, \"data=writeback\"},\n\t{Opt_data_err_abort, \"data_err=abort\"},\n\t{Opt_data_err_ignore, \"data_err=ignore\"},\n\t{Opt_offusrjquota, \"usrjquota=\"},\n\t{Opt_usrjquota, \"usrjquota=%s\"},\n\t{Opt_offgrpjquota, \"grpjquota=\"},\n\t{Opt_grpjquota, \"grpjquota=%s\"},\n\t{Opt_jqfmt_vfsold, \"jqfmt=vfsold\"},\n\t{Opt_jqfmt_vfsv0, \"jqfmt=vfsv0\"},\n\t{Opt_jqfmt_vfsv1, \"jqfmt=vfsv1\"},\n\t{Opt_grpquota, \"grpquota\"},\n\t{Opt_noquota, \"noquota\"},\n\t{Opt_quota, \"quota\"},\n\t{Opt_usrquota, \"usrquota\"},\n\t{Opt_prjquota, \"prjquota\"},\n\t{Opt_barrier, \"barrier=%u\"},\n\t{Opt_barrier, \"barrier\"},\n\t{Opt_nobarrier, \"nobarrier\"},\n\t{Opt_i_version, \"i_version\"},\n\t{Opt_dax, \"dax\"},\n\t{Opt_stripe, \"stripe=%u\"},\n\t{Opt_delalloc, \"delalloc\"},\n\t{Opt_lazytime, \"lazytime\"},\n\t{Opt_nolazytime, \"nolazytime\"},\n\t{Opt_nodelalloc, \"nodelalloc\"},\n\t{Opt_removed, \"mblk_io_submit\"},\n\t{Opt_removed, \"nomblk_io_submit\"},\n\t{Opt_block_validity, \"block_validity\"},\n\t{Opt_noblock_validity, \"noblock_validity\"},\n\t{Opt_inode_readahead_blks, \"inode_readahead_blks=%u\"},\n\t{Opt_journal_ioprio, \"journal_ioprio=%u\"},\n\t{Opt_auto_da_alloc, \"auto_da_alloc=%u\"},\n\t{Opt_auto_da_alloc, \"auto_da_alloc\"},\n\t{Opt_noauto_da_alloc, \"noauto_da_alloc\"},\n\t{Opt_dioread_nolock, \"dioread_nolock\"},\n\t{Opt_dioread_lock, \"dioread_lock\"},\n\t{Opt_discard, \"discard\"},\n\t{Opt_nodiscard, \"nodiscard\"},\n\t{Opt_init_itable, \"init_itable=%u\"},\n\t{Opt_init_itable, \"init_itable\"},\n\t{Opt_noinit_itable, \"noinit_itable\"},\n\t{Opt_max_dir_size_kb, \"max_dir_size_kb=%u\"},\n\t{Opt_test_dummy_encryption, \"test_dummy_encryption\"},\n\t{Opt_removed, \"check=none\"},\t/* mount option from ext2/3 */\n\t{Opt_removed, \"nocheck\"},\t/* mount option from ext2/3 */\n\t{Opt_removed, \"reservation\"},\t/* mount option from ext2/3 */\n\t{Opt_removed, \"noreservation\"}, /* mount option from ext2/3 */\n\t{Opt_removed, \"journal=%u\"},\t/* mount option from ext2/3 */\n\t{Opt_err, NULL},\n};\n\nstatic ext4_fsblk_t get_sb_block(void **data)\n{\n\text4_fsblk_t\tsb_block;\n\tchar\t\t*options = (char *) *data;\n\n\tif (!options || strncmp(options, \"sb=\", 3) != 0)\n\t\treturn 1;\t/* Default location */\n\n\toptions += 3;\n\t/* TODO: use simple_strtoll with >32bit ext4 */\n\tsb_block = simple_strtoul(options, &options, 0);\n\tif (*options && *options != ',') {\n\t\tprintk(KERN_ERR \"EXT4-fs: Invalid sb specification: %s\\n\",\n\t\t       (char *) *data);\n\t\treturn 1;\n\t}\n\tif (*options == ',')\n\t\toptions++;\n\t*data = (void *) options;\n\n\treturn sb_block;\n}\n\n#define DEFAULT_JOURNAL_IOPRIO (IOPRIO_PRIO_VALUE(IOPRIO_CLASS_BE, 3))\nstatic char deprecated_msg[] = \"Mount option \\\"%s\\\" will be removed by %s\\n\"\n\t\"Contact linux-ext4@vger.kernel.org if you think we should keep it.\\n\";\n\n#ifdef CONFIG_QUOTA\nstatic int set_qf_name(struct super_block *sb, int qtype, substring_t *args)\n{\n\tstruct ext4_sb_info *sbi = EXT4_SB(sb);\n\tchar *qname;\n\tint ret = -1;\n\n\tif (sb_any_quota_loaded(sb) &&\n\t\t!sbi->s_qf_names[qtype]) {\n\t\text4_msg(sb, KERN_ERR,\n\t\t\t\"Cannot change journaled \"\n\t\t\t\"quota options when quota turned on\");\n\t\treturn -1;\n\t}\n\tif (ext4_has_feature_quota(sb)) {\n\t\text4_msg(sb, KERN_INFO, \"Journaled quota options \"\n\t\t\t \"ignored when QUOTA feature is enabled\");\n\t\treturn 1;\n\t}\n\tqname = match_strdup(args);\n\tif (!qname) {\n\t\text4_msg(sb, KERN_ERR,\n\t\t\t\"Not enough memory for storing quotafile name\");\n\t\treturn -1;\n\t}\n\tif (sbi->s_qf_names[qtype]) {\n\t\tif (strcmp(sbi->s_qf_names[qtype], qname) == 0)\n\t\t\tret = 1;\n\t\telse\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t\t \"%s quota file already specified\",\n\t\t\t\t QTYPE2NAME(qtype));\n\t\tgoto errout;\n\t}\n\tif (strchr(qname, '/')) {\n\t\text4_msg(sb, KERN_ERR,\n\t\t\t\"quotafile must be on filesystem root\");\n\t\tgoto errout;\n\t}\n\tsbi->s_qf_names[qtype] = qname;\n\tset_opt(sb, QUOTA);\n\treturn 1;\nerrout:\n\tkfree(qname);\n\treturn ret;\n}\n\nstatic int clear_qf_name(struct super_block *sb, int qtype)\n{\n\n\tstruct ext4_sb_info *sbi = EXT4_SB(sb);\n\n\tif (sb_any_quota_loaded(sb) &&\n\t\tsbi->s_qf_names[qtype]) {\n\t\text4_msg(sb, KERN_ERR, \"Cannot change journaled quota options\"\n\t\t\t\" when quota turned on\");\n\t\treturn -1;\n\t}\n\tkfree(sbi->s_qf_names[qtype]);\n\tsbi->s_qf_names[qtype] = NULL;\n\treturn 1;\n}\n#endif\n\n#define MOPT_SET\t0x0001\n#define MOPT_CLEAR\t0x0002\n#define MOPT_NOSUPPORT\t0x0004\n#define MOPT_EXPLICIT\t0x0008\n#define MOPT_CLEAR_ERR\t0x0010\n#define MOPT_GTE0\t0x0020\n#ifdef CONFIG_QUOTA\n#define MOPT_Q\t\t0\n#define MOPT_QFMT\t0x0040\n#else\n#define MOPT_Q\t\tMOPT_NOSUPPORT\n#define MOPT_QFMT\tMOPT_NOSUPPORT\n#endif\n#define MOPT_DATAJ\t0x0080\n#define MOPT_NO_EXT2\t0x0100\n#define MOPT_NO_EXT3\t0x0200\n#define MOPT_EXT4_ONLY\t(MOPT_NO_EXT2 | MOPT_NO_EXT3)\n#define MOPT_STRING\t0x0400\n\nstatic const struct mount_opts {\n\tint\ttoken;\n\tint\tmount_opt;\n\tint\tflags;\n} ext4_mount_opts[] = {\n\t{Opt_minix_df, EXT4_MOUNT_MINIX_DF, MOPT_SET},\n\t{Opt_bsd_df, EXT4_MOUNT_MINIX_DF, MOPT_CLEAR},\n\t{Opt_grpid, EXT4_MOUNT_GRPID, MOPT_SET},\n\t{Opt_nogrpid, EXT4_MOUNT_GRPID, MOPT_CLEAR},\n\t{Opt_block_validity, EXT4_MOUNT_BLOCK_VALIDITY, MOPT_SET},\n\t{Opt_noblock_validity, EXT4_MOUNT_BLOCK_VALIDITY, MOPT_CLEAR},\n\t{Opt_dioread_nolock, EXT4_MOUNT_DIOREAD_NOLOCK,\n\t MOPT_EXT4_ONLY | MOPT_SET},\n\t{Opt_dioread_lock, EXT4_MOUNT_DIOREAD_NOLOCK,\n\t MOPT_EXT4_ONLY | MOPT_CLEAR},\n\t{Opt_discard, EXT4_MOUNT_DISCARD, MOPT_SET},\n\t{Opt_nodiscard, EXT4_MOUNT_DISCARD, MOPT_CLEAR},\n\t{Opt_delalloc, EXT4_MOUNT_DELALLOC,\n\t MOPT_EXT4_ONLY | MOPT_SET | MOPT_EXPLICIT},\n\t{Opt_nodelalloc, EXT4_MOUNT_DELALLOC,\n\t MOPT_EXT4_ONLY | MOPT_CLEAR},\n\t{Opt_nojournal_checksum, EXT4_MOUNT_JOURNAL_CHECKSUM,\n\t MOPT_EXT4_ONLY | MOPT_CLEAR},\n\t{Opt_journal_checksum, EXT4_MOUNT_JOURNAL_CHECKSUM,\n\t MOPT_EXT4_ONLY | MOPT_SET | MOPT_EXPLICIT},\n\t{Opt_journal_async_commit, (EXT4_MOUNT_JOURNAL_ASYNC_COMMIT |\n\t\t\t\t    EXT4_MOUNT_JOURNAL_CHECKSUM),\n\t MOPT_EXT4_ONLY | MOPT_SET | MOPT_EXPLICIT},\n\t{Opt_noload, EXT4_MOUNT_NOLOAD, MOPT_NO_EXT2 | MOPT_SET},\n\t{Opt_err_panic, EXT4_MOUNT_ERRORS_PANIC, MOPT_SET | MOPT_CLEAR_ERR},\n\t{Opt_err_ro, EXT4_MOUNT_ERRORS_RO, MOPT_SET | MOPT_CLEAR_ERR},\n\t{Opt_err_cont, EXT4_MOUNT_ERRORS_CONT, MOPT_SET | MOPT_CLEAR_ERR},\n\t{Opt_data_err_abort, EXT4_MOUNT_DATA_ERR_ABORT,\n\t MOPT_NO_EXT2},\n\t{Opt_data_err_ignore, EXT4_MOUNT_DATA_ERR_ABORT,\n\t MOPT_NO_EXT2},\n\t{Opt_barrier, EXT4_MOUNT_BARRIER, MOPT_SET},\n\t{Opt_nobarrier, EXT4_MOUNT_BARRIER, MOPT_CLEAR},\n\t{Opt_noauto_da_alloc, EXT4_MOUNT_NO_AUTO_DA_ALLOC, MOPT_SET},\n\t{Opt_auto_da_alloc, EXT4_MOUNT_NO_AUTO_DA_ALLOC, MOPT_CLEAR},\n\t{Opt_noinit_itable, EXT4_MOUNT_INIT_INODE_TABLE, MOPT_CLEAR},\n\t{Opt_commit, 0, MOPT_GTE0},\n\t{Opt_max_batch_time, 0, MOPT_GTE0},\n\t{Opt_min_batch_time, 0, MOPT_GTE0},\n\t{Opt_inode_readahead_blks, 0, MOPT_GTE0},\n\t{Opt_init_itable, 0, MOPT_GTE0},\n\t{Opt_dax, EXT4_MOUNT_DAX, MOPT_SET},\n\t{Opt_stripe, 0, MOPT_GTE0},\n\t{Opt_resuid, 0, MOPT_GTE0},\n\t{Opt_resgid, 0, MOPT_GTE0},\n\t{Opt_journal_dev, 0, MOPT_NO_EXT2 | MOPT_GTE0},\n\t{Opt_journal_path, 0, MOPT_NO_EXT2 | MOPT_STRING},\n\t{Opt_journal_ioprio, 0, MOPT_NO_EXT2 | MOPT_GTE0},\n\t{Opt_data_journal, EXT4_MOUNT_JOURNAL_DATA, MOPT_NO_EXT2 | MOPT_DATAJ},\n\t{Opt_data_ordered, EXT4_MOUNT_ORDERED_DATA, MOPT_NO_EXT2 | MOPT_DATAJ},\n\t{Opt_data_writeback, EXT4_MOUNT_WRITEBACK_DATA,\n\t MOPT_NO_EXT2 | MOPT_DATAJ},\n\t{Opt_user_xattr, EXT4_MOUNT_XATTR_USER, MOPT_SET},\n\t{Opt_nouser_xattr, EXT4_MOUNT_XATTR_USER, MOPT_CLEAR},\n#ifdef CONFIG_EXT4_FS_POSIX_ACL\n\t{Opt_acl, EXT4_MOUNT_POSIX_ACL, MOPT_SET},\n\t{Opt_noacl, EXT4_MOUNT_POSIX_ACL, MOPT_CLEAR},\n#else\n\t{Opt_acl, 0, MOPT_NOSUPPORT},\n\t{Opt_noacl, 0, MOPT_NOSUPPORT},\n#endif\n\t{Opt_nouid32, EXT4_MOUNT_NO_UID32, MOPT_SET},\n\t{Opt_debug, EXT4_MOUNT_DEBUG, MOPT_SET},\n\t{Opt_quota, EXT4_MOUNT_QUOTA | EXT4_MOUNT_USRQUOTA, MOPT_SET | MOPT_Q},\n\t{Opt_usrquota, EXT4_MOUNT_QUOTA | EXT4_MOUNT_USRQUOTA,\n\t\t\t\t\t\t\tMOPT_SET | MOPT_Q},\n\t{Opt_grpquota, EXT4_MOUNT_QUOTA | EXT4_MOUNT_GRPQUOTA,\n\t\t\t\t\t\t\tMOPT_SET | MOPT_Q},\n\t{Opt_prjquota, EXT4_MOUNT_QUOTA | EXT4_MOUNT_PRJQUOTA,\n\t\t\t\t\t\t\tMOPT_SET | MOPT_Q},\n\t{Opt_noquota, (EXT4_MOUNT_QUOTA | EXT4_MOUNT_USRQUOTA |\n\t\t       EXT4_MOUNT_GRPQUOTA | EXT4_MOUNT_PRJQUOTA),\n\t\t\t\t\t\t\tMOPT_CLEAR | MOPT_Q},\n\t{Opt_usrjquota, 0, MOPT_Q},\n\t{Opt_grpjquota, 0, MOPT_Q},\n\t{Opt_offusrjquota, 0, MOPT_Q},\n\t{Opt_offgrpjquota, 0, MOPT_Q},\n\t{Opt_jqfmt_vfsold, QFMT_VFS_OLD, MOPT_QFMT},\n\t{Opt_jqfmt_vfsv0, QFMT_VFS_V0, MOPT_QFMT},\n\t{Opt_jqfmt_vfsv1, QFMT_VFS_V1, MOPT_QFMT},\n\t{Opt_max_dir_size_kb, 0, MOPT_GTE0},\n\t{Opt_test_dummy_encryption, 0, MOPT_GTE0},\n\t{Opt_err, 0, 0}\n};\n\nstatic int handle_mount_opt(struct super_block *sb, char *opt, int token,\n\t\t\t    substring_t *args, unsigned long *journal_devnum,\n\t\t\t    unsigned int *journal_ioprio, int is_remount)\n{\n\tstruct ext4_sb_info *sbi = EXT4_SB(sb);\n\tconst struct mount_opts *m;\n\tkuid_t uid;\n\tkgid_t gid;\n\tint arg = 0;\n\n#ifdef CONFIG_QUOTA\n\tif (token == Opt_usrjquota)\n\t\treturn set_qf_name(sb, USRQUOTA, &args[0]);\n\telse if (token == Opt_grpjquota)\n\t\treturn set_qf_name(sb, GRPQUOTA, &args[0]);\n\telse if (token == Opt_offusrjquota)\n\t\treturn clear_qf_name(sb, USRQUOTA);\n\telse if (token == Opt_offgrpjquota)\n\t\treturn clear_qf_name(sb, GRPQUOTA);\n#endif\n\tswitch (token) {\n\tcase Opt_noacl:\n\tcase Opt_nouser_xattr:\n\t\text4_msg(sb, KERN_WARNING, deprecated_msg, opt, \"3.5\");\n\t\tbreak;\n\tcase Opt_sb:\n\t\treturn 1;\t/* handled by get_sb_block() */\n\tcase Opt_removed:\n\t\text4_msg(sb, KERN_WARNING, \"Ignoring removed %s option\", opt);\n\t\treturn 1;\n\tcase Opt_abort:\n\t\tsbi->s_mount_flags |= EXT4_MF_FS_ABORTED;\n\t\treturn 1;\n\tcase Opt_i_version:\n\t\tsb->s_flags |= MS_I_VERSION;\n\t\treturn 1;\n\tcase Opt_lazytime:\n\t\tsb->s_flags |= MS_LAZYTIME;\n\t\treturn 1;\n\tcase Opt_nolazytime:\n\t\tsb->s_flags &= ~MS_LAZYTIME;\n\t\treturn 1;\n\t}\n\n\tfor (m = ext4_mount_opts; m->token != Opt_err; m++)\n\t\tif (token == m->token)\n\t\t\tbreak;\n\n\tif (m->token == Opt_err) {\n\t\text4_msg(sb, KERN_ERR, \"Unrecognized mount option \\\"%s\\\" \"\n\t\t\t \"or missing value\", opt);\n\t\treturn -1;\n\t}\n\n\tif ((m->flags & MOPT_NO_EXT2) && IS_EXT2_SB(sb)) {\n\t\text4_msg(sb, KERN_ERR,\n\t\t\t \"Mount option \\\"%s\\\" incompatible with ext2\", opt);\n\t\treturn -1;\n\t}\n\tif ((m->flags & MOPT_NO_EXT3) && IS_EXT3_SB(sb)) {\n\t\text4_msg(sb, KERN_ERR,\n\t\t\t \"Mount option \\\"%s\\\" incompatible with ext3\", opt);\n\t\treturn -1;\n\t}\n\n\tif (args->from && !(m->flags & MOPT_STRING) && match_int(args, &arg))\n\t\treturn -1;\n\tif (args->from && (m->flags & MOPT_GTE0) && (arg < 0))\n\t\treturn -1;\n\tif (m->flags & MOPT_EXPLICIT) {\n\t\tif (m->mount_opt & EXT4_MOUNT_DELALLOC) {\n\t\t\tset_opt2(sb, EXPLICIT_DELALLOC);\n\t\t} else if (m->mount_opt & EXT4_MOUNT_JOURNAL_CHECKSUM) {\n\t\t\tset_opt2(sb, EXPLICIT_JOURNAL_CHECKSUM);\n\t\t} else\n\t\t\treturn -1;\n\t}\n\tif (m->flags & MOPT_CLEAR_ERR)\n\t\tclear_opt(sb, ERRORS_MASK);\n\tif (token == Opt_noquota && sb_any_quota_loaded(sb)) {\n\t\text4_msg(sb, KERN_ERR, \"Cannot change quota \"\n\t\t\t \"options when quota turned on\");\n\t\treturn -1;\n\t}\n\n\tif (m->flags & MOPT_NOSUPPORT) {\n\t\text4_msg(sb, KERN_ERR, \"%s option not supported\", opt);\n\t} else if (token == Opt_commit) {\n\t\tif (arg == 0)\n\t\t\targ = JBD2_DEFAULT_MAX_COMMIT_AGE;\n\t\tsbi->s_commit_interval = HZ * arg;\n\t} else if (token == Opt_max_batch_time) {\n\t\tsbi->s_max_batch_time = arg;\n\t} else if (token == Opt_min_batch_time) {\n\t\tsbi->s_min_batch_time = arg;\n\t} else if (token == Opt_inode_readahead_blks) {\n\t\tif (arg && (arg > (1 << 30) || !is_power_of_2(arg))) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t\t \"EXT4-fs: inode_readahead_blks must be \"\n\t\t\t\t \"0 or a power of 2 smaller than 2^31\");\n\t\t\treturn -1;\n\t\t}\n\t\tsbi->s_inode_readahead_blks = arg;\n\t} else if (token == Opt_init_itable) {\n\t\tset_opt(sb, INIT_INODE_TABLE);\n\t\tif (!args->from)\n\t\t\targ = EXT4_DEF_LI_WAIT_MULT;\n\t\tsbi->s_li_wait_mult = arg;\n\t} else if (token == Opt_max_dir_size_kb) {\n\t\tsbi->s_max_dir_size_kb = arg;\n\t} else if (token == Opt_stripe) {\n\t\tsbi->s_stripe = arg;\n\t} else if (token == Opt_resuid) {\n\t\tuid = make_kuid(current_user_ns(), arg);\n\t\tif (!uid_valid(uid)) {\n\t\t\text4_msg(sb, KERN_ERR, \"Invalid uid value %d\", arg);\n\t\t\treturn -1;\n\t\t}\n\t\tsbi->s_resuid = uid;\n\t} else if (token == Opt_resgid) {\n\t\tgid = make_kgid(current_user_ns(), arg);\n\t\tif (!gid_valid(gid)) {\n\t\t\text4_msg(sb, KERN_ERR, \"Invalid gid value %d\", arg);\n\t\t\treturn -1;\n\t\t}\n\t\tsbi->s_resgid = gid;\n\t} else if (token == Opt_journal_dev) {\n\t\tif (is_remount) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t\t \"Cannot specify journal on remount\");\n\t\t\treturn -1;\n\t\t}\n\t\t*journal_devnum = arg;\n\t} else if (token == Opt_journal_path) {\n\t\tchar *journal_path;\n\t\tstruct inode *journal_inode;\n\t\tstruct path path;\n\t\tint error;\n\n\t\tif (is_remount) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t\t \"Cannot specify journal on remount\");\n\t\t\treturn -1;\n\t\t}\n\t\tjournal_path = match_strdup(&args[0]);\n\t\tif (!journal_path) {\n\t\t\text4_msg(sb, KERN_ERR, \"error: could not dup \"\n\t\t\t\t\"journal device string\");\n\t\t\treturn -1;\n\t\t}\n\n\t\terror = kern_path(journal_path, LOOKUP_FOLLOW, &path);\n\t\tif (error) {\n\t\t\text4_msg(sb, KERN_ERR, \"error: could not find \"\n\t\t\t\t\"journal device path: error %d\", error);\n\t\t\tkfree(journal_path);\n\t\t\treturn -1;\n\t\t}\n\n\t\tjournal_inode = d_inode(path.dentry);\n\t\tif (!S_ISBLK(journal_inode->i_mode)) {\n\t\t\text4_msg(sb, KERN_ERR, \"error: journal path %s \"\n\t\t\t\t\"is not a block device\", journal_path);\n\t\t\tpath_put(&path);\n\t\t\tkfree(journal_path);\n\t\t\treturn -1;\n\t\t}\n\n\t\t*journal_devnum = new_encode_dev(journal_inode->i_rdev);\n\t\tpath_put(&path);\n\t\tkfree(journal_path);\n\t} else if (token == Opt_journal_ioprio) {\n\t\tif (arg > 7) {\n\t\t\text4_msg(sb, KERN_ERR, \"Invalid journal IO priority\"\n\t\t\t\t \" (must be 0-7)\");\n\t\t\treturn -1;\n\t\t}\n\t\t*journal_ioprio =\n\t\t\tIOPRIO_PRIO_VALUE(IOPRIO_CLASS_BE, arg);\n\t} else if (token == Opt_test_dummy_encryption) {\n#ifdef CONFIG_EXT4_FS_ENCRYPTION\n\t\tsbi->s_mount_flags |= EXT4_MF_TEST_DUMMY_ENCRYPTION;\n\t\text4_msg(sb, KERN_WARNING,\n\t\t\t \"Test dummy encryption mode enabled\");\n#else\n\t\text4_msg(sb, KERN_WARNING,\n\t\t\t \"Test dummy encryption mount option ignored\");\n#endif\n\t} else if (m->flags & MOPT_DATAJ) {\n\t\tif (is_remount) {\n\t\t\tif (!sbi->s_journal)\n\t\t\t\text4_msg(sb, KERN_WARNING, \"Remounting file system with no journal so ignoring journalled data option\");\n\t\t\telse if (test_opt(sb, DATA_FLAGS) != m->mount_opt) {\n\t\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t\t\t \"Cannot change data mode on remount\");\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t} else {\n\t\t\tclear_opt(sb, DATA_FLAGS);\n\t\t\tsbi->s_mount_opt |= m->mount_opt;\n\t\t}\n#ifdef CONFIG_QUOTA\n\t} else if (m->flags & MOPT_QFMT) {\n\t\tif (sb_any_quota_loaded(sb) &&\n\t\t    sbi->s_jquota_fmt != m->mount_opt) {\n\t\t\text4_msg(sb, KERN_ERR, \"Cannot change journaled \"\n\t\t\t\t \"quota options when quota turned on\");\n\t\t\treturn -1;\n\t\t}\n\t\tif (ext4_has_feature_quota(sb)) {\n\t\t\text4_msg(sb, KERN_INFO,\n\t\t\t\t \"Quota format mount options ignored \"\n\t\t\t\t \"when QUOTA feature is enabled\");\n\t\t\treturn 1;\n\t\t}\n\t\tsbi->s_jquota_fmt = m->mount_opt;\n#endif\n\t} else if (token == Opt_dax) {\n#ifdef CONFIG_FS_DAX\n\t\text4_msg(sb, KERN_WARNING,\n\t\t\"DAX enabled. Warning: EXPERIMENTAL, use at your own risk\");\n\t\t\tsbi->s_mount_opt |= m->mount_opt;\n#else\n\t\text4_msg(sb, KERN_INFO, \"dax option not supported\");\n\t\treturn -1;\n#endif\n\t} else if (token == Opt_data_err_abort) {\n\t\tsbi->s_mount_opt |= m->mount_opt;\n\t} else if (token == Opt_data_err_ignore) {\n\t\tsbi->s_mount_opt &= ~m->mount_opt;\n\t} else {\n\t\tif (!args->from)\n\t\t\targ = 1;\n\t\tif (m->flags & MOPT_CLEAR)\n\t\t\targ = !arg;\n\t\telse if (unlikely(!(m->flags & MOPT_SET))) {\n\t\t\text4_msg(sb, KERN_WARNING,\n\t\t\t\t \"buggy handling of option %s\", opt);\n\t\t\tWARN_ON(1);\n\t\t\treturn -1;\n\t\t}\n\t\tif (arg != 0)\n\t\t\tsbi->s_mount_opt |= m->mount_opt;\n\t\telse\n\t\t\tsbi->s_mount_opt &= ~m->mount_opt;\n\t}\n\treturn 1;\n}\n\nstatic int parse_options(char *options, struct super_block *sb,\n\t\t\t unsigned long *journal_devnum,\n\t\t\t unsigned int *journal_ioprio,\n\t\t\t int is_remount)\n{\n\tstruct ext4_sb_info *sbi = EXT4_SB(sb);\n\tchar *p;\n\tsubstring_t args[MAX_OPT_ARGS];\n\tint token;\n\n\tif (!options)\n\t\treturn 1;\n\n\twhile ((p = strsep(&options, \",\")) != NULL) {\n\t\tif (!*p)\n\t\t\tcontinue;\n\t\t/*\n\t\t * Initialize args struct so we know whether arg was\n\t\t * found; some options take optional arguments.\n\t\t */\n\t\targs[0].to = args[0].from = NULL;\n\t\ttoken = match_token(p, tokens, args);\n\t\tif (handle_mount_opt(sb, p, token, args, journal_devnum,\n\t\t\t\t     journal_ioprio, is_remount) < 0)\n\t\t\treturn 0;\n\t}\n#ifdef CONFIG_QUOTA\n\t/*\n\t * We do the test below only for project quotas. 'usrquota' and\n\t * 'grpquota' mount options are allowed even without quota feature\n\t * to support legacy quotas in quota files.\n\t */\n\tif (test_opt(sb, PRJQUOTA) && !ext4_has_feature_project(sb)) {\n\t\text4_msg(sb, KERN_ERR, \"Project quota feature not enabled. \"\n\t\t\t \"Cannot enable project quota enforcement.\");\n\t\treturn 0;\n\t}\n\tif (sbi->s_qf_names[USRQUOTA] || sbi->s_qf_names[GRPQUOTA]) {\n\t\tif (test_opt(sb, USRQUOTA) && sbi->s_qf_names[USRQUOTA])\n\t\t\tclear_opt(sb, USRQUOTA);\n\n\t\tif (test_opt(sb, GRPQUOTA) && sbi->s_qf_names[GRPQUOTA])\n\t\t\tclear_opt(sb, GRPQUOTA);\n\n\t\tif (test_opt(sb, GRPQUOTA) || test_opt(sb, USRQUOTA)) {\n\t\t\text4_msg(sb, KERN_ERR, \"old and new quota \"\n\t\t\t\t\t\"format mixing\");\n\t\t\treturn 0;\n\t\t}\n\n\t\tif (!sbi->s_jquota_fmt) {\n\t\t\text4_msg(sb, KERN_ERR, \"journaled quota format \"\n\t\t\t\t\t\"not specified\");\n\t\t\treturn 0;\n\t\t}\n\t}\n#endif\n\tif (test_opt(sb, DIOREAD_NOLOCK)) {\n\t\tint blocksize =\n\t\t\tBLOCK_SIZE << le32_to_cpu(sbi->s_es->s_log_block_size);\n\n\t\tif (blocksize < PAGE_SIZE) {\n\t\t\text4_msg(sb, KERN_ERR, \"can't mount with \"\n\t\t\t\t \"dioread_nolock if block size != PAGE_SIZE\");\n\t\t\treturn 0;\n\t\t}\n\t}\n\tif (test_opt(sb, DATA_FLAGS) == EXT4_MOUNT_ORDERED_DATA &&\n\t    test_opt(sb, JOURNAL_ASYNC_COMMIT)) {\n\t\text4_msg(sb, KERN_ERR, \"can't mount with journal_async_commit \"\n\t\t\t \"in data=ordered mode\");\n\t\treturn 0;\n\t}\n\treturn 1;\n}\n\nstatic inline void ext4_show_quota_options(struct seq_file *seq,\n\t\t\t\t\t   struct super_block *sb)\n{\n#if defined(CONFIG_QUOTA)\n\tstruct ext4_sb_info *sbi = EXT4_SB(sb);\n\n\tif (sbi->s_jquota_fmt) {\n\t\tchar *fmtname = \"\";\n\n\t\tswitch (sbi->s_jquota_fmt) {\n\t\tcase QFMT_VFS_OLD:\n\t\t\tfmtname = \"vfsold\";\n\t\t\tbreak;\n\t\tcase QFMT_VFS_V0:\n\t\t\tfmtname = \"vfsv0\";\n\t\t\tbreak;\n\t\tcase QFMT_VFS_V1:\n\t\t\tfmtname = \"vfsv1\";\n\t\t\tbreak;\n\t\t}\n\t\tseq_printf(seq, \",jqfmt=%s\", fmtname);\n\t}\n\n\tif (sbi->s_qf_names[USRQUOTA])\n\t\tseq_show_option(seq, \"usrjquota\", sbi->s_qf_names[USRQUOTA]);\n\n\tif (sbi->s_qf_names[GRPQUOTA])\n\t\tseq_show_option(seq, \"grpjquota\", sbi->s_qf_names[GRPQUOTA]);\n#endif\n}\n\nstatic const char *token2str(int token)\n{\n\tconst struct match_token *t;\n\n\tfor (t = tokens; t->token != Opt_err; t++)\n\t\tif (t->token == token && !strchr(t->pattern, '='))\n\t\t\tbreak;\n\treturn t->pattern;\n}\n\n/*\n * Show an option if\n *  - it's set to a non-default value OR\n *  - if the per-sb default is different from the global default\n */\nstatic int _ext4_show_options(struct seq_file *seq, struct super_block *sb,\n\t\t\t      int nodefs)\n{\n\tstruct ext4_sb_info *sbi = EXT4_SB(sb);\n\tstruct ext4_super_block *es = sbi->s_es;\n\tint def_errors, def_mount_opt = nodefs ? 0 : sbi->s_def_mount_opt;\n\tconst struct mount_opts *m;\n\tchar sep = nodefs ? '\\n' : ',';\n\n#define SEQ_OPTS_PUTS(str) seq_printf(seq, \"%c\" str, sep)\n#define SEQ_OPTS_PRINT(str, arg) seq_printf(seq, \"%c\" str, sep, arg)\n\n\tif (sbi->s_sb_block != 1)\n\t\tSEQ_OPTS_PRINT(\"sb=%llu\", sbi->s_sb_block);\n\n\tfor (m = ext4_mount_opts; m->token != Opt_err; m++) {\n\t\tint want_set = m->flags & MOPT_SET;\n\t\tif (((m->flags & (MOPT_SET|MOPT_CLEAR)) == 0) ||\n\t\t    (m->flags & MOPT_CLEAR_ERR))\n\t\t\tcontinue;\n\t\tif (!(m->mount_opt & (sbi->s_mount_opt ^ def_mount_opt)))\n\t\t\tcontinue; /* skip if same as the default */\n\t\tif ((want_set &&\n\t\t     (sbi->s_mount_opt & m->mount_opt) != m->mount_opt) ||\n\t\t    (!want_set && (sbi->s_mount_opt & m->mount_opt)))\n\t\t\tcontinue; /* select Opt_noFoo vs Opt_Foo */\n\t\tSEQ_OPTS_PRINT(\"%s\", token2str(m->token));\n\t}\n\n\tif (nodefs || !uid_eq(sbi->s_resuid, make_kuid(&init_user_ns, EXT4_DEF_RESUID)) ||\n\t    le16_to_cpu(es->s_def_resuid) != EXT4_DEF_RESUID)\n\t\tSEQ_OPTS_PRINT(\"resuid=%u\",\n\t\t\t\tfrom_kuid_munged(&init_user_ns, sbi->s_resuid));\n\tif (nodefs || !gid_eq(sbi->s_resgid, make_kgid(&init_user_ns, EXT4_DEF_RESGID)) ||\n\t    le16_to_cpu(es->s_def_resgid) != EXT4_DEF_RESGID)\n\t\tSEQ_OPTS_PRINT(\"resgid=%u\",\n\t\t\t\tfrom_kgid_munged(&init_user_ns, sbi->s_resgid));\n\tdef_errors = nodefs ? -1 : le16_to_cpu(es->s_errors);\n\tif (test_opt(sb, ERRORS_RO) && def_errors != EXT4_ERRORS_RO)\n\t\tSEQ_OPTS_PUTS(\"errors=remount-ro\");\n\tif (test_opt(sb, ERRORS_CONT) && def_errors != EXT4_ERRORS_CONTINUE)\n\t\tSEQ_OPTS_PUTS(\"errors=continue\");\n\tif (test_opt(sb, ERRORS_PANIC) && def_errors != EXT4_ERRORS_PANIC)\n\t\tSEQ_OPTS_PUTS(\"errors=panic\");\n\tif (nodefs || sbi->s_commit_interval != JBD2_DEFAULT_MAX_COMMIT_AGE*HZ)\n\t\tSEQ_OPTS_PRINT(\"commit=%lu\", sbi->s_commit_interval / HZ);\n\tif (nodefs || sbi->s_min_batch_time != EXT4_DEF_MIN_BATCH_TIME)\n\t\tSEQ_OPTS_PRINT(\"min_batch_time=%u\", sbi->s_min_batch_time);\n\tif (nodefs || sbi->s_max_batch_time != EXT4_DEF_MAX_BATCH_TIME)\n\t\tSEQ_OPTS_PRINT(\"max_batch_time=%u\", sbi->s_max_batch_time);\n\tif (sb->s_flags & MS_I_VERSION)\n\t\tSEQ_OPTS_PUTS(\"i_version\");\n\tif (nodefs || sbi->s_stripe)\n\t\tSEQ_OPTS_PRINT(\"stripe=%lu\", sbi->s_stripe);\n\tif (EXT4_MOUNT_DATA_FLAGS & (sbi->s_mount_opt ^ def_mount_opt)) {\n\t\tif (test_opt(sb, DATA_FLAGS) == EXT4_MOUNT_JOURNAL_DATA)\n\t\t\tSEQ_OPTS_PUTS(\"data=journal\");\n\t\telse if (test_opt(sb, DATA_FLAGS) == EXT4_MOUNT_ORDERED_DATA)\n\t\t\tSEQ_OPTS_PUTS(\"data=ordered\");\n\t\telse if (test_opt(sb, DATA_FLAGS) == EXT4_MOUNT_WRITEBACK_DATA)\n\t\t\tSEQ_OPTS_PUTS(\"data=writeback\");\n\t}\n\tif (nodefs ||\n\t    sbi->s_inode_readahead_blks != EXT4_DEF_INODE_READAHEAD_BLKS)\n\t\tSEQ_OPTS_PRINT(\"inode_readahead_blks=%u\",\n\t\t\t       sbi->s_inode_readahead_blks);\n\n\tif (nodefs || (test_opt(sb, INIT_INODE_TABLE) &&\n\t\t       (sbi->s_li_wait_mult != EXT4_DEF_LI_WAIT_MULT)))\n\t\tSEQ_OPTS_PRINT(\"init_itable=%u\", sbi->s_li_wait_mult);\n\tif (nodefs || sbi->s_max_dir_size_kb)\n\t\tSEQ_OPTS_PRINT(\"max_dir_size_kb=%u\", sbi->s_max_dir_size_kb);\n\tif (test_opt(sb, DATA_ERR_ABORT))\n\t\tSEQ_OPTS_PUTS(\"data_err=abort\");\n\n\text4_show_quota_options(seq, sb);\n\treturn 0;\n}\n\nstatic int ext4_show_options(struct seq_file *seq, struct dentry *root)\n{\n\treturn _ext4_show_options(seq, root->d_sb, 0);\n}\n\nint ext4_seq_options_show(struct seq_file *seq, void *offset)\n{\n\tstruct super_block *sb = seq->private;\n\tint rc;\n\n\tseq_puts(seq, (sb->s_flags & MS_RDONLY) ? \"ro\" : \"rw\");\n\trc = _ext4_show_options(seq, sb, 1);\n\tseq_puts(seq, \"\\n\");\n\treturn rc;\n}\n\nstatic int ext4_setup_super(struct super_block *sb, struct ext4_super_block *es,\n\t\t\t    int read_only)\n{\n\tstruct ext4_sb_info *sbi = EXT4_SB(sb);\n\tint res = 0;\n\n\tif (le32_to_cpu(es->s_rev_level) > EXT4_MAX_SUPP_REV) {\n\t\text4_msg(sb, KERN_ERR, \"revision level too high, \"\n\t\t\t \"forcing read-only mode\");\n\t\tres = MS_RDONLY;\n\t}\n\tif (read_only)\n\t\tgoto done;\n\tif (!(sbi->s_mount_state & EXT4_VALID_FS))\n\t\text4_msg(sb, KERN_WARNING, \"warning: mounting unchecked fs, \"\n\t\t\t \"running e2fsck is recommended\");\n\telse if (sbi->s_mount_state & EXT4_ERROR_FS)\n\t\text4_msg(sb, KERN_WARNING,\n\t\t\t \"warning: mounting fs with errors, \"\n\t\t\t \"running e2fsck is recommended\");\n\telse if ((__s16) le16_to_cpu(es->s_max_mnt_count) > 0 &&\n\t\t le16_to_cpu(es->s_mnt_count) >=\n\t\t (unsigned short) (__s16) le16_to_cpu(es->s_max_mnt_count))\n\t\text4_msg(sb, KERN_WARNING,\n\t\t\t \"warning: maximal mount count reached, \"\n\t\t\t \"running e2fsck is recommended\");\n\telse if (le32_to_cpu(es->s_checkinterval) &&\n\t\t(le32_to_cpu(es->s_lastcheck) +\n\t\t\tle32_to_cpu(es->s_checkinterval) <= get_seconds()))\n\t\text4_msg(sb, KERN_WARNING,\n\t\t\t \"warning: checktime reached, \"\n\t\t\t \"running e2fsck is recommended\");\n\tif (!sbi->s_journal)\n\t\tes->s_state &= cpu_to_le16(~EXT4_VALID_FS);\n\tif (!(__s16) le16_to_cpu(es->s_max_mnt_count))\n\t\tes->s_max_mnt_count = cpu_to_le16(EXT4_DFL_MAX_MNT_COUNT);\n\tle16_add_cpu(&es->s_mnt_count, 1);\n\tes->s_mtime = cpu_to_le32(get_seconds());\n\text4_update_dynamic_rev(sb);\n\tif (sbi->s_journal)\n\t\text4_set_feature_journal_needs_recovery(sb);\n\n\text4_commit_super(sb, 1);\ndone:\n\tif (test_opt(sb, DEBUG))\n\t\tprintk(KERN_INFO \"[EXT4 FS bs=%lu, gc=%u, \"\n\t\t\t\t\"bpg=%lu, ipg=%lu, mo=%04x, mo2=%04x]\\n\",\n\t\t\tsb->s_blocksize,\n\t\t\tsbi->s_groups_count,\n\t\t\tEXT4_BLOCKS_PER_GROUP(sb),\n\t\t\tEXT4_INODES_PER_GROUP(sb),\n\t\t\tsbi->s_mount_opt, sbi->s_mount_opt2);\n\n\tcleancache_init_fs(sb);\n\treturn res;\n}\n\nint ext4_alloc_flex_bg_array(struct super_block *sb, ext4_group_t ngroup)\n{\n\tstruct ext4_sb_info *sbi = EXT4_SB(sb);\n\tstruct flex_groups *new_groups;\n\tint size;\n\n\tif (!sbi->s_log_groups_per_flex)\n\t\treturn 0;\n\n\tsize = ext4_flex_group(sbi, ngroup - 1) + 1;\n\tif (size <= sbi->s_flex_groups_allocated)\n\t\treturn 0;\n\n\tsize = roundup_pow_of_two(size * sizeof(struct flex_groups));\n\tnew_groups = ext4_kvzalloc(size, GFP_KERNEL);\n\tif (!new_groups) {\n\t\text4_msg(sb, KERN_ERR, \"not enough memory for %d flex groups\",\n\t\t\t size / (int) sizeof(struct flex_groups));\n\t\treturn -ENOMEM;\n\t}\n\n\tif (sbi->s_flex_groups) {\n\t\tmemcpy(new_groups, sbi->s_flex_groups,\n\t\t       (sbi->s_flex_groups_allocated *\n\t\t\tsizeof(struct flex_groups)));\n\t\tkvfree(sbi->s_flex_groups);\n\t}\n\tsbi->s_flex_groups = new_groups;\n\tsbi->s_flex_groups_allocated = size / sizeof(struct flex_groups);\n\treturn 0;\n}\n\nstatic int ext4_fill_flex_info(struct super_block *sb)\n{\n\tstruct ext4_sb_info *sbi = EXT4_SB(sb);\n\tstruct ext4_group_desc *gdp = NULL;\n\text4_group_t flex_group;\n\tint i, err;\n\n\tsbi->s_log_groups_per_flex = sbi->s_es->s_log_groups_per_flex;\n\tif (sbi->s_log_groups_per_flex < 1 || sbi->s_log_groups_per_flex > 31) {\n\t\tsbi->s_log_groups_per_flex = 0;\n\t\treturn 1;\n\t}\n\n\terr = ext4_alloc_flex_bg_array(sb, sbi->s_groups_count);\n\tif (err)\n\t\tgoto failed;\n\n\tfor (i = 0; i < sbi->s_groups_count; i++) {\n\t\tgdp = ext4_get_group_desc(sb, i, NULL);\n\n\t\tflex_group = ext4_flex_group(sbi, i);\n\t\tatomic_add(ext4_free_inodes_count(sb, gdp),\n\t\t\t   &sbi->s_flex_groups[flex_group].free_inodes);\n\t\tatomic64_add(ext4_free_group_clusters(sb, gdp),\n\t\t\t     &sbi->s_flex_groups[flex_group].free_clusters);\n\t\tatomic_add(ext4_used_dirs_count(sb, gdp),\n\t\t\t   &sbi->s_flex_groups[flex_group].used_dirs);\n\t}\n\n\treturn 1;\nfailed:\n\treturn 0;\n}\n\nstatic __le16 ext4_group_desc_csum(struct super_block *sb, __u32 block_group,\n\t\t\t\t   struct ext4_group_desc *gdp)\n{\n\tint offset = offsetof(struct ext4_group_desc, bg_checksum);\n\t__u16 crc = 0;\n\t__le32 le_group = cpu_to_le32(block_group);\n\tstruct ext4_sb_info *sbi = EXT4_SB(sb);\n\n\tif (ext4_has_metadata_csum(sbi->s_sb)) {\n\t\t/* Use new metadata_csum algorithm */\n\t\t__u32 csum32;\n\t\t__u16 dummy_csum = 0;\n\n\t\tcsum32 = ext4_chksum(sbi, sbi->s_csum_seed, (__u8 *)&le_group,\n\t\t\t\t     sizeof(le_group));\n\t\tcsum32 = ext4_chksum(sbi, csum32, (__u8 *)gdp, offset);\n\t\tcsum32 = ext4_chksum(sbi, csum32, (__u8 *)&dummy_csum,\n\t\t\t\t     sizeof(dummy_csum));\n\t\toffset += sizeof(dummy_csum);\n\t\tif (offset < sbi->s_desc_size)\n\t\t\tcsum32 = ext4_chksum(sbi, csum32, (__u8 *)gdp + offset,\n\t\t\t\t\t     sbi->s_desc_size - offset);\n\n\t\tcrc = csum32 & 0xFFFF;\n\t\tgoto out;\n\t}\n\n\t/* old crc16 code */\n\tif (!ext4_has_feature_gdt_csum(sb))\n\t\treturn 0;\n\n\tcrc = crc16(~0, sbi->s_es->s_uuid, sizeof(sbi->s_es->s_uuid));\n\tcrc = crc16(crc, (__u8 *)&le_group, sizeof(le_group));\n\tcrc = crc16(crc, (__u8 *)gdp, offset);\n\toffset += sizeof(gdp->bg_checksum); /* skip checksum */\n\t/* for checksum of struct ext4_group_desc do the rest...*/\n\tif (ext4_has_feature_64bit(sb) &&\n\t    offset < le16_to_cpu(sbi->s_es->s_desc_size))\n\t\tcrc = crc16(crc, (__u8 *)gdp + offset,\n\t\t\t    le16_to_cpu(sbi->s_es->s_desc_size) -\n\t\t\t\toffset);\n\nout:\n\treturn cpu_to_le16(crc);\n}\n\nint ext4_group_desc_csum_verify(struct super_block *sb, __u32 block_group,\n\t\t\t\tstruct ext4_group_desc *gdp)\n{\n\tif (ext4_has_group_desc_csum(sb) &&\n\t    (gdp->bg_checksum != ext4_group_desc_csum(sb, block_group, gdp)))\n\t\treturn 0;\n\n\treturn 1;\n}\n\nvoid ext4_group_desc_csum_set(struct super_block *sb, __u32 block_group,\n\t\t\t      struct ext4_group_desc *gdp)\n{\n\tif (!ext4_has_group_desc_csum(sb))\n\t\treturn;\n\tgdp->bg_checksum = ext4_group_desc_csum(sb, block_group, gdp);\n}\n\n/* Called at mount-time, super-block is locked */\nstatic int ext4_check_descriptors(struct super_block *sb,\n\t\t\t\t  ext4_fsblk_t sb_block,\n\t\t\t\t  ext4_group_t *first_not_zeroed)\n{\n\tstruct ext4_sb_info *sbi = EXT4_SB(sb);\n\text4_fsblk_t first_block = le32_to_cpu(sbi->s_es->s_first_data_block);\n\text4_fsblk_t last_block;\n\text4_fsblk_t block_bitmap;\n\text4_fsblk_t inode_bitmap;\n\text4_fsblk_t inode_table;\n\tint flexbg_flag = 0;\n\text4_group_t i, grp = sbi->s_groups_count;\n\n\tif (ext4_has_feature_flex_bg(sb))\n\t\tflexbg_flag = 1;\n\n\text4_debug(\"Checking group descriptors\");\n\n\tfor (i = 0; i < sbi->s_groups_count; i++) {\n\t\tstruct ext4_group_desc *gdp = ext4_get_group_desc(sb, i, NULL);\n\n\t\tif (i == sbi->s_groups_count - 1 || flexbg_flag)\n\t\t\tlast_block = ext4_blocks_count(sbi->s_es) - 1;\n\t\telse\n\t\t\tlast_block = first_block +\n\t\t\t\t(EXT4_BLOCKS_PER_GROUP(sb) - 1);\n\n\t\tif ((grp == sbi->s_groups_count) &&\n\t\t   !(gdp->bg_flags & cpu_to_le16(EXT4_BG_INODE_ZEROED)))\n\t\t\tgrp = i;\n\n\t\tblock_bitmap = ext4_block_bitmap(sb, gdp);\n\t\tif (block_bitmap == sb_block) {\n\t\t\text4_msg(sb, KERN_ERR, \"ext4_check_descriptors: \"\n\t\t\t\t \"Block bitmap for group %u overlaps \"\n\t\t\t\t \"superblock\", i);\n\t\t}\n\t\tif (block_bitmap < first_block || block_bitmap > last_block) {\n\t\t\text4_msg(sb, KERN_ERR, \"ext4_check_descriptors: \"\n\t\t\t       \"Block bitmap for group %u not in group \"\n\t\t\t       \"(block %llu)!\", i, block_bitmap);\n\t\t\treturn 0;\n\t\t}\n\t\tinode_bitmap = ext4_inode_bitmap(sb, gdp);\n\t\tif (inode_bitmap == sb_block) {\n\t\t\text4_msg(sb, KERN_ERR, \"ext4_check_descriptors: \"\n\t\t\t\t \"Inode bitmap for group %u overlaps \"\n\t\t\t\t \"superblock\", i);\n\t\t}\n\t\tif (inode_bitmap < first_block || inode_bitmap > last_block) {\n\t\t\text4_msg(sb, KERN_ERR, \"ext4_check_descriptors: \"\n\t\t\t       \"Inode bitmap for group %u not in group \"\n\t\t\t       \"(block %llu)!\", i, inode_bitmap);\n\t\t\treturn 0;\n\t\t}\n\t\tinode_table = ext4_inode_table(sb, gdp);\n\t\tif (inode_table == sb_block) {\n\t\t\text4_msg(sb, KERN_ERR, \"ext4_check_descriptors: \"\n\t\t\t\t \"Inode table for group %u overlaps \"\n\t\t\t\t \"superblock\", i);\n\t\t}\n\t\tif (inode_table < first_block ||\n\t\t    inode_table + sbi->s_itb_per_group - 1 > last_block) {\n\t\t\text4_msg(sb, KERN_ERR, \"ext4_check_descriptors: \"\n\t\t\t       \"Inode table for group %u not in group \"\n\t\t\t       \"(block %llu)!\", i, inode_table);\n\t\t\treturn 0;\n\t\t}\n\t\text4_lock_group(sb, i);\n\t\tif (!ext4_group_desc_csum_verify(sb, i, gdp)) {\n\t\t\text4_msg(sb, KERN_ERR, \"ext4_check_descriptors: \"\n\t\t\t\t \"Checksum for group %u failed (%u!=%u)\",\n\t\t\t\t i, le16_to_cpu(ext4_group_desc_csum(sb, i,\n\t\t\t\t     gdp)), le16_to_cpu(gdp->bg_checksum));\n\t\t\tif (!(sb->s_flags & MS_RDONLY)) {\n\t\t\t\text4_unlock_group(sb, i);\n\t\t\t\treturn 0;\n\t\t\t}\n\t\t}\n\t\text4_unlock_group(sb, i);\n\t\tif (!flexbg_flag)\n\t\t\tfirst_block += EXT4_BLOCKS_PER_GROUP(sb);\n\t}\n\tif (NULL != first_not_zeroed)\n\t\t*first_not_zeroed = grp;\n\treturn 1;\n}\n\n/* ext4_orphan_cleanup() walks a singly-linked list of inodes (starting at\n * the superblock) which were deleted from all directories, but held open by\n * a process at the time of a crash.  We walk the list and try to delete these\n * inodes at recovery time (only with a read-write filesystem).\n *\n * In order to keep the orphan inode chain consistent during traversal (in\n * case of crash during recovery), we link each inode into the superblock\n * orphan list_head and handle it the same way as an inode deletion during\n * normal operation (which journals the operations for us).\n *\n * We only do an iget() and an iput() on each inode, which is very safe if we\n * accidentally point at an in-use or already deleted inode.  The worst that\n * can happen in this case is that we get a \"bit already cleared\" message from\n * ext4_free_inode().  The only reason we would point at a wrong inode is if\n * e2fsck was run on this filesystem, and it must have already done the orphan\n * inode cleanup for us, so we can safely abort without any further action.\n */\nstatic void ext4_orphan_cleanup(struct super_block *sb,\n\t\t\t\tstruct ext4_super_block *es)\n{\n\tunsigned int s_flags = sb->s_flags;\n\tint ret, nr_orphans = 0, nr_truncates = 0;\n#ifdef CONFIG_QUOTA\n\tint i;\n#endif\n\tif (!es->s_last_orphan) {\n\t\tjbd_debug(4, \"no orphan inodes to clean up\\n\");\n\t\treturn;\n\t}\n\n\tif (bdev_read_only(sb->s_bdev)) {\n\t\text4_msg(sb, KERN_ERR, \"write access \"\n\t\t\t\"unavailable, skipping orphan cleanup\");\n\t\treturn;\n\t}\n\n\t/* Check if feature set would not allow a r/w mount */\n\tif (!ext4_feature_set_ok(sb, 0)) {\n\t\text4_msg(sb, KERN_INFO, \"Skipping orphan cleanup due to \"\n\t\t\t \"unknown ROCOMPAT features\");\n\t\treturn;\n\t}\n\n\tif (EXT4_SB(sb)->s_mount_state & EXT4_ERROR_FS) {\n\t\t/* don't clear list on RO mount w/ errors */\n\t\tif (es->s_last_orphan && !(s_flags & MS_RDONLY)) {\n\t\t\text4_msg(sb, KERN_INFO, \"Errors on filesystem, \"\n\t\t\t\t  \"clearing orphan list.\\n\");\n\t\t\tes->s_last_orphan = 0;\n\t\t}\n\t\tjbd_debug(1, \"Skipping orphan recovery on fs with errors.\\n\");\n\t\treturn;\n\t}\n\n\tif (s_flags & MS_RDONLY) {\n\t\text4_msg(sb, KERN_INFO, \"orphan cleanup on readonly fs\");\n\t\tsb->s_flags &= ~MS_RDONLY;\n\t}\n#ifdef CONFIG_QUOTA\n\t/* Needed for iput() to work correctly and not trash data */\n\tsb->s_flags |= MS_ACTIVE;\n\t/* Turn on quotas so that they are updated correctly */\n\tfor (i = 0; i < EXT4_MAXQUOTAS; i++) {\n\t\tif (EXT4_SB(sb)->s_qf_names[i]) {\n\t\t\tint ret = ext4_quota_on_mount(sb, i);\n\t\t\tif (ret < 0)\n\t\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t\t\t\"Cannot turn on journaled \"\n\t\t\t\t\t\"quota: error %d\", ret);\n\t\t}\n\t}\n#endif\n\n\twhile (es->s_last_orphan) {\n\t\tstruct inode *inode;\n\n\t\t/*\n\t\t * We may have encountered an error during cleanup; if\n\t\t * so, skip the rest.\n\t\t */\n\t\tif (EXT4_SB(sb)->s_mount_state & EXT4_ERROR_FS) {\n\t\t\tjbd_debug(1, \"Skipping orphan recovery on fs with errors.\\n\");\n\t\t\tes->s_last_orphan = 0;\n\t\t\tbreak;\n\t\t}\n\n\t\tinode = ext4_orphan_get(sb, le32_to_cpu(es->s_last_orphan));\n\t\tif (IS_ERR(inode)) {\n\t\t\tes->s_last_orphan = 0;\n\t\t\tbreak;\n\t\t}\n\n\t\tlist_add(&EXT4_I(inode)->i_orphan, &EXT4_SB(sb)->s_orphan);\n\t\tdquot_initialize(inode);\n\t\tif (inode->i_nlink) {\n\t\t\tif (test_opt(sb, DEBUG))\n\t\t\t\text4_msg(sb, KERN_DEBUG,\n\t\t\t\t\t\"%s: truncating inode %lu to %lld bytes\",\n\t\t\t\t\t__func__, inode->i_ino, inode->i_size);\n\t\t\tjbd_debug(2, \"truncating inode %lu to %lld bytes\\n\",\n\t\t\t\t  inode->i_ino, inode->i_size);\n\t\t\tinode_lock(inode);\n\t\t\ttruncate_inode_pages(inode->i_mapping, inode->i_size);\n\t\t\tret = ext4_truncate(inode);\n\t\t\tif (ret)\n\t\t\t\text4_std_error(inode->i_sb, ret);\n\t\t\tinode_unlock(inode);\n\t\t\tnr_truncates++;\n\t\t} else {\n\t\t\tif (test_opt(sb, DEBUG))\n\t\t\t\text4_msg(sb, KERN_DEBUG,\n\t\t\t\t\t\"%s: deleting unreferenced inode %lu\",\n\t\t\t\t\t__func__, inode->i_ino);\n\t\t\tjbd_debug(2, \"deleting unreferenced inode %lu\\n\",\n\t\t\t\t  inode->i_ino);\n\t\t\tnr_orphans++;\n\t\t}\n\t\tiput(inode);  /* The delete magic happens here! */\n\t}\n\n#define PLURAL(x) (x), ((x) == 1) ? \"\" : \"s\"\n\n\tif (nr_orphans)\n\t\text4_msg(sb, KERN_INFO, \"%d orphan inode%s deleted\",\n\t\t       PLURAL(nr_orphans));\n\tif (nr_truncates)\n\t\text4_msg(sb, KERN_INFO, \"%d truncate%s cleaned up\",\n\t\t       PLURAL(nr_truncates));\n#ifdef CONFIG_QUOTA\n\t/* Turn quotas off */\n\tfor (i = 0; i < EXT4_MAXQUOTAS; i++) {\n\t\tif (sb_dqopt(sb)->files[i])\n\t\t\tdquot_quota_off(sb, i);\n\t}\n#endif\n\tsb->s_flags = s_flags; /* Restore MS_RDONLY status */\n}\n\n/*\n * Maximal extent format file size.\n * Resulting logical blkno at s_maxbytes must fit in our on-disk\n * extent format containers, within a sector_t, and within i_blocks\n * in the vfs.  ext4 inode has 48 bits of i_block in fsblock units,\n * so that won't be a limiting factor.\n *\n * However there is other limiting factor. We do store extents in the form\n * of starting block and length, hence the resulting length of the extent\n * covering maximum file size must fit into on-disk format containers as\n * well. Given that length is always by 1 unit bigger than max unit (because\n * we count 0 as well) we have to lower the s_maxbytes by one fs block.\n *\n * Note, this does *not* consider any metadata overhead for vfs i_blocks.\n */\nstatic loff_t ext4_max_size(int blkbits, int has_huge_files)\n{\n\tloff_t res;\n\tloff_t upper_limit = MAX_LFS_FILESIZE;\n\n\t/* small i_blocks in vfs inode? */\n\tif (!has_huge_files || sizeof(blkcnt_t) < sizeof(u64)) {\n\t\t/*\n\t\t * CONFIG_LBDAF is not enabled implies the inode\n\t\t * i_block represent total blocks in 512 bytes\n\t\t * 32 == size of vfs inode i_blocks * 8\n\t\t */\n\t\tupper_limit = (1LL << 32) - 1;\n\n\t\t/* total blocks in file system block size */\n\t\tupper_limit >>= (blkbits - 9);\n\t\tupper_limit <<= blkbits;\n\t}\n\n\t/*\n\t * 32-bit extent-start container, ee_block. We lower the maxbytes\n\t * by one fs block, so ee_len can cover the extent of maximum file\n\t * size\n\t */\n\tres = (1LL << 32) - 1;\n\tres <<= blkbits;\n\n\t/* Sanity check against vm- & vfs- imposed limits */\n\tif (res > upper_limit)\n\t\tres = upper_limit;\n\n\treturn res;\n}\n\n/*\n * Maximal bitmap file size.  There is a direct, and {,double-,triple-}indirect\n * block limit, and also a limit of (2^48 - 1) 512-byte sectors in i_blocks.\n * We need to be 1 filesystem block less than the 2^48 sector limit.\n */\nstatic loff_t ext4_max_bitmap_size(int bits, int has_huge_files)\n{\n\tloff_t res = EXT4_NDIR_BLOCKS;\n\tint meta_blocks;\n\tloff_t upper_limit;\n\t/* This is calculated to be the largest file size for a dense, block\n\t * mapped file such that the file's total number of 512-byte sectors,\n\t * including data and all indirect blocks, does not exceed (2^48 - 1).\n\t *\n\t * __u32 i_blocks_lo and _u16 i_blocks_high represent the total\n\t * number of 512-byte sectors of the file.\n\t */\n\n\tif (!has_huge_files || sizeof(blkcnt_t) < sizeof(u64)) {\n\t\t/*\n\t\t * !has_huge_files or CONFIG_LBDAF not enabled implies that\n\t\t * the inode i_block field represents total file blocks in\n\t\t * 2^32 512-byte sectors == size of vfs inode i_blocks * 8\n\t\t */\n\t\tupper_limit = (1LL << 32) - 1;\n\n\t\t/* total blocks in file system block size */\n\t\tupper_limit >>= (bits - 9);\n\n\t} else {\n\t\t/*\n\t\t * We use 48 bit ext4_inode i_blocks\n\t\t * With EXT4_HUGE_FILE_FL set the i_blocks\n\t\t * represent total number of blocks in\n\t\t * file system block size\n\t\t */\n\t\tupper_limit = (1LL << 48) - 1;\n\n\t}\n\n\t/* indirect blocks */\n\tmeta_blocks = 1;\n\t/* double indirect blocks */\n\tmeta_blocks += 1 + (1LL << (bits-2));\n\t/* tripple indirect blocks */\n\tmeta_blocks += 1 + (1LL << (bits-2)) + (1LL << (2*(bits-2)));\n\n\tupper_limit -= meta_blocks;\n\tupper_limit <<= bits;\n\n\tres += 1LL << (bits-2);\n\tres += 1LL << (2*(bits-2));\n\tres += 1LL << (3*(bits-2));\n\tres <<= bits;\n\tif (res > upper_limit)\n\t\tres = upper_limit;\n\n\tif (res > MAX_LFS_FILESIZE)\n\t\tres = MAX_LFS_FILESIZE;\n\n\treturn res;\n}\n\nstatic ext4_fsblk_t descriptor_loc(struct super_block *sb,\n\t\t\t\t   ext4_fsblk_t logical_sb_block, int nr)\n{\n\tstruct ext4_sb_info *sbi = EXT4_SB(sb);\n\text4_group_t bg, first_meta_bg;\n\tint has_super = 0;\n\n\tfirst_meta_bg = le32_to_cpu(sbi->s_es->s_first_meta_bg);\n\n\tif (!ext4_has_feature_meta_bg(sb) || nr < first_meta_bg)\n\t\treturn logical_sb_block + nr + 1;\n\tbg = sbi->s_desc_per_block * nr;\n\tif (ext4_bg_has_super(sb, bg))\n\t\thas_super = 1;\n\n\t/*\n\t * If we have a meta_bg fs with 1k blocks, group 0's GDT is at\n\t * block 2, not 1.  If s_first_data_block == 0 (bigalloc is enabled\n\t * on modern mke2fs or blksize > 1k on older mke2fs) then we must\n\t * compensate.\n\t */\n\tif (sb->s_blocksize == 1024 && nr == 0 &&\n\t    le32_to_cpu(EXT4_SB(sb)->s_es->s_first_data_block) == 0)\n\t\thas_super++;\n\n\treturn (has_super + ext4_group_first_block_no(sb, bg));\n}\n\n/**\n * ext4_get_stripe_size: Get the stripe size.\n * @sbi: In memory super block info\n *\n * If we have specified it via mount option, then\n * use the mount option value. If the value specified at mount time is\n * greater than the blocks per group use the super block value.\n * If the super block value is greater than blocks per group return 0.\n * Allocator needs it be less than blocks per group.\n *\n */\nstatic unsigned long ext4_get_stripe_size(struct ext4_sb_info *sbi)\n{\n\tunsigned long stride = le16_to_cpu(sbi->s_es->s_raid_stride);\n\tunsigned long stripe_width =\n\t\t\tle32_to_cpu(sbi->s_es->s_raid_stripe_width);\n\tint ret;\n\n\tif (sbi->s_stripe && sbi->s_stripe <= sbi->s_blocks_per_group)\n\t\tret = sbi->s_stripe;\n\telse if (stripe_width <= sbi->s_blocks_per_group)\n\t\tret = stripe_width;\n\telse if (stride <= sbi->s_blocks_per_group)\n\t\tret = stride;\n\telse\n\t\tret = 0;\n\n\t/*\n\t * If the stripe width is 1, this makes no sense and\n\t * we set it to 0 to turn off stripe handling code.\n\t */\n\tif (ret <= 1)\n\t\tret = 0;\n\n\treturn ret;\n}\n\n/*\n * Check whether this filesystem can be mounted based on\n * the features present and the RDONLY/RDWR mount requested.\n * Returns 1 if this filesystem can be mounted as requested,\n * 0 if it cannot be.\n */\nstatic int ext4_feature_set_ok(struct super_block *sb, int readonly)\n{\n\tif (ext4_has_unknown_ext4_incompat_features(sb)) {\n\t\text4_msg(sb, KERN_ERR,\n\t\t\t\"Couldn't mount because of \"\n\t\t\t\"unsupported optional features (%x)\",\n\t\t\t(le32_to_cpu(EXT4_SB(sb)->s_es->s_feature_incompat) &\n\t\t\t~EXT4_FEATURE_INCOMPAT_SUPP));\n\t\treturn 0;\n\t}\n\n\tif (readonly)\n\t\treturn 1;\n\n\tif (ext4_has_feature_readonly(sb)) {\n\t\text4_msg(sb, KERN_INFO, \"filesystem is read-only\");\n\t\tsb->s_flags |= MS_RDONLY;\n\t\treturn 1;\n\t}\n\n\t/* Check that feature set is OK for a read-write mount */\n\tif (ext4_has_unknown_ext4_ro_compat_features(sb)) {\n\t\text4_msg(sb, KERN_ERR, \"couldn't mount RDWR because of \"\n\t\t\t \"unsupported optional features (%x)\",\n\t\t\t (le32_to_cpu(EXT4_SB(sb)->s_es->s_feature_ro_compat) &\n\t\t\t\t~EXT4_FEATURE_RO_COMPAT_SUPP));\n\t\treturn 0;\n\t}\n\t/*\n\t * Large file size enabled file system can only be mounted\n\t * read-write on 32-bit systems if kernel is built with CONFIG_LBDAF\n\t */\n\tif (ext4_has_feature_huge_file(sb)) {\n\t\tif (sizeof(blkcnt_t) < sizeof(u64)) {\n\t\t\text4_msg(sb, KERN_ERR, \"Filesystem with huge files \"\n\t\t\t\t \"cannot be mounted RDWR without \"\n\t\t\t\t \"CONFIG_LBDAF\");\n\t\t\treturn 0;\n\t\t}\n\t}\n\tif (ext4_has_feature_bigalloc(sb) && !ext4_has_feature_extents(sb)) {\n\t\text4_msg(sb, KERN_ERR,\n\t\t\t \"Can't support bigalloc feature without \"\n\t\t\t \"extents feature\\n\");\n\t\treturn 0;\n\t}\n\n#ifndef CONFIG_QUOTA\n\tif (ext4_has_feature_quota(sb) && !readonly) {\n\t\text4_msg(sb, KERN_ERR,\n\t\t\t \"Filesystem with quota feature cannot be mounted RDWR \"\n\t\t\t \"without CONFIG_QUOTA\");\n\t\treturn 0;\n\t}\n\tif (ext4_has_feature_project(sb) && !readonly) {\n\t\text4_msg(sb, KERN_ERR,\n\t\t\t \"Filesystem with project quota feature cannot be mounted RDWR \"\n\t\t\t \"without CONFIG_QUOTA\");\n\t\treturn 0;\n\t}\n#endif  /* CONFIG_QUOTA */\n\treturn 1;\n}\n\n/*\n * This function is called once a day if we have errors logged\n * on the file system\n */\nstatic void print_daily_error_info(unsigned long arg)\n{\n\tstruct super_block *sb = (struct super_block *) arg;\n\tstruct ext4_sb_info *sbi;\n\tstruct ext4_super_block *es;\n\n\tsbi = EXT4_SB(sb);\n\tes = sbi->s_es;\n\n\tif (es->s_error_count)\n\t\t/* fsck newer than v1.41.13 is needed to clean this condition. */\n\t\text4_msg(sb, KERN_NOTICE, \"error count since last fsck: %u\",\n\t\t\t le32_to_cpu(es->s_error_count));\n\tif (es->s_first_error_time) {\n\t\tprintk(KERN_NOTICE \"EXT4-fs (%s): initial error at time %u: %.*s:%d\",\n\t\t       sb->s_id, le32_to_cpu(es->s_first_error_time),\n\t\t       (int) sizeof(es->s_first_error_func),\n\t\t       es->s_first_error_func,\n\t\t       le32_to_cpu(es->s_first_error_line));\n\t\tif (es->s_first_error_ino)\n\t\t\tprintk(KERN_CONT \": inode %u\",\n\t\t\t       le32_to_cpu(es->s_first_error_ino));\n\t\tif (es->s_first_error_block)\n\t\t\tprintk(KERN_CONT \": block %llu\", (unsigned long long)\n\t\t\t       le64_to_cpu(es->s_first_error_block));\n\t\tprintk(KERN_CONT \"\\n\");\n\t}\n\tif (es->s_last_error_time) {\n\t\tprintk(KERN_NOTICE \"EXT4-fs (%s): last error at time %u: %.*s:%d\",\n\t\t       sb->s_id, le32_to_cpu(es->s_last_error_time),\n\t\t       (int) sizeof(es->s_last_error_func),\n\t\t       es->s_last_error_func,\n\t\t       le32_to_cpu(es->s_last_error_line));\n\t\tif (es->s_last_error_ino)\n\t\t\tprintk(KERN_CONT \": inode %u\",\n\t\t\t       le32_to_cpu(es->s_last_error_ino));\n\t\tif (es->s_last_error_block)\n\t\t\tprintk(KERN_CONT \": block %llu\", (unsigned long long)\n\t\t\t       le64_to_cpu(es->s_last_error_block));\n\t\tprintk(KERN_CONT \"\\n\");\n\t}\n\tmod_timer(&sbi->s_err_report, jiffies + 24*60*60*HZ);  /* Once a day */\n}\n\n/* Find next suitable group and run ext4_init_inode_table */\nstatic int ext4_run_li_request(struct ext4_li_request *elr)\n{\n\tstruct ext4_group_desc *gdp = NULL;\n\text4_group_t group, ngroups;\n\tstruct super_block *sb;\n\tunsigned long timeout = 0;\n\tint ret = 0;\n\n\tsb = elr->lr_super;\n\tngroups = EXT4_SB(sb)->s_groups_count;\n\n\tfor (group = elr->lr_next_group; group < ngroups; group++) {\n\t\tgdp = ext4_get_group_desc(sb, group, NULL);\n\t\tif (!gdp) {\n\t\t\tret = 1;\n\t\t\tbreak;\n\t\t}\n\n\t\tif (!(gdp->bg_flags & cpu_to_le16(EXT4_BG_INODE_ZEROED)))\n\t\t\tbreak;\n\t}\n\n\tif (group >= ngroups)\n\t\tret = 1;\n\n\tif (!ret) {\n\t\ttimeout = jiffies;\n\t\tret = ext4_init_inode_table(sb, group,\n\t\t\t\t\t    elr->lr_timeout ? 0 : 1);\n\t\tif (elr->lr_timeout == 0) {\n\t\t\ttimeout = (jiffies - timeout) *\n\t\t\t\t  elr->lr_sbi->s_li_wait_mult;\n\t\t\telr->lr_timeout = timeout;\n\t\t}\n\t\telr->lr_next_sched = jiffies + elr->lr_timeout;\n\t\telr->lr_next_group = group + 1;\n\t}\n\treturn ret;\n}\n\n/*\n * Remove lr_request from the list_request and free the\n * request structure. Should be called with li_list_mtx held\n */\nstatic void ext4_remove_li_request(struct ext4_li_request *elr)\n{\n\tstruct ext4_sb_info *sbi;\n\n\tif (!elr)\n\t\treturn;\n\n\tsbi = elr->lr_sbi;\n\n\tlist_del(&elr->lr_request);\n\tsbi->s_li_request = NULL;\n\tkfree(elr);\n}\n\nstatic void ext4_unregister_li_request(struct super_block *sb)\n{\n\tmutex_lock(&ext4_li_mtx);\n\tif (!ext4_li_info) {\n\t\tmutex_unlock(&ext4_li_mtx);\n\t\treturn;\n\t}\n\n\tmutex_lock(&ext4_li_info->li_list_mtx);\n\text4_remove_li_request(EXT4_SB(sb)->s_li_request);\n\tmutex_unlock(&ext4_li_info->li_list_mtx);\n\tmutex_unlock(&ext4_li_mtx);\n}\n\nstatic struct task_struct *ext4_lazyinit_task;\n\n/*\n * This is the function where ext4lazyinit thread lives. It walks\n * through the request list searching for next scheduled filesystem.\n * When such a fs is found, run the lazy initialization request\n * (ext4_rn_li_request) and keep track of the time spend in this\n * function. Based on that time we compute next schedule time of\n * the request. When walking through the list is complete, compute\n * next waking time and put itself into sleep.\n */\nstatic int ext4_lazyinit_thread(void *arg)\n{\n\tstruct ext4_lazy_init *eli = (struct ext4_lazy_init *)arg;\n\tstruct list_head *pos, *n;\n\tstruct ext4_li_request *elr;\n\tunsigned long next_wakeup, cur;\n\n\tBUG_ON(NULL == eli);\n\ncont_thread:\n\twhile (true) {\n\t\tnext_wakeup = MAX_JIFFY_OFFSET;\n\n\t\tmutex_lock(&eli->li_list_mtx);\n\t\tif (list_empty(&eli->li_request_list)) {\n\t\t\tmutex_unlock(&eli->li_list_mtx);\n\t\t\tgoto exit_thread;\n\t\t}\n\t\tlist_for_each_safe(pos, n, &eli->li_request_list) {\n\t\t\tint err = 0;\n\t\t\tint progress = 0;\n\t\t\telr = list_entry(pos, struct ext4_li_request,\n\t\t\t\t\t lr_request);\n\n\t\t\tif (time_before(jiffies, elr->lr_next_sched)) {\n\t\t\t\tif (time_before(elr->lr_next_sched, next_wakeup))\n\t\t\t\t\tnext_wakeup = elr->lr_next_sched;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tif (down_read_trylock(&elr->lr_super->s_umount)) {\n\t\t\t\tif (sb_start_write_trylock(elr->lr_super)) {\n\t\t\t\t\tprogress = 1;\n\t\t\t\t\t/*\n\t\t\t\t\t * We hold sb->s_umount, sb can not\n\t\t\t\t\t * be removed from the list, it is\n\t\t\t\t\t * now safe to drop li_list_mtx\n\t\t\t\t\t */\n\t\t\t\t\tmutex_unlock(&eli->li_list_mtx);\n\t\t\t\t\terr = ext4_run_li_request(elr);\n\t\t\t\t\tsb_end_write(elr->lr_super);\n\t\t\t\t\tmutex_lock(&eli->li_list_mtx);\n\t\t\t\t\tn = pos->next;\n\t\t\t\t}\n\t\t\t\tup_read((&elr->lr_super->s_umount));\n\t\t\t}\n\t\t\t/* error, remove the lazy_init job */\n\t\t\tif (err) {\n\t\t\t\text4_remove_li_request(elr);\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tif (!progress) {\n\t\t\t\telr->lr_next_sched = jiffies +\n\t\t\t\t\t(prandom_u32()\n\t\t\t\t\t % (EXT4_DEF_LI_MAX_START_DELAY * HZ));\n\t\t\t}\n\t\t\tif (time_before(elr->lr_next_sched, next_wakeup))\n\t\t\t\tnext_wakeup = elr->lr_next_sched;\n\t\t}\n\t\tmutex_unlock(&eli->li_list_mtx);\n\n\t\ttry_to_freeze();\n\n\t\tcur = jiffies;\n\t\tif ((time_after_eq(cur, next_wakeup)) ||\n\t\t    (MAX_JIFFY_OFFSET == next_wakeup)) {\n\t\t\tcond_resched();\n\t\t\tcontinue;\n\t\t}\n\n\t\tschedule_timeout_interruptible(next_wakeup - cur);\n\n\t\tif (kthread_should_stop()) {\n\t\t\text4_clear_request_list();\n\t\t\tgoto exit_thread;\n\t\t}\n\t}\n\nexit_thread:\n\t/*\n\t * It looks like the request list is empty, but we need\n\t * to check it under the li_list_mtx lock, to prevent any\n\t * additions into it, and of course we should lock ext4_li_mtx\n\t * to atomically free the list and ext4_li_info, because at\n\t * this point another ext4 filesystem could be registering\n\t * new one.\n\t */\n\tmutex_lock(&ext4_li_mtx);\n\tmutex_lock(&eli->li_list_mtx);\n\tif (!list_empty(&eli->li_request_list)) {\n\t\tmutex_unlock(&eli->li_list_mtx);\n\t\tmutex_unlock(&ext4_li_mtx);\n\t\tgoto cont_thread;\n\t}\n\tmutex_unlock(&eli->li_list_mtx);\n\tkfree(ext4_li_info);\n\text4_li_info = NULL;\n\tmutex_unlock(&ext4_li_mtx);\n\n\treturn 0;\n}\n\nstatic void ext4_clear_request_list(void)\n{\n\tstruct list_head *pos, *n;\n\tstruct ext4_li_request *elr;\n\n\tmutex_lock(&ext4_li_info->li_list_mtx);\n\tlist_for_each_safe(pos, n, &ext4_li_info->li_request_list) {\n\t\telr = list_entry(pos, struct ext4_li_request,\n\t\t\t\t lr_request);\n\t\text4_remove_li_request(elr);\n\t}\n\tmutex_unlock(&ext4_li_info->li_list_mtx);\n}\n\nstatic int ext4_run_lazyinit_thread(void)\n{\n\text4_lazyinit_task = kthread_run(ext4_lazyinit_thread,\n\t\t\t\t\t ext4_li_info, \"ext4lazyinit\");\n\tif (IS_ERR(ext4_lazyinit_task)) {\n\t\tint err = PTR_ERR(ext4_lazyinit_task);\n\t\text4_clear_request_list();\n\t\tkfree(ext4_li_info);\n\t\text4_li_info = NULL;\n\t\tprintk(KERN_CRIT \"EXT4-fs: error %d creating inode table \"\n\t\t\t\t \"initialization thread\\n\",\n\t\t\t\t err);\n\t\treturn err;\n\t}\n\text4_li_info->li_state |= EXT4_LAZYINIT_RUNNING;\n\treturn 0;\n}\n\n/*\n * Check whether it make sense to run itable init. thread or not.\n * If there is at least one uninitialized inode table, return\n * corresponding group number, else the loop goes through all\n * groups and return total number of groups.\n */\nstatic ext4_group_t ext4_has_uninit_itable(struct super_block *sb)\n{\n\text4_group_t group, ngroups = EXT4_SB(sb)->s_groups_count;\n\tstruct ext4_group_desc *gdp = NULL;\n\n\tfor (group = 0; group < ngroups; group++) {\n\t\tgdp = ext4_get_group_desc(sb, group, NULL);\n\t\tif (!gdp)\n\t\t\tcontinue;\n\n\t\tif (!(gdp->bg_flags & cpu_to_le16(EXT4_BG_INODE_ZEROED)))\n\t\t\tbreak;\n\t}\n\n\treturn group;\n}\n\nstatic int ext4_li_info_new(void)\n{\n\tstruct ext4_lazy_init *eli = NULL;\n\n\teli = kzalloc(sizeof(*eli), GFP_KERNEL);\n\tif (!eli)\n\t\treturn -ENOMEM;\n\n\tINIT_LIST_HEAD(&eli->li_request_list);\n\tmutex_init(&eli->li_list_mtx);\n\n\teli->li_state |= EXT4_LAZYINIT_QUIT;\n\n\text4_li_info = eli;\n\n\treturn 0;\n}\n\nstatic struct ext4_li_request *ext4_li_request_new(struct super_block *sb,\n\t\t\t\t\t    ext4_group_t start)\n{\n\tstruct ext4_sb_info *sbi = EXT4_SB(sb);\n\tstruct ext4_li_request *elr;\n\n\telr = kzalloc(sizeof(*elr), GFP_KERNEL);\n\tif (!elr)\n\t\treturn NULL;\n\n\telr->lr_super = sb;\n\telr->lr_sbi = sbi;\n\telr->lr_next_group = start;\n\n\t/*\n\t * Randomize first schedule time of the request to\n\t * spread the inode table initialization requests\n\t * better.\n\t */\n\telr->lr_next_sched = jiffies + (prandom_u32() %\n\t\t\t\t(EXT4_DEF_LI_MAX_START_DELAY * HZ));\n\treturn elr;\n}\n\nint ext4_register_li_request(struct super_block *sb,\n\t\t\t     ext4_group_t first_not_zeroed)\n{\n\tstruct ext4_sb_info *sbi = EXT4_SB(sb);\n\tstruct ext4_li_request *elr = NULL;\n\text4_group_t ngroups = EXT4_SB(sb)->s_groups_count;\n\tint ret = 0;\n\n\tmutex_lock(&ext4_li_mtx);\n\tif (sbi->s_li_request != NULL) {\n\t\t/*\n\t\t * Reset timeout so it can be computed again, because\n\t\t * s_li_wait_mult might have changed.\n\t\t */\n\t\tsbi->s_li_request->lr_timeout = 0;\n\t\tgoto out;\n\t}\n\n\tif (first_not_zeroed == ngroups ||\n\t    (sb->s_flags & MS_RDONLY) ||\n\t    !test_opt(sb, INIT_INODE_TABLE))\n\t\tgoto out;\n\n\telr = ext4_li_request_new(sb, first_not_zeroed);\n\tif (!elr) {\n\t\tret = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\tif (NULL == ext4_li_info) {\n\t\tret = ext4_li_info_new();\n\t\tif (ret)\n\t\t\tgoto out;\n\t}\n\n\tmutex_lock(&ext4_li_info->li_list_mtx);\n\tlist_add(&elr->lr_request, &ext4_li_info->li_request_list);\n\tmutex_unlock(&ext4_li_info->li_list_mtx);\n\n\tsbi->s_li_request = elr;\n\t/*\n\t * set elr to NULL here since it has been inserted to\n\t * the request_list and the removal and free of it is\n\t * handled by ext4_clear_request_list from now on.\n\t */\n\telr = NULL;\n\n\tif (!(ext4_li_info->li_state & EXT4_LAZYINIT_RUNNING)) {\n\t\tret = ext4_run_lazyinit_thread();\n\t\tif (ret)\n\t\t\tgoto out;\n\t}\nout:\n\tmutex_unlock(&ext4_li_mtx);\n\tif (ret)\n\t\tkfree(elr);\n\treturn ret;\n}\n\n/*\n * We do not need to lock anything since this is called on\n * module unload.\n */\nstatic void ext4_destroy_lazyinit_thread(void)\n{\n\t/*\n\t * If thread exited earlier\n\t * there's nothing to be done.\n\t */\n\tif (!ext4_li_info || !ext4_lazyinit_task)\n\t\treturn;\n\n\tkthread_stop(ext4_lazyinit_task);\n}\n\nstatic int set_journal_csum_feature_set(struct super_block *sb)\n{\n\tint ret = 1;\n\tint compat, incompat;\n\tstruct ext4_sb_info *sbi = EXT4_SB(sb);\n\n\tif (ext4_has_metadata_csum(sb)) {\n\t\t/* journal checksum v3 */\n\t\tcompat = 0;\n\t\tincompat = JBD2_FEATURE_INCOMPAT_CSUM_V3;\n\t} else {\n\t\t/* journal checksum v1 */\n\t\tcompat = JBD2_FEATURE_COMPAT_CHECKSUM;\n\t\tincompat = 0;\n\t}\n\n\tjbd2_journal_clear_features(sbi->s_journal,\n\t\t\tJBD2_FEATURE_COMPAT_CHECKSUM, 0,\n\t\t\tJBD2_FEATURE_INCOMPAT_CSUM_V3 |\n\t\t\tJBD2_FEATURE_INCOMPAT_CSUM_V2);\n\tif (test_opt(sb, JOURNAL_ASYNC_COMMIT)) {\n\t\tret = jbd2_journal_set_features(sbi->s_journal,\n\t\t\t\tcompat, 0,\n\t\t\t\tJBD2_FEATURE_INCOMPAT_ASYNC_COMMIT |\n\t\t\t\tincompat);\n\t} else if (test_opt(sb, JOURNAL_CHECKSUM)) {\n\t\tret = jbd2_journal_set_features(sbi->s_journal,\n\t\t\t\tcompat, 0,\n\t\t\t\tincompat);\n\t\tjbd2_journal_clear_features(sbi->s_journal, 0, 0,\n\t\t\t\tJBD2_FEATURE_INCOMPAT_ASYNC_COMMIT);\n\t} else {\n\t\tjbd2_journal_clear_features(sbi->s_journal, 0, 0,\n\t\t\t\tJBD2_FEATURE_INCOMPAT_ASYNC_COMMIT);\n\t}\n\n\treturn ret;\n}\n\n/*\n * Note: calculating the overhead so we can be compatible with\n * historical BSD practice is quite difficult in the face of\n * clusters/bigalloc.  This is because multiple metadata blocks from\n * different block group can end up in the same allocation cluster.\n * Calculating the exact overhead in the face of clustered allocation\n * requires either O(all block bitmaps) in memory or O(number of block\n * groups**2) in time.  We will still calculate the superblock for\n * older file systems --- and if we come across with a bigalloc file\n * system with zero in s_overhead_clusters the estimate will be close to\n * correct especially for very large cluster sizes --- but for newer\n * file systems, it's better to calculate this figure once at mkfs\n * time, and store it in the superblock.  If the superblock value is\n * present (even for non-bigalloc file systems), we will use it.\n */\nstatic int count_overhead(struct super_block *sb, ext4_group_t grp,\n\t\t\t  char *buf)\n{\n\tstruct ext4_sb_info\t*sbi = EXT4_SB(sb);\n\tstruct ext4_group_desc\t*gdp;\n\text4_fsblk_t\t\tfirst_block, last_block, b;\n\text4_group_t\t\ti, ngroups = ext4_get_groups_count(sb);\n\tint\t\t\ts, j, count = 0;\n\n\tif (!ext4_has_feature_bigalloc(sb))\n\t\treturn (ext4_bg_has_super(sb, grp) + ext4_bg_num_gdb(sb, grp) +\n\t\t\tsbi->s_itb_per_group + 2);\n\n\tfirst_block = le32_to_cpu(sbi->s_es->s_first_data_block) +\n\t\t(grp * EXT4_BLOCKS_PER_GROUP(sb));\n\tlast_block = first_block + EXT4_BLOCKS_PER_GROUP(sb) - 1;\n\tfor (i = 0; i < ngroups; i++) {\n\t\tgdp = ext4_get_group_desc(sb, i, NULL);\n\t\tb = ext4_block_bitmap(sb, gdp);\n\t\tif (b >= first_block && b <= last_block) {\n\t\t\text4_set_bit(EXT4_B2C(sbi, b - first_block), buf);\n\t\t\tcount++;\n\t\t}\n\t\tb = ext4_inode_bitmap(sb, gdp);\n\t\tif (b >= first_block && b <= last_block) {\n\t\t\text4_set_bit(EXT4_B2C(sbi, b - first_block), buf);\n\t\t\tcount++;\n\t\t}\n\t\tb = ext4_inode_table(sb, gdp);\n\t\tif (b >= first_block && b + sbi->s_itb_per_group <= last_block)\n\t\t\tfor (j = 0; j < sbi->s_itb_per_group; j++, b++) {\n\t\t\t\tint c = EXT4_B2C(sbi, b - first_block);\n\t\t\t\text4_set_bit(c, buf);\n\t\t\t\tcount++;\n\t\t\t}\n\t\tif (i != grp)\n\t\t\tcontinue;\n\t\ts = 0;\n\t\tif (ext4_bg_has_super(sb, grp)) {\n\t\t\text4_set_bit(s++, buf);\n\t\t\tcount++;\n\t\t}\n\t\tj = ext4_bg_num_gdb(sb, grp);\n\t\tif (s + j > EXT4_BLOCKS_PER_GROUP(sb)) {\n\t\t\text4_error(sb, \"Invalid number of block group \"\n\t\t\t\t   \"descriptor blocks: %d\", j);\n\t\t\tj = EXT4_BLOCKS_PER_GROUP(sb) - s;\n\t\t}\n\t\tcount += j;\n\t\tfor (; j > 0; j--)\n\t\t\text4_set_bit(EXT4_B2C(sbi, s++), buf);\n\t}\n\tif (!count)\n\t\treturn 0;\n\treturn EXT4_CLUSTERS_PER_GROUP(sb) -\n\t\text4_count_free(buf, EXT4_CLUSTERS_PER_GROUP(sb) / 8);\n}\n\n/*\n * Compute the overhead and stash it in sbi->s_overhead\n */\nint ext4_calculate_overhead(struct super_block *sb)\n{\n\tstruct ext4_sb_info *sbi = EXT4_SB(sb);\n\tstruct ext4_super_block *es = sbi->s_es;\n\tstruct inode *j_inode;\n\tunsigned int j_blocks, j_inum = le32_to_cpu(es->s_journal_inum);\n\text4_group_t i, ngroups = ext4_get_groups_count(sb);\n\text4_fsblk_t overhead = 0;\n\tchar *buf = (char *) get_zeroed_page(GFP_NOFS);\n\n\tif (!buf)\n\t\treturn -ENOMEM;\n\n\t/*\n\t * Compute the overhead (FS structures).  This is constant\n\t * for a given filesystem unless the number of block groups\n\t * changes so we cache the previous value until it does.\n\t */\n\n\t/*\n\t * All of the blocks before first_data_block are overhead\n\t */\n\toverhead = EXT4_B2C(sbi, le32_to_cpu(es->s_first_data_block));\n\n\t/*\n\t * Add the overhead found in each block group\n\t */\n\tfor (i = 0; i < ngroups; i++) {\n\t\tint blks;\n\n\t\tblks = count_overhead(sb, i, buf);\n\t\toverhead += blks;\n\t\tif (blks)\n\t\t\tmemset(buf, 0, PAGE_SIZE);\n\t\tcond_resched();\n\t}\n\n\t/*\n\t * Add the internal journal blocks whether the journal has been\n\t * loaded or not\n\t */\n\tif (sbi->s_journal && !sbi->journal_bdev)\n\t\toverhead += EXT4_NUM_B2C(sbi, sbi->s_journal->j_maxlen);\n\telse if (ext4_has_feature_journal(sb) && !sbi->s_journal) {\n\t\tj_inode = ext4_get_journal_inode(sb, j_inum);\n\t\tif (j_inode) {\n\t\t\tj_blocks = j_inode->i_size >> sb->s_blocksize_bits;\n\t\t\toverhead += EXT4_NUM_B2C(sbi, j_blocks);\n\t\t\tiput(j_inode);\n\t\t} else {\n\t\t\text4_msg(sb, KERN_ERR, \"can't get journal size\");\n\t\t}\n\t}\n\tsbi->s_overhead = overhead;\n\tsmp_wmb();\n\tfree_page((unsigned long) buf);\n\treturn 0;\n}\n\nstatic void ext4_set_resv_clusters(struct super_block *sb)\n{\n\text4_fsblk_t resv_clusters;\n\tstruct ext4_sb_info *sbi = EXT4_SB(sb);\n\n\t/*\n\t * There's no need to reserve anything when we aren't using extents.\n\t * The space estimates are exact, there are no unwritten extents,\n\t * hole punching doesn't need new metadata... This is needed especially\n\t * to keep ext2/3 backward compatibility.\n\t */\n\tif (!ext4_has_feature_extents(sb))\n\t\treturn;\n\t/*\n\t * By default we reserve 2% or 4096 clusters, whichever is smaller.\n\t * This should cover the situations where we can not afford to run\n\t * out of space like for example punch hole, or converting\n\t * unwritten extents in delalloc path. In most cases such\n\t * allocation would require 1, or 2 blocks, higher numbers are\n\t * very rare.\n\t */\n\tresv_clusters = (ext4_blocks_count(sbi->s_es) >>\n\t\t\t sbi->s_cluster_bits);\n\n\tdo_div(resv_clusters, 50);\n\tresv_clusters = min_t(ext4_fsblk_t, resv_clusters, 4096);\n\n\tatomic64_set(&sbi->s_resv_clusters, resv_clusters);\n}\n\nstatic int ext4_fill_super(struct super_block *sb, void *data, int silent)\n{\n\tchar *orig_data = kstrdup(data, GFP_KERNEL);\n\tstruct buffer_head *bh;\n\tstruct ext4_super_block *es = NULL;\n\tstruct ext4_sb_info *sbi = kzalloc(sizeof(*sbi), GFP_KERNEL);\n\text4_fsblk_t block;\n\text4_fsblk_t sb_block = get_sb_block(&data);\n\text4_fsblk_t logical_sb_block;\n\tunsigned long offset = 0;\n\tunsigned long journal_devnum = 0;\n\tunsigned long def_mount_opts;\n\tstruct inode *root;\n\tconst char *descr;\n\tint ret = -ENOMEM;\n\tint blocksize, clustersize;\n\tunsigned int db_count;\n\tunsigned int i;\n\tint needs_recovery, has_huge_files, has_bigalloc;\n\t__u64 blocks_count;\n\tint err = 0;\n\tunsigned int journal_ioprio = DEFAULT_JOURNAL_IOPRIO;\n\text4_group_t first_not_zeroed;\n\n\tif ((data && !orig_data) || !sbi)\n\t\tgoto out_free_base;\n\n\tsbi->s_blockgroup_lock =\n\t\tkzalloc(sizeof(struct blockgroup_lock), GFP_KERNEL);\n\tif (!sbi->s_blockgroup_lock)\n\t\tgoto out_free_base;\n\n\tsb->s_fs_info = sbi;\n\tsbi->s_sb = sb;\n\tsbi->s_inode_readahead_blks = EXT4_DEF_INODE_READAHEAD_BLKS;\n\tsbi->s_sb_block = sb_block;\n\tif (sb->s_bdev->bd_part)\n\t\tsbi->s_sectors_written_start =\n\t\t\tpart_stat_read(sb->s_bdev->bd_part, sectors[1]);\n\n\t/* Cleanup superblock name */\n\tstrreplace(sb->s_id, '/', '!');\n\n\t/* -EINVAL is default */\n\tret = -EINVAL;\n\tblocksize = sb_min_blocksize(sb, EXT4_MIN_BLOCK_SIZE);\n\tif (!blocksize) {\n\t\text4_msg(sb, KERN_ERR, \"unable to set blocksize\");\n\t\tgoto out_fail;\n\t}\n\n\t/*\n\t * The ext4 superblock will not be buffer aligned for other than 1kB\n\t * block sizes.  We need to calculate the offset from buffer start.\n\t */\n\tif (blocksize != EXT4_MIN_BLOCK_SIZE) {\n\t\tlogical_sb_block = sb_block * EXT4_MIN_BLOCK_SIZE;\n\t\toffset = do_div(logical_sb_block, blocksize);\n\t} else {\n\t\tlogical_sb_block = sb_block;\n\t}\n\n\tif (!(bh = sb_bread_unmovable(sb, logical_sb_block))) {\n\t\text4_msg(sb, KERN_ERR, \"unable to read superblock\");\n\t\tgoto out_fail;\n\t}\n\t/*\n\t * Note: s_es must be initialized as soon as possible because\n\t *       some ext4 macro-instructions depend on its value\n\t */\n\tes = (struct ext4_super_block *) (bh->b_data + offset);\n\tsbi->s_es = es;\n\tsb->s_magic = le16_to_cpu(es->s_magic);\n\tif (sb->s_magic != EXT4_SUPER_MAGIC)\n\t\tgoto cantfind_ext4;\n\tsbi->s_kbytes_written = le64_to_cpu(es->s_kbytes_written);\n\n\t/* Warn if metadata_csum and gdt_csum are both set. */\n\tif (ext4_has_feature_metadata_csum(sb) &&\n\t    ext4_has_feature_gdt_csum(sb))\n\t\text4_warning(sb, \"metadata_csum and uninit_bg are \"\n\t\t\t     \"redundant flags; please run fsck.\");\n\n\t/* Check for a known checksum algorithm */\n\tif (!ext4_verify_csum_type(sb, es)) {\n\t\text4_msg(sb, KERN_ERR, \"VFS: Found ext4 filesystem with \"\n\t\t\t \"unknown checksum algorithm.\");\n\t\tsilent = 1;\n\t\tgoto cantfind_ext4;\n\t}\n\n\t/* Load the checksum driver */\n\tif (ext4_has_feature_metadata_csum(sb)) {\n\t\tsbi->s_chksum_driver = crypto_alloc_shash(\"crc32c\", 0, 0);\n\t\tif (IS_ERR(sbi->s_chksum_driver)) {\n\t\t\text4_msg(sb, KERN_ERR, \"Cannot load crc32c driver.\");\n\t\t\tret = PTR_ERR(sbi->s_chksum_driver);\n\t\t\tsbi->s_chksum_driver = NULL;\n\t\t\tgoto failed_mount;\n\t\t}\n\t}\n\n\t/* Check superblock checksum */\n\tif (!ext4_superblock_csum_verify(sb, es)) {\n\t\text4_msg(sb, KERN_ERR, \"VFS: Found ext4 filesystem with \"\n\t\t\t \"invalid superblock checksum.  Run e2fsck?\");\n\t\tsilent = 1;\n\t\tret = -EFSBADCRC;\n\t\tgoto cantfind_ext4;\n\t}\n\n\t/* Precompute checksum seed for all metadata */\n\tif (ext4_has_feature_csum_seed(sb))\n\t\tsbi->s_csum_seed = le32_to_cpu(es->s_checksum_seed);\n\telse if (ext4_has_metadata_csum(sb))\n\t\tsbi->s_csum_seed = ext4_chksum(sbi, ~0, es->s_uuid,\n\t\t\t\t\t       sizeof(es->s_uuid));\n\n\t/* Set defaults before we parse the mount options */\n\tdef_mount_opts = le32_to_cpu(es->s_default_mount_opts);\n\tset_opt(sb, INIT_INODE_TABLE);\n\tif (def_mount_opts & EXT4_DEFM_DEBUG)\n\t\tset_opt(sb, DEBUG);\n\tif (def_mount_opts & EXT4_DEFM_BSDGROUPS)\n\t\tset_opt(sb, GRPID);\n\tif (def_mount_opts & EXT4_DEFM_UID16)\n\t\tset_opt(sb, NO_UID32);\n\t/* xattr user namespace & acls are now defaulted on */\n\tset_opt(sb, XATTR_USER);\n#ifdef CONFIG_EXT4_FS_POSIX_ACL\n\tset_opt(sb, POSIX_ACL);\n#endif\n\t/* don't forget to enable journal_csum when metadata_csum is enabled. */\n\tif (ext4_has_metadata_csum(sb))\n\t\tset_opt(sb, JOURNAL_CHECKSUM);\n\n\tif ((def_mount_opts & EXT4_DEFM_JMODE) == EXT4_DEFM_JMODE_DATA)\n\t\tset_opt(sb, JOURNAL_DATA);\n\telse if ((def_mount_opts & EXT4_DEFM_JMODE) == EXT4_DEFM_JMODE_ORDERED)\n\t\tset_opt(sb, ORDERED_DATA);\n\telse if ((def_mount_opts & EXT4_DEFM_JMODE) == EXT4_DEFM_JMODE_WBACK)\n\t\tset_opt(sb, WRITEBACK_DATA);\n\n\tif (le16_to_cpu(sbi->s_es->s_errors) == EXT4_ERRORS_PANIC)\n\t\tset_opt(sb, ERRORS_PANIC);\n\telse if (le16_to_cpu(sbi->s_es->s_errors) == EXT4_ERRORS_CONTINUE)\n\t\tset_opt(sb, ERRORS_CONT);\n\telse\n\t\tset_opt(sb, ERRORS_RO);\n\t/* block_validity enabled by default; disable with noblock_validity */\n\tset_opt(sb, BLOCK_VALIDITY);\n\tif (def_mount_opts & EXT4_DEFM_DISCARD)\n\t\tset_opt(sb, DISCARD);\n\n\tsbi->s_resuid = make_kuid(&init_user_ns, le16_to_cpu(es->s_def_resuid));\n\tsbi->s_resgid = make_kgid(&init_user_ns, le16_to_cpu(es->s_def_resgid));\n\tsbi->s_commit_interval = JBD2_DEFAULT_MAX_COMMIT_AGE * HZ;\n\tsbi->s_min_batch_time = EXT4_DEF_MIN_BATCH_TIME;\n\tsbi->s_max_batch_time = EXT4_DEF_MAX_BATCH_TIME;\n\n\tif ((def_mount_opts & EXT4_DEFM_NOBARRIER) == 0)\n\t\tset_opt(sb, BARRIER);\n\n\t/*\n\t * enable delayed allocation by default\n\t * Use -o nodelalloc to turn it off\n\t */\n\tif (!IS_EXT3_SB(sb) && !IS_EXT2_SB(sb) &&\n\t    ((def_mount_opts & EXT4_DEFM_NODELALLOC) == 0))\n\t\tset_opt(sb, DELALLOC);\n\n\t/*\n\t * set default s_li_wait_mult for lazyinit, for the case there is\n\t * no mount option specified.\n\t */\n\tsbi->s_li_wait_mult = EXT4_DEF_LI_WAIT_MULT;\n\n\tif (sbi->s_es->s_mount_opts[0]) {\n\t\tchar *s_mount_opts = kstrndup(sbi->s_es->s_mount_opts,\n\t\t\t\t\t      sizeof(sbi->s_es->s_mount_opts),\n\t\t\t\t\t      GFP_KERNEL);\n\t\tif (!s_mount_opts)\n\t\t\tgoto failed_mount;\n\t\tif (!parse_options(s_mount_opts, sb, &journal_devnum,\n\t\t\t\t   &journal_ioprio, 0)) {\n\t\t\text4_msg(sb, KERN_WARNING,\n\t\t\t\t \"failed to parse options in superblock: %s\",\n\t\t\t\t s_mount_opts);\n\t\t}\n\t\tkfree(s_mount_opts);\n\t}\n\tsbi->s_def_mount_opt = sbi->s_mount_opt;\n\tif (!parse_options((char *) data, sb, &journal_devnum,\n\t\t\t   &journal_ioprio, 0))\n\t\tgoto failed_mount;\n\n\tif (test_opt(sb, DATA_FLAGS) == EXT4_MOUNT_JOURNAL_DATA) {\n\t\tprintk_once(KERN_WARNING \"EXT4-fs: Warning: mounting \"\n\t\t\t    \"with data=journal disables delayed \"\n\t\t\t    \"allocation and O_DIRECT support!\\n\");\n\t\tif (test_opt2(sb, EXPLICIT_DELALLOC)) {\n\t\t\text4_msg(sb, KERN_ERR, \"can't mount with \"\n\t\t\t\t \"both data=journal and delalloc\");\n\t\t\tgoto failed_mount;\n\t\t}\n\t\tif (test_opt(sb, DIOREAD_NOLOCK)) {\n\t\t\text4_msg(sb, KERN_ERR, \"can't mount with \"\n\t\t\t\t \"both data=journal and dioread_nolock\");\n\t\t\tgoto failed_mount;\n\t\t}\n\t\tif (test_opt(sb, DAX)) {\n\t\t\text4_msg(sb, KERN_ERR, \"can't mount with \"\n\t\t\t\t \"both data=journal and dax\");\n\t\t\tgoto failed_mount;\n\t\t}\n\t\tif (test_opt(sb, DELALLOC))\n\t\t\tclear_opt(sb, DELALLOC);\n\t} else {\n\t\tsb->s_iflags |= SB_I_CGROUPWB;\n\t}\n\n\tsb->s_flags = (sb->s_flags & ~MS_POSIXACL) |\n\t\t(test_opt(sb, POSIX_ACL) ? MS_POSIXACL : 0);\n\n\tif (le32_to_cpu(es->s_rev_level) == EXT4_GOOD_OLD_REV &&\n\t    (ext4_has_compat_features(sb) ||\n\t     ext4_has_ro_compat_features(sb) ||\n\t     ext4_has_incompat_features(sb)))\n\t\text4_msg(sb, KERN_WARNING,\n\t\t       \"feature flags set on rev 0 fs, \"\n\t\t       \"running e2fsck is recommended\");\n\n\tif (es->s_creator_os == cpu_to_le32(EXT4_OS_HURD)) {\n\t\tset_opt2(sb, HURD_COMPAT);\n\t\tif (ext4_has_feature_64bit(sb)) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t\t \"The Hurd can't support 64-bit file systems\");\n\t\t\tgoto failed_mount;\n\t\t}\n\t}\n\n\tif (IS_EXT2_SB(sb)) {\n\t\tif (ext2_feature_set_ok(sb))\n\t\t\text4_msg(sb, KERN_INFO, \"mounting ext2 file system \"\n\t\t\t\t \"using the ext4 subsystem\");\n\t\telse {\n\t\t\text4_msg(sb, KERN_ERR, \"couldn't mount as ext2 due \"\n\t\t\t\t \"to feature incompatibilities\");\n\t\t\tgoto failed_mount;\n\t\t}\n\t}\n\n\tif (IS_EXT3_SB(sb)) {\n\t\tif (ext3_feature_set_ok(sb))\n\t\t\text4_msg(sb, KERN_INFO, \"mounting ext3 file system \"\n\t\t\t\t \"using the ext4 subsystem\");\n\t\telse {\n\t\t\text4_msg(sb, KERN_ERR, \"couldn't mount as ext3 due \"\n\t\t\t\t \"to feature incompatibilities\");\n\t\t\tgoto failed_mount;\n\t\t}\n\t}\n\n\t/*\n\t * Check feature flags regardless of the revision level, since we\n\t * previously didn't change the revision level when setting the flags,\n\t * so there is a chance incompat flags are set on a rev 0 filesystem.\n\t */\n\tif (!ext4_feature_set_ok(sb, (sb->s_flags & MS_RDONLY)))\n\t\tgoto failed_mount;\n\n\tblocksize = BLOCK_SIZE << le32_to_cpu(es->s_log_block_size);\n\tif (blocksize < EXT4_MIN_BLOCK_SIZE ||\n\t    blocksize > EXT4_MAX_BLOCK_SIZE) {\n\t\text4_msg(sb, KERN_ERR,\n\t\t       \"Unsupported filesystem blocksize %d (%d log_block_size)\",\n\t\t\t blocksize, le32_to_cpu(es->s_log_block_size));\n\t\tgoto failed_mount;\n\t}\n\tif (le32_to_cpu(es->s_log_block_size) >\n\t    (EXT4_MAX_BLOCK_LOG_SIZE - EXT4_MIN_BLOCK_LOG_SIZE)) {\n\t\text4_msg(sb, KERN_ERR,\n\t\t\t \"Invalid log block size: %u\",\n\t\t\t le32_to_cpu(es->s_log_block_size));\n\t\tgoto failed_mount;\n\t}\n\n\tif (le16_to_cpu(sbi->s_es->s_reserved_gdt_blocks) > (blocksize / 4)) {\n\t\text4_msg(sb, KERN_ERR,\n\t\t\t \"Number of reserved GDT blocks insanely large: %d\",\n\t\t\t le16_to_cpu(sbi->s_es->s_reserved_gdt_blocks));\n\t\tgoto failed_mount;\n\t}\n\n\tif (sbi->s_mount_opt & EXT4_MOUNT_DAX) {\n\t\terr = bdev_dax_supported(sb, blocksize);\n\t\tif (err)\n\t\t\tgoto failed_mount;\n\t}\n\n\tif (ext4_has_feature_encrypt(sb) && es->s_encryption_level) {\n\t\text4_msg(sb, KERN_ERR, \"Unsupported encryption level %d\",\n\t\t\t es->s_encryption_level);\n\t\tgoto failed_mount;\n\t}\n\n\tif (sb->s_blocksize != blocksize) {\n\t\t/* Validate the filesystem blocksize */\n\t\tif (!sb_set_blocksize(sb, blocksize)) {\n\t\t\text4_msg(sb, KERN_ERR, \"bad block size %d\",\n\t\t\t\t\tblocksize);\n\t\t\tgoto failed_mount;\n\t\t}\n\n\t\tbrelse(bh);\n\t\tlogical_sb_block = sb_block * EXT4_MIN_BLOCK_SIZE;\n\t\toffset = do_div(logical_sb_block, blocksize);\n\t\tbh = sb_bread_unmovable(sb, logical_sb_block);\n\t\tif (!bh) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t       \"Can't read superblock on 2nd try\");\n\t\t\tgoto failed_mount;\n\t\t}\n\t\tes = (struct ext4_super_block *)(bh->b_data + offset);\n\t\tsbi->s_es = es;\n\t\tif (es->s_magic != cpu_to_le16(EXT4_SUPER_MAGIC)) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t       \"Magic mismatch, very weird!\");\n\t\t\tgoto failed_mount;\n\t\t}\n\t}\n\n\thas_huge_files = ext4_has_feature_huge_file(sb);\n\tsbi->s_bitmap_maxbytes = ext4_max_bitmap_size(sb->s_blocksize_bits,\n\t\t\t\t\t\t      has_huge_files);\n\tsb->s_maxbytes = ext4_max_size(sb->s_blocksize_bits, has_huge_files);\n\n\tif (le32_to_cpu(es->s_rev_level) == EXT4_GOOD_OLD_REV) {\n\t\tsbi->s_inode_size = EXT4_GOOD_OLD_INODE_SIZE;\n\t\tsbi->s_first_ino = EXT4_GOOD_OLD_FIRST_INO;\n\t} else {\n\t\tsbi->s_inode_size = le16_to_cpu(es->s_inode_size);\n\t\tsbi->s_first_ino = le32_to_cpu(es->s_first_ino);\n\t\tif ((sbi->s_inode_size < EXT4_GOOD_OLD_INODE_SIZE) ||\n\t\t    (!is_power_of_2(sbi->s_inode_size)) ||\n\t\t    (sbi->s_inode_size > blocksize)) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t       \"unsupported inode size: %d\",\n\t\t\t       sbi->s_inode_size);\n\t\t\tgoto failed_mount;\n\t\t}\n\t\tif (sbi->s_inode_size > EXT4_GOOD_OLD_INODE_SIZE)\n\t\t\tsb->s_time_gran = 1 << (EXT4_EPOCH_BITS - 2);\n\t}\n\n\tsbi->s_desc_size = le16_to_cpu(es->s_desc_size);\n\tif (ext4_has_feature_64bit(sb)) {\n\t\tif (sbi->s_desc_size < EXT4_MIN_DESC_SIZE_64BIT ||\n\t\t    sbi->s_desc_size > EXT4_MAX_DESC_SIZE ||\n\t\t    !is_power_of_2(sbi->s_desc_size)) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t       \"unsupported descriptor size %lu\",\n\t\t\t       sbi->s_desc_size);\n\t\t\tgoto failed_mount;\n\t\t}\n\t} else\n\t\tsbi->s_desc_size = EXT4_MIN_DESC_SIZE;\n\n\tsbi->s_blocks_per_group = le32_to_cpu(es->s_blocks_per_group);\n\tsbi->s_inodes_per_group = le32_to_cpu(es->s_inodes_per_group);\n\n\tsbi->s_inodes_per_block = blocksize / EXT4_INODE_SIZE(sb);\n\tif (sbi->s_inodes_per_block == 0)\n\t\tgoto cantfind_ext4;\n\tif (sbi->s_inodes_per_group < sbi->s_inodes_per_block ||\n\t    sbi->s_inodes_per_group > blocksize * 8) {\n\t\text4_msg(sb, KERN_ERR, \"invalid inodes per group: %lu\\n\",\n\t\t\t sbi->s_blocks_per_group);\n\t\tgoto failed_mount;\n\t}\n\tsbi->s_itb_per_group = sbi->s_inodes_per_group /\n\t\t\t\t\tsbi->s_inodes_per_block;\n\tsbi->s_desc_per_block = blocksize / EXT4_DESC_SIZE(sb);\n\tsbi->s_sbh = bh;\n\tsbi->s_mount_state = le16_to_cpu(es->s_state);\n\tsbi->s_addr_per_block_bits = ilog2(EXT4_ADDR_PER_BLOCK(sb));\n\tsbi->s_desc_per_block_bits = ilog2(EXT4_DESC_PER_BLOCK(sb));\n\n\tfor (i = 0; i < 4; i++)\n\t\tsbi->s_hash_seed[i] = le32_to_cpu(es->s_hash_seed[i]);\n\tsbi->s_def_hash_version = es->s_def_hash_version;\n\tif (ext4_has_feature_dir_index(sb)) {\n\t\ti = le32_to_cpu(es->s_flags);\n\t\tif (i & EXT2_FLAGS_UNSIGNED_HASH)\n\t\t\tsbi->s_hash_unsigned = 3;\n\t\telse if ((i & EXT2_FLAGS_SIGNED_HASH) == 0) {\n#ifdef __CHAR_UNSIGNED__\n\t\t\tif (!(sb->s_flags & MS_RDONLY))\n\t\t\t\tes->s_flags |=\n\t\t\t\t\tcpu_to_le32(EXT2_FLAGS_UNSIGNED_HASH);\n\t\t\tsbi->s_hash_unsigned = 3;\n#else\n\t\t\tif (!(sb->s_flags & MS_RDONLY))\n\t\t\t\tes->s_flags |=\n\t\t\t\t\tcpu_to_le32(EXT2_FLAGS_SIGNED_HASH);\n#endif\n\t\t}\n\t}\n\n\t/* Handle clustersize */\n\tclustersize = BLOCK_SIZE << le32_to_cpu(es->s_log_cluster_size);\n\thas_bigalloc = ext4_has_feature_bigalloc(sb);\n\tif (has_bigalloc) {\n\t\tif (clustersize < blocksize) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t\t \"cluster size (%d) smaller than \"\n\t\t\t\t \"block size (%d)\", clustersize, blocksize);\n\t\t\tgoto failed_mount;\n\t\t}\n\t\tif (le32_to_cpu(es->s_log_cluster_size) >\n\t\t    (EXT4_MAX_CLUSTER_LOG_SIZE - EXT4_MIN_BLOCK_LOG_SIZE)) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t\t \"Invalid log cluster size: %u\",\n\t\t\t\t le32_to_cpu(es->s_log_cluster_size));\n\t\t\tgoto failed_mount;\n\t\t}\n\t\tsbi->s_cluster_bits = le32_to_cpu(es->s_log_cluster_size) -\n\t\t\tle32_to_cpu(es->s_log_block_size);\n\t\tsbi->s_clusters_per_group =\n\t\t\tle32_to_cpu(es->s_clusters_per_group);\n\t\tif (sbi->s_clusters_per_group > blocksize * 8) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t\t \"#clusters per group too big: %lu\",\n\t\t\t\t sbi->s_clusters_per_group);\n\t\t\tgoto failed_mount;\n\t\t}\n\t\tif (sbi->s_blocks_per_group !=\n\t\t    (sbi->s_clusters_per_group * (clustersize / blocksize))) {\n\t\t\text4_msg(sb, KERN_ERR, \"blocks per group (%lu) and \"\n\t\t\t\t \"clusters per group (%lu) inconsistent\",\n\t\t\t\t sbi->s_blocks_per_group,\n\t\t\t\t sbi->s_clusters_per_group);\n\t\t\tgoto failed_mount;\n\t\t}\n\t} else {\n\t\tif (clustersize != blocksize) {\n\t\t\text4_warning(sb, \"fragment/cluster size (%d) != \"\n\t\t\t\t     \"block size (%d)\", clustersize,\n\t\t\t\t     blocksize);\n\t\t\tclustersize = blocksize;\n\t\t}\n\t\tif (sbi->s_blocks_per_group > blocksize * 8) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t\t \"#blocks per group too big: %lu\",\n\t\t\t\t sbi->s_blocks_per_group);\n\t\t\tgoto failed_mount;\n\t\t}\n\t\tsbi->s_clusters_per_group = sbi->s_blocks_per_group;\n\t\tsbi->s_cluster_bits = 0;\n\t}\n\tsbi->s_cluster_ratio = clustersize / blocksize;\n\n\t/* Do we have standard group size of clustersize * 8 blocks ? */\n\tif (sbi->s_blocks_per_group == clustersize << 3)\n\t\tset_opt2(sb, STD_GROUP_SIZE);\n\n\t/*\n\t * Test whether we have more sectors than will fit in sector_t,\n\t * and whether the max offset is addressable by the page cache.\n\t */\n\terr = generic_check_addressable(sb->s_blocksize_bits,\n\t\t\t\t\text4_blocks_count(es));\n\tif (err) {\n\t\text4_msg(sb, KERN_ERR, \"filesystem\"\n\t\t\t \" too large to mount safely on this system\");\n\t\tif (sizeof(sector_t) < 8)\n\t\t\text4_msg(sb, KERN_WARNING, \"CONFIG_LBDAF not enabled\");\n\t\tgoto failed_mount;\n\t}\n\n\tif (EXT4_BLOCKS_PER_GROUP(sb) == 0)\n\t\tgoto cantfind_ext4;\n\n\t/* check blocks count against device size */\n\tblocks_count = sb->s_bdev->bd_inode->i_size >> sb->s_blocksize_bits;\n\tif (blocks_count && ext4_blocks_count(es) > blocks_count) {\n\t\text4_msg(sb, KERN_WARNING, \"bad geometry: block count %llu \"\n\t\t       \"exceeds size of device (%llu blocks)\",\n\t\t       ext4_blocks_count(es), blocks_count);\n\t\tgoto failed_mount;\n\t}\n\n\t/*\n\t * It makes no sense for the first data block to be beyond the end\n\t * of the filesystem.\n\t */\n\tif (le32_to_cpu(es->s_first_data_block) >= ext4_blocks_count(es)) {\n\t\text4_msg(sb, KERN_WARNING, \"bad geometry: first data \"\n\t\t\t \"block %u is beyond end of filesystem (%llu)\",\n\t\t\t le32_to_cpu(es->s_first_data_block),\n\t\t\t ext4_blocks_count(es));\n\t\tgoto failed_mount;\n\t}\n\tblocks_count = (ext4_blocks_count(es) -\n\t\t\tle32_to_cpu(es->s_first_data_block) +\n\t\t\tEXT4_BLOCKS_PER_GROUP(sb) - 1);\n\tdo_div(blocks_count, EXT4_BLOCKS_PER_GROUP(sb));\n\tif (blocks_count > ((uint64_t)1<<32) - EXT4_DESC_PER_BLOCK(sb)) {\n\t\text4_msg(sb, KERN_WARNING, \"groups count too large: %u \"\n\t\t       \"(block count %llu, first data block %u, \"\n\t\t       \"blocks per group %lu)\", sbi->s_groups_count,\n\t\t       ext4_blocks_count(es),\n\t\t       le32_to_cpu(es->s_first_data_block),\n\t\t       EXT4_BLOCKS_PER_GROUP(sb));\n\t\tgoto failed_mount;\n\t}\n\tsbi->s_groups_count = blocks_count;\n\tsbi->s_blockfile_groups = min_t(ext4_group_t, sbi->s_groups_count,\n\t\t\t(EXT4_MAX_BLOCK_FILE_PHYS / EXT4_BLOCKS_PER_GROUP(sb)));\n\tdb_count = (sbi->s_groups_count + EXT4_DESC_PER_BLOCK(sb) - 1) /\n\t\t   EXT4_DESC_PER_BLOCK(sb);\n\tif (ext4_has_feature_meta_bg(sb)) {\n\t\tif (le32_to_cpu(es->s_first_meta_bg) >= db_count) {\n\t\t\text4_msg(sb, KERN_WARNING,\n\t\t\t\t \"first meta block group too large: %u \"\n\t\t\t\t \"(group descriptor block count %u)\",\n\t\t\t\t le32_to_cpu(es->s_first_meta_bg), db_count);\n\t\t\tgoto failed_mount;\n\t\t}\n\t}\n\tsbi->s_group_desc = ext4_kvmalloc(db_count *\n\t\t\t\t\t  sizeof(struct buffer_head *),\n\t\t\t\t\t  GFP_KERNEL);\n\tif (sbi->s_group_desc == NULL) {\n\t\text4_msg(sb, KERN_ERR, \"not enough memory\");\n\t\tret = -ENOMEM;\n\t\tgoto failed_mount;\n\t}\n\n\tbgl_lock_init(sbi->s_blockgroup_lock);\n\n\tfor (i = 0; i < db_count; i++) {\n\t\tblock = descriptor_loc(sb, logical_sb_block, i);\n\t\tsbi->s_group_desc[i] = sb_bread_unmovable(sb, block);\n\t\tif (!sbi->s_group_desc[i]) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t       \"can't read group descriptor %d\", i);\n\t\t\tdb_count = i;\n\t\t\tgoto failed_mount2;\n\t\t}\n\t}\n\tif (!ext4_check_descriptors(sb, logical_sb_block, &first_not_zeroed)) {\n\t\text4_msg(sb, KERN_ERR, \"group descriptors corrupted!\");\n\t\tret = -EFSCORRUPTED;\n\t\tgoto failed_mount2;\n\t}\n\n\tsbi->s_gdb_count = db_count;\n\tget_random_bytes(&sbi->s_next_generation, sizeof(u32));\n\tspin_lock_init(&sbi->s_next_gen_lock);\n\n\tsetup_timer(&sbi->s_err_report, print_daily_error_info,\n\t\t(unsigned long) sb);\n\n\t/* Register extent status tree shrinker */\n\tif (ext4_es_register_shrinker(sbi))\n\t\tgoto failed_mount3;\n\n\tsbi->s_stripe = ext4_get_stripe_size(sbi);\n\tsbi->s_extent_max_zeroout_kb = 32;\n\n\t/*\n\t * set up enough so that it can read an inode\n\t */\n\tsb->s_op = &ext4_sops;\n\tsb->s_export_op = &ext4_export_ops;\n\tsb->s_xattr = ext4_xattr_handlers;\n\tsb->s_cop = &ext4_cryptops;\n#ifdef CONFIG_QUOTA\n\tsb->dq_op = &ext4_quota_operations;\n\tif (ext4_has_feature_quota(sb))\n\t\tsb->s_qcop = &dquot_quotactl_sysfile_ops;\n\telse\n\t\tsb->s_qcop = &ext4_qctl_operations;\n\tsb->s_quota_types = QTYPE_MASK_USR | QTYPE_MASK_GRP | QTYPE_MASK_PRJ;\n#endif\n\tmemcpy(sb->s_uuid, es->s_uuid, sizeof(es->s_uuid));\n\n\tINIT_LIST_HEAD(&sbi->s_orphan); /* unlinked but open files */\n\tmutex_init(&sbi->s_orphan_lock);\n\n\tsb->s_root = NULL;\n\n\tneeds_recovery = (es->s_last_orphan != 0 ||\n\t\t\t  ext4_has_feature_journal_needs_recovery(sb));\n\n\tif (ext4_has_feature_mmp(sb) && !(sb->s_flags & MS_RDONLY))\n\t\tif (ext4_multi_mount_protect(sb, le64_to_cpu(es->s_mmp_block)))\n\t\t\tgoto failed_mount3a;\n\n\t/*\n\t * The first inode we look at is the journal inode.  Don't try\n\t * root first: it may be modified in the journal!\n\t */\n\tif (!test_opt(sb, NOLOAD) && ext4_has_feature_journal(sb)) {\n\t\tif (ext4_load_journal(sb, es, journal_devnum))\n\t\t\tgoto failed_mount3a;\n\t} else if (test_opt(sb, NOLOAD) && !(sb->s_flags & MS_RDONLY) &&\n\t\t   ext4_has_feature_journal_needs_recovery(sb)) {\n\t\text4_msg(sb, KERN_ERR, \"required journal recovery \"\n\t\t       \"suppressed and not mounted read-only\");\n\t\tgoto failed_mount_wq;\n\t} else {\n\t\t/* Nojournal mode, all journal mount options are illegal */\n\t\tif (test_opt2(sb, EXPLICIT_JOURNAL_CHECKSUM)) {\n\t\t\text4_msg(sb, KERN_ERR, \"can't mount with \"\n\t\t\t\t \"journal_checksum, fs mounted w/o journal\");\n\t\t\tgoto failed_mount_wq;\n\t\t}\n\t\tif (test_opt(sb, JOURNAL_ASYNC_COMMIT)) {\n\t\t\text4_msg(sb, KERN_ERR, \"can't mount with \"\n\t\t\t\t \"journal_async_commit, fs mounted w/o journal\");\n\t\t\tgoto failed_mount_wq;\n\t\t}\n\t\tif (sbi->s_commit_interval != JBD2_DEFAULT_MAX_COMMIT_AGE*HZ) {\n\t\t\text4_msg(sb, KERN_ERR, \"can't mount with \"\n\t\t\t\t \"commit=%lu, fs mounted w/o journal\",\n\t\t\t\t sbi->s_commit_interval / HZ);\n\t\t\tgoto failed_mount_wq;\n\t\t}\n\t\tif (EXT4_MOUNT_DATA_FLAGS &\n\t\t    (sbi->s_mount_opt ^ sbi->s_def_mount_opt)) {\n\t\t\text4_msg(sb, KERN_ERR, \"can't mount with \"\n\t\t\t\t \"data=, fs mounted w/o journal\");\n\t\t\tgoto failed_mount_wq;\n\t\t}\n\t\tsbi->s_def_mount_opt &= EXT4_MOUNT_JOURNAL_CHECKSUM;\n\t\tclear_opt(sb, JOURNAL_CHECKSUM);\n\t\tclear_opt(sb, DATA_FLAGS);\n\t\tsbi->s_journal = NULL;\n\t\tneeds_recovery = 0;\n\t\tgoto no_journal;\n\t}\n\n\tif (ext4_has_feature_64bit(sb) &&\n\t    !jbd2_journal_set_features(EXT4_SB(sb)->s_journal, 0, 0,\n\t\t\t\t       JBD2_FEATURE_INCOMPAT_64BIT)) {\n\t\text4_msg(sb, KERN_ERR, \"Failed to set 64-bit journal feature\");\n\t\tgoto failed_mount_wq;\n\t}\n\n\tif (!set_journal_csum_feature_set(sb)) {\n\t\text4_msg(sb, KERN_ERR, \"Failed to set journal checksum \"\n\t\t\t \"feature set\");\n\t\tgoto failed_mount_wq;\n\t}\n\n\t/* We have now updated the journal if required, so we can\n\t * validate the data journaling mode. */\n\tswitch (test_opt(sb, DATA_FLAGS)) {\n\tcase 0:\n\t\t/* No mode set, assume a default based on the journal\n\t\t * capabilities: ORDERED_DATA if the journal can\n\t\t * cope, else JOURNAL_DATA\n\t\t */\n\t\tif (jbd2_journal_check_available_features\n\t\t    (sbi->s_journal, 0, 0, JBD2_FEATURE_INCOMPAT_REVOKE))\n\t\t\tset_opt(sb, ORDERED_DATA);\n\t\telse\n\t\t\tset_opt(sb, JOURNAL_DATA);\n\t\tbreak;\n\n\tcase EXT4_MOUNT_ORDERED_DATA:\n\tcase EXT4_MOUNT_WRITEBACK_DATA:\n\t\tif (!jbd2_journal_check_available_features\n\t\t    (sbi->s_journal, 0, 0, JBD2_FEATURE_INCOMPAT_REVOKE)) {\n\t\t\text4_msg(sb, KERN_ERR, \"Journal does not support \"\n\t\t\t       \"requested data journaling mode\");\n\t\t\tgoto failed_mount_wq;\n\t\t}\n\tdefault:\n\t\tbreak;\n\t}\n\tset_task_ioprio(sbi->s_journal->j_task, journal_ioprio);\n\n\tsbi->s_journal->j_commit_callback = ext4_journal_commit_callback;\n\nno_journal:\n\tsbi->s_mb_cache = ext4_xattr_create_cache();\n\tif (!sbi->s_mb_cache) {\n\t\text4_msg(sb, KERN_ERR, \"Failed to create an mb_cache\");\n\t\tgoto failed_mount_wq;\n\t}\n\n\tif ((DUMMY_ENCRYPTION_ENABLED(sbi) || ext4_has_feature_encrypt(sb)) &&\n\t    (blocksize != PAGE_SIZE)) {\n\t\text4_msg(sb, KERN_ERR,\n\t\t\t \"Unsupported blocksize for fs encryption\");\n\t\tgoto failed_mount_wq;\n\t}\n\n\tif (DUMMY_ENCRYPTION_ENABLED(sbi) && !(sb->s_flags & MS_RDONLY) &&\n\t    !ext4_has_feature_encrypt(sb)) {\n\t\text4_set_feature_encrypt(sb);\n\t\text4_commit_super(sb, 1);\n\t}\n\n\t/*\n\t * Get the # of file system overhead blocks from the\n\t * superblock if present.\n\t */\n\tif (es->s_overhead_clusters)\n\t\tsbi->s_overhead = le32_to_cpu(es->s_overhead_clusters);\n\telse {\n\t\terr = ext4_calculate_overhead(sb);\n\t\tif (err)\n\t\t\tgoto failed_mount_wq;\n\t}\n\n\t/*\n\t * The maximum number of concurrent works can be high and\n\t * concurrency isn't really necessary.  Limit it to 1.\n\t */\n\tEXT4_SB(sb)->rsv_conversion_wq =\n\t\talloc_workqueue(\"ext4-rsv-conversion\", WQ_MEM_RECLAIM | WQ_UNBOUND, 1);\n\tif (!EXT4_SB(sb)->rsv_conversion_wq) {\n\t\tprintk(KERN_ERR \"EXT4-fs: failed to create workqueue\\n\");\n\t\tret = -ENOMEM;\n\t\tgoto failed_mount4;\n\t}\n\n\t/*\n\t * The jbd2_journal_load will have done any necessary log recovery,\n\t * so we can safely mount the rest of the filesystem now.\n\t */\n\n\troot = ext4_iget(sb, EXT4_ROOT_INO);\n\tif (IS_ERR(root)) {\n\t\text4_msg(sb, KERN_ERR, \"get root inode failed\");\n\t\tret = PTR_ERR(root);\n\t\troot = NULL;\n\t\tgoto failed_mount4;\n\t}\n\tif (!S_ISDIR(root->i_mode) || !root->i_blocks || !root->i_size) {\n\t\text4_msg(sb, KERN_ERR, \"corrupt root inode, run e2fsck\");\n\t\tiput(root);\n\t\tgoto failed_mount4;\n\t}\n\tsb->s_root = d_make_root(root);\n\tif (!sb->s_root) {\n\t\text4_msg(sb, KERN_ERR, \"get root dentry failed\");\n\t\tret = -ENOMEM;\n\t\tgoto failed_mount4;\n\t}\n\n\tif (ext4_setup_super(sb, es, sb->s_flags & MS_RDONLY))\n\t\tsb->s_flags |= MS_RDONLY;\n\n\t/* determine the minimum size of new large inodes, if present */\n\tif (sbi->s_inode_size > EXT4_GOOD_OLD_INODE_SIZE) {\n\t\tsbi->s_want_extra_isize = sizeof(struct ext4_inode) -\n\t\t\t\t\t\t     EXT4_GOOD_OLD_INODE_SIZE;\n\t\tif (ext4_has_feature_extra_isize(sb)) {\n\t\t\tif (sbi->s_want_extra_isize <\n\t\t\t    le16_to_cpu(es->s_want_extra_isize))\n\t\t\t\tsbi->s_want_extra_isize =\n\t\t\t\t\tle16_to_cpu(es->s_want_extra_isize);\n\t\t\tif (sbi->s_want_extra_isize <\n\t\t\t    le16_to_cpu(es->s_min_extra_isize))\n\t\t\t\tsbi->s_want_extra_isize =\n\t\t\t\t\tle16_to_cpu(es->s_min_extra_isize);\n\t\t}\n\t}\n\t/* Check if enough inode space is available */\n\tif (EXT4_GOOD_OLD_INODE_SIZE + sbi->s_want_extra_isize >\n\t\t\t\t\t\t\tsbi->s_inode_size) {\n\t\tsbi->s_want_extra_isize = sizeof(struct ext4_inode) -\n\t\t\t\t\t\t       EXT4_GOOD_OLD_INODE_SIZE;\n\t\text4_msg(sb, KERN_INFO, \"required extra inode space not\"\n\t\t\t \"available\");\n\t}\n\n\text4_set_resv_clusters(sb);\n\n\terr = ext4_setup_system_zone(sb);\n\tif (err) {\n\t\text4_msg(sb, KERN_ERR, \"failed to initialize system \"\n\t\t\t \"zone (%d)\", err);\n\t\tgoto failed_mount4a;\n\t}\n\n\text4_ext_init(sb);\n\terr = ext4_mb_init(sb);\n\tif (err) {\n\t\text4_msg(sb, KERN_ERR, \"failed to initialize mballoc (%d)\",\n\t\t\t err);\n\t\tgoto failed_mount5;\n\t}\n\n\tblock = ext4_count_free_clusters(sb);\n\text4_free_blocks_count_set(sbi->s_es, \n\t\t\t\t   EXT4_C2B(sbi, block));\n\terr = percpu_counter_init(&sbi->s_freeclusters_counter, block,\n\t\t\t\t  GFP_KERNEL);\n\tif (!err) {\n\t\tunsigned long freei = ext4_count_free_inodes(sb);\n\t\tsbi->s_es->s_free_inodes_count = cpu_to_le32(freei);\n\t\terr = percpu_counter_init(&sbi->s_freeinodes_counter, freei,\n\t\t\t\t\t  GFP_KERNEL);\n\t}\n\tif (!err)\n\t\terr = percpu_counter_init(&sbi->s_dirs_counter,\n\t\t\t\t\t  ext4_count_dirs(sb), GFP_KERNEL);\n\tif (!err)\n\t\terr = percpu_counter_init(&sbi->s_dirtyclusters_counter, 0,\n\t\t\t\t\t  GFP_KERNEL);\n\tif (!err)\n\t\terr = percpu_init_rwsem(&sbi->s_journal_flag_rwsem);\n\n\tif (err) {\n\t\text4_msg(sb, KERN_ERR, \"insufficient memory\");\n\t\tgoto failed_mount6;\n\t}\n\n\tif (ext4_has_feature_flex_bg(sb))\n\t\tif (!ext4_fill_flex_info(sb)) {\n\t\t\text4_msg(sb, KERN_ERR,\n\t\t\t       \"unable to initialize \"\n\t\t\t       \"flex_bg meta info!\");\n\t\t\tgoto failed_mount6;\n\t\t}\n\n\terr = ext4_register_li_request(sb, first_not_zeroed);\n\tif (err)\n\t\tgoto failed_mount6;\n\n\terr = ext4_register_sysfs(sb);\n\tif (err)\n\t\tgoto failed_mount7;\n\n#ifdef CONFIG_QUOTA\n\t/* Enable quota usage during mount. */\n\tif (ext4_has_feature_quota(sb) && !(sb->s_flags & MS_RDONLY)) {\n\t\terr = ext4_enable_quotas(sb);\n\t\tif (err)\n\t\t\tgoto failed_mount8;\n\t}\n#endif  /* CONFIG_QUOTA */\n\n\tEXT4_SB(sb)->s_mount_state |= EXT4_ORPHAN_FS;\n\text4_orphan_cleanup(sb, es);\n\tEXT4_SB(sb)->s_mount_state &= ~EXT4_ORPHAN_FS;\n\tif (needs_recovery) {\n\t\text4_msg(sb, KERN_INFO, \"recovery complete\");\n\t\text4_mark_recovery_complete(sb, es);\n\t}\n\tif (EXT4_SB(sb)->s_journal) {\n\t\tif (test_opt(sb, DATA_FLAGS) == EXT4_MOUNT_JOURNAL_DATA)\n\t\t\tdescr = \" journalled data mode\";\n\t\telse if (test_opt(sb, DATA_FLAGS) == EXT4_MOUNT_ORDERED_DATA)\n\t\t\tdescr = \" ordered data mode\";\n\t\telse\n\t\t\tdescr = \" writeback data mode\";\n\t} else\n\t\tdescr = \"out journal\";\n\n\tif (test_opt(sb, DISCARD)) {\n\t\tstruct request_queue *q = bdev_get_queue(sb->s_bdev);\n\t\tif (!blk_queue_discard(q))\n\t\t\text4_msg(sb, KERN_WARNING,\n\t\t\t\t \"mounting with \\\"discard\\\" option, but \"\n\t\t\t\t \"the device does not support discard\");\n\t}\n\n\tif (___ratelimit(&ext4_mount_msg_ratelimit, \"EXT4-fs mount\"))\n\t\text4_msg(sb, KERN_INFO, \"mounted filesystem with%s. \"\n\t\t\t \"Opts: %.*s%s%s\", descr,\n\t\t\t (int) sizeof(sbi->s_es->s_mount_opts),\n\t\t\t sbi->s_es->s_mount_opts,\n\t\t\t *sbi->s_es->s_mount_opts ? \"; \" : \"\", orig_data);\n\n\tif (es->s_error_count)\n\t\tmod_timer(&sbi->s_err_report, jiffies + 300*HZ); /* 5 minutes */\n\n\t/* Enable message ratelimiting. Default is 10 messages per 5 secs. */\n\tratelimit_state_init(&sbi->s_err_ratelimit_state, 5 * HZ, 10);\n\tratelimit_state_init(&sbi->s_warning_ratelimit_state, 5 * HZ, 10);\n\tratelimit_state_init(&sbi->s_msg_ratelimit_state, 5 * HZ, 10);\n\n\tkfree(orig_data);\n#ifdef CONFIG_EXT4_FS_ENCRYPTION\n\tmemcpy(sbi->key_prefix, EXT4_KEY_DESC_PREFIX,\n\t\t\t\tEXT4_KEY_DESC_PREFIX_SIZE);\n\tsbi->key_prefix_size = EXT4_KEY_DESC_PREFIX_SIZE;\n#endif\n\treturn 0;\n\ncantfind_ext4:\n\tif (!silent)\n\t\text4_msg(sb, KERN_ERR, \"VFS: Can't find ext4 filesystem\");\n\tgoto failed_mount;\n\n#ifdef CONFIG_QUOTA\nfailed_mount8:\n\text4_unregister_sysfs(sb);\n#endif\nfailed_mount7:\n\text4_unregister_li_request(sb);\nfailed_mount6:\n\text4_mb_release(sb);\n\tif (sbi->s_flex_groups)\n\t\tkvfree(sbi->s_flex_groups);\n\tpercpu_counter_destroy(&sbi->s_freeclusters_counter);\n\tpercpu_counter_destroy(&sbi->s_freeinodes_counter);\n\tpercpu_counter_destroy(&sbi->s_dirs_counter);\n\tpercpu_counter_destroy(&sbi->s_dirtyclusters_counter);\nfailed_mount5:\n\text4_ext_release(sb);\n\text4_release_system_zone(sb);\nfailed_mount4a:\n\tdput(sb->s_root);\n\tsb->s_root = NULL;\nfailed_mount4:\n\text4_msg(sb, KERN_ERR, \"mount failed\");\n\tif (EXT4_SB(sb)->rsv_conversion_wq)\n\t\tdestroy_workqueue(EXT4_SB(sb)->rsv_conversion_wq);\nfailed_mount_wq:\n\tif (sbi->s_mb_cache) {\n\t\text4_xattr_destroy_cache(sbi->s_mb_cache);\n\t\tsbi->s_mb_cache = NULL;\n\t}\n\tif (sbi->s_journal) {\n\t\tjbd2_journal_destroy(sbi->s_journal);\n\t\tsbi->s_journal = NULL;\n\t}\nfailed_mount3a:\n\text4_es_unregister_shrinker(sbi);\nfailed_mount3:\n\tdel_timer_sync(&sbi->s_err_report);\n\tif (sbi->s_mmp_tsk)\n\t\tkthread_stop(sbi->s_mmp_tsk);\nfailed_mount2:\n\tfor (i = 0; i < db_count; i++)\n\t\tbrelse(sbi->s_group_desc[i]);\n\tkvfree(sbi->s_group_desc);\nfailed_mount:\n\tif (sbi->s_chksum_driver)\n\t\tcrypto_free_shash(sbi->s_chksum_driver);\n#ifdef CONFIG_QUOTA\n\tfor (i = 0; i < EXT4_MAXQUOTAS; i++)\n\t\tkfree(sbi->s_qf_names[i]);\n#endif\n\text4_blkdev_remove(sbi);\n\tbrelse(bh);\nout_fail:\n\tsb->s_fs_info = NULL;\n\tkfree(sbi->s_blockgroup_lock);\nout_free_base:\n\tkfree(sbi);\n\tkfree(orig_data);\n\treturn err ? err : ret;\n}\n\n/*\n * Setup any per-fs journal parameters now.  We'll do this both on\n * initial mount, once the journal has been initialised but before we've\n * done any recovery; and again on any subsequent remount.\n */\nstatic void ext4_init_journal_params(struct super_block *sb, journal_t *journal)\n{\n\tstruct ext4_sb_info *sbi = EXT4_SB(sb);\n\n\tjournal->j_commit_interval = sbi->s_commit_interval;\n\tjournal->j_min_batch_time = sbi->s_min_batch_time;\n\tjournal->j_max_batch_time = sbi->s_max_batch_time;\n\n\twrite_lock(&journal->j_state_lock);\n\tif (test_opt(sb, BARRIER))\n\t\tjournal->j_flags |= JBD2_BARRIER;\n\telse\n\t\tjournal->j_flags &= ~JBD2_BARRIER;\n\tif (test_opt(sb, DATA_ERR_ABORT))\n\t\tjournal->j_flags |= JBD2_ABORT_ON_SYNCDATA_ERR;\n\telse\n\t\tjournal->j_flags &= ~JBD2_ABORT_ON_SYNCDATA_ERR;\n\twrite_unlock(&journal->j_state_lock);\n}\n\nstatic struct inode *ext4_get_journal_inode(struct super_block *sb,\n\t\t\t\t\t     unsigned int journal_inum)\n{\n\tstruct inode *journal_inode;\n\n\t/*\n\t * Test for the existence of a valid inode on disk.  Bad things\n\t * happen if we iget() an unused inode, as the subsequent iput()\n\t * will try to delete it.\n\t */\n\tjournal_inode = ext4_iget(sb, journal_inum);\n\tif (IS_ERR(journal_inode)) {\n\t\text4_msg(sb, KERN_ERR, \"no journal found\");\n\t\treturn NULL;\n\t}\n\tif (!journal_inode->i_nlink) {\n\t\tmake_bad_inode(journal_inode);\n\t\tiput(journal_inode);\n\t\text4_msg(sb, KERN_ERR, \"journal inode is deleted\");\n\t\treturn NULL;\n\t}\n\n\tjbd_debug(2, \"Journal inode found at %p: %lld bytes\\n\",\n\t\t  journal_inode, journal_inode->i_size);\n\tif (!S_ISREG(journal_inode->i_mode)) {\n\t\text4_msg(sb, KERN_ERR, \"invalid journal inode\");\n\t\tiput(journal_inode);\n\t\treturn NULL;\n\t}\n\treturn journal_inode;\n}\n\nstatic journal_t *ext4_get_journal(struct super_block *sb,\n\t\t\t\t   unsigned int journal_inum)\n{\n\tstruct inode *journal_inode;\n\tjournal_t *journal;\n\n\tBUG_ON(!ext4_has_feature_journal(sb));\n\n\tjournal_inode = ext4_get_journal_inode(sb, journal_inum);\n\tif (!journal_inode)\n\t\treturn NULL;\n\n\tjournal = jbd2_journal_init_inode(journal_inode);\n\tif (!journal) {\n\t\text4_msg(sb, KERN_ERR, \"Could not load journal inode\");\n\t\tiput(journal_inode);\n\t\treturn NULL;\n\t}\n\tjournal->j_private = sb;\n\text4_init_journal_params(sb, journal);\n\treturn journal;\n}\n\nstatic journal_t *ext4_get_dev_journal(struct super_block *sb,\n\t\t\t\t       dev_t j_dev)\n{\n\tstruct buffer_head *bh;\n\tjournal_t *journal;\n\text4_fsblk_t start;\n\text4_fsblk_t len;\n\tint hblock, blocksize;\n\text4_fsblk_t sb_block;\n\tunsigned long offset;\n\tstruct ext4_super_block *es;\n\tstruct block_device *bdev;\n\n\tBUG_ON(!ext4_has_feature_journal(sb));\n\n\tbdev = ext4_blkdev_get(j_dev, sb);\n\tif (bdev == NULL)\n\t\treturn NULL;\n\n\tblocksize = sb->s_blocksize;\n\thblock = bdev_logical_block_size(bdev);\n\tif (blocksize < hblock) {\n\t\text4_msg(sb, KERN_ERR,\n\t\t\t\"blocksize too small for journal device\");\n\t\tgoto out_bdev;\n\t}\n\n\tsb_block = EXT4_MIN_BLOCK_SIZE / blocksize;\n\toffset = EXT4_MIN_BLOCK_SIZE % blocksize;\n\tset_blocksize(bdev, blocksize);\n\tif (!(bh = __bread(bdev, sb_block, blocksize))) {\n\t\text4_msg(sb, KERN_ERR, \"couldn't read superblock of \"\n\t\t       \"external journal\");\n\t\tgoto out_bdev;\n\t}\n\n\tes = (struct ext4_super_block *) (bh->b_data + offset);\n\tif ((le16_to_cpu(es->s_magic) != EXT4_SUPER_MAGIC) ||\n\t    !(le32_to_cpu(es->s_feature_incompat) &\n\t      EXT4_FEATURE_INCOMPAT_JOURNAL_DEV)) {\n\t\text4_msg(sb, KERN_ERR, \"external journal has \"\n\t\t\t\t\t\"bad superblock\");\n\t\tbrelse(bh);\n\t\tgoto out_bdev;\n\t}\n\n\tif ((le32_to_cpu(es->s_feature_ro_compat) &\n\t     EXT4_FEATURE_RO_COMPAT_METADATA_CSUM) &&\n\t    es->s_checksum != ext4_superblock_csum(sb, es)) {\n\t\text4_msg(sb, KERN_ERR, \"external journal has \"\n\t\t\t\t       \"corrupt superblock\");\n\t\tbrelse(bh);\n\t\tgoto out_bdev;\n\t}\n\n\tif (memcmp(EXT4_SB(sb)->s_es->s_journal_uuid, es->s_uuid, 16)) {\n\t\text4_msg(sb, KERN_ERR, \"journal UUID does not match\");\n\t\tbrelse(bh);\n\t\tgoto out_bdev;\n\t}\n\n\tlen = ext4_blocks_count(es);\n\tstart = sb_block + 1;\n\tbrelse(bh);\t/* we're done with the superblock */\n\n\tjournal = jbd2_journal_init_dev(bdev, sb->s_bdev,\n\t\t\t\t\tstart, len, blocksize);\n\tif (!journal) {\n\t\text4_msg(sb, KERN_ERR, \"failed to create device journal\");\n\t\tgoto out_bdev;\n\t}\n\tjournal->j_private = sb;\n\tll_rw_block(REQ_OP_READ, REQ_META | REQ_PRIO, 1, &journal->j_sb_buffer);\n\twait_on_buffer(journal->j_sb_buffer);\n\tif (!buffer_uptodate(journal->j_sb_buffer)) {\n\t\text4_msg(sb, KERN_ERR, \"I/O error on journal device\");\n\t\tgoto out_journal;\n\t}\n\tif (be32_to_cpu(journal->j_superblock->s_nr_users) != 1) {\n\t\text4_msg(sb, KERN_ERR, \"External journal has more than one \"\n\t\t\t\t\t\"user (unsupported) - %d\",\n\t\t\tbe32_to_cpu(journal->j_superblock->s_nr_users));\n\t\tgoto out_journal;\n\t}\n\tEXT4_SB(sb)->journal_bdev = bdev;\n\text4_init_journal_params(sb, journal);\n\treturn journal;\n\nout_journal:\n\tjbd2_journal_destroy(journal);\nout_bdev:\n\text4_blkdev_put(bdev);\n\treturn NULL;\n}\n\nstatic int ext4_load_journal(struct super_block *sb,\n\t\t\t     struct ext4_super_block *es,\n\t\t\t     unsigned long journal_devnum)\n{\n\tjournal_t *journal;\n\tunsigned int journal_inum = le32_to_cpu(es->s_journal_inum);\n\tdev_t journal_dev;\n\tint err = 0;\n\tint really_read_only;\n\n\tBUG_ON(!ext4_has_feature_journal(sb));\n\n\tif (journal_devnum &&\n\t    journal_devnum != le32_to_cpu(es->s_journal_dev)) {\n\t\text4_msg(sb, KERN_INFO, \"external journal device major/minor \"\n\t\t\t\"numbers have changed\");\n\t\tjournal_dev = new_decode_dev(journal_devnum);\n\t} else\n\t\tjournal_dev = new_decode_dev(le32_to_cpu(es->s_journal_dev));\n\n\treally_read_only = bdev_read_only(sb->s_bdev);\n\n\t/*\n\t * Are we loading a blank journal or performing recovery after a\n\t * crash?  For recovery, we need to check in advance whether we\n\t * can get read-write access to the device.\n\t */\n\tif (ext4_has_feature_journal_needs_recovery(sb)) {\n\t\tif (sb->s_flags & MS_RDONLY) {\n\t\t\text4_msg(sb, KERN_INFO, \"INFO: recovery \"\n\t\t\t\t\t\"required on readonly filesystem\");\n\t\t\tif (really_read_only) {\n\t\t\t\text4_msg(sb, KERN_ERR, \"write access \"\n\t\t\t\t\t\"unavailable, cannot proceed\");\n\t\t\t\treturn -EROFS;\n\t\t\t}\n\t\t\text4_msg(sb, KERN_INFO, \"write access will \"\n\t\t\t       \"be enabled during recovery\");\n\t\t}\n\t}\n\n\tif (journal_inum && journal_dev) {\n\t\text4_msg(sb, KERN_ERR, \"filesystem has both journal \"\n\t\t       \"and inode journals!\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (journal_inum) {\n\t\tif (!(journal = ext4_get_journal(sb, journal_inum)))\n\t\t\treturn -EINVAL;\n\t} else {\n\t\tif (!(journal = ext4_get_dev_journal(sb, journal_dev)))\n\t\t\treturn -EINVAL;\n\t}\n\n\tif (!(journal->j_flags & JBD2_BARRIER))\n\t\text4_msg(sb, KERN_INFO, \"barriers disabled\");\n\n\tif (!ext4_has_feature_journal_needs_recovery(sb))\n\t\terr = jbd2_journal_wipe(journal, !really_read_only);\n\tif (!err) {\n\t\tchar *save = kmalloc(EXT4_S_ERR_LEN, GFP_KERNEL);\n\t\tif (save)\n\t\t\tmemcpy(save, ((char *) es) +\n\t\t\t       EXT4_S_ERR_START, EXT4_S_ERR_LEN);\n\t\terr = jbd2_journal_load(journal);\n\t\tif (save)\n\t\t\tmemcpy(((char *) es) + EXT4_S_ERR_START,\n\t\t\t       save, EXT4_S_ERR_LEN);\n\t\tkfree(save);\n\t}\n\n\tif (err) {\n\t\text4_msg(sb, KERN_ERR, \"error loading journal\");\n\t\tjbd2_journal_destroy(journal);\n\t\treturn err;\n\t}\n\n\tEXT4_SB(sb)->s_journal = journal;\n\text4_clear_journal_err(sb, es);\n\n\tif (!really_read_only && journal_devnum &&\n\t    journal_devnum != le32_to_cpu(es->s_journal_dev)) {\n\t\tes->s_journal_dev = cpu_to_le32(journal_devnum);\n\n\t\t/* Make sure we flush the recovery flag to disk. */\n\t\text4_commit_super(sb, 1);\n\t}\n\n\treturn 0;\n}\n\nstatic int ext4_commit_super(struct super_block *sb, int sync)\n{\n\tstruct ext4_super_block *es = EXT4_SB(sb)->s_es;\n\tstruct buffer_head *sbh = EXT4_SB(sb)->s_sbh;\n\tint error = 0;\n\n\tif (!sbh || block_device_ejected(sb))\n\t\treturn error;\n\t/*\n\t * If the file system is mounted read-only, don't update the\n\t * superblock write time.  This avoids updating the superblock\n\t * write time when we are mounting the root file system\n\t * read/only but we need to replay the journal; at that point,\n\t * for people who are east of GMT and who make their clock\n\t * tick in localtime for Windows bug-for-bug compatibility,\n\t * the clock is set in the future, and this will cause e2fsck\n\t * to complain and force a full file system check.\n\t */\n\tif (!(sb->s_flags & MS_RDONLY))\n\t\tes->s_wtime = cpu_to_le32(get_seconds());\n\tif (sb->s_bdev->bd_part)\n\t\tes->s_kbytes_written =\n\t\t\tcpu_to_le64(EXT4_SB(sb)->s_kbytes_written +\n\t\t\t    ((part_stat_read(sb->s_bdev->bd_part, sectors[1]) -\n\t\t\t      EXT4_SB(sb)->s_sectors_written_start) >> 1));\n\telse\n\t\tes->s_kbytes_written =\n\t\t\tcpu_to_le64(EXT4_SB(sb)->s_kbytes_written);\n\tif (percpu_counter_initialized(&EXT4_SB(sb)->s_freeclusters_counter))\n\t\text4_free_blocks_count_set(es,\n\t\t\tEXT4_C2B(EXT4_SB(sb), percpu_counter_sum_positive(\n\t\t\t\t&EXT4_SB(sb)->s_freeclusters_counter)));\n\tif (percpu_counter_initialized(&EXT4_SB(sb)->s_freeinodes_counter))\n\t\tes->s_free_inodes_count =\n\t\t\tcpu_to_le32(percpu_counter_sum_positive(\n\t\t\t\t&EXT4_SB(sb)->s_freeinodes_counter));\n\tBUFFER_TRACE(sbh, \"marking dirty\");\n\text4_superblock_csum_set(sb);\n\tif (sync)\n\t\tlock_buffer(sbh);\n\tif (buffer_write_io_error(sbh)) {\n\t\t/*\n\t\t * Oh, dear.  A previous attempt to write the\n\t\t * superblock failed.  This could happen because the\n\t\t * USB device was yanked out.  Or it could happen to\n\t\t * be a transient write error and maybe the block will\n\t\t * be remapped.  Nothing we can do but to retry the\n\t\t * write and hope for the best.\n\t\t */\n\t\text4_msg(sb, KERN_ERR, \"previous I/O error to \"\n\t\t       \"superblock detected\");\n\t\tclear_buffer_write_io_error(sbh);\n\t\tset_buffer_uptodate(sbh);\n\t}\n\tmark_buffer_dirty(sbh);\n\tif (sync) {\n\t\tunlock_buffer(sbh);\n\t\terror = __sync_dirty_buffer(sbh,\n\t\t\ttest_opt(sb, BARRIER) ? WRITE_FUA : WRITE_SYNC);\n\t\tif (error)\n\t\t\treturn error;\n\n\t\terror = buffer_write_io_error(sbh);\n\t\tif (error) {\n\t\t\text4_msg(sb, KERN_ERR, \"I/O error while writing \"\n\t\t\t       \"superblock\");\n\t\t\tclear_buffer_write_io_error(sbh);\n\t\t\tset_buffer_uptodate(sbh);\n\t\t}\n\t}\n\treturn error;\n}\n\n/*\n * Have we just finished recovery?  If so, and if we are mounting (or\n * remounting) the filesystem readonly, then we will end up with a\n * consistent fs on disk.  Record that fact.\n */\nstatic void ext4_mark_recovery_complete(struct super_block *sb,\n\t\t\t\t\tstruct ext4_super_block *es)\n{\n\tjournal_t *journal = EXT4_SB(sb)->s_journal;\n\n\tif (!ext4_has_feature_journal(sb)) {\n\t\tBUG_ON(journal != NULL);\n\t\treturn;\n\t}\n\tjbd2_journal_lock_updates(journal);\n\tif (jbd2_journal_flush(journal) < 0)\n\t\tgoto out;\n\n\tif (ext4_has_feature_journal_needs_recovery(sb) &&\n\t    sb->s_flags & MS_RDONLY) {\n\t\text4_clear_feature_journal_needs_recovery(sb);\n\t\text4_commit_super(sb, 1);\n\t}\n\nout:\n\tjbd2_journal_unlock_updates(journal);\n}\n\n/*\n * If we are mounting (or read-write remounting) a filesystem whose journal\n * has recorded an error from a previous lifetime, move that error to the\n * main filesystem now.\n */\nstatic void ext4_clear_journal_err(struct super_block *sb,\n\t\t\t\t   struct ext4_super_block *es)\n{\n\tjournal_t *journal;\n\tint j_errno;\n\tconst char *errstr;\n\n\tBUG_ON(!ext4_has_feature_journal(sb));\n\n\tjournal = EXT4_SB(sb)->s_journal;\n\n\t/*\n\t * Now check for any error status which may have been recorded in the\n\t * journal by a prior ext4_error() or ext4_abort()\n\t */\n\n\tj_errno = jbd2_journal_errno(journal);\n\tif (j_errno) {\n\t\tchar nbuf[16];\n\n\t\terrstr = ext4_decode_error(sb, j_errno, nbuf);\n\t\text4_warning(sb, \"Filesystem error recorded \"\n\t\t\t     \"from previous mount: %s\", errstr);\n\t\text4_warning(sb, \"Marking fs in need of filesystem check.\");\n\n\t\tEXT4_SB(sb)->s_mount_state |= EXT4_ERROR_FS;\n\t\tes->s_state |= cpu_to_le16(EXT4_ERROR_FS);\n\t\text4_commit_super(sb, 1);\n\n\t\tjbd2_journal_clear_err(journal);\n\t\tjbd2_journal_update_sb_errno(journal);\n\t}\n}\n\n/*\n * Force the running and committing transactions to commit,\n * and wait on the commit.\n */\nint ext4_force_commit(struct super_block *sb)\n{\n\tjournal_t *journal;\n\n\tif (sb->s_flags & MS_RDONLY)\n\t\treturn 0;\n\n\tjournal = EXT4_SB(sb)->s_journal;\n\treturn ext4_journal_force_commit(journal);\n}\n\nstatic int ext4_sync_fs(struct super_block *sb, int wait)\n{\n\tint ret = 0;\n\ttid_t target;\n\tbool needs_barrier = false;\n\tstruct ext4_sb_info *sbi = EXT4_SB(sb);\n\n\ttrace_ext4_sync_fs(sb, wait);\n\tflush_workqueue(sbi->rsv_conversion_wq);\n\t/*\n\t * Writeback quota in non-journalled quota case - journalled quota has\n\t * no dirty dquots\n\t */\n\tdquot_writeback_dquots(sb, -1);\n\t/*\n\t * Data writeback is possible w/o journal transaction, so barrier must\n\t * being sent at the end of the function. But we can skip it if\n\t * transaction_commit will do it for us.\n\t */\n\tif (sbi->s_journal) {\n\t\ttarget = jbd2_get_latest_transaction(sbi->s_journal);\n\t\tif (wait && sbi->s_journal->j_flags & JBD2_BARRIER &&\n\t\t    !jbd2_trans_will_send_data_barrier(sbi->s_journal, target))\n\t\t\tneeds_barrier = true;\n\n\t\tif (jbd2_journal_start_commit(sbi->s_journal, &target)) {\n\t\t\tif (wait)\n\t\t\t\tret = jbd2_log_wait_commit(sbi->s_journal,\n\t\t\t\t\t\t\t   target);\n\t\t}\n\t} else if (wait && test_opt(sb, BARRIER))\n\t\tneeds_barrier = true;\n\tif (needs_barrier) {\n\t\tint err;\n\t\terr = blkdev_issue_flush(sb->s_bdev, GFP_KERNEL, NULL);\n\t\tif (!ret)\n\t\t\tret = err;\n\t}\n\n\treturn ret;\n}\n\n/*\n * LVM calls this function before a (read-only) snapshot is created.  This\n * gives us a chance to flush the journal completely and mark the fs clean.\n *\n * Note that only this function cannot bring a filesystem to be in a clean\n * state independently. It relies on upper layer to stop all data & metadata\n * modifications.\n */\nstatic int ext4_freeze(struct super_block *sb)\n{\n\tint error = 0;\n\tjournal_t *journal;\n\n\tif (sb->s_flags & MS_RDONLY)\n\t\treturn 0;\n\n\tjournal = EXT4_SB(sb)->s_journal;\n\n\tif (journal) {\n\t\t/* Now we set up the journal barrier. */\n\t\tjbd2_journal_lock_updates(journal);\n\n\t\t/*\n\t\t * Don't clear the needs_recovery flag if we failed to\n\t\t * flush the journal.\n\t\t */\n\t\terror = jbd2_journal_flush(journal);\n\t\tif (error < 0)\n\t\t\tgoto out;\n\n\t\t/* Journal blocked and flushed, clear needs_recovery flag. */\n\t\text4_clear_feature_journal_needs_recovery(sb);\n\t}\n\n\terror = ext4_commit_super(sb, 1);\nout:\n\tif (journal)\n\t\t/* we rely on upper layer to stop further updates */\n\t\tjbd2_journal_unlock_updates(journal);\n\treturn error;\n}\n\n/*\n * Called by LVM after the snapshot is done.  We need to reset the RECOVER\n * flag here, even though the filesystem is not technically dirty yet.\n */\nstatic int ext4_unfreeze(struct super_block *sb)\n{\n\tif (sb->s_flags & MS_RDONLY)\n\t\treturn 0;\n\n\tif (EXT4_SB(sb)->s_journal) {\n\t\t/* Reset the needs_recovery flag before the fs is unlocked. */\n\t\text4_set_feature_journal_needs_recovery(sb);\n\t}\n\n\text4_commit_super(sb, 1);\n\treturn 0;\n}\n\n/*\n * Structure to save mount options for ext4_remount's benefit\n */\nstruct ext4_mount_options {\n\tunsigned long s_mount_opt;\n\tunsigned long s_mount_opt2;\n\tkuid_t s_resuid;\n\tkgid_t s_resgid;\n\tunsigned long s_commit_interval;\n\tu32 s_min_batch_time, s_max_batch_time;\n#ifdef CONFIG_QUOTA\n\tint s_jquota_fmt;\n\tchar *s_qf_names[EXT4_MAXQUOTAS];\n#endif\n};\n\nstatic int ext4_remount(struct super_block *sb, int *flags, char *data)\n{\n\tstruct ext4_super_block *es;\n\tstruct ext4_sb_info *sbi = EXT4_SB(sb);\n\tunsigned long old_sb_flags;\n\tstruct ext4_mount_options old_opts;\n\tint enable_quota = 0;\n\text4_group_t g;\n\tunsigned int journal_ioprio = DEFAULT_JOURNAL_IOPRIO;\n\tint err = 0;\n#ifdef CONFIG_QUOTA\n\tint i, j;\n#endif\n\tchar *orig_data = kstrdup(data, GFP_KERNEL);\n\n\t/* Store the original options */\n\told_sb_flags = sb->s_flags;\n\told_opts.s_mount_opt = sbi->s_mount_opt;\n\told_opts.s_mount_opt2 = sbi->s_mount_opt2;\n\told_opts.s_resuid = sbi->s_resuid;\n\told_opts.s_resgid = sbi->s_resgid;\n\told_opts.s_commit_interval = sbi->s_commit_interval;\n\told_opts.s_min_batch_time = sbi->s_min_batch_time;\n\told_opts.s_max_batch_time = sbi->s_max_batch_time;\n#ifdef CONFIG_QUOTA\n\told_opts.s_jquota_fmt = sbi->s_jquota_fmt;\n\tfor (i = 0; i < EXT4_MAXQUOTAS; i++)\n\t\tif (sbi->s_qf_names[i]) {\n\t\t\told_opts.s_qf_names[i] = kstrdup(sbi->s_qf_names[i],\n\t\t\t\t\t\t\t GFP_KERNEL);\n\t\t\tif (!old_opts.s_qf_names[i]) {\n\t\t\t\tfor (j = 0; j < i; j++)\n\t\t\t\t\tkfree(old_opts.s_qf_names[j]);\n\t\t\t\tkfree(orig_data);\n\t\t\t\treturn -ENOMEM;\n\t\t\t}\n\t\t} else\n\t\t\told_opts.s_qf_names[i] = NULL;\n#endif\n\tif (sbi->s_journal && sbi->s_journal->j_task->io_context)\n\t\tjournal_ioprio = sbi->s_journal->j_task->io_context->ioprio;\n\n\tif (!parse_options(data, sb, NULL, &journal_ioprio, 1)) {\n\t\terr = -EINVAL;\n\t\tgoto restore_opts;\n\t}\n\n\tif ((old_opts.s_mount_opt & EXT4_MOUNT_JOURNAL_CHECKSUM) ^\n\t    test_opt(sb, JOURNAL_CHECKSUM)) {\n\t\text4_msg(sb, KERN_ERR, \"changing journal_checksum \"\n\t\t\t \"during remount not supported; ignoring\");\n\t\tsbi->s_mount_opt ^= EXT4_MOUNT_JOURNAL_CHECKSUM;\n\t}\n\n\tif (test_opt(sb, DATA_FLAGS) == EXT4_MOUNT_JOURNAL_DATA) {\n\t\tif (test_opt2(sb, EXPLICIT_DELALLOC)) {\n\t\t\text4_msg(sb, KERN_ERR, \"can't mount with \"\n\t\t\t\t \"both data=journal and delalloc\");\n\t\t\terr = -EINVAL;\n\t\t\tgoto restore_opts;\n\t\t}\n\t\tif (test_opt(sb, DIOREAD_NOLOCK)) {\n\t\t\text4_msg(sb, KERN_ERR, \"can't mount with \"\n\t\t\t\t \"both data=journal and dioread_nolock\");\n\t\t\terr = -EINVAL;\n\t\t\tgoto restore_opts;\n\t\t}\n\t\tif (test_opt(sb, DAX)) {\n\t\t\text4_msg(sb, KERN_ERR, \"can't mount with \"\n\t\t\t\t \"both data=journal and dax\");\n\t\t\terr = -EINVAL;\n\t\t\tgoto restore_opts;\n\t\t}\n\t}\n\n\tif ((sbi->s_mount_opt ^ old_opts.s_mount_opt) & EXT4_MOUNT_DAX) {\n\t\text4_msg(sb, KERN_WARNING, \"warning: refusing change of \"\n\t\t\t\"dax flag with busy inodes while remounting\");\n\t\tsbi->s_mount_opt ^= EXT4_MOUNT_DAX;\n\t}\n\n\tif (sbi->s_mount_flags & EXT4_MF_FS_ABORTED)\n\t\text4_abort(sb, \"Abort forced by user\");\n\n\tsb->s_flags = (sb->s_flags & ~MS_POSIXACL) |\n\t\t(test_opt(sb, POSIX_ACL) ? MS_POSIXACL : 0);\n\n\tes = sbi->s_es;\n\n\tif (sbi->s_journal) {\n\t\text4_init_journal_params(sb, sbi->s_journal);\n\t\tset_task_ioprio(sbi->s_journal->j_task, journal_ioprio);\n\t}\n\n\tif (*flags & MS_LAZYTIME)\n\t\tsb->s_flags |= MS_LAZYTIME;\n\n\tif ((*flags & MS_RDONLY) != (sb->s_flags & MS_RDONLY)) {\n\t\tif (sbi->s_mount_flags & EXT4_MF_FS_ABORTED) {\n\t\t\terr = -EROFS;\n\t\t\tgoto restore_opts;\n\t\t}\n\n\t\tif (*flags & MS_RDONLY) {\n\t\t\terr = sync_filesystem(sb);\n\t\t\tif (err < 0)\n\t\t\t\tgoto restore_opts;\n\t\t\terr = dquot_suspend(sb, -1);\n\t\t\tif (err < 0)\n\t\t\t\tgoto restore_opts;\n\n\t\t\t/*\n\t\t\t * First of all, the unconditional stuff we have to do\n\t\t\t * to disable replay of the journal when we next remount\n\t\t\t */\n\t\t\tsb->s_flags |= MS_RDONLY;\n\n\t\t\t/*\n\t\t\t * OK, test if we are remounting a valid rw partition\n\t\t\t * readonly, and if so set the rdonly flag and then\n\t\t\t * mark the partition as valid again.\n\t\t\t */\n\t\t\tif (!(es->s_state & cpu_to_le16(EXT4_VALID_FS)) &&\n\t\t\t    (sbi->s_mount_state & EXT4_VALID_FS))\n\t\t\t\tes->s_state = cpu_to_le16(sbi->s_mount_state);\n\n\t\t\tif (sbi->s_journal)\n\t\t\t\text4_mark_recovery_complete(sb, es);\n\t\t} else {\n\t\t\t/* Make sure we can mount this feature set readwrite */\n\t\t\tif (ext4_has_feature_readonly(sb) ||\n\t\t\t    !ext4_feature_set_ok(sb, 0)) {\n\t\t\t\terr = -EROFS;\n\t\t\t\tgoto restore_opts;\n\t\t\t}\n\t\t\t/*\n\t\t\t * Make sure the group descriptor checksums\n\t\t\t * are sane.  If they aren't, refuse to remount r/w.\n\t\t\t */\n\t\t\tfor (g = 0; g < sbi->s_groups_count; g++) {\n\t\t\t\tstruct ext4_group_desc *gdp =\n\t\t\t\t\text4_get_group_desc(sb, g, NULL);\n\n\t\t\t\tif (!ext4_group_desc_csum_verify(sb, g, gdp)) {\n\t\t\t\t\text4_msg(sb, KERN_ERR,\n\t       \"ext4_remount: Checksum for group %u failed (%u!=%u)\",\n\t\tg, le16_to_cpu(ext4_group_desc_csum(sb, g, gdp)),\n\t\t\t\t\t       le16_to_cpu(gdp->bg_checksum));\n\t\t\t\t\terr = -EFSBADCRC;\n\t\t\t\t\tgoto restore_opts;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t/*\n\t\t\t * If we have an unprocessed orphan list hanging\n\t\t\t * around from a previously readonly bdev mount,\n\t\t\t * require a full umount/remount for now.\n\t\t\t */\n\t\t\tif (es->s_last_orphan) {\n\t\t\t\text4_msg(sb, KERN_WARNING, \"Couldn't \"\n\t\t\t\t       \"remount RDWR because of unprocessed \"\n\t\t\t\t       \"orphan inode list.  Please \"\n\t\t\t\t       \"umount/remount instead\");\n\t\t\t\terr = -EINVAL;\n\t\t\t\tgoto restore_opts;\n\t\t\t}\n\n\t\t\t/*\n\t\t\t * Mounting a RDONLY partition read-write, so reread\n\t\t\t * and store the current valid flag.  (It may have\n\t\t\t * been changed by e2fsck since we originally mounted\n\t\t\t * the partition.)\n\t\t\t */\n\t\t\tif (sbi->s_journal)\n\t\t\t\text4_clear_journal_err(sb, es);\n\t\t\tsbi->s_mount_state = le16_to_cpu(es->s_state);\n\t\t\tif (!ext4_setup_super(sb, es, 0))\n\t\t\t\tsb->s_flags &= ~MS_RDONLY;\n\t\t\tif (ext4_has_feature_mmp(sb))\n\t\t\t\tif (ext4_multi_mount_protect(sb,\n\t\t\t\t\t\tle64_to_cpu(es->s_mmp_block))) {\n\t\t\t\t\terr = -EROFS;\n\t\t\t\t\tgoto restore_opts;\n\t\t\t\t}\n\t\t\tenable_quota = 1;\n\t\t}\n\t}\n\n\t/*\n\t * Reinitialize lazy itable initialization thread based on\n\t * current settings\n\t */\n\tif ((sb->s_flags & MS_RDONLY) || !test_opt(sb, INIT_INODE_TABLE))\n\t\text4_unregister_li_request(sb);\n\telse {\n\t\text4_group_t first_not_zeroed;\n\t\tfirst_not_zeroed = ext4_has_uninit_itable(sb);\n\t\text4_register_li_request(sb, first_not_zeroed);\n\t}\n\n\text4_setup_system_zone(sb);\n\tif (sbi->s_journal == NULL && !(old_sb_flags & MS_RDONLY))\n\t\text4_commit_super(sb, 1);\n\n#ifdef CONFIG_QUOTA\n\t/* Release old quota file names */\n\tfor (i = 0; i < EXT4_MAXQUOTAS; i++)\n\t\tkfree(old_opts.s_qf_names[i]);\n\tif (enable_quota) {\n\t\tif (sb_any_quota_suspended(sb))\n\t\t\tdquot_resume(sb, -1);\n\t\telse if (ext4_has_feature_quota(sb)) {\n\t\t\terr = ext4_enable_quotas(sb);\n\t\t\tif (err)\n\t\t\t\tgoto restore_opts;\n\t\t}\n\t}\n#endif\n\n\t*flags = (*flags & ~MS_LAZYTIME) | (sb->s_flags & MS_LAZYTIME);\n\text4_msg(sb, KERN_INFO, \"re-mounted. Opts: %s\", orig_data);\n\tkfree(orig_data);\n\treturn 0;\n\nrestore_opts:\n\tsb->s_flags = old_sb_flags;\n\tsbi->s_mount_opt = old_opts.s_mount_opt;\n\tsbi->s_mount_opt2 = old_opts.s_mount_opt2;\n\tsbi->s_resuid = old_opts.s_resuid;\n\tsbi->s_resgid = old_opts.s_resgid;\n\tsbi->s_commit_interval = old_opts.s_commit_interval;\n\tsbi->s_min_batch_time = old_opts.s_min_batch_time;\n\tsbi->s_max_batch_time = old_opts.s_max_batch_time;\n#ifdef CONFIG_QUOTA\n\tsbi->s_jquota_fmt = old_opts.s_jquota_fmt;\n\tfor (i = 0; i < EXT4_MAXQUOTAS; i++) {\n\t\tkfree(sbi->s_qf_names[i]);\n\t\tsbi->s_qf_names[i] = old_opts.s_qf_names[i];\n\t}\n#endif\n\tkfree(orig_data);\n\treturn err;\n}\n\n#ifdef CONFIG_QUOTA\nstatic int ext4_statfs_project(struct super_block *sb,\n\t\t\t       kprojid_t projid, struct kstatfs *buf)\n{\n\tstruct kqid qid;\n\tstruct dquot *dquot;\n\tu64 limit;\n\tu64 curblock;\n\n\tqid = make_kqid_projid(projid);\n\tdquot = dqget(sb, qid);\n\tif (IS_ERR(dquot))\n\t\treturn PTR_ERR(dquot);\n\tspin_lock(&dq_data_lock);\n\n\tlimit = (dquot->dq_dqb.dqb_bsoftlimit ?\n\t\t dquot->dq_dqb.dqb_bsoftlimit :\n\t\t dquot->dq_dqb.dqb_bhardlimit) >> sb->s_blocksize_bits;\n\tif (limit && buf->f_blocks > limit) {\n\t\tcurblock = dquot->dq_dqb.dqb_curspace >> sb->s_blocksize_bits;\n\t\tbuf->f_blocks = limit;\n\t\tbuf->f_bfree = buf->f_bavail =\n\t\t\t(buf->f_blocks > curblock) ?\n\t\t\t (buf->f_blocks - curblock) : 0;\n\t}\n\n\tlimit = dquot->dq_dqb.dqb_isoftlimit ?\n\t\tdquot->dq_dqb.dqb_isoftlimit :\n\t\tdquot->dq_dqb.dqb_ihardlimit;\n\tif (limit && buf->f_files > limit) {\n\t\tbuf->f_files = limit;\n\t\tbuf->f_ffree =\n\t\t\t(buf->f_files > dquot->dq_dqb.dqb_curinodes) ?\n\t\t\t (buf->f_files - dquot->dq_dqb.dqb_curinodes) : 0;\n\t}\n\n\tspin_unlock(&dq_data_lock);\n\tdqput(dquot);\n\treturn 0;\n}\n#endif\n\nstatic int ext4_statfs(struct dentry *dentry, struct kstatfs *buf)\n{\n\tstruct super_block *sb = dentry->d_sb;\n\tstruct ext4_sb_info *sbi = EXT4_SB(sb);\n\tstruct ext4_super_block *es = sbi->s_es;\n\text4_fsblk_t overhead = 0, resv_blocks;\n\tu64 fsid;\n\ts64 bfree;\n\tresv_blocks = EXT4_C2B(sbi, atomic64_read(&sbi->s_resv_clusters));\n\n\tif (!test_opt(sb, MINIX_DF))\n\t\toverhead = sbi->s_overhead;\n\n\tbuf->f_type = EXT4_SUPER_MAGIC;\n\tbuf->f_bsize = sb->s_blocksize;\n\tbuf->f_blocks = ext4_blocks_count(es) - EXT4_C2B(sbi, overhead);\n\tbfree = percpu_counter_sum_positive(&sbi->s_freeclusters_counter) -\n\t\tpercpu_counter_sum_positive(&sbi->s_dirtyclusters_counter);\n\t/* prevent underflow in case that few free space is available */\n\tbuf->f_bfree = EXT4_C2B(sbi, max_t(s64, bfree, 0));\n\tbuf->f_bavail = buf->f_bfree -\n\t\t\t(ext4_r_blocks_count(es) + resv_blocks);\n\tif (buf->f_bfree < (ext4_r_blocks_count(es) + resv_blocks))\n\t\tbuf->f_bavail = 0;\n\tbuf->f_files = le32_to_cpu(es->s_inodes_count);\n\tbuf->f_ffree = percpu_counter_sum_positive(&sbi->s_freeinodes_counter);\n\tbuf->f_namelen = EXT4_NAME_LEN;\n\tfsid = le64_to_cpup((void *)es->s_uuid) ^\n\t       le64_to_cpup((void *)es->s_uuid + sizeof(u64));\n\tbuf->f_fsid.val[0] = fsid & 0xFFFFFFFFUL;\n\tbuf->f_fsid.val[1] = (fsid >> 32) & 0xFFFFFFFFUL;\n\n#ifdef CONFIG_QUOTA\n\tif (ext4_test_inode_flag(dentry->d_inode, EXT4_INODE_PROJINHERIT) &&\n\t    sb_has_quota_limits_enabled(sb, PRJQUOTA))\n\t\text4_statfs_project(sb, EXT4_I(dentry->d_inode)->i_projid, buf);\n#endif\n\treturn 0;\n}\n\n/* Helper function for writing quotas on sync - we need to start transaction\n * before quota file is locked for write. Otherwise the are possible deadlocks:\n * Process 1                         Process 2\n * ext4_create()                     quota_sync()\n *   jbd2_journal_start()                  write_dquot()\n *   dquot_initialize()                         down(dqio_mutex)\n *     down(dqio_mutex)                    jbd2_journal_start()\n *\n */\n\n#ifdef CONFIG_QUOTA\n\nstatic inline struct inode *dquot_to_inode(struct dquot *dquot)\n{\n\treturn sb_dqopt(dquot->dq_sb)->files[dquot->dq_id.type];\n}\n\nstatic int ext4_write_dquot(struct dquot *dquot)\n{\n\tint ret, err;\n\thandle_t *handle;\n\tstruct inode *inode;\n\n\tinode = dquot_to_inode(dquot);\n\thandle = ext4_journal_start(inode, EXT4_HT_QUOTA,\n\t\t\t\t    EXT4_QUOTA_TRANS_BLOCKS(dquot->dq_sb));\n\tif (IS_ERR(handle))\n\t\treturn PTR_ERR(handle);\n\tret = dquot_commit(dquot);\n\terr = ext4_journal_stop(handle);\n\tif (!ret)\n\t\tret = err;\n\treturn ret;\n}\n\nstatic int ext4_acquire_dquot(struct dquot *dquot)\n{\n\tint ret, err;\n\thandle_t *handle;\n\n\thandle = ext4_journal_start(dquot_to_inode(dquot), EXT4_HT_QUOTA,\n\t\t\t\t    EXT4_QUOTA_INIT_BLOCKS(dquot->dq_sb));\n\tif (IS_ERR(handle))\n\t\treturn PTR_ERR(handle);\n\tret = dquot_acquire(dquot);\n\terr = ext4_journal_stop(handle);\n\tif (!ret)\n\t\tret = err;\n\treturn ret;\n}\n\nstatic int ext4_release_dquot(struct dquot *dquot)\n{\n\tint ret, err;\n\thandle_t *handle;\n\n\thandle = ext4_journal_start(dquot_to_inode(dquot), EXT4_HT_QUOTA,\n\t\t\t\t    EXT4_QUOTA_DEL_BLOCKS(dquot->dq_sb));\n\tif (IS_ERR(handle)) {\n\t\t/* Release dquot anyway to avoid endless cycle in dqput() */\n\t\tdquot_release(dquot);\n\t\treturn PTR_ERR(handle);\n\t}\n\tret = dquot_release(dquot);\n\terr = ext4_journal_stop(handle);\n\tif (!ret)\n\t\tret = err;\n\treturn ret;\n}\n\nstatic int ext4_mark_dquot_dirty(struct dquot *dquot)\n{\n\tstruct super_block *sb = dquot->dq_sb;\n\tstruct ext4_sb_info *sbi = EXT4_SB(sb);\n\n\t/* Are we journaling quotas? */\n\tif (ext4_has_feature_quota(sb) ||\n\t    sbi->s_qf_names[USRQUOTA] || sbi->s_qf_names[GRPQUOTA]) {\n\t\tdquot_mark_dquot_dirty(dquot);\n\t\treturn ext4_write_dquot(dquot);\n\t} else {\n\t\treturn dquot_mark_dquot_dirty(dquot);\n\t}\n}\n\nstatic int ext4_write_info(struct super_block *sb, int type)\n{\n\tint ret, err;\n\thandle_t *handle;\n\n\t/* Data block + inode block */\n\thandle = ext4_journal_start(d_inode(sb->s_root), EXT4_HT_QUOTA, 2);\n\tif (IS_ERR(handle))\n\t\treturn PTR_ERR(handle);\n\tret = dquot_commit_info(sb, type);\n\terr = ext4_journal_stop(handle);\n\tif (!ret)\n\t\tret = err;\n\treturn ret;\n}\n\n/*\n * Turn on quotas during mount time - we need to find\n * the quota file and such...\n */\nstatic int ext4_quota_on_mount(struct super_block *sb, int type)\n{\n\treturn dquot_quota_on_mount(sb, EXT4_SB(sb)->s_qf_names[type],\n\t\t\t\t\tEXT4_SB(sb)->s_jquota_fmt, type);\n}\n\nstatic void lockdep_set_quota_inode(struct inode *inode, int subclass)\n{\n\tstruct ext4_inode_info *ei = EXT4_I(inode);\n\n\t/* The first argument of lockdep_set_subclass has to be\n\t * *exactly* the same as the argument to init_rwsem() --- in\n\t * this case, in init_once() --- or lockdep gets unhappy\n\t * because the name of the lock is set using the\n\t * stringification of the argument to init_rwsem().\n\t */\n\t(void) ei;\t/* shut up clang warning if !CONFIG_LOCKDEP */\n\tlockdep_set_subclass(&ei->i_data_sem, subclass);\n}\n\n/*\n * Standard function to be called on quota_on\n */\nstatic int ext4_quota_on(struct super_block *sb, int type, int format_id,\n\t\t\t struct path *path)\n{\n\tint err;\n\n\tif (!test_opt(sb, QUOTA))\n\t\treturn -EINVAL;\n\n\t/* Quotafile not on the same filesystem? */\n\tif (path->dentry->d_sb != sb)\n\t\treturn -EXDEV;\n\t/* Journaling quota? */\n\tif (EXT4_SB(sb)->s_qf_names[type]) {\n\t\t/* Quotafile not in fs root? */\n\t\tif (path->dentry->d_parent != sb->s_root)\n\t\t\text4_msg(sb, KERN_WARNING,\n\t\t\t\t\"Quota file not on filesystem root. \"\n\t\t\t\t\"Journaled quota will not work\");\n\t}\n\n\t/*\n\t * When we journal data on quota file, we have to flush journal to see\n\t * all updates to the file when we bypass pagecache...\n\t */\n\tif (EXT4_SB(sb)->s_journal &&\n\t    ext4_should_journal_data(d_inode(path->dentry))) {\n\t\t/*\n\t\t * We don't need to lock updates but journal_flush() could\n\t\t * otherwise be livelocked...\n\t\t */\n\t\tjbd2_journal_lock_updates(EXT4_SB(sb)->s_journal);\n\t\terr = jbd2_journal_flush(EXT4_SB(sb)->s_journal);\n\t\tjbd2_journal_unlock_updates(EXT4_SB(sb)->s_journal);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\tlockdep_set_quota_inode(path->dentry->d_inode, I_DATA_SEM_QUOTA);\n\terr = dquot_quota_on(sb, type, format_id, path);\n\tif (err)\n\t\tlockdep_set_quota_inode(path->dentry->d_inode,\n\t\t\t\t\t     I_DATA_SEM_NORMAL);\n\treturn err;\n}\n\nstatic int ext4_quota_enable(struct super_block *sb, int type, int format_id,\n\t\t\t     unsigned int flags)\n{\n\tint err;\n\tstruct inode *qf_inode;\n\tunsigned long qf_inums[EXT4_MAXQUOTAS] = {\n\t\tle32_to_cpu(EXT4_SB(sb)->s_es->s_usr_quota_inum),\n\t\tle32_to_cpu(EXT4_SB(sb)->s_es->s_grp_quota_inum),\n\t\tle32_to_cpu(EXT4_SB(sb)->s_es->s_prj_quota_inum)\n\t};\n\n\tBUG_ON(!ext4_has_feature_quota(sb));\n\n\tif (!qf_inums[type])\n\t\treturn -EPERM;\n\n\tqf_inode = ext4_iget(sb, qf_inums[type]);\n\tif (IS_ERR(qf_inode)) {\n\t\text4_error(sb, \"Bad quota inode # %lu\", qf_inums[type]);\n\t\treturn PTR_ERR(qf_inode);\n\t}\n\n\t/* Don't account quota for quota files to avoid recursion */\n\tqf_inode->i_flags |= S_NOQUOTA;\n\tlockdep_set_quota_inode(qf_inode, I_DATA_SEM_QUOTA);\n\terr = dquot_enable(qf_inode, type, format_id, flags);\n\tiput(qf_inode);\n\tif (err)\n\t\tlockdep_set_quota_inode(qf_inode, I_DATA_SEM_NORMAL);\n\n\treturn err;\n}\n\n/* Enable usage tracking for all quota types. */\nstatic int ext4_enable_quotas(struct super_block *sb)\n{\n\tint type, err = 0;\n\tunsigned long qf_inums[EXT4_MAXQUOTAS] = {\n\t\tle32_to_cpu(EXT4_SB(sb)->s_es->s_usr_quota_inum),\n\t\tle32_to_cpu(EXT4_SB(sb)->s_es->s_grp_quota_inum),\n\t\tle32_to_cpu(EXT4_SB(sb)->s_es->s_prj_quota_inum)\n\t};\n\tbool quota_mopt[EXT4_MAXQUOTAS] = {\n\t\ttest_opt(sb, USRQUOTA),\n\t\ttest_opt(sb, GRPQUOTA),\n\t\ttest_opt(sb, PRJQUOTA),\n\t};\n\n\tsb_dqopt(sb)->flags |= DQUOT_QUOTA_SYS_FILE;\n\tfor (type = 0; type < EXT4_MAXQUOTAS; type++) {\n\t\tif (qf_inums[type]) {\n\t\t\terr = ext4_quota_enable(sb, type, QFMT_VFS_V1,\n\t\t\t\tDQUOT_USAGE_ENABLED |\n\t\t\t\t(quota_mopt[type] ? DQUOT_LIMITS_ENABLED : 0));\n\t\t\tif (err) {\n\t\t\t\text4_warning(sb,\n\t\t\t\t\t\"Failed to enable quota tracking \"\n\t\t\t\t\t\"(type=%d, err=%d). Please run \"\n\t\t\t\t\t\"e2fsck to fix.\", type, err);\n\t\t\t\treturn err;\n\t\t\t}\n\t\t}\n\t}\n\treturn 0;\n}\n\nstatic int ext4_quota_off(struct super_block *sb, int type)\n{\n\tstruct inode *inode = sb_dqopt(sb)->files[type];\n\thandle_t *handle;\n\n\t/* Force all delayed allocation blocks to be allocated.\n\t * Caller already holds s_umount sem */\n\tif (test_opt(sb, DELALLOC))\n\t\tsync_filesystem(sb);\n\n\tif (!inode)\n\t\tgoto out;\n\n\t/* Update modification times of quota files when userspace can\n\t * start looking at them */\n\thandle = ext4_journal_start(inode, EXT4_HT_QUOTA, 1);\n\tif (IS_ERR(handle))\n\t\tgoto out;\n\tinode->i_mtime = inode->i_ctime = current_time(inode);\n\text4_mark_inode_dirty(handle, inode);\n\text4_journal_stop(handle);\n\nout:\n\treturn dquot_quota_off(sb, type);\n}\n\n/* Read data from quotafile - avoid pagecache and such because we cannot afford\n * acquiring the locks... As quota files are never truncated and quota code\n * itself serializes the operations (and no one else should touch the files)\n * we don't have to be afraid of races */\nstatic ssize_t ext4_quota_read(struct super_block *sb, int type, char *data,\n\t\t\t       size_t len, loff_t off)\n{\n\tstruct inode *inode = sb_dqopt(sb)->files[type];\n\text4_lblk_t blk = off >> EXT4_BLOCK_SIZE_BITS(sb);\n\tint offset = off & (sb->s_blocksize - 1);\n\tint tocopy;\n\tsize_t toread;\n\tstruct buffer_head *bh;\n\tloff_t i_size = i_size_read(inode);\n\n\tif (off > i_size)\n\t\treturn 0;\n\tif (off+len > i_size)\n\t\tlen = i_size-off;\n\ttoread = len;\n\twhile (toread > 0) {\n\t\ttocopy = sb->s_blocksize - offset < toread ?\n\t\t\t\tsb->s_blocksize - offset : toread;\n\t\tbh = ext4_bread(NULL, inode, blk, 0);\n\t\tif (IS_ERR(bh))\n\t\t\treturn PTR_ERR(bh);\n\t\tif (!bh)\t/* A hole? */\n\t\t\tmemset(data, 0, tocopy);\n\t\telse\n\t\t\tmemcpy(data, bh->b_data+offset, tocopy);\n\t\tbrelse(bh);\n\t\toffset = 0;\n\t\ttoread -= tocopy;\n\t\tdata += tocopy;\n\t\tblk++;\n\t}\n\treturn len;\n}\n\n/* Write to quotafile (we know the transaction is already started and has\n * enough credits) */\nstatic ssize_t ext4_quota_write(struct super_block *sb, int type,\n\t\t\t\tconst char *data, size_t len, loff_t off)\n{\n\tstruct inode *inode = sb_dqopt(sb)->files[type];\n\text4_lblk_t blk = off >> EXT4_BLOCK_SIZE_BITS(sb);\n\tint err, offset = off & (sb->s_blocksize - 1);\n\tint retries = 0;\n\tstruct buffer_head *bh;\n\thandle_t *handle = journal_current_handle();\n\n\tif (EXT4_SB(sb)->s_journal && !handle) {\n\t\text4_msg(sb, KERN_WARNING, \"Quota write (off=%llu, len=%llu)\"\n\t\t\t\" cancelled because transaction is not started\",\n\t\t\t(unsigned long long)off, (unsigned long long)len);\n\t\treturn -EIO;\n\t}\n\t/*\n\t * Since we account only one data block in transaction credits,\n\t * then it is impossible to cross a block boundary.\n\t */\n\tif (sb->s_blocksize - offset < len) {\n\t\text4_msg(sb, KERN_WARNING, \"Quota write (off=%llu, len=%llu)\"\n\t\t\t\" cancelled because not block aligned\",\n\t\t\t(unsigned long long)off, (unsigned long long)len);\n\t\treturn -EIO;\n\t}\n\n\tdo {\n\t\tbh = ext4_bread(handle, inode, blk,\n\t\t\t\tEXT4_GET_BLOCKS_CREATE |\n\t\t\t\tEXT4_GET_BLOCKS_METADATA_NOFAIL);\n\t} while (IS_ERR(bh) && (PTR_ERR(bh) == -ENOSPC) &&\n\t\t ext4_should_retry_alloc(inode->i_sb, &retries));\n\tif (IS_ERR(bh))\n\t\treturn PTR_ERR(bh);\n\tif (!bh)\n\t\tgoto out;\n\tBUFFER_TRACE(bh, \"get write access\");\n\terr = ext4_journal_get_write_access(handle, bh);\n\tif (err) {\n\t\tbrelse(bh);\n\t\treturn err;\n\t}\n\tlock_buffer(bh);\n\tmemcpy(bh->b_data+offset, data, len);\n\tflush_dcache_page(bh->b_page);\n\tunlock_buffer(bh);\n\terr = ext4_handle_dirty_metadata(handle, NULL, bh);\n\tbrelse(bh);\nout:\n\tif (inode->i_size < off + len) {\n\t\ti_size_write(inode, off + len);\n\t\tEXT4_I(inode)->i_disksize = inode->i_size;\n\t\text4_mark_inode_dirty(handle, inode);\n\t}\n\treturn len;\n}\n\nstatic int ext4_get_next_id(struct super_block *sb, struct kqid *qid)\n{\n\tconst struct quota_format_ops\t*ops;\n\n\tif (!sb_has_quota_loaded(sb, qid->type))\n\t\treturn -ESRCH;\n\tops = sb_dqopt(sb)->ops[qid->type];\n\tif (!ops || !ops->get_next_id)\n\t\treturn -ENOSYS;\n\treturn dquot_get_next_id(sb, qid);\n}\n#endif\n\nstatic struct dentry *ext4_mount(struct file_system_type *fs_type, int flags,\n\t\t       const char *dev_name, void *data)\n{\n\treturn mount_bdev(fs_type, flags, dev_name, data, ext4_fill_super);\n}\n\n#if !defined(CONFIG_EXT2_FS) && !defined(CONFIG_EXT2_FS_MODULE) && defined(CONFIG_EXT4_USE_FOR_EXT2)\nstatic inline void register_as_ext2(void)\n{\n\tint err = register_filesystem(&ext2_fs_type);\n\tif (err)\n\t\tprintk(KERN_WARNING\n\t\t       \"EXT4-fs: Unable to register as ext2 (%d)\\n\", err);\n}\n\nstatic inline void unregister_as_ext2(void)\n{\n\tunregister_filesystem(&ext2_fs_type);\n}\n\nstatic inline int ext2_feature_set_ok(struct super_block *sb)\n{\n\tif (ext4_has_unknown_ext2_incompat_features(sb))\n\t\treturn 0;\n\tif (sb->s_flags & MS_RDONLY)\n\t\treturn 1;\n\tif (ext4_has_unknown_ext2_ro_compat_features(sb))\n\t\treturn 0;\n\treturn 1;\n}\n#else\nstatic inline void register_as_ext2(void) { }\nstatic inline void unregister_as_ext2(void) { }\nstatic inline int ext2_feature_set_ok(struct super_block *sb) { return 0; }\n#endif\n\nstatic inline void register_as_ext3(void)\n{\n\tint err = register_filesystem(&ext3_fs_type);\n\tif (err)\n\t\tprintk(KERN_WARNING\n\t\t       \"EXT4-fs: Unable to register as ext3 (%d)\\n\", err);\n}\n\nstatic inline void unregister_as_ext3(void)\n{\n\tunregister_filesystem(&ext3_fs_type);\n}\n\nstatic inline int ext3_feature_set_ok(struct super_block *sb)\n{\n\tif (ext4_has_unknown_ext3_incompat_features(sb))\n\t\treturn 0;\n\tif (!ext4_has_feature_journal(sb))\n\t\treturn 0;\n\tif (sb->s_flags & MS_RDONLY)\n\t\treturn 1;\n\tif (ext4_has_unknown_ext3_ro_compat_features(sb))\n\t\treturn 0;\n\treturn 1;\n}\n\nstatic struct file_system_type ext4_fs_type = {\n\t.owner\t\t= THIS_MODULE,\n\t.name\t\t= \"ext4\",\n\t.mount\t\t= ext4_mount,\n\t.kill_sb\t= kill_block_super,\n\t.fs_flags\t= FS_REQUIRES_DEV,\n};\nMODULE_ALIAS_FS(\"ext4\");\n\n/* Shared across all ext4 file systems */\nwait_queue_head_t ext4__ioend_wq[EXT4_WQ_HASH_SZ];\n\nstatic int __init ext4_init_fs(void)\n{\n\tint i, err;\n\n\tratelimit_state_init(&ext4_mount_msg_ratelimit, 30 * HZ, 64);\n\text4_li_info = NULL;\n\tmutex_init(&ext4_li_mtx);\n\n\t/* Build-time check for flags consistency */\n\text4_check_flag_values();\n\n\tfor (i = 0; i < EXT4_WQ_HASH_SZ; i++)\n\t\tinit_waitqueue_head(&ext4__ioend_wq[i]);\n\n\terr = ext4_init_es();\n\tif (err)\n\t\treturn err;\n\n\terr = ext4_init_pageio();\n\tif (err)\n\t\tgoto out5;\n\n\terr = ext4_init_system_zone();\n\tif (err)\n\t\tgoto out4;\n\n\terr = ext4_init_sysfs();\n\tif (err)\n\t\tgoto out3;\n\n\terr = ext4_init_mballoc();\n\tif (err)\n\t\tgoto out2;\n\terr = init_inodecache();\n\tif (err)\n\t\tgoto out1;\n\tregister_as_ext3();\n\tregister_as_ext2();\n\terr = register_filesystem(&ext4_fs_type);\n\tif (err)\n\t\tgoto out;\n\n\treturn 0;\nout:\n\tunregister_as_ext2();\n\tunregister_as_ext3();\n\tdestroy_inodecache();\nout1:\n\text4_exit_mballoc();\nout2:\n\text4_exit_sysfs();\nout3:\n\text4_exit_system_zone();\nout4:\n\text4_exit_pageio();\nout5:\n\text4_exit_es();\n\n\treturn err;\n}\n\nstatic void __exit ext4_exit_fs(void)\n{\n\text4_destroy_lazyinit_thread();\n\tunregister_as_ext2();\n\tunregister_as_ext3();\n\tunregister_filesystem(&ext4_fs_type);\n\tdestroy_inodecache();\n\text4_exit_mballoc();\n\text4_exit_sysfs();\n\text4_exit_system_zone();\n\text4_exit_pageio();\n\text4_exit_es();\n}\n\nMODULE_AUTHOR(\"Remy Card, Stephen Tweedie, Andrew Morton, Andreas Dilger, Theodore Ts'o and others\");\nMODULE_DESCRIPTION(\"Fourth Extended Filesystem\");\nMODULE_LICENSE(\"GPL\");\nmodule_init(ext4_init_fs)\nmodule_exit(ext4_exit_fs)\n"], "filenames": ["fs/ext4/super.c"], "buggy_code_start_loc": [3844], "buggy_code_end_loc": [3844], "fixing_code_start_loc": [3845], "fixing_code_end_loc": [3854], "type": "CWE-125", "message": "The ext4_fill_super function in fs/ext4/super.c in the Linux kernel through 4.9.8 does not properly validate meta block groups, which allows physically proximate attackers to cause a denial of service (out-of-bounds read and system crash) via a crafted ext4 image.", "other": {"cve": {"id": "CVE-2016-10208", "sourceIdentifier": "cve@mitre.org", "published": "2017-02-06T06:59:00.357", "lastModified": "2018-08-24T10:29:00.333", "vulnStatus": "Modified", "descriptions": [{"lang": "en", "value": "The ext4_fill_super function in fs/ext4/super.c in the Linux kernel through 4.9.8 does not properly validate meta block groups, which allows physically proximate attackers to cause a denial of service (out-of-bounds read and system crash) via a crafted ext4 image."}, {"lang": "es", "value": "La funci\u00f3n ext4_fill_super en fs/ext4/super.c en el kernel de Linux hasta la versi\u00f3n 4.9.8 no valida correctamente los grupos de bloque meta, lo que permite a atacantes f\u00edsicamente pr\u00f3ximos provocar una denegaci\u00f3n de servicio (lectura fuera de l\u00edmites y ca\u00edda del sistema) a trav\u00e9s de una imagen ext4 manipulada."}], "metrics": {"cvssMetricV30": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.0", "vectorString": "CVSS:3.0/AV:P/AC:L/PR:L/UI:N/S:U/C:N/I:N/A:H", "attackVector": "PHYSICAL", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 4.3, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 0.7, "impactScore": 3.6}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:L/AC:L/Au:N/C:N/I:N/A:C", "accessVector": "LOCAL", "accessComplexity": "LOW", "authentication": "NONE", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "COMPLETE", "baseScore": 4.9}, "baseSeverity": "MEDIUM", "exploitabilityScore": 3.9, "impactScore": 6.9, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-125"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionEndIncluding": "4.9.8", "matchCriteriaId": "631307FC-F876-4F6F-9611-3DA04263A60E"}]}]}], "references": [{"url": "http://git.kernel.org/cgit/linux/kernel/git/torvalds/linux.git/commit/?id=3a4b77cd47bb837b8557595ec7425f281f2ca1fe", "source": "cve@mitre.org", "tags": ["Issue Tracking", "Patch", "Third Party Advisory"]}, {"url": "http://seclists.org/fulldisclosure/2016/Nov/75", "source": "cve@mitre.org", "tags": ["Mailing List", "Third Party Advisory"]}, {"url": "http://www.openwall.com/lists/oss-security/2017/02/05/3", "source": "cve@mitre.org", "tags": ["Mailing List", "Patch", "Third Party Advisory"]}, {"url": "http://www.securityfocus.com/bid/94354", "source": "cve@mitre.org"}, {"url": "https://access.redhat.com/errata/RHSA-2017:1297", "source": "cve@mitre.org"}, {"url": "https://access.redhat.com/errata/RHSA-2017:1298", "source": "cve@mitre.org"}, {"url": "https://access.redhat.com/errata/RHSA-2017:1308", "source": "cve@mitre.org"}, {"url": "https://bugzilla.redhat.com/show_bug.cgi?id=1395190", "source": "cve@mitre.org", "tags": ["Issue Tracking", "Patch"]}, {"url": "https://github.com/torvalds/linux/commit/3a4b77cd47bb837b8557595ec7425f281f2ca1fe", "source": "cve@mitre.org", "tags": ["Issue Tracking", "Patch", "Third Party Advisory"]}, {"url": "https://lists.debian.org/debian-lts-announce/2017/12/msg00004.html", "source": "cve@mitre.org"}, {"url": "https://usn.ubuntu.com/3754-1/", "source": "cve@mitre.org"}]}, "github_commit_url": "https://github.com/torvalds/linux/commit/3a4b77cd47bb837b8557595ec7425f281f2ca1fe"}}
{"buggy_code": ["Changes\n=======\n\ndev (master)\n------------\n\n* Change ``is_ipaddress`` to not detect IPvFuture addresses. (Pull #1583)\n\n\n1.25.1 (2019-04-24)\n-------------------\n\n* Add support for Google's ``Brotli`` package. (Pull #1572, Pull #1579)\n\n* Upgrade bundled rfc3986 to v1.3.1 (Pull #1578)\n\n\n1.25 (2019-04-22)\n-----------------\n\n* Require and validate certificates by default when using HTTPS (Pull #1507)\n\n* Upgraded ``urllib3.utils.parse_url()`` to be RFC 3986 compliant. (Pull #1487)\n\n* Added support for ``key_password`` for ``HTTPSConnectionPool`` to use\n  encrypted ``key_file`` without creating your own ``SSLContext`` object. (Pull #1489)\n\n* Add TLSv1.3 support to CPython, pyOpenSSL, and SecureTransport ``SSLContext``\n  implementations. (Pull #1496)\n\n* Switched the default multipart header encoder from RFC 2231 to HTML 5 working draft. (Issue #303, PR #1492)\n\n* Fixed issue where OpenSSL would block if an encrypted client private key was\n  given and no password was given. Instead an ``SSLError`` is raised. (Pull #1489)\n\n* Added support for Brotli content encoding. It is enabled automatically if\n  ``brotlipy`` package is installed which can be requested with\n  ``urllib3[brotli]`` extra. (Pull #1532)\n\n* Drop ciphers using DSS key exchange from default TLS cipher suites.\n  Improve default ciphers when using SecureTransport. (Pull #1496)\n\n* Implemented a more efficient ``HTTPResponse.__iter__()`` method. (Issue #1483)\n\n\n1.24.2 (2019-04-17)\n-------------------\n\n* Don't load system certificates by default when any other ``ca_certs``, ``ca_certs_dir`` or\n  ``ssl_context`` parameters are specified.\n\n* Remove Authorization header regardless of case when redirecting to cross-site. (Issue #1510)\n\n* Add support for IPv6 addresses in subjectAltName section of certificates. (Issue #1269)\n\n\n1.24.1 (2018-11-02)\n-------------------\n\n* Remove quadratic behavior within ``GzipDecoder.decompress()`` (Issue #1467)\n\n* Restored functionality of ``ciphers`` parameter for ``create_urllib3_context()``. (Issue #1462)\n\n\n1.24 (2018-10-16)\n-----------------\n\n* Allow key_server_hostname to be specified when initializing a PoolManager to allow custom SNI to be overridden. (Pull #1449)\n\n* Test against Python 3.7 on AppVeyor. (Pull #1453)\n\n* Early-out ipv6 checks when running on App Engine. (Pull #1450)\n\n* Change ambiguous description of backoff_factor (Pull #1436)\n\n* Add ability to handle multiple Content-Encodings (Issue #1441 and Pull #1442)\n\n* Skip DNS names that can't be idna-decoded when using pyOpenSSL (Issue #1405).\n\n* Add a server_hostname parameter to HTTPSConnection which allows for\n  overriding the SNI hostname sent in the handshake. (Pull #1397)\n\n* Drop support for EOL Python 2.6 (Pull #1429 and Pull #1430)\n\n* Fixed bug where responses with header Content-Type: message/* erroneously\n  raised HeaderParsingError, resulting in a warning being logged. (Pull #1439)\n\n* Move urllib3 to src/urllib3 (Pull #1409)\n\n\n1.23 (2018-06-04)\n-----------------\n\n* Allow providing a list of headers to strip from requests when redirecting\n  to a different host. Defaults to the ``Authorization`` header. Different\n  headers can be set via ``Retry.remove_headers_on_redirect``. (Issue #1316)\n\n* Fix ``util.selectors._fileobj_to_fd`` to accept ``long`` (Issue #1247).\n\n* Dropped Python 3.3 support. (Pull #1242)\n\n* Put the connection back in the pool when calling stream() or read_chunked() on\n  a chunked HEAD response. (Issue #1234)\n\n* Fixed pyOpenSSL-specific ssl client authentication issue when clients\n  attempted to auth via certificate + chain (Issue #1060)\n\n* Add the port to the connectionpool connect print (Pull #1251)\n\n* Don't use the ``uuid`` module to create multipart data boundaries. (Pull #1380)\n\n* ``read_chunked()`` on a closed response returns no chunks. (Issue #1088)\n\n* Add Python 2.6 support to ``contrib.securetransport`` (Pull #1359)\n\n* Added support for auth info in url for SOCKS proxy (Pull #1363)\n\n\n1.22 (2017-07-20)\n-----------------\n\n* Fixed missing brackets in ``HTTP CONNECT`` when connecting to IPv6 address via\n  IPv6 proxy. (Issue #1222)\n\n* Made the connection pool retry on ``SSLError``.  The original ``SSLError``\n  is available on ``MaxRetryError.reason``. (Issue #1112)\n\n* Drain and release connection before recursing on retry/redirect.  Fixes\n  deadlocks with a blocking connectionpool. (Issue #1167)\n\n* Fixed compatibility for cookiejar. (Issue #1229)\n\n* pyopenssl: Use vendored version of ``six``. (Issue #1231)\n\n\n1.21.1 (2017-05-02)\n-------------------\n\n* Fixed SecureTransport issue that would cause long delays in response body\n  delivery. (Pull #1154)\n\n* Fixed regression in 1.21 that threw exceptions when users passed the\n  ``socket_options`` flag to the ``PoolManager``.  (Issue #1165)\n\n* Fixed regression in 1.21 that threw exceptions when users passed the\n  ``assert_hostname`` or ``assert_fingerprint`` flag to the ``PoolManager``.\n  (Pull #1157)\n\n\n1.21 (2017-04-25)\n-----------------\n\n* Improved performance of certain selector system calls on Python 3.5 and\n  later. (Pull #1095)\n\n* Resolved issue where the PyOpenSSL backend would not wrap SysCallError\n  exceptions appropriately when sending data. (Pull #1125)\n\n* Selectors now detects a monkey-patched select module after import for modules\n  that patch the select module like eventlet, greenlet. (Pull #1128)\n\n* Reduced memory consumption when streaming zlib-compressed responses\n  (as opposed to raw deflate streams). (Pull #1129)\n\n* Connection pools now use the entire request context when constructing the\n  pool key. (Pull #1016)\n\n* ``PoolManager.connection_from_*`` methods now accept a new keyword argument,\n  ``pool_kwargs``, which are merged with the existing ``connection_pool_kw``.\n  (Pull #1016)\n\n* Add retry counter for ``status_forcelist``. (Issue #1147)\n\n* Added ``contrib`` module for using SecureTransport on macOS:\n  ``urllib3.contrib.securetransport``.  (Pull #1122)\n\n* urllib3 now only normalizes the case of ``http://`` and ``https://`` schemes:\n  for schemes it does not recognise, it assumes they are case-sensitive and\n  leaves them unchanged.\n  (Issue #1080)\n\n\n1.20 (2017-01-19)\n-----------------\n\n* Added support for waiting for I/O using selectors other than select,\n  improving urllib3's behaviour with large numbers of concurrent connections.\n  (Pull #1001)\n\n* Updated the date for the system clock check. (Issue #1005)\n\n* ConnectionPools now correctly consider hostnames to be case-insensitive.\n  (Issue #1032)\n\n* Outdated versions of PyOpenSSL now cause the PyOpenSSL contrib module\n  to fail when it is injected, rather than at first use. (Pull #1063)\n\n* Outdated versions of cryptography now cause the PyOpenSSL contrib module\n  to fail when it is injected, rather than at first use. (Issue #1044)\n\n* Automatically attempt to rewind a file-like body object when a request is\n  retried or redirected. (Pull #1039)\n\n* Fix some bugs that occur when modules incautiously patch the queue module.\n  (Pull #1061)\n\n* Prevent retries from occurring on read timeouts for which the request method\n  was not in the method whitelist. (Issue #1059)\n\n* Changed the PyOpenSSL contrib module to lazily load idna to avoid\n  unnecessarily bloating the memory of programs that don't need it. (Pull\n  #1076)\n\n* Add support for IPv6 literals with zone identifiers. (Pull #1013)\n\n* Added support for socks5h:// and socks4a:// schemes when working with SOCKS\n  proxies, and controlled remote DNS appropriately. (Issue #1035)\n\n\n1.19.1 (2016-11-16)\n-------------------\n\n* Fixed AppEngine import that didn't function on Python 3.5. (Pull #1025)\n\n\n1.19 (2016-11-03)\n-----------------\n\n* urllib3 now respects Retry-After headers on 413, 429, and 503 responses when\n  using the default retry logic. (Pull #955)\n\n* Remove markers from setup.py to assist ancient setuptools versions. (Issue\n  #986)\n\n* Disallow superscripts and other integerish things in URL ports. (Issue #989)\n\n* Allow urllib3's HTTPResponse.stream() method to continue to work with\n  non-httplib underlying FPs. (Pull #990)\n\n* Empty filenames in multipart headers are now emitted as such, rather than\n  being suppressed. (Issue #1015)\n\n* Prefer user-supplied Host headers on chunked uploads. (Issue #1009)\n\n\n1.18.1 (2016-10-27)\n-------------------\n\n* CVE-2016-9015. Users who are using urllib3 version 1.17 or 1.18 along with\n  PyOpenSSL injection and OpenSSL 1.1.0 *must* upgrade to this version. This\n  release fixes a vulnerability whereby urllib3 in the above configuration\n  would silently fail to validate TLS certificates due to erroneously setting\n  invalid flags in OpenSSL's ``SSL_CTX_set_verify`` function. These erroneous\n  flags do not cause a problem in OpenSSL versions before 1.1.0, which\n  interprets the presence of any flag as requesting certificate validation.\n\n  There is no PR for this patch, as it was prepared for simultaneous disclosure\n  and release. The master branch received the same fix in PR #1010.\n\n\n1.18 (2016-09-26)\n-----------------\n\n* Fixed incorrect message for IncompleteRead exception. (PR #973)\n\n* Accept ``iPAddress`` subject alternative name fields in TLS certificates.\n  (Issue #258)\n\n* Fixed consistency of ``HTTPResponse.closed`` between Python 2 and 3.\n  (Issue #977)\n\n* Fixed handling of wildcard certificates when using PyOpenSSL. (Issue #979)\n\n\n1.17 (2016-09-06)\n-----------------\n\n* Accept ``SSLContext`` objects for use in SSL/TLS negotiation. (Issue #835)\n\n* ConnectionPool debug log now includes scheme, host, and port. (Issue #897)\n\n* Substantially refactored documentation. (Issue #887)\n\n* Used URLFetch default timeout on AppEngine, rather than hardcoding our own.\n  (Issue #858)\n\n* Normalize the scheme and host in the URL parser (Issue #833)\n\n* ``HTTPResponse`` contains the last ``Retry`` object, which now also\n  contains retries history. (Issue #848)\n\n* Timeout can no longer be set as boolean, and must be greater than zero.\n  (PR #924)\n\n* Removed pyasn1 and ndg-httpsclient from dependencies used for PyOpenSSL. We\n  now use cryptography and idna, both of which are already dependencies of\n  PyOpenSSL. (PR #930)\n\n* Fixed infinite loop in ``stream`` when amt=None. (Issue #928)\n\n* Try to use the operating system's certificates when we are using an\n  ``SSLContext``. (PR #941)\n\n* Updated cipher suite list to allow ChaCha20+Poly1305. AES-GCM is preferred to\n  ChaCha20, but ChaCha20 is then preferred to everything else. (PR #947)\n\n* Updated cipher suite list to remove 3DES-based cipher suites. (PR #958)\n\n* Removed the cipher suite fallback to allow HIGH ciphers. (PR #958)\n\n* Implemented ``length_remaining`` to determine remaining content\n  to be read. (PR #949)\n\n* Implemented ``enforce_content_length`` to enable exceptions when\n  incomplete data chunks are received. (PR #949)\n\n* Dropped connection start, dropped connection reset, redirect, forced retry,\n  and new HTTPS connection log levels to DEBUG, from INFO. (PR #967)\n\n\n1.16 (2016-06-11)\n-----------------\n\n* Disable IPv6 DNS when IPv6 connections are not possible. (Issue #840)\n\n* Provide ``key_fn_by_scheme`` pool keying mechanism that can be\n  overridden. (Issue #830)\n\n* Normalize scheme and host to lowercase for pool keys, and include\n  ``source_address``. (Issue #830)\n\n* Cleaner exception chain in Python 3 for ``_make_request``.\n  (Issue #861)\n\n* Fixed installing ``urllib3[socks]`` extra. (Issue #864)\n\n* Fixed signature of ``ConnectionPool.close`` so it can actually safely be\n  called by subclasses. (Issue #873)\n\n* Retain ``release_conn`` state across retries. (Issues #651, #866)\n\n* Add customizable ``HTTPConnectionPool.ResponseCls``, which defaults to\n  ``HTTPResponse`` but can be replaced with a subclass. (Issue #879)\n\n\n1.15.1 (2016-04-11)\n-------------------\n\n* Fix packaging to include backports module. (Issue #841)\n\n\n1.15 (2016-04-06)\n-----------------\n\n* Added Retry(raise_on_status=False). (Issue #720)\n\n* Always use setuptools, no more distutils fallback. (Issue #785)\n\n* Dropped support for Python 3.2. (Issue #786)\n\n* Chunked transfer encoding when requesting with ``chunked=True``.\n  (Issue #790)\n\n* Fixed regression with IPv6 port parsing. (Issue #801)\n\n* Append SNIMissingWarning messages to allow users to specify it in\n  the PYTHONWARNINGS environment variable. (Issue #816)\n\n* Handle unicode headers in Py2. (Issue #818)\n\n* Log certificate when there is a hostname mismatch. (Issue #820)\n\n* Preserve order of request/response headers. (Issue #821)\n\n\n1.14 (2015-12-29)\n-----------------\n\n* contrib: SOCKS proxy support! (Issue #762)\n\n* Fixed AppEngine handling of transfer-encoding header and bug\n  in Timeout defaults checking. (Issue #763)\n\n\n1.13.1 (2015-12-18)\n-------------------\n\n* Fixed regression in IPv6 + SSL for match_hostname. (Issue #761)\n\n\n1.13 (2015-12-14)\n-----------------\n\n* Fixed ``pip install urllib3[secure]`` on modern pip. (Issue #706)\n\n* pyopenssl: Fixed SSL3_WRITE_PENDING error. (Issue #717)\n\n* pyopenssl: Support for TLSv1.1 and TLSv1.2. (Issue #696)\n\n* Close connections more defensively on exception. (Issue #734)\n\n* Adjusted ``read_chunked`` to handle gzipped, chunk-encoded bodies without\n  repeatedly flushing the decoder, to function better on Jython. (Issue #743)\n\n* Accept ``ca_cert_dir`` for SSL-related PoolManager configuration. (Issue #758)\n\n\n1.12 (2015-09-03)\n-----------------\n\n* Rely on ``six`` for importing ``httplib`` to work around\n  conflicts with other Python 3 shims. (Issue #688)\n\n* Add support for directories of certificate authorities, as supported by\n  OpenSSL. (Issue #701)\n\n* New exception: ``NewConnectionError``, raised when we fail to establish\n  a new connection, usually ``ECONNREFUSED`` socket error.\n\n\n1.11 (2015-07-21)\n-----------------\n\n* When ``ca_certs`` is given, ``cert_reqs`` defaults to\n  ``'CERT_REQUIRED'``. (Issue #650)\n\n* ``pip install urllib3[secure]`` will install Certifi and\n  PyOpenSSL as dependencies. (Issue #678)\n\n* Made ``HTTPHeaderDict`` usable as a ``headers`` input value\n  (Issues #632, #679)\n\n* Added `urllib3.contrib.appengine <https://urllib3.readthedocs.io/en/latest/contrib.html#google-app-engine>`_\n  which has an ``AppEngineManager`` for using ``URLFetch`` in a\n  Google AppEngine environment. (Issue #664)\n\n* Dev: Added test suite for AppEngine. (Issue #631)\n\n* Fix performance regression when using PyOpenSSL. (Issue #626)\n\n* Passing incorrect scheme (e.g. ``foo://``) will raise\n  ``ValueError`` instead of ``AssertionError`` (backwards\n  compatible for now, but please migrate). (Issue #640)\n\n* Fix pools not getting replenished when an error occurs during a\n  request using ``release_conn=False``. (Issue #644)\n\n* Fix pool-default headers not applying for url-encoded requests\n  like GET. (Issue #657)\n\n* log.warning in Python 3 when headers are skipped due to parsing\n  errors. (Issue #642)\n\n* Close and discard connections if an error occurs during read.\n  (Issue #660)\n\n* Fix host parsing for IPv6 proxies. (Issue #668)\n\n* Separate warning type SubjectAltNameWarning, now issued once\n  per host. (Issue #671)\n\n* Fix ``httplib.IncompleteRead`` not getting converted to\n  ``ProtocolError`` when using ``HTTPResponse.stream()``\n  (Issue #674)\n\n1.10.4 (2015-05-03)\n-------------------\n\n* Migrate tests to Tornado 4. (Issue #594)\n\n* Append default warning configuration rather than overwrite.\n  (Issue #603)\n\n* Fix streaming decoding regression. (Issue #595)\n\n* Fix chunked requests losing state across keep-alive connections.\n  (Issue #599)\n\n* Fix hanging when chunked HEAD response has no body. (Issue #605)\n\n\n1.10.3 (2015-04-21)\n-------------------\n\n* Emit ``InsecurePlatformWarning`` when SSLContext object is missing.\n  (Issue #558)\n\n* Fix regression of duplicate header keys being discarded.\n  (Issue #563)\n\n* ``Response.stream()`` returns a generator for chunked responses.\n  (Issue #560)\n\n* Set upper-bound timeout when waiting for a socket in PyOpenSSL.\n  (Issue #585)\n\n* Work on platforms without `ssl` module for plain HTTP requests.\n  (Issue #587)\n\n* Stop relying on the stdlib's default cipher list. (Issue #588)\n\n\n1.10.2 (2015-02-25)\n-------------------\n\n* Fix file descriptor leakage on retries. (Issue #548)\n\n* Removed RC4 from default cipher list. (Issue #551)\n\n* Header performance improvements. (Issue #544)\n\n* Fix PoolManager not obeying redirect retry settings. (Issue #553)\n\n\n1.10.1 (2015-02-10)\n-------------------\n\n* Pools can be used as context managers. (Issue #545)\n\n* Don't re-use connections which experienced an SSLError. (Issue #529)\n\n* Don't fail when gzip decoding an empty stream. (Issue #535)\n\n* Add sha256 support for fingerprint verification. (Issue #540)\n\n* Fixed handling of header values containing commas. (Issue #533)\n\n\n1.10 (2014-12-14)\n-----------------\n\n* Disabled SSLv3. (Issue #473)\n\n* Add ``Url.url`` property to return the composed url string. (Issue #394)\n\n* Fixed PyOpenSSL + gevent ``WantWriteError``. (Issue #412)\n\n* ``MaxRetryError.reason`` will always be an exception, not string.\n  (Issue #481)\n\n* Fixed SSL-related timeouts not being detected as timeouts. (Issue #492)\n\n* Py3: Use ``ssl.create_default_context()`` when available. (Issue #473)\n\n* Emit ``InsecureRequestWarning`` for *every* insecure HTTPS request.\n  (Issue #496)\n\n* Emit ``SecurityWarning`` when certificate has no ``subjectAltName``.\n  (Issue #499)\n\n* Close and discard sockets which experienced SSL-related errors.\n  (Issue #501)\n\n* Handle ``body`` param in ``.request(...)``. (Issue #513)\n\n* Respect timeout with HTTPS proxy. (Issue #505)\n\n* PyOpenSSL: Handle ZeroReturnError exception. (Issue #520)\n\n\n1.9.1 (2014-09-13)\n------------------\n\n* Apply socket arguments before binding. (Issue #427)\n\n* More careful checks if fp-like object is closed. (Issue #435)\n\n* Fixed packaging issues of some development-related files not\n  getting included. (Issue #440)\n\n* Allow performing *only* fingerprint verification. (Issue #444)\n\n* Emit ``SecurityWarning`` if system clock is waaay off. (Issue #445)\n\n* Fixed PyOpenSSL compatibility with PyPy. (Issue #450)\n\n* Fixed ``BrokenPipeError`` and ``ConnectionError`` handling in Py3.\n  (Issue #443)\n\n\n\n1.9 (2014-07-04)\n----------------\n\n* Shuffled around development-related files. If you're maintaining a distro\n  package of urllib3, you may need to tweak things. (Issue #415)\n\n* Unverified HTTPS requests will trigger a warning on the first request. See\n  our new `security documentation\n  <https://urllib3.readthedocs.io/en/latest/security.html>`_ for details.\n  (Issue #426)\n\n* New retry logic and ``urllib3.util.retry.Retry`` configuration object.\n  (Issue #326)\n\n* All raised exceptions should now wrapped in a\n  ``urllib3.exceptions.HTTPException``-extending exception. (Issue #326)\n\n* All errors during a retry-enabled request should be wrapped in\n  ``urllib3.exceptions.MaxRetryError``, including timeout-related exceptions\n  which were previously exempt. Underlying error is accessible from the\n  ``.reason`` property. (Issue #326)\n\n* ``urllib3.exceptions.ConnectionError`` renamed to\n  ``urllib3.exceptions.ProtocolError``. (Issue #326)\n\n* Errors during response read (such as IncompleteRead) are now wrapped in\n  ``urllib3.exceptions.ProtocolError``. (Issue #418)\n\n* Requesting an empty host will raise ``urllib3.exceptions.LocationValueError``.\n  (Issue #417)\n\n* Catch read timeouts over SSL connections as\n  ``urllib3.exceptions.ReadTimeoutError``. (Issue #419)\n\n* Apply socket arguments before connecting. (Issue #427)\n\n\n1.8.3 (2014-06-23)\n------------------\n\n* Fix TLS verification when using a proxy in Python 3.4.1. (Issue #385)\n\n* Add ``disable_cache`` option to ``urllib3.util.make_headers``. (Issue #393)\n\n* Wrap ``socket.timeout`` exception with\n  ``urllib3.exceptions.ReadTimeoutError``. (Issue #399)\n\n* Fixed proxy-related bug where connections were being reused incorrectly.\n  (Issues #366, #369)\n\n* Added ``socket_options`` keyword parameter which allows to define\n  ``setsockopt`` configuration of new sockets. (Issue #397)\n\n* Removed ``HTTPConnection.tcp_nodelay`` in favor of\n  ``HTTPConnection.default_socket_options``. (Issue #397)\n\n* Fixed ``TypeError`` bug in Python 2.6.4. (Issue #411)\n\n\n1.8.2 (2014-04-17)\n------------------\n\n* Fix ``urllib3.util`` not being included in the package.\n\n\n1.8.1 (2014-04-17)\n------------------\n\n* Fix AppEngine bug of HTTPS requests going out as HTTP. (Issue #356)\n\n* Don't install ``dummyserver`` into ``site-packages`` as it's only needed\n  for the test suite. (Issue #362)\n\n* Added support for specifying ``source_address``. (Issue #352)\n\n\n1.8 (2014-03-04)\n----------------\n\n* Improved url parsing in ``urllib3.util.parse_url`` (properly parse '@' in\n  username, and blank ports like 'hostname:').\n\n* New ``urllib3.connection`` module which contains all the HTTPConnection\n  objects.\n\n* Several ``urllib3.util.Timeout``-related fixes. Also changed constructor\n  signature to a more sensible order. [Backwards incompatible]\n  (Issues #252, #262, #263)\n\n* Use ``backports.ssl_match_hostname`` if it's installed. (Issue #274)\n\n* Added ``.tell()`` method to ``urllib3.response.HTTPResponse`` which\n  returns the number of bytes read so far. (Issue #277)\n\n* Support for platforms without threading. (Issue #289)\n\n* Expand default-port comparison in ``HTTPConnectionPool.is_same_host``\n  to allow a pool with no specified port to be considered equal to to an\n  HTTP/HTTPS url with port 80/443 explicitly provided. (Issue #305)\n\n* Improved default SSL/TLS settings to avoid vulnerabilities.\n  (Issue #309)\n\n* Fixed ``urllib3.poolmanager.ProxyManager`` not retrying on connect errors.\n  (Issue #310)\n\n* Disable Nagle's Algorithm on the socket for non-proxies. A subset of requests\n  will send the entire HTTP request ~200 milliseconds faster; however, some of\n  the resulting TCP packets will be smaller. (Issue #254)\n\n* Increased maximum number of SubjectAltNames in ``urllib3.contrib.pyopenssl``\n  from the default 64 to 1024 in a single certificate. (Issue #318)\n\n* Headers are now passed and stored as a custom\n  ``urllib3.collections_.HTTPHeaderDict`` object rather than a plain ``dict``.\n  (Issue #329, #333)\n\n* Headers no longer lose their case on Python 3. (Issue #236)\n\n* ``urllib3.contrib.pyopenssl`` now uses the operating system's default CA\n  certificates on inject. (Issue #332)\n\n* Requests with ``retries=False`` will immediately raise any exceptions without\n  wrapping them in ``MaxRetryError``. (Issue #348)\n\n* Fixed open socket leak with SSL-related failures. (Issue #344, #348)\n\n\n1.7.1 (2013-09-25)\n------------------\n\n* Added granular timeout support with new ``urllib3.util.Timeout`` class.\n  (Issue #231)\n\n* Fixed Python 3.4 support. (Issue #238)\n\n\n1.7 (2013-08-14)\n----------------\n\n* More exceptions are now pickle-able, with tests. (Issue #174)\n\n* Fixed redirecting with relative URLs in Location header. (Issue #178)\n\n* Support for relative urls in ``Location: ...`` header. (Issue #179)\n\n* ``urllib3.response.HTTPResponse`` now inherits from ``io.IOBase`` for bonus\n  file-like functionality. (Issue #187)\n\n* Passing ``assert_hostname=False`` when creating a HTTPSConnectionPool will\n  skip hostname verification for SSL connections. (Issue #194)\n\n* New method ``urllib3.response.HTTPResponse.stream(...)`` which acts as a\n  generator wrapped around ``.read(...)``. (Issue #198)\n\n* IPv6 url parsing enforces brackets around the hostname. (Issue #199)\n\n* Fixed thread race condition in\n  ``urllib3.poolmanager.PoolManager.connection_from_host(...)`` (Issue #204)\n\n* ``ProxyManager`` requests now include non-default port in ``Host: ...``\n  header. (Issue #217)\n\n* Added HTTPS proxy support in ``ProxyManager``. (Issue #170 #139)\n\n* New ``RequestField`` object can be passed to the ``fields=...`` param which\n  can specify headers. (Issue #220)\n\n* Raise ``urllib3.exceptions.ProxyError`` when connecting to proxy fails.\n  (Issue #221)\n\n* Use international headers when posting file names. (Issue #119)\n\n* Improved IPv6 support. (Issue #203)\n\n\n1.6 (2013-04-25)\n----------------\n\n* Contrib: Optional SNI support for Py2 using PyOpenSSL. (Issue #156)\n\n* ``ProxyManager`` automatically adds ``Host: ...`` header if not given.\n\n* Improved SSL-related code. ``cert_req`` now optionally takes a string like\n  \"REQUIRED\" or \"NONE\". Same with ``ssl_version`` takes strings like \"SSLv23\"\n  The string values reflect the suffix of the respective constant variable.\n  (Issue #130)\n\n* Vendored ``socksipy`` now based on Anorov's fork which handles unexpectedly\n  closed proxy connections and larger read buffers. (Issue #135)\n\n* Ensure the connection is closed if no data is received, fixes connection leak\n  on some platforms. (Issue #133)\n\n* Added SNI support for SSL/TLS connections on Py32+. (Issue #89)\n\n* Tests fixed to be compatible with Py26 again. (Issue #125)\n\n* Added ability to choose SSL version by passing an ``ssl.PROTOCOL_*`` constant\n  to the ``ssl_version`` parameter of ``HTTPSConnectionPool``. (Issue #109)\n\n* Allow an explicit content type to be specified when encoding file fields.\n  (Issue #126)\n\n* Exceptions are now pickleable, with tests. (Issue #101)\n\n* Fixed default headers not getting passed in some cases. (Issue #99)\n\n* Treat \"content-encoding\" header value as case-insensitive, per RFC 2616\n  Section 3.5. (Issue #110)\n\n* \"Connection Refused\" SocketErrors will get retried rather than raised.\n  (Issue #92)\n\n* Updated vendored ``six``, no longer overrides the global ``six`` module\n  namespace. (Issue #113)\n\n* ``urllib3.exceptions.MaxRetryError`` contains a ``reason`` property holding\n  the exception that prompted the final retry. If ``reason is None`` then it\n  was due to a redirect. (Issue #92, #114)\n\n* Fixed ``PoolManager.urlopen()`` from not redirecting more than once.\n  (Issue #149)\n\n* Don't assume ``Content-Type: text/plain`` for multi-part encoding parameters\n  that are not files. (Issue #111)\n\n* Pass `strict` param down to ``httplib.HTTPConnection``. (Issue #122)\n\n* Added mechanism to verify SSL certificates by fingerprint (md5, sha1) or\n  against an arbitrary hostname (when connecting by IP or for misconfigured\n  servers). (Issue #140)\n\n* Streaming decompression support. (Issue #159)\n\n\n1.5 (2012-08-02)\n----------------\n\n* Added ``urllib3.add_stderr_logger()`` for quickly enabling STDERR debug\n  logging in urllib3.\n\n* Native full URL parsing (including auth, path, query, fragment) available in\n  ``urllib3.util.parse_url(url)``.\n\n* Built-in redirect will switch method to 'GET' if status code is 303.\n  (Issue #11)\n\n* ``urllib3.PoolManager`` strips the scheme and host before sending the request\n  uri. (Issue #8)\n\n* New ``urllib3.exceptions.DecodeError`` exception for when automatic decoding,\n  based on the Content-Type header, fails.\n\n* Fixed bug with pool depletion and leaking connections (Issue #76). Added\n  explicit connection closing on pool eviction. Added\n  ``urllib3.PoolManager.clear()``.\n\n* 99% -> 100% unit test coverage.\n\n\n1.4 (2012-06-16)\n----------------\n\n* Minor AppEngine-related fixes.\n\n* Switched from ``mimetools.choose_boundary`` to ``uuid.uuid4()``.\n\n* Improved url parsing. (Issue #73)\n\n* IPv6 url support. (Issue #72)\n\n\n1.3 (2012-03-25)\n----------------\n\n* Removed pre-1.0 deprecated API.\n\n* Refactored helpers into a ``urllib3.util`` submodule.\n\n* Fixed multipart encoding to support list-of-tuples for keys with multiple\n  values. (Issue #48)\n\n* Fixed multiple Set-Cookie headers in response not getting merged properly in\n  Python 3. (Issue #53)\n\n* AppEngine support with Py27. (Issue #61)\n\n* Minor ``encode_multipart_formdata`` fixes related to Python 3 strings vs\n  bytes.\n\n\n1.2.2 (2012-02-06)\n------------------\n\n* Fixed packaging bug of not shipping ``test-requirements.txt``. (Issue #47)\n\n\n1.2.1 (2012-02-05)\n------------------\n\n* Fixed another bug related to when ``ssl`` module is not available. (Issue #41)\n\n* Location parsing errors now raise ``urllib3.exceptions.LocationParseError``\n  which inherits from ``ValueError``.\n\n\n1.2 (2012-01-29)\n----------------\n\n* Added Python 3 support (tested on 3.2.2)\n\n* Dropped Python 2.5 support (tested on 2.6.7, 2.7.2)\n\n* Use ``select.poll`` instead of ``select.select`` for platforms that support\n  it.\n\n* Use ``Queue.LifoQueue`` instead of ``Queue.Queue`` for more aggressive\n  connection reusing. Configurable by overriding ``ConnectionPool.QueueCls``.\n\n* Fixed ``ImportError`` during install when ``ssl`` module is not available.\n  (Issue #41)\n\n* Fixed ``PoolManager`` redirects between schemes (such as HTTP -> HTTPS) not\n  completing properly. (Issue #28, uncovered by Issue #10 in v1.1)\n\n* Ported ``dummyserver`` to use ``tornado`` instead of ``webob`` +\n  ``eventlet``. Removed extraneous unsupported dummyserver testing backends.\n  Added socket-level tests.\n\n* More tests. Achievement Unlocked: 99% Coverage.\n\n\n1.1 (2012-01-07)\n----------------\n\n* Refactored ``dummyserver`` to its own root namespace module (used for\n  testing).\n\n* Added hostname verification for ``VerifiedHTTPSConnection`` by vendoring in\n  Py32's ``ssl_match_hostname``. (Issue #25)\n\n* Fixed cross-host HTTP redirects when using ``PoolManager``. (Issue #10)\n\n* Fixed ``decode_content`` being ignored when set through ``urlopen``. (Issue\n  #27)\n\n* Fixed timeout-related bugs. (Issues #17, #23)\n\n\n1.0.2 (2011-11-04)\n------------------\n\n* Fixed typo in ``VerifiedHTTPSConnection`` which would only present as a bug if\n  you're using the object manually. (Thanks pyos)\n\n* Made RecentlyUsedContainer (and consequently PoolManager) more thread-safe by\n  wrapping the access log in a mutex. (Thanks @christer)\n\n* Made RecentlyUsedContainer more dict-like (corrected ``__delitem__`` and\n  ``__getitem__`` behaviour), with tests. Shouldn't affect core urllib3 code.\n\n\n1.0.1 (2011-10-10)\n------------------\n\n* Fixed a bug where the same connection would get returned into the pool twice,\n  causing extraneous \"HttpConnectionPool is full\" log warnings.\n\n\n1.0 (2011-10-08)\n----------------\n\n* Added ``PoolManager`` with LRU expiration of connections (tested and\n  documented).\n* Added ``ProxyManager`` (needs tests, docs, and confirmation that it works\n  with HTTPS proxies).\n* Added optional partial-read support for responses when\n  ``preload_content=False``. You can now make requests and just read the headers\n  without loading the content.\n* Made response decoding optional (default on, same as before).\n* Added optional explicit boundary string for ``encode_multipart_formdata``.\n* Convenience request methods are now inherited from ``RequestMethods``. Old\n  helpers like ``get_url`` and ``post_url`` should be abandoned in favour of\n  the new ``request(method, url, ...)``.\n* Refactored code to be even more decoupled, reusable, and extendable.\n* License header added to ``.py`` files.\n* Embiggened the documentation: Lots of Sphinx-friendly docstrings in the code\n  and docs in ``docs/`` and on https://urllib3.readthedocs.io/.\n* Embettered all the things!\n* Started writing this file.\n\n\n0.4.1 (2011-07-17)\n------------------\n\n* Minor bug fixes, code cleanup.\n\n\n0.4 (2011-03-01)\n----------------\n\n* Better unicode support.\n* Added ``VerifiedHTTPSConnection``.\n* Added ``NTLMConnectionPool`` in contrib.\n* Minor improvements.\n\n\n0.3.1 (2010-07-13)\n------------------\n\n* Added ``assert_host_name`` optional parameter. Now compatible with proxies.\n\n\n0.3 (2009-12-10)\n----------------\n\n* Added HTTPS support.\n* Minor bug fixes.\n* Refactored, broken backwards compatibility with 0.2.\n* API to be treated as stable from this version forward.\n\n\n0.2 (2008-11-17)\n----------------\n\n* Added unit tests.\n* Bug fixes.\n\n\n0.1 (2008-11-16)\n----------------\n\n* First release.\n", "from __future__ import absolute_import\nimport re\nfrom collections import namedtuple\n\nfrom ..exceptions import LocationParseError\nfrom ..packages import six, rfc3986\nfrom ..packages.rfc3986.exceptions import RFC3986Exception, ValidationError\nfrom ..packages.rfc3986.validators import Validator\n\n\nurl_attrs = ['scheme', 'auth', 'host', 'port', 'path', 'query', 'fragment']\n\n# We only want to normalize urls with an HTTP(S) scheme.\n# urllib3 infers URLs without a scheme (None) to be http.\nNORMALIZABLE_SCHEMES = ('http', 'https', None)\n\n# Regex for detecting URLs with schemes. RFC 3986 Section 3.1\nSCHEME_REGEX = re.compile(r\"^(?:[a-zA-Z][a-zA-Z0-9+\\-]*:|/)\")\n\n\nclass Url(namedtuple('Url', url_attrs)):\n    \"\"\"\n    Data structure for representing an HTTP URL. Used as a return value for\n    :func:`parse_url`. Both the scheme and host are normalized as they are\n    both case-insensitive according to RFC 3986.\n    \"\"\"\n    __slots__ = ()\n\n    def __new__(cls, scheme=None, auth=None, host=None, port=None, path=None,\n                query=None, fragment=None):\n        if path and not path.startswith('/'):\n            path = '/' + path\n        if scheme is not None:\n            scheme = scheme.lower()\n        return super(Url, cls).__new__(cls, scheme, auth, host, port, path,\n                                       query, fragment)\n\n    @property\n    def hostname(self):\n        \"\"\"For backwards-compatibility with urlparse. We're nice like that.\"\"\"\n        return self.host\n\n    @property\n    def request_uri(self):\n        \"\"\"Absolute path including the query string.\"\"\"\n        uri = self.path or '/'\n\n        if self.query is not None:\n            uri += '?' + self.query\n\n        return uri\n\n    @property\n    def netloc(self):\n        \"\"\"Network location including host and port\"\"\"\n        if self.port:\n            return '%s:%d' % (self.host, self.port)\n        return self.host\n\n    @property\n    def url(self):\n        \"\"\"\n        Convert self into a url\n\n        This function should more or less round-trip with :func:`.parse_url`. The\n        returned url may not be exactly the same as the url inputted to\n        :func:`.parse_url`, but it should be equivalent by the RFC (e.g., urls\n        with a blank port will have : removed).\n\n        Example: ::\n\n            >>> U = parse_url('http://google.com/mail/')\n            >>> U.url\n            'http://google.com/mail/'\n            >>> Url('http', 'username:password', 'host.com', 80,\n            ... '/path', 'query', 'fragment').url\n            'http://username:password@host.com:80/path?query#fragment'\n        \"\"\"\n        scheme, auth, host, port, path, query, fragment = self\n        url = u''\n\n        # We use \"is not None\" we want things to happen with empty strings (or 0 port)\n        if scheme is not None:\n            url += scheme + u'://'\n        if auth is not None:\n            url += auth + u'@'\n        if host is not None:\n            url += host\n        if port is not None:\n            url += u':' + str(port)\n        if path is not None:\n            url += path\n        if query is not None:\n            url += u'?' + query\n        if fragment is not None:\n            url += u'#' + fragment\n\n        return url\n\n    def __str__(self):\n        return self.url\n\n\ndef split_first(s, delims):\n    \"\"\"\n    .. deprecated:: 1.25\n\n    Given a string and an iterable of delimiters, split on the first found\n    delimiter. Return two split parts and the matched delimiter.\n\n    If not found, then the first part is the full input string.\n\n    Example::\n\n        >>> split_first('foo/bar?baz', '?/=')\n        ('foo', 'bar?baz', '/')\n        >>> split_first('foo/bar?baz', '123')\n        ('foo/bar?baz', '', None)\n\n    Scales linearly with number of delims. Not ideal for large number of delims.\n    \"\"\"\n    min_idx = None\n    min_delim = None\n    for d in delims:\n        idx = s.find(d)\n        if idx < 0:\n            continue\n\n        if min_idx is None or idx < min_idx:\n            min_idx = idx\n            min_delim = d\n\n    if min_idx is None or min_idx < 0:\n        return s, '', None\n\n    return s[:min_idx], s[min_idx + 1:], min_delim\n\n\ndef parse_url(url):\n    \"\"\"\n    Given a url, return a parsed :class:`.Url` namedtuple. Best-effort is\n    performed to parse incomplete urls. Fields not provided will be None.\n    This parser is RFC 3986 compliant.\n\n    :param str url: URL to parse into a :class:`.Url` namedtuple.\n\n    Partly backwards-compatible with :mod:`urlparse`.\n\n    Example::\n\n        >>> parse_url('http://google.com/mail/')\n        Url(scheme='http', host='google.com', port=None, path='/mail/', ...)\n        >>> parse_url('google.com:80')\n        Url(scheme=None, host='google.com', port=80, path=None, ...)\n        >>> parse_url('/foo?bar')\n        Url(scheme=None, host=None, port=None, path='/foo', query='bar', ...)\n    \"\"\"\n    if not url:\n        # Empty\n        return Url()\n\n    is_string = not isinstance(url, six.binary_type)\n    if not is_string:\n        url = url.decode(\"utf-8\")\n\n    # RFC 3986 doesn't like URLs that have a host but don't start\n    # with a scheme and we support URLs like that so we need to\n    # detect that problem and add an empty scheme indication.\n    # We don't get hurt on path-only URLs here as it's stripped\n    # off and given an empty scheme anyways.\n    if not SCHEME_REGEX.search(url):\n        url = \"//\" + url\n\n    try:\n        iri_ref = rfc3986.IRIReference.from_string(url, encoding=\"utf-8\")\n    except (ValueError, RFC3986Exception):\n        six.raise_from(LocationParseError(url), None)\n\n    def idna_encode(name):\n        if name and any([ord(x) > 128 for x in name]):\n            try:\n                import idna\n            except ImportError:\n                raise LocationParseError(\"Unable to parse URL without the 'idna' module\")\n            try:\n                return idna.encode(name.lower(), strict=True, std3_rules=True)\n            except idna.IDNAError:\n                raise LocationParseError(u\"Name '%s' is not a valid IDNA label\" % name)\n        return name\n\n    has_authority = iri_ref.authority is not None\n    uri_ref = iri_ref.encode(idna_encoder=idna_encode)\n\n    # rfc3986 strips the authority if it's invalid\n    if has_authority and uri_ref.authority is None:\n        raise LocationParseError(url)\n\n    # Only normalize schemes we understand to not break http+unix\n    # or other schemes that don't follow RFC 3986.\n    if uri_ref.scheme is None or uri_ref.scheme.lower() in NORMALIZABLE_SCHEMES:\n        uri_ref = uri_ref.normalize()\n\n    # Validate all URIReference components and ensure that all\n    # components that were set before are still set after\n    # normalization has completed.\n    validator = Validator()\n    try:\n        validator.check_validity_of(\n            *validator.COMPONENT_NAMES\n        ).validate(uri_ref)\n    except ValidationError:\n        six.raise_from(LocationParseError(url), None)\n\n    # For the sake of backwards compatibility we put empty\n    # string values for path if there are any defined values\n    # beyond the path in the URL.\n    # TODO: Remove this when we break backwards compatibility.\n    path = uri_ref.path\n    if not path:\n        if (uri_ref.query is not None\n                or uri_ref.fragment is not None):\n            path = \"\"\n        else:\n            path = None\n\n    # Ensure that each part of the URL is a `str` for\n    # backwards compatibility.\n    def to_input_type(x):\n        if x is None:\n            return None\n        elif not is_string and not isinstance(x, six.binary_type):\n            return x.encode('utf-8')\n        return x\n\n    return Url(\n        scheme=to_input_type(uri_ref.scheme),\n        auth=to_input_type(uri_ref.userinfo),\n        host=to_input_type(uri_ref.host),\n        port=int(uri_ref.port) if uri_ref.port is not None else None,\n        path=to_input_type(path),\n        query=to_input_type(uri_ref.query),\n        fragment=to_input_type(uri_ref.fragment)\n    )\n\n\ndef get_host(url):\n    \"\"\"\n    Deprecated. Use :func:`parse_url` instead.\n    \"\"\"\n    p = parse_url(url)\n    return p.scheme or 'http', p.hostname, p.port\n", "# coding: utf-8\nimport hashlib\nimport warnings\nimport logging\nimport io\nimport ssl\nimport socket\nfrom itertools import chain\n\nfrom mock import patch, Mock\nimport pytest\n\nfrom urllib3 import add_stderr_logger, disable_warnings\nfrom urllib3.util.request import make_headers, rewind_body, _FAILEDTELL\nfrom urllib3.util.response import assert_header_parsing\nfrom urllib3.util.retry import Retry\nfrom urllib3.util.timeout import Timeout\nfrom urllib3.util.url import (\n    get_host,\n    parse_url,\n    split_first,\n    Url,\n)\nfrom urllib3.util.ssl_ import (\n    resolve_cert_reqs,\n    resolve_ssl_version,\n    ssl_wrap_socket,\n    _const_compare_digest_backport,\n)\nfrom urllib3.exceptions import (\n    LocationParseError,\n    TimeoutStateError,\n    InsecureRequestWarning,\n    SNIMissingWarning,\n    InvalidHeader,\n    UnrewindableBodyError,\n)\nfrom urllib3.util.connection import (\n    allowed_gai_family,\n    _has_ipv6\n)\nfrom urllib3.util import is_fp_closed, ssl_\nfrom urllib3.packages import six\n\nfrom . import clear_warnings\n\nfrom test import onlyPy3, onlyPy2, onlyBrotlipy, notBrotlipy\n\n# This number represents a time in seconds, it doesn't mean anything in\n# isolation. Setting to a high-ish value to avoid conflicts with the smaller\n# numbers used for timeouts\nTIMEOUT_EPOCH = 1000\n\n\nclass TestUtil(object):\n\n    url_host_map = [\n        # Hosts\n        ('http://google.com/mail', ('http', 'google.com', None)),\n        ('http://google.com/mail/', ('http', 'google.com', None)),\n        ('google.com/mail', ('http', 'google.com', None)),\n        ('http://google.com/', ('http', 'google.com', None)),\n        ('http://google.com', ('http', 'google.com', None)),\n        ('http://www.google.com', ('http', 'www.google.com', None)),\n        ('http://mail.google.com', ('http', 'mail.google.com', None)),\n        ('http://google.com:8000/mail/', ('http', 'google.com', 8000)),\n        ('http://google.com:8000', ('http', 'google.com', 8000)),\n        ('https://google.com', ('https', 'google.com', None)),\n        ('https://google.com:8000', ('https', 'google.com', 8000)),\n        ('http://user:password@127.0.0.1:1234', ('http', '127.0.0.1', 1234)),\n        ('http://google.com/foo=http://bar:42/baz', ('http', 'google.com', None)),\n        ('http://google.com?foo=http://bar:42/baz', ('http', 'google.com', None)),\n        ('http://google.com#foo=http://bar:42/baz', ('http', 'google.com', None)),\n\n        # IPv4\n        ('173.194.35.7', ('http', '173.194.35.7', None)),\n        ('http://173.194.35.7', ('http', '173.194.35.7', None)),\n        ('http://173.194.35.7/test', ('http', '173.194.35.7', None)),\n        ('http://173.194.35.7:80', ('http', '173.194.35.7', 80)),\n        ('http://173.194.35.7:80/test', ('http', '173.194.35.7', 80)),\n\n        # IPv6\n        ('[2a00:1450:4001:c01::67]', ('http', '[2a00:1450:4001:c01::67]', None)),\n        ('http://[2a00:1450:4001:c01::67]', ('http', '[2a00:1450:4001:c01::67]', None)),\n        ('http://[2a00:1450:4001:c01::67]/test', ('http', '[2a00:1450:4001:c01::67]', None)),\n        ('http://[2a00:1450:4001:c01::67]:80', ('http', '[2a00:1450:4001:c01::67]', 80)),\n        ('http://[2a00:1450:4001:c01::67]:80/test', ('http', '[2a00:1450:4001:c01::67]', 80)),\n\n        # More IPv6 from http://www.ietf.org/rfc/rfc2732.txt\n        ('http://[fedc:ba98:7654:3210:fedc:ba98:7654:3210]:8000/index.html', (\n            'http', '[fedc:ba98:7654:3210:fedc:ba98:7654:3210]', 8000)),\n        ('http://[1080:0:0:0:8:800:200c:417a]/index.html', (\n            'http', '[1080:0:0:0:8:800:200c:417a]', None)),\n        ('http://[3ffe:2a00:100:7031::1]', ('http', '[3ffe:2a00:100:7031::1]', None)),\n        ('http://[1080::8:800:200c:417a]/foo', ('http', '[1080::8:800:200c:417a]', None)),\n        ('http://[::192.9.5.5]/ipng', ('http', '[::192.9.5.5]', None)),\n        ('http://[::ffff:129.144.52.38]:42/index.html', ('http', '[::ffff:129.144.52.38]', 42)),\n        ('http://[2010:836b:4179::836b:4179]', ('http', '[2010:836b:4179::836b:4179]', None)),\n\n        # Hosts\n        ('HTTP://GOOGLE.COM/mail/', ('http', 'google.com', None)),\n        ('GOogle.COM/mail', ('http', 'google.com', None)),\n        ('HTTP://GoOgLe.CoM:8000/mail/', ('http', 'google.com', 8000)),\n        ('HTTP://user:password@EXAMPLE.COM:1234', ('http', 'example.com', 1234)),\n        ('173.194.35.7', ('http', '173.194.35.7', None)),\n        ('HTTP://173.194.35.7', ('http', '173.194.35.7', None)),\n        ('HTTP://[2a00:1450:4001:c01::67]:80/test', ('http', '[2a00:1450:4001:c01::67]', 80)),\n        ('HTTP://[FEDC:BA98:7654:3210:FEDC:BA98:7654:3210]:8000/index.html', (\n            'http', '[fedc:ba98:7654:3210:fedc:ba98:7654:3210]', 8000)),\n        ('HTTPS://[1080:0:0:0:8:800:200c:417A]/index.html', (\n            'https', '[1080:0:0:0:8:800:200c:417a]', None)),\n        ('abOut://eXamPlE.com?info=1', ('about', 'eXamPlE.com', None)),\n        ('http+UNIX://%2fvar%2frun%2fSOCKET/path', (\n            'http+unix', '%2fvar%2frun%2fSOCKET', None)),\n    ]\n\n    @pytest.mark.parametrize('url, expected_host', url_host_map)\n    def test_get_host(self, url, expected_host):\n        returned_host = get_host(url)\n        assert returned_host == expected_host\n\n    # TODO: Add more tests\n    @pytest.mark.parametrize('location', [\n        'http://google.com:foo',\n        'http://::1/',\n        'http://::1:80/',\n        'http://google.com:-80',\n        six.u('http://google.com:\\xb2\\xb2'),  # \\xb2 = ^2\n    ])\n    def test_invalid_host(self, location):\n        with pytest.raises(LocationParseError):\n            get_host(location)\n\n    @pytest.mark.parametrize('url', [\n        'http://user\\\\@google.com',\n        'http://google\\\\.com',\n        'user\\\\@google.com',\n        'http://google.com#fragment#',\n        'http://user@user@google.com/',\n    ])\n    def test_invalid_url(self, url):\n        with pytest.raises(LocationParseError):\n            parse_url(url)\n\n    @pytest.mark.parametrize('url, expected_normalized_url', [\n        ('HTTP://GOOGLE.COM/MAIL/', 'http://google.com/MAIL/'),\n        ('HTTP://JeremyCline:Hunter2@Example.com:8080/',\n         'http://JeremyCline:Hunter2@example.com:8080/'),\n        ('HTTPS://Example.Com/?Key=Value', 'https://example.com/?Key=Value'),\n        ('Https://Example.Com/#Fragment', 'https://example.com/#Fragment'),\n        ('[::Ff%etH0%Ff]/%ab%Af', '[::ff%25etH0%Ff]/%AB%AF'),\n    ])\n    def test_parse_url_normalization(self, url, expected_normalized_url):\n        \"\"\"Assert parse_url normalizes the scheme/host, and only the scheme/host\"\"\"\n        actual_normalized_url = parse_url(url).url\n        assert actual_normalized_url == expected_normalized_url\n\n    parse_url_host_map = [\n        ('http://google.com/mail', Url('http', host='google.com', path='/mail')),\n        ('http://google.com/mail/', Url('http', host='google.com', path='/mail/')),\n        ('http://google.com/mail', Url('http', host='google.com', path='mail')),\n        ('google.com/mail', Url(host='google.com', path='/mail')),\n        ('http://google.com/', Url('http', host='google.com', path='/')),\n        ('http://google.com', Url('http', host='google.com')),\n        ('http://google.com?foo', Url('http', host='google.com', path='', query='foo')),\n\n        # Path/query/fragment\n        ('', Url()),\n        ('/', Url(path='/')),\n        ('#?/!google.com/?foo', Url(path='', fragment='?/!google.com/?foo')),\n        ('/foo', Url(path='/foo')),\n        ('/foo?bar=baz', Url(path='/foo', query='bar=baz')),\n        ('/foo?bar=baz#banana?apple/orange', Url(path='/foo',\n                                                 query='bar=baz',\n                                                 fragment='banana?apple/orange')),\n        ('/redirect?target=http://localhost:61020/', Url(path='redirect',\n                                                         query='target=http://localhost:61020/')),\n\n        # Port\n        ('http://google.com/', Url('http', host='google.com', path='/')),\n        ('http://google.com:80/', Url('http', host='google.com', port=80, path='/')),\n        ('http://google.com:80', Url('http', host='google.com', port=80)),\n\n        # Auth\n        ('http://foo:bar@localhost/', Url('http', auth='foo:bar', host='localhost', path='/')),\n        ('http://foo@localhost/', Url('http', auth='foo', host='localhost', path='/')),\n        ('http://foo:bar@localhost/', Url('http',\n                                          auth='foo:bar',\n                                          host='localhost',\n                                          path='/')),\n\n        # Unicode type (Python 2.x)\n        (u'http://foo:bar@localhost/', Url(u'http',\n                                           auth=u'foo:bar',\n                                           host=u'localhost',\n                                           path=u'/')),\n        ('http://foo:bar@localhost/', Url('http',\n                                          auth='foo:bar',\n                                          host='localhost',\n                                          path='/')),\n    ]\n\n    non_round_tripping_parse_url_host_map = [\n        # Path/query/fragment\n        ('?', Url(path='', query='')),\n        ('#', Url(path='', fragment='')),\n\n        # Path normalization\n        ('/abc/../def', Url(path=\"/def\")),\n\n        # Empty Port\n        ('http://google.com:', Url('http', host='google.com')),\n        ('http://google.com:/', Url('http', host='google.com', path='/')),\n\n        # Uppercase IRI\n        (u'http://K\u00f6nigsg\u00e4\u00dfchen.de/stra\u00dfe',\n         Url('http', host='xn--knigsgchen-b4a3dun.de', path='/stra%C3%9Fe'))\n    ]\n\n    @pytest.mark.parametrize(\n        'url, expected_url',\n        chain(parse_url_host_map, non_round_tripping_parse_url_host_map)\n    )\n    def test_parse_url(self, url, expected_url):\n        returned_url = parse_url(url)\n        assert returned_url == expected_url\n\n    @pytest.mark.parametrize('url, expected_url', parse_url_host_map)\n    def test_unparse_url(self, url, expected_url):\n        assert url == expected_url.url\n\n    @pytest.mark.parametrize(\n        ['url', 'expected_url'],\n        [\n            # RFC 3986 5.2.4\n            ('/abc/../def', Url(path=\"/def\")),\n            ('/..', Url(path=\"/\")),\n            ('/./abc/./def/', Url(path='/abc/def/')),\n            ('/.', Url(path='/')),\n            ('/./', Url(path='/')),\n            ('/abc/./.././d/././e/.././f/./../../ghi', Url(path='/ghi'))\n        ]\n    )\n    def test_parse_and_normalize_url_paths(self, url, expected_url):\n        actual_url = parse_url(url)\n        assert actual_url == expected_url\n        assert actual_url.url == expected_url.url\n\n    def test_parse_url_invalid_IPv6(self):\n        with pytest.raises(LocationParseError):\n            parse_url('[::1')\n\n    def test_parse_url_negative_port(self):\n        with pytest.raises(LocationParseError):\n            parse_url(\"https://www.google.com:-80/\")\n\n    def test_Url_str(self):\n        U = Url('http', host='google.com')\n        assert str(U) == U.url\n\n    request_uri_map = [\n        ('http://google.com/mail', '/mail'),\n        ('http://google.com/mail/', '/mail/'),\n        ('http://google.com/', '/'),\n        ('http://google.com', '/'),\n        ('', '/'),\n        ('/', '/'),\n        ('?', '/?'),\n        ('#', '/'),\n        ('/foo?bar=baz', '/foo?bar=baz'),\n    ]\n\n    @pytest.mark.parametrize('url, expected_request_uri', request_uri_map)\n    def test_request_uri(self, url, expected_request_uri):\n        returned_url = parse_url(url)\n        assert returned_url.request_uri == expected_request_uri\n\n    url_netloc_map = [\n        ('http://google.com/mail', 'google.com'),\n        ('http://google.com:80/mail', 'google.com:80'),\n        ('google.com/foobar', 'google.com'),\n        ('google.com:12345', 'google.com:12345'),\n    ]\n\n    @pytest.mark.parametrize('url, expected_netloc', url_netloc_map)\n    def test_netloc(self, url, expected_netloc):\n        assert parse_url(url).netloc == expected_netloc\n\n    url_vulnerabilities = [\n        # urlparse doesn't follow RFC 3986 Section 3.2\n        (\"http://google.com#@evil.com/\", Url(\"http\",\n                                             host=\"google.com\",\n                                             path=\"\",\n                                             fragment=\"@evil.com/\")),\n\n        # CVE-2016-5699\n        (\"http://127.0.0.1%0d%0aConnection%3a%20keep-alive\",\n         Url(\"http\", host=\"127.0.0.1%0d%0aconnection%3a%20keep-alive\")),\n\n        # NodeJS unicode -> double dot\n        (u\"http://google.com/\\uff2e\\uff2e/abc\", Url(\"http\",\n                                                    host=\"google.com\",\n                                                    path='/%EF%BC%AE%EF%BC%AE/abc')),\n\n        # Scheme without ://\n        (\"javascript:a='@google.com:12345/';alert(0)\",\n         Url(scheme=\"javascript\",\n             path=\"a='@google.com:12345/';alert(0)\")),\n\n        (\"//google.com/a/b/c\", Url(host=\"google.com\", path=\"/a/b/c\")),\n\n        # International URLs\n        (u'http://\u30d2:\u30ad@\u30d2.abc.\u30cb/\u30d2?\u30ad#\u30ef', Url(u'http',\n                                          host=u'xn--pdk.abc.xn--idk',\n                                          auth=u'%E3%83%92:%E3%82%AD',\n                                          path=u'/%E3%83%92',\n                                          query=u'%E3%82%AD',\n                                          fragment=u'%E3%83%AF')),\n\n        # Injected headers (CVE-2016-5699, CVE-2019-9740, CVE-2019-9947)\n        (\"10.251.0.83:7777?a=1 HTTP/1.1\\r\\nX-injected: header\",\n         Url(host='10.251.0.83', port=7777, path='',\n             query='a=1%20HTTP/1.1%0D%0AX-injected:%20header')),\n\n        (\"http://127.0.0.1:6379?\\r\\nSET test failure12\\r\\n:8080/test/?test=a\",\n         Url(scheme='http', host='127.0.0.1', port=6379, path='',\n             query='%0D%0ASET%20test%20failure12%0D%0A:8080/test/?test=a')),\n    ]\n\n    @pytest.mark.parametrize(\"url, expected_url\", url_vulnerabilities)\n    def test_url_vulnerabilities(self, url, expected_url):\n        if expected_url is False:\n            with pytest.raises(LocationParseError):\n                parse_url(url)\n        else:\n            assert parse_url(url) == expected_url\n\n    @onlyPy2\n    def test_parse_url_bytes_to_str_python_2(self):\n        url = parse_url(b\"https://www.google.com/\")\n        assert url == Url('https', host='www.google.com', path='/')\n\n        assert isinstance(url.scheme, str)\n        assert isinstance(url.host, str)\n        assert isinstance(url.path, str)\n\n    @onlyPy2\n    def test_parse_url_unicode_python_2(self):\n        url = parse_url(u\"https://www.google.com/\")\n        assert url == Url(u'https', host=u'www.google.com', path=u'/')\n\n        assert isinstance(url.scheme, six.text_type)\n        assert isinstance(url.host, six.text_type)\n        assert isinstance(url.path, six.text_type)\n\n    @onlyPy3\n    def test_parse_url_bytes_type_error_python_3(self):\n        with pytest.raises(TypeError):\n            parse_url(b\"https://www.google.com/\")\n\n    @pytest.mark.parametrize('kwargs, expected', [\n        pytest.param(\n            {'accept_encoding': True},\n            {'accept-encoding': 'gzip,deflate,br'},\n            marks=onlyBrotlipy(),\n        ),\n        pytest.param(\n            {'accept_encoding': True},\n            {'accept-encoding': 'gzip,deflate'},\n            marks=notBrotlipy(),\n        ),\n        ({'accept_encoding': 'foo,bar'},\n         {'accept-encoding': 'foo,bar'}),\n        ({'accept_encoding': ['foo', 'bar']},\n         {'accept-encoding': 'foo,bar'}),\n        pytest.param(\n            {'accept_encoding': True, 'user_agent': 'banana'},\n            {'accept-encoding': 'gzip,deflate,br', 'user-agent': 'banana'},\n            marks=onlyBrotlipy(),\n        ),\n        pytest.param(\n            {'accept_encoding': True, 'user_agent': 'banana'},\n            {'accept-encoding': 'gzip,deflate', 'user-agent': 'banana'},\n            marks=notBrotlipy(),\n        ),\n        ({'user_agent': 'banana'},\n         {'user-agent': 'banana'}),\n        ({'keep_alive': True},\n         {'connection': 'keep-alive'}),\n        ({'basic_auth': 'foo:bar'},\n         {'authorization': 'Basic Zm9vOmJhcg=='}),\n        ({'proxy_basic_auth': 'foo:bar'},\n         {'proxy-authorization': 'Basic Zm9vOmJhcg=='}),\n        ({'disable_cache': True},\n         {'cache-control': 'no-cache'}),\n    ])\n    def test_make_headers(self, kwargs, expected):\n        assert make_headers(**kwargs) == expected\n\n    def test_rewind_body(self):\n        body = io.BytesIO(b'test data')\n        assert body.read() == b'test data'\n\n        # Assert the file object has been consumed\n        assert body.read() == b''\n\n        # Rewind it back to just be b'data'\n        rewind_body(body, 5)\n        assert body.read() == b'data'\n\n    def test_rewind_body_failed_tell(self):\n        body = io.BytesIO(b'test data')\n        body.read()  # Consume body\n\n        # Simulate failed tell()\n        body_pos = _FAILEDTELL\n        with pytest.raises(UnrewindableBodyError):\n            rewind_body(body, body_pos)\n\n    def test_rewind_body_bad_position(self):\n        body = io.BytesIO(b'test data')\n        body.read()  # Consume body\n\n        # Pass non-integer position\n        with pytest.raises(ValueError):\n            rewind_body(body, body_pos=None)\n        with pytest.raises(ValueError):\n            rewind_body(body, body_pos=object())\n\n    def test_rewind_body_failed_seek(self):\n        class BadSeek():\n\n            def seek(self, pos, offset=0):\n                raise IOError\n\n        with pytest.raises(UnrewindableBodyError):\n            rewind_body(BadSeek(), body_pos=2)\n\n    @pytest.mark.parametrize('input, expected', [\n        (('abcd', 'b'),  ('a', 'cd', 'b')),\n        (('abcd', 'cb'), ('a', 'cd', 'b')),\n        (('abcd', ''),   ('abcd', '', None)),\n        (('abcd', 'a'),  ('', 'bcd', 'a')),\n        (('abcd', 'ab'), ('', 'bcd', 'a')),\n        (('abcd', 'eb'), ('a', 'cd', 'b')),\n    ])\n    def test_split_first(self, input, expected):\n        output = split_first(*input)\n        assert output == expected\n\n    def test_add_stderr_logger(self):\n        handler = add_stderr_logger(level=logging.INFO)  # Don't actually print debug\n        logger = logging.getLogger('urllib3')\n        assert handler in logger.handlers\n\n        logger.debug('Testing add_stderr_logger')\n        logger.removeHandler(handler)\n\n    def test_disable_warnings(self):\n        with warnings.catch_warnings(record=True) as w:\n            clear_warnings()\n            warnings.warn('This is a test.', InsecureRequestWarning)\n            assert len(w) == 1\n            disable_warnings()\n            warnings.warn('This is a test.', InsecureRequestWarning)\n            assert len(w) == 1\n\n    def _make_time_pass(self, seconds, timeout, time_mock):\n        \"\"\" Make some time pass for the timeout object \"\"\"\n        time_mock.return_value = TIMEOUT_EPOCH\n        timeout.start_connect()\n        time_mock.return_value = TIMEOUT_EPOCH + seconds\n        return timeout\n\n    @pytest.mark.parametrize('kwargs, message', [\n        ({'total': -1},                 'less than'),\n        ({'connect': 2, 'total': -1},   'less than'),\n        ({'read': -1},                  'less than'),\n        ({'connect': False},            'cannot be a boolean'),\n        ({'read': True},                'cannot be a boolean'),\n        ({'connect': 0},                'less than or equal'),\n        ({'read': 'foo'},               'int, float or None')\n    ])\n    def test_invalid_timeouts(self, kwargs, message):\n        with pytest.raises(ValueError) as e:\n            Timeout(**kwargs)\n        assert message in str(e.value)\n\n    @patch('urllib3.util.timeout.current_time')\n    def test_timeout(self, current_time):\n        timeout = Timeout(total=3)\n\n        # make 'no time' elapse\n        timeout = self._make_time_pass(seconds=0, timeout=timeout,\n                                       time_mock=current_time)\n        assert timeout.read_timeout == 3\n        assert timeout.connect_timeout == 3\n\n        timeout = Timeout(total=3, connect=2)\n        assert timeout.connect_timeout == 2\n\n        timeout = Timeout()\n        assert timeout.connect_timeout == Timeout.DEFAULT_TIMEOUT\n\n        # Connect takes 5 seconds, leaving 5 seconds for read\n        timeout = Timeout(total=10, read=7)\n        timeout = self._make_time_pass(seconds=5, timeout=timeout,\n                                       time_mock=current_time)\n        assert timeout.read_timeout == 5\n\n        # Connect takes 2 seconds, read timeout still 7 seconds\n        timeout = Timeout(total=10, read=7)\n        timeout = self._make_time_pass(seconds=2, timeout=timeout,\n                                       time_mock=current_time)\n        assert timeout.read_timeout == 7\n\n        timeout = Timeout(total=10, read=7)\n        assert timeout.read_timeout == 7\n\n        timeout = Timeout(total=None, read=None, connect=None)\n        assert timeout.connect_timeout is None\n        assert timeout.read_timeout is None\n        assert timeout.total is None\n\n        timeout = Timeout(5)\n        assert timeout.total == 5\n\n    def test_timeout_str(self):\n        timeout = Timeout(connect=1, read=2, total=3)\n        assert str(timeout) == \"Timeout(connect=1, read=2, total=3)\"\n        timeout = Timeout(connect=1, read=None, total=3)\n        assert str(timeout) == \"Timeout(connect=1, read=None, total=3)\"\n\n    @patch('urllib3.util.timeout.current_time')\n    def test_timeout_elapsed(self, current_time):\n        current_time.return_value = TIMEOUT_EPOCH\n        timeout = Timeout(total=3)\n        with pytest.raises(TimeoutStateError):\n            timeout.get_connect_duration()\n\n        timeout.start_connect()\n        with pytest.raises(TimeoutStateError):\n            timeout.start_connect()\n\n        current_time.return_value = TIMEOUT_EPOCH + 2\n        assert timeout.get_connect_duration() == 2\n        current_time.return_value = TIMEOUT_EPOCH + 37\n        assert timeout.get_connect_duration() == 37\n\n    @pytest.mark.parametrize('candidate, requirements', [\n        (None, ssl.CERT_REQUIRED),\n        (ssl.CERT_NONE, ssl.CERT_NONE),\n        (ssl.CERT_REQUIRED, ssl.CERT_REQUIRED),\n        ('REQUIRED', ssl.CERT_REQUIRED),\n        ('CERT_REQUIRED', ssl.CERT_REQUIRED),\n    ])\n    def test_resolve_cert_reqs(self, candidate, requirements):\n        assert resolve_cert_reqs(candidate) == requirements\n\n    @pytest.mark.parametrize('candidate, version', [\n        (ssl.PROTOCOL_TLSv1, ssl.PROTOCOL_TLSv1),\n        (\"PROTOCOL_TLSv1\", ssl.PROTOCOL_TLSv1),\n        (\"TLSv1\", ssl.PROTOCOL_TLSv1),\n        (ssl.PROTOCOL_SSLv23, ssl.PROTOCOL_SSLv23),\n    ])\n    def test_resolve_ssl_version(self, candidate, version):\n        assert resolve_ssl_version(candidate) == version\n\n    def test_is_fp_closed_object_supports_closed(self):\n        class ClosedFile(object):\n            @property\n            def closed(self):\n                return True\n\n        assert is_fp_closed(ClosedFile())\n\n    def test_is_fp_closed_object_has_none_fp(self):\n        class NoneFpFile(object):\n            @property\n            def fp(self):\n                return None\n\n        assert is_fp_closed(NoneFpFile())\n\n    def test_is_fp_closed_object_has_fp(self):\n        class FpFile(object):\n            @property\n            def fp(self):\n                return True\n\n        assert not is_fp_closed(FpFile())\n\n    def test_is_fp_closed_object_has_neither_fp_nor_closed(self):\n        class NotReallyAFile(object):\n            pass\n\n        with pytest.raises(ValueError):\n            is_fp_closed(NotReallyAFile())\n\n    def test_ssl_wrap_socket_loads_the_cert_chain(self):\n        socket = object()\n        mock_context = Mock()\n        ssl_wrap_socket(ssl_context=mock_context, sock=socket,\n                        certfile='/path/to/certfile')\n\n        mock_context.load_cert_chain.assert_called_once_with(\n            '/path/to/certfile', None\n        )\n\n    @patch('urllib3.util.ssl_.create_urllib3_context')\n    def test_ssl_wrap_socket_creates_new_context(self,\n                                                 create_urllib3_context):\n        socket = object()\n        ssl_wrap_socket(sock=socket, cert_reqs='CERT_REQUIRED')\n\n        create_urllib3_context.assert_called_once_with(\n            None, 'CERT_REQUIRED', ciphers=None\n        )\n\n    def test_ssl_wrap_socket_loads_verify_locations(self):\n        socket = object()\n        mock_context = Mock()\n        ssl_wrap_socket(ssl_context=mock_context, ca_certs='/path/to/pem',\n                        sock=socket)\n        mock_context.load_verify_locations.assert_called_once_with(\n            '/path/to/pem', None\n        )\n\n    def test_ssl_wrap_socket_loads_certificate_directories(self):\n        socket = object()\n        mock_context = Mock()\n        ssl_wrap_socket(ssl_context=mock_context, ca_cert_dir='/path/to/pems',\n                        sock=socket)\n        mock_context.load_verify_locations.assert_called_once_with(\n            None, '/path/to/pems'\n        )\n\n    def test_ssl_wrap_socket_with_no_sni_warns(self):\n        socket = object()\n        mock_context = Mock()\n        # Ugly preservation of original value\n        HAS_SNI = ssl_.HAS_SNI\n        ssl_.HAS_SNI = False\n        try:\n            with patch('warnings.warn') as warn:\n                ssl_wrap_socket(ssl_context=mock_context, sock=socket,\n                                server_hostname='www.google.com')\n            mock_context.wrap_socket.assert_called_once_with(socket)\n            assert warn.call_count >= 1\n            warnings = [call[0][1] for call in warn.call_args_list]\n            assert SNIMissingWarning in warnings\n        finally:\n            ssl_.HAS_SNI = HAS_SNI\n\n    def test_const_compare_digest_fallback(self):\n        target = hashlib.sha256(b'abcdef').digest()\n        assert _const_compare_digest_backport(target, target)\n\n        prefix = target[:-1]\n        assert not _const_compare_digest_backport(target, prefix)\n\n        suffix = target + b'0'\n        assert not _const_compare_digest_backport(target, suffix)\n\n        incorrect = hashlib.sha256(b'xyz').digest()\n        assert not _const_compare_digest_backport(target, incorrect)\n\n    def test_has_ipv6_disabled_on_compile(self):\n        with patch('socket.has_ipv6', False):\n            assert not _has_ipv6('::1')\n\n    def test_has_ipv6_enabled_but_fails(self):\n        with patch('socket.has_ipv6', True):\n            with patch('socket.socket') as mock:\n                instance = mock.return_value\n                instance.bind = Mock(side_effect=Exception('No IPv6 here!'))\n                assert not _has_ipv6('::1')\n\n    def test_has_ipv6_enabled_and_working(self):\n        with patch('socket.has_ipv6', True):\n            with patch('socket.socket') as mock:\n                instance = mock.return_value\n                instance.bind.return_value = True\n                assert _has_ipv6('::1')\n\n    def test_has_ipv6_disabled_on_appengine(self):\n        gae_patch = patch(\n            'urllib3.contrib._appengine_environ.is_appengine_sandbox',\n            return_value=True)\n        with gae_patch:\n            assert not _has_ipv6('::1')\n\n    def test_ip_family_ipv6_enabled(self):\n        with patch('urllib3.util.connection.HAS_IPV6', True):\n            assert allowed_gai_family() == socket.AF_UNSPEC\n\n    def test_ip_family_ipv6_disabled(self):\n        with patch('urllib3.util.connection.HAS_IPV6', False):\n            assert allowed_gai_family() == socket.AF_INET\n\n    @pytest.mark.parametrize('value', [\n        \"-1\",\n        \"+1\",\n        \"1.0\",\n        six.u(\"\\xb2\"),  # \\xb2 = ^2\n    ])\n    def test_parse_retry_after_invalid(self, value):\n        retry = Retry()\n        with pytest.raises(InvalidHeader):\n            retry.parse_retry_after(value)\n\n    @pytest.mark.parametrize('value, expected', [\n        (\"0\", 0),\n        (\"1000\", 1000),\n        (\"\\t42 \", 42),\n    ])\n    def test_parse_retry_after(self, value, expected):\n        retry = Retry()\n        assert retry.parse_retry_after(value) == expected\n\n    @pytest.mark.parametrize('headers', [\n        b'foo',\n        None,\n        object,\n    ])\n    def test_assert_header_parsing_throws_typeerror_with_non_headers(self, headers):\n        with pytest.raises(TypeError):\n            assert_header_parsing(headers)\n"], "fixing_code": ["Changes\n=======\n\ndev (master)\n------------\n\n* Change ``is_ipaddress`` to not detect IPvFuture addresses. (Pull #1583)\n\n* Change ``parse_url`` to percent-encode invalid characters within the\n  path, query, and target components. (Pull #1586)\n\n\n1.25.1 (2019-04-24)\n-------------------\n\n* Add support for Google's ``Brotli`` package. (Pull #1572, Pull #1579)\n\n* Upgrade bundled rfc3986 to v1.3.1 (Pull #1578)\n\n\n1.25 (2019-04-22)\n-----------------\n\n* Require and validate certificates by default when using HTTPS (Pull #1507)\n\n* Upgraded ``urllib3.utils.parse_url()`` to be RFC 3986 compliant. (Pull #1487)\n\n* Added support for ``key_password`` for ``HTTPSConnectionPool`` to use\n  encrypted ``key_file`` without creating your own ``SSLContext`` object. (Pull #1489)\n\n* Add TLSv1.3 support to CPython, pyOpenSSL, and SecureTransport ``SSLContext``\n  implementations. (Pull #1496)\n\n* Switched the default multipart header encoder from RFC 2231 to HTML 5 working draft. (Issue #303, PR #1492)\n\n* Fixed issue where OpenSSL would block if an encrypted client private key was\n  given and no password was given. Instead an ``SSLError`` is raised. (Pull #1489)\n\n* Added support for Brotli content encoding. It is enabled automatically if\n  ``brotlipy`` package is installed which can be requested with\n  ``urllib3[brotli]`` extra. (Pull #1532)\n\n* Drop ciphers using DSS key exchange from default TLS cipher suites.\n  Improve default ciphers when using SecureTransport. (Pull #1496)\n\n* Implemented a more efficient ``HTTPResponse.__iter__()`` method. (Issue #1483)\n\n\n1.24.2 (2019-04-17)\n-------------------\n\n* Don't load system certificates by default when any other ``ca_certs``, ``ca_certs_dir`` or\n  ``ssl_context`` parameters are specified.\n\n* Remove Authorization header regardless of case when redirecting to cross-site. (Issue #1510)\n\n* Add support for IPv6 addresses in subjectAltName section of certificates. (Issue #1269)\n\n\n1.24.1 (2018-11-02)\n-------------------\n\n* Remove quadratic behavior within ``GzipDecoder.decompress()`` (Issue #1467)\n\n* Restored functionality of ``ciphers`` parameter for ``create_urllib3_context()``. (Issue #1462)\n\n\n1.24 (2018-10-16)\n-----------------\n\n* Allow key_server_hostname to be specified when initializing a PoolManager to allow custom SNI to be overridden. (Pull #1449)\n\n* Test against Python 3.7 on AppVeyor. (Pull #1453)\n\n* Early-out ipv6 checks when running on App Engine. (Pull #1450)\n\n* Change ambiguous description of backoff_factor (Pull #1436)\n\n* Add ability to handle multiple Content-Encodings (Issue #1441 and Pull #1442)\n\n* Skip DNS names that can't be idna-decoded when using pyOpenSSL (Issue #1405).\n\n* Add a server_hostname parameter to HTTPSConnection which allows for\n  overriding the SNI hostname sent in the handshake. (Pull #1397)\n\n* Drop support for EOL Python 2.6 (Pull #1429 and Pull #1430)\n\n* Fixed bug where responses with header Content-Type: message/* erroneously\n  raised HeaderParsingError, resulting in a warning being logged. (Pull #1439)\n\n* Move urllib3 to src/urllib3 (Pull #1409)\n\n\n1.23 (2018-06-04)\n-----------------\n\n* Allow providing a list of headers to strip from requests when redirecting\n  to a different host. Defaults to the ``Authorization`` header. Different\n  headers can be set via ``Retry.remove_headers_on_redirect``. (Issue #1316)\n\n* Fix ``util.selectors._fileobj_to_fd`` to accept ``long`` (Issue #1247).\n\n* Dropped Python 3.3 support. (Pull #1242)\n\n* Put the connection back in the pool when calling stream() or read_chunked() on\n  a chunked HEAD response. (Issue #1234)\n\n* Fixed pyOpenSSL-specific ssl client authentication issue when clients\n  attempted to auth via certificate + chain (Issue #1060)\n\n* Add the port to the connectionpool connect print (Pull #1251)\n\n* Don't use the ``uuid`` module to create multipart data boundaries. (Pull #1380)\n\n* ``read_chunked()`` on a closed response returns no chunks. (Issue #1088)\n\n* Add Python 2.6 support to ``contrib.securetransport`` (Pull #1359)\n\n* Added support for auth info in url for SOCKS proxy (Pull #1363)\n\n\n1.22 (2017-07-20)\n-----------------\n\n* Fixed missing brackets in ``HTTP CONNECT`` when connecting to IPv6 address via\n  IPv6 proxy. (Issue #1222)\n\n* Made the connection pool retry on ``SSLError``.  The original ``SSLError``\n  is available on ``MaxRetryError.reason``. (Issue #1112)\n\n* Drain and release connection before recursing on retry/redirect.  Fixes\n  deadlocks with a blocking connectionpool. (Issue #1167)\n\n* Fixed compatibility for cookiejar. (Issue #1229)\n\n* pyopenssl: Use vendored version of ``six``. (Issue #1231)\n\n\n1.21.1 (2017-05-02)\n-------------------\n\n* Fixed SecureTransport issue that would cause long delays in response body\n  delivery. (Pull #1154)\n\n* Fixed regression in 1.21 that threw exceptions when users passed the\n  ``socket_options`` flag to the ``PoolManager``.  (Issue #1165)\n\n* Fixed regression in 1.21 that threw exceptions when users passed the\n  ``assert_hostname`` or ``assert_fingerprint`` flag to the ``PoolManager``.\n  (Pull #1157)\n\n\n1.21 (2017-04-25)\n-----------------\n\n* Improved performance of certain selector system calls on Python 3.5 and\n  later. (Pull #1095)\n\n* Resolved issue where the PyOpenSSL backend would not wrap SysCallError\n  exceptions appropriately when sending data. (Pull #1125)\n\n* Selectors now detects a monkey-patched select module after import for modules\n  that patch the select module like eventlet, greenlet. (Pull #1128)\n\n* Reduced memory consumption when streaming zlib-compressed responses\n  (as opposed to raw deflate streams). (Pull #1129)\n\n* Connection pools now use the entire request context when constructing the\n  pool key. (Pull #1016)\n\n* ``PoolManager.connection_from_*`` methods now accept a new keyword argument,\n  ``pool_kwargs``, which are merged with the existing ``connection_pool_kw``.\n  (Pull #1016)\n\n* Add retry counter for ``status_forcelist``. (Issue #1147)\n\n* Added ``contrib`` module for using SecureTransport on macOS:\n  ``urllib3.contrib.securetransport``.  (Pull #1122)\n\n* urllib3 now only normalizes the case of ``http://`` and ``https://`` schemes:\n  for schemes it does not recognise, it assumes they are case-sensitive and\n  leaves them unchanged.\n  (Issue #1080)\n\n\n1.20 (2017-01-19)\n-----------------\n\n* Added support for waiting for I/O using selectors other than select,\n  improving urllib3's behaviour with large numbers of concurrent connections.\n  (Pull #1001)\n\n* Updated the date for the system clock check. (Issue #1005)\n\n* ConnectionPools now correctly consider hostnames to be case-insensitive.\n  (Issue #1032)\n\n* Outdated versions of PyOpenSSL now cause the PyOpenSSL contrib module\n  to fail when it is injected, rather than at first use. (Pull #1063)\n\n* Outdated versions of cryptography now cause the PyOpenSSL contrib module\n  to fail when it is injected, rather than at first use. (Issue #1044)\n\n* Automatically attempt to rewind a file-like body object when a request is\n  retried or redirected. (Pull #1039)\n\n* Fix some bugs that occur when modules incautiously patch the queue module.\n  (Pull #1061)\n\n* Prevent retries from occurring on read timeouts for which the request method\n  was not in the method whitelist. (Issue #1059)\n\n* Changed the PyOpenSSL contrib module to lazily load idna to avoid\n  unnecessarily bloating the memory of programs that don't need it. (Pull\n  #1076)\n\n* Add support for IPv6 literals with zone identifiers. (Pull #1013)\n\n* Added support for socks5h:// and socks4a:// schemes when working with SOCKS\n  proxies, and controlled remote DNS appropriately. (Issue #1035)\n\n\n1.19.1 (2016-11-16)\n-------------------\n\n* Fixed AppEngine import that didn't function on Python 3.5. (Pull #1025)\n\n\n1.19 (2016-11-03)\n-----------------\n\n* urllib3 now respects Retry-After headers on 413, 429, and 503 responses when\n  using the default retry logic. (Pull #955)\n\n* Remove markers from setup.py to assist ancient setuptools versions. (Issue\n  #986)\n\n* Disallow superscripts and other integerish things in URL ports. (Issue #989)\n\n* Allow urllib3's HTTPResponse.stream() method to continue to work with\n  non-httplib underlying FPs. (Pull #990)\n\n* Empty filenames in multipart headers are now emitted as such, rather than\n  being suppressed. (Issue #1015)\n\n* Prefer user-supplied Host headers on chunked uploads. (Issue #1009)\n\n\n1.18.1 (2016-10-27)\n-------------------\n\n* CVE-2016-9015. Users who are using urllib3 version 1.17 or 1.18 along with\n  PyOpenSSL injection and OpenSSL 1.1.0 *must* upgrade to this version. This\n  release fixes a vulnerability whereby urllib3 in the above configuration\n  would silently fail to validate TLS certificates due to erroneously setting\n  invalid flags in OpenSSL's ``SSL_CTX_set_verify`` function. These erroneous\n  flags do not cause a problem in OpenSSL versions before 1.1.0, which\n  interprets the presence of any flag as requesting certificate validation.\n\n  There is no PR for this patch, as it was prepared for simultaneous disclosure\n  and release. The master branch received the same fix in PR #1010.\n\n\n1.18 (2016-09-26)\n-----------------\n\n* Fixed incorrect message for IncompleteRead exception. (PR #973)\n\n* Accept ``iPAddress`` subject alternative name fields in TLS certificates.\n  (Issue #258)\n\n* Fixed consistency of ``HTTPResponse.closed`` between Python 2 and 3.\n  (Issue #977)\n\n* Fixed handling of wildcard certificates when using PyOpenSSL. (Issue #979)\n\n\n1.17 (2016-09-06)\n-----------------\n\n* Accept ``SSLContext`` objects for use in SSL/TLS negotiation. (Issue #835)\n\n* ConnectionPool debug log now includes scheme, host, and port. (Issue #897)\n\n* Substantially refactored documentation. (Issue #887)\n\n* Used URLFetch default timeout on AppEngine, rather than hardcoding our own.\n  (Issue #858)\n\n* Normalize the scheme and host in the URL parser (Issue #833)\n\n* ``HTTPResponse`` contains the last ``Retry`` object, which now also\n  contains retries history. (Issue #848)\n\n* Timeout can no longer be set as boolean, and must be greater than zero.\n  (PR #924)\n\n* Removed pyasn1 and ndg-httpsclient from dependencies used for PyOpenSSL. We\n  now use cryptography and idna, both of which are already dependencies of\n  PyOpenSSL. (PR #930)\n\n* Fixed infinite loop in ``stream`` when amt=None. (Issue #928)\n\n* Try to use the operating system's certificates when we are using an\n  ``SSLContext``. (PR #941)\n\n* Updated cipher suite list to allow ChaCha20+Poly1305. AES-GCM is preferred to\n  ChaCha20, but ChaCha20 is then preferred to everything else. (PR #947)\n\n* Updated cipher suite list to remove 3DES-based cipher suites. (PR #958)\n\n* Removed the cipher suite fallback to allow HIGH ciphers. (PR #958)\n\n* Implemented ``length_remaining`` to determine remaining content\n  to be read. (PR #949)\n\n* Implemented ``enforce_content_length`` to enable exceptions when\n  incomplete data chunks are received. (PR #949)\n\n* Dropped connection start, dropped connection reset, redirect, forced retry,\n  and new HTTPS connection log levels to DEBUG, from INFO. (PR #967)\n\n\n1.16 (2016-06-11)\n-----------------\n\n* Disable IPv6 DNS when IPv6 connections are not possible. (Issue #840)\n\n* Provide ``key_fn_by_scheme`` pool keying mechanism that can be\n  overridden. (Issue #830)\n\n* Normalize scheme and host to lowercase for pool keys, and include\n  ``source_address``. (Issue #830)\n\n* Cleaner exception chain in Python 3 for ``_make_request``.\n  (Issue #861)\n\n* Fixed installing ``urllib3[socks]`` extra. (Issue #864)\n\n* Fixed signature of ``ConnectionPool.close`` so it can actually safely be\n  called by subclasses. (Issue #873)\n\n* Retain ``release_conn`` state across retries. (Issues #651, #866)\n\n* Add customizable ``HTTPConnectionPool.ResponseCls``, which defaults to\n  ``HTTPResponse`` but can be replaced with a subclass. (Issue #879)\n\n\n1.15.1 (2016-04-11)\n-------------------\n\n* Fix packaging to include backports module. (Issue #841)\n\n\n1.15 (2016-04-06)\n-----------------\n\n* Added Retry(raise_on_status=False). (Issue #720)\n\n* Always use setuptools, no more distutils fallback. (Issue #785)\n\n* Dropped support for Python 3.2. (Issue #786)\n\n* Chunked transfer encoding when requesting with ``chunked=True``.\n  (Issue #790)\n\n* Fixed regression with IPv6 port parsing. (Issue #801)\n\n* Append SNIMissingWarning messages to allow users to specify it in\n  the PYTHONWARNINGS environment variable. (Issue #816)\n\n* Handle unicode headers in Py2. (Issue #818)\n\n* Log certificate when there is a hostname mismatch. (Issue #820)\n\n* Preserve order of request/response headers. (Issue #821)\n\n\n1.14 (2015-12-29)\n-----------------\n\n* contrib: SOCKS proxy support! (Issue #762)\n\n* Fixed AppEngine handling of transfer-encoding header and bug\n  in Timeout defaults checking. (Issue #763)\n\n\n1.13.1 (2015-12-18)\n-------------------\n\n* Fixed regression in IPv6 + SSL for match_hostname. (Issue #761)\n\n\n1.13 (2015-12-14)\n-----------------\n\n* Fixed ``pip install urllib3[secure]`` on modern pip. (Issue #706)\n\n* pyopenssl: Fixed SSL3_WRITE_PENDING error. (Issue #717)\n\n* pyopenssl: Support for TLSv1.1 and TLSv1.2. (Issue #696)\n\n* Close connections more defensively on exception. (Issue #734)\n\n* Adjusted ``read_chunked`` to handle gzipped, chunk-encoded bodies without\n  repeatedly flushing the decoder, to function better on Jython. (Issue #743)\n\n* Accept ``ca_cert_dir`` for SSL-related PoolManager configuration. (Issue #758)\n\n\n1.12 (2015-09-03)\n-----------------\n\n* Rely on ``six`` for importing ``httplib`` to work around\n  conflicts with other Python 3 shims. (Issue #688)\n\n* Add support for directories of certificate authorities, as supported by\n  OpenSSL. (Issue #701)\n\n* New exception: ``NewConnectionError``, raised when we fail to establish\n  a new connection, usually ``ECONNREFUSED`` socket error.\n\n\n1.11 (2015-07-21)\n-----------------\n\n* When ``ca_certs`` is given, ``cert_reqs`` defaults to\n  ``'CERT_REQUIRED'``. (Issue #650)\n\n* ``pip install urllib3[secure]`` will install Certifi and\n  PyOpenSSL as dependencies. (Issue #678)\n\n* Made ``HTTPHeaderDict`` usable as a ``headers`` input value\n  (Issues #632, #679)\n\n* Added `urllib3.contrib.appengine <https://urllib3.readthedocs.io/en/latest/contrib.html#google-app-engine>`_\n  which has an ``AppEngineManager`` for using ``URLFetch`` in a\n  Google AppEngine environment. (Issue #664)\n\n* Dev: Added test suite for AppEngine. (Issue #631)\n\n* Fix performance regression when using PyOpenSSL. (Issue #626)\n\n* Passing incorrect scheme (e.g. ``foo://``) will raise\n  ``ValueError`` instead of ``AssertionError`` (backwards\n  compatible for now, but please migrate). (Issue #640)\n\n* Fix pools not getting replenished when an error occurs during a\n  request using ``release_conn=False``. (Issue #644)\n\n* Fix pool-default headers not applying for url-encoded requests\n  like GET. (Issue #657)\n\n* log.warning in Python 3 when headers are skipped due to parsing\n  errors. (Issue #642)\n\n* Close and discard connections if an error occurs during read.\n  (Issue #660)\n\n* Fix host parsing for IPv6 proxies. (Issue #668)\n\n* Separate warning type SubjectAltNameWarning, now issued once\n  per host. (Issue #671)\n\n* Fix ``httplib.IncompleteRead`` not getting converted to\n  ``ProtocolError`` when using ``HTTPResponse.stream()``\n  (Issue #674)\n\n1.10.4 (2015-05-03)\n-------------------\n\n* Migrate tests to Tornado 4. (Issue #594)\n\n* Append default warning configuration rather than overwrite.\n  (Issue #603)\n\n* Fix streaming decoding regression. (Issue #595)\n\n* Fix chunked requests losing state across keep-alive connections.\n  (Issue #599)\n\n* Fix hanging when chunked HEAD response has no body. (Issue #605)\n\n\n1.10.3 (2015-04-21)\n-------------------\n\n* Emit ``InsecurePlatformWarning`` when SSLContext object is missing.\n  (Issue #558)\n\n* Fix regression of duplicate header keys being discarded.\n  (Issue #563)\n\n* ``Response.stream()`` returns a generator for chunked responses.\n  (Issue #560)\n\n* Set upper-bound timeout when waiting for a socket in PyOpenSSL.\n  (Issue #585)\n\n* Work on platforms without `ssl` module for plain HTTP requests.\n  (Issue #587)\n\n* Stop relying on the stdlib's default cipher list. (Issue #588)\n\n\n1.10.2 (2015-02-25)\n-------------------\n\n* Fix file descriptor leakage on retries. (Issue #548)\n\n* Removed RC4 from default cipher list. (Issue #551)\n\n* Header performance improvements. (Issue #544)\n\n* Fix PoolManager not obeying redirect retry settings. (Issue #553)\n\n\n1.10.1 (2015-02-10)\n-------------------\n\n* Pools can be used as context managers. (Issue #545)\n\n* Don't re-use connections which experienced an SSLError. (Issue #529)\n\n* Don't fail when gzip decoding an empty stream. (Issue #535)\n\n* Add sha256 support for fingerprint verification. (Issue #540)\n\n* Fixed handling of header values containing commas. (Issue #533)\n\n\n1.10 (2014-12-14)\n-----------------\n\n* Disabled SSLv3. (Issue #473)\n\n* Add ``Url.url`` property to return the composed url string. (Issue #394)\n\n* Fixed PyOpenSSL + gevent ``WantWriteError``. (Issue #412)\n\n* ``MaxRetryError.reason`` will always be an exception, not string.\n  (Issue #481)\n\n* Fixed SSL-related timeouts not being detected as timeouts. (Issue #492)\n\n* Py3: Use ``ssl.create_default_context()`` when available. (Issue #473)\n\n* Emit ``InsecureRequestWarning`` for *every* insecure HTTPS request.\n  (Issue #496)\n\n* Emit ``SecurityWarning`` when certificate has no ``subjectAltName``.\n  (Issue #499)\n\n* Close and discard sockets which experienced SSL-related errors.\n  (Issue #501)\n\n* Handle ``body`` param in ``.request(...)``. (Issue #513)\n\n* Respect timeout with HTTPS proxy. (Issue #505)\n\n* PyOpenSSL: Handle ZeroReturnError exception. (Issue #520)\n\n\n1.9.1 (2014-09-13)\n------------------\n\n* Apply socket arguments before binding. (Issue #427)\n\n* More careful checks if fp-like object is closed. (Issue #435)\n\n* Fixed packaging issues of some development-related files not\n  getting included. (Issue #440)\n\n* Allow performing *only* fingerprint verification. (Issue #444)\n\n* Emit ``SecurityWarning`` if system clock is waaay off. (Issue #445)\n\n* Fixed PyOpenSSL compatibility with PyPy. (Issue #450)\n\n* Fixed ``BrokenPipeError`` and ``ConnectionError`` handling in Py3.\n  (Issue #443)\n\n\n\n1.9 (2014-07-04)\n----------------\n\n* Shuffled around development-related files. If you're maintaining a distro\n  package of urllib3, you may need to tweak things. (Issue #415)\n\n* Unverified HTTPS requests will trigger a warning on the first request. See\n  our new `security documentation\n  <https://urllib3.readthedocs.io/en/latest/security.html>`_ for details.\n  (Issue #426)\n\n* New retry logic and ``urllib3.util.retry.Retry`` configuration object.\n  (Issue #326)\n\n* All raised exceptions should now wrapped in a\n  ``urllib3.exceptions.HTTPException``-extending exception. (Issue #326)\n\n* All errors during a retry-enabled request should be wrapped in\n  ``urllib3.exceptions.MaxRetryError``, including timeout-related exceptions\n  which were previously exempt. Underlying error is accessible from the\n  ``.reason`` property. (Issue #326)\n\n* ``urllib3.exceptions.ConnectionError`` renamed to\n  ``urllib3.exceptions.ProtocolError``. (Issue #326)\n\n* Errors during response read (such as IncompleteRead) are now wrapped in\n  ``urllib3.exceptions.ProtocolError``. (Issue #418)\n\n* Requesting an empty host will raise ``urllib3.exceptions.LocationValueError``.\n  (Issue #417)\n\n* Catch read timeouts over SSL connections as\n  ``urllib3.exceptions.ReadTimeoutError``. (Issue #419)\n\n* Apply socket arguments before connecting. (Issue #427)\n\n\n1.8.3 (2014-06-23)\n------------------\n\n* Fix TLS verification when using a proxy in Python 3.4.1. (Issue #385)\n\n* Add ``disable_cache`` option to ``urllib3.util.make_headers``. (Issue #393)\n\n* Wrap ``socket.timeout`` exception with\n  ``urllib3.exceptions.ReadTimeoutError``. (Issue #399)\n\n* Fixed proxy-related bug where connections were being reused incorrectly.\n  (Issues #366, #369)\n\n* Added ``socket_options`` keyword parameter which allows to define\n  ``setsockopt`` configuration of new sockets. (Issue #397)\n\n* Removed ``HTTPConnection.tcp_nodelay`` in favor of\n  ``HTTPConnection.default_socket_options``. (Issue #397)\n\n* Fixed ``TypeError`` bug in Python 2.6.4. (Issue #411)\n\n\n1.8.2 (2014-04-17)\n------------------\n\n* Fix ``urllib3.util`` not being included in the package.\n\n\n1.8.1 (2014-04-17)\n------------------\n\n* Fix AppEngine bug of HTTPS requests going out as HTTP. (Issue #356)\n\n* Don't install ``dummyserver`` into ``site-packages`` as it's only needed\n  for the test suite. (Issue #362)\n\n* Added support for specifying ``source_address``. (Issue #352)\n\n\n1.8 (2014-03-04)\n----------------\n\n* Improved url parsing in ``urllib3.util.parse_url`` (properly parse '@' in\n  username, and blank ports like 'hostname:').\n\n* New ``urllib3.connection`` module which contains all the HTTPConnection\n  objects.\n\n* Several ``urllib3.util.Timeout``-related fixes. Also changed constructor\n  signature to a more sensible order. [Backwards incompatible]\n  (Issues #252, #262, #263)\n\n* Use ``backports.ssl_match_hostname`` if it's installed. (Issue #274)\n\n* Added ``.tell()`` method to ``urllib3.response.HTTPResponse`` which\n  returns the number of bytes read so far. (Issue #277)\n\n* Support for platforms without threading. (Issue #289)\n\n* Expand default-port comparison in ``HTTPConnectionPool.is_same_host``\n  to allow a pool with no specified port to be considered equal to to an\n  HTTP/HTTPS url with port 80/443 explicitly provided. (Issue #305)\n\n* Improved default SSL/TLS settings to avoid vulnerabilities.\n  (Issue #309)\n\n* Fixed ``urllib3.poolmanager.ProxyManager`` not retrying on connect errors.\n  (Issue #310)\n\n* Disable Nagle's Algorithm on the socket for non-proxies. A subset of requests\n  will send the entire HTTP request ~200 milliseconds faster; however, some of\n  the resulting TCP packets will be smaller. (Issue #254)\n\n* Increased maximum number of SubjectAltNames in ``urllib3.contrib.pyopenssl``\n  from the default 64 to 1024 in a single certificate. (Issue #318)\n\n* Headers are now passed and stored as a custom\n  ``urllib3.collections_.HTTPHeaderDict`` object rather than a plain ``dict``.\n  (Issue #329, #333)\n\n* Headers no longer lose their case on Python 3. (Issue #236)\n\n* ``urllib3.contrib.pyopenssl`` now uses the operating system's default CA\n  certificates on inject. (Issue #332)\n\n* Requests with ``retries=False`` will immediately raise any exceptions without\n  wrapping them in ``MaxRetryError``. (Issue #348)\n\n* Fixed open socket leak with SSL-related failures. (Issue #344, #348)\n\n\n1.7.1 (2013-09-25)\n------------------\n\n* Added granular timeout support with new ``urllib3.util.Timeout`` class.\n  (Issue #231)\n\n* Fixed Python 3.4 support. (Issue #238)\n\n\n1.7 (2013-08-14)\n----------------\n\n* More exceptions are now pickle-able, with tests. (Issue #174)\n\n* Fixed redirecting with relative URLs in Location header. (Issue #178)\n\n* Support for relative urls in ``Location: ...`` header. (Issue #179)\n\n* ``urllib3.response.HTTPResponse`` now inherits from ``io.IOBase`` for bonus\n  file-like functionality. (Issue #187)\n\n* Passing ``assert_hostname=False`` when creating a HTTPSConnectionPool will\n  skip hostname verification for SSL connections. (Issue #194)\n\n* New method ``urllib3.response.HTTPResponse.stream(...)`` which acts as a\n  generator wrapped around ``.read(...)``. (Issue #198)\n\n* IPv6 url parsing enforces brackets around the hostname. (Issue #199)\n\n* Fixed thread race condition in\n  ``urllib3.poolmanager.PoolManager.connection_from_host(...)`` (Issue #204)\n\n* ``ProxyManager`` requests now include non-default port in ``Host: ...``\n  header. (Issue #217)\n\n* Added HTTPS proxy support in ``ProxyManager``. (Issue #170 #139)\n\n* New ``RequestField`` object can be passed to the ``fields=...`` param which\n  can specify headers. (Issue #220)\n\n* Raise ``urllib3.exceptions.ProxyError`` when connecting to proxy fails.\n  (Issue #221)\n\n* Use international headers when posting file names. (Issue #119)\n\n* Improved IPv6 support. (Issue #203)\n\n\n1.6 (2013-04-25)\n----------------\n\n* Contrib: Optional SNI support for Py2 using PyOpenSSL. (Issue #156)\n\n* ``ProxyManager`` automatically adds ``Host: ...`` header if not given.\n\n* Improved SSL-related code. ``cert_req`` now optionally takes a string like\n  \"REQUIRED\" or \"NONE\". Same with ``ssl_version`` takes strings like \"SSLv23\"\n  The string values reflect the suffix of the respective constant variable.\n  (Issue #130)\n\n* Vendored ``socksipy`` now based on Anorov's fork which handles unexpectedly\n  closed proxy connections and larger read buffers. (Issue #135)\n\n* Ensure the connection is closed if no data is received, fixes connection leak\n  on some platforms. (Issue #133)\n\n* Added SNI support for SSL/TLS connections on Py32+. (Issue #89)\n\n* Tests fixed to be compatible with Py26 again. (Issue #125)\n\n* Added ability to choose SSL version by passing an ``ssl.PROTOCOL_*`` constant\n  to the ``ssl_version`` parameter of ``HTTPSConnectionPool``. (Issue #109)\n\n* Allow an explicit content type to be specified when encoding file fields.\n  (Issue #126)\n\n* Exceptions are now pickleable, with tests. (Issue #101)\n\n* Fixed default headers not getting passed in some cases. (Issue #99)\n\n* Treat \"content-encoding\" header value as case-insensitive, per RFC 2616\n  Section 3.5. (Issue #110)\n\n* \"Connection Refused\" SocketErrors will get retried rather than raised.\n  (Issue #92)\n\n* Updated vendored ``six``, no longer overrides the global ``six`` module\n  namespace. (Issue #113)\n\n* ``urllib3.exceptions.MaxRetryError`` contains a ``reason`` property holding\n  the exception that prompted the final retry. If ``reason is None`` then it\n  was due to a redirect. (Issue #92, #114)\n\n* Fixed ``PoolManager.urlopen()`` from not redirecting more than once.\n  (Issue #149)\n\n* Don't assume ``Content-Type: text/plain`` for multi-part encoding parameters\n  that are not files. (Issue #111)\n\n* Pass `strict` param down to ``httplib.HTTPConnection``. (Issue #122)\n\n* Added mechanism to verify SSL certificates by fingerprint (md5, sha1) or\n  against an arbitrary hostname (when connecting by IP or for misconfigured\n  servers). (Issue #140)\n\n* Streaming decompression support. (Issue #159)\n\n\n1.5 (2012-08-02)\n----------------\n\n* Added ``urllib3.add_stderr_logger()`` for quickly enabling STDERR debug\n  logging in urllib3.\n\n* Native full URL parsing (including auth, path, query, fragment) available in\n  ``urllib3.util.parse_url(url)``.\n\n* Built-in redirect will switch method to 'GET' if status code is 303.\n  (Issue #11)\n\n* ``urllib3.PoolManager`` strips the scheme and host before sending the request\n  uri. (Issue #8)\n\n* New ``urllib3.exceptions.DecodeError`` exception for when automatic decoding,\n  based on the Content-Type header, fails.\n\n* Fixed bug with pool depletion and leaking connections (Issue #76). Added\n  explicit connection closing on pool eviction. Added\n  ``urllib3.PoolManager.clear()``.\n\n* 99% -> 100% unit test coverage.\n\n\n1.4 (2012-06-16)\n----------------\n\n* Minor AppEngine-related fixes.\n\n* Switched from ``mimetools.choose_boundary`` to ``uuid.uuid4()``.\n\n* Improved url parsing. (Issue #73)\n\n* IPv6 url support. (Issue #72)\n\n\n1.3 (2012-03-25)\n----------------\n\n* Removed pre-1.0 deprecated API.\n\n* Refactored helpers into a ``urllib3.util`` submodule.\n\n* Fixed multipart encoding to support list-of-tuples for keys with multiple\n  values. (Issue #48)\n\n* Fixed multiple Set-Cookie headers in response not getting merged properly in\n  Python 3. (Issue #53)\n\n* AppEngine support with Py27. (Issue #61)\n\n* Minor ``encode_multipart_formdata`` fixes related to Python 3 strings vs\n  bytes.\n\n\n1.2.2 (2012-02-06)\n------------------\n\n* Fixed packaging bug of not shipping ``test-requirements.txt``. (Issue #47)\n\n\n1.2.1 (2012-02-05)\n------------------\n\n* Fixed another bug related to when ``ssl`` module is not available. (Issue #41)\n\n* Location parsing errors now raise ``urllib3.exceptions.LocationParseError``\n  which inherits from ``ValueError``.\n\n\n1.2 (2012-01-29)\n----------------\n\n* Added Python 3 support (tested on 3.2.2)\n\n* Dropped Python 2.5 support (tested on 2.6.7, 2.7.2)\n\n* Use ``select.poll`` instead of ``select.select`` for platforms that support\n  it.\n\n* Use ``Queue.LifoQueue`` instead of ``Queue.Queue`` for more aggressive\n  connection reusing. Configurable by overriding ``ConnectionPool.QueueCls``.\n\n* Fixed ``ImportError`` during install when ``ssl`` module is not available.\n  (Issue #41)\n\n* Fixed ``PoolManager`` redirects between schemes (such as HTTP -> HTTPS) not\n  completing properly. (Issue #28, uncovered by Issue #10 in v1.1)\n\n* Ported ``dummyserver`` to use ``tornado`` instead of ``webob`` +\n  ``eventlet``. Removed extraneous unsupported dummyserver testing backends.\n  Added socket-level tests.\n\n* More tests. Achievement Unlocked: 99% Coverage.\n\n\n1.1 (2012-01-07)\n----------------\n\n* Refactored ``dummyserver`` to its own root namespace module (used for\n  testing).\n\n* Added hostname verification for ``VerifiedHTTPSConnection`` by vendoring in\n  Py32's ``ssl_match_hostname``. (Issue #25)\n\n* Fixed cross-host HTTP redirects when using ``PoolManager``. (Issue #10)\n\n* Fixed ``decode_content`` being ignored when set through ``urlopen``. (Issue\n  #27)\n\n* Fixed timeout-related bugs. (Issues #17, #23)\n\n\n1.0.2 (2011-11-04)\n------------------\n\n* Fixed typo in ``VerifiedHTTPSConnection`` which would only present as a bug if\n  you're using the object manually. (Thanks pyos)\n\n* Made RecentlyUsedContainer (and consequently PoolManager) more thread-safe by\n  wrapping the access log in a mutex. (Thanks @christer)\n\n* Made RecentlyUsedContainer more dict-like (corrected ``__delitem__`` and\n  ``__getitem__`` behaviour), with tests. Shouldn't affect core urllib3 code.\n\n\n1.0.1 (2011-10-10)\n------------------\n\n* Fixed a bug where the same connection would get returned into the pool twice,\n  causing extraneous \"HttpConnectionPool is full\" log warnings.\n\n\n1.0 (2011-10-08)\n----------------\n\n* Added ``PoolManager`` with LRU expiration of connections (tested and\n  documented).\n* Added ``ProxyManager`` (needs tests, docs, and confirmation that it works\n  with HTTPS proxies).\n* Added optional partial-read support for responses when\n  ``preload_content=False``. You can now make requests and just read the headers\n  without loading the content.\n* Made response decoding optional (default on, same as before).\n* Added optional explicit boundary string for ``encode_multipart_formdata``.\n* Convenience request methods are now inherited from ``RequestMethods``. Old\n  helpers like ``get_url`` and ``post_url`` should be abandoned in favour of\n  the new ``request(method, url, ...)``.\n* Refactored code to be even more decoupled, reusable, and extendable.\n* License header added to ``.py`` files.\n* Embiggened the documentation: Lots of Sphinx-friendly docstrings in the code\n  and docs in ``docs/`` and on https://urllib3.readthedocs.io/.\n* Embettered all the things!\n* Started writing this file.\n\n\n0.4.1 (2011-07-17)\n------------------\n\n* Minor bug fixes, code cleanup.\n\n\n0.4 (2011-03-01)\n----------------\n\n* Better unicode support.\n* Added ``VerifiedHTTPSConnection``.\n* Added ``NTLMConnectionPool`` in contrib.\n* Minor improvements.\n\n\n0.3.1 (2010-07-13)\n------------------\n\n* Added ``assert_host_name`` optional parameter. Now compatible with proxies.\n\n\n0.3 (2009-12-10)\n----------------\n\n* Added HTTPS support.\n* Minor bug fixes.\n* Refactored, broken backwards compatibility with 0.2.\n* API to be treated as stable from this version forward.\n\n\n0.2 (2008-11-17)\n----------------\n\n* Added unit tests.\n* Bug fixes.\n\n\n0.1 (2008-11-16)\n----------------\n\n* First release.\n", "from __future__ import absolute_import\nimport re\nfrom collections import namedtuple\n\nfrom ..exceptions import LocationParseError\nfrom ..packages import six, rfc3986\nfrom ..packages.rfc3986.exceptions import RFC3986Exception, ValidationError\nfrom ..packages.rfc3986.validators import Validator\nfrom ..packages.rfc3986 import abnf_regexp, normalizers, compat, misc\n\n\nurl_attrs = ['scheme', 'auth', 'host', 'port', 'path', 'query', 'fragment']\n\n# We only want to normalize urls with an HTTP(S) scheme.\n# urllib3 infers URLs without a scheme (None) to be http.\nNORMALIZABLE_SCHEMES = ('http', 'https', None)\n\n# Regex for detecting URLs with schemes. RFC 3986 Section 3.1\nSCHEME_REGEX = re.compile(r\"^(?:[a-zA-Z][a-zA-Z0-9+\\-]*:|/)\")\n\nPATH_CHARS = abnf_regexp.UNRESERVED_CHARS_SET | abnf_regexp.SUB_DELIMITERS_SET | {':', '@', '/'}\nQUERY_CHARS = FRAGMENT_CHARS = PATH_CHARS | {'?'}\n\n\nclass Url(namedtuple('Url', url_attrs)):\n    \"\"\"\n    Data structure for representing an HTTP URL. Used as a return value for\n    :func:`parse_url`. Both the scheme and host are normalized as they are\n    both case-insensitive according to RFC 3986.\n    \"\"\"\n    __slots__ = ()\n\n    def __new__(cls, scheme=None, auth=None, host=None, port=None, path=None,\n                query=None, fragment=None):\n        if path and not path.startswith('/'):\n            path = '/' + path\n        if scheme is not None:\n            scheme = scheme.lower()\n        return super(Url, cls).__new__(cls, scheme, auth, host, port, path,\n                                       query, fragment)\n\n    @property\n    def hostname(self):\n        \"\"\"For backwards-compatibility with urlparse. We're nice like that.\"\"\"\n        return self.host\n\n    @property\n    def request_uri(self):\n        \"\"\"Absolute path including the query string.\"\"\"\n        uri = self.path or '/'\n\n        if self.query is not None:\n            uri += '?' + self.query\n\n        return uri\n\n    @property\n    def netloc(self):\n        \"\"\"Network location including host and port\"\"\"\n        if self.port:\n            return '%s:%d' % (self.host, self.port)\n        return self.host\n\n    @property\n    def url(self):\n        \"\"\"\n        Convert self into a url\n\n        This function should more or less round-trip with :func:`.parse_url`. The\n        returned url may not be exactly the same as the url inputted to\n        :func:`.parse_url`, but it should be equivalent by the RFC (e.g., urls\n        with a blank port will have : removed).\n\n        Example: ::\n\n            >>> U = parse_url('http://google.com/mail/')\n            >>> U.url\n            'http://google.com/mail/'\n            >>> Url('http', 'username:password', 'host.com', 80,\n            ... '/path', 'query', 'fragment').url\n            'http://username:password@host.com:80/path?query#fragment'\n        \"\"\"\n        scheme, auth, host, port, path, query, fragment = self\n        url = u''\n\n        # We use \"is not None\" we want things to happen with empty strings (or 0 port)\n        if scheme is not None:\n            url += scheme + u'://'\n        if auth is not None:\n            url += auth + u'@'\n        if host is not None:\n            url += host\n        if port is not None:\n            url += u':' + str(port)\n        if path is not None:\n            url += path\n        if query is not None:\n            url += u'?' + query\n        if fragment is not None:\n            url += u'#' + fragment\n\n        return url\n\n    def __str__(self):\n        return self.url\n\n\ndef split_first(s, delims):\n    \"\"\"\n    .. deprecated:: 1.25\n\n    Given a string and an iterable of delimiters, split on the first found\n    delimiter. Return two split parts and the matched delimiter.\n\n    If not found, then the first part is the full input string.\n\n    Example::\n\n        >>> split_first('foo/bar?baz', '?/=')\n        ('foo', 'bar?baz', '/')\n        >>> split_first('foo/bar?baz', '123')\n        ('foo/bar?baz', '', None)\n\n    Scales linearly with number of delims. Not ideal for large number of delims.\n    \"\"\"\n    min_idx = None\n    min_delim = None\n    for d in delims:\n        idx = s.find(d)\n        if idx < 0:\n            continue\n\n        if min_idx is None or idx < min_idx:\n            min_idx = idx\n            min_delim = d\n\n    if min_idx is None or min_idx < 0:\n        return s, '', None\n\n    return s[:min_idx], s[min_idx + 1:], min_delim\n\n\ndef _encode_invalid_chars(component, allowed_chars, encoding='utf-8'):\n    \"\"\"Percent-encodes a URI component without reapplying\n    onto an already percent-encoded component. Based on\n    rfc3986.normalizers.encode_component()\n    \"\"\"\n    if component is None:\n        return component\n\n    # Try to see if the component we're encoding is already percent-encoded\n    # so we can skip all '%' characters but still encode all others.\n    percent_encodings = len(normalizers.PERCENT_MATCHER.findall(\n                            compat.to_str(component, encoding)))\n\n    uri_bytes = component.encode('utf-8', 'surrogatepass')\n    is_percent_encoded = percent_encodings == uri_bytes.count(b'%')\n\n    encoded_component = bytearray()\n\n    for i in range(0, len(uri_bytes)):\n        # Will return a single character bytestring on both Python 2 & 3\n        byte = uri_bytes[i:i+1]\n        byte_ord = ord(byte)\n        if ((is_percent_encoded and byte == b'%')\n                or (byte_ord < 128 and byte.decode() in allowed_chars)):\n            encoded_component.extend(byte)\n            continue\n        encoded_component.extend('%{0:02x}'.format(byte_ord).encode().upper())\n\n    return encoded_component.decode(encoding)\n\n\ndef parse_url(url):\n    \"\"\"\n    Given a url, return a parsed :class:`.Url` namedtuple. Best-effort is\n    performed to parse incomplete urls. Fields not provided will be None.\n    This parser is RFC 3986 compliant.\n\n    :param str url: URL to parse into a :class:`.Url` namedtuple.\n\n    Partly backwards-compatible with :mod:`urlparse`.\n\n    Example::\n\n        >>> parse_url('http://google.com/mail/')\n        Url(scheme='http', host='google.com', port=None, path='/mail/', ...)\n        >>> parse_url('google.com:80')\n        Url(scheme=None, host='google.com', port=80, path=None, ...)\n        >>> parse_url('/foo?bar')\n        Url(scheme=None, host=None, port=None, path='/foo', query='bar', ...)\n    \"\"\"\n    if not url:\n        # Empty\n        return Url()\n\n    is_string = not isinstance(url, six.binary_type)\n\n    # RFC 3986 doesn't like URLs that have a host but don't start\n    # with a scheme and we support URLs like that so we need to\n    # detect that problem and add an empty scheme indication.\n    # We don't get hurt on path-only URLs here as it's stripped\n    # off and given an empty scheme anyways.\n    if not SCHEME_REGEX.search(url):\n        url = \"//\" + url\n\n    def idna_encode(name):\n        if name and any([ord(x) > 128 for x in name]):\n            try:\n                import idna\n            except ImportError:\n                raise LocationParseError(\"Unable to parse URL without the 'idna' module\")\n            try:\n                return idna.encode(name.lower(), strict=True, std3_rules=True)\n            except idna.IDNAError:\n                raise LocationParseError(u\"Name '%s' is not a valid IDNA label\" % name)\n        return name\n\n    try:\n        split_iri = misc.IRI_MATCHER.match(compat.to_str(url)).groupdict()\n        iri_ref = rfc3986.IRIReference(\n            split_iri['scheme'], split_iri['authority'],\n            _encode_invalid_chars(split_iri['path'], PATH_CHARS),\n            _encode_invalid_chars(split_iri['query'], QUERY_CHARS),\n            _encode_invalid_chars(split_iri['fragment'], FRAGMENT_CHARS)\n        )\n        has_authority = iri_ref.authority is not None\n        uri_ref = iri_ref.encode(idna_encoder=idna_encode)\n    except (ValueError, RFC3986Exception):\n        return six.raise_from(LocationParseError(url), None)\n\n    # rfc3986 strips the authority if it's invalid\n    if has_authority and uri_ref.authority is None:\n        raise LocationParseError(url)\n\n    # Only normalize schemes we understand to not break http+unix\n    # or other schemes that don't follow RFC 3986.\n    if uri_ref.scheme is None or uri_ref.scheme.lower() in NORMALIZABLE_SCHEMES:\n        uri_ref = uri_ref.normalize()\n\n    # Validate all URIReference components and ensure that all\n    # components that were set before are still set after\n    # normalization has completed.\n    validator = Validator()\n    try:\n        validator.check_validity_of(\n            *validator.COMPONENT_NAMES\n        ).validate(uri_ref)\n    except ValidationError:\n        return six.raise_from(LocationParseError(url), None)\n\n    # For the sake of backwards compatibility we put empty\n    # string values for path if there are any defined values\n    # beyond the path in the URL.\n    # TODO: Remove this when we break backwards compatibility.\n    path = uri_ref.path\n    if not path:\n        if (uri_ref.query is not None\n                or uri_ref.fragment is not None):\n            path = \"\"\n        else:\n            path = None\n\n    # Ensure that each part of the URL is a `str` for\n    # backwards compatibility.\n    def to_input_type(x):\n        if x is None:\n            return None\n        elif not is_string and not isinstance(x, six.binary_type):\n            return x.encode('utf-8')\n        return x\n\n    return Url(\n        scheme=to_input_type(uri_ref.scheme),\n        auth=to_input_type(uri_ref.userinfo),\n        host=to_input_type(uri_ref.host),\n        port=int(uri_ref.port) if uri_ref.port is not None else None,\n        path=to_input_type(path),\n        query=to_input_type(uri_ref.query),\n        fragment=to_input_type(uri_ref.fragment)\n    )\n\n\ndef get_host(url):\n    \"\"\"\n    Deprecated. Use :func:`parse_url` instead.\n    \"\"\"\n    p = parse_url(url)\n    return p.scheme or 'http', p.hostname, p.port\n", "# coding: utf-8\nimport hashlib\nimport warnings\nimport logging\nimport io\nimport ssl\nimport socket\nfrom itertools import chain\n\nfrom mock import patch, Mock\nimport pytest\n\nfrom urllib3 import add_stderr_logger, disable_warnings\nfrom urllib3.util.request import make_headers, rewind_body, _FAILEDTELL\nfrom urllib3.util.response import assert_header_parsing\nfrom urllib3.util.retry import Retry\nfrom urllib3.util.timeout import Timeout\nfrom urllib3.util.url import (\n    get_host,\n    parse_url,\n    split_first,\n    Url,\n)\nfrom urllib3.util.ssl_ import (\n    resolve_cert_reqs,\n    resolve_ssl_version,\n    ssl_wrap_socket,\n    _const_compare_digest_backport,\n)\nfrom urllib3.exceptions import (\n    LocationParseError,\n    TimeoutStateError,\n    InsecureRequestWarning,\n    SNIMissingWarning,\n    InvalidHeader,\n    UnrewindableBodyError,\n)\nfrom urllib3.util.connection import (\n    allowed_gai_family,\n    _has_ipv6\n)\nfrom urllib3.util import is_fp_closed, ssl_\nfrom urllib3.packages import six\n\nfrom . import clear_warnings\n\nfrom test import onlyPy3, onlyPy2, onlyBrotlipy, notBrotlipy\n\n# This number represents a time in seconds, it doesn't mean anything in\n# isolation. Setting to a high-ish value to avoid conflicts with the smaller\n# numbers used for timeouts\nTIMEOUT_EPOCH = 1000\n\n\nclass TestUtil(object):\n\n    url_host_map = [\n        # Hosts\n        ('http://google.com/mail', ('http', 'google.com', None)),\n        ('http://google.com/mail/', ('http', 'google.com', None)),\n        ('google.com/mail', ('http', 'google.com', None)),\n        ('http://google.com/', ('http', 'google.com', None)),\n        ('http://google.com', ('http', 'google.com', None)),\n        ('http://www.google.com', ('http', 'www.google.com', None)),\n        ('http://mail.google.com', ('http', 'mail.google.com', None)),\n        ('http://google.com:8000/mail/', ('http', 'google.com', 8000)),\n        ('http://google.com:8000', ('http', 'google.com', 8000)),\n        ('https://google.com', ('https', 'google.com', None)),\n        ('https://google.com:8000', ('https', 'google.com', 8000)),\n        ('http://user:password@127.0.0.1:1234', ('http', '127.0.0.1', 1234)),\n        ('http://google.com/foo=http://bar:42/baz', ('http', 'google.com', None)),\n        ('http://google.com?foo=http://bar:42/baz', ('http', 'google.com', None)),\n        ('http://google.com#foo=http://bar:42/baz', ('http', 'google.com', None)),\n\n        # IPv4\n        ('173.194.35.7', ('http', '173.194.35.7', None)),\n        ('http://173.194.35.7', ('http', '173.194.35.7', None)),\n        ('http://173.194.35.7/test', ('http', '173.194.35.7', None)),\n        ('http://173.194.35.7:80', ('http', '173.194.35.7', 80)),\n        ('http://173.194.35.7:80/test', ('http', '173.194.35.7', 80)),\n\n        # IPv6\n        ('[2a00:1450:4001:c01::67]', ('http', '[2a00:1450:4001:c01::67]', None)),\n        ('http://[2a00:1450:4001:c01::67]', ('http', '[2a00:1450:4001:c01::67]', None)),\n        ('http://[2a00:1450:4001:c01::67]/test', ('http', '[2a00:1450:4001:c01::67]', None)),\n        ('http://[2a00:1450:4001:c01::67]:80', ('http', '[2a00:1450:4001:c01::67]', 80)),\n        ('http://[2a00:1450:4001:c01::67]:80/test', ('http', '[2a00:1450:4001:c01::67]', 80)),\n\n        # More IPv6 from http://www.ietf.org/rfc/rfc2732.txt\n        ('http://[fedc:ba98:7654:3210:fedc:ba98:7654:3210]:8000/index.html', (\n            'http', '[fedc:ba98:7654:3210:fedc:ba98:7654:3210]', 8000)),\n        ('http://[1080:0:0:0:8:800:200c:417a]/index.html', (\n            'http', '[1080:0:0:0:8:800:200c:417a]', None)),\n        ('http://[3ffe:2a00:100:7031::1]', ('http', '[3ffe:2a00:100:7031::1]', None)),\n        ('http://[1080::8:800:200c:417a]/foo', ('http', '[1080::8:800:200c:417a]', None)),\n        ('http://[::192.9.5.5]/ipng', ('http', '[::192.9.5.5]', None)),\n        ('http://[::ffff:129.144.52.38]:42/index.html', ('http', '[::ffff:129.144.52.38]', 42)),\n        ('http://[2010:836b:4179::836b:4179]', ('http', '[2010:836b:4179::836b:4179]', None)),\n\n        # Hosts\n        ('HTTP://GOOGLE.COM/mail/', ('http', 'google.com', None)),\n        ('GOogle.COM/mail', ('http', 'google.com', None)),\n        ('HTTP://GoOgLe.CoM:8000/mail/', ('http', 'google.com', 8000)),\n        ('HTTP://user:password@EXAMPLE.COM:1234', ('http', 'example.com', 1234)),\n        ('173.194.35.7', ('http', '173.194.35.7', None)),\n        ('HTTP://173.194.35.7', ('http', '173.194.35.7', None)),\n        ('HTTP://[2a00:1450:4001:c01::67]:80/test', ('http', '[2a00:1450:4001:c01::67]', 80)),\n        ('HTTP://[FEDC:BA98:7654:3210:FEDC:BA98:7654:3210]:8000/index.html', (\n            'http', '[fedc:ba98:7654:3210:fedc:ba98:7654:3210]', 8000)),\n        ('HTTPS://[1080:0:0:0:8:800:200c:417A]/index.html', (\n            'https', '[1080:0:0:0:8:800:200c:417a]', None)),\n        ('abOut://eXamPlE.com?info=1', ('about', 'eXamPlE.com', None)),\n        ('http+UNIX://%2fvar%2frun%2fSOCKET/path', (\n            'http+unix', '%2fvar%2frun%2fSOCKET', None)),\n    ]\n\n    @pytest.mark.parametrize('url, expected_host', url_host_map)\n    def test_get_host(self, url, expected_host):\n        returned_host = get_host(url)\n        assert returned_host == expected_host\n\n    # TODO: Add more tests\n    @pytest.mark.parametrize('location', [\n        'http://google.com:foo',\n        'http://::1/',\n        'http://::1:80/',\n        'http://google.com:-80',\n        six.u('http://google.com:\\xb2\\xb2'),  # \\xb2 = ^2\n    ])\n    def test_invalid_host(self, location):\n        with pytest.raises(LocationParseError):\n            get_host(location)\n\n    @pytest.mark.parametrize('url', [\n        'http://user\\\\@google.com',\n        'http://google\\\\.com',\n        'user\\\\@google.com',\n        'http://user@user@google.com/',\n\n        # Invalid IDNA labels\n        u'http://\\uD7FF.com',\n        u'http://\u2764\ufe0f',\n\n        # Unicode surrogates\n        u'http://\\uD800.com',\n        u'http://\\uDC00.com',\n    ])\n    def test_invalid_url(self, url):\n        with pytest.raises(LocationParseError):\n            parse_url(url)\n\n    @pytest.mark.parametrize('url, expected_normalized_url', [\n        ('HTTP://GOOGLE.COM/MAIL/', 'http://google.com/MAIL/'),\n        ('HTTP://JeremyCline:Hunter2@Example.com:8080/',\n         'http://JeremyCline:Hunter2@example.com:8080/'),\n        ('HTTPS://Example.Com/?Key=Value', 'https://example.com/?Key=Value'),\n        ('Https://Example.Com/#Fragment', 'https://example.com/#Fragment'),\n        ('[::Ff%etH0%Ff]/%ab%Af', '[::ff%25etH0%Ff]/%AB%AF'),\n\n        # Invalid characters for the query/fragment getting encoded\n        ('http://google.com/p[]?parameter[]=\\\"hello\\\"#fragment#',\n         'http://google.com/p%5B%5D?parameter%5B%5D=%22hello%22#fragment%23'),\n\n        # Percent encoding isn't applied twice despite '%' being invalid\n        # but the percent encoding is still normalized.\n        ('http://google.com/p%5B%5d?parameter%5b%5D=%22hello%22#fragment%23',\n         'http://google.com/p%5B%5D?parameter%5B%5D=%22hello%22#fragment%23')\n    ])\n    def test_parse_url_normalization(self, url, expected_normalized_url):\n        \"\"\"Assert parse_url normalizes the scheme/host, and only the scheme/host\"\"\"\n        actual_normalized_url = parse_url(url).url\n        assert actual_normalized_url == expected_normalized_url\n\n    parse_url_host_map = [\n        ('http://google.com/mail', Url('http', host='google.com', path='/mail')),\n        ('http://google.com/mail/', Url('http', host='google.com', path='/mail/')),\n        ('http://google.com/mail', Url('http', host='google.com', path='mail')),\n        ('google.com/mail', Url(host='google.com', path='/mail')),\n        ('http://google.com/', Url('http', host='google.com', path='/')),\n        ('http://google.com', Url('http', host='google.com')),\n        ('http://google.com?foo', Url('http', host='google.com', path='', query='foo')),\n\n        # Path/query/fragment\n        ('', Url()),\n        ('/', Url(path='/')),\n        ('#?/!google.com/?foo', Url(path='', fragment='?/!google.com/?foo')),\n        ('/foo', Url(path='/foo')),\n        ('/foo?bar=baz', Url(path='/foo', query='bar=baz')),\n        ('/foo?bar=baz#banana?apple/orange', Url(path='/foo',\n                                                 query='bar=baz',\n                                                 fragment='banana?apple/orange')),\n        ('/redirect?target=http://localhost:61020/', Url(path='redirect',\n                                                         query='target=http://localhost:61020/')),\n\n        # Port\n        ('http://google.com/', Url('http', host='google.com', path='/')),\n        ('http://google.com:80/', Url('http', host='google.com', port=80, path='/')),\n        ('http://google.com:80', Url('http', host='google.com', port=80)),\n\n        # Auth\n        ('http://foo:bar@localhost/', Url('http', auth='foo:bar', host='localhost', path='/')),\n        ('http://foo@localhost/', Url('http', auth='foo', host='localhost', path='/')),\n        ('http://foo:bar@localhost/', Url('http',\n                                          auth='foo:bar',\n                                          host='localhost',\n                                          path='/')),\n\n        # Unicode type (Python 2.x)\n        (u'http://foo:bar@localhost/', Url(u'http',\n                                           auth=u'foo:bar',\n                                           host=u'localhost',\n                                           path=u'/')),\n        ('http://foo:bar@localhost/', Url('http',\n                                          auth='foo:bar',\n                                          host='localhost',\n                                          path='/')),\n    ]\n\n    non_round_tripping_parse_url_host_map = [\n        # Path/query/fragment\n        ('?', Url(path='', query='')),\n        ('#', Url(path='', fragment='')),\n\n        # Path normalization\n        ('/abc/../def', Url(path=\"/def\")),\n\n        # Empty Port\n        ('http://google.com:', Url('http', host='google.com')),\n        ('http://google.com:/', Url('http', host='google.com', path='/')),\n\n        # Uppercase IRI\n        (u'http://K\u00f6nigsg\u00e4\u00dfchen.de/stra\u00dfe',\n         Url('http', host='xn--knigsgchen-b4a3dun.de', path='/stra%C3%9Fe')),\n\n        # Unicode Surrogates\n        (u'http://google.com/\\uD800', Url('http', host='google.com', path='%ED%A0%80')),\n        (u'http://google.com?q=\\uDC00',\n         Url('http', host='google.com', path='', query='q=%ED%B0%80')),\n        (u'http://google.com#\\uDC00',\n         Url('http', host='google.com', path='', fragment='%ED%B0%80')),\n    ]\n\n    @pytest.mark.parametrize(\n        'url, expected_url',\n        chain(parse_url_host_map, non_round_tripping_parse_url_host_map)\n    )\n    def test_parse_url(self, url, expected_url):\n        returned_url = parse_url(url)\n        assert returned_url == expected_url\n\n    @pytest.mark.parametrize('url, expected_url', parse_url_host_map)\n    def test_unparse_url(self, url, expected_url):\n        assert url == expected_url.url\n\n    @pytest.mark.parametrize(\n        ['url', 'expected_url'],\n        [\n            # RFC 3986 5.2.4\n            ('/abc/../def', Url(path=\"/def\")),\n            ('/..', Url(path=\"/\")),\n            ('/./abc/./def/', Url(path='/abc/def/')),\n            ('/.', Url(path='/')),\n            ('/./', Url(path='/')),\n            ('/abc/./.././d/././e/.././f/./../../ghi', Url(path='/ghi'))\n        ]\n    )\n    def test_parse_and_normalize_url_paths(self, url, expected_url):\n        actual_url = parse_url(url)\n        assert actual_url == expected_url\n        assert actual_url.url == expected_url.url\n\n    def test_parse_url_invalid_IPv6(self):\n        with pytest.raises(LocationParseError):\n            parse_url('[::1')\n\n    def test_parse_url_negative_port(self):\n        with pytest.raises(LocationParseError):\n            parse_url(\"https://www.google.com:-80/\")\n\n    def test_Url_str(self):\n        U = Url('http', host='google.com')\n        assert str(U) == U.url\n\n    request_uri_map = [\n        ('http://google.com/mail', '/mail'),\n        ('http://google.com/mail/', '/mail/'),\n        ('http://google.com/', '/'),\n        ('http://google.com', '/'),\n        ('', '/'),\n        ('/', '/'),\n        ('?', '/?'),\n        ('#', '/'),\n        ('/foo?bar=baz', '/foo?bar=baz'),\n    ]\n\n    @pytest.mark.parametrize('url, expected_request_uri', request_uri_map)\n    def test_request_uri(self, url, expected_request_uri):\n        returned_url = parse_url(url)\n        assert returned_url.request_uri == expected_request_uri\n\n    url_netloc_map = [\n        ('http://google.com/mail', 'google.com'),\n        ('http://google.com:80/mail', 'google.com:80'),\n        ('google.com/foobar', 'google.com'),\n        ('google.com:12345', 'google.com:12345'),\n    ]\n\n    @pytest.mark.parametrize('url, expected_netloc', url_netloc_map)\n    def test_netloc(self, url, expected_netloc):\n        assert parse_url(url).netloc == expected_netloc\n\n    url_vulnerabilities = [\n        # urlparse doesn't follow RFC 3986 Section 3.2\n        (\"http://google.com#@evil.com/\", Url(\"http\",\n                                             host=\"google.com\",\n                                             path=\"\",\n                                             fragment=\"@evil.com/\")),\n\n        # CVE-2016-5699\n        (\"http://127.0.0.1%0d%0aConnection%3a%20keep-alive\",\n         Url(\"http\", host=\"127.0.0.1%0d%0aconnection%3a%20keep-alive\")),\n\n        # NodeJS unicode -> double dot\n        (u\"http://google.com/\\uff2e\\uff2e/abc\", Url(\"http\",\n                                                    host=\"google.com\",\n                                                    path='/%EF%BC%AE%EF%BC%AE/abc')),\n\n        # Scheme without ://\n        (\"javascript:a='@google.com:12345/';alert(0)\",\n         Url(scheme=\"javascript\",\n             path=\"a='@google.com:12345/';alert(0)\")),\n\n        (\"//google.com/a/b/c\", Url(host=\"google.com\", path=\"/a/b/c\")),\n\n        # International URLs\n        (u'http://\u30d2:\u30ad@\u30d2.abc.\u30cb/\u30d2?\u30ad#\u30ef', Url(u'http',\n                                          host=u'xn--pdk.abc.xn--idk',\n                                          auth=u'%E3%83%92:%E3%82%AD',\n                                          path=u'/%E3%83%92',\n                                          query=u'%E3%82%AD',\n                                          fragment=u'%E3%83%AF')),\n\n        # Injected headers (CVE-2016-5699, CVE-2019-9740, CVE-2019-9947)\n        (\"10.251.0.83:7777?a=1 HTTP/1.1\\r\\nX-injected: header\",\n         Url(host='10.251.0.83', port=7777, path='',\n             query='a=1%20HTTP/1.1%0D%0AX-injected:%20header')),\n\n        (\"http://127.0.0.1:6379?\\r\\nSET test failure12\\r\\n:8080/test/?test=a\",\n         Url(scheme='http', host='127.0.0.1', port=6379, path='',\n             query='%0D%0ASET%20test%20failure12%0D%0A:8080/test/?test=a')),\n    ]\n\n    @pytest.mark.parametrize(\"url, expected_url\", url_vulnerabilities)\n    def test_url_vulnerabilities(self, url, expected_url):\n        if expected_url is False:\n            with pytest.raises(LocationParseError):\n                parse_url(url)\n        else:\n            assert parse_url(url) == expected_url\n\n    @onlyPy2\n    def test_parse_url_bytes_to_str_python_2(self):\n        url = parse_url(b\"https://www.google.com/\")\n        assert url == Url('https', host='www.google.com', path='/')\n\n        assert isinstance(url.scheme, str)\n        assert isinstance(url.host, str)\n        assert isinstance(url.path, str)\n\n    @onlyPy2\n    def test_parse_url_unicode_python_2(self):\n        url = parse_url(u\"https://www.google.com/\")\n        assert url == Url(u'https', host=u'www.google.com', path=u'/')\n\n        assert isinstance(url.scheme, six.text_type)\n        assert isinstance(url.host, six.text_type)\n        assert isinstance(url.path, six.text_type)\n\n    @onlyPy3\n    def test_parse_url_bytes_type_error_python_3(self):\n        with pytest.raises(TypeError):\n            parse_url(b\"https://www.google.com/\")\n\n    @pytest.mark.parametrize('kwargs, expected', [\n        pytest.param(\n            {'accept_encoding': True},\n            {'accept-encoding': 'gzip,deflate,br'},\n            marks=onlyBrotlipy(),\n        ),\n        pytest.param(\n            {'accept_encoding': True},\n            {'accept-encoding': 'gzip,deflate'},\n            marks=notBrotlipy(),\n        ),\n        ({'accept_encoding': 'foo,bar'},\n         {'accept-encoding': 'foo,bar'}),\n        ({'accept_encoding': ['foo', 'bar']},\n         {'accept-encoding': 'foo,bar'}),\n        pytest.param(\n            {'accept_encoding': True, 'user_agent': 'banana'},\n            {'accept-encoding': 'gzip,deflate,br', 'user-agent': 'banana'},\n            marks=onlyBrotlipy(),\n        ),\n        pytest.param(\n            {'accept_encoding': True, 'user_agent': 'banana'},\n            {'accept-encoding': 'gzip,deflate', 'user-agent': 'banana'},\n            marks=notBrotlipy(),\n        ),\n        ({'user_agent': 'banana'},\n         {'user-agent': 'banana'}),\n        ({'keep_alive': True},\n         {'connection': 'keep-alive'}),\n        ({'basic_auth': 'foo:bar'},\n         {'authorization': 'Basic Zm9vOmJhcg=='}),\n        ({'proxy_basic_auth': 'foo:bar'},\n         {'proxy-authorization': 'Basic Zm9vOmJhcg=='}),\n        ({'disable_cache': True},\n         {'cache-control': 'no-cache'}),\n    ])\n    def test_make_headers(self, kwargs, expected):\n        assert make_headers(**kwargs) == expected\n\n    def test_rewind_body(self):\n        body = io.BytesIO(b'test data')\n        assert body.read() == b'test data'\n\n        # Assert the file object has been consumed\n        assert body.read() == b''\n\n        # Rewind it back to just be b'data'\n        rewind_body(body, 5)\n        assert body.read() == b'data'\n\n    def test_rewind_body_failed_tell(self):\n        body = io.BytesIO(b'test data')\n        body.read()  # Consume body\n\n        # Simulate failed tell()\n        body_pos = _FAILEDTELL\n        with pytest.raises(UnrewindableBodyError):\n            rewind_body(body, body_pos)\n\n    def test_rewind_body_bad_position(self):\n        body = io.BytesIO(b'test data')\n        body.read()  # Consume body\n\n        # Pass non-integer position\n        with pytest.raises(ValueError):\n            rewind_body(body, body_pos=None)\n        with pytest.raises(ValueError):\n            rewind_body(body, body_pos=object())\n\n    def test_rewind_body_failed_seek(self):\n        class BadSeek():\n\n            def seek(self, pos, offset=0):\n                raise IOError\n\n        with pytest.raises(UnrewindableBodyError):\n            rewind_body(BadSeek(), body_pos=2)\n\n    @pytest.mark.parametrize('input, expected', [\n        (('abcd', 'b'),  ('a', 'cd', 'b')),\n        (('abcd', 'cb'), ('a', 'cd', 'b')),\n        (('abcd', ''),   ('abcd', '', None)),\n        (('abcd', 'a'),  ('', 'bcd', 'a')),\n        (('abcd', 'ab'), ('', 'bcd', 'a')),\n        (('abcd', 'eb'), ('a', 'cd', 'b')),\n    ])\n    def test_split_first(self, input, expected):\n        output = split_first(*input)\n        assert output == expected\n\n    def test_add_stderr_logger(self):\n        handler = add_stderr_logger(level=logging.INFO)  # Don't actually print debug\n        logger = logging.getLogger('urllib3')\n        assert handler in logger.handlers\n\n        logger.debug('Testing add_stderr_logger')\n        logger.removeHandler(handler)\n\n    def test_disable_warnings(self):\n        with warnings.catch_warnings(record=True) as w:\n            clear_warnings()\n            warnings.warn('This is a test.', InsecureRequestWarning)\n            assert len(w) == 1\n            disable_warnings()\n            warnings.warn('This is a test.', InsecureRequestWarning)\n            assert len(w) == 1\n\n    def _make_time_pass(self, seconds, timeout, time_mock):\n        \"\"\" Make some time pass for the timeout object \"\"\"\n        time_mock.return_value = TIMEOUT_EPOCH\n        timeout.start_connect()\n        time_mock.return_value = TIMEOUT_EPOCH + seconds\n        return timeout\n\n    @pytest.mark.parametrize('kwargs, message', [\n        ({'total': -1},                 'less than'),\n        ({'connect': 2, 'total': -1},   'less than'),\n        ({'read': -1},                  'less than'),\n        ({'connect': False},            'cannot be a boolean'),\n        ({'read': True},                'cannot be a boolean'),\n        ({'connect': 0},                'less than or equal'),\n        ({'read': 'foo'},               'int, float or None')\n    ])\n    def test_invalid_timeouts(self, kwargs, message):\n        with pytest.raises(ValueError) as e:\n            Timeout(**kwargs)\n        assert message in str(e.value)\n\n    @patch('urllib3.util.timeout.current_time')\n    def test_timeout(self, current_time):\n        timeout = Timeout(total=3)\n\n        # make 'no time' elapse\n        timeout = self._make_time_pass(seconds=0, timeout=timeout,\n                                       time_mock=current_time)\n        assert timeout.read_timeout == 3\n        assert timeout.connect_timeout == 3\n\n        timeout = Timeout(total=3, connect=2)\n        assert timeout.connect_timeout == 2\n\n        timeout = Timeout()\n        assert timeout.connect_timeout == Timeout.DEFAULT_TIMEOUT\n\n        # Connect takes 5 seconds, leaving 5 seconds for read\n        timeout = Timeout(total=10, read=7)\n        timeout = self._make_time_pass(seconds=5, timeout=timeout,\n                                       time_mock=current_time)\n        assert timeout.read_timeout == 5\n\n        # Connect takes 2 seconds, read timeout still 7 seconds\n        timeout = Timeout(total=10, read=7)\n        timeout = self._make_time_pass(seconds=2, timeout=timeout,\n                                       time_mock=current_time)\n        assert timeout.read_timeout == 7\n\n        timeout = Timeout(total=10, read=7)\n        assert timeout.read_timeout == 7\n\n        timeout = Timeout(total=None, read=None, connect=None)\n        assert timeout.connect_timeout is None\n        assert timeout.read_timeout is None\n        assert timeout.total is None\n\n        timeout = Timeout(5)\n        assert timeout.total == 5\n\n    def test_timeout_str(self):\n        timeout = Timeout(connect=1, read=2, total=3)\n        assert str(timeout) == \"Timeout(connect=1, read=2, total=3)\"\n        timeout = Timeout(connect=1, read=None, total=3)\n        assert str(timeout) == \"Timeout(connect=1, read=None, total=3)\"\n\n    @patch('urllib3.util.timeout.current_time')\n    def test_timeout_elapsed(self, current_time):\n        current_time.return_value = TIMEOUT_EPOCH\n        timeout = Timeout(total=3)\n        with pytest.raises(TimeoutStateError):\n            timeout.get_connect_duration()\n\n        timeout.start_connect()\n        with pytest.raises(TimeoutStateError):\n            timeout.start_connect()\n\n        current_time.return_value = TIMEOUT_EPOCH + 2\n        assert timeout.get_connect_duration() == 2\n        current_time.return_value = TIMEOUT_EPOCH + 37\n        assert timeout.get_connect_duration() == 37\n\n    @pytest.mark.parametrize('candidate, requirements', [\n        (None, ssl.CERT_REQUIRED),\n        (ssl.CERT_NONE, ssl.CERT_NONE),\n        (ssl.CERT_REQUIRED, ssl.CERT_REQUIRED),\n        ('REQUIRED', ssl.CERT_REQUIRED),\n        ('CERT_REQUIRED', ssl.CERT_REQUIRED),\n    ])\n    def test_resolve_cert_reqs(self, candidate, requirements):\n        assert resolve_cert_reqs(candidate) == requirements\n\n    @pytest.mark.parametrize('candidate, version', [\n        (ssl.PROTOCOL_TLSv1, ssl.PROTOCOL_TLSv1),\n        (\"PROTOCOL_TLSv1\", ssl.PROTOCOL_TLSv1),\n        (\"TLSv1\", ssl.PROTOCOL_TLSv1),\n        (ssl.PROTOCOL_SSLv23, ssl.PROTOCOL_SSLv23),\n    ])\n    def test_resolve_ssl_version(self, candidate, version):\n        assert resolve_ssl_version(candidate) == version\n\n    def test_is_fp_closed_object_supports_closed(self):\n        class ClosedFile(object):\n            @property\n            def closed(self):\n                return True\n\n        assert is_fp_closed(ClosedFile())\n\n    def test_is_fp_closed_object_has_none_fp(self):\n        class NoneFpFile(object):\n            @property\n            def fp(self):\n                return None\n\n        assert is_fp_closed(NoneFpFile())\n\n    def test_is_fp_closed_object_has_fp(self):\n        class FpFile(object):\n            @property\n            def fp(self):\n                return True\n\n        assert not is_fp_closed(FpFile())\n\n    def test_is_fp_closed_object_has_neither_fp_nor_closed(self):\n        class NotReallyAFile(object):\n            pass\n\n        with pytest.raises(ValueError):\n            is_fp_closed(NotReallyAFile())\n\n    def test_ssl_wrap_socket_loads_the_cert_chain(self):\n        socket = object()\n        mock_context = Mock()\n        ssl_wrap_socket(ssl_context=mock_context, sock=socket,\n                        certfile='/path/to/certfile')\n\n        mock_context.load_cert_chain.assert_called_once_with(\n            '/path/to/certfile', None\n        )\n\n    @patch('urllib3.util.ssl_.create_urllib3_context')\n    def test_ssl_wrap_socket_creates_new_context(self,\n                                                 create_urllib3_context):\n        socket = object()\n        ssl_wrap_socket(sock=socket, cert_reqs='CERT_REQUIRED')\n\n        create_urllib3_context.assert_called_once_with(\n            None, 'CERT_REQUIRED', ciphers=None\n        )\n\n    def test_ssl_wrap_socket_loads_verify_locations(self):\n        socket = object()\n        mock_context = Mock()\n        ssl_wrap_socket(ssl_context=mock_context, ca_certs='/path/to/pem',\n                        sock=socket)\n        mock_context.load_verify_locations.assert_called_once_with(\n            '/path/to/pem', None\n        )\n\n    def test_ssl_wrap_socket_loads_certificate_directories(self):\n        socket = object()\n        mock_context = Mock()\n        ssl_wrap_socket(ssl_context=mock_context, ca_cert_dir='/path/to/pems',\n                        sock=socket)\n        mock_context.load_verify_locations.assert_called_once_with(\n            None, '/path/to/pems'\n        )\n\n    def test_ssl_wrap_socket_with_no_sni_warns(self):\n        socket = object()\n        mock_context = Mock()\n        # Ugly preservation of original value\n        HAS_SNI = ssl_.HAS_SNI\n        ssl_.HAS_SNI = False\n        try:\n            with patch('warnings.warn') as warn:\n                ssl_wrap_socket(ssl_context=mock_context, sock=socket,\n                                server_hostname='www.google.com')\n            mock_context.wrap_socket.assert_called_once_with(socket)\n            assert warn.call_count >= 1\n            warnings = [call[0][1] for call in warn.call_args_list]\n            assert SNIMissingWarning in warnings\n        finally:\n            ssl_.HAS_SNI = HAS_SNI\n\n    def test_const_compare_digest_fallback(self):\n        target = hashlib.sha256(b'abcdef').digest()\n        assert _const_compare_digest_backport(target, target)\n\n        prefix = target[:-1]\n        assert not _const_compare_digest_backport(target, prefix)\n\n        suffix = target + b'0'\n        assert not _const_compare_digest_backport(target, suffix)\n\n        incorrect = hashlib.sha256(b'xyz').digest()\n        assert not _const_compare_digest_backport(target, incorrect)\n\n    def test_has_ipv6_disabled_on_compile(self):\n        with patch('socket.has_ipv6', False):\n            assert not _has_ipv6('::1')\n\n    def test_has_ipv6_enabled_but_fails(self):\n        with patch('socket.has_ipv6', True):\n            with patch('socket.socket') as mock:\n                instance = mock.return_value\n                instance.bind = Mock(side_effect=Exception('No IPv6 here!'))\n                assert not _has_ipv6('::1')\n\n    def test_has_ipv6_enabled_and_working(self):\n        with patch('socket.has_ipv6', True):\n            with patch('socket.socket') as mock:\n                instance = mock.return_value\n                instance.bind.return_value = True\n                assert _has_ipv6('::1')\n\n    def test_has_ipv6_disabled_on_appengine(self):\n        gae_patch = patch(\n            'urllib3.contrib._appengine_environ.is_appengine_sandbox',\n            return_value=True)\n        with gae_patch:\n            assert not _has_ipv6('::1')\n\n    def test_ip_family_ipv6_enabled(self):\n        with patch('urllib3.util.connection.HAS_IPV6', True):\n            assert allowed_gai_family() == socket.AF_UNSPEC\n\n    def test_ip_family_ipv6_disabled(self):\n        with patch('urllib3.util.connection.HAS_IPV6', False):\n            assert allowed_gai_family() == socket.AF_INET\n\n    @pytest.mark.parametrize('value', [\n        \"-1\",\n        \"+1\",\n        \"1.0\",\n        six.u(\"\\xb2\"),  # \\xb2 = ^2\n    ])\n    def test_parse_retry_after_invalid(self, value):\n        retry = Retry()\n        with pytest.raises(InvalidHeader):\n            retry.parse_retry_after(value)\n\n    @pytest.mark.parametrize('value, expected', [\n        (\"0\", 0),\n        (\"1000\", 1000),\n        (\"\\t42 \", 42),\n    ])\n    def test_parse_retry_after(self, value, expected):\n        retry = Retry()\n        assert retry.parse_retry_after(value) == expected\n\n    @pytest.mark.parametrize('headers', [\n        b'foo',\n        None,\n        object,\n    ])\n    def test_assert_header_parsing_throws_typeerror_with_non_headers(self, headers):\n        with pytest.raises(TypeError):\n            assert_header_parsing(headers)\n"], "filenames": ["CHANGES.rst", "src/urllib3/util/url.py", "test/test_util.py"], "buggy_code_start_loc": [7, 8, 138], "buggy_code_end_loc": [7, 213, 218], "fixing_code_start_loc": [8, 9, 137], "fixing_code_end_loc": [11, 251, 241], "type": "CWE-400", "message": "The _encode_invalid_chars function in util/url.py in the urllib3 library 1.25.2 through 1.25.7 for Python allows a denial of service (CPU consumption) because of an inefficient algorithm. The percent_encodings array contains all matches of percent encodings. It is not deduplicated. For a URL of length N, the size of percent_encodings may be up to O(N). The next step (normalize existing percent-encoded bytes) also takes up to O(N) for each step, so the total time is O(N^2). If percent_encodings were deduplicated, the time to compute _encode_invalid_chars would be O(kN), where k is at most 484 ((10+6*2)^2).", "other": {"cve": {"id": "CVE-2020-7212", "sourceIdentifier": "cve@mitre.org", "published": "2020-03-06T20:15:12.707", "lastModified": "2020-03-09T16:55:14.563", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "The _encode_invalid_chars function in util/url.py in the urllib3 library 1.25.2 through 1.25.7 for Python allows a denial of service (CPU consumption) because of an inefficient algorithm. The percent_encodings array contains all matches of percent encodings. It is not deduplicated. For a URL of length N, the size of percent_encodings may be up to O(N). The next step (normalize existing percent-encoded bytes) also takes up to O(N) for each step, so the total time is O(N^2). If percent_encodings were deduplicated, the time to compute _encode_invalid_chars would be O(kN), where k is at most 484 ((10+6*2)^2)."}, {"lang": "es", "value": "La funci\u00f3n _encode_invalid_chars en el archivo util/url.py en la biblioteca urllib3 versiones 1.25.2 hasta 1.25.7 para Python, permite una denegaci\u00f3n de servicio (consumo de CPU) debido a un algoritmo ineficiente. La matriz percent_encodings contiene todas las coincidencias de las codificaciones porcentuales. No est\u00e1 desdoblada. Para una URL de longitud N, el tama\u00f1o de percent_encodings puede ser hasta O(N). El siguiente paso (normalizar los bytes codificados porcentualmente existentes) tambi\u00e9n ocupa hasta O(N) para cada paso, por lo que el tiempo total es O(N^2). Si se desdoblaran los porcentajes de codificaci\u00f3n, el tiempo para calcular _encode_invalid_chars ser\u00eda O(kN), donde k es como m\u00e1ximo 484 ((10+6*2)^2)."}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 7.5, "baseSeverity": "HIGH"}, "exploitabilityScore": 3.9, "impactScore": 3.6}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:N/AC:L/Au:N/C:N/I:N/A:C", "accessVector": "NETWORK", "accessComplexity": "LOW", "authentication": "NONE", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "COMPLETE", "baseScore": 7.8}, "baseSeverity": "HIGH", "exploitabilityScore": 10.0, "impactScore": 6.9, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-400"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:python:urllib3:*:*:*:*:*:*:*:*", "versionStartIncluding": "1.25.2", "versionEndIncluding": "1.25.7", "matchCriteriaId": "C6E2E571-FF01-4577-BEE4-CD2F2448A06E"}]}]}], "references": [{"url": "https://github.com/urllib3/urllib3/blob/master/CHANGES.rst", "source": "cve@mitre.org", "tags": ["Release Notes", "Third Party Advisory"]}, {"url": "https://github.com/urllib3/urllib3/commit/a74c9cfbaed9f811e7563cfc3dce894928e0221a", "source": "cve@mitre.org", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://pypi.org/project/urllib3/1.25.8/", "source": "cve@mitre.org", "tags": ["Release Notes", "Vendor Advisory"]}]}, "github_commit_url": "https://github.com/urllib3/urllib3/commit/a74c9cfbaed9f811e7563cfc3dce894928e0221a"}}
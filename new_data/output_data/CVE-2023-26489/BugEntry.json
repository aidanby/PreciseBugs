{"buggy_code": ["--------------------------------------------------------------------------------\n\n## 8.0.0\n\nUnreleased.\n\n### Added\n\n### Changed\n\n--------------------------------------------------------------------------------\n\n## 7.0.0\n\nUnreleased.\n\n### Added\n\n### Changed\n\n--------------------------------------------------------------------------------\n\n## 6.0.0\n\nReleased 2023-02-20\n\n### Added\n\n* Wasmtime's built-in cache can now be disabled after being enabled previously.\n  [#5542](https://github.com/bytecodealliance/wasmtime/pull/5542)\n\n* Older x86\\_64 CPUs, without SSE4.1 for example, are now supported when the\n  wasm SIMD proposal is disabled.\n  [#5567](https://github.com/bytecodealliance/wasmtime/pull/5567)\n\n* The Wasmtime C API now has `WASMTIME_VERSION_*` macros defined in its header\n  files.\n  [#5651](https://github.com/bytecodealliance/wasmtime/pull/5651)\n\n* The `wasmtime` CLI executable as part of Wasmtime's precompiled release\n  artifacts now has the `all-arch` feature enabled.\n  [#5657](https://github.com/bytecodealliance/wasmtime/pull/5657)\n\n### Changed\n\n* Equality of `wasmtime::component::Val::Float{32,64}` now considers NaNs as\n  equal for assistance when fuzzing.\n  [#5535](https://github.com/bytecodealliance/wasmtime/pull/5535)\n\n* WIT syntax supported by `wasmtime::component::bindgen!` has been updated in\n  addition to the generated code being updated.\n  [#5565](https://github.com/bytecodealliance/wasmtime/pull/5565)\n  [#5692](https://github.com/bytecodealliance/wasmtime/pull/5692)\n  [#5694](https://github.com/bytecodealliance/wasmtime/pull/5694)\n\n* Cranelift's egraph-based optimization framework is now enabled by default.\n  [#5587](https://github.com/bytecodealliance/wasmtime/pull/5587)\n\n* The old `PoolingAllocationStrategy` type has been removed in favor of a more\n  flexible configuration via a new option\n  `PoolingAllocationConfig::max_unused_warm_slots` which is more flexible and\n  subsumes the previous use cases for each strategy.\n  [#5661](https://github.com/bytecodealliance/wasmtime/pull/5661)\n\n* Creation of `InstancePre` through `Linker::instantiate_pre` no longer requires\n  a `Store` to be provided. Instead a `Store`-related argument is now required\n  on `Linker::define`-style APIs instead.\n  [#5683](https://github.com/bytecodealliance/wasmtime/pull/5683)\n\n### Fixed\n\n* Compilation for FreeBSD on x86\\_64 and AArch64 has been fixed.\n  [#5606](https://github.com/bytecodealliance/wasmtime/pull/5606)\n\n--------------------------------------------------------------------------------\n\n## 5.0.0\n\nReleased 2023-01-20\n\n### Added\n\n* A `wasmtime::component::bingen!` macro has been added for generating bindings\n  from `*.wit` files. Note that WIT is still heavily in development so this is\n  more of a preview of what will be as opposed to a finished feature.\n  [#5317](https://github.com/bytecodealliance/wasmtime/pull/5317)\n  [#5397](https://github.com/bytecodealliance/wasmtime/pull/5397)\n\n* The `wasmtime settings` CLI command now has a `--json` option for\n  machine-readable output.\n  [#5411](https://github.com/bytecodealliance/wasmtime/pull/5411)\n\n* Wiggle-generated bindings can now generate the trait for either `&mut self` or\n  `&self`.\n  [#5428](https://github.com/bytecodealliance/wasmtime/pull/5428)\n\n* The `wiggle` crate has more convenience APIs for working with guest data\n  that resides in shared memory.\n  [#5471](https://github.com/bytecodealliance/wasmtime/pull/5471)\n  [#5475](https://github.com/bytecodealliance/wasmtime/pull/5475)\n\n### Changed\n\n* Cranelift's egraph support has been rewritten and updated. This functionality\n  is still gated behind a flag and may become the default in the next release.\n  [#5382](https://github.com/bytecodealliance/wasmtime/pull/5382)\n\n* The implementation of codegen for WebAssembly linear memory has changed\n  significantly internally in Cranelift, moving more responsibility to the\n  Wasmtime embedding rather than Cranelift itself. This should have no\n  user-visible change, however.\n  [#5386](https://github.com/bytecodealliance/wasmtime/pull/5386)\n\n* The `Val::Float32` and `Val::Float64` variants for components now store `f32`\n  and `f64` instead of the bit representation.\n  [#5510](https://github.com/bytecodealliance/wasmtime/pull/5510)\n\n### Fixed\n\n* Handling of DWARF debugging information in components with multiple modules\n  has been fixed to ensure the right info is used for each module.\n  [#5358](https://github.com/bytecodealliance/wasmtime/pull/5358)\n\n--------------------------------------------------------------------------------\n\n## 4.0.0\n\nReleased 2022-12-20\n\n### Added\n\n* Dynamic memories are now supported with the pooling instance allocator which\n  can possibly reduce the number of page faults throughout execution at the cost\n  of slower to run code. Page faults are primarily reduced by avoiding\n  releasing memory back to the system, relying on bounds checks to keep the\n  memory inaccessible.\n  [#5208](https://github.com/bytecodealliance/wasmtime/pull/5208)\n\n* The `wiggle` generator now supports function-level control over `tracing`\n  calls.\n  [#5194](https://github.com/bytecodealliance/wasmtime/pull/5194)\n\n* Support has been added to `wiggle` to be compatible with shared memories.\n  [#5225](https://github.com/bytecodealliance/wasmtime/pull/5225)\n  [#5229](https://github.com/bytecodealliance/wasmtime/pull/5229)\n  [#5264](https://github.com/bytecodealliance/wasmtime/pull/5264)\n  [#5268](https://github.com/bytecodealliance/wasmtime/pull/5268)\n  [#5054](https://github.com/bytecodealliance/wasmtime/pull/5054)\n\n* The `wiggle` generator now supports a \"trappable error\" configuration to\n  improve error conversions to guest errors and ensure that no host errors are\n  forgotten or accidentally become traps. The `wasi-common` crate has been\n  updated to use this.\n  [#5276](https://github.com/bytecodealliance/wasmtime/pull/5276)\n  [#5279](https://github.com/bytecodealliance/wasmtime/pull/5279)\n\n* The `memory.atomic.{notify,wait32,wait64}` instructions are now all\n  implemented in Wasmtime.\n  [#5255](https://github.com/bytecodealliance/wasmtime/pull/5255)\n  [#5311](https://github.com/bytecodealliance/wasmtime/pull/5311)\n\n* A `wasm_config_parallel_compilation_set` configuration function has been added\n  to the C API.\n  [#5298](https://github.com/bytecodealliance/wasmtime/pull/5298)\n\n* The `wasmtime` CLI can have its input module piped into it from stdin now.\n  [#5342](https://github.com/bytecodealliance/wasmtime/pull/5342)\n\n* `WasmBacktrace::{capture,force_capture}` methods have been added to\n  programmatically capture a backtrace outside of a trapping context.\n  [#5341](https://github.com/bytecodealliance/wasmtime/pull/5341)\n\n### Changed\n\n* The `S` type parameter on `Func::typed` and `Instance::get_typed_func` has\n  been removed and no longer needs to be specified.\n  [#5275](https://github.com/bytecodealliance/wasmtime/pull/5275)\n\n* The `SharedMemory::data` method now returns `&[UnsafeCell<u8>]` instead of the\n  prior raw slice return.\n  [#5240](https://github.com/bytecodealliance/wasmtime/pull/5240)\n\n* Creation of a `WasiCtx` will no longer unconditionally acquire randomness from\n  the OS, instead using the `rand::thread_rng()` function in Rust which is only\n  periodically reseeded with randomness from the OS.\n  [#5244](https://github.com/bytecodealliance/wasmtime/pull/5244)\n\n* Codegen of dynamically-bounds-checked wasm memory accesses has been improved.\n  [#5190](https://github.com/bytecodealliance/wasmtime/pull/5190)\n\n* Wasmtime will now emit inline stack probes in generated functions for x86\\_64,\n  aarch64, and riscv64 architectures. This guarantees a process abort if an\n  engine was misconfigured to give wasm too much stack instead of optionally\n  allowing wasm to skip the guard page.\n  [#5350](https://github.com/bytecodealliance/wasmtime/pull/5350)\n  [#5353](https://github.com/bytecodealliance/wasmtime/pull/5353)\n\n### Fixed\n\n* Dropping a `Module` will now release kernel resources in-use by the pooling\n  allocator when enabled instead of waiting for a new instance to be\n  re-instantiated into prior slots.\n  [#5321](https://github.com/bytecodealliance/wasmtime/pull/5321)\n\n--------------------------------------------------------------------------------\n\n## 3.0.1\n\nReleased 2022-12-01.\n\n### Fixed\n\n* The instruction cache is now flushed for AArch64 Android.\n  [#5331](https://github.com/bytecodealliance/wasmtime/pull/5331)\n\n* Building for FreeBSD and Android has been fixed.\n  [#5323](https://github.com/bytecodealliance/wasmtime/pull/5323)\n\n--------------------------------------------------------------------------------\n\n## 3.0.0\n\nReleased 2022-11-21\n\n### Added\n\n* New `WasiCtx::{push_file, push_dir}` methods exist for embedders to add their\n  own objects.\n  [#5027](https://github.com/bytecodealliance/wasmtime/pull/5027)\n\n* Wasmtime's `component-model` support now supports `async` host functions and\n  embedding in the same manner as core wasm.\n  [#5055](https://github.com/bytecodealliance/wasmtime/pull/5055)\n\n* The `wasmtime` CLI executable now supports a `--max-wasm-stack` flag.\n  [#5156](https://github.com/bytecodealliance/wasmtime/pull/5156)\n\n* AOT compilation support has been implemented for components (aka the\n  `component-model` feature of the Wasmtime crate).\n  [#5160](https://github.com/bytecodealliance/wasmtime/pull/5160)\n\n* A new `wasi_config_set_stdin_bytes` function is available in the C API to set\n  the stdin of a WASI-using module from an in-memory slice.\n  [#5179](https://github.com/bytecodealliance/wasmtime/pull/5179)\n\n* When using the pooling allocator there are now options to reset memory with\n  `memset` instead of `madvisev` on Linux to keep pages resident in memory to\n  reduce page faults when reusing linear memory slots.\n  [#5207](https://github.com/bytecodealliance/wasmtime/pull/5207)\n\n### Changed\n\n* Consuming 0 fuel with 0 fuel left is now considered to succeed. Additionally a\n  store may not consume its last unit of fuel.\n  [#5013](https://github.com/bytecodealliance/wasmtime/pull/5013)\n\n* A number of variants in the `wasi_common::ErrorKind` enum have been removed.\n  [#5015](https://github.com/bytecodealliance/wasmtime/pull/5015)\n\n* Methods on `WasiDir` now error-by-default instead of requiring a definition by\n  default.\n  [#5019](https://github.com/bytecodealliance/wasmtime/pull/5019)\n\n* Bindings generated by the `wiggle` crate now always depend on the `wasmtime`\n  crate meaning crates like `wasi-common` no longer compile for platforms such\n  as `wasm32-unknown-emscripten`.\n  [#5137](https://github.com/bytecodealliance/wasmtime/pull/5137)\n\n* Error handling in the `wasmtime` crate's API has been changed to primarily\n  work with `anyhow::Error` for custom errors. The `Trap` type has been replaced\n  with a simple `enum Trap { ... }` and backtrace information is now stored as a\n  `WasmBacktrace` type inserted as context into an `anyhow::Error`.\n  Host-functions are expected to return `anyhow::Result<T>` instead of the prior\n  `Trap` error return from before. Additionally the old `Trap::i32_exit`\n  constructor is now a concrete `wasi_commont::I32Exit` type which can be tested\n  for with a `downcast_ref` on the error returned from Wasmtime.\n  [#5149](https://github.com/bytecodealliance/wasmtime/pull/5149)\n\n* Configuration of the pooling allocator is now done through a builder-style\n  `PoolingAllocationConfig` API instead of the prior enum-variant API.\n  [#5205](https://github.com/bytecodealliance/wasmtime/pull/5205)\n\n### Fixed\n\n* The instruction cache is now properly flushed for AArch64 on Windows.\n  [#4997](https://github.com/bytecodealliance/wasmtime/pull/4997)\n\n* Backtrace capturing with many sequences of wasm->host calls on the stack no\n  longer exhibit quadratic capturing behavior.\n  [#5049](https://github.com/bytecodealliance/wasmtime/pull/5049)\n\n--------------------------------------------------------------------------------\n\n## 2.0.2\n\nReleased 2022-11-10.\n\n### Fixed\n\n* [CVE-2022-39392] - modules may perform out-of-bounds reads/writes when the\n  pooling allocator was configured with `memory_pages: 0`.\n\n* [CVE-2022-39393] - data can be leaked between instances when using the pooling\n  allocator.\n\n* [CVE-2022-39394] - An incorrect Rust signature for the C API\n  `wasmtime_trap_code` function could lead to an out-of-bounds write of three\n  zero bytes.\n\n[CVE-2022-39392]: https://github.com/bytecodealliance/wasmtime/security/advisories/GHSA-44mr-8vmm-wjhg\n[CVE-2022-39393]: https://github.com/bytecodealliance/wasmtime/security/advisories/GHSA-wh6w-3828-g9qf\n[CVE-2022-39394]: https://github.com/bytecodealliance/wasmtime/security/advisories/GHSA-h84q-m8rr-3v9q\n\n--------------------------------------------------------------------------------\n\n## 2.0.1\n\nReleased 2022-10-27.\n\n### Fixed\n\n* A compilation error when building only the `wasmtime` crate on Windows with\n  only the default features enabled has been fixed.\n  [#5134](https://github.com/bytecodealliance/wasmtime/pull/5134)\n\n### Changed\n\n* The `rayon` dependency added to `cranelift-isle` in 2.0.0 has been removed to\n  improve the compile time of the `cranelift-codegen` crate.\n  [#5101](https://github.com/bytecodealliance/wasmtime/pull/5101)\n\n--------------------------------------------------------------------------------\n\n## 2.0.0\n\nReleased 2022-10-20\n\n### Added\n\n* Cranelift has gained support for forward-edge CFI on the AArch64 backend.\n  [#3693](https://github.com/bytecodealliance/wasmtime/pull/3693)\n\n* A `--disable-parallel-compilation` CLI flag is now implemented for `wasmtime`.\n  [#4911](https://github.com/bytecodealliance/wasmtime/pull/4911)\n\n* [Tier 3] support has been added for for RISC-V 64 with a new backend in\n  Cranelift for this architecture.\n  [#4271](https://github.com/bytecodealliance/wasmtime/pull/4271)\n\n* Basic [tier 3] support for Windows ARM64 has been added but features such as\n  traps don't work at this time.\n  [#4990](https://github.com/bytecodealliance/wasmtime/pull/4990)\n\n### Changed\n\n* The implementation of the `random_get` function in `wasi-common` is now faster\n  by using a userspace CSPRNG rather than the OS for randomness.\n  [#4917](https://github.com/bytecodealliance/wasmtime/pull/4917)\n\n* The AArch64 backend has completed its transition to ISLE.\n  [#4851](https://github.com/bytecodealliance/wasmtime/pull/4851)\n  [#4866](https://github.com/bytecodealliance/wasmtime/pull/4866)\n  [#4898](https://github.com/bytecodealliance/wasmtime/pull/4898)\n  [#4884](https://github.com/bytecodealliance/wasmtime/pull/4884)\n  [#4820](https://github.com/bytecodealliance/wasmtime/pull/4820)\n  [#4913](https://github.com/bytecodealliance/wasmtime/pull/4913)\n  [#4942](https://github.com/bytecodealliance/wasmtime/pull/4942)\n  [#4943](https://github.com/bytecodealliance/wasmtime/pull/4943)\n\n* The size of the `sigaltstack` allocated per-thread for signal handling has\n  been increased from 16k to 64k.\n  [#4964](https://github.com/bytecodealliance/wasmtime/pull/4964)\n\n\n[Tier 3]: https://docs.wasmtime.dev/stability-tiers.html\n\n--------------------------------------------------------------------------------\n\n## 1.0.2\n\nReleased 2022-11-10.\n\n### Fixed\n\n* [CVE-2022-39392] - modules may perform out-of-bounds reads/writes when the\n  pooling allocator was configured with `memory_pages: 0`.\n\n* [CVE-2022-39393] - data can be leaked between instances when using the pooling\n  allocator.\n\n* [CVE-2022-39394] - An incorrect Rust signature for the C API\n  `wasmtime_trap_code` function could lead to an out-of-bounds write of three\n  zero bytes.\n\n--------------------------------------------------------------------------------\n\n## 1.0.1\n\nReleased 2022-09-26\n\nThis is a patch release that incorporates a fix for a miscompilation of an\natomic-CAS operator on aarch64. The instruction is not usable from Wasmtime\nwith default settings, but may be used if the Wasm atomics extension is\nenabled. The bug may also be reachable via other uses of Cranelift. Thanks to\n@bjorn3 for reporting and debugging this issue!\n\n### Fixed\n\n* Fixed a miscompilation of `atomic_cas` on aarch64. The output register was\n  swapped with a temporary register in the register-allocator constraints.\n  [#4959](https://github.com/bytecodealliance/wasmtime/pull/4959)\n  [#4960](https://github.com/bytecodealliance/wasmtime/pull/4960)\n\n--------------------------------------------------------------------------------\n\n## 1.0.0\n\nReleased 2022-09-20\n\nThis release marks the official 1.0 release of Wasmtime and represents the\nculmination of the work amongst over 300 contributors. Wasmtime has been\nbattle-tested in production through multiple embeddings for quite some time now\nand we're confident in releasing a 1.0 version to signify the stability and\nquality of the Wasmtime engine.\n\nMore information about Wasmtime's 1.0 release is on the [Bytecode Alliance's\nblog][ba-blog] with separate posts on [Wasmtime's performance\nfeatures][ba-perf], [Wasmtime's security story][ba-security], and [the 1.0\nrelease announcement][ba-1.0].\n\nAs a reminder the 2.0 release of Wasmtime is scheduled for one month from now on\nOctober 20th. For more information see the [RFC on Wasmtime's 1.0\nrelease][rfc-1.0].\n\n[ba-blog]: https://bytecodealliance.org/articles/\n[ba-perf]: https://bytecodealliance.org/articles/wasmtime-10-performance\n[ba-security]: https://bytecodealliance.org/articles/security-and-correctness-in-wasmtime\n[ba-1.0]: https://bytecodealliance.org/articles/wasmtime-1-0-fast-safe-and-now-production-ready.md\n[rfc-1.0]: https://github.com/bytecodealliance/rfcs/blob/main/accepted/wasmtime-one-dot-oh.md\n\n### Added\n\n* An incremental compilation cache for Cranelift has been added which can be\n  enabled with `Config::enable_incremental_compilation`, and this option is\n  disabled by default for now. The incremental compilation cache has been\n  measured to improve compile times for cold uncached modules as well due to\n  some wasm modules having similar-enough functions internally.\n  [#4551](https://github.com/bytecodealliance/wasmtime/pull/4551)\n\n* Source tarballs are now available as part of Wasmtime's release artifacts.\n  [#4294](https://github.com/bytecodealliance/wasmtime/pull/4294)\n\n* WASI APIs that specify the REALTIME clock are now supported.\n  [#4777](https://github.com/bytecodealliance/wasmtime/pull/4777)\n\n* WASI's socket functions are now fully implemented.\n  [#4776](https://github.com/bytecodealliance/wasmtime/pull/4776)\n\n* The native call stack for async-executed wasm functions are no longer\n  automatically reset to zero after the stack is returned to the pool when using\n  the pooling allocator. A `Config::async_stack_zeroing` option has been added\n  to restore the old behavior of zero-on-return-to-pool.\n  [#4813](https://github.com/bytecodealliance/wasmtime/pull/4813)\n\n* Inline stack probing has been implemented for the Cranelift x64 backend.\n  [#4747](https://github.com/bytecodealliance/wasmtime/pull/4747)\n\n### Changed\n\n* Generating of native unwind information has moved from a\n  `Config::wasm_backtrace` option to a new `Config::native_unwind_info` option\n  and is enabled by default.\n  [#4643](https://github.com/bytecodealliance/wasmtime/pull/4643)\n\n* The `memory-init-cow` feature is now enabled by default in the C API.\n  [#4690](https://github.com/bytecodealliance/wasmtime/pull/4690)\n\n* Back-edge CFI is now enabled by default on AArch64 macOS.\n  [#4720](https://github.com/bytecodealliance/wasmtime/pull/4720)\n\n* WASI calls will no longer return NOTCAPABLE in preparation for the removal of\n  the rights system from WASI.\n  [#4666](https://github.com/bytecodealliance/wasmtime/pull/4666)\n\n### Internal\n\nThis section of the release notes shouldn't affect external users since no\npublic-facing APIs are affected, but serves as a place to document larger\nchanges internally within Wasmtime.\n\n* Differential fuzzing has been refactored and improved into one fuzzing target\n  which can execute against any of Wasmtime itself (configured differently),\n  wasmi, V8, or the spec interpreter. Fuzzing now executes each exported\n  function with fuzz-generated inputs and the contents of all of memory and each\n  exported global is compared after each execution. Additionally more\n  interesting shapes of modules are also possible to generate.\n  [#4515](https://github.com/bytecodealliance/wasmtime/pull/4515)\n  [#4735](https://github.com/bytecodealliance/wasmtime/pull/4735)\n  [#4737](https://github.com/bytecodealliance/wasmtime/pull/4737)\n  [#4739](https://github.com/bytecodealliance/wasmtime/pull/4739)\n  [#4774](https://github.com/bytecodealliance/wasmtime/pull/4774)\n  [#4773](https://github.com/bytecodealliance/wasmtime/pull/4773)\n  [#4845](https://github.com/bytecodealliance/wasmtime/pull/4845)\n  [#4672](https://github.com/bytecodealliance/wasmtime/pull/4672)\n  [#4674](https://github.com/bytecodealliance/wasmtime/pull/4674)\n\n* The x64 backend for Cranelift has been fully migrated to ISLE.\n  [#4619](https://github.com/bytecodealliance/wasmtime/pull/4619)\n  [#4625](https://github.com/bytecodealliance/wasmtime/pull/4625)\n  [#4645](https://github.com/bytecodealliance/wasmtime/pull/4645)\n  [#4650](https://github.com/bytecodealliance/wasmtime/pull/4650)\n  [#4684](https://github.com/bytecodealliance/wasmtime/pull/4684)\n  [#4704](https://github.com/bytecodealliance/wasmtime/pull/4704)\n  [#4718](https://github.com/bytecodealliance/wasmtime/pull/4718)\n  [#4726](https://github.com/bytecodealliance/wasmtime/pull/4726)\n  [#4722](https://github.com/bytecodealliance/wasmtime/pull/4722)\n  [#4729](https://github.com/bytecodealliance/wasmtime/pull/4729)\n  [#4730](https://github.com/bytecodealliance/wasmtime/pull/4730)\n  [#4741](https://github.com/bytecodealliance/wasmtime/pull/4741)\n  [#4763](https://github.com/bytecodealliance/wasmtime/pull/4763)\n  [#4772](https://github.com/bytecodealliance/wasmtime/pull/4772)\n  [#4780](https://github.com/bytecodealliance/wasmtime/pull/4780)\n  [#4787](https://github.com/bytecodealliance/wasmtime/pull/4787)\n  [#4793](https://github.com/bytecodealliance/wasmtime/pull/4793)\n  [#4809](https://github.com/bytecodealliance/wasmtime/pull/4809)\n\n* The AArch64 backend for Cranelift has seen significant progress in being\n  ported to ISLE.\n  [#4608](https://github.com/bytecodealliance/wasmtime/pull/4608)\n  [#4639](https://github.com/bytecodealliance/wasmtime/pull/4639)\n  [#4634](https://github.com/bytecodealliance/wasmtime/pull/4634)\n  [#4748](https://github.com/bytecodealliance/wasmtime/pull/4748)\n  [#4750](https://github.com/bytecodealliance/wasmtime/pull/4750)\n  [#4751](https://github.com/bytecodealliance/wasmtime/pull/4751)\n  [#4753](https://github.com/bytecodealliance/wasmtime/pull/4753)\n  [#4788](https://github.com/bytecodealliance/wasmtime/pull/4788)\n  [#4796](https://github.com/bytecodealliance/wasmtime/pull/4796)\n  [#4785](https://github.com/bytecodealliance/wasmtime/pull/4785)\n  [#4819](https://github.com/bytecodealliance/wasmtime/pull/4819)\n  [#4821](https://github.com/bytecodealliance/wasmtime/pull/4821)\n  [#4832](https://github.com/bytecodealliance/wasmtime/pull/4832)\n\n* The s390x backend has seen improvements and additions to fully support the\n  Cranelift backend for rustc.\n  [#4682](https://github.com/bytecodealliance/wasmtime/pull/4682)\n  [#4702](https://github.com/bytecodealliance/wasmtime/pull/4702)\n  [#4616](https://github.com/bytecodealliance/wasmtime/pull/4616)\n  [#4680](https://github.com/bytecodealliance/wasmtime/pull/4680)\n\n* Significant improvements have been made to Cranelift-based fuzzing with more\n  supported features and more instructions being fuzzed.\n  [#4589](https://github.com/bytecodealliance/wasmtime/pull/4589)\n  [#4591](https://github.com/bytecodealliance/wasmtime/pull/4591)\n  [#4665](https://github.com/bytecodealliance/wasmtime/pull/4665)\n  [#4670](https://github.com/bytecodealliance/wasmtime/pull/4670)\n  [#4590](https://github.com/bytecodealliance/wasmtime/pull/4590)\n  [#4375](https://github.com/bytecodealliance/wasmtime/pull/4375)\n  [#4519](https://github.com/bytecodealliance/wasmtime/pull/4519)\n  [#4696](https://github.com/bytecodealliance/wasmtime/pull/4696)\n  [#4700](https://github.com/bytecodealliance/wasmtime/pull/4700)\n  [#4703](https://github.com/bytecodealliance/wasmtime/pull/4703)\n  [#4602](https://github.com/bytecodealliance/wasmtime/pull/4602)\n  [#4713](https://github.com/bytecodealliance/wasmtime/pull/4713)\n  [#4738](https://github.com/bytecodealliance/wasmtime/pull/4738)\n  [#4667](https://github.com/bytecodealliance/wasmtime/pull/4667)\n  [#4782](https://github.com/bytecodealliance/wasmtime/pull/4782)\n  [#4783](https://github.com/bytecodealliance/wasmtime/pull/4783)\n  [#4800](https://github.com/bytecodealliance/wasmtime/pull/4800)\n\n* Optimization work on cranelift has continued across various dimensions for\n  some modest compile-time improvements.\n  [#4621](https://github.com/bytecodealliance/wasmtime/pull/4621)\n  [#4701](https://github.com/bytecodealliance/wasmtime/pull/4701)\n  [#4697](https://github.com/bytecodealliance/wasmtime/pull/4697)\n  [#4711](https://github.com/bytecodealliance/wasmtime/pull/4711)\n  [#4710](https://github.com/bytecodealliance/wasmtime/pull/4710)\n  [#4829](https://github.com/bytecodealliance/wasmtime/pull/4829)\n\n--------------------------------------------------------------------------------\n\n## 0.40.0\n\nReleased 2022-08-20\n\nThis was a relatively quiet release in terms of user-facing features where most\nof the work was around the internals of Wasmtime and Cranelift. Improvements\ninternally have been made along the lines of:\n\n* Many more instructions are now implemented with ISLE instead of handwritten\n  lowerings.\n* Many improvements to the cranelift-based fuzzing.\n* Many platform improvements for s390x including full SIMD support, running\n  `rustc_codegen_cranelift` with features like `i128`, supporting more\n  ABIs, etc.\n* Much more of the component model has been implemented and is now fuzzed.\n\nFinally this release is currently scheduled to be the last `0.*` release of\nWasmtime. The upcoming release of Wasmtime on September 20 is planned to be\nWasmtime's 1.0 release. More information about what 1.0 means for Wasmtime is\navailable in the [1.0 RFC]\n\n[1.0 RFC]: https://github.com/bytecodealliance/rfcs/blob/main/accepted/wasmtime-one-dot-oh.md\n\n### Added\n\n* Stack walking has been reimplemented with frame pointers rather than with\n  native unwind information. This means that backtraces are feasible to capture\n  in performance-critical environments and in general stack walking is much\n  faster than before.\n  [#4431](https://github.com/bytecodealliance/wasmtime/pull/4431)\n\n* The WebAssembly `simd` proposal is now fully implemented for the s390x\n  backend.\n  [#4427](https://github.com/bytecodealliance/wasmtime/pull/4427)\n\n* Support for AArch64 has been added in the experimental native debuginfo\n  support that Wasmtime has.\n  [#4468](https://github.com/bytecodealliance/wasmtime/pull/4468)\n\n* Support building the C API of Wasmtime with CMake has been added.\n  [#4369](https://github.com/bytecodealliance/wasmtime/pull/4369)\n\n* Clarification was added to Wasmtime's documentation about \"tiers of support\"\n  for various features.\n  [#4479](https://github.com/bytecodealliance/wasmtime/pull/4479)\n\n### Fixed\n\n* Support for `filestat_get` has been improved for stdio streams in WASI.\n  [#4531](https://github.com/bytecodealliance/wasmtime/pull/4531)\n\n* Enabling the `vtune` feature no longer breaks builds on AArch64.\n  [#4533](https://github.com/bytecodealliance/wasmtime/pull/4533)\n\n--------------------------------------------------------------------------------\n\n## 0.39.1\n\nReleased 2022-07-20.\n\n### Fixed\n\n* An s390x-specific codegen bug in addition to a mistake introduced in the fix\n  of CVE-2022-31146 were fixed.\n  [#4490](https://github.com/bytecodealliance/wasmtime/pull/4490)\n\n--------------------------------------------------------------------------------\n\n## 0.39.0\n\nReleased 2022-07-20\n\n### Added\n\n* Initial support for shared memories and the `threads` WebAssembly proposal\n  has been added. Note that this feature is still experimental and not ready\n  for production use yet.\n  [#4187](https://github.com/bytecodealliance/wasmtime/pull/4187)\n\n* A new `Linker::define_unknown_imports_as_traps` method and\n  `--trap-unknown-imports` CLI flag have been added to conveniently support\n  running modules with imports that aren't dynamically called at runtime.\n  [#4312](https://github.com/bytecodealliance/wasmtime/pull/4312)\n\n* The VTune profiling strategy can now be selected through the C API.\n  [#4316](https://github.com/bytecodealliance/wasmtime/pull/4316)\n\n### Changed\n\n* Some methods on the `Config` structure now return `&mut Self` instead of\n  `Result<&mut Self>` since the validation is deferred until `Engine::new`:\n  `profiler`, `cranelift_flag_enable`, `cranelift_flag_set`, `max_wasm_stack`,\n  `async_stack_size`, and `strategy`.\n  [#4252](https://github.com/bytecodealliance/wasmtime/pull/4252)\n  [#4262](https://github.com/bytecodealliance/wasmtime/pull/4262)\n\n* Parallel compilation of WebAssembly modules is now enabled in the C API by\n  default.\n  [#4270](https://github.com/bytecodealliance/wasmtime/pull/4270)\n\n* Implicit Cargo features of the `wasmtime` introduced through `optional`\n  dependencies may have been removed since namespaced features are now used.\n  It's recommended to only used the set of named `[features]` for Wasmtime.\n  [#4293](https://github.com/bytecodealliance/wasmtime/pull/4293)\n\n* Register allocation has fixed a few issues related to excessive memory usage\n  at compile time.\n  [#4324](https://github.com/bytecodealliance/wasmtime/pull/4324)\n\n### Fixed\n\n* A refactor of `Config` was made to fix an issue that the order of calls to `Config`\n  matters now, which may lead to unexpected behavior.\n  [#4252](https://github.com/bytecodealliance/wasmtime/pull/4252)\n  [#4262](https://github.com/bytecodealliance/wasmtime/pull/4262)\n\n* Wasmtime has been fixed to work on SSE2-only x86\\_64 platforms when the\n  `simd` feature is disabled in `Config`.\n  [#4231](https://github.com/bytecodealliance/wasmtime/pull/4231)\n\n* Generation of platform-specific unwinding information is disabled if\n  `wasm_backtrace` and `wasm_reference_types` are both disabled.\n  [#4351](https://github.com/bytecodealliance/wasmtime/pull/4351)\n\n--------------------------------------------------------------------------------\n\n## 0.38.3\n\nReleased 2022-07-20.\n\n### Fixed.\n\n* An s390x-specific codegen bug in addition to a mistake introduced in the fix\n  of CVE-2022-31146 were fixed.\n  [#4491](https://github.com/bytecodealliance/wasmtime/pull/4491)\n\n--------------------------------------------------------------------------------\n\n## 0.38.2\n\nReleased 2022-07-20.\n\n### Fixed.\n\n* A miscompilation when handling constant divisors on AArch64 has been fixed.\n  [CVE-2022-31169](https://github.com/bytecodealliance/wasmtime/security/advisories/GHSA-7f6x-jwh5-m9r4)\n\n* A use-after-free possible with accidentally missing stack maps has been fixed.\n  [CVE-2022-31146](https://github.com/bytecodealliance/wasmtime/security/advisories/GHSA-5fhj-g3p3-pq9g)\n\n--------------------------------------------------------------------------------\n\n## 0.38.1\n\nReleased 2022-06-27.\n\n### Fixed.\n\n* A register allocator bug was fixed that could affect direct users of\n  Cranelift who use struct-return (`sret`) arguments. The bug had to do with\n  the handling of physical register constraints in the function prologue. No\n  impact should be possible for users of Cranelift via the Wasm frontend,\n  including Wasmtime.\n  [regalloc2#60](https://github.com/bytecodealliance/regalloc2/pull/60)\n  [#4333](https://github.com/bytecodealliance/wasmtime/pull/4333)\n\n* Lowering bugs for the `i8x16.swizzle` and `select`-with-`v128`-inputs\n  instructions were fixed for the x86\\_64 code generator. Note that aarch64 and\n  s390x are unaffected.\n  [#4334](https://github.com/bytecodealliance/wasmtime/pull/4334)\n\n* A bug in the 8-bit lowering of integer division on x86-64 was fixed in\n  Cranelift that could cause a register allocator panic due to an undefined\n  value in a register. (The divide instruction does not take a register `rdx`\n  as a source when 8 bits but the metadata incorrectly claimed it did.) No\n  impact on Wasm/Wasmtime users, and impact on direct Cranelift embedders\n  limited to compilation panics.\n  [#4332](https://github.com/bytecodealliance/wasmtime/pull/4332)\n\n--------------------------------------------------------------------------------\n\n## 0.38.0\n\nReleased 2022-06-21\n\n### Added\n\n* Enabling or disabling NaN canonicalization in generated code is now exposed\n  through the C API.\n  [#4154](https://github.com/bytecodealliance/wasmtime/pull/4154)\n\n* A user-defined callback can now be invoked when an epoch interruption happens\n  via the `Store::epoch_deadline_callback` API.\n  [#4152](https://github.com/bytecodealliance/wasmtime/pull/4152)\n\n* Basic alias analysis with redundant-load elimintation and store-to-load\n  forwarding optimizations has been added to Cranelift.\n  [#4163](https://github.com/bytecodealliance/wasmtime/pull/4163)\n\n### Changed\n\n* Traps originating from epoch-based interruption are now exposed as\n  `TrapCode::Interrupt`.\n  [#4105](https://github.com/bytecodealliance/wasmtime/pull/4105)\n\n* Binary builds for AArch64 now require glibc 2.17 and for s390x require glibc\n  2.16. Previously glibc 2.28 was required.\n  [#4171](https://github.com/bytecodealliance/wasmtime/pull/4171)\n\n* The `wasmtime::ValRaw` now has all of its fields listed as private and instead\n  constructors/accessors are provided for getting at the internal data.\n  [#4186](https://github.com/bytecodealliance/wasmtime/pull/4186)\n\n* The `wasm-backtrace` Cargo feature has been removed in favor of a\n  `Config::wasm_backtrace` runtime configuration option. Additionally backtraces\n  are now only captured when an embedder-generated trap actually reaches a\n  WebAssembly call stack.\n  [#4183](https://github.com/bytecodealliance/wasmtime/pull/4183)\n\n* Usage of `*_unchecked` APIs for `Func` in the `wasmtime` crate and C API now\n  take a `usize` parameter indicating the number of `ValRaw` values behind\n  the associated pointer.\n  [#4192](https://github.com/bytecodealliance/wasmtime/pull/4192)\n\n### Fixed\n\n* An improvement was made to the spill-slot allocation in code generation to fix\n  an issue where some stack slots accidentally weren't reused. This issue was\n  introduced with the landing of regalloc2 in 0.37.0 and may have resulted in\n  larger-than-intended increases in stack frame sizes.\n  [#4222](https://github.com/bytecodealliance/wasmtime/pull/4222)\n\n--------------------------------------------------------------------------------\n\n## 0.37.0\n\nReleased 2022-05-20\n\n### Added\n\n* Updated Cranelift to use regalloc2, a new register allocator. This should\n  result in ~20% faster compile times, and for programs that suffered from\n  register-allocation pressure before, up to ~20% faster generated code.\n  [#3989](https://github.com/bytecodealliance/wasmtime/pull/3989)\n\n* Pre-built binaries for macOS M1 machines are now available as release\n  artifacts.\n  [#3983](https://github.com/bytecodealliance/wasmtime/pull/3983)\n\n* Copy-on-write images of memory can now be manually initialized for a `Module`\n  with an explicit method call, but it is still not required to call this method\n  and will automatically otherwise happen on the first instantiation.\n  [#3964](https://github.com/bytecodealliance/wasmtime/pull/3964)\n\n### Fixed\n\n* Using `InstancePre::instantiate` or `Linker::instantiate` will now panic as\n  intended when used with an async-configured `Store`.\n  [#3972](https://github.com/bytecodealliance/wasmtime/pull/3972)\n\n### Changed\n\n* The unsafe `ValRaw` type in the `wasmtime` crate now always stores its values\n  in little-endian format instead of the prior native-endian format. Users of\n  `ValRaw` are recommended to audit their existing code for usage to continue\n  working on big-endian platforms.\n  [#4035](https://github.com/bytecodealliance/wasmtime/pull/4035)\n\n### Removed\n\n* Support for `Config::paged_memory_initialization` and the `uffd` crate feature\n  have been removed from the `wasmtime` crate. Users should migrate to using\n  `Config::memory_init_cow` which is more portable and faster at this point.\n  [#4040](https://github.com/bytecodealliance/wasmtime/pull/4040)\n\n--------------------------------------------------------------------------------\n\n## 0.36.0\n\nReleased 2022-04-20\n\n### Added\n\n* Support for epoch-based interruption has been added to the C API.\n  [#3925](https://github.com/bytecodealliance/wasmtime/pull/3925)\n\n* Support for disabling libunwind-based backtraces of WebAssembly code at\n  compile time has been added.\n  [#3932](https://github.com/bytecodealliance/wasmtime/pull/3932)\n\n* Async support for call hooks has been added to optionally execute \"blocking\"\n  work whenever a wasm module is entered or exited relative to the host.\n  [#3876](https://github.com/bytecodealliance/wasmtime/pull/3876)\n\n### Fixed\n\n* Loading a `Module` will now check, at runtime, that the compilation settings\n  enabled in a `Config` are compatible with the native host. For example this\n  ensures that if avx2 is enabled that the host actually has avx2 support.\n  [#3899](https://github.com/bytecodealliance/wasmtime/pull/3899)\n\n### Removed\n\n* Support for `Config::interruptable` and `InterruptHandle` has been removed\n  from the `wasmtime` crate. Users should migrate to using epoch-based\n  interruption instead.\n  [#3925](https://github.com/bytecodealliance/wasmtime/pull/3925)\n\n* The module linking implementation of Wasmtime has been removed to make room\n  for the upcoming support for the component model.\n  [#3958](https://github.com/bytecodealliance/wasmtime/pull/3958)\n\n--------------------------------------------------------------------------------\n\n## 0.35.3\n\nReleased 2022-04-11.\n\n### Fixed\n\n* Backported a bugfix for an instruction lowering issue that could cause a\n  regalloc panic due to an undefined register in some cases. No miscompilation\n  was ever possible, but panics would result in a compilation failure.\n  [#4012](https://github.com/bytecodealliance/wasmtime/pull/4012)\n\n--------------------------------------------------------------------------------\n\n## 0.35.2\n\nReleased 2022-03-31.\n\n### Security Fixes\n\n* [CVE-2022-24791](https://github.com/bytecodealliance/wasmtime/security/advisories/GHSA-gwc9-348x-qwv2):\n  Fixed a use after free with `externref`s and epoch interruption.\n\n## 0.35.1\n\nReleased 2022-03-09.\n\n### Fixed\n\n* Fixed a bug in the x86-64 lowering of the `uextend` opcode for narrow (`i8`,\n  `i16`) integer sources when the value is produced by one of several\n  arithmetic instructions.\n  [#3906](https://github.com/bytecodealliance/wasmtime/pull/3906)\n\n## 0.35.0\n\nReleased 2022-03-07.\n\n### Added\n\n* The `wasmtime_wasi::add_to_linker` function now allows providing\n  a context object of a custom type instead of `wasmtime_wasi::WasiCtx`,\n  as long as that type implements the required WASI snapshot traits.\n  This allows, for example, wrapping `WasiCtx` into a struct and providing\n  custom implementations for those traits to override the default behaviour.\n\n### Changed\n\n* WebAssembly tables of `funcref` values are now lazily initialized which can,\n  in some cases, greatly speed up instantiation of a module.\n  [#3733](https://github.com/bytecodealliance/wasmtime/pull/3733)\n\n* The `memfd` feature in 0.34.0, now renamed to `memory-init-cow`, has been\n  enabled by default. This means that, where applicable, WebAssembly linear\n  memories are now initialized with copy-on-write mappings. Support from this\n  has been expanded from Linux-only to include macOS and other Unix systems when\n  modules are loaded from precompiled `*.cwasm` files on disk.\n  [#3777](https://github.com/bytecodealliance/wasmtime/pull/3777)\n  [#3778](https://github.com/bytecodealliance/wasmtime/pull/3778)\n  [#3787](https://github.com/bytecodealliance/wasmtime/pull/3787)\n  [#3819](https://github.com/bytecodealliance/wasmtime/pull/3819)\n  [#3831](https://github.com/bytecodealliance/wasmtime/pull/3831)\n\n* Clarify that SSE 4.2 (and prior) is required for running WebAssembly code with\n  simd support enabled on x86\\_64.\n  [#3816](https://github.com/bytecodealliance/wasmtime/pull/3816)\n  [#3817](https://github.com/bytecodealliance/wasmtime/pull/3817)\n  [#3833](https://github.com/bytecodealliance/wasmtime/pull/3833)\n  [#3825](https://github.com/bytecodealliance/wasmtime/pull/3825)\n\n* Support for profiling with VTune is now enabled at compile time by default,\n  but it remains disabled at runtime by default.\n  [#3821](https://github.com/bytecodealliance/wasmtime/pull/3821)\n\n* The `ModuleLimits` type has been removed from the configuration of the pooling\n  allocator in favor of configuring the total size of an instance allocation\n  rather than each individual field.\n  [#3837](https://github.com/bytecodealliance/wasmtime/pull/3837)\n\n* The native stack size allowed for WebAssembly has been decreased from 1 MiB to\n  512 KiB on all platforms to better accomodate running wasm on the main thread\n  on Windows.\n  [#3861](https://github.com/bytecodealliance/wasmtime/pull/3861)\n\n* The `wasi-common` crate now supports doing polls for both read and write\n  interest on a file descriptor at the same time.\n  [#3866](https://github.com/bytecodealliance/wasmtime/pull/3866)\n\n### Fixed\n\n* The `Store::call_hook` callback is now invoked when entering host functions\n  defined with `*_unchecked` variants.\n  [#3881](https://github.com/bytecodealliance/wasmtime/pull/3881)\n\n### Removed\n\n* The incomplete and unmaintained ARM32 backend has been removed from Cranelift.\n  [#3799](https://github.com/bytecodealliance/wasmtime/pull/3799)\n\n--------------------------------------------------------------------------------\n\n## 0.34.2\n\nReleased 2022-03-31.\n\n### Security Fixes\n\n* [CVE-2022-24791](https://github.com/bytecodealliance/wasmtime/security/advisories/GHSA-gwc9-348x-qwv2):\n  Fixed a use after free with `externref`s and epoch interruption.\n\n## 0.34.1\n\nReleased 2022-02-16.\n\n### Security Fixes\n\n* [CVE-2022-23636](https://github.com/bytecodealliance/wasmtime/security/advisories/GHSA-88xq-w8cq-xfg7):\n  Fixed an invalid drop of a partially-initialized instance in the pooling instance\n  allocator.\n\n## 0.33.1\n\nReleased 2022-02-16.\n\n### Security Fixes\n\n* [CVE-2022-23636](https://github.com/bytecodealliance/wasmtime/security/advisories/GHSA-88xq-w8cq-xfg7):\n  Fixed an invalid drop of a partially-initialized instance in the pooling instance\n  allocator.\n\n## 0.34.0\n\nReleased 2022-02-07.\n\n### Fixed\n\n* The `wasi-common` default implementation of some attributes of files has been\n  updated to ensure that `wasi-libc`'s `isatty` function works as intended.\n  [#3696](https://github.com/bytecodealliance/wasmtime/pull/3696)\n\n* A benign debug assertion related to `externref` and garbage-collection has\n  been fixed.\n  [#3734](https://github.com/bytecodealliance/wasmtime/pull/3734)\n\n### Added\n\n* Function names are now automatically demangled when informing profilers of\n  regions of JIT code to apply Rust-specific demangling rules if applicable.\n  [#3683](https://github.com/bytecodealliance/wasmtime/pull/3683)\n\n* Support for profiling JIT-generated trampolines with VTune has been added.\n  [#3687](https://github.com/bytecodealliance/wasmtime/pull/3687)\n\n* Wasmtime now supports a new method of async preemption dubbed \"epoch-based\n  interruption\" which is intended to be much more efficient than the current\n  fuel-based method of preemption.\n  [#3699](https://github.com/bytecodealliance/wasmtime/pull/3699)\n\n* On Linux Wasmtime will now by default use copy-on-write mappings to initialize\n  memories of wasm modules where possible, accelerating instantiation by\n  avoiding costly memory copies. When combined with the pooling allocator this\n  can also be used to speed up instance-reuse cases due to fewer syscalls to\n  change memory mappings being necessary.\n  [#3697](https://github.com/bytecodealliance/wasmtime/pull/3697)\n  [#3738](https://github.com/bytecodealliance/wasmtime/pull/3738)\n  [#3760](https://github.com/bytecodealliance/wasmtime/pull/3760)\n\n* Wasmtime now supports the recently-added `sock_accept` WASI function.\n  [#3711](https://github.com/bytecodealliance/wasmtime/pull/3711)\n\n* Cranelift now has support for specifying blocks as cold.\n  [#3698](https://github.com/bytecodealliance/wasmtime/pull/3698)\n\n### Changed\n\n* Many more instructions for the x64 backend have been migrated to ISLE,\n  additionally with refactorings to make incorrect lowerings harder to\n  accidentally write.\n  [#3653](https://github.com/bytecodealliance/wasmtime/pull/3653)\n  [#3659](https://github.com/bytecodealliance/wasmtime/pull/3659)\n  [#3681](https://github.com/bytecodealliance/wasmtime/pull/3681)\n  [#3686](https://github.com/bytecodealliance/wasmtime/pull/3686)\n  [#3688](https://github.com/bytecodealliance/wasmtime/pull/3688)\n  [#3690](https://github.com/bytecodealliance/wasmtime/pull/3690)\n  [#3752](https://github.com/bytecodealliance/wasmtime/pull/3752)\n\n* More instructions in the aarch64 backend are now lowered with ISLE.\n  [#3658](https://github.com/bytecodealliance/wasmtime/pull/3658)\n  [#3662](https://github.com/bytecodealliance/wasmtime/pull/3662)\n\n* The s390x backend's lowering rules are now almost entirely defined with ISLE.\n  [#3702](https://github.com/bytecodealliance/wasmtime/pull/3702)\n  [#3703](https://github.com/bytecodealliance/wasmtime/pull/3703)\n  [#3706](https://github.com/bytecodealliance/wasmtime/pull/3706)\n  [#3717](https://github.com/bytecodealliance/wasmtime/pull/3717)\n  [#3723](https://github.com/bytecodealliance/wasmtime/pull/3723)\n  [#3724](https://github.com/bytecodealliance/wasmtime/pull/3724)\n\n* Instantiation of modules in Wasmtime has been further optimized now that the\n  copy-on-write memory initialization removed the previously most-expensive part\n  of instantiating a module.\n  [#3727](https://github.com/bytecodealliance/wasmtime/pull/3727)\n  [#3739](https://github.com/bytecodealliance/wasmtime/pull/3739)\n  [#3741](https://github.com/bytecodealliance/wasmtime/pull/3741)\n  [#3742](https://github.com/bytecodealliance/wasmtime/pull/3742)\n\n--------------------------------------------------------------------------------\n\n## 0.33.0\n\nReleased 2022-01-05.\n\n### Added\n\n* Compiled wasm modules may now optionally omit debugging information about\n  mapping addresses to source locations, resulting in smaller binaries.\n  [#3598](https://github.com/bytecodealliance/wasmtime/pull/3598)\n\n* The WebAssembly SIMD proposal is now enabled by default.\n  [#3601](https://github.com/bytecodealliance/wasmtime/pull/3601)\n\n--------------------------------------------------------------------------------\n\n## 0.32.1\n\nReleased 2022-01-04.\n\n### Fixed\n\n* Cranelift: remove recently-added build dependency on `sha2` to allow usage in\n  some dependency-sensitive environments, by computing ISLE manifest hashes\n  with a different hash function.\n  [#3619](https://github.com/bytecodealliance/wasmtime/pull/3619)\n\n* Cranelift: fixed 8- and 16-bit behavior of popcount (bit population count)\n  instruction. Does not affect Wasm frontend.\n  [#3617](https://github.com/bytecodealliance/wasmtime/pull/3617)\n\n* Cranelift: fixed miscompilation of 8- and 16-bit bit-rotate instructions.\n  Does not affect Wasm frontend.\n  [#3610](https://github.com/bytecodealliance/wasmtime/pull/3610)\n\n--------------------------------------------------------------------------------\n\n## 0.32.0\n\nReleased 2021-12-13.\n\n### Added\n\n* A new configuration option has been added to force using a \"static\" memory\n  style to automatically limit growth of memories in some configurations.\n  [#3503](https://github.com/bytecodealliance/wasmtime/pull/3503)\n\n* The `InstancePre<T>` type now implements `Clone`.\n  [#3510](https://github.com/bytecodealliance/wasmtime/pull/3510)\n\n* Cranelift's instruction selection process has begun to be migrated towards the\n  ISLE compiler and definition language.\n  [#3506](https://github.com/bytecodealliance/wasmtime/pull/3506)\n\n* A `pooling-allocator` feature has been added, which is on-by-default, to\n  disable the pooling allocator at compile time.\n  [#3514](https://github.com/bytecodealliance/wasmtime/pull/3514)\n\n### Fixed\n\n* A possible panic when parsing a WebAssembly `name` section has been fixed.\n  [#3509](https://github.com/bytecodealliance/wasmtime/pull/3509)\n\n* Generating native DWARF information for some C-produced modules has been\n  fixed, notably those where there may be DWARF about dead code.\n  [#3498](https://github.com/bytecodealliance/wasmtime/pull/3498)\n\n* A number of SIMD code generation bugs have been fixed in the x64 backend\n  by migrating their lowerings to ISLE.\n\n--------------------------------------------------------------------------------\n\n## 0.31.0\n\nReleased 2021-10-29.\n\n### Added\n\n* New `Func::new_unchecked` and `Func::call_unchecked` APIs have been added with\n  accompanying functions in the C API to improve the performance of calls into\n  wasm and the host in the C API.\n  [#3350](https://github.com/bytecodealliance/wasmtime/pull/3350)\n\n* Release binaries are now available for the s390x-unknown-linux-gnu\n  architecture.\n  [#3372](https://github.com/bytecodealliance/wasmtime/pull/3372)\n\n* A new `ResourceLimiterAsync` trait is added which allows asynchronous blocking\n  of WebAssembly on instructions such as `memory.grow`.\n  [#3393](https://github.com/bytecodealliance/wasmtime/pull/3393)\n\n### Changed\n\n* The `Func::call` method now takes a slice to write the results into rather\n  than returning a boxed slice.\n  [#3319](https://github.com/bytecodealliance/wasmtime/pull/3319)\n\n* Trampolines are now covered when jitdump profiling is enabled.\n  [#3344](https://github.com/bytecodealliance/wasmtime/pull/3344)\n\n### Fixed\n\n* Debugging with GDB has been fixed on Windows.\n  [#3373](https://github.com/bytecodealliance/wasmtime/pull/3373)\n\n* Some quadradic behavior in Wasmtime's compilation of modules has been fixed.\n  [#3469](https://github.com/bytecodealliance/wasmtime/pull/3469)\n  [#3466](https://github.com/bytecodealliance/wasmtime/pull/3466)\n\n* Bounds-checks for wasm memory accesses in certain non-default configurations\n  have been fixed to correctly allow loads at the end of the address space.\n  [#3462](https://github.com/bytecodealliance/wasmtime/pull/3462)\n\n* When type-checking memories and tables for satisfying instance imports the\n  runtime size of the table/memory is now consulted instead of the object's\n  original type.\n  [#3450](https://github.com/bytecodealliance/wasmtime/pull/3450)\n\n### Removed\n\n* The Lightbeam backend has been removed, as per [RFC 14].\n  [#3390](https://github.com/bytecodealliance/wasmtime/pull/3390)\n\n[RFC 14]: https://github.com/bytecodealliance/rfcs/pull/14\n\n* Cranelift's old x86 backend has been removed, as per [RFC 12].\n  [#3309](https://github.com/bytecodealliance/wasmtime/pull/3009)\n\n[RFC 12]: https://github.com/bytecodealliance/rfcs/pull/12\n\n## 0.30.0\n\nReleased 2021-09-17.\n\n### Security Fixes\n\n* [CVE-2021-39216](https://github.com/bytecodealliance/wasmtime/security/advisories/GHSA-v4cp-h94r-m7xf):\n  Fixed a use after free passing `externref`s to Wasm in Wasmtime.\n\n* [CVE-2021-39218](https://github.com/bytecodealliance/wasmtime/security/advisories/GHSA-4873-36h9-wv49):\n  Fixed an out-of-bounds read/write and invalid free with `externref`s and GC\n  safepoints in Wasmtime.\n\n* [CVE-2021-39219](https://github.com/bytecodealliance/wasmtime/security/advisories/GHSA-q879-9g95-56mx):\n  Fixed a bug where using two different `Engine`s with the same `Linker`-define\n  functions caused unsafety without `unsafe` blocks.\n\n### Added\n\n* Added experimental support for the in-progress 64-bit memories Wasm proposal.\n\n* Added support to build Wasmtime without the compiler. This lets you run\n  pre-compiled Wasm modules, without the ability (or potential attack surface)\n  of compiling new Wasm modules. The compilation functionality is gated by the\n  on-by-default `cranelift` cargo feature.\n\n* Added support for NaN canonicalization with SIMD vectors.\n\n* Added support for differential fuzzing against V8's Wasm engine.\n\n* Added support for fuzzing against the Wasm spec interpreter.\n\n* Enabled SIMD fuzzing on oss-fuzz.\n\n### Changed\n\n* A variety of performance improvements to loading pre-compiled modules.\n\n* A variety of performance improvements to function calls, both through Rust and\n  the C API.\n\n* Leaf functions that do not use the stack no longer bump the frame pointer on\n  aarch64 and s390x.\n\n* Many updates and expanded instruction support to the in-progress CLIF\n  interpreter.\n\n* Expanded fuzzing of reference types and GC.\n\n### Fixed\n\n* A number of fixes to both aarch64 and x86_64 support for the Wasm SIMD\n  proposal and the underlying CLIF vector instructions.\n\n* Fixed a potential infinite loop in the SSA computation for\n  `cranelift-frontend`. This was not reachable from `cranelift-wasm` or\n  Wasmtime, but might have affected general Cranelift users.\n\n### Removed\n\n* The `wasmtime wasm2obj` subcommand has been removed. Generating raw object\n  files for linking natively is no longer supported. Use the `wasmtime compile`\n  subcommand to pre-compile a Wasm module and `wasmtime run` to run pre-compiled\n  Wasm modules.\n\n## 0.29.0\n\nReleased 2021-08-02.\n\n### Changed\n\n* Instance exports are now loaded lazily from instances instead of eagerly as\n  they were before. This is an internal-only change and is not a breaking\n  change.\n  [#2984](https://github.com/bytecodealliance/wasmtime/pull/2984)\n\n* All linear memories created by Wasmtime will now, by default, have guard pages\n  in front of them in addition to after them. This is intended to help mitigate\n  future bugs in Cranelift, should they arise.\n  [#2977](https://github.com/bytecodealliance/wasmtime/pull/2977)\n\n* Linear memories now correctly support a maximum size of 4GB. Previously, the\n  limit field was 32 bits, which did not properly support a full 4GB memory.\n  This update is also a necessary change in preparation for future memory64\n  support.\n  [#3013](https://github.com/bytecodealliance/wasmtime/pull/3013)\n  [#3134](https://github.com/bytecodealliance/wasmtime/pull/3134)\n\n* Injection counts of fuel into a `wasmtime::Store` now uses a u64 instead of a\n  u32.\n  [#3048](https://github.com/bytecodealliance/wasmtime/pull/3048)\n\n### Added\n\n* Support for `i128` has improved in the AArch64 backend.\n  [#2959](https://github.com/bytecodealliance/wasmtime/pull/2959)\n  [#2975](https://github.com/bytecodealliance/wasmtime/pull/2975)\n  [#2985](https://github.com/bytecodealliance/wasmtime/pull/2985)\n  [#2990](https://github.com/bytecodealliance/wasmtime/pull/2990)\n  [#3002](https://github.com/bytecodealliance/wasmtime/pull/3002)\n  [#3004](https://github.com/bytecodealliance/wasmtime/pull/3004)\n  [#3005](https://github.com/bytecodealliance/wasmtime/pull/3005)\n  [#3008](https://github.com/bytecodealliance/wasmtime/pull/3008)\n  [#3027](https://github.com/bytecodealliance/wasmtime/pull/3027)\n\n* The s390x backend now supports z14 and atomics.\n  [#2988](https://github.com/bytecodealliance/wasmtime/pull/2988)\n  [#2991](https://github.com/bytecodealliance/wasmtime/pull/2991)\n\n* The `wasmtime::Linker` type now implements `Clone`.\n  [#2993](https://github.com/bytecodealliance/wasmtime/pull/2993)\n\n* Support for the SIMD proposal on both x86\\_64 and AArch64 has improved. On\n  x86\\_64, all SIMD opcodes are now supported.\n  [#2997](https://github.com/bytecodealliance/wasmtime/pull/2997)\n  [#3035](https://github.com/bytecodealliance/wasmtime/pull/3035)\n  [#2982](https://github.com/bytecodealliance/wasmtime/pull/2982)\n  [#3084](https://github.com/bytecodealliance/wasmtime/pull/3084)\n  [#3082](https://github.com/bytecodealliance/wasmtime/pull/3082)\n  [#3107](https://github.com/bytecodealliance/wasmtime/pull/3107)\n  [#3105](https://github.com/bytecodealliance/wasmtime/pull/3105)\n  [#3114](https://github.com/bytecodealliance/wasmtime/pull/3114)\n  [#3070](https://github.com/bytecodealliance/wasmtime/pull/3070)\n  [#3126](https://github.com/bytecodealliance/wasmtime/pull/3126)\n\n* A `Trap` can now display its reason without also displaying the backtrace.\n  [#3033](https://github.com/bytecodealliance/wasmtime/pull/3033)\n\n* An initiall fuzzer for CLIF has been added.\n  [#3038](https://github.com/bytecodealliance/wasmtime/pull/3038)\n\n* High-level architecture documentation has been added for Wasmtime.\n  [#3019](https://github.com/bytecodealliance/wasmtime/pull/3019)\n\n* Support for multi-memory can now be configured in Wasmtime's C API.\n  [#3071](https://github.com/bytecodealliance/wasmtime/pull/3071)\n\n* The `wasmtime` crate now supports a `posix-signals-on-macos` feature to force\n  the usage of signals instead of mach ports to handle traps on macOS.\n  [#3063](https://github.com/bytecodealliance/wasmtime/pull/3063)\n\n* Wasmtime's C API now has a `wasmtime_trap_code` function to get the raw trap\n  code, if present, for a trap.\n  [#3086](https://github.com/bytecodealliance/wasmtime/pull/3086)\n\n* Wasmtime's C API now has a `wasmtime_linker_define_func` function to define a\n  store-independent function within a linker.\n  [#3122](https://github.com/bytecodealliance/wasmtime/pull/3122)\n\n* A `wasmtime::Linker::module_async` function was added as the asynchronous\n  counterpart to `wasmtime::Linker::module`.\n  [#3121](https://github.com/bytecodealliance/wasmtime/pull/3121)\n\n### Fixed\n\n* Compiling the `wasmtime` crate into a `dylib` crate type has been fixed.\n  [#3010](https://github.com/bytecodealliance/wasmtime/pull/3010)\n\n* The enter/exit hooks for WebAssembly are now executed for an instance's\n  `start` function, if present.\n  [#3001](https://github.com/bytecodealliance/wasmtime/pull/3001)\n\n* Some WASI functions in `wasi-common` have been fixed for big-endian platforms.\n  [#3016](https://github.com/bytecodealliance/wasmtime/pull/3016)\n\n* Wasmtime no longer erroneously assumes that all custom sections may contain\n  DWARF information, reducing instances of `Trap`'s `Display` implementation\n  providing misleading information to set an env var to get more information.\n  [#3083](https://github.com/bytecodealliance/wasmtime/pull/3083)\n\n* Some issues with parsing DWARF debug information have been fixed.\n  [#3116](https://github.com/bytecodealliance/wasmtime/pull/3116)\n\n## 0.28.0\n\nReleased 2021-06-09.\n\n### Changed\n\n* Breaking: Wasmtime's embedding API has been redesigned, as specified in [RFC\n  11]. Rust users can now enjoy easier times with `Send` and `Sync`, and all\n  users can now more clearly manage memory, especially in the C API. Language\n  embeddings have been updated to the new API as well.\n  [#2897](https://github.com/bytecodealliance/wasmtime/pull/2897)\n\n[RFC 11]: https://github.com/bytecodealliance/rfcs/pull/11\n\n### Added\n\n* A new `InstancePre` type, created with `Linker::instantiate_pre`, has been\n  added to perform type-checking of an instance once and reduce the work done\n  for each instantiation of a module:\n  [#2962](https://github.com/bytecodealliance/wasmtime/pull/2962)\n\n* Deserialization of a module can now optionally skip checking the wasmtime\n  version string:\n  [#2945](https://github.com/bytecodealliance/wasmtime/pull/2945)\n\n* A method has been exposed to frontload per-thread initialization costs if the\n  latency of every last wasm call is important:\n  [#2946](https://github.com/bytecodealliance/wasmtime/pull/2946)\n\n* Hooks have been added for entry/exit into wasm code to allow embeddings to\n  track time and other properties about execution in a wasm environment:\n  [#2952](https://github.com/bytecodealliance/wasmtime/pull/2952)\n\n* A [C++ embedding of Wasmtime has been written][cpp].\n\n[RFC 11]: https://github.com/bytecodealliance/rfcs/pull/11\n[cpp]: https://github.com/bytecodealliance/wasmtime-cpp\n\n### Fixed\n\n* Multiple returns on macOS AArch64 have been fixed:\n  [#2956](https://github.com/bytecodealliance/wasmtime/pull/2956)\n\n## 0.27.0\n\nReleased 2021-05-21.\n\n### Security Fixes\n\n* Fixed a security issue in Cranelift's x64 backend that could result in a heap\n  sandbox escape due to an incorrect sign-extension:\n  [#2913](https://github.com/bytecodealliance/wasmtime/issues/2913).\n\n### Added\n\n* Support for IBM z/Archiecture (`s390x`) machines in Cranelift and Wasmtime:\n  [#2836](https://github.com/bytecodealliance/wasmtime/pull/2836),\n  [#2837](https://github.com/bytecodealliance/wasmtime/pull/2837),\n  [#2838](https://github.com/bytecodealliance/wasmtime/pull/2838),\n  [#2843](https://github.com/bytecodealliance/wasmtime/pull/2843),\n  [#2854](https://github.com/bytecodealliance/wasmtime/pull/2854),\n  [#2870](https://github.com/bytecodealliance/wasmtime/pull/2870),\n  [#2871](https://github.com/bytecodealliance/wasmtime/pull/2871),\n  [#2872](https://github.com/bytecodealliance/wasmtime/pull/2872),\n  [#2874](https://github.com/bytecodealliance/wasmtime/pull/2874).\n\n* Improved async support in wasi-common runtime:\n  [#2832](https://github.com/bytecodealliance/wasmtime/pull/2832).\n\n* Added `Store::with_limits`, `StoreLimits`, and `ResourceLimiter` to the\n  Wasmtime API to help with enforcing resource limits at runtime. The\n  `ResourceLimiter` trait can be implemented by custom resource limiters to\n  decide if linear memories or tables can be grown.\n\n* Added `allow-unknown-exports` option for the run command:\n  [#2879](https://github.com/bytecodealliance/wasmtime/pull/2879).\n\n* Added API to notify that a `Store` has moved to a new thread:\n  [#2822](https://github.com/bytecodealliance/wasmtime/pull/2822).\n\n* Documented guidance around using Wasmtime in multithreaded contexts:\n  [#2812](https://github.com/bytecodealliance/wasmtime/pull/2812).\n  In the future, the Wasmtime API will change to allow some of its core types\n  to be Send/Sync; see the in-progress\n  [#2897](https://github.com/bytecodealliance/wasmtime/pull/2897) for details.\n\n* Support calls from native code to multiple-return-value functions:\n  [#2806](https://github.com/bytecodealliance/wasmtime/pull/2806).\n\n### Changed\n\n* Breaking: `Memory::new` has been changed to return `Result` as creating a\n  host memory object is now a fallible operation when the initial size of\n  the memory exceeds the store limits.\n\n### Fixed\n\n* Many instruction selection improvements on x64 and aarch64:\n  [#2819](https://github.com/bytecodealliance/wasmtime/pull/2819),\n  [#2828](https://github.com/bytecodealliance/wasmtime/pull/2828),\n  [#2823](https://github.com/bytecodealliance/wasmtime/pull/2823),\n  [#2862](https://github.com/bytecodealliance/wasmtime/pull/2862),\n  [#2886](https://github.com/bytecodealliance/wasmtime/pull/2886),\n  [#2889](https://github.com/bytecodealliance/wasmtime/pull/2889),\n  [#2905](https://github.com/bytecodealliance/wasmtime/pull/2905).\n\n* Improved performance of Wasmtime runtime substantially:\n  [#2811](https://github.com/bytecodealliance/wasmtime/pull/2811),\n  [#2818](https://github.com/bytecodealliance/wasmtime/pull/2818),\n  [#2821](https://github.com/bytecodealliance/wasmtime/pull/2821),\n  [#2847](https://github.com/bytecodealliance/wasmtime/pull/2847),\n  [#2900](https://github.com/bytecodealliance/wasmtime/pull/2900).\n\n* Fixed WASI issue with file metadata on Windows:\n  [#2884](https://github.com/bytecodealliance/wasmtime/pull/2884).\n\n* Fixed an issue with debug info and an underflowing (trapping) offset:\n  [#2866](https://github.com/bytecodealliance/wasmtime/pull/2866).\n\n* Fixed an issue with unwind information in the old x86 backend:\n  [#2845](https://github.com/bytecodealliance/wasmtime/pull/2845).\n\n* Fixed i32 spilling in x64 backend:\n  [#2840](https://github.com/bytecodealliance/wasmtime/pull/2840).\n\n## 0.26.0\n\nReleased 2021-04-05.\n\n### Added\n\n* Added the `wasmtime compile` command to support AOT compilation of Wasm\n  modules. This adds the `Engine::precompile_module` method. Also added the\n  `Config::target` method to change the compilation target of the\n  configuration. This can be used in conjunction with\n  `Engine::precompile_module` to target a different host triple than the\n  current one.\n  [#2791](https://github.com/bytecodealliance/wasmtime/pull/2791)\n\n* Support for macOS on aarch64 (Apple M1 Silicon), including Apple-specific\n  calling convention details and unwinding/exception handling using Mach ports.\n  [#2742](https://github.com/bytecodealliance/wasmtime/pull/2742),\n  [#2723](https://github.com/bytecodealliance/wasmtime/pull/2723)\n\n* A number of SIMD instruction implementations in the new x86-64 backend.\n  [#2771](https://github.com/bytecodealliance/wasmtime/pull/2771)\n\n* Added the `Config::cranelift_flag_enable` method to enable setting Cranelift\n  boolean flags or presets in a config.\n\n* Added CLI option `--cranelift-enable` to enable boolean settings and ISA presets.\n\n* Deduplicate function signatures in Wasm modules.\n  [#2772](https://github.com/bytecodealliance/wasmtime/pull/2772)\n\n* Optimize overheads of calling into Wasm functions.\n  [#2757](https://github.com/bytecodealliance/wasmtime/pull/2757),\n  [#2759](https://github.com/bytecodealliance/wasmtime/pull/2759)\n\n* Improvements related to Module Linking: compile fewer trampolines;\n\n  [#2774](https://github.com/bytecodealliance/wasmtime/pull/2774)\n\n* Re-export sibling crates from `wasmtime-wasi` to make embedding easier\n  without needing to match crate versions.\n  [#2776](https://github.com/bytecodealliance/wasmtime/pull/2776)\n\n### Changed\n\n* Switched the default compiler backend on x86-64 to Cranelift's new backend.\n  This should not have any user-visible effects other than possibly runtime\n  performance improvements. The old backend is still available with the\n  `old-x86-backend` feature flag to the `cranelift-codegen` or `wasmtime`\n  crates, or programmatically with `BackendVariant::Legacy`. We plan to\n  maintain the old backend for at least one more release and ensure it works on\n  CI.\n  [#2718](https://github.com/bytecodealliance/wasmtime/pull/2718)\n\n* Breaking: `Module::deserialize` has been removed in favor of `Module::new`.\n\n* Breaking: `Config::cranelift_clear_cpu_flags` was removed. Use `Config::target`\n  to clear the CPU flags for the host's target.\n\n* Breaking: `Config::cranelift_other_flag` was renamed to `Config::cranelift_flag_set`.\n\n* CLI changes:\n  * Wasmtime CLI options to enable WebAssembly features have been replaced with\n    a singular `--wasm-features` option. The previous options are still\n    supported, but are not displayed in help text.\n  * Breaking: the CLI option `--cranelift-flags` was changed to\n    `--cranelift-set`.\n  * Breaking: the CLI option `--enable-reference-types=false` has been changed\n    to `--wasm-features=-reference-types`.\n  * Breaking: the CLI option `--enable-multi-value=false` has been changed to\n    `--wasm-features=-multi-value`.\n  * Breaking: the CLI option `--enable-bulk-memory=false` has been changed to\n    `--wasm-features=-bulk-memory`.\n\n* Improved error-reporting in wiggle.\n  [#2760](https://github.com/bytecodealliance/wasmtime/pull/2760)\n\n* Make WASI sleeping fallible (some systems do not support sleep).\n  [#2756](https://github.com/bytecodealliance/wasmtime/pull/2756)\n\n* WASI: Support `poll_oneoff` with a sleep.\n  [#2753](https://github.com/bytecodealliance/wasmtime/pull/2753)\n\n* Allow a `StackMapSink` to be passed when defining functions with\n  `cranelift-module`.\n  [#2739](https://github.com/bytecodealliance/wasmtime/pull/2739)\n\n* Some refactoring in new x86-64 backend to prepare for VEX/EVEX (e.g.,\n  AVX-512) instruction encodings to be supported.\n  [#2799](https://github.com/bytecodealliance/wasmtime/pull/2799)\n\n### Fixed\n\n* Fixed a corner case in `srem` (signed remainder) in the new x86-64 backend:\n  `INT_MIN % -1` should return `0`, rather than trapping. This only occurred\n  when `avoid_div_traps == false` was set by the embedding.\n  [#2763](https://github.com/bytecodealliance/wasmtime/pull/2763)\n\n* Fixed a memory leak of the `Store` when an instance traps.\n  [#2803](https://github.com/bytecodealliance/wasmtime/pull/2803)\n\n* Some fuzzing-related fixes.\n  [#2788](https://github.com/bytecodealliance/wasmtime/pull/2788),\n  [#2770](https://github.com/bytecodealliance/wasmtime/pull/2770)\n\n* Fixed memory-initialization bug in uffd allocator that could copy into the\n  wrong destination under certain conditions. Does not affect the default\n  wasmtime instance allocator.\n  [#2801](https://github.com/bytecodealliance/wasmtime/pull/2801)\n\n* Fix printing of float values from the Wasmtime CLI.\n  [#2797](https://github.com/bytecodealliance/wasmtime/pull/2797)\n\n* Remove the ability for the `Linker` to instantiate modules with duplicate\n  import strings of different types.\n  [#2789](https://github.com/bytecodealliance/wasmtime/pull/2789)\n\n## 0.25.0\n\nReleased 2021-03-16.\n\n### Added\n\n* An implementation of a pooling instance allocator, optionally backed by\n  `userfaultfd` on Linux, was added to improve the performance of embeddings\n  that instantiate a large number of instances continuously.\n  [#2518](https://github.com/bytecodealliance/wasmtime/pull/2518)\n\n* Host functions can now be defined on `Config` to share the function across all\n  `Store` objects connected to an `Engine`. This can improve the time it takes\n  to instantiate instances in a short-lived `Store`.\n  [#2625](https://github.com/bytecodealliance/wasmtime/pull/2625)\n\n* The `Store` object now supports having typed values attached to it which can\n  be retrieved from host functions.\n  [#2625](https://github.com/bytecodealliance/wasmtime/pull/2625)\n\n* The `wiggle` code generator now supports `async` host functions.\n  [#2701](https://github.com/bytecodealliance/wasmtime/pull/2701)\n\n### Changed\n\n* The `Func::getN{,_async}` APIs have all been removed in favor of a new\n  `Func::typed` API which should be more compact in terms of API surface area as\n  well as more flexible in how it can be used.\n  [#2719](https://github.com/bytecodealliance/wasmtime/pull/2719)\n\n* `Engine::new` has been changed from returning `Engine` to returning\n  `anyhow::Result<Engine>`. Callers of `Engine::new` will need to be updated to\n  use the `?` operator on the return value or otherwise unwrap the result to get\n  the `Engine`.\n\n### Fixed\n\n* Interpretation of timestamps in `poll_oneoff` for WASI have been fixed to\n  correctly use nanoseconds instead of microseconds.\n  [#2717](https://github.com/bytecodealliance/wasmtime/pull/2717)\n\n## 0.24.0\n\nReleased 2021-03-04.\n\n### Added\n\n* Implement support for `async` functions in Wasmtime\n  [#2434](https://github.com/bytecodealliance/wasmtime/pull/2434)\n\n### Fixed\n\n* Fix preservation of the sigaltstack on macOS\n  [#2676](https://github.com/bytecodealliance/wasmtime/pull/2676)\n* Fix incorrect semver dependencies involving fs-set-times.\n  [#2705](https://github.com/bytecodealliance/wasmtime/pull/2705)\n* Fix some `i128` shift-related bugs in x64 backend.\n  [#2682](https://github.com/bytecodealliance/wasmtime/pull/2682)\n* Fix incomplete trap metadata due to multiple traps at one address\n  [#2685](https://github.com/bytecodealliance/wasmtime/pull/2685)\n\n## 0.23.0\n\nReleased 2021-02-16.\n\n### Added\n\n* Support for limiting WebAssembly execution with fuel was added, including\n  support in the C API.\n  [#2611](https://github.com/bytecodealliance/wasmtime/pull/2611)\n  [#2643](https://github.com/bytecodealliance/wasmtime/pull/2643)\n* Wasmtime now has more knobs for limiting memory and table allocations\n  [#2617](https://github.com/bytecodealliance/wasmtime/pull/2617)\n* Added a method to share `Config` across machines\n  [#2608](https://github.com/bytecodealliance/wasmtime/pull/2608)\n* Added a safe memory read/write API\n  [#2528](https://github.com/bytecodealliance/wasmtime/pull/2528)\n* Added support for the experimental wasi-crypto APIs\n  [#2597](https://github.com/bytecodealliance/wasmtime/pull/2597)\n* Added an instance limit to `Config`\n  [#2593](https://github.com/bytecodealliance/wasmtime/pull/2593)\n* Implemented module-linking's outer module aliases\n  [#2590](https://github.com/bytecodealliance/wasmtime/pull/2590)\n* Cranelift now supports 128-bit operations for the new x64 backend.\n  [#2539](https://github.com/bytecodealliance/wasmtime/pull/2539)\n* Cranelift now has detailed debug-info (DWARF) support in new backends (initially x64).\n  [#2565](https://github.com/bytecodealliance/wasmtime/pull/2565)\n* Cranelift now uses the `POPCNT`, `TZCNT`, and `LZCNT`, as well as SSE 4.1\n  rounding instructions on x64 when available.\n* Cranelift now uses the `CNT`, instruction on aarch64 when available.\n\n### Changed\n\n* A new WASI implementation built on the new\n  [`cap-std`](https://github.com/bytecodealliance/cap-std) crate was added,\n  replacing the previous implementation. This brings improved robustness,\n  portability, and performance.\n\n* `wasmtime_wasi::WasiCtxBuilder` moved to\n  `wasi_cap_std_sync::WasiCtxBuilder`.\n\n* The WebAssembly C API is updated, with a few minor API changes\n  [#2579](https://github.com/bytecodealliance/wasmtime/pull/2579)\n\n### Fixed\n\n* Fixed a panic in WASI `fd_readdir` on large directories\n  [#2620](https://github.com/bytecodealliance/wasmtime/pull/2620)\n* Fixed a memory leak with command modules\n  [#2017](https://github.com/bytecodealliance/wasmtime/pull/2017)\n\n--------------------------------------------------------------------------------\n\n## 0.22.0\n\nReleased 2021-01-07.\n\n### Added\n\n* Experimental support for [the module-linking\n  proposal](https://github.com/WebAssembly/module-linking) was\n  added. [#2094](https://github.com/bytecodealliance/wasmtime/pull/2094)\n\n* Added support for [the reference types\n  proposal](https://webassembly.github.io/reference-types) on the aarch64\n  architecture. [#2410](https://github.com/bytecodealliance/wasmtime/pull/2410)\n\n* Experimental support for [wasi-nn](https://github.com/WebAssembly/wasi-nn) was\n  added. [#2208](https://github.com/bytecodealliance/wasmtime/pull/2208)\n\n### Changed\n\n### Fixed\n\n* Fixed an issue where the `select` instruction didn't accept `v128` SIMD\n  operands. [#2391](https://github.com/bytecodealliance/wasmtime/pull/2391)\n\n* Fixed an issue where Wasmtime could potentially use the wrong stack map during\n  GCs, leading to a\n  panic. [#2396](https://github.com/bytecodealliance/wasmtime/pull/2396)\n\n* Fixed an issue where if a host-defined function erroneously returned a value\n  from a different store, that value would be\n  leaked. [#2424](https://github.com/bytecodealliance/wasmtime/pull/2424)\n\n* Fixed a bug where in certain cases if a module's instantiation failed, it\n  could leave trampolines in the store that referenced the no-longer-valid\n  instance. These trampolines could be reused in future instantiations, leading\n  to use after free bugs.\n  [#2408](https://github.com/bytecodealliance/wasmtime/pull/2408)\n\n* Fixed a miscompilation on aarch64 where certain instructions would read `SP`\n  instead of the zero register. This could only affect you if you explicitly\n  enabled the Wasm SIMD\n  proposal. [#2548](https://github.com/bytecodealliance/wasmtime/pull/2548)\n\n--------------------------------------------------------------------------------\n\n## 0.21.0\n\nReleased 2020-11-05.\n\n### Added\n\n* Experimental support for the multi-memory proposal was added.\n  [#2263](https://github.com/bytecodealliance/wasmtime/pull/2263)\n\n* The `Trap::trap_code` API enables learning what kind of trap was raised.\n  [#2309](https://github.com/bytecodealliance/wasmtime/pull/2309)\n\n### Changed\n\n* WebAssembly module validation is now parallelized.\n  [#2059](https://github.com/bytecodealliance/wasmtime/pull/2059)\n\n* Documentation is now available at docs.wasmtime.dev.\n  [#2317](https://github.com/bytecodealliance/wasmtime/pull/2317)\n\n* Windows now compiles like other platforms with a huge guard page instead of\n  having its own custom limit which made modules compile and run more slowly.\n  [#2326](https://github.com/bytecodealliance/wasmtime/pull/2326)\n\n* The size of the cache entry for serialized modules has been greatly reduced.\n  [#2321](https://github.com/bytecodealliance/wasmtime/pull/2321)\n  [#2322](https://github.com/bytecodealliance/wasmtime/pull/2322)\n  [#2324](https://github.com/bytecodealliance/wasmtime/pull/2324)\n  [#2325](https://github.com/bytecodealliance/wasmtime/pull/2325)\n\n* The `FuncType` API constructor and accessors are now iterator-based.\n  [#2365](https://github.com/bytecodealliance/wasmtime/pull/2365)\n\n### Fixed\n\n* A panic in compiling reference-types-using modules has been fixed.\n  [#2350](https://github.com/bytecodealliance/wasmtime/pull/2350)\n\n--------------------------------------------------------------------------------\n\n## 0.20.0\n\nReleased 2020-09-23.\n\n### Added\n\n* Support for explicitly serializing and deserializing compiled wasm modules has\n  been added.\n  [#2020](https://github.com/bytecodealliance/wasmtime/pull/2020)\n\n* A `wasmtime_store_gc` C API was added to run GC for `externref`.\n  [#2052](https://github.com/bytecodealliance/wasmtime/pull/2052)\n\n* Support for atomics in Cranelift has been added. Support is not fully\n  implemented in Wasmtime at this time, however.\n  [#2077](https://github.com/bytecodealliance/wasmtime/pull/2077)\n\n* The `Caller::get_export` function is now implemented for `Func` references as\n  well.\n  [#2108](https://github.com/bytecodealliance/wasmtime/pull/2108)\n\n### Fixed\n\n* Leaks in the C API have been fixed.\n  [#2040](https://github.com/bytecodealliance/wasmtime/pull/2040)\n\n* The `wasm_val_copy` C API has been fixed for reference types.\n  [#2041](https://github.com/bytecodealliance/wasmtime/pull/2041)\n\n* Fix a panic with `Func::new` and reference types when the store doesn't have\n  reference types enabled.\n  [#2039](https://github.com/bytecodealliance/wasmtime/pull/2039)\n\n--------------------------------------------------------------------------------\n\n## 0.19.0\n\nReleased 2020-07-14.\n\n### Added\n\n* The [WebAssembly reference-types proposal][reftypes] is now supported in\n  Wasmtime and the C API.\n  [#1832](https://github.com/bytecodealliance/wasmtime/pull/1832),\n  [#1882](https://github.com/bytecodealliance/wasmtime/pull/1882),\n  [#1894](https://github.com/bytecodealliance/wasmtime/pull/1894),\n  [#1901](https://github.com/bytecodealliance/wasmtime/pull/1901),\n  [#1923](https://github.com/bytecodealliance/wasmtime/pull/1923),\n  [#1969](https://github.com/bytecodealliance/wasmtime/pull/1969),\n  [#1973](https://github.com/bytecodealliance/wasmtime/pull/1973),\n  [#1982](https://github.com/bytecodealliance/wasmtime/pull/1982),\n  [#1984](https://github.com/bytecodealliance/wasmtime/pull/1984),\n  [#1991](https://github.com/bytecodealliance/wasmtime/pull/1991),\n  [#1996](https://github.com/bytecodealliance/wasmtime/pull/1996)\n\n* The [WebAssembly simd proposal's][simd] spec tests now pass in Wasmtime.\n  [#1765](https://github.com/bytecodealliance/wasmtime/pull/1765),\n  [#1876](https://github.com/bytecodealliance/wasmtime/pull/1876),\n  [#1941](https://github.com/bytecodealliance/wasmtime/pull/1941),\n  [#1957](https://github.com/bytecodealliance/wasmtime/pull/1957),\n  [#1990](https://github.com/bytecodealliance/wasmtime/pull/1990),\n  [#1994](https://github.com/bytecodealliance/wasmtime/pull/1994)\n\n* Wasmtime can now be compiled without the usage of threads for parallel\n  compilation, although this is still enabled by default.\n  [#1903](https://github.com/bytecodealliance/wasmtime/pull/1903)\n\n* The C API is [now\n  documented](https://bytecodealliance.github.io/wasmtime/c-api/).\n  [#1928](https://github.com/bytecodealliance/wasmtime/pull/1928),\n  [#1959](https://github.com/bytecodealliance/wasmtime/pull/1959),\n  [#1968](https://github.com/bytecodealliance/wasmtime/pull/1968)\n\n* A `wasmtime_linker_get_one_by_name` function was added to the C API.\n  [#1897](https://github.com/bytecodealliance/wasmtime/pull/1897)\n\n* A `wasmtime_trap_exit_status` function was added to the C API.\n  [#1912](https://github.com/bytecodealliance/wasmtime/pull/1912)\n\n* Compilation for the `aarch64-linux-android` target should now work, although\n  keep in mind this platform is not fully tested still.\n  [#2002](https://github.com/bytecodealliance/wasmtime/pull/2002)\n\n[reftypes]: https://github.com/WebAssembly/reference-types\n\n### Fixed\n\n* Runtime warnings when using Wasmtime on musl have been fixed.\n  [#1914](https://github.com/bytecodealliance/wasmtime/pull/1914)\n\n* A bug affecting Windows unwind information with functions that have spilled\n  floating point registers has been fixed.\n  [#1983](https://github.com/bytecodealliance/wasmtime/pull/1983)\n\n### Changed\n\n* Wasmtime's default branch and development now happens on the `main` branch\n  instead of `master`.\n  [#1924](https://github.com/bytecodealliance/wasmtime/pull/1924)\n\n### Removed\n\n* The \"host info\" support in the C API has been removed since it was never fully\n  or correctly implemented.\n  [#1922](https://github.com/bytecodealliance/wasmtime/pull/1922)\n\n* Support for the `*_same` functions in the C API has been removed in the same\n  vein as the host info APIs.\n  [#1926](https://github.com/bytecodealliance/wasmtime/pull/1926)\n\n--------------------------------------------------------------------------------\n\n## 0.18.0\n\nRelease 2020-06-09.\n\n### Added\n\nThe `WasmTy` trait is now implemented for `u32` and `u64`.\n\n  [#1808](https://github.com/bytecodealliance/wasmtime/pull/1808)\n\n--------------------------------------------------------------------------------\n\n## 0.17.0\n\nReleased 2020-06-01.\n\n### Added\n\n* The [Commands and Reactors ABI] is now supported in the Rust API. `Linker::module`\n  loads a module and automatically handles Commands and Reactors semantics.\n\n  [#1565](https://github.com/bytecodealliance/wasmtime/pull/1565)\n\n[Commands and Reactors ABI]: https://github.com/WebAssembly/WASI/blob/master/design/application-abi.md#current-unstable-abi\n\nThe `Table::grow` function now returns the previous table size, making it consistent\nwith the `table.grow` instruction.\n\n  [#1653](https://github.com/bytecodealliance/wasmtime/pull/1653)\n\nNew Wasmtime-specific C APIs for working with tables were added which provide more\ndetailed error information and which make growing a table more consistent with the\n`table.grow` instruction as well.\n\n  [#1654](https://github.com/bytecodealliance/wasmtime/pull/1654)\n\nThe C API now includes support for enabling logging in Wasmtime.\n\n  [#1737](https://github.com/bytecodealliance/wasmtime/pull/1737)\n\n### Changed\n\nThe WASI `proc_exit` function no longer exits the host process. It now unwinds the\ncallstack back to the wasm entrypoint, and the exit value is available from the\n`Trap::i32_exit_status` method.\n\n  [#1646](https://github.com/bytecodealliance/wasmtime/pull/1646)\n\nThe WebAssembly [multi-value](https://github.com/WebAssembly/multi-value/) proposal\nis now enabled by default.\n\n  [#1667](https://github.com/bytecodealliance/wasmtime/pull/1667)\n\nThe Rust API does not require a store provided during `Module::new` operation. The `Module` can be send accross threads and instantiate for a specific store. The `Instance::new` now requires the store.\n\n  [#1761](https://github.com/bytecodealliance/wasmtime/pull/1761)\n\n--------------------------------------------------------------------------------\n\n## 0.16.0\n\nReleased 2020-04-29.\n\n### Added\n\n* The `Instance` struct has new accessors, `get_func`, `get_table`,\n  `get_memory`, and `get_global` for quickly looking up exported\n  functions, tables, memories, and globals by name.\n  [#1524](https://github.com/bytecodealliance/wasmtime/pull/1524)\n\n* The C API has a number of new `wasmtime_*` functions which return error\n  objects to get detailed error information when an API fails.\n  [#1467](https://github.com/bytecodealliance/wasmtime/pull/1467)\n\n* Users now have fine-grained control over creation of instances of `Memory`\n  with a new `MemoryCreator` trait.\n  [#1400](https://github.com/bytecodealliance/wasmtime/pull/1400)\n\n* Go bindings for Wasmtime are [now available][go-bindings].\n  [#1481](https://github.com/bytecodealliance/wasmtime/pull/1481)\n\n* APIs for looking up values in a `Linker` have been added.\n  [#1480](https://github.com/bytecodealliance/wasmtime/pull/1480)\n\n* Preliminary support for AArch64, also known as ARM64.\n  [#1581](https://github.com/bytecodealliance/wasmtime/pull/1581)\n\n[go-bindings]: https://github.com/bytecodealliance/wasmtime-go\n\n### Changed\n\n* `Instance::exports` now returns `Export` objects which contain\n  the `name`s of the exports in addition to their `Extern` definitions,\n  so it's no longer necessary to use `Module::exports` to obtain the\n  export names.\n  [#1524](https://github.com/bytecodealliance/wasmtime/pull/1524)\n\n* The `Func::call` API has changed its error type from `Trap` to `anyhow::Error`\n  to distinguish between wasm traps and runtime violations (like the wrong\n  number of parameters).\n  [#1467](https://github.com/bytecodealliance/wasmtime/pull/1467)\n\n* A number of `wasmtime_linker_*` and `wasmtime_config_*` C APIs have new type\n  signatures which reflect returning errors.\n  [#1467](https://github.com/bytecodealliance/wasmtime/pull/1467)\n\n* Bindings for .NET have moved to\n  https://github.com/bytecodealliance/wasmtime-dotnet.\n  [#1477](https://github.com/bytecodealliance/wasmtime/pull/1477)\n\n* Passing too many imports to `Instance::new` is now considered an error.\n  [#1478](https://github.com/bytecodealliance/wasmtime/pull/1478)\n\n### Fixed\n\n* Spurious segfaults due to out-of-stack conditions when handling signals have\n  been fixed.\n  [#1315](https://github.com/bytecodealliance/wasmtime/pull/1315)\n\n--------------------------------------------------------------------------------\n\n## 0.15.0\n\nReleased 2020-03-31.\n\n### Fixed\n\nFull release produced for all artifacts to account for hiccups in 0.13.0 and\n0.14.0.\n\n--------------------------------------------------------------------------------\n\n## 0.14.0\n\n*This version ended up not getting a full release*\n\n### Fixed\n\nFix build errors in wasi-common on Windows.\n\n--------------------------------------------------------------------------------\n\n## 0.13.0\n\nReleased 2020-03-24.\n\n### Added\n\n* Lots of documentation of `wasmtime` has been updated. Be sure to check out the\n  [book](https://bytecodealliance.github.io/wasmtime/) and [API\n  documentation](https://bytecodealliance.github.io/wasmtime/api/wasmtime/)!\n\n* All wasmtime example programs are now in a top-level `examples` directory and\n  are available in both C and Rust.\n  [#1286](https://github.com/bytecodealliance/wasmtime/pull/1286)\n\n* A `wasmtime::Linker` type was added to conveniently link link wasm modules\n  together and create instances that reference one another.\n  [#1384](https://github.com/bytecodealliance/wasmtime/pull/1384)\n\n* Wasmtime now has \"jitdump\" support enabled by default which allows [profiling\n  wasm code on linux][jitdump].\n  [#1310](https://github.com/bytecodealliance/wasmtime/pull/1310)\n\n* The `wasmtime::Caller` type now exists as a first-class way to access the\n  caller's exports, namely memory, when implementing host APIs. This can be the\n  first argument of functions defined with `Func::new` or `Func::wrap` which\n  allows easily implementing methods which take a pointer into wasm memory. Note\n  that this only works for accessing the caller's `Memory` for now and it must\n  be exported. This will eventually be replaced with a more general-purpose\n  mechanism like interface types.\n  [#1290](https://github.com/bytecodealliance/wasmtime/pull/1290)\n\n* The bulk memory proposal has been fully implemented.\n  [#1264](https://github.com/bytecodealliance/wasmtime/pull/1264)\n  [#976](https://github.com/bytecodealliance/wasmtime/pull/976)\n\n* Virtual file support has been added to `wasi-common`.\n  [#701](https://github.com/bytecodealliance/wasmtime/pull/701)\n\n* The C API has been enhanced with a Wasmtime-specific `wasmtime_wat2wasm` to\n  parse `*.wat` files via the C API.\n  [#1206](https://github.com/bytecodealliance/wasmtime/pull/1206)\n\n[jitdump]: https://bytecodealliance.github.io/wasmtime/examples-profiling.html\n\n### Changed\n\n* The `wast` and `wasm2obj` standalone binaries have been removed. They're\n  available via the `wasmtime wast` and `wasmtime wasm2obj` subcommands.\n  [#1372](https://github.com/bytecodealliance/wasmtime/pull/1372)\n\n* The `wasi-common` crate now uses the new `wiggle` crate to auto-generate a\n  trait which is implemented for the current wasi snapshot.\n  [#1202](https://github.com/bytecodealliance/wasmtime/pull/1202)\n\n* Wasmtime no longer has a dependency on a C++ compiler.\n  [#1365](https://github.com/bytecodealliance/wasmtime/pull/1365)\n\n* The `Func::wrapN` APIs have been consolidated into one `Func::wrap` API.\n  [#1363](https://github.com/bytecodealliance/wasmtime/pull/1363)\n\n* The `Callable` trait has been removed and now `Func::new` takes a closure\n  directly.\n  [#1363](https://github.com/bytecodealliance/wasmtime/pull/1363)\n\n* The Cranelift repository has been merged into the Wasmtime repository.\n\n* Support for interface types has been temporarily removed.\n  [#1292](https://github.com/bytecodealliance/wasmtime/pull/1292)\n\n* The exit code of the `wasmtime` CLI has changed if the program traps.\n  [#1274](https://github.com/bytecodealliance/wasmtime/pull/1274)\n\n* The `wasmtime` CLI now logs to stderr by default and the `-d` flag has been\n  renamed to `--log-to-file`.\n  [#1266](https://github.com/bytecodealliance/wasmtime/pull/1266)\n\n* Values cannot cross `Store` objects, meaning you can't instantiate a module\n  with values from different stores nor pass values from different stores into\n  methods.\n  [#1016](https://github.com/bytecodealliance/wasmtime/pull/1016)\n\n--------------------------------------------------------------------------------\n\n## 0.12.0\n\nReleased 2020-02-26.\n\n### Added\n\n* Support for the [WebAssembly text annotations proposal][annotations-proposal]\n  has been added.\n  [#998](https://github.com/bytecodealliance/wasmtime/pull/998)\n\n* An initial C API for instantiating WASI modules has been added.\n  [#977](https://github.com/bytecodealliance/wasmtime/pull/977)\n\n* A new suite of `Func::getN` functions have been added to the `wasmtime` API to\n  call statically-known function signatures in a highly optimized fashion.\n  [#955](https://github.com/bytecodealliance/wasmtime/pull/955)\n\n* Initial support for profiling JIT code through perf jitdump has been added.\n  [#360](https://github.com/bytecodealliance/wasmtime/pull/360)\n\n* More CLI flags corresponding to proposed WebAssembly features have been added.\n  [#917](https://github.com/bytecodealliance/wasmtime/pull/917)\n\n[annotations-proposal]: https://github.com/webassembly/annotations\n\n### Changed\n\n* The `wasmtime` CLI as well as embedding API will optimize WebAssembly code by\n  default now.\n  [#973](https://github.com/bytecodealliance/wasmtime/pull/973)\n  [#988](https://github.com/bytecodealliance/wasmtime/pull/988)\n\n* The `verifier` pass in Cranelift is now no longer run by default when using\n  the embedding API.\n  [#882](https://github.com/bytecodealliance/wasmtime/pull/882)\n\n### Fixed\n\n* Code caching now accurately accounts for optimization levels, ensuring that if\n  you ask for optimized code you're not accidentally handed unoptimized code\n  from the cache.\n  [#974](https://github.com/bytecodealliance/wasmtime/pull/974)\n\n* Automated releases for tags should be up and running again, along with\n  automatic publication of the `wasmtime` Python package.\n  [#971](https://github.com/bytecodealliance/wasmtime/pull/971)\n", ";; Extern type definitions and constructors for the x64 `MachInst` type.\n\n;;;; `MInst` ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n\n;; Don't build `MInst` variants directly, in general. Instead, use the\n;; instruction-emitting helpers defined further down.\n\n(type MInst nodebug\n      (enum\n       ;; Nops of various sizes, including zero.\n       (Nop (len u8))\n\n       ;; =========================================\n       ;; Integer instructions.\n\n       ;; Integer arithmetic/bit-twiddling.\n       (AluRmiR (size OperandSize) ;; 4 or 8\n                (op AluRmiROpcode)\n                (src1 Gpr)\n                (src2 GprMemImm)\n                (dst WritableGpr))\n\n       ;; Integer arithmetic read-modify-write on memory.\n       (AluRM (size OperandSize) ;; 4 or 8\n              (op AluRmiROpcode)\n              (src1_dst SyntheticAmode)\n              (src2 Gpr))\n\n       ;; Integer arithmetic binary op that relies on the VEX prefix.\n       ;; NOTE: we don't currently support emitting VEX instructions with memory\n       ;; arguments, so `src2` is artificially constrained to be a Gpr.\n       (AluRmRVex (size OperandSize)\n                  (op AluRmROpcode)\n                  (src1 Gpr)\n                  (src2 Gpr)\n                  (dst WritableGpr))\n\n       ;; Production of a zero value into a register of the specified size.\n       (AluConstOp (op AluRmiROpcode)\n                   (size OperandSize)\n                   (dst WritableGpr))\n\n       ;; Instructions on general-purpose registers that only read src and\n       ;; defines dst (dst is not modified). `bsr`, etc.\n       (UnaryRmR (size OperandSize) ;; 2, 4, or 8\n                 (op UnaryRmROpcode)\n                 (src GprMem)\n                 (dst WritableGpr))\n\n       ;; Bitwise not.\n       (Not (size OperandSize) ;; 1, 2, 4, or 8\n            (src Gpr)\n            (dst WritableGpr))\n\n       ;; Integer negation.\n       (Neg (size OperandSize) ;; 1, 2, 4, or 8\n            (src Gpr)\n            (dst WritableGpr))\n\n       ;; Integer quotient and remainder: (div idiv) $rax $rdx (reg addr)\n       (Div (size OperandSize) ;; 1, 2, 4, or 8\n            (signed bool)\n            (divisor GprMem)\n            (dividend_lo Gpr)\n            (dividend_hi Gpr)\n            (dst_quotient WritableGpr)\n            (dst_remainder WritableGpr))\n\n       ;; The high (and low) bits of a (un)signed multiply: `RDX:RAX := RAX *\n       ;; rhs`.\n       (MulHi (size OperandSize)\n              (signed bool)\n              (src1 Gpr)\n              (src2 GprMem)\n              (dst_lo WritableGpr)\n              (dst_hi WritableGpr))\n\n       ;; A synthetic sequence to implement the right inline checks for\n       ;; remainder and division, assuming the dividend is in %rax.\n       ;;\n       ;; The generated code sequence is described in the emit's function match\n       ;; arm for this instruction.\n       (CheckedDivOrRemSeq (kind DivOrRemKind)\n                           (size OperandSize)\n                           (dividend_lo Gpr)\n                           (dividend_hi Gpr)\n                           (divisor Gpr)\n                           (dst_quotient WritableGpr)\n                           (dst_remainder WritableGpr)\n                           (tmp OptionWritableGpr))\n\n       ;; Do a sign-extend based on the sign of the value in rax into rdx: (cwd\n       ;; cdq cqo) or al into ah: (cbw)\n       (SignExtendData (size OperandSize) ;; 1, 2, 4, or 8\n                       (src Gpr)\n                       (dst WritableGpr))\n\n       ;; Constant materialization: (imm32 imm64) reg.\n       ;;\n       ;; Either: movl $imm32, %reg32 or movabsq $imm64, %reg32.\n       (Imm (dst_size OperandSize) ;; 4 or 8\n            (simm64 u64)\n            (dst WritableGpr))\n\n       ;; GPR to GPR move: mov (64 32) reg reg.\n       (MovRR (size OperandSize) ;; 4 or 8\n              (src Gpr)\n              (dst WritableGpr))\n\n       ;; Like `MovRR` but with a physical register source (for implementing\n       ;; CLIF instructions like `get_stack_pointer`).\n       (MovFromPReg (src PReg)\n                    (dst WritableGpr))\n\n       ;; Like `MovRR` but with a physical register destination (for\n       ;; implementing CLIF instructions like `set_pinned_reg`).\n       (MovToPReg (src Gpr)\n                  (dst PReg))\n\n       ;; Zero-extended loads, except for 64 bits: movz (bl bq wl wq lq) addr\n       ;; reg.\n       ;;\n       ;; Note that the lq variant doesn't really exist since the default\n       ;; zero-extend rule makes it unnecessary. For that case we emit the\n       ;; equivalent \"movl AM, reg32\".\n       (MovzxRmR (ext_mode ExtMode)\n                 (src GprMem)\n                 (dst WritableGpr))\n\n       ;; A plain 64-bit integer load, since MovZX_RM_R can't represent that.\n       (Mov64MR (src SyntheticAmode)\n                (dst WritableGpr))\n\n       ;; Loads the memory address of addr into dst.\n       (LoadEffectiveAddress (addr SyntheticAmode)\n                             (dst WritableGpr))\n\n       ;; Sign-extended loads and moves: movs (bl bq wl wq lq) addr reg.\n       (MovsxRmR (ext_mode ExtMode)\n                 (src GprMem)\n                 (dst WritableGpr))\n\n       ;; Immediate store.\n       (MovImmM (size OperandSize)\n\t\t(simm64 u64)\n\t\t(dst SyntheticAmode))\n\n       ;; Integer stores: mov (b w l q) reg addr.\n       (MovRM (size OperandSize) ;; 1, 2, 4, or 8\n              (src Gpr)\n              (dst SyntheticAmode))\n\n       ;; Arithmetic shifts: (shl shr sar) (b w l q) imm reg.\n       (ShiftR (size OperandSize) ;; 1, 2, 4, or 8\n               (kind ShiftKind)\n               (src Gpr)\n               ;; shift count: `Imm8Gpr::Imm8(0 .. #bits-in-type - 1)` or\n               ;; `Imm8Reg::Gpr(r)` where `r` get's move mitosis'd into `%cl`.\n               (num_bits Imm8Gpr)\n               (dst WritableGpr))\n\n       ;; Arithmetic SIMD shifts.\n       (XmmRmiReg (opcode SseOpcode)\n                  (src1 Xmm)\n                  (src2 XmmMemAlignedImm)\n                  (dst WritableXmm))\n\n       ;; Integer comparisons/tests: cmp or test (b w l q) (reg addr imm) reg.\n       (CmpRmiR (size OperandSize) ;; 1, 2, 4, or 8\n                (opcode CmpOpcode)\n                (src GprMemImm)\n                (dst Gpr))\n\n       ;; Materializes the requested condition code in the destinaton reg.\n       (Setcc (cc CC)\n              (dst WritableGpr))\n\n       ;; Swaps byte order in register\n       (Bswap (size OperandSize) ;; 4 or 8\n              (src Gpr)\n              (dst WritableGpr))\n\n       ;; =========================================\n       ;; Conditional moves.\n\n       ;; GPR conditional move; overwrites the destination register.\n       (Cmove (size OperandSize)\n              (cc CC)\n              (consequent GprMem)\n              (alternative Gpr)\n              (dst WritableGpr))\n\n       ;; XMM conditional move; overwrites the destination register.\n       (XmmCmove (ty Type)\n                 (cc CC)\n                 (consequent XmmMemAligned)\n                 (alternative Xmm)\n                 (dst WritableXmm))\n\n       ;; =========================================\n       ;; Stack manipulation.\n\n       ;; pushq (reg addr imm)\n       (Push64 (src GprMemImm))\n\n       ;; popq reg\n       (Pop64 (dst WritableGpr))\n\n      ;; Emits a inline stack probe loop.\n      (StackProbeLoop (tmp WritableReg)\n                      (frame_size u32)\n                      (guard_size u32))\n\n       ;; =========================================\n       ;; Floating-point operations.\n\n       ;; XMM (scalar or vector) binary op: (add sub and or xor mul adc? sbb?)\n       ;; (32 64) (reg addr) reg\n       (XmmRmR (op SseOpcode)\n               (src1 Xmm)\n               (src2 XmmMemAligned)\n               (dst WritableXmm))\n\n       ;; Same as `XmmRmR` except the memory operand can be unaligned\n       (XmmRmRUnaligned (op SseOpcode)\n                        (src1 Xmm)\n                        (src2 XmmMem)\n                        (dst WritableXmm))\n\n       ;; XMM (scalar or vector) production of a constant value by operating\n       ;; on a register with itself.\n       ;;\n       ;; Used to produce all zeros with xor or all one with a comparison.\n       (XmmConstOp (op SseOpcode)\n                   (dst WritableXmm))\n\n       ;; XMM (scalar or vector) blend op. The mask is used to blend between\n       ;; src1 and src2. This differs from a use of `XmmRmR` as the mask is\n       ;; implicitly in register xmm0; this special case exists to allow us to\n       ;; communicate the constraint on the `mask` register to regalloc2.\n       (XmmRmRBlend\n         (op SseOpcode)\n         (src1 Xmm)\n         (src2 XmmMemAligned)\n         (mask Xmm)\n         (dst WritableXmm))\n\n       ;; XMM (scalar or vector) binary op that relies on the VEX prefix and\n       ;; has two inputs.\n       (XmmRmiRVex (op AvxOpcode)\n                   (src1 Xmm)\n                   (src2 XmmMemImm)\n                   (dst WritableXmm))\n\n       ;; XMM (scalar or vector) ternary op that relies on the VEX prefix and\n       ;; has two dynamic inputs plus one immediate input.\n       (XmmRmRImmVex (op AvxOpcode)\n                     (src1 Xmm)\n                     (src2 XmmMem)\n                     (dst WritableXmm)\n                     (imm u8))\n\n       ;; XMM instruction for `vpinsr{b,w,d,q}` which is separte from\n       ;; `XmmRmRImmVex` because `src2` is a gpr, not xmm register.\n       (XmmVexPinsr (op AvxOpcode)\n                   (src1 Xmm)\n                   (src2 GprMem)\n                   (dst WritableXmm)\n                   (imm u8))\n\n       ;; XMM (scalar or vector) ternary op that relies on the VEX prefix and\n       ;; has three dynamic inputs.\n       (XmmRmRVex3 (op AvxOpcode)\n                   (src1 Xmm)\n                   (src2 Xmm)\n                   (src3 XmmMem)\n                   (dst WritableXmm))\n\n       ;; XMM blend operation using the VEX encoding.\n       (XmmRmRBlendVex (op AvxOpcode)\n                       (src1 Xmm)\n                       (src2 XmmMem)\n                       (mask Xmm)\n                       (dst WritableXmm))\n\n       ;; XMM unary op using a VEX encoding (aka AVX).\n       (XmmUnaryRmRVex (op AvxOpcode)\n                       (src XmmMem)\n                       (dst WritableXmm))\n\n       ;; XMM unary op using a VEX encoding (aka AVX) with an immediate.\n       (XmmUnaryRmRImmVex (op AvxOpcode)\n                          (src XmmMem)\n                          (dst WritableXmm)\n                          (imm u8))\n\n       ;; XMM (scalar or vector) binary op that relies on the EVEX\n       ;; prefix. Takes two inputs.\n       (XmmRmREvex (op Avx512Opcode)\n                   (src1 XmmMem)\n                   (src2 Xmm)\n                   (dst WritableXmm))\n\n       ;; XMM (scalar or vector) binary op that relies on the EVEX\n       ;; prefix. Takes three inputs.\n       (XmmRmREvex3 (op Avx512Opcode)\n                   (src1 XmmMem)\n                   (src2 Xmm)\n                   (src3 Xmm)\n                   (dst WritableXmm))\n\n       ;; XMM (scalar or vector) unary op: mov between XMM registers (32 64)\n       ;; (reg addr) reg, sqrt, etc.\n       ;;\n       ;; This differs from XMM_RM_R in that the dst register of XmmUnaryRmR is\n       ;; not used in the computation of the instruction dst value and so does\n       ;; not have to be a previously valid value. This is characteristic of mov\n       ;; instructions.\n       (XmmUnaryRmR (op SseOpcode)\n                    (src XmmMemAligned)\n                    (dst WritableXmm))\n\n       ;; Same as `XmmUnaryRmR` but used for opcodes where the memory address\n       ;; can be unaligned.\n       (XmmUnaryRmRUnaligned (op SseOpcode)\n                             (src XmmMem)\n                             (dst WritableXmm))\n\n       ;; XMM (scalar or vector) unary op with immediate: roundss, roundsd, etc.\n       ;;\n       ;; This differs from XMM_RM_R_IMM in that the dst register of\n       ;; XmmUnaryRmRImm is not used in the computation of the instruction dst\n       ;; value and so does not have to be a previously valid value.\n       (XmmUnaryRmRImm (op SseOpcode)\n                       (src XmmMemAligned)\n                       (imm u8)\n                       (dst WritableXmm))\n\n       ;; XMM (scalar or vector) unary op that relies on the EVEX prefix.\n       (XmmUnaryRmREvex (op Avx512Opcode)\n                        (src XmmMem)\n                        (dst WritableXmm))\n\n       ;; XMM (scalar or vector) unary op (from xmm to reg/mem): stores, movd,\n       ;; movq\n       (XmmMovRM (op SseOpcode)\n                 (src Reg)\n                 (dst SyntheticAmode))\n\n       ;; XMM (scalar) unary op (from xmm to integer reg): movd, movq,\n       ;; cvtts{s,d}2si\n       (XmmToGpr (op SseOpcode)\n                 (src Xmm)\n                 (dst WritableGpr)\n                 (dst_size OperandSize))\n\n       ;; XMM (scalar) unary op (from xmm to integer reg): pextr{w,b,d,q}\n       (XmmToGprImm (op SseOpcode)\n                    (src Xmm)\n                    (dst WritableGpr)\n                    (imm u8))\n\n       ;; XMM (scalar) unary op (from integer to float reg): movd, movq,\n       ;; cvtsi2s{s,d}\n       (GprToXmm (op SseOpcode)\n                 (src GprMem)\n                 (dst WritableXmm)\n                 (src_size OperandSize))\n\n       ;; Converts an unsigned int64 to a float32/float64.\n       (CvtUint64ToFloatSeq (dst_size OperandSize) ;; 4 or 8\n                            (src Gpr)\n                            (dst WritableXmm)\n                            (tmp_gpr1 WritableGpr)\n                            (tmp_gpr2 WritableGpr))\n\n       ;; Converts a scalar xmm to a signed int32/int64.\n       (CvtFloatToSintSeq (dst_size OperandSize)\n                          (src_size OperandSize)\n                          (is_saturating bool)\n                          (src Xmm)\n                          (dst WritableGpr)\n                          (tmp_gpr WritableGpr)\n                          (tmp_xmm WritableXmm))\n\n       ;; Converts a scalar xmm to an unsigned int32/int64.\n       (CvtFloatToUintSeq (dst_size OperandSize)\n                          (src_size OperandSize)\n                          (is_saturating bool)\n                          (src Xmm)\n                          (dst WritableGpr)\n                          (tmp_gpr WritableGpr)\n                          (tmp_xmm WritableXmm)\n                          (tmp_xmm2 WritableXmm))\n\n       ;; A sequence to compute min/max with the proper NaN semantics for xmm\n       ;; registers.\n       (XmmMinMaxSeq (size OperandSize)\n                     (is_min bool)\n                     (lhs Xmm)\n                     (rhs Xmm)\n                     (dst WritableXmm))\n\n       ;; Float comparisons/tests: cmp (b w l q) (reg addr imm) reg.\n       (XmmCmpRmR (op SseOpcode)\n                  (src XmmMemAligned)\n                  (dst Xmm))\n\n       ;; A binary XMM instruction with an 8-bit immediate: e.g. cmp (ps pd) imm\n       ;; (reg addr) reg\n       ;;\n       ;; Note: this has to use `Reg*`, not `Xmm*`, operands because it is used\n       ;; in various lane insertion and extraction instructions that move\n       ;; between XMMs and GPRs.\n       (XmmRmRImm (op SseOpcode)\n                  (src1 Reg)\n                  (src2 RegMem)\n                  (dst WritableReg)\n                  (imm u8)\n                  (size OperandSize))\n\n       ;; =========================================\n       ;; Control flow instructions.\n\n       ;; Direct call: call simm32.\n       (CallKnown (dest ExternalName)\n                  (info BoxCallInfo))\n\n       ;; Indirect call: callq (reg mem)\n       (CallUnknown (dest RegMem)\n                    (info BoxCallInfo))\n\n       ;; A pseudo-instruction that captures register arguments in vregs.\n       (Args\n        (args VecArgPair))\n\n       ;; Return.\n       (Ret (rets VecRetPair))\n\n       ;; Jump to a known target: jmp simm32.\n       (JmpKnown (dst MachLabel))\n\n       ;; One-way conditional branch: jcond cond target.\n       ;;\n       ;; This instruction is useful when we have conditional jumps depending on\n       ;; more than two conditions, see for instance the lowering of Brif\n       ;; with Fcmp inputs.\n       ;;\n       ;; A note of caution: in contexts where the branch target is another\n       ;; block, this has to be the same successor as the one specified in the\n       ;; terminator branch of the current block.  Otherwise, this might confuse\n       ;; register allocation by creating new invisible edges.\n       (JmpIf (cc CC)\n              (taken MachLabel))\n\n       ;; Two-way conditional branch: jcond cond target target.\n       ;;\n       ;; Emitted as a compound sequence; the MachBuffer will shrink it as\n       ;; appropriate.\n       (JmpCond (cc CC)\n                (taken MachLabel)\n                (not_taken MachLabel))\n\n       ;; Jump-table sequence, as one compound instruction (see note in lower.rs\n       ;; for rationale).\n       ;;\n       ;; The generated code sequence is described in the emit's function match\n       ;; arm for this instruction.\n       ;;\n       ;; See comment on jmp_table_seq below about the temporaries signedness.\n       (JmpTableSeq (idx Reg)\n                    (tmp1 WritableReg)\n                    (tmp2 WritableReg)\n                    (default_target MachLabel)\n                    (targets BoxVecMachLabel))\n\n       ;; Indirect jump: jmpq (reg mem).\n       (JmpUnknown (target RegMem))\n\n       ;; Traps if the condition code is set.\n       (TrapIf (cc CC)\n               (trap_code TrapCode))\n\n       ;; Traps if both of the condition codes are set.\n       (TrapIfAnd (cc1 CC)\n                  (cc2 CC)\n                  (trap_code TrapCode))\n\n       ;; Traps if either of the condition codes are set.\n       (TrapIfOr (cc1 CC)\n                 (cc2 CC)\n                 (trap_code TrapCode))\n\n       ;; A debug trap.\n       (Hlt)\n\n       ;; An instruction that will always trigger the illegal instruction\n       ;; exception.\n       (Ud2 (trap_code TrapCode))\n\n       ;; Loads an external symbol in a register, with a relocation:\n       ;;\n       ;; movq $name@GOTPCREL(%rip), dst    if PIC is enabled, or\n       ;; movabsq $name, dst                otherwise.\n       (LoadExtName (dst WritableReg)\n                    (name BoxExternalName)\n                    (offset i64))\n\n       ;; =========================================\n       ;; Instructions pertaining to atomic memory accesses.\n\n       ;; A standard (native) `lock cmpxchg src, (amode)`, with register\n       ;; conventions:\n       ;;\n       ;; `mem`          (read) address\n       ;; `replacement`  (read) replacement value\n       ;; %rax           (modified) in: expected value, out: value that was actually at `dst`\n       ;; %rflags is written.  Do not assume anything about it after the instruction.\n       ;;\n       ;; The instruction \"succeeded\" iff the lowest `ty` bits of %rax\n       ;; afterwards are the same as they were before.\n       (LockCmpxchg (ty Type) ;; I8, I16, I32, or I64\n                    (replacement Reg)\n                    (expected Reg)\n                    (mem SyntheticAmode)\n                    (dst_old WritableReg))\n\n       ;; A synthetic instruction, based on a loop around a native `lock\n       ;; cmpxchg` instruction.\n       ;;\n       ;; This atomically modifies a value in memory and returns the old value.\n       ;; The sequence consists of an initial \"normal\" load from `dst`, followed\n       ;; by a loop which computes the new value and tries to compare-and-swap\n       ;; (\"CAS\") it into `dst`, using the native instruction `lock\n       ;; cmpxchg{b,w,l,q}`.  The loop iterates until the CAS is successful. If\n       ;; there is no contention, there will be only one pass through the loop\n       ;; body.  The sequence does *not* perform any explicit memory fence\n       ;; instructions (`mfence`/`sfence`/`lfence`).\n       ;;\n       ;; Note that the transaction is atomic in the sense that, as observed by\n       ;; some other thread, `dst` either has the initial or final value, but no\n       ;; other.  It isn't atomic in the sense of guaranteeing that no other\n       ;; thread writes to `dst` in between the initial load and the CAS -- but\n       ;; that would cause the CAS to fail unless the other thread's last write\n       ;; before the CAS wrote the same value that was already there.  In other\n       ;; words, this implementation suffers (unavoidably) from the A-B-A\n       ;; problem.\n       ;;\n       ;; This instruction sequence has fixed register uses as follows:\n       ;; - %rax  (written) the old value at `mem`\n       ;; - %rflags is written.  Do not assume anything about it after the\n       ;;   instruction.\n       (AtomicRmwSeq (ty Type) ;; I8, I16, I32, or I64\n                     (op MachAtomicRmwOp)\n                     (mem SyntheticAmode)\n                     (operand Reg)\n                     (temp WritableReg)\n                     (dst_old WritableReg))\n\n       ;; A memory fence (mfence, lfence or sfence).\n       (Fence (kind FenceKind))\n\n       ;; =========================================\n       ;; Meta-instructions generating no code.\n\n       ;; Marker, no-op in generated code: SP \"virtual offset\" is adjusted.\n       ;;\n       ;; This controls how `MemArg::NominalSPOffset` args are lowered.\n       (VirtualSPOffsetAdj (offset i64))\n\n       ;; Provides a way to tell the register allocator that the upcoming\n       ;; sequence of instructions will overwrite `dst` so it should be\n       ;; considered as a `def`; use this with care.\n       ;;\n       ;; This is useful when we have a sequence of instructions whose register\n       ;; usages are nominally `mod`s, but such that the combination of\n       ;; operations creates a result that is independent of the initial\n       ;; register value. It's thus semantically a `def`, not a `mod`, when all\n       ;; the instructions are taken together, so we want to ensure the register\n       ;; is defined (its live-range starts) prior to the sequence to keep\n       ;; analyses happy.\n       ;;\n       ;; One alternative would be a compound instruction that somehow\n       ;; encapsulates the others and reports its own `def`s/`use`s/`mod`s; this\n       ;; adds complexity (the instruction list is no longer flat) and requires\n       ;; knowledge about semantics and initial-value independence anyway.\n       (XmmUninitializedValue (dst WritableXmm))\n\n       ;; A call to the `ElfTlsGetAddr` libcall. Returns address of TLS symbol\n       ;; `dst`, which is constrained to `rax`.\n       (ElfTlsGetAddr (symbol ExternalName)\n                      (dst WritableGpr))\n\n       ;; A Mach-O TLS symbol access. Returns address of the TLS symbol in\n       ;; `dst`, which is constrained to `rax`.\n       (MachOTlsGetAddr (symbol ExternalName)\n                        (dst WritableGpr))\n\n       ;; A Coff TLS symbol access. Returns address of the TLS symbol in\n       ;; `dst`, which is constrained to `rax`.\n       (CoffTlsGetAddr (symbol ExternalName)\n                       (dst WritableGpr)\n                       (tmp WritableGpr))\n\n       ;; An unwind pseudoinstruction describing the state of the machine at\n       ;; this program point.\n       (Unwind (inst UnwindInst))\n\n       ;; A pseudoinstruction that just keeps a value alive.\n       (DummyUse (reg Reg))))\n\n(type OperandSize extern\n      (enum Size8\n            Size16\n            Size32\n            Size64))\n\n(type FenceKind extern\n      (enum MFence\n            LFence\n            SFence))\n\n(type BoxCallInfo extern (enum))\n\n(type BoxVecMachLabel extern (enum))\n\n(type MachLabelSlice extern (enum))\n\n;; The size of the jump table.\n(decl jump_table_size (BoxVecMachLabel) u32)\n(extern constructor jump_table_size jump_table_size)\n\n;; Extract a the target from a MachLabelSlice with exactly one target.\n(decl single_target (MachLabel) MachLabelSlice)\n(extern extractor single_target single_target)\n\n;; Extract a the targets from a MachLabelSlice with exactly two targets.\n(decl two_targets (MachLabel MachLabel) MachLabelSlice)\n(extern extractor two_targets two_targets)\n\n;; Extract the default target and jump table from a MachLabelSlice.\n(decl jump_table_targets (MachLabel BoxVecMachLabel) MachLabelSlice)\n(extern extractor jump_table_targets jump_table_targets)\n\n;; Get the `OperandSize` for a given `Type`, rounding smaller types up to 32 bits.\n(decl operand_size_of_type_32_64 (Type) OperandSize)\n(extern constructor operand_size_of_type_32_64 operand_size_of_type_32_64)\n\n;; Get the true `OperandSize` for a given `Type`, with no rounding.\n(decl raw_operand_size_of_type (Type) OperandSize)\n(extern constructor raw_operand_size_of_type raw_operand_size_of_type)\n\n;; Get the bit width of an `OperandSize`.\n(decl operand_size_bits (OperandSize) u16)\n(rule (operand_size_bits (OperandSize.Size8)) 8)\n(rule (operand_size_bits (OperandSize.Size16)) 16)\n(rule (operand_size_bits (OperandSize.Size32)) 32)\n(rule (operand_size_bits (OperandSize.Size64)) 64)\n\n(type AluRmiROpcode extern\n      (enum Add\n            Adc\n            Sub\n            Sbb\n            And\n            Or\n            Xor\n            Mul))\n\n(type AluRmROpcode extern\n      (enum Andn))\n\n(type UnaryRmROpcode extern\n      (enum Bsr\n            Bsf\n            Lzcnt\n            Tzcnt\n            Popcnt))\n\n(type DivOrRemKind extern\n      (enum SignedDiv\n            UnsignedDiv\n            SignedRem\n            UnsignedRem))\n\n(type SseOpcode extern\n      (enum Addps\n            Addpd\n            Addss\n            Addsd\n            Andps\n            Andpd\n            Andnps\n            Andnpd\n            Blendvpd\n            Blendvps\n            Comiss\n            Comisd\n            Cmpps\n            Cmppd\n            Cmpss\n            Cmpsd\n            Cvtdq2ps\n            Cvtdq2pd\n            Cvtpd2ps\n            Cvtps2pd\n            Cvtsd2ss\n            Cvtsd2si\n            Cvtsi2ss\n            Cvtsi2sd\n            Cvtss2si\n            Cvtss2sd\n            Cvttpd2dq\n            Cvttps2dq\n            Cvttss2si\n            Cvttsd2si\n            Divps\n            Divpd\n            Divss\n            Divsd\n            Insertps\n            Maxps\n            Maxpd\n            Maxss\n            Maxsd\n            Minps\n            Minpd\n            Minss\n            Minsd\n            Movaps\n            Movapd\n            Movd\n            Movdqa\n            Movdqu\n            Movlhps\n            Movmskps\n            Movmskpd\n            Movq\n            Movss\n            Movsd\n            Movups\n            Movupd\n            Mulps\n            Mulpd\n            Mulss\n            Mulsd\n            Orps\n            Orpd\n            Pabsb\n            Pabsw\n            Pabsd\n            Packssdw\n            Packsswb\n            Packusdw\n            Packuswb\n            Paddb\n            Paddd\n            Paddq\n            Paddw\n            Paddsb\n            Paddsw\n            Paddusb\n            Paddusw\n            Palignr\n            Pand\n            Pandn\n            Pavgb\n            Pavgw\n            Pblendvb\n            Pcmpeqb\n            Pcmpeqw\n            Pcmpeqd\n            Pcmpeqq\n            Pcmpgtb\n            Pcmpgtw\n            Pcmpgtd\n            Pcmpgtq\n            Pextrb\n            Pextrw\n            Pextrd\n            Pextrq\n            Pinsrb\n            Pinsrw\n            Pinsrd\n            Pmaddubsw\n            Pmaddwd\n            Pmaxsb\n            Pmaxsw\n            Pmaxsd\n            Pmaxub\n            Pmaxuw\n            Pmaxud\n            Pminsb\n            Pminsw\n            Pminsd\n            Pminub\n            Pminuw\n            Pminud\n            Pmovmskb\n            Pmovsxbd\n            Pmovsxbw\n            Pmovsxbq\n            Pmovsxwd\n            Pmovsxwq\n            Pmovsxdq\n            Pmovzxbd\n            Pmovzxbw\n            Pmovzxbq\n            Pmovzxwd\n            Pmovzxwq\n            Pmovzxdq\n            Pmuldq\n            Pmulhw\n            Pmulhuw\n            Pmulhrsw\n            Pmulld\n            Pmullw\n            Pmuludq\n            Por\n            Pshufb\n            Pshufd\n            Psllw\n            Pslld\n            Psllq\n            Psraw\n            Psrad\n            Psrlw\n            Psrld\n            Psrlq\n            Psubb\n            Psubd\n            Psubq\n            Psubw\n            Psubsb\n            Psubsw\n            Psubusb\n            Psubusw\n            Ptest\n            Punpckhbw\n            Punpckhwd\n            Punpcklbw\n            Punpcklwd\n            Pxor\n            Rcpss\n            Roundps\n            Roundpd\n            Roundss\n            Roundsd\n            Rsqrtss\n            Shufps\n            Sqrtps\n            Sqrtpd\n            Sqrtss\n            Sqrtsd\n            Subps\n            Subpd\n            Subss\n            Subsd\n            Ucomiss\n            Ucomisd\n            Unpcklps\n            Xorps\n            Xorpd\n            Phaddw\n            Phaddd\n          ))\n\n(type CmpOpcode extern\n      (enum Cmp\n            Test))\n\n(type RegMemImm extern\n      (enum\n       (Reg (reg Reg))\n       (Mem (addr SyntheticAmode))\n       (Imm (simm32 u32))))\n\n;; Put the given clif value into a `RegMemImm` operand.\n;;\n;; Asserts that the value fits into a single register, and doesn't require\n;; multiple registers for its representation (like `i128` for example).\n;;\n;; As a side effect, this marks the value as used.\n(decl put_in_reg_mem_imm (Value) RegMemImm)\n(extern constructor put_in_reg_mem_imm put_in_reg_mem_imm)\n\n(type RegMem extern\n      (enum\n       (Reg (reg Reg))\n       (Mem (addr SyntheticAmode))))\n\n;; Convert a RegMem to a RegMemImm.\n(decl reg_mem_to_reg_mem_imm (RegMem) RegMemImm)\n(rule (reg_mem_to_reg_mem_imm (RegMem.Reg reg))\n      (RegMemImm.Reg reg))\n(rule (reg_mem_to_reg_mem_imm (RegMem.Mem addr))\n      (RegMemImm.Mem addr))\n\n;; Put the given clif value into a `RegMem` operand.\n;;\n;; Asserts that the value fits into a single register, and doesn't require\n;; multiple registers for its representation (like `i128` for example).\n;;\n;; As a side effect, this marks the value as used.\n(decl put_in_reg_mem (Value) RegMem)\n(extern constructor put_in_reg_mem put_in_reg_mem)\n\n;; Addressing modes.\n\n(type SyntheticAmode extern (enum))\n\n(decl synthetic_amode_to_reg_mem (SyntheticAmode) RegMem)\n(extern constructor synthetic_amode_to_reg_mem synthetic_amode_to_reg_mem)\n\n(decl amode_to_synthetic_amode (Amode) SyntheticAmode)\n(extern constructor amode_to_synthetic_amode amode_to_synthetic_amode)\n\n;; An `Amode` represents a possible addressing mode that can be used\n;; in instructions. These denote a 64-bit value only.\n(type Amode (enum\n             ;; Immediate sign-extended and a register\n             (ImmReg (simm32 u32)\n                     (base Reg)\n                     (flags MemFlags))\n\n             ;; Sign-extend-32-to-64(simm32) + base + (index << shift)\n             (ImmRegRegShift (simm32 u32)\n                             (base Gpr)\n                             (index Gpr)\n                             (shift u8)\n                             (flags MemFlags))\n\n             ;; Sign-extend-32-to-64(immediate) + RIP (instruction\n             ;; pointer). The appropriate relocation is emitted so\n             ;; that the resulting immediate makes this Amode refer to\n             ;; the given MachLabel.\n             (RipRelative (target MachLabel))))\n\n;; Some Amode constructor helpers.\n\n(decl amode_with_flags (Amode MemFlags) Amode)\n(extern constructor amode_with_flags amode_with_flags)\n\n(decl amode_imm_reg (u32 Gpr) Amode)\n(extern constructor amode_imm_reg amode_imm_reg)\n\n(decl amode_imm_reg_flags (u32 Gpr MemFlags) Amode)\n(rule (amode_imm_reg_flags offset base flags)\n      (amode_with_flags (amode_imm_reg offset base) flags))\n\n(decl amode_imm_reg_reg_shift (u32 Gpr Gpr u8) Amode)\n(extern constructor amode_imm_reg_reg_shift amode_imm_reg_reg_shift)\n\n(decl amode_imm_reg_reg_shift_flags (u32 Gpr Gpr u8 MemFlags) Amode)\n(rule (amode_imm_reg_reg_shift_flags offset base index shift flags)\n      (amode_with_flags (amode_imm_reg_reg_shift offset base index shift) flags))\n\n;; A helper to both check that the `Imm64` and `Offset32` values sum to less\n;; than 32-bits AND return this summed `u32` value. Also, the `Imm64` will be\n;; zero-extended from `Type` up to 64 bits. This is useful for `to_amode`.\n(decl pure partial sum_extend_fits_in_32_bits (Type Imm64 Offset32) u32)\n(extern constructor sum_extend_fits_in_32_bits sum_extend_fits_in_32_bits)\n\n;;;; Amode lowering ;;;;\n\n;; To generate an address for a memory access, we can pattern-match\n;; various CLIF sub-trees to x64's complex addressing modes (`Amode`).\n;;\n;; Information about available addressing modes is available in\n;; Intel's Software Developer's Manual, volume 2, section 2.1.5,\n;; \"Addressing-Mode Encoding of ModR/M and SIB Bytes.\"\n;;\n;; The general strategy to build an `Amode` is to traverse over the\n;; input expression's addends, recursively deconstructing a tree of\n;; `iadd` operators that add up parts of the address, updating the\n;; `Amode` in an incremental fashion as we add in each piece.\n;;\n;; We start with an \"immediate + register\" form that encapsulates the\n;; load/store's built-in `Offset32` and `invalid_reg` as the\n;; register. This is given by `amode_initial`. Then we add `Value`s\n;; one at a time with `amode_add`. (Why start with `invalid_reg` at\n;; all? Because we don't want to special-case the first input and\n;; duplicate rules; this lets us use the \"add a value\" logic even for\n;; the first value.)\n;;\n;; It is always valid to use `amode_add` to add the one single\n;; `address` input to the load/store (i.e., the `Value` given to\n;; `to_amode`). In the fallback case, this is what we do. Then we get\n;; an `Amode.ImmReg` with the `Offset32` and `Value` below and nothing\n;; else; this always works and is not *that* bad.\n;;\n;; But we can often do better. The toplevel rule for `iadd` below will\n;; turn an `(amode_add amode (iadd a b))` into two invocations of\n;; `amode_add`, for each operand of the `iadd`. This is what allows us\n;; to handle sums of many parts.\n;;\n;; Then we \"just\" need to work out how we can incorporate a new\n;; component into an existing addressing mode:\n;;\n;; - Case 1: When we have an `ImmReg` and the register is\n;;   `invalid_reg` (the initial `Amode` above), we can put the new\n;;   addend into a register and insert it into the `ImmReg`.\n;;\n;; - Case 2: When we have an `ImmReg` with a valid register already,\n;;   and we have another register to add, we can transition to an\n;;   `ImmRegRegShift`.\n;;\n;; - Case 3: When we're adding an `ishl`, we can refine the above rule\n;;   and use the built-in multiplier of 1, 2, 4, 8 to implement a\n;;   left-shift by 0, 1, 2, 3.\n;;\n;; - Case 4: When we are adding another constant offset, we can fold\n;;   it into the existing offset, as long as the sum still fits into\n;;   the signed 32-bit field.\n;;\n;; - Case 5: And as a general fallback, we can generate a new `add`\n;;   instruction and add the new addend to an existing component of\n;;   the `Amode`.\n(decl to_amode (MemFlags Value Offset32) Amode)\n\n;; Initial step in amode processing: create an ImmReg with\n;; (invalid_reg) and encapsulating the flags and offset from the\n;; load/store.\n(decl amode_initial (MemFlags Offset32) Amode)\n(rule (amode_initial flags (offset32 off))\n      (Amode.ImmReg off (invalid_reg) flags))\n\n;; One step in amode processing: take an existing amode and add\n;; another value to it.\n(decl amode_add (Amode Value) Amode)\n\n;; -- Top-level driver: pull apart the addends.\n;;\n;; Any amode can absorb an `iadd` by absorbing first the LHS of the\n;; add, then the RHS.\n;;\n;; Priority 2 to take this above fallbacks and ensure we traverse the\n;; `iadd` tree fully.\n(rule 2 (amode_add amode (iadd x y))\n      (let ((amode1 Amode (amode_add amode x))\n            (amode2 Amode (amode_add amode1 y)))\n        amode2))\n\n;; -- Case 1 (adding a register to the initial Amode with invalid_reg).\n;;\n;; An Amode.ImmReg with invalid_reg (initial state) can absorb a\n;; register as the base register.\n(rule (amode_add (Amode.ImmReg off (invalid_reg) flags) value)\n      (Amode.ImmReg off value flags))\n\n;; -- Case 2 (adding a register to an Amode with a register already).\n;;\n;; An Amode.ImmReg can absorb another register as the index register.\n(rule (amode_add (Amode.ImmReg off (valid_reg base) flags) value)\n      ;; Shift of 0 --> base + 1*value.\n      (Amode.ImmRegRegShift off base value 0 flags))\n\n;; -- Case 3 (adding a shifted value to an Amode).\n;;\n;; An Amode.ImmReg can absorb a shift of another register as the index register.\n;;\n;; Priority 2 to take these rules above generic case.\n(rule 2 (amode_add (Amode.ImmReg off (valid_reg base) flags) (ishl index (iconst (uimm8 shift))))\n      (if (u32_lteq (u8_as_u32 shift) 3))\n      (Amode.ImmRegRegShift off base index shift flags))\n(rule 2 (amode_add (Amode.ImmReg off (valid_reg base) flags) (uextend (ishl index (iconst (uimm8 shift)))))\n      (if (u32_lteq (u8_as_u32 shift) 3))\n      (Amode.ImmRegRegShift off base (extend_to_gpr index $I64 (ExtendKind.Zero)) shift flags))\n\n;; Same, but with a uextend of a shift of a 32-bit add. This is valid\n;; because we know our lowering of a narrower-than-64-bit `iadd` will\n;; always write the full register width, so we can effectively ignore\n;; the `uextend` and look through it to the `ishl`.\n;;\n;; Priority 3 to avoid conflict with the previous rule.\n(rule 3 (amode_add (Amode.ImmReg off (valid_reg base) flags)\n                   (uextend (ishl index @ (iadd _ _) (iconst (uimm8 shift)))))\n      (if (u32_lteq (u8_as_u32 shift) 3))\n      (Amode.ImmRegRegShift off base index shift flags))\n\n;; -- Case 4 (absorbing constant offsets).\n;;\n;; An Amode can absorb a constant (i64, or extended i32) as long as\n;; the sum still fits in the signed-32-bit offset.\n;;\n;; Priority 3 in order to take this option above the fallback\n;; (immediate in register). Two rules, for imm+reg and\n;; imm+reg+scale*reg cases.\n(rule 3 (amode_add (Amode.ImmReg off base flags)\n                   (iconst (simm32 c)))\n      (if-let sum (s32_add_fallible off c))\n      (Amode.ImmReg sum base flags))\n(rule 3 (amode_add (Amode.ImmRegRegShift off base index shift flags)\n                   (iconst (simm32 c)))\n      (if-let sum (s32_add_fallible off c))\n      (Amode.ImmRegRegShift sum base index shift flags))\n\n;; Likewise for a zero-extended i32 const, as long as the constant\n;; wasn't negative. (Why nonnegative? Because adding a\n;; non-sign-extended negative to a 64-bit address is not the same as\n;; adding in simm32-space.)\n(rule 3 (amode_add (Amode.ImmReg off base flags)\n                   (uextend (iconst (simm32 (u32_nonnegative c)))))\n      (if-let sum (s32_add_fallible off c))\n      (Amode.ImmReg sum base flags))\n(rule 3 (amode_add (Amode.ImmRegRegShift off base index shift flags)\n                   (uextend (iconst (simm32 (u32_nonnegative c)))))\n      (if-let sum (s32_add_fallible off c))\n      (Amode.ImmRegRegShift sum base index shift flags))\n\n;; Likewise for a sign-extended i32 const.\n(rule 3 (amode_add (Amode.ImmReg off base flags)\n                   (sextend (iconst (simm32 c))))\n      (if-let sum (s32_add_fallible off c))\n      (Amode.ImmReg sum base flags))\n(rule 3 (amode_add (Amode.ImmRegRegShift off base index shift flags)\n                   (sextend (iconst (simm32 c))))\n      (if-let sum (s32_add_fallible off c))\n      (Amode.ImmRegRegShift sum base index shift flags))\n\n;; -- Case 5 (fallback to add a new value to an imm+reg+scale*reg).\n;;\n;; An Amode.ImmRegRegShift can absorb any other value by creating a\n;; new add instruction and replacing the base with\n;; (base+value).\n(rule (amode_add (Amode.ImmRegRegShift off base index shift flags) value)\n      (let ((sum Gpr (x64_add $I64 base value)))\n        (Amode.ImmRegRegShift off sum index shift flags)))\n\n;; Finally, define the toplevel `to_amode`.\n(rule (to_amode flags base offset)\n      (amode_finalize (amode_add (amode_initial flags offset) base)))\n\n;; If an amode has no registers at all and only offsets (a constant\n;; value), we need to \"finalize\" it by sticking in a zero'd reg in\n;; place of the (invalid_reg) produced by (amode_initial).\n(decl amode_finalize (Amode) Amode)\n(rule 1 (amode_finalize (Amode.ImmReg off (invalid_reg) flags))\n      (Amode.ImmReg off (imm $I64 0) flags))\n(rule 0 (amode_finalize amode)\n      amode)\n\n;; Offsetting an Amode. Used when we need to do consecutive\n;; loads/stores to adjacent addresses.\n(decl amode_offset (Amode u32) Amode)\n(extern constructor amode_offset amode_offset)\n\n;; Return a zero offset as an `Offset32`.\n(decl zero_offset () Offset32)\n(extern constructor zero_offset zero_offset)\n\n;; Shift kinds.\n\n(type ShiftKind extern\n      (enum ShiftLeft\n            ShiftRightLogical\n            ShiftRightArithmetic\n            RotateLeft\n            RotateRight))\n\n(type Imm8Reg extern\n      (enum (Imm8 (imm u8))\n            (Reg (reg Reg))))\n\n;; Put the given clif value into a `Imm8Reg` operand, masked to the bit width of\n;; the given type.\n;;\n;; Asserts that the value fits into a single register, and doesn't require\n;; multiple registers for its representation (like `i128` for example).\n;;\n;; As a side effect, this marks the value as used.\n;;\n;; This is used when lowering various shifts and rotates.\n(decl put_masked_in_imm8_gpr (Value Type) Imm8Gpr)\n(rule 2 (put_masked_in_imm8_gpr (u64_from_iconst amt) ty)\n      (const_to_type_masked_imm8 amt ty))\n(rule 1 (put_masked_in_imm8_gpr amt (fits_in_16 ty))\n      (x64_and $I64 (value_regs_get_gpr amt 0) (RegMemImm.Imm (shift_mask ty))))\n(rule (put_masked_in_imm8_gpr amt ty)\n      (value_regs_get_gpr amt 0))\n\n;; Condition codes\n(type CC extern\n      (enum O\n            NO\n            B\n            NB\n            Z\n            NZ\n            BE\n            NBE\n            S\n            NS\n            L\n            NL\n            LE\n            NLE\n            P\n            NP))\n\n(decl intcc_to_cc (IntCC) CC)\n(extern constructor intcc_to_cc intcc_to_cc)\n\n(decl cc_invert (CC) CC)\n(extern constructor cc_invert cc_invert)\n\n;; Fails if the argument is not either CC.NZ or CC.Z.\n(decl cc_nz_or_z (CC) CC)\n(extern extractor cc_nz_or_z cc_nz_or_z)\n\n(type AvxOpcode\n      (enum Vfmadd213ss\n            Vfmadd213sd\n            Vfmadd213ps\n            Vfmadd213pd\n            Vfmadd132ss\n            Vfmadd132sd\n            Vfmadd132ps\n            Vfmadd132pd\n            Vfnmadd213ss\n            Vfnmadd213sd\n            Vfnmadd213ps\n            Vfnmadd213pd\n            Vfnmadd132ss\n            Vfnmadd132sd\n            Vfnmadd132ps\n            Vfnmadd132pd\n            Vcmpps\n            Vcmppd\n            Vpsrlw\n            Vpsrld\n            Vpsrlq\n            Vpaddb\n            Vpaddw\n            Vpaddd\n            Vpaddq\n            Vpaddsb\n            Vpaddsw\n            Vpaddusb\n            Vpaddusw\n            Vpsubb\n            Vpsubw\n            Vpsubd\n            Vpsubq\n            Vpsubsb\n            Vpsubsw\n            Vpsubusb\n            Vpsubusw\n            Vpavgb\n            Vpavgw\n            Vpand\n            Vandps\n            Vandpd\n            Vpor\n            Vorps\n            Vorpd\n            Vpxor\n            Vxorps\n            Vxorpd\n            Vpmullw\n            Vpmulld\n            Vpmulhw\n            Vpmulhd\n            Vpmulhrsw\n            Vpmulhuw\n            Vpmuldq\n            Vpmuludq\n            Vpunpckhwd\n            Vpunpcklwd\n            Vunpcklps\n            Vandnps\n            Vandnpd\n            Vpandn\n            Vaddps\n            Vaddpd\n            Vsubps\n            Vsubpd\n            Vmulps\n            Vmulpd\n            Vdivps\n            Vdivpd\n            Vpcmpeqb\n            Vpcmpeqw\n            Vpcmpeqd\n            Vpcmpeqq\n            Vpcmpgtb\n            Vpcmpgtw\n            Vpcmpgtd\n            Vpcmpgtq\n            Vminps\n            Vminpd\n            Vmaxps\n            Vmaxpd\n            Vblendvpd\n            Vblendvps\n            Vpblendvb\n            Vmovlhps\n            Vpmaxsb\n            Vpmaxsw\n            Vpmaxsd\n            Vpminsb\n            Vpminsw\n            Vpminsd\n            Vpmaxub\n            Vpmaxuw\n            Vpmaxud\n            Vpminub\n            Vpminuw\n            Vpminud\n            Vpunpcklbw\n            Vpunpckhbw\n            Vpacksswb\n            Vpackssdw\n            Vpackuswb\n            Vpackusdw\n            Vpalignr\n            Vpinsrb\n            Vpinsrw\n            Vpinsrd\n            Vpinsrq\n            Vpmaddwd\n            Vpmaddubsw\n            Vinsertps\n            Vpshufb\n            Vshufps\n            Vpsllw\n            Vpslld\n            Vpsllq\n            Vpsraw\n            Vpsrad\n            Vpmovsxbw\n            Vpmovzxbw\n            Vpmovsxwd\n            Vpmovzxwd\n            Vpmovsxdq\n            Vpmovzxdq\n            Vaddss\n            Vaddsd\n            Vmulss\n            Vmulsd\n            Vsubss\n            Vsubsd\n            Vdivss\n            Vdivsd\n            Vpabsb\n            Vpabsw\n            Vpabsd\n            Vminss\n            Vminsd\n            Vmaxss\n            Vmaxsd\n            Vsqrtps\n            Vsqrtpd\n            Vroundps\n            Vroundpd\n            Vcvtdq2pd\n            Vcvtdq2ps\n            Vcvtpd2ps\n            Vcvtps2pd\n            Vcvttpd2dq\n            Vcvttps2dq\n            Vphaddw\n            Vphaddd\n          ))\n\n(type Avx512Opcode extern\n      (enum Vcvtudq2ps\n            Vpabsq\n            Vpermi2b\n            Vpmullq\n            Vpopcntb))\n\n(type FcmpImm extern\n      (enum Equal\n            LessThan\n            LessThanOrEqual\n            Unordered\n            NotEqual\n            UnorderedOrGreaterThanOrEqual\n            UnorderedOrGreaterThan\n            Ordered))\n\n(decl encode_fcmp_imm (FcmpImm) u8)\n(extern constructor encode_fcmp_imm encode_fcmp_imm)\n\n(type RoundImm extern\n      (enum RoundNearest\n            RoundDown\n            RoundUp\n            RoundZero))\n\n(decl encode_round_imm (RoundImm) u8)\n(extern constructor encode_round_imm encode_round_imm)\n\n;;;; Newtypes for Different Register Classes ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n\n(type Gpr (primitive Gpr))\n(type WritableGpr (primitive WritableGpr))\n(type OptionWritableGpr (primitive OptionWritableGpr))\n(type GprMem extern (enum))\n(type GprMemImm extern (enum))\n(type Imm8Gpr extern (enum))\n\n(type Xmm (primitive Xmm))\n(type WritableXmm (primitive WritableXmm))\n(type OptionWritableXmm (primitive OptionWritableXmm))\n(type XmmMem extern (enum))\n(type XmmMemAligned extern (enum))\n(type XmmMemImm extern (enum))\n(type XmmMemAlignedImm extern (enum))\n\n;; Convert an `Imm8Reg` into an `Imm8Gpr`.\n(decl imm8_reg_to_imm8_gpr (Imm8Reg) Imm8Gpr)\n(extern constructor imm8_reg_to_imm8_gpr imm8_reg_to_imm8_gpr)\n\n;; Convert a `WritableGpr` to a `WritableReg`.\n(decl writable_gpr_to_reg (WritableGpr) WritableReg)\n(extern constructor writable_gpr_to_reg writable_gpr_to_reg)\n\n;; Convert a `WritableXmm` to a `WritableReg`.\n(decl writable_xmm_to_reg (WritableXmm) WritableReg)\n(extern constructor writable_xmm_to_reg writable_xmm_to_reg)\n\n;; Convert a `WritableReg` to a `WritableXmm`.\n(decl writable_reg_to_xmm (WritableReg) WritableXmm)\n(extern constructor writable_reg_to_xmm writable_reg_to_xmm)\n\n;; Convert a `WritableXmm` to an `Xmm`.\n(decl writable_xmm_to_xmm (WritableXmm) Xmm)\n(extern constructor writable_xmm_to_xmm writable_xmm_to_xmm)\n\n;; Convert a `WritableGpr` to an `Gpr`.\n(decl writable_gpr_to_gpr (WritableGpr) Gpr)\n(extern constructor writable_gpr_to_gpr writable_gpr_to_gpr)\n\n;; Convert an `Gpr` to a `Reg`.\n(decl gpr_to_reg (Gpr) Reg)\n(extern constructor gpr_to_reg gpr_to_reg)\n\n;; Convert an `Gpr` to a `GprMem`.\n(decl gpr_to_gpr_mem (Gpr) GprMem)\n(extern constructor gpr_to_gpr_mem gpr_to_gpr_mem)\n\n;; Convert an `Gpr` to a `GprMemImm`.\n(decl gpr_to_gpr_mem_imm (Gpr) GprMemImm)\n(extern constructor gpr_to_gpr_mem_imm gpr_to_gpr_mem_imm)\n\n;; Convert an `Xmm` to a `Reg`.\n(decl xmm_to_reg (Xmm) Reg)\n(extern constructor xmm_to_reg xmm_to_reg)\n\n;; Convert an `Xmm` into an `XmmMemImm`.\n(decl xmm_to_xmm_mem_imm (Xmm) XmmMemImm)\n(extern constructor xmm_to_xmm_mem_imm xmm_to_xmm_mem_imm)\n\n;; Convert an `XmmMem` into an `XmmMemImm`.\n(decl xmm_mem_to_xmm_mem_imm (XmmMem) XmmMemImm)\n(extern constructor xmm_mem_to_xmm_mem_imm xmm_mem_to_xmm_mem_imm)\n\n;; Convert an `XmmMem` into an `XmmMemAligned`.\n;;\n;; Note that this is an infallible conversion, not a fallible one. If the\n;; original `XmmMem` source is a register, then it's passed through directly.\n;; If it's `Mem` and refers to aligned memory, it's also passed through\n;; directly. Otherwise, though, it's a memory source which is not aligned to\n;; 16 bytes so a load is performed and the temporary register which is the\n;; result of the load is passed through. The end-result is that the return value\n;; here is guaranteed to be a register or an aligned memory location.\n(decl xmm_mem_to_xmm_mem_aligned (XmmMem) XmmMemAligned)\n(extern constructor xmm_mem_to_xmm_mem_aligned xmm_mem_to_xmm_mem_aligned)\n\n;; Convert an `XmmMemImm` into an `XmmMemImmAligned`.\n;;\n;; Note that this is the same as `xmm_mem_to_xmm_mem_aligned` except it handles\n;; an immediate case as well.\n(decl xmm_mem_imm_to_xmm_mem_aligned_imm (XmmMemImm) XmmMemAlignedImm)\n(extern constructor xmm_mem_imm_to_xmm_mem_aligned_imm xmm_mem_imm_to_xmm_mem_aligned_imm)\n\n;; Allocate a new temporary GPR register.\n(decl temp_writable_gpr () WritableGpr)\n(extern constructor temp_writable_gpr temp_writable_gpr)\n\n;; Allocate a new temporary XMM register.\n(decl temp_writable_xmm () WritableXmm)\n(extern constructor temp_writable_xmm temp_writable_xmm)\n\n;; Construct a new `XmmMem` from the given `RegMem`.\n;;\n;; Asserts that the `RegMem`'s register, if any, is an XMM register.\n(decl reg_mem_to_xmm_mem (RegMem) XmmMem)\n(extern constructor reg_mem_to_xmm_mem reg_mem_to_xmm_mem)\n\n;; Construct a new `RegMemImm` from the given `Reg`.\n(decl reg_to_reg_mem_imm (Reg) RegMemImm)\n(extern constructor reg_to_reg_mem_imm reg_to_reg_mem_imm)\n\n;; Construct a new `GprMemImm` from the given `RegMemImm`.\n;;\n;; Asserts that the `RegMemImm`'s register, if any, is an GPR register.\n(decl gpr_mem_imm_new (RegMemImm) GprMemImm)\n(extern constructor gpr_mem_imm_new gpr_mem_imm_new)\n\n;; Construct a new `XmmMemImm` from the given `RegMemImm`.\n;;\n;; Asserts that the `RegMemImm`'s register, if any, is an XMM register.\n(decl xmm_mem_imm_new (RegMemImm) XmmMemImm)\n(extern constructor xmm_mem_imm_new xmm_mem_imm_new)\n\n;; Construct a new `XmmMem` from an `Xmm`.\n(decl xmm_to_xmm_mem (Xmm) XmmMem)\n(extern constructor xmm_to_xmm_mem xmm_to_xmm_mem)\n\n;; Construct a new `XmmMem` from an `RegMem`.\n(decl xmm_mem_to_reg_mem (XmmMem) RegMem)\n(extern constructor xmm_mem_to_reg_mem xmm_mem_to_reg_mem)\n\n;; Convert a `GprMem` to a `RegMem`.\n(decl gpr_mem_to_reg_mem (GprMem) RegMem)\n(extern constructor gpr_mem_to_reg_mem gpr_mem_to_reg_mem)\n\n;; Construct a new `Xmm` from a `Reg`.\n;;\n;; Asserts that the register is a XMM.\n(decl xmm_new (Reg) Xmm)\n(extern constructor xmm_new xmm_new)\n\n;; Construct a new `Gpr` from a `Reg`.\n;;\n;; Asserts that the register is a GPR.\n(decl gpr_new (Reg) Gpr)\n(extern constructor gpr_new gpr_new)\n\n;; Construct a new `GprMem` from a `RegMem`.\n;;\n;; Asserts that the `RegMem`'s register, if any, is a GPR.\n(decl reg_mem_to_gpr_mem (RegMem) GprMem)\n(extern constructor reg_mem_to_gpr_mem reg_mem_to_gpr_mem)\n\n;; Construct a `GprMem` from a `Reg`.\n;;\n;; Asserts that the `Reg` is a GPR.\n(decl reg_to_gpr_mem (Reg) GprMem)\n(extern constructor reg_to_gpr_mem reg_to_gpr_mem)\n\n;; Construct a `GprMemImm` from a `Reg`.\n;;\n;; Asserts that the `Reg` is a GPR.\n(decl reg_to_gpr_mem_imm (Reg) GprMemImm)\n(rule (reg_to_gpr_mem_imm r)\n      (gpr_to_gpr_mem_imm (gpr_new r)))\n\n;; Put a value into a GPR.\n;;\n;; Asserts that the value goes into a GPR.\n(decl put_in_gpr (Value) Gpr)\n(rule (put_in_gpr val)\n      (gpr_new (put_in_reg val)))\n\n;; Put a value into a `GprMem`.\n;;\n;; Asserts that the value goes into a GPR.\n(decl put_in_gpr_mem (Value) GprMem)\n(rule (put_in_gpr_mem val)\n      (reg_mem_to_gpr_mem (put_in_reg_mem val)))\n\n;; Put a value into a `GprMemImm`.\n;;\n;; Asserts that the value goes into a GPR.\n(decl put_in_gpr_mem_imm (Value) GprMemImm)\n(rule (put_in_gpr_mem_imm val)\n      (gpr_mem_imm_new (put_in_reg_mem_imm val)))\n\n;; Put a value into a XMM.\n;;\n;; Asserts that the value goes into a XMM.\n(decl put_in_xmm (Value) Xmm)\n(rule (put_in_xmm val)\n      (xmm_new (put_in_reg val)))\n\n;; Put a value into a `XmmMem`.\n;;\n;; Asserts that the value goes into a XMM.\n(decl put_in_xmm_mem (Value) XmmMem)\n(extern constructor put_in_xmm_mem put_in_xmm_mem)\n\n;; Put a value into a `XmmMemImm`.\n;;\n;; Asserts that the value goes into a XMM.\n(decl put_in_xmm_mem_imm (Value) XmmMemImm)\n(extern constructor put_in_xmm_mem_imm put_in_xmm_mem_imm)\n\n;; Construct an `InstOutput` out of a single GPR register.\n(decl output_gpr (Gpr) InstOutput)\n(rule (output_gpr x)\n      (output_reg (gpr_to_reg x)))\n\n;; Construct a `ValueRegs` out of two GPR registers.\n(decl value_gprs (Gpr Gpr) ValueRegs)\n(rule (value_gprs x y)\n      (value_regs (gpr_to_reg x) (gpr_to_reg y)))\n\n;; Construct an `InstOutput` out of a single XMM register.\n(decl output_xmm (Xmm) InstOutput)\n(rule (output_xmm x)\n      (output_reg (xmm_to_reg x)))\n\n;; Get the `n`th reg in a `ValueRegs` and construct a GPR from it.\n;;\n;; Asserts that the register is a GPR.\n(decl value_regs_get_gpr (ValueRegs usize) Gpr)\n(rule (value_regs_get_gpr regs n)\n      (gpr_new (value_regs_get regs n)))\n\n;; Convert a `Gpr` to an `Imm8Gpr`.\n(decl gpr_to_imm8_gpr (Gpr) Imm8Gpr)\n(extern constructor gpr_to_imm8_gpr gpr_to_imm8_gpr)\n\n;; Convert an 8-bit immediate into an `Imm8Gpr`.\n(decl imm8_to_imm8_gpr (u8) Imm8Gpr)\n(extern constructor imm8_to_imm8_gpr imm8_to_imm8_gpr)\n\n;; Get the low half of the given `Value` as a GPR.\n(decl lo_gpr (Value) Gpr)\n(rule (lo_gpr regs) (gpr_new (lo_reg regs)))\n\n;;;; Helpers for Working With Integer Comparison Codes ;;;;;;;;;;;;;;;;;;;;;;;;;\n;;\n\n;; This is a direct import of `IntCC::without_equal`.\n;; Get the corresponding IntCC with the equal component removed.\n;; For conditions without a zero component, this is a no-op.\n(decl intcc_without_eq (IntCC) IntCC)\n(extern constructor intcc_without_eq intcc_without_eq)\n\n;;;; Helpers for determining the register class of a value type ;;;;;;;;;;;;;;;;\n\n(type RegisterClass\n      (enum\n        (Gpr (single_register bool))\n        (Xmm)))\n\n(decl type_register_class (RegisterClass) Type)\n(extern extractor type_register_class type_register_class)\n\n(decl is_xmm_type (Type) Type)\n(extractor (is_xmm_type ty) (and (type_register_class (RegisterClass.Xmm)) ty))\n\n(decl is_gpr_type (Type) Type)\n(extractor (is_gpr_type ty) (and (type_register_class (RegisterClass.Gpr _)) ty))\n\n(decl is_single_register_gpr_type (Type) Type)\n(extractor (is_single_register_gpr_type ty)\n           (and (type_register_class (RegisterClass.Gpr $true)) ty))\n\n(decl is_multi_register_gpr_type (Type) Type)\n(extractor (is_multi_register_gpr_type ty)\n           (and (type_register_class (RegisterClass.Gpr $false)) ty))\n\n;;;; Helpers for Querying Enabled ISA Extensions ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n\n(decl avx512vl_enabled (bool) Type)\n(extern extractor infallible avx512vl_enabled avx512vl_enabled)\n\n(decl avx512dq_enabled (bool) Type)\n(extern extractor infallible avx512dq_enabled avx512dq_enabled)\n\n(decl avx512f_enabled (bool) Type)\n(extern extractor infallible avx512f_enabled avx512f_enabled)\n\n(decl avx512bitalg_enabled (bool) Type)\n(extern extractor infallible avx512bitalg_enabled avx512bitalg_enabled)\n\n(decl avx512vbmi_enabled (bool) Type)\n(extern extractor infallible avx512vbmi_enabled avx512vbmi_enabled)\n\n(decl use_lzcnt (bool) Type)\n(extern extractor infallible use_lzcnt use_lzcnt)\n\n(decl use_bmi1 (bool) Type)\n(extern extractor infallible use_bmi1 use_bmi1)\n\n(decl use_popcnt (bool) Type)\n(extern extractor infallible use_popcnt use_popcnt)\n\n(decl pure use_fma () bool)\n(extern constructor use_fma use_fma)\n\n(decl use_sse41 (bool) Type)\n(extern extractor infallible use_sse41 use_sse41)\n\n(decl pure has_avx () bool)\n(extern constructor has_avx has_avx)\n\n;;;; Helpers for Merging and Sinking Immediates/Loads  ;;;;;;;;;;;;;;;;;;;;;;;;;\n\n;; Extract a constant `Imm8Reg.Imm8` from a value operand.\n(decl imm8_from_value (Imm8Reg) Value)\n(extern extractor imm8_from_value imm8_from_value)\n\n;; Mask a constant to the bit-width of the given type and package it into an\n;; `Imm8Reg.Imm8`. This is used for shifts and rotates, so that we don't try and\n;; shift/rotate more bits than the type has available, per Cranelift's\n;; semantics.\n(decl const_to_type_masked_imm8 (u64 Type) Imm8Gpr)\n(extern constructor const_to_type_masked_imm8 const_to_type_masked_imm8)\n\n;; Generate a mask for the bit-width of the given type\n(decl shift_mask (Type) u32)\n(extern constructor shift_mask shift_mask)\n\n;; Mask a constant with the type's shift mask\n(decl shift_amount_masked (Type Imm64) u32)\n(extern constructor shift_amount_masked shift_amount_masked)\n\n;; Extract a constant `GprMemImm.Imm` from a value operand.\n(decl simm32_from_value (GprMemImm) Value)\n(extern extractor simm32_from_value simm32_from_value)\n\n;; Extract a constant `RegMemImm.Imm` from an `Imm64` immediate.\n(decl simm32_from_imm64 (GprMemImm) Imm64)\n(extern extractor simm32_from_imm64 simm32_from_imm64)\n\n;; A load that can be sunk into another operation.\n(type SinkableLoad extern (enum))\n\n;; Extract a `SinkableLoad` that works with `RegMemImm.Mem` from a value\n;; operand.\n(decl sinkable_load (SinkableLoad) Value)\n(extern extractor sinkable_load sinkable_load)\n\n;; Sink a `SinkableLoad` into a `RegMemImm.Mem`.\n;;\n;; This is a side-effectful operation that notifies the context that the\n;; instruction that produced the `SinkableImm` has been sunk into another\n;; instruction, and no longer needs to be lowered.\n(decl sink_load (SinkableLoad) RegMem)\n(extern constructor sink_load sink_load)\n\n(decl sink_load_to_gpr_mem_imm (SinkableLoad) GprMemImm)\n(rule (sink_load_to_gpr_mem_imm load)\n      (gpr_mem_imm_new (sink_load load)))\n\n(decl sink_load_to_xmm_mem (SinkableLoad) XmmMem)\n(rule (sink_load_to_xmm_mem load)\n      (reg_mem_to_xmm_mem (sink_load load)))\n\n;;;; Helpers for Sign/Zero Extending ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n\n(type ExtKind extern\n      (enum None\n            SignExtend\n            ZeroExtend))\n\n(type ExtendKind (enum Sign Zero))\n\n(type ExtMode extern (enum BL BQ WL WQ LQ))\n\n;; `ExtMode::new`\n(decl ext_mode (u16 u16) ExtMode)\n(extern constructor ext_mode ext_mode)\n\n;; Put the given value into a register, but extended as the given type.\n(decl extend_to_gpr (Value Type ExtendKind) Gpr)\n\n;; If the value is already of the requested type, no extending is necessary.\n;;\n;; Priority 1 because the equality constraint doesn't prove that this rule\n;; doesn't overlap with the one below.\n(rule 1 (extend_to_gpr (and val (value_type ty)) ty _kind)\n      (put_in_gpr val))\n\n(rule (extend_to_gpr (and val (value_type from_ty))\n                     to_ty\n                     kind)\n      (let ((from_bits u16 (ty_bits_u16 from_ty))\n            ;; Use `operand_size_of_type` so that the we clamp the output to 32-\n            ;; or 64-bit width types.\n            (to_bits u16 (operand_size_bits (operand_size_of_type_32_64 to_ty))))\n        (extend kind\n                to_ty\n                (ext_mode from_bits to_bits)\n                (put_in_gpr_mem val))))\n\n;; Do a sign or zero extension of the given `GprMem`.\n(decl extend (ExtendKind Type ExtMode GprMem) Gpr)\n\n;; Zero extending uses `movzx`.\n(rule (extend (ExtendKind.Zero) ty mode src)\n      (x64_movzx mode src))\n\n;; Sign extending uses `movsx`.\n(rule (extend (ExtendKind.Sign) ty mode src)\n      (x64_movsx mode src))\n\n;;;; Helpers for Working SSE tidbits ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n\n;; Turn a vector type into its integer-typed vector equivalent.\n(decl vec_int_type (Type) Type)\n(rule (vec_int_type (multi_lane 8 16)) $I8X16)\n(rule (vec_int_type (multi_lane 16 8)) $I16X8)\n(rule (vec_int_type (multi_lane 32 4)) $I32X4)\n(rule (vec_int_type (multi_lane 64 2)) $I64X2)\n\n;; Determine the appropriate operation for xor-ing vectors of the specified type\n(decl sse_xor_op (Type) SseOpcode)\n(rule 1 (sse_xor_op $F32X4) (SseOpcode.Xorps))\n(rule 1 (sse_xor_op $F64X2) (SseOpcode.Xorpd))\n(rule 1 (sse_xor_op $F32) (SseOpcode.Xorps))\n(rule 1 (sse_xor_op $F64) (SseOpcode.Xorpd))\n\n;; Priority 0 because multi_lane overlaps with the previous two explicit type\n;; patterns.\n(rule 0 (sse_xor_op (multi_lane _bits _lanes)) (SseOpcode.Pxor))\n\n(decl avx_xor_op (Type) AvxOpcode)\n(rule 1 (avx_xor_op $F32X4) (AvxOpcode.Vxorps))\n(rule 1 (avx_xor_op $F64X2) (AvxOpcode.Vxorpd))\n(rule 0 (avx_xor_op (multi_lane _bits _lanes)) (AvxOpcode.Vpxor))\n\n;; Performs an xor operation of the two operands specified.\n(decl sse_xor (Type Xmm XmmMem) Xmm)\n(rule 0 (sse_xor ty x y) (xmm_rm_r (sse_xor_op ty) x y))\n(rule 1 (sse_xor ty @ (multi_lane _ _) x y)\n        (if-let $true (has_avx))\n        (xmm_rmir_vex (avx_xor_op ty) x y))\n\n;; Generates a register value which has an all-ones pattern.\n;;\n;; Note that this is accomplished by comparing a fresh register with itself,\n;; which for integers is always true. Also note that the comparison is always\n;; done for integers. This is because we're comparing a fresh register to itself\n;; and we don't know the previous contents of the register. If a floating-point\n;; comparison is used then it runs the risk of comparing NaN against NaN and not\n;; actually producing an all-ones mask. By using integer comparision operations\n;; we're guaranteeed that everything is equal to itself.\n(decl vector_all_ones () Xmm)\n(rule (vector_all_ones)\n      (let ((r WritableXmm (temp_writable_xmm))\n            (_ Unit (emit (MInst.XmmConstOp (SseOpcode.Pcmpeqd) r))))\n        r))\n\n;; Helper for creating XmmUninitializedValue instructions.\n(decl xmm_uninit_value () Xmm)\n(rule (xmm_uninit_value)\n      (let ((dst WritableXmm (temp_writable_xmm))\n            (_ Unit (emit (MInst.XmmUninitializedValue dst))))\n        dst))\n\n;; Helper for creating an SSE register holding an `i64x2` from two `i64` values.\n(decl make_i64x2_from_lanes (GprMem GprMem) Xmm)\n(rule (make_i64x2_from_lanes lo hi)\n      (let ((dst Xmm (xmm_uninit_value))\n            (dst Xmm (x64_pinsrq dst lo 0))\n            (dst Xmm (x64_pinsrq dst hi 1)))\n        dst))\n\n;; Move a `RegMemImm.Reg` operand to an XMM register, if necessary.\n(decl mov_rmi_to_xmm (RegMemImm) XmmMemImm)\n(rule (mov_rmi_to_xmm rmi @ (RegMemImm.Mem _)) (xmm_mem_imm_new rmi))\n(rule (mov_rmi_to_xmm rmi @ (RegMemImm.Imm _)) (xmm_mem_imm_new rmi))\n(rule (mov_rmi_to_xmm (RegMemImm.Reg r))\n      (gpr_to_xmm (SseOpcode.Movd)\n                  r\n                  (OperandSize.Size32)))\n\n;;;; Helpers for Emitting Calls ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n\n(decl gen_call (SigRef ExternalName RelocDistance ValueSlice) InstOutput)\n(extern constructor gen_call gen_call)\n\n(decl gen_call_indirect (SigRef Value ValueSlice) InstOutput)\n(extern constructor gen_call_indirect gen_call_indirect)\n\n;;;; Helpers for Emitting Loads ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n\n;; Helper for constructing a LoadExtName instruction.\n(decl load_ext_name (ExternalName i64) Reg)\n(rule (load_ext_name extname offset)\n      (let ((dst WritableGpr (temp_writable_gpr))\n            (_ Unit (emit (MInst.LoadExtName dst extname offset))))\n        dst))\n\n;; Load a value into a register.\n(decl x64_load (Type SyntheticAmode ExtKind) Reg)\n\n(rule 1 (x64_load (fits_in_32 ty) addr (ExtKind.SignExtend))\n      (x64_movsx (ext_mode (ty_bytes ty) 8)\n             addr))\n\n(rule 2 (x64_load $I64 addr _ext_kind)\n      (let ((dst WritableGpr (temp_writable_gpr))\n            (_ Unit (emit (MInst.Mov64MR addr dst))))\n        dst))\n\n(rule 2 (x64_load $F32 addr _ext_kind)\n      (xmm_unary_rm_r_unaligned (SseOpcode.Movss) addr))\n\n(rule 2 (x64_load $F64 addr _ext_kind)\n      (xmm_unary_rm_r_unaligned (SseOpcode.Movsd) addr))\n\n(rule 2 (x64_load $F32X4 addr _ext_kind)\n      (xmm_unary_rm_r_unaligned (SseOpcode.Movups) addr))\n\n(rule 2 (x64_load $F64X2 addr _ext_kind)\n      (xmm_unary_rm_r_unaligned (SseOpcode.Movupd) addr))\n\n(rule 0 (x64_load (multi_lane _bits _lanes) addr _ext_kind)\n      (xmm_unary_rm_r_unaligned (SseOpcode.Movdqu) addr))\n\n(decl x64_mov (Amode) Reg)\n(rule (x64_mov addr)\n      (let ((dst WritableGpr (temp_writable_gpr))\n            (_ Unit (emit (MInst.Mov64MR addr dst))))\n        dst))\n\n(decl x64_movzx (ExtMode GprMem) Gpr)\n(rule (x64_movzx mode src)\n      (let ((dst WritableGpr (temp_writable_gpr))\n            (_ Unit (emit (MInst.MovzxRmR mode src dst))))\n        dst))\n\n(decl x64_movsx (ExtMode GprMem) Gpr)\n(rule (x64_movsx mode src)\n      (let ((dst WritableGpr (temp_writable_gpr))\n            (_ Unit (emit (MInst.MovsxRmR mode src dst))))\n        dst))\n\n(decl x64_movss_load (XmmMem) Xmm)\n(rule (x64_movss_load from)\n      (xmm_unary_rm_r_unaligned (SseOpcode.Movss) from))\n\n(decl x64_movsd_load (XmmMem) Xmm)\n(rule (x64_movsd_load from)\n      (xmm_unary_rm_r_unaligned (SseOpcode.Movsd) from))\n\n(decl x64_movups (XmmMem) Xmm)\n(rule (x64_movups from)\n      (xmm_unary_rm_r_unaligned (SseOpcode.Movups) from))\n\n(decl x64_movupd (XmmMem) Xmm)\n(rule (x64_movupd from)\n      (xmm_unary_rm_r_unaligned (SseOpcode.Movupd) from))\n\n(decl x64_movd (Xmm) Gpr)\n(rule (x64_movd from)\n      (xmm_to_gpr (SseOpcode.Movd) from (OperandSize.Size32)))\n\n(decl x64_movdqu (XmmMem) Xmm)\n(rule (x64_movdqu from)\n      (xmm_unary_rm_r_unaligned (SseOpcode.Movdqu) from))\n\n(decl x64_pmovsxbw (XmmMem) Xmm)\n(rule (x64_pmovsxbw from)\n      (xmm_unary_rm_r_unaligned (SseOpcode.Pmovsxbw) from))\n(rule 1 (x64_pmovsxbw from)\n      (if-let $true (has_avx))\n      (xmm_unary_rm_r_vex (AvxOpcode.Vpmovsxbw) from))\n\n(decl x64_pmovzxbw (XmmMem) Xmm)\n(rule (x64_pmovzxbw from)\n      (xmm_unary_rm_r_unaligned (SseOpcode.Pmovzxbw) from))\n(rule 1 (x64_pmovzxbw from)\n      (if-let $true (has_avx))\n      (xmm_unary_rm_r_vex (AvxOpcode.Vpmovzxbw) from))\n\n(decl x64_pmovsxwd (XmmMem) Xmm)\n(rule (x64_pmovsxwd from)\n      (xmm_unary_rm_r_unaligned (SseOpcode.Pmovsxwd) from))\n(rule 1 (x64_pmovsxwd from)\n      (if-let $true (has_avx))\n      (xmm_unary_rm_r_vex (AvxOpcode.Vpmovsxwd) from))\n\n(decl x64_pmovzxwd (XmmMem) Xmm)\n(rule (x64_pmovzxwd from)\n      (xmm_unary_rm_r_unaligned (SseOpcode.Pmovzxwd) from))\n(rule 1 (x64_pmovzxwd from)\n      (if-let $true (has_avx))\n      (xmm_unary_rm_r_vex (AvxOpcode.Vpmovzxwd) from))\n\n(decl x64_pmovsxdq (XmmMem) Xmm)\n(rule (x64_pmovsxdq from)\n      (xmm_unary_rm_r_unaligned (SseOpcode.Pmovsxdq) from))\n(rule 1 (x64_pmovsxdq from)\n      (if-let $true (has_avx))\n      (xmm_unary_rm_r_vex (AvxOpcode.Vpmovsxdq) from))\n\n(decl x64_pmovzxdq (XmmMem) Xmm)\n(rule (x64_pmovzxdq from)\n      (xmm_unary_rm_r_unaligned (SseOpcode.Pmovzxdq) from))\n(rule 1 (x64_pmovzxdq from)\n      (if-let $true (has_avx))\n      (xmm_unary_rm_r_vex (AvxOpcode.Vpmovzxdq) from))\n\n(decl x64_movrm (Type SyntheticAmode Gpr) SideEffectNoResult)\n(rule (x64_movrm ty addr data)\n      (let ((size OperandSize (raw_operand_size_of_type ty)))\n        (SideEffectNoResult.Inst (MInst.MovRM size data addr))))\n\n(decl x64_xmm_movrm (SseOpcode SyntheticAmode Xmm) SideEffectNoResult)\n(rule (x64_xmm_movrm op addr data)\n      (SideEffectNoResult.Inst (MInst.XmmMovRM op data addr)))\n\n;; Load a constant into an XMM register.\n(decl x64_xmm_load_const (Type VCodeConstant) Xmm)\n(rule (x64_xmm_load_const ty const)\n      (x64_load ty (const_to_synthetic_amode const) (ExtKind.None)))\n\n;;;; Instruction Constructors ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n;;\n;; These constructors create SSA-style `MInst`s. It is their responsibility to\n;; maintain the invariant that each temporary register they allocate and define\n;; only gets defined the once.\n\n;; Helper for emitting `MInst.AluRmiR` instructions.\n(decl alu_rmi_r (Type AluRmiROpcode Gpr GprMemImm) Gpr)\n(rule (alu_rmi_r ty opcode src1 src2)\n      (let ((dst WritableGpr (temp_writable_gpr))\n            (size OperandSize (operand_size_of_type_32_64 ty))\n            (_ Unit (emit (MInst.AluRmiR size opcode src1 src2 dst))))\n        dst))\n\n;; Helper for emitting `add` instructions.\n(decl x64_add (Type Gpr GprMemImm) Gpr)\n(rule (x64_add ty src1 src2)\n      (alu_rmi_r ty\n                 (AluRmiROpcode.Add)\n                 src1\n                 src2))\n\n;; Helper for creating `add` instructions whose flags are also used.\n(decl x64_add_with_flags_paired (Type Gpr GprMemImm) ProducesFlags)\n(rule (x64_add_with_flags_paired ty src1 src2)\n      (let ((dst WritableGpr (temp_writable_gpr)))\n        (ProducesFlags.ProducesFlagsReturnsResultWithConsumer\n         (MInst.AluRmiR (operand_size_of_type_32_64 ty)\n                        (AluRmiROpcode.Add)\n                        src1\n                        src2\n                        dst)\n         dst)))\n\n;; Helper for creating `adc` instructions.\n(decl x64_adc_paired (Type Gpr GprMemImm) ConsumesFlags)\n(rule (x64_adc_paired ty src1 src2)\n      (let ((dst WritableGpr (temp_writable_gpr)))\n        (ConsumesFlags.ConsumesFlagsReturnsResultWithProducer\n         (MInst.AluRmiR (operand_size_of_type_32_64 ty)\n                        (AluRmiROpcode.Adc)\n                        src1\n                        src2\n                        dst)\n         dst)))\n\n;; Helper for emitting `sub` instructions.\n(decl x64_sub (Type Gpr GprMemImm) Gpr)\n(rule (x64_sub ty src1 src2)\n      (alu_rmi_r ty\n                 (AluRmiROpcode.Sub)\n                 src1\n                 src2))\n\n;; Helper for creating `sub` instructions whose flags are also used.\n(decl x64_sub_with_flags_paired (Type Gpr GprMemImm) ProducesFlags)\n(rule (x64_sub_with_flags_paired ty src1 src2)\n      (let ((dst WritableGpr (temp_writable_gpr)))\n        (ProducesFlags.ProducesFlagsReturnsResultWithConsumer\n         (MInst.AluRmiR (operand_size_of_type_32_64 ty)\n                        (AluRmiROpcode.Sub)\n                        src1\n                        src2\n                        dst)\n         dst)))\n\n;; Helper for creating `sbb` instructions.\n(decl x64_sbb_paired (Type Gpr GprMemImm) ConsumesFlags)\n(rule (x64_sbb_paired ty src1 src2)\n      (let ((dst WritableGpr (temp_writable_gpr)))\n        (ConsumesFlags.ConsumesFlagsReturnsResultWithProducer\n         (MInst.AluRmiR (operand_size_of_type_32_64 ty)\n                        (AluRmiROpcode.Sbb)\n                        src1\n                        src2\n                        dst)\n         dst)))\n\n;; Helper for creating `mul` instructions.\n(decl x64_mul (Type Gpr GprMemImm) Gpr)\n(rule (x64_mul ty src1 src2)\n      (alu_rmi_r ty\n                 (AluRmiROpcode.Mul)\n                 src1\n                 src2))\n\n;; Helper for emitting `and` instructions.\n(decl x64_and (Type Gpr GprMemImm) Gpr)\n(rule (x64_and ty src1 src2)\n      (alu_rmi_r ty\n                 (AluRmiROpcode.And)\n                 src1\n                 src2))\n\n(decl x64_and_with_flags_paired (Type Gpr GprMemImm) ProducesFlags)\n(rule (x64_and_with_flags_paired ty src1 src2)\n      (let ((dst WritableGpr (temp_writable_gpr)))\n           (ProducesFlags.ProducesFlagsSideEffect\n                 (MInst.AluRmiR (operand_size_of_type_32_64 ty)\n                       (AluRmiROpcode.And)\n                       src1\n                       src2\n                       dst))))\n\n;; Helper for emitting `or` instructions.\n(decl x64_or (Type Gpr GprMemImm) Gpr)\n(rule (x64_or ty src1 src2)\n      (alu_rmi_r ty\n                 (AluRmiROpcode.Or)\n                 src1\n                 src2))\n\n;; Helper for emitting `xor` instructions.\n(decl x64_xor (Type Gpr GprMemImm) Gpr)\n(rule (x64_xor ty src1 src2)\n      (alu_rmi_r ty\n                 (AluRmiROpcode.Xor)\n                 src1\n                 src2))\n\n;; Helper for emitting `MInst.AluRmRVex` instructions.\n(decl alu_rm_r_vex (Type AluRmROpcode Gpr Gpr) Gpr)\n(rule (alu_rm_r_vex ty opcode src1 src2)\n      (let ((dst WritableGpr (temp_writable_gpr))\n            (size OperandSize (operand_size_of_type_32_64 ty))\n            (_ Unit (emit (MInst.AluRmRVex size opcode src1 src2 dst))))\n        dst))\n\n(decl x64_andn (Type Gpr Gpr) Gpr)\n(rule (x64_andn ty src1 src2)\n      (alu_rm_r_vex ty (AluRmROpcode.Andn) src1 src2))\n\n;; Helper for emitting immediates with an `i64` value. Note that\n;; integer constants in ISLE are always parsed as `i128`s; this enables\n;; negative numbers to be used as immediates.\n(decl imm_i64 (Type i64) Reg)\n(rule (imm_i64 ty value)\n      (imm ty (i64_as_u64 value)))\n\n(decl nonzero_u64_fits_in_u32 (u64) u64)\n(extern extractor nonzero_u64_fits_in_u32 nonzero_u64_fits_in_u32)\n\n;; Helper for emitting immediates.\n;;\n;; There are three priorities in use in this rule:\n;; 2 - rules that match on an explicit type\n;; 1 - rules that match on types that fit in 64 bits\n;; 0 - rules that match on vectors\n(decl imm (Type u64) Reg)\n\n;; Integer immediates.\n(rule 1 (imm (fits_in_64 ty) (u64_nonzero simm64))\n      (let ((dst WritableGpr (temp_writable_gpr))\n            (size OperandSize (operand_size_of_type_32_64 ty))\n            (_ Unit (emit (MInst.Imm size simm64 dst))))\n        dst))\n\n;; `f32` immediates.\n(rule 2 (imm $F32 (u64_nonzero bits))\n      (gpr_to_xmm (SseOpcode.Movd)\n                  (imm $I32 bits)\n                  (OperandSize.Size32)))\n\n;; `f64` immediates.\n(rule 2 (imm $F64 (u64_nonzero bits))\n      (gpr_to_xmm (SseOpcode.Movq)\n                  (imm $I64 bits)\n                  (OperandSize.Size64)))\n\n;; Special case for when a 64-bit immediate fits into 32-bits. We can use a\n;; 32-bit move that zero-extends the value, which has a smaller encoding.\n(rule 2 (imm $I64 (nonzero_u64_fits_in_u32 x))\n      (let ((dst WritableGpr (temp_writable_gpr))\n            (_ Unit (emit (MInst.Imm (OperandSize.Size32) x dst))))\n        dst))\n\n;; Special case for integer zero immediates: turn them into an `xor r, r`.\n(rule 1 (imm (fits_in_64 ty) (u64_zero))\n      (let ((wgpr WritableGpr (temp_writable_gpr))\n            (size OperandSize (operand_size_of_type_32_64 ty))\n            (_ Unit (emit (MInst.AluConstOp (AluRmiROpcode.Xor) size wgpr))))\n        (gpr_to_reg wgpr)))\n\n;; Special case for zero immediates with vector types, they turn into an xor\n;; specific to the vector type.\n(rule 0 (imm ty @ (multi_lane _bits _lanes) 0)\n      (xmm_to_reg (xmm_zero ty)))\n\n;; Special case for `f32` zero immediates\n(rule 2 (imm ty @ $F32 (u64_zero))\n      (let ((wr WritableXmm (temp_writable_xmm))\n            (_ Unit (emit (MInst.XmmConstOp (SseOpcode.Xorps) wr))))\n        (xmm_to_reg wr)))\n\n;; TODO: use cmpeqps for all 1s\n\n;; Special case for `f64` zero immediates to use `xorpd`.\n(rule 2 (imm ty @ $F64 (u64_zero))\n      (let ((wr WritableXmm (temp_writable_xmm))\n            (_ Unit (emit (MInst.XmmConstOp (SseOpcode.Xorpd) wr))))\n        (xmm_to_reg wr)))\n\n;; TODO: use cmpeqpd for all 1s\n\n(decl xmm_zero (Type) Xmm)\n(rule (xmm_zero ty)\n      (let ((wr WritableXmm (temp_writable_xmm))\n            (_ Unit (emit (MInst.XmmConstOp (sse_xor_op ty) wr))))\n        wr))\n\n;; Helper for creating `MInst.ShiftR` instructions.\n(decl shift_r (Type ShiftKind Gpr Imm8Gpr) Gpr)\n(rule (shift_r ty kind src1 src2)\n      (let ((dst WritableGpr (temp_writable_gpr))\n            ;; Use actual 8/16-bit instructions when appropriate: we\n            ;; rely on their shift-amount-masking semantics.\n            (size OperandSize (raw_operand_size_of_type ty))\n            (_ Unit (emit (MInst.ShiftR size kind src1 src2 dst))))\n        dst))\n\n;; Helper for creating `rotl` instructions.\n(decl x64_rotl (Type Gpr Imm8Gpr) Gpr)\n(rule (x64_rotl ty src1 src2)\n      (shift_r ty (ShiftKind.RotateLeft) src1 src2))\n\n;; Helper for creating `rotr` instructions.\n(decl x64_rotr (Type Gpr Imm8Gpr) Gpr)\n(rule (x64_rotr ty src1 src2)\n      (shift_r ty (ShiftKind.RotateRight) src1 src2))\n\n;; Helper for creating `shl` instructions.\n(decl x64_shl (Type Gpr Imm8Gpr) Gpr)\n(rule (x64_shl ty src1 src2)\n      (shift_r ty (ShiftKind.ShiftLeft) src1 src2))\n\n;; Helper for creating logical shift-right instructions.\n(decl x64_shr (Type Gpr Imm8Gpr) Gpr)\n(rule (x64_shr ty src1 src2)\n      (shift_r ty (ShiftKind.ShiftRightLogical) src1 src2))\n\n;; Helper for creating arithmetic shift-right instructions.\n(decl x64_sar (Type Gpr Imm8Gpr) Gpr)\n(rule (x64_sar ty src1 src2)\n      (shift_r ty (ShiftKind.ShiftRightArithmetic) src1 src2))\n\n;; Helper for creating byteswap instructions.\n;; In x64, 32- and 64-bit registers use BSWAP instruction, and\n;; for 16-bit registers one must instead use xchg or rol/ror\n(decl x64_bswap (Type Gpr) Gpr)\n(rule (x64_bswap ty src)\n      (let ((dst WritableGpr (temp_writable_gpr))\n            (size OperandSize (operand_size_of_type_32_64 ty))\n            (_ Unit (emit (MInst.Bswap size src dst))))\n        dst))\n\n;; Helper for creating `MInst.CmpRmiR` instructions.\n(decl cmp_rmi_r (OperandSize CmpOpcode GprMemImm Gpr) ProducesFlags)\n(rule (cmp_rmi_r size opcode src1 src2)\n      (ProducesFlags.ProducesFlagsSideEffect\n       (MInst.CmpRmiR size\n                      opcode\n                      src1\n                      src2)))\n\n;; Helper for creating `cmp` instructions.\n(decl x64_cmp (OperandSize GprMemImm Gpr) ProducesFlags)\n(rule (x64_cmp size src1 src2)\n      (cmp_rmi_r size (CmpOpcode.Cmp) src1 src2))\n\n;; Helper for creating `cmp` instructions with an immediate.\n(decl x64_cmp_imm (OperandSize u32 Gpr) ProducesFlags)\n(rule (x64_cmp_imm size src1 src2)\n      (cmp_rmi_r size (CmpOpcode.Cmp) (RegMemImm.Imm src1) src2))\n\n;; Helper for creating `MInst.XmmCmpRmR` instructions.\n(decl xmm_cmp_rm_r (SseOpcode XmmMemAligned Xmm) ProducesFlags)\n(rule (xmm_cmp_rm_r opcode src1 src2)\n      (ProducesFlags.ProducesFlagsSideEffect\n       (MInst.XmmCmpRmR opcode src1 src2)))\n\n;; Helper for creating floating-point comparison instructions (`UCOMIS[S|D]`).\n(decl x64_ucomis (Value Value) ProducesFlags)\n(rule (x64_ucomis src1 @ (value_type $F32) src2)\n      ;; N.B.: cmp can be generated more than once, so cannot do a\n      ;; load-op merge. So `put_in_xmm` for src1, not `put_in_xmm_mem`.\n      (xmm_cmp_rm_r (SseOpcode.Ucomiss) (put_in_xmm src1) (put_in_xmm src2)))\n(rule (x64_ucomis src1 @ (value_type $F64) src2)\n      (xmm_cmp_rm_r (SseOpcode.Ucomisd) (put_in_xmm src1) (put_in_xmm src2)))\n\n;; Helper for creating `test` instructions.\n(decl x64_test (OperandSize GprMemImm Gpr) ProducesFlags)\n(rule (x64_test size src1 src2)\n      (cmp_rmi_r size (CmpOpcode.Test) src1 src2))\n\n;; Helper for creating `ptest` instructions.\n(decl x64_ptest (XmmMem Xmm) ProducesFlags)\n(rule (x64_ptest src1 src2)\n      (xmm_cmp_rm_r (SseOpcode.Ptest) src1 src2))\n\n;; Helper for creating `cmove` instructions. Note that these instructions do not\n;; always result in a single emitted x86 instruction; e.g., XmmCmove uses jumps\n;; to conditionally move the selected value into an XMM register.\n(decl cmove (Type CC GprMem Gpr) ConsumesFlags)\n(rule (cmove ty cc consequent alternative)\n      (let ((dst WritableGpr (temp_writable_gpr))\n            (size OperandSize (operand_size_of_type_32_64 ty)))\n        (ConsumesFlags.ConsumesFlagsReturnsReg\n         (MInst.Cmove size cc consequent alternative dst)\n         dst)))\n\n(decl cmove_xmm (Type CC XmmMemAligned Xmm) ConsumesFlags)\n(rule (cmove_xmm ty cc consequent alternative)\n      (let ((dst WritableXmm (temp_writable_xmm)))\n        (ConsumesFlags.ConsumesFlagsReturnsReg\n         (MInst.XmmCmove ty cc consequent alternative dst)\n         dst)))\n\n;; Helper for creating `cmove` instructions directly from values. This allows us\n;; to special-case the `I128` types and default to the `cmove` helper otherwise.\n;; It also eliminates some `put_in_reg*` boilerplate in the lowering ISLE code.\n(decl cmove_from_values (Type CC Value Value) ConsumesFlags)\n(rule (cmove_from_values (is_multi_register_gpr_type $I128) cc consequent alternative)\n      (let ((cons ValueRegs consequent)\n            (alt ValueRegs alternative)\n            (dst1 WritableGpr (temp_writable_gpr))\n            (dst2 WritableGpr (temp_writable_gpr))\n            (size OperandSize (OperandSize.Size64))\n            (lower_cmove MInst (MInst.Cmove\n                                size cc\n                                (value_regs_get_gpr cons 0)\n                                (value_regs_get_gpr alt 0)\n                                dst1))\n            (upper_cmove MInst (MInst.Cmove\n                                size cc\n                                (value_regs_get_gpr cons 1)\n                                (value_regs_get_gpr alt 1)\n                                dst2)))\n        (ConsumesFlags.ConsumesFlagsTwiceReturnsValueRegs\n         lower_cmove\n         upper_cmove\n         (value_regs dst1 dst2))))\n\n(rule (cmove_from_values (is_single_register_gpr_type ty) cc consequent alternative)\n      (cmove ty cc consequent alternative))\n\n(rule (cmove_from_values (is_xmm_type ty) cc consequent alternative)\n      (cmove_xmm ty cc consequent alternative))\n\n;; Helper for creating `cmove` instructions with the logical OR of multiple\n;; flags. Note that these instructions will always result in more than one\n;; emitted x86 instruction.\n(decl cmove_or (Type CC CC GprMem Gpr) ConsumesFlags)\n(rule (cmove_or ty cc1 cc2 consequent alternative)\n      (let ((dst WritableGpr (temp_writable_gpr))\n            (tmp WritableGpr (temp_writable_gpr))\n            (size OperandSize (operand_size_of_type_32_64 ty))\n            (cmove1 MInst (MInst.Cmove size cc1 consequent alternative tmp))\n            (cmove2 MInst (MInst.Cmove size cc2 consequent tmp dst)))\n        (ConsumesFlags.ConsumesFlagsTwiceReturnsValueRegs\n         cmove1\n         cmove2\n         dst)))\n\n(decl cmove_or_xmm (Type CC CC XmmMemAligned Xmm) ConsumesFlags)\n(rule (cmove_or_xmm ty cc1 cc2 consequent alternative)\n      (let ((dst WritableXmm (temp_writable_xmm))\n            (tmp WritableXmm (temp_writable_xmm))\n            (cmove1 MInst (MInst.XmmCmove ty cc1 consequent alternative tmp))\n            (cmove2 MInst (MInst.XmmCmove ty cc2 consequent tmp dst)))\n        (ConsumesFlags.ConsumesFlagsTwiceReturnsValueRegs\n         cmove1\n         cmove2\n         dst)))\n\n;; Helper for creating `cmove_or` instructions directly from values. This allows\n;; us to special-case the `I128` types and default to the `cmove_or` helper\n;; otherwise.\n(decl cmove_or_from_values (Type CC CC Value Value) ConsumesFlags)\n(rule (cmove_or_from_values (is_multi_register_gpr_type $I128) cc1 cc2 consequent alternative)\n      (let ((cons ValueRegs consequent)\n            (alt ValueRegs alternative)\n            (dst1 WritableGpr (temp_writable_gpr))\n            (dst2 WritableGpr (temp_writable_gpr))\n            (tmp1 WritableGpr (temp_writable_gpr))\n            (tmp2 WritableGpr (temp_writable_gpr))\n            (size OperandSize (OperandSize.Size64))\n            (cmove1 MInst (MInst.Cmove size cc1 (value_regs_get_gpr cons 0) (value_regs_get_gpr alt 0) tmp1))\n            (cmove2 MInst (MInst.Cmove size cc2 (value_regs_get_gpr cons 0) tmp1 dst1))\n            (cmove3 MInst (MInst.Cmove size cc1 (value_regs_get_gpr cons 1) (value_regs_get_gpr alt 1) tmp2))\n            (cmove4 MInst (MInst.Cmove size cc2 (value_regs_get_gpr cons 1) tmp2 dst2)))\n        (ConsumesFlags.ConsumesFlagsFourTimesReturnsValueRegs\n         cmove1\n         cmove2\n         cmove3\n         cmove4\n         (value_regs dst1 dst2))))\n\n(rule (cmove_or_from_values (is_single_register_gpr_type ty) cc1 cc2 consequent alternative)\n      (cmove_or ty cc1 cc2 consequent alternative))\n\n(rule (cmove_or_from_values (is_xmm_type ty) cc1 cc2 consequent alternative)\n      (cmove_or_xmm ty cc1 cc2 consequent alternative))\n\n;; Helper for creating `MInst.Setcc` instructions.\n(decl x64_setcc (CC) ConsumesFlags)\n(rule (x64_setcc cc)\n      (let ((dst WritableGpr (temp_writable_gpr)))\n        (ConsumesFlags.ConsumesFlagsReturnsReg\n         (MInst.Setcc cc dst)\n         dst)))\n\n;; Helper for creating `MInst.Setcc` instructions, when the flags producer will\n;; also return a value.\n(decl x64_setcc_paired (CC) ConsumesFlags)\n(rule (x64_setcc_paired cc)\n      (let ((dst WritableGpr (temp_writable_gpr)))\n        (ConsumesFlags.ConsumesFlagsReturnsResultWithProducer\n         (MInst.Setcc cc dst)\n         dst)))\n\n;; Helper for creating `MInst.XmmRmR` instructions.\n(decl xmm_rm_r (SseOpcode Xmm XmmMemAligned) Xmm)\n(rule (xmm_rm_r op src1 src2)\n      (let ((dst WritableXmm (temp_writable_xmm))\n            (_ Unit (emit (MInst.XmmRmR op src1 src2 dst))))\n        dst))\n\n;; Helper for creating `MInst.XmmRmRUnaligned` instructions.\n(decl xmm_rm_r_unaligned (SseOpcode Xmm XmmMem) Xmm)\n(rule (xmm_rm_r_unaligned op src1 src2)\n      (let ((dst WritableXmm (temp_writable_xmm))\n            (_ Unit (emit (MInst.XmmRmRUnaligned op src1 src2 dst))))\n        dst))\n\n;; Helper for creating `paddb` instructions.\n(decl x64_paddb (Xmm XmmMem) Xmm)\n(rule 0 (x64_paddb src1 src2)\n      (xmm_rm_r (SseOpcode.Paddb) src1 src2))\n(rule 1 (x64_paddb src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vpaddb) src1 src2))\n\n;; Helper for creating `paddw` instructions.\n(decl x64_paddw (Xmm XmmMem) Xmm)\n(rule 0 (x64_paddw src1 src2)\n      (xmm_rm_r (SseOpcode.Paddw) src1 src2))\n(rule 1 (x64_paddw src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vpaddw) src1 src2))\n\n;; Helper for creating `paddd` instructions.\n(decl x64_paddd (Xmm XmmMem) Xmm)\n(rule 0 (x64_paddd src1 src2)\n      (xmm_rm_r (SseOpcode.Paddd) src1 src2))\n(rule 1 (x64_paddd src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vpaddd) src1 src2))\n\n;; Helper for creating `paddq` instructions.\n(decl x64_paddq (Xmm XmmMem) Xmm)\n(rule 0 (x64_paddq src1 src2)\n      (xmm_rm_r (SseOpcode.Paddq) src1 src2))\n(rule 1 (x64_paddq src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vpaddq) src1 src2))\n\n;; Helper for creating `paddsb` instructions.\n(decl x64_paddsb (Xmm XmmMem) Xmm)\n(rule 0 (x64_paddsb src1 src2)\n      (xmm_rm_r (SseOpcode.Paddsb) src1 src2))\n(rule 1 (x64_paddsb src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vpaddsb) src1 src2))\n\n;; Helper for creating `paddsw` instructions.\n(decl x64_paddsw (Xmm XmmMem) Xmm)\n(rule 0 (x64_paddsw src1 src2)\n      (xmm_rm_r (SseOpcode.Paddsw) src1 src2))\n(rule 1 (x64_paddsw src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vpaddsw) src1 src2))\n\n;; Helper for creating `phaddw` instructions.\n(decl x64_phaddw (Xmm XmmMem) Xmm)\n(rule 0 (x64_phaddw src1 src2)\n      (xmm_rm_r (SseOpcode.Phaddw) src1 src2))\n(rule 1 (x64_phaddw src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vphaddw) src1 src2))\n\n;; Helper for creating `phaddd` instructions.\n(decl x64_phaddd (Xmm XmmMem) Xmm)\n(rule 0 (x64_phaddd src1 src2)\n      (xmm_rm_r (SseOpcode.Phaddd) src1 src2))\n(rule 1 (x64_phaddd src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vphaddd) src1 src2))\n\n;; Helper for creating `paddusb` instructions.\n(decl x64_paddusb (Xmm XmmMem) Xmm)\n(rule 0 (x64_paddusb src1 src2)\n      (xmm_rm_r (SseOpcode.Paddusb) src1 src2))\n(rule 1 (x64_paddusb src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vpaddusb) src1 src2))\n\n;; Helper for creating `paddusw` instructions.\n(decl x64_paddusw (Xmm XmmMem) Xmm)\n(rule 0 (x64_paddusw src1 src2)\n      (xmm_rm_r (SseOpcode.Paddusw) src1 src2))\n(rule 1 (x64_paddusw src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vpaddusw) src1 src2))\n\n;; Helper for creating `psubb` instructions.\n(decl x64_psubb (Xmm XmmMem) Xmm)\n(rule 0 (x64_psubb src1 src2)\n      (xmm_rm_r (SseOpcode.Psubb) src1 src2))\n(rule 1 (x64_psubb src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vpsubb) src1 src2))\n\n;; Helper for creating `psubw` instructions.\n(decl x64_psubw (Xmm XmmMem) Xmm)\n(rule 0 (x64_psubw src1 src2)\n      (xmm_rm_r (SseOpcode.Psubw) src1 src2))\n(rule 1 (x64_psubw src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vpsubw) src1 src2))\n\n;; Helper for creating `psubd` instructions.\n(decl x64_psubd (Xmm XmmMem) Xmm)\n(rule 0 (x64_psubd src1 src2)\n      (xmm_rm_r (SseOpcode.Psubd) src1 src2))\n(rule 1 (x64_psubd src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vpsubd) src1 src2))\n\n;; Helper for creating `psubq` instructions.\n(decl x64_psubq (Xmm XmmMem) Xmm)\n(rule 0 (x64_psubq src1 src2)\n      (xmm_rm_r (SseOpcode.Psubq) src1 src2))\n(rule 1 (x64_psubq src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vpsubq) src1 src2))\n\n;; Helper for creating `psubsb` instructions.\n(decl x64_psubsb (Xmm XmmMem) Xmm)\n(rule 0 (x64_psubsb src1 src2)\n      (xmm_rm_r (SseOpcode.Psubsb) src1 src2))\n(rule 1 (x64_psubsb src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vpsubsb) src1 src2))\n\n;; Helper for creating `psubsw` instructions.\n(decl x64_psubsw (Xmm XmmMem) Xmm)\n(rule 0 (x64_psubsw src1 src2)\n      (xmm_rm_r (SseOpcode.Psubsw) src1 src2))\n(rule 1 (x64_psubsw src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vpsubsw) src1 src2))\n\n;; Helper for creating `psubusb` instructions.\n(decl x64_psubusb (Xmm XmmMem) Xmm)\n(rule 0 (x64_psubusb src1 src2)\n      (xmm_rm_r (SseOpcode.Psubusb) src1 src2))\n(rule 1 (x64_psubusb src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vpsubusb) src1 src2))\n\n;; Helper for creating `psubusw` instructions.\n(decl x64_psubusw (Xmm XmmMem) Xmm)\n(rule 0 (x64_psubusw src1 src2)\n      (xmm_rm_r (SseOpcode.Psubusw) src1 src2))\n(rule 1 (x64_psubusw src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vpsubusw) src1 src2))\n\n;; Helper for creating `pavgb` instructions.\n(decl x64_pavgb (Xmm XmmMem) Xmm)\n(rule 0 (x64_pavgb src1 src2)\n      (xmm_rm_r (SseOpcode.Pavgb) src1 src2))\n(rule 1 (x64_pavgb src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vpavgb) src1 src2))\n\n;; Helper for creating `pavgw` instructions.\n(decl x64_pavgw (Xmm XmmMem) Xmm)\n(rule 0 (x64_pavgw src1 src2)\n      (xmm_rm_r (SseOpcode.Pavgw) src1 src2))\n(rule 1 (x64_pavgw src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vpavgw) src1 src2))\n\n;; Helper for creating `pand` instructions.\n(decl x64_pand (Xmm XmmMem) Xmm)\n(rule 0 (x64_pand src1 src2)\n      (xmm_rm_r (SseOpcode.Pand) src1 src2))\n(rule 1 (x64_pand src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vpand) src1 src2))\n\n;; Helper for creating `andps` instructions.\n(decl x64_andps (Xmm XmmMem) Xmm)\n(rule 0 (x64_andps src1 src2)\n      (xmm_rm_r (SseOpcode.Andps) src1 src2))\n(rule 1 (x64_andps src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vandps) src1 src2))\n\n;; Helper for creating `andpd` instructions.\n(decl x64_andpd (Xmm XmmMem) Xmm)\n(rule 0 (x64_andpd src1 src2)\n      (xmm_rm_r (SseOpcode.Andpd) src1 src2))\n(rule 1 (x64_andpd src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vandpd) src1 src2))\n\n;; Helper for creating `por` instructions.\n(decl x64_por (Xmm XmmMem) Xmm)\n(rule 0 (x64_por src1 src2)\n      (xmm_rm_r (SseOpcode.Por) src1 src2))\n(rule 1 (x64_por src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vpor) src1 src2))\n\n;; Helper for creating `orps` instructions.\n(decl x64_orps (Xmm XmmMem) Xmm)\n(rule 0 (x64_orps src1 src2)\n      (xmm_rm_r (SseOpcode.Orps) src1 src2))\n(rule 1 (x64_orps src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vorps) src1 src2))\n\n;; Helper for creating `orpd` instructions.\n(decl x64_orpd (Xmm XmmMem) Xmm)\n(rule 0 (x64_orpd src1 src2)\n      (xmm_rm_r (SseOpcode.Orpd) src1 src2))\n(rule 1 (x64_orpd src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vorpd) src1 src2))\n\n;; Helper fxor creating `pxor` instructions.\n(decl x64_pxor (Xmm XmmMem) Xmm)\n(rule 0 (x64_pxor src1 src2)\n      (xmm_rm_r (SseOpcode.Pxor) src1 src2))\n(rule 1 (x64_pxor src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vpxor) src1 src2))\n\n;; Helper fxor creating `xorps` instructions.\n(decl x64_xorps (Xmm XmmMem) Xmm)\n(rule 0 (x64_xorps src1 src2)\n      (xmm_rm_r (SseOpcode.Xorps) src1 src2))\n(rule 1 (x64_xorps src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vxorps) src1 src2))\n\n;; Helper fxor creating `xorpd` instructions.\n(decl x64_xorpd (Xmm XmmMem) Xmm)\n(rule 0 (x64_xorpd src1 src2)\n      (xmm_rm_r (SseOpcode.Xorpd) src1 src2))\n(rule 1 (x64_xorpd src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vxorpd) src1 src2))\n\n;; Helper for creating `pmullw` instructions.\n(decl x64_pmullw (Xmm XmmMem) Xmm)\n(rule 0 (x64_pmullw src1 src2)\n      (xmm_rm_r (SseOpcode.Pmullw) src1 src2))\n(rule 1 (x64_pmullw src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vpmullw) src1 src2))\n\n;; Helper for creating `pmulld` instructions.\n(decl x64_pmulld (Xmm XmmMem) Xmm)\n(rule 0 (x64_pmulld src1 src2)\n      (xmm_rm_r (SseOpcode.Pmulld) src1 src2))\n(rule 1 (x64_pmulld src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vpmulld) src1 src2))\n\n;; Helper for creating `pmulhw` instructions.\n(decl x64_pmulhw (Xmm XmmMem) Xmm)\n(rule 0 (x64_pmulhw src1 src2)\n      (xmm_rm_r (SseOpcode.Pmulhw) src1 src2))\n(rule 1 (x64_pmulhw src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vpmulhw) src1 src2))\n\n;; Helper for creating `pmulhrsw` instructions.\n(decl x64_pmulhrsw (Xmm XmmMem) Xmm)\n(rule 0 (x64_pmulhrsw src1 src2)\n      (xmm_rm_r (SseOpcode.Pmulhrsw) src1 src2))\n(rule 1 (x64_pmulhrsw src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vpmulhrsw) src1 src2))\n\n;; Helper for creating `pmulhuw` instructions.\n(decl x64_pmulhuw (Xmm XmmMem) Xmm)\n(rule 0 (x64_pmulhuw src1 src2)\n      (xmm_rm_r (SseOpcode.Pmulhuw) src1 src2))\n(rule 1 (x64_pmulhuw src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vpmulhuw) src1 src2))\n\n;; Helper for creating `pmuldq` instructions.\n(decl x64_pmuldq (Xmm XmmMem) Xmm)\n(rule 0 (x64_pmuldq src1 src2)\n      (xmm_rm_r (SseOpcode.Pmuldq) src1 src2))\n(rule 1 (x64_pmuldq src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vpmuldq) src1 src2))\n\n;; Helper for creating `pmuludq` instructions.\n(decl x64_pmuludq (Xmm XmmMem) Xmm)\n(rule 0 (x64_pmuludq src1 src2)\n      (xmm_rm_r (SseOpcode.Pmuludq) src1 src2))\n(rule 1 (x64_pmuludq src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vpmuludq) src1 src2))\n\n;; Helper for creating `punpckhwd` instructions.\n(decl x64_punpckhwd (Xmm XmmMem) Xmm)\n(rule 0 (x64_punpckhwd src1 src2)\n      (xmm_rm_r (SseOpcode.Punpckhwd) src1 src2))\n(rule 1 (x64_punpckhwd src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vpunpckhwd) src1 src2))\n\n;; Helper for creating `punpcklwd` instructions.\n(decl x64_punpcklwd (Xmm XmmMem) Xmm)\n(rule 0 (x64_punpcklwd src1 src2)\n      (xmm_rm_r (SseOpcode.Punpcklwd) src1 src2))\n(rule 1 (x64_punpcklwd src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vpunpcklwd) src1 src2))\n\n;; Helper for creating `unpcklps` instructions.\n(decl x64_unpcklps (Xmm XmmMem) Xmm)\n(rule 0 (x64_unpcklps src1 src2)\n      (xmm_rm_r (SseOpcode.Unpcklps) src1 src2))\n(rule 1 (x64_unpcklps src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vunpcklps) src1 src2))\n\n;; Helper for creating `andnps` instructions.\n(decl x64_andnps (Xmm XmmMem) Xmm)\n(rule 0 (x64_andnps src1 src2)\n      (xmm_rm_r (SseOpcode.Andnps) src1 src2))\n(rule 1 (x64_andnps src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vandnps) src1 src2))\n\n;; Helper for creating `andnpd` instructions.\n(decl x64_andnpd (Xmm XmmMem) Xmm)\n(rule 0 (x64_andnpd src1 src2)\n      (xmm_rm_r (SseOpcode.Andnpd) src1 src2))\n(rule 1 (x64_andnpd src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vandnpd) src1 src2))\n\n;; Helper for creating `pandn` instructions.\n(decl x64_pandn (Xmm XmmMem) Xmm)\n(rule 0 (x64_pandn src1 src2)\n      (xmm_rm_r (SseOpcode.Pandn) src1 src2))\n(rule 1 (x64_pandn src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vpandn) src1 src2))\n\n;; Helper for creating `addss` instructions.\n(decl x64_addss (Xmm XmmMem) Xmm)\n(rule (x64_addss src1 src2)\n      (xmm_rm_r_unaligned (SseOpcode.Addss) src1 src2))\n(rule 1 (x64_addss src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vaddss) src1 src2))\n\n;; Helper for creating `addsd` instructions.\n(decl x64_addsd (Xmm XmmMem) Xmm)\n(rule (x64_addsd src1 src2)\n      (xmm_rm_r_unaligned (SseOpcode.Addsd) src1 src2))\n(rule 1 (x64_addsd src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vaddsd) src1 src2))\n\n;; Helper for creating `addps` instructions.\n(decl x64_addps (Xmm XmmMem) Xmm)\n(rule 0 (x64_addps src1 src2)\n      (xmm_rm_r (SseOpcode.Addps) src1 src2))\n(rule 1 (x64_addps src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vaddps) src1 src2))\n\n;; Helper for creating `addpd` instructions.\n(decl x64_addpd (Xmm XmmMem) Xmm)\n(rule 0 (x64_addpd src1 src2)\n      (xmm_rm_r (SseOpcode.Addpd) src1 src2))\n(rule 1 (x64_addpd src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vaddpd) src1 src2))\n\n;; Helper for creating `subss` instructions.\n(decl x64_subss (Xmm XmmMem) Xmm)\n(rule (x64_subss src1 src2)\n      (xmm_rm_r_unaligned (SseOpcode.Subss) src1 src2))\n(rule 1 (x64_subss src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vsubss) src1 src2))\n\n;; Helper for creating `subsd` instructions.\n(decl x64_subsd (Xmm XmmMem) Xmm)\n(rule (x64_subsd src1 src2)\n      (xmm_rm_r_unaligned (SseOpcode.Subsd) src1 src2))\n(rule 1 (x64_subsd src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vsubsd) src1 src2))\n\n;; Helper for creating `subps` instructions.\n(decl x64_subps (Xmm XmmMem) Xmm)\n(rule 0 (x64_subps src1 src2)\n      (xmm_rm_r (SseOpcode.Subps) src1 src2))\n(rule 1 (x64_subps src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vsubps) src1 src2))\n\n;; Helper for creating `subpd` instructions.\n(decl x64_subpd (Xmm XmmMem) Xmm)\n(rule 0 (x64_subpd src1 src2)\n      (xmm_rm_r (SseOpcode.Subpd) src1 src2))\n(rule 1 (x64_subpd src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vsubpd) src1 src2))\n\n;; Helper for creating `mulss` instructions.\n(decl x64_mulss (Xmm XmmMem) Xmm)\n(rule (x64_mulss src1 src2)\n      (xmm_rm_r_unaligned (SseOpcode.Mulss) src1 src2))\n(rule 1 (x64_mulss src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vmulss) src1 src2))\n\n;; Helper for creating `mulsd` instructions.\n(decl x64_mulsd (Xmm XmmMem) Xmm)\n(rule (x64_mulsd src1 src2)\n      (xmm_rm_r_unaligned (SseOpcode.Mulsd) src1 src2))\n(rule 1 (x64_mulsd src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vmulsd) src1 src2))\n\n;; Helper for creating `mulps` instructions.\n(decl x64_mulps (Xmm XmmMem) Xmm)\n(rule 0 (x64_mulps src1 src2)\n      (xmm_rm_r (SseOpcode.Mulps) src1 src2))\n(rule 1 (x64_mulps src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vmulps) src1 src2))\n\n;; Helper for creating `mulpd` instructions.\n(decl x64_mulpd (Xmm XmmMem) Xmm)\n(rule (x64_mulpd src1 src2)\n      (xmm_rm_r (SseOpcode.Mulpd) src1 src2))\n(rule 1 (x64_mulpd src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vmulpd) src1 src2))\n\n;; Helper for creating `divss` instructions.\n(decl x64_divss (Xmm XmmMem) Xmm)\n(rule (x64_divss src1 src2)\n      (xmm_rm_r_unaligned (SseOpcode.Divss) src1 src2))\n(rule 1 (x64_divss src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vdivss) src1 src2))\n\n;; Helper for creating `divsd` instructions.\n(decl x64_divsd (Xmm XmmMem) Xmm)\n(rule (x64_divsd src1 src2)\n      (xmm_rm_r_unaligned (SseOpcode.Divsd) src1 src2))\n(rule 1 (x64_divsd src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vdivsd) src1 src2))\n\n;; Helper for creating `divps` instructions.\n(decl x64_divps (Xmm XmmMem) Xmm)\n(rule 0 (x64_divps src1 src2)\n      (xmm_rm_r (SseOpcode.Divps) src1 src2))\n(rule 1 (x64_divps src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vdivps) src1 src2))\n\n;; Helper for creating `divpd` instructions.\n(decl x64_divpd (Xmm XmmMem) Xmm)\n(rule 0 (x64_divpd src1 src2)\n      (xmm_rm_r (SseOpcode.Divpd) src1 src2))\n(rule 1 (x64_divpd src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vdivpd) src1 src2))\n\n;; Helper for creating `XmmRmRBlend` instructions\n(decl xmm_rm_r_blend (SseOpcode Xmm XmmMemAligned Xmm) Xmm)\n(rule (xmm_rm_r_blend op src1 src2 mask)\n      (let ((dst WritableXmm (temp_writable_xmm))\n            (_ Unit (emit (MInst.XmmRmRBlend op src1 src2 mask dst))))\n        dst))\n\n;; Helper for creating `XmmRmRBlendVex` instructions\n(decl xmm_rmr_blend_vex (AvxOpcode Xmm XmmMem Xmm) Xmm)\n(rule (xmm_rmr_blend_vex op src1 src2 mask)\n      (let ((dst WritableXmm (temp_writable_xmm))\n            (_ Unit (emit (MInst.XmmRmRBlendVex op src1 src2 mask dst))))\n        dst))\n\n;; Helper for creating `XmmUnaryRmRVex` instructions\n(decl xmm_unary_rm_r_vex (AvxOpcode XmmMem) Xmm)\n(rule (xmm_unary_rm_r_vex op src)\n      (let ((dst WritableXmm (temp_writable_xmm))\n            (_ Unit (emit (MInst.XmmUnaryRmRVex op src dst))))\n        dst))\n\n;; Helper for creating `XmmUnaryRmRImmVex` instructions\n(decl xmm_unary_rm_r_imm_vex (AvxOpcode XmmMem u8) Xmm)\n(rule (xmm_unary_rm_r_imm_vex op src imm)\n      (let ((dst WritableXmm (temp_writable_xmm))\n            (_ Unit (emit (MInst.XmmUnaryRmRImmVex op src dst imm))))\n        dst))\n\n;; Helper for creating `blendvp{d,s}` and `pblendvb` instructions.\n(decl x64_blend (Type Xmm XmmMem Xmm) Xmm)\n(rule 1 (x64_blend $F32X4 mask src1 src2) (x64_blendvps src2 src1 mask))\n(rule 1 (x64_blend $F64X2 mask src1 src2) (x64_blendvpd src2 src1 mask))\n(rule 0 (x64_blend (multi_lane _ _) mask src1 src2) (x64_pblendvb src2 src1 mask))\n\n;; Helper for creating `blendvpd` instructions.\n(decl x64_blendvpd (Xmm XmmMem Xmm) Xmm)\n(rule 0 (x64_blendvpd src1 src2 mask)\n      (xmm_rm_r_blend (SseOpcode.Blendvpd) src1 src2 mask))\n(rule 1 (x64_blendvpd src1 src2 mask)\n      (if-let $true (has_avx))\n      (xmm_rmr_blend_vex (AvxOpcode.Vblendvpd) src1 src2 mask))\n\n;; Helper for creating `blendvps` instructions.\n(decl x64_blendvps (Xmm XmmMem Xmm) Xmm)\n(rule 0 (x64_blendvps src1 src2 mask)\n      (xmm_rm_r_blend (SseOpcode.Blendvps) src1 src2 mask))\n(rule 1 (x64_blendvps src1 src2 mask)\n      (if-let $true (has_avx))\n      (xmm_rmr_blend_vex (AvxOpcode.Vblendvps) src1 src2 mask))\n\n;; Helper for creating `pblendvb` instructions.\n(decl x64_pblendvb (Xmm XmmMem Xmm) Xmm)\n(rule 0 (x64_pblendvb src1 src2 mask)\n      (xmm_rm_r_blend (SseOpcode.Pblendvb) src1 src2 mask))\n(rule 1 (x64_pblendvb src1 src2 mask)\n      (if-let $true (has_avx))\n      (xmm_rmr_blend_vex (AvxOpcode.Vpblendvb) src1 src2 mask))\n\n;; Helper for creating `movsd` instructions.\n(decl x64_movsd_regmove (Xmm XmmMem) Xmm)\n(rule (x64_movsd_regmove src1 src2)\n      (xmm_rm_r_unaligned (SseOpcode.Movsd) src1 src2))\n\n;; Helper for creating `movlhps` instructions.\n(decl x64_movlhps (Xmm XmmMem) Xmm)\n(rule 0 (x64_movlhps src1 src2)\n      (xmm_rm_r (SseOpcode.Movlhps) src1 src2))\n(rule 1 (x64_movlhps src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vmovlhps) src1 src2))\n\n;; Helpers for creating `pmaxs*` instructions.\n(decl x64_pmaxs (Type Xmm XmmMem) Xmm)\n(rule (x64_pmaxs $I8X16 x y) (x64_pmaxsb x y))\n(rule (x64_pmaxs $I16X8 x y) (x64_pmaxsw x y))\n(rule (x64_pmaxs $I32X4 x y) (x64_pmaxsd x y))\n;; No $I64X2 version (PMAXSQ) in SSE4.1.\n(decl x64_pmaxsb (Xmm XmmMem) Xmm)\n(rule 0 (x64_pmaxsb src1 src2) (xmm_rm_r (SseOpcode.Pmaxsb) src1 src2))\n(rule 1 (x64_pmaxsb src1 src2)\n        (if-let $true (has_avx))\n        (xmm_rmir_vex (AvxOpcode.Vpmaxsb) src1 src2))\n(decl x64_pmaxsw (Xmm XmmMem) Xmm)\n(rule 0 (x64_pmaxsw src1 src2) (xmm_rm_r (SseOpcode.Pmaxsw) src1 src2))\n(rule 1 (x64_pmaxsw src1 src2)\n        (if-let $true (has_avx))\n        (xmm_rmir_vex (AvxOpcode.Vpmaxsw) src1 src2))\n(decl x64_pmaxsd (Xmm XmmMem) Xmm)\n(rule 0 (x64_pmaxsd src1 src2) (xmm_rm_r (SseOpcode.Pmaxsd) src1 src2))\n(rule 1 (x64_pmaxsd src1 src2)\n        (if-let $true (has_avx))\n        (xmm_rmir_vex (AvxOpcode.Vpmaxsd) src1 src2))\n\n;; Helpers for creating `pmins*` instructions.\n(decl x64_pmins (Type Xmm XmmMem) Xmm)\n(rule (x64_pmins $I8X16 x y) (x64_pminsb x y))\n(rule (x64_pmins $I16X8 x y) (x64_pminsw x y))\n(rule (x64_pmins $I32X4 x y) (x64_pminsd x y))\n;; No $I64X2 version (PMINSQ) in SSE4.1.\n(decl x64_pminsb (Xmm XmmMem) Xmm)\n(rule 0 (x64_pminsb src1 src2) (xmm_rm_r (SseOpcode.Pminsb) src1 src2))\n(rule 1 (x64_pminsb src1 src2)\n        (if-let $true (has_avx))\n        (xmm_rmir_vex (AvxOpcode.Vpminsb) src1 src2))\n(decl x64_pminsw (Xmm XmmMem) Xmm)\n(rule 0 (x64_pminsw src1 src2) (xmm_rm_r (SseOpcode.Pminsw) src1 src2))\n(rule 1 (x64_pminsw src1 src2)\n        (if-let $true (has_avx))\n        (xmm_rmir_vex (AvxOpcode.Vpminsw) src1 src2))\n(decl x64_pminsd (Xmm XmmMem) Xmm)\n(rule 0 (x64_pminsd src1 src2) (xmm_rm_r (SseOpcode.Pminsd) src1 src2))\n(rule 1 (x64_pminsd src1 src2)\n        (if-let $true (has_avx))\n        (xmm_rmir_vex (AvxOpcode.Vpminsd) src1 src2))\n\n;; Helpers for creating `pmaxu*` instructions.\n(decl x64_pmaxu (Type Xmm XmmMem) Xmm)\n(rule (x64_pmaxu $I8X16 x y) (x64_pmaxub x y))\n(rule (x64_pmaxu $I16X8 x y) (x64_pmaxuw x y))\n(rule (x64_pmaxu $I32X4 x y) (x64_pmaxud x y))\n;; No $I64X2 version (PMAXUQ) in SSE4.1.\n(decl x64_pmaxub (Xmm XmmMem) Xmm)\n(rule 0 (x64_pmaxub src1 src2) (xmm_rm_r (SseOpcode.Pmaxub) src1 src2))\n(rule 1 (x64_pmaxub src1 src2)\n        (if-let $true (has_avx))\n        (xmm_rmir_vex (AvxOpcode.Vpmaxub) src1 src2))\n(decl x64_pmaxuw (Xmm XmmMem) Xmm)\n(rule 0 (x64_pmaxuw src1 src2) (xmm_rm_r (SseOpcode.Pmaxuw) src1 src2))\n(rule 1 (x64_pmaxuw src1 src2)\n        (if-let $true (has_avx))\n        (xmm_rmir_vex (AvxOpcode.Vpmaxuw) src1 src2))\n(decl x64_pmaxud (Xmm XmmMem) Xmm)\n(rule 0 (x64_pmaxud src1 src2) (xmm_rm_r (SseOpcode.Pmaxud) src1 src2))\n(rule 1 (x64_pmaxud src1 src2)\n        (if-let $true (has_avx))\n        (xmm_rmir_vex (AvxOpcode.Vpmaxud) src1 src2))\n\n;; Helper for creating `pminu*` instructions.\n(decl x64_pminu (Type Xmm XmmMem) Xmm)\n(rule (x64_pminu $I8X16 x y) (x64_pminub x y))\n(rule (x64_pminu $I16X8 x y) (x64_pminuw x y))\n(rule (x64_pminu $I32X4 x y) (x64_pminud x y))\n;; No $I64X2 version (PMINUQ) in SSE4.1.\n(decl x64_pminub (Xmm XmmMem) Xmm)\n(rule 0 (x64_pminub src1 src2) (xmm_rm_r (SseOpcode.Pminub) src1 src2))\n(rule 1 (x64_pminub src1 src2)\n        (if-let $true (has_avx))\n        (xmm_rmir_vex (AvxOpcode.Vpminub) src1 src2))\n(decl x64_pminuw (Xmm XmmMem) Xmm)\n(rule 0 (x64_pminuw src1 src2) (xmm_rm_r (SseOpcode.Pminuw) src1 src2))\n(rule 1 (x64_pminuw src1 src2)\n        (if-let $true (has_avx))\n        (xmm_rmir_vex (AvxOpcode.Vpminuw) src1 src2))\n(decl x64_pminud (Xmm XmmMem) Xmm)\n(rule 0 (x64_pminud src1 src2) (xmm_rm_r (SseOpcode.Pminud) src1 src2))\n(rule 1 (x64_pminud src1 src2)\n        (if-let $true (has_avx))\n        (xmm_rmir_vex (AvxOpcode.Vpminud) src1 src2))\n\n;; Helper for creating `punpcklbw` instructions.\n(decl x64_punpcklbw (Xmm XmmMem) Xmm)\n(rule 0 (x64_punpcklbw src1 src2)\n      (xmm_rm_r (SseOpcode.Punpcklbw) src1 src2))\n(rule 1 (x64_punpcklbw src1 src2)\n        (if-let $true (has_avx))\n        (xmm_rmir_vex (AvxOpcode.Vpunpcklbw) src1 src2))\n\n;; Helper for creating `punpckhbw` instructions.\n(decl x64_punpckhbw (Xmm XmmMem) Xmm)\n(rule 0 (x64_punpckhbw src1 src2)\n      (xmm_rm_r (SseOpcode.Punpckhbw) src1 src2))\n(rule 1 (x64_punpckhbw src1 src2)\n        (if-let $true (has_avx))\n        (xmm_rmir_vex (AvxOpcode.Vpunpckhbw) src1 src2))\n\n;; Helper for creating `packsswb` instructions.\n(decl x64_packsswb (Xmm XmmMem) Xmm)\n(rule 0 (x64_packsswb src1 src2)\n      (xmm_rm_r (SseOpcode.Packsswb) src1 src2))\n(rule 1 (x64_packsswb src1 src2)\n        (if-let $true (has_avx))\n        (xmm_rmir_vex (AvxOpcode.Vpacksswb) src1 src2))\n\n;; Helper for creating `packssdw` instructions.\n(decl x64_packssdw (Xmm XmmMem) Xmm)\n(rule 0 (x64_packssdw src1 src2)\n      (xmm_rm_r (SseOpcode.Packssdw) src1 src2))\n(rule 1 (x64_packssdw src1 src2)\n        (if-let $true (has_avx))\n        (xmm_rmir_vex (AvxOpcode.Vpackssdw) src1 src2))\n\n;; Helper for creating `packuswb` instructions.\n(decl x64_packuswb (Xmm XmmMem) Xmm)\n(rule 0 (x64_packuswb src1 src2)\n      (xmm_rm_r (SseOpcode.Packuswb) src1 src2))\n(rule 1 (x64_packuswb src1 src2)\n        (if-let $true (has_avx))\n        (xmm_rmir_vex (AvxOpcode.Vpackuswb) src1 src2))\n\n;; Helper for creating `packusdw` instructions.\n(decl x64_packusdw (Xmm XmmMem) Xmm)\n(rule 0 (x64_packusdw src1 src2)\n      (xmm_rm_r (SseOpcode.Packusdw) src1 src2))\n(rule 1 (x64_packusdw src1 src2)\n        (if-let $true (has_avx))\n        (xmm_rmir_vex (AvxOpcode.Vpackusdw) src1 src2))\n\n;; Helper for creating `MInst.XmmRmRImm` instructions.\n(decl xmm_rm_r_imm (SseOpcode Reg RegMem u8 OperandSize) Xmm)\n(rule (xmm_rm_r_imm op src1 src2 imm size)\n      (let ((dst WritableXmm (temp_writable_xmm))\n            (_ Unit (emit (MInst.XmmRmRImm op\n                                           src1\n                                           src2\n                                           dst\n                                           imm\n                                           size))))\n        dst))\n\n;; Helper for creating `palignr` instructions.\n(decl x64_palignr (Xmm XmmMem u8 OperandSize) Xmm)\n(rule 0 (x64_palignr src1 src2 imm size)\n      (xmm_rm_r_imm (SseOpcode.Palignr)\n                    src1\n                    src2\n                    imm\n                    size))\n(rule 1 (x64_palignr src1 src2 imm size)\n      (if-let $true (has_avx))\n      (xmm_rmr_imm_vex (AvxOpcode.Vpalignr) src1 src2 imm))\n\n;; Helpers for creating `cmpp*` instructions.\n(decl x64_cmpp (Type Xmm XmmMem FcmpImm) Xmm)\n(rule (x64_cmpp $F32X4 x y imm) (x64_cmpps x y imm))\n(rule (x64_cmpp $F64X2 x y imm) (x64_cmppd x y imm))\n\n(decl x64_cmpps (Xmm XmmMem FcmpImm) Xmm)\n(rule 0 (x64_cmpps src1 src2 imm)\n      (xmm_rm_r_imm (SseOpcode.Cmpps)\n                    src1\n                    src2\n                    (encode_fcmp_imm imm)\n                    (OperandSize.Size32)))\n(rule 1 (x64_cmpps src1 src2 imm)\n      (if-let $true (has_avx))\n      (xmm_rmr_imm_vex (AvxOpcode.Vcmpps)\n                       src1\n                       src2\n                       (encode_fcmp_imm imm)))\n\n;; Note that `Size32` is intentional despite this being used for 64-bit\n;; operations, since this presumably induces the correct encoding of the\n;; instruction.\n(decl x64_cmppd (Xmm XmmMem FcmpImm) Xmm)\n(rule 0 (x64_cmppd src1 src2 imm)\n      (xmm_rm_r_imm (SseOpcode.Cmppd)\n                    src1\n                    src2\n                    (encode_fcmp_imm imm)\n                    (OperandSize.Size32)))\n(rule 1 (x64_cmppd src1 src2 imm)\n      (if-let $true (has_avx))\n      (xmm_rmr_imm_vex (AvxOpcode.Vcmppd)\n                       src1\n                       src2\n                       (encode_fcmp_imm imm)))\n\n;; Helper for creating `pinsrb` instructions.\n(decl x64_pinsrb (Xmm GprMem u8) Xmm)\n(rule 0 (x64_pinsrb src1 src2 lane)\n      (xmm_rm_r_imm (SseOpcode.Pinsrb)\n                    src1\n                    src2\n                    lane\n                    (OperandSize.Size32)))\n(rule 1 (x64_pinsrb src1 src2 lane)\n      (if-let $true (has_avx))\n      (xmm_vex_pinsr (AvxOpcode.Vpinsrb) src1 src2 lane))\n\n;; Helper for creating `pinsrw` instructions.\n(decl x64_pinsrw (Xmm GprMem u8) Xmm)\n(rule 0 (x64_pinsrw src1 src2 lane)\n      (xmm_rm_r_imm (SseOpcode.Pinsrw)\n                    src1\n                    src2\n                    lane\n                    (OperandSize.Size32)))\n(rule 1 (x64_pinsrw src1 src2 lane)\n      (if-let $true (has_avx))\n      (xmm_vex_pinsr (AvxOpcode.Vpinsrw) src1 src2 lane))\n\n;; Helper for creating `pinsrd` instructions.\n(decl x64_pinsrd (Xmm GprMem u8) Xmm)\n(rule 0 (x64_pinsrd src1 src2 lane)\n      (xmm_rm_r_imm (SseOpcode.Pinsrd)\n                    src1\n                    src2\n                    lane\n                    (OperandSize.Size32)))\n(rule 1 (x64_pinsrd src1 src2 lane)\n      (if-let $true (has_avx))\n      (xmm_vex_pinsr (AvxOpcode.Vpinsrd) src1 src2 lane))\n\n;; Helper for creating `pinsrq` instructions.\n(decl x64_pinsrq (Xmm GprMem u8) Xmm)\n(rule (x64_pinsrq src1 src2 lane)\n      (xmm_rm_r_imm (SseOpcode.Pinsrd)\n                    src1\n                    src2\n                    lane\n                    (OperandSize.Size64)))\n(rule 1 (x64_pinsrq src1 src2 lane)\n      (if-let $true (has_avx))\n      (xmm_vex_pinsr (AvxOpcode.Vpinsrq) src1 src2 lane))\n\n;; Helper for constructing `XmmVexPinsr` instructions.\n(decl xmm_vex_pinsr (AvxOpcode Xmm GprMem u8) Xmm)\n(rule (xmm_vex_pinsr op src1 src2 imm)\n      (let ((dst WritableXmm (temp_writable_xmm))\n            (_ Unit (emit (MInst.XmmVexPinsr op src1 src2 dst imm))))\n        dst))\n\n;; Helper for constructing `XmmUnaryRmRImm` instructions.\n(decl xmm_unary_rm_r_imm (SseOpcode XmmMemAligned u8) Xmm)\n(rule (xmm_unary_rm_r_imm op src1 imm)\n      (let ((dst WritableXmm (temp_writable_xmm))\n            (_ Unit (emit (MInst.XmmUnaryRmRImm op src1 imm dst))))\n        dst))\n\n;; Helper for creating `roundss` instructions.\n(decl x64_roundss (XmmMem RoundImm) Xmm)\n(rule (x64_roundss src1 round)\n      (xmm_unary_rm_r_imm (SseOpcode.Roundss) src1 (encode_round_imm round)))\n\n;; Helper for creating `roundsd` instructions.\n(decl x64_roundsd (XmmMem RoundImm) Xmm)\n(rule (x64_roundsd src1 round)\n      (xmm_unary_rm_r_imm (SseOpcode.Roundsd) src1 (encode_round_imm round)))\n\n;; Helper for creating `roundps` instructions.\n(decl x64_roundps (XmmMem RoundImm) Xmm)\n(rule (x64_roundps src1 round)\n      (xmm_unary_rm_r_imm (SseOpcode.Roundps) src1 (encode_round_imm round)))\n(rule 1 (x64_roundps src1 round)\n      (if-let $true (has_avx))\n      (xmm_unary_rm_r_imm_vex (AvxOpcode.Vroundps) src1 (encode_round_imm round)))\n\n;; Helper for creating `roundpd` instructions.\n(decl x64_roundpd (XmmMem RoundImm) Xmm)\n(rule (x64_roundpd src1 round)\n      (xmm_unary_rm_r_imm (SseOpcode.Roundpd) src1 (encode_round_imm round)))\n(rule 1 (x64_roundpd src1 round)\n      (if-let $true (has_avx))\n      (xmm_unary_rm_r_imm_vex (AvxOpcode.Vroundpd) src1 (encode_round_imm round)))\n\n;; Helper for creating `pmaddwd` instructions.\n(decl x64_pmaddwd (Xmm XmmMem) Xmm)\n(rule 0 (x64_pmaddwd src1 src2)\n      (xmm_rm_r (SseOpcode.Pmaddwd) src1 src2))\n(rule 1 (x64_pmaddwd src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vpmaddwd) src1 src2))\n\n(decl x64_pmaddubsw (Xmm XmmMem) Xmm)\n(rule 0 (x64_pmaddubsw src1 src2)\n      (xmm_rm_r (SseOpcode.Pmaddubsw) src1 src2))\n(rule 1 (x64_pmaddubsw src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vpmaddubsw) src1 src2))\n\n;; Helper for creating `insertps` instructions.\n(decl x64_insertps (Xmm XmmMem u8) Xmm)\n(rule 0 (x64_insertps src1 src2 lane)\n      (xmm_rm_r_imm (SseOpcode.Insertps)\n                    src1\n                    src2\n                    lane\n                    (OperandSize.Size32)))\n(rule 1 (x64_insertps src1 src2 lane)\n      (if-let $true (has_avx))\n      (xmm_rmr_imm_vex (AvxOpcode.Vinsertps) src1 src2 lane))\n\n;; Helper for creating `pshufd` instructions.\n(decl x64_pshufd (XmmMem u8) Xmm)\n(rule (x64_pshufd src imm)\n      (xmm_unary_rm_r_imm (SseOpcode.Pshufd) src imm))\n\n;; Helper for creating `pshufb` instructions.\n(decl x64_pshufb (Xmm XmmMem) Xmm)\n(rule 0 (x64_pshufb src1 src2)\n      (xmm_rm_r (SseOpcode.Pshufb) src1 src2))\n(rule 1 (x64_pshufb src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vpshufb) src1 src2))\n\n;; Helper for creating `shufps` instructions.\n(decl x64_shufps (Xmm XmmMem u8) Xmm)\n(rule 0 (x64_shufps src1 src2 byte)\n      (xmm_rm_r_imm (SseOpcode.Shufps)\n                    src1\n                    src2\n                    byte\n                    (OperandSize.Size32)))\n(rule 1 (x64_shufps src1 src2 byte)\n      (if-let $true (has_avx))\n      (xmm_rmr_imm_vex (AvxOpcode.Vshufps) src1 src2 byte))\n\n;; Helper for creating `MInst.XmmUnaryRmR` instructions.\n(decl xmm_unary_rm_r (SseOpcode XmmMemAligned) Xmm)\n(rule (xmm_unary_rm_r op src)\n      (let ((dst WritableXmm (temp_writable_xmm))\n            (_ Unit (emit (MInst.XmmUnaryRmR op src dst))))\n        dst))\n\n;; Helper for creating `MInst.XmmUnaryRmRUnaligned` instructions.\n(decl xmm_unary_rm_r_unaligned (SseOpcode XmmMem) Xmm)\n(rule (xmm_unary_rm_r_unaligned op src)\n      (let ((dst WritableXmm (temp_writable_xmm))\n            (_ Unit (emit (MInst.XmmUnaryRmRUnaligned op src dst))))\n        dst))\n\n;; Helper for creating `pabsb` instructions.\n(decl x64_pabsb (XmmMem) Xmm)\n(rule (x64_pabsb src)\n      (xmm_unary_rm_r (SseOpcode.Pabsb) src))\n(rule 1 (x64_pabsb src)\n      (if-let $true (has_avx))\n      (xmm_unary_rm_r_vex (AvxOpcode.Vpabsb) src))\n\n;; Helper for creating `pabsw` instructions.\n(decl x64_pabsw (XmmMem) Xmm)\n(rule (x64_pabsw src)\n      (xmm_unary_rm_r (SseOpcode.Pabsw) src))\n(rule 1 (x64_pabsw src)\n      (if-let $true (has_avx))\n      (xmm_unary_rm_r_vex (AvxOpcode.Vpabsw) src))\n\n;; Helper for creating `pabsd` instructions.\n(decl x64_pabsd (XmmMem) Xmm)\n(rule (x64_pabsd src)\n      (xmm_unary_rm_r (SseOpcode.Pabsd) src))\n(rule 1 (x64_pabsd src)\n      (if-let $true (has_avx))\n      (xmm_unary_rm_r_vex (AvxOpcode.Vpabsd) src))\n\n;; Helper for creating `MInst.XmmUnaryRmREvex` instructions.\n(decl xmm_unary_rm_r_evex (Avx512Opcode XmmMem) Xmm)\n(rule (xmm_unary_rm_r_evex op src)\n      (let ((dst WritableXmm (temp_writable_xmm))\n            (_ Unit (emit (MInst.XmmUnaryRmREvex op src dst))))\n        dst))\n\n;; Helper for creating `vcvtudq2ps` instructions.\n(decl x64_vcvtudq2ps (XmmMem) Xmm)\n(rule (x64_vcvtudq2ps src)\n      (xmm_unary_rm_r_evex (Avx512Opcode.Vcvtudq2ps) src))\n\n;; Helper for creating `vpabsq` instructions.\n(decl x64_vpabsq (XmmMem) Xmm)\n(rule (x64_vpabsq src)\n      (xmm_unary_rm_r_evex (Avx512Opcode.Vpabsq) src))\n\n;; Helper for creating `vpopcntb` instructions.\n(decl x64_vpopcntb (XmmMem) Xmm)\n(rule (x64_vpopcntb src)\n      (xmm_unary_rm_r_evex (Avx512Opcode.Vpopcntb) src))\n\n;; Helper for creating `MInst.XmmRmREvex` instructions.\n(decl xmm_rm_r_evex (Avx512Opcode XmmMem Xmm) Xmm)\n(rule (xmm_rm_r_evex op src1 src2)\n      (let ((dst WritableXmm (temp_writable_xmm))\n            (_ Unit (emit (MInst.XmmRmREvex op\n                                            src1\n                                            src2\n                                            dst))))\n        dst))\n\n;; Helper for creating `vpmullq` instructions.\n;;\n;; Requires AVX-512 vl and dq.\n(decl x64_vpmullq (XmmMem Xmm) Xmm)\n(rule (x64_vpmullq src1 src2)\n      (xmm_rm_r_evex (Avx512Opcode.Vpmullq)\n                     src1\n                     src2))\n\n;; Helper for creating `vpermi2b` instructions.\n;;\n;; Requires AVX-512 vl and vbmi extensions.\n(decl x64_vpermi2b (Xmm Xmm Xmm) Xmm)\n(rule (x64_vpermi2b src1 src2 src3)\n      (let ((dst WritableXmm (temp_writable_xmm))\n            (_ Unit (emit (MInst.XmmRmREvex3 (Avx512Opcode.Vpermi2b)\n                                             src1\n                                             src2\n                                             src3\n                                             dst))))\n        dst))\n\n;; Helper for creating `MInst.MulHi` instructions.\n;;\n;; Returns the (lo, hi) register halves of the multiplication.\n(decl mul_hi (Type bool Gpr GprMem) ValueRegs)\n(rule (mul_hi ty signed src1 src2)\n      (let ((dst_lo WritableGpr (temp_writable_gpr))\n            (dst_hi WritableGpr (temp_writable_gpr))\n            (size OperandSize (raw_operand_size_of_type ty))\n            (_ Unit (emit (MInst.MulHi size\n                                       signed\n                                       src1\n                                       src2\n                                       dst_lo\n                                       dst_hi))))\n        (value_gprs dst_lo dst_hi)))\n\n;; Helper for creating `mul` instructions that return both the lower and\n;; (unsigned) higher halves of the result.\n(decl mulhi_u (Type Gpr GprMem) ValueRegs)\n(rule (mulhi_u ty src1 src2)\n      (mul_hi ty $false src1 src2))\n\n;; Helper for creating `MInst.XmmRmiXmm` instructions.\n(decl xmm_rmi_xmm (SseOpcode Xmm XmmMemAlignedImm) Xmm)\n(rule (xmm_rmi_xmm op src1 src2)\n      (let ((dst WritableXmm (temp_writable_xmm))\n            (_ Unit (emit (MInst.XmmRmiReg op\n                                           src1\n                                           src2\n                                           dst))))\n        dst))\n\n;; Helper for creating `psllw` instructions.\n(decl x64_psllw (Xmm XmmMemImm) Xmm)\n(rule 0 (x64_psllw src1 src2)\n      (xmm_rmi_xmm (SseOpcode.Psllw) src1 src2))\n(rule 1 (x64_psllw src1 src2)\n        (if-let $true (has_avx))\n        (xmm_rmir_vex (AvxOpcode.Vpsllw) src1 src2))\n\n;; Helper for creating `pslld` instructions.\n(decl x64_pslld (Xmm XmmMemImm) Xmm)\n(rule 0 (x64_pslld src1 src2)\n      (xmm_rmi_xmm (SseOpcode.Pslld) src1 src2))\n(rule 1 (x64_pslld src1 src2)\n        (if-let $true (has_avx))\n        (xmm_rmir_vex (AvxOpcode.Vpslld) src1 src2))\n\n;; Helper for creating `psllq` instructions.\n(decl x64_psllq (Xmm XmmMemImm) Xmm)\n(rule 0 (x64_psllq src1 src2)\n      (xmm_rmi_xmm (SseOpcode.Psllq) src1 src2))\n(rule 1 (x64_psllq src1 src2)\n        (if-let $true (has_avx))\n        (xmm_rmir_vex (AvxOpcode.Vpsllq) src1 src2))\n\n;; Helper for creating `psrlw` instructions.\n(decl x64_psrlw (Xmm XmmMemImm) Xmm)\n(rule 0 (x64_psrlw src1 src2)\n      (xmm_rmi_xmm (SseOpcode.Psrlw) src1 src2))\n(rule 1 (x64_psrlw src1 src2)\n        (if-let $true (has_avx))\n        (xmm_rmir_vex (AvxOpcode.Vpsrlw) src1 src2))\n\n;; Helper for creating `psrld` instructions.\n(decl x64_psrld (Xmm XmmMemImm) Xmm)\n(rule 0 (x64_psrld src1 src2)\n      (xmm_rmi_xmm (SseOpcode.Psrld) src1 src2))\n(rule 1 (x64_psrld src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vpsrld) src1 src2))\n\n;; Helper for creating `psrlq` instructions.\n(decl x64_psrlq (Xmm XmmMemImm) Xmm)\n(rule 0 (x64_psrlq src1 src2)\n      (xmm_rmi_xmm (SseOpcode.Psrlq) src1 src2))\n(rule 1 (x64_psrlq src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vpsrlq) src1 src2))\n\n;; Helper for creating `psraw` instructions.\n(decl x64_psraw (Xmm XmmMemImm) Xmm)\n(rule 0 (x64_psraw src1 src2)\n      (xmm_rmi_xmm (SseOpcode.Psraw) src1 src2))\n(rule 1 (x64_psraw src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vpsraw) src1 src2))\n\n;; Helper for creating `psrad` instructions.\n(decl x64_psrad (Xmm XmmMemImm) Xmm)\n(rule 0 (x64_psrad src1 src2)\n      (xmm_rmi_xmm (SseOpcode.Psrad) src1 src2))\n(rule 1 (x64_psrad src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vpsrad) src1 src2))\n\n;; Helper for creating `pextrb` instructions.\n(decl x64_pextrb (Xmm u8) Gpr)\n(rule (x64_pextrb src lane)\n      (xmm_to_gpr_imm (SseOpcode.Pextrb) src lane))\n\n;; Helper for creating `pextrw` instructions.\n(decl x64_pextrw (Xmm u8) Gpr)\n(rule (x64_pextrw src lane)\n      (xmm_to_gpr_imm (SseOpcode.Pextrw) src lane))\n\n;; Helper for creating `pextrd` instructions.\n(decl x64_pextrd (Xmm u8) Gpr)\n(rule (x64_pextrd src lane)\n      (xmm_to_gpr_imm (SseOpcode.Pextrd) src lane))\n\n;; Helper for creating `pextrq` instructions.\n(decl x64_pextrq (Xmm u8) Gpr)\n(rule (x64_pextrq src lane)\n      (xmm_to_gpr_imm (SseOpcode.Pextrq) src lane))\n\n;; Helper for creating `MInst.XmmToGpr` instructions.\n(decl xmm_to_gpr (SseOpcode Xmm OperandSize) Gpr)\n(rule (xmm_to_gpr op src size)\n      (let ((dst WritableGpr (temp_writable_gpr))\n            (_ Unit (emit (MInst.XmmToGpr op src dst size))))\n        dst))\n\n;; Helper for creating `MInst.XmmToGpr` instructions.\n(decl xmm_to_gpr_imm (SseOpcode Xmm u8) Gpr)\n(rule (xmm_to_gpr_imm op src imm)\n      (let ((dst WritableGpr (temp_writable_gpr))\n            (_ Unit (emit (MInst.XmmToGprImm op src dst imm))))\n        dst))\n\n;; Helper for creating `pmovmskb` instructions.\n(decl x64_pmovmskb (OperandSize Xmm) Gpr)\n(rule (x64_pmovmskb size src)\n      (xmm_to_gpr (SseOpcode.Pmovmskb) src size))\n\n;; Helper for creating `movmskps` instructions.\n(decl x64_movmskps (OperandSize Xmm) Gpr)\n(rule (x64_movmskps size src)\n      (xmm_to_gpr (SseOpcode.Movmskps) src size))\n\n;; Helper for creating `movmskpd` instructions.\n(decl x64_movmskpd (OperandSize Xmm) Gpr)\n(rule (x64_movmskpd size src)\n      (xmm_to_gpr (SseOpcode.Movmskpd) src size))\n\n;; Helper for creating `MInst.GprToXmm` instructions.\n(decl gpr_to_xmm (SseOpcode GprMem OperandSize) Xmm)\n(rule (gpr_to_xmm op src size)\n      (let ((dst WritableXmm (temp_writable_xmm))\n            (_ Unit (emit (MInst.GprToXmm op src dst size))))\n        dst))\n\n;; Helper for creating `not` instructions.\n(decl x64_not (Type Gpr) Gpr)\n(rule (x64_not ty src)\n      (let ((dst WritableGpr (temp_writable_gpr))\n            (size OperandSize (operand_size_of_type_32_64 ty))\n            (_ Unit (emit (MInst.Not size src dst))))\n        dst))\n\n;; Helper for creating `neg` instructions.\n(decl x64_neg (Type Gpr) Gpr)\n(rule (x64_neg ty src)\n      (let ((dst WritableGpr (temp_writable_gpr))\n            (size OperandSize (raw_operand_size_of_type ty))\n            (_ Unit (emit (MInst.Neg size src dst))))\n        dst))\n\n;; Helper for creating `neg` instructions whose flags are also used.\n(decl x64_neg_paired (Type Gpr) ProducesFlags)\n(rule (x64_neg_paired ty src)\n      (let ((dst WritableGpr (temp_writable_gpr))\n            (size OperandSize (raw_operand_size_of_type ty))\n            (inst MInst (MInst.Neg size src dst)))\n        (ProducesFlags.ProducesFlagsReturnsResultWithConsumer inst dst)))\n\n(decl x64_lea (SyntheticAmode) Gpr)\n(rule (x64_lea addr)\n      (let ((dst WritableGpr (temp_writable_gpr))\n            (_ Unit (emit (MInst.LoadEffectiveAddress addr dst))))\n        dst))\n\n;; Helper for creating `ud2` instructions.\n(decl x64_ud2 (TrapCode) SideEffectNoResult)\n(rule (x64_ud2 code)\n      (SideEffectNoResult.Inst (MInst.Ud2 code)))\n\n;; Helper for creating `hlt` instructions.\n(decl x64_hlt () SideEffectNoResult)\n(rule (x64_hlt)\n      (SideEffectNoResult.Inst (MInst.Hlt)))\n\n;; Helper for creating `lzcnt` instructions.\n(decl x64_lzcnt (Type Gpr) Gpr)\n(rule (x64_lzcnt ty src)\n      (let ((dst WritableGpr (temp_writable_gpr))\n            (size OperandSize (operand_size_of_type_32_64 ty))\n            (_ Unit (emit (MInst.UnaryRmR size (UnaryRmROpcode.Lzcnt) src dst))))\n        dst))\n\n;; Helper for creating `tzcnt` instructions.\n(decl x64_tzcnt (Type Gpr) Gpr)\n(rule (x64_tzcnt ty src)\n      (let ((dst WritableGpr (temp_writable_gpr))\n            (size OperandSize (operand_size_of_type_32_64 ty))\n            (_ Unit (emit (MInst.UnaryRmR size (UnaryRmROpcode.Tzcnt) src dst))))\n        dst))\n\n;; Helper for creating `bsr` instructions.\n(decl x64_bsr (Type Gpr) ProducesFlags)\n(rule (x64_bsr ty src)\n      (let ((dst WritableGpr (temp_writable_gpr))\n            (size OperandSize (operand_size_of_type_32_64 ty))\n            (inst MInst (MInst.UnaryRmR size (UnaryRmROpcode.Bsr) src dst)))\n        (ProducesFlags.ProducesFlagsReturnsReg inst dst)))\n\n;; Helper for creating `bsr + cmov` instruction pairs that produce the\n;; result of the `bsr`, or `alt` if the input was zero.\n(decl bsr_or_else (Type Gpr Gpr) Gpr)\n(rule (bsr_or_else ty src alt)\n      (let ((bsr ProducesFlags (x64_bsr ty src))\n            ;; Manually extract the result from the bsr, then ignore\n            ;; it below, since we need to thread it into the cmove\n            ;; before we pass the cmove to with_flags_reg.\n            (bsr_result Gpr (produces_flags_get_reg bsr))\n            (cmove ConsumesFlags (cmove ty (CC.Z) alt bsr_result)))\n        (with_flags_reg (produces_flags_ignore bsr) cmove)))\n\n;; Helper for creating `bsf` instructions.\n(decl x64_bsf (Type Gpr) ProducesFlags)\n(rule (x64_bsf ty src)\n      (let ((dst WritableGpr (temp_writable_gpr))\n            (size OperandSize (operand_size_of_type_32_64 ty))\n            (inst MInst (MInst.UnaryRmR size (UnaryRmROpcode.Bsf) src dst)))\n        (ProducesFlags.ProducesFlagsReturnsReg inst dst)))\n\n;; Helper for creating `bsf + cmov` instruction pairs that produce the\n;; result of the `bsf`, or `alt` if the input was zero.\n(decl bsf_or_else (Type Gpr Gpr) Gpr)\n(rule (bsf_or_else ty src alt)\n      (let ((bsf ProducesFlags (x64_bsf ty src))\n            ;; Manually extract the result from the bsf, then ignore\n            ;; it below, since we need to thread it into the cmove\n            ;; before we pass the cmove to with_flags_reg.\n            (bsf_result Gpr (produces_flags_get_reg bsf))\n            (cmove ConsumesFlags (cmove ty (CC.Z) alt bsf_result)))\n        (with_flags_reg (produces_flags_ignore bsf) cmove)))\n\n;; Helper for creating `popcnt` instructions.\n(decl x64_popcnt (Type Gpr) Gpr)\n(rule (x64_popcnt ty src)\n      (let ((dst WritableGpr (temp_writable_gpr))\n            (size OperandSize (operand_size_of_type_32_64 ty))\n            (_ Unit (emit (MInst.UnaryRmR size (UnaryRmROpcode.Popcnt) src dst))))\n        dst))\n\n;; Helper for creating `xmm_min_max_seq` psuedo-instructions.\n(decl xmm_min_max_seq (Type bool Xmm Xmm) Xmm)\n(rule (xmm_min_max_seq ty is_min lhs rhs)\n      (let ((dst WritableXmm (temp_writable_xmm))\n            (size OperandSize (operand_size_of_type_32_64 ty))\n            (_ Unit (emit (MInst.XmmMinMaxSeq size is_min lhs rhs dst))))\n        dst))\n\n;; Helper for creating `minss` instructions.\n(decl x64_minss (Xmm XmmMem) Xmm)\n(rule (x64_minss x y)\n      (xmm_rm_r_unaligned (SseOpcode.Minss) x y))\n(rule 1 (x64_minss x y)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vminss) x y))\n\n;; Helper for creating `minsd` instructions.\n(decl x64_minsd (Xmm XmmMem) Xmm)\n(rule (x64_minsd x y)\n      (xmm_rm_r_unaligned (SseOpcode.Minsd) x y))\n(rule 1 (x64_minsd x y)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vminsd) x y))\n\n;; Helper for creating `minps` instructions.\n(decl x64_minps (Xmm XmmMem) Xmm)\n(rule 0 (x64_minps x y)\n      (xmm_rm_r (SseOpcode.Minps) x y))\n(rule 1 (x64_minps x y)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vminps) x y))\n\n;; Helper for creating `minpd` instructions.\n(decl x64_minpd (Xmm XmmMem) Xmm)\n(rule 0 (x64_minpd x y)\n      (xmm_rm_r (SseOpcode.Minpd) x y))\n(rule 1 (x64_minpd x y)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vminpd) x y))\n\n;; Helper for creating `maxss` instructions.\n(decl x64_maxss (Xmm XmmMem) Xmm)\n(rule (x64_maxss x y)\n      (xmm_rm_r_unaligned (SseOpcode.Maxss) x y))\n(rule 1 (x64_maxss x y)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vmaxss) x y))\n\n;; Helper for creating `maxsd` instructions.\n(decl x64_maxsd (Xmm XmmMem) Xmm)\n(rule (x64_maxsd x y)\n      (xmm_rm_r_unaligned (SseOpcode.Maxsd) x y))\n(rule 1 (x64_maxsd x y)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vmaxsd) x y))\n\n;; Helper for creating `maxps` instructions.\n(decl x64_maxps (Xmm XmmMem) Xmm)\n(rule 0 (x64_maxps x y)\n      (xmm_rm_r (SseOpcode.Maxps) x y))\n(rule 1 (x64_maxps x y)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vmaxps) x y))\n\n;; Helper for creating `maxpd` instructions.\n(decl x64_maxpd (Xmm XmmMem) Xmm)\n(rule 0 (x64_maxpd x y)\n      (xmm_rm_r (SseOpcode.Maxpd) x y))\n(rule 1 (x64_maxpd x y)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vmaxpd) x y))\n\n\n;; Helper for creating `MInst.XmmRmiRVex` instructions.\n(decl xmm_rmir_vex (AvxOpcode Xmm XmmMemImm) Xmm)\n(rule (xmm_rmir_vex op src1 src2)\n      (let ((dst WritableXmm (temp_writable_xmm))\n            (_ Unit (emit (MInst.XmmRmiRVex op src1 src2 dst))))\n        dst))\n\n;; Helper for creating `MInst.XmmRmRImmVex` instructions.\n(decl xmm_rmr_imm_vex (AvxOpcode Xmm XmmMem u8) Xmm)\n(rule (xmm_rmr_imm_vex op src1 src2 imm)\n      (let ((dst WritableXmm (temp_writable_xmm))\n            (_ Unit (emit (MInst.XmmRmRImmVex op src1 src2 dst imm))))\n        dst))\n\n;; Helper for creating `MInst.XmmRmRVex3` instructions.\n(decl xmm_rmr_vex3 (AvxOpcode Xmm Xmm XmmMem) Xmm)\n(rule (xmm_rmr_vex3 op src1 src2 src3)\n      (let ((dst WritableXmm (temp_writable_xmm))\n            (_ Unit (emit (MInst.XmmRmRVex3 op src1 src2 src3 dst))))\n        dst))\n\n;; Helper for creating `vfmadd213*` instructions\n(decl x64_vfmadd213 (Type Xmm Xmm XmmMem) Xmm)\n(rule (x64_vfmadd213 $F32 a b c) (xmm_rmr_vex3 (AvxOpcode.Vfmadd213ss) a b c))\n(rule (x64_vfmadd213 $F64 a b c) (xmm_rmr_vex3 (AvxOpcode.Vfmadd213sd) a b c))\n(rule (x64_vfmadd213 $F32X4 a b c) (xmm_rmr_vex3 (AvxOpcode.Vfmadd213ps) a b c))\n(rule (x64_vfmadd213 $F64X2 a b c) (xmm_rmr_vex3 (AvxOpcode.Vfmadd213pd) a b c))\n\n;; Helper for creating `vfmadd132*` instructions\n(decl x64_vfmadd132 (Type Xmm Xmm XmmMem) Xmm)\n(rule (x64_vfmadd132 $F32 a b c) (xmm_rmr_vex3 (AvxOpcode.Vfmadd132ss) a b c))\n(rule (x64_vfmadd132 $F64 a b c) (xmm_rmr_vex3 (AvxOpcode.Vfmadd132sd) a b c))\n(rule (x64_vfmadd132 $F32X4 a b c) (xmm_rmr_vex3 (AvxOpcode.Vfmadd132ps) a b c))\n(rule (x64_vfmadd132 $F64X2 a b c) (xmm_rmr_vex3 (AvxOpcode.Vfmadd132pd) a b c))\n\n;; Helper for creating `vfnmadd213*` instructions\n(decl x64_vfnmadd213 (Type Xmm Xmm XmmMem) Xmm)\n(rule (x64_vfnmadd213 $F32 a b c) (xmm_rmr_vex3 (AvxOpcode.Vfnmadd213ss) a b c))\n(rule (x64_vfnmadd213 $F64 a b c) (xmm_rmr_vex3 (AvxOpcode.Vfnmadd213sd) a b c))\n(rule (x64_vfnmadd213 $F32X4 a b c) (xmm_rmr_vex3 (AvxOpcode.Vfnmadd213ps) a b c))\n(rule (x64_vfnmadd213 $F64X2 a b c) (xmm_rmr_vex3 (AvxOpcode.Vfnmadd213pd) a b c))\n\n;; Helper for creating `vfnmadd132*` instructions\n(decl x64_vfnmadd132 (Type Xmm Xmm XmmMem) Xmm)\n(rule (x64_vfnmadd132 $F32 a b c) (xmm_rmr_vex3 (AvxOpcode.Vfnmadd132ss) a b c))\n(rule (x64_vfnmadd132 $F64 a b c) (xmm_rmr_vex3 (AvxOpcode.Vfnmadd132sd) a b c))\n(rule (x64_vfnmadd132 $F32X4 a b c) (xmm_rmr_vex3 (AvxOpcode.Vfnmadd132ps) a b c))\n(rule (x64_vfnmadd132 $F64X2 a b c) (xmm_rmr_vex3 (AvxOpcode.Vfnmadd132pd) a b c))\n\n;; Helper for creating `sqrtss` instructions.\n(decl x64_sqrtss (XmmMem) Xmm)\n(rule (x64_sqrtss x) (xmm_unary_rm_r_unaligned (SseOpcode.Sqrtss) x))\n\n;; Helper for creating `sqrtsd` instructions.\n(decl x64_sqrtsd (XmmMem) Xmm)\n(rule (x64_sqrtsd x) (xmm_unary_rm_r_unaligned (SseOpcode.Sqrtsd) x))\n\n;; Helper for creating `sqrtps` instructions.\n(decl x64_sqrtps (XmmMem) Xmm)\n(rule (x64_sqrtps x) (xmm_unary_rm_r (SseOpcode.Sqrtps) x))\n(rule 1 (x64_sqrtps x)\n        (if-let $true (has_avx))\n        (xmm_unary_rm_r_vex (AvxOpcode.Vsqrtps) x))\n\n;; Helper for creating `sqrtpd` instructions.\n(decl x64_sqrtpd (XmmMem) Xmm)\n(rule (x64_sqrtpd x) (xmm_unary_rm_r (SseOpcode.Sqrtpd) x))\n(rule 1 (x64_sqrtpd x)\n        (if-let $true (has_avx))\n        (xmm_unary_rm_r_vex (AvxOpcode.Vsqrtpd) x))\n\n;; Helper for creating `cvtss2sd` instructions.\n(decl x64_cvtss2sd (Xmm) Xmm)\n(rule (x64_cvtss2sd x) (xmm_unary_rm_r (SseOpcode.Cvtss2sd) x))\n\n;; Helper for creating `cvtsd2ss` instructions.\n(decl x64_cvtsd2ss (Xmm) Xmm)\n(rule (x64_cvtsd2ss x) (xmm_unary_rm_r (SseOpcode.Cvtsd2ss) x))\n\n;; Helper for creating `cvtdq2ps` instructions.\n(decl x64_cvtdq2ps (XmmMem) Xmm)\n(rule (x64_cvtdq2ps x) (xmm_unary_rm_r (SseOpcode.Cvtdq2ps) x))\n(rule 1 (x64_cvtdq2ps x)\n        (if-let $true (has_avx))\n        (xmm_unary_rm_r_vex (AvxOpcode.Vcvtdq2ps) x))\n\n;; Helper for creating `cvtps2pd` instructions.\n(decl x64_cvtps2pd (XmmMem) Xmm)\n(rule (x64_cvtps2pd x) (xmm_unary_rm_r (SseOpcode.Cvtps2pd) x))\n(rule 1 (x64_cvtps2pd x)\n        (if-let $true (has_avx))\n        (xmm_unary_rm_r_vex (AvxOpcode.Vcvtps2pd) x))\n\n;; Helper for creating `cvtpd2ps` instructions.\n(decl x64_cvtpd2ps (XmmMem) Xmm)\n(rule (x64_cvtpd2ps x) (xmm_unary_rm_r (SseOpcode.Cvtpd2ps) x))\n(rule 1 (x64_cvtpd2ps x)\n        (if-let $true (has_avx))\n        (xmm_unary_rm_r_vex (AvxOpcode.Vcvtpd2ps) x))\n\n;; Helper for creating `cvtdq2pd` instructions.\n(decl x64_cvtdq2pd (XmmMem) Xmm)\n(rule (x64_cvtdq2pd x) (xmm_unary_rm_r (SseOpcode.Cvtdq2pd) x))\n(rule 1 (x64_cvtdq2pd x)\n        (if-let $true (has_avx))\n        (xmm_unary_rm_r_vex (AvxOpcode.Vcvtdq2pd) x))\n\n;; Helper for creating `cvtsi2ss` instructions.\n(decl x64_cvtsi2ss (Type GprMem) Xmm)\n(rule (x64_cvtsi2ss ty x)\n      (gpr_to_xmm (SseOpcode.Cvtsi2ss) x (raw_operand_size_of_type ty)))\n\n;; Helper for creating `cvtsi2sd` instructions.\n(decl x64_cvtsi2sd (Type GprMem) Xmm)\n(rule (x64_cvtsi2sd ty x)\n      (gpr_to_xmm (SseOpcode.Cvtsi2sd) x (raw_operand_size_of_type ty)))\n\n;; Helper for creating `cvttps2dq` instructions.\n(decl x64_cvttps2dq (XmmMem) Xmm)\n(rule (x64_cvttps2dq x)\n      (xmm_unary_rm_r (SseOpcode.Cvttps2dq) x))\n(rule 1 (x64_cvttps2dq x)\n        (if-let $true (has_avx))\n        (xmm_unary_rm_r_vex (AvxOpcode.Vcvttps2dq) x))\n\n;; Helper for creating `cvttpd2dq` instructions.\n(decl x64_cvttpd2dq (XmmMem) Xmm)\n(rule (x64_cvttpd2dq x)\n      (xmm_unary_rm_r (SseOpcode.Cvttpd2dq) x))\n(rule 1 (x64_cvttpd2dq x)\n        (if-let $true (has_avx))\n        (xmm_unary_rm_r_vex (AvxOpcode.Vcvttpd2dq) x))\n\n(decl cvt_u64_to_float_seq (Type Gpr) Xmm)\n(rule (cvt_u64_to_float_seq ty src)\n      (let ((size OperandSize (raw_operand_size_of_type ty))\n            (dst WritableXmm (temp_writable_xmm))\n            (tmp_gpr1 WritableGpr (temp_writable_gpr))\n            (tmp_gpr2 WritableGpr (temp_writable_gpr))\n            (_ Unit (emit (MInst.CvtUint64ToFloatSeq size src dst tmp_gpr1 tmp_gpr2))))\n        dst))\n\n(decl cvt_float_to_uint_seq (Type Value bool) Gpr)\n(rule (cvt_float_to_uint_seq out_ty src @ (value_type src_ty) is_saturating)\n      (let ((out_size OperandSize (raw_operand_size_of_type out_ty))\n            (src_size OperandSize (raw_operand_size_of_type src_ty))\n\n            (dst WritableGpr (temp_writable_gpr))\n            (tmp_xmm WritableXmm (temp_writable_xmm))\n            (tmp_xmm2 WritableXmm (temp_writable_xmm))\n            (tmp_gpr WritableGpr (temp_writable_gpr))\n            (_ Unit (emit (MInst.CvtFloatToUintSeq out_size src_size is_saturating src dst tmp_gpr tmp_xmm tmp_xmm2))))\n        dst))\n\n(decl cvt_float_to_sint_seq (Type Value bool) Gpr)\n(rule (cvt_float_to_sint_seq out_ty src @ (value_type src_ty) is_saturating)\n      (let ((out_size OperandSize (raw_operand_size_of_type out_ty))\n            (src_size OperandSize (raw_operand_size_of_type src_ty))\n\n            (dst WritableGpr (temp_writable_gpr))\n            (tmp_xmm WritableXmm (temp_writable_xmm))\n            (tmp_gpr WritableGpr (temp_writable_gpr))\n            (_ Unit (emit (MInst.CvtFloatToSintSeq out_size src_size is_saturating src dst tmp_gpr tmp_xmm))))\n        dst))\n\n(decl fcvt_uint_mask_const () VCodeConstant)\n(extern constructor fcvt_uint_mask_const fcvt_uint_mask_const)\n\n(decl fcvt_uint_mask_high_const () VCodeConstant)\n(extern constructor fcvt_uint_mask_high_const fcvt_uint_mask_high_const)\n\n;; Helpers for creating `pcmpeq*` instructions.\n(decl x64_pcmpeq (Type Xmm XmmMem) Xmm)\n(rule (x64_pcmpeq $I8X16 x y) (x64_pcmpeqb x y))\n(rule (x64_pcmpeq $I16X8 x y) (x64_pcmpeqw x y))\n(rule (x64_pcmpeq $I32X4 x y) (x64_pcmpeqd x y))\n(rule (x64_pcmpeq $I64X2 x y) (x64_pcmpeqq x y))\n\n(decl x64_pcmpeqb (Xmm XmmMem) Xmm)\n(rule 0 (x64_pcmpeqb x y) (xmm_rm_r (SseOpcode.Pcmpeqb) x y))\n(rule 1 (x64_pcmpeqb x y)\n        (if-let $true (has_avx))\n        (xmm_rmir_vex (AvxOpcode.Vpcmpeqb) x y))\n(decl x64_pcmpeqw (Xmm XmmMem) Xmm)\n(rule 0 (x64_pcmpeqw x y) (xmm_rm_r (SseOpcode.Pcmpeqw) x y))\n(rule 1 (x64_pcmpeqw x y)\n        (if-let $true (has_avx))\n        (xmm_rmir_vex (AvxOpcode.Vpcmpeqw) x y))\n(decl x64_pcmpeqd (Xmm XmmMem) Xmm)\n(rule 0 (x64_pcmpeqd x y) (xmm_rm_r (SseOpcode.Pcmpeqd) x y))\n(rule 1 (x64_pcmpeqd x y)\n        (if-let $true (has_avx))\n        (xmm_rmir_vex (AvxOpcode.Vpcmpeqd) x y))\n(decl x64_pcmpeqq (Xmm XmmMem) Xmm)\n(rule 0 (x64_pcmpeqq x y) (xmm_rm_r (SseOpcode.Pcmpeqq) x y))\n(rule 1 (x64_pcmpeqq x y)\n        (if-let $true (has_avx))\n        (xmm_rmir_vex (AvxOpcode.Vpcmpeqq) x y))\n\n;; Helpers for creating `pcmpgt*` instructions.\n(decl x64_pcmpgt (Type Xmm XmmMem) Xmm)\n(rule (x64_pcmpgt $I8X16 x y) (x64_pcmpgtb x y))\n(rule (x64_pcmpgt $I16X8 x y) (x64_pcmpgtw x y))\n(rule (x64_pcmpgt $I32X4 x y) (x64_pcmpgtd x y))\n(rule (x64_pcmpgt $I64X2 x y) (x64_pcmpgtq x y))\n\n(decl x64_pcmpgtb (Xmm XmmMem) Xmm)\n(rule 0 (x64_pcmpgtb x y) (xmm_rm_r (SseOpcode.Pcmpgtb) x y))\n(rule 1 (x64_pcmpgtb x y)\n        (if-let $true (has_avx))\n        (xmm_rmir_vex (AvxOpcode.Vpcmpgtb) x y))\n(decl x64_pcmpgtw (Xmm XmmMem) Xmm)\n(rule 0 (x64_pcmpgtw x y) (xmm_rm_r (SseOpcode.Pcmpgtw) x y))\n(rule 1 (x64_pcmpgtw x y)\n        (if-let $true (has_avx))\n        (xmm_rmir_vex (AvxOpcode.Vpcmpgtw) x y))\n(decl x64_pcmpgtd (Xmm XmmMem) Xmm)\n(rule 0 (x64_pcmpgtd x y) (xmm_rm_r (SseOpcode.Pcmpgtd) x y))\n(rule 1 (x64_pcmpgtd x y)\n        (if-let $true (has_avx))\n        (xmm_rmir_vex (AvxOpcode.Vpcmpgtd) x y))\n(decl x64_pcmpgtq (Xmm XmmMem) Xmm)\n(rule 0 (x64_pcmpgtq x y) (xmm_rm_r (SseOpcode.Pcmpgtq) x y))\n(rule 1 (x64_pcmpgtq x y)\n        (if-let $true (has_avx))\n        (xmm_rmir_vex (AvxOpcode.Vpcmpgtq) x y))\n\n;; Helpers for read-modify-write ALU form (AluRM).\n(decl alu_rm (Type AluRmiROpcode Amode Gpr) SideEffectNoResult)\n(rule (alu_rm ty opcode src1_dst src2)\n      (let ((size OperandSize (operand_size_of_type_32_64 ty)))\n        (SideEffectNoResult.Inst (MInst.AluRM size opcode src1_dst src2))))\n\n(decl x64_add_mem (Type Amode Gpr) SideEffectNoResult)\n(rule (x64_add_mem ty addr val)\n      (alu_rm ty (AluRmiROpcode.Add) addr val))\n\n(decl x64_sub_mem (Type Amode Gpr) SideEffectNoResult)\n(rule (x64_sub_mem ty addr val)\n      (alu_rm ty (AluRmiROpcode.Sub) addr val))\n\n(decl x64_and_mem (Type Amode Gpr) SideEffectNoResult)\n(rule (x64_and_mem ty addr val)\n      (alu_rm ty (AluRmiROpcode.And) addr val))\n\n(decl x64_or_mem (Type Amode Gpr) SideEffectNoResult)\n(rule (x64_or_mem ty addr val)\n      (alu_rm ty (AluRmiROpcode.Or) addr val))\n\n(decl x64_xor_mem (Type Amode Gpr) SideEffectNoResult)\n(rule (x64_xor_mem ty addr val)\n      (alu_rm ty (AluRmiROpcode.Xor) addr val))\n\n;; Trap if the condition code supplied is set.\n(decl trap_if (CC TrapCode) ConsumesFlags)\n(rule (trap_if cc tc)\n      (ConsumesFlags.ConsumesFlagsSideEffect (MInst.TrapIf cc tc)))\n\n;; Trap if both of the condition codes supplied are set.\n(decl trap_if_and (CC CC TrapCode) ConsumesFlags)\n(rule (trap_if_and cc1 cc2 tc)\n      (ConsumesFlags.ConsumesFlagsSideEffect (MInst.TrapIfAnd cc1 cc2 tc)))\n\n;; Trap if either of the condition codes supplied are set.\n(decl trap_if_or (CC CC TrapCode) ConsumesFlags)\n(rule (trap_if_or cc1 cc2 tc)\n      (ConsumesFlags.ConsumesFlagsSideEffect (MInst.TrapIfOr cc1 cc2 tc)))\n\n(decl trap_if_icmp (IcmpCondResult TrapCode) SideEffectNoResult)\n(rule (trap_if_icmp (IcmpCondResult.Condition producer cc) tc)\n      (with_flags_side_effect producer (trap_if cc tc)))\n\n(decl trap_if_fcmp (FcmpCondResult TrapCode) SideEffectNoResult)\n(rule (trap_if_fcmp (FcmpCondResult.Condition producer cc) tc)\n      (with_flags_side_effect producer (trap_if cc tc)))\n(rule (trap_if_fcmp (FcmpCondResult.AndCondition producer cc1 cc2) tc)\n      (with_flags_side_effect producer (trap_if_and cc1 cc2 tc)))\n(rule (trap_if_fcmp (FcmpCondResult.OrCondition producer cc1 cc2) tc)\n      (with_flags_side_effect producer (trap_if_or cc1 cc2 tc)))\n\n;;;; Jumps ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n\n;; Unconditional jump.\n(decl jmp_known (MachLabel) SideEffectNoResult)\n(rule (jmp_known target)\n      (SideEffectNoResult.Inst (MInst.JmpKnown target)))\n\n(decl jmp_if (CC MachLabel) ConsumesFlags)\n(rule (jmp_if cc taken)\n      (ConsumesFlags.ConsumesFlagsSideEffect (MInst.JmpIf cc taken)))\n\n;; Conditional jump based on the condition code.\n(decl jmp_cond (CC MachLabel MachLabel) ConsumesFlags)\n(rule (jmp_cond cc taken not_taken)\n      (ConsumesFlags.ConsumesFlagsSideEffect (MInst.JmpCond cc taken not_taken)))\n\n;; Conditional jump based on the result of an icmp.\n(decl jmp_cond_icmp (IcmpCondResult MachLabel MachLabel) SideEffectNoResult)\n(rule (jmp_cond_icmp (IcmpCondResult.Condition producer cc) taken not_taken)\n      (with_flags_side_effect producer (jmp_cond cc taken not_taken)))\n\n;; Conditional jump based on the result of an fcmp.\n(decl jmp_cond_fcmp (FcmpCondResult MachLabel MachLabel) SideEffectNoResult)\n(rule (jmp_cond_fcmp (FcmpCondResult.Condition producer cc) taken not_taken)\n      (with_flags_side_effect producer (jmp_cond cc taken not_taken)))\n(rule (jmp_cond_fcmp (FcmpCondResult.AndCondition producer cc1 cc2) taken not_taken)\n      (with_flags_side_effect producer\n                              (consumes_flags_concat\n                                (jmp_if (cc_invert cc1) not_taken)\n                                (jmp_cond (cc_invert cc2) not_taken taken))))\n(rule (jmp_cond_fcmp (FcmpCondResult.OrCondition producer cc1 cc2) taken not_taken)\n      (with_flags_side_effect producer\n                              (consumes_flags_concat\n                                (jmp_if cc1 taken)\n                                (jmp_cond cc2 taken not_taken))))\n\n;; Emit the compound instruction that does:\n;;\n;; lea $jt, %rA\n;; movsbl [%rA, %rIndex, 2], %rB\n;; add %rB, %rA\n;; j *%rA\n;; [jt entries]\n;;\n;; This must be *one* instruction in the vcode because we cannot allow regalloc\n;; to insert any spills/fills in the middle of the sequence; otherwise, the\n;; lea PC-rel offset to the jumptable would be incorrect.  (The alternative\n;; is to introduce a relocation pass for inlined jumptables, which is much\n;; worse.)\n(decl jmp_table_seq (Type Gpr MachLabel BoxVecMachLabel) SideEffectNoResult)\n(rule (jmp_table_seq ty idx default_target jt_targets)\n      (let (;; This temporary is used as a signed integer of 64-bits (to hold\n            ;; addresses).\n            (tmp1 WritableGpr (temp_writable_gpr))\n\n            ;; This temporary is used as a signed integer of 32-bits (for the\n            ;; wasm-table index) and then 64-bits (address addend). The small\n            ;; lie about the I64 type is benign, since the temporary is dead\n            ;; after this instruction (and its Cranelift type is thus unused).\n            (tmp2 WritableGpr (temp_writable_gpr)))\n\n          (SideEffectNoResult.Inst\n            (MInst.JmpTableSeq idx tmp1 tmp2 default_target jt_targets))))\n\n;;;; iadd_pairwise constants ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n\n(decl iadd_pairwise_mul_const_16 () VCodeConstant)\n(extern constructor iadd_pairwise_mul_const_16 iadd_pairwise_mul_const_16)\n\n(decl iadd_pairwise_mul_const_32 () VCodeConstant)\n(extern constructor iadd_pairwise_mul_const_32 iadd_pairwise_mul_const_32)\n\n(decl iadd_pairwise_xor_const_32 () VCodeConstant)\n(extern constructor iadd_pairwise_xor_const_32 iadd_pairwise_xor_const_32)\n\n(decl iadd_pairwise_addd_const_32 () VCodeConstant)\n(extern constructor iadd_pairwise_addd_const_32 iadd_pairwise_addd_const_32)\n\n;;;; snarrow constants ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n\n(decl snarrow_umax_mask () VCodeConstant)\n(extern constructor snarrow_umax_mask snarrow_umax_mask)\n\n;;;; Comparisons ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n\n(type IcmpCondResult (enum (Condition (producer ProducesFlags) (cc CC))))\n\n(decl icmp_cond_result (ProducesFlags CC) IcmpCondResult)\n(rule (icmp_cond_result producer cc) (IcmpCondResult.Condition producer cc))\n\n(decl invert_icmp_cond_result (IcmpCondResult) IcmpCondResult)\n(rule (invert_icmp_cond_result (IcmpCondResult.Condition producer cc))\n      (icmp_cond_result producer (cc_invert cc)))\n\n;; Lower an Icmp result into a boolean value in a register.\n(decl lower_icmp_bool (IcmpCondResult) ValueRegs)\n(rule (lower_icmp_bool (IcmpCondResult.Condition producer cc))\n      (with_flags producer (x64_setcc cc)))\n\n;; Emit a conditional move based on the result of an icmp.\n(decl select_icmp (IcmpCondResult Value Value) ValueRegs)\n\n;; Ensure that we put the `x` argument into a register for single-register\n;; gpr-typed arguments, as we rely on this for the legalization of heap_addr and\n;; loading easily computed constants (like 0) from memory is too expensive.\n(rule 1 (select_icmp (IcmpCondResult.Condition producer cc) x @ (value_type (is_single_register_gpr_type ty)) y)\n      (with_flags producer (cmove ty cc (put_in_gpr x) y)))\n\n;; Otherwise, fall back on the behavior of `cmove_from_values`.\n(rule 0 (select_icmp (IcmpCondResult.Condition producer cc) x @ (value_type ty) y)\n      (with_flags producer (cmove_from_values ty cc x y)))\n\n(decl emit_cmp (IntCC Value Value) IcmpCondResult)\n\n;; For GPR-held values we only need to emit `CMP + SETCC`. We rely here on\n;; Cranelift's verification that `a` and `b` are of the same type.\n;; Unfortunately for clarity, the registers are flipped here (TODO).\n(rule 0 (emit_cmp cc a @ (value_type ty) b)\n      (let ((size OperandSize (raw_operand_size_of_type ty)))\n        (icmp_cond_result (x64_cmp size b a) cc)))\n\n;; As a special case, reverse the arguments to the comparison when the LHS is a\n;; constant. This ensures that we avoid moving the constant into a register when\n;; performing the comparison.\n(rule 1 (emit_cmp cc (and (simm32_from_value a) (value_type ty)) b)\n      (let ((size OperandSize (raw_operand_size_of_type ty)))\n        (icmp_cond_result (x64_cmp size a b) (intcc_reverse cc))))\n\n;; For I128 values (held in two GPRs), the instruction sequences depend on what\n;; kind of condition is tested.\n(rule 3 (emit_cmp (IntCC.Equal) a @ (value_type $I128) b)\n      (let ((a_lo Gpr (value_regs_get_gpr a 0))\n            (a_hi Gpr (value_regs_get_gpr a 1))\n            (b_lo Gpr (value_regs_get_gpr b 0))\n            (b_hi Gpr (value_regs_get_gpr b 1))\n            (cmp_lo Reg (with_flags_reg (x64_cmp (OperandSize.Size64) b_lo a_lo) (x64_setcc (CC.Z))))\n            (cmp_hi Reg (with_flags_reg (x64_cmp (OperandSize.Size64) b_hi a_hi) (x64_setcc (CC.Z))))\n            ;; At this point, `cmp_lo` and `cmp_hi` contain either 0 or 1 in the\n            ;; lowest 8 bits--`SETcc` guarantees this. The upper bits may be\n            ;; unchanged so we must compare against 1 below; this instruction\n            ;; combines `cmp_lo` and `cmp_hi` for that final comparison.\n            (cmp Reg (x64_and $I64 cmp_lo cmp_hi)))\n        ;; We must compare one more time against the immediate value 1 to\n        ;; check if both `cmp_lo` and `cmp_hi` are true. If `cmp AND 1 == 0`\n        ;; then the `ZF` will be set (see `TEST` definition); if either of\n        ;; the halves `AND`s to 0, they were not equal, therefore we `SETcc`\n        ;; with `NZ`.\n        (icmp_cond_result\n          (x64_test (OperandSize.Size64) (RegMemImm.Imm 1) cmp)\n          (CC.NZ))))\n\n(rule 3 (emit_cmp (IntCC.NotEqual) a @ (value_type $I128) b)\n      (let ((a_lo Gpr (value_regs_get_gpr a 0))\n            (a_hi Gpr (value_regs_get_gpr a 1))\n            (b_lo Gpr (value_regs_get_gpr b 0))\n            (b_hi Gpr (value_regs_get_gpr b 1))\n            (cmp_lo Reg (with_flags_reg (x64_cmp (OperandSize.Size64) b_lo a_lo) (x64_setcc (CC.NZ))))\n            (cmp_hi Reg (with_flags_reg (x64_cmp (OperandSize.Size64) b_hi a_hi) (x64_setcc (CC.NZ))))\n            ;; See comments for `IntCC.Equal`.\n            (cmp Reg (x64_or $I64 cmp_lo cmp_hi)))\n           (icmp_cond_result\n             (x64_test (OperandSize.Size64) (RegMemImm.Imm 1) cmp)\n             (CC.NZ))))\n\n;; Result = (a_hi <> b_hi) ||\n;;          (a_hi == b_hi && a_lo <> b_lo)\n(rule 2 (emit_cmp cc a @ (value_type $I128) b)\n      (let ((a_lo Gpr (value_regs_get_gpr a 0))\n            (a_hi Gpr (value_regs_get_gpr a 1))\n            (b_lo Gpr (value_regs_get_gpr b 0))\n            (b_hi Gpr (value_regs_get_gpr b 1))\n            (cmp_hi ValueRegs (with_flags (x64_cmp (OperandSize.Size64) b_hi a_hi)\n                                       (consumes_flags_concat\n                                                 (x64_setcc (intcc_without_eq cc))\n                                                 (x64_setcc (CC.Z)))))\n            (cc_hi Reg (value_regs_get cmp_hi 0))\n            (eq_hi Reg (value_regs_get cmp_hi 1))\n\n            (cmp_lo Reg (with_flags_reg (x64_cmp (OperandSize.Size64) b_lo a_lo)\n                                        (x64_setcc (intcc_unsigned cc))))\n\n            (res_lo Reg (x64_and $I64 eq_hi cmp_lo))\n            (res Reg (x64_or $I64 cc_hi res_lo)))\n        (icmp_cond_result\n          (x64_test (OperandSize.Size64) (RegMemImm.Imm 1) res)\n          (CC.NZ))))\n\n(type FcmpCondResult\n      (enum\n        ;; The given condition code must be set.\n        (Condition (producer ProducesFlags) (cc CC))\n\n        ;; Both condition codes must be set.\n        (AndCondition (producer ProducesFlags) (cc1 CC) (cc2 CC))\n\n        ;; Either of the conditions codes must be set.\n        (OrCondition (producer ProducesFlags) (cc1 CC) (cc2 CC))))\n\n;; Lower a FcmpCondResult to a boolean value in a register.\n(decl lower_fcmp_bool (FcmpCondResult) ValueRegs)\n\n(rule (lower_fcmp_bool (FcmpCondResult.Condition producer cc))\n      (with_flags producer (x64_setcc cc)))\n\n(rule (lower_fcmp_bool (FcmpCondResult.AndCondition producer cc1 cc2))\n      (let ((maybe ValueRegs (with_flags producer\n                                         (consumes_flags_concat\n                                           (x64_setcc cc1)\n                                           (x64_setcc cc2))))\n            (maybe0 Gpr (value_regs_get_gpr maybe 0))\n            (maybe1 Gpr (value_regs_get_gpr maybe 1)))\n        (value_reg (x64_and $I8 maybe0 maybe1))))\n\n(rule (lower_fcmp_bool (FcmpCondResult.OrCondition producer cc1 cc2))\n      (let ((maybe ValueRegs (with_flags producer\n                                         (consumes_flags_concat\n                                           (x64_setcc cc1)\n                                           (x64_setcc cc2))))\n            (maybe0 Gpr (value_regs_get_gpr maybe 0))\n            (maybe1 Gpr (value_regs_get_gpr maybe 1)))\n        (value_reg (x64_or $I8 maybe0 maybe1))))\n\n;; CLIF's `fcmp` instruction always operates on XMM registers--both scalar and\n;; vector. For the scalar versions, we use the flag-setting behavior of the\n;; `UCOMIS*` instruction to `SETcc` a 0 or 1 in a GPR register. Note that CLIF's\n;; `select` uses the same kind of flag-setting behavior but chooses values other\n;; than 0 or 1.\n;;\n;; Checking the result of `UCOMIS*` is unfortunately difficult in some cases\n;; because we do not have `SETcc` instructions that explicitly check\n;; simultaneously for the condition (i.e., `eq`, `le`, `gt`, etc.) *and*\n;; orderedness. Instead, we must check the flags multiple times. The UCOMIS*\n;; documentation (see Intel's Software Developer's Manual, volume 2, chapter 4)\n;; is helpful:\n;;  - unordered assigns    Z = 1, P = 1, C = 1\n;;  - greater than assigns Z = 0, P = 0, C = 0\n;;  - less than assigns    Z = 0, P = 0, C = 1\n;;  - equal assigns        Z = 1, P = 0, C = 0\n(decl emit_fcmp (FloatCC Value Value) FcmpCondResult)\n\n(rule (emit_fcmp (FloatCC.Equal) a @ (value_type (ty_scalar_float _)) b)\n      (FcmpCondResult.AndCondition (x64_ucomis b a) (CC.NP) (CC.Z)))\n\n(rule (emit_fcmp (FloatCC.NotEqual) a @ (value_type (ty_scalar_float _)) b)\n      (FcmpCondResult.OrCondition (x64_ucomis b a) (CC.P) (CC.NZ)))\n\n;; Some scalar lowerings correspond to one condition code.\n\n(rule (emit_fcmp (FloatCC.Ordered) a @ (value_type (ty_scalar_float ty)) b)\n      (FcmpCondResult.Condition (x64_ucomis b a) (CC.NP)))\n(rule (emit_fcmp (FloatCC.Unordered) a @ (value_type (ty_scalar_float ty)) b)\n      (FcmpCondResult.Condition (x64_ucomis b a) (CC.P)))\n(rule (emit_fcmp (FloatCC.OrderedNotEqual) a @ (value_type (ty_scalar_float ty)) b)\n      (FcmpCondResult.Condition (x64_ucomis b a) (CC.NZ)))\n(rule (emit_fcmp (FloatCC.UnorderedOrEqual) a @ (value_type (ty_scalar_float ty)) b)\n      (FcmpCondResult.Condition (x64_ucomis b a) (CC.Z)))\n(rule (emit_fcmp (FloatCC.GreaterThan) a @ (value_type (ty_scalar_float ty)) b)\n      (FcmpCondResult.Condition (x64_ucomis b a) (CC.NBE)))\n(rule (emit_fcmp (FloatCC.GreaterThanOrEqual) a @ (value_type (ty_scalar_float ty)) b)\n      (FcmpCondResult.Condition (x64_ucomis b a) (CC.NB)))\n(rule (emit_fcmp (FloatCC.UnorderedOrLessThan) a @ (value_type (ty_scalar_float ty)) b)\n      (FcmpCondResult.Condition (x64_ucomis b a) (CC.B)))\n(rule (emit_fcmp (FloatCC.UnorderedOrLessThanOrEqual) a @ (value_type (ty_scalar_float ty)) b)\n      (FcmpCondResult.Condition (x64_ucomis b a) (CC.BE)))\n\n;; Other scalar lowerings are made possible by flipping the operands and\n;; reversing the condition code.\n\n(rule (emit_fcmp (FloatCC.LessThan) a @ (value_type (ty_scalar_float ty)) b)\n      ;; Same flags as `GreaterThan`.\n      (FcmpCondResult.Condition (x64_ucomis a b) (CC.NBE)))\n(rule (emit_fcmp (FloatCC.LessThanOrEqual) a @ (value_type (ty_scalar_float ty)) b)\n      ;; Same flags as `GreaterThanOrEqual`.\n      (FcmpCondResult.Condition (x64_ucomis a b) (CC.NB)))\n(rule (emit_fcmp (FloatCC.UnorderedOrGreaterThan) a @ (value_type (ty_scalar_float ty)) b)\n      ;; Same flags as `UnorderedOrLessThan`.\n      (FcmpCondResult.Condition (x64_ucomis a b) (CC.B)))\n(rule (emit_fcmp (FloatCC.UnorderedOrGreaterThanOrEqual) a @ (value_type (ty_scalar_float ty)) b)\n      ;; Same flags as `UnorderedOrLessThanOrEqual`.\n      (FcmpCondResult.Condition (x64_ucomis a b) (CC.BE)))\n\n;;;; Type Guards ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n\n;; A type guard for matching ints and bools up to 64 bits, or 64 bit references.\n(decl ty_int_bool_or_ref () Type)\n(extern extractor ty_int_bool_or_ref ty_int_bool_or_ref)\n\n;;;; Atomics ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n\n(decl x64_mfence () SideEffectNoResult)\n(rule (x64_mfence)\n      (SideEffectNoResult.Inst (MInst.Fence (FenceKind.MFence))))\n\n(decl x64_cmpxchg (Type Gpr Gpr SyntheticAmode) Gpr)\n(rule (x64_cmpxchg ty expected replacement addr)\n      (let ((dst WritableGpr (temp_writable_gpr))\n            (_ Unit (emit (MInst.LockCmpxchg ty replacement expected addr dst))))\n        dst))\n\n(decl x64_atomic_rmw_seq (Type MachAtomicRmwOp SyntheticAmode Gpr) Gpr)\n(rule (x64_atomic_rmw_seq ty op mem input)\n      (let ((dst WritableGpr (temp_writable_gpr))\n            (tmp WritableGpr (temp_writable_gpr))\n            (_ Unit (emit (MInst.AtomicRmwSeq ty op mem input tmp dst))))\n        dst))\n\n;; CLIF IR has one enumeration for atomic operations (`AtomicRmwOp`) while the\n;; mach backend has another (`MachAtomicRmwOp`)--this converts one to the other.\n(type MachAtomicRmwOp extern (enum))\n(decl atomic_rmw_op_to_mach_atomic_rmw_op (AtomicRmwOp) MachAtomicRmwOp)\n(extern constructor atomic_rmw_op_to_mach_atomic_rmw_op atomic_rmw_op_to_mach_atomic_rmw_op)\n\n;;;; Casting ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n\n(decl bitcast_xmm_to_gpr (Type Xmm) Gpr)\n(rule (bitcast_xmm_to_gpr $F32 src)\n      (xmm_to_gpr (SseOpcode.Movd) src (OperandSize.Size32)))\n(rule (bitcast_xmm_to_gpr $F64 src)\n      (xmm_to_gpr (SseOpcode.Movq) src (OperandSize.Size64)))\n\n(decl bitcast_gpr_to_xmm (Type Gpr) Xmm)\n(rule (bitcast_gpr_to_xmm $I32 src)\n      (gpr_to_xmm (SseOpcode.Movd) src (OperandSize.Size32)))\n(rule (bitcast_gpr_to_xmm $I64 src)\n      (gpr_to_xmm (SseOpcode.Movq) src (OperandSize.Size64)))\n\n;;;; Stack Addresses ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n\n(decl stack_addr_impl (StackSlot Offset32) Gpr)\n(rule (stack_addr_impl stack_slot offset)\n      (let ((dst WritableGpr (temp_writable_gpr))\n            (_ Unit (emit (abi_stackslot_addr dst stack_slot offset))))\n        dst))\n\n;;;; Division/Remainders ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n\n(decl emit_div_or_rem (DivOrRemKind Type WritableGpr Gpr Gpr) Unit)\n(extern constructor emit_div_or_rem emit_div_or_rem)\n\n(decl div_or_rem (DivOrRemKind Value Value) Gpr)\n(rule (div_or_rem kind a @ (value_type ty) b)\n      (let ((dst WritableGpr (temp_writable_gpr))\n            (_ Unit (emit_div_or_rem kind ty dst a b)))\n        dst))\n\n;;;; Pinned Register ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n\n(decl read_pinned_gpr () Gpr)\n(rule (read_pinned_gpr)\n      (mov_from_preg (preg_pinned)))\n\n(decl write_pinned_gpr (Gpr) SideEffectNoResult)\n(rule (write_pinned_gpr val)\n      (mov_to_preg (preg_pinned) val))\n\n;;;; Shuffle ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n\n;; Produce a mask suitable for use with `pshufb` for permuting the argument to\n;; shuffle, when the arguments are the same (i.e. `shuffle a a mask`). This will\n;; map all indices in the range 0..31 to the range 0..15.\n(decl shuffle_0_31_mask (VecMask) VCodeConstant)\n(extern constructor shuffle_0_31_mask shuffle_0_31_mask)\n\n;; Produce a mask suitable for use with `pshufb` for permuting the lhs of a\n;; `shuffle` operation (lanes 0-15).\n(decl shuffle_0_15_mask (VecMask) VCodeConstant)\n(extern constructor shuffle_0_15_mask shuffle_0_15_mask)\n\n;; Produce a mask suitable for use with `pshufb` for permuting the rhs of a\n;; `shuffle` operation (lanes 16-31).\n(decl shuffle_16_31_mask (VecMask) VCodeConstant)\n(extern constructor shuffle_16_31_mask shuffle_16_31_mask)\n\n;; Produce a permutation suitable for use with `vpermi2b`, for permuting two\n;; I8X16 vectors simultaneously.\n;;\n;; NOTE: `vpermi2b` will mask the indices in each lane to 5 bits when indexing\n;; into vectors, so this constructor makes no effort to handle indices that are\n;; larger than 31. If you are lowering a clif opcode like `shuffle` that has\n;; special behavior for out of bounds indices (emitting a `0` in the resulting\n;; vector in the case of `shuffle`) you'll need to handle that behavior\n;; separately.\n(decl perm_from_mask (VecMask) VCodeConstant)\n(extern constructor perm_from_mask perm_from_mask)\n\n;; If the mask that would be given to `shuffle` contains any out-of-bounds\n;; indices, return a mask that will zero those.\n(decl perm_from_mask_with_zeros (VCodeConstant VCodeConstant) VecMask)\n(extern extractor perm_from_mask_with_zeros perm_from_mask_with_zeros)\n\n;;;; Swizzle ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n\n;; Create a mask for zeroing out-of-bounds lanes of the swizzle mask.\n(decl swizzle_zero_mask () VCodeConstant)\n(extern constructor swizzle_zero_mask swizzle_zero_mask)\n\n;;;; TLS Values ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n\n;; Helper for emitting ElfTlsGetAddr.\n(decl elf_tls_get_addr (ExternalName) Gpr)\n(rule (elf_tls_get_addr name)\n      (let ((dst WritableGpr (temp_writable_gpr))\n            (_ Unit (emit (MInst.ElfTlsGetAddr name dst))))\n        dst))\n\n;; Helper for emitting MachOTlsGetAddr.\n(decl macho_tls_get_addr (ExternalName) Gpr)\n(rule (macho_tls_get_addr name)\n      (let ((dst WritableGpr (temp_writable_gpr))\n            (_ Unit (emit (MInst.MachOTlsGetAddr name dst))))\n        dst))\n\n;; Helper for emitting CoffTlsGetAddr.\n(decl coff_tls_get_addr (ExternalName) Gpr)\n(rule (coff_tls_get_addr name)\n      (let ((dst WritableGpr (temp_writable_gpr))\n            (tmp WritableGpr (temp_writable_gpr))\n            (_ Unit (emit (MInst.CoffTlsGetAddr name dst tmp))))\n        dst))\n\n;;;; sqmul_round_sat ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n\n(decl sqmul_round_sat_mask () VCodeConstant)\n(extern constructor sqmul_round_sat_mask sqmul_round_sat_mask)\n\n;;;; uunarrow ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n\n(decl uunarrow_umax_mask () VCodeConstant)\n(extern constructor uunarrow_umax_mask uunarrow_umax_mask)\n\n(decl uunarrow_uint_mask () VCodeConstant)\n(extern constructor uunarrow_uint_mask uunarrow_uint_mask)\n\n;;;; Automatic conversions ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n\n(convert Gpr InstOutput output_gpr)\n(convert Value Gpr put_in_gpr)\n(convert Value GprMem put_in_gpr_mem)\n(convert Value GprMemImm put_in_gpr_mem_imm)\n(convert Value RegMem put_in_reg_mem)\n(convert Value RegMemImm put_in_reg_mem_imm)\n(convert Gpr GprMemImm gpr_to_gpr_mem_imm)\n(convert Gpr GprMem gpr_to_gpr_mem)\n(convert Gpr Reg gpr_to_reg)\n(convert GprMem RegMem gpr_mem_to_reg_mem)\n(convert Reg Gpr gpr_new)\n(convert WritableGpr Gpr writable_gpr_to_gpr)\n(convert RegMemImm GprMemImm gpr_mem_imm_new)\n(convert RegMem GprMem reg_mem_to_gpr_mem)\n(convert RegMem RegMemImm reg_mem_to_reg_mem_imm)\n(convert Reg GprMem reg_to_gpr_mem)\n(convert Reg GprMemImm reg_to_gpr_mem_imm)\n(convert WritableGpr WritableReg writable_gpr_to_reg)\n(convert WritableGpr Reg writable_gpr_to_r_reg)\n(convert WritableGpr GprMem writable_gpr_to_gpr_mem)\n(convert WritableGpr ValueRegs writable_gpr_to_value_regs)\n\n(convert Xmm InstOutput output_xmm)\n(convert Value Xmm put_in_xmm)\n(convert Value XmmMem put_in_xmm_mem)\n(convert Value XmmMemAligned put_in_xmm_mem_aligned)\n(convert Value XmmMemImm put_in_xmm_mem_imm)\n(convert Xmm Reg xmm_to_reg)\n(convert Xmm RegMem xmm_to_reg_mem)\n(convert Reg Xmm xmm_new)\n(convert Reg XmmMem reg_to_xmm_mem)\n(convert Reg RegMemImm reg_to_reg_mem_imm)\n(convert RegMem XmmMem reg_mem_to_xmm_mem)\n(convert RegMemImm XmmMemImm mov_rmi_to_xmm)\n(convert Xmm XmmMem xmm_to_xmm_mem)\n(convert Xmm XmmMemImm xmm_to_xmm_mem_imm)\n(convert Xmm XmmMemAligned xmm_to_xmm_mem_aligned)\n(convert XmmMem XmmMemImm xmm_mem_to_xmm_mem_imm)\n(convert XmmMem RegMem xmm_mem_to_reg_mem)\n(convert WritableXmm Xmm writable_xmm_to_xmm)\n(convert WritableXmm WritableReg writable_xmm_to_reg)\n(convert WritableXmm Reg writable_xmm_to_r_reg)\n(convert WritableXmm XmmMem writable_xmm_to_xmm_mem)\n(convert WritableXmm ValueRegs writable_xmm_to_value_regs)\n\n;; Note that these conversions will introduce a `movupd` instruction if\n;; the memory location is not aligned to a 16-byte boundary. This is primarily\n;; used to convert `XmmMem` inputs, which themselves were typically created\n;; via the `put_in_xmm_mem` constructor, into operands of SSE instructions.\n;; Most pre-AVX instructions working with 16-bytes of data (e.g. full xmm\n;; registers) require 16-byte alignment.\n(convert XmmMem XmmMemAligned xmm_mem_to_xmm_mem_aligned)\n(convert XmmMemImm XmmMemAlignedImm xmm_mem_imm_to_xmm_mem_aligned_imm)\n\n(convert Gpr Imm8Gpr gpr_to_imm8_gpr)\n(convert Imm8Reg Imm8Gpr imm8_reg_to_imm8_gpr)\n\n(convert Amode SyntheticAmode amode_to_synthetic_amode)\n(convert Amode GprMem amode_to_gpr_mem)\n(convert SyntheticAmode GprMem synthetic_amode_to_gpr_mem)\n(convert Amode XmmMem amode_to_xmm_mem)\n(convert SyntheticAmode XmmMem synthetic_amode_to_xmm_mem)\n(convert Amode XmmMemAligned amode_to_xmm_mem_aligned)\n(convert SyntheticAmode XmmMemAligned synthetic_amode_to_xmm_mem_aligned)\n(convert VCodeConstant SyntheticAmode const_to_synthetic_amode)\n(convert VCodeConstant XmmMem const_to_xmm_mem)\n\n(convert IntCC CC intcc_to_cc)\n(convert AtomicRmwOp MachAtomicRmwOp atomic_rmw_op_to_mach_atomic_rmw_op)\n\n(convert SinkableLoad RegMem sink_load)\n(convert SinkableLoad GprMemImm sink_load_to_gpr_mem_imm)\n(convert SinkableLoad XmmMem sink_load_to_xmm_mem)\n\n(decl reg_to_xmm_mem (Reg) XmmMem)\n(rule (reg_to_xmm_mem r)\n      (xmm_to_xmm_mem (xmm_new r)))\n(decl xmm_to_reg_mem (Reg) XmmMem)\n(rule (xmm_to_reg_mem r)\n      (RegMem.Reg (xmm_to_reg r)))\n\n(decl writable_gpr_to_r_reg (WritableGpr) Reg)\n(rule (writable_gpr_to_r_reg w_gpr)\n      (writable_reg_to_reg (writable_gpr_to_reg w_gpr)))\n(decl writable_gpr_to_gpr_mem (WritableGpr) GprMem)\n(rule (writable_gpr_to_gpr_mem w_gpr)\n      (gpr_to_gpr_mem w_gpr))\n(decl writable_gpr_to_value_regs (WritableGpr) ValueRegs)\n(rule (writable_gpr_to_value_regs w_gpr)\n      (value_reg w_gpr))\n(decl writable_xmm_to_r_reg (WritableXmm) Reg)\n(rule (writable_xmm_to_r_reg w_xmm)\n      (writable_reg_to_reg (writable_xmm_to_reg w_xmm)))\n(decl writable_xmm_to_xmm_mem (WritableXmm) XmmMem)\n(rule (writable_xmm_to_xmm_mem w_xmm)\n      (xmm_to_xmm_mem (writable_xmm_to_xmm w_xmm)))\n(decl writable_xmm_to_value_regs (WritableXmm) ValueRegs)\n(rule (writable_xmm_to_value_regs w_xmm)\n      (value_reg w_xmm))\n\n(decl synthetic_amode_to_gpr_mem (SyntheticAmode) GprMem)\n(decl amode_to_gpr_mem (Amode) GprMem)\n(rule (amode_to_gpr_mem amode)\n      (amode_to_synthetic_amode amode))\n(rule (synthetic_amode_to_gpr_mem amode)\n      (synthetic_amode_to_reg_mem amode))\n(decl amode_to_xmm_mem (Amode) XmmMem)\n(rule (amode_to_xmm_mem amode)\n      (amode_to_synthetic_amode amode))\n(decl synthetic_amode_to_xmm_mem (SyntheticAmode) XmmMem)\n(rule (synthetic_amode_to_xmm_mem amode)\n      (synthetic_amode_to_reg_mem amode))\n(decl const_to_synthetic_amode (VCodeConstant) SyntheticAmode)\n(extern constructor const_to_synthetic_amode const_to_synthetic_amode)\n(decl const_to_xmm_mem (VCodeConstant) XmmMem)\n(rule (const_to_xmm_mem c) (const_to_synthetic_amode c))\n\n(decl xmm_to_xmm_mem_aligned (Xmm) XmmMemAligned)\n(rule (xmm_to_xmm_mem_aligned reg) (xmm_mem_to_xmm_mem_aligned reg))\n(decl amode_to_xmm_mem_aligned (Amode) XmmMemAligned)\n(rule (amode_to_xmm_mem_aligned mode) (amode_to_xmm_mem mode))\n(decl synthetic_amode_to_xmm_mem_aligned (SyntheticAmode) XmmMemAligned)\n(rule (synthetic_amode_to_xmm_mem_aligned mode) (synthetic_amode_to_xmm_mem mode))\n(decl put_in_xmm_mem_aligned (Value) XmmMemAligned)\n(rule (put_in_xmm_mem_aligned val) (put_in_xmm_mem val))\n\n;; Helper for creating `MovFromPReg` instructions.\n(decl mov_from_preg (PReg) Reg)\n(rule (mov_from_preg preg)\n      (let ((dst WritableGpr (temp_writable_gpr))\n            (_ Unit (emit (MInst.MovFromPReg preg dst))))\n        dst))\n\n(decl mov_to_preg (PReg Gpr) SideEffectNoResult)\n(rule (mov_to_preg dst src)\n      (SideEffectNoResult.Inst (MInst.MovToPReg src dst)))\n\n(decl preg_rbp () PReg)\n(extern constructor preg_rbp preg_rbp)\n\n(decl preg_rsp () PReg)\n(extern constructor preg_rsp preg_rsp)\n\n(decl preg_pinned () PReg)\n(extern constructor preg_pinned preg_pinned)\n\n(decl x64_rbp () Reg)\n(rule (x64_rbp)\n      (mov_from_preg (preg_rbp)))\n\n(decl x64_rsp () Reg)\n(rule (x64_rsp)\n      (mov_from_preg (preg_rsp)))\n\n;;;; Helpers for Emitting LibCalls ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n\n(type LibCall extern\n      (enum\n        FmaF32\n        FmaF64\n        CeilF32\n        CeilF64\n        FloorF32\n        FloorF64\n        NearestF32\n        NearestF64\n        TruncF32\n        TruncF64))\n\n(decl libcall_1 (LibCall Reg) Reg)\n(extern constructor libcall_1 libcall_1)\n\n(decl libcall_3 (LibCall Reg Reg Reg) Reg)\n(extern constructor libcall_3 libcall_3)\n", "test compile precise-output\ntarget x86_64\n\nfunction %amode_add(i64, i64) -> i64 {\nblock0(v0: i64, v1: i64):\n    v2 = iadd v0, v1\n    v3 = load.i64 v2\n    return v3\n}\n\n; VCode:\n;   pushq   %rbp\n;   movq    %rsp, %rbp\n; block0:\n;   movq    0(%rdi,%rsi,1), %rax\n;   movq    %rbp, %rsp\n;   popq    %rbp\n;   ret\n; \n; Disassembled:\n; block0: ; offset 0x0\n;   pushq %rbp\n;   movq %rsp, %rbp\n; block1: ; offset 0x4\n;   movq (%rdi, %rsi), %rax ; trap: heap_oob\n;   movq %rbp, %rsp\n;   popq %rbp\n;   retq\n\nfunction %amode_add_imm(i64) -> i64 {\nblock0(v0: i64):\n    v1 = iconst.i64 42\n    v2 = iadd v0, v1\n    v3 = load.i64 v2\n    return v3\n}\n\n; VCode:\n;   pushq   %rbp\n;   movq    %rsp, %rbp\n; block0:\n;   movq    42(%rdi), %rax\n;   movq    %rbp, %rsp\n;   popq    %rbp\n;   ret\n; \n; Disassembled:\n; block0: ; offset 0x0\n;   pushq %rbp\n;   movq %rsp, %rbp\n; block1: ; offset 0x4\n;   movq 0x2a(%rdi), %rax ; trap: heap_oob\n;   movq %rbp, %rsp\n;   popq %rbp\n;   retq\n\nfunction %amode_add_imm_order(i64) -> i64 {\nblock0(v0: i64):\n    v1 = iconst.i64 42\n    v2 = iadd v1, v0\n    v3 = load.i64 v2\n    return v3\n}\n\n; VCode:\n;   pushq   %rbp\n;   movq    %rsp, %rbp\n; block0:\n;   movq    42(%rdi), %rax\n;   movq    %rbp, %rsp\n;   popq    %rbp\n;   ret\n; \n; Disassembled:\n; block0: ; offset 0x0\n;   pushq %rbp\n;   movq %rsp, %rbp\n; block1: ; offset 0x4\n;   movq 0x2a(%rdi), %rax ; trap: heap_oob\n;   movq %rbp, %rsp\n;   popq %rbp\n;   retq\n\nfunction %amode_add_uext_imm(i64) -> i64 {\nblock0(v0: i64):\n    v1 = iconst.i32 42\n    v2 = uextend.i64 v1\n    v3 = iadd v2, v0\n    v4 = load.i64 v3\n    return v4\n}\n\n; VCode:\n;   pushq   %rbp\n;   movq    %rsp, %rbp\n; block0:\n;   movq    42(%rdi), %rax\n;   movq    %rbp, %rsp\n;   popq    %rbp\n;   ret\n; \n; Disassembled:\n; block0: ; offset 0x0\n;   pushq %rbp\n;   movq %rsp, %rbp\n; block1: ; offset 0x4\n;   movq 0x2a(%rdi), %rax ; trap: heap_oob\n;   movq %rbp, %rsp\n;   popq %rbp\n;   retq\n\nfunction %amode_reg_reg_imm(i64, i64) -> i64 {\nblock0(v0: i64, v1: i64):\n    v2 = iadd v0, v1\n    v3 = iconst.i64 256\n    v4 = iadd v2, v3\n    v5 = load.i64 v4+64\n    return v5\n}\n\n; VCode:\n;   pushq   %rbp\n;   movq    %rsp, %rbp\n; block0:\n;   movq    320(%rdi,%rsi,1), %rax\n;   movq    %rbp, %rsp\n;   popq    %rbp\n;   ret\n; \n; Disassembled:\n; block0: ; offset 0x0\n;   pushq %rbp\n;   movq %rsp, %rbp\n; block1: ; offset 0x4\n;   movq 0x140(%rdi, %rsi), %rax ; trap: heap_oob\n;   movq %rbp, %rsp\n;   popq %rbp\n;   retq\n\nfunction %amode_reg_reg_imm_negative(i64, i64) -> i64 {\nblock0(v0: i64, v1: i64):\n    v2 = iadd v0, v1\n    v3 = iconst.i64 -1\n    v4 = iadd v2, v3\n    v5 = load.i64 v4\n    return v5\n}\n\n; VCode:\n;   pushq   %rbp\n;   movq    %rsp, %rbp\n; block0:\n;   movq    -1(%rdi,%rsi,1), %rax\n;   movq    %rbp, %rsp\n;   popq    %rbp\n;   ret\n; \n; Disassembled:\n; block0: ; offset 0x0\n;   pushq %rbp\n;   movq %rsp, %rbp\n; block1: ; offset 0x4\n;   movq -1(%rdi, %rsi), %rax ; trap: heap_oob\n;   movq %rbp, %rsp\n;   popq %rbp\n;   retq\n\nfunction %amode_reg_reg_imm_scaled(i64, i64) -> i64 {\nblock0(v0: i64, v1: i64):\n    v2 = iconst.i64 -1\n    v3 = iadd v0, v2\n    v4 = ishl_imm v1, 3\n    v5 = iadd v3, v4\n    v6 = load.i64 v5\n    return v6\n}\n\n; VCode:\n;   pushq   %rbp\n;   movq    %rsp, %rbp\n; block0:\n;   movq    -1(%rdi,%rsi,8), %rax\n;   movq    %rbp, %rsp\n;   popq    %rbp\n;   ret\n; \n; Disassembled:\n; block0: ; offset 0x0\n;   pushq %rbp\n;   movq %rsp, %rbp\n; block1: ; offset 0x4\n;   movq -1(%rdi, %rsi, 8), %rax ; trap: heap_oob\n;   movq %rbp, %rsp\n;   popq %rbp\n;   retq\n\nfunction %amode_reg_reg_imm_uext_scaled(i64, i32) -> i64 {\nblock0(v0: i64, v1: i32):\n    v2 = iconst.i64 -1\n    v3 = iadd v0, v2\n    v4 = ishl_imm v1, 3\n    v5 = uextend.i64 v4\n    v6 = iadd v3, v5\n    v7 = load.i64 v6\n    return v7\n}\n\n; VCode:\n;   pushq   %rbp\n;   movq    %rsp, %rbp\n; block0:\n;   movl    %esi, %ecx\n;   movq    -1(%rdi,%rcx,8), %rax\n;   movq    %rbp, %rsp\n;   popq    %rbp\n;   ret\n; \n; Disassembled:\n; block0: ; offset 0x0\n;   pushq %rbp\n;   movq %rsp, %rbp\n; block1: ; offset 0x4\n;   movl %esi, %ecx\n;   movq -1(%rdi, %rcx, 8), %rax ; trap: heap_oob\n;   movq %rbp, %rsp\n;   popq %rbp\n;   retq\n\nfunction %amode_reg_reg_imm_uext_scaled_add(i64, i32, i32) -> i64 {\nblock0(v0: i64, v1: i32, v2: i32):\n    v3 = iconst.i64 -1\n    v4 = iadd v0, v3\n    v5 = iadd v1, v2\n    v6 = ishl_imm v5, 2\n    v7 = uextend.i64 v6\n    v8 = iadd v4, v7\n    v9 = load.i64 v8\n    return v9\n}\n\n; VCode:\n;   pushq   %rbp\n;   movq    %rsp, %rbp\n; block0:\n;   movq    %rsi, %r8\n;   addl    %r8d, %edx, %r8d\n;   movq    -1(%rdi,%r8,4), %rax\n;   movq    %rbp, %rsp\n;   popq    %rbp\n;   ret\n; \n; Disassembled:\n; block0: ; offset 0x0\n;   pushq %rbp\n;   movq %rsp, %rbp\n; block1: ; offset 0x4\n;   movq %rsi, %r8\n;   addl %edx, %r8d\n;   movq -1(%rdi, %r8, 4), %rax ; trap: heap_oob\n;   movq %rbp, %rsp\n;   popq %rbp\n;   retq\n\n"], "fixing_code": ["--------------------------------------------------------------------------------\n\n## 8.0.0\n\nUnreleased.\n\n### Added\n\n### Changed\n\n--------------------------------------------------------------------------------\n\n## 7.0.0\n\nUnreleased.\n\n### Added\n\n### Changed\n\n--------------------------------------------------------------------------------\n\n## 6.0.1\n\nReleased 2023-03-08.\n\n### Fixed\n\n* Guest-controlled out-of-bounds read/write on x86\\_64\n  [GHSA-ff4p-7xrq-q5r8](https://github.com/bytecodealliance/wasmtime/security/advisories/GHSA-ff4p-7xrq-q5r8)\n\n*  Miscompilation of `i8x16.select` with the same inputs on x86\\_64\n  [GHSA-xm67-587q-r2vw](https://github.com/bytecodealliance/wasmtime/security/advisories/GHSA-xm67-587q-r2vw)\n\n--------------------------------------------------------------------------------\n\n## 6.0.0\n\nReleased 2023-02-20\n\n### Added\n\n* Wasmtime's built-in cache can now be disabled after being enabled previously.\n  [#5542](https://github.com/bytecodealliance/wasmtime/pull/5542)\n\n* Older x86\\_64 CPUs, without SSE4.1 for example, are now supported when the\n  wasm SIMD proposal is disabled.\n  [#5567](https://github.com/bytecodealliance/wasmtime/pull/5567)\n\n* The Wasmtime C API now has `WASMTIME_VERSION_*` macros defined in its header\n  files.\n  [#5651](https://github.com/bytecodealliance/wasmtime/pull/5651)\n\n* The `wasmtime` CLI executable as part of Wasmtime's precompiled release\n  artifacts now has the `all-arch` feature enabled.\n  [#5657](https://github.com/bytecodealliance/wasmtime/pull/5657)\n\n### Changed\n\n* Equality of `wasmtime::component::Val::Float{32,64}` now considers NaNs as\n  equal for assistance when fuzzing.\n  [#5535](https://github.com/bytecodealliance/wasmtime/pull/5535)\n\n* WIT syntax supported by `wasmtime::component::bindgen!` has been updated in\n  addition to the generated code being updated.\n  [#5565](https://github.com/bytecodealliance/wasmtime/pull/5565)\n  [#5692](https://github.com/bytecodealliance/wasmtime/pull/5692)\n  [#5694](https://github.com/bytecodealliance/wasmtime/pull/5694)\n\n* Cranelift's egraph-based optimization framework is now enabled by default.\n  [#5587](https://github.com/bytecodealliance/wasmtime/pull/5587)\n\n* The old `PoolingAllocationStrategy` type has been removed in favor of a more\n  flexible configuration via a new option\n  `PoolingAllocationConfig::max_unused_warm_slots` which is more flexible and\n  subsumes the previous use cases for each strategy.\n  [#5661](https://github.com/bytecodealliance/wasmtime/pull/5661)\n\n* Creation of `InstancePre` through `Linker::instantiate_pre` no longer requires\n  a `Store` to be provided. Instead a `Store`-related argument is now required\n  on `Linker::define`-style APIs instead.\n  [#5683](https://github.com/bytecodealliance/wasmtime/pull/5683)\n\n### Fixed\n\n* Compilation for FreeBSD on x86\\_64 and AArch64 has been fixed.\n  [#5606](https://github.com/bytecodealliance/wasmtime/pull/5606)\n\n--------------------------------------------------------------------------------\n\n## 5.0.1\n\nReleased 2023-03-08.\n\n### Fixed\n\n* Guest-controlled out-of-bounds read/write on x86\\_64\n  [GHSA-ff4p-7xrq-q5r8](https://github.com/bytecodealliance/wasmtime/security/advisories/GHSA-ff4p-7xrq-q5r8)\n\n*  Miscompilation of `i8x16.select` with the same inputs on x86\\_64\n  [GHSA-xm67-587q-r2vw](https://github.com/bytecodealliance/wasmtime/security/advisories/GHSA-xm67-587q-r2vw)\n\n--------------------------------------------------------------------------------\n\n## 5.0.0\n\nReleased 2023-01-20\n\n### Added\n\n* A `wasmtime::component::bingen!` macro has been added for generating bindings\n  from `*.wit` files. Note that WIT is still heavily in development so this is\n  more of a preview of what will be as opposed to a finished feature.\n  [#5317](https://github.com/bytecodealliance/wasmtime/pull/5317)\n  [#5397](https://github.com/bytecodealliance/wasmtime/pull/5397)\n\n* The `wasmtime settings` CLI command now has a `--json` option for\n  machine-readable output.\n  [#5411](https://github.com/bytecodealliance/wasmtime/pull/5411)\n\n* Wiggle-generated bindings can now generate the trait for either `&mut self` or\n  `&self`.\n  [#5428](https://github.com/bytecodealliance/wasmtime/pull/5428)\n\n* The `wiggle` crate has more convenience APIs for working with guest data\n  that resides in shared memory.\n  [#5471](https://github.com/bytecodealliance/wasmtime/pull/5471)\n  [#5475](https://github.com/bytecodealliance/wasmtime/pull/5475)\n\n### Changed\n\n* Cranelift's egraph support has been rewritten and updated. This functionality\n  is still gated behind a flag and may become the default in the next release.\n  [#5382](https://github.com/bytecodealliance/wasmtime/pull/5382)\n\n* The implementation of codegen for WebAssembly linear memory has changed\n  significantly internally in Cranelift, moving more responsibility to the\n  Wasmtime embedding rather than Cranelift itself. This should have no\n  user-visible change, however.\n  [#5386](https://github.com/bytecodealliance/wasmtime/pull/5386)\n\n* The `Val::Float32` and `Val::Float64` variants for components now store `f32`\n  and `f64` instead of the bit representation.\n  [#5510](https://github.com/bytecodealliance/wasmtime/pull/5510)\n\n### Fixed\n\n* Handling of DWARF debugging information in components with multiple modules\n  has been fixed to ensure the right info is used for each module.\n  [#5358](https://github.com/bytecodealliance/wasmtime/pull/5358)\n\n--------------------------------------------------------------------------------\n\n## 4.0.1\n\nReleased 2023-03-08.\n\n### Fixed\n\n* Guest-controlled out-of-bounds read/write on x86\\_64\n  [GHSA-ff4p-7xrq-q5r8](https://github.com/bytecodealliance/wasmtime/security/advisories/GHSA-ff4p-7xrq-q5r8)\n\n*  Miscompilation of `i8x16.select` with the same inputs on x86\\_64\n  [GHSA-xm67-587q-r2vw](https://github.com/bytecodealliance/wasmtime/security/advisories/GHSA-xm67-587q-r2vw)\n\n--------------------------------------------------------------------------------\n\n## 4.0.0\n\nReleased 2022-12-20\n\n### Added\n\n* Dynamic memories are now supported with the pooling instance allocator which\n  can possibly reduce the number of page faults throughout execution at the cost\n  of slower to run code. Page faults are primarily reduced by avoiding\n  releasing memory back to the system, relying on bounds checks to keep the\n  memory inaccessible.\n  [#5208](https://github.com/bytecodealliance/wasmtime/pull/5208)\n\n* The `wiggle` generator now supports function-level control over `tracing`\n  calls.\n  [#5194](https://github.com/bytecodealliance/wasmtime/pull/5194)\n\n* Support has been added to `wiggle` to be compatible with shared memories.\n  [#5225](https://github.com/bytecodealliance/wasmtime/pull/5225)\n  [#5229](https://github.com/bytecodealliance/wasmtime/pull/5229)\n  [#5264](https://github.com/bytecodealliance/wasmtime/pull/5264)\n  [#5268](https://github.com/bytecodealliance/wasmtime/pull/5268)\n  [#5054](https://github.com/bytecodealliance/wasmtime/pull/5054)\n\n* The `wiggle` generator now supports a \"trappable error\" configuration to\n  improve error conversions to guest errors and ensure that no host errors are\n  forgotten or accidentally become traps. The `wasi-common` crate has been\n  updated to use this.\n  [#5276](https://github.com/bytecodealliance/wasmtime/pull/5276)\n  [#5279](https://github.com/bytecodealliance/wasmtime/pull/5279)\n\n* The `memory.atomic.{notify,wait32,wait64}` instructions are now all\n  implemented in Wasmtime.\n  [#5255](https://github.com/bytecodealliance/wasmtime/pull/5255)\n  [#5311](https://github.com/bytecodealliance/wasmtime/pull/5311)\n\n* A `wasm_config_parallel_compilation_set` configuration function has been added\n  to the C API.\n  [#5298](https://github.com/bytecodealliance/wasmtime/pull/5298)\n\n* The `wasmtime` CLI can have its input module piped into it from stdin now.\n  [#5342](https://github.com/bytecodealliance/wasmtime/pull/5342)\n\n* `WasmBacktrace::{capture,force_capture}` methods have been added to\n  programmatically capture a backtrace outside of a trapping context.\n  [#5341](https://github.com/bytecodealliance/wasmtime/pull/5341)\n\n### Changed\n\n* The `S` type parameter on `Func::typed` and `Instance::get_typed_func` has\n  been removed and no longer needs to be specified.\n  [#5275](https://github.com/bytecodealliance/wasmtime/pull/5275)\n\n* The `SharedMemory::data` method now returns `&[UnsafeCell<u8>]` instead of the\n  prior raw slice return.\n  [#5240](https://github.com/bytecodealliance/wasmtime/pull/5240)\n\n* Creation of a `WasiCtx` will no longer unconditionally acquire randomness from\n  the OS, instead using the `rand::thread_rng()` function in Rust which is only\n  periodically reseeded with randomness from the OS.\n  [#5244](https://github.com/bytecodealliance/wasmtime/pull/5244)\n\n* Codegen of dynamically-bounds-checked wasm memory accesses has been improved.\n  [#5190](https://github.com/bytecodealliance/wasmtime/pull/5190)\n\n* Wasmtime will now emit inline stack probes in generated functions for x86\\_64,\n  aarch64, and riscv64 architectures. This guarantees a process abort if an\n  engine was misconfigured to give wasm too much stack instead of optionally\n  allowing wasm to skip the guard page.\n  [#5350](https://github.com/bytecodealliance/wasmtime/pull/5350)\n  [#5353](https://github.com/bytecodealliance/wasmtime/pull/5353)\n\n### Fixed\n\n* Dropping a `Module` will now release kernel resources in-use by the pooling\n  allocator when enabled instead of waiting for a new instance to be\n  re-instantiated into prior slots.\n  [#5321](https://github.com/bytecodealliance/wasmtime/pull/5321)\n\n--------------------------------------------------------------------------------\n\n## 3.0.1\n\nReleased 2022-12-01.\n\n### Fixed\n\n* The instruction cache is now flushed for AArch64 Android.\n  [#5331](https://github.com/bytecodealliance/wasmtime/pull/5331)\n\n* Building for FreeBSD and Android has been fixed.\n  [#5323](https://github.com/bytecodealliance/wasmtime/pull/5323)\n\n--------------------------------------------------------------------------------\n\n## 3.0.0\n\nReleased 2022-11-21\n\n### Added\n\n* New `WasiCtx::{push_file, push_dir}` methods exist for embedders to add their\n  own objects.\n  [#5027](https://github.com/bytecodealliance/wasmtime/pull/5027)\n\n* Wasmtime's `component-model` support now supports `async` host functions and\n  embedding in the same manner as core wasm.\n  [#5055](https://github.com/bytecodealliance/wasmtime/pull/5055)\n\n* The `wasmtime` CLI executable now supports a `--max-wasm-stack` flag.\n  [#5156](https://github.com/bytecodealliance/wasmtime/pull/5156)\n\n* AOT compilation support has been implemented for components (aka the\n  `component-model` feature of the Wasmtime crate).\n  [#5160](https://github.com/bytecodealliance/wasmtime/pull/5160)\n\n* A new `wasi_config_set_stdin_bytes` function is available in the C API to set\n  the stdin of a WASI-using module from an in-memory slice.\n  [#5179](https://github.com/bytecodealliance/wasmtime/pull/5179)\n\n* When using the pooling allocator there are now options to reset memory with\n  `memset` instead of `madvisev` on Linux to keep pages resident in memory to\n  reduce page faults when reusing linear memory slots.\n  [#5207](https://github.com/bytecodealliance/wasmtime/pull/5207)\n\n### Changed\n\n* Consuming 0 fuel with 0 fuel left is now considered to succeed. Additionally a\n  store may not consume its last unit of fuel.\n  [#5013](https://github.com/bytecodealliance/wasmtime/pull/5013)\n\n* A number of variants in the `wasi_common::ErrorKind` enum have been removed.\n  [#5015](https://github.com/bytecodealliance/wasmtime/pull/5015)\n\n* Methods on `WasiDir` now error-by-default instead of requiring a definition by\n  default.\n  [#5019](https://github.com/bytecodealliance/wasmtime/pull/5019)\n\n* Bindings generated by the `wiggle` crate now always depend on the `wasmtime`\n  crate meaning crates like `wasi-common` no longer compile for platforms such\n  as `wasm32-unknown-emscripten`.\n  [#5137](https://github.com/bytecodealliance/wasmtime/pull/5137)\n\n* Error handling in the `wasmtime` crate's API has been changed to primarily\n  work with `anyhow::Error` for custom errors. The `Trap` type has been replaced\n  with a simple `enum Trap { ... }` and backtrace information is now stored as a\n  `WasmBacktrace` type inserted as context into an `anyhow::Error`.\n  Host-functions are expected to return `anyhow::Result<T>` instead of the prior\n  `Trap` error return from before. Additionally the old `Trap::i32_exit`\n  constructor is now a concrete `wasi_commont::I32Exit` type which can be tested\n  for with a `downcast_ref` on the error returned from Wasmtime.\n  [#5149](https://github.com/bytecodealliance/wasmtime/pull/5149)\n\n* Configuration of the pooling allocator is now done through a builder-style\n  `PoolingAllocationConfig` API instead of the prior enum-variant API.\n  [#5205](https://github.com/bytecodealliance/wasmtime/pull/5205)\n\n### Fixed\n\n* The instruction cache is now properly flushed for AArch64 on Windows.\n  [#4997](https://github.com/bytecodealliance/wasmtime/pull/4997)\n\n* Backtrace capturing with many sequences of wasm->host calls on the stack no\n  longer exhibit quadratic capturing behavior.\n  [#5049](https://github.com/bytecodealliance/wasmtime/pull/5049)\n\n--------------------------------------------------------------------------------\n\n## 2.0.2\n\nReleased 2022-11-10.\n\n### Fixed\n\n* [CVE-2022-39392] - modules may perform out-of-bounds reads/writes when the\n  pooling allocator was configured with `memory_pages: 0`.\n\n* [CVE-2022-39393] - data can be leaked between instances when using the pooling\n  allocator.\n\n* [CVE-2022-39394] - An incorrect Rust signature for the C API\n  `wasmtime_trap_code` function could lead to an out-of-bounds write of three\n  zero bytes.\n\n[CVE-2022-39392]: https://github.com/bytecodealliance/wasmtime/security/advisories/GHSA-44mr-8vmm-wjhg\n[CVE-2022-39393]: https://github.com/bytecodealliance/wasmtime/security/advisories/GHSA-wh6w-3828-g9qf\n[CVE-2022-39394]: https://github.com/bytecodealliance/wasmtime/security/advisories/GHSA-h84q-m8rr-3v9q\n\n--------------------------------------------------------------------------------\n\n## 2.0.1\n\nReleased 2022-10-27.\n\n### Fixed\n\n* A compilation error when building only the `wasmtime` crate on Windows with\n  only the default features enabled has been fixed.\n  [#5134](https://github.com/bytecodealliance/wasmtime/pull/5134)\n\n### Changed\n\n* The `rayon` dependency added to `cranelift-isle` in 2.0.0 has been removed to\n  improve the compile time of the `cranelift-codegen` crate.\n  [#5101](https://github.com/bytecodealliance/wasmtime/pull/5101)\n\n--------------------------------------------------------------------------------\n\n## 2.0.0\n\nReleased 2022-10-20\n\n### Added\n\n* Cranelift has gained support for forward-edge CFI on the AArch64 backend.\n  [#3693](https://github.com/bytecodealliance/wasmtime/pull/3693)\n\n* A `--disable-parallel-compilation` CLI flag is now implemented for `wasmtime`.\n  [#4911](https://github.com/bytecodealliance/wasmtime/pull/4911)\n\n* [Tier 3] support has been added for for RISC-V 64 with a new backend in\n  Cranelift for this architecture.\n  [#4271](https://github.com/bytecodealliance/wasmtime/pull/4271)\n\n* Basic [tier 3] support for Windows ARM64 has been added but features such as\n  traps don't work at this time.\n  [#4990](https://github.com/bytecodealliance/wasmtime/pull/4990)\n\n### Changed\n\n* The implementation of the `random_get` function in `wasi-common` is now faster\n  by using a userspace CSPRNG rather than the OS for randomness.\n  [#4917](https://github.com/bytecodealliance/wasmtime/pull/4917)\n\n* The AArch64 backend has completed its transition to ISLE.\n  [#4851](https://github.com/bytecodealliance/wasmtime/pull/4851)\n  [#4866](https://github.com/bytecodealliance/wasmtime/pull/4866)\n  [#4898](https://github.com/bytecodealliance/wasmtime/pull/4898)\n  [#4884](https://github.com/bytecodealliance/wasmtime/pull/4884)\n  [#4820](https://github.com/bytecodealliance/wasmtime/pull/4820)\n  [#4913](https://github.com/bytecodealliance/wasmtime/pull/4913)\n  [#4942](https://github.com/bytecodealliance/wasmtime/pull/4942)\n  [#4943](https://github.com/bytecodealliance/wasmtime/pull/4943)\n\n* The size of the `sigaltstack` allocated per-thread for signal handling has\n  been increased from 16k to 64k.\n  [#4964](https://github.com/bytecodealliance/wasmtime/pull/4964)\n\n\n[Tier 3]: https://docs.wasmtime.dev/stability-tiers.html\n\n--------------------------------------------------------------------------------\n\n## 1.0.2\n\nReleased 2022-11-10.\n\n### Fixed\n\n* [CVE-2022-39392] - modules may perform out-of-bounds reads/writes when the\n  pooling allocator was configured with `memory_pages: 0`.\n\n* [CVE-2022-39393] - data can be leaked between instances when using the pooling\n  allocator.\n\n* [CVE-2022-39394] - An incorrect Rust signature for the C API\n  `wasmtime_trap_code` function could lead to an out-of-bounds write of three\n  zero bytes.\n\n--------------------------------------------------------------------------------\n\n## 1.0.1\n\nReleased 2022-09-26\n\nThis is a patch release that incorporates a fix for a miscompilation of an\natomic-CAS operator on aarch64. The instruction is not usable from Wasmtime\nwith default settings, but may be used if the Wasm atomics extension is\nenabled. The bug may also be reachable via other uses of Cranelift. Thanks to\n@bjorn3 for reporting and debugging this issue!\n\n### Fixed\n\n* Fixed a miscompilation of `atomic_cas` on aarch64. The output register was\n  swapped with a temporary register in the register-allocator constraints.\n  [#4959](https://github.com/bytecodealliance/wasmtime/pull/4959)\n  [#4960](https://github.com/bytecodealliance/wasmtime/pull/4960)\n\n--------------------------------------------------------------------------------\n\n## 1.0.0\n\nReleased 2022-09-20\n\nThis release marks the official 1.0 release of Wasmtime and represents the\nculmination of the work amongst over 300 contributors. Wasmtime has been\nbattle-tested in production through multiple embeddings for quite some time now\nand we're confident in releasing a 1.0 version to signify the stability and\nquality of the Wasmtime engine.\n\nMore information about Wasmtime's 1.0 release is on the [Bytecode Alliance's\nblog][ba-blog] with separate posts on [Wasmtime's performance\nfeatures][ba-perf], [Wasmtime's security story][ba-security], and [the 1.0\nrelease announcement][ba-1.0].\n\nAs a reminder the 2.0 release of Wasmtime is scheduled for one month from now on\nOctober 20th. For more information see the [RFC on Wasmtime's 1.0\nrelease][rfc-1.0].\n\n[ba-blog]: https://bytecodealliance.org/articles/\n[ba-perf]: https://bytecodealliance.org/articles/wasmtime-10-performance\n[ba-security]: https://bytecodealliance.org/articles/security-and-correctness-in-wasmtime\n[ba-1.0]: https://bytecodealliance.org/articles/wasmtime-1-0-fast-safe-and-now-production-ready.md\n[rfc-1.0]: https://github.com/bytecodealliance/rfcs/blob/main/accepted/wasmtime-one-dot-oh.md\n\n### Added\n\n* An incremental compilation cache for Cranelift has been added which can be\n  enabled with `Config::enable_incremental_compilation`, and this option is\n  disabled by default for now. The incremental compilation cache has been\n  measured to improve compile times for cold uncached modules as well due to\n  some wasm modules having similar-enough functions internally.\n  [#4551](https://github.com/bytecodealliance/wasmtime/pull/4551)\n\n* Source tarballs are now available as part of Wasmtime's release artifacts.\n  [#4294](https://github.com/bytecodealliance/wasmtime/pull/4294)\n\n* WASI APIs that specify the REALTIME clock are now supported.\n  [#4777](https://github.com/bytecodealliance/wasmtime/pull/4777)\n\n* WASI's socket functions are now fully implemented.\n  [#4776](https://github.com/bytecodealliance/wasmtime/pull/4776)\n\n* The native call stack for async-executed wasm functions are no longer\n  automatically reset to zero after the stack is returned to the pool when using\n  the pooling allocator. A `Config::async_stack_zeroing` option has been added\n  to restore the old behavior of zero-on-return-to-pool.\n  [#4813](https://github.com/bytecodealliance/wasmtime/pull/4813)\n\n* Inline stack probing has been implemented for the Cranelift x64 backend.\n  [#4747](https://github.com/bytecodealliance/wasmtime/pull/4747)\n\n### Changed\n\n* Generating of native unwind information has moved from a\n  `Config::wasm_backtrace` option to a new `Config::native_unwind_info` option\n  and is enabled by default.\n  [#4643](https://github.com/bytecodealliance/wasmtime/pull/4643)\n\n* The `memory-init-cow` feature is now enabled by default in the C API.\n  [#4690](https://github.com/bytecodealliance/wasmtime/pull/4690)\n\n* Back-edge CFI is now enabled by default on AArch64 macOS.\n  [#4720](https://github.com/bytecodealliance/wasmtime/pull/4720)\n\n* WASI calls will no longer return NOTCAPABLE in preparation for the removal of\n  the rights system from WASI.\n  [#4666](https://github.com/bytecodealliance/wasmtime/pull/4666)\n\n### Internal\n\nThis section of the release notes shouldn't affect external users since no\npublic-facing APIs are affected, but serves as a place to document larger\nchanges internally within Wasmtime.\n\n* Differential fuzzing has been refactored and improved into one fuzzing target\n  which can execute against any of Wasmtime itself (configured differently),\n  wasmi, V8, or the spec interpreter. Fuzzing now executes each exported\n  function with fuzz-generated inputs and the contents of all of memory and each\n  exported global is compared after each execution. Additionally more\n  interesting shapes of modules are also possible to generate.\n  [#4515](https://github.com/bytecodealliance/wasmtime/pull/4515)\n  [#4735](https://github.com/bytecodealliance/wasmtime/pull/4735)\n  [#4737](https://github.com/bytecodealliance/wasmtime/pull/4737)\n  [#4739](https://github.com/bytecodealliance/wasmtime/pull/4739)\n  [#4774](https://github.com/bytecodealliance/wasmtime/pull/4774)\n  [#4773](https://github.com/bytecodealliance/wasmtime/pull/4773)\n  [#4845](https://github.com/bytecodealliance/wasmtime/pull/4845)\n  [#4672](https://github.com/bytecodealliance/wasmtime/pull/4672)\n  [#4674](https://github.com/bytecodealliance/wasmtime/pull/4674)\n\n* The x64 backend for Cranelift has been fully migrated to ISLE.\n  [#4619](https://github.com/bytecodealliance/wasmtime/pull/4619)\n  [#4625](https://github.com/bytecodealliance/wasmtime/pull/4625)\n  [#4645](https://github.com/bytecodealliance/wasmtime/pull/4645)\n  [#4650](https://github.com/bytecodealliance/wasmtime/pull/4650)\n  [#4684](https://github.com/bytecodealliance/wasmtime/pull/4684)\n  [#4704](https://github.com/bytecodealliance/wasmtime/pull/4704)\n  [#4718](https://github.com/bytecodealliance/wasmtime/pull/4718)\n  [#4726](https://github.com/bytecodealliance/wasmtime/pull/4726)\n  [#4722](https://github.com/bytecodealliance/wasmtime/pull/4722)\n  [#4729](https://github.com/bytecodealliance/wasmtime/pull/4729)\n  [#4730](https://github.com/bytecodealliance/wasmtime/pull/4730)\n  [#4741](https://github.com/bytecodealliance/wasmtime/pull/4741)\n  [#4763](https://github.com/bytecodealliance/wasmtime/pull/4763)\n  [#4772](https://github.com/bytecodealliance/wasmtime/pull/4772)\n  [#4780](https://github.com/bytecodealliance/wasmtime/pull/4780)\n  [#4787](https://github.com/bytecodealliance/wasmtime/pull/4787)\n  [#4793](https://github.com/bytecodealliance/wasmtime/pull/4793)\n  [#4809](https://github.com/bytecodealliance/wasmtime/pull/4809)\n\n* The AArch64 backend for Cranelift has seen significant progress in being\n  ported to ISLE.\n  [#4608](https://github.com/bytecodealliance/wasmtime/pull/4608)\n  [#4639](https://github.com/bytecodealliance/wasmtime/pull/4639)\n  [#4634](https://github.com/bytecodealliance/wasmtime/pull/4634)\n  [#4748](https://github.com/bytecodealliance/wasmtime/pull/4748)\n  [#4750](https://github.com/bytecodealliance/wasmtime/pull/4750)\n  [#4751](https://github.com/bytecodealliance/wasmtime/pull/4751)\n  [#4753](https://github.com/bytecodealliance/wasmtime/pull/4753)\n  [#4788](https://github.com/bytecodealliance/wasmtime/pull/4788)\n  [#4796](https://github.com/bytecodealliance/wasmtime/pull/4796)\n  [#4785](https://github.com/bytecodealliance/wasmtime/pull/4785)\n  [#4819](https://github.com/bytecodealliance/wasmtime/pull/4819)\n  [#4821](https://github.com/bytecodealliance/wasmtime/pull/4821)\n  [#4832](https://github.com/bytecodealliance/wasmtime/pull/4832)\n\n* The s390x backend has seen improvements and additions to fully support the\n  Cranelift backend for rustc.\n  [#4682](https://github.com/bytecodealliance/wasmtime/pull/4682)\n  [#4702](https://github.com/bytecodealliance/wasmtime/pull/4702)\n  [#4616](https://github.com/bytecodealliance/wasmtime/pull/4616)\n  [#4680](https://github.com/bytecodealliance/wasmtime/pull/4680)\n\n* Significant improvements have been made to Cranelift-based fuzzing with more\n  supported features and more instructions being fuzzed.\n  [#4589](https://github.com/bytecodealliance/wasmtime/pull/4589)\n  [#4591](https://github.com/bytecodealliance/wasmtime/pull/4591)\n  [#4665](https://github.com/bytecodealliance/wasmtime/pull/4665)\n  [#4670](https://github.com/bytecodealliance/wasmtime/pull/4670)\n  [#4590](https://github.com/bytecodealliance/wasmtime/pull/4590)\n  [#4375](https://github.com/bytecodealliance/wasmtime/pull/4375)\n  [#4519](https://github.com/bytecodealliance/wasmtime/pull/4519)\n  [#4696](https://github.com/bytecodealliance/wasmtime/pull/4696)\n  [#4700](https://github.com/bytecodealliance/wasmtime/pull/4700)\n  [#4703](https://github.com/bytecodealliance/wasmtime/pull/4703)\n  [#4602](https://github.com/bytecodealliance/wasmtime/pull/4602)\n  [#4713](https://github.com/bytecodealliance/wasmtime/pull/4713)\n  [#4738](https://github.com/bytecodealliance/wasmtime/pull/4738)\n  [#4667](https://github.com/bytecodealliance/wasmtime/pull/4667)\n  [#4782](https://github.com/bytecodealliance/wasmtime/pull/4782)\n  [#4783](https://github.com/bytecodealliance/wasmtime/pull/4783)\n  [#4800](https://github.com/bytecodealliance/wasmtime/pull/4800)\n\n* Optimization work on cranelift has continued across various dimensions for\n  some modest compile-time improvements.\n  [#4621](https://github.com/bytecodealliance/wasmtime/pull/4621)\n  [#4701](https://github.com/bytecodealliance/wasmtime/pull/4701)\n  [#4697](https://github.com/bytecodealliance/wasmtime/pull/4697)\n  [#4711](https://github.com/bytecodealliance/wasmtime/pull/4711)\n  [#4710](https://github.com/bytecodealliance/wasmtime/pull/4710)\n  [#4829](https://github.com/bytecodealliance/wasmtime/pull/4829)\n\n--------------------------------------------------------------------------------\n\n## 0.40.0\n\nReleased 2022-08-20\n\nThis was a relatively quiet release in terms of user-facing features where most\nof the work was around the internals of Wasmtime and Cranelift. Improvements\ninternally have been made along the lines of:\n\n* Many more instructions are now implemented with ISLE instead of handwritten\n  lowerings.\n* Many improvements to the cranelift-based fuzzing.\n* Many platform improvements for s390x including full SIMD support, running\n  `rustc_codegen_cranelift` with features like `i128`, supporting more\n  ABIs, etc.\n* Much more of the component model has been implemented and is now fuzzed.\n\nFinally this release is currently scheduled to be the last `0.*` release of\nWasmtime. The upcoming release of Wasmtime on September 20 is planned to be\nWasmtime's 1.0 release. More information about what 1.0 means for Wasmtime is\navailable in the [1.0 RFC]\n\n[1.0 RFC]: https://github.com/bytecodealliance/rfcs/blob/main/accepted/wasmtime-one-dot-oh.md\n\n### Added\n\n* Stack walking has been reimplemented with frame pointers rather than with\n  native unwind information. This means that backtraces are feasible to capture\n  in performance-critical environments and in general stack walking is much\n  faster than before.\n  [#4431](https://github.com/bytecodealliance/wasmtime/pull/4431)\n\n* The WebAssembly `simd` proposal is now fully implemented for the s390x\n  backend.\n  [#4427](https://github.com/bytecodealliance/wasmtime/pull/4427)\n\n* Support for AArch64 has been added in the experimental native debuginfo\n  support that Wasmtime has.\n  [#4468](https://github.com/bytecodealliance/wasmtime/pull/4468)\n\n* Support building the C API of Wasmtime with CMake has been added.\n  [#4369](https://github.com/bytecodealliance/wasmtime/pull/4369)\n\n* Clarification was added to Wasmtime's documentation about \"tiers of support\"\n  for various features.\n  [#4479](https://github.com/bytecodealliance/wasmtime/pull/4479)\n\n### Fixed\n\n* Support for `filestat_get` has been improved for stdio streams in WASI.\n  [#4531](https://github.com/bytecodealliance/wasmtime/pull/4531)\n\n* Enabling the `vtune` feature no longer breaks builds on AArch64.\n  [#4533](https://github.com/bytecodealliance/wasmtime/pull/4533)\n\n--------------------------------------------------------------------------------\n\n## 0.39.1\n\nReleased 2022-07-20.\n\n### Fixed\n\n* An s390x-specific codegen bug in addition to a mistake introduced in the fix\n  of CVE-2022-31146 were fixed.\n  [#4490](https://github.com/bytecodealliance/wasmtime/pull/4490)\n\n--------------------------------------------------------------------------------\n\n## 0.39.0\n\nReleased 2022-07-20\n\n### Added\n\n* Initial support for shared memories and the `threads` WebAssembly proposal\n  has been added. Note that this feature is still experimental and not ready\n  for production use yet.\n  [#4187](https://github.com/bytecodealliance/wasmtime/pull/4187)\n\n* A new `Linker::define_unknown_imports_as_traps` method and\n  `--trap-unknown-imports` CLI flag have been added to conveniently support\n  running modules with imports that aren't dynamically called at runtime.\n  [#4312](https://github.com/bytecodealliance/wasmtime/pull/4312)\n\n* The VTune profiling strategy can now be selected through the C API.\n  [#4316](https://github.com/bytecodealliance/wasmtime/pull/4316)\n\n### Changed\n\n* Some methods on the `Config` structure now return `&mut Self` instead of\n  `Result<&mut Self>` since the validation is deferred until `Engine::new`:\n  `profiler`, `cranelift_flag_enable`, `cranelift_flag_set`, `max_wasm_stack`,\n  `async_stack_size`, and `strategy`.\n  [#4252](https://github.com/bytecodealliance/wasmtime/pull/4252)\n  [#4262](https://github.com/bytecodealliance/wasmtime/pull/4262)\n\n* Parallel compilation of WebAssembly modules is now enabled in the C API by\n  default.\n  [#4270](https://github.com/bytecodealliance/wasmtime/pull/4270)\n\n* Implicit Cargo features of the `wasmtime` introduced through `optional`\n  dependencies may have been removed since namespaced features are now used.\n  It's recommended to only used the set of named `[features]` for Wasmtime.\n  [#4293](https://github.com/bytecodealliance/wasmtime/pull/4293)\n\n* Register allocation has fixed a few issues related to excessive memory usage\n  at compile time.\n  [#4324](https://github.com/bytecodealliance/wasmtime/pull/4324)\n\n### Fixed\n\n* A refactor of `Config` was made to fix an issue that the order of calls to `Config`\n  matters now, which may lead to unexpected behavior.\n  [#4252](https://github.com/bytecodealliance/wasmtime/pull/4252)\n  [#4262](https://github.com/bytecodealliance/wasmtime/pull/4262)\n\n* Wasmtime has been fixed to work on SSE2-only x86\\_64 platforms when the\n  `simd` feature is disabled in `Config`.\n  [#4231](https://github.com/bytecodealliance/wasmtime/pull/4231)\n\n* Generation of platform-specific unwinding information is disabled if\n  `wasm_backtrace` and `wasm_reference_types` are both disabled.\n  [#4351](https://github.com/bytecodealliance/wasmtime/pull/4351)\n\n--------------------------------------------------------------------------------\n\n## 0.38.3\n\nReleased 2022-07-20.\n\n### Fixed.\n\n* An s390x-specific codegen bug in addition to a mistake introduced in the fix\n  of CVE-2022-31146 were fixed.\n  [#4491](https://github.com/bytecodealliance/wasmtime/pull/4491)\n\n--------------------------------------------------------------------------------\n\n## 0.38.2\n\nReleased 2022-07-20.\n\n### Fixed.\n\n* A miscompilation when handling constant divisors on AArch64 has been fixed.\n  [CVE-2022-31169](https://github.com/bytecodealliance/wasmtime/security/advisories/GHSA-7f6x-jwh5-m9r4)\n\n* A use-after-free possible with accidentally missing stack maps has been fixed.\n  [CVE-2022-31146](https://github.com/bytecodealliance/wasmtime/security/advisories/GHSA-5fhj-g3p3-pq9g)\n\n--------------------------------------------------------------------------------\n\n## 0.38.1\n\nReleased 2022-06-27.\n\n### Fixed.\n\n* A register allocator bug was fixed that could affect direct users of\n  Cranelift who use struct-return (`sret`) arguments. The bug had to do with\n  the handling of physical register constraints in the function prologue. No\n  impact should be possible for users of Cranelift via the Wasm frontend,\n  including Wasmtime.\n  [regalloc2#60](https://github.com/bytecodealliance/regalloc2/pull/60)\n  [#4333](https://github.com/bytecodealliance/wasmtime/pull/4333)\n\n* Lowering bugs for the `i8x16.swizzle` and `select`-with-`v128`-inputs\n  instructions were fixed for the x86\\_64 code generator. Note that aarch64 and\n  s390x are unaffected.\n  [#4334](https://github.com/bytecodealliance/wasmtime/pull/4334)\n\n* A bug in the 8-bit lowering of integer division on x86-64 was fixed in\n  Cranelift that could cause a register allocator panic due to an undefined\n  value in a register. (The divide instruction does not take a register `rdx`\n  as a source when 8 bits but the metadata incorrectly claimed it did.) No\n  impact on Wasm/Wasmtime users, and impact on direct Cranelift embedders\n  limited to compilation panics.\n  [#4332](https://github.com/bytecodealliance/wasmtime/pull/4332)\n\n--------------------------------------------------------------------------------\n\n## 0.38.0\n\nReleased 2022-06-21\n\n### Added\n\n* Enabling or disabling NaN canonicalization in generated code is now exposed\n  through the C API.\n  [#4154](https://github.com/bytecodealliance/wasmtime/pull/4154)\n\n* A user-defined callback can now be invoked when an epoch interruption happens\n  via the `Store::epoch_deadline_callback` API.\n  [#4152](https://github.com/bytecodealliance/wasmtime/pull/4152)\n\n* Basic alias analysis with redundant-load elimintation and store-to-load\n  forwarding optimizations has been added to Cranelift.\n  [#4163](https://github.com/bytecodealliance/wasmtime/pull/4163)\n\n### Changed\n\n* Traps originating from epoch-based interruption are now exposed as\n  `TrapCode::Interrupt`.\n  [#4105](https://github.com/bytecodealliance/wasmtime/pull/4105)\n\n* Binary builds for AArch64 now require glibc 2.17 and for s390x require glibc\n  2.16. Previously glibc 2.28 was required.\n  [#4171](https://github.com/bytecodealliance/wasmtime/pull/4171)\n\n* The `wasmtime::ValRaw` now has all of its fields listed as private and instead\n  constructors/accessors are provided for getting at the internal data.\n  [#4186](https://github.com/bytecodealliance/wasmtime/pull/4186)\n\n* The `wasm-backtrace` Cargo feature has been removed in favor of a\n  `Config::wasm_backtrace` runtime configuration option. Additionally backtraces\n  are now only captured when an embedder-generated trap actually reaches a\n  WebAssembly call stack.\n  [#4183](https://github.com/bytecodealliance/wasmtime/pull/4183)\n\n* Usage of `*_unchecked` APIs for `Func` in the `wasmtime` crate and C API now\n  take a `usize` parameter indicating the number of `ValRaw` values behind\n  the associated pointer.\n  [#4192](https://github.com/bytecodealliance/wasmtime/pull/4192)\n\n### Fixed\n\n* An improvement was made to the spill-slot allocation in code generation to fix\n  an issue where some stack slots accidentally weren't reused. This issue was\n  introduced with the landing of regalloc2 in 0.37.0 and may have resulted in\n  larger-than-intended increases in stack frame sizes.\n  [#4222](https://github.com/bytecodealliance/wasmtime/pull/4222)\n\n--------------------------------------------------------------------------------\n\n## 0.37.0\n\nReleased 2022-05-20\n\n### Added\n\n* Updated Cranelift to use regalloc2, a new register allocator. This should\n  result in ~20% faster compile times, and for programs that suffered from\n  register-allocation pressure before, up to ~20% faster generated code.\n  [#3989](https://github.com/bytecodealliance/wasmtime/pull/3989)\n\n* Pre-built binaries for macOS M1 machines are now available as release\n  artifacts.\n  [#3983](https://github.com/bytecodealliance/wasmtime/pull/3983)\n\n* Copy-on-write images of memory can now be manually initialized for a `Module`\n  with an explicit method call, but it is still not required to call this method\n  and will automatically otherwise happen on the first instantiation.\n  [#3964](https://github.com/bytecodealliance/wasmtime/pull/3964)\n\n### Fixed\n\n* Using `InstancePre::instantiate` or `Linker::instantiate` will now panic as\n  intended when used with an async-configured `Store`.\n  [#3972](https://github.com/bytecodealliance/wasmtime/pull/3972)\n\n### Changed\n\n* The unsafe `ValRaw` type in the `wasmtime` crate now always stores its values\n  in little-endian format instead of the prior native-endian format. Users of\n  `ValRaw` are recommended to audit their existing code for usage to continue\n  working on big-endian platforms.\n  [#4035](https://github.com/bytecodealliance/wasmtime/pull/4035)\n\n### Removed\n\n* Support for `Config::paged_memory_initialization` and the `uffd` crate feature\n  have been removed from the `wasmtime` crate. Users should migrate to using\n  `Config::memory_init_cow` which is more portable and faster at this point.\n  [#4040](https://github.com/bytecodealliance/wasmtime/pull/4040)\n\n--------------------------------------------------------------------------------\n\n## 0.36.0\n\nReleased 2022-04-20\n\n### Added\n\n* Support for epoch-based interruption has been added to the C API.\n  [#3925](https://github.com/bytecodealliance/wasmtime/pull/3925)\n\n* Support for disabling libunwind-based backtraces of WebAssembly code at\n  compile time has been added.\n  [#3932](https://github.com/bytecodealliance/wasmtime/pull/3932)\n\n* Async support for call hooks has been added to optionally execute \"blocking\"\n  work whenever a wasm module is entered or exited relative to the host.\n  [#3876](https://github.com/bytecodealliance/wasmtime/pull/3876)\n\n### Fixed\n\n* Loading a `Module` will now check, at runtime, that the compilation settings\n  enabled in a `Config` are compatible with the native host. For example this\n  ensures that if avx2 is enabled that the host actually has avx2 support.\n  [#3899](https://github.com/bytecodealliance/wasmtime/pull/3899)\n\n### Removed\n\n* Support for `Config::interruptable` and `InterruptHandle` has been removed\n  from the `wasmtime` crate. Users should migrate to using epoch-based\n  interruption instead.\n  [#3925](https://github.com/bytecodealliance/wasmtime/pull/3925)\n\n* The module linking implementation of Wasmtime has been removed to make room\n  for the upcoming support for the component model.\n  [#3958](https://github.com/bytecodealliance/wasmtime/pull/3958)\n\n--------------------------------------------------------------------------------\n\n## 0.35.3\n\nReleased 2022-04-11.\n\n### Fixed\n\n* Backported a bugfix for an instruction lowering issue that could cause a\n  regalloc panic due to an undefined register in some cases. No miscompilation\n  was ever possible, but panics would result in a compilation failure.\n  [#4012](https://github.com/bytecodealliance/wasmtime/pull/4012)\n\n--------------------------------------------------------------------------------\n\n## 0.35.2\n\nReleased 2022-03-31.\n\n### Security Fixes\n\n* [CVE-2022-24791](https://github.com/bytecodealliance/wasmtime/security/advisories/GHSA-gwc9-348x-qwv2):\n  Fixed a use after free with `externref`s and epoch interruption.\n\n## 0.35.1\n\nReleased 2022-03-09.\n\n### Fixed\n\n* Fixed a bug in the x86-64 lowering of the `uextend` opcode for narrow (`i8`,\n  `i16`) integer sources when the value is produced by one of several\n  arithmetic instructions.\n  [#3906](https://github.com/bytecodealliance/wasmtime/pull/3906)\n\n## 0.35.0\n\nReleased 2022-03-07.\n\n### Added\n\n* The `wasmtime_wasi::add_to_linker` function now allows providing\n  a context object of a custom type instead of `wasmtime_wasi::WasiCtx`,\n  as long as that type implements the required WASI snapshot traits.\n  This allows, for example, wrapping `WasiCtx` into a struct and providing\n  custom implementations for those traits to override the default behaviour.\n\n### Changed\n\n* WebAssembly tables of `funcref` values are now lazily initialized which can,\n  in some cases, greatly speed up instantiation of a module.\n  [#3733](https://github.com/bytecodealliance/wasmtime/pull/3733)\n\n* The `memfd` feature in 0.34.0, now renamed to `memory-init-cow`, has been\n  enabled by default. This means that, where applicable, WebAssembly linear\n  memories are now initialized with copy-on-write mappings. Support from this\n  has been expanded from Linux-only to include macOS and other Unix systems when\n  modules are loaded from precompiled `*.cwasm` files on disk.\n  [#3777](https://github.com/bytecodealliance/wasmtime/pull/3777)\n  [#3778](https://github.com/bytecodealliance/wasmtime/pull/3778)\n  [#3787](https://github.com/bytecodealliance/wasmtime/pull/3787)\n  [#3819](https://github.com/bytecodealliance/wasmtime/pull/3819)\n  [#3831](https://github.com/bytecodealliance/wasmtime/pull/3831)\n\n* Clarify that SSE 4.2 (and prior) is required for running WebAssembly code with\n  simd support enabled on x86\\_64.\n  [#3816](https://github.com/bytecodealliance/wasmtime/pull/3816)\n  [#3817](https://github.com/bytecodealliance/wasmtime/pull/3817)\n  [#3833](https://github.com/bytecodealliance/wasmtime/pull/3833)\n  [#3825](https://github.com/bytecodealliance/wasmtime/pull/3825)\n\n* Support for profiling with VTune is now enabled at compile time by default,\n  but it remains disabled at runtime by default.\n  [#3821](https://github.com/bytecodealliance/wasmtime/pull/3821)\n\n* The `ModuleLimits` type has been removed from the configuration of the pooling\n  allocator in favor of configuring the total size of an instance allocation\n  rather than each individual field.\n  [#3837](https://github.com/bytecodealliance/wasmtime/pull/3837)\n\n* The native stack size allowed for WebAssembly has been decreased from 1 MiB to\n  512 KiB on all platforms to better accomodate running wasm on the main thread\n  on Windows.\n  [#3861](https://github.com/bytecodealliance/wasmtime/pull/3861)\n\n* The `wasi-common` crate now supports doing polls for both read and write\n  interest on a file descriptor at the same time.\n  [#3866](https://github.com/bytecodealliance/wasmtime/pull/3866)\n\n### Fixed\n\n* The `Store::call_hook` callback is now invoked when entering host functions\n  defined with `*_unchecked` variants.\n  [#3881](https://github.com/bytecodealliance/wasmtime/pull/3881)\n\n### Removed\n\n* The incomplete and unmaintained ARM32 backend has been removed from Cranelift.\n  [#3799](https://github.com/bytecodealliance/wasmtime/pull/3799)\n\n--------------------------------------------------------------------------------\n\n## 0.34.2\n\nReleased 2022-03-31.\n\n### Security Fixes\n\n* [CVE-2022-24791](https://github.com/bytecodealliance/wasmtime/security/advisories/GHSA-gwc9-348x-qwv2):\n  Fixed a use after free with `externref`s and epoch interruption.\n\n## 0.34.1\n\nReleased 2022-02-16.\n\n### Security Fixes\n\n* [CVE-2022-23636](https://github.com/bytecodealliance/wasmtime/security/advisories/GHSA-88xq-w8cq-xfg7):\n  Fixed an invalid drop of a partially-initialized instance in the pooling instance\n  allocator.\n\n## 0.33.1\n\nReleased 2022-02-16.\n\n### Security Fixes\n\n* [CVE-2022-23636](https://github.com/bytecodealliance/wasmtime/security/advisories/GHSA-88xq-w8cq-xfg7):\n  Fixed an invalid drop of a partially-initialized instance in the pooling instance\n  allocator.\n\n## 0.34.0\n\nReleased 2022-02-07.\n\n### Fixed\n\n* The `wasi-common` default implementation of some attributes of files has been\n  updated to ensure that `wasi-libc`'s `isatty` function works as intended.\n  [#3696](https://github.com/bytecodealliance/wasmtime/pull/3696)\n\n* A benign debug assertion related to `externref` and garbage-collection has\n  been fixed.\n  [#3734](https://github.com/bytecodealliance/wasmtime/pull/3734)\n\n### Added\n\n* Function names are now automatically demangled when informing profilers of\n  regions of JIT code to apply Rust-specific demangling rules if applicable.\n  [#3683](https://github.com/bytecodealliance/wasmtime/pull/3683)\n\n* Support for profiling JIT-generated trampolines with VTune has been added.\n  [#3687](https://github.com/bytecodealliance/wasmtime/pull/3687)\n\n* Wasmtime now supports a new method of async preemption dubbed \"epoch-based\n  interruption\" which is intended to be much more efficient than the current\n  fuel-based method of preemption.\n  [#3699](https://github.com/bytecodealliance/wasmtime/pull/3699)\n\n* On Linux Wasmtime will now by default use copy-on-write mappings to initialize\n  memories of wasm modules where possible, accelerating instantiation by\n  avoiding costly memory copies. When combined with the pooling allocator this\n  can also be used to speed up instance-reuse cases due to fewer syscalls to\n  change memory mappings being necessary.\n  [#3697](https://github.com/bytecodealliance/wasmtime/pull/3697)\n  [#3738](https://github.com/bytecodealliance/wasmtime/pull/3738)\n  [#3760](https://github.com/bytecodealliance/wasmtime/pull/3760)\n\n* Wasmtime now supports the recently-added `sock_accept` WASI function.\n  [#3711](https://github.com/bytecodealliance/wasmtime/pull/3711)\n\n* Cranelift now has support for specifying blocks as cold.\n  [#3698](https://github.com/bytecodealliance/wasmtime/pull/3698)\n\n### Changed\n\n* Many more instructions for the x64 backend have been migrated to ISLE,\n  additionally with refactorings to make incorrect lowerings harder to\n  accidentally write.\n  [#3653](https://github.com/bytecodealliance/wasmtime/pull/3653)\n  [#3659](https://github.com/bytecodealliance/wasmtime/pull/3659)\n  [#3681](https://github.com/bytecodealliance/wasmtime/pull/3681)\n  [#3686](https://github.com/bytecodealliance/wasmtime/pull/3686)\n  [#3688](https://github.com/bytecodealliance/wasmtime/pull/3688)\n  [#3690](https://github.com/bytecodealliance/wasmtime/pull/3690)\n  [#3752](https://github.com/bytecodealliance/wasmtime/pull/3752)\n\n* More instructions in the aarch64 backend are now lowered with ISLE.\n  [#3658](https://github.com/bytecodealliance/wasmtime/pull/3658)\n  [#3662](https://github.com/bytecodealliance/wasmtime/pull/3662)\n\n* The s390x backend's lowering rules are now almost entirely defined with ISLE.\n  [#3702](https://github.com/bytecodealliance/wasmtime/pull/3702)\n  [#3703](https://github.com/bytecodealliance/wasmtime/pull/3703)\n  [#3706](https://github.com/bytecodealliance/wasmtime/pull/3706)\n  [#3717](https://github.com/bytecodealliance/wasmtime/pull/3717)\n  [#3723](https://github.com/bytecodealliance/wasmtime/pull/3723)\n  [#3724](https://github.com/bytecodealliance/wasmtime/pull/3724)\n\n* Instantiation of modules in Wasmtime has been further optimized now that the\n  copy-on-write memory initialization removed the previously most-expensive part\n  of instantiating a module.\n  [#3727](https://github.com/bytecodealliance/wasmtime/pull/3727)\n  [#3739](https://github.com/bytecodealliance/wasmtime/pull/3739)\n  [#3741](https://github.com/bytecodealliance/wasmtime/pull/3741)\n  [#3742](https://github.com/bytecodealliance/wasmtime/pull/3742)\n\n--------------------------------------------------------------------------------\n\n## 0.33.0\n\nReleased 2022-01-05.\n\n### Added\n\n* Compiled wasm modules may now optionally omit debugging information about\n  mapping addresses to source locations, resulting in smaller binaries.\n  [#3598](https://github.com/bytecodealliance/wasmtime/pull/3598)\n\n* The WebAssembly SIMD proposal is now enabled by default.\n  [#3601](https://github.com/bytecodealliance/wasmtime/pull/3601)\n\n--------------------------------------------------------------------------------\n\n## 0.32.1\n\nReleased 2022-01-04.\n\n### Fixed\n\n* Cranelift: remove recently-added build dependency on `sha2` to allow usage in\n  some dependency-sensitive environments, by computing ISLE manifest hashes\n  with a different hash function.\n  [#3619](https://github.com/bytecodealliance/wasmtime/pull/3619)\n\n* Cranelift: fixed 8- and 16-bit behavior of popcount (bit population count)\n  instruction. Does not affect Wasm frontend.\n  [#3617](https://github.com/bytecodealliance/wasmtime/pull/3617)\n\n* Cranelift: fixed miscompilation of 8- and 16-bit bit-rotate instructions.\n  Does not affect Wasm frontend.\n  [#3610](https://github.com/bytecodealliance/wasmtime/pull/3610)\n\n--------------------------------------------------------------------------------\n\n## 0.32.0\n\nReleased 2021-12-13.\n\n### Added\n\n* A new configuration option has been added to force using a \"static\" memory\n  style to automatically limit growth of memories in some configurations.\n  [#3503](https://github.com/bytecodealliance/wasmtime/pull/3503)\n\n* The `InstancePre<T>` type now implements `Clone`.\n  [#3510](https://github.com/bytecodealliance/wasmtime/pull/3510)\n\n* Cranelift's instruction selection process has begun to be migrated towards the\n  ISLE compiler and definition language.\n  [#3506](https://github.com/bytecodealliance/wasmtime/pull/3506)\n\n* A `pooling-allocator` feature has been added, which is on-by-default, to\n  disable the pooling allocator at compile time.\n  [#3514](https://github.com/bytecodealliance/wasmtime/pull/3514)\n\n### Fixed\n\n* A possible panic when parsing a WebAssembly `name` section has been fixed.\n  [#3509](https://github.com/bytecodealliance/wasmtime/pull/3509)\n\n* Generating native DWARF information for some C-produced modules has been\n  fixed, notably those where there may be DWARF about dead code.\n  [#3498](https://github.com/bytecodealliance/wasmtime/pull/3498)\n\n* A number of SIMD code generation bugs have been fixed in the x64 backend\n  by migrating their lowerings to ISLE.\n\n--------------------------------------------------------------------------------\n\n## 0.31.0\n\nReleased 2021-10-29.\n\n### Added\n\n* New `Func::new_unchecked` and `Func::call_unchecked` APIs have been added with\n  accompanying functions in the C API to improve the performance of calls into\n  wasm and the host in the C API.\n  [#3350](https://github.com/bytecodealliance/wasmtime/pull/3350)\n\n* Release binaries are now available for the s390x-unknown-linux-gnu\n  architecture.\n  [#3372](https://github.com/bytecodealliance/wasmtime/pull/3372)\n\n* A new `ResourceLimiterAsync` trait is added which allows asynchronous blocking\n  of WebAssembly on instructions such as `memory.grow`.\n  [#3393](https://github.com/bytecodealliance/wasmtime/pull/3393)\n\n### Changed\n\n* The `Func::call` method now takes a slice to write the results into rather\n  than returning a boxed slice.\n  [#3319](https://github.com/bytecodealliance/wasmtime/pull/3319)\n\n* Trampolines are now covered when jitdump profiling is enabled.\n  [#3344](https://github.com/bytecodealliance/wasmtime/pull/3344)\n\n### Fixed\n\n* Debugging with GDB has been fixed on Windows.\n  [#3373](https://github.com/bytecodealliance/wasmtime/pull/3373)\n\n* Some quadradic behavior in Wasmtime's compilation of modules has been fixed.\n  [#3469](https://github.com/bytecodealliance/wasmtime/pull/3469)\n  [#3466](https://github.com/bytecodealliance/wasmtime/pull/3466)\n\n* Bounds-checks for wasm memory accesses in certain non-default configurations\n  have been fixed to correctly allow loads at the end of the address space.\n  [#3462](https://github.com/bytecodealliance/wasmtime/pull/3462)\n\n* When type-checking memories and tables for satisfying instance imports the\n  runtime size of the table/memory is now consulted instead of the object's\n  original type.\n  [#3450](https://github.com/bytecodealliance/wasmtime/pull/3450)\n\n### Removed\n\n* The Lightbeam backend has been removed, as per [RFC 14].\n  [#3390](https://github.com/bytecodealliance/wasmtime/pull/3390)\n\n[RFC 14]: https://github.com/bytecodealliance/rfcs/pull/14\n\n* Cranelift's old x86 backend has been removed, as per [RFC 12].\n  [#3309](https://github.com/bytecodealliance/wasmtime/pull/3009)\n\n[RFC 12]: https://github.com/bytecodealliance/rfcs/pull/12\n\n## 0.30.0\n\nReleased 2021-09-17.\n\n### Security Fixes\n\n* [CVE-2021-39216](https://github.com/bytecodealliance/wasmtime/security/advisories/GHSA-v4cp-h94r-m7xf):\n  Fixed a use after free passing `externref`s to Wasm in Wasmtime.\n\n* [CVE-2021-39218](https://github.com/bytecodealliance/wasmtime/security/advisories/GHSA-4873-36h9-wv49):\n  Fixed an out-of-bounds read/write and invalid free with `externref`s and GC\n  safepoints in Wasmtime.\n\n* [CVE-2021-39219](https://github.com/bytecodealliance/wasmtime/security/advisories/GHSA-q879-9g95-56mx):\n  Fixed a bug where using two different `Engine`s with the same `Linker`-define\n  functions caused unsafety without `unsafe` blocks.\n\n### Added\n\n* Added experimental support for the in-progress 64-bit memories Wasm proposal.\n\n* Added support to build Wasmtime without the compiler. This lets you run\n  pre-compiled Wasm modules, without the ability (or potential attack surface)\n  of compiling new Wasm modules. The compilation functionality is gated by the\n  on-by-default `cranelift` cargo feature.\n\n* Added support for NaN canonicalization with SIMD vectors.\n\n* Added support for differential fuzzing against V8's Wasm engine.\n\n* Added support for fuzzing against the Wasm spec interpreter.\n\n* Enabled SIMD fuzzing on oss-fuzz.\n\n### Changed\n\n* A variety of performance improvements to loading pre-compiled modules.\n\n* A variety of performance improvements to function calls, both through Rust and\n  the C API.\n\n* Leaf functions that do not use the stack no longer bump the frame pointer on\n  aarch64 and s390x.\n\n* Many updates and expanded instruction support to the in-progress CLIF\n  interpreter.\n\n* Expanded fuzzing of reference types and GC.\n\n### Fixed\n\n* A number of fixes to both aarch64 and x86_64 support for the Wasm SIMD\n  proposal and the underlying CLIF vector instructions.\n\n* Fixed a potential infinite loop in the SSA computation for\n  `cranelift-frontend`. This was not reachable from `cranelift-wasm` or\n  Wasmtime, but might have affected general Cranelift users.\n\n### Removed\n\n* The `wasmtime wasm2obj` subcommand has been removed. Generating raw object\n  files for linking natively is no longer supported. Use the `wasmtime compile`\n  subcommand to pre-compile a Wasm module and `wasmtime run` to run pre-compiled\n  Wasm modules.\n\n## 0.29.0\n\nReleased 2021-08-02.\n\n### Changed\n\n* Instance exports are now loaded lazily from instances instead of eagerly as\n  they were before. This is an internal-only change and is not a breaking\n  change.\n  [#2984](https://github.com/bytecodealliance/wasmtime/pull/2984)\n\n* All linear memories created by Wasmtime will now, by default, have guard pages\n  in front of them in addition to after them. This is intended to help mitigate\n  future bugs in Cranelift, should they arise.\n  [#2977](https://github.com/bytecodealliance/wasmtime/pull/2977)\n\n* Linear memories now correctly support a maximum size of 4GB. Previously, the\n  limit field was 32 bits, which did not properly support a full 4GB memory.\n  This update is also a necessary change in preparation for future memory64\n  support.\n  [#3013](https://github.com/bytecodealliance/wasmtime/pull/3013)\n  [#3134](https://github.com/bytecodealliance/wasmtime/pull/3134)\n\n* Injection counts of fuel into a `wasmtime::Store` now uses a u64 instead of a\n  u32.\n  [#3048](https://github.com/bytecodealliance/wasmtime/pull/3048)\n\n### Added\n\n* Support for `i128` has improved in the AArch64 backend.\n  [#2959](https://github.com/bytecodealliance/wasmtime/pull/2959)\n  [#2975](https://github.com/bytecodealliance/wasmtime/pull/2975)\n  [#2985](https://github.com/bytecodealliance/wasmtime/pull/2985)\n  [#2990](https://github.com/bytecodealliance/wasmtime/pull/2990)\n  [#3002](https://github.com/bytecodealliance/wasmtime/pull/3002)\n  [#3004](https://github.com/bytecodealliance/wasmtime/pull/3004)\n  [#3005](https://github.com/bytecodealliance/wasmtime/pull/3005)\n  [#3008](https://github.com/bytecodealliance/wasmtime/pull/3008)\n  [#3027](https://github.com/bytecodealliance/wasmtime/pull/3027)\n\n* The s390x backend now supports z14 and atomics.\n  [#2988](https://github.com/bytecodealliance/wasmtime/pull/2988)\n  [#2991](https://github.com/bytecodealliance/wasmtime/pull/2991)\n\n* The `wasmtime::Linker` type now implements `Clone`.\n  [#2993](https://github.com/bytecodealliance/wasmtime/pull/2993)\n\n* Support for the SIMD proposal on both x86\\_64 and AArch64 has improved. On\n  x86\\_64, all SIMD opcodes are now supported.\n  [#2997](https://github.com/bytecodealliance/wasmtime/pull/2997)\n  [#3035](https://github.com/bytecodealliance/wasmtime/pull/3035)\n  [#2982](https://github.com/bytecodealliance/wasmtime/pull/2982)\n  [#3084](https://github.com/bytecodealliance/wasmtime/pull/3084)\n  [#3082](https://github.com/bytecodealliance/wasmtime/pull/3082)\n  [#3107](https://github.com/bytecodealliance/wasmtime/pull/3107)\n  [#3105](https://github.com/bytecodealliance/wasmtime/pull/3105)\n  [#3114](https://github.com/bytecodealliance/wasmtime/pull/3114)\n  [#3070](https://github.com/bytecodealliance/wasmtime/pull/3070)\n  [#3126](https://github.com/bytecodealliance/wasmtime/pull/3126)\n\n* A `Trap` can now display its reason without also displaying the backtrace.\n  [#3033](https://github.com/bytecodealliance/wasmtime/pull/3033)\n\n* An initiall fuzzer for CLIF has been added.\n  [#3038](https://github.com/bytecodealliance/wasmtime/pull/3038)\n\n* High-level architecture documentation has been added for Wasmtime.\n  [#3019](https://github.com/bytecodealliance/wasmtime/pull/3019)\n\n* Support for multi-memory can now be configured in Wasmtime's C API.\n  [#3071](https://github.com/bytecodealliance/wasmtime/pull/3071)\n\n* The `wasmtime` crate now supports a `posix-signals-on-macos` feature to force\n  the usage of signals instead of mach ports to handle traps on macOS.\n  [#3063](https://github.com/bytecodealliance/wasmtime/pull/3063)\n\n* Wasmtime's C API now has a `wasmtime_trap_code` function to get the raw trap\n  code, if present, for a trap.\n  [#3086](https://github.com/bytecodealliance/wasmtime/pull/3086)\n\n* Wasmtime's C API now has a `wasmtime_linker_define_func` function to define a\n  store-independent function within a linker.\n  [#3122](https://github.com/bytecodealliance/wasmtime/pull/3122)\n\n* A `wasmtime::Linker::module_async` function was added as the asynchronous\n  counterpart to `wasmtime::Linker::module`.\n  [#3121](https://github.com/bytecodealliance/wasmtime/pull/3121)\n\n### Fixed\n\n* Compiling the `wasmtime` crate into a `dylib` crate type has been fixed.\n  [#3010](https://github.com/bytecodealliance/wasmtime/pull/3010)\n\n* The enter/exit hooks for WebAssembly are now executed for an instance's\n  `start` function, if present.\n  [#3001](https://github.com/bytecodealliance/wasmtime/pull/3001)\n\n* Some WASI functions in `wasi-common` have been fixed for big-endian platforms.\n  [#3016](https://github.com/bytecodealliance/wasmtime/pull/3016)\n\n* Wasmtime no longer erroneously assumes that all custom sections may contain\n  DWARF information, reducing instances of `Trap`'s `Display` implementation\n  providing misleading information to set an env var to get more information.\n  [#3083](https://github.com/bytecodealliance/wasmtime/pull/3083)\n\n* Some issues with parsing DWARF debug information have been fixed.\n  [#3116](https://github.com/bytecodealliance/wasmtime/pull/3116)\n\n## 0.28.0\n\nReleased 2021-06-09.\n\n### Changed\n\n* Breaking: Wasmtime's embedding API has been redesigned, as specified in [RFC\n  11]. Rust users can now enjoy easier times with `Send` and `Sync`, and all\n  users can now more clearly manage memory, especially in the C API. Language\n  embeddings have been updated to the new API as well.\n  [#2897](https://github.com/bytecodealliance/wasmtime/pull/2897)\n\n[RFC 11]: https://github.com/bytecodealliance/rfcs/pull/11\n\n### Added\n\n* A new `InstancePre` type, created with `Linker::instantiate_pre`, has been\n  added to perform type-checking of an instance once and reduce the work done\n  for each instantiation of a module:\n  [#2962](https://github.com/bytecodealliance/wasmtime/pull/2962)\n\n* Deserialization of a module can now optionally skip checking the wasmtime\n  version string:\n  [#2945](https://github.com/bytecodealliance/wasmtime/pull/2945)\n\n* A method has been exposed to frontload per-thread initialization costs if the\n  latency of every last wasm call is important:\n  [#2946](https://github.com/bytecodealliance/wasmtime/pull/2946)\n\n* Hooks have been added for entry/exit into wasm code to allow embeddings to\n  track time and other properties about execution in a wasm environment:\n  [#2952](https://github.com/bytecodealliance/wasmtime/pull/2952)\n\n* A [C++ embedding of Wasmtime has been written][cpp].\n\n[RFC 11]: https://github.com/bytecodealliance/rfcs/pull/11\n[cpp]: https://github.com/bytecodealliance/wasmtime-cpp\n\n### Fixed\n\n* Multiple returns on macOS AArch64 have been fixed:\n  [#2956](https://github.com/bytecodealliance/wasmtime/pull/2956)\n\n## 0.27.0\n\nReleased 2021-05-21.\n\n### Security Fixes\n\n* Fixed a security issue in Cranelift's x64 backend that could result in a heap\n  sandbox escape due to an incorrect sign-extension:\n  [#2913](https://github.com/bytecodealliance/wasmtime/issues/2913).\n\n### Added\n\n* Support for IBM z/Archiecture (`s390x`) machines in Cranelift and Wasmtime:\n  [#2836](https://github.com/bytecodealliance/wasmtime/pull/2836),\n  [#2837](https://github.com/bytecodealliance/wasmtime/pull/2837),\n  [#2838](https://github.com/bytecodealliance/wasmtime/pull/2838),\n  [#2843](https://github.com/bytecodealliance/wasmtime/pull/2843),\n  [#2854](https://github.com/bytecodealliance/wasmtime/pull/2854),\n  [#2870](https://github.com/bytecodealliance/wasmtime/pull/2870),\n  [#2871](https://github.com/bytecodealliance/wasmtime/pull/2871),\n  [#2872](https://github.com/bytecodealliance/wasmtime/pull/2872),\n  [#2874](https://github.com/bytecodealliance/wasmtime/pull/2874).\n\n* Improved async support in wasi-common runtime:\n  [#2832](https://github.com/bytecodealliance/wasmtime/pull/2832).\n\n* Added `Store::with_limits`, `StoreLimits`, and `ResourceLimiter` to the\n  Wasmtime API to help with enforcing resource limits at runtime. The\n  `ResourceLimiter` trait can be implemented by custom resource limiters to\n  decide if linear memories or tables can be grown.\n\n* Added `allow-unknown-exports` option for the run command:\n  [#2879](https://github.com/bytecodealliance/wasmtime/pull/2879).\n\n* Added API to notify that a `Store` has moved to a new thread:\n  [#2822](https://github.com/bytecodealliance/wasmtime/pull/2822).\n\n* Documented guidance around using Wasmtime in multithreaded contexts:\n  [#2812](https://github.com/bytecodealliance/wasmtime/pull/2812).\n  In the future, the Wasmtime API will change to allow some of its core types\n  to be Send/Sync; see the in-progress\n  [#2897](https://github.com/bytecodealliance/wasmtime/pull/2897) for details.\n\n* Support calls from native code to multiple-return-value functions:\n  [#2806](https://github.com/bytecodealliance/wasmtime/pull/2806).\n\n### Changed\n\n* Breaking: `Memory::new` has been changed to return `Result` as creating a\n  host memory object is now a fallible operation when the initial size of\n  the memory exceeds the store limits.\n\n### Fixed\n\n* Many instruction selection improvements on x64 and aarch64:\n  [#2819](https://github.com/bytecodealliance/wasmtime/pull/2819),\n  [#2828](https://github.com/bytecodealliance/wasmtime/pull/2828),\n  [#2823](https://github.com/bytecodealliance/wasmtime/pull/2823),\n  [#2862](https://github.com/bytecodealliance/wasmtime/pull/2862),\n  [#2886](https://github.com/bytecodealliance/wasmtime/pull/2886),\n  [#2889](https://github.com/bytecodealliance/wasmtime/pull/2889),\n  [#2905](https://github.com/bytecodealliance/wasmtime/pull/2905).\n\n* Improved performance of Wasmtime runtime substantially:\n  [#2811](https://github.com/bytecodealliance/wasmtime/pull/2811),\n  [#2818](https://github.com/bytecodealliance/wasmtime/pull/2818),\n  [#2821](https://github.com/bytecodealliance/wasmtime/pull/2821),\n  [#2847](https://github.com/bytecodealliance/wasmtime/pull/2847),\n  [#2900](https://github.com/bytecodealliance/wasmtime/pull/2900).\n\n* Fixed WASI issue with file metadata on Windows:\n  [#2884](https://github.com/bytecodealliance/wasmtime/pull/2884).\n\n* Fixed an issue with debug info and an underflowing (trapping) offset:\n  [#2866](https://github.com/bytecodealliance/wasmtime/pull/2866).\n\n* Fixed an issue with unwind information in the old x86 backend:\n  [#2845](https://github.com/bytecodealliance/wasmtime/pull/2845).\n\n* Fixed i32 spilling in x64 backend:\n  [#2840](https://github.com/bytecodealliance/wasmtime/pull/2840).\n\n## 0.26.0\n\nReleased 2021-04-05.\n\n### Added\n\n* Added the `wasmtime compile` command to support AOT compilation of Wasm\n  modules. This adds the `Engine::precompile_module` method. Also added the\n  `Config::target` method to change the compilation target of the\n  configuration. This can be used in conjunction with\n  `Engine::precompile_module` to target a different host triple than the\n  current one.\n  [#2791](https://github.com/bytecodealliance/wasmtime/pull/2791)\n\n* Support for macOS on aarch64 (Apple M1 Silicon), including Apple-specific\n  calling convention details and unwinding/exception handling using Mach ports.\n  [#2742](https://github.com/bytecodealliance/wasmtime/pull/2742),\n  [#2723](https://github.com/bytecodealliance/wasmtime/pull/2723)\n\n* A number of SIMD instruction implementations in the new x86-64 backend.\n  [#2771](https://github.com/bytecodealliance/wasmtime/pull/2771)\n\n* Added the `Config::cranelift_flag_enable` method to enable setting Cranelift\n  boolean flags or presets in a config.\n\n* Added CLI option `--cranelift-enable` to enable boolean settings and ISA presets.\n\n* Deduplicate function signatures in Wasm modules.\n  [#2772](https://github.com/bytecodealliance/wasmtime/pull/2772)\n\n* Optimize overheads of calling into Wasm functions.\n  [#2757](https://github.com/bytecodealliance/wasmtime/pull/2757),\n  [#2759](https://github.com/bytecodealliance/wasmtime/pull/2759)\n\n* Improvements related to Module Linking: compile fewer trampolines;\n\n  [#2774](https://github.com/bytecodealliance/wasmtime/pull/2774)\n\n* Re-export sibling crates from `wasmtime-wasi` to make embedding easier\n  without needing to match crate versions.\n  [#2776](https://github.com/bytecodealliance/wasmtime/pull/2776)\n\n### Changed\n\n* Switched the default compiler backend on x86-64 to Cranelift's new backend.\n  This should not have any user-visible effects other than possibly runtime\n  performance improvements. The old backend is still available with the\n  `old-x86-backend` feature flag to the `cranelift-codegen` or `wasmtime`\n  crates, or programmatically with `BackendVariant::Legacy`. We plan to\n  maintain the old backend for at least one more release and ensure it works on\n  CI.\n  [#2718](https://github.com/bytecodealliance/wasmtime/pull/2718)\n\n* Breaking: `Module::deserialize` has been removed in favor of `Module::new`.\n\n* Breaking: `Config::cranelift_clear_cpu_flags` was removed. Use `Config::target`\n  to clear the CPU flags for the host's target.\n\n* Breaking: `Config::cranelift_other_flag` was renamed to `Config::cranelift_flag_set`.\n\n* CLI changes:\n  * Wasmtime CLI options to enable WebAssembly features have been replaced with\n    a singular `--wasm-features` option. The previous options are still\n    supported, but are not displayed in help text.\n  * Breaking: the CLI option `--cranelift-flags` was changed to\n    `--cranelift-set`.\n  * Breaking: the CLI option `--enable-reference-types=false` has been changed\n    to `--wasm-features=-reference-types`.\n  * Breaking: the CLI option `--enable-multi-value=false` has been changed to\n    `--wasm-features=-multi-value`.\n  * Breaking: the CLI option `--enable-bulk-memory=false` has been changed to\n    `--wasm-features=-bulk-memory`.\n\n* Improved error-reporting in wiggle.\n  [#2760](https://github.com/bytecodealliance/wasmtime/pull/2760)\n\n* Make WASI sleeping fallible (some systems do not support sleep).\n  [#2756](https://github.com/bytecodealliance/wasmtime/pull/2756)\n\n* WASI: Support `poll_oneoff` with a sleep.\n  [#2753](https://github.com/bytecodealliance/wasmtime/pull/2753)\n\n* Allow a `StackMapSink` to be passed when defining functions with\n  `cranelift-module`.\n  [#2739](https://github.com/bytecodealliance/wasmtime/pull/2739)\n\n* Some refactoring in new x86-64 backend to prepare for VEX/EVEX (e.g.,\n  AVX-512) instruction encodings to be supported.\n  [#2799](https://github.com/bytecodealliance/wasmtime/pull/2799)\n\n### Fixed\n\n* Fixed a corner case in `srem` (signed remainder) in the new x86-64 backend:\n  `INT_MIN % -1` should return `0`, rather than trapping. This only occurred\n  when `avoid_div_traps == false` was set by the embedding.\n  [#2763](https://github.com/bytecodealliance/wasmtime/pull/2763)\n\n* Fixed a memory leak of the `Store` when an instance traps.\n  [#2803](https://github.com/bytecodealliance/wasmtime/pull/2803)\n\n* Some fuzzing-related fixes.\n  [#2788](https://github.com/bytecodealliance/wasmtime/pull/2788),\n  [#2770](https://github.com/bytecodealliance/wasmtime/pull/2770)\n\n* Fixed memory-initialization bug in uffd allocator that could copy into the\n  wrong destination under certain conditions. Does not affect the default\n  wasmtime instance allocator.\n  [#2801](https://github.com/bytecodealliance/wasmtime/pull/2801)\n\n* Fix printing of float values from the Wasmtime CLI.\n  [#2797](https://github.com/bytecodealliance/wasmtime/pull/2797)\n\n* Remove the ability for the `Linker` to instantiate modules with duplicate\n  import strings of different types.\n  [#2789](https://github.com/bytecodealliance/wasmtime/pull/2789)\n\n## 0.25.0\n\nReleased 2021-03-16.\n\n### Added\n\n* An implementation of a pooling instance allocator, optionally backed by\n  `userfaultfd` on Linux, was added to improve the performance of embeddings\n  that instantiate a large number of instances continuously.\n  [#2518](https://github.com/bytecodealliance/wasmtime/pull/2518)\n\n* Host functions can now be defined on `Config` to share the function across all\n  `Store` objects connected to an `Engine`. This can improve the time it takes\n  to instantiate instances in a short-lived `Store`.\n  [#2625](https://github.com/bytecodealliance/wasmtime/pull/2625)\n\n* The `Store` object now supports having typed values attached to it which can\n  be retrieved from host functions.\n  [#2625](https://github.com/bytecodealliance/wasmtime/pull/2625)\n\n* The `wiggle` code generator now supports `async` host functions.\n  [#2701](https://github.com/bytecodealliance/wasmtime/pull/2701)\n\n### Changed\n\n* The `Func::getN{,_async}` APIs have all been removed in favor of a new\n  `Func::typed` API which should be more compact in terms of API surface area as\n  well as more flexible in how it can be used.\n  [#2719](https://github.com/bytecodealliance/wasmtime/pull/2719)\n\n* `Engine::new` has been changed from returning `Engine` to returning\n  `anyhow::Result<Engine>`. Callers of `Engine::new` will need to be updated to\n  use the `?` operator on the return value or otherwise unwrap the result to get\n  the `Engine`.\n\n### Fixed\n\n* Interpretation of timestamps in `poll_oneoff` for WASI have been fixed to\n  correctly use nanoseconds instead of microseconds.\n  [#2717](https://github.com/bytecodealliance/wasmtime/pull/2717)\n\n## 0.24.0\n\nReleased 2021-03-04.\n\n### Added\n\n* Implement support for `async` functions in Wasmtime\n  [#2434](https://github.com/bytecodealliance/wasmtime/pull/2434)\n\n### Fixed\n\n* Fix preservation of the sigaltstack on macOS\n  [#2676](https://github.com/bytecodealliance/wasmtime/pull/2676)\n* Fix incorrect semver dependencies involving fs-set-times.\n  [#2705](https://github.com/bytecodealliance/wasmtime/pull/2705)\n* Fix some `i128` shift-related bugs in x64 backend.\n  [#2682](https://github.com/bytecodealliance/wasmtime/pull/2682)\n* Fix incomplete trap metadata due to multiple traps at one address\n  [#2685](https://github.com/bytecodealliance/wasmtime/pull/2685)\n\n## 0.23.0\n\nReleased 2021-02-16.\n\n### Added\n\n* Support for limiting WebAssembly execution with fuel was added, including\n  support in the C API.\n  [#2611](https://github.com/bytecodealliance/wasmtime/pull/2611)\n  [#2643](https://github.com/bytecodealliance/wasmtime/pull/2643)\n* Wasmtime now has more knobs for limiting memory and table allocations\n  [#2617](https://github.com/bytecodealliance/wasmtime/pull/2617)\n* Added a method to share `Config` across machines\n  [#2608](https://github.com/bytecodealliance/wasmtime/pull/2608)\n* Added a safe memory read/write API\n  [#2528](https://github.com/bytecodealliance/wasmtime/pull/2528)\n* Added support for the experimental wasi-crypto APIs\n  [#2597](https://github.com/bytecodealliance/wasmtime/pull/2597)\n* Added an instance limit to `Config`\n  [#2593](https://github.com/bytecodealliance/wasmtime/pull/2593)\n* Implemented module-linking's outer module aliases\n  [#2590](https://github.com/bytecodealliance/wasmtime/pull/2590)\n* Cranelift now supports 128-bit operations for the new x64 backend.\n  [#2539](https://github.com/bytecodealliance/wasmtime/pull/2539)\n* Cranelift now has detailed debug-info (DWARF) support in new backends (initially x64).\n  [#2565](https://github.com/bytecodealliance/wasmtime/pull/2565)\n* Cranelift now uses the `POPCNT`, `TZCNT`, and `LZCNT`, as well as SSE 4.1\n  rounding instructions on x64 when available.\n* Cranelift now uses the `CNT`, instruction on aarch64 when available.\n\n### Changed\n\n* A new WASI implementation built on the new\n  [`cap-std`](https://github.com/bytecodealliance/cap-std) crate was added,\n  replacing the previous implementation. This brings improved robustness,\n  portability, and performance.\n\n* `wasmtime_wasi::WasiCtxBuilder` moved to\n  `wasi_cap_std_sync::WasiCtxBuilder`.\n\n* The WebAssembly C API is updated, with a few minor API changes\n  [#2579](https://github.com/bytecodealliance/wasmtime/pull/2579)\n\n### Fixed\n\n* Fixed a panic in WASI `fd_readdir` on large directories\n  [#2620](https://github.com/bytecodealliance/wasmtime/pull/2620)\n* Fixed a memory leak with command modules\n  [#2017](https://github.com/bytecodealliance/wasmtime/pull/2017)\n\n--------------------------------------------------------------------------------\n\n## 0.22.0\n\nReleased 2021-01-07.\n\n### Added\n\n* Experimental support for [the module-linking\n  proposal](https://github.com/WebAssembly/module-linking) was\n  added. [#2094](https://github.com/bytecodealliance/wasmtime/pull/2094)\n\n* Added support for [the reference types\n  proposal](https://webassembly.github.io/reference-types) on the aarch64\n  architecture. [#2410](https://github.com/bytecodealliance/wasmtime/pull/2410)\n\n* Experimental support for [wasi-nn](https://github.com/WebAssembly/wasi-nn) was\n  added. [#2208](https://github.com/bytecodealliance/wasmtime/pull/2208)\n\n### Changed\n\n### Fixed\n\n* Fixed an issue where the `select` instruction didn't accept `v128` SIMD\n  operands. [#2391](https://github.com/bytecodealliance/wasmtime/pull/2391)\n\n* Fixed an issue where Wasmtime could potentially use the wrong stack map during\n  GCs, leading to a\n  panic. [#2396](https://github.com/bytecodealliance/wasmtime/pull/2396)\n\n* Fixed an issue where if a host-defined function erroneously returned a value\n  from a different store, that value would be\n  leaked. [#2424](https://github.com/bytecodealliance/wasmtime/pull/2424)\n\n* Fixed a bug where in certain cases if a module's instantiation failed, it\n  could leave trampolines in the store that referenced the no-longer-valid\n  instance. These trampolines could be reused in future instantiations, leading\n  to use after free bugs.\n  [#2408](https://github.com/bytecodealliance/wasmtime/pull/2408)\n\n* Fixed a miscompilation on aarch64 where certain instructions would read `SP`\n  instead of the zero register. This could only affect you if you explicitly\n  enabled the Wasm SIMD\n  proposal. [#2548](https://github.com/bytecodealliance/wasmtime/pull/2548)\n\n--------------------------------------------------------------------------------\n\n## 0.21.0\n\nReleased 2020-11-05.\n\n### Added\n\n* Experimental support for the multi-memory proposal was added.\n  [#2263](https://github.com/bytecodealliance/wasmtime/pull/2263)\n\n* The `Trap::trap_code` API enables learning what kind of trap was raised.\n  [#2309](https://github.com/bytecodealliance/wasmtime/pull/2309)\n\n### Changed\n\n* WebAssembly module validation is now parallelized.\n  [#2059](https://github.com/bytecodealliance/wasmtime/pull/2059)\n\n* Documentation is now available at docs.wasmtime.dev.\n  [#2317](https://github.com/bytecodealliance/wasmtime/pull/2317)\n\n* Windows now compiles like other platforms with a huge guard page instead of\n  having its own custom limit which made modules compile and run more slowly.\n  [#2326](https://github.com/bytecodealliance/wasmtime/pull/2326)\n\n* The size of the cache entry for serialized modules has been greatly reduced.\n  [#2321](https://github.com/bytecodealliance/wasmtime/pull/2321)\n  [#2322](https://github.com/bytecodealliance/wasmtime/pull/2322)\n  [#2324](https://github.com/bytecodealliance/wasmtime/pull/2324)\n  [#2325](https://github.com/bytecodealliance/wasmtime/pull/2325)\n\n* The `FuncType` API constructor and accessors are now iterator-based.\n  [#2365](https://github.com/bytecodealliance/wasmtime/pull/2365)\n\n### Fixed\n\n* A panic in compiling reference-types-using modules has been fixed.\n  [#2350](https://github.com/bytecodealliance/wasmtime/pull/2350)\n\n--------------------------------------------------------------------------------\n\n## 0.20.0\n\nReleased 2020-09-23.\n\n### Added\n\n* Support for explicitly serializing and deserializing compiled wasm modules has\n  been added.\n  [#2020](https://github.com/bytecodealliance/wasmtime/pull/2020)\n\n* A `wasmtime_store_gc` C API was added to run GC for `externref`.\n  [#2052](https://github.com/bytecodealliance/wasmtime/pull/2052)\n\n* Support for atomics in Cranelift has been added. Support is not fully\n  implemented in Wasmtime at this time, however.\n  [#2077](https://github.com/bytecodealliance/wasmtime/pull/2077)\n\n* The `Caller::get_export` function is now implemented for `Func` references as\n  well.\n  [#2108](https://github.com/bytecodealliance/wasmtime/pull/2108)\n\n### Fixed\n\n* Leaks in the C API have been fixed.\n  [#2040](https://github.com/bytecodealliance/wasmtime/pull/2040)\n\n* The `wasm_val_copy` C API has been fixed for reference types.\n  [#2041](https://github.com/bytecodealliance/wasmtime/pull/2041)\n\n* Fix a panic with `Func::new` and reference types when the store doesn't have\n  reference types enabled.\n  [#2039](https://github.com/bytecodealliance/wasmtime/pull/2039)\n\n--------------------------------------------------------------------------------\n\n## 0.19.0\n\nReleased 2020-07-14.\n\n### Added\n\n* The [WebAssembly reference-types proposal][reftypes] is now supported in\n  Wasmtime and the C API.\n  [#1832](https://github.com/bytecodealliance/wasmtime/pull/1832),\n  [#1882](https://github.com/bytecodealliance/wasmtime/pull/1882),\n  [#1894](https://github.com/bytecodealliance/wasmtime/pull/1894),\n  [#1901](https://github.com/bytecodealliance/wasmtime/pull/1901),\n  [#1923](https://github.com/bytecodealliance/wasmtime/pull/1923),\n  [#1969](https://github.com/bytecodealliance/wasmtime/pull/1969),\n  [#1973](https://github.com/bytecodealliance/wasmtime/pull/1973),\n  [#1982](https://github.com/bytecodealliance/wasmtime/pull/1982),\n  [#1984](https://github.com/bytecodealliance/wasmtime/pull/1984),\n  [#1991](https://github.com/bytecodealliance/wasmtime/pull/1991),\n  [#1996](https://github.com/bytecodealliance/wasmtime/pull/1996)\n\n* The [WebAssembly simd proposal's][simd] spec tests now pass in Wasmtime.\n  [#1765](https://github.com/bytecodealliance/wasmtime/pull/1765),\n  [#1876](https://github.com/bytecodealliance/wasmtime/pull/1876),\n  [#1941](https://github.com/bytecodealliance/wasmtime/pull/1941),\n  [#1957](https://github.com/bytecodealliance/wasmtime/pull/1957),\n  [#1990](https://github.com/bytecodealliance/wasmtime/pull/1990),\n  [#1994](https://github.com/bytecodealliance/wasmtime/pull/1994)\n\n* Wasmtime can now be compiled without the usage of threads for parallel\n  compilation, although this is still enabled by default.\n  [#1903](https://github.com/bytecodealliance/wasmtime/pull/1903)\n\n* The C API is [now\n  documented](https://bytecodealliance.github.io/wasmtime/c-api/).\n  [#1928](https://github.com/bytecodealliance/wasmtime/pull/1928),\n  [#1959](https://github.com/bytecodealliance/wasmtime/pull/1959),\n  [#1968](https://github.com/bytecodealliance/wasmtime/pull/1968)\n\n* A `wasmtime_linker_get_one_by_name` function was added to the C API.\n  [#1897](https://github.com/bytecodealliance/wasmtime/pull/1897)\n\n* A `wasmtime_trap_exit_status` function was added to the C API.\n  [#1912](https://github.com/bytecodealliance/wasmtime/pull/1912)\n\n* Compilation for the `aarch64-linux-android` target should now work, although\n  keep in mind this platform is not fully tested still.\n  [#2002](https://github.com/bytecodealliance/wasmtime/pull/2002)\n\n[reftypes]: https://github.com/WebAssembly/reference-types\n\n### Fixed\n\n* Runtime warnings when using Wasmtime on musl have been fixed.\n  [#1914](https://github.com/bytecodealliance/wasmtime/pull/1914)\n\n* A bug affecting Windows unwind information with functions that have spilled\n  floating point registers has been fixed.\n  [#1983](https://github.com/bytecodealliance/wasmtime/pull/1983)\n\n### Changed\n\n* Wasmtime's default branch and development now happens on the `main` branch\n  instead of `master`.\n  [#1924](https://github.com/bytecodealliance/wasmtime/pull/1924)\n\n### Removed\n\n* The \"host info\" support in the C API has been removed since it was never fully\n  or correctly implemented.\n  [#1922](https://github.com/bytecodealliance/wasmtime/pull/1922)\n\n* Support for the `*_same` functions in the C API has been removed in the same\n  vein as the host info APIs.\n  [#1926](https://github.com/bytecodealliance/wasmtime/pull/1926)\n\n--------------------------------------------------------------------------------\n\n## 0.18.0\n\nRelease 2020-06-09.\n\n### Added\n\nThe `WasmTy` trait is now implemented for `u32` and `u64`.\n\n  [#1808](https://github.com/bytecodealliance/wasmtime/pull/1808)\n\n--------------------------------------------------------------------------------\n\n## 0.17.0\n\nReleased 2020-06-01.\n\n### Added\n\n* The [Commands and Reactors ABI] is now supported in the Rust API. `Linker::module`\n  loads a module and automatically handles Commands and Reactors semantics.\n\n  [#1565](https://github.com/bytecodealliance/wasmtime/pull/1565)\n\n[Commands and Reactors ABI]: https://github.com/WebAssembly/WASI/blob/master/design/application-abi.md#current-unstable-abi\n\nThe `Table::grow` function now returns the previous table size, making it consistent\nwith the `table.grow` instruction.\n\n  [#1653](https://github.com/bytecodealliance/wasmtime/pull/1653)\n\nNew Wasmtime-specific C APIs for working with tables were added which provide more\ndetailed error information and which make growing a table more consistent with the\n`table.grow` instruction as well.\n\n  [#1654](https://github.com/bytecodealliance/wasmtime/pull/1654)\n\nThe C API now includes support for enabling logging in Wasmtime.\n\n  [#1737](https://github.com/bytecodealliance/wasmtime/pull/1737)\n\n### Changed\n\nThe WASI `proc_exit` function no longer exits the host process. It now unwinds the\ncallstack back to the wasm entrypoint, and the exit value is available from the\n`Trap::i32_exit_status` method.\n\n  [#1646](https://github.com/bytecodealliance/wasmtime/pull/1646)\n\nThe WebAssembly [multi-value](https://github.com/WebAssembly/multi-value/) proposal\nis now enabled by default.\n\n  [#1667](https://github.com/bytecodealliance/wasmtime/pull/1667)\n\nThe Rust API does not require a store provided during `Module::new` operation. The `Module` can be send accross threads and instantiate for a specific store. The `Instance::new` now requires the store.\n\n  [#1761](https://github.com/bytecodealliance/wasmtime/pull/1761)\n\n--------------------------------------------------------------------------------\n\n## 0.16.0\n\nReleased 2020-04-29.\n\n### Added\n\n* The `Instance` struct has new accessors, `get_func`, `get_table`,\n  `get_memory`, and `get_global` for quickly looking up exported\n  functions, tables, memories, and globals by name.\n  [#1524](https://github.com/bytecodealliance/wasmtime/pull/1524)\n\n* The C API has a number of new `wasmtime_*` functions which return error\n  objects to get detailed error information when an API fails.\n  [#1467](https://github.com/bytecodealliance/wasmtime/pull/1467)\n\n* Users now have fine-grained control over creation of instances of `Memory`\n  with a new `MemoryCreator` trait.\n  [#1400](https://github.com/bytecodealliance/wasmtime/pull/1400)\n\n* Go bindings for Wasmtime are [now available][go-bindings].\n  [#1481](https://github.com/bytecodealliance/wasmtime/pull/1481)\n\n* APIs for looking up values in a `Linker` have been added.\n  [#1480](https://github.com/bytecodealliance/wasmtime/pull/1480)\n\n* Preliminary support for AArch64, also known as ARM64.\n  [#1581](https://github.com/bytecodealliance/wasmtime/pull/1581)\n\n[go-bindings]: https://github.com/bytecodealliance/wasmtime-go\n\n### Changed\n\n* `Instance::exports` now returns `Export` objects which contain\n  the `name`s of the exports in addition to their `Extern` definitions,\n  so it's no longer necessary to use `Module::exports` to obtain the\n  export names.\n  [#1524](https://github.com/bytecodealliance/wasmtime/pull/1524)\n\n* The `Func::call` API has changed its error type from `Trap` to `anyhow::Error`\n  to distinguish between wasm traps and runtime violations (like the wrong\n  number of parameters).\n  [#1467](https://github.com/bytecodealliance/wasmtime/pull/1467)\n\n* A number of `wasmtime_linker_*` and `wasmtime_config_*` C APIs have new type\n  signatures which reflect returning errors.\n  [#1467](https://github.com/bytecodealliance/wasmtime/pull/1467)\n\n* Bindings for .NET have moved to\n  https://github.com/bytecodealliance/wasmtime-dotnet.\n  [#1477](https://github.com/bytecodealliance/wasmtime/pull/1477)\n\n* Passing too many imports to `Instance::new` is now considered an error.\n  [#1478](https://github.com/bytecodealliance/wasmtime/pull/1478)\n\n### Fixed\n\n* Spurious segfaults due to out-of-stack conditions when handling signals have\n  been fixed.\n  [#1315](https://github.com/bytecodealliance/wasmtime/pull/1315)\n\n--------------------------------------------------------------------------------\n\n## 0.15.0\n\nReleased 2020-03-31.\n\n### Fixed\n\nFull release produced for all artifacts to account for hiccups in 0.13.0 and\n0.14.0.\n\n--------------------------------------------------------------------------------\n\n## 0.14.0\n\n*This version ended up not getting a full release*\n\n### Fixed\n\nFix build errors in wasi-common on Windows.\n\n--------------------------------------------------------------------------------\n\n## 0.13.0\n\nReleased 2020-03-24.\n\n### Added\n\n* Lots of documentation of `wasmtime` has been updated. Be sure to check out the\n  [book](https://bytecodealliance.github.io/wasmtime/) and [API\n  documentation](https://bytecodealliance.github.io/wasmtime/api/wasmtime/)!\n\n* All wasmtime example programs are now in a top-level `examples` directory and\n  are available in both C and Rust.\n  [#1286](https://github.com/bytecodealliance/wasmtime/pull/1286)\n\n* A `wasmtime::Linker` type was added to conveniently link link wasm modules\n  together and create instances that reference one another.\n  [#1384](https://github.com/bytecodealliance/wasmtime/pull/1384)\n\n* Wasmtime now has \"jitdump\" support enabled by default which allows [profiling\n  wasm code on linux][jitdump].\n  [#1310](https://github.com/bytecodealliance/wasmtime/pull/1310)\n\n* The `wasmtime::Caller` type now exists as a first-class way to access the\n  caller's exports, namely memory, when implementing host APIs. This can be the\n  first argument of functions defined with `Func::new` or `Func::wrap` which\n  allows easily implementing methods which take a pointer into wasm memory. Note\n  that this only works for accessing the caller's `Memory` for now and it must\n  be exported. This will eventually be replaced with a more general-purpose\n  mechanism like interface types.\n  [#1290](https://github.com/bytecodealliance/wasmtime/pull/1290)\n\n* The bulk memory proposal has been fully implemented.\n  [#1264](https://github.com/bytecodealliance/wasmtime/pull/1264)\n  [#976](https://github.com/bytecodealliance/wasmtime/pull/976)\n\n* Virtual file support has been added to `wasi-common`.\n  [#701](https://github.com/bytecodealliance/wasmtime/pull/701)\n\n* The C API has been enhanced with a Wasmtime-specific `wasmtime_wat2wasm` to\n  parse `*.wat` files via the C API.\n  [#1206](https://github.com/bytecodealliance/wasmtime/pull/1206)\n\n[jitdump]: https://bytecodealliance.github.io/wasmtime/examples-profiling.html\n\n### Changed\n\n* The `wast` and `wasm2obj` standalone binaries have been removed. They're\n  available via the `wasmtime wast` and `wasmtime wasm2obj` subcommands.\n  [#1372](https://github.com/bytecodealliance/wasmtime/pull/1372)\n\n* The `wasi-common` crate now uses the new `wiggle` crate to auto-generate a\n  trait which is implemented for the current wasi snapshot.\n  [#1202](https://github.com/bytecodealliance/wasmtime/pull/1202)\n\n* Wasmtime no longer has a dependency on a C++ compiler.\n  [#1365](https://github.com/bytecodealliance/wasmtime/pull/1365)\n\n* The `Func::wrapN` APIs have been consolidated into one `Func::wrap` API.\n  [#1363](https://github.com/bytecodealliance/wasmtime/pull/1363)\n\n* The `Callable` trait has been removed and now `Func::new` takes a closure\n  directly.\n  [#1363](https://github.com/bytecodealliance/wasmtime/pull/1363)\n\n* The Cranelift repository has been merged into the Wasmtime repository.\n\n* Support for interface types has been temporarily removed.\n  [#1292](https://github.com/bytecodealliance/wasmtime/pull/1292)\n\n* The exit code of the `wasmtime` CLI has changed if the program traps.\n  [#1274](https://github.com/bytecodealliance/wasmtime/pull/1274)\n\n* The `wasmtime` CLI now logs to stderr by default and the `-d` flag has been\n  renamed to `--log-to-file`.\n  [#1266](https://github.com/bytecodealliance/wasmtime/pull/1266)\n\n* Values cannot cross `Store` objects, meaning you can't instantiate a module\n  with values from different stores nor pass values from different stores into\n  methods.\n  [#1016](https://github.com/bytecodealliance/wasmtime/pull/1016)\n\n--------------------------------------------------------------------------------\n\n## 0.12.0\n\nReleased 2020-02-26.\n\n### Added\n\n* Support for the [WebAssembly text annotations proposal][annotations-proposal]\n  has been added.\n  [#998](https://github.com/bytecodealliance/wasmtime/pull/998)\n\n* An initial C API for instantiating WASI modules has been added.\n  [#977](https://github.com/bytecodealliance/wasmtime/pull/977)\n\n* A new suite of `Func::getN` functions have been added to the `wasmtime` API to\n  call statically-known function signatures in a highly optimized fashion.\n  [#955](https://github.com/bytecodealliance/wasmtime/pull/955)\n\n* Initial support for profiling JIT code through perf jitdump has been added.\n  [#360](https://github.com/bytecodealliance/wasmtime/pull/360)\n\n* More CLI flags corresponding to proposed WebAssembly features have been added.\n  [#917](https://github.com/bytecodealliance/wasmtime/pull/917)\n\n[annotations-proposal]: https://github.com/webassembly/annotations\n\n### Changed\n\n* The `wasmtime` CLI as well as embedding API will optimize WebAssembly code by\n  default now.\n  [#973](https://github.com/bytecodealliance/wasmtime/pull/973)\n  [#988](https://github.com/bytecodealliance/wasmtime/pull/988)\n\n* The `verifier` pass in Cranelift is now no longer run by default when using\n  the embedding API.\n  [#882](https://github.com/bytecodealliance/wasmtime/pull/882)\n\n### Fixed\n\n* Code caching now accurately accounts for optimization levels, ensuring that if\n  you ask for optimized code you're not accidentally handed unoptimized code\n  from the cache.\n  [#974](https://github.com/bytecodealliance/wasmtime/pull/974)\n\n* Automated releases for tags should be up and running again, along with\n  automatic publication of the `wasmtime` Python package.\n  [#971](https://github.com/bytecodealliance/wasmtime/pull/971)\n", ";; Extern type definitions and constructors for the x64 `MachInst` type.\n\n;;;; `MInst` ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n\n;; Don't build `MInst` variants directly, in general. Instead, use the\n;; instruction-emitting helpers defined further down.\n\n(type MInst nodebug\n      (enum\n       ;; Nops of various sizes, including zero.\n       (Nop (len u8))\n\n       ;; =========================================\n       ;; Integer instructions.\n\n       ;; Integer arithmetic/bit-twiddling.\n       (AluRmiR (size OperandSize) ;; 4 or 8\n                (op AluRmiROpcode)\n                (src1 Gpr)\n                (src2 GprMemImm)\n                (dst WritableGpr))\n\n       ;; Integer arithmetic read-modify-write on memory.\n       (AluRM (size OperandSize) ;; 4 or 8\n              (op AluRmiROpcode)\n              (src1_dst SyntheticAmode)\n              (src2 Gpr))\n\n       ;; Integer arithmetic binary op that relies on the VEX prefix.\n       ;; NOTE: we don't currently support emitting VEX instructions with memory\n       ;; arguments, so `src2` is artificially constrained to be a Gpr.\n       (AluRmRVex (size OperandSize)\n                  (op AluRmROpcode)\n                  (src1 Gpr)\n                  (src2 Gpr)\n                  (dst WritableGpr))\n\n       ;; Production of a zero value into a register of the specified size.\n       (AluConstOp (op AluRmiROpcode)\n                   (size OperandSize)\n                   (dst WritableGpr))\n\n       ;; Instructions on general-purpose registers that only read src and\n       ;; defines dst (dst is not modified). `bsr`, etc.\n       (UnaryRmR (size OperandSize) ;; 2, 4, or 8\n                 (op UnaryRmROpcode)\n                 (src GprMem)\n                 (dst WritableGpr))\n\n       ;; Bitwise not.\n       (Not (size OperandSize) ;; 1, 2, 4, or 8\n            (src Gpr)\n            (dst WritableGpr))\n\n       ;; Integer negation.\n       (Neg (size OperandSize) ;; 1, 2, 4, or 8\n            (src Gpr)\n            (dst WritableGpr))\n\n       ;; Integer quotient and remainder: (div idiv) $rax $rdx (reg addr)\n       (Div (size OperandSize) ;; 1, 2, 4, or 8\n            (signed bool)\n            (divisor GprMem)\n            (dividend_lo Gpr)\n            (dividend_hi Gpr)\n            (dst_quotient WritableGpr)\n            (dst_remainder WritableGpr))\n\n       ;; The high (and low) bits of a (un)signed multiply: `RDX:RAX := RAX *\n       ;; rhs`.\n       (MulHi (size OperandSize)\n              (signed bool)\n              (src1 Gpr)\n              (src2 GprMem)\n              (dst_lo WritableGpr)\n              (dst_hi WritableGpr))\n\n       ;; A synthetic sequence to implement the right inline checks for\n       ;; remainder and division, assuming the dividend is in %rax.\n       ;;\n       ;; The generated code sequence is described in the emit's function match\n       ;; arm for this instruction.\n       (CheckedDivOrRemSeq (kind DivOrRemKind)\n                           (size OperandSize)\n                           (dividend_lo Gpr)\n                           (dividend_hi Gpr)\n                           (divisor Gpr)\n                           (dst_quotient WritableGpr)\n                           (dst_remainder WritableGpr)\n                           (tmp OptionWritableGpr))\n\n       ;; Do a sign-extend based on the sign of the value in rax into rdx: (cwd\n       ;; cdq cqo) or al into ah: (cbw)\n       (SignExtendData (size OperandSize) ;; 1, 2, 4, or 8\n                       (src Gpr)\n                       (dst WritableGpr))\n\n       ;; Constant materialization: (imm32 imm64) reg.\n       ;;\n       ;; Either: movl $imm32, %reg32 or movabsq $imm64, %reg32.\n       (Imm (dst_size OperandSize) ;; 4 or 8\n            (simm64 u64)\n            (dst WritableGpr))\n\n       ;; GPR to GPR move: mov (64 32) reg reg.\n       (MovRR (size OperandSize) ;; 4 or 8\n              (src Gpr)\n              (dst WritableGpr))\n\n       ;; Like `MovRR` but with a physical register source (for implementing\n       ;; CLIF instructions like `get_stack_pointer`).\n       (MovFromPReg (src PReg)\n                    (dst WritableGpr))\n\n       ;; Like `MovRR` but with a physical register destination (for\n       ;; implementing CLIF instructions like `set_pinned_reg`).\n       (MovToPReg (src Gpr)\n                  (dst PReg))\n\n       ;; Zero-extended loads, except for 64 bits: movz (bl bq wl wq lq) addr\n       ;; reg.\n       ;;\n       ;; Note that the lq variant doesn't really exist since the default\n       ;; zero-extend rule makes it unnecessary. For that case we emit the\n       ;; equivalent \"movl AM, reg32\".\n       (MovzxRmR (ext_mode ExtMode)\n                 (src GprMem)\n                 (dst WritableGpr))\n\n       ;; A plain 64-bit integer load, since MovZX_RM_R can't represent that.\n       (Mov64MR (src SyntheticAmode)\n                (dst WritableGpr))\n\n       ;; Loads the memory address of addr into dst.\n       (LoadEffectiveAddress (addr SyntheticAmode)\n                             (dst WritableGpr))\n\n       ;; Sign-extended loads and moves: movs (bl bq wl wq lq) addr reg.\n       (MovsxRmR (ext_mode ExtMode)\n                 (src GprMem)\n                 (dst WritableGpr))\n\n       ;; Immediate store.\n       (MovImmM (size OperandSize)\n\t\t(simm64 u64)\n\t\t(dst SyntheticAmode))\n\n       ;; Integer stores: mov (b w l q) reg addr.\n       (MovRM (size OperandSize) ;; 1, 2, 4, or 8\n              (src Gpr)\n              (dst SyntheticAmode))\n\n       ;; Arithmetic shifts: (shl shr sar) (b w l q) imm reg.\n       (ShiftR (size OperandSize) ;; 1, 2, 4, or 8\n               (kind ShiftKind)\n               (src Gpr)\n               ;; shift count: `Imm8Gpr::Imm8(0 .. #bits-in-type - 1)` or\n               ;; `Imm8Reg::Gpr(r)` where `r` get's move mitosis'd into `%cl`.\n               (num_bits Imm8Gpr)\n               (dst WritableGpr))\n\n       ;; Arithmetic SIMD shifts.\n       (XmmRmiReg (opcode SseOpcode)\n                  (src1 Xmm)\n                  (src2 XmmMemAlignedImm)\n                  (dst WritableXmm))\n\n       ;; Integer comparisons/tests: cmp or test (b w l q) (reg addr imm) reg.\n       (CmpRmiR (size OperandSize) ;; 1, 2, 4, or 8\n                (opcode CmpOpcode)\n                (src GprMemImm)\n                (dst Gpr))\n\n       ;; Materializes the requested condition code in the destinaton reg.\n       (Setcc (cc CC)\n              (dst WritableGpr))\n\n       ;; Swaps byte order in register\n       (Bswap (size OperandSize) ;; 4 or 8\n              (src Gpr)\n              (dst WritableGpr))\n\n       ;; =========================================\n       ;; Conditional moves.\n\n       ;; GPR conditional move; overwrites the destination register.\n       (Cmove (size OperandSize)\n              (cc CC)\n              (consequent GprMem)\n              (alternative Gpr)\n              (dst WritableGpr))\n\n       ;; XMM conditional move; overwrites the destination register.\n       (XmmCmove (ty Type)\n                 (cc CC)\n                 (consequent XmmMemAligned)\n                 (alternative Xmm)\n                 (dst WritableXmm))\n\n       ;; =========================================\n       ;; Stack manipulation.\n\n       ;; pushq (reg addr imm)\n       (Push64 (src GprMemImm))\n\n       ;; popq reg\n       (Pop64 (dst WritableGpr))\n\n      ;; Emits a inline stack probe loop.\n      (StackProbeLoop (tmp WritableReg)\n                      (frame_size u32)\n                      (guard_size u32))\n\n       ;; =========================================\n       ;; Floating-point operations.\n\n       ;; XMM (scalar or vector) binary op: (add sub and or xor mul adc? sbb?)\n       ;; (32 64) (reg addr) reg\n       (XmmRmR (op SseOpcode)\n               (src1 Xmm)\n               (src2 XmmMemAligned)\n               (dst WritableXmm))\n\n       ;; Same as `XmmRmR` except the memory operand can be unaligned\n       (XmmRmRUnaligned (op SseOpcode)\n                        (src1 Xmm)\n                        (src2 XmmMem)\n                        (dst WritableXmm))\n\n       ;; XMM (scalar or vector) production of a constant value by operating\n       ;; on a register with itself.\n       ;;\n       ;; Used to produce all zeros with xor or all one with a comparison.\n       (XmmConstOp (op SseOpcode)\n                   (dst WritableXmm))\n\n       ;; XMM (scalar or vector) blend op. The mask is used to blend between\n       ;; src1 and src2. This differs from a use of `XmmRmR` as the mask is\n       ;; implicitly in register xmm0; this special case exists to allow us to\n       ;; communicate the constraint on the `mask` register to regalloc2.\n       (XmmRmRBlend\n         (op SseOpcode)\n         (src1 Xmm)\n         (src2 XmmMemAligned)\n         (mask Xmm)\n         (dst WritableXmm))\n\n       ;; XMM (scalar or vector) binary op that relies on the VEX prefix and\n       ;; has two inputs.\n       (XmmRmiRVex (op AvxOpcode)\n                   (src1 Xmm)\n                   (src2 XmmMemImm)\n                   (dst WritableXmm))\n\n       ;; XMM (scalar or vector) ternary op that relies on the VEX prefix and\n       ;; has two dynamic inputs plus one immediate input.\n       (XmmRmRImmVex (op AvxOpcode)\n                     (src1 Xmm)\n                     (src2 XmmMem)\n                     (dst WritableXmm)\n                     (imm u8))\n\n       ;; XMM instruction for `vpinsr{b,w,d,q}` which is separte from\n       ;; `XmmRmRImmVex` because `src2` is a gpr, not xmm register.\n       (XmmVexPinsr (op AvxOpcode)\n                   (src1 Xmm)\n                   (src2 GprMem)\n                   (dst WritableXmm)\n                   (imm u8))\n\n       ;; XMM (scalar or vector) ternary op that relies on the VEX prefix and\n       ;; has three dynamic inputs.\n       (XmmRmRVex3 (op AvxOpcode)\n                   (src1 Xmm)\n                   (src2 Xmm)\n                   (src3 XmmMem)\n                   (dst WritableXmm))\n\n       ;; XMM blend operation using the VEX encoding.\n       (XmmRmRBlendVex (op AvxOpcode)\n                       (src1 Xmm)\n                       (src2 XmmMem)\n                       (mask Xmm)\n                       (dst WritableXmm))\n\n       ;; XMM unary op using a VEX encoding (aka AVX).\n       (XmmUnaryRmRVex (op AvxOpcode)\n                       (src XmmMem)\n                       (dst WritableXmm))\n\n       ;; XMM unary op using a VEX encoding (aka AVX) with an immediate.\n       (XmmUnaryRmRImmVex (op AvxOpcode)\n                          (src XmmMem)\n                          (dst WritableXmm)\n                          (imm u8))\n\n       ;; XMM (scalar or vector) binary op that relies on the EVEX\n       ;; prefix. Takes two inputs.\n       (XmmRmREvex (op Avx512Opcode)\n                   (src1 XmmMem)\n                   (src2 Xmm)\n                   (dst WritableXmm))\n\n       ;; XMM (scalar or vector) binary op that relies on the EVEX\n       ;; prefix. Takes three inputs.\n       (XmmRmREvex3 (op Avx512Opcode)\n                   (src1 XmmMem)\n                   (src2 Xmm)\n                   (src3 Xmm)\n                   (dst WritableXmm))\n\n       ;; XMM (scalar or vector) unary op: mov between XMM registers (32 64)\n       ;; (reg addr) reg, sqrt, etc.\n       ;;\n       ;; This differs from XMM_RM_R in that the dst register of XmmUnaryRmR is\n       ;; not used in the computation of the instruction dst value and so does\n       ;; not have to be a previously valid value. This is characteristic of mov\n       ;; instructions.\n       (XmmUnaryRmR (op SseOpcode)\n                    (src XmmMemAligned)\n                    (dst WritableXmm))\n\n       ;; Same as `XmmUnaryRmR` but used for opcodes where the memory address\n       ;; can be unaligned.\n       (XmmUnaryRmRUnaligned (op SseOpcode)\n                             (src XmmMem)\n                             (dst WritableXmm))\n\n       ;; XMM (scalar or vector) unary op with immediate: roundss, roundsd, etc.\n       ;;\n       ;; This differs from XMM_RM_R_IMM in that the dst register of\n       ;; XmmUnaryRmRImm is not used in the computation of the instruction dst\n       ;; value and so does not have to be a previously valid value.\n       (XmmUnaryRmRImm (op SseOpcode)\n                       (src XmmMemAligned)\n                       (imm u8)\n                       (dst WritableXmm))\n\n       ;; XMM (scalar or vector) unary op that relies on the EVEX prefix.\n       (XmmUnaryRmREvex (op Avx512Opcode)\n                        (src XmmMem)\n                        (dst WritableXmm))\n\n       ;; XMM (scalar or vector) unary op (from xmm to reg/mem): stores, movd,\n       ;; movq\n       (XmmMovRM (op SseOpcode)\n                 (src Reg)\n                 (dst SyntheticAmode))\n\n       ;; XMM (scalar) unary op (from xmm to integer reg): movd, movq,\n       ;; cvtts{s,d}2si\n       (XmmToGpr (op SseOpcode)\n                 (src Xmm)\n                 (dst WritableGpr)\n                 (dst_size OperandSize))\n\n       ;; XMM (scalar) unary op (from xmm to integer reg): pextr{w,b,d,q}\n       (XmmToGprImm (op SseOpcode)\n                    (src Xmm)\n                    (dst WritableGpr)\n                    (imm u8))\n\n       ;; XMM (scalar) unary op (from integer to float reg): movd, movq,\n       ;; cvtsi2s{s,d}\n       (GprToXmm (op SseOpcode)\n                 (src GprMem)\n                 (dst WritableXmm)\n                 (src_size OperandSize))\n\n       ;; Converts an unsigned int64 to a float32/float64.\n       (CvtUint64ToFloatSeq (dst_size OperandSize) ;; 4 or 8\n                            (src Gpr)\n                            (dst WritableXmm)\n                            (tmp_gpr1 WritableGpr)\n                            (tmp_gpr2 WritableGpr))\n\n       ;; Converts a scalar xmm to a signed int32/int64.\n       (CvtFloatToSintSeq (dst_size OperandSize)\n                          (src_size OperandSize)\n                          (is_saturating bool)\n                          (src Xmm)\n                          (dst WritableGpr)\n                          (tmp_gpr WritableGpr)\n                          (tmp_xmm WritableXmm))\n\n       ;; Converts a scalar xmm to an unsigned int32/int64.\n       (CvtFloatToUintSeq (dst_size OperandSize)\n                          (src_size OperandSize)\n                          (is_saturating bool)\n                          (src Xmm)\n                          (dst WritableGpr)\n                          (tmp_gpr WritableGpr)\n                          (tmp_xmm WritableXmm)\n                          (tmp_xmm2 WritableXmm))\n\n       ;; A sequence to compute min/max with the proper NaN semantics for xmm\n       ;; registers.\n       (XmmMinMaxSeq (size OperandSize)\n                     (is_min bool)\n                     (lhs Xmm)\n                     (rhs Xmm)\n                     (dst WritableXmm))\n\n       ;; Float comparisons/tests: cmp (b w l q) (reg addr imm) reg.\n       (XmmCmpRmR (op SseOpcode)\n                  (src XmmMemAligned)\n                  (dst Xmm))\n\n       ;; A binary XMM instruction with an 8-bit immediate: e.g. cmp (ps pd) imm\n       ;; (reg addr) reg\n       ;;\n       ;; Note: this has to use `Reg*`, not `Xmm*`, operands because it is used\n       ;; in various lane insertion and extraction instructions that move\n       ;; between XMMs and GPRs.\n       (XmmRmRImm (op SseOpcode)\n                  (src1 Reg)\n                  (src2 RegMem)\n                  (dst WritableReg)\n                  (imm u8)\n                  (size OperandSize))\n\n       ;; =========================================\n       ;; Control flow instructions.\n\n       ;; Direct call: call simm32.\n       (CallKnown (dest ExternalName)\n                  (info BoxCallInfo))\n\n       ;; Indirect call: callq (reg mem)\n       (CallUnknown (dest RegMem)\n                    (info BoxCallInfo))\n\n       ;; A pseudo-instruction that captures register arguments in vregs.\n       (Args\n        (args VecArgPair))\n\n       ;; Return.\n       (Ret (rets VecRetPair))\n\n       ;; Jump to a known target: jmp simm32.\n       (JmpKnown (dst MachLabel))\n\n       ;; One-way conditional branch: jcond cond target.\n       ;;\n       ;; This instruction is useful when we have conditional jumps depending on\n       ;; more than two conditions, see for instance the lowering of Brif\n       ;; with Fcmp inputs.\n       ;;\n       ;; A note of caution: in contexts where the branch target is another\n       ;; block, this has to be the same successor as the one specified in the\n       ;; terminator branch of the current block.  Otherwise, this might confuse\n       ;; register allocation by creating new invisible edges.\n       (JmpIf (cc CC)\n              (taken MachLabel))\n\n       ;; Two-way conditional branch: jcond cond target target.\n       ;;\n       ;; Emitted as a compound sequence; the MachBuffer will shrink it as\n       ;; appropriate.\n       (JmpCond (cc CC)\n                (taken MachLabel)\n                (not_taken MachLabel))\n\n       ;; Jump-table sequence, as one compound instruction (see note in lower.rs\n       ;; for rationale).\n       ;;\n       ;; The generated code sequence is described in the emit's function match\n       ;; arm for this instruction.\n       ;;\n       ;; See comment on jmp_table_seq below about the temporaries signedness.\n       (JmpTableSeq (idx Reg)\n                    (tmp1 WritableReg)\n                    (tmp2 WritableReg)\n                    (default_target MachLabel)\n                    (targets BoxVecMachLabel))\n\n       ;; Indirect jump: jmpq (reg mem).\n       (JmpUnknown (target RegMem))\n\n       ;; Traps if the condition code is set.\n       (TrapIf (cc CC)\n               (trap_code TrapCode))\n\n       ;; Traps if both of the condition codes are set.\n       (TrapIfAnd (cc1 CC)\n                  (cc2 CC)\n                  (trap_code TrapCode))\n\n       ;; Traps if either of the condition codes are set.\n       (TrapIfOr (cc1 CC)\n                 (cc2 CC)\n                 (trap_code TrapCode))\n\n       ;; A debug trap.\n       (Hlt)\n\n       ;; An instruction that will always trigger the illegal instruction\n       ;; exception.\n       (Ud2 (trap_code TrapCode))\n\n       ;; Loads an external symbol in a register, with a relocation:\n       ;;\n       ;; movq $name@GOTPCREL(%rip), dst    if PIC is enabled, or\n       ;; movabsq $name, dst                otherwise.\n       (LoadExtName (dst WritableReg)\n                    (name BoxExternalName)\n                    (offset i64))\n\n       ;; =========================================\n       ;; Instructions pertaining to atomic memory accesses.\n\n       ;; A standard (native) `lock cmpxchg src, (amode)`, with register\n       ;; conventions:\n       ;;\n       ;; `mem`          (read) address\n       ;; `replacement`  (read) replacement value\n       ;; %rax           (modified) in: expected value, out: value that was actually at `dst`\n       ;; %rflags is written.  Do not assume anything about it after the instruction.\n       ;;\n       ;; The instruction \"succeeded\" iff the lowest `ty` bits of %rax\n       ;; afterwards are the same as they were before.\n       (LockCmpxchg (ty Type) ;; I8, I16, I32, or I64\n                    (replacement Reg)\n                    (expected Reg)\n                    (mem SyntheticAmode)\n                    (dst_old WritableReg))\n\n       ;; A synthetic instruction, based on a loop around a native `lock\n       ;; cmpxchg` instruction.\n       ;;\n       ;; This atomically modifies a value in memory and returns the old value.\n       ;; The sequence consists of an initial \"normal\" load from `dst`, followed\n       ;; by a loop which computes the new value and tries to compare-and-swap\n       ;; (\"CAS\") it into `dst`, using the native instruction `lock\n       ;; cmpxchg{b,w,l,q}`.  The loop iterates until the CAS is successful. If\n       ;; there is no contention, there will be only one pass through the loop\n       ;; body.  The sequence does *not* perform any explicit memory fence\n       ;; instructions (`mfence`/`sfence`/`lfence`).\n       ;;\n       ;; Note that the transaction is atomic in the sense that, as observed by\n       ;; some other thread, `dst` either has the initial or final value, but no\n       ;; other.  It isn't atomic in the sense of guaranteeing that no other\n       ;; thread writes to `dst` in between the initial load and the CAS -- but\n       ;; that would cause the CAS to fail unless the other thread's last write\n       ;; before the CAS wrote the same value that was already there.  In other\n       ;; words, this implementation suffers (unavoidably) from the A-B-A\n       ;; problem.\n       ;;\n       ;; This instruction sequence has fixed register uses as follows:\n       ;; - %rax  (written) the old value at `mem`\n       ;; - %rflags is written.  Do not assume anything about it after the\n       ;;   instruction.\n       (AtomicRmwSeq (ty Type) ;; I8, I16, I32, or I64\n                     (op MachAtomicRmwOp)\n                     (mem SyntheticAmode)\n                     (operand Reg)\n                     (temp WritableReg)\n                     (dst_old WritableReg))\n\n       ;; A memory fence (mfence, lfence or sfence).\n       (Fence (kind FenceKind))\n\n       ;; =========================================\n       ;; Meta-instructions generating no code.\n\n       ;; Marker, no-op in generated code: SP \"virtual offset\" is adjusted.\n       ;;\n       ;; This controls how `MemArg::NominalSPOffset` args are lowered.\n       (VirtualSPOffsetAdj (offset i64))\n\n       ;; Provides a way to tell the register allocator that the upcoming\n       ;; sequence of instructions will overwrite `dst` so it should be\n       ;; considered as a `def`; use this with care.\n       ;;\n       ;; This is useful when we have a sequence of instructions whose register\n       ;; usages are nominally `mod`s, but such that the combination of\n       ;; operations creates a result that is independent of the initial\n       ;; register value. It's thus semantically a `def`, not a `mod`, when all\n       ;; the instructions are taken together, so we want to ensure the register\n       ;; is defined (its live-range starts) prior to the sequence to keep\n       ;; analyses happy.\n       ;;\n       ;; One alternative would be a compound instruction that somehow\n       ;; encapsulates the others and reports its own `def`s/`use`s/`mod`s; this\n       ;; adds complexity (the instruction list is no longer flat) and requires\n       ;; knowledge about semantics and initial-value independence anyway.\n       (XmmUninitializedValue (dst WritableXmm))\n\n       ;; A call to the `ElfTlsGetAddr` libcall. Returns address of TLS symbol\n       ;; `dst`, which is constrained to `rax`.\n       (ElfTlsGetAddr (symbol ExternalName)\n                      (dst WritableGpr))\n\n       ;; A Mach-O TLS symbol access. Returns address of the TLS symbol in\n       ;; `dst`, which is constrained to `rax`.\n       (MachOTlsGetAddr (symbol ExternalName)\n                        (dst WritableGpr))\n\n       ;; A Coff TLS symbol access. Returns address of the TLS symbol in\n       ;; `dst`, which is constrained to `rax`.\n       (CoffTlsGetAddr (symbol ExternalName)\n                       (dst WritableGpr)\n                       (tmp WritableGpr))\n\n       ;; An unwind pseudoinstruction describing the state of the machine at\n       ;; this program point.\n       (Unwind (inst UnwindInst))\n\n       ;; A pseudoinstruction that just keeps a value alive.\n       (DummyUse (reg Reg))))\n\n(type OperandSize extern\n      (enum Size8\n            Size16\n            Size32\n            Size64))\n\n(type FenceKind extern\n      (enum MFence\n            LFence\n            SFence))\n\n(type BoxCallInfo extern (enum))\n\n(type BoxVecMachLabel extern (enum))\n\n(type MachLabelSlice extern (enum))\n\n;; The size of the jump table.\n(decl jump_table_size (BoxVecMachLabel) u32)\n(extern constructor jump_table_size jump_table_size)\n\n;; Extract a the target from a MachLabelSlice with exactly one target.\n(decl single_target (MachLabel) MachLabelSlice)\n(extern extractor single_target single_target)\n\n;; Extract a the targets from a MachLabelSlice with exactly two targets.\n(decl two_targets (MachLabel MachLabel) MachLabelSlice)\n(extern extractor two_targets two_targets)\n\n;; Extract the default target and jump table from a MachLabelSlice.\n(decl jump_table_targets (MachLabel BoxVecMachLabel) MachLabelSlice)\n(extern extractor jump_table_targets jump_table_targets)\n\n;; Get the `OperandSize` for a given `Type`, rounding smaller types up to 32 bits.\n(decl operand_size_of_type_32_64 (Type) OperandSize)\n(extern constructor operand_size_of_type_32_64 operand_size_of_type_32_64)\n\n;; Get the true `OperandSize` for a given `Type`, with no rounding.\n(decl raw_operand_size_of_type (Type) OperandSize)\n(extern constructor raw_operand_size_of_type raw_operand_size_of_type)\n\n;; Get the bit width of an `OperandSize`.\n(decl operand_size_bits (OperandSize) u16)\n(rule (operand_size_bits (OperandSize.Size8)) 8)\n(rule (operand_size_bits (OperandSize.Size16)) 16)\n(rule (operand_size_bits (OperandSize.Size32)) 32)\n(rule (operand_size_bits (OperandSize.Size64)) 64)\n\n(type AluRmiROpcode extern\n      (enum Add\n            Adc\n            Sub\n            Sbb\n            And\n            Or\n            Xor\n            Mul))\n\n(type AluRmROpcode extern\n      (enum Andn))\n\n(type UnaryRmROpcode extern\n      (enum Bsr\n            Bsf\n            Lzcnt\n            Tzcnt\n            Popcnt))\n\n(type DivOrRemKind extern\n      (enum SignedDiv\n            UnsignedDiv\n            SignedRem\n            UnsignedRem))\n\n(type SseOpcode extern\n      (enum Addps\n            Addpd\n            Addss\n            Addsd\n            Andps\n            Andpd\n            Andnps\n            Andnpd\n            Blendvpd\n            Blendvps\n            Comiss\n            Comisd\n            Cmpps\n            Cmppd\n            Cmpss\n            Cmpsd\n            Cvtdq2ps\n            Cvtdq2pd\n            Cvtpd2ps\n            Cvtps2pd\n            Cvtsd2ss\n            Cvtsd2si\n            Cvtsi2ss\n            Cvtsi2sd\n            Cvtss2si\n            Cvtss2sd\n            Cvttpd2dq\n            Cvttps2dq\n            Cvttss2si\n            Cvttsd2si\n            Divps\n            Divpd\n            Divss\n            Divsd\n            Insertps\n            Maxps\n            Maxpd\n            Maxss\n            Maxsd\n            Minps\n            Minpd\n            Minss\n            Minsd\n            Movaps\n            Movapd\n            Movd\n            Movdqa\n            Movdqu\n            Movlhps\n            Movmskps\n            Movmskpd\n            Movq\n            Movss\n            Movsd\n            Movups\n            Movupd\n            Mulps\n            Mulpd\n            Mulss\n            Mulsd\n            Orps\n            Orpd\n            Pabsb\n            Pabsw\n            Pabsd\n            Packssdw\n            Packsswb\n            Packusdw\n            Packuswb\n            Paddb\n            Paddd\n            Paddq\n            Paddw\n            Paddsb\n            Paddsw\n            Paddusb\n            Paddusw\n            Palignr\n            Pand\n            Pandn\n            Pavgb\n            Pavgw\n            Pblendvb\n            Pcmpeqb\n            Pcmpeqw\n            Pcmpeqd\n            Pcmpeqq\n            Pcmpgtb\n            Pcmpgtw\n            Pcmpgtd\n            Pcmpgtq\n            Pextrb\n            Pextrw\n            Pextrd\n            Pextrq\n            Pinsrb\n            Pinsrw\n            Pinsrd\n            Pmaddubsw\n            Pmaddwd\n            Pmaxsb\n            Pmaxsw\n            Pmaxsd\n            Pmaxub\n            Pmaxuw\n            Pmaxud\n            Pminsb\n            Pminsw\n            Pminsd\n            Pminub\n            Pminuw\n            Pminud\n            Pmovmskb\n            Pmovsxbd\n            Pmovsxbw\n            Pmovsxbq\n            Pmovsxwd\n            Pmovsxwq\n            Pmovsxdq\n            Pmovzxbd\n            Pmovzxbw\n            Pmovzxbq\n            Pmovzxwd\n            Pmovzxwq\n            Pmovzxdq\n            Pmuldq\n            Pmulhw\n            Pmulhuw\n            Pmulhrsw\n            Pmulld\n            Pmullw\n            Pmuludq\n            Por\n            Pshufb\n            Pshufd\n            Psllw\n            Pslld\n            Psllq\n            Psraw\n            Psrad\n            Psrlw\n            Psrld\n            Psrlq\n            Psubb\n            Psubd\n            Psubq\n            Psubw\n            Psubsb\n            Psubsw\n            Psubusb\n            Psubusw\n            Ptest\n            Punpckhbw\n            Punpckhwd\n            Punpcklbw\n            Punpcklwd\n            Pxor\n            Rcpss\n            Roundps\n            Roundpd\n            Roundss\n            Roundsd\n            Rsqrtss\n            Shufps\n            Sqrtps\n            Sqrtpd\n            Sqrtss\n            Sqrtsd\n            Subps\n            Subpd\n            Subss\n            Subsd\n            Ucomiss\n            Ucomisd\n            Unpcklps\n            Xorps\n            Xorpd\n            Phaddw\n            Phaddd\n          ))\n\n(type CmpOpcode extern\n      (enum Cmp\n            Test))\n\n(type RegMemImm extern\n      (enum\n       (Reg (reg Reg))\n       (Mem (addr SyntheticAmode))\n       (Imm (simm32 u32))))\n\n;; Put the given clif value into a `RegMemImm` operand.\n;;\n;; Asserts that the value fits into a single register, and doesn't require\n;; multiple registers for its representation (like `i128` for example).\n;;\n;; As a side effect, this marks the value as used.\n(decl put_in_reg_mem_imm (Value) RegMemImm)\n(extern constructor put_in_reg_mem_imm put_in_reg_mem_imm)\n\n(type RegMem extern\n      (enum\n       (Reg (reg Reg))\n       (Mem (addr SyntheticAmode))))\n\n;; Convert a RegMem to a RegMemImm.\n(decl reg_mem_to_reg_mem_imm (RegMem) RegMemImm)\n(rule (reg_mem_to_reg_mem_imm (RegMem.Reg reg))\n      (RegMemImm.Reg reg))\n(rule (reg_mem_to_reg_mem_imm (RegMem.Mem addr))\n      (RegMemImm.Mem addr))\n\n;; Put the given clif value into a `RegMem` operand.\n;;\n;; Asserts that the value fits into a single register, and doesn't require\n;; multiple registers for its representation (like `i128` for example).\n;;\n;; As a side effect, this marks the value as used.\n(decl put_in_reg_mem (Value) RegMem)\n(extern constructor put_in_reg_mem put_in_reg_mem)\n\n;; Addressing modes.\n\n(type SyntheticAmode extern (enum))\n\n(decl synthetic_amode_to_reg_mem (SyntheticAmode) RegMem)\n(extern constructor synthetic_amode_to_reg_mem synthetic_amode_to_reg_mem)\n\n(decl amode_to_synthetic_amode (Amode) SyntheticAmode)\n(extern constructor amode_to_synthetic_amode amode_to_synthetic_amode)\n\n;; An `Amode` represents a possible addressing mode that can be used\n;; in instructions. These denote a 64-bit value only.\n(type Amode (enum\n             ;; Immediate sign-extended and a register\n             (ImmReg (simm32 u32)\n                     (base Reg)\n                     (flags MemFlags))\n\n             ;; Sign-extend-32-to-64(simm32) + base + (index << shift)\n             (ImmRegRegShift (simm32 u32)\n                             (base Gpr)\n                             (index Gpr)\n                             (shift u8)\n                             (flags MemFlags))\n\n             ;; Sign-extend-32-to-64(immediate) + RIP (instruction\n             ;; pointer). The appropriate relocation is emitted so\n             ;; that the resulting immediate makes this Amode refer to\n             ;; the given MachLabel.\n             (RipRelative (target MachLabel))))\n\n;; Some Amode constructor helpers.\n\n(decl amode_with_flags (Amode MemFlags) Amode)\n(extern constructor amode_with_flags amode_with_flags)\n\n(decl amode_imm_reg (u32 Gpr) Amode)\n(extern constructor amode_imm_reg amode_imm_reg)\n\n(decl amode_imm_reg_flags (u32 Gpr MemFlags) Amode)\n(rule (amode_imm_reg_flags offset base flags)\n      (amode_with_flags (amode_imm_reg offset base) flags))\n\n(decl amode_imm_reg_reg_shift (u32 Gpr Gpr u8) Amode)\n(extern constructor amode_imm_reg_reg_shift amode_imm_reg_reg_shift)\n\n(decl amode_imm_reg_reg_shift_flags (u32 Gpr Gpr u8 MemFlags) Amode)\n(rule (amode_imm_reg_reg_shift_flags offset base index shift flags)\n      (amode_with_flags (amode_imm_reg_reg_shift offset base index shift) flags))\n\n;; A helper to both check that the `Imm64` and `Offset32` values sum to less\n;; than 32-bits AND return this summed `u32` value. Also, the `Imm64` will be\n;; zero-extended from `Type` up to 64 bits. This is useful for `to_amode`.\n(decl pure partial sum_extend_fits_in_32_bits (Type Imm64 Offset32) u32)\n(extern constructor sum_extend_fits_in_32_bits sum_extend_fits_in_32_bits)\n\n;;;; Amode lowering ;;;;\n\n;; To generate an address for a memory access, we can pattern-match\n;; various CLIF sub-trees to x64's complex addressing modes (`Amode`).\n;;\n;; Information about available addressing modes is available in\n;; Intel's Software Developer's Manual, volume 2, section 2.1.5,\n;; \"Addressing-Mode Encoding of ModR/M and SIB Bytes.\"\n;;\n;; The general strategy to build an `Amode` is to traverse over the\n;; input expression's addends, recursively deconstructing a tree of\n;; `iadd` operators that add up parts of the address, updating the\n;; `Amode` in an incremental fashion as we add in each piece.\n;;\n;; We start with an \"immediate + register\" form that encapsulates the\n;; load/store's built-in `Offset32` and `invalid_reg` as the\n;; register. This is given by `amode_initial`. Then we add `Value`s\n;; one at a time with `amode_add`. (Why start with `invalid_reg` at\n;; all? Because we don't want to special-case the first input and\n;; duplicate rules; this lets us use the \"add a value\" logic even for\n;; the first value.)\n;;\n;; It is always valid to use `amode_add` to add the one single\n;; `address` input to the load/store (i.e., the `Value` given to\n;; `to_amode`). In the fallback case, this is what we do. Then we get\n;; an `Amode.ImmReg` with the `Offset32` and `Value` below and nothing\n;; else; this always works and is not *that* bad.\n;;\n;; But we can often do better. The toplevel rule for `iadd` below will\n;; turn an `(amode_add amode (iadd a b))` into two invocations of\n;; `amode_add`, for each operand of the `iadd`. This is what allows us\n;; to handle sums of many parts.\n;;\n;; Then we \"just\" need to work out how we can incorporate a new\n;; component into an existing addressing mode:\n;;\n;; - Case 1: When we have an `ImmReg` and the register is\n;;   `invalid_reg` (the initial `Amode` above), we can put the new\n;;   addend into a register and insert it into the `ImmReg`.\n;;\n;; - Case 2: When we have an `ImmReg` with a valid register already,\n;;   and we have another register to add, we can transition to an\n;;   `ImmRegRegShift`.\n;;\n;; - Case 3: When we're adding an `ishl`, we can refine the above rule\n;;   and use the built-in multiplier of 1, 2, 4, 8 to implement a\n;;   left-shift by 0, 1, 2, 3.\n;;\n;; - Case 4: When we are adding another constant offset, we can fold\n;;   it into the existing offset, as long as the sum still fits into\n;;   the signed 32-bit field.\n;;\n;; - Case 5: And as a general fallback, we can generate a new `add`\n;;   instruction and add the new addend to an existing component of\n;;   the `Amode`.\n(decl to_amode (MemFlags Value Offset32) Amode)\n\n;; Initial step in amode processing: create an ImmReg with\n;; (invalid_reg) and encapsulating the flags and offset from the\n;; load/store.\n(decl amode_initial (MemFlags Offset32) Amode)\n(rule (amode_initial flags (offset32 off))\n      (Amode.ImmReg off (invalid_reg) flags))\n\n;; One step in amode processing: take an existing amode and add\n;; another value to it.\n(decl amode_add (Amode Value) Amode)\n\n;; -- Top-level driver: pull apart the addends.\n;;\n;; Any amode can absorb an `iadd` by absorbing first the LHS of the\n;; add, then the RHS.\n;;\n;; Priority 2 to take this above fallbacks and ensure we traverse the\n;; `iadd` tree fully.\n(rule 2 (amode_add amode (iadd x y))\n      (let ((amode1 Amode (amode_add amode x))\n            (amode2 Amode (amode_add amode1 y)))\n        amode2))\n\n;; -- Case 1 (adding a register to the initial Amode with invalid_reg).\n;;\n;; An Amode.ImmReg with invalid_reg (initial state) can absorb a\n;; register as the base register.\n(rule (amode_add (Amode.ImmReg off (invalid_reg) flags) value)\n      (Amode.ImmReg off value flags))\n\n;; -- Case 2 (adding a register to an Amode with a register already).\n;;\n;; An Amode.ImmReg can absorb another register as the index register.\n(rule (amode_add (Amode.ImmReg off (valid_reg base) flags) value)\n      ;; Shift of 0 --> base + 1*value.\n      (Amode.ImmRegRegShift off base value 0 flags))\n\n;; -- Case 3 (adding a shifted value to an Amode).\n;;\n;; An Amode.ImmReg can absorb a shift of another register as the index register.\n;;\n;; Priority 2 to take these rules above generic case.\n(rule 2 (amode_add (Amode.ImmReg off (valid_reg base) flags) (ishl index (iconst (uimm8 shift))))\n      (if (u32_lteq (u8_as_u32 shift) 3))\n      (Amode.ImmRegRegShift off base index shift flags))\n\n;; -- Case 4 (absorbing constant offsets).\n;;\n;; An Amode can absorb a constant (i64, or extended i32) as long as\n;; the sum still fits in the signed-32-bit offset.\n;;\n;; Priority 3 in order to take this option above the fallback\n;; (immediate in register). Two rules, for imm+reg and\n;; imm+reg+scale*reg cases.\n(rule 3 (amode_add (Amode.ImmReg off base flags)\n                   (iconst (simm32 c)))\n      (if-let sum (s32_add_fallible off c))\n      (Amode.ImmReg sum base flags))\n(rule 3 (amode_add (Amode.ImmRegRegShift off base index shift flags)\n                   (iconst (simm32 c)))\n      (if-let sum (s32_add_fallible off c))\n      (Amode.ImmRegRegShift sum base index shift flags))\n\n;; Likewise for a zero-extended i32 const, as long as the constant\n;; wasn't negative. (Why nonnegative? Because adding a\n;; non-sign-extended negative to a 64-bit address is not the same as\n;; adding in simm32-space.)\n(rule 3 (amode_add (Amode.ImmReg off base flags)\n                   (uextend (iconst (simm32 (u32_nonnegative c)))))\n      (if-let sum (s32_add_fallible off c))\n      (Amode.ImmReg sum base flags))\n(rule 3 (amode_add (Amode.ImmRegRegShift off base index shift flags)\n                   (uextend (iconst (simm32 (u32_nonnegative c)))))\n      (if-let sum (s32_add_fallible off c))\n      (Amode.ImmRegRegShift sum base index shift flags))\n\n;; Likewise for a sign-extended i32 const.\n(rule 3 (amode_add (Amode.ImmReg off base flags)\n                   (sextend (iconst (simm32 c))))\n      (if-let sum (s32_add_fallible off c))\n      (Amode.ImmReg sum base flags))\n(rule 3 (amode_add (Amode.ImmRegRegShift off base index shift flags)\n                   (sextend (iconst (simm32 c))))\n      (if-let sum (s32_add_fallible off c))\n      (Amode.ImmRegRegShift sum base index shift flags))\n\n;; -- Case 5 (fallback to add a new value to an imm+reg+scale*reg).\n;;\n;; An Amode.ImmRegRegShift can absorb any other value by creating a\n;; new add instruction and replacing the base with\n;; (base+value).\n(rule (amode_add (Amode.ImmRegRegShift off base index shift flags) value)\n      (let ((sum Gpr (x64_add $I64 base value)))\n        (Amode.ImmRegRegShift off sum index shift flags)))\n\n;; Finally, define the toplevel `to_amode`.\n(rule (to_amode flags base offset)\n      (amode_finalize (amode_add (amode_initial flags offset) base)))\n\n;; If an amode has no registers at all and only offsets (a constant\n;; value), we need to \"finalize\" it by sticking in a zero'd reg in\n;; place of the (invalid_reg) produced by (amode_initial).\n(decl amode_finalize (Amode) Amode)\n(rule 1 (amode_finalize (Amode.ImmReg off (invalid_reg) flags))\n      (Amode.ImmReg off (imm $I64 0) flags))\n(rule 0 (amode_finalize amode)\n      amode)\n\n;; Offsetting an Amode. Used when we need to do consecutive\n;; loads/stores to adjacent addresses.\n(decl amode_offset (Amode u32) Amode)\n(extern constructor amode_offset amode_offset)\n\n;; Return a zero offset as an `Offset32`.\n(decl zero_offset () Offset32)\n(extern constructor zero_offset zero_offset)\n\n;; Shift kinds.\n\n(type ShiftKind extern\n      (enum ShiftLeft\n            ShiftRightLogical\n            ShiftRightArithmetic\n            RotateLeft\n            RotateRight))\n\n(type Imm8Reg extern\n      (enum (Imm8 (imm u8))\n            (Reg (reg Reg))))\n\n;; Put the given clif value into a `Imm8Reg` operand, masked to the bit width of\n;; the given type.\n;;\n;; Asserts that the value fits into a single register, and doesn't require\n;; multiple registers for its representation (like `i128` for example).\n;;\n;; As a side effect, this marks the value as used.\n;;\n;; This is used when lowering various shifts and rotates.\n(decl put_masked_in_imm8_gpr (Value Type) Imm8Gpr)\n(rule 2 (put_masked_in_imm8_gpr (u64_from_iconst amt) ty)\n      (const_to_type_masked_imm8 amt ty))\n(rule 1 (put_masked_in_imm8_gpr amt (fits_in_16 ty))\n      (x64_and $I64 (value_regs_get_gpr amt 0) (RegMemImm.Imm (shift_mask ty))))\n(rule (put_masked_in_imm8_gpr amt ty)\n      (value_regs_get_gpr amt 0))\n\n;; Condition codes\n(type CC extern\n      (enum O\n            NO\n            B\n            NB\n            Z\n            NZ\n            BE\n            NBE\n            S\n            NS\n            L\n            NL\n            LE\n            NLE\n            P\n            NP))\n\n(decl intcc_to_cc (IntCC) CC)\n(extern constructor intcc_to_cc intcc_to_cc)\n\n(decl cc_invert (CC) CC)\n(extern constructor cc_invert cc_invert)\n\n;; Fails if the argument is not either CC.NZ or CC.Z.\n(decl cc_nz_or_z (CC) CC)\n(extern extractor cc_nz_or_z cc_nz_or_z)\n\n(type AvxOpcode\n      (enum Vfmadd213ss\n            Vfmadd213sd\n            Vfmadd213ps\n            Vfmadd213pd\n            Vfmadd132ss\n            Vfmadd132sd\n            Vfmadd132ps\n            Vfmadd132pd\n            Vfnmadd213ss\n            Vfnmadd213sd\n            Vfnmadd213ps\n            Vfnmadd213pd\n            Vfnmadd132ss\n            Vfnmadd132sd\n            Vfnmadd132ps\n            Vfnmadd132pd\n            Vcmpps\n            Vcmppd\n            Vpsrlw\n            Vpsrld\n            Vpsrlq\n            Vpaddb\n            Vpaddw\n            Vpaddd\n            Vpaddq\n            Vpaddsb\n            Vpaddsw\n            Vpaddusb\n            Vpaddusw\n            Vpsubb\n            Vpsubw\n            Vpsubd\n            Vpsubq\n            Vpsubsb\n            Vpsubsw\n            Vpsubusb\n            Vpsubusw\n            Vpavgb\n            Vpavgw\n            Vpand\n            Vandps\n            Vandpd\n            Vpor\n            Vorps\n            Vorpd\n            Vpxor\n            Vxorps\n            Vxorpd\n            Vpmullw\n            Vpmulld\n            Vpmulhw\n            Vpmulhd\n            Vpmulhrsw\n            Vpmulhuw\n            Vpmuldq\n            Vpmuludq\n            Vpunpckhwd\n            Vpunpcklwd\n            Vunpcklps\n            Vandnps\n            Vandnpd\n            Vpandn\n            Vaddps\n            Vaddpd\n            Vsubps\n            Vsubpd\n            Vmulps\n            Vmulpd\n            Vdivps\n            Vdivpd\n            Vpcmpeqb\n            Vpcmpeqw\n            Vpcmpeqd\n            Vpcmpeqq\n            Vpcmpgtb\n            Vpcmpgtw\n            Vpcmpgtd\n            Vpcmpgtq\n            Vminps\n            Vminpd\n            Vmaxps\n            Vmaxpd\n            Vblendvpd\n            Vblendvps\n            Vpblendvb\n            Vmovlhps\n            Vpmaxsb\n            Vpmaxsw\n            Vpmaxsd\n            Vpminsb\n            Vpminsw\n            Vpminsd\n            Vpmaxub\n            Vpmaxuw\n            Vpmaxud\n            Vpminub\n            Vpminuw\n            Vpminud\n            Vpunpcklbw\n            Vpunpckhbw\n            Vpacksswb\n            Vpackssdw\n            Vpackuswb\n            Vpackusdw\n            Vpalignr\n            Vpinsrb\n            Vpinsrw\n            Vpinsrd\n            Vpinsrq\n            Vpmaddwd\n            Vpmaddubsw\n            Vinsertps\n            Vpshufb\n            Vshufps\n            Vpsllw\n            Vpslld\n            Vpsllq\n            Vpsraw\n            Vpsrad\n            Vpmovsxbw\n            Vpmovzxbw\n            Vpmovsxwd\n            Vpmovzxwd\n            Vpmovsxdq\n            Vpmovzxdq\n            Vaddss\n            Vaddsd\n            Vmulss\n            Vmulsd\n            Vsubss\n            Vsubsd\n            Vdivss\n            Vdivsd\n            Vpabsb\n            Vpabsw\n            Vpabsd\n            Vminss\n            Vminsd\n            Vmaxss\n            Vmaxsd\n            Vsqrtps\n            Vsqrtpd\n            Vroundps\n            Vroundpd\n            Vcvtdq2pd\n            Vcvtdq2ps\n            Vcvtpd2ps\n            Vcvtps2pd\n            Vcvttpd2dq\n            Vcvttps2dq\n            Vphaddw\n            Vphaddd\n          ))\n\n(type Avx512Opcode extern\n      (enum Vcvtudq2ps\n            Vpabsq\n            Vpermi2b\n            Vpmullq\n            Vpopcntb))\n\n(type FcmpImm extern\n      (enum Equal\n            LessThan\n            LessThanOrEqual\n            Unordered\n            NotEqual\n            UnorderedOrGreaterThanOrEqual\n            UnorderedOrGreaterThan\n            Ordered))\n\n(decl encode_fcmp_imm (FcmpImm) u8)\n(extern constructor encode_fcmp_imm encode_fcmp_imm)\n\n(type RoundImm extern\n      (enum RoundNearest\n            RoundDown\n            RoundUp\n            RoundZero))\n\n(decl encode_round_imm (RoundImm) u8)\n(extern constructor encode_round_imm encode_round_imm)\n\n;;;; Newtypes for Different Register Classes ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n\n(type Gpr (primitive Gpr))\n(type WritableGpr (primitive WritableGpr))\n(type OptionWritableGpr (primitive OptionWritableGpr))\n(type GprMem extern (enum))\n(type GprMemImm extern (enum))\n(type Imm8Gpr extern (enum))\n\n(type Xmm (primitive Xmm))\n(type WritableXmm (primitive WritableXmm))\n(type OptionWritableXmm (primitive OptionWritableXmm))\n(type XmmMem extern (enum))\n(type XmmMemAligned extern (enum))\n(type XmmMemImm extern (enum))\n(type XmmMemAlignedImm extern (enum))\n\n;; Convert an `Imm8Reg` into an `Imm8Gpr`.\n(decl imm8_reg_to_imm8_gpr (Imm8Reg) Imm8Gpr)\n(extern constructor imm8_reg_to_imm8_gpr imm8_reg_to_imm8_gpr)\n\n;; Convert a `WritableGpr` to a `WritableReg`.\n(decl writable_gpr_to_reg (WritableGpr) WritableReg)\n(extern constructor writable_gpr_to_reg writable_gpr_to_reg)\n\n;; Convert a `WritableXmm` to a `WritableReg`.\n(decl writable_xmm_to_reg (WritableXmm) WritableReg)\n(extern constructor writable_xmm_to_reg writable_xmm_to_reg)\n\n;; Convert a `WritableReg` to a `WritableXmm`.\n(decl writable_reg_to_xmm (WritableReg) WritableXmm)\n(extern constructor writable_reg_to_xmm writable_reg_to_xmm)\n\n;; Convert a `WritableXmm` to an `Xmm`.\n(decl writable_xmm_to_xmm (WritableXmm) Xmm)\n(extern constructor writable_xmm_to_xmm writable_xmm_to_xmm)\n\n;; Convert a `WritableGpr` to an `Gpr`.\n(decl writable_gpr_to_gpr (WritableGpr) Gpr)\n(extern constructor writable_gpr_to_gpr writable_gpr_to_gpr)\n\n;; Convert an `Gpr` to a `Reg`.\n(decl gpr_to_reg (Gpr) Reg)\n(extern constructor gpr_to_reg gpr_to_reg)\n\n;; Convert an `Gpr` to a `GprMem`.\n(decl gpr_to_gpr_mem (Gpr) GprMem)\n(extern constructor gpr_to_gpr_mem gpr_to_gpr_mem)\n\n;; Convert an `Gpr` to a `GprMemImm`.\n(decl gpr_to_gpr_mem_imm (Gpr) GprMemImm)\n(extern constructor gpr_to_gpr_mem_imm gpr_to_gpr_mem_imm)\n\n;; Convert an `Xmm` to a `Reg`.\n(decl xmm_to_reg (Xmm) Reg)\n(extern constructor xmm_to_reg xmm_to_reg)\n\n;; Convert an `Xmm` into an `XmmMemImm`.\n(decl xmm_to_xmm_mem_imm (Xmm) XmmMemImm)\n(extern constructor xmm_to_xmm_mem_imm xmm_to_xmm_mem_imm)\n\n;; Convert an `XmmMem` into an `XmmMemImm`.\n(decl xmm_mem_to_xmm_mem_imm (XmmMem) XmmMemImm)\n(extern constructor xmm_mem_to_xmm_mem_imm xmm_mem_to_xmm_mem_imm)\n\n;; Convert an `XmmMem` into an `XmmMemAligned`.\n;;\n;; Note that this is an infallible conversion, not a fallible one. If the\n;; original `XmmMem` source is a register, then it's passed through directly.\n;; If it's `Mem` and refers to aligned memory, it's also passed through\n;; directly. Otherwise, though, it's a memory source which is not aligned to\n;; 16 bytes so a load is performed and the temporary register which is the\n;; result of the load is passed through. The end-result is that the return value\n;; here is guaranteed to be a register or an aligned memory location.\n(decl xmm_mem_to_xmm_mem_aligned (XmmMem) XmmMemAligned)\n(extern constructor xmm_mem_to_xmm_mem_aligned xmm_mem_to_xmm_mem_aligned)\n\n;; Convert an `XmmMemImm` into an `XmmMemImmAligned`.\n;;\n;; Note that this is the same as `xmm_mem_to_xmm_mem_aligned` except it handles\n;; an immediate case as well.\n(decl xmm_mem_imm_to_xmm_mem_aligned_imm (XmmMemImm) XmmMemAlignedImm)\n(extern constructor xmm_mem_imm_to_xmm_mem_aligned_imm xmm_mem_imm_to_xmm_mem_aligned_imm)\n\n;; Allocate a new temporary GPR register.\n(decl temp_writable_gpr () WritableGpr)\n(extern constructor temp_writable_gpr temp_writable_gpr)\n\n;; Allocate a new temporary XMM register.\n(decl temp_writable_xmm () WritableXmm)\n(extern constructor temp_writable_xmm temp_writable_xmm)\n\n;; Construct a new `XmmMem` from the given `RegMem`.\n;;\n;; Asserts that the `RegMem`'s register, if any, is an XMM register.\n(decl reg_mem_to_xmm_mem (RegMem) XmmMem)\n(extern constructor reg_mem_to_xmm_mem reg_mem_to_xmm_mem)\n\n;; Construct a new `RegMemImm` from the given `Reg`.\n(decl reg_to_reg_mem_imm (Reg) RegMemImm)\n(extern constructor reg_to_reg_mem_imm reg_to_reg_mem_imm)\n\n;; Construct a new `GprMemImm` from the given `RegMemImm`.\n;;\n;; Asserts that the `RegMemImm`'s register, if any, is an GPR register.\n(decl gpr_mem_imm_new (RegMemImm) GprMemImm)\n(extern constructor gpr_mem_imm_new gpr_mem_imm_new)\n\n;; Construct a new `XmmMemImm` from the given `RegMemImm`.\n;;\n;; Asserts that the `RegMemImm`'s register, if any, is an XMM register.\n(decl xmm_mem_imm_new (RegMemImm) XmmMemImm)\n(extern constructor xmm_mem_imm_new xmm_mem_imm_new)\n\n;; Construct a new `XmmMem` from an `Xmm`.\n(decl xmm_to_xmm_mem (Xmm) XmmMem)\n(extern constructor xmm_to_xmm_mem xmm_to_xmm_mem)\n\n;; Construct a new `XmmMem` from an `RegMem`.\n(decl xmm_mem_to_reg_mem (XmmMem) RegMem)\n(extern constructor xmm_mem_to_reg_mem xmm_mem_to_reg_mem)\n\n;; Convert a `GprMem` to a `RegMem`.\n(decl gpr_mem_to_reg_mem (GprMem) RegMem)\n(extern constructor gpr_mem_to_reg_mem gpr_mem_to_reg_mem)\n\n;; Construct a new `Xmm` from a `Reg`.\n;;\n;; Asserts that the register is a XMM.\n(decl xmm_new (Reg) Xmm)\n(extern constructor xmm_new xmm_new)\n\n;; Construct a new `Gpr` from a `Reg`.\n;;\n;; Asserts that the register is a GPR.\n(decl gpr_new (Reg) Gpr)\n(extern constructor gpr_new gpr_new)\n\n;; Construct a new `GprMem` from a `RegMem`.\n;;\n;; Asserts that the `RegMem`'s register, if any, is a GPR.\n(decl reg_mem_to_gpr_mem (RegMem) GprMem)\n(extern constructor reg_mem_to_gpr_mem reg_mem_to_gpr_mem)\n\n;; Construct a `GprMem` from a `Reg`.\n;;\n;; Asserts that the `Reg` is a GPR.\n(decl reg_to_gpr_mem (Reg) GprMem)\n(extern constructor reg_to_gpr_mem reg_to_gpr_mem)\n\n;; Construct a `GprMemImm` from a `Reg`.\n;;\n;; Asserts that the `Reg` is a GPR.\n(decl reg_to_gpr_mem_imm (Reg) GprMemImm)\n(rule (reg_to_gpr_mem_imm r)\n      (gpr_to_gpr_mem_imm (gpr_new r)))\n\n;; Put a value into a GPR.\n;;\n;; Asserts that the value goes into a GPR.\n(decl put_in_gpr (Value) Gpr)\n(rule (put_in_gpr val)\n      (gpr_new (put_in_reg val)))\n\n;; Put a value into a `GprMem`.\n;;\n;; Asserts that the value goes into a GPR.\n(decl put_in_gpr_mem (Value) GprMem)\n(rule (put_in_gpr_mem val)\n      (reg_mem_to_gpr_mem (put_in_reg_mem val)))\n\n;; Put a value into a `GprMemImm`.\n;;\n;; Asserts that the value goes into a GPR.\n(decl put_in_gpr_mem_imm (Value) GprMemImm)\n(rule (put_in_gpr_mem_imm val)\n      (gpr_mem_imm_new (put_in_reg_mem_imm val)))\n\n;; Put a value into a XMM.\n;;\n;; Asserts that the value goes into a XMM.\n(decl put_in_xmm (Value) Xmm)\n(rule (put_in_xmm val)\n      (xmm_new (put_in_reg val)))\n\n;; Put a value into a `XmmMem`.\n;;\n;; Asserts that the value goes into a XMM.\n(decl put_in_xmm_mem (Value) XmmMem)\n(extern constructor put_in_xmm_mem put_in_xmm_mem)\n\n;; Put a value into a `XmmMemImm`.\n;;\n;; Asserts that the value goes into a XMM.\n(decl put_in_xmm_mem_imm (Value) XmmMemImm)\n(extern constructor put_in_xmm_mem_imm put_in_xmm_mem_imm)\n\n;; Construct an `InstOutput` out of a single GPR register.\n(decl output_gpr (Gpr) InstOutput)\n(rule (output_gpr x)\n      (output_reg (gpr_to_reg x)))\n\n;; Construct a `ValueRegs` out of two GPR registers.\n(decl value_gprs (Gpr Gpr) ValueRegs)\n(rule (value_gprs x y)\n      (value_regs (gpr_to_reg x) (gpr_to_reg y)))\n\n;; Construct an `InstOutput` out of a single XMM register.\n(decl output_xmm (Xmm) InstOutput)\n(rule (output_xmm x)\n      (output_reg (xmm_to_reg x)))\n\n;; Get the `n`th reg in a `ValueRegs` and construct a GPR from it.\n;;\n;; Asserts that the register is a GPR.\n(decl value_regs_get_gpr (ValueRegs usize) Gpr)\n(rule (value_regs_get_gpr regs n)\n      (gpr_new (value_regs_get regs n)))\n\n;; Convert a `Gpr` to an `Imm8Gpr`.\n(decl gpr_to_imm8_gpr (Gpr) Imm8Gpr)\n(extern constructor gpr_to_imm8_gpr gpr_to_imm8_gpr)\n\n;; Convert an 8-bit immediate into an `Imm8Gpr`.\n(decl imm8_to_imm8_gpr (u8) Imm8Gpr)\n(extern constructor imm8_to_imm8_gpr imm8_to_imm8_gpr)\n\n;; Get the low half of the given `Value` as a GPR.\n(decl lo_gpr (Value) Gpr)\n(rule (lo_gpr regs) (gpr_new (lo_reg regs)))\n\n;;;; Helpers for Working With Integer Comparison Codes ;;;;;;;;;;;;;;;;;;;;;;;;;\n;;\n\n;; This is a direct import of `IntCC::without_equal`.\n;; Get the corresponding IntCC with the equal component removed.\n;; For conditions without a zero component, this is a no-op.\n(decl intcc_without_eq (IntCC) IntCC)\n(extern constructor intcc_without_eq intcc_without_eq)\n\n;;;; Helpers for determining the register class of a value type ;;;;;;;;;;;;;;;;\n\n(type RegisterClass\n      (enum\n        (Gpr (single_register bool))\n        (Xmm)))\n\n(decl type_register_class (RegisterClass) Type)\n(extern extractor type_register_class type_register_class)\n\n(decl is_xmm_type (Type) Type)\n(extractor (is_xmm_type ty) (and (type_register_class (RegisterClass.Xmm)) ty))\n\n(decl is_gpr_type (Type) Type)\n(extractor (is_gpr_type ty) (and (type_register_class (RegisterClass.Gpr _)) ty))\n\n(decl is_single_register_gpr_type (Type) Type)\n(extractor (is_single_register_gpr_type ty)\n           (and (type_register_class (RegisterClass.Gpr $true)) ty))\n\n(decl is_multi_register_gpr_type (Type) Type)\n(extractor (is_multi_register_gpr_type ty)\n           (and (type_register_class (RegisterClass.Gpr $false)) ty))\n\n;;;; Helpers for Querying Enabled ISA Extensions ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n\n(decl avx512vl_enabled (bool) Type)\n(extern extractor infallible avx512vl_enabled avx512vl_enabled)\n\n(decl avx512dq_enabled (bool) Type)\n(extern extractor infallible avx512dq_enabled avx512dq_enabled)\n\n(decl avx512f_enabled (bool) Type)\n(extern extractor infallible avx512f_enabled avx512f_enabled)\n\n(decl avx512bitalg_enabled (bool) Type)\n(extern extractor infallible avx512bitalg_enabled avx512bitalg_enabled)\n\n(decl avx512vbmi_enabled (bool) Type)\n(extern extractor infallible avx512vbmi_enabled avx512vbmi_enabled)\n\n(decl use_lzcnt (bool) Type)\n(extern extractor infallible use_lzcnt use_lzcnt)\n\n(decl use_bmi1 (bool) Type)\n(extern extractor infallible use_bmi1 use_bmi1)\n\n(decl use_popcnt (bool) Type)\n(extern extractor infallible use_popcnt use_popcnt)\n\n(decl pure use_fma () bool)\n(extern constructor use_fma use_fma)\n\n(decl use_sse41 (bool) Type)\n(extern extractor infallible use_sse41 use_sse41)\n\n(decl pure has_avx () bool)\n(extern constructor has_avx has_avx)\n\n;;;; Helpers for Merging and Sinking Immediates/Loads  ;;;;;;;;;;;;;;;;;;;;;;;;;\n\n;; Extract a constant `Imm8Reg.Imm8` from a value operand.\n(decl imm8_from_value (Imm8Reg) Value)\n(extern extractor imm8_from_value imm8_from_value)\n\n;; Mask a constant to the bit-width of the given type and package it into an\n;; `Imm8Reg.Imm8`. This is used for shifts and rotates, so that we don't try and\n;; shift/rotate more bits than the type has available, per Cranelift's\n;; semantics.\n(decl const_to_type_masked_imm8 (u64 Type) Imm8Gpr)\n(extern constructor const_to_type_masked_imm8 const_to_type_masked_imm8)\n\n;; Generate a mask for the bit-width of the given type\n(decl shift_mask (Type) u32)\n(extern constructor shift_mask shift_mask)\n\n;; Mask a constant with the type's shift mask\n(decl shift_amount_masked (Type Imm64) u32)\n(extern constructor shift_amount_masked shift_amount_masked)\n\n;; Extract a constant `GprMemImm.Imm` from a value operand.\n(decl simm32_from_value (GprMemImm) Value)\n(extern extractor simm32_from_value simm32_from_value)\n\n;; Extract a constant `RegMemImm.Imm` from an `Imm64` immediate.\n(decl simm32_from_imm64 (GprMemImm) Imm64)\n(extern extractor simm32_from_imm64 simm32_from_imm64)\n\n;; A load that can be sunk into another operation.\n(type SinkableLoad extern (enum))\n\n;; Extract a `SinkableLoad` that works with `RegMemImm.Mem` from a value\n;; operand.\n(decl sinkable_load (SinkableLoad) Value)\n(extern extractor sinkable_load sinkable_load)\n\n;; Sink a `SinkableLoad` into a `RegMemImm.Mem`.\n;;\n;; This is a side-effectful operation that notifies the context that the\n;; instruction that produced the `SinkableImm` has been sunk into another\n;; instruction, and no longer needs to be lowered.\n(decl sink_load (SinkableLoad) RegMem)\n(extern constructor sink_load sink_load)\n\n(decl sink_load_to_gpr_mem_imm (SinkableLoad) GprMemImm)\n(rule (sink_load_to_gpr_mem_imm load)\n      (gpr_mem_imm_new (sink_load load)))\n\n(decl sink_load_to_xmm_mem (SinkableLoad) XmmMem)\n(rule (sink_load_to_xmm_mem load)\n      (reg_mem_to_xmm_mem (sink_load load)))\n\n;;;; Helpers for Sign/Zero Extending ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n\n(type ExtKind extern\n      (enum None\n            SignExtend\n            ZeroExtend))\n\n(type ExtendKind (enum Sign Zero))\n\n(type ExtMode extern (enum BL BQ WL WQ LQ))\n\n;; `ExtMode::new`\n(decl ext_mode (u16 u16) ExtMode)\n(extern constructor ext_mode ext_mode)\n\n;; Put the given value into a register, but extended as the given type.\n(decl extend_to_gpr (Value Type ExtendKind) Gpr)\n\n;; If the value is already of the requested type, no extending is necessary.\n;;\n;; Priority 1 because the equality constraint doesn't prove that this rule\n;; doesn't overlap with the one below.\n(rule 1 (extend_to_gpr (and val (value_type ty)) ty _kind)\n      (put_in_gpr val))\n\n(rule (extend_to_gpr (and val (value_type from_ty))\n                     to_ty\n                     kind)\n      (let ((from_bits u16 (ty_bits_u16 from_ty))\n            ;; Use `operand_size_of_type` so that the we clamp the output to 32-\n            ;; or 64-bit width types.\n            (to_bits u16 (operand_size_bits (operand_size_of_type_32_64 to_ty))))\n        (extend kind\n                to_ty\n                (ext_mode from_bits to_bits)\n                (put_in_gpr_mem val))))\n\n;; Do a sign or zero extension of the given `GprMem`.\n(decl extend (ExtendKind Type ExtMode GprMem) Gpr)\n\n;; Zero extending uses `movzx`.\n(rule (extend (ExtendKind.Zero) ty mode src)\n      (x64_movzx mode src))\n\n;; Sign extending uses `movsx`.\n(rule (extend (ExtendKind.Sign) ty mode src)\n      (x64_movsx mode src))\n\n;;;; Helpers for Working SSE tidbits ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n\n;; Turn a vector type into its integer-typed vector equivalent.\n(decl vec_int_type (Type) Type)\n(rule (vec_int_type (multi_lane 8 16)) $I8X16)\n(rule (vec_int_type (multi_lane 16 8)) $I16X8)\n(rule (vec_int_type (multi_lane 32 4)) $I32X4)\n(rule (vec_int_type (multi_lane 64 2)) $I64X2)\n\n;; Determine the appropriate operation for xor-ing vectors of the specified type\n(decl sse_xor_op (Type) SseOpcode)\n(rule 1 (sse_xor_op $F32X4) (SseOpcode.Xorps))\n(rule 1 (sse_xor_op $F64X2) (SseOpcode.Xorpd))\n(rule 1 (sse_xor_op $F32) (SseOpcode.Xorps))\n(rule 1 (sse_xor_op $F64) (SseOpcode.Xorpd))\n\n;; Priority 0 because multi_lane overlaps with the previous two explicit type\n;; patterns.\n(rule 0 (sse_xor_op (multi_lane _bits _lanes)) (SseOpcode.Pxor))\n\n(decl avx_xor_op (Type) AvxOpcode)\n(rule 1 (avx_xor_op $F32X4) (AvxOpcode.Vxorps))\n(rule 1 (avx_xor_op $F64X2) (AvxOpcode.Vxorpd))\n(rule 0 (avx_xor_op (multi_lane _bits _lanes)) (AvxOpcode.Vpxor))\n\n;; Performs an xor operation of the two operands specified.\n(decl sse_xor (Type Xmm XmmMem) Xmm)\n(rule 0 (sse_xor ty x y) (xmm_rm_r (sse_xor_op ty) x y))\n(rule 1 (sse_xor ty @ (multi_lane _ _) x y)\n        (if-let $true (has_avx))\n        (xmm_rmir_vex (avx_xor_op ty) x y))\n\n;; Generates a register value which has an all-ones pattern.\n;;\n;; Note that this is accomplished by comparing a fresh register with itself,\n;; which for integers is always true. Also note that the comparison is always\n;; done for integers. This is because we're comparing a fresh register to itself\n;; and we don't know the previous contents of the register. If a floating-point\n;; comparison is used then it runs the risk of comparing NaN against NaN and not\n;; actually producing an all-ones mask. By using integer comparision operations\n;; we're guaranteeed that everything is equal to itself.\n(decl vector_all_ones () Xmm)\n(rule (vector_all_ones)\n      (let ((r WritableXmm (temp_writable_xmm))\n            (_ Unit (emit (MInst.XmmConstOp (SseOpcode.Pcmpeqd) r))))\n        r))\n\n;; Helper for creating XmmUninitializedValue instructions.\n(decl xmm_uninit_value () Xmm)\n(rule (xmm_uninit_value)\n      (let ((dst WritableXmm (temp_writable_xmm))\n            (_ Unit (emit (MInst.XmmUninitializedValue dst))))\n        dst))\n\n;; Helper for creating an SSE register holding an `i64x2` from two `i64` values.\n(decl make_i64x2_from_lanes (GprMem GprMem) Xmm)\n(rule (make_i64x2_from_lanes lo hi)\n      (let ((dst Xmm (xmm_uninit_value))\n            (dst Xmm (x64_pinsrq dst lo 0))\n            (dst Xmm (x64_pinsrq dst hi 1)))\n        dst))\n\n;; Move a `RegMemImm.Reg` operand to an XMM register, if necessary.\n(decl mov_rmi_to_xmm (RegMemImm) XmmMemImm)\n(rule (mov_rmi_to_xmm rmi @ (RegMemImm.Mem _)) (xmm_mem_imm_new rmi))\n(rule (mov_rmi_to_xmm rmi @ (RegMemImm.Imm _)) (xmm_mem_imm_new rmi))\n(rule (mov_rmi_to_xmm (RegMemImm.Reg r))\n      (gpr_to_xmm (SseOpcode.Movd)\n                  r\n                  (OperandSize.Size32)))\n\n;;;; Helpers for Emitting Calls ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n\n(decl gen_call (SigRef ExternalName RelocDistance ValueSlice) InstOutput)\n(extern constructor gen_call gen_call)\n\n(decl gen_call_indirect (SigRef Value ValueSlice) InstOutput)\n(extern constructor gen_call_indirect gen_call_indirect)\n\n;;;; Helpers for Emitting Loads ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n\n;; Helper for constructing a LoadExtName instruction.\n(decl load_ext_name (ExternalName i64) Reg)\n(rule (load_ext_name extname offset)\n      (let ((dst WritableGpr (temp_writable_gpr))\n            (_ Unit (emit (MInst.LoadExtName dst extname offset))))\n        dst))\n\n;; Load a value into a register.\n(decl x64_load (Type SyntheticAmode ExtKind) Reg)\n\n(rule 1 (x64_load (fits_in_32 ty) addr (ExtKind.SignExtend))\n      (x64_movsx (ext_mode (ty_bytes ty) 8)\n             addr))\n\n(rule 2 (x64_load $I64 addr _ext_kind)\n      (let ((dst WritableGpr (temp_writable_gpr))\n            (_ Unit (emit (MInst.Mov64MR addr dst))))\n        dst))\n\n(rule 2 (x64_load $F32 addr _ext_kind)\n      (xmm_unary_rm_r_unaligned (SseOpcode.Movss) addr))\n\n(rule 2 (x64_load $F64 addr _ext_kind)\n      (xmm_unary_rm_r_unaligned (SseOpcode.Movsd) addr))\n\n(rule 2 (x64_load $F32X4 addr _ext_kind)\n      (xmm_unary_rm_r_unaligned (SseOpcode.Movups) addr))\n\n(rule 2 (x64_load $F64X2 addr _ext_kind)\n      (xmm_unary_rm_r_unaligned (SseOpcode.Movupd) addr))\n\n(rule 0 (x64_load (multi_lane _bits _lanes) addr _ext_kind)\n      (xmm_unary_rm_r_unaligned (SseOpcode.Movdqu) addr))\n\n(decl x64_mov (Amode) Reg)\n(rule (x64_mov addr)\n      (let ((dst WritableGpr (temp_writable_gpr))\n            (_ Unit (emit (MInst.Mov64MR addr dst))))\n        dst))\n\n(decl x64_movzx (ExtMode GprMem) Gpr)\n(rule (x64_movzx mode src)\n      (let ((dst WritableGpr (temp_writable_gpr))\n            (_ Unit (emit (MInst.MovzxRmR mode src dst))))\n        dst))\n\n(decl x64_movsx (ExtMode GprMem) Gpr)\n(rule (x64_movsx mode src)\n      (let ((dst WritableGpr (temp_writable_gpr))\n            (_ Unit (emit (MInst.MovsxRmR mode src dst))))\n        dst))\n\n(decl x64_movss_load (XmmMem) Xmm)\n(rule (x64_movss_load from)\n      (xmm_unary_rm_r_unaligned (SseOpcode.Movss) from))\n\n(decl x64_movsd_load (XmmMem) Xmm)\n(rule (x64_movsd_load from)\n      (xmm_unary_rm_r_unaligned (SseOpcode.Movsd) from))\n\n(decl x64_movups (XmmMem) Xmm)\n(rule (x64_movups from)\n      (xmm_unary_rm_r_unaligned (SseOpcode.Movups) from))\n\n(decl x64_movupd (XmmMem) Xmm)\n(rule (x64_movupd from)\n      (xmm_unary_rm_r_unaligned (SseOpcode.Movupd) from))\n\n(decl x64_movd (Xmm) Gpr)\n(rule (x64_movd from)\n      (xmm_to_gpr (SseOpcode.Movd) from (OperandSize.Size32)))\n\n(decl x64_movdqu (XmmMem) Xmm)\n(rule (x64_movdqu from)\n      (xmm_unary_rm_r_unaligned (SseOpcode.Movdqu) from))\n\n(decl x64_pmovsxbw (XmmMem) Xmm)\n(rule (x64_pmovsxbw from)\n      (xmm_unary_rm_r_unaligned (SseOpcode.Pmovsxbw) from))\n(rule 1 (x64_pmovsxbw from)\n      (if-let $true (has_avx))\n      (xmm_unary_rm_r_vex (AvxOpcode.Vpmovsxbw) from))\n\n(decl x64_pmovzxbw (XmmMem) Xmm)\n(rule (x64_pmovzxbw from)\n      (xmm_unary_rm_r_unaligned (SseOpcode.Pmovzxbw) from))\n(rule 1 (x64_pmovzxbw from)\n      (if-let $true (has_avx))\n      (xmm_unary_rm_r_vex (AvxOpcode.Vpmovzxbw) from))\n\n(decl x64_pmovsxwd (XmmMem) Xmm)\n(rule (x64_pmovsxwd from)\n      (xmm_unary_rm_r_unaligned (SseOpcode.Pmovsxwd) from))\n(rule 1 (x64_pmovsxwd from)\n      (if-let $true (has_avx))\n      (xmm_unary_rm_r_vex (AvxOpcode.Vpmovsxwd) from))\n\n(decl x64_pmovzxwd (XmmMem) Xmm)\n(rule (x64_pmovzxwd from)\n      (xmm_unary_rm_r_unaligned (SseOpcode.Pmovzxwd) from))\n(rule 1 (x64_pmovzxwd from)\n      (if-let $true (has_avx))\n      (xmm_unary_rm_r_vex (AvxOpcode.Vpmovzxwd) from))\n\n(decl x64_pmovsxdq (XmmMem) Xmm)\n(rule (x64_pmovsxdq from)\n      (xmm_unary_rm_r_unaligned (SseOpcode.Pmovsxdq) from))\n(rule 1 (x64_pmovsxdq from)\n      (if-let $true (has_avx))\n      (xmm_unary_rm_r_vex (AvxOpcode.Vpmovsxdq) from))\n\n(decl x64_pmovzxdq (XmmMem) Xmm)\n(rule (x64_pmovzxdq from)\n      (xmm_unary_rm_r_unaligned (SseOpcode.Pmovzxdq) from))\n(rule 1 (x64_pmovzxdq from)\n      (if-let $true (has_avx))\n      (xmm_unary_rm_r_vex (AvxOpcode.Vpmovzxdq) from))\n\n(decl x64_movrm (Type SyntheticAmode Gpr) SideEffectNoResult)\n(rule (x64_movrm ty addr data)\n      (let ((size OperandSize (raw_operand_size_of_type ty)))\n        (SideEffectNoResult.Inst (MInst.MovRM size data addr))))\n\n(decl x64_xmm_movrm (SseOpcode SyntheticAmode Xmm) SideEffectNoResult)\n(rule (x64_xmm_movrm op addr data)\n      (SideEffectNoResult.Inst (MInst.XmmMovRM op data addr)))\n\n;; Load a constant into an XMM register.\n(decl x64_xmm_load_const (Type VCodeConstant) Xmm)\n(rule (x64_xmm_load_const ty const)\n      (x64_load ty (const_to_synthetic_amode const) (ExtKind.None)))\n\n;;;; Instruction Constructors ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n;;\n;; These constructors create SSA-style `MInst`s. It is their responsibility to\n;; maintain the invariant that each temporary register they allocate and define\n;; only gets defined the once.\n\n;; Helper for emitting `MInst.AluRmiR` instructions.\n(decl alu_rmi_r (Type AluRmiROpcode Gpr GprMemImm) Gpr)\n(rule (alu_rmi_r ty opcode src1 src2)\n      (let ((dst WritableGpr (temp_writable_gpr))\n            (size OperandSize (operand_size_of_type_32_64 ty))\n            (_ Unit (emit (MInst.AluRmiR size opcode src1 src2 dst))))\n        dst))\n\n;; Helper for emitting `add` instructions.\n(decl x64_add (Type Gpr GprMemImm) Gpr)\n(rule (x64_add ty src1 src2)\n      (alu_rmi_r ty\n                 (AluRmiROpcode.Add)\n                 src1\n                 src2))\n\n;; Helper for creating `add` instructions whose flags are also used.\n(decl x64_add_with_flags_paired (Type Gpr GprMemImm) ProducesFlags)\n(rule (x64_add_with_flags_paired ty src1 src2)\n      (let ((dst WritableGpr (temp_writable_gpr)))\n        (ProducesFlags.ProducesFlagsReturnsResultWithConsumer\n         (MInst.AluRmiR (operand_size_of_type_32_64 ty)\n                        (AluRmiROpcode.Add)\n                        src1\n                        src2\n                        dst)\n         dst)))\n\n;; Helper for creating `adc` instructions.\n(decl x64_adc_paired (Type Gpr GprMemImm) ConsumesFlags)\n(rule (x64_adc_paired ty src1 src2)\n      (let ((dst WritableGpr (temp_writable_gpr)))\n        (ConsumesFlags.ConsumesFlagsReturnsResultWithProducer\n         (MInst.AluRmiR (operand_size_of_type_32_64 ty)\n                        (AluRmiROpcode.Adc)\n                        src1\n                        src2\n                        dst)\n         dst)))\n\n;; Helper for emitting `sub` instructions.\n(decl x64_sub (Type Gpr GprMemImm) Gpr)\n(rule (x64_sub ty src1 src2)\n      (alu_rmi_r ty\n                 (AluRmiROpcode.Sub)\n                 src1\n                 src2))\n\n;; Helper for creating `sub` instructions whose flags are also used.\n(decl x64_sub_with_flags_paired (Type Gpr GprMemImm) ProducesFlags)\n(rule (x64_sub_with_flags_paired ty src1 src2)\n      (let ((dst WritableGpr (temp_writable_gpr)))\n        (ProducesFlags.ProducesFlagsReturnsResultWithConsumer\n         (MInst.AluRmiR (operand_size_of_type_32_64 ty)\n                        (AluRmiROpcode.Sub)\n                        src1\n                        src2\n                        dst)\n         dst)))\n\n;; Helper for creating `sbb` instructions.\n(decl x64_sbb_paired (Type Gpr GprMemImm) ConsumesFlags)\n(rule (x64_sbb_paired ty src1 src2)\n      (let ((dst WritableGpr (temp_writable_gpr)))\n        (ConsumesFlags.ConsumesFlagsReturnsResultWithProducer\n         (MInst.AluRmiR (operand_size_of_type_32_64 ty)\n                        (AluRmiROpcode.Sbb)\n                        src1\n                        src2\n                        dst)\n         dst)))\n\n;; Helper for creating `mul` instructions.\n(decl x64_mul (Type Gpr GprMemImm) Gpr)\n(rule (x64_mul ty src1 src2)\n      (alu_rmi_r ty\n                 (AluRmiROpcode.Mul)\n                 src1\n                 src2))\n\n;; Helper for emitting `and` instructions.\n(decl x64_and (Type Gpr GprMemImm) Gpr)\n(rule (x64_and ty src1 src2)\n      (alu_rmi_r ty\n                 (AluRmiROpcode.And)\n                 src1\n                 src2))\n\n(decl x64_and_with_flags_paired (Type Gpr GprMemImm) ProducesFlags)\n(rule (x64_and_with_flags_paired ty src1 src2)\n      (let ((dst WritableGpr (temp_writable_gpr)))\n           (ProducesFlags.ProducesFlagsSideEffect\n                 (MInst.AluRmiR (operand_size_of_type_32_64 ty)\n                       (AluRmiROpcode.And)\n                       src1\n                       src2\n                       dst))))\n\n;; Helper for emitting `or` instructions.\n(decl x64_or (Type Gpr GprMemImm) Gpr)\n(rule (x64_or ty src1 src2)\n      (alu_rmi_r ty\n                 (AluRmiROpcode.Or)\n                 src1\n                 src2))\n\n;; Helper for emitting `xor` instructions.\n(decl x64_xor (Type Gpr GprMemImm) Gpr)\n(rule (x64_xor ty src1 src2)\n      (alu_rmi_r ty\n                 (AluRmiROpcode.Xor)\n                 src1\n                 src2))\n\n;; Helper for emitting `MInst.AluRmRVex` instructions.\n(decl alu_rm_r_vex (Type AluRmROpcode Gpr Gpr) Gpr)\n(rule (alu_rm_r_vex ty opcode src1 src2)\n      (let ((dst WritableGpr (temp_writable_gpr))\n            (size OperandSize (operand_size_of_type_32_64 ty))\n            (_ Unit (emit (MInst.AluRmRVex size opcode src1 src2 dst))))\n        dst))\n\n(decl x64_andn (Type Gpr Gpr) Gpr)\n(rule (x64_andn ty src1 src2)\n      (alu_rm_r_vex ty (AluRmROpcode.Andn) src1 src2))\n\n;; Helper for emitting immediates with an `i64` value. Note that\n;; integer constants in ISLE are always parsed as `i128`s; this enables\n;; negative numbers to be used as immediates.\n(decl imm_i64 (Type i64) Reg)\n(rule (imm_i64 ty value)\n      (imm ty (i64_as_u64 value)))\n\n(decl nonzero_u64_fits_in_u32 (u64) u64)\n(extern extractor nonzero_u64_fits_in_u32 nonzero_u64_fits_in_u32)\n\n;; Helper for emitting immediates.\n;;\n;; There are three priorities in use in this rule:\n;; 2 - rules that match on an explicit type\n;; 1 - rules that match on types that fit in 64 bits\n;; 0 - rules that match on vectors\n(decl imm (Type u64) Reg)\n\n;; Integer immediates.\n(rule 1 (imm (fits_in_64 ty) (u64_nonzero simm64))\n      (let ((dst WritableGpr (temp_writable_gpr))\n            (size OperandSize (operand_size_of_type_32_64 ty))\n            (_ Unit (emit (MInst.Imm size simm64 dst))))\n        dst))\n\n;; `f32` immediates.\n(rule 2 (imm $F32 (u64_nonzero bits))\n      (gpr_to_xmm (SseOpcode.Movd)\n                  (imm $I32 bits)\n                  (OperandSize.Size32)))\n\n;; `f64` immediates.\n(rule 2 (imm $F64 (u64_nonzero bits))\n      (gpr_to_xmm (SseOpcode.Movq)\n                  (imm $I64 bits)\n                  (OperandSize.Size64)))\n\n;; Special case for when a 64-bit immediate fits into 32-bits. We can use a\n;; 32-bit move that zero-extends the value, which has a smaller encoding.\n(rule 2 (imm $I64 (nonzero_u64_fits_in_u32 x))\n      (let ((dst WritableGpr (temp_writable_gpr))\n            (_ Unit (emit (MInst.Imm (OperandSize.Size32) x dst))))\n        dst))\n\n;; Special case for integer zero immediates: turn them into an `xor r, r`.\n(rule 1 (imm (fits_in_64 ty) (u64_zero))\n      (let ((wgpr WritableGpr (temp_writable_gpr))\n            (size OperandSize (operand_size_of_type_32_64 ty))\n            (_ Unit (emit (MInst.AluConstOp (AluRmiROpcode.Xor) size wgpr))))\n        (gpr_to_reg wgpr)))\n\n;; Special case for zero immediates with vector types, they turn into an xor\n;; specific to the vector type.\n(rule 0 (imm ty @ (multi_lane _bits _lanes) 0)\n      (xmm_to_reg (xmm_zero ty)))\n\n;; Special case for `f32` zero immediates\n(rule 2 (imm ty @ $F32 (u64_zero))\n      (let ((wr WritableXmm (temp_writable_xmm))\n            (_ Unit (emit (MInst.XmmConstOp (SseOpcode.Xorps) wr))))\n        (xmm_to_reg wr)))\n\n;; TODO: use cmpeqps for all 1s\n\n;; Special case for `f64` zero immediates to use `xorpd`.\n(rule 2 (imm ty @ $F64 (u64_zero))\n      (let ((wr WritableXmm (temp_writable_xmm))\n            (_ Unit (emit (MInst.XmmConstOp (SseOpcode.Xorpd) wr))))\n        (xmm_to_reg wr)))\n\n;; TODO: use cmpeqpd for all 1s\n\n(decl xmm_zero (Type) Xmm)\n(rule (xmm_zero ty)\n      (let ((wr WritableXmm (temp_writable_xmm))\n            (_ Unit (emit (MInst.XmmConstOp (sse_xor_op ty) wr))))\n        wr))\n\n;; Helper for creating `MInst.ShiftR` instructions.\n(decl shift_r (Type ShiftKind Gpr Imm8Gpr) Gpr)\n(rule (shift_r ty kind src1 src2)\n      (let ((dst WritableGpr (temp_writable_gpr))\n            ;; Use actual 8/16-bit instructions when appropriate: we\n            ;; rely on their shift-amount-masking semantics.\n            (size OperandSize (raw_operand_size_of_type ty))\n            (_ Unit (emit (MInst.ShiftR size kind src1 src2 dst))))\n        dst))\n\n;; Helper for creating `rotl` instructions.\n(decl x64_rotl (Type Gpr Imm8Gpr) Gpr)\n(rule (x64_rotl ty src1 src2)\n      (shift_r ty (ShiftKind.RotateLeft) src1 src2))\n\n;; Helper for creating `rotr` instructions.\n(decl x64_rotr (Type Gpr Imm8Gpr) Gpr)\n(rule (x64_rotr ty src1 src2)\n      (shift_r ty (ShiftKind.RotateRight) src1 src2))\n\n;; Helper for creating `shl` instructions.\n(decl x64_shl (Type Gpr Imm8Gpr) Gpr)\n(rule (x64_shl ty src1 src2)\n      (shift_r ty (ShiftKind.ShiftLeft) src1 src2))\n\n;; Helper for creating logical shift-right instructions.\n(decl x64_shr (Type Gpr Imm8Gpr) Gpr)\n(rule (x64_shr ty src1 src2)\n      (shift_r ty (ShiftKind.ShiftRightLogical) src1 src2))\n\n;; Helper for creating arithmetic shift-right instructions.\n(decl x64_sar (Type Gpr Imm8Gpr) Gpr)\n(rule (x64_sar ty src1 src2)\n      (shift_r ty (ShiftKind.ShiftRightArithmetic) src1 src2))\n\n;; Helper for creating byteswap instructions.\n;; In x64, 32- and 64-bit registers use BSWAP instruction, and\n;; for 16-bit registers one must instead use xchg or rol/ror\n(decl x64_bswap (Type Gpr) Gpr)\n(rule (x64_bswap ty src)\n      (let ((dst WritableGpr (temp_writable_gpr))\n            (size OperandSize (operand_size_of_type_32_64 ty))\n            (_ Unit (emit (MInst.Bswap size src dst))))\n        dst))\n\n;; Helper for creating `MInst.CmpRmiR` instructions.\n(decl cmp_rmi_r (OperandSize CmpOpcode GprMemImm Gpr) ProducesFlags)\n(rule (cmp_rmi_r size opcode src1 src2)\n      (ProducesFlags.ProducesFlagsSideEffect\n       (MInst.CmpRmiR size\n                      opcode\n                      src1\n                      src2)))\n\n;; Helper for creating `cmp` instructions.\n(decl x64_cmp (OperandSize GprMemImm Gpr) ProducesFlags)\n(rule (x64_cmp size src1 src2)\n      (cmp_rmi_r size (CmpOpcode.Cmp) src1 src2))\n\n;; Helper for creating `cmp` instructions with an immediate.\n(decl x64_cmp_imm (OperandSize u32 Gpr) ProducesFlags)\n(rule (x64_cmp_imm size src1 src2)\n      (cmp_rmi_r size (CmpOpcode.Cmp) (RegMemImm.Imm src1) src2))\n\n;; Helper for creating `MInst.XmmCmpRmR` instructions.\n(decl xmm_cmp_rm_r (SseOpcode XmmMemAligned Xmm) ProducesFlags)\n(rule (xmm_cmp_rm_r opcode src1 src2)\n      (ProducesFlags.ProducesFlagsSideEffect\n       (MInst.XmmCmpRmR opcode src1 src2)))\n\n;; Helper for creating floating-point comparison instructions (`UCOMIS[S|D]`).\n(decl x64_ucomis (Value Value) ProducesFlags)\n(rule (x64_ucomis src1 @ (value_type $F32) src2)\n      ;; N.B.: cmp can be generated more than once, so cannot do a\n      ;; load-op merge. So `put_in_xmm` for src1, not `put_in_xmm_mem`.\n      (xmm_cmp_rm_r (SseOpcode.Ucomiss) (put_in_xmm src1) (put_in_xmm src2)))\n(rule (x64_ucomis src1 @ (value_type $F64) src2)\n      (xmm_cmp_rm_r (SseOpcode.Ucomisd) (put_in_xmm src1) (put_in_xmm src2)))\n\n;; Helper for creating `test` instructions.\n(decl x64_test (OperandSize GprMemImm Gpr) ProducesFlags)\n(rule (x64_test size src1 src2)\n      (cmp_rmi_r size (CmpOpcode.Test) src1 src2))\n\n;; Helper for creating `ptest` instructions.\n(decl x64_ptest (XmmMem Xmm) ProducesFlags)\n(rule (x64_ptest src1 src2)\n      (xmm_cmp_rm_r (SseOpcode.Ptest) src1 src2))\n\n;; Helper for creating `cmove` instructions. Note that these instructions do not\n;; always result in a single emitted x86 instruction; e.g., XmmCmove uses jumps\n;; to conditionally move the selected value into an XMM register.\n(decl cmove (Type CC GprMem Gpr) ConsumesFlags)\n(rule (cmove ty cc consequent alternative)\n      (let ((dst WritableGpr (temp_writable_gpr))\n            (size OperandSize (operand_size_of_type_32_64 ty)))\n        (ConsumesFlags.ConsumesFlagsReturnsReg\n         (MInst.Cmove size cc consequent alternative dst)\n         dst)))\n\n(decl cmove_xmm (Type CC XmmMemAligned Xmm) ConsumesFlags)\n(rule (cmove_xmm ty cc consequent alternative)\n      (let ((dst WritableXmm (temp_writable_xmm)))\n        (ConsumesFlags.ConsumesFlagsReturnsReg\n         (MInst.XmmCmove ty cc consequent alternative dst)\n         dst)))\n\n;; Helper for creating `cmove` instructions directly from values. This allows us\n;; to special-case the `I128` types and default to the `cmove` helper otherwise.\n;; It also eliminates some `put_in_reg*` boilerplate in the lowering ISLE code.\n(decl cmove_from_values (Type CC Value Value) ConsumesFlags)\n(rule (cmove_from_values (is_multi_register_gpr_type $I128) cc consequent alternative)\n      (let ((cons ValueRegs consequent)\n            (alt ValueRegs alternative)\n            (dst1 WritableGpr (temp_writable_gpr))\n            (dst2 WritableGpr (temp_writable_gpr))\n            (size OperandSize (OperandSize.Size64))\n            (lower_cmove MInst (MInst.Cmove\n                                size cc\n                                (value_regs_get_gpr cons 0)\n                                (value_regs_get_gpr alt 0)\n                                dst1))\n            (upper_cmove MInst (MInst.Cmove\n                                size cc\n                                (value_regs_get_gpr cons 1)\n                                (value_regs_get_gpr alt 1)\n                                dst2)))\n        (ConsumesFlags.ConsumesFlagsTwiceReturnsValueRegs\n         lower_cmove\n         upper_cmove\n         (value_regs dst1 dst2))))\n\n(rule (cmove_from_values (is_single_register_gpr_type ty) cc consequent alternative)\n      (cmove ty cc consequent alternative))\n\n(rule (cmove_from_values (is_xmm_type ty) cc consequent alternative)\n      (cmove_xmm ty cc consequent alternative))\n\n;; Helper for creating `cmove` instructions with the logical OR of multiple\n;; flags. Note that these instructions will always result in more than one\n;; emitted x86 instruction.\n(decl cmove_or (Type CC CC GprMem Gpr) ConsumesFlags)\n(rule (cmove_or ty cc1 cc2 consequent alternative)\n      (let ((dst WritableGpr (temp_writable_gpr))\n            (tmp WritableGpr (temp_writable_gpr))\n            (size OperandSize (operand_size_of_type_32_64 ty))\n            (cmove1 MInst (MInst.Cmove size cc1 consequent alternative tmp))\n            (cmove2 MInst (MInst.Cmove size cc2 consequent tmp dst)))\n        (ConsumesFlags.ConsumesFlagsTwiceReturnsValueRegs\n         cmove1\n         cmove2\n         dst)))\n\n(decl cmove_or_xmm (Type CC CC XmmMemAligned Xmm) ConsumesFlags)\n(rule (cmove_or_xmm ty cc1 cc2 consequent alternative)\n      (let ((dst WritableXmm (temp_writable_xmm))\n            (tmp WritableXmm (temp_writable_xmm))\n            (cmove1 MInst (MInst.XmmCmove ty cc1 consequent alternative tmp))\n            (cmove2 MInst (MInst.XmmCmove ty cc2 consequent tmp dst)))\n        (ConsumesFlags.ConsumesFlagsTwiceReturnsValueRegs\n         cmove1\n         cmove2\n         dst)))\n\n;; Helper for creating `cmove_or` instructions directly from values. This allows\n;; us to special-case the `I128` types and default to the `cmove_or` helper\n;; otherwise.\n(decl cmove_or_from_values (Type CC CC Value Value) ConsumesFlags)\n(rule (cmove_or_from_values (is_multi_register_gpr_type $I128) cc1 cc2 consequent alternative)\n      (let ((cons ValueRegs consequent)\n            (alt ValueRegs alternative)\n            (dst1 WritableGpr (temp_writable_gpr))\n            (dst2 WritableGpr (temp_writable_gpr))\n            (tmp1 WritableGpr (temp_writable_gpr))\n            (tmp2 WritableGpr (temp_writable_gpr))\n            (size OperandSize (OperandSize.Size64))\n            (cmove1 MInst (MInst.Cmove size cc1 (value_regs_get_gpr cons 0) (value_regs_get_gpr alt 0) tmp1))\n            (cmove2 MInst (MInst.Cmove size cc2 (value_regs_get_gpr cons 0) tmp1 dst1))\n            (cmove3 MInst (MInst.Cmove size cc1 (value_regs_get_gpr cons 1) (value_regs_get_gpr alt 1) tmp2))\n            (cmove4 MInst (MInst.Cmove size cc2 (value_regs_get_gpr cons 1) tmp2 dst2)))\n        (ConsumesFlags.ConsumesFlagsFourTimesReturnsValueRegs\n         cmove1\n         cmove2\n         cmove3\n         cmove4\n         (value_regs dst1 dst2))))\n\n(rule (cmove_or_from_values (is_single_register_gpr_type ty) cc1 cc2 consequent alternative)\n      (cmove_or ty cc1 cc2 consequent alternative))\n\n(rule (cmove_or_from_values (is_xmm_type ty) cc1 cc2 consequent alternative)\n      (cmove_or_xmm ty cc1 cc2 consequent alternative))\n\n;; Helper for creating `MInst.Setcc` instructions.\n(decl x64_setcc (CC) ConsumesFlags)\n(rule (x64_setcc cc)\n      (let ((dst WritableGpr (temp_writable_gpr)))\n        (ConsumesFlags.ConsumesFlagsReturnsReg\n         (MInst.Setcc cc dst)\n         dst)))\n\n;; Helper for creating `MInst.Setcc` instructions, when the flags producer will\n;; also return a value.\n(decl x64_setcc_paired (CC) ConsumesFlags)\n(rule (x64_setcc_paired cc)\n      (let ((dst WritableGpr (temp_writable_gpr)))\n        (ConsumesFlags.ConsumesFlagsReturnsResultWithProducer\n         (MInst.Setcc cc dst)\n         dst)))\n\n;; Helper for creating `MInst.XmmRmR` instructions.\n(decl xmm_rm_r (SseOpcode Xmm XmmMemAligned) Xmm)\n(rule (xmm_rm_r op src1 src2)\n      (let ((dst WritableXmm (temp_writable_xmm))\n            (_ Unit (emit (MInst.XmmRmR op src1 src2 dst))))\n        dst))\n\n;; Helper for creating `MInst.XmmRmRUnaligned` instructions.\n(decl xmm_rm_r_unaligned (SseOpcode Xmm XmmMem) Xmm)\n(rule (xmm_rm_r_unaligned op src1 src2)\n      (let ((dst WritableXmm (temp_writable_xmm))\n            (_ Unit (emit (MInst.XmmRmRUnaligned op src1 src2 dst))))\n        dst))\n\n;; Helper for creating `paddb` instructions.\n(decl x64_paddb (Xmm XmmMem) Xmm)\n(rule 0 (x64_paddb src1 src2)\n      (xmm_rm_r (SseOpcode.Paddb) src1 src2))\n(rule 1 (x64_paddb src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vpaddb) src1 src2))\n\n;; Helper for creating `paddw` instructions.\n(decl x64_paddw (Xmm XmmMem) Xmm)\n(rule 0 (x64_paddw src1 src2)\n      (xmm_rm_r (SseOpcode.Paddw) src1 src2))\n(rule 1 (x64_paddw src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vpaddw) src1 src2))\n\n;; Helper for creating `paddd` instructions.\n(decl x64_paddd (Xmm XmmMem) Xmm)\n(rule 0 (x64_paddd src1 src2)\n      (xmm_rm_r (SseOpcode.Paddd) src1 src2))\n(rule 1 (x64_paddd src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vpaddd) src1 src2))\n\n;; Helper for creating `paddq` instructions.\n(decl x64_paddq (Xmm XmmMem) Xmm)\n(rule 0 (x64_paddq src1 src2)\n      (xmm_rm_r (SseOpcode.Paddq) src1 src2))\n(rule 1 (x64_paddq src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vpaddq) src1 src2))\n\n;; Helper for creating `paddsb` instructions.\n(decl x64_paddsb (Xmm XmmMem) Xmm)\n(rule 0 (x64_paddsb src1 src2)\n      (xmm_rm_r (SseOpcode.Paddsb) src1 src2))\n(rule 1 (x64_paddsb src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vpaddsb) src1 src2))\n\n;; Helper for creating `paddsw` instructions.\n(decl x64_paddsw (Xmm XmmMem) Xmm)\n(rule 0 (x64_paddsw src1 src2)\n      (xmm_rm_r (SseOpcode.Paddsw) src1 src2))\n(rule 1 (x64_paddsw src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vpaddsw) src1 src2))\n\n;; Helper for creating `phaddw` instructions.\n(decl x64_phaddw (Xmm XmmMem) Xmm)\n(rule 0 (x64_phaddw src1 src2)\n      (xmm_rm_r (SseOpcode.Phaddw) src1 src2))\n(rule 1 (x64_phaddw src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vphaddw) src1 src2))\n\n;; Helper for creating `phaddd` instructions.\n(decl x64_phaddd (Xmm XmmMem) Xmm)\n(rule 0 (x64_phaddd src1 src2)\n      (xmm_rm_r (SseOpcode.Phaddd) src1 src2))\n(rule 1 (x64_phaddd src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vphaddd) src1 src2))\n\n;; Helper for creating `paddusb` instructions.\n(decl x64_paddusb (Xmm XmmMem) Xmm)\n(rule 0 (x64_paddusb src1 src2)\n      (xmm_rm_r (SseOpcode.Paddusb) src1 src2))\n(rule 1 (x64_paddusb src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vpaddusb) src1 src2))\n\n;; Helper for creating `paddusw` instructions.\n(decl x64_paddusw (Xmm XmmMem) Xmm)\n(rule 0 (x64_paddusw src1 src2)\n      (xmm_rm_r (SseOpcode.Paddusw) src1 src2))\n(rule 1 (x64_paddusw src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vpaddusw) src1 src2))\n\n;; Helper for creating `psubb` instructions.\n(decl x64_psubb (Xmm XmmMem) Xmm)\n(rule 0 (x64_psubb src1 src2)\n      (xmm_rm_r (SseOpcode.Psubb) src1 src2))\n(rule 1 (x64_psubb src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vpsubb) src1 src2))\n\n;; Helper for creating `psubw` instructions.\n(decl x64_psubw (Xmm XmmMem) Xmm)\n(rule 0 (x64_psubw src1 src2)\n      (xmm_rm_r (SseOpcode.Psubw) src1 src2))\n(rule 1 (x64_psubw src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vpsubw) src1 src2))\n\n;; Helper for creating `psubd` instructions.\n(decl x64_psubd (Xmm XmmMem) Xmm)\n(rule 0 (x64_psubd src1 src2)\n      (xmm_rm_r (SseOpcode.Psubd) src1 src2))\n(rule 1 (x64_psubd src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vpsubd) src1 src2))\n\n;; Helper for creating `psubq` instructions.\n(decl x64_psubq (Xmm XmmMem) Xmm)\n(rule 0 (x64_psubq src1 src2)\n      (xmm_rm_r (SseOpcode.Psubq) src1 src2))\n(rule 1 (x64_psubq src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vpsubq) src1 src2))\n\n;; Helper for creating `psubsb` instructions.\n(decl x64_psubsb (Xmm XmmMem) Xmm)\n(rule 0 (x64_psubsb src1 src2)\n      (xmm_rm_r (SseOpcode.Psubsb) src1 src2))\n(rule 1 (x64_psubsb src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vpsubsb) src1 src2))\n\n;; Helper for creating `psubsw` instructions.\n(decl x64_psubsw (Xmm XmmMem) Xmm)\n(rule 0 (x64_psubsw src1 src2)\n      (xmm_rm_r (SseOpcode.Psubsw) src1 src2))\n(rule 1 (x64_psubsw src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vpsubsw) src1 src2))\n\n;; Helper for creating `psubusb` instructions.\n(decl x64_psubusb (Xmm XmmMem) Xmm)\n(rule 0 (x64_psubusb src1 src2)\n      (xmm_rm_r (SseOpcode.Psubusb) src1 src2))\n(rule 1 (x64_psubusb src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vpsubusb) src1 src2))\n\n;; Helper for creating `psubusw` instructions.\n(decl x64_psubusw (Xmm XmmMem) Xmm)\n(rule 0 (x64_psubusw src1 src2)\n      (xmm_rm_r (SseOpcode.Psubusw) src1 src2))\n(rule 1 (x64_psubusw src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vpsubusw) src1 src2))\n\n;; Helper for creating `pavgb` instructions.\n(decl x64_pavgb (Xmm XmmMem) Xmm)\n(rule 0 (x64_pavgb src1 src2)\n      (xmm_rm_r (SseOpcode.Pavgb) src1 src2))\n(rule 1 (x64_pavgb src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vpavgb) src1 src2))\n\n;; Helper for creating `pavgw` instructions.\n(decl x64_pavgw (Xmm XmmMem) Xmm)\n(rule 0 (x64_pavgw src1 src2)\n      (xmm_rm_r (SseOpcode.Pavgw) src1 src2))\n(rule 1 (x64_pavgw src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vpavgw) src1 src2))\n\n;; Helper for creating `pand` instructions.\n(decl x64_pand (Xmm XmmMem) Xmm)\n(rule 0 (x64_pand src1 src2)\n      (xmm_rm_r (SseOpcode.Pand) src1 src2))\n(rule 1 (x64_pand src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vpand) src1 src2))\n\n;; Helper for creating `andps` instructions.\n(decl x64_andps (Xmm XmmMem) Xmm)\n(rule 0 (x64_andps src1 src2)\n      (xmm_rm_r (SseOpcode.Andps) src1 src2))\n(rule 1 (x64_andps src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vandps) src1 src2))\n\n;; Helper for creating `andpd` instructions.\n(decl x64_andpd (Xmm XmmMem) Xmm)\n(rule 0 (x64_andpd src1 src2)\n      (xmm_rm_r (SseOpcode.Andpd) src1 src2))\n(rule 1 (x64_andpd src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vandpd) src1 src2))\n\n;; Helper for creating `por` instructions.\n(decl x64_por (Xmm XmmMem) Xmm)\n(rule 0 (x64_por src1 src2)\n      (xmm_rm_r (SseOpcode.Por) src1 src2))\n(rule 1 (x64_por src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vpor) src1 src2))\n\n;; Helper for creating `orps` instructions.\n(decl x64_orps (Xmm XmmMem) Xmm)\n(rule 0 (x64_orps src1 src2)\n      (xmm_rm_r (SseOpcode.Orps) src1 src2))\n(rule 1 (x64_orps src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vorps) src1 src2))\n\n;; Helper for creating `orpd` instructions.\n(decl x64_orpd (Xmm XmmMem) Xmm)\n(rule 0 (x64_orpd src1 src2)\n      (xmm_rm_r (SseOpcode.Orpd) src1 src2))\n(rule 1 (x64_orpd src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vorpd) src1 src2))\n\n;; Helper fxor creating `pxor` instructions.\n(decl x64_pxor (Xmm XmmMem) Xmm)\n(rule 0 (x64_pxor src1 src2)\n      (xmm_rm_r (SseOpcode.Pxor) src1 src2))\n(rule 1 (x64_pxor src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vpxor) src1 src2))\n\n;; Helper fxor creating `xorps` instructions.\n(decl x64_xorps (Xmm XmmMem) Xmm)\n(rule 0 (x64_xorps src1 src2)\n      (xmm_rm_r (SseOpcode.Xorps) src1 src2))\n(rule 1 (x64_xorps src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vxorps) src1 src2))\n\n;; Helper fxor creating `xorpd` instructions.\n(decl x64_xorpd (Xmm XmmMem) Xmm)\n(rule 0 (x64_xorpd src1 src2)\n      (xmm_rm_r (SseOpcode.Xorpd) src1 src2))\n(rule 1 (x64_xorpd src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vxorpd) src1 src2))\n\n;; Helper for creating `pmullw` instructions.\n(decl x64_pmullw (Xmm XmmMem) Xmm)\n(rule 0 (x64_pmullw src1 src2)\n      (xmm_rm_r (SseOpcode.Pmullw) src1 src2))\n(rule 1 (x64_pmullw src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vpmullw) src1 src2))\n\n;; Helper for creating `pmulld` instructions.\n(decl x64_pmulld (Xmm XmmMem) Xmm)\n(rule 0 (x64_pmulld src1 src2)\n      (xmm_rm_r (SseOpcode.Pmulld) src1 src2))\n(rule 1 (x64_pmulld src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vpmulld) src1 src2))\n\n;; Helper for creating `pmulhw` instructions.\n(decl x64_pmulhw (Xmm XmmMem) Xmm)\n(rule 0 (x64_pmulhw src1 src2)\n      (xmm_rm_r (SseOpcode.Pmulhw) src1 src2))\n(rule 1 (x64_pmulhw src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vpmulhw) src1 src2))\n\n;; Helper for creating `pmulhrsw` instructions.\n(decl x64_pmulhrsw (Xmm XmmMem) Xmm)\n(rule 0 (x64_pmulhrsw src1 src2)\n      (xmm_rm_r (SseOpcode.Pmulhrsw) src1 src2))\n(rule 1 (x64_pmulhrsw src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vpmulhrsw) src1 src2))\n\n;; Helper for creating `pmulhuw` instructions.\n(decl x64_pmulhuw (Xmm XmmMem) Xmm)\n(rule 0 (x64_pmulhuw src1 src2)\n      (xmm_rm_r (SseOpcode.Pmulhuw) src1 src2))\n(rule 1 (x64_pmulhuw src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vpmulhuw) src1 src2))\n\n;; Helper for creating `pmuldq` instructions.\n(decl x64_pmuldq (Xmm XmmMem) Xmm)\n(rule 0 (x64_pmuldq src1 src2)\n      (xmm_rm_r (SseOpcode.Pmuldq) src1 src2))\n(rule 1 (x64_pmuldq src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vpmuldq) src1 src2))\n\n;; Helper for creating `pmuludq` instructions.\n(decl x64_pmuludq (Xmm XmmMem) Xmm)\n(rule 0 (x64_pmuludq src1 src2)\n      (xmm_rm_r (SseOpcode.Pmuludq) src1 src2))\n(rule 1 (x64_pmuludq src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vpmuludq) src1 src2))\n\n;; Helper for creating `punpckhwd` instructions.\n(decl x64_punpckhwd (Xmm XmmMem) Xmm)\n(rule 0 (x64_punpckhwd src1 src2)\n      (xmm_rm_r (SseOpcode.Punpckhwd) src1 src2))\n(rule 1 (x64_punpckhwd src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vpunpckhwd) src1 src2))\n\n;; Helper for creating `punpcklwd` instructions.\n(decl x64_punpcklwd (Xmm XmmMem) Xmm)\n(rule 0 (x64_punpcklwd src1 src2)\n      (xmm_rm_r (SseOpcode.Punpcklwd) src1 src2))\n(rule 1 (x64_punpcklwd src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vpunpcklwd) src1 src2))\n\n;; Helper for creating `unpcklps` instructions.\n(decl x64_unpcklps (Xmm XmmMem) Xmm)\n(rule 0 (x64_unpcklps src1 src2)\n      (xmm_rm_r (SseOpcode.Unpcklps) src1 src2))\n(rule 1 (x64_unpcklps src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vunpcklps) src1 src2))\n\n;; Helper for creating `andnps` instructions.\n(decl x64_andnps (Xmm XmmMem) Xmm)\n(rule 0 (x64_andnps src1 src2)\n      (xmm_rm_r (SseOpcode.Andnps) src1 src2))\n(rule 1 (x64_andnps src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vandnps) src1 src2))\n\n;; Helper for creating `andnpd` instructions.\n(decl x64_andnpd (Xmm XmmMem) Xmm)\n(rule 0 (x64_andnpd src1 src2)\n      (xmm_rm_r (SseOpcode.Andnpd) src1 src2))\n(rule 1 (x64_andnpd src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vandnpd) src1 src2))\n\n;; Helper for creating `pandn` instructions.\n(decl x64_pandn (Xmm XmmMem) Xmm)\n(rule 0 (x64_pandn src1 src2)\n      (xmm_rm_r (SseOpcode.Pandn) src1 src2))\n(rule 1 (x64_pandn src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vpandn) src1 src2))\n\n;; Helper for creating `addss` instructions.\n(decl x64_addss (Xmm XmmMem) Xmm)\n(rule (x64_addss src1 src2)\n      (xmm_rm_r_unaligned (SseOpcode.Addss) src1 src2))\n(rule 1 (x64_addss src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vaddss) src1 src2))\n\n;; Helper for creating `addsd` instructions.\n(decl x64_addsd (Xmm XmmMem) Xmm)\n(rule (x64_addsd src1 src2)\n      (xmm_rm_r_unaligned (SseOpcode.Addsd) src1 src2))\n(rule 1 (x64_addsd src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vaddsd) src1 src2))\n\n;; Helper for creating `addps` instructions.\n(decl x64_addps (Xmm XmmMem) Xmm)\n(rule 0 (x64_addps src1 src2)\n      (xmm_rm_r (SseOpcode.Addps) src1 src2))\n(rule 1 (x64_addps src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vaddps) src1 src2))\n\n;; Helper for creating `addpd` instructions.\n(decl x64_addpd (Xmm XmmMem) Xmm)\n(rule 0 (x64_addpd src1 src2)\n      (xmm_rm_r (SseOpcode.Addpd) src1 src2))\n(rule 1 (x64_addpd src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vaddpd) src1 src2))\n\n;; Helper for creating `subss` instructions.\n(decl x64_subss (Xmm XmmMem) Xmm)\n(rule (x64_subss src1 src2)\n      (xmm_rm_r_unaligned (SseOpcode.Subss) src1 src2))\n(rule 1 (x64_subss src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vsubss) src1 src2))\n\n;; Helper for creating `subsd` instructions.\n(decl x64_subsd (Xmm XmmMem) Xmm)\n(rule (x64_subsd src1 src2)\n      (xmm_rm_r_unaligned (SseOpcode.Subsd) src1 src2))\n(rule 1 (x64_subsd src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vsubsd) src1 src2))\n\n;; Helper for creating `subps` instructions.\n(decl x64_subps (Xmm XmmMem) Xmm)\n(rule 0 (x64_subps src1 src2)\n      (xmm_rm_r (SseOpcode.Subps) src1 src2))\n(rule 1 (x64_subps src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vsubps) src1 src2))\n\n;; Helper for creating `subpd` instructions.\n(decl x64_subpd (Xmm XmmMem) Xmm)\n(rule 0 (x64_subpd src1 src2)\n      (xmm_rm_r (SseOpcode.Subpd) src1 src2))\n(rule 1 (x64_subpd src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vsubpd) src1 src2))\n\n;; Helper for creating `mulss` instructions.\n(decl x64_mulss (Xmm XmmMem) Xmm)\n(rule (x64_mulss src1 src2)\n      (xmm_rm_r_unaligned (SseOpcode.Mulss) src1 src2))\n(rule 1 (x64_mulss src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vmulss) src1 src2))\n\n;; Helper for creating `mulsd` instructions.\n(decl x64_mulsd (Xmm XmmMem) Xmm)\n(rule (x64_mulsd src1 src2)\n      (xmm_rm_r_unaligned (SseOpcode.Mulsd) src1 src2))\n(rule 1 (x64_mulsd src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vmulsd) src1 src2))\n\n;; Helper for creating `mulps` instructions.\n(decl x64_mulps (Xmm XmmMem) Xmm)\n(rule 0 (x64_mulps src1 src2)\n      (xmm_rm_r (SseOpcode.Mulps) src1 src2))\n(rule 1 (x64_mulps src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vmulps) src1 src2))\n\n;; Helper for creating `mulpd` instructions.\n(decl x64_mulpd (Xmm XmmMem) Xmm)\n(rule (x64_mulpd src1 src2)\n      (xmm_rm_r (SseOpcode.Mulpd) src1 src2))\n(rule 1 (x64_mulpd src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vmulpd) src1 src2))\n\n;; Helper for creating `divss` instructions.\n(decl x64_divss (Xmm XmmMem) Xmm)\n(rule (x64_divss src1 src2)\n      (xmm_rm_r_unaligned (SseOpcode.Divss) src1 src2))\n(rule 1 (x64_divss src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vdivss) src1 src2))\n\n;; Helper for creating `divsd` instructions.\n(decl x64_divsd (Xmm XmmMem) Xmm)\n(rule (x64_divsd src1 src2)\n      (xmm_rm_r_unaligned (SseOpcode.Divsd) src1 src2))\n(rule 1 (x64_divsd src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vdivsd) src1 src2))\n\n;; Helper for creating `divps` instructions.\n(decl x64_divps (Xmm XmmMem) Xmm)\n(rule 0 (x64_divps src1 src2)\n      (xmm_rm_r (SseOpcode.Divps) src1 src2))\n(rule 1 (x64_divps src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vdivps) src1 src2))\n\n;; Helper for creating `divpd` instructions.\n(decl x64_divpd (Xmm XmmMem) Xmm)\n(rule 0 (x64_divpd src1 src2)\n      (xmm_rm_r (SseOpcode.Divpd) src1 src2))\n(rule 1 (x64_divpd src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vdivpd) src1 src2))\n\n;; Helper for creating `XmmRmRBlend` instructions\n(decl xmm_rm_r_blend (SseOpcode Xmm XmmMemAligned Xmm) Xmm)\n(rule (xmm_rm_r_blend op src1 src2 mask)\n      (let ((dst WritableXmm (temp_writable_xmm))\n            (_ Unit (emit (MInst.XmmRmRBlend op src1 src2 mask dst))))\n        dst))\n\n;; Helper for creating `XmmRmRBlendVex` instructions\n(decl xmm_rmr_blend_vex (AvxOpcode Xmm XmmMem Xmm) Xmm)\n(rule (xmm_rmr_blend_vex op src1 src2 mask)\n      (let ((dst WritableXmm (temp_writable_xmm))\n            (_ Unit (emit (MInst.XmmRmRBlendVex op src1 src2 mask dst))))\n        dst))\n\n;; Helper for creating `XmmUnaryRmRVex` instructions\n(decl xmm_unary_rm_r_vex (AvxOpcode XmmMem) Xmm)\n(rule (xmm_unary_rm_r_vex op src)\n      (let ((dst WritableXmm (temp_writable_xmm))\n            (_ Unit (emit (MInst.XmmUnaryRmRVex op src dst))))\n        dst))\n\n;; Helper for creating `XmmUnaryRmRImmVex` instructions\n(decl xmm_unary_rm_r_imm_vex (AvxOpcode XmmMem u8) Xmm)\n(rule (xmm_unary_rm_r_imm_vex op src imm)\n      (let ((dst WritableXmm (temp_writable_xmm))\n            (_ Unit (emit (MInst.XmmUnaryRmRImmVex op src dst imm))))\n        dst))\n\n;; Helper for creating `blendvp{d,s}` and `pblendvb` instructions.\n(decl x64_blend (Type Xmm XmmMem Xmm) Xmm)\n(rule 1 (x64_blend $F32X4 mask src1 src2) (x64_blendvps src2 src1 mask))\n(rule 1 (x64_blend $F64X2 mask src1 src2) (x64_blendvpd src2 src1 mask))\n(rule 0 (x64_blend (multi_lane _ _) mask src1 src2) (x64_pblendvb src2 src1 mask))\n\n;; Helper for creating `blendvpd` instructions.\n(decl x64_blendvpd (Xmm XmmMem Xmm) Xmm)\n(rule 0 (x64_blendvpd src1 src2 mask)\n      (xmm_rm_r_blend (SseOpcode.Blendvpd) src1 src2 mask))\n(rule 1 (x64_blendvpd src1 src2 mask)\n      (if-let $true (has_avx))\n      (xmm_rmr_blend_vex (AvxOpcode.Vblendvpd) src1 src2 mask))\n\n;; Helper for creating `blendvps` instructions.\n(decl x64_blendvps (Xmm XmmMem Xmm) Xmm)\n(rule 0 (x64_blendvps src1 src2 mask)\n      (xmm_rm_r_blend (SseOpcode.Blendvps) src1 src2 mask))\n(rule 1 (x64_blendvps src1 src2 mask)\n      (if-let $true (has_avx))\n      (xmm_rmr_blend_vex (AvxOpcode.Vblendvps) src1 src2 mask))\n\n;; Helper for creating `pblendvb` instructions.\n(decl x64_pblendvb (Xmm XmmMem Xmm) Xmm)\n(rule 0 (x64_pblendvb src1 src2 mask)\n      (xmm_rm_r_blend (SseOpcode.Pblendvb) src1 src2 mask))\n(rule 1 (x64_pblendvb src1 src2 mask)\n      (if-let $true (has_avx))\n      (xmm_rmr_blend_vex (AvxOpcode.Vpblendvb) src1 src2 mask))\n\n;; Helper for creating `movsd` instructions.\n(decl x64_movsd_regmove (Xmm XmmMem) Xmm)\n(rule (x64_movsd_regmove src1 src2)\n      (xmm_rm_r_unaligned (SseOpcode.Movsd) src1 src2))\n\n;; Helper for creating `movlhps` instructions.\n(decl x64_movlhps (Xmm XmmMem) Xmm)\n(rule 0 (x64_movlhps src1 src2)\n      (xmm_rm_r (SseOpcode.Movlhps) src1 src2))\n(rule 1 (x64_movlhps src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vmovlhps) src1 src2))\n\n;; Helpers for creating `pmaxs*` instructions.\n(decl x64_pmaxs (Type Xmm XmmMem) Xmm)\n(rule (x64_pmaxs $I8X16 x y) (x64_pmaxsb x y))\n(rule (x64_pmaxs $I16X8 x y) (x64_pmaxsw x y))\n(rule (x64_pmaxs $I32X4 x y) (x64_pmaxsd x y))\n;; No $I64X2 version (PMAXSQ) in SSE4.1.\n(decl x64_pmaxsb (Xmm XmmMem) Xmm)\n(rule 0 (x64_pmaxsb src1 src2) (xmm_rm_r (SseOpcode.Pmaxsb) src1 src2))\n(rule 1 (x64_pmaxsb src1 src2)\n        (if-let $true (has_avx))\n        (xmm_rmir_vex (AvxOpcode.Vpmaxsb) src1 src2))\n(decl x64_pmaxsw (Xmm XmmMem) Xmm)\n(rule 0 (x64_pmaxsw src1 src2) (xmm_rm_r (SseOpcode.Pmaxsw) src1 src2))\n(rule 1 (x64_pmaxsw src1 src2)\n        (if-let $true (has_avx))\n        (xmm_rmir_vex (AvxOpcode.Vpmaxsw) src1 src2))\n(decl x64_pmaxsd (Xmm XmmMem) Xmm)\n(rule 0 (x64_pmaxsd src1 src2) (xmm_rm_r (SseOpcode.Pmaxsd) src1 src2))\n(rule 1 (x64_pmaxsd src1 src2)\n        (if-let $true (has_avx))\n        (xmm_rmir_vex (AvxOpcode.Vpmaxsd) src1 src2))\n\n;; Helpers for creating `pmins*` instructions.\n(decl x64_pmins (Type Xmm XmmMem) Xmm)\n(rule (x64_pmins $I8X16 x y) (x64_pminsb x y))\n(rule (x64_pmins $I16X8 x y) (x64_pminsw x y))\n(rule (x64_pmins $I32X4 x y) (x64_pminsd x y))\n;; No $I64X2 version (PMINSQ) in SSE4.1.\n(decl x64_pminsb (Xmm XmmMem) Xmm)\n(rule 0 (x64_pminsb src1 src2) (xmm_rm_r (SseOpcode.Pminsb) src1 src2))\n(rule 1 (x64_pminsb src1 src2)\n        (if-let $true (has_avx))\n        (xmm_rmir_vex (AvxOpcode.Vpminsb) src1 src2))\n(decl x64_pminsw (Xmm XmmMem) Xmm)\n(rule 0 (x64_pminsw src1 src2) (xmm_rm_r (SseOpcode.Pminsw) src1 src2))\n(rule 1 (x64_pminsw src1 src2)\n        (if-let $true (has_avx))\n        (xmm_rmir_vex (AvxOpcode.Vpminsw) src1 src2))\n(decl x64_pminsd (Xmm XmmMem) Xmm)\n(rule 0 (x64_pminsd src1 src2) (xmm_rm_r (SseOpcode.Pminsd) src1 src2))\n(rule 1 (x64_pminsd src1 src2)\n        (if-let $true (has_avx))\n        (xmm_rmir_vex (AvxOpcode.Vpminsd) src1 src2))\n\n;; Helpers for creating `pmaxu*` instructions.\n(decl x64_pmaxu (Type Xmm XmmMem) Xmm)\n(rule (x64_pmaxu $I8X16 x y) (x64_pmaxub x y))\n(rule (x64_pmaxu $I16X8 x y) (x64_pmaxuw x y))\n(rule (x64_pmaxu $I32X4 x y) (x64_pmaxud x y))\n;; No $I64X2 version (PMAXUQ) in SSE4.1.\n(decl x64_pmaxub (Xmm XmmMem) Xmm)\n(rule 0 (x64_pmaxub src1 src2) (xmm_rm_r (SseOpcode.Pmaxub) src1 src2))\n(rule 1 (x64_pmaxub src1 src2)\n        (if-let $true (has_avx))\n        (xmm_rmir_vex (AvxOpcode.Vpmaxub) src1 src2))\n(decl x64_pmaxuw (Xmm XmmMem) Xmm)\n(rule 0 (x64_pmaxuw src1 src2) (xmm_rm_r (SseOpcode.Pmaxuw) src1 src2))\n(rule 1 (x64_pmaxuw src1 src2)\n        (if-let $true (has_avx))\n        (xmm_rmir_vex (AvxOpcode.Vpmaxuw) src1 src2))\n(decl x64_pmaxud (Xmm XmmMem) Xmm)\n(rule 0 (x64_pmaxud src1 src2) (xmm_rm_r (SseOpcode.Pmaxud) src1 src2))\n(rule 1 (x64_pmaxud src1 src2)\n        (if-let $true (has_avx))\n        (xmm_rmir_vex (AvxOpcode.Vpmaxud) src1 src2))\n\n;; Helper for creating `pminu*` instructions.\n(decl x64_pminu (Type Xmm XmmMem) Xmm)\n(rule (x64_pminu $I8X16 x y) (x64_pminub x y))\n(rule (x64_pminu $I16X8 x y) (x64_pminuw x y))\n(rule (x64_pminu $I32X4 x y) (x64_pminud x y))\n;; No $I64X2 version (PMINUQ) in SSE4.1.\n(decl x64_pminub (Xmm XmmMem) Xmm)\n(rule 0 (x64_pminub src1 src2) (xmm_rm_r (SseOpcode.Pminub) src1 src2))\n(rule 1 (x64_pminub src1 src2)\n        (if-let $true (has_avx))\n        (xmm_rmir_vex (AvxOpcode.Vpminub) src1 src2))\n(decl x64_pminuw (Xmm XmmMem) Xmm)\n(rule 0 (x64_pminuw src1 src2) (xmm_rm_r (SseOpcode.Pminuw) src1 src2))\n(rule 1 (x64_pminuw src1 src2)\n        (if-let $true (has_avx))\n        (xmm_rmir_vex (AvxOpcode.Vpminuw) src1 src2))\n(decl x64_pminud (Xmm XmmMem) Xmm)\n(rule 0 (x64_pminud src1 src2) (xmm_rm_r (SseOpcode.Pminud) src1 src2))\n(rule 1 (x64_pminud src1 src2)\n        (if-let $true (has_avx))\n        (xmm_rmir_vex (AvxOpcode.Vpminud) src1 src2))\n\n;; Helper for creating `punpcklbw` instructions.\n(decl x64_punpcklbw (Xmm XmmMem) Xmm)\n(rule 0 (x64_punpcklbw src1 src2)\n      (xmm_rm_r (SseOpcode.Punpcklbw) src1 src2))\n(rule 1 (x64_punpcklbw src1 src2)\n        (if-let $true (has_avx))\n        (xmm_rmir_vex (AvxOpcode.Vpunpcklbw) src1 src2))\n\n;; Helper for creating `punpckhbw` instructions.\n(decl x64_punpckhbw (Xmm XmmMem) Xmm)\n(rule 0 (x64_punpckhbw src1 src2)\n      (xmm_rm_r (SseOpcode.Punpckhbw) src1 src2))\n(rule 1 (x64_punpckhbw src1 src2)\n        (if-let $true (has_avx))\n        (xmm_rmir_vex (AvxOpcode.Vpunpckhbw) src1 src2))\n\n;; Helper for creating `packsswb` instructions.\n(decl x64_packsswb (Xmm XmmMem) Xmm)\n(rule 0 (x64_packsswb src1 src2)\n      (xmm_rm_r (SseOpcode.Packsswb) src1 src2))\n(rule 1 (x64_packsswb src1 src2)\n        (if-let $true (has_avx))\n        (xmm_rmir_vex (AvxOpcode.Vpacksswb) src1 src2))\n\n;; Helper for creating `packssdw` instructions.\n(decl x64_packssdw (Xmm XmmMem) Xmm)\n(rule 0 (x64_packssdw src1 src2)\n      (xmm_rm_r (SseOpcode.Packssdw) src1 src2))\n(rule 1 (x64_packssdw src1 src2)\n        (if-let $true (has_avx))\n        (xmm_rmir_vex (AvxOpcode.Vpackssdw) src1 src2))\n\n;; Helper for creating `packuswb` instructions.\n(decl x64_packuswb (Xmm XmmMem) Xmm)\n(rule 0 (x64_packuswb src1 src2)\n      (xmm_rm_r (SseOpcode.Packuswb) src1 src2))\n(rule 1 (x64_packuswb src1 src2)\n        (if-let $true (has_avx))\n        (xmm_rmir_vex (AvxOpcode.Vpackuswb) src1 src2))\n\n;; Helper for creating `packusdw` instructions.\n(decl x64_packusdw (Xmm XmmMem) Xmm)\n(rule 0 (x64_packusdw src1 src2)\n      (xmm_rm_r (SseOpcode.Packusdw) src1 src2))\n(rule 1 (x64_packusdw src1 src2)\n        (if-let $true (has_avx))\n        (xmm_rmir_vex (AvxOpcode.Vpackusdw) src1 src2))\n\n;; Helper for creating `MInst.XmmRmRImm` instructions.\n(decl xmm_rm_r_imm (SseOpcode Reg RegMem u8 OperandSize) Xmm)\n(rule (xmm_rm_r_imm op src1 src2 imm size)\n      (let ((dst WritableXmm (temp_writable_xmm))\n            (_ Unit (emit (MInst.XmmRmRImm op\n                                           src1\n                                           src2\n                                           dst\n                                           imm\n                                           size))))\n        dst))\n\n;; Helper for creating `palignr` instructions.\n(decl x64_palignr (Xmm XmmMem u8 OperandSize) Xmm)\n(rule 0 (x64_palignr src1 src2 imm size)\n      (xmm_rm_r_imm (SseOpcode.Palignr)\n                    src1\n                    src2\n                    imm\n                    size))\n(rule 1 (x64_palignr src1 src2 imm size)\n      (if-let $true (has_avx))\n      (xmm_rmr_imm_vex (AvxOpcode.Vpalignr) src1 src2 imm))\n\n;; Helpers for creating `cmpp*` instructions.\n(decl x64_cmpp (Type Xmm XmmMem FcmpImm) Xmm)\n(rule (x64_cmpp $F32X4 x y imm) (x64_cmpps x y imm))\n(rule (x64_cmpp $F64X2 x y imm) (x64_cmppd x y imm))\n\n(decl x64_cmpps (Xmm XmmMem FcmpImm) Xmm)\n(rule 0 (x64_cmpps src1 src2 imm)\n      (xmm_rm_r_imm (SseOpcode.Cmpps)\n                    src1\n                    src2\n                    (encode_fcmp_imm imm)\n                    (OperandSize.Size32)))\n(rule 1 (x64_cmpps src1 src2 imm)\n      (if-let $true (has_avx))\n      (xmm_rmr_imm_vex (AvxOpcode.Vcmpps)\n                       src1\n                       src2\n                       (encode_fcmp_imm imm)))\n\n;; Note that `Size32` is intentional despite this being used for 64-bit\n;; operations, since this presumably induces the correct encoding of the\n;; instruction.\n(decl x64_cmppd (Xmm XmmMem FcmpImm) Xmm)\n(rule 0 (x64_cmppd src1 src2 imm)\n      (xmm_rm_r_imm (SseOpcode.Cmppd)\n                    src1\n                    src2\n                    (encode_fcmp_imm imm)\n                    (OperandSize.Size32)))\n(rule 1 (x64_cmppd src1 src2 imm)\n      (if-let $true (has_avx))\n      (xmm_rmr_imm_vex (AvxOpcode.Vcmppd)\n                       src1\n                       src2\n                       (encode_fcmp_imm imm)))\n\n;; Helper for creating `pinsrb` instructions.\n(decl x64_pinsrb (Xmm GprMem u8) Xmm)\n(rule 0 (x64_pinsrb src1 src2 lane)\n      (xmm_rm_r_imm (SseOpcode.Pinsrb)\n                    src1\n                    src2\n                    lane\n                    (OperandSize.Size32)))\n(rule 1 (x64_pinsrb src1 src2 lane)\n      (if-let $true (has_avx))\n      (xmm_vex_pinsr (AvxOpcode.Vpinsrb) src1 src2 lane))\n\n;; Helper for creating `pinsrw` instructions.\n(decl x64_pinsrw (Xmm GprMem u8) Xmm)\n(rule 0 (x64_pinsrw src1 src2 lane)\n      (xmm_rm_r_imm (SseOpcode.Pinsrw)\n                    src1\n                    src2\n                    lane\n                    (OperandSize.Size32)))\n(rule 1 (x64_pinsrw src1 src2 lane)\n      (if-let $true (has_avx))\n      (xmm_vex_pinsr (AvxOpcode.Vpinsrw) src1 src2 lane))\n\n;; Helper for creating `pinsrd` instructions.\n(decl x64_pinsrd (Xmm GprMem u8) Xmm)\n(rule 0 (x64_pinsrd src1 src2 lane)\n      (xmm_rm_r_imm (SseOpcode.Pinsrd)\n                    src1\n                    src2\n                    lane\n                    (OperandSize.Size32)))\n(rule 1 (x64_pinsrd src1 src2 lane)\n      (if-let $true (has_avx))\n      (xmm_vex_pinsr (AvxOpcode.Vpinsrd) src1 src2 lane))\n\n;; Helper for creating `pinsrq` instructions.\n(decl x64_pinsrq (Xmm GprMem u8) Xmm)\n(rule (x64_pinsrq src1 src2 lane)\n      (xmm_rm_r_imm (SseOpcode.Pinsrd)\n                    src1\n                    src2\n                    lane\n                    (OperandSize.Size64)))\n(rule 1 (x64_pinsrq src1 src2 lane)\n      (if-let $true (has_avx))\n      (xmm_vex_pinsr (AvxOpcode.Vpinsrq) src1 src2 lane))\n\n;; Helper for constructing `XmmVexPinsr` instructions.\n(decl xmm_vex_pinsr (AvxOpcode Xmm GprMem u8) Xmm)\n(rule (xmm_vex_pinsr op src1 src2 imm)\n      (let ((dst WritableXmm (temp_writable_xmm))\n            (_ Unit (emit (MInst.XmmVexPinsr op src1 src2 dst imm))))\n        dst))\n\n;; Helper for constructing `XmmUnaryRmRImm` instructions.\n(decl xmm_unary_rm_r_imm (SseOpcode XmmMemAligned u8) Xmm)\n(rule (xmm_unary_rm_r_imm op src1 imm)\n      (let ((dst WritableXmm (temp_writable_xmm))\n            (_ Unit (emit (MInst.XmmUnaryRmRImm op src1 imm dst))))\n        dst))\n\n;; Helper for creating `roundss` instructions.\n(decl x64_roundss (XmmMem RoundImm) Xmm)\n(rule (x64_roundss src1 round)\n      (xmm_unary_rm_r_imm (SseOpcode.Roundss) src1 (encode_round_imm round)))\n\n;; Helper for creating `roundsd` instructions.\n(decl x64_roundsd (XmmMem RoundImm) Xmm)\n(rule (x64_roundsd src1 round)\n      (xmm_unary_rm_r_imm (SseOpcode.Roundsd) src1 (encode_round_imm round)))\n\n;; Helper for creating `roundps` instructions.\n(decl x64_roundps (XmmMem RoundImm) Xmm)\n(rule (x64_roundps src1 round)\n      (xmm_unary_rm_r_imm (SseOpcode.Roundps) src1 (encode_round_imm round)))\n(rule 1 (x64_roundps src1 round)\n      (if-let $true (has_avx))\n      (xmm_unary_rm_r_imm_vex (AvxOpcode.Vroundps) src1 (encode_round_imm round)))\n\n;; Helper for creating `roundpd` instructions.\n(decl x64_roundpd (XmmMem RoundImm) Xmm)\n(rule (x64_roundpd src1 round)\n      (xmm_unary_rm_r_imm (SseOpcode.Roundpd) src1 (encode_round_imm round)))\n(rule 1 (x64_roundpd src1 round)\n      (if-let $true (has_avx))\n      (xmm_unary_rm_r_imm_vex (AvxOpcode.Vroundpd) src1 (encode_round_imm round)))\n\n;; Helper for creating `pmaddwd` instructions.\n(decl x64_pmaddwd (Xmm XmmMem) Xmm)\n(rule 0 (x64_pmaddwd src1 src2)\n      (xmm_rm_r (SseOpcode.Pmaddwd) src1 src2))\n(rule 1 (x64_pmaddwd src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vpmaddwd) src1 src2))\n\n(decl x64_pmaddubsw (Xmm XmmMem) Xmm)\n(rule 0 (x64_pmaddubsw src1 src2)\n      (xmm_rm_r (SseOpcode.Pmaddubsw) src1 src2))\n(rule 1 (x64_pmaddubsw src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vpmaddubsw) src1 src2))\n\n;; Helper for creating `insertps` instructions.\n(decl x64_insertps (Xmm XmmMem u8) Xmm)\n(rule 0 (x64_insertps src1 src2 lane)\n      (xmm_rm_r_imm (SseOpcode.Insertps)\n                    src1\n                    src2\n                    lane\n                    (OperandSize.Size32)))\n(rule 1 (x64_insertps src1 src2 lane)\n      (if-let $true (has_avx))\n      (xmm_rmr_imm_vex (AvxOpcode.Vinsertps) src1 src2 lane))\n\n;; Helper for creating `pshufd` instructions.\n(decl x64_pshufd (XmmMem u8) Xmm)\n(rule (x64_pshufd src imm)\n      (xmm_unary_rm_r_imm (SseOpcode.Pshufd) src imm))\n\n;; Helper for creating `pshufb` instructions.\n(decl x64_pshufb (Xmm XmmMem) Xmm)\n(rule 0 (x64_pshufb src1 src2)\n      (xmm_rm_r (SseOpcode.Pshufb) src1 src2))\n(rule 1 (x64_pshufb src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vpshufb) src1 src2))\n\n;; Helper for creating `shufps` instructions.\n(decl x64_shufps (Xmm XmmMem u8) Xmm)\n(rule 0 (x64_shufps src1 src2 byte)\n      (xmm_rm_r_imm (SseOpcode.Shufps)\n                    src1\n                    src2\n                    byte\n                    (OperandSize.Size32)))\n(rule 1 (x64_shufps src1 src2 byte)\n      (if-let $true (has_avx))\n      (xmm_rmr_imm_vex (AvxOpcode.Vshufps) src1 src2 byte))\n\n;; Helper for creating `MInst.XmmUnaryRmR` instructions.\n(decl xmm_unary_rm_r (SseOpcode XmmMemAligned) Xmm)\n(rule (xmm_unary_rm_r op src)\n      (let ((dst WritableXmm (temp_writable_xmm))\n            (_ Unit (emit (MInst.XmmUnaryRmR op src dst))))\n        dst))\n\n;; Helper for creating `MInst.XmmUnaryRmRUnaligned` instructions.\n(decl xmm_unary_rm_r_unaligned (SseOpcode XmmMem) Xmm)\n(rule (xmm_unary_rm_r_unaligned op src)\n      (let ((dst WritableXmm (temp_writable_xmm))\n            (_ Unit (emit (MInst.XmmUnaryRmRUnaligned op src dst))))\n        dst))\n\n;; Helper for creating `pabsb` instructions.\n(decl x64_pabsb (XmmMem) Xmm)\n(rule (x64_pabsb src)\n      (xmm_unary_rm_r (SseOpcode.Pabsb) src))\n(rule 1 (x64_pabsb src)\n      (if-let $true (has_avx))\n      (xmm_unary_rm_r_vex (AvxOpcode.Vpabsb) src))\n\n;; Helper for creating `pabsw` instructions.\n(decl x64_pabsw (XmmMem) Xmm)\n(rule (x64_pabsw src)\n      (xmm_unary_rm_r (SseOpcode.Pabsw) src))\n(rule 1 (x64_pabsw src)\n      (if-let $true (has_avx))\n      (xmm_unary_rm_r_vex (AvxOpcode.Vpabsw) src))\n\n;; Helper for creating `pabsd` instructions.\n(decl x64_pabsd (XmmMem) Xmm)\n(rule (x64_pabsd src)\n      (xmm_unary_rm_r (SseOpcode.Pabsd) src))\n(rule 1 (x64_pabsd src)\n      (if-let $true (has_avx))\n      (xmm_unary_rm_r_vex (AvxOpcode.Vpabsd) src))\n\n;; Helper for creating `MInst.XmmUnaryRmREvex` instructions.\n(decl xmm_unary_rm_r_evex (Avx512Opcode XmmMem) Xmm)\n(rule (xmm_unary_rm_r_evex op src)\n      (let ((dst WritableXmm (temp_writable_xmm))\n            (_ Unit (emit (MInst.XmmUnaryRmREvex op src dst))))\n        dst))\n\n;; Helper for creating `vcvtudq2ps` instructions.\n(decl x64_vcvtudq2ps (XmmMem) Xmm)\n(rule (x64_vcvtudq2ps src)\n      (xmm_unary_rm_r_evex (Avx512Opcode.Vcvtudq2ps) src))\n\n;; Helper for creating `vpabsq` instructions.\n(decl x64_vpabsq (XmmMem) Xmm)\n(rule (x64_vpabsq src)\n      (xmm_unary_rm_r_evex (Avx512Opcode.Vpabsq) src))\n\n;; Helper for creating `vpopcntb` instructions.\n(decl x64_vpopcntb (XmmMem) Xmm)\n(rule (x64_vpopcntb src)\n      (xmm_unary_rm_r_evex (Avx512Opcode.Vpopcntb) src))\n\n;; Helper for creating `MInst.XmmRmREvex` instructions.\n(decl xmm_rm_r_evex (Avx512Opcode XmmMem Xmm) Xmm)\n(rule (xmm_rm_r_evex op src1 src2)\n      (let ((dst WritableXmm (temp_writable_xmm))\n            (_ Unit (emit (MInst.XmmRmREvex op\n                                            src1\n                                            src2\n                                            dst))))\n        dst))\n\n;; Helper for creating `vpmullq` instructions.\n;;\n;; Requires AVX-512 vl and dq.\n(decl x64_vpmullq (XmmMem Xmm) Xmm)\n(rule (x64_vpmullq src1 src2)\n      (xmm_rm_r_evex (Avx512Opcode.Vpmullq)\n                     src1\n                     src2))\n\n;; Helper for creating `vpermi2b` instructions.\n;;\n;; Requires AVX-512 vl and vbmi extensions.\n(decl x64_vpermi2b (Xmm Xmm Xmm) Xmm)\n(rule (x64_vpermi2b src1 src2 src3)\n      (let ((dst WritableXmm (temp_writable_xmm))\n            (_ Unit (emit (MInst.XmmRmREvex3 (Avx512Opcode.Vpermi2b)\n                                             src1\n                                             src2\n                                             src3\n                                             dst))))\n        dst))\n\n;; Helper for creating `MInst.MulHi` instructions.\n;;\n;; Returns the (lo, hi) register halves of the multiplication.\n(decl mul_hi (Type bool Gpr GprMem) ValueRegs)\n(rule (mul_hi ty signed src1 src2)\n      (let ((dst_lo WritableGpr (temp_writable_gpr))\n            (dst_hi WritableGpr (temp_writable_gpr))\n            (size OperandSize (raw_operand_size_of_type ty))\n            (_ Unit (emit (MInst.MulHi size\n                                       signed\n                                       src1\n                                       src2\n                                       dst_lo\n                                       dst_hi))))\n        (value_gprs dst_lo dst_hi)))\n\n;; Helper for creating `mul` instructions that return both the lower and\n;; (unsigned) higher halves of the result.\n(decl mulhi_u (Type Gpr GprMem) ValueRegs)\n(rule (mulhi_u ty src1 src2)\n      (mul_hi ty $false src1 src2))\n\n;; Helper for creating `MInst.XmmRmiXmm` instructions.\n(decl xmm_rmi_xmm (SseOpcode Xmm XmmMemAlignedImm) Xmm)\n(rule (xmm_rmi_xmm op src1 src2)\n      (let ((dst WritableXmm (temp_writable_xmm))\n            (_ Unit (emit (MInst.XmmRmiReg op\n                                           src1\n                                           src2\n                                           dst))))\n        dst))\n\n;; Helper for creating `psllw` instructions.\n(decl x64_psllw (Xmm XmmMemImm) Xmm)\n(rule 0 (x64_psllw src1 src2)\n      (xmm_rmi_xmm (SseOpcode.Psllw) src1 src2))\n(rule 1 (x64_psllw src1 src2)\n        (if-let $true (has_avx))\n        (xmm_rmir_vex (AvxOpcode.Vpsllw) src1 src2))\n\n;; Helper for creating `pslld` instructions.\n(decl x64_pslld (Xmm XmmMemImm) Xmm)\n(rule 0 (x64_pslld src1 src2)\n      (xmm_rmi_xmm (SseOpcode.Pslld) src1 src2))\n(rule 1 (x64_pslld src1 src2)\n        (if-let $true (has_avx))\n        (xmm_rmir_vex (AvxOpcode.Vpslld) src1 src2))\n\n;; Helper for creating `psllq` instructions.\n(decl x64_psllq (Xmm XmmMemImm) Xmm)\n(rule 0 (x64_psllq src1 src2)\n      (xmm_rmi_xmm (SseOpcode.Psllq) src1 src2))\n(rule 1 (x64_psllq src1 src2)\n        (if-let $true (has_avx))\n        (xmm_rmir_vex (AvxOpcode.Vpsllq) src1 src2))\n\n;; Helper for creating `psrlw` instructions.\n(decl x64_psrlw (Xmm XmmMemImm) Xmm)\n(rule 0 (x64_psrlw src1 src2)\n      (xmm_rmi_xmm (SseOpcode.Psrlw) src1 src2))\n(rule 1 (x64_psrlw src1 src2)\n        (if-let $true (has_avx))\n        (xmm_rmir_vex (AvxOpcode.Vpsrlw) src1 src2))\n\n;; Helper for creating `psrld` instructions.\n(decl x64_psrld (Xmm XmmMemImm) Xmm)\n(rule 0 (x64_psrld src1 src2)\n      (xmm_rmi_xmm (SseOpcode.Psrld) src1 src2))\n(rule 1 (x64_psrld src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vpsrld) src1 src2))\n\n;; Helper for creating `psrlq` instructions.\n(decl x64_psrlq (Xmm XmmMemImm) Xmm)\n(rule 0 (x64_psrlq src1 src2)\n      (xmm_rmi_xmm (SseOpcode.Psrlq) src1 src2))\n(rule 1 (x64_psrlq src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vpsrlq) src1 src2))\n\n;; Helper for creating `psraw` instructions.\n(decl x64_psraw (Xmm XmmMemImm) Xmm)\n(rule 0 (x64_psraw src1 src2)\n      (xmm_rmi_xmm (SseOpcode.Psraw) src1 src2))\n(rule 1 (x64_psraw src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vpsraw) src1 src2))\n\n;; Helper for creating `psrad` instructions.\n(decl x64_psrad (Xmm XmmMemImm) Xmm)\n(rule 0 (x64_psrad src1 src2)\n      (xmm_rmi_xmm (SseOpcode.Psrad) src1 src2))\n(rule 1 (x64_psrad src1 src2)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vpsrad) src1 src2))\n\n;; Helper for creating `pextrb` instructions.\n(decl x64_pextrb (Xmm u8) Gpr)\n(rule (x64_pextrb src lane)\n      (xmm_to_gpr_imm (SseOpcode.Pextrb) src lane))\n\n;; Helper for creating `pextrw` instructions.\n(decl x64_pextrw (Xmm u8) Gpr)\n(rule (x64_pextrw src lane)\n      (xmm_to_gpr_imm (SseOpcode.Pextrw) src lane))\n\n;; Helper for creating `pextrd` instructions.\n(decl x64_pextrd (Xmm u8) Gpr)\n(rule (x64_pextrd src lane)\n      (xmm_to_gpr_imm (SseOpcode.Pextrd) src lane))\n\n;; Helper for creating `pextrq` instructions.\n(decl x64_pextrq (Xmm u8) Gpr)\n(rule (x64_pextrq src lane)\n      (xmm_to_gpr_imm (SseOpcode.Pextrq) src lane))\n\n;; Helper for creating `MInst.XmmToGpr` instructions.\n(decl xmm_to_gpr (SseOpcode Xmm OperandSize) Gpr)\n(rule (xmm_to_gpr op src size)\n      (let ((dst WritableGpr (temp_writable_gpr))\n            (_ Unit (emit (MInst.XmmToGpr op src dst size))))\n        dst))\n\n;; Helper for creating `MInst.XmmToGpr` instructions.\n(decl xmm_to_gpr_imm (SseOpcode Xmm u8) Gpr)\n(rule (xmm_to_gpr_imm op src imm)\n      (let ((dst WritableGpr (temp_writable_gpr))\n            (_ Unit (emit (MInst.XmmToGprImm op src dst imm))))\n        dst))\n\n;; Helper for creating `pmovmskb` instructions.\n(decl x64_pmovmskb (OperandSize Xmm) Gpr)\n(rule (x64_pmovmskb size src)\n      (xmm_to_gpr (SseOpcode.Pmovmskb) src size))\n\n;; Helper for creating `movmskps` instructions.\n(decl x64_movmskps (OperandSize Xmm) Gpr)\n(rule (x64_movmskps size src)\n      (xmm_to_gpr (SseOpcode.Movmskps) src size))\n\n;; Helper for creating `movmskpd` instructions.\n(decl x64_movmskpd (OperandSize Xmm) Gpr)\n(rule (x64_movmskpd size src)\n      (xmm_to_gpr (SseOpcode.Movmskpd) src size))\n\n;; Helper for creating `MInst.GprToXmm` instructions.\n(decl gpr_to_xmm (SseOpcode GprMem OperandSize) Xmm)\n(rule (gpr_to_xmm op src size)\n      (let ((dst WritableXmm (temp_writable_xmm))\n            (_ Unit (emit (MInst.GprToXmm op src dst size))))\n        dst))\n\n;; Helper for creating `not` instructions.\n(decl x64_not (Type Gpr) Gpr)\n(rule (x64_not ty src)\n      (let ((dst WritableGpr (temp_writable_gpr))\n            (size OperandSize (operand_size_of_type_32_64 ty))\n            (_ Unit (emit (MInst.Not size src dst))))\n        dst))\n\n;; Helper for creating `neg` instructions.\n(decl x64_neg (Type Gpr) Gpr)\n(rule (x64_neg ty src)\n      (let ((dst WritableGpr (temp_writable_gpr))\n            (size OperandSize (raw_operand_size_of_type ty))\n            (_ Unit (emit (MInst.Neg size src dst))))\n        dst))\n\n;; Helper for creating `neg` instructions whose flags are also used.\n(decl x64_neg_paired (Type Gpr) ProducesFlags)\n(rule (x64_neg_paired ty src)\n      (let ((dst WritableGpr (temp_writable_gpr))\n            (size OperandSize (raw_operand_size_of_type ty))\n            (inst MInst (MInst.Neg size src dst)))\n        (ProducesFlags.ProducesFlagsReturnsResultWithConsumer inst dst)))\n\n(decl x64_lea (SyntheticAmode) Gpr)\n(rule (x64_lea addr)\n      (let ((dst WritableGpr (temp_writable_gpr))\n            (_ Unit (emit (MInst.LoadEffectiveAddress addr dst))))\n        dst))\n\n;; Helper for creating `ud2` instructions.\n(decl x64_ud2 (TrapCode) SideEffectNoResult)\n(rule (x64_ud2 code)\n      (SideEffectNoResult.Inst (MInst.Ud2 code)))\n\n;; Helper for creating `hlt` instructions.\n(decl x64_hlt () SideEffectNoResult)\n(rule (x64_hlt)\n      (SideEffectNoResult.Inst (MInst.Hlt)))\n\n;; Helper for creating `lzcnt` instructions.\n(decl x64_lzcnt (Type Gpr) Gpr)\n(rule (x64_lzcnt ty src)\n      (let ((dst WritableGpr (temp_writable_gpr))\n            (size OperandSize (operand_size_of_type_32_64 ty))\n            (_ Unit (emit (MInst.UnaryRmR size (UnaryRmROpcode.Lzcnt) src dst))))\n        dst))\n\n;; Helper for creating `tzcnt` instructions.\n(decl x64_tzcnt (Type Gpr) Gpr)\n(rule (x64_tzcnt ty src)\n      (let ((dst WritableGpr (temp_writable_gpr))\n            (size OperandSize (operand_size_of_type_32_64 ty))\n            (_ Unit (emit (MInst.UnaryRmR size (UnaryRmROpcode.Tzcnt) src dst))))\n        dst))\n\n;; Helper for creating `bsr` instructions.\n(decl x64_bsr (Type Gpr) ProducesFlags)\n(rule (x64_bsr ty src)\n      (let ((dst WritableGpr (temp_writable_gpr))\n            (size OperandSize (operand_size_of_type_32_64 ty))\n            (inst MInst (MInst.UnaryRmR size (UnaryRmROpcode.Bsr) src dst)))\n        (ProducesFlags.ProducesFlagsReturnsReg inst dst)))\n\n;; Helper for creating `bsr + cmov` instruction pairs that produce the\n;; result of the `bsr`, or `alt` if the input was zero.\n(decl bsr_or_else (Type Gpr Gpr) Gpr)\n(rule (bsr_or_else ty src alt)\n      (let ((bsr ProducesFlags (x64_bsr ty src))\n            ;; Manually extract the result from the bsr, then ignore\n            ;; it below, since we need to thread it into the cmove\n            ;; before we pass the cmove to with_flags_reg.\n            (bsr_result Gpr (produces_flags_get_reg bsr))\n            (cmove ConsumesFlags (cmove ty (CC.Z) alt bsr_result)))\n        (with_flags_reg (produces_flags_ignore bsr) cmove)))\n\n;; Helper for creating `bsf` instructions.\n(decl x64_bsf (Type Gpr) ProducesFlags)\n(rule (x64_bsf ty src)\n      (let ((dst WritableGpr (temp_writable_gpr))\n            (size OperandSize (operand_size_of_type_32_64 ty))\n            (inst MInst (MInst.UnaryRmR size (UnaryRmROpcode.Bsf) src dst)))\n        (ProducesFlags.ProducesFlagsReturnsReg inst dst)))\n\n;; Helper for creating `bsf + cmov` instruction pairs that produce the\n;; result of the `bsf`, or `alt` if the input was zero.\n(decl bsf_or_else (Type Gpr Gpr) Gpr)\n(rule (bsf_or_else ty src alt)\n      (let ((bsf ProducesFlags (x64_bsf ty src))\n            ;; Manually extract the result from the bsf, then ignore\n            ;; it below, since we need to thread it into the cmove\n            ;; before we pass the cmove to with_flags_reg.\n            (bsf_result Gpr (produces_flags_get_reg bsf))\n            (cmove ConsumesFlags (cmove ty (CC.Z) alt bsf_result)))\n        (with_flags_reg (produces_flags_ignore bsf) cmove)))\n\n;; Helper for creating `popcnt` instructions.\n(decl x64_popcnt (Type Gpr) Gpr)\n(rule (x64_popcnt ty src)\n      (let ((dst WritableGpr (temp_writable_gpr))\n            (size OperandSize (operand_size_of_type_32_64 ty))\n            (_ Unit (emit (MInst.UnaryRmR size (UnaryRmROpcode.Popcnt) src dst))))\n        dst))\n\n;; Helper for creating `xmm_min_max_seq` psuedo-instructions.\n(decl xmm_min_max_seq (Type bool Xmm Xmm) Xmm)\n(rule (xmm_min_max_seq ty is_min lhs rhs)\n      (let ((dst WritableXmm (temp_writable_xmm))\n            (size OperandSize (operand_size_of_type_32_64 ty))\n            (_ Unit (emit (MInst.XmmMinMaxSeq size is_min lhs rhs dst))))\n        dst))\n\n;; Helper for creating `minss` instructions.\n(decl x64_minss (Xmm XmmMem) Xmm)\n(rule (x64_minss x y)\n      (xmm_rm_r_unaligned (SseOpcode.Minss) x y))\n(rule 1 (x64_minss x y)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vminss) x y))\n\n;; Helper for creating `minsd` instructions.\n(decl x64_minsd (Xmm XmmMem) Xmm)\n(rule (x64_minsd x y)\n      (xmm_rm_r_unaligned (SseOpcode.Minsd) x y))\n(rule 1 (x64_minsd x y)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vminsd) x y))\n\n;; Helper for creating `minps` instructions.\n(decl x64_minps (Xmm XmmMem) Xmm)\n(rule 0 (x64_minps x y)\n      (xmm_rm_r (SseOpcode.Minps) x y))\n(rule 1 (x64_minps x y)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vminps) x y))\n\n;; Helper for creating `minpd` instructions.\n(decl x64_minpd (Xmm XmmMem) Xmm)\n(rule 0 (x64_minpd x y)\n      (xmm_rm_r (SseOpcode.Minpd) x y))\n(rule 1 (x64_minpd x y)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vminpd) x y))\n\n;; Helper for creating `maxss` instructions.\n(decl x64_maxss (Xmm XmmMem) Xmm)\n(rule (x64_maxss x y)\n      (xmm_rm_r_unaligned (SseOpcode.Maxss) x y))\n(rule 1 (x64_maxss x y)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vmaxss) x y))\n\n;; Helper for creating `maxsd` instructions.\n(decl x64_maxsd (Xmm XmmMem) Xmm)\n(rule (x64_maxsd x y)\n      (xmm_rm_r_unaligned (SseOpcode.Maxsd) x y))\n(rule 1 (x64_maxsd x y)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vmaxsd) x y))\n\n;; Helper for creating `maxps` instructions.\n(decl x64_maxps (Xmm XmmMem) Xmm)\n(rule 0 (x64_maxps x y)\n      (xmm_rm_r (SseOpcode.Maxps) x y))\n(rule 1 (x64_maxps x y)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vmaxps) x y))\n\n;; Helper for creating `maxpd` instructions.\n(decl x64_maxpd (Xmm XmmMem) Xmm)\n(rule 0 (x64_maxpd x y)\n      (xmm_rm_r (SseOpcode.Maxpd) x y))\n(rule 1 (x64_maxpd x y)\n      (if-let $true (has_avx))\n      (xmm_rmir_vex (AvxOpcode.Vmaxpd) x y))\n\n\n;; Helper for creating `MInst.XmmRmiRVex` instructions.\n(decl xmm_rmir_vex (AvxOpcode Xmm XmmMemImm) Xmm)\n(rule (xmm_rmir_vex op src1 src2)\n      (let ((dst WritableXmm (temp_writable_xmm))\n            (_ Unit (emit (MInst.XmmRmiRVex op src1 src2 dst))))\n        dst))\n\n;; Helper for creating `MInst.XmmRmRImmVex` instructions.\n(decl xmm_rmr_imm_vex (AvxOpcode Xmm XmmMem u8) Xmm)\n(rule (xmm_rmr_imm_vex op src1 src2 imm)\n      (let ((dst WritableXmm (temp_writable_xmm))\n            (_ Unit (emit (MInst.XmmRmRImmVex op src1 src2 dst imm))))\n        dst))\n\n;; Helper for creating `MInst.XmmRmRVex3` instructions.\n(decl xmm_rmr_vex3 (AvxOpcode Xmm Xmm XmmMem) Xmm)\n(rule (xmm_rmr_vex3 op src1 src2 src3)\n      (let ((dst WritableXmm (temp_writable_xmm))\n            (_ Unit (emit (MInst.XmmRmRVex3 op src1 src2 src3 dst))))\n        dst))\n\n;; Helper for creating `vfmadd213*` instructions\n(decl x64_vfmadd213 (Type Xmm Xmm XmmMem) Xmm)\n(rule (x64_vfmadd213 $F32 a b c) (xmm_rmr_vex3 (AvxOpcode.Vfmadd213ss) a b c))\n(rule (x64_vfmadd213 $F64 a b c) (xmm_rmr_vex3 (AvxOpcode.Vfmadd213sd) a b c))\n(rule (x64_vfmadd213 $F32X4 a b c) (xmm_rmr_vex3 (AvxOpcode.Vfmadd213ps) a b c))\n(rule (x64_vfmadd213 $F64X2 a b c) (xmm_rmr_vex3 (AvxOpcode.Vfmadd213pd) a b c))\n\n;; Helper for creating `vfmadd132*` instructions\n(decl x64_vfmadd132 (Type Xmm Xmm XmmMem) Xmm)\n(rule (x64_vfmadd132 $F32 a b c) (xmm_rmr_vex3 (AvxOpcode.Vfmadd132ss) a b c))\n(rule (x64_vfmadd132 $F64 a b c) (xmm_rmr_vex3 (AvxOpcode.Vfmadd132sd) a b c))\n(rule (x64_vfmadd132 $F32X4 a b c) (xmm_rmr_vex3 (AvxOpcode.Vfmadd132ps) a b c))\n(rule (x64_vfmadd132 $F64X2 a b c) (xmm_rmr_vex3 (AvxOpcode.Vfmadd132pd) a b c))\n\n;; Helper for creating `vfnmadd213*` instructions\n(decl x64_vfnmadd213 (Type Xmm Xmm XmmMem) Xmm)\n(rule (x64_vfnmadd213 $F32 a b c) (xmm_rmr_vex3 (AvxOpcode.Vfnmadd213ss) a b c))\n(rule (x64_vfnmadd213 $F64 a b c) (xmm_rmr_vex3 (AvxOpcode.Vfnmadd213sd) a b c))\n(rule (x64_vfnmadd213 $F32X4 a b c) (xmm_rmr_vex3 (AvxOpcode.Vfnmadd213ps) a b c))\n(rule (x64_vfnmadd213 $F64X2 a b c) (xmm_rmr_vex3 (AvxOpcode.Vfnmadd213pd) a b c))\n\n;; Helper for creating `vfnmadd132*` instructions\n(decl x64_vfnmadd132 (Type Xmm Xmm XmmMem) Xmm)\n(rule (x64_vfnmadd132 $F32 a b c) (xmm_rmr_vex3 (AvxOpcode.Vfnmadd132ss) a b c))\n(rule (x64_vfnmadd132 $F64 a b c) (xmm_rmr_vex3 (AvxOpcode.Vfnmadd132sd) a b c))\n(rule (x64_vfnmadd132 $F32X4 a b c) (xmm_rmr_vex3 (AvxOpcode.Vfnmadd132ps) a b c))\n(rule (x64_vfnmadd132 $F64X2 a b c) (xmm_rmr_vex3 (AvxOpcode.Vfnmadd132pd) a b c))\n\n;; Helper for creating `sqrtss` instructions.\n(decl x64_sqrtss (XmmMem) Xmm)\n(rule (x64_sqrtss x) (xmm_unary_rm_r_unaligned (SseOpcode.Sqrtss) x))\n\n;; Helper for creating `sqrtsd` instructions.\n(decl x64_sqrtsd (XmmMem) Xmm)\n(rule (x64_sqrtsd x) (xmm_unary_rm_r_unaligned (SseOpcode.Sqrtsd) x))\n\n;; Helper for creating `sqrtps` instructions.\n(decl x64_sqrtps (XmmMem) Xmm)\n(rule (x64_sqrtps x) (xmm_unary_rm_r (SseOpcode.Sqrtps) x))\n(rule 1 (x64_sqrtps x)\n        (if-let $true (has_avx))\n        (xmm_unary_rm_r_vex (AvxOpcode.Vsqrtps) x))\n\n;; Helper for creating `sqrtpd` instructions.\n(decl x64_sqrtpd (XmmMem) Xmm)\n(rule (x64_sqrtpd x) (xmm_unary_rm_r (SseOpcode.Sqrtpd) x))\n(rule 1 (x64_sqrtpd x)\n        (if-let $true (has_avx))\n        (xmm_unary_rm_r_vex (AvxOpcode.Vsqrtpd) x))\n\n;; Helper for creating `cvtss2sd` instructions.\n(decl x64_cvtss2sd (Xmm) Xmm)\n(rule (x64_cvtss2sd x) (xmm_unary_rm_r (SseOpcode.Cvtss2sd) x))\n\n;; Helper for creating `cvtsd2ss` instructions.\n(decl x64_cvtsd2ss (Xmm) Xmm)\n(rule (x64_cvtsd2ss x) (xmm_unary_rm_r (SseOpcode.Cvtsd2ss) x))\n\n;; Helper for creating `cvtdq2ps` instructions.\n(decl x64_cvtdq2ps (XmmMem) Xmm)\n(rule (x64_cvtdq2ps x) (xmm_unary_rm_r (SseOpcode.Cvtdq2ps) x))\n(rule 1 (x64_cvtdq2ps x)\n        (if-let $true (has_avx))\n        (xmm_unary_rm_r_vex (AvxOpcode.Vcvtdq2ps) x))\n\n;; Helper for creating `cvtps2pd` instructions.\n(decl x64_cvtps2pd (XmmMem) Xmm)\n(rule (x64_cvtps2pd x) (xmm_unary_rm_r (SseOpcode.Cvtps2pd) x))\n(rule 1 (x64_cvtps2pd x)\n        (if-let $true (has_avx))\n        (xmm_unary_rm_r_vex (AvxOpcode.Vcvtps2pd) x))\n\n;; Helper for creating `cvtpd2ps` instructions.\n(decl x64_cvtpd2ps (XmmMem) Xmm)\n(rule (x64_cvtpd2ps x) (xmm_unary_rm_r (SseOpcode.Cvtpd2ps) x))\n(rule 1 (x64_cvtpd2ps x)\n        (if-let $true (has_avx))\n        (xmm_unary_rm_r_vex (AvxOpcode.Vcvtpd2ps) x))\n\n;; Helper for creating `cvtdq2pd` instructions.\n(decl x64_cvtdq2pd (XmmMem) Xmm)\n(rule (x64_cvtdq2pd x) (xmm_unary_rm_r (SseOpcode.Cvtdq2pd) x))\n(rule 1 (x64_cvtdq2pd x)\n        (if-let $true (has_avx))\n        (xmm_unary_rm_r_vex (AvxOpcode.Vcvtdq2pd) x))\n\n;; Helper for creating `cvtsi2ss` instructions.\n(decl x64_cvtsi2ss (Type GprMem) Xmm)\n(rule (x64_cvtsi2ss ty x)\n      (gpr_to_xmm (SseOpcode.Cvtsi2ss) x (raw_operand_size_of_type ty)))\n\n;; Helper for creating `cvtsi2sd` instructions.\n(decl x64_cvtsi2sd (Type GprMem) Xmm)\n(rule (x64_cvtsi2sd ty x)\n      (gpr_to_xmm (SseOpcode.Cvtsi2sd) x (raw_operand_size_of_type ty)))\n\n;; Helper for creating `cvttps2dq` instructions.\n(decl x64_cvttps2dq (XmmMem) Xmm)\n(rule (x64_cvttps2dq x)\n      (xmm_unary_rm_r (SseOpcode.Cvttps2dq) x))\n(rule 1 (x64_cvttps2dq x)\n        (if-let $true (has_avx))\n        (xmm_unary_rm_r_vex (AvxOpcode.Vcvttps2dq) x))\n\n;; Helper for creating `cvttpd2dq` instructions.\n(decl x64_cvttpd2dq (XmmMem) Xmm)\n(rule (x64_cvttpd2dq x)\n      (xmm_unary_rm_r (SseOpcode.Cvttpd2dq) x))\n(rule 1 (x64_cvttpd2dq x)\n        (if-let $true (has_avx))\n        (xmm_unary_rm_r_vex (AvxOpcode.Vcvttpd2dq) x))\n\n(decl cvt_u64_to_float_seq (Type Gpr) Xmm)\n(rule (cvt_u64_to_float_seq ty src)\n      (let ((size OperandSize (raw_operand_size_of_type ty))\n            (dst WritableXmm (temp_writable_xmm))\n            (tmp_gpr1 WritableGpr (temp_writable_gpr))\n            (tmp_gpr2 WritableGpr (temp_writable_gpr))\n            (_ Unit (emit (MInst.CvtUint64ToFloatSeq size src dst tmp_gpr1 tmp_gpr2))))\n        dst))\n\n(decl cvt_float_to_uint_seq (Type Value bool) Gpr)\n(rule (cvt_float_to_uint_seq out_ty src @ (value_type src_ty) is_saturating)\n      (let ((out_size OperandSize (raw_operand_size_of_type out_ty))\n            (src_size OperandSize (raw_operand_size_of_type src_ty))\n\n            (dst WritableGpr (temp_writable_gpr))\n            (tmp_xmm WritableXmm (temp_writable_xmm))\n            (tmp_xmm2 WritableXmm (temp_writable_xmm))\n            (tmp_gpr WritableGpr (temp_writable_gpr))\n            (_ Unit (emit (MInst.CvtFloatToUintSeq out_size src_size is_saturating src dst tmp_gpr tmp_xmm tmp_xmm2))))\n        dst))\n\n(decl cvt_float_to_sint_seq (Type Value bool) Gpr)\n(rule (cvt_float_to_sint_seq out_ty src @ (value_type src_ty) is_saturating)\n      (let ((out_size OperandSize (raw_operand_size_of_type out_ty))\n            (src_size OperandSize (raw_operand_size_of_type src_ty))\n\n            (dst WritableGpr (temp_writable_gpr))\n            (tmp_xmm WritableXmm (temp_writable_xmm))\n            (tmp_gpr WritableGpr (temp_writable_gpr))\n            (_ Unit (emit (MInst.CvtFloatToSintSeq out_size src_size is_saturating src dst tmp_gpr tmp_xmm))))\n        dst))\n\n(decl fcvt_uint_mask_const () VCodeConstant)\n(extern constructor fcvt_uint_mask_const fcvt_uint_mask_const)\n\n(decl fcvt_uint_mask_high_const () VCodeConstant)\n(extern constructor fcvt_uint_mask_high_const fcvt_uint_mask_high_const)\n\n;; Helpers for creating `pcmpeq*` instructions.\n(decl x64_pcmpeq (Type Xmm XmmMem) Xmm)\n(rule (x64_pcmpeq $I8X16 x y) (x64_pcmpeqb x y))\n(rule (x64_pcmpeq $I16X8 x y) (x64_pcmpeqw x y))\n(rule (x64_pcmpeq $I32X4 x y) (x64_pcmpeqd x y))\n(rule (x64_pcmpeq $I64X2 x y) (x64_pcmpeqq x y))\n\n(decl x64_pcmpeqb (Xmm XmmMem) Xmm)\n(rule 0 (x64_pcmpeqb x y) (xmm_rm_r (SseOpcode.Pcmpeqb) x y))\n(rule 1 (x64_pcmpeqb x y)\n        (if-let $true (has_avx))\n        (xmm_rmir_vex (AvxOpcode.Vpcmpeqb) x y))\n(decl x64_pcmpeqw (Xmm XmmMem) Xmm)\n(rule 0 (x64_pcmpeqw x y) (xmm_rm_r (SseOpcode.Pcmpeqw) x y))\n(rule 1 (x64_pcmpeqw x y)\n        (if-let $true (has_avx))\n        (xmm_rmir_vex (AvxOpcode.Vpcmpeqw) x y))\n(decl x64_pcmpeqd (Xmm XmmMem) Xmm)\n(rule 0 (x64_pcmpeqd x y) (xmm_rm_r (SseOpcode.Pcmpeqd) x y))\n(rule 1 (x64_pcmpeqd x y)\n        (if-let $true (has_avx))\n        (xmm_rmir_vex (AvxOpcode.Vpcmpeqd) x y))\n(decl x64_pcmpeqq (Xmm XmmMem) Xmm)\n(rule 0 (x64_pcmpeqq x y) (xmm_rm_r (SseOpcode.Pcmpeqq) x y))\n(rule 1 (x64_pcmpeqq x y)\n        (if-let $true (has_avx))\n        (xmm_rmir_vex (AvxOpcode.Vpcmpeqq) x y))\n\n;; Helpers for creating `pcmpgt*` instructions.\n(decl x64_pcmpgt (Type Xmm XmmMem) Xmm)\n(rule (x64_pcmpgt $I8X16 x y) (x64_pcmpgtb x y))\n(rule (x64_pcmpgt $I16X8 x y) (x64_pcmpgtw x y))\n(rule (x64_pcmpgt $I32X4 x y) (x64_pcmpgtd x y))\n(rule (x64_pcmpgt $I64X2 x y) (x64_pcmpgtq x y))\n\n(decl x64_pcmpgtb (Xmm XmmMem) Xmm)\n(rule 0 (x64_pcmpgtb x y) (xmm_rm_r (SseOpcode.Pcmpgtb) x y))\n(rule 1 (x64_pcmpgtb x y)\n        (if-let $true (has_avx))\n        (xmm_rmir_vex (AvxOpcode.Vpcmpgtb) x y))\n(decl x64_pcmpgtw (Xmm XmmMem) Xmm)\n(rule 0 (x64_pcmpgtw x y) (xmm_rm_r (SseOpcode.Pcmpgtw) x y))\n(rule 1 (x64_pcmpgtw x y)\n        (if-let $true (has_avx))\n        (xmm_rmir_vex (AvxOpcode.Vpcmpgtw) x y))\n(decl x64_pcmpgtd (Xmm XmmMem) Xmm)\n(rule 0 (x64_pcmpgtd x y) (xmm_rm_r (SseOpcode.Pcmpgtd) x y))\n(rule 1 (x64_pcmpgtd x y)\n        (if-let $true (has_avx))\n        (xmm_rmir_vex (AvxOpcode.Vpcmpgtd) x y))\n(decl x64_pcmpgtq (Xmm XmmMem) Xmm)\n(rule 0 (x64_pcmpgtq x y) (xmm_rm_r (SseOpcode.Pcmpgtq) x y))\n(rule 1 (x64_pcmpgtq x y)\n        (if-let $true (has_avx))\n        (xmm_rmir_vex (AvxOpcode.Vpcmpgtq) x y))\n\n;; Helpers for read-modify-write ALU form (AluRM).\n(decl alu_rm (Type AluRmiROpcode Amode Gpr) SideEffectNoResult)\n(rule (alu_rm ty opcode src1_dst src2)\n      (let ((size OperandSize (operand_size_of_type_32_64 ty)))\n        (SideEffectNoResult.Inst (MInst.AluRM size opcode src1_dst src2))))\n\n(decl x64_add_mem (Type Amode Gpr) SideEffectNoResult)\n(rule (x64_add_mem ty addr val)\n      (alu_rm ty (AluRmiROpcode.Add) addr val))\n\n(decl x64_sub_mem (Type Amode Gpr) SideEffectNoResult)\n(rule (x64_sub_mem ty addr val)\n      (alu_rm ty (AluRmiROpcode.Sub) addr val))\n\n(decl x64_and_mem (Type Amode Gpr) SideEffectNoResult)\n(rule (x64_and_mem ty addr val)\n      (alu_rm ty (AluRmiROpcode.And) addr val))\n\n(decl x64_or_mem (Type Amode Gpr) SideEffectNoResult)\n(rule (x64_or_mem ty addr val)\n      (alu_rm ty (AluRmiROpcode.Or) addr val))\n\n(decl x64_xor_mem (Type Amode Gpr) SideEffectNoResult)\n(rule (x64_xor_mem ty addr val)\n      (alu_rm ty (AluRmiROpcode.Xor) addr val))\n\n;; Trap if the condition code supplied is set.\n(decl trap_if (CC TrapCode) ConsumesFlags)\n(rule (trap_if cc tc)\n      (ConsumesFlags.ConsumesFlagsSideEffect (MInst.TrapIf cc tc)))\n\n;; Trap if both of the condition codes supplied are set.\n(decl trap_if_and (CC CC TrapCode) ConsumesFlags)\n(rule (trap_if_and cc1 cc2 tc)\n      (ConsumesFlags.ConsumesFlagsSideEffect (MInst.TrapIfAnd cc1 cc2 tc)))\n\n;; Trap if either of the condition codes supplied are set.\n(decl trap_if_or (CC CC TrapCode) ConsumesFlags)\n(rule (trap_if_or cc1 cc2 tc)\n      (ConsumesFlags.ConsumesFlagsSideEffect (MInst.TrapIfOr cc1 cc2 tc)))\n\n(decl trap_if_icmp (IcmpCondResult TrapCode) SideEffectNoResult)\n(rule (trap_if_icmp (IcmpCondResult.Condition producer cc) tc)\n      (with_flags_side_effect producer (trap_if cc tc)))\n\n(decl trap_if_fcmp (FcmpCondResult TrapCode) SideEffectNoResult)\n(rule (trap_if_fcmp (FcmpCondResult.Condition producer cc) tc)\n      (with_flags_side_effect producer (trap_if cc tc)))\n(rule (trap_if_fcmp (FcmpCondResult.AndCondition producer cc1 cc2) tc)\n      (with_flags_side_effect producer (trap_if_and cc1 cc2 tc)))\n(rule (trap_if_fcmp (FcmpCondResult.OrCondition producer cc1 cc2) tc)\n      (with_flags_side_effect producer (trap_if_or cc1 cc2 tc)))\n\n;;;; Jumps ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n\n;; Unconditional jump.\n(decl jmp_known (MachLabel) SideEffectNoResult)\n(rule (jmp_known target)\n      (SideEffectNoResult.Inst (MInst.JmpKnown target)))\n\n(decl jmp_if (CC MachLabel) ConsumesFlags)\n(rule (jmp_if cc taken)\n      (ConsumesFlags.ConsumesFlagsSideEffect (MInst.JmpIf cc taken)))\n\n;; Conditional jump based on the condition code.\n(decl jmp_cond (CC MachLabel MachLabel) ConsumesFlags)\n(rule (jmp_cond cc taken not_taken)\n      (ConsumesFlags.ConsumesFlagsSideEffect (MInst.JmpCond cc taken not_taken)))\n\n;; Conditional jump based on the result of an icmp.\n(decl jmp_cond_icmp (IcmpCondResult MachLabel MachLabel) SideEffectNoResult)\n(rule (jmp_cond_icmp (IcmpCondResult.Condition producer cc) taken not_taken)\n      (with_flags_side_effect producer (jmp_cond cc taken not_taken)))\n\n;; Conditional jump based on the result of an fcmp.\n(decl jmp_cond_fcmp (FcmpCondResult MachLabel MachLabel) SideEffectNoResult)\n(rule (jmp_cond_fcmp (FcmpCondResult.Condition producer cc) taken not_taken)\n      (with_flags_side_effect producer (jmp_cond cc taken not_taken)))\n(rule (jmp_cond_fcmp (FcmpCondResult.AndCondition producer cc1 cc2) taken not_taken)\n      (with_flags_side_effect producer\n                              (consumes_flags_concat\n                                (jmp_if (cc_invert cc1) not_taken)\n                                (jmp_cond (cc_invert cc2) not_taken taken))))\n(rule (jmp_cond_fcmp (FcmpCondResult.OrCondition producer cc1 cc2) taken not_taken)\n      (with_flags_side_effect producer\n                              (consumes_flags_concat\n                                (jmp_if cc1 taken)\n                                (jmp_cond cc2 taken not_taken))))\n\n;; Emit the compound instruction that does:\n;;\n;; lea $jt, %rA\n;; movsbl [%rA, %rIndex, 2], %rB\n;; add %rB, %rA\n;; j *%rA\n;; [jt entries]\n;;\n;; This must be *one* instruction in the vcode because we cannot allow regalloc\n;; to insert any spills/fills in the middle of the sequence; otherwise, the\n;; lea PC-rel offset to the jumptable would be incorrect.  (The alternative\n;; is to introduce a relocation pass for inlined jumptables, which is much\n;; worse.)\n(decl jmp_table_seq (Type Gpr MachLabel BoxVecMachLabel) SideEffectNoResult)\n(rule (jmp_table_seq ty idx default_target jt_targets)\n      (let (;; This temporary is used as a signed integer of 64-bits (to hold\n            ;; addresses).\n            (tmp1 WritableGpr (temp_writable_gpr))\n\n            ;; This temporary is used as a signed integer of 32-bits (for the\n            ;; wasm-table index) and then 64-bits (address addend). The small\n            ;; lie about the I64 type is benign, since the temporary is dead\n            ;; after this instruction (and its Cranelift type is thus unused).\n            (tmp2 WritableGpr (temp_writable_gpr)))\n\n          (SideEffectNoResult.Inst\n            (MInst.JmpTableSeq idx tmp1 tmp2 default_target jt_targets))))\n\n;;;; iadd_pairwise constants ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n\n(decl iadd_pairwise_mul_const_16 () VCodeConstant)\n(extern constructor iadd_pairwise_mul_const_16 iadd_pairwise_mul_const_16)\n\n(decl iadd_pairwise_mul_const_32 () VCodeConstant)\n(extern constructor iadd_pairwise_mul_const_32 iadd_pairwise_mul_const_32)\n\n(decl iadd_pairwise_xor_const_32 () VCodeConstant)\n(extern constructor iadd_pairwise_xor_const_32 iadd_pairwise_xor_const_32)\n\n(decl iadd_pairwise_addd_const_32 () VCodeConstant)\n(extern constructor iadd_pairwise_addd_const_32 iadd_pairwise_addd_const_32)\n\n;;;; snarrow constants ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n\n(decl snarrow_umax_mask () VCodeConstant)\n(extern constructor snarrow_umax_mask snarrow_umax_mask)\n\n;;;; Comparisons ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n\n(type IcmpCondResult (enum (Condition (producer ProducesFlags) (cc CC))))\n\n(decl icmp_cond_result (ProducesFlags CC) IcmpCondResult)\n(rule (icmp_cond_result producer cc) (IcmpCondResult.Condition producer cc))\n\n(decl invert_icmp_cond_result (IcmpCondResult) IcmpCondResult)\n(rule (invert_icmp_cond_result (IcmpCondResult.Condition producer cc))\n      (icmp_cond_result producer (cc_invert cc)))\n\n;; Lower an Icmp result into a boolean value in a register.\n(decl lower_icmp_bool (IcmpCondResult) ValueRegs)\n(rule (lower_icmp_bool (IcmpCondResult.Condition producer cc))\n      (with_flags producer (x64_setcc cc)))\n\n;; Emit a conditional move based on the result of an icmp.\n(decl select_icmp (IcmpCondResult Value Value) ValueRegs)\n\n;; Ensure that we put the `x` argument into a register for single-register\n;; gpr-typed arguments, as we rely on this for the legalization of heap_addr and\n;; loading easily computed constants (like 0) from memory is too expensive.\n(rule 1 (select_icmp (IcmpCondResult.Condition producer cc) x @ (value_type (is_single_register_gpr_type ty)) y)\n      (with_flags producer (cmove ty cc (put_in_gpr x) y)))\n\n;; Otherwise, fall back on the behavior of `cmove_from_values`.\n(rule 0 (select_icmp (IcmpCondResult.Condition producer cc) x @ (value_type ty) y)\n      (with_flags producer (cmove_from_values ty cc x y)))\n\n(decl emit_cmp (IntCC Value Value) IcmpCondResult)\n\n;; For GPR-held values we only need to emit `CMP + SETCC`. We rely here on\n;; Cranelift's verification that `a` and `b` are of the same type.\n;; Unfortunately for clarity, the registers are flipped here (TODO).\n(rule 0 (emit_cmp cc a @ (value_type ty) b)\n      (let ((size OperandSize (raw_operand_size_of_type ty)))\n        (icmp_cond_result (x64_cmp size b a) cc)))\n\n;; As a special case, reverse the arguments to the comparison when the LHS is a\n;; constant. This ensures that we avoid moving the constant into a register when\n;; performing the comparison.\n(rule 1 (emit_cmp cc (and (simm32_from_value a) (value_type ty)) b)\n      (let ((size OperandSize (raw_operand_size_of_type ty)))\n        (icmp_cond_result (x64_cmp size a b) (intcc_reverse cc))))\n\n;; For I128 values (held in two GPRs), the instruction sequences depend on what\n;; kind of condition is tested.\n(rule 3 (emit_cmp (IntCC.Equal) a @ (value_type $I128) b)\n      (let ((a_lo Gpr (value_regs_get_gpr a 0))\n            (a_hi Gpr (value_regs_get_gpr a 1))\n            (b_lo Gpr (value_regs_get_gpr b 0))\n            (b_hi Gpr (value_regs_get_gpr b 1))\n            (cmp_lo Reg (with_flags_reg (x64_cmp (OperandSize.Size64) b_lo a_lo) (x64_setcc (CC.Z))))\n            (cmp_hi Reg (with_flags_reg (x64_cmp (OperandSize.Size64) b_hi a_hi) (x64_setcc (CC.Z))))\n            ;; At this point, `cmp_lo` and `cmp_hi` contain either 0 or 1 in the\n            ;; lowest 8 bits--`SETcc` guarantees this. The upper bits may be\n            ;; unchanged so we must compare against 1 below; this instruction\n            ;; combines `cmp_lo` and `cmp_hi` for that final comparison.\n            (cmp Reg (x64_and $I64 cmp_lo cmp_hi)))\n        ;; We must compare one more time against the immediate value 1 to\n        ;; check if both `cmp_lo` and `cmp_hi` are true. If `cmp AND 1 == 0`\n        ;; then the `ZF` will be set (see `TEST` definition); if either of\n        ;; the halves `AND`s to 0, they were not equal, therefore we `SETcc`\n        ;; with `NZ`.\n        (icmp_cond_result\n          (x64_test (OperandSize.Size64) (RegMemImm.Imm 1) cmp)\n          (CC.NZ))))\n\n(rule 3 (emit_cmp (IntCC.NotEqual) a @ (value_type $I128) b)\n      (let ((a_lo Gpr (value_regs_get_gpr a 0))\n            (a_hi Gpr (value_regs_get_gpr a 1))\n            (b_lo Gpr (value_regs_get_gpr b 0))\n            (b_hi Gpr (value_regs_get_gpr b 1))\n            (cmp_lo Reg (with_flags_reg (x64_cmp (OperandSize.Size64) b_lo a_lo) (x64_setcc (CC.NZ))))\n            (cmp_hi Reg (with_flags_reg (x64_cmp (OperandSize.Size64) b_hi a_hi) (x64_setcc (CC.NZ))))\n            ;; See comments for `IntCC.Equal`.\n            (cmp Reg (x64_or $I64 cmp_lo cmp_hi)))\n           (icmp_cond_result\n             (x64_test (OperandSize.Size64) (RegMemImm.Imm 1) cmp)\n             (CC.NZ))))\n\n;; Result = (a_hi <> b_hi) ||\n;;          (a_hi == b_hi && a_lo <> b_lo)\n(rule 2 (emit_cmp cc a @ (value_type $I128) b)\n      (let ((a_lo Gpr (value_regs_get_gpr a 0))\n            (a_hi Gpr (value_regs_get_gpr a 1))\n            (b_lo Gpr (value_regs_get_gpr b 0))\n            (b_hi Gpr (value_regs_get_gpr b 1))\n            (cmp_hi ValueRegs (with_flags (x64_cmp (OperandSize.Size64) b_hi a_hi)\n                                       (consumes_flags_concat\n                                                 (x64_setcc (intcc_without_eq cc))\n                                                 (x64_setcc (CC.Z)))))\n            (cc_hi Reg (value_regs_get cmp_hi 0))\n            (eq_hi Reg (value_regs_get cmp_hi 1))\n\n            (cmp_lo Reg (with_flags_reg (x64_cmp (OperandSize.Size64) b_lo a_lo)\n                                        (x64_setcc (intcc_unsigned cc))))\n\n            (res_lo Reg (x64_and $I64 eq_hi cmp_lo))\n            (res Reg (x64_or $I64 cc_hi res_lo)))\n        (icmp_cond_result\n          (x64_test (OperandSize.Size64) (RegMemImm.Imm 1) res)\n          (CC.NZ))))\n\n(type FcmpCondResult\n      (enum\n        ;; The given condition code must be set.\n        (Condition (producer ProducesFlags) (cc CC))\n\n        ;; Both condition codes must be set.\n        (AndCondition (producer ProducesFlags) (cc1 CC) (cc2 CC))\n\n        ;; Either of the conditions codes must be set.\n        (OrCondition (producer ProducesFlags) (cc1 CC) (cc2 CC))))\n\n;; Lower a FcmpCondResult to a boolean value in a register.\n(decl lower_fcmp_bool (FcmpCondResult) ValueRegs)\n\n(rule (lower_fcmp_bool (FcmpCondResult.Condition producer cc))\n      (with_flags producer (x64_setcc cc)))\n\n(rule (lower_fcmp_bool (FcmpCondResult.AndCondition producer cc1 cc2))\n      (let ((maybe ValueRegs (with_flags producer\n                                         (consumes_flags_concat\n                                           (x64_setcc cc1)\n                                           (x64_setcc cc2))))\n            (maybe0 Gpr (value_regs_get_gpr maybe 0))\n            (maybe1 Gpr (value_regs_get_gpr maybe 1)))\n        (value_reg (x64_and $I8 maybe0 maybe1))))\n\n(rule (lower_fcmp_bool (FcmpCondResult.OrCondition producer cc1 cc2))\n      (let ((maybe ValueRegs (with_flags producer\n                                         (consumes_flags_concat\n                                           (x64_setcc cc1)\n                                           (x64_setcc cc2))))\n            (maybe0 Gpr (value_regs_get_gpr maybe 0))\n            (maybe1 Gpr (value_regs_get_gpr maybe 1)))\n        (value_reg (x64_or $I8 maybe0 maybe1))))\n\n;; CLIF's `fcmp` instruction always operates on XMM registers--both scalar and\n;; vector. For the scalar versions, we use the flag-setting behavior of the\n;; `UCOMIS*` instruction to `SETcc` a 0 or 1 in a GPR register. Note that CLIF's\n;; `select` uses the same kind of flag-setting behavior but chooses values other\n;; than 0 or 1.\n;;\n;; Checking the result of `UCOMIS*` is unfortunately difficult in some cases\n;; because we do not have `SETcc` instructions that explicitly check\n;; simultaneously for the condition (i.e., `eq`, `le`, `gt`, etc.) *and*\n;; orderedness. Instead, we must check the flags multiple times. The UCOMIS*\n;; documentation (see Intel's Software Developer's Manual, volume 2, chapter 4)\n;; is helpful:\n;;  - unordered assigns    Z = 1, P = 1, C = 1\n;;  - greater than assigns Z = 0, P = 0, C = 0\n;;  - less than assigns    Z = 0, P = 0, C = 1\n;;  - equal assigns        Z = 1, P = 0, C = 0\n(decl emit_fcmp (FloatCC Value Value) FcmpCondResult)\n\n(rule (emit_fcmp (FloatCC.Equal) a @ (value_type (ty_scalar_float _)) b)\n      (FcmpCondResult.AndCondition (x64_ucomis b a) (CC.NP) (CC.Z)))\n\n(rule (emit_fcmp (FloatCC.NotEqual) a @ (value_type (ty_scalar_float _)) b)\n      (FcmpCondResult.OrCondition (x64_ucomis b a) (CC.P) (CC.NZ)))\n\n;; Some scalar lowerings correspond to one condition code.\n\n(rule (emit_fcmp (FloatCC.Ordered) a @ (value_type (ty_scalar_float ty)) b)\n      (FcmpCondResult.Condition (x64_ucomis b a) (CC.NP)))\n(rule (emit_fcmp (FloatCC.Unordered) a @ (value_type (ty_scalar_float ty)) b)\n      (FcmpCondResult.Condition (x64_ucomis b a) (CC.P)))\n(rule (emit_fcmp (FloatCC.OrderedNotEqual) a @ (value_type (ty_scalar_float ty)) b)\n      (FcmpCondResult.Condition (x64_ucomis b a) (CC.NZ)))\n(rule (emit_fcmp (FloatCC.UnorderedOrEqual) a @ (value_type (ty_scalar_float ty)) b)\n      (FcmpCondResult.Condition (x64_ucomis b a) (CC.Z)))\n(rule (emit_fcmp (FloatCC.GreaterThan) a @ (value_type (ty_scalar_float ty)) b)\n      (FcmpCondResult.Condition (x64_ucomis b a) (CC.NBE)))\n(rule (emit_fcmp (FloatCC.GreaterThanOrEqual) a @ (value_type (ty_scalar_float ty)) b)\n      (FcmpCondResult.Condition (x64_ucomis b a) (CC.NB)))\n(rule (emit_fcmp (FloatCC.UnorderedOrLessThan) a @ (value_type (ty_scalar_float ty)) b)\n      (FcmpCondResult.Condition (x64_ucomis b a) (CC.B)))\n(rule (emit_fcmp (FloatCC.UnorderedOrLessThanOrEqual) a @ (value_type (ty_scalar_float ty)) b)\n      (FcmpCondResult.Condition (x64_ucomis b a) (CC.BE)))\n\n;; Other scalar lowerings are made possible by flipping the operands and\n;; reversing the condition code.\n\n(rule (emit_fcmp (FloatCC.LessThan) a @ (value_type (ty_scalar_float ty)) b)\n      ;; Same flags as `GreaterThan`.\n      (FcmpCondResult.Condition (x64_ucomis a b) (CC.NBE)))\n(rule (emit_fcmp (FloatCC.LessThanOrEqual) a @ (value_type (ty_scalar_float ty)) b)\n      ;; Same flags as `GreaterThanOrEqual`.\n      (FcmpCondResult.Condition (x64_ucomis a b) (CC.NB)))\n(rule (emit_fcmp (FloatCC.UnorderedOrGreaterThan) a @ (value_type (ty_scalar_float ty)) b)\n      ;; Same flags as `UnorderedOrLessThan`.\n      (FcmpCondResult.Condition (x64_ucomis a b) (CC.B)))\n(rule (emit_fcmp (FloatCC.UnorderedOrGreaterThanOrEqual) a @ (value_type (ty_scalar_float ty)) b)\n      ;; Same flags as `UnorderedOrLessThanOrEqual`.\n      (FcmpCondResult.Condition (x64_ucomis a b) (CC.BE)))\n\n;;;; Type Guards ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n\n;; A type guard for matching ints and bools up to 64 bits, or 64 bit references.\n(decl ty_int_bool_or_ref () Type)\n(extern extractor ty_int_bool_or_ref ty_int_bool_or_ref)\n\n;;;; Atomics ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n\n(decl x64_mfence () SideEffectNoResult)\n(rule (x64_mfence)\n      (SideEffectNoResult.Inst (MInst.Fence (FenceKind.MFence))))\n\n(decl x64_cmpxchg (Type Gpr Gpr SyntheticAmode) Gpr)\n(rule (x64_cmpxchg ty expected replacement addr)\n      (let ((dst WritableGpr (temp_writable_gpr))\n            (_ Unit (emit (MInst.LockCmpxchg ty replacement expected addr dst))))\n        dst))\n\n(decl x64_atomic_rmw_seq (Type MachAtomicRmwOp SyntheticAmode Gpr) Gpr)\n(rule (x64_atomic_rmw_seq ty op mem input)\n      (let ((dst WritableGpr (temp_writable_gpr))\n            (tmp WritableGpr (temp_writable_gpr))\n            (_ Unit (emit (MInst.AtomicRmwSeq ty op mem input tmp dst))))\n        dst))\n\n;; CLIF IR has one enumeration for atomic operations (`AtomicRmwOp`) while the\n;; mach backend has another (`MachAtomicRmwOp`)--this converts one to the other.\n(type MachAtomicRmwOp extern (enum))\n(decl atomic_rmw_op_to_mach_atomic_rmw_op (AtomicRmwOp) MachAtomicRmwOp)\n(extern constructor atomic_rmw_op_to_mach_atomic_rmw_op atomic_rmw_op_to_mach_atomic_rmw_op)\n\n;;;; Casting ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n\n(decl bitcast_xmm_to_gpr (Type Xmm) Gpr)\n(rule (bitcast_xmm_to_gpr $F32 src)\n      (xmm_to_gpr (SseOpcode.Movd) src (OperandSize.Size32)))\n(rule (bitcast_xmm_to_gpr $F64 src)\n      (xmm_to_gpr (SseOpcode.Movq) src (OperandSize.Size64)))\n\n(decl bitcast_gpr_to_xmm (Type Gpr) Xmm)\n(rule (bitcast_gpr_to_xmm $I32 src)\n      (gpr_to_xmm (SseOpcode.Movd) src (OperandSize.Size32)))\n(rule (bitcast_gpr_to_xmm $I64 src)\n      (gpr_to_xmm (SseOpcode.Movq) src (OperandSize.Size64)))\n\n;;;; Stack Addresses ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n\n(decl stack_addr_impl (StackSlot Offset32) Gpr)\n(rule (stack_addr_impl stack_slot offset)\n      (let ((dst WritableGpr (temp_writable_gpr))\n            (_ Unit (emit (abi_stackslot_addr dst stack_slot offset))))\n        dst))\n\n;;;; Division/Remainders ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n\n(decl emit_div_or_rem (DivOrRemKind Type WritableGpr Gpr Gpr) Unit)\n(extern constructor emit_div_or_rem emit_div_or_rem)\n\n(decl div_or_rem (DivOrRemKind Value Value) Gpr)\n(rule (div_or_rem kind a @ (value_type ty) b)\n      (let ((dst WritableGpr (temp_writable_gpr))\n            (_ Unit (emit_div_or_rem kind ty dst a b)))\n        dst))\n\n;;;; Pinned Register ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n\n(decl read_pinned_gpr () Gpr)\n(rule (read_pinned_gpr)\n      (mov_from_preg (preg_pinned)))\n\n(decl write_pinned_gpr (Gpr) SideEffectNoResult)\n(rule (write_pinned_gpr val)\n      (mov_to_preg (preg_pinned) val))\n\n;;;; Shuffle ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n\n;; Produce a mask suitable for use with `pshufb` for permuting the argument to\n;; shuffle, when the arguments are the same (i.e. `shuffle a a mask`). This will\n;; map all indices in the range 0..31 to the range 0..15.\n(decl shuffle_0_31_mask (VecMask) VCodeConstant)\n(extern constructor shuffle_0_31_mask shuffle_0_31_mask)\n\n;; Produce a mask suitable for use with `pshufb` for permuting the lhs of a\n;; `shuffle` operation (lanes 0-15).\n(decl shuffle_0_15_mask (VecMask) VCodeConstant)\n(extern constructor shuffle_0_15_mask shuffle_0_15_mask)\n\n;; Produce a mask suitable for use with `pshufb` for permuting the rhs of a\n;; `shuffle` operation (lanes 16-31).\n(decl shuffle_16_31_mask (VecMask) VCodeConstant)\n(extern constructor shuffle_16_31_mask shuffle_16_31_mask)\n\n;; Produce a permutation suitable for use with `vpermi2b`, for permuting two\n;; I8X16 vectors simultaneously.\n;;\n;; NOTE: `vpermi2b` will mask the indices in each lane to 5 bits when indexing\n;; into vectors, so this constructor makes no effort to handle indices that are\n;; larger than 31. If you are lowering a clif opcode like `shuffle` that has\n;; special behavior for out of bounds indices (emitting a `0` in the resulting\n;; vector in the case of `shuffle`) you'll need to handle that behavior\n;; separately.\n(decl perm_from_mask (VecMask) VCodeConstant)\n(extern constructor perm_from_mask perm_from_mask)\n\n;; If the mask that would be given to `shuffle` contains any out-of-bounds\n;; indices, return a mask that will zero those.\n(decl perm_from_mask_with_zeros (VCodeConstant VCodeConstant) VecMask)\n(extern extractor perm_from_mask_with_zeros perm_from_mask_with_zeros)\n\n;;;; Swizzle ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n\n;; Create a mask for zeroing out-of-bounds lanes of the swizzle mask.\n(decl swizzle_zero_mask () VCodeConstant)\n(extern constructor swizzle_zero_mask swizzle_zero_mask)\n\n;;;; TLS Values ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n\n;; Helper for emitting ElfTlsGetAddr.\n(decl elf_tls_get_addr (ExternalName) Gpr)\n(rule (elf_tls_get_addr name)\n      (let ((dst WritableGpr (temp_writable_gpr))\n            (_ Unit (emit (MInst.ElfTlsGetAddr name dst))))\n        dst))\n\n;; Helper for emitting MachOTlsGetAddr.\n(decl macho_tls_get_addr (ExternalName) Gpr)\n(rule (macho_tls_get_addr name)\n      (let ((dst WritableGpr (temp_writable_gpr))\n            (_ Unit (emit (MInst.MachOTlsGetAddr name dst))))\n        dst))\n\n;; Helper for emitting CoffTlsGetAddr.\n(decl coff_tls_get_addr (ExternalName) Gpr)\n(rule (coff_tls_get_addr name)\n      (let ((dst WritableGpr (temp_writable_gpr))\n            (tmp WritableGpr (temp_writable_gpr))\n            (_ Unit (emit (MInst.CoffTlsGetAddr name dst tmp))))\n        dst))\n\n;;;; sqmul_round_sat ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n\n(decl sqmul_round_sat_mask () VCodeConstant)\n(extern constructor sqmul_round_sat_mask sqmul_round_sat_mask)\n\n;;;; uunarrow ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n\n(decl uunarrow_umax_mask () VCodeConstant)\n(extern constructor uunarrow_umax_mask uunarrow_umax_mask)\n\n(decl uunarrow_uint_mask () VCodeConstant)\n(extern constructor uunarrow_uint_mask uunarrow_uint_mask)\n\n;;;; Automatic conversions ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n\n(convert Gpr InstOutput output_gpr)\n(convert Value Gpr put_in_gpr)\n(convert Value GprMem put_in_gpr_mem)\n(convert Value GprMemImm put_in_gpr_mem_imm)\n(convert Value RegMem put_in_reg_mem)\n(convert Value RegMemImm put_in_reg_mem_imm)\n(convert Gpr GprMemImm gpr_to_gpr_mem_imm)\n(convert Gpr GprMem gpr_to_gpr_mem)\n(convert Gpr Reg gpr_to_reg)\n(convert GprMem RegMem gpr_mem_to_reg_mem)\n(convert Reg Gpr gpr_new)\n(convert WritableGpr Gpr writable_gpr_to_gpr)\n(convert RegMemImm GprMemImm gpr_mem_imm_new)\n(convert RegMem GprMem reg_mem_to_gpr_mem)\n(convert RegMem RegMemImm reg_mem_to_reg_mem_imm)\n(convert Reg GprMem reg_to_gpr_mem)\n(convert Reg GprMemImm reg_to_gpr_mem_imm)\n(convert WritableGpr WritableReg writable_gpr_to_reg)\n(convert WritableGpr Reg writable_gpr_to_r_reg)\n(convert WritableGpr GprMem writable_gpr_to_gpr_mem)\n(convert WritableGpr ValueRegs writable_gpr_to_value_regs)\n\n(convert Xmm InstOutput output_xmm)\n(convert Value Xmm put_in_xmm)\n(convert Value XmmMem put_in_xmm_mem)\n(convert Value XmmMemAligned put_in_xmm_mem_aligned)\n(convert Value XmmMemImm put_in_xmm_mem_imm)\n(convert Xmm Reg xmm_to_reg)\n(convert Xmm RegMem xmm_to_reg_mem)\n(convert Reg Xmm xmm_new)\n(convert Reg XmmMem reg_to_xmm_mem)\n(convert Reg RegMemImm reg_to_reg_mem_imm)\n(convert RegMem XmmMem reg_mem_to_xmm_mem)\n(convert RegMemImm XmmMemImm mov_rmi_to_xmm)\n(convert Xmm XmmMem xmm_to_xmm_mem)\n(convert Xmm XmmMemImm xmm_to_xmm_mem_imm)\n(convert Xmm XmmMemAligned xmm_to_xmm_mem_aligned)\n(convert XmmMem XmmMemImm xmm_mem_to_xmm_mem_imm)\n(convert XmmMem RegMem xmm_mem_to_reg_mem)\n(convert WritableXmm Xmm writable_xmm_to_xmm)\n(convert WritableXmm WritableReg writable_xmm_to_reg)\n(convert WritableXmm Reg writable_xmm_to_r_reg)\n(convert WritableXmm XmmMem writable_xmm_to_xmm_mem)\n(convert WritableXmm ValueRegs writable_xmm_to_value_regs)\n\n;; Note that these conversions will introduce a `movupd` instruction if\n;; the memory location is not aligned to a 16-byte boundary. This is primarily\n;; used to convert `XmmMem` inputs, which themselves were typically created\n;; via the `put_in_xmm_mem` constructor, into operands of SSE instructions.\n;; Most pre-AVX instructions working with 16-bytes of data (e.g. full xmm\n;; registers) require 16-byte alignment.\n(convert XmmMem XmmMemAligned xmm_mem_to_xmm_mem_aligned)\n(convert XmmMemImm XmmMemAlignedImm xmm_mem_imm_to_xmm_mem_aligned_imm)\n\n(convert Gpr Imm8Gpr gpr_to_imm8_gpr)\n(convert Imm8Reg Imm8Gpr imm8_reg_to_imm8_gpr)\n\n(convert Amode SyntheticAmode amode_to_synthetic_amode)\n(convert Amode GprMem amode_to_gpr_mem)\n(convert SyntheticAmode GprMem synthetic_amode_to_gpr_mem)\n(convert Amode XmmMem amode_to_xmm_mem)\n(convert SyntheticAmode XmmMem synthetic_amode_to_xmm_mem)\n(convert Amode XmmMemAligned amode_to_xmm_mem_aligned)\n(convert SyntheticAmode XmmMemAligned synthetic_amode_to_xmm_mem_aligned)\n(convert VCodeConstant SyntheticAmode const_to_synthetic_amode)\n(convert VCodeConstant XmmMem const_to_xmm_mem)\n\n(convert IntCC CC intcc_to_cc)\n(convert AtomicRmwOp MachAtomicRmwOp atomic_rmw_op_to_mach_atomic_rmw_op)\n\n(convert SinkableLoad RegMem sink_load)\n(convert SinkableLoad GprMemImm sink_load_to_gpr_mem_imm)\n(convert SinkableLoad XmmMem sink_load_to_xmm_mem)\n\n(decl reg_to_xmm_mem (Reg) XmmMem)\n(rule (reg_to_xmm_mem r)\n      (xmm_to_xmm_mem (xmm_new r)))\n(decl xmm_to_reg_mem (Reg) XmmMem)\n(rule (xmm_to_reg_mem r)\n      (RegMem.Reg (xmm_to_reg r)))\n\n(decl writable_gpr_to_r_reg (WritableGpr) Reg)\n(rule (writable_gpr_to_r_reg w_gpr)\n      (writable_reg_to_reg (writable_gpr_to_reg w_gpr)))\n(decl writable_gpr_to_gpr_mem (WritableGpr) GprMem)\n(rule (writable_gpr_to_gpr_mem w_gpr)\n      (gpr_to_gpr_mem w_gpr))\n(decl writable_gpr_to_value_regs (WritableGpr) ValueRegs)\n(rule (writable_gpr_to_value_regs w_gpr)\n      (value_reg w_gpr))\n(decl writable_xmm_to_r_reg (WritableXmm) Reg)\n(rule (writable_xmm_to_r_reg w_xmm)\n      (writable_reg_to_reg (writable_xmm_to_reg w_xmm)))\n(decl writable_xmm_to_xmm_mem (WritableXmm) XmmMem)\n(rule (writable_xmm_to_xmm_mem w_xmm)\n      (xmm_to_xmm_mem (writable_xmm_to_xmm w_xmm)))\n(decl writable_xmm_to_value_regs (WritableXmm) ValueRegs)\n(rule (writable_xmm_to_value_regs w_xmm)\n      (value_reg w_xmm))\n\n(decl synthetic_amode_to_gpr_mem (SyntheticAmode) GprMem)\n(decl amode_to_gpr_mem (Amode) GprMem)\n(rule (amode_to_gpr_mem amode)\n      (amode_to_synthetic_amode amode))\n(rule (synthetic_amode_to_gpr_mem amode)\n      (synthetic_amode_to_reg_mem amode))\n(decl amode_to_xmm_mem (Amode) XmmMem)\n(rule (amode_to_xmm_mem amode)\n      (amode_to_synthetic_amode amode))\n(decl synthetic_amode_to_xmm_mem (SyntheticAmode) XmmMem)\n(rule (synthetic_amode_to_xmm_mem amode)\n      (synthetic_amode_to_reg_mem amode))\n(decl const_to_synthetic_amode (VCodeConstant) SyntheticAmode)\n(extern constructor const_to_synthetic_amode const_to_synthetic_amode)\n(decl const_to_xmm_mem (VCodeConstant) XmmMem)\n(rule (const_to_xmm_mem c) (const_to_synthetic_amode c))\n\n(decl xmm_to_xmm_mem_aligned (Xmm) XmmMemAligned)\n(rule (xmm_to_xmm_mem_aligned reg) (xmm_mem_to_xmm_mem_aligned reg))\n(decl amode_to_xmm_mem_aligned (Amode) XmmMemAligned)\n(rule (amode_to_xmm_mem_aligned mode) (amode_to_xmm_mem mode))\n(decl synthetic_amode_to_xmm_mem_aligned (SyntheticAmode) XmmMemAligned)\n(rule (synthetic_amode_to_xmm_mem_aligned mode) (synthetic_amode_to_xmm_mem mode))\n(decl put_in_xmm_mem_aligned (Value) XmmMemAligned)\n(rule (put_in_xmm_mem_aligned val) (put_in_xmm_mem val))\n\n;; Helper for creating `MovFromPReg` instructions.\n(decl mov_from_preg (PReg) Reg)\n(rule (mov_from_preg preg)\n      (let ((dst WritableGpr (temp_writable_gpr))\n            (_ Unit (emit (MInst.MovFromPReg preg dst))))\n        dst))\n\n(decl mov_to_preg (PReg Gpr) SideEffectNoResult)\n(rule (mov_to_preg dst src)\n      (SideEffectNoResult.Inst (MInst.MovToPReg src dst)))\n\n(decl preg_rbp () PReg)\n(extern constructor preg_rbp preg_rbp)\n\n(decl preg_rsp () PReg)\n(extern constructor preg_rsp preg_rsp)\n\n(decl preg_pinned () PReg)\n(extern constructor preg_pinned preg_pinned)\n\n(decl x64_rbp () Reg)\n(rule (x64_rbp)\n      (mov_from_preg (preg_rbp)))\n\n(decl x64_rsp () Reg)\n(rule (x64_rsp)\n      (mov_from_preg (preg_rsp)))\n\n;;;; Helpers for Emitting LibCalls ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n\n(type LibCall extern\n      (enum\n        FmaF32\n        FmaF64\n        CeilF32\n        CeilF64\n        FloorF32\n        FloorF64\n        NearestF32\n        NearestF64\n        TruncF32\n        TruncF64))\n\n(decl libcall_1 (LibCall Reg) Reg)\n(extern constructor libcall_1 libcall_1)\n\n(decl libcall_3 (LibCall Reg Reg Reg) Reg)\n(extern constructor libcall_3 libcall_3)\n", "test compile precise-output\ntarget x86_64\n\nfunction %amode_add(i64, i64) -> i64 {\nblock0(v0: i64, v1: i64):\n    v2 = iadd v0, v1\n    v3 = load.i64 v2\n    return v3\n}\n\n; VCode:\n;   pushq   %rbp\n;   movq    %rsp, %rbp\n; block0:\n;   movq    0(%rdi,%rsi,1), %rax\n;   movq    %rbp, %rsp\n;   popq    %rbp\n;   ret\n; \n; Disassembled:\n; block0: ; offset 0x0\n;   pushq %rbp\n;   movq %rsp, %rbp\n; block1: ; offset 0x4\n;   movq (%rdi, %rsi), %rax ; trap: heap_oob\n;   movq %rbp, %rsp\n;   popq %rbp\n;   retq\n\nfunction %amode_add_imm(i64) -> i64 {\nblock0(v0: i64):\n    v1 = iconst.i64 42\n    v2 = iadd v0, v1\n    v3 = load.i64 v2\n    return v3\n}\n\n; VCode:\n;   pushq   %rbp\n;   movq    %rsp, %rbp\n; block0:\n;   movq    42(%rdi), %rax\n;   movq    %rbp, %rsp\n;   popq    %rbp\n;   ret\n; \n; Disassembled:\n; block0: ; offset 0x0\n;   pushq %rbp\n;   movq %rsp, %rbp\n; block1: ; offset 0x4\n;   movq 0x2a(%rdi), %rax ; trap: heap_oob\n;   movq %rbp, %rsp\n;   popq %rbp\n;   retq\n\nfunction %amode_add_imm_order(i64) -> i64 {\nblock0(v0: i64):\n    v1 = iconst.i64 42\n    v2 = iadd v1, v0\n    v3 = load.i64 v2\n    return v3\n}\n\n; VCode:\n;   pushq   %rbp\n;   movq    %rsp, %rbp\n; block0:\n;   movq    42(%rdi), %rax\n;   movq    %rbp, %rsp\n;   popq    %rbp\n;   ret\n; \n; Disassembled:\n; block0: ; offset 0x0\n;   pushq %rbp\n;   movq %rsp, %rbp\n; block1: ; offset 0x4\n;   movq 0x2a(%rdi), %rax ; trap: heap_oob\n;   movq %rbp, %rsp\n;   popq %rbp\n;   retq\n\nfunction %amode_add_uext_imm(i64) -> i64 {\nblock0(v0: i64):\n    v1 = iconst.i32 42\n    v2 = uextend.i64 v1\n    v3 = iadd v2, v0\n    v4 = load.i64 v3\n    return v4\n}\n\n; VCode:\n;   pushq   %rbp\n;   movq    %rsp, %rbp\n; block0:\n;   movq    42(%rdi), %rax\n;   movq    %rbp, %rsp\n;   popq    %rbp\n;   ret\n; \n; Disassembled:\n; block0: ; offset 0x0\n;   pushq %rbp\n;   movq %rsp, %rbp\n; block1: ; offset 0x4\n;   movq 0x2a(%rdi), %rax ; trap: heap_oob\n;   movq %rbp, %rsp\n;   popq %rbp\n;   retq\n\nfunction %amode_reg_reg_imm(i64, i64) -> i64 {\nblock0(v0: i64, v1: i64):\n    v2 = iadd v0, v1\n    v3 = iconst.i64 256\n    v4 = iadd v2, v3\n    v5 = load.i64 v4+64\n    return v5\n}\n\n; VCode:\n;   pushq   %rbp\n;   movq    %rsp, %rbp\n; block0:\n;   movq    320(%rdi,%rsi,1), %rax\n;   movq    %rbp, %rsp\n;   popq    %rbp\n;   ret\n; \n; Disassembled:\n; block0: ; offset 0x0\n;   pushq %rbp\n;   movq %rsp, %rbp\n; block1: ; offset 0x4\n;   movq 0x140(%rdi, %rsi), %rax ; trap: heap_oob\n;   movq %rbp, %rsp\n;   popq %rbp\n;   retq\n\nfunction %amode_reg_reg_imm_negative(i64, i64) -> i64 {\nblock0(v0: i64, v1: i64):\n    v2 = iadd v0, v1\n    v3 = iconst.i64 -1\n    v4 = iadd v2, v3\n    v5 = load.i64 v4\n    return v5\n}\n\n; VCode:\n;   pushq   %rbp\n;   movq    %rsp, %rbp\n; block0:\n;   movq    -1(%rdi,%rsi,1), %rax\n;   movq    %rbp, %rsp\n;   popq    %rbp\n;   ret\n; \n; Disassembled:\n; block0: ; offset 0x0\n;   pushq %rbp\n;   movq %rsp, %rbp\n; block1: ; offset 0x4\n;   movq -1(%rdi, %rsi), %rax ; trap: heap_oob\n;   movq %rbp, %rsp\n;   popq %rbp\n;   retq\n\nfunction %amode_reg_reg_imm_scaled(i64, i64) -> i64 {\nblock0(v0: i64, v1: i64):\n    v2 = iconst.i64 -1\n    v3 = iadd v0, v2\n    v4 = ishl_imm v1, 3\n    v5 = iadd v3, v4\n    v6 = load.i64 v5\n    return v6\n}\n\n; VCode:\n;   pushq   %rbp\n;   movq    %rsp, %rbp\n; block0:\n;   movq    -1(%rdi,%rsi,8), %rax\n;   movq    %rbp, %rsp\n;   popq    %rbp\n;   ret\n; \n; Disassembled:\n; block0: ; offset 0x0\n;   pushq %rbp\n;   movq %rsp, %rbp\n; block1: ; offset 0x4\n;   movq -1(%rdi, %rsi, 8), %rax ; trap: heap_oob\n;   movq %rbp, %rsp\n;   popq %rbp\n;   retq\n\nfunction %amode_reg_reg_imm_uext_scaled(i64, i32) -> i64 {\nblock0(v0: i64, v1: i32):\n    v2 = iconst.i64 -1\n    v3 = iadd v0, v2\n    v4 = ishl_imm v1, 3\n    v5 = uextend.i64 v4\n    v6 = iadd v3, v5\n    v7 = load.i64 v6\n    return v7\n}\n\n; VCode:\n;   pushq   %rbp\n;   movq    %rsp, %rbp\n; block0:\n;   movq    %rsi, %rdx\n;   shll    $3, %edx, %edx\n;   movq    -1(%rdi,%rdx,1), %rax\n;   movq    %rbp, %rsp\n;   popq    %rbp\n;   ret\n; \n; Disassembled:\n; block0: ; offset 0x0\n;   pushq %rbp\n;   movq %rsp, %rbp\n; block1: ; offset 0x4\n;   movq %rsi, %rdx\n;   shll $3, %edx\n;   movq -1(%rdi, %rdx), %rax ; trap: heap_oob\n;   movq %rbp, %rsp\n;   popq %rbp\n;   retq\n\nfunction %amode_reg_reg_imm_uext_scaled_add(i64, i32, i32) -> i64 {\nblock0(v0: i64, v1: i32, v2: i32):\n    v3 = iconst.i64 -1\n    v4 = iadd v0, v3\n    v5 = iadd v1, v2\n    v6 = ishl_imm v5, 2\n    v7 = uextend.i64 v6\n    v8 = iadd v4, v7\n    v9 = load.i64 v8\n    return v9\n}\n\n; VCode:\n;   pushq   %rbp\n;   movq    %rsp, %rbp\n; block0:\n;   movq    %rsi, %r8\n;   addl    %r8d, %edx, %r8d\n;   shll    $2, %r8d, %r8d\n;   movq    -1(%rdi,%r8,1), %rax\n;   movq    %rbp, %rsp\n;   popq    %rbp\n;   ret\n; \n; Disassembled:\n; block0: ; offset 0x0\n;   pushq %rbp\n;   movq %rsp, %rbp\n; block1: ; offset 0x4\n;   movq %rsi, %r8\n;   addl %edx, %r8d\n;   shll $2, %r8d\n;   movq -1(%rdi, %r8), %rax ; trap: heap_oob\n;   movq %rbp, %rsp\n;   popq %rbp\n;   retq\n\n"], "filenames": ["RELEASES.md", "cranelift/codegen/src/isa/x64/inst.isle", "cranelift/filetests/filetests/isa/x64/amode-opt.clif"], "buggy_code_start_loc": [19, 1066, 212], "buggy_code_end_loc": [122, 1080, 264], "fixing_code_start_loc": [20, 1065, 212], "fixing_code_end_loc": [165, 1065, 268], "type": "CWE-125", "message": "wasmtime is a fast and secure runtime for WebAssembly. In affected versions wasmtime's code generator, Cranelift, has a bug on x86_64 targets where address-mode computation mistakenly would calculate a 35-bit effective address instead of WebAssembly's defined 33-bit effective address. This bug means that, with default codegen settings, a wasm-controlled load/store operation could read/write addresses up to 35 bits away from the base of linear memory. Due to this bug, however, addresses up to `0xffffffff * 8 + 0x7ffffffc = 36507222004 = ~34G` bytes away from the base of linear memory are possible from guest code. This means that the virtual memory 6G away from the base of linear memory up to ~34G away can be read/written by a malicious module. A guest module can, without the knowledge of the embedder, read/write memory in this region. The memory may belong to other WebAssembly instances when using the pooling allocator, for example. Affected embedders are recommended to analyze preexisting wasm modules to see if they're affected by the incorrect codegen rules and possibly correlate that with an anomalous number of traps during historical execution to locate possibly suspicious modules. The specific bug in Cranelift's x86_64 backend is that a WebAssembly address which is left-shifted by a constant amount from 1 to 3 will get folded into x86_64's addressing modes which perform shifts. For example `(i32.load (i32.shl (local.get 0) (i32.const 3)))` loads from the WebAssembly address `$local0 << 3`. When translated to Cranelift the `$local0 << 3` computation, a 32-bit value, is zero-extended to a 64-bit value and then added to the base address of linear memory. Cranelift would generate an instruction of the form `movl (%base, %local0, 8), %dst` which calculates `%base + %local0 << 3`. The bug here, however, is that the address computation happens with 64-bit values, where the `$local0 << 3` computation was supposed to be truncated to a a 32-bit value. This means that `%local0`, which can use up to 32-bits for an address, gets 3 extra bits of address space to be accessible via this `movl` instruction. The fix in Cranelift is to remove the erroneous lowering rules in the backend which handle these zero-extended expression. The above example is then translated to `movl %local0, %temp; shl $3, %temp; movl (%base, %temp), %dst` which correctly truncates the intermediate computation of `%local0 << 3` to 32-bits inside the `%temp` register which is then added to the `%base` value. Wasmtime version 4.0.1, 5.0.1, and 6.0.1 have been released and have all been patched to no longer contain the erroneous lowering rules. While updating Wasmtime is recommended, there are a number of possible workarounds that embedders can employ to mitigate this issue if updating is not possible. Note that none of these workarounds are on-by-default and require explicit configuration: 1. The `Config::static_memory_maximum_size(0)` option can be used to force all accesses to linear memory to be explicitly bounds-checked. This will perform a bounds check separately from the address-mode computation which correctly calculates the effective address of a load/store. Note that this can have a large impact on the execution performance of WebAssembly modules. 2. The `Config::static_memory_guard_size(1 << 36)` option can be used to greatly increase the guard pages placed after linear memory. This will guarantee that memory accesses up-to-34G away are guaranteed to be semantically correct by reserving unmapped memory for the instance. Note that this reserves a very large amount of virtual memory per-instances and can greatly reduce the maximum number of concurrent instances being run. 3. If using a non-x86_64 host is possible, then that will also work around this bug. This bug does not affect Wasmtime's or Cranelift's AArch64 backend, for example.", "other": {"cve": {"id": "CVE-2023-26489", "sourceIdentifier": "security-advisories@github.com", "published": "2023-03-08T20:15:09.583", "lastModified": "2023-03-15T18:32:29.833", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "wasmtime is a fast and secure runtime for WebAssembly. In affected versions wasmtime's code generator, Cranelift, has a bug on x86_64 targets where address-mode computation mistakenly would calculate a 35-bit effective address instead of WebAssembly's defined 33-bit effective address. This bug means that, with default codegen settings, a wasm-controlled load/store operation could read/write addresses up to 35 bits away from the base of linear memory. Due to this bug, however, addresses up to `0xffffffff * 8 + 0x7ffffffc = 36507222004 = ~34G` bytes away from the base of linear memory are possible from guest code. This means that the virtual memory 6G away from the base of linear memory up to ~34G away can be read/written by a malicious module. A guest module can, without the knowledge of the embedder, read/write memory in this region. The memory may belong to other WebAssembly instances when using the pooling allocator, for example. Affected embedders are recommended to analyze preexisting wasm modules to see if they're affected by the incorrect codegen rules and possibly correlate that with an anomalous number of traps during historical execution to locate possibly suspicious modules. The specific bug in Cranelift's x86_64 backend is that a WebAssembly address which is left-shifted by a constant amount from 1 to 3 will get folded into x86_64's addressing modes which perform shifts. For example `(i32.load (i32.shl (local.get 0) (i32.const 3)))` loads from the WebAssembly address `$local0 << 3`. When translated to Cranelift the `$local0 << 3` computation, a 32-bit value, is zero-extended to a 64-bit value and then added to the base address of linear memory. Cranelift would generate an instruction of the form `movl (%base, %local0, 8), %dst` which calculates `%base + %local0 << 3`. The bug here, however, is that the address computation happens with 64-bit values, where the `$local0 << 3` computation was supposed to be truncated to a a 32-bit value. This means that `%local0`, which can use up to 32-bits for an address, gets 3 extra bits of address space to be accessible via this `movl` instruction. The fix in Cranelift is to remove the erroneous lowering rules in the backend which handle these zero-extended expression. The above example is then translated to `movl %local0, %temp; shl $3, %temp; movl (%base, %temp), %dst` which correctly truncates the intermediate computation of `%local0 << 3` to 32-bits inside the `%temp` register which is then added to the `%base` value. Wasmtime version 4.0.1, 5.0.1, and 6.0.1 have been released and have all been patched to no longer contain the erroneous lowering rules. While updating Wasmtime is recommended, there are a number of possible workarounds that embedders can employ to mitigate this issue if updating is not possible. Note that none of these workarounds are on-by-default and require explicit configuration: 1. The `Config::static_memory_maximum_size(0)` option can be used to force all accesses to linear memory to be explicitly bounds-checked. This will perform a bounds check separately from the address-mode computation which correctly calculates the effective address of a load/store. Note that this can have a large impact on the execution performance of WebAssembly modules. 2. The `Config::static_memory_guard_size(1 << 36)` option can be used to greatly increase the guard pages placed after linear memory. This will guarantee that memory accesses up-to-34G away are guaranteed to be semantically correct by reserving unmapped memory for the instance. Note that this reserves a very large amount of virtual memory per-instances and can greatly reduce the maximum number of concurrent instances being run. 3. If using a non-x86_64 host is possible, then that will also work around this bug. This bug does not affect Wasmtime's or Cranelift's AArch64 backend, for example."}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:C/C:H/I:H/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "CHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "HIGH", "availabilityImpact": "HIGH", "baseScore": 9.9, "baseSeverity": "CRITICAL"}, "exploitabilityScore": 3.1, "impactScore": 6.0}, {"source": "security-advisories@github.com", "type": "Secondary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:C/C:H/I:H/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "CHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "HIGH", "availabilityImpact": "HIGH", "baseScore": 9.9, "baseSeverity": "CRITICAL"}, "exploitabilityScore": 3.1, "impactScore": 6.0}]}, "weaknesses": [{"source": "security-advisories@github.com", "type": "Primary", "description": [{"lang": "en", "value": "CWE-125"}, {"lang": "en", "value": "CWE-787"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:bytecodealliance:cranelift-codegen:*:*:*:*:*:rust:*:*", "versionStartIncluding": "0.84.0", "versionEndExcluding": "0.91.1", "matchCriteriaId": "DBCFE132-FEDA-4A43-AE02-08E150E411D7"}, {"vulnerable": true, "criteria": "cpe:2.3:a:bytecodealliance:cranelift-codegen:0.92.0:*:*:*:*:rust:*:*", "matchCriteriaId": "7D7B0DE4-0071-4056-A243-D0BB71963F93"}, {"vulnerable": true, "criteria": "cpe:2.3:a:bytecodealliance:cranelift-codegen:0.93.0:*:*:*:*:rust:*:*", "matchCriteriaId": "0EC7D2FC-6423-45AE-8F82-A37F93C17285"}, {"vulnerable": true, "criteria": "cpe:2.3:a:bytecodealliance:wasmtime:*:*:*:*:*:rust:*:*", "versionStartIncluding": "0.37.0", "versionEndExcluding": "4.0.1", "matchCriteriaId": "DD965E87-91DE-4FD2-8AED-37274050D01F"}, {"vulnerable": true, "criteria": "cpe:2.3:a:bytecodealliance:wasmtime:5.0.0:*:*:*:*:rust:*:*", "matchCriteriaId": "87B4AC93-F648-4E7B-9FC7-53D885110E35"}, {"vulnerable": true, "criteria": "cpe:2.3:a:bytecodealliance:wasmtime:6.0.0:*:*:*:*:rust:*:*", "matchCriteriaId": "A21E7233-1DAD-449F-A48F-05BE3DE8E2E0"}]}]}], "references": [{"url": "https://docs.rs/wasmtime/latest/wasmtime/struct.Config.html#method.static_memory_guard_size", "source": "security-advisories@github.com", "tags": ["Product"]}, {"url": "https://docs.rs/wasmtime/latest/wasmtime/struct.Config.html#method.static_memory_maximum_size", "source": "security-advisories@github.com", "tags": ["Product"]}, {"url": "https://github.com/bytecodealliance/wasmtime/commit/63fb30e4b4415455d47b3da5a19d79c12f4f2d1f", "source": "security-advisories@github.com", "tags": ["Patch"]}, {"url": "https://github.com/bytecodealliance/wasmtime/security/advisories/GHSA-ff4p-7xrq-q5r8", "source": "security-advisories@github.com", "tags": ["Mitigation", "Patch", "Vendor Advisory"]}, {"url": "https://groups.google.com/a/bytecodealliance.org/g/sec-announce/c/Mov-ItrNJsQ", "source": "security-advisories@github.com", "tags": ["Mailing List", "Release Notes", "Vendor Advisory"]}]}, "github_commit_url": "https://github.com/bytecodealliance/wasmtime/commit/63fb30e4b4415455d47b3da5a19d79c12f4f2d1f"}}
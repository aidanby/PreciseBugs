{"buggy_code": ["1.3.1 (2019-08-27)\n------------------\n\nBugfixes\n~~~~~~~~\n\n- Waitress won't accidentally throw away part of the path if it starts with a\n  double slash (``GET //testing/whatever HTTP/1.0``). WSGI applications will\n  now receive a ``PATH_INFO`` in the environment that contains\n  ``//testing/whatever`` as required. See\n  https://github.com/Pylons/waitress/issues/260 and\n  https://github.com/Pylons/waitress/pull/261\n\n\n1.3.0 (2019-04-22)\n------------------\n\nDeprecations\n~~~~~~~~~~~~\n\n- The ``send_bytes`` adjustment now defaults to ``1`` and is deprecated\n  pending removal in a future release.\n  and https://github.com/Pylons/waitress/pull/246\n\nFeatures\n~~~~~~~~\n\n- Add a new ``outbuf_high_watermark`` adjustment which is used to apply\n  backpressure on the ``app_iter`` to avoid letting it spin faster than data\n  can be written to the socket. This stabilizes responses that iterate quickly\n  with a lot of data.\n  See https://github.com/Pylons/waitress/pull/242\n\n- Stop early and close the ``app_iter`` when attempting to write to a closed\n  socket due to a client disconnect. This should notify a long-lived streaming\n  response when a client hangs up.\n  See https://github.com/Pylons/waitress/pull/238\n  and https://github.com/Pylons/waitress/pull/240\n  and https://github.com/Pylons/waitress/pull/241\n\n- Adjust the flush to output ``SO_SNDBUF`` bytes instead of whatever was\n  set in the ``send_bytes`` adjustment. ``send_bytes`` now only controls how\n  much waitress will buffer internally before flushing to the kernel, whereas\n  previously it used to also throttle how much data was sent to the kernel.\n  This change enables a streaming ``app_iter`` containing small chunks to\n  still be flushed efficiently.\n  See https://github.com/Pylons/waitress/pull/246\n\nBugfixes\n~~~~~~~~\n\n- Upon receiving a request that does not include HTTP/1.0 or HTTP/1.1 we will\n  no longer set the version to the string value \"None\". See\n  https://github.com/Pylons/waitress/pull/252 and\n  https://github.com/Pylons/waitress/issues/110\n\n- When a client closes a socket unexpectedly there was potential for memory\n  leaks in which data was written to the buffers after they were closed,\n  causing them to reopen.\n  See https://github.com/Pylons/waitress/pull/239\n\n- Fix the queue depth warnings to only show when all threads are busy.\n  See https://github.com/Pylons/waitress/pull/243\n  and https://github.com/Pylons/waitress/pull/247\n\n- Trigger the ``app_iter`` to close as part of shutdown. This will only be\n  noticeable for users of the internal server api. In more typical operations\n  the server will die before benefiting from these changes.\n  See https://github.com/Pylons/waitress/pull/245\n\n- Fix a bug in which a streaming ``app_iter`` may never cleanup data that has\n  already been sent. This would cause buffers in waitress to grow without\n  bounds. These buffers now properly rotate and release their data.\n  See https://github.com/Pylons/waitress/pull/242\n\n- Fix a bug in which non-seekable subclasses of ``io.IOBase`` would trigger\n  an exception when passed to the ``wsgi.file_wrapper`` callback.\n  See https://github.com/Pylons/waitress/pull/249\n", "1.2.1 (2019-01-25)\n------------------\n\nBugfixes\n~~~~~~~~\n\n- When given an IPv6 address in ``X-Forwarded-For`` or ``Forwarded for=``\n  waitress was placing the IP address in ``REMOTE_ADDR`` with brackets:\n  ``[2001:db8::0]``, this does not match the requirements in the CGI spec which\n  ``REMOTE_ADDR`` was lifted from. Waitress will now place the bare IPv6\n  address in ``REMOTE_ADDR``: ``2001:db8::0``. See\n  https://github.com/Pylons/waitress/pull/232 and\n  https://github.com/Pylons/waitress/issues/230\n\n1.2.0 (2019-01-15)\n------------------\n\nNo changes since the last beta release. Enjoy Waitress!\n\n1.2.0b3 (2019-01-07)\n--------------------\n\nBugfixes\n~~~~~~~~\n\n- Modified ``clear_untrusted_proxy_headers`` to be usable without a\n  ``trusted_proxy``.\n  https://github.com/Pylons/waitress/pull/228\n\n- Modified ``trusted_proxy_count`` to error when used without a\n  ``trusted_proxy``.\n  https://github.com/Pylons/waitress/pull/228\n\n1.2.0b2 (2019-02-02)\n--------------------\n\nBugfixes\n~~~~~~~~\n\n- Fixed logic to no longer warn on writes where the output is required to have\n  a body but there may not be any data to be written. Solves issue posted on\n  the Pylons Project mailing list with 1.2.0b1.\n\n1.2.0b1 (2018-12-31)\n--------------------\n\nHappy New Year!\n\nFeatures\n~~~~~~~~\n\n- Setting the ``trusted_proxy`` setting to ``'*'`` (wildcard) will allow all\n  upstreams to be considered trusted proxies, thereby allowing services behind\n  Cloudflare/ELBs to function correctly whereby there may not be a singular IP\n  address that requests are received from.\n\n  Using this setting is potentially dangerous if your server is also available\n  from anywhere on the internet, and further protections should be used to lock\n  down access to Waitress. See https://github.com/Pylons/waitress/pull/224\n\n- Waitress has increased its support of the X-Forwarded-* headers and includes\n  Forwarded (RFC7239) support. This may be used to allow proxy servers to\n  influence the WSGI environment. See\n  https://github.com/Pylons/waitress/pull/209\n\n  This also provides a new security feature when using Waitress behind a proxy\n  in that it is possible to remove untrusted proxy headers thereby making sure\n  that downstream WSGI applications don't accidentally use those proxy headers\n  to make security decisions.\n\n  The documentation has more information, see the following new arguments:\n\n  - trusted_proxy_count\n  - trusted_proxy_headers\n  - clear_untrusted_proxy_headers\n  - log_untrusted_proxy_headers (useful for debugging)\n\n  Be aware that the defaults for these are currently backwards compatible with\n  older versions of Waitress, this will change in a future release of waitress.\n  If you expect to need this behaviour please explicitly set these variables in\n  your configuration, or pin this version of waitress.\n\n  Documentation:\n  https://docs.pylonsproject.org/projects/waitress/en/latest/reverse-proxy.html\n\n- Waitress can now accept a list of sockets that are already pre-bound rather\n  than creating its own to allow for socket activation. Support for init\n  systems/other systems that create said activated sockets is not included. See\n  https://github.com/Pylons/waitress/pull/215\n\n- Server header can be omitted by specifying ``ident=None`` or ``ident=''``.\n  See https://github.com/Pylons/waitress/pull/187\n\nBugfixes\n~~~~~~~~\n\n- Waitress will no longer send Transfer-Encoding or Content-Length for 1xx,\n  204, or 304 responses, and will completely ignore any message body sent by\n  the WSGI application, making sure to follow the HTTP standard. See\n  https://github.com/Pylons/waitress/pull/166,\n  https://github.com/Pylons/waitress/issues/165,\n  https://github.com/Pylons/waitress/issues/152, and\n  https://github.com/Pylons/waitress/pull/202\n\nCompatibility\n~~~~~~~~~~~~~\n\n- Waitress has now \"vendored\" asyncore into itself as ``waitress.wasyncore``.\n  This is to cope with the eventuality that asyncore will be removed from\n  the Python standard library in 3.8 or so.\n\nDocumentation\n~~~~~~~~~~~~~\n\n- Bring in documentation of paste.translogger from Pyramid. Reorganize and\n  clean up documentation. See\n  https://github.com/Pylons/waitress/pull/205\n  https://github.com/Pylons/waitress/pull/70\n  https://github.com/Pylons/waitress/pull/206\n\n1.1.0 (2017-10-10)\n------------------\n\nFeatures\n~~~~~~~~\n\n- Waitress now has a __main__ and thus may be called with ``python -mwaitress``\n\nBugfixes\n~~~~~~~~\n\n- Waitress no longer allows lowercase HTTP verbs. This change was made to fall\n  in line with most HTTP servers. See https://github.com/Pylons/waitress/pull/170\n\n- When receiving non-ascii bytes in the request URL, waitress will no longer\n  abruptly close the connection, instead returning a 400 Bad Request. See\n  https://github.com/Pylons/waitress/pull/162 and\n  https://github.com/Pylons/waitress/issues/64\n\n1.0.2 (2017-02-04)\n------------------\n\nFeatures\n~~~~~~~~\n\n- Python 3.6 is now officially supported in Waitress\n\nBugfixes\n~~~~~~~~\n\n- Add a work-around for libc issue on Linux not following the documented\n  standards. If getnameinfo() fails because of DNS not being available it\n  should return the IP address instead of the reverse DNS entry, however\n  instead getnameinfo() raises. We catch this, and ask getnameinfo()\n  for the same information again, explicitly asking for IP address instead of\n  reverse DNS hostname. See https://github.com/Pylons/waitress/issues/149 and\n  https://github.com/Pylons/waitress/pull/153\n\n1.0.1 (2016-10-22)\n------------------\n\nBugfixes\n~~~~~~~~\n\n- IPv6 support on Windows was broken due to missing constants in the socket\n  module. This has been resolved by setting the constants on Windows if they\n  are missing. See https://github.com/Pylons/waitress/issues/138\n\n- A ValueError was raised on Windows when passing a string for the port, on\n  Windows in Python 2 using service names instead of port numbers doesn't work\n  with `getaddrinfo`. This has been resolved by attempting to convert the port\n  number to an integer, if that fails a ValueError will be raised. See\n  https://github.com/Pylons/waitress/issues/139\n\n\n1.0.0 (2016-08-31)\n------------------\n\nBugfixes\n~~~~~~~~\n\n- Removed `AI_ADDRCONFIG` from the call to `getaddrinfo`, this resolves an\n  issue whereby `getaddrinfo` wouldn't return any addresses to `bind` to on\n  hosts where there is no internet connection but localhost is requested to be\n  bound to. See https://github.com/Pylons/waitress/issues/131 for more\n  information.\n\nDeprecations\n~~~~~~~~~~~~\n\n- Python 2.6 is no longer supported.\n\nFeatures\n~~~~~~~~\n\n- IPv6 support\n\n- Waitress is now able to listen on multiple sockets, including IPv4 and IPv6.\n  Instead of passing in a host/port combination you now provide waitress with a\n  space delineated list, and it will create as many sockets as required.\n\n  .. code-block:: python\n\n\tfrom waitress import serve\n\tserve(wsgiapp, listen='0.0.0.0:8080 [::]:9090 *:6543')\n\nSecurity\n~~~~~~~~\n\n- Waitress will now drop HTTP headers that contain an underscore in the key\n  when received from a client. This is to stop any possible underscore/dash\n  conflation that may lead to security issues. See\n  https://github.com/Pylons/waitress/pull/80 and\n  https://www.djangoproject.com/weblog/2015/jan/13/security/\n\n0.9.0 (2016-04-15)\n------------------\n\nDeprecations\n~~~~~~~~~~~~\n\n- Python 3.2 is no longer supported by Waitress.\n\n- Python 2.6 will no longer be supported by Waitress in future releases.\n\nSecurity/Protections\n~~~~~~~~~~~~~~~~~~~~\n\n- Building on the changes made in pull request 117, add in checking for line\n  feed/carriage return HTTP Response Splitting in the status line, as well as\n  the key of a header. See https://github.com/Pylons/waitress/pull/124 and\n  https://github.com/Pylons/waitress/issues/122.\n\n- Waitress will no longer accept headers or status lines with\n  newline/carriage returns in them, thereby disallowing HTTP Response\n  Splitting. See https://github.com/Pylons/waitress/issues/117 for\n  more information, as well as\n  https://www.owasp.org/index.php/HTTP_Response_Splitting.\n\nBugfixes\n~~~~~~~~\n\n- FileBasedBuffer and more important ReadOnlyFileBasedBuffer no longer report\n  False when tested with bool(), instead always returning True, and becoming\n  more iterator like.\n  See: https://github.com/Pylons/waitress/pull/82 and\n  https://github.com/Pylons/waitress/issues/76\n\n- Call prune() on the output buffer at the end of a request so that it doesn't\n  continue to grow without bounds. See\n  https://github.com/Pylons/waitress/issues/111 for more information.\n\n0.8.10 (2015-09-02)\n-------------------\n\n- Add support for Python 3.4, 3.5b2, and PyPy3.\n\n- Use a nonglobal asyncore socket map by default, trying to prevent conflicts\n  with apps and libs that use the asyncore global socket map ala\n  https://github.com/Pylons/waitress/issues/63.  You can get the old\n  use-global-socket-map behavior back by passing ``asyncore.socket_map`` to the\n  ``create_server`` function as the ``map`` argument.\n\n- Waitress violated PEP 3333 with respect to reraising an exception when\n  ``start_response`` was called with an ``exc_info`` argument.  It would\n  reraise the exception even if no data had been sent to the client.  It now\n  only reraises the exception if data has actually been sent to the client.\n  See https://github.com/Pylons/waitress/pull/52 and\n  https://github.com/Pylons/waitress/issues/51\n\n- Add a ``docs`` section to tox.ini that, when run, ensures docs can be built.\n\n- If an ``application`` value of ``None`` is supplied to the ``create_server``\n  constructor function, a ValueError is now raised eagerly instead of an error\n  occuring during runtime.  See https://github.com/Pylons/waitress/pull/60\n\n- Fix parsing of multi-line (folded) headers.\n  See https://github.com/Pylons/waitress/issues/53 and\n  https://github.com/Pylons/waitress/pull/90\n\n- Switch from the low level Python thread/_thread module to the threading\n  module.\n\n- Improved exception information should module import go awry.\n\n0.8.9 (2014-05-16)\n------------------\n\n- Fix tests under Windows.  NB: to run tests under Windows, you cannot run\n  \"setup.py test\" or \"setup.py nosetests\".  Instead you must run ``python.exe\n  -c \"import nose; nose.main()\"``.  If you try to run the tests using the\n  normal method under Windows, each subprocess created by the test suite will\n  attempt to run the test suite again.  See\n  https://github.com/nose-devs/nose/issues/407 for more information.\n\n- Give the WSGI app_iter generated when ``wsgi.file_wrapper`` is used\n  (ReadOnlyFileBasedBuffer) a ``close`` method.  Do not call ``close`` on an\n  instance of such a class when it's used as a WSGI app_iter, however.  This is\n  part of a fix which prevents a leakage of file descriptors; the other part of\n  the fix was in WebOb\n  (https://github.com/Pylons/webob/commit/951a41ce57bd853947f842028bccb500bd5237da).\n\n- Allow trusted proxies to override ``wsgi.url_scheme`` via a request header,\n  ``X_FORWARDED_PROTO``.  Allows proxies which serve mixed HTTP / HTTPS\n  requests to control signal which are served as HTTPS.  See\n  https://github.com/Pylons/waitress/pull/42.\n\n0.8.8 (2013-11-30)\n------------------\n\n- Fix some cases where the creation of extremely large output buffers (greater\n  than 2GB, suspected to be buffers added via ``wsgi.file_wrapper``) might\n  cause an OverflowError on Python 2.  See\n  https://github.com/Pylons/waitress/issues/47.\n\n- When the ``url_prefix`` adjustment starts with more than one slash, all\n  slashes except one will be stripped from its beginning.  This differs from\n  older behavior where more than one leading slash would be preserved in\n  ``url_prefix``.\n\n- If a client somehow manages to send an empty path, we no longer convert the\n  empty path to a single slash in ``PATH_INFO``.  Instead, the path remains\n  empty.  According to RFC 2616 section \"5.1.2 Request-URI\", the scenario of a\n  client sending an empty path is actually not possible because the request URI\n  portion cannot be empty.\n\n- If the ``url_prefix`` adjustment matches the request path exactly, we now\n  compute ``SCRIPT_NAME`` and ``PATH_INFO`` properly.  Previously, if the\n  ``url_prefix`` was ``/foo`` and the path received from a client was ``/foo``,\n  we would set *both* ``SCRIPT_NAME`` and ``PATH_INFO`` to ``/foo``.  This was\n  incorrect.  Now in such a case we set ``PATH_INFO`` to the empty string and\n  we set ``SCRIPT_NAME`` to ``/foo``.  Note that the change we made has no\n  effect on paths that do not match the ``url_prefix`` exactly (such as\n  ``/foo/bar``); these continue to operate as they did.  See\n  https://github.com/Pylons/waitress/issues/46\n\n- Preserve header ordering of headers with the same name as per RFC 2616.  See\n  https://github.com/Pylons/waitress/pull/44\n\n- When waitress receives a ``Transfer-Encoding: chunked`` request, we no longer\n  send the ``TRANSFER_ENCODING`` nor the ``HTTP_TRANSFER_ENCODING`` value to\n  the application in the environment.  Instead, we pop this header.  Since we\n  cope with chunked requests by buffering the data in the server, we also know\n  when a chunked request has ended, and therefore we know the content length.\n  We set the content-length header in the environment, such that applications\n  effectively never know the original request was a T-E: chunked request; it\n  will appear to them as if the request is a non-chunked request with an\n  accurate content-length.\n\n- Cope with the fact that the ``Transfer-Encoding`` value is case-insensitive.\n\n- When the ``--unix-socket-perms`` option was used as an argument to\n  ``waitress-serve``, a ``TypeError`` would be raised.  See\n  https://github.com/Pylons/waitress/issues/50.\n\n0.8.7 (2013-08-29)\n------------------\n\n- The HTTP version of the response returned by waitress when it catches an\n  exception will now match the HTTP request version.\n\n- Fix: CONNECTION header will be HTTP_CONNECTION and not CONNECTION_TYPE\n  (see https://github.com/Pylons/waitress/issues/13)\n\n0.8.6 (2013-08-12)\n------------------\n\n- Do alternate type of checking for UNIX socket support, instead of checking\n  for platform == windows.\n\n- Functional tests now use multiprocessing module instead of subprocess module,\n  speeding up test suite and making concurrent execution more reliable.\n\n- Runner now appends the current working directory to ``sys.path`` to support\n  running WSGI applications from a directory (i.e., not installed in a\n  virtualenv).\n\n- Add a ``url_prefix`` adjustment setting.  You can use it by passing\n  ``script_name='/foo'`` to ``waitress.serve`` or you can use it in a\n  ``PasteDeploy`` ini file as ``script_name = /foo``.  This will cause the WSGI\n  ``SCRIPT_NAME`` value to be the value passed minus any trailing slashes you\n  add, and it will cause the ``PATH_INFO`` of any request which is prefixed\n  with this value to be stripped of the prefix.  You can use this instead of\n  PasteDeploy's ``prefixmiddleware`` to always prefix the path.\n\n0.8.5 (2013-05-27)\n------------------\n\n- Fix runner multisegment imports in some Python 2 revisions (see\n  https://github.com/Pylons/waitress/pull/34).\n\n- For compatibility, WSGIServer is now an alias of TcpWSGIServer. The\n  signature of BaseWSGIServer is now compatible with WSGIServer pre-0.8.4.\n\n0.8.4 (2013-05-24)\n------------------\n\n- Add a command-line runner called ``waitress-serve`` to allow Waitress\n  to run WSGI applications without any addional machinery. This is\n  essentially a thin wrapper around the ``waitress.serve()`` function.\n\n- Allow parallel testing (e.g., under ``detox`` or ``nosetests --processes``)\n  using PID-dependent port / socket for functest servers.\n\n- Fix integer overflow errors on large buffers. Thanks to Marcin Kuzminski\n  for the patch.  See: https://github.com/Pylons/waitress/issues/22\n\n- Add support for listening on Unix domain sockets.\n\n0.8.3 (2013-04-28)\n------------------\n\nFeatures\n~~~~~~~~\n\n- Add an ``asyncore_loop_timeout`` adjustment value, which controls the\n  ``timeout`` value passed to ``asyncore.loop``; defaults to 1.\n\nBug Fixes\n~~~~~~~~~\n\n- The default asyncore loop timeout is now 1 second.  This prevents slow\n  shutdown on Windows.  See https://github.com/Pylons/waitress/issues/6 .  This\n  shouldn't matter to anyone in particular, but it can be changed via the\n  ``asyncore_loop_timeout`` adjustment (it used to previously default to 30\n  seconds).\n\n- Don't complain if there's a response to a HEAD request that contains a\n  Content-Length > 0.  See https://github.com/Pylons/waitress/pull/7.\n\n- Fix bug in HTTP Expect/Continue support.  See\n  https://github.com/Pylons/waitress/issues/9 .\n\n\n0.8.2 (2012-11-14)\n------------------\n\nBug Fixes\n~~~~~~~~~\n\n- https://corte.si/posts/code/pathod/pythonservers/index.html pointed out that\n  sending a bad header resulted in an exception leading to a 500 response\n  instead of the more proper 400 response without an exception.\n\n- Fix a race condition in the test suite.\n\n- Allow \"ident\" to be used as a keyword to ``serve()`` as per docs.\n\n- Add py33 to tox.ini.\n\n0.8.1 (2012-02-13)\n------------------\n\nBug Fixes\n~~~~~~~~~\n\n- A brown-bag bug prevented request concurrency.  A slow request would block\n  subsequent the responses of subsequent requests until the slow request's\n  response was fully generated.  This was due to a \"task lock\" being declared\n  as a class attribute rather than as an instance attribute on HTTPChannel.\n  Also took the opportunity to move another lock named \"outbuf lock\" to the\n  channel instance rather than the class.  See\n  https://github.com/Pylons/waitress/pull/1 .\n\n0.8 (2012-01-31)\n----------------\n\nFeatures\n~~~~~~~~\n\n- Support the WSGI ``wsgi.file_wrapper`` protocol as per\n  https://www.python.org/dev/peps/pep-0333/#optional-platform-specific-file-handling.\n  Here's a usage example::\n\n    import os\n\n    here = os.path.dirname(os.path.abspath(__file__))\n\n    def myapp(environ, start_response):\n        f = open(os.path.join(here, 'myphoto.jpg'), 'rb')\n        headers = [('Content-Type', 'image/jpeg')]\n        start_response(\n            '200 OK',\n            headers\n            )\n        return environ['wsgi.file_wrapper'](f, 32768)\n\n  The signature of the file wrapper constructor is ``(filelike_object,\n  block_size)``.  Both arguments must be passed as positional (not keyword)\n  arguments.  The result of creating a file wrapper should be **returned** as\n  the ``app_iter`` from a WSGI application.\n\n  The object passed as ``filelike_object`` to the wrapper must be a file-like\n  object which supports *at least* the ``read()`` method, and the ``read()``\n  method must support an optional size hint argument.  It *should* support\n  the ``seek()`` and ``tell()`` methods.  If it does not, normal iteration\n  over the filelike object using the provided block_size is used (and copying\n  is done, negating any benefit of the file wrapper).  It *should* support a\n  ``close()`` method.\n\n  The specified ``block_size`` argument to the file wrapper constructor will\n  be used only when the ``filelike_object`` doesn't support ``seek`` and/or\n  ``tell`` methods.  Waitress needs to use normal iteration to serve the file\n  in this degenerate case (as per the WSGI spec), and this block size will be\n  used as the iteration chunk size.  The ``block_size`` argument is optional;\n  if it is not passed, a default value``32768`` is used.\n\n  Waitress will set a ``Content-Length`` header on the behalf of an\n  application when a file wrapper with a sufficiently filelike object is used\n  if the application hasn't already set one.\n\n  The machinery which handles a file wrapper currently doesn't do anything\n  particularly special using fancy system calls (it doesn't use ``sendfile``\n  for example); using it currently just prevents the system from needing to\n  copy data to a temporary buffer in order to send it to the client.  No\n  copying of data is done when a WSGI app returns a file wrapper that wraps a\n  sufficiently filelike object.  It may do something fancier in the future.\n\n0.7 (2012-01-11)\n----------------\n\nFeatures\n~~~~~~~~\n\n- Default ``send_bytes`` value is now 18000 instead of 9000.  The larger\n  default value prevents asyncore from needing to execute select so many\n  times to serve large files, speeding up file serving by about 15%-20% or\n  so.  This is probably only an optimization for LAN communications, and\n  could slow things down across a WAN (due to higher TCP overhead), but we're\n  likely to be behind a reverse proxy on a LAN anyway if in production.\n\n- Added an (undocumented) profiling feature to the ``serve()`` command.\n\n0.6.1 (2012-01-08)\n------------------\n\nBug Fixes\n~~~~~~~~~\n\n- Remove performance-sapping call to ``pull_trigger`` in the channel's\n  ``write_soon`` method added mistakenly in 0.6.\n\n0.6 (2012-01-07)\n----------------\n\nBug Fixes\n~~~~~~~~~\n\n- A logic error prevented the internal outbuf buffer of a channel from being\n  flushed when the client could not accept the entire contents of the output\n  buffer in a single succession of socket.send calls when the channel was in\n  a \"pending close\" state.  The socket in such a case would be closed\n  prematurely, sometimes resulting in partially delivered content.  This was\n  discovered by a user using waitress behind an Nginx reverse proxy, which\n  apparently is not always ready to receive data.  The symptom was that he\n  received \"half\" of a large CSS file (110K) while serving content via\n  waitress behind the proxy.\n\n0.5 (2012-01-03)\n----------------\n\nBug Fixes\n~~~~~~~~~\n\n- Fix PATH_INFO encoding/decoding on Python 3 (as per PEP 3333, tunnel\n  bytes-in-unicode-as-latin-1-after-unquoting).\n\n0.4 (2012-01-02)\n----------------\n\nFeatures\n~~~~~~~~\n\n- Added \"design\" document to docs.\n\nBug Fixes\n~~~~~~~~~\n\n- Set default ``connection_limit`` back to 100 for benefit of maximal\n  platform compatibility.\n\n- Normalize setting of ``last_activity`` during send.\n\n- Minor resource cleanups during tests.\n\n- Channel timeout cleanup was broken.\n\n0.3 (2012-01-02)\n----------------\n\nFeatures\n~~~~~~~~\n\n- Dont hang a thread up trying to send data to slow clients.\n\n- Use self.logger to log socket errors instead of self.log_info (normalize).\n\n- Remove pointless handle_error method from channel.\n\n- Queue requests instead of tasks in a channel.\n\nBug Fixes\n~~~~~~~~~\n\n- Expect: 100-continue responses were broken.\n\n\n0.2 (2011-12-31)\n----------------\n\nBug Fixes\n~~~~~~~~~\n\n- Set up logging by calling logging.basicConfig() when ``serve`` is called\n  (show tracebacks and other warnings to console by default).\n\n- Disallow WSGI applications to set \"hop-by-hop\" headers (Connection,\n  Transfer-Encoding, etc).\n\n- Don't treat 304 status responses specially in HTTP/1.1 mode.\n\n- Remove out of date ``interfaces.py`` file.\n\n- Normalize logging (all output is now sent to the ``waitress`` logger rather\n  than in degenerate cases some output being sent directly to stderr).\n\nFeatures\n~~~~~~~~\n\n- Support HTTP/1.1 ``Transfer-Encoding: chunked`` responses.\n\n- Slightly better docs about logging.\n\n0.1 (2011-12-30)\n----------------\n\n- Initial release.\n", "##############################################################################\n#\n# Copyright (c) 2006 Zope Foundation and Contributors.\n# All Rights Reserved.\n#\n# This software is subject to the provisions of the Zope Public License,\n# Version 2.1 (ZPL).  A copy of the ZPL should accompany this distribution.\n# THIS SOFTWARE IS PROVIDED \"AS IS\" AND ANY AND ALL EXPRESS OR IMPLIED\n# WARRANTIES ARE DISCLAIMED, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\n# WARRANTIES OF TITLE, MERCHANTABILITY, AGAINST INFRINGEMENT, AND FITNESS\n# FOR A PARTICULAR PURPOSE.\n#\n##############################################################################\nimport os\nfrom setuptools import setup, find_packages\n\nhere = os.path.abspath(os.path.dirname(__file__))\ntry:\n    README = open(os.path.join(here, \"README.rst\")).read()\n    CHANGES = open(os.path.join(here, \"CHANGES.txt\")).read()\nexcept IOError:\n    README = CHANGES = \"\"\n\ndocs_extras = [\n    \"Sphinx>=1.8.1\",\n    \"docutils\",\n    \"pylons-sphinx-themes>=1.0.9\",\n]\n\ntesting_extras = [\n    \"nose\",\n    \"coverage>=5.0\",\n]\n\nsetup(\n    name=\"waitress\",\n    version=\"1.3.1\",\n    author=\"Zope Foundation and Contributors\",\n    author_email=\"zope-dev@zope.org\",\n    maintainer=\"Pylons Project\",\n    maintainer_email=\"pylons-discuss@googlegroups.com\",\n    description=\"Waitress WSGI server\",\n    long_description=README + \"\\n\\n\" + CHANGES,\n    license=\"ZPL 2.1\",\n    keywords=\"waitress wsgi server http\",\n    classifiers=[\n        \"Development Status :: 5 - Production/Stable\",\n        \"Environment :: Web Environment\",\n        \"Intended Audience :: Developers\",\n        \"License :: OSI Approved :: Zope Public License\",\n        \"Programming Language :: Python\",\n        \"Programming Language :: Python :: 2\",\n        \"Programming Language :: Python :: 2.7\",\n        \"Programming Language :: Python :: 3\",\n        \"Programming Language :: Python :: 3.4\",\n        \"Programming Language :: Python :: 3.5\",\n        \"Programming Language :: Python :: 3.6\",\n        \"Programming Language :: Python :: 3.7\",\n        \"Programming Language :: Python :: Implementation :: CPython\",\n        \"Programming Language :: Python :: Implementation :: PyPy\",\n        \"Natural Language :: English\",\n        \"Operating System :: OS Independent\",\n        \"Topic :: Internet :: WWW/HTTP\",\n        \"Topic :: Internet :: WWW/HTTP :: WSGI\",\n    ],\n    url=\"https://github.com/Pylons/waitress\",\n    packages=find_packages(),\n    extras_require={\"testing\": testing_extras, \"docs\": docs_extras,},\n    include_package_data=True,\n    test_suite=\"waitress\",\n    zip_safe=False,\n    entry_points=\"\"\"\n    [paste.server_runner]\n    main = waitress:serve_paste\n    [console_scripts]\n    waitress-serve = waitress.runner:run\n    \"\"\",\n)\n", "##############################################################################\n#\n# Copyright (c) 2001, 2002 Zope Foundation and Contributors.\n# All Rights Reserved.\n#\n# This software is subject to the provisions of the Zope Public License,\n# Version 2.1 (ZPL).  A copy of the ZPL should accompany this distribution.\n# THIS SOFTWARE IS PROVIDED \"AS IS\" AND ANY AND ALL EXPRESS OR IMPLIED\n# WARRANTIES ARE DISCLAIMED, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\n# WARRANTIES OF TITLE, MERCHANTABILITY, AGAINST INFRINGEMENT, AND FITNESS\n# FOR A PARTICULAR PURPOSE.\n#\n##############################################################################\n\"\"\"HTTP Request Parser\n\nThis server uses asyncore to accept connections and do initial\nprocessing but threads to do work.\n\"\"\"\nimport re\nfrom io import BytesIO\n\nfrom waitress.compat import (\n    tostr,\n    urlparse,\n    unquote_bytes_to_wsgi,\n)\n\nfrom waitress.buffers import OverflowableBuffer\n\nfrom waitress.receiver import (\n    FixedStreamReceiver,\n    ChunkedReceiver,\n)\n\nfrom waitress.utilities import (\n    find_double_newline,\n    RequestEntityTooLarge,\n    RequestHeaderFieldsTooLarge,\n    BadRequest,\n)\n\n\nclass ParsingError(Exception):\n    pass\n\n\nclass HTTPRequestParser(object):\n    \"\"\"A structure that collects the HTTP request.\n\n    Once the stream is completed, the instance is passed to\n    a server task constructor.\n    \"\"\"\n\n    completed = False  # Set once request is completed.\n    empty = False  # Set if no request was made.\n    expect_continue = False  # client sent \"Expect: 100-continue\" header\n    headers_finished = False  # True when headers have been read\n    header_plus = b\"\"\n    chunked = False\n    content_length = 0\n    header_bytes_received = 0\n    body_bytes_received = 0\n    body_rcv = None\n    version = \"1.0\"\n    error = None\n    connection_close = False\n\n    # Other attributes: first_line, header, headers, command, uri, version,\n    # path, query, fragment\n\n    def __init__(self, adj):\n        \"\"\"\n        adj is an Adjustments object.\n        \"\"\"\n        # headers is a mapping containing keys translated to uppercase\n        # with dashes turned into underscores.\n        self.headers = {}\n        self.adj = adj\n\n    def received(self, data):\n        \"\"\"\n        Receives the HTTP stream for one request.  Returns the number of\n        bytes consumed.  Sets the completed flag once both the header and the\n        body have been received.\n        \"\"\"\n        if self.completed:\n            return 0  # Can't consume any more.\n        datalen = len(data)\n        br = self.body_rcv\n        if br is None:\n            # In header.\n            s = self.header_plus + data\n            index = find_double_newline(s)\n            if index >= 0:\n                # Header finished.\n                header_plus = s[:index]\n                consumed = len(data) - (len(s) - index)\n                # Remove preceeding blank lines.\n                header_plus = header_plus.lstrip()\n                if not header_plus:\n                    self.empty = True\n                    self.completed = True\n                else:\n                    try:\n                        self.parse_header(header_plus)\n                    except ParsingError as e:\n                        self.error = BadRequest(e.args[0])\n                        self.completed = True\n                    else:\n                        if self.body_rcv is None:\n                            # no content-length header and not a t-e: chunked\n                            # request\n                            self.completed = True\n                        if self.content_length > 0:\n                            max_body = self.adj.max_request_body_size\n                            # we won't accept this request if the content-length\n                            # is too large\n                            if self.content_length >= max_body:\n                                self.error = RequestEntityTooLarge(\n                                    \"exceeds max_body of %s\" % max_body\n                                )\n                                self.completed = True\n                self.headers_finished = True\n                return consumed\n            else:\n                # Header not finished yet.\n                self.header_bytes_received += datalen\n                max_header = self.adj.max_request_header_size\n                if self.header_bytes_received >= max_header:\n                    # malformed header, we need to construct some request\n                    # on our own. we disregard the incoming(?) requests HTTP\n                    # version and just use 1.0. IOW someone just sent garbage\n                    # over the wire\n                    self.parse_header(b\"GET / HTTP/1.0\\n\")\n                    self.error = RequestHeaderFieldsTooLarge(\n                        \"exceeds max_header of %s\" % max_header\n                    )\n                    self.completed = True\n                self.header_plus = s\n                return datalen\n        else:\n            # In body.\n            consumed = br.received(data)\n            self.body_bytes_received += consumed\n            max_body = self.adj.max_request_body_size\n            if self.body_bytes_received >= max_body:\n                # this will only be raised during t-e: chunked requests\n                self.error = RequestEntityTooLarge(\"exceeds max_body of %s\" % max_body)\n                self.completed = True\n            elif br.error:\n                # garbage in chunked encoding input probably\n                self.error = br.error\n                self.completed = True\n            elif br.completed:\n                # The request (with the body) is ready to use.\n                self.completed = True\n                if self.chunked:\n                    # We've converted the chunked transfer encoding request\n                    # body into a normal request body, so we know its content\n                    # length; set the header here.  We already popped the\n                    # TRANSFER_ENCODING header in parse_header, so this will\n                    # appear to the client to be an entirely non-chunked HTTP\n                    # request with a valid content-length.\n                    self.headers[\"CONTENT_LENGTH\"] = str(br.__len__())\n            return consumed\n\n    def parse_header(self, header_plus):\n        \"\"\"\n        Parses the header_plus block of text (the headers plus the\n        first line of the request).\n        \"\"\"\n        index = header_plus.find(b\"\\n\")\n        if index >= 0:\n            first_line = header_plus[:index].rstrip()\n            header = header_plus[index + 1 :]\n        else:\n            first_line = header_plus.rstrip()\n            header = b\"\"\n\n        self.first_line = first_line  # for testing\n\n        lines = get_header_lines(header)\n\n        headers = self.headers\n        for line in lines:\n            index = line.find(b\":\")\n            if index > 0:\n                key = line[:index]\n                if b\"_\" in key:\n                    continue\n                value = line[index + 1 :].strip()\n                key1 = tostr(key.upper().replace(b\"-\", b\"_\"))\n                # If a header already exists, we append subsequent values\n                # seperated by a comma. Applications already need to handle\n                # the comma seperated values, as HTTP front ends might do\n                # the concatenation for you (behavior specified in RFC2616).\n                try:\n                    headers[key1] += tostr(b\", \" + value)\n                except KeyError:\n                    headers[key1] = tostr(value)\n            # else there's garbage in the headers?\n\n        # command, uri, version will be bytes\n        command, uri, version = crack_first_line(first_line)\n        version = tostr(version)\n        command = tostr(command)\n        self.command = command\n        self.version = version\n        (\n            self.proxy_scheme,\n            self.proxy_netloc,\n            self.path,\n            self.query,\n            self.fragment,\n        ) = split_uri(uri)\n        self.url_scheme = self.adj.url_scheme\n        connection = headers.get(\"CONNECTION\", \"\")\n\n        if version == \"1.0\":\n            if connection.lower() != \"keep-alive\":\n                self.connection_close = True\n\n        if version == \"1.1\":\n            # since the server buffers data from chunked transfers and clients\n            # never need to deal with chunked requests, downstream clients\n            # should not see the HTTP_TRANSFER_ENCODING header; we pop it\n            # here\n            te = headers.pop(\"TRANSFER_ENCODING\", \"\")\n            if te.lower() == \"chunked\":\n                self.chunked = True\n                buf = OverflowableBuffer(self.adj.inbuf_overflow)\n                self.body_rcv = ChunkedReceiver(buf)\n            expect = headers.get(\"EXPECT\", \"\").lower()\n            self.expect_continue = expect == \"100-continue\"\n            if connection.lower() == \"close\":\n                self.connection_close = True\n\n        if not self.chunked:\n            try:\n                cl = int(headers.get(\"CONTENT_LENGTH\", 0))\n            except ValueError:\n                cl = 0\n            self.content_length = cl\n            if cl > 0:\n                buf = OverflowableBuffer(self.adj.inbuf_overflow)\n                self.body_rcv = FixedStreamReceiver(cl, buf)\n\n    def get_body_stream(self):\n        body_rcv = self.body_rcv\n        if body_rcv is not None:\n            return body_rcv.getfile()\n        else:\n            return BytesIO()\n\n    def close(self):\n        body_rcv = self.body_rcv\n        if body_rcv is not None:\n            body_rcv.getbuf().close()\n\n\ndef split_uri(uri):\n    # urlsplit handles byte input by returning bytes on py3, so\n    # scheme, netloc, path, query, and fragment are bytes\n\n    scheme = netloc = path = query = fragment = b\"\"\n\n    # urlsplit below will treat this as a scheme-less netloc, thereby losing\n    # the original intent of the request. Here we shamelessly stole 4 lines of\n    # code from the CPython stdlib to parse out the fragment and query but\n    # leave the path alone. See\n    # https://github.com/python/cpython/blob/8c9e9b0cd5b24dfbf1424d1f253d02de80e8f5ef/Lib/urllib/parse.py#L465-L468\n    # and https://github.com/Pylons/waitress/issues/260\n\n    if uri[:2] == b\"//\":\n        path = uri\n\n        if b\"#\" in path:\n            path, fragment = path.split(b\"#\", 1)\n\n        if b\"?\" in path:\n            path, query = path.split(b\"?\", 1)\n    else:\n        try:\n            scheme, netloc, path, query, fragment = urlparse.urlsplit(uri)\n        except UnicodeError:\n            raise ParsingError(\"Bad URI\")\n\n    return (\n        tostr(scheme),\n        tostr(netloc),\n        unquote_bytes_to_wsgi(path),\n        tostr(query),\n        tostr(fragment),\n    )\n\n\ndef get_header_lines(header):\n    \"\"\"\n    Splits the header into lines, putting multi-line headers together.\n    \"\"\"\n    r = []\n    lines = header.split(b\"\\n\")\n    for line in lines:\n        if line.startswith((b\" \", b\"\\t\")):\n            if not r:\n                # https://corte.si/posts/code/pathod/pythonservers/index.html\n                raise ParsingError('Malformed header line \"%s\"' % tostr(line))\n            r[-1] += line\n        else:\n            r.append(line)\n    return r\n\n\nfirst_line_re = re.compile(\n    b\"([^ ]+) \"\n    b\"((?:[^ :?#]+://[^ ?#/]*(?:[0-9]{1,5})?)?[^ ]+)\"\n    b\"(( HTTP/([0-9.]+))$|$)\"\n)\n\n\ndef crack_first_line(line):\n    m = first_line_re.match(line)\n    if m is not None and m.end() == len(line):\n        if m.group(3):\n            version = m.group(5)\n        else:\n            version = b\"\"\n        method = m.group(1)\n\n        # the request methods that are currently defined are all uppercase:\n        # https://www.iana.org/assignments/http-methods/http-methods.xhtml and\n        # the request method is case sensitive according to\n        # https://tools.ietf.org/html/rfc7231#section-4.1\n\n        # By disallowing anything but uppercase methods we save poor\n        # unsuspecting souls from sending lowercase HTTP methods to waitress\n        # and having the request complete, while servers like nginx drop the\n        # request onto the floor.\n        if method != method.upper():\n            raise ParsingError('Malformed HTTP method \"%s\"' % tostr(method))\n        uri = m.group(2)\n        return method, uri, version\n    else:\n        return b\"\", b\"\", b\"\"\n", "##############################################################################\n#\n# Copyright (c) 2001, 2002 Zope Foundation and Contributors.\n# All Rights Reserved.\n#\n# This software is subject to the provisions of the Zope Public License,\n# Version 2.1 (ZPL).  A copy of the ZPL should accompany this distribution.\n# THIS SOFTWARE IS PROVIDED \"AS IS\" AND ANY AND ALL EXPRESS OR IMPLIED\n# WARRANTIES ARE DISCLAIMED, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\n# WARRANTIES OF TITLE, MERCHANTABILITY, AGAINST INFRINGEMENT, AND FITNESS\n# FOR A PARTICULAR PURPOSE.\n#\n##############################################################################\n\"\"\"Data Chunk Receiver\n\"\"\"\n\nfrom waitress.utilities import find_double_newline\n\nfrom waitress.utilities import BadRequest\n\n\nclass FixedStreamReceiver(object):\n\n    # See IStreamConsumer\n    completed = False\n    error = None\n\n    def __init__(self, cl, buf):\n        self.remain = cl\n        self.buf = buf\n\n    def __len__(self):\n        return self.buf.__len__()\n\n    def received(self, data):\n        \"See IStreamConsumer\"\n        rm = self.remain\n        if rm < 1:\n            self.completed = True  # Avoid any chance of spinning\n            return 0\n        datalen = len(data)\n        if rm <= datalen:\n            self.buf.append(data[:rm])\n            self.remain = 0\n            self.completed = True\n            return rm\n        else:\n            self.buf.append(data)\n            self.remain -= datalen\n            return datalen\n\n    def getfile(self):\n        return self.buf.getfile()\n\n    def getbuf(self):\n        return self.buf\n\n\nclass ChunkedReceiver(object):\n\n    chunk_remainder = 0\n    control_line = b\"\"\n    all_chunks_received = False\n    trailer = b\"\"\n    completed = False\n    error = None\n\n    # max_control_line = 1024\n    # max_trailer = 65536\n\n    def __init__(self, buf):\n        self.buf = buf\n\n    def __len__(self):\n        return self.buf.__len__()\n\n    def received(self, s):\n        # Returns the number of bytes consumed.\n        if self.completed:\n            return 0\n        orig_size = len(s)\n        while s:\n            rm = self.chunk_remainder\n            if rm > 0:\n                # Receive the remainder of a chunk.\n                to_write = s[:rm]\n                self.buf.append(to_write)\n                written = len(to_write)\n                s = s[written:]\n                self.chunk_remainder -= written\n            elif not self.all_chunks_received:\n                # Receive a control line.\n                s = self.control_line + s\n                pos = s.find(b\"\\n\")\n                if pos < 0:\n                    # Control line not finished.\n                    self.control_line = s\n                    s = \"\"\n                else:\n                    # Control line finished.\n                    line = s[:pos]\n                    s = s[pos + 1 :]\n                    self.control_line = b\"\"\n                    line = line.strip()\n                    if line:\n                        # Begin a new chunk.\n                        semi = line.find(b\";\")\n                        if semi >= 0:\n                            # discard extension info.\n                            line = line[:semi]\n                        try:\n                            sz = int(line.strip(), 16)  # hexadecimal\n                        except ValueError:  # garbage in input\n                            self.error = BadRequest(\"garbage in chunked encoding input\")\n                            sz = 0\n                        if sz > 0:\n                            # Start a new chunk.\n                            self.chunk_remainder = sz\n                        else:\n                            # Finished chunks.\n                            self.all_chunks_received = True\n                    # else expect a control line.\n            else:\n                # Receive the trailer.\n                trailer = self.trailer + s\n                if trailer.startswith(b\"\\r\\n\"):\n                    # No trailer.\n                    self.completed = True\n                    return orig_size - (len(trailer) - 2)\n                elif trailer.startswith(b\"\\n\"):\n                    # No trailer.\n                    self.completed = True\n                    return orig_size - (len(trailer) - 1)\n                pos = find_double_newline(trailer)\n                if pos < 0:\n                    # Trailer not finished.\n                    self.trailer = trailer\n                    s = b\"\"\n                else:\n                    # Finished the trailer.\n                    self.completed = True\n                    self.trailer = trailer[:pos]\n                    return orig_size - (len(trailer) - pos)\n        return orig_size\n\n    def getfile(self):\n        return self.buf.getfile()\n\n    def getbuf(self):\n        return self.buf\n", "##############################################################################\n#\n# Copyright (c) 2001, 2002 Zope Foundation and Contributors.\n# All Rights Reserved.\n#\n# This software is subject to the provisions of the Zope Public License,\n# Version 2.1 (ZPL).  A copy of the ZPL should accompany this distribution.\n# THIS SOFTWARE IS PROVIDED \"AS IS\" AND ANY AND ALL EXPRESS OR IMPLIED\n# WARRANTIES ARE DISCLAIMED, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\n# WARRANTIES OF TITLE, MERCHANTABILITY, AGAINST INFRINGEMENT, AND FITNESS\n# FOR A PARTICULAR PURPOSE.\n#\n##############################################################################\n\nimport socket\nimport sys\nimport threading\nimport time\nfrom collections import deque\n\nfrom .buffers import ReadOnlyFileBasedBuffer\nfrom .compat import reraise, tobytes\nfrom .utilities import build_http_date, logger, queue_logger\n\nrename_headers = {  # or keep them without the HTTP_ prefix added\n    \"CONTENT_LENGTH\": \"CONTENT_LENGTH\",\n    \"CONTENT_TYPE\": \"CONTENT_TYPE\",\n}\n\nhop_by_hop = frozenset(\n    (\n        \"connection\",\n        \"keep-alive\",\n        \"proxy-authenticate\",\n        \"proxy-authorization\",\n        \"te\",\n        \"trailers\",\n        \"transfer-encoding\",\n        \"upgrade\",\n    )\n)\n\n\nclass ThreadedTaskDispatcher(object):\n    \"\"\"A Task Dispatcher that creates a thread for each task.\n    \"\"\"\n\n    stop_count = 0  # Number of threads that will stop soon.\n    active_count = 0  # Number of currently active threads\n    logger = logger\n    queue_logger = queue_logger\n\n    def __init__(self):\n        self.threads = set()\n        self.queue = deque()\n        self.lock = threading.Lock()\n        self.queue_cv = threading.Condition(self.lock)\n        self.thread_exit_cv = threading.Condition(self.lock)\n\n    def start_new_thread(self, target, args):\n        t = threading.Thread(target=target, name=\"waitress\", args=args)\n        t.daemon = True\n        t.start()\n\n    def handler_thread(self, thread_no):\n        while True:\n            with self.lock:\n                while not self.queue and self.stop_count == 0:\n                    # Mark ourselves as idle before waiting to be\n                    # woken up, then we will once again be active\n                    self.active_count -= 1\n                    self.queue_cv.wait()\n                    self.active_count += 1\n\n                if self.stop_count > 0:\n                    self.active_count -= 1\n                    self.stop_count -= 1\n                    self.threads.discard(thread_no)\n                    self.thread_exit_cv.notify()\n                    break\n\n                task = self.queue.popleft()\n            try:\n                task.service()\n            except BaseException:\n                self.logger.exception(\"Exception when servicing %r\", task)\n\n    def set_thread_count(self, count):\n        with self.lock:\n            threads = self.threads\n            thread_no = 0\n            running = len(threads) - self.stop_count\n            while running < count:\n                # Start threads.\n                while thread_no in threads:\n                    thread_no = thread_no + 1\n                threads.add(thread_no)\n                running += 1\n                self.start_new_thread(self.handler_thread, (thread_no,))\n                self.active_count += 1\n                thread_no = thread_no + 1\n            if running > count:\n                # Stop threads.\n                self.stop_count += running - count\n                self.queue_cv.notify_all()\n\n    def add_task(self, task):\n        with self.lock:\n            self.queue.append(task)\n            self.queue_cv.notify()\n            queue_size = len(self.queue)\n            idle_threads = len(self.threads) - self.stop_count - self.active_count\n            if queue_size > idle_threads:\n                self.queue_logger.warning(\n                    \"Task queue depth is %d\", queue_size - idle_threads\n                )\n\n    def shutdown(self, cancel_pending=True, timeout=5):\n        self.set_thread_count(0)\n        # Ensure the threads shut down.\n        threads = self.threads\n        expiration = time.time() + timeout\n        with self.lock:\n            while threads:\n                if time.time() >= expiration:\n                    self.logger.warning(\"%d thread(s) still running\", len(threads))\n                    break\n                self.thread_exit_cv.wait(0.1)\n            if cancel_pending:\n                # Cancel remaining tasks.\n                queue = self.queue\n                if len(queue) > 0:\n                    self.logger.warning(\"Canceling %d pending task(s)\", len(queue))\n                while queue:\n                    task = queue.popleft()\n                    task.cancel()\n                self.queue_cv.notify_all()\n                return True\n        return False\n\n\nclass Task(object):\n    close_on_finish = False\n    status = \"200 OK\"\n    wrote_header = False\n    start_time = 0\n    content_length = None\n    content_bytes_written = 0\n    logged_write_excess = False\n    logged_write_no_body = False\n    complete = False\n    chunked_response = False\n    logger = logger\n\n    def __init__(self, channel, request):\n        self.channel = channel\n        self.request = request\n        self.response_headers = []\n        version = request.version\n        if version not in (\"1.0\", \"1.1\"):\n            # fall back to a version we support.\n            version = \"1.0\"\n        self.version = version\n\n    def service(self):\n        try:\n            try:\n                self.start()\n                self.execute()\n                self.finish()\n            except socket.error:\n                self.close_on_finish = True\n                if self.channel.adj.log_socket_errors:\n                    raise\n        finally:\n            pass\n\n    @property\n    def has_body(self):\n        return not (\n            self.status.startswith(\"1\")\n            or self.status.startswith(\"204\")\n            or self.status.startswith(\"304\")\n        )\n\n    def build_response_header(self):\n        version = self.version\n        # Figure out whether the connection should be closed.\n        connection = self.request.headers.get(\"CONNECTION\", \"\").lower()\n        response_headers = []\n        content_length_header = None\n        date_header = None\n        server_header = None\n        connection_close_header = None\n\n        for (headername, headerval) in self.response_headers:\n            headername = \"-\".join([x.capitalize() for x in headername.split(\"-\")])\n\n            if headername == \"Content-Length\":\n                if self.has_body:\n                    content_length_header = headerval\n                else:\n                    continue  # pragma: no cover\n\n            if headername == \"Date\":\n                date_header = headerval\n\n            if headername == \"Server\":\n                server_header = headerval\n\n            if headername == \"Connection\":\n                connection_close_header = headerval.lower()\n            # replace with properly capitalized version\n            response_headers.append((headername, headerval))\n\n        if (\n            content_length_header is None\n            and self.content_length is not None\n            and self.has_body\n        ):\n            content_length_header = str(self.content_length)\n            response_headers.append((\"Content-Length\", content_length_header))\n\n        def close_on_finish():\n            if connection_close_header is None:\n                response_headers.append((\"Connection\", \"close\"))\n            self.close_on_finish = True\n\n        if version == \"1.0\":\n            if connection == \"keep-alive\":\n                if not content_length_header:\n                    close_on_finish()\n                else:\n                    response_headers.append((\"Connection\", \"Keep-Alive\"))\n            else:\n                close_on_finish()\n\n        elif version == \"1.1\":\n            if connection == \"close\":\n                close_on_finish()\n\n            if not content_length_header:\n                # RFC 7230: MUST NOT send Transfer-Encoding or Content-Length\n                # for any response with a status code of 1xx, 204 or 304.\n\n                if self.has_body:\n                    response_headers.append((\"Transfer-Encoding\", \"chunked\"))\n                    self.chunked_response = True\n\n                if not self.close_on_finish:\n                    close_on_finish()\n\n            # under HTTP 1.1 keep-alive is default, no need to set the header\n        else:\n            raise AssertionError(\"neither HTTP/1.0 or HTTP/1.1\")\n\n        # Set the Server and Date field, if not yet specified. This is needed\n        # if the server is used as a proxy.\n        ident = self.channel.server.adj.ident\n\n        if not server_header:\n            if ident:\n                response_headers.append((\"Server\", ident))\n        else:\n            response_headers.append((\"Via\", ident or \"waitress\"))\n\n        if not date_header:\n            response_headers.append((\"Date\", build_http_date(self.start_time)))\n\n        self.response_headers = response_headers\n\n        first_line = \"HTTP/%s %s\" % (self.version, self.status)\n        # NB: sorting headers needs to preserve same-named-header order\n        # as per RFC 2616 section 4.2; thus the key=lambda x: x[0] here;\n        # rely on stable sort to keep relative position of same-named headers\n        next_lines = [\n            \"%s: %s\" % hv for hv in sorted(self.response_headers, key=lambda x: x[0])\n        ]\n        lines = [first_line] + next_lines\n        res = \"%s\\r\\n\\r\\n\" % \"\\r\\n\".join(lines)\n\n        return tobytes(res)\n\n    def remove_content_length_header(self):\n        response_headers = []\n\n        for header_name, header_value in self.response_headers:\n            if header_name.lower() == \"content-length\":\n                continue  # pragma: nocover\n            response_headers.append((header_name, header_value))\n\n        self.response_headers = response_headers\n\n    def start(self):\n        self.start_time = time.time()\n\n    def finish(self):\n        if not self.wrote_header:\n            self.write(b\"\")\n        if self.chunked_response:\n            # not self.write, it will chunk it!\n            self.channel.write_soon(b\"0\\r\\n\\r\\n\")\n\n    def write(self, data):\n        if not self.complete:\n            raise RuntimeError(\"start_response was not called before body written\")\n        channel = self.channel\n        if not self.wrote_header:\n            rh = self.build_response_header()\n            channel.write_soon(rh)\n            self.wrote_header = True\n\n        if data and self.has_body:\n            towrite = data\n            cl = self.content_length\n            if self.chunked_response:\n                # use chunked encoding response\n                towrite = tobytes(hex(len(data))[2:].upper()) + b\"\\r\\n\"\n                towrite += data + b\"\\r\\n\"\n            elif cl is not None:\n                towrite = data[: cl - self.content_bytes_written]\n                self.content_bytes_written += len(towrite)\n                if towrite != data and not self.logged_write_excess:\n                    self.logger.warning(\n                        \"application-written content exceeded the number of \"\n                        \"bytes specified by Content-Length header (%s)\" % cl\n                    )\n                    self.logged_write_excess = True\n            if towrite:\n                channel.write_soon(towrite)\n        elif data:\n            # Cheat, and tell the application we have written all of the bytes,\n            # even though the response shouldn't have a body and we are\n            # ignoring it entirely.\n            self.content_bytes_written += len(data)\n\n            if not self.logged_write_no_body:\n                self.logger.warning(\n                    \"application-written content was ignored due to HTTP \"\n                    \"response that may not contain a message-body: (%s)\" % self.status\n                )\n                self.logged_write_no_body = True\n\n\nclass ErrorTask(Task):\n    \"\"\" An error task produces an error response\n    \"\"\"\n\n    complete = True\n\n    def execute(self):\n        e = self.request.error\n        status, headers, body = e.to_response()\n        self.status = status\n        self.response_headers.extend(headers)\n        if self.version == \"1.1\":\n            connection = self.request.headers.get(\"CONNECTION\", \"\").lower()\n            if connection == \"close\":\n                self.response_headers.append((\"Connection\", \"close\"))\n            # under HTTP 1.1 keep-alive is default, no need to set the header\n        else:\n            # HTTP 1.0\n            self.response_headers.append((\"Connection\", \"close\"))\n        self.close_on_finish = True\n        self.content_length = len(body)\n        self.write(tobytes(body))\n\n\nclass WSGITask(Task):\n    \"\"\"A WSGI task produces a response from a WSGI application.\n    \"\"\"\n\n    environ = None\n\n    def execute(self):\n        environ = self.get_environment()\n\n        def start_response(status, headers, exc_info=None):\n            if self.complete and not exc_info:\n                raise AssertionError(\n                    \"start_response called a second time without providing exc_info.\"\n                )\n            if exc_info:\n                try:\n                    if self.wrote_header:\n                        # higher levels will catch and handle raised exception:\n                        # 1. \"service\" method in task.py\n                        # 2. \"service\" method in channel.py\n                        # 3. \"handler_thread\" method in task.py\n                        reraise(exc_info[0], exc_info[1], exc_info[2])\n                    else:\n                        # As per WSGI spec existing headers must be cleared\n                        self.response_headers = []\n                finally:\n                    exc_info = None\n\n            self.complete = True\n\n            if not status.__class__ is str:\n                raise AssertionError(\"status %s is not a string\" % status)\n            if \"\\n\" in status or \"\\r\" in status:\n                raise ValueError(\n                    \"carriage return/line feed character present in status\"\n                )\n\n            self.status = status\n\n            # Prepare the headers for output\n            for k, v in headers:\n                if not k.__class__ is str:\n                    raise AssertionError(\n                        \"Header name %r is not a string in %r\" % (k, (k, v))\n                    )\n                if not v.__class__ is str:\n                    raise AssertionError(\n                        \"Header value %r is not a string in %r\" % (v, (k, v))\n                    )\n\n                if \"\\n\" in v or \"\\r\" in v:\n                    raise ValueError(\n                        \"carriage return/line feed character present in header value\"\n                    )\n                if \"\\n\" in k or \"\\r\" in k:\n                    raise ValueError(\n                        \"carriage return/line feed character present in header name\"\n                    )\n\n                kl = k.lower()\n                if kl == \"content-length\":\n                    self.content_length = int(v)\n                elif kl in hop_by_hop:\n                    raise AssertionError(\n                        '%s is a \"hop-by-hop\" header; it cannot be used by '\n                        \"a WSGI application (see PEP 3333)\" % k\n                    )\n\n            self.response_headers.extend(headers)\n\n            # Return a method used to write the response data.\n            return self.write\n\n        # Call the application to handle the request and write a response\n        app_iter = self.channel.server.application(environ, start_response)\n\n        can_close_app_iter = True\n        try:\n            if app_iter.__class__ is ReadOnlyFileBasedBuffer:\n                cl = self.content_length\n                size = app_iter.prepare(cl)\n                if size:\n                    if cl != size:\n                        if cl is not None:\n                            self.remove_content_length_header()\n                        self.content_length = size\n                    self.write(b\"\")  # generate headers\n                    # if the write_soon below succeeds then the channel will\n                    # take over closing the underlying file via the channel's\n                    # _flush_some or handle_close so we intentionally avoid\n                    # calling close in the finally block\n                    self.channel.write_soon(app_iter)\n                    can_close_app_iter = False\n                    return\n\n            first_chunk_len = None\n            for chunk in app_iter:\n                if first_chunk_len is None:\n                    first_chunk_len = len(chunk)\n                    # Set a Content-Length header if one is not supplied.\n                    # start_response may not have been called until first\n                    # iteration as per PEP, so we must reinterrogate\n                    # self.content_length here\n                    if self.content_length is None:\n                        app_iter_len = None\n                        if hasattr(app_iter, \"__len__\"):\n                            app_iter_len = len(app_iter)\n                        if app_iter_len == 1:\n                            self.content_length = first_chunk_len\n                # transmit headers only after first iteration of the iterable\n                # that returns a non-empty bytestring (PEP 3333)\n                if chunk:\n                    self.write(chunk)\n\n            cl = self.content_length\n            if cl is not None:\n                if self.content_bytes_written != cl:\n                    # close the connection so the client isn't sitting around\n                    # waiting for more data when there are too few bytes\n                    # to service content-length\n                    self.close_on_finish = True\n                    if self.request.command != \"HEAD\":\n                        self.logger.warning(\n                            \"application returned too few bytes (%s) \"\n                            \"for specified Content-Length (%s) via app_iter\"\n                            % (self.content_bytes_written, cl),\n                        )\n        finally:\n            if can_close_app_iter and hasattr(app_iter, \"close\"):\n                app_iter.close()\n\n    def get_environment(self):\n        \"\"\"Returns a WSGI environment.\"\"\"\n        environ = self.environ\n        if environ is not None:\n            # Return the cached copy.\n            return environ\n\n        request = self.request\n        path = request.path\n        channel = self.channel\n        server = channel.server\n        url_prefix = server.adj.url_prefix\n\n        if path.startswith(\"/\"):\n            # strip extra slashes at the beginning of a path that starts\n            # with any number of slashes\n            path = \"/\" + path.lstrip(\"/\")\n\n        if url_prefix:\n            # NB: url_prefix is guaranteed by the configuration machinery to\n            # be either the empty string or a string that starts with a single\n            # slash and ends without any slashes\n            if path == url_prefix:\n                # if the path is the same as the url prefix, the SCRIPT_NAME\n                # should be the url_prefix and PATH_INFO should be empty\n                path = \"\"\n            else:\n                # if the path starts with the url prefix plus a slash,\n                # the SCRIPT_NAME should be the url_prefix and PATH_INFO should\n                # the value of path from the slash until its end\n                url_prefix_with_trailing_slash = url_prefix + \"/\"\n                if path.startswith(url_prefix_with_trailing_slash):\n                    path = path[len(url_prefix) :]\n\n        environ = {\n            \"REMOTE_ADDR\": channel.addr[0],\n            # Nah, we aren't actually going to look up the reverse DNS for\n            # REMOTE_ADDR, but we will happily set this environment variable\n            # for the WSGI application. Spec says we can just set this to\n            # REMOTE_ADDR, so we do.\n            \"REMOTE_HOST\": channel.addr[0],\n            # try and set the REMOTE_PORT to something useful, but maybe None\n            \"REMOTE_PORT\": str(channel.addr[1]),\n            \"REQUEST_METHOD\": request.command.upper(),\n            \"SERVER_PORT\": str(server.effective_port),\n            \"SERVER_NAME\": server.server_name,\n            \"SERVER_SOFTWARE\": server.adj.ident,\n            \"SERVER_PROTOCOL\": \"HTTP/%s\" % self.version,\n            \"SCRIPT_NAME\": url_prefix,\n            \"PATH_INFO\": path,\n            \"QUERY_STRING\": request.query,\n            \"wsgi.url_scheme\": request.url_scheme,\n            # the following environment variables are required by the WSGI spec\n            \"wsgi.version\": (1, 0),\n            # apps should use the logging module\n            \"wsgi.errors\": sys.stderr,\n            \"wsgi.multithread\": True,\n            \"wsgi.multiprocess\": False,\n            \"wsgi.run_once\": False,\n            \"wsgi.input\": request.get_body_stream(),\n            \"wsgi.file_wrapper\": ReadOnlyFileBasedBuffer,\n            \"wsgi.input_terminated\": True,  # wsgi.input is EOF terminated\n        }\n\n        for key, value in dict(request.headers).items():\n            value = value.strip()\n            mykey = rename_headers.get(key, None)\n            if mykey is None:\n                mykey = \"HTTP_\" + key\n            if mykey not in environ:\n                environ[mykey] = value\n\n        # cache the environ for this request\n        self.environ = environ\n        return environ\n", "import unittest\nimport io\n\n\nclass TestHTTPChannel(unittest.TestCase):\n    def _makeOne(self, sock, addr, adj, map=None):\n        from waitress.channel import HTTPChannel\n\n        server = DummyServer()\n        return HTTPChannel(server, sock, addr, adj=adj, map=map)\n\n    def _makeOneWithMap(self, adj=None):\n        if adj is None:\n            adj = DummyAdjustments()\n        sock = DummySock()\n        map = {}\n        inst = self._makeOne(sock, \"127.0.0.1\", adj, map=map)\n        inst.outbuf_lock = DummyLock()\n        return inst, sock, map\n\n    def test_ctor(self):\n        inst, _, map = self._makeOneWithMap()\n        self.assertEqual(inst.addr, \"127.0.0.1\")\n        self.assertEqual(inst.sendbuf_len, 2048)\n        self.assertEqual(map[100], inst)\n\n    def test_total_outbufs_len_an_outbuf_size_gt_sys_maxint(self):\n        from waitress.compat import MAXINT\n\n        inst, _, map = self._makeOneWithMap()\n\n        class DummyBuffer(object):\n            chunks = []\n\n            def append(self, data):\n                self.chunks.append(data)\n\n        class DummyData(object):\n            def __len__(self):\n                return MAXINT\n\n        inst.total_outbufs_len = 1\n        inst.outbufs = [DummyBuffer()]\n        inst.write_soon(DummyData())\n        # we are testing that this method does not raise an OverflowError\n        # (see https://github.com/Pylons/waitress/issues/47)\n        self.assertEqual(inst.total_outbufs_len, MAXINT + 1)\n\n    def test_writable_something_in_outbuf(self):\n        inst, sock, map = self._makeOneWithMap()\n        inst.total_outbufs_len = 3\n        self.assertTrue(inst.writable())\n\n    def test_writable_nothing_in_outbuf(self):\n        inst, sock, map = self._makeOneWithMap()\n        self.assertFalse(inst.writable())\n\n    def test_writable_nothing_in_outbuf_will_close(self):\n        inst, sock, map = self._makeOneWithMap()\n        inst.will_close = True\n        self.assertTrue(inst.writable())\n\n    def test_handle_write_not_connected(self):\n        inst, sock, map = self._makeOneWithMap()\n        inst.connected = False\n        self.assertFalse(inst.handle_write())\n\n    def test_handle_write_with_requests(self):\n        inst, sock, map = self._makeOneWithMap()\n        inst.requests = True\n        inst.last_activity = 0\n        result = inst.handle_write()\n        self.assertEqual(result, None)\n        self.assertEqual(inst.last_activity, 0)\n\n    def test_handle_write_no_request_with_outbuf(self):\n        inst, sock, map = self._makeOneWithMap()\n        inst.requests = []\n        inst.outbufs = [DummyBuffer(b\"abc\")]\n        inst.total_outbufs_len = len(inst.outbufs[0])\n        inst.last_activity = 0\n        result = inst.handle_write()\n        self.assertEqual(result, None)\n        self.assertNotEqual(inst.last_activity, 0)\n        self.assertEqual(sock.sent, b\"abc\")\n\n    def test_handle_write_outbuf_raises_socketerror(self):\n        import socket\n\n        inst, sock, map = self._makeOneWithMap()\n        inst.requests = []\n        outbuf = DummyBuffer(b\"abc\", socket.error)\n        inst.outbufs = [outbuf]\n        inst.total_outbufs_len = len(outbuf)\n        inst.last_activity = 0\n        inst.logger = DummyLogger()\n        result = inst.handle_write()\n        self.assertEqual(result, None)\n        self.assertEqual(inst.last_activity, 0)\n        self.assertEqual(sock.sent, b\"\")\n        self.assertEqual(len(inst.logger.exceptions), 1)\n        self.assertTrue(outbuf.closed)\n\n    def test_handle_write_outbuf_raises_othererror(self):\n        inst, sock, map = self._makeOneWithMap()\n        inst.requests = []\n        outbuf = DummyBuffer(b\"abc\", IOError)\n        inst.outbufs = [outbuf]\n        inst.total_outbufs_len = len(outbuf)\n        inst.last_activity = 0\n        inst.logger = DummyLogger()\n        result = inst.handle_write()\n        self.assertEqual(result, None)\n        self.assertEqual(inst.last_activity, 0)\n        self.assertEqual(sock.sent, b\"\")\n        self.assertEqual(len(inst.logger.exceptions), 1)\n        self.assertTrue(outbuf.closed)\n\n    def test_handle_write_no_requests_no_outbuf_will_close(self):\n        inst, sock, map = self._makeOneWithMap()\n        inst.requests = []\n        outbuf = DummyBuffer(b\"\")\n        inst.outbufs = [outbuf]\n        inst.will_close = True\n        inst.last_activity = 0\n        result = inst.handle_write()\n        self.assertEqual(result, None)\n        self.assertEqual(inst.connected, False)\n        self.assertEqual(sock.closed, True)\n        self.assertEqual(inst.last_activity, 0)\n        self.assertTrue(outbuf.closed)\n\n    def test_handle_write_no_requests_outbuf_gt_send_bytes(self):\n        inst, sock, map = self._makeOneWithMap()\n        inst.requests = [True]\n        inst.outbufs = [DummyBuffer(b\"abc\")]\n        inst.total_outbufs_len = len(inst.outbufs[0])\n        inst.adj.send_bytes = 2\n        inst.will_close = False\n        inst.last_activity = 0\n        result = inst.handle_write()\n        self.assertEqual(result, None)\n        self.assertEqual(inst.will_close, False)\n        self.assertTrue(inst.outbuf_lock.acquired)\n        self.assertEqual(sock.sent, b\"abc\")\n\n    def test_handle_write_close_when_flushed(self):\n        inst, sock, map = self._makeOneWithMap()\n        outbuf = DummyBuffer(b\"abc\")\n        inst.outbufs = [outbuf]\n        inst.total_outbufs_len = len(outbuf)\n        inst.will_close = False\n        inst.close_when_flushed = True\n        inst.last_activity = 0\n        result = inst.handle_write()\n        self.assertEqual(result, None)\n        self.assertEqual(inst.will_close, True)\n        self.assertEqual(inst.close_when_flushed, False)\n        self.assertEqual(sock.sent, b\"abc\")\n        self.assertTrue(outbuf.closed)\n\n    def test_readable_no_requests_not_will_close(self):\n        inst, sock, map = self._makeOneWithMap()\n        inst.requests = []\n        inst.will_close = False\n        self.assertEqual(inst.readable(), True)\n\n    def test_readable_no_requests_will_close(self):\n        inst, sock, map = self._makeOneWithMap()\n        inst.requests = []\n        inst.will_close = True\n        self.assertEqual(inst.readable(), False)\n\n    def test_readable_with_requests(self):\n        inst, sock, map = self._makeOneWithMap()\n        inst.requests = True\n        self.assertEqual(inst.readable(), False)\n\n    def test_handle_read_no_error(self):\n        inst, sock, map = self._makeOneWithMap()\n        inst.will_close = False\n        inst.recv = lambda *arg: b\"abc\"\n        inst.last_activity = 0\n        L = []\n        inst.received = lambda x: L.append(x)\n        result = inst.handle_read()\n        self.assertEqual(result, None)\n        self.assertNotEqual(inst.last_activity, 0)\n        self.assertEqual(L, [b\"abc\"])\n\n    def test_handle_read_error(self):\n        import socket\n\n        inst, sock, map = self._makeOneWithMap()\n        inst.will_close = False\n\n        def recv(b):\n            raise socket.error\n\n        inst.recv = recv\n        inst.last_activity = 0\n        inst.logger = DummyLogger()\n        result = inst.handle_read()\n        self.assertEqual(result, None)\n        self.assertEqual(inst.last_activity, 0)\n        self.assertEqual(len(inst.logger.exceptions), 1)\n\n    def test_write_soon_empty_byte(self):\n        inst, sock, map = self._makeOneWithMap()\n        wrote = inst.write_soon(b\"\")\n        self.assertEqual(wrote, 0)\n        self.assertEqual(len(inst.outbufs[0]), 0)\n\n    def test_write_soon_nonempty_byte(self):\n        inst, sock, map = self._makeOneWithMap()\n        wrote = inst.write_soon(b\"a\")\n        self.assertEqual(wrote, 1)\n        self.assertEqual(len(inst.outbufs[0]), 1)\n\n    def test_write_soon_filewrapper(self):\n        from waitress.buffers import ReadOnlyFileBasedBuffer\n\n        f = io.BytesIO(b\"abc\")\n        wrapper = ReadOnlyFileBasedBuffer(f, 8192)\n        wrapper.prepare()\n        inst, sock, map = self._makeOneWithMap()\n        outbufs = inst.outbufs\n        orig_outbuf = outbufs[0]\n        wrote = inst.write_soon(wrapper)\n        self.assertEqual(wrote, 3)\n        self.assertEqual(len(outbufs), 3)\n        self.assertEqual(outbufs[0], orig_outbuf)\n        self.assertEqual(outbufs[1], wrapper)\n        self.assertEqual(outbufs[2].__class__.__name__, \"OverflowableBuffer\")\n\n    def test_write_soon_disconnected(self):\n        from waitress.channel import ClientDisconnected\n\n        inst, sock, map = self._makeOneWithMap()\n        inst.connected = False\n        self.assertRaises(ClientDisconnected, lambda: inst.write_soon(b\"stuff\"))\n\n    def test_write_soon_disconnected_while_over_watermark(self):\n        from waitress.channel import ClientDisconnected\n\n        inst, sock, map = self._makeOneWithMap()\n\n        def dummy_flush():\n            inst.connected = False\n\n        inst._flush_outbufs_below_high_watermark = dummy_flush\n        self.assertRaises(ClientDisconnected, lambda: inst.write_soon(b\"stuff\"))\n\n    def test_write_soon_rotates_outbuf_on_overflow(self):\n        inst, sock, map = self._makeOneWithMap()\n        inst.adj.outbuf_high_watermark = 3\n        inst.current_outbuf_count = 4\n        wrote = inst.write_soon(b\"xyz\")\n        self.assertEqual(wrote, 3)\n        self.assertEqual(len(inst.outbufs), 2)\n        self.assertEqual(inst.outbufs[0].get(), b\"\")\n        self.assertEqual(inst.outbufs[1].get(), b\"xyz\")\n\n    def test_write_soon_waits_on_backpressure(self):\n        inst, sock, map = self._makeOneWithMap()\n        inst.adj.outbuf_high_watermark = 3\n        inst.total_outbufs_len = 4\n        inst.current_outbuf_count = 4\n\n        class Lock(DummyLock):\n            def wait(self):\n                inst.total_outbufs_len = 0\n                super(Lock, self).wait()\n\n        inst.outbuf_lock = Lock()\n        wrote = inst.write_soon(b\"xyz\")\n        self.assertEqual(wrote, 3)\n        self.assertEqual(len(inst.outbufs), 2)\n        self.assertEqual(inst.outbufs[0].get(), b\"\")\n        self.assertEqual(inst.outbufs[1].get(), b\"xyz\")\n        self.assertTrue(inst.outbuf_lock.waited)\n\n    def test_handle_write_notify_after_flush(self):\n        inst, sock, map = self._makeOneWithMap()\n        inst.requests = [True]\n        inst.outbufs = [DummyBuffer(b\"abc\")]\n        inst.total_outbufs_len = len(inst.outbufs[0])\n        inst.adj.send_bytes = 1\n        inst.adj.outbuf_high_watermark = 5\n        inst.will_close = False\n        inst.last_activity = 0\n        result = inst.handle_write()\n        self.assertEqual(result, None)\n        self.assertEqual(inst.will_close, False)\n        self.assertTrue(inst.outbuf_lock.acquired)\n        self.assertTrue(inst.outbuf_lock.notified)\n        self.assertEqual(sock.sent, b\"abc\")\n\n    def test_handle_write_no_notify_after_flush(self):\n        inst, sock, map = self._makeOneWithMap()\n        inst.requests = [True]\n        inst.outbufs = [DummyBuffer(b\"abc\")]\n        inst.total_outbufs_len = len(inst.outbufs[0])\n        inst.adj.send_bytes = 1\n        inst.adj.outbuf_high_watermark = 2\n        sock.send = lambda x: False\n        inst.will_close = False\n        inst.last_activity = 0\n        result = inst.handle_write()\n        self.assertEqual(result, None)\n        self.assertEqual(inst.will_close, False)\n        self.assertTrue(inst.outbuf_lock.acquired)\n        self.assertFalse(inst.outbuf_lock.notified)\n        self.assertEqual(sock.sent, b\"\")\n\n    def test__flush_some_empty_outbuf(self):\n        inst, sock, map = self._makeOneWithMap()\n        result = inst._flush_some()\n        self.assertEqual(result, False)\n\n    def test__flush_some_full_outbuf_socket_returns_nonzero(self):\n        inst, sock, map = self._makeOneWithMap()\n        inst.outbufs[0].append(b\"abc\")\n        inst.total_outbufs_len = sum(len(x) for x in inst.outbufs)\n        result = inst._flush_some()\n        self.assertEqual(result, True)\n\n    def test__flush_some_full_outbuf_socket_returns_zero(self):\n        inst, sock, map = self._makeOneWithMap()\n        sock.send = lambda x: False\n        inst.outbufs[0].append(b\"abc\")\n        inst.total_outbufs_len = sum(len(x) for x in inst.outbufs)\n        result = inst._flush_some()\n        self.assertEqual(result, False)\n\n    def test_flush_some_multiple_buffers_first_empty(self):\n        inst, sock, map = self._makeOneWithMap()\n        sock.send = lambda x: len(x)\n        buffer = DummyBuffer(b\"abc\")\n        inst.outbufs.append(buffer)\n        inst.total_outbufs_len = sum(len(x) for x in inst.outbufs)\n        result = inst._flush_some()\n        self.assertEqual(result, True)\n        self.assertEqual(buffer.skipped, 3)\n        self.assertEqual(inst.outbufs, [buffer])\n\n    def test_flush_some_multiple_buffers_close_raises(self):\n        inst, sock, map = self._makeOneWithMap()\n        sock.send = lambda x: len(x)\n        buffer = DummyBuffer(b\"abc\")\n        inst.outbufs.append(buffer)\n        inst.total_outbufs_len = sum(len(x) for x in inst.outbufs)\n        inst.logger = DummyLogger()\n\n        def doraise():\n            raise NotImplementedError\n\n        inst.outbufs[0].close = doraise\n        result = inst._flush_some()\n        self.assertEqual(result, True)\n        self.assertEqual(buffer.skipped, 3)\n        self.assertEqual(inst.outbufs, [buffer])\n        self.assertEqual(len(inst.logger.exceptions), 1)\n\n    def test__flush_some_outbuf_len_gt_sys_maxint(self):\n        from waitress.compat import MAXINT\n\n        inst, sock, map = self._makeOneWithMap()\n\n        class DummyHugeOutbuffer(object):\n            def __init__(self):\n                self.length = MAXINT + 1\n\n            def __len__(self):\n                return self.length\n\n            def get(self, numbytes):\n                self.length = 0\n                return b\"123\"\n\n        buf = DummyHugeOutbuffer()\n        inst.outbufs = [buf]\n        inst.send = lambda *arg: 0\n        result = inst._flush_some()\n        # we are testing that _flush_some doesn't raise an OverflowError\n        # when one of its outbufs has a __len__ that returns gt sys.maxint\n        self.assertEqual(result, False)\n\n    def test_handle_close(self):\n        inst, sock, map = self._makeOneWithMap()\n        inst.handle_close()\n        self.assertEqual(inst.connected, False)\n        self.assertEqual(sock.closed, True)\n\n    def test_handle_close_outbuf_raises_on_close(self):\n        inst, sock, map = self._makeOneWithMap()\n\n        def doraise():\n            raise NotImplementedError\n\n        inst.outbufs[0].close = doraise\n        inst.logger = DummyLogger()\n        inst.handle_close()\n        self.assertEqual(inst.connected, False)\n        self.assertEqual(sock.closed, True)\n        self.assertEqual(len(inst.logger.exceptions), 1)\n\n    def test_add_channel(self):\n        inst, sock, map = self._makeOneWithMap()\n        fileno = inst._fileno\n        inst.add_channel(map)\n        self.assertEqual(map[fileno], inst)\n        self.assertEqual(inst.server.active_channels[fileno], inst)\n\n    def test_del_channel(self):\n        inst, sock, map = self._makeOneWithMap()\n        fileno = inst._fileno\n        inst.server.active_channels[fileno] = True\n        inst.del_channel(map)\n        self.assertEqual(map.get(fileno), None)\n        self.assertEqual(inst.server.active_channels.get(fileno), None)\n\n    def test_received(self):\n        inst, sock, map = self._makeOneWithMap()\n        inst.server = DummyServer()\n        inst.received(b\"GET / HTTP/1.1\\n\\n\")\n        self.assertEqual(inst.server.tasks, [inst])\n        self.assertTrue(inst.requests)\n\n    def test_received_no_chunk(self):\n        inst, sock, map = self._makeOneWithMap()\n        self.assertEqual(inst.received(b\"\"), False)\n\n    def test_received_preq_not_completed(self):\n        inst, sock, map = self._makeOneWithMap()\n        inst.server = DummyServer()\n        preq = DummyParser()\n        inst.request = preq\n        preq.completed = False\n        preq.empty = True\n        inst.received(b\"GET / HTTP/1.1\\n\\n\")\n        self.assertEqual(inst.requests, ())\n        self.assertEqual(inst.server.tasks, [])\n\n    def test_received_preq_completed_empty(self):\n        inst, sock, map = self._makeOneWithMap()\n        inst.server = DummyServer()\n        preq = DummyParser()\n        inst.request = preq\n        preq.completed = True\n        preq.empty = True\n        inst.received(b\"GET / HTTP/1.1\\n\\n\")\n        self.assertEqual(inst.request, None)\n        self.assertEqual(inst.server.tasks, [])\n\n    def test_received_preq_error(self):\n        inst, sock, map = self._makeOneWithMap()\n        inst.server = DummyServer()\n        preq = DummyParser()\n        inst.request = preq\n        preq.completed = True\n        preq.error = True\n        inst.received(b\"GET / HTTP/1.1\\n\\n\")\n        self.assertEqual(inst.request, None)\n        self.assertEqual(len(inst.server.tasks), 1)\n        self.assertTrue(inst.requests)\n\n    def test_received_preq_completed_connection_close(self):\n        inst, sock, map = self._makeOneWithMap()\n        inst.server = DummyServer()\n        preq = DummyParser()\n        inst.request = preq\n        preq.completed = True\n        preq.empty = True\n        preq.connection_close = True\n        inst.received(b\"GET / HTTP/1.1\\n\\n\" + b\"a\" * 50000)\n        self.assertEqual(inst.request, None)\n        self.assertEqual(inst.server.tasks, [])\n\n    def test_received_preq_completed_n_lt_data(self):\n        inst, sock, map = self._makeOneWithMap()\n        inst.server = DummyServer()\n        preq = DummyParser()\n        inst.request = preq\n        preq.completed = True\n        preq.empty = False\n        line = b\"GET / HTTP/1.1\\n\\n\"\n        preq.retval = len(line)\n        inst.received(line + line)\n        self.assertEqual(inst.request, None)\n        self.assertEqual(len(inst.requests), 2)\n        self.assertEqual(len(inst.server.tasks), 1)\n\n    def test_received_headers_finished_expect_continue_false(self):\n        inst, sock, map = self._makeOneWithMap()\n        inst.server = DummyServer()\n        preq = DummyParser()\n        inst.request = preq\n        preq.expect_continue = False\n        preq.headers_finished = True\n        preq.completed = False\n        preq.empty = False\n        preq.retval = 1\n        inst.received(b\"GET / HTTP/1.1\\n\\n\")\n        self.assertEqual(inst.request, preq)\n        self.assertEqual(inst.server.tasks, [])\n        self.assertEqual(inst.outbufs[0].get(100), b\"\")\n\n    def test_received_headers_finished_expect_continue_true(self):\n        inst, sock, map = self._makeOneWithMap()\n        inst.server = DummyServer()\n        preq = DummyParser()\n        inst.request = preq\n        preq.expect_continue = True\n        preq.headers_finished = True\n        preq.completed = False\n        preq.empty = False\n        inst.received(b\"GET / HTTP/1.1\\n\\n\")\n        self.assertEqual(inst.request, preq)\n        self.assertEqual(inst.server.tasks, [])\n        self.assertEqual(sock.sent, b\"HTTP/1.1 100 Continue\\r\\n\\r\\n\")\n        self.assertEqual(inst.sent_continue, True)\n        self.assertEqual(preq.completed, False)\n\n    def test_received_headers_finished_expect_continue_true_sent_true(self):\n        inst, sock, map = self._makeOneWithMap()\n        inst.server = DummyServer()\n        preq = DummyParser()\n        inst.request = preq\n        preq.expect_continue = True\n        preq.headers_finished = True\n        preq.completed = False\n        preq.empty = False\n        inst.sent_continue = True\n        inst.received(b\"GET / HTTP/1.1\\n\\n\")\n        self.assertEqual(inst.request, preq)\n        self.assertEqual(inst.server.tasks, [])\n        self.assertEqual(sock.sent, b\"\")\n        self.assertEqual(inst.sent_continue, True)\n        self.assertEqual(preq.completed, False)\n\n    def test_service_no_requests(self):\n        inst, sock, map = self._makeOneWithMap()\n        inst.requests = []\n        inst.service()\n        self.assertEqual(inst.requests, [])\n        self.assertTrue(inst.server.trigger_pulled)\n        self.assertTrue(inst.last_activity)\n\n    def test_service_with_one_request(self):\n        inst, sock, map = self._makeOneWithMap()\n        request = DummyRequest()\n        inst.task_class = DummyTaskClass()\n        inst.requests = [request]\n        inst.service()\n        self.assertEqual(inst.requests, [])\n        self.assertTrue(request.serviced)\n        self.assertTrue(request.closed)\n\n    def test_service_with_one_error_request(self):\n        inst, sock, map = self._makeOneWithMap()\n        request = DummyRequest()\n        request.error = DummyError()\n        inst.error_task_class = DummyTaskClass()\n        inst.requests = [request]\n        inst.service()\n        self.assertEqual(inst.requests, [])\n        self.assertTrue(request.serviced)\n        self.assertTrue(request.closed)\n\n    def test_service_with_multiple_requests(self):\n        inst, sock, map = self._makeOneWithMap()\n        request1 = DummyRequest()\n        request2 = DummyRequest()\n        inst.task_class = DummyTaskClass()\n        inst.requests = [request1, request2]\n        inst.service()\n        self.assertEqual(inst.requests, [])\n        self.assertTrue(request1.serviced)\n        self.assertTrue(request2.serviced)\n        self.assertTrue(request1.closed)\n        self.assertTrue(request2.closed)\n\n    def test_service_with_request_raises(self):\n        inst, sock, map = self._makeOneWithMap()\n        inst.adj.expose_tracebacks = False\n        inst.server = DummyServer()\n        request = DummyRequest()\n        inst.requests = [request]\n        inst.task_class = DummyTaskClass(ValueError)\n        inst.task_class.wrote_header = False\n        inst.error_task_class = DummyTaskClass()\n        inst.logger = DummyLogger()\n        inst.service()\n        self.assertTrue(request.serviced)\n        self.assertEqual(inst.requests, [])\n        self.assertEqual(len(inst.logger.exceptions), 1)\n        self.assertTrue(inst.server.trigger_pulled)\n        self.assertTrue(inst.last_activity)\n        self.assertFalse(inst.will_close)\n        self.assertEqual(inst.error_task_class.serviced, True)\n        self.assertTrue(request.closed)\n\n    def test_service_with_requests_raises_already_wrote_header(self):\n        inst, sock, map = self._makeOneWithMap()\n        inst.adj.expose_tracebacks = False\n        inst.server = DummyServer()\n        request = DummyRequest()\n        inst.requests = [request]\n        inst.task_class = DummyTaskClass(ValueError)\n        inst.error_task_class = DummyTaskClass()\n        inst.logger = DummyLogger()\n        inst.service()\n        self.assertTrue(request.serviced)\n        self.assertEqual(inst.requests, [])\n        self.assertEqual(len(inst.logger.exceptions), 1)\n        self.assertTrue(inst.server.trigger_pulled)\n        self.assertTrue(inst.last_activity)\n        self.assertTrue(inst.close_when_flushed)\n        self.assertEqual(inst.error_task_class.serviced, False)\n        self.assertTrue(request.closed)\n\n    def test_service_with_requests_raises_didnt_write_header_expose_tbs(self):\n        inst, sock, map = self._makeOneWithMap()\n        inst.adj.expose_tracebacks = True\n        inst.server = DummyServer()\n        request = DummyRequest()\n        inst.requests = [request]\n        inst.task_class = DummyTaskClass(ValueError)\n        inst.task_class.wrote_header = False\n        inst.error_task_class = DummyTaskClass()\n        inst.logger = DummyLogger()\n        inst.service()\n        self.assertTrue(request.serviced)\n        self.assertFalse(inst.will_close)\n        self.assertEqual(inst.requests, [])\n        self.assertEqual(len(inst.logger.exceptions), 1)\n        self.assertTrue(inst.server.trigger_pulled)\n        self.assertTrue(inst.last_activity)\n        self.assertEqual(inst.error_task_class.serviced, True)\n        self.assertTrue(request.closed)\n\n    def test_service_with_requests_raises_didnt_write_header(self):\n        inst, sock, map = self._makeOneWithMap()\n        inst.adj.expose_tracebacks = False\n        inst.server = DummyServer()\n        request = DummyRequest()\n        inst.requests = [request]\n        inst.task_class = DummyTaskClass(ValueError)\n        inst.task_class.wrote_header = False\n        inst.logger = DummyLogger()\n        inst.service()\n        self.assertTrue(request.serviced)\n        self.assertEqual(inst.requests, [])\n        self.assertEqual(len(inst.logger.exceptions), 1)\n        self.assertTrue(inst.server.trigger_pulled)\n        self.assertTrue(inst.last_activity)\n        self.assertTrue(inst.close_when_flushed)\n        self.assertTrue(request.closed)\n\n    def test_service_with_request_raises_disconnect(self):\n        from waitress.channel import ClientDisconnected\n\n        inst, sock, map = self._makeOneWithMap()\n        inst.adj.expose_tracebacks = False\n        inst.server = DummyServer()\n        request = DummyRequest()\n        inst.requests = [request]\n        inst.task_class = DummyTaskClass(ClientDisconnected)\n        inst.error_task_class = DummyTaskClass()\n        inst.logger = DummyLogger()\n        inst.service()\n        self.assertTrue(request.serviced)\n        self.assertEqual(inst.requests, [])\n        self.assertEqual(len(inst.logger.infos), 1)\n        self.assertTrue(inst.server.trigger_pulled)\n        self.assertTrue(inst.last_activity)\n        self.assertFalse(inst.will_close)\n        self.assertEqual(inst.error_task_class.serviced, False)\n        self.assertTrue(request.closed)\n\n    def test_service_with_request_error_raises_disconnect(self):\n        from waitress.channel import ClientDisconnected\n\n        inst, sock, map = self._makeOneWithMap()\n        inst.adj.expose_tracebacks = False\n        inst.server = DummyServer()\n        request = DummyRequest()\n        err_request = DummyRequest()\n        inst.requests = [request]\n        inst.parser_class = lambda x: err_request\n        inst.task_class = DummyTaskClass(RuntimeError)\n        inst.task_class.wrote_header = False\n        inst.error_task_class = DummyTaskClass(ClientDisconnected)\n        inst.logger = DummyLogger()\n        inst.service()\n        self.assertTrue(request.serviced)\n        self.assertTrue(err_request.serviced)\n        self.assertEqual(inst.requests, [])\n        self.assertEqual(len(inst.logger.exceptions), 1)\n        self.assertEqual(len(inst.logger.infos), 0)\n        self.assertTrue(inst.server.trigger_pulled)\n        self.assertTrue(inst.last_activity)\n        self.assertFalse(inst.will_close)\n        self.assertEqual(inst.task_class.serviced, True)\n        self.assertEqual(inst.error_task_class.serviced, True)\n        self.assertTrue(request.closed)\n\n    def test_cancel_no_requests(self):\n        inst, sock, map = self._makeOneWithMap()\n        inst.requests = ()\n        inst.cancel()\n        self.assertEqual(inst.requests, [])\n\n    def test_cancel_with_requests(self):\n        inst, sock, map = self._makeOneWithMap()\n        inst.requests = [None]\n        inst.cancel()\n        self.assertEqual(inst.requests, [])\n\n\nclass DummySock(object):\n    blocking = False\n    closed = False\n\n    def __init__(self):\n        self.sent = b\"\"\n\n    def setblocking(self, *arg):\n        self.blocking = True\n\n    def fileno(self):\n        return 100\n\n    def getpeername(self):\n        return \"127.0.0.1\"\n\n    def getsockopt(self, level, option):\n        return 2048\n\n    def close(self):\n        self.closed = True\n\n    def send(self, data):\n        self.sent += data\n        return len(data)\n\n\nclass DummyLock(object):\n    notified = False\n\n    def __init__(self, acquirable=True):\n        self.acquirable = acquirable\n\n    def acquire(self, val):\n        self.val = val\n        self.acquired = True\n        return self.acquirable\n\n    def release(self):\n        self.released = True\n\n    def notify(self):\n        self.notified = True\n\n    def wait(self):\n        self.waited = True\n\n    def __exit__(self, type, val, traceback):\n        self.acquire(True)\n\n    def __enter__(self):\n        pass\n\n\nclass DummyBuffer(object):\n    closed = False\n\n    def __init__(self, data, toraise=None):\n        self.data = data\n        self.toraise = toraise\n\n    def get(self, *arg):\n        if self.toraise:\n            raise self.toraise\n        data = self.data\n        self.data = b\"\"\n        return data\n\n    def skip(self, num, x):\n        self.skipped = num\n\n    def __len__(self):\n        return len(self.data)\n\n    def close(self):\n        self.closed = True\n\n\nclass DummyAdjustments(object):\n    outbuf_overflow = 1048576\n    outbuf_high_watermark = 1048576\n    inbuf_overflow = 512000\n    cleanup_interval = 900\n    url_scheme = \"http\"\n    channel_timeout = 300\n    log_socket_errors = True\n    recv_bytes = 8192\n    send_bytes = 1\n    expose_tracebacks = True\n    ident = \"waitress\"\n    max_request_header_size = 10000\n\n\nclass DummyServer(object):\n    trigger_pulled = False\n    adj = DummyAdjustments()\n\n    def __init__(self):\n        self.tasks = []\n        self.active_channels = {}\n\n    def add_task(self, task):\n        self.tasks.append(task)\n\n    def pull_trigger(self):\n        self.trigger_pulled = True\n\n\nclass DummyParser(object):\n    version = 1\n    data = None\n    completed = True\n    empty = False\n    headers_finished = False\n    expect_continue = False\n    retval = None\n    error = None\n    connection_close = False\n\n    def received(self, data):\n        self.data = data\n        if self.retval is not None:\n            return self.retval\n        return len(data)\n\n\nclass DummyRequest(object):\n    error = None\n    path = \"/\"\n    version = \"1.0\"\n    closed = False\n\n    def __init__(self):\n        self.headers = {}\n\n    def close(self):\n        self.closed = True\n\n\nclass DummyLogger(object):\n    def __init__(self):\n        self.exceptions = []\n        self.infos = []\n        self.warnings = []\n\n    def info(self, msg):\n        self.infos.append(msg)\n\n    def exception(self, msg):\n        self.exceptions.append(msg)\n\n\nclass DummyError(object):\n    code = \"431\"\n    reason = \"Bleh\"\n    body = \"My body\"\n\n\nclass DummyTaskClass(object):\n    wrote_header = True\n    close_on_finish = False\n    serviced = False\n\n    def __init__(self, toraise=None):\n        self.toraise = toraise\n\n    def __call__(self, channel, request):\n        self.request = request\n        return self\n\n    def service(self):\n        self.serviced = True\n        self.request.serviced = True\n        if self.toraise:\n            raise self.toraise\n", "import errno\nimport logging\nimport multiprocessing\nimport os\nimport signal\nimport socket\nimport string\nimport subprocess\nimport sys\nimport time\nimport unittest\nfrom waitress import server\nfrom waitress.compat import httplib, tobytes\nfrom waitress.utilities import cleanup_unix_socket\n\ndn = os.path.dirname\nhere = dn(__file__)\n\n\nclass NullHandler(logging.Handler):  # pragma: no cover\n    \"\"\"A logging handler that swallows all emitted messages.\n    \"\"\"\n\n    def emit(self, record):\n        pass\n\n\ndef start_server(app, svr, queue, **kwargs):  # pragma: no cover\n    \"\"\"Run a fixture application.\n    \"\"\"\n    logging.getLogger(\"waitress\").addHandler(NullHandler())\n    try_register_coverage()\n    svr(app, queue, **kwargs).run()\n\n\ndef try_register_coverage():  # pragma: no cover\n    # Hack around multiprocessing exiting early and not triggering coverage's\n    # atexit handler by always registering a signal handler\n\n    if \"COVERAGE_PROCESS_START\" in os.environ:\n        def sigterm(*args):\n            sys.exit(0)\n\n        signal.signal(signal.SIGTERM, sigterm)\n\n\nclass FixtureTcpWSGIServer(server.TcpWSGIServer):\n    \"\"\"A version of TcpWSGIServer that relays back what it's bound to.\n    \"\"\"\n\n    family = socket.AF_INET  # Testing\n\n    def __init__(self, application, queue, **kw):  # pragma: no cover\n        # Coverage doesn't see this as it's ran in a separate process.\n        kw[\"port\"] = 0  # Bind to any available port.\n        super(FixtureTcpWSGIServer, self).__init__(application, **kw)\n        host, port = self.socket.getsockname()\n        if os.name == \"nt\":\n            host = \"127.0.0.1\"\n        queue.put((host, port))\n\n\nclass SubprocessTests(object):\n\n    # For nose: all tests may be ran in separate processes.\n    _multiprocess_can_split_ = True\n\n    exe = sys.executable\n\n    server = None\n\n    def start_subprocess(self, target, **kw):\n        # Spawn a server process.\n        self.queue = multiprocessing.Queue()\n\n        if \"COVERAGE_RCFILE\" in os.environ:\n            os.environ[\"COVERAGE_PROCESS_START\"] = os.environ[\"COVERAGE_RCFILE\"]\n\n        self.proc = multiprocessing.Process(\n            target=start_server, args=(target, self.server, self.queue), kwargs=kw,\n        )\n        self.proc.start()\n\n        if self.proc.exitcode is not None:  # pragma: no cover\n            raise RuntimeError(\"%s didn't start\" % str(target))\n        # Get the socket the server is listening on.\n        self.bound_to = self.queue.get(timeout=5)\n        self.sock = self.create_socket()\n\n    def stop_subprocess(self):\n        if self.proc.exitcode is None:\n            self.proc.terminate()\n        self.sock.close()\n        # This give us one FD back ...\n        self.queue.close()\n        self.proc.join()\n\n    def assertline(self, line, status, reason, version):\n        v, s, r = (x.strip() for x in line.split(None, 2))\n        self.assertEqual(s, tobytes(status))\n        self.assertEqual(r, tobytes(reason))\n        self.assertEqual(v, tobytes(version))\n\n    def create_socket(self):\n        return socket.socket(self.server.family, socket.SOCK_STREAM)\n\n    def connect(self):\n        self.sock.connect(self.bound_to)\n\n    def make_http_connection(self):\n        raise NotImplementedError  # pragma: no cover\n\n    def send_check_error(self, to_send):\n        self.sock.send(to_send)\n\n\nclass TcpTests(SubprocessTests):\n\n    server = FixtureTcpWSGIServer\n\n    def make_http_connection(self):\n        return httplib.HTTPConnection(*self.bound_to)\n\n\nclass SleepyThreadTests(TcpTests, unittest.TestCase):\n    # test that sleepy thread doesnt block other requests\n\n    def setUp(self):\n        from waitress.tests.fixtureapps import sleepy\n\n        self.start_subprocess(sleepy.app)\n\n    def tearDown(self):\n        self.stop_subprocess()\n\n    def test_it(self):\n        getline = os.path.join(here, \"fixtureapps\", \"getline.py\")\n        cmds = (\n            [self.exe, getline, \"http://%s:%d/sleepy\" % self.bound_to],\n            [self.exe, getline, \"http://%s:%d/\" % self.bound_to],\n        )\n        r, w = os.pipe()\n        procs = []\n        for cmd in cmds:\n            procs.append(subprocess.Popen(cmd, stdout=w))\n        time.sleep(3)\n        for proc in procs:\n            if proc.returncode is not None:  # pragma: no cover\n                proc.terminate()\n            proc.wait()\n        # the notsleepy response should always be first returned (it sleeps\n        # for 2 seconds, then returns; the notsleepy response should be\n        # processed in the meantime)\n        result = os.read(r, 10000)\n        os.close(r)\n        os.close(w)\n        self.assertEqual(result, b\"notsleepy returnedsleepy returned\")\n\n\nclass EchoTests(object):\n    def setUp(self):\n        from waitress.tests.fixtureapps import echo\n\n        self.start_subprocess(\n            echo.app,\n            trusted_proxy=\"*\",\n            trusted_proxy_count=1,\n            trusted_proxy_headers={\"x-forwarded-for\", \"x-forwarded-proto\"},\n            clear_untrusted_proxy_headers=True,\n        )\n\n    def tearDown(self):\n        self.stop_subprocess()\n\n    def _read_echo(self, fp):\n        from waitress.tests.fixtureapps import echo\n\n        line, headers, body = read_http(fp)\n        return line, headers, echo.parse_response(body)\n\n    def test_date_and_server(self):\n        to_send = \"GET / HTTP/1.0\\n\" \"Content-Length: 0\\n\\n\"\n        to_send = tobytes(to_send)\n        self.connect()\n        self.sock.send(to_send)\n        fp = self.sock.makefile(\"rb\", 0)\n        line, headers, echo = self._read_echo(fp)\n        self.assertline(line, \"200\", \"OK\", \"HTTP/1.0\")\n        self.assertEqual(headers.get(\"server\"), \"waitress\")\n        self.assertTrue(headers.get(\"date\"))\n\n    def test_bad_host_header(self):\n        # https://corte.si/posts/code/pathod/pythonservers/index.html\n        to_send = \"GET / HTTP/1.0\\n\" \" Host: 0\\n\\n\"\n        to_send = tobytes(to_send)\n        self.connect()\n        self.sock.send(to_send)\n        fp = self.sock.makefile(\"rb\", 0)\n        line, headers, response_body = read_http(fp)\n        self.assertline(line, \"400\", \"Bad Request\", \"HTTP/1.0\")\n        self.assertEqual(headers.get(\"server\"), \"waitress\")\n        self.assertTrue(headers.get(\"date\"))\n\n    def test_send_with_body(self):\n        to_send = \"GET / HTTP/1.0\\n\" \"Content-Length: 5\\n\\n\"\n        to_send += \"hello\"\n        to_send = tobytes(to_send)\n        self.connect()\n        self.sock.send(to_send)\n        fp = self.sock.makefile(\"rb\", 0)\n        line, headers, echo = self._read_echo(fp)\n        self.assertline(line, \"200\", \"OK\", \"HTTP/1.0\")\n        self.assertEqual(echo.content_length, \"5\")\n        self.assertEqual(echo.body, b\"hello\")\n\n    def test_send_empty_body(self):\n        to_send = \"GET / HTTP/1.0\\n\" \"Content-Length: 0\\n\\n\"\n        to_send = tobytes(to_send)\n        self.connect()\n        self.sock.send(to_send)\n        fp = self.sock.makefile(\"rb\", 0)\n        line, headers, echo = self._read_echo(fp)\n        self.assertline(line, \"200\", \"OK\", \"HTTP/1.0\")\n        self.assertEqual(echo.content_length, \"0\")\n        self.assertEqual(echo.body, b\"\")\n\n    def test_multiple_requests_with_body(self):\n        orig_sock = self.sock\n        for x in range(3):\n            self.sock = self.create_socket()\n            self.test_send_with_body()\n            self.sock.close()\n        self.sock = orig_sock\n\n    def test_multiple_requests_without_body(self):\n        orig_sock = self.sock\n        for x in range(3):\n            self.sock = self.create_socket()\n            self.test_send_empty_body()\n            self.sock.close()\n        self.sock = orig_sock\n\n    def test_without_crlf(self):\n        data = \"Echo\\nthis\\r\\nplease\"\n        s = tobytes(\n            \"GET / HTTP/1.0\\n\"\n            \"Connection: close\\n\"\n            \"Content-Length: %d\\n\"\n            \"\\n\"\n            \"%s\" % (len(data), data)\n        )\n        self.connect()\n        self.sock.send(s)\n        fp = self.sock.makefile(\"rb\", 0)\n        line, headers, echo = self._read_echo(fp)\n        self.assertline(line, \"200\", \"OK\", \"HTTP/1.0\")\n        self.assertEqual(int(echo.content_length), len(data))\n        self.assertEqual(len(echo.body), len(data))\n        self.assertEqual(echo.body, tobytes(data))\n\n    def test_large_body(self):\n        # 1024 characters.\n        body = \"This string has 32 characters.\\r\\n\" * 32\n        s = tobytes(\n            \"GET / HTTP/1.0\\n\" \"Content-Length: %d\\n\" \"\\n\" \"%s\" % (len(body), body)\n        )\n        self.connect()\n        self.sock.send(s)\n        fp = self.sock.makefile(\"rb\", 0)\n        line, headers, echo = self._read_echo(fp)\n        self.assertline(line, \"200\", \"OK\", \"HTTP/1.0\")\n        self.assertEqual(echo.content_length, \"1024\")\n        self.assertEqual(echo.body, tobytes(body))\n\n    def test_many_clients(self):\n        conns = []\n        for n in range(50):\n            h = self.make_http_connection()\n            h.request(\"GET\", \"/\", headers={\"Accept\": \"text/plain\"})\n            conns.append(h)\n        responses = []\n        for h in conns:\n            response = h.getresponse()\n            self.assertEqual(response.status, 200)\n            responses.append(response)\n        for response in responses:\n            response.read()\n        for h in conns:\n            h.close()\n\n    def test_chunking_request_without_content(self):\n        header = tobytes(\"GET / HTTP/1.1\\n\" \"Transfer-Encoding: chunked\\n\\n\")\n        self.connect()\n        self.sock.send(header)\n        self.sock.send(b\"0\\r\\n\\r\\n\")\n        fp = self.sock.makefile(\"rb\", 0)\n        line, headers, echo = self._read_echo(fp)\n        self.assertline(line, \"200\", \"OK\", \"HTTP/1.1\")\n        self.assertEqual(echo.body, b\"\")\n        self.assertEqual(echo.content_length, \"0\")\n        self.assertFalse(\"transfer-encoding\" in headers)\n\n    def test_chunking_request_with_content(self):\n        control_line = b\"20;\\r\\n\"  # 20 hex = 32 dec\n        s = b\"This string has 32 characters.\\r\\n\"\n        expected = s * 12\n        header = tobytes(\"GET / HTTP/1.1\\n\" \"Transfer-Encoding: chunked\\n\\n\")\n        self.connect()\n        self.sock.send(header)\n        fp = self.sock.makefile(\"rb\", 0)\n        for n in range(12):\n            self.sock.send(control_line)\n            self.sock.send(s)\n        self.sock.send(b\"0\\r\\n\\r\\n\")\n        line, headers, echo = self._read_echo(fp)\n        self.assertline(line, \"200\", \"OK\", \"HTTP/1.1\")\n        self.assertEqual(echo.body, expected)\n        self.assertEqual(echo.content_length, str(len(expected)))\n        self.assertFalse(\"transfer-encoding\" in headers)\n\n    def test_broken_chunked_encoding(self):\n        control_line = \"20;\\r\\n\"  # 20 hex = 32 dec\n        s = \"This string has 32 characters.\\r\\n\"\n        to_send = \"GET / HTTP/1.1\\nTransfer-Encoding: chunked\\n\\n\"\n        to_send += control_line + s\n        # garbage in input\n        to_send += \"GET / HTTP/1.1\\nTransfer-Encoding: chunked\\n\\n\"\n        to_send += control_line + s\n        to_send = tobytes(to_send)\n        self.connect()\n        self.sock.send(to_send)\n        fp = self.sock.makefile(\"rb\", 0)\n        line, headers, response_body = read_http(fp)\n        # receiver caught garbage and turned it into a 400\n        self.assertline(line, \"400\", \"Bad Request\", \"HTTP/1.1\")\n        cl = int(headers[\"content-length\"])\n        self.assertEqual(cl, len(response_body))\n        self.assertEqual(\n            sorted(headers.keys()), [\"content-length\", \"content-type\", \"date\", \"server\"]\n        )\n        self.assertEqual(headers[\"content-type\"], \"text/plain\")\n        # connection has been closed\n        self.send_check_error(to_send)\n        self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_keepalive_http_10(self):\n        # Handling of Keep-Alive within HTTP 1.0\n        data = \"Default: Don't keep me alive\"\n        s = tobytes(\n            \"GET / HTTP/1.0\\n\" \"Content-Length: %d\\n\" \"\\n\" \"%s\" % (len(data), data)\n        )\n        self.connect()\n        self.sock.send(s)\n        response = httplib.HTTPResponse(self.sock)\n        response.begin()\n        self.assertEqual(int(response.status), 200)\n        connection = response.getheader(\"Connection\", \"\")\n        # We sent no Connection: Keep-Alive header\n        # Connection: close (or no header) is default.\n        self.assertTrue(connection != \"Keep-Alive\")\n\n    def test_keepalive_http10_explicit(self):\n        # If header Connection: Keep-Alive is explicitly sent,\n        # we want to keept the connection open, we also need to return\n        # the corresponding header\n        data = \"Keep me alive\"\n        s = tobytes(\n            \"GET / HTTP/1.0\\n\"\n            \"Connection: Keep-Alive\\n\"\n            \"Content-Length: %d\\n\"\n            \"\\n\"\n            \"%s\" % (len(data), data)\n        )\n        self.connect()\n        self.sock.send(s)\n        response = httplib.HTTPResponse(self.sock)\n        response.begin()\n        self.assertEqual(int(response.status), 200)\n        connection = response.getheader(\"Connection\", \"\")\n        self.assertEqual(connection, \"Keep-Alive\")\n\n    def test_keepalive_http_11(self):\n        # Handling of Keep-Alive within HTTP 1.1\n\n        # All connections are kept alive, unless stated otherwise\n        data = \"Default: Keep me alive\"\n        s = tobytes(\n            \"GET / HTTP/1.1\\n\" \"Content-Length: %d\\n\" \"\\n\" \"%s\" % (len(data), data)\n        )\n        self.connect()\n        self.sock.send(s)\n        response = httplib.HTTPResponse(self.sock)\n        response.begin()\n        self.assertEqual(int(response.status), 200)\n        self.assertTrue(response.getheader(\"connection\") != \"close\")\n\n    def test_keepalive_http11_explicit(self):\n        # Explicitly set keep-alive\n        data = \"Default: Keep me alive\"\n        s = tobytes(\n            \"GET / HTTP/1.1\\n\"\n            \"Connection: keep-alive\\n\"\n            \"Content-Length: %d\\n\"\n            \"\\n\"\n            \"%s\" % (len(data), data)\n        )\n        self.connect()\n        self.sock.send(s)\n        response = httplib.HTTPResponse(self.sock)\n        response.begin()\n        self.assertEqual(int(response.status), 200)\n        self.assertTrue(response.getheader(\"connection\") != \"close\")\n\n    def test_keepalive_http11_connclose(self):\n        # specifying Connection: close explicitly\n        data = \"Don't keep me alive\"\n        s = tobytes(\n            \"GET / HTTP/1.1\\n\"\n            \"Connection: close\\n\"\n            \"Content-Length: %d\\n\"\n            \"\\n\"\n            \"%s\" % (len(data), data)\n        )\n        self.connect()\n        self.sock.send(s)\n        response = httplib.HTTPResponse(self.sock)\n        response.begin()\n        self.assertEqual(int(response.status), 200)\n        self.assertEqual(response.getheader(\"connection\"), \"close\")\n\n    def test_proxy_headers(self):\n        to_send = (\n            \"GET / HTTP/1.0\\n\"\n            \"Content-Length: 0\\n\"\n            \"Host: www.google.com:8080\\n\"\n            \"X-Forwarded-For: 192.168.1.1\\n\"\n            \"X-Forwarded-Proto: https\\n\"\n            \"X-Forwarded-Port: 5000\\n\\n\"\n        )\n        to_send = tobytes(to_send)\n        self.connect()\n        self.sock.send(to_send)\n        fp = self.sock.makefile(\"rb\", 0)\n        line, headers, echo = self._read_echo(fp)\n        self.assertline(line, \"200\", \"OK\", \"HTTP/1.0\")\n        self.assertEqual(headers.get(\"server\"), \"waitress\")\n        self.assertTrue(headers.get(\"date\"))\n        self.assertIsNone(echo.headers.get(\"X_FORWARDED_PORT\"))\n        self.assertEqual(echo.headers[\"HOST\"], \"www.google.com:8080\")\n        self.assertEqual(echo.scheme, \"https\")\n        self.assertEqual(echo.remote_addr, \"192.168.1.1\")\n        self.assertEqual(echo.remote_host, \"192.168.1.1\")\n\n\nclass PipeliningTests(object):\n    def setUp(self):\n        from waitress.tests.fixtureapps import echo\n\n        self.start_subprocess(echo.app_body_only)\n\n    def tearDown(self):\n        self.stop_subprocess()\n\n    def test_pipelining(self):\n        s = (\n            \"GET / HTTP/1.0\\r\\n\"\n            \"Connection: %s\\r\\n\"\n            \"Content-Length: %d\\r\\n\"\n            \"\\r\\n\"\n            \"%s\"\n        )\n        to_send = b\"\"\n        count = 25\n        for n in range(count):\n            body = \"Response #%d\\r\\n\" % (n + 1)\n            if n + 1 < count:\n                conn = \"keep-alive\"\n            else:\n                conn = \"close\"\n            to_send += tobytes(s % (conn, len(body), body))\n\n        self.connect()\n        self.sock.send(to_send)\n        fp = self.sock.makefile(\"rb\", 0)\n        for n in range(count):\n            expect_body = tobytes(\"Response #%d\\r\\n\" % (n + 1))\n            line = fp.readline()  # status line\n            version, status, reason = (x.strip() for x in line.split(None, 2))\n            headers = parse_headers(fp)\n            length = int(headers.get(\"content-length\")) or None\n            response_body = fp.read(length)\n            self.assertEqual(int(status), 200)\n            self.assertEqual(length, len(response_body))\n            self.assertEqual(response_body, expect_body)\n\n\nclass ExpectContinueTests(object):\n    def setUp(self):\n        from waitress.tests.fixtureapps import echo\n\n        self.start_subprocess(echo.app_body_only)\n\n    def tearDown(self):\n        self.stop_subprocess()\n\n    def test_expect_continue(self):\n        # specifying Connection: close explicitly\n        data = \"I have expectations\"\n        to_send = tobytes(\n            \"GET / HTTP/1.1\\n\"\n            \"Connection: close\\n\"\n            \"Content-Length: %d\\n\"\n            \"Expect: 100-continue\\n\"\n            \"\\n\"\n            \"%s\" % (len(data), data)\n        )\n        self.connect()\n        self.sock.send(to_send)\n        fp = self.sock.makefile(\"rb\", 0)\n        line = fp.readline()  # continue status line\n        version, status, reason = (x.strip() for x in line.split(None, 2))\n        self.assertEqual(int(status), 100)\n        self.assertEqual(reason, b\"Continue\")\n        self.assertEqual(version, b\"HTTP/1.1\")\n        fp.readline()  # blank line\n        line = fp.readline()  # next status line\n        version, status, reason = (x.strip() for x in line.split(None, 2))\n        headers = parse_headers(fp)\n        length = int(headers.get(\"content-length\")) or None\n        response_body = fp.read(length)\n        self.assertEqual(int(status), 200)\n        self.assertEqual(length, len(response_body))\n        self.assertEqual(response_body, tobytes(data))\n\n\nclass BadContentLengthTests(object):\n    def setUp(self):\n        from waitress.tests.fixtureapps import badcl\n\n        self.start_subprocess(badcl.app)\n\n    def tearDown(self):\n        self.stop_subprocess()\n\n    def test_short_body(self):\n        # check to see if server closes connection when body is too short\n        # for cl header\n        to_send = tobytes(\n            \"GET /short_body HTTP/1.0\\n\"\n            \"Connection: Keep-Alive\\n\"\n            \"Content-Length: 0\\n\"\n            \"\\n\"\n        )\n        self.connect()\n        self.sock.send(to_send)\n        fp = self.sock.makefile(\"rb\", 0)\n        line = fp.readline()  # status line\n        version, status, reason = (x.strip() for x in line.split(None, 2))\n        headers = parse_headers(fp)\n        content_length = int(headers.get(\"content-length\"))\n        response_body = fp.read(content_length)\n        self.assertEqual(int(status), 200)\n        self.assertNotEqual(content_length, len(response_body))\n        self.assertEqual(len(response_body), content_length - 1)\n        self.assertEqual(response_body, tobytes(\"abcdefghi\"))\n        # remote closed connection (despite keepalive header); not sure why\n        # first send succeeds\n        self.send_check_error(to_send)\n        self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_long_body(self):\n        # check server doesnt close connection when body is too short\n        # for cl header\n        to_send = tobytes(\n            \"GET /long_body HTTP/1.0\\n\"\n            \"Connection: Keep-Alive\\n\"\n            \"Content-Length: 0\\n\"\n            \"\\n\"\n        )\n        self.connect()\n        self.sock.send(to_send)\n        fp = self.sock.makefile(\"rb\", 0)\n        line = fp.readline()  # status line\n        version, status, reason = (x.strip() for x in line.split(None, 2))\n        headers = parse_headers(fp)\n        content_length = int(headers.get(\"content-length\")) or None\n        response_body = fp.read(content_length)\n        self.assertEqual(int(status), 200)\n        self.assertEqual(content_length, len(response_body))\n        self.assertEqual(response_body, tobytes(\"abcdefgh\"))\n        # remote does not close connection (keepalive header)\n        self.sock.send(to_send)\n        fp = self.sock.makefile(\"rb\", 0)\n        line = fp.readline()  # status line\n        version, status, reason = (x.strip() for x in line.split(None, 2))\n        headers = parse_headers(fp)\n        content_length = int(headers.get(\"content-length\")) or None\n        response_body = fp.read(content_length)\n        self.assertEqual(int(status), 200)\n\n\nclass NoContentLengthTests(object):\n    def setUp(self):\n        from waitress.tests.fixtureapps import nocl\n\n        self.start_subprocess(nocl.app)\n\n    def tearDown(self):\n        self.stop_subprocess()\n\n    def test_http10_generator(self):\n        body = string.ascii_letters\n        to_send = (\n            \"GET / HTTP/1.0\\n\"\n            \"Connection: Keep-Alive\\n\"\n            \"Content-Length: %d\\n\\n\" % len(body)\n        )\n        to_send += body\n        to_send = tobytes(to_send)\n        self.connect()\n        self.sock.send(to_send)\n        fp = self.sock.makefile(\"rb\", 0)\n        line, headers, response_body = read_http(fp)\n        self.assertline(line, \"200\", \"OK\", \"HTTP/1.0\")\n        self.assertEqual(headers.get(\"content-length\"), None)\n        self.assertEqual(headers.get(\"connection\"), \"close\")\n        self.assertEqual(response_body, tobytes(body))\n        # remote closed connection (despite keepalive header), because\n        # generators cannot have a content-length divined\n        self.send_check_error(to_send)\n        self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_http10_list(self):\n        body = string.ascii_letters\n        to_send = (\n            \"GET /list HTTP/1.0\\n\"\n            \"Connection: Keep-Alive\\n\"\n            \"Content-Length: %d\\n\\n\" % len(body)\n        )\n        to_send += body\n        to_send = tobytes(to_send)\n        self.connect()\n        self.sock.send(to_send)\n        fp = self.sock.makefile(\"rb\", 0)\n        line, headers, response_body = read_http(fp)\n        self.assertline(line, \"200\", \"OK\", \"HTTP/1.0\")\n        self.assertEqual(headers[\"content-length\"], str(len(body)))\n        self.assertEqual(headers.get(\"connection\"), \"Keep-Alive\")\n        self.assertEqual(response_body, tobytes(body))\n        # remote keeps connection open because it divined the content length\n        # from a length-1 list\n        self.sock.send(to_send)\n        line, headers, response_body = read_http(fp)\n        self.assertline(line, \"200\", \"OK\", \"HTTP/1.0\")\n\n    def test_http10_listlentwo(self):\n        body = string.ascii_letters\n        to_send = (\n            \"GET /list_lentwo HTTP/1.0\\n\"\n            \"Connection: Keep-Alive\\n\"\n            \"Content-Length: %d\\n\\n\" % len(body)\n        )\n        to_send += body\n        to_send = tobytes(to_send)\n        self.connect()\n        self.sock.send(to_send)\n        fp = self.sock.makefile(\"rb\", 0)\n        line, headers, response_body = read_http(fp)\n        self.assertline(line, \"200\", \"OK\", \"HTTP/1.0\")\n        self.assertEqual(headers.get(\"content-length\"), None)\n        self.assertEqual(headers.get(\"connection\"), \"close\")\n        self.assertEqual(response_body, tobytes(body))\n        # remote closed connection (despite keepalive header), because\n        # lists of length > 1 cannot have their content length divined\n        self.send_check_error(to_send)\n        self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_http11_generator(self):\n        body = string.ascii_letters\n        to_send = \"GET / HTTP/1.1\\n\" \"Content-Length: %s\\n\\n\" % len(body)\n        to_send += body\n        to_send = tobytes(to_send)\n        self.connect()\n        self.sock.send(to_send)\n        fp = self.sock.makefile(\"rb\")\n        line, headers, response_body = read_http(fp)\n        self.assertline(line, \"200\", \"OK\", \"HTTP/1.1\")\n        expected = b\"\"\n        for chunk in chunks(body, 10):\n            expected += tobytes(\n                \"%s\\r\\n%s\\r\\n\" % (str(hex(len(chunk))[2:].upper()), chunk)\n            )\n        expected += b\"0\\r\\n\\r\\n\"\n        self.assertEqual(response_body, expected)\n        # connection is always closed at the end of a chunked response\n        self.send_check_error(to_send)\n        self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_http11_list(self):\n        body = string.ascii_letters\n        to_send = \"GET /list HTTP/1.1\\n\" \"Content-Length: %d\\n\\n\" % len(body)\n        to_send += body\n        to_send = tobytes(to_send)\n        self.connect()\n        self.sock.send(to_send)\n        fp = self.sock.makefile(\"rb\", 0)\n        line, headers, response_body = read_http(fp)\n        self.assertline(line, \"200\", \"OK\", \"HTTP/1.1\")\n        self.assertEqual(headers[\"content-length\"], str(len(body)))\n        self.assertEqual(response_body, tobytes(body))\n        # remote keeps connection open because it divined the content length\n        # from a length-1 list\n        self.sock.send(to_send)\n        line, headers, response_body = read_http(fp)\n        self.assertline(line, \"200\", \"OK\", \"HTTP/1.1\")\n\n    def test_http11_listlentwo(self):\n        body = string.ascii_letters\n        to_send = \"GET /list_lentwo HTTP/1.1\\n\" \"Content-Length: %s\\n\\n\" % len(body)\n        to_send += body\n        to_send = tobytes(to_send)\n        self.connect()\n        self.sock.send(to_send)\n        fp = self.sock.makefile(\"rb\")\n        line, headers, response_body = read_http(fp)\n        self.assertline(line, \"200\", \"OK\", \"HTTP/1.1\")\n        expected = b\"\"\n        for chunk in (body[0], body[1:]):\n            expected += tobytes(\n                \"%s\\r\\n%s\\r\\n\" % (str(hex(len(chunk))[2:].upper()), chunk)\n            )\n        expected += b\"0\\r\\n\\r\\n\"\n        self.assertEqual(response_body, expected)\n        # connection is always closed at the end of a chunked response\n        self.send_check_error(to_send)\n        self.assertRaises(ConnectionClosed, read_http, fp)\n\n\nclass WriteCallbackTests(object):\n    def setUp(self):\n        from waitress.tests.fixtureapps import writecb\n\n        self.start_subprocess(writecb.app)\n\n    def tearDown(self):\n        self.stop_subprocess()\n\n    def test_short_body(self):\n        # check to see if server closes connection when body is too short\n        # for cl header\n        to_send = tobytes(\n            \"GET /short_body HTTP/1.0\\n\"\n            \"Connection: Keep-Alive\\n\"\n            \"Content-Length: 0\\n\"\n            \"\\n\"\n        )\n        self.connect()\n        self.sock.send(to_send)\n        fp = self.sock.makefile(\"rb\", 0)\n        line, headers, response_body = read_http(fp)\n        # server trusts the content-length header (5)\n        self.assertline(line, \"200\", \"OK\", \"HTTP/1.0\")\n        cl = int(headers[\"content-length\"])\n        self.assertEqual(cl, 9)\n        self.assertNotEqual(cl, len(response_body))\n        self.assertEqual(len(response_body), cl - 1)\n        self.assertEqual(response_body, tobytes(\"abcdefgh\"))\n        # remote closed connection (despite keepalive header)\n        self.send_check_error(to_send)\n        self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_long_body(self):\n        # check server doesnt close connection when body is too long\n        # for cl header\n        to_send = tobytes(\n            \"GET /long_body HTTP/1.0\\n\"\n            \"Connection: Keep-Alive\\n\"\n            \"Content-Length: 0\\n\"\n            \"\\n\"\n        )\n        self.connect()\n        self.sock.send(to_send)\n        fp = self.sock.makefile(\"rb\", 0)\n        line, headers, response_body = read_http(fp)\n        content_length = int(headers.get(\"content-length\")) or None\n        self.assertEqual(content_length, 9)\n        self.assertEqual(content_length, len(response_body))\n        self.assertEqual(response_body, tobytes(\"abcdefghi\"))\n        # remote does not close connection (keepalive header)\n        self.sock.send(to_send)\n        fp = self.sock.makefile(\"rb\", 0)\n        line, headers, response_body = read_http(fp)\n        self.assertline(line, \"200\", \"OK\", \"HTTP/1.0\")\n\n    def test_equal_body(self):\n        # check server doesnt close connection when body is equal to\n        # cl header\n        to_send = tobytes(\n            \"GET /equal_body HTTP/1.0\\n\"\n            \"Connection: Keep-Alive\\n\"\n            \"Content-Length: 0\\n\"\n            \"\\n\"\n        )\n        self.connect()\n        self.sock.send(to_send)\n        fp = self.sock.makefile(\"rb\", 0)\n        line, headers, response_body = read_http(fp)\n        content_length = int(headers.get(\"content-length\")) or None\n        self.assertEqual(content_length, 9)\n        self.assertline(line, \"200\", \"OK\", \"HTTP/1.0\")\n        self.assertEqual(content_length, len(response_body))\n        self.assertEqual(response_body, tobytes(\"abcdefghi\"))\n        # remote does not close connection (keepalive header)\n        self.sock.send(to_send)\n        fp = self.sock.makefile(\"rb\", 0)\n        line, headers, response_body = read_http(fp)\n        self.assertline(line, \"200\", \"OK\", \"HTTP/1.0\")\n\n    def test_no_content_length(self):\n        # wtf happens when there's no content-length\n        to_send = tobytes(\n            \"GET /no_content_length HTTP/1.0\\n\"\n            \"Connection: Keep-Alive\\n\"\n            \"Content-Length: 0\\n\"\n            \"\\n\"\n        )\n        self.connect()\n        self.sock.send(to_send)\n        fp = self.sock.makefile(\"rb\", 0)\n        line = fp.readline()  # status line\n        line, headers, response_body = read_http(fp)\n        content_length = headers.get(\"content-length\")\n        self.assertEqual(content_length, None)\n        self.assertEqual(response_body, tobytes(\"abcdefghi\"))\n        # remote closed connection (despite keepalive header)\n        self.send_check_error(to_send)\n        self.assertRaises(ConnectionClosed, read_http, fp)\n\n\nclass TooLargeTests(object):\n\n    toobig = 1050\n\n    def setUp(self):\n        from waitress.tests.fixtureapps import toolarge\n\n        self.start_subprocess(\n            toolarge.app, max_request_header_size=1000, max_request_body_size=1000\n        )\n\n    def tearDown(self):\n        self.stop_subprocess()\n\n    def test_request_body_too_large_with_wrong_cl_http10(self):\n        body = \"a\" * self.toobig\n        to_send = \"GET / HTTP/1.0\\n\" \"Content-Length: 5\\n\\n\"\n        to_send += body\n        to_send = tobytes(to_send)\n        self.connect()\n        self.sock.send(to_send)\n        fp = self.sock.makefile(\"rb\")\n        # first request succeeds (content-length 5)\n        line, headers, response_body = read_http(fp)\n        self.assertline(line, \"200\", \"OK\", \"HTTP/1.0\")\n        cl = int(headers[\"content-length\"])\n        self.assertEqual(cl, len(response_body))\n        # server trusts the content-length header; no pipelining,\n        # so request fulfilled, extra bytes are thrown away\n        # connection has been closed\n        self.send_check_error(to_send)\n        self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_request_body_too_large_with_wrong_cl_http10_keepalive(self):\n        body = \"a\" * self.toobig\n        to_send = \"GET / HTTP/1.0\\n\" \"Content-Length: 5\\n\" \"Connection: Keep-Alive\\n\\n\"\n        to_send += body\n        to_send = tobytes(to_send)\n        self.connect()\n        self.sock.send(to_send)\n        fp = self.sock.makefile(\"rb\")\n        # first request succeeds (content-length 5)\n        line, headers, response_body = read_http(fp)\n        self.assertline(line, \"200\", \"OK\", \"HTTP/1.0\")\n        cl = int(headers[\"content-length\"])\n        self.assertEqual(cl, len(response_body))\n        line, headers, response_body = read_http(fp)\n        self.assertline(line, \"431\", \"Request Header Fields Too Large\", \"HTTP/1.0\")\n        cl = int(headers[\"content-length\"])\n        self.assertEqual(cl, len(response_body))\n        # connection has been closed\n        self.send_check_error(to_send)\n        self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_request_body_too_large_with_no_cl_http10(self):\n        body = \"a\" * self.toobig\n        to_send = \"GET / HTTP/1.0\\n\\n\"\n        to_send += body\n        to_send = tobytes(to_send)\n        self.connect()\n        self.sock.send(to_send)\n        fp = self.sock.makefile(\"rb\", 0)\n        line, headers, response_body = read_http(fp)\n        self.assertline(line, \"200\", \"OK\", \"HTTP/1.0\")\n        cl = int(headers[\"content-length\"])\n        self.assertEqual(cl, len(response_body))\n        # extra bytes are thrown away (no pipelining), connection closed\n        self.send_check_error(to_send)\n        self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_request_body_too_large_with_no_cl_http10_keepalive(self):\n        body = \"a\" * self.toobig\n        to_send = \"GET / HTTP/1.0\\nConnection: Keep-Alive\\n\\n\"\n        to_send += body\n        to_send = tobytes(to_send)\n        self.connect()\n        self.sock.send(to_send)\n        fp = self.sock.makefile(\"rb\", 0)\n        line, headers, response_body = read_http(fp)\n        # server trusts the content-length header (assumed zero)\n        self.assertline(line, \"200\", \"OK\", \"HTTP/1.0\")\n        cl = int(headers[\"content-length\"])\n        self.assertEqual(cl, len(response_body))\n        line, headers, response_body = read_http(fp)\n        # next response overruns because the extra data appears to be\n        # header data\n        self.assertline(line, \"431\", \"Request Header Fields Too Large\", \"HTTP/1.0\")\n        cl = int(headers[\"content-length\"])\n        self.assertEqual(cl, len(response_body))\n        # connection has been closed\n        self.send_check_error(to_send)\n        self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_request_body_too_large_with_wrong_cl_http11(self):\n        body = \"a\" * self.toobig\n        to_send = \"GET / HTTP/1.1\\n\" \"Content-Length: 5\\n\\n\"\n        to_send += body\n        to_send = tobytes(to_send)\n        self.connect()\n        self.sock.send(to_send)\n        fp = self.sock.makefile(\"rb\")\n        # first request succeeds (content-length 5)\n        line, headers, response_body = read_http(fp)\n        self.assertline(line, \"200\", \"OK\", \"HTTP/1.1\")\n        cl = int(headers[\"content-length\"])\n        self.assertEqual(cl, len(response_body))\n        # second response is an error response\n        line, headers, response_body = read_http(fp)\n        self.assertline(line, \"431\", \"Request Header Fields Too Large\", \"HTTP/1.0\")\n        cl = int(headers[\"content-length\"])\n        self.assertEqual(cl, len(response_body))\n        # connection has been closed\n        self.send_check_error(to_send)\n        self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_request_body_too_large_with_wrong_cl_http11_connclose(self):\n        body = \"a\" * self.toobig\n        to_send = \"GET / HTTP/1.1\\nContent-Length: 5\\nConnection: close\\n\\n\"\n        to_send += body\n        to_send = tobytes(to_send)\n        self.connect()\n        self.sock.send(to_send)\n        fp = self.sock.makefile(\"rb\", 0)\n        line, headers, response_body = read_http(fp)\n        # server trusts the content-length header (5)\n        self.assertline(line, \"200\", \"OK\", \"HTTP/1.1\")\n        cl = int(headers[\"content-length\"])\n        self.assertEqual(cl, len(response_body))\n        # connection has been closed\n        self.send_check_error(to_send)\n        self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_request_body_too_large_with_no_cl_http11(self):\n        body = \"a\" * self.toobig\n        to_send = \"GET / HTTP/1.1\\n\\n\"\n        to_send += body\n        to_send = tobytes(to_send)\n        self.connect()\n        self.sock.send(to_send)\n        fp = self.sock.makefile(\"rb\")\n        # server trusts the content-length header (assumed 0)\n        line, headers, response_body = read_http(fp)\n        self.assertline(line, \"200\", \"OK\", \"HTTP/1.1\")\n        cl = int(headers[\"content-length\"])\n        self.assertEqual(cl, len(response_body))\n        # server assumes pipelined requests due to http/1.1, and the first\n        # request was assumed c-l 0 because it had no content-length header,\n        # so entire body looks like the header of the subsequent request\n        # second response is an error response\n        line, headers, response_body = read_http(fp)\n        self.assertline(line, \"431\", \"Request Header Fields Too Large\", \"HTTP/1.0\")\n        cl = int(headers[\"content-length\"])\n        self.assertEqual(cl, len(response_body))\n        # connection has been closed\n        self.send_check_error(to_send)\n        self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_request_body_too_large_with_no_cl_http11_connclose(self):\n        body = \"a\" * self.toobig\n        to_send = \"GET / HTTP/1.1\\nConnection: close\\n\\n\"\n        to_send += body\n        to_send = tobytes(to_send)\n        self.connect()\n        self.sock.send(to_send)\n        fp = self.sock.makefile(\"rb\", 0)\n        line, headers, response_body = read_http(fp)\n        # server trusts the content-length header (assumed 0)\n        self.assertline(line, \"200\", \"OK\", \"HTTP/1.1\")\n        cl = int(headers[\"content-length\"])\n        self.assertEqual(cl, len(response_body))\n        # connection has been closed\n        self.send_check_error(to_send)\n        self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_request_body_too_large_chunked_encoding(self):\n        control_line = \"20;\\r\\n\"  # 20 hex = 32 dec\n        s = \"This string has 32 characters.\\r\\n\"\n        to_send = \"GET / HTTP/1.1\\nTransfer-Encoding: chunked\\n\\n\"\n        repeat = control_line + s\n        to_send += repeat * ((self.toobig // len(repeat)) + 1)\n        to_send = tobytes(to_send)\n        self.connect()\n        self.sock.send(to_send)\n        fp = self.sock.makefile(\"rb\", 0)\n        line, headers, response_body = read_http(fp)\n        # body bytes counter caught a max_request_body_size overrun\n        self.assertline(line, \"413\", \"Request Entity Too Large\", \"HTTP/1.1\")\n        cl = int(headers[\"content-length\"])\n        self.assertEqual(cl, len(response_body))\n        self.assertEqual(headers[\"content-type\"], \"text/plain\")\n        # connection has been closed\n        self.send_check_error(to_send)\n        self.assertRaises(ConnectionClosed, read_http, fp)\n\n\nclass InternalServerErrorTests(object):\n    def setUp(self):\n        from waitress.tests.fixtureapps import error\n\n        self.start_subprocess(error.app, expose_tracebacks=True)\n\n    def tearDown(self):\n        self.stop_subprocess()\n\n    def test_before_start_response_http_10(self):\n        to_send = \"GET /before_start_response HTTP/1.0\\n\\n\"\n        to_send = tobytes(to_send)\n        self.connect()\n        self.sock.send(to_send)\n        fp = self.sock.makefile(\"rb\", 0)\n        line, headers, response_body = read_http(fp)\n        self.assertline(line, \"500\", \"Internal Server Error\", \"HTTP/1.0\")\n        cl = int(headers[\"content-length\"])\n        self.assertEqual(cl, len(response_body))\n        self.assertTrue(response_body.startswith(b\"Internal Server Error\"))\n        self.assertEqual(headers[\"connection\"], \"close\")\n        # connection has been closed\n        self.send_check_error(to_send)\n        self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_before_start_response_http_11(self):\n        to_send = \"GET /before_start_response HTTP/1.1\\n\\n\"\n        to_send = tobytes(to_send)\n        self.connect()\n        self.sock.send(to_send)\n        fp = self.sock.makefile(\"rb\", 0)\n        line, headers, response_body = read_http(fp)\n        self.assertline(line, \"500\", \"Internal Server Error\", \"HTTP/1.1\")\n        cl = int(headers[\"content-length\"])\n        self.assertEqual(cl, len(response_body))\n        self.assertTrue(response_body.startswith(b\"Internal Server Error\"))\n        self.assertEqual(\n            sorted(headers.keys()), [\"content-length\", \"content-type\", \"date\", \"server\"]\n        )\n        # connection has been closed\n        self.send_check_error(to_send)\n        self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_before_start_response_http_11_close(self):\n        to_send = tobytes(\n            \"GET /before_start_response HTTP/1.1\\n\" \"Connection: close\\n\\n\"\n        )\n        self.connect()\n        self.sock.send(to_send)\n        fp = self.sock.makefile(\"rb\", 0)\n        line, headers, response_body = read_http(fp)\n        self.assertline(line, \"500\", \"Internal Server Error\", \"HTTP/1.1\")\n        cl = int(headers[\"content-length\"])\n        self.assertEqual(cl, len(response_body))\n        self.assertTrue(response_body.startswith(b\"Internal Server Error\"))\n        self.assertEqual(\n            sorted(headers.keys()),\n            [\"connection\", \"content-length\", \"content-type\", \"date\", \"server\"],\n        )\n        self.assertEqual(headers[\"connection\"], \"close\")\n        # connection has been closed\n        self.send_check_error(to_send)\n        self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_after_start_response_http10(self):\n        to_send = \"GET /after_start_response HTTP/1.0\\n\\n\"\n        to_send = tobytes(to_send)\n        self.connect()\n        self.sock.send(to_send)\n        fp = self.sock.makefile(\"rb\", 0)\n        line, headers, response_body = read_http(fp)\n        self.assertline(line, \"500\", \"Internal Server Error\", \"HTTP/1.0\")\n        cl = int(headers[\"content-length\"])\n        self.assertEqual(cl, len(response_body))\n        self.assertTrue(response_body.startswith(b\"Internal Server Error\"))\n        self.assertEqual(\n            sorted(headers.keys()),\n            [\"connection\", \"content-length\", \"content-type\", \"date\", \"server\"],\n        )\n        self.assertEqual(headers[\"connection\"], \"close\")\n        # connection has been closed\n        self.send_check_error(to_send)\n        self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_after_start_response_http11(self):\n        to_send = \"GET /after_start_response HTTP/1.1\\n\\n\"\n        to_send = tobytes(to_send)\n        self.connect()\n        self.sock.send(to_send)\n        fp = self.sock.makefile(\"rb\", 0)\n        line, headers, response_body = read_http(fp)\n        self.assertline(line, \"500\", \"Internal Server Error\", \"HTTP/1.1\")\n        cl = int(headers[\"content-length\"])\n        self.assertEqual(cl, len(response_body))\n        self.assertTrue(response_body.startswith(b\"Internal Server Error\"))\n        self.assertEqual(\n            sorted(headers.keys()), [\"content-length\", \"content-type\", \"date\", \"server\"]\n        )\n        # connection has been closed\n        self.send_check_error(to_send)\n        self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_after_start_response_http11_close(self):\n        to_send = tobytes(\n            \"GET /after_start_response HTTP/1.1\\n\" \"Connection: close\\n\\n\"\n        )\n        self.connect()\n        self.sock.send(to_send)\n        fp = self.sock.makefile(\"rb\", 0)\n        line, headers, response_body = read_http(fp)\n        self.assertline(line, \"500\", \"Internal Server Error\", \"HTTP/1.1\")\n        cl = int(headers[\"content-length\"])\n        self.assertEqual(cl, len(response_body))\n        self.assertTrue(response_body.startswith(b\"Internal Server Error\"))\n        self.assertEqual(\n            sorted(headers.keys()),\n            [\"connection\", \"content-length\", \"content-type\", \"date\", \"server\"],\n        )\n        self.assertEqual(headers[\"connection\"], \"close\")\n        # connection has been closed\n        self.send_check_error(to_send)\n        self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_after_write_cb(self):\n        to_send = \"GET /after_write_cb HTTP/1.1\\n\\n\"\n        to_send = tobytes(to_send)\n        self.connect()\n        self.sock.send(to_send)\n        fp = self.sock.makefile(\"rb\", 0)\n        line, headers, response_body = read_http(fp)\n        self.assertline(line, \"200\", \"OK\", \"HTTP/1.1\")\n        self.assertEqual(response_body, b\"\")\n        # connection has been closed\n        self.send_check_error(to_send)\n        self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_in_generator(self):\n        to_send = \"GET /in_generator HTTP/1.1\\n\\n\"\n        to_send = tobytes(to_send)\n        self.connect()\n        self.sock.send(to_send)\n        fp = self.sock.makefile(\"rb\", 0)\n        line, headers, response_body = read_http(fp)\n        self.assertline(line, \"200\", \"OK\", \"HTTP/1.1\")\n        self.assertEqual(response_body, b\"\")\n        # connection has been closed\n        self.send_check_error(to_send)\n        self.assertRaises(ConnectionClosed, read_http, fp)\n\n\nclass FileWrapperTests(object):\n    def setUp(self):\n        from waitress.tests.fixtureapps import filewrapper\n\n        self.start_subprocess(filewrapper.app)\n\n    def tearDown(self):\n        self.stop_subprocess()\n\n    def test_filelike_http11(self):\n        to_send = \"GET /filelike HTTP/1.1\\n\\n\"\n        to_send = tobytes(to_send)\n\n        self.connect()\n\n        for t in range(0, 2):\n            self.sock.send(to_send)\n            fp = self.sock.makefile(\"rb\", 0)\n            line, headers, response_body = read_http(fp)\n            self.assertline(line, \"200\", \"OK\", \"HTTP/1.1\")\n            cl = int(headers[\"content-length\"])\n            self.assertEqual(cl, len(response_body))\n            ct = headers[\"content-type\"]\n            self.assertEqual(ct, \"image/jpeg\")\n            self.assertTrue(b\"\\377\\330\\377\" in response_body)\n            # connection has not been closed\n\n    def test_filelike_nocl_http11(self):\n        to_send = \"GET /filelike_nocl HTTP/1.1\\n\\n\"\n        to_send = tobytes(to_send)\n\n        self.connect()\n\n        for t in range(0, 2):\n            self.sock.send(to_send)\n            fp = self.sock.makefile(\"rb\", 0)\n            line, headers, response_body = read_http(fp)\n            self.assertline(line, \"200\", \"OK\", \"HTTP/1.1\")\n            cl = int(headers[\"content-length\"])\n            self.assertEqual(cl, len(response_body))\n            ct = headers[\"content-type\"]\n            self.assertEqual(ct, \"image/jpeg\")\n            self.assertTrue(b\"\\377\\330\\377\" in response_body)\n            # connection has not been closed\n\n    def test_filelike_shortcl_http11(self):\n        to_send = \"GET /filelike_shortcl HTTP/1.1\\n\\n\"\n        to_send = tobytes(to_send)\n\n        self.connect()\n\n        for t in range(0, 2):\n            self.sock.send(to_send)\n            fp = self.sock.makefile(\"rb\", 0)\n            line, headers, response_body = read_http(fp)\n            self.assertline(line, \"200\", \"OK\", \"HTTP/1.1\")\n            cl = int(headers[\"content-length\"])\n            self.assertEqual(cl, 1)\n            self.assertEqual(cl, len(response_body))\n            ct = headers[\"content-type\"]\n            self.assertEqual(ct, \"image/jpeg\")\n            self.assertTrue(b\"\\377\" in response_body)\n            # connection has not been closed\n\n    def test_filelike_longcl_http11(self):\n        to_send = \"GET /filelike_longcl HTTP/1.1\\n\\n\"\n        to_send = tobytes(to_send)\n\n        self.connect()\n\n        for t in range(0, 2):\n            self.sock.send(to_send)\n            fp = self.sock.makefile(\"rb\", 0)\n            line, headers, response_body = read_http(fp)\n            self.assertline(line, \"200\", \"OK\", \"HTTP/1.1\")\n            cl = int(headers[\"content-length\"])\n            self.assertEqual(cl, len(response_body))\n            ct = headers[\"content-type\"]\n            self.assertEqual(ct, \"image/jpeg\")\n            self.assertTrue(b\"\\377\\330\\377\" in response_body)\n            # connection has not been closed\n\n    def test_notfilelike_http11(self):\n        to_send = \"GET /notfilelike HTTP/1.1\\n\\n\"\n        to_send = tobytes(to_send)\n\n        self.connect()\n\n        for t in range(0, 2):\n            self.sock.send(to_send)\n            fp = self.sock.makefile(\"rb\", 0)\n            line, headers, response_body = read_http(fp)\n            self.assertline(line, \"200\", \"OK\", \"HTTP/1.1\")\n            cl = int(headers[\"content-length\"])\n            self.assertEqual(cl, len(response_body))\n            ct = headers[\"content-type\"]\n            self.assertEqual(ct, \"image/jpeg\")\n            self.assertTrue(b\"\\377\\330\\377\" in response_body)\n            # connection has not been closed\n\n    def test_notfilelike_iobase_http11(self):\n        to_send = \"GET /notfilelike_iobase HTTP/1.1\\n\\n\"\n        to_send = tobytes(to_send)\n\n        self.connect()\n\n        for t in range(0, 2):\n            self.sock.send(to_send)\n            fp = self.sock.makefile(\"rb\", 0)\n            line, headers, response_body = read_http(fp)\n            self.assertline(line, \"200\", \"OK\", \"HTTP/1.1\")\n            cl = int(headers[\"content-length\"])\n            self.assertEqual(cl, len(response_body))\n            ct = headers[\"content-type\"]\n            self.assertEqual(ct, \"image/jpeg\")\n            self.assertTrue(b\"\\377\\330\\377\" in response_body)\n            # connection has not been closed\n\n    def test_notfilelike_nocl_http11(self):\n        to_send = \"GET /notfilelike_nocl HTTP/1.1\\n\\n\"\n        to_send = tobytes(to_send)\n\n        self.connect()\n\n        self.sock.send(to_send)\n        fp = self.sock.makefile(\"rb\", 0)\n        line, headers, response_body = read_http(fp)\n        self.assertline(line, \"200\", \"OK\", \"HTTP/1.1\")\n        ct = headers[\"content-type\"]\n        self.assertEqual(ct, \"image/jpeg\")\n        self.assertTrue(b\"\\377\\330\\377\" in response_body)\n        # connection has been closed (no content-length)\n        self.send_check_error(to_send)\n        self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_notfilelike_shortcl_http11(self):\n        to_send = \"GET /notfilelike_shortcl HTTP/1.1\\n\\n\"\n        to_send = tobytes(to_send)\n\n        self.connect()\n\n        for t in range(0, 2):\n            self.sock.send(to_send)\n            fp = self.sock.makefile(\"rb\", 0)\n            line, headers, response_body = read_http(fp)\n            self.assertline(line, \"200\", \"OK\", \"HTTP/1.1\")\n            cl = int(headers[\"content-length\"])\n            self.assertEqual(cl, 1)\n            self.assertEqual(cl, len(response_body))\n            ct = headers[\"content-type\"]\n            self.assertEqual(ct, \"image/jpeg\")\n            self.assertTrue(b\"\\377\" in response_body)\n            # connection has not been closed\n\n    def test_notfilelike_longcl_http11(self):\n        to_send = \"GET /notfilelike_longcl HTTP/1.1\\n\\n\"\n        to_send = tobytes(to_send)\n\n        self.connect()\n\n        self.sock.send(to_send)\n        fp = self.sock.makefile(\"rb\", 0)\n        line, headers, response_body = read_http(fp)\n        self.assertline(line, \"200\", \"OK\", \"HTTP/1.1\")\n        cl = int(headers[\"content-length\"])\n        self.assertEqual(cl, len(response_body) + 10)\n        ct = headers[\"content-type\"]\n        self.assertEqual(ct, \"image/jpeg\")\n        self.assertTrue(b\"\\377\\330\\377\" in response_body)\n        # connection has been closed\n        self.send_check_error(to_send)\n        self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_filelike_http10(self):\n        to_send = \"GET /filelike HTTP/1.0\\n\\n\"\n        to_send = tobytes(to_send)\n\n        self.connect()\n\n        self.sock.send(to_send)\n        fp = self.sock.makefile(\"rb\", 0)\n        line, headers, response_body = read_http(fp)\n        self.assertline(line, \"200\", \"OK\", \"HTTP/1.0\")\n        cl = int(headers[\"content-length\"])\n        self.assertEqual(cl, len(response_body))\n        ct = headers[\"content-type\"]\n        self.assertEqual(ct, \"image/jpeg\")\n        self.assertTrue(b\"\\377\\330\\377\" in response_body)\n        # connection has been closed\n        self.send_check_error(to_send)\n        self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_filelike_nocl_http10(self):\n        to_send = \"GET /filelike_nocl HTTP/1.0\\n\\n\"\n        to_send = tobytes(to_send)\n\n        self.connect()\n\n        self.sock.send(to_send)\n        fp = self.sock.makefile(\"rb\", 0)\n        line, headers, response_body = read_http(fp)\n        self.assertline(line, \"200\", \"OK\", \"HTTP/1.0\")\n        cl = int(headers[\"content-length\"])\n        self.assertEqual(cl, len(response_body))\n        ct = headers[\"content-type\"]\n        self.assertEqual(ct, \"image/jpeg\")\n        self.assertTrue(b\"\\377\\330\\377\" in response_body)\n        # connection has been closed\n        self.send_check_error(to_send)\n        self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_notfilelike_http10(self):\n        to_send = \"GET /notfilelike HTTP/1.0\\n\\n\"\n        to_send = tobytes(to_send)\n\n        self.connect()\n\n        self.sock.send(to_send)\n        fp = self.sock.makefile(\"rb\", 0)\n        line, headers, response_body = read_http(fp)\n        self.assertline(line, \"200\", \"OK\", \"HTTP/1.0\")\n        cl = int(headers[\"content-length\"])\n        self.assertEqual(cl, len(response_body))\n        ct = headers[\"content-type\"]\n        self.assertEqual(ct, \"image/jpeg\")\n        self.assertTrue(b\"\\377\\330\\377\" in response_body)\n        # connection has been closed\n        self.send_check_error(to_send)\n        self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_notfilelike_nocl_http10(self):\n        to_send = \"GET /notfilelike_nocl HTTP/1.0\\n\\n\"\n        to_send = tobytes(to_send)\n\n        self.connect()\n\n        self.sock.send(to_send)\n        fp = self.sock.makefile(\"rb\", 0)\n        line, headers, response_body = read_http(fp)\n        self.assertline(line, \"200\", \"OK\", \"HTTP/1.0\")\n        ct = headers[\"content-type\"]\n        self.assertEqual(ct, \"image/jpeg\")\n        self.assertTrue(b\"\\377\\330\\377\" in response_body)\n        # connection has been closed (no content-length)\n        self.send_check_error(to_send)\n        self.assertRaises(ConnectionClosed, read_http, fp)\n\n\nclass TcpEchoTests(EchoTests, TcpTests, unittest.TestCase):\n    pass\n\n\nclass TcpPipeliningTests(PipeliningTests, TcpTests, unittest.TestCase):\n    pass\n\n\nclass TcpExpectContinueTests(ExpectContinueTests, TcpTests, unittest.TestCase):\n    pass\n\n\nclass TcpBadContentLengthTests(BadContentLengthTests, TcpTests, unittest.TestCase):\n    pass\n\n\nclass TcpNoContentLengthTests(NoContentLengthTests, TcpTests, unittest.TestCase):\n    pass\n\n\nclass TcpWriteCallbackTests(WriteCallbackTests, TcpTests, unittest.TestCase):\n    pass\n\n\nclass TcpTooLargeTests(TooLargeTests, TcpTests, unittest.TestCase):\n    pass\n\n\nclass TcpInternalServerErrorTests(\n    InternalServerErrorTests, TcpTests, unittest.TestCase\n):\n    pass\n\n\nclass TcpFileWrapperTests(FileWrapperTests, TcpTests, unittest.TestCase):\n    pass\n\n\nif hasattr(socket, \"AF_UNIX\"):\n\n    class FixtureUnixWSGIServer(server.UnixWSGIServer):\n        \"\"\"A version of UnixWSGIServer that relays back what it's bound to.\n        \"\"\"\n\n        family = socket.AF_UNIX  # Testing\n\n        def __init__(self, application, queue, **kw):  # pragma: no cover\n            # Coverage doesn't see this as it's ran in a separate process.\n            # To permit parallel testing, use a PID-dependent socket.\n            kw[\"unix_socket\"] = \"/tmp/waitress.test-%d.sock\" % os.getpid()\n            super(FixtureUnixWSGIServer, self).__init__(application, **kw)\n            queue.put(self.socket.getsockname())\n\n    class UnixTests(SubprocessTests):\n\n        server = FixtureUnixWSGIServer\n\n        def make_http_connection(self):\n            return UnixHTTPConnection(self.bound_to)\n\n        def stop_subprocess(self):\n            super(UnixTests, self).stop_subprocess()\n            cleanup_unix_socket(self.bound_to)\n\n        def send_check_error(self, to_send):\n            # Unlike inet domain sockets, Unix domain sockets can trigger a\n            # 'Broken pipe' error when the socket it closed.\n            try:\n                self.sock.send(to_send)\n            except socket.error as exc:\n                self.assertEqual(get_errno(exc), errno.EPIPE)\n\n    class UnixEchoTests(EchoTests, UnixTests, unittest.TestCase):\n        pass\n\n    class UnixPipeliningTests(PipeliningTests, UnixTests, unittest.TestCase):\n        pass\n\n    class UnixExpectContinueTests(ExpectContinueTests, UnixTests, unittest.TestCase):\n        pass\n\n    class UnixBadContentLengthTests(\n        BadContentLengthTests, UnixTests, unittest.TestCase\n    ):\n        pass\n\n    class UnixNoContentLengthTests(NoContentLengthTests, UnixTests, unittest.TestCase):\n        pass\n\n    class UnixWriteCallbackTests(WriteCallbackTests, UnixTests, unittest.TestCase):\n        pass\n\n    class UnixTooLargeTests(TooLargeTests, UnixTests, unittest.TestCase):\n        pass\n\n    class UnixInternalServerErrorTests(\n        InternalServerErrorTests, UnixTests, unittest.TestCase\n    ):\n        pass\n\n    class UnixFileWrapperTests(FileWrapperTests, UnixTests, unittest.TestCase):\n        pass\n\n\ndef parse_headers(fp):\n    \"\"\"Parses only RFC2822 headers from a file pointer.\n    \"\"\"\n    headers = {}\n    while True:\n        line = fp.readline()\n        if line in (b\"\\r\\n\", b\"\\n\", b\"\"):\n            break\n        line = line.decode(\"iso-8859-1\")\n        name, value = line.strip().split(\":\", 1)\n        headers[name.lower().strip()] = value.lower().strip()\n    return headers\n\n\nclass UnixHTTPConnection(httplib.HTTPConnection):\n    \"\"\"Patched version of HTTPConnection that uses Unix domain sockets.\n    \"\"\"\n\n    def __init__(self, path):\n        httplib.HTTPConnection.__init__(self, \"localhost\")\n        self.path = path\n\n    def connect(self):\n        sock = socket.socket(socket.AF_UNIX, socket.SOCK_STREAM)\n        sock.connect(self.path)\n        self.sock = sock\n\n\nclass ConnectionClosed(Exception):\n    pass\n\n\n# stolen from gevent\ndef read_http(fp):  # pragma: no cover\n    try:\n        response_line = fp.readline()\n    except socket.error as exc:\n        fp.close()\n        # errno 104 is ENOTRECOVERABLE, In WinSock 10054 is ECONNRESET\n        if get_errno(exc) in (errno.ECONNABORTED, errno.ECONNRESET, 104, 10054):\n            raise ConnectionClosed\n        raise\n    if not response_line:\n        raise ConnectionClosed\n\n    header_lines = []\n    while True:\n        line = fp.readline()\n        if line in (b\"\\r\\n\", b\"\\n\", b\"\"):\n            break\n        else:\n            header_lines.append(line)\n    headers = dict()\n    for x in header_lines:\n        x = x.strip()\n        if not x:\n            continue\n        key, value = x.split(b\": \", 1)\n        key = key.decode(\"iso-8859-1\").lower()\n        value = value.decode(\"iso-8859-1\")\n        assert key not in headers, \"%s header duplicated\" % key\n        headers[key] = value\n\n    if \"content-length\" in headers:\n        num = int(headers[\"content-length\"])\n        body = b\"\"\n        left = num\n        while left > 0:\n            data = fp.read(left)\n            if not data:\n                break\n            body += data\n            left -= len(data)\n    else:\n        # read until EOF\n        body = fp.read()\n\n    return response_line, headers, body\n\n\n# stolen from gevent\ndef get_errno(exc):  # pragma: no cover\n    \"\"\" Get the error code out of socket.error objects.\n    socket.error in <2.5 does not have errno attribute\n    socket.error in 3.x does not allow indexing access\n    e.args[0] works for all.\n    There are cases when args[0] is not errno.\n    i.e. http://bugs.python.org/issue6471\n    Maybe there are cases when errno is set, but it is not the first argument?\n    \"\"\"\n    try:\n        if exc.errno is not None:\n            return exc.errno\n    except AttributeError:\n        pass\n    try:\n        return exc.args[0]\n    except IndexError:\n        return None\n\n\ndef chunks(l, n):\n    \"\"\" Yield successive n-sized chunks from l.\n    \"\"\"\n    for i in range(0, len(l), n):\n        yield l[i : i + n]\n", "##############################################################################\n#\n# Copyright (c) 2002 Zope Foundation and Contributors.\n# All Rights Reserved.\n#\n# This software is subject to the provisions of the Zope Public License,\n# Version 2.1 (ZPL).  A copy of the ZPL should accompany this distribution.\n# THIS SOFTWARE IS PROVIDED \"AS IS\" AND ANY AND ALL EXPRESS OR IMPLIED\n# WARRANTIES ARE DISCLAIMED, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\n# WARRANTIES OF TITLE, MERCHANTABILITY, AGAINST INFRINGEMENT, AND FITNESS\n# FOR A PARTICULAR PURPOSE.\n#\n##############################################################################\n\"\"\"HTTP Request Parser tests\n\"\"\"\nimport unittest\n\nfrom waitress.compat import (\n    text_,\n    tobytes,\n)\n\n\nclass TestHTTPRequestParser(unittest.TestCase):\n    def setUp(self):\n        from waitress.parser import HTTPRequestParser\n        from waitress.adjustments import Adjustments\n\n        my_adj = Adjustments()\n        self.parser = HTTPRequestParser(my_adj)\n\n    def test_get_body_stream_None(self):\n        self.parser.body_recv = None\n        result = self.parser.get_body_stream()\n        self.assertEqual(result.getvalue(), b\"\")\n\n    def test_get_body_stream_nonNone(self):\n        body_rcv = DummyBodyStream()\n        self.parser.body_rcv = body_rcv\n        result = self.parser.get_body_stream()\n        self.assertEqual(result, body_rcv)\n\n    def test_received_nonsense_with_double_cr(self):\n        data = b\"\"\"\\\nHTTP/1.0 GET /foobar\n\n\n\"\"\"\n        result = self.parser.received(data)\n        self.assertEqual(result, 22)\n        self.assertTrue(self.parser.completed)\n        self.assertEqual(self.parser.headers, {})\n\n    def test_received_bad_host_header(self):\n        from waitress.utilities import BadRequest\n\n        data = b\"\"\"\\\nHTTP/1.0 GET /foobar\n Host: foo\n\n\n\"\"\"\n        result = self.parser.received(data)\n        self.assertEqual(result, 33)\n        self.assertTrue(self.parser.completed)\n        self.assertEqual(self.parser.error.__class__, BadRequest)\n\n    def test_received_nonsense_nothing(self):\n        data = b\"\"\"\\\n\n\n\"\"\"\n        result = self.parser.received(data)\n        self.assertEqual(result, 2)\n        self.assertTrue(self.parser.completed)\n        self.assertEqual(self.parser.headers, {})\n\n    def test_received_no_doublecr(self):\n        data = b\"\"\"\\\nGET /foobar HTTP/8.4\n\"\"\"\n        result = self.parser.received(data)\n        self.assertEqual(result, 21)\n        self.assertFalse(self.parser.completed)\n        self.assertEqual(self.parser.headers, {})\n\n    def test_received_already_completed(self):\n        self.parser.completed = True\n        result = self.parser.received(b\"a\")\n        self.assertEqual(result, 0)\n\n    def test_received_cl_too_large(self):\n        from waitress.utilities import RequestEntityTooLarge\n\n        self.parser.adj.max_request_body_size = 2\n        data = b\"\"\"\\\nGET /foobar HTTP/8.4\nContent-Length: 10\n\n\"\"\"\n        result = self.parser.received(data)\n        self.assertEqual(result, 41)\n        self.assertTrue(self.parser.completed)\n        self.assertTrue(isinstance(self.parser.error, RequestEntityTooLarge))\n\n    def test_received_headers_too_large(self):\n        from waitress.utilities import RequestHeaderFieldsTooLarge\n\n        self.parser.adj.max_request_header_size = 2\n        data = b\"\"\"\\\nGET /foobar HTTP/8.4\nX-Foo: 1\n\"\"\"\n        result = self.parser.received(data)\n        self.assertEqual(result, 30)\n        self.assertTrue(self.parser.completed)\n        self.assertTrue(isinstance(self.parser.error, RequestHeaderFieldsTooLarge))\n\n    def test_received_body_too_large(self):\n        from waitress.utilities import RequestEntityTooLarge\n\n        self.parser.adj.max_request_body_size = 2\n        data = b\"\"\"\\\nGET /foobar HTTP/1.1\nTransfer-Encoding: chunked\nX-Foo: 1\n\n20;\\r\\n\nThis string has 32 characters\\r\\n\n0\\r\\n\\r\\n\"\"\"\n        result = self.parser.received(data)\n        self.assertEqual(result, 58)\n        self.parser.received(data[result:])\n        self.assertTrue(self.parser.completed)\n        self.assertTrue(isinstance(self.parser.error, RequestEntityTooLarge))\n\n    def test_received_error_from_parser(self):\n        from waitress.utilities import BadRequest\n\n        data = b\"\"\"\\\nGET /foobar HTTP/1.1\nTransfer-Encoding: chunked\nX-Foo: 1\n\ngarbage\n\"\"\"\n        # header\n        result = self.parser.received(data)\n        # body\n        result = self.parser.received(data[result:])\n        self.assertEqual(result, 8)\n        self.assertTrue(self.parser.completed)\n        self.assertTrue(isinstance(self.parser.error, BadRequest))\n\n    def test_received_chunked_completed_sets_content_length(self):\n        data = b\"\"\"\\\nGET /foobar HTTP/1.1\nTransfer-Encoding: chunked\nX-Foo: 1\n\n20;\\r\\n\nThis string has 32 characters\\r\\n\n0\\r\\n\\r\\n\"\"\"\n        result = self.parser.received(data)\n        self.assertEqual(result, 58)\n        data = data[result:]\n        result = self.parser.received(data)\n        self.assertTrue(self.parser.completed)\n        self.assertTrue(self.parser.error is None)\n        self.assertEqual(self.parser.headers[\"CONTENT_LENGTH\"], \"32\")\n\n    def test_parse_header_gardenpath(self):\n        data = b\"\"\"\\\nGET /foobar HTTP/8.4\nfoo: bar\"\"\"\n        self.parser.parse_header(data)\n        self.assertEqual(self.parser.first_line, b\"GET /foobar HTTP/8.4\")\n        self.assertEqual(self.parser.headers[\"FOO\"], \"bar\")\n\n    def test_parse_header_no_cr_in_headerplus(self):\n        data = b\"GET /foobar HTTP/8.4\"\n        self.parser.parse_header(data)\n        self.assertEqual(self.parser.first_line, data)\n\n    def test_parse_header_bad_content_length(self):\n        data = b\"GET /foobar HTTP/8.4\\ncontent-length: abc\"\n        self.parser.parse_header(data)\n        self.assertEqual(self.parser.body_rcv, None)\n\n    def test_parse_header_11_te_chunked(self):\n        # NB: test that capitalization of header value is unimportant\n        data = b\"GET /foobar HTTP/1.1\\ntransfer-encoding: ChUnKed\"\n        self.parser.parse_header(data)\n        self.assertEqual(self.parser.body_rcv.__class__.__name__, \"ChunkedReceiver\")\n\n    def test_parse_header_11_expect_continue(self):\n        data = b\"GET /foobar HTTP/1.1\\nexpect: 100-continue\"\n        self.parser.parse_header(data)\n        self.assertEqual(self.parser.expect_continue, True)\n\n    def test_parse_header_connection_close(self):\n        data = b\"GET /foobar HTTP/1.1\\nConnection: close\\n\\n\"\n        self.parser.parse_header(data)\n        self.assertEqual(self.parser.connection_close, True)\n\n    def test_close_with_body_rcv(self):\n        body_rcv = DummyBodyStream()\n        self.parser.body_rcv = body_rcv\n        self.parser.close()\n        self.assertTrue(body_rcv.closed)\n\n    def test_close_with_no_body_rcv(self):\n        self.parser.body_rcv = None\n        self.parser.close()  # doesn't raise\n\n\nclass Test_split_uri(unittest.TestCase):\n    def _callFUT(self, uri):\n        from waitress.parser import split_uri\n\n        (\n            self.proxy_scheme,\n            self.proxy_netloc,\n            self.path,\n            self.query,\n            self.fragment,\n        ) = split_uri(uri)\n\n    def test_split_uri_unquoting_unneeded(self):\n        self._callFUT(b\"http://localhost:8080/abc def\")\n        self.assertEqual(self.path, \"/abc def\")\n\n    def test_split_uri_unquoting_needed(self):\n        self._callFUT(b\"http://localhost:8080/abc%20def\")\n        self.assertEqual(self.path, \"/abc def\")\n\n    def test_split_url_with_query(self):\n        self._callFUT(b\"http://localhost:8080/abc?a=1&b=2\")\n        self.assertEqual(self.path, \"/abc\")\n        self.assertEqual(self.query, \"a=1&b=2\")\n\n    def test_split_url_with_query_empty(self):\n        self._callFUT(b\"http://localhost:8080/abc?\")\n        self.assertEqual(self.path, \"/abc\")\n        self.assertEqual(self.query, \"\")\n\n    def test_split_url_with_fragment(self):\n        self._callFUT(b\"http://localhost:8080/#foo\")\n        self.assertEqual(self.path, \"/\")\n        self.assertEqual(self.fragment, \"foo\")\n\n    def test_split_url_https(self):\n        self._callFUT(b\"https://localhost:8080/\")\n        self.assertEqual(self.path, \"/\")\n        self.assertEqual(self.proxy_scheme, \"https\")\n        self.assertEqual(self.proxy_netloc, \"localhost:8080\")\n\n    def test_split_uri_unicode_error_raises_parsing_error(self):\n        # See https://github.com/Pylons/waitress/issues/64\n        from waitress.parser import ParsingError\n\n        # Either pass or throw a ParsingError, just don't throw another type of\n        # exception as that will cause the connection to close badly:\n        try:\n            self._callFUT(b\"/\\xd0\")\n        except ParsingError:\n            pass\n\n    def test_split_uri_path(self):\n        self._callFUT(b\"//testing/whatever\")\n        self.assertEqual(self.path, \"//testing/whatever\")\n        self.assertEqual(self.proxy_scheme, \"\")\n        self.assertEqual(self.proxy_netloc, \"\")\n        self.assertEqual(self.query, \"\")\n        self.assertEqual(self.fragment, \"\")\n\n    def test_split_uri_path_query(self):\n        self._callFUT(b\"//testing/whatever?a=1&b=2\")\n        self.assertEqual(self.path, \"//testing/whatever\")\n        self.assertEqual(self.proxy_scheme, \"\")\n        self.assertEqual(self.proxy_netloc, \"\")\n        self.assertEqual(self.query, \"a=1&b=2\")\n        self.assertEqual(self.fragment, \"\")\n\n    def test_split_uri_path_query_fragment(self):\n        self._callFUT(b\"//testing/whatever?a=1&b=2#fragment\")\n        self.assertEqual(self.path, \"//testing/whatever\")\n        self.assertEqual(self.proxy_scheme, \"\")\n        self.assertEqual(self.proxy_netloc, \"\")\n        self.assertEqual(self.query, \"a=1&b=2\")\n        self.assertEqual(self.fragment, \"fragment\")\n\n\nclass Test_get_header_lines(unittest.TestCase):\n    def _callFUT(self, data):\n        from waitress.parser import get_header_lines\n\n        return get_header_lines(data)\n\n    def test_get_header_lines(self):\n        result = self._callFUT(b\"slam\\nslim\")\n        self.assertEqual(result, [b\"slam\", b\"slim\"])\n\n    def test_get_header_lines_folded(self):\n        # From RFC2616:\n        # HTTP/1.1 header field values can be folded onto multiple lines if the\n        # continuation line begins with a space or horizontal tab. All linear\n        # white space, including folding, has the same semantics as SP. A\n        # recipient MAY replace any linear white space with a single SP before\n        # interpreting the field value or forwarding the message downstream.\n\n        # We are just preserving the whitespace that indicates folding.\n        result = self._callFUT(b\"slim\\n slam\")\n        self.assertEqual(result, [b\"slim slam\"])\n\n    def test_get_header_lines_tabbed(self):\n        result = self._callFUT(b\"slam\\n\\tslim\")\n        self.assertEqual(result, [b\"slam\\tslim\"])\n\n    def test_get_header_lines_malformed(self):\n        # https://corte.si/posts/code/pathod/pythonservers/index.html\n        from waitress.parser import ParsingError\n\n        self.assertRaises(ParsingError, self._callFUT, b\" Host: localhost\\r\\n\\r\\n\")\n\n\nclass Test_crack_first_line(unittest.TestCase):\n    def _callFUT(self, line):\n        from waitress.parser import crack_first_line\n\n        return crack_first_line(line)\n\n    def test_crack_first_line_matchok(self):\n        result = self._callFUT(b\"GET / HTTP/1.0\")\n        self.assertEqual(result, (b\"GET\", b\"/\", b\"1.0\"))\n\n    def test_crack_first_line_lowercase_method(self):\n        from waitress.parser import ParsingError\n\n        self.assertRaises(ParsingError, self._callFUT, b\"get / HTTP/1.0\")\n\n    def test_crack_first_line_nomatch(self):\n        result = self._callFUT(b\"GET / bleh\")\n        self.assertEqual(result, (b\"\", b\"\", b\"\"))\n\n        result = self._callFUT(b\"GET /info?txtAirPlay&txtRAOP RTSP/1.0\")\n        self.assertEqual(result, (b\"\", b\"\", b\"\"))\n\n    def test_crack_first_line_missing_version(self):\n        result = self._callFUT(b\"GET /\")\n        self.assertEqual(result, (b\"GET\", b\"/\", b\"\"))\n\n\nclass TestHTTPRequestParserIntegration(unittest.TestCase):\n    def setUp(self):\n        from waitress.parser import HTTPRequestParser\n        from waitress.adjustments import Adjustments\n\n        my_adj = Adjustments()\n        self.parser = HTTPRequestParser(my_adj)\n\n    def feed(self, data):\n        parser = self.parser\n        for n in range(100):  # make sure we never loop forever\n            consumed = parser.received(data)\n            data = data[consumed:]\n            if parser.completed:\n                return\n        raise ValueError(\"Looping\")  # pragma: no cover\n\n    def testSimpleGET(self):\n        data = b\"\"\"\\\nGET /foobar HTTP/8.4\nFirstName: mickey\nlastname: Mouse\ncontent-length: 7\n\nHello.\n\"\"\"\n        parser = self.parser\n        self.feed(data)\n        self.assertTrue(parser.completed)\n        self.assertEqual(parser.version, \"8.4\")\n        self.assertFalse(parser.empty)\n        self.assertEqual(\n            parser.headers,\n            {\"FIRSTNAME\": \"mickey\", \"LASTNAME\": \"Mouse\", \"CONTENT_LENGTH\": \"7\",},\n        )\n        self.assertEqual(parser.path, \"/foobar\")\n        self.assertEqual(parser.command, \"GET\")\n        self.assertEqual(parser.query, \"\")\n        self.assertEqual(parser.proxy_scheme, \"\")\n        self.assertEqual(parser.proxy_netloc, \"\")\n        self.assertEqual(parser.get_body_stream().getvalue(), b\"Hello.\\n\")\n\n    def testComplexGET(self):\n        data = b\"\"\"\\\nGET /foo/a+%2B%2F%C3%A4%3D%26a%3Aint?d=b+%2B%2F%3D%26b%3Aint&c+%2B%2F%3D%26c%3Aint=6 HTTP/8.4\nFirstName: mickey\nlastname: Mouse\ncontent-length: 10\n\nHello mickey.\n\"\"\"\n        parser = self.parser\n        self.feed(data)\n        self.assertEqual(parser.command, \"GET\")\n        self.assertEqual(parser.version, \"8.4\")\n        self.assertFalse(parser.empty)\n        self.assertEqual(\n            parser.headers,\n            {\"FIRSTNAME\": \"mickey\", \"LASTNAME\": \"Mouse\", \"CONTENT_LENGTH\": \"10\",},\n        )\n        # path should be utf-8 encoded\n        self.assertEqual(\n            tobytes(parser.path).decode(\"utf-8\"),\n            text_(b\"/foo/a++/\\xc3\\xa4=&a:int\", \"utf-8\"),\n        )\n        self.assertEqual(\n            parser.query, \"d=b+%2B%2F%3D%26b%3Aint&c+%2B%2F%3D%26c%3Aint=6\"\n        )\n        self.assertEqual(parser.get_body_stream().getvalue(), b\"Hello mick\")\n\n    def testProxyGET(self):\n        data = b\"\"\"\\\nGET https://example.com:8080/foobar HTTP/8.4\ncontent-length: 7\n\nHello.\n\"\"\"\n        parser = self.parser\n        self.feed(data)\n        self.assertTrue(parser.completed)\n        self.assertEqual(parser.version, \"8.4\")\n        self.assertFalse(parser.empty)\n        self.assertEqual(parser.headers, {\"CONTENT_LENGTH\": \"7\",})\n        self.assertEqual(parser.path, \"/foobar\")\n        self.assertEqual(parser.command, \"GET\")\n        self.assertEqual(parser.proxy_scheme, \"https\")\n        self.assertEqual(parser.proxy_netloc, \"example.com:8080\")\n        self.assertEqual(parser.command, \"GET\")\n        self.assertEqual(parser.query, \"\")\n        self.assertEqual(parser.get_body_stream().getvalue(), b\"Hello.\\n\")\n\n    def testDuplicateHeaders(self):\n        # Ensure that headers with the same key get concatenated as per\n        # RFC2616.\n        data = b\"\"\"\\\nGET /foobar HTTP/8.4\nx-forwarded-for: 10.11.12.13\nx-forwarded-for: unknown,127.0.0.1\nX-Forwarded_for: 255.255.255.255\ncontent-length: 7\n\nHello.\n\"\"\"\n        self.feed(data)\n        self.assertTrue(self.parser.completed)\n        self.assertEqual(\n            self.parser.headers,\n            {\n                \"CONTENT_LENGTH\": \"7\",\n                \"X_FORWARDED_FOR\": \"10.11.12.13, unknown,127.0.0.1\",\n            },\n        )\n\n    def testSpoofedHeadersDropped(self):\n        data = b\"\"\"\\\nGET /foobar HTTP/8.4\nx-auth_user: bob\ncontent-length: 7\n\nHello.\n\"\"\"\n        self.feed(data)\n        self.assertTrue(self.parser.completed)\n        self.assertEqual(self.parser.headers, {\"CONTENT_LENGTH\": \"7\",})\n\n\nclass DummyBodyStream(object):\n    def getfile(self):\n        return self\n\n    def getbuf(self):\n        return self\n\n    def close(self):\n        self.closed = True\n", "import unittest\n\n\nclass TestFixedStreamReceiver(unittest.TestCase):\n    def _makeOne(self, cl, buf):\n        from waitress.receiver import FixedStreamReceiver\n\n        return FixedStreamReceiver(cl, buf)\n\n    def test_received_remain_lt_1(self):\n        buf = DummyBuffer()\n        inst = self._makeOne(0, buf)\n        result = inst.received(\"a\")\n        self.assertEqual(result, 0)\n        self.assertEqual(inst.completed, True)\n\n    def test_received_remain_lte_datalen(self):\n        buf = DummyBuffer()\n        inst = self._makeOne(1, buf)\n        result = inst.received(\"aa\")\n        self.assertEqual(result, 1)\n        self.assertEqual(inst.completed, True)\n        self.assertEqual(inst.completed, 1)\n        self.assertEqual(inst.remain, 0)\n        self.assertEqual(buf.data, [\"a\"])\n\n    def test_received_remain_gt_datalen(self):\n        buf = DummyBuffer()\n        inst = self._makeOne(10, buf)\n        result = inst.received(\"aa\")\n        self.assertEqual(result, 2)\n        self.assertEqual(inst.completed, False)\n        self.assertEqual(inst.remain, 8)\n        self.assertEqual(buf.data, [\"aa\"])\n\n    def test_getfile(self):\n        buf = DummyBuffer()\n        inst = self._makeOne(10, buf)\n        self.assertEqual(inst.getfile(), buf)\n\n    def test_getbuf(self):\n        buf = DummyBuffer()\n        inst = self._makeOne(10, buf)\n        self.assertEqual(inst.getbuf(), buf)\n\n    def test___len__(self):\n        buf = DummyBuffer([\"1\", \"2\"])\n        inst = self._makeOne(10, buf)\n        self.assertEqual(inst.__len__(), 2)\n\n\nclass TestChunkedReceiver(unittest.TestCase):\n    def _makeOne(self, buf):\n        from waitress.receiver import ChunkedReceiver\n\n        return ChunkedReceiver(buf)\n\n    def test_alreadycompleted(self):\n        buf = DummyBuffer()\n        inst = self._makeOne(buf)\n        inst.completed = True\n        result = inst.received(b\"a\")\n        self.assertEqual(result, 0)\n        self.assertEqual(inst.completed, True)\n\n    def test_received_remain_gt_zero(self):\n        buf = DummyBuffer()\n        inst = self._makeOne(buf)\n        inst.chunk_remainder = 100\n        result = inst.received(b\"a\")\n        self.assertEqual(inst.chunk_remainder, 99)\n        self.assertEqual(result, 1)\n        self.assertEqual(inst.completed, False)\n\n    def test_received_control_line_notfinished(self):\n        buf = DummyBuffer()\n        inst = self._makeOne(buf)\n        result = inst.received(b\"a\")\n        self.assertEqual(inst.control_line, b\"a\")\n        self.assertEqual(result, 1)\n        self.assertEqual(inst.completed, False)\n\n    def test_received_control_line_finished_garbage_in_input(self):\n        buf = DummyBuffer()\n        inst = self._makeOne(buf)\n        result = inst.received(b\"garbage\\n\")\n        self.assertEqual(result, 8)\n        self.assertTrue(inst.error)\n\n    def test_received_control_line_finished_all_chunks_not_received(self):\n        buf = DummyBuffer()\n        inst = self._makeOne(buf)\n        result = inst.received(b\"a;discard\\n\")\n        self.assertEqual(inst.control_line, b\"\")\n        self.assertEqual(inst.chunk_remainder, 10)\n        self.assertEqual(inst.all_chunks_received, False)\n        self.assertEqual(result, 10)\n        self.assertEqual(inst.completed, False)\n\n    def test_received_control_line_finished_all_chunks_received(self):\n        buf = DummyBuffer()\n        inst = self._makeOne(buf)\n        result = inst.received(b\"0;discard\\n\")\n        self.assertEqual(inst.control_line, b\"\")\n        self.assertEqual(inst.all_chunks_received, True)\n        self.assertEqual(result, 10)\n        self.assertEqual(inst.completed, False)\n\n    def test_received_trailer_startswith_crlf(self):\n        buf = DummyBuffer()\n        inst = self._makeOne(buf)\n        inst.all_chunks_received = True\n        result = inst.received(b\"\\r\\n\")\n        self.assertEqual(result, 2)\n        self.assertEqual(inst.completed, True)\n\n    def test_received_trailer_startswith_lf(self):\n        buf = DummyBuffer()\n        inst = self._makeOne(buf)\n        inst.all_chunks_received = True\n        result = inst.received(b\"\\n\")\n        self.assertEqual(result, 1)\n        self.assertEqual(inst.completed, True)\n\n    def test_received_trailer_not_finished(self):\n        buf = DummyBuffer()\n        inst = self._makeOne(buf)\n        inst.all_chunks_received = True\n        result = inst.received(b\"a\")\n        self.assertEqual(result, 1)\n        self.assertEqual(inst.completed, False)\n\n    def test_received_trailer_finished(self):\n        buf = DummyBuffer()\n        inst = self._makeOne(buf)\n        inst.all_chunks_received = True\n        result = inst.received(b\"abc\\r\\n\\r\\n\")\n        self.assertEqual(inst.trailer, b\"abc\\r\\n\\r\\n\")\n        self.assertEqual(result, 7)\n        self.assertEqual(inst.completed, True)\n\n    def test_getfile(self):\n        buf = DummyBuffer()\n        inst = self._makeOne(buf)\n        self.assertEqual(inst.getfile(), buf)\n\n    def test_getbuf(self):\n        buf = DummyBuffer()\n        inst = self._makeOne(buf)\n        self.assertEqual(inst.getbuf(), buf)\n\n    def test___len__(self):\n        buf = DummyBuffer([\"1\", \"2\"])\n        inst = self._makeOne(buf)\n        self.assertEqual(inst.__len__(), 2)\n\n\nclass DummyBuffer(object):\n    def __init__(self, data=None):\n        if data is None:\n            data = []\n        self.data = data\n\n    def append(self, s):\n        self.data.append(s)\n\n    def getfile(self):\n        return self\n\n    def __len__(self):\n        return len(self.data)\n", "import unittest\nimport io\n\n\nclass TestThreadedTaskDispatcher(unittest.TestCase):\n    def _makeOne(self):\n        from waitress.task import ThreadedTaskDispatcher\n\n        return ThreadedTaskDispatcher()\n\n    def test_handler_thread_task_raises(self):\n        inst = self._makeOne()\n        inst.threads.add(0)\n        inst.logger = DummyLogger()\n\n        class BadDummyTask(DummyTask):\n            def service(self):\n                super(BadDummyTask, self).service()\n                inst.stop_count += 1\n                raise Exception\n\n        task = BadDummyTask()\n        inst.logger = DummyLogger()\n        inst.queue.append(task)\n        inst.active_count += 1\n        inst.handler_thread(0)\n        self.assertEqual(inst.stop_count, 0)\n        self.assertEqual(inst.active_count, 0)\n        self.assertEqual(inst.threads, set())\n        self.assertEqual(len(inst.logger.logged), 1)\n\n    def test_set_thread_count_increase(self):\n        inst = self._makeOne()\n        L = []\n        inst.start_new_thread = lambda *x: L.append(x)\n        inst.set_thread_count(1)\n        self.assertEqual(L, [(inst.handler_thread, (0,))])\n\n    def test_set_thread_count_increase_with_existing(self):\n        inst = self._makeOne()\n        L = []\n        inst.threads = {0}\n        inst.start_new_thread = lambda *x: L.append(x)\n        inst.set_thread_count(2)\n        self.assertEqual(L, [(inst.handler_thread, (1,))])\n\n    def test_set_thread_count_decrease(self):\n        inst = self._makeOne()\n        inst.threads = {0, 1}\n        inst.set_thread_count(1)\n        self.assertEqual(inst.stop_count, 1)\n\n    def test_set_thread_count_same(self):\n        inst = self._makeOne()\n        L = []\n        inst.start_new_thread = lambda *x: L.append(x)\n        inst.threads = {0}\n        inst.set_thread_count(1)\n        self.assertEqual(L, [])\n\n    def test_add_task_with_idle_threads(self):\n        task = DummyTask()\n        inst = self._makeOne()\n        inst.threads.add(0)\n        inst.queue_logger = DummyLogger()\n        inst.add_task(task)\n        self.assertEqual(len(inst.queue), 1)\n        self.assertEqual(len(inst.queue_logger.logged), 0)\n\n    def test_add_task_with_all_busy_threads(self):\n        task = DummyTask()\n        inst = self._makeOne()\n        inst.queue_logger = DummyLogger()\n        inst.add_task(task)\n        self.assertEqual(len(inst.queue_logger.logged), 1)\n        inst.add_task(task)\n        self.assertEqual(len(inst.queue_logger.logged), 2)\n\n    def test_shutdown_one_thread(self):\n        inst = self._makeOne()\n        inst.threads.add(0)\n        inst.logger = DummyLogger()\n        task = DummyTask()\n        inst.queue.append(task)\n        self.assertEqual(inst.shutdown(timeout=0.01), True)\n        self.assertEqual(\n            inst.logger.logged,\n            [\"1 thread(s) still running\", \"Canceling 1 pending task(s)\",],\n        )\n        self.assertEqual(task.cancelled, True)\n\n    def test_shutdown_no_threads(self):\n        inst = self._makeOne()\n        self.assertEqual(inst.shutdown(timeout=0.01), True)\n\n    def test_shutdown_no_cancel_pending(self):\n        inst = self._makeOne()\n        self.assertEqual(inst.shutdown(cancel_pending=False, timeout=0.01), False)\n\n\nclass TestTask(unittest.TestCase):\n    def _makeOne(self, channel=None, request=None):\n        if channel is None:\n            channel = DummyChannel()\n        if request is None:\n            request = DummyParser()\n        from waitress.task import Task\n\n        return Task(channel, request)\n\n    def test_ctor_version_not_in_known(self):\n        request = DummyParser()\n        request.version = \"8.4\"\n        inst = self._makeOne(request=request)\n        self.assertEqual(inst.version, \"1.0\")\n\n    def test_build_response_header_bad_http_version(self):\n        inst = self._makeOne()\n        inst.request = DummyParser()\n        inst.version = \"8.4\"\n        self.assertRaises(AssertionError, inst.build_response_header)\n\n    def test_build_response_header_v10_keepalive_no_content_length(self):\n        inst = self._makeOne()\n        inst.request = DummyParser()\n        inst.request.headers[\"CONNECTION\"] = \"keep-alive\"\n        inst.version = \"1.0\"\n        result = inst.build_response_header()\n        lines = filter_lines(result)\n        self.assertEqual(len(lines), 4)\n        self.assertEqual(lines[0], b\"HTTP/1.0 200 OK\")\n        self.assertEqual(lines[1], b\"Connection: close\")\n        self.assertTrue(lines[2].startswith(b\"Date:\"))\n        self.assertEqual(lines[3], b\"Server: waitress\")\n        self.assertEqual(inst.close_on_finish, True)\n        self.assertTrue((\"Connection\", \"close\") in inst.response_headers)\n\n    def test_build_response_header_v10_keepalive_with_content_length(self):\n        inst = self._makeOne()\n        inst.request = DummyParser()\n        inst.request.headers[\"CONNECTION\"] = \"keep-alive\"\n        inst.response_headers = [(\"Content-Length\", \"10\")]\n        inst.version = \"1.0\"\n        inst.content_length = 0\n        result = inst.build_response_header()\n        lines = filter_lines(result)\n        self.assertEqual(len(lines), 5)\n        self.assertEqual(lines[0], b\"HTTP/1.0 200 OK\")\n        self.assertEqual(lines[1], b\"Connection: Keep-Alive\")\n        self.assertEqual(lines[2], b\"Content-Length: 10\")\n        self.assertTrue(lines[3].startswith(b\"Date:\"))\n        self.assertEqual(lines[4], b\"Server: waitress\")\n        self.assertEqual(inst.close_on_finish, False)\n\n    def test_build_response_header_v11_connection_closed_by_client(self):\n        inst = self._makeOne()\n        inst.request = DummyParser()\n        inst.version = \"1.1\"\n        inst.request.headers[\"CONNECTION\"] = \"close\"\n        result = inst.build_response_header()\n        lines = filter_lines(result)\n        self.assertEqual(len(lines), 5)\n        self.assertEqual(lines[0], b\"HTTP/1.1 200 OK\")\n        self.assertEqual(lines[1], b\"Connection: close\")\n        self.assertTrue(lines[2].startswith(b\"Date:\"))\n        self.assertEqual(lines[3], b\"Server: waitress\")\n        self.assertEqual(lines[4], b\"Transfer-Encoding: chunked\")\n        self.assertTrue((\"Connection\", \"close\") in inst.response_headers)\n        self.assertEqual(inst.close_on_finish, True)\n\n    def test_build_response_header_v11_connection_keepalive_by_client(self):\n        inst = self._makeOne()\n        inst.request = DummyParser()\n        inst.request.headers[\"CONNECTION\"] = \"keep-alive\"\n        inst.version = \"1.1\"\n        result = inst.build_response_header()\n        lines = filter_lines(result)\n        self.assertEqual(len(lines), 5)\n        self.assertEqual(lines[0], b\"HTTP/1.1 200 OK\")\n        self.assertEqual(lines[1], b\"Connection: close\")\n        self.assertTrue(lines[2].startswith(b\"Date:\"))\n        self.assertEqual(lines[3], b\"Server: waitress\")\n        self.assertEqual(lines[4], b\"Transfer-Encoding: chunked\")\n        self.assertTrue((\"Connection\", \"close\") in inst.response_headers)\n        self.assertEqual(inst.close_on_finish, True)\n\n    def test_build_response_header_v11_200_no_content_length(self):\n        inst = self._makeOne()\n        inst.request = DummyParser()\n        inst.version = \"1.1\"\n        result = inst.build_response_header()\n        lines = filter_lines(result)\n        self.assertEqual(len(lines), 5)\n        self.assertEqual(lines[0], b\"HTTP/1.1 200 OK\")\n        self.assertEqual(lines[1], b\"Connection: close\")\n        self.assertTrue(lines[2].startswith(b\"Date:\"))\n        self.assertEqual(lines[3], b\"Server: waitress\")\n        self.assertEqual(lines[4], b\"Transfer-Encoding: chunked\")\n        self.assertEqual(inst.close_on_finish, True)\n        self.assertTrue((\"Connection\", \"close\") in inst.response_headers)\n\n    def test_build_response_header_v11_204_no_content_length_or_transfer_encoding(self):\n        # RFC 7230: MUST NOT send Transfer-Encoding or Content-Length\n        # for any response with a status code of 1xx or 204.\n        inst = self._makeOne()\n        inst.request = DummyParser()\n        inst.version = \"1.1\"\n        inst.status = \"204 No Content\"\n        result = inst.build_response_header()\n        lines = filter_lines(result)\n        self.assertEqual(len(lines), 4)\n        self.assertEqual(lines[0], b\"HTTP/1.1 204 No Content\")\n        self.assertEqual(lines[1], b\"Connection: close\")\n        self.assertTrue(lines[2].startswith(b\"Date:\"))\n        self.assertEqual(lines[3], b\"Server: waitress\")\n        self.assertEqual(inst.close_on_finish, True)\n        self.assertTrue((\"Connection\", \"close\") in inst.response_headers)\n\n    def test_build_response_header_v11_1xx_no_content_length_or_transfer_encoding(self):\n        # RFC 7230: MUST NOT send Transfer-Encoding or Content-Length\n        # for any response with a status code of 1xx or 204.\n        inst = self._makeOne()\n        inst.request = DummyParser()\n        inst.version = \"1.1\"\n        inst.status = \"100 Continue\"\n        result = inst.build_response_header()\n        lines = filter_lines(result)\n        self.assertEqual(len(lines), 4)\n        self.assertEqual(lines[0], b\"HTTP/1.1 100 Continue\")\n        self.assertEqual(lines[1], b\"Connection: close\")\n        self.assertTrue(lines[2].startswith(b\"Date:\"))\n        self.assertEqual(lines[3], b\"Server: waitress\")\n        self.assertEqual(inst.close_on_finish, True)\n        self.assertTrue((\"Connection\", \"close\") in inst.response_headers)\n\n    def test_build_response_header_v11_304_no_content_length_or_transfer_encoding(self):\n        # RFC 7230: MUST NOT send Transfer-Encoding or Content-Length\n        # for any response with a status code of 1xx, 204 or 304.\n        inst = self._makeOne()\n        inst.request = DummyParser()\n        inst.version = \"1.1\"\n        inst.status = \"304 Not Modified\"\n        result = inst.build_response_header()\n        lines = filter_lines(result)\n        self.assertEqual(len(lines), 4)\n        self.assertEqual(lines[0], b\"HTTP/1.1 304 Not Modified\")\n        self.assertEqual(lines[1], b\"Connection: close\")\n        self.assertTrue(lines[2].startswith(b\"Date:\"))\n        self.assertEqual(lines[3], b\"Server: waitress\")\n        self.assertEqual(inst.close_on_finish, True)\n        self.assertTrue((\"Connection\", \"close\") in inst.response_headers)\n\n    def test_build_response_header_via_added(self):\n        inst = self._makeOne()\n        inst.request = DummyParser()\n        inst.version = \"1.0\"\n        inst.response_headers = [(\"Server\", \"abc\")]\n        result = inst.build_response_header()\n        lines = filter_lines(result)\n        self.assertEqual(len(lines), 5)\n        self.assertEqual(lines[0], b\"HTTP/1.0 200 OK\")\n        self.assertEqual(lines[1], b\"Connection: close\")\n        self.assertTrue(lines[2].startswith(b\"Date:\"))\n        self.assertEqual(lines[3], b\"Server: abc\")\n        self.assertEqual(lines[4], b\"Via: waitress\")\n\n    def test_build_response_header_date_exists(self):\n        inst = self._makeOne()\n        inst.request = DummyParser()\n        inst.version = \"1.0\"\n        inst.response_headers = [(\"Date\", \"date\")]\n        result = inst.build_response_header()\n        lines = filter_lines(result)\n        self.assertEqual(len(lines), 4)\n        self.assertEqual(lines[0], b\"HTTP/1.0 200 OK\")\n        self.assertEqual(lines[1], b\"Connection: close\")\n        self.assertTrue(lines[2].startswith(b\"Date:\"))\n        self.assertEqual(lines[3], b\"Server: waitress\")\n\n    def test_build_response_header_preexisting_content_length(self):\n        inst = self._makeOne()\n        inst.request = DummyParser()\n        inst.version = \"1.1\"\n        inst.content_length = 100\n        result = inst.build_response_header()\n        lines = filter_lines(result)\n        self.assertEqual(len(lines), 4)\n        self.assertEqual(lines[0], b\"HTTP/1.1 200 OK\")\n        self.assertEqual(lines[1], b\"Content-Length: 100\")\n        self.assertTrue(lines[2].startswith(b\"Date:\"))\n        self.assertEqual(lines[3], b\"Server: waitress\")\n\n    def test_remove_content_length_header(self):\n        inst = self._makeOne()\n        inst.response_headers = [(\"Content-Length\", \"70\")]\n        inst.remove_content_length_header()\n        self.assertEqual(inst.response_headers, [])\n\n    def test_remove_content_length_header_with_other(self):\n        inst = self._makeOne()\n        inst.response_headers = [\n            (\"Content-Length\", \"70\"),\n            (\"Content-Type\", \"text/html\"),\n        ]\n        inst.remove_content_length_header()\n        self.assertEqual(inst.response_headers, [(\"Content-Type\", \"text/html\")])\n\n    def test_start(self):\n        inst = self._makeOne()\n        inst.start()\n        self.assertTrue(inst.start_time)\n\n    def test_finish_didnt_write_header(self):\n        inst = self._makeOne()\n        inst.wrote_header = False\n        inst.complete = True\n        inst.finish()\n        self.assertTrue(inst.channel.written)\n\n    def test_finish_wrote_header(self):\n        inst = self._makeOne()\n        inst.wrote_header = True\n        inst.finish()\n        self.assertFalse(inst.channel.written)\n\n    def test_finish_chunked_response(self):\n        inst = self._makeOne()\n        inst.wrote_header = True\n        inst.chunked_response = True\n        inst.finish()\n        self.assertEqual(inst.channel.written, b\"0\\r\\n\\r\\n\")\n\n    def test_write_wrote_header(self):\n        inst = self._makeOne()\n        inst.wrote_header = True\n        inst.complete = True\n        inst.content_length = 3\n        inst.write(b\"abc\")\n        self.assertEqual(inst.channel.written, b\"abc\")\n\n    def test_write_header_not_written(self):\n        inst = self._makeOne()\n        inst.wrote_header = False\n        inst.complete = True\n        inst.write(b\"abc\")\n        self.assertTrue(inst.channel.written)\n        self.assertEqual(inst.wrote_header, True)\n\n    def test_write_start_response_uncalled(self):\n        inst = self._makeOne()\n        self.assertRaises(RuntimeError, inst.write, b\"\")\n\n    def test_write_chunked_response(self):\n        inst = self._makeOne()\n        inst.wrote_header = True\n        inst.chunked_response = True\n        inst.complete = True\n        inst.write(b\"abc\")\n        self.assertEqual(inst.channel.written, b\"3\\r\\nabc\\r\\n\")\n\n    def test_write_preexisting_content_length(self):\n        inst = self._makeOne()\n        inst.wrote_header = True\n        inst.complete = True\n        inst.content_length = 1\n        inst.logger = DummyLogger()\n        inst.write(b\"abc\")\n        self.assertTrue(inst.channel.written)\n        self.assertEqual(inst.logged_write_excess, True)\n        self.assertEqual(len(inst.logger.logged), 1)\n\n\nclass TestWSGITask(unittest.TestCase):\n    def _makeOne(self, channel=None, request=None):\n        if channel is None:\n            channel = DummyChannel()\n        if request is None:\n            request = DummyParser()\n        from waitress.task import WSGITask\n\n        return WSGITask(channel, request)\n\n    def test_service(self):\n        inst = self._makeOne()\n\n        def execute():\n            inst.executed = True\n\n        inst.execute = execute\n        inst.complete = True\n        inst.service()\n        self.assertTrue(inst.start_time)\n        self.assertTrue(inst.close_on_finish)\n        self.assertTrue(inst.channel.written)\n        self.assertEqual(inst.executed, True)\n\n    def test_service_server_raises_socket_error(self):\n        import socket\n\n        inst = self._makeOne()\n\n        def execute():\n            raise socket.error\n\n        inst.execute = execute\n        self.assertRaises(socket.error, inst.service)\n        self.assertTrue(inst.start_time)\n        self.assertTrue(inst.close_on_finish)\n        self.assertFalse(inst.channel.written)\n\n    def test_execute_app_calls_start_response_twice_wo_exc_info(self):\n        def app(environ, start_response):\n            start_response(\"200 OK\", [])\n            start_response(\"200 OK\", [])\n\n        inst = self._makeOne()\n        inst.channel.server.application = app\n        self.assertRaises(AssertionError, inst.execute)\n\n    def test_execute_app_calls_start_response_w_exc_info_complete(self):\n        def app(environ, start_response):\n            start_response(\"200 OK\", [], [ValueError, ValueError(), None])\n            return [b\"a\"]\n\n        inst = self._makeOne()\n        inst.complete = True\n        inst.channel.server.application = app\n        inst.execute()\n        self.assertTrue(inst.complete)\n        self.assertEqual(inst.status, \"200 OK\")\n        self.assertTrue(inst.channel.written)\n\n    def test_execute_app_calls_start_response_w_excinf_headers_unwritten(self):\n        def app(environ, start_response):\n            start_response(\"200 OK\", [], [ValueError, None, None])\n            return [b\"a\"]\n\n        inst = self._makeOne()\n        inst.wrote_header = False\n        inst.channel.server.application = app\n        inst.response_headers = [(\"a\", \"b\")]\n        inst.execute()\n        self.assertTrue(inst.complete)\n        self.assertEqual(inst.status, \"200 OK\")\n        self.assertTrue(inst.channel.written)\n        self.assertFalse((\"a\", \"b\") in inst.response_headers)\n\n    def test_execute_app_calls_start_response_w_excinf_headers_written(self):\n        def app(environ, start_response):\n            start_response(\"200 OK\", [], [ValueError, ValueError(), None])\n\n        inst = self._makeOne()\n        inst.complete = True\n        inst.wrote_header = True\n        inst.channel.server.application = app\n        self.assertRaises(ValueError, inst.execute)\n\n    def test_execute_bad_header_key(self):\n        def app(environ, start_response):\n            start_response(\"200 OK\", [(None, \"a\")])\n\n        inst = self._makeOne()\n        inst.channel.server.application = app\n        self.assertRaises(AssertionError, inst.execute)\n\n    def test_execute_bad_header_value(self):\n        def app(environ, start_response):\n            start_response(\"200 OK\", [(\"a\", None)])\n\n        inst = self._makeOne()\n        inst.channel.server.application = app\n        self.assertRaises(AssertionError, inst.execute)\n\n    def test_execute_hopbyhop_header(self):\n        def app(environ, start_response):\n            start_response(\"200 OK\", [(\"Connection\", \"close\")])\n\n        inst = self._makeOne()\n        inst.channel.server.application = app\n        self.assertRaises(AssertionError, inst.execute)\n\n    def test_execute_bad_header_value_control_characters(self):\n        def app(environ, start_response):\n            start_response(\"200 OK\", [(\"a\", \"\\n\")])\n\n        inst = self._makeOne()\n        inst.channel.server.application = app\n        self.assertRaises(ValueError, inst.execute)\n\n    def test_execute_bad_header_name_control_characters(self):\n        def app(environ, start_response):\n            start_response(\"200 OK\", [(\"a\\r\", \"value\")])\n\n        inst = self._makeOne()\n        inst.channel.server.application = app\n        self.assertRaises(ValueError, inst.execute)\n\n    def test_execute_bad_status_control_characters(self):\n        def app(environ, start_response):\n            start_response(\"200 OK\\r\", [])\n\n        inst = self._makeOne()\n        inst.channel.server.application = app\n        self.assertRaises(ValueError, inst.execute)\n\n    def test_preserve_header_value_order(self):\n        def app(environ, start_response):\n            write = start_response(\"200 OK\", [(\"C\", \"b\"), (\"A\", \"b\"), (\"A\", \"a\")])\n            write(b\"abc\")\n            return []\n\n        inst = self._makeOne()\n        inst.channel.server.application = app\n        inst.execute()\n        self.assertTrue(b\"A: b\\r\\nA: a\\r\\nC: b\\r\\n\" in inst.channel.written)\n\n    def test_execute_bad_status_value(self):\n        def app(environ, start_response):\n            start_response(None, [])\n\n        inst = self._makeOne()\n        inst.channel.server.application = app\n        self.assertRaises(AssertionError, inst.execute)\n\n    def test_execute_with_content_length_header(self):\n        def app(environ, start_response):\n            start_response(\"200 OK\", [(\"Content-Length\", \"1\")])\n            return [b\"a\"]\n\n        inst = self._makeOne()\n        inst.channel.server.application = app\n        inst.execute()\n        self.assertEqual(inst.content_length, 1)\n\n    def test_execute_app_calls_write(self):\n        def app(environ, start_response):\n            write = start_response(\"200 OK\", [(\"Content-Length\", \"3\")])\n            write(b\"abc\")\n            return []\n\n        inst = self._makeOne()\n        inst.channel.server.application = app\n        inst.execute()\n        self.assertEqual(inst.channel.written[-3:], b\"abc\")\n\n    def test_execute_app_returns_len1_chunk_without_cl(self):\n        def app(environ, start_response):\n            start_response(\"200 OK\", [])\n            return [b\"abc\"]\n\n        inst = self._makeOne()\n        inst.channel.server.application = app\n        inst.execute()\n        self.assertEqual(inst.content_length, 3)\n\n    def test_execute_app_returns_empty_chunk_as_first(self):\n        def app(environ, start_response):\n            start_response(\"200 OK\", [])\n            return [\"\", b\"abc\"]\n\n        inst = self._makeOne()\n        inst.channel.server.application = app\n        inst.execute()\n        self.assertEqual(inst.content_length, None)\n\n    def test_execute_app_returns_too_many_bytes(self):\n        def app(environ, start_response):\n            start_response(\"200 OK\", [(\"Content-Length\", \"1\")])\n            return [b\"abc\"]\n\n        inst = self._makeOne()\n        inst.channel.server.application = app\n        inst.logger = DummyLogger()\n        inst.execute()\n        self.assertEqual(inst.close_on_finish, True)\n        self.assertEqual(len(inst.logger.logged), 1)\n\n    def test_execute_app_returns_too_few_bytes(self):\n        def app(environ, start_response):\n            start_response(\"200 OK\", [(\"Content-Length\", \"3\")])\n            return [b\"a\"]\n\n        inst = self._makeOne()\n        inst.channel.server.application = app\n        inst.logger = DummyLogger()\n        inst.execute()\n        self.assertEqual(inst.close_on_finish, True)\n        self.assertEqual(len(inst.logger.logged), 1)\n\n    def test_execute_app_do_not_warn_on_head(self):\n        def app(environ, start_response):\n            start_response(\"200 OK\", [(\"Content-Length\", \"3\")])\n            return [b\"\"]\n\n        inst = self._makeOne()\n        inst.request.command = \"HEAD\"\n        inst.channel.server.application = app\n        inst.logger = DummyLogger()\n        inst.execute()\n        self.assertEqual(inst.close_on_finish, True)\n        self.assertEqual(len(inst.logger.logged), 0)\n\n    def test_execute_app_without_body_204_logged(self):\n        def app(environ, start_response):\n            start_response(\"204 No Content\", [(\"Content-Length\", \"3\")])\n            return [b\"abc\"]\n\n        inst = self._makeOne()\n        inst.channel.server.application = app\n        inst.logger = DummyLogger()\n        inst.execute()\n        self.assertEqual(inst.close_on_finish, True)\n        self.assertNotIn(b\"abc\", inst.channel.written)\n        self.assertNotIn(b\"Content-Length\", inst.channel.written)\n        self.assertNotIn(b\"Transfer-Encoding\", inst.channel.written)\n        self.assertEqual(len(inst.logger.logged), 1)\n\n    def test_execute_app_without_body_304_logged(self):\n        def app(environ, start_response):\n            start_response(\"304 Not Modified\", [(\"Content-Length\", \"3\")])\n            return [b\"abc\"]\n\n        inst = self._makeOne()\n        inst.channel.server.application = app\n        inst.logger = DummyLogger()\n        inst.execute()\n        self.assertEqual(inst.close_on_finish, True)\n        self.assertNotIn(b\"abc\", inst.channel.written)\n        self.assertNotIn(b\"Content-Length\", inst.channel.written)\n        self.assertNotIn(b\"Transfer-Encoding\", inst.channel.written)\n        self.assertEqual(len(inst.logger.logged), 1)\n\n    def test_execute_app_returns_closeable(self):\n        class closeable(list):\n            def close(self):\n                self.closed = True\n\n        foo = closeable([b\"abc\"])\n\n        def app(environ, start_response):\n            start_response(\"200 OK\", [(\"Content-Length\", \"3\")])\n            return foo\n\n        inst = self._makeOne()\n        inst.channel.server.application = app\n        inst.execute()\n        self.assertEqual(foo.closed, True)\n\n    def test_execute_app_returns_filewrapper_prepare_returns_True(self):\n        from waitress.buffers import ReadOnlyFileBasedBuffer\n\n        f = io.BytesIO(b\"abc\")\n        app_iter = ReadOnlyFileBasedBuffer(f, 8192)\n\n        def app(environ, start_response):\n            start_response(\"200 OK\", [(\"Content-Length\", \"3\")])\n            return app_iter\n\n        inst = self._makeOne()\n        inst.channel.server.application = app\n        inst.execute()\n        self.assertTrue(inst.channel.written)  # header\n        self.assertEqual(inst.channel.otherdata, [app_iter])\n\n    def test_execute_app_returns_filewrapper_prepare_returns_True_nocl(self):\n        from waitress.buffers import ReadOnlyFileBasedBuffer\n\n        f = io.BytesIO(b\"abc\")\n        app_iter = ReadOnlyFileBasedBuffer(f, 8192)\n\n        def app(environ, start_response):\n            start_response(\"200 OK\", [])\n            return app_iter\n\n        inst = self._makeOne()\n        inst.channel.server.application = app\n        inst.execute()\n        self.assertTrue(inst.channel.written)  # header\n        self.assertEqual(inst.channel.otherdata, [app_iter])\n        self.assertEqual(inst.content_length, 3)\n\n    def test_execute_app_returns_filewrapper_prepare_returns_True_badcl(self):\n        from waitress.buffers import ReadOnlyFileBasedBuffer\n\n        f = io.BytesIO(b\"abc\")\n        app_iter = ReadOnlyFileBasedBuffer(f, 8192)\n\n        def app(environ, start_response):\n            start_response(\"200 OK\", [])\n            return app_iter\n\n        inst = self._makeOne()\n        inst.channel.server.application = app\n        inst.content_length = 10\n        inst.response_headers = [(\"Content-Length\", \"10\")]\n        inst.execute()\n        self.assertTrue(inst.channel.written)  # header\n        self.assertEqual(inst.channel.otherdata, [app_iter])\n        self.assertEqual(inst.content_length, 3)\n        self.assertEqual(dict(inst.response_headers)[\"Content-Length\"], \"3\")\n\n    def test_get_environment_already_cached(self):\n        inst = self._makeOne()\n        inst.environ = object()\n        self.assertEqual(inst.get_environment(), inst.environ)\n\n    def test_get_environment_path_startswith_more_than_one_slash(self):\n        inst = self._makeOne()\n        request = DummyParser()\n        request.path = \"///abc\"\n        inst.request = request\n        environ = inst.get_environment()\n        self.assertEqual(environ[\"PATH_INFO\"], \"/abc\")\n\n    def test_get_environment_path_empty(self):\n        inst = self._makeOne()\n        request = DummyParser()\n        request.path = \"\"\n        inst.request = request\n        environ = inst.get_environment()\n        self.assertEqual(environ[\"PATH_INFO\"], \"\")\n\n    def test_get_environment_no_query(self):\n        inst = self._makeOne()\n        request = DummyParser()\n        inst.request = request\n        environ = inst.get_environment()\n        self.assertEqual(environ[\"QUERY_STRING\"], \"\")\n\n    def test_get_environment_with_query(self):\n        inst = self._makeOne()\n        request = DummyParser()\n        request.query = \"abc\"\n        inst.request = request\n        environ = inst.get_environment()\n        self.assertEqual(environ[\"QUERY_STRING\"], \"abc\")\n\n    def test_get_environ_with_url_prefix_miss(self):\n        inst = self._makeOne()\n        inst.channel.server.adj.url_prefix = \"/foo\"\n        request = DummyParser()\n        request.path = \"/bar\"\n        inst.request = request\n        environ = inst.get_environment()\n        self.assertEqual(environ[\"PATH_INFO\"], \"/bar\")\n        self.assertEqual(environ[\"SCRIPT_NAME\"], \"/foo\")\n\n    def test_get_environ_with_url_prefix_hit(self):\n        inst = self._makeOne()\n        inst.channel.server.adj.url_prefix = \"/foo\"\n        request = DummyParser()\n        request.path = \"/foo/fuz\"\n        inst.request = request\n        environ = inst.get_environment()\n        self.assertEqual(environ[\"PATH_INFO\"], \"/fuz\")\n        self.assertEqual(environ[\"SCRIPT_NAME\"], \"/foo\")\n\n    def test_get_environ_with_url_prefix_empty_path(self):\n        inst = self._makeOne()\n        inst.channel.server.adj.url_prefix = \"/foo\"\n        request = DummyParser()\n        request.path = \"/foo\"\n        inst.request = request\n        environ = inst.get_environment()\n        self.assertEqual(environ[\"PATH_INFO\"], \"\")\n        self.assertEqual(environ[\"SCRIPT_NAME\"], \"/foo\")\n\n    def test_get_environment_values(self):\n        import sys\n\n        inst = self._makeOne()\n        request = DummyParser()\n        request.headers = {\n            \"CONTENT_TYPE\": \"abc\",\n            \"CONTENT_LENGTH\": \"10\",\n            \"X_FOO\": \"BAR\",\n            \"CONNECTION\": \"close\",\n        }\n        request.query = \"abc\"\n        inst.request = request\n        environ = inst.get_environment()\n\n        # nail the keys of environ\n        self.assertEqual(\n            sorted(environ.keys()),\n            [\n                \"CONTENT_LENGTH\",\n                \"CONTENT_TYPE\",\n                \"HTTP_CONNECTION\",\n                \"HTTP_X_FOO\",\n                \"PATH_INFO\",\n                \"QUERY_STRING\",\n                \"REMOTE_ADDR\",\n                \"REMOTE_HOST\",\n                \"REMOTE_PORT\",\n                \"REQUEST_METHOD\",\n                \"SCRIPT_NAME\",\n                \"SERVER_NAME\",\n                \"SERVER_PORT\",\n                \"SERVER_PROTOCOL\",\n                \"SERVER_SOFTWARE\",\n                \"wsgi.errors\",\n                \"wsgi.file_wrapper\",\n                \"wsgi.input\",\n                \"wsgi.input_terminated\",\n                \"wsgi.multiprocess\",\n                \"wsgi.multithread\",\n                \"wsgi.run_once\",\n                \"wsgi.url_scheme\",\n                \"wsgi.version\",\n            ],\n        )\n\n        self.assertEqual(environ[\"REQUEST_METHOD\"], \"GET\")\n        self.assertEqual(environ[\"SERVER_PORT\"], \"80\")\n        self.assertEqual(environ[\"SERVER_NAME\"], \"localhost\")\n        self.assertEqual(environ[\"SERVER_SOFTWARE\"], \"waitress\")\n        self.assertEqual(environ[\"SERVER_PROTOCOL\"], \"HTTP/1.0\")\n        self.assertEqual(environ[\"SCRIPT_NAME\"], \"\")\n        self.assertEqual(environ[\"HTTP_CONNECTION\"], \"close\")\n        self.assertEqual(environ[\"PATH_INFO\"], \"/\")\n        self.assertEqual(environ[\"QUERY_STRING\"], \"abc\")\n        self.assertEqual(environ[\"REMOTE_ADDR\"], \"127.0.0.1\")\n        self.assertEqual(environ[\"REMOTE_HOST\"], \"127.0.0.1\")\n        self.assertEqual(environ[\"REMOTE_PORT\"], \"39830\")\n        self.assertEqual(environ[\"CONTENT_TYPE\"], \"abc\")\n        self.assertEqual(environ[\"CONTENT_LENGTH\"], \"10\")\n        self.assertEqual(environ[\"HTTP_X_FOO\"], \"BAR\")\n        self.assertEqual(environ[\"wsgi.version\"], (1, 0))\n        self.assertEqual(environ[\"wsgi.url_scheme\"], \"http\")\n        self.assertEqual(environ[\"wsgi.errors\"], sys.stderr)\n        self.assertEqual(environ[\"wsgi.multithread\"], True)\n        self.assertEqual(environ[\"wsgi.multiprocess\"], False)\n        self.assertEqual(environ[\"wsgi.run_once\"], False)\n        self.assertEqual(environ[\"wsgi.input\"], \"stream\")\n        self.assertEqual(environ[\"wsgi.input_terminated\"], True)\n        self.assertEqual(inst.environ, environ)\n\n\nclass TestErrorTask(unittest.TestCase):\n    def _makeOne(self, channel=None, request=None):\n        if channel is None:\n            channel = DummyChannel()\n        if request is None:\n            request = DummyParser()\n            request.error = self._makeDummyError()\n        from waitress.task import ErrorTask\n\n        return ErrorTask(channel, request)\n\n    def _makeDummyError(self):\n        from waitress.utilities import Error\n\n        e = Error(\"body\")\n        e.code = 432\n        e.reason = \"Too Ugly\"\n        return e\n\n    def test_execute_http_10(self):\n        inst = self._makeOne()\n        inst.execute()\n        lines = filter_lines(inst.channel.written)\n        self.assertEqual(len(lines), 9)\n        self.assertEqual(lines[0], b\"HTTP/1.0 432 Too Ugly\")\n        self.assertEqual(lines[1], b\"Connection: close\")\n        self.assertEqual(lines[2], b\"Content-Length: 43\")\n        self.assertEqual(lines[3], b\"Content-Type: text/plain\")\n        self.assertTrue(lines[4])\n        self.assertEqual(lines[5], b\"Server: waitress\")\n        self.assertEqual(lines[6], b\"Too Ugly\")\n        self.assertEqual(lines[7], b\"body\")\n        self.assertEqual(lines[8], b\"(generated by waitress)\")\n\n    def test_execute_http_11(self):\n        inst = self._makeOne()\n        inst.version = \"1.1\"\n        inst.execute()\n        lines = filter_lines(inst.channel.written)\n        self.assertEqual(len(lines), 8)\n        self.assertEqual(lines[0], b\"HTTP/1.1 432 Too Ugly\")\n        self.assertEqual(lines[1], b\"Content-Length: 43\")\n        self.assertEqual(lines[2], b\"Content-Type: text/plain\")\n        self.assertTrue(lines[3])\n        self.assertEqual(lines[4], b\"Server: waitress\")\n        self.assertEqual(lines[5], b\"Too Ugly\")\n        self.assertEqual(lines[6], b\"body\")\n        self.assertEqual(lines[7], b\"(generated by waitress)\")\n\n    def test_execute_http_11_close(self):\n        inst = self._makeOne()\n        inst.version = \"1.1\"\n        inst.request.headers[\"CONNECTION\"] = \"close\"\n        inst.execute()\n        lines = filter_lines(inst.channel.written)\n        self.assertEqual(len(lines), 9)\n        self.assertEqual(lines[0], b\"HTTP/1.1 432 Too Ugly\")\n        self.assertEqual(lines[1], b\"Connection: close\")\n        self.assertEqual(lines[2], b\"Content-Length: 43\")\n        self.assertEqual(lines[3], b\"Content-Type: text/plain\")\n        self.assertTrue(lines[4])\n        self.assertEqual(lines[5], b\"Server: waitress\")\n        self.assertEqual(lines[6], b\"Too Ugly\")\n        self.assertEqual(lines[7], b\"body\")\n        self.assertEqual(lines[8], b\"(generated by waitress)\")\n\n    def test_execute_http_11_keep(self):\n        inst = self._makeOne()\n        inst.version = \"1.1\"\n        inst.request.headers[\"CONNECTION\"] = \"keep-alive\"\n        inst.execute()\n        lines = filter_lines(inst.channel.written)\n        self.assertEqual(len(lines), 8)\n        self.assertEqual(lines[0], b\"HTTP/1.1 432 Too Ugly\")\n        self.assertEqual(lines[1], b\"Content-Length: 43\")\n        self.assertEqual(lines[2], b\"Content-Type: text/plain\")\n        self.assertTrue(lines[3])\n        self.assertEqual(lines[4], b\"Server: waitress\")\n        self.assertEqual(lines[5], b\"Too Ugly\")\n        self.assertEqual(lines[6], b\"body\")\n        self.assertEqual(lines[7], b\"(generated by waitress)\")\n\n\nclass DummyTask(object):\n    serviced = False\n    cancelled = False\n\n    def service(self):\n        self.serviced = True\n\n    def cancel(self):\n        self.cancelled = True\n\n\nclass DummyAdj(object):\n    log_socket_errors = True\n    ident = \"waitress\"\n    host = \"127.0.0.1\"\n    port = 80\n    url_prefix = \"\"\n\n\nclass DummyServer(object):\n    server_name = \"localhost\"\n    effective_port = 80\n\n    def __init__(self):\n        self.adj = DummyAdj()\n\n\nclass DummyChannel(object):\n    closed_when_done = False\n    adj = DummyAdj()\n    creation_time = 0\n    addr = (\"127.0.0.1\", 39830)\n\n    def __init__(self, server=None):\n        if server is None:\n            server = DummyServer()\n        self.server = server\n        self.written = b\"\"\n        self.otherdata = []\n\n    def write_soon(self, data):\n        if isinstance(data, bytes):\n            self.written += data\n        else:\n            self.otherdata.append(data)\n        return len(data)\n\n\nclass DummyParser(object):\n    version = \"1.0\"\n    command = \"GET\"\n    path = \"/\"\n    query = \"\"\n    url_scheme = \"http\"\n    expect_continue = False\n    headers_finished = False\n\n    def __init__(self):\n        self.headers = {}\n\n    def get_body_stream(self):\n        return \"stream\"\n\n\ndef filter_lines(s):\n    return list(filter(None, s.split(b\"\\r\\n\")))\n\n\nclass DummyLogger(object):\n    def __init__(self):\n        self.logged = []\n\n    def warning(self, msg, *args):\n        self.logged.append(msg % args)\n\n    def exception(self, msg, *args):\n        self.logged.append(msg % args)\n", "##############################################################################\n#\n# Copyright (c) 2002 Zope Foundation and Contributors.\n# All Rights Reserved.\n#\n# This software is subject to the provisions of the Zope Public License,\n# Version 2.1 (ZPL).  A copy of the ZPL should accompany this distribution.\n# THIS SOFTWARE IS PROVIDED \"AS IS\" AND ANY AND ALL EXPRESS OR IMPLIED\n# WARRANTIES ARE DISCLAIMED, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\n# WARRANTIES OF TITLE, MERCHANTABILITY, AGAINST INFRINGEMENT, AND FITNESS\n# FOR A PARTICULAR PURPOSE.\n#\n##############################################################################\n\nimport unittest\n\n\nclass Test_parse_http_date(unittest.TestCase):\n    def _callFUT(self, v):\n        from waitress.utilities import parse_http_date\n\n        return parse_http_date(v)\n\n    def test_rfc850(self):\n        val = \"Tuesday, 08-Feb-94 14:15:29 GMT\"\n        result = self._callFUT(val)\n        self.assertEqual(result, 760716929)\n\n    def test_rfc822(self):\n        val = \"Sun, 08 Feb 1994 14:15:29 GMT\"\n        result = self._callFUT(val)\n        self.assertEqual(result, 760716929)\n\n    def test_neither(self):\n        val = \"\"\n        result = self._callFUT(val)\n        self.assertEqual(result, 0)\n\n\nclass Test_build_http_date(unittest.TestCase):\n    def test_rountdrip(self):\n        from waitress.utilities import build_http_date, parse_http_date\n        from time import time\n\n        t = int(time())\n        self.assertEqual(t, parse_http_date(build_http_date(t)))\n\n\nclass Test_unpack_rfc850(unittest.TestCase):\n    def _callFUT(self, val):\n        from waitress.utilities import unpack_rfc850, rfc850_reg\n\n        return unpack_rfc850(rfc850_reg.match(val.lower()))\n\n    def test_it(self):\n        val = \"Tuesday, 08-Feb-94 14:15:29 GMT\"\n        result = self._callFUT(val)\n        self.assertEqual(result, (1994, 2, 8, 14, 15, 29, 0, 0, 0))\n\n\nclass Test_unpack_rfc_822(unittest.TestCase):\n    def _callFUT(self, val):\n        from waitress.utilities import unpack_rfc822, rfc822_reg\n\n        return unpack_rfc822(rfc822_reg.match(val.lower()))\n\n    def test_it(self):\n        val = \"Sun, 08 Feb 1994 14:15:29 GMT\"\n        result = self._callFUT(val)\n        self.assertEqual(result, (1994, 2, 8, 14, 15, 29, 0, 0, 0))\n\n\nclass Test_find_double_newline(unittest.TestCase):\n    def _callFUT(self, val):\n        from waitress.utilities import find_double_newline\n\n        return find_double_newline(val)\n\n    def test_empty(self):\n        self.assertEqual(self._callFUT(b\"\"), -1)\n\n    def test_one_linefeed(self):\n        self.assertEqual(self._callFUT(b\"\\n\"), -1)\n\n    def test_double_linefeed(self):\n        self.assertEqual(self._callFUT(b\"\\n\\n\"), 2)\n\n    def test_one_crlf(self):\n        self.assertEqual(self._callFUT(b\"\\r\\n\"), -1)\n\n    def test_double_crfl(self):\n        self.assertEqual(self._callFUT(b\"\\r\\n\\r\\n\"), 4)\n\n    def test_mixed(self):\n        self.assertEqual(self._callFUT(b\"\\n\\n00\\r\\n\\r\\n\"), 2)\n\n\nclass TestBadRequest(unittest.TestCase):\n    def _makeOne(self):\n        from waitress.utilities import BadRequest\n\n        return BadRequest(1)\n\n    def test_it(self):\n        inst = self._makeOne()\n        self.assertEqual(inst.body, 1)\n\n\nclass Test_undquote(unittest.TestCase):\n    def _callFUT(self, value):\n        from waitress.utilities import undquote\n\n        return undquote(value)\n\n    def test_empty(self):\n        self.assertEqual(self._callFUT(\"\"), \"\")\n\n    def test_quoted(self):\n        self.assertEqual(self._callFUT('\"test\"'), \"test\")\n\n    def test_unquoted(self):\n        self.assertEqual(self._callFUT(\"test\"), \"test\")\n\n    def test_quoted_backslash_quote(self):\n        self.assertEqual(self._callFUT('\"\\\\\"\"'), '\"')\n\n    def test_quoted_htab(self):\n        self.assertEqual(self._callFUT('\"\\t\"'), \"\\t\")\n\n    def test_quoted_backslash_htab(self):\n        self.assertEqual(self._callFUT('\"\\\\\\t\"'), \"\\t\")\n\n    def test_quoted_backslash_invalid(self):\n        self.assertRaises(ValueError, self._callFUT, '\"\\\\\"')\n\n    def test_invalid_quoting(self):\n        self.assertRaises(ValueError, self._callFUT, '\"test')\n\n    def test_invalid_quoting_single_quote(self):\n        self.assertRaises(ValueError, self._callFUT, '\"')\n", "##############################################################################\n#\n# Copyright (c) 2004 Zope Foundation and Contributors.\n# All Rights Reserved.\n#\n# This software is subject to the provisions of the Zope Public License,\n# Version 2.1 (ZPL).  A copy of the ZPL should accompany this distribution.\n# THIS SOFTWARE IS PROVIDED \"AS IS\" AND ANY AND ALL EXPRESS OR IMPLIED\n# WARRANTIES ARE DISCLAIMED, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\n# WARRANTIES OF TITLE, MERCHANTABILITY, AGAINST INFRINGEMENT, AND FITNESS\n# FOR A PARTICULAR PURPOSE.\n#\n##############################################################################\n\"\"\"Utility functions\n\"\"\"\n\nimport calendar\nimport errno\nimport logging\nimport os\nimport re\nimport stat\nimport time\n\nlogger = logging.getLogger(\"waitress\")\nqueue_logger = logging.getLogger(\"waitress.queue\")\n\n\ndef find_double_newline(s):\n    \"\"\"Returns the position just after a double newline in the given string.\"\"\"\n    pos1 = s.find(b\"\\n\\r\\n\")  # One kind of double newline\n    if pos1 >= 0:\n        pos1 += 3\n    pos2 = s.find(b\"\\n\\n\")  # Another kind of double newline\n    if pos2 >= 0:\n        pos2 += 2\n\n    if pos1 >= 0:\n        if pos2 >= 0:\n            return min(pos1, pos2)\n        else:\n            return pos1\n    else:\n        return pos2\n\n\ndef concat(*args):\n    return \"\".join(args)\n\n\ndef join(seq, field=\" \"):\n    return field.join(seq)\n\n\ndef group(s):\n    return \"(\" + s + \")\"\n\n\nshort_days = [\"sun\", \"mon\", \"tue\", \"wed\", \"thu\", \"fri\", \"sat\"]\nlong_days = [\n    \"sunday\",\n    \"monday\",\n    \"tuesday\",\n    \"wednesday\",\n    \"thursday\",\n    \"friday\",\n    \"saturday\",\n]\n\nshort_day_reg = group(join(short_days, \"|\"))\nlong_day_reg = group(join(long_days, \"|\"))\n\ndaymap = {}\nfor i in range(7):\n    daymap[short_days[i]] = i\n    daymap[long_days[i]] = i\n\nhms_reg = join(3 * [group(\"[0-9][0-9]\")], \":\")\n\nmonths = [\n    \"jan\",\n    \"feb\",\n    \"mar\",\n    \"apr\",\n    \"may\",\n    \"jun\",\n    \"jul\",\n    \"aug\",\n    \"sep\",\n    \"oct\",\n    \"nov\",\n    \"dec\",\n]\n\nmonmap = {}\nfor i in range(12):\n    monmap[months[i]] = i + 1\n\nmonths_reg = group(join(months, \"|\"))\n\n# From draft-ietf-http-v11-spec-07.txt/3.3.1\n#       Sun, 06 Nov 1994 08:49:37 GMT  ; RFC 822, updated by RFC 1123\n#       Sunday, 06-Nov-94 08:49:37 GMT ; RFC 850, obsoleted by RFC 1036\n#       Sun Nov  6 08:49:37 1994       ; ANSI C's asctime() format\n\n# rfc822 format\nrfc822_date = join(\n    [\n        concat(short_day_reg, \",\"),  # day\n        group(\"[0-9][0-9]?\"),  # date\n        months_reg,  # month\n        group(\"[0-9]+\"),  # year\n        hms_reg,  # hour minute second\n        \"gmt\",\n    ],\n    \" \",\n)\n\nrfc822_reg = re.compile(rfc822_date)\n\n\ndef unpack_rfc822(m):\n    g = m.group\n    return (\n        int(g(4)),  # year\n        monmap[g(3)],  # month\n        int(g(2)),  # day\n        int(g(5)),  # hour\n        int(g(6)),  # minute\n        int(g(7)),  # second\n        0,\n        0,\n        0,\n    )\n\n\n# rfc850 format\nrfc850_date = join(\n    [\n        concat(long_day_reg, \",\"),\n        join([group(\"[0-9][0-9]?\"), months_reg, group(\"[0-9]+\")], \"-\"),\n        hms_reg,\n        \"gmt\",\n    ],\n    \" \",\n)\n\nrfc850_reg = re.compile(rfc850_date)\n# they actually unpack the same way\ndef unpack_rfc850(m):\n    g = m.group\n    yr = g(4)\n    if len(yr) == 2:\n        yr = \"19\" + yr\n    return (\n        int(yr),  # year\n        monmap[g(3)],  # month\n        int(g(2)),  # day\n        int(g(5)),  # hour\n        int(g(6)),  # minute\n        int(g(7)),  # second\n        0,\n        0,\n        0,\n    )\n\n\n# parsdate.parsedate - ~700/sec.\n# parse_http_date    - ~1333/sec.\n\nweekdayname = [\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\"]\nmonthname = [\n    None,\n    \"Jan\",\n    \"Feb\",\n    \"Mar\",\n    \"Apr\",\n    \"May\",\n    \"Jun\",\n    \"Jul\",\n    \"Aug\",\n    \"Sep\",\n    \"Oct\",\n    \"Nov\",\n    \"Dec\",\n]\n\n\ndef build_http_date(when):\n    year, month, day, hh, mm, ss, wd, y, z = time.gmtime(when)\n    return \"%s, %02d %3s %4d %02d:%02d:%02d GMT\" % (\n        weekdayname[wd],\n        day,\n        monthname[month],\n        year,\n        hh,\n        mm,\n        ss,\n    )\n\n\ndef parse_http_date(d):\n    d = d.lower()\n    m = rfc850_reg.match(d)\n    if m and m.end() == len(d):\n        retval = int(calendar.timegm(unpack_rfc850(m)))\n    else:\n        m = rfc822_reg.match(d)\n        if m and m.end() == len(d):\n            retval = int(calendar.timegm(unpack_rfc822(m)))\n        else:\n            return 0\n    return retval\n\n\n# RFC 5234 Appendix B.1 \"Core Rules\":\n# VCHAR         =  %x21-7E\n#                  ; visible (printing) characters\nvchar_re = \"\\x21-\\x7e\"\n\n# RFC 7230 Section 3.2.6 \"Field Value Components\":\n# quoted-string = DQUOTE *( qdtext / quoted-pair ) DQUOTE\n# qdtext        = HTAB / SP /%x21 / %x23-5B / %x5D-7E / obs-text\n# obs-text      = %x80-FF\n# quoted-pair   = \"\\\" ( HTAB / SP / VCHAR / obs-text )\nobs_text_re = \"\\x80-\\xff\"\n\n# The '\\\\' between \\x5b and \\x5d is needed to escape \\x5d (']')\nqdtext_re = \"[\\t \\x21\\x23-\\x5b\\\\\\x5d-\\x7e\" + obs_text_re + \"]\"\n\nquoted_pair_re = r\"\\\\\" + \"([\\t \" + vchar_re + obs_text_re + \"])\"\nquoted_string_re = '\"(?:(?:' + qdtext_re + \")|(?:\" + quoted_pair_re + '))*\"'\n\nquoted_string = re.compile(quoted_string_re)\nquoted_pair = re.compile(quoted_pair_re)\n\n\ndef undquote(value):\n    if value.startswith('\"') and value.endswith('\"'):\n        # So it claims to be DQUOTE'ed, let's validate that\n        matches = quoted_string.match(value)\n\n        if matches and matches.end() == len(value):\n            # Remove the DQUOTE's from the value\n            value = value[1:-1]\n\n            # Remove all backslashes that are followed by a valid vchar or\n            # obs-text\n            value = quoted_pair.sub(r\"\\1\", value)\n\n            return value\n    elif not value.startswith('\"') and not value.endswith('\"'):\n        return value\n\n    raise ValueError(\"Invalid quoting in value\")\n\n\ndef cleanup_unix_socket(path):\n    try:\n        st = os.stat(path)\n    except OSError as exc:\n        if exc.errno != errno.ENOENT:\n            raise  # pragma: no cover\n    else:\n        if stat.S_ISSOCK(st.st_mode):\n            try:\n                os.remove(path)\n            except OSError:  # pragma: no cover\n                # avoid race condition error during tests\n                pass\n\n\nclass Error(object):\n    def __init__(self, body):\n        self.body = body\n\n    def to_response(self):\n        status = \"%s %s\" % (self.code, self.reason)\n        body = \"%s\\r\\n\\r\\n%s\" % (self.reason, self.body)\n        tag = \"\\r\\n\\r\\n(generated by waitress)\"\n        body = body + tag\n        headers = [(\"Content-Type\", \"text/plain\")]\n        return status, headers, body\n\n    def wsgi_response(self, environ, start_response):\n        status, headers, body = self.to_response()\n        start_response(status, headers)\n        yield body\n\n\nclass BadRequest(Error):\n    code = 400\n    reason = \"Bad Request\"\n\n\nclass RequestHeaderFieldsTooLarge(BadRequest):\n    code = 431\n    reason = \"Request Header Fields Too Large\"\n\n\nclass RequestEntityTooLarge(BadRequest):\n    code = 413\n    reason = \"Request Entity Too Large\"\n\n\nclass InternalServerError(Error):\n    code = 500\n    reason = \"Internal Server Error\"\n"], "fixing_code": ["1.4.0 (2019-12-20)\n------------------\n\nBugfixes\n~~~~~~~~\n\n- Waitress used to slam the door shut on HTTP pipelined requests without\n  setting the ``Connection: close`` header as appropriate in the response. This\n  is of course not very friendly. Waitress now explicitly sets the header when\n  responding with an internally generated error such as 400 Bad Request or 500\n  Internal Server Error to notify the remote client that it will be closing the\n  connection after the response is sent.\n\n- Waitress no longer allows any spaces to exist between the header field-name\n  and the colon. While waitress did not strip the space and thereby was not\n  vulnerable to any potential header field-name confusion, it should have sent\n  back a 400 Bad Request. See https://github.com/Pylons/waitress/issues/273\n\nSecurity Fixes\n~~~~~~~~~~~~~~\n\n- Waitress implemented a \"MAY\" part of the RFC7230\n  (https://tools.ietf.org/html/rfc7230#section-3.5) which states:\n\n      Although the line terminator for the start-line and header fields is\n      the sequence CRLF, a recipient MAY recognize a single LF as a line\n      terminator and ignore any preceding CR.\n\n  Unfortunately if a front-end server does not parse header fields with an LF\n  the same way as it does those with a CRLF it can lead to the front-end and\n  the back-end server parsing the same HTTP message in two different ways. This\n  can lead to a potential for HTTP request smuggling/splitting whereby Waitress\n  may see two requests while the front-end server only sees a single HTTP\n  message.\n\n  For more information I can highly recommend the blog post by ZeddYu Lu\n  https://blog.zeddyu.info/2019/12/08/HTTP-Smuggling-en/\n\n- Waitress used to treat LF the same as CRLF in ``Transfer-Encoding: chunked``\n  requests, while the maintainer doesn't believe this could lead to a security\n  issue, this is no longer supported and all chunks are now validated to be\n  properly framed with CRLF as required by RFC7230.\n\n- Waitress now validates that the ``Transfer-Encoding`` header contains only\n  transfer codes that it is able to decode. At the moment that includes the\n  only valid header value being ``chunked``.\n\n  That means that if the following header is sent:\n\n  ``Transfer-Encoding: gzip, chunked``\n\n  Waitress will send back a 501 Not Implemented with an error message stating\n  as such, as while Waitress supports ``chunked`` encoding it does not support\n  ``gzip`` and it is unable to pass that to the underlying WSGI environment\n  correctly.\n\n  Waitress DOES NOT implement support for ``Transfer-Encoding: identity``\n  eventhough ``identity`` was valid in RFC2616, it was removed in RFC7230.\n  Please update your clients to remove the ``Transfer-Encoding`` header if the\n  only transfer coding is ``identity`` or update your client to use\n  ``Transfer-Encoding: chunked`` instead of ``Transfer-Encoding: identity,\n  chunked``.\n\n- While validating the ``Transfer-Encoding`` header, Waitress now properly\n  handles line-folded ``Transfer-Encoding`` headers or those that contain\n  multiple comma seperated values. This closes a potential issue where a\n  front-end server may treat the request as being a chunked request (and thus\n  ignoring the Content-Length) and Waitress using the Content-Length as it was\n  looking for the single value ``chunked`` and did not support comma seperated\n  values.\n\n- Waitress used to explicitly set the Content-Length header to 0 if it was\n  unable to parse it as an integer (for example if the Content-Length header\n  was sent twice (and thus folded together), or was invalid) thereby allowing\n  for a potential request to be split and treated as two requests by HTTP\n  pipelining support in Waitress. If Waitress is now unable to parse the\n  Content-Length header, a 400 Bad Request is sent back to the client.\n", "1.3.1 (2019-08-27)\n------------------\n\nBugfixes\n~~~~~~~~\n\n- Waitress won't accidentally throw away part of the path if it starts with a\n  double slash (``GET //testing/whatever HTTP/1.0``). WSGI applications will\n  now receive a ``PATH_INFO`` in the environment that contains\n  ``//testing/whatever`` as required. See\n  https://github.com/Pylons/waitress/issues/260 and\n  https://github.com/Pylons/waitress/pull/261\n\n\n1.3.0 (2019-04-22)\n------------------\n\nDeprecations\n~~~~~~~~~~~~\n\n- The ``send_bytes`` adjustment now defaults to ``1`` and is deprecated\n  pending removal in a future release.\n  and https://github.com/Pylons/waitress/pull/246\n\nFeatures\n~~~~~~~~\n\n- Add a new ``outbuf_high_watermark`` adjustment which is used to apply\n  backpressure on the ``app_iter`` to avoid letting it spin faster than data\n  can be written to the socket. This stabilizes responses that iterate quickly\n  with a lot of data.\n  See https://github.com/Pylons/waitress/pull/242\n\n- Stop early and close the ``app_iter`` when attempting to write to a closed\n  socket due to a client disconnect. This should notify a long-lived streaming\n  response when a client hangs up.\n  See https://github.com/Pylons/waitress/pull/238\n  and https://github.com/Pylons/waitress/pull/240\n  and https://github.com/Pylons/waitress/pull/241\n\n- Adjust the flush to output ``SO_SNDBUF`` bytes instead of whatever was\n  set in the ``send_bytes`` adjustment. ``send_bytes`` now only controls how\n  much waitress will buffer internally before flushing to the kernel, whereas\n  previously it used to also throttle how much data was sent to the kernel.\n  This change enables a streaming ``app_iter`` containing small chunks to\n  still be flushed efficiently.\n  See https://github.com/Pylons/waitress/pull/246\n\nBugfixes\n~~~~~~~~\n\n- Upon receiving a request that does not include HTTP/1.0 or HTTP/1.1 we will\n  no longer set the version to the string value \"None\". See\n  https://github.com/Pylons/waitress/pull/252 and\n  https://github.com/Pylons/waitress/issues/110\n\n- When a client closes a socket unexpectedly there was potential for memory\n  leaks in which data was written to the buffers after they were closed,\n  causing them to reopen.\n  See https://github.com/Pylons/waitress/pull/239\n\n- Fix the queue depth warnings to only show when all threads are busy.\n  See https://github.com/Pylons/waitress/pull/243\n  and https://github.com/Pylons/waitress/pull/247\n\n- Trigger the ``app_iter`` to close as part of shutdown. This will only be\n  noticeable for users of the internal server api. In more typical operations\n  the server will die before benefiting from these changes.\n  See https://github.com/Pylons/waitress/pull/245\n\n- Fix a bug in which a streaming ``app_iter`` may never cleanup data that has\n  already been sent. This would cause buffers in waitress to grow without\n  bounds. These buffers now properly rotate and release their data.\n  See https://github.com/Pylons/waitress/pull/242\n\n- Fix a bug in which non-seekable subclasses of ``io.IOBase`` would trigger\n  an exception when passed to the ``wsgi.file_wrapper`` callback.\n  See https://github.com/Pylons/waitress/pull/249\n\n1.2.1 (2019-01-25)\n------------------\n\nBugfixes\n~~~~~~~~\n\n- When given an IPv6 address in ``X-Forwarded-For`` or ``Forwarded for=``\n  waitress was placing the IP address in ``REMOTE_ADDR`` with brackets:\n  ``[2001:db8::0]``, this does not match the requirements in the CGI spec which\n  ``REMOTE_ADDR`` was lifted from. Waitress will now place the bare IPv6\n  address in ``REMOTE_ADDR``: ``2001:db8::0``. See\n  https://github.com/Pylons/waitress/pull/232 and\n  https://github.com/Pylons/waitress/issues/230\n\n1.2.0 (2019-01-15)\n------------------\n\nNo changes since the last beta release. Enjoy Waitress!\n\n1.2.0b3 (2019-01-07)\n--------------------\n\nBugfixes\n~~~~~~~~\n\n- Modified ``clear_untrusted_proxy_headers`` to be usable without a\n  ``trusted_proxy``.\n  https://github.com/Pylons/waitress/pull/228\n\n- Modified ``trusted_proxy_count`` to error when used without a\n  ``trusted_proxy``.\n  https://github.com/Pylons/waitress/pull/228\n\n1.2.0b2 (2019-02-02)\n--------------------\n\nBugfixes\n~~~~~~~~\n\n- Fixed logic to no longer warn on writes where the output is required to have\n  a body but there may not be any data to be written. Solves issue posted on\n  the Pylons Project mailing list with 1.2.0b1.\n\n1.2.0b1 (2018-12-31)\n--------------------\n\nHappy New Year!\n\nFeatures\n~~~~~~~~\n\n- Setting the ``trusted_proxy`` setting to ``'*'`` (wildcard) will allow all\n  upstreams to be considered trusted proxies, thereby allowing services behind\n  Cloudflare/ELBs to function correctly whereby there may not be a singular IP\n  address that requests are received from.\n\n  Using this setting is potentially dangerous if your server is also available\n  from anywhere on the internet, and further protections should be used to lock\n  down access to Waitress. See https://github.com/Pylons/waitress/pull/224\n\n- Waitress has increased its support of the X-Forwarded-* headers and includes\n  Forwarded (RFC7239) support. This may be used to allow proxy servers to\n  influence the WSGI environment. See\n  https://github.com/Pylons/waitress/pull/209\n\n  This also provides a new security feature when using Waitress behind a proxy\n  in that it is possible to remove untrusted proxy headers thereby making sure\n  that downstream WSGI applications don't accidentally use those proxy headers\n  to make security decisions.\n\n  The documentation has more information, see the following new arguments:\n\n  - trusted_proxy_count\n  - trusted_proxy_headers\n  - clear_untrusted_proxy_headers\n  - log_untrusted_proxy_headers (useful for debugging)\n\n  Be aware that the defaults for these are currently backwards compatible with\n  older versions of Waitress, this will change in a future release of waitress.\n  If you expect to need this behaviour please explicitly set these variables in\n  your configuration, or pin this version of waitress.\n\n  Documentation:\n  https://docs.pylonsproject.org/projects/waitress/en/latest/reverse-proxy.html\n\n- Waitress can now accept a list of sockets that are already pre-bound rather\n  than creating its own to allow for socket activation. Support for init\n  systems/other systems that create said activated sockets is not included. See\n  https://github.com/Pylons/waitress/pull/215\n\n- Server header can be omitted by specifying ``ident=None`` or ``ident=''``.\n  See https://github.com/Pylons/waitress/pull/187\n\nBugfixes\n~~~~~~~~\n\n- Waitress will no longer send Transfer-Encoding or Content-Length for 1xx,\n  204, or 304 responses, and will completely ignore any message body sent by\n  the WSGI application, making sure to follow the HTTP standard. See\n  https://github.com/Pylons/waitress/pull/166,\n  https://github.com/Pylons/waitress/issues/165,\n  https://github.com/Pylons/waitress/issues/152, and\n  https://github.com/Pylons/waitress/pull/202\n\nCompatibility\n~~~~~~~~~~~~~\n\n- Waitress has now \"vendored\" asyncore into itself as ``waitress.wasyncore``.\n  This is to cope with the eventuality that asyncore will be removed from\n  the Python standard library in 3.8 or so.\n\nDocumentation\n~~~~~~~~~~~~~\n\n- Bring in documentation of paste.translogger from Pyramid. Reorganize and\n  clean up documentation. See\n  https://github.com/Pylons/waitress/pull/205\n  https://github.com/Pylons/waitress/pull/70\n  https://github.com/Pylons/waitress/pull/206\n\n1.1.0 (2017-10-10)\n------------------\n\nFeatures\n~~~~~~~~\n\n- Waitress now has a __main__ and thus may be called with ``python -mwaitress``\n\nBugfixes\n~~~~~~~~\n\n- Waitress no longer allows lowercase HTTP verbs. This change was made to fall\n  in line with most HTTP servers. See https://github.com/Pylons/waitress/pull/170\n\n- When receiving non-ascii bytes in the request URL, waitress will no longer\n  abruptly close the connection, instead returning a 400 Bad Request. See\n  https://github.com/Pylons/waitress/pull/162 and\n  https://github.com/Pylons/waitress/issues/64\n\n1.0.2 (2017-02-04)\n------------------\n\nFeatures\n~~~~~~~~\n\n- Python 3.6 is now officially supported in Waitress\n\nBugfixes\n~~~~~~~~\n\n- Add a work-around for libc issue on Linux not following the documented\n  standards. If getnameinfo() fails because of DNS not being available it\n  should return the IP address instead of the reverse DNS entry, however\n  instead getnameinfo() raises. We catch this, and ask getnameinfo()\n  for the same information again, explicitly asking for IP address instead of\n  reverse DNS hostname. See https://github.com/Pylons/waitress/issues/149 and\n  https://github.com/Pylons/waitress/pull/153\n\n1.0.1 (2016-10-22)\n------------------\n\nBugfixes\n~~~~~~~~\n\n- IPv6 support on Windows was broken due to missing constants in the socket\n  module. This has been resolved by setting the constants on Windows if they\n  are missing. See https://github.com/Pylons/waitress/issues/138\n\n- A ValueError was raised on Windows when passing a string for the port, on\n  Windows in Python 2 using service names instead of port numbers doesn't work\n  with `getaddrinfo`. This has been resolved by attempting to convert the port\n  number to an integer, if that fails a ValueError will be raised. See\n  https://github.com/Pylons/waitress/issues/139\n\n\n1.0.0 (2016-08-31)\n------------------\n\nBugfixes\n~~~~~~~~\n\n- Removed `AI_ADDRCONFIG` from the call to `getaddrinfo`, this resolves an\n  issue whereby `getaddrinfo` wouldn't return any addresses to `bind` to on\n  hosts where there is no internet connection but localhost is requested to be\n  bound to. See https://github.com/Pylons/waitress/issues/131 for more\n  information.\n\nDeprecations\n~~~~~~~~~~~~\n\n- Python 2.6 is no longer supported.\n\nFeatures\n~~~~~~~~\n\n- IPv6 support\n\n- Waitress is now able to listen on multiple sockets, including IPv4 and IPv6.\n  Instead of passing in a host/port combination you now provide waitress with a\n  space delineated list, and it will create as many sockets as required.\n\n  .. code-block:: python\n\n\tfrom waitress import serve\n\tserve(wsgiapp, listen='0.0.0.0:8080 [::]:9090 *:6543')\n\nSecurity\n~~~~~~~~\n\n- Waitress will now drop HTTP headers that contain an underscore in the key\n  when received from a client. This is to stop any possible underscore/dash\n  conflation that may lead to security issues. See\n  https://github.com/Pylons/waitress/pull/80 and\n  https://www.djangoproject.com/weblog/2015/jan/13/security/\n\n0.9.0 (2016-04-15)\n------------------\n\nDeprecations\n~~~~~~~~~~~~\n\n- Python 3.2 is no longer supported by Waitress.\n\n- Python 2.6 will no longer be supported by Waitress in future releases.\n\nSecurity/Protections\n~~~~~~~~~~~~~~~~~~~~\n\n- Building on the changes made in pull request 117, add in checking for line\n  feed/carriage return HTTP Response Splitting in the status line, as well as\n  the key of a header. See https://github.com/Pylons/waitress/pull/124 and\n  https://github.com/Pylons/waitress/issues/122.\n\n- Waitress will no longer accept headers or status lines with\n  newline/carriage returns in them, thereby disallowing HTTP Response\n  Splitting. See https://github.com/Pylons/waitress/issues/117 for\n  more information, as well as\n  https://www.owasp.org/index.php/HTTP_Response_Splitting.\n\nBugfixes\n~~~~~~~~\n\n- FileBasedBuffer and more important ReadOnlyFileBasedBuffer no longer report\n  False when tested with bool(), instead always returning True, and becoming\n  more iterator like.\n  See: https://github.com/Pylons/waitress/pull/82 and\n  https://github.com/Pylons/waitress/issues/76\n\n- Call prune() on the output buffer at the end of a request so that it doesn't\n  continue to grow without bounds. See\n  https://github.com/Pylons/waitress/issues/111 for more information.\n\n0.8.10 (2015-09-02)\n-------------------\n\n- Add support for Python 3.4, 3.5b2, and PyPy3.\n\n- Use a nonglobal asyncore socket map by default, trying to prevent conflicts\n  with apps and libs that use the asyncore global socket map ala\n  https://github.com/Pylons/waitress/issues/63.  You can get the old\n  use-global-socket-map behavior back by passing ``asyncore.socket_map`` to the\n  ``create_server`` function as the ``map`` argument.\n\n- Waitress violated PEP 3333 with respect to reraising an exception when\n  ``start_response`` was called with an ``exc_info`` argument.  It would\n  reraise the exception even if no data had been sent to the client.  It now\n  only reraises the exception if data has actually been sent to the client.\n  See https://github.com/Pylons/waitress/pull/52 and\n  https://github.com/Pylons/waitress/issues/51\n\n- Add a ``docs`` section to tox.ini that, when run, ensures docs can be built.\n\n- If an ``application`` value of ``None`` is supplied to the ``create_server``\n  constructor function, a ValueError is now raised eagerly instead of an error\n  occuring during runtime.  See https://github.com/Pylons/waitress/pull/60\n\n- Fix parsing of multi-line (folded) headers.\n  See https://github.com/Pylons/waitress/issues/53 and\n  https://github.com/Pylons/waitress/pull/90\n\n- Switch from the low level Python thread/_thread module to the threading\n  module.\n\n- Improved exception information should module import go awry.\n\n0.8.9 (2014-05-16)\n------------------\n\n- Fix tests under Windows.  NB: to run tests under Windows, you cannot run\n  \"setup.py test\" or \"setup.py nosetests\".  Instead you must run ``python.exe\n  -c \"import nose; nose.main()\"``.  If you try to run the tests using the\n  normal method under Windows, each subprocess created by the test suite will\n  attempt to run the test suite again.  See\n  https://github.com/nose-devs/nose/issues/407 for more information.\n\n- Give the WSGI app_iter generated when ``wsgi.file_wrapper`` is used\n  (ReadOnlyFileBasedBuffer) a ``close`` method.  Do not call ``close`` on an\n  instance of such a class when it's used as a WSGI app_iter, however.  This is\n  part of a fix which prevents a leakage of file descriptors; the other part of\n  the fix was in WebOb\n  (https://github.com/Pylons/webob/commit/951a41ce57bd853947f842028bccb500bd5237da).\n\n- Allow trusted proxies to override ``wsgi.url_scheme`` via a request header,\n  ``X_FORWARDED_PROTO``.  Allows proxies which serve mixed HTTP / HTTPS\n  requests to control signal which are served as HTTPS.  See\n  https://github.com/Pylons/waitress/pull/42.\n\n0.8.8 (2013-11-30)\n------------------\n\n- Fix some cases where the creation of extremely large output buffers (greater\n  than 2GB, suspected to be buffers added via ``wsgi.file_wrapper``) might\n  cause an OverflowError on Python 2.  See\n  https://github.com/Pylons/waitress/issues/47.\n\n- When the ``url_prefix`` adjustment starts with more than one slash, all\n  slashes except one will be stripped from its beginning.  This differs from\n  older behavior where more than one leading slash would be preserved in\n  ``url_prefix``.\n\n- If a client somehow manages to send an empty path, we no longer convert the\n  empty path to a single slash in ``PATH_INFO``.  Instead, the path remains\n  empty.  According to RFC 2616 section \"5.1.2 Request-URI\", the scenario of a\n  client sending an empty path is actually not possible because the request URI\n  portion cannot be empty.\n\n- If the ``url_prefix`` adjustment matches the request path exactly, we now\n  compute ``SCRIPT_NAME`` and ``PATH_INFO`` properly.  Previously, if the\n  ``url_prefix`` was ``/foo`` and the path received from a client was ``/foo``,\n  we would set *both* ``SCRIPT_NAME`` and ``PATH_INFO`` to ``/foo``.  This was\n  incorrect.  Now in such a case we set ``PATH_INFO`` to the empty string and\n  we set ``SCRIPT_NAME`` to ``/foo``.  Note that the change we made has no\n  effect on paths that do not match the ``url_prefix`` exactly (such as\n  ``/foo/bar``); these continue to operate as they did.  See\n  https://github.com/Pylons/waitress/issues/46\n\n- Preserve header ordering of headers with the same name as per RFC 2616.  See\n  https://github.com/Pylons/waitress/pull/44\n\n- When waitress receives a ``Transfer-Encoding: chunked`` request, we no longer\n  send the ``TRANSFER_ENCODING`` nor the ``HTTP_TRANSFER_ENCODING`` value to\n  the application in the environment.  Instead, we pop this header.  Since we\n  cope with chunked requests by buffering the data in the server, we also know\n  when a chunked request has ended, and therefore we know the content length.\n  We set the content-length header in the environment, such that applications\n  effectively never know the original request was a T-E: chunked request; it\n  will appear to them as if the request is a non-chunked request with an\n  accurate content-length.\n\n- Cope with the fact that the ``Transfer-Encoding`` value is case-insensitive.\n\n- When the ``--unix-socket-perms`` option was used as an argument to\n  ``waitress-serve``, a ``TypeError`` would be raised.  See\n  https://github.com/Pylons/waitress/issues/50.\n\n0.8.7 (2013-08-29)\n------------------\n\n- The HTTP version of the response returned by waitress when it catches an\n  exception will now match the HTTP request version.\n\n- Fix: CONNECTION header will be HTTP_CONNECTION and not CONNECTION_TYPE\n  (see https://github.com/Pylons/waitress/issues/13)\n\n0.8.6 (2013-08-12)\n------------------\n\n- Do alternate type of checking for UNIX socket support, instead of checking\n  for platform == windows.\n\n- Functional tests now use multiprocessing module instead of subprocess module,\n  speeding up test suite and making concurrent execution more reliable.\n\n- Runner now appends the current working directory to ``sys.path`` to support\n  running WSGI applications from a directory (i.e., not installed in a\n  virtualenv).\n\n- Add a ``url_prefix`` adjustment setting.  You can use it by passing\n  ``script_name='/foo'`` to ``waitress.serve`` or you can use it in a\n  ``PasteDeploy`` ini file as ``script_name = /foo``.  This will cause the WSGI\n  ``SCRIPT_NAME`` value to be the value passed minus any trailing slashes you\n  add, and it will cause the ``PATH_INFO`` of any request which is prefixed\n  with this value to be stripped of the prefix.  You can use this instead of\n  PasteDeploy's ``prefixmiddleware`` to always prefix the path.\n\n0.8.5 (2013-05-27)\n------------------\n\n- Fix runner multisegment imports in some Python 2 revisions (see\n  https://github.com/Pylons/waitress/pull/34).\n\n- For compatibility, WSGIServer is now an alias of TcpWSGIServer. The\n  signature of BaseWSGIServer is now compatible with WSGIServer pre-0.8.4.\n\n0.8.4 (2013-05-24)\n------------------\n\n- Add a command-line runner called ``waitress-serve`` to allow Waitress\n  to run WSGI applications without any addional machinery. This is\n  essentially a thin wrapper around the ``waitress.serve()`` function.\n\n- Allow parallel testing (e.g., under ``detox`` or ``nosetests --processes``)\n  using PID-dependent port / socket for functest servers.\n\n- Fix integer overflow errors on large buffers. Thanks to Marcin Kuzminski\n  for the patch.  See: https://github.com/Pylons/waitress/issues/22\n\n- Add support for listening on Unix domain sockets.\n\n0.8.3 (2013-04-28)\n------------------\n\nFeatures\n~~~~~~~~\n\n- Add an ``asyncore_loop_timeout`` adjustment value, which controls the\n  ``timeout`` value passed to ``asyncore.loop``; defaults to 1.\n\nBug Fixes\n~~~~~~~~~\n\n- The default asyncore loop timeout is now 1 second.  This prevents slow\n  shutdown on Windows.  See https://github.com/Pylons/waitress/issues/6 .  This\n  shouldn't matter to anyone in particular, but it can be changed via the\n  ``asyncore_loop_timeout`` adjustment (it used to previously default to 30\n  seconds).\n\n- Don't complain if there's a response to a HEAD request that contains a\n  Content-Length > 0.  See https://github.com/Pylons/waitress/pull/7.\n\n- Fix bug in HTTP Expect/Continue support.  See\n  https://github.com/Pylons/waitress/issues/9 .\n\n\n0.8.2 (2012-11-14)\n------------------\n\nBug Fixes\n~~~~~~~~~\n\n- https://corte.si/posts/code/pathod/pythonservers/index.html pointed out that\n  sending a bad header resulted in an exception leading to a 500 response\n  instead of the more proper 400 response without an exception.\n\n- Fix a race condition in the test suite.\n\n- Allow \"ident\" to be used as a keyword to ``serve()`` as per docs.\n\n- Add py33 to tox.ini.\n\n0.8.1 (2012-02-13)\n------------------\n\nBug Fixes\n~~~~~~~~~\n\n- A brown-bag bug prevented request concurrency.  A slow request would block\n  subsequent the responses of subsequent requests until the slow request's\n  response was fully generated.  This was due to a \"task lock\" being declared\n  as a class attribute rather than as an instance attribute on HTTPChannel.\n  Also took the opportunity to move another lock named \"outbuf lock\" to the\n  channel instance rather than the class.  See\n  https://github.com/Pylons/waitress/pull/1 .\n\n0.8 (2012-01-31)\n----------------\n\nFeatures\n~~~~~~~~\n\n- Support the WSGI ``wsgi.file_wrapper`` protocol as per\n  https://www.python.org/dev/peps/pep-0333/#optional-platform-specific-file-handling.\n  Here's a usage example::\n\n    import os\n\n    here = os.path.dirname(os.path.abspath(__file__))\n\n    def myapp(environ, start_response):\n        f = open(os.path.join(here, 'myphoto.jpg'), 'rb')\n        headers = [('Content-Type', 'image/jpeg')]\n        start_response(\n            '200 OK',\n            headers\n            )\n        return environ['wsgi.file_wrapper'](f, 32768)\n\n  The signature of the file wrapper constructor is ``(filelike_object,\n  block_size)``.  Both arguments must be passed as positional (not keyword)\n  arguments.  The result of creating a file wrapper should be **returned** as\n  the ``app_iter`` from a WSGI application.\n\n  The object passed as ``filelike_object`` to the wrapper must be a file-like\n  object which supports *at least* the ``read()`` method, and the ``read()``\n  method must support an optional size hint argument.  It *should* support\n  the ``seek()`` and ``tell()`` methods.  If it does not, normal iteration\n  over the filelike object using the provided block_size is used (and copying\n  is done, negating any benefit of the file wrapper).  It *should* support a\n  ``close()`` method.\n\n  The specified ``block_size`` argument to the file wrapper constructor will\n  be used only when the ``filelike_object`` doesn't support ``seek`` and/or\n  ``tell`` methods.  Waitress needs to use normal iteration to serve the file\n  in this degenerate case (as per the WSGI spec), and this block size will be\n  used as the iteration chunk size.  The ``block_size`` argument is optional;\n  if it is not passed, a default value``32768`` is used.\n\n  Waitress will set a ``Content-Length`` header on the behalf of an\n  application when a file wrapper with a sufficiently filelike object is used\n  if the application hasn't already set one.\n\n  The machinery which handles a file wrapper currently doesn't do anything\n  particularly special using fancy system calls (it doesn't use ``sendfile``\n  for example); using it currently just prevents the system from needing to\n  copy data to a temporary buffer in order to send it to the client.  No\n  copying of data is done when a WSGI app returns a file wrapper that wraps a\n  sufficiently filelike object.  It may do something fancier in the future.\n\n0.7 (2012-01-11)\n----------------\n\nFeatures\n~~~~~~~~\n\n- Default ``send_bytes`` value is now 18000 instead of 9000.  The larger\n  default value prevents asyncore from needing to execute select so many\n  times to serve large files, speeding up file serving by about 15%-20% or\n  so.  This is probably only an optimization for LAN communications, and\n  could slow things down across a WAN (due to higher TCP overhead), but we're\n  likely to be behind a reverse proxy on a LAN anyway if in production.\n\n- Added an (undocumented) profiling feature to the ``serve()`` command.\n\n0.6.1 (2012-01-08)\n------------------\n\nBug Fixes\n~~~~~~~~~\n\n- Remove performance-sapping call to ``pull_trigger`` in the channel's\n  ``write_soon`` method added mistakenly in 0.6.\n\n0.6 (2012-01-07)\n----------------\n\nBug Fixes\n~~~~~~~~~\n\n- A logic error prevented the internal outbuf buffer of a channel from being\n  flushed when the client could not accept the entire contents of the output\n  buffer in a single succession of socket.send calls when the channel was in\n  a \"pending close\" state.  The socket in such a case would be closed\n  prematurely, sometimes resulting in partially delivered content.  This was\n  discovered by a user using waitress behind an Nginx reverse proxy, which\n  apparently is not always ready to receive data.  The symptom was that he\n  received \"half\" of a large CSS file (110K) while serving content via\n  waitress behind the proxy.\n\n0.5 (2012-01-03)\n----------------\n\nBug Fixes\n~~~~~~~~~\n\n- Fix PATH_INFO encoding/decoding on Python 3 (as per PEP 3333, tunnel\n  bytes-in-unicode-as-latin-1-after-unquoting).\n\n0.4 (2012-01-02)\n----------------\n\nFeatures\n~~~~~~~~\n\n- Added \"design\" document to docs.\n\nBug Fixes\n~~~~~~~~~\n\n- Set default ``connection_limit`` back to 100 for benefit of maximal\n  platform compatibility.\n\n- Normalize setting of ``last_activity`` during send.\n\n- Minor resource cleanups during tests.\n\n- Channel timeout cleanup was broken.\n\n0.3 (2012-01-02)\n----------------\n\nFeatures\n~~~~~~~~\n\n- Dont hang a thread up trying to send data to slow clients.\n\n- Use self.logger to log socket errors instead of self.log_info (normalize).\n\n- Remove pointless handle_error method from channel.\n\n- Queue requests instead of tasks in a channel.\n\nBug Fixes\n~~~~~~~~~\n\n- Expect: 100-continue responses were broken.\n\n\n0.2 (2011-12-31)\n----------------\n\nBug Fixes\n~~~~~~~~~\n\n- Set up logging by calling logging.basicConfig() when ``serve`` is called\n  (show tracebacks and other warnings to console by default).\n\n- Disallow WSGI applications to set \"hop-by-hop\" headers (Connection,\n  Transfer-Encoding, etc).\n\n- Don't treat 304 status responses specially in HTTP/1.1 mode.\n\n- Remove out of date ``interfaces.py`` file.\n\n- Normalize logging (all output is now sent to the ``waitress`` logger rather\n  than in degenerate cases some output being sent directly to stderr).\n\nFeatures\n~~~~~~~~\n\n- Support HTTP/1.1 ``Transfer-Encoding: chunked`` responses.\n\n- Slightly better docs about logging.\n\n0.1 (2011-12-30)\n----------------\n\n- Initial release.\n", "##############################################################################\n#\n# Copyright (c) 2006 Zope Foundation and Contributors.\n# All Rights Reserved.\n#\n# This software is subject to the provisions of the Zope Public License,\n# Version 2.1 (ZPL).  A copy of the ZPL should accompany this distribution.\n# THIS SOFTWARE IS PROVIDED \"AS IS\" AND ANY AND ALL EXPRESS OR IMPLIED\n# WARRANTIES ARE DISCLAIMED, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\n# WARRANTIES OF TITLE, MERCHANTABILITY, AGAINST INFRINGEMENT, AND FITNESS\n# FOR A PARTICULAR PURPOSE.\n#\n##############################################################################\nimport os\nfrom setuptools import setup, find_packages\n\nhere = os.path.abspath(os.path.dirname(__file__))\ntry:\n    README = open(os.path.join(here, \"README.rst\")).read()\n    CHANGES = open(os.path.join(here, \"CHANGES.txt\")).read()\nexcept IOError:\n    README = CHANGES = \"\"\n\ndocs_extras = [\n    \"Sphinx>=1.8.1\",\n    \"docutils\",\n    \"pylons-sphinx-themes>=1.0.9\",\n]\n\ntesting_extras = [\n    \"nose\",\n    \"coverage>=5.0\",\n]\n\nsetup(\n    name=\"waitress\",\n    version=\"1.4.0\",\n    author=\"Zope Foundation and Contributors\",\n    author_email=\"zope-dev@zope.org\",\n    maintainer=\"Pylons Project\",\n    maintainer_email=\"pylons-discuss@googlegroups.com\",\n    description=\"Waitress WSGI server\",\n    long_description=README + \"\\n\\n\" + CHANGES,\n    license=\"ZPL 2.1\",\n    keywords=\"waitress wsgi server http\",\n    classifiers=[\n        \"Development Status :: 5 - Production/Stable\",\n        \"Environment :: Web Environment\",\n        \"Intended Audience :: Developers\",\n        \"License :: OSI Approved :: Zope Public License\",\n        \"Programming Language :: Python\",\n        \"Programming Language :: Python :: 2\",\n        \"Programming Language :: Python :: 2.7\",\n        \"Programming Language :: Python :: 3\",\n        \"Programming Language :: Python :: 3.4\",\n        \"Programming Language :: Python :: 3.5\",\n        \"Programming Language :: Python :: 3.6\",\n        \"Programming Language :: Python :: 3.7\",\n        \"Programming Language :: Python :: Implementation :: CPython\",\n        \"Programming Language :: Python :: Implementation :: PyPy\",\n        \"Natural Language :: English\",\n        \"Operating System :: OS Independent\",\n        \"Topic :: Internet :: WWW/HTTP\",\n        \"Topic :: Internet :: WWW/HTTP :: WSGI\",\n    ],\n    url=\"https://github.com/Pylons/waitress\",\n    packages=find_packages(),\n    extras_require={\"testing\": testing_extras, \"docs\": docs_extras,},\n    include_package_data=True,\n    test_suite=\"waitress\",\n    zip_safe=False,\n    entry_points=\"\"\"\n    [paste.server_runner]\n    main = waitress:serve_paste\n    [console_scripts]\n    waitress-serve = waitress.runner:run\n    \"\"\",\n)\n", "##############################################################################\n#\n# Copyright (c) 2001, 2002 Zope Foundation and Contributors.\n# All Rights Reserved.\n#\n# This software is subject to the provisions of the Zope Public License,\n# Version 2.1 (ZPL).  A copy of the ZPL should accompany this distribution.\n# THIS SOFTWARE IS PROVIDED \"AS IS\" AND ANY AND ALL EXPRESS OR IMPLIED\n# WARRANTIES ARE DISCLAIMED, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\n# WARRANTIES OF TITLE, MERCHANTABILITY, AGAINST INFRINGEMENT, AND FITNESS\n# FOR A PARTICULAR PURPOSE.\n#\n##############################################################################\n\"\"\"HTTP Request Parser\n\nThis server uses asyncore to accept connections and do initial\nprocessing but threads to do work.\n\"\"\"\nimport re\nfrom io import BytesIO\n\nfrom waitress.buffers import OverflowableBuffer\nfrom waitress.compat import tostr, unquote_bytes_to_wsgi, urlparse\nfrom waitress.receiver import ChunkedReceiver, FixedStreamReceiver\nfrom waitress.utilities import (\n    BadRequest,\n    RequestEntityTooLarge,\n    RequestHeaderFieldsTooLarge,\n    ServerNotImplemented,\n    find_double_newline,\n)\n\n\nclass ParsingError(Exception):\n    pass\n\n\nclass TransferEncodingNotImplemented(Exception):\n    pass\n\n\nclass HTTPRequestParser(object):\n    \"\"\"A structure that collects the HTTP request.\n\n    Once the stream is completed, the instance is passed to\n    a server task constructor.\n    \"\"\"\n\n    completed = False  # Set once request is completed.\n    empty = False  # Set if no request was made.\n    expect_continue = False  # client sent \"Expect: 100-continue\" header\n    headers_finished = False  # True when headers have been read\n    header_plus = b\"\"\n    chunked = False\n    content_length = 0\n    header_bytes_received = 0\n    body_bytes_received = 0\n    body_rcv = None\n    version = \"1.0\"\n    error = None\n    connection_close = False\n\n    # Other attributes: first_line, header, headers, command, uri, version,\n    # path, query, fragment\n\n    def __init__(self, adj):\n        \"\"\"\n        adj is an Adjustments object.\n        \"\"\"\n        # headers is a mapping containing keys translated to uppercase\n        # with dashes turned into underscores.\n        self.headers = {}\n        self.adj = adj\n\n    def received(self, data):\n        \"\"\"\n        Receives the HTTP stream for one request.  Returns the number of\n        bytes consumed.  Sets the completed flag once both the header and the\n        body have been received.\n        \"\"\"\n        if self.completed:\n            return 0  # Can't consume any more.\n\n        datalen = len(data)\n        br = self.body_rcv\n        if br is None:\n            # In header.\n            max_header = self.adj.max_request_header_size\n\n            s = self.header_plus + data\n            index = find_double_newline(s)\n            consumed = 0\n\n            if index >= 0:\n                # If the headers have ended, and we also have part of the body\n                # message in data we still want to validate we aren't going\n                # over our limit for received headers.\n                self.header_bytes_received += index\n                consumed = datalen - (len(s) - index)\n            else:\n                self.header_bytes_received += datalen\n                consumed = datalen\n\n            # If the first line + headers is over the max length, we return a\n            # RequestHeaderFieldsTooLarge error rather than continuing to\n            # attempt to parse the headers.\n            if self.header_bytes_received >= max_header:\n                self.parse_header(b\"GET / HTTP/1.0\\r\\n\")\n                self.error = RequestHeaderFieldsTooLarge(\n                    \"exceeds max_header of %s\" % max_header\n                )\n                self.completed = True\n                return consumed\n\n            if index >= 0:\n                # Header finished.\n                header_plus = s[:index]\n\n                # Remove preceeding blank lines. This is suggested by\n                # https://tools.ietf.org/html/rfc7230#section-3.5 to support\n                # clients sending an extra CR LF after another request when\n                # using HTTP pipelining\n                header_plus = header_plus.lstrip()\n\n                if not header_plus:\n                    self.empty = True\n                    self.completed = True\n                else:\n                    try:\n                        self.parse_header(header_plus)\n                    except ParsingError as e:\n                        self.error = BadRequest(e.args[0])\n                        self.completed = True\n                    except TransferEncodingNotImplemented as e:\n                        self.error = ServerNotImplemented(e.args[0])\n                        self.completed = True\n                    else:\n                        if self.body_rcv is None:\n                            # no content-length header and not a t-e: chunked\n                            # request\n                            self.completed = True\n\n                        if self.content_length > 0:\n                            max_body = self.adj.max_request_body_size\n                            # we won't accept this request if the content-length\n                            # is too large\n\n                            if self.content_length >= max_body:\n                                self.error = RequestEntityTooLarge(\n                                    \"exceeds max_body of %s\" % max_body\n                                )\n                                self.completed = True\n                self.headers_finished = True\n\n                return consumed\n\n            # Header not finished yet.\n            self.header_plus = s\n\n            return datalen\n        else:\n            # In body.\n            consumed = br.received(data)\n            self.body_bytes_received += consumed\n            max_body = self.adj.max_request_body_size\n\n            if self.body_bytes_received >= max_body:\n                # this will only be raised during t-e: chunked requests\n                self.error = RequestEntityTooLarge(\"exceeds max_body of %s\" % max_body)\n                self.completed = True\n            elif br.error:\n                # garbage in chunked encoding input probably\n                self.error = br.error\n                self.completed = True\n            elif br.completed:\n                # The request (with the body) is ready to use.\n                self.completed = True\n\n                if self.chunked:\n                    # We've converted the chunked transfer encoding request\n                    # body into a normal request body, so we know its content\n                    # length; set the header here.  We already popped the\n                    # TRANSFER_ENCODING header in parse_header, so this will\n                    # appear to the client to be an entirely non-chunked HTTP\n                    # request with a valid content-length.\n                    self.headers[\"CONTENT_LENGTH\"] = str(br.__len__())\n\n            return consumed\n\n    def parse_header(self, header_plus):\n        \"\"\"\n        Parses the header_plus block of text (the headers plus the\n        first line of the request).\n        \"\"\"\n        index = header_plus.find(b\"\\r\\n\")\n        if index >= 0:\n            first_line = header_plus[:index].rstrip()\n            header = header_plus[index + 2 :]\n        else:\n            raise ParsingError(\"HTTP message header invalid\")\n\n        if b\"\\r\" in first_line or b\"\\n\" in first_line:\n            raise ParsingError(\"Bare CR or LF found in HTTP message\")\n\n        self.first_line = first_line  # for testing\n\n        lines = get_header_lines(header)\n\n        headers = self.headers\n        for line in lines:\n            index = line.find(b\":\")\n            if index > 0:\n                key = line[:index]\n\n                if key != key.strip():\n                    raise ParsingError(\"Invalid whitespace after field-name\")\n\n                if b\"_\" in key:\n                    continue\n                value = line[index + 1 :].strip()\n                key1 = tostr(key.upper().replace(b\"-\", b\"_\"))\n                # If a header already exists, we append subsequent values\n                # seperated by a comma. Applications already need to handle\n                # the comma seperated values, as HTTP front ends might do\n                # the concatenation for you (behavior specified in RFC2616).\n                try:\n                    headers[key1] += tostr(b\", \" + value)\n                except KeyError:\n                    headers[key1] = tostr(value)\n            # else there's garbage in the headers?\n\n        # command, uri, version will be bytes\n        command, uri, version = crack_first_line(first_line)\n        version = tostr(version)\n        command = tostr(command)\n        self.command = command\n        self.version = version\n        (\n            self.proxy_scheme,\n            self.proxy_netloc,\n            self.path,\n            self.query,\n            self.fragment,\n        ) = split_uri(uri)\n        self.url_scheme = self.adj.url_scheme\n        connection = headers.get(\"CONNECTION\", \"\")\n\n        if version == \"1.0\":\n            if connection.lower() != \"keep-alive\":\n                self.connection_close = True\n\n        if version == \"1.1\":\n            # since the server buffers data from chunked transfers and clients\n            # never need to deal with chunked requests, downstream clients\n            # should not see the HTTP_TRANSFER_ENCODING header; we pop it\n            # here\n            te = headers.pop(\"TRANSFER_ENCODING\", \"\")\n\n            encodings = [encoding.strip().lower() for encoding in te.split(\",\") if encoding]\n\n            for encoding in encodings:\n                # Out of the transfer-codings listed in\n                # https://tools.ietf.org/html/rfc7230#section-4 we only support\n                # chunked at this time.\n\n                # Note: the identity transfer-coding was removed in RFC7230:\n                # https://tools.ietf.org/html/rfc7230#appendix-A.2 and is thus\n                # not supported\n                if encoding not in {\"chunked\"}:\n                    raise TransferEncodingNotImplemented(\n                        \"Transfer-Encoding requested is not supported.\"\n                    )\n\n            if encodings and encodings[-1] == \"chunked\":\n                self.chunked = True\n                buf = OverflowableBuffer(self.adj.inbuf_overflow)\n                self.body_rcv = ChunkedReceiver(buf)\n            elif encodings:  # pragma: nocover\n                raise TransferEncodingNotImplemented(\n                    \"Transfer-Encoding requested is not supported.\"\n                )\n\n            expect = headers.get(\"EXPECT\", \"\").lower()\n            self.expect_continue = expect == \"100-continue\"\n            if connection.lower() == \"close\":\n                self.connection_close = True\n\n        if not self.chunked:\n            try:\n                cl = int(headers.get(\"CONTENT_LENGTH\", 0))\n            except ValueError:\n                raise ParsingError(\"Content-Length is invalid\")\n\n            self.content_length = cl\n            if cl > 0:\n                buf = OverflowableBuffer(self.adj.inbuf_overflow)\n                self.body_rcv = FixedStreamReceiver(cl, buf)\n\n    def get_body_stream(self):\n        body_rcv = self.body_rcv\n        if body_rcv is not None:\n            return body_rcv.getfile()\n        else:\n            return BytesIO()\n\n    def close(self):\n        body_rcv = self.body_rcv\n        if body_rcv is not None:\n            body_rcv.getbuf().close()\n\n\ndef split_uri(uri):\n    # urlsplit handles byte input by returning bytes on py3, so\n    # scheme, netloc, path, query, and fragment are bytes\n\n    scheme = netloc = path = query = fragment = b\"\"\n\n    # urlsplit below will treat this as a scheme-less netloc, thereby losing\n    # the original intent of the request. Here we shamelessly stole 4 lines of\n    # code from the CPython stdlib to parse out the fragment and query but\n    # leave the path alone. See\n    # https://github.com/python/cpython/blob/8c9e9b0cd5b24dfbf1424d1f253d02de80e8f5ef/Lib/urllib/parse.py#L465-L468\n    # and https://github.com/Pylons/waitress/issues/260\n\n    if uri[:2] == b\"//\":\n        path = uri\n\n        if b\"#\" in path:\n            path, fragment = path.split(b\"#\", 1)\n\n        if b\"?\" in path:\n            path, query = path.split(b\"?\", 1)\n    else:\n        try:\n            scheme, netloc, path, query, fragment = urlparse.urlsplit(uri)\n        except UnicodeError:\n            raise ParsingError(\"Bad URI\")\n\n    return (\n        tostr(scheme),\n        tostr(netloc),\n        unquote_bytes_to_wsgi(path),\n        tostr(query),\n        tostr(fragment),\n    )\n\n\ndef get_header_lines(header):\n    \"\"\"\n    Splits the header into lines, putting multi-line headers together.\n    \"\"\"\n    r = []\n    lines = header.split(b\"\\r\\n\")\n    for line in lines:\n        if b\"\\r\" in line or b\"\\n\" in line:\n            raise ParsingError('Bare CR or LF found in header line \"%s\"' % tostr(line))\n\n        if line.startswith((b\" \", b\"\\t\")):\n            if not r:\n                # https://corte.si/posts/code/pathod/pythonservers/index.html\n                raise ParsingError('Malformed header line \"%s\"' % tostr(line))\n            r[-1] += line\n        else:\n            r.append(line)\n    return r\n\n\nfirst_line_re = re.compile(\n    b\"([^ ]+) \"\n    b\"((?:[^ :?#]+://[^ ?#/]*(?:[0-9]{1,5})?)?[^ ]+)\"\n    b\"(( HTTP/([0-9.]+))$|$)\"\n)\n\n\ndef crack_first_line(line):\n    m = first_line_re.match(line)\n    if m is not None and m.end() == len(line):\n        if m.group(3):\n            version = m.group(5)\n        else:\n            version = b\"\"\n        method = m.group(1)\n\n        # the request methods that are currently defined are all uppercase:\n        # https://www.iana.org/assignments/http-methods/http-methods.xhtml and\n        # the request method is case sensitive according to\n        # https://tools.ietf.org/html/rfc7231#section-4.1\n\n        # By disallowing anything but uppercase methods we save poor\n        # unsuspecting souls from sending lowercase HTTP methods to waitress\n        # and having the request complete, while servers like nginx drop the\n        # request onto the floor.\n        if method != method.upper():\n            raise ParsingError('Malformed HTTP method \"%s\"' % tostr(method))\n        uri = m.group(2)\n        return method, uri, version\n    else:\n        return b\"\", b\"\", b\"\"\n", "##############################################################################\n#\n# Copyright (c) 2001, 2002 Zope Foundation and Contributors.\n# All Rights Reserved.\n#\n# This software is subject to the provisions of the Zope Public License,\n# Version 2.1 (ZPL).  A copy of the ZPL should accompany this distribution.\n# THIS SOFTWARE IS PROVIDED \"AS IS\" AND ANY AND ALL EXPRESS OR IMPLIED\n# WARRANTIES ARE DISCLAIMED, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\n# WARRANTIES OF TITLE, MERCHANTABILITY, AGAINST INFRINGEMENT, AND FITNESS\n# FOR A PARTICULAR PURPOSE.\n#\n##############################################################################\n\"\"\"Data Chunk Receiver\n\"\"\"\n\nfrom waitress.utilities import BadRequest, find_double_newline\n\n\nclass FixedStreamReceiver(object):\n\n    # See IStreamConsumer\n    completed = False\n    error = None\n\n    def __init__(self, cl, buf):\n        self.remain = cl\n        self.buf = buf\n\n    def __len__(self):\n        return self.buf.__len__()\n\n    def received(self, data):\n        \"See IStreamConsumer\"\n        rm = self.remain\n\n        if rm < 1:\n            self.completed = True  # Avoid any chance of spinning\n\n            return 0\n        datalen = len(data)\n\n        if rm <= datalen:\n            self.buf.append(data[:rm])\n            self.remain = 0\n            self.completed = True\n\n            return rm\n        else:\n            self.buf.append(data)\n            self.remain -= datalen\n\n            return datalen\n\n    def getfile(self):\n        return self.buf.getfile()\n\n    def getbuf(self):\n        return self.buf\n\n\nclass ChunkedReceiver(object):\n\n    chunk_remainder = 0\n    validate_chunk_end = False\n    control_line = b\"\"\n    chunk_end = b\"\"\n    all_chunks_received = False\n    trailer = b\"\"\n    completed = False\n    error = None\n\n    # max_control_line = 1024\n    # max_trailer = 65536\n\n    def __init__(self, buf):\n        self.buf = buf\n\n    def __len__(self):\n        return self.buf.__len__()\n\n    def received(self, s):\n        # Returns the number of bytes consumed.\n\n        if self.completed:\n            return 0\n        orig_size = len(s)\n\n        while s:\n            rm = self.chunk_remainder\n\n            if rm > 0:\n                # Receive the remainder of a chunk.\n                to_write = s[:rm]\n                self.buf.append(to_write)\n                written = len(to_write)\n                s = s[written:]\n\n                self.chunk_remainder -= written\n\n                if self.chunk_remainder == 0:\n                    self.validate_chunk_end = True\n            elif self.validate_chunk_end:\n                s = self.chunk_end + s\n\n                pos = s.find(b\"\\r\\n\")\n\n                if pos < 0 and len(s) < 2:\n                    self.chunk_end = s\n                    s = b\"\"\n                else:\n                    self.chunk_end = b\"\"\n                    if pos == 0:\n                        # Chop off the terminating CR LF from the chunk\n                        s = s[2:]\n                    else:\n                        self.error = BadRequest(\"Chunk not properly terminated\")\n                        self.all_chunks_received = True\n\n                    # Always exit this loop\n                    self.validate_chunk_end = False\n            elif not self.all_chunks_received:\n                # Receive a control line.\n                s = self.control_line + s\n                pos = s.find(b\"\\r\\n\")\n\n                if pos < 0:\n                    # Control line not finished.\n                    self.control_line = s\n                    s = b\"\"\n                else:\n                    # Control line finished.\n                    line = s[:pos]\n                    s = s[pos + 2 :]\n                    self.control_line = b\"\"\n                    line = line.strip()\n\n                    if line:\n                        # Begin a new chunk.\n                        semi = line.find(b\";\")\n\n                        if semi >= 0:\n                            # discard extension info.\n                            line = line[:semi]\n                        try:\n                            sz = int(line.strip(), 16)  # hexadecimal\n                        except ValueError:  # garbage in input\n                            self.error = BadRequest(\"garbage in chunked encoding input\")\n                            sz = 0\n\n                        if sz > 0:\n                            # Start a new chunk.\n                            self.chunk_remainder = sz\n                        else:\n                            # Finished chunks.\n                            self.all_chunks_received = True\n                    # else expect a control line.\n            else:\n                # Receive the trailer.\n                trailer = self.trailer + s\n\n                if trailer.startswith(b\"\\r\\n\"):\n                    # No trailer.\n                    self.completed = True\n\n                    return orig_size - (len(trailer) - 2)\n                pos = find_double_newline(trailer)\n\n                if pos < 0:\n                    # Trailer not finished.\n                    self.trailer = trailer\n                    s = b\"\"\n                else:\n                    # Finished the trailer.\n                    self.completed = True\n                    self.trailer = trailer[:pos]\n\n                    return orig_size - (len(trailer) - pos)\n\n        return orig_size\n\n    def getfile(self):\n        return self.buf.getfile()\n\n    def getbuf(self):\n        return self.buf\n", "##############################################################################\n#\n# Copyright (c) 2001, 2002 Zope Foundation and Contributors.\n# All Rights Reserved.\n#\n# This software is subject to the provisions of the Zope Public License,\n# Version 2.1 (ZPL).  A copy of the ZPL should accompany this distribution.\n# THIS SOFTWARE IS PROVIDED \"AS IS\" AND ANY AND ALL EXPRESS OR IMPLIED\n# WARRANTIES ARE DISCLAIMED, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\n# WARRANTIES OF TITLE, MERCHANTABILITY, AGAINST INFRINGEMENT, AND FITNESS\n# FOR A PARTICULAR PURPOSE.\n#\n##############################################################################\n\nimport socket\nimport sys\nimport threading\nimport time\nfrom collections import deque\n\nfrom .buffers import ReadOnlyFileBasedBuffer\nfrom .compat import reraise, tobytes\nfrom .utilities import build_http_date, logger, queue_logger\n\nrename_headers = {  # or keep them without the HTTP_ prefix added\n    \"CONTENT_LENGTH\": \"CONTENT_LENGTH\",\n    \"CONTENT_TYPE\": \"CONTENT_TYPE\",\n}\n\nhop_by_hop = frozenset(\n    (\n        \"connection\",\n        \"keep-alive\",\n        \"proxy-authenticate\",\n        \"proxy-authorization\",\n        \"te\",\n        \"trailers\",\n        \"transfer-encoding\",\n        \"upgrade\",\n    )\n)\n\n\nclass ThreadedTaskDispatcher(object):\n    \"\"\"A Task Dispatcher that creates a thread for each task.\n    \"\"\"\n\n    stop_count = 0  # Number of threads that will stop soon.\n    active_count = 0  # Number of currently active threads\n    logger = logger\n    queue_logger = queue_logger\n\n    def __init__(self):\n        self.threads = set()\n        self.queue = deque()\n        self.lock = threading.Lock()\n        self.queue_cv = threading.Condition(self.lock)\n        self.thread_exit_cv = threading.Condition(self.lock)\n\n    def start_new_thread(self, target, args):\n        t = threading.Thread(target=target, name=\"waitress\", args=args)\n        t.daemon = True\n        t.start()\n\n    def handler_thread(self, thread_no):\n        while True:\n            with self.lock:\n                while not self.queue and self.stop_count == 0:\n                    # Mark ourselves as idle before waiting to be\n                    # woken up, then we will once again be active\n                    self.active_count -= 1\n                    self.queue_cv.wait()\n                    self.active_count += 1\n\n                if self.stop_count > 0:\n                    self.active_count -= 1\n                    self.stop_count -= 1\n                    self.threads.discard(thread_no)\n                    self.thread_exit_cv.notify()\n                    break\n\n                task = self.queue.popleft()\n            try:\n                task.service()\n            except BaseException:\n                self.logger.exception(\"Exception when servicing %r\", task)\n\n    def set_thread_count(self, count):\n        with self.lock:\n            threads = self.threads\n            thread_no = 0\n            running = len(threads) - self.stop_count\n            while running < count:\n                # Start threads.\n                while thread_no in threads:\n                    thread_no = thread_no + 1\n                threads.add(thread_no)\n                running += 1\n                self.start_new_thread(self.handler_thread, (thread_no,))\n                self.active_count += 1\n                thread_no = thread_no + 1\n            if running > count:\n                # Stop threads.\n                self.stop_count += running - count\n                self.queue_cv.notify_all()\n\n    def add_task(self, task):\n        with self.lock:\n            self.queue.append(task)\n            self.queue_cv.notify()\n            queue_size = len(self.queue)\n            idle_threads = len(self.threads) - self.stop_count - self.active_count\n            if queue_size > idle_threads:\n                self.queue_logger.warning(\n                    \"Task queue depth is %d\", queue_size - idle_threads\n                )\n\n    def shutdown(self, cancel_pending=True, timeout=5):\n        self.set_thread_count(0)\n        # Ensure the threads shut down.\n        threads = self.threads\n        expiration = time.time() + timeout\n        with self.lock:\n            while threads:\n                if time.time() >= expiration:\n                    self.logger.warning(\"%d thread(s) still running\", len(threads))\n                    break\n                self.thread_exit_cv.wait(0.1)\n            if cancel_pending:\n                # Cancel remaining tasks.\n                queue = self.queue\n                if len(queue) > 0:\n                    self.logger.warning(\"Canceling %d pending task(s)\", len(queue))\n                while queue:\n                    task = queue.popleft()\n                    task.cancel()\n                self.queue_cv.notify_all()\n                return True\n        return False\n\n\nclass Task(object):\n    close_on_finish = False\n    status = \"200 OK\"\n    wrote_header = False\n    start_time = 0\n    content_length = None\n    content_bytes_written = 0\n    logged_write_excess = False\n    logged_write_no_body = False\n    complete = False\n    chunked_response = False\n    logger = logger\n\n    def __init__(self, channel, request):\n        self.channel = channel\n        self.request = request\n        self.response_headers = []\n        version = request.version\n        if version not in (\"1.0\", \"1.1\"):\n            # fall back to a version we support.\n            version = \"1.0\"\n        self.version = version\n\n    def service(self):\n        try:\n            try:\n                self.start()\n                self.execute()\n                self.finish()\n            except socket.error:\n                self.close_on_finish = True\n                if self.channel.adj.log_socket_errors:\n                    raise\n        finally:\n            pass\n\n    @property\n    def has_body(self):\n        return not (\n            self.status.startswith(\"1\")\n            or self.status.startswith(\"204\")\n            or self.status.startswith(\"304\")\n        )\n\n    def build_response_header(self):\n        version = self.version\n        # Figure out whether the connection should be closed.\n        connection = self.request.headers.get(\"CONNECTION\", \"\").lower()\n        response_headers = []\n        content_length_header = None\n        date_header = None\n        server_header = None\n        connection_close_header = None\n\n        for (headername, headerval) in self.response_headers:\n            headername = \"-\".join([x.capitalize() for x in headername.split(\"-\")])\n\n            if headername == \"Content-Length\":\n                if self.has_body:\n                    content_length_header = headerval\n                else:\n                    continue  # pragma: no cover\n\n            if headername == \"Date\":\n                date_header = headerval\n\n            if headername == \"Server\":\n                server_header = headerval\n\n            if headername == \"Connection\":\n                connection_close_header = headerval.lower()\n            # replace with properly capitalized version\n            response_headers.append((headername, headerval))\n\n        if (\n            content_length_header is None\n            and self.content_length is not None\n            and self.has_body\n        ):\n            content_length_header = str(self.content_length)\n            response_headers.append((\"Content-Length\", content_length_header))\n\n        def close_on_finish():\n            if connection_close_header is None:\n                response_headers.append((\"Connection\", \"close\"))\n            self.close_on_finish = True\n\n        if version == \"1.0\":\n            if connection == \"keep-alive\":\n                if not content_length_header:\n                    close_on_finish()\n                else:\n                    response_headers.append((\"Connection\", \"Keep-Alive\"))\n            else:\n                close_on_finish()\n\n        elif version == \"1.1\":\n            if connection == \"close\":\n                close_on_finish()\n\n            if not content_length_header:\n                # RFC 7230: MUST NOT send Transfer-Encoding or Content-Length\n                # for any response with a status code of 1xx, 204 or 304.\n\n                if self.has_body:\n                    response_headers.append((\"Transfer-Encoding\", \"chunked\"))\n                    self.chunked_response = True\n\n                if not self.close_on_finish:\n                    close_on_finish()\n\n            # under HTTP 1.1 keep-alive is default, no need to set the header\n        else:\n            raise AssertionError(\"neither HTTP/1.0 or HTTP/1.1\")\n\n        # Set the Server and Date field, if not yet specified. This is needed\n        # if the server is used as a proxy.\n        ident = self.channel.server.adj.ident\n\n        if not server_header:\n            if ident:\n                response_headers.append((\"Server\", ident))\n        else:\n            response_headers.append((\"Via\", ident or \"waitress\"))\n\n        if not date_header:\n            response_headers.append((\"Date\", build_http_date(self.start_time)))\n\n        self.response_headers = response_headers\n\n        first_line = \"HTTP/%s %s\" % (self.version, self.status)\n        # NB: sorting headers needs to preserve same-named-header order\n        # as per RFC 2616 section 4.2; thus the key=lambda x: x[0] here;\n        # rely on stable sort to keep relative position of same-named headers\n        next_lines = [\n            \"%s: %s\" % hv for hv in sorted(self.response_headers, key=lambda x: x[0])\n        ]\n        lines = [first_line] + next_lines\n        res = \"%s\\r\\n\\r\\n\" % \"\\r\\n\".join(lines)\n\n        return tobytes(res)\n\n    def remove_content_length_header(self):\n        response_headers = []\n\n        for header_name, header_value in self.response_headers:\n            if header_name.lower() == \"content-length\":\n                continue  # pragma: nocover\n            response_headers.append((header_name, header_value))\n\n        self.response_headers = response_headers\n\n    def start(self):\n        self.start_time = time.time()\n\n    def finish(self):\n        if not self.wrote_header:\n            self.write(b\"\")\n        if self.chunked_response:\n            # not self.write, it will chunk it!\n            self.channel.write_soon(b\"0\\r\\n\\r\\n\")\n\n    def write(self, data):\n        if not self.complete:\n            raise RuntimeError(\"start_response was not called before body written\")\n        channel = self.channel\n        if not self.wrote_header:\n            rh = self.build_response_header()\n            channel.write_soon(rh)\n            self.wrote_header = True\n\n        if data and self.has_body:\n            towrite = data\n            cl = self.content_length\n            if self.chunked_response:\n                # use chunked encoding response\n                towrite = tobytes(hex(len(data))[2:].upper()) + b\"\\r\\n\"\n                towrite += data + b\"\\r\\n\"\n            elif cl is not None:\n                towrite = data[: cl - self.content_bytes_written]\n                self.content_bytes_written += len(towrite)\n                if towrite != data and not self.logged_write_excess:\n                    self.logger.warning(\n                        \"application-written content exceeded the number of \"\n                        \"bytes specified by Content-Length header (%s)\" % cl\n                    )\n                    self.logged_write_excess = True\n            if towrite:\n                channel.write_soon(towrite)\n        elif data:\n            # Cheat, and tell the application we have written all of the bytes,\n            # even though the response shouldn't have a body and we are\n            # ignoring it entirely.\n            self.content_bytes_written += len(data)\n\n            if not self.logged_write_no_body:\n                self.logger.warning(\n                    \"application-written content was ignored due to HTTP \"\n                    \"response that may not contain a message-body: (%s)\" % self.status\n                )\n                self.logged_write_no_body = True\n\n\nclass ErrorTask(Task):\n    \"\"\" An error task produces an error response\n    \"\"\"\n\n    complete = True\n\n    def execute(self):\n        e = self.request.error\n        status, headers, body = e.to_response()\n        self.status = status\n        self.response_headers.extend(headers)\n        # We need to explicitly tell the remote client we are closing the\n        # connection, because self.close_on_finish is set, and we are going to\n        # slam the door in the clients face.\n        self.response_headers.append((\"Connection\", \"close\"))\n        self.close_on_finish = True\n        self.content_length = len(body)\n        self.write(tobytes(body))\n\n\nclass WSGITask(Task):\n    \"\"\"A WSGI task produces a response from a WSGI application.\n    \"\"\"\n\n    environ = None\n\n    def execute(self):\n        environ = self.get_environment()\n\n        def start_response(status, headers, exc_info=None):\n            if self.complete and not exc_info:\n                raise AssertionError(\n                    \"start_response called a second time without providing exc_info.\"\n                )\n            if exc_info:\n                try:\n                    if self.wrote_header:\n                        # higher levels will catch and handle raised exception:\n                        # 1. \"service\" method in task.py\n                        # 2. \"service\" method in channel.py\n                        # 3. \"handler_thread\" method in task.py\n                        reraise(exc_info[0], exc_info[1], exc_info[2])\n                    else:\n                        # As per WSGI spec existing headers must be cleared\n                        self.response_headers = []\n                finally:\n                    exc_info = None\n\n            self.complete = True\n\n            if not status.__class__ is str:\n                raise AssertionError(\"status %s is not a string\" % status)\n            if \"\\n\" in status or \"\\r\" in status:\n                raise ValueError(\n                    \"carriage return/line feed character present in status\"\n                )\n\n            self.status = status\n\n            # Prepare the headers for output\n            for k, v in headers:\n                if not k.__class__ is str:\n                    raise AssertionError(\n                        \"Header name %r is not a string in %r\" % (k, (k, v))\n                    )\n                if not v.__class__ is str:\n                    raise AssertionError(\n                        \"Header value %r is not a string in %r\" % (v, (k, v))\n                    )\n\n                if \"\\n\" in v or \"\\r\" in v:\n                    raise ValueError(\n                        \"carriage return/line feed character present in header value\"\n                    )\n                if \"\\n\" in k or \"\\r\" in k:\n                    raise ValueError(\n                        \"carriage return/line feed character present in header name\"\n                    )\n\n                kl = k.lower()\n                if kl == \"content-length\":\n                    self.content_length = int(v)\n                elif kl in hop_by_hop:\n                    raise AssertionError(\n                        '%s is a \"hop-by-hop\" header; it cannot be used by '\n                        \"a WSGI application (see PEP 3333)\" % k\n                    )\n\n            self.response_headers.extend(headers)\n\n            # Return a method used to write the response data.\n            return self.write\n\n        # Call the application to handle the request and write a response\n        app_iter = self.channel.server.application(environ, start_response)\n\n        can_close_app_iter = True\n        try:\n            if app_iter.__class__ is ReadOnlyFileBasedBuffer:\n                cl = self.content_length\n                size = app_iter.prepare(cl)\n                if size:\n                    if cl != size:\n                        if cl is not None:\n                            self.remove_content_length_header()\n                        self.content_length = size\n                    self.write(b\"\")  # generate headers\n                    # if the write_soon below succeeds then the channel will\n                    # take over closing the underlying file via the channel's\n                    # _flush_some or handle_close so we intentionally avoid\n                    # calling close in the finally block\n                    self.channel.write_soon(app_iter)\n                    can_close_app_iter = False\n                    return\n\n            first_chunk_len = None\n            for chunk in app_iter:\n                if first_chunk_len is None:\n                    first_chunk_len = len(chunk)\n                    # Set a Content-Length header if one is not supplied.\n                    # start_response may not have been called until first\n                    # iteration as per PEP, so we must reinterrogate\n                    # self.content_length here\n                    if self.content_length is None:\n                        app_iter_len = None\n                        if hasattr(app_iter, \"__len__\"):\n                            app_iter_len = len(app_iter)\n                        if app_iter_len == 1:\n                            self.content_length = first_chunk_len\n                # transmit headers only after first iteration of the iterable\n                # that returns a non-empty bytestring (PEP 3333)\n                if chunk:\n                    self.write(chunk)\n\n            cl = self.content_length\n            if cl is not None:\n                if self.content_bytes_written != cl:\n                    # close the connection so the client isn't sitting around\n                    # waiting for more data when there are too few bytes\n                    # to service content-length\n                    self.close_on_finish = True\n                    if self.request.command != \"HEAD\":\n                        self.logger.warning(\n                            \"application returned too few bytes (%s) \"\n                            \"for specified Content-Length (%s) via app_iter\"\n                            % (self.content_bytes_written, cl),\n                        )\n        finally:\n            if can_close_app_iter and hasattr(app_iter, \"close\"):\n                app_iter.close()\n\n    def get_environment(self):\n        \"\"\"Returns a WSGI environment.\"\"\"\n        environ = self.environ\n        if environ is not None:\n            # Return the cached copy.\n            return environ\n\n        request = self.request\n        path = request.path\n        channel = self.channel\n        server = channel.server\n        url_prefix = server.adj.url_prefix\n\n        if path.startswith(\"/\"):\n            # strip extra slashes at the beginning of a path that starts\n            # with any number of slashes\n            path = \"/\" + path.lstrip(\"/\")\n\n        if url_prefix:\n            # NB: url_prefix is guaranteed by the configuration machinery to\n            # be either the empty string or a string that starts with a single\n            # slash and ends without any slashes\n            if path == url_prefix:\n                # if the path is the same as the url prefix, the SCRIPT_NAME\n                # should be the url_prefix and PATH_INFO should be empty\n                path = \"\"\n            else:\n                # if the path starts with the url prefix plus a slash,\n                # the SCRIPT_NAME should be the url_prefix and PATH_INFO should\n                # the value of path from the slash until its end\n                url_prefix_with_trailing_slash = url_prefix + \"/\"\n                if path.startswith(url_prefix_with_trailing_slash):\n                    path = path[len(url_prefix) :]\n\n        environ = {\n            \"REMOTE_ADDR\": channel.addr[0],\n            # Nah, we aren't actually going to look up the reverse DNS for\n            # REMOTE_ADDR, but we will happily set this environment variable\n            # for the WSGI application. Spec says we can just set this to\n            # REMOTE_ADDR, so we do.\n            \"REMOTE_HOST\": channel.addr[0],\n            # try and set the REMOTE_PORT to something useful, but maybe None\n            \"REMOTE_PORT\": str(channel.addr[1]),\n            \"REQUEST_METHOD\": request.command.upper(),\n            \"SERVER_PORT\": str(server.effective_port),\n            \"SERVER_NAME\": server.server_name,\n            \"SERVER_SOFTWARE\": server.adj.ident,\n            \"SERVER_PROTOCOL\": \"HTTP/%s\" % self.version,\n            \"SCRIPT_NAME\": url_prefix,\n            \"PATH_INFO\": path,\n            \"QUERY_STRING\": request.query,\n            \"wsgi.url_scheme\": request.url_scheme,\n            # the following environment variables are required by the WSGI spec\n            \"wsgi.version\": (1, 0),\n            # apps should use the logging module\n            \"wsgi.errors\": sys.stderr,\n            \"wsgi.multithread\": True,\n            \"wsgi.multiprocess\": False,\n            \"wsgi.run_once\": False,\n            \"wsgi.input\": request.get_body_stream(),\n            \"wsgi.file_wrapper\": ReadOnlyFileBasedBuffer,\n            \"wsgi.input_terminated\": True,  # wsgi.input is EOF terminated\n        }\n\n        for key, value in dict(request.headers).items():\n            value = value.strip()\n            mykey = rename_headers.get(key, None)\n            if mykey is None:\n                mykey = \"HTTP_\" + key\n            if mykey not in environ:\n                environ[mykey] = value\n\n        # cache the environ for this request\n        self.environ = environ\n        return environ\n", "import unittest\nimport io\n\n\nclass TestHTTPChannel(unittest.TestCase):\n    def _makeOne(self, sock, addr, adj, map=None):\n        from waitress.channel import HTTPChannel\n\n        server = DummyServer()\n        return HTTPChannel(server, sock, addr, adj=adj, map=map)\n\n    def _makeOneWithMap(self, adj=None):\n        if adj is None:\n            adj = DummyAdjustments()\n        sock = DummySock()\n        map = {}\n        inst = self._makeOne(sock, \"127.0.0.1\", adj, map=map)\n        inst.outbuf_lock = DummyLock()\n        return inst, sock, map\n\n    def test_ctor(self):\n        inst, _, map = self._makeOneWithMap()\n        self.assertEqual(inst.addr, \"127.0.0.1\")\n        self.assertEqual(inst.sendbuf_len, 2048)\n        self.assertEqual(map[100], inst)\n\n    def test_total_outbufs_len_an_outbuf_size_gt_sys_maxint(self):\n        from waitress.compat import MAXINT\n\n        inst, _, map = self._makeOneWithMap()\n\n        class DummyBuffer(object):\n            chunks = []\n\n            def append(self, data):\n                self.chunks.append(data)\n\n        class DummyData(object):\n            def __len__(self):\n                return MAXINT\n\n        inst.total_outbufs_len = 1\n        inst.outbufs = [DummyBuffer()]\n        inst.write_soon(DummyData())\n        # we are testing that this method does not raise an OverflowError\n        # (see https://github.com/Pylons/waitress/issues/47)\n        self.assertEqual(inst.total_outbufs_len, MAXINT + 1)\n\n    def test_writable_something_in_outbuf(self):\n        inst, sock, map = self._makeOneWithMap()\n        inst.total_outbufs_len = 3\n        self.assertTrue(inst.writable())\n\n    def test_writable_nothing_in_outbuf(self):\n        inst, sock, map = self._makeOneWithMap()\n        self.assertFalse(inst.writable())\n\n    def test_writable_nothing_in_outbuf_will_close(self):\n        inst, sock, map = self._makeOneWithMap()\n        inst.will_close = True\n        self.assertTrue(inst.writable())\n\n    def test_handle_write_not_connected(self):\n        inst, sock, map = self._makeOneWithMap()\n        inst.connected = False\n        self.assertFalse(inst.handle_write())\n\n    def test_handle_write_with_requests(self):\n        inst, sock, map = self._makeOneWithMap()\n        inst.requests = True\n        inst.last_activity = 0\n        result = inst.handle_write()\n        self.assertEqual(result, None)\n        self.assertEqual(inst.last_activity, 0)\n\n    def test_handle_write_no_request_with_outbuf(self):\n        inst, sock, map = self._makeOneWithMap()\n        inst.requests = []\n        inst.outbufs = [DummyBuffer(b\"abc\")]\n        inst.total_outbufs_len = len(inst.outbufs[0])\n        inst.last_activity = 0\n        result = inst.handle_write()\n        self.assertEqual(result, None)\n        self.assertNotEqual(inst.last_activity, 0)\n        self.assertEqual(sock.sent, b\"abc\")\n\n    def test_handle_write_outbuf_raises_socketerror(self):\n        import socket\n\n        inst, sock, map = self._makeOneWithMap()\n        inst.requests = []\n        outbuf = DummyBuffer(b\"abc\", socket.error)\n        inst.outbufs = [outbuf]\n        inst.total_outbufs_len = len(outbuf)\n        inst.last_activity = 0\n        inst.logger = DummyLogger()\n        result = inst.handle_write()\n        self.assertEqual(result, None)\n        self.assertEqual(inst.last_activity, 0)\n        self.assertEqual(sock.sent, b\"\")\n        self.assertEqual(len(inst.logger.exceptions), 1)\n        self.assertTrue(outbuf.closed)\n\n    def test_handle_write_outbuf_raises_othererror(self):\n        inst, sock, map = self._makeOneWithMap()\n        inst.requests = []\n        outbuf = DummyBuffer(b\"abc\", IOError)\n        inst.outbufs = [outbuf]\n        inst.total_outbufs_len = len(outbuf)\n        inst.last_activity = 0\n        inst.logger = DummyLogger()\n        result = inst.handle_write()\n        self.assertEqual(result, None)\n        self.assertEqual(inst.last_activity, 0)\n        self.assertEqual(sock.sent, b\"\")\n        self.assertEqual(len(inst.logger.exceptions), 1)\n        self.assertTrue(outbuf.closed)\n\n    def test_handle_write_no_requests_no_outbuf_will_close(self):\n        inst, sock, map = self._makeOneWithMap()\n        inst.requests = []\n        outbuf = DummyBuffer(b\"\")\n        inst.outbufs = [outbuf]\n        inst.will_close = True\n        inst.last_activity = 0\n        result = inst.handle_write()\n        self.assertEqual(result, None)\n        self.assertEqual(inst.connected, False)\n        self.assertEqual(sock.closed, True)\n        self.assertEqual(inst.last_activity, 0)\n        self.assertTrue(outbuf.closed)\n\n    def test_handle_write_no_requests_outbuf_gt_send_bytes(self):\n        inst, sock, map = self._makeOneWithMap()\n        inst.requests = [True]\n        inst.outbufs = [DummyBuffer(b\"abc\")]\n        inst.total_outbufs_len = len(inst.outbufs[0])\n        inst.adj.send_bytes = 2\n        inst.will_close = False\n        inst.last_activity = 0\n        result = inst.handle_write()\n        self.assertEqual(result, None)\n        self.assertEqual(inst.will_close, False)\n        self.assertTrue(inst.outbuf_lock.acquired)\n        self.assertEqual(sock.sent, b\"abc\")\n\n    def test_handle_write_close_when_flushed(self):\n        inst, sock, map = self._makeOneWithMap()\n        outbuf = DummyBuffer(b\"abc\")\n        inst.outbufs = [outbuf]\n        inst.total_outbufs_len = len(outbuf)\n        inst.will_close = False\n        inst.close_when_flushed = True\n        inst.last_activity = 0\n        result = inst.handle_write()\n        self.assertEqual(result, None)\n        self.assertEqual(inst.will_close, True)\n        self.assertEqual(inst.close_when_flushed, False)\n        self.assertEqual(sock.sent, b\"abc\")\n        self.assertTrue(outbuf.closed)\n\n    def test_readable_no_requests_not_will_close(self):\n        inst, sock, map = self._makeOneWithMap()\n        inst.requests = []\n        inst.will_close = False\n        self.assertEqual(inst.readable(), True)\n\n    def test_readable_no_requests_will_close(self):\n        inst, sock, map = self._makeOneWithMap()\n        inst.requests = []\n        inst.will_close = True\n        self.assertEqual(inst.readable(), False)\n\n    def test_readable_with_requests(self):\n        inst, sock, map = self._makeOneWithMap()\n        inst.requests = True\n        self.assertEqual(inst.readable(), False)\n\n    def test_handle_read_no_error(self):\n        inst, sock, map = self._makeOneWithMap()\n        inst.will_close = False\n        inst.recv = lambda *arg: b\"abc\"\n        inst.last_activity = 0\n        L = []\n        inst.received = lambda x: L.append(x)\n        result = inst.handle_read()\n        self.assertEqual(result, None)\n        self.assertNotEqual(inst.last_activity, 0)\n        self.assertEqual(L, [b\"abc\"])\n\n    def test_handle_read_error(self):\n        import socket\n\n        inst, sock, map = self._makeOneWithMap()\n        inst.will_close = False\n\n        def recv(b):\n            raise socket.error\n\n        inst.recv = recv\n        inst.last_activity = 0\n        inst.logger = DummyLogger()\n        result = inst.handle_read()\n        self.assertEqual(result, None)\n        self.assertEqual(inst.last_activity, 0)\n        self.assertEqual(len(inst.logger.exceptions), 1)\n\n    def test_write_soon_empty_byte(self):\n        inst, sock, map = self._makeOneWithMap()\n        wrote = inst.write_soon(b\"\")\n        self.assertEqual(wrote, 0)\n        self.assertEqual(len(inst.outbufs[0]), 0)\n\n    def test_write_soon_nonempty_byte(self):\n        inst, sock, map = self._makeOneWithMap()\n        wrote = inst.write_soon(b\"a\")\n        self.assertEqual(wrote, 1)\n        self.assertEqual(len(inst.outbufs[0]), 1)\n\n    def test_write_soon_filewrapper(self):\n        from waitress.buffers import ReadOnlyFileBasedBuffer\n\n        f = io.BytesIO(b\"abc\")\n        wrapper = ReadOnlyFileBasedBuffer(f, 8192)\n        wrapper.prepare()\n        inst, sock, map = self._makeOneWithMap()\n        outbufs = inst.outbufs\n        orig_outbuf = outbufs[0]\n        wrote = inst.write_soon(wrapper)\n        self.assertEqual(wrote, 3)\n        self.assertEqual(len(outbufs), 3)\n        self.assertEqual(outbufs[0], orig_outbuf)\n        self.assertEqual(outbufs[1], wrapper)\n        self.assertEqual(outbufs[2].__class__.__name__, \"OverflowableBuffer\")\n\n    def test_write_soon_disconnected(self):\n        from waitress.channel import ClientDisconnected\n\n        inst, sock, map = self._makeOneWithMap()\n        inst.connected = False\n        self.assertRaises(ClientDisconnected, lambda: inst.write_soon(b\"stuff\"))\n\n    def test_write_soon_disconnected_while_over_watermark(self):\n        from waitress.channel import ClientDisconnected\n\n        inst, sock, map = self._makeOneWithMap()\n\n        def dummy_flush():\n            inst.connected = False\n\n        inst._flush_outbufs_below_high_watermark = dummy_flush\n        self.assertRaises(ClientDisconnected, lambda: inst.write_soon(b\"stuff\"))\n\n    def test_write_soon_rotates_outbuf_on_overflow(self):\n        inst, sock, map = self._makeOneWithMap()\n        inst.adj.outbuf_high_watermark = 3\n        inst.current_outbuf_count = 4\n        wrote = inst.write_soon(b\"xyz\")\n        self.assertEqual(wrote, 3)\n        self.assertEqual(len(inst.outbufs), 2)\n        self.assertEqual(inst.outbufs[0].get(), b\"\")\n        self.assertEqual(inst.outbufs[1].get(), b\"xyz\")\n\n    def test_write_soon_waits_on_backpressure(self):\n        inst, sock, map = self._makeOneWithMap()\n        inst.adj.outbuf_high_watermark = 3\n        inst.total_outbufs_len = 4\n        inst.current_outbuf_count = 4\n\n        class Lock(DummyLock):\n            def wait(self):\n                inst.total_outbufs_len = 0\n                super(Lock, self).wait()\n\n        inst.outbuf_lock = Lock()\n        wrote = inst.write_soon(b\"xyz\")\n        self.assertEqual(wrote, 3)\n        self.assertEqual(len(inst.outbufs), 2)\n        self.assertEqual(inst.outbufs[0].get(), b\"\")\n        self.assertEqual(inst.outbufs[1].get(), b\"xyz\")\n        self.assertTrue(inst.outbuf_lock.waited)\n\n    def test_handle_write_notify_after_flush(self):\n        inst, sock, map = self._makeOneWithMap()\n        inst.requests = [True]\n        inst.outbufs = [DummyBuffer(b\"abc\")]\n        inst.total_outbufs_len = len(inst.outbufs[0])\n        inst.adj.send_bytes = 1\n        inst.adj.outbuf_high_watermark = 5\n        inst.will_close = False\n        inst.last_activity = 0\n        result = inst.handle_write()\n        self.assertEqual(result, None)\n        self.assertEqual(inst.will_close, False)\n        self.assertTrue(inst.outbuf_lock.acquired)\n        self.assertTrue(inst.outbuf_lock.notified)\n        self.assertEqual(sock.sent, b\"abc\")\n\n    def test_handle_write_no_notify_after_flush(self):\n        inst, sock, map = self._makeOneWithMap()\n        inst.requests = [True]\n        inst.outbufs = [DummyBuffer(b\"abc\")]\n        inst.total_outbufs_len = len(inst.outbufs[0])\n        inst.adj.send_bytes = 1\n        inst.adj.outbuf_high_watermark = 2\n        sock.send = lambda x: False\n        inst.will_close = False\n        inst.last_activity = 0\n        result = inst.handle_write()\n        self.assertEqual(result, None)\n        self.assertEqual(inst.will_close, False)\n        self.assertTrue(inst.outbuf_lock.acquired)\n        self.assertFalse(inst.outbuf_lock.notified)\n        self.assertEqual(sock.sent, b\"\")\n\n    def test__flush_some_empty_outbuf(self):\n        inst, sock, map = self._makeOneWithMap()\n        result = inst._flush_some()\n        self.assertEqual(result, False)\n\n    def test__flush_some_full_outbuf_socket_returns_nonzero(self):\n        inst, sock, map = self._makeOneWithMap()\n        inst.outbufs[0].append(b\"abc\")\n        inst.total_outbufs_len = sum(len(x) for x in inst.outbufs)\n        result = inst._flush_some()\n        self.assertEqual(result, True)\n\n    def test__flush_some_full_outbuf_socket_returns_zero(self):\n        inst, sock, map = self._makeOneWithMap()\n        sock.send = lambda x: False\n        inst.outbufs[0].append(b\"abc\")\n        inst.total_outbufs_len = sum(len(x) for x in inst.outbufs)\n        result = inst._flush_some()\n        self.assertEqual(result, False)\n\n    def test_flush_some_multiple_buffers_first_empty(self):\n        inst, sock, map = self._makeOneWithMap()\n        sock.send = lambda x: len(x)\n        buffer = DummyBuffer(b\"abc\")\n        inst.outbufs.append(buffer)\n        inst.total_outbufs_len = sum(len(x) for x in inst.outbufs)\n        result = inst._flush_some()\n        self.assertEqual(result, True)\n        self.assertEqual(buffer.skipped, 3)\n        self.assertEqual(inst.outbufs, [buffer])\n\n    def test_flush_some_multiple_buffers_close_raises(self):\n        inst, sock, map = self._makeOneWithMap()\n        sock.send = lambda x: len(x)\n        buffer = DummyBuffer(b\"abc\")\n        inst.outbufs.append(buffer)\n        inst.total_outbufs_len = sum(len(x) for x in inst.outbufs)\n        inst.logger = DummyLogger()\n\n        def doraise():\n            raise NotImplementedError\n\n        inst.outbufs[0].close = doraise\n        result = inst._flush_some()\n        self.assertEqual(result, True)\n        self.assertEqual(buffer.skipped, 3)\n        self.assertEqual(inst.outbufs, [buffer])\n        self.assertEqual(len(inst.logger.exceptions), 1)\n\n    def test__flush_some_outbuf_len_gt_sys_maxint(self):\n        from waitress.compat import MAXINT\n\n        inst, sock, map = self._makeOneWithMap()\n\n        class DummyHugeOutbuffer(object):\n            def __init__(self):\n                self.length = MAXINT + 1\n\n            def __len__(self):\n                return self.length\n\n            def get(self, numbytes):\n                self.length = 0\n                return b\"123\"\n\n        buf = DummyHugeOutbuffer()\n        inst.outbufs = [buf]\n        inst.send = lambda *arg: 0\n        result = inst._flush_some()\n        # we are testing that _flush_some doesn't raise an OverflowError\n        # when one of its outbufs has a __len__ that returns gt sys.maxint\n        self.assertEqual(result, False)\n\n    def test_handle_close(self):\n        inst, sock, map = self._makeOneWithMap()\n        inst.handle_close()\n        self.assertEqual(inst.connected, False)\n        self.assertEqual(sock.closed, True)\n\n    def test_handle_close_outbuf_raises_on_close(self):\n        inst, sock, map = self._makeOneWithMap()\n\n        def doraise():\n            raise NotImplementedError\n\n        inst.outbufs[0].close = doraise\n        inst.logger = DummyLogger()\n        inst.handle_close()\n        self.assertEqual(inst.connected, False)\n        self.assertEqual(sock.closed, True)\n        self.assertEqual(len(inst.logger.exceptions), 1)\n\n    def test_add_channel(self):\n        inst, sock, map = self._makeOneWithMap()\n        fileno = inst._fileno\n        inst.add_channel(map)\n        self.assertEqual(map[fileno], inst)\n        self.assertEqual(inst.server.active_channels[fileno], inst)\n\n    def test_del_channel(self):\n        inst, sock, map = self._makeOneWithMap()\n        fileno = inst._fileno\n        inst.server.active_channels[fileno] = True\n        inst.del_channel(map)\n        self.assertEqual(map.get(fileno), None)\n        self.assertEqual(inst.server.active_channels.get(fileno), None)\n\n    def test_received(self):\n        inst, sock, map = self._makeOneWithMap()\n        inst.server = DummyServer()\n        inst.received(b\"GET / HTTP/1.1\\r\\n\\r\\n\")\n        self.assertEqual(inst.server.tasks, [inst])\n        self.assertTrue(inst.requests)\n\n    def test_received_no_chunk(self):\n        inst, sock, map = self._makeOneWithMap()\n        self.assertEqual(inst.received(b\"\"), False)\n\n    def test_received_preq_not_completed(self):\n        inst, sock, map = self._makeOneWithMap()\n        inst.server = DummyServer()\n        preq = DummyParser()\n        inst.request = preq\n        preq.completed = False\n        preq.empty = True\n        inst.received(b\"GET / HTTP/1.1\\r\\n\\r\\n\")\n        self.assertEqual(inst.requests, ())\n        self.assertEqual(inst.server.tasks, [])\n\n    def test_received_preq_completed_empty(self):\n        inst, sock, map = self._makeOneWithMap()\n        inst.server = DummyServer()\n        preq = DummyParser()\n        inst.request = preq\n        preq.completed = True\n        preq.empty = True\n        inst.received(b\"GET / HTTP/1.1\\r\\n\\r\\n\")\n        self.assertEqual(inst.request, None)\n        self.assertEqual(inst.server.tasks, [])\n\n    def test_received_preq_error(self):\n        inst, sock, map = self._makeOneWithMap()\n        inst.server = DummyServer()\n        preq = DummyParser()\n        inst.request = preq\n        preq.completed = True\n        preq.error = True\n        inst.received(b\"GET / HTTP/1.1\\r\\n\\r\\n\")\n        self.assertEqual(inst.request, None)\n        self.assertEqual(len(inst.server.tasks), 1)\n        self.assertTrue(inst.requests)\n\n    def test_received_preq_completed_connection_close(self):\n        inst, sock, map = self._makeOneWithMap()\n        inst.server = DummyServer()\n        preq = DummyParser()\n        inst.request = preq\n        preq.completed = True\n        preq.empty = True\n        preq.connection_close = True\n        inst.received(b\"GET / HTTP/1.1\\r\\n\\r\\n\" + b\"a\" * 50000)\n        self.assertEqual(inst.request, None)\n        self.assertEqual(inst.server.tasks, [])\n\n    def test_received_headers_finished_expect_continue_false(self):\n        inst, sock, map = self._makeOneWithMap()\n        inst.server = DummyServer()\n        preq = DummyParser()\n        inst.request = preq\n        preq.expect_continue = False\n        preq.headers_finished = True\n        preq.completed = False\n        preq.empty = False\n        preq.retval = 1\n        inst.received(b\"GET / HTTP/1.1\\r\\n\\r\\n\")\n        self.assertEqual(inst.request, preq)\n        self.assertEqual(inst.server.tasks, [])\n        self.assertEqual(inst.outbufs[0].get(100), b\"\")\n\n    def test_received_headers_finished_expect_continue_true(self):\n        inst, sock, map = self._makeOneWithMap()\n        inst.server = DummyServer()\n        preq = DummyParser()\n        inst.request = preq\n        preq.expect_continue = True\n        preq.headers_finished = True\n        preq.completed = False\n        preq.empty = False\n        inst.received(b\"GET / HTTP/1.1\\r\\n\\r\\n\")\n        self.assertEqual(inst.request, preq)\n        self.assertEqual(inst.server.tasks, [])\n        self.assertEqual(sock.sent, b\"HTTP/1.1 100 Continue\\r\\n\\r\\n\")\n        self.assertEqual(inst.sent_continue, True)\n        self.assertEqual(preq.completed, False)\n\n    def test_received_headers_finished_expect_continue_true_sent_true(self):\n        inst, sock, map = self._makeOneWithMap()\n        inst.server = DummyServer()\n        preq = DummyParser()\n        inst.request = preq\n        preq.expect_continue = True\n        preq.headers_finished = True\n        preq.completed = False\n        preq.empty = False\n        inst.sent_continue = True\n        inst.received(b\"GET / HTTP/1.1\\r\\n\\r\\n\")\n        self.assertEqual(inst.request, preq)\n        self.assertEqual(inst.server.tasks, [])\n        self.assertEqual(sock.sent, b\"\")\n        self.assertEqual(inst.sent_continue, True)\n        self.assertEqual(preq.completed, False)\n\n    def test_service_no_requests(self):\n        inst, sock, map = self._makeOneWithMap()\n        inst.requests = []\n        inst.service()\n        self.assertEqual(inst.requests, [])\n        self.assertTrue(inst.server.trigger_pulled)\n        self.assertTrue(inst.last_activity)\n\n    def test_service_with_one_request(self):\n        inst, sock, map = self._makeOneWithMap()\n        request = DummyRequest()\n        inst.task_class = DummyTaskClass()\n        inst.requests = [request]\n        inst.service()\n        self.assertEqual(inst.requests, [])\n        self.assertTrue(request.serviced)\n        self.assertTrue(request.closed)\n\n    def test_service_with_one_error_request(self):\n        inst, sock, map = self._makeOneWithMap()\n        request = DummyRequest()\n        request.error = DummyError()\n        inst.error_task_class = DummyTaskClass()\n        inst.requests = [request]\n        inst.service()\n        self.assertEqual(inst.requests, [])\n        self.assertTrue(request.serviced)\n        self.assertTrue(request.closed)\n\n    def test_service_with_multiple_requests(self):\n        inst, sock, map = self._makeOneWithMap()\n        request1 = DummyRequest()\n        request2 = DummyRequest()\n        inst.task_class = DummyTaskClass()\n        inst.requests = [request1, request2]\n        inst.service()\n        self.assertEqual(inst.requests, [])\n        self.assertTrue(request1.serviced)\n        self.assertTrue(request2.serviced)\n        self.assertTrue(request1.closed)\n        self.assertTrue(request2.closed)\n\n    def test_service_with_request_raises(self):\n        inst, sock, map = self._makeOneWithMap()\n        inst.adj.expose_tracebacks = False\n        inst.server = DummyServer()\n        request = DummyRequest()\n        inst.requests = [request]\n        inst.task_class = DummyTaskClass(ValueError)\n        inst.task_class.wrote_header = False\n        inst.error_task_class = DummyTaskClass()\n        inst.logger = DummyLogger()\n        inst.service()\n        self.assertTrue(request.serviced)\n        self.assertEqual(inst.requests, [])\n        self.assertEqual(len(inst.logger.exceptions), 1)\n        self.assertTrue(inst.server.trigger_pulled)\n        self.assertTrue(inst.last_activity)\n        self.assertFalse(inst.will_close)\n        self.assertEqual(inst.error_task_class.serviced, True)\n        self.assertTrue(request.closed)\n\n    def test_service_with_requests_raises_already_wrote_header(self):\n        inst, sock, map = self._makeOneWithMap()\n        inst.adj.expose_tracebacks = False\n        inst.server = DummyServer()\n        request = DummyRequest()\n        inst.requests = [request]\n        inst.task_class = DummyTaskClass(ValueError)\n        inst.error_task_class = DummyTaskClass()\n        inst.logger = DummyLogger()\n        inst.service()\n        self.assertTrue(request.serviced)\n        self.assertEqual(inst.requests, [])\n        self.assertEqual(len(inst.logger.exceptions), 1)\n        self.assertTrue(inst.server.trigger_pulled)\n        self.assertTrue(inst.last_activity)\n        self.assertTrue(inst.close_when_flushed)\n        self.assertEqual(inst.error_task_class.serviced, False)\n        self.assertTrue(request.closed)\n\n    def test_service_with_requests_raises_didnt_write_header_expose_tbs(self):\n        inst, sock, map = self._makeOneWithMap()\n        inst.adj.expose_tracebacks = True\n        inst.server = DummyServer()\n        request = DummyRequest()\n        inst.requests = [request]\n        inst.task_class = DummyTaskClass(ValueError)\n        inst.task_class.wrote_header = False\n        inst.error_task_class = DummyTaskClass()\n        inst.logger = DummyLogger()\n        inst.service()\n        self.assertTrue(request.serviced)\n        self.assertFalse(inst.will_close)\n        self.assertEqual(inst.requests, [])\n        self.assertEqual(len(inst.logger.exceptions), 1)\n        self.assertTrue(inst.server.trigger_pulled)\n        self.assertTrue(inst.last_activity)\n        self.assertEqual(inst.error_task_class.serviced, True)\n        self.assertTrue(request.closed)\n\n    def test_service_with_requests_raises_didnt_write_header(self):\n        inst, sock, map = self._makeOneWithMap()\n        inst.adj.expose_tracebacks = False\n        inst.server = DummyServer()\n        request = DummyRequest()\n        inst.requests = [request]\n        inst.task_class = DummyTaskClass(ValueError)\n        inst.task_class.wrote_header = False\n        inst.logger = DummyLogger()\n        inst.service()\n        self.assertTrue(request.serviced)\n        self.assertEqual(inst.requests, [])\n        self.assertEqual(len(inst.logger.exceptions), 1)\n        self.assertTrue(inst.server.trigger_pulled)\n        self.assertTrue(inst.last_activity)\n        self.assertTrue(inst.close_when_flushed)\n        self.assertTrue(request.closed)\n\n    def test_service_with_request_raises_disconnect(self):\n        from waitress.channel import ClientDisconnected\n\n        inst, sock, map = self._makeOneWithMap()\n        inst.adj.expose_tracebacks = False\n        inst.server = DummyServer()\n        request = DummyRequest()\n        inst.requests = [request]\n        inst.task_class = DummyTaskClass(ClientDisconnected)\n        inst.error_task_class = DummyTaskClass()\n        inst.logger = DummyLogger()\n        inst.service()\n        self.assertTrue(request.serviced)\n        self.assertEqual(inst.requests, [])\n        self.assertEqual(len(inst.logger.infos), 1)\n        self.assertTrue(inst.server.trigger_pulled)\n        self.assertTrue(inst.last_activity)\n        self.assertFalse(inst.will_close)\n        self.assertEqual(inst.error_task_class.serviced, False)\n        self.assertTrue(request.closed)\n\n    def test_service_with_request_error_raises_disconnect(self):\n        from waitress.channel import ClientDisconnected\n\n        inst, sock, map = self._makeOneWithMap()\n        inst.adj.expose_tracebacks = False\n        inst.server = DummyServer()\n        request = DummyRequest()\n        err_request = DummyRequest()\n        inst.requests = [request]\n        inst.parser_class = lambda x: err_request\n        inst.task_class = DummyTaskClass(RuntimeError)\n        inst.task_class.wrote_header = False\n        inst.error_task_class = DummyTaskClass(ClientDisconnected)\n        inst.logger = DummyLogger()\n        inst.service()\n        self.assertTrue(request.serviced)\n        self.assertTrue(err_request.serviced)\n        self.assertEqual(inst.requests, [])\n        self.assertEqual(len(inst.logger.exceptions), 1)\n        self.assertEqual(len(inst.logger.infos), 0)\n        self.assertTrue(inst.server.trigger_pulled)\n        self.assertTrue(inst.last_activity)\n        self.assertFalse(inst.will_close)\n        self.assertEqual(inst.task_class.serviced, True)\n        self.assertEqual(inst.error_task_class.serviced, True)\n        self.assertTrue(request.closed)\n\n    def test_cancel_no_requests(self):\n        inst, sock, map = self._makeOneWithMap()\n        inst.requests = ()\n        inst.cancel()\n        self.assertEqual(inst.requests, [])\n\n    def test_cancel_with_requests(self):\n        inst, sock, map = self._makeOneWithMap()\n        inst.requests = [None]\n        inst.cancel()\n        self.assertEqual(inst.requests, [])\n\n\nclass DummySock(object):\n    blocking = False\n    closed = False\n\n    def __init__(self):\n        self.sent = b\"\"\n\n    def setblocking(self, *arg):\n        self.blocking = True\n\n    def fileno(self):\n        return 100\n\n    def getpeername(self):\n        return \"127.0.0.1\"\n\n    def getsockopt(self, level, option):\n        return 2048\n\n    def close(self):\n        self.closed = True\n\n    def send(self, data):\n        self.sent += data\n        return len(data)\n\n\nclass DummyLock(object):\n    notified = False\n\n    def __init__(self, acquirable=True):\n        self.acquirable = acquirable\n\n    def acquire(self, val):\n        self.val = val\n        self.acquired = True\n        return self.acquirable\n\n    def release(self):\n        self.released = True\n\n    def notify(self):\n        self.notified = True\n\n    def wait(self):\n        self.waited = True\n\n    def __exit__(self, type, val, traceback):\n        self.acquire(True)\n\n    def __enter__(self):\n        pass\n\n\nclass DummyBuffer(object):\n    closed = False\n\n    def __init__(self, data, toraise=None):\n        self.data = data\n        self.toraise = toraise\n\n    def get(self, *arg):\n        if self.toraise:\n            raise self.toraise\n        data = self.data\n        self.data = b\"\"\n        return data\n\n    def skip(self, num, x):\n        self.skipped = num\n\n    def __len__(self):\n        return len(self.data)\n\n    def close(self):\n        self.closed = True\n\n\nclass DummyAdjustments(object):\n    outbuf_overflow = 1048576\n    outbuf_high_watermark = 1048576\n    inbuf_overflow = 512000\n    cleanup_interval = 900\n    url_scheme = \"http\"\n    channel_timeout = 300\n    log_socket_errors = True\n    recv_bytes = 8192\n    send_bytes = 1\n    expose_tracebacks = True\n    ident = \"waitress\"\n    max_request_header_size = 10000\n\n\nclass DummyServer(object):\n    trigger_pulled = False\n    adj = DummyAdjustments()\n\n    def __init__(self):\n        self.tasks = []\n        self.active_channels = {}\n\n    def add_task(self, task):\n        self.tasks.append(task)\n\n    def pull_trigger(self):\n        self.trigger_pulled = True\n\n\nclass DummyParser(object):\n    version = 1\n    data = None\n    completed = True\n    empty = False\n    headers_finished = False\n    expect_continue = False\n    retval = None\n    error = None\n    connection_close = False\n\n    def received(self, data):\n        self.data = data\n        if self.retval is not None:\n            return self.retval\n        return len(data)\n\n\nclass DummyRequest(object):\n    error = None\n    path = \"/\"\n    version = \"1.0\"\n    closed = False\n\n    def __init__(self):\n        self.headers = {}\n\n    def close(self):\n        self.closed = True\n\n\nclass DummyLogger(object):\n    def __init__(self):\n        self.exceptions = []\n        self.infos = []\n        self.warnings = []\n\n    def info(self, msg):\n        self.infos.append(msg)\n\n    def exception(self, msg):\n        self.exceptions.append(msg)\n\n\nclass DummyError(object):\n    code = \"431\"\n    reason = \"Bleh\"\n    body = \"My body\"\n\n\nclass DummyTaskClass(object):\n    wrote_header = True\n    close_on_finish = False\n    serviced = False\n\n    def __init__(self, toraise=None):\n        self.toraise = toraise\n\n    def __call__(self, channel, request):\n        self.request = request\n        return self\n\n    def service(self):\n        self.serviced = True\n        self.request.serviced = True\n        if self.toraise:\n            raise self.toraise\n", "import errno\nimport logging\nimport multiprocessing\nimport os\nimport signal\nimport socket\nimport string\nimport subprocess\nimport sys\nimport time\nimport unittest\nfrom waitress import server\nfrom waitress.compat import httplib, tobytes\nfrom waitress.utilities import cleanup_unix_socket\n\ndn = os.path.dirname\nhere = dn(__file__)\n\n\nclass NullHandler(logging.Handler):  # pragma: no cover\n    \"\"\"A logging handler that swallows all emitted messages.\n    \"\"\"\n\n    def emit(self, record):\n        pass\n\n\ndef start_server(app, svr, queue, **kwargs):  # pragma: no cover\n    \"\"\"Run a fixture application.\n    \"\"\"\n    logging.getLogger(\"waitress\").addHandler(NullHandler())\n    try_register_coverage()\n    svr(app, queue, **kwargs).run()\n\n\ndef try_register_coverage():  # pragma: no cover\n    # Hack around multiprocessing exiting early and not triggering coverage's\n    # atexit handler by always registering a signal handler\n\n    if \"COVERAGE_PROCESS_START\" in os.environ:\n        def sigterm(*args):\n            sys.exit(0)\n\n        signal.signal(signal.SIGTERM, sigterm)\n\n\nclass FixtureTcpWSGIServer(server.TcpWSGIServer):\n    \"\"\"A version of TcpWSGIServer that relays back what it's bound to.\n    \"\"\"\n\n    family = socket.AF_INET  # Testing\n\n    def __init__(self, application, queue, **kw):  # pragma: no cover\n        # Coverage doesn't see this as it's ran in a separate process.\n        kw[\"port\"] = 0  # Bind to any available port.\n        super(FixtureTcpWSGIServer, self).__init__(application, **kw)\n        host, port = self.socket.getsockname()\n        if os.name == \"nt\":\n            host = \"127.0.0.1\"\n        queue.put((host, port))\n\n\nclass SubprocessTests(object):\n\n    # For nose: all tests may be ran in separate processes.\n    _multiprocess_can_split_ = True\n\n    exe = sys.executable\n\n    server = None\n\n    def start_subprocess(self, target, **kw):\n        # Spawn a server process.\n        self.queue = multiprocessing.Queue()\n\n        if \"COVERAGE_RCFILE\" in os.environ:\n            os.environ[\"COVERAGE_PROCESS_START\"] = os.environ[\"COVERAGE_RCFILE\"]\n\n        self.proc = multiprocessing.Process(\n            target=start_server, args=(target, self.server, self.queue), kwargs=kw,\n        )\n        self.proc.start()\n\n        if self.proc.exitcode is not None:  # pragma: no cover\n            raise RuntimeError(\"%s didn't start\" % str(target))\n        # Get the socket the server is listening on.\n        self.bound_to = self.queue.get(timeout=5)\n        self.sock = self.create_socket()\n\n    def stop_subprocess(self):\n        if self.proc.exitcode is None:\n            self.proc.terminate()\n        self.sock.close()\n        # This give us one FD back ...\n        self.queue.close()\n        self.proc.join()\n\n    def assertline(self, line, status, reason, version):\n        v, s, r = (x.strip() for x in line.split(None, 2))\n        self.assertEqual(s, tobytes(status))\n        self.assertEqual(r, tobytes(reason))\n        self.assertEqual(v, tobytes(version))\n\n    def create_socket(self):\n        return socket.socket(self.server.family, socket.SOCK_STREAM)\n\n    def connect(self):\n        self.sock.connect(self.bound_to)\n\n    def make_http_connection(self):\n        raise NotImplementedError  # pragma: no cover\n\n    def send_check_error(self, to_send):\n        self.sock.send(to_send)\n\n\nclass TcpTests(SubprocessTests):\n\n    server = FixtureTcpWSGIServer\n\n    def make_http_connection(self):\n        return httplib.HTTPConnection(*self.bound_to)\n\n\nclass SleepyThreadTests(TcpTests, unittest.TestCase):\n    # test that sleepy thread doesnt block other requests\n\n    def setUp(self):\n        from waitress.tests.fixtureapps import sleepy\n\n        self.start_subprocess(sleepy.app)\n\n    def tearDown(self):\n        self.stop_subprocess()\n\n    def test_it(self):\n        getline = os.path.join(here, \"fixtureapps\", \"getline.py\")\n        cmds = (\n            [self.exe, getline, \"http://%s:%d/sleepy\" % self.bound_to],\n            [self.exe, getline, \"http://%s:%d/\" % self.bound_to],\n        )\n        r, w = os.pipe()\n        procs = []\n        for cmd in cmds:\n            procs.append(subprocess.Popen(cmd, stdout=w))\n        time.sleep(3)\n        for proc in procs:\n            if proc.returncode is not None:  # pragma: no cover\n                proc.terminate()\n            proc.wait()\n        # the notsleepy response should always be first returned (it sleeps\n        # for 2 seconds, then returns; the notsleepy response should be\n        # processed in the meantime)\n        result = os.read(r, 10000)\n        os.close(r)\n        os.close(w)\n        self.assertEqual(result, b\"notsleepy returnedsleepy returned\")\n\n\nclass EchoTests(object):\n    def setUp(self):\n        from waitress.tests.fixtureapps import echo\n\n        self.start_subprocess(\n            echo.app,\n            trusted_proxy=\"*\",\n            trusted_proxy_count=1,\n            trusted_proxy_headers={\"x-forwarded-for\", \"x-forwarded-proto\"},\n            clear_untrusted_proxy_headers=True,\n        )\n\n    def tearDown(self):\n        self.stop_subprocess()\n\n    def _read_echo(self, fp):\n        from waitress.tests.fixtureapps import echo\n\n        line, headers, body = read_http(fp)\n        return line, headers, echo.parse_response(body)\n\n    def test_date_and_server(self):\n        to_send = \"GET / HTTP/1.0\\r\\nContent-Length: 0\\r\\n\\r\\n\"\n        to_send = tobytes(to_send)\n        self.connect()\n        self.sock.send(to_send)\n        fp = self.sock.makefile(\"rb\", 0)\n        line, headers, echo = self._read_echo(fp)\n        self.assertline(line, \"200\", \"OK\", \"HTTP/1.0\")\n        self.assertEqual(headers.get(\"server\"), \"waitress\")\n        self.assertTrue(headers.get(\"date\"))\n\n    def test_bad_host_header(self):\n        # https://corte.si/posts/code/pathod/pythonservers/index.html\n        to_send = \"GET / HTTP/1.0\\r\\n Host: 0\\r\\n\\r\\n\"\n        to_send = tobytes(to_send)\n        self.connect()\n        self.sock.send(to_send)\n        fp = self.sock.makefile(\"rb\", 0)\n        line, headers, response_body = read_http(fp)\n        self.assertline(line, \"400\", \"Bad Request\", \"HTTP/1.0\")\n        self.assertEqual(headers.get(\"server\"), \"waitress\")\n        self.assertTrue(headers.get(\"date\"))\n\n    def test_send_with_body(self):\n        to_send = \"GET / HTTP/1.0\\r\\nContent-Length: 5\\r\\n\\r\\n\"\n        to_send += \"hello\"\n        to_send = tobytes(to_send)\n        self.connect()\n        self.sock.send(to_send)\n        fp = self.sock.makefile(\"rb\", 0)\n        line, headers, echo = self._read_echo(fp)\n        self.assertline(line, \"200\", \"OK\", \"HTTP/1.0\")\n        self.assertEqual(echo.content_length, \"5\")\n        self.assertEqual(echo.body, b\"hello\")\n\n    def test_send_empty_body(self):\n        to_send = \"GET / HTTP/1.0\\r\\nContent-Length: 0\\r\\n\\r\\n\"\n        to_send = tobytes(to_send)\n        self.connect()\n        self.sock.send(to_send)\n        fp = self.sock.makefile(\"rb\", 0)\n        line, headers, echo = self._read_echo(fp)\n        self.assertline(line, \"200\", \"OK\", \"HTTP/1.0\")\n        self.assertEqual(echo.content_length, \"0\")\n        self.assertEqual(echo.body, b\"\")\n\n    def test_multiple_requests_with_body(self):\n        orig_sock = self.sock\n        for x in range(3):\n            self.sock = self.create_socket()\n            self.test_send_with_body()\n            self.sock.close()\n        self.sock = orig_sock\n\n    def test_multiple_requests_without_body(self):\n        orig_sock = self.sock\n        for x in range(3):\n            self.sock = self.create_socket()\n            self.test_send_empty_body()\n            self.sock.close()\n        self.sock = orig_sock\n\n    def test_without_crlf(self):\n        data = \"Echo\\r\\nthis\\r\\nplease\"\n        s = tobytes(\n            \"GET / HTTP/1.0\\r\\n\"\n            \"Connection: close\\r\\n\"\n            \"Content-Length: %d\\r\\n\"\n            \"\\r\\n\"\n            \"%s\" % (len(data), data)\n        )\n        self.connect()\n        self.sock.send(s)\n        fp = self.sock.makefile(\"rb\", 0)\n        line, headers, echo = self._read_echo(fp)\n        self.assertline(line, \"200\", \"OK\", \"HTTP/1.0\")\n        self.assertEqual(int(echo.content_length), len(data))\n        self.assertEqual(len(echo.body), len(data))\n        self.assertEqual(echo.body, tobytes(data))\n\n    def test_large_body(self):\n        # 1024 characters.\n        body = \"This string has 32 characters.\\r\\n\" * 32\n        s = tobytes(\n            \"GET / HTTP/1.0\\r\\nContent-Length: %d\\r\\n\\r\\n%s\" % (len(body), body)\n        )\n        self.connect()\n        self.sock.send(s)\n        fp = self.sock.makefile(\"rb\", 0)\n        line, headers, echo = self._read_echo(fp)\n        self.assertline(line, \"200\", \"OK\", \"HTTP/1.0\")\n        self.assertEqual(echo.content_length, \"1024\")\n        self.assertEqual(echo.body, tobytes(body))\n\n    def test_many_clients(self):\n        conns = []\n        for n in range(50):\n            h = self.make_http_connection()\n            h.request(\"GET\", \"/\", headers={\"Accept\": \"text/plain\"})\n            conns.append(h)\n        responses = []\n        for h in conns:\n            response = h.getresponse()\n            self.assertEqual(response.status, 200)\n            responses.append(response)\n        for response in responses:\n            response.read()\n        for h in conns:\n            h.close()\n\n    def test_chunking_request_without_content(self):\n        header = tobytes(\"GET / HTTP/1.1\\r\\nTransfer-Encoding: chunked\\r\\n\\r\\n\")\n        self.connect()\n        self.sock.send(header)\n        self.sock.send(b\"0\\r\\n\\r\\n\")\n        fp = self.sock.makefile(\"rb\", 0)\n        line, headers, echo = self._read_echo(fp)\n        self.assertline(line, \"200\", \"OK\", \"HTTP/1.1\")\n        self.assertEqual(echo.body, b\"\")\n        self.assertEqual(echo.content_length, \"0\")\n        self.assertFalse(\"transfer-encoding\" in headers)\n\n    def test_chunking_request_with_content(self):\n        control_line = b\"20;\\r\\n\"  # 20 hex = 32 dec\n        s = b\"This string has 32 characters.\\r\\n\"\n        expected = s * 12\n        header = tobytes(\"GET / HTTP/1.1\\r\\nTransfer-Encoding: chunked\\r\\n\\r\\n\")\n        self.connect()\n        self.sock.send(header)\n        fp = self.sock.makefile(\"rb\", 0)\n        for n in range(12):\n            self.sock.send(control_line)\n            self.sock.send(s)\n            self.sock.send(b\"\\r\\n\")  # End the chunk\n        self.sock.send(b\"0\\r\\n\\r\\n\")\n        line, headers, echo = self._read_echo(fp)\n        self.assertline(line, \"200\", \"OK\", \"HTTP/1.1\")\n        self.assertEqual(echo.body, expected)\n        self.assertEqual(echo.content_length, str(len(expected)))\n        self.assertFalse(\"transfer-encoding\" in headers)\n\n    def test_broken_chunked_encoding(self):\n        control_line = \"20;\\r\\n\"  # 20 hex = 32 dec\n        s = \"This string has 32 characters.\\r\\n\"\n        to_send = \"GET / HTTP/1.1\\r\\nTransfer-Encoding: chunked\\r\\n\\r\\n\"\n        to_send += control_line + s + \"\\r\\n\"\n        # garbage in input\n        to_send += \"garbage\\r\\n\"\n        to_send = tobytes(to_send)\n        self.connect()\n        self.sock.send(to_send)\n        fp = self.sock.makefile(\"rb\", 0)\n        line, headers, response_body = read_http(fp)\n        # receiver caught garbage and turned it into a 400\n        self.assertline(line, \"400\", \"Bad Request\", \"HTTP/1.1\")\n        cl = int(headers[\"content-length\"])\n        self.assertEqual(cl, len(response_body))\n        self.assertEqual(\n            sorted(headers.keys()), [\"connection\", \"content-length\", \"content-type\", \"date\", \"server\"]\n        )\n        self.assertEqual(headers[\"content-type\"], \"text/plain\")\n        # connection has been closed\n        self.send_check_error(to_send)\n        self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_broken_chunked_encoding_missing_chunk_end(self):\n        control_line = \"20;\\r\\n\"  # 20 hex = 32 dec\n        s = \"This string has 32 characters.\\r\\n\"\n        to_send = \"GET / HTTP/1.1\\r\\nTransfer-Encoding: chunked\\r\\n\\r\\n\"\n        to_send += control_line + s\n        # garbage in input\n        to_send += \"garbage\"\n        to_send = tobytes(to_send)\n        self.connect()\n        self.sock.send(to_send)\n        fp = self.sock.makefile(\"rb\", 0)\n        line, headers, response_body = read_http(fp)\n        # receiver caught garbage and turned it into a 400\n        self.assertline(line, \"400\", \"Bad Request\", \"HTTP/1.1\")\n        cl = int(headers[\"content-length\"])\n        self.assertEqual(cl, len(response_body))\n        self.assertTrue(b\"Chunk not properly terminated\" in response_body)\n        self.assertEqual(\n            sorted(headers.keys()), [\"connection\", \"content-length\", \"content-type\", \"date\", \"server\"]\n        )\n        self.assertEqual(headers[\"content-type\"], \"text/plain\")\n        # connection has been closed\n        self.send_check_error(to_send)\n        self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_keepalive_http_10(self):\n        # Handling of Keep-Alive within HTTP 1.0\n        data = \"Default: Don't keep me alive\"\n        s = tobytes(\n            \"GET / HTTP/1.0\\r\\nContent-Length: %d\\r\\n\\r\\n%s\" % (len(data), data)\n        )\n        self.connect()\n        self.sock.send(s)\n        response = httplib.HTTPResponse(self.sock)\n        response.begin()\n        self.assertEqual(int(response.status), 200)\n        connection = response.getheader(\"Connection\", \"\")\n        # We sent no Connection: Keep-Alive header\n        # Connection: close (or no header) is default.\n        self.assertTrue(connection != \"Keep-Alive\")\n\n    def test_keepalive_http10_explicit(self):\n        # If header Connection: Keep-Alive is explicitly sent,\n        # we want to keept the connection open, we also need to return\n        # the corresponding header\n        data = \"Keep me alive\"\n        s = tobytes(\n            \"GET / HTTP/1.0\\r\\n\"\n            \"Connection: Keep-Alive\\r\\n\"\n            \"Content-Length: %d\\r\\n\"\n            \"\\r\\n\"\n            \"%s\" % (len(data), data)\n        )\n        self.connect()\n        self.sock.send(s)\n        response = httplib.HTTPResponse(self.sock)\n        response.begin()\n        self.assertEqual(int(response.status), 200)\n        connection = response.getheader(\"Connection\", \"\")\n        self.assertEqual(connection, \"Keep-Alive\")\n\n    def test_keepalive_http_11(self):\n        # Handling of Keep-Alive within HTTP 1.1\n\n        # All connections are kept alive, unless stated otherwise\n        data = \"Default: Keep me alive\"\n        s = tobytes(\n            \"GET / HTTP/1.1\\r\\nContent-Length: %d\\r\\n\\r\\n%s\" % (len(data), data)\n        )\n        self.connect()\n        self.sock.send(s)\n        response = httplib.HTTPResponse(self.sock)\n        response.begin()\n        self.assertEqual(int(response.status), 200)\n        self.assertTrue(response.getheader(\"connection\") != \"close\")\n\n    def test_keepalive_http11_explicit(self):\n        # Explicitly set keep-alive\n        data = \"Default: Keep me alive\"\n        s = tobytes(\n            \"GET / HTTP/1.1\\r\\n\"\n            \"Connection: keep-alive\\r\\n\"\n            \"Content-Length: %d\\r\\n\"\n            \"\\r\\n\"\n            \"%s\" % (len(data), data)\n        )\n        self.connect()\n        self.sock.send(s)\n        response = httplib.HTTPResponse(self.sock)\n        response.begin()\n        self.assertEqual(int(response.status), 200)\n        self.assertTrue(response.getheader(\"connection\") != \"close\")\n\n    def test_keepalive_http11_connclose(self):\n        # specifying Connection: close explicitly\n        data = \"Don't keep me alive\"\n        s = tobytes(\n            \"GET / HTTP/1.1\\r\\n\"\n            \"Connection: close\\r\\n\"\n            \"Content-Length: %d\\r\\n\"\n            \"\\r\\n\"\n            \"%s\" % (len(data), data)\n        )\n        self.connect()\n        self.sock.send(s)\n        response = httplib.HTTPResponse(self.sock)\n        response.begin()\n        self.assertEqual(int(response.status), 200)\n        self.assertEqual(response.getheader(\"connection\"), \"close\")\n\n    def test_proxy_headers(self):\n        to_send = (\n            \"GET / HTTP/1.0\\r\\n\"\n            \"Content-Length: 0\\r\\n\"\n            \"Host: www.google.com:8080\\r\\n\"\n            \"X-Forwarded-For: 192.168.1.1\\r\\n\"\n            \"X-Forwarded-Proto: https\\r\\n\"\n            \"X-Forwarded-Port: 5000\\r\\n\\r\\n\"\n        )\n        to_send = tobytes(to_send)\n        self.connect()\n        self.sock.send(to_send)\n        fp = self.sock.makefile(\"rb\", 0)\n        line, headers, echo = self._read_echo(fp)\n        self.assertline(line, \"200\", \"OK\", \"HTTP/1.0\")\n        self.assertEqual(headers.get(\"server\"), \"waitress\")\n        self.assertTrue(headers.get(\"date\"))\n        self.assertIsNone(echo.headers.get(\"X_FORWARDED_PORT\"))\n        self.assertEqual(echo.headers[\"HOST\"], \"www.google.com:8080\")\n        self.assertEqual(echo.scheme, \"https\")\n        self.assertEqual(echo.remote_addr, \"192.168.1.1\")\n        self.assertEqual(echo.remote_host, \"192.168.1.1\")\n\n\nclass PipeliningTests(object):\n    def setUp(self):\n        from waitress.tests.fixtureapps import echo\n\n        self.start_subprocess(echo.app_body_only)\n\n    def tearDown(self):\n        self.stop_subprocess()\n\n    def test_pipelining(self):\n        s = (\n            \"GET / HTTP/1.0\\r\\n\"\n            \"Connection: %s\\r\\n\"\n            \"Content-Length: %d\\r\\n\"\n            \"\\r\\n\"\n            \"%s\"\n        )\n        to_send = b\"\"\n        count = 25\n        for n in range(count):\n            body = \"Response #%d\\r\\n\" % (n + 1)\n            if n + 1 < count:\n                conn = \"keep-alive\"\n            else:\n                conn = \"close\"\n            to_send += tobytes(s % (conn, len(body), body))\n\n        self.connect()\n        self.sock.send(to_send)\n        fp = self.sock.makefile(\"rb\", 0)\n        for n in range(count):\n            expect_body = tobytes(\"Response #%d\\r\\n\" % (n + 1))\n            line = fp.readline()  # status line\n            version, status, reason = (x.strip() for x in line.split(None, 2))\n            headers = parse_headers(fp)\n            length = int(headers.get(\"content-length\")) or None\n            response_body = fp.read(length)\n            self.assertEqual(int(status), 200)\n            self.assertEqual(length, len(response_body))\n            self.assertEqual(response_body, expect_body)\n\n\nclass ExpectContinueTests(object):\n    def setUp(self):\n        from waitress.tests.fixtureapps import echo\n\n        self.start_subprocess(echo.app_body_only)\n\n    def tearDown(self):\n        self.stop_subprocess()\n\n    def test_expect_continue(self):\n        # specifying Connection: close explicitly\n        data = \"I have expectations\"\n        to_send = tobytes(\n            \"GET / HTTP/1.1\\r\\n\"\n            \"Connection: close\\r\\n\"\n            \"Content-Length: %d\\r\\n\"\n            \"Expect: 100-continue\\r\\n\"\n            \"\\r\\n\"\n            \"%s\" % (len(data), data)\n        )\n        self.connect()\n        self.sock.send(to_send)\n        fp = self.sock.makefile(\"rb\", 0)\n        line = fp.readline()  # continue status line\n        version, status, reason = (x.strip() for x in line.split(None, 2))\n        self.assertEqual(int(status), 100)\n        self.assertEqual(reason, b\"Continue\")\n        self.assertEqual(version, b\"HTTP/1.1\")\n        fp.readline()  # blank line\n        line = fp.readline()  # next status line\n        version, status, reason = (x.strip() for x in line.split(None, 2))\n        headers = parse_headers(fp)\n        length = int(headers.get(\"content-length\")) or None\n        response_body = fp.read(length)\n        self.assertEqual(int(status), 200)\n        self.assertEqual(length, len(response_body))\n        self.assertEqual(response_body, tobytes(data))\n\n\nclass BadContentLengthTests(object):\n    def setUp(self):\n        from waitress.tests.fixtureapps import badcl\n\n        self.start_subprocess(badcl.app)\n\n    def tearDown(self):\n        self.stop_subprocess()\n\n    def test_short_body(self):\n        # check to see if server closes connection when body is too short\n        # for cl header\n        to_send = tobytes(\n            \"GET /short_body HTTP/1.0\\r\\n\"\n            \"Connection: Keep-Alive\\r\\n\"\n            \"Content-Length: 0\\r\\n\"\n            \"\\r\\n\"\n        )\n        self.connect()\n        self.sock.send(to_send)\n        fp = self.sock.makefile(\"rb\", 0)\n        line = fp.readline()  # status line\n        version, status, reason = (x.strip() for x in line.split(None, 2))\n        headers = parse_headers(fp)\n        content_length = int(headers.get(\"content-length\"))\n        response_body = fp.read(content_length)\n        self.assertEqual(int(status), 200)\n        self.assertNotEqual(content_length, len(response_body))\n        self.assertEqual(len(response_body), content_length - 1)\n        self.assertEqual(response_body, tobytes(\"abcdefghi\"))\n        # remote closed connection (despite keepalive header); not sure why\n        # first send succeeds\n        self.send_check_error(to_send)\n        self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_long_body(self):\n        # check server doesnt close connection when body is too short\n        # for cl header\n        to_send = tobytes(\n            \"GET /long_body HTTP/1.0\\r\\n\"\n            \"Connection: Keep-Alive\\r\\n\"\n            \"Content-Length: 0\\r\\n\"\n            \"\\r\\n\"\n        )\n        self.connect()\n        self.sock.send(to_send)\n        fp = self.sock.makefile(\"rb\", 0)\n        line = fp.readline()  # status line\n        version, status, reason = (x.strip() for x in line.split(None, 2))\n        headers = parse_headers(fp)\n        content_length = int(headers.get(\"content-length\")) or None\n        response_body = fp.read(content_length)\n        self.assertEqual(int(status), 200)\n        self.assertEqual(content_length, len(response_body))\n        self.assertEqual(response_body, tobytes(\"abcdefgh\"))\n        # remote does not close connection (keepalive header)\n        self.sock.send(to_send)\n        fp = self.sock.makefile(\"rb\", 0)\n        line = fp.readline()  # status line\n        version, status, reason = (x.strip() for x in line.split(None, 2))\n        headers = parse_headers(fp)\n        content_length = int(headers.get(\"content-length\")) or None\n        response_body = fp.read(content_length)\n        self.assertEqual(int(status), 200)\n\n\nclass NoContentLengthTests(object):\n    def setUp(self):\n        from waitress.tests.fixtureapps import nocl\n\n        self.start_subprocess(nocl.app)\n\n    def tearDown(self):\n        self.stop_subprocess()\n\n    def test_http10_generator(self):\n        body = string.ascii_letters\n        to_send = (\n            \"GET / HTTP/1.0\\r\\n\"\n            \"Connection: Keep-Alive\\r\\n\"\n            \"Content-Length: %d\\r\\n\\r\\n\" % len(body)\n        )\n        to_send += body\n        to_send = tobytes(to_send)\n        self.connect()\n        self.sock.send(to_send)\n        fp = self.sock.makefile(\"rb\", 0)\n        line, headers, response_body = read_http(fp)\n        self.assertline(line, \"200\", \"OK\", \"HTTP/1.0\")\n        self.assertEqual(headers.get(\"content-length\"), None)\n        self.assertEqual(headers.get(\"connection\"), \"close\")\n        self.assertEqual(response_body, tobytes(body))\n        # remote closed connection (despite keepalive header), because\n        # generators cannot have a content-length divined\n        self.send_check_error(to_send)\n        self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_http10_list(self):\n        body = string.ascii_letters\n        to_send = (\n            \"GET /list HTTP/1.0\\r\\n\"\n            \"Connection: Keep-Alive\\r\\n\"\n            \"Content-Length: %d\\r\\n\\r\\n\" % len(body)\n        )\n        to_send += body\n        to_send = tobytes(to_send)\n        self.connect()\n        self.sock.send(to_send)\n        fp = self.sock.makefile(\"rb\", 0)\n        line, headers, response_body = read_http(fp)\n        self.assertline(line, \"200\", \"OK\", \"HTTP/1.0\")\n        self.assertEqual(headers[\"content-length\"], str(len(body)))\n        self.assertEqual(headers.get(\"connection\"), \"Keep-Alive\")\n        self.assertEqual(response_body, tobytes(body))\n        # remote keeps connection open because it divined the content length\n        # from a length-1 list\n        self.sock.send(to_send)\n        line, headers, response_body = read_http(fp)\n        self.assertline(line, \"200\", \"OK\", \"HTTP/1.0\")\n\n    def test_http10_listlentwo(self):\n        body = string.ascii_letters\n        to_send = (\n            \"GET /list_lentwo HTTP/1.0\\r\\n\"\n            \"Connection: Keep-Alive\\r\\n\"\n            \"Content-Length: %d\\r\\n\\r\\n\" % len(body)\n        )\n        to_send += body\n        to_send = tobytes(to_send)\n        self.connect()\n        self.sock.send(to_send)\n        fp = self.sock.makefile(\"rb\", 0)\n        line, headers, response_body = read_http(fp)\n        self.assertline(line, \"200\", \"OK\", \"HTTP/1.0\")\n        self.assertEqual(headers.get(\"content-length\"), None)\n        self.assertEqual(headers.get(\"connection\"), \"close\")\n        self.assertEqual(response_body, tobytes(body))\n        # remote closed connection (despite keepalive header), because\n        # lists of length > 1 cannot have their content length divined\n        self.send_check_error(to_send)\n        self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_http11_generator(self):\n        body = string.ascii_letters\n        to_send = \"GET / HTTP/1.1\\r\\nContent-Length: %s\\r\\n\\r\\n\" % len(body)\n        to_send += body\n        to_send = tobytes(to_send)\n        self.connect()\n        self.sock.send(to_send)\n        fp = self.sock.makefile(\"rb\")\n        line, headers, response_body = read_http(fp)\n        self.assertline(line, \"200\", \"OK\", \"HTTP/1.1\")\n        expected = b\"\"\n        for chunk in chunks(body, 10):\n            expected += tobytes(\n                \"%s\\r\\n%s\\r\\n\" % (str(hex(len(chunk))[2:].upper()), chunk)\n            )\n        expected += b\"0\\r\\n\\r\\n\"\n        self.assertEqual(response_body, expected)\n        # connection is always closed at the end of a chunked response\n        self.send_check_error(to_send)\n        self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_http11_list(self):\n        body = string.ascii_letters\n        to_send = \"GET /list HTTP/1.1\\r\\nContent-Length: %d\\r\\n\\r\\n\" % len(body)\n        to_send += body\n        to_send = tobytes(to_send)\n        self.connect()\n        self.sock.send(to_send)\n        fp = self.sock.makefile(\"rb\", 0)\n        line, headers, response_body = read_http(fp)\n        self.assertline(line, \"200\", \"OK\", \"HTTP/1.1\")\n        self.assertEqual(headers[\"content-length\"], str(len(body)))\n        self.assertEqual(response_body, tobytes(body))\n        # remote keeps connection open because it divined the content length\n        # from a length-1 list\n        self.sock.send(to_send)\n        line, headers, response_body = read_http(fp)\n        self.assertline(line, \"200\", \"OK\", \"HTTP/1.1\")\n\n    def test_http11_listlentwo(self):\n        body = string.ascii_letters\n        to_send = \"GET /list_lentwo HTTP/1.1\\r\\nContent-Length: %s\\r\\n\\r\\n\" % len(body)\n        to_send += body\n        to_send = tobytes(to_send)\n        self.connect()\n        self.sock.send(to_send)\n        fp = self.sock.makefile(\"rb\")\n        line, headers, response_body = read_http(fp)\n        self.assertline(line, \"200\", \"OK\", \"HTTP/1.1\")\n        expected = b\"\"\n        for chunk in (body[0], body[1:]):\n            expected += tobytes(\n                \"%s\\r\\n%s\\r\\n\" % (str(hex(len(chunk))[2:].upper()), chunk)\n            )\n        expected += b\"0\\r\\n\\r\\n\"\n        self.assertEqual(response_body, expected)\n        # connection is always closed at the end of a chunked response\n        self.send_check_error(to_send)\n        self.assertRaises(ConnectionClosed, read_http, fp)\n\n\nclass WriteCallbackTests(object):\n    def setUp(self):\n        from waitress.tests.fixtureapps import writecb\n\n        self.start_subprocess(writecb.app)\n\n    def tearDown(self):\n        self.stop_subprocess()\n\n    def test_short_body(self):\n        # check to see if server closes connection when body is too short\n        # for cl header\n        to_send = tobytes(\n            \"GET /short_body HTTP/1.0\\r\\n\"\n            \"Connection: Keep-Alive\\r\\n\"\n            \"Content-Length: 0\\r\\n\"\n            \"\\r\\n\"\n        )\n        self.connect()\n        self.sock.send(to_send)\n        fp = self.sock.makefile(\"rb\", 0)\n        line, headers, response_body = read_http(fp)\n        # server trusts the content-length header (5)\n        self.assertline(line, \"200\", \"OK\", \"HTTP/1.0\")\n        cl = int(headers[\"content-length\"])\n        self.assertEqual(cl, 9)\n        self.assertNotEqual(cl, len(response_body))\n        self.assertEqual(len(response_body), cl - 1)\n        self.assertEqual(response_body, tobytes(\"abcdefgh\"))\n        # remote closed connection (despite keepalive header)\n        self.send_check_error(to_send)\n        self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_long_body(self):\n        # check server doesnt close connection when body is too long\n        # for cl header\n        to_send = tobytes(\n            \"GET /long_body HTTP/1.0\\r\\n\"\n            \"Connection: Keep-Alive\\r\\n\"\n            \"Content-Length: 0\\r\\n\"\n            \"\\r\\n\"\n        )\n        self.connect()\n        self.sock.send(to_send)\n        fp = self.sock.makefile(\"rb\", 0)\n        line, headers, response_body = read_http(fp)\n        content_length = int(headers.get(\"content-length\")) or None\n        self.assertEqual(content_length, 9)\n        self.assertEqual(content_length, len(response_body))\n        self.assertEqual(response_body, tobytes(\"abcdefghi\"))\n        # remote does not close connection (keepalive header)\n        self.sock.send(to_send)\n        fp = self.sock.makefile(\"rb\", 0)\n        line, headers, response_body = read_http(fp)\n        self.assertline(line, \"200\", \"OK\", \"HTTP/1.0\")\n\n    def test_equal_body(self):\n        # check server doesnt close connection when body is equal to\n        # cl header\n        to_send = tobytes(\n            \"GET /equal_body HTTP/1.0\\r\\n\"\n            \"Connection: Keep-Alive\\r\\n\"\n            \"Content-Length: 0\\r\\n\"\n            \"\\r\\n\"\n        )\n        self.connect()\n        self.sock.send(to_send)\n        fp = self.sock.makefile(\"rb\", 0)\n        line, headers, response_body = read_http(fp)\n        content_length = int(headers.get(\"content-length\")) or None\n        self.assertEqual(content_length, 9)\n        self.assertline(line, \"200\", \"OK\", \"HTTP/1.0\")\n        self.assertEqual(content_length, len(response_body))\n        self.assertEqual(response_body, tobytes(\"abcdefghi\"))\n        # remote does not close connection (keepalive header)\n        self.sock.send(to_send)\n        fp = self.sock.makefile(\"rb\", 0)\n        line, headers, response_body = read_http(fp)\n        self.assertline(line, \"200\", \"OK\", \"HTTP/1.0\")\n\n    def test_no_content_length(self):\n        # wtf happens when there's no content-length\n        to_send = tobytes(\n            \"GET /no_content_length HTTP/1.0\\r\\n\"\n            \"Connection: Keep-Alive\\r\\n\"\n            \"Content-Length: 0\\r\\n\"\n            \"\\r\\n\"\n        )\n        self.connect()\n        self.sock.send(to_send)\n        fp = self.sock.makefile(\"rb\", 0)\n        line = fp.readline()  # status line\n        line, headers, response_body = read_http(fp)\n        content_length = headers.get(\"content-length\")\n        self.assertEqual(content_length, None)\n        self.assertEqual(response_body, tobytes(\"abcdefghi\"))\n        # remote closed connection (despite keepalive header)\n        self.send_check_error(to_send)\n        self.assertRaises(ConnectionClosed, read_http, fp)\n\n\nclass TooLargeTests(object):\n\n    toobig = 1050\n\n    def setUp(self):\n        from waitress.tests.fixtureapps import toolarge\n\n        self.start_subprocess(\n            toolarge.app, max_request_header_size=1000, max_request_body_size=1000\n        )\n\n    def tearDown(self):\n        self.stop_subprocess()\n\n    def test_request_body_too_large_with_wrong_cl_http10(self):\n        body = \"a\" * self.toobig\n        to_send = \"GET / HTTP/1.0\\r\\nContent-Length: 5\\r\\n\\r\\n\"\n        to_send += body\n        to_send = tobytes(to_send)\n        self.connect()\n        self.sock.send(to_send)\n        fp = self.sock.makefile(\"rb\")\n        # first request succeeds (content-length 5)\n        line, headers, response_body = read_http(fp)\n        self.assertline(line, \"200\", \"OK\", \"HTTP/1.0\")\n        cl = int(headers[\"content-length\"])\n        self.assertEqual(cl, len(response_body))\n        # server trusts the content-length header; no pipelining,\n        # so request fulfilled, extra bytes are thrown away\n        # connection has been closed\n        self.send_check_error(to_send)\n        self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_request_body_too_large_with_wrong_cl_http10_keepalive(self):\n        body = \"a\" * self.toobig\n        to_send = \"GET / HTTP/1.0\\r\\nContent-Length: 5\\r\\nConnection: Keep-Alive\\r\\n\\r\\n\"\n        to_send += body\n        to_send = tobytes(to_send)\n        self.connect()\n        self.sock.send(to_send)\n        fp = self.sock.makefile(\"rb\")\n        # first request succeeds (content-length 5)\n        line, headers, response_body = read_http(fp)\n        self.assertline(line, \"200\", \"OK\", \"HTTP/1.0\")\n        cl = int(headers[\"content-length\"])\n        self.assertEqual(cl, len(response_body))\n        line, headers, response_body = read_http(fp)\n        self.assertline(line, \"431\", \"Request Header Fields Too Large\", \"HTTP/1.0\")\n        cl = int(headers[\"content-length\"])\n        self.assertEqual(cl, len(response_body))\n        # connection has been closed\n        self.send_check_error(to_send)\n        self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_request_body_too_large_with_no_cl_http10(self):\n        body = \"a\" * self.toobig\n        to_send = \"GET / HTTP/1.0\\r\\n\\r\\n\"\n        to_send += body\n        to_send = tobytes(to_send)\n        self.connect()\n        self.sock.send(to_send)\n        fp = self.sock.makefile(\"rb\", 0)\n        line, headers, response_body = read_http(fp)\n        self.assertline(line, \"200\", \"OK\", \"HTTP/1.0\")\n        cl = int(headers[\"content-length\"])\n        self.assertEqual(cl, len(response_body))\n        # extra bytes are thrown away (no pipelining), connection closed\n        self.send_check_error(to_send)\n        self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_request_body_too_large_with_no_cl_http10_keepalive(self):\n        body = \"a\" * self.toobig\n        to_send = \"GET / HTTP/1.0\\r\\nConnection: Keep-Alive\\r\\n\\r\\n\"\n        to_send += body\n        to_send = tobytes(to_send)\n        self.connect()\n        self.sock.send(to_send)\n        fp = self.sock.makefile(\"rb\", 0)\n        line, headers, response_body = read_http(fp)\n        # server trusts the content-length header (assumed zero)\n        self.assertline(line, \"200\", \"OK\", \"HTTP/1.0\")\n        cl = int(headers[\"content-length\"])\n        self.assertEqual(cl, len(response_body))\n        line, headers, response_body = read_http(fp)\n        # next response overruns because the extra data appears to be\n        # header data\n        self.assertline(line, \"431\", \"Request Header Fields Too Large\", \"HTTP/1.0\")\n        cl = int(headers[\"content-length\"])\n        self.assertEqual(cl, len(response_body))\n        # connection has been closed\n        self.send_check_error(to_send)\n        self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_request_body_too_large_with_wrong_cl_http11(self):\n        body = \"a\" * self.toobig\n        to_send = \"GET / HTTP/1.1\\r\\nContent-Length: 5\\r\\n\\r\\n\"\n        to_send += body\n        to_send = tobytes(to_send)\n        self.connect()\n        self.sock.send(to_send)\n        fp = self.sock.makefile(\"rb\")\n        # first request succeeds (content-length 5)\n        line, headers, response_body = read_http(fp)\n        self.assertline(line, \"200\", \"OK\", \"HTTP/1.1\")\n        cl = int(headers[\"content-length\"])\n        self.assertEqual(cl, len(response_body))\n        # second response is an error response\n        line, headers, response_body = read_http(fp)\n        self.assertline(line, \"431\", \"Request Header Fields Too Large\", \"HTTP/1.0\")\n        cl = int(headers[\"content-length\"])\n        self.assertEqual(cl, len(response_body))\n        # connection has been closed\n        self.send_check_error(to_send)\n        self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_request_body_too_large_with_wrong_cl_http11_connclose(self):\n        body = \"a\" * self.toobig\n        to_send = \"GET / HTTP/1.1\\r\\nContent-Length: 5\\r\\nConnection: close\\r\\n\\r\\n\"\n        to_send += body\n        to_send = tobytes(to_send)\n        self.connect()\n        self.sock.send(to_send)\n        fp = self.sock.makefile(\"rb\", 0)\n        line, headers, response_body = read_http(fp)\n        # server trusts the content-length header (5)\n        self.assertline(line, \"200\", \"OK\", \"HTTP/1.1\")\n        cl = int(headers[\"content-length\"])\n        self.assertEqual(cl, len(response_body))\n        # connection has been closed\n        self.send_check_error(to_send)\n        self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_request_body_too_large_with_no_cl_http11(self):\n        body = \"a\" * self.toobig\n        to_send = \"GET / HTTP/1.1\\r\\n\\r\\n\"\n        to_send += body\n        to_send = tobytes(to_send)\n        self.connect()\n        self.sock.send(to_send)\n        fp = self.sock.makefile(\"rb\")\n        # server trusts the content-length header (assumed 0)\n        line, headers, response_body = read_http(fp)\n        self.assertline(line, \"200\", \"OK\", \"HTTP/1.1\")\n        cl = int(headers[\"content-length\"])\n        self.assertEqual(cl, len(response_body))\n        # server assumes pipelined requests due to http/1.1, and the first\n        # request was assumed c-l 0 because it had no content-length header,\n        # so entire body looks like the header of the subsequent request\n        # second response is an error response\n        line, headers, response_body = read_http(fp)\n        self.assertline(line, \"431\", \"Request Header Fields Too Large\", \"HTTP/1.0\")\n        cl = int(headers[\"content-length\"])\n        self.assertEqual(cl, len(response_body))\n        # connection has been closed\n        self.send_check_error(to_send)\n        self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_request_body_too_large_with_no_cl_http11_connclose(self):\n        body = \"a\" * self.toobig\n        to_send = \"GET / HTTP/1.1\\r\\nConnection: close\\r\\n\\r\\n\"\n        to_send += body\n        to_send = tobytes(to_send)\n        self.connect()\n        self.sock.send(to_send)\n        fp = self.sock.makefile(\"rb\", 0)\n        line, headers, response_body = read_http(fp)\n        # server trusts the content-length header (assumed 0)\n        self.assertline(line, \"200\", \"OK\", \"HTTP/1.1\")\n        cl = int(headers[\"content-length\"])\n        self.assertEqual(cl, len(response_body))\n        # connection has been closed\n        self.send_check_error(to_send)\n        self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_request_body_too_large_chunked_encoding(self):\n        control_line = \"20;\\r\\n\"  # 20 hex = 32 dec\n        s = \"This string has 32 characters.\\r\\n\"\n        to_send = \"GET / HTTP/1.1\\r\\nTransfer-Encoding: chunked\\r\\n\\r\\n\"\n        repeat = control_line + s\n        to_send += repeat * ((self.toobig // len(repeat)) + 1)\n        to_send = tobytes(to_send)\n        self.connect()\n        self.sock.send(to_send)\n        fp = self.sock.makefile(\"rb\", 0)\n        line, headers, response_body = read_http(fp)\n        # body bytes counter caught a max_request_body_size overrun\n        self.assertline(line, \"413\", \"Request Entity Too Large\", \"HTTP/1.1\")\n        cl = int(headers[\"content-length\"])\n        self.assertEqual(cl, len(response_body))\n        self.assertEqual(headers[\"content-type\"], \"text/plain\")\n        # connection has been closed\n        self.send_check_error(to_send)\n        self.assertRaises(ConnectionClosed, read_http, fp)\n\n\nclass InternalServerErrorTests(object):\n    def setUp(self):\n        from waitress.tests.fixtureapps import error\n\n        self.start_subprocess(error.app, expose_tracebacks=True)\n\n    def tearDown(self):\n        self.stop_subprocess()\n\n    def test_before_start_response_http_10(self):\n        to_send = \"GET /before_start_response HTTP/1.0\\r\\n\\r\\n\"\n        to_send = tobytes(to_send)\n        self.connect()\n        self.sock.send(to_send)\n        fp = self.sock.makefile(\"rb\", 0)\n        line, headers, response_body = read_http(fp)\n        self.assertline(line, \"500\", \"Internal Server Error\", \"HTTP/1.0\")\n        cl = int(headers[\"content-length\"])\n        self.assertEqual(cl, len(response_body))\n        self.assertTrue(response_body.startswith(b\"Internal Server Error\"))\n        self.assertEqual(headers[\"connection\"], \"close\")\n        # connection has been closed\n        self.send_check_error(to_send)\n        self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_before_start_response_http_11(self):\n        to_send = \"GET /before_start_response HTTP/1.1\\r\\n\\r\\n\"\n        to_send = tobytes(to_send)\n        self.connect()\n        self.sock.send(to_send)\n        fp = self.sock.makefile(\"rb\", 0)\n        line, headers, response_body = read_http(fp)\n        self.assertline(line, \"500\", \"Internal Server Error\", \"HTTP/1.1\")\n        cl = int(headers[\"content-length\"])\n        self.assertEqual(cl, len(response_body))\n        self.assertTrue(response_body.startswith(b\"Internal Server Error\"))\n        self.assertEqual(\n            sorted(headers.keys()), [\"connection\", \"content-length\", \"content-type\", \"date\", \"server\"]\n        )\n        # connection has been closed\n        self.send_check_error(to_send)\n        self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_before_start_response_http_11_close(self):\n        to_send = tobytes(\n            \"GET /before_start_response HTTP/1.1\\r\\nConnection: close\\r\\n\\r\\n\"\n        )\n        self.connect()\n        self.sock.send(to_send)\n        fp = self.sock.makefile(\"rb\", 0)\n        line, headers, response_body = read_http(fp)\n        self.assertline(line, \"500\", \"Internal Server Error\", \"HTTP/1.1\")\n        cl = int(headers[\"content-length\"])\n        self.assertEqual(cl, len(response_body))\n        self.assertTrue(response_body.startswith(b\"Internal Server Error\"))\n        self.assertEqual(\n            sorted(headers.keys()),\n            [\"connection\", \"content-length\", \"content-type\", \"date\", \"server\"],\n        )\n        self.assertEqual(headers[\"connection\"], \"close\")\n        # connection has been closed\n        self.send_check_error(to_send)\n        self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_after_start_response_http10(self):\n        to_send = \"GET /after_start_response HTTP/1.0\\r\\n\\r\\n\"\n        to_send = tobytes(to_send)\n        self.connect()\n        self.sock.send(to_send)\n        fp = self.sock.makefile(\"rb\", 0)\n        line, headers, response_body = read_http(fp)\n        self.assertline(line, \"500\", \"Internal Server Error\", \"HTTP/1.0\")\n        cl = int(headers[\"content-length\"])\n        self.assertEqual(cl, len(response_body))\n        self.assertTrue(response_body.startswith(b\"Internal Server Error\"))\n        self.assertEqual(\n            sorted(headers.keys()),\n            [\"connection\", \"content-length\", \"content-type\", \"date\", \"server\"],\n        )\n        self.assertEqual(headers[\"connection\"], \"close\")\n        # connection has been closed\n        self.send_check_error(to_send)\n        self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_after_start_response_http11(self):\n        to_send = \"GET /after_start_response HTTP/1.1\\r\\n\\r\\n\"\n        to_send = tobytes(to_send)\n        self.connect()\n        self.sock.send(to_send)\n        fp = self.sock.makefile(\"rb\", 0)\n        line, headers, response_body = read_http(fp)\n        self.assertline(line, \"500\", \"Internal Server Error\", \"HTTP/1.1\")\n        cl = int(headers[\"content-length\"])\n        self.assertEqual(cl, len(response_body))\n        self.assertTrue(response_body.startswith(b\"Internal Server Error\"))\n        self.assertEqual(\n            sorted(headers.keys()), [\"connection\", \"content-length\", \"content-type\", \"date\", \"server\"]\n        )\n        # connection has been closed\n        self.send_check_error(to_send)\n        self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_after_start_response_http11_close(self):\n        to_send = tobytes(\n            \"GET /after_start_response HTTP/1.1\\r\\nConnection: close\\r\\n\\r\\n\"\n        )\n        self.connect()\n        self.sock.send(to_send)\n        fp = self.sock.makefile(\"rb\", 0)\n        line, headers, response_body = read_http(fp)\n        self.assertline(line, \"500\", \"Internal Server Error\", \"HTTP/1.1\")\n        cl = int(headers[\"content-length\"])\n        self.assertEqual(cl, len(response_body))\n        self.assertTrue(response_body.startswith(b\"Internal Server Error\"))\n        self.assertEqual(\n            sorted(headers.keys()),\n            [\"connection\", \"content-length\", \"content-type\", \"date\", \"server\"],\n        )\n        self.assertEqual(headers[\"connection\"], \"close\")\n        # connection has been closed\n        self.send_check_error(to_send)\n        self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_after_write_cb(self):\n        to_send = \"GET /after_write_cb HTTP/1.1\\r\\n\\r\\n\"\n        to_send = tobytes(to_send)\n        self.connect()\n        self.sock.send(to_send)\n        fp = self.sock.makefile(\"rb\", 0)\n        line, headers, response_body = read_http(fp)\n        self.assertline(line, \"200\", \"OK\", \"HTTP/1.1\")\n        self.assertEqual(response_body, b\"\")\n        # connection has been closed\n        self.send_check_error(to_send)\n        self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_in_generator(self):\n        to_send = \"GET /in_generator HTTP/1.1\\r\\n\\r\\n\"\n        to_send = tobytes(to_send)\n        self.connect()\n        self.sock.send(to_send)\n        fp = self.sock.makefile(\"rb\", 0)\n        line, headers, response_body = read_http(fp)\n        self.assertline(line, \"200\", \"OK\", \"HTTP/1.1\")\n        self.assertEqual(response_body, b\"\")\n        # connection has been closed\n        self.send_check_error(to_send)\n        self.assertRaises(ConnectionClosed, read_http, fp)\n\n\nclass FileWrapperTests(object):\n    def setUp(self):\n        from waitress.tests.fixtureapps import filewrapper\n\n        self.start_subprocess(filewrapper.app)\n\n    def tearDown(self):\n        self.stop_subprocess()\n\n    def test_filelike_http11(self):\n        to_send = \"GET /filelike HTTP/1.1\\r\\n\\r\\n\"\n        to_send = tobytes(to_send)\n\n        self.connect()\n\n        for t in range(0, 2):\n            self.sock.send(to_send)\n            fp = self.sock.makefile(\"rb\", 0)\n            line, headers, response_body = read_http(fp)\n            self.assertline(line, \"200\", \"OK\", \"HTTP/1.1\")\n            cl = int(headers[\"content-length\"])\n            self.assertEqual(cl, len(response_body))\n            ct = headers[\"content-type\"]\n            self.assertEqual(ct, \"image/jpeg\")\n            self.assertTrue(b\"\\377\\330\\377\" in response_body)\n            # connection has not been closed\n\n    def test_filelike_nocl_http11(self):\n        to_send = \"GET /filelike_nocl HTTP/1.1\\r\\n\\r\\n\"\n        to_send = tobytes(to_send)\n\n        self.connect()\n\n        for t in range(0, 2):\n            self.sock.send(to_send)\n            fp = self.sock.makefile(\"rb\", 0)\n            line, headers, response_body = read_http(fp)\n            self.assertline(line, \"200\", \"OK\", \"HTTP/1.1\")\n            cl = int(headers[\"content-length\"])\n            self.assertEqual(cl, len(response_body))\n            ct = headers[\"content-type\"]\n            self.assertEqual(ct, \"image/jpeg\")\n            self.assertTrue(b\"\\377\\330\\377\" in response_body)\n            # connection has not been closed\n\n    def test_filelike_shortcl_http11(self):\n        to_send = \"GET /filelike_shortcl HTTP/1.1\\r\\n\\r\\n\"\n        to_send = tobytes(to_send)\n\n        self.connect()\n\n        for t in range(0, 2):\n            self.sock.send(to_send)\n            fp = self.sock.makefile(\"rb\", 0)\n            line, headers, response_body = read_http(fp)\n            self.assertline(line, \"200\", \"OK\", \"HTTP/1.1\")\n            cl = int(headers[\"content-length\"])\n            self.assertEqual(cl, 1)\n            self.assertEqual(cl, len(response_body))\n            ct = headers[\"content-type\"]\n            self.assertEqual(ct, \"image/jpeg\")\n            self.assertTrue(b\"\\377\" in response_body)\n            # connection has not been closed\n\n    def test_filelike_longcl_http11(self):\n        to_send = \"GET /filelike_longcl HTTP/1.1\\r\\n\\r\\n\"\n        to_send = tobytes(to_send)\n\n        self.connect()\n\n        for t in range(0, 2):\n            self.sock.send(to_send)\n            fp = self.sock.makefile(\"rb\", 0)\n            line, headers, response_body = read_http(fp)\n            self.assertline(line, \"200\", \"OK\", \"HTTP/1.1\")\n            cl = int(headers[\"content-length\"])\n            self.assertEqual(cl, len(response_body))\n            ct = headers[\"content-type\"]\n            self.assertEqual(ct, \"image/jpeg\")\n            self.assertTrue(b\"\\377\\330\\377\" in response_body)\n            # connection has not been closed\n\n    def test_notfilelike_http11(self):\n        to_send = \"GET /notfilelike HTTP/1.1\\r\\n\\r\\n\"\n        to_send = tobytes(to_send)\n\n        self.connect()\n\n        for t in range(0, 2):\n            self.sock.send(to_send)\n            fp = self.sock.makefile(\"rb\", 0)\n            line, headers, response_body = read_http(fp)\n            self.assertline(line, \"200\", \"OK\", \"HTTP/1.1\")\n            cl = int(headers[\"content-length\"])\n            self.assertEqual(cl, len(response_body))\n            ct = headers[\"content-type\"]\n            self.assertEqual(ct, \"image/jpeg\")\n            self.assertTrue(b\"\\377\\330\\377\" in response_body)\n            # connection has not been closed\n\n    def test_notfilelike_iobase_http11(self):\n        to_send = \"GET /notfilelike_iobase HTTP/1.1\\r\\n\\r\\n\"\n        to_send = tobytes(to_send)\n\n        self.connect()\n\n        for t in range(0, 2):\n            self.sock.send(to_send)\n            fp = self.sock.makefile(\"rb\", 0)\n            line, headers, response_body = read_http(fp)\n            self.assertline(line, \"200\", \"OK\", \"HTTP/1.1\")\n            cl = int(headers[\"content-length\"])\n            self.assertEqual(cl, len(response_body))\n            ct = headers[\"content-type\"]\n            self.assertEqual(ct, \"image/jpeg\")\n            self.assertTrue(b\"\\377\\330\\377\" in response_body)\n            # connection has not been closed\n\n    def test_notfilelike_nocl_http11(self):\n        to_send = \"GET /notfilelike_nocl HTTP/1.1\\r\\n\\r\\n\"\n        to_send = tobytes(to_send)\n\n        self.connect()\n\n        self.sock.send(to_send)\n        fp = self.sock.makefile(\"rb\", 0)\n        line, headers, response_body = read_http(fp)\n        self.assertline(line, \"200\", \"OK\", \"HTTP/1.1\")\n        ct = headers[\"content-type\"]\n        self.assertEqual(ct, \"image/jpeg\")\n        self.assertTrue(b\"\\377\\330\\377\" in response_body)\n        # connection has been closed (no content-length)\n        self.send_check_error(to_send)\n        self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_notfilelike_shortcl_http11(self):\n        to_send = \"GET /notfilelike_shortcl HTTP/1.1\\r\\n\\r\\n\"\n        to_send = tobytes(to_send)\n\n        self.connect()\n\n        for t in range(0, 2):\n            self.sock.send(to_send)\n            fp = self.sock.makefile(\"rb\", 0)\n            line, headers, response_body = read_http(fp)\n            self.assertline(line, \"200\", \"OK\", \"HTTP/1.1\")\n            cl = int(headers[\"content-length\"])\n            self.assertEqual(cl, 1)\n            self.assertEqual(cl, len(response_body))\n            ct = headers[\"content-type\"]\n            self.assertEqual(ct, \"image/jpeg\")\n            self.assertTrue(b\"\\377\" in response_body)\n            # connection has not been closed\n\n    def test_notfilelike_longcl_http11(self):\n        to_send = \"GET /notfilelike_longcl HTTP/1.1\\r\\n\\r\\n\"\n        to_send = tobytes(to_send)\n\n        self.connect()\n\n        self.sock.send(to_send)\n        fp = self.sock.makefile(\"rb\", 0)\n        line, headers, response_body = read_http(fp)\n        self.assertline(line, \"200\", \"OK\", \"HTTP/1.1\")\n        cl = int(headers[\"content-length\"])\n        self.assertEqual(cl, len(response_body) + 10)\n        ct = headers[\"content-type\"]\n        self.assertEqual(ct, \"image/jpeg\")\n        self.assertTrue(b\"\\377\\330\\377\" in response_body)\n        # connection has been closed\n        self.send_check_error(to_send)\n        self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_filelike_http10(self):\n        to_send = \"GET /filelike HTTP/1.0\\r\\n\\r\\n\"\n        to_send = tobytes(to_send)\n\n        self.connect()\n\n        self.sock.send(to_send)\n        fp = self.sock.makefile(\"rb\", 0)\n        line, headers, response_body = read_http(fp)\n        self.assertline(line, \"200\", \"OK\", \"HTTP/1.0\")\n        cl = int(headers[\"content-length\"])\n        self.assertEqual(cl, len(response_body))\n        ct = headers[\"content-type\"]\n        self.assertEqual(ct, \"image/jpeg\")\n        self.assertTrue(b\"\\377\\330\\377\" in response_body)\n        # connection has been closed\n        self.send_check_error(to_send)\n        self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_filelike_nocl_http10(self):\n        to_send = \"GET /filelike_nocl HTTP/1.0\\r\\n\\r\\n\"\n        to_send = tobytes(to_send)\n\n        self.connect()\n\n        self.sock.send(to_send)\n        fp = self.sock.makefile(\"rb\", 0)\n        line, headers, response_body = read_http(fp)\n        self.assertline(line, \"200\", \"OK\", \"HTTP/1.0\")\n        cl = int(headers[\"content-length\"])\n        self.assertEqual(cl, len(response_body))\n        ct = headers[\"content-type\"]\n        self.assertEqual(ct, \"image/jpeg\")\n        self.assertTrue(b\"\\377\\330\\377\" in response_body)\n        # connection has been closed\n        self.send_check_error(to_send)\n        self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_notfilelike_http10(self):\n        to_send = \"GET /notfilelike HTTP/1.0\\r\\n\\r\\n\"\n        to_send = tobytes(to_send)\n\n        self.connect()\n\n        self.sock.send(to_send)\n        fp = self.sock.makefile(\"rb\", 0)\n        line, headers, response_body = read_http(fp)\n        self.assertline(line, \"200\", \"OK\", \"HTTP/1.0\")\n        cl = int(headers[\"content-length\"])\n        self.assertEqual(cl, len(response_body))\n        ct = headers[\"content-type\"]\n        self.assertEqual(ct, \"image/jpeg\")\n        self.assertTrue(b\"\\377\\330\\377\" in response_body)\n        # connection has been closed\n        self.send_check_error(to_send)\n        self.assertRaises(ConnectionClosed, read_http, fp)\n\n    def test_notfilelike_nocl_http10(self):\n        to_send = \"GET /notfilelike_nocl HTTP/1.0\\r\\n\\r\\n\"\n        to_send = tobytes(to_send)\n\n        self.connect()\n\n        self.sock.send(to_send)\n        fp = self.sock.makefile(\"rb\", 0)\n        line, headers, response_body = read_http(fp)\n        self.assertline(line, \"200\", \"OK\", \"HTTP/1.0\")\n        ct = headers[\"content-type\"]\n        self.assertEqual(ct, \"image/jpeg\")\n        self.assertTrue(b\"\\377\\330\\377\" in response_body)\n        # connection has been closed (no content-length)\n        self.send_check_error(to_send)\n        self.assertRaises(ConnectionClosed, read_http, fp)\n\n\nclass TcpEchoTests(EchoTests, TcpTests, unittest.TestCase):\n    pass\n\n\nclass TcpPipeliningTests(PipeliningTests, TcpTests, unittest.TestCase):\n    pass\n\n\nclass TcpExpectContinueTests(ExpectContinueTests, TcpTests, unittest.TestCase):\n    pass\n\n\nclass TcpBadContentLengthTests(BadContentLengthTests, TcpTests, unittest.TestCase):\n    pass\n\n\nclass TcpNoContentLengthTests(NoContentLengthTests, TcpTests, unittest.TestCase):\n    pass\n\n\nclass TcpWriteCallbackTests(WriteCallbackTests, TcpTests, unittest.TestCase):\n    pass\n\n\nclass TcpTooLargeTests(TooLargeTests, TcpTests, unittest.TestCase):\n    pass\n\n\nclass TcpInternalServerErrorTests(\n    InternalServerErrorTests, TcpTests, unittest.TestCase\n):\n    pass\n\n\nclass TcpFileWrapperTests(FileWrapperTests, TcpTests, unittest.TestCase):\n    pass\n\n\nif hasattr(socket, \"AF_UNIX\"):\n\n    class FixtureUnixWSGIServer(server.UnixWSGIServer):\n        \"\"\"A version of UnixWSGIServer that relays back what it's bound to.\n        \"\"\"\n\n        family = socket.AF_UNIX  # Testing\n\n        def __init__(self, application, queue, **kw):  # pragma: no cover\n            # Coverage doesn't see this as it's ran in a separate process.\n            # To permit parallel testing, use a PID-dependent socket.\n            kw[\"unix_socket\"] = \"/tmp/waitress.test-%d.sock\" % os.getpid()\n            super(FixtureUnixWSGIServer, self).__init__(application, **kw)\n            queue.put(self.socket.getsockname())\n\n    class UnixTests(SubprocessTests):\n\n        server = FixtureUnixWSGIServer\n\n        def make_http_connection(self):\n            return UnixHTTPConnection(self.bound_to)\n\n        def stop_subprocess(self):\n            super(UnixTests, self).stop_subprocess()\n            cleanup_unix_socket(self.bound_to)\n\n        def send_check_error(self, to_send):\n            # Unlike inet domain sockets, Unix domain sockets can trigger a\n            # 'Broken pipe' error when the socket it closed.\n            try:\n                self.sock.send(to_send)\n            except socket.error as exc:\n                self.assertEqual(get_errno(exc), errno.EPIPE)\n\n    class UnixEchoTests(EchoTests, UnixTests, unittest.TestCase):\n        pass\n\n    class UnixPipeliningTests(PipeliningTests, UnixTests, unittest.TestCase):\n        pass\n\n    class UnixExpectContinueTests(ExpectContinueTests, UnixTests, unittest.TestCase):\n        pass\n\n    class UnixBadContentLengthTests(\n        BadContentLengthTests, UnixTests, unittest.TestCase\n    ):\n        pass\n\n    class UnixNoContentLengthTests(NoContentLengthTests, UnixTests, unittest.TestCase):\n        pass\n\n    class UnixWriteCallbackTests(WriteCallbackTests, UnixTests, unittest.TestCase):\n        pass\n\n    class UnixTooLargeTests(TooLargeTests, UnixTests, unittest.TestCase):\n        pass\n\n    class UnixInternalServerErrorTests(\n        InternalServerErrorTests, UnixTests, unittest.TestCase\n    ):\n        pass\n\n    class UnixFileWrapperTests(FileWrapperTests, UnixTests, unittest.TestCase):\n        pass\n\n\ndef parse_headers(fp):\n    \"\"\"Parses only RFC2822 headers from a file pointer.\n    \"\"\"\n    headers = {}\n    while True:\n        line = fp.readline()\n        if line in (b\"\\r\\n\", b\"\\n\", b\"\"):\n            break\n        line = line.decode(\"iso-8859-1\")\n        name, value = line.strip().split(\":\", 1)\n        headers[name.lower().strip()] = value.lower().strip()\n    return headers\n\n\nclass UnixHTTPConnection(httplib.HTTPConnection):\n    \"\"\"Patched version of HTTPConnection that uses Unix domain sockets.\n    \"\"\"\n\n    def __init__(self, path):\n        httplib.HTTPConnection.__init__(self, \"localhost\")\n        self.path = path\n\n    def connect(self):\n        sock = socket.socket(socket.AF_UNIX, socket.SOCK_STREAM)\n        sock.connect(self.path)\n        self.sock = sock\n\n\nclass ConnectionClosed(Exception):\n    pass\n\n\n# stolen from gevent\ndef read_http(fp):  # pragma: no cover\n    try:\n        response_line = fp.readline()\n    except socket.error as exc:\n        fp.close()\n        # errno 104 is ENOTRECOVERABLE, In WinSock 10054 is ECONNRESET\n        if get_errno(exc) in (errno.ECONNABORTED, errno.ECONNRESET, 104, 10054):\n            raise ConnectionClosed\n        raise\n    if not response_line:\n        raise ConnectionClosed\n\n    header_lines = []\n    while True:\n        line = fp.readline()\n        if line in (b\"\\r\\n\", b\"\\r\\n\", b\"\"):\n            break\n        else:\n            header_lines.append(line)\n    headers = dict()\n    for x in header_lines:\n        x = x.strip()\n        if not x:\n            continue\n        key, value = x.split(b\": \", 1)\n        key = key.decode(\"iso-8859-1\").lower()\n        value = value.decode(\"iso-8859-1\")\n        assert key not in headers, \"%s header duplicated\" % key\n        headers[key] = value\n\n    if \"content-length\" in headers:\n        num = int(headers[\"content-length\"])\n        body = b\"\"\n        left = num\n        while left > 0:\n            data = fp.read(left)\n            if not data:\n                break\n            body += data\n            left -= len(data)\n    else:\n        # read until EOF\n        body = fp.read()\n\n    return response_line, headers, body\n\n\n# stolen from gevent\ndef get_errno(exc):  # pragma: no cover\n    \"\"\" Get the error code out of socket.error objects.\n    socket.error in <2.5 does not have errno attribute\n    socket.error in 3.x does not allow indexing access\n    e.args[0] works for all.\n    There are cases when args[0] is not errno.\n    i.e. http://bugs.python.org/issue6471\n    Maybe there are cases when errno is set, but it is not the first argument?\n    \"\"\"\n    try:\n        if exc.errno is not None:\n            return exc.errno\n    except AttributeError:\n        pass\n    try:\n        return exc.args[0]\n    except IndexError:\n        return None\n\n\ndef chunks(l, n):\n    \"\"\" Yield successive n-sized chunks from l.\n    \"\"\"\n    for i in range(0, len(l), n):\n        yield l[i : i + n]\n", "##############################################################################\n#\n# Copyright (c) 2002 Zope Foundation and Contributors.\n# All Rights Reserved.\n#\n# This software is subject to the provisions of the Zope Public License,\n# Version 2.1 (ZPL).  A copy of the ZPL should accompany this distribution.\n# THIS SOFTWARE IS PROVIDED \"AS IS\" AND ANY AND ALL EXPRESS OR IMPLIED\n# WARRANTIES ARE DISCLAIMED, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\n# WARRANTIES OF TITLE, MERCHANTABILITY, AGAINST INFRINGEMENT, AND FITNESS\n# FOR A PARTICULAR PURPOSE.\n#\n##############################################################################\n\"\"\"HTTP Request Parser tests\n\"\"\"\nimport unittest\n\nfrom waitress.compat import text_, tobytes\n\n\nclass TestHTTPRequestParser(unittest.TestCase):\n    def setUp(self):\n        from waitress.parser import HTTPRequestParser\n        from waitress.adjustments import Adjustments\n\n        my_adj = Adjustments()\n        self.parser = HTTPRequestParser(my_adj)\n\n    def test_get_body_stream_None(self):\n        self.parser.body_recv = None\n        result = self.parser.get_body_stream()\n        self.assertEqual(result.getvalue(), b\"\")\n\n    def test_get_body_stream_nonNone(self):\n        body_rcv = DummyBodyStream()\n        self.parser.body_rcv = body_rcv\n        result = self.parser.get_body_stream()\n        self.assertEqual(result, body_rcv)\n\n    def test_received_get_no_headers(self):\n        data = b\"HTTP/1.0 GET /foobar\\r\\n\\r\\n\"\n        result = self.parser.received(data)\n        self.assertEqual(result, 24)\n        self.assertTrue(self.parser.completed)\n        self.assertEqual(self.parser.headers, {})\n\n    def test_received_bad_host_header(self):\n        from waitress.utilities import BadRequest\n\n        data = b\"HTTP/1.0 GET /foobar\\r\\n Host: foo\\r\\n\\r\\n\"\n        result = self.parser.received(data)\n        self.assertEqual(result, 36)\n        self.assertTrue(self.parser.completed)\n        self.assertEqual(self.parser.error.__class__, BadRequest)\n\n    def test_received_bad_transfer_encoding(self):\n        from waitress.utilities import ServerNotImplemented\n        data = (\n            b\"GET /foobar HTTP/1.1\\r\\n\"\n            b\"Transfer-Encoding: foo\\r\\n\"\n            b\"\\r\\n\"\n            b\"1d;\\r\\n\"\n            b\"This string has 29 characters\\r\\n\"\n            b\"0\\r\\n\\r\\n\"\n        )\n        result = self.parser.received(data)\n        self.assertEqual(result, 48)\n        self.assertTrue(self.parser.completed)\n        self.assertEqual(self.parser.error.__class__, ServerNotImplemented)\n\n    def test_received_nonsense_nothing(self):\n        data = b\"\\r\\n\\r\\n\"\n        result = self.parser.received(data)\n        self.assertEqual(result, 4)\n        self.assertTrue(self.parser.completed)\n        self.assertEqual(self.parser.headers, {})\n\n    def test_received_no_doublecr(self):\n        data = b\"GET /foobar HTTP/8.4\\r\\n\"\n        result = self.parser.received(data)\n        self.assertEqual(result, 22)\n        self.assertFalse(self.parser.completed)\n        self.assertEqual(self.parser.headers, {})\n\n    def test_received_already_completed(self):\n        self.parser.completed = True\n        result = self.parser.received(b\"a\")\n        self.assertEqual(result, 0)\n\n    def test_received_cl_too_large(self):\n        from waitress.utilities import RequestEntityTooLarge\n\n        self.parser.adj.max_request_body_size = 2\n        data = b\"GET /foobar HTTP/8.4\\r\\nContent-Length: 10\\r\\n\\r\\n\"\n        result = self.parser.received(data)\n        self.assertEqual(result, 44)\n        self.assertTrue(self.parser.completed)\n        self.assertTrue(isinstance(self.parser.error, RequestEntityTooLarge))\n\n    def test_received_headers_too_large(self):\n        from waitress.utilities import RequestHeaderFieldsTooLarge\n\n        self.parser.adj.max_request_header_size = 2\n        data = b\"GET /foobar HTTP/8.4\\r\\nX-Foo: 1\\r\\n\\r\\n\"\n        result = self.parser.received(data)\n        self.assertEqual(result, 34)\n        self.assertTrue(self.parser.completed)\n        self.assertTrue(isinstance(self.parser.error, RequestHeaderFieldsTooLarge))\n\n    def test_received_body_too_large(self):\n        from waitress.utilities import RequestEntityTooLarge\n\n        self.parser.adj.max_request_body_size = 2\n        data = (\n            b\"GET /foobar HTTP/1.1\\r\\n\"\n            b\"Transfer-Encoding: chunked\\r\\n\"\n            b\"X-Foo: 1\\r\\n\"\n            b\"\\r\\n\"\n            b\"1d;\\r\\n\"\n            b\"This string has 29 characters\\r\\n\"\n            b\"0\\r\\n\\r\\n\"\n        )\n\n        result = self.parser.received(data)\n        self.assertEqual(result, 62)\n        self.parser.received(data[result:])\n        self.assertTrue(self.parser.completed)\n        self.assertTrue(isinstance(self.parser.error, RequestEntityTooLarge))\n\n    def test_received_error_from_parser(self):\n        from waitress.utilities import BadRequest\n\n        data = (\n            b\"GET /foobar HTTP/1.1\\r\\n\"\n            b\"Transfer-Encoding: chunked\\r\\n\"\n            b\"X-Foo: 1\\r\\n\"\n            b\"\\r\\n\"\n            b\"garbage\\r\\n\"\n        )\n        # header\n        result = self.parser.received(data)\n        # body\n        result = self.parser.received(data[result:])\n        self.assertEqual(result, 9)\n        self.assertTrue(self.parser.completed)\n        self.assertTrue(isinstance(self.parser.error, BadRequest))\n\n    def test_received_chunked_completed_sets_content_length(self):\n        data = (\n            b\"GET /foobar HTTP/1.1\\r\\n\"\n            b\"Transfer-Encoding: chunked\\r\\n\"\n            b\"X-Foo: 1\\r\\n\"\n            b\"\\r\\n\"\n            b\"1d;\\r\\n\"\n            b\"This string has 29 characters\\r\\n\"\n            b\"0\\r\\n\\r\\n\"\n        )\n        result = self.parser.received(data)\n        self.assertEqual(result, 62)\n        data = data[result:]\n        result = self.parser.received(data)\n        self.assertTrue(self.parser.completed)\n        self.assertTrue(self.parser.error is None)\n        self.assertEqual(self.parser.headers[\"CONTENT_LENGTH\"], \"29\")\n\n    def test_parse_header_gardenpath(self):\n        data = b\"GET /foobar HTTP/8.4\\r\\nfoo: bar\\r\\n\"\n        self.parser.parse_header(data)\n        self.assertEqual(self.parser.first_line, b\"GET /foobar HTTP/8.4\")\n        self.assertEqual(self.parser.headers[\"FOO\"], \"bar\")\n\n    def test_parse_header_no_cr_in_headerplus(self):\n        from waitress.parser import ParsingError\n\n        data = b\"GET /foobar HTTP/8.4\"\n\n        try:\n            self.parser.parse_header(data)\n        except ParsingError:\n            pass\n        else:  # pragma: nocover\n            self.assertTrue(False)\n\n    def test_parse_header_bad_content_length(self):\n        from waitress.parser import ParsingError\n\n        data = b\"GET /foobar HTTP/8.4\\r\\ncontent-length: abc\\r\\n\"\n\n        try:\n            self.parser.parse_header(data)\n        except ParsingError as e:\n            self.assertIn(\"Content-Length is invalid\", e.args[0])\n        else:  # pragma: nocover\n            self.assertTrue(False)\n\n    def test_parse_header_multiple_content_length(self):\n        from waitress.parser import ParsingError\n\n        data = b\"GET /foobar HTTP/8.4\\r\\ncontent-length: 10\\r\\ncontent-length: 20\\r\\n\"\n\n        try:\n            self.parser.parse_header(data)\n        except ParsingError as e:\n            self.assertIn(\"Content-Length is invalid\", e.args[0])\n        else:  # pragma: nocover\n            self.assertTrue(False)\n\n    def test_parse_header_11_te_chunked(self):\n        # NB: test that capitalization of header value is unimportant\n        data = b\"GET /foobar HTTP/1.1\\r\\ntransfer-encoding: ChUnKed\\r\\n\"\n        self.parser.parse_header(data)\n        self.assertEqual(self.parser.body_rcv.__class__.__name__, \"ChunkedReceiver\")\n\n\n    def test_parse_header_transfer_encoding_invalid(self):\n        from waitress.parser import TransferEncodingNotImplemented\n\n        data = b\"GET /foobar HTTP/1.1\\r\\ntransfer-encoding: gzip\\r\\n\"\n\n        try:\n            self.parser.parse_header(data)\n        except TransferEncodingNotImplemented as e:\n            self.assertIn(\"Transfer-Encoding requested is not supported.\", e.args[0])\n        else:  # pragma: nocover\n            self.assertTrue(False)\n\n    def test_parse_header_transfer_encoding_invalid_multiple(self):\n        from waitress.parser import TransferEncodingNotImplemented\n\n        data = b\"GET /foobar HTTP/1.1\\r\\ntransfer-encoding: gzip\\r\\ntransfer-encoding: chunked\\r\\n\"\n\n        try:\n            self.parser.parse_header(data)\n        except TransferEncodingNotImplemented as e:\n            self.assertIn(\"Transfer-Encoding requested is not supported.\", e.args[0])\n        else:  # pragma: nocover\n            self.assertTrue(False)\n\n    def test_parse_header_11_expect_continue(self):\n        data = b\"GET /foobar HTTP/1.1\\r\\nexpect: 100-continue\\r\\n\"\n        self.parser.parse_header(data)\n        self.assertEqual(self.parser.expect_continue, True)\n\n    def test_parse_header_connection_close(self):\n        data = b\"GET /foobar HTTP/1.1\\r\\nConnection: close\\r\\n\"\n        self.parser.parse_header(data)\n        self.assertEqual(self.parser.connection_close, True)\n\n    def test_close_with_body_rcv(self):\n        body_rcv = DummyBodyStream()\n        self.parser.body_rcv = body_rcv\n        self.parser.close()\n        self.assertTrue(body_rcv.closed)\n\n    def test_close_with_no_body_rcv(self):\n        self.parser.body_rcv = None\n        self.parser.close()  # doesn't raise\n\n    def test_parse_header_lf_only(self):\n        from waitress.parser import ParsingError\n\n        data = b\"GET /foobar HTTP/8.4\\nfoo: bar\"\n\n        try:\n            self.parser.parse_header(data)\n        except ParsingError:\n            pass\n        else:  # pragma: nocover\n            self.assertTrue(False)\n\n    def test_parse_header_cr_only(self):\n        from waitress.parser import ParsingError\n\n        data = b\"GET /foobar HTTP/8.4\\rfoo: bar\"\n        try:\n            self.parser.parse_header(data)\n        except ParsingError:\n            pass\n        else:  # pragma: nocover\n            self.assertTrue(False)\n\n    def test_parse_header_extra_lf_in_header(self):\n        from waitress.parser import ParsingError\n\n        data = b\"GET /foobar HTTP/8.4\\r\\nfoo: \\nbar\\r\\n\"\n        try:\n            self.parser.parse_header(data)\n        except ParsingError as e:\n            self.assertIn(\"Bare CR or LF found in header line\", e.args[0])\n        else:  # pragma: nocover\n            self.assertTrue(False)\n\n    def test_parse_header_extra_lf_in_first_line(self):\n        from waitress.parser import ParsingError\n\n        data = b\"GET /foobar\\n HTTP/8.4\\r\\n\"\n        try:\n            self.parser.parse_header(data)\n        except ParsingError as e:\n            self.assertIn(\"Bare CR or LF found in HTTP message\", e.args[0])\n        else:  # pragma: nocover\n            self.assertTrue(False)\n\n    def test_parse_header_invalid_whitespace(self):\n        from waitress.parser import ParsingError\n\n        data = b\"GET /foobar HTTP/8.4\\r\\nfoo : bar\\r\\n\"\n        try:\n            self.parser.parse_header(data)\n        except ParsingError as e:\n            self.assertIn(\"Invalid whitespace after field-name\", e.args[0])\n        else:  # pragma: nocover\n            self.assertTrue(False)\n\n\nclass Test_split_uri(unittest.TestCase):\n    def _callFUT(self, uri):\n        from waitress.parser import split_uri\n\n        (\n            self.proxy_scheme,\n            self.proxy_netloc,\n            self.path,\n            self.query,\n            self.fragment,\n        ) = split_uri(uri)\n\n    def test_split_uri_unquoting_unneeded(self):\n        self._callFUT(b\"http://localhost:8080/abc def\")\n        self.assertEqual(self.path, \"/abc def\")\n\n    def test_split_uri_unquoting_needed(self):\n        self._callFUT(b\"http://localhost:8080/abc%20def\")\n        self.assertEqual(self.path, \"/abc def\")\n\n    def test_split_url_with_query(self):\n        self._callFUT(b\"http://localhost:8080/abc?a=1&b=2\")\n        self.assertEqual(self.path, \"/abc\")\n        self.assertEqual(self.query, \"a=1&b=2\")\n\n    def test_split_url_with_query_empty(self):\n        self._callFUT(b\"http://localhost:8080/abc?\")\n        self.assertEqual(self.path, \"/abc\")\n        self.assertEqual(self.query, \"\")\n\n    def test_split_url_with_fragment(self):\n        self._callFUT(b\"http://localhost:8080/#foo\")\n        self.assertEqual(self.path, \"/\")\n        self.assertEqual(self.fragment, \"foo\")\n\n    def test_split_url_https(self):\n        self._callFUT(b\"https://localhost:8080/\")\n        self.assertEqual(self.path, \"/\")\n        self.assertEqual(self.proxy_scheme, \"https\")\n        self.assertEqual(self.proxy_netloc, \"localhost:8080\")\n\n    def test_split_uri_unicode_error_raises_parsing_error(self):\n        # See https://github.com/Pylons/waitress/issues/64\n        from waitress.parser import ParsingError\n\n        # Either pass or throw a ParsingError, just don't throw another type of\n        # exception as that will cause the connection to close badly:\n        try:\n            self._callFUT(b\"/\\xd0\")\n        except ParsingError:\n            pass\n\n    def test_split_uri_path(self):\n        self._callFUT(b\"//testing/whatever\")\n        self.assertEqual(self.path, \"//testing/whatever\")\n        self.assertEqual(self.proxy_scheme, \"\")\n        self.assertEqual(self.proxy_netloc, \"\")\n        self.assertEqual(self.query, \"\")\n        self.assertEqual(self.fragment, \"\")\n\n    def test_split_uri_path_query(self):\n        self._callFUT(b\"//testing/whatever?a=1&b=2\")\n        self.assertEqual(self.path, \"//testing/whatever\")\n        self.assertEqual(self.proxy_scheme, \"\")\n        self.assertEqual(self.proxy_netloc, \"\")\n        self.assertEqual(self.query, \"a=1&b=2\")\n        self.assertEqual(self.fragment, \"\")\n\n    def test_split_uri_path_query_fragment(self):\n        self._callFUT(b\"//testing/whatever?a=1&b=2#fragment\")\n        self.assertEqual(self.path, \"//testing/whatever\")\n        self.assertEqual(self.proxy_scheme, \"\")\n        self.assertEqual(self.proxy_netloc, \"\")\n        self.assertEqual(self.query, \"a=1&b=2\")\n        self.assertEqual(self.fragment, \"fragment\")\n\n\nclass Test_get_header_lines(unittest.TestCase):\n    def _callFUT(self, data):\n        from waitress.parser import get_header_lines\n\n        return get_header_lines(data)\n\n    def test_get_header_lines(self):\n        result = self._callFUT(b\"slam\\r\\nslim\")\n        self.assertEqual(result, [b\"slam\", b\"slim\"])\n\n    def test_get_header_lines_folded(self):\n        # From RFC2616:\n        # HTTP/1.1 header field values can be folded onto multiple lines if the\n        # continuation line begins with a space or horizontal tab. All linear\n        # white space, including folding, has the same semantics as SP. A\n        # recipient MAY replace any linear white space with a single SP before\n        # interpreting the field value or forwarding the message downstream.\n\n        # We are just preserving the whitespace that indicates folding.\n        result = self._callFUT(b\"slim\\r\\n slam\")\n        self.assertEqual(result, [b\"slim slam\"])\n\n    def test_get_header_lines_tabbed(self):\n        result = self._callFUT(b\"slam\\r\\n\\tslim\")\n        self.assertEqual(result, [b\"slam\\tslim\"])\n\n    def test_get_header_lines_malformed(self):\n        # https://corte.si/posts/code/pathod/pythonservers/index.html\n        from waitress.parser import ParsingError\n\n        self.assertRaises(ParsingError, self._callFUT, b\" Host: localhost\\r\\n\\r\\n\")\n\n\nclass Test_crack_first_line(unittest.TestCase):\n    def _callFUT(self, line):\n        from waitress.parser import crack_first_line\n\n        return crack_first_line(line)\n\n    def test_crack_first_line_matchok(self):\n        result = self._callFUT(b\"GET / HTTP/1.0\")\n        self.assertEqual(result, (b\"GET\", b\"/\", b\"1.0\"))\n\n    def test_crack_first_line_lowercase_method(self):\n        from waitress.parser import ParsingError\n\n        self.assertRaises(ParsingError, self._callFUT, b\"get / HTTP/1.0\")\n\n    def test_crack_first_line_nomatch(self):\n        result = self._callFUT(b\"GET / bleh\")\n        self.assertEqual(result, (b\"\", b\"\", b\"\"))\n\n        result = self._callFUT(b\"GET /info?txtAirPlay&txtRAOP RTSP/1.0\")\n        self.assertEqual(result, (b\"\", b\"\", b\"\"))\n\n    def test_crack_first_line_missing_version(self):\n        result = self._callFUT(b\"GET /\")\n        self.assertEqual(result, (b\"GET\", b\"/\", b\"\"))\n\n\nclass TestHTTPRequestParserIntegration(unittest.TestCase):\n    def setUp(self):\n        from waitress.parser import HTTPRequestParser\n        from waitress.adjustments import Adjustments\n\n        my_adj = Adjustments()\n        self.parser = HTTPRequestParser(my_adj)\n\n    def feed(self, data):\n        parser = self.parser\n\n        for n in range(100):  # make sure we never loop forever\n            consumed = parser.received(data)\n            data = data[consumed:]\n\n            if parser.completed:\n                return\n        raise ValueError(\"Looping\")  # pragma: no cover\n\n    def testSimpleGET(self):\n        data = (\n            b\"GET /foobar HTTP/8.4\\r\\n\"\n            b\"FirstName: mickey\\r\\n\"\n            b\"lastname: Mouse\\r\\n\"\n            b\"content-length: 6\\r\\n\"\n            b\"\\r\\n\"\n            b\"Hello.\"\n        )\n        parser = self.parser\n        self.feed(data)\n        self.assertTrue(parser.completed)\n        self.assertEqual(parser.version, \"8.4\")\n        self.assertFalse(parser.empty)\n        self.assertEqual(\n            parser.headers,\n            {\"FIRSTNAME\": \"mickey\", \"LASTNAME\": \"Mouse\", \"CONTENT_LENGTH\": \"6\",},\n        )\n        self.assertEqual(parser.path, \"/foobar\")\n        self.assertEqual(parser.command, \"GET\")\n        self.assertEqual(parser.query, \"\")\n        self.assertEqual(parser.proxy_scheme, \"\")\n        self.assertEqual(parser.proxy_netloc, \"\")\n        self.assertEqual(parser.get_body_stream().getvalue(), b\"Hello.\")\n\n    def testComplexGET(self):\n        data = (\n            b\"GET /foo/a+%2B%2F%C3%A4%3D%26a%3Aint?d=b+%2B%2F%3D%26b%3Aint&c+%2B%2F%3D%26c%3Aint=6 HTTP/8.4\\r\\n\"\n            b\"FirstName: mickey\\r\\n\"\n            b\"lastname: Mouse\\r\\n\"\n            b\"content-length: 10\\r\\n\"\n            b\"\\r\\n\"\n            b\"Hello mickey.\"\n        )\n        parser = self.parser\n        self.feed(data)\n        self.assertEqual(parser.command, \"GET\")\n        self.assertEqual(parser.version, \"8.4\")\n        self.assertFalse(parser.empty)\n        self.assertEqual(\n            parser.headers,\n            {\"FIRSTNAME\": \"mickey\", \"LASTNAME\": \"Mouse\", \"CONTENT_LENGTH\": \"10\"},\n        )\n        # path should be utf-8 encoded\n        self.assertEqual(\n            tobytes(parser.path).decode(\"utf-8\"),\n            text_(b\"/foo/a++/\\xc3\\xa4=&a:int\", \"utf-8\"),\n        )\n        self.assertEqual(\n            parser.query, \"d=b+%2B%2F%3D%26b%3Aint&c+%2B%2F%3D%26c%3Aint=6\"\n        )\n        self.assertEqual(parser.get_body_stream().getvalue(), b\"Hello mick\")\n\n    def testProxyGET(self):\n        data = (\n            b\"GET https://example.com:8080/foobar HTTP/8.4\\r\\n\"\n            b\"content-length: 6\\r\\n\"\n            b\"\\r\\n\"\n            b\"Hello.\"\n        )\n        parser = self.parser\n        self.feed(data)\n        self.assertTrue(parser.completed)\n        self.assertEqual(parser.version, \"8.4\")\n        self.assertFalse(parser.empty)\n        self.assertEqual(parser.headers, {\"CONTENT_LENGTH\": \"6\"})\n        self.assertEqual(parser.path, \"/foobar\")\n        self.assertEqual(parser.command, \"GET\")\n        self.assertEqual(parser.proxy_scheme, \"https\")\n        self.assertEqual(parser.proxy_netloc, \"example.com:8080\")\n        self.assertEqual(parser.command, \"GET\")\n        self.assertEqual(parser.query, \"\")\n        self.assertEqual(parser.get_body_stream().getvalue(), b\"Hello.\")\n\n    def testDuplicateHeaders(self):\n        # Ensure that headers with the same key get concatenated as per\n        # RFC2616.\n        data = (\n            b\"GET /foobar HTTP/8.4\\r\\n\"\n            b\"x-forwarded-for: 10.11.12.13\\r\\n\"\n            b\"x-forwarded-for: unknown,127.0.0.1\\r\\n\"\n            b\"X-Forwarded_for: 255.255.255.255\\r\\n\"\n            b\"content-length: 6\\r\\n\"\n            b\"\\r\\n\"\n            b\"Hello.\"\n        )\n        self.feed(data)\n        self.assertTrue(self.parser.completed)\n        self.assertEqual(\n            self.parser.headers,\n            {\n                \"CONTENT_LENGTH\": \"6\",\n                \"X_FORWARDED_FOR\": \"10.11.12.13, unknown,127.0.0.1\",\n            },\n        )\n\n    def testSpoofedHeadersDropped(self):\n        data = (\n            b\"GET /foobar HTTP/8.4\\r\\n\"\n            b\"x-auth_user: bob\\r\\n\"\n            b\"content-length: 6\\r\\n\"\n            b\"\\r\\n\"\n            b\"Hello.\"\n        )\n        self.feed(data)\n        self.assertTrue(self.parser.completed)\n        self.assertEqual(self.parser.headers, {\"CONTENT_LENGTH\": \"6\",})\n\n\nclass DummyBodyStream(object):\n    def getfile(self):\n        return self\n\n    def getbuf(self):\n        return self\n\n    def close(self):\n        self.closed = True\n", "import unittest\n\n\nclass TestFixedStreamReceiver(unittest.TestCase):\n    def _makeOne(self, cl, buf):\n        from waitress.receiver import FixedStreamReceiver\n\n        return FixedStreamReceiver(cl, buf)\n\n    def test_received_remain_lt_1(self):\n        buf = DummyBuffer()\n        inst = self._makeOne(0, buf)\n        result = inst.received(\"a\")\n        self.assertEqual(result, 0)\n        self.assertEqual(inst.completed, True)\n\n    def test_received_remain_lte_datalen(self):\n        buf = DummyBuffer()\n        inst = self._makeOne(1, buf)\n        result = inst.received(\"aa\")\n        self.assertEqual(result, 1)\n        self.assertEqual(inst.completed, True)\n        self.assertEqual(inst.completed, 1)\n        self.assertEqual(inst.remain, 0)\n        self.assertEqual(buf.data, [\"a\"])\n\n    def test_received_remain_gt_datalen(self):\n        buf = DummyBuffer()\n        inst = self._makeOne(10, buf)\n        result = inst.received(\"aa\")\n        self.assertEqual(result, 2)\n        self.assertEqual(inst.completed, False)\n        self.assertEqual(inst.remain, 8)\n        self.assertEqual(buf.data, [\"aa\"])\n\n    def test_getfile(self):\n        buf = DummyBuffer()\n        inst = self._makeOne(10, buf)\n        self.assertEqual(inst.getfile(), buf)\n\n    def test_getbuf(self):\n        buf = DummyBuffer()\n        inst = self._makeOne(10, buf)\n        self.assertEqual(inst.getbuf(), buf)\n\n    def test___len__(self):\n        buf = DummyBuffer([\"1\", \"2\"])\n        inst = self._makeOne(10, buf)\n        self.assertEqual(inst.__len__(), 2)\n\n\nclass TestChunkedReceiver(unittest.TestCase):\n    def _makeOne(self, buf):\n        from waitress.receiver import ChunkedReceiver\n\n        return ChunkedReceiver(buf)\n\n    def test_alreadycompleted(self):\n        buf = DummyBuffer()\n        inst = self._makeOne(buf)\n        inst.completed = True\n        result = inst.received(b\"a\")\n        self.assertEqual(result, 0)\n        self.assertEqual(inst.completed, True)\n\n    def test_received_remain_gt_zero(self):\n        buf = DummyBuffer()\n        inst = self._makeOne(buf)\n        inst.chunk_remainder = 100\n        result = inst.received(b\"a\")\n        self.assertEqual(inst.chunk_remainder, 99)\n        self.assertEqual(result, 1)\n        self.assertEqual(inst.completed, False)\n\n    def test_received_control_line_notfinished(self):\n        buf = DummyBuffer()\n        inst = self._makeOne(buf)\n        result = inst.received(b\"a\")\n        self.assertEqual(inst.control_line, b\"a\")\n        self.assertEqual(result, 1)\n        self.assertEqual(inst.completed, False)\n\n    def test_received_control_line_finished_garbage_in_input(self):\n        buf = DummyBuffer()\n        inst = self._makeOne(buf)\n        result = inst.received(b\"garbage\\r\\n\")\n        self.assertEqual(result, 9)\n        self.assertTrue(inst.error)\n\n    def test_received_control_line_finished_all_chunks_not_received(self):\n        buf = DummyBuffer()\n        inst = self._makeOne(buf)\n        result = inst.received(b\"a;discard\\r\\n\")\n        self.assertEqual(inst.control_line, b\"\")\n        self.assertEqual(inst.chunk_remainder, 10)\n        self.assertEqual(inst.all_chunks_received, False)\n        self.assertEqual(result, 11)\n        self.assertEqual(inst.completed, False)\n\n    def test_received_control_line_finished_all_chunks_received(self):\n        buf = DummyBuffer()\n        inst = self._makeOne(buf)\n        result = inst.received(b\"0;discard\\r\\n\")\n        self.assertEqual(inst.control_line, b\"\")\n        self.assertEqual(inst.all_chunks_received, True)\n        self.assertEqual(result, 11)\n        self.assertEqual(inst.completed, False)\n\n    def test_received_trailer_startswith_crlf(self):\n        buf = DummyBuffer()\n        inst = self._makeOne(buf)\n        inst.all_chunks_received = True\n        result = inst.received(b\"\\r\\n\")\n        self.assertEqual(result, 2)\n        self.assertEqual(inst.completed, True)\n\n    def test_received_trailer_startswith_lf(self):\n        buf = DummyBuffer()\n        inst = self._makeOne(buf)\n        inst.all_chunks_received = True\n        result = inst.received(b\"\\n\")\n        self.assertEqual(result, 1)\n        self.assertEqual(inst.completed, False)\n\n    def test_received_trailer_not_finished(self):\n        buf = DummyBuffer()\n        inst = self._makeOne(buf)\n        inst.all_chunks_received = True\n        result = inst.received(b\"a\")\n        self.assertEqual(result, 1)\n        self.assertEqual(inst.completed, False)\n\n    def test_received_trailer_finished(self):\n        buf = DummyBuffer()\n        inst = self._makeOne(buf)\n        inst.all_chunks_received = True\n        result = inst.received(b\"abc\\r\\n\\r\\n\")\n        self.assertEqual(inst.trailer, b\"abc\\r\\n\\r\\n\")\n        self.assertEqual(result, 7)\n        self.assertEqual(inst.completed, True)\n\n    def test_getfile(self):\n        buf = DummyBuffer()\n        inst = self._makeOne(buf)\n        self.assertEqual(inst.getfile(), buf)\n\n    def test_getbuf(self):\n        buf = DummyBuffer()\n        inst = self._makeOne(buf)\n        self.assertEqual(inst.getbuf(), buf)\n\n    def test___len__(self):\n        buf = DummyBuffer([\"1\", \"2\"])\n        inst = self._makeOne(buf)\n        self.assertEqual(inst.__len__(), 2)\n\n    def test_received_chunk_is_properly_terminated(self):\n        buf = DummyBuffer()\n        inst = self._makeOne(buf)\n        data = b\"4\\r\\nWiki\\r\\n\"\n        result = inst.received(data)\n        self.assertEqual(result, len(data))\n        self.assertEqual(inst.completed, False)\n        self.assertEqual(buf.data[0], b\"Wiki\")\n\n    def test_received_chunk_not_properly_terminated(self):\n        from waitress.utilities import BadRequest\n\n        buf = DummyBuffer()\n        inst = self._makeOne(buf)\n        data = b\"4\\r\\nWikibadchunk\\r\\n\"\n        result = inst.received(data)\n        self.assertEqual(result, len(data))\n        self.assertEqual(inst.completed, False)\n        self.assertEqual(buf.data[0], b\"Wiki\")\n        self.assertEqual(inst.error.__class__, BadRequest)\n\n    def test_received_multiple_chunks(self):\n        from waitress.utilities import BadRequest\n\n        buf = DummyBuffer()\n        inst = self._makeOne(buf)\n        data = (\n            b\"4\\r\\n\"\n            b\"Wiki\\r\\n\"\n            b\"5\\r\\n\"\n            b\"pedia\\r\\n\"\n            b\"E\\r\\n\"\n            b\" in\\r\\n\"\n            b\"\\r\\n\"\n            b\"chunks.\\r\\n\"\n            b\"0\\r\\n\"\n            b\"\\r\\n\"\n        )\n        result = inst.received(data)\n        self.assertEqual(result, len(data))\n        self.assertEqual(inst.completed, True)\n        self.assertEqual(b\"\".join(buf.data), b\"Wikipedia in\\r\\n\\r\\nchunks.\")\n        self.assertEqual(inst.error, None)\n\n    def test_received_multiple_chunks_split(self):\n        from waitress.utilities import BadRequest\n\n        buf = DummyBuffer()\n        inst = self._makeOne(buf)\n        data1 = b\"4\\r\\nWiki\\r\"\n        result = inst.received(data1)\n        self.assertEqual(result, len(data1))\n\n        data2 = (\n            b\"\\n5\\r\\n\"\n            b\"pedia\\r\\n\"\n            b\"E\\r\\n\"\n            b\" in\\r\\n\"\n            b\"\\r\\n\"\n            b\"chunks.\\r\\n\"\n            b\"0\\r\\n\"\n            b\"\\r\\n\"\n        )\n\n        result = inst.received(data2)\n        self.assertEqual(result, len(data2))\n\n        self.assertEqual(inst.completed, True)\n        self.assertEqual(b\"\".join(buf.data), b\"Wikipedia in\\r\\n\\r\\nchunks.\")\n        self.assertEqual(inst.error, None)\n\n\nclass DummyBuffer(object):\n    def __init__(self, data=None):\n        if data is None:\n            data = []\n        self.data = data\n\n    def append(self, s):\n        self.data.append(s)\n\n    def getfile(self):\n        return self\n\n    def __len__(self):\n        return len(self.data)\n", "import unittest\nimport io\n\n\nclass TestThreadedTaskDispatcher(unittest.TestCase):\n    def _makeOne(self):\n        from waitress.task import ThreadedTaskDispatcher\n\n        return ThreadedTaskDispatcher()\n\n    def test_handler_thread_task_raises(self):\n        inst = self._makeOne()\n        inst.threads.add(0)\n        inst.logger = DummyLogger()\n\n        class BadDummyTask(DummyTask):\n            def service(self):\n                super(BadDummyTask, self).service()\n                inst.stop_count += 1\n                raise Exception\n\n        task = BadDummyTask()\n        inst.logger = DummyLogger()\n        inst.queue.append(task)\n        inst.active_count += 1\n        inst.handler_thread(0)\n        self.assertEqual(inst.stop_count, 0)\n        self.assertEqual(inst.active_count, 0)\n        self.assertEqual(inst.threads, set())\n        self.assertEqual(len(inst.logger.logged), 1)\n\n    def test_set_thread_count_increase(self):\n        inst = self._makeOne()\n        L = []\n        inst.start_new_thread = lambda *x: L.append(x)\n        inst.set_thread_count(1)\n        self.assertEqual(L, [(inst.handler_thread, (0,))])\n\n    def test_set_thread_count_increase_with_existing(self):\n        inst = self._makeOne()\n        L = []\n        inst.threads = {0}\n        inst.start_new_thread = lambda *x: L.append(x)\n        inst.set_thread_count(2)\n        self.assertEqual(L, [(inst.handler_thread, (1,))])\n\n    def test_set_thread_count_decrease(self):\n        inst = self._makeOne()\n        inst.threads = {0, 1}\n        inst.set_thread_count(1)\n        self.assertEqual(inst.stop_count, 1)\n\n    def test_set_thread_count_same(self):\n        inst = self._makeOne()\n        L = []\n        inst.start_new_thread = lambda *x: L.append(x)\n        inst.threads = {0}\n        inst.set_thread_count(1)\n        self.assertEqual(L, [])\n\n    def test_add_task_with_idle_threads(self):\n        task = DummyTask()\n        inst = self._makeOne()\n        inst.threads.add(0)\n        inst.queue_logger = DummyLogger()\n        inst.add_task(task)\n        self.assertEqual(len(inst.queue), 1)\n        self.assertEqual(len(inst.queue_logger.logged), 0)\n\n    def test_add_task_with_all_busy_threads(self):\n        task = DummyTask()\n        inst = self._makeOne()\n        inst.queue_logger = DummyLogger()\n        inst.add_task(task)\n        self.assertEqual(len(inst.queue_logger.logged), 1)\n        inst.add_task(task)\n        self.assertEqual(len(inst.queue_logger.logged), 2)\n\n    def test_shutdown_one_thread(self):\n        inst = self._makeOne()\n        inst.threads.add(0)\n        inst.logger = DummyLogger()\n        task = DummyTask()\n        inst.queue.append(task)\n        self.assertEqual(inst.shutdown(timeout=0.01), True)\n        self.assertEqual(\n            inst.logger.logged,\n            [\"1 thread(s) still running\", \"Canceling 1 pending task(s)\",],\n        )\n        self.assertEqual(task.cancelled, True)\n\n    def test_shutdown_no_threads(self):\n        inst = self._makeOne()\n        self.assertEqual(inst.shutdown(timeout=0.01), True)\n\n    def test_shutdown_no_cancel_pending(self):\n        inst = self._makeOne()\n        self.assertEqual(inst.shutdown(cancel_pending=False, timeout=0.01), False)\n\n\nclass TestTask(unittest.TestCase):\n    def _makeOne(self, channel=None, request=None):\n        if channel is None:\n            channel = DummyChannel()\n        if request is None:\n            request = DummyParser()\n        from waitress.task import Task\n\n        return Task(channel, request)\n\n    def test_ctor_version_not_in_known(self):\n        request = DummyParser()\n        request.version = \"8.4\"\n        inst = self._makeOne(request=request)\n        self.assertEqual(inst.version, \"1.0\")\n\n    def test_build_response_header_bad_http_version(self):\n        inst = self._makeOne()\n        inst.request = DummyParser()\n        inst.version = \"8.4\"\n        self.assertRaises(AssertionError, inst.build_response_header)\n\n    def test_build_response_header_v10_keepalive_no_content_length(self):\n        inst = self._makeOne()\n        inst.request = DummyParser()\n        inst.request.headers[\"CONNECTION\"] = \"keep-alive\"\n        inst.version = \"1.0\"\n        result = inst.build_response_header()\n        lines = filter_lines(result)\n        self.assertEqual(len(lines), 4)\n        self.assertEqual(lines[0], b\"HTTP/1.0 200 OK\")\n        self.assertEqual(lines[1], b\"Connection: close\")\n        self.assertTrue(lines[2].startswith(b\"Date:\"))\n        self.assertEqual(lines[3], b\"Server: waitress\")\n        self.assertEqual(inst.close_on_finish, True)\n        self.assertTrue((\"Connection\", \"close\") in inst.response_headers)\n\n    def test_build_response_header_v10_keepalive_with_content_length(self):\n        inst = self._makeOne()\n        inst.request = DummyParser()\n        inst.request.headers[\"CONNECTION\"] = \"keep-alive\"\n        inst.response_headers = [(\"Content-Length\", \"10\")]\n        inst.version = \"1.0\"\n        inst.content_length = 0\n        result = inst.build_response_header()\n        lines = filter_lines(result)\n        self.assertEqual(len(lines), 5)\n        self.assertEqual(lines[0], b\"HTTP/1.0 200 OK\")\n        self.assertEqual(lines[1], b\"Connection: Keep-Alive\")\n        self.assertEqual(lines[2], b\"Content-Length: 10\")\n        self.assertTrue(lines[3].startswith(b\"Date:\"))\n        self.assertEqual(lines[4], b\"Server: waitress\")\n        self.assertEqual(inst.close_on_finish, False)\n\n    def test_build_response_header_v11_connection_closed_by_client(self):\n        inst = self._makeOne()\n        inst.request = DummyParser()\n        inst.version = \"1.1\"\n        inst.request.headers[\"CONNECTION\"] = \"close\"\n        result = inst.build_response_header()\n        lines = filter_lines(result)\n        self.assertEqual(len(lines), 5)\n        self.assertEqual(lines[0], b\"HTTP/1.1 200 OK\")\n        self.assertEqual(lines[1], b\"Connection: close\")\n        self.assertTrue(lines[2].startswith(b\"Date:\"))\n        self.assertEqual(lines[3], b\"Server: waitress\")\n        self.assertEqual(lines[4], b\"Transfer-Encoding: chunked\")\n        self.assertTrue((\"Connection\", \"close\") in inst.response_headers)\n        self.assertEqual(inst.close_on_finish, True)\n\n    def test_build_response_header_v11_connection_keepalive_by_client(self):\n        inst = self._makeOne()\n        inst.request = DummyParser()\n        inst.request.headers[\"CONNECTION\"] = \"keep-alive\"\n        inst.version = \"1.1\"\n        result = inst.build_response_header()\n        lines = filter_lines(result)\n        self.assertEqual(len(lines), 5)\n        self.assertEqual(lines[0], b\"HTTP/1.1 200 OK\")\n        self.assertEqual(lines[1], b\"Connection: close\")\n        self.assertTrue(lines[2].startswith(b\"Date:\"))\n        self.assertEqual(lines[3], b\"Server: waitress\")\n        self.assertEqual(lines[4], b\"Transfer-Encoding: chunked\")\n        self.assertTrue((\"Connection\", \"close\") in inst.response_headers)\n        self.assertEqual(inst.close_on_finish, True)\n\n    def test_build_response_header_v11_200_no_content_length(self):\n        inst = self._makeOne()\n        inst.request = DummyParser()\n        inst.version = \"1.1\"\n        result = inst.build_response_header()\n        lines = filter_lines(result)\n        self.assertEqual(len(lines), 5)\n        self.assertEqual(lines[0], b\"HTTP/1.1 200 OK\")\n        self.assertEqual(lines[1], b\"Connection: close\")\n        self.assertTrue(lines[2].startswith(b\"Date:\"))\n        self.assertEqual(lines[3], b\"Server: waitress\")\n        self.assertEqual(lines[4], b\"Transfer-Encoding: chunked\")\n        self.assertEqual(inst.close_on_finish, True)\n        self.assertTrue((\"Connection\", \"close\") in inst.response_headers)\n\n    def test_build_response_header_v11_204_no_content_length_or_transfer_encoding(self):\n        # RFC 7230: MUST NOT send Transfer-Encoding or Content-Length\n        # for any response with a status code of 1xx or 204.\n        inst = self._makeOne()\n        inst.request = DummyParser()\n        inst.version = \"1.1\"\n        inst.status = \"204 No Content\"\n        result = inst.build_response_header()\n        lines = filter_lines(result)\n        self.assertEqual(len(lines), 4)\n        self.assertEqual(lines[0], b\"HTTP/1.1 204 No Content\")\n        self.assertEqual(lines[1], b\"Connection: close\")\n        self.assertTrue(lines[2].startswith(b\"Date:\"))\n        self.assertEqual(lines[3], b\"Server: waitress\")\n        self.assertEqual(inst.close_on_finish, True)\n        self.assertTrue((\"Connection\", \"close\") in inst.response_headers)\n\n    def test_build_response_header_v11_1xx_no_content_length_or_transfer_encoding(self):\n        # RFC 7230: MUST NOT send Transfer-Encoding or Content-Length\n        # for any response with a status code of 1xx or 204.\n        inst = self._makeOne()\n        inst.request = DummyParser()\n        inst.version = \"1.1\"\n        inst.status = \"100 Continue\"\n        result = inst.build_response_header()\n        lines = filter_lines(result)\n        self.assertEqual(len(lines), 4)\n        self.assertEqual(lines[0], b\"HTTP/1.1 100 Continue\")\n        self.assertEqual(lines[1], b\"Connection: close\")\n        self.assertTrue(lines[2].startswith(b\"Date:\"))\n        self.assertEqual(lines[3], b\"Server: waitress\")\n        self.assertEqual(inst.close_on_finish, True)\n        self.assertTrue((\"Connection\", \"close\") in inst.response_headers)\n\n    def test_build_response_header_v11_304_no_content_length_or_transfer_encoding(self):\n        # RFC 7230: MUST NOT send Transfer-Encoding or Content-Length\n        # for any response with a status code of 1xx, 204 or 304.\n        inst = self._makeOne()\n        inst.request = DummyParser()\n        inst.version = \"1.1\"\n        inst.status = \"304 Not Modified\"\n        result = inst.build_response_header()\n        lines = filter_lines(result)\n        self.assertEqual(len(lines), 4)\n        self.assertEqual(lines[0], b\"HTTP/1.1 304 Not Modified\")\n        self.assertEqual(lines[1], b\"Connection: close\")\n        self.assertTrue(lines[2].startswith(b\"Date:\"))\n        self.assertEqual(lines[3], b\"Server: waitress\")\n        self.assertEqual(inst.close_on_finish, True)\n        self.assertTrue((\"Connection\", \"close\") in inst.response_headers)\n\n    def test_build_response_header_via_added(self):\n        inst = self._makeOne()\n        inst.request = DummyParser()\n        inst.version = \"1.0\"\n        inst.response_headers = [(\"Server\", \"abc\")]\n        result = inst.build_response_header()\n        lines = filter_lines(result)\n        self.assertEqual(len(lines), 5)\n        self.assertEqual(lines[0], b\"HTTP/1.0 200 OK\")\n        self.assertEqual(lines[1], b\"Connection: close\")\n        self.assertTrue(lines[2].startswith(b\"Date:\"))\n        self.assertEqual(lines[3], b\"Server: abc\")\n        self.assertEqual(lines[4], b\"Via: waitress\")\n\n    def test_build_response_header_date_exists(self):\n        inst = self._makeOne()\n        inst.request = DummyParser()\n        inst.version = \"1.0\"\n        inst.response_headers = [(\"Date\", \"date\")]\n        result = inst.build_response_header()\n        lines = filter_lines(result)\n        self.assertEqual(len(lines), 4)\n        self.assertEqual(lines[0], b\"HTTP/1.0 200 OK\")\n        self.assertEqual(lines[1], b\"Connection: close\")\n        self.assertTrue(lines[2].startswith(b\"Date:\"))\n        self.assertEqual(lines[3], b\"Server: waitress\")\n\n    def test_build_response_header_preexisting_content_length(self):\n        inst = self._makeOne()\n        inst.request = DummyParser()\n        inst.version = \"1.1\"\n        inst.content_length = 100\n        result = inst.build_response_header()\n        lines = filter_lines(result)\n        self.assertEqual(len(lines), 4)\n        self.assertEqual(lines[0], b\"HTTP/1.1 200 OK\")\n        self.assertEqual(lines[1], b\"Content-Length: 100\")\n        self.assertTrue(lines[2].startswith(b\"Date:\"))\n        self.assertEqual(lines[3], b\"Server: waitress\")\n\n    def test_remove_content_length_header(self):\n        inst = self._makeOne()\n        inst.response_headers = [(\"Content-Length\", \"70\")]\n        inst.remove_content_length_header()\n        self.assertEqual(inst.response_headers, [])\n\n    def test_remove_content_length_header_with_other(self):\n        inst = self._makeOne()\n        inst.response_headers = [\n            (\"Content-Length\", \"70\"),\n            (\"Content-Type\", \"text/html\"),\n        ]\n        inst.remove_content_length_header()\n        self.assertEqual(inst.response_headers, [(\"Content-Type\", \"text/html\")])\n\n    def test_start(self):\n        inst = self._makeOne()\n        inst.start()\n        self.assertTrue(inst.start_time)\n\n    def test_finish_didnt_write_header(self):\n        inst = self._makeOne()\n        inst.wrote_header = False\n        inst.complete = True\n        inst.finish()\n        self.assertTrue(inst.channel.written)\n\n    def test_finish_wrote_header(self):\n        inst = self._makeOne()\n        inst.wrote_header = True\n        inst.finish()\n        self.assertFalse(inst.channel.written)\n\n    def test_finish_chunked_response(self):\n        inst = self._makeOne()\n        inst.wrote_header = True\n        inst.chunked_response = True\n        inst.finish()\n        self.assertEqual(inst.channel.written, b\"0\\r\\n\\r\\n\")\n\n    def test_write_wrote_header(self):\n        inst = self._makeOne()\n        inst.wrote_header = True\n        inst.complete = True\n        inst.content_length = 3\n        inst.write(b\"abc\")\n        self.assertEqual(inst.channel.written, b\"abc\")\n\n    def test_write_header_not_written(self):\n        inst = self._makeOne()\n        inst.wrote_header = False\n        inst.complete = True\n        inst.write(b\"abc\")\n        self.assertTrue(inst.channel.written)\n        self.assertEqual(inst.wrote_header, True)\n\n    def test_write_start_response_uncalled(self):\n        inst = self._makeOne()\n        self.assertRaises(RuntimeError, inst.write, b\"\")\n\n    def test_write_chunked_response(self):\n        inst = self._makeOne()\n        inst.wrote_header = True\n        inst.chunked_response = True\n        inst.complete = True\n        inst.write(b\"abc\")\n        self.assertEqual(inst.channel.written, b\"3\\r\\nabc\\r\\n\")\n\n    def test_write_preexisting_content_length(self):\n        inst = self._makeOne()\n        inst.wrote_header = True\n        inst.complete = True\n        inst.content_length = 1\n        inst.logger = DummyLogger()\n        inst.write(b\"abc\")\n        self.assertTrue(inst.channel.written)\n        self.assertEqual(inst.logged_write_excess, True)\n        self.assertEqual(len(inst.logger.logged), 1)\n\n\nclass TestWSGITask(unittest.TestCase):\n    def _makeOne(self, channel=None, request=None):\n        if channel is None:\n            channel = DummyChannel()\n        if request is None:\n            request = DummyParser()\n        from waitress.task import WSGITask\n\n        return WSGITask(channel, request)\n\n    def test_service(self):\n        inst = self._makeOne()\n\n        def execute():\n            inst.executed = True\n\n        inst.execute = execute\n        inst.complete = True\n        inst.service()\n        self.assertTrue(inst.start_time)\n        self.assertTrue(inst.close_on_finish)\n        self.assertTrue(inst.channel.written)\n        self.assertEqual(inst.executed, True)\n\n    def test_service_server_raises_socket_error(self):\n        import socket\n\n        inst = self._makeOne()\n\n        def execute():\n            raise socket.error\n\n        inst.execute = execute\n        self.assertRaises(socket.error, inst.service)\n        self.assertTrue(inst.start_time)\n        self.assertTrue(inst.close_on_finish)\n        self.assertFalse(inst.channel.written)\n\n    def test_execute_app_calls_start_response_twice_wo_exc_info(self):\n        def app(environ, start_response):\n            start_response(\"200 OK\", [])\n            start_response(\"200 OK\", [])\n\n        inst = self._makeOne()\n        inst.channel.server.application = app\n        self.assertRaises(AssertionError, inst.execute)\n\n    def test_execute_app_calls_start_response_w_exc_info_complete(self):\n        def app(environ, start_response):\n            start_response(\"200 OK\", [], [ValueError, ValueError(), None])\n            return [b\"a\"]\n\n        inst = self._makeOne()\n        inst.complete = True\n        inst.channel.server.application = app\n        inst.execute()\n        self.assertTrue(inst.complete)\n        self.assertEqual(inst.status, \"200 OK\")\n        self.assertTrue(inst.channel.written)\n\n    def test_execute_app_calls_start_response_w_excinf_headers_unwritten(self):\n        def app(environ, start_response):\n            start_response(\"200 OK\", [], [ValueError, None, None])\n            return [b\"a\"]\n\n        inst = self._makeOne()\n        inst.wrote_header = False\n        inst.channel.server.application = app\n        inst.response_headers = [(\"a\", \"b\")]\n        inst.execute()\n        self.assertTrue(inst.complete)\n        self.assertEqual(inst.status, \"200 OK\")\n        self.assertTrue(inst.channel.written)\n        self.assertFalse((\"a\", \"b\") in inst.response_headers)\n\n    def test_execute_app_calls_start_response_w_excinf_headers_written(self):\n        def app(environ, start_response):\n            start_response(\"200 OK\", [], [ValueError, ValueError(), None])\n\n        inst = self._makeOne()\n        inst.complete = True\n        inst.wrote_header = True\n        inst.channel.server.application = app\n        self.assertRaises(ValueError, inst.execute)\n\n    def test_execute_bad_header_key(self):\n        def app(environ, start_response):\n            start_response(\"200 OK\", [(None, \"a\")])\n\n        inst = self._makeOne()\n        inst.channel.server.application = app\n        self.assertRaises(AssertionError, inst.execute)\n\n    def test_execute_bad_header_value(self):\n        def app(environ, start_response):\n            start_response(\"200 OK\", [(\"a\", None)])\n\n        inst = self._makeOne()\n        inst.channel.server.application = app\n        self.assertRaises(AssertionError, inst.execute)\n\n    def test_execute_hopbyhop_header(self):\n        def app(environ, start_response):\n            start_response(\"200 OK\", [(\"Connection\", \"close\")])\n\n        inst = self._makeOne()\n        inst.channel.server.application = app\n        self.assertRaises(AssertionError, inst.execute)\n\n    def test_execute_bad_header_value_control_characters(self):\n        def app(environ, start_response):\n            start_response(\"200 OK\", [(\"a\", \"\\n\")])\n\n        inst = self._makeOne()\n        inst.channel.server.application = app\n        self.assertRaises(ValueError, inst.execute)\n\n    def test_execute_bad_header_name_control_characters(self):\n        def app(environ, start_response):\n            start_response(\"200 OK\", [(\"a\\r\", \"value\")])\n\n        inst = self._makeOne()\n        inst.channel.server.application = app\n        self.assertRaises(ValueError, inst.execute)\n\n    def test_execute_bad_status_control_characters(self):\n        def app(environ, start_response):\n            start_response(\"200 OK\\r\", [])\n\n        inst = self._makeOne()\n        inst.channel.server.application = app\n        self.assertRaises(ValueError, inst.execute)\n\n    def test_preserve_header_value_order(self):\n        def app(environ, start_response):\n            write = start_response(\"200 OK\", [(\"C\", \"b\"), (\"A\", \"b\"), (\"A\", \"a\")])\n            write(b\"abc\")\n            return []\n\n        inst = self._makeOne()\n        inst.channel.server.application = app\n        inst.execute()\n        self.assertTrue(b\"A: b\\r\\nA: a\\r\\nC: b\\r\\n\" in inst.channel.written)\n\n    def test_execute_bad_status_value(self):\n        def app(environ, start_response):\n            start_response(None, [])\n\n        inst = self._makeOne()\n        inst.channel.server.application = app\n        self.assertRaises(AssertionError, inst.execute)\n\n    def test_execute_with_content_length_header(self):\n        def app(environ, start_response):\n            start_response(\"200 OK\", [(\"Content-Length\", \"1\")])\n            return [b\"a\"]\n\n        inst = self._makeOne()\n        inst.channel.server.application = app\n        inst.execute()\n        self.assertEqual(inst.content_length, 1)\n\n    def test_execute_app_calls_write(self):\n        def app(environ, start_response):\n            write = start_response(\"200 OK\", [(\"Content-Length\", \"3\")])\n            write(b\"abc\")\n            return []\n\n        inst = self._makeOne()\n        inst.channel.server.application = app\n        inst.execute()\n        self.assertEqual(inst.channel.written[-3:], b\"abc\")\n\n    def test_execute_app_returns_len1_chunk_without_cl(self):\n        def app(environ, start_response):\n            start_response(\"200 OK\", [])\n            return [b\"abc\"]\n\n        inst = self._makeOne()\n        inst.channel.server.application = app\n        inst.execute()\n        self.assertEqual(inst.content_length, 3)\n\n    def test_execute_app_returns_empty_chunk_as_first(self):\n        def app(environ, start_response):\n            start_response(\"200 OK\", [])\n            return [\"\", b\"abc\"]\n\n        inst = self._makeOne()\n        inst.channel.server.application = app\n        inst.execute()\n        self.assertEqual(inst.content_length, None)\n\n    def test_execute_app_returns_too_many_bytes(self):\n        def app(environ, start_response):\n            start_response(\"200 OK\", [(\"Content-Length\", \"1\")])\n            return [b\"abc\"]\n\n        inst = self._makeOne()\n        inst.channel.server.application = app\n        inst.logger = DummyLogger()\n        inst.execute()\n        self.assertEqual(inst.close_on_finish, True)\n        self.assertEqual(len(inst.logger.logged), 1)\n\n    def test_execute_app_returns_too_few_bytes(self):\n        def app(environ, start_response):\n            start_response(\"200 OK\", [(\"Content-Length\", \"3\")])\n            return [b\"a\"]\n\n        inst = self._makeOne()\n        inst.channel.server.application = app\n        inst.logger = DummyLogger()\n        inst.execute()\n        self.assertEqual(inst.close_on_finish, True)\n        self.assertEqual(len(inst.logger.logged), 1)\n\n    def test_execute_app_do_not_warn_on_head(self):\n        def app(environ, start_response):\n            start_response(\"200 OK\", [(\"Content-Length\", \"3\")])\n            return [b\"\"]\n\n        inst = self._makeOne()\n        inst.request.command = \"HEAD\"\n        inst.channel.server.application = app\n        inst.logger = DummyLogger()\n        inst.execute()\n        self.assertEqual(inst.close_on_finish, True)\n        self.assertEqual(len(inst.logger.logged), 0)\n\n    def test_execute_app_without_body_204_logged(self):\n        def app(environ, start_response):\n            start_response(\"204 No Content\", [(\"Content-Length\", \"3\")])\n            return [b\"abc\"]\n\n        inst = self._makeOne()\n        inst.channel.server.application = app\n        inst.logger = DummyLogger()\n        inst.execute()\n        self.assertEqual(inst.close_on_finish, True)\n        self.assertNotIn(b\"abc\", inst.channel.written)\n        self.assertNotIn(b\"Content-Length\", inst.channel.written)\n        self.assertNotIn(b\"Transfer-Encoding\", inst.channel.written)\n        self.assertEqual(len(inst.logger.logged), 1)\n\n    def test_execute_app_without_body_304_logged(self):\n        def app(environ, start_response):\n            start_response(\"304 Not Modified\", [(\"Content-Length\", \"3\")])\n            return [b\"abc\"]\n\n        inst = self._makeOne()\n        inst.channel.server.application = app\n        inst.logger = DummyLogger()\n        inst.execute()\n        self.assertEqual(inst.close_on_finish, True)\n        self.assertNotIn(b\"abc\", inst.channel.written)\n        self.assertNotIn(b\"Content-Length\", inst.channel.written)\n        self.assertNotIn(b\"Transfer-Encoding\", inst.channel.written)\n        self.assertEqual(len(inst.logger.logged), 1)\n\n    def test_execute_app_returns_closeable(self):\n        class closeable(list):\n            def close(self):\n                self.closed = True\n\n        foo = closeable([b\"abc\"])\n\n        def app(environ, start_response):\n            start_response(\"200 OK\", [(\"Content-Length\", \"3\")])\n            return foo\n\n        inst = self._makeOne()\n        inst.channel.server.application = app\n        inst.execute()\n        self.assertEqual(foo.closed, True)\n\n    def test_execute_app_returns_filewrapper_prepare_returns_True(self):\n        from waitress.buffers import ReadOnlyFileBasedBuffer\n\n        f = io.BytesIO(b\"abc\")\n        app_iter = ReadOnlyFileBasedBuffer(f, 8192)\n\n        def app(environ, start_response):\n            start_response(\"200 OK\", [(\"Content-Length\", \"3\")])\n            return app_iter\n\n        inst = self._makeOne()\n        inst.channel.server.application = app\n        inst.execute()\n        self.assertTrue(inst.channel.written)  # header\n        self.assertEqual(inst.channel.otherdata, [app_iter])\n\n    def test_execute_app_returns_filewrapper_prepare_returns_True_nocl(self):\n        from waitress.buffers import ReadOnlyFileBasedBuffer\n\n        f = io.BytesIO(b\"abc\")\n        app_iter = ReadOnlyFileBasedBuffer(f, 8192)\n\n        def app(environ, start_response):\n            start_response(\"200 OK\", [])\n            return app_iter\n\n        inst = self._makeOne()\n        inst.channel.server.application = app\n        inst.execute()\n        self.assertTrue(inst.channel.written)  # header\n        self.assertEqual(inst.channel.otherdata, [app_iter])\n        self.assertEqual(inst.content_length, 3)\n\n    def test_execute_app_returns_filewrapper_prepare_returns_True_badcl(self):\n        from waitress.buffers import ReadOnlyFileBasedBuffer\n\n        f = io.BytesIO(b\"abc\")\n        app_iter = ReadOnlyFileBasedBuffer(f, 8192)\n\n        def app(environ, start_response):\n            start_response(\"200 OK\", [])\n            return app_iter\n\n        inst = self._makeOne()\n        inst.channel.server.application = app\n        inst.content_length = 10\n        inst.response_headers = [(\"Content-Length\", \"10\")]\n        inst.execute()\n        self.assertTrue(inst.channel.written)  # header\n        self.assertEqual(inst.channel.otherdata, [app_iter])\n        self.assertEqual(inst.content_length, 3)\n        self.assertEqual(dict(inst.response_headers)[\"Content-Length\"], \"3\")\n\n    def test_get_environment_already_cached(self):\n        inst = self._makeOne()\n        inst.environ = object()\n        self.assertEqual(inst.get_environment(), inst.environ)\n\n    def test_get_environment_path_startswith_more_than_one_slash(self):\n        inst = self._makeOne()\n        request = DummyParser()\n        request.path = \"///abc\"\n        inst.request = request\n        environ = inst.get_environment()\n        self.assertEqual(environ[\"PATH_INFO\"], \"/abc\")\n\n    def test_get_environment_path_empty(self):\n        inst = self._makeOne()\n        request = DummyParser()\n        request.path = \"\"\n        inst.request = request\n        environ = inst.get_environment()\n        self.assertEqual(environ[\"PATH_INFO\"], \"\")\n\n    def test_get_environment_no_query(self):\n        inst = self._makeOne()\n        request = DummyParser()\n        inst.request = request\n        environ = inst.get_environment()\n        self.assertEqual(environ[\"QUERY_STRING\"], \"\")\n\n    def test_get_environment_with_query(self):\n        inst = self._makeOne()\n        request = DummyParser()\n        request.query = \"abc\"\n        inst.request = request\n        environ = inst.get_environment()\n        self.assertEqual(environ[\"QUERY_STRING\"], \"abc\")\n\n    def test_get_environ_with_url_prefix_miss(self):\n        inst = self._makeOne()\n        inst.channel.server.adj.url_prefix = \"/foo\"\n        request = DummyParser()\n        request.path = \"/bar\"\n        inst.request = request\n        environ = inst.get_environment()\n        self.assertEqual(environ[\"PATH_INFO\"], \"/bar\")\n        self.assertEqual(environ[\"SCRIPT_NAME\"], \"/foo\")\n\n    def test_get_environ_with_url_prefix_hit(self):\n        inst = self._makeOne()\n        inst.channel.server.adj.url_prefix = \"/foo\"\n        request = DummyParser()\n        request.path = \"/foo/fuz\"\n        inst.request = request\n        environ = inst.get_environment()\n        self.assertEqual(environ[\"PATH_INFO\"], \"/fuz\")\n        self.assertEqual(environ[\"SCRIPT_NAME\"], \"/foo\")\n\n    def test_get_environ_with_url_prefix_empty_path(self):\n        inst = self._makeOne()\n        inst.channel.server.adj.url_prefix = \"/foo\"\n        request = DummyParser()\n        request.path = \"/foo\"\n        inst.request = request\n        environ = inst.get_environment()\n        self.assertEqual(environ[\"PATH_INFO\"], \"\")\n        self.assertEqual(environ[\"SCRIPT_NAME\"], \"/foo\")\n\n    def test_get_environment_values(self):\n        import sys\n\n        inst = self._makeOne()\n        request = DummyParser()\n        request.headers = {\n            \"CONTENT_TYPE\": \"abc\",\n            \"CONTENT_LENGTH\": \"10\",\n            \"X_FOO\": \"BAR\",\n            \"CONNECTION\": \"close\",\n        }\n        request.query = \"abc\"\n        inst.request = request\n        environ = inst.get_environment()\n\n        # nail the keys of environ\n        self.assertEqual(\n            sorted(environ.keys()),\n            [\n                \"CONTENT_LENGTH\",\n                \"CONTENT_TYPE\",\n                \"HTTP_CONNECTION\",\n                \"HTTP_X_FOO\",\n                \"PATH_INFO\",\n                \"QUERY_STRING\",\n                \"REMOTE_ADDR\",\n                \"REMOTE_HOST\",\n                \"REMOTE_PORT\",\n                \"REQUEST_METHOD\",\n                \"SCRIPT_NAME\",\n                \"SERVER_NAME\",\n                \"SERVER_PORT\",\n                \"SERVER_PROTOCOL\",\n                \"SERVER_SOFTWARE\",\n                \"wsgi.errors\",\n                \"wsgi.file_wrapper\",\n                \"wsgi.input\",\n                \"wsgi.input_terminated\",\n                \"wsgi.multiprocess\",\n                \"wsgi.multithread\",\n                \"wsgi.run_once\",\n                \"wsgi.url_scheme\",\n                \"wsgi.version\",\n            ],\n        )\n\n        self.assertEqual(environ[\"REQUEST_METHOD\"], \"GET\")\n        self.assertEqual(environ[\"SERVER_PORT\"], \"80\")\n        self.assertEqual(environ[\"SERVER_NAME\"], \"localhost\")\n        self.assertEqual(environ[\"SERVER_SOFTWARE\"], \"waitress\")\n        self.assertEqual(environ[\"SERVER_PROTOCOL\"], \"HTTP/1.0\")\n        self.assertEqual(environ[\"SCRIPT_NAME\"], \"\")\n        self.assertEqual(environ[\"HTTP_CONNECTION\"], \"close\")\n        self.assertEqual(environ[\"PATH_INFO\"], \"/\")\n        self.assertEqual(environ[\"QUERY_STRING\"], \"abc\")\n        self.assertEqual(environ[\"REMOTE_ADDR\"], \"127.0.0.1\")\n        self.assertEqual(environ[\"REMOTE_HOST\"], \"127.0.0.1\")\n        self.assertEqual(environ[\"REMOTE_PORT\"], \"39830\")\n        self.assertEqual(environ[\"CONTENT_TYPE\"], \"abc\")\n        self.assertEqual(environ[\"CONTENT_LENGTH\"], \"10\")\n        self.assertEqual(environ[\"HTTP_X_FOO\"], \"BAR\")\n        self.assertEqual(environ[\"wsgi.version\"], (1, 0))\n        self.assertEqual(environ[\"wsgi.url_scheme\"], \"http\")\n        self.assertEqual(environ[\"wsgi.errors\"], sys.stderr)\n        self.assertEqual(environ[\"wsgi.multithread\"], True)\n        self.assertEqual(environ[\"wsgi.multiprocess\"], False)\n        self.assertEqual(environ[\"wsgi.run_once\"], False)\n        self.assertEqual(environ[\"wsgi.input\"], \"stream\")\n        self.assertEqual(environ[\"wsgi.input_terminated\"], True)\n        self.assertEqual(inst.environ, environ)\n\n\nclass TestErrorTask(unittest.TestCase):\n    def _makeOne(self, channel=None, request=None):\n        if channel is None:\n            channel = DummyChannel()\n        if request is None:\n            request = DummyParser()\n            request.error = self._makeDummyError()\n        from waitress.task import ErrorTask\n\n        return ErrorTask(channel, request)\n\n    def _makeDummyError(self):\n        from waitress.utilities import Error\n\n        e = Error(\"body\")\n        e.code = 432\n        e.reason = \"Too Ugly\"\n        return e\n\n    def test_execute_http_10(self):\n        inst = self._makeOne()\n        inst.execute()\n        lines = filter_lines(inst.channel.written)\n        self.assertEqual(len(lines), 9)\n        self.assertEqual(lines[0], b\"HTTP/1.0 432 Too Ugly\")\n        self.assertEqual(lines[1], b\"Connection: close\")\n        self.assertEqual(lines[2], b\"Content-Length: 43\")\n        self.assertEqual(lines[3], b\"Content-Type: text/plain\")\n        self.assertTrue(lines[4])\n        self.assertEqual(lines[5], b\"Server: waitress\")\n        self.assertEqual(lines[6], b\"Too Ugly\")\n        self.assertEqual(lines[7], b\"body\")\n        self.assertEqual(lines[8], b\"(generated by waitress)\")\n\n    def test_execute_http_11(self):\n        inst = self._makeOne()\n        inst.version = \"1.1\"\n        inst.execute()\n        lines = filter_lines(inst.channel.written)\n        self.assertEqual(len(lines), 9)\n        self.assertEqual(lines[0], b\"HTTP/1.1 432 Too Ugly\")\n        self.assertEqual(lines[1], b\"Connection: close\")\n        self.assertEqual(lines[2], b\"Content-Length: 43\")\n        self.assertEqual(lines[3], b\"Content-Type: text/plain\")\n        self.assertTrue(lines[4])\n        self.assertEqual(lines[5], b\"Server: waitress\")\n        self.assertEqual(lines[6], b\"Too Ugly\")\n        self.assertEqual(lines[7], b\"body\")\n        self.assertEqual(lines[8], b\"(generated by waitress)\")\n\n    def test_execute_http_11_close(self):\n        inst = self._makeOne()\n        inst.version = \"1.1\"\n        inst.request.headers[\"CONNECTION\"] = \"close\"\n        inst.execute()\n        lines = filter_lines(inst.channel.written)\n        self.assertEqual(len(lines), 9)\n        self.assertEqual(lines[0], b\"HTTP/1.1 432 Too Ugly\")\n        self.assertEqual(lines[1], b\"Connection: close\")\n        self.assertEqual(lines[2], b\"Content-Length: 43\")\n        self.assertEqual(lines[3], b\"Content-Type: text/plain\")\n        self.assertTrue(lines[4])\n        self.assertEqual(lines[5], b\"Server: waitress\")\n        self.assertEqual(lines[6], b\"Too Ugly\")\n        self.assertEqual(lines[7], b\"body\")\n        self.assertEqual(lines[8], b\"(generated by waitress)\")\n\n    def test_execute_http_11_keep_forces_close(self):\n        inst = self._makeOne()\n        inst.version = \"1.1\"\n        inst.request.headers[\"CONNECTION\"] = \"keep-alive\"\n        inst.execute()\n        lines = filter_lines(inst.channel.written)\n        self.assertEqual(len(lines), 9)\n        self.assertEqual(lines[0], b\"HTTP/1.1 432 Too Ugly\")\n        self.assertEqual(lines[1], b\"Connection: close\")\n        self.assertEqual(lines[2], b\"Content-Length: 43\")\n        self.assertEqual(lines[3], b\"Content-Type: text/plain\")\n        self.assertTrue(lines[4])\n        self.assertEqual(lines[5], b\"Server: waitress\")\n        self.assertEqual(lines[6], b\"Too Ugly\")\n        self.assertEqual(lines[7], b\"body\")\n        self.assertEqual(lines[8], b\"(generated by waitress)\")\n\n\nclass DummyTask(object):\n    serviced = False\n    cancelled = False\n\n    def service(self):\n        self.serviced = True\n\n    def cancel(self):\n        self.cancelled = True\n\n\nclass DummyAdj(object):\n    log_socket_errors = True\n    ident = \"waitress\"\n    host = \"127.0.0.1\"\n    port = 80\n    url_prefix = \"\"\n\n\nclass DummyServer(object):\n    server_name = \"localhost\"\n    effective_port = 80\n\n    def __init__(self):\n        self.adj = DummyAdj()\n\n\nclass DummyChannel(object):\n    closed_when_done = False\n    adj = DummyAdj()\n    creation_time = 0\n    addr = (\"127.0.0.1\", 39830)\n\n    def __init__(self, server=None):\n        if server is None:\n            server = DummyServer()\n        self.server = server\n        self.written = b\"\"\n        self.otherdata = []\n\n    def write_soon(self, data):\n        if isinstance(data, bytes):\n            self.written += data\n        else:\n            self.otherdata.append(data)\n        return len(data)\n\n\nclass DummyParser(object):\n    version = \"1.0\"\n    command = \"GET\"\n    path = \"/\"\n    query = \"\"\n    url_scheme = \"http\"\n    expect_continue = False\n    headers_finished = False\n\n    def __init__(self):\n        self.headers = {}\n\n    def get_body_stream(self):\n        return \"stream\"\n\n\ndef filter_lines(s):\n    return list(filter(None, s.split(b\"\\r\\n\")))\n\n\nclass DummyLogger(object):\n    def __init__(self):\n        self.logged = []\n\n    def warning(self, msg, *args):\n        self.logged.append(msg % args)\n\n    def exception(self, msg, *args):\n        self.logged.append(msg % args)\n", "##############################################################################\n#\n# Copyright (c) 2002 Zope Foundation and Contributors.\n# All Rights Reserved.\n#\n# This software is subject to the provisions of the Zope Public License,\n# Version 2.1 (ZPL).  A copy of the ZPL should accompany this distribution.\n# THIS SOFTWARE IS PROVIDED \"AS IS\" AND ANY AND ALL EXPRESS OR IMPLIED\n# WARRANTIES ARE DISCLAIMED, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\n# WARRANTIES OF TITLE, MERCHANTABILITY, AGAINST INFRINGEMENT, AND FITNESS\n# FOR A PARTICULAR PURPOSE.\n#\n##############################################################################\n\nimport unittest\n\n\nclass Test_parse_http_date(unittest.TestCase):\n    def _callFUT(self, v):\n        from waitress.utilities import parse_http_date\n\n        return parse_http_date(v)\n\n    def test_rfc850(self):\n        val = \"Tuesday, 08-Feb-94 14:15:29 GMT\"\n        result = self._callFUT(val)\n        self.assertEqual(result, 760716929)\n\n    def test_rfc822(self):\n        val = \"Sun, 08 Feb 1994 14:15:29 GMT\"\n        result = self._callFUT(val)\n        self.assertEqual(result, 760716929)\n\n    def test_neither(self):\n        val = \"\"\n        result = self._callFUT(val)\n        self.assertEqual(result, 0)\n\n\nclass Test_build_http_date(unittest.TestCase):\n    def test_rountdrip(self):\n        from waitress.utilities import build_http_date, parse_http_date\n        from time import time\n\n        t = int(time())\n        self.assertEqual(t, parse_http_date(build_http_date(t)))\n\n\nclass Test_unpack_rfc850(unittest.TestCase):\n    def _callFUT(self, val):\n        from waitress.utilities import unpack_rfc850, rfc850_reg\n\n        return unpack_rfc850(rfc850_reg.match(val.lower()))\n\n    def test_it(self):\n        val = \"Tuesday, 08-Feb-94 14:15:29 GMT\"\n        result = self._callFUT(val)\n        self.assertEqual(result, (1994, 2, 8, 14, 15, 29, 0, 0, 0))\n\n\nclass Test_unpack_rfc_822(unittest.TestCase):\n    def _callFUT(self, val):\n        from waitress.utilities import unpack_rfc822, rfc822_reg\n\n        return unpack_rfc822(rfc822_reg.match(val.lower()))\n\n    def test_it(self):\n        val = \"Sun, 08 Feb 1994 14:15:29 GMT\"\n        result = self._callFUT(val)\n        self.assertEqual(result, (1994, 2, 8, 14, 15, 29, 0, 0, 0))\n\n\nclass Test_find_double_newline(unittest.TestCase):\n    def _callFUT(self, val):\n        from waitress.utilities import find_double_newline\n\n        return find_double_newline(val)\n\n    def test_empty(self):\n        self.assertEqual(self._callFUT(b\"\"), -1)\n\n    def test_one_linefeed(self):\n        self.assertEqual(self._callFUT(b\"\\n\"), -1)\n\n    def test_double_linefeed(self):\n        self.assertEqual(self._callFUT(b\"\\n\\n\"), -1)\n\n    def test_one_crlf(self):\n        self.assertEqual(self._callFUT(b\"\\r\\n\"), -1)\n\n    def test_double_crfl(self):\n        self.assertEqual(self._callFUT(b\"\\r\\n\\r\\n\"), 4)\n\n    def test_mixed(self):\n        self.assertEqual(self._callFUT(b\"\\n\\n00\\r\\n\\r\\n\"), 8)\n\n\nclass TestBadRequest(unittest.TestCase):\n    def _makeOne(self):\n        from waitress.utilities import BadRequest\n\n        return BadRequest(1)\n\n    def test_it(self):\n        inst = self._makeOne()\n        self.assertEqual(inst.body, 1)\n\n\nclass Test_undquote(unittest.TestCase):\n    def _callFUT(self, value):\n        from waitress.utilities import undquote\n\n        return undquote(value)\n\n    def test_empty(self):\n        self.assertEqual(self._callFUT(\"\"), \"\")\n\n    def test_quoted(self):\n        self.assertEqual(self._callFUT('\"test\"'), \"test\")\n\n    def test_unquoted(self):\n        self.assertEqual(self._callFUT(\"test\"), \"test\")\n\n    def test_quoted_backslash_quote(self):\n        self.assertEqual(self._callFUT('\"\\\\\"\"'), '\"')\n\n    def test_quoted_htab(self):\n        self.assertEqual(self._callFUT('\"\\t\"'), \"\\t\")\n\n    def test_quoted_backslash_htab(self):\n        self.assertEqual(self._callFUT('\"\\\\\\t\"'), \"\\t\")\n\n    def test_quoted_backslash_invalid(self):\n        self.assertRaises(ValueError, self._callFUT, '\"\\\\\"')\n\n    def test_invalid_quoting(self):\n        self.assertRaises(ValueError, self._callFUT, '\"test')\n\n    def test_invalid_quoting_single_quote(self):\n        self.assertRaises(ValueError, self._callFUT, '\"')\n", "##############################################################################\n#\n# Copyright (c) 2004 Zope Foundation and Contributors.\n# All Rights Reserved.\n#\n# This software is subject to the provisions of the Zope Public License,\n# Version 2.1 (ZPL).  A copy of the ZPL should accompany this distribution.\n# THIS SOFTWARE IS PROVIDED \"AS IS\" AND ANY AND ALL EXPRESS OR IMPLIED\n# WARRANTIES ARE DISCLAIMED, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\n# WARRANTIES OF TITLE, MERCHANTABILITY, AGAINST INFRINGEMENT, AND FITNESS\n# FOR A PARTICULAR PURPOSE.\n#\n##############################################################################\n\"\"\"Utility functions\n\"\"\"\n\nimport calendar\nimport errno\nimport logging\nimport os\nimport re\nimport stat\nimport time\n\nlogger = logging.getLogger(\"waitress\")\nqueue_logger = logging.getLogger(\"waitress.queue\")\n\n\ndef find_double_newline(s):\n    \"\"\"Returns the position just after a double newline in the given string.\"\"\"\n    pos = s.find(b\"\\r\\n\\r\\n\")\n\n    if pos >= 0:\n        pos += 4\n\n    return pos\n\n\ndef concat(*args):\n    return \"\".join(args)\n\n\ndef join(seq, field=\" \"):\n    return field.join(seq)\n\n\ndef group(s):\n    return \"(\" + s + \")\"\n\n\nshort_days = [\"sun\", \"mon\", \"tue\", \"wed\", \"thu\", \"fri\", \"sat\"]\nlong_days = [\n    \"sunday\",\n    \"monday\",\n    \"tuesday\",\n    \"wednesday\",\n    \"thursday\",\n    \"friday\",\n    \"saturday\",\n]\n\nshort_day_reg = group(join(short_days, \"|\"))\nlong_day_reg = group(join(long_days, \"|\"))\n\ndaymap = {}\nfor i in range(7):\n    daymap[short_days[i]] = i\n    daymap[long_days[i]] = i\n\nhms_reg = join(3 * [group(\"[0-9][0-9]\")], \":\")\n\nmonths = [\n    \"jan\",\n    \"feb\",\n    \"mar\",\n    \"apr\",\n    \"may\",\n    \"jun\",\n    \"jul\",\n    \"aug\",\n    \"sep\",\n    \"oct\",\n    \"nov\",\n    \"dec\",\n]\n\nmonmap = {}\nfor i in range(12):\n    monmap[months[i]] = i + 1\n\nmonths_reg = group(join(months, \"|\"))\n\n# From draft-ietf-http-v11-spec-07.txt/3.3.1\n#       Sun, 06 Nov 1994 08:49:37 GMT  ; RFC 822, updated by RFC 1123\n#       Sunday, 06-Nov-94 08:49:37 GMT ; RFC 850, obsoleted by RFC 1036\n#       Sun Nov  6 08:49:37 1994       ; ANSI C's asctime() format\n\n# rfc822 format\nrfc822_date = join(\n    [\n        concat(short_day_reg, \",\"),  # day\n        group(\"[0-9][0-9]?\"),  # date\n        months_reg,  # month\n        group(\"[0-9]+\"),  # year\n        hms_reg,  # hour minute second\n        \"gmt\",\n    ],\n    \" \",\n)\n\nrfc822_reg = re.compile(rfc822_date)\n\n\ndef unpack_rfc822(m):\n    g = m.group\n    return (\n        int(g(4)),  # year\n        monmap[g(3)],  # month\n        int(g(2)),  # day\n        int(g(5)),  # hour\n        int(g(6)),  # minute\n        int(g(7)),  # second\n        0,\n        0,\n        0,\n    )\n\n\n# rfc850 format\nrfc850_date = join(\n    [\n        concat(long_day_reg, \",\"),\n        join([group(\"[0-9][0-9]?\"), months_reg, group(\"[0-9]+\")], \"-\"),\n        hms_reg,\n        \"gmt\",\n    ],\n    \" \",\n)\n\nrfc850_reg = re.compile(rfc850_date)\n# they actually unpack the same way\ndef unpack_rfc850(m):\n    g = m.group\n    yr = g(4)\n    if len(yr) == 2:\n        yr = \"19\" + yr\n    return (\n        int(yr),  # year\n        monmap[g(3)],  # month\n        int(g(2)),  # day\n        int(g(5)),  # hour\n        int(g(6)),  # minute\n        int(g(7)),  # second\n        0,\n        0,\n        0,\n    )\n\n\n# parsdate.parsedate - ~700/sec.\n# parse_http_date    - ~1333/sec.\n\nweekdayname = [\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\"]\nmonthname = [\n    None,\n    \"Jan\",\n    \"Feb\",\n    \"Mar\",\n    \"Apr\",\n    \"May\",\n    \"Jun\",\n    \"Jul\",\n    \"Aug\",\n    \"Sep\",\n    \"Oct\",\n    \"Nov\",\n    \"Dec\",\n]\n\n\ndef build_http_date(when):\n    year, month, day, hh, mm, ss, wd, y, z = time.gmtime(when)\n    return \"%s, %02d %3s %4d %02d:%02d:%02d GMT\" % (\n        weekdayname[wd],\n        day,\n        monthname[month],\n        year,\n        hh,\n        mm,\n        ss,\n    )\n\n\ndef parse_http_date(d):\n    d = d.lower()\n    m = rfc850_reg.match(d)\n    if m and m.end() == len(d):\n        retval = int(calendar.timegm(unpack_rfc850(m)))\n    else:\n        m = rfc822_reg.match(d)\n        if m and m.end() == len(d):\n            retval = int(calendar.timegm(unpack_rfc822(m)))\n        else:\n            return 0\n    return retval\n\n\n# RFC 5234 Appendix B.1 \"Core Rules\":\n# VCHAR         =  %x21-7E\n#                  ; visible (printing) characters\nvchar_re = \"\\x21-\\x7e\"\n\n# RFC 7230 Section 3.2.6 \"Field Value Components\":\n# quoted-string = DQUOTE *( qdtext / quoted-pair ) DQUOTE\n# qdtext        = HTAB / SP /%x21 / %x23-5B / %x5D-7E / obs-text\n# obs-text      = %x80-FF\n# quoted-pair   = \"\\\" ( HTAB / SP / VCHAR / obs-text )\nobs_text_re = \"\\x80-\\xff\"\n\n# The '\\\\' between \\x5b and \\x5d is needed to escape \\x5d (']')\nqdtext_re = \"[\\t \\x21\\x23-\\x5b\\\\\\x5d-\\x7e\" + obs_text_re + \"]\"\n\nquoted_pair_re = r\"\\\\\" + \"([\\t \" + vchar_re + obs_text_re + \"])\"\nquoted_string_re = '\"(?:(?:' + qdtext_re + \")|(?:\" + quoted_pair_re + '))*\"'\n\nquoted_string = re.compile(quoted_string_re)\nquoted_pair = re.compile(quoted_pair_re)\n\n\ndef undquote(value):\n    if value.startswith('\"') and value.endswith('\"'):\n        # So it claims to be DQUOTE'ed, let's validate that\n        matches = quoted_string.match(value)\n\n        if matches and matches.end() == len(value):\n            # Remove the DQUOTE's from the value\n            value = value[1:-1]\n\n            # Remove all backslashes that are followed by a valid vchar or\n            # obs-text\n            value = quoted_pair.sub(r\"\\1\", value)\n\n            return value\n    elif not value.startswith('\"') and not value.endswith('\"'):\n        return value\n\n    raise ValueError(\"Invalid quoting in value\")\n\n\ndef cleanup_unix_socket(path):\n    try:\n        st = os.stat(path)\n    except OSError as exc:\n        if exc.errno != errno.ENOENT:\n            raise  # pragma: no cover\n    else:\n        if stat.S_ISSOCK(st.st_mode):\n            try:\n                os.remove(path)\n            except OSError:  # pragma: no cover\n                # avoid race condition error during tests\n                pass\n\n\nclass Error(object):\n    code = 500\n    reason = \"Internal Server Error\"\n\n    def __init__(self, body):\n        self.body = body\n\n    def to_response(self):\n        status = \"%s %s\" % (self.code, self.reason)\n        body = \"%s\\r\\n\\r\\n%s\" % (self.reason, self.body)\n        tag = \"\\r\\n\\r\\n(generated by waitress)\"\n        body = body + tag\n        headers = [(\"Content-Type\", \"text/plain\")]\n\n        return status, headers, body\n\n    def wsgi_response(self, environ, start_response):\n        status, headers, body = self.to_response()\n        start_response(status, headers)\n        yield body\n\n\nclass BadRequest(Error):\n    code = 400\n    reason = \"Bad Request\"\n\n\nclass RequestHeaderFieldsTooLarge(BadRequest):\n    code = 431\n    reason = \"Request Header Fields Too Large\"\n\n\nclass RequestEntityTooLarge(BadRequest):\n    code = 413\n    reason = \"Request Entity Too Large\"\n\n\nclass InternalServerError(Error):\n    code = 500\n    reason = \"Internal Server Error\"\n\n\nclass ServerNotImplemented(Error):\n    code = 501\n    reason = \"Not Implemented\"\n"], "filenames": ["CHANGES.txt", "HISTORY.txt", "setup.py", "waitress/parser.py", "waitress/receiver.py", "waitress/task.py", "waitress/tests/test_channel.py", "waitress/tests/test_functional.py", "waitress/tests/test_parser.py", "waitress/tests/test_receiver.py", "waitress/tests/test_task.py", "waitress/tests/test_utilities.py", "waitress/utilities.py"], "buggy_code_start_loc": [1, 0, 37, 22, 17, 356, 426, 182, 18, 86, 879, 86, 31], "buggy_code_end_loc": [79, 0, 38, 303, 143, 364, 536, 1586, 478, 155, 921, 96, 308], "fixing_code_start_loc": [1, 1, 37, 21, 17, 356, 426, 182, 18, 86, 878, 86, 31], "fixing_code_end_loc": [78, 80, 38, 358, 180, 360, 522, 1611, 579, 227, 923, 96, 310], "type": "CWE-444", "message": "Waitress through version 1.3.1 would parse the Transfer-Encoding header and only look for a single string value, if that value was not chunked it would fall through and use the Content-Length header instead. According to the HTTP standard Transfer-Encoding should be a comma separated list, with the inner-most encoding first, followed by any further transfer codings, ending with chunked. Requests sent with: \"Transfer-Encoding: gzip, chunked\" would incorrectly get ignored, and the request would use a Content-Length header instead to determine the body size of the HTTP message. This could allow for Waitress to treat a single request as multiple requests in the case of HTTP pipelining. This issue is fixed in Waitress 1.4.0.", "other": {"cve": {"id": "CVE-2019-16786", "sourceIdentifier": "security-advisories@github.com", "published": "2019-12-20T23:15:11.277", "lastModified": "2022-09-23T18:58:17.537", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "Waitress through version 1.3.1 would parse the Transfer-Encoding header and only look for a single string value, if that value was not chunked it would fall through and use the Content-Length header instead. According to the HTTP standard Transfer-Encoding should be a comma separated list, with the inner-most encoding first, followed by any further transfer codings, ending with chunked. Requests sent with: \"Transfer-Encoding: gzip, chunked\" would incorrectly get ignored, and the request would use a Content-Length header instead to determine the body size of the HTTP message. This could allow for Waitress to treat a single request as multiple requests in the case of HTTP pipelining. This issue is fixed in Waitress 1.4.0."}, {"lang": "es", "value": "Waitress versi\u00f3n hasta 1.3.1 analizar\u00eda el encabezado Transfer-Encoding y solo buscar\u00eda un \u00fanico valor de cadena, si ese valor no se dividiera, caer\u00eda y usar\u00eda en su lugar el encabezado Content-Length. De acuerdo con el est\u00e1ndar HTTP, Transfer-Encoding debe ser una lista separada por comas, con la codificaci\u00f3n m\u00e1s interna primero, seguida de cualquier otra codificaci\u00f3n de transferencia, que termine en fragmentos. Las peticiones enviadas con: \"Transfer-Encoding: gzip, chunked\" se ignorar\u00edan incorrectamente, y la petici\u00f3n utilizar\u00eda un encabezado Content-Length para determinar el tama\u00f1o del cuerpo del mensaje HTTP. Esto podr\u00eda permitir que Waitress trate una petici\u00f3n \u00fanica como peticiones m\u00faltiples en el caso de la canalizaci\u00f3n HTTP. Este problema fue corregido en Waitress versi\u00f3n 1.4.0."}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:H/A:N", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "HIGH", "availabilityImpact": "NONE", "baseScore": 7.5, "baseSeverity": "HIGH"}, "exploitabilityScore": 3.9, "impactScore": 3.6}, {"source": "security-advisories@github.com", "type": "Secondary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:H/PR:L/UI:N/S:C/C:H/I:L/A:N", "attackVector": "NETWORK", "attackComplexity": "HIGH", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "CHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "LOW", "availabilityImpact": "NONE", "baseScore": 7.1, "baseSeverity": "HIGH"}, "exploitabilityScore": 1.8, "impactScore": 4.7}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:N/AC:L/Au:N/C:N/I:P/A:N", "accessVector": "NETWORK", "accessComplexity": "LOW", "authentication": "NONE", "confidentialityImpact": "NONE", "integrityImpact": "PARTIAL", "availabilityImpact": "NONE", "baseScore": 5.0}, "baseSeverity": "MEDIUM", "exploitabilityScore": 10.0, "impactScore": 2.9, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-444"}]}, {"source": "security-advisories@github.com", "type": "Secondary", "description": [{"lang": "en", "value": "CWE-444"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:agendaless:waitress:*:*:*:*:*:*:*:*", "versionEndExcluding": "1.3.1", "matchCriteriaId": "6CAB3F2E-7A4C-4F03-8848-E03D4E028F59"}]}]}, {"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:oracle:communications_cloud_native_core_network_function_cloud_native_environment:1.10.0:*:*:*:*:*:*:*", "matchCriteriaId": "C2A5B24D-BDF2-423C-98EA-A40778C01A05"}]}]}, {"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:debian:debian_linux:9.0:*:*:*:*:*:*:*", "matchCriteriaId": "DEECE5FC-CACF-4496-A3E7-164736409252"}]}]}, {"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:fedoraproject:fedora:30:*:*:*:*:*:*:*", "matchCriteriaId": "97A4B8DF-58DA-4AB6-A1F9-331B36409BA3"}, {"vulnerable": true, "criteria": "cpe:2.3:o:fedoraproject:fedora:31:*:*:*:*:*:*:*", "matchCriteriaId": "80F0FA5D-8D3B-4C0E-81E2-87998286AF33"}]}]}, {"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:redhat:openstack:15:*:*:*:*:*:*:*", "matchCriteriaId": "70108B60-8817-40B4-8412-796A592E4E5E"}]}]}], "references": [{"url": "https://access.redhat.com/errata/RHSA-2020:0720", "source": "security-advisories@github.com", "tags": ["Third Party Advisory"]}, {"url": "https://docs.pylonsproject.org/projects/waitress/en/latest/#security-fixes", "source": "security-advisories@github.com", "tags": ["Release Notes", "Vendor Advisory"]}, {"url": "https://github.com/Pylons/waitress/commit/f11093a6b3240fc26830b6111e826128af7771c3", "source": "security-advisories@github.com", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/Pylons/waitress/security/advisories/GHSA-g2xc-35jw-c63p", "source": "security-advisories@github.com", "tags": ["Third Party Advisory"]}, {"url": "https://lists.debian.org/debian-lts-announce/2022/05/msg00011.html", "source": "security-advisories@github.com", "tags": ["Mailing List", "Third Party Advisory"]}, {"url": "https://lists.fedoraproject.org/archives/list/package-announce@lists.fedoraproject.org/message/GVDHR2DNKCNQ7YQXISJ45NT4IQDX3LJ7/", "source": "security-advisories@github.com", "tags": ["Mailing List", "Third Party Advisory"]}, {"url": "https://lists.fedoraproject.org/archives/list/package-announce@lists.fedoraproject.org/message/LYEOTGWJZVKPRXX2HBNVIYWCX73QYPM5/", "source": "security-advisories@github.com", "tags": ["Mailing List", "Third Party Advisory"]}, {"url": "https://www.oracle.com/security-alerts/cpuapr2022.html", "source": "security-advisories@github.com", "tags": ["Patch", "Third Party Advisory"]}]}, "github_commit_url": "https://github.com/Pylons/waitress/commit/f11093a6b3240fc26830b6111e826128af7771c3"}}
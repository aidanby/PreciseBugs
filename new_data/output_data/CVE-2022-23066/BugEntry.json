{"buggy_code": ["#![allow(clippy::integer_arithmetic)]\n// Derived from uBPF <https://github.com/iovisor/ubpf>\n// Copyright 2015 Big Switch Networks, Inc\n//      (uBPF: JIT algorithm, originally in C)\n// Copyright 2016 6WIND S.A. <quentin.monnet@6wind.com>\n//      (Translation to Rust, MetaBuff addition)\n//\n// Licensed under the Apache License, Version 2.0 <http://www.apache.org/licenses/LICENSE-2.0> or\n// the MIT license <http://opensource.org/licenses/MIT>, at your option. This file may not be\n// copied, modified, or distributed except according to those terms.\n\n#![allow(clippy::deprecated_cfg_attr)]\n#![cfg_attr(rustfmt, rustfmt_skip)]\n#![allow(unreachable_code)]\n\nextern crate libc;\n\nuse std::{\n    collections::HashMap,\n    fmt::{Debug, Error as FormatterError, Formatter},\n    mem,\n    ops::{Index, IndexMut},\n    pin::Pin, ptr,\n};\nuse rand::{rngs::SmallRng, Rng, SeedableRng};\n\nuse crate::{\n    elf::Executable,\n    vm::{Config, ProgramResult, InstructionMeter, Tracer, SYSCALL_CONTEXT_OBJECTS_OFFSET},\n    ebpf::{self, INSN_SIZE, FIRST_SCRATCH_REG, SCRATCH_REGS, FRAME_PTR_REG, MM_STACK_START, STACK_PTR_REG},\n    error::{UserDefinedError, EbpfError},\n    memory_region::{AccessType, MemoryMapping, MemoryRegion},\n    user_error::UserError,\n    x86::*,\n};\n\nconst MAX_EMPTY_PROGRAM_MACHINE_CODE_LENGTH: usize = 4096;\nconst MAX_MACHINE_CODE_LENGTH_PER_INSTRUCTION: usize = 110;\n\n/// Argument for executing a eBPF JIT-compiled program\npub struct JitProgramArgument<'a> {\n    /// The MemoryMapping to be used to run the compiled code\n    pub memory_mapping: MemoryMapping<'a>,\n    /// Pointers to the context objects of syscalls\n    pub syscall_context_objects: [*const u8; 0],\n}\n\nstruct JitProgramSections {\n    page_size: usize,\n    pc_section: &'static mut [u64],\n    text_section: &'static mut [u8],\n}\n\n#[cfg(not(target_os = \"windows\"))]\nmacro_rules! libc_error_guard {\n    (succeeded?, mmap, $addr:expr, $($arg:expr),*) => {{\n        *$addr = libc::mmap(*$addr, $($arg),*);\n        *$addr != libc::MAP_FAILED\n    }};\n    (succeeded?, $function:ident, $($arg:expr),*) => {\n        libc::$function($($arg),*) == 0\n    };\n    ($function:ident, $($arg:expr),*) => {{\n        const RETRY_COUNT: usize = 3;\n        for i in 0..RETRY_COUNT {\n            if libc_error_guard!(succeeded?, $function, $($arg),*) {\n                break;\n            } else if i + 1 == RETRY_COUNT {\n                let args = vec![$(format!(\"{:?}\", $arg)),*];\n                #[cfg(any(target_os = \"freebsd\", target_os = \"ios\", target_os = \"macos\"))]\n                let errno = *libc::__error();\n                #[cfg(target_os = \"linux\")]\n                let errno = *libc::__errno_location();\n                return Err(EbpfError::LibcInvocationFailed(stringify!($function), args, errno));\n            }\n        }\n    }};\n}\n\nfn round_to_page_size(value: usize, page_size: usize) -> usize {\n    (value + page_size - 1) / page_size * page_size\n}\n\n#[allow(unused_variables)]\nimpl JitProgramSections {\n    fn new<E: UserDefinedError>(pc: usize, code_size: usize) -> Result<Self, EbpfError<E>> {\n        #[cfg(target_os = \"windows\")]\n        {\n            Ok(Self {\n                page_size: 0,\n                pc_section: &mut [],\n                text_section: &mut [],\n            })\n        }\n        #[cfg(not(target_os = \"windows\"))]\n        unsafe {\n            let page_size = libc::sysconf(libc::_SC_PAGESIZE) as usize;\n            let pc_loc_table_size = round_to_page_size(pc * 8, page_size);\n            let over_allocated_code_size = round_to_page_size(code_size, page_size);\n            let mut raw: *mut libc::c_void = std::ptr::null_mut();\n            libc_error_guard!(mmap, &mut raw, pc_loc_table_size + over_allocated_code_size, libc::PROT_READ | libc::PROT_WRITE, libc::MAP_ANONYMOUS | libc::MAP_PRIVATE, 0, 0);\n            Ok(Self {\n                page_size,\n                pc_section: std::slice::from_raw_parts_mut(raw as *mut u64, pc),\n                text_section: std::slice::from_raw_parts_mut(raw.add(pc_loc_table_size) as *mut u8, over_allocated_code_size),\n            })\n        }\n    }\n\n    fn seal<E: UserDefinedError>(&mut self, text_section_usage: usize) -> Result<(), EbpfError<E>> {\n        if self.page_size > 0 {\n            let raw = self.pc_section.as_ptr() as *mut u8;\n            let pc_loc_table_size = round_to_page_size(self.pc_section.len() * 8, self.page_size);\n            let over_allocated_code_size = round_to_page_size(self.text_section.len(), self.page_size);\n            let code_size = round_to_page_size(text_section_usage, self.page_size);\n            #[cfg(not(target_os = \"windows\"))]\n            unsafe {\n                if over_allocated_code_size > code_size {\n                    libc_error_guard!(munmap, raw.add(pc_loc_table_size).add(code_size) as *mut _, over_allocated_code_size - code_size);\n                }\n                std::ptr::write_bytes(raw.add(pc_loc_table_size).add(text_section_usage), 0xcc, code_size - text_section_usage); // Fill with debugger traps\n                self.text_section = std::slice::from_raw_parts_mut(raw.add(pc_loc_table_size), text_section_usage);\n                libc_error_guard!(mprotect, self.pc_section.as_mut_ptr() as *mut _, pc_loc_table_size, libc::PROT_READ);\n                libc_error_guard!(mprotect, self.text_section.as_mut_ptr() as *mut _, code_size, libc::PROT_EXEC | libc::PROT_READ);\n            }\n        }\n        Ok(())\n    }\n\n    pub fn mem_size(&self) -> usize {\n        let pc_loc_table_size = round_to_page_size(self.pc_section.len() * 8, self.page_size);\n        let code_size = round_to_page_size(self.text_section.len(), self.page_size);\n        pc_loc_table_size + code_size\n    }\n}\n\nimpl Drop for JitProgramSections {\n    fn drop(&mut self) {\n        let pc_loc_table_size = round_to_page_size(self.pc_section.len() * 8, self.page_size);\n        let code_size = round_to_page_size(self.text_section.len(), self.page_size);\n        if pc_loc_table_size + code_size > 0 {\n            #[cfg(not(target_os = \"windows\"))]\n            unsafe {\n                libc::munmap(self.pc_section.as_ptr() as *mut _, pc_loc_table_size + code_size);\n            }\n        }\n    }\n}\n\n/// eBPF JIT-compiled program\npub struct JitProgram<E: UserDefinedError, I: InstructionMeter> {\n    /// Holds and manages the protected memory\n    sections: JitProgramSections,\n    /// Call this with JitProgramArgument to execute the compiled code\n    pub main: unsafe fn(&ProgramResult<E>, u64, &JitProgramArgument, &mut I) -> i64,\n}\n\nimpl<E: UserDefinedError, I: InstructionMeter> Debug for JitProgram<E, I> {\n    fn fmt(&self, fmt: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        fmt.write_fmt(format_args!(\"JitProgram {:?}\", &self.main as *const _))\n    }\n}\n\nimpl<E: UserDefinedError, I: InstructionMeter> PartialEq for JitProgram<E, I> {\n    fn eq(&self, other: &Self) -> bool {\n        std::ptr::eq(self.main as *const u8, other.main as *const u8)\n    }\n}\n\nimpl<E: UserDefinedError, I: InstructionMeter> JitProgram<E, I> {\n    pub fn new(executable: &Pin<Box<Executable<E, I>>>) -> Result<Self, EbpfError<E>> {\n        let program = executable.get_text_bytes().1;\n        let mut jit = JitCompiler::new::<E>(program, executable.get_config())?;\n        jit.compile::<E, I>(executable)?;\n        let main = unsafe { mem::transmute(jit.result.text_section.as_ptr()) };\n        Ok(Self {\n            sections: jit.result,\n            main,\n        })\n    }\n\n    pub fn mem_size(&self) -> usize {\n        mem::size_of::<Self>() +\n        self.sections.mem_size()\n    }\n\n    pub fn machine_code_length(&self) -> usize {\n        self.sections.text_section.len()\n    }\n}\n\n// Special values for target_pc in struct Jump\nconst TARGET_PC_LOCAL_ANCHOR: usize = std::usize::MAX - 100;\nconst TARGET_PC_DIV_OVERFLOW: usize = std::usize::MAX - 33;\nconst TARGET_PC_TRACE: usize = std::usize::MAX - 32;\nconst TARGET_PC_SYSCALL: usize = std::usize::MAX - 31;\nconst TARGET_PC_BPF_CALL_PROLOGUE: usize = std::usize::MAX - 30;\nconst TARGET_PC_BPF_CALL_REG: usize = std::usize::MAX - 29;\nconst TARGET_PC_TRANSLATE_PC: usize = std::usize::MAX - 28;\nconst TARGET_PC_TRANSLATE_PC_LOOP: usize = std::usize::MAX - 27;\nconst TARGET_PC_TRANSLATE_MEMORY_ADDRESS: usize = std::usize::MAX - 26;\nconst TARGET_PC_MEMORY_ACCESS_VIOLATION: usize = std::usize::MAX - 18;\nconst TARGET_PC_CALL_EXCEEDED_MAX_INSTRUCTIONS: usize = std::usize::MAX - 10;\nconst TARGET_PC_CALL_DEPTH_EXCEEDED: usize = std::usize::MAX - 9;\nconst TARGET_PC_CALL_OUTSIDE_TEXT_SEGMENT: usize = std::usize::MAX - 8;\nconst TARGET_PC_CALLX_UNSUPPORTED_INSTRUCTION: usize = std::usize::MAX - 7;\nconst TARGET_PC_CALL_UNSUPPORTED_INSTRUCTION: usize = std::usize::MAX - 6;\nconst TARGET_PC_DIV_BY_ZERO: usize = std::usize::MAX - 5;\nconst TARGET_PC_EXCEPTION_AT: usize = std::usize::MAX - 4;\nconst TARGET_PC_RUST_EXCEPTION: usize = std::usize::MAX - 3;\nconst TARGET_PC_EXIT: usize = std::usize::MAX - 2;\nconst TARGET_PC_EPILOGUE: usize = std::usize::MAX - 1;\n\nconst REGISTER_MAP: [u8; 11] = [\n    CALLER_SAVED_REGISTERS[0],\n    ARGUMENT_REGISTERS[1],\n    ARGUMENT_REGISTERS[2],\n    ARGUMENT_REGISTERS[3],\n    ARGUMENT_REGISTERS[4],\n    ARGUMENT_REGISTERS[5],\n    CALLEE_SAVED_REGISTERS[2],\n    CALLEE_SAVED_REGISTERS[3],\n    CALLEE_SAVED_REGISTERS[4],\n    CALLEE_SAVED_REGISTERS[5],\n    CALLEE_SAVED_REGISTERS[1],\n];\n\n// Special registers:\n//     ARGUMENT_REGISTERS[0]  RDI  BPF program counter limit (used by instruction meter)\n// CALLER_SAVED_REGISTERS[8]  R11  Scratch register\n// CALLER_SAVED_REGISTERS[7]  R10  Constant pointer to JitProgramArgument (also scratch register for exception handling)\n// CALLEE_SAVED_REGISTERS[0]  RBP  Constant pointer to inital RSP - 8\n\n#[inline]\npub fn emit<T, E: UserDefinedError>(jit: &mut JitCompiler, data: T) -> Result<(), EbpfError<E>> {\n    let size = mem::size_of::<T>() as usize;\n    if jit.offset_in_text_section + size > jit.result.text_section.len() {\n        return Err(EbpfError::ExhausedTextSegment(jit.pc));\n    }\n    unsafe {\n        #[allow(clippy::cast_ptr_alignment)]\n        let ptr = jit.result.text_section.as_ptr().add(jit.offset_in_text_section) as *mut T;\n        *ptr = data as T;\n    }\n    jit.offset_in_text_section += size;\n    Ok(())\n}\n\npub fn emit_variable_length<E: UserDefinedError>(jit: &mut JitCompiler, size: OperandSize, data: u64) -> Result<(), EbpfError<E>> {\n    match size {\n        OperandSize::S0 => Ok(()),\n        OperandSize::S8 => emit::<u8, E>(jit, data as u8),\n        OperandSize::S16 => emit::<u16, E>(jit, data as u16),\n        OperandSize::S32 => emit::<u32, E>(jit, data as u32),\n        OperandSize::S64 => emit::<u64, E>(jit, data),\n    }\n}\n\n#[derive(PartialEq, Eq, Copy, Clone, Debug)]\npub enum OperandSize {\n    S0  = 0,\n    S8  = 8,\n    S16 = 16,\n    S32 = 32,\n    S64 = 64,\n}\n\n#[inline]\nfn emit_sanitized_load_immediate<E: UserDefinedError>(jit: &mut JitCompiler, size: OperandSize, destination: u8, value: i64) -> Result<(), EbpfError<E>> {\n    match size {\n        OperandSize::S32 => {\n            let key: i32 = jit.diversification_rng.gen();\n            X86Instruction::load_immediate(size, destination, (value as i32).wrapping_sub(key) as i64).emit(jit)?;\n            emit_alu(jit, size, 0x81, 0, destination, key as i64, None)\n        },\n        OperandSize::S64 if destination == R11 => {\n            let key: i64 = jit.diversification_rng.gen();\n            let lower_key = key as i32 as i64;\n            let upper_key = (key >> 32) as i32 as i64;\n            X86Instruction::load_immediate(size, destination, value.wrapping_sub(lower_key).rotate_right(32).wrapping_sub(upper_key)).emit(jit)?;\n            emit_alu(jit, size, 0x81, 0, destination, upper_key, None)?; // wrapping_add(upper_key)\n            emit_alu(jit, size, 0xc1, 1, destination, 32, None)?; // rotate_right(32)\n            emit_alu(jit, size, 0x81, 0, destination, lower_key, None) // wrapping_add(lower_key)\n        },\n        OperandSize::S64 if value >= std::i32::MIN as i64 && value <= std::i32::MAX as i64 => {\n            let key = jit.diversification_rng.gen::<i32>() as i64;\n            X86Instruction::load_immediate(size, destination, value.wrapping_sub(key)).emit(jit)?;\n            emit_alu(jit, size, 0x81, 0, destination, key, None)\n        },\n        OperandSize::S64 => {\n            let key: i64 = jit.diversification_rng.gen();\n            X86Instruction::load_immediate(size, destination, value.wrapping_sub(key)).emit(jit)?;\n            X86Instruction::load_immediate(size, R11, key).emit(jit)?;\n            emit_alu(jit, size, 0x01, R11, destination, 0, None)\n        },\n        _ => {\n            #[cfg(debug_assertions)]\n            unreachable!();\n            Ok(())\n        }\n    }\n}\n\n#[inline]\nfn emit_alu<E: UserDefinedError>(jit: &mut JitCompiler, size: OperandSize, opcode: u8, source: u8, destination: u8, immediate: i64, indirect: Option<X86IndirectAccess>) -> Result<(), EbpfError<E>> {\n    X86Instruction {\n        size,\n        opcode,\n        first_operand: source,\n        second_operand: destination,\n        immediate_size: match opcode {\n            0xc1 => OperandSize::S8,\n            0x81 => OperandSize::S32,\n            0xf7 if source == 0 => OperandSize::S32,\n            _ => OperandSize::S0,\n        },\n        immediate,\n        indirect,\n        ..X86Instruction::default()\n    }.emit(jit)\n}\n\n#[inline]\nfn should_sanitize_constant(jit: &JitCompiler, value: i64) -> bool {\n    if !jit.config.sanitize_user_provided_values {\n        return false;\n    }\n\n    match value as u64 {\n        0xFFFF\n        | 0xFFFFFF\n        | 0xFFFFFFFF\n        | 0xFFFFFFFFFF\n        | 0xFFFFFFFFFFFF\n        | 0xFFFFFFFFFFFFFF\n        | 0xFFFFFFFFFFFFFFFF => false,\n        v if v <= 0xFF => false,\n        v if !v <= 0xFF => false,\n        _ => true\n    }\n}\n\n#[inline]\nfn emit_sanitized_alu<E: UserDefinedError>(jit: &mut JitCompiler, size: OperandSize, opcode: u8, opcode_extension: u8, destination: u8, immediate: i64) -> Result<(), EbpfError<E>> {\n    if should_sanitize_constant(jit, immediate) {\n        emit_sanitized_load_immediate(jit, size, R11, immediate)?;\n        emit_alu(jit, size, opcode, R11, destination, immediate, None)\n    } else {\n        emit_alu(jit, size, 0x81, opcode_extension, destination, immediate, None)\n    }\n}\n\n#[inline]\nfn emit_jump_offset<E: UserDefinedError>(jit: &mut JitCompiler, target_pc: usize) -> Result<(), EbpfError<E>> {\n    jit.text_section_jumps.push(Jump { location: jit.offset_in_text_section, target_pc });\n    emit::<u32, E>(jit, 0)\n}\n\n#[inline]\nfn emit_jcc<E: UserDefinedError>(jit: &mut JitCompiler, code: u8, target_pc: usize) -> Result<(), EbpfError<E>> {\n    emit::<u8, E>(jit, 0x0f)?;\n    emit::<u8, E>(jit, code)?;\n    emit_jump_offset(jit, target_pc)\n}\n\n#[inline]\nfn emit_jmp<E: UserDefinedError>(jit: &mut JitCompiler, target_pc: usize) -> Result<(), EbpfError<E>> {\n    emit::<u8, E>(jit, 0xe9)?;\n    emit_jump_offset(jit, target_pc)\n}\n\n#[inline]\nfn emit_call<E: UserDefinedError>(jit: &mut JitCompiler, target_pc: usize) -> Result<(), EbpfError<E>> {\n    emit::<u8, E>(jit, 0xe8)?;\n    emit_jump_offset(jit, target_pc)\n}\n\n#[inline]\nfn set_anchor(jit: &mut JitCompiler, target: usize) {\n    jit.handler_anchors.insert(target, jit.offset_in_text_section);\n}\n\n/// Indices of slots inside the struct at inital RSP\n#[repr(C)]\nenum EnvironmentStackSlot {\n    /// The 6 CALLEE_SAVED_REGISTERS\n    LastSavedRegister = 5,\n    /// The current call depth.\n    ///\n    /// Incremented on calls and decremented on exits. It's used to enforce\n    /// config.max_call_depth and to know when to terminate execution.\n    CallDepth = 6,\n    /// BPF frame pointer (REGISTER_MAP[FRAME_PTR_REG]).\n    BpfFramePtr = 7,\n    /// The BPF stack pointer (r11). Only used when config.dynamic_stack_frames=true.\n    ///\n    /// The stack pointer isn't exposed as an actual register. Only sub and add\n    /// instructions (typically generated by the LLVM backend) are allowed to\n    /// access it. Its value is only stored in this slot and therefore the\n    /// register is not tracked in REGISTER_MAP.\n    BpfStackPtr = 8,\n    /// Constant pointer to optional typed return value\n    OptRetValPtr = 9,\n    /// Last return value of instruction_meter.get_remaining()\n    PrevInsnMeter = 10,\n    /// Constant pointer to instruction_meter\n    InsnMeterPtr = 11,\n    /// CPU cycles accumulated by the stop watch\n    StopwatchNumerator = 12,\n    /// Number of times the stop watch was used\n    StopwatchDenominator = 13,\n    /// Bumper for size_of\n    SlotCount = 14,\n}\n\nfn slot_on_environment_stack(jit: &JitCompiler, slot: EnvironmentStackSlot) -> i32 {\n    -8 * (slot as i32 + jit.environment_stack_key)\n}\n\n#[allow(dead_code)]\n#[inline]\nfn emit_stopwatch<E: UserDefinedError>(jit: &mut JitCompiler, begin: bool) -> Result<(), EbpfError<E>> {\n    jit.stopwatch_is_active = true;\n    X86Instruction::push(RDX, None).emit(jit)?;\n    X86Instruction::push(RAX, None).emit(jit)?;\n    X86Instruction::fence(FenceType::Load).emit(jit)?; // lfence\n    X86Instruction::cycle_count().emit(jit)?; // rdtsc\n    X86Instruction::fence(FenceType::Load).emit(jit)?; // lfence\n    emit_alu(jit, OperandSize::S64, 0xc1, 4, RDX, 32, None)?; // RDX <<= 32;\n    emit_alu(jit, OperandSize::S64, 0x09, RDX, RAX, 0, None)?; // RAX |= RDX;\n    if begin {\n        emit_alu(jit, OperandSize::S64, 0x29, RAX, RBP, 0, Some(X86IndirectAccess::Offset(slot_on_environment_stack(jit, EnvironmentStackSlot::StopwatchNumerator))))?; // *numerator -= RAX;\n    } else {\n        emit_alu(jit, OperandSize::S64, 0x01, RAX, RBP, 0, Some(X86IndirectAccess::Offset(slot_on_environment_stack(jit, EnvironmentStackSlot::StopwatchNumerator))))?; // *numerator += RAX;\n        emit_alu(jit, OperandSize::S64, 0x81, 0, RBP, 1, Some(X86IndirectAccess::Offset(slot_on_environment_stack(jit, EnvironmentStackSlot::StopwatchDenominator))))?; // *denominator += 1;\n    }\n    X86Instruction::pop(RAX).emit(jit)?;\n    X86Instruction::pop(RDX).emit(jit)\n}\n\n/* Explaination of the Instruction Meter\n\n    The instruction meter serves two purposes: First, measure how many BPF instructions are\n    executed (profiling) and second, limit this number by stopping the program with an exception\n    once a given threshold is reached (validation). One approach would be to increment and\n    validate the instruction meter before each instruction. However, this would heavily impact\n    performance. Thus, we only profile and validate the instruction meter at branches.\n\n    For this, we implicitly sum up all the instructions between two branches.\n    It is easy to know the end of such a slice of instructions, but how do we know where it\n    started? There could be multiple ways to jump onto a path which all lead to the same final\n    branch. This is, where the integral technique comes in. The program is basically a sequence\n    of instructions with the x-axis being the program counter (short \"pc\"). The cost function is\n    a constant function which returns one for every point on the x axis. Now, the instruction\n    meter needs to calculate the definite integral of the cost function between the start and the\n    end of the current slice of instructions. For that we need the indefinite integral of the cost\n    function. Fortunately, the derivative of the pc is the cost function (it increases by one for\n    every instruction), thus the pc is an antiderivative of the the cost function and a valid\n    indefinite integral. So, to calculate an definite integral of the cost function, we just need\n    to subtract the start pc from the end pc of the slice. This difference can then be subtracted\n    from the remaining instruction counter until it goes below zero at which point it reaches\n    the instruction meter limit. Ok, but how do we know the start of the slice at the end?\n\n    The trick is: We do not need to know. As subtraction and addition are associative operations,\n    we can reorder them, even beyond the current branch. Thus, we can simply account for the\n    amount the start will subtract at the next branch by already adding that to the remaining\n    instruction counter at the current branch. So, every branch just subtracts its current pc\n    (the end of the slice) and adds the target pc (the start of the next slice) to the remaining\n    instruction counter. This way, no branch needs to know the pc of the last branch explicitly.\n    Another way to think about this trick is as follows: The remaining instruction counter now\n    measures what the maximum pc is, that we can reach with the remaining budget after the last\n    branch.\n\n    One problem are conditional branches. There are basically two ways to handle them: Either,\n    only do the profiling if the branch is taken, which requires two jumps (one for the profiling\n    and one to get to the target pc). Or, always profile it as if the jump to the target pc was\n    taken, but then behind the conditional branch, undo the profiling (as it was not taken). We\n    use the second method and the undo profiling is the same as the normal profiling, just with\n    reversed plus and minus signs.\n\n    Another special case to keep in mind are return instructions. They would require us to know\n    the return address (target pc), but in the JIT we already converted that to be a host address.\n    Of course, one could also save the BPF return address on the stack, but an even simpler\n    solution exists: Just count as if you were jumping to an specific target pc before the exit,\n    and then after returning use the undo profiling. The trick is, that the undo profiling now\n    has the current pc which is the BPF return address. The virtual target pc we count towards\n    and undo again can be anything, so we just set it to zero.\n*/\n\n#[inline]\nfn emit_validate_instruction_count<E: UserDefinedError>(jit: &mut JitCompiler, exclusive: bool, pc: Option<usize>) -> Result<(), EbpfError<E>> {\n    if let Some(pc) = pc {\n        jit.last_instruction_meter_validation_pc = pc;\n        X86Instruction::cmp_immediate(OperandSize::S64, ARGUMENT_REGISTERS[0], pc as i64 + 1, None).emit(jit)?;\n    } else {\n        X86Instruction::cmp(OperandSize::S64, R11, ARGUMENT_REGISTERS[0], None).emit(jit)?;\n    }\n    emit_jcc(jit, if exclusive { 0x82 } else { 0x86 }, TARGET_PC_CALL_EXCEEDED_MAX_INSTRUCTIONS)\n}\n\n#[inline]\nfn emit_profile_instruction_count<E: UserDefinedError>(jit: &mut JitCompiler, target_pc: Option<usize>) -> Result<(), EbpfError<E>> {\n    match target_pc {\n        Some(target_pc) => {\n            emit_alu(jit, OperandSize::S64, 0x81, 0, ARGUMENT_REGISTERS[0], target_pc as i64 - jit.pc as i64 - 1, None)?; // instruction_meter += target_pc - (jit.pc + 1);\n        },\n        None => {\n            emit_alu(jit, OperandSize::S64, 0x81, 5, ARGUMENT_REGISTERS[0], jit.pc as i64 + 1, None)?; // instruction_meter -= jit.pc + 1;\n            emit_alu(jit, OperandSize::S64, 0x01, R11, ARGUMENT_REGISTERS[0], jit.pc as i64, None)?; // instruction_meter += target_pc;\n        },\n    }\n    Ok(())\n}\n\n#[inline]\nfn emit_validate_and_profile_instruction_count<E: UserDefinedError>(jit: &mut JitCompiler, exclusive: bool, target_pc: Option<usize>) -> Result<(), EbpfError<E>> {\n    if jit.config.enable_instruction_meter {\n        emit_validate_instruction_count(jit, exclusive, Some(jit.pc))?;\n        emit_profile_instruction_count(jit, target_pc)?;\n    }\n    Ok(())\n}\n\n#[inline]\nfn emit_undo_profile_instruction_count<E: UserDefinedError>(jit: &mut JitCompiler, target_pc: usize) -> Result<(), EbpfError<E>> {\n    if jit.config.enable_instruction_meter {\n        emit_alu(jit, OperandSize::S64, 0x81, 0, ARGUMENT_REGISTERS[0], jit.pc as i64 + 1 - target_pc as i64, None)?; // instruction_meter += (jit.pc + 1) - target_pc;\n    }\n    Ok(())\n}\n\n#[inline]\nfn emit_profile_instruction_count_finalize<E: UserDefinedError>(jit: &mut JitCompiler, store_pc_in_exception: bool) -> Result<(), EbpfError<E>> {\n    if jit.config.enable_instruction_meter || store_pc_in_exception {\n        emit_alu(jit, OperandSize::S64, 0x81, 0, R11, 1, None)?; // R11 += 1;\n    }\n    if jit.config.enable_instruction_meter {\n        emit_alu(jit, OperandSize::S64, 0x29, R11, ARGUMENT_REGISTERS[0], 0, None)?; // instruction_meter -= pc + 1;\n    }\n    if store_pc_in_exception {\n        X86Instruction::load(OperandSize::S64, RBP, R10, X86IndirectAccess::Offset(slot_on_environment_stack(jit, EnvironmentStackSlot::OptRetValPtr))).emit(jit)?;\n        X86Instruction::store_immediate(OperandSize::S64, R10, X86IndirectAccess::Offset(0), 1).emit(jit)?; // is_err = true;\n        emit_alu(jit, OperandSize::S64, 0x81, 0, R11, ebpf::ELF_INSN_DUMP_OFFSET as i64 - 1, None)?;\n        X86Instruction::store(OperandSize::S64, R11, R10, X86IndirectAccess::Offset(16)).emit(jit)?; // pc = jit.pc + ebpf::ELF_INSN_DUMP_OFFSET;\n    }\n    Ok(())\n}\n\n#[inline]\nfn emit_conditional_branch_reg<E: UserDefinedError>(jit: &mut JitCompiler, op: u8, bitwise: bool, first_operand: u8, second_operand: u8, target_pc: usize) -> Result<(), EbpfError<E>> {\n    emit_validate_and_profile_instruction_count(jit, false, Some(target_pc))?;\n    if bitwise { // Logical\n        X86Instruction::test(OperandSize::S64, first_operand, second_operand, None).emit(jit)?;\n    } else { // Arithmetic\n        X86Instruction::cmp(OperandSize::S64, first_operand, second_operand, None).emit(jit)?;\n    }\n    X86Instruction::load_immediate(OperandSize::S64, R11, target_pc as i64).emit(jit)?;\n    emit_jcc(jit, op, target_pc)?;\n    emit_undo_profile_instruction_count(jit, target_pc)\n}\n\n#[inline]\nfn emit_conditional_branch_imm<E: UserDefinedError>(jit: &mut JitCompiler, op: u8, bitwise: bool, immediate: i64, second_operand: u8, target_pc: usize) -> Result<(), EbpfError<E>> {\n    emit_validate_and_profile_instruction_count(jit, false, Some(target_pc))?;\n    if should_sanitize_constant(jit, immediate) {\n        emit_sanitized_load_immediate(jit, OperandSize::S64, R11, immediate)?;\n        if bitwise { // Logical\n            X86Instruction::test(OperandSize::S64, R11, second_operand, None).emit(jit)?;\n        } else { // Arithmetic\n            X86Instruction::cmp(OperandSize::S64, R11, second_operand, None).emit(jit)?;\n        }\n    } else if bitwise { // Logical\n        X86Instruction::test_immediate(OperandSize::S64, second_operand, immediate, None).emit(jit)?;\n    } else { // Arithmetic\n        X86Instruction::cmp_immediate(OperandSize::S64, second_operand, immediate, None).emit(jit)?;\n    }\n    X86Instruction::load_immediate(OperandSize::S64, R11, target_pc as i64).emit(jit)?;\n    emit_jcc(jit, op, target_pc)?;\n    emit_undo_profile_instruction_count(jit, target_pc)\n}\n\nenum Value {\n    Register(u8),\n    RegisterIndirect(u8, i32, bool),\n    RegisterPlusConstant32(u8, i32, bool),\n    RegisterPlusConstant64(u8, i64, bool),\n    Constant64(i64, bool),\n}\n\n#[inline]\nfn emit_bpf_call<E: UserDefinedError>(jit: &mut JitCompiler, dst: Value) -> Result<(), EbpfError<E>> {\n    // Store PC in case the bounds check fails\n    X86Instruction::load_immediate(OperandSize::S64, R11, jit.pc as i64).emit(jit)?;\n\n    emit_call(jit, TARGET_PC_BPF_CALL_PROLOGUE)?;\n\n    match dst {\n        Value::Register(reg) => {\n            // Move vm target_address into RAX\n            X86Instruction::push(REGISTER_MAP[0], None).emit(jit)?;\n            if reg != REGISTER_MAP[0] {\n                X86Instruction::mov(OperandSize::S64, reg, REGISTER_MAP[0]).emit(jit)?;\n            }\n\n            emit_call(jit, TARGET_PC_BPF_CALL_REG)?;\n\n            emit_validate_and_profile_instruction_count(jit, false, None)?;\n            X86Instruction::mov(OperandSize::S64, REGISTER_MAP[0], R11).emit(jit)?; // Save target_pc\n            X86Instruction::pop(REGISTER_MAP[0]).emit(jit)?; // Restore RAX\n            X86Instruction::call_reg(R11, None).emit(jit)?; // callq *%r11\n        },\n        Value::Constant64(target_pc, user_provided) => {\n            debug_assert!(!user_provided);\n            emit_validate_and_profile_instruction_count(jit, false, Some(target_pc as usize))?;\n            X86Instruction::load_immediate(OperandSize::S64, R11, target_pc as i64).emit(jit)?;\n            emit_call(jit, target_pc as usize)?;\n        },\n        _ => {\n            #[cfg(debug_assertions)]\n            unreachable!();\n        }\n    }\n\n    emit_undo_profile_instruction_count(jit, 0)?;\n\n    // Restore the previous frame pointer\n    X86Instruction::pop(REGISTER_MAP[FRAME_PTR_REG]).emit(jit)?;\n    let frame_ptr_access = X86IndirectAccess::Offset(slot_on_environment_stack(jit, EnvironmentStackSlot::BpfFramePtr));\n    X86Instruction::store(OperandSize::S64, REGISTER_MAP[FRAME_PTR_REG], RBP, frame_ptr_access).emit(jit)?;\n    for reg in REGISTER_MAP.iter().skip(FIRST_SCRATCH_REG).take(SCRATCH_REGS).rev() {\n        X86Instruction::pop(*reg).emit(jit)?;\n    }\n    Ok(())\n}\n\nstruct Argument {\n    index: usize,\n    value: Value,\n}\n\nimpl Argument {\n    fn is_stack_argument(&self) -> bool {\n        self.index >= ARGUMENT_REGISTERS.len()\n    }\n\n    fn get_argument_register(&self) -> u8 {\n        ARGUMENT_REGISTERS[self.index]\n    }\n\n    fn emit_pass<E: UserDefinedError>(&self, jit: &mut JitCompiler) -> Result<(), EbpfError<E>> {\n        let is_stack_argument = self.is_stack_argument();\n        let dst = if is_stack_argument {\n            R11\n        } else {\n            self.get_argument_register()\n        };\n        match self.value {\n            Value::Register(reg) => {\n                if is_stack_argument {\n                    X86Instruction::push(reg, None).emit(jit)?;\n                } else if reg != dst {\n                    X86Instruction::mov(OperandSize::S64, reg, dst).emit(jit)?;\n                }\n            },\n            Value::RegisterIndirect(reg, offset, user_provided) => {\n                debug_assert!(!user_provided);\n                if is_stack_argument {\n                    X86Instruction::push(reg, Some(X86IndirectAccess::Offset(offset))).emit(jit)?;\n                } else {\n                    X86Instruction::load(OperandSize::S64, reg, dst, X86IndirectAccess::Offset(offset)).emit(jit)?;\n                }\n            },\n            Value::RegisterPlusConstant32(reg, offset, user_provided) => {\n                debug_assert!(!user_provided);\n                if is_stack_argument {\n                    X86Instruction::push(reg, None).emit(jit)?;\n                    emit_alu(jit, OperandSize::S64, 0x81, 0, RSP, offset as i64, Some(X86IndirectAccess::OffsetIndexShift(0, RSP, 0)))?;\n                } else {\n                    X86Instruction::lea(OperandSize::S64, reg, dst, Some(X86IndirectAccess::Offset(offset))).emit(jit)?;\n                }\n            },\n            Value::RegisterPlusConstant64(reg, offset, user_provided) => {\n                debug_assert!(!user_provided);\n                if is_stack_argument {\n                    X86Instruction::push(reg, None).emit(jit)?;\n                    emit_alu(jit, OperandSize::S64, 0x81, 0, RSP, offset, Some(X86IndirectAccess::OffsetIndexShift(0, RSP, 0)))?;\n                } else {\n                    X86Instruction::load_immediate(OperandSize::S64, dst, offset).emit(jit)?;\n                    emit_alu(jit, OperandSize::S64, 0x01, reg, dst, 0, None)?;\n                }\n            },\n            Value::Constant64(value, user_provided) => {\n                debug_assert!(!user_provided && !is_stack_argument);\n                X86Instruction::load_immediate(OperandSize::S64, dst, value).emit(jit)?;\n            },\n        }\n        Ok(())\n    }\n}\n\n#[inline]\nfn emit_rust_call<E: UserDefinedError>(jit: &mut JitCompiler, dst: Value, arguments: &[Argument], result_reg: Option<u8>, check_exception: bool) -> Result<(), EbpfError<E>> {\n    let mut saved_registers = CALLER_SAVED_REGISTERS.to_vec();\n    if let Some(reg) = result_reg {\n        let dst = saved_registers.iter().position(|x| *x == reg);\n        debug_assert!(dst.is_some());\n        if let Some(dst) = dst {\n            saved_registers.remove(dst);\n        }\n    }\n\n    // Save registers on stack\n    for reg in saved_registers.iter() {\n        X86Instruction::push(*reg, None).emit(jit)?;\n    }\n\n    // Pass arguments\n    let mut stack_arguments = 0;\n    for argument in arguments {\n        if argument.is_stack_argument() {\n            stack_arguments += 1;\n        }\n        argument.emit_pass(jit)?;\n    }\n\n    match dst {\n        Value::Register(reg) => {\n            X86Instruction::call_reg(reg, None).emit(jit)?;\n        },\n        Value::Constant64(value, user_provided) => {\n            debug_assert!(!user_provided);\n            X86Instruction::load_immediate(OperandSize::S64, RAX, value).emit(jit)?;\n            X86Instruction::call_reg(RAX, None).emit(jit)?;\n        },\n        _ => {\n            #[cfg(debug_assertions)]\n            unreachable!();\n        }\n    }\n\n    // Save returned value in result register\n    if let Some(reg) = result_reg {\n        X86Instruction::mov(OperandSize::S64, RAX, reg).emit(jit)?;\n    }\n\n    // Restore registers from stack\n    emit_alu(jit, OperandSize::S64, 0x81, 0, RSP, stack_arguments * 8, None)?;\n    for reg in saved_registers.iter().rev() {\n        X86Instruction::pop(*reg).emit(jit)?;\n    }\n\n    if check_exception {\n        // Test if result indicates that an error occured\n        X86Instruction::load(OperandSize::S64, RBP, R11, X86IndirectAccess::Offset(slot_on_environment_stack(jit, EnvironmentStackSlot::OptRetValPtr))).emit(jit)?;\n        X86Instruction::cmp_immediate(OperandSize::S64, R11, 0, Some(X86IndirectAccess::Offset(0))).emit(jit)?;\n    }\n    Ok(())\n}\n\n#[inline]\nfn emit_address_translation<E: UserDefinedError>(jit: &mut JitCompiler, host_addr: u8, vm_addr: Value, len: u64, access_type: AccessType) -> Result<(), EbpfError<E>> {\n    match vm_addr {\n        Value::RegisterPlusConstant64(reg, constant, user_provided) => {\n            if user_provided && should_sanitize_constant(jit, constant) {\n                emit_sanitized_load_immediate(jit, OperandSize::S64, R11, constant)?;\n            } else {\n                X86Instruction::load_immediate(OperandSize::S64, R11, constant).emit(jit)?;\n            }\n            emit_alu(jit, OperandSize::S64, 0x01, reg, R11, 0, None)?;\n        },\n        Value::Constant64(constant, user_provided) => {\n            if user_provided && should_sanitize_constant(jit, constant) {\n                emit_sanitized_load_immediate(jit, OperandSize::S64, R11, constant)?;\n            } else {\n                X86Instruction::load_immediate(OperandSize::S64, R11, constant).emit(jit)?;\n            }\n        },\n        _ => {\n            #[cfg(debug_assertions)]\n            unreachable!();\n        },\n    }\n    emit_call(jit, TARGET_PC_TRANSLATE_MEMORY_ADDRESS + len.trailing_zeros() as usize + 4 * (access_type as usize))?;\n    X86Instruction::mov(OperandSize::S64, R11, host_addr).emit(jit)\n}\n\nfn emit_shift<E: UserDefinedError>(jit: &mut JitCompiler, size: OperandSize, opcode_extension: u8, source: u8, destination: u8, immediate: Option<i64>) -> Result<(), EbpfError<E>> {\n    if let Some(immediate) = immediate {\n        if should_sanitize_constant(jit, immediate) {\n            emit_sanitized_load_immediate(jit, OperandSize::S32, source, immediate)?;\n        } else {\n            return emit_alu(jit, size, 0xc1, opcode_extension, destination, immediate, None);\n        }\n    }\n    if size == OperandSize::S32 {\n        emit_alu(jit, OperandSize::S32, 0x81, 4, destination, -1, None)?; // Mask to 32 bit\n    }\n    if source == RCX {\n        if destination == RCX {\n            emit_alu(jit, size, 0xd3, opcode_extension, destination, 0, None)\n        } else {\n            X86Instruction::push(RCX, None).emit(jit)?;\n            emit_alu(jit, size, 0xd3, opcode_extension, destination, 0, None)?;\n            X86Instruction::pop(RCX).emit(jit)\n        }\n    } else if destination == RCX {\n        if source != R11 {\n            X86Instruction::push(source, None).emit(jit)?;\n        }\n        X86Instruction::xchg(OperandSize::S64, source, RCX, None).emit(jit)?;\n        emit_alu(jit, size, 0xd3, opcode_extension, source, 0, None)?;\n        X86Instruction::mov(OperandSize::S64, source, RCX).emit(jit)?;\n        if source != R11 {\n            X86Instruction::pop(source).emit(jit)?;\n        }\n        Ok(())\n    } else {\n        X86Instruction::push(RCX, None).emit(jit)?;\n        X86Instruction::mov(OperandSize::S64, source, RCX).emit(jit)?;\n        emit_alu(jit, size, 0xd3, opcode_extension, destination, 0, None)?;\n        X86Instruction::pop(RCX).emit(jit)\n    }\n}\n\nfn emit_muldivmod<E: UserDefinedError>(jit: &mut JitCompiler, opc: u8, src: u8, dst: u8, imm: Option<i64>) -> Result<(), EbpfError<E>> {\n    let mul = (opc & ebpf::BPF_ALU_OP_MASK) == (ebpf::MUL32_IMM & ebpf::BPF_ALU_OP_MASK);\n    let div = (opc & ebpf::BPF_ALU_OP_MASK) == (ebpf::DIV32_IMM & ebpf::BPF_ALU_OP_MASK);\n    let sdiv = (opc & ebpf::BPF_ALU_OP_MASK) == (ebpf::SDIV32_IMM & ebpf::BPF_ALU_OP_MASK);\n    let modrm = (opc & ebpf::BPF_ALU_OP_MASK) == (ebpf::MOD32_IMM & ebpf::BPF_ALU_OP_MASK);\n    let size = if (opc & ebpf::BPF_CLS_MASK) == ebpf::BPF_ALU64 { OperandSize::S64 } else { OperandSize::S32 };\n\n    // subtracting offset_in_text_section from TARGET_PC_LOCAL_ANCHOR gives us a\n    // unique local anchor\n    let sdiv_anchor =  if sdiv { TARGET_PC_LOCAL_ANCHOR - jit.offset_in_text_section } else { 0 };\n\n    if (div || sdiv || modrm) && imm.is_none() {\n        // Save pc\n        X86Instruction::load_immediate(OperandSize::S64, R11, jit.pc as i64).emit(jit)?;\n        X86Instruction::test(size, src, src, None).emit(jit)?; // src == 0\n        emit_jcc(jit, 0x84, TARGET_PC_DIV_BY_ZERO)?;\n\n    }\n\n    // sdiv overflows with MIN / -1. If we have an immediate and it's not -1, we\n    // don't need any checks.\n    if sdiv && imm.unwrap_or(-1) == -1 {\n        if imm.is_none() {\n            // if src != -1, we can skip checking dst\n            X86Instruction::cmp_immediate(size, src, -1, None).emit(jit)?;\n            emit_jcc(jit, 0x85, sdiv_anchor)?;\n        }\n\n        // if dst != MIN, we're not going to overflow\n        X86Instruction::load_immediate(size, R11, if size == OperandSize::S64 { i64::MIN } else { i32::MIN as i64 }).emit(jit)?;\n        X86Instruction::cmp(size, dst, R11, None).emit(jit)?;\n        emit_jcc(jit, 0x85, sdiv_anchor)?;\n\n        // MIN / -1, raise EbpfError::DivideOverflow(pc)\n        X86Instruction::load_immediate(OperandSize::S64, R11, jit.pc as i64).emit(jit)?;\n        emit_jmp(jit, TARGET_PC_DIV_OVERFLOW)?;\n    }\n\n    if sdiv {\n        set_anchor(jit, sdiv_anchor);\n    }\n\n    if dst != RAX {\n        X86Instruction::push(RAX, None).emit(jit)?;\n    }\n    if dst != RDX {\n        X86Instruction::push(RDX, None).emit(jit)?;\n    }\n\n    if let Some(imm) = imm {\n        if should_sanitize_constant(jit, imm) {\n            emit_sanitized_load_immediate(jit, OperandSize::S64, R11, imm)?;\n        } else {\n            X86Instruction::load_immediate(OperandSize::S64, R11, imm).emit(jit)?;\n        }\n    } else {\n        X86Instruction::mov(OperandSize::S64, src, R11).emit(jit)?;\n    }\n\n    if dst != RAX {\n        X86Instruction::mov(OperandSize::S64, dst, RAX).emit(jit)?;\n    }\n\n    if div || modrm {\n        // xor %edx,%edx\n        emit_alu(jit, size, 0x31, RDX, RDX, 0, None)?;\n    } else if sdiv {\n        // cdq or cqo depending on operand size\n        X86Instruction {\n            size,\n            opcode: 0x99,\n            modrm: false,\n            ..X86Instruction::default()\n        }.emit(jit)?;\n    }\n\n    emit_alu(jit, size, 0xf7, if mul { 4 } else if sdiv { 7 } else { 6 }, R11, 0, None)?;\n\n    if dst != RDX {\n        if modrm {\n            X86Instruction::mov(OperandSize::S64, RDX, dst).emit(jit)?;\n        }\n        X86Instruction::pop(RDX).emit(jit)?;\n    }\n    if dst != RAX {\n        if div || sdiv || mul {\n            X86Instruction::mov(OperandSize::S64, RAX, dst).emit(jit)?;\n        }\n        X86Instruction::pop(RAX).emit(jit)?;\n    }\n\n    if size == OperandSize::S32 && opc & ebpf::BPF_ALU_OP_MASK == ebpf::BPF_MUL {\n        X86Instruction::sign_extend_i32_to_i64(dst, dst).emit(jit)?;\n    }\n    Ok(())\n}\n\n#[inline]\nfn emit_set_exception_kind<E: UserDefinedError>(jit: &mut JitCompiler, err: EbpfError<E>) -> Result<(), EbpfError<E>> {\n    let err = Result::<u64, EbpfError<E>>::Err(err);\n    let err_kind = unsafe { *(&err as *const _ as *const u64).offset(1) };\n    X86Instruction::load(OperandSize::S64, RBP, R10, X86IndirectAccess::Offset(slot_on_environment_stack(jit, EnvironmentStackSlot::OptRetValPtr))).emit(jit)?;\n    X86Instruction::store_immediate(OperandSize::S64, R10, X86IndirectAccess::Offset(8), err_kind as i64).emit(jit)\n}\n\n#[derive(Debug)]\nstruct Jump {\n    location: usize,\n    target_pc: usize,\n}\nimpl Jump {\n    fn get_target_offset(&self, jit: &JitCompiler) -> u64 {\n        match jit.handler_anchors.get(&self.target_pc) {\n            Some(target) => *target as u64,\n            None         => jit.result.pc_section[self.target_pc]\n        }\n    }\n}\n\npub struct JitCompiler {\n    result: JitProgramSections,\n    pc_section_jumps: Vec<Jump>,\n    text_section_jumps: Vec<Jump>,\n    offset_in_text_section: usize,\n    pc: usize,\n    last_instruction_meter_validation_pc: usize,\n    program_vm_addr: u64,\n    handler_anchors: HashMap<usize, usize>,\n    config: Config,\n    diversification_rng: SmallRng,\n    stopwatch_is_active: bool,\n    environment_stack_key: i32,\n    program_argument_key: i32,\n}\n\nimpl Index<usize> for JitCompiler {\n    type Output = u8;\n\n    fn index(&self, _index: usize) -> &u8 {\n        &self.result.text_section[_index]\n    }\n}\n\nimpl IndexMut<usize> for JitCompiler {\n    fn index_mut(&mut self, _index: usize) -> &mut u8 {\n        &mut self.result.text_section[_index]\n    }\n}\n\nimpl std::fmt::Debug for JitCompiler {\n    fn fmt(&self, fmt: &mut Formatter) -> Result<(), FormatterError> {\n        fmt.write_str(\"JIT text_section: [\")?;\n        for i in self.result.text_section as &[u8] {\n            fmt.write_fmt(format_args!(\" {:#04x},\", i))?;\n        };\n        fmt.write_str(\" ] | \")?;\n        fmt.debug_struct(\"JIT state\")\n            .field(\"memory\", &self.result.pc_section.as_ptr())\n            .field(\"pc\", &self.pc)\n            .field(\"offset_in_text_section\", &self.offset_in_text_section)\n            .field(\"pc_section\", &self.result.pc_section)\n            .field(\"handler_anchors\", &self.handler_anchors)\n            .field(\"pc_section_jumps\", &self.pc_section_jumps)\n            .field(\"text_section_jumps\", &self.text_section_jumps)\n            .finish()\n    }\n}\n\nimpl JitCompiler {\n    // Arguments are unused on windows\n    fn new<E: UserDefinedError>(program: &[u8], config: &Config) -> Result<Self, EbpfError<E>> {\n        #[cfg(target_os = \"windows\")]\n        {\n            let _ = program;\n            let _ = config;\n            panic!(\"JIT not supported on windows\");\n        }\n\n        #[cfg(not(target_arch = \"x86_64\"))]\n        {\n            let _ = program;\n            let _ = config;\n            panic!(\"JIT is only supported on x86_64\");\n        }\n\n        // Scan through program to find actual number of instructions\n        let mut pc = 0;\n        while (pc + 1) * ebpf::INSN_SIZE <= program.len() {\n            let insn = ebpf::get_insn_unchecked(program, pc);\n            pc += match insn.opc {\n                ebpf::LD_DW_IMM => 2,\n                _ => 1,\n            };\n        }\n\n        let mut code_length_estimate = MAX_EMPTY_PROGRAM_MACHINE_CODE_LENGTH + MAX_MACHINE_CODE_LENGTH_PER_INSTRUCTION * pc;\n        code_length_estimate += (code_length_estimate as f64 * config.noop_instruction_ratio) as usize;\n        let mut diversification_rng = SmallRng::from_rng(rand::thread_rng()).unwrap();\n        let (environment_stack_key, program_argument_key) =\n            if config.encrypt_environment_registers {\n                (\n                    diversification_rng.gen::<i32>() / 16, // -3 bits for 8 Byte alignment, and -1 bit to have encoding space for EnvironmentStackSlot::SlotCount\n                    diversification_rng.gen::<i32>() / 2, // -1 bit to have encoding space for (SYSCALL_CONTEXT_OBJECTS_OFFSET + syscall.context_object_slot) * 8\n                )\n            } else { (0, 0) };\n\n        Ok(Self {\n            result: JitProgramSections::new(pc + 1, code_length_estimate)?,\n            pc_section_jumps: vec![],\n            text_section_jumps: vec![],\n            offset_in_text_section: 0,\n            pc: 0,\n            last_instruction_meter_validation_pc: 0,\n            program_vm_addr: 0,\n            handler_anchors: HashMap::new(),\n            config: *config,\n            diversification_rng,\n            stopwatch_is_active: false,\n            environment_stack_key,\n            program_argument_key,\n        })\n    }\n\n    fn compile<E: UserDefinedError, I: InstructionMeter>(&mut self,\n            executable: &Pin<Box<Executable<E, I>>>) -> Result<(), EbpfError<E>> {\n        let (program_vm_addr, program) = executable.get_text_bytes();\n        self.program_vm_addr = program_vm_addr;\n\n        self.generate_prologue::<E, I>()?;\n\n        // Jump to entry point\n        let entry = executable.get_entrypoint_instruction_offset().unwrap_or(0);\n        if self.config.enable_instruction_meter {\n            emit_profile_instruction_count(self, Some(entry + 1))?;\n        }\n        X86Instruction::load_immediate(OperandSize::S64, R11, entry as i64).emit(self)?;\n        emit_jmp(self, entry)?;\n\n        // Have these in front so that the linear search of TARGET_PC_TRANSLATE_PC does not terminate early\n        self.generate_helper_routines::<E, I>()?;\n        self.generate_exception_handlers::<E>()?;\n\n        while self.pc * ebpf::INSN_SIZE < program.len() {\n            let mut insn = ebpf::get_insn_unchecked(program, self.pc);\n\n            self.result.pc_section[self.pc] = self.offset_in_text_section as u64;\n\n            // Regular instruction meter checkpoints to prevent long linear runs from exceeding their budget\n            if self.last_instruction_meter_validation_pc + self.config.instruction_meter_checkpoint_distance <= self.pc {\n                emit_validate_instruction_count(self, true, Some(self.pc))?;\n            }\n\n            if self.config.enable_instruction_tracing {\n                X86Instruction::load_immediate(OperandSize::S64, R11, self.pc as i64).emit(self)?;\n                emit_call(self, TARGET_PC_TRACE)?;\n                X86Instruction::load_immediate(OperandSize::S64, R11, 0).emit(self)?;\n            }\n\n            let dst = if insn.dst == STACK_PTR_REG as u8 { u8::MAX } else { REGISTER_MAP[insn.dst as usize] };\n            let src = REGISTER_MAP[insn.src as usize];\n            let target_pc = (self.pc as isize + insn.off as isize + 1) as usize;\n\n            match insn.opc {\n                _ if insn.dst == STACK_PTR_REG as u8 && self.config.dynamic_stack_frames => {\n                    let stack_ptr_access = X86IndirectAccess::Offset(slot_on_environment_stack(self, EnvironmentStackSlot::BpfStackPtr));\n                    match insn.opc {\n                        ebpf::SUB64_IMM => emit_alu(self, OperandSize::S64, 0x81, 5, RBP, insn.imm, Some(stack_ptr_access))?,\n                        ebpf::ADD64_IMM => emit_alu(self, OperandSize::S64, 0x81, 0, RBP, insn.imm, Some(stack_ptr_access))?,\n                        _ => {\n                            #[cfg(debug_assertions)]\n                            unreachable!(\"unexpected insn on r11\")\n                        }\n                    }\n                }\n                // BPF_LD class\n                ebpf::LD_ABS_B   => {\n                    emit_address_translation(self, R11, Value::Constant64(ebpf::MM_INPUT_START.wrapping_add(insn.imm as u32 as u64) as i64, true), 1, AccessType::Load)?;\n                    X86Instruction::load(OperandSize::S8, R11, RAX, X86IndirectAccess::Offset(0)).emit(self)?;\n                },\n                ebpf::LD_ABS_H   => {\n                    emit_address_translation(self, R11, Value::Constant64(ebpf::MM_INPUT_START.wrapping_add(insn.imm as u32 as u64) as i64, true), 2, AccessType::Load)?;\n                    X86Instruction::load(OperandSize::S16, R11, RAX, X86IndirectAccess::Offset(0)).emit(self)?;\n                },\n                ebpf::LD_ABS_W   => {\n                    emit_address_translation(self, R11, Value::Constant64(ebpf::MM_INPUT_START.wrapping_add(insn.imm as u32 as u64) as i64, true), 4, AccessType::Load)?;\n                    X86Instruction::load(OperandSize::S32, R11, RAX, X86IndirectAccess::Offset(0)).emit(self)?;\n                },\n                ebpf::LD_ABS_DW  => {\n                    emit_address_translation(self, R11, Value::Constant64(ebpf::MM_INPUT_START.wrapping_add(insn.imm as u32 as u64) as i64, true), 8, AccessType::Load)?;\n                    X86Instruction::load(OperandSize::S64, R11, RAX, X86IndirectAccess::Offset(0)).emit(self)?;\n                },\n                ebpf::LD_IND_B   => {\n                    emit_address_translation(self, R11, Value::RegisterPlusConstant64(src, ebpf::MM_INPUT_START.wrapping_add(insn.imm as u32 as u64) as i64, true), 1, AccessType::Load)?;\n                    X86Instruction::load(OperandSize::S8, R11, RAX, X86IndirectAccess::Offset(0)).emit(self)?;\n                },\n                ebpf::LD_IND_H   => {\n                    emit_address_translation(self, R11, Value::RegisterPlusConstant64(src, ebpf::MM_INPUT_START.wrapping_add(insn.imm as u32 as u64) as i64, true), 2, AccessType::Load)?;\n                    X86Instruction::load(OperandSize::S16, R11, RAX, X86IndirectAccess::Offset(0)).emit(self)?;\n                },\n                ebpf::LD_IND_W   => {\n                    emit_address_translation(self, R11, Value::RegisterPlusConstant64(src, ebpf::MM_INPUT_START.wrapping_add(insn.imm as u32 as u64) as i64, true), 4, AccessType::Load)?;\n                    X86Instruction::load(OperandSize::S32, R11, RAX, X86IndirectAccess::Offset(0)).emit(self)?;\n                },\n                ebpf::LD_IND_DW  => {\n                    emit_address_translation(self, R11, Value::RegisterPlusConstant64(src, ebpf::MM_INPUT_START.wrapping_add(insn.imm as u32 as u64) as i64, true), 8, AccessType::Load)?;\n                    X86Instruction::load(OperandSize::S64, R11, RAX, X86IndirectAccess::Offset(0)).emit(self)?;\n                },\n\n                ebpf::LD_DW_IMM  => {\n                    emit_validate_and_profile_instruction_count(self, true, Some(self.pc + 2))?;\n                    self.pc += 1;\n                    self.pc_section_jumps.push(Jump { location: self.pc, target_pc: TARGET_PC_CALL_UNSUPPORTED_INSTRUCTION });\n                    ebpf::augment_lddw_unchecked(program, &mut insn);\n                    if should_sanitize_constant(self, insn.imm) {\n                        emit_sanitized_load_immediate(self, OperandSize::S64, dst, insn.imm)?;\n                    } else {\n                        X86Instruction::load_immediate(OperandSize::S64, dst, insn.imm).emit(self)?;\n                    }\n                },\n\n                // BPF_LDX class\n                ebpf::LD_B_REG   => {\n                    emit_address_translation(self, R11, Value::RegisterPlusConstant64(src, insn.off as i64, true), 1, AccessType::Load)?;\n                    X86Instruction::load(OperandSize::S8, R11, dst, X86IndirectAccess::Offset(0)).emit(self)?;\n                },\n                ebpf::LD_H_REG   => {\n                    emit_address_translation(self, R11, Value::RegisterPlusConstant64(src, insn.off as i64, true), 2, AccessType::Load)?;\n                    X86Instruction::load(OperandSize::S16, R11, dst, X86IndirectAccess::Offset(0)).emit(self)?;\n                },\n                ebpf::LD_W_REG   => {\n                    emit_address_translation(self, R11, Value::RegisterPlusConstant64(src, insn.off as i64, true), 4, AccessType::Load)?;\n                    X86Instruction::load(OperandSize::S32, R11, dst, X86IndirectAccess::Offset(0)).emit(self)?;\n                },\n                ebpf::LD_DW_REG  => {\n                    emit_address_translation(self, R11, Value::RegisterPlusConstant64(src, insn.off as i64, true), 8, AccessType::Load)?;\n                    X86Instruction::load(OperandSize::S64, R11, dst, X86IndirectAccess::Offset(0)).emit(self)?;\n                },\n\n                // BPF_ST class\n                ebpf::ST_B_IMM   => {\n                    emit_address_translation(self, R11, Value::RegisterPlusConstant64(dst, insn.off as i64, true), 1, AccessType::Store)?;\n                    X86Instruction::store_immediate(OperandSize::S8, R11, X86IndirectAccess::Offset(0), insn.imm as i64).emit(self)?;\n                },\n                ebpf::ST_H_IMM   => {\n                    emit_address_translation(self, R11, Value::RegisterPlusConstant64(dst, insn.off as i64, true), 2, AccessType::Store)?;\n                    X86Instruction::store_immediate(OperandSize::S16, R11, X86IndirectAccess::Offset(0), insn.imm as i64).emit(self)?;\n                },\n                ebpf::ST_W_IMM   => {\n                    emit_address_translation(self, R11, Value::RegisterPlusConstant64(dst, insn.off as i64, true), 4, AccessType::Store)?;\n                    X86Instruction::store_immediate(OperandSize::S32, R11, X86IndirectAccess::Offset(0), insn.imm as i64).emit(self)?;\n                },\n                ebpf::ST_DW_IMM  => {\n                    emit_address_translation(self, R11, Value::RegisterPlusConstant64(dst, insn.off as i64, true), 8, AccessType::Store)?;\n                    X86Instruction::store_immediate(OperandSize::S64, R11, X86IndirectAccess::Offset(0), insn.imm as i64).emit(self)?;\n                },\n\n                // BPF_STX class\n                ebpf::ST_B_REG  => {\n                    emit_address_translation(self, R11, Value::RegisterPlusConstant64(dst, insn.off as i64, true), 1, AccessType::Store)?;\n                    X86Instruction::store(OperandSize::S8, src, R11, X86IndirectAccess::Offset(0)).emit(self)?;\n                },\n                ebpf::ST_H_REG  => {\n                    emit_address_translation(self, R11, Value::RegisterPlusConstant64(dst, insn.off as i64, true), 2, AccessType::Store)?;\n                    X86Instruction::store(OperandSize::S16, src, R11, X86IndirectAccess::Offset(0)).emit(self)?;\n                },\n                ebpf::ST_W_REG  => {\n                    emit_address_translation(self, R11, Value::RegisterPlusConstant64(dst, insn.off as i64, true), 4, AccessType::Store)?;\n                    X86Instruction::store(OperandSize::S32, src, R11, X86IndirectAccess::Offset(0)).emit(self)?;\n                },\n                ebpf::ST_DW_REG  => {\n                    emit_address_translation(self, R11, Value::RegisterPlusConstant64(dst, insn.off as i64, true), 8, AccessType::Store)?;\n                    X86Instruction::store(OperandSize::S64, src, R11, X86IndirectAccess::Offset(0)).emit(self)?;\n                },\n\n                // BPF_ALU class\n                ebpf::ADD32_IMM  => {\n                    emit_sanitized_alu(self, OperandSize::S32, 0x01, 0, dst, insn.imm)?;\n                    X86Instruction::sign_extend_i32_to_i64(dst, dst).emit(self)?;\n                },\n                ebpf::ADD32_REG  => {\n                    emit_alu(self, OperandSize::S32, 0x01, src, dst, 0, None)?;\n                    X86Instruction::sign_extend_i32_to_i64(dst, dst).emit(self)?;\n                },\n                ebpf::SUB32_IMM  => {\n                    emit_sanitized_alu(self, OperandSize::S32, 0x29, 5, dst, insn.imm)?;\n                    X86Instruction::sign_extend_i32_to_i64(dst, dst).emit(self)?;\n                },\n                ebpf::SUB32_REG  => {\n                    emit_alu(self, OperandSize::S32, 0x29, src, dst, 0, None)?;\n                    X86Instruction::sign_extend_i32_to_i64(dst, dst).emit(self)?;\n                },\n                ebpf::MUL32_IMM | ebpf::DIV32_IMM | ebpf::SDIV32_IMM | ebpf::MOD32_IMM  =>\n                    emit_muldivmod(self, insn.opc, dst, dst, Some(insn.imm))?,\n                ebpf::MUL32_REG | ebpf::DIV32_REG | ebpf::SDIV32_REG | ebpf::MOD32_REG  =>\n                    emit_muldivmod(self, insn.opc, src, dst, None)?,\n                ebpf::OR32_IMM   => emit_sanitized_alu(self, OperandSize::S32, 0x09, 1, dst, insn.imm)?,\n                ebpf::OR32_REG   => emit_alu(self, OperandSize::S32, 0x09, src, dst, 0, None)?,\n                ebpf::AND32_IMM  => emit_sanitized_alu(self, OperandSize::S32, 0x21, 4, dst, insn.imm)?,\n                ebpf::AND32_REG  => emit_alu(self, OperandSize::S32, 0x21, src, dst, 0, None)?,\n                ebpf::LSH32_IMM  => emit_shift(self, OperandSize::S32, 4, R11, dst, Some(insn.imm))?,\n                ebpf::LSH32_REG  => emit_shift(self, OperandSize::S32, 4, src, dst, None)?,\n                ebpf::RSH32_IMM  => emit_shift(self, OperandSize::S32, 5, R11, dst, Some(insn.imm))?,\n                ebpf::RSH32_REG  => emit_shift(self, OperandSize::S32, 5, src, dst, None)?,\n                ebpf::NEG32      => emit_alu(self, OperandSize::S32, 0xf7, 3, dst, 0, None)?,\n                ebpf::XOR32_IMM  => emit_sanitized_alu(self, OperandSize::S32, 0x31, 6, dst, insn.imm)?,\n                ebpf::XOR32_REG  => emit_alu(self, OperandSize::S32, 0x31, src, dst, 0, None)?,\n                ebpf::MOV32_IMM  => {\n                    if should_sanitize_constant(self, insn.imm) {\n                        emit_sanitized_load_immediate(self, OperandSize::S32, dst, insn.imm)?;\n                    } else {\n                        X86Instruction::load_immediate(OperandSize::S32, dst, insn.imm).emit(self)?;\n                    }\n                }\n                ebpf::MOV32_REG  => X86Instruction::mov(OperandSize::S32, src, dst).emit(self)?,\n                ebpf::ARSH32_IMM => emit_shift(self, OperandSize::S32, 7, R11, dst, Some(insn.imm))?,\n                ebpf::ARSH32_REG => emit_shift(self, OperandSize::S32, 7, src, dst, None)?,\n                ebpf::LE         => {\n                    match insn.imm {\n                        16 => {\n                            emit_alu(self, OperandSize::S32, 0x81, 4, dst, 0xffff, None)?; // Mask to 16 bit\n                        }\n                        32 => {\n                            emit_alu(self, OperandSize::S32, 0x81, 4, dst, -1, None)?; // Mask to 32 bit\n                        }\n                        64 => {}\n                        _ => {\n                            return Err(EbpfError::InvalidInstruction(self.pc + ebpf::ELF_INSN_DUMP_OFFSET));\n                        }\n                    }\n                },\n                ebpf::BE         => {\n                    match insn.imm {\n                        16 => {\n                            X86Instruction::bswap(OperandSize::S16, dst).emit(self)?;\n                            emit_alu(self, OperandSize::S32, 0x81, 4, dst, 0xffff, None)?; // Mask to 16 bit\n                        }\n                        32 => X86Instruction::bswap(OperandSize::S32, dst).emit(self)?,\n                        64 => X86Instruction::bswap(OperandSize::S64, dst).emit(self)?,\n                        _ => {\n                            return Err(EbpfError::InvalidInstruction(self.pc + ebpf::ELF_INSN_DUMP_OFFSET));\n                        }\n                    }\n                },\n\n                // BPF_ALU64 class\n                ebpf::ADD64_IMM  => emit_sanitized_alu(self, OperandSize::S64, 0x01, 0, dst, insn.imm)?,\n                ebpf::ADD64_REG  => emit_alu(self, OperandSize::S64, 0x01, src, dst, 0, None)?,\n                ebpf::SUB64_IMM  => emit_sanitized_alu(self, OperandSize::S64, 0x29, 5, dst, insn.imm)?,\n                ebpf::SUB64_REG  => emit_alu(self, OperandSize::S64, 0x29, src, dst, 0, None)?,\n                ebpf::MUL64_IMM | ebpf::DIV64_IMM | ebpf::SDIV64_IMM | ebpf::MOD64_IMM  =>\n                    emit_muldivmod(self, insn.opc, dst, dst, Some(insn.imm))?,\n                ebpf::MUL64_REG | ebpf::DIV64_REG | ebpf::SDIV64_REG | ebpf::MOD64_REG  =>\n                    emit_muldivmod(self, insn.opc, src, dst, None)?,\n                ebpf::OR64_IMM   => emit_sanitized_alu(self, OperandSize::S64, 0x09, 1, dst, insn.imm)?,\n                ebpf::OR64_REG   => emit_alu(self, OperandSize::S64, 0x09, src, dst, 0, None)?,\n                ebpf::AND64_IMM  => emit_sanitized_alu(self, OperandSize::S64, 0x21, 4, dst, insn.imm)?,\n                ebpf::AND64_REG  => emit_alu(self, OperandSize::S64, 0x21, src, dst, 0, None)?,\n                ebpf::LSH64_IMM  => emit_shift(self, OperandSize::S64, 4, R11, dst, Some(insn.imm))?,\n                ebpf::LSH64_REG  => emit_shift(self, OperandSize::S64, 4, src, dst, None)?,\n                ebpf::RSH64_IMM  => emit_shift(self, OperandSize::S64, 5, R11, dst, Some(insn.imm))?,\n                ebpf::RSH64_REG  => emit_shift(self, OperandSize::S64, 5, src, dst, None)?,\n                ebpf::NEG64      => emit_alu(self, OperandSize::S64, 0xf7, 3, dst, 0, None)?,\n                ebpf::XOR64_IMM  => emit_sanitized_alu(self, OperandSize::S64, 0x31, 6, dst, insn.imm)?,\n                ebpf::XOR64_REG  => emit_alu(self, OperandSize::S64, 0x31, src, dst, 0, None)?,\n                ebpf::MOV64_IMM  => {\n                    if should_sanitize_constant(self, insn.imm) {\n                        emit_sanitized_load_immediate(self, OperandSize::S64, dst, insn.imm)?;\n                    } else {\n                        X86Instruction::load_immediate(OperandSize::S64, dst, insn.imm).emit(self)?;\n                    }\n                }\n                ebpf::MOV64_REG  => X86Instruction::mov(OperandSize::S64, src, dst).emit(self)?,\n                ebpf::ARSH64_IMM => emit_shift(self, OperandSize::S64, 7, R11, dst, Some(insn.imm))?,\n                ebpf::ARSH64_REG => emit_shift(self, OperandSize::S64, 7, src, dst, None)?,\n\n                // BPF_JMP class\n                ebpf::JA         => {\n                    emit_validate_and_profile_instruction_count(self, false, Some(target_pc))?;\n                    X86Instruction::load_immediate(OperandSize::S64, R11, target_pc as i64).emit(self)?;\n                    emit_jmp(self, target_pc)?;\n                },\n                ebpf::JEQ_IMM    => emit_conditional_branch_imm(self, 0x84, false, insn.imm, dst, target_pc)?,\n                ebpf::JEQ_REG    => emit_conditional_branch_reg(self, 0x84, false, src, dst, target_pc)?,\n                ebpf::JGT_IMM    => emit_conditional_branch_imm(self, 0x87, false, insn.imm, dst, target_pc)?,\n                ebpf::JGT_REG    => emit_conditional_branch_reg(self, 0x87, false, src, dst, target_pc)?,\n                ebpf::JGE_IMM    => emit_conditional_branch_imm(self, 0x83, false, insn.imm, dst, target_pc)?,\n                ebpf::JGE_REG    => emit_conditional_branch_reg(self, 0x83, false, src, dst, target_pc)?,\n                ebpf::JLT_IMM    => emit_conditional_branch_imm(self, 0x82, false, insn.imm, dst, target_pc)?,\n                ebpf::JLT_REG    => emit_conditional_branch_reg(self, 0x82, false, src, dst, target_pc)?,\n                ebpf::JLE_IMM    => emit_conditional_branch_imm(self, 0x86, false, insn.imm, dst, target_pc)?,\n                ebpf::JLE_REG    => emit_conditional_branch_reg(self, 0x86, false, src, dst, target_pc)?,\n                ebpf::JSET_IMM   => emit_conditional_branch_imm(self, 0x85, true, insn.imm, dst, target_pc)?,\n                ebpf::JSET_REG   => emit_conditional_branch_reg(self, 0x85, true, src, dst, target_pc)?,\n                ebpf::JNE_IMM    => emit_conditional_branch_imm(self, 0x85, false, insn.imm, dst, target_pc)?,\n                ebpf::JNE_REG    => emit_conditional_branch_reg(self, 0x85, false, src, dst, target_pc)?,\n                ebpf::JSGT_IMM   => emit_conditional_branch_imm(self, 0x8f, false, insn.imm, dst, target_pc)?,\n                ebpf::JSGT_REG   => emit_conditional_branch_reg(self, 0x8f, false, src, dst, target_pc)?,\n                ebpf::JSGE_IMM   => emit_conditional_branch_imm(self, 0x8d, false, insn.imm, dst, target_pc)?,\n                ebpf::JSGE_REG   => emit_conditional_branch_reg(self, 0x8d, false, src, dst, target_pc)?,\n                ebpf::JSLT_IMM   => emit_conditional_branch_imm(self, 0x8c, false, insn.imm, dst, target_pc)?,\n                ebpf::JSLT_REG   => emit_conditional_branch_reg(self, 0x8c, false, src, dst, target_pc)?,\n                ebpf::JSLE_IMM   => emit_conditional_branch_imm(self, 0x8e, false, insn.imm, dst, target_pc)?,\n                ebpf::JSLE_REG   => emit_conditional_branch_reg(self, 0x8e, false, src, dst, target_pc)?,\n                ebpf::CALL_IMM   => {\n                    // For JIT, syscalls MUST be registered at compile time. They can be\n                    // updated later, but not created after compiling (we need the address of the\n                    // syscall function in the JIT-compiled program).\n\n                    let mut resolved = false;\n                    let (syscalls, calls) = if self.config.static_syscalls {\n                        (insn.src == 0, insn.src != 0)\n                    } else {\n                        (true, true)\n                    };\n\n                    if syscalls {\n                        if let Some(syscall) = executable.get_syscall_registry().lookup_syscall(insn.imm as u32) {\n                            if self.config.enable_instruction_meter {\n                                emit_validate_and_profile_instruction_count(self, true, Some(0))?;\n                            }\n                            X86Instruction::load_immediate(OperandSize::S64, R11, syscall.function as *const u8 as i64).emit(self)?;\n                            X86Instruction::load(OperandSize::S64, R10, RAX, X86IndirectAccess::Offset((SYSCALL_CONTEXT_OBJECTS_OFFSET + syscall.context_object_slot) as i32 * 8 + self.program_argument_key)).emit(self)?;\n                            emit_call(self, TARGET_PC_SYSCALL)?;\n                            if self.config.enable_instruction_meter {\n                                emit_undo_profile_instruction_count(self, 0)?;\n                            }\n                            // Throw error if the result indicates one\n                            X86Instruction::cmp_immediate(OperandSize::S64, R11, 0, Some(X86IndirectAccess::Offset(0))).emit(self)?;\n                            X86Instruction::load_immediate(OperandSize::S64, R11, self.pc as i64).emit(self)?;\n                            emit_jcc(self, 0x85, TARGET_PC_RUST_EXCEPTION)?;\n\n                            resolved = true;\n                        }\n                    }\n\n                    if calls {\n                        if let Some(target_pc) = executable.lookup_bpf_function(insn.imm as u32) {\n                            emit_bpf_call(self, Value::Constant64(target_pc as i64, false))?;\n                            resolved = true;\n                        }\n                    }\n\n                    if !resolved {\n                        if self.config.disable_unresolved_symbols_at_runtime {\n                            X86Instruction::load_immediate(OperandSize::S64, R11, self.pc as i64).emit(self)?;\n                            emit_jmp(self, TARGET_PC_CALL_UNSUPPORTED_INSTRUCTION)?;\n                        } else {\n                            emit_validate_instruction_count(self, true, Some(self.pc))?;\n                            // executable.report_unresolved_symbol(self.pc)?;\n                            // Workaround for unresolved symbols in ELF: Report error at runtime instead of compiletime\n                            emit_rust_call(self, Value::Constant64(Executable::<E, I>::report_unresolved_symbol as *const u8 as i64, false), &[\n                                Argument { index: 2, value: Value::Constant64(self.pc as i64, false) },\n                                Argument { index: 1, value: Value::Constant64(&*executable.as_ref() as *const _ as i64, false) },\n                                Argument { index: 0, value: Value::RegisterIndirect(RBP, slot_on_environment_stack(self, EnvironmentStackSlot::OptRetValPtr), false) },\n                            ], None, true)?;\n                            X86Instruction::load_immediate(OperandSize::S64, R11, self.pc as i64).emit(self)?;\n                            emit_jmp(self, TARGET_PC_RUST_EXCEPTION)?;\n                        }\n                    }\n                },\n                ebpf::CALL_REG  => {\n                    emit_bpf_call(self, Value::Register(REGISTER_MAP[insn.imm as usize]))?;\n                },\n                ebpf::EXIT      => {\n                    let call_depth_access = X86IndirectAccess::Offset(slot_on_environment_stack(self, EnvironmentStackSlot::CallDepth));\n                    X86Instruction::load(OperandSize::S64, RBP, REGISTER_MAP[FRAME_PTR_REG], call_depth_access).emit(self)?;\n\n                    // If CallDepth == 0, we've reached the exit instruction of the entry point\n                    X86Instruction::cmp_immediate(OperandSize::S32, REGISTER_MAP[FRAME_PTR_REG], 0, None).emit(self)?;\n                    if self.config.enable_instruction_meter {\n                        X86Instruction::load_immediate(OperandSize::S64, R11, self.pc as i64).emit(self)?;\n                    }\n                    // we're done\n                    emit_jcc(self, 0x84, TARGET_PC_EXIT)?;\n\n                    // else decrement and update CallDepth\n                    emit_alu(self, OperandSize::S64, 0x81, 5, REGISTER_MAP[FRAME_PTR_REG], 1, None)?;\n                    X86Instruction::store(OperandSize::S64, REGISTER_MAP[FRAME_PTR_REG], RBP, call_depth_access).emit(self)?;\n\n                    // and return\n                    emit_validate_and_profile_instruction_count(self, false, Some(0))?;\n                    X86Instruction::return_near().emit(self)?;\n                },\n\n                _               => return Err(EbpfError::UnsupportedInstruction(self.pc + ebpf::ELF_INSN_DUMP_OFFSET)),\n            }\n\n            self.pc += 1;\n        }\n        self.result.pc_section[self.pc] = self.offset_in_text_section as u64; // Bumper so that the linear search of TARGET_PC_TRANSLATE_PC can not run off\n\n        // Bumper in case there was no final exit\n        emit_validate_and_profile_instruction_count(self, true, Some(self.pc + 2))?;\n        X86Instruction::load_immediate(OperandSize::S64, R11, self.pc as i64).emit(self)?;\n        emit_set_exception_kind::<E>(self, EbpfError::ExecutionOverrun(0))?;\n        emit_jmp(self, TARGET_PC_EXCEPTION_AT)?;\n\n        self.generate_epilogue::<E>()?;\n        self.resolve_jumps();\n        self.result.seal(self.offset_in_text_section)?;\n\n        // Delete secrets\n        self.environment_stack_key = 0;\n        self.program_argument_key = 0;\n\n        Ok(())\n    }\n\n    fn generate_helper_routines<E: UserDefinedError, I: InstructionMeter>(&mut self) -> Result<(), EbpfError<E>> {\n        // Routine for instruction tracing\n        if self.config.enable_instruction_tracing {\n            set_anchor(self, TARGET_PC_TRACE);\n            // Save registers on stack\n            X86Instruction::push(R11, None).emit(self)?;\n            for reg in REGISTER_MAP.iter().rev() {\n                X86Instruction::push(*reg, None).emit(self)?;\n            }\n            X86Instruction::mov(OperandSize::S64, RSP, REGISTER_MAP[0]).emit(self)?;\n            emit_alu(self, OperandSize::S64, 0x81, 0, RSP, - 8 * 3, None)?; // RSP -= 8 * 3;\n            emit_rust_call(self, Value::Constant64(Tracer::trace as *const u8 as i64, false), &[\n                Argument { index: 1, value: Value::Register(REGISTER_MAP[0]) }, // registers\n                Argument { index: 0, value: Value::RegisterIndirect(R10, mem::size_of::<MemoryMapping>() as i32 + self.program_argument_key, false) }, // jit.tracer\n            ], None, false)?;\n            // Pop stack and return\n            emit_alu(self, OperandSize::S64, 0x81, 0, RSP, 8 * 3, None)?; // RSP += 8 * 3;\n            X86Instruction::pop(REGISTER_MAP[0]).emit(self)?;\n            emit_alu(self, OperandSize::S64, 0x81, 0, RSP, 8 * (REGISTER_MAP.len() - 1) as i64, None)?; // RSP += 8 * (REGISTER_MAP.len() - 1);\n            X86Instruction::pop(R11).emit(self)?;\n            X86Instruction::return_near().emit(self)?;\n        }\n\n        // Routine for syscall\n        set_anchor(self, TARGET_PC_SYSCALL);\n        X86Instruction::push(R11, None).emit(self)?; // Padding for stack alignment\n        if self.config.enable_instruction_meter {\n            // RDI = *PrevInsnMeter - RDI;\n            emit_alu(self, OperandSize::S64, 0x2B, ARGUMENT_REGISTERS[0], RBP, 0, Some(X86IndirectAccess::Offset(slot_on_environment_stack(self, EnvironmentStackSlot::PrevInsnMeter))))?; // RDI -= *PrevInsnMeter;\n            emit_alu(self, OperandSize::S64, 0xf7, 3, ARGUMENT_REGISTERS[0], 0, None)?; // RDI = -RDI;\n            emit_rust_call(self, Value::Constant64(I::consume as *const u8 as i64, false), &[\n                Argument { index: 1, value: Value::Register(ARGUMENT_REGISTERS[0]) },\n                Argument { index: 0, value: Value::RegisterIndirect(RBP, slot_on_environment_stack(self, EnvironmentStackSlot::InsnMeterPtr), false) },\n            ], None, false)?;\n        }\n        emit_rust_call(self, Value::Register(R11), &[\n            Argument { index: 7, value: Value::RegisterIndirect(RBP, slot_on_environment_stack(self, EnvironmentStackSlot::OptRetValPtr), false) },\n            Argument { index: 6, value: Value::RegisterPlusConstant32(R10, self.program_argument_key, false) }, // jit_program_argument.memory_mapping\n            Argument { index: 5, value: Value::Register(ARGUMENT_REGISTERS[5]) },\n            Argument { index: 4, value: Value::Register(ARGUMENT_REGISTERS[4]) },\n            Argument { index: 3, value: Value::Register(ARGUMENT_REGISTERS[3]) },\n            Argument { index: 2, value: Value::Register(ARGUMENT_REGISTERS[2]) },\n            Argument { index: 1, value: Value::Register(ARGUMENT_REGISTERS[1]) },\n            Argument { index: 0, value: Value::Register(RAX) }, // \"&mut self\" in the \"call\" method of the SyscallObject\n        ], None, false)?;\n        if self.config.enable_instruction_meter {\n            emit_rust_call(self, Value::Constant64(I::get_remaining as *const u8 as i64, false), &[\n                Argument { index: 0, value: Value::RegisterIndirect(RBP, slot_on_environment_stack(self, EnvironmentStackSlot::InsnMeterPtr), false) },\n            ], Some(ARGUMENT_REGISTERS[0]), false)?;\n            X86Instruction::store(OperandSize::S64, ARGUMENT_REGISTERS[0], RBP, X86IndirectAccess::Offset(slot_on_environment_stack(self, EnvironmentStackSlot::PrevInsnMeter))).emit(self)?;\n        }\n        X86Instruction::pop(R11).emit(self)?;\n        // Store Ok value in result register\n        X86Instruction::load(OperandSize::S64, RBP, R11, X86IndirectAccess::Offset(slot_on_environment_stack(self, EnvironmentStackSlot::OptRetValPtr))).emit(self)?;\n        X86Instruction::load(OperandSize::S64, R11, REGISTER_MAP[0], X86IndirectAccess::Offset(8)).emit(self)?;\n        X86Instruction::return_near().emit(self)?;\n\n        // Routine for prologue of emit_bpf_call()\n        set_anchor(self, TARGET_PC_BPF_CALL_PROLOGUE);\n        emit_alu(self, OperandSize::S64, 0x81, 5, RSP, 8 * (SCRATCH_REGS + 1) as i64, None)?; // alloca\n        X86Instruction::store(OperandSize::S64, R11, RSP, X86IndirectAccess::OffsetIndexShift(0, RSP, 0)).emit(self)?; // Save original R11\n        X86Instruction::load(OperandSize::S64, RSP, R11, X86IndirectAccess::OffsetIndexShift(8 * (SCRATCH_REGS + 1) as i32, RSP, 0)).emit(self)?; // Load return address\n        for (i, reg) in REGISTER_MAP.iter().skip(FIRST_SCRATCH_REG).take(SCRATCH_REGS).enumerate() {\n            X86Instruction::store(OperandSize::S64, *reg, RSP, X86IndirectAccess::OffsetIndexShift(8 * (SCRATCH_REGS - i + 1) as i32, RSP, 0)).emit(self)?; // Push SCRATCH_REG\n        }\n        // Push the caller's frame pointer. The code to restore it is emitted at the end of emit_bpf_call().\n        X86Instruction::store(OperandSize::S64, REGISTER_MAP[FRAME_PTR_REG], RSP, X86IndirectAccess::OffsetIndexShift(8, RSP, 0)).emit(self)?;\n        X86Instruction::xchg(OperandSize::S64, R11, RSP, Some(X86IndirectAccess::OffsetIndexShift(0, RSP, 0))).emit(self)?; // Push return address and restore original R11\n\n        // Increase CallDepth\n        let call_depth_access = X86IndirectAccess::Offset(slot_on_environment_stack(self, EnvironmentStackSlot::CallDepth));\n        emit_alu(self, OperandSize::S64, 0x81, 0, RBP, 1, Some(call_depth_access))?;\n        X86Instruction::load(OperandSize::S64, RBP, REGISTER_MAP[FRAME_PTR_REG], call_depth_access).emit(self)?;\n        // If CallDepth == self.config.max_call_depth, stop and return CallDepthExceeded\n        X86Instruction::cmp_immediate(OperandSize::S32, REGISTER_MAP[FRAME_PTR_REG], self.config.max_call_depth as i64, None).emit(self)?;\n        emit_jcc(self, 0x83, TARGET_PC_CALL_DEPTH_EXCEEDED)?;\n\n        // Setup the frame pointer for the new frame. What we do depends on whether we're using dynamic or fixed frames.\n        let frame_ptr_access = X86IndirectAccess::Offset(slot_on_environment_stack(self, EnvironmentStackSlot::BpfFramePtr));\n        if self.config.dynamic_stack_frames {\n            // When dynamic frames are on, the next frame starts at the end of the current frame\n            let stack_ptr_access = X86IndirectAccess::Offset(slot_on_environment_stack(self, EnvironmentStackSlot::BpfStackPtr));\n            X86Instruction::load(OperandSize::S64, RBP, REGISTER_MAP[FRAME_PTR_REG], stack_ptr_access).emit(self)?;\n            X86Instruction::store(OperandSize::S64, REGISTER_MAP[FRAME_PTR_REG], RBP, frame_ptr_access).emit(self)?;\n        } else {\n            // With fixed frames we start the new frame at the next fixed offset\n            let stack_frame_size = self.config.stack_frame_size as i64 * if self.config.enable_stack_frame_gaps { 2 } else { 1 };\n            emit_alu(self, OperandSize::S64, 0x81, 0, RBP, stack_frame_size, Some(frame_ptr_access))?; // frame_ptr += stack_frame_size;\n            X86Instruction::load(OperandSize::S64, RBP, REGISTER_MAP[FRAME_PTR_REG], frame_ptr_access).emit(self)?; // Load BpfFramePtr\n        }\n        X86Instruction::return_near().emit(self)?;\n\n        // Routine for emit_bpf_call(Value::Register())\n        set_anchor(self, TARGET_PC_BPF_CALL_REG);\n        // Force alignment of RAX\n        emit_alu(self, OperandSize::S64, 0x81, 4, REGISTER_MAP[0], !(INSN_SIZE as i64 - 1), None)?; // RAX &= !(INSN_SIZE - 1);\n        // Upper bound check\n        // if(RAX >= self.program_vm_addr + number_of_instructions * INSN_SIZE) throw CALL_OUTSIDE_TEXT_SEGMENT;\n        let number_of_instructions = self.result.pc_section.len() - 1;\n        X86Instruction::load_immediate(OperandSize::S64, REGISTER_MAP[FRAME_PTR_REG], self.program_vm_addr as i64 + (number_of_instructions * INSN_SIZE) as i64).emit(self)?;\n        X86Instruction::cmp(OperandSize::S64, REGISTER_MAP[FRAME_PTR_REG], REGISTER_MAP[0], None).emit(self)?;\n        emit_jcc(self, 0x83, TARGET_PC_CALL_OUTSIDE_TEXT_SEGMENT)?;\n        // Lower bound check\n        // if(RAX < self.program_vm_addr) throw CALL_OUTSIDE_TEXT_SEGMENT;\n        X86Instruction::load_immediate(OperandSize::S64, REGISTER_MAP[FRAME_PTR_REG], self.program_vm_addr as i64).emit(self)?;\n        X86Instruction::cmp(OperandSize::S64, REGISTER_MAP[FRAME_PTR_REG], REGISTER_MAP[0], None).emit(self)?;\n        emit_jcc(self, 0x82, TARGET_PC_CALL_OUTSIDE_TEXT_SEGMENT)?;\n        // Calculate offset relative to instruction_addresses\n        emit_alu(self, OperandSize::S64, 0x29, REGISTER_MAP[FRAME_PTR_REG], REGISTER_MAP[0], 0, None)?; // RAX -= self.program_vm_addr;\n        // Calculate the target_pc (dst / INSN_SIZE) to update the instruction_meter\n        let shift_amount = INSN_SIZE.trailing_zeros();\n        debug_assert_eq!(INSN_SIZE, 1 << shift_amount);\n        X86Instruction::mov(OperandSize::S64, REGISTER_MAP[0], R11).emit(self)?;\n        emit_alu(self, OperandSize::S64, 0xc1, 5, R11, shift_amount as i64, None)?;\n        // Save BPF target pc for potential TARGET_PC_CALLX_UNSUPPORTED_INSTRUCTION\n        X86Instruction::store(OperandSize::S64, R11, RSP, X86IndirectAccess::OffsetIndexShift(-8, RSP, 0)).emit(self)?; // RSP[-8] = R11;\n        // Load host target_address from self.result.pc_section\n        debug_assert_eq!(INSN_SIZE, 8); // Because the instruction size is also the slot size we do not need to shift the offset\n        X86Instruction::load_immediate(OperandSize::S64, REGISTER_MAP[FRAME_PTR_REG], self.result.pc_section.as_ptr() as i64).emit(self)?;\n        emit_alu(self, OperandSize::S64, 0x01, REGISTER_MAP[FRAME_PTR_REG], REGISTER_MAP[0], 0, None)?; // RAX += self.result.pc_section;\n        X86Instruction::load(OperandSize::S64, REGISTER_MAP[0], REGISTER_MAP[0], X86IndirectAccess::Offset(0)).emit(self)?; // RAX = self.result.pc_section[RAX / 8];\n        // Load the frame pointer again since we've clobbered REGISTER_MAP[FRAME_PTR_REG]\n        X86Instruction::load(OperandSize::S64, RBP, REGISTER_MAP[FRAME_PTR_REG], X86IndirectAccess::Offset(slot_on_environment_stack(self, EnvironmentStackSlot::BpfFramePtr))).emit(self)?;\n        X86Instruction::return_near().emit(self)?;\n\n        // Translates a host pc back to a BPF pc by linear search of the pc_section table\n        set_anchor(self, TARGET_PC_TRANSLATE_PC);\n        X86Instruction::push(REGISTER_MAP[0], None).emit(self)?; // Save REGISTER_MAP[0]\n        X86Instruction::load_immediate(OperandSize::S64, REGISTER_MAP[0], self.result.pc_section.as_ptr() as i64 - 8).emit(self)?; // Loop index and pointer to look up\n        set_anchor(self, TARGET_PC_TRANSLATE_PC_LOOP); // Loop label\n        emit_alu(self, OperandSize::S64, 0x81, 0, REGISTER_MAP[0], 8, None)?; // Increase index\n        X86Instruction::cmp(OperandSize::S64, R11, REGISTER_MAP[0], Some(X86IndirectAccess::Offset(8))).emit(self)?; // Look up and compare against value at next index\n        emit_jcc(self, 0x86, TARGET_PC_TRANSLATE_PC_LOOP)?; // Continue while *REGISTER_MAP[0] <= R11\n        X86Instruction::mov(OperandSize::S64, REGISTER_MAP[0], R11).emit(self)?; // R11 = REGISTER_MAP[0];\n        X86Instruction::load_immediate(OperandSize::S64, REGISTER_MAP[0], self.result.pc_section.as_ptr() as i64).emit(self)?; // REGISTER_MAP[0] = self.result.pc_section;\n        emit_alu(self, OperandSize::S64, 0x29, REGISTER_MAP[0], R11, 0, None)?; // R11 -= REGISTER_MAP[0];\n        emit_alu(self, OperandSize::S64, 0xc1, 5, R11, 3, None)?; // R11 >>= 3;\n        X86Instruction::pop(REGISTER_MAP[0]).emit(self)?; // Restore REGISTER_MAP[0]\n        X86Instruction::return_near().emit(self)?;\n\n        // Translates a vm memory address to a host memory address\n        for (access_type, len) in &[\n            (AccessType::Load, 1i32),\n            (AccessType::Load, 2i32),\n            (AccessType::Load, 4i32),\n            (AccessType::Load, 8i32),\n            (AccessType::Store, 1i32),\n            (AccessType::Store, 2i32),\n            (AccessType::Store, 4i32),\n            (AccessType::Store, 8i32),\n        ] {\n            let target_offset = len.trailing_zeros() as usize + 4 * (*access_type as usize);\n\n            set_anchor(self, TARGET_PC_TRANSLATE_MEMORY_ADDRESS + target_offset);\n            X86Instruction::push(R11, None).emit(self)?;\n            X86Instruction::push(RAX, None).emit(self)?;\n            X86Instruction::push(RCX, None).emit(self)?;\n            let stack_offset = if !self.config.dynamic_stack_frames && self.config.enable_stack_frame_gaps {\n                X86Instruction::push(RDX, None).emit(self)?;\n                24\n            } else {\n                16\n            };\n            X86Instruction::mov(OperandSize::S64, R11, RAX).emit(self)?; // RAX = vm_addr;\n            emit_alu(self, OperandSize::S64, 0xc1, 5, RAX, ebpf::VIRTUAL_ADDRESS_BITS as i64, None)?; // RAX >>= ebpf::VIRTUAL_ADDRESS_BITS;\n            X86Instruction::cmp(OperandSize::S64, RAX, R10, Some(X86IndirectAccess::Offset(self.program_argument_key + 8))).emit(self)?; // region_index >= jit_program_argument.memory_mapping.regions.len()\n            emit_jcc(self, 0x86, TARGET_PC_MEMORY_ACCESS_VIOLATION + target_offset)?;\n            debug_assert_eq!(1 << 5, mem::size_of::<MemoryRegion>());\n            emit_alu(self, OperandSize::S64, 0xc1, 4, RAX, 5, None)?; // RAX *= mem::size_of::<MemoryRegion>();\n            emit_alu(self, OperandSize::S64, 0x03, RAX, R10, 0, Some(X86IndirectAccess::Offset(self.program_argument_key)))?; // region = &jit_program_argument.memory_mapping.regions[region_index];\n            if *access_type == AccessType::Store {\n                X86Instruction::cmp_immediate(OperandSize::S8, RAX, 0, Some(X86IndirectAccess::Offset(MemoryRegion::IS_WRITABLE_OFFSET))).emit(self)?; // region.is_writable == 0\n                emit_jcc(self, 0x84, TARGET_PC_MEMORY_ACCESS_VIOLATION + target_offset)?;\n            }\n            X86Instruction::load(OperandSize::S64, RAX, RCX, X86IndirectAccess::Offset(MemoryRegion::VM_ADDR_OFFSET)).emit(self)?; // RCX = region.vm_addr\n            X86Instruction::cmp(OperandSize::S64, RCX, R11, None).emit(self)?; // vm_addr < region.vm_addr\n            emit_jcc(self, 0x82, TARGET_PC_MEMORY_ACCESS_VIOLATION + target_offset)?;\n            emit_alu(self, OperandSize::S64, 0x29, RCX, R11, 0, None)?; // vm_addr -= region.vm_addr\n            if !self.config.dynamic_stack_frames && self.config.enable_stack_frame_gaps {\n                X86Instruction::load(OperandSize::S8, RAX, RCX, X86IndirectAccess::Offset(MemoryRegion::VM_GAP_SHIFT_OFFSET)).emit(self)?; // RCX = region.vm_gap_shift;\n                X86Instruction::mov(OperandSize::S64, R11, RDX).emit(self)?; // RDX = R11;\n                emit_alu(self, OperandSize::S64, 0xd3, 5, RDX, 0, None)?; // RDX = R11 >> region.vm_gap_shift;\n                X86Instruction::test_immediate(OperandSize::S64, RDX, 1, None).emit(self)?; // (RDX & 1) != 0\n                emit_jcc(self, 0x85, TARGET_PC_MEMORY_ACCESS_VIOLATION + target_offset)?;\n                X86Instruction::load_immediate(OperandSize::S64, RDX, -1).emit(self)?; // RDX = -1;\n                emit_alu(self, OperandSize::S64, 0xd3, 4, RDX, 0, None)?; // gap_mask = -1 << region.vm_gap_shift;\n                X86Instruction::mov(OperandSize::S64, RDX, RCX).emit(self)?; // RCX = RDX;\n                emit_alu(self, OperandSize::S64, 0xf7, 2, RCX, 0, None)?; // inverse_gap_mask = !gap_mask;\n                emit_alu(self, OperandSize::S64, 0x21, R11, RCX, 0, None)?; // below_gap = R11 & inverse_gap_mask;\n                emit_alu(self, OperandSize::S64, 0x21, RDX, R11, 0, None)?; // above_gap = R11 & gap_mask;\n                emit_alu(self, OperandSize::S64, 0xc1, 5, R11, 1, None)?; // above_gap >>= 1;\n                emit_alu(self, OperandSize::S64, 0x09, RCX, R11, 0, None)?; // gapped_offset = above_gap | below_gap;\n            }\n            X86Instruction::lea(OperandSize::S64, R11, RCX, Some(X86IndirectAccess::Offset(*len))).emit(self)?; // RCX = R11 + len;\n            X86Instruction::cmp(OperandSize::S64, RCX, RAX, Some(X86IndirectAccess::Offset(MemoryRegion::LEN_OFFSET))).emit(self)?; // region.len < R11 + len\n            emit_jcc(self, 0x82, TARGET_PC_MEMORY_ACCESS_VIOLATION + target_offset)?;\n            emit_alu(self, OperandSize::S64, 0x03, R11, RAX, 0, Some(X86IndirectAccess::Offset(MemoryRegion::HOST_ADDR_OFFSET)))?; // R11 += region.host_addr;\n            if !self.config.dynamic_stack_frames && self.config.enable_stack_frame_gaps {\n                X86Instruction::pop(RDX).emit(self)?;\n            }\n            X86Instruction::pop(RCX).emit(self)?;\n            X86Instruction::pop(RAX).emit(self)?;\n            emit_alu(self, OperandSize::S64, 0x81, 0, RSP, 8, None)?;\n            X86Instruction::return_near().emit(self)?;\n\n            set_anchor(self, TARGET_PC_MEMORY_ACCESS_VIOLATION + target_offset);\n            emit_alu(self, OperandSize::S64, 0x31, R11, R11, 0, None)?; // R11 = 0;\n            X86Instruction::load(OperandSize::S64, RSP, R11, X86IndirectAccess::OffsetIndexShift(stack_offset, R11, 0)).emit(self)?;\n            emit_rust_call(self, Value::Constant64(MemoryMapping::generate_access_violation::<UserError> as *const u8 as i64, false), &[\n                Argument { index: 3, value: Value::Register(R11) }, // Specify first as the src register could be overwritten by other arguments\n                Argument { index: 4, value: Value::Constant64(*len as i64, false) },\n                Argument { index: 2, value: Value::Constant64(*access_type as i64, false) },\n                Argument { index: 1, value: Value::RegisterPlusConstant32(R10, self.program_argument_key, false) }, // jit_program_argument.memory_mapping\n                Argument { index: 0, value: Value::RegisterIndirect(RBP, slot_on_environment_stack(self, EnvironmentStackSlot::OptRetValPtr), false) }, // Pointer to optional typed return value\n            ], None, true)?;\n            emit_alu(self, OperandSize::S64, 0x81, 0, RSP, stack_offset as i64 + 8, None)?; // Drop R11, RAX, RCX, RDX from stack\n            X86Instruction::pop(R11).emit(self)?; // Put callers PC in R11\n            emit_call(self, TARGET_PC_TRANSLATE_PC)?;\n            emit_jmp(self, TARGET_PC_EXCEPTION_AT)?;\n        }\n        Ok(())\n    }\n\n    fn generate_exception_handlers<E: UserDefinedError>(&mut self) -> Result<(), EbpfError<E>> {\n        // Handler for EbpfError::ExceededMaxInstructions\n        set_anchor(self, TARGET_PC_CALL_EXCEEDED_MAX_INSTRUCTIONS);\n        emit_set_exception_kind::<E>(self, EbpfError::ExceededMaxInstructions(0, 0))?;\n        X86Instruction::mov(OperandSize::S64, ARGUMENT_REGISTERS[0], R11).emit(self)?; // R11 = instruction_meter;\n        emit_profile_instruction_count_finalize(self, true)?;\n        emit_jmp(self, TARGET_PC_EPILOGUE)?;\n\n        // Handler for EbpfError::CallDepthExceeded\n        set_anchor(self, TARGET_PC_CALL_DEPTH_EXCEEDED);\n        emit_set_exception_kind::<E>(self, EbpfError::CallDepthExceeded(0, 0))?;\n        X86Instruction::store_immediate(OperandSize::S64, R10, X86IndirectAccess::Offset(24), self.config.max_call_depth as i64).emit(self)?; // depth = jit.config.max_call_depth;\n        emit_jmp(self, TARGET_PC_EXCEPTION_AT)?;\n\n        // Handler for EbpfError::CallOutsideTextSegment\n        set_anchor(self, TARGET_PC_CALL_OUTSIDE_TEXT_SEGMENT);\n        emit_set_exception_kind::<E>(self, EbpfError::CallOutsideTextSegment(0, 0))?;\n        X86Instruction::store(OperandSize::S64, REGISTER_MAP[0], R10, X86IndirectAccess::Offset(24)).emit(self)?; // target_address = RAX;\n        emit_jmp(self, TARGET_PC_EXCEPTION_AT)?;\n\n        // Handler for EbpfError::DivideByZero\n        set_anchor(self, TARGET_PC_DIV_BY_ZERO);\n        emit_set_exception_kind::<E>(self, EbpfError::DivideByZero(0))?;\n        emit_jmp(self, TARGET_PC_EXCEPTION_AT)?;\n\n        // Handler for EbpfError::DivideOverflow\n        set_anchor(self, TARGET_PC_DIV_OVERFLOW);\n        emit_set_exception_kind::<E>(self, EbpfError::DivideOverflow(0))?;\n        emit_jmp(self, TARGET_PC_EXCEPTION_AT)?;\n\n        // Handler for EbpfError::UnsupportedInstruction\n        set_anchor(self, TARGET_PC_CALLX_UNSUPPORTED_INSTRUCTION);\n        // Load BPF target pc from stack (which was saved in TARGET_PC_BPF_CALL_REG)\n        X86Instruction::load(OperandSize::S64, RSP, R11, X86IndirectAccess::OffsetIndexShift(-16, RSP, 0)).emit(self)?; // R11 = RSP[-16];\n        // emit_jmp(self, TARGET_PC_CALL_UNSUPPORTED_INSTRUCTION)?; // Fall-through\n\n        // Handler for EbpfError::UnsupportedInstruction\n        set_anchor(self, TARGET_PC_CALL_UNSUPPORTED_INSTRUCTION);\n        if self.config.enable_instruction_tracing {\n            emit_call(self, TARGET_PC_TRACE)?;\n        }\n        emit_set_exception_kind::<E>(self, EbpfError::UnsupportedInstruction(0))?;\n        // emit_jmp(self, TARGET_PC_EXCEPTION_AT)?; // Fall-through\n\n        // Handler for exceptions which report their pc\n        set_anchor(self, TARGET_PC_EXCEPTION_AT);\n        // Validate that we did not reach the instruction meter limit before the exception occured\n        if self.config.enable_instruction_meter {\n            emit_validate_instruction_count(self, false, None)?;\n        }\n        emit_profile_instruction_count_finalize(self, true)?;\n        emit_jmp(self, TARGET_PC_EPILOGUE)?;\n\n        // Handler for syscall exceptions\n        set_anchor(self, TARGET_PC_RUST_EXCEPTION);\n        emit_profile_instruction_count_finalize(self, false)?;\n        emit_jmp(self, TARGET_PC_EPILOGUE)\n    }\n\n    fn generate_prologue<E: UserDefinedError, I: InstructionMeter>(&mut self) -> Result<(), EbpfError<E>> {\n        // Place the environment on the stack according to EnvironmentStackSlot\n\n        // Save registers\n        for reg in CALLEE_SAVED_REGISTERS.iter() {\n            X86Instruction::push(*reg, None).emit(self)?;\n        }\n\n        // Initialize CallDepth to 0\n        X86Instruction::load_immediate(OperandSize::S64, REGISTER_MAP[FRAME_PTR_REG], 0).emit(self)?;\n        X86Instruction::push(REGISTER_MAP[FRAME_PTR_REG], None).emit(self)?;\n\n        // Initialize the BPF frame and stack pointers (BpfFramePtr and BpfStackPtr)\n        if self.config.dynamic_stack_frames {\n            // The stack is fully descending from MM_STACK_START + stack_size to MM_STACK_START\n            X86Instruction::load_immediate(OperandSize::S64, REGISTER_MAP[FRAME_PTR_REG], MM_STACK_START as i64 + self.config.stack_size() as i64).emit(self)?;\n            // Push BpfFramePtr\n            X86Instruction::push(REGISTER_MAP[FRAME_PTR_REG], None).emit(self)?;\n            // Push BpfStackPtr\n            X86Instruction::push(REGISTER_MAP[FRAME_PTR_REG], None).emit(self)?;\n        } else {\n            // The frames are ascending from MM_STACK_START to MM_STACK_START + stack_size. The stack within the frames is descending.\n            X86Instruction::load_immediate(OperandSize::S64, REGISTER_MAP[FRAME_PTR_REG], MM_STACK_START as i64 + self.config.stack_frame_size as i64).emit(self)?;\n            // Push BpfFramePtr\n            X86Instruction::push(REGISTER_MAP[FRAME_PTR_REG], None).emit(self)?;\n            // When using static frames BpfStackPtr is not used\n            X86Instruction::load_immediate(OperandSize::S64, RBP, 0).emit(self)?;\n            X86Instruction::push(RBP, None).emit(self)?;\n        }\n\n        // Save pointer to optional typed return value\n        X86Instruction::push(ARGUMENT_REGISTERS[0], None).emit(self)?;\n\n        // Save initial value of instruction_meter.get_remaining()\n        emit_rust_call(self, Value::Constant64(I::get_remaining as *const u8 as i64, false), &[\n            Argument { index: 0, value: Value::Register(ARGUMENT_REGISTERS[3]) },\n        ], Some(ARGUMENT_REGISTERS[0]), false)?;\n        X86Instruction::push(ARGUMENT_REGISTERS[0], None).emit(self)?;\n\n        // Save instruction meter\n        X86Instruction::push(ARGUMENT_REGISTERS[3], None).emit(self)?;\n\n        // Initialize stop watch\n        emit_alu(self, OperandSize::S64, 0x31, R11, R11, 0, None)?; // R11 ^= R11;\n        X86Instruction::push(R11, None).emit(self)?;\n        X86Instruction::push(R11, None).emit(self)?;\n\n        // Initialize frame pointer\n        X86Instruction::mov(OperandSize::S64, RSP, RBP).emit(self)?;\n        emit_alu(self, OperandSize::S64, 0x81, 0, RBP, 8 * (EnvironmentStackSlot::SlotCount as i64 - 1 + self.environment_stack_key as i64), None)?;\n\n        // Save JitProgramArgument\n        X86Instruction::lea(OperandSize::S64, ARGUMENT_REGISTERS[2], R10, Some(X86IndirectAccess::Offset(-self.program_argument_key))).emit(self)?;\n\n        // Zero BPF registers\n        for reg in REGISTER_MAP.iter() {\n            if *reg != REGISTER_MAP[1] && *reg != REGISTER_MAP[FRAME_PTR_REG] {\n                X86Instruction::load_immediate(OperandSize::S64, *reg, 0).emit(self)?;\n            }\n        }\n\n        Ok(())\n    }\n\n    fn generate_epilogue<E: UserDefinedError>(&mut self) -> Result<(), EbpfError<E>> {\n        // Quit gracefully\n        set_anchor(self, TARGET_PC_EXIT);\n        emit_validate_instruction_count(self, false, None)?;\n        emit_profile_instruction_count_finalize(self, false)?;\n\n        X86Instruction::load(OperandSize::S64, RBP, R10, X86IndirectAccess::Offset(slot_on_environment_stack(self, EnvironmentStackSlot::OptRetValPtr))).emit(self)?;\n        X86Instruction::store(OperandSize::S64, REGISTER_MAP[0], R10, X86IndirectAccess::Offset(8)).emit(self)?; // result.return_value = R0;\n        X86Instruction::load_immediate(OperandSize::S64, REGISTER_MAP[0], 0).emit(self)?;\n        X86Instruction::store(OperandSize::S64, REGISTER_MAP[0], R10, X86IndirectAccess::Offset(0)).emit(self)?;  // result.is_error = false;\n\n        // Epilogue\n        set_anchor(self, TARGET_PC_EPILOGUE);\n\n        // Print stop watch value\n        fn stopwatch_result(numerator: u64, denominator: u64) {\n            println!(\"Stop watch: {} / {} = {}\", numerator, denominator, if denominator == 0 { 0.0 } else { numerator as f64 / denominator as f64 });\n        }\n        if self.stopwatch_is_active {\n            emit_rust_call(self, Value::Constant64(stopwatch_result as *const u8 as i64, false), &[\n                Argument { index: 1, value: Value::RegisterIndirect(RBP, slot_on_environment_stack(self, EnvironmentStackSlot::StopwatchDenominator), false) },\n                Argument { index: 0, value: Value::RegisterIndirect(RBP, slot_on_environment_stack(self, EnvironmentStackSlot::StopwatchNumerator), false) },\n            ], None, false)?;\n        }\n\n        // Store instruction_meter in RAX\n        X86Instruction::mov(OperandSize::S64, ARGUMENT_REGISTERS[0], RAX).emit(self)?;\n\n        // Restore stack pointer in case the BPF stack was used\n        X86Instruction::lea(OperandSize::S64, RBP, RSP, Some(X86IndirectAccess::Offset(slot_on_environment_stack(self, EnvironmentStackSlot::LastSavedRegister)))).emit(self)?;\n\n        // Restore registers\n        for reg in CALLEE_SAVED_REGISTERS.iter().rev() {\n            X86Instruction::pop(*reg).emit(self)?;\n        }\n\n        X86Instruction::return_near().emit(self)\n    }\n\n    pub fn emit_random_noop<E: UserDefinedError>(&mut self) -> Result<(), EbpfError<E>> {\n        if self.config.noop_instruction_ratio != 0.0 && self.diversification_rng.gen_bool(self.config.noop_instruction_ratio) {\n            // X86Instruction::noop().emit(self)\n            emit::<u8, E>(self, 0x90)\n        } else {\n            Ok(())\n        }\n    }\n\n    fn resolve_jumps(&mut self) {\n        for jump in &self.pc_section_jumps {\n            self.result.pc_section[jump.location] = jump.get_target_offset(self);\n        }\n        for jump in &self.text_section_jumps {\n            let offset_value = jump.get_target_offset(self) as i32\n                - jump.location as i32 // Relative jump\n                - mem::size_of::<i32>() as i32; // Jump from end of instruction\n            unsafe {\n                ptr::write_unaligned(\n                    self.result.text_section.as_ptr().add(jump.location) as *mut i32,\n                    offset_value,\n                );\n            }\n        }\n        let call_unsupported_instruction = self.handler_anchors.get(&TARGET_PC_CALL_UNSUPPORTED_INSTRUCTION).unwrap();\n        let callx_unsupported_instruction = self.handler_anchors.get(&TARGET_PC_CALLX_UNSUPPORTED_INSTRUCTION).unwrap();\n        for offset in self.result.pc_section.iter_mut() {\n            if *offset == *call_unsupported_instruction as u64 {\n                // Turns compiletime exception handlers to runtime ones (as they need to turn the host PC back into a BPF PC)\n                *offset = *callx_unsupported_instruction as u64;\n            }\n            *offset = unsafe { (self.result.text_section.as_ptr() as *const u8).add(*offset as usize) } as u64;\n        }\n    }\n}\n\n#[cfg(all(test, target_arch = \"x86_64\", not(target_os = \"windows\")))]\nmod tests {\n    use super::*;\n    use crate::{syscalls, vm::{SyscallRegistry, SyscallObject, TestInstructionMeter}, elf::register_bpf_function};\n    use std::collections::BTreeMap;\n    use byteorder::{LittleEndian, ByteOrder};\n\n    fn create_mockup_executable(program: &[u8]) -> Pin<Box<Executable::<UserError, TestInstructionMeter>>> {\n        let config = Config {\n            noop_instruction_ratio: 0.0,\n            ..Config::default()\n        };\n        let mut syscall_registry = SyscallRegistry::default();\n        syscall_registry\n            .register_syscall_by_hash(\n                0xFFFFFFFF,\n                syscalls::BpfGatherBytes::init::<syscalls::BpfSyscallContext, UserError>,\n                syscalls::BpfGatherBytes::call,\n            )\n            .unwrap();\n        let mut bpf_functions = BTreeMap::new();\n        register_bpf_function(\n            &config,\n            &mut bpf_functions,\n            &syscall_registry,\n            0,\n            \"entrypoint\",\n        )\n        .unwrap();\n        bpf_functions.insert(0xFFFFFFFF, (8, \"foo\".to_string()));\n        Executable::<UserError, TestInstructionMeter>::from_text_bytes(\n            program,\n            None,\n            config,\n            syscall_registry,\n            bpf_functions,\n        )\n        .unwrap()\n    }\n    \n    #[test]\n    fn test_code_length_estimate() {\n        const INSTRUCTION_COUNT: usize = 256;\n        let mut prog = [0; ebpf::INSN_SIZE * INSTRUCTION_COUNT];\n    \n        let empty_program_machine_code_length = {\n            prog[0] = ebpf::EXIT;\n            let mut executable = create_mockup_executable(&[]);\n            Executable::<UserError, TestInstructionMeter>::jit_compile(&mut executable).unwrap();\n            executable.get_compiled_program().unwrap().machine_code_length()\n        };\n        assert!(empty_program_machine_code_length <= MAX_EMPTY_PROGRAM_MACHINE_CODE_LENGTH);\n    \n        for opcode in 0..255 {\n            for pc in 0..INSTRUCTION_COUNT {\n                prog[pc * ebpf::INSN_SIZE] = opcode;\n                prog[pc * ebpf::INSN_SIZE + 1] = 0x88;\n                prog[pc * ebpf::INSN_SIZE + 2] = 0xFF;\n                prog[pc * ebpf::INSN_SIZE + 3] = 0xFF;\n                LittleEndian::write_u32(&mut prog[pc * ebpf::INSN_SIZE + 4..], match opcode {\n                    0x8D => 8,\n                    0xD4 | 0xDC => 16,\n                    _ => 0xFFFFFFFF,\n                });\n            }\n            let mut executable = create_mockup_executable(&prog);\n            let result = Executable::<UserError, TestInstructionMeter>::jit_compile(&mut executable);\n            if result.is_err() {\n                assert!(matches!(result.unwrap_err(), EbpfError::UnsupportedInstruction(_)));\n                continue;\n            }\n            let machine_code_length = executable.get_compiled_program().unwrap().machine_code_length() - empty_program_machine_code_length;\n            let instruction_count = if opcode == 0x18 { INSTRUCTION_COUNT / 2 } else { INSTRUCTION_COUNT };\n            let machine_code_length_per_instruction = (machine_code_length as f64 / instruction_count as f64 + 0.5) as usize;\n            assert!(machine_code_length_per_instruction <= MAX_MACHINE_CODE_LENGTH_PER_INSTRUCTION);\n        }\n    }\n}\n", "#![allow(clippy::integer_arithmetic)]\n// Copyright 2020 Solana Maintainers <maintainers@solana.com>\n//\n// Licensed under the Apache License, Version 2.0 <http://www.apache.org/licenses/LICENSE-2.0> or\n// the MIT license <http://opensource.org/licenses/MIT>, at your option. This file may not be\n// copied, modified, or distributed except according to those terms.\n\nextern crate byteorder;\nextern crate libc;\nextern crate solana_rbpf;\nextern crate test_utils;\nextern crate thiserror;\n\nuse byteorder::{ByteOrder, LittleEndian};\n#[cfg(all(not(windows), target_arch = \"x86_64\"))]\nuse rand::{rngs::SmallRng, RngCore, SeedableRng};\nuse solana_rbpf::{\n    assembler::assemble,\n    ebpf,\n    elf::{register_bpf_function, ElfError, Executable},\n    error::EbpfError,\n    memory_region::{AccessType, MemoryMapping, MemoryRegion},\n    syscalls::{self, BpfSyscallContext, Result},\n    user_error::UserError,\n    vm::{Config, EbpfVm, SyscallObject, SyscallRegistry, TestInstructionMeter},\n};\nuse std::{collections::BTreeMap, fs::File, io::Read};\nuse test_utils::{PROG_TCP_PORT_80, TCP_SACK_ASM, TCP_SACK_MATCH, TCP_SACK_NOMATCH};\n\nmacro_rules! test_interpreter_and_jit {\n    (register, $syscall_registry:expr, $location:expr => $syscall_init:expr; $syscall_function:expr) => {\n        $syscall_registry\n            .register_syscall_by_name($location, $syscall_init, $syscall_function)\n            .unwrap();\n    };\n    (bind, $vm:expr, $syscall_context:expr) => {\n        $vm.bind_syscall_context_objects($syscall_context).unwrap();\n    };\n    ($executable:expr, $mem:tt, $syscall_context:expr, $check:block, $expected_instruction_count:expr) => {\n        #[allow(unused_mut)]\n        let mut check_closure = $check;\n        let (instruction_count_interpreter, _tracer_interpreter) = {\n            let mut mem = $mem;\n            let mem_region = MemoryRegion::new_writable(&mut mem, ebpf::MM_INPUT_START);\n            let mut vm = EbpfVm::new(&$executable, &mut [], vec![mem_region]).unwrap();\n            test_interpreter_and_jit!(bind, vm, $syscall_context);\n            let result = vm.execute_program_interpreted(&mut TestInstructionMeter {\n                remaining: $expected_instruction_count,\n            });\n            assert!(check_closure(&vm, result));\n            (vm.get_total_instruction_count(), vm.get_tracer().clone())\n        };\n        #[cfg(all(not(windows), target_arch = \"x86_64\"))]\n        {\n            #[allow(unused_mut)]\n            let mut check_closure = $check;\n            let compilation_result =\n                Executable::<UserError, TestInstructionMeter>::jit_compile(&mut $executable);\n            let mut mem = $mem;\n            let mem_region = MemoryRegion::new_writable(&mut mem, ebpf::MM_INPUT_START);\n            let mut vm = EbpfVm::new(&$executable, &mut [], vec![mem_region]).unwrap();\n            match compilation_result {\n                Err(err) => assert!(check_closure(&vm, Err(err))),\n                Ok(()) => {\n                    test_interpreter_and_jit!(bind, vm, $syscall_context);\n                    let result = vm.execute_program_jit(&mut TestInstructionMeter {\n                        remaining: $expected_instruction_count,\n                    });\n                    let tracer_jit = vm.get_tracer();\n                    if !check_closure(&vm, result)\n                        || !solana_rbpf::vm::Tracer::compare(&_tracer_interpreter, tracer_jit)\n                    {\n                        let analysis =\n                            solana_rbpf::static_analysis::Analysis::from_executable(&$executable)\n                                .unwrap();\n                        let stdout = std::io::stdout();\n                        _tracer_interpreter\n                            .write(&mut stdout.lock(), &analysis)\n                            .unwrap();\n                        tracer_jit.write(&mut stdout.lock(), &analysis).unwrap();\n                        panic!();\n                    }\n                    if $executable.get_config().enable_instruction_meter {\n                        let instruction_count_jit = vm.get_total_instruction_count();\n                        assert_eq!(instruction_count_interpreter, instruction_count_jit);\n                    }\n                }\n            }\n        }\n        if $executable.get_config().enable_instruction_meter {\n            assert_eq!(instruction_count_interpreter, $expected_instruction_count);\n        }\n    };\n}\n\nmacro_rules! test_interpreter_and_jit_asm {\n    ($source:tt, $config:tt, $mem:tt, ($($location:expr => $syscall_init:expr; $syscall_function:expr),* $(,)?), $syscall_context:expr, $check:block, $expected_instruction_count:expr) => {\n        #[allow(unused_mut)]\n        {\n            let mut syscall_registry = SyscallRegistry::default();\n            $(test_interpreter_and_jit!(register, syscall_registry, $location => $syscall_init; $syscall_function);)*\n            let mut executable = assemble($source, None, $config, syscall_registry).unwrap();\n            test_interpreter_and_jit!(executable, $mem, $syscall_context, $check, $expected_instruction_count);\n        }\n    };\n    ($source:tt, $mem:tt, ($($location:expr => $syscall_init:expr; $syscall_function:expr),* $(,)?), $syscall_context:expr, $check:block, $expected_instruction_count:expr) => {\n        #[allow(unused_mut)]\n        {\n            let config = Config {\n                enable_instruction_tracing: true,\n                ..Config::default()\n            };\n            test_interpreter_and_jit_asm!($source, config, $mem, ($($location => $syscall_init; $syscall_function),*), $syscall_context, $check, $expected_instruction_count);\n        }\n    };\n}\n\nmacro_rules! test_interpreter_and_jit_elf {\n    ($source:tt, $config:tt, $mem:tt, ($($location:expr => $syscall_init:expr; $syscall_function:expr),* $(,)?), $syscall_context:expr, $check:block, $expected_instruction_count:expr) => {\n        let mut file = File::open($source).unwrap();\n        let mut elf = Vec::new();\n        file.read_to_end(&mut elf).unwrap();\n        #[allow(unused_mut)]\n        {\n            let mut syscall_registry = SyscallRegistry::default();\n            $(test_interpreter_and_jit!(register, syscall_registry, $location => $syscall_init; $syscall_function);)*\n            let mut executable = Executable::<UserError, TestInstructionMeter>::from_elf(&elf, None, $config, syscall_registry).unwrap();\n            test_interpreter_and_jit!(executable, $mem, $syscall_context, $check, $expected_instruction_count);\n        }\n    };\n    ($source:tt, $mem:tt, ($($location:expr => $syscall_init:expr; $syscall_function:expr),* $(,)?), $syscall_context:expr, $check:block, $expected_instruction_count:expr) => {\n        let config = Config {\n            enable_instruction_tracing: true,\n            ..Config::default()\n        };\n        test_interpreter_and_jit_elf!($source, config, $mem, ($($location => $syscall_init; $syscall_function),*), $syscall_context, $check, $expected_instruction_count);\n    };\n}\n\n// BPF_ALU : Arithmetic and Logic\n\n#[test]\nfn test_mov() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov32 r1, 1\n        mov32 r0, r1\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x1 } },\n        3\n    );\n}\n\n#[test]\nfn test_mov32_imm_large() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov32 r0, -1\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0xffffffff } },\n        2\n    );\n}\n\n#[test]\nfn test_mov_large() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov32 r1, -1\n        mov32 r0, r1\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0xffffffff } },\n        3\n    );\n}\n\n#[test]\nfn test_bounce() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov r0, 1\n        mov r6, r0\n        mov r7, r6\n        mov r8, r7\n        mov r9, r8\n        mov r0, r9\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x1 } },\n        7\n    );\n}\n\n#[test]\nfn test_add32() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov32 r0, 0\n        mov32 r1, 2\n        add32 r0, 1\n        add32 r0, r1\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x3 } },\n        5\n    );\n}\n\n#[test]\nfn test_neg32() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov32 r0, 2\n        neg32 r0\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0xfffffffe } },\n        3\n    );\n}\n\n#[test]\nfn test_neg64() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov32 r0, 2\n        neg r0\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0xfffffffffffffffe } },\n        3\n    );\n}\n\n#[test]\nfn test_alu32_arithmetic() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov32 r0, 0\n        mov32 r1, 1\n        mov32 r2, 2\n        mov32 r3, 3\n        mov32 r4, 4\n        mov32 r5, 5\n        mov32 r6, 6\n        mov32 r7, 7\n        mov32 r8, 8\n        mov32 r9, 9\n        add32 r0, 23\n        add32 r0, r7\n        sub32 r0, 13\n        sub32 r0, r1\n        mul32 r0, 7\n        mul32 r0, r3\n        div32 r0, 2\n        div32 r0, r4\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x2a } },\n        19\n    );\n}\n\n#[test]\nfn test_alu64_arithmetic() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov r0, 0\n        mov r1, 1\n        mov r2, 2\n        mov r3, 3\n        mov r4, 4\n        mov r5, 5\n        mov r6, 6\n        mov r7, 7\n        mov r8, 8\n        mov r9, 9\n        add r0, 23\n        add r0, r7\n        sub r0, 13\n        sub r0, r1\n        mul r0, 7\n        mul r0, r3\n        div r0, 2\n        div r0, r4\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x2a } },\n        19\n    );\n}\n\n#[test]\nfn test_mul128() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov r0, r1\n        mov r2, 30\n        mov r3, 0\n        mov r4, 20\n        mov r5, 0\n        mul64 r3, r4\n        mul64 r5, r2\n        add64 r5, r3\n        mov64 r0, r2\n        rsh64 r0, 0x20\n        mov64 r3, r4\n        rsh64 r3, 0x20\n        mov64 r6, r3\n        mul64 r6, r0\n        add64 r5, r6\n        lsh64 r4, 0x20\n        rsh64 r4, 0x20\n        mov64 r6, r4\n        mul64 r6, r0\n        lsh64 r2, 0x20\n        rsh64 r2, 0x20\n        mul64 r4, r2\n        mov64 r0, r4\n        rsh64 r0, 0x20\n        add64 r0, r6\n        mov64 r6, r0\n        rsh64 r6, 0x20\n        add64 r5, r6\n        mul64 r3, r2\n        lsh64 r0, 0x20\n        rsh64 r0, 0x20\n        add64 r0, r3\n        mov64 r2, r0\n        rsh64 r2, 0x20\n        add64 r5, r2\n        stxdw [r1+0x8], r5\n        lsh64 r0, 0x20\n        lsh64 r4, 0x20\n        rsh64 r4, 0x20\n        or64 r0, r4\n        stxdw [r1+0x0], r0\n        exit\",\n        [0; 16],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 600 } },\n        42\n    );\n}\n\n#[test]\nfn test_alu32_logic() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov32 r0, 0\n        mov32 r1, 1\n        mov32 r2, 2\n        mov32 r3, 3\n        mov32 r4, 4\n        mov32 r5, 5\n        mov32 r6, 6\n        mov32 r7, 7\n        mov32 r8, 8\n        or32 r0, r5\n        or32 r0, 0xa0\n        and32 r0, 0xa3\n        mov32 r9, 0x91\n        and32 r0, r9\n        lsh32 r0, 22\n        lsh32 r0, r8\n        rsh32 r0, 19\n        rsh32 r0, r7\n        xor32 r0, 0x03\n        xor32 r0, r2\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x11 } },\n        21\n    );\n}\n\n#[test]\nfn test_alu64_logic() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov r0, 0\n        mov r1, 1\n        mov r2, 2\n        mov r3, 3\n        mov r4, 4\n        mov r5, 5\n        mov r6, 6\n        mov r7, 7\n        mov r8, 8\n        or r0, r5\n        or r0, 0xa0\n        and r0, 0xa3\n        mov r9, 0x91\n        and r0, r9\n        lsh r0, 32\n        lsh r0, 22\n        lsh r0, r8\n        rsh r0, 32\n        rsh r0, 19\n        rsh r0, r7\n        xor r0, 0x03\n        xor r0, r2\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x11 } },\n        23\n    );\n}\n\n#[test]\nfn test_arsh32_high_shift() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov r0, 8\n        lddw r1, 0x100000001\n        arsh32 r0, r1\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x4 } },\n        4\n    );\n}\n\n#[test]\nfn test_arsh32_imm() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov32 r0, 0xf8\n        lsh32 r0, 28\n        arsh32 r0, 16\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0xffff8000 } },\n        4\n    );\n}\n\n#[test]\nfn test_arsh32_reg() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov32 r0, 0xf8\n        mov32 r1, 16\n        lsh32 r0, 28\n        arsh32 r0, r1\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0xffff8000 } },\n        5\n    );\n}\n\n#[test]\nfn test_arsh64() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov32 r0, 1\n        lsh r0, 63\n        arsh r0, 55\n        mov32 r1, 5\n        arsh r0, r1\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0xfffffffffffffff8 } },\n        6\n    );\n}\n\n#[test]\nfn test_lsh64_reg() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov r0, 0x1\n        mov r7, 4\n        lsh r0, r7\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x10 } },\n        4\n    );\n}\n\n#[test]\nfn test_rhs32_imm() {\n    test_interpreter_and_jit_asm!(\n        \"\n        xor r0, r0\n        sub r0, 1\n        rsh32 r0, 8\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x00ffffff } },\n        4\n    );\n}\n\n#[test]\nfn test_rsh64_reg() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov r0, 0x10\n        mov r7, 4\n        rsh r0, r7\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x1 } },\n        4\n    );\n}\n\n#[test]\nfn test_be16() {\n    test_interpreter_and_jit_asm!(\n        \"\n        ldxh r0, [r1]\n        be16 r0\n        exit\",\n        [0x11, 0x22],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x1122 } },\n        3\n    );\n}\n\n#[test]\nfn test_be16_high() {\n    test_interpreter_and_jit_asm!(\n        \"\n        ldxdw r0, [r1]\n        be16 r0\n        exit\",\n        [0x11, 0x22, 0x33, 0x44, 0x55, 0x66, 0x77, 0x88],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x1122 } },\n        3\n    );\n}\n\n#[test]\nfn test_be32() {\n    test_interpreter_and_jit_asm!(\n        \"\n        ldxw r0, [r1]\n        be32 r0\n        exit\",\n        [0x11, 0x22, 0x33, 0x44],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x11223344 } },\n        3\n    );\n}\n\n#[test]\nfn test_be32_high() {\n    test_interpreter_and_jit_asm!(\n        \"\n        ldxdw r0, [r1]\n        be32 r0\n        exit\",\n        [0x11, 0x22, 0x33, 0x44, 0x55, 0x66, 0x77, 0x88],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x11223344 } },\n        3\n    );\n}\n\n#[test]\nfn test_be64() {\n    test_interpreter_and_jit_asm!(\n        \"\n        ldxdw r0, [r1]\n        be64 r0\n        exit\",\n        [0x11, 0x22, 0x33, 0x44, 0x55, 0x66, 0x77, 0x88],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x1122334455667788 } },\n        3\n    );\n}\n\n#[test]\nfn test_le16() {\n    test_interpreter_and_jit_asm!(\n        \"\n        ldxh r0, [r1]\n        le16 r0\n        exit\",\n        [0x22, 0x11],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x1122 } },\n        3\n    );\n}\n\n#[test]\nfn test_le16_high() {\n    test_interpreter_and_jit_asm!(\n        \"\n        ldxdw r0, [r1]\n        le16 r0\n        exit\",\n        [0x11, 0x22, 0x33, 0x44, 0x55, 0x66, 0x77, 0x88],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x2211 } },\n        3\n    );\n}\n\n#[test]\nfn test_le32() {\n    test_interpreter_and_jit_asm!(\n        \"\n        ldxw r0, [r1]\n        le32 r0\n        exit\",\n        [0x44, 0x33, 0x22, 0x11],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x11223344 } },\n        3\n    );\n}\n\n#[test]\nfn test_le32_high() {\n    test_interpreter_and_jit_asm!(\n        \"\n        ldxdw r0, [r1]\n        le32 r0\n        exit\",\n        [0x11, 0x22, 0x33, 0x44, 0x55, 0x66, 0x77, 0x88],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x44332211 } },\n        3\n    );\n}\n\n#[test]\nfn test_le64() {\n    test_interpreter_and_jit_asm!(\n        \"\n        ldxdw r0, [r1]\n        le64 r0\n        exit\",\n        [0x88, 0x77, 0x66, 0x55, 0x44, 0x33, 0x22, 0x11],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x1122334455667788 } },\n        3\n    );\n}\n\n#[test]\nfn test_mul32_imm() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov r0, 3\n        mul32 r0, 4\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0xc } },\n        3\n    );\n}\n\n#[test]\nfn test_mul32_reg() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov r0, 3\n        mov r1, 4\n        mul32 r0, r1\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0xc } },\n        4\n    );\n}\n\n#[test]\nfn test_mul32_reg_overflow() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov r0, 0x40000001\n        mov r1, 4\n        mul32 r0, r1\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x4 } },\n        4\n    );\n}\n\n#[test]\nfn test_mul64_imm() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov r0, 0x40000001\n        mul r0, 4\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x100000004 } },\n        3\n    );\n}\n\n#[test]\nfn test_mul64_reg() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov r0, 0x40000001\n        mov r1, 4\n        mul r0, r1\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x100000004 } },\n        4\n    );\n}\n\n#[test]\nfn test_div32_high_divisor() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov r0, 12\n        lddw r1, 0x100000004\n        div32 r0, r1\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x3 } },\n        4\n    );\n}\n\n#[test]\nfn test_div32_imm() {\n    test_interpreter_and_jit_asm!(\n        \"\n        lddw r0, 0x10000000c\n        div32 r0, 4\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x3 } },\n        3\n    );\n}\n\n#[test]\nfn test_div32_reg() {\n    test_interpreter_and_jit_asm!(\n        \"\n        lddw r0, 0x10000000c\n        mov r1, 4\n        div32 r0, r1\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x3 } },\n        4\n    );\n}\n\n#[test]\nfn test_sdiv32_imm() {\n    test_interpreter_and_jit_asm!(\n        \"\n        lddw r0, 0x10000000c\n        sdiv32 r0, 4\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x3 } },\n        3\n    );\n}\n\n#[test]\nfn test_sdiv32_reg() {\n    test_interpreter_and_jit_asm!(\n        \"\n        lddw r0, 0x10000000c\n        mov r1, 4\n        sdiv32 r0, r1\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x3 } },\n        4\n    );\n}\n\n#[test]\nfn test_div64_imm() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov r0, 0xc\n        lsh r0, 32\n        div r0, 4\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x300000000 } },\n        4\n    );\n}\n\n#[test]\nfn test_div64_reg() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov r0, 0xc\n        lsh r0, 32\n        mov r1, 4\n        div r0, r1\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x300000000 } },\n        5\n    );\n}\n\n#[test]\nfn test_sdiv64_imm() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov r0, 0xc\n        lsh r0, 32\n        sdiv r0, 4\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x300000000 } },\n        4\n    );\n}\n\n#[test]\nfn test_sdiv64_reg() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov r0, 0xc\n        lsh r0, 32\n        mov r1, 4\n        sdiv r0, r1\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x300000000 } },\n        5\n    );\n}\n\n#[test]\nfn test_err_div64_by_zero_reg() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov32 r0, 1\n        mov32 r1, 0\n        div r0, r1\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| matches!(res.unwrap_err(), EbpfError::DivideByZero(pc) if pc == 31) },\n        3\n    );\n}\n\n#[test]\nfn test_err_div32_by_zero_reg() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov32 r0, 1\n        mov32 r1, 0\n        div32 r0, r1\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| matches!(res.unwrap_err(), EbpfError::DivideByZero(pc) if pc == 31) },\n        3\n    );\n}\n\n#[test]\nfn test_err_sdiv64_by_zero_reg() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov32 r0, 1\n        mov32 r1, 0\n        sdiv r0, r1\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| matches!(res.unwrap_err(), EbpfError::DivideByZero(pc) if pc == 31) },\n        3\n    );\n}\n\n#[test]\nfn test_err_sdiv32_by_zero_reg() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov32 r0, 1\n        mov32 r1, 0\n        sdiv32 r0, r1\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| matches!(res.unwrap_err(), EbpfError::DivideByZero(pc) if pc == 31) },\n        3\n    );\n}\n\n#[test]\nfn test_err_sdiv64_overflow_imm() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov r0, 0x80\n        lsh r0, 56\n        sdiv r0, -1\n        exit\",\n        [],\n        (),\n        0,\n        {\n            |_vm, res: Result| matches!(res.unwrap_err(), EbpfError::DivideOverflow(pc) if pc == 31)\n        },\n        3\n    );\n}\n\n#[test]\nfn test_err_sdiv64_overflow_reg() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov r0, 0x80\n        lsh r0, 56\n        mov r1, -1\n        sdiv r0, r1\n        exit\",\n        [],\n        (),\n        0,\n        {\n            |_vm, res: Result| matches!(res.unwrap_err(), EbpfError::DivideOverflow(pc) if pc == 32)\n        },\n        4\n    );\n}\n\n#[test]\nfn test_err_sdiv32_overflow_imm() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov r0, 0x80\n        lsh r0, 24\n        sdiv32 r0, -1\n        exit\",\n        [],\n        (),\n        0,\n        {\n            |_vm, res: Result| matches!(res.unwrap_err(), EbpfError::DivideOverflow(pc) if pc == 31)\n        },\n        3\n    );\n}\n\n#[test]\nfn test_err_sdiv32_overflow_reg() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov r0, 0x80\n        lsh r0, 24\n        mov r1, -1\n        sdiv32 r0, r1\n        exit\",\n        [],\n        (),\n        0,\n        {\n            |_vm, res: Result| matches!(res.unwrap_err(), EbpfError::DivideOverflow(pc) if pc == 32)\n        },\n        4\n    );\n}\n\n#[test]\nfn test_mod32() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov32 r0, 5748\n        mod32 r0, 92\n        mov32 r1, 13\n        mod32 r0, r1\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x5 } },\n        5\n    );\n}\n\n#[test]\nfn test_mod32_imm() {\n    test_interpreter_and_jit_asm!(\n        \"\n        lddw r0, 0x100000003\n        mod32 r0, 3\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x0 } },\n        3\n    );\n}\n\n#[test]\nfn test_mod64() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov32 r0, -1316649930\n        lsh r0, 32\n        or r0, 0x100dc5c8\n        mov32 r1, 0xdde263e\n        lsh r1, 32\n        or r1, 0x3cbef7f3\n        mod r0, r1\n        mod r0, 0x658f1778\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x30ba5a04 } },\n        9\n    );\n}\n\n#[test]\nfn test_err_mod64_by_zero_reg() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov32 r0, 1\n        mov32 r1, 0\n        mod r0, r1\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| matches!(res.unwrap_err(), EbpfError::DivideByZero(pc) if pc == 31) },\n        3\n    );\n}\n\n#[test]\nfn test_err_mod_by_zero_reg() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov32 r0, 1\n        mov32 r1, 0\n        mod32 r0, r1\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| matches!(res.unwrap_err(), EbpfError::DivideByZero(pc) if pc == 31) },\n        3\n    );\n}\n\n// BPF_LD : Loads\n\n#[test]\nfn test_ldabsb() {\n    test_interpreter_and_jit_asm!(\n        \"\n        ldabsb 0x3\n        exit\",\n        [\n            0x00, 0x11, 0x22, 0x33, 0x44, 0x55, 0x66, 0x77, //\n            0x88, 0x99, 0xaa, 0xbb, 0xcc, 0xdd, 0xee, 0xff, //\n        ],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x33 } },\n        2\n    );\n}\n\n#[test]\nfn test_ldabsh() {\n    test_interpreter_and_jit_asm!(\n        \"\n        ldabsh 0x3\n        exit\",\n        [\n            0x00, 0x11, 0x22, 0x33, 0x44, 0x55, 0x66, 0x77, //\n            0x88, 0x99, 0xaa, 0xbb, 0xcc, 0xdd, 0xee, 0xff, //\n        ],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x4433 } },\n        2\n    );\n}\n\n#[test]\nfn test_ldabsw() {\n    test_interpreter_and_jit_asm!(\n        \"\n        ldabsw 0x3\n        exit\",\n        [\n            0x00, 0x11, 0x22, 0x33, 0x44, 0x55, 0x66, 0x77, //\n            0x88, 0x99, 0xaa, 0xbb, 0xcc, 0xdd, 0xee, 0xff, //\n        ],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x66554433 } },\n        2\n    );\n}\n\n#[test]\nfn test_ldabsdw() {\n    test_interpreter_and_jit_asm!(\n        \"\n        ldabsdw 0x3\n        exit\",\n        [\n            0x00, 0x11, 0x22, 0x33, 0x44, 0x55, 0x66, 0x77, //\n            0x88, 0x99, 0xaa, 0xbb, 0xcc, 0xdd, 0xee, 0xff, //\n        ],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0xaa99887766554433 } },\n        2\n    );\n}\n\n#[test]\nfn test_err_ldabsb_oob() {\n    test_interpreter_and_jit_asm!(\n        \"\n        ldabsb 0x33\n        exit\",\n        [\n            0x00, 0x11, 0x22, 0x33, 0x44, 0x55, 0x66, 0x77, //\n            0x88, 0x99, 0xaa, 0xbb, 0xcc, 0xdd, 0xee, 0xff, //\n        ],\n        (),\n        0,\n        {\n            |_vm, res: Result| {\n                matches!(res.unwrap_err(),\n                    EbpfError::AccessViolation(pc, access_type, vm_addr, len, name)\n                    if access_type == AccessType::Load && pc == 29 && vm_addr == 0x400000033 && len == 1 && name == \"input\"\n                )\n            }\n        },\n        1\n    );\n}\n\n#[test]\nfn test_err_ldabsb_nomem() {\n    test_interpreter_and_jit_asm!(\n        \"\n        ldabsb 0x33\n        exit\",\n        [],\n        (),\n        0,\n        {\n            |_vm, res: Result| {\n                matches!(res.unwrap_err(),\n                    EbpfError::AccessViolation(pc, access_type, vm_addr, len, name)\n                    if access_type == AccessType::Load && pc == 29 && vm_addr == 0x400000033 && len == 1 && name == \"input\"\n                )\n            }\n        },\n        1\n    );\n}\n\n#[test]\nfn test_ldindb() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov64 r1, 0x5\n        ldindb r1, 0x3\n        exit\",\n        [\n            0x00, 0x11, 0x22, 0x33, 0x44, 0x55, 0x66, 0x77, //\n            0x88, 0x99, 0xaa, 0xbb, 0xcc, 0xdd, 0xee, 0xff, //\n        ],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x88 } },\n        3\n    );\n}\n\n#[test]\nfn test_ldindh() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov64 r1, 0x5\n        ldindh r1, 0x3\n        exit\",\n        [\n            0x00, 0x11, 0x22, 0x33, 0x44, 0x55, 0x66, 0x77, //\n            0x88, 0x99, 0xaa, 0xbb, 0xcc, 0xdd, 0xee, 0xff, //\n        ],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x9988 } },\n        3\n    );\n}\n\n#[test]\nfn test_ldindw() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov64 r1, 0x4\n        ldindw r1, 0x1\n        exit\",\n        [\n            0x00, 0x11, 0x22, 0x33, 0x44, 0x55, 0x66, 0x77, //\n            0x88, 0x99, 0xaa, 0xbb, 0xcc, 0xdd, 0xee, 0xff, //\n        ],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x88776655 } },\n        3\n    );\n}\n\n#[test]\nfn test_ldinddw() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov64 r1, 0x2\n        ldinddw r1, 0x3\n        exit\",\n        [\n            0x00, 0x11, 0x22, 0x33, 0x44, 0x55, 0x66, 0x77, //\n            0x88, 0x99, 0xaa, 0xbb, 0xcc, 0xdd, 0xee, 0xff, //\n        ],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0xccbbaa9988776655 } },\n        3\n    );\n}\n\n#[test]\nfn test_err_ldindb_oob() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov64 r1, 0x5\n        ldindb r1, 0x33\n        exit\",\n        [\n            0x00, 0x11, 0x22, 0x33, 0x44, 0x55, 0x66, 0x77, //\n            0x88, 0x99, 0xaa, 0xbb, 0xcc, 0xdd, 0xee, 0xff, //\n        ],\n        (),\n        0,\n        {\n            |_vm, res: Result| {\n                matches!(res.unwrap_err(),\n                    EbpfError::AccessViolation(pc, access_type, vm_addr, len, name)\n                    if access_type == AccessType::Load && pc == 30 && vm_addr == 0x400000038 && len == 1 && name == \"input\"\n                )\n            }\n        },\n        2\n    );\n}\n\n#[test]\nfn test_err_ldindb_nomem() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov64 r1, 0x5\n        ldindb r1, 0x33\n        exit\",\n        [],\n        (),\n        0,\n        {\n            |_vm, res: Result| {\n                matches!(res.unwrap_err(),\n                    EbpfError::AccessViolation(pc, access_type, vm_addr, len, name)\n                    if access_type == AccessType::Load && pc == 30 && vm_addr == 0x400000038 && len == 1 && name == \"input\"\n                )\n            }\n        },\n        2\n    );\n}\n\n#[test]\nfn test_ldxb() {\n    test_interpreter_and_jit_asm!(\n        \"\n        ldxb r0, [r1+2]\n        exit\",\n        [0xaa, 0xbb, 0x11, 0xcc, 0xdd],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x11 } },\n        2\n    );\n}\n\n#[test]\nfn test_ldxh() {\n    test_interpreter_and_jit_asm!(\n        \"\n        ldxh r0, [r1+2]\n        exit\",\n        [0xaa, 0xbb, 0x11, 0x22, 0xcc, 0xdd],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x2211 } },\n        2\n    );\n}\n\n#[test]\nfn test_ldxw() {\n    test_interpreter_and_jit_asm!(\n        \"\n        ldxw r0, [r1+2]\n        exit\",\n        [\n            0xaa, 0xbb, 0x11, 0x22, 0x33, 0x44, 0xcc, 0xdd, //\n        ],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x44332211 } },\n        2\n    );\n}\n\n#[test]\nfn test_ldxh_same_reg() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov r0, r1\n        sth [r0], 0x1234\n        ldxh r0, [r0]\n        exit\",\n        [0xff, 0xff],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x1234 } },\n        4\n    );\n}\n\n#[test]\nfn test_lldxdw() {\n    test_interpreter_and_jit_asm!(\n        \"\n        ldxdw r0, [r1+2]\n        exit\",\n        [\n            0xaa, 0xbb, 0x11, 0x22, 0x33, 0x44, 0x55, 0x66, //\n            0x77, 0x88, 0xcc, 0xdd, //\n        ],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x8877665544332211 } },\n        2\n    );\n}\n\n#[test]\nfn test_err_ldxdw_oob() {\n    test_interpreter_and_jit_asm!(\n        \"\n        ldxdw r0, [r1+6]\n        exit\",\n        [\n            0xaa, 0xbb, 0x11, 0x22, 0x33, 0x44, 0x55, 0x66, //\n            0x77, 0x88, 0xcc, 0xdd, //\n        ],\n        (),\n        0,\n        {\n            |_vm, res: Result| {\n                matches!(res.unwrap_err(),\n                    EbpfError::AccessViolation(pc, access_type, vm_addr, len, name)\n                    if access_type == AccessType::Load && pc == 29 && vm_addr == 0x400000006 && len == 8 && name == \"input\"\n                )\n            }\n        },\n        1\n    );\n}\n\n#[test]\nfn test_ldxb_all() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov r0, r1\n        ldxb r9, [r0+0]\n        lsh r9, 0\n        ldxb r8, [r0+1]\n        lsh r8, 4\n        ldxb r7, [r0+2]\n        lsh r7, 8\n        ldxb r6, [r0+3]\n        lsh r6, 12\n        ldxb r5, [r0+4]\n        lsh r5, 16\n        ldxb r4, [r0+5]\n        lsh r4, 20\n        ldxb r3, [r0+6]\n        lsh r3, 24\n        ldxb r2, [r0+7]\n        lsh r2, 28\n        ldxb r1, [r0+8]\n        lsh r1, 32\n        ldxb r0, [r0+9]\n        lsh r0, 36\n        or r0, r1\n        or r0, r2\n        or r0, r3\n        or r0, r4\n        or r0, r5\n        or r0, r6\n        or r0, r7\n        or r0, r8\n        or r0, r9\n        exit\",\n        [\n            0x00, 0x01, 0x02, 0x03, 0x04, 0x05, 0x06, 0x07, //\n            0x08, 0x09, //\n        ],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x9876543210 } },\n        31\n    );\n}\n\n#[test]\nfn test_ldxh_all() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov r0, r1\n        ldxh r9, [r0+0]\n        be16 r9\n        lsh r9, 0\n        ldxh r8, [r0+2]\n        be16 r8\n        lsh r8, 4\n        ldxh r7, [r0+4]\n        be16 r7\n        lsh r7, 8\n        ldxh r6, [r0+6]\n        be16 r6\n        lsh r6, 12\n        ldxh r5, [r0+8]\n        be16 r5\n        lsh r5, 16\n        ldxh r4, [r0+10]\n        be16 r4\n        lsh r4, 20\n        ldxh r3, [r0+12]\n        be16 r3\n        lsh r3, 24\n        ldxh r2, [r0+14]\n        be16 r2\n        lsh r2, 28\n        ldxh r1, [r0+16]\n        be16 r1\n        lsh r1, 32\n        ldxh r0, [r0+18]\n        be16 r0\n        lsh r0, 36\n        or r0, r1\n        or r0, r2\n        or r0, r3\n        or r0, r4\n        or r0, r5\n        or r0, r6\n        or r0, r7\n        or r0, r8\n        or r0, r9\n        exit\",\n        [\n            0x00, 0x00, 0x00, 0x01, 0x00, 0x02, 0x00, 0x03, //\n            0x00, 0x04, 0x00, 0x05, 0x00, 0x06, 0x00, 0x07, //\n            0x00, 0x08, 0x00, 0x09, //\n        ],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x9876543210 } },\n        41\n    );\n}\n\n#[test]\nfn test_ldxh_all2() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov r0, r1\n        ldxh r9, [r0+0]\n        be16 r9\n        ldxh r8, [r0+2]\n        be16 r8\n        ldxh r7, [r0+4]\n        be16 r7\n        ldxh r6, [r0+6]\n        be16 r6\n        ldxh r5, [r0+8]\n        be16 r5\n        ldxh r4, [r0+10]\n        be16 r4\n        ldxh r3, [r0+12]\n        be16 r3\n        ldxh r2, [r0+14]\n        be16 r2\n        ldxh r1, [r0+16]\n        be16 r1\n        ldxh r0, [r0+18]\n        be16 r0\n        or r0, r1\n        or r0, r2\n        or r0, r3\n        or r0, r4\n        or r0, r5\n        or r0, r6\n        or r0, r7\n        or r0, r8\n        or r0, r9\n        exit\",\n        [\n            0x00, 0x01, 0x00, 0x02, 0x00, 0x04, 0x00, 0x08, //\n            0x00, 0x10, 0x00, 0x20, 0x00, 0x40, 0x00, 0x80, //\n            0x01, 0x00, 0x02, 0x00, //\n        ],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x3ff } },\n        31\n    );\n}\n\n#[test]\nfn test_ldxw_all() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov r0, r1\n        ldxw r9, [r0+0]\n        be32 r9\n        ldxw r8, [r0+4]\n        be32 r8\n        ldxw r7, [r0+8]\n        be32 r7\n        ldxw r6, [r0+12]\n        be32 r6\n        ldxw r5, [r0+16]\n        be32 r5\n        ldxw r4, [r0+20]\n        be32 r4\n        ldxw r3, [r0+24]\n        be32 r3\n        ldxw r2, [r0+28]\n        be32 r2\n        ldxw r1, [r0+32]\n        be32 r1\n        ldxw r0, [r0+36]\n        be32 r0\n        or r0, r1\n        or r0, r2\n        or r0, r3\n        or r0, r4\n        or r0, r5\n        or r0, r6\n        or r0, r7\n        or r0, r8\n        or r0, r9\n        exit\",\n        [\n            0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x02, //\n            0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00, 0x08, //\n            0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x02, 0x00, //\n            0x00, 0x00, 0x04, 0x00, 0x00, 0x00, 0x08, 0x00, //\n            0x00, 0x01, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, //\n        ],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x030f0f } },\n        31\n    );\n}\n\n#[test]\nfn test_lddw() {\n    test_interpreter_and_jit_asm!(\n        \"\n        lddw r0, 0x1122334455667788\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x1122334455667788 } },\n        2\n    );\n    test_interpreter_and_jit_asm!(\n        \"\n        lddw r0, 0x0000000080000000\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x80000000 } },\n        2\n    );\n}\n\n#[test]\nfn test_stb() {\n    test_interpreter_and_jit_asm!(\n        \"\n        stb [r1+2], 0x11\n        ldxb r0, [r1+2]\n        exit\",\n        [0xaa, 0xbb, 0xff, 0xcc, 0xdd],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x11 } },\n        3\n    );\n}\n\n#[test]\nfn test_sth() {\n    test_interpreter_and_jit_asm!(\n        \"\n        sth [r1+2], 0x2211\n        ldxh r0, [r1+2]\n        exit\",\n        [\n            0xaa, 0xbb, 0xff, 0xff, 0xcc, 0xdd, //\n        ],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x2211 } },\n        3\n    );\n}\n\n#[test]\nfn test_stw() {\n    test_interpreter_and_jit_asm!(\n        \"\n        stw [r1+2], 0x44332211\n        ldxw r0, [r1+2]\n        exit\",\n        [\n            0xaa, 0xbb, 0xff, 0xff, 0xff, 0xff, 0xcc, 0xdd, //\n        ],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x44332211 } },\n        3\n    );\n}\n\n#[test]\nfn test_stdw() {\n    test_interpreter_and_jit_asm!(\n        \"\n        stdw [r1+2], 0x44332211\n        ldxdw r0, [r1+2]\n        exit\",\n        [\n            0xaa, 0xbb, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, //\n            0xff, 0xff, 0xcc, 0xdd, //\n        ],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x44332211 } },\n        3\n    );\n}\n\n#[test]\nfn test_stxb() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov32 r2, 0x11\n        stxb [r1+2], r2\n        ldxb r0, [r1+2]\n        exit\",\n        [\n            0xaa, 0xbb, 0xff, 0xcc, 0xdd, //\n        ],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x11 } },\n        4\n    );\n}\n\n#[test]\nfn test_stxh() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov32 r2, 0x2211\n        stxh [r1+2], r2\n        ldxh r0, [r1+2]\n        exit\",\n        [\n            0xaa, 0xbb, 0xff, 0xff, 0xcc, 0xdd, //\n        ],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x2211 } },\n        4\n    );\n}\n\n#[test]\nfn test_stxw() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov32 r2, 0x44332211\n        stxw [r1+2], r2\n        ldxw r0, [r1+2]\n        exit\",\n        [\n            0xaa, 0xbb, 0xff, 0xff, 0xff, 0xff, 0xcc, 0xdd, //\n        ],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x44332211 } },\n        4\n    );\n}\n\n#[test]\nfn test_stxdw() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov r2, -2005440939\n        lsh r2, 32\n        or r2, 0x44332211\n        stxdw [r1+2], r2\n        ldxdw r0, [r1+2]\n        exit\",\n        [\n            0xaa, 0xbb, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, //\n            0xff, 0xff, 0xcc, 0xdd, //\n        ],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x8877665544332211 } },\n        6\n    );\n}\n\n#[test]\nfn test_stxb_all() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov r0, 0xf0\n        mov r2, 0xf2\n        mov r3, 0xf3\n        mov r4, 0xf4\n        mov r5, 0xf5\n        mov r6, 0xf6\n        mov r7, 0xf7\n        mov r8, 0xf8\n        stxb [r1], r0\n        stxb [r1+1], r2\n        stxb [r1+2], r3\n        stxb [r1+3], r4\n        stxb [r1+4], r5\n        stxb [r1+5], r6\n        stxb [r1+6], r7\n        stxb [r1+7], r8\n        ldxdw r0, [r1]\n        be64 r0\n        exit\",\n        [\n            0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, //\n        ],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0xf0f2f3f4f5f6f7f8 } },\n        19\n    );\n}\n\n#[test]\nfn test_stxb_all2() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov r0, r1\n        mov r1, 0xf1\n        mov r9, 0xf9\n        stxb [r0], r1\n        stxb [r0+1], r9\n        ldxh r0, [r0]\n        be16 r0\n        exit\",\n        [0xff, 0xff],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0xf1f9 } },\n        8\n    );\n}\n\n#[test]\nfn test_stxb_chain() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov r0, r1\n        ldxb r9, [r0+0]\n        stxb [r0+1], r9\n        ldxb r8, [r0+1]\n        stxb [r0+2], r8\n        ldxb r7, [r0+2]\n        stxb [r0+3], r7\n        ldxb r6, [r0+3]\n        stxb [r0+4], r6\n        ldxb r5, [r0+4]\n        stxb [r0+5], r5\n        ldxb r4, [r0+5]\n        stxb [r0+6], r4\n        ldxb r3, [r0+6]\n        stxb [r0+7], r3\n        ldxb r2, [r0+7]\n        stxb [r0+8], r2\n        ldxb r1, [r0+8]\n        stxb [r0+9], r1\n        ldxb r0, [r0+9]\n        exit\",\n        [\n            0x2a, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, //\n            0x00, 0x00, //\n        ],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x2a } },\n        21\n    );\n}\n\n// BPF_JMP : Branches\n\n#[test]\nfn test_exit_without_value() {\n    test_interpreter_and_jit_asm!(\n        \"\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x0 } },\n        1\n    );\n}\n\n#[test]\nfn test_exit() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov r0, 0\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x0 } },\n        2\n    );\n}\n\n#[test]\nfn test_early_exit() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov r0, 3\n        exit\n        mov r0, 4\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x3 } },\n        2\n    );\n}\n\n#[test]\nfn test_ja() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov r0, 1\n        ja +1\n        mov r0, 2\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x1 } },\n        3\n    );\n}\n\n#[test]\nfn test_jeq_imm() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov32 r0, 0\n        mov32 r1, 0xa\n        jeq r1, 0xb, +4\n        mov32 r0, 1\n        mov32 r1, 0xb\n        jeq r1, 0xb, +1\n        mov32 r0, 2\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x1 } },\n        7\n    );\n}\n\n#[test]\nfn test_jeq_reg() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov32 r0, 0\n        mov32 r1, 0xa\n        mov32 r2, 0xb\n        jeq r1, r2, +4\n        mov32 r0, 1\n        mov32 r1, 0xb\n        jeq r1, r2, +1\n        mov32 r0, 2\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x1 } },\n        8\n    );\n}\n\n#[test]\nfn test_jge_imm() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov32 r0, 0\n        mov32 r1, 0xa\n        jge r1, 0xb, +4\n        mov32 r0, 1\n        mov32 r1, 0xc\n        jge r1, 0xb, +1\n        mov32 r0, 2\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x1 } },\n        7\n    );\n}\n\n#[test]\nfn test_jge_reg() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov32 r0, 0\n        mov32 r1, 0xa\n        mov32 r2, 0xb\n        jge r1, r2, +4\n        mov32 r0, 1\n        mov32 r1, 0xb\n        jge r1, r2, +1\n        mov32 r0, 2\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x1 } },\n        8\n    );\n}\n\n#[test]\nfn test_jle_imm() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov32 r0, 0\n        mov32 r1, 5\n        jle r1, 4, +1\n        jle r1, 6, +1\n        exit\n        jle r1, 5, +1\n        exit\n        mov32 r0, 1\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x1 } },\n        7\n    );\n}\n\n#[test]\nfn test_jle_reg() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov r0, 0\n        mov r1, 5\n        mov r2, 4\n        mov r3, 6\n        jle r1, r2, +2\n        jle r1, r1, +1\n        exit\n        jle r1, r3, +1\n        exit\n        mov r0, 1\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x1 } },\n        9\n    );\n}\n\n#[test]\nfn test_jgt_imm() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov32 r0, 0\n        mov32 r1, 5\n        jgt r1, 6, +2\n        jgt r1, 5, +1\n        jgt r1, 4, +1\n        exit\n        mov32 r0, 1\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x1 } },\n        7\n    );\n}\n\n#[test]\nfn test_jgt_reg() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov r0, 0\n        mov r1, 5\n        mov r2, 6\n        mov r3, 4\n        jgt r1, r2, +2\n        jgt r1, r1, +1\n        jgt r1, r3, +1\n        exit\n        mov r0, 1\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x1 } },\n        9\n    );\n}\n\n#[test]\nfn test_jlt_imm() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov32 r0, 0\n        mov32 r1, 5\n        jlt r1, 4, +2\n        jlt r1, 5, +1\n        jlt r1, 6, +1\n        exit\n        mov32 r0, 1\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x1 } },\n        7\n    );\n}\n\n#[test]\nfn test_jlt_reg() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov r0, 0\n        mov r1, 5\n        mov r2, 4\n        mov r3, 6\n        jlt r1, r2, +2\n        jlt r1, r1, +1\n        jlt r1, r3, +1\n        exit\n        mov r0, 1\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x1 } },\n        9\n    );\n}\n\n#[test]\nfn test_jne_imm() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov32 r0, 0\n        mov32 r1, 0xb\n        jne r1, 0xb, +4\n        mov32 r0, 1\n        mov32 r1, 0xa\n        jne r1, 0xb, +1\n        mov32 r0, 2\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x1 } },\n        7\n    );\n}\n\n#[test]\nfn test_jne_reg() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov32 r0, 0\n        mov32 r1, 0xb\n        mov32 r2, 0xb\n        jne r1, r2, +4\n        mov32 r0, 1\n        mov32 r1, 0xa\n        jne r1, r2, +1\n        mov32 r0, 2\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x1 } },\n        8\n    );\n}\n\n#[test]\nfn test_jset_imm() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov32 r0, 0\n        mov32 r1, 0x7\n        jset r1, 0x8, +4\n        mov32 r0, 1\n        mov32 r1, 0x9\n        jset r1, 0x8, +1\n        mov32 r0, 2\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x1 } },\n        7\n    );\n}\n\n#[test]\nfn test_jset_reg() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov32 r0, 0\n        mov32 r1, 0x7\n        mov32 r2, 0x8\n        jset r1, r2, +4\n        mov32 r0, 1\n        mov32 r1, 0x9\n        jset r1, r2, +1\n        mov32 r0, 2\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x1 } },\n        8\n    );\n}\n\n#[test]\nfn test_jsge_imm() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov32 r0, 0\n        mov r1, -2\n        jsge r1, -1, +5\n        jsge r1, 0, +4\n        mov32 r0, 1\n        mov r1, -1\n        jsge r1, -1, +1\n        mov32 r0, 2\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x1 } },\n        8\n    );\n}\n\n#[test]\nfn test_jsge_reg() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov32 r0, 0\n        mov r1, -2\n        mov r2, -1\n        mov32 r3, 0\n        jsge r1, r2, +5\n        jsge r1, r3, +4\n        mov32 r0, 1\n        mov r1, r2\n        jsge r1, r2, +1\n        mov32 r0, 2\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x1 } },\n        10\n    );\n}\n\n#[test]\nfn test_jsle_imm() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov32 r0, 0\n        mov r1, -2\n        jsle r1, -3, +1\n        jsle r1, -1, +1\n        exit\n        mov32 r0, 1\n        jsle r1, -2, +1\n        mov32 r0, 2\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x1 } },\n        7\n    );\n}\n\n#[test]\nfn test_jsle_reg() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov32 r0, 0\n        mov r1, -1\n        mov r2, -2\n        mov32 r3, 0\n        jsle r1, r2, +1\n        jsle r1, r3, +1\n        exit\n        mov32 r0, 1\n        mov r1, r2\n        jsle r1, r2, +1\n        mov32 r0, 2\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x1 } },\n        10\n    );\n}\n\n#[test]\nfn test_jsgt_imm() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov32 r0, 0\n        mov r1, -2\n        jsgt r1, -1, +4\n        mov32 r0, 1\n        mov32 r1, 0\n        jsgt r1, -1, +1\n        mov32 r0, 2\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x1 } },\n        7\n    );\n}\n\n#[test]\nfn test_jsgt_reg() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov32 r0, 0\n        mov r1, -2\n        mov r2, -1\n        jsgt r1, r2, +4\n        mov32 r0, 1\n        mov32 r1, 0\n        jsgt r1, r2, +1\n        mov32 r0, 2\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x1 } },\n        8\n    );\n}\n\n#[test]\nfn test_jslt_imm() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov32 r0, 0\n        mov r1, -2\n        jslt r1, -3, +2\n        jslt r1, -2, +1\n        jslt r1, -1, +1\n        exit\n        mov32 r0, 1\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x1 } },\n        7\n    );\n}\n\n#[test]\nfn test_jslt_reg() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov32 r0, 0\n        mov r1, -2\n        mov r2, -3\n        mov r3, -1\n        jslt r1, r1, +2\n        jslt r1, r2, +1\n        jslt r1, r3, +1\n        exit\n        mov32 r0, 1\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x1 } },\n        9\n    );\n}\n\n// Call Stack\n\n#[test]\nfn test_stack1() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov r1, 51\n        stdw [r10-16], 0xab\n        stdw [r10-8], 0xcd\n        and r1, 1\n        lsh r1, 3\n        mov r2, r10\n        add r2, r1\n        ldxdw r0, [r2-16]\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0xcd } },\n        9\n    );\n}\n\n#[test]\nfn test_stack2() {\n    test_interpreter_and_jit_asm!(\n        \"\n        stb [r10-4], 0x01\n        stb [r10-3], 0x02\n        stb [r10-2], 0x03\n        stb [r10-1], 0x04\n        mov r1, r10\n        mov r2, 0x4\n        sub r1, r2\n        syscall BpfMemFrob\n        mov r1, 0\n        ldxb r2, [r10-4]\n        ldxb r3, [r10-3]\n        ldxb r4, [r10-2]\n        ldxb r5, [r10-1]\n        syscall BpfGatherBytes\n        xor r0, 0x2a2a2a2a\n        exit\",\n        [],\n        (\n            b\"BpfMemFrob\" => syscalls::BpfMemFrob::init::<BpfSyscallContext, UserError>; syscalls::BpfMemFrob::call,\n            b\"BpfGatherBytes\" => syscalls::BpfGatherBytes::init::<BpfSyscallContext, UserError>; syscalls::BpfGatherBytes::call,\n        ),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x01020304 } },\n        16\n    );\n}\n\n#[test]\nfn test_string_stack() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov r1, 0x78636261\n        stxw [r10-8], r1\n        mov r6, 0x0\n        stxb [r10-4], r6\n        stxb [r10-12], r6\n        mov r1, 0x79636261\n        stxw [r10-16], r1\n        mov r1, r10\n        add r1, -8\n        mov r2, r1\n        syscall BpfStrCmp\n        mov r1, r0\n        mov r0, 0x1\n        lsh r1, 0x20\n        rsh r1, 0x20\n        jne r1, 0x0, +11\n        mov r1, r10\n        add r1, -8\n        mov r2, r10\n        add r2, -16\n        syscall BpfStrCmp\n        mov r1, r0\n        lsh r1, 0x20\n        rsh r1, 0x20\n        mov r0, 0x1\n        jeq r1, r6, +1\n        mov r0, 0x0\n        exit\",\n        [],\n        (\n            b\"BpfStrCmp\" => syscalls::BpfStrCmp::init::<BpfSyscallContext, UserError>; syscalls::BpfStrCmp::call,\n        ),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x0 } },\n        28\n    );\n}\n\n#[test]\nfn test_err_fixed_stack_out_of_bound() {\n    let config = Config {\n        dynamic_stack_frames: false,\n        max_call_depth: 3,\n        ..Config::default()\n    };\n    test_interpreter_and_jit_asm!(\n        \"\n        stb [r10-0x4000], 0\n        exit\",\n        config,\n        [],\n        (),\n        0,\n        {\n            |_vm, res: Result| {\n                matches!(res.unwrap_err(),\n                    EbpfError::AccessViolation(pc, access_type, vm_addr, len, name)\n                    if access_type == AccessType::Store && pc == 29 && vm_addr == 0x1FFFFD000 && len == 1 && name == \"program\"\n                )\n            }\n        },\n        1\n    );\n}\n\n#[test]\nfn test_err_dynamic_stack_out_of_bound() {\n    let config = Config {\n        dynamic_stack_frames: true,\n        max_call_depth: 3,\n        ..Config::default()\n    };\n\n    // The stack goes from MM_STACK_START + config.stack_size() to MM_STACK_START\n\n    // Check that accessing MM_STACK_START - 1 fails\n    test_interpreter_and_jit_asm!(\n        \"\n        stb [r10-0x3001], 0\n        exit\",\n        config,\n        [],\n        (),\n        0,\n        {\n            |_vm, res: Result| {\n                matches!(res.unwrap_err(),\n                    EbpfError::AccessViolation(pc, access_type, vm_addr, len, region)\n                    if access_type == AccessType::Store && pc == 29 && vm_addr == ebpf::MM_STACK_START - 1 && len == 1 && region == \"program\"\n                )\n            }\n        },\n        1\n    );\n\n    // Check that accessing MM_STACK_START + expected_stack_len fails\n    test_interpreter_and_jit_asm!(\n        \"\n        stb [r10], 0\n        exit\",\n        config,\n        [],\n        (),\n        0,\n        {\n            |_vm, res: Result| {\n                matches!(res.unwrap_err(),\n                    EbpfError::AccessViolation(pc, access_type, vm_addr, len, region)\n                    if access_type == AccessType::Store && pc == 29 && vm_addr == ebpf::MM_STACK_START + config.stack_size() as u64 && len == 1 && region == \"stack\"\n                )\n            }\n        },\n        1\n    );\n}\n\n#[test]\nfn test_err_dynamic_stack_ptr_overflow() {\n    let config = Config {\n        dynamic_stack_frames: true,\n        ..Config::default()\n    };\n\n    // See the comment in CallFrames::resize_stack() for the reason why it's\n    // safe to let the stack pointer overflow\n\n    // stack_ptr -= stack_ptr + 1\n    test_interpreter_and_jit_asm!(\n        \"\n        sub r11, 0x7FFFFFFF\n        sub r11, 0x7FFFFFFF\n        sub r11, 0x7FFFFFFF\n        sub r11, 0x7FFFFFFF\n        sub r11, 0x14005\n        call foo\n        exit\n        foo:\n        stb [r10], 0\n        exit\",\n        config,\n        [],\n        (),\n        0,\n        {\n            |_vm, res: Result| {\n                matches!(res.unwrap_err(),\n                    EbpfError::AccessViolation(pc, access_type, vm_addr, len, region)\n                    if access_type == AccessType::Store && pc == 29 + 7 && vm_addr == u64::MAX && len == 1 && region == \"unknown\"\n                )\n            }\n        },\n        7\n    );\n}\n\n#[test]\nfn test_dynamic_stack_frames_empty() {\n    let config = Config {\n        dynamic_stack_frames: true,\n        ..Config::default()\n    };\n\n    // Check that unless explicitly resized the stack doesn't grow\n    test_interpreter_and_jit_asm!(\n        \"\n        call foo\n        exit\n        foo:\n        mov r0, r10\n        exit\",\n        config,\n        [],\n        (),\n        0,\n        { |_vm, res: Result| res.unwrap() == ebpf::MM_STACK_START + config.stack_size() as u64 },\n        4\n    );\n}\n\n#[test]\nfn test_dynamic_frame_ptr() {\n    let config = Config {\n        dynamic_stack_frames: true,\n        ..Config::default()\n    };\n\n    // Check that upon entering a function (foo) the frame pointer is advanced\n    // to the top of the stack\n    test_interpreter_and_jit_asm!(\n        \"\n        sub r11, 8\n        call foo\n        exit\n        foo:\n        mov r0, r10\n        exit\",\n        config,\n        [],\n        (),\n        0,\n        {\n            |_vm, res: Result| res.unwrap() == ebpf::MM_STACK_START + config.stack_size() as u64 - 8\n        },\n        5\n    );\n\n    // And check that when exiting a function (foo) the caller's frame pointer\n    // is restored\n    test_interpreter_and_jit_asm!(\n        \"\n        sub r11, 8\n        call foo\n        mov r0, r10\n        exit\n        foo:\n        exit\n        \",\n        config,\n        [],\n        (),\n        0,\n        { |_vm, res: Result| res.unwrap() == ebpf::MM_STACK_START + config.stack_size() as u64 },\n        5\n    );\n}\n\n#[test]\nfn test_entrypoint_exit() {\n    // With fixed frames we used to exit the entrypoint when we reached an exit\n    // instruction and the stack size was 1 * config.stack_frame_size, which\n    // meant that we were in the entrypoint's frame.  With dynamic frames we\n    // can't infer anything from the stack size so we track call depth\n    // explicitly. Make sure exit still works with both fixed and dynamic\n    // frames.\n    for dynamic_stack_frames in [false, true] {\n        let config = Config {\n            dynamic_stack_frames,\n            ..Config::default()\n        };\n\n        // This checks that when foo exits we don't stop execution even if the\n        // stack is empty (stack size and call depth are decoupled)\n        test_interpreter_and_jit_asm!(\n            \"\n            entrypoint:\n            call foo\n            mov r0, 42\n            exit\n            foo:\n            mov r0, 12\n            exit\",\n            config,\n            [],\n            (),\n            0,\n            { |_vm, res: Result| { res.unwrap() == 42 } },\n            5\n        );\n    }\n}\n\n#[test]\nfn test_stack_call_depth_tracking() {\n    for dynamic_stack_frames in [false, true] {\n        let config = Config {\n            dynamic_stack_frames,\n            max_call_depth: 2,\n            ..Config::default()\n        };\n\n        // Given max_call_depth=2, make sure that two sibling calls don't\n        // trigger CallDepthExceeded. In other words ensure that we correctly\n        // pop frames in the interpreter and decrement\n        // EnvironmentStackSlot::CallDepth on ebpf::EXIT in the jit.\n        test_interpreter_and_jit_asm!(\n            \"\n            call foo\n            call foo\n            exit\n            foo:\n            exit\n            \",\n            config,\n            [],\n            (),\n            0,\n            { |_vm, res: Result| { res.is_ok() } },\n            5\n        );\n\n        // two nested calls should trigger CallDepthExceeded instead\n        test_interpreter_and_jit_asm!(\n            \"\n            entrypoint:\n            call foo\n            exit\n            foo:\n            call bar\n            exit\n            bar:\n            exit\n            \",\n            config,\n            [],\n            (),\n            0,\n            {\n                |_vm, res: Result| {\n                    matches!(res.unwrap_err(),\n                        EbpfError::CallDepthExceeded(pc, depth)\n                        if pc == 29 + 2 && depth == config.max_call_depth\n                    )\n                }\n            },\n            2\n        );\n    }\n}\n\n#[test]\nfn test_err_mem_access_out_of_bound() {\n    let mem = [0; 512];\n    let mut prog = [0; 32];\n    prog[0] = ebpf::LD_DW_IMM;\n    prog[16] = ebpf::ST_B_IMM;\n    prog[24] = ebpf::EXIT;\n    for address in [0x2u64, 0x8002u64, 0x80000002u64, 0x8000000000000002u64] {\n        LittleEndian::write_u32(&mut prog[4..], address as u32);\n        LittleEndian::write_u32(&mut prog[12..], (address >> 32) as u32);\n        let config = Config::default();\n        let mut bpf_functions = BTreeMap::new();\n        let syscall_registry = SyscallRegistry::default();\n        register_bpf_function(\n            &config,\n            &mut bpf_functions,\n            &syscall_registry,\n            0,\n            \"entrypoint\",\n        )\n        .unwrap();\n        #[allow(unused_mut)]\n        let mut executable = Executable::<UserError, TestInstructionMeter>::from_text_bytes(\n            &prog,\n            None,\n            config,\n            syscall_registry,\n            bpf_functions,\n        )\n        .unwrap();\n        test_interpreter_and_jit!(\n            executable,\n            mem,\n            0,\n            {\n                |_vm, res: Result| {\n                    matches!(res.unwrap_err(),\n                        EbpfError::AccessViolation(pc, access_type, vm_addr, len, name)\n                        if access_type == AccessType::Store && pc == 31 && vm_addr == address && len == 1 && name == \"unknown\"\n                    )\n                }\n            },\n            2\n        );\n    }\n}\n\n// CALL_IMM & CALL_REG : Procedure Calls\n\n#[test]\nfn test_relative_call() {\n    let config = Config {\n        static_syscalls: false,\n        ..Config::default()\n    };\n    test_interpreter_and_jit_elf!(\n        \"tests/elfs/relative_call.so\",\n        config,\n        [1],\n        (\n            b\"log\" => syscalls::BpfSyscallString::init::<BpfSyscallContext, UserError>; syscalls::BpfSyscallString::call,\n        ),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 2 } },\n        14\n    );\n}\n\n#[test]\nfn test_bpf_to_bpf_scratch_registers() {\n    let config = Config {\n        static_syscalls: false,\n        ..Config::default()\n    };\n    test_interpreter_and_jit_elf!(\n        \"tests/elfs/scratch_registers.so\",\n        config,\n        [1],\n        (\n            b\"log_64\" => syscalls::BpfSyscallU64::init::<BpfSyscallContext, UserError>; syscalls::BpfSyscallU64::call,\n        ),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 112 } },\n        41\n    );\n}\n\n#[test]\nfn test_bpf_to_bpf_pass_stack_reference() {\n    test_interpreter_and_jit_elf!(\n        \"tests/elfs/pass_stack_reference.so\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| res.unwrap() == 42 },\n        29\n    );\n}\n\n#[test]\nfn test_syscall_parameter_on_stack() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov64 r1, r10\n        add64 r1, -0x100\n        mov64 r2, 0x1\n        syscall BpfSyscallString\n        mov64 r0, 0x0\n        exit\",\n        [],\n        (\n            b\"BpfSyscallString\" => syscalls::BpfSyscallString::init::<BpfSyscallContext, UserError>; syscalls::BpfSyscallString::call,\n        ),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0 } },\n        6\n    );\n}\n\n#[test]\nfn test_call_reg() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov64 r0, 0x0\n        mov64 r8, 0x1\n        lsh64 r8, 0x20\n        or64 r8, 0x30\n        callx r8\n        exit\n        mov64 r0, 0x2A\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 42 } },\n        8\n    );\n}\n\n#[test]\nfn test_err_callx_oob_low() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov64 r0, 0x3\n        callx r0\n        exit\",\n        [],\n        (),\n        0,\n        {\n            |_vm, res: Result| {\n                matches!(res.unwrap_err(),\n                    EbpfError::CallOutsideTextSegment(pc, target_pc)\n                    if pc == 30 && target_pc == 0\n                )\n            }\n        },\n        2\n    );\n}\n\n#[test]\nfn test_err_callx_oob_high() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov64 r0, -0x1\n        lsh64 r0, 0x20\n        or64 r0, 0x3\n        callx r0\n        exit\",\n        [],\n        (),\n        0,\n        {\n            |_vm, res: Result| {\n                matches!(res.unwrap_err(),\n                    EbpfError::CallOutsideTextSegment(pc, target_pc)\n                    if pc == 32 && target_pc == 0xffffffff00000000\n                )\n            }\n        },\n        4\n    );\n}\n\n#[test]\nfn test_err_static_jmp_lddw() {\n    test_interpreter_and_jit_asm!(\n        \"\n        ja 2\n        mov r0, r0\n        lddw r0, 0x1122334455667788\n        exit\n        \",\n        [],\n        (),\n        0,\n        {\n            |_vm, res: Result| {\n                matches!(res.unwrap_err(),\n                    EbpfError::UnsupportedInstruction(pc) if pc == 32\n                )\n            }\n        },\n        2\n    );\n    test_interpreter_and_jit_asm!(\n        \"\n        mov r0, 0\n        mov r1, 0\n        mov r2, 0\n        lddw r0, 0x1\n        ja +2\n        lddw r1, 0x1\n        lddw r2, 0x1\n        add r1, r2\n        add r0, r1\n        exit\n        \",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x2 } },\n        9\n    );\n    test_interpreter_and_jit_asm!(\n        \"\n        jeq r0, 0, 1\n        lddw r0, 0x1122334455667788\n        exit\n        \",\n        [],\n        (),\n        0,\n        {\n            |_vm, res: Result| {\n                matches!(res.unwrap_err(),\n                    EbpfError::UnsupportedInstruction(pc) if pc == 31\n                )\n            }\n        },\n        2\n    );\n    test_interpreter_and_jit_asm!(\n        \"\n        call 3\n        mov r0, r0\n        mov r0, r0\n        lddw r0, 0x1122334455667788\n        exit\n        \",\n        [],\n        (),\n        0,\n        {\n            |_vm, res: Result| {\n                matches!(res.unwrap_err(),\n                    EbpfError::UnsupportedInstruction(pc) if pc == 33\n                )\n            }\n        },\n        2\n    );\n}\n\n#[test]\nfn test_err_dynamic_jmp_lddw() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov64 r8, 0x1\n        lsh64 r8, 0x20\n        or64 r8, 0x28\n        callx r8\n        lddw r0, 0x1122334455667788\n        exit\",\n        [],\n        (),\n        0,\n        {\n            |_vm, res: Result| {\n                matches!(res.unwrap_err(),\n                    EbpfError::UnsupportedInstruction(pc) if pc == 34\n                )\n            }\n        },\n        5\n    );\n    test_interpreter_and_jit_asm!(\n        \"\n        mov64 r1, 0x1\n        lsh64 r1, 0x20\n        or64 r1, 0x38\n        callx r1\n        mov r0, r0\n        mov r0, r0\n        lddw r0, 0x1122334455667788\n        exit\n        \",\n        [],\n        (),\n        0,\n        {\n            |_vm, res: Result| {\n                matches!(res.unwrap_err(),\n                    EbpfError::UnsupportedInstruction(pc) if pc == 36\n                )\n            }\n        },\n        5\n    );\n    test_interpreter_and_jit_asm!(\n        \"\n        lddw r1, 0x100000038\n        callx r1\n        mov r0, r0\n        mov r0, r0\n        exit\n        lddw r0, 0x1122334455667788\n        exit\n        \",\n        [],\n        (),\n        0,\n        {\n            |_vm, res: Result| {\n                matches!(res.unwrap_err(),\n                    EbpfError::UnsupportedInstruction(pc) if pc == 36\n                )\n            }\n        },\n        3\n    );\n}\n\n#[test]\nfn test_bpf_to_bpf_depth() {\n    let config = Config {\n        static_syscalls: false,\n        ..Config::default()\n    };\n    for i in 0..config.max_call_depth {\n        test_interpreter_and_jit_elf!(\n            \"tests/elfs/multiple_file.so\",\n            config,\n            [i as u8],\n            (\n                b\"log\" => syscalls::BpfSyscallString::init::<BpfSyscallContext, UserError>; syscalls::BpfSyscallString::call,\n            ),\n            0,\n            { |_vm, res: Result| { res.unwrap() == 0 } },\n            if i == 0 { 4 } else { 3 + 10 * i as u64 }\n        );\n    }\n}\n\n#[test]\nfn test_err_bpf_to_bpf_too_deep() {\n    let config = Config {\n        static_syscalls: false,\n        ..Config::default()\n    };\n    test_interpreter_and_jit_elf!(\n        \"tests/elfs/multiple_file.so\",\n        config,\n        [config.max_call_depth as u8],\n        (\n            b\"log\" => syscalls::BpfSyscallString::init::<BpfSyscallContext, UserError>; syscalls::BpfSyscallString::call,\n        ),\n        0,\n        {\n            |_vm, res: Result| {\n                matches!(res.unwrap_err(),\n                    EbpfError::CallDepthExceeded(pc, depth)\n                    if pc == 55 && depth == config.max_call_depth\n                )\n            }\n        },\n        176\n    );\n}\n\n#[test]\nfn test_err_reg_stack_depth() {\n    let config = Config::default();\n    test_interpreter_and_jit_asm!(\n        \"\n        mov64 r0, 0x1\n        lsh64 r0, 0x20\n        callx r0\n        exit\",\n        [],\n        (),\n        0,\n        {\n            |_vm, res: Result| {\n                matches!(res.unwrap_err(),\n                    EbpfError::CallDepthExceeded(pc, depth)\n                    if pc == 31 && depth == config.max_call_depth\n                )\n            }\n        },\n        60\n    );\n}\n\n// CALL_IMM : Syscalls\n\n/* TODO: syscalls::trash_registers needs asm!().\n// https://github.com/rust-lang/rust/issues/72016\n#[test]\nfn test_call_save() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov64 r6, 0x1\n        mov64 r7, 0x20\n        mov64 r8, 0x300\n        mov64 r9, 0x4000\n        call 0\n        mov64 r0, 0x0\n        or64 r0, r6\n        or64 r0, r7\n        or64 r0, r8\n        or64 r0, r9\n        exit\",\n        [],\n        (\n            0 => syscalls::trash_registers,\n        ),\n        { |_vm, res: Result| { res.unwrap() == 0 } }\n    );\n}*/\n\n#[test]\nfn test_err_syscall_string() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov64 r1, 0x0\n        syscall BpfSyscallString\n        mov64 r0, 0x0\n        exit\",\n        [72, 101, 108, 108, 111],\n        (\n            b\"BpfSyscallString\" => syscalls::BpfSyscallString::init::<BpfSyscallContext, UserError>; syscalls::BpfSyscallString::call,\n        ),\n        0,\n        {\n            |_vm, res: Result| {\n                matches!(res.unwrap_err(),\n                    EbpfError::AccessViolation(pc, access_type, vm_addr, len, name)\n                    if access_type == AccessType::Load && pc == 0 && vm_addr == 0 && len == 0 && name == \"unknown\"\n                )\n            }\n        },\n        2\n    );\n}\n\n#[test]\nfn test_syscall_string() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov64 r2, 0x5\n        syscall BpfSyscallString\n        mov64 r0, 0x0\n        exit\",\n        [72, 101, 108, 108, 111],\n        (\n            b\"BpfSyscallString\" => syscalls::BpfSyscallString::init::<BpfSyscallContext, UserError>; syscalls::BpfSyscallString::call,\n        ),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0 } },\n        4\n    );\n}\n\n#[test]\nfn test_syscall() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov64 r1, 0xAA\n        mov64 r2, 0xBB\n        mov64 r3, 0xCC\n        mov64 r4, 0xDD\n        mov64 r5, 0xEE\n        syscall BpfSyscallU64\n        mov64 r0, 0x0\n        exit\",\n        [],\n        (\n            b\"BpfSyscallU64\" => syscalls::BpfSyscallU64::init::<BpfSyscallContext, UserError>; syscalls::BpfSyscallU64::call,\n        ),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0 } },\n        8\n    );\n}\n\n#[test]\nfn test_call_gather_bytes() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov r1, 1\n        mov r2, 2\n        mov r3, 3\n        mov r4, 4\n        mov r5, 5\n        syscall BpfGatherBytes\n        exit\",\n        [],\n        (\n            b\"BpfGatherBytes\" => syscalls::BpfGatherBytes::init::<BpfSyscallContext, UserError>; syscalls::BpfGatherBytes::call,\n        ),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x0102030405 } },\n        7\n    );\n}\n\n#[test]\nfn test_call_memfrob() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov r6, r1\n        add r1, 2\n        mov r2, 4\n        syscall BpfMemFrob\n        ldxdw r0, [r6]\n        be64 r0\n        exit\",\n        [\n            0x01, 0x02, 0x03, 0x04, 0x05, 0x06, 0x07, 0x08, //\n        ],\n        (\n            b\"BpfMemFrob\" => syscalls::BpfMemFrob::init::<BpfSyscallContext, UserError>; syscalls::BpfMemFrob::call,\n        ),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x102292e2f2c0708 } },\n        7\n    );\n}\n\n#[test]\nfn test_syscall_with_context() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov64 r1, 0xAA\n        mov64 r2, 0xBB\n        mov64 r3, 0xCC\n        mov64 r4, 0xDD\n        mov64 r5, 0xEE\n        syscall SyscallWithContext\n        mov64 r0, 0x0\n        exit\",\n        [],\n        (\n            b\"SyscallWithContext\" => syscalls::SyscallWithContext::init::< syscalls::BpfSyscallContext, UserError>; syscalls::SyscallWithContext::call\n        ),\n        42,\n        { |vm: &EbpfVm<UserError, TestInstructionMeter>, res: Result| {\n            let syscall_context_object = unsafe { &*(vm.get_syscall_context_object(syscalls::SyscallWithContext::call as usize).unwrap() as *const syscalls::SyscallWithContext) };\n            assert_eq!(syscall_context_object.context, 84);\n            res.unwrap() == 0\n        }},\n        8\n    );\n}\n\ntype UserContext = u64;\npub struct NestedVmSyscall {}\nimpl NestedVmSyscall {\n    pub fn init<C, E>(_unused: C) -> Box<dyn SyscallObject<UserError>> {\n        Box::new(Self {})\n    }\n}\nimpl SyscallObject<UserError> for NestedVmSyscall {\n    fn call(\n        &mut self,\n        depth: u64,\n        throw: u64,\n        _arg3: u64,\n        _arg4: u64,\n        _arg5: u64,\n        _memory_mapping: &MemoryMapping,\n        result: &mut Result,\n    ) {\n        #[allow(unused_mut)]\n        if depth > 0 {\n            let mut syscall_registry = SyscallRegistry::default();\n            syscall_registry\n                .register_syscall_by_name(\n                    b\"NestedVmSyscall\",\n                    NestedVmSyscall::init::<UserContext, UserError>,\n                    NestedVmSyscall::call,\n                )\n                .unwrap();\n            let mem = [depth as u8 - 1, throw as u8];\n            let mut executable = assemble::<UserError, TestInstructionMeter>(\n                \"\n                ldabsb 0\n                mov64 r1, r0\n                ldabsb 1\n                mov64 r2, r0\n                syscall NestedVmSyscall\n                exit\",\n                None,\n                Config::default(),\n                syscall_registry,\n            )\n            .unwrap();\n            test_interpreter_and_jit!(\n                executable,\n                mem,\n                0,\n                {\n                    |_vm, res: Result| {\n                        *result = res;\n                        true\n                    }\n                },\n                if throw == 0 { 6 } else { 5 }\n            );\n        } else {\n            *result = if throw == 0 {\n                Ok(42)\n            } else {\n                Err(EbpfError::CallDepthExceeded(33, 0))\n            };\n        }\n    }\n}\n\n#[test]\nfn test_nested_vm_syscall() {\n    let config = Config::default();\n    let mut nested_vm_syscall = NestedVmSyscall {};\n    let memory_mapping = MemoryMapping::new::<UserError>(vec![], &config).unwrap();\n    let mut result = Ok(0);\n    nested_vm_syscall.call(1, 0, 0, 0, 0, &memory_mapping, &mut result);\n    assert!(result.unwrap() == 42);\n    let mut result = Ok(0);\n    nested_vm_syscall.call(1, 1, 0, 0, 0, &memory_mapping, &mut result);\n    assert!(matches!(result.unwrap_err(),\n        EbpfError::CallDepthExceeded(pc, depth)\n        if pc == 33 && depth == 0\n    ));\n}\n\n// Elf\n\n#[test]\nfn test_load_elf() {\n    let config = Config {\n        static_syscalls: false,\n        ..Config::default()\n    };\n    test_interpreter_and_jit_elf!(\n        \"tests/elfs/noop.so\",\n        config,\n        [],\n        (\n            b\"log\" => syscalls::BpfSyscallString::init::<BpfSyscallContext, UserError>; syscalls::BpfSyscallString::call,\n            b\"log_64\" => syscalls::BpfSyscallU64::init::<BpfSyscallContext, UserError>; syscalls::BpfSyscallU64::call,\n        ),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0 } },\n        11\n    );\n}\n\n#[test]\nfn test_load_elf_empty_noro() {\n    let config = Config {\n        static_syscalls: false,\n        ..Config::default()\n    };\n    test_interpreter_and_jit_elf!(\n        \"tests/elfs/noro.so\",\n        config,\n        [],\n        (\n            b\"log_64\" => syscalls::BpfSyscallU64::init::<BpfSyscallContext, UserError>; syscalls::BpfSyscallU64::call,\n        ),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0 } },\n        8\n    );\n}\n\n#[test]\nfn test_load_elf_empty_rodata() {\n    let config = Config {\n        static_syscalls: false,\n        ..Config::default()\n    };\n    test_interpreter_and_jit_elf!(\n        \"tests/elfs/empty_rodata.so\",\n        config,\n        [],\n        (\n            b\"log_64\" => syscalls::BpfSyscallU64::init::<BpfSyscallContext, UserError>; syscalls::BpfSyscallU64::call,\n        ),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0 } },\n        8\n    );\n}\n\n#[test]\nfn test_load_elf_rodata() {\n    // checks that the program loads the correct rodata offset with both\n    // borrowed and owned rodata\n    for optimize_rodata in [false, true] {\n        let config = Config {\n            optimize_rodata,\n            ..Config::default()\n        };\n        test_interpreter_and_jit_elf!(\n            \"tests/elfs/rodata.so\",\n            config,\n            [],\n            (),\n            0,\n            { |_vm, res: Result| { res.unwrap() == 42 } },\n            3\n        );\n    }\n}\n\n#[test]\nfn test_load_elf_rodata_high_vaddr() {\n    test_interpreter_and_jit_elf!(\n        \"tests/elfs/rodata_high_vaddr.so\",\n        [1],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 42 } },\n        3\n    );\n}\n\n#[test]\nfn test_custom_entrypoint() {\n    let mut file = File::open(\"tests/elfs/unresolved_syscall.so\").expect(\"file open failed\");\n    let mut elf = Vec::new();\n    file.read_to_end(&mut elf).unwrap();\n    elf[24] = 80; // Move entrypoint to later in the text section\n    let config = Config {\n        enable_instruction_tracing: true,\n        ..Config::default()\n    };\n    let mut syscall_registry = SyscallRegistry::default();\n    test_interpreter_and_jit!(register, syscall_registry, b\"log\" => syscalls::BpfSyscallString::init::<BpfSyscallContext, UserError>; syscalls::BpfSyscallString::call);\n    let mut syscall_registry = SyscallRegistry::default();\n    test_interpreter_and_jit!(register, syscall_registry, b\"log_64\" => syscalls::BpfSyscallU64::init::<BpfSyscallContext, UserError>; syscalls::BpfSyscallU64::call);\n    #[allow(unused_mut)]\n    let mut executable = Executable::<UserError, TestInstructionMeter>::from_elf(\n        &elf,\n        None,\n        config,\n        syscall_registry,\n    )\n    .unwrap();\n    test_interpreter_and_jit!(\n        executable,\n        [],\n        syscalls::BpfSyscallContext::default(),\n        { |_vm, res: Result| { res.unwrap() == 0 } },\n        2\n    );\n}\n\n// Instruction Meter Limit\n\n#[test]\nfn test_tight_infinite_loop_conditional() {\n    test_interpreter_and_jit_asm!(\n        \"\n        jsge r0, r0, -1\n        exit\",\n        [],\n        (),\n        0,\n        {\n            |_vm, res: Result| {\n                matches!(res.unwrap_err(),\n                    EbpfError::ExceededMaxInstructions(pc, initial_insn_count)\n                    if pc == 30 && initial_insn_count == 4\n                )\n            }\n        },\n        4\n    );\n}\n\n#[test]\nfn test_tight_infinite_loop_unconditional() {\n    test_interpreter_and_jit_asm!(\n        \"\n        ja -1\n        exit\",\n        [],\n        (),\n        0,\n        {\n            |_vm, res: Result| {\n                matches!(res.unwrap_err(),\n                    EbpfError::ExceededMaxInstructions(pc, initial_insn_count)\n                    if pc == 30 && initial_insn_count == 4\n                )\n            }\n        },\n        4\n    );\n}\n\n#[test]\nfn test_tight_infinite_recursion() {\n    test_interpreter_and_jit_asm!(\n        \"\n        entrypoint:\n        mov64 r3, 0x41414141\n        call entrypoint\n        exit\",\n        [],\n        (),\n        0,\n        {\n            |_vm, res: Result| {\n                matches!(res.unwrap_err(),\n                    EbpfError::ExceededMaxInstructions(pc, initial_insn_count)\n                    if pc == 31 && initial_insn_count == 4\n                )\n            }\n        },\n        4\n    );\n}\n\n#[test]\nfn test_tight_infinite_recursion_callx() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov64 r8, 0x1\n        lsh64 r8, 0x20\n        or64 r8, 0x18\n        mov64 r3, 0x41414141\n        callx r8\n        exit\",\n        [],\n        (),\n        0,\n        {\n            |_vm, res: Result| {\n                matches!(res.unwrap_err(),\n                    EbpfError::ExceededMaxInstructions(pc, initial_insn_count)\n                    if pc == 34 && initial_insn_count == 7\n                )\n            }\n        },\n        7\n    );\n}\n\n#[test]\nfn test_instruction_count_syscall() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov64 r2, 0x5\n        syscall BpfSyscallString\n        mov64 r0, 0x0\n        exit\",\n        [72, 101, 108, 108, 111],\n        (\n            b\"BpfSyscallString\" => syscalls::BpfSyscallString::init::<BpfSyscallContext, UserError>; syscalls::BpfSyscallString::call,\n        ),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0 } },\n        4\n    );\n}\n\n#[test]\nfn test_err_instruction_count_syscall_capped() {\n    let config = Config {\n        static_syscalls: false,\n        ..Config::default()\n    };\n    test_interpreter_and_jit_asm!(\n        \"\n        mov64 r2, 0x5\n        call 0\n        mov64 r0, 0x0\n        exit\",\n        config,\n        [72, 101, 108, 108, 111],\n        (\n            b\"BpfSyscallString\" => syscalls::BpfSyscallString::init::<BpfSyscallContext, UserError>; syscalls::BpfSyscallString::call,\n        ),\n        0,\n        {\n            |_vm, res: Result| {\n                matches!(res.unwrap_err(),\n                    EbpfError::ExceededMaxInstructions(pc, initial_insn_count)\n                    if pc == 32 && initial_insn_count == 3\n                )\n            }\n        },\n        3\n    );\n}\n\n#[test]\nfn test_err_instruction_count_lddw_capped() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov r0, 0\n        lddw r1, 0x1\n        mov r2, 0\n        exit\n        \",\n        [],\n        (),\n        0,\n        {\n            |_vm, res: Result| {\n                matches!(res.unwrap_err(),\n                    EbpfError::ExceededMaxInstructions(pc, initial_insn_count)\n                    if pc == 32 && initial_insn_count == 2\n                )\n            }\n        },\n        2\n    );\n}\n\n#[test]\nfn test_non_terminate_early() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov64 r6, 0x0\n        mov64 r1, 0x0\n        mov64 r2, 0x0\n        mov64 r3, 0x0\n        mov64 r4, 0x0\n        mov64 r5, r6\n        syscall Unresolved\n        add64 r6, 0x1\n        ja -0x8\n        exit\",\n        [],\n        (),\n        0,\n        {\n            |_vm, res: Result| {\n                matches!(res.unwrap_err(),\n                    EbpfError::UnsupportedInstruction(pc)\n                    if pc == 35\n                )\n            }\n        },\n        7\n    );\n}\n\n#[test]\nfn test_err_non_terminate_capped() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov64 r6, 0x0\n        mov64 r1, 0x0\n        mov64 r2, 0x0\n        mov64 r3, 0x0\n        mov64 r4, 0x0\n        mov64 r5, r6\n        syscall BpfTracePrintf\n        add64 r6, 0x1\n        ja -0x8\n        exit\",\n        [],\n        (\n            b\"BpfTracePrintf\" => syscalls::BpfTracePrintf::init::<BpfSyscallContext, UserError>; syscalls::BpfTracePrintf::call,\n        ),\n        0,\n        {\n            |_vm, res: Result| {\n                matches!(res.unwrap_err(),\n                    EbpfError::ExceededMaxInstructions(pc, initial_insn_count)\n                    if pc == 35 && initial_insn_count == 6\n                )\n            }\n        },\n        6\n    );\n    test_interpreter_and_jit_asm!(\n        \"\n        mov64 r6, 0x0\n        mov64 r1, 0x0\n        mov64 r2, 0x0\n        mov64 r3, 0x0\n        mov64 r4, 0x0\n        mov64 r5, r6\n        syscall BpfTracePrintf\n        add64 r6, 0x1\n        ja -0x8\n        exit\",\n        [],\n        (\n            b\"BpfTracePrintf\" => syscalls::BpfTracePrintf::init::<BpfSyscallContext, UserError>; syscalls::BpfTracePrintf::call,\n        ),\n        0,\n        {\n            |_vm, res: Result| {\n                matches!(res.unwrap_err(),\n                    EbpfError::ExceededMaxInstructions(pc, initial_insn_count)\n                    if pc == 37 && initial_insn_count == 1000\n                )\n            }\n        },\n        1000\n    );\n}\n\n#[test]\nfn test_err_capped_before_exception() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov64 r1, 0x0\n        mov64 r2, 0x0\n        add64 r0, 0x0\n        add64 r0, 0x0\n        div64 r1, r2\n        add64 r0, 0x0\n        exit\",\n        [],\n        (),\n        0,\n        {\n            |_vm, res: Result| {\n                matches!(res.unwrap_err(),\n                    EbpfError::ExceededMaxInstructions(pc, initial_insn_count)\n                    if pc == 31 && initial_insn_count == 2\n                )\n            }\n        },\n        2\n    );\n    test_interpreter_and_jit_asm!(\n        \"\n        mov64 r1, 0x0\n        mov64 r2, 0x0\n        add64 r0, 0x0\n        add64 r0, 0x0\n        syscall Unresolved\n        add64 r0, 0x0\n        exit\",\n        [],\n        (),\n        0,\n        {\n            |_vm, res: Result| {\n                matches!(res.unwrap_err(),\n                    EbpfError::ExceededMaxInstructions(pc, initial_insn_count)\n                    if pc == 33 && initial_insn_count == 4\n                )\n            }\n        },\n        4\n    );\n}\n\n#[test]\nfn test_err_exit_capped() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov64 r1, 0x1\n        lsh64 r1, 0x20\n        or64 r1, 0x20\n        callx r1\n        exit\n        \",\n        [],\n        (),\n        0,\n        {\n            |_vm, res: Result| {\n                matches!(res.unwrap_err(),\n                    EbpfError::ExceededMaxInstructions(pc, initial_insn_count) if pc == 34 && initial_insn_count == 5\n                )\n            }\n        },\n        5\n    );\n    test_interpreter_and_jit_asm!(\n        \"\n        mov64 r1, 0x1\n        lsh64 r1, 0x20\n        or64 r1, 0x20\n        callx r1\n        mov r0, r0\n        exit\n        \",\n        [],\n        (),\n        0,\n        {\n            |_vm, res: Result| {\n                matches!(res.unwrap_err(),\n                    EbpfError::ExceededMaxInstructions(pc, initial_insn_count) if pc == 35 && initial_insn_count == 6\n                )\n            }\n        },\n        6\n    );\n    test_interpreter_and_jit_asm!(\n        \"\n        call 0\n        mov r0, r0\n        exit\n        \",\n        [],\n        (),\n        0,\n        {\n            |_vm, res: Result| {\n                matches!(res.unwrap_err(),\n                    EbpfError::ExceededMaxInstructions(pc, initial_insn_count) if pc == 32 && initial_insn_count == 3\n                )\n            }\n        },\n        3\n    );\n}\n\n// Symbols and Relocation\n\n#[test]\nfn test_symbol_relocation() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov64 r1, r10\n        sub64 r1, 0x1\n        mov64 r2, 0x1\n        syscall BpfSyscallString\n        mov64 r0, 0x0\n        exit\",\n        [72, 101, 108, 108, 111],\n        (\n            b\"BpfSyscallString\" => syscalls::BpfSyscallString::init::<BpfSyscallContext, UserError>; syscalls::BpfSyscallString::call\n        ),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0 } },\n        6\n    );\n}\n\n#[test]\nfn test_err_call_unresolved() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov r1, 1\n        mov r2, 2\n        mov r3, 3\n        mov r4, 4\n        mov r5, 5\n        syscall Unresolved\n        mov64 r0, 0x0\n        exit\",\n        [],\n        (),\n        0,\n        {\n            |_vm, res: Result| matches!(res.unwrap_err(), EbpfError::UnsupportedInstruction(pc) if pc == 34)\n        },\n        6\n    );\n}\n\n#[test]\nfn test_err_unresolved_elf() {\n    let mut syscall_registry = SyscallRegistry::default();\n    test_interpreter_and_jit!(register, syscall_registry, b\"log\" => syscalls::BpfSyscallString::init::<BpfSyscallContext, UserError>; syscalls::BpfSyscallString::call);\n    let mut file = File::open(\"tests/elfs/unresolved_syscall.so\").unwrap();\n    let mut elf = Vec::new();\n    file.read_to_end(&mut elf).unwrap();\n    let config = Config {\n        reject_broken_elfs: true,\n        ..Config::default()\n    };\n    assert!(\n        matches!(Executable::<UserError, TestInstructionMeter>::from_elf(&elf, None, config, syscall_registry), Err(EbpfError::ElfError(ElfError::UnresolvedSymbol(symbol, pc, offset))) if symbol == \"log_64\" && pc == 550 && offset == 4168)\n    );\n}\n\n#[test]\nfn test_syscall_static() {\n    test_interpreter_and_jit_elf!(\n        \"tests/elfs/syscall_static.so\",\n        [],\n        (\n            b\"log\" => syscalls::BpfSyscallString::init::<BpfSyscallContext, UserError>; syscalls::BpfSyscallString::call,\n        ),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0 } },\n        5\n    );\n}\n\n#[test]\nfn test_syscall_unknown_static() {\n    // Check that unknown static syscalls result in UnsupportedInstruction (or\n    // would be UnresolvedSymbol with\n    // config.disable_unresolved_symbols_at_runtime=false).\n    //\n    // See also elf::test::test_static_syscall_disabled for the corresponding\n    // check with config.syscalls_static=false.\n    test_interpreter_and_jit_elf!(\n        \"tests/elfs/syscall_static_unknown.so\",\n        [],\n        (\n            b\"log\" => syscalls::BpfSyscallString::init::<BpfSyscallContext, UserError>; syscalls::BpfSyscallString::call,\n        ),\n        0,\n        { |_vm, res: Result| { matches!(res.unwrap_err(), EbpfError::UnsupportedInstruction(29)) } },\n        1\n    );\n}\n\n#[test]\nfn test_reloc_64_64() {\n    // Tests the correctness of R_BPF_64_64 relocations. The program returns the\n    // address of the entrypoint.\n    //   [ 1] .text             PROGBITS        00000000000000e8 0000e8 000018 00  AX  0   0  8\n    test_interpreter_and_jit_elf!(\n        \"tests/elfs/reloc_64_64.so\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == ebpf::MM_PROGRAM_START + 0xe8 } },\n        2\n    );\n}\n\n#[test]\nfn test_reloc_64_64_high_vaddr() {\n    // Same as test_reloc_64_64, but with .text already alinged to\n    // MM_PROGRAM_START by the linker\n    test_interpreter_and_jit_elf!(\n        \"tests/elfs/reloc_64_64_high_vaddr.so\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == ebpf::MM_PROGRAM_START } },\n        2\n    );\n}\n\n#[test]\nfn test_reloc_64_relative() {\n    // Tests the correctness of R_BPF_64_RELATIVE relocations. The program\n    // returns the address of the first .rodata byte.\n    //   [ 1] .text             PROGBITS        00000000000000e8 0000e8 000018 00  AX  0   0  8\n    //   [ 2] .rodata           PROGBITS        0000000000000100 000100 00000b 01 AMS  0   0  1\n    test_interpreter_and_jit_elf!(\n        \"tests/elfs/reloc_64_relative.so\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == ebpf::MM_PROGRAM_START + 0x100 } },\n        2\n    );\n}\n\n#[test]\nfn test_reloc_64_relative_high_vaddr() {\n    // Same as test_reloc_64_relative, but with .text placed already within\n    // MM_PROGRAM_START by the linker\n    // [ 1] .text             PROGBITS        0000000100000000 001000 000018 00  AX  0   0  8\n    // [ 2] .rodata           PROGBITS        0000000100000018 001018 00000b 01 AMS  0   0  1\n    test_interpreter_and_jit_elf!(\n        \"tests/elfs/reloc_64_relative_high_vaddr.so\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == ebpf::MM_PROGRAM_START + 0x18 } },\n        2\n    );\n}\n\n#[test]\nfn test_reloc_64_relative_data() {\n    // Tests the correctness of R_BPF_64_RELATIVE relocations in sections other\n    // than .text. The program returns the address of the first .rodata byte.\n    // [ 1] .text             PROGBITS        00000000000000e8 0000e8 000020 00  AX  0   0  8\n    // [ 2] .rodata           PROGBITS        0000000000000108 000108 000019 01 AMS  0   0  1\n    //\n    // 00000000000001f8 <FILE>:\n    // 63:       08 01 00 00 00 00 00 00\n    test_interpreter_and_jit_elf!(\n        \"tests/elfs/reloc_64_relative_data.so\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == ebpf::MM_PROGRAM_START + 0x108 } },\n        3\n    );\n}\n\n#[test]\nfn test_reloc_64_relative_data_high_vaddr() {\n    // Same as test_reloc_64_relative_data, but with rodata already placed\n    // within MM_PROGRAM_START by the linker\n    // [ 1] .text             PROGBITS        0000000100000000 001000 000020 00  AX  0   0  8\n    // [ 2] .rodata           PROGBITS        0000000100000020 001020 000019 01 AMS  0   0  1\n    //\n    // 0000000100000110 <FILE>:\n    // 536870946:      20 00 00 00 01 00 00 00\n    test_interpreter_and_jit_elf!(\n        \"tests/elfs/reloc_64_relative_data_high_vaddr.so\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == ebpf::MM_PROGRAM_START + 0x20 } },\n        3\n    );\n}\n\n#[test]\nfn test_reloc_64_relative_data_pre_sbfv2() {\n    // Before https://github.com/solana-labs/llvm-project/pull/35, we used to\n    // generate invalid R_BPF_64_RELATIVE relocations in sections other than\n    // .text.\n    //\n    // This test checks that the old behaviour is maintained for backwards\n    // compatibility when dealing with non-sbfv2 files. See also Elf::relocate().\n    //\n    // The program returns the address of the first .rodata byte.\n    // [ 1] .text             PROGBITS        00000000000000e8 0000e8 000020 00  AX  0   0  8\n    // [ 2] .rodata           PROGBITS        0000000000000108 000108 000019 01 AMS  0   0  1\n    //\n    // 00000000000001f8 <FILE>:\n    // 63:       00 00 00 00 08 01 00 00\n    test_interpreter_and_jit_elf!(\n        \"tests/elfs/reloc_64_relative_data_pre_sbfv2.so\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == ebpf::MM_PROGRAM_START + 0x108 } },\n        3\n    );\n}\n\n// Programs\n\n#[test]\nfn test_mul_loop() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov r0, 0x7\n        add r1, 0xa\n        lsh r1, 0x20\n        rsh r1, 0x20\n        jeq r1, 0x0, +4\n        mov r0, 0x7\n        mul r0, 0x7\n        add r1, -1\n        jne r1, 0x0, -3\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x75db9c97 } },\n        37\n    );\n}\n\n#[test]\nfn test_prime() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov r1, 67\n        mov r0, 0x1\n        mov r2, 0x2\n        jgt r1, 0x2, +4\n        ja +10\n        add r2, 0x1\n        mov r0, 0x1\n        jge r2, r1, +7\n        mov r3, r1\n        div r3, r2\n        mul r3, r2\n        mov r4, r1\n        sub r4, r3\n        mov r0, 0x0\n        jne r4, 0x0, -10\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x1 } },\n        655\n    );\n}\n\n#[test]\nfn test_subnet() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov r2, 0xe\n        ldxh r3, [r1+12]\n        jne r3, 0x81, +2\n        mov r2, 0x12\n        ldxh r3, [r1+16]\n        and r3, 0xffff\n        jne r3, 0x8, +5\n        add r1, r2\n        mov r0, 0x1\n        ldxw r1, [r1+16]\n        and r1, 0xffffff\n        jeq r1, 0x1a8c0, +1\n        mov r0, 0x0\n        exit\",\n        [\n            0x00, 0x00, 0xc0, 0x9f, 0xa0, 0x97, 0x00, 0xa0, //\n            0xcc, 0x3b, 0xbf, 0xfa, 0x08, 0x00, 0x45, 0x10, //\n            0x00, 0x3c, 0x46, 0x3c, 0x40, 0x00, 0x40, 0x06, //\n            0x73, 0x1c, 0xc0, 0xa8, 0x01, 0x02, 0xc0, 0xa8, //\n            0x01, 0x01, 0x06, 0x0e, 0x00, 0x17, 0x99, 0xc5, //\n            0xa0, 0xec, 0x00, 0x00, 0x00, 0x00, 0xa0, 0x02, //\n            0x7d, 0x78, 0xe0, 0xa3, 0x00, 0x00, 0x02, 0x04, //\n            0x05, 0xb4, 0x04, 0x02, 0x08, 0x0a, 0x00, 0x9c, //\n            0x27, 0x24, 0x00, 0x00, 0x00, 0x00, 0x01, 0x03, //\n            0x03, 0x00, //\n        ],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x1 } },\n        11\n    );\n}\n\n#[test]\nfn test_tcp_port80_match() {\n    test_interpreter_and_jit_asm!(\n        PROG_TCP_PORT_80,\n        [\n            0x00, 0x01, 0x02, 0x03, 0x04, 0x05, 0x00, 0x06, //\n            0x07, 0x08, 0x09, 0x0a, 0x08, 0x00, 0x45, 0x00, //\n            0x00, 0x56, 0x00, 0x01, 0x00, 0x00, 0x40, 0x06, //\n            0xf9, 0x4d, 0xc0, 0xa8, 0x00, 0x01, 0xc0, 0xa8, //\n            0x00, 0x02, 0x27, 0x10, 0x00, 0x50, 0x00, 0x00, //\n            0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x50, 0x02, //\n            0x20, 0x00, 0xc5, 0x18, 0x00, 0x00, 0x44, 0x44, //\n            0x44, 0x44, 0x44, 0x44, 0x44, 0x44, 0x44, 0x44, //\n            0x44, 0x44, 0x44, 0x44, 0x44, 0x44, 0x44, 0x44, //\n            0x44, 0x44, 0x44, 0x44, 0x44, 0x44, 0x44, 0x44, //\n            0x44, 0x44, 0x44, 0x44, 0x44, 0x44, 0x44, 0x44, //\n            0x44, 0x44, 0x44, 0x44, 0x44, 0x44, 0x44, 0x44, //\n            0x44, 0x44, 0x44, 0x44, //\n        ],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x1 } },\n        17\n    );\n}\n\n#[test]\nfn test_tcp_port80_nomatch() {\n    test_interpreter_and_jit_asm!(\n        PROG_TCP_PORT_80,\n        [\n            0x00, 0x01, 0x02, 0x03, 0x04, 0x05, 0x00, 0x06, //\n            0x07, 0x08, 0x09, 0x0a, 0x08, 0x00, 0x45, 0x00, //\n            0x00, 0x56, 0x00, 0x01, 0x00, 0x00, 0x40, 0x06, //\n            0xf9, 0x4d, 0xc0, 0xa8, 0x00, 0x01, 0xc0, 0xa8, //\n            0x00, 0x02, 0x00, 0x16, 0x27, 0x10, 0x00, 0x00, //\n            0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x51, 0x02, //\n            0x20, 0x00, 0xc5, 0x18, 0x00, 0x00, 0x44, 0x44, //\n            0x44, 0x44, 0x44, 0x44, 0x44, 0x44, 0x44, 0x44, //\n            0x44, 0x44, 0x44, 0x44, 0x44, 0x44, 0x44, 0x44, //\n            0x44, 0x44, 0x44, 0x44, 0x44, 0x44, 0x44, 0x44, //\n            0x44, 0x44, 0x44, 0x44, 0x44, 0x44, 0x44, 0x44, //\n            0x44, 0x44, 0x44, 0x44, 0x44, 0x44, 0x44, 0x44, //\n            0x44, 0x44, 0x44, 0x44, //\n        ],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x0 } },\n        18\n    );\n}\n\n#[test]\nfn test_tcp_port80_nomatch_ethertype() {\n    test_interpreter_and_jit_asm!(\n        PROG_TCP_PORT_80,\n        [\n            0x00, 0x01, 0x02, 0x03, 0x04, 0x05, 0x00, 0x06, //\n            0x07, 0x08, 0x09, 0x0a, 0x08, 0x01, 0x45, 0x00, //\n            0x00, 0x56, 0x00, 0x01, 0x00, 0x00, 0x40, 0x06, //\n            0xf9, 0x4d, 0xc0, 0xa8, 0x00, 0x01, 0xc0, 0xa8, //\n            0x00, 0x02, 0x27, 0x10, 0x00, 0x50, 0x00, 0x00, //\n            0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x50, 0x02, //\n            0x20, 0x00, 0xc5, 0x18, 0x00, 0x00, 0x44, 0x44, //\n            0x44, 0x44, 0x44, 0x44, 0x44, 0x44, 0x44, 0x44, //\n            0x44, 0x44, 0x44, 0x44, 0x44, 0x44, 0x44, 0x44, //\n            0x44, 0x44, 0x44, 0x44, 0x44, 0x44, 0x44, 0x44, //\n            0x44, 0x44, 0x44, 0x44, 0x44, 0x44, 0x44, 0x44, //\n            0x44, 0x44, 0x44, 0x44, 0x44, 0x44, 0x44, 0x44, //\n            0x44, 0x44, 0x44, 0x44, //\n        ],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x0 } },\n        7\n    );\n}\n\n#[test]\nfn test_tcp_port80_nomatch_proto() {\n    test_interpreter_and_jit_asm!(\n        PROG_TCP_PORT_80,\n        [\n            0x00, 0x01, 0x02, 0x03, 0x04, 0x05, 0x00, 0x06, //\n            0x07, 0x08, 0x09, 0x0a, 0x08, 0x00, 0x45, 0x00, //\n            0x00, 0x56, 0x00, 0x01, 0x00, 0x00, 0x40, 0x11, //\n            0xf9, 0x4d, 0xc0, 0xa8, 0x00, 0x01, 0xc0, 0xa8, //\n            0x00, 0x02, 0x27, 0x10, 0x00, 0x50, 0x00, 0x00, //\n            0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x50, 0x02, //\n            0x20, 0x00, 0xc5, 0x18, 0x00, 0x00, 0x44, 0x44, //\n            0x44, 0x44, 0x44, 0x44, 0x44, 0x44, 0x44, 0x44, //\n            0x44, 0x44, 0x44, 0x44, 0x44, 0x44, 0x44, 0x44, //\n            0x44, 0x44, 0x44, 0x44, 0x44, 0x44, 0x44, 0x44, //\n            0x44, 0x44, 0x44, 0x44, 0x44, 0x44, 0x44, 0x44, //\n            0x44, 0x44, 0x44, 0x44, 0x44, 0x44, 0x44, 0x44, //\n            0x44, 0x44, 0x44, 0x44, //\n        ],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x0 } },\n        9\n    );\n}\n\n#[test]\nfn test_tcp_sack_match() {\n    test_interpreter_and_jit_asm!(\n        TCP_SACK_ASM,\n        TCP_SACK_MATCH,\n        (),\n        0,\n        { |_vm, res: Result| res.unwrap() == 0x1 },\n        79\n    );\n}\n\n#[test]\nfn test_tcp_sack_nomatch() {\n    test_interpreter_and_jit_asm!(\n        TCP_SACK_ASM,\n        TCP_SACK_NOMATCH,\n        (),\n        0,\n        { |_vm, res: Result| res.unwrap() == 0x0 },\n        55\n    );\n}\n\n// Fuzzy\n\n#[cfg(all(not(windows), target_arch = \"x86_64\"))]\nfn execute_generated_program(prog: &[u8]) -> bool {\n    let max_instruction_count = 1024;\n    let mem_size = 1024 * 1024;\n    let mut bpf_functions = BTreeMap::new();\n    let config = Config {\n        enable_instruction_tracing: true,\n        ..Config::default()\n    };\n    let syscall_registry = SyscallRegistry::default();\n    register_bpf_function(\n        &config,\n        &mut bpf_functions,\n        &syscall_registry,\n        0,\n        \"entrypoint\",\n    )\n    .unwrap();\n    let executable = Executable::<UserError, TestInstructionMeter>::from_text_bytes(\n        prog,\n        Some(solana_rbpf::verifier::check),\n        config,\n        syscall_registry,\n        bpf_functions,\n    );\n    let mut executable = if let Ok(executable) = executable {\n        executable\n    } else {\n        return false;\n    };\n    if Executable::<UserError, TestInstructionMeter>::jit_compile(&mut executable).is_err() {\n        return false;\n    }\n    let (instruction_count_interpreter, tracer_interpreter, result_interpreter) = {\n        let mut mem = vec![0u8; mem_size];\n        let mem_region = MemoryRegion::new_writable(&mut mem, ebpf::MM_INPUT_START);\n        let mut vm = EbpfVm::new(&executable, &mut [], vec![mem_region]).unwrap();\n        let result_interpreter = vm.execute_program_interpreted(&mut TestInstructionMeter {\n            remaining: max_instruction_count,\n        });\n        let tracer_interpreter = vm.get_tracer().clone();\n        (\n            vm.get_total_instruction_count(),\n            tracer_interpreter,\n            result_interpreter,\n        )\n    };\n    let mut mem = vec![0u8; mem_size];\n    let mem_region = MemoryRegion::new_writable(&mut mem, ebpf::MM_INPUT_START);\n    let mut vm = EbpfVm::new(&executable, &mut [], vec![mem_region]).unwrap();\n    let result_jit = vm.execute_program_jit(&mut TestInstructionMeter {\n        remaining: max_instruction_count,\n    });\n    let tracer_jit = vm.get_tracer();\n    if result_interpreter != result_jit\n        || !solana_rbpf::vm::Tracer::compare(&tracer_interpreter, tracer_jit)\n    {\n        let analysis =\n            solana_rbpf::static_analysis::Analysis::from_executable(&executable).unwrap();\n        println!(\"result_interpreter={:?}\", result_interpreter);\n        println!(\"result_jit={:?}\", result_jit);\n        let stdout = std::io::stdout();\n        tracer_interpreter\n            .write(&mut stdout.lock(), &analysis)\n            .unwrap();\n        tracer_jit.write(&mut stdout.lock(), &analysis).unwrap();\n        panic!();\n    }\n    if executable.get_config().enable_instruction_meter {\n        let instruction_count_jit = vm.get_total_instruction_count();\n        assert_eq!(instruction_count_interpreter, instruction_count_jit);\n    }\n    true\n}\n\n#[cfg(all(not(windows), target_arch = \"x86_64\"))]\n#[test]\nfn test_total_chaos() {\n    let instruction_count = 6;\n    let iteration_count = 1000000;\n    let mut program = vec![0; instruction_count * ebpf::INSN_SIZE];\n    program[ebpf::INSN_SIZE * (instruction_count - 1)..ebpf::INSN_SIZE * instruction_count]\n        .copy_from_slice(&[ebpf::EXIT, 0, 0, 0, 0, 0, 0, 0]);\n    let seed = 0xC2DB2F8F282284A0;\n    let mut prng = SmallRng::seed_from_u64(seed);\n    for _ in 0..iteration_count {\n        prng.fill_bytes(&mut program[0..ebpf::INSN_SIZE * (instruction_count - 1)]);\n        execute_generated_program(&program);\n    }\n    for _ in 0..iteration_count {\n        prng.fill_bytes(&mut program[0..ebpf::INSN_SIZE * (instruction_count - 1)]);\n        for index in (0..program.len()).step_by(ebpf::INSN_SIZE) {\n            program[index + 0x1] &= 0x77;\n            program[index + 0x2] &= 0x00;\n            program[index + 0x3] &= 0x77;\n            program[index + 0x4] &= 0x00;\n            program[index + 0x5] &= 0x77;\n            program[index + 0x6] &= 0x77;\n            program[index + 0x7] &= 0x77;\n        }\n        execute_generated_program(&program);\n    }\n}\n"], "fixing_code": ["#![allow(clippy::integer_arithmetic)]\n// Derived from uBPF <https://github.com/iovisor/ubpf>\n// Copyright 2015 Big Switch Networks, Inc\n//      (uBPF: JIT algorithm, originally in C)\n// Copyright 2016 6WIND S.A. <quentin.monnet@6wind.com>\n//      (Translation to Rust, MetaBuff addition)\n//\n// Licensed under the Apache License, Version 2.0 <http://www.apache.org/licenses/LICENSE-2.0> or\n// the MIT license <http://opensource.org/licenses/MIT>, at your option. This file may not be\n// copied, modified, or distributed except according to those terms.\n\n#![allow(clippy::deprecated_cfg_attr)]\n#![cfg_attr(rustfmt, rustfmt_skip)]\n#![allow(unreachable_code)]\n\nextern crate libc;\n\nuse std::{\n    collections::HashMap,\n    fmt::{Debug, Error as FormatterError, Formatter},\n    mem,\n    ops::{Index, IndexMut},\n    pin::Pin, ptr,\n};\nuse rand::{rngs::SmallRng, Rng, SeedableRng};\n\nuse crate::{\n    elf::Executable,\n    vm::{Config, ProgramResult, InstructionMeter, Tracer, SYSCALL_CONTEXT_OBJECTS_OFFSET},\n    ebpf::{self, INSN_SIZE, FIRST_SCRATCH_REG, SCRATCH_REGS, FRAME_PTR_REG, MM_STACK_START, STACK_PTR_REG},\n    error::{UserDefinedError, EbpfError},\n    memory_region::{AccessType, MemoryMapping, MemoryRegion},\n    user_error::UserError,\n    x86::*,\n};\n\nconst MAX_EMPTY_PROGRAM_MACHINE_CODE_LENGTH: usize = 4096;\nconst MAX_MACHINE_CODE_LENGTH_PER_INSTRUCTION: usize = 110;\n\n/// Argument for executing a eBPF JIT-compiled program\npub struct JitProgramArgument<'a> {\n    /// The MemoryMapping to be used to run the compiled code\n    pub memory_mapping: MemoryMapping<'a>,\n    /// Pointers to the context objects of syscalls\n    pub syscall_context_objects: [*const u8; 0],\n}\n\nstruct JitProgramSections {\n    page_size: usize,\n    pc_section: &'static mut [u64],\n    text_section: &'static mut [u8],\n}\n\n#[cfg(not(target_os = \"windows\"))]\nmacro_rules! libc_error_guard {\n    (succeeded?, mmap, $addr:expr, $($arg:expr),*) => {{\n        *$addr = libc::mmap(*$addr, $($arg),*);\n        *$addr != libc::MAP_FAILED\n    }};\n    (succeeded?, $function:ident, $($arg:expr),*) => {\n        libc::$function($($arg),*) == 0\n    };\n    ($function:ident, $($arg:expr),*) => {{\n        const RETRY_COUNT: usize = 3;\n        for i in 0..RETRY_COUNT {\n            if libc_error_guard!(succeeded?, $function, $($arg),*) {\n                break;\n            } else if i + 1 == RETRY_COUNT {\n                let args = vec![$(format!(\"{:?}\", $arg)),*];\n                #[cfg(any(target_os = \"freebsd\", target_os = \"ios\", target_os = \"macos\"))]\n                let errno = *libc::__error();\n                #[cfg(target_os = \"linux\")]\n                let errno = *libc::__errno_location();\n                return Err(EbpfError::LibcInvocationFailed(stringify!($function), args, errno));\n            }\n        }\n    }};\n}\n\nfn round_to_page_size(value: usize, page_size: usize) -> usize {\n    (value + page_size - 1) / page_size * page_size\n}\n\n#[allow(unused_variables)]\nimpl JitProgramSections {\n    fn new<E: UserDefinedError>(pc: usize, code_size: usize) -> Result<Self, EbpfError<E>> {\n        #[cfg(target_os = \"windows\")]\n        {\n            Ok(Self {\n                page_size: 0,\n                pc_section: &mut [],\n                text_section: &mut [],\n            })\n        }\n        #[cfg(not(target_os = \"windows\"))]\n        unsafe {\n            let page_size = libc::sysconf(libc::_SC_PAGESIZE) as usize;\n            let pc_loc_table_size = round_to_page_size(pc * 8, page_size);\n            let over_allocated_code_size = round_to_page_size(code_size, page_size);\n            let mut raw: *mut libc::c_void = std::ptr::null_mut();\n            libc_error_guard!(mmap, &mut raw, pc_loc_table_size + over_allocated_code_size, libc::PROT_READ | libc::PROT_WRITE, libc::MAP_ANONYMOUS | libc::MAP_PRIVATE, 0, 0);\n            Ok(Self {\n                page_size,\n                pc_section: std::slice::from_raw_parts_mut(raw as *mut u64, pc),\n                text_section: std::slice::from_raw_parts_mut(raw.add(pc_loc_table_size) as *mut u8, over_allocated_code_size),\n            })\n        }\n    }\n\n    fn seal<E: UserDefinedError>(&mut self, text_section_usage: usize) -> Result<(), EbpfError<E>> {\n        if self.page_size > 0 {\n            let raw = self.pc_section.as_ptr() as *mut u8;\n            let pc_loc_table_size = round_to_page_size(self.pc_section.len() * 8, self.page_size);\n            let over_allocated_code_size = round_to_page_size(self.text_section.len(), self.page_size);\n            let code_size = round_to_page_size(text_section_usage, self.page_size);\n            #[cfg(not(target_os = \"windows\"))]\n            unsafe {\n                if over_allocated_code_size > code_size {\n                    libc_error_guard!(munmap, raw.add(pc_loc_table_size).add(code_size) as *mut _, over_allocated_code_size - code_size);\n                }\n                std::ptr::write_bytes(raw.add(pc_loc_table_size).add(text_section_usage), 0xcc, code_size - text_section_usage); // Fill with debugger traps\n                self.text_section = std::slice::from_raw_parts_mut(raw.add(pc_loc_table_size), text_section_usage);\n                libc_error_guard!(mprotect, self.pc_section.as_mut_ptr() as *mut _, pc_loc_table_size, libc::PROT_READ);\n                libc_error_guard!(mprotect, self.text_section.as_mut_ptr() as *mut _, code_size, libc::PROT_EXEC | libc::PROT_READ);\n            }\n        }\n        Ok(())\n    }\n\n    pub fn mem_size(&self) -> usize {\n        let pc_loc_table_size = round_to_page_size(self.pc_section.len() * 8, self.page_size);\n        let code_size = round_to_page_size(self.text_section.len(), self.page_size);\n        pc_loc_table_size + code_size\n    }\n}\n\nimpl Drop for JitProgramSections {\n    fn drop(&mut self) {\n        let pc_loc_table_size = round_to_page_size(self.pc_section.len() * 8, self.page_size);\n        let code_size = round_to_page_size(self.text_section.len(), self.page_size);\n        if pc_loc_table_size + code_size > 0 {\n            #[cfg(not(target_os = \"windows\"))]\n            unsafe {\n                libc::munmap(self.pc_section.as_ptr() as *mut _, pc_loc_table_size + code_size);\n            }\n        }\n    }\n}\n\n/// eBPF JIT-compiled program\npub struct JitProgram<E: UserDefinedError, I: InstructionMeter> {\n    /// Holds and manages the protected memory\n    sections: JitProgramSections,\n    /// Call this with JitProgramArgument to execute the compiled code\n    pub main: unsafe fn(&ProgramResult<E>, u64, &JitProgramArgument, &mut I) -> i64,\n}\n\nimpl<E: UserDefinedError, I: InstructionMeter> Debug for JitProgram<E, I> {\n    fn fmt(&self, fmt: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        fmt.write_fmt(format_args!(\"JitProgram {:?}\", &self.main as *const _))\n    }\n}\n\nimpl<E: UserDefinedError, I: InstructionMeter> PartialEq for JitProgram<E, I> {\n    fn eq(&self, other: &Self) -> bool {\n        std::ptr::eq(self.main as *const u8, other.main as *const u8)\n    }\n}\n\nimpl<E: UserDefinedError, I: InstructionMeter> JitProgram<E, I> {\n    pub fn new(executable: &Pin<Box<Executable<E, I>>>) -> Result<Self, EbpfError<E>> {\n        let program = executable.get_text_bytes().1;\n        let mut jit = JitCompiler::new::<E>(program, executable.get_config())?;\n        jit.compile::<E, I>(executable)?;\n        let main = unsafe { mem::transmute(jit.result.text_section.as_ptr()) };\n        Ok(Self {\n            sections: jit.result,\n            main,\n        })\n    }\n\n    pub fn mem_size(&self) -> usize {\n        mem::size_of::<Self>() +\n        self.sections.mem_size()\n    }\n\n    pub fn machine_code_length(&self) -> usize {\n        self.sections.text_section.len()\n    }\n}\n\n// Special values for target_pc in struct Jump\nconst TARGET_PC_LOCAL_ANCHOR: usize = std::usize::MAX - 100;\nconst TARGET_PC_DIV_OVERFLOW: usize = std::usize::MAX - 33;\nconst TARGET_PC_TRACE: usize = std::usize::MAX - 32;\nconst TARGET_PC_SYSCALL: usize = std::usize::MAX - 31;\nconst TARGET_PC_BPF_CALL_PROLOGUE: usize = std::usize::MAX - 30;\nconst TARGET_PC_BPF_CALL_REG: usize = std::usize::MAX - 29;\nconst TARGET_PC_TRANSLATE_PC: usize = std::usize::MAX - 28;\nconst TARGET_PC_TRANSLATE_PC_LOOP: usize = std::usize::MAX - 27;\nconst TARGET_PC_TRANSLATE_MEMORY_ADDRESS: usize = std::usize::MAX - 26;\nconst TARGET_PC_MEMORY_ACCESS_VIOLATION: usize = std::usize::MAX - 18;\nconst TARGET_PC_CALL_EXCEEDED_MAX_INSTRUCTIONS: usize = std::usize::MAX - 10;\nconst TARGET_PC_CALL_DEPTH_EXCEEDED: usize = std::usize::MAX - 9;\nconst TARGET_PC_CALL_OUTSIDE_TEXT_SEGMENT: usize = std::usize::MAX - 8;\nconst TARGET_PC_CALLX_UNSUPPORTED_INSTRUCTION: usize = std::usize::MAX - 7;\nconst TARGET_PC_CALL_UNSUPPORTED_INSTRUCTION: usize = std::usize::MAX - 6;\nconst TARGET_PC_DIV_BY_ZERO: usize = std::usize::MAX - 5;\nconst TARGET_PC_EXCEPTION_AT: usize = std::usize::MAX - 4;\nconst TARGET_PC_RUST_EXCEPTION: usize = std::usize::MAX - 3;\nconst TARGET_PC_EXIT: usize = std::usize::MAX - 2;\nconst TARGET_PC_EPILOGUE: usize = std::usize::MAX - 1;\n\nconst REGISTER_MAP: [u8; 11] = [\n    CALLER_SAVED_REGISTERS[0],\n    ARGUMENT_REGISTERS[1],\n    ARGUMENT_REGISTERS[2],\n    ARGUMENT_REGISTERS[3],\n    ARGUMENT_REGISTERS[4],\n    ARGUMENT_REGISTERS[5],\n    CALLEE_SAVED_REGISTERS[2],\n    CALLEE_SAVED_REGISTERS[3],\n    CALLEE_SAVED_REGISTERS[4],\n    CALLEE_SAVED_REGISTERS[5],\n    CALLEE_SAVED_REGISTERS[1],\n];\n\n// Special registers:\n//     ARGUMENT_REGISTERS[0]  RDI  BPF program counter limit (used by instruction meter)\n// CALLER_SAVED_REGISTERS[8]  R11  Scratch register\n// CALLER_SAVED_REGISTERS[7]  R10  Constant pointer to JitProgramArgument (also scratch register for exception handling)\n// CALLEE_SAVED_REGISTERS[0]  RBP  Constant pointer to inital RSP - 8\n\n#[inline]\npub fn emit<T, E: UserDefinedError>(jit: &mut JitCompiler, data: T) -> Result<(), EbpfError<E>> {\n    let size = mem::size_of::<T>() as usize;\n    if jit.offset_in_text_section + size > jit.result.text_section.len() {\n        return Err(EbpfError::ExhausedTextSegment(jit.pc));\n    }\n    unsafe {\n        #[allow(clippy::cast_ptr_alignment)]\n        let ptr = jit.result.text_section.as_ptr().add(jit.offset_in_text_section) as *mut T;\n        *ptr = data as T;\n    }\n    jit.offset_in_text_section += size;\n    Ok(())\n}\n\npub fn emit_variable_length<E: UserDefinedError>(jit: &mut JitCompiler, size: OperandSize, data: u64) -> Result<(), EbpfError<E>> {\n    match size {\n        OperandSize::S0 => Ok(()),\n        OperandSize::S8 => emit::<u8, E>(jit, data as u8),\n        OperandSize::S16 => emit::<u16, E>(jit, data as u16),\n        OperandSize::S32 => emit::<u32, E>(jit, data as u32),\n        OperandSize::S64 => emit::<u64, E>(jit, data),\n    }\n}\n\n#[derive(PartialEq, Eq, Copy, Clone, Debug)]\npub enum OperandSize {\n    S0  = 0,\n    S8  = 8,\n    S16 = 16,\n    S32 = 32,\n    S64 = 64,\n}\n\n#[inline]\nfn emit_sanitized_load_immediate<E: UserDefinedError>(jit: &mut JitCompiler, size: OperandSize, destination: u8, value: i64) -> Result<(), EbpfError<E>> {\n    match size {\n        OperandSize::S32 => {\n            let key: i32 = jit.diversification_rng.gen();\n            X86Instruction::load_immediate(size, destination, (value as i32).wrapping_sub(key) as i64).emit(jit)?;\n            emit_alu(jit, size, 0x81, 0, destination, key as i64, None)\n        },\n        OperandSize::S64 if destination == R11 => {\n            let key: i64 = jit.diversification_rng.gen();\n            let lower_key = key as i32 as i64;\n            let upper_key = (key >> 32) as i32 as i64;\n            X86Instruction::load_immediate(size, destination, value.wrapping_sub(lower_key).rotate_right(32).wrapping_sub(upper_key)).emit(jit)?;\n            emit_alu(jit, size, 0x81, 0, destination, upper_key, None)?; // wrapping_add(upper_key)\n            emit_alu(jit, size, 0xc1, 1, destination, 32, None)?; // rotate_right(32)\n            emit_alu(jit, size, 0x81, 0, destination, lower_key, None) // wrapping_add(lower_key)\n        },\n        OperandSize::S64 if value >= std::i32::MIN as i64 && value <= std::i32::MAX as i64 => {\n            let key = jit.diversification_rng.gen::<i32>() as i64;\n            X86Instruction::load_immediate(size, destination, value.wrapping_sub(key)).emit(jit)?;\n            emit_alu(jit, size, 0x81, 0, destination, key, None)\n        },\n        OperandSize::S64 => {\n            let key: i64 = jit.diversification_rng.gen();\n            X86Instruction::load_immediate(size, destination, value.wrapping_sub(key)).emit(jit)?;\n            X86Instruction::load_immediate(size, R11, key).emit(jit)?;\n            emit_alu(jit, size, 0x01, R11, destination, 0, None)\n        },\n        _ => {\n            #[cfg(debug_assertions)]\n            unreachable!();\n            Ok(())\n        }\n    }\n}\n\n#[inline]\nfn emit_alu<E: UserDefinedError>(jit: &mut JitCompiler, size: OperandSize, opcode: u8, source: u8, destination: u8, immediate: i64, indirect: Option<X86IndirectAccess>) -> Result<(), EbpfError<E>> {\n    X86Instruction {\n        size,\n        opcode,\n        first_operand: source,\n        second_operand: destination,\n        immediate_size: match opcode {\n            0xc1 => OperandSize::S8,\n            0x81 => OperandSize::S32,\n            0xf7 if source == 0 => OperandSize::S32,\n            _ => OperandSize::S0,\n        },\n        immediate,\n        indirect,\n        ..X86Instruction::default()\n    }.emit(jit)\n}\n\n#[inline]\nfn should_sanitize_constant(jit: &JitCompiler, value: i64) -> bool {\n    if !jit.config.sanitize_user_provided_values {\n        return false;\n    }\n\n    match value as u64 {\n        0xFFFF\n        | 0xFFFFFF\n        | 0xFFFFFFFF\n        | 0xFFFFFFFFFF\n        | 0xFFFFFFFFFFFF\n        | 0xFFFFFFFFFFFFFF\n        | 0xFFFFFFFFFFFFFFFF => false,\n        v if v <= 0xFF => false,\n        v if !v <= 0xFF => false,\n        _ => true\n    }\n}\n\n#[inline]\nfn emit_sanitized_alu<E: UserDefinedError>(jit: &mut JitCompiler, size: OperandSize, opcode: u8, opcode_extension: u8, destination: u8, immediate: i64) -> Result<(), EbpfError<E>> {\n    if should_sanitize_constant(jit, immediate) {\n        emit_sanitized_load_immediate(jit, size, R11, immediate)?;\n        emit_alu(jit, size, opcode, R11, destination, immediate, None)\n    } else {\n        emit_alu(jit, size, 0x81, opcode_extension, destination, immediate, None)\n    }\n}\n\n#[inline]\nfn emit_jump_offset<E: UserDefinedError>(jit: &mut JitCompiler, target_pc: usize) -> Result<(), EbpfError<E>> {\n    jit.text_section_jumps.push(Jump { location: jit.offset_in_text_section, target_pc });\n    emit::<u32, E>(jit, 0)\n}\n\n#[inline]\nfn emit_jcc<E: UserDefinedError>(jit: &mut JitCompiler, code: u8, target_pc: usize) -> Result<(), EbpfError<E>> {\n    emit::<u8, E>(jit, 0x0f)?;\n    emit::<u8, E>(jit, code)?;\n    emit_jump_offset(jit, target_pc)\n}\n\n#[inline]\nfn emit_jmp<E: UserDefinedError>(jit: &mut JitCompiler, target_pc: usize) -> Result<(), EbpfError<E>> {\n    emit::<u8, E>(jit, 0xe9)?;\n    emit_jump_offset(jit, target_pc)\n}\n\n#[inline]\nfn emit_call<E: UserDefinedError>(jit: &mut JitCompiler, target_pc: usize) -> Result<(), EbpfError<E>> {\n    emit::<u8, E>(jit, 0xe8)?;\n    emit_jump_offset(jit, target_pc)\n}\n\n#[inline]\nfn set_anchor(jit: &mut JitCompiler, target: usize) {\n    jit.handler_anchors.insert(target, jit.offset_in_text_section);\n}\n\n/// Indices of slots inside the struct at inital RSP\n#[repr(C)]\nenum EnvironmentStackSlot {\n    /// The 6 CALLEE_SAVED_REGISTERS\n    LastSavedRegister = 5,\n    /// The current call depth.\n    ///\n    /// Incremented on calls and decremented on exits. It's used to enforce\n    /// config.max_call_depth and to know when to terminate execution.\n    CallDepth = 6,\n    /// BPF frame pointer (REGISTER_MAP[FRAME_PTR_REG]).\n    BpfFramePtr = 7,\n    /// The BPF stack pointer (r11). Only used when config.dynamic_stack_frames=true.\n    ///\n    /// The stack pointer isn't exposed as an actual register. Only sub and add\n    /// instructions (typically generated by the LLVM backend) are allowed to\n    /// access it. Its value is only stored in this slot and therefore the\n    /// register is not tracked in REGISTER_MAP.\n    BpfStackPtr = 8,\n    /// Constant pointer to optional typed return value\n    OptRetValPtr = 9,\n    /// Last return value of instruction_meter.get_remaining()\n    PrevInsnMeter = 10,\n    /// Constant pointer to instruction_meter\n    InsnMeterPtr = 11,\n    /// CPU cycles accumulated by the stop watch\n    StopwatchNumerator = 12,\n    /// Number of times the stop watch was used\n    StopwatchDenominator = 13,\n    /// Bumper for size_of\n    SlotCount = 14,\n}\n\nfn slot_on_environment_stack(jit: &JitCompiler, slot: EnvironmentStackSlot) -> i32 {\n    -8 * (slot as i32 + jit.environment_stack_key)\n}\n\n#[allow(dead_code)]\n#[inline]\nfn emit_stopwatch<E: UserDefinedError>(jit: &mut JitCompiler, begin: bool) -> Result<(), EbpfError<E>> {\n    jit.stopwatch_is_active = true;\n    X86Instruction::push(RDX, None).emit(jit)?;\n    X86Instruction::push(RAX, None).emit(jit)?;\n    X86Instruction::fence(FenceType::Load).emit(jit)?; // lfence\n    X86Instruction::cycle_count().emit(jit)?; // rdtsc\n    X86Instruction::fence(FenceType::Load).emit(jit)?; // lfence\n    emit_alu(jit, OperandSize::S64, 0xc1, 4, RDX, 32, None)?; // RDX <<= 32;\n    emit_alu(jit, OperandSize::S64, 0x09, RDX, RAX, 0, None)?; // RAX |= RDX;\n    if begin {\n        emit_alu(jit, OperandSize::S64, 0x29, RAX, RBP, 0, Some(X86IndirectAccess::Offset(slot_on_environment_stack(jit, EnvironmentStackSlot::StopwatchNumerator))))?; // *numerator -= RAX;\n    } else {\n        emit_alu(jit, OperandSize::S64, 0x01, RAX, RBP, 0, Some(X86IndirectAccess::Offset(slot_on_environment_stack(jit, EnvironmentStackSlot::StopwatchNumerator))))?; // *numerator += RAX;\n        emit_alu(jit, OperandSize::S64, 0x81, 0, RBP, 1, Some(X86IndirectAccess::Offset(slot_on_environment_stack(jit, EnvironmentStackSlot::StopwatchDenominator))))?; // *denominator += 1;\n    }\n    X86Instruction::pop(RAX).emit(jit)?;\n    X86Instruction::pop(RDX).emit(jit)\n}\n\n/* Explaination of the Instruction Meter\n\n    The instruction meter serves two purposes: First, measure how many BPF instructions are\n    executed (profiling) and second, limit this number by stopping the program with an exception\n    once a given threshold is reached (validation). One approach would be to increment and\n    validate the instruction meter before each instruction. However, this would heavily impact\n    performance. Thus, we only profile and validate the instruction meter at branches.\n\n    For this, we implicitly sum up all the instructions between two branches.\n    It is easy to know the end of such a slice of instructions, but how do we know where it\n    started? There could be multiple ways to jump onto a path which all lead to the same final\n    branch. This is, where the integral technique comes in. The program is basically a sequence\n    of instructions with the x-axis being the program counter (short \"pc\"). The cost function is\n    a constant function which returns one for every point on the x axis. Now, the instruction\n    meter needs to calculate the definite integral of the cost function between the start and the\n    end of the current slice of instructions. For that we need the indefinite integral of the cost\n    function. Fortunately, the derivative of the pc is the cost function (it increases by one for\n    every instruction), thus the pc is an antiderivative of the the cost function and a valid\n    indefinite integral. So, to calculate an definite integral of the cost function, we just need\n    to subtract the start pc from the end pc of the slice. This difference can then be subtracted\n    from the remaining instruction counter until it goes below zero at which point it reaches\n    the instruction meter limit. Ok, but how do we know the start of the slice at the end?\n\n    The trick is: We do not need to know. As subtraction and addition are associative operations,\n    we can reorder them, even beyond the current branch. Thus, we can simply account for the\n    amount the start will subtract at the next branch by already adding that to the remaining\n    instruction counter at the current branch. So, every branch just subtracts its current pc\n    (the end of the slice) and adds the target pc (the start of the next slice) to the remaining\n    instruction counter. This way, no branch needs to know the pc of the last branch explicitly.\n    Another way to think about this trick is as follows: The remaining instruction counter now\n    measures what the maximum pc is, that we can reach with the remaining budget after the last\n    branch.\n\n    One problem are conditional branches. There are basically two ways to handle them: Either,\n    only do the profiling if the branch is taken, which requires two jumps (one for the profiling\n    and one to get to the target pc). Or, always profile it as if the jump to the target pc was\n    taken, but then behind the conditional branch, undo the profiling (as it was not taken). We\n    use the second method and the undo profiling is the same as the normal profiling, just with\n    reversed plus and minus signs.\n\n    Another special case to keep in mind are return instructions. They would require us to know\n    the return address (target pc), but in the JIT we already converted that to be a host address.\n    Of course, one could also save the BPF return address on the stack, but an even simpler\n    solution exists: Just count as if you were jumping to an specific target pc before the exit,\n    and then after returning use the undo profiling. The trick is, that the undo profiling now\n    has the current pc which is the BPF return address. The virtual target pc we count towards\n    and undo again can be anything, so we just set it to zero.\n*/\n\n#[inline]\nfn emit_validate_instruction_count<E: UserDefinedError>(jit: &mut JitCompiler, exclusive: bool, pc: Option<usize>) -> Result<(), EbpfError<E>> {\n    if let Some(pc) = pc {\n        jit.last_instruction_meter_validation_pc = pc;\n        X86Instruction::cmp_immediate(OperandSize::S64, ARGUMENT_REGISTERS[0], pc as i64 + 1, None).emit(jit)?;\n    } else {\n        X86Instruction::cmp(OperandSize::S64, R11, ARGUMENT_REGISTERS[0], None).emit(jit)?;\n    }\n    emit_jcc(jit, if exclusive { 0x82 } else { 0x86 }, TARGET_PC_CALL_EXCEEDED_MAX_INSTRUCTIONS)\n}\n\n#[inline]\nfn emit_profile_instruction_count<E: UserDefinedError>(jit: &mut JitCompiler, target_pc: Option<usize>) -> Result<(), EbpfError<E>> {\n    match target_pc {\n        Some(target_pc) => {\n            emit_alu(jit, OperandSize::S64, 0x81, 0, ARGUMENT_REGISTERS[0], target_pc as i64 - jit.pc as i64 - 1, None)?; // instruction_meter += target_pc - (jit.pc + 1);\n        },\n        None => {\n            emit_alu(jit, OperandSize::S64, 0x81, 5, ARGUMENT_REGISTERS[0], jit.pc as i64 + 1, None)?; // instruction_meter -= jit.pc + 1;\n            emit_alu(jit, OperandSize::S64, 0x01, R11, ARGUMENT_REGISTERS[0], jit.pc as i64, None)?; // instruction_meter += target_pc;\n        },\n    }\n    Ok(())\n}\n\n#[inline]\nfn emit_validate_and_profile_instruction_count<E: UserDefinedError>(jit: &mut JitCompiler, exclusive: bool, target_pc: Option<usize>) -> Result<(), EbpfError<E>> {\n    if jit.config.enable_instruction_meter {\n        emit_validate_instruction_count(jit, exclusive, Some(jit.pc))?;\n        emit_profile_instruction_count(jit, target_pc)?;\n    }\n    Ok(())\n}\n\n#[inline]\nfn emit_undo_profile_instruction_count<E: UserDefinedError>(jit: &mut JitCompiler, target_pc: usize) -> Result<(), EbpfError<E>> {\n    if jit.config.enable_instruction_meter {\n        emit_alu(jit, OperandSize::S64, 0x81, 0, ARGUMENT_REGISTERS[0], jit.pc as i64 + 1 - target_pc as i64, None)?; // instruction_meter += (jit.pc + 1) - target_pc;\n    }\n    Ok(())\n}\n\n#[inline]\nfn emit_profile_instruction_count_finalize<E: UserDefinedError>(jit: &mut JitCompiler, store_pc_in_exception: bool) -> Result<(), EbpfError<E>> {\n    if jit.config.enable_instruction_meter || store_pc_in_exception {\n        emit_alu(jit, OperandSize::S64, 0x81, 0, R11, 1, None)?; // R11 += 1;\n    }\n    if jit.config.enable_instruction_meter {\n        emit_alu(jit, OperandSize::S64, 0x29, R11, ARGUMENT_REGISTERS[0], 0, None)?; // instruction_meter -= pc + 1;\n    }\n    if store_pc_in_exception {\n        X86Instruction::load(OperandSize::S64, RBP, R10, X86IndirectAccess::Offset(slot_on_environment_stack(jit, EnvironmentStackSlot::OptRetValPtr))).emit(jit)?;\n        X86Instruction::store_immediate(OperandSize::S64, R10, X86IndirectAccess::Offset(0), 1).emit(jit)?; // is_err = true;\n        emit_alu(jit, OperandSize::S64, 0x81, 0, R11, ebpf::ELF_INSN_DUMP_OFFSET as i64 - 1, None)?;\n        X86Instruction::store(OperandSize::S64, R11, R10, X86IndirectAccess::Offset(16)).emit(jit)?; // pc = jit.pc + ebpf::ELF_INSN_DUMP_OFFSET;\n    }\n    Ok(())\n}\n\n#[inline]\nfn emit_conditional_branch_reg<E: UserDefinedError>(jit: &mut JitCompiler, op: u8, bitwise: bool, first_operand: u8, second_operand: u8, target_pc: usize) -> Result<(), EbpfError<E>> {\n    emit_validate_and_profile_instruction_count(jit, false, Some(target_pc))?;\n    if bitwise { // Logical\n        X86Instruction::test(OperandSize::S64, first_operand, second_operand, None).emit(jit)?;\n    } else { // Arithmetic\n        X86Instruction::cmp(OperandSize::S64, first_operand, second_operand, None).emit(jit)?;\n    }\n    X86Instruction::load_immediate(OperandSize::S64, R11, target_pc as i64).emit(jit)?;\n    emit_jcc(jit, op, target_pc)?;\n    emit_undo_profile_instruction_count(jit, target_pc)\n}\n\n#[inline]\nfn emit_conditional_branch_imm<E: UserDefinedError>(jit: &mut JitCompiler, op: u8, bitwise: bool, immediate: i64, second_operand: u8, target_pc: usize) -> Result<(), EbpfError<E>> {\n    emit_validate_and_profile_instruction_count(jit, false, Some(target_pc))?;\n    if should_sanitize_constant(jit, immediate) {\n        emit_sanitized_load_immediate(jit, OperandSize::S64, R11, immediate)?;\n        if bitwise { // Logical\n            X86Instruction::test(OperandSize::S64, R11, second_operand, None).emit(jit)?;\n        } else { // Arithmetic\n            X86Instruction::cmp(OperandSize::S64, R11, second_operand, None).emit(jit)?;\n        }\n    } else if bitwise { // Logical\n        X86Instruction::test_immediate(OperandSize::S64, second_operand, immediate, None).emit(jit)?;\n    } else { // Arithmetic\n        X86Instruction::cmp_immediate(OperandSize::S64, second_operand, immediate, None).emit(jit)?;\n    }\n    X86Instruction::load_immediate(OperandSize::S64, R11, target_pc as i64).emit(jit)?;\n    emit_jcc(jit, op, target_pc)?;\n    emit_undo_profile_instruction_count(jit, target_pc)\n}\n\nenum Value {\n    Register(u8),\n    RegisterIndirect(u8, i32, bool),\n    RegisterPlusConstant32(u8, i32, bool),\n    RegisterPlusConstant64(u8, i64, bool),\n    Constant64(i64, bool),\n}\n\n#[inline]\nfn emit_bpf_call<E: UserDefinedError>(jit: &mut JitCompiler, dst: Value) -> Result<(), EbpfError<E>> {\n    // Store PC in case the bounds check fails\n    X86Instruction::load_immediate(OperandSize::S64, R11, jit.pc as i64).emit(jit)?;\n\n    emit_call(jit, TARGET_PC_BPF_CALL_PROLOGUE)?;\n\n    match dst {\n        Value::Register(reg) => {\n            // Move vm target_address into RAX\n            X86Instruction::push(REGISTER_MAP[0], None).emit(jit)?;\n            if reg != REGISTER_MAP[0] {\n                X86Instruction::mov(OperandSize::S64, reg, REGISTER_MAP[0]).emit(jit)?;\n            }\n\n            emit_call(jit, TARGET_PC_BPF_CALL_REG)?;\n\n            emit_validate_and_profile_instruction_count(jit, false, None)?;\n            X86Instruction::mov(OperandSize::S64, REGISTER_MAP[0], R11).emit(jit)?; // Save target_pc\n            X86Instruction::pop(REGISTER_MAP[0]).emit(jit)?; // Restore RAX\n            X86Instruction::call_reg(R11, None).emit(jit)?; // callq *%r11\n        },\n        Value::Constant64(target_pc, user_provided) => {\n            debug_assert!(!user_provided);\n            emit_validate_and_profile_instruction_count(jit, false, Some(target_pc as usize))?;\n            X86Instruction::load_immediate(OperandSize::S64, R11, target_pc as i64).emit(jit)?;\n            emit_call(jit, target_pc as usize)?;\n        },\n        _ => {\n            #[cfg(debug_assertions)]\n            unreachable!();\n        }\n    }\n\n    emit_undo_profile_instruction_count(jit, 0)?;\n\n    // Restore the previous frame pointer\n    X86Instruction::pop(REGISTER_MAP[FRAME_PTR_REG]).emit(jit)?;\n    let frame_ptr_access = X86IndirectAccess::Offset(slot_on_environment_stack(jit, EnvironmentStackSlot::BpfFramePtr));\n    X86Instruction::store(OperandSize::S64, REGISTER_MAP[FRAME_PTR_REG], RBP, frame_ptr_access).emit(jit)?;\n    for reg in REGISTER_MAP.iter().skip(FIRST_SCRATCH_REG).take(SCRATCH_REGS).rev() {\n        X86Instruction::pop(*reg).emit(jit)?;\n    }\n    Ok(())\n}\n\nstruct Argument {\n    index: usize,\n    value: Value,\n}\n\nimpl Argument {\n    fn is_stack_argument(&self) -> bool {\n        self.index >= ARGUMENT_REGISTERS.len()\n    }\n\n    fn get_argument_register(&self) -> u8 {\n        ARGUMENT_REGISTERS[self.index]\n    }\n\n    fn emit_pass<E: UserDefinedError>(&self, jit: &mut JitCompiler) -> Result<(), EbpfError<E>> {\n        let is_stack_argument = self.is_stack_argument();\n        let dst = if is_stack_argument {\n            R11\n        } else {\n            self.get_argument_register()\n        };\n        match self.value {\n            Value::Register(reg) => {\n                if is_stack_argument {\n                    X86Instruction::push(reg, None).emit(jit)?;\n                } else if reg != dst {\n                    X86Instruction::mov(OperandSize::S64, reg, dst).emit(jit)?;\n                }\n            },\n            Value::RegisterIndirect(reg, offset, user_provided) => {\n                debug_assert!(!user_provided);\n                if is_stack_argument {\n                    X86Instruction::push(reg, Some(X86IndirectAccess::Offset(offset))).emit(jit)?;\n                } else {\n                    X86Instruction::load(OperandSize::S64, reg, dst, X86IndirectAccess::Offset(offset)).emit(jit)?;\n                }\n            },\n            Value::RegisterPlusConstant32(reg, offset, user_provided) => {\n                debug_assert!(!user_provided);\n                if is_stack_argument {\n                    X86Instruction::push(reg, None).emit(jit)?;\n                    emit_alu(jit, OperandSize::S64, 0x81, 0, RSP, offset as i64, Some(X86IndirectAccess::OffsetIndexShift(0, RSP, 0)))?;\n                } else {\n                    X86Instruction::lea(OperandSize::S64, reg, dst, Some(X86IndirectAccess::Offset(offset))).emit(jit)?;\n                }\n            },\n            Value::RegisterPlusConstant64(reg, offset, user_provided) => {\n                debug_assert!(!user_provided);\n                if is_stack_argument {\n                    X86Instruction::push(reg, None).emit(jit)?;\n                    emit_alu(jit, OperandSize::S64, 0x81, 0, RSP, offset, Some(X86IndirectAccess::OffsetIndexShift(0, RSP, 0)))?;\n                } else {\n                    X86Instruction::load_immediate(OperandSize::S64, dst, offset).emit(jit)?;\n                    emit_alu(jit, OperandSize::S64, 0x01, reg, dst, 0, None)?;\n                }\n            },\n            Value::Constant64(value, user_provided) => {\n                debug_assert!(!user_provided && !is_stack_argument);\n                X86Instruction::load_immediate(OperandSize::S64, dst, value).emit(jit)?;\n            },\n        }\n        Ok(())\n    }\n}\n\n#[inline]\nfn emit_rust_call<E: UserDefinedError>(jit: &mut JitCompiler, dst: Value, arguments: &[Argument], result_reg: Option<u8>, check_exception: bool) -> Result<(), EbpfError<E>> {\n    let mut saved_registers = CALLER_SAVED_REGISTERS.to_vec();\n    if let Some(reg) = result_reg {\n        let dst = saved_registers.iter().position(|x| *x == reg);\n        debug_assert!(dst.is_some());\n        if let Some(dst) = dst {\n            saved_registers.remove(dst);\n        }\n    }\n\n    // Save registers on stack\n    for reg in saved_registers.iter() {\n        X86Instruction::push(*reg, None).emit(jit)?;\n    }\n\n    // Pass arguments\n    let mut stack_arguments = 0;\n    for argument in arguments {\n        if argument.is_stack_argument() {\n            stack_arguments += 1;\n        }\n        argument.emit_pass(jit)?;\n    }\n\n    match dst {\n        Value::Register(reg) => {\n            X86Instruction::call_reg(reg, None).emit(jit)?;\n        },\n        Value::Constant64(value, user_provided) => {\n            debug_assert!(!user_provided);\n            X86Instruction::load_immediate(OperandSize::S64, RAX, value).emit(jit)?;\n            X86Instruction::call_reg(RAX, None).emit(jit)?;\n        },\n        _ => {\n            #[cfg(debug_assertions)]\n            unreachable!();\n        }\n    }\n\n    // Save returned value in result register\n    if let Some(reg) = result_reg {\n        X86Instruction::mov(OperandSize::S64, RAX, reg).emit(jit)?;\n    }\n\n    // Restore registers from stack\n    emit_alu(jit, OperandSize::S64, 0x81, 0, RSP, stack_arguments * 8, None)?;\n    for reg in saved_registers.iter().rev() {\n        X86Instruction::pop(*reg).emit(jit)?;\n    }\n\n    if check_exception {\n        // Test if result indicates that an error occured\n        X86Instruction::load(OperandSize::S64, RBP, R11, X86IndirectAccess::Offset(slot_on_environment_stack(jit, EnvironmentStackSlot::OptRetValPtr))).emit(jit)?;\n        X86Instruction::cmp_immediate(OperandSize::S64, R11, 0, Some(X86IndirectAccess::Offset(0))).emit(jit)?;\n    }\n    Ok(())\n}\n\n#[inline]\nfn emit_address_translation<E: UserDefinedError>(jit: &mut JitCompiler, host_addr: u8, vm_addr: Value, len: u64, access_type: AccessType) -> Result<(), EbpfError<E>> {\n    match vm_addr {\n        Value::RegisterPlusConstant64(reg, constant, user_provided) => {\n            if user_provided && should_sanitize_constant(jit, constant) {\n                emit_sanitized_load_immediate(jit, OperandSize::S64, R11, constant)?;\n            } else {\n                X86Instruction::load_immediate(OperandSize::S64, R11, constant).emit(jit)?;\n            }\n            emit_alu(jit, OperandSize::S64, 0x01, reg, R11, 0, None)?;\n        },\n        Value::Constant64(constant, user_provided) => {\n            if user_provided && should_sanitize_constant(jit, constant) {\n                emit_sanitized_load_immediate(jit, OperandSize::S64, R11, constant)?;\n            } else {\n                X86Instruction::load_immediate(OperandSize::S64, R11, constant).emit(jit)?;\n            }\n        },\n        _ => {\n            #[cfg(debug_assertions)]\n            unreachable!();\n        },\n    }\n    emit_call(jit, TARGET_PC_TRANSLATE_MEMORY_ADDRESS + len.trailing_zeros() as usize + 4 * (access_type as usize))?;\n    X86Instruction::mov(OperandSize::S64, R11, host_addr).emit(jit)\n}\n\nfn emit_shift<E: UserDefinedError>(jit: &mut JitCompiler, size: OperandSize, opcode_extension: u8, source: u8, destination: u8, immediate: Option<i64>) -> Result<(), EbpfError<E>> {\n    if let Some(immediate) = immediate {\n        if should_sanitize_constant(jit, immediate) {\n            emit_sanitized_load_immediate(jit, OperandSize::S32, source, immediate)?;\n        } else {\n            return emit_alu(jit, size, 0xc1, opcode_extension, destination, immediate, None);\n        }\n    }\n    if size == OperandSize::S32 {\n        emit_alu(jit, OperandSize::S32, 0x81, 4, destination, -1, None)?; // Mask to 32 bit\n    }\n    if source == RCX {\n        if destination == RCX {\n            emit_alu(jit, size, 0xd3, opcode_extension, destination, 0, None)\n        } else {\n            X86Instruction::push(RCX, None).emit(jit)?;\n            emit_alu(jit, size, 0xd3, opcode_extension, destination, 0, None)?;\n            X86Instruction::pop(RCX).emit(jit)\n        }\n    } else if destination == RCX {\n        if source != R11 {\n            X86Instruction::push(source, None).emit(jit)?;\n        }\n        X86Instruction::xchg(OperandSize::S64, source, RCX, None).emit(jit)?;\n        emit_alu(jit, size, 0xd3, opcode_extension, source, 0, None)?;\n        X86Instruction::mov(OperandSize::S64, source, RCX).emit(jit)?;\n        if source != R11 {\n            X86Instruction::pop(source).emit(jit)?;\n        }\n        Ok(())\n    } else {\n        X86Instruction::push(RCX, None).emit(jit)?;\n        X86Instruction::mov(OperandSize::S64, source, RCX).emit(jit)?;\n        emit_alu(jit, size, 0xd3, opcode_extension, destination, 0, None)?;\n        X86Instruction::pop(RCX).emit(jit)\n    }\n}\n\nfn emit_muldivmod<E: UserDefinedError>(jit: &mut JitCompiler, opc: u8, src: u8, dst: u8, imm: Option<i64>) -> Result<(), EbpfError<E>> {\n    let mul = (opc & ebpf::BPF_ALU_OP_MASK) == (ebpf::MUL32_IMM & ebpf::BPF_ALU_OP_MASK);\n    let div = (opc & ebpf::BPF_ALU_OP_MASK) == (ebpf::DIV32_IMM & ebpf::BPF_ALU_OP_MASK);\n    let sdiv = (opc & ebpf::BPF_ALU_OP_MASK) == (ebpf::SDIV32_IMM & ebpf::BPF_ALU_OP_MASK);\n    let modrm = (opc & ebpf::BPF_ALU_OP_MASK) == (ebpf::MOD32_IMM & ebpf::BPF_ALU_OP_MASK);\n    let size = if (opc & ebpf::BPF_CLS_MASK) == ebpf::BPF_ALU64 { OperandSize::S64 } else { OperandSize::S32 };\n\n    // subtracting offset_in_text_section from TARGET_PC_LOCAL_ANCHOR gives us a\n    // unique local anchor\n    let sdiv_anchor =  if sdiv { TARGET_PC_LOCAL_ANCHOR - jit.offset_in_text_section } else { 0 };\n\n    if (div || sdiv || modrm) && imm.is_none() {\n        // Save pc\n        X86Instruction::load_immediate(OperandSize::S64, R11, jit.pc as i64).emit(jit)?;\n        X86Instruction::test(size, src, src, None).emit(jit)?; // src == 0\n        emit_jcc(jit, 0x84, TARGET_PC_DIV_BY_ZERO)?;\n\n    }\n\n    // sdiv overflows with MIN / -1. If we have an immediate and it's not -1, we\n    // don't need any checks.\n    if sdiv && imm.unwrap_or(-1) == -1 {\n        if imm.is_none() {\n            // if src != -1, we can skip checking dst\n            X86Instruction::cmp_immediate(size, src, -1, None).emit(jit)?;\n            emit_jcc(jit, 0x85, sdiv_anchor)?;\n        }\n\n        // if dst != MIN, we're not going to overflow\n        X86Instruction::load_immediate(size, R11, if size == OperandSize::S64 { i64::MIN } else { i32::MIN as i64 }).emit(jit)?;\n        X86Instruction::cmp(size, dst, R11, None).emit(jit)?;\n        emit_jcc(jit, 0x85, sdiv_anchor)?;\n\n        // MIN / -1, raise EbpfError::DivideOverflow(pc)\n        X86Instruction::load_immediate(OperandSize::S64, R11, jit.pc as i64).emit(jit)?;\n        emit_jmp(jit, TARGET_PC_DIV_OVERFLOW)?;\n    }\n\n    if sdiv {\n        set_anchor(jit, sdiv_anchor);\n    }\n\n    if dst != RAX {\n        X86Instruction::push(RAX, None).emit(jit)?;\n    }\n    if dst != RDX {\n        X86Instruction::push(RDX, None).emit(jit)?;\n    }\n\n    if let Some(imm) = imm {\n        if should_sanitize_constant(jit, imm) {\n            emit_sanitized_load_immediate(jit, OperandSize::S64, R11, imm)?;\n        } else {\n            X86Instruction::load_immediate(OperandSize::S64, R11, imm).emit(jit)?;\n        }\n    } else {\n        X86Instruction::mov(OperandSize::S64, src, R11).emit(jit)?;\n    }\n\n    if dst != RAX {\n        X86Instruction::mov(OperandSize::S64, dst, RAX).emit(jit)?;\n    }\n\n    if div || modrm {\n        // xor %edx,%edx\n        emit_alu(jit, size, 0x31, RDX, RDX, 0, None)?;\n    } else if sdiv {\n        // cdq or cqo depending on operand size\n        X86Instruction {\n            size,\n            opcode: 0x99,\n            modrm: false,\n            ..X86Instruction::default()\n        }.emit(jit)?;\n    }\n\n    emit_alu(jit, size, 0xf7, if mul { 4 } else if sdiv { 7 } else { 6 }, R11, 0, None)?;\n\n    if dst != RDX {\n        if modrm {\n            X86Instruction::mov(OperandSize::S64, RDX, dst).emit(jit)?;\n        }\n        X86Instruction::pop(RDX).emit(jit)?;\n    }\n    if dst != RAX {\n        if div || sdiv || mul {\n            X86Instruction::mov(OperandSize::S64, RAX, dst).emit(jit)?;\n        }\n        X86Instruction::pop(RAX).emit(jit)?;\n    }\n\n    if size == OperandSize::S32 && (mul || sdiv)  {\n        X86Instruction::sign_extend_i32_to_i64(dst, dst).emit(jit)?;\n    }\n    Ok(())\n}\n\n#[inline]\nfn emit_set_exception_kind<E: UserDefinedError>(jit: &mut JitCompiler, err: EbpfError<E>) -> Result<(), EbpfError<E>> {\n    let err = Result::<u64, EbpfError<E>>::Err(err);\n    let err_kind = unsafe { *(&err as *const _ as *const u64).offset(1) };\n    X86Instruction::load(OperandSize::S64, RBP, R10, X86IndirectAccess::Offset(slot_on_environment_stack(jit, EnvironmentStackSlot::OptRetValPtr))).emit(jit)?;\n    X86Instruction::store_immediate(OperandSize::S64, R10, X86IndirectAccess::Offset(8), err_kind as i64).emit(jit)\n}\n\n#[derive(Debug)]\nstruct Jump {\n    location: usize,\n    target_pc: usize,\n}\nimpl Jump {\n    fn get_target_offset(&self, jit: &JitCompiler) -> u64 {\n        match jit.handler_anchors.get(&self.target_pc) {\n            Some(target) => *target as u64,\n            None         => jit.result.pc_section[self.target_pc]\n        }\n    }\n}\n\npub struct JitCompiler {\n    result: JitProgramSections,\n    pc_section_jumps: Vec<Jump>,\n    text_section_jumps: Vec<Jump>,\n    offset_in_text_section: usize,\n    pc: usize,\n    last_instruction_meter_validation_pc: usize,\n    program_vm_addr: u64,\n    handler_anchors: HashMap<usize, usize>,\n    config: Config,\n    diversification_rng: SmallRng,\n    stopwatch_is_active: bool,\n    environment_stack_key: i32,\n    program_argument_key: i32,\n}\n\nimpl Index<usize> for JitCompiler {\n    type Output = u8;\n\n    fn index(&self, _index: usize) -> &u8 {\n        &self.result.text_section[_index]\n    }\n}\n\nimpl IndexMut<usize> for JitCompiler {\n    fn index_mut(&mut self, _index: usize) -> &mut u8 {\n        &mut self.result.text_section[_index]\n    }\n}\n\nimpl std::fmt::Debug for JitCompiler {\n    fn fmt(&self, fmt: &mut Formatter) -> Result<(), FormatterError> {\n        fmt.write_str(\"JIT text_section: [\")?;\n        for i in self.result.text_section as &[u8] {\n            fmt.write_fmt(format_args!(\" {:#04x},\", i))?;\n        };\n        fmt.write_str(\" ] | \")?;\n        fmt.debug_struct(\"JIT state\")\n            .field(\"memory\", &self.result.pc_section.as_ptr())\n            .field(\"pc\", &self.pc)\n            .field(\"offset_in_text_section\", &self.offset_in_text_section)\n            .field(\"pc_section\", &self.result.pc_section)\n            .field(\"handler_anchors\", &self.handler_anchors)\n            .field(\"pc_section_jumps\", &self.pc_section_jumps)\n            .field(\"text_section_jumps\", &self.text_section_jumps)\n            .finish()\n    }\n}\n\nimpl JitCompiler {\n    // Arguments are unused on windows\n    fn new<E: UserDefinedError>(program: &[u8], config: &Config) -> Result<Self, EbpfError<E>> {\n        #[cfg(target_os = \"windows\")]\n        {\n            let _ = program;\n            let _ = config;\n            panic!(\"JIT not supported on windows\");\n        }\n\n        #[cfg(not(target_arch = \"x86_64\"))]\n        {\n            let _ = program;\n            let _ = config;\n            panic!(\"JIT is only supported on x86_64\");\n        }\n\n        // Scan through program to find actual number of instructions\n        let mut pc = 0;\n        while (pc + 1) * ebpf::INSN_SIZE <= program.len() {\n            let insn = ebpf::get_insn_unchecked(program, pc);\n            pc += match insn.opc {\n                ebpf::LD_DW_IMM => 2,\n                _ => 1,\n            };\n        }\n\n        let mut code_length_estimate = MAX_EMPTY_PROGRAM_MACHINE_CODE_LENGTH + MAX_MACHINE_CODE_LENGTH_PER_INSTRUCTION * pc;\n        code_length_estimate += (code_length_estimate as f64 * config.noop_instruction_ratio) as usize;\n        let mut diversification_rng = SmallRng::from_rng(rand::thread_rng()).unwrap();\n        let (environment_stack_key, program_argument_key) =\n            if config.encrypt_environment_registers {\n                (\n                    diversification_rng.gen::<i32>() / 16, // -3 bits for 8 Byte alignment, and -1 bit to have encoding space for EnvironmentStackSlot::SlotCount\n                    diversification_rng.gen::<i32>() / 2, // -1 bit to have encoding space for (SYSCALL_CONTEXT_OBJECTS_OFFSET + syscall.context_object_slot) * 8\n                )\n            } else { (0, 0) };\n\n        Ok(Self {\n            result: JitProgramSections::new(pc + 1, code_length_estimate)?,\n            pc_section_jumps: vec![],\n            text_section_jumps: vec![],\n            offset_in_text_section: 0,\n            pc: 0,\n            last_instruction_meter_validation_pc: 0,\n            program_vm_addr: 0,\n            handler_anchors: HashMap::new(),\n            config: *config,\n            diversification_rng,\n            stopwatch_is_active: false,\n            environment_stack_key,\n            program_argument_key,\n        })\n    }\n\n    fn compile<E: UserDefinedError, I: InstructionMeter>(&mut self,\n            executable: &Pin<Box<Executable<E, I>>>) -> Result<(), EbpfError<E>> {\n        let (program_vm_addr, program) = executable.get_text_bytes();\n        self.program_vm_addr = program_vm_addr;\n\n        self.generate_prologue::<E, I>()?;\n\n        // Jump to entry point\n        let entry = executable.get_entrypoint_instruction_offset().unwrap_or(0);\n        if self.config.enable_instruction_meter {\n            emit_profile_instruction_count(self, Some(entry + 1))?;\n        }\n        X86Instruction::load_immediate(OperandSize::S64, R11, entry as i64).emit(self)?;\n        emit_jmp(self, entry)?;\n\n        // Have these in front so that the linear search of TARGET_PC_TRANSLATE_PC does not terminate early\n        self.generate_helper_routines::<E, I>()?;\n        self.generate_exception_handlers::<E>()?;\n\n        while self.pc * ebpf::INSN_SIZE < program.len() {\n            let mut insn = ebpf::get_insn_unchecked(program, self.pc);\n\n            self.result.pc_section[self.pc] = self.offset_in_text_section as u64;\n\n            // Regular instruction meter checkpoints to prevent long linear runs from exceeding their budget\n            if self.last_instruction_meter_validation_pc + self.config.instruction_meter_checkpoint_distance <= self.pc {\n                emit_validate_instruction_count(self, true, Some(self.pc))?;\n            }\n\n            if self.config.enable_instruction_tracing {\n                X86Instruction::load_immediate(OperandSize::S64, R11, self.pc as i64).emit(self)?;\n                emit_call(self, TARGET_PC_TRACE)?;\n                X86Instruction::load_immediate(OperandSize::S64, R11, 0).emit(self)?;\n            }\n\n            let dst = if insn.dst == STACK_PTR_REG as u8 { u8::MAX } else { REGISTER_MAP[insn.dst as usize] };\n            let src = REGISTER_MAP[insn.src as usize];\n            let target_pc = (self.pc as isize + insn.off as isize + 1) as usize;\n\n            match insn.opc {\n                _ if insn.dst == STACK_PTR_REG as u8 && self.config.dynamic_stack_frames => {\n                    let stack_ptr_access = X86IndirectAccess::Offset(slot_on_environment_stack(self, EnvironmentStackSlot::BpfStackPtr));\n                    match insn.opc {\n                        ebpf::SUB64_IMM => emit_alu(self, OperandSize::S64, 0x81, 5, RBP, insn.imm, Some(stack_ptr_access))?,\n                        ebpf::ADD64_IMM => emit_alu(self, OperandSize::S64, 0x81, 0, RBP, insn.imm, Some(stack_ptr_access))?,\n                        _ => {\n                            #[cfg(debug_assertions)]\n                            unreachable!(\"unexpected insn on r11\")\n                        }\n                    }\n                }\n                // BPF_LD class\n                ebpf::LD_ABS_B   => {\n                    emit_address_translation(self, R11, Value::Constant64(ebpf::MM_INPUT_START.wrapping_add(insn.imm as u32 as u64) as i64, true), 1, AccessType::Load)?;\n                    X86Instruction::load(OperandSize::S8, R11, RAX, X86IndirectAccess::Offset(0)).emit(self)?;\n                },\n                ebpf::LD_ABS_H   => {\n                    emit_address_translation(self, R11, Value::Constant64(ebpf::MM_INPUT_START.wrapping_add(insn.imm as u32 as u64) as i64, true), 2, AccessType::Load)?;\n                    X86Instruction::load(OperandSize::S16, R11, RAX, X86IndirectAccess::Offset(0)).emit(self)?;\n                },\n                ebpf::LD_ABS_W   => {\n                    emit_address_translation(self, R11, Value::Constant64(ebpf::MM_INPUT_START.wrapping_add(insn.imm as u32 as u64) as i64, true), 4, AccessType::Load)?;\n                    X86Instruction::load(OperandSize::S32, R11, RAX, X86IndirectAccess::Offset(0)).emit(self)?;\n                },\n                ebpf::LD_ABS_DW  => {\n                    emit_address_translation(self, R11, Value::Constant64(ebpf::MM_INPUT_START.wrapping_add(insn.imm as u32 as u64) as i64, true), 8, AccessType::Load)?;\n                    X86Instruction::load(OperandSize::S64, R11, RAX, X86IndirectAccess::Offset(0)).emit(self)?;\n                },\n                ebpf::LD_IND_B   => {\n                    emit_address_translation(self, R11, Value::RegisterPlusConstant64(src, ebpf::MM_INPUT_START.wrapping_add(insn.imm as u32 as u64) as i64, true), 1, AccessType::Load)?;\n                    X86Instruction::load(OperandSize::S8, R11, RAX, X86IndirectAccess::Offset(0)).emit(self)?;\n                },\n                ebpf::LD_IND_H   => {\n                    emit_address_translation(self, R11, Value::RegisterPlusConstant64(src, ebpf::MM_INPUT_START.wrapping_add(insn.imm as u32 as u64) as i64, true), 2, AccessType::Load)?;\n                    X86Instruction::load(OperandSize::S16, R11, RAX, X86IndirectAccess::Offset(0)).emit(self)?;\n                },\n                ebpf::LD_IND_W   => {\n                    emit_address_translation(self, R11, Value::RegisterPlusConstant64(src, ebpf::MM_INPUT_START.wrapping_add(insn.imm as u32 as u64) as i64, true), 4, AccessType::Load)?;\n                    X86Instruction::load(OperandSize::S32, R11, RAX, X86IndirectAccess::Offset(0)).emit(self)?;\n                },\n                ebpf::LD_IND_DW  => {\n                    emit_address_translation(self, R11, Value::RegisterPlusConstant64(src, ebpf::MM_INPUT_START.wrapping_add(insn.imm as u32 as u64) as i64, true), 8, AccessType::Load)?;\n                    X86Instruction::load(OperandSize::S64, R11, RAX, X86IndirectAccess::Offset(0)).emit(self)?;\n                },\n\n                ebpf::LD_DW_IMM  => {\n                    emit_validate_and_profile_instruction_count(self, true, Some(self.pc + 2))?;\n                    self.pc += 1;\n                    self.pc_section_jumps.push(Jump { location: self.pc, target_pc: TARGET_PC_CALL_UNSUPPORTED_INSTRUCTION });\n                    ebpf::augment_lddw_unchecked(program, &mut insn);\n                    if should_sanitize_constant(self, insn.imm) {\n                        emit_sanitized_load_immediate(self, OperandSize::S64, dst, insn.imm)?;\n                    } else {\n                        X86Instruction::load_immediate(OperandSize::S64, dst, insn.imm).emit(self)?;\n                    }\n                },\n\n                // BPF_LDX class\n                ebpf::LD_B_REG   => {\n                    emit_address_translation(self, R11, Value::RegisterPlusConstant64(src, insn.off as i64, true), 1, AccessType::Load)?;\n                    X86Instruction::load(OperandSize::S8, R11, dst, X86IndirectAccess::Offset(0)).emit(self)?;\n                },\n                ebpf::LD_H_REG   => {\n                    emit_address_translation(self, R11, Value::RegisterPlusConstant64(src, insn.off as i64, true), 2, AccessType::Load)?;\n                    X86Instruction::load(OperandSize::S16, R11, dst, X86IndirectAccess::Offset(0)).emit(self)?;\n                },\n                ebpf::LD_W_REG   => {\n                    emit_address_translation(self, R11, Value::RegisterPlusConstant64(src, insn.off as i64, true), 4, AccessType::Load)?;\n                    X86Instruction::load(OperandSize::S32, R11, dst, X86IndirectAccess::Offset(0)).emit(self)?;\n                },\n                ebpf::LD_DW_REG  => {\n                    emit_address_translation(self, R11, Value::RegisterPlusConstant64(src, insn.off as i64, true), 8, AccessType::Load)?;\n                    X86Instruction::load(OperandSize::S64, R11, dst, X86IndirectAccess::Offset(0)).emit(self)?;\n                },\n\n                // BPF_ST class\n                ebpf::ST_B_IMM   => {\n                    emit_address_translation(self, R11, Value::RegisterPlusConstant64(dst, insn.off as i64, true), 1, AccessType::Store)?;\n                    X86Instruction::store_immediate(OperandSize::S8, R11, X86IndirectAccess::Offset(0), insn.imm as i64).emit(self)?;\n                },\n                ebpf::ST_H_IMM   => {\n                    emit_address_translation(self, R11, Value::RegisterPlusConstant64(dst, insn.off as i64, true), 2, AccessType::Store)?;\n                    X86Instruction::store_immediate(OperandSize::S16, R11, X86IndirectAccess::Offset(0), insn.imm as i64).emit(self)?;\n                },\n                ebpf::ST_W_IMM   => {\n                    emit_address_translation(self, R11, Value::RegisterPlusConstant64(dst, insn.off as i64, true), 4, AccessType::Store)?;\n                    X86Instruction::store_immediate(OperandSize::S32, R11, X86IndirectAccess::Offset(0), insn.imm as i64).emit(self)?;\n                },\n                ebpf::ST_DW_IMM  => {\n                    emit_address_translation(self, R11, Value::RegisterPlusConstant64(dst, insn.off as i64, true), 8, AccessType::Store)?;\n                    X86Instruction::store_immediate(OperandSize::S64, R11, X86IndirectAccess::Offset(0), insn.imm as i64).emit(self)?;\n                },\n\n                // BPF_STX class\n                ebpf::ST_B_REG  => {\n                    emit_address_translation(self, R11, Value::RegisterPlusConstant64(dst, insn.off as i64, true), 1, AccessType::Store)?;\n                    X86Instruction::store(OperandSize::S8, src, R11, X86IndirectAccess::Offset(0)).emit(self)?;\n                },\n                ebpf::ST_H_REG  => {\n                    emit_address_translation(self, R11, Value::RegisterPlusConstant64(dst, insn.off as i64, true), 2, AccessType::Store)?;\n                    X86Instruction::store(OperandSize::S16, src, R11, X86IndirectAccess::Offset(0)).emit(self)?;\n                },\n                ebpf::ST_W_REG  => {\n                    emit_address_translation(self, R11, Value::RegisterPlusConstant64(dst, insn.off as i64, true), 4, AccessType::Store)?;\n                    X86Instruction::store(OperandSize::S32, src, R11, X86IndirectAccess::Offset(0)).emit(self)?;\n                },\n                ebpf::ST_DW_REG  => {\n                    emit_address_translation(self, R11, Value::RegisterPlusConstant64(dst, insn.off as i64, true), 8, AccessType::Store)?;\n                    X86Instruction::store(OperandSize::S64, src, R11, X86IndirectAccess::Offset(0)).emit(self)?;\n                },\n\n                // BPF_ALU class\n                ebpf::ADD32_IMM  => {\n                    emit_sanitized_alu(self, OperandSize::S32, 0x01, 0, dst, insn.imm)?;\n                    X86Instruction::sign_extend_i32_to_i64(dst, dst).emit(self)?;\n                },\n                ebpf::ADD32_REG  => {\n                    emit_alu(self, OperandSize::S32, 0x01, src, dst, 0, None)?;\n                    X86Instruction::sign_extend_i32_to_i64(dst, dst).emit(self)?;\n                },\n                ebpf::SUB32_IMM  => {\n                    emit_sanitized_alu(self, OperandSize::S32, 0x29, 5, dst, insn.imm)?;\n                    X86Instruction::sign_extend_i32_to_i64(dst, dst).emit(self)?;\n                },\n                ebpf::SUB32_REG  => {\n                    emit_alu(self, OperandSize::S32, 0x29, src, dst, 0, None)?;\n                    X86Instruction::sign_extend_i32_to_i64(dst, dst).emit(self)?;\n                },\n                ebpf::MUL32_IMM | ebpf::DIV32_IMM | ebpf::SDIV32_IMM | ebpf::MOD32_IMM  =>\n                    emit_muldivmod(self, insn.opc, dst, dst, Some(insn.imm))?,\n                ebpf::MUL32_REG | ebpf::DIV32_REG | ebpf::SDIV32_REG | ebpf::MOD32_REG  =>\n                    emit_muldivmod(self, insn.opc, src, dst, None)?,\n                ebpf::OR32_IMM   => emit_sanitized_alu(self, OperandSize::S32, 0x09, 1, dst, insn.imm)?,\n                ebpf::OR32_REG   => emit_alu(self, OperandSize::S32, 0x09, src, dst, 0, None)?,\n                ebpf::AND32_IMM  => emit_sanitized_alu(self, OperandSize::S32, 0x21, 4, dst, insn.imm)?,\n                ebpf::AND32_REG  => emit_alu(self, OperandSize::S32, 0x21, src, dst, 0, None)?,\n                ebpf::LSH32_IMM  => emit_shift(self, OperandSize::S32, 4, R11, dst, Some(insn.imm))?,\n                ebpf::LSH32_REG  => emit_shift(self, OperandSize::S32, 4, src, dst, None)?,\n                ebpf::RSH32_IMM  => emit_shift(self, OperandSize::S32, 5, R11, dst, Some(insn.imm))?,\n                ebpf::RSH32_REG  => emit_shift(self, OperandSize::S32, 5, src, dst, None)?,\n                ebpf::NEG32      => emit_alu(self, OperandSize::S32, 0xf7, 3, dst, 0, None)?,\n                ebpf::XOR32_IMM  => emit_sanitized_alu(self, OperandSize::S32, 0x31, 6, dst, insn.imm)?,\n                ebpf::XOR32_REG  => emit_alu(self, OperandSize::S32, 0x31, src, dst, 0, None)?,\n                ebpf::MOV32_IMM  => {\n                    if should_sanitize_constant(self, insn.imm) {\n                        emit_sanitized_load_immediate(self, OperandSize::S32, dst, insn.imm)?;\n                    } else {\n                        X86Instruction::load_immediate(OperandSize::S32, dst, insn.imm).emit(self)?;\n                    }\n                }\n                ebpf::MOV32_REG  => X86Instruction::mov(OperandSize::S32, src, dst).emit(self)?,\n                ebpf::ARSH32_IMM => emit_shift(self, OperandSize::S32, 7, R11, dst, Some(insn.imm))?,\n                ebpf::ARSH32_REG => emit_shift(self, OperandSize::S32, 7, src, dst, None)?,\n                ebpf::LE         => {\n                    match insn.imm {\n                        16 => {\n                            emit_alu(self, OperandSize::S32, 0x81, 4, dst, 0xffff, None)?; // Mask to 16 bit\n                        }\n                        32 => {\n                            emit_alu(self, OperandSize::S32, 0x81, 4, dst, -1, None)?; // Mask to 32 bit\n                        }\n                        64 => {}\n                        _ => {\n                            return Err(EbpfError::InvalidInstruction(self.pc + ebpf::ELF_INSN_DUMP_OFFSET));\n                        }\n                    }\n                },\n                ebpf::BE         => {\n                    match insn.imm {\n                        16 => {\n                            X86Instruction::bswap(OperandSize::S16, dst).emit(self)?;\n                            emit_alu(self, OperandSize::S32, 0x81, 4, dst, 0xffff, None)?; // Mask to 16 bit\n                        }\n                        32 => X86Instruction::bswap(OperandSize::S32, dst).emit(self)?,\n                        64 => X86Instruction::bswap(OperandSize::S64, dst).emit(self)?,\n                        _ => {\n                            return Err(EbpfError::InvalidInstruction(self.pc + ebpf::ELF_INSN_DUMP_OFFSET));\n                        }\n                    }\n                },\n\n                // BPF_ALU64 class\n                ebpf::ADD64_IMM  => emit_sanitized_alu(self, OperandSize::S64, 0x01, 0, dst, insn.imm)?,\n                ebpf::ADD64_REG  => emit_alu(self, OperandSize::S64, 0x01, src, dst, 0, None)?,\n                ebpf::SUB64_IMM  => emit_sanitized_alu(self, OperandSize::S64, 0x29, 5, dst, insn.imm)?,\n                ebpf::SUB64_REG  => emit_alu(self, OperandSize::S64, 0x29, src, dst, 0, None)?,\n                ebpf::MUL64_IMM | ebpf::DIV64_IMM | ebpf::SDIV64_IMM | ebpf::MOD64_IMM  =>\n                    emit_muldivmod(self, insn.opc, dst, dst, Some(insn.imm))?,\n                ebpf::MUL64_REG | ebpf::DIV64_REG | ebpf::SDIV64_REG | ebpf::MOD64_REG  =>\n                    emit_muldivmod(self, insn.opc, src, dst, None)?,\n                ebpf::OR64_IMM   => emit_sanitized_alu(self, OperandSize::S64, 0x09, 1, dst, insn.imm)?,\n                ebpf::OR64_REG   => emit_alu(self, OperandSize::S64, 0x09, src, dst, 0, None)?,\n                ebpf::AND64_IMM  => emit_sanitized_alu(self, OperandSize::S64, 0x21, 4, dst, insn.imm)?,\n                ebpf::AND64_REG  => emit_alu(self, OperandSize::S64, 0x21, src, dst, 0, None)?,\n                ebpf::LSH64_IMM  => emit_shift(self, OperandSize::S64, 4, R11, dst, Some(insn.imm))?,\n                ebpf::LSH64_REG  => emit_shift(self, OperandSize::S64, 4, src, dst, None)?,\n                ebpf::RSH64_IMM  => emit_shift(self, OperandSize::S64, 5, R11, dst, Some(insn.imm))?,\n                ebpf::RSH64_REG  => emit_shift(self, OperandSize::S64, 5, src, dst, None)?,\n                ebpf::NEG64      => emit_alu(self, OperandSize::S64, 0xf7, 3, dst, 0, None)?,\n                ebpf::XOR64_IMM  => emit_sanitized_alu(self, OperandSize::S64, 0x31, 6, dst, insn.imm)?,\n                ebpf::XOR64_REG  => emit_alu(self, OperandSize::S64, 0x31, src, dst, 0, None)?,\n                ebpf::MOV64_IMM  => {\n                    if should_sanitize_constant(self, insn.imm) {\n                        emit_sanitized_load_immediate(self, OperandSize::S64, dst, insn.imm)?;\n                    } else {\n                        X86Instruction::load_immediate(OperandSize::S64, dst, insn.imm).emit(self)?;\n                    }\n                }\n                ebpf::MOV64_REG  => X86Instruction::mov(OperandSize::S64, src, dst).emit(self)?,\n                ebpf::ARSH64_IMM => emit_shift(self, OperandSize::S64, 7, R11, dst, Some(insn.imm))?,\n                ebpf::ARSH64_REG => emit_shift(self, OperandSize::S64, 7, src, dst, None)?,\n\n                // BPF_JMP class\n                ebpf::JA         => {\n                    emit_validate_and_profile_instruction_count(self, false, Some(target_pc))?;\n                    X86Instruction::load_immediate(OperandSize::S64, R11, target_pc as i64).emit(self)?;\n                    emit_jmp(self, target_pc)?;\n                },\n                ebpf::JEQ_IMM    => emit_conditional_branch_imm(self, 0x84, false, insn.imm, dst, target_pc)?,\n                ebpf::JEQ_REG    => emit_conditional_branch_reg(self, 0x84, false, src, dst, target_pc)?,\n                ebpf::JGT_IMM    => emit_conditional_branch_imm(self, 0x87, false, insn.imm, dst, target_pc)?,\n                ebpf::JGT_REG    => emit_conditional_branch_reg(self, 0x87, false, src, dst, target_pc)?,\n                ebpf::JGE_IMM    => emit_conditional_branch_imm(self, 0x83, false, insn.imm, dst, target_pc)?,\n                ebpf::JGE_REG    => emit_conditional_branch_reg(self, 0x83, false, src, dst, target_pc)?,\n                ebpf::JLT_IMM    => emit_conditional_branch_imm(self, 0x82, false, insn.imm, dst, target_pc)?,\n                ebpf::JLT_REG    => emit_conditional_branch_reg(self, 0x82, false, src, dst, target_pc)?,\n                ebpf::JLE_IMM    => emit_conditional_branch_imm(self, 0x86, false, insn.imm, dst, target_pc)?,\n                ebpf::JLE_REG    => emit_conditional_branch_reg(self, 0x86, false, src, dst, target_pc)?,\n                ebpf::JSET_IMM   => emit_conditional_branch_imm(self, 0x85, true, insn.imm, dst, target_pc)?,\n                ebpf::JSET_REG   => emit_conditional_branch_reg(self, 0x85, true, src, dst, target_pc)?,\n                ebpf::JNE_IMM    => emit_conditional_branch_imm(self, 0x85, false, insn.imm, dst, target_pc)?,\n                ebpf::JNE_REG    => emit_conditional_branch_reg(self, 0x85, false, src, dst, target_pc)?,\n                ebpf::JSGT_IMM   => emit_conditional_branch_imm(self, 0x8f, false, insn.imm, dst, target_pc)?,\n                ebpf::JSGT_REG   => emit_conditional_branch_reg(self, 0x8f, false, src, dst, target_pc)?,\n                ebpf::JSGE_IMM   => emit_conditional_branch_imm(self, 0x8d, false, insn.imm, dst, target_pc)?,\n                ebpf::JSGE_REG   => emit_conditional_branch_reg(self, 0x8d, false, src, dst, target_pc)?,\n                ebpf::JSLT_IMM   => emit_conditional_branch_imm(self, 0x8c, false, insn.imm, dst, target_pc)?,\n                ebpf::JSLT_REG   => emit_conditional_branch_reg(self, 0x8c, false, src, dst, target_pc)?,\n                ebpf::JSLE_IMM   => emit_conditional_branch_imm(self, 0x8e, false, insn.imm, dst, target_pc)?,\n                ebpf::JSLE_REG   => emit_conditional_branch_reg(self, 0x8e, false, src, dst, target_pc)?,\n                ebpf::CALL_IMM   => {\n                    // For JIT, syscalls MUST be registered at compile time. They can be\n                    // updated later, but not created after compiling (we need the address of the\n                    // syscall function in the JIT-compiled program).\n\n                    let mut resolved = false;\n                    let (syscalls, calls) = if self.config.static_syscalls {\n                        (insn.src == 0, insn.src != 0)\n                    } else {\n                        (true, true)\n                    };\n\n                    if syscalls {\n                        if let Some(syscall) = executable.get_syscall_registry().lookup_syscall(insn.imm as u32) {\n                            if self.config.enable_instruction_meter {\n                                emit_validate_and_profile_instruction_count(self, true, Some(0))?;\n                            }\n                            X86Instruction::load_immediate(OperandSize::S64, R11, syscall.function as *const u8 as i64).emit(self)?;\n                            X86Instruction::load(OperandSize::S64, R10, RAX, X86IndirectAccess::Offset((SYSCALL_CONTEXT_OBJECTS_OFFSET + syscall.context_object_slot) as i32 * 8 + self.program_argument_key)).emit(self)?;\n                            emit_call(self, TARGET_PC_SYSCALL)?;\n                            if self.config.enable_instruction_meter {\n                                emit_undo_profile_instruction_count(self, 0)?;\n                            }\n                            // Throw error if the result indicates one\n                            X86Instruction::cmp_immediate(OperandSize::S64, R11, 0, Some(X86IndirectAccess::Offset(0))).emit(self)?;\n                            X86Instruction::load_immediate(OperandSize::S64, R11, self.pc as i64).emit(self)?;\n                            emit_jcc(self, 0x85, TARGET_PC_RUST_EXCEPTION)?;\n\n                            resolved = true;\n                        }\n                    }\n\n                    if calls {\n                        if let Some(target_pc) = executable.lookup_bpf_function(insn.imm as u32) {\n                            emit_bpf_call(self, Value::Constant64(target_pc as i64, false))?;\n                            resolved = true;\n                        }\n                    }\n\n                    if !resolved {\n                        if self.config.disable_unresolved_symbols_at_runtime {\n                            X86Instruction::load_immediate(OperandSize::S64, R11, self.pc as i64).emit(self)?;\n                            emit_jmp(self, TARGET_PC_CALL_UNSUPPORTED_INSTRUCTION)?;\n                        } else {\n                            emit_validate_instruction_count(self, true, Some(self.pc))?;\n                            // executable.report_unresolved_symbol(self.pc)?;\n                            // Workaround for unresolved symbols in ELF: Report error at runtime instead of compiletime\n                            emit_rust_call(self, Value::Constant64(Executable::<E, I>::report_unresolved_symbol as *const u8 as i64, false), &[\n                                Argument { index: 2, value: Value::Constant64(self.pc as i64, false) },\n                                Argument { index: 1, value: Value::Constant64(&*executable.as_ref() as *const _ as i64, false) },\n                                Argument { index: 0, value: Value::RegisterIndirect(RBP, slot_on_environment_stack(self, EnvironmentStackSlot::OptRetValPtr), false) },\n                            ], None, true)?;\n                            X86Instruction::load_immediate(OperandSize::S64, R11, self.pc as i64).emit(self)?;\n                            emit_jmp(self, TARGET_PC_RUST_EXCEPTION)?;\n                        }\n                    }\n                },\n                ebpf::CALL_REG  => {\n                    emit_bpf_call(self, Value::Register(REGISTER_MAP[insn.imm as usize]))?;\n                },\n                ebpf::EXIT      => {\n                    let call_depth_access = X86IndirectAccess::Offset(slot_on_environment_stack(self, EnvironmentStackSlot::CallDepth));\n                    X86Instruction::load(OperandSize::S64, RBP, REGISTER_MAP[FRAME_PTR_REG], call_depth_access).emit(self)?;\n\n                    // If CallDepth == 0, we've reached the exit instruction of the entry point\n                    X86Instruction::cmp_immediate(OperandSize::S32, REGISTER_MAP[FRAME_PTR_REG], 0, None).emit(self)?;\n                    if self.config.enable_instruction_meter {\n                        X86Instruction::load_immediate(OperandSize::S64, R11, self.pc as i64).emit(self)?;\n                    }\n                    // we're done\n                    emit_jcc(self, 0x84, TARGET_PC_EXIT)?;\n\n                    // else decrement and update CallDepth\n                    emit_alu(self, OperandSize::S64, 0x81, 5, REGISTER_MAP[FRAME_PTR_REG], 1, None)?;\n                    X86Instruction::store(OperandSize::S64, REGISTER_MAP[FRAME_PTR_REG], RBP, call_depth_access).emit(self)?;\n\n                    // and return\n                    emit_validate_and_profile_instruction_count(self, false, Some(0))?;\n                    X86Instruction::return_near().emit(self)?;\n                },\n\n                _               => return Err(EbpfError::UnsupportedInstruction(self.pc + ebpf::ELF_INSN_DUMP_OFFSET)),\n            }\n\n            self.pc += 1;\n        }\n        self.result.pc_section[self.pc] = self.offset_in_text_section as u64; // Bumper so that the linear search of TARGET_PC_TRANSLATE_PC can not run off\n\n        // Bumper in case there was no final exit\n        emit_validate_and_profile_instruction_count(self, true, Some(self.pc + 2))?;\n        X86Instruction::load_immediate(OperandSize::S64, R11, self.pc as i64).emit(self)?;\n        emit_set_exception_kind::<E>(self, EbpfError::ExecutionOverrun(0))?;\n        emit_jmp(self, TARGET_PC_EXCEPTION_AT)?;\n\n        self.generate_epilogue::<E>()?;\n        self.resolve_jumps();\n        self.result.seal(self.offset_in_text_section)?;\n\n        // Delete secrets\n        self.environment_stack_key = 0;\n        self.program_argument_key = 0;\n\n        Ok(())\n    }\n\n    fn generate_helper_routines<E: UserDefinedError, I: InstructionMeter>(&mut self) -> Result<(), EbpfError<E>> {\n        // Routine for instruction tracing\n        if self.config.enable_instruction_tracing {\n            set_anchor(self, TARGET_PC_TRACE);\n            // Save registers on stack\n            X86Instruction::push(R11, None).emit(self)?;\n            for reg in REGISTER_MAP.iter().rev() {\n                X86Instruction::push(*reg, None).emit(self)?;\n            }\n            X86Instruction::mov(OperandSize::S64, RSP, REGISTER_MAP[0]).emit(self)?;\n            emit_alu(self, OperandSize::S64, 0x81, 0, RSP, - 8 * 3, None)?; // RSP -= 8 * 3;\n            emit_rust_call(self, Value::Constant64(Tracer::trace as *const u8 as i64, false), &[\n                Argument { index: 1, value: Value::Register(REGISTER_MAP[0]) }, // registers\n                Argument { index: 0, value: Value::RegisterIndirect(R10, mem::size_of::<MemoryMapping>() as i32 + self.program_argument_key, false) }, // jit.tracer\n            ], None, false)?;\n            // Pop stack and return\n            emit_alu(self, OperandSize::S64, 0x81, 0, RSP, 8 * 3, None)?; // RSP += 8 * 3;\n            X86Instruction::pop(REGISTER_MAP[0]).emit(self)?;\n            emit_alu(self, OperandSize::S64, 0x81, 0, RSP, 8 * (REGISTER_MAP.len() - 1) as i64, None)?; // RSP += 8 * (REGISTER_MAP.len() - 1);\n            X86Instruction::pop(R11).emit(self)?;\n            X86Instruction::return_near().emit(self)?;\n        }\n\n        // Routine for syscall\n        set_anchor(self, TARGET_PC_SYSCALL);\n        X86Instruction::push(R11, None).emit(self)?; // Padding for stack alignment\n        if self.config.enable_instruction_meter {\n            // RDI = *PrevInsnMeter - RDI;\n            emit_alu(self, OperandSize::S64, 0x2B, ARGUMENT_REGISTERS[0], RBP, 0, Some(X86IndirectAccess::Offset(slot_on_environment_stack(self, EnvironmentStackSlot::PrevInsnMeter))))?; // RDI -= *PrevInsnMeter;\n            emit_alu(self, OperandSize::S64, 0xf7, 3, ARGUMENT_REGISTERS[0], 0, None)?; // RDI = -RDI;\n            emit_rust_call(self, Value::Constant64(I::consume as *const u8 as i64, false), &[\n                Argument { index: 1, value: Value::Register(ARGUMENT_REGISTERS[0]) },\n                Argument { index: 0, value: Value::RegisterIndirect(RBP, slot_on_environment_stack(self, EnvironmentStackSlot::InsnMeterPtr), false) },\n            ], None, false)?;\n        }\n        emit_rust_call(self, Value::Register(R11), &[\n            Argument { index: 7, value: Value::RegisterIndirect(RBP, slot_on_environment_stack(self, EnvironmentStackSlot::OptRetValPtr), false) },\n            Argument { index: 6, value: Value::RegisterPlusConstant32(R10, self.program_argument_key, false) }, // jit_program_argument.memory_mapping\n            Argument { index: 5, value: Value::Register(ARGUMENT_REGISTERS[5]) },\n            Argument { index: 4, value: Value::Register(ARGUMENT_REGISTERS[4]) },\n            Argument { index: 3, value: Value::Register(ARGUMENT_REGISTERS[3]) },\n            Argument { index: 2, value: Value::Register(ARGUMENT_REGISTERS[2]) },\n            Argument { index: 1, value: Value::Register(ARGUMENT_REGISTERS[1]) },\n            Argument { index: 0, value: Value::Register(RAX) }, // \"&mut self\" in the \"call\" method of the SyscallObject\n        ], None, false)?;\n        if self.config.enable_instruction_meter {\n            emit_rust_call(self, Value::Constant64(I::get_remaining as *const u8 as i64, false), &[\n                Argument { index: 0, value: Value::RegisterIndirect(RBP, slot_on_environment_stack(self, EnvironmentStackSlot::InsnMeterPtr), false) },\n            ], Some(ARGUMENT_REGISTERS[0]), false)?;\n            X86Instruction::store(OperandSize::S64, ARGUMENT_REGISTERS[0], RBP, X86IndirectAccess::Offset(slot_on_environment_stack(self, EnvironmentStackSlot::PrevInsnMeter))).emit(self)?;\n        }\n        X86Instruction::pop(R11).emit(self)?;\n        // Store Ok value in result register\n        X86Instruction::load(OperandSize::S64, RBP, R11, X86IndirectAccess::Offset(slot_on_environment_stack(self, EnvironmentStackSlot::OptRetValPtr))).emit(self)?;\n        X86Instruction::load(OperandSize::S64, R11, REGISTER_MAP[0], X86IndirectAccess::Offset(8)).emit(self)?;\n        X86Instruction::return_near().emit(self)?;\n\n        // Routine for prologue of emit_bpf_call()\n        set_anchor(self, TARGET_PC_BPF_CALL_PROLOGUE);\n        emit_alu(self, OperandSize::S64, 0x81, 5, RSP, 8 * (SCRATCH_REGS + 1) as i64, None)?; // alloca\n        X86Instruction::store(OperandSize::S64, R11, RSP, X86IndirectAccess::OffsetIndexShift(0, RSP, 0)).emit(self)?; // Save original R11\n        X86Instruction::load(OperandSize::S64, RSP, R11, X86IndirectAccess::OffsetIndexShift(8 * (SCRATCH_REGS + 1) as i32, RSP, 0)).emit(self)?; // Load return address\n        for (i, reg) in REGISTER_MAP.iter().skip(FIRST_SCRATCH_REG).take(SCRATCH_REGS).enumerate() {\n            X86Instruction::store(OperandSize::S64, *reg, RSP, X86IndirectAccess::OffsetIndexShift(8 * (SCRATCH_REGS - i + 1) as i32, RSP, 0)).emit(self)?; // Push SCRATCH_REG\n        }\n        // Push the caller's frame pointer. The code to restore it is emitted at the end of emit_bpf_call().\n        X86Instruction::store(OperandSize::S64, REGISTER_MAP[FRAME_PTR_REG], RSP, X86IndirectAccess::OffsetIndexShift(8, RSP, 0)).emit(self)?;\n        X86Instruction::xchg(OperandSize::S64, R11, RSP, Some(X86IndirectAccess::OffsetIndexShift(0, RSP, 0))).emit(self)?; // Push return address and restore original R11\n\n        // Increase CallDepth\n        let call_depth_access = X86IndirectAccess::Offset(slot_on_environment_stack(self, EnvironmentStackSlot::CallDepth));\n        emit_alu(self, OperandSize::S64, 0x81, 0, RBP, 1, Some(call_depth_access))?;\n        X86Instruction::load(OperandSize::S64, RBP, REGISTER_MAP[FRAME_PTR_REG], call_depth_access).emit(self)?;\n        // If CallDepth == self.config.max_call_depth, stop and return CallDepthExceeded\n        X86Instruction::cmp_immediate(OperandSize::S32, REGISTER_MAP[FRAME_PTR_REG], self.config.max_call_depth as i64, None).emit(self)?;\n        emit_jcc(self, 0x83, TARGET_PC_CALL_DEPTH_EXCEEDED)?;\n\n        // Setup the frame pointer for the new frame. What we do depends on whether we're using dynamic or fixed frames.\n        let frame_ptr_access = X86IndirectAccess::Offset(slot_on_environment_stack(self, EnvironmentStackSlot::BpfFramePtr));\n        if self.config.dynamic_stack_frames {\n            // When dynamic frames are on, the next frame starts at the end of the current frame\n            let stack_ptr_access = X86IndirectAccess::Offset(slot_on_environment_stack(self, EnvironmentStackSlot::BpfStackPtr));\n            X86Instruction::load(OperandSize::S64, RBP, REGISTER_MAP[FRAME_PTR_REG], stack_ptr_access).emit(self)?;\n            X86Instruction::store(OperandSize::S64, REGISTER_MAP[FRAME_PTR_REG], RBP, frame_ptr_access).emit(self)?;\n        } else {\n            // With fixed frames we start the new frame at the next fixed offset\n            let stack_frame_size = self.config.stack_frame_size as i64 * if self.config.enable_stack_frame_gaps { 2 } else { 1 };\n            emit_alu(self, OperandSize::S64, 0x81, 0, RBP, stack_frame_size, Some(frame_ptr_access))?; // frame_ptr += stack_frame_size;\n            X86Instruction::load(OperandSize::S64, RBP, REGISTER_MAP[FRAME_PTR_REG], frame_ptr_access).emit(self)?; // Load BpfFramePtr\n        }\n        X86Instruction::return_near().emit(self)?;\n\n        // Routine for emit_bpf_call(Value::Register())\n        set_anchor(self, TARGET_PC_BPF_CALL_REG);\n        // Force alignment of RAX\n        emit_alu(self, OperandSize::S64, 0x81, 4, REGISTER_MAP[0], !(INSN_SIZE as i64 - 1), None)?; // RAX &= !(INSN_SIZE - 1);\n        // Upper bound check\n        // if(RAX >= self.program_vm_addr + number_of_instructions * INSN_SIZE) throw CALL_OUTSIDE_TEXT_SEGMENT;\n        let number_of_instructions = self.result.pc_section.len() - 1;\n        X86Instruction::load_immediate(OperandSize::S64, REGISTER_MAP[FRAME_PTR_REG], self.program_vm_addr as i64 + (number_of_instructions * INSN_SIZE) as i64).emit(self)?;\n        X86Instruction::cmp(OperandSize::S64, REGISTER_MAP[FRAME_PTR_REG], REGISTER_MAP[0], None).emit(self)?;\n        emit_jcc(self, 0x83, TARGET_PC_CALL_OUTSIDE_TEXT_SEGMENT)?;\n        // Lower bound check\n        // if(RAX < self.program_vm_addr) throw CALL_OUTSIDE_TEXT_SEGMENT;\n        X86Instruction::load_immediate(OperandSize::S64, REGISTER_MAP[FRAME_PTR_REG], self.program_vm_addr as i64).emit(self)?;\n        X86Instruction::cmp(OperandSize::S64, REGISTER_MAP[FRAME_PTR_REG], REGISTER_MAP[0], None).emit(self)?;\n        emit_jcc(self, 0x82, TARGET_PC_CALL_OUTSIDE_TEXT_SEGMENT)?;\n        // Calculate offset relative to instruction_addresses\n        emit_alu(self, OperandSize::S64, 0x29, REGISTER_MAP[FRAME_PTR_REG], REGISTER_MAP[0], 0, None)?; // RAX -= self.program_vm_addr;\n        // Calculate the target_pc (dst / INSN_SIZE) to update the instruction_meter\n        let shift_amount = INSN_SIZE.trailing_zeros();\n        debug_assert_eq!(INSN_SIZE, 1 << shift_amount);\n        X86Instruction::mov(OperandSize::S64, REGISTER_MAP[0], R11).emit(self)?;\n        emit_alu(self, OperandSize::S64, 0xc1, 5, R11, shift_amount as i64, None)?;\n        // Save BPF target pc for potential TARGET_PC_CALLX_UNSUPPORTED_INSTRUCTION\n        X86Instruction::store(OperandSize::S64, R11, RSP, X86IndirectAccess::OffsetIndexShift(-8, RSP, 0)).emit(self)?; // RSP[-8] = R11;\n        // Load host target_address from self.result.pc_section\n        debug_assert_eq!(INSN_SIZE, 8); // Because the instruction size is also the slot size we do not need to shift the offset\n        X86Instruction::load_immediate(OperandSize::S64, REGISTER_MAP[FRAME_PTR_REG], self.result.pc_section.as_ptr() as i64).emit(self)?;\n        emit_alu(self, OperandSize::S64, 0x01, REGISTER_MAP[FRAME_PTR_REG], REGISTER_MAP[0], 0, None)?; // RAX += self.result.pc_section;\n        X86Instruction::load(OperandSize::S64, REGISTER_MAP[0], REGISTER_MAP[0], X86IndirectAccess::Offset(0)).emit(self)?; // RAX = self.result.pc_section[RAX / 8];\n        // Load the frame pointer again since we've clobbered REGISTER_MAP[FRAME_PTR_REG]\n        X86Instruction::load(OperandSize::S64, RBP, REGISTER_MAP[FRAME_PTR_REG], X86IndirectAccess::Offset(slot_on_environment_stack(self, EnvironmentStackSlot::BpfFramePtr))).emit(self)?;\n        X86Instruction::return_near().emit(self)?;\n\n        // Translates a host pc back to a BPF pc by linear search of the pc_section table\n        set_anchor(self, TARGET_PC_TRANSLATE_PC);\n        X86Instruction::push(REGISTER_MAP[0], None).emit(self)?; // Save REGISTER_MAP[0]\n        X86Instruction::load_immediate(OperandSize::S64, REGISTER_MAP[0], self.result.pc_section.as_ptr() as i64 - 8).emit(self)?; // Loop index and pointer to look up\n        set_anchor(self, TARGET_PC_TRANSLATE_PC_LOOP); // Loop label\n        emit_alu(self, OperandSize::S64, 0x81, 0, REGISTER_MAP[0], 8, None)?; // Increase index\n        X86Instruction::cmp(OperandSize::S64, R11, REGISTER_MAP[0], Some(X86IndirectAccess::Offset(8))).emit(self)?; // Look up and compare against value at next index\n        emit_jcc(self, 0x86, TARGET_PC_TRANSLATE_PC_LOOP)?; // Continue while *REGISTER_MAP[0] <= R11\n        X86Instruction::mov(OperandSize::S64, REGISTER_MAP[0], R11).emit(self)?; // R11 = REGISTER_MAP[0];\n        X86Instruction::load_immediate(OperandSize::S64, REGISTER_MAP[0], self.result.pc_section.as_ptr() as i64).emit(self)?; // REGISTER_MAP[0] = self.result.pc_section;\n        emit_alu(self, OperandSize::S64, 0x29, REGISTER_MAP[0], R11, 0, None)?; // R11 -= REGISTER_MAP[0];\n        emit_alu(self, OperandSize::S64, 0xc1, 5, R11, 3, None)?; // R11 >>= 3;\n        X86Instruction::pop(REGISTER_MAP[0]).emit(self)?; // Restore REGISTER_MAP[0]\n        X86Instruction::return_near().emit(self)?;\n\n        // Translates a vm memory address to a host memory address\n        for (access_type, len) in &[\n            (AccessType::Load, 1i32),\n            (AccessType::Load, 2i32),\n            (AccessType::Load, 4i32),\n            (AccessType::Load, 8i32),\n            (AccessType::Store, 1i32),\n            (AccessType::Store, 2i32),\n            (AccessType::Store, 4i32),\n            (AccessType::Store, 8i32),\n        ] {\n            let target_offset = len.trailing_zeros() as usize + 4 * (*access_type as usize);\n\n            set_anchor(self, TARGET_PC_TRANSLATE_MEMORY_ADDRESS + target_offset);\n            X86Instruction::push(R11, None).emit(self)?;\n            X86Instruction::push(RAX, None).emit(self)?;\n            X86Instruction::push(RCX, None).emit(self)?;\n            let stack_offset = if !self.config.dynamic_stack_frames && self.config.enable_stack_frame_gaps {\n                X86Instruction::push(RDX, None).emit(self)?;\n                24\n            } else {\n                16\n            };\n            X86Instruction::mov(OperandSize::S64, R11, RAX).emit(self)?; // RAX = vm_addr;\n            emit_alu(self, OperandSize::S64, 0xc1, 5, RAX, ebpf::VIRTUAL_ADDRESS_BITS as i64, None)?; // RAX >>= ebpf::VIRTUAL_ADDRESS_BITS;\n            X86Instruction::cmp(OperandSize::S64, RAX, R10, Some(X86IndirectAccess::Offset(self.program_argument_key + 8))).emit(self)?; // region_index >= jit_program_argument.memory_mapping.regions.len()\n            emit_jcc(self, 0x86, TARGET_PC_MEMORY_ACCESS_VIOLATION + target_offset)?;\n            debug_assert_eq!(1 << 5, mem::size_of::<MemoryRegion>());\n            emit_alu(self, OperandSize::S64, 0xc1, 4, RAX, 5, None)?; // RAX *= mem::size_of::<MemoryRegion>();\n            emit_alu(self, OperandSize::S64, 0x03, RAX, R10, 0, Some(X86IndirectAccess::Offset(self.program_argument_key)))?; // region = &jit_program_argument.memory_mapping.regions[region_index];\n            if *access_type == AccessType::Store {\n                X86Instruction::cmp_immediate(OperandSize::S8, RAX, 0, Some(X86IndirectAccess::Offset(MemoryRegion::IS_WRITABLE_OFFSET))).emit(self)?; // region.is_writable == 0\n                emit_jcc(self, 0x84, TARGET_PC_MEMORY_ACCESS_VIOLATION + target_offset)?;\n            }\n            X86Instruction::load(OperandSize::S64, RAX, RCX, X86IndirectAccess::Offset(MemoryRegion::VM_ADDR_OFFSET)).emit(self)?; // RCX = region.vm_addr\n            X86Instruction::cmp(OperandSize::S64, RCX, R11, None).emit(self)?; // vm_addr < region.vm_addr\n            emit_jcc(self, 0x82, TARGET_PC_MEMORY_ACCESS_VIOLATION + target_offset)?;\n            emit_alu(self, OperandSize::S64, 0x29, RCX, R11, 0, None)?; // vm_addr -= region.vm_addr\n            if !self.config.dynamic_stack_frames && self.config.enable_stack_frame_gaps {\n                X86Instruction::load(OperandSize::S8, RAX, RCX, X86IndirectAccess::Offset(MemoryRegion::VM_GAP_SHIFT_OFFSET)).emit(self)?; // RCX = region.vm_gap_shift;\n                X86Instruction::mov(OperandSize::S64, R11, RDX).emit(self)?; // RDX = R11;\n                emit_alu(self, OperandSize::S64, 0xd3, 5, RDX, 0, None)?; // RDX = R11 >> region.vm_gap_shift;\n                X86Instruction::test_immediate(OperandSize::S64, RDX, 1, None).emit(self)?; // (RDX & 1) != 0\n                emit_jcc(self, 0x85, TARGET_PC_MEMORY_ACCESS_VIOLATION + target_offset)?;\n                X86Instruction::load_immediate(OperandSize::S64, RDX, -1).emit(self)?; // RDX = -1;\n                emit_alu(self, OperandSize::S64, 0xd3, 4, RDX, 0, None)?; // gap_mask = -1 << region.vm_gap_shift;\n                X86Instruction::mov(OperandSize::S64, RDX, RCX).emit(self)?; // RCX = RDX;\n                emit_alu(self, OperandSize::S64, 0xf7, 2, RCX, 0, None)?; // inverse_gap_mask = !gap_mask;\n                emit_alu(self, OperandSize::S64, 0x21, R11, RCX, 0, None)?; // below_gap = R11 & inverse_gap_mask;\n                emit_alu(self, OperandSize::S64, 0x21, RDX, R11, 0, None)?; // above_gap = R11 & gap_mask;\n                emit_alu(self, OperandSize::S64, 0xc1, 5, R11, 1, None)?; // above_gap >>= 1;\n                emit_alu(self, OperandSize::S64, 0x09, RCX, R11, 0, None)?; // gapped_offset = above_gap | below_gap;\n            }\n            X86Instruction::lea(OperandSize::S64, R11, RCX, Some(X86IndirectAccess::Offset(*len))).emit(self)?; // RCX = R11 + len;\n            X86Instruction::cmp(OperandSize::S64, RCX, RAX, Some(X86IndirectAccess::Offset(MemoryRegion::LEN_OFFSET))).emit(self)?; // region.len < R11 + len\n            emit_jcc(self, 0x82, TARGET_PC_MEMORY_ACCESS_VIOLATION + target_offset)?;\n            emit_alu(self, OperandSize::S64, 0x03, R11, RAX, 0, Some(X86IndirectAccess::Offset(MemoryRegion::HOST_ADDR_OFFSET)))?; // R11 += region.host_addr;\n            if !self.config.dynamic_stack_frames && self.config.enable_stack_frame_gaps {\n                X86Instruction::pop(RDX).emit(self)?;\n            }\n            X86Instruction::pop(RCX).emit(self)?;\n            X86Instruction::pop(RAX).emit(self)?;\n            emit_alu(self, OperandSize::S64, 0x81, 0, RSP, 8, None)?;\n            X86Instruction::return_near().emit(self)?;\n\n            set_anchor(self, TARGET_PC_MEMORY_ACCESS_VIOLATION + target_offset);\n            emit_alu(self, OperandSize::S64, 0x31, R11, R11, 0, None)?; // R11 = 0;\n            X86Instruction::load(OperandSize::S64, RSP, R11, X86IndirectAccess::OffsetIndexShift(stack_offset, R11, 0)).emit(self)?;\n            emit_rust_call(self, Value::Constant64(MemoryMapping::generate_access_violation::<UserError> as *const u8 as i64, false), &[\n                Argument { index: 3, value: Value::Register(R11) }, // Specify first as the src register could be overwritten by other arguments\n                Argument { index: 4, value: Value::Constant64(*len as i64, false) },\n                Argument { index: 2, value: Value::Constant64(*access_type as i64, false) },\n                Argument { index: 1, value: Value::RegisterPlusConstant32(R10, self.program_argument_key, false) }, // jit_program_argument.memory_mapping\n                Argument { index: 0, value: Value::RegisterIndirect(RBP, slot_on_environment_stack(self, EnvironmentStackSlot::OptRetValPtr), false) }, // Pointer to optional typed return value\n            ], None, true)?;\n            emit_alu(self, OperandSize::S64, 0x81, 0, RSP, stack_offset as i64 + 8, None)?; // Drop R11, RAX, RCX, RDX from stack\n            X86Instruction::pop(R11).emit(self)?; // Put callers PC in R11\n            emit_call(self, TARGET_PC_TRANSLATE_PC)?;\n            emit_jmp(self, TARGET_PC_EXCEPTION_AT)?;\n        }\n        Ok(())\n    }\n\n    fn generate_exception_handlers<E: UserDefinedError>(&mut self) -> Result<(), EbpfError<E>> {\n        // Handler for EbpfError::ExceededMaxInstructions\n        set_anchor(self, TARGET_PC_CALL_EXCEEDED_MAX_INSTRUCTIONS);\n        emit_set_exception_kind::<E>(self, EbpfError::ExceededMaxInstructions(0, 0))?;\n        X86Instruction::mov(OperandSize::S64, ARGUMENT_REGISTERS[0], R11).emit(self)?; // R11 = instruction_meter;\n        emit_profile_instruction_count_finalize(self, true)?;\n        emit_jmp(self, TARGET_PC_EPILOGUE)?;\n\n        // Handler for EbpfError::CallDepthExceeded\n        set_anchor(self, TARGET_PC_CALL_DEPTH_EXCEEDED);\n        emit_set_exception_kind::<E>(self, EbpfError::CallDepthExceeded(0, 0))?;\n        X86Instruction::store_immediate(OperandSize::S64, R10, X86IndirectAccess::Offset(24), self.config.max_call_depth as i64).emit(self)?; // depth = jit.config.max_call_depth;\n        emit_jmp(self, TARGET_PC_EXCEPTION_AT)?;\n\n        // Handler for EbpfError::CallOutsideTextSegment\n        set_anchor(self, TARGET_PC_CALL_OUTSIDE_TEXT_SEGMENT);\n        emit_set_exception_kind::<E>(self, EbpfError::CallOutsideTextSegment(0, 0))?;\n        X86Instruction::store(OperandSize::S64, REGISTER_MAP[0], R10, X86IndirectAccess::Offset(24)).emit(self)?; // target_address = RAX;\n        emit_jmp(self, TARGET_PC_EXCEPTION_AT)?;\n\n        // Handler for EbpfError::DivideByZero\n        set_anchor(self, TARGET_PC_DIV_BY_ZERO);\n        emit_set_exception_kind::<E>(self, EbpfError::DivideByZero(0))?;\n        emit_jmp(self, TARGET_PC_EXCEPTION_AT)?;\n\n        // Handler for EbpfError::DivideOverflow\n        set_anchor(self, TARGET_PC_DIV_OVERFLOW);\n        emit_set_exception_kind::<E>(self, EbpfError::DivideOverflow(0))?;\n        emit_jmp(self, TARGET_PC_EXCEPTION_AT)?;\n\n        // Handler for EbpfError::UnsupportedInstruction\n        set_anchor(self, TARGET_PC_CALLX_UNSUPPORTED_INSTRUCTION);\n        // Load BPF target pc from stack (which was saved in TARGET_PC_BPF_CALL_REG)\n        X86Instruction::load(OperandSize::S64, RSP, R11, X86IndirectAccess::OffsetIndexShift(-16, RSP, 0)).emit(self)?; // R11 = RSP[-16];\n        // emit_jmp(self, TARGET_PC_CALL_UNSUPPORTED_INSTRUCTION)?; // Fall-through\n\n        // Handler for EbpfError::UnsupportedInstruction\n        set_anchor(self, TARGET_PC_CALL_UNSUPPORTED_INSTRUCTION);\n        if self.config.enable_instruction_tracing {\n            emit_call(self, TARGET_PC_TRACE)?;\n        }\n        emit_set_exception_kind::<E>(self, EbpfError::UnsupportedInstruction(0))?;\n        // emit_jmp(self, TARGET_PC_EXCEPTION_AT)?; // Fall-through\n\n        // Handler for exceptions which report their pc\n        set_anchor(self, TARGET_PC_EXCEPTION_AT);\n        // Validate that we did not reach the instruction meter limit before the exception occured\n        if self.config.enable_instruction_meter {\n            emit_validate_instruction_count(self, false, None)?;\n        }\n        emit_profile_instruction_count_finalize(self, true)?;\n        emit_jmp(self, TARGET_PC_EPILOGUE)?;\n\n        // Handler for syscall exceptions\n        set_anchor(self, TARGET_PC_RUST_EXCEPTION);\n        emit_profile_instruction_count_finalize(self, false)?;\n        emit_jmp(self, TARGET_PC_EPILOGUE)\n    }\n\n    fn generate_prologue<E: UserDefinedError, I: InstructionMeter>(&mut self) -> Result<(), EbpfError<E>> {\n        // Place the environment on the stack according to EnvironmentStackSlot\n\n        // Save registers\n        for reg in CALLEE_SAVED_REGISTERS.iter() {\n            X86Instruction::push(*reg, None).emit(self)?;\n        }\n\n        // Initialize CallDepth to 0\n        X86Instruction::load_immediate(OperandSize::S64, REGISTER_MAP[FRAME_PTR_REG], 0).emit(self)?;\n        X86Instruction::push(REGISTER_MAP[FRAME_PTR_REG], None).emit(self)?;\n\n        // Initialize the BPF frame and stack pointers (BpfFramePtr and BpfStackPtr)\n        if self.config.dynamic_stack_frames {\n            // The stack is fully descending from MM_STACK_START + stack_size to MM_STACK_START\n            X86Instruction::load_immediate(OperandSize::S64, REGISTER_MAP[FRAME_PTR_REG], MM_STACK_START as i64 + self.config.stack_size() as i64).emit(self)?;\n            // Push BpfFramePtr\n            X86Instruction::push(REGISTER_MAP[FRAME_PTR_REG], None).emit(self)?;\n            // Push BpfStackPtr\n            X86Instruction::push(REGISTER_MAP[FRAME_PTR_REG], None).emit(self)?;\n        } else {\n            // The frames are ascending from MM_STACK_START to MM_STACK_START + stack_size. The stack within the frames is descending.\n            X86Instruction::load_immediate(OperandSize::S64, REGISTER_MAP[FRAME_PTR_REG], MM_STACK_START as i64 + self.config.stack_frame_size as i64).emit(self)?;\n            // Push BpfFramePtr\n            X86Instruction::push(REGISTER_MAP[FRAME_PTR_REG], None).emit(self)?;\n            // When using static frames BpfStackPtr is not used\n            X86Instruction::load_immediate(OperandSize::S64, RBP, 0).emit(self)?;\n            X86Instruction::push(RBP, None).emit(self)?;\n        }\n\n        // Save pointer to optional typed return value\n        X86Instruction::push(ARGUMENT_REGISTERS[0], None).emit(self)?;\n\n        // Save initial value of instruction_meter.get_remaining()\n        emit_rust_call(self, Value::Constant64(I::get_remaining as *const u8 as i64, false), &[\n            Argument { index: 0, value: Value::Register(ARGUMENT_REGISTERS[3]) },\n        ], Some(ARGUMENT_REGISTERS[0]), false)?;\n        X86Instruction::push(ARGUMENT_REGISTERS[0], None).emit(self)?;\n\n        // Save instruction meter\n        X86Instruction::push(ARGUMENT_REGISTERS[3], None).emit(self)?;\n\n        // Initialize stop watch\n        emit_alu(self, OperandSize::S64, 0x31, R11, R11, 0, None)?; // R11 ^= R11;\n        X86Instruction::push(R11, None).emit(self)?;\n        X86Instruction::push(R11, None).emit(self)?;\n\n        // Initialize frame pointer\n        X86Instruction::mov(OperandSize::S64, RSP, RBP).emit(self)?;\n        emit_alu(self, OperandSize::S64, 0x81, 0, RBP, 8 * (EnvironmentStackSlot::SlotCount as i64 - 1 + self.environment_stack_key as i64), None)?;\n\n        // Save JitProgramArgument\n        X86Instruction::lea(OperandSize::S64, ARGUMENT_REGISTERS[2], R10, Some(X86IndirectAccess::Offset(-self.program_argument_key))).emit(self)?;\n\n        // Zero BPF registers\n        for reg in REGISTER_MAP.iter() {\n            if *reg != REGISTER_MAP[1] && *reg != REGISTER_MAP[FRAME_PTR_REG] {\n                X86Instruction::load_immediate(OperandSize::S64, *reg, 0).emit(self)?;\n            }\n        }\n\n        Ok(())\n    }\n\n    fn generate_epilogue<E: UserDefinedError>(&mut self) -> Result<(), EbpfError<E>> {\n        // Quit gracefully\n        set_anchor(self, TARGET_PC_EXIT);\n        emit_validate_instruction_count(self, false, None)?;\n        emit_profile_instruction_count_finalize(self, false)?;\n\n        X86Instruction::load(OperandSize::S64, RBP, R10, X86IndirectAccess::Offset(slot_on_environment_stack(self, EnvironmentStackSlot::OptRetValPtr))).emit(self)?;\n        X86Instruction::store(OperandSize::S64, REGISTER_MAP[0], R10, X86IndirectAccess::Offset(8)).emit(self)?; // result.return_value = R0;\n        X86Instruction::load_immediate(OperandSize::S64, REGISTER_MAP[0], 0).emit(self)?;\n        X86Instruction::store(OperandSize::S64, REGISTER_MAP[0], R10, X86IndirectAccess::Offset(0)).emit(self)?;  // result.is_error = false;\n\n        // Epilogue\n        set_anchor(self, TARGET_PC_EPILOGUE);\n\n        // Print stop watch value\n        fn stopwatch_result(numerator: u64, denominator: u64) {\n            println!(\"Stop watch: {} / {} = {}\", numerator, denominator, if denominator == 0 { 0.0 } else { numerator as f64 / denominator as f64 });\n        }\n        if self.stopwatch_is_active {\n            emit_rust_call(self, Value::Constant64(stopwatch_result as *const u8 as i64, false), &[\n                Argument { index: 1, value: Value::RegisterIndirect(RBP, slot_on_environment_stack(self, EnvironmentStackSlot::StopwatchDenominator), false) },\n                Argument { index: 0, value: Value::RegisterIndirect(RBP, slot_on_environment_stack(self, EnvironmentStackSlot::StopwatchNumerator), false) },\n            ], None, false)?;\n        }\n\n        // Store instruction_meter in RAX\n        X86Instruction::mov(OperandSize::S64, ARGUMENT_REGISTERS[0], RAX).emit(self)?;\n\n        // Restore stack pointer in case the BPF stack was used\n        X86Instruction::lea(OperandSize::S64, RBP, RSP, Some(X86IndirectAccess::Offset(slot_on_environment_stack(self, EnvironmentStackSlot::LastSavedRegister)))).emit(self)?;\n\n        // Restore registers\n        for reg in CALLEE_SAVED_REGISTERS.iter().rev() {\n            X86Instruction::pop(*reg).emit(self)?;\n        }\n\n        X86Instruction::return_near().emit(self)\n    }\n\n    pub fn emit_random_noop<E: UserDefinedError>(&mut self) -> Result<(), EbpfError<E>> {\n        if self.config.noop_instruction_ratio != 0.0 && self.diversification_rng.gen_bool(self.config.noop_instruction_ratio) {\n            // X86Instruction::noop().emit(self)\n            emit::<u8, E>(self, 0x90)\n        } else {\n            Ok(())\n        }\n    }\n\n    fn resolve_jumps(&mut self) {\n        for jump in &self.pc_section_jumps {\n            self.result.pc_section[jump.location] = jump.get_target_offset(self);\n        }\n        for jump in &self.text_section_jumps {\n            let offset_value = jump.get_target_offset(self) as i32\n                - jump.location as i32 // Relative jump\n                - mem::size_of::<i32>() as i32; // Jump from end of instruction\n            unsafe {\n                ptr::write_unaligned(\n                    self.result.text_section.as_ptr().add(jump.location) as *mut i32,\n                    offset_value,\n                );\n            }\n        }\n        let call_unsupported_instruction = self.handler_anchors.get(&TARGET_PC_CALL_UNSUPPORTED_INSTRUCTION).unwrap();\n        let callx_unsupported_instruction = self.handler_anchors.get(&TARGET_PC_CALLX_UNSUPPORTED_INSTRUCTION).unwrap();\n        for offset in self.result.pc_section.iter_mut() {\n            if *offset == *call_unsupported_instruction as u64 {\n                // Turns compiletime exception handlers to runtime ones (as they need to turn the host PC back into a BPF PC)\n                *offset = *callx_unsupported_instruction as u64;\n            }\n            *offset = unsafe { (self.result.text_section.as_ptr() as *const u8).add(*offset as usize) } as u64;\n        }\n    }\n}\n\n#[cfg(all(test, target_arch = \"x86_64\", not(target_os = \"windows\")))]\nmod tests {\n    use super::*;\n    use crate::{syscalls, vm::{SyscallRegistry, SyscallObject, TestInstructionMeter}, elf::register_bpf_function};\n    use std::collections::BTreeMap;\n    use byteorder::{LittleEndian, ByteOrder};\n\n    fn create_mockup_executable(program: &[u8]) -> Pin<Box<Executable::<UserError, TestInstructionMeter>>> {\n        let config = Config {\n            noop_instruction_ratio: 0.0,\n            ..Config::default()\n        };\n        let mut syscall_registry = SyscallRegistry::default();\n        syscall_registry\n            .register_syscall_by_hash(\n                0xFFFFFFFF,\n                syscalls::BpfGatherBytes::init::<syscalls::BpfSyscallContext, UserError>,\n                syscalls::BpfGatherBytes::call,\n            )\n            .unwrap();\n        let mut bpf_functions = BTreeMap::new();\n        register_bpf_function(\n            &config,\n            &mut bpf_functions,\n            &syscall_registry,\n            0,\n            \"entrypoint\",\n        )\n        .unwrap();\n        bpf_functions.insert(0xFFFFFFFF, (8, \"foo\".to_string()));\n        Executable::<UserError, TestInstructionMeter>::from_text_bytes(\n            program,\n            None,\n            config,\n            syscall_registry,\n            bpf_functions,\n        )\n        .unwrap()\n    }\n    \n    #[test]\n    fn test_code_length_estimate() {\n        const INSTRUCTION_COUNT: usize = 256;\n        let mut prog = [0; ebpf::INSN_SIZE * INSTRUCTION_COUNT];\n    \n        let empty_program_machine_code_length = {\n            prog[0] = ebpf::EXIT;\n            let mut executable = create_mockup_executable(&[]);\n            Executable::<UserError, TestInstructionMeter>::jit_compile(&mut executable).unwrap();\n            executable.get_compiled_program().unwrap().machine_code_length()\n        };\n        assert!(empty_program_machine_code_length <= MAX_EMPTY_PROGRAM_MACHINE_CODE_LENGTH);\n    \n        for opcode in 0..255 {\n            for pc in 0..INSTRUCTION_COUNT {\n                prog[pc * ebpf::INSN_SIZE] = opcode;\n                prog[pc * ebpf::INSN_SIZE + 1] = 0x88;\n                prog[pc * ebpf::INSN_SIZE + 2] = 0xFF;\n                prog[pc * ebpf::INSN_SIZE + 3] = 0xFF;\n                LittleEndian::write_u32(&mut prog[pc * ebpf::INSN_SIZE + 4..], match opcode {\n                    0x8D => 8,\n                    0xD4 | 0xDC => 16,\n                    _ => 0xFFFFFFFF,\n                });\n            }\n            let mut executable = create_mockup_executable(&prog);\n            let result = Executable::<UserError, TestInstructionMeter>::jit_compile(&mut executable);\n            if result.is_err() {\n                assert!(matches!(result.unwrap_err(), EbpfError::UnsupportedInstruction(_)));\n                continue;\n            }\n            let machine_code_length = executable.get_compiled_program().unwrap().machine_code_length() - empty_program_machine_code_length;\n            let instruction_count = if opcode == 0x18 { INSTRUCTION_COUNT / 2 } else { INSTRUCTION_COUNT };\n            let machine_code_length_per_instruction = (machine_code_length as f64 / instruction_count as f64 + 0.5) as usize;\n            assert!(machine_code_length_per_instruction <= MAX_MACHINE_CODE_LENGTH_PER_INSTRUCTION);\n        }\n    }\n}\n", "#![allow(clippy::integer_arithmetic)]\n// Copyright 2020 Solana Maintainers <maintainers@solana.com>\n//\n// Licensed under the Apache License, Version 2.0 <http://www.apache.org/licenses/LICENSE-2.0> or\n// the MIT license <http://opensource.org/licenses/MIT>, at your option. This file may not be\n// copied, modified, or distributed except according to those terms.\n\nextern crate byteorder;\nextern crate libc;\nextern crate solana_rbpf;\nextern crate test_utils;\nextern crate thiserror;\n\nuse byteorder::{ByteOrder, LittleEndian};\n#[cfg(all(not(windows), target_arch = \"x86_64\"))]\nuse rand::{rngs::SmallRng, RngCore, SeedableRng};\nuse solana_rbpf::{\n    assembler::assemble,\n    ebpf,\n    elf::{register_bpf_function, ElfError, Executable},\n    error::EbpfError,\n    memory_region::{AccessType, MemoryMapping, MemoryRegion},\n    syscalls::{self, BpfSyscallContext, Result},\n    user_error::UserError,\n    vm::{Config, EbpfVm, SyscallObject, SyscallRegistry, TestInstructionMeter},\n};\nuse std::{collections::BTreeMap, fs::File, io::Read};\nuse test_utils::{PROG_TCP_PORT_80, TCP_SACK_ASM, TCP_SACK_MATCH, TCP_SACK_NOMATCH};\n\nmacro_rules! test_interpreter_and_jit {\n    (register, $syscall_registry:expr, $location:expr => $syscall_init:expr; $syscall_function:expr) => {\n        $syscall_registry\n            .register_syscall_by_name($location, $syscall_init, $syscall_function)\n            .unwrap();\n    };\n    (bind, $vm:expr, $syscall_context:expr) => {\n        $vm.bind_syscall_context_objects($syscall_context).unwrap();\n    };\n    ($executable:expr, $mem:tt, $syscall_context:expr, $check:block, $expected_instruction_count:expr) => {\n        #[allow(unused_mut)]\n        let mut check_closure = $check;\n        let (instruction_count_interpreter, _tracer_interpreter) = {\n            let mut mem = $mem;\n            let mem_region = MemoryRegion::new_writable(&mut mem, ebpf::MM_INPUT_START);\n            let mut vm = EbpfVm::new(&$executable, &mut [], vec![mem_region]).unwrap();\n            test_interpreter_and_jit!(bind, vm, $syscall_context);\n            let result = vm.execute_program_interpreted(&mut TestInstructionMeter {\n                remaining: $expected_instruction_count,\n            });\n            assert!(check_closure(&vm, result));\n            (vm.get_total_instruction_count(), vm.get_tracer().clone())\n        };\n        #[cfg(all(not(windows), target_arch = \"x86_64\"))]\n        {\n            #[allow(unused_mut)]\n            let mut check_closure = $check;\n            let compilation_result =\n                Executable::<UserError, TestInstructionMeter>::jit_compile(&mut $executable);\n            let mut mem = $mem;\n            let mem_region = MemoryRegion::new_writable(&mut mem, ebpf::MM_INPUT_START);\n            let mut vm = EbpfVm::new(&$executable, &mut [], vec![mem_region]).unwrap();\n            match compilation_result {\n                Err(err) => assert!(check_closure(&vm, Err(err))),\n                Ok(()) => {\n                    test_interpreter_and_jit!(bind, vm, $syscall_context);\n                    let result = vm.execute_program_jit(&mut TestInstructionMeter {\n                        remaining: $expected_instruction_count,\n                    });\n                    let tracer_jit = vm.get_tracer();\n                    if !check_closure(&vm, result)\n                        || !solana_rbpf::vm::Tracer::compare(&_tracer_interpreter, tracer_jit)\n                    {\n                        let analysis =\n                            solana_rbpf::static_analysis::Analysis::from_executable(&$executable)\n                                .unwrap();\n                        let stdout = std::io::stdout();\n                        _tracer_interpreter\n                            .write(&mut stdout.lock(), &analysis)\n                            .unwrap();\n                        tracer_jit.write(&mut stdout.lock(), &analysis).unwrap();\n                        panic!();\n                    }\n                    if $executable.get_config().enable_instruction_meter {\n                        let instruction_count_jit = vm.get_total_instruction_count();\n                        assert_eq!(instruction_count_interpreter, instruction_count_jit);\n                    }\n                }\n            }\n        }\n        if $executable.get_config().enable_instruction_meter {\n            assert_eq!(instruction_count_interpreter, $expected_instruction_count);\n        }\n    };\n}\n\nmacro_rules! test_interpreter_and_jit_asm {\n    ($source:tt, $config:tt, $mem:tt, ($($location:expr => $syscall_init:expr; $syscall_function:expr),* $(,)?), $syscall_context:expr, $check:block, $expected_instruction_count:expr) => {\n        #[allow(unused_mut)]\n        {\n            let mut syscall_registry = SyscallRegistry::default();\n            $(test_interpreter_and_jit!(register, syscall_registry, $location => $syscall_init; $syscall_function);)*\n            let mut executable = assemble($source, None, $config, syscall_registry).unwrap();\n            test_interpreter_and_jit!(executable, $mem, $syscall_context, $check, $expected_instruction_count);\n        }\n    };\n    ($source:tt, $mem:tt, ($($location:expr => $syscall_init:expr; $syscall_function:expr),* $(,)?), $syscall_context:expr, $check:block, $expected_instruction_count:expr) => {\n        #[allow(unused_mut)]\n        {\n            let config = Config {\n                enable_instruction_tracing: true,\n                ..Config::default()\n            };\n            test_interpreter_and_jit_asm!($source, config, $mem, ($($location => $syscall_init; $syscall_function),*), $syscall_context, $check, $expected_instruction_count);\n        }\n    };\n}\n\nmacro_rules! test_interpreter_and_jit_elf {\n    ($source:tt, $config:tt, $mem:tt, ($($location:expr => $syscall_init:expr; $syscall_function:expr),* $(,)?), $syscall_context:expr, $check:block, $expected_instruction_count:expr) => {\n        let mut file = File::open($source).unwrap();\n        let mut elf = Vec::new();\n        file.read_to_end(&mut elf).unwrap();\n        #[allow(unused_mut)]\n        {\n            let mut syscall_registry = SyscallRegistry::default();\n            $(test_interpreter_and_jit!(register, syscall_registry, $location => $syscall_init; $syscall_function);)*\n            let mut executable = Executable::<UserError, TestInstructionMeter>::from_elf(&elf, None, $config, syscall_registry).unwrap();\n            test_interpreter_and_jit!(executable, $mem, $syscall_context, $check, $expected_instruction_count);\n        }\n    };\n    ($source:tt, $mem:tt, ($($location:expr => $syscall_init:expr; $syscall_function:expr),* $(,)?), $syscall_context:expr, $check:block, $expected_instruction_count:expr) => {\n        let config = Config {\n            enable_instruction_tracing: true,\n            ..Config::default()\n        };\n        test_interpreter_and_jit_elf!($source, config, $mem, ($($location => $syscall_init; $syscall_function),*), $syscall_context, $check, $expected_instruction_count);\n    };\n}\n\n// BPF_ALU : Arithmetic and Logic\n\n#[test]\nfn test_mov() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov32 r1, 1\n        mov32 r0, r1\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x1 } },\n        3\n    );\n}\n\n#[test]\nfn test_mov32_imm_large() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov32 r0, -1\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0xffffffff } },\n        2\n    );\n}\n\n#[test]\nfn test_mov_large() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov32 r1, -1\n        mov32 r0, r1\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0xffffffff } },\n        3\n    );\n}\n\n#[test]\nfn test_bounce() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov r0, 1\n        mov r6, r0\n        mov r7, r6\n        mov r8, r7\n        mov r9, r8\n        mov r0, r9\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x1 } },\n        7\n    );\n}\n\n#[test]\nfn test_add32() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov32 r0, 0\n        mov32 r1, 2\n        add32 r0, 1\n        add32 r0, r1\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x3 } },\n        5\n    );\n}\n\n#[test]\nfn test_neg32() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov32 r0, 2\n        neg32 r0\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0xfffffffe } },\n        3\n    );\n}\n\n#[test]\nfn test_neg64() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov32 r0, 2\n        neg r0\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0xfffffffffffffffe } },\n        3\n    );\n}\n\n#[test]\nfn test_alu32_arithmetic() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov32 r0, 0\n        mov32 r1, 1\n        mov32 r2, 2\n        mov32 r3, 3\n        mov32 r4, 4\n        mov32 r5, 5\n        mov32 r6, 6\n        mov32 r7, 7\n        mov32 r8, 8\n        mov32 r9, 9\n        add32 r0, 23\n        add32 r0, r7\n        sub32 r0, 13\n        sub32 r0, r1\n        mul32 r0, 7\n        mul32 r0, r3\n        div32 r0, 2\n        div32 r0, r4\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x2a } },\n        19\n    );\n}\n\n#[test]\nfn test_alu64_arithmetic() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov r0, 0\n        mov r1, 1\n        mov r2, 2\n        mov r3, 3\n        mov r4, 4\n        mov r5, 5\n        mov r6, 6\n        mov r7, 7\n        mov r8, 8\n        mov r9, 9\n        add r0, 23\n        add r0, r7\n        sub r0, 13\n        sub r0, r1\n        mul r0, 7\n        mul r0, r3\n        div r0, 2\n        div r0, r4\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x2a } },\n        19\n    );\n}\n\n#[test]\nfn test_mul128() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov r0, r1\n        mov r2, 30\n        mov r3, 0\n        mov r4, 20\n        mov r5, 0\n        mul64 r3, r4\n        mul64 r5, r2\n        add64 r5, r3\n        mov64 r0, r2\n        rsh64 r0, 0x20\n        mov64 r3, r4\n        rsh64 r3, 0x20\n        mov64 r6, r3\n        mul64 r6, r0\n        add64 r5, r6\n        lsh64 r4, 0x20\n        rsh64 r4, 0x20\n        mov64 r6, r4\n        mul64 r6, r0\n        lsh64 r2, 0x20\n        rsh64 r2, 0x20\n        mul64 r4, r2\n        mov64 r0, r4\n        rsh64 r0, 0x20\n        add64 r0, r6\n        mov64 r6, r0\n        rsh64 r6, 0x20\n        add64 r5, r6\n        mul64 r3, r2\n        lsh64 r0, 0x20\n        rsh64 r0, 0x20\n        add64 r0, r3\n        mov64 r2, r0\n        rsh64 r2, 0x20\n        add64 r5, r2\n        stxdw [r1+0x8], r5\n        lsh64 r0, 0x20\n        lsh64 r4, 0x20\n        rsh64 r4, 0x20\n        or64 r0, r4\n        stxdw [r1+0x0], r0\n        exit\",\n        [0; 16],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 600 } },\n        42\n    );\n}\n\n#[test]\nfn test_alu32_logic() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov32 r0, 0\n        mov32 r1, 1\n        mov32 r2, 2\n        mov32 r3, 3\n        mov32 r4, 4\n        mov32 r5, 5\n        mov32 r6, 6\n        mov32 r7, 7\n        mov32 r8, 8\n        or32 r0, r5\n        or32 r0, 0xa0\n        and32 r0, 0xa3\n        mov32 r9, 0x91\n        and32 r0, r9\n        lsh32 r0, 22\n        lsh32 r0, r8\n        rsh32 r0, 19\n        rsh32 r0, r7\n        xor32 r0, 0x03\n        xor32 r0, r2\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x11 } },\n        21\n    );\n}\n\n#[test]\nfn test_alu64_logic() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov r0, 0\n        mov r1, 1\n        mov r2, 2\n        mov r3, 3\n        mov r4, 4\n        mov r5, 5\n        mov r6, 6\n        mov r7, 7\n        mov r8, 8\n        or r0, r5\n        or r0, 0xa0\n        and r0, 0xa3\n        mov r9, 0x91\n        and r0, r9\n        lsh r0, 32\n        lsh r0, 22\n        lsh r0, r8\n        rsh r0, 32\n        rsh r0, 19\n        rsh r0, r7\n        xor r0, 0x03\n        xor r0, r2\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x11 } },\n        23\n    );\n}\n\n#[test]\nfn test_arsh32_high_shift() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov r0, 8\n        lddw r1, 0x100000001\n        arsh32 r0, r1\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x4 } },\n        4\n    );\n}\n\n#[test]\nfn test_arsh32_imm() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov32 r0, 0xf8\n        lsh32 r0, 28\n        arsh32 r0, 16\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0xffff8000 } },\n        4\n    );\n}\n\n#[test]\nfn test_arsh32_reg() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov32 r0, 0xf8\n        mov32 r1, 16\n        lsh32 r0, 28\n        arsh32 r0, r1\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0xffff8000 } },\n        5\n    );\n}\n\n#[test]\nfn test_arsh64() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov32 r0, 1\n        lsh r0, 63\n        arsh r0, 55\n        mov32 r1, 5\n        arsh r0, r1\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0xfffffffffffffff8 } },\n        6\n    );\n}\n\n#[test]\nfn test_lsh64_reg() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov r0, 0x1\n        mov r7, 4\n        lsh r0, r7\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x10 } },\n        4\n    );\n}\n\n#[test]\nfn test_rhs32_imm() {\n    test_interpreter_and_jit_asm!(\n        \"\n        xor r0, r0\n        sub r0, 1\n        rsh32 r0, 8\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x00ffffff } },\n        4\n    );\n}\n\n#[test]\nfn test_rsh64_reg() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov r0, 0x10\n        mov r7, 4\n        rsh r0, r7\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x1 } },\n        4\n    );\n}\n\n#[test]\nfn test_be16() {\n    test_interpreter_and_jit_asm!(\n        \"\n        ldxh r0, [r1]\n        be16 r0\n        exit\",\n        [0x11, 0x22],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x1122 } },\n        3\n    );\n}\n\n#[test]\nfn test_be16_high() {\n    test_interpreter_and_jit_asm!(\n        \"\n        ldxdw r0, [r1]\n        be16 r0\n        exit\",\n        [0x11, 0x22, 0x33, 0x44, 0x55, 0x66, 0x77, 0x88],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x1122 } },\n        3\n    );\n}\n\n#[test]\nfn test_be32() {\n    test_interpreter_and_jit_asm!(\n        \"\n        ldxw r0, [r1]\n        be32 r0\n        exit\",\n        [0x11, 0x22, 0x33, 0x44],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x11223344 } },\n        3\n    );\n}\n\n#[test]\nfn test_be32_high() {\n    test_interpreter_and_jit_asm!(\n        \"\n        ldxdw r0, [r1]\n        be32 r0\n        exit\",\n        [0x11, 0x22, 0x33, 0x44, 0x55, 0x66, 0x77, 0x88],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x11223344 } },\n        3\n    );\n}\n\n#[test]\nfn test_be64() {\n    test_interpreter_and_jit_asm!(\n        \"\n        ldxdw r0, [r1]\n        be64 r0\n        exit\",\n        [0x11, 0x22, 0x33, 0x44, 0x55, 0x66, 0x77, 0x88],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x1122334455667788 } },\n        3\n    );\n}\n\n#[test]\nfn test_le16() {\n    test_interpreter_and_jit_asm!(\n        \"\n        ldxh r0, [r1]\n        le16 r0\n        exit\",\n        [0x22, 0x11],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x1122 } },\n        3\n    );\n}\n\n#[test]\nfn test_le16_high() {\n    test_interpreter_and_jit_asm!(\n        \"\n        ldxdw r0, [r1]\n        le16 r0\n        exit\",\n        [0x11, 0x22, 0x33, 0x44, 0x55, 0x66, 0x77, 0x88],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x2211 } },\n        3\n    );\n}\n\n#[test]\nfn test_le32() {\n    test_interpreter_and_jit_asm!(\n        \"\n        ldxw r0, [r1]\n        le32 r0\n        exit\",\n        [0x44, 0x33, 0x22, 0x11],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x11223344 } },\n        3\n    );\n}\n\n#[test]\nfn test_le32_high() {\n    test_interpreter_and_jit_asm!(\n        \"\n        ldxdw r0, [r1]\n        le32 r0\n        exit\",\n        [0x11, 0x22, 0x33, 0x44, 0x55, 0x66, 0x77, 0x88],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x44332211 } },\n        3\n    );\n}\n\n#[test]\nfn test_le64() {\n    test_interpreter_and_jit_asm!(\n        \"\n        ldxdw r0, [r1]\n        le64 r0\n        exit\",\n        [0x88, 0x77, 0x66, 0x55, 0x44, 0x33, 0x22, 0x11],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x1122334455667788 } },\n        3\n    );\n}\n\n#[test]\nfn test_mul32_imm() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov r0, 3\n        mul32 r0, 4\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0xc } },\n        3\n    );\n}\n\n#[test]\nfn test_mul32_reg() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov r0, 3\n        mov r1, 4\n        mul32 r0, r1\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0xc } },\n        4\n    );\n}\n\n#[test]\nfn test_mul32_reg_overflow() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov r0, 0x40000001\n        mov r1, 4\n        mul32 r0, r1\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x4 } },\n        4\n    );\n}\n\n#[test]\nfn test_mul64_imm() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov r0, 0x40000001\n        mul r0, 4\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x100000004 } },\n        3\n    );\n}\n\n#[test]\nfn test_mul64_reg() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov r0, 0x40000001\n        mov r1, 4\n        mul r0, r1\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x100000004 } },\n        4\n    );\n}\n\n#[test]\nfn test_div32_high_divisor() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov r0, 12\n        lddw r1, 0x100000004\n        div32 r0, r1\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x3 } },\n        4\n    );\n}\n\n#[test]\nfn test_div32_imm() {\n    test_interpreter_and_jit_asm!(\n        \"\n        lddw r0, 0x10000000c\n        div32 r0, 4\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x3 } },\n        3\n    );\n}\n\n#[test]\nfn test_div32_reg() {\n    test_interpreter_and_jit_asm!(\n        \"\n        lddw r0, 0x10000000c\n        mov r1, 4\n        div32 r0, r1\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x3 } },\n        4\n    );\n}\n\n#[test]\nfn test_sdiv32_imm() {\n    test_interpreter_and_jit_asm!(\n        \"\n        lddw r0, 0x10000000c\n        sdiv32 r0, 4\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x3 } },\n        3\n    );\n}\n\n#[test]\nfn test_sdiv32_neg_imm() {\n    test_interpreter_and_jit_asm!(\n        \"\n        lddw r0, 0x10000000c\n        sdiv32 r0, -4\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() as i64 == -3 } },\n        3\n    );\n}\n\n#[test]\nfn test_sdiv32_reg() {\n    test_interpreter_and_jit_asm!(\n        \"\n        lddw r0, 0x10000000c\n        mov r1, 4\n        sdiv32 r0, r1\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x3 } },\n        4\n    );\n}\n\n#[test]\nfn test_sdiv32_neg_reg() {\n    test_interpreter_and_jit_asm!(\n        \"\n        lddw r0, 0x10000000c\n        mov r1, -4\n        sdiv32 r0, r1\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() as i64 == -0x3 } },\n        4\n    );\n}\n\n#[test]\nfn test_div64_imm() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov r0, 0xc\n        lsh r0, 32\n        div r0, 4\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x300000000 } },\n        4\n    );\n}\n\n#[test]\nfn test_div64_reg() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov r0, 0xc\n        lsh r0, 32\n        mov r1, 4\n        div r0, r1\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x300000000 } },\n        5\n    );\n}\n\n#[test]\nfn test_sdiv64_imm() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov r0, 0xc\n        lsh r0, 32\n        sdiv r0, 4\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x300000000 } },\n        4\n    );\n}\n\n#[test]\nfn test_sdiv64_reg() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov r0, 0xc\n        lsh r0, 32\n        mov r1, 4\n        sdiv r0, r1\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x300000000 } },\n        5\n    );\n}\n\n#[test]\nfn test_err_div64_by_zero_reg() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov32 r0, 1\n        mov32 r1, 0\n        div r0, r1\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| matches!(res.unwrap_err(), EbpfError::DivideByZero(pc) if pc == 31) },\n        3\n    );\n}\n\n#[test]\nfn test_err_div32_by_zero_reg() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov32 r0, 1\n        mov32 r1, 0\n        div32 r0, r1\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| matches!(res.unwrap_err(), EbpfError::DivideByZero(pc) if pc == 31) },\n        3\n    );\n}\n\n#[test]\nfn test_err_sdiv64_by_zero_reg() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov32 r0, 1\n        mov32 r1, 0\n        sdiv r0, r1\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| matches!(res.unwrap_err(), EbpfError::DivideByZero(pc) if pc == 31) },\n        3\n    );\n}\n\n#[test]\nfn test_err_sdiv32_by_zero_reg() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov32 r0, 1\n        mov32 r1, 0\n        sdiv32 r0, r1\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| matches!(res.unwrap_err(), EbpfError::DivideByZero(pc) if pc == 31) },\n        3\n    );\n}\n\n#[test]\nfn test_err_sdiv64_overflow_imm() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov r0, 0x80\n        lsh r0, 56\n        sdiv r0, -1\n        exit\",\n        [],\n        (),\n        0,\n        {\n            |_vm, res: Result| matches!(res.unwrap_err(), EbpfError::DivideOverflow(pc) if pc == 31)\n        },\n        3\n    );\n}\n\n#[test]\nfn test_err_sdiv64_overflow_reg() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov r0, 0x80\n        lsh r0, 56\n        mov r1, -1\n        sdiv r0, r1\n        exit\",\n        [],\n        (),\n        0,\n        {\n            |_vm, res: Result| matches!(res.unwrap_err(), EbpfError::DivideOverflow(pc) if pc == 32)\n        },\n        4\n    );\n}\n\n#[test]\nfn test_err_sdiv32_overflow_imm() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov r0, 0x80\n        lsh r0, 24\n        sdiv32 r0, -1\n        exit\",\n        [],\n        (),\n        0,\n        {\n            |_vm, res: Result| matches!(res.unwrap_err(), EbpfError::DivideOverflow(pc) if pc == 31)\n        },\n        3\n    );\n}\n\n#[test]\nfn test_err_sdiv32_overflow_reg() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov r0, 0x80\n        lsh r0, 24\n        mov r1, -1\n        sdiv32 r0, r1\n        exit\",\n        [],\n        (),\n        0,\n        {\n            |_vm, res: Result| matches!(res.unwrap_err(), EbpfError::DivideOverflow(pc) if pc == 32)\n        },\n        4\n    );\n}\n\n#[test]\nfn test_mod32() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov32 r0, 5748\n        mod32 r0, 92\n        mov32 r1, 13\n        mod32 r0, r1\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x5 } },\n        5\n    );\n}\n\n#[test]\nfn test_mod32_imm() {\n    test_interpreter_and_jit_asm!(\n        \"\n        lddw r0, 0x100000003\n        mod32 r0, 3\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x0 } },\n        3\n    );\n}\n\n#[test]\nfn test_mod64() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov32 r0, -1316649930\n        lsh r0, 32\n        or r0, 0x100dc5c8\n        mov32 r1, 0xdde263e\n        lsh r1, 32\n        or r1, 0x3cbef7f3\n        mod r0, r1\n        mod r0, 0x658f1778\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x30ba5a04 } },\n        9\n    );\n}\n\n#[test]\nfn test_err_mod64_by_zero_reg() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov32 r0, 1\n        mov32 r1, 0\n        mod r0, r1\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| matches!(res.unwrap_err(), EbpfError::DivideByZero(pc) if pc == 31) },\n        3\n    );\n}\n\n#[test]\nfn test_err_mod_by_zero_reg() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov32 r0, 1\n        mov32 r1, 0\n        mod32 r0, r1\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| matches!(res.unwrap_err(), EbpfError::DivideByZero(pc) if pc == 31) },\n        3\n    );\n}\n\n// BPF_LD : Loads\n\n#[test]\nfn test_ldabsb() {\n    test_interpreter_and_jit_asm!(\n        \"\n        ldabsb 0x3\n        exit\",\n        [\n            0x00, 0x11, 0x22, 0x33, 0x44, 0x55, 0x66, 0x77, //\n            0x88, 0x99, 0xaa, 0xbb, 0xcc, 0xdd, 0xee, 0xff, //\n        ],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x33 } },\n        2\n    );\n}\n\n#[test]\nfn test_ldabsh() {\n    test_interpreter_and_jit_asm!(\n        \"\n        ldabsh 0x3\n        exit\",\n        [\n            0x00, 0x11, 0x22, 0x33, 0x44, 0x55, 0x66, 0x77, //\n            0x88, 0x99, 0xaa, 0xbb, 0xcc, 0xdd, 0xee, 0xff, //\n        ],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x4433 } },\n        2\n    );\n}\n\n#[test]\nfn test_ldabsw() {\n    test_interpreter_and_jit_asm!(\n        \"\n        ldabsw 0x3\n        exit\",\n        [\n            0x00, 0x11, 0x22, 0x33, 0x44, 0x55, 0x66, 0x77, //\n            0x88, 0x99, 0xaa, 0xbb, 0xcc, 0xdd, 0xee, 0xff, //\n        ],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x66554433 } },\n        2\n    );\n}\n\n#[test]\nfn test_ldabsdw() {\n    test_interpreter_and_jit_asm!(\n        \"\n        ldabsdw 0x3\n        exit\",\n        [\n            0x00, 0x11, 0x22, 0x33, 0x44, 0x55, 0x66, 0x77, //\n            0x88, 0x99, 0xaa, 0xbb, 0xcc, 0xdd, 0xee, 0xff, //\n        ],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0xaa99887766554433 } },\n        2\n    );\n}\n\n#[test]\nfn test_err_ldabsb_oob() {\n    test_interpreter_and_jit_asm!(\n        \"\n        ldabsb 0x33\n        exit\",\n        [\n            0x00, 0x11, 0x22, 0x33, 0x44, 0x55, 0x66, 0x77, //\n            0x88, 0x99, 0xaa, 0xbb, 0xcc, 0xdd, 0xee, 0xff, //\n        ],\n        (),\n        0,\n        {\n            |_vm, res: Result| {\n                matches!(res.unwrap_err(),\n                    EbpfError::AccessViolation(pc, access_type, vm_addr, len, name)\n                    if access_type == AccessType::Load && pc == 29 && vm_addr == 0x400000033 && len == 1 && name == \"input\"\n                )\n            }\n        },\n        1\n    );\n}\n\n#[test]\nfn test_err_ldabsb_nomem() {\n    test_interpreter_and_jit_asm!(\n        \"\n        ldabsb 0x33\n        exit\",\n        [],\n        (),\n        0,\n        {\n            |_vm, res: Result| {\n                matches!(res.unwrap_err(),\n                    EbpfError::AccessViolation(pc, access_type, vm_addr, len, name)\n                    if access_type == AccessType::Load && pc == 29 && vm_addr == 0x400000033 && len == 1 && name == \"input\"\n                )\n            }\n        },\n        1\n    );\n}\n\n#[test]\nfn test_ldindb() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov64 r1, 0x5\n        ldindb r1, 0x3\n        exit\",\n        [\n            0x00, 0x11, 0x22, 0x33, 0x44, 0x55, 0x66, 0x77, //\n            0x88, 0x99, 0xaa, 0xbb, 0xcc, 0xdd, 0xee, 0xff, //\n        ],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x88 } },\n        3\n    );\n}\n\n#[test]\nfn test_ldindh() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov64 r1, 0x5\n        ldindh r1, 0x3\n        exit\",\n        [\n            0x00, 0x11, 0x22, 0x33, 0x44, 0x55, 0x66, 0x77, //\n            0x88, 0x99, 0xaa, 0xbb, 0xcc, 0xdd, 0xee, 0xff, //\n        ],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x9988 } },\n        3\n    );\n}\n\n#[test]\nfn test_ldindw() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov64 r1, 0x4\n        ldindw r1, 0x1\n        exit\",\n        [\n            0x00, 0x11, 0x22, 0x33, 0x44, 0x55, 0x66, 0x77, //\n            0x88, 0x99, 0xaa, 0xbb, 0xcc, 0xdd, 0xee, 0xff, //\n        ],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x88776655 } },\n        3\n    );\n}\n\n#[test]\nfn test_ldinddw() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov64 r1, 0x2\n        ldinddw r1, 0x3\n        exit\",\n        [\n            0x00, 0x11, 0x22, 0x33, 0x44, 0x55, 0x66, 0x77, //\n            0x88, 0x99, 0xaa, 0xbb, 0xcc, 0xdd, 0xee, 0xff, //\n        ],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0xccbbaa9988776655 } },\n        3\n    );\n}\n\n#[test]\nfn test_err_ldindb_oob() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov64 r1, 0x5\n        ldindb r1, 0x33\n        exit\",\n        [\n            0x00, 0x11, 0x22, 0x33, 0x44, 0x55, 0x66, 0x77, //\n            0x88, 0x99, 0xaa, 0xbb, 0xcc, 0xdd, 0xee, 0xff, //\n        ],\n        (),\n        0,\n        {\n            |_vm, res: Result| {\n                matches!(res.unwrap_err(),\n                    EbpfError::AccessViolation(pc, access_type, vm_addr, len, name)\n                    if access_type == AccessType::Load && pc == 30 && vm_addr == 0x400000038 && len == 1 && name == \"input\"\n                )\n            }\n        },\n        2\n    );\n}\n\n#[test]\nfn test_err_ldindb_nomem() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov64 r1, 0x5\n        ldindb r1, 0x33\n        exit\",\n        [],\n        (),\n        0,\n        {\n            |_vm, res: Result| {\n                matches!(res.unwrap_err(),\n                    EbpfError::AccessViolation(pc, access_type, vm_addr, len, name)\n                    if access_type == AccessType::Load && pc == 30 && vm_addr == 0x400000038 && len == 1 && name == \"input\"\n                )\n            }\n        },\n        2\n    );\n}\n\n#[test]\nfn test_ldxb() {\n    test_interpreter_and_jit_asm!(\n        \"\n        ldxb r0, [r1+2]\n        exit\",\n        [0xaa, 0xbb, 0x11, 0xcc, 0xdd],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x11 } },\n        2\n    );\n}\n\n#[test]\nfn test_ldxh() {\n    test_interpreter_and_jit_asm!(\n        \"\n        ldxh r0, [r1+2]\n        exit\",\n        [0xaa, 0xbb, 0x11, 0x22, 0xcc, 0xdd],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x2211 } },\n        2\n    );\n}\n\n#[test]\nfn test_ldxw() {\n    test_interpreter_and_jit_asm!(\n        \"\n        ldxw r0, [r1+2]\n        exit\",\n        [\n            0xaa, 0xbb, 0x11, 0x22, 0x33, 0x44, 0xcc, 0xdd, //\n        ],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x44332211 } },\n        2\n    );\n}\n\n#[test]\nfn test_ldxh_same_reg() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov r0, r1\n        sth [r0], 0x1234\n        ldxh r0, [r0]\n        exit\",\n        [0xff, 0xff],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x1234 } },\n        4\n    );\n}\n\n#[test]\nfn test_lldxdw() {\n    test_interpreter_and_jit_asm!(\n        \"\n        ldxdw r0, [r1+2]\n        exit\",\n        [\n            0xaa, 0xbb, 0x11, 0x22, 0x33, 0x44, 0x55, 0x66, //\n            0x77, 0x88, 0xcc, 0xdd, //\n        ],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x8877665544332211 } },\n        2\n    );\n}\n\n#[test]\nfn test_err_ldxdw_oob() {\n    test_interpreter_and_jit_asm!(\n        \"\n        ldxdw r0, [r1+6]\n        exit\",\n        [\n            0xaa, 0xbb, 0x11, 0x22, 0x33, 0x44, 0x55, 0x66, //\n            0x77, 0x88, 0xcc, 0xdd, //\n        ],\n        (),\n        0,\n        {\n            |_vm, res: Result| {\n                matches!(res.unwrap_err(),\n                    EbpfError::AccessViolation(pc, access_type, vm_addr, len, name)\n                    if access_type == AccessType::Load && pc == 29 && vm_addr == 0x400000006 && len == 8 && name == \"input\"\n                )\n            }\n        },\n        1\n    );\n}\n\n#[test]\nfn test_ldxb_all() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov r0, r1\n        ldxb r9, [r0+0]\n        lsh r9, 0\n        ldxb r8, [r0+1]\n        lsh r8, 4\n        ldxb r7, [r0+2]\n        lsh r7, 8\n        ldxb r6, [r0+3]\n        lsh r6, 12\n        ldxb r5, [r0+4]\n        lsh r5, 16\n        ldxb r4, [r0+5]\n        lsh r4, 20\n        ldxb r3, [r0+6]\n        lsh r3, 24\n        ldxb r2, [r0+7]\n        lsh r2, 28\n        ldxb r1, [r0+8]\n        lsh r1, 32\n        ldxb r0, [r0+9]\n        lsh r0, 36\n        or r0, r1\n        or r0, r2\n        or r0, r3\n        or r0, r4\n        or r0, r5\n        or r0, r6\n        or r0, r7\n        or r0, r8\n        or r0, r9\n        exit\",\n        [\n            0x00, 0x01, 0x02, 0x03, 0x04, 0x05, 0x06, 0x07, //\n            0x08, 0x09, //\n        ],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x9876543210 } },\n        31\n    );\n}\n\n#[test]\nfn test_ldxh_all() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov r0, r1\n        ldxh r9, [r0+0]\n        be16 r9\n        lsh r9, 0\n        ldxh r8, [r0+2]\n        be16 r8\n        lsh r8, 4\n        ldxh r7, [r0+4]\n        be16 r7\n        lsh r7, 8\n        ldxh r6, [r0+6]\n        be16 r6\n        lsh r6, 12\n        ldxh r5, [r0+8]\n        be16 r5\n        lsh r5, 16\n        ldxh r4, [r0+10]\n        be16 r4\n        lsh r4, 20\n        ldxh r3, [r0+12]\n        be16 r3\n        lsh r3, 24\n        ldxh r2, [r0+14]\n        be16 r2\n        lsh r2, 28\n        ldxh r1, [r0+16]\n        be16 r1\n        lsh r1, 32\n        ldxh r0, [r0+18]\n        be16 r0\n        lsh r0, 36\n        or r0, r1\n        or r0, r2\n        or r0, r3\n        or r0, r4\n        or r0, r5\n        or r0, r6\n        or r0, r7\n        or r0, r8\n        or r0, r9\n        exit\",\n        [\n            0x00, 0x00, 0x00, 0x01, 0x00, 0x02, 0x00, 0x03, //\n            0x00, 0x04, 0x00, 0x05, 0x00, 0x06, 0x00, 0x07, //\n            0x00, 0x08, 0x00, 0x09, //\n        ],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x9876543210 } },\n        41\n    );\n}\n\n#[test]\nfn test_ldxh_all2() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov r0, r1\n        ldxh r9, [r0+0]\n        be16 r9\n        ldxh r8, [r0+2]\n        be16 r8\n        ldxh r7, [r0+4]\n        be16 r7\n        ldxh r6, [r0+6]\n        be16 r6\n        ldxh r5, [r0+8]\n        be16 r5\n        ldxh r4, [r0+10]\n        be16 r4\n        ldxh r3, [r0+12]\n        be16 r3\n        ldxh r2, [r0+14]\n        be16 r2\n        ldxh r1, [r0+16]\n        be16 r1\n        ldxh r0, [r0+18]\n        be16 r0\n        or r0, r1\n        or r0, r2\n        or r0, r3\n        or r0, r4\n        or r0, r5\n        or r0, r6\n        or r0, r7\n        or r0, r8\n        or r0, r9\n        exit\",\n        [\n            0x00, 0x01, 0x00, 0x02, 0x00, 0x04, 0x00, 0x08, //\n            0x00, 0x10, 0x00, 0x20, 0x00, 0x40, 0x00, 0x80, //\n            0x01, 0x00, 0x02, 0x00, //\n        ],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x3ff } },\n        31\n    );\n}\n\n#[test]\nfn test_ldxw_all() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov r0, r1\n        ldxw r9, [r0+0]\n        be32 r9\n        ldxw r8, [r0+4]\n        be32 r8\n        ldxw r7, [r0+8]\n        be32 r7\n        ldxw r6, [r0+12]\n        be32 r6\n        ldxw r5, [r0+16]\n        be32 r5\n        ldxw r4, [r0+20]\n        be32 r4\n        ldxw r3, [r0+24]\n        be32 r3\n        ldxw r2, [r0+28]\n        be32 r2\n        ldxw r1, [r0+32]\n        be32 r1\n        ldxw r0, [r0+36]\n        be32 r0\n        or r0, r1\n        or r0, r2\n        or r0, r3\n        or r0, r4\n        or r0, r5\n        or r0, r6\n        or r0, r7\n        or r0, r8\n        or r0, r9\n        exit\",\n        [\n            0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x02, //\n            0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00, 0x08, //\n            0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x02, 0x00, //\n            0x00, 0x00, 0x04, 0x00, 0x00, 0x00, 0x08, 0x00, //\n            0x00, 0x01, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, //\n        ],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x030f0f } },\n        31\n    );\n}\n\n#[test]\nfn test_lddw() {\n    test_interpreter_and_jit_asm!(\n        \"\n        lddw r0, 0x1122334455667788\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x1122334455667788 } },\n        2\n    );\n    test_interpreter_and_jit_asm!(\n        \"\n        lddw r0, 0x0000000080000000\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x80000000 } },\n        2\n    );\n}\n\n#[test]\nfn test_stb() {\n    test_interpreter_and_jit_asm!(\n        \"\n        stb [r1+2], 0x11\n        ldxb r0, [r1+2]\n        exit\",\n        [0xaa, 0xbb, 0xff, 0xcc, 0xdd],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x11 } },\n        3\n    );\n}\n\n#[test]\nfn test_sth() {\n    test_interpreter_and_jit_asm!(\n        \"\n        sth [r1+2], 0x2211\n        ldxh r0, [r1+2]\n        exit\",\n        [\n            0xaa, 0xbb, 0xff, 0xff, 0xcc, 0xdd, //\n        ],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x2211 } },\n        3\n    );\n}\n\n#[test]\nfn test_stw() {\n    test_interpreter_and_jit_asm!(\n        \"\n        stw [r1+2], 0x44332211\n        ldxw r0, [r1+2]\n        exit\",\n        [\n            0xaa, 0xbb, 0xff, 0xff, 0xff, 0xff, 0xcc, 0xdd, //\n        ],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x44332211 } },\n        3\n    );\n}\n\n#[test]\nfn test_stdw() {\n    test_interpreter_and_jit_asm!(\n        \"\n        stdw [r1+2], 0x44332211\n        ldxdw r0, [r1+2]\n        exit\",\n        [\n            0xaa, 0xbb, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, //\n            0xff, 0xff, 0xcc, 0xdd, //\n        ],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x44332211 } },\n        3\n    );\n}\n\n#[test]\nfn test_stxb() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov32 r2, 0x11\n        stxb [r1+2], r2\n        ldxb r0, [r1+2]\n        exit\",\n        [\n            0xaa, 0xbb, 0xff, 0xcc, 0xdd, //\n        ],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x11 } },\n        4\n    );\n}\n\n#[test]\nfn test_stxh() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov32 r2, 0x2211\n        stxh [r1+2], r2\n        ldxh r0, [r1+2]\n        exit\",\n        [\n            0xaa, 0xbb, 0xff, 0xff, 0xcc, 0xdd, //\n        ],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x2211 } },\n        4\n    );\n}\n\n#[test]\nfn test_stxw() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov32 r2, 0x44332211\n        stxw [r1+2], r2\n        ldxw r0, [r1+2]\n        exit\",\n        [\n            0xaa, 0xbb, 0xff, 0xff, 0xff, 0xff, 0xcc, 0xdd, //\n        ],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x44332211 } },\n        4\n    );\n}\n\n#[test]\nfn test_stxdw() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov r2, -2005440939\n        lsh r2, 32\n        or r2, 0x44332211\n        stxdw [r1+2], r2\n        ldxdw r0, [r1+2]\n        exit\",\n        [\n            0xaa, 0xbb, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, //\n            0xff, 0xff, 0xcc, 0xdd, //\n        ],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x8877665544332211 } },\n        6\n    );\n}\n\n#[test]\nfn test_stxb_all() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov r0, 0xf0\n        mov r2, 0xf2\n        mov r3, 0xf3\n        mov r4, 0xf4\n        mov r5, 0xf5\n        mov r6, 0xf6\n        mov r7, 0xf7\n        mov r8, 0xf8\n        stxb [r1], r0\n        stxb [r1+1], r2\n        stxb [r1+2], r3\n        stxb [r1+3], r4\n        stxb [r1+4], r5\n        stxb [r1+5], r6\n        stxb [r1+6], r7\n        stxb [r1+7], r8\n        ldxdw r0, [r1]\n        be64 r0\n        exit\",\n        [\n            0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, //\n        ],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0xf0f2f3f4f5f6f7f8 } },\n        19\n    );\n}\n\n#[test]\nfn test_stxb_all2() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov r0, r1\n        mov r1, 0xf1\n        mov r9, 0xf9\n        stxb [r0], r1\n        stxb [r0+1], r9\n        ldxh r0, [r0]\n        be16 r0\n        exit\",\n        [0xff, 0xff],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0xf1f9 } },\n        8\n    );\n}\n\n#[test]\nfn test_stxb_chain() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov r0, r1\n        ldxb r9, [r0+0]\n        stxb [r0+1], r9\n        ldxb r8, [r0+1]\n        stxb [r0+2], r8\n        ldxb r7, [r0+2]\n        stxb [r0+3], r7\n        ldxb r6, [r0+3]\n        stxb [r0+4], r6\n        ldxb r5, [r0+4]\n        stxb [r0+5], r5\n        ldxb r4, [r0+5]\n        stxb [r0+6], r4\n        ldxb r3, [r0+6]\n        stxb [r0+7], r3\n        ldxb r2, [r0+7]\n        stxb [r0+8], r2\n        ldxb r1, [r0+8]\n        stxb [r0+9], r1\n        ldxb r0, [r0+9]\n        exit\",\n        [\n            0x2a, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, //\n            0x00, 0x00, //\n        ],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x2a } },\n        21\n    );\n}\n\n// BPF_JMP : Branches\n\n#[test]\nfn test_exit_without_value() {\n    test_interpreter_and_jit_asm!(\n        \"\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x0 } },\n        1\n    );\n}\n\n#[test]\nfn test_exit() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov r0, 0\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x0 } },\n        2\n    );\n}\n\n#[test]\nfn test_early_exit() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov r0, 3\n        exit\n        mov r0, 4\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x3 } },\n        2\n    );\n}\n\n#[test]\nfn test_ja() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov r0, 1\n        ja +1\n        mov r0, 2\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x1 } },\n        3\n    );\n}\n\n#[test]\nfn test_jeq_imm() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov32 r0, 0\n        mov32 r1, 0xa\n        jeq r1, 0xb, +4\n        mov32 r0, 1\n        mov32 r1, 0xb\n        jeq r1, 0xb, +1\n        mov32 r0, 2\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x1 } },\n        7\n    );\n}\n\n#[test]\nfn test_jeq_reg() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov32 r0, 0\n        mov32 r1, 0xa\n        mov32 r2, 0xb\n        jeq r1, r2, +4\n        mov32 r0, 1\n        mov32 r1, 0xb\n        jeq r1, r2, +1\n        mov32 r0, 2\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x1 } },\n        8\n    );\n}\n\n#[test]\nfn test_jge_imm() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov32 r0, 0\n        mov32 r1, 0xa\n        jge r1, 0xb, +4\n        mov32 r0, 1\n        mov32 r1, 0xc\n        jge r1, 0xb, +1\n        mov32 r0, 2\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x1 } },\n        7\n    );\n}\n\n#[test]\nfn test_jge_reg() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov32 r0, 0\n        mov32 r1, 0xa\n        mov32 r2, 0xb\n        jge r1, r2, +4\n        mov32 r0, 1\n        mov32 r1, 0xb\n        jge r1, r2, +1\n        mov32 r0, 2\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x1 } },\n        8\n    );\n}\n\n#[test]\nfn test_jle_imm() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov32 r0, 0\n        mov32 r1, 5\n        jle r1, 4, +1\n        jle r1, 6, +1\n        exit\n        jle r1, 5, +1\n        exit\n        mov32 r0, 1\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x1 } },\n        7\n    );\n}\n\n#[test]\nfn test_jle_reg() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov r0, 0\n        mov r1, 5\n        mov r2, 4\n        mov r3, 6\n        jle r1, r2, +2\n        jle r1, r1, +1\n        exit\n        jle r1, r3, +1\n        exit\n        mov r0, 1\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x1 } },\n        9\n    );\n}\n\n#[test]\nfn test_jgt_imm() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov32 r0, 0\n        mov32 r1, 5\n        jgt r1, 6, +2\n        jgt r1, 5, +1\n        jgt r1, 4, +1\n        exit\n        mov32 r0, 1\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x1 } },\n        7\n    );\n}\n\n#[test]\nfn test_jgt_reg() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov r0, 0\n        mov r1, 5\n        mov r2, 6\n        mov r3, 4\n        jgt r1, r2, +2\n        jgt r1, r1, +1\n        jgt r1, r3, +1\n        exit\n        mov r0, 1\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x1 } },\n        9\n    );\n}\n\n#[test]\nfn test_jlt_imm() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov32 r0, 0\n        mov32 r1, 5\n        jlt r1, 4, +2\n        jlt r1, 5, +1\n        jlt r1, 6, +1\n        exit\n        mov32 r0, 1\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x1 } },\n        7\n    );\n}\n\n#[test]\nfn test_jlt_reg() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov r0, 0\n        mov r1, 5\n        mov r2, 4\n        mov r3, 6\n        jlt r1, r2, +2\n        jlt r1, r1, +1\n        jlt r1, r3, +1\n        exit\n        mov r0, 1\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x1 } },\n        9\n    );\n}\n\n#[test]\nfn test_jne_imm() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov32 r0, 0\n        mov32 r1, 0xb\n        jne r1, 0xb, +4\n        mov32 r0, 1\n        mov32 r1, 0xa\n        jne r1, 0xb, +1\n        mov32 r0, 2\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x1 } },\n        7\n    );\n}\n\n#[test]\nfn test_jne_reg() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov32 r0, 0\n        mov32 r1, 0xb\n        mov32 r2, 0xb\n        jne r1, r2, +4\n        mov32 r0, 1\n        mov32 r1, 0xa\n        jne r1, r2, +1\n        mov32 r0, 2\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x1 } },\n        8\n    );\n}\n\n#[test]\nfn test_jset_imm() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov32 r0, 0\n        mov32 r1, 0x7\n        jset r1, 0x8, +4\n        mov32 r0, 1\n        mov32 r1, 0x9\n        jset r1, 0x8, +1\n        mov32 r0, 2\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x1 } },\n        7\n    );\n}\n\n#[test]\nfn test_jset_reg() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov32 r0, 0\n        mov32 r1, 0x7\n        mov32 r2, 0x8\n        jset r1, r2, +4\n        mov32 r0, 1\n        mov32 r1, 0x9\n        jset r1, r2, +1\n        mov32 r0, 2\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x1 } },\n        8\n    );\n}\n\n#[test]\nfn test_jsge_imm() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov32 r0, 0\n        mov r1, -2\n        jsge r1, -1, +5\n        jsge r1, 0, +4\n        mov32 r0, 1\n        mov r1, -1\n        jsge r1, -1, +1\n        mov32 r0, 2\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x1 } },\n        8\n    );\n}\n\n#[test]\nfn test_jsge_reg() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov32 r0, 0\n        mov r1, -2\n        mov r2, -1\n        mov32 r3, 0\n        jsge r1, r2, +5\n        jsge r1, r3, +4\n        mov32 r0, 1\n        mov r1, r2\n        jsge r1, r2, +1\n        mov32 r0, 2\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x1 } },\n        10\n    );\n}\n\n#[test]\nfn test_jsle_imm() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov32 r0, 0\n        mov r1, -2\n        jsle r1, -3, +1\n        jsle r1, -1, +1\n        exit\n        mov32 r0, 1\n        jsle r1, -2, +1\n        mov32 r0, 2\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x1 } },\n        7\n    );\n}\n\n#[test]\nfn test_jsle_reg() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov32 r0, 0\n        mov r1, -1\n        mov r2, -2\n        mov32 r3, 0\n        jsle r1, r2, +1\n        jsle r1, r3, +1\n        exit\n        mov32 r0, 1\n        mov r1, r2\n        jsle r1, r2, +1\n        mov32 r0, 2\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x1 } },\n        10\n    );\n}\n\n#[test]\nfn test_jsgt_imm() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov32 r0, 0\n        mov r1, -2\n        jsgt r1, -1, +4\n        mov32 r0, 1\n        mov32 r1, 0\n        jsgt r1, -1, +1\n        mov32 r0, 2\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x1 } },\n        7\n    );\n}\n\n#[test]\nfn test_jsgt_reg() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov32 r0, 0\n        mov r1, -2\n        mov r2, -1\n        jsgt r1, r2, +4\n        mov32 r0, 1\n        mov32 r1, 0\n        jsgt r1, r2, +1\n        mov32 r0, 2\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x1 } },\n        8\n    );\n}\n\n#[test]\nfn test_jslt_imm() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov32 r0, 0\n        mov r1, -2\n        jslt r1, -3, +2\n        jslt r1, -2, +1\n        jslt r1, -1, +1\n        exit\n        mov32 r0, 1\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x1 } },\n        7\n    );\n}\n\n#[test]\nfn test_jslt_reg() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov32 r0, 0\n        mov r1, -2\n        mov r2, -3\n        mov r3, -1\n        jslt r1, r1, +2\n        jslt r1, r2, +1\n        jslt r1, r3, +1\n        exit\n        mov32 r0, 1\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x1 } },\n        9\n    );\n}\n\n// Call Stack\n\n#[test]\nfn test_stack1() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov r1, 51\n        stdw [r10-16], 0xab\n        stdw [r10-8], 0xcd\n        and r1, 1\n        lsh r1, 3\n        mov r2, r10\n        add r2, r1\n        ldxdw r0, [r2-16]\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0xcd } },\n        9\n    );\n}\n\n#[test]\nfn test_stack2() {\n    test_interpreter_and_jit_asm!(\n        \"\n        stb [r10-4], 0x01\n        stb [r10-3], 0x02\n        stb [r10-2], 0x03\n        stb [r10-1], 0x04\n        mov r1, r10\n        mov r2, 0x4\n        sub r1, r2\n        syscall BpfMemFrob\n        mov r1, 0\n        ldxb r2, [r10-4]\n        ldxb r3, [r10-3]\n        ldxb r4, [r10-2]\n        ldxb r5, [r10-1]\n        syscall BpfGatherBytes\n        xor r0, 0x2a2a2a2a\n        exit\",\n        [],\n        (\n            b\"BpfMemFrob\" => syscalls::BpfMemFrob::init::<BpfSyscallContext, UserError>; syscalls::BpfMemFrob::call,\n            b\"BpfGatherBytes\" => syscalls::BpfGatherBytes::init::<BpfSyscallContext, UserError>; syscalls::BpfGatherBytes::call,\n        ),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x01020304 } },\n        16\n    );\n}\n\n#[test]\nfn test_string_stack() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov r1, 0x78636261\n        stxw [r10-8], r1\n        mov r6, 0x0\n        stxb [r10-4], r6\n        stxb [r10-12], r6\n        mov r1, 0x79636261\n        stxw [r10-16], r1\n        mov r1, r10\n        add r1, -8\n        mov r2, r1\n        syscall BpfStrCmp\n        mov r1, r0\n        mov r0, 0x1\n        lsh r1, 0x20\n        rsh r1, 0x20\n        jne r1, 0x0, +11\n        mov r1, r10\n        add r1, -8\n        mov r2, r10\n        add r2, -16\n        syscall BpfStrCmp\n        mov r1, r0\n        lsh r1, 0x20\n        rsh r1, 0x20\n        mov r0, 0x1\n        jeq r1, r6, +1\n        mov r0, 0x0\n        exit\",\n        [],\n        (\n            b\"BpfStrCmp\" => syscalls::BpfStrCmp::init::<BpfSyscallContext, UserError>; syscalls::BpfStrCmp::call,\n        ),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x0 } },\n        28\n    );\n}\n\n#[test]\nfn test_err_fixed_stack_out_of_bound() {\n    let config = Config {\n        dynamic_stack_frames: false,\n        max_call_depth: 3,\n        ..Config::default()\n    };\n    test_interpreter_and_jit_asm!(\n        \"\n        stb [r10-0x4000], 0\n        exit\",\n        config,\n        [],\n        (),\n        0,\n        {\n            |_vm, res: Result| {\n                matches!(res.unwrap_err(),\n                    EbpfError::AccessViolation(pc, access_type, vm_addr, len, name)\n                    if access_type == AccessType::Store && pc == 29 && vm_addr == 0x1FFFFD000 && len == 1 && name == \"program\"\n                )\n            }\n        },\n        1\n    );\n}\n\n#[test]\nfn test_err_dynamic_stack_out_of_bound() {\n    let config = Config {\n        dynamic_stack_frames: true,\n        max_call_depth: 3,\n        ..Config::default()\n    };\n\n    // The stack goes from MM_STACK_START + config.stack_size() to MM_STACK_START\n\n    // Check that accessing MM_STACK_START - 1 fails\n    test_interpreter_and_jit_asm!(\n        \"\n        stb [r10-0x3001], 0\n        exit\",\n        config,\n        [],\n        (),\n        0,\n        {\n            |_vm, res: Result| {\n                matches!(res.unwrap_err(),\n                    EbpfError::AccessViolation(pc, access_type, vm_addr, len, region)\n                    if access_type == AccessType::Store && pc == 29 && vm_addr == ebpf::MM_STACK_START - 1 && len == 1 && region == \"program\"\n                )\n            }\n        },\n        1\n    );\n\n    // Check that accessing MM_STACK_START + expected_stack_len fails\n    test_interpreter_and_jit_asm!(\n        \"\n        stb [r10], 0\n        exit\",\n        config,\n        [],\n        (),\n        0,\n        {\n            |_vm, res: Result| {\n                matches!(res.unwrap_err(),\n                    EbpfError::AccessViolation(pc, access_type, vm_addr, len, region)\n                    if access_type == AccessType::Store && pc == 29 && vm_addr == ebpf::MM_STACK_START + config.stack_size() as u64 && len == 1 && region == \"stack\"\n                )\n            }\n        },\n        1\n    );\n}\n\n#[test]\nfn test_err_dynamic_stack_ptr_overflow() {\n    let config = Config {\n        dynamic_stack_frames: true,\n        ..Config::default()\n    };\n\n    // See the comment in CallFrames::resize_stack() for the reason why it's\n    // safe to let the stack pointer overflow\n\n    // stack_ptr -= stack_ptr + 1\n    test_interpreter_and_jit_asm!(\n        \"\n        sub r11, 0x7FFFFFFF\n        sub r11, 0x7FFFFFFF\n        sub r11, 0x7FFFFFFF\n        sub r11, 0x7FFFFFFF\n        sub r11, 0x14005\n        call foo\n        exit\n        foo:\n        stb [r10], 0\n        exit\",\n        config,\n        [],\n        (),\n        0,\n        {\n            |_vm, res: Result| {\n                matches!(res.unwrap_err(),\n                    EbpfError::AccessViolation(pc, access_type, vm_addr, len, region)\n                    if access_type == AccessType::Store && pc == 29 + 7 && vm_addr == u64::MAX && len == 1 && region == \"unknown\"\n                )\n            }\n        },\n        7\n    );\n}\n\n#[test]\nfn test_dynamic_stack_frames_empty() {\n    let config = Config {\n        dynamic_stack_frames: true,\n        ..Config::default()\n    };\n\n    // Check that unless explicitly resized the stack doesn't grow\n    test_interpreter_and_jit_asm!(\n        \"\n        call foo\n        exit\n        foo:\n        mov r0, r10\n        exit\",\n        config,\n        [],\n        (),\n        0,\n        { |_vm, res: Result| res.unwrap() == ebpf::MM_STACK_START + config.stack_size() as u64 },\n        4\n    );\n}\n\n#[test]\nfn test_dynamic_frame_ptr() {\n    let config = Config {\n        dynamic_stack_frames: true,\n        ..Config::default()\n    };\n\n    // Check that upon entering a function (foo) the frame pointer is advanced\n    // to the top of the stack\n    test_interpreter_and_jit_asm!(\n        \"\n        sub r11, 8\n        call foo\n        exit\n        foo:\n        mov r0, r10\n        exit\",\n        config,\n        [],\n        (),\n        0,\n        {\n            |_vm, res: Result| res.unwrap() == ebpf::MM_STACK_START + config.stack_size() as u64 - 8\n        },\n        5\n    );\n\n    // And check that when exiting a function (foo) the caller's frame pointer\n    // is restored\n    test_interpreter_and_jit_asm!(\n        \"\n        sub r11, 8\n        call foo\n        mov r0, r10\n        exit\n        foo:\n        exit\n        \",\n        config,\n        [],\n        (),\n        0,\n        { |_vm, res: Result| res.unwrap() == ebpf::MM_STACK_START + config.stack_size() as u64 },\n        5\n    );\n}\n\n#[test]\nfn test_entrypoint_exit() {\n    // With fixed frames we used to exit the entrypoint when we reached an exit\n    // instruction and the stack size was 1 * config.stack_frame_size, which\n    // meant that we were in the entrypoint's frame.  With dynamic frames we\n    // can't infer anything from the stack size so we track call depth\n    // explicitly. Make sure exit still works with both fixed and dynamic\n    // frames.\n    for dynamic_stack_frames in [false, true] {\n        let config = Config {\n            dynamic_stack_frames,\n            ..Config::default()\n        };\n\n        // This checks that when foo exits we don't stop execution even if the\n        // stack is empty (stack size and call depth are decoupled)\n        test_interpreter_and_jit_asm!(\n            \"\n            entrypoint:\n            call foo\n            mov r0, 42\n            exit\n            foo:\n            mov r0, 12\n            exit\",\n            config,\n            [],\n            (),\n            0,\n            { |_vm, res: Result| { res.unwrap() == 42 } },\n            5\n        );\n    }\n}\n\n#[test]\nfn test_stack_call_depth_tracking() {\n    for dynamic_stack_frames in [false, true] {\n        let config = Config {\n            dynamic_stack_frames,\n            max_call_depth: 2,\n            ..Config::default()\n        };\n\n        // Given max_call_depth=2, make sure that two sibling calls don't\n        // trigger CallDepthExceeded. In other words ensure that we correctly\n        // pop frames in the interpreter and decrement\n        // EnvironmentStackSlot::CallDepth on ebpf::EXIT in the jit.\n        test_interpreter_and_jit_asm!(\n            \"\n            call foo\n            call foo\n            exit\n            foo:\n            exit\n            \",\n            config,\n            [],\n            (),\n            0,\n            { |_vm, res: Result| { res.is_ok() } },\n            5\n        );\n\n        // two nested calls should trigger CallDepthExceeded instead\n        test_interpreter_and_jit_asm!(\n            \"\n            entrypoint:\n            call foo\n            exit\n            foo:\n            call bar\n            exit\n            bar:\n            exit\n            \",\n            config,\n            [],\n            (),\n            0,\n            {\n                |_vm, res: Result| {\n                    matches!(res.unwrap_err(),\n                        EbpfError::CallDepthExceeded(pc, depth)\n                        if pc == 29 + 2 && depth == config.max_call_depth\n                    )\n                }\n            },\n            2\n        );\n    }\n}\n\n#[test]\nfn test_err_mem_access_out_of_bound() {\n    let mem = [0; 512];\n    let mut prog = [0; 32];\n    prog[0] = ebpf::LD_DW_IMM;\n    prog[16] = ebpf::ST_B_IMM;\n    prog[24] = ebpf::EXIT;\n    for address in [0x2u64, 0x8002u64, 0x80000002u64, 0x8000000000000002u64] {\n        LittleEndian::write_u32(&mut prog[4..], address as u32);\n        LittleEndian::write_u32(&mut prog[12..], (address >> 32) as u32);\n        let config = Config::default();\n        let mut bpf_functions = BTreeMap::new();\n        let syscall_registry = SyscallRegistry::default();\n        register_bpf_function(\n            &config,\n            &mut bpf_functions,\n            &syscall_registry,\n            0,\n            \"entrypoint\",\n        )\n        .unwrap();\n        #[allow(unused_mut)]\n        let mut executable = Executable::<UserError, TestInstructionMeter>::from_text_bytes(\n            &prog,\n            None,\n            config,\n            syscall_registry,\n            bpf_functions,\n        )\n        .unwrap();\n        test_interpreter_and_jit!(\n            executable,\n            mem,\n            0,\n            {\n                |_vm, res: Result| {\n                    matches!(res.unwrap_err(),\n                        EbpfError::AccessViolation(pc, access_type, vm_addr, len, name)\n                        if access_type == AccessType::Store && pc == 31 && vm_addr == address && len == 1 && name == \"unknown\"\n                    )\n                }\n            },\n            2\n        );\n    }\n}\n\n// CALL_IMM & CALL_REG : Procedure Calls\n\n#[test]\nfn test_relative_call() {\n    let config = Config {\n        static_syscalls: false,\n        ..Config::default()\n    };\n    test_interpreter_and_jit_elf!(\n        \"tests/elfs/relative_call.so\",\n        config,\n        [1],\n        (\n            b\"log\" => syscalls::BpfSyscallString::init::<BpfSyscallContext, UserError>; syscalls::BpfSyscallString::call,\n        ),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 2 } },\n        14\n    );\n}\n\n#[test]\nfn test_bpf_to_bpf_scratch_registers() {\n    let config = Config {\n        static_syscalls: false,\n        ..Config::default()\n    };\n    test_interpreter_and_jit_elf!(\n        \"tests/elfs/scratch_registers.so\",\n        config,\n        [1],\n        (\n            b\"log_64\" => syscalls::BpfSyscallU64::init::<BpfSyscallContext, UserError>; syscalls::BpfSyscallU64::call,\n        ),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 112 } },\n        41\n    );\n}\n\n#[test]\nfn test_bpf_to_bpf_pass_stack_reference() {\n    test_interpreter_and_jit_elf!(\n        \"tests/elfs/pass_stack_reference.so\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| res.unwrap() == 42 },\n        29\n    );\n}\n\n#[test]\nfn test_syscall_parameter_on_stack() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov64 r1, r10\n        add64 r1, -0x100\n        mov64 r2, 0x1\n        syscall BpfSyscallString\n        mov64 r0, 0x0\n        exit\",\n        [],\n        (\n            b\"BpfSyscallString\" => syscalls::BpfSyscallString::init::<BpfSyscallContext, UserError>; syscalls::BpfSyscallString::call,\n        ),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0 } },\n        6\n    );\n}\n\n#[test]\nfn test_call_reg() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov64 r0, 0x0\n        mov64 r8, 0x1\n        lsh64 r8, 0x20\n        or64 r8, 0x30\n        callx r8\n        exit\n        mov64 r0, 0x2A\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 42 } },\n        8\n    );\n}\n\n#[test]\nfn test_err_callx_oob_low() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov64 r0, 0x3\n        callx r0\n        exit\",\n        [],\n        (),\n        0,\n        {\n            |_vm, res: Result| {\n                matches!(res.unwrap_err(),\n                    EbpfError::CallOutsideTextSegment(pc, target_pc)\n                    if pc == 30 && target_pc == 0\n                )\n            }\n        },\n        2\n    );\n}\n\n#[test]\nfn test_err_callx_oob_high() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov64 r0, -0x1\n        lsh64 r0, 0x20\n        or64 r0, 0x3\n        callx r0\n        exit\",\n        [],\n        (),\n        0,\n        {\n            |_vm, res: Result| {\n                matches!(res.unwrap_err(),\n                    EbpfError::CallOutsideTextSegment(pc, target_pc)\n                    if pc == 32 && target_pc == 0xffffffff00000000\n                )\n            }\n        },\n        4\n    );\n}\n\n#[test]\nfn test_err_static_jmp_lddw() {\n    test_interpreter_and_jit_asm!(\n        \"\n        ja 2\n        mov r0, r0\n        lddw r0, 0x1122334455667788\n        exit\n        \",\n        [],\n        (),\n        0,\n        {\n            |_vm, res: Result| {\n                matches!(res.unwrap_err(),\n                    EbpfError::UnsupportedInstruction(pc) if pc == 32\n                )\n            }\n        },\n        2\n    );\n    test_interpreter_and_jit_asm!(\n        \"\n        mov r0, 0\n        mov r1, 0\n        mov r2, 0\n        lddw r0, 0x1\n        ja +2\n        lddw r1, 0x1\n        lddw r2, 0x1\n        add r1, r2\n        add r0, r1\n        exit\n        \",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x2 } },\n        9\n    );\n    test_interpreter_and_jit_asm!(\n        \"\n        jeq r0, 0, 1\n        lddw r0, 0x1122334455667788\n        exit\n        \",\n        [],\n        (),\n        0,\n        {\n            |_vm, res: Result| {\n                matches!(res.unwrap_err(),\n                    EbpfError::UnsupportedInstruction(pc) if pc == 31\n                )\n            }\n        },\n        2\n    );\n    test_interpreter_and_jit_asm!(\n        \"\n        call 3\n        mov r0, r0\n        mov r0, r0\n        lddw r0, 0x1122334455667788\n        exit\n        \",\n        [],\n        (),\n        0,\n        {\n            |_vm, res: Result| {\n                matches!(res.unwrap_err(),\n                    EbpfError::UnsupportedInstruction(pc) if pc == 33\n                )\n            }\n        },\n        2\n    );\n}\n\n#[test]\nfn test_err_dynamic_jmp_lddw() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov64 r8, 0x1\n        lsh64 r8, 0x20\n        or64 r8, 0x28\n        callx r8\n        lddw r0, 0x1122334455667788\n        exit\",\n        [],\n        (),\n        0,\n        {\n            |_vm, res: Result| {\n                matches!(res.unwrap_err(),\n                    EbpfError::UnsupportedInstruction(pc) if pc == 34\n                )\n            }\n        },\n        5\n    );\n    test_interpreter_and_jit_asm!(\n        \"\n        mov64 r1, 0x1\n        lsh64 r1, 0x20\n        or64 r1, 0x38\n        callx r1\n        mov r0, r0\n        mov r0, r0\n        lddw r0, 0x1122334455667788\n        exit\n        \",\n        [],\n        (),\n        0,\n        {\n            |_vm, res: Result| {\n                matches!(res.unwrap_err(),\n                    EbpfError::UnsupportedInstruction(pc) if pc == 36\n                )\n            }\n        },\n        5\n    );\n    test_interpreter_and_jit_asm!(\n        \"\n        lddw r1, 0x100000038\n        callx r1\n        mov r0, r0\n        mov r0, r0\n        exit\n        lddw r0, 0x1122334455667788\n        exit\n        \",\n        [],\n        (),\n        0,\n        {\n            |_vm, res: Result| {\n                matches!(res.unwrap_err(),\n                    EbpfError::UnsupportedInstruction(pc) if pc == 36\n                )\n            }\n        },\n        3\n    );\n}\n\n#[test]\nfn test_bpf_to_bpf_depth() {\n    let config = Config {\n        static_syscalls: false,\n        ..Config::default()\n    };\n    for i in 0..config.max_call_depth {\n        test_interpreter_and_jit_elf!(\n            \"tests/elfs/multiple_file.so\",\n            config,\n            [i as u8],\n            (\n                b\"log\" => syscalls::BpfSyscallString::init::<BpfSyscallContext, UserError>; syscalls::BpfSyscallString::call,\n            ),\n            0,\n            { |_vm, res: Result| { res.unwrap() == 0 } },\n            if i == 0 { 4 } else { 3 + 10 * i as u64 }\n        );\n    }\n}\n\n#[test]\nfn test_err_bpf_to_bpf_too_deep() {\n    let config = Config {\n        static_syscalls: false,\n        ..Config::default()\n    };\n    test_interpreter_and_jit_elf!(\n        \"tests/elfs/multiple_file.so\",\n        config,\n        [config.max_call_depth as u8],\n        (\n            b\"log\" => syscalls::BpfSyscallString::init::<BpfSyscallContext, UserError>; syscalls::BpfSyscallString::call,\n        ),\n        0,\n        {\n            |_vm, res: Result| {\n                matches!(res.unwrap_err(),\n                    EbpfError::CallDepthExceeded(pc, depth)\n                    if pc == 55 && depth == config.max_call_depth\n                )\n            }\n        },\n        176\n    );\n}\n\n#[test]\nfn test_err_reg_stack_depth() {\n    let config = Config::default();\n    test_interpreter_and_jit_asm!(\n        \"\n        mov64 r0, 0x1\n        lsh64 r0, 0x20\n        callx r0\n        exit\",\n        [],\n        (),\n        0,\n        {\n            |_vm, res: Result| {\n                matches!(res.unwrap_err(),\n                    EbpfError::CallDepthExceeded(pc, depth)\n                    if pc == 31 && depth == config.max_call_depth\n                )\n            }\n        },\n        60\n    );\n}\n\n// CALL_IMM : Syscalls\n\n/* TODO: syscalls::trash_registers needs asm!().\n// https://github.com/rust-lang/rust/issues/72016\n#[test]\nfn test_call_save() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov64 r6, 0x1\n        mov64 r7, 0x20\n        mov64 r8, 0x300\n        mov64 r9, 0x4000\n        call 0\n        mov64 r0, 0x0\n        or64 r0, r6\n        or64 r0, r7\n        or64 r0, r8\n        or64 r0, r9\n        exit\",\n        [],\n        (\n            0 => syscalls::trash_registers,\n        ),\n        { |_vm, res: Result| { res.unwrap() == 0 } }\n    );\n}*/\n\n#[test]\nfn test_err_syscall_string() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov64 r1, 0x0\n        syscall BpfSyscallString\n        mov64 r0, 0x0\n        exit\",\n        [72, 101, 108, 108, 111],\n        (\n            b\"BpfSyscallString\" => syscalls::BpfSyscallString::init::<BpfSyscallContext, UserError>; syscalls::BpfSyscallString::call,\n        ),\n        0,\n        {\n            |_vm, res: Result| {\n                matches!(res.unwrap_err(),\n                    EbpfError::AccessViolation(pc, access_type, vm_addr, len, name)\n                    if access_type == AccessType::Load && pc == 0 && vm_addr == 0 && len == 0 && name == \"unknown\"\n                )\n            }\n        },\n        2\n    );\n}\n\n#[test]\nfn test_syscall_string() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov64 r2, 0x5\n        syscall BpfSyscallString\n        mov64 r0, 0x0\n        exit\",\n        [72, 101, 108, 108, 111],\n        (\n            b\"BpfSyscallString\" => syscalls::BpfSyscallString::init::<BpfSyscallContext, UserError>; syscalls::BpfSyscallString::call,\n        ),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0 } },\n        4\n    );\n}\n\n#[test]\nfn test_syscall() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov64 r1, 0xAA\n        mov64 r2, 0xBB\n        mov64 r3, 0xCC\n        mov64 r4, 0xDD\n        mov64 r5, 0xEE\n        syscall BpfSyscallU64\n        mov64 r0, 0x0\n        exit\",\n        [],\n        (\n            b\"BpfSyscallU64\" => syscalls::BpfSyscallU64::init::<BpfSyscallContext, UserError>; syscalls::BpfSyscallU64::call,\n        ),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0 } },\n        8\n    );\n}\n\n#[test]\nfn test_call_gather_bytes() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov r1, 1\n        mov r2, 2\n        mov r3, 3\n        mov r4, 4\n        mov r5, 5\n        syscall BpfGatherBytes\n        exit\",\n        [],\n        (\n            b\"BpfGatherBytes\" => syscalls::BpfGatherBytes::init::<BpfSyscallContext, UserError>; syscalls::BpfGatherBytes::call,\n        ),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x0102030405 } },\n        7\n    );\n}\n\n#[test]\nfn test_call_memfrob() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov r6, r1\n        add r1, 2\n        mov r2, 4\n        syscall BpfMemFrob\n        ldxdw r0, [r6]\n        be64 r0\n        exit\",\n        [\n            0x01, 0x02, 0x03, 0x04, 0x05, 0x06, 0x07, 0x08, //\n        ],\n        (\n            b\"BpfMemFrob\" => syscalls::BpfMemFrob::init::<BpfSyscallContext, UserError>; syscalls::BpfMemFrob::call,\n        ),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x102292e2f2c0708 } },\n        7\n    );\n}\n\n#[test]\nfn test_syscall_with_context() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov64 r1, 0xAA\n        mov64 r2, 0xBB\n        mov64 r3, 0xCC\n        mov64 r4, 0xDD\n        mov64 r5, 0xEE\n        syscall SyscallWithContext\n        mov64 r0, 0x0\n        exit\",\n        [],\n        (\n            b\"SyscallWithContext\" => syscalls::SyscallWithContext::init::< syscalls::BpfSyscallContext, UserError>; syscalls::SyscallWithContext::call\n        ),\n        42,\n        { |vm: &EbpfVm<UserError, TestInstructionMeter>, res: Result| {\n            let syscall_context_object = unsafe { &*(vm.get_syscall_context_object(syscalls::SyscallWithContext::call as usize).unwrap() as *const syscalls::SyscallWithContext) };\n            assert_eq!(syscall_context_object.context, 84);\n            res.unwrap() == 0\n        }},\n        8\n    );\n}\n\ntype UserContext = u64;\npub struct NestedVmSyscall {}\nimpl NestedVmSyscall {\n    pub fn init<C, E>(_unused: C) -> Box<dyn SyscallObject<UserError>> {\n        Box::new(Self {})\n    }\n}\nimpl SyscallObject<UserError> for NestedVmSyscall {\n    fn call(\n        &mut self,\n        depth: u64,\n        throw: u64,\n        _arg3: u64,\n        _arg4: u64,\n        _arg5: u64,\n        _memory_mapping: &MemoryMapping,\n        result: &mut Result,\n    ) {\n        #[allow(unused_mut)]\n        if depth > 0 {\n            let mut syscall_registry = SyscallRegistry::default();\n            syscall_registry\n                .register_syscall_by_name(\n                    b\"NestedVmSyscall\",\n                    NestedVmSyscall::init::<UserContext, UserError>,\n                    NestedVmSyscall::call,\n                )\n                .unwrap();\n            let mem = [depth as u8 - 1, throw as u8];\n            let mut executable = assemble::<UserError, TestInstructionMeter>(\n                \"\n                ldabsb 0\n                mov64 r1, r0\n                ldabsb 1\n                mov64 r2, r0\n                syscall NestedVmSyscall\n                exit\",\n                None,\n                Config::default(),\n                syscall_registry,\n            )\n            .unwrap();\n            test_interpreter_and_jit!(\n                executable,\n                mem,\n                0,\n                {\n                    |_vm, res: Result| {\n                        *result = res;\n                        true\n                    }\n                },\n                if throw == 0 { 6 } else { 5 }\n            );\n        } else {\n            *result = if throw == 0 {\n                Ok(42)\n            } else {\n                Err(EbpfError::CallDepthExceeded(33, 0))\n            };\n        }\n    }\n}\n\n#[test]\nfn test_nested_vm_syscall() {\n    let config = Config::default();\n    let mut nested_vm_syscall = NestedVmSyscall {};\n    let memory_mapping = MemoryMapping::new::<UserError>(vec![], &config).unwrap();\n    let mut result = Ok(0);\n    nested_vm_syscall.call(1, 0, 0, 0, 0, &memory_mapping, &mut result);\n    assert!(result.unwrap() == 42);\n    let mut result = Ok(0);\n    nested_vm_syscall.call(1, 1, 0, 0, 0, &memory_mapping, &mut result);\n    assert!(matches!(result.unwrap_err(),\n        EbpfError::CallDepthExceeded(pc, depth)\n        if pc == 33 && depth == 0\n    ));\n}\n\n// Elf\n\n#[test]\nfn test_load_elf() {\n    let config = Config {\n        static_syscalls: false,\n        ..Config::default()\n    };\n    test_interpreter_and_jit_elf!(\n        \"tests/elfs/noop.so\",\n        config,\n        [],\n        (\n            b\"log\" => syscalls::BpfSyscallString::init::<BpfSyscallContext, UserError>; syscalls::BpfSyscallString::call,\n            b\"log_64\" => syscalls::BpfSyscallU64::init::<BpfSyscallContext, UserError>; syscalls::BpfSyscallU64::call,\n        ),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0 } },\n        11\n    );\n}\n\n#[test]\nfn test_load_elf_empty_noro() {\n    let config = Config {\n        static_syscalls: false,\n        ..Config::default()\n    };\n    test_interpreter_and_jit_elf!(\n        \"tests/elfs/noro.so\",\n        config,\n        [],\n        (\n            b\"log_64\" => syscalls::BpfSyscallU64::init::<BpfSyscallContext, UserError>; syscalls::BpfSyscallU64::call,\n        ),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0 } },\n        8\n    );\n}\n\n#[test]\nfn test_load_elf_empty_rodata() {\n    let config = Config {\n        static_syscalls: false,\n        ..Config::default()\n    };\n    test_interpreter_and_jit_elf!(\n        \"tests/elfs/empty_rodata.so\",\n        config,\n        [],\n        (\n            b\"log_64\" => syscalls::BpfSyscallU64::init::<BpfSyscallContext, UserError>; syscalls::BpfSyscallU64::call,\n        ),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0 } },\n        8\n    );\n}\n\n#[test]\nfn test_load_elf_rodata() {\n    // checks that the program loads the correct rodata offset with both\n    // borrowed and owned rodata\n    for optimize_rodata in [false, true] {\n        let config = Config {\n            optimize_rodata,\n            ..Config::default()\n        };\n        test_interpreter_and_jit_elf!(\n            \"tests/elfs/rodata.so\",\n            config,\n            [],\n            (),\n            0,\n            { |_vm, res: Result| { res.unwrap() == 42 } },\n            3\n        );\n    }\n}\n\n#[test]\nfn test_load_elf_rodata_high_vaddr() {\n    test_interpreter_and_jit_elf!(\n        \"tests/elfs/rodata_high_vaddr.so\",\n        [1],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 42 } },\n        3\n    );\n}\n\n#[test]\nfn test_custom_entrypoint() {\n    let mut file = File::open(\"tests/elfs/unresolved_syscall.so\").expect(\"file open failed\");\n    let mut elf = Vec::new();\n    file.read_to_end(&mut elf).unwrap();\n    elf[24] = 80; // Move entrypoint to later in the text section\n    let config = Config {\n        enable_instruction_tracing: true,\n        ..Config::default()\n    };\n    let mut syscall_registry = SyscallRegistry::default();\n    test_interpreter_and_jit!(register, syscall_registry, b\"log\" => syscalls::BpfSyscallString::init::<BpfSyscallContext, UserError>; syscalls::BpfSyscallString::call);\n    let mut syscall_registry = SyscallRegistry::default();\n    test_interpreter_and_jit!(register, syscall_registry, b\"log_64\" => syscalls::BpfSyscallU64::init::<BpfSyscallContext, UserError>; syscalls::BpfSyscallU64::call);\n    #[allow(unused_mut)]\n    let mut executable = Executable::<UserError, TestInstructionMeter>::from_elf(\n        &elf,\n        None,\n        config,\n        syscall_registry,\n    )\n    .unwrap();\n    test_interpreter_and_jit!(\n        executable,\n        [],\n        syscalls::BpfSyscallContext::default(),\n        { |_vm, res: Result| { res.unwrap() == 0 } },\n        2\n    );\n}\n\n// Instruction Meter Limit\n\n#[test]\nfn test_tight_infinite_loop_conditional() {\n    test_interpreter_and_jit_asm!(\n        \"\n        jsge r0, r0, -1\n        exit\",\n        [],\n        (),\n        0,\n        {\n            |_vm, res: Result| {\n                matches!(res.unwrap_err(),\n                    EbpfError::ExceededMaxInstructions(pc, initial_insn_count)\n                    if pc == 30 && initial_insn_count == 4\n                )\n            }\n        },\n        4\n    );\n}\n\n#[test]\nfn test_tight_infinite_loop_unconditional() {\n    test_interpreter_and_jit_asm!(\n        \"\n        ja -1\n        exit\",\n        [],\n        (),\n        0,\n        {\n            |_vm, res: Result| {\n                matches!(res.unwrap_err(),\n                    EbpfError::ExceededMaxInstructions(pc, initial_insn_count)\n                    if pc == 30 && initial_insn_count == 4\n                )\n            }\n        },\n        4\n    );\n}\n\n#[test]\nfn test_tight_infinite_recursion() {\n    test_interpreter_and_jit_asm!(\n        \"\n        entrypoint:\n        mov64 r3, 0x41414141\n        call entrypoint\n        exit\",\n        [],\n        (),\n        0,\n        {\n            |_vm, res: Result| {\n                matches!(res.unwrap_err(),\n                    EbpfError::ExceededMaxInstructions(pc, initial_insn_count)\n                    if pc == 31 && initial_insn_count == 4\n                )\n            }\n        },\n        4\n    );\n}\n\n#[test]\nfn test_tight_infinite_recursion_callx() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov64 r8, 0x1\n        lsh64 r8, 0x20\n        or64 r8, 0x18\n        mov64 r3, 0x41414141\n        callx r8\n        exit\",\n        [],\n        (),\n        0,\n        {\n            |_vm, res: Result| {\n                matches!(res.unwrap_err(),\n                    EbpfError::ExceededMaxInstructions(pc, initial_insn_count)\n                    if pc == 34 && initial_insn_count == 7\n                )\n            }\n        },\n        7\n    );\n}\n\n#[test]\nfn test_instruction_count_syscall() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov64 r2, 0x5\n        syscall BpfSyscallString\n        mov64 r0, 0x0\n        exit\",\n        [72, 101, 108, 108, 111],\n        (\n            b\"BpfSyscallString\" => syscalls::BpfSyscallString::init::<BpfSyscallContext, UserError>; syscalls::BpfSyscallString::call,\n        ),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0 } },\n        4\n    );\n}\n\n#[test]\nfn test_err_instruction_count_syscall_capped() {\n    let config = Config {\n        static_syscalls: false,\n        ..Config::default()\n    };\n    test_interpreter_and_jit_asm!(\n        \"\n        mov64 r2, 0x5\n        call 0\n        mov64 r0, 0x0\n        exit\",\n        config,\n        [72, 101, 108, 108, 111],\n        (\n            b\"BpfSyscallString\" => syscalls::BpfSyscallString::init::<BpfSyscallContext, UserError>; syscalls::BpfSyscallString::call,\n        ),\n        0,\n        {\n            |_vm, res: Result| {\n                matches!(res.unwrap_err(),\n                    EbpfError::ExceededMaxInstructions(pc, initial_insn_count)\n                    if pc == 32 && initial_insn_count == 3\n                )\n            }\n        },\n        3\n    );\n}\n\n#[test]\nfn test_err_instruction_count_lddw_capped() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov r0, 0\n        lddw r1, 0x1\n        mov r2, 0\n        exit\n        \",\n        [],\n        (),\n        0,\n        {\n            |_vm, res: Result| {\n                matches!(res.unwrap_err(),\n                    EbpfError::ExceededMaxInstructions(pc, initial_insn_count)\n                    if pc == 32 && initial_insn_count == 2\n                )\n            }\n        },\n        2\n    );\n}\n\n#[test]\nfn test_non_terminate_early() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov64 r6, 0x0\n        mov64 r1, 0x0\n        mov64 r2, 0x0\n        mov64 r3, 0x0\n        mov64 r4, 0x0\n        mov64 r5, r6\n        syscall Unresolved\n        add64 r6, 0x1\n        ja -0x8\n        exit\",\n        [],\n        (),\n        0,\n        {\n            |_vm, res: Result| {\n                matches!(res.unwrap_err(),\n                    EbpfError::UnsupportedInstruction(pc)\n                    if pc == 35\n                )\n            }\n        },\n        7\n    );\n}\n\n#[test]\nfn test_err_non_terminate_capped() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov64 r6, 0x0\n        mov64 r1, 0x0\n        mov64 r2, 0x0\n        mov64 r3, 0x0\n        mov64 r4, 0x0\n        mov64 r5, r6\n        syscall BpfTracePrintf\n        add64 r6, 0x1\n        ja -0x8\n        exit\",\n        [],\n        (\n            b\"BpfTracePrintf\" => syscalls::BpfTracePrintf::init::<BpfSyscallContext, UserError>; syscalls::BpfTracePrintf::call,\n        ),\n        0,\n        {\n            |_vm, res: Result| {\n                matches!(res.unwrap_err(),\n                    EbpfError::ExceededMaxInstructions(pc, initial_insn_count)\n                    if pc == 35 && initial_insn_count == 6\n                )\n            }\n        },\n        6\n    );\n    test_interpreter_and_jit_asm!(\n        \"\n        mov64 r6, 0x0\n        mov64 r1, 0x0\n        mov64 r2, 0x0\n        mov64 r3, 0x0\n        mov64 r4, 0x0\n        mov64 r5, r6\n        syscall BpfTracePrintf\n        add64 r6, 0x1\n        ja -0x8\n        exit\",\n        [],\n        (\n            b\"BpfTracePrintf\" => syscalls::BpfTracePrintf::init::<BpfSyscallContext, UserError>; syscalls::BpfTracePrintf::call,\n        ),\n        0,\n        {\n            |_vm, res: Result| {\n                matches!(res.unwrap_err(),\n                    EbpfError::ExceededMaxInstructions(pc, initial_insn_count)\n                    if pc == 37 && initial_insn_count == 1000\n                )\n            }\n        },\n        1000\n    );\n}\n\n#[test]\nfn test_err_capped_before_exception() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov64 r1, 0x0\n        mov64 r2, 0x0\n        add64 r0, 0x0\n        add64 r0, 0x0\n        div64 r1, r2\n        add64 r0, 0x0\n        exit\",\n        [],\n        (),\n        0,\n        {\n            |_vm, res: Result| {\n                matches!(res.unwrap_err(),\n                    EbpfError::ExceededMaxInstructions(pc, initial_insn_count)\n                    if pc == 31 && initial_insn_count == 2\n                )\n            }\n        },\n        2\n    );\n    test_interpreter_and_jit_asm!(\n        \"\n        mov64 r1, 0x0\n        mov64 r2, 0x0\n        add64 r0, 0x0\n        add64 r0, 0x0\n        syscall Unresolved\n        add64 r0, 0x0\n        exit\",\n        [],\n        (),\n        0,\n        {\n            |_vm, res: Result| {\n                matches!(res.unwrap_err(),\n                    EbpfError::ExceededMaxInstructions(pc, initial_insn_count)\n                    if pc == 33 && initial_insn_count == 4\n                )\n            }\n        },\n        4\n    );\n}\n\n#[test]\nfn test_err_exit_capped() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov64 r1, 0x1\n        lsh64 r1, 0x20\n        or64 r1, 0x20\n        callx r1\n        exit\n        \",\n        [],\n        (),\n        0,\n        {\n            |_vm, res: Result| {\n                matches!(res.unwrap_err(),\n                    EbpfError::ExceededMaxInstructions(pc, initial_insn_count) if pc == 34 && initial_insn_count == 5\n                )\n            }\n        },\n        5\n    );\n    test_interpreter_and_jit_asm!(\n        \"\n        mov64 r1, 0x1\n        lsh64 r1, 0x20\n        or64 r1, 0x20\n        callx r1\n        mov r0, r0\n        exit\n        \",\n        [],\n        (),\n        0,\n        {\n            |_vm, res: Result| {\n                matches!(res.unwrap_err(),\n                    EbpfError::ExceededMaxInstructions(pc, initial_insn_count) if pc == 35 && initial_insn_count == 6\n                )\n            }\n        },\n        6\n    );\n    test_interpreter_and_jit_asm!(\n        \"\n        call 0\n        mov r0, r0\n        exit\n        \",\n        [],\n        (),\n        0,\n        {\n            |_vm, res: Result| {\n                matches!(res.unwrap_err(),\n                    EbpfError::ExceededMaxInstructions(pc, initial_insn_count) if pc == 32 && initial_insn_count == 3\n                )\n            }\n        },\n        3\n    );\n}\n\n// Symbols and Relocation\n\n#[test]\nfn test_symbol_relocation() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov64 r1, r10\n        sub64 r1, 0x1\n        mov64 r2, 0x1\n        syscall BpfSyscallString\n        mov64 r0, 0x0\n        exit\",\n        [72, 101, 108, 108, 111],\n        (\n            b\"BpfSyscallString\" => syscalls::BpfSyscallString::init::<BpfSyscallContext, UserError>; syscalls::BpfSyscallString::call\n        ),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0 } },\n        6\n    );\n}\n\n#[test]\nfn test_err_call_unresolved() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov r1, 1\n        mov r2, 2\n        mov r3, 3\n        mov r4, 4\n        mov r5, 5\n        syscall Unresolved\n        mov64 r0, 0x0\n        exit\",\n        [],\n        (),\n        0,\n        {\n            |_vm, res: Result| matches!(res.unwrap_err(), EbpfError::UnsupportedInstruction(pc) if pc == 34)\n        },\n        6\n    );\n}\n\n#[test]\nfn test_err_unresolved_elf() {\n    let mut syscall_registry = SyscallRegistry::default();\n    test_interpreter_and_jit!(register, syscall_registry, b\"log\" => syscalls::BpfSyscallString::init::<BpfSyscallContext, UserError>; syscalls::BpfSyscallString::call);\n    let mut file = File::open(\"tests/elfs/unresolved_syscall.so\").unwrap();\n    let mut elf = Vec::new();\n    file.read_to_end(&mut elf).unwrap();\n    let config = Config {\n        reject_broken_elfs: true,\n        ..Config::default()\n    };\n    assert!(\n        matches!(Executable::<UserError, TestInstructionMeter>::from_elf(&elf, None, config, syscall_registry), Err(EbpfError::ElfError(ElfError::UnresolvedSymbol(symbol, pc, offset))) if symbol == \"log_64\" && pc == 550 && offset == 4168)\n    );\n}\n\n#[test]\nfn test_syscall_static() {\n    test_interpreter_and_jit_elf!(\n        \"tests/elfs/syscall_static.so\",\n        [],\n        (\n            b\"log\" => syscalls::BpfSyscallString::init::<BpfSyscallContext, UserError>; syscalls::BpfSyscallString::call,\n        ),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0 } },\n        5\n    );\n}\n\n#[test]\nfn test_syscall_unknown_static() {\n    // Check that unknown static syscalls result in UnsupportedInstruction (or\n    // would be UnresolvedSymbol with\n    // config.disable_unresolved_symbols_at_runtime=false).\n    //\n    // See also elf::test::test_static_syscall_disabled for the corresponding\n    // check with config.syscalls_static=false.\n    test_interpreter_and_jit_elf!(\n        \"tests/elfs/syscall_static_unknown.so\",\n        [],\n        (\n            b\"log\" => syscalls::BpfSyscallString::init::<BpfSyscallContext, UserError>; syscalls::BpfSyscallString::call,\n        ),\n        0,\n        { |_vm, res: Result| { matches!(res.unwrap_err(), EbpfError::UnsupportedInstruction(29)) } },\n        1\n    );\n}\n\n#[test]\nfn test_reloc_64_64() {\n    // Tests the correctness of R_BPF_64_64 relocations. The program returns the\n    // address of the entrypoint.\n    //   [ 1] .text             PROGBITS        00000000000000e8 0000e8 000018 00  AX  0   0  8\n    test_interpreter_and_jit_elf!(\n        \"tests/elfs/reloc_64_64.so\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == ebpf::MM_PROGRAM_START + 0xe8 } },\n        2\n    );\n}\n\n#[test]\nfn test_reloc_64_64_high_vaddr() {\n    // Same as test_reloc_64_64, but with .text already alinged to\n    // MM_PROGRAM_START by the linker\n    test_interpreter_and_jit_elf!(\n        \"tests/elfs/reloc_64_64_high_vaddr.so\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == ebpf::MM_PROGRAM_START } },\n        2\n    );\n}\n\n#[test]\nfn test_reloc_64_relative() {\n    // Tests the correctness of R_BPF_64_RELATIVE relocations. The program\n    // returns the address of the first .rodata byte.\n    //   [ 1] .text             PROGBITS        00000000000000e8 0000e8 000018 00  AX  0   0  8\n    //   [ 2] .rodata           PROGBITS        0000000000000100 000100 00000b 01 AMS  0   0  1\n    test_interpreter_and_jit_elf!(\n        \"tests/elfs/reloc_64_relative.so\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == ebpf::MM_PROGRAM_START + 0x100 } },\n        2\n    );\n}\n\n#[test]\nfn test_reloc_64_relative_high_vaddr() {\n    // Same as test_reloc_64_relative, but with .text placed already within\n    // MM_PROGRAM_START by the linker\n    // [ 1] .text             PROGBITS        0000000100000000 001000 000018 00  AX  0   0  8\n    // [ 2] .rodata           PROGBITS        0000000100000018 001018 00000b 01 AMS  0   0  1\n    test_interpreter_and_jit_elf!(\n        \"tests/elfs/reloc_64_relative_high_vaddr.so\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == ebpf::MM_PROGRAM_START + 0x18 } },\n        2\n    );\n}\n\n#[test]\nfn test_reloc_64_relative_data() {\n    // Tests the correctness of R_BPF_64_RELATIVE relocations in sections other\n    // than .text. The program returns the address of the first .rodata byte.\n    // [ 1] .text             PROGBITS        00000000000000e8 0000e8 000020 00  AX  0   0  8\n    // [ 2] .rodata           PROGBITS        0000000000000108 000108 000019 01 AMS  0   0  1\n    //\n    // 00000000000001f8 <FILE>:\n    // 63:       08 01 00 00 00 00 00 00\n    test_interpreter_and_jit_elf!(\n        \"tests/elfs/reloc_64_relative_data.so\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == ebpf::MM_PROGRAM_START + 0x108 } },\n        3\n    );\n}\n\n#[test]\nfn test_reloc_64_relative_data_high_vaddr() {\n    // Same as test_reloc_64_relative_data, but with rodata already placed\n    // within MM_PROGRAM_START by the linker\n    // [ 1] .text             PROGBITS        0000000100000000 001000 000020 00  AX  0   0  8\n    // [ 2] .rodata           PROGBITS        0000000100000020 001020 000019 01 AMS  0   0  1\n    //\n    // 0000000100000110 <FILE>:\n    // 536870946:      20 00 00 00 01 00 00 00\n    test_interpreter_and_jit_elf!(\n        \"tests/elfs/reloc_64_relative_data_high_vaddr.so\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == ebpf::MM_PROGRAM_START + 0x20 } },\n        3\n    );\n}\n\n#[test]\nfn test_reloc_64_relative_data_pre_sbfv2() {\n    // Before https://github.com/solana-labs/llvm-project/pull/35, we used to\n    // generate invalid R_BPF_64_RELATIVE relocations in sections other than\n    // .text.\n    //\n    // This test checks that the old behaviour is maintained for backwards\n    // compatibility when dealing with non-sbfv2 files. See also Elf::relocate().\n    //\n    // The program returns the address of the first .rodata byte.\n    // [ 1] .text             PROGBITS        00000000000000e8 0000e8 000020 00  AX  0   0  8\n    // [ 2] .rodata           PROGBITS        0000000000000108 000108 000019 01 AMS  0   0  1\n    //\n    // 00000000000001f8 <FILE>:\n    // 63:       00 00 00 00 08 01 00 00\n    test_interpreter_and_jit_elf!(\n        \"tests/elfs/reloc_64_relative_data_pre_sbfv2.so\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == ebpf::MM_PROGRAM_START + 0x108 } },\n        3\n    );\n}\n\n// Programs\n\n#[test]\nfn test_mul_loop() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov r0, 0x7\n        add r1, 0xa\n        lsh r1, 0x20\n        rsh r1, 0x20\n        jeq r1, 0x0, +4\n        mov r0, 0x7\n        mul r0, 0x7\n        add r1, -1\n        jne r1, 0x0, -3\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x75db9c97 } },\n        37\n    );\n}\n\n#[test]\nfn test_prime() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov r1, 67\n        mov r0, 0x1\n        mov r2, 0x2\n        jgt r1, 0x2, +4\n        ja +10\n        add r2, 0x1\n        mov r0, 0x1\n        jge r2, r1, +7\n        mov r3, r1\n        div r3, r2\n        mul r3, r2\n        mov r4, r1\n        sub r4, r3\n        mov r0, 0x0\n        jne r4, 0x0, -10\n        exit\",\n        [],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x1 } },\n        655\n    );\n}\n\n#[test]\nfn test_subnet() {\n    test_interpreter_and_jit_asm!(\n        \"\n        mov r2, 0xe\n        ldxh r3, [r1+12]\n        jne r3, 0x81, +2\n        mov r2, 0x12\n        ldxh r3, [r1+16]\n        and r3, 0xffff\n        jne r3, 0x8, +5\n        add r1, r2\n        mov r0, 0x1\n        ldxw r1, [r1+16]\n        and r1, 0xffffff\n        jeq r1, 0x1a8c0, +1\n        mov r0, 0x0\n        exit\",\n        [\n            0x00, 0x00, 0xc0, 0x9f, 0xa0, 0x97, 0x00, 0xa0, //\n            0xcc, 0x3b, 0xbf, 0xfa, 0x08, 0x00, 0x45, 0x10, //\n            0x00, 0x3c, 0x46, 0x3c, 0x40, 0x00, 0x40, 0x06, //\n            0x73, 0x1c, 0xc0, 0xa8, 0x01, 0x02, 0xc0, 0xa8, //\n            0x01, 0x01, 0x06, 0x0e, 0x00, 0x17, 0x99, 0xc5, //\n            0xa0, 0xec, 0x00, 0x00, 0x00, 0x00, 0xa0, 0x02, //\n            0x7d, 0x78, 0xe0, 0xa3, 0x00, 0x00, 0x02, 0x04, //\n            0x05, 0xb4, 0x04, 0x02, 0x08, 0x0a, 0x00, 0x9c, //\n            0x27, 0x24, 0x00, 0x00, 0x00, 0x00, 0x01, 0x03, //\n            0x03, 0x00, //\n        ],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x1 } },\n        11\n    );\n}\n\n#[test]\nfn test_tcp_port80_match() {\n    test_interpreter_and_jit_asm!(\n        PROG_TCP_PORT_80,\n        [\n            0x00, 0x01, 0x02, 0x03, 0x04, 0x05, 0x00, 0x06, //\n            0x07, 0x08, 0x09, 0x0a, 0x08, 0x00, 0x45, 0x00, //\n            0x00, 0x56, 0x00, 0x01, 0x00, 0x00, 0x40, 0x06, //\n            0xf9, 0x4d, 0xc0, 0xa8, 0x00, 0x01, 0xc0, 0xa8, //\n            0x00, 0x02, 0x27, 0x10, 0x00, 0x50, 0x00, 0x00, //\n            0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x50, 0x02, //\n            0x20, 0x00, 0xc5, 0x18, 0x00, 0x00, 0x44, 0x44, //\n            0x44, 0x44, 0x44, 0x44, 0x44, 0x44, 0x44, 0x44, //\n            0x44, 0x44, 0x44, 0x44, 0x44, 0x44, 0x44, 0x44, //\n            0x44, 0x44, 0x44, 0x44, 0x44, 0x44, 0x44, 0x44, //\n            0x44, 0x44, 0x44, 0x44, 0x44, 0x44, 0x44, 0x44, //\n            0x44, 0x44, 0x44, 0x44, 0x44, 0x44, 0x44, 0x44, //\n            0x44, 0x44, 0x44, 0x44, //\n        ],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x1 } },\n        17\n    );\n}\n\n#[test]\nfn test_tcp_port80_nomatch() {\n    test_interpreter_and_jit_asm!(\n        PROG_TCP_PORT_80,\n        [\n            0x00, 0x01, 0x02, 0x03, 0x04, 0x05, 0x00, 0x06, //\n            0x07, 0x08, 0x09, 0x0a, 0x08, 0x00, 0x45, 0x00, //\n            0x00, 0x56, 0x00, 0x01, 0x00, 0x00, 0x40, 0x06, //\n            0xf9, 0x4d, 0xc0, 0xa8, 0x00, 0x01, 0xc0, 0xa8, //\n            0x00, 0x02, 0x00, 0x16, 0x27, 0x10, 0x00, 0x00, //\n            0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x51, 0x02, //\n            0x20, 0x00, 0xc5, 0x18, 0x00, 0x00, 0x44, 0x44, //\n            0x44, 0x44, 0x44, 0x44, 0x44, 0x44, 0x44, 0x44, //\n            0x44, 0x44, 0x44, 0x44, 0x44, 0x44, 0x44, 0x44, //\n            0x44, 0x44, 0x44, 0x44, 0x44, 0x44, 0x44, 0x44, //\n            0x44, 0x44, 0x44, 0x44, 0x44, 0x44, 0x44, 0x44, //\n            0x44, 0x44, 0x44, 0x44, 0x44, 0x44, 0x44, 0x44, //\n            0x44, 0x44, 0x44, 0x44, //\n        ],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x0 } },\n        18\n    );\n}\n\n#[test]\nfn test_tcp_port80_nomatch_ethertype() {\n    test_interpreter_and_jit_asm!(\n        PROG_TCP_PORT_80,\n        [\n            0x00, 0x01, 0x02, 0x03, 0x04, 0x05, 0x00, 0x06, //\n            0x07, 0x08, 0x09, 0x0a, 0x08, 0x01, 0x45, 0x00, //\n            0x00, 0x56, 0x00, 0x01, 0x00, 0x00, 0x40, 0x06, //\n            0xf9, 0x4d, 0xc0, 0xa8, 0x00, 0x01, 0xc0, 0xa8, //\n            0x00, 0x02, 0x27, 0x10, 0x00, 0x50, 0x00, 0x00, //\n            0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x50, 0x02, //\n            0x20, 0x00, 0xc5, 0x18, 0x00, 0x00, 0x44, 0x44, //\n            0x44, 0x44, 0x44, 0x44, 0x44, 0x44, 0x44, 0x44, //\n            0x44, 0x44, 0x44, 0x44, 0x44, 0x44, 0x44, 0x44, //\n            0x44, 0x44, 0x44, 0x44, 0x44, 0x44, 0x44, 0x44, //\n            0x44, 0x44, 0x44, 0x44, 0x44, 0x44, 0x44, 0x44, //\n            0x44, 0x44, 0x44, 0x44, 0x44, 0x44, 0x44, 0x44, //\n            0x44, 0x44, 0x44, 0x44, //\n        ],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x0 } },\n        7\n    );\n}\n\n#[test]\nfn test_tcp_port80_nomatch_proto() {\n    test_interpreter_and_jit_asm!(\n        PROG_TCP_PORT_80,\n        [\n            0x00, 0x01, 0x02, 0x03, 0x04, 0x05, 0x00, 0x06, //\n            0x07, 0x08, 0x09, 0x0a, 0x08, 0x00, 0x45, 0x00, //\n            0x00, 0x56, 0x00, 0x01, 0x00, 0x00, 0x40, 0x11, //\n            0xf9, 0x4d, 0xc0, 0xa8, 0x00, 0x01, 0xc0, 0xa8, //\n            0x00, 0x02, 0x27, 0x10, 0x00, 0x50, 0x00, 0x00, //\n            0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x50, 0x02, //\n            0x20, 0x00, 0xc5, 0x18, 0x00, 0x00, 0x44, 0x44, //\n            0x44, 0x44, 0x44, 0x44, 0x44, 0x44, 0x44, 0x44, //\n            0x44, 0x44, 0x44, 0x44, 0x44, 0x44, 0x44, 0x44, //\n            0x44, 0x44, 0x44, 0x44, 0x44, 0x44, 0x44, 0x44, //\n            0x44, 0x44, 0x44, 0x44, 0x44, 0x44, 0x44, 0x44, //\n            0x44, 0x44, 0x44, 0x44, 0x44, 0x44, 0x44, 0x44, //\n            0x44, 0x44, 0x44, 0x44, //\n        ],\n        (),\n        0,\n        { |_vm, res: Result| { res.unwrap() == 0x0 } },\n        9\n    );\n}\n\n#[test]\nfn test_tcp_sack_match() {\n    test_interpreter_and_jit_asm!(\n        TCP_SACK_ASM,\n        TCP_SACK_MATCH,\n        (),\n        0,\n        { |_vm, res: Result| res.unwrap() == 0x1 },\n        79\n    );\n}\n\n#[test]\nfn test_tcp_sack_nomatch() {\n    test_interpreter_and_jit_asm!(\n        TCP_SACK_ASM,\n        TCP_SACK_NOMATCH,\n        (),\n        0,\n        { |_vm, res: Result| res.unwrap() == 0x0 },\n        55\n    );\n}\n\n// Fuzzy\n\n#[cfg(all(not(windows), target_arch = \"x86_64\"))]\nfn execute_generated_program(prog: &[u8]) -> bool {\n    let max_instruction_count = 1024;\n    let mem_size = 1024 * 1024;\n    let mut bpf_functions = BTreeMap::new();\n    let config = Config {\n        enable_instruction_tracing: true,\n        ..Config::default()\n    };\n    let syscall_registry = SyscallRegistry::default();\n    register_bpf_function(\n        &config,\n        &mut bpf_functions,\n        &syscall_registry,\n        0,\n        \"entrypoint\",\n    )\n    .unwrap();\n    let executable = Executable::<UserError, TestInstructionMeter>::from_text_bytes(\n        prog,\n        Some(solana_rbpf::verifier::check),\n        config,\n        syscall_registry,\n        bpf_functions,\n    );\n    let mut executable = if let Ok(executable) = executable {\n        executable\n    } else {\n        return false;\n    };\n    if Executable::<UserError, TestInstructionMeter>::jit_compile(&mut executable).is_err() {\n        return false;\n    }\n    let (instruction_count_interpreter, tracer_interpreter, result_interpreter) = {\n        let mut mem = vec![0u8; mem_size];\n        let mem_region = MemoryRegion::new_writable(&mut mem, ebpf::MM_INPUT_START);\n        let mut vm = EbpfVm::new(&executable, &mut [], vec![mem_region]).unwrap();\n        let result_interpreter = vm.execute_program_interpreted(&mut TestInstructionMeter {\n            remaining: max_instruction_count,\n        });\n        let tracer_interpreter = vm.get_tracer().clone();\n        (\n            vm.get_total_instruction_count(),\n            tracer_interpreter,\n            result_interpreter,\n        )\n    };\n    let mut mem = vec![0u8; mem_size];\n    let mem_region = MemoryRegion::new_writable(&mut mem, ebpf::MM_INPUT_START);\n    let mut vm = EbpfVm::new(&executable, &mut [], vec![mem_region]).unwrap();\n    let result_jit = vm.execute_program_jit(&mut TestInstructionMeter {\n        remaining: max_instruction_count,\n    });\n    let tracer_jit = vm.get_tracer();\n    if result_interpreter != result_jit\n        || !solana_rbpf::vm::Tracer::compare(&tracer_interpreter, tracer_jit)\n    {\n        let analysis =\n            solana_rbpf::static_analysis::Analysis::from_executable(&executable).unwrap();\n        println!(\"result_interpreter={:?}\", result_interpreter);\n        println!(\"result_jit={:?}\", result_jit);\n        let stdout = std::io::stdout();\n        tracer_interpreter\n            .write(&mut stdout.lock(), &analysis)\n            .unwrap();\n        tracer_jit.write(&mut stdout.lock(), &analysis).unwrap();\n        panic!();\n    }\n    if executable.get_config().enable_instruction_meter {\n        let instruction_count_jit = vm.get_total_instruction_count();\n        assert_eq!(instruction_count_interpreter, instruction_count_jit);\n    }\n    true\n}\n\n#[cfg(all(not(windows), target_arch = \"x86_64\"))]\n#[test]\nfn test_total_chaos() {\n    let instruction_count = 6;\n    let iteration_count = 1000000;\n    let mut program = vec![0; instruction_count * ebpf::INSN_SIZE];\n    program[ebpf::INSN_SIZE * (instruction_count - 1)..ebpf::INSN_SIZE * instruction_count]\n        .copy_from_slice(&[ebpf::EXIT, 0, 0, 0, 0, 0, 0, 0]);\n    let seed = 0xC2DB2F8F282284A0;\n    let mut prng = SmallRng::seed_from_u64(seed);\n    for _ in 0..iteration_count {\n        prng.fill_bytes(&mut program[0..ebpf::INSN_SIZE * (instruction_count - 1)]);\n        execute_generated_program(&program);\n    }\n    for _ in 0..iteration_count {\n        prng.fill_bytes(&mut program[0..ebpf::INSN_SIZE * (instruction_count - 1)]);\n        for index in (0..program.len()).step_by(ebpf::INSN_SIZE) {\n            program[index + 0x1] &= 0x77;\n            program[index + 0x2] &= 0x00;\n            program[index + 0x3] &= 0x77;\n            program[index + 0x4] &= 0x00;\n            program[index + 0x5] &= 0x77;\n            program[index + 0x6] &= 0x77;\n            program[index + 0x7] &= 0x77;\n        }\n        execute_generated_program(&program);\n    }\n}\n"], "filenames": ["src/jit.rs", "tests/ubpf_execution.rs"], "buggy_code_start_loc": [916, 841], "buggy_code_end_loc": [917, 852], "fixing_code_start_loc": [916, 842], "fixing_code_end_loc": [917, 884], "type": "CWE-682", "message": "In Solana rBPF versions 0.2.26 and 0.2.27 are affected by Incorrect Calculation which is caused by improper implementation of sdiv instruction. This can lead to the wrong execution path, resulting in huge loss in specific cases. For example, the result of a sdiv instruction may decide whether to transfer tokens or not. The vulnerability affects both integrity and may cause serious availability problems.", "other": {"cve": {"id": "CVE-2022-23066", "sourceIdentifier": "vulnerabilitylab@mend.io", "published": "2022-05-09T07:15:08.330", "lastModified": "2023-02-10T16:38:55.830", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "In Solana rBPF versions 0.2.26 and 0.2.27 are affected by Incorrect Calculation which is caused by improper implementation of sdiv instruction. This can lead to the wrong execution path, resulting in huge loss in specific cases. For example, the result of a sdiv instruction may decide whether to transfer tokens or not. The vulnerability affects both integrity and may cause serious availability problems."}, {"lang": "es", "value": "En Solana rBPF versiones 0.2.26 y 0.2.27, est\u00e1n afectadas por un C\u00e1lculo Incorrecto que es causado por la implementaci\u00f3n inapropiada de la instrucci\u00f3n sdiv. Esto puede conllevar a una ruta de ejecuci\u00f3n err\u00f3nea, resultando en grandes p\u00e9rdidas en casos concretos. Por ejemplo, el resultado de una instrucci\u00f3n sdiv puede decidir si son transferidas fichas o no. La vulnerabilidad afecta tanto a la integridad como puede causar graves problemas de disponibilidad"}], "metrics": {"cvssMetricV31": [{"source": "vulnerabilitylab@mend.io", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:H/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "HIGH", "availabilityImpact": "HIGH", "baseScore": 9.1, "baseSeverity": "CRITICAL"}, "exploitabilityScore": 3.9, "impactScore": 5.2}, {"source": "nvd@nist.gov", "type": "Secondary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:H/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "HIGH", "availabilityImpact": "HIGH", "baseScore": 9.1, "baseSeverity": "CRITICAL"}, "exploitabilityScore": 3.9, "impactScore": 5.2}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:N/AC:L/Au:N/C:N/I:P/A:P", "accessVector": "NETWORK", "accessComplexity": "LOW", "authentication": "NONE", "confidentialityImpact": "NONE", "integrityImpact": "PARTIAL", "availabilityImpact": "PARTIAL", "baseScore": 6.4}, "baseSeverity": "MEDIUM", "exploitabilityScore": 10.0, "impactScore": 4.9, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "vulnerabilitylab@mend.io", "type": "Primary", "description": [{"lang": "en", "value": "CWE-682"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:solana:rbpf:0.2.26:*:*:*:*:*:*:*", "matchCriteriaId": "6A17AFA5-0067-48EA-94DE-DDA94ED7638B"}, {"vulnerable": true, "criteria": "cpe:2.3:a:solana:rbpf:0.2.27:*:*:*:*:*:*:*", "matchCriteriaId": "8FF35CC7-D9DA-4A9C-9500-8F930138A0ED"}]}]}], "references": [{"url": "https://blocksecteam.medium.com/how-a-critical-bug-in-solana-network-was-detected-and-timely-patched-a701870e1324", "source": "vulnerabilitylab@mend.io", "tags": ["Exploit", "Third Party Advisory"]}, {"url": "https://github.com/solana-labs/rbpf/commit/e61e045f8c244de978401d186dcfd50838817297", "source": "vulnerabilitylab@mend.io", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://www.whitesourcesoftware.com/vulnerability-database/CVE-2022-23066", "source": "vulnerabilitylab@mend.io", "tags": ["Exploit", "Third Party Advisory"]}]}, "github_commit_url": "https://github.com/solana-labs/rbpf/commit/e61e045f8c244de978401d186dcfd50838817297"}}
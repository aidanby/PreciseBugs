{"buggy_code": ["/*\n * Copyright(C) 2015 Linaro Limited. All rights reserved.\n * Author: Mathieu Poirier <mathieu.poirier@linaro.org>\n *\n * This program is free software; you can redistribute it and/or modify it\n * under the terms of the GNU General Public License version 2 as published by\n * the Free Software Foundation.\n *\n * This program is distributed in the hope that it will be useful, but WITHOUT\n * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for\n * more details.\n *\n * You should have received a copy of the GNU General Public License along with\n * this program.  If not, see <http://www.gnu.org/licenses/>.\n */\n\n#include <linux/coresight.h>\n#include <linux/coresight-pmu.h>\n#include <linux/cpumask.h>\n#include <linux/device.h>\n#include <linux/list.h>\n#include <linux/mm.h>\n#include <linux/init.h>\n#include <linux/perf_event.h>\n#include <linux/slab.h>\n#include <linux/types.h>\n#include <linux/workqueue.h>\n\n#include \"coresight-etm-perf.h\"\n#include \"coresight-priv.h\"\n\nstatic struct pmu etm_pmu;\nstatic bool etm_perf_up;\n\n/**\n * struct etm_event_data - Coresight specifics associated to an event\n * @work:\t\tHandle to free allocated memory outside IRQ context.\n * @mask:\t\tHold the CPU(s) this event was set for.\n * @snk_config:\t\tThe sink configuration.\n * @path:\t\tAn array of path, each slot for one CPU.\n */\nstruct etm_event_data {\n\tstruct work_struct work;\n\tcpumask_t mask;\n\tvoid *snk_config;\n\tstruct list_head **path;\n};\n\nstatic DEFINE_PER_CPU(struct perf_output_handle, ctx_handle);\nstatic DEFINE_PER_CPU(struct coresight_device *, csdev_src);\n\n/* ETMv3.5/PTM's ETMCR is 'config' */\nPMU_FORMAT_ATTR(cycacc,\t\t\"config:\" __stringify(ETM_OPT_CYCACC));\nPMU_FORMAT_ATTR(timestamp,\t\"config:\" __stringify(ETM_OPT_TS));\n\nstatic struct attribute *etm_config_formats_attr[] = {\n\t&format_attr_cycacc.attr,\n\t&format_attr_timestamp.attr,\n\tNULL,\n};\n\nstatic struct attribute_group etm_pmu_format_group = {\n\t.name   = \"format\",\n\t.attrs  = etm_config_formats_attr,\n};\n\nstatic const struct attribute_group *etm_pmu_attr_groups[] = {\n\t&etm_pmu_format_group,\n\tNULL,\n};\n\nstatic void etm_event_read(struct perf_event *event) {}\n\nstatic int etm_addr_filters_alloc(struct perf_event *event)\n{\n\tstruct etm_filters *filters;\n\tint node = event->cpu == -1 ? -1 : cpu_to_node(event->cpu);\n\n\tfilters = kzalloc_node(sizeof(struct etm_filters), GFP_KERNEL, node);\n\tif (!filters)\n\t\treturn -ENOMEM;\n\n\tif (event->parent)\n\t\tmemcpy(filters, event->parent->hw.addr_filters,\n\t\t       sizeof(*filters));\n\n\tevent->hw.addr_filters = filters;\n\n\treturn 0;\n}\n\nstatic void etm_event_destroy(struct perf_event *event)\n{\n\tkfree(event->hw.addr_filters);\n\tevent->hw.addr_filters = NULL;\n}\n\nstatic int etm_event_init(struct perf_event *event)\n{\n\tint ret = 0;\n\n\tif (event->attr.type != etm_pmu.type) {\n\t\tret = -ENOENT;\n\t\tgoto out;\n\t}\n\n\tret = etm_addr_filters_alloc(event);\n\tif (ret)\n\t\tgoto out;\n\n\tevent->destroy = etm_event_destroy;\nout:\n\treturn ret;\n}\n\nstatic void free_event_data(struct work_struct *work)\n{\n\tint cpu;\n\tcpumask_t *mask;\n\tstruct etm_event_data *event_data;\n\tstruct coresight_device *sink;\n\n\tevent_data = container_of(work, struct etm_event_data, work);\n\tmask = &event_data->mask;\n\t/*\n\t * First deal with the sink configuration.  See comment in\n\t * etm_setup_aux() about why we take the first available path.\n\t */\n\tif (event_data->snk_config) {\n\t\tcpu = cpumask_first(mask);\n\t\tsink = coresight_get_sink(event_data->path[cpu]);\n\t\tif (sink_ops(sink)->free_buffer)\n\t\t\tsink_ops(sink)->free_buffer(event_data->snk_config);\n\t}\n\n\tfor_each_cpu(cpu, mask) {\n\t\tif (!(IS_ERR_OR_NULL(event_data->path[cpu])))\n\t\t\tcoresight_release_path(event_data->path[cpu]);\n\t}\n\n\tkfree(event_data->path);\n\tkfree(event_data);\n}\n\nstatic void *alloc_event_data(int cpu)\n{\n\tint size;\n\tcpumask_t *mask;\n\tstruct etm_event_data *event_data;\n\n\t/* First get memory for the session's data */\n\tevent_data = kzalloc(sizeof(struct etm_event_data), GFP_KERNEL);\n\tif (!event_data)\n\t\treturn NULL;\n\n\t/* Make sure nothing disappears under us */\n\tget_online_cpus();\n\tsize = num_online_cpus();\n\n\tmask = &event_data->mask;\n\tif (cpu != -1)\n\t\tcpumask_set_cpu(cpu, mask);\n\telse\n\t\tcpumask_copy(mask, cpu_online_mask);\n\tput_online_cpus();\n\n\t/*\n\t * Each CPU has a single path between source and destination.  As such\n\t * allocate an array using CPU numbers as indexes.  That way a path\n\t * for any CPU can easily be accessed at any given time.  We proceed\n\t * the same way for sessions involving a single CPU.  The cost of\n\t * unused memory when dealing with single CPU trace scenarios is small\n\t * compared to the cost of searching through an optimized array.\n\t */\n\tevent_data->path = kcalloc(size,\n\t\t\t\t   sizeof(struct list_head *), GFP_KERNEL);\n\tif (!event_data->path) {\n\t\tkfree(event_data);\n\t\treturn NULL;\n\t}\n\n\treturn event_data;\n}\n\nstatic void etm_free_aux(void *data)\n{\n\tstruct etm_event_data *event_data = data;\n\n\tschedule_work(&event_data->work);\n}\n\nstatic void *etm_setup_aux(int event_cpu, void **pages,\n\t\t\t   int nr_pages, bool overwrite)\n{\n\tint cpu;\n\tcpumask_t *mask;\n\tstruct coresight_device *sink;\n\tstruct etm_event_data *event_data = NULL;\n\n\tevent_data = alloc_event_data(event_cpu);\n\tif (!event_data)\n\t\treturn NULL;\n\n\t/*\n\t * In theory nothing prevent tracers in a trace session from being\n\t * associated with different sinks, nor having a sink per tracer.  But\n\t * until we have HW with this kind of topology we need to assume tracers\n\t * in a trace session are using the same sink.  Therefore go through\n\t * the coresight bus and pick the first enabled sink.\n\t *\n\t * When operated from sysFS users are responsible to enable the sink\n\t * while from perf, the perf tools will do it based on the choice made\n\t * on the cmd line.  As such the \"enable_sink\" flag in sysFS is reset.\n\t */\n\tsink = coresight_get_enabled_sink(true);\n\tif (!sink)\n\t\tgoto err;\n\n\tINIT_WORK(&event_data->work, free_event_data);\n\n\tmask = &event_data->mask;\n\n\t/* Setup the path for each CPU in a trace session */\n\tfor_each_cpu(cpu, mask) {\n\t\tstruct coresight_device *csdev;\n\n\t\tcsdev = per_cpu(csdev_src, cpu);\n\t\tif (!csdev)\n\t\t\tgoto err;\n\n\t\t/*\n\t\t * Building a path doesn't enable it, it simply builds a\n\t\t * list of devices from source to sink that can be\n\t\t * referenced later when the path is actually needed.\n\t\t */\n\t\tevent_data->path[cpu] = coresight_build_path(csdev, sink);\n\t\tif (IS_ERR(event_data->path[cpu]))\n\t\t\tgoto err;\n\t}\n\n\tif (!sink_ops(sink)->alloc_buffer)\n\t\tgoto err;\n\n\t/* Get the AUX specific data from the sink buffer */\n\tevent_data->snk_config =\n\t\t\tsink_ops(sink)->alloc_buffer(sink, cpu, pages,\n\t\t\t\t\t\t     nr_pages, overwrite);\n\tif (!event_data->snk_config)\n\t\tgoto err;\n\nout:\n\treturn event_data;\n\nerr:\n\tetm_free_aux(event_data);\n\tevent_data = NULL;\n\tgoto out;\n}\n\nstatic void etm_event_start(struct perf_event *event, int flags)\n{\n\tint cpu = smp_processor_id();\n\tstruct etm_event_data *event_data;\n\tstruct perf_output_handle *handle = this_cpu_ptr(&ctx_handle);\n\tstruct coresight_device *sink, *csdev = per_cpu(csdev_src, cpu);\n\n\tif (!csdev)\n\t\tgoto fail;\n\n\t/*\n\t * Deal with the ring buffer API and get a handle on the\n\t * session's information.\n\t */\n\tevent_data = perf_aux_output_begin(handle, event);\n\tif (!event_data)\n\t\tgoto fail;\n\n\t/* We need a sink, no need to continue without one */\n\tsink = coresight_get_sink(event_data->path[cpu]);\n\tif (WARN_ON_ONCE(!sink || !sink_ops(sink)->set_buffer))\n\t\tgoto fail_end_stop;\n\n\t/* Configure the sink */\n\tif (sink_ops(sink)->set_buffer(sink, handle,\n\t\t\t\t       event_data->snk_config))\n\t\tgoto fail_end_stop;\n\n\t/* Nothing will happen without a path */\n\tif (coresight_enable_path(event_data->path[cpu], CS_MODE_PERF))\n\t\tgoto fail_end_stop;\n\n\t/* Tell the perf core the event is alive */\n\tevent->hw.state = 0;\n\n\t/* Finally enable the tracer */\n\tif (source_ops(csdev)->enable(csdev, event, CS_MODE_PERF))\n\t\tgoto fail_end_stop;\n\nout:\n\treturn;\n\nfail_end_stop:\n\tperf_aux_output_end(handle, 0, true);\nfail:\n\tevent->hw.state = PERF_HES_STOPPED;\n\tgoto out;\n}\n\nstatic void etm_event_stop(struct perf_event *event, int mode)\n{\n\tbool lost;\n\tint cpu = smp_processor_id();\n\tunsigned long size;\n\tstruct coresight_device *sink, *csdev = per_cpu(csdev_src, cpu);\n\tstruct perf_output_handle *handle = this_cpu_ptr(&ctx_handle);\n\tstruct etm_event_data *event_data = perf_get_aux(handle);\n\n\tif (event->hw.state == PERF_HES_STOPPED)\n\t\treturn;\n\n\tif (!csdev)\n\t\treturn;\n\n\tsink = coresight_get_sink(event_data->path[cpu]);\n\tif (!sink)\n\t\treturn;\n\n\t/* stop tracer */\n\tsource_ops(csdev)->disable(csdev, event);\n\n\t/* tell the core */\n\tevent->hw.state = PERF_HES_STOPPED;\n\n\tif (mode & PERF_EF_UPDATE) {\n\t\tif (WARN_ON_ONCE(handle->event != event))\n\t\t\treturn;\n\n\t\t/* update trace information */\n\t\tif (!sink_ops(sink)->update_buffer)\n\t\t\treturn;\n\n\t\tsink_ops(sink)->update_buffer(sink, handle,\n\t\t\t\t\t      event_data->snk_config);\n\n\t\tif (!sink_ops(sink)->reset_buffer)\n\t\t\treturn;\n\n\t\tsize = sink_ops(sink)->reset_buffer(sink, handle,\n\t\t\t\t\t\t    event_data->snk_config,\n\t\t\t\t\t\t    &lost);\n\n\t\tperf_aux_output_end(handle, size, lost);\n\t}\n\n\t/* Disabling the path make its elements available to other sessions */\n\tcoresight_disable_path(event_data->path[cpu]);\n}\n\nstatic int etm_event_add(struct perf_event *event, int mode)\n{\n\tint ret = 0;\n\tstruct hw_perf_event *hwc = &event->hw;\n\n\tif (mode & PERF_EF_START) {\n\t\tetm_event_start(event, 0);\n\t\tif (hwc->state & PERF_HES_STOPPED)\n\t\t\tret = -EINVAL;\n\t} else {\n\t\thwc->state = PERF_HES_STOPPED;\n\t}\n\n\treturn ret;\n}\n\nstatic void etm_event_del(struct perf_event *event, int mode)\n{\n\tetm_event_stop(event, PERF_EF_UPDATE);\n}\n\nstatic int etm_addr_filters_validate(struct list_head *filters)\n{\n\tbool range = false, address = false;\n\tint index = 0;\n\tstruct perf_addr_filter *filter;\n\n\tlist_for_each_entry(filter, filters, entry) {\n\t\t/*\n\t\t * No need to go further if there's no more\n\t\t * room for filters.\n\t\t */\n\t\tif (++index > ETM_ADDR_CMP_MAX)\n\t\t\treturn -EOPNOTSUPP;\n\n\t\t/*\n\t\t * As taken from the struct perf_addr_filter documentation:\n\t\t *\t@range:\t1: range, 0: address\n\t\t *\n\t\t * At this time we don't allow range and start/stop filtering\n\t\t * to cohabitate, they have to be mutually exclusive.\n\t\t */\n\t\tif ((filter->range == 1) && address)\n\t\t\treturn -EOPNOTSUPP;\n\n\t\tif ((filter->range == 0) && range)\n\t\t\treturn -EOPNOTSUPP;\n\n\t\t/*\n\t\t * For range filtering, the second address in the address\n\t\t * range comparator needs to be higher than the first.\n\t\t * Invalid otherwise.\n\t\t */\n\t\tif (filter->range && filter->size == 0)\n\t\t\treturn -EINVAL;\n\n\t\t/*\n\t\t * Everything checks out with this filter, record what we've\n\t\t * received before moving on to the next one.\n\t\t */\n\t\tif (filter->range)\n\t\t\trange = true;\n\t\telse\n\t\t\taddress = true;\n\t}\n\n\treturn 0;\n}\n\nstatic void etm_addr_filters_sync(struct perf_event *event)\n{\n\tstruct perf_addr_filters_head *head = perf_event_addr_filters(event);\n\tunsigned long start, stop, *offs = event->addr_filters_offs;\n\tstruct etm_filters *filters = event->hw.addr_filters;\n\tstruct etm_filter *etm_filter;\n\tstruct perf_addr_filter *filter;\n\tint i = 0;\n\n\tlist_for_each_entry(filter, &head->list, entry) {\n\t\tstart = filter->offset + offs[i];\n\t\tstop = start + filter->size;\n\t\tetm_filter = &filters->etm_filter[i];\n\n\t\tif (filter->range == 1) {\n\t\t\tetm_filter->start_addr = start;\n\t\t\tetm_filter->stop_addr = stop;\n\t\t\tetm_filter->type = ETM_ADDR_TYPE_RANGE;\n\t\t} else {\n\t\t\tif (filter->filter == 1) {\n\t\t\t\tetm_filter->start_addr = start;\n\t\t\t\tetm_filter->type = ETM_ADDR_TYPE_START;\n\t\t\t} else {\n\t\t\t\tetm_filter->stop_addr = stop;\n\t\t\t\tetm_filter->type = ETM_ADDR_TYPE_STOP;\n\t\t\t}\n\t\t}\n\t\ti++;\n\t}\n\n\tfilters->nr_filters = i;\n}\n\nint etm_perf_symlink(struct coresight_device *csdev, bool link)\n{\n\tchar entry[sizeof(\"cpu9999999\")];\n\tint ret = 0, cpu = source_ops(csdev)->cpu_id(csdev);\n\tstruct device *pmu_dev = etm_pmu.dev;\n\tstruct device *cs_dev = &csdev->dev;\n\n\tsprintf(entry, \"cpu%d\", cpu);\n\n\tif (!etm_perf_up)\n\t\treturn -EPROBE_DEFER;\n\n\tif (link) {\n\t\tret = sysfs_create_link(&pmu_dev->kobj, &cs_dev->kobj, entry);\n\t\tif (ret)\n\t\t\treturn ret;\n\t\tper_cpu(csdev_src, cpu) = csdev;\n\t} else {\n\t\tsysfs_remove_link(&pmu_dev->kobj, entry);\n\t\tper_cpu(csdev_src, cpu) = NULL;\n\t}\n\n\treturn 0;\n}\n\nstatic int __init etm_perf_init(void)\n{\n\tint ret;\n\n\tetm_pmu.capabilities\t\t= PERF_PMU_CAP_EXCLUSIVE;\n\n\tetm_pmu.attr_groups\t\t= etm_pmu_attr_groups;\n\tetm_pmu.task_ctx_nr\t\t= perf_sw_context;\n\tetm_pmu.read\t\t\t= etm_event_read;\n\tetm_pmu.event_init\t\t= etm_event_init;\n\tetm_pmu.setup_aux\t\t= etm_setup_aux;\n\tetm_pmu.free_aux\t\t= etm_free_aux;\n\tetm_pmu.start\t\t\t= etm_event_start;\n\tetm_pmu.stop\t\t\t= etm_event_stop;\n\tetm_pmu.add\t\t\t= etm_event_add;\n\tetm_pmu.del\t\t\t= etm_event_del;\n\tetm_pmu.addr_filters_sync\t= etm_addr_filters_sync;\n\tetm_pmu.addr_filters_validate\t= etm_addr_filters_validate;\n\tetm_pmu.nr_addr_filters\t\t= ETM_ADDR_CMP_MAX;\n\n\tret = perf_pmu_register(&etm_pmu, CORESIGHT_ETM_PMU_NAME, -1);\n\tif (ret == 0)\n\t\tetm_perf_up = true;\n\n\treturn ret;\n}\ndevice_initcall(etm_perf_init);\n"], "fixing_code": ["/*\n * Copyright(C) 2015 Linaro Limited. All rights reserved.\n * Author: Mathieu Poirier <mathieu.poirier@linaro.org>\n *\n * This program is free software; you can redistribute it and/or modify it\n * under the terms of the GNU General Public License version 2 as published by\n * the Free Software Foundation.\n *\n * This program is distributed in the hope that it will be useful, but WITHOUT\n * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for\n * more details.\n *\n * You should have received a copy of the GNU General Public License along with\n * this program.  If not, see <http://www.gnu.org/licenses/>.\n */\n\n#include <linux/coresight.h>\n#include <linux/coresight-pmu.h>\n#include <linux/cpumask.h>\n#include <linux/device.h>\n#include <linux/list.h>\n#include <linux/mm.h>\n#include <linux/init.h>\n#include <linux/perf_event.h>\n#include <linux/slab.h>\n#include <linux/types.h>\n#include <linux/workqueue.h>\n\n#include \"coresight-etm-perf.h\"\n#include \"coresight-priv.h\"\n\nstatic struct pmu etm_pmu;\nstatic bool etm_perf_up;\n\n/**\n * struct etm_event_data - Coresight specifics associated to an event\n * @work:\t\tHandle to free allocated memory outside IRQ context.\n * @mask:\t\tHold the CPU(s) this event was set for.\n * @snk_config:\t\tThe sink configuration.\n * @path:\t\tAn array of path, each slot for one CPU.\n */\nstruct etm_event_data {\n\tstruct work_struct work;\n\tcpumask_t mask;\n\tvoid *snk_config;\n\tstruct list_head **path;\n};\n\nstatic DEFINE_PER_CPU(struct perf_output_handle, ctx_handle);\nstatic DEFINE_PER_CPU(struct coresight_device *, csdev_src);\n\n/* ETMv3.5/PTM's ETMCR is 'config' */\nPMU_FORMAT_ATTR(cycacc,\t\t\"config:\" __stringify(ETM_OPT_CYCACC));\nPMU_FORMAT_ATTR(timestamp,\t\"config:\" __stringify(ETM_OPT_TS));\n\nstatic struct attribute *etm_config_formats_attr[] = {\n\t&format_attr_cycacc.attr,\n\t&format_attr_timestamp.attr,\n\tNULL,\n};\n\nstatic struct attribute_group etm_pmu_format_group = {\n\t.name   = \"format\",\n\t.attrs  = etm_config_formats_attr,\n};\n\nstatic const struct attribute_group *etm_pmu_attr_groups[] = {\n\t&etm_pmu_format_group,\n\tNULL,\n};\n\nstatic void etm_event_read(struct perf_event *event) {}\n\nstatic int etm_addr_filters_alloc(struct perf_event *event)\n{\n\tstruct etm_filters *filters;\n\tint node = event->cpu == -1 ? -1 : cpu_to_node(event->cpu);\n\n\tfilters = kzalloc_node(sizeof(struct etm_filters), GFP_KERNEL, node);\n\tif (!filters)\n\t\treturn -ENOMEM;\n\n\tif (event->parent)\n\t\tmemcpy(filters, event->parent->hw.addr_filters,\n\t\t       sizeof(*filters));\n\n\tevent->hw.addr_filters = filters;\n\n\treturn 0;\n}\n\nstatic void etm_event_destroy(struct perf_event *event)\n{\n\tkfree(event->hw.addr_filters);\n\tevent->hw.addr_filters = NULL;\n}\n\nstatic int etm_event_init(struct perf_event *event)\n{\n\tint ret = 0;\n\n\tif (event->attr.type != etm_pmu.type) {\n\t\tret = -ENOENT;\n\t\tgoto out;\n\t}\n\n\tret = etm_addr_filters_alloc(event);\n\tif (ret)\n\t\tgoto out;\n\n\tevent->destroy = etm_event_destroy;\nout:\n\treturn ret;\n}\n\nstatic void free_event_data(struct work_struct *work)\n{\n\tint cpu;\n\tcpumask_t *mask;\n\tstruct etm_event_data *event_data;\n\tstruct coresight_device *sink;\n\n\tevent_data = container_of(work, struct etm_event_data, work);\n\tmask = &event_data->mask;\n\t/*\n\t * First deal with the sink configuration.  See comment in\n\t * etm_setup_aux() about why we take the first available path.\n\t */\n\tif (event_data->snk_config) {\n\t\tcpu = cpumask_first(mask);\n\t\tsink = coresight_get_sink(event_data->path[cpu]);\n\t\tif (sink_ops(sink)->free_buffer)\n\t\t\tsink_ops(sink)->free_buffer(event_data->snk_config);\n\t}\n\n\tfor_each_cpu(cpu, mask) {\n\t\tif (!(IS_ERR_OR_NULL(event_data->path[cpu])))\n\t\t\tcoresight_release_path(event_data->path[cpu]);\n\t}\n\n\tkfree(event_data->path);\n\tkfree(event_data);\n}\n\nstatic void *alloc_event_data(int cpu)\n{\n\tint size;\n\tcpumask_t *mask;\n\tstruct etm_event_data *event_data;\n\n\t/* First get memory for the session's data */\n\tevent_data = kzalloc(sizeof(struct etm_event_data), GFP_KERNEL);\n\tif (!event_data)\n\t\treturn NULL;\n\n\t/* Make sure nothing disappears under us */\n\tget_online_cpus();\n\tsize = num_online_cpus();\n\n\tmask = &event_data->mask;\n\tif (cpu != -1)\n\t\tcpumask_set_cpu(cpu, mask);\n\telse\n\t\tcpumask_copy(mask, cpu_online_mask);\n\tput_online_cpus();\n\n\t/*\n\t * Each CPU has a single path between source and destination.  As such\n\t * allocate an array using CPU numbers as indexes.  That way a path\n\t * for any CPU can easily be accessed at any given time.  We proceed\n\t * the same way for sessions involving a single CPU.  The cost of\n\t * unused memory when dealing with single CPU trace scenarios is small\n\t * compared to the cost of searching through an optimized array.\n\t */\n\tevent_data->path = kcalloc(size,\n\t\t\t\t   sizeof(struct list_head *), GFP_KERNEL);\n\tif (!event_data->path) {\n\t\tkfree(event_data);\n\t\treturn NULL;\n\t}\n\n\treturn event_data;\n}\n\nstatic void etm_free_aux(void *data)\n{\n\tstruct etm_event_data *event_data = data;\n\n\tschedule_work(&event_data->work);\n}\n\nstatic void *etm_setup_aux(int event_cpu, void **pages,\n\t\t\t   int nr_pages, bool overwrite)\n{\n\tint cpu;\n\tcpumask_t *mask;\n\tstruct coresight_device *sink;\n\tstruct etm_event_data *event_data = NULL;\n\n\tevent_data = alloc_event_data(event_cpu);\n\tif (!event_data)\n\t\treturn NULL;\n\n\t/*\n\t * In theory nothing prevent tracers in a trace session from being\n\t * associated with different sinks, nor having a sink per tracer.  But\n\t * until we have HW with this kind of topology we need to assume tracers\n\t * in a trace session are using the same sink.  Therefore go through\n\t * the coresight bus and pick the first enabled sink.\n\t *\n\t * When operated from sysFS users are responsible to enable the sink\n\t * while from perf, the perf tools will do it based on the choice made\n\t * on the cmd line.  As such the \"enable_sink\" flag in sysFS is reset.\n\t */\n\tsink = coresight_get_enabled_sink(true);\n\tif (!sink)\n\t\tgoto err;\n\n\tINIT_WORK(&event_data->work, free_event_data);\n\n\tmask = &event_data->mask;\n\n\t/* Setup the path for each CPU in a trace session */\n\tfor_each_cpu(cpu, mask) {\n\t\tstruct coresight_device *csdev;\n\n\t\tcsdev = per_cpu(csdev_src, cpu);\n\t\tif (!csdev)\n\t\t\tgoto err;\n\n\t\t/*\n\t\t * Building a path doesn't enable it, it simply builds a\n\t\t * list of devices from source to sink that can be\n\t\t * referenced later when the path is actually needed.\n\t\t */\n\t\tevent_data->path[cpu] = coresight_build_path(csdev, sink);\n\t\tif (IS_ERR(event_data->path[cpu]))\n\t\t\tgoto err;\n\t}\n\n\tif (!sink_ops(sink)->alloc_buffer)\n\t\tgoto err;\n\n\tcpu = cpumask_first(mask);\n\t/* Get the AUX specific data from the sink buffer */\n\tevent_data->snk_config =\n\t\t\tsink_ops(sink)->alloc_buffer(sink, cpu, pages,\n\t\t\t\t\t\t     nr_pages, overwrite);\n\tif (!event_data->snk_config)\n\t\tgoto err;\n\nout:\n\treturn event_data;\n\nerr:\n\tetm_free_aux(event_data);\n\tevent_data = NULL;\n\tgoto out;\n}\n\nstatic void etm_event_start(struct perf_event *event, int flags)\n{\n\tint cpu = smp_processor_id();\n\tstruct etm_event_data *event_data;\n\tstruct perf_output_handle *handle = this_cpu_ptr(&ctx_handle);\n\tstruct coresight_device *sink, *csdev = per_cpu(csdev_src, cpu);\n\n\tif (!csdev)\n\t\tgoto fail;\n\n\t/*\n\t * Deal with the ring buffer API and get a handle on the\n\t * session's information.\n\t */\n\tevent_data = perf_aux_output_begin(handle, event);\n\tif (!event_data)\n\t\tgoto fail;\n\n\t/* We need a sink, no need to continue without one */\n\tsink = coresight_get_sink(event_data->path[cpu]);\n\tif (WARN_ON_ONCE(!sink || !sink_ops(sink)->set_buffer))\n\t\tgoto fail_end_stop;\n\n\t/* Configure the sink */\n\tif (sink_ops(sink)->set_buffer(sink, handle,\n\t\t\t\t       event_data->snk_config))\n\t\tgoto fail_end_stop;\n\n\t/* Nothing will happen without a path */\n\tif (coresight_enable_path(event_data->path[cpu], CS_MODE_PERF))\n\t\tgoto fail_end_stop;\n\n\t/* Tell the perf core the event is alive */\n\tevent->hw.state = 0;\n\n\t/* Finally enable the tracer */\n\tif (source_ops(csdev)->enable(csdev, event, CS_MODE_PERF))\n\t\tgoto fail_end_stop;\n\nout:\n\treturn;\n\nfail_end_stop:\n\tperf_aux_output_end(handle, 0, true);\nfail:\n\tevent->hw.state = PERF_HES_STOPPED;\n\tgoto out;\n}\n\nstatic void etm_event_stop(struct perf_event *event, int mode)\n{\n\tbool lost;\n\tint cpu = smp_processor_id();\n\tunsigned long size;\n\tstruct coresight_device *sink, *csdev = per_cpu(csdev_src, cpu);\n\tstruct perf_output_handle *handle = this_cpu_ptr(&ctx_handle);\n\tstruct etm_event_data *event_data = perf_get_aux(handle);\n\n\tif (event->hw.state == PERF_HES_STOPPED)\n\t\treturn;\n\n\tif (!csdev)\n\t\treturn;\n\n\tsink = coresight_get_sink(event_data->path[cpu]);\n\tif (!sink)\n\t\treturn;\n\n\t/* stop tracer */\n\tsource_ops(csdev)->disable(csdev, event);\n\n\t/* tell the core */\n\tevent->hw.state = PERF_HES_STOPPED;\n\n\tif (mode & PERF_EF_UPDATE) {\n\t\tif (WARN_ON_ONCE(handle->event != event))\n\t\t\treturn;\n\n\t\t/* update trace information */\n\t\tif (!sink_ops(sink)->update_buffer)\n\t\t\treturn;\n\n\t\tsink_ops(sink)->update_buffer(sink, handle,\n\t\t\t\t\t      event_data->snk_config);\n\n\t\tif (!sink_ops(sink)->reset_buffer)\n\t\t\treturn;\n\n\t\tsize = sink_ops(sink)->reset_buffer(sink, handle,\n\t\t\t\t\t\t    event_data->snk_config,\n\t\t\t\t\t\t    &lost);\n\n\t\tperf_aux_output_end(handle, size, lost);\n\t}\n\n\t/* Disabling the path make its elements available to other sessions */\n\tcoresight_disable_path(event_data->path[cpu]);\n}\n\nstatic int etm_event_add(struct perf_event *event, int mode)\n{\n\tint ret = 0;\n\tstruct hw_perf_event *hwc = &event->hw;\n\n\tif (mode & PERF_EF_START) {\n\t\tetm_event_start(event, 0);\n\t\tif (hwc->state & PERF_HES_STOPPED)\n\t\t\tret = -EINVAL;\n\t} else {\n\t\thwc->state = PERF_HES_STOPPED;\n\t}\n\n\treturn ret;\n}\n\nstatic void etm_event_del(struct perf_event *event, int mode)\n{\n\tetm_event_stop(event, PERF_EF_UPDATE);\n}\n\nstatic int etm_addr_filters_validate(struct list_head *filters)\n{\n\tbool range = false, address = false;\n\tint index = 0;\n\tstruct perf_addr_filter *filter;\n\n\tlist_for_each_entry(filter, filters, entry) {\n\t\t/*\n\t\t * No need to go further if there's no more\n\t\t * room for filters.\n\t\t */\n\t\tif (++index > ETM_ADDR_CMP_MAX)\n\t\t\treturn -EOPNOTSUPP;\n\n\t\t/*\n\t\t * As taken from the struct perf_addr_filter documentation:\n\t\t *\t@range:\t1: range, 0: address\n\t\t *\n\t\t * At this time we don't allow range and start/stop filtering\n\t\t * to cohabitate, they have to be mutually exclusive.\n\t\t */\n\t\tif ((filter->range == 1) && address)\n\t\t\treturn -EOPNOTSUPP;\n\n\t\tif ((filter->range == 0) && range)\n\t\t\treturn -EOPNOTSUPP;\n\n\t\t/*\n\t\t * For range filtering, the second address in the address\n\t\t * range comparator needs to be higher than the first.\n\t\t * Invalid otherwise.\n\t\t */\n\t\tif (filter->range && filter->size == 0)\n\t\t\treturn -EINVAL;\n\n\t\t/*\n\t\t * Everything checks out with this filter, record what we've\n\t\t * received before moving on to the next one.\n\t\t */\n\t\tif (filter->range)\n\t\t\trange = true;\n\t\telse\n\t\t\taddress = true;\n\t}\n\n\treturn 0;\n}\n\nstatic void etm_addr_filters_sync(struct perf_event *event)\n{\n\tstruct perf_addr_filters_head *head = perf_event_addr_filters(event);\n\tunsigned long start, stop, *offs = event->addr_filters_offs;\n\tstruct etm_filters *filters = event->hw.addr_filters;\n\tstruct etm_filter *etm_filter;\n\tstruct perf_addr_filter *filter;\n\tint i = 0;\n\n\tlist_for_each_entry(filter, &head->list, entry) {\n\t\tstart = filter->offset + offs[i];\n\t\tstop = start + filter->size;\n\t\tetm_filter = &filters->etm_filter[i];\n\n\t\tif (filter->range == 1) {\n\t\t\tetm_filter->start_addr = start;\n\t\t\tetm_filter->stop_addr = stop;\n\t\t\tetm_filter->type = ETM_ADDR_TYPE_RANGE;\n\t\t} else {\n\t\t\tif (filter->filter == 1) {\n\t\t\t\tetm_filter->start_addr = start;\n\t\t\t\tetm_filter->type = ETM_ADDR_TYPE_START;\n\t\t\t} else {\n\t\t\t\tetm_filter->stop_addr = stop;\n\t\t\t\tetm_filter->type = ETM_ADDR_TYPE_STOP;\n\t\t\t}\n\t\t}\n\t\ti++;\n\t}\n\n\tfilters->nr_filters = i;\n}\n\nint etm_perf_symlink(struct coresight_device *csdev, bool link)\n{\n\tchar entry[sizeof(\"cpu9999999\")];\n\tint ret = 0, cpu = source_ops(csdev)->cpu_id(csdev);\n\tstruct device *pmu_dev = etm_pmu.dev;\n\tstruct device *cs_dev = &csdev->dev;\n\n\tsprintf(entry, \"cpu%d\", cpu);\n\n\tif (!etm_perf_up)\n\t\treturn -EPROBE_DEFER;\n\n\tif (link) {\n\t\tret = sysfs_create_link(&pmu_dev->kobj, &cs_dev->kobj, entry);\n\t\tif (ret)\n\t\t\treturn ret;\n\t\tper_cpu(csdev_src, cpu) = csdev;\n\t} else {\n\t\tsysfs_remove_link(&pmu_dev->kobj, entry);\n\t\tper_cpu(csdev_src, cpu) = NULL;\n\t}\n\n\treturn 0;\n}\n\nstatic int __init etm_perf_init(void)\n{\n\tint ret;\n\n\tetm_pmu.capabilities\t\t= PERF_PMU_CAP_EXCLUSIVE;\n\n\tetm_pmu.attr_groups\t\t= etm_pmu_attr_groups;\n\tetm_pmu.task_ctx_nr\t\t= perf_sw_context;\n\tetm_pmu.read\t\t\t= etm_event_read;\n\tetm_pmu.event_init\t\t= etm_event_init;\n\tetm_pmu.setup_aux\t\t= etm_setup_aux;\n\tetm_pmu.free_aux\t\t= etm_free_aux;\n\tetm_pmu.start\t\t\t= etm_event_start;\n\tetm_pmu.stop\t\t\t= etm_event_stop;\n\tetm_pmu.add\t\t\t= etm_event_add;\n\tetm_pmu.del\t\t\t= etm_event_del;\n\tetm_pmu.addr_filters_sync\t= etm_addr_filters_sync;\n\tetm_pmu.addr_filters_validate\t= etm_addr_filters_validate;\n\tetm_pmu.nr_addr_filters\t\t= ETM_ADDR_CMP_MAX;\n\n\tret = perf_pmu_register(&etm_pmu, CORESIGHT_ETM_PMU_NAME, -1);\n\tif (ret == 0)\n\t\tetm_perf_up = true;\n\n\treturn ret;\n}\ndevice_initcall(etm_perf_init);\n"], "filenames": ["drivers/hwtracing/coresight/coresight-etm-perf.c"], "buggy_code_start_loc": [244], "buggy_code_end_loc": [244], "fixing_code_start_loc": [245], "fixing_code_end_loc": [246], "type": "CWE-20", "message": "The etm_setup_aux function in drivers/hwtracing/coresight/coresight-etm-perf.c in the Linux kernel before 4.10.2 allows attackers to cause a denial of service (panic) because a parameter is incorrectly used as a local variable.", "other": {"cve": {"id": "CVE-2018-11232", "sourceIdentifier": "cve@mitre.org", "published": "2018-05-18T04:29:00.227", "lastModified": "2018-06-19T15:07:21.180", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "The etm_setup_aux function in drivers/hwtracing/coresight/coresight-etm-perf.c in the Linux kernel before 4.10.2 allows attackers to cause a denial of service (panic) because a parameter is incorrectly used as a local variable."}, {"lang": "es", "value": "La funci\u00f3n etm_setup_aux function en drivers/hwtracing/coresight/coresight-etm-perf.c en el kernel de Linux en versiones anteriores a la 4.10.2 permite que los atacantes provoquen una denegaci\u00f3n de servicio (p\u00e1nico) debido a que un par\u00e1metro se emplea de forma incorrecta como variable local."}], "metrics": {"cvssMetricV30": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.0", "vectorString": "CVSS:3.0/AV:L/AC:L/PR:L/UI:N/S:U/C:N/I:N/A:H", "attackVector": "LOCAL", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 5.5, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 1.8, "impactScore": 3.6}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:L/AC:L/Au:N/C:N/I:N/A:C", "accessVector": "LOCAL", "accessComplexity": "LOW", "authentication": "NONE", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "COMPLETE", "baseScore": 4.9}, "baseSeverity": "MEDIUM", "exploitabilityScore": 3.9, "impactScore": 6.9, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-20"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionEndExcluding": "4.10.2", "matchCriteriaId": "44AD133E-ADE3-4AEB-84EF-1ED266033EF8"}]}]}], "references": [{"url": "http://git.kernel.org/cgit/linux/kernel/git/torvalds/linux.git/commit/?id=f09444639099584bc4784dfcd85ada67c6f33e0f", "source": "cve@mitre.org", "tags": ["Patch", "Vendor Advisory"]}, {"url": "https://github.com/torvalds/linux/commit/f09444639099584bc4784dfcd85ada67c6f33e0f", "source": "cve@mitre.org", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://www.kernel.org/pub/linux/kernel/v4.x/ChangeLog-4.10.2", "source": "cve@mitre.org", "tags": ["Vendor Advisory"]}]}, "github_commit_url": "https://github.com/torvalds/linux/commit/f09444639099584bc4784dfcd85ada67c6f33e0f"}}
{"buggy_code": ["\"\"\"\nThis module represents OctoPrint's settings management. Within this module the default settings for the core\napplication are defined and the instance of the :class:`Settings` is held, which offers getter and setter\nmethods for the raw configuration values as well as various convenience methods to access the paths to base folders\nof various types and the configuration file itself.\n\n.. autodata:: default_settings\n   :annotation: = dict(...)\n\n.. autodata:: valid_boolean_trues\n\n.. autofunction:: settings\n\n.. autoclass:: Settings\n   :members:\n   :undoc-members:\n\"\"\"\n\n__author__ = \"Gina H\u00e4u\u00dfge <osd@foosel.net>\"\n__license__ = \"GNU Affero General Public License http://www.gnu.org/licenses/agpl.html\"\n__copyright__ = \"Copyright (C) 2014 The OctoPrint Project - Released under terms of the AGPLv3 License\"\n\nimport fnmatch\nimport logging\nimport os\nimport re\nimport sys\nimport threading\nimport time\nfrom collections import ChainMap, defaultdict\nfrom collections.abc import KeysView\n\nfrom yaml import YAMLError\n\nfrom octoprint.schema.config import Config\nfrom octoprint.util import (\n    CaseInsensitiveSet,\n    atomic_write,\n    deprecated,\n    dict_merge,\n    fast_deepcopy,\n    generate_api_key,\n    is_hidden_path,\n    yaml,\n)\n\n_APPNAME = \"OctoPrint\"\n\n_instance = None\n\n\ndef settings(init=False, basedir=None, configfile=None, overlays=None):\n    \"\"\"\n    Factory method for initially constructing and consecutively retrieving the :class:`~octoprint.settings.Settings`\n    singleton.\n\n    Arguments:\n        init (boolean): A flag indicating whether this is the initial call to construct the singleton (True) or not\n            (False, default). If this is set to True and the plugin manager has already been initialized, a :class:`ValueError`\n            will be raised. The same will happen if the plugin manager has not yet been initialized and this is set to\n            False.\n        basedir (str): Path of the base directory for all of OctoPrint's settings, log files, uploads etc. If not set\n            the default will be used: ``~/.octoprint`` on Linux, ``%APPDATA%/OctoPrint`` on Windows and\n            ``~/Library/Application Support/OctoPrint`` on MacOS.\n        configfile (str): Path of the configuration file (``config.yaml``) to work on. If not set the default will\n            be used: ``<basedir>/config.yaml`` for ``basedir`` as defined above.\n        overlays (list): List of paths to config overlays to put between default settings and config.yaml\n\n    Returns:\n        Settings: The fully initialized :class:`Settings` instance.\n\n    Raises:\n        ValueError: ``init`` is True but settings are already initialized or vice versa.\n    \"\"\"\n    global _instance\n    if _instance is not None:\n        if init:\n            raise ValueError(\"Settings Manager already initialized\")\n\n    else:\n        if init:\n            _instance = Settings(\n                configfile=configfile, basedir=basedir, overlays=overlays\n            )\n        else:\n            raise ValueError(\"Settings not initialized yet\")\n\n    return _instance\n\n\n# TODO: This is a temporary solution to get the default settings from the pydantic model.\n_config = Config()\ndefault_settings = _config.dict(by_alias=True)\n\"\"\"The default settings of the core application.\"\"\"\n\nvalid_boolean_trues = CaseInsensitiveSet(True, \"true\", \"yes\", \"y\", \"1\", 1)\n\"\"\" Values that are considered to be equivalent to the boolean ``True`` value, used for type conversion in various places.\"\"\"\n\n\nclass NoSuchSettingsPath(Exception):\n    pass\n\n\nclass InvalidSettings(Exception):\n    pass\n\n\nclass InvalidYaml(InvalidSettings):\n    def __init__(self, file, line=None, column=None, details=None):\n        self.file = file\n        self.line = line\n        self.column = column\n        self.details = details\n\n    def __str__(self):\n        message = (\n            \"Error parsing the configuration file {}, \"\n            \"it is invalid YAML.\".format(self.file)\n        )\n        if self.line and self.column:\n            message += \" The parser reported an error on line {}, column {}.\".format(\n                self.line, self.column\n            )\n        return message\n\n\nclass DuplicateFolderPaths(InvalidSettings):\n    def __init__(self, folders):\n        self.folders = folders\n\n        self.duplicates = {}\n        for folder, path in folders.items():\n            duplicates = []\n            for other_folder, other_path in folders.items():\n                if other_folder == folder:\n                    continue\n                if other_path == path:\n                    duplicates.append(other_folder)\n            if len(duplicates):\n                self.duplicates[folder] = duplicates\n\n    def __str__(self):\n        duplicates = [\n            \"{} (duplicates: {})\".format(folder, \", \".join(dupes))\n            for folder, dupes in self.duplicates.items()\n        ]\n        return \"There are duplicate folder paths configured: {}\".format(\n            \", \".join(duplicates)\n        )\n\n\n_CHAINMAP_SEP = \"\\x1f\"\n\n\nclass HierarchicalChainMap:\n    \"\"\"\n    Stores a bunch of nested dictionaries in chain map, allowing queries of nested values\n    work on lower directories. For example:\n\n    Example:\n        >>> example_dict = {\"a\": \"a\", \"b\": {\"c\": \"c\"}}\n        >>> hcm = HierarchicalChainMap({\"b\": {\"d\": \"d\"}}, example_dict)\n        >>> cm = ChainMap({\"b\": {\"d\": \"d\"}}, example_dict)\n        >>> cm[\"b\"][\"d\"]\n        'd'\n        >>> cm[\"b\"][\"c\"]\n        Traceback (most recent call last):\n            ...\n        KeyError: 'c'\n        >>> hcm.get_by_path([\"b\", \"d\"])\n        'd'\n        >>> hcm.get_by_path([\"b\", \"c\"])\n        'c'\n    \"\"\"\n\n    @staticmethod\n    def _flatten(d: dict, parent_key: str = \"\") -> dict:\n        \"\"\"Flattens a hierarchical dictionary.\"\"\"\n\n        if d is None:\n            return {}\n\n        items = []\n        for k, v in d.items():\n            new_key = parent_key + _CHAINMAP_SEP + str(k) if parent_key else str(k)\n            if v and isinstance(v, dict):\n                items.extend(HierarchicalChainMap._flatten(v, new_key).items())\n            else:\n                items.append((new_key, v))\n        return dict(items)\n\n    @staticmethod\n    def _unflatten(d: dict, prefix: str = \"\") -> dict:\n        \"\"\"Unflattens a flattened dictionary.\"\"\"\n\n        if d is None:\n            return {}\n\n        result = {}\n        for key, value in d.items():\n            if not key.startswith(prefix):\n                continue\n            subkeys = key[len(prefix) :].split(_CHAINMAP_SEP)\n            current = result\n\n            path = []\n            for subkey in subkeys[:-1]:\n                # we only need that for logging in case of data weirdness below\n                path.append(subkey)\n\n                # make sure the subkey is in the current dict, and that it is a dict\n                if subkey not in current:\n                    current[subkey] = {}\n                elif not isinstance(current[subkey], dict):\n                    logging.getLogger(__name__).warning(\n                        f\"There is a non-dict value on the path to {key} at {path!r}, ignoring.\"\n                    )\n                    current[subkey] = {}\n\n                # go down a level\n                current = current[subkey]\n\n            current[subkeys[-1]] = value\n\n        return result\n\n    @staticmethod\n    def _path_to_key(path):\n        \"\"\"\n        :type path: List[str]\n        \"\"\"\n        return _CHAINMAP_SEP.join(path)\n\n    @staticmethod\n    def from_layers(*layers):\n        result = HierarchicalChainMap()\n        result._chainmap.maps = layers\n        return result\n\n    def __init__(self, *maps):\n        self._chainmap = ChainMap(*map(self._flatten, maps))\n\n    def deep_dict(self):\n        return self._unflatten(self._chainmap)\n\n    def has_path(self, path, only_local=False, only_defaults=False):\n        if only_defaults:\n            current = self._chainmap.parents\n        elif only_local:\n            current = self._chainmap.maps[0]\n        else:\n            current = self._chainmap\n\n        key = self._path_to_key(path)\n        prefix = key + _CHAINMAP_SEP\n        return key in current or any(map(lambda x: x.startswith(prefix), current.keys()))\n\n    def get_by_path(self, path, only_local=False, only_defaults=False, merged=False):\n        if only_defaults:\n            current = self._chainmap.parents\n        elif only_local:\n            current = self._chainmap.maps[0]\n        else:\n            current = self._chainmap\n\n        key = self._path_to_key(path)\n        prefix = key + _CHAINMAP_SEP\n\n        if key in current and not any(k.startswith(prefix) for k in current.keys()):\n            # found it, return\n            return current[key]\n\n        # if we arrived here we might be trying to grab a dict, look for children\n\n        # TODO 2.0.0 remove this & make 'merged' the default\n        if not merged and hasattr(current, \"maps\"):\n            # we do something a bit odd here: if merged is not true, we don't include the\n            # full contents of the key. Instead, we only include the contents of the key\n            # on the first level where we find the value.\n            for layer in current.maps:\n                if any(k.startswith(prefix) for k in layer):\n                    current = layer\n                    break\n\n        result = self._unflatten(\n            {k: v for k, v in current.items() if k.startswith(prefix)}, prefix=prefix\n        )\n        if not result:\n            raise KeyError(\"Could not find entry for \" + str(path))\n        return result\n\n    def set_by_path(self, path, value):\n        current = self._chainmap.maps[0]  # config only\n        key = self._path_to_key(path)\n\n        # delete any subkeys\n        self._del_prefix(current, key)\n\n        if isinstance(value, dict):\n            current.update(self._flatten(value, key))\n        else:\n            # make sure to clear anything below the path (e.g. switching from dict\n            # to something else, for whatever reason)\n            self._clean_upward_path(current, path)\n            current[key] = value\n\n    def del_by_path(self, path):\n        if not path:\n            raise ValueError(\"Invalid path\")\n\n        current = self._chainmap.maps[0]  # config only\n        delete_key = self._path_to_key(path)\n        deleted = False\n\n        # delete any subkeys\n        deleted = self._del_prefix(current, delete_key)\n\n        # delete the key itself if it's there\n        try:\n            del current[delete_key]\n            deleted = True\n        except KeyError:\n            pass\n\n        if not deleted:\n            raise KeyError(\"Could not find entry for \" + str(path))\n\n        # clean anything that's now empty and above our path\n        self._clean_upward_path(current, path)\n\n    def _del_prefix(self, current, key):\n        prefix = key + _CHAINMAP_SEP\n\n        to_delete = [k for k in current if k.startswith(prefix)]\n        for k in to_delete:\n            del current[k]\n\n        return len(to_delete) > 0\n\n    def _clean_upward_path(self, current, path):\n        working_path = path\n        while len(working_path):\n            working_path = working_path[:-1]\n            if not working_path:\n                break\n\n            key = self._path_to_key(working_path)\n            prefix = key + _CHAINMAP_SEP\n            if any(map(lambda k: k.startswith(prefix), current)):\n                # there's at least one subkey here, we're done\n                break\n\n            # delete the key itself if it's there\n            try:\n                del current[key]\n            except KeyError:\n                # key itself wasn't in there\n                pass\n\n    def with_config_defaults(self, config=None, defaults=None):\n        \"\"\"\n        Builds a new map with the following layers: provided config + any intermediary\n        parents + provided defaults + regular defaults\n\n        :param config:\n        :param defaults:\n        :return:\n        \"\"\"\n        if config is None and defaults is None:\n            return self\n\n        if config is not None:\n            config = self._flatten(config)\n        else:\n            config = self._chainmap.maps[0]\n\n        if defaults is not None:\n            defaults = [self._flatten(defaults)]\n        else:\n            defaults = []\n\n        layers = [config] + self._middle_layers() + defaults + [self._chainmap.maps[-1]]\n        return HierarchicalChainMap.from_layers(*layers)\n\n    @property\n    def top_map(self):\n        \"\"\"This is the layer that is written to\"\"\"\n        return self._unflatten(self._chainmap.maps[0])\n\n    @top_map.setter\n    def top_map(self, value):\n        self._chainmap.maps[0] = self._flatten(value)\n\n    @property\n    def bottom_map(self):\n        \"\"\"The very bottom layer is the default layer\"\"\"\n        return self._unflatten(self._chainmap.maps[-1])\n\n    def insert_map(self, pos, d):\n        self._chainmap.maps.insert(pos, self._flatten(d))\n\n    def delete_map(self, pos):\n        del self._chainmap.maps[pos]\n\n    @property\n    def all_layers(self):\n        \"\"\"A list of all layers in this map. read-only\"\"\"\n        return self._chainmap.maps\n\n    def _middle_layers(self):\n        if len(self._chainmap.maps) > 2:\n            return self._chainmap.maps[1:-1]\n        else:\n            return []\n\n\nclass Settings:\n    \"\"\"\n    The :class:`Settings` class allows managing all of OctoPrint's settings. It takes care of initializing the settings\n    directory, loading the configuration from ``config.yaml``, persisting changes to disk etc and provides access\n    methods for getting and setting specific values from the overall settings structure via paths.\n\n    A general word on the concept of paths, since they play an important role in OctoPrint's settings management. A\n    path is basically a list or tuple consisting of keys to follow down into the settings (which are basically like\n    a ``dict``) in order to set or retrieve a specific value (or more than one). For example, for a settings\n    structure like the following::\n\n        serial:\n            port: \"/dev/ttyACM0\"\n            baudrate: 250000\n            timeout:\n                communication: 20.0\n                temperature: 5.0\n                sdStatus: 1.0\n                connection: 10.0\n        server:\n            host: \"0.0.0.0\"\n            port: 5000\n\n    the following paths could be used:\n\n    ========================================== ============================================================================\n    Path                                       Value\n    ========================================== ============================================================================\n    ``[\"serial\", \"port\"]``                     ::\n\n                                                   \"/dev/ttyACM0\"\n\n    ``[\"serial\", \"timeout\"]``                  ::\n\n                                                   communication: 20.0\n                                                   temperature: 5.0\n                                                   sdStatus: 1.0\n                                                   connection: 10.0\n\n    ``[\"serial\", \"timeout\", \"temperature\"]``   ::\n\n                                                   5.0\n\n    ``[\"server\", \"port\"]``                     ::\n\n                                                   5000\n\n    ========================================== ============================================================================\n\n    However, these would be invalid paths: ``[\"key\"]``, ``[\"serial\", \"port\", \"value\"]``, ``[\"server\", \"host\", 3]``.\n    \"\"\"\n\n    OVERLAY_KEY = \"__overlay__\"\n\n    def __init__(self, configfile=None, basedir=None, overlays=None):\n        self._logger = logging.getLogger(__name__)\n\n        self._basedir = None\n\n        if overlays is None:\n            overlays = []\n\n        assert isinstance(default_settings, dict)\n\n        self._map = HierarchicalChainMap({}, default_settings)\n        self.load_overlays(overlays)\n\n        self._dirty = False\n        self._dirty_time = 0\n        self._last_config_hash = None\n        self._last_effective_hash = None\n        self._mtime = None\n\n        self._lock = threading.RLock()\n\n        self._get_preprocessors = {\"controls\": self._process_custom_controls}\n        self._set_preprocessors = {}\n        self._path_update_callbacks = defaultdict(list)\n        self._deprecated_paths = defaultdict(dict)\n\n        self._init_basedir(basedir)\n\n        if configfile is not None:\n            self._configfile = configfile\n        else:\n            self._configfile = os.path.join(self._basedir, \"config.yaml\")\n        self.load(migrate=True)\n\n        apikey = self.get([\"api\", \"key\"])\n        if not apikey or apikey == \"n/a\":\n            self.generateApiKey()\n\n        self._script_env = self._init_script_templating()\n\n        self.sanity_check_folders(\n            folders=[\n                \"logs\",\n            ]\n        )\n        self.warn_about_risky_settings()\n\n    def _init_basedir(self, basedir):\n        if basedir is not None:\n            self._basedir = basedir\n        else:\n            self._basedir = _default_basedir(_APPNAME)\n\n        if not os.path.isdir(self._basedir):\n            try:\n                os.makedirs(self._basedir)\n            except Exception:\n                self._logger.fatal(\n                    \"Could not create basefolder at {}. This is a fatal error, OctoPrint \"\n                    \"can't run without a writable base folder.\".format(self._basedir),\n                    exc_info=1,\n                )\n                raise\n\n    def sanity_check_folders(self, folders=None):\n        if folders is None:\n            folders = default_settings[\"folder\"].keys()\n\n        folder_map = {}\n        for folder in folders:\n            folder_map[folder] = self.getBaseFolder(\n                folder, check_writable=True, deep_check_writable=True\n            )\n\n        # validate uniqueness of folder paths\n        if len(folder_map.values()) != len(set(folder_map.values())):\n            raise DuplicateFolderPaths(folders)\n\n    def warn_about_risky_settings(self):\n        if not self.getBoolean([\"devel\", \"enableRateLimiter\"]):\n            self._logger.warning(\n                \"Rate limiting is disabled, this is a security risk. Do not run this in production.\"\n            )\n        if not self.getBoolean([\"devel\", \"enableCsrfProtection\"]):\n            self._logger.warning(\n                \"CSRF Protection is disabled, this is a security risk. Do not run this in production.\"\n            )\n\n    def _is_deprecated_path(self, path):\n        if path and isinstance(path[-1], (list, tuple)):\n            prefix = path[:-1]\n            return any(\n                map(lambda x: bool(self._deprecated_paths[tuple(prefix + [x])]), path[-1])\n            )\n\n        if (\n            tuple(path) not in self._deprecated_paths\n            or not self._deprecated_paths[tuple(path)]\n        ):\n            return False\n\n        try:\n            return list(self._deprecated_paths[tuple(path)].values())[-1]\n        except StopIteration:\n            return False\n\n    def _path_modified(self, path, current_value, new_value):\n        callbacks = self._path_update_callbacks.get(tuple(path))\n        if callbacks:\n            for callback in callbacks:\n                try:\n                    if callable(callback):\n                        callback(path, current_value, new_value)\n                except Exception:\n                    self._logger.exception(\n                        f\"Error while executing callback {callback} for path {path}\"\n                    )\n\n    def _get_default_folder(self, type):\n        folder = default_settings[\"folder\"][type]\n        if folder is None:\n            folder = os.path.join(self._basedir, type.replace(\"_\", os.path.sep))\n        return folder\n\n    def _init_script_templating(self):\n        from jinja2 import BaseLoader, ChoiceLoader, Environment, TemplateNotFound\n        from jinja2.ext import Extension\n        from jinja2.nodes import Include\n\n        from octoprint.util.jinja import FilteredFileSystemLoader\n\n        class SnippetExtension(Extension):\n            tags = {\"snippet\"}\n            fields = Include.fields\n\n            def parse(self, parser):\n                node = parser.parse_include()\n                if not node.template.value.startswith(\"/\"):\n                    node.template.value = \"snippets/\" + node.template.value\n                return node\n\n        class SettingsScriptLoader(BaseLoader):\n            def __init__(self, s):\n                self._settings = s\n\n            def get_source(self, environment, template):\n                parts = template.split(\"/\")\n                if not len(parts):\n                    raise TemplateNotFound(template)\n\n                script = self._settings.get([\"scripts\"], merged=True)\n                for part in parts:\n                    if isinstance(script, dict) and part in script:\n                        script = script[part]\n                    else:\n                        raise TemplateNotFound(template)\n                source = script\n                if source is None:\n                    raise TemplateNotFound(template)\n                mtime = self._settings._mtime\n                return source, None, lambda: mtime == self._settings.last_modified\n\n            def list_templates(self):\n                scripts = self._settings.get([\"scripts\"], merged=True)\n                return self._get_templates(scripts)\n\n            def _get_templates(self, scripts):\n                templates = []\n                for key in scripts:\n                    if isinstance(scripts[key], dict):\n                        templates += list(\n                            map(\n                                lambda x: key + \"/\" + x, self._get_templates(scripts[key])\n                            )\n                        )\n                    elif isinstance(scripts[key], str):\n                        templates.append(key)\n                return templates\n\n        class SelectLoader(BaseLoader):\n            def __init__(self, default, mapping, sep=\":\"):\n                self._default = default\n                self._mapping = mapping\n                self._sep = sep\n\n            def get_source(self, environment, template):\n                if self._sep in template:\n                    prefix, name = template.split(self._sep, 1)\n                    if prefix not in self._mapping:\n                        raise TemplateNotFound(template)\n                    return self._mapping[prefix].get_source(environment, name)\n                return self._default.get_source(environment, template)\n\n            def list_templates(self):\n                return self._default.list_templates()\n\n        class RelEnvironment(Environment):\n            def __init__(self, prefix_sep=\":\", *args, **kwargs):\n                Environment.__init__(self, *args, **kwargs)\n                self._prefix_sep = prefix_sep\n\n            def join_path(self, template, parent):\n                prefix, name = self._split_prefix(template)\n\n                if name.startswith(\"/\"):\n                    return self._join_prefix(prefix, name[1:])\n                else:\n                    _, parent_name = self._split_prefix(parent)\n                    parent_base = parent_name.split(\"/\")[:-1]\n                    return self._join_prefix(prefix, \"/\".join(parent_base) + \"/\" + name)\n\n            def _split_prefix(self, template):\n                if self._prefix_sep in template:\n                    return template.split(self._prefix_sep, 1)\n                else:\n                    return \"\", template\n\n            def _join_prefix(self, prefix, template):\n                if len(prefix):\n                    return prefix + self._prefix_sep + template\n                else:\n                    return template\n\n        path_filter = lambda path: not is_hidden_path(path)\n        file_system_loader = FilteredFileSystemLoader(\n            self.getBaseFolder(\"scripts\"), path_filter=path_filter\n        )\n        settings_loader = SettingsScriptLoader(self)\n        choice_loader = ChoiceLoader([file_system_loader, settings_loader])\n        select_loader = SelectLoader(\n            choice_loader, {\"bundled\": settings_loader, \"file\": file_system_loader}\n        )\n        return RelEnvironment(loader=select_loader, extensions=[SnippetExtension])\n\n    def _get_script_template(self, script_type, name, source=False):\n        from jinja2 import TemplateNotFound\n\n        template_name = script_type + \"/\" + name\n        try:\n            if source:\n                template_name, _, _ = self._script_env.loader.get_source(\n                    self._script_env, template_name\n                )\n                return template_name\n            else:\n                return self._script_env.get_template(template_name)\n        except TemplateNotFound:\n            return None\n        except Exception:\n            self._logger.exception(\n                f\"Exception while trying to resolve template {template_name}\"\n            )\n            return None\n\n    def _get_scripts(self, script_type):\n        return self._script_env.list_templates(\n            filter_func=lambda x: x.startswith(script_type + \"/\")\n        )\n\n    def _process_custom_controls(self, controls):\n        def process_control(c):\n            # shallow copy\n            result = dict(c)\n\n            if \"regex\" in result and \"template\" in result:\n                # if it's a template matcher, we need to add a key to associate with the matcher output\n                import hashlib\n\n                key_hash = hashlib.md5()\n                key_hash.update(result[\"regex\"].encode(\"utf-8\"))\n                result[\"key\"] = key_hash.hexdigest()\n\n                template_key_hash = hashlib.md5()\n                template_key_hash.update(result[\"template\"].encode(\"utf-8\"))\n                result[\"template_key\"] = template_key_hash.hexdigest()\n\n            elif \"children\" in result:\n                # if it has children we need to process them recursively\n                result[\"children\"] = list(\n                    map(\n                        process_control,\n                        [child for child in result[\"children\"] if child is not None],\n                    )\n                )\n\n            return result\n\n        return list(map(process_control, controls))\n\n    def _forget_hashes(self):\n        self._last_config_hash = None\n        self._last_effective_hash = None\n\n    def _mark_dirty(self):\n        with self._lock:\n            self._dirty = True\n            self._dirty_time = time.time()\n            self._forget_hashes()\n\n    @property\n    def effective(self):\n        return self._map.deep_dict()\n\n    @property\n    def effective_yaml(self):\n        return yaml.dump(self.effective)\n\n    @property\n    def effective_hash(self):\n        if self._last_effective_hash is not None:\n            return self._last_effective_hash\n\n        import hashlib\n\n        hash = hashlib.md5()\n        hash.update(self.effective_yaml.encode(\"utf-8\"))\n        self._last_effective_hash = hash.hexdigest()\n        return self._last_effective_hash\n\n    @property\n    def config_yaml(self):\n        return yaml.dump(self.config)\n\n    @property\n    def config_hash(self):\n        if self._last_config_hash:\n            return self._last_config_hash\n\n        import hashlib\n\n        hash = hashlib.md5()\n        hash.update(self.config_yaml.encode(\"utf-8\"))\n        self._last_config_hash = hash.hexdigest()\n        return self._last_config_hash\n\n    @property\n    def config(self):\n        \"\"\"\n        A view of the local config as stored in config.yaml\n\n        Does not support modifications, they will be thrown away silently. If you need to\n        modify anything in the settings, utilize the provided set and remove methods.\n        \"\"\"\n        return self._map.top_map\n\n    @property\n    @deprecated(\n        \"Settings._config has been deprecated and is a read-only view. Please use Settings.config or the set & remove methods instead.\",\n        since=\"1.8.0\",\n    )\n    def _config(self):\n        return self.config\n\n    @_config.setter\n    @deprecated(\n        \"Setting of Settings._config has been deprecated. Please use the set & remove methods instead and get in touch if you have a usecase they don't cover.\",\n        since=\"1.8.0\",\n    )\n    def _config(self, value):\n        self._map.top_map = value\n\n    @property\n    def _overlay_layers(self):\n        if len(self._map.all_layers) > 2:\n            return self._map.all_layers[1:-1]\n        else:\n            return []\n\n    @property\n    def _default_map(self):\n        return self._map.bottom_map\n\n    @property\n    def last_modified(self):\n        \"\"\"\n        Returns:\n            (int) The last modification time of the configuration file.\n        \"\"\"\n        stat = os.stat(self._configfile)\n        return stat.st_mtime\n\n    @property\n    def last_modified_or_made_dirty(self):\n        return max(self.last_modified, self._dirty_time)\n\n    # ~~ load and save\n\n    def load(self, migrate=False):\n        config = None\n        mtime = None\n\n        if os.path.exists(self._configfile) and os.path.isfile(self._configfile):\n            with open(self._configfile, encoding=\"utf-8\", errors=\"replace\") as f:\n                try:\n                    config = yaml.load_from_file(file=f)\n                    mtime = self.last_modified\n\n                except YAMLError as e:\n                    details = str(e)\n\n                    if hasattr(e, \"problem_mark\"):\n                        line = e.problem_mark.line\n                        column = e.problem_mark.column\n                    else:\n                        line = None\n                        column = None\n\n                    raise InvalidYaml(\n                        self._configfile,\n                        details=details,\n                        line=line,\n                        column=column,\n                    )\n\n        # changed from else to handle cases where the file exists, but is empty / 0 bytes\n        if not config or not isinstance(config, dict):\n            config = {}\n\n        self._map.top_map = config\n        self._mtime = mtime\n\n        if migrate:\n            self._migrate_config()\n\n        self._forget_hashes()\n\n    def load_overlays(self, overlays, migrate=True):\n        for overlay in overlays:\n            if not os.path.exists(overlay):\n                continue\n\n            def process(path):\n                try:\n                    overlay_config = self.load_overlay(path, migrate=migrate)\n                    self.add_overlay(overlay_config)\n                    self._logger.info(f\"Added config overlay from {path}\")\n                except Exception:\n                    self._logger.exception(f\"Could not add config overlay from {path}\")\n\n            if os.path.isfile(overlay):\n                process(overlay)\n\n            elif os.path.isdir(overlay):\n                for entry in os.scandir(overlay):\n                    name = entry.name\n                    path = entry.path\n\n                    if is_hidden_path(path) or not fnmatch.fnmatch(name, \"*.yaml\"):\n                        continue\n\n                    process(path)\n\n    def load_overlay(self, overlay, migrate=True):\n        config = None\n\n        if callable(overlay):\n            try:\n                overlay = overlay(self)\n            except Exception:\n                self._logger.exception(\"Error loading overlay from callable\")\n                return\n\n        if isinstance(overlay, str):\n            if os.path.exists(overlay) and os.path.isfile(overlay):\n                config = yaml.load_from_file(path=overlay)\n        elif isinstance(overlay, dict):\n            config = overlay\n        else:\n            raise ValueError(\n                \"Overlay must be either a path to a yaml file or a dictionary\"\n            )\n\n        if not isinstance(config, dict):\n            raise ValueError(\n                f\"Configuration data must be a dict but is a {config.__class__}\"\n            )\n\n        if migrate:\n            self._migrate_config(config)\n        return config\n\n    def add_overlay(\n        self, overlay, at_end=False, key=None, deprecated=None, replace=False\n    ):\n        assert isinstance(overlay, dict)\n\n        if key is None:\n            overlay_yaml = yaml.dump(overlay)\n            import hashlib\n\n            hash = hashlib.md5()\n            hash.update(overlay_yaml.encode(\"utf-8\"))\n            key = hash.hexdigest()\n\n        if replace:\n            self.remove_overlay(key)\n\n        if deprecated is not None:\n            self._logger.debug(\n                f\"Marking all (recursive) paths in this overlay as deprecated: {overlay}\"\n            )\n            for path in _paths([], overlay):\n                self._deprecated_paths[tuple(path)][key] = deprecated\n\n        overlay[self.OVERLAY_KEY] = key\n        if at_end:\n            self._map.insert_map(-1, overlay)\n        else:\n            self._map.insert_map(1, overlay)\n\n        return key\n\n    def remove_overlay(self, key):\n        index = -1\n        for i, overlay in enumerate(self._overlay_layers):\n            if key == overlay.get(self.OVERLAY_KEY):\n                index = i\n                overlay = self._map._unflatten(overlay)\n                break\n\n        if index > -1:\n            self._map.delete_map(index + 1)\n\n            self._logger.debug(\n                f\"Removing all deprecation marks for (recursive) paths in this overlay: {overlay}\"\n            )\n            for path in _paths([], overlay):\n                try:\n                    del self._deprecated_paths[tuple(path)][key]\n                except KeyError:\n                    # key not in dict\n                    pass\n\n            return True\n        return False\n\n    def add_path_update_callback(self, path, callback):\n        callbacks = self._path_update_callbacks[tuple(path)]\n        if callback not in callbacks:\n            callbacks.append(callback)\n\n    def remove_path_update_callback(self, path, callback):\n        try:\n            self._path_update_callbacks[tuple(path)].remove(callback)\n        except ValueError:\n            # callback not in list\n            pass\n\n    def _migrate_config(self, config=None, persist=False):\n        if config is None:\n            config = self._map.top_map\n            persist = True\n\n        dirty = False\n\n        migrators = (\n            self._migrate_event_config,\n            self._migrate_reverse_proxy_config,\n            self._migrate_printer_parameters,\n            self._migrate_gcode_scripts,\n            self._migrate_core_system_commands,\n            self._migrate_serial_features,\n            self._migrate_resend_without_ok,\n            self._migrate_string_temperature_profile_values,\n            self._migrate_blocked_commands,\n            self._migrate_gcodeviewer_enabled,\n        )\n\n        for migrate in migrators:\n            dirty = migrate(config) or dirty\n\n        if dirty and persist:\n            self._map.top_map = (\n                config  # we need to write it back here or the changes will be lost\n            )\n            self.save(force=True)\n\n    def _migrate_gcode_scripts(self, config):\n        \"\"\"\n        Migrates an old development version of gcode scripts to the new template based format.\n\n        Added in 1.2.0\n        \"\"\"\n\n        dirty = False\n        if \"scripts\" in config:\n            if \"gcode\" in config[\"scripts\"]:\n                if \"templates\" in config[\"scripts\"][\"gcode\"]:\n                    del config[\"scripts\"][\"gcode\"][\"templates\"]\n\n                replacements = {\n                    \"disable_steppers\": \"M84\",\n                    \"disable_hotends\": \"{% snippet 'disable_hotends' %}\",\n                    \"disable_bed\": \"M140 S0\",\n                    \"disable_fan\": \"M106 S0\",\n                }\n\n                for name, script in config[\"scripts\"][\"gcode\"].items():\n                    self.saveScript(\"gcode\", name, script.format(**replacements))\n            del config[\"scripts\"]\n            dirty = True\n        return dirty\n\n    def _migrate_printer_parameters(self, config):\n        \"\"\"\n        Migrates the old \"printer > parameters\" data structure to the new printer profile mechanism.\n\n        Added in 1.2.0\n        \"\"\"\n        default_profile = (\n            config[\"printerProfiles\"][\"defaultProfile\"]\n            if \"printerProfiles\" in config\n            and \"defaultProfile\" in config[\"printerProfiles\"]\n            else {}\n        )\n        dirty = False\n\n        if \"printerParameters\" in config:\n            printer_parameters = config[\"printerParameters\"]\n\n            if (\n                \"movementSpeed\" in printer_parameters\n                or \"invertAxes\" in printer_parameters\n            ):\n                dirty = True\n                default_profile[\"axes\"] = {\"x\": {}, \"y\": {}, \"z\": {}, \"e\": {}}\n                if \"movementSpeed\" in printer_parameters:\n                    for axis in (\"x\", \"y\", \"z\", \"e\"):\n                        if axis in printer_parameters[\"movementSpeed\"]:\n                            default_profile[\"axes\"][axis][\"speed\"] = printer_parameters[\n                                \"movementSpeed\"\n                            ][axis]\n                    del config[\"printerParameters\"][\"movementSpeed\"]\n                if \"invertedAxes\" in printer_parameters:\n                    for axis in (\"x\", \"y\", \"z\", \"e\"):\n                        if axis in printer_parameters[\"invertedAxes\"]:\n                            default_profile[\"axes\"][axis][\"inverted\"] = True\n                    del config[\"printerParameters\"][\"invertedAxes\"]\n\n            if (\n                \"numExtruders\" in printer_parameters\n                or \"extruderOffsets\" in printer_parameters\n            ):\n                dirty = True\n                if \"extruder\" not in default_profile:\n                    default_profile[\"extruder\"] = {}\n\n                if \"numExtruders\" in printer_parameters:\n                    default_profile[\"extruder\"][\"count\"] = printer_parameters[\n                        \"numExtruders\"\n                    ]\n                    del config[\"printerParameters\"][\"numExtruders\"]\n                if \"extruderOffsets\" in printer_parameters:\n                    extruder_offsets = []\n                    for offset in printer_parameters[\"extruderOffsets\"]:\n                        if \"x\" in offset and \"y\" in offset:\n                            extruder_offsets.append((offset[\"x\"], offset[\"y\"]))\n                    default_profile[\"extruder\"][\"offsets\"] = extruder_offsets\n                    del config[\"printerParameters\"][\"extruderOffsets\"]\n\n            if \"bedDimensions\" in printer_parameters:\n                dirty = True\n                bed_dimensions = printer_parameters[\"bedDimensions\"]\n                if \"volume\" not in default_profile:\n                    default_profile[\"volume\"] = {}\n\n                if (\n                    \"circular\" in bed_dimensions\n                    and \"r\" in bed_dimensions\n                    and bed_dimensions[\"circular\"]\n                ):\n                    default_profile[\"volume\"][\"formFactor\"] = \"circular\"\n                    default_profile[\"volume\"][\"width\"] = 2 * bed_dimensions[\"r\"]\n                    default_profile[\"volume\"][\"depth\"] = default_profile[\"volume\"][\n                        \"width\"\n                    ]\n                elif \"x\" in bed_dimensions or \"y\" in bed_dimensions:\n                    default_profile[\"volume\"][\"formFactor\"] = \"rectangular\"\n                    if \"x\" in bed_dimensions:\n                        default_profile[\"volume\"][\"width\"] = bed_dimensions[\"x\"]\n                    if \"y\" in bed_dimensions:\n                        default_profile[\"volume\"][\"depth\"] = bed_dimensions[\"y\"]\n                del config[\"printerParameters\"][\"bedDimensions\"]\n\n        if dirty:\n            if \"printerProfiles\" not in config:\n                config[\"printerProfiles\"] = {}\n            config[\"printerProfiles\"][\"defaultProfile\"] = default_profile\n        return dirty\n\n    def _migrate_reverse_proxy_config(self, config):\n        \"\"\"\n        Migrates the old \"server > baseUrl\" and \"server > scheme\" configuration entries to\n        \"server > reverseProxy > prefixFallback\" and \"server > reverseProxy > schemeFallback\".\n\n        Added in 1.2.0\n        \"\"\"\n        if \"server\" in config and (\n            \"baseUrl\" in config[\"server\"] or \"scheme\" in config[\"server\"]\n        ):\n            prefix = \"\"\n            if \"baseUrl\" in config[\"server\"]:\n                prefix = config[\"server\"][\"baseUrl\"]\n                del config[\"server\"][\"baseUrl\"]\n\n            scheme = \"\"\n            if \"scheme\" in config[\"server\"]:\n                scheme = config[\"server\"][\"scheme\"]\n                del config[\"server\"][\"scheme\"]\n\n            if \"reverseProxy\" not in config[\"server\"] or not isinstance(\n                config[\"server\"][\"reverseProxy\"], dict\n            ):\n                config[\"server\"][\"reverseProxy\"] = {}\n            if prefix:\n                config[\"server\"][\"reverseProxy\"][\"prefixFallback\"] = prefix\n            if scheme:\n                config[\"server\"][\"reverseProxy\"][\"schemeFallback\"] = scheme\n            self._logger.info(\"Migrated reverse proxy configuration to new structure\")\n            return True\n        else:\n            return False\n\n    def _migrate_event_config(self, config):\n        \"\"\"\n        Migrates the old event configuration format of type \"events > gcodeCommandTrigger\" and\n        \"event > systemCommandTrigger\" to the new events format.\n\n        Added in 1.2.0\n        \"\"\"\n        if \"events\" in config and (\n            \"gcodeCommandTrigger\" in config[\"events\"]\n            or \"systemCommandTrigger\" in config[\"events\"]\n        ):\n            self._logger.info(\"Migrating config (event subscriptions)...\")\n\n            # migrate event hooks to new format\n            placeholderRe = re.compile(r\"%\\((.*?)\\)s\")\n\n            eventNameReplacements = {\n                \"ClientOpen\": \"ClientOpened\",\n                \"TransferStart\": \"TransferStarted\",\n            }\n            payloadDataReplacements = {\n                \"Upload\": {\"data\": \"{file}\", \"filename\": \"{file}\"},\n                \"Connected\": {\"data\": \"{port} at {baudrate} baud\"},\n                \"FileSelected\": {\"data\": \"{file}\", \"filename\": \"{file}\"},\n                \"TransferStarted\": {\"data\": \"{remote}\", \"filename\": \"{remote}\"},\n                \"TransferDone\": {\"data\": \"{remote}\", \"filename\": \"{remote}\"},\n                \"ZChange\": {\"data\": \"{new}\"},\n                \"CaptureStart\": {\"data\": \"{file}\"},\n                \"CaptureDone\": {\"data\": \"{file}\"},\n                \"MovieDone\": {\"data\": \"{movie}\", \"filename\": \"{gcode}\"},\n                \"Error\": {\"data\": \"{error}\"},\n                \"PrintStarted\": {\"data\": \"{file}\", \"filename\": \"{file}\"},\n                \"PrintDone\": {\"data\": \"{file}\", \"filename\": \"{file}\"},\n            }\n\n            def migrateEventHook(event, command):\n                # migrate placeholders\n                command = placeholderRe.sub(\"{__\\\\1}\", command)\n\n                # migrate event names\n                if event in eventNameReplacements:\n                    event = eventNameReplacements[\"event\"]\n\n                # migrate payloads to more specific placeholders\n                if event in payloadDataReplacements:\n                    for key in payloadDataReplacements[event]:\n                        command = command.replace(\n                            \"{__%s}\" % key, payloadDataReplacements[event][key]\n                        )\n\n                # return processed tuple\n                return event, command\n\n            disableSystemCommands = False\n            if (\n                \"systemCommandTrigger\" in config[\"events\"]\n                and \"enabled\" in config[\"events\"][\"systemCommandTrigger\"]\n            ):\n                disableSystemCommands = not config[\"events\"][\"systemCommandTrigger\"][\n                    \"enabled\"\n                ]\n\n            disableGcodeCommands = False\n            if (\n                \"gcodeCommandTrigger\" in config[\"events\"]\n                and \"enabled\" in config[\"events\"][\"gcodeCommandTrigger\"]\n            ):\n                disableGcodeCommands = not config[\"events\"][\"gcodeCommandTrigger\"][\n                    \"enabled\"\n                ]\n\n            disableAllCommands = disableSystemCommands and disableGcodeCommands\n            newEvents = {\"enabled\": not disableAllCommands, \"subscriptions\": []}\n\n            if (\n                \"systemCommandTrigger\" in config[\"events\"]\n                and \"subscriptions\" in config[\"events\"][\"systemCommandTrigger\"]\n            ):\n                for trigger in config[\"events\"][\"systemCommandTrigger\"][\"subscriptions\"]:\n                    if not (\"event\" in trigger and \"command\" in trigger):\n                        continue\n\n                    newTrigger = {\"type\": \"system\"}\n                    if disableSystemCommands and not disableAllCommands:\n                        newTrigger[\"enabled\"] = False\n\n                    newTrigger[\"event\"], newTrigger[\"command\"] = migrateEventHook(\n                        trigger[\"event\"], trigger[\"command\"]\n                    )\n                    newEvents[\"subscriptions\"].append(newTrigger)\n\n            if (\n                \"gcodeCommandTrigger\" in config[\"events\"]\n                and \"subscriptions\" in config[\"events\"][\"gcodeCommandTrigger\"]\n            ):\n                for trigger in config[\"events\"][\"gcodeCommandTrigger\"][\"subscriptions\"]:\n                    if not (\"event\" in trigger and \"command\" in trigger):\n                        continue\n\n                    newTrigger = {\"type\": \"gcode\"}\n                    if disableGcodeCommands and not disableAllCommands:\n                        newTrigger[\"enabled\"] = False\n\n                    newTrigger[\"event\"], newTrigger[\"command\"] = migrateEventHook(\n                        trigger[\"event\"], trigger[\"command\"]\n                    )\n                    newTrigger[\"command\"] = newTrigger[\"command\"].split(\",\")\n                    newEvents[\"subscriptions\"].append(newTrigger)\n\n            config[\"events\"] = newEvents\n            self._logger.info(\n                \"Migrated %d event subscriptions to new format and structure\"\n                % len(newEvents[\"subscriptions\"])\n            )\n            return True\n        else:\n            return False\n\n    def _migrate_core_system_commands(self, config):\n        \"\"\"\n        Migrates system commands for restart, reboot and shutdown as defined on OctoPi or\n        according to the official setup guide to new core system commands to remove\n        duplication.\n\n        If server commands for action is not yet set, migrates command. Otherwise only\n        deletes definition from custom system commands.\n\n        Added in 1.3.0\n        \"\"\"\n        changed = False\n\n        migration_map = {\n            \"shutdown\": \"systemShutdownCommand\",\n            \"reboot\": \"systemRestartCommand\",\n            \"restart\": \"serverRestartCommand\",\n        }\n\n        if (\n            \"system\" in config\n            and \"actions\" in config[\"system\"]\n            and isinstance(config[\"system\"][\"actions\"], (list, tuple))\n        ):\n            actions = config[\"system\"][\"actions\"]\n            to_delete = []\n            for index, spec in enumerate(actions):\n                action = spec.get(\"action\")\n                command = spec.get(\"command\")\n                if action is None or command is None:\n                    continue\n\n                migrate_to = migration_map.get(action)\n                if migrate_to is not None:\n                    if (\n                        \"server\" not in config\n                        or \"commands\" not in config[\"server\"]\n                        or migrate_to not in config[\"server\"][\"commands\"]\n                    ):\n                        if \"server\" not in config:\n                            config[\"server\"] = {}\n                        if \"commands\" not in config[\"server\"]:\n                            config[\"server\"][\"commands\"] = {}\n                        config[\"server\"][\"commands\"][migrate_to] = command\n                        self._logger.info(\n                            \"Migrated {} action to server.commands.{}\".format(\n                                action, migrate_to\n                            )\n                        )\n\n                    to_delete.append(index)\n                    self._logger.info(\n                        \"Deleting {} action from configured system commands, superseded by server.commands.{}\".format(\n                            action, migrate_to\n                        )\n                    )\n\n            for index in reversed(to_delete):\n                actions.pop(index)\n                changed = True\n\n        if changed:\n            # let's make a backup of our current config, in case someone wants to roll back to an\n            # earlier version and needs to recover the former system commands for that\n            backup_path = self.backup(\"system_command_migration\")\n            self._logger.info(\n                \"Made a copy of the current config at {} to allow recovery of manual system command configuration\".format(\n                    backup_path\n                )\n            )\n\n        return changed\n\n    def _migrate_serial_features(self, config):\n        \"\"\"\n        Migrates feature flags identified as serial specific from the feature to the serial config tree and vice versa.\n\n        If a flag already exists in the target tree, only deletes the copy in the source tree.\n\n        Added in 1.3.7\n        \"\"\"\n        changed = False\n\n        FEATURE_TO_SERIAL = (\n            \"waitForStartOnConnect\",\n            \"alwaysSendChecksum\",\n            \"neverSendChecksum\",\n            \"sendChecksumWithUnknownCommands\",\n            \"unknownCommandsNeedAck\",\n            \"sdRelativePath\",\n            \"sdAlwaysAvailable\",\n            \"swallowOkAfterResend\",\n            \"repetierTargetTemp\",\n            \"externalHeatupDetection\",\n            \"supportWait\",\n            \"ignoreIdenticalResends\",\n            \"identicalResendsCountdown\",\n            \"supportFAsCommand\",\n            \"firmwareDetection\",\n            \"blockWhileDwelling\",\n        )\n        SERIAL_TO_FEATURE = (\"autoUppercaseBlacklist\",)\n\n        def migrate_key(key, source, target):\n            if source in config and key in config[source]:\n                if config.get(target) is None:\n                    # make sure we have a serial tree\n                    config[target] = {}\n                if key not in config[target]:\n                    # only copy over if it's not there yet\n                    config[target][key] = config[source][key]\n                # delete feature flag\n                del config[source][key]\n                return True\n            return False\n\n        for key in FEATURE_TO_SERIAL:\n            changed = migrate_key(key, \"feature\", \"serial\") or changed\n\n        for key in SERIAL_TO_FEATURE:\n            changed = migrate_key(key, \"serial\", \"feature\") or changed\n\n        if changed:\n            # let's make a backup of our current config, in case someone wants to roll back to an\n            # earlier version and needs a backup of their flags\n            backup_path = self.backup(\"serial_feature_migration\")\n            self._logger.info(\n                \"Made a copy of the current config at {} to allow recovery of serial feature flags\".format(\n                    backup_path\n                )\n            )\n\n        return changed\n\n    def _migrate_resend_without_ok(self, config):\n        \"\"\"\n        Migrates supportResendsWithoutOk flag from boolean to (\"always\", \"detect\", \"never\") value range.\n\n        True gets migrated to \"always\", False to \"detect\" (which is the new default).\n\n        Added in 1.3.7\n        \"\"\"\n        if (\n            \"serial\" in config\n            and \"supportResendsWithoutOk\" in config[\"serial\"]\n            and config[\"serial\"][\"supportResendsWithoutOk\"]\n            not in (\"always\", \"detect\", \"never\")\n        ):\n            value = config[\"serial\"][\"supportResendsWithoutOk\"]\n            if value:\n                config[\"serial\"][\"supportResendsWithoutOk\"] = \"always\"\n            else:\n                config[\"serial\"][\"supportResendsWithoutOk\"] = \"detect\"\n            return True\n        return False\n\n    def _migrate_string_temperature_profile_values(self, config):\n        \"\"\"\n        Migrates/fixes temperature profile wrongly saved with strings instead of ints as temperature values.\n\n        Added in 1.3.8\n        \"\"\"\n        if \"temperature\" in config and \"profiles\" in config[\"temperature\"]:\n            profiles = config[\"temperature\"][\"profiles\"]\n            if any(\n                map(\n                    lambda x: not isinstance(x.get(\"extruder\", 0), int)\n                    or not isinstance(x.get(\"bed\", 0), int),\n                    profiles,\n                )\n            ):\n                result = []\n                for profile in profiles:\n                    try:\n                        profile[\"extruder\"] = int(profile[\"extruder\"])\n                        profile[\"bed\"] = int(profile[\"bed\"])\n                    except ValueError:\n                        pass\n                    result.append(profile)\n                config[\"temperature\"][\"profiles\"] = result\n                return True\n        return False\n\n    def _migrate_blocked_commands(self, config):\n        if \"serial\" in config and \"blockM0M1\" in config[\"serial\"]:\n            blockM0M1 = config[\"serial\"][\"blockM0M1\"]\n            blockedCommands = config[\"serial\"].get(\"blockedCommands\", [])\n            if blockM0M1:\n                blockedCommands = set(blockedCommands)\n                blockedCommands.add(\"M0\")\n                blockedCommands.add(\"M1\")\n                config[\"serial\"][\"blockedCommands\"] = sorted(blockedCommands)\n            else:\n                config[\"serial\"][\"blockedCommands\"] = sorted(\n                    v for v in blockedCommands if v not in (\"M0\", \"M1\")\n                )\n            del config[\"serial\"][\"blockM0M1\"]\n            return True\n        return False\n\n    def _migrate_gcodeviewer_enabled(self, config):\n        if (\n            \"gcodeViewer\" in config\n            and \"enabled\" in config[\"gcodeViewer\"]\n            and not config[\"gcodeViewer\"][\"enabled\"]\n        ):\n            if \"plugins\" not in config:\n                config[\"plugins\"] = {}\n            if \"_disabled\" not in config[\"plugins\"]:\n                config[\"plugins\"][\"_disabled\"] = []\n            config[\"plugins\"][\"_disabled\"].append(\"gcodeviewer\")\n            del config[\"gcodeViewer\"][\"enabled\"]\n            return True\n        return False\n\n    def backup(self, suffix=None, path=None, ext=None, hidden=False):\n        import shutil\n\n        if path is None:\n            path = os.path.dirname(self._configfile)\n\n        basename = os.path.basename(self._configfile)\n        name, default_ext = os.path.splitext(basename)\n\n        if ext is None:\n            ext = default_ext\n\n        if suffix is None and ext == default_ext:\n            raise ValueError(\"Need a suffix or a different extension\")\n\n        if suffix is None:\n            suffix = \"\"\n\n        backup = os.path.join(\n            path, \"{}{}.{}{}\".format(\".\" if hidden else \"\", name, suffix, ext)\n        )\n        shutil.copy(self._configfile, backup)\n        return backup\n\n    def save(self, force=False, trigger_event=False):\n        with self._lock:\n            if not self._dirty and not force:\n                return False\n\n            try:\n                with atomic_write(\n                    self._configfile,\n                    mode=\"wt\",\n                    prefix=\"octoprint-config-\",\n                    suffix=\".yaml\",\n                    permissions=0o600,\n                    max_permissions=0o666,\n                ) as configFile:\n                    yaml.save_to_file(self._map.top_map, file=configFile)\n                    self._dirty = False\n            except Exception:\n                self._logger.exception(\"Error while saving config.yaml!\")\n                raise\n            else:\n                from octoprint.events import Events, eventManager\n\n                self.load()\n\n                if trigger_event:\n                    payload = {\n                        \"config_hash\": self.config_hash,\n                        \"effective_hash\": self.effective_hash,\n                    }\n                    eventManager().fire(Events.SETTINGS_UPDATED, payload=payload)\n\n                return True\n\n    ##~~ Internal getter\n\n    def _get_by_path(self, path, config):\n        current = config\n        for key in path:\n            if key not in current:\n                raise NoSuchSettingsPath()\n            current = current[key]\n        return current\n\n    def _get_value(\n        self,\n        path,\n        asdict=False,\n        config=None,\n        defaults=None,\n        preprocessors=None,\n        merged=False,\n        incl_defaults=True,\n        do_copy=True,\n    ):\n        if not path:\n            raise NoSuchSettingsPath()\n\n        is_deprecated = self._is_deprecated_path(path)\n        if is_deprecated:\n            self._logger.warning(\n                f\"DeprecationWarning: Detected access to deprecated settings path {path}, returned value is derived from compatibility overlay. {is_deprecated if isinstance(is_deprecated, str) else ''}\"\n            )\n            config = {}\n\n        chain = self._map.with_config_defaults(config=config, defaults=defaults)\n\n        if preprocessors is None:\n            preprocessors = self._get_preprocessors\n\n        preprocessor = None\n        try:\n            preprocessor = self._get_by_path(path, preprocessors)\n        except NoSuchSettingsPath:\n            pass\n\n        parent_path = path[:-1]\n        last = path[-1]\n\n        if not isinstance(last, (list, tuple)):\n            keys = [last]\n        else:\n            keys = last\n\n        if asdict:\n            results = {}\n        else:\n            results = list()\n\n        for key in keys:\n            try:\n                value = chain.get_by_path(\n                    parent_path + [key], only_local=not incl_defaults, merged=merged\n                )\n            except KeyError:\n                raise NoSuchSettingsPath()\n\n            if isinstance(value, dict) and merged:\n                try:\n                    default_value = chain.get_by_path(\n                        parent_path + [key], only_defaults=True, merged=True\n                    )\n                    if default_value is not None:\n                        value = dict_merge(default_value, value)\n                except KeyError:\n                    raise NoSuchSettingsPath()\n\n            if callable(preprocessor):\n                value = preprocessor(value)\n\n            if do_copy:\n                if isinstance(value, KeysView):\n                    value = list(value)\n                value = fast_deepcopy(value)\n\n            if asdict:\n                results[key] = value\n            else:\n                results.append(value)\n\n        if not isinstance(last, (list, tuple)):\n            if asdict:\n                return list(results.values()).pop()\n            else:\n                return results.pop()\n        else:\n            return results\n\n    # ~~ has\n\n    def has(self, path, **kwargs):\n        try:\n            self._get_value(path, **kwargs)\n        except NoSuchSettingsPath:\n            return False\n        else:\n            return True\n\n    # ~~ getter\n\n    def get(self, path, **kwargs):\n        error_on_path = kwargs.pop(\"error_on_path\", False)\n        validator = kwargs.pop(\"validator\", None)\n        fallback = kwargs.pop(\"fallback\", None)\n\n        def process():\n            try:\n                return self._get_value(path, **kwargs)\n            except NoSuchSettingsPath:\n                if error_on_path:\n                    raise\n                return None\n\n        result = process()\n        if callable(validator) and not validator(result):\n            result = fallback\n        return result\n\n    def getInt(self, path, **kwargs):\n        minimum = kwargs.pop(\"min\", None)\n        maximum = kwargs.pop(\"max\", None)\n\n        value = self.get(path, **kwargs)\n        if value is None:\n            return None\n\n        try:\n            intValue = int(value)\n\n            if minimum is not None and intValue < minimum:\n                return minimum\n            elif maximum is not None and intValue > maximum:\n                return maximum\n            else:\n                return intValue\n        except ValueError:\n            self._logger.warning(\n                \"Could not convert %r to a valid integer when getting option %r\"\n                % (value, path)\n            )\n            return None\n\n    def getFloat(self, path, **kwargs):\n        minimum = kwargs.pop(\"min\", None)\n        maximum = kwargs.pop(\"max\", None)\n\n        value = self.get(path, **kwargs)\n        if value is None:\n            return None\n\n        try:\n            floatValue = float(value)\n\n            if minimum is not None and floatValue < minimum:\n                return minimum\n            elif maximum is not None and floatValue > maximum:\n                return maximum\n            else:\n                return floatValue\n        except ValueError:\n            self._logger.warning(\n                \"Could not convert %r to a valid integer when getting option %r\"\n                % (value, path)\n            )\n            return None\n\n    def getBoolean(self, path, **kwargs):\n        value = self.get(path, **kwargs)\n        if value is None:\n            return None\n        if isinstance(value, bool):\n            return value\n        if isinstance(value, (int, float)):\n            return value != 0\n        if isinstance(value, str):\n            return value.lower() in valid_boolean_trues\n        return value is not None\n\n    def checkBaseFolder(self, type):\n        if type != \"base\" and type not in default_settings[\"folder\"]:\n            return False\n\n        if type == \"base\":\n            return os.path.exists(self._basedir)\n\n        folder = self.get([\"folder\", type])\n        default_folder = self._get_default_folder(type)\n        if folder is None:\n            folder = default_folder\n        return os.path.exists(folder)\n\n    def getBaseFolder(\n        self,\n        type,\n        create=True,\n        allow_fallback=True,\n        check_writable=True,\n        deep_check_writable=False,\n    ):\n        if type != \"base\" and type not in default_settings[\"folder\"]:\n            return None\n\n        if type == \"base\":\n            return self._basedir\n\n        folder = self.get([\"folder\", type])\n        default_folder = self._get_default_folder(type)\n        if folder is None:\n            folder = default_folder\n\n        try:\n            _validate_folder(\n                folder,\n                create=create,\n                check_writable=check_writable,\n                deep_check_writable=deep_check_writable,\n            )\n        except Exception:\n            if folder != default_folder and allow_fallback:\n                self._logger.exception(\n                    \"Invalid configured {} folder at {}, attempting to \"\n                    \"fall back on default folder at {}\".format(\n                        type, folder, default_folder\n                    )\n                )\n                _validate_folder(\n                    default_folder,\n                    create=create,\n                    check_writable=check_writable,\n                    deep_check_writable=deep_check_writable,\n                )\n                folder = default_folder\n\n                try:\n                    self.remove([\"folder\", type])\n                    self.save()\n                except KeyError:\n                    pass\n            else:\n                raise\n\n        return folder\n\n    def listScripts(self, script_type):\n        return list(\n            map(\n                lambda x: x[len(script_type + \"/\") :],\n                filter(\n                    lambda x: x.startswith(script_type + \"/\"),\n                    self._get_scripts(script_type),\n                ),\n            )\n        )\n\n    def loadScript(self, script_type, name, context=None, source=False):\n        if context is None:\n            context = {}\n        context.update({\"script\": {\"type\": script_type, \"name\": name}})\n\n        template = self._get_script_template(script_type, name, source=source)\n        if template is None:\n            return None\n\n        if source:\n            script = template\n        else:\n            try:\n                script = template.render(**context)\n            except Exception:\n                self._logger.exception(\n                    f\"Exception while trying to render script {script_type}:{name}\"\n                )\n                return None\n\n        return script\n\n    # ~~ remove\n\n    def remove(self, path, config=None, error_on_path=False, defaults=None):\n        if not path:\n            if error_on_path:\n                raise NoSuchSettingsPath()\n            return\n\n        chain = self._map.with_config_defaults(config=config, defaults=defaults)\n\n        try:\n            with self._lock:\n                chain.del_by_path(path)\n                self._mark_dirty()\n        except KeyError:\n            if error_on_path:\n                raise NoSuchSettingsPath()\n            pass\n\n    # ~~ setter\n\n    def set(\n        self,\n        path,\n        value,\n        force=False,\n        defaults=None,\n        config=None,\n        preprocessors=None,\n        error_on_path=False,\n        *args,\n        **kwargs,\n    ):\n        if not path:\n            if error_on_path:\n                raise NoSuchSettingsPath()\n            return\n\n        is_deprecated = self._is_deprecated_path(path)\n        if is_deprecated:\n            self._logger.warning(\n                f\"[Deprecation] Prevented write of `{value}` to deprecated settings path {path}. {is_deprecated if isinstance(is_deprecated, str) else ''}\"\n            )\n            return\n\n        if self._mtime is not None and self.last_modified != self._mtime:\n            self.load()\n\n        chain = self._map.with_config_defaults(config=config, defaults=defaults)\n\n        if preprocessors is None:\n            preprocessors = self._set_preprocessors\n\n        preprocessor = None\n        try:\n            preprocessor = self._get_by_path(path, preprocessors)\n        except NoSuchSettingsPath:\n            pass\n\n        if callable(preprocessor):\n            value = preprocessor(value)\n\n        try:\n            current = chain.get_by_path(path)\n        except KeyError:\n            current = None\n\n        try:\n            default_value = chain.get_by_path(path, only_defaults=True)\n        except KeyError:\n            if error_on_path:\n                raise NoSuchSettingsPath()\n            default_value = None\n\n        with self._lock:\n            in_local = chain.has_path(path, only_local=True)\n            in_defaults = chain.has_path(path, only_defaults=True)\n\n            if not force and in_defaults and in_local and default_value == value:\n                try:\n                    chain.del_by_path(path)\n                    self._mark_dirty()\n                    self._path_modified(path, current, value)\n                except KeyError:\n                    if error_on_path:\n                        raise NoSuchSettingsPath()\n                    pass\n            elif (\n                force\n                or (not in_local and in_defaults and default_value != value)\n                or (in_local and current != value)\n            ):\n                chain.set_by_path(path, value)\n                self._mark_dirty()\n                self._path_modified(path, current, value)\n\n        # we've changed the interface to no longer mutate the passed in config, so we\n        # must manually do that here\n        if config is not None:\n            config.clear()\n            config.update(chain.top_map)\n\n    def setInt(self, path, value, **kwargs):\n        if value is None:\n            self.set(path, None, **kwargs)\n            return\n\n        minimum = kwargs.pop(\"min\", None)\n        maximum = kwargs.pop(\"max\", None)\n\n        try:\n            intValue = int(value)\n\n            if minimum is not None and intValue < minimum:\n                intValue = minimum\n            if maximum is not None and intValue > maximum:\n                intValue = maximum\n        except ValueError:\n            self._logger.warning(\n                \"Could not convert %r to a valid integer when setting option %r\"\n                % (value, path)\n            )\n            return\n\n        self.set(path, intValue, **kwargs)\n\n    def setFloat(self, path, value, **kwargs):\n        if value is None:\n            self.set(path, None, **kwargs)\n            return\n\n        minimum = kwargs.pop(\"min\", None)\n        maximum = kwargs.pop(\"max\", None)\n\n        try:\n            floatValue = float(value)\n\n            if minimum is not None and floatValue < minimum:\n                floatValue = minimum\n            if maximum is not None and floatValue > maximum:\n                floatValue = maximum\n        except ValueError:\n            self._logger.warning(\n                \"Could not convert %r to a valid integer when setting option %r\"\n                % (value, path)\n            )\n            return\n\n        self.set(path, floatValue, **kwargs)\n\n    def setBoolean(self, path, value, **kwargs):\n        if value is None or isinstance(value, bool):\n            self.set(path, value, **kwargs)\n        elif isinstance(value, str) and value.lower() in valid_boolean_trues:\n            self.set(path, True, **kwargs)\n        else:\n            self.set(path, False, **kwargs)\n\n    def setBaseFolder(self, type, path, force=False, validate=True):\n        if type not in default_settings[\"folder\"]:\n            return None\n\n        currentPath = self.getBaseFolder(type)\n        defaultPath = self._get_default_folder(type)\n        if path is None or path == defaultPath:\n            self.remove([\"folder\", type])\n        elif (path != currentPath and path != defaultPath) or force:\n            if validate:\n                _validate_folder(path, check_writable=True, deep_check_writable=True)\n            self.set([\"folder\", type], path, force=force)\n\n    def saveScript(self, script_type, name, script):\n        script_folder = self.getBaseFolder(\"scripts\")\n        filename = os.path.realpath(os.path.join(script_folder, script_type, name))\n        if not filename.startswith(os.path.realpath(script_folder)):\n            # oops, jail break, that shouldn't happen\n            raise ValueError(\n                f\"Invalid script path to save to: {filename} (from {script_type}:{name})\"\n            )\n\n        path, _ = os.path.split(filename)\n        if not os.path.exists(path):\n            os.makedirs(path)\n        with atomic_write(filename, mode=\"wt\", max_permissions=0o666) as f:\n            f.write(script)\n\n    def generateApiKey(self):\n        apikey = generate_api_key()\n        self.set([\"api\", \"key\"], apikey)\n        self.save(force=True)\n        return apikey\n\n    def deleteApiKey(self):\n        self.set([\"api\", \"key\"], None)\n        self.save(force=True)\n\n\ndef _default_basedir(applicationName):\n    # taken from http://stackoverflow.com/questions/1084697/how-do-i-store-desktop-application-data-in-a-cross-platform-way-for-python\n    if sys.platform == \"darwin\":\n        import appdirs\n\n        return appdirs.user_data_dir(applicationName, \"\")\n    elif sys.platform == \"win32\":\n        return os.path.join(os.environ[\"APPDATA\"], applicationName)\n    else:\n        return os.path.expanduser(os.path.join(\"~\", \".\" + applicationName.lower()))\n\n\ndef _validate_folder(folder, create=True, check_writable=True, deep_check_writable=False):\n    logger = logging.getLogger(__name__)\n\n    if not os.path.exists(folder):\n        if os.path.islink(folder):\n            # broken symlink, see #2644\n            raise OSError(f\"Folder at {folder} appears to be a broken symlink\")\n\n        elif create:\n            # non existing, but we are allowed to create it\n            try:\n                os.makedirs(folder)\n            except Exception:\n                logger.exception(f\"Could not create {folder}\")\n                raise OSError(\n                    \"Folder for type {} at {} does not exist and creation failed\".format(\n                        type, folder\n                    )\n                )\n\n        else:\n            # not extisting, not allowed to create it\n            raise OSError(f\"No such folder: {folder}\")\n\n    elif os.path.isfile(folder):\n        # hardening against misconfiguration, see #1953\n        raise OSError(f\"Expected a folder at {folder} but found a file instead\")\n\n    elif check_writable:\n        # make sure we can also write into the folder\n        error = \"Folder at {} doesn't appear to be writable, please fix its permissions\".format(\n            folder\n        )\n        if not os.access(folder, os.W_OK):\n            raise OSError(error)\n\n        elif deep_check_writable:\n            # try to write a file to the folder - on network shares that might be the only reliable way\n            # to determine whether things are *actually* writable\n            testfile = os.path.join(folder, \".testballoon.txt\")\n            try:\n                with open(testfile, \"w\", encoding=\"utf-8\") as f:\n                    f.write(\"test\")\n                os.remove(testfile)\n            except Exception:\n                logger.exception(f\"Could not write test file to {testfile}\")\n                raise OSError(error)\n\n\ndef _paths(prefix, data):\n    if isinstance(data, dict):\n        for k, v in data.items():\n            yield from _paths(prefix + [k], v)\n    else:\n        yield prefix\n"], "fixing_code": ["\"\"\"\nThis module represents OctoPrint's settings management. Within this module the default settings for the core\napplication are defined and the instance of the :class:`Settings` is held, which offers getter and setter\nmethods for the raw configuration values as well as various convenience methods to access the paths to base folders\nof various types and the configuration file itself.\n\n.. autodata:: default_settings\n   :annotation: = dict(...)\n\n.. autodata:: valid_boolean_trues\n\n.. autofunction:: settings\n\n.. autoclass:: Settings\n   :members:\n   :undoc-members:\n\"\"\"\n\n__author__ = \"Gina H\u00e4u\u00dfge <osd@foosel.net>\"\n__license__ = \"GNU Affero General Public License http://www.gnu.org/licenses/agpl.html\"\n__copyright__ = \"Copyright (C) 2014 The OctoPrint Project - Released under terms of the AGPLv3 License\"\n\nimport fnmatch\nimport logging\nimport os\nimport re\nimport sys\nimport threading\nimport time\nfrom collections import ChainMap, defaultdict\nfrom collections.abc import KeysView\n\nfrom yaml import YAMLError\n\nfrom octoprint.schema.config import Config\nfrom octoprint.util import (\n    CaseInsensitiveSet,\n    atomic_write,\n    deprecated,\n    dict_merge,\n    fast_deepcopy,\n    generate_api_key,\n    is_hidden_path,\n    yaml,\n)\n\n_APPNAME = \"OctoPrint\"\n\n_instance = None\n\n\ndef settings(init=False, basedir=None, configfile=None, overlays=None):\n    \"\"\"\n    Factory method for initially constructing and consecutively retrieving the :class:`~octoprint.settings.Settings`\n    singleton.\n\n    Arguments:\n        init (boolean): A flag indicating whether this is the initial call to construct the singleton (True) or not\n            (False, default). If this is set to True and the plugin manager has already been initialized, a :class:`ValueError`\n            will be raised. The same will happen if the plugin manager has not yet been initialized and this is set to\n            False.\n        basedir (str): Path of the base directory for all of OctoPrint's settings, log files, uploads etc. If not set\n            the default will be used: ``~/.octoprint`` on Linux, ``%APPDATA%/OctoPrint`` on Windows and\n            ``~/Library/Application Support/OctoPrint`` on MacOS.\n        configfile (str): Path of the configuration file (``config.yaml``) to work on. If not set the default will\n            be used: ``<basedir>/config.yaml`` for ``basedir`` as defined above.\n        overlays (list): List of paths to config overlays to put between default settings and config.yaml\n\n    Returns:\n        Settings: The fully initialized :class:`Settings` instance.\n\n    Raises:\n        ValueError: ``init`` is True but settings are already initialized or vice versa.\n    \"\"\"\n    global _instance\n    if _instance is not None:\n        if init:\n            raise ValueError(\"Settings Manager already initialized\")\n\n    else:\n        if init:\n            _instance = Settings(\n                configfile=configfile, basedir=basedir, overlays=overlays\n            )\n        else:\n            raise ValueError(\"Settings not initialized yet\")\n\n    return _instance\n\n\n# TODO: This is a temporary solution to get the default settings from the pydantic model.\n_config = Config()\ndefault_settings = _config.dict(by_alias=True)\n\"\"\"The default settings of the core application.\"\"\"\n\nvalid_boolean_trues = CaseInsensitiveSet(True, \"true\", \"yes\", \"y\", \"1\", 1)\n\"\"\" Values that are considered to be equivalent to the boolean ``True`` value, used for type conversion in various places.\"\"\"\n\n\nclass NoSuchSettingsPath(Exception):\n    pass\n\n\nclass InvalidSettings(Exception):\n    pass\n\n\nclass InvalidYaml(InvalidSettings):\n    def __init__(self, file, line=None, column=None, details=None):\n        self.file = file\n        self.line = line\n        self.column = column\n        self.details = details\n\n    def __str__(self):\n        message = (\n            \"Error parsing the configuration file {}, \"\n            \"it is invalid YAML.\".format(self.file)\n        )\n        if self.line and self.column:\n            message += \" The parser reported an error on line {}, column {}.\".format(\n                self.line, self.column\n            )\n        return message\n\n\nclass DuplicateFolderPaths(InvalidSettings):\n    def __init__(self, folders):\n        self.folders = folders\n\n        self.duplicates = {}\n        for folder, path in folders.items():\n            duplicates = []\n            for other_folder, other_path in folders.items():\n                if other_folder == folder:\n                    continue\n                if other_path == path:\n                    duplicates.append(other_folder)\n            if len(duplicates):\n                self.duplicates[folder] = duplicates\n\n    def __str__(self):\n        duplicates = [\n            \"{} (duplicates: {})\".format(folder, \", \".join(dupes))\n            for folder, dupes in self.duplicates.items()\n        ]\n        return \"There are duplicate folder paths configured: {}\".format(\n            \", \".join(duplicates)\n        )\n\n\n_CHAINMAP_SEP = \"\\x1f\"\n\n\nclass HierarchicalChainMap:\n    \"\"\"\n    Stores a bunch of nested dictionaries in chain map, allowing queries of nested values\n    work on lower directories. For example:\n\n    Example:\n        >>> example_dict = {\"a\": \"a\", \"b\": {\"c\": \"c\"}}\n        >>> hcm = HierarchicalChainMap({\"b\": {\"d\": \"d\"}}, example_dict)\n        >>> cm = ChainMap({\"b\": {\"d\": \"d\"}}, example_dict)\n        >>> cm[\"b\"][\"d\"]\n        'd'\n        >>> cm[\"b\"][\"c\"]\n        Traceback (most recent call last):\n            ...\n        KeyError: 'c'\n        >>> hcm.get_by_path([\"b\", \"d\"])\n        'd'\n        >>> hcm.get_by_path([\"b\", \"c\"])\n        'c'\n    \"\"\"\n\n    @staticmethod\n    def _flatten(d: dict, parent_key: str = \"\") -> dict:\n        \"\"\"Flattens a hierarchical dictionary.\"\"\"\n\n        if d is None:\n            return {}\n\n        items = []\n        for k, v in d.items():\n            new_key = parent_key + _CHAINMAP_SEP + str(k) if parent_key else str(k)\n            if v and isinstance(v, dict):\n                items.extend(HierarchicalChainMap._flatten(v, new_key).items())\n            else:\n                items.append((new_key, v))\n        return dict(items)\n\n    @staticmethod\n    def _unflatten(d: dict, prefix: str = \"\") -> dict:\n        \"\"\"Unflattens a flattened dictionary.\"\"\"\n\n        if d is None:\n            return {}\n\n        result = {}\n        for key, value in d.items():\n            if not key.startswith(prefix):\n                continue\n            subkeys = key[len(prefix) :].split(_CHAINMAP_SEP)\n            current = result\n\n            path = []\n            for subkey in subkeys[:-1]:\n                # we only need that for logging in case of data weirdness below\n                path.append(subkey)\n\n                # make sure the subkey is in the current dict, and that it is a dict\n                if subkey not in current:\n                    current[subkey] = {}\n                elif not isinstance(current[subkey], dict):\n                    logging.getLogger(__name__).warning(\n                        f\"There is a non-dict value on the path to {key} at {path!r}, ignoring.\"\n                    )\n                    current[subkey] = {}\n\n                # go down a level\n                current = current[subkey]\n\n            current[subkeys[-1]] = value\n\n        return result\n\n    @staticmethod\n    def _path_to_key(path):\n        \"\"\"\n        :type path: List[str]\n        \"\"\"\n        return _CHAINMAP_SEP.join(path)\n\n    @staticmethod\n    def from_layers(*layers):\n        result = HierarchicalChainMap()\n        result._chainmap.maps = layers\n        return result\n\n    def __init__(self, *maps):\n        self._chainmap = ChainMap(*map(self._flatten, maps))\n\n    def deep_dict(self):\n        return self._unflatten(self._chainmap)\n\n    def has_path(self, path, only_local=False, only_defaults=False):\n        if only_defaults:\n            current = self._chainmap.parents\n        elif only_local:\n            current = self._chainmap.maps[0]\n        else:\n            current = self._chainmap\n\n        key = self._path_to_key(path)\n        prefix = key + _CHAINMAP_SEP\n        return key in current or any(map(lambda x: x.startswith(prefix), current.keys()))\n\n    def get_by_path(self, path, only_local=False, only_defaults=False, merged=False):\n        if only_defaults:\n            current = self._chainmap.parents\n        elif only_local:\n            current = self._chainmap.maps[0]\n        else:\n            current = self._chainmap\n\n        key = self._path_to_key(path)\n        prefix = key + _CHAINMAP_SEP\n\n        if key in current and not any(k.startswith(prefix) for k in current.keys()):\n            # found it, return\n            return current[key]\n\n        # if we arrived here we might be trying to grab a dict, look for children\n\n        # TODO 2.0.0 remove this & make 'merged' the default\n        if not merged and hasattr(current, \"maps\"):\n            # we do something a bit odd here: if merged is not true, we don't include the\n            # full contents of the key. Instead, we only include the contents of the key\n            # on the first level where we find the value.\n            for layer in current.maps:\n                if any(k.startswith(prefix) for k in layer):\n                    current = layer\n                    break\n\n        result = self._unflatten(\n            {k: v for k, v in current.items() if k.startswith(prefix)}, prefix=prefix\n        )\n        if not result:\n            raise KeyError(\"Could not find entry for \" + str(path))\n        return result\n\n    def set_by_path(self, path, value):\n        current = self._chainmap.maps[0]  # config only\n        key = self._path_to_key(path)\n\n        # delete any subkeys\n        self._del_prefix(current, key)\n\n        if isinstance(value, dict):\n            current.update(self._flatten(value, key))\n        else:\n            # make sure to clear anything below the path (e.g. switching from dict\n            # to something else, for whatever reason)\n            self._clean_upward_path(current, path)\n            current[key] = value\n\n    def del_by_path(self, path):\n        if not path:\n            raise ValueError(\"Invalid path\")\n\n        current = self._chainmap.maps[0]  # config only\n        delete_key = self._path_to_key(path)\n        deleted = False\n\n        # delete any subkeys\n        deleted = self._del_prefix(current, delete_key)\n\n        # delete the key itself if it's there\n        try:\n            del current[delete_key]\n            deleted = True\n        except KeyError:\n            pass\n\n        if not deleted:\n            raise KeyError(\"Could not find entry for \" + str(path))\n\n        # clean anything that's now empty and above our path\n        self._clean_upward_path(current, path)\n\n    def _del_prefix(self, current, key):\n        prefix = key + _CHAINMAP_SEP\n\n        to_delete = [k for k in current if k.startswith(prefix)]\n        for k in to_delete:\n            del current[k]\n\n        return len(to_delete) > 0\n\n    def _clean_upward_path(self, current, path):\n        working_path = path\n        while len(working_path):\n            working_path = working_path[:-1]\n            if not working_path:\n                break\n\n            key = self._path_to_key(working_path)\n            prefix = key + _CHAINMAP_SEP\n            if any(map(lambda k: k.startswith(prefix), current)):\n                # there's at least one subkey here, we're done\n                break\n\n            # delete the key itself if it's there\n            try:\n                del current[key]\n            except KeyError:\n                # key itself wasn't in there\n                pass\n\n    def with_config_defaults(self, config=None, defaults=None):\n        \"\"\"\n        Builds a new map with the following layers: provided config + any intermediary\n        parents + provided defaults + regular defaults\n\n        :param config:\n        :param defaults:\n        :return:\n        \"\"\"\n        if config is None and defaults is None:\n            return self\n\n        if config is not None:\n            config = self._flatten(config)\n        else:\n            config = self._chainmap.maps[0]\n\n        if defaults is not None:\n            defaults = [self._flatten(defaults)]\n        else:\n            defaults = []\n\n        layers = [config] + self._middle_layers() + defaults + [self._chainmap.maps[-1]]\n        return HierarchicalChainMap.from_layers(*layers)\n\n    @property\n    def top_map(self):\n        \"\"\"This is the layer that is written to\"\"\"\n        return self._unflatten(self._chainmap.maps[0])\n\n    @top_map.setter\n    def top_map(self, value):\n        self._chainmap.maps[0] = self._flatten(value)\n\n    @property\n    def bottom_map(self):\n        \"\"\"The very bottom layer is the default layer\"\"\"\n        return self._unflatten(self._chainmap.maps[-1])\n\n    def insert_map(self, pos, d):\n        self._chainmap.maps.insert(pos, self._flatten(d))\n\n    def delete_map(self, pos):\n        del self._chainmap.maps[pos]\n\n    @property\n    def all_layers(self):\n        \"\"\"A list of all layers in this map. read-only\"\"\"\n        return self._chainmap.maps\n\n    def _middle_layers(self):\n        if len(self._chainmap.maps) > 2:\n            return self._chainmap.maps[1:-1]\n        else:\n            return []\n\n\nclass Settings:\n    \"\"\"\n    The :class:`Settings` class allows managing all of OctoPrint's settings. It takes care of initializing the settings\n    directory, loading the configuration from ``config.yaml``, persisting changes to disk etc and provides access\n    methods for getting and setting specific values from the overall settings structure via paths.\n\n    A general word on the concept of paths, since they play an important role in OctoPrint's settings management. A\n    path is basically a list or tuple consisting of keys to follow down into the settings (which are basically like\n    a ``dict``) in order to set or retrieve a specific value (or more than one). For example, for a settings\n    structure like the following::\n\n        serial:\n            port: \"/dev/ttyACM0\"\n            baudrate: 250000\n            timeout:\n                communication: 20.0\n                temperature: 5.0\n                sdStatus: 1.0\n                connection: 10.0\n        server:\n            host: \"0.0.0.0\"\n            port: 5000\n\n    the following paths could be used:\n\n    ========================================== ============================================================================\n    Path                                       Value\n    ========================================== ============================================================================\n    ``[\"serial\", \"port\"]``                     ::\n\n                                                   \"/dev/ttyACM0\"\n\n    ``[\"serial\", \"timeout\"]``                  ::\n\n                                                   communication: 20.0\n                                                   temperature: 5.0\n                                                   sdStatus: 1.0\n                                                   connection: 10.0\n\n    ``[\"serial\", \"timeout\", \"temperature\"]``   ::\n\n                                                   5.0\n\n    ``[\"server\", \"port\"]``                     ::\n\n                                                   5000\n\n    ========================================== ============================================================================\n\n    However, these would be invalid paths: ``[\"key\"]``, ``[\"serial\", \"port\", \"value\"]``, ``[\"server\", \"host\", 3]``.\n    \"\"\"\n\n    OVERLAY_KEY = \"__overlay__\"\n\n    def __init__(self, configfile=None, basedir=None, overlays=None):\n        self._logger = logging.getLogger(__name__)\n\n        self._basedir = None\n\n        if overlays is None:\n            overlays = []\n\n        assert isinstance(default_settings, dict)\n\n        self._map = HierarchicalChainMap({}, default_settings)\n        self.load_overlays(overlays)\n\n        self._dirty = False\n        self._dirty_time = 0\n        self._last_config_hash = None\n        self._last_effective_hash = None\n        self._mtime = None\n\n        self._lock = threading.RLock()\n\n        self._get_preprocessors = {\"controls\": self._process_custom_controls}\n        self._set_preprocessors = {}\n        self._path_update_callbacks = defaultdict(list)\n        self._deprecated_paths = defaultdict(dict)\n\n        self._init_basedir(basedir)\n\n        if configfile is not None:\n            self._configfile = configfile\n        else:\n            self._configfile = os.path.join(self._basedir, \"config.yaml\")\n        self.load(migrate=True)\n\n        apikey = self.get([\"api\", \"key\"])\n        if not apikey or apikey == \"n/a\":\n            self.generateApiKey()\n\n        self._script_env = self._init_script_templating()\n\n        self.sanity_check_folders(\n            folders=[\n                \"logs\",\n            ]\n        )\n        self.warn_about_risky_settings()\n\n    def _init_basedir(self, basedir):\n        if basedir is not None:\n            self._basedir = basedir\n        else:\n            self._basedir = _default_basedir(_APPNAME)\n\n        if not os.path.isdir(self._basedir):\n            try:\n                os.makedirs(self._basedir)\n            except Exception:\n                self._logger.fatal(\n                    \"Could not create basefolder at {}. This is a fatal error, OctoPrint \"\n                    \"can't run without a writable base folder.\".format(self._basedir),\n                    exc_info=1,\n                )\n                raise\n\n    def sanity_check_folders(self, folders=None):\n        if folders is None:\n            folders = default_settings[\"folder\"].keys()\n\n        folder_map = {}\n        for folder in folders:\n            folder_map[folder] = self.getBaseFolder(\n                folder, check_writable=True, deep_check_writable=True\n            )\n\n        # validate uniqueness of folder paths\n        if len(folder_map.values()) != len(set(folder_map.values())):\n            raise DuplicateFolderPaths(folders)\n\n    def warn_about_risky_settings(self):\n        if not self.getBoolean([\"devel\", \"enableRateLimiter\"]):\n            self._logger.warning(\n                \"Rate limiting is disabled, this is a security risk. Do not run this in production.\"\n            )\n        if not self.getBoolean([\"devel\", \"enableCsrfProtection\"]):\n            self._logger.warning(\n                \"CSRF Protection is disabled, this is a security risk. Do not run this in production.\"\n            )\n\n    def _is_deprecated_path(self, path):\n        if path and isinstance(path[-1], (list, tuple)):\n            prefix = path[:-1]\n            return any(\n                map(lambda x: bool(self._deprecated_paths[tuple(prefix + [x])]), path[-1])\n            )\n\n        if (\n            tuple(path) not in self._deprecated_paths\n            or not self._deprecated_paths[tuple(path)]\n        ):\n            return False\n\n        try:\n            return list(self._deprecated_paths[tuple(path)].values())[-1]\n        except StopIteration:\n            return False\n\n    def _path_modified(self, path, current_value, new_value):\n        callbacks = self._path_update_callbacks.get(tuple(path))\n        if callbacks:\n            for callback in callbacks:\n                try:\n                    if callable(callback):\n                        callback(path, current_value, new_value)\n                except Exception:\n                    self._logger.exception(\n                        f\"Error while executing callback {callback} for path {path}\"\n                    )\n\n    def _get_default_folder(self, type):\n        folder = default_settings[\"folder\"][type]\n        if folder is None:\n            folder = os.path.join(self._basedir, type.replace(\"_\", os.path.sep))\n        return folder\n\n    def _init_script_templating(self):\n        from jinja2 import BaseLoader, ChoiceLoader, TemplateNotFound\n        from jinja2.ext import Extension\n        from jinja2.nodes import Include\n        from jinja2.sandbox import SandboxedEnvironment\n\n        from octoprint.util.jinja import FilteredFileSystemLoader\n\n        class SnippetExtension(Extension):\n            tags = {\"snippet\"}\n            fields = Include.fields\n\n            def parse(self, parser):\n                node = parser.parse_include()\n                if not node.template.value.startswith(\"/\"):\n                    node.template.value = \"snippets/\" + node.template.value\n                return node\n\n        class SettingsScriptLoader(BaseLoader):\n            def __init__(self, s):\n                self._settings = s\n\n            def get_source(self, environment, template):\n                parts = template.split(\"/\")\n                if not len(parts):\n                    raise TemplateNotFound(template)\n\n                script = self._settings.get([\"scripts\"], merged=True)\n                for part in parts:\n                    if isinstance(script, dict) and part in script:\n                        script = script[part]\n                    else:\n                        raise TemplateNotFound(template)\n                source = script\n                if source is None:\n                    raise TemplateNotFound(template)\n                mtime = self._settings._mtime\n                return source, None, lambda: mtime == self._settings.last_modified\n\n            def list_templates(self):\n                scripts = self._settings.get([\"scripts\"], merged=True)\n                return self._get_templates(scripts)\n\n            def _get_templates(self, scripts):\n                templates = []\n                for key in scripts:\n                    if isinstance(scripts[key], dict):\n                        templates += list(\n                            map(\n                                lambda x: key + \"/\" + x, self._get_templates(scripts[key])\n                            )\n                        )\n                    elif isinstance(scripts[key], str):\n                        templates.append(key)\n                return templates\n\n        class SelectLoader(BaseLoader):\n            def __init__(self, default, mapping, sep=\":\"):\n                self._default = default\n                self._mapping = mapping\n                self._sep = sep\n\n            def get_source(self, environment, template):\n                if self._sep in template:\n                    prefix, name = template.split(self._sep, 1)\n                    if prefix not in self._mapping:\n                        raise TemplateNotFound(template)\n                    return self._mapping[prefix].get_source(environment, name)\n                return self._default.get_source(environment, template)\n\n            def list_templates(self):\n                return self._default.list_templates()\n\n        class RelEnvironment(SandboxedEnvironment):\n            def __init__(self, prefix_sep=\":\", *args, **kwargs):\n                super().__init__(*args, **kwargs)\n                self._prefix_sep = prefix_sep\n\n            def join_path(self, template, parent):\n                prefix, name = self._split_prefix(template)\n\n                if name.startswith(\"/\"):\n                    return self._join_prefix(prefix, name[1:])\n                else:\n                    _, parent_name = self._split_prefix(parent)\n                    parent_base = parent_name.split(\"/\")[:-1]\n                    return self._join_prefix(prefix, \"/\".join(parent_base) + \"/\" + name)\n\n            def _split_prefix(self, template):\n                if self._prefix_sep in template:\n                    return template.split(self._prefix_sep, 1)\n                else:\n                    return \"\", template\n\n            def _join_prefix(self, prefix, template):\n                if len(prefix):\n                    return prefix + self._prefix_sep + template\n                else:\n                    return template\n\n        path_filter = lambda path: not is_hidden_path(path)\n        file_system_loader = FilteredFileSystemLoader(\n            self.getBaseFolder(\"scripts\"), path_filter=path_filter\n        )\n        settings_loader = SettingsScriptLoader(self)\n        choice_loader = ChoiceLoader([file_system_loader, settings_loader])\n        select_loader = SelectLoader(\n            choice_loader, {\"bundled\": settings_loader, \"file\": file_system_loader}\n        )\n        return RelEnvironment(loader=select_loader, extensions=[SnippetExtension])\n\n    def _get_script_template(self, script_type, name, source=False):\n        from jinja2 import TemplateNotFound\n\n        template_name = script_type + \"/\" + name\n        try:\n            if source:\n                template_name, _, _ = self._script_env.loader.get_source(\n                    self._script_env, template_name\n                )\n                return template_name\n            else:\n                return self._script_env.get_template(template_name)\n        except TemplateNotFound:\n            return None\n        except Exception:\n            self._logger.exception(\n                f\"Exception while trying to resolve template {template_name}\"\n            )\n            return None\n\n    def _get_scripts(self, script_type):\n        return self._script_env.list_templates(\n            filter_func=lambda x: x.startswith(script_type + \"/\")\n        )\n\n    def _process_custom_controls(self, controls):\n        def process_control(c):\n            # shallow copy\n            result = dict(c)\n\n            if \"regex\" in result and \"template\" in result:\n                # if it's a template matcher, we need to add a key to associate with the matcher output\n                import hashlib\n\n                key_hash = hashlib.md5()\n                key_hash.update(result[\"regex\"].encode(\"utf-8\"))\n                result[\"key\"] = key_hash.hexdigest()\n\n                template_key_hash = hashlib.md5()\n                template_key_hash.update(result[\"template\"].encode(\"utf-8\"))\n                result[\"template_key\"] = template_key_hash.hexdigest()\n\n            elif \"children\" in result:\n                # if it has children we need to process them recursively\n                result[\"children\"] = list(\n                    map(\n                        process_control,\n                        [child for child in result[\"children\"] if child is not None],\n                    )\n                )\n\n            return result\n\n        return list(map(process_control, controls))\n\n    def _forget_hashes(self):\n        self._last_config_hash = None\n        self._last_effective_hash = None\n\n    def _mark_dirty(self):\n        with self._lock:\n            self._dirty = True\n            self._dirty_time = time.time()\n            self._forget_hashes()\n\n    @property\n    def effective(self):\n        return self._map.deep_dict()\n\n    @property\n    def effective_yaml(self):\n        return yaml.dump(self.effective)\n\n    @property\n    def effective_hash(self):\n        if self._last_effective_hash is not None:\n            return self._last_effective_hash\n\n        import hashlib\n\n        hash = hashlib.md5()\n        hash.update(self.effective_yaml.encode(\"utf-8\"))\n        self._last_effective_hash = hash.hexdigest()\n        return self._last_effective_hash\n\n    @property\n    def config_yaml(self):\n        return yaml.dump(self.config)\n\n    @property\n    def config_hash(self):\n        if self._last_config_hash:\n            return self._last_config_hash\n\n        import hashlib\n\n        hash = hashlib.md5()\n        hash.update(self.config_yaml.encode(\"utf-8\"))\n        self._last_config_hash = hash.hexdigest()\n        return self._last_config_hash\n\n    @property\n    def config(self):\n        \"\"\"\n        A view of the local config as stored in config.yaml\n\n        Does not support modifications, they will be thrown away silently. If you need to\n        modify anything in the settings, utilize the provided set and remove methods.\n        \"\"\"\n        return self._map.top_map\n\n    @property\n    @deprecated(\n        \"Settings._config has been deprecated and is a read-only view. Please use Settings.config or the set & remove methods instead.\",\n        since=\"1.8.0\",\n    )\n    def _config(self):\n        return self.config\n\n    @_config.setter\n    @deprecated(\n        \"Setting of Settings._config has been deprecated. Please use the set & remove methods instead and get in touch if you have a usecase they don't cover.\",\n        since=\"1.8.0\",\n    )\n    def _config(self, value):\n        self._map.top_map = value\n\n    @property\n    def _overlay_layers(self):\n        if len(self._map.all_layers) > 2:\n            return self._map.all_layers[1:-1]\n        else:\n            return []\n\n    @property\n    def _default_map(self):\n        return self._map.bottom_map\n\n    @property\n    def last_modified(self):\n        \"\"\"\n        Returns:\n            (int) The last modification time of the configuration file.\n        \"\"\"\n        stat = os.stat(self._configfile)\n        return stat.st_mtime\n\n    @property\n    def last_modified_or_made_dirty(self):\n        return max(self.last_modified, self._dirty_time)\n\n    # ~~ load and save\n\n    def load(self, migrate=False):\n        config = None\n        mtime = None\n\n        if os.path.exists(self._configfile) and os.path.isfile(self._configfile):\n            with open(self._configfile, encoding=\"utf-8\", errors=\"replace\") as f:\n                try:\n                    config = yaml.load_from_file(file=f)\n                    mtime = self.last_modified\n\n                except YAMLError as e:\n                    details = str(e)\n\n                    if hasattr(e, \"problem_mark\"):\n                        line = e.problem_mark.line\n                        column = e.problem_mark.column\n                    else:\n                        line = None\n                        column = None\n\n                    raise InvalidYaml(\n                        self._configfile,\n                        details=details,\n                        line=line,\n                        column=column,\n                    )\n\n        # changed from else to handle cases where the file exists, but is empty / 0 bytes\n        if not config or not isinstance(config, dict):\n            config = {}\n\n        self._map.top_map = config\n        self._mtime = mtime\n\n        if migrate:\n            self._migrate_config()\n\n        self._forget_hashes()\n\n    def load_overlays(self, overlays, migrate=True):\n        for overlay in overlays:\n            if not os.path.exists(overlay):\n                continue\n\n            def process(path):\n                try:\n                    overlay_config = self.load_overlay(path, migrate=migrate)\n                    self.add_overlay(overlay_config)\n                    self._logger.info(f\"Added config overlay from {path}\")\n                except Exception:\n                    self._logger.exception(f\"Could not add config overlay from {path}\")\n\n            if os.path.isfile(overlay):\n                process(overlay)\n\n            elif os.path.isdir(overlay):\n                for entry in os.scandir(overlay):\n                    name = entry.name\n                    path = entry.path\n\n                    if is_hidden_path(path) or not fnmatch.fnmatch(name, \"*.yaml\"):\n                        continue\n\n                    process(path)\n\n    def load_overlay(self, overlay, migrate=True):\n        config = None\n\n        if callable(overlay):\n            try:\n                overlay = overlay(self)\n            except Exception:\n                self._logger.exception(\"Error loading overlay from callable\")\n                return\n\n        if isinstance(overlay, str):\n            if os.path.exists(overlay) and os.path.isfile(overlay):\n                config = yaml.load_from_file(path=overlay)\n        elif isinstance(overlay, dict):\n            config = overlay\n        else:\n            raise ValueError(\n                \"Overlay must be either a path to a yaml file or a dictionary\"\n            )\n\n        if not isinstance(config, dict):\n            raise ValueError(\n                f\"Configuration data must be a dict but is a {config.__class__}\"\n            )\n\n        if migrate:\n            self._migrate_config(config)\n        return config\n\n    def add_overlay(\n        self, overlay, at_end=False, key=None, deprecated=None, replace=False\n    ):\n        assert isinstance(overlay, dict)\n\n        if key is None:\n            overlay_yaml = yaml.dump(overlay)\n            import hashlib\n\n            hash = hashlib.md5()\n            hash.update(overlay_yaml.encode(\"utf-8\"))\n            key = hash.hexdigest()\n\n        if replace:\n            self.remove_overlay(key)\n\n        if deprecated is not None:\n            self._logger.debug(\n                f\"Marking all (recursive) paths in this overlay as deprecated: {overlay}\"\n            )\n            for path in _paths([], overlay):\n                self._deprecated_paths[tuple(path)][key] = deprecated\n\n        overlay[self.OVERLAY_KEY] = key\n        if at_end:\n            self._map.insert_map(-1, overlay)\n        else:\n            self._map.insert_map(1, overlay)\n\n        return key\n\n    def remove_overlay(self, key):\n        index = -1\n        for i, overlay in enumerate(self._overlay_layers):\n            if key == overlay.get(self.OVERLAY_KEY):\n                index = i\n                overlay = self._map._unflatten(overlay)\n                break\n\n        if index > -1:\n            self._map.delete_map(index + 1)\n\n            self._logger.debug(\n                f\"Removing all deprecation marks for (recursive) paths in this overlay: {overlay}\"\n            )\n            for path in _paths([], overlay):\n                try:\n                    del self._deprecated_paths[tuple(path)][key]\n                except KeyError:\n                    # key not in dict\n                    pass\n\n            return True\n        return False\n\n    def add_path_update_callback(self, path, callback):\n        callbacks = self._path_update_callbacks[tuple(path)]\n        if callback not in callbacks:\n            callbacks.append(callback)\n\n    def remove_path_update_callback(self, path, callback):\n        try:\n            self._path_update_callbacks[tuple(path)].remove(callback)\n        except ValueError:\n            # callback not in list\n            pass\n\n    def _migrate_config(self, config=None, persist=False):\n        if config is None:\n            config = self._map.top_map\n            persist = True\n\n        dirty = False\n\n        migrators = (\n            self._migrate_event_config,\n            self._migrate_reverse_proxy_config,\n            self._migrate_printer_parameters,\n            self._migrate_gcode_scripts,\n            self._migrate_core_system_commands,\n            self._migrate_serial_features,\n            self._migrate_resend_without_ok,\n            self._migrate_string_temperature_profile_values,\n            self._migrate_blocked_commands,\n            self._migrate_gcodeviewer_enabled,\n        )\n\n        for migrate in migrators:\n            dirty = migrate(config) or dirty\n\n        if dirty and persist:\n            self._map.top_map = (\n                config  # we need to write it back here or the changes will be lost\n            )\n            self.save(force=True)\n\n    def _migrate_gcode_scripts(self, config):\n        \"\"\"\n        Migrates an old development version of gcode scripts to the new template based format.\n\n        Added in 1.2.0\n        \"\"\"\n\n        dirty = False\n        if \"scripts\" in config:\n            if \"gcode\" in config[\"scripts\"]:\n                if \"templates\" in config[\"scripts\"][\"gcode\"]:\n                    del config[\"scripts\"][\"gcode\"][\"templates\"]\n\n                replacements = {\n                    \"disable_steppers\": \"M84\",\n                    \"disable_hotends\": \"{% snippet 'disable_hotends' %}\",\n                    \"disable_bed\": \"M140 S0\",\n                    \"disable_fan\": \"M106 S0\",\n                }\n\n                for name, script in config[\"scripts\"][\"gcode\"].items():\n                    self.saveScript(\"gcode\", name, script.format(**replacements))\n            del config[\"scripts\"]\n            dirty = True\n        return dirty\n\n    def _migrate_printer_parameters(self, config):\n        \"\"\"\n        Migrates the old \"printer > parameters\" data structure to the new printer profile mechanism.\n\n        Added in 1.2.0\n        \"\"\"\n        default_profile = (\n            config[\"printerProfiles\"][\"defaultProfile\"]\n            if \"printerProfiles\" in config\n            and \"defaultProfile\" in config[\"printerProfiles\"]\n            else {}\n        )\n        dirty = False\n\n        if \"printerParameters\" in config:\n            printer_parameters = config[\"printerParameters\"]\n\n            if (\n                \"movementSpeed\" in printer_parameters\n                or \"invertAxes\" in printer_parameters\n            ):\n                dirty = True\n                default_profile[\"axes\"] = {\"x\": {}, \"y\": {}, \"z\": {}, \"e\": {}}\n                if \"movementSpeed\" in printer_parameters:\n                    for axis in (\"x\", \"y\", \"z\", \"e\"):\n                        if axis in printer_parameters[\"movementSpeed\"]:\n                            default_profile[\"axes\"][axis][\"speed\"] = printer_parameters[\n                                \"movementSpeed\"\n                            ][axis]\n                    del config[\"printerParameters\"][\"movementSpeed\"]\n                if \"invertedAxes\" in printer_parameters:\n                    for axis in (\"x\", \"y\", \"z\", \"e\"):\n                        if axis in printer_parameters[\"invertedAxes\"]:\n                            default_profile[\"axes\"][axis][\"inverted\"] = True\n                    del config[\"printerParameters\"][\"invertedAxes\"]\n\n            if (\n                \"numExtruders\" in printer_parameters\n                or \"extruderOffsets\" in printer_parameters\n            ):\n                dirty = True\n                if \"extruder\" not in default_profile:\n                    default_profile[\"extruder\"] = {}\n\n                if \"numExtruders\" in printer_parameters:\n                    default_profile[\"extruder\"][\"count\"] = printer_parameters[\n                        \"numExtruders\"\n                    ]\n                    del config[\"printerParameters\"][\"numExtruders\"]\n                if \"extruderOffsets\" in printer_parameters:\n                    extruder_offsets = []\n                    for offset in printer_parameters[\"extruderOffsets\"]:\n                        if \"x\" in offset and \"y\" in offset:\n                            extruder_offsets.append((offset[\"x\"], offset[\"y\"]))\n                    default_profile[\"extruder\"][\"offsets\"] = extruder_offsets\n                    del config[\"printerParameters\"][\"extruderOffsets\"]\n\n            if \"bedDimensions\" in printer_parameters:\n                dirty = True\n                bed_dimensions = printer_parameters[\"bedDimensions\"]\n                if \"volume\" not in default_profile:\n                    default_profile[\"volume\"] = {}\n\n                if (\n                    \"circular\" in bed_dimensions\n                    and \"r\" in bed_dimensions\n                    and bed_dimensions[\"circular\"]\n                ):\n                    default_profile[\"volume\"][\"formFactor\"] = \"circular\"\n                    default_profile[\"volume\"][\"width\"] = 2 * bed_dimensions[\"r\"]\n                    default_profile[\"volume\"][\"depth\"] = default_profile[\"volume\"][\n                        \"width\"\n                    ]\n                elif \"x\" in bed_dimensions or \"y\" in bed_dimensions:\n                    default_profile[\"volume\"][\"formFactor\"] = \"rectangular\"\n                    if \"x\" in bed_dimensions:\n                        default_profile[\"volume\"][\"width\"] = bed_dimensions[\"x\"]\n                    if \"y\" in bed_dimensions:\n                        default_profile[\"volume\"][\"depth\"] = bed_dimensions[\"y\"]\n                del config[\"printerParameters\"][\"bedDimensions\"]\n\n        if dirty:\n            if \"printerProfiles\" not in config:\n                config[\"printerProfiles\"] = {}\n            config[\"printerProfiles\"][\"defaultProfile\"] = default_profile\n        return dirty\n\n    def _migrate_reverse_proxy_config(self, config):\n        \"\"\"\n        Migrates the old \"server > baseUrl\" and \"server > scheme\" configuration entries to\n        \"server > reverseProxy > prefixFallback\" and \"server > reverseProxy > schemeFallback\".\n\n        Added in 1.2.0\n        \"\"\"\n        if \"server\" in config and (\n            \"baseUrl\" in config[\"server\"] or \"scheme\" in config[\"server\"]\n        ):\n            prefix = \"\"\n            if \"baseUrl\" in config[\"server\"]:\n                prefix = config[\"server\"][\"baseUrl\"]\n                del config[\"server\"][\"baseUrl\"]\n\n            scheme = \"\"\n            if \"scheme\" in config[\"server\"]:\n                scheme = config[\"server\"][\"scheme\"]\n                del config[\"server\"][\"scheme\"]\n\n            if \"reverseProxy\" not in config[\"server\"] or not isinstance(\n                config[\"server\"][\"reverseProxy\"], dict\n            ):\n                config[\"server\"][\"reverseProxy\"] = {}\n            if prefix:\n                config[\"server\"][\"reverseProxy\"][\"prefixFallback\"] = prefix\n            if scheme:\n                config[\"server\"][\"reverseProxy\"][\"schemeFallback\"] = scheme\n            self._logger.info(\"Migrated reverse proxy configuration to new structure\")\n            return True\n        else:\n            return False\n\n    def _migrate_event_config(self, config):\n        \"\"\"\n        Migrates the old event configuration format of type \"events > gcodeCommandTrigger\" and\n        \"event > systemCommandTrigger\" to the new events format.\n\n        Added in 1.2.0\n        \"\"\"\n        if \"events\" in config and (\n            \"gcodeCommandTrigger\" in config[\"events\"]\n            or \"systemCommandTrigger\" in config[\"events\"]\n        ):\n            self._logger.info(\"Migrating config (event subscriptions)...\")\n\n            # migrate event hooks to new format\n            placeholderRe = re.compile(r\"%\\((.*?)\\)s\")\n\n            eventNameReplacements = {\n                \"ClientOpen\": \"ClientOpened\",\n                \"TransferStart\": \"TransferStarted\",\n            }\n            payloadDataReplacements = {\n                \"Upload\": {\"data\": \"{file}\", \"filename\": \"{file}\"},\n                \"Connected\": {\"data\": \"{port} at {baudrate} baud\"},\n                \"FileSelected\": {\"data\": \"{file}\", \"filename\": \"{file}\"},\n                \"TransferStarted\": {\"data\": \"{remote}\", \"filename\": \"{remote}\"},\n                \"TransferDone\": {\"data\": \"{remote}\", \"filename\": \"{remote}\"},\n                \"ZChange\": {\"data\": \"{new}\"},\n                \"CaptureStart\": {\"data\": \"{file}\"},\n                \"CaptureDone\": {\"data\": \"{file}\"},\n                \"MovieDone\": {\"data\": \"{movie}\", \"filename\": \"{gcode}\"},\n                \"Error\": {\"data\": \"{error}\"},\n                \"PrintStarted\": {\"data\": \"{file}\", \"filename\": \"{file}\"},\n                \"PrintDone\": {\"data\": \"{file}\", \"filename\": \"{file}\"},\n            }\n\n            def migrateEventHook(event, command):\n                # migrate placeholders\n                command = placeholderRe.sub(\"{__\\\\1}\", command)\n\n                # migrate event names\n                if event in eventNameReplacements:\n                    event = eventNameReplacements[\"event\"]\n\n                # migrate payloads to more specific placeholders\n                if event in payloadDataReplacements:\n                    for key in payloadDataReplacements[event]:\n                        command = command.replace(\n                            \"{__%s}\" % key, payloadDataReplacements[event][key]\n                        )\n\n                # return processed tuple\n                return event, command\n\n            disableSystemCommands = False\n            if (\n                \"systemCommandTrigger\" in config[\"events\"]\n                and \"enabled\" in config[\"events\"][\"systemCommandTrigger\"]\n            ):\n                disableSystemCommands = not config[\"events\"][\"systemCommandTrigger\"][\n                    \"enabled\"\n                ]\n\n            disableGcodeCommands = False\n            if (\n                \"gcodeCommandTrigger\" in config[\"events\"]\n                and \"enabled\" in config[\"events\"][\"gcodeCommandTrigger\"]\n            ):\n                disableGcodeCommands = not config[\"events\"][\"gcodeCommandTrigger\"][\n                    \"enabled\"\n                ]\n\n            disableAllCommands = disableSystemCommands and disableGcodeCommands\n            newEvents = {\"enabled\": not disableAllCommands, \"subscriptions\": []}\n\n            if (\n                \"systemCommandTrigger\" in config[\"events\"]\n                and \"subscriptions\" in config[\"events\"][\"systemCommandTrigger\"]\n            ):\n                for trigger in config[\"events\"][\"systemCommandTrigger\"][\"subscriptions\"]:\n                    if not (\"event\" in trigger and \"command\" in trigger):\n                        continue\n\n                    newTrigger = {\"type\": \"system\"}\n                    if disableSystemCommands and not disableAllCommands:\n                        newTrigger[\"enabled\"] = False\n\n                    newTrigger[\"event\"], newTrigger[\"command\"] = migrateEventHook(\n                        trigger[\"event\"], trigger[\"command\"]\n                    )\n                    newEvents[\"subscriptions\"].append(newTrigger)\n\n            if (\n                \"gcodeCommandTrigger\" in config[\"events\"]\n                and \"subscriptions\" in config[\"events\"][\"gcodeCommandTrigger\"]\n            ):\n                for trigger in config[\"events\"][\"gcodeCommandTrigger\"][\"subscriptions\"]:\n                    if not (\"event\" in trigger and \"command\" in trigger):\n                        continue\n\n                    newTrigger = {\"type\": \"gcode\"}\n                    if disableGcodeCommands and not disableAllCommands:\n                        newTrigger[\"enabled\"] = False\n\n                    newTrigger[\"event\"], newTrigger[\"command\"] = migrateEventHook(\n                        trigger[\"event\"], trigger[\"command\"]\n                    )\n                    newTrigger[\"command\"] = newTrigger[\"command\"].split(\",\")\n                    newEvents[\"subscriptions\"].append(newTrigger)\n\n            config[\"events\"] = newEvents\n            self._logger.info(\n                \"Migrated %d event subscriptions to new format and structure\"\n                % len(newEvents[\"subscriptions\"])\n            )\n            return True\n        else:\n            return False\n\n    def _migrate_core_system_commands(self, config):\n        \"\"\"\n        Migrates system commands for restart, reboot and shutdown as defined on OctoPi or\n        according to the official setup guide to new core system commands to remove\n        duplication.\n\n        If server commands for action is not yet set, migrates command. Otherwise only\n        deletes definition from custom system commands.\n\n        Added in 1.3.0\n        \"\"\"\n        changed = False\n\n        migration_map = {\n            \"shutdown\": \"systemShutdownCommand\",\n            \"reboot\": \"systemRestartCommand\",\n            \"restart\": \"serverRestartCommand\",\n        }\n\n        if (\n            \"system\" in config\n            and \"actions\" in config[\"system\"]\n            and isinstance(config[\"system\"][\"actions\"], (list, tuple))\n        ):\n            actions = config[\"system\"][\"actions\"]\n            to_delete = []\n            for index, spec in enumerate(actions):\n                action = spec.get(\"action\")\n                command = spec.get(\"command\")\n                if action is None or command is None:\n                    continue\n\n                migrate_to = migration_map.get(action)\n                if migrate_to is not None:\n                    if (\n                        \"server\" not in config\n                        or \"commands\" not in config[\"server\"]\n                        or migrate_to not in config[\"server\"][\"commands\"]\n                    ):\n                        if \"server\" not in config:\n                            config[\"server\"] = {}\n                        if \"commands\" not in config[\"server\"]:\n                            config[\"server\"][\"commands\"] = {}\n                        config[\"server\"][\"commands\"][migrate_to] = command\n                        self._logger.info(\n                            \"Migrated {} action to server.commands.{}\".format(\n                                action, migrate_to\n                            )\n                        )\n\n                    to_delete.append(index)\n                    self._logger.info(\n                        \"Deleting {} action from configured system commands, superseded by server.commands.{}\".format(\n                            action, migrate_to\n                        )\n                    )\n\n            for index in reversed(to_delete):\n                actions.pop(index)\n                changed = True\n\n        if changed:\n            # let's make a backup of our current config, in case someone wants to roll back to an\n            # earlier version and needs to recover the former system commands for that\n            backup_path = self.backup(\"system_command_migration\")\n            self._logger.info(\n                \"Made a copy of the current config at {} to allow recovery of manual system command configuration\".format(\n                    backup_path\n                )\n            )\n\n        return changed\n\n    def _migrate_serial_features(self, config):\n        \"\"\"\n        Migrates feature flags identified as serial specific from the feature to the serial config tree and vice versa.\n\n        If a flag already exists in the target tree, only deletes the copy in the source tree.\n\n        Added in 1.3.7\n        \"\"\"\n        changed = False\n\n        FEATURE_TO_SERIAL = (\n            \"waitForStartOnConnect\",\n            \"alwaysSendChecksum\",\n            \"neverSendChecksum\",\n            \"sendChecksumWithUnknownCommands\",\n            \"unknownCommandsNeedAck\",\n            \"sdRelativePath\",\n            \"sdAlwaysAvailable\",\n            \"swallowOkAfterResend\",\n            \"repetierTargetTemp\",\n            \"externalHeatupDetection\",\n            \"supportWait\",\n            \"ignoreIdenticalResends\",\n            \"identicalResendsCountdown\",\n            \"supportFAsCommand\",\n            \"firmwareDetection\",\n            \"blockWhileDwelling\",\n        )\n        SERIAL_TO_FEATURE = (\"autoUppercaseBlacklist\",)\n\n        def migrate_key(key, source, target):\n            if source in config and key in config[source]:\n                if config.get(target) is None:\n                    # make sure we have a serial tree\n                    config[target] = {}\n                if key not in config[target]:\n                    # only copy over if it's not there yet\n                    config[target][key] = config[source][key]\n                # delete feature flag\n                del config[source][key]\n                return True\n            return False\n\n        for key in FEATURE_TO_SERIAL:\n            changed = migrate_key(key, \"feature\", \"serial\") or changed\n\n        for key in SERIAL_TO_FEATURE:\n            changed = migrate_key(key, \"serial\", \"feature\") or changed\n\n        if changed:\n            # let's make a backup of our current config, in case someone wants to roll back to an\n            # earlier version and needs a backup of their flags\n            backup_path = self.backup(\"serial_feature_migration\")\n            self._logger.info(\n                \"Made a copy of the current config at {} to allow recovery of serial feature flags\".format(\n                    backup_path\n                )\n            )\n\n        return changed\n\n    def _migrate_resend_without_ok(self, config):\n        \"\"\"\n        Migrates supportResendsWithoutOk flag from boolean to (\"always\", \"detect\", \"never\") value range.\n\n        True gets migrated to \"always\", False to \"detect\" (which is the new default).\n\n        Added in 1.3.7\n        \"\"\"\n        if (\n            \"serial\" in config\n            and \"supportResendsWithoutOk\" in config[\"serial\"]\n            and config[\"serial\"][\"supportResendsWithoutOk\"]\n            not in (\"always\", \"detect\", \"never\")\n        ):\n            value = config[\"serial\"][\"supportResendsWithoutOk\"]\n            if value:\n                config[\"serial\"][\"supportResendsWithoutOk\"] = \"always\"\n            else:\n                config[\"serial\"][\"supportResendsWithoutOk\"] = \"detect\"\n            return True\n        return False\n\n    def _migrate_string_temperature_profile_values(self, config):\n        \"\"\"\n        Migrates/fixes temperature profile wrongly saved with strings instead of ints as temperature values.\n\n        Added in 1.3.8\n        \"\"\"\n        if \"temperature\" in config and \"profiles\" in config[\"temperature\"]:\n            profiles = config[\"temperature\"][\"profiles\"]\n            if any(\n                map(\n                    lambda x: not isinstance(x.get(\"extruder\", 0), int)\n                    or not isinstance(x.get(\"bed\", 0), int),\n                    profiles,\n                )\n            ):\n                result = []\n                for profile in profiles:\n                    try:\n                        profile[\"extruder\"] = int(profile[\"extruder\"])\n                        profile[\"bed\"] = int(profile[\"bed\"])\n                    except ValueError:\n                        pass\n                    result.append(profile)\n                config[\"temperature\"][\"profiles\"] = result\n                return True\n        return False\n\n    def _migrate_blocked_commands(self, config):\n        if \"serial\" in config and \"blockM0M1\" in config[\"serial\"]:\n            blockM0M1 = config[\"serial\"][\"blockM0M1\"]\n            blockedCommands = config[\"serial\"].get(\"blockedCommands\", [])\n            if blockM0M1:\n                blockedCommands = set(blockedCommands)\n                blockedCommands.add(\"M0\")\n                blockedCommands.add(\"M1\")\n                config[\"serial\"][\"blockedCommands\"] = sorted(blockedCommands)\n            else:\n                config[\"serial\"][\"blockedCommands\"] = sorted(\n                    v for v in blockedCommands if v not in (\"M0\", \"M1\")\n                )\n            del config[\"serial\"][\"blockM0M1\"]\n            return True\n        return False\n\n    def _migrate_gcodeviewer_enabled(self, config):\n        if (\n            \"gcodeViewer\" in config\n            and \"enabled\" in config[\"gcodeViewer\"]\n            and not config[\"gcodeViewer\"][\"enabled\"]\n        ):\n            if \"plugins\" not in config:\n                config[\"plugins\"] = {}\n            if \"_disabled\" not in config[\"plugins\"]:\n                config[\"plugins\"][\"_disabled\"] = []\n            config[\"plugins\"][\"_disabled\"].append(\"gcodeviewer\")\n            del config[\"gcodeViewer\"][\"enabled\"]\n            return True\n        return False\n\n    def backup(self, suffix=None, path=None, ext=None, hidden=False):\n        import shutil\n\n        if path is None:\n            path = os.path.dirname(self._configfile)\n\n        basename = os.path.basename(self._configfile)\n        name, default_ext = os.path.splitext(basename)\n\n        if ext is None:\n            ext = default_ext\n\n        if suffix is None and ext == default_ext:\n            raise ValueError(\"Need a suffix or a different extension\")\n\n        if suffix is None:\n            suffix = \"\"\n\n        backup = os.path.join(\n            path, \"{}{}.{}{}\".format(\".\" if hidden else \"\", name, suffix, ext)\n        )\n        shutil.copy(self._configfile, backup)\n        return backup\n\n    def save(self, force=False, trigger_event=False):\n        with self._lock:\n            if not self._dirty and not force:\n                return False\n\n            try:\n                with atomic_write(\n                    self._configfile,\n                    mode=\"wt\",\n                    prefix=\"octoprint-config-\",\n                    suffix=\".yaml\",\n                    permissions=0o600,\n                    max_permissions=0o666,\n                ) as configFile:\n                    yaml.save_to_file(self._map.top_map, file=configFile)\n                    self._dirty = False\n            except Exception:\n                self._logger.exception(\"Error while saving config.yaml!\")\n                raise\n            else:\n                from octoprint.events import Events, eventManager\n\n                self.load()\n\n                if trigger_event:\n                    payload = {\n                        \"config_hash\": self.config_hash,\n                        \"effective_hash\": self.effective_hash,\n                    }\n                    eventManager().fire(Events.SETTINGS_UPDATED, payload=payload)\n\n                return True\n\n    ##~~ Internal getter\n\n    def _get_by_path(self, path, config):\n        current = config\n        for key in path:\n            if key not in current:\n                raise NoSuchSettingsPath()\n            current = current[key]\n        return current\n\n    def _get_value(\n        self,\n        path,\n        asdict=False,\n        config=None,\n        defaults=None,\n        preprocessors=None,\n        merged=False,\n        incl_defaults=True,\n        do_copy=True,\n    ):\n        if not path:\n            raise NoSuchSettingsPath()\n\n        is_deprecated = self._is_deprecated_path(path)\n        if is_deprecated:\n            self._logger.warning(\n                f\"DeprecationWarning: Detected access to deprecated settings path {path}, returned value is derived from compatibility overlay. {is_deprecated if isinstance(is_deprecated, str) else ''}\"\n            )\n            config = {}\n\n        chain = self._map.with_config_defaults(config=config, defaults=defaults)\n\n        if preprocessors is None:\n            preprocessors = self._get_preprocessors\n\n        preprocessor = None\n        try:\n            preprocessor = self._get_by_path(path, preprocessors)\n        except NoSuchSettingsPath:\n            pass\n\n        parent_path = path[:-1]\n        last = path[-1]\n\n        if not isinstance(last, (list, tuple)):\n            keys = [last]\n        else:\n            keys = last\n\n        if asdict:\n            results = {}\n        else:\n            results = list()\n\n        for key in keys:\n            try:\n                value = chain.get_by_path(\n                    parent_path + [key], only_local=not incl_defaults, merged=merged\n                )\n            except KeyError:\n                raise NoSuchSettingsPath()\n\n            if isinstance(value, dict) and merged:\n                try:\n                    default_value = chain.get_by_path(\n                        parent_path + [key], only_defaults=True, merged=True\n                    )\n                    if default_value is not None:\n                        value = dict_merge(default_value, value)\n                except KeyError:\n                    raise NoSuchSettingsPath()\n\n            if callable(preprocessor):\n                value = preprocessor(value)\n\n            if do_copy:\n                if isinstance(value, KeysView):\n                    value = list(value)\n                value = fast_deepcopy(value)\n\n            if asdict:\n                results[key] = value\n            else:\n                results.append(value)\n\n        if not isinstance(last, (list, tuple)):\n            if asdict:\n                return list(results.values()).pop()\n            else:\n                return results.pop()\n        else:\n            return results\n\n    # ~~ has\n\n    def has(self, path, **kwargs):\n        try:\n            self._get_value(path, **kwargs)\n        except NoSuchSettingsPath:\n            return False\n        else:\n            return True\n\n    # ~~ getter\n\n    def get(self, path, **kwargs):\n        error_on_path = kwargs.pop(\"error_on_path\", False)\n        validator = kwargs.pop(\"validator\", None)\n        fallback = kwargs.pop(\"fallback\", None)\n\n        def process():\n            try:\n                return self._get_value(path, **kwargs)\n            except NoSuchSettingsPath:\n                if error_on_path:\n                    raise\n                return None\n\n        result = process()\n        if callable(validator) and not validator(result):\n            result = fallback\n        return result\n\n    def getInt(self, path, **kwargs):\n        minimum = kwargs.pop(\"min\", None)\n        maximum = kwargs.pop(\"max\", None)\n\n        value = self.get(path, **kwargs)\n        if value is None:\n            return None\n\n        try:\n            intValue = int(value)\n\n            if minimum is not None and intValue < minimum:\n                return minimum\n            elif maximum is not None and intValue > maximum:\n                return maximum\n            else:\n                return intValue\n        except ValueError:\n            self._logger.warning(\n                \"Could not convert %r to a valid integer when getting option %r\"\n                % (value, path)\n            )\n            return None\n\n    def getFloat(self, path, **kwargs):\n        minimum = kwargs.pop(\"min\", None)\n        maximum = kwargs.pop(\"max\", None)\n\n        value = self.get(path, **kwargs)\n        if value is None:\n            return None\n\n        try:\n            floatValue = float(value)\n\n            if minimum is not None and floatValue < minimum:\n                return minimum\n            elif maximum is not None and floatValue > maximum:\n                return maximum\n            else:\n                return floatValue\n        except ValueError:\n            self._logger.warning(\n                \"Could not convert %r to a valid integer when getting option %r\"\n                % (value, path)\n            )\n            return None\n\n    def getBoolean(self, path, **kwargs):\n        value = self.get(path, **kwargs)\n        if value is None:\n            return None\n        if isinstance(value, bool):\n            return value\n        if isinstance(value, (int, float)):\n            return value != 0\n        if isinstance(value, str):\n            return value.lower() in valid_boolean_trues\n        return value is not None\n\n    def checkBaseFolder(self, type):\n        if type != \"base\" and type not in default_settings[\"folder\"]:\n            return False\n\n        if type == \"base\":\n            return os.path.exists(self._basedir)\n\n        folder = self.get([\"folder\", type])\n        default_folder = self._get_default_folder(type)\n        if folder is None:\n            folder = default_folder\n        return os.path.exists(folder)\n\n    def getBaseFolder(\n        self,\n        type,\n        create=True,\n        allow_fallback=True,\n        check_writable=True,\n        deep_check_writable=False,\n    ):\n        if type != \"base\" and type not in default_settings[\"folder\"]:\n            return None\n\n        if type == \"base\":\n            return self._basedir\n\n        folder = self.get([\"folder\", type])\n        default_folder = self._get_default_folder(type)\n        if folder is None:\n            folder = default_folder\n\n        try:\n            _validate_folder(\n                folder,\n                create=create,\n                check_writable=check_writable,\n                deep_check_writable=deep_check_writable,\n            )\n        except Exception:\n            if folder != default_folder and allow_fallback:\n                self._logger.exception(\n                    \"Invalid configured {} folder at {}, attempting to \"\n                    \"fall back on default folder at {}\".format(\n                        type, folder, default_folder\n                    )\n                )\n                _validate_folder(\n                    default_folder,\n                    create=create,\n                    check_writable=check_writable,\n                    deep_check_writable=deep_check_writable,\n                )\n                folder = default_folder\n\n                try:\n                    self.remove([\"folder\", type])\n                    self.save()\n                except KeyError:\n                    pass\n            else:\n                raise\n\n        return folder\n\n    def listScripts(self, script_type):\n        return list(\n            map(\n                lambda x: x[len(script_type + \"/\") :],\n                filter(\n                    lambda x: x.startswith(script_type + \"/\"),\n                    self._get_scripts(script_type),\n                ),\n            )\n        )\n\n    def loadScript(self, script_type, name, context=None, source=False):\n        if context is None:\n            context = {}\n        context.update({\"script\": {\"type\": script_type, \"name\": name}})\n\n        template = self._get_script_template(script_type, name, source=source)\n        if template is None:\n            return None\n\n        if source:\n            script = template\n        else:\n            try:\n                script = template.render(**context)\n            except Exception:\n                self._logger.exception(\n                    f\"Exception while trying to render script {script_type}:{name}\"\n                )\n                return None\n\n        return script\n\n    # ~~ remove\n\n    def remove(self, path, config=None, error_on_path=False, defaults=None):\n        if not path:\n            if error_on_path:\n                raise NoSuchSettingsPath()\n            return\n\n        chain = self._map.with_config_defaults(config=config, defaults=defaults)\n\n        try:\n            with self._lock:\n                chain.del_by_path(path)\n                self._mark_dirty()\n        except KeyError:\n            if error_on_path:\n                raise NoSuchSettingsPath()\n            pass\n\n    # ~~ setter\n\n    def set(\n        self,\n        path,\n        value,\n        force=False,\n        defaults=None,\n        config=None,\n        preprocessors=None,\n        error_on_path=False,\n        *args,\n        **kwargs,\n    ):\n        if not path:\n            if error_on_path:\n                raise NoSuchSettingsPath()\n            return\n\n        is_deprecated = self._is_deprecated_path(path)\n        if is_deprecated:\n            self._logger.warning(\n                f\"[Deprecation] Prevented write of `{value}` to deprecated settings path {path}. {is_deprecated if isinstance(is_deprecated, str) else ''}\"\n            )\n            return\n\n        if self._mtime is not None and self.last_modified != self._mtime:\n            self.load()\n\n        chain = self._map.with_config_defaults(config=config, defaults=defaults)\n\n        if preprocessors is None:\n            preprocessors = self._set_preprocessors\n\n        preprocessor = None\n        try:\n            preprocessor = self._get_by_path(path, preprocessors)\n        except NoSuchSettingsPath:\n            pass\n\n        if callable(preprocessor):\n            value = preprocessor(value)\n\n        try:\n            current = chain.get_by_path(path)\n        except KeyError:\n            current = None\n\n        try:\n            default_value = chain.get_by_path(path, only_defaults=True)\n        except KeyError:\n            if error_on_path:\n                raise NoSuchSettingsPath()\n            default_value = None\n\n        with self._lock:\n            in_local = chain.has_path(path, only_local=True)\n            in_defaults = chain.has_path(path, only_defaults=True)\n\n            if not force and in_defaults and in_local and default_value == value:\n                try:\n                    chain.del_by_path(path)\n                    self._mark_dirty()\n                    self._path_modified(path, current, value)\n                except KeyError:\n                    if error_on_path:\n                        raise NoSuchSettingsPath()\n                    pass\n            elif (\n                force\n                or (not in_local and in_defaults and default_value != value)\n                or (in_local and current != value)\n            ):\n                chain.set_by_path(path, value)\n                self._mark_dirty()\n                self._path_modified(path, current, value)\n\n        # we've changed the interface to no longer mutate the passed in config, so we\n        # must manually do that here\n        if config is not None:\n            config.clear()\n            config.update(chain.top_map)\n\n    def setInt(self, path, value, **kwargs):\n        if value is None:\n            self.set(path, None, **kwargs)\n            return\n\n        minimum = kwargs.pop(\"min\", None)\n        maximum = kwargs.pop(\"max\", None)\n\n        try:\n            intValue = int(value)\n\n            if minimum is not None and intValue < minimum:\n                intValue = minimum\n            if maximum is not None and intValue > maximum:\n                intValue = maximum\n        except ValueError:\n            self._logger.warning(\n                \"Could not convert %r to a valid integer when setting option %r\"\n                % (value, path)\n            )\n            return\n\n        self.set(path, intValue, **kwargs)\n\n    def setFloat(self, path, value, **kwargs):\n        if value is None:\n            self.set(path, None, **kwargs)\n            return\n\n        minimum = kwargs.pop(\"min\", None)\n        maximum = kwargs.pop(\"max\", None)\n\n        try:\n            floatValue = float(value)\n\n            if minimum is not None and floatValue < minimum:\n                floatValue = minimum\n            if maximum is not None and floatValue > maximum:\n                floatValue = maximum\n        except ValueError:\n            self._logger.warning(\n                \"Could not convert %r to a valid integer when setting option %r\"\n                % (value, path)\n            )\n            return\n\n        self.set(path, floatValue, **kwargs)\n\n    def setBoolean(self, path, value, **kwargs):\n        if value is None or isinstance(value, bool):\n            self.set(path, value, **kwargs)\n        elif isinstance(value, str) and value.lower() in valid_boolean_trues:\n            self.set(path, True, **kwargs)\n        else:\n            self.set(path, False, **kwargs)\n\n    def setBaseFolder(self, type, path, force=False, validate=True):\n        if type not in default_settings[\"folder\"]:\n            return None\n\n        currentPath = self.getBaseFolder(type)\n        defaultPath = self._get_default_folder(type)\n        if path is None or path == defaultPath:\n            self.remove([\"folder\", type])\n        elif (path != currentPath and path != defaultPath) or force:\n            if validate:\n                _validate_folder(path, check_writable=True, deep_check_writable=True)\n            self.set([\"folder\", type], path, force=force)\n\n    def saveScript(self, script_type, name, script):\n        script_folder = self.getBaseFolder(\"scripts\")\n        filename = os.path.realpath(os.path.join(script_folder, script_type, name))\n        if not filename.startswith(os.path.realpath(script_folder)):\n            # oops, jail break, that shouldn't happen\n            raise ValueError(\n                f\"Invalid script path to save to: {filename} (from {script_type}:{name})\"\n            )\n\n        path, _ = os.path.split(filename)\n        if not os.path.exists(path):\n            os.makedirs(path)\n        with atomic_write(filename, mode=\"wt\", max_permissions=0o666) as f:\n            f.write(script)\n\n    def generateApiKey(self):\n        apikey = generate_api_key()\n        self.set([\"api\", \"key\"], apikey)\n        self.save(force=True)\n        return apikey\n\n    def deleteApiKey(self):\n        self.set([\"api\", \"key\"], None)\n        self.save(force=True)\n\n\ndef _default_basedir(applicationName):\n    # taken from http://stackoverflow.com/questions/1084697/how-do-i-store-desktop-application-data-in-a-cross-platform-way-for-python\n    if sys.platform == \"darwin\":\n        import appdirs\n\n        return appdirs.user_data_dir(applicationName, \"\")\n    elif sys.platform == \"win32\":\n        return os.path.join(os.environ[\"APPDATA\"], applicationName)\n    else:\n        return os.path.expanduser(os.path.join(\"~\", \".\" + applicationName.lower()))\n\n\ndef _validate_folder(folder, create=True, check_writable=True, deep_check_writable=False):\n    logger = logging.getLogger(__name__)\n\n    if not os.path.exists(folder):\n        if os.path.islink(folder):\n            # broken symlink, see #2644\n            raise OSError(f\"Folder at {folder} appears to be a broken symlink\")\n\n        elif create:\n            # non existing, but we are allowed to create it\n            try:\n                os.makedirs(folder)\n            except Exception:\n                logger.exception(f\"Could not create {folder}\")\n                raise OSError(\n                    \"Folder for type {} at {} does not exist and creation failed\".format(\n                        type, folder\n                    )\n                )\n\n        else:\n            # not extisting, not allowed to create it\n            raise OSError(f\"No such folder: {folder}\")\n\n    elif os.path.isfile(folder):\n        # hardening against misconfiguration, see #1953\n        raise OSError(f\"Expected a folder at {folder} but found a file instead\")\n\n    elif check_writable:\n        # make sure we can also write into the folder\n        error = \"Folder at {} doesn't appear to be writable, please fix its permissions\".format(\n            folder\n        )\n        if not os.access(folder, os.W_OK):\n            raise OSError(error)\n\n        elif deep_check_writable:\n            # try to write a file to the folder - on network shares that might be the only reliable way\n            # to determine whether things are *actually* writable\n            testfile = os.path.join(folder, \".testballoon.txt\")\n            try:\n                with open(testfile, \"w\", encoding=\"utf-8\") as f:\n                    f.write(\"test\")\n                os.remove(testfile)\n            except Exception:\n                logger.exception(f\"Could not write test file to {testfile}\")\n                raise OSError(error)\n\n\ndef _paths(prefix, data):\n    if isinstance(data, dict):\n        for k, v in data.items():\n            yield from _paths(prefix + [k], v)\n    else:\n        yield prefix\n"], "filenames": ["src/octoprint/settings/__init__.py"], "buggy_code_start_loc": [596], "buggy_code_end_loc": [670], "fixing_code_start_loc": [596], "fixing_code_end_loc": [671], "type": "CWE-1336", "message": "OctoPrint is a web interface for 3D printers. OctoPrint versions up until and including 1.9.2 contain a vulnerability that allows malicious admins to configure a specially crafted GCODE script that will allow code execution during rendering of that script. An attacker might use this to extract data managed by OctoPrint, or manipulate data managed by OctoPrint, as well as execute arbitrary commands with the rights of the OctoPrint process on the server system. OctoPrint versions from 1.9.3 onward have been patched. Administrators of OctoPrint instances are advised to make sure they can trust all other administrators on their instance and to also not blindly configure arbitrary GCODE scripts found online or provided to them by third parties.", "other": {"cve": {"id": "CVE-2023-41047", "sourceIdentifier": "security-advisories@github.com", "published": "2023-10-09T16:15:10.480", "lastModified": "2023-10-13T18:40:38.120", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "OctoPrint is a web interface for 3D printers. OctoPrint versions up until and including 1.9.2 contain a vulnerability that allows malicious admins to configure a specially crafted GCODE script that will allow code execution during rendering of that script. An attacker might use this to extract data managed by OctoPrint, or manipulate data managed by OctoPrint, as well as execute arbitrary commands with the rights of the OctoPrint process on the server system. OctoPrint versions from 1.9.3 onward have been patched. Administrators of OctoPrint instances are advised to make sure they can trust all other administrators on their instance and to also not blindly configure arbitrary GCODE scripts found online or provided to them by third parties."}, {"lang": "es", "value": "OctoPrint es una interfaz web para impresoras 3D. Las versiones de OctoPrint hasta la 1.9.2 incluida contienen una vulnerabilidad que permite a administradores malintencionados configurar un script GCODE especialmente manipulado que permitir\u00e1 la ejecuci\u00f3n de c\u00f3digo durante la representaci\u00f3n de ese script. Un atacante podr\u00eda usar esto para extraer datos administrados por OctoPrint o manipular datos administrados por OctoPrint, as\u00ed como ejecutar comandos arbitrarios con los derechos del proceso OctoPrint en el sistema servidor. Se han parcheado las versiones de OctoPrint desde 1.9.3 en adelante. Se recomienda a los administradores de instancias de OctoPrint que se aseguren de que pueden confiar en todos los dem\u00e1s administradores de su instancia y que tampoco configuren ciegamente scripts GCODE arbitrarios que se encuentren en l\u00ednea o que les proporcionen terceros."}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:L/AC:L/PR:H/UI:R/S:U/C:H/I:H/A:H", "attackVector": "LOCAL", "attackComplexity": "LOW", "privilegesRequired": "HIGH", "userInteraction": "REQUIRED", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "HIGH", "availabilityImpact": "HIGH", "baseScore": 6.5, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 0.6, "impactScore": 5.9}, {"source": "security-advisories@github.com", "type": "Secondary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:A/AC:L/PR:H/UI:R/S:U/C:H/I:H/A:L", "attackVector": "ADJACENT_NETWORK", "attackComplexity": "LOW", "privilegesRequired": "HIGH", "userInteraction": "REQUIRED", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "HIGH", "availabilityImpact": "LOW", "baseScore": 6.2, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 0.7, "impactScore": 5.5}]}, "weaknesses": [{"source": "security-advisories@github.com", "type": "Primary", "description": [{"lang": "en", "value": "CWE-1336"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:octoprint:octoprint:*:*:*:*:*:*:*:*", "versionEndExcluding": "1.9.3", "matchCriteriaId": "6DDB94E4-F56F-4C7C-A828-B76E70051E66"}]}]}], "references": [{"url": "https://github.com/OctoPrint/OctoPrint/commit/d0072cff894509c77e243d6562245ad3079e17db", "source": "security-advisories@github.com", "tags": ["Patch"]}, {"url": "https://github.com/OctoPrint/OctoPrint/releases/tag/1.9.3", "source": "security-advisories@github.com", "tags": ["Release Notes"]}, {"url": "https://github.com/OctoPrint/OctoPrint/security/advisories/GHSA-fwfg-vprh-97ph", "source": "security-advisories@github.com", "tags": ["Vendor Advisory"]}]}, "github_commit_url": "https://github.com/OctoPrint/OctoPrint/commit/d0072cff894509c77e243d6562245ad3079e17db"}}
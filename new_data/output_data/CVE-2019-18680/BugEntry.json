{"buggy_code": ["/*\n * Copyright (c) 2006 Oracle.  All rights reserved.\n *\n * This software is available to you under a choice of one of two\n * licenses.  You may choose to be licensed under the terms of the GNU\n * General Public License (GPL) Version 2, available from the file\n * COPYING in the main directory of this source tree, or the\n * OpenIB.org BSD license below:\n *\n *     Redistribution and use in source and binary forms, with or\n *     without modification, are permitted provided that the following\n *     conditions are met:\n *\n *      - Redistributions of source code must retain the above\n *        copyright notice, this list of conditions and the following\n *        disclaimer.\n *\n *      - Redistributions in binary form must reproduce the above\n *        copyright notice, this list of conditions and the following\n *        disclaimer in the documentation and/or other materials\n *        provided with the distribution.\n *\n * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\n * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\n * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS\n * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN\n * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n * SOFTWARE.\n *\n */\n#include <linux/kernel.h>\n#include <linux/slab.h>\n#include <linux/in.h>\n#include <linux/module.h>\n#include <net/tcp.h>\n#include <net/net_namespace.h>\n#include <net/netns/generic.h>\n#include <net/tcp.h>\n\n#include \"rds.h\"\n#include \"tcp.h\"\n\n/* only for info exporting */\nstatic DEFINE_SPINLOCK(rds_tcp_tc_list_lock);\nstatic LIST_HEAD(rds_tcp_tc_list);\nstatic unsigned int rds_tcp_tc_count;\n\n/* Track rds_tcp_connection structs so they can be cleaned up */\nstatic DEFINE_SPINLOCK(rds_tcp_conn_lock);\nstatic LIST_HEAD(rds_tcp_conn_list);\n\nstatic struct kmem_cache *rds_tcp_conn_slab;\n\n#define RDS_TCP_DEFAULT_BUFSIZE (128 * 1024)\n\n/* doing it this way avoids calling tcp_sk() */\nvoid rds_tcp_nonagle(struct socket *sock)\n{\n\tmm_segment_t oldfs = get_fs();\n\tint val = 1;\n\n\tset_fs(KERNEL_DS);\n\tsock->ops->setsockopt(sock, SOL_TCP, TCP_NODELAY, (char __user *)&val,\n\t\t\t      sizeof(val));\n\tset_fs(oldfs);\n}\n\n/* All module specific customizations to the RDS-TCP socket should be done in\n * rds_tcp_tune() and applied after socket creation. In general these\n * customizations should be tunable via module_param()\n */\nvoid rds_tcp_tune(struct socket *sock)\n{\n\trds_tcp_nonagle(sock);\n}\n\nu32 rds_tcp_snd_nxt(struct rds_tcp_connection *tc)\n{\n\treturn tcp_sk(tc->t_sock->sk)->snd_nxt;\n}\n\nu32 rds_tcp_snd_una(struct rds_tcp_connection *tc)\n{\n\treturn tcp_sk(tc->t_sock->sk)->snd_una;\n}\n\nvoid rds_tcp_restore_callbacks(struct socket *sock,\n\t\t\t       struct rds_tcp_connection *tc)\n{\n\trdsdebug(\"restoring sock %p callbacks from tc %p\\n\", sock, tc);\n\twrite_lock_bh(&sock->sk->sk_callback_lock);\n\n\t/* done under the callback_lock to serialize with write_space */\n\tspin_lock(&rds_tcp_tc_list_lock);\n\tlist_del_init(&tc->t_list_item);\n\trds_tcp_tc_count--;\n\tspin_unlock(&rds_tcp_tc_list_lock);\n\n\ttc->t_sock = NULL;\n\n\tsock->sk->sk_write_space = tc->t_orig_write_space;\n\tsock->sk->sk_data_ready = tc->t_orig_data_ready;\n\tsock->sk->sk_state_change = tc->t_orig_state_change;\n\tsock->sk->sk_user_data = NULL;\n\n\twrite_unlock_bh(&sock->sk->sk_callback_lock);\n}\n\n/*\n * This is the only path that sets tc->t_sock.  Send and receive trust that\n * it is set.  The RDS_CONN_CONNECTED bit protects those paths from being\n * called while it isn't set.\n */\nvoid rds_tcp_set_callbacks(struct socket *sock, struct rds_connection *conn)\n{\n\tstruct rds_tcp_connection *tc = conn->c_transport_data;\n\n\trdsdebug(\"setting sock %p callbacks to tc %p\\n\", sock, tc);\n\twrite_lock_bh(&sock->sk->sk_callback_lock);\n\n\t/* done under the callback_lock to serialize with write_space */\n\tspin_lock(&rds_tcp_tc_list_lock);\n\tlist_add_tail(&tc->t_list_item, &rds_tcp_tc_list);\n\trds_tcp_tc_count++;\n\tspin_unlock(&rds_tcp_tc_list_lock);\n\n\t/* accepted sockets need our listen data ready undone */\n\tif (sock->sk->sk_data_ready == rds_tcp_listen_data_ready)\n\t\tsock->sk->sk_data_ready = sock->sk->sk_user_data;\n\n\ttc->t_sock = sock;\n\ttc->conn = conn;\n\ttc->t_orig_data_ready = sock->sk->sk_data_ready;\n\ttc->t_orig_write_space = sock->sk->sk_write_space;\n\ttc->t_orig_state_change = sock->sk->sk_state_change;\n\n\tsock->sk->sk_user_data = conn;\n\tsock->sk->sk_data_ready = rds_tcp_data_ready;\n\tsock->sk->sk_write_space = rds_tcp_write_space;\n\tsock->sk->sk_state_change = rds_tcp_state_change;\n\n\twrite_unlock_bh(&sock->sk->sk_callback_lock);\n}\n\nstatic void rds_tcp_tc_info(struct socket *sock, unsigned int len,\n\t\t\t    struct rds_info_iterator *iter,\n\t\t\t    struct rds_info_lengths *lens)\n{\n\tstruct rds_info_tcp_socket tsinfo;\n\tstruct rds_tcp_connection *tc;\n\tunsigned long flags;\n\tstruct sockaddr_in sin;\n\tint sinlen;\n\n\tspin_lock_irqsave(&rds_tcp_tc_list_lock, flags);\n\n\tif (len / sizeof(tsinfo) < rds_tcp_tc_count)\n\t\tgoto out;\n\n\tlist_for_each_entry(tc, &rds_tcp_tc_list, t_list_item) {\n\n\t\tsock->ops->getname(sock, (struct sockaddr *)&sin, &sinlen, 0);\n\t\ttsinfo.local_addr = sin.sin_addr.s_addr;\n\t\ttsinfo.local_port = sin.sin_port;\n\t\tsock->ops->getname(sock, (struct sockaddr *)&sin, &sinlen, 1);\n\t\ttsinfo.peer_addr = sin.sin_addr.s_addr;\n\t\ttsinfo.peer_port = sin.sin_port;\n\n\t\ttsinfo.hdr_rem = tc->t_tinc_hdr_rem;\n\t\ttsinfo.data_rem = tc->t_tinc_data_rem;\n\t\ttsinfo.last_sent_nxt = tc->t_last_sent_nxt;\n\t\ttsinfo.last_expected_una = tc->t_last_expected_una;\n\t\ttsinfo.last_seen_una = tc->t_last_seen_una;\n\n\t\trds_info_copy(iter, &tsinfo, sizeof(tsinfo));\n\t}\n\nout:\n\tlens->nr = rds_tcp_tc_count;\n\tlens->each = sizeof(tsinfo);\n\n\tspin_unlock_irqrestore(&rds_tcp_tc_list_lock, flags);\n}\n\nstatic int rds_tcp_laddr_check(struct net *net, __be32 addr)\n{\n\tif (inet_addr_type(net, addr) == RTN_LOCAL)\n\t\treturn 0;\n\treturn -EADDRNOTAVAIL;\n}\n\nstatic int rds_tcp_conn_alloc(struct rds_connection *conn, gfp_t gfp)\n{\n\tstruct rds_tcp_connection *tc;\n\n\ttc = kmem_cache_alloc(rds_tcp_conn_slab, gfp);\n\tif (!tc)\n\t\treturn -ENOMEM;\n\n\ttc->t_sock = NULL;\n\ttc->t_tinc = NULL;\n\ttc->t_tinc_hdr_rem = sizeof(struct rds_header);\n\ttc->t_tinc_data_rem = 0;\n\n\tconn->c_transport_data = tc;\n\n\tspin_lock_irq(&rds_tcp_conn_lock);\n\tlist_add_tail(&tc->t_tcp_node, &rds_tcp_conn_list);\n\tspin_unlock_irq(&rds_tcp_conn_lock);\n\n\trdsdebug(\"alloced tc %p\\n\", conn->c_transport_data);\n\treturn 0;\n}\n\nstatic void rds_tcp_conn_free(void *arg)\n{\n\tstruct rds_tcp_connection *tc = arg;\n\tunsigned long flags;\n\trdsdebug(\"freeing tc %p\\n\", tc);\n\n\tspin_lock_irqsave(&rds_tcp_conn_lock, flags);\n\tlist_del(&tc->t_tcp_node);\n\tspin_unlock_irqrestore(&rds_tcp_conn_lock, flags);\n\n\tkmem_cache_free(rds_tcp_conn_slab, tc);\n}\n\nstatic void rds_tcp_destroy_conns(void)\n{\n\tstruct rds_tcp_connection *tc, *_tc;\n\tLIST_HEAD(tmp_list);\n\n\t/* avoid calling conn_destroy with irqs off */\n\tspin_lock_irq(&rds_tcp_conn_lock);\n\tlist_splice(&rds_tcp_conn_list, &tmp_list);\n\tINIT_LIST_HEAD(&rds_tcp_conn_list);\n\tspin_unlock_irq(&rds_tcp_conn_lock);\n\n\tlist_for_each_entry_safe(tc, _tc, &tmp_list, t_tcp_node) {\n\t\tif (tc->conn->c_passive)\n\t\t\trds_conn_destroy(tc->conn->c_passive);\n\t\trds_conn_destroy(tc->conn);\n\t}\n}\n\nstatic void rds_tcp_exit(void);\n\nstruct rds_transport rds_tcp_transport = {\n\t.laddr_check\t\t= rds_tcp_laddr_check,\n\t.xmit_prepare\t\t= rds_tcp_xmit_prepare,\n\t.xmit_complete\t\t= rds_tcp_xmit_complete,\n\t.xmit\t\t\t= rds_tcp_xmit,\n\t.recv\t\t\t= rds_tcp_recv,\n\t.conn_alloc\t\t= rds_tcp_conn_alloc,\n\t.conn_free\t\t= rds_tcp_conn_free,\n\t.conn_connect\t\t= rds_tcp_conn_connect,\n\t.conn_shutdown\t\t= rds_tcp_conn_shutdown,\n\t.inc_copy_to_user\t= rds_tcp_inc_copy_to_user,\n\t.inc_free\t\t= rds_tcp_inc_free,\n\t.stats_info_copy\t= rds_tcp_stats_info_copy,\n\t.exit\t\t\t= rds_tcp_exit,\n\t.t_owner\t\t= THIS_MODULE,\n\t.t_name\t\t\t= \"tcp\",\n\t.t_type\t\t\t= RDS_TRANS_TCP,\n\t.t_prefer_loopback\t= 1,\n};\n\nstatic int rds_tcp_netid;\n\n/* per-network namespace private data for this module */\nstruct rds_tcp_net {\n\tstruct socket *rds_tcp_listen_sock;\n\tstruct work_struct rds_tcp_accept_w;\n};\n\nstatic void rds_tcp_accept_worker(struct work_struct *work)\n{\n\tstruct rds_tcp_net *rtn = container_of(work,\n\t\t\t\t\t       struct rds_tcp_net,\n\t\t\t\t\t       rds_tcp_accept_w);\n\n\twhile (rds_tcp_accept_one(rtn->rds_tcp_listen_sock) == 0)\n\t\tcond_resched();\n}\n\nvoid rds_tcp_accept_work(struct sock *sk)\n{\n\tstruct net *net = sock_net(sk);\n\tstruct rds_tcp_net *rtn = net_generic(net, rds_tcp_netid);\n\n\tqueue_work(rds_wq, &rtn->rds_tcp_accept_w);\n}\n\nstatic __net_init int rds_tcp_init_net(struct net *net)\n{\n\tstruct rds_tcp_net *rtn = net_generic(net, rds_tcp_netid);\n\n\trtn->rds_tcp_listen_sock = rds_tcp_listen_init(net);\n\tif (!rtn->rds_tcp_listen_sock) {\n\t\tpr_warn(\"could not set up listen sock\\n\");\n\t\treturn -EAFNOSUPPORT;\n\t}\n\tINIT_WORK(&rtn->rds_tcp_accept_w, rds_tcp_accept_worker);\n\treturn 0;\n}\n\nstatic void __net_exit rds_tcp_exit_net(struct net *net)\n{\n\tstruct rds_tcp_net *rtn = net_generic(net, rds_tcp_netid);\n\n\t/* If rds_tcp_exit_net() is called as a result of netns deletion,\n\t * the rds_tcp_kill_sock() device notifier would already have cleaned\n\t * up the listen socket, thus there is no work to do in this function.\n\t *\n\t * If rds_tcp_exit_net() is called as a result of module unload,\n\t * i.e., due to rds_tcp_exit() -> unregister_pernet_subsys(), then\n\t * we do need to clean up the listen socket here.\n\t */\n\tif (rtn->rds_tcp_listen_sock) {\n\t\trds_tcp_listen_stop(rtn->rds_tcp_listen_sock);\n\t\trtn->rds_tcp_listen_sock = NULL;\n\t\tflush_work(&rtn->rds_tcp_accept_w);\n\t}\n}\n\nstatic struct pernet_operations rds_tcp_net_ops = {\n\t.init = rds_tcp_init_net,\n\t.exit = rds_tcp_exit_net,\n\t.id = &rds_tcp_netid,\n\t.size = sizeof(struct rds_tcp_net),\n};\n\nstatic void rds_tcp_kill_sock(struct net *net)\n{\n\tstruct rds_tcp_connection *tc, *_tc;\n\tstruct sock *sk;\n\tLIST_HEAD(tmp_list);\n\tstruct rds_tcp_net *rtn = net_generic(net, rds_tcp_netid);\n\n\trds_tcp_listen_stop(rtn->rds_tcp_listen_sock);\n\trtn->rds_tcp_listen_sock = NULL;\n\tflush_work(&rtn->rds_tcp_accept_w);\n\tspin_lock_irq(&rds_tcp_conn_lock);\n\tlist_for_each_entry_safe(tc, _tc, &rds_tcp_conn_list, t_tcp_node) {\n\t\tstruct net *c_net = read_pnet(&tc->conn->c_net);\n\n\t\tif (net != c_net)\n\t\t\tcontinue;\n\t\tlist_move_tail(&tc->t_tcp_node, &tmp_list);\n\t}\n\tspin_unlock_irq(&rds_tcp_conn_lock);\n\tlist_for_each_entry_safe(tc, _tc, &tmp_list, t_tcp_node) {\n\t\tsk = tc->t_sock->sk;\n\t\tsk->sk_prot->disconnect(sk, 0);\n\t\ttcp_done(sk);\n\t\tif (tc->conn->c_passive)\n\t\t\trds_conn_destroy(tc->conn->c_passive);\n\t\trds_conn_destroy(tc->conn);\n\t}\n}\n\nstatic int rds_tcp_dev_event(struct notifier_block *this,\n\t\t\t     unsigned long event, void *ptr)\n{\n\tstruct net_device *dev = netdev_notifier_info_to_dev(ptr);\n\n\t/* rds-tcp registers as a pernet subys, so the ->exit will only\n\t * get invoked after network acitivity has quiesced. We need to\n\t * clean up all sockets  to quiesce network activity, and use\n\t * the unregistration of the per-net loopback device as a trigger\n\t * to start that cleanup.\n\t */\n\tif (event == NETDEV_UNREGISTER_FINAL &&\n\t    dev->ifindex == LOOPBACK_IFINDEX)\n\t\trds_tcp_kill_sock(dev_net(dev));\n\n\treturn NOTIFY_DONE;\n}\n\nstatic struct notifier_block rds_tcp_dev_notifier = {\n\t.notifier_call        = rds_tcp_dev_event,\n\t.priority = -10, /* must be called after other network notifiers */\n};\n\nstatic void rds_tcp_exit(void)\n{\n\trds_info_deregister_func(RDS_INFO_TCP_SOCKETS, rds_tcp_tc_info);\n\tunregister_pernet_subsys(&rds_tcp_net_ops);\n\tif (unregister_netdevice_notifier(&rds_tcp_dev_notifier))\n\t\tpr_warn(\"could not unregister rds_tcp_dev_notifier\\n\");\n\trds_tcp_destroy_conns();\n\trds_trans_unregister(&rds_tcp_transport);\n\trds_tcp_recv_exit();\n\tkmem_cache_destroy(rds_tcp_conn_slab);\n}\nmodule_exit(rds_tcp_exit);\n\nstatic int rds_tcp_init(void)\n{\n\tint ret;\n\n\trds_tcp_conn_slab = kmem_cache_create(\"rds_tcp_connection\",\n\t\t\t\t\t      sizeof(struct rds_tcp_connection),\n\t\t\t\t\t      0, 0, NULL);\n\tif (!rds_tcp_conn_slab) {\n\t\tret = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\tret = register_netdevice_notifier(&rds_tcp_dev_notifier);\n\tif (ret) {\n\t\tpr_warn(\"could not register rds_tcp_dev_notifier\\n\");\n\t\tgoto out;\n\t}\n\n\tret = register_pernet_subsys(&rds_tcp_net_ops);\n\tif (ret)\n\t\tgoto out_slab;\n\n\tret = rds_tcp_recv_init();\n\tif (ret)\n\t\tgoto out_pernet;\n\n\tret = rds_trans_register(&rds_tcp_transport);\n\tif (ret)\n\t\tgoto out_recv;\n\n\trds_info_register_func(RDS_INFO_TCP_SOCKETS, rds_tcp_tc_info);\n\n\tgoto out;\n\nout_recv:\n\trds_tcp_recv_exit();\nout_pernet:\n\tunregister_pernet_subsys(&rds_tcp_net_ops);\nout_slab:\n\tkmem_cache_destroy(rds_tcp_conn_slab);\nout:\n\treturn ret;\n}\nmodule_init(rds_tcp_init);\n\nMODULE_AUTHOR(\"Oracle Corporation <rds-devel@oss.oracle.com>\");\nMODULE_DESCRIPTION(\"RDS: TCP transport\");\nMODULE_LICENSE(\"Dual BSD/GPL\");\n\n"], "fixing_code": ["/*\n * Copyright (c) 2006 Oracle.  All rights reserved.\n *\n * This software is available to you under a choice of one of two\n * licenses.  You may choose to be licensed under the terms of the GNU\n * General Public License (GPL) Version 2, available from the file\n * COPYING in the main directory of this source tree, or the\n * OpenIB.org BSD license below:\n *\n *     Redistribution and use in source and binary forms, with or\n *     without modification, are permitted provided that the following\n *     conditions are met:\n *\n *      - Redistributions of source code must retain the above\n *        copyright notice, this list of conditions and the following\n *        disclaimer.\n *\n *      - Redistributions in binary form must reproduce the above\n *        copyright notice, this list of conditions and the following\n *        disclaimer in the documentation and/or other materials\n *        provided with the distribution.\n *\n * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\n * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\n * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS\n * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN\n * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n * SOFTWARE.\n *\n */\n#include <linux/kernel.h>\n#include <linux/slab.h>\n#include <linux/in.h>\n#include <linux/module.h>\n#include <net/tcp.h>\n#include <net/net_namespace.h>\n#include <net/netns/generic.h>\n#include <net/tcp.h>\n\n#include \"rds.h\"\n#include \"tcp.h\"\n\n/* only for info exporting */\nstatic DEFINE_SPINLOCK(rds_tcp_tc_list_lock);\nstatic LIST_HEAD(rds_tcp_tc_list);\nstatic unsigned int rds_tcp_tc_count;\n\n/* Track rds_tcp_connection structs so they can be cleaned up */\nstatic DEFINE_SPINLOCK(rds_tcp_conn_lock);\nstatic LIST_HEAD(rds_tcp_conn_list);\n\nstatic struct kmem_cache *rds_tcp_conn_slab;\n\n#define RDS_TCP_DEFAULT_BUFSIZE (128 * 1024)\n\n/* doing it this way avoids calling tcp_sk() */\nvoid rds_tcp_nonagle(struct socket *sock)\n{\n\tmm_segment_t oldfs = get_fs();\n\tint val = 1;\n\n\tset_fs(KERNEL_DS);\n\tsock->ops->setsockopt(sock, SOL_TCP, TCP_NODELAY, (char __user *)&val,\n\t\t\t      sizeof(val));\n\tset_fs(oldfs);\n}\n\n/* All module specific customizations to the RDS-TCP socket should be done in\n * rds_tcp_tune() and applied after socket creation. In general these\n * customizations should be tunable via module_param()\n */\nvoid rds_tcp_tune(struct socket *sock)\n{\n\trds_tcp_nonagle(sock);\n}\n\nu32 rds_tcp_snd_nxt(struct rds_tcp_connection *tc)\n{\n\treturn tcp_sk(tc->t_sock->sk)->snd_nxt;\n}\n\nu32 rds_tcp_snd_una(struct rds_tcp_connection *tc)\n{\n\treturn tcp_sk(tc->t_sock->sk)->snd_una;\n}\n\nvoid rds_tcp_restore_callbacks(struct socket *sock,\n\t\t\t       struct rds_tcp_connection *tc)\n{\n\trdsdebug(\"restoring sock %p callbacks from tc %p\\n\", sock, tc);\n\twrite_lock_bh(&sock->sk->sk_callback_lock);\n\n\t/* done under the callback_lock to serialize with write_space */\n\tspin_lock(&rds_tcp_tc_list_lock);\n\tlist_del_init(&tc->t_list_item);\n\trds_tcp_tc_count--;\n\tspin_unlock(&rds_tcp_tc_list_lock);\n\n\ttc->t_sock = NULL;\n\n\tsock->sk->sk_write_space = tc->t_orig_write_space;\n\tsock->sk->sk_data_ready = tc->t_orig_data_ready;\n\tsock->sk->sk_state_change = tc->t_orig_state_change;\n\tsock->sk->sk_user_data = NULL;\n\n\twrite_unlock_bh(&sock->sk->sk_callback_lock);\n}\n\n/*\n * This is the only path that sets tc->t_sock.  Send and receive trust that\n * it is set.  The RDS_CONN_CONNECTED bit protects those paths from being\n * called while it isn't set.\n */\nvoid rds_tcp_set_callbacks(struct socket *sock, struct rds_connection *conn)\n{\n\tstruct rds_tcp_connection *tc = conn->c_transport_data;\n\n\trdsdebug(\"setting sock %p callbacks to tc %p\\n\", sock, tc);\n\twrite_lock_bh(&sock->sk->sk_callback_lock);\n\n\t/* done under the callback_lock to serialize with write_space */\n\tspin_lock(&rds_tcp_tc_list_lock);\n\tlist_add_tail(&tc->t_list_item, &rds_tcp_tc_list);\n\trds_tcp_tc_count++;\n\tspin_unlock(&rds_tcp_tc_list_lock);\n\n\t/* accepted sockets need our listen data ready undone */\n\tif (sock->sk->sk_data_ready == rds_tcp_listen_data_ready)\n\t\tsock->sk->sk_data_ready = sock->sk->sk_user_data;\n\n\ttc->t_sock = sock;\n\ttc->conn = conn;\n\ttc->t_orig_data_ready = sock->sk->sk_data_ready;\n\ttc->t_orig_write_space = sock->sk->sk_write_space;\n\ttc->t_orig_state_change = sock->sk->sk_state_change;\n\n\tsock->sk->sk_user_data = conn;\n\tsock->sk->sk_data_ready = rds_tcp_data_ready;\n\tsock->sk->sk_write_space = rds_tcp_write_space;\n\tsock->sk->sk_state_change = rds_tcp_state_change;\n\n\twrite_unlock_bh(&sock->sk->sk_callback_lock);\n}\n\nstatic void rds_tcp_tc_info(struct socket *sock, unsigned int len,\n\t\t\t    struct rds_info_iterator *iter,\n\t\t\t    struct rds_info_lengths *lens)\n{\n\tstruct rds_info_tcp_socket tsinfo;\n\tstruct rds_tcp_connection *tc;\n\tunsigned long flags;\n\tstruct sockaddr_in sin;\n\tint sinlen;\n\n\tspin_lock_irqsave(&rds_tcp_tc_list_lock, flags);\n\n\tif (len / sizeof(tsinfo) < rds_tcp_tc_count)\n\t\tgoto out;\n\n\tlist_for_each_entry(tc, &rds_tcp_tc_list, t_list_item) {\n\n\t\tsock->ops->getname(sock, (struct sockaddr *)&sin, &sinlen, 0);\n\t\ttsinfo.local_addr = sin.sin_addr.s_addr;\n\t\ttsinfo.local_port = sin.sin_port;\n\t\tsock->ops->getname(sock, (struct sockaddr *)&sin, &sinlen, 1);\n\t\ttsinfo.peer_addr = sin.sin_addr.s_addr;\n\t\ttsinfo.peer_port = sin.sin_port;\n\n\t\ttsinfo.hdr_rem = tc->t_tinc_hdr_rem;\n\t\ttsinfo.data_rem = tc->t_tinc_data_rem;\n\t\ttsinfo.last_sent_nxt = tc->t_last_sent_nxt;\n\t\ttsinfo.last_expected_una = tc->t_last_expected_una;\n\t\ttsinfo.last_seen_una = tc->t_last_seen_una;\n\n\t\trds_info_copy(iter, &tsinfo, sizeof(tsinfo));\n\t}\n\nout:\n\tlens->nr = rds_tcp_tc_count;\n\tlens->each = sizeof(tsinfo);\n\n\tspin_unlock_irqrestore(&rds_tcp_tc_list_lock, flags);\n}\n\nstatic int rds_tcp_laddr_check(struct net *net, __be32 addr)\n{\n\tif (inet_addr_type(net, addr) == RTN_LOCAL)\n\t\treturn 0;\n\treturn -EADDRNOTAVAIL;\n}\n\nstatic int rds_tcp_conn_alloc(struct rds_connection *conn, gfp_t gfp)\n{\n\tstruct rds_tcp_connection *tc;\n\n\ttc = kmem_cache_alloc(rds_tcp_conn_slab, gfp);\n\tif (!tc)\n\t\treturn -ENOMEM;\n\n\ttc->t_sock = NULL;\n\ttc->t_tinc = NULL;\n\ttc->t_tinc_hdr_rem = sizeof(struct rds_header);\n\ttc->t_tinc_data_rem = 0;\n\n\tconn->c_transport_data = tc;\n\n\tspin_lock_irq(&rds_tcp_conn_lock);\n\tlist_add_tail(&tc->t_tcp_node, &rds_tcp_conn_list);\n\tspin_unlock_irq(&rds_tcp_conn_lock);\n\n\trdsdebug(\"alloced tc %p\\n\", conn->c_transport_data);\n\treturn 0;\n}\n\nstatic void rds_tcp_conn_free(void *arg)\n{\n\tstruct rds_tcp_connection *tc = arg;\n\tunsigned long flags;\n\trdsdebug(\"freeing tc %p\\n\", tc);\n\n\tspin_lock_irqsave(&rds_tcp_conn_lock, flags);\n\tlist_del(&tc->t_tcp_node);\n\tspin_unlock_irqrestore(&rds_tcp_conn_lock, flags);\n\n\tkmem_cache_free(rds_tcp_conn_slab, tc);\n}\n\nstatic void rds_tcp_destroy_conns(void)\n{\n\tstruct rds_tcp_connection *tc, *_tc;\n\tLIST_HEAD(tmp_list);\n\n\t/* avoid calling conn_destroy with irqs off */\n\tspin_lock_irq(&rds_tcp_conn_lock);\n\tlist_splice(&rds_tcp_conn_list, &tmp_list);\n\tINIT_LIST_HEAD(&rds_tcp_conn_list);\n\tspin_unlock_irq(&rds_tcp_conn_lock);\n\n\tlist_for_each_entry_safe(tc, _tc, &tmp_list, t_tcp_node) {\n\t\tif (tc->conn->c_passive)\n\t\t\trds_conn_destroy(tc->conn->c_passive);\n\t\trds_conn_destroy(tc->conn);\n\t}\n}\n\nstatic void rds_tcp_exit(void);\n\nstruct rds_transport rds_tcp_transport = {\n\t.laddr_check\t\t= rds_tcp_laddr_check,\n\t.xmit_prepare\t\t= rds_tcp_xmit_prepare,\n\t.xmit_complete\t\t= rds_tcp_xmit_complete,\n\t.xmit\t\t\t= rds_tcp_xmit,\n\t.recv\t\t\t= rds_tcp_recv,\n\t.conn_alloc\t\t= rds_tcp_conn_alloc,\n\t.conn_free\t\t= rds_tcp_conn_free,\n\t.conn_connect\t\t= rds_tcp_conn_connect,\n\t.conn_shutdown\t\t= rds_tcp_conn_shutdown,\n\t.inc_copy_to_user\t= rds_tcp_inc_copy_to_user,\n\t.inc_free\t\t= rds_tcp_inc_free,\n\t.stats_info_copy\t= rds_tcp_stats_info_copy,\n\t.exit\t\t\t= rds_tcp_exit,\n\t.t_owner\t\t= THIS_MODULE,\n\t.t_name\t\t\t= \"tcp\",\n\t.t_type\t\t\t= RDS_TRANS_TCP,\n\t.t_prefer_loopback\t= 1,\n};\n\nstatic int rds_tcp_netid;\n\n/* per-network namespace private data for this module */\nstruct rds_tcp_net {\n\tstruct socket *rds_tcp_listen_sock;\n\tstruct work_struct rds_tcp_accept_w;\n};\n\nstatic void rds_tcp_accept_worker(struct work_struct *work)\n{\n\tstruct rds_tcp_net *rtn = container_of(work,\n\t\t\t\t\t       struct rds_tcp_net,\n\t\t\t\t\t       rds_tcp_accept_w);\n\n\twhile (rds_tcp_accept_one(rtn->rds_tcp_listen_sock) == 0)\n\t\tcond_resched();\n}\n\nvoid rds_tcp_accept_work(struct sock *sk)\n{\n\tstruct net *net = sock_net(sk);\n\tstruct rds_tcp_net *rtn = net_generic(net, rds_tcp_netid);\n\n\tqueue_work(rds_wq, &rtn->rds_tcp_accept_w);\n}\n\nstatic __net_init int rds_tcp_init_net(struct net *net)\n{\n\tstruct rds_tcp_net *rtn = net_generic(net, rds_tcp_netid);\n\n\trtn->rds_tcp_listen_sock = rds_tcp_listen_init(net);\n\tif (!rtn->rds_tcp_listen_sock) {\n\t\tpr_warn(\"could not set up listen sock\\n\");\n\t\treturn -EAFNOSUPPORT;\n\t}\n\tINIT_WORK(&rtn->rds_tcp_accept_w, rds_tcp_accept_worker);\n\treturn 0;\n}\n\nstatic void __net_exit rds_tcp_exit_net(struct net *net)\n{\n\tstruct rds_tcp_net *rtn = net_generic(net, rds_tcp_netid);\n\n\t/* If rds_tcp_exit_net() is called as a result of netns deletion,\n\t * the rds_tcp_kill_sock() device notifier would already have cleaned\n\t * up the listen socket, thus there is no work to do in this function.\n\t *\n\t * If rds_tcp_exit_net() is called as a result of module unload,\n\t * i.e., due to rds_tcp_exit() -> unregister_pernet_subsys(), then\n\t * we do need to clean up the listen socket here.\n\t */\n\tif (rtn->rds_tcp_listen_sock) {\n\t\trds_tcp_listen_stop(rtn->rds_tcp_listen_sock);\n\t\trtn->rds_tcp_listen_sock = NULL;\n\t\tflush_work(&rtn->rds_tcp_accept_w);\n\t}\n}\n\nstatic struct pernet_operations rds_tcp_net_ops = {\n\t.init = rds_tcp_init_net,\n\t.exit = rds_tcp_exit_net,\n\t.id = &rds_tcp_netid,\n\t.size = sizeof(struct rds_tcp_net),\n};\n\nstatic void rds_tcp_kill_sock(struct net *net)\n{\n\tstruct rds_tcp_connection *tc, *_tc;\n\tstruct sock *sk;\n\tLIST_HEAD(tmp_list);\n\tstruct rds_tcp_net *rtn = net_generic(net, rds_tcp_netid);\n\n\trds_tcp_listen_stop(rtn->rds_tcp_listen_sock);\n\trtn->rds_tcp_listen_sock = NULL;\n\tflush_work(&rtn->rds_tcp_accept_w);\n\tspin_lock_irq(&rds_tcp_conn_lock);\n\tlist_for_each_entry_safe(tc, _tc, &rds_tcp_conn_list, t_tcp_node) {\n\t\tstruct net *c_net = read_pnet(&tc->conn->c_net);\n\n\t\tif (net != c_net)\n\t\t\tcontinue;\n\t\tlist_move_tail(&tc->t_tcp_node, &tmp_list);\n\t}\n\tspin_unlock_irq(&rds_tcp_conn_lock);\n\tlist_for_each_entry_safe(tc, _tc, &tmp_list, t_tcp_node) {\n\t\tif (tc->t_sock) {\n\t\t\tsk = tc->t_sock->sk;\n\t\t\tsk->sk_prot->disconnect(sk, 0);\n\t\t\ttcp_done(sk);\n\t\t}\n\t\tif (tc->conn->c_passive)\n\t\t\trds_conn_destroy(tc->conn->c_passive);\n\t\trds_conn_destroy(tc->conn);\n\t}\n}\n\nstatic int rds_tcp_dev_event(struct notifier_block *this,\n\t\t\t     unsigned long event, void *ptr)\n{\n\tstruct net_device *dev = netdev_notifier_info_to_dev(ptr);\n\n\t/* rds-tcp registers as a pernet subys, so the ->exit will only\n\t * get invoked after network acitivity has quiesced. We need to\n\t * clean up all sockets  to quiesce network activity, and use\n\t * the unregistration of the per-net loopback device as a trigger\n\t * to start that cleanup.\n\t */\n\tif (event == NETDEV_UNREGISTER_FINAL &&\n\t    dev->ifindex == LOOPBACK_IFINDEX)\n\t\trds_tcp_kill_sock(dev_net(dev));\n\n\treturn NOTIFY_DONE;\n}\n\nstatic struct notifier_block rds_tcp_dev_notifier = {\n\t.notifier_call        = rds_tcp_dev_event,\n\t.priority = -10, /* must be called after other network notifiers */\n};\n\nstatic void rds_tcp_exit(void)\n{\n\trds_info_deregister_func(RDS_INFO_TCP_SOCKETS, rds_tcp_tc_info);\n\tunregister_pernet_subsys(&rds_tcp_net_ops);\n\tif (unregister_netdevice_notifier(&rds_tcp_dev_notifier))\n\t\tpr_warn(\"could not unregister rds_tcp_dev_notifier\\n\");\n\trds_tcp_destroy_conns();\n\trds_trans_unregister(&rds_tcp_transport);\n\trds_tcp_recv_exit();\n\tkmem_cache_destroy(rds_tcp_conn_slab);\n}\nmodule_exit(rds_tcp_exit);\n\nstatic int rds_tcp_init(void)\n{\n\tint ret;\n\n\trds_tcp_conn_slab = kmem_cache_create(\"rds_tcp_connection\",\n\t\t\t\t\t      sizeof(struct rds_tcp_connection),\n\t\t\t\t\t      0, 0, NULL);\n\tif (!rds_tcp_conn_slab) {\n\t\tret = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\tret = register_netdevice_notifier(&rds_tcp_dev_notifier);\n\tif (ret) {\n\t\tpr_warn(\"could not register rds_tcp_dev_notifier\\n\");\n\t\tgoto out;\n\t}\n\n\tret = register_pernet_subsys(&rds_tcp_net_ops);\n\tif (ret)\n\t\tgoto out_slab;\n\n\tret = rds_tcp_recv_init();\n\tif (ret)\n\t\tgoto out_pernet;\n\n\tret = rds_trans_register(&rds_tcp_transport);\n\tif (ret)\n\t\tgoto out_recv;\n\n\trds_info_register_func(RDS_INFO_TCP_SOCKETS, rds_tcp_tc_info);\n\n\tgoto out;\n\nout_recv:\n\trds_tcp_recv_exit();\nout_pernet:\n\tunregister_pernet_subsys(&rds_tcp_net_ops);\nout_slab:\n\tkmem_cache_destroy(rds_tcp_conn_slab);\nout:\n\treturn ret;\n}\nmodule_init(rds_tcp_init);\n\nMODULE_AUTHOR(\"Oracle Corporation <rds-devel@oss.oracle.com>\");\nMODULE_DESCRIPTION(\"RDS: TCP transport\");\nMODULE_LICENSE(\"Dual BSD/GPL\");\n\n"], "filenames": ["net/rds/tcp.c"], "buggy_code_start_loc": [355], "buggy_code_end_loc": [358], "fixing_code_start_loc": [355], "fixing_code_end_loc": [360], "type": "CWE-476", "message": "An issue was discovered in the Linux kernel 4.4.x before 4.4.195. There is a NULL pointer dereference in rds_tcp_kill_sock() in net/rds/tcp.c that will cause denial of service, aka CID-91573ae4aed0.", "other": {"cve": {"id": "CVE-2019-18680", "sourceIdentifier": "cve@mitre.org", "published": "2019-11-04T15:15:11.507", "lastModified": "2023-01-17T21:31:48.287", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "An issue was discovered in the Linux kernel 4.4.x before 4.4.195. There is a NULL pointer dereference in rds_tcp_kill_sock() in net/rds/tcp.c that will cause denial of service, aka CID-91573ae4aed0."}, {"lang": "es", "value": "Se detect\u00f3 un problema en el kernel de Linux versiones 4.4.x anteriores a 4.4.195. Se presenta una desreferencia del puntero NULL en la funci\u00f3n rds_tcp_kill_sock() en el archivo net/rds/tcp.c que causar\u00e1 una denegaci\u00f3n de servicio, tambi\u00e9n se conoce como CID-91573ae4aed0."}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 7.5, "baseSeverity": "HIGH"}, "exploitabilityScore": 3.9, "impactScore": 3.6}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:N/AC:L/Au:N/C:N/I:N/A:C", "accessVector": "NETWORK", "accessComplexity": "LOW", "authentication": "NONE", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "COMPLETE", "baseScore": 7.8}, "baseSeverity": "HIGH", "exploitabilityScore": 10.0, "impactScore": 6.9, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-476"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionStartIncluding": "4.4.179", "versionEndExcluding": "4.4.195", "matchCriteriaId": "4DB0A6CA-C553-490A-AD8F-C98FE222ABEC"}]}]}], "references": [{"url": "https://cdn.kernel.org/pub/linux/kernel/v4.x/ChangeLog-4.4.195", "source": "cve@mitre.org", "tags": ["Exploit", "Patch", "Vendor Advisory"]}, {"url": "https://git.kernel.org/pub/scm/linux/kernel/git/stable/linux.git/commit/?id=91573ae4aed0a49660abdad4d42f2a0db995ee5e", "source": "cve@mitre.org", "tags": ["Patch", "Vendor Advisory"]}, {"url": "https://github.com/torvalds/linux/commit/91573ae4aed0a49660abdad4d42f2a0db995ee5e", "source": "cve@mitre.org", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://lkml.org/lkml/2019/9/18/337", "source": "cve@mitre.org", "tags": ["Exploit", "Mailing List", "Vendor Advisory"]}, {"url": "https://security.netapp.com/advisory/ntap-20191205-0001/", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}]}, "github_commit_url": "https://github.com/torvalds/linux/commit/91573ae4aed0a49660abdad4d42f2a0db995ee5e"}}
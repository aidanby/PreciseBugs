{"buggy_code": ["def test_concat(get_contract_with_gas_estimation):\n    test_concat = \"\"\"\n@external\ndef foo2(input1: Bytes[50], input2: Bytes[50]) -> Bytes[1000]:\n    return concat(input1, input2)\n\n@external\ndef foo3(input1: Bytes[50], input2: Bytes[50], input3: Bytes[50]) -> Bytes[1000]:\n    return concat(input1, input2, input3)\n    \"\"\"\n\n    c = get_contract_with_gas_estimation(test_concat)\n    assert c.foo2(b\"h\", b\"orse\") == b\"horse\"\n    assert c.foo2(b\"h\", b\"\") == b\"h\"\n    assert c.foo2(b\"\", b\"\") == b\"\"\n    assert c.foo2(b\"\", b\"orse\") == b\"orse\"\n    assert c.foo3(b\"Buffalo\", b\" \", b\"buffalo\") == b\"Buffalo buffalo\"\n    assert c.foo2(b\"\\x36\", b\"\\x35\" * 32) == b\"\\x36\" + b\"\\x35\" * 32\n    assert c.foo2(b\"\\x36\" * 48, b\"\\x35\" * 32) == b\"\\x36\" * 48 + b\"\\x35\" * 32\n    assert (\n        c.foo3(b\"horses\" * 4, b\"mice\" * 7, b\"crows\" * 10)\n        == b\"horses\" * 4 + b\"mice\" * 7 + b\"crows\" * 10\n    )  # noqa: E501\n    print(\"Passed simple concat test\")\n\n\ndef test_concat2(get_contract_with_gas_estimation):\n    test_concat2 = \"\"\"\n@external\ndef foo(inp: Bytes[50]) -> Bytes[1000]:\n    x: Bytes[50] = inp\n    return concat(x, inp, x, inp, x, inp, x, inp, x, inp)\n    \"\"\"\n\n    c = get_contract_with_gas_estimation(test_concat2)\n    assert c.foo(b\"horse\" * 9 + b\"vyper\") == (b\"horse\" * 9 + b\"vyper\") * 10\n    print(\"Passed second concat test\")\n\n\ndef test_crazy_concat_code(get_contract_with_gas_estimation):\n    crazy_concat_code = \"\"\"\ny: Bytes[10]\n\n@external\ndef krazykonkat(z: Bytes[10]) -> Bytes[25]:\n    x: Bytes[3] = b\"cow\"\n    self.y = b\"horse\"\n    return concat(x, b\" \", self.y, b\" \", z)\n    \"\"\"\n\n    c = get_contract_with_gas_estimation(crazy_concat_code)\n\n    assert c.krazykonkat(b\"moose\") == b\"cow horse moose\"\n\n    print(\"Passed third concat test\")\n\n\ndef test_concat_bytes32(get_contract_with_gas_estimation):\n    test_concat_bytes32 = \"\"\"\n@external\ndef sandwich(inp: Bytes[100], inp2: bytes32) -> Bytes[164]:\n    return concat(inp2, inp, inp2)\n\n@external\ndef fivetimes(inp: bytes32) -> Bytes[160]:\n    return concat(inp, inp, inp, inp, inp)\n    \"\"\"\n\n    c = get_contract_with_gas_estimation(test_concat_bytes32)\n    assert c.sandwich(b\"cow\", b\"\\x35\" * 32) == b\"\\x35\" * 32 + b\"cow\" + b\"\\x35\" * 32, c.sandwich(\n        b\"cow\", b\"\\x35\" * 32\n    )  # noqa: E501\n    assert c.sandwich(b\"\", b\"\\x46\" * 32) == b\"\\x46\" * 64\n    assert c.sandwich(b\"\\x57\" * 95, b\"\\x57\" * 32) == b\"\\x57\" * 159\n    assert c.sandwich(b\"\\x57\" * 96, b\"\\x57\" * 32) == b\"\\x57\" * 160\n    assert c.sandwich(b\"\\x57\" * 97, b\"\\x57\" * 32) == b\"\\x57\" * 161\n    assert c.fivetimes(b\"mongoose\" * 4) == b\"mongoose\" * 20\n\n    print(\"Passed concat bytes32 test\")\n\n\ndef test_konkat_code(get_contract_with_gas_estimation):\n    konkat_code = \"\"\"\necks: bytes32\n\n@external\ndef foo(x: bytes32, y: bytes32) -> Bytes[64]:\n    self.ecks = x\n    return concat(self.ecks, y)\n\n@external\ndef goo(x: bytes32, y: bytes32) -> Bytes[64]:\n    self.ecks = x\n    return concat(self.ecks, y)\n\n@external\ndef hoo(x: bytes32, y: bytes32) -> Bytes[64]:\n    return concat(x, y)\n    \"\"\"\n\n    c = get_contract_with_gas_estimation(konkat_code)\n    assert c.foo(b\"\\x35\" * 32, b\"\\x00\" * 32) == b\"\\x35\" * 32 + b\"\\x00\" * 32\n    assert c.goo(b\"\\x35\" * 32, b\"\\x00\" * 32) == b\"\\x35\" * 32 + b\"\\x00\" * 32\n    assert c.hoo(b\"\\x35\" * 32, b\"\\x00\" * 32) == b\"\\x35\" * 32 + b\"\\x00\" * 32\n\n    print(\"Passed second concat tests\")\n\n\ndef test_small_output(get_contract_with_gas_estimation):\n    code = \"\"\"\n@external\ndef small_output(a: String[5], b: String[4]) -> String[9]:\n    c: String[9] = concat(a, b)\n    return c\n    \"\"\"\n    c = get_contract_with_gas_estimation(code)\n    assert c.small_output(\"abcde\", \"fghi\") == \"abcdefghi\"\n    assert c.small_output(\"\", \"\") == \"\"\n\n\ndef test_small_bytes(get_contract_with_gas_estimation):\n    # TODO maybe use parametrization or hypothesis for the examples\n    code = \"\"\"\n@external\ndef small_bytes1(a: bytes1, b: Bytes[2]) -> Bytes[3]:\n    return concat(a, b)\n\n@external\ndef small_bytes2(a: Bytes[1], b: bytes2) -> Bytes[3]:\n    return concat(a, b)\n\n@external\ndef small_bytes3(a: bytes4, b: bytes32) -> Bytes[36]:\n    return concat(a, b)\n\n@external\ndef small_bytes4(a: bytes8, b: Bytes[32], c: bytes8) -> Bytes[48]:\n    return concat(a, b, c)\n    \"\"\"\n    contract = get_contract_with_gas_estimation(code)\n\n    i = 0\n\n    def bytes_for_len(n):\n        nonlocal i\n        # bytes constructor with state\n        # (so we don't keep generating the same string)\n        xs = []\n        for _ in range(n):\n            i += 1\n            i %= 256\n            xs.append(i)\n        return bytes(xs)\n\n    a, b = bytes_for_len(1), bytes_for_len(2)\n    assert contract.small_bytes1(a, b) == a + b\n\n    a, b = bytes_for_len(1), bytes_for_len(1)\n    assert contract.small_bytes1(a, b) == a + b\n\n    a, b = bytes_for_len(1), bytes_for_len(2)\n    assert contract.small_bytes2(a, b) == a + b\n\n    a, b = b\"\", bytes_for_len(2)\n    assert contract.small_bytes2(a, b) == a + b\n\n    a, b = bytes_for_len(4), bytes_for_len(32)\n    assert contract.small_bytes3(a, b) == a + b\n\n    a, b, c = bytes_for_len(8), bytes_for_len(32), bytes_for_len(8)\n    assert contract.small_bytes4(a, b, c) == a + b + c\n\n    a, b, c = bytes_for_len(8), bytes_for_len(1), bytes_for_len(8)\n    assert contract.small_bytes4(a, b, c) == a + b + c\n\n    a, b, c = bytes_for_len(8), bytes_for_len(0), bytes_for_len(8)\n    assert contract.small_bytes4(a, b, c) == a + b + c\n", "import hashlib\nimport math\nimport operator\n\nfrom vyper import ast as vy_ast\nfrom vyper.abi_types import ABI_Tuple\nfrom vyper.ast.validation import validate_call_args\nfrom vyper.codegen.abi_encoder import abi_encode\nfrom vyper.codegen.context import Context, VariableRecord\nfrom vyper.codegen.core import (\n    STORE,\n    IRnode,\n    _freshname,\n    add_ofst,\n    bytes_data_ptr,\n    calculate_type_for_external_return,\n    check_external_call,\n    clamp,\n    clamp2,\n    clamp_basetype,\n    clamp_nonzero,\n    copy_bytes,\n    dummy_node_for_type,\n    ensure_in_memory,\n    eval_once_check,\n    eval_seq,\n    get_bytearray_length,\n    get_type_for_exact_size,\n    ir_tuple_from_args,\n    make_setter,\n    promote_signed_int,\n    sar,\n    shl,\n    shr,\n    unwrap_location,\n)\nfrom vyper.codegen.expr import Expr\nfrom vyper.codegen.ir_node import Encoding, scope_multi\nfrom vyper.codegen.keccak256_helper import keccak256_helper\nfrom vyper.evm.address_space import MEMORY, STORAGE\nfrom vyper.exceptions import (\n    ArgumentException,\n    CompilerPanic,\n    InvalidLiteral,\n    InvalidType,\n    StateAccessViolation,\n    StructureException,\n    TypeMismatch,\n    UnfoldableNode,\n    ZeroDivisionException,\n)\nfrom vyper.semantics.analysis.base import Modifiability, VarInfo\nfrom vyper.semantics.analysis.utils import (\n    get_common_types,\n    get_exact_type_from_node,\n    get_possible_types_from_node,\n    validate_expected_type,\n)\nfrom vyper.semantics.types import (\n    TYPE_T,\n    AddressT,\n    BoolT,\n    BytesM_T,\n    BytesT,\n    DArrayT,\n    DecimalT,\n    HashMapT,\n    IntegerT,\n    KwargSettings,\n    SArrayT,\n    StringT,\n    TupleT,\n)\nfrom vyper.semantics.types.bytestrings import _BytestringT\nfrom vyper.semantics.types.shortcuts import (\n    BYTES4_T,\n    BYTES32_T,\n    INT128_T,\n    INT256_T,\n    UINT8_T,\n    UINT256_T,\n)\nfrom vyper.semantics.types.utils import type_from_annotation\nfrom vyper.utils import (\n    DECIMAL_DIVISOR,\n    EIP_170_LIMIT,\n    SHA3_PER_WORD,\n    MemoryPositions,\n    bytes_to_int,\n    ceil32,\n    fourbytes_to_int,\n    keccak256,\n    method_id,\n    method_id_int,\n    vyper_warn,\n)\n\nfrom ._convert import convert\nfrom ._signatures import BuiltinFunctionT, process_inputs\n\nSHA256_ADDRESS = 2\nSHA256_BASE_GAS = 60\nSHA256_PER_WORD_GAS = 12\n\n\nclass FoldedFunctionT(BuiltinFunctionT):\n    # Base class for nodes which should always be folded\n\n    _modifiability = Modifiability.CONSTANT\n\n\nclass TypenameFoldedFunctionT(FoldedFunctionT):\n    # Base class for builtin functions that:\n    # (1) take a typename as the only argument; and\n    # (2) should always be folded.\n\n    # \"TYPE_DEFINITION\" is a placeholder value for a type definition string, and\n    # will be replaced by a `TypeTypeDefinition` object in `infer_arg_types`.\n    _inputs = [(\"typename\", \"TYPE_DEFINITION\")]\n\n    def fetch_call_return(self, node):\n        type_ = self.infer_arg_types(node)[0].typedef\n        return type_\n\n    def infer_arg_types(self, node, expected_return_typ=None):\n        validate_call_args(node, 1)\n        input_typedef = TYPE_T(type_from_annotation(node.args[0]))\n        return [input_typedef]\n\n\nclass Floor(BuiltinFunctionT):\n    _id = \"floor\"\n    _inputs = [(\"value\", DecimalT())]\n    # TODO: maybe use int136?\n    _return_type = INT256_T\n\n    def _try_fold(self, node):\n        validate_call_args(node, 1)\n        value = node.args[0].get_folded_value()\n        if not isinstance(value, vy_ast.Decimal):\n            raise UnfoldableNode\n\n        value = math.floor(value.value)\n        return vy_ast.Int.from_node(node, value=value)\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        arg = args[0]\n        with arg.cache_when_complex(\"arg\") as (b1, arg):\n            ret = IRnode.from_list(\n                [\n                    \"if\",\n                    [\"slt\", arg, 0],\n                    [\"sdiv\", [\"sub\", arg, DECIMAL_DIVISOR - 1], DECIMAL_DIVISOR],\n                    [\"sdiv\", arg, DECIMAL_DIVISOR],\n                ],\n                typ=INT256_T,\n            )\n            return b1.resolve(ret)\n\n\nclass Ceil(BuiltinFunctionT):\n    _id = \"ceil\"\n    _inputs = [(\"value\", DecimalT())]\n    # TODO: maybe use int136?\n    _return_type = INT256_T\n\n    def _try_fold(self, node):\n        validate_call_args(node, 1)\n        value = node.args[0].get_folded_value()\n        if not isinstance(value, vy_ast.Decimal):\n            raise UnfoldableNode\n\n        value = math.ceil(value.value)\n        return vy_ast.Int.from_node(node, value=value)\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        arg = args[0]\n        with arg.cache_when_complex(\"arg\") as (b1, arg):\n            ret = IRnode.from_list(\n                [\n                    \"if\",\n                    [\"slt\", arg, 0],\n                    [\"sdiv\", arg, DECIMAL_DIVISOR],\n                    [\"sdiv\", [\"add\", arg, DECIMAL_DIVISOR - 1], DECIMAL_DIVISOR],\n                ],\n                typ=INT256_T,\n            )\n            return b1.resolve(ret)\n\n\nclass Convert(BuiltinFunctionT):\n    _id = \"convert\"\n\n    def fetch_call_return(self, node):\n        _, target_typedef = self.infer_arg_types(node)\n\n        # note: more type conversion validation happens in convert.py\n        return target_typedef.typedef\n\n    # TODO: push this down into convert.py for more consistency\n    def infer_arg_types(self, node, expected_return_typ=None):\n        validate_call_args(node, 2)\n\n        target_type = type_from_annotation(node.args[1])\n        value_types = get_possible_types_from_node(node.args[0])\n\n        # For `convert` of integer literals, we need to match type inference rules in\n        # convert.py codegen routines.\n        # TODO: This can probably be removed once constant folding for `convert` is implemented\n        if len(value_types) > 1 and all(isinstance(v, IntegerT) for v in value_types):\n            # Get the smallest (and unsigned if available) type for non-integer target types\n            # (note this is different from the ordering returned by `get_possible_types_from_node`)\n            if not isinstance(target_type, IntegerT):\n                value_types = sorted(value_types, key=lambda v: (v.is_signed, v.bits), reverse=True)\n            else:\n                # filter out the target type from list of possible types\n                value_types = [i for i in value_types if not target_type.compare_type(i)]\n\n        value_type = value_types.pop()\n\n        # block conversions between same type\n        if target_type.compare_type(value_type):\n            raise InvalidType(f\"Value and target type are both '{target_type}'\", node)\n\n        return [value_type, TYPE_T(target_type)]\n\n    def build_IR(self, expr, context):\n        return convert(expr, context)\n\n\nADHOC_SLICE_NODE_MACROS = [\"~calldata\", \"~selfcode\", \"~extcode\"]\n\n\ndef _build_adhoc_slice_node(sub: IRnode, start: IRnode, length: IRnode, context: Context) -> IRnode:\n    assert length.is_literal, \"typechecker failed\"\n    assert isinstance(length.value, int)  # mypy hint\n\n    dst_typ = BytesT(length.value)\n    # allocate a buffer for the return value\n    np = context.new_internal_variable(dst_typ)\n\n    # `msg.data` by `calldatacopy`\n    if sub.value == \"~calldata\":\n        node = [\n            \"seq\",\n            [\"assert\", [\"le\", [\"add\", start, length], \"calldatasize\"]],  # runtime bounds check\n            [\"mstore\", np, length],\n            [\"calldatacopy\", np + 32, start, length],\n            np,\n        ]\n\n    # `self.code` by `codecopy`\n    elif sub.value == \"~selfcode\":\n        node = [\n            \"seq\",\n            [\"assert\", [\"le\", [\"add\", start, length], \"codesize\"]],  # runtime bounds check\n            [\"mstore\", np, length],\n            [\"codecopy\", np + 32, start, length],\n            np,\n        ]\n\n    # `<address>.code` by `extcodecopy`\n    else:\n        assert sub.value == \"~extcode\" and len(sub.args) == 1\n        node = [\n            \"with\",\n            \"_extcode_address\",\n            sub.args[0],\n            [\n                \"seq\",\n                # runtime bounds check\n                [\"assert\", [\"le\", [\"add\", start, length], [\"extcodesize\", \"_extcode_address\"]]],\n                [\"mstore\", np, length],\n                [\"extcodecopy\", \"_extcode_address\", np + 32, start, length],\n                np,\n            ],\n        ]\n\n    assert isinstance(length.value, int)  # mypy hint\n    return IRnode.from_list(node, typ=BytesT(length.value), location=MEMORY)\n\n\n# note: this and a lot of other builtins could be refactored to accept any uint type\nclass Slice(BuiltinFunctionT):\n    _id = \"slice\"\n    _inputs = [\n        (\"b\", (BYTES32_T, BytesT.any(), StringT.any())),\n        (\"start\", UINT256_T),\n        (\"length\", UINT256_T),\n    ]\n\n    def fetch_call_return(self, node):\n        arg_type, _, _ = self.infer_arg_types(node)\n\n        if isinstance(arg_type, StringT):\n            return_type = StringT()\n        else:\n            return_type = BytesT()\n\n        # validate start and length are in bounds\n\n        arg = node.args[0]\n        start_expr = node.args[1]\n        length_expr = node.args[2]\n\n        # CMC 2022-03-22 NOTE slight code duplication with semantics/analysis/local\n        is_adhoc_slice = arg.get(\"attr\") == \"code\" or (\n            arg.get(\"value.id\") == \"msg\" and arg.get(\"attr\") == \"data\"\n        )\n\n        start_literal = start_expr.value if isinstance(start_expr, vy_ast.Int) else None\n        length_literal = length_expr.value if isinstance(length_expr, vy_ast.Int) else None\n\n        if not is_adhoc_slice:\n            if length_literal is not None:\n                if length_literal < 1:\n                    raise ArgumentException(\"Length cannot be less than 1\", length_expr)\n\n                if length_literal > arg_type.length:\n                    raise ArgumentException(f\"slice out of bounds for {arg_type}\", length_expr)\n\n            if start_literal is not None:\n                if start_literal > arg_type.length:\n                    raise ArgumentException(f\"slice out of bounds for {arg_type}\", start_expr)\n                if length_literal is not None and start_literal + length_literal > arg_type.length:\n                    raise ArgumentException(f\"slice out of bounds for {arg_type}\", node)\n\n        # we know the length statically\n        if length_literal is not None:\n            return_type.set_length(length_literal)\n        else:\n            return_type.set_min_length(arg_type.length)\n\n        return return_type\n\n    def infer_arg_types(self, node, expected_return_typ=None):\n        self._validate_arg_types(node)\n        # return a concrete type for `b`\n        b_type = get_possible_types_from_node(node.args[0]).pop()\n        return [b_type, self._inputs[1][1], self._inputs[2][1]]\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        src, start, length = args\n\n        # Handle `msg.data`, `self.code`, and `<address>.code`\n        if src.value in ADHOC_SLICE_NODE_MACROS:\n            return _build_adhoc_slice_node(src, start, length, context)\n\n        is_bytes32 = src.typ == BYTES32_T\n        if src.location is None:\n            # it's not a pointer; force it to be one since\n            # copy_bytes works on pointers.\n            assert is_bytes32, src\n            src = ensure_in_memory(src, context)\n\n        with src.cache_when_complex(\"src\") as (b1, src), start.cache_when_complex(\"start\") as (\n            b2,\n            start,\n        ), length.cache_when_complex(\"length\") as (b3, length):\n            if is_bytes32:\n                src_maxlen = 32\n            else:\n                src_maxlen = src.typ.maxlen\n\n            dst_maxlen = length.value if length.is_literal else src_maxlen\n\n            buflen = dst_maxlen\n\n            # add 32 bytes to the buffer size bc word access might\n            # be unaligned (see below)\n            if src.location == STORAGE:\n                buflen += 32\n\n            # Get returntype string or bytes\n            assert isinstance(src.typ, _BytestringT) or is_bytes32\n            # TODO: try to get dst_typ from semantic analysis\n            if isinstance(src.typ, StringT):\n                dst_typ = StringT(dst_maxlen)\n            else:\n                dst_typ = BytesT(dst_maxlen)\n\n            # allocate a buffer for the return value\n            buf = context.new_internal_variable(BytesT(buflen))\n            # assign it the correct return type.\n            # (note mismatch between dst_maxlen and buflen)\n            dst = IRnode.from_list(buf, typ=dst_typ, location=MEMORY)\n\n            dst_data = bytes_data_ptr(dst)\n\n            if is_bytes32:\n                src_len = 32\n                src_data = src\n            else:\n                src_len = get_bytearray_length(src)\n                src_data = bytes_data_ptr(src)\n\n            # general case. byte-for-byte copy\n            if src.location == STORAGE:\n                # because slice uses byte-addressing but storage\n                # is word-aligned, this algorithm starts at some number\n                # of bytes before the data section starts, and might copy\n                # an extra word. the pseudocode is:\n                #   dst_data = dst + 32\n                #   copy_dst = dst_data - start % 32\n                #   src_data = src + 32\n                #   copy_src = src_data + (start - start % 32) / 32\n                #            = src_data + (start // 32)\n                #   copy_bytes(copy_dst, copy_src, length)\n                #   //set length AFTER copy because the length word has been clobbered!\n                #   mstore(src, length)\n\n                # start at the first word-aligned address before `start`\n                # e.g. start == byte 7 -> we start copying from byte 0\n                #      start == byte 32 -> we start copying from byte 32\n                copy_src = IRnode.from_list(\n                    [\"add\", src_data, [\"div\", start, 32]], location=src.location\n                )\n\n                # e.g. start == byte 0 -> we copy to dst_data + 0\n                #      start == byte 7 -> we copy to dst_data - 7\n                #      start == byte 33 -> we copy to dst_data - 1\n                copy_dst = IRnode.from_list(\n                    [\"sub\", dst_data, [\"mod\", start, 32]], location=dst.location\n                )\n\n                # len + (32 if start % 32 > 0 else 0)\n                copy_len = [\"add\", length, [\"mul\", 32, [\"iszero\", [\"iszero\", [\"mod\", start, 32]]]]]\n                copy_maxlen = buflen\n\n            else:\n                # all other address spaces (mem, calldata, code) we have\n                # byte-aligned access so we can just do the easy thing,\n                # memcopy(dst_data, src_data + dst_data)\n\n                copy_src = add_ofst(src_data, start)\n                copy_dst = dst_data\n                copy_len = length\n                copy_maxlen = buflen\n\n            do_copy = copy_bytes(copy_dst, copy_src, copy_len, copy_maxlen)\n\n            ret = [\n                \"seq\",\n                # make sure we don't overrun the source buffer\n                [\"assert\", [\"le\", [\"add\", start, length], src_len]],  # bounds check\n                do_copy,\n                [\"mstore\", dst, length],  # set length\n                dst,  # return pointer to dst\n            ]\n            ret = IRnode.from_list(ret, typ=dst_typ, location=MEMORY)\n            return b1.resolve(b2.resolve(b3.resolve(ret)))\n\n\nclass Len(BuiltinFunctionT):\n    _id = \"len\"\n    _inputs = [(\"b\", (StringT.any(), BytesT.any(), DArrayT.any()))]\n    _return_type = UINT256_T\n\n    def _try_fold(self, node):\n        validate_call_args(node, 1)\n        arg = node.args[0].get_folded_value()\n        if isinstance(arg, (vy_ast.Str, vy_ast.Bytes)):\n            length = len(arg.value)\n        elif isinstance(arg, vy_ast.Hex):\n            length = len(arg.bytes_value)\n        else:\n            raise UnfoldableNode\n\n        return vy_ast.Int.from_node(node, value=length)\n\n    def infer_arg_types(self, node, expected_return_typ=None):\n        self._validate_arg_types(node)\n        # return a concrete type\n        typ = get_possible_types_from_node(node.args[0]).pop()\n        return [typ]\n\n    def build_IR(self, node, context):\n        arg = Expr(node.args[0], context).ir_node\n        if arg.value == \"~calldata\":\n            return IRnode.from_list([\"calldatasize\"], typ=UINT256_T)\n        return get_bytearray_length(arg)\n\n\nclass Concat(BuiltinFunctionT):\n    _id = \"concat\"\n\n    def fetch_call_return(self, node):\n        arg_types = self.infer_arg_types(node)\n\n        length = 0\n        for arg_t in arg_types:\n            length += arg_t.length\n\n        if isinstance(arg_types[0], (StringT)):\n            return_type = StringT()\n        else:\n            return_type = BytesT()\n        return_type.set_length(length)\n        return return_type\n\n    def infer_arg_types(self, node, expected_return_typ=None):\n        if len(node.args) < 2:\n            raise ArgumentException(\"Invalid argument count: expected at least 2\", node)\n\n        if node.keywords:\n            raise ArgumentException(\"Keyword arguments are not accepted here\", node.keywords[0])\n\n        ret = []\n        prev_typeclass = None\n        for arg in node.args:\n            validate_expected_type(arg, (BytesT.any(), StringT.any(), BytesM_T.any()))\n            arg_t = get_possible_types_from_node(arg).pop()\n            current_typeclass = \"String\" if isinstance(arg_t, StringT) else \"Bytes\"\n            if prev_typeclass and current_typeclass != prev_typeclass:\n                raise TypeMismatch(\n                    (\n                        \"Concat expects consistent use of string or bytes types, \"\n                        \"use either string or bytes.\"\n                    ),\n                    arg,\n                )\n            prev_typeclass = current_typeclass\n            ret.append(arg_t)\n\n        return ret\n\n    def build_IR(self, expr, context):\n        args = [Expr(arg, context).ir_node for arg in expr.args]\n        if len(args) < 2:\n            raise StructureException(\"Concat expects at least two arguments\", expr)\n\n        # Maximum length of the output\n        dst_maxlen = sum(\n            [arg.typ.maxlen if isinstance(arg.typ, _BytestringT) else arg.typ.m for arg in args]\n        )\n\n        # TODO: try to grab these from semantic analysis\n        if isinstance(args[0].typ, StringT):\n            ret_typ = StringT(dst_maxlen)\n        else:\n            ret_typ = BytesT(dst_maxlen)\n\n        # Node representing the position of the output in memory\n        dst = IRnode.from_list(\n            context.new_internal_variable(ret_typ),\n            typ=ret_typ,\n            location=MEMORY,\n            annotation=\"concat destination\",\n        )\n\n        ret = [\"seq\"]\n        # stack item representing our current offset in the dst buffer\n        ofst = \"concat_ofst\"\n\n        # TODO: optimize for the case where all lengths are statically known.\n        for arg in args:\n            dst_data = add_ofst(bytes_data_ptr(dst), ofst)\n\n            if isinstance(arg.typ, _BytestringT):\n                # Ignore empty strings\n                if arg.typ.maxlen == 0:\n                    continue\n\n                with arg.cache_when_complex(\"arg\") as (b1, arg):\n                    argdata = bytes_data_ptr(arg)\n\n                    with get_bytearray_length(arg).cache_when_complex(\"len\") as (b2, arglen):\n                        do_copy = [\n                            \"seq\",\n                            copy_bytes(dst_data, argdata, arglen, arg.typ.maxlen),\n                            [\"set\", ofst, [\"add\", ofst, arglen]],\n                        ]\n                        ret.append(b1.resolve(b2.resolve(do_copy)))\n\n            else:\n                ret.append(STORE(dst_data, unwrap_location(arg)))\n                ret.append([\"set\", ofst, [\"add\", ofst, arg.typ.m]])\n\n        ret.append(STORE(dst, ofst))\n\n        # Memory location of the output\n        ret.append(dst)\n\n        return IRnode.from_list(\n            [\"with\", ofst, 0, ret], typ=ret_typ, location=MEMORY, annotation=\"concat\"\n        )\n\n\nclass Keccak256(BuiltinFunctionT):\n    _id = \"keccak256\"\n    # TODO allow any BytesM_T\n    _inputs = [(\"value\", (BytesT.any(), BYTES32_T, StringT.any()))]\n    _return_type = BYTES32_T\n\n    def _try_fold(self, node):\n        validate_call_args(node, 1)\n        value = node.args[0].get_folded_value()\n        if isinstance(value, vy_ast.Bytes):\n            value = value.value\n        elif isinstance(value, vy_ast.Str):\n            value = value.value.encode()\n        elif isinstance(value, vy_ast.Hex):\n            value = value.bytes_value\n        else:\n            raise UnfoldableNode\n\n        hash_ = f\"0x{keccak256(value).hex()}\"\n        return vy_ast.Hex.from_node(node, value=hash_)\n\n    def infer_arg_types(self, node, expected_return_typ=None):\n        self._validate_arg_types(node)\n        # return a concrete type for `value`\n        value_type = get_possible_types_from_node(node.args[0]).pop()\n        return [value_type]\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        assert len(args) == 1\n        return keccak256_helper(args[0], context)\n\n\ndef _make_sha256_call(inp_start, inp_len, out_start, out_len):\n    return [\n        \"assert\",\n        [\n            \"staticcall\",\n            [\"gas\"],  # gas\n            SHA256_ADDRESS,  # address\n            inp_start,\n            inp_len,\n            out_start,\n            out_len,\n        ],\n    ]\n\n\nclass Sha256(BuiltinFunctionT):\n    _id = \"sha256\"\n    _inputs = [(\"value\", (BYTES32_T, BytesT.any(), StringT.any()))]\n    _return_type = BYTES32_T\n\n    def _try_fold(self, node):\n        validate_call_args(node, 1)\n        value = node.args[0].get_folded_value()\n        if isinstance(value, vy_ast.Bytes):\n            value = value.value\n        elif isinstance(value, vy_ast.Str):\n            value = value.value.encode()\n        elif isinstance(value, vy_ast.Hex):\n            value = value.bytes_value\n        else:\n            raise UnfoldableNode\n\n        hash_ = f\"0x{hashlib.sha256(value).hexdigest()}\"\n        return vy_ast.Hex.from_node(node, value=hash_)\n\n    def infer_arg_types(self, node, expected_return_typ=None):\n        self._validate_arg_types(node)\n        # return a concrete type for `value`\n        value_type = get_possible_types_from_node(node.args[0]).pop()\n        return [value_type]\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        sub = args[0]\n        # bytes32 input\n        if sub.typ == BYTES32_T:\n            return IRnode.from_list(\n                [\n                    \"seq\",\n                    [\"mstore\", MemoryPositions.FREE_VAR_SPACE, sub],\n                    _make_sha256_call(\n                        inp_start=MemoryPositions.FREE_VAR_SPACE,\n                        inp_len=32,\n                        out_start=MemoryPositions.FREE_VAR_SPACE,\n                        out_len=32,\n                    ),\n                    [\"mload\", MemoryPositions.FREE_VAR_SPACE],  # push value onto stack\n                ],\n                typ=BYTES32_T,\n                add_gas_estimate=SHA256_BASE_GAS + 1 * SHA256_PER_WORD_GAS,\n            )\n        # bytearay-like input\n        # special case if it's already in memory\n        sub = ensure_in_memory(sub, context)\n\n        return IRnode.from_list(\n            [\n                \"with\",\n                \"_sub\",\n                sub,\n                [\n                    \"seq\",\n                    _make_sha256_call(\n                        # TODO use add_ofst if sub is statically known\n                        inp_start=[\"add\", \"_sub\", 32],\n                        inp_len=[\"mload\", \"_sub\"],\n                        out_start=MemoryPositions.FREE_VAR_SPACE,\n                        out_len=32,\n                    ),\n                    [\"mload\", MemoryPositions.FREE_VAR_SPACE],\n                ],\n            ],\n            typ=BYTES32_T,\n            add_gas_estimate=SHA256_BASE_GAS + sub.typ.maxlen * SHA256_PER_WORD_GAS,\n        )\n\n\nclass MethodID(FoldedFunctionT):\n    _id = \"method_id\"\n    _inputs = [(\"value\", StringT.any())]\n    _kwargs = {\"output_type\": KwargSettings(\"TYPE_DEFINITION\", BytesT(4))}\n\n    def _try_fold(self, node):\n        validate_call_args(node, 1, [\"output_type\"])\n\n        value = node.args[0].get_folded_value()\n        if not isinstance(value, vy_ast.Str):\n            raise InvalidType(\"method id must be given as a literal string\", node.args[0])\n        if \" \" in value.value:\n            raise InvalidLiteral(\"Invalid function signature - no spaces allowed.\", node.args[0])\n\n        return_type = self.infer_kwarg_types(node)[\"output_type\"].typedef\n        value = method_id(value.value)\n\n        if return_type.compare_type(BYTES4_T):\n            return vy_ast.Hex.from_node(node, value=\"0x\" + value.hex())\n        else:\n            return vy_ast.Bytes.from_node(node, value=value)\n\n    def fetch_call_return(self, node):\n        validate_call_args(node, 1, [\"output_type\"])\n\n        type_ = self.infer_kwarg_types(node)[\"output_type\"].typedef\n        return type_\n\n    def infer_arg_types(self, node, expected_return_typ=None):\n        return [self._inputs[0][1]]\n\n    def infer_kwarg_types(self, node):\n        if node.keywords:\n            output_type = type_from_annotation(node.keywords[0].value)\n            if output_type not in (BytesT(4), BYTES4_T):\n                raise ArgumentException(\"output_type must be Bytes[4] or bytes4\", node.keywords[0])\n        else:\n            # default to `Bytes[4]`\n            output_type = BytesT(4)\n\n        return {\"output_type\": TYPE_T(output_type)}\n\n\nclass ECRecover(BuiltinFunctionT):\n    _id = \"ecrecover\"\n    _inputs = [\n        (\"hash\", BYTES32_T),\n        (\"v\", (UINT256_T, UINT8_T)),\n        (\"r\", (UINT256_T, BYTES32_T)),\n        (\"s\", (UINT256_T, BYTES32_T)),\n    ]\n    _return_type = AddressT()\n\n    def infer_arg_types(self, node, expected_return_typ=None):\n        self._validate_arg_types(node)\n        v_t, r_t, s_t = [get_possible_types_from_node(arg).pop() for arg in node.args[1:]]\n        return [BYTES32_T, v_t, r_t, s_t]\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        input_buf = context.new_internal_variable(get_type_for_exact_size(128))\n        output_buf = context.new_internal_variable(get_type_for_exact_size(32))\n        return IRnode.from_list(\n            [\n                \"seq\",\n                # clear output memory first, ecrecover can return 0 bytes\n                [\"mstore\", output_buf, 0],\n                [\"mstore\", input_buf, args[0]],\n                [\"mstore\", input_buf + 32, args[1]],\n                [\"mstore\", input_buf + 64, args[2]],\n                [\"mstore\", input_buf + 96, args[3]],\n                [\"staticcall\", \"gas\", 1, input_buf, 128, output_buf, 32],\n                [\"mload\", output_buf],\n            ],\n            typ=AddressT(),\n        )\n\n\nclass _ECArith(BuiltinFunctionT):\n    @process_inputs\n    def build_IR(self, expr, _args, kwargs, context):\n        args_tuple = ir_tuple_from_args(_args)\n\n        args_t = args_tuple.typ\n        input_buf = IRnode.from_list(\n            context.new_internal_variable(args_t), typ=args_t, location=MEMORY\n        )\n        ret_t = self._return_type\n\n        ret = [\"seq\"]\n        ret.append(make_setter(input_buf, args_tuple))\n\n        output_buf = context.new_internal_variable(ret_t)\n\n        args_ofst = input_buf\n        args_len = args_t.memory_bytes_required\n        out_ofst = output_buf\n        out_len = ret_t.memory_bytes_required\n\n        ret.append(\n            [\n                \"assert\",\n                [\"staticcall\", [\"gas\"], self._precompile, args_ofst, args_len, out_ofst, out_len],\n            ]\n        )\n        ret.append(output_buf)\n\n        return IRnode.from_list(ret, typ=ret_t, location=MEMORY)\n\n\nclass ECAdd(_ECArith):\n    _id = \"ecadd\"\n    _inputs = [(\"a\", SArrayT(UINT256_T, 2)), (\"b\", SArrayT(UINT256_T, 2))]\n    _return_type = SArrayT(UINT256_T, 2)\n    _precompile = 0x6\n\n\nclass ECMul(_ECArith):\n    _id = \"ecmul\"\n    _inputs = [(\"point\", SArrayT(UINT256_T, 2)), (\"scalar\", UINT256_T)]\n    _return_type = SArrayT(UINT256_T, 2)\n    _precompile = 0x7\n\n\ndef _generic_element_getter(op):\n    def f(index):\n        return IRnode.from_list(\n            [op, [\"add\", \"_sub\", [\"add\", 32, [\"mul\", 32, index]]]], typ=INT128_T\n        )\n\n    return f\n\n\ndef _storage_element_getter(index):\n    return IRnode.from_list([\"sload\", [\"add\", \"_sub\", [\"add\", 1, index]]], typ=INT128_T)\n\n\nclass Extract32(BuiltinFunctionT):\n    _id = \"extract32\"\n    _inputs = [(\"b\", BytesT.any()), (\"start\", IntegerT.unsigneds())]\n    # \"TYPE_DEFINITION\" is a placeholder value for a type definition string, and\n    # will be replaced by a `TYPE_T` object in `infer_kwarg_types`\n    # (note that it is ignored in _validate_arg_types)\n    _kwargs = {\"output_type\": KwargSettings(\"TYPE_DEFINITION\", BYTES32_T)}\n\n    def fetch_call_return(self, node):\n        self._validate_arg_types(node)\n        return_type = self.infer_kwarg_types(node)[\"output_type\"].typedef\n        return return_type\n\n    def infer_arg_types(self, node, expected_return_typ=None):\n        self._validate_arg_types(node)\n        input_type = get_possible_types_from_node(node.args[0]).pop()\n        return [input_type, UINT256_T]\n\n    def infer_kwarg_types(self, node):\n        if node.keywords:\n            output_type = type_from_annotation(node.keywords[0].value)\n            if not isinstance(output_type, (AddressT, BytesM_T, IntegerT)):\n                raise InvalidType(\n                    \"Output type must be one of integer, bytes32 or address\", node.keywords[0].value\n                )\n            output_typedef = TYPE_T(output_type)\n            node.keywords[0].value._metadata[\"type\"] = output_typedef\n        else:\n            output_typedef = TYPE_T(BYTES32_T)\n\n        return {\"output_type\": output_typedef}\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        sub, index = args\n        ret_type = kwargs[\"output_type\"]\n\n        # Get length and specific element\n        if sub.location == STORAGE:\n            lengetter = IRnode.from_list([\"sload\", \"_sub\"], typ=INT128_T)\n            elementgetter = _storage_element_getter\n\n        else:\n            op = sub.location.load_op\n            lengetter = IRnode.from_list([op, \"_sub\"], typ=INT128_T)\n            elementgetter = _generic_element_getter(op)\n\n        # TODO rewrite all this with cache_when_complex and bitshifts\n\n        # Special case: index known to be a multiple of 32\n        if isinstance(index.value, int) and not index.value % 32:\n            o = IRnode.from_list(\n                [\n                    \"with\",\n                    \"_sub\",\n                    sub,\n                    elementgetter(\n                        [\"div\", clamp2(0, index, [\"sub\", lengetter, 32], signed=True), 32]\n                    ),\n                ],\n                typ=ret_type,\n                annotation=\"extracting 32 bytes\",\n            )\n        # General case\n        else:\n            o = IRnode.from_list(\n                [\n                    \"with\",\n                    \"_sub\",\n                    sub,\n                    [\n                        \"with\",\n                        \"_len\",\n                        lengetter,\n                        [\n                            \"with\",\n                            \"_index\",\n                            clamp2(0, index, [\"sub\", \"_len\", 32], signed=True),\n                            [\n                                \"with\",\n                                \"_mi32\",\n                                [\"mod\", \"_index\", 32],\n                                [\n                                    \"with\",\n                                    \"_di32\",\n                                    [\"div\", \"_index\", 32],\n                                    [\n                                        \"if\",\n                                        \"_mi32\",\n                                        [\n                                            \"add\",\n                                            [\"mul\", elementgetter(\"_di32\"), [\"exp\", 256, \"_mi32\"]],\n                                            [\n                                                \"div\",\n                                                elementgetter([\"add\", \"_di32\", 1]),\n                                                [\"exp\", 256, [\"sub\", 32, \"_mi32\"]],\n                                            ],\n                                        ],\n                                        elementgetter(\"_di32\"),\n                                    ],\n                                ],\n                            ],\n                        ],\n                    ],\n                ],\n                typ=ret_type,\n                annotation=\"extract32\",\n            )\n        return IRnode.from_list(clamp_basetype(o), typ=ret_type)\n\n\nclass AsWeiValue(BuiltinFunctionT):\n    _id = \"as_wei_value\"\n    _inputs = [(\"value\", (IntegerT.any(), DecimalT())), (\"unit\", StringT.any())]\n    _return_type = UINT256_T\n\n    wei_denoms = {\n        (\"wei\",): 1,\n        (\"femtoether\", \"kwei\", \"babbage\"): 10**3,\n        (\"picoether\", \"mwei\", \"lovelace\"): 10**6,\n        (\"nanoether\", \"gwei\", \"shannon\"): 10**9,\n        (\"microether\", \"szabo\"): 10**12,\n        (\"milliether\", \"finney\"): 10**15,\n        (\"ether\",): 10**18,\n        (\"kether\", \"grand\"): 10**21,\n    }\n\n    def get_denomination(self, node):\n        value = node.args[1].get_folded_value()\n        if not isinstance(value, vy_ast.Str):\n            raise ArgumentException(\n                \"Wei denomination must be given as a literal string\", node.args[1]\n            )\n        try:\n            denom = next(v for k, v in self.wei_denoms.items() if value.value in k)\n        except StopIteration:\n            raise ArgumentException(f\"Unknown denomination: {value.value}\", node.args[1]) from None\n\n        return denom\n\n    def _try_fold(self, node):\n        validate_call_args(node, 2)\n        denom = self.get_denomination(node)\n\n        value = node.args[0].get_folded_value()\n        if not isinstance(value, (vy_ast.Decimal, vy_ast.Int)):\n            raise UnfoldableNode\n        value = value.value\n\n        if value < 0:\n            raise InvalidLiteral(\"Negative wei value not allowed\", node.args[0])\n\n        return vy_ast.Int.from_node(node, value=int(value * denom))\n\n    def fetch_call_return(self, node):\n        self.infer_arg_types(node)\n        return self._return_type\n\n    def infer_arg_types(self, node, expected_return_typ=None):\n        self._validate_arg_types(node)\n        # return a concrete type instead of abstract type\n        value_type = get_possible_types_from_node(node.args[0]).pop()\n        unit_type = get_possible_types_from_node(node.args[1]).pop()\n        return [value_type, unit_type]\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        value = args[0]\n\n        denom_divisor = self.get_denomination(expr)\n        with value.cache_when_complex(\"value\") as (b1, value):\n            if value.typ in (UINT256_T, UINT8_T):\n                sub = [\n                    \"with\",\n                    \"ans\",\n                    [\"mul\", value, denom_divisor],\n                    [\n                        \"seq\",\n                        [\n                            \"assert\",\n                            [\"or\", [\"eq\", [\"div\", \"ans\", value], denom_divisor], [\"iszero\", value]],\n                        ],\n                        \"ans\",\n                    ],\n                ]\n            elif value.typ == INT128_T:\n                # signed types do not require bounds checks because the\n                # largest possible converted value will not overflow 2**256\n                sub = [\"seq\", [\"assert\", [\"sgt\", value, -1]], [\"mul\", value, denom_divisor]]\n            elif value.typ == DecimalT():\n                sub = [\n                    \"seq\",\n                    [\"assert\", [\"sgt\", value, -1]],\n                    [\"div\", [\"mul\", value, denom_divisor], DECIMAL_DIVISOR],\n                ]\n            else:\n                raise CompilerPanic(f\"Unexpected type: {value.typ}\")\n\n            return IRnode.from_list(b1.resolve(sub), typ=UINT256_T)\n\n\nzero_value = IRnode.from_list(0, typ=UINT256_T)\nempty_value = IRnode.from_list(0, typ=BYTES32_T)\n\n\nclass RawCall(BuiltinFunctionT):\n    _id = \"raw_call\"\n    _inputs = [(\"to\", AddressT()), (\"data\", BytesT.any())]\n    _kwargs = {\n        \"max_outsize\": KwargSettings(UINT256_T, 0, require_literal=True),\n        \"gas\": KwargSettings(UINT256_T, \"gas\"),\n        \"value\": KwargSettings(UINT256_T, zero_value),\n        \"is_delegate_call\": KwargSettings(BoolT(), False, require_literal=True),\n        \"is_static_call\": KwargSettings(BoolT(), False, require_literal=True),\n        \"revert_on_failure\": KwargSettings(BoolT(), True, require_literal=True),\n    }\n\n    def fetch_call_return(self, node):\n        self._validate_arg_types(node)\n\n        kwargz = {i.arg: i.value for i in node.keywords}\n\n        outsize = kwargz.get(\"max_outsize\")\n        if outsize is not None:\n            outsize = outsize.get_folded_value()\n\n        revert_on_failure = kwargz.get(\"revert_on_failure\")\n        if revert_on_failure is not None:\n            revert_on_failure = revert_on_failure.get_folded_value().value\n        else:\n            revert_on_failure = True\n\n        if outsize is None or outsize.value == 0:\n            if revert_on_failure:\n                return None\n            return BoolT()\n\n        if not isinstance(outsize, vy_ast.Int) or outsize.value < 0:\n            raise\n\n        if outsize.value:\n            return_type = BytesT()\n            return_type.set_min_length(outsize.value)\n\n            if revert_on_failure:\n                return return_type\n            return TupleT([BoolT(), return_type])\n\n    def infer_arg_types(self, node, expected_return_typ=None):\n        self._validate_arg_types(node)\n        # return a concrete type for `data`\n        data_type = get_possible_types_from_node(node.args[1]).pop()\n        return [self._inputs[0][1], data_type]\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        to, data = args\n        # TODO: must compile in source code order, left-to-right\n        gas, value, outsize, delegate_call, static_call, revert_on_failure = (\n            kwargs[\"gas\"],\n            kwargs[\"value\"],\n            kwargs[\"max_outsize\"],\n            kwargs[\"is_delegate_call\"],\n            kwargs[\"is_static_call\"],\n            kwargs[\"revert_on_failure\"],\n        )\n\n        if delegate_call and static_call:\n            raise ArgumentException(\n                \"Call may use one of `is_delegate_call` or `is_static_call`, not both\", expr\n            )\n        if not static_call and context.is_constant():\n            raise StateAccessViolation(\n                f\"Cannot make modifying calls from {context.pp_constancy()},\"\n                \" use `is_static_call=True` to perform this action\",\n                expr,\n            )\n\n        if data.value == \"~calldata\":\n            call_ir = [\"with\", \"mem_ofst\", \"msize\"]\n            args_ofst = [\"seq\", [\"calldatacopy\", \"mem_ofst\", 0, \"calldatasize\"], \"mem_ofst\"]\n            args_len = \"calldatasize\"\n        else:\n            # some gymnastics to propagate constants (if eval_input_buf\n            # returns a static memory location)\n            eval_input_buf = ensure_in_memory(data, context)\n\n            input_buf = eval_seq(eval_input_buf)\n\n            if input_buf is None:\n                call_ir = [\"with\", \"arg_buf\", eval_input_buf]\n                input_buf = IRnode.from_list(\"arg_buf\")\n            else:\n                call_ir = [\"seq\", eval_input_buf]\n\n            args_ofst = add_ofst(input_buf, 32)\n            args_len = [\"mload\", input_buf]\n\n        output_node = IRnode.from_list(\n            context.new_internal_variable(BytesT(outsize)), typ=BytesT(outsize), location=MEMORY\n        )\n\n        bool_ty = BoolT()\n\n        # build IR for call or delegatecall\n        common_call_args = [\n            args_ofst,\n            args_len,\n            # if there is no return value, the return offset can be 0\n            add_ofst(output_node, 32) if outsize else 0,\n            outsize,\n        ]\n\n        gas, value = IRnode.from_list(gas), IRnode.from_list(value)\n        with scope_multi((to, value, gas), (\"_to\", \"_value\", \"_gas\")) as (b1, (to, value, gas)):\n            if delegate_call:\n                call_op = [\"delegatecall\", gas, to, *common_call_args]\n            elif static_call:\n                call_op = [\"staticcall\", gas, to, *common_call_args]\n            else:\n                call_op = [\"call\", gas, to, value, *common_call_args]\n\n            call_ir += [call_op]\n            call_ir = b1.resolve(call_ir)\n\n        # build sequence IR\n        if outsize:\n            # return minimum of outsize and returndatasize\n            size = [\"select\", [\"lt\", outsize, \"returndatasize\"], outsize, \"returndatasize\"]\n\n            # store output size and return output location\n            store_output_size = [\"seq\", [\"mstore\", output_node, size], output_node]\n\n            bytes_ty = BytesT(outsize)\n\n            if revert_on_failure:\n                typ = bytes_ty\n                # check the call success flag, and store returndata in memory\n                ret_ir = [\"seq\", check_external_call(call_ir), store_output_size]\n                return IRnode.from_list(ret_ir, typ=typ, location=MEMORY)\n            else:\n                typ = TupleT([bool_ty, bytes_ty])\n                ret_ir = [\n                    \"multi\",\n                    # use IRnode.from_list to make sure the types are\n                    # set properly on the \"multi\" members\n                    IRnode.from_list(call_ir, typ=bool_ty),\n                    IRnode.from_list(store_output_size, typ=bytes_ty, location=MEMORY),\n                ]\n                # return an IR tuple of call success flag and returndata pointer\n                return IRnode.from_list(ret_ir, typ=typ)\n\n        # max_outsize is 0.\n\n        if not revert_on_failure:\n            # return call flag as stack item\n            typ = bool_ty\n            return IRnode.from_list(call_ir, typ=typ)\n\n        else:\n            # check the call success flag and don't return anything\n            ret_ir = check_external_call(call_ir)\n            return IRnode.from_list(ret_ir, typ=None)\n\n        raise CompilerPanic(\"unreachable!\")\n\n\nclass Send(BuiltinFunctionT):\n    _id = \"send\"\n    _inputs = [(\"to\", AddressT()), (\"value\", UINT256_T)]\n    # default gas stipend is 0\n    _kwargs = {\"gas\": KwargSettings(UINT256_T, 0)}\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        to, value = args\n        gas = kwargs[\"gas\"]\n        context.check_is_not_constant(\"send ether\", expr)\n        return IRnode.from_list(\n            [\"assert\", [\"call\", gas, to, value, 0, 0, 0, 0]], error_msg=\"send failed\"\n        )\n\n\nclass SelfDestruct(BuiltinFunctionT):\n    _id = \"selfdestruct\"\n    _inputs = [(\"to\", AddressT())]\n    _is_terminus = True\n    _warned = False\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        if not self._warned:\n            vyper_warn(\"`selfdestruct` is deprecated! The opcode is no longer recommended for use.\")\n            self._warned = True\n\n        context.check_is_not_constant(\"selfdestruct\", expr)\n        return IRnode.from_list(\n            [\"seq\", eval_once_check(_freshname(\"selfdestruct\")), [\"selfdestruct\", args[0]]]\n        )\n\n\nclass BlockHash(BuiltinFunctionT):\n    _id = \"blockhash\"\n    _inputs = [(\"block_num\", UINT256_T)]\n    _return_type = BYTES32_T\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, contact):\n        return IRnode.from_list(\n            [\"blockhash\", clamp(\"lt\", clamp(\"sge\", args[0], [\"sub\", [\"number\"], 256]), \"number\")],\n            typ=BYTES32_T,\n        )\n\n\nclass RawRevert(BuiltinFunctionT):\n    _id = \"raw_revert\"\n    _inputs = [(\"data\", BytesT.any())]\n    _return_type = None\n    _is_terminus = True\n\n    def fetch_call_return(self, node):\n        return None\n\n    def infer_arg_types(self, node, expected_return_typ=None):\n        self._validate_arg_types(node)\n        data_type = get_possible_types_from_node(node.args[0]).pop()\n        return [data_type]\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        with ensure_in_memory(args[0], context).cache_when_complex(\"err_buf\") as (b, buf):\n            data = bytes_data_ptr(buf)\n            len_ = get_bytearray_length(buf)\n            return b.resolve(IRnode.from_list([\"revert\", data, len_]))\n\n\nclass RawLog(BuiltinFunctionT):\n    _id = \"raw_log\"\n    _inputs = [(\"topics\", DArrayT(BYTES32_T, 4)), (\"data\", (BYTES32_T, BytesT.any()))]\n\n    def fetch_call_return(self, node):\n        self.infer_arg_types(node)\n\n    def infer_arg_types(self, node, expected_return_typ=None):\n        self._validate_arg_types(node)\n\n        if not isinstance(node.args[0], vy_ast.List) or len(node.args[0].elements) > 4:\n            raise InvalidType(\"Expecting a list of 0-4 topics as first argument\", node.args[0])\n\n        # return a concrete type for `data`\n        data_type = get_possible_types_from_node(node.args[1]).pop()\n\n        return [self._inputs[0][1], data_type]\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        topics_length = len(expr.args[0].elements)\n        topics = args[0].args\n\n        # sanity check topics is a literal list\n        assert args[0].value in (\"~empty\", \"multi\")\n\n        data = args[1]\n\n        if data.typ == BYTES32_T:\n            placeholder = context.new_internal_variable(BYTES32_T)\n            return IRnode.from_list(\n                [\n                    \"seq\",\n                    # TODO use make_setter\n                    [\"mstore\", placeholder, unwrap_location(data)],\n                    [\"log\" + str(topics_length), placeholder, 32] + topics,\n                ]\n            )\n\n        input_buf = ensure_in_memory(data, context)\n\n        return IRnode.from_list(\n            [\n                \"with\",\n                \"_sub\",\n                input_buf,\n                [\"log\" + str(topics_length), [\"add\", \"_sub\", 32], [\"mload\", \"_sub\"], *topics],\n            ]\n        )\n\n\nclass BitwiseAnd(BuiltinFunctionT):\n    _id = \"bitwise_and\"\n    _inputs = [(\"x\", UINT256_T), (\"y\", UINT256_T)]\n    _return_type = UINT256_T\n    _warned = False\n\n    def _try_fold(self, node):\n        if not self.__class__._warned:\n            vyper_warn(\"`bitwise_and()` is deprecated! Please use the & operator instead.\")\n            self.__class__._warned = True\n\n        validate_call_args(node, 2)\n        values = [i.get_folded_value() for i in node.args]\n        for val in values:\n            if not isinstance(val, vy_ast.Int):\n                raise UnfoldableNode\n\n        value = values[0].value & values[1].value\n        return vy_ast.Int.from_node(node, value=value)\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        return IRnode.from_list([\"and\", args[0], args[1]], typ=UINT256_T)\n\n\nclass BitwiseOr(BuiltinFunctionT):\n    _id = \"bitwise_or\"\n    _inputs = [(\"x\", UINT256_T), (\"y\", UINT256_T)]\n    _return_type = UINT256_T\n    _warned = False\n\n    def _try_fold(self, node):\n        if not self.__class__._warned:\n            vyper_warn(\"`bitwise_or()` is deprecated! Please use the | operator instead.\")\n            self.__class__._warned = True\n\n        validate_call_args(node, 2)\n        values = [i.get_folded_value() for i in node.args]\n        for val in values:\n            if not isinstance(val, vy_ast.Int):\n                raise UnfoldableNode\n\n        value = values[0].value | values[1].value\n        return vy_ast.Int.from_node(node, value=value)\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        return IRnode.from_list([\"or\", args[0], args[1]], typ=UINT256_T)\n\n\nclass BitwiseXor(BuiltinFunctionT):\n    _id = \"bitwise_xor\"\n    _inputs = [(\"x\", UINT256_T), (\"y\", UINT256_T)]\n    _return_type = UINT256_T\n    _warned = False\n\n    def _try_fold(self, node):\n        if not self.__class__._warned:\n            vyper_warn(\"`bitwise_xor()` is deprecated! Please use the ^ operator instead.\")\n            self.__class__._warned = True\n\n        validate_call_args(node, 2)\n        values = [i.get_folded_value() for i in node.args]\n        for val in values:\n            if not isinstance(val, vy_ast.Int):\n                raise UnfoldableNode\n\n        value = values[0].value ^ values[1].value\n        return vy_ast.Int.from_node(node, value=value)\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        return IRnode.from_list([\"xor\", args[0], args[1]], typ=UINT256_T)\n\n\nclass BitwiseNot(BuiltinFunctionT):\n    _id = \"bitwise_not\"\n    _inputs = [(\"x\", UINT256_T)]\n    _return_type = UINT256_T\n    _warned = False\n\n    def _try_fold(self, node):\n        if not self.__class__._warned:\n            vyper_warn(\"`bitwise_not()` is deprecated! Please use the ~ operator instead.\")\n            self.__class__._warned = True\n\n        validate_call_args(node, 1)\n        value = node.args[0].get_folded_value()\n        if not isinstance(value, vy_ast.Int):\n            raise UnfoldableNode\n\n        value = value.value\n\n        value = (2**256 - 1) - value\n        return vy_ast.Int.from_node(node, value=value)\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        return IRnode.from_list([\"not\", args[0]], typ=UINT256_T)\n\n\nclass Shift(BuiltinFunctionT):\n    _id = \"shift\"\n    _inputs = [(\"x\", (UINT256_T, INT256_T)), (\"_shift_bits\", IntegerT.any())]\n    _return_type = UINT256_T\n    _warned = False\n\n    def _try_fold(self, node):\n        if not self.__class__._warned:\n            vyper_warn(\"`shift()` is deprecated! Please use the << or >> operator instead.\")\n            self.__class__._warned = True\n\n        validate_call_args(node, 2)\n        args = [i.get_folded_value() for i in node.args]\n        if any(not isinstance(i, vy_ast.Int) for i in args):\n            raise UnfoldableNode\n        value, shift = [i.value for i in args]\n        if shift < -256 or shift > 256:\n            # this validation is performed to prevent the compiler from hanging\n            # rather than for correctness because the post-folded constant would\n            # have been validated anyway\n            raise InvalidLiteral(\"Shift must be between -256 and 256\", node.args[1])\n\n        if shift < 0:\n            value = value >> -shift\n        else:\n            value = (value << shift) % (2**256)\n        return vy_ast.Int.from_node(node, value=value)\n\n    def fetch_call_return(self, node):\n        # return type is the type of the first argument\n        return self.infer_arg_types(node)[0]\n\n    def infer_arg_types(self, node, expected_return_typ=None):\n        self._validate_arg_types(node)\n        # return a concrete type instead of SignedIntegerAbstractType\n        arg_ty = get_possible_types_from_node(node.args[0])[0]\n        shift_ty = get_possible_types_from_node(node.args[1])[0]\n        return [arg_ty, shift_ty]\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        # \"gshr\" -- generalized right shift\n        argty = args[0].typ\n        GSHR = sar if argty.is_signed else shr\n\n        with args[0].cache_when_complex(\"to_shift\") as (b1, arg), args[1].cache_when_complex(\n            \"bits\"\n        ) as (b2, bits):\n            neg_bits = [\"sub\", 0, bits]\n            ret = [\"if\", [\"slt\", bits, 0], GSHR(neg_bits, arg), shl(bits, arg)]\n            return b1.resolve(b2.resolve(IRnode.from_list(ret, typ=argty)))\n\n\nclass _AddMulMod(BuiltinFunctionT):\n    _inputs = [(\"a\", UINT256_T), (\"b\", UINT256_T), (\"c\", UINT256_T)]\n    _return_type = UINT256_T\n\n    def _try_fold(self, node):\n        validate_call_args(node, 3)\n        args = [i.get_folded_value() for i in node.args]\n        if isinstance(args[2], vy_ast.Int) and args[2].value == 0:\n            raise ZeroDivisionException(\"Modulo by 0\", node.args[2])\n        for arg in args:\n            if not isinstance(arg, vy_ast.Int):\n                raise UnfoldableNode\n\n        value = self._eval_fn(args[0].value, args[1].value) % args[2].value\n        return vy_ast.Int.from_node(node, value=value)\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        x, y, z = args\n        with x.cache_when_complex(\"x\") as (b1, x):\n            with y.cache_when_complex(\"y\") as (b2, y):\n                with z.cache_when_complex(\"z\") as (b3, z):\n                    ret = IRnode.from_list(\n                        [\"seq\", [\"assert\", z], [self._opcode, x, y, z]], typ=UINT256_T\n                    )\n                    return b1.resolve(b2.resolve(b3.resolve(ret)))\n\n\nclass AddMod(_AddMulMod):\n    _id = \"uint256_addmod\"\n    _eval_fn = operator.add\n    _opcode = \"addmod\"\n\n\nclass MulMod(_AddMulMod):\n    _id = \"uint256_mulmod\"\n    _eval_fn = operator.mul\n    _opcode = \"mulmod\"\n\n\nclass PowMod256(BuiltinFunctionT):\n    _id = \"pow_mod256\"\n    _inputs = [(\"a\", UINT256_T), (\"b\", UINT256_T)]\n    _return_type = UINT256_T\n\n    def _try_fold(self, node):\n        validate_call_args(node, 2)\n        values = [i.get_folded_value() for i in node.args]\n        if any(not isinstance(i, vy_ast.Int) for i in values):\n            raise UnfoldableNode\n\n        left, right = values\n        value = pow(left.value, right.value, 2**256)\n        return vy_ast.Int.from_node(node, value=value)\n\n    def build_IR(self, expr, context):\n        left = Expr.parse_value_expr(expr.args[0], context)\n        right = Expr.parse_value_expr(expr.args[1], context)\n        return IRnode.from_list([\"exp\", left, right], typ=left.typ)\n\n\nclass Abs(BuiltinFunctionT):\n    _id = \"abs\"\n    _inputs = [(\"value\", INT256_T)]\n    _return_type = INT256_T\n\n    def _try_fold(self, node):\n        validate_call_args(node, 1)\n        value = node.args[0].get_folded_value()\n        if not isinstance(value, vy_ast.Int):\n            raise UnfoldableNode\n\n        value = abs(value.value)\n        return vy_ast.Int.from_node(node, value=value)\n\n    def build_IR(self, expr, context):\n        value = Expr.parse_value_expr(expr.args[0], context)\n        sub = [\n            \"with\",\n            \"orig\",\n            value,\n            [\n                \"if\",\n                [\"slt\", \"orig\", 0],\n                # clamp orig != -2**255 (because it maps to itself under negation)\n                [\"seq\", [\"assert\", [\"ne\", \"orig\", [\"sub\", 0, \"orig\"]]], [\"sub\", 0, \"orig\"]],\n                \"orig\",\n            ],\n        ]\n        return IRnode.from_list(sub, typ=INT256_T)\n\n\n# CREATE* functions\n\nCREATE2_SENTINEL = dummy_node_for_type(BYTES32_T)\n\n\n# create helper functions\n# generates CREATE op sequence + zero check for result\ndef _create_ir(value, buf, length, salt, checked=True):\n    args = [value, buf, length]\n    create_op = \"create\"\n    if salt is not CREATE2_SENTINEL:\n        create_op = \"create2\"\n        args.append(salt)\n\n    ret = IRnode.from_list(\n        [\"seq\", eval_once_check(_freshname(\"create_builtin\")), [create_op, *args]]\n    )\n\n    if not checked:\n        return ret\n\n    ret = clamp_nonzero(ret)\n    ret.set_error_msg(f\"{create_op} failed\")\n    return ret\n\n\n# calculate the gas used by create for a given number of bytes\ndef _create_addl_gas_estimate(size, should_use_create2):\n    ret = 200 * size\n    if should_use_create2:\n        ret += SHA3_PER_WORD * ceil32(size) // 32\n    return ret\n\n\ndef eip1167_bytecode():\n    # NOTE cyclic import?\n    from vyper.ir.compile_ir import assembly_to_evm\n\n    loader_asm = [\n        \"PUSH1\",\n        0x2D,\n        \"RETURNDATASIZE\",\n        \"DUP2\",\n        \"PUSH1\",\n        0x09,\n        \"RETURNDATASIZE\",\n        \"CODECOPY\",\n        \"RETURN\",\n    ]\n    forwarder_pre_asm = [\n        \"CALLDATASIZE\",\n        \"RETURNDATASIZE\",\n        \"RETURNDATASIZE\",\n        \"CALLDATACOPY\",\n        \"RETURNDATASIZE\",\n        \"RETURNDATASIZE\",\n        \"RETURNDATASIZE\",\n        \"CALLDATASIZE\",\n        \"RETURNDATASIZE\",\n        \"PUSH20\",  # [address to delegate to]\n    ]\n    forwarder_post_asm = [\n        \"GAS\",\n        \"DELEGATECALL\",\n        \"RETURNDATASIZE\",\n        \"DUP3\",\n        \"DUP1\",\n        \"RETURNDATACOPY\",\n        \"SWAP1\",\n        \"RETURNDATASIZE\",\n        \"SWAP2\",\n        \"PUSH1\",\n        0x2B,  # jumpdest of whole program.\n        \"JUMPI\",\n        \"REVERT\",\n        \"JUMPDEST\",\n        \"RETURN\",\n    ]\n    return (\n        assembly_to_evm(loader_asm)[0],\n        assembly_to_evm(forwarder_pre_asm)[0],\n        assembly_to_evm(forwarder_post_asm)[0],\n    )\n\n\n# \"standard\" initcode for code which can be larger than 256 bytes.\n# returns the code starting from 0x0b with len `codesize`.\n# NOTE: it assumes codesize <= 2**24.\ndef _create_preamble(codesize):\n    from vyper.ir.compile_ir import assembly_to_evm\n\n    evm_len = 0x0B  # 11 bytes\n    asm = [\n        # use PUSH3 to be able to deal with larger contracts\n        \"PUSH3\",\n        # blank space for codesize\n        0x00,\n        0x00,\n        0x00,\n        \"RETURNDATASIZE\",\n        \"DUP2\",\n        \"PUSH1\",\n        evm_len,\n        \"RETURNDATASIZE\",\n        \"CODECOPY\",\n        \"RETURN\",\n    ]\n    evm = assembly_to_evm(asm)[0]\n    assert len(evm) == evm_len, evm\n\n    shl_bits = (evm_len - 4) * 8  # codesize needs to go right after the PUSH3\n    # mask codesize into the aforementioned \"blank space\"\n    return [\"or\", bytes_to_int(evm), shl(shl_bits, codesize)], evm_len\n\n\nclass _CreateBase(BuiltinFunctionT):\n    _kwargs = {\n        \"value\": KwargSettings(UINT256_T, zero_value),\n        \"salt\": KwargSettings(BYTES32_T, empty_value),\n    }\n    _return_type = AddressT()\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        # errmsg something like \"Cannot use {self._id} in pure fn\"\n        context.check_is_not_constant(\"use {self._id}\", expr)\n\n        should_use_create2 = \"salt\" in [kwarg.arg for kwarg in expr.keywords]\n\n        if not should_use_create2:\n            kwargs[\"salt\"] = CREATE2_SENTINEL\n\n        ir_builder = self._build_create_IR(expr, args, context, **kwargs)\n\n        add_gas_estimate = self._add_gas_estimate(args, should_use_create2)\n\n        return IRnode.from_list(\n            ir_builder, typ=AddressT(), annotation=self._id, add_gas_estimate=add_gas_estimate\n        )\n\n\nclass CreateMinimalProxyTo(_CreateBase):\n    # create an EIP1167 \"minimal proxy\" to the target contract\n\n    _id = \"create_minimal_proxy_to\"\n    _inputs = [(\"target\", AddressT())]\n\n    def _add_gas_estimate(self, args, should_use_create2):\n        a, b, c = eip1167_bytecode()\n        bytecode_len = 20 + len(b) + len(c)\n        return _create_addl_gas_estimate(bytecode_len, should_use_create2)\n\n    def _build_create_IR(self, expr, args, context, value, salt):\n        target_address = args[0]\n\n        buf = context.new_internal_variable(BytesT(96))\n\n        loader_evm, forwarder_pre_evm, forwarder_post_evm = eip1167_bytecode()\n        # Adjust to 32-byte boundaries\n        preamble_length = len(loader_evm) + len(forwarder_pre_evm)\n        forwarder_preamble = bytes_to_int(\n            loader_evm + forwarder_pre_evm + b\"\\x00\" * (32 - preamble_length)\n        )\n        forwarder_post = bytes_to_int(forwarder_post_evm + b\"\\x00\" * (32 - len(forwarder_post_evm)))\n\n        # left-align the target\n        if target_address.is_literal:\n            # note: should move to optimizer once we have\n            # codesize optimization pipeline\n            aligned_target = args[0].value << 96\n        else:\n            aligned_target = shl(96, target_address)\n\n        buf_len = preamble_length + 20 + len(forwarder_post_evm)\n\n        return [\n            \"seq\",\n            [\"mstore\", buf, forwarder_preamble],\n            [\"mstore\", [\"add\", buf, preamble_length], aligned_target],\n            [\"mstore\", [\"add\", buf, preamble_length + 20], forwarder_post],\n            _create_ir(value, buf, buf_len, salt=salt),\n        ]\n\n\nclass CreateForwarderTo(CreateMinimalProxyTo):\n    _warned = False\n\n    def build_IR(self, expr, context):\n        if not self._warned:\n            vyper_warn(\"`create_forwarder_to` is a deprecated alias of `create_minimal_proxy_to`!\")\n            self._warned = True\n\n        return super().build_IR(expr, context)\n\n\nclass CreateCopyOf(_CreateBase):\n    _id = \"create_copy_of\"\n    _inputs = [(\"target\", AddressT())]\n\n    @property\n    def _preamble_len(self):\n        return 11\n\n    def _add_gas_estimate(self, args, should_use_create2):\n        # max possible runtime length + preamble length\n        return _create_addl_gas_estimate(EIP_170_LIMIT + self._preamble_len, should_use_create2)\n\n    def _build_create_IR(self, expr, args, context, value, salt):\n        target = args[0]\n\n        # something we can pass to scope_multi\n        with scope_multi(\n            (target, value, salt), (\"create_target\", \"create_value\", \"create_salt\")\n        ) as (b1, (target, value, salt)):\n            codesize = IRnode.from_list([\"extcodesize\", target])\n            msize = IRnode.from_list([\"msize\"])\n            with scope_multi((codesize, msize), (\"target_codesize\", \"mem_ofst\")) as (\n                b2,\n                (codesize, mem_ofst),\n            ):\n                ir = [\"seq\"]\n\n                # make sure there is actually code at the target\n                check_codesize = [\"assert\", codesize]\n                ir.append(\n                    IRnode.from_list(check_codesize, error_msg=\"empty target (create_copy_of)\")\n                )\n\n                # store the preamble at msize + 22 (zero padding)\n                preamble, preamble_len = _create_preamble(codesize)\n                assert preamble_len == self._preamble_len\n\n                ir.append([\"mstore\", mem_ofst, preamble])\n\n                # copy the target code into memory. current layout:\n                # msize | 00...00 (22 0's) | preamble | bytecode\n                ir.append([\"extcodecopy\", target, add_ofst(mem_ofst, 32), 0, codesize])\n\n                buf = add_ofst(mem_ofst, 32 - preamble_len)\n                buf_len = [\"add\", codesize, preamble_len]\n\n                ir.append(_create_ir(value, buf, buf_len, salt))\n\n                return b1.resolve(b2.resolve(ir))\n\n\nclass CreateFromBlueprint(_CreateBase):\n    _id = \"create_from_blueprint\"\n    _inputs = [(\"target\", AddressT())]\n    _kwargs = {\n        \"value\": KwargSettings(UINT256_T, zero_value),\n        \"salt\": KwargSettings(BYTES32_T, empty_value),\n        \"raw_args\": KwargSettings(BoolT(), False, require_literal=True),\n        \"code_offset\": KwargSettings(UINT256_T, zero_value),\n    }\n    _has_varargs = True\n\n    def _add_gas_estimate(self, args, should_use_create2):\n        ctor_args = ir_tuple_from_args(args[1:])\n        # max possible size of init code\n        maxlen = EIP_170_LIMIT + ctor_args.typ.abi_type.size_bound()\n        return _create_addl_gas_estimate(maxlen, should_use_create2)\n\n    def _build_create_IR(self, expr, args, context, value, salt, code_offset, raw_args):\n        target = args[0]\n        ctor_args = args[1:]\n\n        ctor_args = [ensure_in_memory(arg, context) for arg in ctor_args]\n\n        if raw_args:\n            if len(ctor_args) != 1 or not isinstance(ctor_args[0].typ, BytesT):\n                raise StructureException(\"raw_args must be used with exactly 1 bytes argument\")\n\n            argbuf = bytes_data_ptr(ctor_args[0])\n            argslen = get_bytearray_length(ctor_args[0])\n            bufsz = ctor_args[0].typ.maxlen\n        else:\n            # encode the varargs\n            to_encode = ir_tuple_from_args(ctor_args)\n\n            # pretend we allocated enough memory for the encoder\n            # (we didn't, but we are clobbering unused memory so it's safe.)\n            bufsz = to_encode.typ.abi_type.size_bound()\n            argbuf = IRnode.from_list(\n                context.new_internal_variable(get_type_for_exact_size(bufsz)), location=MEMORY\n            )\n\n            # return a complex expression which writes to memory and returns\n            # the length of the encoded data\n            argslen = abi_encode(argbuf, to_encode, context, bufsz=bufsz, returns_len=True)\n\n        # NOTE: we need to invoke the abi encoder before evaluating MSIZE,\n        # then copy the abi encoded buffer to past-the-end of the initcode\n        # (since the abi encoder could write to fresh memory).\n        # it would be good to not require the memory copy, but need\n        # to evaluate memory safety.\n        with scope_multi(\n            (target, value, salt, argslen, code_offset),\n            (\"create_target\", \"create_value\", \"create_salt\", \"encoded_args_len\", \"code_offset\"),\n        ) as (b1, (target, value, salt, encoded_args_len, code_offset)):\n            codesize = IRnode.from_list([\"sub\", [\"extcodesize\", target], code_offset])\n            # copy code to memory starting from msize. we are clobbering\n            # unused memory so it's safe.\n            msize = IRnode.from_list([\"msize\"], location=MEMORY)\n            with scope_multi((codesize, msize), (\"target_codesize\", \"mem_ofst\")) as (\n                b2,\n                (codesize, mem_ofst),\n            ):\n                ir = [\"seq\"]\n\n                # make sure there is code at the target, and that\n                # code_ofst <= (extcodesize target).\n                # (note if code_ofst > (extcodesize target), would be\n                # OOG on the EXTCODECOPY)\n                # (code_ofst == (extcodesize target) would be empty\n                # initcode, which we disallow for hygiene reasons -\n                # same as `create_copy_of` on an empty target).\n                check_codesize = [\"assert\", [\"sgt\", codesize, 0]]\n                ir.append(\n                    IRnode.from_list(\n                        check_codesize, error_msg=\"empty target (create_from_blueprint)\"\n                    )\n                )\n\n                # copy the target code into memory.\n                # layout starting from mem_ofst:\n                # <target initcode> | <abi-encoded args OR arg buffer if raw_arg=True>\n                ir.append([\"extcodecopy\", target, mem_ofst, code_offset, codesize])\n                ir.append(copy_bytes(add_ofst(mem_ofst, codesize), argbuf, encoded_args_len, bufsz))\n\n                # theoretically, dst = \"msize\", but just be safe.\n                # if len(ctor_args) > 0:\n                #    dst = add_ofst(mem_ofst, codesize)\n                #    encoded_args_len = self._encode_args(dst, ctor_args, context)\n                # else:\n                #    encoded_args_len = 0\n\n                length = [\"add\", codesize, encoded_args_len]\n\n                ir.append(_create_ir(value, mem_ofst, length, salt))\n\n                return b1.resolve(b2.resolve(ir))\n\n\nclass _UnsafeMath(BuiltinFunctionT):\n    # TODO add unsafe math for `decimal`s\n    _inputs = [(\"a\", IntegerT.any()), (\"b\", IntegerT.any())]\n\n    def __repr__(self):\n        return f\"builtin function unsafe_{self.op}\"\n\n    def fetch_call_return(self, node):\n        return_type = self.infer_arg_types(node).pop()\n        return return_type\n\n    def infer_arg_types(self, node, expected_return_typ=None):\n        self._validate_arg_types(node)\n\n        types_list = get_common_types(*node.args, filter_fn=lambda x: isinstance(x, IntegerT))\n        if not types_list:\n            raise TypeMismatch(f\"unsafe_{self.op} called on dislike types\", node)\n\n        type_ = types_list.pop()\n        return [type_, type_]\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        (a, b) = args\n        op = self.op\n\n        assert a.typ == b.typ, \"unreachable\"\n\n        otyp = a.typ\n\n        if op == \"div\" and a.typ.is_signed:\n            op = \"sdiv\"\n\n        ret = [op, a, b]\n\n        if a.typ.bits < 256:\n            # wrap for ops which could under/overflow\n            if a.typ.is_signed:\n                # e.g. int128 -> (signextend 15 (add x y))\n                ret = promote_signed_int(ret, a.typ.bits)\n            else:\n                # e.g. uint8 -> (mod (add x y) 256)\n                # TODO mod_bound could be a really large literal\n                ret = [\"mod\", ret, 2**a.typ.bits]\n\n        return IRnode.from_list(ret, typ=otyp)\n\n        # TODO handle decimal case\n\n\nclass UnsafeAdd(_UnsafeMath):\n    op = \"add\"\n\n\nclass UnsafeSub(_UnsafeMath):\n    op = \"sub\"\n\n\nclass UnsafeMul(_UnsafeMath):\n    op = \"mul\"\n\n\nclass UnsafeDiv(_UnsafeMath):\n    op = \"div\"\n\n\nclass _MinMax(BuiltinFunctionT):\n    _inputs = [(\"a\", (DecimalT(), IntegerT.any())), (\"b\", (DecimalT(), IntegerT.any()))]\n\n    def _try_fold(self, node):\n        validate_call_args(node, 2)\n\n        left = node.args[0].get_folded_value()\n        right = node.args[1].get_folded_value()\n        if not isinstance(left, type(right)):\n            raise UnfoldableNode\n        if not isinstance(left, (vy_ast.Decimal, vy_ast.Int)):\n            raise UnfoldableNode\n\n        types_list = get_common_types(\n            *(left, right), filter_fn=lambda x: isinstance(x, (IntegerT, DecimalT))\n        )\n        if not types_list:\n            raise TypeMismatch(\"Cannot perform action between dislike numeric types\", node)\n\n        value = self._eval_fn(left.value, right.value)\n        return type(left).from_node(node, value=value)\n\n    def fetch_call_return(self, node):\n        self._validate_arg_types(node)\n\n        types_list = get_common_types(\n            *node.args, filter_fn=lambda x: isinstance(x, (IntegerT, DecimalT))\n        )\n        if not types_list:\n            raise TypeMismatch(\"Cannot perform action between dislike numeric types\", node)\n\n        return types_list\n\n    def infer_arg_types(self, node, expected_return_typ=None):\n        types_list = self.fetch_call_return(node)\n        # type mismatch should have been caught in `fetch_call_return`\n        assert expected_return_typ in types_list\n        return [expected_return_typ, expected_return_typ]\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        op = self._opcode\n\n        with args[0].cache_when_complex(\"_l\") as (b1, left), args[1].cache_when_complex(\"_r\") as (\n            b2,\n            right,\n        ):\n            if left.typ == right.typ:\n                if left.typ != UINT256_T:\n                    # if comparing like types that are not uint256, use SLT or SGT\n                    op = f\"s{op}\"\n                o = [\"select\", [op, left, right], left, right]\n                otyp = left.typ\n\n            else:\n                raise TypeMismatch(f\"Minmax types incompatible: {left.typ.typ} {right.typ.typ}\")\n            return IRnode.from_list(b1.resolve(b2.resolve(o)), typ=otyp)\n\n\nclass Min(_MinMax):\n    _id = \"min\"\n    _eval_fn = min\n    _opcode = \"lt\"\n\n\nclass Max(_MinMax):\n    _id = \"max\"\n    _eval_fn = max\n    _opcode = \"gt\"\n\n\nclass Uint2Str(BuiltinFunctionT):\n    _id = \"uint2str\"\n    _inputs = [(\"x\", IntegerT.unsigneds())]\n\n    def fetch_call_return(self, node):\n        arg_t = self.infer_arg_types(node)[0]\n        bits = arg_t.bits\n        len_needed = math.ceil(bits * math.log(2) / math.log(10))\n        return StringT(len_needed)\n\n    def _try_fold(self, node):\n        validate_call_args(node, 1)\n        value = node.args[0].get_folded_value()\n        if not isinstance(value, vy_ast.Int):\n            raise UnfoldableNode\n\n        value = value.value\n        if value < 0:\n            raise InvalidType(\"Only unsigned ints allowed\", node)\n        value = str(value)\n        return vy_ast.Str.from_node(node, value=value)\n\n    def infer_arg_types(self, node, expected_return_typ=None):\n        self._validate_arg_types(node)\n        input_type = get_possible_types_from_node(node.args[0]).pop()\n        return [input_type]\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        return_t = self.fetch_call_return(expr)\n        n_digits = return_t.maxlen\n\n        with args[0].cache_when_complex(\"val\") as (b1, val):\n            buf = context.new_internal_variable(return_t)\n\n            i = IRnode.from_list(context.fresh_varname(\"uint2str_i\"), typ=UINT256_T)\n\n            ret = [\"repeat\", i, 0, n_digits + 1, n_digits + 1]\n\n            body = [\n                \"seq\",\n                [\n                    \"if\",\n                    [\"eq\", val, 0],\n                    # clobber val, and return it as a pointer\n                    [\n                        \"seq\",\n                        [\"mstore\", [\"sub\", buf + n_digits, i], i],\n                        [\"set\", val, [\"sub\", buf + n_digits, i]],\n                        \"break\",\n                    ],\n                    [\n                        \"seq\",\n                        [\"mstore\", [\"sub\", buf + n_digits, i], [\"add\", 48, [\"mod\", val, 10]]],\n                        [\"set\", val, [\"div\", val, 10]],\n                    ],\n                ],\n            ]\n            ret.append(body)\n\n            # \"0\" has hex representation 0x00..0130..00\n            # if (val == 0) {\n            #   return \"0\"\n            # } else {\n            #   do the loop\n            # }\n            ret = [\n                \"if\",\n                [\"eq\", val, 0],\n                [\"seq\", [\"mstore\", buf + 1, ord(\"0\")], [\"mstore\", buf, 1], buf],\n                [\"seq\", ret, val],\n            ]\n\n            return b1.resolve(IRnode.from_list(ret, location=MEMORY, typ=return_t))\n\n\nclass Sqrt(BuiltinFunctionT):\n    _id = \"sqrt\"\n    _inputs = [(\"d\", DecimalT())]\n    _return_type = DecimalT()\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        # TODO fix cyclic dependency with codegen/stmt.py\n        from ._utils import generate_inline_function\n\n        arg = args[0]\n        # TODO: reify decimal and integer sqrt paths (see isqrt)\n        sqrt_code = \"\"\"\nassert x >= 0.0\nz: decimal = 0.0\n\nif x == 0.0:\n    z = 0.0\nelse:\n    z = x / 2.0 + 0.5\n    y: decimal = x\n\n    for i: uint256 in range(256):\n        if z == y:\n            break\n        y = z\n        z = (x / z + z) / 2.0\n        \"\"\"\n\n        x_type = DecimalT()\n        placeholder_copy = [\"pass\"]\n        # Steal current position if variable is already allocated.\n        if arg.value == \"mload\":\n            new_var_pos = arg.args[0]\n        # Other locations need to be copied.\n        else:\n            new_var_pos = context.new_internal_variable(x_type)\n            placeholder_copy = [\"mstore\", new_var_pos, arg]\n        # Create input variables.\n        variables = {\"x\": VariableRecord(name=\"x\", pos=new_var_pos, typ=x_type, mutable=False)}\n        # Dictionary to update new (i.e. typecheck) namespace\n        variables_2 = {\"x\": VarInfo(DecimalT())}\n        # Generate inline IR.\n        new_ctx, sqrt_ir = generate_inline_function(\n            code=sqrt_code,\n            variables=variables,\n            variables_2=variables_2,\n            memory_allocator=context.memory_allocator,\n        )\n        return IRnode.from_list(\n            [\"seq\", placeholder_copy, sqrt_ir, new_ctx.vars[\"z\"].pos],  # load x variable\n            typ=DecimalT(),\n            location=MEMORY,\n        )\n\n\nclass ISqrt(BuiltinFunctionT):\n    _id = \"isqrt\"\n    _inputs = [(\"d\", UINT256_T)]\n    _return_type = UINT256_T\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        # calculate isqrt using the babylonian method\n\n        y, z = \"y\", \"z\"\n        arg = args[0]\n        with arg.cache_when_complex(\"x\") as (b1, x):\n            ret = [\n                \"seq\",\n                [\n                    \"if\",\n                    [\"ge\", y, 2 ** (128 + 8)],\n                    [\"seq\", [\"set\", y, shr(128, y)], [\"set\", z, shl(64, z)]],\n                ],\n                [\n                    \"if\",\n                    [\"ge\", y, 2 ** (64 + 8)],\n                    [\"seq\", [\"set\", y, shr(64, y)], [\"set\", z, shl(32, z)]],\n                ],\n                [\n                    \"if\",\n                    [\"ge\", y, 2 ** (32 + 8)],\n                    [\"seq\", [\"set\", y, shr(32, y)], [\"set\", z, shl(16, z)]],\n                ],\n                [\n                    \"if\",\n                    [\"ge\", y, 2 ** (16 + 8)],\n                    [\"seq\", [\"set\", y, shr(16, y)], [\"set\", z, shl(8, z)]],\n                ],\n            ]\n            ret.append([\"set\", z, [\"div\", [\"mul\", z, [\"add\", y, 2**16]], 2**18]])\n\n            for _ in range(7):\n                ret.append([\"set\", z, [\"div\", [\"add\", [\"div\", x, z], z], 2]])\n\n            # note: If ``x+1`` is a perfect square, then the Babylonian\n            # algorithm oscillates between floor(sqrt(x)) and ceil(sqrt(x)) in\n            # consecutive iterations. return the floor value always.\n\n            ret.append([\"with\", \"t\", [\"div\", x, z], [\"select\", [\"lt\", z, \"t\"], z, \"t\"]])\n\n            ret = [\"with\", y, x, [\"with\", z, 181, ret]]\n            return b1.resolve(IRnode.from_list(ret, typ=UINT256_T))\n\n\nclass Empty(TypenameFoldedFunctionT):\n    _id = \"empty\"\n\n    def fetch_call_return(self, node):\n        type_ = self.infer_arg_types(node)[0].typedef\n        if isinstance(type_, HashMapT):\n            raise TypeMismatch(\"Cannot use empty on HashMap\", node)\n        return type_\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        output_type = args[0]\n        return IRnode(\"~empty\", typ=output_type)\n\n\nclass Breakpoint(BuiltinFunctionT):\n    _id = \"breakpoint\"\n    _inputs: list = []\n\n    _warned = False\n\n    def fetch_call_return(self, node):\n        if not self._warned:\n            vyper_warn(\"`breakpoint` should only be used for debugging!\\n\" + node._annotated_source)\n            self._warned = True\n\n        return None\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        return IRnode.from_list(\"breakpoint\", annotation=\"breakpoint()\")\n\n\nclass Print(BuiltinFunctionT):\n    _id = \"print\"\n    _inputs: list = []\n    _has_varargs = True\n    _kwargs = {\"hardhat_compat\": KwargSettings(BoolT(), False, require_literal=True)}\n\n    _warned = False\n\n    def fetch_call_return(self, node):\n        if not self._warned:\n            vyper_warn(\"`print` should only be used for debugging!\\n\" + node._annotated_source)\n            self._warned = True\n\n        return None\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        args_as_tuple = ir_tuple_from_args(args)\n        args_abi_t = args_as_tuple.typ.abi_type\n\n        # create a signature like \"log(uint256)\"\n        sig = \"log\" + \"(\" + \",\".join([arg.typ.abi_type.selector_name() for arg in args]) + \")\"\n\n        if kwargs[\"hardhat_compat\"] is True:\n            method_id = method_id_int(sig)\n            buflen = 32 + args_abi_t.size_bound()\n\n            # 32 bytes extra space for the method id\n            buf = context.new_internal_variable(get_type_for_exact_size(buflen))\n\n            ret = [\"seq\"]\n            ret.append([\"mstore\", buf, method_id])\n            encode = abi_encode(buf + 32, args_as_tuple, context, buflen, returns_len=True)\n\n        else:\n            method_id = method_id_int(\"log(string,bytes)\")\n            schema = args_abi_t.selector_name().encode(\"utf-8\")\n            if len(schema) > 32:\n                raise CompilerPanic(\"print signature too long: {schema}\")\n\n            schema_t = StringT(len(schema))\n            schema_buf = context.new_internal_variable(schema_t)\n            ret = [\"seq\"]\n            ret.append([\"mstore\", schema_buf, len(schema)])\n\n            # TODO use Expr.make_bytelike, or better have a `bytestring` IRnode type\n            ret.append([\"mstore\", schema_buf + 32, bytes_to_int(schema.ljust(32, b\"\\x00\"))])\n\n            payload_buflen = args_abi_t.size_bound()\n            payload_t = BytesT(payload_buflen)\n\n            # 32 bytes extra space for the method id\n            payload_buf = context.new_internal_variable(payload_t)\n            encode_payload = abi_encode(\n                payload_buf + 32, args_as_tuple, context, payload_buflen, returns_len=True\n            )\n\n            ret.append([\"mstore\", payload_buf, encode_payload])\n            args_as_tuple = ir_tuple_from_args(\n                [\n                    IRnode.from_list(schema_buf, typ=schema_t, location=MEMORY),\n                    IRnode.from_list(payload_buf, typ=payload_t, location=MEMORY),\n                ]\n            )\n\n            # add 32 for method id padding\n            buflen = 32 + args_as_tuple.typ.abi_type.size_bound()\n            buf = context.new_internal_variable(get_type_for_exact_size(buflen))\n            ret.append([\"mstore\", buf, method_id])\n            encode = abi_encode(buf + 32, args_as_tuple, context, buflen, returns_len=True)\n\n        # debug address that tooling uses\n        CONSOLE_ADDRESS = 0x000000000000000000636F6E736F6C652E6C6F67\n        ret.append([\"staticcall\", \"gas\", CONSOLE_ADDRESS, buf + 28, [\"add\", 4, encode], 0, 0])\n\n        return IRnode.from_list(ret, annotation=\"print:\" + sig)\n\n\nclass ABIEncode(BuiltinFunctionT):\n    _id = \"_abi_encode\"  # TODO prettier to rename this to abi.encode\n    # signature: *, ensure_tuple=<literal_bool> -> Bytes[<calculated len>]\n    # explanation of ensure_tuple:\n    # default is to force even a single value into a tuple,\n    # e.g. _abi_encode(bytes) -> _abi_encode((bytes,))\n    #      _abi_encode((bytes,)) -> _abi_encode(((bytes,),))\n    # this follows the encoding convention for functions:\n    # ://docs.soliditylang.org/en/v0.8.6/abi-spec.html#function-selector-and-argument-encoding\n    # if this is turned off, then bytes will be encoded as bytes.\n\n    _inputs: list = []\n    _has_varargs = True\n\n    _kwargs = {\n        \"ensure_tuple\": KwargSettings(BoolT(), True, require_literal=True),\n        \"method_id\": KwargSettings((BYTES4_T, BytesT(4)), None, require_literal=True),\n    }\n\n    def infer_kwarg_types(self, node):\n        ret = {}\n        for kwarg in node.keywords:\n            kwarg_name = kwarg.arg\n            validate_expected_type(kwarg.value, self._kwargs[kwarg_name].typ)\n            ret[kwarg_name] = get_exact_type_from_node(kwarg.value)\n        return ret\n\n    def fetch_call_return(self, node):\n        self._validate_arg_types(node)\n        ensure_tuple = next(\n            (arg.value.value for arg in node.keywords if arg.arg == \"ensure_tuple\"), True\n        )\n        assert isinstance(ensure_tuple, bool)\n        has_method_id = \"method_id\" in [arg.arg for arg in node.keywords]\n\n        # figure out the output type by converting\n        # the types to ABI_Types and calling size_bound API\n        arg_abi_types = []\n        arg_types = self.infer_arg_types(node)\n        for arg_t in arg_types:\n            arg_abi_types.append(arg_t.abi_type)\n\n        # special case, no tuple\n        if len(arg_abi_types) == 1 and not ensure_tuple:\n            arg_abi_t = arg_abi_types[0]\n        else:\n            arg_abi_t = ABI_Tuple(arg_abi_types)\n\n        maxlen = arg_abi_t.size_bound()\n\n        if has_method_id:\n            # the output includes 4 bytes for the method_id.\n            maxlen += 4\n\n        ret = BytesT()\n        ret.set_length(maxlen)\n        return ret\n\n    @staticmethod\n    def _parse_method_id(method_id_literal):\n        if method_id_literal is None:\n            return None\n        if isinstance(method_id_literal, bytes):\n            assert len(method_id_literal) == 4\n            return fourbytes_to_int(method_id_literal)\n        if method_id_literal.startswith(\"0x\"):\n            method_id_literal = method_id_literal[2:]\n        return fourbytes_to_int(bytes.fromhex(method_id_literal))\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        ensure_tuple = kwargs[\"ensure_tuple\"]\n        method_id = self._parse_method_id(kwargs[\"method_id\"])\n\n        if len(args) < 1:\n            raise StructureException(\"abi_encode expects at least one argument\", expr)\n\n        # figure out the required length for the output buffer\n        if len(args) == 1 and not ensure_tuple:\n            # special case, no tuple\n            encode_input = args[0]\n        else:\n            encode_input = ir_tuple_from_args(args)\n\n        input_abi_t = encode_input.typ.abi_type\n        maxlen = input_abi_t.size_bound()\n        if method_id is not None:\n            maxlen += 4\n\n        buf_t = BytesT(maxlen)\n        assert self.fetch_call_return(expr).length == maxlen\n        buf = context.new_internal_variable(buf_t)\n\n        ret = [\"seq\"]\n        if method_id is not None:\n            # <32 bytes length> | <4 bytes method_id> | <everything else>\n            # write the unaligned method_id first, then we will\n            # overwrite the 28 bytes of zeros with the bytestring length\n            ret += [[\"mstore\", buf + 4, method_id]]\n            # abi encode, and grab length as stack item\n            length = abi_encode(buf + 36, encode_input, context, returns_len=True, bufsz=maxlen)\n            # write the output length to where bytestring stores its length\n            ret += [[\"mstore\", buf, [\"add\", length, 4]]]\n\n        else:\n            # abi encode and grab length as stack item\n            length = abi_encode(buf + 32, encode_input, context, returns_len=True, bufsz=maxlen)\n            # write the output length to where bytestring stores its length\n            ret += [[\"mstore\", buf, length]]\n\n        # return the buf location\n        # TODO location is statically known, optimize this out\n        ret += [buf]\n\n        return IRnode.from_list(ret, location=MEMORY, typ=buf_t)\n\n\nclass ABIDecode(BuiltinFunctionT):\n    _id = \"_abi_decode\"\n    _inputs = [(\"data\", BytesT.any()), (\"output_type\", \"TYPE_DEFINITION\")]\n    _kwargs = {\"unwrap_tuple\": KwargSettings(BoolT(), True, require_literal=True)}\n\n    def fetch_call_return(self, node):\n        _, output_type = self.infer_arg_types(node)\n        return output_type.typedef\n\n    def infer_arg_types(self, node, expected_return_typ=None):\n        self._validate_arg_types(node)\n\n        validate_call_args(node, 2, [\"unwrap_tuple\"])\n\n        data_type = get_exact_type_from_node(node.args[0])\n        output_type = type_from_annotation(node.args[1])\n\n        return [data_type, TYPE_T(output_type)]\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        unwrap_tuple = kwargs[\"unwrap_tuple\"]\n\n        data = args[0]\n        output_typ = args[1]\n        wrapped_typ = output_typ\n\n        if unwrap_tuple is True:\n            wrapped_typ = calculate_type_for_external_return(output_typ)\n\n        abi_size_bound = wrapped_typ.abi_type.size_bound()\n        abi_min_size = wrapped_typ.abi_type.min_size()\n\n        # Get the size of data\n        input_max_len = data.typ.maxlen\n\n        assert abi_min_size <= abi_size_bound, \"bad abi type\"\n        if input_max_len < abi_size_bound:\n            raise StructureException(\n                (\n                    \"Mismatch between size of input and size of decoded types. \"\n                    f\"length of ABI-encoded {wrapped_typ} must be equal to or greater \"\n                    f\"than {abi_size_bound}\"\n                ),\n                expr.args[0],\n            )\n\n        data = ensure_in_memory(data, context)\n\n        with data.cache_when_complex(\"to_decode\") as (b1, data):\n            data_ptr = bytes_data_ptr(data)\n            data_len = get_bytearray_length(data)\n\n            ret = [\"seq\"]\n\n            if abi_min_size == abi_size_bound:\n                ret.append([\"assert\", [\"eq\", abi_min_size, data_len]])\n            else:\n                # runtime assert: abi_min_size <= data_len <= abi_size_bound\n                ret.append(clamp2(abi_min_size, data_len, abi_size_bound, signed=False))\n\n            to_decode = IRnode.from_list(\n                data_ptr,\n                typ=wrapped_typ,\n                location=data.location,\n                encoding=Encoding.ABI,\n                annotation=f\"abi_decode({output_typ})\",\n            )\n            to_decode.encoding = Encoding.ABI\n\n            # TODO optimization: skip make_setter when we don't need\n            # input validation\n\n            output_buf = context.new_internal_variable(wrapped_typ)\n            output = IRnode.from_list(output_buf, typ=wrapped_typ, location=MEMORY)\n\n            # sanity check buffer size for wrapped output type will not buffer overflow\n            assert wrapped_typ.memory_bytes_required == output_typ.memory_bytes_required\n            ret.append(make_setter(output, to_decode))\n\n            ret.append(output)\n            # finalize. set the type and location for the return buffer.\n            # (note: unwraps the tuple type if necessary)\n            ret = IRnode.from_list(ret, typ=output_typ, location=MEMORY)\n            return b1.resolve(ret)\n\n\nclass _MinMaxValue(TypenameFoldedFunctionT):\n    def _try_fold(self, node):\n        self._validate_arg_types(node)\n        input_type = type_from_annotation(node.args[0])\n\n        if not isinstance(input_type, (IntegerT, DecimalT)):\n            raise InvalidType(f\"Expected numeric type but got {input_type} instead\", node)\n\n        val = self._eval(input_type)\n\n        if isinstance(input_type, DecimalT):\n            ret = vy_ast.Decimal.from_node(node, value=val)\n\n        if isinstance(input_type, IntegerT):\n            ret = vy_ast.Int.from_node(node, value=val)\n\n        ret._metadata[\"type\"] = input_type\n        return ret\n\n    def infer_arg_types(self, node, expected_return_typ=None):\n        input_typedef = TYPE_T(type_from_annotation(node.args[0]))\n        return [input_typedef]\n\n\nclass MinValue(_MinMaxValue):\n    _id = \"min_value\"\n\n    def _eval(self, type_):\n        return type_.ast_bounds[0]\n\n\nclass MaxValue(_MinMaxValue):\n    _id = \"max_value\"\n\n    def _eval(self, type_):\n        return type_.ast_bounds[1]\n\n\nclass Epsilon(TypenameFoldedFunctionT):\n    _id = \"epsilon\"\n\n    def _try_fold(self, node):\n        self._validate_arg_types(node)\n        input_type = type_from_annotation(node.args[0])\n\n        if not input_type.compare_type(DecimalT()):\n            raise InvalidType(f\"Expected decimal type but got {input_type} instead\", node)\n\n        return vy_ast.Decimal.from_node(node, value=input_type.epsilon)\n\n\nDISPATCH_TABLE = {\n    \"_abi_encode\": ABIEncode(),\n    \"_abi_decode\": ABIDecode(),\n    \"floor\": Floor(),\n    \"ceil\": Ceil(),\n    \"convert\": Convert(),\n    \"slice\": Slice(),\n    \"len\": Len(),\n    \"concat\": Concat(),\n    \"sha256\": Sha256(),\n    \"method_id\": MethodID(),\n    \"keccak256\": Keccak256(),\n    \"ecrecover\": ECRecover(),\n    \"ecadd\": ECAdd(),\n    \"ecmul\": ECMul(),\n    \"extract32\": Extract32(),\n    \"as_wei_value\": AsWeiValue(),\n    \"raw_call\": RawCall(),\n    \"blockhash\": BlockHash(),\n    \"bitwise_and\": BitwiseAnd(),\n    \"bitwise_or\": BitwiseOr(),\n    \"bitwise_xor\": BitwiseXor(),\n    \"bitwise_not\": BitwiseNot(),\n    \"uint256_addmod\": AddMod(),\n    \"uint256_mulmod\": MulMod(),\n    \"unsafe_add\": UnsafeAdd(),\n    \"unsafe_sub\": UnsafeSub(),\n    \"unsafe_mul\": UnsafeMul(),\n    \"unsafe_div\": UnsafeDiv(),\n    \"pow_mod256\": PowMod256(),\n    \"uint2str\": Uint2Str(),\n    \"isqrt\": ISqrt(),\n    \"sqrt\": Sqrt(),\n    \"shift\": Shift(),\n    \"create_minimal_proxy_to\": CreateMinimalProxyTo(),\n    \"create_forwarder_to\": CreateForwarderTo(),\n    \"create_copy_of\": CreateCopyOf(),\n    \"create_from_blueprint\": CreateFromBlueprint(),\n    \"min\": Min(),\n    \"max\": Max(),\n    \"empty\": Empty(),\n    \"abs\": Abs(),\n    \"min_value\": MinValue(),\n    \"max_value\": MaxValue(),\n    \"epsilon\": Epsilon(),\n}\n\nSTMT_DISPATCH_TABLE = {\n    \"send\": Send(),\n    \"print\": Print(),\n    \"breakpoint\": Breakpoint(),\n    \"selfdestruct\": SelfDestruct(),\n    \"raw_call\": RawCall(),\n    \"raw_log\": RawLog(),\n    \"raw_revert\": RawRevert(),\n    \"create_minimal_proxy_to\": CreateMinimalProxyTo(),\n    \"create_forwarder_to\": CreateForwarderTo(),\n    \"create_copy_of\": CreateCopyOf(),\n    \"create_from_blueprint\": CreateFromBlueprint(),\n}\n\nBUILTIN_FUNCTIONS = {**STMT_DISPATCH_TABLE, **DISPATCH_TABLE}.keys()\n\n\ndef get_builtin_functions():\n    return {**STMT_DISPATCH_TABLE, **DISPATCH_TABLE}\n"], "fixing_code": ["def test_concat(get_contract_with_gas_estimation):\n    test_concat = \"\"\"\n@external\ndef foo2(input1: Bytes[50], input2: Bytes[50]) -> Bytes[1000]:\n    return concat(input1, input2)\n\n@external\ndef foo3(input1: Bytes[50], input2: Bytes[50], input3: Bytes[50]) -> Bytes[1000]:\n    return concat(input1, input2, input3)\n    \"\"\"\n\n    c = get_contract_with_gas_estimation(test_concat)\n    assert c.foo2(b\"h\", b\"orse\") == b\"horse\"\n    assert c.foo2(b\"h\", b\"\") == b\"h\"\n    assert c.foo2(b\"\", b\"\") == b\"\"\n    assert c.foo2(b\"\", b\"orse\") == b\"orse\"\n    assert c.foo3(b\"Buffalo\", b\" \", b\"buffalo\") == b\"Buffalo buffalo\"\n    assert c.foo2(b\"\\x36\", b\"\\x35\" * 32) == b\"\\x36\" + b\"\\x35\" * 32\n    assert c.foo2(b\"\\x36\" * 48, b\"\\x35\" * 32) == b\"\\x36\" * 48 + b\"\\x35\" * 32\n    assert (\n        c.foo3(b\"horses\" * 4, b\"mice\" * 7, b\"crows\" * 10)\n        == b\"horses\" * 4 + b\"mice\" * 7 + b\"crows\" * 10\n    )  # noqa: E501\n    print(\"Passed simple concat test\")\n\n\ndef test_concat2(get_contract_with_gas_estimation):\n    test_concat2 = \"\"\"\n@external\ndef foo(inp: Bytes[50]) -> Bytes[1000]:\n    x: Bytes[50] = inp\n    return concat(x, inp, x, inp, x, inp, x, inp, x, inp)\n    \"\"\"\n\n    c = get_contract_with_gas_estimation(test_concat2)\n    assert c.foo(b\"horse\" * 9 + b\"vyper\") == (b\"horse\" * 9 + b\"vyper\") * 10\n    print(\"Passed second concat test\")\n\n\ndef test_crazy_concat_code(get_contract_with_gas_estimation):\n    crazy_concat_code = \"\"\"\ny: Bytes[10]\n\n@external\ndef krazykonkat(z: Bytes[10]) -> Bytes[25]:\n    x: Bytes[3] = b\"cow\"\n    self.y = b\"horse\"\n    return concat(x, b\" \", self.y, b\" \", z)\n    \"\"\"\n\n    c = get_contract_with_gas_estimation(crazy_concat_code)\n\n    assert c.krazykonkat(b\"moose\") == b\"cow horse moose\"\n\n    print(\"Passed third concat test\")\n\n\ndef test_concat_buffer(get_contract):\n    # GHSA-2q8v-3gqq-4f8p\n    code = \"\"\"\n@internal\ndef bar() -> uint256:\n    sss: String[2] = concat(\"a\", \"b\")\n    return 1\n\n\n@external\ndef foo() -> int256:\n    a: int256 = -1\n    b: uint256 = self.bar()\n    return a\n    \"\"\"\n    c = get_contract(code)\n    assert c.foo() == -1\n\n\ndef test_concat_buffer2(get_contract):\n    # GHSA-2q8v-3gqq-4f8p\n    code = \"\"\"\ni: immutable(int256)\n\n@external\ndef __init__():\n    i = -1\n    s: String[2] = concat(\"a\", \"b\")\n\n@external\ndef foo() -> int256:\n    return i\n    \"\"\"\n    c = get_contract(code)\n    assert c.foo() == -1\n\n\ndef test_concat_buffer3(get_contract):\n    # GHSA-2q8v-3gqq-4f8p\n    code = \"\"\"\ns: String[1]\ns2: String[33]\ns3: String[34]\n\n@external\ndef __init__():\n    self.s = \"a\"\n    self.s2 = \"aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\" # 33*'a'\n\n@internal\ndef bar() -> uint256:\n    self.s3 = concat(self.s, self.s2)\n    return 1\n\n@external\ndef foo() -> int256:\n    i: int256 = -1\n    b: uint256 = self.bar()\n    return i\n    \"\"\"\n    c = get_contract(code)\n    assert c.foo() == -1\n\n\ndef test_concat_bytes32(get_contract_with_gas_estimation):\n    test_concat_bytes32 = \"\"\"\n@external\ndef sandwich(inp: Bytes[100], inp2: bytes32) -> Bytes[164]:\n    return concat(inp2, inp, inp2)\n\n@external\ndef fivetimes(inp: bytes32) -> Bytes[160]:\n    return concat(inp, inp, inp, inp, inp)\n    \"\"\"\n\n    c = get_contract_with_gas_estimation(test_concat_bytes32)\n    assert c.sandwich(b\"cow\", b\"\\x35\" * 32) == b\"\\x35\" * 32 + b\"cow\" + b\"\\x35\" * 32, c.sandwich(\n        b\"cow\", b\"\\x35\" * 32\n    )  # noqa: E501\n    assert c.sandwich(b\"\", b\"\\x46\" * 32) == b\"\\x46\" * 64\n    assert c.sandwich(b\"\\x57\" * 95, b\"\\x57\" * 32) == b\"\\x57\" * 159\n    assert c.sandwich(b\"\\x57\" * 96, b\"\\x57\" * 32) == b\"\\x57\" * 160\n    assert c.sandwich(b\"\\x57\" * 97, b\"\\x57\" * 32) == b\"\\x57\" * 161\n    assert c.fivetimes(b\"mongoose\" * 4) == b\"mongoose\" * 20\n\n    print(\"Passed concat bytes32 test\")\n\n\ndef test_konkat_code(get_contract_with_gas_estimation):\n    konkat_code = \"\"\"\necks: bytes32\n\n@external\ndef foo(x: bytes32, y: bytes32) -> Bytes[64]:\n    self.ecks = x\n    return concat(self.ecks, y)\n\n@external\ndef goo(x: bytes32, y: bytes32) -> Bytes[64]:\n    self.ecks = x\n    return concat(self.ecks, y)\n\n@external\ndef hoo(x: bytes32, y: bytes32) -> Bytes[64]:\n    return concat(x, y)\n    \"\"\"\n\n    c = get_contract_with_gas_estimation(konkat_code)\n    assert c.foo(b\"\\x35\" * 32, b\"\\x00\" * 32) == b\"\\x35\" * 32 + b\"\\x00\" * 32\n    assert c.goo(b\"\\x35\" * 32, b\"\\x00\" * 32) == b\"\\x35\" * 32 + b\"\\x00\" * 32\n    assert c.hoo(b\"\\x35\" * 32, b\"\\x00\" * 32) == b\"\\x35\" * 32 + b\"\\x00\" * 32\n\n    print(\"Passed second concat tests\")\n\n\ndef test_small_output(get_contract_with_gas_estimation):\n    code = \"\"\"\n@external\ndef small_output(a: String[5], b: String[4]) -> String[9]:\n    c: String[9] = concat(a, b)\n    return c\n    \"\"\"\n    c = get_contract_with_gas_estimation(code)\n    assert c.small_output(\"abcde\", \"fghi\") == \"abcdefghi\"\n    assert c.small_output(\"\", \"\") == \"\"\n\n\ndef test_small_bytes(get_contract_with_gas_estimation):\n    # TODO maybe use parametrization or hypothesis for the examples\n    code = \"\"\"\n@external\ndef small_bytes1(a: bytes1, b: Bytes[2]) -> Bytes[3]:\n    return concat(a, b)\n\n@external\ndef small_bytes2(a: Bytes[1], b: bytes2) -> Bytes[3]:\n    return concat(a, b)\n\n@external\ndef small_bytes3(a: bytes4, b: bytes32) -> Bytes[36]:\n    return concat(a, b)\n\n@external\ndef small_bytes4(a: bytes8, b: Bytes[32], c: bytes8) -> Bytes[48]:\n    return concat(a, b, c)\n    \"\"\"\n    contract = get_contract_with_gas_estimation(code)\n\n    i = 0\n\n    def bytes_for_len(n):\n        nonlocal i\n        # bytes constructor with state\n        # (so we don't keep generating the same string)\n        xs = []\n        for _ in range(n):\n            i += 1\n            i %= 256\n            xs.append(i)\n        return bytes(xs)\n\n    a, b = bytes_for_len(1), bytes_for_len(2)\n    assert contract.small_bytes1(a, b) == a + b\n\n    a, b = bytes_for_len(1), bytes_for_len(1)\n    assert contract.small_bytes1(a, b) == a + b\n\n    a, b = bytes_for_len(1), bytes_for_len(2)\n    assert contract.small_bytes2(a, b) == a + b\n\n    a, b = b\"\", bytes_for_len(2)\n    assert contract.small_bytes2(a, b) == a + b\n\n    a, b = bytes_for_len(4), bytes_for_len(32)\n    assert contract.small_bytes3(a, b) == a + b\n\n    a, b, c = bytes_for_len(8), bytes_for_len(32), bytes_for_len(8)\n    assert contract.small_bytes4(a, b, c) == a + b + c\n\n    a, b, c = bytes_for_len(8), bytes_for_len(1), bytes_for_len(8)\n    assert contract.small_bytes4(a, b, c) == a + b + c\n\n    a, b, c = bytes_for_len(8), bytes_for_len(0), bytes_for_len(8)\n    assert contract.small_bytes4(a, b, c) == a + b + c\n", "import hashlib\nimport math\nimport operator\n\nfrom vyper import ast as vy_ast\nfrom vyper.abi_types import ABI_Tuple\nfrom vyper.ast.validation import validate_call_args\nfrom vyper.codegen.abi_encoder import abi_encode\nfrom vyper.codegen.context import Context, VariableRecord\nfrom vyper.codegen.core import (\n    STORE,\n    IRnode,\n    _freshname,\n    add_ofst,\n    bytes_data_ptr,\n    calculate_type_for_external_return,\n    check_external_call,\n    clamp,\n    clamp2,\n    clamp_basetype,\n    clamp_nonzero,\n    copy_bytes,\n    dummy_node_for_type,\n    ensure_in_memory,\n    eval_once_check,\n    eval_seq,\n    get_bytearray_length,\n    get_type_for_exact_size,\n    ir_tuple_from_args,\n    make_setter,\n    promote_signed_int,\n    sar,\n    shl,\n    shr,\n    unwrap_location,\n)\nfrom vyper.codegen.expr import Expr\nfrom vyper.codegen.ir_node import Encoding, scope_multi\nfrom vyper.codegen.keccak256_helper import keccak256_helper\nfrom vyper.evm.address_space import MEMORY, STORAGE\nfrom vyper.exceptions import (\n    ArgumentException,\n    CompilerPanic,\n    InvalidLiteral,\n    InvalidType,\n    StateAccessViolation,\n    StructureException,\n    TypeMismatch,\n    UnfoldableNode,\n    ZeroDivisionException,\n)\nfrom vyper.semantics.analysis.base import Modifiability, VarInfo\nfrom vyper.semantics.analysis.utils import (\n    get_common_types,\n    get_exact_type_from_node,\n    get_possible_types_from_node,\n    validate_expected_type,\n)\nfrom vyper.semantics.types import (\n    TYPE_T,\n    AddressT,\n    BoolT,\n    BytesM_T,\n    BytesT,\n    DArrayT,\n    DecimalT,\n    HashMapT,\n    IntegerT,\n    KwargSettings,\n    SArrayT,\n    StringT,\n    TupleT,\n)\nfrom vyper.semantics.types.bytestrings import _BytestringT\nfrom vyper.semantics.types.shortcuts import (\n    BYTES4_T,\n    BYTES32_T,\n    INT128_T,\n    INT256_T,\n    UINT8_T,\n    UINT256_T,\n)\nfrom vyper.semantics.types.utils import type_from_annotation\nfrom vyper.utils import (\n    DECIMAL_DIVISOR,\n    EIP_170_LIMIT,\n    SHA3_PER_WORD,\n    MemoryPositions,\n    bytes_to_int,\n    ceil32,\n    fourbytes_to_int,\n    keccak256,\n    method_id,\n    method_id_int,\n    vyper_warn,\n)\n\nfrom ._convert import convert\nfrom ._signatures import BuiltinFunctionT, process_inputs\n\nSHA256_ADDRESS = 2\nSHA256_BASE_GAS = 60\nSHA256_PER_WORD_GAS = 12\n\n\nclass FoldedFunctionT(BuiltinFunctionT):\n    # Base class for nodes which should always be folded\n\n    _modifiability = Modifiability.CONSTANT\n\n\nclass TypenameFoldedFunctionT(FoldedFunctionT):\n    # Base class for builtin functions that:\n    # (1) take a typename as the only argument; and\n    # (2) should always be folded.\n\n    # \"TYPE_DEFINITION\" is a placeholder value for a type definition string, and\n    # will be replaced by a `TypeTypeDefinition` object in `infer_arg_types`.\n    _inputs = [(\"typename\", \"TYPE_DEFINITION\")]\n\n    def fetch_call_return(self, node):\n        type_ = self.infer_arg_types(node)[0].typedef\n        return type_\n\n    def infer_arg_types(self, node, expected_return_typ=None):\n        validate_call_args(node, 1)\n        input_typedef = TYPE_T(type_from_annotation(node.args[0]))\n        return [input_typedef]\n\n\nclass Floor(BuiltinFunctionT):\n    _id = \"floor\"\n    _inputs = [(\"value\", DecimalT())]\n    # TODO: maybe use int136?\n    _return_type = INT256_T\n\n    def _try_fold(self, node):\n        validate_call_args(node, 1)\n        value = node.args[0].get_folded_value()\n        if not isinstance(value, vy_ast.Decimal):\n            raise UnfoldableNode\n\n        value = math.floor(value.value)\n        return vy_ast.Int.from_node(node, value=value)\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        arg = args[0]\n        with arg.cache_when_complex(\"arg\") as (b1, arg):\n            ret = IRnode.from_list(\n                [\n                    \"if\",\n                    [\"slt\", arg, 0],\n                    [\"sdiv\", [\"sub\", arg, DECIMAL_DIVISOR - 1], DECIMAL_DIVISOR],\n                    [\"sdiv\", arg, DECIMAL_DIVISOR],\n                ],\n                typ=INT256_T,\n            )\n            return b1.resolve(ret)\n\n\nclass Ceil(BuiltinFunctionT):\n    _id = \"ceil\"\n    _inputs = [(\"value\", DecimalT())]\n    # TODO: maybe use int136?\n    _return_type = INT256_T\n\n    def _try_fold(self, node):\n        validate_call_args(node, 1)\n        value = node.args[0].get_folded_value()\n        if not isinstance(value, vy_ast.Decimal):\n            raise UnfoldableNode\n\n        value = math.ceil(value.value)\n        return vy_ast.Int.from_node(node, value=value)\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        arg = args[0]\n        with arg.cache_when_complex(\"arg\") as (b1, arg):\n            ret = IRnode.from_list(\n                [\n                    \"if\",\n                    [\"slt\", arg, 0],\n                    [\"sdiv\", arg, DECIMAL_DIVISOR],\n                    [\"sdiv\", [\"add\", arg, DECIMAL_DIVISOR - 1], DECIMAL_DIVISOR],\n                ],\n                typ=INT256_T,\n            )\n            return b1.resolve(ret)\n\n\nclass Convert(BuiltinFunctionT):\n    _id = \"convert\"\n\n    def fetch_call_return(self, node):\n        _, target_typedef = self.infer_arg_types(node)\n\n        # note: more type conversion validation happens in convert.py\n        return target_typedef.typedef\n\n    # TODO: push this down into convert.py for more consistency\n    def infer_arg_types(self, node, expected_return_typ=None):\n        validate_call_args(node, 2)\n\n        target_type = type_from_annotation(node.args[1])\n        value_types = get_possible_types_from_node(node.args[0])\n\n        # For `convert` of integer literals, we need to match type inference rules in\n        # convert.py codegen routines.\n        # TODO: This can probably be removed once constant folding for `convert` is implemented\n        if len(value_types) > 1 and all(isinstance(v, IntegerT) for v in value_types):\n            # Get the smallest (and unsigned if available) type for non-integer target types\n            # (note this is different from the ordering returned by `get_possible_types_from_node`)\n            if not isinstance(target_type, IntegerT):\n                value_types = sorted(value_types, key=lambda v: (v.is_signed, v.bits), reverse=True)\n            else:\n                # filter out the target type from list of possible types\n                value_types = [i for i in value_types if not target_type.compare_type(i)]\n\n        value_type = value_types.pop()\n\n        # block conversions between same type\n        if target_type.compare_type(value_type):\n            raise InvalidType(f\"Value and target type are both '{target_type}'\", node)\n\n        return [value_type, TYPE_T(target_type)]\n\n    def build_IR(self, expr, context):\n        return convert(expr, context)\n\n\nADHOC_SLICE_NODE_MACROS = [\"~calldata\", \"~selfcode\", \"~extcode\"]\n\n\ndef _build_adhoc_slice_node(sub: IRnode, start: IRnode, length: IRnode, context: Context) -> IRnode:\n    assert length.is_literal, \"typechecker failed\"\n    assert isinstance(length.value, int)  # mypy hint\n\n    dst_typ = BytesT(length.value)\n    # allocate a buffer for the return value\n    np = context.new_internal_variable(dst_typ)\n\n    # `msg.data` by `calldatacopy`\n    if sub.value == \"~calldata\":\n        node = [\n            \"seq\",\n            [\"assert\", [\"le\", [\"add\", start, length], \"calldatasize\"]],  # runtime bounds check\n            [\"mstore\", np, length],\n            [\"calldatacopy\", np + 32, start, length],\n            np,\n        ]\n\n    # `self.code` by `codecopy`\n    elif sub.value == \"~selfcode\":\n        node = [\n            \"seq\",\n            [\"assert\", [\"le\", [\"add\", start, length], \"codesize\"]],  # runtime bounds check\n            [\"mstore\", np, length],\n            [\"codecopy\", np + 32, start, length],\n            np,\n        ]\n\n    # `<address>.code` by `extcodecopy`\n    else:\n        assert sub.value == \"~extcode\" and len(sub.args) == 1\n        node = [\n            \"with\",\n            \"_extcode_address\",\n            sub.args[0],\n            [\n                \"seq\",\n                # runtime bounds check\n                [\"assert\", [\"le\", [\"add\", start, length], [\"extcodesize\", \"_extcode_address\"]]],\n                [\"mstore\", np, length],\n                [\"extcodecopy\", \"_extcode_address\", np + 32, start, length],\n                np,\n            ],\n        ]\n\n    assert isinstance(length.value, int)  # mypy hint\n    return IRnode.from_list(node, typ=BytesT(length.value), location=MEMORY)\n\n\n# note: this and a lot of other builtins could be refactored to accept any uint type\nclass Slice(BuiltinFunctionT):\n    _id = \"slice\"\n    _inputs = [\n        (\"b\", (BYTES32_T, BytesT.any(), StringT.any())),\n        (\"start\", UINT256_T),\n        (\"length\", UINT256_T),\n    ]\n\n    def fetch_call_return(self, node):\n        arg_type, _, _ = self.infer_arg_types(node)\n\n        if isinstance(arg_type, StringT):\n            return_type = StringT()\n        else:\n            return_type = BytesT()\n\n        # validate start and length are in bounds\n\n        arg = node.args[0]\n        start_expr = node.args[1]\n        length_expr = node.args[2]\n\n        # CMC 2022-03-22 NOTE slight code duplication with semantics/analysis/local\n        is_adhoc_slice = arg.get(\"attr\") == \"code\" or (\n            arg.get(\"value.id\") == \"msg\" and arg.get(\"attr\") == \"data\"\n        )\n\n        start_literal = start_expr.value if isinstance(start_expr, vy_ast.Int) else None\n        length_literal = length_expr.value if isinstance(length_expr, vy_ast.Int) else None\n\n        if not is_adhoc_slice:\n            if length_literal is not None:\n                if length_literal < 1:\n                    raise ArgumentException(\"Length cannot be less than 1\", length_expr)\n\n                if length_literal > arg_type.length:\n                    raise ArgumentException(f\"slice out of bounds for {arg_type}\", length_expr)\n\n            if start_literal is not None:\n                if start_literal > arg_type.length:\n                    raise ArgumentException(f\"slice out of bounds for {arg_type}\", start_expr)\n                if length_literal is not None and start_literal + length_literal > arg_type.length:\n                    raise ArgumentException(f\"slice out of bounds for {arg_type}\", node)\n\n        # we know the length statically\n        if length_literal is not None:\n            return_type.set_length(length_literal)\n        else:\n            return_type.set_min_length(arg_type.length)\n\n        return return_type\n\n    def infer_arg_types(self, node, expected_return_typ=None):\n        self._validate_arg_types(node)\n        # return a concrete type for `b`\n        b_type = get_possible_types_from_node(node.args[0]).pop()\n        return [b_type, self._inputs[1][1], self._inputs[2][1]]\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        src, start, length = args\n\n        # Handle `msg.data`, `self.code`, and `<address>.code`\n        if src.value in ADHOC_SLICE_NODE_MACROS:\n            return _build_adhoc_slice_node(src, start, length, context)\n\n        is_bytes32 = src.typ == BYTES32_T\n        if src.location is None:\n            # it's not a pointer; force it to be one since\n            # copy_bytes works on pointers.\n            assert is_bytes32, src\n            src = ensure_in_memory(src, context)\n\n        with src.cache_when_complex(\"src\") as (b1, src), start.cache_when_complex(\"start\") as (\n            b2,\n            start,\n        ), length.cache_when_complex(\"length\") as (b3, length):\n            if is_bytes32:\n                src_maxlen = 32\n            else:\n                src_maxlen = src.typ.maxlen\n\n            dst_maxlen = length.value if length.is_literal else src_maxlen\n\n            buflen = dst_maxlen\n\n            # add 32 bytes to the buffer size bc word access might\n            # be unaligned (see below)\n            if src.location == STORAGE:\n                buflen += 32\n\n            # Get returntype string or bytes\n            assert isinstance(src.typ, _BytestringT) or is_bytes32\n            # TODO: try to get dst_typ from semantic analysis\n            if isinstance(src.typ, StringT):\n                dst_typ = StringT(dst_maxlen)\n            else:\n                dst_typ = BytesT(dst_maxlen)\n\n            # allocate a buffer for the return value\n            buf = context.new_internal_variable(BytesT(buflen))\n            # assign it the correct return type.\n            # (note mismatch between dst_maxlen and buflen)\n            dst = IRnode.from_list(buf, typ=dst_typ, location=MEMORY)\n\n            dst_data = bytes_data_ptr(dst)\n\n            if is_bytes32:\n                src_len = 32\n                src_data = src\n            else:\n                src_len = get_bytearray_length(src)\n                src_data = bytes_data_ptr(src)\n\n            # general case. byte-for-byte copy\n            if src.location == STORAGE:\n                # because slice uses byte-addressing but storage\n                # is word-aligned, this algorithm starts at some number\n                # of bytes before the data section starts, and might copy\n                # an extra word. the pseudocode is:\n                #   dst_data = dst + 32\n                #   copy_dst = dst_data - start % 32\n                #   src_data = src + 32\n                #   copy_src = src_data + (start - start % 32) / 32\n                #            = src_data + (start // 32)\n                #   copy_bytes(copy_dst, copy_src, length)\n                #   //set length AFTER copy because the length word has been clobbered!\n                #   mstore(src, length)\n\n                # start at the first word-aligned address before `start`\n                # e.g. start == byte 7 -> we start copying from byte 0\n                #      start == byte 32 -> we start copying from byte 32\n                copy_src = IRnode.from_list(\n                    [\"add\", src_data, [\"div\", start, 32]], location=src.location\n                )\n\n                # e.g. start == byte 0 -> we copy to dst_data + 0\n                #      start == byte 7 -> we copy to dst_data - 7\n                #      start == byte 33 -> we copy to dst_data - 1\n                copy_dst = IRnode.from_list(\n                    [\"sub\", dst_data, [\"mod\", start, 32]], location=dst.location\n                )\n\n                # len + (32 if start % 32 > 0 else 0)\n                copy_len = [\"add\", length, [\"mul\", 32, [\"iszero\", [\"iszero\", [\"mod\", start, 32]]]]]\n                copy_maxlen = buflen\n\n            else:\n                # all other address spaces (mem, calldata, code) we have\n                # byte-aligned access so we can just do the easy thing,\n                # memcopy(dst_data, src_data + dst_data)\n\n                copy_src = add_ofst(src_data, start)\n                copy_dst = dst_data\n                copy_len = length\n                copy_maxlen = buflen\n\n            do_copy = copy_bytes(copy_dst, copy_src, copy_len, copy_maxlen)\n\n            ret = [\n                \"seq\",\n                # make sure we don't overrun the source buffer\n                [\"assert\", [\"le\", [\"add\", start, length], src_len]],  # bounds check\n                do_copy,\n                [\"mstore\", dst, length],  # set length\n                dst,  # return pointer to dst\n            ]\n            ret = IRnode.from_list(ret, typ=dst_typ, location=MEMORY)\n            return b1.resolve(b2.resolve(b3.resolve(ret)))\n\n\nclass Len(BuiltinFunctionT):\n    _id = \"len\"\n    _inputs = [(\"b\", (StringT.any(), BytesT.any(), DArrayT.any()))]\n    _return_type = UINT256_T\n\n    def _try_fold(self, node):\n        validate_call_args(node, 1)\n        arg = node.args[0].get_folded_value()\n        if isinstance(arg, (vy_ast.Str, vy_ast.Bytes)):\n            length = len(arg.value)\n        elif isinstance(arg, vy_ast.Hex):\n            length = len(arg.bytes_value)\n        else:\n            raise UnfoldableNode\n\n        return vy_ast.Int.from_node(node, value=length)\n\n    def infer_arg_types(self, node, expected_return_typ=None):\n        self._validate_arg_types(node)\n        # return a concrete type\n        typ = get_possible_types_from_node(node.args[0]).pop()\n        return [typ]\n\n    def build_IR(self, node, context):\n        arg = Expr(node.args[0], context).ir_node\n        if arg.value == \"~calldata\":\n            return IRnode.from_list([\"calldatasize\"], typ=UINT256_T)\n        return get_bytearray_length(arg)\n\n\nclass Concat(BuiltinFunctionT):\n    _id = \"concat\"\n\n    def fetch_call_return(self, node):\n        arg_types = self.infer_arg_types(node)\n\n        length = 0\n        for arg_t in arg_types:\n            length += arg_t.length\n\n        if isinstance(arg_types[0], (StringT)):\n            return_type = StringT()\n        else:\n            return_type = BytesT()\n        return_type.set_length(length)\n        return return_type\n\n    def infer_arg_types(self, node, expected_return_typ=None):\n        if len(node.args) < 2:\n            raise ArgumentException(\"Invalid argument count: expected at least 2\", node)\n\n        if node.keywords:\n            raise ArgumentException(\"Keyword arguments are not accepted here\", node.keywords[0])\n\n        ret = []\n        prev_typeclass = None\n        for arg in node.args:\n            validate_expected_type(arg, (BytesT.any(), StringT.any(), BytesM_T.any()))\n            arg_t = get_possible_types_from_node(arg).pop()\n            current_typeclass = \"String\" if isinstance(arg_t, StringT) else \"Bytes\"\n            if prev_typeclass and current_typeclass != prev_typeclass:\n                raise TypeMismatch(\n                    (\n                        \"Concat expects consistent use of string or bytes types, \"\n                        \"use either string or bytes.\"\n                    ),\n                    arg,\n                )\n            prev_typeclass = current_typeclass\n            ret.append(arg_t)\n\n        return ret\n\n    def build_IR(self, expr, context):\n        args = [Expr(arg, context).ir_node for arg in expr.args]\n        if len(args) < 2:\n            raise StructureException(\"Concat expects at least two arguments\", expr)\n\n        # Maximum length of the output\n        dst_maxlen = sum(\n            [arg.typ.maxlen if isinstance(arg.typ, _BytestringT) else arg.typ.m for arg in args]\n        )\n\n        # TODO: try to grab these from semantic analysis\n        if isinstance(args[0].typ, StringT):\n            ret_typ = StringT(dst_maxlen)\n        else:\n            ret_typ = BytesT(dst_maxlen)\n\n        # respect API of copy_bytes\n        bufsize = dst_maxlen + 32\n        buf = context.new_internal_variable(BytesT(bufsize))\n\n        # Node representing the position of the output in memory\n        dst = IRnode.from_list(buf, typ=ret_typ, location=MEMORY, annotation=\"concat destination\")\n\n        ret = [\"seq\"]\n        # stack item representing our current offset in the dst buffer\n        ofst = \"concat_ofst\"\n\n        # TODO: optimize for the case where all lengths are statically known.\n        for arg in args:\n            dst_data = add_ofst(bytes_data_ptr(dst), ofst)\n\n            if isinstance(arg.typ, _BytestringT):\n                # Ignore empty strings\n                if arg.typ.maxlen == 0:\n                    continue\n\n                with arg.cache_when_complex(\"arg\") as (b1, arg):\n                    argdata = bytes_data_ptr(arg)\n\n                    with get_bytearray_length(arg).cache_when_complex(\"len\") as (b2, arglen):\n                        do_copy = [\n                            \"seq\",\n                            copy_bytes(dst_data, argdata, arglen, arg.typ.maxlen),\n                            [\"set\", ofst, [\"add\", ofst, arglen]],\n                        ]\n                        ret.append(b1.resolve(b2.resolve(do_copy)))\n\n            else:\n                ret.append(STORE(dst_data, unwrap_location(arg)))\n                ret.append([\"set\", ofst, [\"add\", ofst, arg.typ.m]])\n\n        ret.append(STORE(dst, ofst))\n\n        # Memory location of the output\n        ret.append(dst)\n\n        return IRnode.from_list(\n            [\"with\", ofst, 0, ret], typ=ret_typ, location=MEMORY, annotation=\"concat\"\n        )\n\n\nclass Keccak256(BuiltinFunctionT):\n    _id = \"keccak256\"\n    # TODO allow any BytesM_T\n    _inputs = [(\"value\", (BytesT.any(), BYTES32_T, StringT.any()))]\n    _return_type = BYTES32_T\n\n    def _try_fold(self, node):\n        validate_call_args(node, 1)\n        value = node.args[0].get_folded_value()\n        if isinstance(value, vy_ast.Bytes):\n            value = value.value\n        elif isinstance(value, vy_ast.Str):\n            value = value.value.encode()\n        elif isinstance(value, vy_ast.Hex):\n            value = value.bytes_value\n        else:\n            raise UnfoldableNode\n\n        hash_ = f\"0x{keccak256(value).hex()}\"\n        return vy_ast.Hex.from_node(node, value=hash_)\n\n    def infer_arg_types(self, node, expected_return_typ=None):\n        self._validate_arg_types(node)\n        # return a concrete type for `value`\n        value_type = get_possible_types_from_node(node.args[0]).pop()\n        return [value_type]\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        assert len(args) == 1\n        return keccak256_helper(args[0], context)\n\n\ndef _make_sha256_call(inp_start, inp_len, out_start, out_len):\n    return [\n        \"assert\",\n        [\n            \"staticcall\",\n            [\"gas\"],  # gas\n            SHA256_ADDRESS,  # address\n            inp_start,\n            inp_len,\n            out_start,\n            out_len,\n        ],\n    ]\n\n\nclass Sha256(BuiltinFunctionT):\n    _id = \"sha256\"\n    _inputs = [(\"value\", (BYTES32_T, BytesT.any(), StringT.any()))]\n    _return_type = BYTES32_T\n\n    def _try_fold(self, node):\n        validate_call_args(node, 1)\n        value = node.args[0].get_folded_value()\n        if isinstance(value, vy_ast.Bytes):\n            value = value.value\n        elif isinstance(value, vy_ast.Str):\n            value = value.value.encode()\n        elif isinstance(value, vy_ast.Hex):\n            value = value.bytes_value\n        else:\n            raise UnfoldableNode\n\n        hash_ = f\"0x{hashlib.sha256(value).hexdigest()}\"\n        return vy_ast.Hex.from_node(node, value=hash_)\n\n    def infer_arg_types(self, node, expected_return_typ=None):\n        self._validate_arg_types(node)\n        # return a concrete type for `value`\n        value_type = get_possible_types_from_node(node.args[0]).pop()\n        return [value_type]\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        sub = args[0]\n        # bytes32 input\n        if sub.typ == BYTES32_T:\n            return IRnode.from_list(\n                [\n                    \"seq\",\n                    [\"mstore\", MemoryPositions.FREE_VAR_SPACE, sub],\n                    _make_sha256_call(\n                        inp_start=MemoryPositions.FREE_VAR_SPACE,\n                        inp_len=32,\n                        out_start=MemoryPositions.FREE_VAR_SPACE,\n                        out_len=32,\n                    ),\n                    [\"mload\", MemoryPositions.FREE_VAR_SPACE],  # push value onto stack\n                ],\n                typ=BYTES32_T,\n                add_gas_estimate=SHA256_BASE_GAS + 1 * SHA256_PER_WORD_GAS,\n            )\n        # bytearay-like input\n        # special case if it's already in memory\n        sub = ensure_in_memory(sub, context)\n\n        return IRnode.from_list(\n            [\n                \"with\",\n                \"_sub\",\n                sub,\n                [\n                    \"seq\",\n                    _make_sha256_call(\n                        # TODO use add_ofst if sub is statically known\n                        inp_start=[\"add\", \"_sub\", 32],\n                        inp_len=[\"mload\", \"_sub\"],\n                        out_start=MemoryPositions.FREE_VAR_SPACE,\n                        out_len=32,\n                    ),\n                    [\"mload\", MemoryPositions.FREE_VAR_SPACE],\n                ],\n            ],\n            typ=BYTES32_T,\n            add_gas_estimate=SHA256_BASE_GAS + sub.typ.maxlen * SHA256_PER_WORD_GAS,\n        )\n\n\nclass MethodID(FoldedFunctionT):\n    _id = \"method_id\"\n    _inputs = [(\"value\", StringT.any())]\n    _kwargs = {\"output_type\": KwargSettings(\"TYPE_DEFINITION\", BytesT(4))}\n\n    def _try_fold(self, node):\n        validate_call_args(node, 1, [\"output_type\"])\n\n        value = node.args[0].get_folded_value()\n        if not isinstance(value, vy_ast.Str):\n            raise InvalidType(\"method id must be given as a literal string\", node.args[0])\n        if \" \" in value.value:\n            raise InvalidLiteral(\"Invalid function signature - no spaces allowed.\", node.args[0])\n\n        return_type = self.infer_kwarg_types(node)[\"output_type\"].typedef\n        value = method_id(value.value)\n\n        if return_type.compare_type(BYTES4_T):\n            return vy_ast.Hex.from_node(node, value=\"0x\" + value.hex())\n        else:\n            return vy_ast.Bytes.from_node(node, value=value)\n\n    def fetch_call_return(self, node):\n        validate_call_args(node, 1, [\"output_type\"])\n\n        type_ = self.infer_kwarg_types(node)[\"output_type\"].typedef\n        return type_\n\n    def infer_arg_types(self, node, expected_return_typ=None):\n        return [self._inputs[0][1]]\n\n    def infer_kwarg_types(self, node):\n        if node.keywords:\n            output_type = type_from_annotation(node.keywords[0].value)\n            if output_type not in (BytesT(4), BYTES4_T):\n                raise ArgumentException(\"output_type must be Bytes[4] or bytes4\", node.keywords[0])\n        else:\n            # default to `Bytes[4]`\n            output_type = BytesT(4)\n\n        return {\"output_type\": TYPE_T(output_type)}\n\n\nclass ECRecover(BuiltinFunctionT):\n    _id = \"ecrecover\"\n    _inputs = [\n        (\"hash\", BYTES32_T),\n        (\"v\", (UINT256_T, UINT8_T)),\n        (\"r\", (UINT256_T, BYTES32_T)),\n        (\"s\", (UINT256_T, BYTES32_T)),\n    ]\n    _return_type = AddressT()\n\n    def infer_arg_types(self, node, expected_return_typ=None):\n        self._validate_arg_types(node)\n        v_t, r_t, s_t = [get_possible_types_from_node(arg).pop() for arg in node.args[1:]]\n        return [BYTES32_T, v_t, r_t, s_t]\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        input_buf = context.new_internal_variable(get_type_for_exact_size(128))\n        output_buf = context.new_internal_variable(get_type_for_exact_size(32))\n        return IRnode.from_list(\n            [\n                \"seq\",\n                # clear output memory first, ecrecover can return 0 bytes\n                [\"mstore\", output_buf, 0],\n                [\"mstore\", input_buf, args[0]],\n                [\"mstore\", input_buf + 32, args[1]],\n                [\"mstore\", input_buf + 64, args[2]],\n                [\"mstore\", input_buf + 96, args[3]],\n                [\"staticcall\", \"gas\", 1, input_buf, 128, output_buf, 32],\n                [\"mload\", output_buf],\n            ],\n            typ=AddressT(),\n        )\n\n\nclass _ECArith(BuiltinFunctionT):\n    @process_inputs\n    def build_IR(self, expr, _args, kwargs, context):\n        args_tuple = ir_tuple_from_args(_args)\n\n        args_t = args_tuple.typ\n        input_buf = IRnode.from_list(\n            context.new_internal_variable(args_t), typ=args_t, location=MEMORY\n        )\n        ret_t = self._return_type\n\n        ret = [\"seq\"]\n        ret.append(make_setter(input_buf, args_tuple))\n\n        output_buf = context.new_internal_variable(ret_t)\n\n        args_ofst = input_buf\n        args_len = args_t.memory_bytes_required\n        out_ofst = output_buf\n        out_len = ret_t.memory_bytes_required\n\n        ret.append(\n            [\n                \"assert\",\n                [\"staticcall\", [\"gas\"], self._precompile, args_ofst, args_len, out_ofst, out_len],\n            ]\n        )\n        ret.append(output_buf)\n\n        return IRnode.from_list(ret, typ=ret_t, location=MEMORY)\n\n\nclass ECAdd(_ECArith):\n    _id = \"ecadd\"\n    _inputs = [(\"a\", SArrayT(UINT256_T, 2)), (\"b\", SArrayT(UINT256_T, 2))]\n    _return_type = SArrayT(UINT256_T, 2)\n    _precompile = 0x6\n\n\nclass ECMul(_ECArith):\n    _id = \"ecmul\"\n    _inputs = [(\"point\", SArrayT(UINT256_T, 2)), (\"scalar\", UINT256_T)]\n    _return_type = SArrayT(UINT256_T, 2)\n    _precompile = 0x7\n\n\ndef _generic_element_getter(op):\n    def f(index):\n        return IRnode.from_list(\n            [op, [\"add\", \"_sub\", [\"add\", 32, [\"mul\", 32, index]]]], typ=INT128_T\n        )\n\n    return f\n\n\ndef _storage_element_getter(index):\n    return IRnode.from_list([\"sload\", [\"add\", \"_sub\", [\"add\", 1, index]]], typ=INT128_T)\n\n\nclass Extract32(BuiltinFunctionT):\n    _id = \"extract32\"\n    _inputs = [(\"b\", BytesT.any()), (\"start\", IntegerT.unsigneds())]\n    # \"TYPE_DEFINITION\" is a placeholder value for a type definition string, and\n    # will be replaced by a `TYPE_T` object in `infer_kwarg_types`\n    # (note that it is ignored in _validate_arg_types)\n    _kwargs = {\"output_type\": KwargSettings(\"TYPE_DEFINITION\", BYTES32_T)}\n\n    def fetch_call_return(self, node):\n        self._validate_arg_types(node)\n        return_type = self.infer_kwarg_types(node)[\"output_type\"].typedef\n        return return_type\n\n    def infer_arg_types(self, node, expected_return_typ=None):\n        self._validate_arg_types(node)\n        input_type = get_possible_types_from_node(node.args[0]).pop()\n        return [input_type, UINT256_T]\n\n    def infer_kwarg_types(self, node):\n        if node.keywords:\n            output_type = type_from_annotation(node.keywords[0].value)\n            if not isinstance(output_type, (AddressT, BytesM_T, IntegerT)):\n                raise InvalidType(\n                    \"Output type must be one of integer, bytes32 or address\", node.keywords[0].value\n                )\n            output_typedef = TYPE_T(output_type)\n            node.keywords[0].value._metadata[\"type\"] = output_typedef\n        else:\n            output_typedef = TYPE_T(BYTES32_T)\n\n        return {\"output_type\": output_typedef}\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        sub, index = args\n        ret_type = kwargs[\"output_type\"]\n\n        # Get length and specific element\n        if sub.location == STORAGE:\n            lengetter = IRnode.from_list([\"sload\", \"_sub\"], typ=INT128_T)\n            elementgetter = _storage_element_getter\n\n        else:\n            op = sub.location.load_op\n            lengetter = IRnode.from_list([op, \"_sub\"], typ=INT128_T)\n            elementgetter = _generic_element_getter(op)\n\n        # TODO rewrite all this with cache_when_complex and bitshifts\n\n        # Special case: index known to be a multiple of 32\n        if isinstance(index.value, int) and not index.value % 32:\n            o = IRnode.from_list(\n                [\n                    \"with\",\n                    \"_sub\",\n                    sub,\n                    elementgetter(\n                        [\"div\", clamp2(0, index, [\"sub\", lengetter, 32], signed=True), 32]\n                    ),\n                ],\n                typ=ret_type,\n                annotation=\"extracting 32 bytes\",\n            )\n        # General case\n        else:\n            o = IRnode.from_list(\n                [\n                    \"with\",\n                    \"_sub\",\n                    sub,\n                    [\n                        \"with\",\n                        \"_len\",\n                        lengetter,\n                        [\n                            \"with\",\n                            \"_index\",\n                            clamp2(0, index, [\"sub\", \"_len\", 32], signed=True),\n                            [\n                                \"with\",\n                                \"_mi32\",\n                                [\"mod\", \"_index\", 32],\n                                [\n                                    \"with\",\n                                    \"_di32\",\n                                    [\"div\", \"_index\", 32],\n                                    [\n                                        \"if\",\n                                        \"_mi32\",\n                                        [\n                                            \"add\",\n                                            [\"mul\", elementgetter(\"_di32\"), [\"exp\", 256, \"_mi32\"]],\n                                            [\n                                                \"div\",\n                                                elementgetter([\"add\", \"_di32\", 1]),\n                                                [\"exp\", 256, [\"sub\", 32, \"_mi32\"]],\n                                            ],\n                                        ],\n                                        elementgetter(\"_di32\"),\n                                    ],\n                                ],\n                            ],\n                        ],\n                    ],\n                ],\n                typ=ret_type,\n                annotation=\"extract32\",\n            )\n        return IRnode.from_list(clamp_basetype(o), typ=ret_type)\n\n\nclass AsWeiValue(BuiltinFunctionT):\n    _id = \"as_wei_value\"\n    _inputs = [(\"value\", (IntegerT.any(), DecimalT())), (\"unit\", StringT.any())]\n    _return_type = UINT256_T\n\n    wei_denoms = {\n        (\"wei\",): 1,\n        (\"femtoether\", \"kwei\", \"babbage\"): 10**3,\n        (\"picoether\", \"mwei\", \"lovelace\"): 10**6,\n        (\"nanoether\", \"gwei\", \"shannon\"): 10**9,\n        (\"microether\", \"szabo\"): 10**12,\n        (\"milliether\", \"finney\"): 10**15,\n        (\"ether\",): 10**18,\n        (\"kether\", \"grand\"): 10**21,\n    }\n\n    def get_denomination(self, node):\n        value = node.args[1].get_folded_value()\n        if not isinstance(value, vy_ast.Str):\n            raise ArgumentException(\n                \"Wei denomination must be given as a literal string\", node.args[1]\n            )\n        try:\n            denom = next(v for k, v in self.wei_denoms.items() if value.value in k)\n        except StopIteration:\n            raise ArgumentException(f\"Unknown denomination: {value.value}\", node.args[1]) from None\n\n        return denom\n\n    def _try_fold(self, node):\n        validate_call_args(node, 2)\n        denom = self.get_denomination(node)\n\n        value = node.args[0].get_folded_value()\n        if not isinstance(value, (vy_ast.Decimal, vy_ast.Int)):\n            raise UnfoldableNode\n        value = value.value\n\n        if value < 0:\n            raise InvalidLiteral(\"Negative wei value not allowed\", node.args[0])\n\n        return vy_ast.Int.from_node(node, value=int(value * denom))\n\n    def fetch_call_return(self, node):\n        self.infer_arg_types(node)\n        return self._return_type\n\n    def infer_arg_types(self, node, expected_return_typ=None):\n        self._validate_arg_types(node)\n        # return a concrete type instead of abstract type\n        value_type = get_possible_types_from_node(node.args[0]).pop()\n        unit_type = get_possible_types_from_node(node.args[1]).pop()\n        return [value_type, unit_type]\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        value = args[0]\n\n        denom_divisor = self.get_denomination(expr)\n        with value.cache_when_complex(\"value\") as (b1, value):\n            if value.typ in (UINT256_T, UINT8_T):\n                sub = [\n                    \"with\",\n                    \"ans\",\n                    [\"mul\", value, denom_divisor],\n                    [\n                        \"seq\",\n                        [\n                            \"assert\",\n                            [\"or\", [\"eq\", [\"div\", \"ans\", value], denom_divisor], [\"iszero\", value]],\n                        ],\n                        \"ans\",\n                    ],\n                ]\n            elif value.typ == INT128_T:\n                # signed types do not require bounds checks because the\n                # largest possible converted value will not overflow 2**256\n                sub = [\"seq\", [\"assert\", [\"sgt\", value, -1]], [\"mul\", value, denom_divisor]]\n            elif value.typ == DecimalT():\n                sub = [\n                    \"seq\",\n                    [\"assert\", [\"sgt\", value, -1]],\n                    [\"div\", [\"mul\", value, denom_divisor], DECIMAL_DIVISOR],\n                ]\n            else:\n                raise CompilerPanic(f\"Unexpected type: {value.typ}\")\n\n            return IRnode.from_list(b1.resolve(sub), typ=UINT256_T)\n\n\nzero_value = IRnode.from_list(0, typ=UINT256_T)\nempty_value = IRnode.from_list(0, typ=BYTES32_T)\n\n\nclass RawCall(BuiltinFunctionT):\n    _id = \"raw_call\"\n    _inputs = [(\"to\", AddressT()), (\"data\", BytesT.any())]\n    _kwargs = {\n        \"max_outsize\": KwargSettings(UINT256_T, 0, require_literal=True),\n        \"gas\": KwargSettings(UINT256_T, \"gas\"),\n        \"value\": KwargSettings(UINT256_T, zero_value),\n        \"is_delegate_call\": KwargSettings(BoolT(), False, require_literal=True),\n        \"is_static_call\": KwargSettings(BoolT(), False, require_literal=True),\n        \"revert_on_failure\": KwargSettings(BoolT(), True, require_literal=True),\n    }\n\n    def fetch_call_return(self, node):\n        self._validate_arg_types(node)\n\n        kwargz = {i.arg: i.value for i in node.keywords}\n\n        outsize = kwargz.get(\"max_outsize\")\n        if outsize is not None:\n            outsize = outsize.get_folded_value()\n\n        revert_on_failure = kwargz.get(\"revert_on_failure\")\n        if revert_on_failure is not None:\n            revert_on_failure = revert_on_failure.get_folded_value().value\n        else:\n            revert_on_failure = True\n\n        if outsize is None or outsize.value == 0:\n            if revert_on_failure:\n                return None\n            return BoolT()\n\n        if not isinstance(outsize, vy_ast.Int) or outsize.value < 0:\n            raise\n\n        if outsize.value:\n            return_type = BytesT()\n            return_type.set_min_length(outsize.value)\n\n            if revert_on_failure:\n                return return_type\n            return TupleT([BoolT(), return_type])\n\n    def infer_arg_types(self, node, expected_return_typ=None):\n        self._validate_arg_types(node)\n        # return a concrete type for `data`\n        data_type = get_possible_types_from_node(node.args[1]).pop()\n        return [self._inputs[0][1], data_type]\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        to, data = args\n        # TODO: must compile in source code order, left-to-right\n        gas, value, outsize, delegate_call, static_call, revert_on_failure = (\n            kwargs[\"gas\"],\n            kwargs[\"value\"],\n            kwargs[\"max_outsize\"],\n            kwargs[\"is_delegate_call\"],\n            kwargs[\"is_static_call\"],\n            kwargs[\"revert_on_failure\"],\n        )\n\n        if delegate_call and static_call:\n            raise ArgumentException(\n                \"Call may use one of `is_delegate_call` or `is_static_call`, not both\", expr\n            )\n        if not static_call and context.is_constant():\n            raise StateAccessViolation(\n                f\"Cannot make modifying calls from {context.pp_constancy()},\"\n                \" use `is_static_call=True` to perform this action\",\n                expr,\n            )\n\n        if data.value == \"~calldata\":\n            call_ir = [\"with\", \"mem_ofst\", \"msize\"]\n            args_ofst = [\"seq\", [\"calldatacopy\", \"mem_ofst\", 0, \"calldatasize\"], \"mem_ofst\"]\n            args_len = \"calldatasize\"\n        else:\n            # some gymnastics to propagate constants (if eval_input_buf\n            # returns a static memory location)\n            eval_input_buf = ensure_in_memory(data, context)\n\n            input_buf = eval_seq(eval_input_buf)\n\n            if input_buf is None:\n                call_ir = [\"with\", \"arg_buf\", eval_input_buf]\n                input_buf = IRnode.from_list(\"arg_buf\")\n            else:\n                call_ir = [\"seq\", eval_input_buf]\n\n            args_ofst = add_ofst(input_buf, 32)\n            args_len = [\"mload\", input_buf]\n\n        output_node = IRnode.from_list(\n            context.new_internal_variable(BytesT(outsize)), typ=BytesT(outsize), location=MEMORY\n        )\n\n        bool_ty = BoolT()\n\n        # build IR for call or delegatecall\n        common_call_args = [\n            args_ofst,\n            args_len,\n            # if there is no return value, the return offset can be 0\n            add_ofst(output_node, 32) if outsize else 0,\n            outsize,\n        ]\n\n        gas, value = IRnode.from_list(gas), IRnode.from_list(value)\n        with scope_multi((to, value, gas), (\"_to\", \"_value\", \"_gas\")) as (b1, (to, value, gas)):\n            if delegate_call:\n                call_op = [\"delegatecall\", gas, to, *common_call_args]\n            elif static_call:\n                call_op = [\"staticcall\", gas, to, *common_call_args]\n            else:\n                call_op = [\"call\", gas, to, value, *common_call_args]\n\n            call_ir += [call_op]\n            call_ir = b1.resolve(call_ir)\n\n        # build sequence IR\n        if outsize:\n            # return minimum of outsize and returndatasize\n            size = [\"select\", [\"lt\", outsize, \"returndatasize\"], outsize, \"returndatasize\"]\n\n            # store output size and return output location\n            store_output_size = [\"seq\", [\"mstore\", output_node, size], output_node]\n\n            bytes_ty = BytesT(outsize)\n\n            if revert_on_failure:\n                typ = bytes_ty\n                # check the call success flag, and store returndata in memory\n                ret_ir = [\"seq\", check_external_call(call_ir), store_output_size]\n                return IRnode.from_list(ret_ir, typ=typ, location=MEMORY)\n            else:\n                typ = TupleT([bool_ty, bytes_ty])\n                ret_ir = [\n                    \"multi\",\n                    # use IRnode.from_list to make sure the types are\n                    # set properly on the \"multi\" members\n                    IRnode.from_list(call_ir, typ=bool_ty),\n                    IRnode.from_list(store_output_size, typ=bytes_ty, location=MEMORY),\n                ]\n                # return an IR tuple of call success flag and returndata pointer\n                return IRnode.from_list(ret_ir, typ=typ)\n\n        # max_outsize is 0.\n\n        if not revert_on_failure:\n            # return call flag as stack item\n            typ = bool_ty\n            return IRnode.from_list(call_ir, typ=typ)\n\n        else:\n            # check the call success flag and don't return anything\n            ret_ir = check_external_call(call_ir)\n            return IRnode.from_list(ret_ir, typ=None)\n\n        raise CompilerPanic(\"unreachable!\")\n\n\nclass Send(BuiltinFunctionT):\n    _id = \"send\"\n    _inputs = [(\"to\", AddressT()), (\"value\", UINT256_T)]\n    # default gas stipend is 0\n    _kwargs = {\"gas\": KwargSettings(UINT256_T, 0)}\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        to, value = args\n        gas = kwargs[\"gas\"]\n        context.check_is_not_constant(\"send ether\", expr)\n        return IRnode.from_list(\n            [\"assert\", [\"call\", gas, to, value, 0, 0, 0, 0]], error_msg=\"send failed\"\n        )\n\n\nclass SelfDestruct(BuiltinFunctionT):\n    _id = \"selfdestruct\"\n    _inputs = [(\"to\", AddressT())]\n    _is_terminus = True\n    _warned = False\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        if not self._warned:\n            vyper_warn(\"`selfdestruct` is deprecated! The opcode is no longer recommended for use.\")\n            self._warned = True\n\n        context.check_is_not_constant(\"selfdestruct\", expr)\n        return IRnode.from_list(\n            [\"seq\", eval_once_check(_freshname(\"selfdestruct\")), [\"selfdestruct\", args[0]]]\n        )\n\n\nclass BlockHash(BuiltinFunctionT):\n    _id = \"blockhash\"\n    _inputs = [(\"block_num\", UINT256_T)]\n    _return_type = BYTES32_T\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, contact):\n        return IRnode.from_list(\n            [\"blockhash\", clamp(\"lt\", clamp(\"sge\", args[0], [\"sub\", [\"number\"], 256]), \"number\")],\n            typ=BYTES32_T,\n        )\n\n\nclass RawRevert(BuiltinFunctionT):\n    _id = \"raw_revert\"\n    _inputs = [(\"data\", BytesT.any())]\n    _return_type = None\n    _is_terminus = True\n\n    def fetch_call_return(self, node):\n        return None\n\n    def infer_arg_types(self, node, expected_return_typ=None):\n        self._validate_arg_types(node)\n        data_type = get_possible_types_from_node(node.args[0]).pop()\n        return [data_type]\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        with ensure_in_memory(args[0], context).cache_when_complex(\"err_buf\") as (b, buf):\n            data = bytes_data_ptr(buf)\n            len_ = get_bytearray_length(buf)\n            return b.resolve(IRnode.from_list([\"revert\", data, len_]))\n\n\nclass RawLog(BuiltinFunctionT):\n    _id = \"raw_log\"\n    _inputs = [(\"topics\", DArrayT(BYTES32_T, 4)), (\"data\", (BYTES32_T, BytesT.any()))]\n\n    def fetch_call_return(self, node):\n        self.infer_arg_types(node)\n\n    def infer_arg_types(self, node, expected_return_typ=None):\n        self._validate_arg_types(node)\n\n        if not isinstance(node.args[0], vy_ast.List) or len(node.args[0].elements) > 4:\n            raise InvalidType(\"Expecting a list of 0-4 topics as first argument\", node.args[0])\n\n        # return a concrete type for `data`\n        data_type = get_possible_types_from_node(node.args[1]).pop()\n\n        return [self._inputs[0][1], data_type]\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        topics_length = len(expr.args[0].elements)\n        topics = args[0].args\n\n        # sanity check topics is a literal list\n        assert args[0].value in (\"~empty\", \"multi\")\n\n        data = args[1]\n\n        if data.typ == BYTES32_T:\n            placeholder = context.new_internal_variable(BYTES32_T)\n            return IRnode.from_list(\n                [\n                    \"seq\",\n                    # TODO use make_setter\n                    [\"mstore\", placeholder, unwrap_location(data)],\n                    [\"log\" + str(topics_length), placeholder, 32] + topics,\n                ]\n            )\n\n        input_buf = ensure_in_memory(data, context)\n\n        return IRnode.from_list(\n            [\n                \"with\",\n                \"_sub\",\n                input_buf,\n                [\"log\" + str(topics_length), [\"add\", \"_sub\", 32], [\"mload\", \"_sub\"], *topics],\n            ]\n        )\n\n\nclass BitwiseAnd(BuiltinFunctionT):\n    _id = \"bitwise_and\"\n    _inputs = [(\"x\", UINT256_T), (\"y\", UINT256_T)]\n    _return_type = UINT256_T\n    _warned = False\n\n    def _try_fold(self, node):\n        if not self.__class__._warned:\n            vyper_warn(\"`bitwise_and()` is deprecated! Please use the & operator instead.\")\n            self.__class__._warned = True\n\n        validate_call_args(node, 2)\n        values = [i.get_folded_value() for i in node.args]\n        for val in values:\n            if not isinstance(val, vy_ast.Int):\n                raise UnfoldableNode\n\n        value = values[0].value & values[1].value\n        return vy_ast.Int.from_node(node, value=value)\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        return IRnode.from_list([\"and\", args[0], args[1]], typ=UINT256_T)\n\n\nclass BitwiseOr(BuiltinFunctionT):\n    _id = \"bitwise_or\"\n    _inputs = [(\"x\", UINT256_T), (\"y\", UINT256_T)]\n    _return_type = UINT256_T\n    _warned = False\n\n    def _try_fold(self, node):\n        if not self.__class__._warned:\n            vyper_warn(\"`bitwise_or()` is deprecated! Please use the | operator instead.\")\n            self.__class__._warned = True\n\n        validate_call_args(node, 2)\n        values = [i.get_folded_value() for i in node.args]\n        for val in values:\n            if not isinstance(val, vy_ast.Int):\n                raise UnfoldableNode\n\n        value = values[0].value | values[1].value\n        return vy_ast.Int.from_node(node, value=value)\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        return IRnode.from_list([\"or\", args[0], args[1]], typ=UINT256_T)\n\n\nclass BitwiseXor(BuiltinFunctionT):\n    _id = \"bitwise_xor\"\n    _inputs = [(\"x\", UINT256_T), (\"y\", UINT256_T)]\n    _return_type = UINT256_T\n    _warned = False\n\n    def _try_fold(self, node):\n        if not self.__class__._warned:\n            vyper_warn(\"`bitwise_xor()` is deprecated! Please use the ^ operator instead.\")\n            self.__class__._warned = True\n\n        validate_call_args(node, 2)\n        values = [i.get_folded_value() for i in node.args]\n        for val in values:\n            if not isinstance(val, vy_ast.Int):\n                raise UnfoldableNode\n\n        value = values[0].value ^ values[1].value\n        return vy_ast.Int.from_node(node, value=value)\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        return IRnode.from_list([\"xor\", args[0], args[1]], typ=UINT256_T)\n\n\nclass BitwiseNot(BuiltinFunctionT):\n    _id = \"bitwise_not\"\n    _inputs = [(\"x\", UINT256_T)]\n    _return_type = UINT256_T\n    _warned = False\n\n    def _try_fold(self, node):\n        if not self.__class__._warned:\n            vyper_warn(\"`bitwise_not()` is deprecated! Please use the ~ operator instead.\")\n            self.__class__._warned = True\n\n        validate_call_args(node, 1)\n        value = node.args[0].get_folded_value()\n        if not isinstance(value, vy_ast.Int):\n            raise UnfoldableNode\n\n        value = value.value\n\n        value = (2**256 - 1) - value\n        return vy_ast.Int.from_node(node, value=value)\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        return IRnode.from_list([\"not\", args[0]], typ=UINT256_T)\n\n\nclass Shift(BuiltinFunctionT):\n    _id = \"shift\"\n    _inputs = [(\"x\", (UINT256_T, INT256_T)), (\"_shift_bits\", IntegerT.any())]\n    _return_type = UINT256_T\n    _warned = False\n\n    def _try_fold(self, node):\n        if not self.__class__._warned:\n            vyper_warn(\"`shift()` is deprecated! Please use the << or >> operator instead.\")\n            self.__class__._warned = True\n\n        validate_call_args(node, 2)\n        args = [i.get_folded_value() for i in node.args]\n        if any(not isinstance(i, vy_ast.Int) for i in args):\n            raise UnfoldableNode\n        value, shift = [i.value for i in args]\n        if shift < -256 or shift > 256:\n            # this validation is performed to prevent the compiler from hanging\n            # rather than for correctness because the post-folded constant would\n            # have been validated anyway\n            raise InvalidLiteral(\"Shift must be between -256 and 256\", node.args[1])\n\n        if shift < 0:\n            value = value >> -shift\n        else:\n            value = (value << shift) % (2**256)\n        return vy_ast.Int.from_node(node, value=value)\n\n    def fetch_call_return(self, node):\n        # return type is the type of the first argument\n        return self.infer_arg_types(node)[0]\n\n    def infer_arg_types(self, node, expected_return_typ=None):\n        self._validate_arg_types(node)\n        # return a concrete type instead of SignedIntegerAbstractType\n        arg_ty = get_possible_types_from_node(node.args[0])[0]\n        shift_ty = get_possible_types_from_node(node.args[1])[0]\n        return [arg_ty, shift_ty]\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        # \"gshr\" -- generalized right shift\n        argty = args[0].typ\n        GSHR = sar if argty.is_signed else shr\n\n        with args[0].cache_when_complex(\"to_shift\") as (b1, arg), args[1].cache_when_complex(\n            \"bits\"\n        ) as (b2, bits):\n            neg_bits = [\"sub\", 0, bits]\n            ret = [\"if\", [\"slt\", bits, 0], GSHR(neg_bits, arg), shl(bits, arg)]\n            return b1.resolve(b2.resolve(IRnode.from_list(ret, typ=argty)))\n\n\nclass _AddMulMod(BuiltinFunctionT):\n    _inputs = [(\"a\", UINT256_T), (\"b\", UINT256_T), (\"c\", UINT256_T)]\n    _return_type = UINT256_T\n\n    def _try_fold(self, node):\n        validate_call_args(node, 3)\n        args = [i.get_folded_value() for i in node.args]\n        if isinstance(args[2], vy_ast.Int) and args[2].value == 0:\n            raise ZeroDivisionException(\"Modulo by 0\", node.args[2])\n        for arg in args:\n            if not isinstance(arg, vy_ast.Int):\n                raise UnfoldableNode\n\n        value = self._eval_fn(args[0].value, args[1].value) % args[2].value\n        return vy_ast.Int.from_node(node, value=value)\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        x, y, z = args\n        with x.cache_when_complex(\"x\") as (b1, x):\n            with y.cache_when_complex(\"y\") as (b2, y):\n                with z.cache_when_complex(\"z\") as (b3, z):\n                    ret = IRnode.from_list(\n                        [\"seq\", [\"assert\", z], [self._opcode, x, y, z]], typ=UINT256_T\n                    )\n                    return b1.resolve(b2.resolve(b3.resolve(ret)))\n\n\nclass AddMod(_AddMulMod):\n    _id = \"uint256_addmod\"\n    _eval_fn = operator.add\n    _opcode = \"addmod\"\n\n\nclass MulMod(_AddMulMod):\n    _id = \"uint256_mulmod\"\n    _eval_fn = operator.mul\n    _opcode = \"mulmod\"\n\n\nclass PowMod256(BuiltinFunctionT):\n    _id = \"pow_mod256\"\n    _inputs = [(\"a\", UINT256_T), (\"b\", UINT256_T)]\n    _return_type = UINT256_T\n\n    def _try_fold(self, node):\n        validate_call_args(node, 2)\n        values = [i.get_folded_value() for i in node.args]\n        if any(not isinstance(i, vy_ast.Int) for i in values):\n            raise UnfoldableNode\n\n        left, right = values\n        value = pow(left.value, right.value, 2**256)\n        return vy_ast.Int.from_node(node, value=value)\n\n    def build_IR(self, expr, context):\n        left = Expr.parse_value_expr(expr.args[0], context)\n        right = Expr.parse_value_expr(expr.args[1], context)\n        return IRnode.from_list([\"exp\", left, right], typ=left.typ)\n\n\nclass Abs(BuiltinFunctionT):\n    _id = \"abs\"\n    _inputs = [(\"value\", INT256_T)]\n    _return_type = INT256_T\n\n    def _try_fold(self, node):\n        validate_call_args(node, 1)\n        value = node.args[0].get_folded_value()\n        if not isinstance(value, vy_ast.Int):\n            raise UnfoldableNode\n\n        value = abs(value.value)\n        return vy_ast.Int.from_node(node, value=value)\n\n    def build_IR(self, expr, context):\n        value = Expr.parse_value_expr(expr.args[0], context)\n        sub = [\n            \"with\",\n            \"orig\",\n            value,\n            [\n                \"if\",\n                [\"slt\", \"orig\", 0],\n                # clamp orig != -2**255 (because it maps to itself under negation)\n                [\"seq\", [\"assert\", [\"ne\", \"orig\", [\"sub\", 0, \"orig\"]]], [\"sub\", 0, \"orig\"]],\n                \"orig\",\n            ],\n        ]\n        return IRnode.from_list(sub, typ=INT256_T)\n\n\n# CREATE* functions\n\nCREATE2_SENTINEL = dummy_node_for_type(BYTES32_T)\n\n\n# create helper functions\n# generates CREATE op sequence + zero check for result\ndef _create_ir(value, buf, length, salt, checked=True):\n    args = [value, buf, length]\n    create_op = \"create\"\n    if salt is not CREATE2_SENTINEL:\n        create_op = \"create2\"\n        args.append(salt)\n\n    ret = IRnode.from_list(\n        [\"seq\", eval_once_check(_freshname(\"create_builtin\")), [create_op, *args]]\n    )\n\n    if not checked:\n        return ret\n\n    ret = clamp_nonzero(ret)\n    ret.set_error_msg(f\"{create_op} failed\")\n    return ret\n\n\n# calculate the gas used by create for a given number of bytes\ndef _create_addl_gas_estimate(size, should_use_create2):\n    ret = 200 * size\n    if should_use_create2:\n        ret += SHA3_PER_WORD * ceil32(size) // 32\n    return ret\n\n\ndef eip1167_bytecode():\n    # NOTE cyclic import?\n    from vyper.ir.compile_ir import assembly_to_evm\n\n    loader_asm = [\n        \"PUSH1\",\n        0x2D,\n        \"RETURNDATASIZE\",\n        \"DUP2\",\n        \"PUSH1\",\n        0x09,\n        \"RETURNDATASIZE\",\n        \"CODECOPY\",\n        \"RETURN\",\n    ]\n    forwarder_pre_asm = [\n        \"CALLDATASIZE\",\n        \"RETURNDATASIZE\",\n        \"RETURNDATASIZE\",\n        \"CALLDATACOPY\",\n        \"RETURNDATASIZE\",\n        \"RETURNDATASIZE\",\n        \"RETURNDATASIZE\",\n        \"CALLDATASIZE\",\n        \"RETURNDATASIZE\",\n        \"PUSH20\",  # [address to delegate to]\n    ]\n    forwarder_post_asm = [\n        \"GAS\",\n        \"DELEGATECALL\",\n        \"RETURNDATASIZE\",\n        \"DUP3\",\n        \"DUP1\",\n        \"RETURNDATACOPY\",\n        \"SWAP1\",\n        \"RETURNDATASIZE\",\n        \"SWAP2\",\n        \"PUSH1\",\n        0x2B,  # jumpdest of whole program.\n        \"JUMPI\",\n        \"REVERT\",\n        \"JUMPDEST\",\n        \"RETURN\",\n    ]\n    return (\n        assembly_to_evm(loader_asm)[0],\n        assembly_to_evm(forwarder_pre_asm)[0],\n        assembly_to_evm(forwarder_post_asm)[0],\n    )\n\n\n# \"standard\" initcode for code which can be larger than 256 bytes.\n# returns the code starting from 0x0b with len `codesize`.\n# NOTE: it assumes codesize <= 2**24.\ndef _create_preamble(codesize):\n    from vyper.ir.compile_ir import assembly_to_evm\n\n    evm_len = 0x0B  # 11 bytes\n    asm = [\n        # use PUSH3 to be able to deal with larger contracts\n        \"PUSH3\",\n        # blank space for codesize\n        0x00,\n        0x00,\n        0x00,\n        \"RETURNDATASIZE\",\n        \"DUP2\",\n        \"PUSH1\",\n        evm_len,\n        \"RETURNDATASIZE\",\n        \"CODECOPY\",\n        \"RETURN\",\n    ]\n    evm = assembly_to_evm(asm)[0]\n    assert len(evm) == evm_len, evm\n\n    shl_bits = (evm_len - 4) * 8  # codesize needs to go right after the PUSH3\n    # mask codesize into the aforementioned \"blank space\"\n    return [\"or\", bytes_to_int(evm), shl(shl_bits, codesize)], evm_len\n\n\nclass _CreateBase(BuiltinFunctionT):\n    _kwargs = {\n        \"value\": KwargSettings(UINT256_T, zero_value),\n        \"salt\": KwargSettings(BYTES32_T, empty_value),\n    }\n    _return_type = AddressT()\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        # errmsg something like \"Cannot use {self._id} in pure fn\"\n        context.check_is_not_constant(\"use {self._id}\", expr)\n\n        should_use_create2 = \"salt\" in [kwarg.arg for kwarg in expr.keywords]\n\n        if not should_use_create2:\n            kwargs[\"salt\"] = CREATE2_SENTINEL\n\n        ir_builder = self._build_create_IR(expr, args, context, **kwargs)\n\n        add_gas_estimate = self._add_gas_estimate(args, should_use_create2)\n\n        return IRnode.from_list(\n            ir_builder, typ=AddressT(), annotation=self._id, add_gas_estimate=add_gas_estimate\n        )\n\n\nclass CreateMinimalProxyTo(_CreateBase):\n    # create an EIP1167 \"minimal proxy\" to the target contract\n\n    _id = \"create_minimal_proxy_to\"\n    _inputs = [(\"target\", AddressT())]\n\n    def _add_gas_estimate(self, args, should_use_create2):\n        a, b, c = eip1167_bytecode()\n        bytecode_len = 20 + len(b) + len(c)\n        return _create_addl_gas_estimate(bytecode_len, should_use_create2)\n\n    def _build_create_IR(self, expr, args, context, value, salt):\n        target_address = args[0]\n\n        buf = context.new_internal_variable(BytesT(96))\n\n        loader_evm, forwarder_pre_evm, forwarder_post_evm = eip1167_bytecode()\n        # Adjust to 32-byte boundaries\n        preamble_length = len(loader_evm) + len(forwarder_pre_evm)\n        forwarder_preamble = bytes_to_int(\n            loader_evm + forwarder_pre_evm + b\"\\x00\" * (32 - preamble_length)\n        )\n        forwarder_post = bytes_to_int(forwarder_post_evm + b\"\\x00\" * (32 - len(forwarder_post_evm)))\n\n        # left-align the target\n        if target_address.is_literal:\n            # note: should move to optimizer once we have\n            # codesize optimization pipeline\n            aligned_target = args[0].value << 96\n        else:\n            aligned_target = shl(96, target_address)\n\n        buf_len = preamble_length + 20 + len(forwarder_post_evm)\n\n        return [\n            \"seq\",\n            [\"mstore\", buf, forwarder_preamble],\n            [\"mstore\", [\"add\", buf, preamble_length], aligned_target],\n            [\"mstore\", [\"add\", buf, preamble_length + 20], forwarder_post],\n            _create_ir(value, buf, buf_len, salt=salt),\n        ]\n\n\nclass CreateForwarderTo(CreateMinimalProxyTo):\n    _warned = False\n\n    def build_IR(self, expr, context):\n        if not self._warned:\n            vyper_warn(\"`create_forwarder_to` is a deprecated alias of `create_minimal_proxy_to`!\")\n            self._warned = True\n\n        return super().build_IR(expr, context)\n\n\nclass CreateCopyOf(_CreateBase):\n    _id = \"create_copy_of\"\n    _inputs = [(\"target\", AddressT())]\n\n    @property\n    def _preamble_len(self):\n        return 11\n\n    def _add_gas_estimate(self, args, should_use_create2):\n        # max possible runtime length + preamble length\n        return _create_addl_gas_estimate(EIP_170_LIMIT + self._preamble_len, should_use_create2)\n\n    def _build_create_IR(self, expr, args, context, value, salt):\n        target = args[0]\n\n        # something we can pass to scope_multi\n        with scope_multi(\n            (target, value, salt), (\"create_target\", \"create_value\", \"create_salt\")\n        ) as (b1, (target, value, salt)):\n            codesize = IRnode.from_list([\"extcodesize\", target])\n            msize = IRnode.from_list([\"msize\"])\n            with scope_multi((codesize, msize), (\"target_codesize\", \"mem_ofst\")) as (\n                b2,\n                (codesize, mem_ofst),\n            ):\n                ir = [\"seq\"]\n\n                # make sure there is actually code at the target\n                check_codesize = [\"assert\", codesize]\n                ir.append(\n                    IRnode.from_list(check_codesize, error_msg=\"empty target (create_copy_of)\")\n                )\n\n                # store the preamble at msize + 22 (zero padding)\n                preamble, preamble_len = _create_preamble(codesize)\n                assert preamble_len == self._preamble_len\n\n                ir.append([\"mstore\", mem_ofst, preamble])\n\n                # copy the target code into memory. current layout:\n                # msize | 00...00 (22 0's) | preamble | bytecode\n                ir.append([\"extcodecopy\", target, add_ofst(mem_ofst, 32), 0, codesize])\n\n                buf = add_ofst(mem_ofst, 32 - preamble_len)\n                buf_len = [\"add\", codesize, preamble_len]\n\n                ir.append(_create_ir(value, buf, buf_len, salt))\n\n                return b1.resolve(b2.resolve(ir))\n\n\nclass CreateFromBlueprint(_CreateBase):\n    _id = \"create_from_blueprint\"\n    _inputs = [(\"target\", AddressT())]\n    _kwargs = {\n        \"value\": KwargSettings(UINT256_T, zero_value),\n        \"salt\": KwargSettings(BYTES32_T, empty_value),\n        \"raw_args\": KwargSettings(BoolT(), False, require_literal=True),\n        \"code_offset\": KwargSettings(UINT256_T, zero_value),\n    }\n    _has_varargs = True\n\n    def _add_gas_estimate(self, args, should_use_create2):\n        ctor_args = ir_tuple_from_args(args[1:])\n        # max possible size of init code\n        maxlen = EIP_170_LIMIT + ctor_args.typ.abi_type.size_bound()\n        return _create_addl_gas_estimate(maxlen, should_use_create2)\n\n    def _build_create_IR(self, expr, args, context, value, salt, code_offset, raw_args):\n        target = args[0]\n        ctor_args = args[1:]\n\n        ctor_args = [ensure_in_memory(arg, context) for arg in ctor_args]\n\n        if raw_args:\n            if len(ctor_args) != 1 or not isinstance(ctor_args[0].typ, BytesT):\n                raise StructureException(\"raw_args must be used with exactly 1 bytes argument\")\n\n            argbuf = bytes_data_ptr(ctor_args[0])\n            argslen = get_bytearray_length(ctor_args[0])\n            bufsz = ctor_args[0].typ.maxlen\n        else:\n            # encode the varargs\n            to_encode = ir_tuple_from_args(ctor_args)\n\n            # pretend we allocated enough memory for the encoder\n            # (we didn't, but we are clobbering unused memory so it's safe.)\n            bufsz = to_encode.typ.abi_type.size_bound()\n            argbuf = IRnode.from_list(\n                context.new_internal_variable(get_type_for_exact_size(bufsz)), location=MEMORY\n            )\n\n            # return a complex expression which writes to memory and returns\n            # the length of the encoded data\n            argslen = abi_encode(argbuf, to_encode, context, bufsz=bufsz, returns_len=True)\n\n        # NOTE: we need to invoke the abi encoder before evaluating MSIZE,\n        # then copy the abi encoded buffer to past-the-end of the initcode\n        # (since the abi encoder could write to fresh memory).\n        # it would be good to not require the memory copy, but need\n        # to evaluate memory safety.\n        with scope_multi(\n            (target, value, salt, argslen, code_offset),\n            (\"create_target\", \"create_value\", \"create_salt\", \"encoded_args_len\", \"code_offset\"),\n        ) as (b1, (target, value, salt, encoded_args_len, code_offset)):\n            codesize = IRnode.from_list([\"sub\", [\"extcodesize\", target], code_offset])\n            # copy code to memory starting from msize. we are clobbering\n            # unused memory so it's safe.\n            msize = IRnode.from_list([\"msize\"], location=MEMORY)\n            with scope_multi((codesize, msize), (\"target_codesize\", \"mem_ofst\")) as (\n                b2,\n                (codesize, mem_ofst),\n            ):\n                ir = [\"seq\"]\n\n                # make sure there is code at the target, and that\n                # code_ofst <= (extcodesize target).\n                # (note if code_ofst > (extcodesize target), would be\n                # OOG on the EXTCODECOPY)\n                # (code_ofst == (extcodesize target) would be empty\n                # initcode, which we disallow for hygiene reasons -\n                # same as `create_copy_of` on an empty target).\n                check_codesize = [\"assert\", [\"sgt\", codesize, 0]]\n                ir.append(\n                    IRnode.from_list(\n                        check_codesize, error_msg=\"empty target (create_from_blueprint)\"\n                    )\n                )\n\n                # copy the target code into memory.\n                # layout starting from mem_ofst:\n                # <target initcode> | <abi-encoded args OR arg buffer if raw_arg=True>\n                ir.append([\"extcodecopy\", target, mem_ofst, code_offset, codesize])\n                ir.append(copy_bytes(add_ofst(mem_ofst, codesize), argbuf, encoded_args_len, bufsz))\n\n                # theoretically, dst = \"msize\", but just be safe.\n                # if len(ctor_args) > 0:\n                #    dst = add_ofst(mem_ofst, codesize)\n                #    encoded_args_len = self._encode_args(dst, ctor_args, context)\n                # else:\n                #    encoded_args_len = 0\n\n                length = [\"add\", codesize, encoded_args_len]\n\n                ir.append(_create_ir(value, mem_ofst, length, salt))\n\n                return b1.resolve(b2.resolve(ir))\n\n\nclass _UnsafeMath(BuiltinFunctionT):\n    # TODO add unsafe math for `decimal`s\n    _inputs = [(\"a\", IntegerT.any()), (\"b\", IntegerT.any())]\n\n    def __repr__(self):\n        return f\"builtin function unsafe_{self.op}\"\n\n    def fetch_call_return(self, node):\n        return_type = self.infer_arg_types(node).pop()\n        return return_type\n\n    def infer_arg_types(self, node, expected_return_typ=None):\n        self._validate_arg_types(node)\n\n        types_list = get_common_types(*node.args, filter_fn=lambda x: isinstance(x, IntegerT))\n        if not types_list:\n            raise TypeMismatch(f\"unsafe_{self.op} called on dislike types\", node)\n\n        type_ = types_list.pop()\n        return [type_, type_]\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        (a, b) = args\n        op = self.op\n\n        assert a.typ == b.typ, \"unreachable\"\n\n        otyp = a.typ\n\n        if op == \"div\" and a.typ.is_signed:\n            op = \"sdiv\"\n\n        ret = [op, a, b]\n\n        if a.typ.bits < 256:\n            # wrap for ops which could under/overflow\n            if a.typ.is_signed:\n                # e.g. int128 -> (signextend 15 (add x y))\n                ret = promote_signed_int(ret, a.typ.bits)\n            else:\n                # e.g. uint8 -> (mod (add x y) 256)\n                # TODO mod_bound could be a really large literal\n                ret = [\"mod\", ret, 2**a.typ.bits]\n\n        return IRnode.from_list(ret, typ=otyp)\n\n        # TODO handle decimal case\n\n\nclass UnsafeAdd(_UnsafeMath):\n    op = \"add\"\n\n\nclass UnsafeSub(_UnsafeMath):\n    op = \"sub\"\n\n\nclass UnsafeMul(_UnsafeMath):\n    op = \"mul\"\n\n\nclass UnsafeDiv(_UnsafeMath):\n    op = \"div\"\n\n\nclass _MinMax(BuiltinFunctionT):\n    _inputs = [(\"a\", (DecimalT(), IntegerT.any())), (\"b\", (DecimalT(), IntegerT.any()))]\n\n    def _try_fold(self, node):\n        validate_call_args(node, 2)\n\n        left = node.args[0].get_folded_value()\n        right = node.args[1].get_folded_value()\n        if not isinstance(left, type(right)):\n            raise UnfoldableNode\n        if not isinstance(left, (vy_ast.Decimal, vy_ast.Int)):\n            raise UnfoldableNode\n\n        types_list = get_common_types(\n            *(left, right), filter_fn=lambda x: isinstance(x, (IntegerT, DecimalT))\n        )\n        if not types_list:\n            raise TypeMismatch(\"Cannot perform action between dislike numeric types\", node)\n\n        value = self._eval_fn(left.value, right.value)\n        return type(left).from_node(node, value=value)\n\n    def fetch_call_return(self, node):\n        self._validate_arg_types(node)\n\n        types_list = get_common_types(\n            *node.args, filter_fn=lambda x: isinstance(x, (IntegerT, DecimalT))\n        )\n        if not types_list:\n            raise TypeMismatch(\"Cannot perform action between dislike numeric types\", node)\n\n        return types_list\n\n    def infer_arg_types(self, node, expected_return_typ=None):\n        types_list = self.fetch_call_return(node)\n        # type mismatch should have been caught in `fetch_call_return`\n        assert expected_return_typ in types_list\n        return [expected_return_typ, expected_return_typ]\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        op = self._opcode\n\n        with args[0].cache_when_complex(\"_l\") as (b1, left), args[1].cache_when_complex(\"_r\") as (\n            b2,\n            right,\n        ):\n            if left.typ == right.typ:\n                if left.typ != UINT256_T:\n                    # if comparing like types that are not uint256, use SLT or SGT\n                    op = f\"s{op}\"\n                o = [\"select\", [op, left, right], left, right]\n                otyp = left.typ\n\n            else:\n                raise TypeMismatch(f\"Minmax types incompatible: {left.typ.typ} {right.typ.typ}\")\n            return IRnode.from_list(b1.resolve(b2.resolve(o)), typ=otyp)\n\n\nclass Min(_MinMax):\n    _id = \"min\"\n    _eval_fn = min\n    _opcode = \"lt\"\n\n\nclass Max(_MinMax):\n    _id = \"max\"\n    _eval_fn = max\n    _opcode = \"gt\"\n\n\nclass Uint2Str(BuiltinFunctionT):\n    _id = \"uint2str\"\n    _inputs = [(\"x\", IntegerT.unsigneds())]\n\n    def fetch_call_return(self, node):\n        arg_t = self.infer_arg_types(node)[0]\n        bits = arg_t.bits\n        len_needed = math.ceil(bits * math.log(2) / math.log(10))\n        return StringT(len_needed)\n\n    def _try_fold(self, node):\n        validate_call_args(node, 1)\n        value = node.args[0].get_folded_value()\n        if not isinstance(value, vy_ast.Int):\n            raise UnfoldableNode\n\n        value = value.value\n        if value < 0:\n            raise InvalidType(\"Only unsigned ints allowed\", node)\n        value = str(value)\n        return vy_ast.Str.from_node(node, value=value)\n\n    def infer_arg_types(self, node, expected_return_typ=None):\n        self._validate_arg_types(node)\n        input_type = get_possible_types_from_node(node.args[0]).pop()\n        return [input_type]\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        return_t = self.fetch_call_return(expr)\n        n_digits = return_t.maxlen\n\n        with args[0].cache_when_complex(\"val\") as (b1, val):\n            buf = context.new_internal_variable(return_t)\n\n            i = IRnode.from_list(context.fresh_varname(\"uint2str_i\"), typ=UINT256_T)\n\n            ret = [\"repeat\", i, 0, n_digits + 1, n_digits + 1]\n\n            body = [\n                \"seq\",\n                [\n                    \"if\",\n                    [\"eq\", val, 0],\n                    # clobber val, and return it as a pointer\n                    [\n                        \"seq\",\n                        [\"mstore\", [\"sub\", buf + n_digits, i], i],\n                        [\"set\", val, [\"sub\", buf + n_digits, i]],\n                        \"break\",\n                    ],\n                    [\n                        \"seq\",\n                        [\"mstore\", [\"sub\", buf + n_digits, i], [\"add\", 48, [\"mod\", val, 10]]],\n                        [\"set\", val, [\"div\", val, 10]],\n                    ],\n                ],\n            ]\n            ret.append(body)\n\n            # \"0\" has hex representation 0x00..0130..00\n            # if (val == 0) {\n            #   return \"0\"\n            # } else {\n            #   do the loop\n            # }\n            ret = [\n                \"if\",\n                [\"eq\", val, 0],\n                [\"seq\", [\"mstore\", buf + 1, ord(\"0\")], [\"mstore\", buf, 1], buf],\n                [\"seq\", ret, val],\n            ]\n\n            return b1.resolve(IRnode.from_list(ret, location=MEMORY, typ=return_t))\n\n\nclass Sqrt(BuiltinFunctionT):\n    _id = \"sqrt\"\n    _inputs = [(\"d\", DecimalT())]\n    _return_type = DecimalT()\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        # TODO fix cyclic dependency with codegen/stmt.py\n        from ._utils import generate_inline_function\n\n        arg = args[0]\n        # TODO: reify decimal and integer sqrt paths (see isqrt)\n        sqrt_code = \"\"\"\nassert x >= 0.0\nz: decimal = 0.0\n\nif x == 0.0:\n    z = 0.0\nelse:\n    z = x / 2.0 + 0.5\n    y: decimal = x\n\n    for i: uint256 in range(256):\n        if z == y:\n            break\n        y = z\n        z = (x / z + z) / 2.0\n        \"\"\"\n\n        x_type = DecimalT()\n        placeholder_copy = [\"pass\"]\n        # Steal current position if variable is already allocated.\n        if arg.value == \"mload\":\n            new_var_pos = arg.args[0]\n        # Other locations need to be copied.\n        else:\n            new_var_pos = context.new_internal_variable(x_type)\n            placeholder_copy = [\"mstore\", new_var_pos, arg]\n        # Create input variables.\n        variables = {\"x\": VariableRecord(name=\"x\", pos=new_var_pos, typ=x_type, mutable=False)}\n        # Dictionary to update new (i.e. typecheck) namespace\n        variables_2 = {\"x\": VarInfo(DecimalT())}\n        # Generate inline IR.\n        new_ctx, sqrt_ir = generate_inline_function(\n            code=sqrt_code,\n            variables=variables,\n            variables_2=variables_2,\n            memory_allocator=context.memory_allocator,\n        )\n        return IRnode.from_list(\n            [\"seq\", placeholder_copy, sqrt_ir, new_ctx.vars[\"z\"].pos],  # load x variable\n            typ=DecimalT(),\n            location=MEMORY,\n        )\n\n\nclass ISqrt(BuiltinFunctionT):\n    _id = \"isqrt\"\n    _inputs = [(\"d\", UINT256_T)]\n    _return_type = UINT256_T\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        # calculate isqrt using the babylonian method\n\n        y, z = \"y\", \"z\"\n        arg = args[0]\n        with arg.cache_when_complex(\"x\") as (b1, x):\n            ret = [\n                \"seq\",\n                [\n                    \"if\",\n                    [\"ge\", y, 2 ** (128 + 8)],\n                    [\"seq\", [\"set\", y, shr(128, y)], [\"set\", z, shl(64, z)]],\n                ],\n                [\n                    \"if\",\n                    [\"ge\", y, 2 ** (64 + 8)],\n                    [\"seq\", [\"set\", y, shr(64, y)], [\"set\", z, shl(32, z)]],\n                ],\n                [\n                    \"if\",\n                    [\"ge\", y, 2 ** (32 + 8)],\n                    [\"seq\", [\"set\", y, shr(32, y)], [\"set\", z, shl(16, z)]],\n                ],\n                [\n                    \"if\",\n                    [\"ge\", y, 2 ** (16 + 8)],\n                    [\"seq\", [\"set\", y, shr(16, y)], [\"set\", z, shl(8, z)]],\n                ],\n            ]\n            ret.append([\"set\", z, [\"div\", [\"mul\", z, [\"add\", y, 2**16]], 2**18]])\n\n            for _ in range(7):\n                ret.append([\"set\", z, [\"div\", [\"add\", [\"div\", x, z], z], 2]])\n\n            # note: If ``x+1`` is a perfect square, then the Babylonian\n            # algorithm oscillates between floor(sqrt(x)) and ceil(sqrt(x)) in\n            # consecutive iterations. return the floor value always.\n\n            ret.append([\"with\", \"t\", [\"div\", x, z], [\"select\", [\"lt\", z, \"t\"], z, \"t\"]])\n\n            ret = [\"with\", y, x, [\"with\", z, 181, ret]]\n            return b1.resolve(IRnode.from_list(ret, typ=UINT256_T))\n\n\nclass Empty(TypenameFoldedFunctionT):\n    _id = \"empty\"\n\n    def fetch_call_return(self, node):\n        type_ = self.infer_arg_types(node)[0].typedef\n        if isinstance(type_, HashMapT):\n            raise TypeMismatch(\"Cannot use empty on HashMap\", node)\n        return type_\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        output_type = args[0]\n        return IRnode(\"~empty\", typ=output_type)\n\n\nclass Breakpoint(BuiltinFunctionT):\n    _id = \"breakpoint\"\n    _inputs: list = []\n\n    _warned = False\n\n    def fetch_call_return(self, node):\n        if not self._warned:\n            vyper_warn(\"`breakpoint` should only be used for debugging!\\n\" + node._annotated_source)\n            self._warned = True\n\n        return None\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        return IRnode.from_list(\"breakpoint\", annotation=\"breakpoint()\")\n\n\nclass Print(BuiltinFunctionT):\n    _id = \"print\"\n    _inputs: list = []\n    _has_varargs = True\n    _kwargs = {\"hardhat_compat\": KwargSettings(BoolT(), False, require_literal=True)}\n\n    _warned = False\n\n    def fetch_call_return(self, node):\n        if not self._warned:\n            vyper_warn(\"`print` should only be used for debugging!\\n\" + node._annotated_source)\n            self._warned = True\n\n        return None\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        args_as_tuple = ir_tuple_from_args(args)\n        args_abi_t = args_as_tuple.typ.abi_type\n\n        # create a signature like \"log(uint256)\"\n        sig = \"log\" + \"(\" + \",\".join([arg.typ.abi_type.selector_name() for arg in args]) + \")\"\n\n        if kwargs[\"hardhat_compat\"] is True:\n            method_id = method_id_int(sig)\n            buflen = 32 + args_abi_t.size_bound()\n\n            # 32 bytes extra space for the method id\n            buf = context.new_internal_variable(get_type_for_exact_size(buflen))\n\n            ret = [\"seq\"]\n            ret.append([\"mstore\", buf, method_id])\n            encode = abi_encode(buf + 32, args_as_tuple, context, buflen, returns_len=True)\n\n        else:\n            method_id = method_id_int(\"log(string,bytes)\")\n            schema = args_abi_t.selector_name().encode(\"utf-8\")\n            if len(schema) > 32:\n                raise CompilerPanic(\"print signature too long: {schema}\")\n\n            schema_t = StringT(len(schema))\n            schema_buf = context.new_internal_variable(schema_t)\n            ret = [\"seq\"]\n            ret.append([\"mstore\", schema_buf, len(schema)])\n\n            # TODO use Expr.make_bytelike, or better have a `bytestring` IRnode type\n            ret.append([\"mstore\", schema_buf + 32, bytes_to_int(schema.ljust(32, b\"\\x00\"))])\n\n            payload_buflen = args_abi_t.size_bound()\n            payload_t = BytesT(payload_buflen)\n\n            # 32 bytes extra space for the method id\n            payload_buf = context.new_internal_variable(payload_t)\n            encode_payload = abi_encode(\n                payload_buf + 32, args_as_tuple, context, payload_buflen, returns_len=True\n            )\n\n            ret.append([\"mstore\", payload_buf, encode_payload])\n            args_as_tuple = ir_tuple_from_args(\n                [\n                    IRnode.from_list(schema_buf, typ=schema_t, location=MEMORY),\n                    IRnode.from_list(payload_buf, typ=payload_t, location=MEMORY),\n                ]\n            )\n\n            # add 32 for method id padding\n            buflen = 32 + args_as_tuple.typ.abi_type.size_bound()\n            buf = context.new_internal_variable(get_type_for_exact_size(buflen))\n            ret.append([\"mstore\", buf, method_id])\n            encode = abi_encode(buf + 32, args_as_tuple, context, buflen, returns_len=True)\n\n        # debug address that tooling uses\n        CONSOLE_ADDRESS = 0x000000000000000000636F6E736F6C652E6C6F67\n        ret.append([\"staticcall\", \"gas\", CONSOLE_ADDRESS, buf + 28, [\"add\", 4, encode], 0, 0])\n\n        return IRnode.from_list(ret, annotation=\"print:\" + sig)\n\n\nclass ABIEncode(BuiltinFunctionT):\n    _id = \"_abi_encode\"  # TODO prettier to rename this to abi.encode\n    # signature: *, ensure_tuple=<literal_bool> -> Bytes[<calculated len>]\n    # explanation of ensure_tuple:\n    # default is to force even a single value into a tuple,\n    # e.g. _abi_encode(bytes) -> _abi_encode((bytes,))\n    #      _abi_encode((bytes,)) -> _abi_encode(((bytes,),))\n    # this follows the encoding convention for functions:\n    # ://docs.soliditylang.org/en/v0.8.6/abi-spec.html#function-selector-and-argument-encoding\n    # if this is turned off, then bytes will be encoded as bytes.\n\n    _inputs: list = []\n    _has_varargs = True\n\n    _kwargs = {\n        \"ensure_tuple\": KwargSettings(BoolT(), True, require_literal=True),\n        \"method_id\": KwargSettings((BYTES4_T, BytesT(4)), None, require_literal=True),\n    }\n\n    def infer_kwarg_types(self, node):\n        ret = {}\n        for kwarg in node.keywords:\n            kwarg_name = kwarg.arg\n            validate_expected_type(kwarg.value, self._kwargs[kwarg_name].typ)\n            ret[kwarg_name] = get_exact_type_from_node(kwarg.value)\n        return ret\n\n    def fetch_call_return(self, node):\n        self._validate_arg_types(node)\n        ensure_tuple = next(\n            (arg.value.value for arg in node.keywords if arg.arg == \"ensure_tuple\"), True\n        )\n        assert isinstance(ensure_tuple, bool)\n        has_method_id = \"method_id\" in [arg.arg for arg in node.keywords]\n\n        # figure out the output type by converting\n        # the types to ABI_Types and calling size_bound API\n        arg_abi_types = []\n        arg_types = self.infer_arg_types(node)\n        for arg_t in arg_types:\n            arg_abi_types.append(arg_t.abi_type)\n\n        # special case, no tuple\n        if len(arg_abi_types) == 1 and not ensure_tuple:\n            arg_abi_t = arg_abi_types[0]\n        else:\n            arg_abi_t = ABI_Tuple(arg_abi_types)\n\n        maxlen = arg_abi_t.size_bound()\n\n        if has_method_id:\n            # the output includes 4 bytes for the method_id.\n            maxlen += 4\n\n        ret = BytesT()\n        ret.set_length(maxlen)\n        return ret\n\n    @staticmethod\n    def _parse_method_id(method_id_literal):\n        if method_id_literal is None:\n            return None\n        if isinstance(method_id_literal, bytes):\n            assert len(method_id_literal) == 4\n            return fourbytes_to_int(method_id_literal)\n        if method_id_literal.startswith(\"0x\"):\n            method_id_literal = method_id_literal[2:]\n        return fourbytes_to_int(bytes.fromhex(method_id_literal))\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        ensure_tuple = kwargs[\"ensure_tuple\"]\n        method_id = self._parse_method_id(kwargs[\"method_id\"])\n\n        if len(args) < 1:\n            raise StructureException(\"abi_encode expects at least one argument\", expr)\n\n        # figure out the required length for the output buffer\n        if len(args) == 1 and not ensure_tuple:\n            # special case, no tuple\n            encode_input = args[0]\n        else:\n            encode_input = ir_tuple_from_args(args)\n\n        input_abi_t = encode_input.typ.abi_type\n        maxlen = input_abi_t.size_bound()\n        if method_id is not None:\n            maxlen += 4\n\n        buf_t = BytesT(maxlen)\n        assert self.fetch_call_return(expr).length == maxlen\n        buf = context.new_internal_variable(buf_t)\n\n        ret = [\"seq\"]\n        if method_id is not None:\n            # <32 bytes length> | <4 bytes method_id> | <everything else>\n            # write the unaligned method_id first, then we will\n            # overwrite the 28 bytes of zeros with the bytestring length\n            ret += [[\"mstore\", buf + 4, method_id]]\n            # abi encode, and grab length as stack item\n            length = abi_encode(buf + 36, encode_input, context, returns_len=True, bufsz=maxlen)\n            # write the output length to where bytestring stores its length\n            ret += [[\"mstore\", buf, [\"add\", length, 4]]]\n\n        else:\n            # abi encode and grab length as stack item\n            length = abi_encode(buf + 32, encode_input, context, returns_len=True, bufsz=maxlen)\n            # write the output length to where bytestring stores its length\n            ret += [[\"mstore\", buf, length]]\n\n        # return the buf location\n        # TODO location is statically known, optimize this out\n        ret += [buf]\n\n        return IRnode.from_list(ret, location=MEMORY, typ=buf_t)\n\n\nclass ABIDecode(BuiltinFunctionT):\n    _id = \"_abi_decode\"\n    _inputs = [(\"data\", BytesT.any()), (\"output_type\", \"TYPE_DEFINITION\")]\n    _kwargs = {\"unwrap_tuple\": KwargSettings(BoolT(), True, require_literal=True)}\n\n    def fetch_call_return(self, node):\n        _, output_type = self.infer_arg_types(node)\n        return output_type.typedef\n\n    def infer_arg_types(self, node, expected_return_typ=None):\n        self._validate_arg_types(node)\n\n        validate_call_args(node, 2, [\"unwrap_tuple\"])\n\n        data_type = get_exact_type_from_node(node.args[0])\n        output_type = type_from_annotation(node.args[1])\n\n        return [data_type, TYPE_T(output_type)]\n\n    @process_inputs\n    def build_IR(self, expr, args, kwargs, context):\n        unwrap_tuple = kwargs[\"unwrap_tuple\"]\n\n        data = args[0]\n        output_typ = args[1]\n        wrapped_typ = output_typ\n\n        if unwrap_tuple is True:\n            wrapped_typ = calculate_type_for_external_return(output_typ)\n\n        abi_size_bound = wrapped_typ.abi_type.size_bound()\n        abi_min_size = wrapped_typ.abi_type.min_size()\n\n        # Get the size of data\n        input_max_len = data.typ.maxlen\n\n        assert abi_min_size <= abi_size_bound, \"bad abi type\"\n        if input_max_len < abi_size_bound:\n            raise StructureException(\n                (\n                    \"Mismatch between size of input and size of decoded types. \"\n                    f\"length of ABI-encoded {wrapped_typ} must be equal to or greater \"\n                    f\"than {abi_size_bound}\"\n                ),\n                expr.args[0],\n            )\n\n        data = ensure_in_memory(data, context)\n\n        with data.cache_when_complex(\"to_decode\") as (b1, data):\n            data_ptr = bytes_data_ptr(data)\n            data_len = get_bytearray_length(data)\n\n            ret = [\"seq\"]\n\n            if abi_min_size == abi_size_bound:\n                ret.append([\"assert\", [\"eq\", abi_min_size, data_len]])\n            else:\n                # runtime assert: abi_min_size <= data_len <= abi_size_bound\n                ret.append(clamp2(abi_min_size, data_len, abi_size_bound, signed=False))\n\n            to_decode = IRnode.from_list(\n                data_ptr,\n                typ=wrapped_typ,\n                location=data.location,\n                encoding=Encoding.ABI,\n                annotation=f\"abi_decode({output_typ})\",\n            )\n            to_decode.encoding = Encoding.ABI\n\n            # TODO optimization: skip make_setter when we don't need\n            # input validation\n\n            output_buf = context.new_internal_variable(wrapped_typ)\n            output = IRnode.from_list(output_buf, typ=wrapped_typ, location=MEMORY)\n\n            # sanity check buffer size for wrapped output type will not buffer overflow\n            assert wrapped_typ.memory_bytes_required == output_typ.memory_bytes_required\n            ret.append(make_setter(output, to_decode))\n\n            ret.append(output)\n            # finalize. set the type and location for the return buffer.\n            # (note: unwraps the tuple type if necessary)\n            ret = IRnode.from_list(ret, typ=output_typ, location=MEMORY)\n            return b1.resolve(ret)\n\n\nclass _MinMaxValue(TypenameFoldedFunctionT):\n    def _try_fold(self, node):\n        self._validate_arg_types(node)\n        input_type = type_from_annotation(node.args[0])\n\n        if not isinstance(input_type, (IntegerT, DecimalT)):\n            raise InvalidType(f\"Expected numeric type but got {input_type} instead\", node)\n\n        val = self._eval(input_type)\n\n        if isinstance(input_type, DecimalT):\n            ret = vy_ast.Decimal.from_node(node, value=val)\n\n        if isinstance(input_type, IntegerT):\n            ret = vy_ast.Int.from_node(node, value=val)\n\n        ret._metadata[\"type\"] = input_type\n        return ret\n\n    def infer_arg_types(self, node, expected_return_typ=None):\n        input_typedef = TYPE_T(type_from_annotation(node.args[0]))\n        return [input_typedef]\n\n\nclass MinValue(_MinMaxValue):\n    _id = \"min_value\"\n\n    def _eval(self, type_):\n        return type_.ast_bounds[0]\n\n\nclass MaxValue(_MinMaxValue):\n    _id = \"max_value\"\n\n    def _eval(self, type_):\n        return type_.ast_bounds[1]\n\n\nclass Epsilon(TypenameFoldedFunctionT):\n    _id = \"epsilon\"\n\n    def _try_fold(self, node):\n        self._validate_arg_types(node)\n        input_type = type_from_annotation(node.args[0])\n\n        if not input_type.compare_type(DecimalT()):\n            raise InvalidType(f\"Expected decimal type but got {input_type} instead\", node)\n\n        return vy_ast.Decimal.from_node(node, value=input_type.epsilon)\n\n\nDISPATCH_TABLE = {\n    \"_abi_encode\": ABIEncode(),\n    \"_abi_decode\": ABIDecode(),\n    \"floor\": Floor(),\n    \"ceil\": Ceil(),\n    \"convert\": Convert(),\n    \"slice\": Slice(),\n    \"len\": Len(),\n    \"concat\": Concat(),\n    \"sha256\": Sha256(),\n    \"method_id\": MethodID(),\n    \"keccak256\": Keccak256(),\n    \"ecrecover\": ECRecover(),\n    \"ecadd\": ECAdd(),\n    \"ecmul\": ECMul(),\n    \"extract32\": Extract32(),\n    \"as_wei_value\": AsWeiValue(),\n    \"raw_call\": RawCall(),\n    \"blockhash\": BlockHash(),\n    \"bitwise_and\": BitwiseAnd(),\n    \"bitwise_or\": BitwiseOr(),\n    \"bitwise_xor\": BitwiseXor(),\n    \"bitwise_not\": BitwiseNot(),\n    \"uint256_addmod\": AddMod(),\n    \"uint256_mulmod\": MulMod(),\n    \"unsafe_add\": UnsafeAdd(),\n    \"unsafe_sub\": UnsafeSub(),\n    \"unsafe_mul\": UnsafeMul(),\n    \"unsafe_div\": UnsafeDiv(),\n    \"pow_mod256\": PowMod256(),\n    \"uint2str\": Uint2Str(),\n    \"isqrt\": ISqrt(),\n    \"sqrt\": Sqrt(),\n    \"shift\": Shift(),\n    \"create_minimal_proxy_to\": CreateMinimalProxyTo(),\n    \"create_forwarder_to\": CreateForwarderTo(),\n    \"create_copy_of\": CreateCopyOf(),\n    \"create_from_blueprint\": CreateFromBlueprint(),\n    \"min\": Min(),\n    \"max\": Max(),\n    \"empty\": Empty(),\n    \"abs\": Abs(),\n    \"min_value\": MinValue(),\n    \"max_value\": MaxValue(),\n    \"epsilon\": Epsilon(),\n}\n\nSTMT_DISPATCH_TABLE = {\n    \"send\": Send(),\n    \"print\": Print(),\n    \"breakpoint\": Breakpoint(),\n    \"selfdestruct\": SelfDestruct(),\n    \"raw_call\": RawCall(),\n    \"raw_log\": RawLog(),\n    \"raw_revert\": RawRevert(),\n    \"create_minimal_proxy_to\": CreateMinimalProxyTo(),\n    \"create_forwarder_to\": CreateForwarderTo(),\n    \"create_copy_of\": CreateCopyOf(),\n    \"create_from_blueprint\": CreateFromBlueprint(),\n}\n\nBUILTIN_FUNCTIONS = {**STMT_DISPATCH_TABLE, **DISPATCH_TABLE}.keys()\n\n\ndef get_builtin_functions():\n    return {**STMT_DISPATCH_TABLE, **DISPATCH_TABLE}\n"], "filenames": ["tests/functional/builtins/codegen/test_concat.py", "vyper/builtins/functions.py"], "buggy_code_start_loc": [57, 545], "buggy_code_end_loc": [57, 553], "fixing_code_start_loc": [58, 546], "fixing_code_end_loc": [122, 552], "type": "CWE-787", "message": "Vyper is a Pythonic Smart Contract Language for the Ethereum Virtual Machine. The `concat` built-in can write over the bounds of the memory buffer that was allocated for it and thus overwrite existing valid data. The root cause is that the `build_IR` for `concat` doesn't properly adhere to the API of copy functions (for `>=0.3.2` the `copy_bytes` function). A contract search was performed and no vulnerable contracts were found in production. The buffer overflow can result in the change of semantics of the contract. The overflow is length-dependent and thus it might go unnoticed during contract testing. However, certainly not all usages of concat will result in overwritten valid data as we require it to be in an internal function and close to the return statement where other memory allocations don't occur. This issue has been addressed in commit `55e18f6d1` which will be included in future releases. Users are advised to update when possible.", "other": {"cve": {"id": "CVE-2024-22419", "sourceIdentifier": "security-advisories@github.com", "published": "2024-01-18T19:15:10.550", "lastModified": "2024-01-26T18:10:24.747", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "Vyper is a Pythonic Smart Contract Language for the Ethereum Virtual Machine. The `concat` built-in can write over the bounds of the memory buffer that was allocated for it and thus overwrite existing valid data. The root cause is that the `build_IR` for `concat` doesn't properly adhere to the API of copy functions (for `>=0.3.2` the `copy_bytes` function). A contract search was performed and no vulnerable contracts were found in production. The buffer overflow can result in the change of semantics of the contract. The overflow is length-dependent and thus it might go unnoticed during contract testing. However, certainly not all usages of concat will result in overwritten valid data as we require it to be in an internal function and close to the return statement where other memory allocations don't occur. This issue has been addressed in commit `55e18f6d1` which will be included in future releases. Users are advised to update when possible."}, {"lang": "es", "value": "Vyper es un lenguaje de contrato inteligente pit\u00f3nico para la m\u00e1quina virtual Ethereum. El `concat` integrado puede escribir sobre los l\u00edmites del b\u00fafer de memoria que se le asign\u00f3 y as\u00ed sobrescribir los datos v\u00e1lidos existentes. La causa principal es que `build_IR` para `concat` no se adhiere correctamente a la API de funciones de copia (para `&gt;=0.3.2` la funci\u00f3n `copy_bytes`). Se realiz\u00f3 una b\u00fasqueda de contratos y no se encontraron contratos vulnerables en producci\u00f3n. El desbordamiento de b\u00fafer puede provocar un cambio en la sem\u00e1ntica del contrato. El desbordamiento depende de la longitud y, por lo tanto, puede pasar desapercibido durante las pruebas del contrato. Sin embargo, ciertamente no todos los usos de concat dar\u00e1n como resultado la sobrescritura de datos v\u00e1lidos, ya que requerimos que est\u00e9n en una funci\u00f3n interna y cerca de la declaraci\u00f3n de devoluci\u00f3n donde no ocurren otras asignaciones de memoria. Este problema se solucion\u00f3 en el commit `55e18f6d1` que se incluir\u00e1 en versiones futuras. Se recomienda a los usuarios que actualicen cuando sea posible."}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "HIGH", "availabilityImpact": "HIGH", "baseScore": 9.8, "baseSeverity": "CRITICAL"}, "exploitabilityScore": 3.9, "impactScore": 5.9}, {"source": "security-advisories@github.com", "type": "Secondary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:L/I:L/A:L", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "LOW", "integrityImpact": "LOW", "availabilityImpact": "LOW", "baseScore": 7.3, "baseSeverity": "HIGH"}, "exploitabilityScore": 3.9, "impactScore": 3.4}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-787"}]}, {"source": "security-advisories@github.com", "type": "Secondary", "description": [{"lang": "en", "value": "CWE-120"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:vyperlang:vyper:*:*:*:*:*:python:*:*", "versionEndIncluding": "0.3.10", "matchCriteriaId": "832C489D-4288-46B4-A29E-0E7168748042"}]}]}], "references": [{"url": "https://github.com/vyperlang/vyper/commit/55e18f6d128b2da8986adbbcccf1cd59a4b9ad6f", "source": "security-advisories@github.com", "tags": ["Patch"]}, {"url": "https://github.com/vyperlang/vyper/issues/3737", "source": "security-advisories@github.com", "tags": ["Exploit", "Issue Tracking", "Vendor Advisory"]}, {"url": "https://github.com/vyperlang/vyper/security/advisories/GHSA-2q8v-3gqq-4f8p", "source": "security-advisories@github.com", "tags": ["Exploit", "Vendor Advisory"]}]}, "github_commit_url": "https://github.com/vyperlang/vyper/commit/55e18f6d128b2da8986adbbcccf1cd59a4b9ad6f"}}
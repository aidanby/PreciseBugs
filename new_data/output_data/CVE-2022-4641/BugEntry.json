{"buggy_code": ["/*\n * Copyright 2014 Ted Dunning\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\npackage org.apache.mahout.pig;\n\nimport com.google.common.base.Joiner;\nimport com.google.common.base.Splitter;\nimport com.google.common.collect.AbstractIterator;\nimport com.google.common.collect.Lists;\nimport com.google.common.collect.Maps;\nimport com.google.common.io.Closeables;\nimport org.apache.hadoop.conf.Configuration;\nimport org.apache.hadoop.fs.FileSystem;\nimport org.apache.hadoop.fs.Path;\nimport org.apache.mahout.classifier.sgd.L1;\nimport org.apache.mahout.classifier.sgd.OnlineLogisticRegression;\nimport org.apache.mahout.classifier.sgd.PolymorphicWritable;\nimport org.apache.mahout.math.Vector;\nimport org.apache.mahout.math.VectorWritable;\nimport org.apache.pig.Accumulator;\nimport org.apache.pig.EvalFunc;\nimport org.apache.pig.data.DataBag;\nimport org.apache.pig.data.DataByteArray;\nimport org.apache.pig.data.Tuple;\nimport org.apache.pig.impl.util.UDFContext;\n\nimport java.io.*;\nimport java.util.Iterator;\nimport java.util.List;\nimport java.util.Map;\nimport java.util.Random;\n\n/**\n * Trains a logistic regression model entirely in memory using the simplest learning algorithm from Mahout.\n * <p/>\n * A number of options can be supplied in a configuration string passed to the constructor.  These options\n * are of the form name=value and options are separated by commas.  Whitespace around option names and around\n * values is not significant.  Spaces inside values are preserved.\n * <p/>\n * The model to be trained can be read from a file in order to allow learning to continue at a previous\n * stopping point or the particulars of a new model to be trained from scratch can be specified using the\n * options.  Training data can be held in-memory or written to a temporary file.\n * <p/>\n * The following options can be used to load a pre-existing model:\n * <p/>\n * <ul>\n * <li>model</li>\n * <li>categories</li>\n * </ul>\n * <p/>\n * The following options can be used with a newly created model:\n * <p/>\n * <ul>\n * <li>categories - specifies a list of values that the target variable can take on.  This list should be space\n * separated and given in the same order as when the model is later used.  (required)</li>\n * <li>features - the number of elements in the feature vectors to be given to the learning algorithm.   (required)</li>\n * <li>decayExponent - specifies how quickly the learning rate will decay.  Optional with default value of 0.5.\n * Note that per-term annealing still has effect.</li>\n * <li>lambda - specifies how much regularization constant is used.  Optional with default of 1e-5.</li>\n * <li>stepOffset - slows down the decay of the learning rate at first if set greater than zero.  Default is 10</li>\n * <li>learningRate - initial value of the learning rate.  Default is 1.</li>\n * </ul>\n * <p/>\n * The following options can be used with any model:\n * <p/>\n * <ul>\n * <li>inMemory - if \"true\" then training examples are kept in-memory and used in a random order.  If \"false\" then\n * a temporary file is used to hold training examples and the order they are used is fixed by the order they are\n * given to this UDF.  The default is \"true\".</li>\n * <li>iterations - the number of iterations through the training data that are to be taken.</li>\n * </ul>\n */\npublic class LogisticRegression extends EvalFunc<DataByteArray> implements Accumulator<DataByteArray> {\n    private List<String> categories;\n    OnlineLogisticRegression model;\n    List<Example> trainingData = Lists.newArrayList();\n    private int iterations;\n    private boolean inMemory;\n    private File tmpFile;\n\n    public LogisticRegression(String modelParams) throws IOException {\n        Splitter onComma = Splitter.on(\",\").trimResults().omitEmptyStrings();\n        Splitter onEquals = Splitter.on(\"=\").trimResults();\n        Splitter onSpaces = Splitter.on(\" \");\n        Joiner withSpaces = Joiner.on(\" \");\n\n        Map<String, String> options = Maps.newHashMap();\n\n        for (String option : onComma.split(modelParams)) {\n            List<String> values = Lists.newArrayList(onEquals.split(option));\n            options.put(values.get(0), values.get(1));\n        }\n\n        if (options.containsKey(\"model\")) {\n            if (options.containsKey(\"categories\")) {\n                categories = Lists.newArrayList(onSpaces.split(options.get(\"categories\")));\n                Configuration conf = UDFContext.getUDFContext().getJobConf();\n                model = PolymorphicWritable.read(FileSystem.get(conf).open(new Path(options.get(\"model\"))), OnlineLogisticRegression.class);\n                options.remove(\"model\");\n                options.remove((\"categories\"));\n            } else {\n                throw new BadClassifierSpecException(\"Must specify \\\"categories\\\" if pre-existing model is used\");\n            }\n        } else {\n            if (options.containsKey(\"categories\") && options.containsKey(\"features\")) {\n                categories = Lists.newArrayList(onSpaces.split(options.get(\"categories\")));\n                if (categories.size() < 2) {\n                    throw new BadClassifierSpecException(\"Must have more than one target category.  Remember that categories is a space separated list\");\n                }\n                model = new OnlineLogisticRegression(categories.size(), Integer.parseInt(options.get(\"features\")), new L1());\n                options.remove(\"categories\");\n                options.remove(\"features\");\n            } else {\n                throw new BadClassifierSpecException(\"Must specify previous model location using \\\"file\\\" or supply \\\"categories\\\" and \\\"features\\\"\");\n            }\n\n            if (options.containsKey(\"decayExponent\")) {\n                model.decayExponent(Double.parseDouble(options.get(\"decayExponent\")));\n                options.remove(\"decayExponent\");\n            }\n\n            if (options.containsKey(\"lambda\")) {\n                model.lambda(Double.parseDouble(options.get(\"lambda\")));\n                options.remove(\"lambda\");\n            }\n\n            if (options.containsKey(\"stepOffset\")) {\n                model.stepOffset(Integer.parseInt(options.get(\"stepOffset\")));\n                options.remove(\"stepOffset\");\n            }\n\n            if (options.containsKey(\"learningRate\")) {\n                model.learningRate(Double.parseDouble(options.get(\"learningRate\")));\n                options.remove(\"learningRate\");\n            }\n        }\n\n        iterations = options.containsKey(\"iterations\") ? Integer.parseInt(options.get(\"iterations\")) : 1;\n        options.remove(\"iterations\");\n\n        inMemory = options.containsKey(\"inMemory\") ? Boolean.parseBoolean(options.get(\"inMemory\")) : true;\n        options.remove(\"inMemory\");\n\n        if (options.size() > 0) {\n            throw new BadClassifierSpecException(\"Extra options supplied: \" + withSpaces.join(options.keySet()));\n        }\n\n        if (!inMemory) {\n            tmpFile = File.createTempFile(\"trainingData\", \"tmp\");\n            tmpFile.deleteOnExit();\n        }\n    }\n\n    @Override\n    public DataByteArray exec(Tuple input) throws IOException {\n        addBagOfData((DataBag) input.get(0));\n        return getValue();\n    }\n\n    /**\n     * Pass tuples to the learning algorithm.  Each tuple should have two fields.  The first\n     * fields should correspond to one of the categories for the model and the second should\n     * be the encoded features for the training example.\n     *\n     * @param example A tuple containing a single field, which is a bag.  The bag will contain the set\n     *                of training examples being passed to the learning algorithm in this iteration.  Not all\n     *                training examples will be passed at once.\n     */\n    public void accumulate(Tuple example) throws IOException {\n        if (example.size() != 1) {\n            throw new IllegalArgumentException(\"Input to training algorithm should be a single bag containing tuples each with target and vector\");\n        }\n        addBagOfData((DataBag) example.get(0));\n    }\n\n    private void addBagOfData(DataBag data) throws IOException {\n        if (inMemory) {\n            for (Tuple input : data) {\n                trainingData.add(new Example(categories.indexOf(input.get(0)), PigVector.fromBytes((DataByteArray) input.get(1))));\n            }\n        } else {\n            DataOutputStream out = new DataOutputStream(new FileOutputStream(tmpFile));\n            try {\n                for (Tuple input : data) {\n                    out.writeInt(categories.indexOf(input.get(0)));\n                    PolymorphicWritable.write(out, new VectorWritable(PigVector.fromBytes((DataByteArray) input.get(1))));\n                }\n            } finally {\n                out.close();\n            }\n        }\n    }\n\n    /**\n     * Called when all tuples from current key have been passed to accumulate.  This is where the\n     * actual training occurs.  We can't do it earlier unless iterations = 1 which is an unusual\n     * case.\n     *\n     * @return the trained model.\n     */\n    public DataByteArray getValue() {\n        for (int i = 0; i < iterations; i++) {\n            for (Example example : readInput()) {\n                model.train(example.getTarget(), example.getFeatures());\n            }\n        }\n\n        try {\n            ByteArrayOutputStream baos = new ByteArrayOutputStream();\n            DataOutputStream out = new DataOutputStream(baos);\n            PolymorphicWritable.write(out, new Classifier(categories, model));\n            out.close();\n\n            return new DataByteArray(baos.toByteArray());\n        } catch (IOException e) {\n            // should never happen\n            throw new ImpossibleStateError(\"Can't put results into tuple\", e);\n        }\n    }\n\n    /**\n     * Called after getValue() to prepare processing for next key.\n     */\n    public void cleanup() {\n        if (tmpFile != null) {\n            tmpFile.delete();\n        }\n    }\n\n    public int getIterations() {\n        return iterations;\n    }\n\n    public boolean isInMemory() {\n        return inMemory;\n    }\n\n    public OnlineLogisticRegression getModel() {\n        return model;\n    }\n\n    private Iterable<Example> readInput() {\n        if (inMemory) {\n            return new Iterable<Example>() {\n                public Iterator<Example> iterator() {\n                    return new AbstractIterator<Example>() {\n                        int remainingExamples = trainingData.size();\n                        Random gen = new Random();\n\n                        @Override\n                        protected Example computeNext() {\n                            if (remainingExamples > 0) {\n                                remainingExamples--;\n                                return trainingData.get(gen.nextInt(trainingData.size()));\n                            } else {\n                                return endOfData();\n                            }\n                        }\n                    };\n                }\n            };\n        } else {\n            return new Iterable<Example>() {\n                public Iterator<Example> iterator() {\n                    try {\n                        return new AbstractIterator<Example>() {\n                            DataInputStream in = new DataInputStream(new FileInputStream(tmpFile));\n\n                            @Override\n                            protected Example computeNext() {\n                                int target;\n                                try {\n                                    target = in.readInt();\n                                } catch (EOFException e) {\n                                    Closeables.closeQuietly(in);\n                                    return endOfData();\n                                } catch (IOException e) {\n                                    Closeables.closeQuietly(in);\n                                    throw new TrainingDataException(\"Error reading training data\", e);\n                                }\n                                try {\n                                    return new Example(target, PolymorphicWritable.read(in, VectorWritable.class));\n                                } catch (EOFException e) {\n                                    Closeables.closeQuietly(in);\n                                    throw new TrainingDataException(\"Premature EOF while reading training data\", e);\n                                } catch (IOException e) {\n                                    Closeables.closeQuietly(in);\n                                    throw new TrainingDataException(\"Error reading training data\", e);\n                                }\n                            }\n                        };\n                    } catch (FileNotFoundException e) {\n                        throw new TrainingDataException(\"Could not training data file\", e);\n                    }\n                }\n            };\n        }\n    }\n\n    private static class Example {\n        int target;\n        Vector features;\n\n        public Example(int target, Vector v) {\n            this.target = target;\n            this.features = v;\n        }\n\n        public Example(int target, VectorWritable v) {\n            this(target, v.get());\n        }\n\n        public int getTarget() {\n            return target;\n        }\n\n        public Vector getFeatures() {\n            return features;\n        }\n    }\n\n    private static class TrainingDataException extends RuntimeException {\n        public TrainingDataException(String msg, Throwable e) {\n            super(msg, e);\n        }\n    }\n}\n"], "fixing_code": ["/*\n * Copyright 2014 Ted Dunning\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\npackage org.apache.mahout.pig;\n\nimport com.google.common.base.Joiner;\nimport com.google.common.base.Splitter;\nimport com.google.common.collect.AbstractIterator;\nimport com.google.common.collect.Lists;\nimport com.google.common.collect.Maps;\nimport com.google.common.io.Closeables;\nimport org.apache.hadoop.conf.Configuration;\nimport org.apache.hadoop.fs.FileSystem;\nimport org.apache.hadoop.fs.Path;\nimport org.apache.mahout.classifier.sgd.L1;\nimport org.apache.mahout.classifier.sgd.OnlineLogisticRegression;\nimport org.apache.mahout.classifier.sgd.PolymorphicWritable;\nimport org.apache.mahout.math.Vector;\nimport org.apache.mahout.math.VectorWritable;\nimport org.apache.pig.Accumulator;\nimport org.apache.pig.EvalFunc;\nimport org.apache.pig.data.DataBag;\nimport org.apache.pig.data.DataByteArray;\nimport org.apache.pig.data.Tuple;\nimport org.apache.pig.impl.util.UDFContext;\n\nimport java.io.*;\nimport java.nio.file.Files;\nimport java.util.Iterator;\nimport java.util.List;\nimport java.util.Map;\nimport java.util.Random;\n\n/**\n * Trains a logistic regression model entirely in memory using the simplest learning algorithm from Mahout.\n * <p/>\n * A number of options can be supplied in a configuration string passed to the constructor.  These options\n * are of the form name=value and options are separated by commas.  Whitespace around option names and around\n * values is not significant.  Spaces inside values are preserved.\n * <p/>\n * The model to be trained can be read from a file in order to allow learning to continue at a previous\n * stopping point or the particulars of a new model to be trained from scratch can be specified using the\n * options.  Training data can be held in-memory or written to a temporary file.\n * <p/>\n * The following options can be used to load a pre-existing model:\n * <p/>\n * <ul>\n * <li>model</li>\n * <li>categories</li>\n * </ul>\n * <p/>\n * The following options can be used with a newly created model:\n * <p/>\n * <ul>\n * <li>categories - specifies a list of values that the target variable can take on.  This list should be space\n * separated and given in the same order as when the model is later used.  (required)</li>\n * <li>features - the number of elements in the feature vectors to be given to the learning algorithm.   (required)</li>\n * <li>decayExponent - specifies how quickly the learning rate will decay.  Optional with default value of 0.5.\n * Note that per-term annealing still has effect.</li>\n * <li>lambda - specifies how much regularization constant is used.  Optional with default of 1e-5.</li>\n * <li>stepOffset - slows down the decay of the learning rate at first if set greater than zero.  Default is 10</li>\n * <li>learningRate - initial value of the learning rate.  Default is 1.</li>\n * </ul>\n * <p/>\n * The following options can be used with any model:\n * <p/>\n * <ul>\n * <li>inMemory - if \"true\" then training examples are kept in-memory and used in a random order.  If \"false\" then\n * a temporary file is used to hold training examples and the order they are used is fixed by the order they are\n * given to this UDF.  The default is \"true\".</li>\n * <li>iterations - the number of iterations through the training data that are to be taken.</li>\n * </ul>\n */\npublic class LogisticRegression extends EvalFunc<DataByteArray> implements Accumulator<DataByteArray> {\n    private List<String> categories;\n    OnlineLogisticRegression model;\n    List<Example> trainingData = Lists.newArrayList();\n    private int iterations;\n    private boolean inMemory;\n    private File tmpFile;\n\n    public LogisticRegression(String modelParams) throws IOException {\n        Splitter onComma = Splitter.on(\",\").trimResults().omitEmptyStrings();\n        Splitter onEquals = Splitter.on(\"=\").trimResults();\n        Splitter onSpaces = Splitter.on(\" \");\n        Joiner withSpaces = Joiner.on(\" \");\n\n        Map<String, String> options = Maps.newHashMap();\n\n        for (String option : onComma.split(modelParams)) {\n            List<String> values = Lists.newArrayList(onEquals.split(option));\n            options.put(values.get(0), values.get(1));\n        }\n\n        if (options.containsKey(\"model\")) {\n            if (options.containsKey(\"categories\")) {\n                categories = Lists.newArrayList(onSpaces.split(options.get(\"categories\")));\n                Configuration conf = UDFContext.getUDFContext().getJobConf();\n                model = PolymorphicWritable.read(FileSystem.get(conf).open(new Path(options.get(\"model\"))), OnlineLogisticRegression.class);\n                options.remove(\"model\");\n                options.remove((\"categories\"));\n            } else {\n                throw new BadClassifierSpecException(\"Must specify \\\"categories\\\" if pre-existing model is used\");\n            }\n        } else {\n            if (options.containsKey(\"categories\") && options.containsKey(\"features\")) {\n                categories = Lists.newArrayList(onSpaces.split(options.get(\"categories\")));\n                if (categories.size() < 2) {\n                    throw new BadClassifierSpecException(\"Must have more than one target category.  Remember that categories is a space separated list\");\n                }\n                model = new OnlineLogisticRegression(categories.size(), Integer.parseInt(options.get(\"features\")), new L1());\n                options.remove(\"categories\");\n                options.remove(\"features\");\n            } else {\n                throw new BadClassifierSpecException(\"Must specify previous model location using \\\"file\\\" or supply \\\"categories\\\" and \\\"features\\\"\");\n            }\n\n            if (options.containsKey(\"decayExponent\")) {\n                model.decayExponent(Double.parseDouble(options.get(\"decayExponent\")));\n                options.remove(\"decayExponent\");\n            }\n\n            if (options.containsKey(\"lambda\")) {\n                model.lambda(Double.parseDouble(options.get(\"lambda\")));\n                options.remove(\"lambda\");\n            }\n\n            if (options.containsKey(\"stepOffset\")) {\n                model.stepOffset(Integer.parseInt(options.get(\"stepOffset\")));\n                options.remove(\"stepOffset\");\n            }\n\n            if (options.containsKey(\"learningRate\")) {\n                model.learningRate(Double.parseDouble(options.get(\"learningRate\")));\n                options.remove(\"learningRate\");\n            }\n        }\n\n        iterations = options.containsKey(\"iterations\") ? Integer.parseInt(options.get(\"iterations\")) : 1;\n        options.remove(\"iterations\");\n\n        inMemory = options.containsKey(\"inMemory\") ? Boolean.parseBoolean(options.get(\"inMemory\")) : true;\n        options.remove(\"inMemory\");\n\n        if (options.size() > 0) {\n            throw new BadClassifierSpecException(\"Extra options supplied: \" + withSpaces.join(options.keySet()));\n        }\n\n        if (!inMemory) {\n            tmpFile = Files.createTempFile(\"trainingData\", \"tmp\").toFile();\n            tmpFile.deleteOnExit();\n        }\n    }\n\n    @Override\n    public DataByteArray exec(Tuple input) throws IOException {\n        addBagOfData((DataBag) input.get(0));\n        return getValue();\n    }\n\n    /**\n     * Pass tuples to the learning algorithm.  Each tuple should have two fields.  The first\n     * fields should correspond to one of the categories for the model and the second should\n     * be the encoded features for the training example.\n     *\n     * @param example A tuple containing a single field, which is a bag.  The bag will contain the set\n     *                of training examples being passed to the learning algorithm in this iteration.  Not all\n     *                training examples will be passed at once.\n     */\n    public void accumulate(Tuple example) throws IOException {\n        if (example.size() != 1) {\n            throw new IllegalArgumentException(\"Input to training algorithm should be a single bag containing tuples each with target and vector\");\n        }\n        addBagOfData((DataBag) example.get(0));\n    }\n\n    private void addBagOfData(DataBag data) throws IOException {\n        if (inMemory) {\n            for (Tuple input : data) {\n                trainingData.add(new Example(categories.indexOf(input.get(0)), PigVector.fromBytes((DataByteArray) input.get(1))));\n            }\n        } else {\n            DataOutputStream out = new DataOutputStream(new FileOutputStream(tmpFile));\n            try {\n                for (Tuple input : data) {\n                    out.writeInt(categories.indexOf(input.get(0)));\n                    PolymorphicWritable.write(out, new VectorWritable(PigVector.fromBytes((DataByteArray) input.get(1))));\n                }\n            } finally {\n                out.close();\n            }\n        }\n    }\n\n    /**\n     * Called when all tuples from current key have been passed to accumulate.  This is where the\n     * actual training occurs.  We can't do it earlier unless iterations = 1 which is an unusual\n     * case.\n     *\n     * @return the trained model.\n     */\n    public DataByteArray getValue() {\n        for (int i = 0; i < iterations; i++) {\n            for (Example example : readInput()) {\n                model.train(example.getTarget(), example.getFeatures());\n            }\n        }\n\n        try {\n            ByteArrayOutputStream baos = new ByteArrayOutputStream();\n            DataOutputStream out = new DataOutputStream(baos);\n            PolymorphicWritable.write(out, new Classifier(categories, model));\n            out.close();\n\n            return new DataByteArray(baos.toByteArray());\n        } catch (IOException e) {\n            // should never happen\n            throw new ImpossibleStateError(\"Can't put results into tuple\", e);\n        }\n    }\n\n    /**\n     * Called after getValue() to prepare processing for next key.\n     */\n    public void cleanup() {\n        if (tmpFile != null) {\n            tmpFile.delete();\n        }\n    }\n\n    public int getIterations() {\n        return iterations;\n    }\n\n    public boolean isInMemory() {\n        return inMemory;\n    }\n\n    public OnlineLogisticRegression getModel() {\n        return model;\n    }\n\n    private Iterable<Example> readInput() {\n        if (inMemory) {\n            return new Iterable<Example>() {\n                public Iterator<Example> iterator() {\n                    return new AbstractIterator<Example>() {\n                        int remainingExamples = trainingData.size();\n                        Random gen = new Random();\n\n                        @Override\n                        protected Example computeNext() {\n                            if (remainingExamples > 0) {\n                                remainingExamples--;\n                                return trainingData.get(gen.nextInt(trainingData.size()));\n                            } else {\n                                return endOfData();\n                            }\n                        }\n                    };\n                }\n            };\n        } else {\n            return new Iterable<Example>() {\n                public Iterator<Example> iterator() {\n                    try {\n                        return new AbstractIterator<Example>() {\n                            DataInputStream in = new DataInputStream(new FileInputStream(tmpFile));\n\n                            @Override\n                            protected Example computeNext() {\n                                int target;\n                                try {\n                                    target = in.readInt();\n                                } catch (EOFException e) {\n                                    Closeables.closeQuietly(in);\n                                    return endOfData();\n                                } catch (IOException e) {\n                                    Closeables.closeQuietly(in);\n                                    throw new TrainingDataException(\"Error reading training data\", e);\n                                }\n                                try {\n                                    return new Example(target, PolymorphicWritable.read(in, VectorWritable.class));\n                                } catch (EOFException e) {\n                                    Closeables.closeQuietly(in);\n                                    throw new TrainingDataException(\"Premature EOF while reading training data\", e);\n                                } catch (IOException e) {\n                                    Closeables.closeQuietly(in);\n                                    throw new TrainingDataException(\"Error reading training data\", e);\n                                }\n                            }\n                        };\n                    } catch (FileNotFoundException e) {\n                        throw new TrainingDataException(\"Could not training data file\", e);\n                    }\n                }\n            };\n        }\n    }\n\n    private static class Example {\n        int target;\n        Vector features;\n\n        public Example(int target, Vector v) {\n            this.target = target;\n            this.features = v;\n        }\n\n        public Example(int target, VectorWritable v) {\n            this(target, v.get());\n        }\n\n        public int getTarget() {\n            return target;\n        }\n\n        public Vector getFeatures() {\n            return features;\n        }\n    }\n\n    private static class TrainingDataException extends RuntimeException {\n        public TrainingDataException(String msg, Throwable e) {\n            super(msg, e);\n        }\n    }\n}\n"], "filenames": ["src/main/java/org/apache/mahout/pig/LogisticRegression.java"], "buggy_code_start_loc": [40], "buggy_code_end_loc": [163], "fixing_code_start_loc": [41], "fixing_code_end_loc": [164], "type": "CWE-377", "message": "A vulnerability was found in pig-vector and classified as problematic. Affected by this issue is the function LogisticRegression of the file src/main/java/org/apache/mahout/pig/LogisticRegression.java. The manipulation leads to insecure temporary file. The attack needs to be approached locally. The name of the patch is 1e7bd9fab5401a2df18d2eabd802adcf0dcf1f15. It is recommended to apply a patch to fix this issue. The identifier of this vulnerability is VDB-216500.", "other": {"cve": {"id": "CVE-2022-4641", "sourceIdentifier": "cna@vuldb.com", "published": "2022-12-21T22:15:08.823", "lastModified": "2022-12-29T21:20:25.520", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "A vulnerability was found in pig-vector and classified as problematic. Affected by this issue is the function LogisticRegression of the file src/main/java/org/apache/mahout/pig/LogisticRegression.java. The manipulation leads to insecure temporary file. The attack needs to be approached locally. The name of the patch is 1e7bd9fab5401a2df18d2eabd802adcf0dcf1f15. It is recommended to apply a patch to fix this issue. The identifier of this vulnerability is VDB-216500."}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:L/AC:L/PR:L/UI:N/S:U/C:H/I:N/A:N", "attackVector": "LOCAL", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "NONE", "availabilityImpact": "NONE", "baseScore": 5.5, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 1.8, "impactScore": 3.6}, {"source": "cna@vuldb.com", "type": "Secondary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:L/AC:H/PR:L/UI:N/S:U/C:L/I:N/A:N", "attackVector": "LOCAL", "attackComplexity": "HIGH", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "LOW", "integrityImpact": "NONE", "availabilityImpact": "NONE", "baseScore": 2.5, "baseSeverity": "LOW"}, "exploitabilityScore": 1.0, "impactScore": 1.4}]}, "weaknesses": [{"source": "cna@vuldb.com", "type": "Primary", "description": [{"lang": "en", "value": "CWE-377"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:pig-vector_project:pig-vector:-:*:*:*:*:*:*:*", "matchCriteriaId": "524F4B7B-0474-4F0C-9782-F4907F2B3FC4"}]}]}], "references": [{"url": "https://github.com/tdunning/pig-vector/commit/1e7bd9fab5401a2df18d2eabd802adcf0dcf1f15", "source": "cna@vuldb.com", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/tdunning/pig-vector/pull/2", "source": "cna@vuldb.com", "tags": ["Mitigation", "Patch", "Third Party Advisory"]}, {"url": "https://vuldb.com/?id.216500", "source": "cna@vuldb.com", "tags": ["Third Party Advisory"]}]}, "github_commit_url": "https://github.com/tdunning/pig-vector/commit/1e7bd9fab5401a2df18d2eabd802adcf0dcf1f15"}}
{"buggy_code": ["load(\"//tensorflow/core/platform:rules_cc.bzl\", \"cc_library\")\nload(\"//tensorflow:tensorflow.bzl\", \"if_google\", \"if_libtpu\", \"tf_cc_binary\", \"tf_cc_test\", \"tf_copts\", \"tf_cuda_cc_test\", \"tf_gen_op_wrapper_py\", \"tf_openmp_copts\")\nload(\"//tensorflow:tensorflow.bzl\", \"cuda_py_test\")\nload(\n    \"//tensorflow/core/platform/default:cuda_build_defs.bzl\",\n    \"if_cuda_is_configured\",\n)\nload(\n    \"//tensorflow/core/platform:build_config.bzl\",\n    \"tf_additional_tensor_coding_deps\",\n    \"tf_proto_library\",\n)\nload(\"//tensorflow/compiler/xla:xla.bzl\", \"xla_py_proto_library\")\n\n# buildifier: disable=same-origin-load\nload(\"//tensorflow:tensorflow.bzl\", \"filegroup\")\n\n# buildifier: disable=same-origin-load\nload(\"//tensorflow:tensorflow.bzl\", \"get_compatible_with_portable\")\nload(\"@local_config_rocm//rocm:build_defs.bzl\", \"if_rocm_is_configured\")\nload(\"//tensorflow/compiler/xla/service/cpu:build_defs.bzl\", \"runtime_copts\")\n\npackage(\n    default_visibility = [\":internal\"],\n    licenses = [\"notice\"],\n)\n\npackage_group(\n    name = \"internal\",\n    packages = [\n        \"//tensorflow/compiler/aot/...\",\n        \"//tensorflow/compiler/jit/...\",\n        \"//tensorflow/compiler/mlir/...\",\n        \"//tensorflow/compiler/tests/...\",\n        \"//tensorflow/compiler/tf2xla/...\",\n        \"//tensorflow/core/tpu/...\",\n        \"//tensorflow/python/compiler/...\",\n    ],\n)\n\npackage_group(\n    name = \"friends\",\n    includes = [\":internal\"],\n    packages = [\n        \"//tensorflow/...\",\n        \"//tensorflow_models/...\",\n        \"//third_party/deepmind/deepmind_research/density_functional_approximation_dm21/...\",\n        \"//third_party/mlir_edge/model_curriculum/iree/...\",\n        \"//third_party/mlperf/submissions/training/v0_7/models/...\",\n        \"//third_party/py/keras/...\",\n        \"//waymo/ml/deploy/benchmark/...\",\n    ],\n)\n\ncc_library(\n    name = \"tf2xla_supported_ops_lib\",\n    srcs = [\"tf2xla_supported_ops.cc\"],\n    hdrs = [\"tf2xla_supported_ops.h\"],\n    visibility = [\"//visibility:public\"],\n    deps = [\n        \":xla_compiler\",\n        \":xla_op_registry\",\n        \"//tensorflow/compiler/tf2xla/kernels:xla_ops\",\n        \"//tensorflow/core:framework\",\n        \"//tensorflow/core:framework_internal\",\n        \"//tensorflow/core:lib\",\n        \"//tensorflow/core:ops\",\n        \"//tensorflow/core:protos_all_cc\",\n        \"@com_google_absl//absl/strings\",\n    ],\n)\n\ntf_cc_binary(\n    name = \"tf2xla_supported_ops\",\n    srcs = [\"tf2xla_supported_ops_main.cc\"],\n    visibility = [\"//visibility:public\"],\n    deps = [\":tf2xla_supported_ops_lib\"],\n)\n\ntf_proto_library(\n    name = \"tf2xla_support_proto\",\n    srcs = [\"support.proto\"],\n    cc_api_version = 2,\n    visibility = [\"//visibility:public\"],\n)\n\nxla_py_proto_library(\n    name = \"tf2xla_support_py_pb2\",\n    has_services = False,\n    api_version = 2,\n    visibility = [\"//visibility:public\"],\n    deps = [\":tf2xla_support_proto\"],\n)\n\ntf_proto_library(\n    name = \"tf2xla_proto\",\n    srcs = [\"tf2xla.proto\"],\n    cc_api_version = 2,\n    protodeps = [\n        \"//tensorflow/core:protos_all\",\n    ],\n    visibility = [\"//visibility:public\"],\n)\n\nxla_py_proto_library(\n    name = \"tf2xla_py\",\n    has_services = False,\n    api_version = 2,\n    visibility = [\"//visibility:public\"],\n    deps = [\":tf2xla_proto\"],\n)\n\ntf_proto_library(\n    name = \"host_compute_metadata_proto\",\n    srcs = [\"host_compute_metadata.proto\"],\n    cc_api_version = 2,\n    protodeps = [\n        \"//tensorflow/core:protos_all\",\n    ],\n    visibility = [\"//visibility:public\"],\n)\n\ncc_library(\n    name = \"graph_compiler_util\",\n    srcs = [\"graph_compiler_util.cc\"],\n    hdrs = [\"graph_compiler_util.h\"],\n    visibility = [\":friends\"],\n    deps = [\n        \":functionalize_control_flow\",\n        \":sharding_util\",\n        \":tf2xla_proto_cc\",\n        \":tf2xla_util\",\n        \":xla_compiler\",\n        \"//tensorflow/compiler/xla:status_macros\",\n        \"//tensorflow/compiler/xla:statusor\",\n        \"//tensorflow/compiler/xla:xla_data_proto_cc\",\n        \"//tensorflow/core:core_cpu\",\n        \"//tensorflow/core:core_cpu_internal\",\n        \"//tensorflow/core:framework\",\n        \"//tensorflow/core:framework_internal\",\n        \"//tensorflow/core:graph\",\n        \"//tensorflow/core:lib\",\n        \"//tensorflow/core:protos_all_cc\",\n        \"@com_google_absl//absl/strings\",\n        \"@com_google_absl//absl/types:optional\",\n    ],\n)\n\ncc_library(\n    name = \"tf2xla\",\n    srcs = [\"tf2xla.cc\"],\n    hdrs = [\"tf2xla.h\"],\n    visibility = [\"//visibility:public\"],\n    deps = [\n        \":common\",\n        \":graph_compiler_util\",\n        \":tf2xla_proto_cc\",\n        \":tf2xla_util\",\n        \":xla_compiler\",\n        \":xla_op_registry\",\n        \"//tensorflow/compiler/aot:aot_only_var_handle_op\",\n        \"//tensorflow/compiler/tf2xla/kernels:xla_ops\",\n        \"//tensorflow/compiler/xla/client\",\n        \"//tensorflow/compiler/xla/client:xla_computation\",\n        \"//tensorflow/core:core_cpu\",\n        \"//tensorflow/core:core_cpu_internal\",\n        \"//tensorflow/core:framework\",\n        \"//tensorflow/core:framework_internal\",\n        \"//tensorflow/core:lib\",\n        \"//tensorflow/core:protos_all_cc\",\n        \"@com_google_absl//absl/strings\",\n    ],\n)\n\ncc_library(\n    name = \"mlir_tf2xla\",\n    srcs = [\"mlir_tf2xla.cc\"],\n    hdrs = [\"tf2xla.h\"],\n    visibility = [\"//visibility:public\"],\n    deps = [\n        \":tf2xla_proto_cc\",\n        \":tf2xla_util\",\n        \":xla_compiler\",\n        \"//tensorflow/compiler/jit\",\n        \"//tensorflow/compiler/mlir/hlo\",\n        \"//tensorflow/compiler/mlir/tensorflow\",\n        \"//tensorflow/compiler/mlir/tensorflow:compile_mlir_util\",\n        \"//tensorflow/compiler/mlir/tensorflow:device_util\",\n        \"//tensorflow/compiler/mlir/tensorflow:error_util\",\n        \"//tensorflow/compiler/mlir/tensorflow:import_model\",\n        \"//tensorflow/compiler/mlir/tensorflow:import_utils\",\n        \"//tensorflow/compiler/mlir/tensorflow:mlir_roundtrip_flags\",\n        \"//tensorflow/compiler/mlir/tensorflow:tensorflow_passes\",\n        \"//tensorflow/compiler/mlir/tensorflow:tf_dialect_passes\",\n        \"//tensorflow/compiler/mlir/xla:mlir_hlo_to_hlo\",\n        \"//tensorflow/compiler/xla/client\",\n        \"//tensorflow/compiler/xla/client:xla_computation\",\n        \"//tensorflow/core:protos_all_cc\",\n        \"@com_google_absl//absl/strings\",\n        \"@llvm-project//mlir:FuncDialect\",\n        \"@llvm-project//mlir:IR\",\n        \"@llvm-project//mlir:ShapeDialect\",\n    ],\n)\n\n# The filegroups below are explicitly used by\n# tensorflow/tools/pip_package:build_pip_package to ensure we include the proper\n# sources for the XLA AOT CPU runtime; as these are necessary outside of bazel\n# when linking tfcompile objects using saved_model_cli (e.g. using the\n# tensorflow pip package). The associated .cc files are included in tensorflow\n# pip package's xla_aot_runtime_srcs/ subdirectory. All necessary headers are\n# also included in the pip package's include/tensorflow/ and include/external/\n# subdirectories. Note however that sometimes additional object files may need\n# to be linked when linking aot xla objects, e.g. abseil libraries. See the deps\n# attribute of the \"xla_compiled_cpu_runtime_standalone\" target below for an\n# exhaustive list.\nfilegroup(\n    name = \"xla_compiled_cpu_runtime_hdrs\",\n    srcs = [\n        \"xla_compiled_cpu_function.h\",\n        \"//tensorflow/compiler/xla:cpu_runtime_hdrs\",\n        \"//tensorflow/compiler/xla/service/cpu:runtime_hdrs\",\n        \"//tensorflow/core/kernels:xla_cpu_runtime_hdrs\",\n        \"//tensorflow/core/platform:xla_cpu_runtime_srcs\",\n    ],\n    visibility = [\"//tensorflow/tools/pip_package:__pkg__\"],\n)\n\nfilegroup(\n    name = \"xla_compiled_cpu_runtime_srcs\",\n    srcs = [\n        \"xla_compiled_cpu_function.cc\",\n        \"//tensorflow/compiler/xla:cpu_runtime_srcs\",\n        \"//tensorflow/compiler/xla/service/cpu:runtime_srcs\",\n        \"//tensorflow/core/kernels:xla_cpu_runtime_srcs\",\n        \"//tensorflow/core/platform:xla_cpu_runtime_srcs\",\n    ],\n    visibility = [\"//tensorflow/tools/pip_package:__pkg__\"],\n)\n\n# This stand-alone target is used to ensure that we can build tf_library type\n# targets against the subset of sources declared in\n# xla_compiled_cpu_runtime_{srcs,hdrs}.\n#\n# The macros in tensorflow/python/tools/tools.bzl produce AOT compiled binaries\n# that rely on this target, as do unit tests in tensorflow/python/tools.\n#\n# See above for the significance of the source filegroups.\ncc_library(\n    name = \"xla_compiled_cpu_runtime_standalone\",\n    srcs = [\n        \":xla_compiled_cpu_runtime_srcs\",\n    ],\n    hdrs = [\n        \":xla_compiled_cpu_runtime_hdrs\",\n    ],\n    copts = runtime_copts() + tf_openmp_copts(),\n    features = [\"fully_static_link\"],\n    linkstatic = 1,\n    visibility = [\":friends\"],\n    # Note, we specifically removed MKL and multithreaded dependencies so the\n    # standalone does not require the MKL binary blob or threading libraries.\n    #\n    # TODO(ebrevdo): Remove tf_additoinal_tensor_coding_deps in favor of\n    # absl/strings:cord when we update absl to a newer version.\n    deps = [\n        \"@com_google_absl//absl/base\",\n        \"@com_google_absl//absl/base:core_headers\",\n        \"@com_google_absl//absl/base:dynamic_annotations\",\n        \"@com_google_absl//absl/strings\",\n        \"@com_google_absl//absl/strings:str_format\",\n        \"@com_google_absl//absl/synchronization\",\n        \"//third_party/eigen3\",\n        \"//tensorflow/compiler/xla/service:custom_call_status_internal\",\n        \"//tensorflow/core/framework:numeric_types\",\n        \"//tensorflow/core/platform:bfloat16\",\n        \"//tensorflow/core/platform:stringpiece\",\n        # Extra dependencies required for multithreaded runtime objects.\n        \"//tensorflow/core/platform:blocking_counter\",\n        \"//tensorflow/core/platform:logging\",\n        \"//tensorflow/core/platform:mutex\",\n    ] + tf_additional_tensor_coding_deps(),\n    alwayslink = 1,\n)\n\ncc_library(\n    name = \"xla_compiled_cpu_function\",\n    srcs = [\"xla_compiled_cpu_function.cc\"],\n    hdrs = [\"xla_compiled_cpu_function.h\"],\n    compatible_with = get_compatible_with_portable(),\n    visibility = [\"//visibility:public\"],\n    deps = [\n        \"//tensorflow/compiler/xla/service:custom_call_status_internal\",\n        # Keep dependencies to a minimum here; this library is used in every AOT\n        # binary produced by tfcompile.\n        \"//tensorflow/compiler/xla:cpu_function_runtime\",\n        \"//tensorflow/compiler/xla:executable_run_options\",\n        \"//tensorflow/core/platform:types\",\n    ],\n)\n\ntf_cc_test(\n    name = \"cpu_function_runtime_test\",\n    srcs = [\"cpu_function_runtime_test.cc\"],\n    deps = [\n        \"//tensorflow/compiler/xla:cpu_function_runtime\",\n        \"//tensorflow/core:framework\",\n        \"//tensorflow/core:test\",\n        \"//tensorflow/core:test_main\",\n    ],\n)\n\ncc_library(\n    name = \"xla_jit_compiled_cpu_function\",\n    srcs = [\"xla_jit_compiled_cpu_function.cc\"],\n    hdrs = [\"xla_jit_compiled_cpu_function.h\"],\n    visibility = [\"//visibility:public\"],\n    deps = [\n        \":tf2xla\",\n        \":tf2xla_proto_cc\",\n        \":xla_compiled_cpu_function\",\n        \"//tensorflow/compiler/xla:cpu_function_runtime\",\n        \"//tensorflow/compiler/xla:shape_util\",\n        \"//tensorflow/compiler/xla:statusor\",\n        \"//tensorflow/compiler/xla:xla_data_proto_cc\",\n        \"//tensorflow/compiler/xla/client:client_library\",\n        \"//tensorflow/compiler/xla/client:local_client\",\n        \"//tensorflow/compiler/xla/client:xla_computation\",\n        \"//tensorflow/compiler/xla/service:platform_util\",\n        \"//tensorflow/core:lib\",\n        \"//tensorflow/core:protos_all_cc\",\n        \"//tensorflow/stream_executor:platform\",\n    ] + if_libtpu(\n        if_false = [\n            \"//tensorflow/compiler/xla/service:cpu_plugin\",\n            \"//tensorflow/compiler/xla/service/cpu:buffer_info_util\",\n            \"//tensorflow/compiler/xla/service/cpu:cpu_executable\",\n        ],\n        if_true = [],\n    ),\n)\n\ncc_library(\n    name = \"xla_compiler\",\n    srcs = [\n        \"const_analysis.cc\",\n        \"graph_compiler.cc\",\n        \"xla_compiler.cc\",\n        \"xla_op_kernel.cc\",\n        \"xla_cpu_backend.cc\",\n    ] + if_cuda_is_configured([\n        \"xla_gpu_backend.cc\",\n    ]) + if_rocm_is_configured([\n        \"xla_gpu_backend.cc\",\n    ]),\n    hdrs = [\n        \"const_analysis.h\",\n        \"graph_compiler.h\",\n        \"xla_compiler.h\",\n        \"xla_helpers.h\",\n        \"xla_op_kernel.h\",\n        \"xla_op_registry.h\",\n    ],\n    copts = tf_copts(),\n    visibility = [\":friends\"],\n    deps = [\n        \":common\",\n        \":layout_util\",\n        \":host_compute_metadata_proto_cc\",\n        \":rearrange_function_argument\",\n        \":sharding_util\",\n        \":side_effect_util\",\n        \":tf2xla_util\",\n        \":xla_argument\",\n        \":xla_compilation_device\",\n        \":xla_context\",\n        \":xla_expression\",\n        \":xla_helpers\",\n        \":xla_op_registry\",\n        \":xla_resource\",\n        \"//tensorflow/compiler/mlir:mlir_bridge_rollout_policy\",\n        \"@com_google_absl//absl/algorithm:container\",\n        \"@com_google_absl//absl/container:flat_hash_map\",\n        \"@com_google_absl//absl/memory\",\n        \"@com_google_absl//absl/types:optional\",\n        \"@com_google_absl//absl/types:span\",\n        \"@com_google_absl//absl/types:variant\",\n        \"//tensorflow/compiler/jit:common\",\n        \"//tensorflow/compiler/jit:flags\",\n        \"//tensorflow/compiler/jit:shape_inference\",\n        \"//tensorflow/compiler/mlir:array_container_utils\",\n        \"//tensorflow/compiler/mlir/tensorflow:compile_mlir_util_no_tf_dialect_passes\",\n        \"//tensorflow/compiler/xla/client:value_inference\",\n        \"//tensorflow/compiler/xla/service:computation_placer_hdr\",\n        \"//tensorflow/compiler/xla:executable_run_options\",\n        \"//tensorflow/compiler/xla:protobuf_util\",\n        \"//tensorflow/compiler/xla:shape_util\",\n        \"//tensorflow/compiler/xla:status_macros\",\n        \"//tensorflow/compiler/xla:util\",\n        \"//tensorflow/compiler/xla:xla_data_proto_cc\",\n        \"//tensorflow/compiler/xla/client:client_library\",\n        \"//tensorflow/compiler/xla/client:local_client\",\n        \"//tensorflow/compiler/xla/client:xla_builder\",\n        \"//tensorflow/compiler/xla/client:xla_computation\",\n        \"//tensorflow/compiler/xla/service:hlo\",\n        \"//tensorflow/core:core_cpu\",\n        \"//tensorflow/core:core_cpu_internal\",\n        \"//tensorflow/core:framework\",\n        \"//tensorflow/core:lib\",\n        \"//tensorflow/core:lib_internal\",\n        \"//tensorflow/core:ops\",\n        \"//tensorflow/core:protos_all_cc\",\n    ] + if_libtpu([\n        \":xla_tpu_backend_registration\",\n    ]),\n    alwayslink = 1,\n)\n\ncc_library(\n    name = \"xla_compilation_device\",\n    srcs = [\n        \"xla_compilation_device.cc\",\n    ],\n    hdrs = [\n        \"xla_compilation_device.h\",\n    ],\n    deps = [\n        \":common\",\n        \":frontend_attributes_util\",\n        \":sharding_util\",\n        \":xla_context\",\n        \":xla_helpers\",\n        \"//tensorflow/compiler/xla/client:xla_builder\",\n        \"//tensorflow/core:framework\",\n        \"//tensorflow/core:lib\",\n        \"//tensorflow/core:session_options\",\n        \"//tensorflow/core/common_runtime:core_cpu_internal\",\n    ],\n    alwayslink = 1,\n)\n\ncc_library(\n    name = \"xla_tpu_backend_registration\",\n    srcs = [\"xla_tpu_backend.cc\"],\n    visibility = [\"//visibility:public\"],\n    deps = [\n        \":xla_op_registry\",\n        \"//tensorflow/core/tpu:tpu_defs\",\n        \"//tensorflow/core/tpu:tpu_node_device_util\",\n    ],\n    alwayslink = 1,\n)\n\ncc_library(\n    name = \"xla_context\",\n    srcs = [\n        \"xla_context.cc\",\n    ],\n    hdrs = [\n        \"xla_context.h\",\n    ],\n    deps = [\n        \":common\",\n        \":xla_expression\",\n        \":xla_helpers\",\n        \"//tensorflow/compiler/xla:literal\",\n        \"//tensorflow/compiler/xla:shape_util\",\n        \"//tensorflow/compiler/xla:status_macros\",\n        \"//tensorflow/compiler/xla:statusor\",\n        \"//tensorflow/compiler/xla:xla_data_proto_cc\",\n        \"//tensorflow/compiler/xla/client:client_library\",\n        \"//tensorflow/compiler/xla/client:xla_builder\",\n        \"//tensorflow/compiler/xla/client:xla_computation\",\n        \"//tensorflow/core:framework\",\n        \"//tensorflow/core:lib\",\n        \"//tensorflow/core/common_runtime:core_cpu_internal\",\n        \"@com_google_absl//absl/types:span\",\n    ],\n    alwayslink = 1,\n)\n\ncc_library(\n    name = \"xla_op_registry\",\n    srcs = [\n        \"xla_op_registry.cc\",\n    ],\n    hdrs = [\n        \"xla_op_registry.h\",\n    ],\n    visibility = [\":friends\"],\n    deps = [\n        \":common\",\n        \":xla_context\",\n        \"//tensorflow/compiler/jit:flags\",\n        \"//tensorflow/compiler/jit:xla_cluster_util\",\n        \"//tensorflow/compiler/xla/client:client_library\",\n        \"//tensorflow/core:framework\",\n        \"//tensorflow/core:lib\",\n        \"//tensorflow/core:protos_all_cc\",\n        \"//tensorflow/core:session_options\",\n        \"//tensorflow/core/common_runtime:core_cpu_internal\",\n        \"//tensorflow/core/platform:stream_executor_no_cuda\",\n    ],\n    alwayslink = 1,\n)\n\ncc_library(\n    name = \"xla_expression\",\n    srcs = [\n        \"xla_expression.cc\",\n    ],\n    hdrs = [\n        \"xla_expression.h\",\n    ],\n    deps = [\n        \":common\",\n        \":xla_resource\",\n        \"//tensorflow/compiler/xla:statusor\",\n        \"//tensorflow/compiler/xla/client\",\n        \"//tensorflow/compiler/xla/client:value_inference\",\n        \"//tensorflow/compiler/xla/client:xla_builder\",\n        \"//tensorflow/core:framework\",\n        \"//tensorflow/core:lib\",\n        \"//tensorflow/core:protos_all_cc\",\n        \"@com_google_absl//absl/types:optional\",\n    ],\n    alwayslink = 1,\n)\n\ncc_library(\n    name = \"xla_resource\",\n    srcs = [\n        \"xla_resource.cc\",\n    ],\n    hdrs = [\n        \"xla_resource.h\",\n    ],\n    deps = [\n        \":common\",\n        \":sharding_util\",\n        \":xla_helpers\",\n        \"//tensorflow/compiler/xla:xla_data_proto_cc\",\n        \"//tensorflow/compiler/xla/client:xla_builder\",\n        \"//tensorflow/core:framework\",\n        \"//tensorflow/core:lib\",\n        \"//tensorflow/core:protos_all_cc\",\n        \"@com_google_absl//absl/memory\",\n        \"@com_google_absl//absl/strings\",\n    ],\n    alwayslink = 1,\n)\n\ncc_library(\n    name = \"xla_helpers\",\n    srcs = [\n        \"xla_helpers.cc\",\n    ],\n    hdrs = [\n        \"xla_helpers.h\",\n    ],\n    visibility = [\":friends\"],\n    deps = [\n        \":common\",\n        \":host_compute_metadata_proto_cc\",\n        \"//tensorflow/compiler/tf2xla/lib:util\",\n        \"//tensorflow/compiler/xla:executable_run_options\",\n        \"//tensorflow/compiler/xla:types\",\n        \"//tensorflow/compiler/xla/client:xla_builder\",\n        \"//tensorflow/compiler/xla/client:xla_computation\",\n        \"//tensorflow/compiler/xla/client/lib:arithmetic\",\n        \"//tensorflow/compiler/xla/client/lib:constants\",\n        \"//tensorflow/compiler/xla/service:computation_placer_hdr\",\n        \"//tensorflow/compiler/xla/service:hlo\",\n        \"//tensorflow/compiler/xla/service/gpu:gpu_executable_run_options\",\n        \"//tensorflow/core:core_cpu_base\",\n        \"//tensorflow/core:framework\",\n        \"//tensorflow/core:lib\",\n        \"//tensorflow/stream_executor:stream_header\",\n        \"@com_google_absl//absl/synchronization\",\n        \"@com_google_absl//absl/types:optional\",\n        \"@com_google_absl//absl/types:span\",\n    ],\n    alwayslink = 1,\n)\n\ncc_library(\n    name = \"xla_argument\",\n    srcs = [\n        \"xla_argument.cc\",\n    ],\n    hdrs = [\n        \"xla_argument.h\",\n    ],\n    deps = [\n        \":host_compute_metadata_proto_cc\",\n        \":xla_resource\",\n        \"//tensorflow/compiler/xla/client:xla_builder\",\n        \"//tensorflow/compiler/xla/service:hlo\",\n        \"//tensorflow/core:framework\",\n        \"@com_google_absl//absl/types:optional\",\n        \"@com_google_absl//absl/types:span\",\n        \"@llvm-project//llvm:Support\",\n    ],\n    alwayslink = 1,\n)\n\ncc_library(\n    name = \"layout_util\",\n    srcs = [\n        \"layout_util.cc\",\n    ],\n    hdrs = [\n        \"layout_util.h\",\n    ],\n    visibility = [\":friends\"],\n    deps = [\n        \":common\",\n        \":xla_argument\",\n        \":xla_helpers\",\n        \"//tensorflow/compiler/xla:shape_util\",\n        \"//tensorflow/compiler/xla:statusor\",\n        \"//tensorflow/compiler/xla:xla_data_proto_cc\",\n        \"//tensorflow/core:framework\",\n        \"//tensorflow/core:lib\",\n        \"//tensorflow/core:protos_all_cc\",\n    ],\n    alwayslink = 1,\n)\n\ncc_library(\n    name = \"common\",\n    srcs = [\n        \"literal_util.cc\",\n        \"shape_util.cc\",\n        \"type_util.cc\",\n    ],\n    hdrs = [\n        \"literal_util.h\",\n        \"shape_util.h\",\n        \"type_util.h\",\n    ],\n    visibility = [\":friends\"],\n    deps = [\n        \"//tensorflow/compiler/xla:literal\",\n        \"//tensorflow/compiler/xla:shape_util\",\n        \"//tensorflow/compiler/xla:statusor\",\n        \"//tensorflow/compiler/xla:xla_data_proto_cc\",\n        \"//tensorflow/core:core_cpu_internal\",\n        \"//tensorflow/core:framework\",\n        \"//tensorflow/core:lib\",\n        \"//tensorflow/core:protos_all_cc\",\n        \"@com_google_absl//absl/container:flat_hash_map\",\n        \"@com_google_absl//absl/types:span\",\n    ],\n)\n\ncc_library(\n    name = \"frontend_attributes_util\",\n    srcs = [\"frontend_attributes_util.cc\"],\n    hdrs = [\"frontend_attributes_util.h\"],\n    visibility = [\"//visibility:public\"],\n    deps = [\n        \":tf2xla_defs\",\n        \"//tensorflow/compiler/xla:statusor\",\n        \"//tensorflow/compiler/xla:xla_data_proto_cc\",\n        \"//tensorflow/core:framework\",\n        \"//tensorflow/core:lib\",\n        \"//tensorflow/core:protos_all_cc\",\n        \"@com_google_absl//absl/types:optional\",\n    ],\n)\n\ncc_library(\n    name = \"sharding_util\",\n    srcs = [\"sharding_util.cc\"],\n    hdrs = [\"sharding_util.h\"],\n    visibility = [\"//visibility:public\"],\n    deps = [\n        \"//tensorflow/compiler/xla:status_macros\",\n        \"//tensorflow/compiler/xla/client:sharding_builder\",\n        \"//tensorflow/core:core_cpu\",\n        \"//tensorflow/core:core_cpu_internal\",\n        \"//tensorflow/core:framework\",\n        \"//tensorflow/core:framework_internal\",\n        \"//tensorflow/core:lib\",\n        \"//tensorflow/core:protos_all_cc\",\n        \"@com_google_absl//absl/strings\",\n    ],\n)\n\ntf_cc_test(\n    name = \"sharding_util_test\",\n    srcs = [\"sharding_util_test.cc\"],\n    deps = [\n        \":sharding_util\",\n        \"//tensorflow/core:lib\",\n        \"//tensorflow/core:protos_all_cc\",\n        \"//tensorflow/core:test\",\n        \"//tensorflow/core:test_main\",\n        \"//tensorflow/core:testlib\",\n    ],\n)\n\n# Internal targets below this point.\n\ncc_library(\n    name = \"tf2xla_defs\",\n    hdrs = [\"tf2xla_defs.h\"],\n    visibility = [\":friends\"],\n    deps = [\n        \"@com_google_absl//absl/strings\",\n    ],\n)\n\ncc_library(\n    name = \"tf2xla_util\",\n    srcs = [\"tf2xla_util.cc\"],\n    hdrs = [\"tf2xla_util.h\"],\n    visibility = [\":friends\"],\n    deps = [\n        \":sharding_util\",\n        \":tf2xla_defs\",\n        \":tf2xla_proto_cc\",\n        \"//tensorflow/compiler/xla:status_macros\",\n        \"//tensorflow/compiler/xla:xla_data_proto_cc\",\n        \"//tensorflow/core:core_cpu\",\n        \"//tensorflow/core:core_cpu_internal\",\n        \"//tensorflow/core:framework\",\n        \"//tensorflow/core:framework_internal\",\n        \"//tensorflow/core:lib\",\n        \"//tensorflow/core:protos_all_cc\",\n        \"@com_google_absl//absl/container:flat_hash_map\",\n        \"@com_google_absl//absl/strings\",\n        \"@com_google_absl//absl/types:optional\",\n    ],\n)\n\ntf_cc_test(\n    name = \"tf2xla_util_test\",\n    srcs = [\"tf2xla_util_test.cc\"],\n    deps = [\n        \":sharding_util\",\n        \":tf2xla_util\",\n        \"//tensorflow/cc:cc_ops\",\n        \"//tensorflow/cc:function_ops\",\n        \"//tensorflow/cc:functional_ops\",\n        \"//tensorflow/cc:ops\",\n        \"//tensorflow/core:core_cpu_internal\",\n        \"//tensorflow/core:framework\",\n        \"//tensorflow/core:lib\",\n        \"//tensorflow/core:math_ops_op_lib\",\n        \"//tensorflow/core:ops\",\n        \"//tensorflow/core:protos_all_cc\",\n        \"//tensorflow/core:test\",\n        \"//tensorflow/core:test_main\",\n        \"@com_google_absl//absl/strings\",\n    ],\n)\n\ntf_cc_test(\n    name = \"tf2xla_test\",\n    srcs = [\"tf2xla_test.cc\"],\n    deps = [\n        \":tf2xla\",\n        \":tf2xla_proto_cc\",\n        \"//tensorflow/compiler/xla:literal\",\n        \"//tensorflow/compiler/xla:literal_util\",\n        \"//tensorflow/compiler/xla:statusor\",\n        \"//tensorflow/compiler/xla/client:client_library\",\n        \"//tensorflow/compiler/xla/client:local_client\",\n        \"//tensorflow/compiler/xla/client:xla_computation\",\n        \"//tensorflow/compiler/xla/service:cpu_plugin\",\n        \"//tensorflow/core:framework\",\n        \"//tensorflow/core:lib\",\n        \"//tensorflow/core:protos_all_cc\",\n        \"//tensorflow/core:test\",\n        \"//tensorflow/core:test_main\",\n    ],\n)\n\ntf_cc_test(\n    name = \"xla_jit_compiled_cpu_function_test\",\n    srcs = [\"xla_jit_compiled_cpu_function_test.cc\"],\n    deps = [\n        \":tf2xla_proto_cc\",\n        \":xla_jit_compiled_cpu_function\",\n        \"//tensorflow/compiler/xla:shape_util\",\n        \"//tensorflow/compiler/xla:status_macros\",\n        \"//tensorflow/compiler/xla:statusor\",\n        \"//tensorflow/compiler/xla:test\",\n        \"//tensorflow/compiler/xla:xla_data_proto_cc\",\n        \"//tensorflow/compiler/xla/client:local_client\",\n        \"//tensorflow/compiler/xla/service:compiler\",\n        \"//tensorflow/compiler/xla/service:platform_util\",\n        \"//tensorflow/core:framework\",\n        \"//tensorflow/core:lib\",\n        \"//tensorflow/core:protos_all_cc\",\n        \"//tensorflow/core:test\",\n        \"//tensorflow/core:test_main\",\n        \"//tensorflow/stream_executor:multi_platform_manager\",\n        \"//tensorflow/stream_executor:platform\",\n        \"@com_google_absl//absl/memory\",\n        \"@com_google_absl//absl/strings\",\n    ],\n)\n\ntf_cc_test(\n    name = \"xla_compiler_test\",\n    srcs = [\n        \"xla_compiler_test.cc\",\n        \"xla_expression_test.cc\",\n    ],\n    deps = [\n        \":common\",\n        \":layout_util\",\n        \":side_effect_util\",\n        \":xla_argument\",\n        \":xla_compiler\",\n        \":xla_expression\",\n        \":xla_resource\",\n        \"//tensorflow/cc:cc_ops\",\n        \"//tensorflow/cc:function_ops\",\n        \"//tensorflow/cc:functional_ops\",\n        \"//tensorflow/cc:ops\",\n        \"//tensorflow/cc:resource_variable_ops\",\n        \"//tensorflow/compiler/tf2xla/kernels:xla_ops\",\n        \"//tensorflow/compiler/xla:literal\",\n        \"//tensorflow/compiler/xla:shape_util\",\n        \"//tensorflow/compiler/xla:status_macros\",\n        \"//tensorflow/compiler/xla/client:client_library\",\n        \"//tensorflow/compiler/xla/client:local_client\",\n        \"//tensorflow/compiler/xla/client:xla_builder\",\n        \"//tensorflow/compiler/xla/service:cpu_plugin\",\n        \"//tensorflow/compiler/xla/service:hlo_proto_cc\",\n        \"//tensorflow/compiler/xla/tests:literal_test_util\",\n        \"//tensorflow/core:core_cpu_internal\",\n        \"//tensorflow/core:framework\",\n        \"//tensorflow/core:lib\",\n        \"//tensorflow/core:protos_all_cc\",\n        \"//tensorflow/core:test\",\n        \"//tensorflow/core:test_main\",\n        \"//tensorflow/core:testlib\",\n        \"//tensorflow/core/framework:tensor_testutil\",\n        \"@com_google_absl//absl/memory\",\n        \"@com_google_absl//absl/strings\",\n    ],\n)\n\ntf_cc_test(\n    name = \"literal_util_test\",\n    srcs = [\n        \"literal_util_test.cc\",\n    ],\n    deps = [\n        \":common\",\n        \"//tensorflow/compiler/xla:literal\",\n        \"//tensorflow/compiler/xla:literal_util\",\n        \"//tensorflow/core:framework\",\n        \"//tensorflow/core:test\",\n        \"//tensorflow/core:test_main\",\n        \"//tensorflow/core:testlib\",\n    ],\n)\n\ntf_cc_test(\n    name = \"const_analysis_test\",\n    size = \"small\",\n    srcs = [\"const_analysis_test.cc\"],\n    deps = [\n        \":xla_compiler\",\n        \"//tensorflow/cc:cc_ops\",\n        \"//tensorflow/cc:function_ops\",\n        \"//tensorflow/cc:functional_ops\",\n        \"//tensorflow/cc:ops\",\n        \"//tensorflow/compiler/jit:flags\",\n        \"//tensorflow/compiler/jit:xla_cluster_util\",\n        \"//tensorflow/compiler/tf2xla/kernels:xla_ops\",\n        \"//tensorflow/core:core_cpu_internal\",\n        \"//tensorflow/core:framework\",\n        \"//tensorflow/core:ops\",\n        \"//tensorflow/core:test\",\n        \"//tensorflow/core:test_main\",\n    ],\n)\n\ncc_library(\n    name = \"light_outside_compilation_kernels_for_test\",\n    testonly = True,\n    srcs = [\"light_outside_compilation_kernels_for_test.cc\"],\n    linkstatic = 1,\n    deps = [\n        \":xla_compiler\",\n        \"//tensorflow/cc:cc_ops\",\n        \"//tensorflow/cc:function_ops\",\n        \"//tensorflow/cc:functional_ops\",\n        \"//tensorflow/cc:ops\",\n        \"//tensorflow/compiler/tf2xla/kernels:gpu_tf_kernel_custom_call\",\n        \"//tensorflow/core:framework\",\n    ],\n    alwayslink = 1,\n)\n\ntf_gen_op_wrapper_py(\n    name = \"test_ops_for_light_outside_compilation\",\n    testonly = True,\n    out = \"test_ops_for_light_outside_compilation.py\",\n    deps = [\n        \":light_outside_compilation_kernels_for_test\",\n    ],\n)\n\ncuda_py_test(\n    name = \"light_outside_compilation_test\",\n    srcs = [\"light_outside_compilation_test.py\"],\n    python_version = \"PY3\",\n    tags = [\n        \"no_oss\",\n        \"no_pip\",\n    ],\n    xla_enable_strict_auto_jit = False,\n    deps = [\n        \":test_ops_for_light_outside_compilation\",\n        \"//tensorflow/compiler/mlir/python/mlir_wrapper:filecheck_wrapper\",\n    ] + if_google([\":light_outside_compilation_kernels_for_test\"]),\n)\n\ncc_library(\n    name = \"functionalize_control_flow_util\",\n    srcs = [\n        \"functionalize_control_flow_util.cc\",\n    ],\n    hdrs = [\n        \"functionalize_control_flow_util.h\",\n    ],\n    deps = [\n        \"//tensorflow/compiler/tf2xla/ops:xla_ops\",\n        \"//tensorflow/compiler/xla:status_macros\",\n        \"//tensorflow/core:core_cpu\",\n        \"//tensorflow/core:core_cpu_internal\",\n        \"//tensorflow/core:graph\",\n        \"//tensorflow/core:protos_all_cc\",\n        \"@com_google_absl//absl/strings\",\n    ],\n)\n\ncc_library(\n    name = \"functionalize_cond\",\n    srcs = [\n        \"functionalize_cond.cc\",\n    ],\n    hdrs = [\n        \"functionalize_cond.h\",\n    ],\n    deps = [\n        \":frontend_attributes_util\",\n        \":functionalize_control_flow_util\",\n        \":tf2xla_util\",\n        \"//tensorflow/compiler/tf2xla/ops:xla_ops\",\n        \"//tensorflow/compiler/xla:status_macros\",\n        \"//tensorflow/compiler/xla:union_find\",\n        \"//tensorflow/core:core_cpu\",\n        \"//tensorflow/core:core_cpu_internal\",\n        \"//tensorflow/core:framework\",\n        \"//tensorflow/core:graph\",\n        \"//tensorflow/core:lib\",\n        \"//tensorflow/core:protos_all_cc\",\n        \"@com_google_absl//absl/memory\",\n        \"@com_google_absl//absl/strings\",\n        \"@com_google_absl//absl/types:optional\",\n    ],\n)\n\ncc_library(\n    name = \"functionalize_control_flow\",\n    srcs = [\n        \"functionalize_control_flow.cc\",\n    ],\n    hdrs = [\n        \"functionalize_control_flow.h\",\n    ],\n    visibility = [\":friends\"],\n    deps = [\n        \":functionalize_cond\",\n        \":functionalize_control_flow_util\",\n        \":functionalize_while\",\n        \":tf2xla_util\",\n        \"//tensorflow/compiler/tf2xla/ops:xla_ops\",\n        \"//tensorflow/compiler/xla:status_macros\",\n        \"//tensorflow/compiler/xla:union_find\",\n        \"//tensorflow/core:core_cpu\",\n        \"//tensorflow/core:core_cpu_internal\",\n        \"//tensorflow/core:framework\",\n        \"//tensorflow/core:graph\",\n        \"//tensorflow/core:lib\",\n        \"@com_google_absl//absl/memory\",\n        \"@com_google_absl//absl/types:optional\",\n    ],\n)\n\ncc_library(\n    name = \"mlir_bridge_pass\",\n    srcs = [\"mlir_bridge_pass.cc\"],\n    hdrs = [\"mlir_bridge_pass.h\"],\n    deps = [\n        \":tf2xla_defs\",\n        \"//tensorflow/compiler/jit:flags\",\n        \"//tensorflow/compiler/mlir:mlir_bridge_rollout_policy\",\n        \"//tensorflow/compiler/mlir:mlir_graph_optimization_pass\",\n        \"//tensorflow/compiler/mlir/tensorflow\",\n        \"//tensorflow/compiler/mlir/tensorflow:device_util\",\n        \"//tensorflow/compiler/mlir/tensorflow:tensorflow_passes\",\n        \"//tensorflow/core:core_cpu\",\n        \"//tensorflow/core:framework\",\n        \"//tensorflow/core:lib\",\n        \"//tensorflow/core/common_runtime:device_set\",\n        \"@com_google_absl//absl/base\",\n        \"@llvm-project//llvm:Support\",\n    ],\n    alwayslink = 1,\n)\n\ncc_library(\n    name = \"mlir_bridge_pass_registration\",\n    srcs = [\n        \"mlir_bridge_pass_registration.cc\",\n    ],\n    visibility = [\n        # We define a new TPU device in TFRT to enable TFRT TPU Runtime.\n        \"//learning/brain/tfrt/tf_tpu:__pkg__\",\n        \":internal\",\n    ],\n    deps = [\n        \":mlir_bridge_pass\",\n        \"//tensorflow/compiler/mlir:mlir_graph_optimization_pass_registration\",\n        \"//tensorflow/core:core_cpu\",\n    ],\n    alwayslink = 1,\n)\n\ncc_library(\n    name = \"rearrange_function_argument\",\n    srcs = [\n        \"rearrange_function_argument.cc\",\n    ],\n    hdrs = [\n        \"rearrange_function_argument.h\",\n    ],\n    deps = [\n        \":tf2xla_util\",\n        \"//tensorflow/compiler/tf2xla/ops:xla_ops\",\n        \"//tensorflow/compiler/xla:status_macros\",\n        \"//tensorflow/core:core_cpu\",\n        \"//tensorflow/core:core_cpu_internal\",\n        \"//tensorflow/core:framework\",\n        \"//tensorflow/core:graph\",\n        \"//tensorflow/core:lib\",\n        \"@com_google_absl//absl/memory\",\n        \"@com_google_absl//absl/types:optional\",\n    ],\n)\n\ncc_library(\n    name = \"functionalize_control_flow_pass_registration\",\n    srcs = [\n        \"functionalize_control_flow_pass_registration.cc\",\n    ],\n    visibility = [\":friends\"],\n    deps = [\n        \":functionalize_control_flow\",\n    ],\n    alwayslink = 1,\n)\n\ncc_library(\n    name = \"functionalize_while\",\n    srcs = [\n        \"functionalize_while.cc\",\n    ],\n    hdrs = [\n        \"functionalize_while.h\",\n    ],\n    deps = [\n        \":frontend_attributes_util\",\n        \":functionalize_cond\",\n        \":functionalize_control_flow_util\",\n        \":tf2xla_util\",\n        \"//tensorflow/compiler/tf2xla/ops:xla_ops\",\n        \"//tensorflow/compiler/xla:status_macros\",\n        \"//tensorflow/compiler/xla:union_find\",\n        \"//tensorflow/core:core_cpu\",\n        \"//tensorflow/core:core_cpu_internal\",\n        \"//tensorflow/core:framework\",\n        \"//tensorflow/core:graph\",\n        \"//tensorflow/core:lib\",\n        \"@com_google_absl//absl/memory\",\n        \"@com_google_absl//absl/strings\",\n        \"@com_google_absl//absl/types:optional\",\n    ],\n)\n\ntf_cc_test(\n    name = \"functionalize_control_flow_test\",\n    srcs = [\"functionalize_control_flow_test.cc\"],\n    deps = [\n        \":functionalize_control_flow\",\n        \":test_util\",\n        \":tf2xla_util\",\n        \"//tensorflow/cc:cc_ops\",\n        \"//tensorflow/cc:cc_ops_internal\",\n        \"//tensorflow/cc:function_ops\",\n        \"//tensorflow/cc:functional_ops\",\n        \"//tensorflow/cc:ops\",\n        \"//tensorflow/cc:resource_variable_ops\",\n        \"//tensorflow/compiler/tf2xla/cc:xla_ops\",\n        \"//tensorflow/compiler/xla:status_macros\",\n        \"//tensorflow/core:core_cpu\",\n        \"//tensorflow/core:core_cpu_internal\",\n        \"//tensorflow/core:framework\",\n        \"//tensorflow/core:framework_internal\",\n        \"//tensorflow/core:ops\",\n        \"//tensorflow/core:resource_variable_ops_op_lib\",\n        \"//tensorflow/core:test\",\n        \"//tensorflow/core:test_main\",\n    ],\n)\n\ntf_cc_test(\n    name = \"functionalize_cond_test\",\n    srcs = [\"functionalize_cond_test.cc\"],\n    deps = [\n        \":functionalize_cond\",\n        \":functionalize_control_flow\",\n        \":test_util\",\n        \"//tensorflow/cc:cc_ops\",\n        \"//tensorflow/cc:cc_ops_internal\",\n        \"//tensorflow/cc:function_ops\",\n        \"//tensorflow/cc:ops\",\n        \"//tensorflow/cc:resource_variable_ops\",\n        \"//tensorflow/cc:scope\",\n        \"//tensorflow/compiler/tf2xla/cc:xla_ops\",\n        \"//tensorflow/compiler/xla:status_macros\",\n        \"//tensorflow/core:core_cpu\",\n        \"//tensorflow/core:core_cpu_internal\",\n        \"//tensorflow/core:framework\",\n        \"//tensorflow/core:framework_internal\",\n        \"//tensorflow/core:ops\",\n        \"//tensorflow/core:protos_all_cc\",\n        \"//tensorflow/core:resource_variable_ops_op_lib\",\n        \"//tensorflow/core:test\",\n        \"//tensorflow/core:test_main\",\n        \"//tensorflow/core:testlib\",\n        \"//tensorflow/core/platform:test\",\n        \"@com_google_absl//absl/container:flat_hash_set\",\n        \"@com_google_absl//absl/strings\",\n    ],\n)\n\ncc_library(\n    name = \"test_util\",\n    testonly = 1,\n    srcs = [\"test_util.cc\"],\n    hdrs = [\"test_util.h\"],\n    deps = [\n        \"//tensorflow/compiler/xla:status_macros\",\n        \"//tensorflow/core:core_cpu\",\n        \"//tensorflow/core:framework\",\n        \"//tensorflow/core:framework_internal\",\n        \"//tensorflow/core:lib\",\n        \"//tensorflow/core:protos_all_cc\",\n    ],\n)\n\ntf_cc_test(\n    name = \"xla_op_registry_test\",\n    srcs = [\"xla_op_registry_test.cc\"],\n    deps = [\n        \":xla_compiler\",\n        \"//tensorflow/core:test\",\n        \"//tensorflow/core:test_main\",\n    ],\n)\n\ncc_library(\n    name = \"resource_operation_table\",\n    srcs = [\"resource_operation_table.cc\"],\n    hdrs = [\"resource_operation_table.h\"],\n    deps = [\n        \"//tensorflow/core:lib\",\n        \"//tensorflow/core:ops\",\n        \"@com_google_absl//absl/algorithm:container\",\n        \"@com_google_absl//absl/container:flat_hash_map\",\n        \"@com_google_absl//absl/strings\",\n    ],\n)\n\ntf_cc_test(\n    name = \"resource_operation_table_test\",\n    srcs = [\"resource_operation_table_test.cc\"],\n    deps = [\n        \":resource_operation_table\",\n        \":xla_compiler\",\n        \"//tensorflow/compiler/tf2xla/kernels:xla_ops\",\n        \"//tensorflow/core:test\",\n        \"//tensorflow/core:test_main\",\n        \"@com_google_absl//absl/algorithm:container\",\n        \"@com_google_absl//absl/container:flat_hash_map\",\n        \"@com_google_absl//absl/strings\",\n    ],\n)\n\ncc_library(\n    name = \"side_effect_util\",\n    srcs = [\"side_effect_util.cc\"],\n    hdrs = [\"side_effect_util.h\"],\n    visibility = [\":friends\"],\n    deps = [\n        \"//tensorflow/core:core_cpu\",\n        \"@com_google_absl//absl/strings\",\n    ],\n)\n\ntf_cuda_cc_test(\n    name = \"fused_batchnorm_reserve_space_test\",\n    size = \"medium\",\n    srcs = [\"fused_batchnorm_reserve_space_test.cc\"],\n    tags = [\n        \"no_cuda_asan\",  # TODO(b/193450885)\n    ],\n    deps = [\n        \"//tensorflow/cc:cc_ops\",\n        \"//tensorflow/cc:ops\",\n        \"//tensorflow/cc:scope\",\n        \"//tensorflow/compiler/jit\",\n        \"//tensorflow/compiler/jit:flags\",\n        \"//tensorflow/core:core_cpu\",\n        \"//tensorflow/core:framework\",\n        \"//tensorflow/core:framework_internal\",\n        \"//tensorflow/core:lib\",\n        \"//tensorflow/core:protos_all_cc\",\n        \"//tensorflow/core:tensorflow\",\n        \"//tensorflow/core:test\",\n        \"//tensorflow/core:test_main\",\n        \"//tensorflow/core:testlib\",\n        \"//third_party/eigen3\",\n        \"@com_google_absl//absl/algorithm:container\",\n        \"@com_google_absl//absl/strings\",\n    ],\n)\n\ncc_library(\n    name = \"mlir_xla_op_kernel\",\n    srcs = [\"mlir_xla_op_kernel.cc\"],\n    hdrs = [\"mlir_xla_op_kernel.h\"],\n    deps = [\n        \":xla_compiler\",\n        \"//tensorflow/compiler/jit:xla_compilation_cache\",\n        \"//tensorflow/compiler/mlir:array_container_utils\",\n        \"//tensorflow/compiler/mlir/tensorflow:compile_mlir_util_no_tf_dialect_passes\",\n        \"@llvm-project//mlir:IR\",\n    ],\n)\n\ncc_library(\n    name = \"resource_util\",\n    srcs = [\"resource_util.cc\"],\n    hdrs = [\"resource_util.h\"],\n    visibility = [\":friends\"],\n    deps = [\n        \":resource_operation_table\",\n        \"//tensorflow/compiler/xla:status_macros\",\n        \"//tensorflow/core:core_cpu\",\n        \"//tensorflow/core:graph\",\n        \"//tensorflow/core:lib\",\n        \"//tensorflow/core:protos_all_cc\",\n        \"//tensorflow/stream_executor/lib\",\n        \"@com_google_absl//absl/container:flat_hash_map\",\n        \"@com_google_absl//absl/container:flat_hash_set\",\n        \"@com_google_absl//absl/hash\",\n        \"@com_google_absl//absl/strings\",\n    ],\n)\n\ntf_cuda_cc_test(\n    name = \"resource_util_test\",\n    size = \"small\",\n    srcs = [\"resource_util_test.cc\"],\n    deps = [\n        \":resource_util\",\n        \"//tensorflow/cc:scope\",\n        \"//tensorflow/core:framework\",\n        \"//tensorflow/core:graph\",\n        \"//tensorflow/core:protos_all_cc\",\n        \"//tensorflow/core:tensorflow\",\n        \"//tensorflow/core:test\",\n        \"//tensorflow/core:test_main\",\n        \"//tensorflow/core:testlib\",\n        \"@com_google_absl//absl/container:flat_hash_map\",\n        \"@com_google_absl//absl/container:flat_hash_set\",\n        \"@com_google_absl//absl/memory\",\n    ],\n)\n", "/* Copyright 2017 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n\n#include \"tensorflow/compiler/tf2xla/xla_op_kernel.h\"\n\n#include <numeric>\n\n#include \"absl/memory/memory.h\"\n#include \"tensorflow/compiler/tf2xla/literal_util.h\"\n#include \"tensorflow/compiler/tf2xla/shape_util.h\"\n#include \"tensorflow/compiler/tf2xla/type_util.h\"\n#include \"tensorflow/compiler/tf2xla/xla_compilation_device.h\"\n#include \"tensorflow/compiler/tf2xla/xla_context.h\"\n#include \"tensorflow/compiler/tf2xla/xla_helpers.h\"\n#include \"tensorflow/compiler/xla/client/value_inference.h\"\n#include \"tensorflow/compiler/xla/client/xla_builder.h\"\n#include \"tensorflow/compiler/xla/client/xla_computation.h\"\n#include \"tensorflow/compiler/xla/status_macros.h\"\n#include \"tensorflow/core/common_runtime/dma_helper.h\"\n#include \"tensorflow/core/platform/errors.h\"\n\nnamespace tensorflow {\n\nXlaOpKernelContext::XlaOpKernelContext(OpKernelContext* context)\n    : context_(context),\n      dynamic_dimension_is_minus_one_(false),\n      value_inference_(xla_context()->builder()) {}\n\nbool XlaOpKernelContext::ValidateInputsAreSameShape(OpKernel* op) {\n  return context_->ValidateInputsAreSameShape(op);\n}\n\nXlaContext* XlaOpKernelContext::xla_context() const {\n  return &XlaContext::Get(context_);\n}\n\nxla::XlaBuilder* XlaOpKernelContext::builder() const {\n  return xla_context()->builder();\n}\n\nxla::ValueInference& XlaOpKernelContext::value_inference() {\n  return value_inference_;\n}\n\nXlaCompiler* XlaOpKernelContext::compiler() const {\n  return xla_context()->compiler();\n}\n\nconst XlaExpression& XlaOpKernelContext::InputExpression(int index) {\n  return *XlaExpression::CastExpressionFromTensor(context_->input(index));\n}\n\nconst XlaExpression& XlaOpKernelContext::InputExpression(\n    absl::string_view name) {\n  return *XlaExpression::CastExpressionFromTensor(GetInputTensorByName(name));\n}\n\nxla::XlaOp XlaOpKernelContext::Input(int index) {\n  return InputExpression(index).AsXlaOp(builder());\n}\n\nxla::XlaOp XlaOpKernelContext::Input(absl::string_view name) {\n  return InputExpression(name).AsXlaOp(builder());\n}\n\nTensorShape XlaOpKernelContext::InputShape(int index) {\n  return context_->input(index).shape();\n}\n\nTensorShape XlaOpKernelContext::InputShape(absl::string_view name) {\n  return GetInputTensorByName(name).shape();\n}\n\nStatusOr<xla::Shape> XlaOpKernelContext::InputXlaShape(int index) {\n  return builder()->GetShape(Input(index));\n}\n\nStatusOr<xla::Shape> XlaOpKernelContext::InputXlaShape(absl::string_view name) {\n  return builder()->GetShape(Input(name));\n}\n\nDataType XlaOpKernelContext::input_type(int index) const {\n  DataType type = context_->input_dtype(index);\n  if (type == DT_UINT8) {\n    // Masqueraded XlaExpression could have different type. See\n    // XlaOpKernelContext::SetOutputExpression for details.\n    auto expression =\n        XlaExpression::CastExpressionFromTensor(context_->input(index));\n    type = expression->dtype();\n  }\n  return type;\n}\n\nDataType XlaOpKernelContext::InputType(absl::string_view name) {\n  const Tensor& tensor = GetInputTensorByName(name);\n  DataType type = tensor.dtype();\n  if (type == DT_UINT8) {\n    // Masqueraded XlaExpression could have different type. See\n    // XlaOpKernelContext::SetOutputExpression for details.\n    auto expression = XlaExpression::CastExpressionFromTensor(tensor);\n    type = expression->dtype();\n  }\n  return type;\n}\n\nxla::PrimitiveType XlaOpKernelContext::input_xla_type(int index) {\n  xla::PrimitiveType type;\n  Status status = DataTypeToPrimitiveType(input_type(index), &type);\n  if (!status.ok()) {\n    SetStatus(status);\n    return xla::PRIMITIVE_TYPE_INVALID;\n  }\n  return type;\n}\n\nxla::PrimitiveType XlaOpKernelContext::InputXlaType(absl::string_view name) {\n  xla::PrimitiveType type;\n  Status status = DataTypeToPrimitiveType(InputType(name), &type);\n  if (!status.ok()) {\n    SetStatus(status);\n    return xla::PRIMITIVE_TYPE_INVALID;\n  }\n  return type;\n}\n\nStatus XlaOpKernelContext::ConstantInput(int index,\n                                         xla::Literal* constant_literal,\n                                         xla::ValueInferenceMode mode) {\n  if (this->InputXlaShape(index)->is_dynamic()) {\n    return errors::InvalidArgument(\n        \"Reading input as constant from a dynamic tensor is not yet supported. \"\n        \"Xla shape: \",\n        this->InputXlaShape(index)->ToString());\n  }\n  return ConstantInputReshaped(index,\n                               context_->input(index).shape().dim_sizes(),\n                               constant_literal, mode);\n}\n\nstatic StatusOr<int> InputIndex(XlaOpKernelContext* context,\n                                absl::string_view name) {\n  int start, stop;\n  TF_RETURN_IF_ERROR(context->op_kernel().InputRange(name, &start, &stop));\n  if (stop != start + 1) {\n    return errors::InvalidArgument(\"OpKernel used list-valued input name '\",\n                                   name,\n                                   \"' when single-valued input was \"\n                                   \"expected\");\n  }\n  return start;\n}\n\nStatus XlaOpKernelContext::ResolveInputDynamism(\n    int index, xla::Literal* dynamism_literal) {\n  return ResolveInputDynamismReshaped(\n      index, context_->input(index).shape().dim_sizes(), dynamism_literal);\n}\n\nStatus XlaOpKernelContext::ResolveInputDynamism(\n    absl::string_view name, xla::Literal* dynamism_literal) {\n  TF_ASSIGN_OR_RETURN(int index, InputIndex(this, name));\n  return ResolveInputDynamism(index, dynamism_literal);\n}\n\nStatus XlaOpKernelContext::ConstantInput(absl::string_view name,\n                                         xla::Literal* constant_literal,\n                                         xla::ValueInferenceMode mode) {\n  TF_ASSIGN_OR_RETURN(int index, InputIndex(this, name));\n  return ConstantInput(index, constant_literal, mode);\n}\n\nStatus XlaOpKernelContext::ConstantInputReshaped(\n    int index, absl::Span<const int64_t> new_dims,\n    xla::Literal* constant_literal, xla::ValueInferenceMode mode) {\n  TF_ASSIGN_OR_RETURN(Tensor constant, ConstantInputTensor(index, mode));\n  Tensor temp(constant.dtype());\n  if (!temp.CopyFrom(constant, TensorShape(new_dims))) {\n    return errors::InvalidArgument(\n        context_->op_kernel().name(), \" input \", index, \" has shape \",\n        constant.shape().DebugString(),\n        \" but was asked to be reshaped to incompatible shape \",\n        TensorShape(new_dims).DebugString());\n  }\n\n  TF_ASSIGN_OR_RETURN(*constant_literal, HostTensorToLiteral(temp));\n  return OkStatus();\n}\n\n// Converts an int32 or int64 scalar literal to an int64.\nstatic Status LiteralToInt64Scalar(const xla::LiteralSlice& literal,\n                                   int64_t* out) {\n  if (literal.shape().rank() != 0) {\n    return errors::InvalidArgument(\"value is not a scalar\");\n  }\n  if (literal.shape().element_type() == xla::S32) {\n    *out = literal.Get<int32>({});\n  } else if (literal.shape().element_type() == xla::S64) {\n    *out = literal.Get<int64_t>({});\n  } else {\n    return errors::InvalidArgument(\"value must be either int32 or int64\");\n  }\n  return OkStatus();\n}\n\n// Converts an float32 or float64 scalar literal to a float64.\nstatic Status LiteralToFloat64Scalar(const xla::LiteralSlice& literal,\n                                     double* out) {\n  if (literal.shape().rank() != 0) {\n    return errors::InvalidArgument(\"value is not a scalar\");\n  }\n  if (literal.shape().element_type() == xla::F32) {\n    *out = literal.Get<float>({});\n  } else if (literal.shape().element_type() == xla::F64) {\n    *out = literal.Get<double>({});\n  } else {\n    return errors::InvalidArgument(\"value must be either float32 or float64\");\n  }\n  return OkStatus();\n}\n\nStatus XlaOpKernelContext::ConstantInputAsIntScalar(\n    int index, int64_t* out, xla::ValueInferenceMode mode) {\n  xla::Literal literal;\n  TF_RETURN_IF_ERROR(ConstantInput(index, &literal, mode));\n  return LiteralToInt64Scalar(literal, out);\n}\n\nStatus XlaOpKernelContext::ConstantInputAsIntScalar(\n    absl::string_view name, int64_t* out, xla::ValueInferenceMode mode) {\n  TF_ASSIGN_OR_RETURN(int index, InputIndex(this, name));\n  return ConstantInputAsIntScalar(index, out, mode);\n}\n\nStatus XlaOpKernelContext::ConstantInputAsFloatScalar(\n    int index, double* out, xla::ValueInferenceMode mode) {\n  xla::Literal literal;\n  TF_RETURN_IF_ERROR(ConstantInput(index, &literal, mode));\n  return LiteralToFloat64Scalar(literal, out);\n}\n\nstatic Status LiteralToPredVector(const xla::LiteralSlice& literal,\n                                  std::vector<bool>* out) {\n  if (literal.shape().rank() != 1) {\n    return errors::InvalidArgument(\"output_shape must be rank 1, got shape \",\n                                   literal.shape().DebugString());\n  }\n  int64_t size = xla::ShapeUtil::ElementsIn(literal.shape());\n  if (literal.shape().element_type() != xla::PRED) {\n    return errors::InvalidArgument(\"value is not PRED\");\n  }\n  for (int64_t i = 0; i < size; ++i) {\n    out->push_back(literal.Get<bool>({i}));\n  }\n  return OkStatus();\n}\n\nStatus XlaOpKernelContext::ResolveInputDynamismIntoPred(int index, bool* out) {\n  xla::Literal literal;\n  XlaExpression e = InputExpression(index);\n  auto* client = compiler() ? compiler()->client() : nullptr;\n  StatusOr<Tensor> dynamism_or_status = e.ResolveDynamism(client);\n  if (!dynamism_or_status.ok()) {\n    // When failed to resolve dynamism, conservatively consider the value\n    // dynamic. This could happen if the input depends on some ops like\n    // custom-call that is not supported generally for dynamism computation.\n    //\n    // TODO(b/176993339): Support resolving dynamism across computations so\n    // resolving dynamism will not fail in those cases.\n    *out = true;\n    return OkStatus();\n  }\n  Tensor dynamism = dynamism_or_status.ValueOrDie();\n\n  Tensor temp(dynamism.dtype());\n  TensorShape tensor_shape({});\n  if (!temp.CopyFrom(dynamism, tensor_shape)) {\n    return errors::InvalidArgument(\n        context_->op_kernel().name(), \" input \", index, \" has shape \",\n        dynamism.shape().DebugString(), \" which is not a R0 \", tensor_shape);\n  }\n\n  TF_ASSIGN_OR_RETURN(literal, HostTensorToLiteral(temp));\n  *out = literal.Get<bool>({});\n  return OkStatus();\n}\n\nStatus XlaOpKernelContext::ResolveInputDynamismIntoPredVector(\n    absl::string_view name, std::vector<bool>* out) {\n  TF_ASSIGN_OR_RETURN(int index, InputIndex(this, name));\n  return ResolveInputDynamismIntoPredVector(index, out);\n}\n\nStatus XlaOpKernelContext::ResolveInputDynamismIntoPred(absl::string_view name,\n                                                        bool* out) {\n  TF_ASSIGN_OR_RETURN(int index, InputIndex(this, name));\n  return ResolveInputDynamismIntoPred(index, out);\n}\n\nStatus XlaOpKernelContext::ResolveInputDynamismReshaped(\n    int index, absl::Span<const int64_t> new_dims,\n    xla::Literal* dynamism_literal) {\n  XlaExpression e = InputExpression(index);\n  auto* client = compiler() ? compiler()->client() : nullptr;\n  StatusOr<Tensor> dynamism_or_status = e.ResolveDynamism(client);\n  if (!dynamism_or_status.ok()) {\n    xla::Literal true_literal = xla::LiteralUtil::CreateR0<bool>(true);\n    // When failed to resolve dynamism, conservatively consider the value\n    // dynamic. This could happen if the input depends on some ops like\n    // custom-call that is not supported generally for dynamism computation.\n    *dynamism_literal =\n        true_literal\n            .Broadcast(xla::ShapeUtil::MakeShape(xla::PRED, new_dims), {})\n            .ValueOrDie();\n\n    return OkStatus();\n  }\n  Tensor dynamism = dynamism_or_status.ValueOrDie();\n\n  Tensor temp(dynamism.dtype());\n  if (!temp.CopyFrom(dynamism, TensorShape(new_dims))) {\n    return errors::InvalidArgument(\n        context_->op_kernel().name(), \" input \", index, \" has shape \",\n        dynamism.shape().DebugString(),\n        \" but was asked to be reshaped to incompatible shape \",\n        TensorShape(new_dims).DebugString());\n  }\n\n  TF_ASSIGN_OR_RETURN(*dynamism_literal, HostTensorToLiteral(temp));\n  return OkStatus();\n}\n\nStatus XlaOpKernelContext::ResolveInputDynamismIntoPredVector(\n    int index, std::vector<bool>* out) {\n  xla::Literal literal;\n  TF_RETURN_IF_ERROR(ResolveInputDynamismReshaped(\n      index, {InputShape(index).num_elements()}, &literal));\n\n  return LiteralToPredVector(literal, out);\n}\n\n// Converts an int32 or int64 1D literal to an int64 vector.\nstatic Status LiteralToInt64Vector(const xla::LiteralSlice& literal,\n                                   std::vector<int64_t>* out) {\n  if (literal.shape().rank() != 1) {\n    return errors::InvalidArgument(\"output_shape must be rank 1, got shape \",\n                                   literal.shape().DebugString());\n  }\n  int64_t size = xla::ShapeUtil::ElementsIn(literal.shape());\n  if (literal.shape().element_type() == xla::S32) {\n    for (int64_t i = 0; i < size; ++i) {\n      out->push_back(literal.Get<int32>({i}));\n    }\n  } else if (literal.shape().element_type() == xla::S64) {\n    for (int64_t i = 0; i < size; ++i) {\n      out->push_back(literal.Get<int64_t>({i}));\n    }\n  } else {\n    return errors::InvalidArgument(\"value must be either int32 or int64\");\n  }\n  return OkStatus();\n}\n\nStatus XlaOpKernelContext::ConstantInputAsIntVector(\n    int index, std::vector<int64_t>* out, xla::ValueInferenceMode mode) {\n  xla::Literal literal;\n  TF_RETURN_IF_ERROR(ConstantInput(index, &literal, mode));\n  return LiteralToInt64Vector(literal, out);\n}\n\nStatus XlaOpKernelContext::ConstantInputAsIntVector(\n    absl::string_view name, std::vector<int64_t>* out,\n    xla::ValueInferenceMode mode) {\n  TF_ASSIGN_OR_RETURN(int index, InputIndex(this, name));\n  return ConstantInputAsIntVector(index, out, mode);\n}\n\nStatus XlaOpKernelContext::ConstantInputReshapedToIntVector(\n    int index, std::vector<int64_t>* out, xla::ValueInferenceMode mode) {\n  xla::Literal literal;\n  TF_RETURN_IF_ERROR(ConstantInputReshaped(\n      index, {InputShape(index).num_elements()}, &literal, mode));\n  return LiteralToInt64Vector(literal, out);\n}\n\nStatus XlaOpKernelContext::ConstantInputReshapedToIntVector(\n    absl::string_view name, std::vector<int64_t>* out,\n    xla::ValueInferenceMode mode) {\n  TF_ASSIGN_OR_RETURN(int index, InputIndex(this, name));\n  xla::Literal literal;\n  TF_RETURN_IF_ERROR(ConstantInputReshaped(\n      index, {InputShape(index).num_elements()}, &literal, mode));\n  return LiteralToInt64Vector(literal, out);\n}\n\nStatus XlaOpKernelContext::ConstantInputAsInt64Literal(\n    int index, xla::Literal* out, xla::ValueInferenceMode mode) {\n  xla::Literal literal;\n  TF_RETURN_IF_ERROR(ConstantInput(index, &literal, mode));\n  switch (literal.shape().element_type()) {\n    case xla::S32: {\n      *out = xla::Literal(\n          xla::ShapeUtil::ChangeElementType(literal.shape(), xla::S64));\n      auto src_data = literal.data<int32>();\n      for (int64_t i = 0; i < src_data.size(); ++i) {\n        out->data<int64_t>()[i] = src_data[i];\n      }\n      return OkStatus();\n    }\n    case xla::S64:\n      *out = std::move(literal);\n      return OkStatus();\n\n    default:\n      return errors::InvalidArgument(\n          \"Invalid argument to ConstantInputAsInt64Literal: \",\n          xla::ShapeUtil::HumanString(literal.shape()));\n  }\n}\n\nStatus XlaOpKernelContext::ConstantInputAsInt64Literal(\n    absl::string_view name, xla::Literal* out, xla::ValueInferenceMode mode) {\n  TF_ASSIGN_OR_RETURN(int index, InputIndex(this, name));\n  return ConstantInputAsInt64Literal(index, out, mode);\n}\n\n// TODO(phawkins): validate that the dimensions form a valid shape, fail\n// gracefully if they do not.\nStatus XlaOpKernelContext::ConstantInputAsShape(int index, TensorShape* shape,\n                                                xla::ValueInferenceMode mode) {\n  xla::Literal literal;\n  TF_RETURN_IF_ERROR(ConstantInput(index, &literal, mode));\n  std::vector<int64_t> dims;\n  TF_RETURN_IF_ERROR(LiteralToInt64Vector(literal, &dims));\n  *shape = TensorShape(dims);\n  return OkStatus();\n}\n\nStatus XlaOpKernelContext::ConstantInputAsPartialShape(\n    int index, PartialTensorShape* shape) {\n  xla::Literal literal;\n  TF_RETURN_IF_ERROR(ConstantInput(index, &literal));\n  // If `literal` is a scalar it's value must be -1.\n  if (literal.shape().rank() == 0) {\n    int64_t shape_val;\n    TF_RETURN_IF_ERROR(LiteralToInt64Scalar(literal, &shape_val));\n    if (shape_val != -1) {\n      return errors::InvalidArgument(\n          \"Cannot convert value to PartialTensorShape: \", shape_val);\n    }\n    *shape = PartialTensorShape();  // Shape with unknown rank.\n    return OkStatus();\n  }\n  std::vector<int64_t> dims;\n  TF_RETURN_IF_ERROR(LiteralToInt64Vector(literal, &dims));\n  *shape = PartialTensorShape(dims);\n  return OkStatus();\n}\n\nStatus XlaOpKernelContext::InputList(absl::string_view name,\n                                     std::vector<xla::XlaOp>* handles,\n                                     std::vector<TensorShape>* shapes) {\n  OpInputList inputs;\n  TF_RETURN_IF_ERROR(context_->input_list(name, &inputs));\n  handles->clear();\n  shapes->clear();\n  for (const Tensor& input : inputs) {\n    handles->push_back(\n        XlaExpression::CastExpressionFromTensor(input)->AsXlaOp(builder()));\n    shapes->push_back(input.shape());\n  }\n  return OkStatus();\n}\n\nStatus XlaOpKernelContext::ConstantInputList(absl::string_view name,\n                                             std::vector<xla::Literal>* outputs,\n                                             xla::ValueInferenceMode mode) {\n  int start, stop;\n  TF_RETURN_IF_ERROR(op_kernel().InputRange(name, &start, &stop));\n  outputs->resize(stop - start);\n  for (int i = start; i < stop; ++i) {\n    TF_RETURN_IF_ERROR(ConstantInput(i, &(*outputs)[i], mode));\n  }\n  return OkStatus();\n}\n\nStatusOr<Tensor> XlaOpKernelContext::ConstantInputTensor(\n    int index, xla::ValueInferenceMode mode) {\n  XlaExpression e = InputExpression(index);\n  auto* client = compiler() ? compiler()->client() : nullptr;\n  StatusOr<std::optional<Tensor>> constant_or_status =\n      e.ResolveConstant(client, dynamic_dimension_is_minus_one_, mode);\n  if (!constant_or_status.ok()) {\n    Status status = constant_or_status.status();\n    errors::AppendToMessage(&status, \"while evaluating input \", index, \" of \",\n                            context_->op_kernel().type_string(),\n                            \" operator as a compile-time constant.\");\n    return status;\n  }\n  std::optional<Tensor> constant = constant_or_status.ValueOrDie();\n  if (!constant.has_value()) {\n    return errors::InvalidArgument(\n        \"Input \", index, \" to node `\", context_->op_kernel().name(),\n        \"` with op \", context_->op_kernel().type_string(),\n        \" must be a compile-time constant.\\n\\n\"\n        \"XLA compilation requires that operator arguments that represent \"\n        \"shapes or dimensions be evaluated to concrete values at compile time. \"\n        \"This error means that a shape or dimension argument could not be \"\n        \"evaluated at compile time, usually because the value of the argument \"\n        \"depends on a parameter to the computation, on a variable, or on a \"\n        \"stateful operation such as a random number generator.\");\n  }\n  return *constant;\n}\n\nnamespace {\n\nStatus ReadVariableInputTensor(const Tensor& tensor, DataType type,\n                               const XlaOpKernelContext* ctx,\n                               TensorShape* shape, xla::XlaOp* value) {\n  const XlaExpression* expression =\n      XlaExpression::CastExpressionFromTensor(tensor);\n  XlaResource* variable = expression->resource();\n  TF_RET_CHECK(variable != nullptr);\n  TF_RET_CHECK(variable->kind() == XlaResource::kVariable);\n  if (!variable->initialized()) {\n    return errors::FailedPrecondition(\n        \"Read variable failure \", variable->name(),\n        \". It could mean the variable is uninitialized or the variable is on \"\n        \"another device \");\n  }\n  if (variable->type() != type) {\n    return errors::InvalidArgument(\n        \"Trying to read variable with wrong dtype. Expected \",\n        DataTypeString(type), \" got \", DataTypeString(variable->type()));\n  }\n  if (shape) {\n    *shape = variable->shape();\n  }\n\n  if (!variable->IsOverwritten() && expression->constant_value()) {\n    TF_ASSIGN_OR_RETURN(xla::Literal literal,\n                        HostTensorToLiteral(*expression->constant_value()));\n    *value = xla::ConstantLiteral(ctx->builder(), literal);\n    return OkStatus();\n  }\n  auto shape_determination_fns =\n      ctx->compiler()->options().shape_determination_fns;\n  XlaLayoutPreference layout_preference =\n      shape_determination_fns.layout_preference_fn(\n          variable->shape(), variable->type(), std::nullopt);\n  TF_ASSIGN_OR_RETURN(xla::Shape representation_shape,\n                      shape_determination_fns.shape_representation_fn(\n                          variable->shape(), variable->type(),\n                          /*use_fast_memory=*/false, layout_preference));\n  xla::Shape xla_shape;\n  TF_RETURN_IF_ERROR(\n      TensorShapeToXLAShape(variable->type(), variable->shape(), &xla_shape));\n  if (xla::ShapeUtil::Compatible(xla_shape, representation_shape)) {\n    *value = variable->value();\n  } else {\n    *value = xla::Reshape(variable->value(), variable->shape().dim_sizes());\n  }\n  return OkStatus();\n}\n\n}  // namespace\n\nStatus XlaOpKernelContext::ReadVariableInput(int index, DataType type,\n                                             TensorShape* shape,\n                                             xla::XlaOp* value) {\n  return ReadVariableInputTensor(context_->input(index), type, this, shape,\n                                 value);\n}\n\nStatus XlaOpKernelContext::ReadVariableInput(absl::string_view name,\n                                             DataType type, TensorShape* shape,\n                                             xla::XlaOp* value) {\n  return ReadVariableInputTensor(GetInputTensorByName(name), type, this, shape,\n                                 value);\n}\n\nStatus XlaOpKernelContext::GetVariableTypeAndShape(int index, DataType* type,\n                                                   TensorShape* shape) const {\n  const Tensor& tensor = context_->input(index);\n  const XlaExpression* expression =\n      XlaExpression::CastExpressionFromTensor(tensor);\n  XlaResource* variable = expression->resource();\n  TF_RET_CHECK(variable != nullptr);\n  TF_RET_CHECK(variable->kind() == XlaResource::kVariable);\n  if (!variable->initialized()) {\n    return errors::InvalidArgument(\n        \"Read variable failure \", variable->name(),\n        \". It could mean the variable is uninitialized or the variable is on \"\n        \"another device \");\n  }\n  *type = variable->type();\n  *shape = variable->shape();\n  return OkStatus();\n}\n\nvoid XlaOpKernelContext::SetOutputExpression(int index,\n                                             const XlaExpression& expression) {\n  Status status = [&] {\n    // The step's default allocator is the dummy XlaCompilationAllocator which\n    // simply allocates a metadata buffer to hold the expression to which it\n    // corresponds.\n    // Provides a special behavior for DT_VARIANT and other types that are not\n    // trivially copyable. In those cases, allocate a tensor of type DT_UINT8.\n    if (!DataTypeCanUseMemcpy(expression.dtype())) {\n      // tensor_data() is not supported for tensors that cannot be copied via\n      // memcpy, as the copy logic might try to inspect the stored data (e.g.\n      // a std::string). This is likely to fail, as the data is invalid given\n      // that it actually encodes an XlaExpression. Using a uint8 tensor is\n      // always safe, so simply do that.\n      // TODO(jpienaar): This should be refactored to stop masquerading\n      // XlaExpressions as Tensors.\n      Tensor output;\n      TensorShape tensor_shape;\n      TF_RETURN_IF_ERROR(\n          context_->allocate_temp(DT_UINT8, tensor_shape, &output));\n      context_->set_output(index, output);\n    } else {\n      Tensor* output = nullptr;\n      TF_ASSIGN_OR_RETURN(TensorShape shape, expression.GetShape());\n      TF_RETURN_IF_ERROR(context_->allocate_output(index, shape, &output));\n    }\n    XlaExpression::AssignExpressionToTensor(expression,\n                                            context_->mutable_output(index));\n    return OkStatus();\n  }();\n  if (!status.ok()) {\n    SetStatus(status);\n  }\n}\n\nxla::PrimitiveType XlaOpKernelContext::output_xla_type(int index) {\n  xla::PrimitiveType type;\n  Status status = DataTypeToPrimitiveType(expected_output_dtype(index), &type);\n  if (!status.ok()) {\n    SetStatus(status);\n    return xla::PRIMITIVE_TYPE_INVALID;\n  }\n  return type;\n}\n\nvoid XlaOpKernelContext::SetOutput(int index, const xla::XlaOp& handle) {\n  SetOutputExpression(\n      index,\n      XlaExpression::XlaOp(handle, context_->expected_output_dtype(index)));\n}\n\nvoid XlaOpKernelContext::SetConstantOutput(int index, const Tensor& constant) {\n  SetOutputExpression(index, XlaExpression::Constant(constant));\n}\n\nvoid XlaOpKernelContext::SetTensorListOutput(int index,\n                                             const xla::XlaOp& handle) {\n  SetOutputExpression(index, XlaExpression::TensorList(handle));\n}\n\nvoid XlaOpKernelContext::SetResourceOutput(int index, XlaResource* resource) {\n  SetOutputExpression(index, XlaExpression::Resource(resource));\n}\n\nStatus XlaOpKernelContext::GetResourceInput(int index, XlaResource** resource) {\n  const XlaExpression* expression =\n      XlaExpression::CastExpressionFromTensor(context_->input(index));\n  TF_RET_CHECK(expression->resource() != nullptr);\n  *resource = expression->resource();\n  return OkStatus();\n}\n\nnamespace {\n\nStatus AssignVariableTensor(const Tensor& tensor, DataType type,\n                            const XlaOpKernelContext* ctx, xla::XlaOp handle,\n                            xla::XlaBuilder* builder) {\n  const XlaExpression* expression =\n      XlaExpression::CastExpressionFromTensor(tensor);\n  XlaResource* variable = expression->resource();\n  TF_RET_CHECK(variable != nullptr);\n  TF_RET_CHECK(variable->kind() == XlaResource::kVariable);\n\n  auto shape_or_status = builder->GetShape(handle);\n  if (!shape_or_status.ok()) {\n    return shape_or_status.status();\n  }\n  TensorShape shape;\n  TF_RETURN_IF_ERROR(\n      XLAShapeToTensorShape(shape_or_status.ValueOrDie(), &shape));\n\n  TF_RETURN_IF_ERROR(variable->SetTypeAndShape(type, shape));\n\n  auto shape_determination_fns =\n      ctx->compiler()->options().shape_determination_fns;\n  XlaLayoutPreference layout_preference =\n      shape_determination_fns.layout_preference_fn(shape, type, std::nullopt);\n  TF_ASSIGN_OR_RETURN(xla::Shape representation_shape,\n                      shape_determination_fns.shape_representation_fn(\n                          shape, type,\n                          /*use_fast_memory=*/false, layout_preference));\n  xla::Shape xla_shape;\n  TF_RETURN_IF_ERROR(TensorShapeToXLAShape(type, shape, &xla_shape));\n  if (!xla::ShapeUtil::Compatible(xla_shape, representation_shape)) {\n    handle = xla::Reshape(handle, representation_shape.dimensions());\n  }\n  variable->SetRepresentationShape(representation_shape);\n  return variable->SetValue(handle);\n}\n\n}  // namespace\n\nStatus XlaOpKernelContext::AssignVariable(int input_index, DataType type,\n                                          xla::XlaOp handle) {\n  TF_RET_CHECK(handle.valid());\n  return AssignVariableTensor(context_->input(input_index), type, this, handle,\n                              builder());\n}\n\nStatus XlaOpKernelContext::AssignVariable(absl::string_view name, DataType type,\n                                          xla::XlaOp handle) {\n  TF_RET_CHECK(handle.valid());\n  return AssignVariableTensor(GetInputTensorByName(name), type, this, handle,\n                              builder());\n}\n\nstatic Status GetStatusWithStackTrace(const Status& s,\n                                      const XlaOpKernelContext* ctx) {\n  if (s.code() == error::INVALID_ARGUMENT) {\n    return Status{s.code(),\n                  absl::StrCat(s.error_message(), \"\\n\", ctx->StackTrace())};\n  }\n  return s;\n}\n\nvoid XlaOpKernelContext::CtxFailure(const Status& s) {\n  context_->CtxFailure(GetStatusWithStackTrace(s, this));\n}\nvoid XlaOpKernelContext::CtxFailureWithWarning(const Status& s) {\n  context_->CtxFailureWithWarning(GetStatusWithStackTrace(s, this));\n}\n\nvoid XlaOpKernelContext::CtxFailure(const char* file, int line,\n                                    const Status& s) {\n  context_->CtxFailure(file, line, GetStatusWithStackTrace(s, this));\n}\nvoid XlaOpKernelContext::CtxFailureWithWarning(const char* file, int line,\n                                               const Status& s) {\n  context_->CtxFailureWithWarning(file, line, GetStatusWithStackTrace(s, this));\n}\n\nconst xla::XlaComputation* XlaOpKernelContext::GetOrCreateMax(\n    const DataType type) {\n  return xla_context()->GetOrCreateMax(type);\n}\n\nconst xla::XlaComputation* XlaOpKernelContext::GetOrCreateMin(\n    const DataType type) {\n  return xla_context()->GetOrCreateMin(type);\n}\n\nconst xla::XlaComputation* XlaOpKernelContext::GetOrCreateAdd(\n    const DataType type) {\n  return xla_context()->GetOrCreateAdd(type);\n}\n\nconst xla::XlaComputation* XlaOpKernelContext::GetOrCreateMul(\n    const DataType type) {\n  return xla_context()->GetOrCreateMul(type);\n}\n\nconst Tensor& XlaOpKernelContext::GetInputTensorByName(absl::string_view name) {\n  const Tensor* tensor;\n  CHECK(context_->input(name, &tensor).ok());\n  return *tensor;\n}\n\nXlaOpKernel::XlaOpKernel(OpKernelConstruction* context) : OpKernel(context) {}\n\nvoid XlaOpKernel::Compute(OpKernelContext* context) {\n  XlaOpKernelContext xla_context(context);\n  Compile(&xla_context);\n}\n\nstd::string XlaOpKernelContext::StackTrace() const {\n  if (const AbstractStackTrace* stack_trace =\n          xla_context()->StackTraceForNodeName(op_kernel().name())) {\n    AbstractStackTrace::TracePrintingOptions opts;\n    opts.show_line_contents = true;\n    opts.filter_common_prefix = true;\n    opts.drop_internal_frames = true;\n    return absl::StrCat(\"\\nStack trace for op definition: \\n\",\n                        stack_trace->ToString(opts), \"\\n\");\n  } else {\n    return \"\";\n  }\n}\n\n}  // namespace tensorflow\n", "/* Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n#define EIGEN_USE_THREADS\n\n#include \"tensorflow/core/kernels/pooling_ops_3d.h\"\n\n#include <array>\n\n#include \"third_party/eigen3/Eigen/Core\"\n#include \"third_party/eigen3/unsupported/Eigen/CXX11/Tensor\"\n#include \"tensorflow/core/framework/kernel_shape_util.h\"\n#include \"tensorflow/core/framework/numeric_op.h\"\n#include \"tensorflow/core/framework/op_kernel.h\"\n#include \"tensorflow/core/framework/register_types.h\"\n#include \"tensorflow/core/framework/tensor.h\"\n#include \"tensorflow/core/framework/tensor_shape.h\"\n#include \"tensorflow/core/framework/tensor_slice.h\"\n#include \"tensorflow/core/kernels/eigen_pooling.h\"\n#include \"tensorflow/core/kernels/ops_util.h\"\n#include \"tensorflow/core/lib/core/errors.h\"\n#include \"tensorflow/core/util/padding.h\"\n#include \"tensorflow/core/util/tensor_format.h\"\n#include \"tensorflow/core/util/work_sharder.h\"\n\n#if GOOGLE_CUDA || TENSORFLOW_USE_ROCM\n#include \"tensorflow/core/kernels/cudnn_pooling_gpu.h\"\n#include \"tensorflow/core/kernels/pooling_ops_3d_gpu.h\"\n#endif\n\n\nnamespace tensorflow {\n\ntypedef Eigen::ThreadPoolDevice CPUDevice;\ntypedef Eigen::GpuDevice GPUDevice;\n\nPool3dParameters::Pool3dParameters(OpKernelContext* context,\n                                   const std::vector<int32>& ksize,\n                                   const std::vector<int32>& stride,\n                                   Padding padding, TensorFormat data_format,\n                                   const TensorShape& tensor_in_shape) {\n  // For maxpooling, tensor_in should have 4 dimensions.\n  OP_REQUIRES(context, tensor_in_shape.dims() == 5,\n              errors::InvalidArgument(\"tensor_in must be 4-dimensional\"));\n\n  this->data_format = data_format;\n  depth = GetTensorDim(tensor_in_shape, data_format, 'C');\n  tensor_in_planes = GetTensorDim(tensor_in_shape, data_format, '0');\n  tensor_in_rows = GetTensorDim(tensor_in_shape, data_format, '1');\n  tensor_in_cols = GetTensorDim(tensor_in_shape, data_format, '2');\n  tensor_in_batch = GetTensorDim(tensor_in_shape, data_format, 'N');\n  window_planes = GetTensorDim(ksize, data_format, '0');\n  window_rows = GetTensorDim(ksize, data_format, '1');\n  window_cols = GetTensorDim(ksize, data_format, '2');\n  depth_window = GetTensorDim(ksize, data_format, 'C');\n  plane_stride = GetTensorDim(stride, data_format, '0');\n  row_stride = GetTensorDim(stride, data_format, '1');\n  col_stride = GetTensorDim(stride, data_format, '2');\n  depth_stride = GetTensorDim(stride, data_format, 'C');\n\n  // We only support 3D pooling across plane/width/height. Depthwise\n  // pooling is not supported.\n  OP_REQUIRES(\n      context, depth_window == 1 && depth_stride == 1,\n      errors::Unimplemented(\n          \"Pooling3d only supports pooling across plane/width/height.\"));\n\n  OP_REQUIRES_OK(context, GetWindowedOutputSize(tensor_in_planes, window_planes,\n                                                plane_stride, padding,\n                                                &out_plane, &pad_planes));\n  OP_REQUIRES_OK(context,\n                 GetWindowedOutputSize(tensor_in_rows, window_rows, row_stride,\n                                       padding, &out_height, &pad_rows));\n  OP_REQUIRES_OK(context,\n                 GetWindowedOutputSize(tensor_in_cols, window_cols, col_stride,\n                                       padding, &out_width, &pad_cols));\n}\n\nTensorShape Pool3dParameters::forward_output_shape() {\n  return ShapeFromFormat(data_format, tensor_in_batch,\n                         {{out_plane, out_height, out_width}}, depth);\n}\n\ntemplate <typename T>\nstruct LaunchPoolingOp<CPUDevice, T, AVG> {\n  static void launch(OpKernelContext* context, const Tensor& tensor_in,\n                     const std::array<int64, 3>& window,\n                     const std::array<int64, 3>& stride,\n                     const std::array<int64, 3>& padding,\n                     TensorFormat data_format, Padding padding_type,\n                     Tensor* output) {\n    output->tensor<T, 5>().device(context->eigen_device<CPUDevice>()) =\n        Eigen::CuboidAvgPooling(tensor_in.tensor<T, 5>(), window[0], window[1],\n                                window[2], stride[0], stride[1], stride[2],\n                                BrainPadding2EigenPadding(padding_type));\n  }\n};\n\ntemplate <typename T>\nstruct LaunchPoolingOp<CPUDevice, T, MAX> {\n  static void launch(OpKernelContext* context, const Tensor& tensor_in,\n                     const std::array<int64, 3>& window,\n                     const std::array<int64, 3>& stride,\n                     const std::array<int64, 3>& padding,\n                     TensorFormat data_format, Padding padding_type,\n                     Tensor* output) {\n    output->tensor<T, 5>().device(context->eigen_device<CPUDevice>()) =\n        Eigen::CuboidMaxPooling(tensor_in.tensor<T, 5>(), window[0], window[1],\n                                window[2], stride[0], stride[1], stride[2],\n                                BrainPadding2EigenPadding(padding_type));\n  }\n};\n\ntemplate <typename Device, typename T, PoolingType Type>\nclass Pooling3DOp : public UnaryOp<T> {\n public:\n  explicit Pooling3DOp(OpKernelConstruction* context) : UnaryOp<T>(context) {\n    string data_format;\n    OP_REQUIRES_OK(context, context->GetAttr(\"data_format\", &data_format));\n    OP_REQUIRES(context, FormatFromString(data_format, &data_format_),\n                errors::InvalidArgument(\"Invalid data format\"));\n    if (context->device_type() == DEVICE_CPU) {\n      OP_REQUIRES(\n          context, data_format_ == FORMAT_NHWC,\n          errors::InvalidArgument(\"Default Pooling3DOp only supports NDHWC \",\n                                  \"on device type \",\n                                  DeviceTypeString(context->device_type())));\n    }\n    OP_REQUIRES_OK(context, context->GetAttr(\"ksize\", &ksize_));\n    OP_REQUIRES(context, ksize_.size() == 5,\n                errors::InvalidArgument(\"Sliding window ksize field must \"\n                                        \"specify 5 dimensions\"));\n    bool non_negative =\n        std::all_of(ksize_.begin(), ksize_.end(), [](int k) { return k > 0; });\n    OP_REQUIRES(context, non_negative,\n                errors::InvalidArgument(\"Sliding window ksize field must \"\n                                        \"have non-negative dimensions\"));\n    OP_REQUIRES_OK(context, context->GetAttr(\"strides\", &stride_));\n    OP_REQUIRES(context, stride_.size() == 5,\n                errors::InvalidArgument(\"Sliding window stride field must \"\n                                        \"specify 5 dimensions\"));\n    OP_REQUIRES_OK(context, context->GetAttr(\"padding\", &padding_));\n    OP_REQUIRES(context,\n                (GetTensorDim(ksize_, data_format_, 'N') == 1 &&\n                 GetTensorDim(stride_, data_format_, 'N') == 1),\n                errors::Unimplemented(\n                    \"Pooling is not yet supported on the batch dimension.\"));\n    OP_REQUIRES(context,\n                (GetTensorDim(ksize_, data_format_, 'C') == 1 &&\n                 GetTensorDim(stride_, data_format_, 'C') == 1),\n                errors::Unimplemented(\n                    \"Pooling is not yet supported on the depth dimension.\"));\n  }\n\n  void Compute(OpKernelContext* context) override {\n    const Tensor& tensor_in = context->input(0);\n\n    OP_REQUIRES(context, tensor_in.dims() == 5,\n                errors::InvalidArgument(\"tensor_in must be 5-dimensional\"));\n    const int64_t depth = GetTensorDim(tensor_in, data_format_, 'C');\n    const int64_t in_batch = GetTensorDim(tensor_in, data_format_, 'N');\n\n    // Dimension order for these arrays is: x, y, z.\n    std::array<int64_t, 3> input_size{\n        {GetTensorDim(tensor_in, data_format_, '2'),\n         GetTensorDim(tensor_in, data_format_, '1'),\n         GetTensorDim(tensor_in, data_format_, '0')}};\n    std::array<int64_t, 3> window{{GetTensorDim(ksize_, data_format_, '2'),\n                                   GetTensorDim(ksize_, data_format_, '1'),\n                                   GetTensorDim(ksize_, data_format_, '0')}};\n    std::array<int64_t, 3> stride{{GetTensorDim(stride_, data_format_, '2'),\n                                   GetTensorDim(stride_, data_format_, '1'),\n                                   GetTensorDim(stride_, data_format_, '0')}};\n    std::array<int64_t, 3> padding, out;\n\n    OP_REQUIRES_OK(context, Get3dOutputSize(input_size, window, stride,\n                                            padding_, &out, &padding));\n\n    TensorShape out_shape = ShapeFromFormat(data_format_, in_batch,\n                                            {{out[2], out[1], out[0]}}, depth);\n    Tensor* output;\n    OP_REQUIRES_OK(context, context->allocate_output(0, out_shape, &output));\n    if (out_shape.num_elements() == 0) return;\n    LaunchPoolingOp<Device, T, Type>::launch(context, tensor_in, window, stride,\n                                             padding, data_format_, padding_,\n                                             output);\n  }\n\n private:\n  std::vector<int32> ksize_;\n  std::vector<int32> stride_;\n  Padding padding_;\n  TensorFormat data_format_;\n};\n\ntemplate <typename T>\nstruct LaunchMaxPooling3dGradOp<CPUDevice, T> {\n  static void launch(OpKernelContext* context, const Tensor& tensor_in,\n                     const Tensor& tensor_out, const Tensor& out_backprop,\n                     const std::array<int64, 3>& window,\n                     const std::array<int64, 3>& stride,\n                     const std::array<int64, 3>& out,\n                     const std::array<int64, 3>& padding,\n                     TensorFormat data_format, Tensor* output) {\n    output->flat<T>().setZero();\n    for (int64_t p = 0; p < out_backprop.dim_size(3); ++p) {\n      // Calculate broadcast size for planes/rows/cols. For SAME padding,\n      // current index could be in the padding area, and\n      //   p * stride_planes + window_planes\n      // could be beyond the input tensor's boundary. In such cases, change\n      // the starting index and reduce the broadcast size.\n      //\n      // The same procedure is repeated for every spatial dimension in the\n      // nested loops below.\n      int pindex, psize;\n      std::array<int64_t, 3> input_size{{tensor_in.dim_size(3),\n                                         tensor_in.dim_size(2),\n                                         tensor_in.dim_size(1)}};\n      OP_REQUIRES_OK(context,\n                     GetBroadcastSize(p, input_size[0], window[0], stride[0],\n                                      padding[0], &pindex, &psize));\n      for (int64_t r = 0; r < out_backprop.dim_size(2); ++r) {\n        int rindex, rsize;\n        OP_REQUIRES_OK(context,\n                       GetBroadcastSize(r, input_size[1], window[1], stride[1],\n                                        padding[1], &rindex, &rsize));\n        for (int64_t c = 0; c < out_backprop.dim_size(1); ++c) {\n          int cindex, csize;\n          OP_REQUIRES_OK(\n              context, GetBroadcastSize(c, input_size[2], window[2], stride[2],\n                                        padding[2], &cindex, &csize));\n          TensorSlice src{{0, -1}, {c, 1}, {r, 1}, {p, 1}, {0, -1}};\n          TensorSlice dst{{0, -1},\n                          {cindex, csize},\n                          {rindex, rsize},\n                          {pindex, psize},\n                          {0, -1}};\n          Eigen::DSizes<Eigen::DenseIndex, 5> src_indices;\n          Eigen::DSizes<Eigen::DenseIndex, 5> src_sizes;\n          Eigen::DSizes<Eigen::DenseIndex, 5> dst_indices;\n          Eigen::DSizes<Eigen::DenseIndex, 5> dst_sizes;\n          src.FillIndicesAndSizes<5>(out_backprop.shape(), &src_indices,\n                                     &src_sizes);\n          dst.FillIndicesAndSizes<5>(tensor_in.shape(), &dst_indices,\n                                     &dst_sizes);\n\n          Eigen::IndexList<Eigen::type2index<1>, int, int, int,\n                           Eigen::type2index<1>>\n              bcast;\n          bcast.set(1, csize);\n          bcast.set(2, rsize);\n          bcast.set(3, psize);\n\n          // Slice from tensor_in.\n          Eigen::Tensor<T, 5, Eigen::RowMajor> tensor_in_slice(dst_sizes);\n          tensor_in_slice.device(context->eigen_cpu_device()) =\n              tensor_in.tensor<T, 5>().slice(dst_indices, dst_sizes);\n\n          // Slice from tensor_out.\n          Eigen::Tensor<T, 5, Eigen::RowMajor> tensor_out_slice(src_sizes);\n          tensor_out_slice.device(context->eigen_cpu_device()) =\n              tensor_out.tensor<T, 5>().slice(src_indices, src_sizes);\n\n          // Backprop slice.\n          Eigen::Tensor<T, 5, Eigen::RowMajor> out_backprop_slice(src_sizes);\n          out_backprop_slice.device(context->eigen_cpu_device()) =\n              out_backprop.tensor<T, 5>().slice(src_indices, src_sizes);\n\n          // The true backprop slice: if an element is the max, choose\n          // the backprop slice; otherwise set to 0.\n          Eigen::Tensor<T, 5, Eigen::RowMajor> select_slice(dst_sizes);\n          Eigen::Tensor<T, 5, Eigen::RowMajor> mat0(dst_sizes);\n          mat0.setZero();\n          select_slice =\n              ((tensor_in_slice - tensor_out_slice.broadcast(bcast)).abs() <\n               tensor_in_slice.constant(1e-5))\n                  .select(out_backprop_slice.broadcast(bcast), mat0);\n\n          output->tensor<T, 5>()\n              .slice(dst_indices, dst_sizes)\n              .device(context->eigen_cpu_device()) += select_slice;\n        }\n      }\n    }\n  }\n};\n\ntemplate <class Device, class T>\nclass MaxPooling3dGradOp : public OpKernel {\n public:\n  explicit MaxPooling3dGradOp(OpKernelConstruction* context)\n      : OpKernel(context) {\n    string data_format;\n    OP_REQUIRES_OK(context, context->GetAttr(\"data_format\", &data_format));\n    OP_REQUIRES(context, FormatFromString(data_format, &data_format_),\n                errors::InvalidArgument(\"Invalid data format\"));\n    if (context->device_type() == DEVICE_CPU) {\n      OP_REQUIRES(\n          context, data_format_ == FORMAT_NHWC,\n          errors::InvalidArgument(\n              \"Default MaxPooling3dGradOp only supports NDHWC \",\n              \"on device type \", DeviceTypeString(context->device_type())));\n    }\n    OP_REQUIRES_OK(context, context->GetAttr(\"ksize\", &ksize_));\n    OP_REQUIRES(context, ksize_.size() == 5,\n                errors::InvalidArgument(\"Sliding window ksize field must \"\n                                        \"specify 5 dimensions\"));\n    OP_REQUIRES_OK(context, context->GetAttr(\"strides\", &stride_));\n    OP_REQUIRES(context, stride_.size() == 5,\n                errors::InvalidArgument(\"Sliding window stride field must \"\n                                        \"specify 5 dimensions\"));\n    OP_REQUIRES_OK(context, context->GetAttr(\"padding\", &padding_));\n    OP_REQUIRES(context,\n                (GetTensorDim(ksize_, data_format_, 'N') == 1 &&\n                 GetTensorDim(stride_, data_format_, 'N') == 1),\n                errors::Unimplemented(\n                    \"Pooling is not yet supported on the batch dimension.\"));\n    OP_REQUIRES(context,\n                (GetTensorDim(ksize_, data_format_, 'C') == 1 &&\n                 GetTensorDim(stride_, data_format_, 'C') == 1),\n                errors::Unimplemented(\n                    \"Pooling is not yet supported on the depth dimension.\"));\n  }\n\n  void Compute(OpKernelContext* context) override {\n    const Tensor& tensor_in = context->input(0);\n    const Tensor& tensor_out = context->input(1);\n    const Tensor& out_backprop = context->input(2);\n    OP_REQUIRES(context, tensor_in.dims() == 5,\n                errors::InvalidArgument(\"tensor_in must be 5-dimensional\"));\n    OP_REQUIRES(context, tensor_out.dims() == 5,\n                errors::InvalidArgument(\"tensor_out must be 5-dimensional\"));\n    OP_REQUIRES(context, out_backprop.dims() == 5,\n                errors::InvalidArgument(\"out_backprop must be 5-dimensional\"));\n\n    const TensorShape& output_shape = tensor_in.shape();\n    Tensor* input_backprop;\n    OP_REQUIRES_OK(context,\n                   context->allocate_output(0, output_shape, &input_backprop));\n    std::array<int64_t, 3> input_size{\n        {GetTensorDim(output_shape, data_format_, '2'),\n         GetTensorDim(output_shape, data_format_, '1'),\n         GetTensorDim(output_shape, data_format_, '0')}};\n    std::array<int64_t, 3> window{{GetTensorDim(ksize_, data_format_, '2'),\n                                   GetTensorDim(ksize_, data_format_, '1'),\n                                   GetTensorDim(ksize_, data_format_, '0')}};\n    std::array<int64_t, 3> stride{{GetTensorDim(stride_, data_format_, '2'),\n                                   GetTensorDim(stride_, data_format_, '1'),\n                                   GetTensorDim(stride_, data_format_, '0')}};\n    std::array<int64_t, 3> out, padding;\n\n    OP_REQUIRES_OK(context, Get3dOutputSize(input_size, window, stride,\n                                            padding_, &out, &padding));\n\n    const int64_t depth = GetTensorDim(tensor_in, data_format_, 'C');\n    const int64_t in_batch = GetTensorDim(tensor_in, data_format_, 'N');\n    TensorShape out_shape = ShapeFromFormat(data_format_, in_batch,\n                                            {{out[2], out[1], out[0]}}, depth);\n    OP_REQUIRES(\n        context, tensor_out.shape() == out_shape,\n        errors::InvalidArgument(\"Expected orig_output shape to be \", out_shape,\n                                \", but got \", tensor_out.shape()));\n    OP_REQUIRES(context, out_backprop.shape() == out_shape,\n                errors::InvalidArgument(\"Expected grad shape to be \", out_shape,\n                                        \", but got \", out_backprop.shape()));\n\n    LaunchMaxPooling3dGradOp<Device, T>::launch(\n        context, tensor_in, tensor_out, out_backprop, window, stride, out,\n        padding, data_format_, input_backprop);\n  }\n\n private:\n  std::vector<int32> ksize_;\n  std::vector<int32> stride_;\n  Padding padding_;\n  TensorFormat data_format_;\n};\n\ntemplate <typename T>\nstruct LaunchAvgPooling3dGradOp<CPUDevice, T> {\n  static void launch(OpKernelContext* context,\n                     const TensorShape& tensor_in_shape,\n                     const Tensor& out_backprop,\n                     const std::array<int64, 3>& window,\n                     const std::array<int64, 3>& stride,\n                     const std::array<int64, 3>& output_shape,\n                     const std::array<int64, 3>& padding,\n                     TensorFormat data_format, Tensor* output) {\n    OP_REQUIRES(\n        context, tensor_in_shape.dim_size(0) == out_backprop.dim_size(0),\n        errors::InvalidArgument(\n            \"Expected first dimension of tensor_in_shape and \"\n            \"out_backprop to match, got \",\n            tensor_in_shape.dim_size(0), \" and \", out_backprop.dim_size(0)));\n    OP_REQUIRES(\n        context, tensor_in_shape.dim_size(4) == out_backprop.dim_size(4),\n        errors::InvalidArgument(\n            \"Expected last dimension of tensor_in_shape and \"\n            \"out_backprop to match, got \",\n            tensor_in_shape.dim_size(4), \" and \", out_backprop.dim_size(4)));\n\n    output->flat<T>().setZero();\n    std::array<int64_t, 3> input_size = {{tensor_in_shape.dim_size(3),\n                                          tensor_in_shape.dim_size(2),\n                                          tensor_in_shape.dim_size(1)}};\n    for (int64_t p = 0; p < out_backprop.dim_size(3); ++p) {\n      // Calculate broadcast size for planes/rows/cols. For SAME padding,\n      // current index could be in the padding area, and\n      //   p * stride_planes + window_planes\n      // could be beyond the input tensor's boundary. In such cases, change\n      // the starting index and reduce the broadcast size.\n      //\n      // The same procedure is repeated for every spatial dimension in the\n      // nested loops below.\n      int pindex, psize;\n      OP_REQUIRES_OK(context,\n                     GetBroadcastSize(p, input_size[0], window[0], stride[0],\n                                      padding[0], &pindex, &psize));\n      for (int64_t r = 0; r < out_backprop.dim_size(2); ++r) {\n        int rindex, rsize;\n        OP_REQUIRES_OK(context,\n                       GetBroadcastSize(r, input_size[1], window[1], stride[1],\n                                        padding[1], &rindex, &rsize));\n        for (int64_t c = 0; c < out_backprop.dim_size(1); ++c) {\n          int cindex, csize;\n          OP_REQUIRES_OK(\n              context, GetBroadcastSize(c, input_size[2], window[2], stride[2],\n                                        padding[2], &cindex, &csize));\n          TensorSlice src{{0, -1}, {c, 1}, {r, 1}, {p, 1}, {0, -1}};\n          TensorSlice dst{{0, -1},\n                          {cindex, csize},\n                          {rindex, rsize},\n                          {pindex, psize},\n                          {0, -1}};\n          Eigen::DSizes<Eigen::DenseIndex, 5> src_indices;\n          Eigen::DSizes<Eigen::DenseIndex, 5> src_sizes;\n          Eigen::DSizes<Eigen::DenseIndex, 5> dst_indices;\n          Eigen::DSizes<Eigen::DenseIndex, 5> dst_sizes;\n          src.FillIndicesAndSizes<5>(out_backprop.shape(), &src_indices,\n                                     &src_sizes);\n          dst.FillIndicesAndSizes<5>(tensor_in_shape, &dst_indices, &dst_sizes);\n          Eigen::IndexList<Eigen::type2index<1>, int, int, int,\n                           Eigen::type2index<1>>\n              bcast;\n          bcast.set(1, csize);\n          bcast.set(2, rsize);\n          bcast.set(3, psize);\n          Eigen::Tensor<T, 5, Eigen::RowMajor> slices(src_sizes);\n          slices.device(context->eigen_cpu_device()) =\n              out_backprop.tensor<T, 5>().slice(src_indices, src_sizes);\n          // Divide by the size of the actual patch (psize * rsize * csize).\n          float divide_size = rsize * csize * psize * 1.0f;\n          slices *= slices.constant(1.0f / divide_size);\n\n          output->tensor<T, 5>()\n              .slice(dst_indices, dst_sizes)\n              .device(context->eigen_cpu_device()) += slices.broadcast(bcast);\n        }\n      }\n    }\n  }\n};\n\ntemplate <class Device, class T>\nclass AvgPooling3dGradOp : public OpKernel {\n public:\n  explicit AvgPooling3dGradOp(OpKernelConstruction* context)\n      : OpKernel(context) {\n    string data_format;\n    OP_REQUIRES_OK(context, context->GetAttr(\"data_format\", &data_format));\n    OP_REQUIRES(context, FormatFromString(data_format, &data_format_),\n                errors::InvalidArgument(\"Invalid data format\"));\n    if (context->device_type() == DEVICE_CPU) {\n      OP_REQUIRES(\n          context, data_format_ == FORMAT_NHWC,\n          errors::InvalidArgument(\n              \"Default AvgPooling3dGradOp only supports NDHWC \",\n              \"on device type \", DeviceTypeString(context->device_type())));\n    }\n    OP_REQUIRES_OK(context, context->GetAttr(\"ksize\", &ksize_));\n    OP_REQUIRES(context, ksize_.size() == 5,\n                errors::InvalidArgument(\"Sliding window ksize field must \"\n                                        \"specify 5 dimensions\"));\n    OP_REQUIRES_OK(context, context->GetAttr(\"strides\", &stride_));\n    OP_REQUIRES(context, stride_.size() == 5,\n                errors::InvalidArgument(\"Sliding window stride field must \"\n                                        \"specify 5 dimensions\"));\n    OP_REQUIRES_OK(context, context->GetAttr(\"padding\", &padding_));\n    OP_REQUIRES(context,\n                (GetTensorDim(ksize_, data_format_, 'N') == 1 &&\n                 GetTensorDim(stride_, data_format_, 'N') == 1),\n                errors::Unimplemented(\n                    \"Pooling is not yet supported on the batch dimension.\"));\n    OP_REQUIRES(context,\n                (GetTensorDim(ksize_, data_format_, 'C') == 1 &&\n                 GetTensorDim(stride_, data_format_, 'C') == 1),\n                errors::Unimplemented(\n                    \"Pooling is not yet supported on the depth dimension.\"));\n  }\n\n  void Compute(OpKernelContext* context) override {\n    const Tensor& tensor_in_shape = context->input(0);\n    const Tensor& out_backprop = context->input(1);\n    OP_REQUIRES(\n        context,\n        tensor_in_shape.dims() == 1 && tensor_in_shape.NumElements() == 5,\n        errors::InvalidArgument(\"tensor_in must be 1-dimensional and 5 \"\n                                \"elements\"));\n    OP_REQUIRES(context, out_backprop.dims() == 5,\n                errors::InvalidArgument(\"out_backprop must be 5-dimensional\"));\n\n    TensorShape output_shape;\n    auto shape_vec = tensor_in_shape.vec<int32>();\n    for (int64_t i = 0; i < tensor_in_shape.NumElements(); ++i) {\n      output_shape.AddDim(shape_vec(i));\n    }\n\n    Tensor* output;\n    OP_REQUIRES_OK(context, context->allocate_output(0, output_shape, &output));\n\n    // Dimension order for these arrays is x, y, z.\n    std::array<int64_t, 3> input_size{\n        {GetTensorDim(output_shape, data_format_, '2'),\n         GetTensorDim(output_shape, data_format_, '1'),\n         GetTensorDim(output_shape, data_format_, '0')}};\n    std::array<int64_t, 3> window{{GetTensorDim(ksize_, data_format_, '2'),\n                                   GetTensorDim(ksize_, data_format_, '1'),\n                                   GetTensorDim(ksize_, data_format_, '0')}};\n    std::array<int64_t, 3> stride{{GetTensorDim(stride_, data_format_, '2'),\n                                   GetTensorDim(stride_, data_format_, '1'),\n                                   GetTensorDim(stride_, data_format_, '0')}};\n    std::array<int64_t, 3> padding, out;\n\n    OP_REQUIRES_OK(context, Get3dOutputSize(input_size, window, stride,\n                                            padding_, &out, &padding));\n\n    LaunchAvgPooling3dGradOp<Device, T>::launch(\n        context, output_shape, out_backprop, window, stride, out, padding,\n        data_format_, output);\n  }\n\n private:\n  std::vector<int32> ksize_;\n  std::vector<int32> stride_;\n  Padding padding_;\n  TensorFormat data_format_;\n};\n\ntemplate <typename T>\nstruct LaunchMaxPooling3dGradGradOp<CPUDevice, T> {\n  static void launch(OpKernelContext* context, const Pool3dParameters& params,\n                     const Tensor& tensor_in, const Tensor& tensor_out,\n                     const Tensor& tensor_top_diff,\n                     Tensor* tensor_bottom_diff) {\n    OP_REQUIRES(\n        context, params.data_format == FORMAT_NHWC,\n        errors::InvalidArgument(\"Default MaxPooling3dGradGradOp only supports\",\n                                \"NDHWC on CPU device type\"));\n\n    typedef Eigen::Map<const Eigen::Matrix<T, Eigen::Dynamic, Eigen::Dynamic>>\n        ConstEigenMatrixMap;\n    typedef Eigen::Map<Eigen::Matrix<T, Eigen::Dynamic, Eigen::Dynamic>>\n        EigenMatrixMap;\n\n    ConstEigenMatrixMap in_mat(tensor_in.flat<T>().data(), params.depth,\n                               params.tensor_in_planes * params.tensor_in_cols *\n                                   params.tensor_in_rows *\n                                   params.tensor_in_batch);\n    ConstEigenMatrixMap out_mat(tensor_out.flat<T>().data(), params.depth,\n                                params.out_plane * params.out_width *\n                                    params.out_height * params.tensor_in_batch);\n    ConstEigenMatrixMap top_diff_mat(\n        tensor_top_diff.flat<T>().data(), params.depth,\n        params.tensor_in_planes * params.tensor_in_cols *\n            params.tensor_in_rows * params.tensor_in_batch);\n    EigenMatrixMap bottom_diff_mat(\n        tensor_bottom_diff->flat<T>().data(), params.depth,\n        params.out_plane * params.out_width * params.out_height *\n            params.tensor_in_batch);\n\n    const DeviceBase::CpuWorkerThreads& worker_threads =\n        *(context->device()->tensorflow_cpu_worker_threads());\n\n    auto shard = [&params, &in_mat, &out_mat, &top_diff_mat, &bottom_diff_mat](\n                     int64_t start, int64_t limit) {\n      const int32_t depth = params.depth;\n      const int32_t in_planes = params.tensor_in_planes;\n      const int32_t in_rows = params.tensor_in_rows;\n      const int32_t in_cols = params.tensor_in_cols;\n      const int32_t pad_planes = params.pad_planes;\n      const int32_t pad_rows = params.pad_rows;\n      const int32_t pad_cols = params.pad_cols;\n      const int32_t window_planes = params.window_planes;\n      const int32_t window_rows = params.window_rows;\n      const int32_t window_cols = params.window_cols;\n      const int32_t plane_stride = params.plane_stride;\n      const int32_t row_stride = params.row_stride;\n      const int32_t col_stride = params.col_stride;\n      const int32_t out_plane = params.out_plane;\n      const int32_t out_height = params.out_height;\n      const int32_t out_width = params.out_width;\n\n      {\n        // Initializes the output grad backprop tensor with 0.\n        const int32_t output_image_size =\n            out_plane * out_height * out_width * params.depth;\n        EigenMatrixMap bottom_diff_shard(\n            bottom_diff_mat.data() + start * output_image_size, 1,\n            (limit - start) * output_image_size);\n        bottom_diff_shard.setZero();\n      }\n\n      for (int b = start; b < limit; ++b) {\n        for (int pp = 0; pp < out_plane; ++pp) {\n          for (int ph = 0; ph < out_height; ++ph) {\n            for (int pw = 0; pw < out_width; ++pw) {\n              // (p_start, p_end) * (h_start, h_end) * (w_start, w_end) is the\n              // range that the input vector projects to.\n              int p_start = pp * plane_stride - pad_planes;\n              const int p_end = std::min(p_start + window_planes, in_planes);\n              int h_start = ph * row_stride - pad_rows;\n              const int h_end = std::min(h_start + window_rows, in_rows);\n              int w_start = pw * col_stride - pad_cols;\n              const int w_end = std::min(w_start + window_cols, in_cols);\n              p_start = std::max(p_start, 0);\n              h_start = std::max(h_start, 0);\n              w_start = std::max(w_start, 0);\n              const int out_index =\n                  ((b * out_plane + pp) * out_height + ph) * out_width + pw;\n              // Find value corresponding to the input maximum in top_diff.\n              for (int d = 0; d < depth; ++d) {\n                const T& output_ref = out_mat.coeffRef(d, out_index);\n                bool should_stop = false;\n                for (int p = p_start; p < p_end && !should_stop; ++p) {\n                  for (int h = h_start; h < h_end && !should_stop; ++h) {\n                    for (int w = w_start; w < w_end && !should_stop; ++w) {\n                      const int in_index =\n                          ((b * in_planes + p) * in_rows + h) * in_cols + w;\n                      const T& input_ref = in_mat.coeffRef(d, in_index);\n                      if (output_ref == input_ref) {\n                        T& bottom_diff_ref =\n                            bottom_diff_mat.coeffRef(d, out_index);\n                        bottom_diff_ref = top_diff_mat.coeffRef(d, in_index);\n                        should_stop = true;\n                      }\n                    }\n                  }\n                }\n              }\n            }\n          }\n        }\n      }\n    };\n    const int64_t shard_cost =\n        params.out_plane * params.out_height * params.out_width * params.depth *\n        params.window_planes * params.window_rows * params.window_cols;\n    Shard(worker_threads.num_threads, worker_threads.workers,\n          params.tensor_in_batch, shard_cost, shard);\n  }\n};\n\ntemplate <class Device, class T>\nclass MaxPooling3dGradGradOp : public OpKernel {\n public:\n  explicit MaxPooling3dGradGradOp(OpKernelConstruction* context)\n      : OpKernel(context) {\n    string data_format;\n    OP_REQUIRES_OK(context, context->GetAttr(\"data_format\", &data_format));\n    OP_REQUIRES(context, FormatFromString(data_format, &data_format_),\n                errors::InvalidArgument(\"Invalid data format\"));\n    OP_REQUIRES_OK(context, context->GetAttr(\"ksize\", &ksize_));\n    OP_REQUIRES(context, ksize_.size() == 5,\n                errors::InvalidArgument(\"Sliding window ksize field must \"\n                                        \"specify 5 dimensions\"));\n    OP_REQUIRES_OK(context, context->GetAttr(\"strides\", &stride_));\n    OP_REQUIRES(context, stride_.size() == 5,\n                errors::InvalidArgument(\"Sliding window strides field must \"\n                                        \"specify 5 dimensions\"));\n    OP_REQUIRES_OK(context, context->GetAttr(\"padding\", &padding_));\n    OP_REQUIRES(context, ksize_[0] == 1 && stride_[0] == 1,\n                errors::Unimplemented(\n                    \"Pooling is not yet supported on the batch dimension.\"));\n    const int32_t ksize_c = GetTensorDim(ksize_, data_format_, 'C');\n    const int32_t stride_c = GetTensorDim(stride_, data_format_, 'C');\n    OP_REQUIRES(context, ksize_c == 1 && stride_c == 1,\n                errors::Unimplemented(\"MaxPooling3dGradGrad is not yet \"\n                                      \"supported on the depth dimension.\"));\n  }\n\n  void Compute(OpKernelContext* context) override {\n    const Tensor& tensor_in = context->input(0);\n    const Tensor& tensor_out = context->input(1);\n    const Tensor& out_grad_backprop = context->input(2);\n\n    // For maxpooling3d, tensor_in should have 5 dimensions.\n    OP_REQUIRES(context, tensor_in.dims() == 5,\n                errors::InvalidArgument(\"tensor_in must be 5-dimensional\"));\n    OP_REQUIRES(context, tensor_out.dims() == 5,\n                errors::InvalidArgument(\"tensor_out must be 5-dimensional\"));\n    // For maxpooling3d, out_grad_backprop should have 5 dimensions.\n    OP_REQUIRES(\n        context, out_grad_backprop.dims() == 5,\n        errors::InvalidArgument(\"out_grad_backprop must be 5-dimensional\"));\n\n    Pool3dParameters params{context,  ksize_,       stride_,\n                            padding_, data_format_, tensor_in.shape()};\n    if (!context->status().ok()) return;  // params is invalid\n    OP_REQUIRES(context, tensor_out.shape() == params.forward_output_shape(),\n                errors::InvalidArgument(\"Expected orig_output shape to be \",\n                                        params.forward_output_shape(),\n                                        \", but got \", tensor_out.shape()));\n    OP_REQUIRES(\n        context, out_grad_backprop.shape() == tensor_in.shape(),\n        errors::InvalidArgument(\"Expected grad shape to be \", tensor_in.shape(),\n                                \", but got \", out_grad_backprop.shape()));\n\n    Tensor* output = nullptr;\n    OP_REQUIRES_OK(context, context->forward_input_or_allocate_output(\n                                {2}, 0, tensor_out.shape(), &output));\n\n    // Given access patterns in LaunchMaxPooling3dGradGradOp, these tensors must\n    // have elements.\n    OP_REQUIRES(context, tensor_in.NumElements() > 0,\n                errors::InvalidArgument(\"received empty tensor tensor_in: \",\n                                        tensor_in.DebugString()));\n    OP_REQUIRES(context, tensor_out.NumElements() > 0,\n                errors::InvalidArgument(\"received empty tensor tensor_out: \",\n                                        tensor_out.DebugString()));\n    OP_REQUIRES(\n        context, out_grad_backprop.NumElements() > 0,\n        errors::InvalidArgument(\"received empty tensor out_grad_backprop: \",\n                                out_grad_backprop.DebugString()));\n    OP_REQUIRES(context,\n                tensor_in.NumElements() == out_grad_backprop.NumElements(),\n                errors::InvalidArgument(\"tensor_in and out_grad_backprop must \"\n                                        \"have same number of elements, got <\",\n                                        tensor_in.DebugString(), \"> and <\",\n                                        out_grad_backprop.DebugString(), \">\"));\n    OP_REQUIRES(\n        context, tensor_out.NumElements() == output->NumElements(),\n        errors::InvalidArgument(\n            \"tensor_out and output must have same number of elements, got <\",\n            tensor_out.DebugString(), \"> and <\", output->DebugString(), \">\"));\n\n    LaunchMaxPooling3dGradGradOp<Device, T>::launch(\n        context, params, tensor_in, tensor_out, out_grad_backprop, output);\n  }\n\n private:\n  std::vector<int32> ksize_;\n  std::vector<int32> stride_;\n  Padding padding_;\n  TensorFormat data_format_;\n};\n\n#define REGISTER_KERNELS(D, T)                                             \\\n  REGISTER_KERNEL_BUILDER(                                                 \\\n      Name(\"MaxPool3D\").Device(DEVICE_##D).TypeConstraint<T>(\"T\"),         \\\n      Pooling3DOp<D##Device, T, MAX>);                                     \\\n  REGISTER_KERNEL_BUILDER(Name(\"MaxPool3DGrad\")                            \\\n                              .Device(DEVICE_##D)                          \\\n                              .TypeConstraint<T>(\"T\")                      \\\n                              .TypeConstraint<T>(\"TInput\"),                \\\n                          MaxPooling3dGradOp<D##Device, T>);               \\\n  REGISTER_KERNEL_BUILDER(                                                 \\\n      Name(\"MaxPool3DGradGrad\").Device(DEVICE_##D).TypeConstraint<T>(\"T\"), \\\n      MaxPooling3dGradGradOp<D##Device, T>);                               \\\n  REGISTER_KERNEL_BUILDER(                                                 \\\n      Name(\"AvgPool3D\").Device(DEVICE_##D).TypeConstraint<T>(\"T\"),         \\\n      Pooling3DOp<D##Device, T, AVG>);                                     \\\n  REGISTER_KERNEL_BUILDER(Name(\"AvgPool3DGrad\")                            \\\n                              .Device(DEVICE_##D)                          \\\n                              .TypeConstraint<T>(\"T\")                      \\\n                              .HostMemory(\"orig_input_shape\"),             \\\n                          AvgPooling3dGradOp<D##Device, T>);\n\n#define REGISTER_CPU_KERNELS(T) REGISTER_KERNELS(CPU, T)\nTF_CALL_float(REGISTER_CPU_KERNELS);\n#undef REGISTER_CPU_KERNELS\n\n#if GOOGLE_CUDA || TENSORFLOW_USE_ROCM\n\ntemplate <typename T>\nstruct LaunchPoolingOp<GPUDevice, T, AVG> {\n  static void launch(OpKernelContext* context, const Tensor& tensor_in,\n                     const std::array<int64, 3>& window,\n                     const std::array<int64, 3>& stride,\n                     const std::array<int64, 3>& padding,\n                     TensorFormat data_format, Padding padding_type,\n                     Tensor* output) {\n    DnnPooling3dOp<T>::Compute(context, se::dnn::PoolingMode::kAverage, window,\n                               stride, padding, data_format, tensor_in, output);\n  }\n};\n\ntemplate <typename T>\nstruct LaunchPoolingOp<GPUDevice, T, MAX> {\n  static void launch(OpKernelContext* context, const Tensor& tensor_in,\n                     const std::array<int64, 3>& window,\n                     const std::array<int64, 3>& stride,\n                     const std::array<int64, 3>& padding,\n                     TensorFormat data_format, Padding padding_type,\n                     Tensor* output) {\n    DnnPooling3dOp<T>::Compute(context, se::dnn::PoolingMode::kMaximum, window,\n                               stride, padding, data_format, tensor_in, output);\n  }\n};\n\ntemplate <typename T>\nstruct LaunchMaxPooling3dGradOp<GPUDevice, T> {\n  static void launch(OpKernelContext* context, const Tensor& tensor_in,\n                     const Tensor& tensor_out, const Tensor& out_backprop,\n                     const std::array<int64, 3>& window,\n                     const std::array<int64, 3>& stride,\n                     const std::array<int64, 3>& out,\n                     const std::array<int64, 3>& padding,\n                     TensorFormat data_format, Tensor* input_backprop) {\n    const TensorShape output_shape = tensor_in.shape();\n    DnnPooling3dGradOp<T>::Compute(context, se::dnn::PoolingMode::kMaximum,\n                                   window, stride, padding, out, data_format,\n                                   out_backprop, output_shape, &tensor_in,\n                                   &tensor_out, input_backprop);\n  }\n};\n\ntemplate <typename T>\nstruct LaunchAvgPooling3dGradOp<GPUDevice, T> {\n  static void launch(OpKernelContext* context,\n                     const TensorShape& tensor_in_shape,\n                     const Tensor& out_backprop,\n                     const std::array<int64, 3>& window,\n                     const std::array<int64, 3>& stride,\n                     const std::array<int64, 3>& out,\n                     const std::array<int64, 3>& padding,\n                     TensorFormat data_format, Tensor* output) {\n    DnnPooling3dGradOp<T>::Compute(\n        context, se::dnn::PoolingMode::kAverage, window, stride, padding, out,\n        data_format, out_backprop, tensor_in_shape, nullptr, nullptr, output);\n  }\n};\n\ntemplate <typename T>\nstruct LaunchMaxPooling3dGradGradOp<GPUDevice, T> {\n  static void launch(OpKernelContext* context, const Pool3dParameters& params,\n                     const Tensor& tensor_in, const Tensor& tensor_out,\n                     const Tensor& tensor_top_diff,\n                     Tensor* tensor_bottom_diff) {\n    bool status = functor::MaxPool3dGradBackward<T>()(\n        params.data_format, tensor_in.flat<T>().data(),\n        tensor_out.flat<T>().data(), params.tensor_in_batch, params.out_plane,\n        params.out_height, params.out_width, params.depth,\n        params.tensor_in_planes, params.tensor_in_rows, params.tensor_in_cols,\n        params.window_planes, params.window_rows, params.window_cols,\n        params.plane_stride, params.row_stride, params.col_stride,\n        params.pad_planes, params.pad_rows, params.pad_cols,\n        tensor_top_diff.flat<T>().data(), tensor_bottom_diff->flat<T>().data(),\n        context->eigen_gpu_device());\n    if (!status) {\n      context->SetStatus(\n          errors::Internal(\"Failed launching MaxPool3dGradBackward\"));\n    }\n  }\n};\n\n#define REGISTER_GPU_KERNELS(T) REGISTER_KERNELS(GPU, T)\nTF_CALL_float(REGISTER_GPU_KERNELS) TF_CALL_half(REGISTER_GPU_KERNELS)\n#undef REGISTER_GPU_KERNELS\n\n#endif  // GOOGLE_CUDA || TENSORFLOW_USE_ROCM\n\n\n#undef REGISTER_KERNELS\n\n}  // namespace tensorflow\n", "# Tests of TensorFlow NN kernels written using the Python API.\n\nload(\"//tensorflow:tensorflow.bzl\", \"cuda_py_test\")\n\n# buildifier: disable=same-origin-load\nload(\"//tensorflow:tensorflow.bzl\", \"tf_py_test\")\n\npackage(\n    default_visibility = [\"//tensorflow:internal\"],\n    licenses = [\"notice\"],\n)\n\nCONV_TEST_BASENAMES = [\n    \":atrous_conv2d_test\",\n    \":conv1d_test\",\n    \":conv1d_transpose_test\",\n    \":conv2d_backprop_filter_grad_test\",\n    \":conv3d_transpose_test\",\n    \":conv3d_backprop_filter_v2_grad_test\",\n    \":conv_ops_3d_test\",\n    \":conv_ops_test\",\n    \":depthwise_conv_op_test\",\n    \":conv2d_transpose_test\",\n]\n\ntest_suite(\n    name = \"conv_tests\",\n    tests = [basename for basename in CONV_TEST_BASENAMES] +\n            [basename + \"_gpu\" for basename in CONV_TEST_BASENAMES],\n)\n\ncuda_py_test(\n    name = \"atrous_conv2d_test\",\n    size = \"medium\",\n    srcs = [\"atrous_conv2d_test.py\"],\n    shard_count = 2,\n    tags = [\n        \"no_gpu\",  #  Flaky: b/80127739, b/127001953\n    ],\n    deps = [\n        \"//tensorflow/python:array_ops\",\n        \"//tensorflow/python:client_testlib\",\n        \"//tensorflow/python:framework_for_generated_wrappers\",\n        \"//tensorflow/python:nn\",\n        \"//tensorflow/python:nn_grad\",\n        \"//tensorflow/python:nn_ops\",\n        \"//third_party/py/numpy\",\n    ],\n)\n\ncuda_py_test(\n    name = \"atrous_convolution_test\",\n    size = \"medium\",\n    srcs = [\"atrous_convolution_test.py\"],\n    tags = [\n        \"manual\",\n        \"no_cuda_asan\",\n    ],\n    deps = [\n        \"//tensorflow/python:array_ops\",\n        \"//tensorflow/python:client_testlib\",\n        \"//tensorflow/python:framework_for_generated_wrappers\",\n        \"//tensorflow/python:nn_grad\",\n        \"//tensorflow/python:nn_ops\",\n        \"//third_party/py/numpy\",\n    ],\n)\n\ncuda_py_test(\n    name = \"betainc_op_test\",\n    size = \"small\",\n    srcs = [\"betainc_op_test.py\"],\n    xla_tags = [\n        \"no_cuda_asan\",  # times out\n    ],\n    deps = [\n        \"//tensorflow/python:array_ops\",\n        \"//tensorflow/python:client_testlib\",\n        \"//tensorflow/python:framework_for_generated_wrappers\",\n        \"//tensorflow/python:math_ops\",\n        \"//tensorflow/python:platform\",\n        \"//third_party/py/numpy\",\n    ],\n)\n\npy_library(\n    name = \"bias_op_base\",\n    srcs = [\"bias_op_base.py\"],\n    srcs_version = \"PY3\",\n    deps = [\n        \"//tensorflow/python:array_ops\",\n        \"//tensorflow/python:client_testlib\",\n        \"//tensorflow/python:framework_for_generated_wrappers\",\n        \"//tensorflow/python:gradients\",\n        \"//tensorflow/python:nn_grad\",\n        \"//tensorflow/python:nn_ops\",\n        \"//third_party/py/numpy\",\n    ],\n)\n\ncuda_py_test(\n    name = \"bias_op_d9m_test\",\n    size = \"medium\",\n    srcs = [\"bias_op_d9m_test.py\"],\n    shard_count = 2,\n    deps = [\n        \":bias_op_base\",\n    ],\n)\n\ncuda_py_test(\n    name = \"bias_op_test\",\n    size = \"medium\",\n    srcs = [\"bias_op_test.py\"],\n    deps = [\n        \":bias_op_base\",\n    ],\n)\n\ncuda_py_test(\n    name = \"conv1d_test\",\n    size = \"small\",\n    srcs = [\"conv1d_test.py\"],\n    deps = [\n        \"//tensorflow/python:array_ops\",\n        \"//tensorflow/python:client_testlib\",\n        \"//tensorflow/python:framework_for_generated_wrappers\",\n        \"//tensorflow/python:nn_ops\",\n    ],\n)\n\ncuda_py_test(\n    name = \"conv1d_transpose_test\",\n    size = \"small\",\n    srcs = [\"conv1d_transpose_test.py\"],\n    deps = [\n        \"//tensorflow/python:client\",\n        \"//tensorflow/python:client_testlib\",\n        \"//tensorflow/python:framework_for_generated_wrappers\",\n        \"//tensorflow/python:nn_ops\",\n        \"//third_party/py/numpy\",\n    ],\n)\n\ncuda_py_test(\n    name = \"conv2d_backprop_filter_grad_test\",\n    size = \"medium\",\n    srcs = [\"conv2d_backprop_filter_grad_test.py\"],\n    shard_count = 2,\n    tags = [\n        \"optonly\",  # flaky timeouts unless optimized\n    ],\n    deps = [\n        \"//tensorflow/python:array_ops\",\n        \"//tensorflow/python:client_testlib\",\n        \"//tensorflow/python:framework_for_generated_wrappers\",\n        \"//tensorflow/python:nn_grad\",\n        \"//tensorflow/python:nn_ops\",\n        \"//third_party/py/numpy\",\n    ],\n)\n\ncuda_py_test(\n    name = \"conv2d_transpose_test\",\n    size = \"small\",\n    srcs = [\"conv2d_transpose_test.py\"],\n\n    # TODO(b/144432983): S32 convolutions should not be auto-clustered, only\n    # crashes tests.\n    xla_enable_strict_auto_jit = False,\n    deps = [\n        \"//tensorflow/python:client\",\n        \"//tensorflow/python:client_testlib\",\n        \"//tensorflow/python:framework_for_generated_wrappers\",\n        \"//tensorflow/python:nn_grad\",\n        \"//tensorflow/python:nn_ops\",\n        \"//third_party/py/numpy\",\n    ],\n)\n\ncuda_py_test(\n    name = \"conv3d_backprop_filter_v2_grad_test\",\n    size = \"small\",\n    srcs = [\"conv3d_backprop_filter_v2_grad_test.py\"],\n    deps = [\n        \"//tensorflow/python:array_ops\",\n        \"//tensorflow/python:client_testlib\",\n        \"//tensorflow/python:framework_for_generated_wrappers\",\n        \"//tensorflow/python:nn_grad\",\n        \"//tensorflow/python:nn_ops\",\n        \"//third_party/py/numpy\",\n    ],\n)\n\ncuda_py_test(\n    name = \"conv3d_transpose_test\",\n    size = \"medium\",\n    srcs = [\"conv3d_transpose_test.py\"],\n    deps = [\n        \"//tensorflow/python:client_testlib\",\n        \"//tensorflow/python:framework_for_generated_wrappers\",\n        \"//tensorflow/python:nn_grad\",\n        \"//tensorflow/python:nn_ops\",\n        \"//third_party/py/numpy\",\n    ],\n)\n\ncuda_py_test(\n    name = \"conv_ops_3d_test\",\n    size = \"medium\",\n    srcs = [\"conv_ops_3d_test.py\"],\n    shard_count = 30,\n    tags = [\"no_cuda11\"],\n    deps = [\n        \"//tensorflow/python:client_testlib\",\n        \"//tensorflow/python:framework_for_generated_wrappers\",\n        \"//tensorflow/python:nn_grad\",\n        \"//tensorflow/python:nn_ops\",\n    ],\n)\n\ncuda_py_test(\n    name = \"conv_ops_test\",\n    size = \"medium\",\n    srcs = [\"conv_ops_test.py\"],\n    shard_count = 4,\n    tags = [\n        \"optonly\",  # times out\n    ],\n    deps = [\n        \"//tensorflow/python:array_ops\",\n        \"//tensorflow/python:client\",\n        \"//tensorflow/python:client_testlib\",\n        \"//tensorflow/python:errors\",\n        \"//tensorflow/python:framework_for_generated_wrappers\",\n        \"//tensorflow/python:framework_test_lib\",\n        \"//tensorflow/python:nn\",\n        \"//tensorflow/python:nn_grad\",\n        \"//tensorflow/python:nn_ops\",\n        \"//tensorflow/python:platform\",\n        \"//tensorflow/python:random_ops\",\n        \"//tensorflow/python:variables\",\n        \"//third_party/py/numpy\",\n    ],\n)\n\ntf_py_test(\n    name = \"ctc_decoder_ops_test\",\n    size = \"small\",\n    srcs = [\"ctc_decoder_ops_test.py\"],\n    deps = [\n        \"//tensorflow/python:array_ops\",\n        \"//tensorflow/python:client_testlib\",\n        \"//tensorflow/python:ctc_ops\",\n        \"//tensorflow/python:framework_for_generated_wrappers\",\n        \"//third_party/py/numpy\",\n    ],\n)\n\ncuda_py_test(\n    name = \"ctc_loss_op_test\",\n    size = \"medium\",\n    srcs = [\"ctc_loss_op_test.py\"],\n    xla_enable_strict_auto_jit = False,  # b/148153828\n    deps = [\n        \"//tensorflow/python:client_testlib\",\n        \"//tensorflow/python:ctc_ops\",\n        \"//tensorflow/python:framework\",\n        \"//tensorflow/python:framework_for_generated_wrappers\",\n        \"//tensorflow/python:gradients\",\n        \"//third_party/py/numpy\",\n    ],\n)\n\npy_library(\n    name = \"cudnn_deterministic_base\",\n    srcs = [\"cudnn_deterministic_base.py\"],\n    srcs_version = \"PY3\",\n    deps = [\n        \"//tensorflow/python:client_testlib\",\n        \"//tensorflow/python:constant_op\",\n        \"//tensorflow/python:dtypes\",\n        \"//tensorflow/python:nn_ops\",\n        \"//tensorflow/python/eager:backprop\",\n        \"//third_party/py/numpy\",\n    ],\n)\n\ncuda_py_test(\n    name = \"cudnn_deterministic_ops_test\",\n    size = \"small\",\n    srcs = [\"cudnn_deterministic_ops_test.py\"],\n    tags = [\n        \"no_cuda_asan\",  # TODO(b/171509035): re-enable.\n    ],\n    xla_enable_strict_auto_jit = True,\n    deps = [\n        \":cudnn_deterministic_base\",\n    ],\n)\n\ncuda_py_test(\n    name = \"cudnn_d9m_test\",\n    size = \"small\",\n    srcs = [\"cudnn_d9m_test.py\"],\n    tags = [\n        \"no_cuda_asan\",  # TODO(b/171509035): re-enable.\n    ],\n    deps = [\n        \":cudnn_deterministic_base\",\n    ],\n)\n\npy_library(\n    name = \"depthwise_conv_op_base\",\n    srcs = [\"depthwise_conv_op_base.py\"],\n    deps = [\n        \"//tensorflow/python:array_ops\",\n        \"//tensorflow/python:client_testlib\",\n        \"//tensorflow/python:framework_for_generated_wrappers\",\n        \"//tensorflow/python:nn\",\n        \"//tensorflow/python:nn_grad\",\n        \"//tensorflow/python:nn_ops\",\n        \"//third_party/py/numpy\",\n    ],\n)\n\ncuda_py_test(\n    name = \"depthwise_conv_op_d9m_test\",\n    size = \"medium\",  # http://b/30603882\n    timeout = \"long\",\n    srcs = [\"depthwise_conv_op_d9m_test.py\"],\n    shard_count = 8,\n    deps = [\n        \":depthwise_conv_op_base\",\n        \"//tensorflow/python:random_ops\",\n        \"//tensorflow/python/eager:backprop\",\n    ],\n)\n\ncuda_py_test(\n    name = \"depthwise_conv_op_test\",\n    size = \"medium\",  # http://b/30603882\n    timeout = \"long\",\n    srcs = [\"depthwise_conv_op_test.py\"],\n    shard_count = 8,\n    deps = [\n        \":depthwise_conv_op_base\",\n    ],\n)\n\ncuda_py_test(\n    name = \"embedding_ops_test\",\n    size = \"medium\",\n    srcs = [\"embedding_ops_test.py\"],\n    shard_count = 20,\n    tags = [\n        \"no_cuda_asan\",  # Size limit: b/192505612\n    ],\n    xla_tags = [\n        \"no_cuda_asan\",  # Size limit: b/192505612\n    ],\n    deps = [\n        \"//tensorflow/python:array_ops\",\n        \"//tensorflow/python:client_testlib\",\n        \"//tensorflow/python:data_flow_ops\",\n        \"//tensorflow/python:embedding_ops\",\n        \"//tensorflow/python:framework\",\n        \"//tensorflow/python:framework_for_generated_wrappers\",\n        \"//tensorflow/python:init_ops\",\n        \"//tensorflow/python:linalg_ops\",\n        \"//tensorflow/python:math_ops\",\n        \"//tensorflow/python:partitioned_variables\",\n        \"//tensorflow/python:platform\",\n        \"//tensorflow/python:state_ops\",\n        \"//tensorflow/python:util\",\n        \"//tensorflow/python:variable_scope\",\n        \"//tensorflow/python:variables\",\n        \"//third_party/py/numpy\",\n    ],\n)\n\ntf_py_test(\n    name = \"fractional_avg_pool_op_test\",\n    size = \"small\",\n    srcs = [\"fractional_avg_pool_op_test.py\"],\n    shard_count = 5,\n    deps = [\n        \"//tensorflow/python:array_ops\",\n        \"//tensorflow/python:client_testlib\",\n        \"//tensorflow/python:framework_for_generated_wrappers\",\n        \"//tensorflow/python:nn_grad\",\n        \"//tensorflow/python:nn_ops\",\n        \"//tensorflow/python:nn_ops_gen\",\n        \"//third_party/py/numpy\",\n    ],\n)\n\ntf_py_test(\n    name = \"fractional_max_pool_op_test\",\n    size = \"small\",\n    srcs = [\"fractional_max_pool_op_test.py\"],\n    shard_count = 5,\n    deps = [\n        \"//tensorflow/python:array_ops\",\n        \"//tensorflow/python:client_testlib\",\n        \"//tensorflow/python:framework_for_generated_wrappers\",\n        \"//tensorflow/python:nn_grad\",\n        \"//tensorflow/python:nn_ops\",\n        \"//tensorflow/python:nn_ops_gen\",\n        \"//third_party/py/numpy\",\n    ],\n)\n\ntf_py_test(\n    name = \"losses_test\",\n    size = \"medium\",\n    srcs = [\"losses_test.py\"],\n    deps = [\n        \"//tensorflow/python:array_ops\",\n        \"//tensorflow/python:client_testlib\",\n        \"//tensorflow/python:errors\",\n        \"//tensorflow/python:framework\",\n        \"//tensorflow/python:framework_for_generated_wrappers\",\n        \"//tensorflow/python:init_ops\",\n        \"//tensorflow/python:math_ops\",\n        \"//tensorflow/python:training\",\n        \"//tensorflow/python:variable_scope\",\n        \"//tensorflow/python:variables\",\n        \"//tensorflow/python/ops/losses\",\n        \"//third_party/py/numpy\",\n    ],\n)\n\ncuda_py_test(\n    name = \"lrn_op_test\",\n    size = \"medium\",\n    srcs = [\"lrn_op_test.py\"],\n    deps = [\n        \"//tensorflow/python:array_ops\",\n        \"//tensorflow/python:client_testlib\",\n        \"//tensorflow/python:framework_for_generated_wrappers\",\n        \"//tensorflow/python:gradients\",\n        \"//tensorflow/python:nn\",\n        \"//tensorflow/python:nn_grad\",\n        \"//third_party/py/numpy\",\n    ],\n)\n\ncuda_py_test(\n    name = \"morphological_ops_test\",\n    size = \"small\",\n    srcs = [\"morphological_ops_test.py\"],\n    xla_tags = [\n        \"no_cuda_asan\",  # times out\n    ],\n    deps = [\n        \"//tensorflow/python:client_testlib\",\n        \"//tensorflow/python:framework_for_generated_wrappers\",\n        \"//tensorflow/python:nn_grad\",\n        \"//tensorflow/python:nn_ops\",\n        \"//third_party/py/numpy\",\n    ],\n)\n\ncuda_py_test(\n    name = \"nth_element_op_test\",\n    size = \"small\",\n    srcs = [\"nth_element_op_test.py\"],\n    deps = [\n        \"//tensorflow/python:array_ops\",\n        \"//tensorflow/python:client_testlib\",\n        \"//tensorflow/python:framework_for_generated_wrappers\",\n        \"//tensorflow/python:gradients\",\n        \"//tensorflow/python:nn_grad\",\n        \"//tensorflow/python:nn_ops\",\n        \"//third_party/py/numpy\",\n    ],\n)\n\ncuda_py_test(\n    name = \"pool_test\",\n    size = \"medium\",\n    srcs = [\"pool_test.py\"],\n    xla_tags = [\n        \"no_cuda_asan\",  # times out\n    ],\n    deps = [\n        \"//tensorflow/python:client_testlib\",\n        \"//tensorflow/python:framework_for_generated_wrappers\",\n        \"//tensorflow/python:nn_grad\",\n        \"//tensorflow/python:nn_ops\",\n        \"//third_party/py/numpy\",\n    ],\n)\n\ncuda_py_test(\n    name = \"pooling_ops_3d_test\",\n    size = \"medium\",\n    srcs = [\"pooling_ops_3d_test.py\"],\n    deps = [\n        \"//tensorflow/python:client_testlib\",\n        \"//tensorflow/python:framework_for_generated_wrappers\",\n        \"//tensorflow/python:nn_grad\",\n        \"//tensorflow/python:nn_ops\",\n        \"//third_party/py/numpy\",\n    ],\n)\n\ncuda_py_test(\n    name = \"pooling_ops_test\",\n    size = \"medium\",\n    srcs = [\"pooling_ops_test.py\"],\n    shard_count = 10,\n    # Some operations in this test can only be checked on sm61+.\n    tags = [\"prefer-sm70\"],\n    deps = [\n        \"//tensorflow/python:array_ops\",\n        \"//tensorflow/python:client_testlib\",\n        \"//tensorflow/python:errors\",\n        \"//tensorflow/python:framework_for_generated_wrappers\",\n        \"//tensorflow/python:framework_test_lib\",\n        \"//tensorflow/python:nn_grad\",\n        \"//tensorflow/python:nn_ops\",\n        \"//tensorflow/python:nn_ops_gen\",\n        \"//third_party/py/numpy\",\n    ],\n)\n\ncuda_py_test(\n    name = \"relu_op_test\",\n    size = \"small\",\n    srcs = [\"relu_op_test.py\"],\n    xla_tags = [\n        \"no_cuda_asan\",  # times out\n    ],\n    deps = [\n        \"//tensorflow/python:client_testlib\",\n        \"//tensorflow/python:framework_for_generated_wrappers\",\n        \"//tensorflow/python:nn_grad\",\n        \"//tensorflow/python:nn_ops\",\n        \"//tensorflow/python:random_ops\",\n        \"//tensorflow/python:tf2\",\n        \"//tensorflow/python:training\",\n        \"//tensorflow/python:variables\",\n        \"//tensorflow/python/eager:backprop\",\n        \"//third_party/py/numpy\",\n    ],\n)\n\ncuda_py_test(\n    name = \"rnn_cell_test\",\n    size = \"medium\",\n    srcs = [\"rnn_cell_test.py\"],\n    shard_count = 15,\n    tags = [\"no_windows\"],  # b/139739217\n    deps = [\n        \"//tensorflow/python:array_ops\",\n        \"//tensorflow/python:client_testlib\",\n        \"//tensorflow/python:control_flow_ops\",\n        \"//tensorflow/python:control_flow_v2_toggles\",\n        \"//tensorflow/python:framework_for_generated_wrappers\",\n        \"//tensorflow/python:framework_test_lib\",\n        \"//tensorflow/python:gradients\",\n        \"//tensorflow/python:init_ops\",\n        \"//tensorflow/python:math_ops\",\n        \"//tensorflow/python:platform\",\n        \"//tensorflow/python:rnn\",\n        \"//tensorflow/python:rnn_cell\",\n        \"//tensorflow/python:tensor_array_ops\",\n        \"//tensorflow/python:util\",\n        \"//tensorflow/python:variable_scope\",\n        \"//tensorflow/python:variables\",\n        \"//tensorflow/python/eager:context\",\n        \"//tensorflow/python/eager:def_function\",\n        \"//tensorflow/python/saved_model:load\",\n        \"//tensorflow/python/saved_model:save\",\n        \"//tensorflow/python/trackable:autotrackable\",\n        \"//third_party/py/numpy\",\n        \"@absl_py//absl/testing:parameterized\",\n    ],\n)\n\ncuda_py_test(\n    name = \"rnn_test\",\n    size = \"medium\",\n    timeout = \"long\",\n    srcs = [\"rnn_test.py\"],\n    shard_count = 10,\n    deps = [\n        \"//tensorflow/core:protos_all_py\",\n        \"//tensorflow/python:array_ops\",\n        \"//tensorflow/python:client\",\n        \"//tensorflow/python:client_testlib\",\n        \"//tensorflow/python:control_flow_ops\",\n        \"//tensorflow/python:data_flow_grad\",\n        \"//tensorflow/python:framework_for_generated_wrappers\",\n        \"//tensorflow/python:framework_test_lib\",\n        \"//tensorflow/python:gradients\",\n        \"//tensorflow/python:init_ops\",\n        \"//tensorflow/python:nn_grad\",\n        \"//tensorflow/python:rnn\",\n        \"//tensorflow/python:rnn_cell\",\n        \"//tensorflow/python:sparse_grad\",\n        \"//tensorflow/python:tensor_array_grad\",\n        \"//tensorflow/python:tensor_array_ops\",\n        \"//tensorflow/python:variables\",\n        \"//tensorflow/python/eager:context\",\n        \"//third_party/py/numpy\",\n    ],\n)\n\ncuda_py_test(\n    name = \"softmax_op_test\",\n    size = \"medium\",\n    srcs = [\"softmax_op_test.py\"],\n    deps = [\n        \"//tensorflow/python:array_ops\",\n        \"//tensorflow/python:client_testlib\",\n        \"//tensorflow/python:errors\",\n        \"//tensorflow/python:framework_for_generated_wrappers\",\n        \"//tensorflow/python:nn_ops\",\n        \"//third_party/py/numpy\",\n    ],\n)\n\ncuda_py_test(\n    name = \"softplus_op_test\",\n    size = \"small\",\n    srcs = [\"softplus_op_test.py\"],\n    deps = [\n        \"//tensorflow/python:client_testlib\",\n        \"//tensorflow/python:framework_for_generated_wrappers\",\n        \"//tensorflow/python:nn_grad\",\n        \"//tensorflow/python:nn_ops\",\n        \"//third_party/py/numpy\",\n    ],\n)\n\ncuda_py_test(\n    name = \"softsign_op_test\",\n    size = \"small\",\n    srcs = [\"softsign_op_test.py\"],\n    deps = [\n        \"//tensorflow/python:client_testlib\",\n        \"//tensorflow/python:framework_for_generated_wrappers\",\n        \"//tensorflow/python:nn_grad\",\n        \"//tensorflow/python:nn_ops\",\n        \"//third_party/py/numpy\",\n    ],\n)\n\ncuda_py_test(\n    name = \"xent_op_d9m_test\",\n    size = \"medium\",\n    srcs = [\"xent_op_d9m_test.py\"],\n    tags = [\n        \"no_windows\",  # Flaky on Windows CPU: https://github.com/tensorflow/tensorflow/issues/55827\n        \"noasan\",  # TODO(b/231484532): Remove after flakiness resolved.\n        \"nomac\",  # TODO(b/235277289) Flaky on OSX\n        \"notsan\",  # TODO(b/200548634): Remove.\n    ],\n    xla_enable_strict_auto_jit = False,\n    deps = [\n        \":xent_op_test_base\",\n        \"//tensorflow/python:client_testlib\",\n        \"//tensorflow/python:constant_op\",\n        \"//tensorflow/python:dtypes\",\n        \"//tensorflow/python:framework_for_generated_wrappers\",\n        \"//tensorflow/python:nn_grad\",\n        \"//tensorflow/python:nn_ops\",\n        \"//tensorflow/python:nn_ops_gen\",\n        \"//tensorflow/python/eager:backprop\",\n        \"//third_party/py/numpy\",\n    ],\n)\n\ncuda_py_test(\n    name = \"xent_op_test\",\n    size = \"small\",\n    srcs = [\"xent_op_test.py\"],\n    deps = [\n        \":xent_op_test_base\",\n        \"//tensorflow/python:client_testlib\",\n        \"//tensorflow/python:framework_for_generated_wrappers\",\n        \"//tensorflow/python:framework_ops\",\n        \"//tensorflow/python:nn_ops\",\n        \"//tensorflow/python:nn_ops_gen\",\n        \"//third_party/py/numpy\",\n    ],\n)\n\npy_library(\n    name = \"xent_op_test_base\",\n    srcs = [\"xent_op_test_base.py\"],\n    srcs_version = \"PY3\",\n    deps = [\n        \"//tensorflow/python:array_ops\",\n        \"//tensorflow/python:client_testlib\",\n        \"//tensorflow/python:constant_op\",\n        \"//tensorflow/python:dtypes\",\n        \"//tensorflow/python:framework_for_generated_wrappers\",\n        \"//tensorflow/python:framework_ops\",\n        \"//tensorflow/python:gradients\",\n        \"//tensorflow/python:math_ops\",\n        \"//tensorflow/python:nn_grad\",\n        \"//tensorflow/python:nn_ops\",\n        \"//tensorflow/python/eager:backprop\",\n        \"//third_party/py/numpy\",\n    ],\n)\n", "# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\"\"\"Functional tests for 3d pooling operations.\"\"\"\n\nimport numpy as np\n\nfrom tensorflow.python.eager import context\nfrom tensorflow.python.framework import constant_op\nfrom tensorflow.python.framework import errors\nfrom tensorflow.python.framework import errors_impl\nfrom tensorflow.python.framework import test_util\nfrom tensorflow.python.ops import array_ops\nfrom tensorflow.python.ops import gen_nn_ops\nfrom tensorflow.python.ops import gradient_checker\nfrom tensorflow.python.ops import gradients_impl\nfrom tensorflow.python.ops import nn_ops\nimport tensorflow.python.ops.nn_grad  # pylint: disable=unused-import\nfrom tensorflow.python.platform import test\n\n\ndef GetTestConfigs():\n  \"\"\"Get all the valid tests configs to run.\n\n  Returns:\n    all the valid test configs as tuples of data_format and use_gpu.\n  \"\"\"\n  test_configs = [(\"NDHWC\", False), (\"NDHWC\", True)]\n  if test.is_gpu_available(cuda_only=True):\n    # \"NCHW\" format is currently supported exclusively on CUDA GPUs.\n    test_configs += [(\"NCDHW\", True)]\n  return test_configs\n\n\n# TODO(mjanusz): Add microbenchmarks for 3d pooling.\n@test_util.with_eager_op_as_function\nclass PoolingTest(test.TestCase):\n\n  def _VerifyOneTest(self, pool_func, input_sizes, window, strides, padding,\n                     data_format, expected, use_gpu):\n    \"\"\"Verifies the output values of the pooling function.\n\n    Args:\n      pool_func: Function to be called: co.MaxPool, co.AvgPool.\n      input_sizes: Input tensor dimensions.\n      window: Tuple of kernel dims: planes, rows, cols.\n      strides: Tuple of strides for dims: planes, rows, cols.\n      padding: Padding type.\n      data_format: The data format we use to run the pooling operation.\n      expected: An array containing the expected operation outputs.\n      use_gpu: Whether to run ops on GPU.\n    \"\"\"\n    total_size = 1\n    for s in input_sizes:\n      total_size *= s\n    # Initializes the input tensor with array containing incrementing\n    # numbers from 1.\n    x = [f * 1.0 for f in range(1, total_size + 1)]\n    with self.cached_session(use_gpu=use_gpu) as sess:\n      t = constant_op.constant(x, shape=input_sizes)\n      window = [1] + list(window) + [1]\n      strides = [1] + list(strides) + [1]\n      if data_format == \"NCDHW\":\n        t = test_util.NHWCToNCHW(t)\n        window = test_util.NHWCToNCHW(window)\n        strides = test_util.NHWCToNCHW(strides)\n      t = pool_func(\n          t,\n          ksize=window,\n          strides=strides,\n          padding=padding,\n          data_format=data_format)\n      if data_format == \"NCDHW\":\n        t = test_util.NCHWToNHWC(t)\n      vals = self.evaluate(t)\n    # Verifies values.\n    actual = vals.flatten()\n    self.assertAllClose(expected, actual)\n\n  def _VerifyValues(self, pool_func, input_sizes, window, strides,\n                    padding, expected):\n    for data_format, use_gpu in GetTestConfigs():\n      self._VerifyOneTest(pool_func, input_sizes, window, strides, padding,\n                          data_format, expected, use_gpu)\n\n  def testAvgPool3dValidPadding(self):\n    expected_output = [20.5, 21.5, 22.5]\n    self._VerifyValues(\n        nn_ops.avg_pool3d,\n        input_sizes=[1, 3, 3, 3, 3],\n        window=(2, 2, 2),\n        strides=(2, 2, 2),\n        padding=\"VALID\",\n        expected=expected_output)\n\n  def testAvgPool3dSamePadding(self):\n    expected_output = [20.5, 21.5, 22.5, 26.5, 27.5, 28.5]\n    self._VerifyValues(\n        nn_ops.avg_pool3d,\n        input_sizes=[1, 2, 2, 4, 3],\n        window=(2, 2, 2),\n        strides=(2, 2, 2),\n        padding=\"SAME\",\n        expected=expected_output)\n\n  def testAvgPool3dSamePaddingDifferentStrides(self):\n    expected_output = [1.5, 4.5, 7.5, 17.5, 20.5, 23.5, 33.5, 36.5, 39.5]\n    self._VerifyValues(\n        nn_ops.avg_pool3d,\n        input_sizes=[1, 5, 8, 1, 1],\n        window=(1, 2, 3),\n        strides=(2, 3, 1),\n        padding=\"SAME\",\n        expected=expected_output)\n\n  def testMaxPool3dValidPadding(self):\n    expected_output = [40.0, 41.0, 42.0]\n    self._VerifyValues(\n        nn_ops.max_pool3d,\n        input_sizes=[1, 3, 3, 3, 3],\n        window=(2, 2, 2),\n        strides=(2, 2, 2),\n        padding=\"VALID\",\n        expected=expected_output)\n\n  def testMaxPool3dSamePadding(self):\n    expected_output = [31., 32., 33., 34., 35., 36.]\n    self._VerifyValues(\n        nn_ops.max_pool3d,\n        input_sizes=[1, 2, 2, 3, 3],\n        window=(2, 2, 2),\n        strides=(2, 2, 2),\n        padding=\"SAME\",\n        expected=expected_output)\n\n  def testMaxPool3dSamePaddingDifferentStrides(self):\n    expected_output = [2., 5., 8., 18., 21., 24., 34., 37., 40.]\n    self._VerifyValues(\n        nn_ops.max_pool3d,\n        input_sizes=[1, 5, 8, 1, 1],\n        window=(1, 2, 3),\n        strides=(2, 3, 1),\n        padding=\"SAME\",\n        expected=expected_output)\n\n    # Test pooling on a larger input, with different stride and kernel\n    # size for the 'z' dimension.\n\n    # Simulate max pooling in numpy to get the expected output.\n    input_data = np.arange(1, 5 * 27 * 27 * 64 + 1).reshape((5, 27, 27, 64))\n    input_data = np.pad(input_data, [[0, 0], [0, 1], [0, 1], [0, 0]],\n                        mode=\"constant\")\n    expected_output = input_data[:, 1::2, 1::2, :]\n    expected_output[:, -1, :, :] = input_data[:, -2, 1::2, :]\n    expected_output[:, :, -1, :] = input_data[:, 1::2, -2, :]\n    expected_output[:, -1, -1, :] = input_data[:, -2, -2, :]\n\n    self._VerifyValues(\n        nn_ops.max_pool3d,\n        input_sizes=[1, 5, 27, 27, 64],\n        window=(1, 2, 2),\n        strides=(1, 2, 2),\n        padding=\"SAME\",\n        expected=expected_output.flatten())\n\n  def testKernelSmallerThanStride(self):\n    self._VerifyValues(\n        nn_ops.max_pool3d,\n        input_sizes=[1, 3, 3, 3, 1],\n        window=[1, 1, 1],\n        strides=[2, 2, 2],\n        padding=\"SAME\",\n        expected=[1, 3, 7, 9, 19, 21, 25, 27])\n\n    self._VerifyValues(\n        nn_ops.max_pool3d,\n        input_sizes=[1, 7, 7, 7, 1],\n        window=[2, 2, 2],\n        strides=[3, 3, 3],\n        padding=\"VALID\",\n        expected=[58, 61, 79, 82, 205, 208, 226, 229])\n\n    self._VerifyValues(\n        nn_ops.avg_pool3d,\n        input_sizes=[1, 3, 3, 3, 1],\n        window=[1, 1, 1],\n        strides=[2, 2, 2],\n        padding=\"SAME\",\n        expected=[1, 3, 7, 9, 19, 21, 25, 27])\n\n    self._VerifyValues(\n        nn_ops.avg_pool3d,\n        input_sizes=[1, 7, 7, 7, 1],\n        window=[2, 2, 2],\n        strides=[3, 3, 3],\n        padding=\"VALID\",\n        expected=[29.5, 32.5, 50.5, 53.5, 176.5, 179.5, 197.5, 200.5])\n\n  def testMaxPool3DEmptyTensorOutputShape(self):\n    \"\"\"Verifies the output shape of the max pooling function when tensor is empty.\n\n    Args: none\n    \"\"\"\n    input_sizes = [0, 112, 112, 112, 64]\n\n    input_data = 1.\n    input_tensor = constant_op.constant(\n        input_data, shape=input_sizes, name=\"input\")\n    max_pool_3d = nn_ops.max_pool3d(\n        input_tensor,\n        ksize=[2, 2, 2],\n        strides=[2, 2, 2],\n        padding=\"VALID\",\n        data_format=\"NDHWC\",\n        name=\"max_pool_3d\")\n    values = self.evaluate(max_pool_3d)\n    self.assertEqual(values.shape, (0, 56, 56, 56, 64))\n\n  def _ConstructAndTestGradientForConfig(self,\n                                         pool_func,\n                                         input_sizes,\n                                         output_sizes,\n                                         window,\n                                         strides,\n                                         padding,\n                                         data_format,\n                                         use_gpu):\n    \"\"\"Verifies the gradients of a pooling function.\n\n    Args:\n      pool_func: Function to be called, co.MaxPool, co.AvgPool,\n        or the Lua version.\n      input_sizes: Input tensor dimensions.\n      output_sizes: Output tensor dimensions.\n      window: Tuple of kernel dims: planes, rows, cols.\n      strides: Tuple of strides for dims: planes, rows, cols.\n      padding: Padding type.\n      data_format: Data format string.\n      use_gpu: Whether to run on GPU.\n    \"\"\"\n    total_size = 1\n    for s in input_sizes:\n      total_size *= s\n    # Initializes the input tensor with array containing incrementing\n    # numbers from 1.\n    x = np.arange(1, total_size + 1, dtype=np.float32)\n    with self.cached_session(use_gpu=use_gpu):\n      input_tensor = constant_op.constant(x, shape=input_sizes, name=\"input\")\n      err_g_margin = 1e-3\n      err_gg_margin = 1.5e-2\n      if pool_func == nn_ops.avg_pool3d:\n        func_name = \"avg_pool3d\"\n        x_init_value = None\n      else:\n        x_init_value = np.asfarray(np.arange(1, total_size + 1),\n                                   dtype=np.float32).reshape(input_sizes)\n        func_name = \"max_pool3d\"\n\n      ksize = [1, window[0], window[1], window[2], 1]\n      strides = [1, strides[0], strides[1], strides[2], 1]\n      t = input_tensor\n\n      if data_format == \"NCDHW\":\n        ksize = test_util.NHWCToNCHW(ksize)\n        strides = test_util.NHWCToNCHW(strides)\n        t = test_util.NHWCToNCHW(t)\n        output_sizes = test_util.NHWCToNCHW(output_sizes)\n\n      t = pool_func(\n          t,\n          ksize=ksize,\n          strides=strides,\n          padding=padding,\n          data_format=data_format,\n          name=func_name)\n      t_g = gradients_impl.gradients(t**2, input_tensor)[0]\n\n      err_g = gradient_checker.compute_gradient_error(\n          input_tensor,\n          input_sizes,\n          t,\n          output_sizes,\n          x_init_value=x_init_value,\n          delta=1e-2)\n      err_gg = gradient_checker.compute_gradient_error(\n          input_tensor,\n          input_sizes,\n          t_g,\n          input_sizes,\n          x_init_value=x_init_value,\n          delta=1e-2)\n\n    print(\"%s gradient error = \" % func_name, err_g)\n    self.assertLess(err_g, err_g_margin)\n    print(\"%s second-order gradient error = \" % func_name, err_gg)\n    self.assertLess(err_gg, err_gg_margin)\n\n  def _ConstructAndTestGradient(self,\n                                pool_func,\n                                **kwargs):\n    \"\"\"Runs _ConstructAndTestGradientForConfig for all tests configurations.\"\"\"\n\n    for data_format, use_gpu in GetTestConfigs():\n      self._ConstructAndTestGradientForConfig(pool_func,\n                                              data_format=data_format,\n                                              use_gpu=use_gpu,\n                                              **kwargs)\n\n  @test_util.run_deprecated_v1\n  def testMaxPoolGradValidPadding1_1_3d(self):\n    self._ConstructAndTestGradient(\n        nn_ops.max_pool3d,\n        input_sizes=[1, 3, 3, 3, 1],\n        output_sizes=[1, 3, 3, 3, 1],\n        window=(1, 1, 1),\n        strides=(1, 1, 1),\n        padding=\"VALID\")\n\n  @test_util.run_deprecated_v1\n  def testMaxPoolGradValidPadding2_1_6_3d(self):\n    self._ConstructAndTestGradient(\n        nn_ops.max_pool3d,\n        input_sizes=[1, 2, 3, 4, 2],\n        output_sizes=[1, 1, 2, 3, 2],\n        window=(2, 2, 2),\n        strides=(1, 1, 1),\n        padding=\"VALID\")\n\n  @test_util.run_deprecated_v1\n  def testMaxPoolGradValidPadding2_1_7_3d(self):\n    self._ConstructAndTestGradient(\n        nn_ops.max_pool3d,\n        input_sizes=[1, 3, 2, 7, 1],\n        output_sizes=[1, 2, 1, 6, 1],\n        window=(2, 2, 2),\n        strides=(1, 1, 1),\n        padding=\"VALID\")\n\n  @test_util.run_deprecated_v1\n  def testMaxPoolGradValidPadding1_2_3d(self):\n    self._ConstructAndTestGradient(\n        nn_ops.max_pool3d,\n        input_sizes=[1, 3, 3, 3, 1],\n        output_sizes=[1, 2, 2, 2, 1],\n        window=(1, 1, 1),\n        strides=(2, 2, 2),\n        padding=\"VALID\")\n\n  @test_util.run_deprecated_v1\n  def testMaxPoolGradValidPadding2_2_3d(self):\n    self._ConstructAndTestGradient(\n        nn_ops.max_pool3d,\n        input_sizes=[2, 2, 2, 2, 1],\n        output_sizes=[2, 1, 1, 1, 1],\n        window=(2, 2, 2),\n        strides=(2, 2, 2),\n        padding=\"VALID\")\n\n  @test_util.run_deprecated_v1\n  def testMaxPoolGradSamePadding1_1_3d(self):\n    self._ConstructAndTestGradient(\n        nn_ops.max_pool3d,\n        input_sizes=[1, 3, 2, 4, 1],\n        output_sizes=[1, 3, 2, 4, 1],\n        window=(1, 1, 1),\n        strides=(1, 1, 1),\n        padding=\"SAME\")\n\n  @test_util.run_deprecated_v1\n  def testMaxPoolGradSamePadding1_2_3d(self):\n    self._ConstructAndTestGradient(\n        nn_ops.max_pool3d,\n        input_sizes=[1, 3, 2, 4, 1],\n        output_sizes=[1, 2, 1, 2, 1],\n        window=(1, 1, 1),\n        strides=(2, 2, 2),\n        padding=\"SAME\")\n\n  @test_util.run_deprecated_v1\n  def testMaxPoolGradSamePadding2_1_3d(self):\n    self._ConstructAndTestGradient(\n        nn_ops.max_pool3d,\n        input_sizes=[1, 3, 2, 4, 1],\n        output_sizes=[1, 3, 2, 4, 1],\n        window=(2, 2, 2),\n        strides=(1, 1, 1),\n        padding=\"SAME\")\n\n  @test_util.run_deprecated_v1\n  def testMaxPoolGradSamePadding2_2_3d(self):\n    self._ConstructAndTestGradient(\n        nn_ops.max_pool3d,\n        input_sizes=[1, 5, 2, 4, 2],\n        output_sizes=[1, 3, 1, 2, 2],\n        window=(2, 2, 2),\n        strides=(2, 2, 2),\n        padding=\"SAME\")\n\n  @test_util.run_deprecated_v1\n  def testMaxPoolGradSamePadding3_1_3d(self):\n    self._ConstructAndTestGradient(\n        nn_ops.max_pool3d,\n        input_sizes=[1, 3, 4, 2, 1],\n        output_sizes=[1, 3, 4, 2, 1],\n        window=(3, 3, 3),\n        strides=(1, 1, 1),\n        padding=\"SAME\")\n\n  @test_util.run_deprecated_v1\n  def testAvgPoolGradValidPadding1_1_3d(self):\n    self._ConstructAndTestGradient(\n        nn_ops.avg_pool3d,\n        input_sizes=[1, 3, 3, 3, 1],\n        output_sizes=[1, 3, 3, 3, 1],\n        window=(1, 1, 1),\n        strides=(1, 1, 1),\n        padding=\"VALID\")\n\n  @test_util.run_deprecated_v1\n  def testAvgPoolGradValidPadding1_2_3d(self):\n    self._ConstructAndTestGradient(\n        nn_ops.avg_pool3d,\n        input_sizes=[1, 3, 3, 3, 1],\n        output_sizes=[1, 2, 2, 2, 1],\n        window=(1, 1, 1),\n        strides=(2, 2, 2),\n        padding=\"VALID\")\n\n  @test_util.run_deprecated_v1\n  def testAvgPoolGradValidPadding2_1_3d(self):\n    self._ConstructAndTestGradient(\n        nn_ops.avg_pool3d,\n        input_sizes=[1, 3, 3, 3, 2],\n        output_sizes=[1, 2, 2, 2, 2],\n        window=(2, 2, 2),\n        strides=(1, 1, 1),\n        padding=\"VALID\")\n\n  @test_util.run_deprecated_v1\n  def testAvgPoolGradValidPadding2_2_3d(self):\n    self._ConstructAndTestGradient(\n        nn_ops.avg_pool3d,\n        input_sizes=[2, 2, 2, 2, 2],\n        output_sizes=[2, 1, 1, 1, 2],\n        window=(2, 2, 2),\n        strides=(2, 2, 2),\n        padding=\"VALID\")\n\n  @test_util.run_deprecated_v1\n  def testAvgPoolGradSamePadding1_1_3d(self):\n    self._ConstructAndTestGradient(\n        nn_ops.avg_pool3d,\n        input_sizes=[1, 3, 2, 4, 2],\n        output_sizes=[1, 3, 2, 4, 2],\n        window=(1, 1, 1),\n        strides=(1, 1, 1),\n        padding=\"SAME\")\n\n  @test_util.run_deprecated_v1\n  def testAvgPoolGradSamePadding1_2_3d(self):\n    self._ConstructAndTestGradient(\n        nn_ops.avg_pool3d,\n        input_sizes=[1, 3, 2, 4, 2],\n        output_sizes=[1, 2, 1, 2, 2],\n        window=(1, 1, 1),\n        strides=(2, 2, 2),\n        padding=\"SAME\")\n\n  @test_util.run_deprecated_v1\n  def testAvgPoolGradSamePadding2_1_3d(self):\n    self._ConstructAndTestGradient(\n        nn_ops.avg_pool3d,\n        input_sizes=[1, 2, 2, 2, 1],\n        output_sizes=[1, 2, 2, 2, 1],\n        window=(2, 2, 2),\n        strides=(1, 1, 1),\n        padding=\"SAME\")\n\n  @test_util.run_deprecated_v1\n  def testAvgPoolGradSamePadding2_2_3d(self):\n    self._ConstructAndTestGradient(\n        nn_ops.avg_pool3d,\n        input_sizes=[1, 5, 2, 4, 1],\n        output_sizes=[1, 3, 1, 2, 1],\n        window=(2, 2, 2),\n        strides=(2, 2, 2),\n        padding=\"SAME\")\n\n  @test_util.run_deprecated_v1\n  def testAvgPoolGradSamePadding3_1_3d(self):\n    self._ConstructAndTestGradient(\n        nn_ops.avg_pool3d,\n        input_sizes=[1, 3, 6, 2, 1],\n        output_sizes=[1, 3, 6, 2, 1],\n        window=(3, 3, 3),\n        strides=(1, 1, 1),\n        padding=\"SAME\")\n\n  def testMaxPool3DZeroPoolSize(self):\n    # Test case for GitHub issue 51936.\n    for f in [nn_ops.max_pool3d, nn_ops.avg_pool3d]:\n      with self.session():\n        with self.assertRaises((errors.InvalidArgumentError, ValueError)):\n          input_sizes = [3, 4, 10, 11, 12]\n\n          input_data = 1.\n          input_tensor = constant_op.constant(\n              input_data, shape=input_sizes, name=\"input\")\n          pool_3d = f(input_tensor, ksize=[2, 2, 0], strides=1, padding=\"VALID\")\n          self.evaluate(pool_3d)\n\n  @test_util.disable_xla(\"b/205634417\")  # XLA does not raise these errors.\n  def testMaxPoolGradEagerShapeErrors(self):\n    with context.eager_mode():\n      orig_in = array_ops.ones((1, 1, 1, 1, 1))\n\n      # Test invalid orig_out shape\n      orig_out = array_ops.ones((1, 1, 1, 1, 2))\n      grad = array_ops.ones((1, 1, 1, 1, 1))\n      with self.assertRaisesRegex(\n          errors_impl.InvalidArgumentError,\n          r\"Expected orig_output shape to be \\[1,1,1,1,1\\], but got \"\n          r\"\\[1,1,1,1,2\\]\"):\n        gen_nn_ops.max_pool3d_grad(\n            orig_in, orig_out, grad, ksize=[1, 1, 1, 1, 1],\n            strides=[1, 1, 1, 1, 1], padding=\"VALID\")\n      with self.assertRaisesRegex(\n          errors_impl.InvalidArgumentError,\n          r\"Expected orig_output shape to be \\[1,1,1,1,1\\], but got \"\n          r\"\\[1,1,1,1,2\\]\"):\n        gen_nn_ops.max_pool3d_grad_grad(\n            orig_in, orig_out, grad, ksize=[1, 1, 1, 1, 1],\n            strides=[1, 1, 1, 1, 1], padding=\"VALID\")\n\n      # Test invalid grad shape\n      orig_out = array_ops.ones((1, 1, 1, 1, 1))\n      grad = array_ops.ones((1, 1, 1, 1, 2))\n      with self.assertRaisesRegex(\n          errors_impl.InvalidArgumentError,\n          r\"Expected grad shape to be \\[1,1,1,1,1\\], but got \\[1,1,1,1,2\\]\"):\n        gen_nn_ops.max_pool3d_grad(\n            orig_in, orig_out, grad, ksize=[1, 1, 1, 1, 1],\n            strides=[1, 1, 1, 1, 1], padding=\"VALID\")\n      with self.assertRaisesRegex(\n          errors_impl.InvalidArgumentError,\n          r\"Expected grad shape to be \\[1,1,1,1,1\\], but got \\[1,1,1,1,2\\]\"):\n        gen_nn_ops.max_pool3d_grad_grad(\n            orig_in, orig_out, grad, ksize=[1, 1, 1, 1, 1],\n            strides=[1, 1, 1, 1, 1], padding=\"VALID\")\n\n\nif __name__ == \"__main__\":\n  test.main()\n"], "fixing_code": ["load(\"//tensorflow/core/platform:rules_cc.bzl\", \"cc_library\")\nload(\"//tensorflow:tensorflow.bzl\", \"if_google\", \"if_libtpu\", \"tf_cc_binary\", \"tf_cc_test\", \"tf_copts\", \"tf_cuda_cc_test\", \"tf_gen_op_wrapper_py\", \"tf_openmp_copts\")\nload(\"//tensorflow:tensorflow.bzl\", \"cuda_py_test\")\nload(\n    \"//tensorflow/core/platform/default:cuda_build_defs.bzl\",\n    \"if_cuda_is_configured\",\n)\nload(\n    \"//tensorflow/core/platform:build_config.bzl\",\n    \"tf_additional_tensor_coding_deps\",\n    \"tf_proto_library\",\n)\nload(\"//tensorflow/compiler/xla:xla.bzl\", \"xla_py_proto_library\")\n\n# buildifier: disable=same-origin-load\nload(\"//tensorflow:tensorflow.bzl\", \"filegroup\")\n\n# buildifier: disable=same-origin-load\nload(\"//tensorflow:tensorflow.bzl\", \"get_compatible_with_portable\")\nload(\"@local_config_rocm//rocm:build_defs.bzl\", \"if_rocm_is_configured\")\nload(\"//tensorflow/compiler/xla/service/cpu:build_defs.bzl\", \"runtime_copts\")\n\npackage(\n    default_visibility = [\":internal\"],\n    licenses = [\"notice\"],\n)\n\npackage_group(\n    name = \"internal\",\n    packages = [\n        \"//tensorflow/compiler/aot/...\",\n        \"//tensorflow/compiler/jit/...\",\n        \"//tensorflow/compiler/mlir/...\",\n        \"//tensorflow/compiler/tests/...\",\n        \"//tensorflow/compiler/tf2xla/...\",\n        \"//tensorflow/core/tpu/...\",\n        \"//tensorflow/python/compiler/...\",\n    ],\n)\n\npackage_group(\n    name = \"friends\",\n    includes = [\":internal\"],\n    packages = [\n        \"//tensorflow/...\",\n        \"//tensorflow_models/...\",\n        \"//third_party/deepmind/deepmind_research/density_functional_approximation_dm21/...\",\n        \"//third_party/mlir_edge/model_curriculum/iree/...\",\n        \"//third_party/mlperf/submissions/training/v0_7/models/...\",\n        \"//third_party/py/keras/...\",\n        \"//waymo/ml/deploy/benchmark/...\",\n    ],\n)\n\ncc_library(\n    name = \"tf2xla_supported_ops_lib\",\n    srcs = [\"tf2xla_supported_ops.cc\"],\n    hdrs = [\"tf2xla_supported_ops.h\"],\n    visibility = [\"//visibility:public\"],\n    deps = [\n        \":xla_compiler\",\n        \":xla_op_registry\",\n        \"//tensorflow/compiler/tf2xla/kernels:xla_ops\",\n        \"//tensorflow/core:framework\",\n        \"//tensorflow/core:framework_internal\",\n        \"//tensorflow/core:lib\",\n        \"//tensorflow/core:ops\",\n        \"//tensorflow/core:protos_all_cc\",\n        \"@com_google_absl//absl/strings\",\n    ],\n)\n\ntf_cc_binary(\n    name = \"tf2xla_supported_ops\",\n    srcs = [\"tf2xla_supported_ops_main.cc\"],\n    visibility = [\"//visibility:public\"],\n    deps = [\":tf2xla_supported_ops_lib\"],\n)\n\ntf_proto_library(\n    name = \"tf2xla_support_proto\",\n    srcs = [\"support.proto\"],\n    cc_api_version = 2,\n    visibility = [\"//visibility:public\"],\n)\n\nxla_py_proto_library(\n    name = \"tf2xla_support_py_pb2\",\n    has_services = False,\n    api_version = 2,\n    visibility = [\"//visibility:public\"],\n    deps = [\":tf2xla_support_proto\"],\n)\n\ntf_proto_library(\n    name = \"tf2xla_proto\",\n    srcs = [\"tf2xla.proto\"],\n    cc_api_version = 2,\n    protodeps = [\n        \"//tensorflow/core:protos_all\",\n    ],\n    visibility = [\"//visibility:public\"],\n)\n\nxla_py_proto_library(\n    name = \"tf2xla_py\",\n    has_services = False,\n    api_version = 2,\n    visibility = [\"//visibility:public\"],\n    deps = [\":tf2xla_proto\"],\n)\n\ntf_proto_library(\n    name = \"host_compute_metadata_proto\",\n    srcs = [\"host_compute_metadata.proto\"],\n    cc_api_version = 2,\n    protodeps = [\n        \"//tensorflow/core:protos_all\",\n    ],\n    visibility = [\"//visibility:public\"],\n)\n\ncc_library(\n    name = \"graph_compiler_util\",\n    srcs = [\"graph_compiler_util.cc\"],\n    hdrs = [\"graph_compiler_util.h\"],\n    visibility = [\":friends\"],\n    deps = [\n        \":functionalize_control_flow\",\n        \":sharding_util\",\n        \":tf2xla_proto_cc\",\n        \":tf2xla_util\",\n        \":xla_compiler\",\n        \"//tensorflow/compiler/xla:status_macros\",\n        \"//tensorflow/compiler/xla:statusor\",\n        \"//tensorflow/compiler/xla:xla_data_proto_cc\",\n        \"//tensorflow/core:core_cpu\",\n        \"//tensorflow/core:core_cpu_internal\",\n        \"//tensorflow/core:framework\",\n        \"//tensorflow/core:framework_internal\",\n        \"//tensorflow/core:graph\",\n        \"//tensorflow/core:lib\",\n        \"//tensorflow/core:protos_all_cc\",\n        \"@com_google_absl//absl/strings\",\n        \"@com_google_absl//absl/types:optional\",\n    ],\n)\n\ncc_library(\n    name = \"tf2xla\",\n    srcs = [\"tf2xla.cc\"],\n    hdrs = [\"tf2xla.h\"],\n    visibility = [\"//visibility:public\"],\n    deps = [\n        \":common\",\n        \":graph_compiler_util\",\n        \":tf2xla_proto_cc\",\n        \":tf2xla_util\",\n        \":xla_compiler\",\n        \":xla_op_registry\",\n        \"//tensorflow/compiler/aot:aot_only_var_handle_op\",\n        \"//tensorflow/compiler/tf2xla/kernels:xla_ops\",\n        \"//tensorflow/compiler/xla/client\",\n        \"//tensorflow/compiler/xla/client:xla_computation\",\n        \"//tensorflow/core:core_cpu\",\n        \"//tensorflow/core:core_cpu_internal\",\n        \"//tensorflow/core:framework\",\n        \"//tensorflow/core:framework_internal\",\n        \"//tensorflow/core:lib\",\n        \"//tensorflow/core:protos_all_cc\",\n        \"@com_google_absl//absl/strings\",\n    ],\n)\n\ncc_library(\n    name = \"mlir_tf2xla\",\n    srcs = [\"mlir_tf2xla.cc\"],\n    hdrs = [\"tf2xla.h\"],\n    visibility = [\"//visibility:public\"],\n    deps = [\n        \":tf2xla_proto_cc\",\n        \":tf2xla_util\",\n        \":xla_compiler\",\n        \"//tensorflow/compiler/jit\",\n        \"//tensorflow/compiler/mlir/hlo\",\n        \"//tensorflow/compiler/mlir/tensorflow\",\n        \"//tensorflow/compiler/mlir/tensorflow:compile_mlir_util\",\n        \"//tensorflow/compiler/mlir/tensorflow:device_util\",\n        \"//tensorflow/compiler/mlir/tensorflow:error_util\",\n        \"//tensorflow/compiler/mlir/tensorflow:import_model\",\n        \"//tensorflow/compiler/mlir/tensorflow:import_utils\",\n        \"//tensorflow/compiler/mlir/tensorflow:mlir_roundtrip_flags\",\n        \"//tensorflow/compiler/mlir/tensorflow:tensorflow_passes\",\n        \"//tensorflow/compiler/mlir/tensorflow:tf_dialect_passes\",\n        \"//tensorflow/compiler/mlir/xla:mlir_hlo_to_hlo\",\n        \"//tensorflow/compiler/xla/client\",\n        \"//tensorflow/compiler/xla/client:xla_computation\",\n        \"//tensorflow/core:protos_all_cc\",\n        \"@com_google_absl//absl/strings\",\n        \"@llvm-project//mlir:FuncDialect\",\n        \"@llvm-project//mlir:IR\",\n        \"@llvm-project//mlir:ShapeDialect\",\n    ],\n)\n\n# The filegroups below are explicitly used by\n# tensorflow/tools/pip_package:build_pip_package to ensure we include the proper\n# sources for the XLA AOT CPU runtime; as these are necessary outside of bazel\n# when linking tfcompile objects using saved_model_cli (e.g. using the\n# tensorflow pip package). The associated .cc files are included in tensorflow\n# pip package's xla_aot_runtime_srcs/ subdirectory. All necessary headers are\n# also included in the pip package's include/tensorflow/ and include/external/\n# subdirectories. Note however that sometimes additional object files may need\n# to be linked when linking aot xla objects, e.g. abseil libraries. See the deps\n# attribute of the \"xla_compiled_cpu_runtime_standalone\" target below for an\n# exhaustive list.\nfilegroup(\n    name = \"xla_compiled_cpu_runtime_hdrs\",\n    srcs = [\n        \"xla_compiled_cpu_function.h\",\n        \"//tensorflow/compiler/xla:cpu_runtime_hdrs\",\n        \"//tensorflow/compiler/xla/service/cpu:runtime_hdrs\",\n        \"//tensorflow/core/kernels:xla_cpu_runtime_hdrs\",\n        \"//tensorflow/core/platform:xla_cpu_runtime_srcs\",\n    ],\n    visibility = [\"//tensorflow/tools/pip_package:__pkg__\"],\n)\n\nfilegroup(\n    name = \"xla_compiled_cpu_runtime_srcs\",\n    srcs = [\n        \"xla_compiled_cpu_function.cc\",\n        \"//tensorflow/compiler/xla:cpu_runtime_srcs\",\n        \"//tensorflow/compiler/xla/service/cpu:runtime_srcs\",\n        \"//tensorflow/core/kernels:xla_cpu_runtime_srcs\",\n        \"//tensorflow/core/platform:xla_cpu_runtime_srcs\",\n    ],\n    visibility = [\"//tensorflow/tools/pip_package:__pkg__\"],\n)\n\n# This stand-alone target is used to ensure that we can build tf_library type\n# targets against the subset of sources declared in\n# xla_compiled_cpu_runtime_{srcs,hdrs}.\n#\n# The macros in tensorflow/python/tools/tools.bzl produce AOT compiled binaries\n# that rely on this target, as do unit tests in tensorflow/python/tools.\n#\n# See above for the significance of the source filegroups.\ncc_library(\n    name = \"xla_compiled_cpu_runtime_standalone\",\n    srcs = [\n        \":xla_compiled_cpu_runtime_srcs\",\n    ],\n    hdrs = [\n        \":xla_compiled_cpu_runtime_hdrs\",\n    ],\n    copts = runtime_copts() + tf_openmp_copts(),\n    features = [\"fully_static_link\"],\n    linkstatic = 1,\n    visibility = [\":friends\"],\n    # Note, we specifically removed MKL and multithreaded dependencies so the\n    # standalone does not require the MKL binary blob or threading libraries.\n    #\n    # TODO(ebrevdo): Remove tf_additoinal_tensor_coding_deps in favor of\n    # absl/strings:cord when we update absl to a newer version.\n    deps = [\n        \"@com_google_absl//absl/base\",\n        \"@com_google_absl//absl/base:core_headers\",\n        \"@com_google_absl//absl/base:dynamic_annotations\",\n        \"@com_google_absl//absl/strings\",\n        \"@com_google_absl//absl/strings:str_format\",\n        \"@com_google_absl//absl/synchronization\",\n        \"//third_party/eigen3\",\n        \"//tensorflow/compiler/xla/service:custom_call_status_internal\",\n        \"//tensorflow/core/framework:numeric_types\",\n        \"//tensorflow/core/platform:bfloat16\",\n        \"//tensorflow/core/platform:stringpiece\",\n        # Extra dependencies required for multithreaded runtime objects.\n        \"//tensorflow/core/platform:blocking_counter\",\n        \"//tensorflow/core/platform:logging\",\n        \"//tensorflow/core/platform:mutex\",\n    ] + tf_additional_tensor_coding_deps(),\n    alwayslink = 1,\n)\n\ncc_library(\n    name = \"xla_compiled_cpu_function\",\n    srcs = [\"xla_compiled_cpu_function.cc\"],\n    hdrs = [\"xla_compiled_cpu_function.h\"],\n    compatible_with = get_compatible_with_portable(),\n    visibility = [\"//visibility:public\"],\n    deps = [\n        \"//tensorflow/compiler/xla/service:custom_call_status_internal\",\n        # Keep dependencies to a minimum here; this library is used in every AOT\n        # binary produced by tfcompile.\n        \"//tensorflow/compiler/xla:cpu_function_runtime\",\n        \"//tensorflow/compiler/xla:executable_run_options\",\n        \"//tensorflow/core/platform:types\",\n    ],\n)\n\ntf_cc_test(\n    name = \"cpu_function_runtime_test\",\n    srcs = [\"cpu_function_runtime_test.cc\"],\n    deps = [\n        \"//tensorflow/compiler/xla:cpu_function_runtime\",\n        \"//tensorflow/core:framework\",\n        \"//tensorflow/core:test\",\n        \"//tensorflow/core:test_main\",\n    ],\n)\n\ncc_library(\n    name = \"xla_jit_compiled_cpu_function\",\n    srcs = [\"xla_jit_compiled_cpu_function.cc\"],\n    hdrs = [\"xla_jit_compiled_cpu_function.h\"],\n    visibility = [\"//visibility:public\"],\n    deps = [\n        \":tf2xla\",\n        \":tf2xla_proto_cc\",\n        \":xla_compiled_cpu_function\",\n        \"//tensorflow/compiler/xla:cpu_function_runtime\",\n        \"//tensorflow/compiler/xla:shape_util\",\n        \"//tensorflow/compiler/xla:statusor\",\n        \"//tensorflow/compiler/xla:xla_data_proto_cc\",\n        \"//tensorflow/compiler/xla/client:client_library\",\n        \"//tensorflow/compiler/xla/client:local_client\",\n        \"//tensorflow/compiler/xla/client:xla_computation\",\n        \"//tensorflow/compiler/xla/service:platform_util\",\n        \"//tensorflow/core:lib\",\n        \"//tensorflow/core:protos_all_cc\",\n        \"//tensorflow/stream_executor:platform\",\n    ] + if_libtpu(\n        if_false = [\n            \"//tensorflow/compiler/xla/service:cpu_plugin\",\n            \"//tensorflow/compiler/xla/service/cpu:buffer_info_util\",\n            \"//tensorflow/compiler/xla/service/cpu:cpu_executable\",\n        ],\n        if_true = [],\n    ),\n)\n\ncc_library(\n    name = \"xla_compiler\",\n    srcs = [\n        \"const_analysis.cc\",\n        \"graph_compiler.cc\",\n        \"xla_compiler.cc\",\n        \"xla_op_kernel.cc\",\n        \"xla_cpu_backend.cc\",\n    ] + if_cuda_is_configured([\n        \"xla_gpu_backend.cc\",\n    ]) + if_rocm_is_configured([\n        \"xla_gpu_backend.cc\",\n    ]),\n    hdrs = [\n        \"const_analysis.h\",\n        \"graph_compiler.h\",\n        \"xla_compiler.h\",\n        \"xla_helpers.h\",\n        \"xla_op_kernel.h\",\n        \"xla_op_registry.h\",\n    ],\n    copts = tf_copts(),\n    visibility = [\":friends\"],\n    deps = [\n        \":common\",\n        \":layout_util\",\n        \":host_compute_metadata_proto_cc\",\n        \":rearrange_function_argument\",\n        \":sharding_util\",\n        \":side_effect_util\",\n        \":tf2xla_util\",\n        \":xla_argument\",\n        \":xla_compilation_device\",\n        \":xla_context\",\n        \":xla_expression\",\n        \":xla_helpers\",\n        \":xla_op_registry\",\n        \":xla_resource\",\n        \"//tensorflow/compiler/mlir:mlir_bridge_rollout_policy\",\n        \"@com_google_absl//absl/algorithm:container\",\n        \"@com_google_absl//absl/container:flat_hash_map\",\n        \"@com_google_absl//absl/memory\",\n        \"@com_google_absl//absl/types:optional\",\n        \"@com_google_absl//absl/types:span\",\n        \"@com_google_absl//absl/types:variant\",\n        \"//tensorflow/compiler/jit:common\",\n        \"//tensorflow/compiler/jit:flags\",\n        \"//tensorflow/compiler/jit:shape_inference\",\n        \"//tensorflow/compiler/mlir:array_container_utils\",\n        \"//tensorflow/compiler/mlir/tensorflow:compile_mlir_util_no_tf_dialect_passes\",\n        \"//tensorflow/compiler/xla/client:value_inference\",\n        \"//tensorflow/compiler/xla/service:computation_placer_hdr\",\n        \"//tensorflow/compiler/xla:executable_run_options\",\n        \"//tensorflow/compiler/xla:protobuf_util\",\n        \"//tensorflow/compiler/xla:shape_util\",\n        \"//tensorflow/compiler/xla:status_macros\",\n        \"//tensorflow/compiler/xla:util\",\n        \"//tensorflow/compiler/xla:xla_data_proto_cc\",\n        \"//tensorflow/compiler/xla/client:client_library\",\n        \"//tensorflow/compiler/xla/client:local_client\",\n        \"//tensorflow/compiler/xla/client:xla_builder\",\n        \"//tensorflow/compiler/xla/client:xla_computation\",\n        \"//tensorflow/compiler/xla/service:hlo\",\n        \"//tensorflow/core/util:overflow\",\n        \"//tensorflow/core:core_cpu\",\n        \"//tensorflow/core:core_cpu_internal\",\n        \"//tensorflow/core:framework\",\n        \"//tensorflow/core:lib\",\n        \"//tensorflow/core:lib_internal\",\n        \"//tensorflow/core:ops\",\n        \"//tensorflow/core:protos_all_cc\",\n    ] + if_libtpu([\n        \":xla_tpu_backend_registration\",\n    ]),\n    alwayslink = 1,\n)\n\ncc_library(\n    name = \"xla_compilation_device\",\n    srcs = [\n        \"xla_compilation_device.cc\",\n    ],\n    hdrs = [\n        \"xla_compilation_device.h\",\n    ],\n    deps = [\n        \":common\",\n        \":frontend_attributes_util\",\n        \":sharding_util\",\n        \":xla_context\",\n        \":xla_helpers\",\n        \"//tensorflow/compiler/xla/client:xla_builder\",\n        \"//tensorflow/core:framework\",\n        \"//tensorflow/core:lib\",\n        \"//tensorflow/core:session_options\",\n        \"//tensorflow/core/common_runtime:core_cpu_internal\",\n    ],\n    alwayslink = 1,\n)\n\ncc_library(\n    name = \"xla_tpu_backend_registration\",\n    srcs = [\"xla_tpu_backend.cc\"],\n    visibility = [\"//visibility:public\"],\n    deps = [\n        \":xla_op_registry\",\n        \"//tensorflow/core/tpu:tpu_defs\",\n        \"//tensorflow/core/tpu:tpu_node_device_util\",\n    ],\n    alwayslink = 1,\n)\n\ncc_library(\n    name = \"xla_context\",\n    srcs = [\n        \"xla_context.cc\",\n    ],\n    hdrs = [\n        \"xla_context.h\",\n    ],\n    deps = [\n        \":common\",\n        \":xla_expression\",\n        \":xla_helpers\",\n        \"//tensorflow/compiler/xla:literal\",\n        \"//tensorflow/compiler/xla:shape_util\",\n        \"//tensorflow/compiler/xla:status_macros\",\n        \"//tensorflow/compiler/xla:statusor\",\n        \"//tensorflow/compiler/xla:xla_data_proto_cc\",\n        \"//tensorflow/compiler/xla/client:client_library\",\n        \"//tensorflow/compiler/xla/client:xla_builder\",\n        \"//tensorflow/compiler/xla/client:xla_computation\",\n        \"//tensorflow/core:framework\",\n        \"//tensorflow/core:lib\",\n        \"//tensorflow/core/common_runtime:core_cpu_internal\",\n        \"@com_google_absl//absl/types:span\",\n    ],\n    alwayslink = 1,\n)\n\ncc_library(\n    name = \"xla_op_registry\",\n    srcs = [\n        \"xla_op_registry.cc\",\n    ],\n    hdrs = [\n        \"xla_op_registry.h\",\n    ],\n    visibility = [\":friends\"],\n    deps = [\n        \":common\",\n        \":xla_context\",\n        \"//tensorflow/compiler/jit:flags\",\n        \"//tensorflow/compiler/jit:xla_cluster_util\",\n        \"//tensorflow/compiler/xla/client:client_library\",\n        \"//tensorflow/core:framework\",\n        \"//tensorflow/core:lib\",\n        \"//tensorflow/core:protos_all_cc\",\n        \"//tensorflow/core:session_options\",\n        \"//tensorflow/core/common_runtime:core_cpu_internal\",\n        \"//tensorflow/core/platform:stream_executor_no_cuda\",\n    ],\n    alwayslink = 1,\n)\n\ncc_library(\n    name = \"xla_expression\",\n    srcs = [\n        \"xla_expression.cc\",\n    ],\n    hdrs = [\n        \"xla_expression.h\",\n    ],\n    deps = [\n        \":common\",\n        \":xla_resource\",\n        \"//tensorflow/compiler/xla:statusor\",\n        \"//tensorflow/compiler/xla/client\",\n        \"//tensorflow/compiler/xla/client:value_inference\",\n        \"//tensorflow/compiler/xla/client:xla_builder\",\n        \"//tensorflow/core:framework\",\n        \"//tensorflow/core:lib\",\n        \"//tensorflow/core:protos_all_cc\",\n        \"@com_google_absl//absl/types:optional\",\n    ],\n    alwayslink = 1,\n)\n\ncc_library(\n    name = \"xla_resource\",\n    srcs = [\n        \"xla_resource.cc\",\n    ],\n    hdrs = [\n        \"xla_resource.h\",\n    ],\n    deps = [\n        \":common\",\n        \":sharding_util\",\n        \":xla_helpers\",\n        \"//tensorflow/compiler/xla:xla_data_proto_cc\",\n        \"//tensorflow/compiler/xla/client:xla_builder\",\n        \"//tensorflow/core:framework\",\n        \"//tensorflow/core:lib\",\n        \"//tensorflow/core:protos_all_cc\",\n        \"@com_google_absl//absl/memory\",\n        \"@com_google_absl//absl/strings\",\n    ],\n    alwayslink = 1,\n)\n\ncc_library(\n    name = \"xla_helpers\",\n    srcs = [\n        \"xla_helpers.cc\",\n    ],\n    hdrs = [\n        \"xla_helpers.h\",\n    ],\n    visibility = [\":friends\"],\n    deps = [\n        \":common\",\n        \":host_compute_metadata_proto_cc\",\n        \"//tensorflow/compiler/tf2xla/lib:util\",\n        \"//tensorflow/compiler/xla:executable_run_options\",\n        \"//tensorflow/compiler/xla:types\",\n        \"//tensorflow/compiler/xla/client:xla_builder\",\n        \"//tensorflow/compiler/xla/client:xla_computation\",\n        \"//tensorflow/compiler/xla/client/lib:arithmetic\",\n        \"//tensorflow/compiler/xla/client/lib:constants\",\n        \"//tensorflow/compiler/xla/service:computation_placer_hdr\",\n        \"//tensorflow/compiler/xla/service:hlo\",\n        \"//tensorflow/compiler/xla/service/gpu:gpu_executable_run_options\",\n        \"//tensorflow/core:core_cpu_base\",\n        \"//tensorflow/core:framework\",\n        \"//tensorflow/core:lib\",\n        \"//tensorflow/stream_executor:stream_header\",\n        \"@com_google_absl//absl/synchronization\",\n        \"@com_google_absl//absl/types:optional\",\n        \"@com_google_absl//absl/types:span\",\n    ],\n    alwayslink = 1,\n)\n\ncc_library(\n    name = \"xla_argument\",\n    srcs = [\n        \"xla_argument.cc\",\n    ],\n    hdrs = [\n        \"xla_argument.h\",\n    ],\n    deps = [\n        \":host_compute_metadata_proto_cc\",\n        \":xla_resource\",\n        \"//tensorflow/compiler/xla/client:xla_builder\",\n        \"//tensorflow/compiler/xla/service:hlo\",\n        \"//tensorflow/core:framework\",\n        \"@com_google_absl//absl/types:optional\",\n        \"@com_google_absl//absl/types:span\",\n        \"@llvm-project//llvm:Support\",\n    ],\n    alwayslink = 1,\n)\n\ncc_library(\n    name = \"layout_util\",\n    srcs = [\n        \"layout_util.cc\",\n    ],\n    hdrs = [\n        \"layout_util.h\",\n    ],\n    visibility = [\":friends\"],\n    deps = [\n        \":common\",\n        \":xla_argument\",\n        \":xla_helpers\",\n        \"//tensorflow/compiler/xla:shape_util\",\n        \"//tensorflow/compiler/xla:statusor\",\n        \"//tensorflow/compiler/xla:xla_data_proto_cc\",\n        \"//tensorflow/core:framework\",\n        \"//tensorflow/core:lib\",\n        \"//tensorflow/core:protos_all_cc\",\n    ],\n    alwayslink = 1,\n)\n\ncc_library(\n    name = \"common\",\n    srcs = [\n        \"literal_util.cc\",\n        \"shape_util.cc\",\n        \"type_util.cc\",\n    ],\n    hdrs = [\n        \"literal_util.h\",\n        \"shape_util.h\",\n        \"type_util.h\",\n    ],\n    visibility = [\":friends\"],\n    deps = [\n        \"//tensorflow/compiler/xla:literal\",\n        \"//tensorflow/compiler/xla:shape_util\",\n        \"//tensorflow/compiler/xla:statusor\",\n        \"//tensorflow/compiler/xla:xla_data_proto_cc\",\n        \"//tensorflow/core:core_cpu_internal\",\n        \"//tensorflow/core:framework\",\n        \"//tensorflow/core:lib\",\n        \"//tensorflow/core:protos_all_cc\",\n        \"@com_google_absl//absl/container:flat_hash_map\",\n        \"@com_google_absl//absl/types:span\",\n    ],\n)\n\ncc_library(\n    name = \"frontend_attributes_util\",\n    srcs = [\"frontend_attributes_util.cc\"],\n    hdrs = [\"frontend_attributes_util.h\"],\n    visibility = [\"//visibility:public\"],\n    deps = [\n        \":tf2xla_defs\",\n        \"//tensorflow/compiler/xla:statusor\",\n        \"//tensorflow/compiler/xla:xla_data_proto_cc\",\n        \"//tensorflow/core:framework\",\n        \"//tensorflow/core:lib\",\n        \"//tensorflow/core:protos_all_cc\",\n        \"@com_google_absl//absl/types:optional\",\n    ],\n)\n\ncc_library(\n    name = \"sharding_util\",\n    srcs = [\"sharding_util.cc\"],\n    hdrs = [\"sharding_util.h\"],\n    visibility = [\"//visibility:public\"],\n    deps = [\n        \"//tensorflow/compiler/xla:status_macros\",\n        \"//tensorflow/compiler/xla/client:sharding_builder\",\n        \"//tensorflow/core:core_cpu\",\n        \"//tensorflow/core:core_cpu_internal\",\n        \"//tensorflow/core:framework\",\n        \"//tensorflow/core:framework_internal\",\n        \"//tensorflow/core:lib\",\n        \"//tensorflow/core:protos_all_cc\",\n        \"@com_google_absl//absl/strings\",\n    ],\n)\n\ntf_cc_test(\n    name = \"sharding_util_test\",\n    srcs = [\"sharding_util_test.cc\"],\n    deps = [\n        \":sharding_util\",\n        \"//tensorflow/core:lib\",\n        \"//tensorflow/core:protos_all_cc\",\n        \"//tensorflow/core:test\",\n        \"//tensorflow/core:test_main\",\n        \"//tensorflow/core:testlib\",\n    ],\n)\n\n# Internal targets below this point.\n\ncc_library(\n    name = \"tf2xla_defs\",\n    hdrs = [\"tf2xla_defs.h\"],\n    visibility = [\":friends\"],\n    deps = [\n        \"@com_google_absl//absl/strings\",\n    ],\n)\n\ncc_library(\n    name = \"tf2xla_util\",\n    srcs = [\"tf2xla_util.cc\"],\n    hdrs = [\"tf2xla_util.h\"],\n    visibility = [\":friends\"],\n    deps = [\n        \":sharding_util\",\n        \":tf2xla_defs\",\n        \":tf2xla_proto_cc\",\n        \"//tensorflow/compiler/xla:status_macros\",\n        \"//tensorflow/compiler/xla:xla_data_proto_cc\",\n        \"//tensorflow/core:core_cpu\",\n        \"//tensorflow/core:core_cpu_internal\",\n        \"//tensorflow/core:framework\",\n        \"//tensorflow/core:framework_internal\",\n        \"//tensorflow/core:lib\",\n        \"//tensorflow/core:protos_all_cc\",\n        \"@com_google_absl//absl/container:flat_hash_map\",\n        \"@com_google_absl//absl/strings\",\n        \"@com_google_absl//absl/types:optional\",\n    ],\n)\n\ntf_cc_test(\n    name = \"tf2xla_util_test\",\n    srcs = [\"tf2xla_util_test.cc\"],\n    deps = [\n        \":sharding_util\",\n        \":tf2xla_util\",\n        \"//tensorflow/cc:cc_ops\",\n        \"//tensorflow/cc:function_ops\",\n        \"//tensorflow/cc:functional_ops\",\n        \"//tensorflow/cc:ops\",\n        \"//tensorflow/core:core_cpu_internal\",\n        \"//tensorflow/core:framework\",\n        \"//tensorflow/core:lib\",\n        \"//tensorflow/core:math_ops_op_lib\",\n        \"//tensorflow/core:ops\",\n        \"//tensorflow/core:protos_all_cc\",\n        \"//tensorflow/core:test\",\n        \"//tensorflow/core:test_main\",\n        \"@com_google_absl//absl/strings\",\n    ],\n)\n\ntf_cc_test(\n    name = \"tf2xla_test\",\n    srcs = [\"tf2xla_test.cc\"],\n    deps = [\n        \":tf2xla\",\n        \":tf2xla_proto_cc\",\n        \"//tensorflow/compiler/xla:literal\",\n        \"//tensorflow/compiler/xla:literal_util\",\n        \"//tensorflow/compiler/xla:statusor\",\n        \"//tensorflow/compiler/xla/client:client_library\",\n        \"//tensorflow/compiler/xla/client:local_client\",\n        \"//tensorflow/compiler/xla/client:xla_computation\",\n        \"//tensorflow/compiler/xla/service:cpu_plugin\",\n        \"//tensorflow/core:framework\",\n        \"//tensorflow/core:lib\",\n        \"//tensorflow/core:protos_all_cc\",\n        \"//tensorflow/core:test\",\n        \"//tensorflow/core:test_main\",\n    ],\n)\n\ntf_cc_test(\n    name = \"xla_jit_compiled_cpu_function_test\",\n    srcs = [\"xla_jit_compiled_cpu_function_test.cc\"],\n    deps = [\n        \":tf2xla_proto_cc\",\n        \":xla_jit_compiled_cpu_function\",\n        \"//tensorflow/compiler/xla:shape_util\",\n        \"//tensorflow/compiler/xla:status_macros\",\n        \"//tensorflow/compiler/xla:statusor\",\n        \"//tensorflow/compiler/xla:test\",\n        \"//tensorflow/compiler/xla:xla_data_proto_cc\",\n        \"//tensorflow/compiler/xla/client:local_client\",\n        \"//tensorflow/compiler/xla/service:compiler\",\n        \"//tensorflow/compiler/xla/service:platform_util\",\n        \"//tensorflow/core:framework\",\n        \"//tensorflow/core:lib\",\n        \"//tensorflow/core:protos_all_cc\",\n        \"//tensorflow/core:test\",\n        \"//tensorflow/core:test_main\",\n        \"//tensorflow/stream_executor:multi_platform_manager\",\n        \"//tensorflow/stream_executor:platform\",\n        \"@com_google_absl//absl/memory\",\n        \"@com_google_absl//absl/strings\",\n    ],\n)\n\ntf_cc_test(\n    name = \"xla_compiler_test\",\n    srcs = [\n        \"xla_compiler_test.cc\",\n        \"xla_expression_test.cc\",\n    ],\n    deps = [\n        \":common\",\n        \":layout_util\",\n        \":side_effect_util\",\n        \":xla_argument\",\n        \":xla_compiler\",\n        \":xla_expression\",\n        \":xla_resource\",\n        \"//tensorflow/cc:cc_ops\",\n        \"//tensorflow/cc:function_ops\",\n        \"//tensorflow/cc:functional_ops\",\n        \"//tensorflow/cc:ops\",\n        \"//tensorflow/cc:resource_variable_ops\",\n        \"//tensorflow/compiler/tf2xla/kernels:xla_ops\",\n        \"//tensorflow/compiler/xla:literal\",\n        \"//tensorflow/compiler/xla:shape_util\",\n        \"//tensorflow/compiler/xla:status_macros\",\n        \"//tensorflow/compiler/xla/client:client_library\",\n        \"//tensorflow/compiler/xla/client:local_client\",\n        \"//tensorflow/compiler/xla/client:xla_builder\",\n        \"//tensorflow/compiler/xla/service:cpu_plugin\",\n        \"//tensorflow/compiler/xla/service:hlo_proto_cc\",\n        \"//tensorflow/compiler/xla/tests:literal_test_util\",\n        \"//tensorflow/core:core_cpu_internal\",\n        \"//tensorflow/core:framework\",\n        \"//tensorflow/core:lib\",\n        \"//tensorflow/core:protos_all_cc\",\n        \"//tensorflow/core:test\",\n        \"//tensorflow/core:test_main\",\n        \"//tensorflow/core:testlib\",\n        \"//tensorflow/core/framework:tensor_testutil\",\n        \"@com_google_absl//absl/memory\",\n        \"@com_google_absl//absl/strings\",\n    ],\n)\n\ntf_cc_test(\n    name = \"literal_util_test\",\n    srcs = [\n        \"literal_util_test.cc\",\n    ],\n    deps = [\n        \":common\",\n        \"//tensorflow/compiler/xla:literal\",\n        \"//tensorflow/compiler/xla:literal_util\",\n        \"//tensorflow/core:framework\",\n        \"//tensorflow/core:test\",\n        \"//tensorflow/core:test_main\",\n        \"//tensorflow/core:testlib\",\n    ],\n)\n\ntf_cc_test(\n    name = \"const_analysis_test\",\n    size = \"small\",\n    srcs = [\"const_analysis_test.cc\"],\n    deps = [\n        \":xla_compiler\",\n        \"//tensorflow/cc:cc_ops\",\n        \"//tensorflow/cc:function_ops\",\n        \"//tensorflow/cc:functional_ops\",\n        \"//tensorflow/cc:ops\",\n        \"//tensorflow/compiler/jit:flags\",\n        \"//tensorflow/compiler/jit:xla_cluster_util\",\n        \"//tensorflow/compiler/tf2xla/kernels:xla_ops\",\n        \"//tensorflow/core:core_cpu_internal\",\n        \"//tensorflow/core:framework\",\n        \"//tensorflow/core:ops\",\n        \"//tensorflow/core:test\",\n        \"//tensorflow/core:test_main\",\n    ],\n)\n\ncc_library(\n    name = \"light_outside_compilation_kernels_for_test\",\n    testonly = True,\n    srcs = [\"light_outside_compilation_kernels_for_test.cc\"],\n    linkstatic = 1,\n    deps = [\n        \":xla_compiler\",\n        \"//tensorflow/cc:cc_ops\",\n        \"//tensorflow/cc:function_ops\",\n        \"//tensorflow/cc:functional_ops\",\n        \"//tensorflow/cc:ops\",\n        \"//tensorflow/compiler/tf2xla/kernels:gpu_tf_kernel_custom_call\",\n        \"//tensorflow/core:framework\",\n    ],\n    alwayslink = 1,\n)\n\ntf_gen_op_wrapper_py(\n    name = \"test_ops_for_light_outside_compilation\",\n    testonly = True,\n    out = \"test_ops_for_light_outside_compilation.py\",\n    deps = [\n        \":light_outside_compilation_kernels_for_test\",\n    ],\n)\n\ncuda_py_test(\n    name = \"light_outside_compilation_test\",\n    srcs = [\"light_outside_compilation_test.py\"],\n    python_version = \"PY3\",\n    tags = [\n        \"no_oss\",\n        \"no_pip\",\n    ],\n    xla_enable_strict_auto_jit = False,\n    deps = [\n        \":test_ops_for_light_outside_compilation\",\n        \"//tensorflow/compiler/mlir/python/mlir_wrapper:filecheck_wrapper\",\n    ] + if_google([\":light_outside_compilation_kernels_for_test\"]),\n)\n\ncc_library(\n    name = \"functionalize_control_flow_util\",\n    srcs = [\n        \"functionalize_control_flow_util.cc\",\n    ],\n    hdrs = [\n        \"functionalize_control_flow_util.h\",\n    ],\n    deps = [\n        \"//tensorflow/compiler/tf2xla/ops:xla_ops\",\n        \"//tensorflow/compiler/xla:status_macros\",\n        \"//tensorflow/core:core_cpu\",\n        \"//tensorflow/core:core_cpu_internal\",\n        \"//tensorflow/core:graph\",\n        \"//tensorflow/core:protos_all_cc\",\n        \"@com_google_absl//absl/strings\",\n    ],\n)\n\ncc_library(\n    name = \"functionalize_cond\",\n    srcs = [\n        \"functionalize_cond.cc\",\n    ],\n    hdrs = [\n        \"functionalize_cond.h\",\n    ],\n    deps = [\n        \":frontend_attributes_util\",\n        \":functionalize_control_flow_util\",\n        \":tf2xla_util\",\n        \"//tensorflow/compiler/tf2xla/ops:xla_ops\",\n        \"//tensorflow/compiler/xla:status_macros\",\n        \"//tensorflow/compiler/xla:union_find\",\n        \"//tensorflow/core:core_cpu\",\n        \"//tensorflow/core:core_cpu_internal\",\n        \"//tensorflow/core:framework\",\n        \"//tensorflow/core:graph\",\n        \"//tensorflow/core:lib\",\n        \"//tensorflow/core:protos_all_cc\",\n        \"@com_google_absl//absl/memory\",\n        \"@com_google_absl//absl/strings\",\n        \"@com_google_absl//absl/types:optional\",\n    ],\n)\n\ncc_library(\n    name = \"functionalize_control_flow\",\n    srcs = [\n        \"functionalize_control_flow.cc\",\n    ],\n    hdrs = [\n        \"functionalize_control_flow.h\",\n    ],\n    visibility = [\":friends\"],\n    deps = [\n        \":functionalize_cond\",\n        \":functionalize_control_flow_util\",\n        \":functionalize_while\",\n        \":tf2xla_util\",\n        \"//tensorflow/compiler/tf2xla/ops:xla_ops\",\n        \"//tensorflow/compiler/xla:status_macros\",\n        \"//tensorflow/compiler/xla:union_find\",\n        \"//tensorflow/core:core_cpu\",\n        \"//tensorflow/core:core_cpu_internal\",\n        \"//tensorflow/core:framework\",\n        \"//tensorflow/core:graph\",\n        \"//tensorflow/core:lib\",\n        \"@com_google_absl//absl/memory\",\n        \"@com_google_absl//absl/types:optional\",\n    ],\n)\n\ncc_library(\n    name = \"mlir_bridge_pass\",\n    srcs = [\"mlir_bridge_pass.cc\"],\n    hdrs = [\"mlir_bridge_pass.h\"],\n    deps = [\n        \":tf2xla_defs\",\n        \"//tensorflow/compiler/jit:flags\",\n        \"//tensorflow/compiler/mlir:mlir_bridge_rollout_policy\",\n        \"//tensorflow/compiler/mlir:mlir_graph_optimization_pass\",\n        \"//tensorflow/compiler/mlir/tensorflow\",\n        \"//tensorflow/compiler/mlir/tensorflow:device_util\",\n        \"//tensorflow/compiler/mlir/tensorflow:tensorflow_passes\",\n        \"//tensorflow/core:core_cpu\",\n        \"//tensorflow/core:framework\",\n        \"//tensorflow/core:lib\",\n        \"//tensorflow/core/common_runtime:device_set\",\n        \"@com_google_absl//absl/base\",\n        \"@llvm-project//llvm:Support\",\n    ],\n    alwayslink = 1,\n)\n\ncc_library(\n    name = \"mlir_bridge_pass_registration\",\n    srcs = [\n        \"mlir_bridge_pass_registration.cc\",\n    ],\n    visibility = [\n        # We define a new TPU device in TFRT to enable TFRT TPU Runtime.\n        \"//learning/brain/tfrt/tf_tpu:__pkg__\",\n        \":internal\",\n    ],\n    deps = [\n        \":mlir_bridge_pass\",\n        \"//tensorflow/compiler/mlir:mlir_graph_optimization_pass_registration\",\n        \"//tensorflow/core:core_cpu\",\n    ],\n    alwayslink = 1,\n)\n\ncc_library(\n    name = \"rearrange_function_argument\",\n    srcs = [\n        \"rearrange_function_argument.cc\",\n    ],\n    hdrs = [\n        \"rearrange_function_argument.h\",\n    ],\n    deps = [\n        \":tf2xla_util\",\n        \"//tensorflow/compiler/tf2xla/ops:xla_ops\",\n        \"//tensorflow/compiler/xla:status_macros\",\n        \"//tensorflow/core:core_cpu\",\n        \"//tensorflow/core:core_cpu_internal\",\n        \"//tensorflow/core:framework\",\n        \"//tensorflow/core:graph\",\n        \"//tensorflow/core:lib\",\n        \"@com_google_absl//absl/memory\",\n        \"@com_google_absl//absl/types:optional\",\n    ],\n)\n\ncc_library(\n    name = \"functionalize_control_flow_pass_registration\",\n    srcs = [\n        \"functionalize_control_flow_pass_registration.cc\",\n    ],\n    visibility = [\":friends\"],\n    deps = [\n        \":functionalize_control_flow\",\n    ],\n    alwayslink = 1,\n)\n\ncc_library(\n    name = \"functionalize_while\",\n    srcs = [\n        \"functionalize_while.cc\",\n    ],\n    hdrs = [\n        \"functionalize_while.h\",\n    ],\n    deps = [\n        \":frontend_attributes_util\",\n        \":functionalize_cond\",\n        \":functionalize_control_flow_util\",\n        \":tf2xla_util\",\n        \"//tensorflow/compiler/tf2xla/ops:xla_ops\",\n        \"//tensorflow/compiler/xla:status_macros\",\n        \"//tensorflow/compiler/xla:union_find\",\n        \"//tensorflow/core:core_cpu\",\n        \"//tensorflow/core:core_cpu_internal\",\n        \"//tensorflow/core:framework\",\n        \"//tensorflow/core:graph\",\n        \"//tensorflow/core:lib\",\n        \"@com_google_absl//absl/memory\",\n        \"@com_google_absl//absl/strings\",\n        \"@com_google_absl//absl/types:optional\",\n    ],\n)\n\ntf_cc_test(\n    name = \"functionalize_control_flow_test\",\n    srcs = [\"functionalize_control_flow_test.cc\"],\n    deps = [\n        \":functionalize_control_flow\",\n        \":test_util\",\n        \":tf2xla_util\",\n        \"//tensorflow/cc:cc_ops\",\n        \"//tensorflow/cc:cc_ops_internal\",\n        \"//tensorflow/cc:function_ops\",\n        \"//tensorflow/cc:functional_ops\",\n        \"//tensorflow/cc:ops\",\n        \"//tensorflow/cc:resource_variable_ops\",\n        \"//tensorflow/compiler/tf2xla/cc:xla_ops\",\n        \"//tensorflow/compiler/xla:status_macros\",\n        \"//tensorflow/core:core_cpu\",\n        \"//tensorflow/core:core_cpu_internal\",\n        \"//tensorflow/core:framework\",\n        \"//tensorflow/core:framework_internal\",\n        \"//tensorflow/core:ops\",\n        \"//tensorflow/core:resource_variable_ops_op_lib\",\n        \"//tensorflow/core:test\",\n        \"//tensorflow/core:test_main\",\n    ],\n)\n\ntf_cc_test(\n    name = \"functionalize_cond_test\",\n    srcs = [\"functionalize_cond_test.cc\"],\n    deps = [\n        \":functionalize_cond\",\n        \":functionalize_control_flow\",\n        \":test_util\",\n        \"//tensorflow/cc:cc_ops\",\n        \"//tensorflow/cc:cc_ops_internal\",\n        \"//tensorflow/cc:function_ops\",\n        \"//tensorflow/cc:ops\",\n        \"//tensorflow/cc:resource_variable_ops\",\n        \"//tensorflow/cc:scope\",\n        \"//tensorflow/compiler/tf2xla/cc:xla_ops\",\n        \"//tensorflow/compiler/xla:status_macros\",\n        \"//tensorflow/core:core_cpu\",\n        \"//tensorflow/core:core_cpu_internal\",\n        \"//tensorflow/core:framework\",\n        \"//tensorflow/core:framework_internal\",\n        \"//tensorflow/core:ops\",\n        \"//tensorflow/core:protos_all_cc\",\n        \"//tensorflow/core:resource_variable_ops_op_lib\",\n        \"//tensorflow/core:test\",\n        \"//tensorflow/core:test_main\",\n        \"//tensorflow/core:testlib\",\n        \"//tensorflow/core/platform:test\",\n        \"@com_google_absl//absl/container:flat_hash_set\",\n        \"@com_google_absl//absl/strings\",\n    ],\n)\n\ncc_library(\n    name = \"test_util\",\n    testonly = 1,\n    srcs = [\"test_util.cc\"],\n    hdrs = [\"test_util.h\"],\n    deps = [\n        \"//tensorflow/compiler/xla:status_macros\",\n        \"//tensorflow/core:core_cpu\",\n        \"//tensorflow/core:framework\",\n        \"//tensorflow/core:framework_internal\",\n        \"//tensorflow/core:lib\",\n        \"//tensorflow/core:protos_all_cc\",\n    ],\n)\n\ntf_cc_test(\n    name = \"xla_op_registry_test\",\n    srcs = [\"xla_op_registry_test.cc\"],\n    deps = [\n        \":xla_compiler\",\n        \"//tensorflow/core:test\",\n        \"//tensorflow/core:test_main\",\n    ],\n)\n\ncc_library(\n    name = \"resource_operation_table\",\n    srcs = [\"resource_operation_table.cc\"],\n    hdrs = [\"resource_operation_table.h\"],\n    deps = [\n        \"//tensorflow/core:lib\",\n        \"//tensorflow/core:ops\",\n        \"@com_google_absl//absl/algorithm:container\",\n        \"@com_google_absl//absl/container:flat_hash_map\",\n        \"@com_google_absl//absl/strings\",\n    ],\n)\n\ntf_cc_test(\n    name = \"resource_operation_table_test\",\n    srcs = [\"resource_operation_table_test.cc\"],\n    deps = [\n        \":resource_operation_table\",\n        \":xla_compiler\",\n        \"//tensorflow/compiler/tf2xla/kernels:xla_ops\",\n        \"//tensorflow/core:test\",\n        \"//tensorflow/core:test_main\",\n        \"@com_google_absl//absl/algorithm:container\",\n        \"@com_google_absl//absl/container:flat_hash_map\",\n        \"@com_google_absl//absl/strings\",\n    ],\n)\n\ncc_library(\n    name = \"side_effect_util\",\n    srcs = [\"side_effect_util.cc\"],\n    hdrs = [\"side_effect_util.h\"],\n    visibility = [\":friends\"],\n    deps = [\n        \"//tensorflow/core:core_cpu\",\n        \"@com_google_absl//absl/strings\",\n    ],\n)\n\ntf_cuda_cc_test(\n    name = \"fused_batchnorm_reserve_space_test\",\n    size = \"medium\",\n    srcs = [\"fused_batchnorm_reserve_space_test.cc\"],\n    tags = [\n        \"no_cuda_asan\",  # TODO(b/193450885)\n    ],\n    deps = [\n        \"//tensorflow/cc:cc_ops\",\n        \"//tensorflow/cc:ops\",\n        \"//tensorflow/cc:scope\",\n        \"//tensorflow/compiler/jit\",\n        \"//tensorflow/compiler/jit:flags\",\n        \"//tensorflow/core:core_cpu\",\n        \"//tensorflow/core:framework\",\n        \"//tensorflow/core:framework_internal\",\n        \"//tensorflow/core:lib\",\n        \"//tensorflow/core:protos_all_cc\",\n        \"//tensorflow/core:tensorflow\",\n        \"//tensorflow/core:test\",\n        \"//tensorflow/core:test_main\",\n        \"//tensorflow/core:testlib\",\n        \"//third_party/eigen3\",\n        \"@com_google_absl//absl/algorithm:container\",\n        \"@com_google_absl//absl/strings\",\n    ],\n)\n\ncc_library(\n    name = \"mlir_xla_op_kernel\",\n    srcs = [\"mlir_xla_op_kernel.cc\"],\n    hdrs = [\"mlir_xla_op_kernel.h\"],\n    deps = [\n        \":xla_compiler\",\n        \"//tensorflow/compiler/jit:xla_compilation_cache\",\n        \"//tensorflow/compiler/mlir:array_container_utils\",\n        \"//tensorflow/compiler/mlir/tensorflow:compile_mlir_util_no_tf_dialect_passes\",\n        \"@llvm-project//mlir:IR\",\n    ],\n)\n\ncc_library(\n    name = \"resource_util\",\n    srcs = [\"resource_util.cc\"],\n    hdrs = [\"resource_util.h\"],\n    visibility = [\":friends\"],\n    deps = [\n        \":resource_operation_table\",\n        \"//tensorflow/compiler/xla:status_macros\",\n        \"//tensorflow/core:core_cpu\",\n        \"//tensorflow/core:graph\",\n        \"//tensorflow/core:lib\",\n        \"//tensorflow/core:protos_all_cc\",\n        \"//tensorflow/stream_executor/lib\",\n        \"@com_google_absl//absl/container:flat_hash_map\",\n        \"@com_google_absl//absl/container:flat_hash_set\",\n        \"@com_google_absl//absl/hash\",\n        \"@com_google_absl//absl/strings\",\n    ],\n)\n\ntf_cuda_cc_test(\n    name = \"resource_util_test\",\n    size = \"small\",\n    srcs = [\"resource_util_test.cc\"],\n    deps = [\n        \":resource_util\",\n        \"//tensorflow/cc:scope\",\n        \"//tensorflow/core:framework\",\n        \"//tensorflow/core:graph\",\n        \"//tensorflow/core:protos_all_cc\",\n        \"//tensorflow/core:tensorflow\",\n        \"//tensorflow/core:test\",\n        \"//tensorflow/core:test_main\",\n        \"//tensorflow/core:testlib\",\n        \"@com_google_absl//absl/container:flat_hash_map\",\n        \"@com_google_absl//absl/container:flat_hash_set\",\n        \"@com_google_absl//absl/memory\",\n    ],\n)\n", "/* Copyright 2017 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n\n#include \"tensorflow/compiler/tf2xla/xla_op_kernel.h\"\n\n#include <numeric>\n\n#include \"absl/memory/memory.h\"\n#include \"tensorflow/compiler/tf2xla/literal_util.h\"\n#include \"tensorflow/compiler/tf2xla/shape_util.h\"\n#include \"tensorflow/compiler/tf2xla/type_util.h\"\n#include \"tensorflow/compiler/tf2xla/xla_compilation_device.h\"\n#include \"tensorflow/compiler/tf2xla/xla_context.h\"\n#include \"tensorflow/compiler/tf2xla/xla_helpers.h\"\n#include \"tensorflow/compiler/xla/client/value_inference.h\"\n#include \"tensorflow/compiler/xla/client/xla_builder.h\"\n#include \"tensorflow/compiler/xla/client/xla_computation.h\"\n#include \"tensorflow/compiler/xla/status_macros.h\"\n#include \"tensorflow/core/common_runtime/dma_helper.h\"\n#include \"tensorflow/core/platform/errors.h\"\n#include \"tensorflow/core/util/overflow.h\"\n\nnamespace tensorflow {\n\nXlaOpKernelContext::XlaOpKernelContext(OpKernelContext* context)\n    : context_(context),\n      dynamic_dimension_is_minus_one_(false),\n      value_inference_(xla_context()->builder()) {}\n\nbool XlaOpKernelContext::ValidateInputsAreSameShape(OpKernel* op) {\n  return context_->ValidateInputsAreSameShape(op);\n}\n\nXlaContext* XlaOpKernelContext::xla_context() const {\n  return &XlaContext::Get(context_);\n}\n\nxla::XlaBuilder* XlaOpKernelContext::builder() const {\n  return xla_context()->builder();\n}\n\nxla::ValueInference& XlaOpKernelContext::value_inference() {\n  return value_inference_;\n}\n\nXlaCompiler* XlaOpKernelContext::compiler() const {\n  return xla_context()->compiler();\n}\n\nconst XlaExpression& XlaOpKernelContext::InputExpression(int index) {\n  return *XlaExpression::CastExpressionFromTensor(context_->input(index));\n}\n\nconst XlaExpression& XlaOpKernelContext::InputExpression(\n    absl::string_view name) {\n  return *XlaExpression::CastExpressionFromTensor(GetInputTensorByName(name));\n}\n\nxla::XlaOp XlaOpKernelContext::Input(int index) {\n  return InputExpression(index).AsXlaOp(builder());\n}\n\nxla::XlaOp XlaOpKernelContext::Input(absl::string_view name) {\n  return InputExpression(name).AsXlaOp(builder());\n}\n\nTensorShape XlaOpKernelContext::InputShape(int index) {\n  return context_->input(index).shape();\n}\n\nTensorShape XlaOpKernelContext::InputShape(absl::string_view name) {\n  return GetInputTensorByName(name).shape();\n}\n\nStatusOr<xla::Shape> XlaOpKernelContext::InputXlaShape(int index) {\n  return builder()->GetShape(Input(index));\n}\n\nStatusOr<xla::Shape> XlaOpKernelContext::InputXlaShape(absl::string_view name) {\n  return builder()->GetShape(Input(name));\n}\n\nDataType XlaOpKernelContext::input_type(int index) const {\n  DataType type = context_->input_dtype(index);\n  if (type == DT_UINT8) {\n    // Masqueraded XlaExpression could have different type. See\n    // XlaOpKernelContext::SetOutputExpression for details.\n    auto expression =\n        XlaExpression::CastExpressionFromTensor(context_->input(index));\n    type = expression->dtype();\n  }\n  return type;\n}\n\nDataType XlaOpKernelContext::InputType(absl::string_view name) {\n  const Tensor& tensor = GetInputTensorByName(name);\n  DataType type = tensor.dtype();\n  if (type == DT_UINT8) {\n    // Masqueraded XlaExpression could have different type. See\n    // XlaOpKernelContext::SetOutputExpression for details.\n    auto expression = XlaExpression::CastExpressionFromTensor(tensor);\n    type = expression->dtype();\n  }\n  return type;\n}\n\nxla::PrimitiveType XlaOpKernelContext::input_xla_type(int index) {\n  xla::PrimitiveType type;\n  Status status = DataTypeToPrimitiveType(input_type(index), &type);\n  if (!status.ok()) {\n    SetStatus(status);\n    return xla::PRIMITIVE_TYPE_INVALID;\n  }\n  return type;\n}\n\nxla::PrimitiveType XlaOpKernelContext::InputXlaType(absl::string_view name) {\n  xla::PrimitiveType type;\n  Status status = DataTypeToPrimitiveType(InputType(name), &type);\n  if (!status.ok()) {\n    SetStatus(status);\n    return xla::PRIMITIVE_TYPE_INVALID;\n  }\n  return type;\n}\n\nStatus XlaOpKernelContext::ConstantInput(int index,\n                                         xla::Literal* constant_literal,\n                                         xla::ValueInferenceMode mode) {\n  if (this->InputXlaShape(index)->is_dynamic()) {\n    return errors::InvalidArgument(\n        \"Reading input as constant from a dynamic tensor is not yet supported. \"\n        \"Xla shape: \",\n        this->InputXlaShape(index)->ToString());\n  }\n  return ConstantInputReshaped(index,\n                               context_->input(index).shape().dim_sizes(),\n                               constant_literal, mode);\n}\n\nstatic StatusOr<int> InputIndex(XlaOpKernelContext* context,\n                                absl::string_view name) {\n  int start, stop;\n  TF_RETURN_IF_ERROR(context->op_kernel().InputRange(name, &start, &stop));\n  if (stop != start + 1) {\n    return errors::InvalidArgument(\"OpKernel used list-valued input name '\",\n                                   name,\n                                   \"' when single-valued input was \"\n                                   \"expected\");\n  }\n  return start;\n}\n\nStatus XlaOpKernelContext::ResolveInputDynamism(\n    int index, xla::Literal* dynamism_literal) {\n  return ResolveInputDynamismReshaped(\n      index, context_->input(index).shape().dim_sizes(), dynamism_literal);\n}\n\nStatus XlaOpKernelContext::ResolveInputDynamism(\n    absl::string_view name, xla::Literal* dynamism_literal) {\n  TF_ASSIGN_OR_RETURN(int index, InputIndex(this, name));\n  return ResolveInputDynamism(index, dynamism_literal);\n}\n\nStatus XlaOpKernelContext::ConstantInput(absl::string_view name,\n                                         xla::Literal* constant_literal,\n                                         xla::ValueInferenceMode mode) {\n  TF_ASSIGN_OR_RETURN(int index, InputIndex(this, name));\n  return ConstantInput(index, constant_literal, mode);\n}\n\nStatus XlaOpKernelContext::ConstantInputReshaped(\n    int index, absl::Span<const int64_t> new_dims,\n    xla::Literal* constant_literal, xla::ValueInferenceMode mode) {\n  TF_ASSIGN_OR_RETURN(Tensor constant, ConstantInputTensor(index, mode));\n  Tensor temp(constant.dtype());\n  if (!temp.CopyFrom(constant, TensorShape(new_dims))) {\n    return errors::InvalidArgument(\n        context_->op_kernel().name(), \" input \", index, \" has shape \",\n        constant.shape().DebugString(),\n        \" but was asked to be reshaped to incompatible shape \",\n        TensorShape(new_dims).DebugString());\n  }\n\n  TF_ASSIGN_OR_RETURN(*constant_literal, HostTensorToLiteral(temp));\n  return OkStatus();\n}\n\n// Converts an int32 or int64 scalar literal to an int64.\nstatic Status LiteralToInt64Scalar(const xla::LiteralSlice& literal,\n                                   int64_t* out) {\n  if (literal.shape().rank() != 0) {\n    return errors::InvalidArgument(\"value is not a scalar\");\n  }\n  if (literal.shape().element_type() == xla::S32) {\n    *out = literal.Get<int32>({});\n  } else if (literal.shape().element_type() == xla::S64) {\n    *out = literal.Get<int64_t>({});\n  } else {\n    return errors::InvalidArgument(\"value must be either int32 or int64\");\n  }\n  return OkStatus();\n}\n\n// Converts an float32 or float64 scalar literal to a float64.\nstatic Status LiteralToFloat64Scalar(const xla::LiteralSlice& literal,\n                                     double* out) {\n  if (literal.shape().rank() != 0) {\n    return errors::InvalidArgument(\"value is not a scalar\");\n  }\n  if (literal.shape().element_type() == xla::F32) {\n    *out = literal.Get<float>({});\n  } else if (literal.shape().element_type() == xla::F64) {\n    *out = literal.Get<double>({});\n  } else {\n    return errors::InvalidArgument(\"value must be either float32 or float64\");\n  }\n  return OkStatus();\n}\n\nStatus XlaOpKernelContext::ConstantInputAsIntScalar(\n    int index, int64_t* out, xla::ValueInferenceMode mode) {\n  xla::Literal literal;\n  TF_RETURN_IF_ERROR(ConstantInput(index, &literal, mode));\n  return LiteralToInt64Scalar(literal, out);\n}\n\nStatus XlaOpKernelContext::ConstantInputAsIntScalar(\n    absl::string_view name, int64_t* out, xla::ValueInferenceMode mode) {\n  TF_ASSIGN_OR_RETURN(int index, InputIndex(this, name));\n  return ConstantInputAsIntScalar(index, out, mode);\n}\n\nStatus XlaOpKernelContext::ConstantInputAsFloatScalar(\n    int index, double* out, xla::ValueInferenceMode mode) {\n  xla::Literal literal;\n  TF_RETURN_IF_ERROR(ConstantInput(index, &literal, mode));\n  return LiteralToFloat64Scalar(literal, out);\n}\n\nstatic Status LiteralToPredVector(const xla::LiteralSlice& literal,\n                                  std::vector<bool>* out) {\n  if (literal.shape().rank() != 1) {\n    return errors::InvalidArgument(\"output_shape must be rank 1, got shape \",\n                                   literal.shape().DebugString());\n  }\n  int64_t size = xla::ShapeUtil::ElementsIn(literal.shape());\n  if (literal.shape().element_type() != xla::PRED) {\n    return errors::InvalidArgument(\"value is not PRED\");\n  }\n  for (int64_t i = 0; i < size; ++i) {\n    out->push_back(literal.Get<bool>({i}));\n  }\n  return OkStatus();\n}\n\nStatus XlaOpKernelContext::ResolveInputDynamismIntoPred(int index, bool* out) {\n  xla::Literal literal;\n  XlaExpression e = InputExpression(index);\n  auto* client = compiler() ? compiler()->client() : nullptr;\n  StatusOr<Tensor> dynamism_or_status = e.ResolveDynamism(client);\n  if (!dynamism_or_status.ok()) {\n    // When failed to resolve dynamism, conservatively consider the value\n    // dynamic. This could happen if the input depends on some ops like\n    // custom-call that is not supported generally for dynamism computation.\n    //\n    // TODO(b/176993339): Support resolving dynamism across computations so\n    // resolving dynamism will not fail in those cases.\n    *out = true;\n    return OkStatus();\n  }\n  Tensor dynamism = dynamism_or_status.ValueOrDie();\n\n  Tensor temp(dynamism.dtype());\n  TensorShape tensor_shape({});\n  if (!temp.CopyFrom(dynamism, tensor_shape)) {\n    return errors::InvalidArgument(\n        context_->op_kernel().name(), \" input \", index, \" has shape \",\n        dynamism.shape().DebugString(), \" which is not a R0 \", tensor_shape);\n  }\n\n  TF_ASSIGN_OR_RETURN(literal, HostTensorToLiteral(temp));\n  *out = literal.Get<bool>({});\n  return OkStatus();\n}\n\nStatus XlaOpKernelContext::ResolveInputDynamismIntoPredVector(\n    absl::string_view name, std::vector<bool>* out) {\n  TF_ASSIGN_OR_RETURN(int index, InputIndex(this, name));\n  return ResolveInputDynamismIntoPredVector(index, out);\n}\n\nStatus XlaOpKernelContext::ResolveInputDynamismIntoPred(absl::string_view name,\n                                                        bool* out) {\n  TF_ASSIGN_OR_RETURN(int index, InputIndex(this, name));\n  return ResolveInputDynamismIntoPred(index, out);\n}\n\nStatus XlaOpKernelContext::ResolveInputDynamismReshaped(\n    int index, absl::Span<const int64_t> new_dims,\n    xla::Literal* dynamism_literal) {\n  XlaExpression e = InputExpression(index);\n  auto* client = compiler() ? compiler()->client() : nullptr;\n  StatusOr<Tensor> dynamism_or_status = e.ResolveDynamism(client);\n  if (!dynamism_or_status.ok()) {\n    xla::Literal true_literal = xla::LiteralUtil::CreateR0<bool>(true);\n    // When failed to resolve dynamism, conservatively consider the value\n    // dynamic. This could happen if the input depends on some ops like\n    // custom-call that is not supported generally for dynamism computation.\n    *dynamism_literal =\n        true_literal\n            .Broadcast(xla::ShapeUtil::MakeShape(xla::PRED, new_dims), {})\n            .ValueOrDie();\n\n    return OkStatus();\n  }\n  Tensor dynamism = dynamism_or_status.ValueOrDie();\n\n  Tensor temp(dynamism.dtype());\n  if (!temp.CopyFrom(dynamism, TensorShape(new_dims))) {\n    return errors::InvalidArgument(\n        context_->op_kernel().name(), \" input \", index, \" has shape \",\n        dynamism.shape().DebugString(),\n        \" but was asked to be reshaped to incompatible shape \",\n        TensorShape(new_dims).DebugString());\n  }\n\n  TF_ASSIGN_OR_RETURN(*dynamism_literal, HostTensorToLiteral(temp));\n  return OkStatus();\n}\n\nStatus XlaOpKernelContext::ResolveInputDynamismIntoPredVector(\n    int index, std::vector<bool>* out) {\n  xla::Literal literal;\n  TF_RETURN_IF_ERROR(ResolveInputDynamismReshaped(\n      index, {InputShape(index).num_elements()}, &literal));\n\n  return LiteralToPredVector(literal, out);\n}\n\n// Converts an int32 or int64 1D literal to an int64 vector.\nstatic Status LiteralToInt64Vector(const xla::LiteralSlice& literal,\n                                   std::vector<int64_t>* out) {\n  if (literal.shape().rank() != 1) {\n    return errors::InvalidArgument(\"output_shape must be rank 1, got shape \",\n                                   literal.shape().DebugString());\n  }\n  int64_t size = xla::ShapeUtil::ElementsIn(literal.shape());\n  if (literal.shape().element_type() == xla::S32) {\n    for (int64_t i = 0; i < size; ++i) {\n      out->push_back(literal.Get<int32>({i}));\n    }\n  } else if (literal.shape().element_type() == xla::S64) {\n    for (int64_t i = 0; i < size; ++i) {\n      out->push_back(literal.Get<int64_t>({i}));\n    }\n  } else {\n    return errors::InvalidArgument(\"value must be either int32 or int64\");\n  }\n  return OkStatus();\n}\n\nStatus XlaOpKernelContext::ConstantInputAsIntVector(\n    int index, std::vector<int64_t>* out, xla::ValueInferenceMode mode) {\n  xla::Literal literal;\n  TF_RETURN_IF_ERROR(ConstantInput(index, &literal, mode));\n  return LiteralToInt64Vector(literal, out);\n}\n\nStatus XlaOpKernelContext::ConstantInputAsIntVector(\n    absl::string_view name, std::vector<int64_t>* out,\n    xla::ValueInferenceMode mode) {\n  TF_ASSIGN_OR_RETURN(int index, InputIndex(this, name));\n  return ConstantInputAsIntVector(index, out, mode);\n}\n\nStatus XlaOpKernelContext::ConstantInputReshapedToIntVector(\n    int index, std::vector<int64_t>* out, xla::ValueInferenceMode mode) {\n  xla::Literal literal;\n  TF_RETURN_IF_ERROR(ConstantInputReshaped(\n      index, {InputShape(index).num_elements()}, &literal, mode));\n  return LiteralToInt64Vector(literal, out);\n}\n\nStatus XlaOpKernelContext::ConstantInputReshapedToIntVector(\n    absl::string_view name, std::vector<int64_t>* out,\n    xla::ValueInferenceMode mode) {\n  TF_ASSIGN_OR_RETURN(int index, InputIndex(this, name));\n  xla::Literal literal;\n  TF_RETURN_IF_ERROR(ConstantInputReshaped(\n      index, {InputShape(index).num_elements()}, &literal, mode));\n  return LiteralToInt64Vector(literal, out);\n}\n\nStatus XlaOpKernelContext::ConstantInputAsInt64Literal(\n    int index, xla::Literal* out, xla::ValueInferenceMode mode) {\n  xla::Literal literal;\n  TF_RETURN_IF_ERROR(ConstantInput(index, &literal, mode));\n  switch (literal.shape().element_type()) {\n    case xla::S32: {\n      *out = xla::Literal(\n          xla::ShapeUtil::ChangeElementType(literal.shape(), xla::S64));\n      auto src_data = literal.data<int32>();\n      for (int64_t i = 0; i < src_data.size(); ++i) {\n        out->data<int64_t>()[i] = src_data[i];\n      }\n      return OkStatus();\n    }\n    case xla::S64:\n      *out = std::move(literal);\n      return OkStatus();\n\n    default:\n      return errors::InvalidArgument(\n          \"Invalid argument to ConstantInputAsInt64Literal: \",\n          xla::ShapeUtil::HumanString(literal.shape()));\n  }\n}\n\nStatus XlaOpKernelContext::ConstantInputAsInt64Literal(\n    absl::string_view name, xla::Literal* out, xla::ValueInferenceMode mode) {\n  TF_ASSIGN_OR_RETURN(int index, InputIndex(this, name));\n  return ConstantInputAsInt64Literal(index, out, mode);\n}\n\n// TODO(phawkins): validate that the dimensions form a valid shape, fail\n// gracefully if they do not.\nStatus XlaOpKernelContext::ConstantInputAsShape(int index, TensorShape* shape,\n                                                xla::ValueInferenceMode mode) {\n  xla::Literal literal;\n  TF_RETURN_IF_ERROR(ConstantInput(index, &literal, mode));\n  std::vector<int64_t> dims;\n  TF_RETURN_IF_ERROR(LiteralToInt64Vector(literal, &dims));\n\n  int64_t num_elements = 1;\n  for (auto i = dims.begin(); i != dims.end(); ++i) {\n    num_elements = MultiplyWithoutOverflow(num_elements, *i);\n    if (num_elements < 0)\n      return errors::InvalidArgument(\n          \"The total elements specified by orig_input_shape is too large.\",\n          \"Encountered overflow after multiplying\", *i,\n          \", result: \", num_elements);\n  }\n  *shape = TensorShape(dims);\n  return OkStatus();\n}\n\nStatus XlaOpKernelContext::ConstantInputAsPartialShape(\n    int index, PartialTensorShape* shape) {\n  xla::Literal literal;\n  TF_RETURN_IF_ERROR(ConstantInput(index, &literal));\n  // If `literal` is a scalar it's value must be -1.\n  if (literal.shape().rank() == 0) {\n    int64_t shape_val;\n    TF_RETURN_IF_ERROR(LiteralToInt64Scalar(literal, &shape_val));\n    if (shape_val != -1) {\n      return errors::InvalidArgument(\n          \"Cannot convert value to PartialTensorShape: \", shape_val);\n    }\n    *shape = PartialTensorShape();  // Shape with unknown rank.\n    return OkStatus();\n  }\n  std::vector<int64_t> dims;\n  TF_RETURN_IF_ERROR(LiteralToInt64Vector(literal, &dims));\n  *shape = PartialTensorShape(dims);\n  return OkStatus();\n}\n\nStatus XlaOpKernelContext::InputList(absl::string_view name,\n                                     std::vector<xla::XlaOp>* handles,\n                                     std::vector<TensorShape>* shapes) {\n  OpInputList inputs;\n  TF_RETURN_IF_ERROR(context_->input_list(name, &inputs));\n  handles->clear();\n  shapes->clear();\n  for (const Tensor& input : inputs) {\n    handles->push_back(\n        XlaExpression::CastExpressionFromTensor(input)->AsXlaOp(builder()));\n    shapes->push_back(input.shape());\n  }\n  return OkStatus();\n}\n\nStatus XlaOpKernelContext::ConstantInputList(absl::string_view name,\n                                             std::vector<xla::Literal>* outputs,\n                                             xla::ValueInferenceMode mode) {\n  int start, stop;\n  TF_RETURN_IF_ERROR(op_kernel().InputRange(name, &start, &stop));\n  outputs->resize(stop - start);\n  for (int i = start; i < stop; ++i) {\n    TF_RETURN_IF_ERROR(ConstantInput(i, &(*outputs)[i], mode));\n  }\n  return OkStatus();\n}\n\nStatusOr<Tensor> XlaOpKernelContext::ConstantInputTensor(\n    int index, xla::ValueInferenceMode mode) {\n  XlaExpression e = InputExpression(index);\n  auto* client = compiler() ? compiler()->client() : nullptr;\n  StatusOr<std::optional<Tensor>> constant_or_status =\n      e.ResolveConstant(client, dynamic_dimension_is_minus_one_, mode);\n  if (!constant_or_status.ok()) {\n    Status status = constant_or_status.status();\n    errors::AppendToMessage(&status, \"while evaluating input \", index, \" of \",\n                            context_->op_kernel().type_string(),\n                            \" operator as a compile-time constant.\");\n    return status;\n  }\n  std::optional<Tensor> constant = constant_or_status.ValueOrDie();\n  if (!constant.has_value()) {\n    return errors::InvalidArgument(\n        \"Input \", index, \" to node `\", context_->op_kernel().name(),\n        \"` with op \", context_->op_kernel().type_string(),\n        \" must be a compile-time constant.\\n\\n\"\n        \"XLA compilation requires that operator arguments that represent \"\n        \"shapes or dimensions be evaluated to concrete values at compile time. \"\n        \"This error means that a shape or dimension argument could not be \"\n        \"evaluated at compile time, usually because the value of the argument \"\n        \"depends on a parameter to the computation, on a variable, or on a \"\n        \"stateful operation such as a random number generator.\");\n  }\n  return *constant;\n}\n\nnamespace {\n\nStatus ReadVariableInputTensor(const Tensor& tensor, DataType type,\n                               const XlaOpKernelContext* ctx,\n                               TensorShape* shape, xla::XlaOp* value) {\n  const XlaExpression* expression =\n      XlaExpression::CastExpressionFromTensor(tensor);\n  XlaResource* variable = expression->resource();\n  TF_RET_CHECK(variable != nullptr);\n  TF_RET_CHECK(variable->kind() == XlaResource::kVariable);\n  if (!variable->initialized()) {\n    return errors::FailedPrecondition(\n        \"Read variable failure \", variable->name(),\n        \". It could mean the variable is uninitialized or the variable is on \"\n        \"another device \");\n  }\n  if (variable->type() != type) {\n    return errors::InvalidArgument(\n        \"Trying to read variable with wrong dtype. Expected \",\n        DataTypeString(type), \" got \", DataTypeString(variable->type()));\n  }\n  if (shape) {\n    *shape = variable->shape();\n  }\n\n  if (!variable->IsOverwritten() && expression->constant_value()) {\n    TF_ASSIGN_OR_RETURN(xla::Literal literal,\n                        HostTensorToLiteral(*expression->constant_value()));\n    *value = xla::ConstantLiteral(ctx->builder(), literal);\n    return OkStatus();\n  }\n  auto shape_determination_fns =\n      ctx->compiler()->options().shape_determination_fns;\n  XlaLayoutPreference layout_preference =\n      shape_determination_fns.layout_preference_fn(\n          variable->shape(), variable->type(), std::nullopt);\n  TF_ASSIGN_OR_RETURN(xla::Shape representation_shape,\n                      shape_determination_fns.shape_representation_fn(\n                          variable->shape(), variable->type(),\n                          /*use_fast_memory=*/false, layout_preference));\n  xla::Shape xla_shape;\n  TF_RETURN_IF_ERROR(\n      TensorShapeToXLAShape(variable->type(), variable->shape(), &xla_shape));\n  if (xla::ShapeUtil::Compatible(xla_shape, representation_shape)) {\n    *value = variable->value();\n  } else {\n    *value = xla::Reshape(variable->value(), variable->shape().dim_sizes());\n  }\n  return OkStatus();\n}\n\n}  // namespace\n\nStatus XlaOpKernelContext::ReadVariableInput(int index, DataType type,\n                                             TensorShape* shape,\n                                             xla::XlaOp* value) {\n  return ReadVariableInputTensor(context_->input(index), type, this, shape,\n                                 value);\n}\n\nStatus XlaOpKernelContext::ReadVariableInput(absl::string_view name,\n                                             DataType type, TensorShape* shape,\n                                             xla::XlaOp* value) {\n  return ReadVariableInputTensor(GetInputTensorByName(name), type, this, shape,\n                                 value);\n}\n\nStatus XlaOpKernelContext::GetVariableTypeAndShape(int index, DataType* type,\n                                                   TensorShape* shape) const {\n  const Tensor& tensor = context_->input(index);\n  const XlaExpression* expression =\n      XlaExpression::CastExpressionFromTensor(tensor);\n  XlaResource* variable = expression->resource();\n  TF_RET_CHECK(variable != nullptr);\n  TF_RET_CHECK(variable->kind() == XlaResource::kVariable);\n  if (!variable->initialized()) {\n    return errors::InvalidArgument(\n        \"Read variable failure \", variable->name(),\n        \". It could mean the variable is uninitialized or the variable is on \"\n        \"another device \");\n  }\n  *type = variable->type();\n  *shape = variable->shape();\n  return OkStatus();\n}\n\nvoid XlaOpKernelContext::SetOutputExpression(int index,\n                                             const XlaExpression& expression) {\n  Status status = [&] {\n    // The step's default allocator is the dummy XlaCompilationAllocator which\n    // simply allocates a metadata buffer to hold the expression to which it\n    // corresponds.\n    // Provides a special behavior for DT_VARIANT and other types that are not\n    // trivially copyable. In those cases, allocate a tensor of type DT_UINT8.\n    if (!DataTypeCanUseMemcpy(expression.dtype())) {\n      // tensor_data() is not supported for tensors that cannot be copied via\n      // memcpy, as the copy logic might try to inspect the stored data (e.g.\n      // a std::string). This is likely to fail, as the data is invalid given\n      // that it actually encodes an XlaExpression. Using a uint8 tensor is\n      // always safe, so simply do that.\n      // TODO(jpienaar): This should be refactored to stop masquerading\n      // XlaExpressions as Tensors.\n      Tensor output;\n      TensorShape tensor_shape;\n      TF_RETURN_IF_ERROR(\n          context_->allocate_temp(DT_UINT8, tensor_shape, &output));\n      context_->set_output(index, output);\n    } else {\n      Tensor* output = nullptr;\n      TF_ASSIGN_OR_RETURN(TensorShape shape, expression.GetShape());\n      TF_RETURN_IF_ERROR(context_->allocate_output(index, shape, &output));\n    }\n    XlaExpression::AssignExpressionToTensor(expression,\n                                            context_->mutable_output(index));\n    return OkStatus();\n  }();\n  if (!status.ok()) {\n    SetStatus(status);\n  }\n}\n\nxla::PrimitiveType XlaOpKernelContext::output_xla_type(int index) {\n  xla::PrimitiveType type;\n  Status status = DataTypeToPrimitiveType(expected_output_dtype(index), &type);\n  if (!status.ok()) {\n    SetStatus(status);\n    return xla::PRIMITIVE_TYPE_INVALID;\n  }\n  return type;\n}\n\nvoid XlaOpKernelContext::SetOutput(int index, const xla::XlaOp& handle) {\n  SetOutputExpression(\n      index,\n      XlaExpression::XlaOp(handle, context_->expected_output_dtype(index)));\n}\n\nvoid XlaOpKernelContext::SetConstantOutput(int index, const Tensor& constant) {\n  SetOutputExpression(index, XlaExpression::Constant(constant));\n}\n\nvoid XlaOpKernelContext::SetTensorListOutput(int index,\n                                             const xla::XlaOp& handle) {\n  SetOutputExpression(index, XlaExpression::TensorList(handle));\n}\n\nvoid XlaOpKernelContext::SetResourceOutput(int index, XlaResource* resource) {\n  SetOutputExpression(index, XlaExpression::Resource(resource));\n}\n\nStatus XlaOpKernelContext::GetResourceInput(int index, XlaResource** resource) {\n  const XlaExpression* expression =\n      XlaExpression::CastExpressionFromTensor(context_->input(index));\n  TF_RET_CHECK(expression->resource() != nullptr);\n  *resource = expression->resource();\n  return OkStatus();\n}\n\nnamespace {\n\nStatus AssignVariableTensor(const Tensor& tensor, DataType type,\n                            const XlaOpKernelContext* ctx, xla::XlaOp handle,\n                            xla::XlaBuilder* builder) {\n  const XlaExpression* expression =\n      XlaExpression::CastExpressionFromTensor(tensor);\n  XlaResource* variable = expression->resource();\n  TF_RET_CHECK(variable != nullptr);\n  TF_RET_CHECK(variable->kind() == XlaResource::kVariable);\n\n  auto shape_or_status = builder->GetShape(handle);\n  if (!shape_or_status.ok()) {\n    return shape_or_status.status();\n  }\n  TensorShape shape;\n  TF_RETURN_IF_ERROR(\n      XLAShapeToTensorShape(shape_or_status.ValueOrDie(), &shape));\n\n  TF_RETURN_IF_ERROR(variable->SetTypeAndShape(type, shape));\n\n  auto shape_determination_fns =\n      ctx->compiler()->options().shape_determination_fns;\n  XlaLayoutPreference layout_preference =\n      shape_determination_fns.layout_preference_fn(shape, type, std::nullopt);\n  TF_ASSIGN_OR_RETURN(xla::Shape representation_shape,\n                      shape_determination_fns.shape_representation_fn(\n                          shape, type,\n                          /*use_fast_memory=*/false, layout_preference));\n  xla::Shape xla_shape;\n  TF_RETURN_IF_ERROR(TensorShapeToXLAShape(type, shape, &xla_shape));\n  if (!xla::ShapeUtil::Compatible(xla_shape, representation_shape)) {\n    handle = xla::Reshape(handle, representation_shape.dimensions());\n  }\n  variable->SetRepresentationShape(representation_shape);\n  return variable->SetValue(handle);\n}\n\n}  // namespace\n\nStatus XlaOpKernelContext::AssignVariable(int input_index, DataType type,\n                                          xla::XlaOp handle) {\n  TF_RET_CHECK(handle.valid());\n  return AssignVariableTensor(context_->input(input_index), type, this, handle,\n                              builder());\n}\n\nStatus XlaOpKernelContext::AssignVariable(absl::string_view name, DataType type,\n                                          xla::XlaOp handle) {\n  TF_RET_CHECK(handle.valid());\n  return AssignVariableTensor(GetInputTensorByName(name), type, this, handle,\n                              builder());\n}\n\nstatic Status GetStatusWithStackTrace(const Status& s,\n                                      const XlaOpKernelContext* ctx) {\n  if (s.code() == error::INVALID_ARGUMENT) {\n    return Status{s.code(),\n                  absl::StrCat(s.error_message(), \"\\n\", ctx->StackTrace())};\n  }\n  return s;\n}\n\nvoid XlaOpKernelContext::CtxFailure(const Status& s) {\n  context_->CtxFailure(GetStatusWithStackTrace(s, this));\n}\nvoid XlaOpKernelContext::CtxFailureWithWarning(const Status& s) {\n  context_->CtxFailureWithWarning(GetStatusWithStackTrace(s, this));\n}\n\nvoid XlaOpKernelContext::CtxFailure(const char* file, int line,\n                                    const Status& s) {\n  context_->CtxFailure(file, line, GetStatusWithStackTrace(s, this));\n}\nvoid XlaOpKernelContext::CtxFailureWithWarning(const char* file, int line,\n                                               const Status& s) {\n  context_->CtxFailureWithWarning(file, line, GetStatusWithStackTrace(s, this));\n}\n\nconst xla::XlaComputation* XlaOpKernelContext::GetOrCreateMax(\n    const DataType type) {\n  return xla_context()->GetOrCreateMax(type);\n}\n\nconst xla::XlaComputation* XlaOpKernelContext::GetOrCreateMin(\n    const DataType type) {\n  return xla_context()->GetOrCreateMin(type);\n}\n\nconst xla::XlaComputation* XlaOpKernelContext::GetOrCreateAdd(\n    const DataType type) {\n  return xla_context()->GetOrCreateAdd(type);\n}\n\nconst xla::XlaComputation* XlaOpKernelContext::GetOrCreateMul(\n    const DataType type) {\n  return xla_context()->GetOrCreateMul(type);\n}\n\nconst Tensor& XlaOpKernelContext::GetInputTensorByName(absl::string_view name) {\n  const Tensor* tensor;\n  CHECK(context_->input(name, &tensor).ok());\n  return *tensor;\n}\n\nXlaOpKernel::XlaOpKernel(OpKernelConstruction* context) : OpKernel(context) {}\n\nvoid XlaOpKernel::Compute(OpKernelContext* context) {\n  XlaOpKernelContext xla_context(context);\n  Compile(&xla_context);\n}\n\nstd::string XlaOpKernelContext::StackTrace() const {\n  if (const AbstractStackTrace* stack_trace =\n          xla_context()->StackTraceForNodeName(op_kernel().name())) {\n    AbstractStackTrace::TracePrintingOptions opts;\n    opts.show_line_contents = true;\n    opts.filter_common_prefix = true;\n    opts.drop_internal_frames = true;\n    return absl::StrCat(\"\\nStack trace for op definition: \\n\",\n                        stack_trace->ToString(opts), \"\\n\");\n  } else {\n    return \"\";\n  }\n}\n\n}  // namespace tensorflow\n", "/* Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n#define EIGEN_USE_THREADS\n\n#include \"tensorflow/core/kernels/pooling_ops_3d.h\"\n\n#include <array>\n\n#include \"third_party/eigen3/Eigen/Core\"\n#include \"third_party/eigen3/unsupported/Eigen/CXX11/Tensor\"\n#include \"tensorflow/core/framework/kernel_shape_util.h\"\n#include \"tensorflow/core/framework/numeric_op.h\"\n#include \"tensorflow/core/framework/op_kernel.h\"\n#include \"tensorflow/core/framework/register_types.h\"\n#include \"tensorflow/core/framework/tensor.h\"\n#include \"tensorflow/core/framework/tensor_shape.h\"\n#include \"tensorflow/core/framework/tensor_slice.h\"\n#include \"tensorflow/core/kernels/eigen_pooling.h\"\n#include \"tensorflow/core/kernels/ops_util.h\"\n#include \"tensorflow/core/lib/core/errors.h\"\n#include \"tensorflow/core/util/padding.h\"\n#include \"tensorflow/core/util/tensor_format.h\"\n#include \"tensorflow/core/util/work_sharder.h\"\n\n#if GOOGLE_CUDA || TENSORFLOW_USE_ROCM\n#include \"tensorflow/core/kernels/cudnn_pooling_gpu.h\"\n#include \"tensorflow/core/kernels/pooling_ops_3d_gpu.h\"\n#endif\n\n\nnamespace tensorflow {\n\ntypedef Eigen::ThreadPoolDevice CPUDevice;\ntypedef Eigen::GpuDevice GPUDevice;\n\nPool3dParameters::Pool3dParameters(OpKernelContext* context,\n                                   const std::vector<int32>& ksize,\n                                   const std::vector<int32>& stride,\n                                   Padding padding, TensorFormat data_format,\n                                   const TensorShape& tensor_in_shape) {\n  // For maxpooling, tensor_in should have 4 dimensions.\n  OP_REQUIRES(context, tensor_in_shape.dims() == 5,\n              errors::InvalidArgument(\"tensor_in must be 4-dimensional\"));\n\n  this->data_format = data_format;\n  depth = GetTensorDim(tensor_in_shape, data_format, 'C');\n  tensor_in_planes = GetTensorDim(tensor_in_shape, data_format, '0');\n  tensor_in_rows = GetTensorDim(tensor_in_shape, data_format, '1');\n  tensor_in_cols = GetTensorDim(tensor_in_shape, data_format, '2');\n  tensor_in_batch = GetTensorDim(tensor_in_shape, data_format, 'N');\n  window_planes = GetTensorDim(ksize, data_format, '0');\n  window_rows = GetTensorDim(ksize, data_format, '1');\n  window_cols = GetTensorDim(ksize, data_format, '2');\n  depth_window = GetTensorDim(ksize, data_format, 'C');\n  plane_stride = GetTensorDim(stride, data_format, '0');\n  row_stride = GetTensorDim(stride, data_format, '1');\n  col_stride = GetTensorDim(stride, data_format, '2');\n  depth_stride = GetTensorDim(stride, data_format, 'C');\n\n  // We only support 3D pooling across plane/width/height. Depthwise\n  // pooling is not supported.\n  OP_REQUIRES(\n      context, depth_window == 1 && depth_stride == 1,\n      errors::Unimplemented(\n          \"Pooling3d only supports pooling across plane/width/height.\"));\n\n  OP_REQUIRES_OK(context, GetWindowedOutputSize(tensor_in_planes, window_planes,\n                                                plane_stride, padding,\n                                                &out_plane, &pad_planes));\n  OP_REQUIRES_OK(context,\n                 GetWindowedOutputSize(tensor_in_rows, window_rows, row_stride,\n                                       padding, &out_height, &pad_rows));\n  OP_REQUIRES_OK(context,\n                 GetWindowedOutputSize(tensor_in_cols, window_cols, col_stride,\n                                       padding, &out_width, &pad_cols));\n}\n\nTensorShape Pool3dParameters::forward_output_shape() {\n  return ShapeFromFormat(data_format, tensor_in_batch,\n                         {{out_plane, out_height, out_width}}, depth);\n}\n\ntemplate <typename T>\nstruct LaunchPoolingOp<CPUDevice, T, AVG> {\n  static void launch(OpKernelContext* context, const Tensor& tensor_in,\n                     const std::array<int64, 3>& window,\n                     const std::array<int64, 3>& stride,\n                     const std::array<int64, 3>& padding,\n                     TensorFormat data_format, Padding padding_type,\n                     Tensor* output) {\n    output->tensor<T, 5>().device(context->eigen_device<CPUDevice>()) =\n        Eigen::CuboidAvgPooling(tensor_in.tensor<T, 5>(), window[0], window[1],\n                                window[2], stride[0], stride[1], stride[2],\n                                BrainPadding2EigenPadding(padding_type));\n  }\n};\n\ntemplate <typename T>\nstruct LaunchPoolingOp<CPUDevice, T, MAX> {\n  static void launch(OpKernelContext* context, const Tensor& tensor_in,\n                     const std::array<int64, 3>& window,\n                     const std::array<int64, 3>& stride,\n                     const std::array<int64, 3>& padding,\n                     TensorFormat data_format, Padding padding_type,\n                     Tensor* output) {\n    output->tensor<T, 5>().device(context->eigen_device<CPUDevice>()) =\n        Eigen::CuboidMaxPooling(tensor_in.tensor<T, 5>(), window[0], window[1],\n                                window[2], stride[0], stride[1], stride[2],\n                                BrainPadding2EigenPadding(padding_type));\n  }\n};\n\ntemplate <typename Device, typename T, PoolingType Type>\nclass Pooling3DOp : public UnaryOp<T> {\n public:\n  explicit Pooling3DOp(OpKernelConstruction* context) : UnaryOp<T>(context) {\n    string data_format;\n    OP_REQUIRES_OK(context, context->GetAttr(\"data_format\", &data_format));\n    OP_REQUIRES(context, FormatFromString(data_format, &data_format_),\n                errors::InvalidArgument(\"Invalid data format\"));\n    if (context->device_type() == DEVICE_CPU) {\n      OP_REQUIRES(\n          context, data_format_ == FORMAT_NHWC,\n          errors::InvalidArgument(\"Default Pooling3DOp only supports NDHWC \",\n                                  \"on device type \",\n                                  DeviceTypeString(context->device_type())));\n    }\n    OP_REQUIRES_OK(context, context->GetAttr(\"ksize\", &ksize_));\n    OP_REQUIRES(context, ksize_.size() == 5,\n                errors::InvalidArgument(\"Sliding window ksize field must \"\n                                        \"specify 5 dimensions\"));\n    bool non_negative =\n        std::all_of(ksize_.begin(), ksize_.end(), [](int k) { return k > 0; });\n    OP_REQUIRES(context, non_negative,\n                errors::InvalidArgument(\"Sliding window ksize field must \"\n                                        \"have non-negative dimensions\"));\n    OP_REQUIRES_OK(context, context->GetAttr(\"strides\", &stride_));\n    OP_REQUIRES(context, stride_.size() == 5,\n                errors::InvalidArgument(\"Sliding window stride field must \"\n                                        \"specify 5 dimensions\"));\n    OP_REQUIRES_OK(context, context->GetAttr(\"padding\", &padding_));\n    OP_REQUIRES(context,\n                (GetTensorDim(ksize_, data_format_, 'N') == 1 &&\n                 GetTensorDim(stride_, data_format_, 'N') == 1),\n                errors::Unimplemented(\n                    \"Pooling is not yet supported on the batch dimension.\"));\n    OP_REQUIRES(context,\n                (GetTensorDim(ksize_, data_format_, 'C') == 1 &&\n                 GetTensorDim(stride_, data_format_, 'C') == 1),\n                errors::Unimplemented(\n                    \"Pooling is not yet supported on the depth dimension.\"));\n  }\n\n  void Compute(OpKernelContext* context) override {\n    const Tensor& tensor_in = context->input(0);\n\n    OP_REQUIRES(context, tensor_in.dims() == 5,\n                errors::InvalidArgument(\"tensor_in must be 5-dimensional\"));\n    const int64_t depth = GetTensorDim(tensor_in, data_format_, 'C');\n    const int64_t in_batch = GetTensorDim(tensor_in, data_format_, 'N');\n\n    // Dimension order for these arrays is: x, y, z.\n    std::array<int64_t, 3> input_size{\n        {GetTensorDim(tensor_in, data_format_, '2'),\n         GetTensorDim(tensor_in, data_format_, '1'),\n         GetTensorDim(tensor_in, data_format_, '0')}};\n    std::array<int64_t, 3> window{{GetTensorDim(ksize_, data_format_, '2'),\n                                   GetTensorDim(ksize_, data_format_, '1'),\n                                   GetTensorDim(ksize_, data_format_, '0')}};\n    std::array<int64_t, 3> stride{{GetTensorDim(stride_, data_format_, '2'),\n                                   GetTensorDim(stride_, data_format_, '1'),\n                                   GetTensorDim(stride_, data_format_, '0')}};\n    std::array<int64_t, 3> padding, out;\n\n    OP_REQUIRES_OK(context, Get3dOutputSize(input_size, window, stride,\n                                            padding_, &out, &padding));\n\n    TensorShape out_shape = ShapeFromFormat(data_format_, in_batch,\n                                            {{out[2], out[1], out[0]}}, depth);\n    Tensor* output;\n    OP_REQUIRES_OK(context, context->allocate_output(0, out_shape, &output));\n    if (out_shape.num_elements() == 0) return;\n    LaunchPoolingOp<Device, T, Type>::launch(context, tensor_in, window, stride,\n                                             padding, data_format_, padding_,\n                                             output);\n  }\n\n private:\n  std::vector<int32> ksize_;\n  std::vector<int32> stride_;\n  Padding padding_;\n  TensorFormat data_format_;\n};\n\ntemplate <typename T>\nstruct LaunchMaxPooling3dGradOp<CPUDevice, T> {\n  static void launch(OpKernelContext* context, const Tensor& tensor_in,\n                     const Tensor& tensor_out, const Tensor& out_backprop,\n                     const std::array<int64, 3>& window,\n                     const std::array<int64, 3>& stride,\n                     const std::array<int64, 3>& out,\n                     const std::array<int64, 3>& padding,\n                     TensorFormat data_format, Tensor* output) {\n    output->flat<T>().setZero();\n    for (int64_t p = 0; p < out_backprop.dim_size(3); ++p) {\n      // Calculate broadcast size for planes/rows/cols. For SAME padding,\n      // current index could be in the padding area, and\n      //   p * stride_planes + window_planes\n      // could be beyond the input tensor's boundary. In such cases, change\n      // the starting index and reduce the broadcast size.\n      //\n      // The same procedure is repeated for every spatial dimension in the\n      // nested loops below.\n      int pindex, psize;\n      std::array<int64_t, 3> input_size{{tensor_in.dim_size(3),\n                                         tensor_in.dim_size(2),\n                                         tensor_in.dim_size(1)}};\n      OP_REQUIRES_OK(context,\n                     GetBroadcastSize(p, input_size[0], window[0], stride[0],\n                                      padding[0], &pindex, &psize));\n      for (int64_t r = 0; r < out_backprop.dim_size(2); ++r) {\n        int rindex, rsize;\n        OP_REQUIRES_OK(context,\n                       GetBroadcastSize(r, input_size[1], window[1], stride[1],\n                                        padding[1], &rindex, &rsize));\n        for (int64_t c = 0; c < out_backprop.dim_size(1); ++c) {\n          int cindex, csize;\n          OP_REQUIRES_OK(\n              context, GetBroadcastSize(c, input_size[2], window[2], stride[2],\n                                        padding[2], &cindex, &csize));\n          TensorSlice src{{0, -1}, {c, 1}, {r, 1}, {p, 1}, {0, -1}};\n          TensorSlice dst{{0, -1},\n                          {cindex, csize},\n                          {rindex, rsize},\n                          {pindex, psize},\n                          {0, -1}};\n          Eigen::DSizes<Eigen::DenseIndex, 5> src_indices;\n          Eigen::DSizes<Eigen::DenseIndex, 5> src_sizes;\n          Eigen::DSizes<Eigen::DenseIndex, 5> dst_indices;\n          Eigen::DSizes<Eigen::DenseIndex, 5> dst_sizes;\n          src.FillIndicesAndSizes<5>(out_backprop.shape(), &src_indices,\n                                     &src_sizes);\n          dst.FillIndicesAndSizes<5>(tensor_in.shape(), &dst_indices,\n                                     &dst_sizes);\n\n          Eigen::IndexList<Eigen::type2index<1>, int, int, int,\n                           Eigen::type2index<1>>\n              bcast;\n          bcast.set(1, csize);\n          bcast.set(2, rsize);\n          bcast.set(3, psize);\n\n          // Slice from tensor_in.\n          Eigen::Tensor<T, 5, Eigen::RowMajor> tensor_in_slice(dst_sizes);\n          tensor_in_slice.device(context->eigen_cpu_device()) =\n              tensor_in.tensor<T, 5>().slice(dst_indices, dst_sizes);\n\n          // Slice from tensor_out.\n          Eigen::Tensor<T, 5, Eigen::RowMajor> tensor_out_slice(src_sizes);\n          tensor_out_slice.device(context->eigen_cpu_device()) =\n              tensor_out.tensor<T, 5>().slice(src_indices, src_sizes);\n\n          // Backprop slice.\n          Eigen::Tensor<T, 5, Eigen::RowMajor> out_backprop_slice(src_sizes);\n          out_backprop_slice.device(context->eigen_cpu_device()) =\n              out_backprop.tensor<T, 5>().slice(src_indices, src_sizes);\n\n          // The true backprop slice: if an element is the max, choose\n          // the backprop slice; otherwise set to 0.\n          Eigen::Tensor<T, 5, Eigen::RowMajor> select_slice(dst_sizes);\n          Eigen::Tensor<T, 5, Eigen::RowMajor> mat0(dst_sizes);\n          mat0.setZero();\n          select_slice =\n              ((tensor_in_slice - tensor_out_slice.broadcast(bcast)).abs() <\n               tensor_in_slice.constant(1e-5))\n                  .select(out_backprop_slice.broadcast(bcast), mat0);\n\n          output->tensor<T, 5>()\n              .slice(dst_indices, dst_sizes)\n              .device(context->eigen_cpu_device()) += select_slice;\n        }\n      }\n    }\n  }\n};\n\ntemplate <class Device, class T>\nclass MaxPooling3dGradOp : public OpKernel {\n public:\n  explicit MaxPooling3dGradOp(OpKernelConstruction* context)\n      : OpKernel(context) {\n    string data_format;\n    OP_REQUIRES_OK(context, context->GetAttr(\"data_format\", &data_format));\n    OP_REQUIRES(context, FormatFromString(data_format, &data_format_),\n                errors::InvalidArgument(\"Invalid data format\"));\n    if (context->device_type() == DEVICE_CPU) {\n      OP_REQUIRES(\n          context, data_format_ == FORMAT_NHWC,\n          errors::InvalidArgument(\n              \"Default MaxPooling3dGradOp only supports NDHWC \",\n              \"on device type \", DeviceTypeString(context->device_type())));\n    }\n    OP_REQUIRES_OK(context, context->GetAttr(\"ksize\", &ksize_));\n    OP_REQUIRES(context, ksize_.size() == 5,\n                errors::InvalidArgument(\"Sliding window ksize field must \"\n                                        \"specify 5 dimensions\"));\n    OP_REQUIRES_OK(context, context->GetAttr(\"strides\", &stride_));\n    OP_REQUIRES(context, stride_.size() == 5,\n                errors::InvalidArgument(\"Sliding window stride field must \"\n                                        \"specify 5 dimensions\"));\n    OP_REQUIRES_OK(context, context->GetAttr(\"padding\", &padding_));\n    OP_REQUIRES(context,\n                (GetTensorDim(ksize_, data_format_, 'N') == 1 &&\n                 GetTensorDim(stride_, data_format_, 'N') == 1),\n                errors::Unimplemented(\n                    \"Pooling is not yet supported on the batch dimension.\"));\n    OP_REQUIRES(context,\n                (GetTensorDim(ksize_, data_format_, 'C') == 1 &&\n                 GetTensorDim(stride_, data_format_, 'C') == 1),\n                errors::Unimplemented(\n                    \"Pooling is not yet supported on the depth dimension.\"));\n  }\n\n  void Compute(OpKernelContext* context) override {\n    const Tensor& tensor_in = context->input(0);\n    const Tensor& tensor_out = context->input(1);\n    const Tensor& out_backprop = context->input(2);\n    OP_REQUIRES(context, tensor_in.dims() == 5,\n                errors::InvalidArgument(\"tensor_in must be 5-dimensional\"));\n    OP_REQUIRES(context, tensor_out.dims() == 5,\n                errors::InvalidArgument(\"tensor_out must be 5-dimensional\"));\n    OP_REQUIRES(context, out_backprop.dims() == 5,\n                errors::InvalidArgument(\"out_backprop must be 5-dimensional\"));\n\n    const TensorShape& output_shape = tensor_in.shape();\n    Tensor* input_backprop;\n    OP_REQUIRES_OK(context,\n                   context->allocate_output(0, output_shape, &input_backprop));\n    std::array<int64_t, 3> input_size{\n        {GetTensorDim(output_shape, data_format_, '2'),\n         GetTensorDim(output_shape, data_format_, '1'),\n         GetTensorDim(output_shape, data_format_, '0')}};\n    std::array<int64_t, 3> window{{GetTensorDim(ksize_, data_format_, '2'),\n                                   GetTensorDim(ksize_, data_format_, '1'),\n                                   GetTensorDim(ksize_, data_format_, '0')}};\n    std::array<int64_t, 3> stride{{GetTensorDim(stride_, data_format_, '2'),\n                                   GetTensorDim(stride_, data_format_, '1'),\n                                   GetTensorDim(stride_, data_format_, '0')}};\n    std::array<int64_t, 3> out, padding;\n\n    OP_REQUIRES_OK(context, Get3dOutputSize(input_size, window, stride,\n                                            padding_, &out, &padding));\n\n    const int64_t depth = GetTensorDim(tensor_in, data_format_, 'C');\n    const int64_t in_batch = GetTensorDim(tensor_in, data_format_, 'N');\n    TensorShape out_shape = ShapeFromFormat(data_format_, in_batch,\n                                            {{out[2], out[1], out[0]}}, depth);\n    OP_REQUIRES(\n        context, tensor_out.shape() == out_shape,\n        errors::InvalidArgument(\"Expected orig_output shape to be \", out_shape,\n                                \", but got \", tensor_out.shape()));\n    OP_REQUIRES(context, out_backprop.shape() == out_shape,\n                errors::InvalidArgument(\"Expected grad shape to be \", out_shape,\n                                        \", but got \", out_backprop.shape()));\n\n    LaunchMaxPooling3dGradOp<Device, T>::launch(\n        context, tensor_in, tensor_out, out_backprop, window, stride, out,\n        padding, data_format_, input_backprop);\n  }\n\n private:\n  std::vector<int32> ksize_;\n  std::vector<int32> stride_;\n  Padding padding_;\n  TensorFormat data_format_;\n};\n\ntemplate <typename T>\nstruct LaunchAvgPooling3dGradOp<CPUDevice, T> {\n  static void launch(OpKernelContext* context,\n                     const TensorShape& tensor_in_shape,\n                     const Tensor& out_backprop,\n                     const std::array<int64, 3>& window,\n                     const std::array<int64, 3>& stride,\n                     const std::array<int64, 3>& output_shape,\n                     const std::array<int64, 3>& padding,\n                     TensorFormat data_format, Tensor* output) {\n    OP_REQUIRES(\n        context, tensor_in_shape.dim_size(0) == out_backprop.dim_size(0),\n        errors::InvalidArgument(\n            \"Expected first dimension of tensor_in_shape and \"\n            \"out_backprop to match, got \",\n            tensor_in_shape.dim_size(0), \" and \", out_backprop.dim_size(0)));\n    OP_REQUIRES(\n        context, tensor_in_shape.dim_size(4) == out_backprop.dim_size(4),\n        errors::InvalidArgument(\n            \"Expected last dimension of tensor_in_shape and \"\n            \"out_backprop to match, got \",\n            tensor_in_shape.dim_size(4), \" and \", out_backprop.dim_size(4)));\n\n    output->flat<T>().setZero();\n    std::array<int64_t, 3> input_size = {{tensor_in_shape.dim_size(3),\n                                          tensor_in_shape.dim_size(2),\n                                          tensor_in_shape.dim_size(1)}};\n    for (int64_t p = 0; p < out_backprop.dim_size(3); ++p) {\n      // Calculate broadcast size for planes/rows/cols. For SAME padding,\n      // current index could be in the padding area, and\n      //   p * stride_planes + window_planes\n      // could be beyond the input tensor's boundary. In such cases, change\n      // the starting index and reduce the broadcast size.\n      //\n      // The same procedure is repeated for every spatial dimension in the\n      // nested loops below.\n      int pindex, psize;\n      OP_REQUIRES_OK(context,\n                     GetBroadcastSize(p, input_size[0], window[0], stride[0],\n                                      padding[0], &pindex, &psize));\n      for (int64_t r = 0; r < out_backprop.dim_size(2); ++r) {\n        int rindex, rsize;\n        OP_REQUIRES_OK(context,\n                       GetBroadcastSize(r, input_size[1], window[1], stride[1],\n                                        padding[1], &rindex, &rsize));\n        for (int64_t c = 0; c < out_backprop.dim_size(1); ++c) {\n          int cindex, csize;\n          OP_REQUIRES_OK(\n              context, GetBroadcastSize(c, input_size[2], window[2], stride[2],\n                                        padding[2], &cindex, &csize));\n          TensorSlice src{{0, -1}, {c, 1}, {r, 1}, {p, 1}, {0, -1}};\n          TensorSlice dst{{0, -1},\n                          {cindex, csize},\n                          {rindex, rsize},\n                          {pindex, psize},\n                          {0, -1}};\n          Eigen::DSizes<Eigen::DenseIndex, 5> src_indices;\n          Eigen::DSizes<Eigen::DenseIndex, 5> src_sizes;\n          Eigen::DSizes<Eigen::DenseIndex, 5> dst_indices;\n          Eigen::DSizes<Eigen::DenseIndex, 5> dst_sizes;\n          src.FillIndicesAndSizes<5>(out_backprop.shape(), &src_indices,\n                                     &src_sizes);\n          dst.FillIndicesAndSizes<5>(tensor_in_shape, &dst_indices, &dst_sizes);\n          Eigen::IndexList<Eigen::type2index<1>, int, int, int,\n                           Eigen::type2index<1>>\n              bcast;\n          bcast.set(1, csize);\n          bcast.set(2, rsize);\n          bcast.set(3, psize);\n          Eigen::Tensor<T, 5, Eigen::RowMajor> slices(src_sizes);\n          slices.device(context->eigen_cpu_device()) =\n              out_backprop.tensor<T, 5>().slice(src_indices, src_sizes);\n          // Divide by the size of the actual patch (psize * rsize * csize).\n          float divide_size = rsize * csize * psize * 1.0f;\n          slices *= slices.constant(1.0f / divide_size);\n\n          output->tensor<T, 5>()\n              .slice(dst_indices, dst_sizes)\n              .device(context->eigen_cpu_device()) += slices.broadcast(bcast);\n        }\n      }\n    }\n  }\n};\n\ntemplate <class Device, class T>\nclass AvgPooling3dGradOp : public OpKernel {\n public:\n  explicit AvgPooling3dGradOp(OpKernelConstruction* context)\n      : OpKernel(context) {\n    string data_format;\n    OP_REQUIRES_OK(context, context->GetAttr(\"data_format\", &data_format));\n    OP_REQUIRES(context, FormatFromString(data_format, &data_format_),\n                errors::InvalidArgument(\"Invalid data format\"));\n    if (context->device_type() == DEVICE_CPU) {\n      OP_REQUIRES(\n          context, data_format_ == FORMAT_NHWC,\n          errors::InvalidArgument(\n              \"Default AvgPooling3dGradOp only supports NDHWC \",\n              \"on device type \", DeviceTypeString(context->device_type())));\n    }\n    OP_REQUIRES_OK(context, context->GetAttr(\"ksize\", &ksize_));\n    OP_REQUIRES(context, ksize_.size() == 5,\n                errors::InvalidArgument(\"Sliding window ksize field must \"\n                                        \"specify 5 dimensions\"));\n    OP_REQUIRES_OK(context, context->GetAttr(\"strides\", &stride_));\n    OP_REQUIRES(context, stride_.size() == 5,\n                errors::InvalidArgument(\"Sliding window stride field must \"\n                                        \"specify 5 dimensions\"));\n    OP_REQUIRES_OK(context, context->GetAttr(\"padding\", &padding_));\n    OP_REQUIRES(context,\n                (GetTensorDim(ksize_, data_format_, 'N') == 1 &&\n                 GetTensorDim(stride_, data_format_, 'N') == 1),\n                errors::Unimplemented(\n                    \"Pooling is not yet supported on the batch dimension.\"));\n    OP_REQUIRES(context,\n                (GetTensorDim(ksize_, data_format_, 'C') == 1 &&\n                 GetTensorDim(stride_, data_format_, 'C') == 1),\n                errors::Unimplemented(\n                    \"Pooling is not yet supported on the depth dimension.\"));\n  }\n\n  void Compute(OpKernelContext* context) override {\n    const Tensor& tensor_in_shape = context->input(0);\n    const Tensor& out_backprop = context->input(1);\n    OP_REQUIRES(\n        context,\n        tensor_in_shape.dims() == 1 && tensor_in_shape.NumElements() == 5,\n        errors::InvalidArgument(\"tensor_in must be 1-dimensional and 5 \"\n                                \"elements\"));\n    OP_REQUIRES(context, out_backprop.dims() == 5,\n                errors::InvalidArgument(\"out_backprop must be 5-dimensional\"));\n\n    TensorShape output_shape;\n    auto shape_vec = tensor_in_shape.vec<int32>();\n    for (int64_t i = 0; i < tensor_in_shape.NumElements(); ++i) {\n      OP_REQUIRES_OK(context, output_shape.AddDimWithStatus(shape_vec(i)));\n    }\n\n    Tensor* output;\n    OP_REQUIRES_OK(context, context->allocate_output(0, output_shape, &output));\n\n    // Dimension order for these arrays is x, y, z.\n    std::array<int64_t, 3> input_size{\n        {GetTensorDim(output_shape, data_format_, '2'),\n         GetTensorDim(output_shape, data_format_, '1'),\n         GetTensorDim(output_shape, data_format_, '0')}};\n    std::array<int64_t, 3> window{{GetTensorDim(ksize_, data_format_, '2'),\n                                   GetTensorDim(ksize_, data_format_, '1'),\n                                   GetTensorDim(ksize_, data_format_, '0')}};\n    std::array<int64_t, 3> stride{{GetTensorDim(stride_, data_format_, '2'),\n                                   GetTensorDim(stride_, data_format_, '1'),\n                                   GetTensorDim(stride_, data_format_, '0')}};\n    std::array<int64_t, 3> padding, out;\n\n    OP_REQUIRES_OK(context, Get3dOutputSize(input_size, window, stride,\n                                            padding_, &out, &padding));\n\n    LaunchAvgPooling3dGradOp<Device, T>::launch(\n        context, output_shape, out_backprop, window, stride, out, padding,\n        data_format_, output);\n  }\n\n private:\n  std::vector<int32> ksize_;\n  std::vector<int32> stride_;\n  Padding padding_;\n  TensorFormat data_format_;\n};\n\ntemplate <typename T>\nstruct LaunchMaxPooling3dGradGradOp<CPUDevice, T> {\n  static void launch(OpKernelContext* context, const Pool3dParameters& params,\n                     const Tensor& tensor_in, const Tensor& tensor_out,\n                     const Tensor& tensor_top_diff,\n                     Tensor* tensor_bottom_diff) {\n    OP_REQUIRES(\n        context, params.data_format == FORMAT_NHWC,\n        errors::InvalidArgument(\"Default MaxPooling3dGradGradOp only supports\",\n                                \"NDHWC on CPU device type\"));\n\n    typedef Eigen::Map<const Eigen::Matrix<T, Eigen::Dynamic, Eigen::Dynamic>>\n        ConstEigenMatrixMap;\n    typedef Eigen::Map<Eigen::Matrix<T, Eigen::Dynamic, Eigen::Dynamic>>\n        EigenMatrixMap;\n\n    ConstEigenMatrixMap in_mat(tensor_in.flat<T>().data(), params.depth,\n                               params.tensor_in_planes * params.tensor_in_cols *\n                                   params.tensor_in_rows *\n                                   params.tensor_in_batch);\n    ConstEigenMatrixMap out_mat(tensor_out.flat<T>().data(), params.depth,\n                                params.out_plane * params.out_width *\n                                    params.out_height * params.tensor_in_batch);\n    ConstEigenMatrixMap top_diff_mat(\n        tensor_top_diff.flat<T>().data(), params.depth,\n        params.tensor_in_planes * params.tensor_in_cols *\n            params.tensor_in_rows * params.tensor_in_batch);\n    EigenMatrixMap bottom_diff_mat(\n        tensor_bottom_diff->flat<T>().data(), params.depth,\n        params.out_plane * params.out_width * params.out_height *\n            params.tensor_in_batch);\n\n    const DeviceBase::CpuWorkerThreads& worker_threads =\n        *(context->device()->tensorflow_cpu_worker_threads());\n\n    auto shard = [&params, &in_mat, &out_mat, &top_diff_mat, &bottom_diff_mat](\n                     int64_t start, int64_t limit) {\n      const int32_t depth = params.depth;\n      const int32_t in_planes = params.tensor_in_planes;\n      const int32_t in_rows = params.tensor_in_rows;\n      const int32_t in_cols = params.tensor_in_cols;\n      const int32_t pad_planes = params.pad_planes;\n      const int32_t pad_rows = params.pad_rows;\n      const int32_t pad_cols = params.pad_cols;\n      const int32_t window_planes = params.window_planes;\n      const int32_t window_rows = params.window_rows;\n      const int32_t window_cols = params.window_cols;\n      const int32_t plane_stride = params.plane_stride;\n      const int32_t row_stride = params.row_stride;\n      const int32_t col_stride = params.col_stride;\n      const int32_t out_plane = params.out_plane;\n      const int32_t out_height = params.out_height;\n      const int32_t out_width = params.out_width;\n\n      {\n        // Initializes the output grad backprop tensor with 0.\n        const int32_t output_image_size =\n            out_plane * out_height * out_width * params.depth;\n        EigenMatrixMap bottom_diff_shard(\n            bottom_diff_mat.data() + start * output_image_size, 1,\n            (limit - start) * output_image_size);\n        bottom_diff_shard.setZero();\n      }\n\n      for (int b = start; b < limit; ++b) {\n        for (int pp = 0; pp < out_plane; ++pp) {\n          for (int ph = 0; ph < out_height; ++ph) {\n            for (int pw = 0; pw < out_width; ++pw) {\n              // (p_start, p_end) * (h_start, h_end) * (w_start, w_end) is the\n              // range that the input vector projects to.\n              int p_start = pp * plane_stride - pad_planes;\n              const int p_end = std::min(p_start + window_planes, in_planes);\n              int h_start = ph * row_stride - pad_rows;\n              const int h_end = std::min(h_start + window_rows, in_rows);\n              int w_start = pw * col_stride - pad_cols;\n              const int w_end = std::min(w_start + window_cols, in_cols);\n              p_start = std::max(p_start, 0);\n              h_start = std::max(h_start, 0);\n              w_start = std::max(w_start, 0);\n              const int out_index =\n                  ((b * out_plane + pp) * out_height + ph) * out_width + pw;\n              // Find value corresponding to the input maximum in top_diff.\n              for (int d = 0; d < depth; ++d) {\n                const T& output_ref = out_mat.coeffRef(d, out_index);\n                bool should_stop = false;\n                for (int p = p_start; p < p_end && !should_stop; ++p) {\n                  for (int h = h_start; h < h_end && !should_stop; ++h) {\n                    for (int w = w_start; w < w_end && !should_stop; ++w) {\n                      const int in_index =\n                          ((b * in_planes + p) * in_rows + h) * in_cols + w;\n                      const T& input_ref = in_mat.coeffRef(d, in_index);\n                      if (output_ref == input_ref) {\n                        T& bottom_diff_ref =\n                            bottom_diff_mat.coeffRef(d, out_index);\n                        bottom_diff_ref = top_diff_mat.coeffRef(d, in_index);\n                        should_stop = true;\n                      }\n                    }\n                  }\n                }\n              }\n            }\n          }\n        }\n      }\n    };\n    const int64_t shard_cost =\n        params.out_plane * params.out_height * params.out_width * params.depth *\n        params.window_planes * params.window_rows * params.window_cols;\n    Shard(worker_threads.num_threads, worker_threads.workers,\n          params.tensor_in_batch, shard_cost, shard);\n  }\n};\n\ntemplate <class Device, class T>\nclass MaxPooling3dGradGradOp : public OpKernel {\n public:\n  explicit MaxPooling3dGradGradOp(OpKernelConstruction* context)\n      : OpKernel(context) {\n    string data_format;\n    OP_REQUIRES_OK(context, context->GetAttr(\"data_format\", &data_format));\n    OP_REQUIRES(context, FormatFromString(data_format, &data_format_),\n                errors::InvalidArgument(\"Invalid data format\"));\n    OP_REQUIRES_OK(context, context->GetAttr(\"ksize\", &ksize_));\n    OP_REQUIRES(context, ksize_.size() == 5,\n                errors::InvalidArgument(\"Sliding window ksize field must \"\n                                        \"specify 5 dimensions\"));\n    OP_REQUIRES_OK(context, context->GetAttr(\"strides\", &stride_));\n    OP_REQUIRES(context, stride_.size() == 5,\n                errors::InvalidArgument(\"Sliding window strides field must \"\n                                        \"specify 5 dimensions\"));\n    OP_REQUIRES_OK(context, context->GetAttr(\"padding\", &padding_));\n    OP_REQUIRES(context, ksize_[0] == 1 && stride_[0] == 1,\n                errors::Unimplemented(\n                    \"Pooling is not yet supported on the batch dimension.\"));\n    const int32_t ksize_c = GetTensorDim(ksize_, data_format_, 'C');\n    const int32_t stride_c = GetTensorDim(stride_, data_format_, 'C');\n    OP_REQUIRES(context, ksize_c == 1 && stride_c == 1,\n                errors::Unimplemented(\"MaxPooling3dGradGrad is not yet \"\n                                      \"supported on the depth dimension.\"));\n  }\n\n  void Compute(OpKernelContext* context) override {\n    const Tensor& tensor_in = context->input(0);\n    const Tensor& tensor_out = context->input(1);\n    const Tensor& out_grad_backprop = context->input(2);\n\n    // For maxpooling3d, tensor_in should have 5 dimensions.\n    OP_REQUIRES(context, tensor_in.dims() == 5,\n                errors::InvalidArgument(\"tensor_in must be 5-dimensional\"));\n    OP_REQUIRES(context, tensor_out.dims() == 5,\n                errors::InvalidArgument(\"tensor_out must be 5-dimensional\"));\n    // For maxpooling3d, out_grad_backprop should have 5 dimensions.\n    OP_REQUIRES(\n        context, out_grad_backprop.dims() == 5,\n        errors::InvalidArgument(\"out_grad_backprop must be 5-dimensional\"));\n\n    Pool3dParameters params{context,  ksize_,       stride_,\n                            padding_, data_format_, tensor_in.shape()};\n    if (!context->status().ok()) return;  // params is invalid\n    OP_REQUIRES(context, tensor_out.shape() == params.forward_output_shape(),\n                errors::InvalidArgument(\"Expected orig_output shape to be \",\n                                        params.forward_output_shape(),\n                                        \", but got \", tensor_out.shape()));\n    OP_REQUIRES(\n        context, out_grad_backprop.shape() == tensor_in.shape(),\n        errors::InvalidArgument(\"Expected grad shape to be \", tensor_in.shape(),\n                                \", but got \", out_grad_backprop.shape()));\n\n    Tensor* output = nullptr;\n    OP_REQUIRES_OK(context, context->forward_input_or_allocate_output(\n                                {2}, 0, tensor_out.shape(), &output));\n\n    // Given access patterns in LaunchMaxPooling3dGradGradOp, these tensors must\n    // have elements.\n    OP_REQUIRES(context, tensor_in.NumElements() > 0,\n                errors::InvalidArgument(\"received empty tensor tensor_in: \",\n                                        tensor_in.DebugString()));\n    OP_REQUIRES(context, tensor_out.NumElements() > 0,\n                errors::InvalidArgument(\"received empty tensor tensor_out: \",\n                                        tensor_out.DebugString()));\n    OP_REQUIRES(\n        context, out_grad_backprop.NumElements() > 0,\n        errors::InvalidArgument(\"received empty tensor out_grad_backprop: \",\n                                out_grad_backprop.DebugString()));\n    OP_REQUIRES(context,\n                tensor_in.NumElements() == out_grad_backprop.NumElements(),\n                errors::InvalidArgument(\"tensor_in and out_grad_backprop must \"\n                                        \"have same number of elements, got <\",\n                                        tensor_in.DebugString(), \"> and <\",\n                                        out_grad_backprop.DebugString(), \">\"));\n    OP_REQUIRES(\n        context, tensor_out.NumElements() == output->NumElements(),\n        errors::InvalidArgument(\n            \"tensor_out and output must have same number of elements, got <\",\n            tensor_out.DebugString(), \"> and <\", output->DebugString(), \">\"));\n\n    LaunchMaxPooling3dGradGradOp<Device, T>::launch(\n        context, params, tensor_in, tensor_out, out_grad_backprop, output);\n  }\n\n private:\n  std::vector<int32> ksize_;\n  std::vector<int32> stride_;\n  Padding padding_;\n  TensorFormat data_format_;\n};\n\n#define REGISTER_KERNELS(D, T)                                             \\\n  REGISTER_KERNEL_BUILDER(                                                 \\\n      Name(\"MaxPool3D\").Device(DEVICE_##D).TypeConstraint<T>(\"T\"),         \\\n      Pooling3DOp<D##Device, T, MAX>);                                     \\\n  REGISTER_KERNEL_BUILDER(Name(\"MaxPool3DGrad\")                            \\\n                              .Device(DEVICE_##D)                          \\\n                              .TypeConstraint<T>(\"T\")                      \\\n                              .TypeConstraint<T>(\"TInput\"),                \\\n                          MaxPooling3dGradOp<D##Device, T>);               \\\n  REGISTER_KERNEL_BUILDER(                                                 \\\n      Name(\"MaxPool3DGradGrad\").Device(DEVICE_##D).TypeConstraint<T>(\"T\"), \\\n      MaxPooling3dGradGradOp<D##Device, T>);                               \\\n  REGISTER_KERNEL_BUILDER(                                                 \\\n      Name(\"AvgPool3D\").Device(DEVICE_##D).TypeConstraint<T>(\"T\"),         \\\n      Pooling3DOp<D##Device, T, AVG>);                                     \\\n  REGISTER_KERNEL_BUILDER(Name(\"AvgPool3DGrad\")                            \\\n                              .Device(DEVICE_##D)                          \\\n                              .TypeConstraint<T>(\"T\")                      \\\n                              .HostMemory(\"orig_input_shape\"),             \\\n                          AvgPooling3dGradOp<D##Device, T>);\n\n#define REGISTER_CPU_KERNELS(T) REGISTER_KERNELS(CPU, T)\nTF_CALL_float(REGISTER_CPU_KERNELS);\n#undef REGISTER_CPU_KERNELS\n\n#if GOOGLE_CUDA || TENSORFLOW_USE_ROCM\n\ntemplate <typename T>\nstruct LaunchPoolingOp<GPUDevice, T, AVG> {\n  static void launch(OpKernelContext* context, const Tensor& tensor_in,\n                     const std::array<int64, 3>& window,\n                     const std::array<int64, 3>& stride,\n                     const std::array<int64, 3>& padding,\n                     TensorFormat data_format, Padding padding_type,\n                     Tensor* output) {\n    DnnPooling3dOp<T>::Compute(context, se::dnn::PoolingMode::kAverage, window,\n                               stride, padding, data_format, tensor_in, output);\n  }\n};\n\ntemplate <typename T>\nstruct LaunchPoolingOp<GPUDevice, T, MAX> {\n  static void launch(OpKernelContext* context, const Tensor& tensor_in,\n                     const std::array<int64, 3>& window,\n                     const std::array<int64, 3>& stride,\n                     const std::array<int64, 3>& padding,\n                     TensorFormat data_format, Padding padding_type,\n                     Tensor* output) {\n    DnnPooling3dOp<T>::Compute(context, se::dnn::PoolingMode::kMaximum, window,\n                               stride, padding, data_format, tensor_in, output);\n  }\n};\n\ntemplate <typename T>\nstruct LaunchMaxPooling3dGradOp<GPUDevice, T> {\n  static void launch(OpKernelContext* context, const Tensor& tensor_in,\n                     const Tensor& tensor_out, const Tensor& out_backprop,\n                     const std::array<int64, 3>& window,\n                     const std::array<int64, 3>& stride,\n                     const std::array<int64, 3>& out,\n                     const std::array<int64, 3>& padding,\n                     TensorFormat data_format, Tensor* input_backprop) {\n    const TensorShape output_shape = tensor_in.shape();\n    DnnPooling3dGradOp<T>::Compute(context, se::dnn::PoolingMode::kMaximum,\n                                   window, stride, padding, out, data_format,\n                                   out_backprop, output_shape, &tensor_in,\n                                   &tensor_out, input_backprop);\n  }\n};\n\ntemplate <typename T>\nstruct LaunchAvgPooling3dGradOp<GPUDevice, T> {\n  static void launch(OpKernelContext* context,\n                     const TensorShape& tensor_in_shape,\n                     const Tensor& out_backprop,\n                     const std::array<int64, 3>& window,\n                     const std::array<int64, 3>& stride,\n                     const std::array<int64, 3>& out,\n                     const std::array<int64, 3>& padding,\n                     TensorFormat data_format, Tensor* output) {\n    DnnPooling3dGradOp<T>::Compute(\n        context, se::dnn::PoolingMode::kAverage, window, stride, padding, out,\n        data_format, out_backprop, tensor_in_shape, nullptr, nullptr, output);\n  }\n};\n\ntemplate <typename T>\nstruct LaunchMaxPooling3dGradGradOp<GPUDevice, T> {\n  static void launch(OpKernelContext* context, const Pool3dParameters& params,\n                     const Tensor& tensor_in, const Tensor& tensor_out,\n                     const Tensor& tensor_top_diff,\n                     Tensor* tensor_bottom_diff) {\n    bool status = functor::MaxPool3dGradBackward<T>()(\n        params.data_format, tensor_in.flat<T>().data(),\n        tensor_out.flat<T>().data(), params.tensor_in_batch, params.out_plane,\n        params.out_height, params.out_width, params.depth,\n        params.tensor_in_planes, params.tensor_in_rows, params.tensor_in_cols,\n        params.window_planes, params.window_rows, params.window_cols,\n        params.plane_stride, params.row_stride, params.col_stride,\n        params.pad_planes, params.pad_rows, params.pad_cols,\n        tensor_top_diff.flat<T>().data(), tensor_bottom_diff->flat<T>().data(),\n        context->eigen_gpu_device());\n    if (!status) {\n      context->SetStatus(\n          errors::Internal(\"Failed launching MaxPool3dGradBackward\"));\n    }\n  }\n};\n\n#define REGISTER_GPU_KERNELS(T) REGISTER_KERNELS(GPU, T)\nTF_CALL_float(REGISTER_GPU_KERNELS) TF_CALL_half(REGISTER_GPU_KERNELS)\n#undef REGISTER_GPU_KERNELS\n\n#endif  // GOOGLE_CUDA || TENSORFLOW_USE_ROCM\n\n\n#undef REGISTER_KERNELS\n\n}  // namespace tensorflow\n", "# Tests of TensorFlow NN kernels written using the Python API.\n\nload(\"//tensorflow:tensorflow.bzl\", \"cuda_py_test\")\n\n# buildifier: disable=same-origin-load\nload(\"//tensorflow:tensorflow.bzl\", \"tf_py_test\")\n\npackage(\n    default_visibility = [\"//tensorflow:internal\"],\n    licenses = [\"notice\"],\n)\n\nCONV_TEST_BASENAMES = [\n    \":atrous_conv2d_test\",\n    \":conv1d_test\",\n    \":conv1d_transpose_test\",\n    \":conv2d_backprop_filter_grad_test\",\n    \":conv3d_transpose_test\",\n    \":conv3d_backprop_filter_v2_grad_test\",\n    \":conv_ops_3d_test\",\n    \":conv_ops_test\",\n    \":depthwise_conv_op_test\",\n    \":conv2d_transpose_test\",\n]\n\ntest_suite(\n    name = \"conv_tests\",\n    tests = [basename for basename in CONV_TEST_BASENAMES] +\n            [basename + \"_gpu\" for basename in CONV_TEST_BASENAMES],\n)\n\ncuda_py_test(\n    name = \"atrous_conv2d_test\",\n    size = \"medium\",\n    srcs = [\"atrous_conv2d_test.py\"],\n    shard_count = 2,\n    tags = [\n        \"no_gpu\",  #  Flaky: b/80127739, b/127001953\n    ],\n    deps = [\n        \"//tensorflow/python:array_ops\",\n        \"//tensorflow/python:client_testlib\",\n        \"//tensorflow/python:framework_for_generated_wrappers\",\n        \"//tensorflow/python:nn\",\n        \"//tensorflow/python:nn_grad\",\n        \"//tensorflow/python:nn_ops\",\n        \"//third_party/py/numpy\",\n    ],\n)\n\ncuda_py_test(\n    name = \"atrous_convolution_test\",\n    size = \"medium\",\n    srcs = [\"atrous_convolution_test.py\"],\n    tags = [\n        \"manual\",\n        \"no_cuda_asan\",\n    ],\n    deps = [\n        \"//tensorflow/python:array_ops\",\n        \"//tensorflow/python:client_testlib\",\n        \"//tensorflow/python:framework_for_generated_wrappers\",\n        \"//tensorflow/python:nn_grad\",\n        \"//tensorflow/python:nn_ops\",\n        \"//third_party/py/numpy\",\n    ],\n)\n\ncuda_py_test(\n    name = \"betainc_op_test\",\n    size = \"small\",\n    srcs = [\"betainc_op_test.py\"],\n    xla_tags = [\n        \"no_cuda_asan\",  # times out\n    ],\n    deps = [\n        \"//tensorflow/python:array_ops\",\n        \"//tensorflow/python:client_testlib\",\n        \"//tensorflow/python:framework_for_generated_wrappers\",\n        \"//tensorflow/python:math_ops\",\n        \"//tensorflow/python:platform\",\n        \"//third_party/py/numpy\",\n    ],\n)\n\npy_library(\n    name = \"bias_op_base\",\n    srcs = [\"bias_op_base.py\"],\n    srcs_version = \"PY3\",\n    deps = [\n        \"//tensorflow/python:array_ops\",\n        \"//tensorflow/python:client_testlib\",\n        \"//tensorflow/python:framework_for_generated_wrappers\",\n        \"//tensorflow/python:gradients\",\n        \"//tensorflow/python:nn_grad\",\n        \"//tensorflow/python:nn_ops\",\n        \"//third_party/py/numpy\",\n    ],\n)\n\ncuda_py_test(\n    name = \"bias_op_d9m_test\",\n    size = \"medium\",\n    srcs = [\"bias_op_d9m_test.py\"],\n    shard_count = 2,\n    deps = [\n        \":bias_op_base\",\n    ],\n)\n\ncuda_py_test(\n    name = \"bias_op_test\",\n    size = \"medium\",\n    srcs = [\"bias_op_test.py\"],\n    deps = [\n        \":bias_op_base\",\n    ],\n)\n\ncuda_py_test(\n    name = \"conv1d_test\",\n    size = \"small\",\n    srcs = [\"conv1d_test.py\"],\n    deps = [\n        \"//tensorflow/python:array_ops\",\n        \"//tensorflow/python:client_testlib\",\n        \"//tensorflow/python:framework_for_generated_wrappers\",\n        \"//tensorflow/python:nn_ops\",\n    ],\n)\n\ncuda_py_test(\n    name = \"conv1d_transpose_test\",\n    size = \"small\",\n    srcs = [\"conv1d_transpose_test.py\"],\n    deps = [\n        \"//tensorflow/python:client\",\n        \"//tensorflow/python:client_testlib\",\n        \"//tensorflow/python:framework_for_generated_wrappers\",\n        \"//tensorflow/python:nn_ops\",\n        \"//third_party/py/numpy\",\n    ],\n)\n\ncuda_py_test(\n    name = \"conv2d_backprop_filter_grad_test\",\n    size = \"medium\",\n    srcs = [\"conv2d_backprop_filter_grad_test.py\"],\n    shard_count = 2,\n    tags = [\n        \"optonly\",  # flaky timeouts unless optimized\n    ],\n    deps = [\n        \"//tensorflow/python:array_ops\",\n        \"//tensorflow/python:client_testlib\",\n        \"//tensorflow/python:framework_for_generated_wrappers\",\n        \"//tensorflow/python:nn_grad\",\n        \"//tensorflow/python:nn_ops\",\n        \"//third_party/py/numpy\",\n    ],\n)\n\ncuda_py_test(\n    name = \"conv2d_transpose_test\",\n    size = \"small\",\n    srcs = [\"conv2d_transpose_test.py\"],\n\n    # TODO(b/144432983): S32 convolutions should not be auto-clustered, only\n    # crashes tests.\n    xla_enable_strict_auto_jit = False,\n    deps = [\n        \"//tensorflow/python:client\",\n        \"//tensorflow/python:client_testlib\",\n        \"//tensorflow/python:framework_for_generated_wrappers\",\n        \"//tensorflow/python:nn_grad\",\n        \"//tensorflow/python:nn_ops\",\n        \"//third_party/py/numpy\",\n    ],\n)\n\ncuda_py_test(\n    name = \"conv3d_backprop_filter_v2_grad_test\",\n    size = \"small\",\n    srcs = [\"conv3d_backprop_filter_v2_grad_test.py\"],\n    deps = [\n        \"//tensorflow/python:array_ops\",\n        \"//tensorflow/python:client_testlib\",\n        \"//tensorflow/python:framework_for_generated_wrappers\",\n        \"//tensorflow/python:nn_grad\",\n        \"//tensorflow/python:nn_ops\",\n        \"//third_party/py/numpy\",\n    ],\n)\n\ncuda_py_test(\n    name = \"conv3d_transpose_test\",\n    size = \"medium\",\n    srcs = [\"conv3d_transpose_test.py\"],\n    deps = [\n        \"//tensorflow/python:client_testlib\",\n        \"//tensorflow/python:framework_for_generated_wrappers\",\n        \"//tensorflow/python:nn_grad\",\n        \"//tensorflow/python:nn_ops\",\n        \"//third_party/py/numpy\",\n    ],\n)\n\ncuda_py_test(\n    name = \"conv_ops_3d_test\",\n    size = \"medium\",\n    srcs = [\"conv_ops_3d_test.py\"],\n    shard_count = 30,\n    tags = [\"no_cuda11\"],\n    deps = [\n        \"//tensorflow/python:client_testlib\",\n        \"//tensorflow/python:framework_for_generated_wrappers\",\n        \"//tensorflow/python:nn_grad\",\n        \"//tensorflow/python:nn_ops\",\n    ],\n)\n\ncuda_py_test(\n    name = \"conv_ops_test\",\n    size = \"medium\",\n    srcs = [\"conv_ops_test.py\"],\n    shard_count = 4,\n    tags = [\n        \"optonly\",  # times out\n    ],\n    deps = [\n        \"//tensorflow/python:array_ops\",\n        \"//tensorflow/python:client\",\n        \"//tensorflow/python:client_testlib\",\n        \"//tensorflow/python:errors\",\n        \"//tensorflow/python:framework_for_generated_wrappers\",\n        \"//tensorflow/python:framework_test_lib\",\n        \"//tensorflow/python:nn\",\n        \"//tensorflow/python:nn_grad\",\n        \"//tensorflow/python:nn_ops\",\n        \"//tensorflow/python:platform\",\n        \"//tensorflow/python:random_ops\",\n        \"//tensorflow/python:variables\",\n        \"//third_party/py/numpy\",\n    ],\n)\n\ntf_py_test(\n    name = \"ctc_decoder_ops_test\",\n    size = \"small\",\n    srcs = [\"ctc_decoder_ops_test.py\"],\n    deps = [\n        \"//tensorflow/python:array_ops\",\n        \"//tensorflow/python:client_testlib\",\n        \"//tensorflow/python:ctc_ops\",\n        \"//tensorflow/python:framework_for_generated_wrappers\",\n        \"//third_party/py/numpy\",\n    ],\n)\n\ncuda_py_test(\n    name = \"ctc_loss_op_test\",\n    size = \"medium\",\n    srcs = [\"ctc_loss_op_test.py\"],\n    xla_enable_strict_auto_jit = False,  # b/148153828\n    deps = [\n        \"//tensorflow/python:client_testlib\",\n        \"//tensorflow/python:ctc_ops\",\n        \"//tensorflow/python:framework\",\n        \"//tensorflow/python:framework_for_generated_wrappers\",\n        \"//tensorflow/python:gradients\",\n        \"//third_party/py/numpy\",\n    ],\n)\n\npy_library(\n    name = \"cudnn_deterministic_base\",\n    srcs = [\"cudnn_deterministic_base.py\"],\n    srcs_version = \"PY3\",\n    deps = [\n        \"//tensorflow/python:client_testlib\",\n        \"//tensorflow/python:constant_op\",\n        \"//tensorflow/python:dtypes\",\n        \"//tensorflow/python:nn_ops\",\n        \"//tensorflow/python/eager:backprop\",\n        \"//third_party/py/numpy\",\n    ],\n)\n\ncuda_py_test(\n    name = \"cudnn_deterministic_ops_test\",\n    size = \"small\",\n    srcs = [\"cudnn_deterministic_ops_test.py\"],\n    tags = [\n        \"no_cuda_asan\",  # TODO(b/171509035): re-enable.\n    ],\n    xla_enable_strict_auto_jit = True,\n    deps = [\n        \":cudnn_deterministic_base\",\n    ],\n)\n\ncuda_py_test(\n    name = \"cudnn_d9m_test\",\n    size = \"small\",\n    srcs = [\"cudnn_d9m_test.py\"],\n    tags = [\n        \"no_cuda_asan\",  # TODO(b/171509035): re-enable.\n    ],\n    deps = [\n        \":cudnn_deterministic_base\",\n    ],\n)\n\npy_library(\n    name = \"depthwise_conv_op_base\",\n    srcs = [\"depthwise_conv_op_base.py\"],\n    deps = [\n        \"//tensorflow/python:array_ops\",\n        \"//tensorflow/python:client_testlib\",\n        \"//tensorflow/python:framework_for_generated_wrappers\",\n        \"//tensorflow/python:nn\",\n        \"//tensorflow/python:nn_grad\",\n        \"//tensorflow/python:nn_ops\",\n        \"//third_party/py/numpy\",\n    ],\n)\n\ncuda_py_test(\n    name = \"depthwise_conv_op_d9m_test\",\n    size = \"medium\",  # http://b/30603882\n    timeout = \"long\",\n    srcs = [\"depthwise_conv_op_d9m_test.py\"],\n    shard_count = 8,\n    deps = [\n        \":depthwise_conv_op_base\",\n        \"//tensorflow/python:random_ops\",\n        \"//tensorflow/python/eager:backprop\",\n    ],\n)\n\ncuda_py_test(\n    name = \"depthwise_conv_op_test\",\n    size = \"medium\",  # http://b/30603882\n    timeout = \"long\",\n    srcs = [\"depthwise_conv_op_test.py\"],\n    shard_count = 8,\n    deps = [\n        \":depthwise_conv_op_base\",\n    ],\n)\n\ncuda_py_test(\n    name = \"embedding_ops_test\",\n    size = \"medium\",\n    srcs = [\"embedding_ops_test.py\"],\n    shard_count = 20,\n    tags = [\n        \"no_cuda_asan\",  # Size limit: b/192505612\n    ],\n    xla_tags = [\n        \"no_cuda_asan\",  # Size limit: b/192505612\n    ],\n    deps = [\n        \"//tensorflow/python:array_ops\",\n        \"//tensorflow/python:client_testlib\",\n        \"//tensorflow/python:data_flow_ops\",\n        \"//tensorflow/python:embedding_ops\",\n        \"//tensorflow/python:framework\",\n        \"//tensorflow/python:framework_for_generated_wrappers\",\n        \"//tensorflow/python:init_ops\",\n        \"//tensorflow/python:linalg_ops\",\n        \"//tensorflow/python:math_ops\",\n        \"//tensorflow/python:partitioned_variables\",\n        \"//tensorflow/python:platform\",\n        \"//tensorflow/python:state_ops\",\n        \"//tensorflow/python:util\",\n        \"//tensorflow/python:variable_scope\",\n        \"//tensorflow/python:variables\",\n        \"//third_party/py/numpy\",\n    ],\n)\n\ntf_py_test(\n    name = \"fractional_avg_pool_op_test\",\n    size = \"small\",\n    srcs = [\"fractional_avg_pool_op_test.py\"],\n    shard_count = 5,\n    deps = [\n        \"//tensorflow/python:array_ops\",\n        \"//tensorflow/python:client_testlib\",\n        \"//tensorflow/python:framework_for_generated_wrappers\",\n        \"//tensorflow/python:nn_grad\",\n        \"//tensorflow/python:nn_ops\",\n        \"//tensorflow/python:nn_ops_gen\",\n        \"//third_party/py/numpy\",\n    ],\n)\n\ntf_py_test(\n    name = \"fractional_max_pool_op_test\",\n    size = \"small\",\n    srcs = [\"fractional_max_pool_op_test.py\"],\n    shard_count = 5,\n    deps = [\n        \"//tensorflow/python:array_ops\",\n        \"//tensorflow/python:client_testlib\",\n        \"//tensorflow/python:framework_for_generated_wrappers\",\n        \"//tensorflow/python:nn_grad\",\n        \"//tensorflow/python:nn_ops\",\n        \"//tensorflow/python:nn_ops_gen\",\n        \"//third_party/py/numpy\",\n    ],\n)\n\ntf_py_test(\n    name = \"losses_test\",\n    size = \"medium\",\n    srcs = [\"losses_test.py\"],\n    deps = [\n        \"//tensorflow/python:array_ops\",\n        \"//tensorflow/python:client_testlib\",\n        \"//tensorflow/python:errors\",\n        \"//tensorflow/python:framework\",\n        \"//tensorflow/python:framework_for_generated_wrappers\",\n        \"//tensorflow/python:init_ops\",\n        \"//tensorflow/python:math_ops\",\n        \"//tensorflow/python:training\",\n        \"//tensorflow/python:variable_scope\",\n        \"//tensorflow/python:variables\",\n        \"//tensorflow/python/ops/losses\",\n        \"//third_party/py/numpy\",\n    ],\n)\n\ncuda_py_test(\n    name = \"lrn_op_test\",\n    size = \"medium\",\n    srcs = [\"lrn_op_test.py\"],\n    deps = [\n        \"//tensorflow/python:array_ops\",\n        \"//tensorflow/python:client_testlib\",\n        \"//tensorflow/python:framework_for_generated_wrappers\",\n        \"//tensorflow/python:gradients\",\n        \"//tensorflow/python:nn\",\n        \"//tensorflow/python:nn_grad\",\n        \"//third_party/py/numpy\",\n    ],\n)\n\ncuda_py_test(\n    name = \"morphological_ops_test\",\n    size = \"small\",\n    srcs = [\"morphological_ops_test.py\"],\n    xla_tags = [\n        \"no_cuda_asan\",  # times out\n    ],\n    deps = [\n        \"//tensorflow/python:client_testlib\",\n        \"//tensorflow/python:framework_for_generated_wrappers\",\n        \"//tensorflow/python:nn_grad\",\n        \"//tensorflow/python:nn_ops\",\n        \"//third_party/py/numpy\",\n    ],\n)\n\ncuda_py_test(\n    name = \"nth_element_op_test\",\n    size = \"small\",\n    srcs = [\"nth_element_op_test.py\"],\n    deps = [\n        \"//tensorflow/python:array_ops\",\n        \"//tensorflow/python:client_testlib\",\n        \"//tensorflow/python:framework_for_generated_wrappers\",\n        \"//tensorflow/python:gradients\",\n        \"//tensorflow/python:nn_grad\",\n        \"//tensorflow/python:nn_ops\",\n        \"//third_party/py/numpy\",\n    ],\n)\n\ncuda_py_test(\n    name = \"pool_test\",\n    size = \"medium\",\n    srcs = [\"pool_test.py\"],\n    xla_tags = [\n        \"no_cuda_asan\",  # times out\n    ],\n    deps = [\n        \"//tensorflow/python:client_testlib\",\n        \"//tensorflow/python:framework_for_generated_wrappers\",\n        \"//tensorflow/python:nn_grad\",\n        \"//tensorflow/python:nn_ops\",\n        \"//third_party/py/numpy\",\n    ],\n)\n\ncuda_py_test(\n    name = \"pooling_ops_3d_test\",\n    size = \"medium\",\n    srcs = [\"pooling_ops_3d_test.py\"],\n    deps = [\n        \"//tensorflow/python:client_testlib\",\n        \"//tensorflow/python:dtypes\",\n        \"//tensorflow/python:framework_for_generated_wrappers\",\n        \"//tensorflow/python:nn_grad\",\n        \"//tensorflow/python:nn_ops\",\n        \"//third_party/py/numpy\",\n    ],\n)\n\ncuda_py_test(\n    name = \"pooling_ops_test\",\n    size = \"medium\",\n    srcs = [\"pooling_ops_test.py\"],\n    shard_count = 10,\n    # Some operations in this test can only be checked on sm61+.\n    tags = [\"prefer-sm70\"],\n    deps = [\n        \"//tensorflow/python:array_ops\",\n        \"//tensorflow/python:client_testlib\",\n        \"//tensorflow/python:errors\",\n        \"//tensorflow/python:framework_for_generated_wrappers\",\n        \"//tensorflow/python:framework_test_lib\",\n        \"//tensorflow/python:nn_grad\",\n        \"//tensorflow/python:nn_ops\",\n        \"//tensorflow/python:nn_ops_gen\",\n        \"//third_party/py/numpy\",\n    ],\n)\n\ncuda_py_test(\n    name = \"relu_op_test\",\n    size = \"small\",\n    srcs = [\"relu_op_test.py\"],\n    xla_tags = [\n        \"no_cuda_asan\",  # times out\n    ],\n    deps = [\n        \"//tensorflow/python:client_testlib\",\n        \"//tensorflow/python:framework_for_generated_wrappers\",\n        \"//tensorflow/python:nn_grad\",\n        \"//tensorflow/python:nn_ops\",\n        \"//tensorflow/python:random_ops\",\n        \"//tensorflow/python:tf2\",\n        \"//tensorflow/python:training\",\n        \"//tensorflow/python:variables\",\n        \"//tensorflow/python/eager:backprop\",\n        \"//third_party/py/numpy\",\n    ],\n)\n\ncuda_py_test(\n    name = \"rnn_cell_test\",\n    size = \"medium\",\n    srcs = [\"rnn_cell_test.py\"],\n    shard_count = 15,\n    tags = [\"no_windows\"],  # b/139739217\n    deps = [\n        \"//tensorflow/python:array_ops\",\n        \"//tensorflow/python:client_testlib\",\n        \"//tensorflow/python:control_flow_ops\",\n        \"//tensorflow/python:control_flow_v2_toggles\",\n        \"//tensorflow/python:framework_for_generated_wrappers\",\n        \"//tensorflow/python:framework_test_lib\",\n        \"//tensorflow/python:gradients\",\n        \"//tensorflow/python:init_ops\",\n        \"//tensorflow/python:math_ops\",\n        \"//tensorflow/python:platform\",\n        \"//tensorflow/python:rnn\",\n        \"//tensorflow/python:rnn_cell\",\n        \"//tensorflow/python:tensor_array_ops\",\n        \"//tensorflow/python:util\",\n        \"//tensorflow/python:variable_scope\",\n        \"//tensorflow/python:variables\",\n        \"//tensorflow/python/eager:context\",\n        \"//tensorflow/python/eager:def_function\",\n        \"//tensorflow/python/saved_model:load\",\n        \"//tensorflow/python/saved_model:save\",\n        \"//tensorflow/python/trackable:autotrackable\",\n        \"//third_party/py/numpy\",\n        \"@absl_py//absl/testing:parameterized\",\n    ],\n)\n\ncuda_py_test(\n    name = \"rnn_test\",\n    size = \"medium\",\n    timeout = \"long\",\n    srcs = [\"rnn_test.py\"],\n    shard_count = 10,\n    deps = [\n        \"//tensorflow/core:protos_all_py\",\n        \"//tensorflow/python:array_ops\",\n        \"//tensorflow/python:client\",\n        \"//tensorflow/python:client_testlib\",\n        \"//tensorflow/python:control_flow_ops\",\n        \"//tensorflow/python:data_flow_grad\",\n        \"//tensorflow/python:framework_for_generated_wrappers\",\n        \"//tensorflow/python:framework_test_lib\",\n        \"//tensorflow/python:gradients\",\n        \"//tensorflow/python:init_ops\",\n        \"//tensorflow/python:nn_grad\",\n        \"//tensorflow/python:rnn\",\n        \"//tensorflow/python:rnn_cell\",\n        \"//tensorflow/python:sparse_grad\",\n        \"//tensorflow/python:tensor_array_grad\",\n        \"//tensorflow/python:tensor_array_ops\",\n        \"//tensorflow/python:variables\",\n        \"//tensorflow/python/eager:context\",\n        \"//third_party/py/numpy\",\n    ],\n)\n\ncuda_py_test(\n    name = \"softmax_op_test\",\n    size = \"medium\",\n    srcs = [\"softmax_op_test.py\"],\n    deps = [\n        \"//tensorflow/python:array_ops\",\n        \"//tensorflow/python:client_testlib\",\n        \"//tensorflow/python:errors\",\n        \"//tensorflow/python:framework_for_generated_wrappers\",\n        \"//tensorflow/python:nn_ops\",\n        \"//third_party/py/numpy\",\n    ],\n)\n\ncuda_py_test(\n    name = \"softplus_op_test\",\n    size = \"small\",\n    srcs = [\"softplus_op_test.py\"],\n    deps = [\n        \"//tensorflow/python:client_testlib\",\n        \"//tensorflow/python:framework_for_generated_wrappers\",\n        \"//tensorflow/python:nn_grad\",\n        \"//tensorflow/python:nn_ops\",\n        \"//third_party/py/numpy\",\n    ],\n)\n\ncuda_py_test(\n    name = \"softsign_op_test\",\n    size = \"small\",\n    srcs = [\"softsign_op_test.py\"],\n    deps = [\n        \"//tensorflow/python:client_testlib\",\n        \"//tensorflow/python:framework_for_generated_wrappers\",\n        \"//tensorflow/python:nn_grad\",\n        \"//tensorflow/python:nn_ops\",\n        \"//third_party/py/numpy\",\n    ],\n)\n\ncuda_py_test(\n    name = \"xent_op_d9m_test\",\n    size = \"medium\",\n    srcs = [\"xent_op_d9m_test.py\"],\n    tags = [\n        \"no_windows\",  # Flaky on Windows CPU: https://github.com/tensorflow/tensorflow/issues/55827\n        \"noasan\",  # TODO(b/231484532): Remove after flakiness resolved.\n        \"nomac\",  # TODO(b/235277289) Flaky on OSX\n        \"notsan\",  # TODO(b/200548634): Remove.\n    ],\n    xla_enable_strict_auto_jit = False,\n    deps = [\n        \":xent_op_test_base\",\n        \"//tensorflow/python:client_testlib\",\n        \"//tensorflow/python:constant_op\",\n        \"//tensorflow/python:dtypes\",\n        \"//tensorflow/python:framework_for_generated_wrappers\",\n        \"//tensorflow/python:nn_grad\",\n        \"//tensorflow/python:nn_ops\",\n        \"//tensorflow/python:nn_ops_gen\",\n        \"//tensorflow/python/eager:backprop\",\n        \"//third_party/py/numpy\",\n    ],\n)\n\ncuda_py_test(\n    name = \"xent_op_test\",\n    size = \"small\",\n    srcs = [\"xent_op_test.py\"],\n    deps = [\n        \":xent_op_test_base\",\n        \"//tensorflow/python:client_testlib\",\n        \"//tensorflow/python:framework_for_generated_wrappers\",\n        \"//tensorflow/python:framework_ops\",\n        \"//tensorflow/python:nn_ops\",\n        \"//tensorflow/python:nn_ops_gen\",\n        \"//third_party/py/numpy\",\n    ],\n)\n\npy_library(\n    name = \"xent_op_test_base\",\n    srcs = [\"xent_op_test_base.py\"],\n    srcs_version = \"PY3\",\n    deps = [\n        \"//tensorflow/python:array_ops\",\n        \"//tensorflow/python:client_testlib\",\n        \"//tensorflow/python:constant_op\",\n        \"//tensorflow/python:dtypes\",\n        \"//tensorflow/python:framework_for_generated_wrappers\",\n        \"//tensorflow/python:framework_ops\",\n        \"//tensorflow/python:gradients\",\n        \"//tensorflow/python:math_ops\",\n        \"//tensorflow/python:nn_grad\",\n        \"//tensorflow/python:nn_ops\",\n        \"//tensorflow/python/eager:backprop\",\n        \"//third_party/py/numpy\",\n    ],\n)\n", "# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\"\"\"Functional tests for 3d pooling operations.\"\"\"\n\nimport numpy as np\n\nfrom tensorflow.python.eager import context\nfrom tensorflow.python.framework import constant_op\nfrom tensorflow.python.framework import dtypes\nfrom tensorflow.python.framework import errors\nfrom tensorflow.python.framework import errors_impl\nfrom tensorflow.python.framework import test_util\nfrom tensorflow.python.ops import array_ops\nfrom tensorflow.python.ops import gen_nn_ops\nfrom tensorflow.python.ops import gradient_checker\nfrom tensorflow.python.ops import gradients_impl\nfrom tensorflow.python.ops import nn_ops\nimport tensorflow.python.ops.nn_grad  # pylint: disable=unused-import\nfrom tensorflow.python.platform import test\n\n\ndef GetTestConfigs():\n  \"\"\"Get all the valid tests configs to run.\n\n  Returns:\n    all the valid test configs as tuples of data_format and use_gpu.\n  \"\"\"\n  test_configs = [(\"NDHWC\", False), (\"NDHWC\", True)]\n  if test.is_gpu_available(cuda_only=True):\n    # \"NCHW\" format is currently supported exclusively on CUDA GPUs.\n    test_configs += [(\"NCDHW\", True)]\n  return test_configs\n\n\n# TODO(mjanusz): Add microbenchmarks for 3d pooling.\n@test_util.with_eager_op_as_function\nclass PoolingTest(test.TestCase):\n\n  def _VerifyOneTest(self, pool_func, input_sizes, window, strides, padding,\n                     data_format, expected, use_gpu):\n    \"\"\"Verifies the output values of the pooling function.\n\n    Args:\n      pool_func: Function to be called: co.MaxPool, co.AvgPool.\n      input_sizes: Input tensor dimensions.\n      window: Tuple of kernel dims: planes, rows, cols.\n      strides: Tuple of strides for dims: planes, rows, cols.\n      padding: Padding type.\n      data_format: The data format we use to run the pooling operation.\n      expected: An array containing the expected operation outputs.\n      use_gpu: Whether to run ops on GPU.\n    \"\"\"\n    total_size = 1\n    for s in input_sizes:\n      total_size *= s\n    # Initializes the input tensor with array containing incrementing\n    # numbers from 1.\n    x = [f * 1.0 for f in range(1, total_size + 1)]\n    with self.cached_session(use_gpu=use_gpu):\n      t = constant_op.constant(x, shape=input_sizes)\n      window = [1] + list(window) + [1]\n      strides = [1] + list(strides) + [1]\n      if data_format == \"NCDHW\":\n        t = test_util.NHWCToNCHW(t)\n        window = test_util.NHWCToNCHW(window)\n        strides = test_util.NHWCToNCHW(strides)\n      t = pool_func(\n          t,\n          ksize=window,\n          strides=strides,\n          padding=padding,\n          data_format=data_format)\n      if data_format == \"NCDHW\":\n        t = test_util.NCHWToNHWC(t)\n      vals = self.evaluate(t)\n    # Verifies values.\n    actual = vals.flatten()\n    self.assertAllClose(expected, actual)\n\n  def _VerifyValues(self, pool_func, input_sizes, window, strides,\n                    padding, expected):\n    for data_format, use_gpu in GetTestConfigs():\n      self._VerifyOneTest(pool_func, input_sizes, window, strides, padding,\n                          data_format, expected, use_gpu)\n\n  def testAvgPool3dValidPadding(self):\n    expected_output = [20.5, 21.5, 22.5]\n    self._VerifyValues(\n        nn_ops.avg_pool3d,\n        input_sizes=[1, 3, 3, 3, 3],\n        window=(2, 2, 2),\n        strides=(2, 2, 2),\n        padding=\"VALID\",\n        expected=expected_output)\n\n  def testAvgPool3dSamePadding(self):\n    expected_output = [20.5, 21.5, 22.5, 26.5, 27.5, 28.5]\n    self._VerifyValues(\n        nn_ops.avg_pool3d,\n        input_sizes=[1, 2, 2, 4, 3],\n        window=(2, 2, 2),\n        strides=(2, 2, 2),\n        padding=\"SAME\",\n        expected=expected_output)\n\n  def testAvgPool3dSamePaddingDifferentStrides(self):\n    expected_output = [1.5, 4.5, 7.5, 17.5, 20.5, 23.5, 33.5, 36.5, 39.5]\n    self._VerifyValues(\n        nn_ops.avg_pool3d,\n        input_sizes=[1, 5, 8, 1, 1],\n        window=(1, 2, 3),\n        strides=(2, 3, 1),\n        padding=\"SAME\",\n        expected=expected_output)\n\n  def testMaxPool3dGrad(self):\n    with self.assertRaises(\n        (errors.ResourceExhaustedError, errors.InvalidArgumentError)):\n      with self.cached_session():\n        orig_input_shape = constant_op.constant(\n            1879048192, shape=[5], dtype=dtypes.int32)\n        grad = constant_op.constant(\n            1, shape=[1, 3, 2, 4, 2], dtype=dtypes.float32)\n        t = gen_nn_ops.AvgPool3DGrad(\n            orig_input_shape=orig_input_shape,\n            grad=grad,\n            ksize=[1, 1, 1, 1, 1],\n            strides=[1, 1, 1, 1, 1],\n            padding=\"SAME\",\n            data_format=\"NDHWC\")\n        self.evaluate(t)\n\n  def testMaxPool3dValidPadding(self):\n    expected_output = [40.0, 41.0, 42.0]\n    self._VerifyValues(\n        nn_ops.max_pool3d,\n        input_sizes=[1, 3, 3, 3, 3],\n        window=(2, 2, 2),\n        strides=(2, 2, 2),\n        padding=\"VALID\",\n        expected=expected_output)\n\n  def testMaxPool3dSamePadding(self):\n    expected_output = [31., 32., 33., 34., 35., 36.]\n    self._VerifyValues(\n        nn_ops.max_pool3d,\n        input_sizes=[1, 2, 2, 3, 3],\n        window=(2, 2, 2),\n        strides=(2, 2, 2),\n        padding=\"SAME\",\n        expected=expected_output)\n\n  def testMaxPool3dSamePaddingDifferentStrides(self):\n    expected_output = [2., 5., 8., 18., 21., 24., 34., 37., 40.]\n    self._VerifyValues(\n        nn_ops.max_pool3d,\n        input_sizes=[1, 5, 8, 1, 1],\n        window=(1, 2, 3),\n        strides=(2, 3, 1),\n        padding=\"SAME\",\n        expected=expected_output)\n\n    # Test pooling on a larger input, with different stride and kernel\n    # size for the 'z' dimension.\n\n    # Simulate max pooling in numpy to get the expected output.\n    input_data = np.arange(1, 5 * 27 * 27 * 64 + 1).reshape((5, 27, 27, 64))\n    input_data = np.pad(input_data, [[0, 0], [0, 1], [0, 1], [0, 0]],\n                        mode=\"constant\")\n    expected_output = input_data[:, 1::2, 1::2, :]\n    expected_output[:, -1, :, :] = input_data[:, -2, 1::2, :]\n    expected_output[:, :, -1, :] = input_data[:, 1::2, -2, :]\n    expected_output[:, -1, -1, :] = input_data[:, -2, -2, :]\n\n    self._VerifyValues(\n        nn_ops.max_pool3d,\n        input_sizes=[1, 5, 27, 27, 64],\n        window=(1, 2, 2),\n        strides=(1, 2, 2),\n        padding=\"SAME\",\n        expected=expected_output.flatten())\n\n  def testKernelSmallerThanStride(self):\n    self._VerifyValues(\n        nn_ops.max_pool3d,\n        input_sizes=[1, 3, 3, 3, 1],\n        window=[1, 1, 1],\n        strides=[2, 2, 2],\n        padding=\"SAME\",\n        expected=[1, 3, 7, 9, 19, 21, 25, 27])\n\n    self._VerifyValues(\n        nn_ops.max_pool3d,\n        input_sizes=[1, 7, 7, 7, 1],\n        window=[2, 2, 2],\n        strides=[3, 3, 3],\n        padding=\"VALID\",\n        expected=[58, 61, 79, 82, 205, 208, 226, 229])\n\n    self._VerifyValues(\n        nn_ops.avg_pool3d,\n        input_sizes=[1, 3, 3, 3, 1],\n        window=[1, 1, 1],\n        strides=[2, 2, 2],\n        padding=\"SAME\",\n        expected=[1, 3, 7, 9, 19, 21, 25, 27])\n\n    self._VerifyValues(\n        nn_ops.avg_pool3d,\n        input_sizes=[1, 7, 7, 7, 1],\n        window=[2, 2, 2],\n        strides=[3, 3, 3],\n        padding=\"VALID\",\n        expected=[29.5, 32.5, 50.5, 53.5, 176.5, 179.5, 197.5, 200.5])\n\n  def testMaxPool3DEmptyTensorOutputShape(self):\n    \"\"\"Verifies the output shape of the max pooling function when tensor is empty.\n\n    Args: none\n    \"\"\"\n    input_sizes = [0, 112, 112, 112, 64]\n\n    input_data = 1.\n    input_tensor = constant_op.constant(\n        input_data, shape=input_sizes, name=\"input\")\n    max_pool_3d = nn_ops.max_pool3d(\n        input_tensor,\n        ksize=[2, 2, 2],\n        strides=[2, 2, 2],\n        padding=\"VALID\",\n        data_format=\"NDHWC\",\n        name=\"max_pool_3d\")\n    values = self.evaluate(max_pool_3d)\n    self.assertEqual(values.shape, (0, 56, 56, 56, 64))\n\n  def _ConstructAndTestGradientForConfig(self,\n                                         pool_func,\n                                         input_sizes,\n                                         output_sizes,\n                                         window,\n                                         strides,\n                                         padding,\n                                         data_format,\n                                         use_gpu):\n    \"\"\"Verifies the gradients of a pooling function.\n\n    Args:\n      pool_func: Function to be called, co.MaxPool, co.AvgPool,\n        or the Lua version.\n      input_sizes: Input tensor dimensions.\n      output_sizes: Output tensor dimensions.\n      window: Tuple of kernel dims: planes, rows, cols.\n      strides: Tuple of strides for dims: planes, rows, cols.\n      padding: Padding type.\n      data_format: Data format string.\n      use_gpu: Whether to run on GPU.\n    \"\"\"\n    total_size = 1\n    for s in input_sizes:\n      total_size *= s\n    # Initializes the input tensor with array containing incrementing\n    # numbers from 1.\n    x = np.arange(1, total_size + 1, dtype=np.float32)\n    with self.cached_session(use_gpu=use_gpu):\n      input_tensor = constant_op.constant(x, shape=input_sizes, name=\"input\")\n      err_g_margin = 1e-3\n      err_gg_margin = 1.5e-2\n      if pool_func == nn_ops.avg_pool3d:\n        func_name = \"avg_pool3d\"\n        x_init_value = None\n      else:\n        x_init_value = np.asfarray(np.arange(1, total_size + 1),\n                                   dtype=np.float32).reshape(input_sizes)\n        func_name = \"max_pool3d\"\n\n      ksize = [1, window[0], window[1], window[2], 1]\n      strides = [1, strides[0], strides[1], strides[2], 1]\n      t = input_tensor\n\n      if data_format == \"NCDHW\":\n        ksize = test_util.NHWCToNCHW(ksize)\n        strides = test_util.NHWCToNCHW(strides)\n        t = test_util.NHWCToNCHW(t)\n        output_sizes = test_util.NHWCToNCHW(output_sizes)\n\n      t = pool_func(\n          t,\n          ksize=ksize,\n          strides=strides,\n          padding=padding,\n          data_format=data_format,\n          name=func_name)\n      t_g = gradients_impl.gradients(t**2, input_tensor)[0]\n\n      err_g = gradient_checker.compute_gradient_error(\n          input_tensor,\n          input_sizes,\n          t,\n          output_sizes,\n          x_init_value=x_init_value,\n          delta=1e-2)\n      err_gg = gradient_checker.compute_gradient_error(\n          input_tensor,\n          input_sizes,\n          t_g,\n          input_sizes,\n          x_init_value=x_init_value,\n          delta=1e-2)\n\n    print(\"%s gradient error = \" % func_name, err_g)\n    self.assertLess(err_g, err_g_margin)\n    print(\"%s second-order gradient error = \" % func_name, err_gg)\n    self.assertLess(err_gg, err_gg_margin)\n\n  def _ConstructAndTestGradient(self,\n                                pool_func,\n                                **kwargs):\n    \"\"\"Runs _ConstructAndTestGradientForConfig for all tests configurations.\"\"\"\n\n    for data_format, use_gpu in GetTestConfigs():\n      self._ConstructAndTestGradientForConfig(pool_func,\n                                              data_format=data_format,\n                                              use_gpu=use_gpu,\n                                              **kwargs)\n\n  @test_util.run_deprecated_v1\n  def testMaxPoolGradValidPadding1_1_3d(self):\n    self._ConstructAndTestGradient(\n        nn_ops.max_pool3d,\n        input_sizes=[1, 3, 3, 3, 1],\n        output_sizes=[1, 3, 3, 3, 1],\n        window=(1, 1, 1),\n        strides=(1, 1, 1),\n        padding=\"VALID\")\n\n  @test_util.run_deprecated_v1\n  def testMaxPoolGradValidPadding2_1_6_3d(self):\n    self._ConstructAndTestGradient(\n        nn_ops.max_pool3d,\n        input_sizes=[1, 2, 3, 4, 2],\n        output_sizes=[1, 1, 2, 3, 2],\n        window=(2, 2, 2),\n        strides=(1, 1, 1),\n        padding=\"VALID\")\n\n  @test_util.run_deprecated_v1\n  def testMaxPoolGradValidPadding2_1_7_3d(self):\n    self._ConstructAndTestGradient(\n        nn_ops.max_pool3d,\n        input_sizes=[1, 3, 2, 7, 1],\n        output_sizes=[1, 2, 1, 6, 1],\n        window=(2, 2, 2),\n        strides=(1, 1, 1),\n        padding=\"VALID\")\n\n  @test_util.run_deprecated_v1\n  def testMaxPoolGradValidPadding1_2_3d(self):\n    self._ConstructAndTestGradient(\n        nn_ops.max_pool3d,\n        input_sizes=[1, 3, 3, 3, 1],\n        output_sizes=[1, 2, 2, 2, 1],\n        window=(1, 1, 1),\n        strides=(2, 2, 2),\n        padding=\"VALID\")\n\n  @test_util.run_deprecated_v1\n  def testMaxPoolGradValidPadding2_2_3d(self):\n    self._ConstructAndTestGradient(\n        nn_ops.max_pool3d,\n        input_sizes=[2, 2, 2, 2, 1],\n        output_sizes=[2, 1, 1, 1, 1],\n        window=(2, 2, 2),\n        strides=(2, 2, 2),\n        padding=\"VALID\")\n\n  @test_util.run_deprecated_v1\n  def testMaxPoolGradSamePadding1_1_3d(self):\n    self._ConstructAndTestGradient(\n        nn_ops.max_pool3d,\n        input_sizes=[1, 3, 2, 4, 1],\n        output_sizes=[1, 3, 2, 4, 1],\n        window=(1, 1, 1),\n        strides=(1, 1, 1),\n        padding=\"SAME\")\n\n  @test_util.run_deprecated_v1\n  def testMaxPoolGradSamePadding1_2_3d(self):\n    self._ConstructAndTestGradient(\n        nn_ops.max_pool3d,\n        input_sizes=[1, 3, 2, 4, 1],\n        output_sizes=[1, 2, 1, 2, 1],\n        window=(1, 1, 1),\n        strides=(2, 2, 2),\n        padding=\"SAME\")\n\n  @test_util.run_deprecated_v1\n  def testMaxPoolGradSamePadding2_1_3d(self):\n    self._ConstructAndTestGradient(\n        nn_ops.max_pool3d,\n        input_sizes=[1, 3, 2, 4, 1],\n        output_sizes=[1, 3, 2, 4, 1],\n        window=(2, 2, 2),\n        strides=(1, 1, 1),\n        padding=\"SAME\")\n\n  @test_util.run_deprecated_v1\n  def testMaxPoolGradSamePadding2_2_3d(self):\n    self._ConstructAndTestGradient(\n        nn_ops.max_pool3d,\n        input_sizes=[1, 5, 2, 4, 2],\n        output_sizes=[1, 3, 1, 2, 2],\n        window=(2, 2, 2),\n        strides=(2, 2, 2),\n        padding=\"SAME\")\n\n  @test_util.run_deprecated_v1\n  def testMaxPoolGradSamePadding3_1_3d(self):\n    self._ConstructAndTestGradient(\n        nn_ops.max_pool3d,\n        input_sizes=[1, 3, 4, 2, 1],\n        output_sizes=[1, 3, 4, 2, 1],\n        window=(3, 3, 3),\n        strides=(1, 1, 1),\n        padding=\"SAME\")\n\n  @test_util.run_deprecated_v1\n  def testAvgPoolGradValidPadding1_1_3d(self):\n    self._ConstructAndTestGradient(\n        nn_ops.avg_pool3d,\n        input_sizes=[1, 3, 3, 3, 1],\n        output_sizes=[1, 3, 3, 3, 1],\n        window=(1, 1, 1),\n        strides=(1, 1, 1),\n        padding=\"VALID\")\n\n  @test_util.run_deprecated_v1\n  def testAvgPoolGradValidPadding1_2_3d(self):\n    self._ConstructAndTestGradient(\n        nn_ops.avg_pool3d,\n        input_sizes=[1, 3, 3, 3, 1],\n        output_sizes=[1, 2, 2, 2, 1],\n        window=(1, 1, 1),\n        strides=(2, 2, 2),\n        padding=\"VALID\")\n\n  @test_util.run_deprecated_v1\n  def testAvgPoolGradValidPadding2_1_3d(self):\n    self._ConstructAndTestGradient(\n        nn_ops.avg_pool3d,\n        input_sizes=[1, 3, 3, 3, 2],\n        output_sizes=[1, 2, 2, 2, 2],\n        window=(2, 2, 2),\n        strides=(1, 1, 1),\n        padding=\"VALID\")\n\n  @test_util.run_deprecated_v1\n  def testAvgPoolGradValidPadding2_2_3d(self):\n    self._ConstructAndTestGradient(\n        nn_ops.avg_pool3d,\n        input_sizes=[2, 2, 2, 2, 2],\n        output_sizes=[2, 1, 1, 1, 2],\n        window=(2, 2, 2),\n        strides=(2, 2, 2),\n        padding=\"VALID\")\n\n  @test_util.run_deprecated_v1\n  def testAvgPoolGradSamePadding1_1_3d(self):\n    self._ConstructAndTestGradient(\n        nn_ops.avg_pool3d,\n        input_sizes=[1, 3, 2, 4, 2],\n        output_sizes=[1, 3, 2, 4, 2],\n        window=(1, 1, 1),\n        strides=(1, 1, 1),\n        padding=\"SAME\")\n\n  @test_util.run_deprecated_v1\n  def testAvgPoolGradSamePadding1_2_3d(self):\n    self._ConstructAndTestGradient(\n        nn_ops.avg_pool3d,\n        input_sizes=[1, 3, 2, 4, 2],\n        output_sizes=[1, 2, 1, 2, 2],\n        window=(1, 1, 1),\n        strides=(2, 2, 2),\n        padding=\"SAME\")\n\n  @test_util.run_deprecated_v1\n  def testAvgPoolGradSamePadding2_1_3d(self):\n    self._ConstructAndTestGradient(\n        nn_ops.avg_pool3d,\n        input_sizes=[1, 2, 2, 2, 1],\n        output_sizes=[1, 2, 2, 2, 1],\n        window=(2, 2, 2),\n        strides=(1, 1, 1),\n        padding=\"SAME\")\n\n  @test_util.run_deprecated_v1\n  def testAvgPoolGradSamePadding2_2_3d(self):\n    self._ConstructAndTestGradient(\n        nn_ops.avg_pool3d,\n        input_sizes=[1, 5, 2, 4, 1],\n        output_sizes=[1, 3, 1, 2, 1],\n        window=(2, 2, 2),\n        strides=(2, 2, 2),\n        padding=\"SAME\")\n\n  @test_util.run_deprecated_v1\n  def testAvgPoolGradSamePadding3_1_3d(self):\n    self._ConstructAndTestGradient(\n        nn_ops.avg_pool3d,\n        input_sizes=[1, 3, 6, 2, 1],\n        output_sizes=[1, 3, 6, 2, 1],\n        window=(3, 3, 3),\n        strides=(1, 1, 1),\n        padding=\"SAME\")\n\n  def testMaxPool3DZeroPoolSize(self):\n    # Test case for GitHub issue 51936.\n    for f in [nn_ops.max_pool3d, nn_ops.avg_pool3d]:\n      with self.session():\n        with self.assertRaises((errors.InvalidArgumentError, ValueError)):\n          input_sizes = [3, 4, 10, 11, 12]\n\n          input_data = 1.\n          input_tensor = constant_op.constant(\n              input_data, shape=input_sizes, name=\"input\")\n          pool_3d = f(input_tensor, ksize=[2, 2, 0], strides=1, padding=\"VALID\")\n          self.evaluate(pool_3d)\n\n  @test_util.disable_xla(\"b/205634417\")  # XLA does not raise these errors.\n  def testMaxPoolGradEagerShapeErrors(self):\n    with context.eager_mode():\n      orig_in = array_ops.ones((1, 1, 1, 1, 1))\n\n      # Test invalid orig_out shape\n      orig_out = array_ops.ones((1, 1, 1, 1, 2))\n      grad = array_ops.ones((1, 1, 1, 1, 1))\n      with self.assertRaisesRegex(\n          errors_impl.InvalidArgumentError,\n          r\"Expected orig_output shape to be \\[1,1,1,1,1\\], but got \"\n          r\"\\[1,1,1,1,2\\]\"):\n        gen_nn_ops.max_pool3d_grad(\n            orig_in, orig_out, grad, ksize=[1, 1, 1, 1, 1],\n            strides=[1, 1, 1, 1, 1], padding=\"VALID\")\n      with self.assertRaisesRegex(\n          errors_impl.InvalidArgumentError,\n          r\"Expected orig_output shape to be \\[1,1,1,1,1\\], but got \"\n          r\"\\[1,1,1,1,2\\]\"):\n        gen_nn_ops.max_pool3d_grad_grad(\n            orig_in, orig_out, grad, ksize=[1, 1, 1, 1, 1],\n            strides=[1, 1, 1, 1, 1], padding=\"VALID\")\n\n      # Test invalid grad shape\n      orig_out = array_ops.ones((1, 1, 1, 1, 1))\n      grad = array_ops.ones((1, 1, 1, 1, 2))\n      with self.assertRaisesRegex(\n          errors_impl.InvalidArgumentError,\n          r\"Expected grad shape to be \\[1,1,1,1,1\\], but got \\[1,1,1,1,2\\]\"):\n        gen_nn_ops.max_pool3d_grad(\n            orig_in, orig_out, grad, ksize=[1, 1, 1, 1, 1],\n            strides=[1, 1, 1, 1, 1], padding=\"VALID\")\n      with self.assertRaisesRegex(\n          errors_impl.InvalidArgumentError,\n          r\"Expected grad shape to be \\[1,1,1,1,1\\], but got \\[1,1,1,1,2\\]\"):\n        gen_nn_ops.max_pool3d_grad_grad(\n            orig_in, orig_out, grad, ksize=[1, 1, 1, 1, 1],\n            strides=[1, 1, 1, 1, 1], padding=\"VALID\")\n\n\nif __name__ == \"__main__\":\n  test.main()\n"], "filenames": ["tensorflow/compiler/tf2xla/BUILD", "tensorflow/compiler/tf2xla/xla_op_kernel.cc", "tensorflow/core/kernels/pooling_ops_3d.cc", "tensorflow/python/kernel_tests/nn_ops/BUILD", "tensorflow/python/kernel_tests/nn_ops/pooling_ops_3d_test.py"], "buggy_code_start_loc": [405, 32, 526, 502, 20], "buggy_code_end_loc": [405, 445, 527, 502, 125], "fixing_code_start_loc": [406, 33, 526, 503, 21], "fixing_code_end_loc": [407, 457, 527, 504, 144], "type": "CWE-617", "message": "TensorFlow is an open source platform for machine learning. The implementation of `AvgPool3DGradOp` does not fully validate the input `orig_input_shape`. This results in an overflow that results in a `CHECK` failure which can be used to trigger a denial of service attack. We have patched the issue in GitHub commit 9178ac9d6389bdc54638ab913ea0e419234d14eb. The fix will be included in TensorFlow 2.10.0. We will also cherrypick this commit on TensorFlow 2.9.1, TensorFlow 2.8.1, and TensorFlow 2.7.2, as these are also affected and still in supported range. There are no known workarounds for this issue.", "other": {"cve": {"id": "CVE-2022-35959", "sourceIdentifier": "security-advisories@github.com", "published": "2022-09-16T20:15:10.510", "lastModified": "2022-09-21T17:12:03.627", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "TensorFlow is an open source platform for machine learning. The implementation of `AvgPool3DGradOp` does not fully validate the input `orig_input_shape`. This results in an overflow that results in a `CHECK` failure which can be used to trigger a denial of service attack. We have patched the issue in GitHub commit 9178ac9d6389bdc54638ab913ea0e419234d14eb. The fix will be included in TensorFlow 2.10.0. We will also cherrypick this commit on TensorFlow 2.9.1, TensorFlow 2.8.1, and TensorFlow 2.7.2, as these are also affected and still in supported range. There are no known workarounds for this issue."}, {"lang": "es", "value": "TensorFlow es una plataforma de c\u00f3digo abierto para el aprendizaje autom\u00e1tico. La implementaci\u00f3n de \"AvgPool3DGradOp\" no comprueba completamente la entrada \"orig_input_shape\". Esto resulta en un desbordamiento que resulta en un fallo de \"CHECK\" que puede ser usado para desencadenar un ataque de denegaci\u00f3n de servicio. Hemos parcheado el problema en el commit 9178ac9d6389bdc54638ab913ea0e419234d14eb de GitHub. La correcci\u00f3n ser\u00e1 incluida en TensorFlow versi\u00f3n 2.10.0. Tambi\u00e9n seleccionaremos este compromiso en TensorFlow versi\u00f3n 2.9.1, TensorFlow versi\u00f3n 2.8.1, y TensorFlow versi\u00f3n 2.7.2, ya que estos tambi\u00e9n est\u00e1n afectados y todav\u00eda est\u00e1n en el rango admitido. No se presentan mitigaciones conocidas para este problema"}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 7.5, "baseSeverity": "HIGH"}, "exploitabilityScore": 3.9, "impactScore": 3.6}, {"source": "security-advisories@github.com", "type": "Secondary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:H/PR:N/UI:N/S:U/C:N/I:N/A:H", "attackVector": "NETWORK", "attackComplexity": "HIGH", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 5.9, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 2.2, "impactScore": 3.6}]}, "weaknesses": [{"source": "security-advisories@github.com", "type": "Primary", "description": [{"lang": "en", "value": "CWE-617"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:*:*:*:*:*:*:*:*", "versionStartIncluding": "2.7.0", "versionEndExcluding": "2.7.2", "matchCriteriaId": "C4DFBF2D-5283-42F6-8800-D653BFA5CE82"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:2.8.0:*:*:*:*:*:*:*", "matchCriteriaId": "C3684238-B1B8-4134-9FED-8A3733E1F39B"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:2.9.0:*:*:*:*:*:*:*", "matchCriteriaId": "08DF9052-55EF-4B54-94C6-EC9B4FC87DE1"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:2.10:rc0:*:*:*:*:*:*", "matchCriteriaId": "1DBFBCE2-0A01-4575-BE45-6775ABFB8B28"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:2.10:rc1:*:*:*:*:*:*", "matchCriteriaId": "89806CF9-E423-4CA6-A01A-8175C260CB24"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:2.10:rc2:*:*:*:*:*:*", "matchCriteriaId": "F2B80690-A257-4E16-BD27-9AE045BC56ED"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:2.10:rc3:*:*:*:*:*:*", "matchCriteriaId": "F335F9A4-5AB8-4E53-BC18-E01F7C653E5E"}]}]}], "references": [{"url": "https://github.com/tensorflow/tensorflow/commit/9178ac9d6389bdc54638ab913ea0e419234d14eb", "source": "security-advisories@github.com", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-wxjj-cgcx-r3vq", "source": "security-advisories@github.com", "tags": ["Patch", "Third Party Advisory"]}]}, "github_commit_url": "https://github.com/tensorflow/tensorflow/commit/9178ac9d6389bdc54638ab913ea0e419234d14eb"}}
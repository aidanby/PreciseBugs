{"buggy_code": ["import contextlib\nimport logging\nimport re\nimport shutil\nimport urllib.parse\nfrom pathlib import Path\nfrom shutil import make_archive\n\nfrom bs4 import BeautifulSoup\nfrom django.conf import settings\nfrom django.core.management.base import BaseCommand, CommandError\nfrom django.test import Client, override_settings\nfrom django.utils.timezone import override as override_timezone\nfrom django_scopes import scope, scopes_disabled\n\nfrom pretalx.common.signals import register_data_exporters\nfrom pretalx.common.utils import rolledback_transaction\nfrom pretalx.event.models import Event\n\n\n@contextlib.contextmanager\ndef fake_admin(event):\n    with rolledback_transaction():\n        event.is_public = True\n        event.save()\n        client = Client()\n\n        def get(url):\n            try:\n                # Try getting the file from disk directly first, \u2026\n                return get_mediastatic_content(url)\n            except FileNotFoundError:\n                # \u2026 then fall back to asking the views.\n                response = client.get(url, is_html_export=True, HTTP_ACCEPT=\"text/html\")\n                content = get_content(response)\n                return content\n\n        yield get\n\n\ndef find_assets(html):\n    \"\"\"Find URLs of images, style sheets and scripts included in `html`.\"\"\"\n    soup = BeautifulSoup(html, \"lxml\")\n\n    for asset in soup.find_all([\"script\", \"img\"]):\n        yield asset.attrs[\"src\"]\n    for asset in soup.find_all([\"link\"]):\n        if asset.attrs[\"rel\"][0] in [\"icon\", \"stylesheet\"]:\n            yield asset.attrs[\"href\"]\n\n\ndef find_urls(css):\n    return re.findall(r'url\\(\"?(/[^\")]+)\"?\\)', css.decode(\"utf-8\"), re.IGNORECASE)\n\n\ndef event_talk_urls(event):\n    for talk in event.talks:\n        yield talk.urls.public\n        yield talk.urls.ical\n\n        for resource in talk.active_resources:\n            if resource.resource and resource.resource.url:\n                yield resource.resource.url\n\n\ndef event_speaker_urls(event):\n    for speaker in event.speakers:\n        profile = speaker.event_profile(event)\n        yield profile.urls.public\n        yield profile.urls.talks_ical\n\n\ndef event_exporter_urls(event):\n    for _, exporter in register_data_exporters.send(event):\n        if exporter.public:\n            yield exporter(event).urls.base\n\n\ndef schedule_version_urls(event):\n    for schedule in event.schedules.filter(version__isnull=False):\n        yield schedule.urls.public\n        yield schedule.urls.widget_data\n        yield schedule.urls.nojs\n\n\ndef event_urls(event):\n    yield event.urls.base\n    yield event.urls.schedule\n    yield event.urls.schedule_nojs\n    yield event.urls.widget_data\n    yield from schedule_version_urls(event)\n    yield event.urls.featured\n    yield event.urls.talks\n    yield from event_talk_urls(event)\n    yield event.urls.speakers\n    yield from event_speaker_urls(event)\n    yield from event_exporter_urls(event)\n    yield event.urls.changelog\n    yield event.urls.feed\n\n\ndef get_path(url):\n    return urllib.parse.urlparse(url).path\n\n\ndef get_content(response):\n    return (\n        b\"\".join(response.streaming_content) if response.streaming else response.content\n    )\n\n\ndef dump_content(destination, path, getter):\n    logging.debug(path)\n    content = getter(path)\n    if path.endswith(\"/\"):\n        path = path + \"index.html\"\n\n    path = Path(destination) / path.lstrip(\"/\")\n    path.parent.mkdir(parents=True, exist_ok=True)\n\n    with open(path, \"wb\") as f:\n        f.write(content)\n    return content\n\n\ndef get_mediastatic_content(url):\n    if url.startswith(settings.STATIC_URL):\n        local_path = settings.STATIC_ROOT / url[len(settings.STATIC_URL) :]\n    elif url.startswith(settings.MEDIA_URL):\n        local_path = settings.MEDIA_ROOT / url[len(settings.MEDIA_URL) :]\n    else:\n        raise FileNotFoundError()\n\n    with open(local_path, \"rb\") as f:\n        return f.read()\n\n\ndef export_event(event, destination):\n    with override_settings(\n        COMPRESS_ENABLED=True, COMPRESS_OFFLINE=True\n    ), override_timezone(event.timezone):\n        with fake_admin(event) as get:\n            logging.info(\"Collecting URLs for export\")\n            urls = [*event_urls(event)]\n            assets = set()\n\n            logging.info(f\"Exporting {len(urls)} pages\")\n            for url in map(get_path, urls):\n                content = dump_content(destination, url, get)\n                assets |= set(map(get_path, find_assets(content)))\n\n            css_assets = set()\n\n            logging.info(f\"Exporting {len(assets)} static files from HTML links\")\n            for url in assets:\n                content = dump_content(destination, url, get)\n\n                if url.endswith(\".css\"):\n                    css_assets |= set(find_urls(content))\n\n            logging.info(f\"Exporting {len(css_assets)} files from CSS links\")\n            for url_path in (get_path(urllib.parse.unquote(url)) for url in css_assets):\n                dump_content(destination, url_path, get)\n\n\ndef delete_directory(path):\n    with contextlib.suppress(FileNotFoundError):\n        shutil.rmtree(path)\n\n\ndef get_export_path(event):\n    return settings.HTMLEXPORT_ROOT / event.slug\n\n\ndef get_export_zip_path(event):\n    return get_export_path(event).with_suffix(\".zip\")\n\n\nclass Command(BaseCommand):\n    def add_arguments(self, parser):\n        super().add_arguments(parser)\n        parser.add_argument(\"event\", type=str)\n        parser.add_argument(\"--zip\", action=\"store_true\")\n\n    def handle(self, *args, **options):\n        event_slug = options.get(\"event\")\n\n        with scopes_disabled():\n            try:\n                event = Event.objects.get(slug__iexact=event_slug)\n            except Event.DoesNotExist:\n                raise CommandError(f'Could not find event with slug \"{event_slug}\".')\n\n        with scope(event=event):\n            logging.info(f\"Exporting {event.name}\")\n            export_dir = get_export_path(event)\n            zip_path = get_export_zip_path(event)\n            tmp_dir = export_dir.with_name(export_dir.name + \"-new\")\n\n            delete_directory(tmp_dir)\n            tmp_dir.mkdir()\n\n            try:\n                export_event(event, tmp_dir)\n                delete_directory(export_dir)\n                tmp_dir.rename(export_dir)\n            finally:\n                delete_directory(tmp_dir)\n\n            logging.info(f\"Exported to {export_dir}\")\n\n            if options.get(\"zip\"):\n                make_archive(\n                    root_dir=settings.HTMLEXPORT_ROOT,\n                    base_dir=event.slug,\n                    base_name=zip_path.parent / zip_path.stem,\n                    format=\"zip\",\n                )\n\n                logging.info(f\"Exported to {zip_path}\")\n"], "fixing_code": ["import contextlib\nimport logging\nimport re\nimport shutil\nimport urllib.parse\nfrom pathlib import Path\nfrom shutil import make_archive\n\nfrom bs4 import BeautifulSoup\nfrom django.conf import settings\nfrom django.core.management.base import BaseCommand, CommandError\nfrom django.test import Client, override_settings\nfrom django.utils.timezone import override as override_timezone\nfrom django_scopes import scope, scopes_disabled\n\nfrom pretalx.common.signals import register_data_exporters\nfrom pretalx.common.utils import rolledback_transaction\nfrom pretalx.event.models import Event\n\n\n@contextlib.contextmanager\ndef fake_admin(event):\n    with rolledback_transaction():\n        event.is_public = True\n        event.save()\n        client = Client()\n\n        def get(url):\n            try:\n                # Try getting the file from disk directly first, \u2026\n                return get_mediastatic_content(url)\n            except FileNotFoundError:\n                # \u2026 then fall back to asking the views.\n                response = client.get(url, is_html_export=True, HTTP_ACCEPT=\"text/html\")\n                content = get_content(response)\n                return content\n\n        yield get\n\n\ndef find_assets(html):\n    \"\"\"Find URLs of images, style sheets and scripts included in `html`.\"\"\"\n    soup = BeautifulSoup(html, \"lxml\")\n\n    for asset in soup.find_all([\"script\", \"img\"]):\n        yield asset.attrs[\"src\"]\n    for asset in soup.find_all([\"link\"]):\n        if asset.attrs[\"rel\"][0] in [\"icon\", \"stylesheet\"]:\n            yield asset.attrs[\"href\"]\n\n\ndef find_urls(css):\n    return re.findall(r'url\\(\"?(/[^\")]+)\"?\\)', css.decode(\"utf-8\"), re.IGNORECASE)\n\n\ndef event_talk_urls(event):\n    for talk in event.talks:\n        yield talk.urls.public\n        yield talk.urls.ical\n\n        for resource in talk.active_resources:\n            if resource.resource and resource.resource.url:\n                yield resource.resource.url\n\n\ndef event_speaker_urls(event):\n    for speaker in event.speakers:\n        profile = speaker.event_profile(event)\n        yield profile.urls.public\n        yield profile.urls.talks_ical\n\n\ndef event_exporter_urls(event):\n    for _, exporter in register_data_exporters.send(event):\n        if exporter.public:\n            yield exporter(event).urls.base\n\n\ndef schedule_version_urls(event):\n    for schedule in event.schedules.filter(version__isnull=False):\n        yield schedule.urls.public\n        yield schedule.urls.widget_data\n        yield schedule.urls.nojs\n\n\ndef event_urls(event):\n    yield event.urls.base\n    yield event.urls.schedule\n    yield event.urls.schedule_nojs\n    yield event.urls.widget_data\n    yield from schedule_version_urls(event)\n    yield event.urls.featured\n    yield event.urls.talks\n    yield from event_talk_urls(event)\n    yield event.urls.speakers\n    yield from event_speaker_urls(event)\n    yield from event_exporter_urls(event)\n    yield event.urls.changelog\n    yield event.urls.feed\n\n\ndef get_path(url):\n    return urllib.parse.urlparse(url).path\n\n\ndef get_content(response):\n    return (\n        b\"\".join(response.streaming_content) if response.streaming else response.content\n    )\n\n\ndef dump_content(destination, path, getter):\n    logging.debug(path)\n    content = getter(path)\n    if path.endswith(\"/\"):\n        path = path + \"index.html\"\n\n    path = (Path(destination) / path.lstrip(\"/\")).resolve()\n    if not Path(destination) in path.parents:\n        raise CommandError(\"Path traversal detected, aborting.\")\n    path.parent.mkdir(parents=True, exist_ok=True)\n\n    with open(path, \"wb\") as f:\n        f.write(content)\n    return content\n\n\ndef get_mediastatic_content(url):\n    if url.startswith(settings.STATIC_URL):\n        local_path = settings.STATIC_ROOT / url[len(settings.STATIC_URL) :]\n    elif url.startswith(settings.MEDIA_URL):\n        local_path = settings.MEDIA_ROOT / url[len(settings.MEDIA_URL) :]\n    else:\n        raise FileNotFoundError()\n\n    # Prevent directory traversal, make sure the path is inside the media or static root\n    local_path = local_path.resolve(strict=True)\n    if not any(\n        path in local_path.parents\n        for path in (settings.MEDIA_ROOT, settings.STATIC_ROOT)\n    ):\n        raise FileNotFoundError()\n\n    with open(local_path, \"rb\") as f:\n        return f.read()\n\n\ndef export_event(event, destination):\n    with override_settings(\n        COMPRESS_ENABLED=True, COMPRESS_OFFLINE=True\n    ), override_timezone(event.timezone):\n        with fake_admin(event) as get:\n            logging.info(\"Collecting URLs for export\")\n            urls = [*event_urls(event)]\n            assets = set()\n\n            logging.info(f\"Exporting {len(urls)} pages\")\n            for url in map(get_path, urls):\n                content = dump_content(destination, url, get)\n                assets |= set(map(get_path, find_assets(content)))\n\n            css_assets = set()\n\n            logging.info(f\"Exporting {len(assets)} static files from HTML links\")\n            for url in assets:\n                content = dump_content(destination, url, get)\n\n                if url.endswith(\".css\"):\n                    css_assets |= set(find_urls(content))\n\n            logging.info(f\"Exporting {len(css_assets)} files from CSS links\")\n            for url_path in (get_path(urllib.parse.unquote(url)) for url in css_assets):\n                dump_content(destination, url_path, get)\n\n\ndef delete_directory(path):\n    with contextlib.suppress(FileNotFoundError):\n        shutil.rmtree(path)\n\n\ndef get_export_path(event):\n    return settings.HTMLEXPORT_ROOT / event.slug\n\n\ndef get_export_zip_path(event):\n    return get_export_path(event).with_suffix(\".zip\")\n\n\nclass Command(BaseCommand):\n    def add_arguments(self, parser):\n        super().add_arguments(parser)\n        parser.add_argument(\"event\", type=str)\n        parser.add_argument(\"--zip\", action=\"store_true\")\n\n    def handle(self, *args, **options):\n        event_slug = options.get(\"event\")\n\n        with scopes_disabled():\n            try:\n                event = Event.objects.get(slug__iexact=event_slug)\n            except Event.DoesNotExist:\n                raise CommandError(f'Could not find event with slug \"{event_slug}\".')\n\n        with scope(event=event):\n            logging.info(f\"Exporting {event.name}\")\n            export_dir = get_export_path(event)\n            zip_path = get_export_zip_path(event)\n            tmp_dir = export_dir.with_name(export_dir.name + \"-new\")\n\n            delete_directory(tmp_dir)\n            tmp_dir.mkdir()\n\n            try:\n                export_event(event, tmp_dir)\n                delete_directory(export_dir)\n                tmp_dir.rename(export_dir)\n            finally:\n                delete_directory(tmp_dir)\n\n            logging.info(f\"Exported to {export_dir}\")\n\n            if options.get(\"zip\"):\n                make_archive(\n                    root_dir=settings.HTMLEXPORT_ROOT,\n                    base_dir=event.slug,\n                    base_name=zip_path.parent / zip_path.stem,\n                    format=\"zip\",\n                )\n\n                logging.info(f\"Exported to {zip_path}\")\n"], "filenames": ["src/pretalx/agenda/management/commands/export_schedule_html.py"], "buggy_code_start_loc": [118], "buggy_code_end_loc": [131], "fixing_code_start_loc": [118], "fixing_code_end_loc": [142], "type": "CWE-22", "message": "pretalx 2.3.1 before 2.3.2 allows path traversal in HTML export (a non-default feature). Organizers can trigger the overwriting (with the standard pretalx 404 page content) of an arbitrary file.", "other": {"cve": {"id": "CVE-2023-28458", "sourceIdentifier": "cve@mitre.org", "published": "2023-04-20T21:15:08.770", "lastModified": "2023-05-04T12:38:48.727", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "pretalx 2.3.1 before 2.3.2 allows path traversal in HTML export (a non-default feature). Organizers can trigger the overwriting (with the standard pretalx 404 page content) of an arbitrary file."}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:N/I:L/A:N", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "LOW", "availabilityImpact": "NONE", "baseScore": 4.3, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 2.8, "impactScore": 1.4}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-22"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:pretalx:pretalx:*:*:*:*:*:*:*:*", "versionEndIncluding": "2.3.1", "matchCriteriaId": "C032C969-F9AA-4312-B987-0DD4C8BB6D97"}]}]}], "references": [{"url": "https://github.com/pretalx/pretalx/commit/60722c43cf975f319e94102e6bff320723776890", "source": "cve@mitre.org", "tags": ["Patch"]}, {"url": "https://github.com/pretalx/pretalx/releases/tag/v2.3.2", "source": "cve@mitre.org", "tags": ["Release Notes"]}, {"url": "https://pretalx.com/p/news/security-release-232/", "source": "cve@mitre.org", "tags": ["Vendor Advisory"]}, {"url": "https://www.sonarsource.com/blog/pretalx-vulnerabilities-how-to-get-accepted-at-every-conference/", "source": "cve@mitre.org", "tags": ["Exploit", "Patch", "Third Party Advisory"]}]}, "github_commit_url": "https://github.com/pretalx/pretalx/commit/60722c43cf975f319e94102e6bff320723776890"}}
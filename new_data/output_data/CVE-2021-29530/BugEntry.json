{"buggy_code": ["/* Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n\n#include <atomic>\n#include <numeric>\n#include <vector>\n\n#define EIGEN_USE_THREADS\n\n#include \"third_party/eigen3/Eigen/Core\"\n#include \"third_party/eigen3/Eigen/SparseCholesky\"\n#include \"third_party/eigen3/Eigen/SparseCore\"\n#include \"third_party/eigen3/Eigen/OrderingMethods\"\n#include \"third_party/eigen3/unsupported/Eigen/CXX11/Tensor\"\n#include \"tensorflow/core/framework/op.h\"\n#include \"tensorflow/core/framework/op_kernel.h\"\n#include \"tensorflow/core/framework/tensor_types.h\"\n#include \"tensorflow/core/framework/variant_op_registry.h\"\n#include \"tensorflow/core/kernels/sparse/kernels.h\"\n#include \"tensorflow/core/kernels/sparse/sparse_matrix.h\"\n#include \"tensorflow/core/util/work_sharder.h\"\n\nnamespace tensorflow {\n\n// Op to compute the sparse Cholesky factorization of a sparse matrix.\n//\n// Implements a CPU kernel which returns the lower triangular sparse Cholesky\n// factor of a CSRSparseMatrix, using the fill-in reducing permutation.\n//\n// The CSRSparseMatrix may represent a single sparse matrix (rank 2) or a batch\n// of sparse matrices (rank 3). Each component must represent a symmetric\n// positive definite (SPD) matrix. In particular, this means the component\n// matrices must be square. We don't actually check if the input is symmetric,\n// only the lower triangular part of each component is read.\n//\n// The associated permutation must be a Tensor of rank (R - 1), where the\n// CSRSparseMatrix has rank R. Additionally, the batch dimension of the\n// CSRSparseMatrix and the permutation must be the same. Each batch of\n// the permutation should the contain each of the integers [0,..,N - 1] exactly\n// once, where N is the number of rows of each CSR SparseMatrix component.\n// TODO(anudhyan): Add checks to throw an InvalidArgument error if the\n// permutation is not valid.\n//\n// Returns a CSRSparseMatrix representing the lower triangular (batched)\n// Cholesky factors. It has the same shape as the input CSRSparseMatrix. For\n// each component sparse matrix A, the corresponding output sparse matrix L\n// satisfies the identity:\n//   A = L * Lt\n// where Lt denotes the adjoint of L.\n//\n// TODO(b/126472741): Due to the multiple batches of a 3D CSRSparseMatrix being\n// laid out in contiguous memory, this implementation allocates memory to store\n// a temporary copy of the Cholesky factor. Consequently, it uses roughly twice\n// the amount of memory that it needs to. This may cause a memory blowup for\n// sparse matrices with a high number of non-zero elements.\ntemplate <typename T>\nclass CSRSparseCholeskyCPUOp : public OpKernel {\n  // Note: We operate in column major (CSC) format in this Op since the\n  // SimplicialLLT returns the factor in column major.\n  using SparseMatrix = Eigen::SparseMatrix<T, Eigen::ColMajor>;\n\n public:\n  explicit CSRSparseCholeskyCPUOp(OpKernelConstruction* c) : OpKernel(c) {}\n\n  void Compute(OpKernelContext* ctx) final {\n    // Extract inputs and validate shapes and types.\n    const CSRSparseMatrix* input_matrix;\n    OP_REQUIRES_OK(ctx, ExtractVariantFromInput(ctx, 0, &input_matrix));\n    const Tensor& input_permutation_indices = ctx->input(1);\n\n    int64 num_rows;\n    int batch_size;\n    ValidateInputs(ctx, *input_matrix, input_permutation_indices, &batch_size,\n                   &num_rows);\n\n    // Allocate batch pointers.\n    Tensor batch_ptr(cpu_allocator(), DT_INT32, TensorShape({batch_size + 1}));\n    auto batch_ptr_vec = batch_ptr.vec<int32>();\n    batch_ptr_vec(0) = 0;\n\n    // Temporary vector of Eigen SparseMatrices to store the Sparse Cholesky\n    // factors.\n    // Note: we use column-compressed (CSC) SparseMatrix because SimplicialLLT\n    // returns the factors in column major format. Since our input should be\n    // symmetric, column major and row major is identical in storage. We just\n    // have to switch to reading the upper triangular part of the input, which\n    // corresponds to the lower triangular part in row major format.\n    std::vector<SparseMatrix> sparse_cholesky_factors(batch_size);\n\n    // TODO(anudhyan): Tune the cost per unit based on benchmarks.\n    const double nnz_per_row =\n        (input_matrix->total_nnz() / batch_size) / num_rows;\n    const int64 sparse_cholesky_cost_per_batch =\n        nnz_per_row * nnz_per_row * num_rows;\n    // Perform sparse Cholesky factorization of each batch in parallel.\n    auto worker_threads = *(ctx->device()->tensorflow_cpu_worker_threads());\n    std::atomic<int64> invalid_input_index(-1);\n    Shard(worker_threads.num_threads, worker_threads.workers, batch_size,\n          sparse_cholesky_cost_per_batch,\n          [&](int64 batch_begin, int64 batch_end) {\n            for (int64 batch_index = batch_begin; batch_index < batch_end;\n                 ++batch_index) {\n              // Define an Eigen SparseMatrix Map to operate on the\n              // CSRSparseMatrix component without copying the data.\n              Eigen::Map<const SparseMatrix> sparse_matrix(\n                  num_rows, num_rows, input_matrix->nnz(batch_index),\n                  input_matrix->row_pointers_vec(batch_index).data(),\n                  input_matrix->col_indices_vec(batch_index).data(),\n                  input_matrix->values_vec<T>(batch_index).data());\n\n              Eigen::SimplicialLLT<SparseMatrix, Eigen::Upper,\n                                   Eigen::NaturalOrdering<int>>\n                  solver;\n              auto permutation_indices_flat =\n                  input_permutation_indices.flat<int32>().data();\n\n              // Invert the fill-in reducing ordering and apply it to the input\n              // sparse matrix.\n              Eigen::Map<\n                  Eigen::PermutationMatrix<Eigen::Dynamic, Eigen::Dynamic, int>>\n                  permutation(permutation_indices_flat + batch_index * num_rows,\n                              num_rows);\n              auto permutation_inverse = permutation.inverse();\n\n              SparseMatrix permuted_sparse_matrix;\n              permuted_sparse_matrix.template selfadjointView<Eigen::Upper>() =\n                  sparse_matrix.template selfadjointView<Eigen::Upper>()\n                      .twistedBy(permutation_inverse);\n\n              // Compute the Cholesky decomposition.\n              solver.compute(permuted_sparse_matrix);\n              if (solver.info() != Eigen::Success) {\n                invalid_input_index = batch_index;\n                return;\n              }\n\n              // Get the upper triangular factor, which would end up in the\n              // lower triangular part of the output CSRSparseMatrix when\n              // interpreted in row major format.\n              sparse_cholesky_factors[batch_index] =\n                  std::move(solver.matrixU());\n              // For now, batch_ptr contains the number of nonzeros in each\n              // batch.\n              batch_ptr_vec(batch_index + 1) =\n                  sparse_cholesky_factors[batch_index].nonZeros();\n            }\n          });\n\n    // Check for invalid input.\n    OP_REQUIRES(\n        ctx, invalid_input_index == -1,\n        errors::InvalidArgument(\n            \"Sparse Cholesky factorization failed for batch index \",\n            invalid_input_index.load(), \". The input might not be valid.\"));\n\n    // Compute a cumulative sum to obtain the batch pointers.\n    std::partial_sum(batch_ptr_vec.data(),\n                     batch_ptr_vec.data() + batch_size + 1,\n                     batch_ptr_vec.data());\n\n    // Allocate output Tensors.\n    const int64 total_nnz = batch_ptr_vec(batch_size);\n    Tensor output_row_ptr(cpu_allocator(), DT_INT32,\n                          TensorShape({(num_rows + 1) * batch_size}));\n    Tensor output_col_ind(cpu_allocator(), DT_INT32, TensorShape({total_nnz}));\n    Tensor output_values(cpu_allocator(), DataTypeToEnum<T>::value,\n                         TensorShape({total_nnz}));\n    auto output_row_ptr_ptr = output_row_ptr.flat<int32>().data();\n    auto output_col_ind_ptr = output_col_ind.flat<int32>().data();\n    auto output_values_ptr = output_values.flat<T>().data();\n\n    // Copy the output matrices from each batch into the CSRSparseMatrix\n    // Tensors.\n    // TODO(b/129906419): Factor out the copy from Eigen SparseMatrix to\n    // CSRSparseMatrix into common utils. This is also used in\n    // SparseMatrixSparseMatMul.\n    Shard(worker_threads.num_threads, worker_threads.workers, batch_size,\n          (3 * total_nnz) / batch_size /* cost per unit */,\n          [&](int64 batch_begin, int64 batch_end) {\n            for (int64 batch_index = batch_begin; batch_index < batch_end;\n                 ++batch_index) {\n              const SparseMatrix& cholesky_factor =\n                  sparse_cholesky_factors[batch_index];\n              const int64 nnz = cholesky_factor.nonZeros();\n\n              std::copy(cholesky_factor.outerIndexPtr(),\n                        cholesky_factor.outerIndexPtr() + num_rows + 1,\n                        output_row_ptr_ptr + batch_index * (num_rows + 1));\n              std::copy(cholesky_factor.innerIndexPtr(),\n                        cholesky_factor.innerIndexPtr() + nnz,\n                        output_col_ind_ptr + batch_ptr_vec(batch_index));\n              std::copy(cholesky_factor.valuePtr(),\n                        cholesky_factor.valuePtr() + nnz,\n                        output_values_ptr + batch_ptr_vec(batch_index));\n            }\n          });\n\n    // Create the CSRSparseMatrix instance from its component Tensors and\n    // prepare the Variant output Tensor.\n    CSRSparseMatrix output_csr_matrix;\n    OP_REQUIRES_OK(\n        ctx,\n        CSRSparseMatrix::CreateCSRSparseMatrix(\n            DataTypeToEnum<T>::value, input_matrix->dense_shape(), batch_ptr,\n            output_row_ptr, output_col_ind, output_values, &output_csr_matrix));\n    Tensor* output_csr_matrix_tensor;\n    AllocatorAttributes cpu_alloc;\n    cpu_alloc.set_on_host(true);\n    OP_REQUIRES_OK(\n        ctx, ctx->allocate_output(0, TensorShape({}), &output_csr_matrix_tensor,\n                                  cpu_alloc));\n    output_csr_matrix_tensor->scalar<Variant>()() =\n        std::move(output_csr_matrix);\n  }\n\n private:\n  void ValidateInputs(OpKernelContext* ctx,\n                      const CSRSparseMatrix& sparse_matrix,\n                      const Tensor& permutation_indices, int* batch_size,\n                      int64* num_rows) {\n    OP_REQUIRES(ctx, sparse_matrix.dtype() == DataTypeToEnum<T>::value,\n                errors::InvalidArgument(\n                    \"Asked for a CSRSparseMatrix of type \",\n                    DataTypeString(DataTypeToEnum<T>::value),\n                    \" but saw dtype: \", DataTypeString(sparse_matrix.dtype())));\n\n    const Tensor& dense_shape = sparse_matrix.dense_shape();\n    const int rank = dense_shape.dim_size(0);\n    OP_REQUIRES(ctx, rank == 2 || rank == 3,\n                errors::InvalidArgument(\"sparse matrix must have rank 2 or 3; \",\n                                        \"but dense_shape has size \", rank));\n    const int row_dim = (rank == 2) ? 0 : 1;\n    auto dense_shape_vec = dense_shape.vec<int64>();\n    *num_rows = dense_shape_vec(row_dim);\n    const int64 num_cols = dense_shape_vec(row_dim + 1);\n    OP_REQUIRES(ctx, *num_rows == num_cols,\n                errors::InvalidArgument(\"sparse matrix must be square; got: \",\n                                        *num_rows, \" != \", num_cols));\n    const TensorShape& perm_shape = permutation_indices.shape();\n    OP_REQUIRES(\n        ctx, perm_shape.dims() + 1 == rank,\n        errors::InvalidArgument(\n            \"sparse matrix must have the same rank as permutation; got: \", rank,\n            \" != \", perm_shape.dims(), \" + 1.\"));\n    OP_REQUIRES(\n        ctx, perm_shape.dim_size(rank - 2) == *num_rows,\n        errors::InvalidArgument(\n            \"permutation must have the same number of elements in each batch \"\n            \"as the number of rows in sparse matrix; got: \",\n            perm_shape.dim_size(rank - 2), \" != \", *num_rows));\n\n    *batch_size = sparse_matrix.batch_size();\n    if (*batch_size > 1) {\n      OP_REQUIRES(\n          ctx, perm_shape.dim_size(0) == *batch_size,\n          errors::InvalidArgument(\"permutation must have the same batch size \"\n                                  \"as sparse matrix; got: \",\n                                  perm_shape.dim_size(0), \" != \", *batch_size));\n    }\n  }\n};\n\n#define REGISTER_CPU(T)                                      \\\n  REGISTER_KERNEL_BUILDER(Name(\"SparseMatrixSparseCholesky\") \\\n                              .Device(DEVICE_CPU)            \\\n                              .TypeConstraint<T>(\"type\"),    \\\n                          CSRSparseCholeskyCPUOp<T>);\nREGISTER_CPU(float);\nREGISTER_CPU(double);\nREGISTER_CPU(complex64);\nREGISTER_CPU(complex128);\n\n#undef REGISTER_CPU\n\n}  // namespace tensorflow\n"], "fixing_code": ["/* Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n\n#include <atomic>\n#include <numeric>\n#include <vector>\n\n#include \"tensorflow/core/framework/op_requires.h\"\n\n#define EIGEN_USE_THREADS\n\n#include \"third_party/eigen3/Eigen/Core\"\n#include \"third_party/eigen3/Eigen/SparseCholesky\"\n#include \"third_party/eigen3/Eigen/SparseCore\"\n#include \"third_party/eigen3/Eigen/OrderingMethods\"\n#include \"third_party/eigen3/unsupported/Eigen/CXX11/Tensor\"\n#include \"tensorflow/core/framework/op.h\"\n#include \"tensorflow/core/framework/op_kernel.h\"\n#include \"tensorflow/core/framework/tensor_types.h\"\n#include \"tensorflow/core/framework/variant_op_registry.h\"\n#include \"tensorflow/core/kernels/sparse/kernels.h\"\n#include \"tensorflow/core/kernels/sparse/sparse_matrix.h\"\n#include \"tensorflow/core/util/work_sharder.h\"\n\nnamespace tensorflow {\n\n// Op to compute the sparse Cholesky factorization of a sparse matrix.\n//\n// Implements a CPU kernel which returns the lower triangular sparse Cholesky\n// factor of a CSRSparseMatrix, using the fill-in reducing permutation.\n//\n// The CSRSparseMatrix may represent a single sparse matrix (rank 2) or a batch\n// of sparse matrices (rank 3). Each component must represent a symmetric\n// positive definite (SPD) matrix. In particular, this means the component\n// matrices must be square. We don't actually check if the input is symmetric,\n// only the lower triangular part of each component is read.\n//\n// The associated permutation must be a Tensor of rank (R - 1), where the\n// CSRSparseMatrix has rank R. Additionally, the batch dimension of the\n// CSRSparseMatrix and the permutation must be the same. Each batch of\n// the permutation should the contain each of the integers [0,..,N - 1] exactly\n// once, where N is the number of rows of each CSR SparseMatrix component.\n// TODO(anudhyan): Add checks to throw an InvalidArgument error if the\n// permutation is not valid.\n//\n// Returns a CSRSparseMatrix representing the lower triangular (batched)\n// Cholesky factors. It has the same shape as the input CSRSparseMatrix. For\n// each component sparse matrix A, the corresponding output sparse matrix L\n// satisfies the identity:\n//   A = L * Lt\n// where Lt denotes the adjoint of L.\n//\n// TODO(b/126472741): Due to the multiple batches of a 3D CSRSparseMatrix being\n// laid out in contiguous memory, this implementation allocates memory to store\n// a temporary copy of the Cholesky factor. Consequently, it uses roughly twice\n// the amount of memory that it needs to. This may cause a memory blowup for\n// sparse matrices with a high number of non-zero elements.\ntemplate <typename T>\nclass CSRSparseCholeskyCPUOp : public OpKernel {\n  // Note: We operate in column major (CSC) format in this Op since the\n  // SimplicialLLT returns the factor in column major.\n  using SparseMatrix = Eigen::SparseMatrix<T, Eigen::ColMajor>;\n\n public:\n  explicit CSRSparseCholeskyCPUOp(OpKernelConstruction* c) : OpKernel(c) {}\n\n  void Compute(OpKernelContext* ctx) final {\n    // Extract inputs and validate shapes and types.\n    const CSRSparseMatrix* input_matrix;\n    OP_REQUIRES_OK(ctx, ExtractVariantFromInput(ctx, 0, &input_matrix));\n    const Tensor& input_permutation_indices = ctx->input(1);\n\n    int64 num_rows;\n    int batch_size;\n    OP_REQUIRES_OK(ctx, ValidateInputs(*input_matrix, input_permutation_indices,\n                                       &batch_size, &num_rows));\n\n    // Allocate batch pointers.\n    Tensor batch_ptr(cpu_allocator(), DT_INT32, TensorShape({batch_size + 1}));\n    auto batch_ptr_vec = batch_ptr.vec<int32>();\n    batch_ptr_vec(0) = 0;\n\n    // Temporary vector of Eigen SparseMatrices to store the Sparse Cholesky\n    // factors.\n    // Note: we use column-compressed (CSC) SparseMatrix because SimplicialLLT\n    // returns the factors in column major format. Since our input should be\n    // symmetric, column major and row major is identical in storage. We just\n    // have to switch to reading the upper triangular part of the input, which\n    // corresponds to the lower triangular part in row major format.\n    std::vector<SparseMatrix> sparse_cholesky_factors(batch_size);\n\n    // TODO(anudhyan): Tune the cost per unit based on benchmarks.\n    const double nnz_per_row =\n        (input_matrix->total_nnz() / batch_size) / num_rows;\n    const int64 sparse_cholesky_cost_per_batch =\n        nnz_per_row * nnz_per_row * num_rows;\n    // Perform sparse Cholesky factorization of each batch in parallel.\n    auto worker_threads = *(ctx->device()->tensorflow_cpu_worker_threads());\n    std::atomic<int64> invalid_input_index(-1);\n    Shard(worker_threads.num_threads, worker_threads.workers, batch_size,\n          sparse_cholesky_cost_per_batch,\n          [&](int64 batch_begin, int64 batch_end) {\n            for (int64 batch_index = batch_begin; batch_index < batch_end;\n                 ++batch_index) {\n              // Define an Eigen SparseMatrix Map to operate on the\n              // CSRSparseMatrix component without copying the data.\n              Eigen::Map<const SparseMatrix> sparse_matrix(\n                  num_rows, num_rows, input_matrix->nnz(batch_index),\n                  input_matrix->row_pointers_vec(batch_index).data(),\n                  input_matrix->col_indices_vec(batch_index).data(),\n                  input_matrix->values_vec<T>(batch_index).data());\n\n              Eigen::SimplicialLLT<SparseMatrix, Eigen::Upper,\n                                   Eigen::NaturalOrdering<int>>\n                  solver;\n              auto permutation_indices_flat =\n                  input_permutation_indices.flat<int32>().data();\n\n              // Invert the fill-in reducing ordering and apply it to the input\n              // sparse matrix.\n              Eigen::Map<\n                  Eigen::PermutationMatrix<Eigen::Dynamic, Eigen::Dynamic, int>>\n                  permutation(permutation_indices_flat + batch_index * num_rows,\n                              num_rows);\n              auto permutation_inverse = permutation.inverse();\n\n              SparseMatrix permuted_sparse_matrix;\n              permuted_sparse_matrix.template selfadjointView<Eigen::Upper>() =\n                  sparse_matrix.template selfadjointView<Eigen::Upper>()\n                      .twistedBy(permutation_inverse);\n\n              // Compute the Cholesky decomposition.\n              solver.compute(permuted_sparse_matrix);\n              if (solver.info() != Eigen::Success) {\n                invalid_input_index = batch_index;\n                return;\n              }\n\n              // Get the upper triangular factor, which would end up in the\n              // lower triangular part of the output CSRSparseMatrix when\n              // interpreted in row major format.\n              sparse_cholesky_factors[batch_index] =\n                  std::move(solver.matrixU());\n              // For now, batch_ptr contains the number of nonzeros in each\n              // batch.\n              batch_ptr_vec(batch_index + 1) =\n                  sparse_cholesky_factors[batch_index].nonZeros();\n            }\n          });\n\n    // Check for invalid input.\n    OP_REQUIRES(\n        ctx, invalid_input_index == -1,\n        errors::InvalidArgument(\n            \"Sparse Cholesky factorization failed for batch index \",\n            invalid_input_index.load(), \". The input might not be valid.\"));\n\n    // Compute a cumulative sum to obtain the batch pointers.\n    std::partial_sum(batch_ptr_vec.data(),\n                     batch_ptr_vec.data() + batch_size + 1,\n                     batch_ptr_vec.data());\n\n    // Allocate output Tensors.\n    const int64 total_nnz = batch_ptr_vec(batch_size);\n    Tensor output_row_ptr(cpu_allocator(), DT_INT32,\n                          TensorShape({(num_rows + 1) * batch_size}));\n    Tensor output_col_ind(cpu_allocator(), DT_INT32, TensorShape({total_nnz}));\n    Tensor output_values(cpu_allocator(), DataTypeToEnum<T>::value,\n                         TensorShape({total_nnz}));\n    auto output_row_ptr_ptr = output_row_ptr.flat<int32>().data();\n    auto output_col_ind_ptr = output_col_ind.flat<int32>().data();\n    auto output_values_ptr = output_values.flat<T>().data();\n\n    // Copy the output matrices from each batch into the CSRSparseMatrix\n    // Tensors.\n    // TODO(b/129906419): Factor out the copy from Eigen SparseMatrix to\n    // CSRSparseMatrix into common utils. This is also used in\n    // SparseMatrixSparseMatMul.\n    Shard(worker_threads.num_threads, worker_threads.workers, batch_size,\n          (3 * total_nnz) / batch_size /* cost per unit */,\n          [&](int64 batch_begin, int64 batch_end) {\n            for (int64 batch_index = batch_begin; batch_index < batch_end;\n                 ++batch_index) {\n              const SparseMatrix& cholesky_factor =\n                  sparse_cholesky_factors[batch_index];\n              const int64 nnz = cholesky_factor.nonZeros();\n\n              std::copy(cholesky_factor.outerIndexPtr(),\n                        cholesky_factor.outerIndexPtr() + num_rows + 1,\n                        output_row_ptr_ptr + batch_index * (num_rows + 1));\n              std::copy(cholesky_factor.innerIndexPtr(),\n                        cholesky_factor.innerIndexPtr() + nnz,\n                        output_col_ind_ptr + batch_ptr_vec(batch_index));\n              std::copy(cholesky_factor.valuePtr(),\n                        cholesky_factor.valuePtr() + nnz,\n                        output_values_ptr + batch_ptr_vec(batch_index));\n            }\n          });\n\n    // Create the CSRSparseMatrix instance from its component Tensors and\n    // prepare the Variant output Tensor.\n    CSRSparseMatrix output_csr_matrix;\n    OP_REQUIRES_OK(\n        ctx,\n        CSRSparseMatrix::CreateCSRSparseMatrix(\n            DataTypeToEnum<T>::value, input_matrix->dense_shape(), batch_ptr,\n            output_row_ptr, output_col_ind, output_values, &output_csr_matrix));\n    Tensor* output_csr_matrix_tensor;\n    AllocatorAttributes cpu_alloc;\n    cpu_alloc.set_on_host(true);\n    OP_REQUIRES_OK(\n        ctx, ctx->allocate_output(0, TensorShape({}), &output_csr_matrix_tensor,\n                                  cpu_alloc));\n    output_csr_matrix_tensor->scalar<Variant>()() =\n        std::move(output_csr_matrix);\n  }\n\n private:\n  Status ValidateInputs(const CSRSparseMatrix& sparse_matrix,\n                        const Tensor& permutation_indices, int* batch_size,\n                        int64* num_rows) {\n    if (sparse_matrix.dtype() != DataTypeToEnum<T>::value)\n      return errors::InvalidArgument(\n          \"Asked for a CSRSparseMatrix of type \",\n          DataTypeString(DataTypeToEnum<T>::value),\n          \" but saw dtype: \", DataTypeString(sparse_matrix.dtype()));\n\n    const Tensor& dense_shape = sparse_matrix.dense_shape();\n    const int rank = dense_shape.dim_size(0);\n    if (rank < 2 || rank > 3)\n      return errors::InvalidArgument(\"sparse matrix must have rank 2 or 3; \",\n                                     \"but dense_shape has size \", rank);\n    const int row_dim = (rank == 2) ? 0 : 1;\n    auto dense_shape_vec = dense_shape.vec<int64>();\n    *num_rows = dense_shape_vec(row_dim);\n    const int64 num_cols = dense_shape_vec(row_dim + 1);\n    if (*num_rows != num_cols)\n      return errors::InvalidArgument(\n          \"sparse matrix must be square; got: \", *num_rows, \" != \", num_cols);\n    const TensorShape& perm_shape = permutation_indices.shape();\n    if (perm_shape.dims() + 1 != rank)\n      return errors::InvalidArgument(\n          \"sparse matrix must have the same rank as permutation; got: \", rank,\n          \" != \", perm_shape.dims(), \" + 1.\");\n    if (perm_shape.dim_size(rank - 2) != *num_rows)\n      return errors::InvalidArgument(\n          \"permutation must have the same number of elements in each batch \"\n          \"as the number of rows in sparse matrix; got: \",\n          perm_shape.dim_size(rank - 2), \" != \", *num_rows);\n\n    *batch_size = sparse_matrix.batch_size();\n    if (*batch_size > 1) {\n      if (perm_shape.dim_size(0) != *batch_size)\n        return errors::InvalidArgument(\n            \"permutation must have the same batch size \"\n            \"as sparse matrix; got: \",\n            perm_shape.dim_size(0), \" != \", *batch_size);\n    }\n\n    return Status::OK();\n  }\n};\n\n#define REGISTER_CPU(T)                                      \\\n  REGISTER_KERNEL_BUILDER(Name(\"SparseMatrixSparseCholesky\") \\\n                              .Device(DEVICE_CPU)            \\\n                              .TypeConstraint<T>(\"type\"),    \\\n                          CSRSparseCholeskyCPUOp<T>);\nREGISTER_CPU(float);\nREGISTER_CPU(double);\nREGISTER_CPU(complex64);\nREGISTER_CPU(complex128);\n\n#undef REGISTER_CPU\n\n}  // namespace tensorflow\n"], "filenames": ["tensorflow/core/kernels/sparse/sparse_cholesky_op.cc"], "buggy_code_start_loc": [18], "buggy_code_end_loc": [271], "fixing_code_start_loc": [19], "fixing_code_end_loc": [273], "type": "CWE-476", "message": "TensorFlow is an end-to-end open source platform for machine learning. An attacker can trigger a null pointer dereference by providing an invalid `permutation` to `tf.raw_ops.SparseMatrixSparseCholesky`. This is because the implementation(https://github.com/tensorflow/tensorflow/blob/080f1d9e257589f78b3ffb75debf584168aa6062/tensorflow/core/kernels/sparse/sparse_cholesky_op.cc#L85-L86) fails to properly validate the input arguments. Although `ValidateInputs` is called and there are checks in the body of this function, the code proceeds to the next line in `ValidateInputs` since `OP_REQUIRES`(https://github.com/tensorflow/tensorflow/blob/080f1d9e257589f78b3ffb75debf584168aa6062/tensorflow/core/framework/op_requires.h#L41-L48) is a macro that only exits the current function. Thus, the first validation condition that fails in `ValidateInputs` will cause an early return from that function. However, the caller will continue execution from the next line. The fix is to either explicitly check `context->status()` or to convert `ValidateInputs` to return a `Status`. The fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.", "other": {"cve": {"id": "CVE-2021-29530", "sourceIdentifier": "security-advisories@github.com", "published": "2021-05-14T20:15:11.983", "lastModified": "2021-05-20T15:49:10.877", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "TensorFlow is an end-to-end open source platform for machine learning. An attacker can trigger a null pointer dereference by providing an invalid `permutation` to `tf.raw_ops.SparseMatrixSparseCholesky`. This is because the implementation(https://github.com/tensorflow/tensorflow/blob/080f1d9e257589f78b3ffb75debf584168aa6062/tensorflow/core/kernels/sparse/sparse_cholesky_op.cc#L85-L86) fails to properly validate the input arguments. Although `ValidateInputs` is called and there are checks in the body of this function, the code proceeds to the next line in `ValidateInputs` since `OP_REQUIRES`(https://github.com/tensorflow/tensorflow/blob/080f1d9e257589f78b3ffb75debf584168aa6062/tensorflow/core/framework/op_requires.h#L41-L48) is a macro that only exits the current function. Thus, the first validation condition that fails in `ValidateInputs` will cause an early return from that function. However, the caller will continue execution from the next line. The fix is to either explicitly check `context->status()` or to convert `ValidateInputs` to return a `Status`. The fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range."}, {"lang": "es", "value": "TensorFlow es una plataforma de c\u00f3digo abierto de extremo a extremo para el aprendizaje autom\u00e1tico.&#xa0;Un atacante puede desencadenar una desreferencia de puntero null proporcionando una \"permutation\" no v\u00e1lida a \"tf.raw_ops.SparseMatrixSparseCholesky\".&#xa0;Esto es debido a que la implementaci\u00f3n (https://github.com/tensorflow/tensorflow/blob/080f1d9e257589f78b3ffb75debf584168aa6062/tensorflow/core/kernels/sparse/sparse_cholesky_op.cc#L85-L86) no comprueba apropiadamente los argumentos de entrada.&#xa0;Aunque se llama a \"ValidateInputs\" y se presentan comprobaciones en el cuerpo de esta funci\u00f3n, el c\u00f3digo pasa a la siguiente l\u00ednea en \"ValidateInputs\" desde \"OP_REQUIRES\" (https://github.com/tensorflow/tensorflow/blob/080f1d9e257589f78b3ffb75debf584168aa6062/tensorflow /core/framework/op_requires.h#L41-L48) es una macro que solo sale de la funci\u00f3n actual.&#xa0;Por lo tanto,&#xa0;la primera condici\u00f3n de comprobaci\u00f3n que fallo en \"ValidateInputs\" causar\u00e1 un retorno anticipado de esa funci\u00f3n.&#xa0;Sin embargo, la persona que llama continuar\u00e1 una ejecuci\u00f3n desde la siguiente l\u00ednea.&#xa0;La correcci\u00f3n es comprobar expl\u00edcitamente \"context-) status()\" o convertir \"ValidateInputs\" para devolver un\" Status\".&#xa0;La correcci\u00f3n ser\u00e1 incluida en TensorFlow versi\u00f3n 2.5.0.&#xa0;Tambi\u00e9n seleccionaremos este commit en TensorFlow versi\u00f3n 2.4.2, TensorFlow versi\u00f3n 2.3.3, TensorFlow versi\u00f3n 2.2.3 y TensorFlow versi\u00f3n 2.1.4, ya que estos tambi\u00e9n est\u00e1n afectados y a\u00fan est\u00e1n en el rango compatible"}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:L/AC:L/PR:L/UI:N/S:U/C:H/I:H/A:H", "attackVector": "LOCAL", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "HIGH", "availabilityImpact": "HIGH", "baseScore": 7.8, "baseSeverity": "HIGH"}, "exploitabilityScore": 1.8, "impactScore": 5.9}, {"source": "security-advisories@github.com", "type": "Secondary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:L/AC:H/PR:L/UI:N/S:U/C:N/I:N/A:L", "attackVector": "LOCAL", "attackComplexity": "HIGH", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "LOW", "baseScore": 2.5, "baseSeverity": "LOW"}, "exploitabilityScore": 1.0, "impactScore": 1.4}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:L/AC:L/Au:N/C:P/I:P/A:P", "accessVector": "LOCAL", "accessComplexity": "LOW", "authentication": "NONE", "confidentialityImpact": "PARTIAL", "integrityImpact": "PARTIAL", "availabilityImpact": "PARTIAL", "baseScore": 4.6}, "baseSeverity": "MEDIUM", "exploitabilityScore": 3.9, "impactScore": 6.4, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "security-advisories@github.com", "type": "Primary", "description": [{"lang": "en", "value": "CWE-476"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:*:*:*:*:*:*:*:*", "versionEndExcluding": "2.1.4", "matchCriteriaId": "323ABCCE-24EB-47CC-87F6-48C101477587"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:*:*:*:*:*:*:*:*", "versionStartIncluding": "2.2.0", "versionEndExcluding": "2.2.3", "matchCriteriaId": "64ABA90C-0649-4BB0-89C9-83C14BBDCC0F"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:*:*:*:*:*:*:*:*", "versionStartIncluding": "2.3.0", "versionEndExcluding": "2.3.3", "matchCriteriaId": "0F83E0CF-CBF6-4C24-8683-3E7A5DC95BA9"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:*:*:*:*:*:*:*:*", "versionStartIncluding": "2.4.0", "versionEndExcluding": "2.4.2", "matchCriteriaId": "8259531B-A8AC-4F8B-B60F-B69DE4767C03"}]}]}], "references": [{"url": "https://github.com/tensorflow/tensorflow/commit/e6a7c7cc18c3aaad1ae0872cb0a959f5c923d2bd", "source": "security-advisories@github.com", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-xcwj-wfcm-m23c", "source": "security-advisories@github.com", "tags": ["Exploit", "Patch", "Third Party Advisory"]}]}, "github_commit_url": "https://github.com/tensorflow/tensorflow/commit/e6a7c7cc18c3aaad1ae0872cb0a959f5c923d2bd"}}
{"buggy_code": ["import datetime\nimport hashlib\nimport itertools\nimport logging\nimport os\nimport time\nfrom collections import defaultdict\nfrom dataclasses import asdict, dataclass, field\nfrom operator import itemgetter\nfrom typing import (\n    IO,\n    AbstractSet,\n    Any,\n    Callable,\n    Collection,\n    Dict,\n    Iterable,\n    List,\n    Mapping,\n    Optional,\n    Sequence,\n    Set,\n    Tuple,\n    Union,\n)\n\nimport django.db.utils\nimport orjson\nfrom django.conf import settings\nfrom django.contrib.contenttypes.models import ContentType\nfrom django.core.exceptions import ValidationError\nfrom django.db import IntegrityError, connection, transaction\nfrom django.db.models import Count, Exists, F, OuterRef, Q, Sum\nfrom django.db.models.query import QuerySet\nfrom django.utils.html import escape\nfrom django.utils.timezone import now as timezone_now\nfrom django.utils.translation import gettext as _\nfrom django.utils.translation import gettext_lazy\nfrom django.utils.translation import override as override_language\nfrom psycopg2.extras import execute_values\nfrom psycopg2.sql import SQL\nfrom typing_extensions import TypedDict\n\nfrom analytics.lib.counts import COUNT_STATS, do_increment_logging_stat\nfrom analytics.models import RealmCount\nfrom confirmation import settings as confirmation_settings\nfrom confirmation.models import (\n    Confirmation,\n    confirmation_url,\n    create_confirmation_link,\n    generate_key,\n)\nfrom zerver.decorator import statsd_increment\nfrom zerver.lib import retention as retention\nfrom zerver.lib.addressee import Addressee\nfrom zerver.lib.alert_words import (\n    add_user_alert_words,\n    get_alert_word_automaton,\n    remove_user_alert_words,\n)\nfrom zerver.lib.avatar import avatar_url, avatar_url_from_dict\nfrom zerver.lib.bot_config import ConfigError, get_bot_config, get_bot_configs, set_bot_config\nfrom zerver.lib.bulk_create import bulk_create_users\nfrom zerver.lib.cache import (\n    bot_dict_fields,\n    cache_delete,\n    cache_delete_many,\n    cache_set,\n    cache_set_many,\n    cache_with_key,\n    delete_user_profile_caches,\n    display_recipient_cache_key,\n    flush_user_profile,\n    get_stream_cache_key,\n    to_dict_cache_key_id,\n    user_profile_by_api_key_cache_key,\n    user_profile_delivery_email_cache_key,\n)\nfrom zerver.lib.create_user import create_user, get_display_email_address\nfrom zerver.lib.email_mirror_helpers import encode_email_address\nfrom zerver.lib.email_notifications import enqueue_welcome_emails\nfrom zerver.lib.email_validation import (\n    email_reserved_for_system_bots_error,\n    get_existing_user_errors,\n    get_realm_email_validator,\n    validate_email_is_valid,\n)\nfrom zerver.lib.emoji import check_emoji_request, emoji_name_to_emoji_code, get_emoji_file_name\nfrom zerver.lib.exceptions import (\n    InvitationError,\n    JsonableError,\n    MarkdownRenderingException,\n    StreamDoesNotExistError,\n    StreamWithIDDoesNotExistError,\n    ZephyrMessageAlreadySentException,\n)\nfrom zerver.lib.export import get_realm_exports_serialized\nfrom zerver.lib.external_accounts import DEFAULT_EXTERNAL_ACCOUNTS\nfrom zerver.lib.hotspots import get_next_hotspots\nfrom zerver.lib.i18n import get_language_name\nfrom zerver.lib.markdown import MessageRenderingResult, topic_links\nfrom zerver.lib.markdown import version as markdown_version\nfrom zerver.lib.mention import MentionBackend, MentionData, silent_mention_syntax_for_user\nfrom zerver.lib.message import (\n    MessageDict,\n    SendMessageRequest,\n    access_message,\n    bulk_access_messages,\n    get_last_message_id,\n    normalize_body,\n    render_markdown,\n    truncate_topic,\n    update_first_visible_message_id,\n    wildcard_mention_allowed,\n)\nfrom zerver.lib.notification_data import UserMessageNotificationsData, get_user_group_mentions_data\nfrom zerver.lib.pysa import mark_sanitized\nfrom zerver.lib.queue import queue_json_publish\nfrom zerver.lib.realm_icon import realm_icon_url\nfrom zerver.lib.realm_logo import get_realm_logo_data\nfrom zerver.lib.retention import move_messages_to_archive\nfrom zerver.lib.send_email import (\n    FromAddress,\n    clear_scheduled_emails,\n    clear_scheduled_invitation_emails,\n    send_email,\n    send_email_to_admins,\n)\nfrom zerver.lib.server_initialization import create_internal_realm, server_initialized\nfrom zerver.lib.sessions import delete_user_sessions\nfrom zerver.lib.storage import static_path\nfrom zerver.lib.stream_color import pick_colors\nfrom zerver.lib.stream_subscription import (\n    SubInfo,\n    bulk_get_private_peers,\n    bulk_get_subscriber_peer_info,\n    get_active_subscriptions_for_stream_id,\n    get_bulk_stream_subscriber_info,\n    get_stream_subscriptions_for_user,\n    get_subscribed_stream_ids_for_user,\n    get_subscriptions_for_send_message,\n    get_used_colors_for_user_ids,\n    get_user_ids_for_streams,\n    num_subscribers_for_stream_id,\n    subscriber_ids_with_stream_history_access,\n)\nfrom zerver.lib.stream_topic import StreamTopicTarget\nfrom zerver.lib.stream_traffic import get_average_weekly_stream_traffic, get_streams_traffic\nfrom zerver.lib.streams import (\n    access_stream_by_id,\n    access_stream_for_send_message,\n    can_access_stream_user_ids,\n    check_stream_access_based_on_stream_post_policy,\n    create_stream_if_needed,\n    get_default_value_for_history_public_to_subscribers,\n    get_stream_permission_policy_name,\n    get_web_public_streams_queryset,\n    render_stream_description,\n    send_stream_creation_event,\n    subscribed_to_stream,\n)\nfrom zerver.lib.string_validation import check_stream_name, check_stream_topic\nfrom zerver.lib.subscription_info import build_stream_dict_for_never_sub, build_stream_dict_for_sub\nfrom zerver.lib.timestamp import datetime_to_timestamp, timestamp_to_datetime\nfrom zerver.lib.timezone import canonicalize_timezone\nfrom zerver.lib.topic import (\n    ORIG_TOPIC,\n    RESOLVED_TOPIC_PREFIX,\n    TOPIC_LINKS,\n    TOPIC_NAME,\n    filter_by_exact_message_topic,\n    filter_by_topic_name_via_message,\n    messages_for_topic,\n    save_message_for_edit_use_case,\n    update_edit_history,\n    update_messages_for_topic_edit,\n)\nfrom zerver.lib.types import (\n    EditHistoryEvent,\n    NeverSubscribedStreamDict,\n    ProfileDataElementValue,\n    ProfileFieldData,\n    RawStreamDict,\n    RawSubscriptionDict,\n    SubscriptionInfo,\n    SubscriptionStreamDict,\n    UnspecifiedValue,\n)\nfrom zerver.lib.upload import (\n    claim_attachment,\n    delete_avatar_image,\n    delete_export_tarball,\n    delete_message_image,\n    upload_emoji_image,\n)\nfrom zerver.lib.user_groups import (\n    access_user_group_by_id,\n    create_system_user_groups_for_realm,\n    create_user_group,\n    get_system_user_group_for_user,\n)\nfrom zerver.lib.user_mutes import add_user_mute, get_muting_users, get_user_mutes\nfrom zerver.lib.user_status import update_user_status\nfrom zerver.lib.user_topics import add_topic_mute, get_topic_mutes, remove_topic_mute\nfrom zerver.lib.users import (\n    check_bot_name_available,\n    check_full_name,\n    format_user_row,\n    get_api_key,\n    user_profile_to_user_row,\n)\nfrom zerver.lib.utils import generate_api_key, log_statsd_event\nfrom zerver.lib.validator import check_widget_content\nfrom zerver.lib.widget import do_widget_post_save_actions, is_widget_message\nfrom zerver.models import (\n    Attachment,\n    Client,\n    CustomProfileField,\n    CustomProfileFieldValue,\n    DefaultStream,\n    DefaultStreamGroup,\n    Draft,\n    EmailChangeStatus,\n    Message,\n    MultiuseInvite,\n    MutedUser,\n    PreregistrationUser,\n    Reaction,\n    Realm,\n    RealmAuditLog,\n    RealmDomain,\n    RealmEmoji,\n    RealmFilter,\n    RealmPlayground,\n    RealmUserDefault,\n    Recipient,\n    ScheduledEmail,\n    ScheduledMessage,\n    ScheduledMessageNotificationEmail,\n    Service,\n    Stream,\n    SubMessage,\n    Subscription,\n    UserActivity,\n    UserActivityInterval,\n    UserGroup,\n    UserGroupMembership,\n    UserHotspot,\n    UserMessage,\n    UserPresence,\n    UserProfile,\n    UserStatus,\n    UserTopic,\n    active_non_guest_user_ids,\n    active_user_ids,\n    custom_profile_fields_for_realm,\n    filter_to_valid_prereg_users,\n    get_active_streams,\n    get_bot_dicts_in_realm,\n    get_bot_services,\n    get_client,\n    get_default_stream_groups,\n    get_fake_email_domain,\n    get_huddle_recipient,\n    get_huddle_user_ids,\n    get_old_unclaimed_attachments,\n    get_realm,\n    get_realm_domains,\n    get_realm_playgrounds,\n    get_stream,\n    get_stream_by_id_in_realm,\n    get_system_bot,\n    get_user_by_delivery_email,\n    get_user_by_id_in_realm_including_cross_realm,\n    get_user_profile_by_id,\n    is_cross_realm_bot_email,\n    linkifiers_for_realm,\n    query_for_ids,\n    realm_filters_for_realm,\n    validate_attachment_request,\n)\nfrom zerver.tornado.django_api import send_event\n\nif settings.BILLING_ENABLED:\n    from corporate.lib.stripe import (\n        downgrade_now_without_creating_additional_invoices,\n        update_license_ledger_if_needed,\n    )\n\n\nONBOARDING_TOTAL_MESSAGES = 1000\nONBOARDING_UNREAD_MESSAGES = 20\nONBOARDING_RECENT_TIMEDELTA = datetime.timedelta(weeks=1)\n\n\ndef create_historical_user_messages(*, user_id: int, message_ids: List[int]) -> None:\n    # Users can see and interact with messages sent to streams with\n    # public history for which they do not have a UserMessage because\n    # they were not a subscriber at the time the message was sent.\n    # In order to add emoji reactions or mutate message flags for\n    # those messages, we create UserMessage objects for those messages;\n    # these have the special historical flag which keeps track of the\n    # fact that the user did not receive the message at the time it was sent.\n    for message_id in message_ids:\n        UserMessage.objects.create(\n            user_profile_id=user_id,\n            message_id=message_id,\n            flags=UserMessage.flags.historical | UserMessage.flags.read,\n        )\n\n\ndef subscriber_info(user_id: int) -> Dict[str, Any]:\n    return {\"id\": user_id, \"flags\": [\"read\"]}\n\n\ndef bot_owner_user_ids(user_profile: UserProfile) -> Set[int]:\n    is_private_bot = (\n        user_profile.default_sending_stream\n        and user_profile.default_sending_stream.invite_only\n        or user_profile.default_events_register_stream\n        and user_profile.default_events_register_stream.invite_only\n    )\n    if is_private_bot:\n        return {user_profile.bot_owner_id}\n    else:\n        users = {user.id for user in user_profile.realm.get_human_admin_users()}\n        users.add(user_profile.bot_owner_id)\n        return users\n\n\ndef realm_user_count(realm: Realm) -> int:\n    return UserProfile.objects.filter(realm=realm, is_active=True, is_bot=False).count()\n\n\ndef realm_user_count_by_role(realm: Realm) -> Dict[str, Any]:\n    human_counts = {\n        str(UserProfile.ROLE_REALM_ADMINISTRATOR): 0,\n        str(UserProfile.ROLE_REALM_OWNER): 0,\n        str(UserProfile.ROLE_MODERATOR): 0,\n        str(UserProfile.ROLE_MEMBER): 0,\n        str(UserProfile.ROLE_GUEST): 0,\n    }\n    for value_dict in list(\n        UserProfile.objects.filter(realm=realm, is_bot=False, is_active=True)\n        .values(\"role\")\n        .annotate(Count(\"role\"))\n    ):\n        human_counts[str(value_dict[\"role\"])] = value_dict[\"role__count\"]\n    bot_count = UserProfile.objects.filter(realm=realm, is_bot=True, is_active=True).count()\n    return {\n        RealmAuditLog.ROLE_COUNT_HUMANS: human_counts,\n        RealmAuditLog.ROLE_COUNT_BOTS: bot_count,\n    }\n\n\ndef get_signups_stream(realm: Realm) -> Stream:\n    # This one-liner helps us work around a lint rule.\n    return get_stream(\"signups\", realm)\n\n\ndef send_message_to_signup_notification_stream(\n    sender: UserProfile, realm: Realm, message: str, topic_name: str = _(\"signups\")\n) -> None:\n    signup_notifications_stream = realm.get_signup_notifications_stream()\n    if signup_notifications_stream is None:\n        return\n\n    with override_language(realm.default_language):\n        internal_send_stream_message(sender, signup_notifications_stream, topic_name, message)\n\n\ndef notify_new_user(user_profile: UserProfile) -> None:\n    user_count = realm_user_count(user_profile.realm)\n    sender_email = settings.NOTIFICATION_BOT\n    sender = get_system_bot(sender_email, user_profile.realm_id)\n\n    is_first_user = user_count == 1\n    if not is_first_user:\n        message = _(\"{user} just signed up for Zulip. (total: {user_count})\").format(\n            user=silent_mention_syntax_for_user(user_profile), user_count=user_count\n        )\n\n        if settings.BILLING_ENABLED:\n            from corporate.lib.registration import generate_licenses_low_warning_message_if_required\n\n            licenses_low_warning_message = generate_licenses_low_warning_message_if_required(\n                user_profile.realm\n            )\n            if licenses_low_warning_message is not None:\n                message += \"\\n\"\n                message += licenses_low_warning_message\n\n        send_message_to_signup_notification_stream(sender, user_profile.realm, message)\n\n    # We also send a notification to the Zulip administrative realm\n    admin_realm = get_realm(settings.SYSTEM_BOT_REALM)\n    admin_realm_sender = get_system_bot(sender_email, admin_realm.id)\n    try:\n        # Check whether the stream exists\n        signups_stream = get_signups_stream(admin_realm)\n        # We intentionally use the same strings as above to avoid translation burden.\n        message = _(\"{user} just signed up for Zulip. (total: {user_count})\").format(\n            user=f\"{user_profile.full_name} <`{user_profile.email}`>\", user_count=user_count\n        )\n        internal_send_stream_message(\n            admin_realm_sender, signups_stream, user_profile.realm.display_subdomain, message\n        )\n\n    except Stream.DoesNotExist:\n        # If the signups stream hasn't been created in the admin\n        # realm, don't auto-create it to send to it; just do nothing.\n        pass\n\n\ndef notify_invites_changed(realm: Realm) -> None:\n    event = dict(type=\"invites_changed\")\n    admin_ids = [user.id for user in realm.get_admin_users_and_bots()]\n    send_event(realm, event, admin_ids)\n\n\ndef add_new_user_history(user_profile: UserProfile, streams: Iterable[Stream]) -> None:\n    \"\"\"Give you the last ONBOARDING_TOTAL_MESSAGES messages on your public\n    streams, so you have something to look at in your home view once\n    you finish the tutorial.  The most recent ONBOARDING_UNREAD_MESSAGES\n    are marked unread.\n    \"\"\"\n    one_week_ago = timezone_now() - ONBOARDING_RECENT_TIMEDELTA\n\n    recipient_ids = [stream.recipient_id for stream in streams if not stream.invite_only]\n    recent_messages = Message.objects.filter(\n        recipient_id__in=recipient_ids, date_sent__gt=one_week_ago\n    ).order_by(\"-id\")\n    message_ids_to_use = list(\n        reversed(recent_messages.values_list(\"id\", flat=True)[0:ONBOARDING_TOTAL_MESSAGES])\n    )\n    if len(message_ids_to_use) == 0:\n        return\n\n    # Handle the race condition where a message arrives between\n    # bulk_add_subscriptions above and the Message query just above\n    already_ids = set(\n        UserMessage.objects.filter(\n            message_id__in=message_ids_to_use, user_profile=user_profile\n        ).values_list(\"message_id\", flat=True)\n    )\n\n    # Mark the newest ONBOARDING_UNREAD_MESSAGES as unread.\n    marked_unread = 0\n    ums_to_create = []\n    for message_id in reversed(message_ids_to_use):\n        if message_id in already_ids:\n            continue\n\n        um = UserMessage(user_profile=user_profile, message_id=message_id)\n        if marked_unread < ONBOARDING_UNREAD_MESSAGES:\n            marked_unread += 1\n        else:\n            um.flags = UserMessage.flags.read\n        ums_to_create.append(um)\n\n    UserMessage.objects.bulk_create(reversed(ums_to_create))\n\n\n# Does the processing for a new user account:\n# * Subscribes to default/invitation streams\n# * Fills in some recent historical messages\n# * Notifies other users in realm and Zulip about the signup\n# * Deactivates PreregistrationUser objects\ndef process_new_human_user(\n    user_profile: UserProfile,\n    prereg_user: Optional[PreregistrationUser] = None,\n    default_stream_groups: Sequence[DefaultStreamGroup] = [],\n    realm_creation: bool = False,\n) -> None:\n    realm = user_profile.realm\n\n    mit_beta_user = realm.is_zephyr_mirror_realm\n    if prereg_user is not None:\n        streams: List[Stream] = list(prereg_user.streams.all())\n        acting_user: Optional[UserProfile] = prereg_user.referred_by\n    else:\n        streams = []\n        acting_user = None\n\n    # If the user's invitation didn't explicitly list some streams, we\n    # add the default streams\n    if len(streams) == 0:\n        streams = get_default_subs(user_profile)\n\n    for default_stream_group in default_stream_groups:\n        default_stream_group_streams = default_stream_group.streams.all()\n        for stream in default_stream_group_streams:\n            if stream not in streams:\n                streams.append(stream)\n\n    bulk_add_subscriptions(\n        realm,\n        streams,\n        [user_profile],\n        from_user_creation=True,\n        acting_user=acting_user,\n    )\n\n    add_new_user_history(user_profile, streams)\n\n    # mit_beta_users don't have a referred_by field\n    if (\n        not mit_beta_user\n        and prereg_user is not None\n        and prereg_user.referred_by is not None\n        and prereg_user.referred_by.is_active\n    ):\n        # This is a cross-realm private message.\n        with override_language(prereg_user.referred_by.default_language):\n            internal_send_private_message(\n                get_system_bot(settings.NOTIFICATION_BOT, prereg_user.referred_by.realm_id),\n                prereg_user.referred_by,\n                _(\"{user} accepted your invitation to join Zulip!\").format(\n                    user=f\"{user_profile.full_name} <`{user_profile.email}`>\"\n                ),\n            )\n\n    revoke_preregistration_users(user_profile, prereg_user, realm_creation)\n    if not realm_creation and prereg_user is not None and prereg_user.referred_by is not None:\n        notify_invites_changed(user_profile.realm)\n\n    notify_new_user(user_profile)\n    # Clear any scheduled invitation emails to prevent them\n    # from being sent after the user is created.\n    clear_scheduled_invitation_emails(user_profile.delivery_email)\n    if realm.send_welcome_emails:\n        enqueue_welcome_emails(user_profile, realm_creation)\n\n    # We have an import loop here; it's intentional, because we want\n    # to keep all the onboarding code in zerver/lib/onboarding.py.\n    from zerver.lib.onboarding import send_initial_pms\n\n    send_initial_pms(user_profile)\n\n\ndef revoke_preregistration_users(\n    created_user_profile: UserProfile,\n    used_preregistration_user: Optional[PreregistrationUser],\n    realm_creation: bool,\n) -> None:\n    if used_preregistration_user is None:\n        assert not realm_creation, \"realm_creation should only happen with a PreregistrationUser\"\n\n    if used_preregistration_user is not None:\n        used_preregistration_user.status = confirmation_settings.STATUS_ACTIVE\n        used_preregistration_user.save(update_fields=[\"status\"])\n\n    # In the special case of realm creation, there can be no additional PreregistrationUser\n    # for us to want to modify - because other realm_creation PreregistrationUsers should be\n    # left usable for creating different realms.\n    if realm_creation:\n        return\n\n    # Mark any other PreregistrationUsers in the realm that are STATUS_ACTIVE as\n    # inactive so we can keep track of the PreregistrationUser we\n    # actually used for analytics.\n    if used_preregistration_user is not None:\n        PreregistrationUser.objects.filter(\n            email__iexact=created_user_profile.delivery_email, realm=created_user_profile.realm\n        ).exclude(id=used_preregistration_user.id).update(\n            status=confirmation_settings.STATUS_REVOKED\n        )\n    else:\n        PreregistrationUser.objects.filter(\n            email__iexact=created_user_profile.delivery_email, realm=created_user_profile.realm\n        ).update(status=confirmation_settings.STATUS_REVOKED)\n\n\ndef notify_created_user(user_profile: UserProfile) -> None:\n    user_row = user_profile_to_user_row(user_profile)\n    person = format_user_row(\n        user_profile.realm,\n        user_profile,\n        user_row,\n        # Since we don't know what the client\n        # supports at this point in the code, we\n        # just assume client_gravatar and\n        # user_avatar_url_field_optional = False :(\n        client_gravatar=False,\n        user_avatar_url_field_optional=False,\n        # We assume there's no custom profile\n        # field data for a new user; initial\n        # values are expected to be added in a\n        # later event.\n        custom_profile_field_data={},\n    )\n    event: Dict[str, Any] = dict(type=\"realm_user\", op=\"add\", person=person)\n    send_event(user_profile.realm, event, active_user_ids(user_profile.realm_id))\n\n\ndef created_bot_event(user_profile: UserProfile) -> Dict[str, Any]:\n    def stream_name(stream: Optional[Stream]) -> Optional[str]:\n        if not stream:\n            return None\n        return stream.name\n\n    default_sending_stream_name = stream_name(user_profile.default_sending_stream)\n    default_events_register_stream_name = stream_name(user_profile.default_events_register_stream)\n\n    bot = dict(\n        email=user_profile.email,\n        user_id=user_profile.id,\n        full_name=user_profile.full_name,\n        bot_type=user_profile.bot_type,\n        is_active=user_profile.is_active,\n        api_key=get_api_key(user_profile),\n        default_sending_stream=default_sending_stream_name,\n        default_events_register_stream=default_events_register_stream_name,\n        default_all_public_streams=user_profile.default_all_public_streams,\n        avatar_url=avatar_url(user_profile),\n        services=get_service_dicts_for_bot(user_profile.id),\n    )\n\n    # Set the owner key only when the bot has an owner.\n    # The default bots don't have an owner. So don't\n    # set the owner key while reactivating them.\n    if user_profile.bot_owner is not None:\n        bot[\"owner_id\"] = user_profile.bot_owner.id\n\n    return dict(type=\"realm_bot\", op=\"add\", bot=bot)\n\n\ndef notify_created_bot(user_profile: UserProfile) -> None:\n    event = created_bot_event(user_profile)\n    send_event(user_profile.realm, event, bot_owner_user_ids(user_profile))\n\n\ndef create_users(\n    realm: Realm, name_list: Iterable[Tuple[str, str]], bot_type: Optional[int] = None\n) -> None:\n    user_set = set()\n    for full_name, email in name_list:\n        user_set.add((email, full_name, True))\n    bulk_create_users(realm, user_set, bot_type)\n\n\ndef do_create_user(\n    email: str,\n    password: Optional[str],\n    realm: Realm,\n    full_name: str,\n    bot_type: Optional[int] = None,\n    role: Optional[int] = None,\n    bot_owner: Optional[UserProfile] = None,\n    tos_version: Optional[str] = None,\n    timezone: str = \"\",\n    avatar_source: str = UserProfile.AVATAR_FROM_GRAVATAR,\n    default_sending_stream: Optional[Stream] = None,\n    default_events_register_stream: Optional[Stream] = None,\n    default_all_public_streams: Optional[bool] = None,\n    prereg_user: Optional[PreregistrationUser] = None,\n    default_stream_groups: Sequence[DefaultStreamGroup] = [],\n    source_profile: Optional[UserProfile] = None,\n    realm_creation: bool = False,\n    *,\n    acting_user: Optional[UserProfile],\n    enable_marketing_emails: bool = True,\n) -> UserProfile:\n    with transaction.atomic():\n        user_profile = create_user(\n            email=email,\n            password=password,\n            realm=realm,\n            full_name=full_name,\n            role=role,\n            bot_type=bot_type,\n            bot_owner=bot_owner,\n            tos_version=tos_version,\n            timezone=timezone,\n            avatar_source=avatar_source,\n            default_sending_stream=default_sending_stream,\n            default_events_register_stream=default_events_register_stream,\n            default_all_public_streams=default_all_public_streams,\n            source_profile=source_profile,\n            enable_marketing_emails=enable_marketing_emails,\n        )\n\n        event_time = user_profile.date_joined\n        if not acting_user:\n            acting_user = user_profile\n        RealmAuditLog.objects.create(\n            realm=user_profile.realm,\n            acting_user=acting_user,\n            modified_user=user_profile,\n            event_type=RealmAuditLog.USER_CREATED,\n            event_time=event_time,\n            extra_data=orjson.dumps(\n                {\n                    RealmAuditLog.ROLE_COUNT: realm_user_count_by_role(user_profile.realm),\n                }\n            ).decode(),\n        )\n\n        if realm_creation:\n            # If this user just created a realm, make sure they are\n            # properly tagged as the creator of the realm.\n            realm_creation_audit_log = (\n                RealmAuditLog.objects.filter(event_type=RealmAuditLog.REALM_CREATED, realm=realm)\n                .order_by(\"id\")\n                .last()\n            )\n            assert realm_creation_audit_log is not None\n            realm_creation_audit_log.acting_user = user_profile\n            realm_creation_audit_log.save(update_fields=[\"acting_user\"])\n\n        do_increment_logging_stat(\n            user_profile.realm,\n            COUNT_STATS[\"active_users_log:is_bot:day\"],\n            user_profile.is_bot,\n            event_time,\n        )\n        if settings.BILLING_ENABLED:\n            update_license_ledger_if_needed(user_profile.realm, event_time)\n\n        system_user_group = get_system_user_group_for_user(user_profile)\n        UserGroupMembership.objects.create(user_profile=user_profile, user_group=system_user_group)\n\n        if user_profile.role == UserProfile.ROLE_MEMBER and not user_profile.is_provisional_member:\n            full_members_system_group = UserGroup.objects.get(\n                name=\"@role:fullmembers\", realm=user_profile.realm, is_system_group=True\n            )\n            UserGroupMembership.objects.create(\n                user_profile=user_profile, user_group=full_members_system_group\n            )\n\n    # Note that for bots, the caller will send an additional event\n    # with bot-specific info like services.\n    notify_created_user(user_profile)\n\n    do_send_user_group_members_update_event(\"add_members\", system_user_group, [user_profile.id])\n    if user_profile.role == UserProfile.ROLE_MEMBER and not user_profile.is_provisional_member:\n        do_send_user_group_members_update_event(\n            \"add_members\", full_members_system_group, [user_profile.id]\n        )\n\n    if bot_type is None:\n        process_new_human_user(\n            user_profile,\n            prereg_user=prereg_user,\n            default_stream_groups=default_stream_groups,\n            realm_creation=realm_creation,\n        )\n    return user_profile\n\n\ndef do_activate_mirror_dummy_user(\n    user_profile: UserProfile, *, acting_user: Optional[UserProfile]\n) -> None:\n    \"\"\"Called to have a user \"take over\" a \"mirror dummy\" user\n    (i.e. is_mirror_dummy=True) account when they sign up with the\n    same email address.\n\n    Essentially, the result should be as though we had created the\n    UserProfile just now with do_create_user, except that the mirror\n    dummy user may appear as the recipient or sender of messages from\n    before their account was fully created.\n\n    TODO: This function likely has bugs resulting from this being a\n    parallel code path to do_create_user; e.g. it likely does not\n    handle preferences or default streams properly.\n    \"\"\"\n    with transaction.atomic():\n        change_user_is_active(user_profile, True)\n        user_profile.is_mirror_dummy = False\n        user_profile.set_unusable_password()\n        user_profile.date_joined = timezone_now()\n        user_profile.tos_version = settings.TERMS_OF_SERVICE_VERSION\n        user_profile.save(\n            update_fields=[\"date_joined\", \"password\", \"is_mirror_dummy\", \"tos_version\"]\n        )\n\n        event_time = user_profile.date_joined\n        RealmAuditLog.objects.create(\n            realm=user_profile.realm,\n            modified_user=user_profile,\n            acting_user=acting_user,\n            event_type=RealmAuditLog.USER_ACTIVATED,\n            event_time=event_time,\n            extra_data=orjson.dumps(\n                {\n                    RealmAuditLog.ROLE_COUNT: realm_user_count_by_role(user_profile.realm),\n                }\n            ).decode(),\n        )\n        do_increment_logging_stat(\n            user_profile.realm,\n            COUNT_STATS[\"active_users_log:is_bot:day\"],\n            user_profile.is_bot,\n            event_time,\n        )\n        if settings.BILLING_ENABLED:\n            update_license_ledger_if_needed(user_profile.realm, event_time)\n\n    notify_created_user(user_profile)\n\n\ndef do_reactivate_user(user_profile: UserProfile, *, acting_user: Optional[UserProfile]) -> None:\n    \"\"\"Reactivate a user that had previously been deactivated\"\"\"\n    with transaction.atomic():\n        change_user_is_active(user_profile, True)\n\n        event_time = timezone_now()\n        RealmAuditLog.objects.create(\n            realm=user_profile.realm,\n            modified_user=user_profile,\n            acting_user=acting_user,\n            event_type=RealmAuditLog.USER_REACTIVATED,\n            event_time=event_time,\n            extra_data=orjson.dumps(\n                {\n                    RealmAuditLog.ROLE_COUNT: realm_user_count_by_role(user_profile.realm),\n                }\n            ).decode(),\n        )\n        do_increment_logging_stat(\n            user_profile.realm,\n            COUNT_STATS[\"active_users_log:is_bot:day\"],\n            user_profile.is_bot,\n            event_time,\n        )\n        if settings.BILLING_ENABLED:\n            update_license_ledger_if_needed(user_profile.realm, event_time)\n\n    notify_created_user(user_profile)\n\n    if user_profile.is_bot:\n        notify_created_bot(user_profile)\n\n    subscribed_recipient_ids = Subscription.objects.filter(\n        user_profile_id=user_profile.id, active=True, recipient__type=Recipient.STREAM\n    ).values_list(\"recipient__type_id\", flat=True)\n    subscribed_streams = Stream.objects.filter(id__in=subscribed_recipient_ids, deactivated=False)\n    subscriber_peer_info = bulk_get_subscriber_peer_info(\n        realm=user_profile.realm,\n        streams=subscribed_streams,\n    )\n\n    altered_user_dict: Dict[int, Set[int]] = defaultdict(set)\n    for stream in subscribed_streams:\n        altered_user_dict[stream.id] = {user_profile.id}\n\n    stream_dict = {stream.id: stream for stream in subscribed_streams}\n\n    send_peer_subscriber_events(\n        op=\"peer_add\",\n        realm=user_profile.realm,\n        altered_user_dict=altered_user_dict,\n        stream_dict=stream_dict,\n        private_peer_dict=subscriber_peer_info.private_peer_dict,\n    )\n\n\ndef active_humans_in_realm(realm: Realm) -> Sequence[UserProfile]:\n    return UserProfile.objects.filter(realm=realm, is_active=True, is_bot=False)\n\n\n@transaction.atomic(savepoint=False)\ndef update_users_in_full_members_system_group(\n    realm: Realm, affected_user_ids: Sequence[int] = []\n) -> None:\n    full_members_system_group = UserGroup.objects.get(\n        realm=realm, name=\"@role:fullmembers\", is_system_group=True\n    )\n    members_system_group = UserGroup.objects.get(\n        realm=realm, name=\"@role:members\", is_system_group=True\n    )\n\n    full_member_group_users: List[Dict[str, Union[int, datetime.datetime]]] = list()\n    member_group_users: List[Dict[str, Union[int, datetime.datetime]]] = list()\n\n    if affected_user_ids:\n        full_member_group_users = list(\n            full_members_system_group.direct_members.filter(id__in=affected_user_ids).values(\n                \"id\", \"role\", \"date_joined\"\n            )\n        )\n        member_group_users = list(\n            members_system_group.direct_members.filter(id__in=affected_user_ids).values(\n                \"id\", \"role\", \"date_joined\"\n            )\n        )\n    else:\n        full_member_group_users = list(\n            full_members_system_group.direct_members.all().values(\"id\", \"role\", \"date_joined\")\n        )\n        member_group_users = list(\n            members_system_group.direct_members.all().values(\"id\", \"role\", \"date_joined\")\n        )\n\n    def is_provisional_member(user: Dict[str, Union[int, datetime.datetime]]) -> bool:\n        diff = (timezone_now() - user[\"date_joined\"]).days\n        if diff < realm.waiting_period_threshold:\n            return True\n        return False\n\n    old_full_members = [\n        user\n        for user in full_member_group_users\n        if is_provisional_member(user) or user[\"role\"] != UserProfile.ROLE_MEMBER\n    ]\n\n    full_member_group_user_ids = [user[\"id\"] for user in full_member_group_users]\n    members_excluding_full_members = [\n        user for user in member_group_users if user[\"id\"] not in full_member_group_user_ids\n    ]\n\n    new_full_members = [\n        user for user in members_excluding_full_members if not is_provisional_member(user)\n    ]\n\n    old_full_member_ids = [user[\"id\"] for user in old_full_members]\n    new_full_member_ids = [user[\"id\"] for user in new_full_members]\n\n    if len(old_full_members) > 0:\n        remove_members_from_user_group(full_members_system_group, old_full_member_ids)\n\n    if len(new_full_members) > 0:\n        bulk_add_members_to_user_group(full_members_system_group, new_full_member_ids)\n\n\ndef promote_new_full_members() -> None:\n    for realm in Realm.objects.filter(deactivated=False).exclude(waiting_period_threshold=0):\n        update_users_in_full_members_system_group(realm)\n\n\n@transaction.atomic(savepoint=False)\ndef do_set_realm_property(\n    realm: Realm, name: str, value: Any, *, acting_user: Optional[UserProfile]\n) -> None:\n    \"\"\"Takes in a realm object, the name of an attribute to update, the\n    value to update and and the user who initiated the update.\n    \"\"\"\n    property_type = Realm.property_types[name]\n    assert isinstance(\n        value, property_type\n    ), f\"Cannot update {name}: {value} is not an instance of {property_type}\"\n\n    old_value = getattr(realm, name)\n    setattr(realm, name, value)\n    realm.save(update_fields=[name])\n\n    event = dict(\n        type=\"realm\",\n        op=\"update\",\n        property=name,\n        value=value,\n    )\n    transaction.on_commit(lambda: send_event(realm, event, active_user_ids(realm.id)))\n\n    event_time = timezone_now()\n    RealmAuditLog.objects.create(\n        realm=realm,\n        event_type=RealmAuditLog.REALM_PROPERTY_CHANGED,\n        event_time=event_time,\n        acting_user=acting_user,\n        extra_data=orjson.dumps(\n            {\n                RealmAuditLog.OLD_VALUE: old_value,\n                RealmAuditLog.NEW_VALUE: value,\n                \"property\": name,\n            }\n        ).decode(),\n    )\n\n    if name == \"email_address_visibility\":\n        if Realm.EMAIL_ADDRESS_VISIBILITY_EVERYONE not in [old_value, value]:\n            # We use real email addresses on UserProfile.email only if\n            # EMAIL_ADDRESS_VISIBILITY_EVERYONE is configured, so\n            # changes between values that will not require changing\n            # that field, so we can save work and return here.\n            return\n\n        user_profiles = UserProfile.objects.filter(realm=realm, is_bot=False)\n        for user_profile in user_profiles:\n            user_profile.email = get_display_email_address(user_profile)\n        UserProfile.objects.bulk_update(user_profiles, [\"email\"])\n\n        for user_profile in user_profiles:\n            transaction.on_commit(\n                lambda: flush_user_profile(sender=UserProfile, instance=user_profile)\n            )\n            # TODO: Design a bulk event for this or force-reload all clients\n            send_user_email_update_event(user_profile)\n\n    if name == \"waiting_period_threshold\":\n        update_users_in_full_members_system_group(realm)\n\n\ndef do_set_realm_authentication_methods(\n    realm: Realm, authentication_methods: Dict[str, bool], *, acting_user: Optional[UserProfile]\n) -> None:\n    old_value = realm.authentication_methods_dict()\n    with transaction.atomic():\n        for key, value in list(authentication_methods.items()):\n            index = getattr(realm.authentication_methods, key).number\n            realm.authentication_methods.set_bit(index, int(value))\n        realm.save(update_fields=[\"authentication_methods\"])\n        updated_value = realm.authentication_methods_dict()\n        RealmAuditLog.objects.create(\n            realm=realm,\n            event_type=RealmAuditLog.REALM_PROPERTY_CHANGED,\n            event_time=timezone_now(),\n            acting_user=acting_user,\n            extra_data=orjson.dumps(\n                {\n                    RealmAuditLog.OLD_VALUE: old_value,\n                    RealmAuditLog.NEW_VALUE: updated_value,\n                    \"property\": \"authentication_methods\",\n                }\n            ).decode(),\n        )\n\n    event = dict(\n        type=\"realm\",\n        op=\"update_dict\",\n        property=\"default\",\n        data=dict(authentication_methods=updated_value),\n    )\n    send_event(realm, event, active_user_ids(realm.id))\n\n\ndef do_set_realm_message_editing(\n    realm: Realm,\n    allow_message_editing: bool,\n    message_content_edit_limit_seconds: int,\n    edit_topic_policy: int,\n    *,\n    acting_user: Optional[UserProfile],\n) -> None:\n    old_values = dict(\n        allow_message_editing=realm.allow_message_editing,\n        message_content_edit_limit_seconds=realm.message_content_edit_limit_seconds,\n        edit_topic_policy=realm.edit_topic_policy,\n    )\n\n    realm.allow_message_editing = allow_message_editing\n    realm.message_content_edit_limit_seconds = message_content_edit_limit_seconds\n    realm.edit_topic_policy = edit_topic_policy\n\n    event_time = timezone_now()\n    updated_properties = dict(\n        allow_message_editing=allow_message_editing,\n        message_content_edit_limit_seconds=message_content_edit_limit_seconds,\n        edit_topic_policy=edit_topic_policy,\n    )\n\n    with transaction.atomic():\n        for updated_property, updated_value in updated_properties.items():\n            if updated_value == old_values[updated_property]:\n                continue\n            RealmAuditLog.objects.create(\n                realm=realm,\n                event_type=RealmAuditLog.REALM_PROPERTY_CHANGED,\n                event_time=event_time,\n                acting_user=acting_user,\n                extra_data=orjson.dumps(\n                    {\n                        RealmAuditLog.OLD_VALUE: old_values[updated_property],\n                        RealmAuditLog.NEW_VALUE: updated_value,\n                        \"property\": updated_property,\n                    }\n                ).decode(),\n            )\n\n        realm.save(update_fields=list(updated_properties.keys()))\n\n    event = dict(\n        type=\"realm\",\n        op=\"update_dict\",\n        property=\"default\",\n        data=updated_properties,\n    )\n    send_event(realm, event, active_user_ids(realm.id))\n\n\ndef do_set_realm_notifications_stream(\n    realm: Realm, stream: Optional[Stream], stream_id: int, *, acting_user: Optional[UserProfile]\n) -> None:\n    old_value = realm.notifications_stream_id\n    realm.notifications_stream = stream\n    with transaction.atomic():\n        realm.save(update_fields=[\"notifications_stream\"])\n\n        event_time = timezone_now()\n        RealmAuditLog.objects.create(\n            realm=realm,\n            event_type=RealmAuditLog.REALM_PROPERTY_CHANGED,\n            event_time=event_time,\n            acting_user=acting_user,\n            extra_data=orjson.dumps(\n                {\n                    RealmAuditLog.OLD_VALUE: old_value,\n                    RealmAuditLog.NEW_VALUE: stream_id,\n                    \"property\": \"notifications_stream\",\n                }\n            ).decode(),\n        )\n\n    event = dict(\n        type=\"realm\",\n        op=\"update\",\n        property=\"notifications_stream_id\",\n        value=stream_id,\n    )\n    send_event(realm, event, active_user_ids(realm.id))\n\n\ndef do_set_realm_signup_notifications_stream(\n    realm: Realm, stream: Optional[Stream], stream_id: int, *, acting_user: Optional[UserProfile]\n) -> None:\n    old_value = realm.signup_notifications_stream_id\n    realm.signup_notifications_stream = stream\n    with transaction.atomic():\n        realm.save(update_fields=[\"signup_notifications_stream\"])\n\n        event_time = timezone_now()\n        RealmAuditLog.objects.create(\n            realm=realm,\n            event_type=RealmAuditLog.REALM_PROPERTY_CHANGED,\n            event_time=event_time,\n            acting_user=acting_user,\n            extra_data=orjson.dumps(\n                {\n                    RealmAuditLog.OLD_VALUE: old_value,\n                    RealmAuditLog.NEW_VALUE: stream_id,\n                    \"property\": \"signup_notifications_stream\",\n                }\n            ).decode(),\n        )\n    event = dict(\n        type=\"realm\",\n        op=\"update\",\n        property=\"signup_notifications_stream_id\",\n        value=stream_id,\n    )\n    send_event(realm, event, active_user_ids(realm.id))\n\n\ndef do_set_realm_user_default_setting(\n    realm_user_default: RealmUserDefault,\n    name: str,\n    value: Any,\n    *,\n    acting_user: Optional[UserProfile],\n) -> None:\n    old_value = getattr(realm_user_default, name)\n    realm = realm_user_default.realm\n    event_time = timezone_now()\n\n    with transaction.atomic(savepoint=False):\n        setattr(realm_user_default, name, value)\n        realm_user_default.save(update_fields=[name])\n\n        RealmAuditLog.objects.create(\n            realm=realm,\n            event_type=RealmAuditLog.REALM_DEFAULT_USER_SETTINGS_CHANGED,\n            event_time=event_time,\n            acting_user=acting_user,\n            extra_data=orjson.dumps(\n                {\n                    RealmAuditLog.OLD_VALUE: old_value,\n                    RealmAuditLog.NEW_VALUE: value,\n                    \"property\": name,\n                }\n            ).decode(),\n        )\n\n    event = dict(\n        type=\"realm_user_settings_defaults\",\n        op=\"update\",\n        property=name,\n        value=value,\n    )\n    send_event(realm, event, active_user_ids(realm.id))\n\n\ndef do_deactivate_realm(realm: Realm, *, acting_user: Optional[UserProfile]) -> None:\n    \"\"\"\n    Deactivate this realm. Do NOT deactivate the users -- we need to be able to\n    tell the difference between users that were intentionally deactivated,\n    e.g. by a realm admin, and users who can't currently use Zulip because their\n    realm has been deactivated.\n    \"\"\"\n    if realm.deactivated:\n        return\n\n    realm.deactivated = True\n    realm.save(update_fields=[\"deactivated\"])\n\n    if settings.BILLING_ENABLED:\n        downgrade_now_without_creating_additional_invoices(realm)\n\n    event_time = timezone_now()\n    RealmAuditLog.objects.create(\n        realm=realm,\n        event_type=RealmAuditLog.REALM_DEACTIVATED,\n        event_time=event_time,\n        acting_user=acting_user,\n        extra_data=orjson.dumps(\n            {\n                RealmAuditLog.ROLE_COUNT: realm_user_count_by_role(realm),\n            }\n        ).decode(),\n    )\n\n    ScheduledEmail.objects.filter(realm=realm).delete()\n    for user in active_humans_in_realm(realm):\n        # Don't deactivate the users, but do delete their sessions so they get\n        # bumped to the login screen, where they'll get a realm deactivation\n        # notice when they try to log in.\n        delete_user_sessions(user)\n\n    # This event will only ever be received by clients with an active\n    # longpoll connection, because by this point clients will be\n    # unable to authenticate again to their event queue (triggering an\n    # immediate reload into the page explaining the realm was\n    # deactivated). So the purpose of sending this is to flush all\n    # active longpoll connections for the realm.\n    event = dict(type=\"realm\", op=\"deactivated\", realm_id=realm.id)\n    send_event(realm, event, active_user_ids(realm.id))\n\n\ndef do_reactivate_realm(realm: Realm) -> None:\n    realm.deactivated = False\n    with transaction.atomic():\n        realm.save(update_fields=[\"deactivated\"])\n\n        event_time = timezone_now()\n        RealmAuditLog.objects.create(\n            realm=realm,\n            event_type=RealmAuditLog.REALM_REACTIVATED,\n            event_time=event_time,\n            extra_data=orjson.dumps(\n                {\n                    RealmAuditLog.ROLE_COUNT: realm_user_count_by_role(realm),\n                }\n            ).decode(),\n        )\n\n\ndef do_change_realm_subdomain(\n    realm: Realm, new_subdomain: str, *, acting_user: Optional[UserProfile]\n) -> None:\n    \"\"\"Changing a realm's subdomain is a highly disruptive operation,\n    because all existing clients will need to be updated to point to\n    the new URL.  Further, requests to fetch data from existing event\n    queues will fail with an authentication error when this change\n    happens (because the old subdomain is no longer associated with\n    the realm), making it hard for us to provide a graceful update\n    experience for clients.\n    \"\"\"\n    old_subdomain = realm.subdomain\n    old_uri = realm.uri\n    # If the realm had been a demo organization scheduled for\n    # deleting, clear that state.\n    realm.demo_organization_scheduled_deletion_date = None\n    realm.string_id = new_subdomain\n    with transaction.atomic():\n        realm.save(update_fields=[\"string_id\", \"demo_organization_scheduled_deletion_date\"])\n        RealmAuditLog.objects.create(\n            realm=realm,\n            event_type=RealmAuditLog.REALM_SUBDOMAIN_CHANGED,\n            event_time=timezone_now(),\n            acting_user=acting_user,\n            extra_data={\"old_subdomain\": old_subdomain, \"new_subdomain\": new_subdomain},\n        )\n\n        # If a realm if being renamed multiple times, we should find all the placeholder\n        # realms and reset their deactivated_redirect field to point to the new realm uri\n        placeholder_realms = Realm.objects.filter(deactivated_redirect=old_uri, deactivated=True)\n        for placeholder_realm in placeholder_realms:\n            do_add_deactivated_redirect(placeholder_realm, realm.uri)\n\n    # The below block isn't executed in a transaction with the earlier code due to\n    # the functions called below being complex and potentially sending events,\n    # which we don't want to do in atomic blocks.\n    # When we change a realm's subdomain the realm with old subdomain is basically\n    # deactivated. We are creating a deactivated realm using old subdomain and setting\n    # it's deactivated redirect to new_subdomain so that we can tell the users that\n    # the realm has been moved to a new subdomain.\n    placeholder_realm = do_create_realm(old_subdomain, realm.name)\n    do_deactivate_realm(placeholder_realm, acting_user=None)\n    do_add_deactivated_redirect(placeholder_realm, realm.uri)\n\n\ndef do_add_deactivated_redirect(realm: Realm, redirect_url: str) -> None:\n    realm.deactivated_redirect = redirect_url\n    realm.save(update_fields=[\"deactivated_redirect\"])\n\n\ndef do_scrub_realm(realm: Realm, *, acting_user: Optional[UserProfile]) -> None:\n    if settings.BILLING_ENABLED:\n        downgrade_now_without_creating_additional_invoices(realm)\n\n    users = UserProfile.objects.filter(realm=realm)\n    for user in users:\n        do_delete_messages_by_sender(user)\n        do_delete_avatar_image(user, acting_user=acting_user)\n        user.full_name = f\"Scrubbed {generate_key()[:15]}\"\n        scrubbed_email = f\"scrubbed-{generate_key()[:15]}@{realm.host}\"\n        user.email = scrubbed_email\n        user.delivery_email = scrubbed_email\n        user.save(update_fields=[\"full_name\", \"email\", \"delivery_email\"])\n\n    do_remove_realm_custom_profile_fields(realm)\n    Attachment.objects.filter(realm=realm).delete()\n\n    RealmAuditLog.objects.create(\n        realm=realm,\n        event_time=timezone_now(),\n        acting_user=acting_user,\n        event_type=RealmAuditLog.REALM_SCRUBBED,\n    )\n\n\ndef do_delete_user(user_profile: UserProfile) -> None:\n    if user_profile.realm.is_zephyr_mirror_realm:\n        raise AssertionError(\"Deleting zephyr mirror users is not supported\")\n\n    do_deactivate_user(user_profile, acting_user=None)\n\n    subscribed_huddle_recipient_ids = set(\n        Subscription.objects.filter(\n            user_profile=user_profile, recipient__type=Recipient.HUDDLE\n        ).values_list(\"recipient_id\", flat=True)\n    )\n    user_id = user_profile.id\n    realm = user_profile.realm\n    date_joined = user_profile.date_joined\n    personal_recipient = user_profile.recipient\n\n    with transaction.atomic():\n        user_profile.delete()\n        # Recipient objects don't get deleted through CASCADE, so we need to handle\n        # the user's personal recipient manually. This will also delete all Messages pointing\n        # to this recipient (all private messages sent to the user).\n        assert personal_recipient is not None\n        personal_recipient.delete()\n        replacement_user = create_user(\n            force_id=user_id,\n            email=f\"deleteduser{user_id}@{get_fake_email_domain(realm)}\",\n            password=None,\n            realm=realm,\n            full_name=f\"Deleted User {user_id}\",\n            active=False,\n            is_mirror_dummy=True,\n            force_date_joined=date_joined,\n        )\n        subs_to_recreate = [\n            Subscription(\n                user_profile=replacement_user,\n                recipient=recipient,\n                is_user_active=replacement_user.is_active,\n            )\n            for recipient in Recipient.objects.filter(id__in=subscribed_huddle_recipient_ids)\n        ]\n        Subscription.objects.bulk_create(subs_to_recreate)\n\n        RealmAuditLog.objects.create(\n            realm=replacement_user.realm,\n            modified_user=replacement_user,\n            acting_user=None,\n            event_type=RealmAuditLog.USER_DELETED,\n            event_time=timezone_now(),\n        )\n\n\ndef change_user_is_active(user_profile: UserProfile, value: bool) -> None:\n    \"\"\"\n    Helper function for changing the .is_active field. Not meant as a standalone function\n    in production code as properly activating/deactivating users requires more steps.\n    This changes the is_active value and saves it, while ensuring\n    Subscription.is_user_active values are updated in the same db transaction.\n    \"\"\"\n    with transaction.atomic(savepoint=False):\n        user_profile.is_active = value\n        user_profile.save(update_fields=[\"is_active\"])\n        Subscription.objects.filter(user_profile=user_profile).update(is_user_active=value)\n\n\ndef get_active_bots_owned_by_user(user_profile: UserProfile) -> QuerySet:\n    return UserProfile.objects.filter(is_bot=True, is_active=True, bot_owner=user_profile)\n\n\ndef do_deactivate_user(\n    user_profile: UserProfile, _cascade: bool = True, *, acting_user: Optional[UserProfile]\n) -> None:\n    if not user_profile.is_active:\n        return\n\n    if _cascade:\n        # We need to deactivate bots before the target user, to ensure\n        # that a failure partway through this function cannot result\n        # in only the user being deactivated.\n        bot_profiles = get_active_bots_owned_by_user(user_profile)\n        for profile in bot_profiles:\n            do_deactivate_user(profile, _cascade=False, acting_user=acting_user)\n\n    with transaction.atomic():\n        if user_profile.realm.is_zephyr_mirror_realm:  # nocoverage\n            # For zephyr mirror users, we need to make them a mirror dummy\n            # again; otherwise, other users won't get the correct behavior\n            # when trying to send messages to this person inside Zulip.\n            #\n            # Ideally, we need to also ensure their zephyr mirroring bot\n            # isn't running, but that's a separate issue.\n            user_profile.is_mirror_dummy = True\n            user_profile.save(update_fields=[\"is_mirror_dummy\"])\n\n        change_user_is_active(user_profile, False)\n\n        delete_user_sessions(user_profile)\n        clear_scheduled_emails(user_profile.id)\n        revoke_invites_generated_by_user(user_profile)\n\n        event_time = timezone_now()\n        RealmAuditLog.objects.create(\n            realm=user_profile.realm,\n            modified_user=user_profile,\n            acting_user=acting_user,\n            event_type=RealmAuditLog.USER_DEACTIVATED,\n            event_time=event_time,\n            extra_data=orjson.dumps(\n                {\n                    RealmAuditLog.ROLE_COUNT: realm_user_count_by_role(user_profile.realm),\n                }\n            ).decode(),\n        )\n        do_increment_logging_stat(\n            user_profile.realm,\n            COUNT_STATS[\"active_users_log:is_bot:day\"],\n            user_profile.is_bot,\n            event_time,\n            increment=-1,\n        )\n        if settings.BILLING_ENABLED:\n            update_license_ledger_if_needed(user_profile.realm, event_time)\n\n    event = dict(\n        type=\"realm_user\",\n        op=\"remove\",\n        person=dict(user_id=user_profile.id, full_name=user_profile.full_name),\n    )\n    send_event(user_profile.realm, event, active_user_ids(user_profile.realm_id))\n\n    if user_profile.is_bot:\n        event = dict(\n            type=\"realm_bot\",\n            op=\"remove\",\n            bot=dict(user_id=user_profile.id, full_name=user_profile.full_name),\n        )\n        send_event(user_profile.realm, event, bot_owner_user_ids(user_profile))\n\n\n@transaction.atomic(savepoint=False)\ndef do_deactivate_stream(\n    stream: Stream, log: bool = True, *, acting_user: Optional[UserProfile]\n) -> None:\n    # We want to mark all messages in the to-be-deactivated stream as\n    # read for all users; otherwise they will pollute queries like\n    # \"Get the user's first unread message\".  Since this can be an\n    # expensive operation, we do it via the deferred_work queue\n    # processor.\n    deferred_work_event = {\n        \"type\": \"mark_stream_messages_as_read_for_everyone\",\n        \"stream_recipient_id\": stream.recipient_id,\n    }\n    transaction.on_commit(lambda: queue_json_publish(\"deferred_work\", deferred_work_event))\n\n    # Get the affected user ids *before* we deactivate everybody.\n    affected_user_ids = can_access_stream_user_ids(stream)\n\n    get_active_subscriptions_for_stream_id(stream.id, include_deactivated_users=True).update(\n        active=False\n    )\n\n    was_invite_only = stream.invite_only\n    stream.deactivated = True\n    stream.invite_only = True\n    # Preserve as much as possible the original stream name while giving it a\n    # special prefix that both indicates that the stream is deactivated and\n    # frees up the original name for reuse.\n    old_name = stream.name\n\n    # Prepend a substring of the hashed stream ID to the new stream name\n    streamID = str(stream.id)\n    stream_id_hash_object = hashlib.sha512(streamID.encode())\n    hashed_stream_id = stream_id_hash_object.hexdigest()[0:7]\n\n    new_name = (hashed_stream_id + \"!DEACTIVATED:\" + old_name)[: Stream.MAX_NAME_LENGTH]\n\n    stream.name = new_name[: Stream.MAX_NAME_LENGTH]\n    stream.save(update_fields=[\"name\", \"deactivated\", \"invite_only\"])\n\n    # If this is a default stream, remove it, properly sending a\n    # notification to browser clients.\n    if DefaultStream.objects.filter(realm_id=stream.realm_id, stream_id=stream.id).exists():\n        do_remove_default_stream(stream)\n\n    default_stream_groups_for_stream = DefaultStreamGroup.objects.filter(streams__id=stream.id)\n    for group in default_stream_groups_for_stream:\n        do_remove_streams_from_default_stream_group(stream.realm, group, [stream])\n\n    # Remove the old stream information from remote cache.\n    old_cache_key = get_stream_cache_key(old_name, stream.realm_id)\n    cache_delete(old_cache_key)\n\n    stream_dict = stream.to_dict()\n    stream_dict.update(dict(name=old_name, invite_only=was_invite_only))\n    event = dict(type=\"stream\", op=\"delete\", streams=[stream_dict])\n    transaction.on_commit(lambda: send_event(stream.realm, event, affected_user_ids))\n\n    event_time = timezone_now()\n    RealmAuditLog.objects.create(\n        realm=stream.realm,\n        acting_user=acting_user,\n        modified_stream=stream,\n        event_type=RealmAuditLog.STREAM_DEACTIVATED,\n        event_time=event_time,\n    )\n\n\ndef send_user_email_update_event(user_profile: UserProfile) -> None:\n    payload = dict(user_id=user_profile.id, new_email=user_profile.email)\n    event = dict(type=\"realm_user\", op=\"update\", person=payload)\n    transaction.on_commit(\n        lambda: send_event(\n            user_profile.realm,\n            event,\n            active_user_ids(user_profile.realm_id),\n        )\n    )\n\n\n@transaction.atomic(savepoint=False)\ndef do_change_user_delivery_email(user_profile: UserProfile, new_email: str) -> None:\n    delete_user_profile_caches([user_profile])\n\n    user_profile.delivery_email = new_email\n    if user_profile.email_address_is_realm_public():\n        user_profile.email = new_email\n        user_profile.save(update_fields=[\"email\", \"delivery_email\"])\n    else:\n        user_profile.save(update_fields=[\"delivery_email\"])\n\n    # We notify just the target user (and eventually org admins, only\n    # when email_address_visibility=EMAIL_ADDRESS_VISIBILITY_ADMINS)\n    # about their new delivery email, since that field is private.\n    payload = dict(user_id=user_profile.id, delivery_email=new_email)\n    event = dict(type=\"realm_user\", op=\"update\", person=payload)\n    transaction.on_commit(lambda: send_event(user_profile.realm, event, [user_profile.id]))\n\n    if user_profile.avatar_source == UserProfile.AVATAR_FROM_GRAVATAR:\n        # If the user is using Gravatar to manage their email address,\n        # their Gravatar just changed, and we need to notify other\n        # clients.\n        notify_avatar_url_change(user_profile)\n\n    if user_profile.email_address_is_realm_public():\n        # Additionally, if we're also changing the publicly visible\n        # email, we send a new_email event as well.\n        send_user_email_update_event(user_profile)\n\n    event_time = timezone_now()\n    RealmAuditLog.objects.create(\n        realm=user_profile.realm,\n        acting_user=user_profile,\n        modified_user=user_profile,\n        event_type=RealmAuditLog.USER_EMAIL_CHANGED,\n        event_time=event_time,\n    )\n\n\ndef do_start_email_change_process(user_profile: UserProfile, new_email: str) -> None:\n    old_email = user_profile.delivery_email\n    obj = EmailChangeStatus.objects.create(\n        new_email=new_email,\n        old_email=old_email,\n        user_profile=user_profile,\n        realm=user_profile.realm,\n    )\n\n    activation_url = create_confirmation_link(obj, Confirmation.EMAIL_CHANGE)\n    from zerver.context_processors import common_context\n\n    context = common_context(user_profile)\n    context.update(\n        old_email=old_email,\n        new_email=new_email,\n        activate_url=activation_url,\n    )\n    language = user_profile.default_language\n    send_email(\n        \"zerver/emails/confirm_new_email\",\n        to_emails=[new_email],\n        from_name=FromAddress.security_email_from_name(language=language),\n        from_address=FromAddress.tokenized_no_reply_address(),\n        language=language,\n        context=context,\n        realm=user_profile.realm,\n    )\n\n\ndef compute_irc_user_fullname(email: str) -> str:\n    return email.split(\"@\")[0] + \" (IRC)\"\n\n\ndef compute_jabber_user_fullname(email: str) -> str:\n    return email.split(\"@\")[0] + \" (XMPP)\"\n\n\n@cache_with_key(\n    lambda realm, email, f: user_profile_delivery_email_cache_key(email, realm),\n    timeout=3600 * 24 * 7,\n)\ndef create_mirror_user_if_needed(\n    realm: Realm, email: str, email_to_fullname: Callable[[str], str]\n) -> UserProfile:\n    try:\n        return get_user_by_delivery_email(email, realm)\n    except UserProfile.DoesNotExist:\n        try:\n            # Forge a user for this person\n            return create_user(\n                email=email,\n                password=None,\n                realm=realm,\n                full_name=email_to_fullname(email),\n                active=False,\n                is_mirror_dummy=True,\n            )\n        except IntegrityError:\n            return get_user_by_delivery_email(email, realm)\n\n\ndef render_incoming_message(\n    message: Message,\n    content: str,\n    user_ids: Set[int],\n    realm: Realm,\n    mention_data: Optional[MentionData] = None,\n    email_gateway: bool = False,\n) -> MessageRenderingResult:\n    realm_alert_words_automaton = get_alert_word_automaton(realm)\n    try:\n        rendering_result = render_markdown(\n            message=message,\n            content=content,\n            realm=realm,\n            realm_alert_words_automaton=realm_alert_words_automaton,\n            mention_data=mention_data,\n            email_gateway=email_gateway,\n        )\n    except MarkdownRenderingException:\n        raise JsonableError(_(\"Unable to render message\"))\n    return rendering_result\n\n\nclass RecipientInfoResult(TypedDict):\n    active_user_ids: Set[int]\n    online_push_user_ids: Set[int]\n    pm_mention_email_disabled_user_ids: Set[int]\n    pm_mention_push_disabled_user_ids: Set[int]\n    stream_email_user_ids: Set[int]\n    stream_push_user_ids: Set[int]\n    wildcard_mention_user_ids: Set[int]\n    muted_sender_user_ids: Set[int]\n    um_eligible_user_ids: Set[int]\n    long_term_idle_user_ids: Set[int]\n    default_bot_user_ids: Set[int]\n    service_bot_tuples: List[Tuple[int, int]]\n    all_bot_user_ids: Set[int]\n\n\ndef get_recipient_info(\n    *,\n    realm_id: int,\n    recipient: Recipient,\n    sender_id: int,\n    stream_topic: Optional[StreamTopicTarget],\n    possibly_mentioned_user_ids: AbstractSet[int] = set(),\n    possible_wildcard_mention: bool = True,\n) -> RecipientInfoResult:\n    stream_push_user_ids: Set[int] = set()\n    stream_email_user_ids: Set[int] = set()\n    wildcard_mention_user_ids: Set[int] = set()\n    muted_sender_user_ids: Set[int] = get_muting_users(sender_id)\n\n    if recipient.type == Recipient.PERSONAL:\n        # The sender and recipient may be the same id, so\n        # de-duplicate using a set.\n        message_to_user_ids = list({recipient.type_id, sender_id})\n        assert len(message_to_user_ids) in [1, 2]\n\n    elif recipient.type == Recipient.STREAM:\n        # Anybody calling us w/r/t a stream message needs to supply\n        # stream_topic.  We may eventually want to have different versions\n        # of this function for different message types.\n        assert stream_topic is not None\n        user_ids_muting_topic = stream_topic.user_ids_muting_topic()\n\n        subscription_rows = (\n            get_subscriptions_for_send_message(\n                realm_id=realm_id,\n                stream_id=stream_topic.stream_id,\n                possible_wildcard_mention=possible_wildcard_mention,\n                possibly_mentioned_user_ids=possibly_mentioned_user_ids,\n            )\n            .annotate(\n                user_profile_email_notifications=F(\n                    \"user_profile__enable_stream_email_notifications\"\n                ),\n                user_profile_push_notifications=F(\"user_profile__enable_stream_push_notifications\"),\n                user_profile_wildcard_mentions_notify=F(\"user_profile__wildcard_mentions_notify\"),\n            )\n            .values(\n                \"user_profile_id\",\n                \"push_notifications\",\n                \"email_notifications\",\n                \"wildcard_mentions_notify\",\n                \"user_profile_email_notifications\",\n                \"user_profile_push_notifications\",\n                \"user_profile_wildcard_mentions_notify\",\n                \"is_muted\",\n            )\n            .order_by(\"user_profile_id\")\n        )\n\n        message_to_user_ids = [row[\"user_profile_id\"] for row in subscription_rows]\n\n        def should_send(setting: str, row: Dict[str, Any]) -> bool:\n            # This implements the structure that the UserProfile stream notification settings\n            # are defaults, which can be overridden by the stream-level settings (if those\n            # values are not null).\n            if row[\"is_muted\"]:\n                return False\n            if row[\"user_profile_id\"] in user_ids_muting_topic:\n                return False\n            if row[setting] is not None:\n                return row[setting]\n            return row[\"user_profile_\" + setting]\n\n        stream_push_user_ids = {\n            row[\"user_profile_id\"]\n            for row in subscription_rows\n            # Note: muting a stream overrides stream_push_notify\n            if should_send(\"push_notifications\", row)\n        }\n\n        stream_email_user_ids = {\n            row[\"user_profile_id\"]\n            for row in subscription_rows\n            # Note: muting a stream overrides stream_email_notify\n            if should_send(\"email_notifications\", row)\n        }\n\n        if possible_wildcard_mention:\n            # If there's a possible wildcard mention, we need to\n            # determine the set of users who have enabled the\n            # \"wildcard_mentions_notify\" setting (that is, the set of\n            # users for whom wildcard mentions should be treated like\n            # personal mentions for notifications). This setting\n            # applies to both email and push notifications.\n            wildcard_mention_user_ids = {\n                row[\"user_profile_id\"]\n                for row in subscription_rows\n                if should_send(\"wildcard_mentions_notify\", row)\n            }\n\n    elif recipient.type == Recipient.HUDDLE:\n        message_to_user_ids = get_huddle_user_ids(recipient)\n\n    else:\n        raise ValueError(\"Bad recipient type\")\n\n    message_to_user_id_set = set(message_to_user_ids)\n\n    user_ids = set(message_to_user_id_set)\n    # Important note: Because we haven't rendered Markdown yet, we\n    # don't yet know which of these possibly-mentioned users was\n    # actually mentioned in the message (in other words, the\n    # mention syntax might have been in a code block or otherwise\n    # escaped).  `get_ids_for` will filter these extra user rows\n    # for our data structures not related to bots\n    user_ids |= possibly_mentioned_user_ids\n\n    if user_ids:\n        query = UserProfile.objects.filter(is_active=True).values(\n            \"id\",\n            \"enable_online_push_notifications\",\n            \"enable_offline_email_notifications\",\n            \"enable_offline_push_notifications\",\n            \"is_bot\",\n            \"bot_type\",\n            \"long_term_idle\",\n        )\n\n        # query_for_ids is fast highly optimized for large queries, and we\n        # need this codepath to be fast (it's part of sending messages)\n        query = query_for_ids(\n            query=query,\n            user_ids=sorted(user_ids),\n            field=\"id\",\n        )\n        rows = list(query)\n    else:\n        # TODO: We should always have at least one user_id as a recipient\n        #       of any message we send.  Right now the exception to this\n        #       rule is `notify_new_user`, which, at least in a possibly\n        #       contrived test scenario, can attempt to send messages\n        #       to an inactive bot.  When we plug that hole, we can avoid\n        #       this `else` clause and just `assert(user_ids)`.\n        #\n        # UPDATE: It's February 2020 (and a couple years after the above\n        #         comment was written).  We have simplified notify_new_user\n        #         so that it should be a little easier to reason about.\n        #         There is currently some cleanup to how we handle cross\n        #         realm bots that is still under development.  Once that\n        #         effort is complete, we should be able to address this\n        #         to-do.\n        rows = []\n\n    def get_ids_for(f: Callable[[Dict[str, Any]], bool]) -> Set[int]:\n        \"\"\"Only includes users on the explicit message to line\"\"\"\n        return {row[\"id\"] for row in rows if f(row)} & message_to_user_id_set\n\n    def is_service_bot(row: Dict[str, Any]) -> bool:\n        return row[\"is_bot\"] and (row[\"bot_type\"] in UserProfile.SERVICE_BOT_TYPES)\n\n    active_user_ids = get_ids_for(lambda r: True)\n    online_push_user_ids = get_ids_for(\n        lambda r: r[\"enable_online_push_notifications\"],\n    )\n\n    # We deal with only the users who have disabled this setting, since that\n    # will usually be much smaller a set than those who have enabled it (which\n    # is the default)\n    pm_mention_email_disabled_user_ids = get_ids_for(\n        lambda r: not r[\"enable_offline_email_notifications\"]\n    )\n    pm_mention_push_disabled_user_ids = get_ids_for(\n        lambda r: not r[\"enable_offline_push_notifications\"]\n    )\n\n    # Service bots don't get UserMessage rows.\n    um_eligible_user_ids = get_ids_for(\n        lambda r: not is_service_bot(r),\n    )\n\n    long_term_idle_user_ids = get_ids_for(\n        lambda r: r[\"long_term_idle\"],\n    )\n\n    # These three bot data structures need to filter from the full set\n    # of users who either are receiving the message or might have been\n    # mentioned in it, and so can't use get_ids_for.\n    #\n    # Further in the do_send_messages code path, once\n    # `mentioned_user_ids` has been computed via Markdown, we'll filter\n    # these data structures for just those users who are either a\n    # direct recipient or were mentioned; for now, we're just making\n    # sure we have the data we need for that without extra database\n    # queries.\n    default_bot_user_ids = {\n        row[\"id\"] for row in rows if row[\"is_bot\"] and row[\"bot_type\"] == UserProfile.DEFAULT_BOT\n    }\n\n    service_bot_tuples = [(row[\"id\"], row[\"bot_type\"]) for row in rows if is_service_bot(row)]\n\n    # We also need the user IDs of all bots, to avoid trying to send push/email\n    # notifications to them. This set will be directly sent to the event queue code\n    # where we determine notifiability of the message for users.\n    all_bot_user_ids = {row[\"id\"] for row in rows if row[\"is_bot\"]}\n\n    info: RecipientInfoResult = dict(\n        active_user_ids=active_user_ids,\n        online_push_user_ids=online_push_user_ids,\n        pm_mention_email_disabled_user_ids=pm_mention_email_disabled_user_ids,\n        pm_mention_push_disabled_user_ids=pm_mention_push_disabled_user_ids,\n        stream_push_user_ids=stream_push_user_ids,\n        stream_email_user_ids=stream_email_user_ids,\n        wildcard_mention_user_ids=wildcard_mention_user_ids,\n        muted_sender_user_ids=muted_sender_user_ids,\n        um_eligible_user_ids=um_eligible_user_ids,\n        long_term_idle_user_ids=long_term_idle_user_ids,\n        default_bot_user_ids=default_bot_user_ids,\n        service_bot_tuples=service_bot_tuples,\n        all_bot_user_ids=all_bot_user_ids,\n    )\n    return info\n\n\ndef get_service_bot_events(\n    sender: UserProfile,\n    service_bot_tuples: List[Tuple[int, int]],\n    mentioned_user_ids: Set[int],\n    active_user_ids: Set[int],\n    recipient_type: int,\n) -> Dict[str, List[Dict[str, Any]]]:\n\n    event_dict: Dict[str, List[Dict[str, Any]]] = defaultdict(list)\n\n    # Avoid infinite loops by preventing messages sent by bots from generating\n    # Service events.\n    if sender.is_bot:\n        return event_dict\n\n    def maybe_add_event(user_profile_id: int, bot_type: int) -> None:\n        if bot_type == UserProfile.OUTGOING_WEBHOOK_BOT:\n            queue_name = \"outgoing_webhooks\"\n        elif bot_type == UserProfile.EMBEDDED_BOT:\n            queue_name = \"embedded_bots\"\n        else:\n            logging.error(\n                \"Unexpected bot_type for Service bot id=%s: %s\",\n                user_profile_id,\n                bot_type,\n            )\n            return\n\n        is_stream = recipient_type == Recipient.STREAM\n\n        # Important note: service_bot_tuples may contain service bots\n        # who were not actually mentioned in the message (e.g. if\n        # mention syntax for that bot appeared in a code block).\n        # Thus, it is important to filter any users who aren't part of\n        # either mentioned_user_ids (the actual mentioned users) or\n        # active_user_ids (the actual recipients).\n        #\n        # So even though this is implied by the logic below, we filter\n        # these not-actually-mentioned users here, to help keep this\n        # function future-proof.\n        if user_profile_id not in mentioned_user_ids and user_profile_id not in active_user_ids:\n            return\n\n        # Mention triggers, for stream messages\n        if is_stream and user_profile_id in mentioned_user_ids:\n            trigger = \"mention\"\n        # PM triggers for personal and huddle messages\n        elif (not is_stream) and (user_profile_id in active_user_ids):\n            trigger = \"private_message\"\n        else:\n            return\n\n        event_dict[queue_name].append(\n            {\n                \"trigger\": trigger,\n                \"user_profile_id\": user_profile_id,\n            }\n        )\n\n    for user_profile_id, bot_type in service_bot_tuples:\n        maybe_add_event(\n            user_profile_id=user_profile_id,\n            bot_type=bot_type,\n        )\n\n    return event_dict\n\n\ndef do_schedule_messages(send_message_requests: Sequence[SendMessageRequest]) -> List[int]:\n    scheduled_messages: List[ScheduledMessage] = []\n\n    for send_request in send_message_requests:\n        scheduled_message = ScheduledMessage()\n        scheduled_message.sender = send_request.message.sender\n        scheduled_message.recipient = send_request.message.recipient\n        topic_name = send_request.message.topic_name()\n        scheduled_message.set_topic_name(topic_name=topic_name)\n        scheduled_message.content = send_request.message.content\n        scheduled_message.sending_client = send_request.message.sending_client\n        scheduled_message.stream = send_request.stream\n        scheduled_message.realm = send_request.realm\n        assert send_request.deliver_at is not None\n        scheduled_message.scheduled_timestamp = send_request.deliver_at\n        if send_request.delivery_type == \"send_later\":\n            scheduled_message.delivery_type = ScheduledMessage.SEND_LATER\n        elif send_request.delivery_type == \"remind\":\n            scheduled_message.delivery_type = ScheduledMessage.REMIND\n\n        scheduled_messages.append(scheduled_message)\n\n    ScheduledMessage.objects.bulk_create(scheduled_messages)\n    return [scheduled_message.id for scheduled_message in scheduled_messages]\n\n\ndef build_message_send_dict(\n    message: Message,\n    stream: Optional[Stream] = None,\n    local_id: Optional[str] = None,\n    sender_queue_id: Optional[str] = None,\n    realm: Optional[Realm] = None,\n    widget_content_dict: Optional[Dict[str, Any]] = None,\n    email_gateway: bool = False,\n    mention_backend: Optional[MentionBackend] = None,\n    limit_unread_user_ids: Optional[Set[int]] = None,\n) -> SendMessageRequest:\n    \"\"\"Returns a dictionary that can be passed into do_send_messages.  In\n    production, this is always called by check_message, but some\n    testing code paths call it directly.\n    \"\"\"\n    if realm is None:\n        realm = message.sender.realm\n\n    if mention_backend is None:\n        mention_backend = MentionBackend(realm.id)\n\n    mention_data = MentionData(\n        mention_backend=mention_backend,\n        content=message.content,\n    )\n\n    if message.is_stream_message():\n        stream_id = message.recipient.type_id\n        stream_topic: Optional[StreamTopicTarget] = StreamTopicTarget(\n            stream_id=stream_id,\n            topic_name=message.topic_name(),\n        )\n    else:\n        stream_topic = None\n\n    info = get_recipient_info(\n        realm_id=realm.id,\n        recipient=message.recipient,\n        sender_id=message.sender_id,\n        stream_topic=stream_topic,\n        possibly_mentioned_user_ids=mention_data.get_user_ids(),\n        possible_wildcard_mention=mention_data.message_has_wildcards(),\n    )\n\n    # Render our message_dicts.\n    assert message.rendered_content is None\n\n    rendering_result = render_incoming_message(\n        message,\n        message.content,\n        info[\"active_user_ids\"],\n        realm,\n        mention_data=mention_data,\n        email_gateway=email_gateway,\n    )\n    message.rendered_content = rendering_result.rendered_content\n    message.rendered_content_version = markdown_version\n    links_for_embed = rendering_result.links_for_preview\n\n    mentioned_user_groups_map = get_user_group_mentions_data(\n        mentioned_user_ids=rendering_result.mentions_user_ids,\n        mentioned_user_group_ids=list(rendering_result.mentions_user_group_ids),\n        mention_data=mention_data,\n    )\n\n    # For single user as well as user group mentions, we set the `mentioned`\n    # flag on `UserMessage`\n    for group_id in rendering_result.mentions_user_group_ids:\n        members = mention_data.get_group_members(group_id)\n        rendering_result.mentions_user_ids.update(members)\n\n    # Only send data to Tornado about wildcard mentions if message\n    # rendering determined the message had an actual wildcard\n    # mention in it (and not e.g. wildcard mention syntax inside a\n    # code block).\n    if rendering_result.mentions_wildcard:\n        wildcard_mention_user_ids = info[\"wildcard_mention_user_ids\"]\n    else:\n        wildcard_mention_user_ids = set()\n\n    \"\"\"\n    Once we have the actual list of mentioned ids from message\n    rendering, we can patch in \"default bots\" (aka normal bots)\n    who were directly mentioned in this message as eligible to\n    get UserMessage rows.\n    \"\"\"\n    mentioned_user_ids = rendering_result.mentions_user_ids\n    default_bot_user_ids = info[\"default_bot_user_ids\"]\n    mentioned_bot_user_ids = default_bot_user_ids & mentioned_user_ids\n    info[\"um_eligible_user_ids\"] |= mentioned_bot_user_ids\n\n    message_send_dict = SendMessageRequest(\n        stream=stream,\n        local_id=local_id,\n        sender_queue_id=sender_queue_id,\n        realm=realm,\n        mention_data=mention_data,\n        mentioned_user_groups_map=mentioned_user_groups_map,\n        message=message,\n        rendering_result=rendering_result,\n        active_user_ids=info[\"active_user_ids\"],\n        online_push_user_ids=info[\"online_push_user_ids\"],\n        pm_mention_email_disabled_user_ids=info[\"pm_mention_email_disabled_user_ids\"],\n        pm_mention_push_disabled_user_ids=info[\"pm_mention_push_disabled_user_ids\"],\n        stream_push_user_ids=info[\"stream_push_user_ids\"],\n        stream_email_user_ids=info[\"stream_email_user_ids\"],\n        muted_sender_user_ids=info[\"muted_sender_user_ids\"],\n        um_eligible_user_ids=info[\"um_eligible_user_ids\"],\n        long_term_idle_user_ids=info[\"long_term_idle_user_ids\"],\n        default_bot_user_ids=info[\"default_bot_user_ids\"],\n        service_bot_tuples=info[\"service_bot_tuples\"],\n        all_bot_user_ids=info[\"all_bot_user_ids\"],\n        wildcard_mention_user_ids=wildcard_mention_user_ids,\n        links_for_embed=links_for_embed,\n        widget_content=widget_content_dict,\n        limit_unread_user_ids=limit_unread_user_ids,\n    )\n\n    return message_send_dict\n\n\ndef do_send_messages(\n    send_message_requests_maybe_none: Sequence[Optional[SendMessageRequest]],\n    email_gateway: bool = False,\n    mark_as_read: Sequence[int] = [],\n) -> List[int]:\n    \"\"\"See\n    https://zulip.readthedocs.io/en/latest/subsystems/sending-messages.html\n    for high-level documentation on this subsystem.\n    \"\"\"\n\n    # Filter out messages which didn't pass internal_prep_message properly\n    send_message_requests = [\n        send_request\n        for send_request in send_message_requests_maybe_none\n        if send_request is not None\n    ]\n\n    # Save the message receipts in the database\n    user_message_flags: Dict[int, Dict[int, List[str]]] = defaultdict(dict)\n    with transaction.atomic():\n        Message.objects.bulk_create(send_request.message for send_request in send_message_requests)\n\n        # Claim attachments in message\n        for send_request in send_message_requests:\n            if do_claim_attachments(\n                send_request.message, send_request.rendering_result.potential_attachment_path_ids\n            ):\n                send_request.message.has_attachment = True\n                send_request.message.save(update_fields=[\"has_attachment\"])\n\n        ums: List[UserMessageLite] = []\n        for send_request in send_message_requests:\n            # Service bots (outgoing webhook bots and embedded bots) don't store UserMessage rows;\n            # they will be processed later.\n            mentioned_user_ids = send_request.rendering_result.mentions_user_ids\n\n            # Extend the set with users who have muted the sender.\n            mark_as_read_user_ids = send_request.muted_sender_user_ids\n            mark_as_read_user_ids.update(mark_as_read)\n\n            user_messages = create_user_messages(\n                message=send_request.message,\n                rendering_result=send_request.rendering_result,\n                um_eligible_user_ids=send_request.um_eligible_user_ids,\n                long_term_idle_user_ids=send_request.long_term_idle_user_ids,\n                stream_push_user_ids=send_request.stream_push_user_ids,\n                stream_email_user_ids=send_request.stream_email_user_ids,\n                mentioned_user_ids=mentioned_user_ids,\n                mark_as_read_user_ids=mark_as_read_user_ids,\n                limit_unread_user_ids=send_request.limit_unread_user_ids,\n            )\n\n            for um in user_messages:\n                user_message_flags[send_request.message.id][um.user_profile_id] = um.flags_list()\n\n            ums.extend(user_messages)\n\n            send_request.message.service_queue_events = get_service_bot_events(\n                sender=send_request.message.sender,\n                service_bot_tuples=send_request.service_bot_tuples,\n                mentioned_user_ids=mentioned_user_ids,\n                active_user_ids=send_request.active_user_ids,\n                recipient_type=send_request.message.recipient.type,\n            )\n\n        bulk_insert_ums(ums)\n\n        for send_request in send_message_requests:\n            do_widget_post_save_actions(send_request)\n\n    # This next loop is responsible for notifying other parts of the\n    # Zulip system about the messages we just committed to the database:\n    # * Notifying clients via send_event\n    # * Triggering outgoing webhooks via the service event queue.\n    # * Updating the `first_message_id` field for streams without any message history.\n    # * Implementing the Welcome Bot reply hack\n    # * Adding links to the embed_links queue for open graph processing.\n    for send_request in send_message_requests:\n        realm_id: Optional[int] = None\n        if send_request.message.is_stream_message():\n            if send_request.stream is None:\n                stream_id = send_request.message.recipient.type_id\n                send_request.stream = Stream.objects.select_related().get(id=stream_id)\n            # assert needed because stubs for django are missing\n            assert send_request.stream is not None\n            realm_id = send_request.stream.realm_id\n\n        # Deliver events to the real-time push system, as well as\n        # enqueuing any additional processing triggered by the message.\n        wide_message_dict = MessageDict.wide_dict(send_request.message, realm_id)\n\n        user_flags = user_message_flags.get(send_request.message.id, {})\n\n        \"\"\"\n        TODO:  We may want to limit user_ids to only those users who have\n               UserMessage rows, if only for minor performance reasons.\n\n               For now we queue events for all subscribers/sendees of the\n               message, since downstream code may still do notifications\n               that don't require UserMessage rows.\n\n               Our automated tests have gotten better on this codepath,\n               but we may have coverage gaps, so we should be careful\n               about changing the next line.\n        \"\"\"\n        user_ids = send_request.active_user_ids | set(user_flags.keys())\n        sender_id = send_request.message.sender_id\n\n        # We make sure the sender is listed first in the `users` list;\n        # this results in the sender receiving the message first if\n        # there are thousands of recipients, decreasing perceived latency.\n        if sender_id in user_ids:\n            user_list = [sender_id] + list(user_ids - {sender_id})\n        else:\n            user_list = list(user_ids)\n\n        class UserData(TypedDict):\n            id: int\n            flags: List[str]\n            mentioned_user_group_id: Optional[int]\n\n        users: List[UserData] = []\n        for user_id in user_list:\n            flags = user_flags.get(user_id, [])\n            user_data: UserData = dict(id=user_id, flags=flags, mentioned_user_group_id=None)\n\n            if user_id in send_request.mentioned_user_groups_map:\n                user_data[\"mentioned_user_group_id\"] = send_request.mentioned_user_groups_map[\n                    user_id\n                ]\n\n            users.append(user_data)\n\n        sender = send_request.message.sender\n        message_type = wide_message_dict[\"type\"]\n        active_users_data = [\n            ActivePresenceIdleUserData(\n                alerted=\"has_alert_word\" in user_flags.get(user_id, []),\n                notifications_data=UserMessageNotificationsData.from_user_id_sets(\n                    user_id=user_id,\n                    flags=user_flags.get(user_id, []),\n                    private_message=(message_type == \"private\"),\n                    online_push_user_ids=send_request.online_push_user_ids,\n                    pm_mention_push_disabled_user_ids=send_request.pm_mention_push_disabled_user_ids,\n                    pm_mention_email_disabled_user_ids=send_request.pm_mention_email_disabled_user_ids,\n                    stream_push_user_ids=send_request.stream_push_user_ids,\n                    stream_email_user_ids=send_request.stream_email_user_ids,\n                    wildcard_mention_user_ids=send_request.wildcard_mention_user_ids,\n                    muted_sender_user_ids=send_request.muted_sender_user_ids,\n                    all_bot_user_ids=send_request.all_bot_user_ids,\n                ),\n            )\n            for user_id in send_request.active_user_ids\n        ]\n\n        presence_idle_user_ids = get_active_presence_idle_user_ids(\n            realm=sender.realm,\n            sender_id=sender.id,\n            active_users_data=active_users_data,\n        )\n\n        event = dict(\n            type=\"message\",\n            message=send_request.message.id,\n            message_dict=wide_message_dict,\n            presence_idle_user_ids=presence_idle_user_ids,\n            online_push_user_ids=list(send_request.online_push_user_ids),\n            pm_mention_push_disabled_user_ids=list(send_request.pm_mention_push_disabled_user_ids),\n            pm_mention_email_disabled_user_ids=list(\n                send_request.pm_mention_email_disabled_user_ids\n            ),\n            stream_push_user_ids=list(send_request.stream_push_user_ids),\n            stream_email_user_ids=list(send_request.stream_email_user_ids),\n            wildcard_mention_user_ids=list(send_request.wildcard_mention_user_ids),\n            muted_sender_user_ids=list(send_request.muted_sender_user_ids),\n            all_bot_user_ids=list(send_request.all_bot_user_ids),\n        )\n\n        if send_request.message.is_stream_message():\n            # Note: This is where authorization for single-stream\n            # get_updates happens! We only attach stream data to the\n            # notify new_message request if it's a public stream,\n            # ensuring that in the tornado server, non-public stream\n            # messages are only associated to their subscribed users.\n\n            # assert needed because stubs for django are missing\n            assert send_request.stream is not None\n            if send_request.stream.is_public():\n                event[\"realm_id\"] = send_request.stream.realm_id\n                event[\"stream_name\"] = send_request.stream.name\n            if send_request.stream.invite_only:\n                event[\"invite_only\"] = True\n            if send_request.stream.first_message_id is None:\n                send_request.stream.first_message_id = send_request.message.id\n                send_request.stream.save(update_fields=[\"first_message_id\"])\n        if send_request.local_id is not None:\n            event[\"local_id\"] = send_request.local_id\n        if send_request.sender_queue_id is not None:\n            event[\"sender_queue_id\"] = send_request.sender_queue_id\n        send_event(send_request.realm, event, users)\n\n        if send_request.links_for_embed:\n            event_data = {\n                \"message_id\": send_request.message.id,\n                \"message_content\": send_request.message.content,\n                \"message_realm_id\": send_request.realm.id,\n                \"urls\": list(send_request.links_for_embed),\n            }\n            queue_json_publish(\"embed_links\", event_data)\n\n        if send_request.message.recipient.type == Recipient.PERSONAL:\n            welcome_bot_id = get_system_bot(\n                settings.WELCOME_BOT, send_request.message.sender.realm_id\n            ).id\n            if (\n                welcome_bot_id in send_request.active_user_ids\n                and welcome_bot_id != send_request.message.sender_id\n            ):\n                from zerver.lib.onboarding import send_welcome_bot_response\n\n                send_welcome_bot_response(send_request)\n\n        for queue_name, events in send_request.message.service_queue_events.items():\n            for event in events:\n                queue_json_publish(\n                    queue_name,\n                    {\n                        \"message\": wide_message_dict,\n                        \"trigger\": event[\"trigger\"],\n                        \"user_profile_id\": event[\"user_profile_id\"],\n                    },\n                )\n\n    return [send_request.message.id for send_request in send_message_requests]\n\n\nclass UserMessageLite:\n    \"\"\"\n    The Django ORM is too slow for bulk operations.  This class\n    is optimized for the simple use case of inserting a bunch of\n    rows into zerver_usermessage.\n    \"\"\"\n\n    def __init__(self, user_profile_id: int, message_id: int, flags: int) -> None:\n        self.user_profile_id = user_profile_id\n        self.message_id = message_id\n        self.flags = flags\n\n    def flags_list(self) -> List[str]:\n        return UserMessage.flags_list_for_flags(self.flags)\n\n\ndef create_user_messages(\n    message: Message,\n    rendering_result: MessageRenderingResult,\n    um_eligible_user_ids: AbstractSet[int],\n    long_term_idle_user_ids: AbstractSet[int],\n    stream_push_user_ids: AbstractSet[int],\n    stream_email_user_ids: AbstractSet[int],\n    mentioned_user_ids: AbstractSet[int],\n    mark_as_read_user_ids: Set[int],\n    limit_unread_user_ids: Optional[Set[int]],\n) -> List[UserMessageLite]:\n    # These properties on the Message are set via\n    # render_markdown by code in the Markdown inline patterns\n    ids_with_alert_words = rendering_result.user_ids_with_alert_words\n    sender_id = message.sender.id\n    is_stream_message = message.is_stream_message()\n\n    base_flags = 0\n    if rendering_result.mentions_wildcard:\n        base_flags |= UserMessage.flags.wildcard_mentioned\n    if message.recipient.type in [Recipient.HUDDLE, Recipient.PERSONAL]:\n        base_flags |= UserMessage.flags.is_private\n\n    # For long_term_idle (aka soft-deactivated) users, we are allowed\n    # to optimize by lazily not creating UserMessage rows that would\n    # have the default 0 flag set (since the soft-reactivation logic\n    # knows how to create those when the user comes back).  We need to\n    # create the UserMessage rows for these long_term_idle users\n    # non-lazily in a few cases:\n    #\n    # * There are nonzero flags (e.g. the user was mentioned), since\n    #   that case is rare and this saves a lot of complexity in\n    #   soft-reactivation.\n    #\n    # * If the user is going to be notified (e.g. they get push/email\n    #   notifications for every message on a stream), since in that\n    #   case the notifications code will call `access_message` on the\n    #   message to re-verify permissions, and for private streams,\n    #   will get an error if the UserMessage row doesn't exist yet.\n    #\n    # See https://zulip.readthedocs.io/en/latest/subsystems/sending-messages.html#soft-deactivation\n    # for details on this system.\n    user_messages = []\n    for user_profile_id in um_eligible_user_ids:\n        flags = base_flags\n        if (\n            (user_profile_id == sender_id and message.sent_by_human())\n            or user_profile_id in mark_as_read_user_ids\n            or (limit_unread_user_ids is not None and user_profile_id not in limit_unread_user_ids)\n        ):\n            flags |= UserMessage.flags.read\n        if user_profile_id in mentioned_user_ids:\n            flags |= UserMessage.flags.mentioned\n        if user_profile_id in ids_with_alert_words:\n            flags |= UserMessage.flags.has_alert_word\n\n        if (\n            user_profile_id in long_term_idle_user_ids\n            and user_profile_id not in stream_push_user_ids\n            and user_profile_id not in stream_email_user_ids\n            and is_stream_message\n            and int(flags) == 0\n        ):\n            continue\n\n        um = UserMessageLite(\n            user_profile_id=user_profile_id,\n            message_id=message.id,\n            flags=flags,\n        )\n        user_messages.append(um)\n\n    return user_messages\n\n\ndef bulk_insert_ums(ums: List[UserMessageLite]) -> None:\n    \"\"\"\n    Doing bulk inserts this way is much faster than using Django,\n    since we don't have any ORM overhead.  Profiling with 1000\n    users shows a speedup of 0.436 -> 0.027 seconds, so we're\n    talking about a 15x speedup.\n    \"\"\"\n    if not ums:\n        return\n\n    vals = [(um.user_profile_id, um.message_id, um.flags) for um in ums]\n    query = SQL(\n        \"\"\"\n        INSERT into\n            zerver_usermessage (user_profile_id, message_id, flags)\n        VALUES %s\n    \"\"\"\n    )\n\n    with connection.cursor() as cursor:\n        execute_values(cursor.cursor, query, vals)\n\n\ndef verify_submessage_sender(\n    *,\n    message_id: int,\n    message_sender_id: int,\n    submessage_sender_id: int,\n) -> None:\n    \"\"\"Even though our submessage architecture is geared toward\n    collaboration among all message readers, we still enforce\n    the the first person to attach a submessage to the message\n    must be the original sender of the message.\n    \"\"\"\n\n    if message_sender_id == submessage_sender_id:\n        return\n\n    if SubMessage.objects.filter(\n        message_id=message_id,\n        sender_id=message_sender_id,\n    ).exists():\n        return\n\n    raise JsonableError(_(\"You cannot attach a submessage to this message.\"))\n\n\ndef do_add_submessage(\n    realm: Realm,\n    sender_id: int,\n    message_id: int,\n    msg_type: str,\n    content: str,\n) -> None:\n    \"\"\"Should be called while holding a SELECT FOR UPDATE lock\n    (e.g. via access_message(..., lock_message=True)) on the\n    Message row, to prevent race conditions.\n    \"\"\"\n    submessage = SubMessage(\n        sender_id=sender_id,\n        message_id=message_id,\n        msg_type=msg_type,\n        content=content,\n    )\n    submessage.save()\n\n    event = dict(\n        type=\"submessage\",\n        msg_type=msg_type,\n        message_id=message_id,\n        submessage_id=submessage.id,\n        sender_id=sender_id,\n        content=content,\n    )\n    ums = UserMessage.objects.filter(message_id=message_id)\n    target_user_ids = [um.user_profile_id for um in ums]\n\n    transaction.on_commit(lambda: send_event(realm, event, target_user_ids))\n\n\ndef notify_reaction_update(\n    user_profile: UserProfile, message: Message, reaction: Reaction, op: str\n) -> None:\n    user_dict = {\n        \"user_id\": user_profile.id,\n        \"email\": user_profile.email,\n        \"full_name\": user_profile.full_name,\n    }\n\n    event: Dict[str, Any] = {\n        \"type\": \"reaction\",\n        \"op\": op,\n        \"user_id\": user_profile.id,\n        # TODO: We plan to remove this redundant user_dict object once\n        # clients are updated to support accessing use user_id.  See\n        # https://github.com/zulip/zulip/pull/14711 for details.\n        \"user\": user_dict,\n        \"message_id\": message.id,\n        \"emoji_name\": reaction.emoji_name,\n        \"emoji_code\": reaction.emoji_code,\n        \"reaction_type\": reaction.reaction_type,\n    }\n\n    # Update the cached message since new reaction is added.\n    update_to_dict_cache([message])\n\n    # Recipients for message update events, including reactions, are\n    # everyone who got the original message, plus subscribers of\n    # streams with the access to stream's full history.\n    #\n    # This means reactions won't live-update in preview narrows for a\n    # stream the user isn't yet subscribed to; this is the right\n    # performance tradeoff to avoid sending every reaction to public\n    # stream messages to all users.\n    #\n    # To ensure that reactions do live-update for any user who has\n    # actually participated in reacting to a message, we add a\n    # \"historical\" UserMessage row for any user who reacts to message,\n    # subscribing them to future notifications, even if they are not\n    # subscribed to the stream.\n    user_ids = set(\n        UserMessage.objects.filter(message=message.id).values_list(\"user_profile_id\", flat=True)\n    )\n    if message.recipient.type == Recipient.STREAM:\n        stream_id = message.recipient.type_id\n        stream = Stream.objects.get(id=stream_id)\n        user_ids |= subscriber_ids_with_stream_history_access(stream)\n\n    transaction.on_commit(lambda: send_event(user_profile.realm, event, list(user_ids)))\n\n\ndef do_add_reaction(\n    user_profile: UserProfile,\n    message: Message,\n    emoji_name: str,\n    emoji_code: str,\n    reaction_type: str,\n) -> None:\n    \"\"\"Should be called while holding a SELECT FOR UPDATE lock\n    (e.g. via access_message(..., lock_message=True)) on the\n    Message row, to prevent race conditions.\n    \"\"\"\n\n    reaction = Reaction(\n        user_profile=user_profile,\n        message=message,\n        emoji_name=emoji_name,\n        emoji_code=emoji_code,\n        reaction_type=reaction_type,\n    )\n\n    reaction.save()\n\n    notify_reaction_update(user_profile, message, reaction, \"add\")\n\n\ndef check_add_reaction(\n    user_profile: UserProfile,\n    message_id: int,\n    emoji_name: str,\n    emoji_code: Optional[str],\n    reaction_type: Optional[str],\n) -> None:\n    message, user_message = access_message(user_profile, message_id, lock_message=True)\n\n    if emoji_code is None:\n        # The emoji_code argument is only required for rare corner\n        # cases discussed in the long block comment below.  For simple\n        # API clients, we allow specifying just the name, and just\n        # look up the code using the current name->code mapping.\n        emoji_code = emoji_name_to_emoji_code(message.sender.realm, emoji_name)[0]\n\n    if reaction_type is None:\n        reaction_type = emoji_name_to_emoji_code(message.sender.realm, emoji_name)[1]\n\n    if Reaction.objects.filter(\n        user_profile=user_profile,\n        message=message,\n        emoji_code=emoji_code,\n        reaction_type=reaction_type,\n    ).exists():\n        raise JsonableError(_(\"Reaction already exists.\"))\n\n    query = Reaction.objects.filter(\n        message=message, emoji_code=emoji_code, reaction_type=reaction_type\n    )\n    if query.exists():\n        # If another user has already reacted to this message with\n        # same emoji code, we treat the new reaction as a vote for the\n        # existing reaction.  So the emoji name used by that earlier\n        # reaction takes precedence over whatever was passed in this\n        # request.  This is necessary to avoid a message having 2\n        # \"different\" emoji reactions with the same emoji code (and\n        # thus same image) on the same message, which looks ugly.\n        #\n        # In this \"voting for an existing reaction\" case, we shouldn't\n        # check whether the emoji code and emoji name match, since\n        # it's possible that the (emoji_type, emoji_name, emoji_code)\n        # triple for this existing reaction may not pass validation\n        # now (e.g. because it is for a realm emoji that has been\n        # since deactivated).  We still want to allow users to add a\n        # vote any old reaction they see in the UI even if that is a\n        # deactivated custom emoji, so we just use the emoji name from\n        # the existing reaction with no further validation.\n        reaction = query.first()\n        assert reaction is not None\n        emoji_name = reaction.emoji_name\n    else:\n        # Otherwise, use the name provided in this request, but verify\n        # it is valid in the user's realm (e.g. not a deactivated\n        # realm emoji).\n        check_emoji_request(user_profile.realm, emoji_name, emoji_code, reaction_type)\n\n    if user_message is None:\n        # See called function for more context.\n        create_historical_user_messages(user_id=user_profile.id, message_ids=[message.id])\n\n    do_add_reaction(user_profile, message, emoji_name, emoji_code, reaction_type)\n\n\ndef do_remove_reaction(\n    user_profile: UserProfile, message: Message, emoji_code: str, reaction_type: str\n) -> None:\n    \"\"\"Should be called while holding a SELECT FOR UPDATE lock\n    (e.g. via access_message(..., lock_message=True)) on the\n    Message row, to prevent race conditions.\n    \"\"\"\n    reaction = Reaction.objects.filter(\n        user_profile=user_profile,\n        message=message,\n        emoji_code=emoji_code,\n        reaction_type=reaction_type,\n    ).get()\n    reaction.delete()\n\n    notify_reaction_update(user_profile, message, reaction, \"remove\")\n\n\ndef do_send_typing_notification(\n    realm: Realm, sender: UserProfile, recipient_user_profiles: List[UserProfile], operator: str\n) -> None:\n\n    sender_dict = {\"user_id\": sender.id, \"email\": sender.email}\n\n    # Include a list of recipients in the event body to help identify where the typing is happening\n    recipient_dicts = [\n        {\"user_id\": profile.id, \"email\": profile.email} for profile in recipient_user_profiles\n    ]\n    event = dict(\n        type=\"typing\",\n        message_type=\"private\",\n        op=operator,\n        sender=sender_dict,\n        recipients=recipient_dicts,\n    )\n\n    # Only deliver the notification to active user recipients\n    user_ids_to_notify = [user.id for user in recipient_user_profiles if user.is_active]\n\n    send_event(realm, event, user_ids_to_notify)\n\n\n# check_send_typing_notification:\n# Checks the typing notification and sends it\ndef check_send_typing_notification(sender: UserProfile, user_ids: List[int], operator: str) -> None:\n    realm = sender.realm\n\n    if sender.id not in user_ids:\n        user_ids.append(sender.id)\n\n    # If any of the user_ids being sent in are invalid, we will\n    # just reject the whole request, since a partial list of user_ids\n    # can create confusion related to huddles.  Plus it's a good\n    # sign that a client is confused (or possibly even malicious) if\n    # we get bad user_ids.\n    user_profiles = []\n    for user_id in user_ids:\n        try:\n            # We include cross-bot realms as possible recipients,\n            # so that clients can know which huddle conversation\n            # is relevant here.\n            user_profile = get_user_by_id_in_realm_including_cross_realm(user_id, sender.realm)\n        except UserProfile.DoesNotExist:\n            raise JsonableError(_(\"Invalid user ID {}\").format(user_id))\n        user_profiles.append(user_profile)\n\n    do_send_typing_notification(\n        realm=realm,\n        sender=sender,\n        recipient_user_profiles=user_profiles,\n        operator=operator,\n    )\n\n\ndef do_send_stream_typing_notification(\n    sender: UserProfile, operator: str, stream: Stream, topic: str\n) -> None:\n\n    sender_dict = {\"user_id\": sender.id, \"email\": sender.email}\n\n    event = dict(\n        type=\"typing\",\n        message_type=\"stream\",\n        op=operator,\n        sender=sender_dict,\n        stream_id=stream.id,\n        topic=topic,\n    )\n\n    user_ids_to_notify = get_user_ids_for_streams({stream.id})[stream.id]\n\n    send_event(sender.realm, event, user_ids_to_notify)\n\n\ndef ensure_stream(\n    realm: Realm,\n    stream_name: str,\n    invite_only: bool = False,\n    stream_description: str = \"\",\n    *,\n    acting_user: Optional[UserProfile],\n) -> Stream:\n    return create_stream_if_needed(\n        realm,\n        stream_name,\n        invite_only=invite_only,\n        stream_description=stream_description,\n        acting_user=acting_user,\n    )[0]\n\n\ndef get_recipient_from_user_profiles(\n    recipient_profiles: Sequence[UserProfile],\n    forwarded_mirror_message: bool,\n    forwarder_user_profile: Optional[UserProfile],\n    sender: UserProfile,\n) -> Recipient:\n\n    # Avoid mutating the passed in list of recipient_profiles.\n    recipient_profiles_map = {user_profile.id: user_profile for user_profile in recipient_profiles}\n\n    if forwarded_mirror_message:\n        # In our mirroring integrations with some third-party\n        # protocols, bots subscribed to the third-party protocol\n        # forward to Zulip messages that they received in the\n        # third-party service.  The permissions model for that\n        # forwarding is that users can only submit to Zulip private\n        # messages they personally received, and here we do the check\n        # for whether forwarder_user_profile is among the private\n        # message recipients of the message.\n        assert forwarder_user_profile is not None\n        if forwarder_user_profile.id not in recipient_profiles_map:\n            raise ValidationError(_(\"User not authorized for this query\"))\n\n    # If the private message is just between the sender and\n    # another person, force it to be a personal internally\n    if len(recipient_profiles_map) == 2 and sender.id in recipient_profiles_map:\n        del recipient_profiles_map[sender.id]\n\n    assert recipient_profiles_map\n    if len(recipient_profiles_map) == 1:\n        [user_profile] = recipient_profiles_map.values()\n        return Recipient(\n            id=user_profile.recipient_id,\n            type=Recipient.PERSONAL,\n            type_id=user_profile.id,\n        )\n\n    # Otherwise, we need a huddle.  Make sure the sender is included in huddle messages\n    recipient_profiles_map[sender.id] = sender\n\n    user_ids = set(recipient_profiles_map)\n    return get_huddle_recipient(user_ids)\n\n\ndef validate_recipient_user_profiles(\n    user_profiles: Sequence[UserProfile], sender: UserProfile, allow_deactivated: bool = False\n) -> Sequence[UserProfile]:\n    recipient_profiles_map: Dict[int, UserProfile] = {}\n\n    # We exempt cross-realm bots from the check that all the recipients\n    # are in the same realm.\n    realms = set()\n    if not is_cross_realm_bot_email(sender.email):\n        realms.add(sender.realm_id)\n\n    for user_profile in user_profiles:\n        if (\n            not user_profile.is_active\n            and not user_profile.is_mirror_dummy\n            and not allow_deactivated\n        ) or user_profile.realm.deactivated:\n            raise ValidationError(\n                _(\"'{email}' is no longer using Zulip.\").format(email=user_profile.email)\n            )\n        recipient_profiles_map[user_profile.id] = user_profile\n        if not is_cross_realm_bot_email(user_profile.email):\n            realms.add(user_profile.realm_id)\n\n    if len(realms) > 1:\n        raise ValidationError(_(\"You can't send private messages outside of your organization.\"))\n\n    return list(recipient_profiles_map.values())\n\n\ndef recipient_for_user_profiles(\n    user_profiles: Sequence[UserProfile],\n    forwarded_mirror_message: bool,\n    forwarder_user_profile: Optional[UserProfile],\n    sender: UserProfile,\n    allow_deactivated: bool = False,\n) -> Recipient:\n\n    recipient_profiles = validate_recipient_user_profiles(\n        user_profiles, sender, allow_deactivated=allow_deactivated\n    )\n\n    return get_recipient_from_user_profiles(\n        recipient_profiles, forwarded_mirror_message, forwarder_user_profile, sender\n    )\n\n\ndef already_sent_mirrored_message_id(message: Message) -> Optional[int]:\n    if message.recipient.type == Recipient.HUDDLE:\n        # For huddle messages, we use a 10-second window because the\n        # timestamps aren't guaranteed to actually match between two\n        # copies of the same message.\n        time_window = datetime.timedelta(seconds=10)\n    else:\n        time_window = datetime.timedelta(seconds=0)\n\n    query = Message.objects.filter(\n        sender=message.sender,\n        recipient=message.recipient,\n        content=message.content,\n        sending_client=message.sending_client,\n        date_sent__gte=message.date_sent - time_window,\n        date_sent__lte=message.date_sent + time_window,\n    )\n\n    messages = filter_by_exact_message_topic(\n        query=query,\n        message=message,\n    )\n\n    if messages.exists():\n        return messages[0].id\n    return None\n\n\ndef extract_stream_indicator(s: str) -> Union[str, int]:\n    # Users can pass stream name as either an id or a name,\n    # and if they choose to pass a name, they may JSON encode\n    # it for legacy reasons.\n\n    try:\n        data = orjson.loads(s)\n    except orjson.JSONDecodeError:\n        # If there was no JSON encoding, then we just\n        # have a raw stream name.\n        return s\n\n    # We should stop supporting this odd use case\n    # once we improve our documentation.\n    if isinstance(data, list):\n        if len(data) != 1:  # nocoverage\n            raise JsonableError(_(\"Expected exactly one stream\"))\n        data = data[0]\n\n    if isinstance(data, str):\n        # We had a JSON-encoded stream name.\n        return data\n\n    if isinstance(data, int):\n        # We had a stream id.\n        return data\n\n    raise JsonableError(_(\"Invalid data type for stream\"))\n\n\ndef extract_private_recipients(s: str) -> Union[List[str], List[int]]:\n    # We try to accept multiple incoming formats for recipients.\n    # See test_extract_recipients() for examples of what we allow.\n\n    try:\n        data = orjson.loads(s)\n    except orjson.JSONDecodeError:\n        data = s\n\n    if isinstance(data, str):\n        data = data.split(\",\")\n\n    if not isinstance(data, list):\n        raise JsonableError(_(\"Invalid data type for recipients\"))\n\n    if not data:\n        # We don't complain about empty message recipients here\n        return data\n\n    if isinstance(data[0], str):\n        return get_validated_emails(data)\n\n    if not isinstance(data[0], int):\n        raise JsonableError(_(\"Invalid data type for recipients\"))\n\n    return get_validated_user_ids(data)\n\n\ndef get_validated_user_ids(user_ids: Collection[int]) -> List[int]:\n    for user_id in user_ids:\n        if not isinstance(user_id, int):\n            raise JsonableError(_(\"Recipient lists may contain emails or user IDs, but not both.\"))\n\n    return list(set(user_ids))\n\n\ndef get_validated_emails(emails: Collection[str]) -> List[str]:\n    for email in emails:\n        if not isinstance(email, str):\n            raise JsonableError(_(\"Recipient lists may contain emails or user IDs, but not both.\"))\n\n    return list(filter(bool, {email.strip() for email in emails}))\n\n\ndef check_send_stream_message(\n    sender: UserProfile,\n    client: Client,\n    stream_name: str,\n    topic: str,\n    body: str,\n    realm: Optional[Realm] = None,\n) -> int:\n    addressee = Addressee.for_stream_name(stream_name, topic)\n    message = check_message(sender, client, addressee, body, realm)\n\n    return do_send_messages([message])[0]\n\n\ndef check_send_stream_message_by_id(\n    sender: UserProfile,\n    client: Client,\n    stream_id: int,\n    topic: str,\n    body: str,\n    realm: Optional[Realm] = None,\n) -> int:\n    addressee = Addressee.for_stream_id(stream_id, topic)\n    message = check_message(sender, client, addressee, body, realm)\n\n    return do_send_messages([message])[0]\n\n\ndef check_send_private_message(\n    sender: UserProfile, client: Client, receiving_user: UserProfile, body: str\n) -> int:\n    addressee = Addressee.for_user_profile(receiving_user)\n    message = check_message(sender, client, addressee, body)\n\n    return do_send_messages([message])[0]\n\n\n# check_send_message:\n# Returns the id of the sent message.  Has same argspec as check_message.\ndef check_send_message(\n    sender: UserProfile,\n    client: Client,\n    message_type_name: str,\n    message_to: Union[Sequence[int], Sequence[str]],\n    topic_name: Optional[str],\n    message_content: str,\n    realm: Optional[Realm] = None,\n    forged: bool = False,\n    forged_timestamp: Optional[float] = None,\n    forwarder_user_profile: Optional[UserProfile] = None,\n    local_id: Optional[str] = None,\n    sender_queue_id: Optional[str] = None,\n    widget_content: Optional[str] = None,\n    *,\n    skip_stream_access_check: bool = False,\n) -> int:\n\n    addressee = Addressee.legacy_build(sender, message_type_name, message_to, topic_name)\n    try:\n        message = check_message(\n            sender,\n            client,\n            addressee,\n            message_content,\n            realm,\n            forged,\n            forged_timestamp,\n            forwarder_user_profile,\n            local_id,\n            sender_queue_id,\n            widget_content,\n            skip_stream_access_check=skip_stream_access_check,\n        )\n    except ZephyrMessageAlreadySentException as e:\n        return e.message_id\n    return do_send_messages([message])[0]\n\n\ndef check_schedule_message(\n    sender: UserProfile,\n    client: Client,\n    message_type_name: str,\n    message_to: Union[Sequence[str], Sequence[int]],\n    topic_name: Optional[str],\n    message_content: str,\n    delivery_type: str,\n    deliver_at: datetime.datetime,\n    realm: Optional[Realm] = None,\n    forwarder_user_profile: Optional[UserProfile] = None,\n) -> int:\n    addressee = Addressee.legacy_build(sender, message_type_name, message_to, topic_name)\n\n    send_request = check_message(\n        sender,\n        client,\n        addressee,\n        message_content,\n        realm=realm,\n        forwarder_user_profile=forwarder_user_profile,\n    )\n    send_request.deliver_at = deliver_at\n    send_request.delivery_type = delivery_type\n\n    recipient = send_request.message.recipient\n    if delivery_type == \"remind\" and (\n        recipient.type != Recipient.STREAM and recipient.type_id != sender.id\n    ):\n        raise JsonableError(_(\"Reminders can only be set for streams.\"))\n\n    return do_schedule_messages([send_request])[0]\n\n\ndef validate_message_edit_payload(\n    message: Message,\n    stream_id: Optional[int],\n    topic_name: Optional[str],\n    propagate_mode: Optional[str],\n    content: Optional[str],\n) -> None:\n    \"\"\"\n    Checks that the data sent is well-formed. Does not handle editability, permissions etc.\n    \"\"\"\n    if topic_name is None and content is None and stream_id is None:\n        raise JsonableError(_(\"Nothing to change\"))\n\n    if not message.is_stream_message():\n        if stream_id is not None:\n            raise JsonableError(_(\"Private messages cannot be moved to streams.\"))\n        if topic_name is not None:\n            raise JsonableError(_(\"Private messages cannot have topics.\"))\n\n    if propagate_mode != \"change_one\" and topic_name is None and stream_id is None:\n        raise JsonableError(_(\"Invalid propagate_mode without topic edit\"))\n\n    if topic_name is not None:\n        check_stream_topic(topic_name)\n\n    if stream_id is not None and content is not None:\n        raise JsonableError(_(\"Cannot change message content while changing stream\"))\n\n    # Right now, we prevent users from editing widgets.\n    if content is not None and is_widget_message(message):\n        raise JsonableError(_(\"Widgets cannot be edited.\"))\n\n\ndef can_edit_content_or_topic(\n    message: Message,\n    user_profile: UserProfile,\n    is_no_topic_msg: bool,\n    content: Optional[str] = None,\n    topic_name: Optional[str] = None,\n) -> bool:\n    # You have permission to edit the message (both content and topic) if you sent it.\n    if message.sender_id == user_profile.id:\n        return True\n\n    # You cannot edit the content of message sent by someone else.\n    if content is not None:\n        return False\n\n    assert topic_name is not None\n\n    # The following cases are the various reasons a user might be\n    # allowed to edit topics.\n\n    # We allow anyone to edit (no topic) messages to help tend them.\n    if is_no_topic_msg:\n        return True\n\n    # The can_edit_topic_of_any_message helper returns whether the user can edit the topic\n    # or not based on edit_topic_policy setting and the user's role.\n    if user_profile.can_edit_topic_of_any_message():\n        return True\n\n    return False\n\n\ndef check_update_message(\n    user_profile: UserProfile,\n    message_id: int,\n    stream_id: Optional[int] = None,\n    topic_name: Optional[str] = None,\n    propagate_mode: str = \"change_one\",\n    send_notification_to_old_thread: bool = True,\n    send_notification_to_new_thread: bool = True,\n    content: Optional[str] = None,\n) -> int:\n    \"\"\"This will update a message given the message id and user profile.\n    It checks whether the user profile has the permission to edit the message\n    and raises a JsonableError if otherwise.\n    It returns the number changed.\n    \"\"\"\n    message, ignored_user_message = access_message(user_profile, message_id)\n\n    if not user_profile.realm.allow_message_editing:\n        raise JsonableError(_(\"Your organization has turned off message editing\"))\n\n    # The zerver/views/message_edit.py call point already strips this\n    # via REQ_topic; so we can delete this line if we arrange a\n    # contract where future callers in the embedded bots system strip\n    # use REQ_topic as well (or otherwise are guaranteed to strip input).\n    if topic_name is not None:\n        topic_name = topic_name.strip()\n        if topic_name == message.topic_name():\n            topic_name = None\n\n    validate_message_edit_payload(message, stream_id, topic_name, propagate_mode, content)\n\n    is_no_topic_msg = message.topic_name() == \"(no topic)\"\n\n    if content is not None or topic_name is not None:\n        if not can_edit_content_or_topic(\n            message, user_profile, is_no_topic_msg, content, topic_name\n        ):\n            raise JsonableError(_(\"You don't have permission to edit this message\"))\n\n    # If there is a change to the content, check that it hasn't been too long\n    # Allow an extra 20 seconds since we potentially allow editing 15 seconds\n    # past the limit, and in case there are network issues, etc. The 15 comes\n    # from (min_seconds_to_edit + seconds_left_buffer) in message_edit.js; if\n    # you change this value also change those two parameters in message_edit.js.\n    edit_limit_buffer = 20\n    if content is not None and user_profile.realm.message_content_edit_limit_seconds > 0:\n        deadline_seconds = user_profile.realm.message_content_edit_limit_seconds + edit_limit_buffer\n        if (timezone_now() - message.date_sent) > datetime.timedelta(seconds=deadline_seconds):\n            raise JsonableError(_(\"The time limit for editing this message has passed\"))\n\n    # If there is a change to the topic, check that the user is allowed to\n    # edit it and that it has not been too long. If this is not the user who\n    # sent the message, they are not the admin, and the time limit for editing\n    # topics is passed, raise an error.\n    if (\n        topic_name is not None\n        and message.sender != user_profile\n        and not user_profile.is_realm_admin\n        and not user_profile.is_moderator\n        and not is_no_topic_msg\n    ):\n        deadline_seconds = Realm.DEFAULT_COMMUNITY_TOPIC_EDITING_LIMIT_SECONDS + edit_limit_buffer\n        if (timezone_now() - message.date_sent) > datetime.timedelta(seconds=deadline_seconds):\n            raise JsonableError(_(\"The time limit for editing this message's topic has passed\"))\n\n    rendering_result = None\n    links_for_embed: Set[str] = set()\n    prior_mention_user_ids: Set[int] = set()\n    mention_data: Optional[MentionData] = None\n    if content is not None:\n        if content.rstrip() == \"\":\n            content = \"(deleted)\"\n        content = normalize_body(content)\n\n        mention_backend = MentionBackend(user_profile.realm_id)\n        mention_data = MentionData(\n            mention_backend=mention_backend,\n            content=content,\n        )\n        user_info = get_user_info_for_message_updates(message.id)\n        prior_mention_user_ids = user_info[\"mention_user_ids\"]\n\n        # We render the message using the current user's realm; since\n        # the cross-realm bots never edit messages, this should be\n        # always correct.\n        # Note: If rendering fails, the called code will raise a JsonableError.\n        rendering_result = render_incoming_message(\n            message,\n            content,\n            user_info[\"message_user_ids\"],\n            user_profile.realm,\n            mention_data=mention_data,\n        )\n        links_for_embed |= rendering_result.links_for_preview\n\n        if message.is_stream_message() and rendering_result.mentions_wildcard:\n            stream = access_stream_by_id(user_profile, message.recipient.type_id)[0]\n            if not wildcard_mention_allowed(message.sender, stream):\n                raise JsonableError(\n                    _(\"You do not have permission to use wildcard mentions in this stream.\")\n                )\n\n    new_stream = None\n    number_changed = 0\n\n    if stream_id is not None:\n        assert message.is_stream_message()\n        if not user_profile.can_move_messages_between_streams():\n            raise JsonableError(_(\"You don't have permission to move this message\"))\n        try:\n            access_stream_by_id(user_profile, message.recipient.type_id)\n        except JsonableError:\n            raise JsonableError(\n                _(\n                    \"You don't have permission to move this message due to missing access to its stream\"\n                )\n            )\n\n        new_stream = access_stream_by_id(user_profile, stream_id, require_active=True)[0]\n        check_stream_access_based_on_stream_post_policy(user_profile, new_stream)\n\n    number_changed = do_update_message(\n        user_profile,\n        message,\n        new_stream,\n        topic_name,\n        propagate_mode,\n        send_notification_to_old_thread,\n        send_notification_to_new_thread,\n        content,\n        rendering_result,\n        prior_mention_user_ids,\n        mention_data,\n    )\n\n    if links_for_embed:\n        event_data = {\n            \"message_id\": message.id,\n            \"message_content\": message.content,\n            # The choice of `user_profile.realm_id` rather than\n            # `sender.realm_id` must match the decision made in the\n            # `render_incoming_message` call earlier in this function.\n            \"message_realm_id\": user_profile.realm_id,\n            \"urls\": list(links_for_embed),\n        }\n        queue_json_publish(\"embed_links\", event_data)\n\n    return number_changed\n\n\ndef check_default_stream_group_name(group_name: str) -> None:\n    if group_name.strip() == \"\":\n        raise JsonableError(_(\"Invalid default stream group name '{}'\").format(group_name))\n    if len(group_name) > DefaultStreamGroup.MAX_NAME_LENGTH:\n        raise JsonableError(\n            _(\"Default stream group name too long (limit: {} characters)\").format(\n                DefaultStreamGroup.MAX_NAME_LENGTH,\n            )\n        )\n    for i in group_name:\n        if ord(i) == 0:\n            raise JsonableError(\n                _(\"Default stream group name '{}' contains NULL (0x00) characters.\").format(\n                    group_name,\n                )\n            )\n\n\ndef send_rate_limited_pm_notification_to_bot_owner(\n    sender: UserProfile, realm: Realm, content: str\n) -> None:\n    \"\"\"\n    Sends a PM error notification to a bot's owner if one hasn't already\n    been sent in the last 5 minutes.\n    \"\"\"\n    if sender.realm.is_zephyr_mirror_realm or sender.realm.deactivated:\n        return\n\n    if not sender.is_bot or sender.bot_owner is None:\n        return\n\n    # Don't send these notifications for cross-realm bot messages\n    # (e.g. from EMAIL_GATEWAY_BOT) since the owner for\n    # EMAIL_GATEWAY_BOT is probably the server administrator, not\n    # the owner of the bot who could potentially fix the problem.\n    if sender.realm != realm:\n        return\n\n    # We warn the user once every 5 minutes to avoid a flood of\n    # PMs on a misconfigured integration, re-using the\n    # UserProfile.last_reminder field, which is not used for bots.\n    last_reminder = sender.last_reminder\n    waitperiod = datetime.timedelta(minutes=UserProfile.BOT_OWNER_STREAM_ALERT_WAITPERIOD)\n    if last_reminder and timezone_now() - last_reminder <= waitperiod:\n        return\n\n    internal_send_private_message(\n        get_system_bot(settings.NOTIFICATION_BOT, sender.bot_owner.realm_id),\n        sender.bot_owner,\n        content,\n    )\n\n    sender.last_reminder = timezone_now()\n    sender.save(update_fields=[\"last_reminder\"])\n\n\ndef send_pm_if_empty_stream(\n    stream: Optional[Stream],\n    realm: Realm,\n    sender: UserProfile,\n    stream_name: Optional[str] = None,\n    stream_id: Optional[int] = None,\n) -> None:\n    \"\"\"If a bot sends a message to a stream that doesn't exist or has no\n    subscribers, sends a notification to the bot owner (if not a\n    cross-realm bot) so that the owner can correct the issue.\"\"\"\n    if not sender.is_bot or sender.bot_owner is None:\n        return\n\n    arg_dict = {\n        \"bot_identity\": f\"`{sender.delivery_email}`\",\n        \"stream_id\": stream_id,\n        \"stream_name\": f\"#**{stream_name}**\",\n        \"new_stream_link\": \"#streams/new\",\n    }\n    if sender.bot_owner is not None:\n        with override_language(sender.bot_owner.default_language):\n            if stream is None:\n                if stream_id is not None:\n                    content = _(\n                        \"Your bot {bot_identity} tried to send a message to stream ID \"\n                        \"{stream_id}, but there is no stream with that ID.\"\n                    ).format(**arg_dict)\n                else:\n                    assert stream_name is not None\n                    content = _(\n                        \"Your bot {bot_identity} tried to send a message to stream \"\n                        \"{stream_name}, but that stream does not exist. \"\n                        \"Click [here]({new_stream_link}) to create it.\"\n                    ).format(**arg_dict)\n            else:\n                if num_subscribers_for_stream_id(stream.id) > 0:\n                    return\n                content = _(\n                    \"Your bot {bot_identity} tried to send a message to \"\n                    \"stream {stream_name}. The stream exists but \"\n                    \"does not have any subscribers.\"\n                ).format(**arg_dict)\n\n        send_rate_limited_pm_notification_to_bot_owner(sender, realm, content)\n\n\ndef validate_stream_name_with_pm_notification(\n    stream_name: str, realm: Realm, sender: UserProfile\n) -> Stream:\n    stream_name = stream_name.strip()\n    check_stream_name(stream_name)\n\n    try:\n        stream = get_stream(stream_name, realm)\n        send_pm_if_empty_stream(stream, realm, sender)\n    except Stream.DoesNotExist:\n        send_pm_if_empty_stream(None, realm, sender, stream_name=stream_name)\n        raise StreamDoesNotExistError(escape(stream_name))\n\n    return stream\n\n\ndef validate_stream_id_with_pm_notification(\n    stream_id: int, realm: Realm, sender: UserProfile\n) -> Stream:\n    try:\n        stream = get_stream_by_id_in_realm(stream_id, realm)\n        send_pm_if_empty_stream(stream, realm, sender)\n    except Stream.DoesNotExist:\n        send_pm_if_empty_stream(None, realm, sender, stream_id=stream_id)\n        raise StreamWithIDDoesNotExistError(stream_id)\n\n    return stream\n\n\ndef check_private_message_policy(\n    realm: Realm, sender: UserProfile, user_profiles: Sequence[UserProfile]\n) -> None:\n    if realm.private_message_policy == Realm.PRIVATE_MESSAGE_POLICY_DISABLED:\n        if sender.is_bot or (len(user_profiles) == 1 and user_profiles[0].is_bot):\n            # We allow PMs only between users and bots, to avoid\n            # breaking the tutorial as well as automated\n            # notifications from system bots to users.\n            return\n\n        raise JsonableError(_(\"Private messages are disabled in this organization.\"))\n\n\n# check_message:\n# Returns message ready for sending with do_send_message on success or the error message (string) on error.\ndef check_message(\n    sender: UserProfile,\n    client: Client,\n    addressee: Addressee,\n    message_content_raw: str,\n    realm: Optional[Realm] = None,\n    forged: bool = False,\n    forged_timestamp: Optional[float] = None,\n    forwarder_user_profile: Optional[UserProfile] = None,\n    local_id: Optional[str] = None,\n    sender_queue_id: Optional[str] = None,\n    widget_content: Optional[str] = None,\n    email_gateway: bool = False,\n    *,\n    skip_stream_access_check: bool = False,\n    mention_backend: Optional[MentionBackend] = None,\n    limit_unread_user_ids: Optional[Set[int]] = None,\n) -> SendMessageRequest:\n    \"\"\"See\n    https://zulip.readthedocs.io/en/latest/subsystems/sending-messages.html\n    for high-level documentation on this subsystem.\n    \"\"\"\n    stream = None\n\n    message_content = normalize_body(message_content_raw)\n\n    if realm is None:\n        realm = sender.realm\n\n    if addressee.is_stream():\n        topic_name = addressee.topic()\n        topic_name = truncate_topic(topic_name)\n\n        stream_name = addressee.stream_name()\n        stream_id = addressee.stream_id()\n\n        if stream_name is not None:\n            stream = validate_stream_name_with_pm_notification(stream_name, realm, sender)\n        elif stream_id is not None:\n            stream = validate_stream_id_with_pm_notification(stream_id, realm, sender)\n        else:\n            stream = addressee.stream()\n        assert stream is not None\n\n        # To save a database round trip, we construct the Recipient\n        # object for the Stream rather than fetching it from the\n        # database using the stream.recipient foreign key.\n        #\n        # This is simpler than ensuring that code paths that fetch a\n        # Stream that will be used for sending a message have a\n        # `select_related(\"recipient\"), which would also needlessly\n        # expand Stream objects in memory (all the fields of Recipient\n        # are already known given the Stream object).\n        recipient = Recipient(\n            id=stream.recipient_id,\n            type_id=stream.id,\n            type=Recipient.STREAM,\n        )\n\n        if not skip_stream_access_check:\n            access_stream_for_send_message(\n                sender=sender, stream=stream, forwarder_user_profile=forwarder_user_profile\n            )\n        else:\n            # Defensive assertion - the only currently supported use case\n            # for this option is for outgoing webhook bots and since this\n            # is security-sensitive code, it's beneficial to ensure nothing\n            # else can sneak past the access check.\n            assert sender.bot_type == sender.OUTGOING_WEBHOOK_BOT\n\n        if realm.mandatory_topics and topic_name == \"(no topic)\":\n            raise JsonableError(_(\"Topics are required in this organization\"))\n\n    elif addressee.is_private():\n        user_profiles = addressee.user_profiles()\n        mirror_message = client and client.name in [\n            \"zephyr_mirror\",\n            \"irc_mirror\",\n            \"jabber_mirror\",\n            \"JabberMirror\",\n        ]\n\n        check_private_message_policy(realm, sender, user_profiles)\n\n        # API super-users who set the `forged` flag are allowed to\n        # forge messages sent by any user, so we disable the\n        # `forwarded_mirror_message` security check in that case.\n        forwarded_mirror_message = mirror_message and not forged\n        try:\n            recipient = recipient_for_user_profiles(\n                user_profiles, forwarded_mirror_message, forwarder_user_profile, sender\n            )\n        except ValidationError as e:\n            assert isinstance(e.messages[0], str)\n            raise JsonableError(e.messages[0])\n    else:\n        # This is defensive code--Addressee already validates\n        # the message type.\n        raise AssertionError(\"Invalid message type\")\n\n    message = Message()\n    message.sender = sender\n    message.content = message_content\n    message.recipient = recipient\n    if addressee.is_stream():\n        message.set_topic_name(topic_name)\n    if forged and forged_timestamp is not None:\n        # Forged messages come with a timestamp\n        message.date_sent = timestamp_to_datetime(forged_timestamp)\n    else:\n        message.date_sent = timezone_now()\n    message.sending_client = client\n\n    # We render messages later in the process.\n    assert message.rendered_content is None\n\n    if client.name == \"zephyr_mirror\":\n        id = already_sent_mirrored_message_id(message)\n        if id is not None:\n            raise ZephyrMessageAlreadySentException(id)\n\n    widget_content_dict = None\n    if widget_content is not None:\n        try:\n            widget_content_dict = orjson.loads(widget_content)\n        except orjson.JSONDecodeError:\n            raise JsonableError(_(\"Widgets: API programmer sent invalid JSON content\"))\n\n        try:\n            check_widget_content(widget_content_dict)\n        except ValidationError as error:\n            raise JsonableError(\n                _(\"Widgets: {error_msg}\").format(\n                    error_msg=error.message,\n                )\n            )\n\n    message_send_dict = build_message_send_dict(\n        message=message,\n        stream=stream,\n        local_id=local_id,\n        sender_queue_id=sender_queue_id,\n        realm=realm,\n        widget_content_dict=widget_content_dict,\n        email_gateway=email_gateway,\n        mention_backend=mention_backend,\n        limit_unread_user_ids=limit_unread_user_ids,\n    )\n\n    if stream is not None and message_send_dict.rendering_result.mentions_wildcard:\n        if not wildcard_mention_allowed(sender, stream):\n            raise JsonableError(\n                _(\"You do not have permission to use wildcard mentions in this stream.\")\n            )\n    return message_send_dict\n\n\ndef _internal_prep_message(\n    realm: Realm,\n    sender: UserProfile,\n    addressee: Addressee,\n    content: str,\n    email_gateway: bool = False,\n    mention_backend: Optional[MentionBackend] = None,\n    limit_unread_user_ids: Optional[Set[int]] = None,\n) -> Optional[SendMessageRequest]:\n    \"\"\"\n    Create a message object and checks it, but doesn't send it or save it to the database.\n    The internal function that calls this can therefore batch send a bunch of created\n    messages together as one database query.\n    Call do_send_messages with a list of the return values of this method.\n    \"\"\"\n    # Remove any null bytes from the content\n    if len(content) > settings.MAX_MESSAGE_LENGTH:\n        content = content[0:3900] + \"\\n\\n[message was too long and has been truncated]\"\n\n    # If we have a stream name, and the stream doesn't exist, we\n    # create it here (though this code path should probably be removed\n    # eventually, moving that responsibility to the caller).  If\n    # addressee.stream_name() is None (i.e. we're sending to a stream\n    # by ID), we skip this, as the stream object must already exist.\n    if addressee.is_stream():\n        stream_name = addressee.stream_name()\n        if stream_name is not None:\n            ensure_stream(realm, stream_name, acting_user=sender)\n\n    try:\n        return check_message(\n            sender,\n            get_client(\"Internal\"),\n            addressee,\n            content,\n            realm=realm,\n            email_gateway=email_gateway,\n            mention_backend=mention_backend,\n            limit_unread_user_ids=limit_unread_user_ids,\n        )\n    except JsonableError as e:\n        logging.exception(\n            \"Error queueing internal message by %s: %s\",\n            sender.delivery_email,\n            e.msg,\n            stack_info=True,\n        )\n\n    return None\n\n\ndef internal_prep_stream_message(\n    sender: UserProfile,\n    stream: Stream,\n    topic: str,\n    content: str,\n    email_gateway: bool = False,\n    limit_unread_user_ids: Optional[Set[int]] = None,\n) -> Optional[SendMessageRequest]:\n    \"\"\"\n    See _internal_prep_message for details of how this works.\n    \"\"\"\n    realm = stream.realm\n    addressee = Addressee.for_stream(stream, topic)\n\n    return _internal_prep_message(\n        realm=realm,\n        sender=sender,\n        addressee=addressee,\n        content=content,\n        email_gateway=email_gateway,\n        limit_unread_user_ids=limit_unread_user_ids,\n    )\n\n\ndef internal_prep_stream_message_by_name(\n    realm: Realm,\n    sender: UserProfile,\n    stream_name: str,\n    topic: str,\n    content: str,\n) -> Optional[SendMessageRequest]:\n    \"\"\"\n    See _internal_prep_message for details of how this works.\n    \"\"\"\n    addressee = Addressee.for_stream_name(stream_name, topic)\n\n    return _internal_prep_message(\n        realm=realm,\n        sender=sender,\n        addressee=addressee,\n        content=content,\n    )\n\n\ndef internal_prep_private_message(\n    realm: Realm,\n    sender: UserProfile,\n    recipient_user: UserProfile,\n    content: str,\n    mention_backend: Optional[MentionBackend] = None,\n) -> Optional[SendMessageRequest]:\n    \"\"\"\n    See _internal_prep_message for details of how this works.\n    \"\"\"\n    addressee = Addressee.for_user_profile(recipient_user)\n\n    return _internal_prep_message(\n        realm=realm,\n        sender=sender,\n        addressee=addressee,\n        content=content,\n        mention_backend=mention_backend,\n    )\n\n\ndef internal_send_private_message(\n    sender: UserProfile, recipient_user: UserProfile, content: str\n) -> Optional[int]:\n    realm = recipient_user.realm\n    message = internal_prep_private_message(realm, sender, recipient_user, content)\n    if message is None:\n        return None\n    message_ids = do_send_messages([message])\n    return message_ids[0]\n\n\ndef internal_send_stream_message(\n    sender: UserProfile,\n    stream: Stream,\n    topic: str,\n    content: str,\n    email_gateway: bool = False,\n    limit_unread_user_ids: Optional[Set[int]] = None,\n) -> Optional[int]:\n\n    message = internal_prep_stream_message(\n        sender, stream, topic, content, email_gateway, limit_unread_user_ids=limit_unread_user_ids\n    )\n\n    if message is None:\n        return None\n    message_ids = do_send_messages([message])\n    return message_ids[0]\n\n\ndef internal_send_stream_message_by_name(\n    realm: Realm,\n    sender: UserProfile,\n    stream_name: str,\n    topic: str,\n    content: str,\n) -> Optional[int]:\n    message = internal_prep_stream_message_by_name(\n        realm,\n        sender,\n        stream_name,\n        topic,\n        content,\n    )\n\n    if message is None:\n        return None\n    message_ids = do_send_messages([message])\n    return message_ids[0]\n\n\ndef internal_send_huddle_message(\n    realm: Realm, sender: UserProfile, emails: List[str], content: str\n) -> Optional[int]:\n    addressee = Addressee.for_private(emails, realm)\n    message = _internal_prep_message(\n        realm=realm,\n        sender=sender,\n        addressee=addressee,\n        content=content,\n    )\n    if message is None:\n        return None\n    message_ids = do_send_messages([message])\n    return message_ids[0]\n\n\ndef validate_user_access_to_subscribers(\n    user_profile: Optional[UserProfile], stream: Stream\n) -> None:\n    \"\"\"Validates whether the user can view the subscribers of a stream.  Raises a JsonableError if:\n    * The user and the stream are in different realms\n    * The realm is MIT and the stream is not invite only.\n    * The stream is invite only, requesting_user is passed, and that user\n      does not subscribe to the stream.\n    \"\"\"\n    validate_user_access_to_subscribers_helper(\n        user_profile,\n        {\n            \"realm_id\": stream.realm_id,\n            \"is_web_public\": stream.is_web_public,\n            \"invite_only\": stream.invite_only,\n        },\n        # We use a lambda here so that we only compute whether the\n        # user is subscribed if we have to\n        lambda user_profile: subscribed_to_stream(user_profile, stream.id),\n    )\n\n\ndef validate_user_access_to_subscribers_helper(\n    user_profile: Optional[UserProfile],\n    stream_dict: Mapping[str, Any],\n    check_user_subscribed: Callable[[UserProfile], bool],\n) -> None:\n    \"\"\"Helper for validate_user_access_to_subscribers that doesn't require\n    a full stream object.  This function is a bit hard to read,\n    because it is carefully optimized for performance in the two code\n    paths we call it from:\n\n    * In `bulk_get_subscriber_user_ids`, we already know whether the\n    user was subscribed via `sub_dict`, and so we want to avoid a\n    database query at all (especially since it calls this in a loop);\n    * In `validate_user_access_to_subscribers`, we want to only check\n    if the user is subscribed when we absolutely have to, since it\n    costs a database query.\n\n    The `check_user_subscribed` argument is a function that reports\n    whether the user is subscribed to the stream.\n\n    Note also that we raise a ValidationError in cases where the\n    caller is doing the wrong thing (maybe these should be\n    AssertionErrors), and JsonableError for 400 type errors.\n    \"\"\"\n    if user_profile is None:\n        raise ValidationError(\"Missing user to validate access for\")\n\n    if user_profile.realm_id != stream_dict[\"realm_id\"]:\n        raise ValidationError(\"Requesting user not in given realm\")\n\n    # Even guest users can access subscribers to web-public streams,\n    # since they can freely become subscribers to these streams.\n    if stream_dict[\"is_web_public\"]:\n        return\n\n    # With the exception of web-public streams, a guest must\n    # be subscribed to a stream (even a public one) in order\n    # to see subscribers.\n    if user_profile.is_guest:\n        if check_user_subscribed(user_profile):\n            return\n        # We could explicitly handle the case where guests aren't\n        # subscribed here in an `else` statement or we can fall\n        # through to the subsequent logic.  Tim prefers the latter.\n        # Adding an `else` would ensure better code coverage.\n\n    if not user_profile.can_access_public_streams() and not stream_dict[\"invite_only\"]:\n        raise JsonableError(_(\"Subscriber data is not available for this stream\"))\n\n    # Organization administrators can view subscribers for all streams.\n    if user_profile.is_realm_admin:\n        return\n\n    if stream_dict[\"invite_only\"] and not check_user_subscribed(user_profile):\n        raise JsonableError(_(\"Unable to retrieve subscribers for private stream\"))\n\n\ndef bulk_get_subscriber_user_ids(\n    stream_dicts: Collection[Mapping[str, Any]],\n    user_profile: UserProfile,\n    subscribed_stream_ids: Set[int],\n) -> Dict[int, List[int]]:\n    \"\"\"sub_dict maps stream_id => whether the user is subscribed to that stream.\"\"\"\n    target_stream_dicts = []\n    for stream_dict in stream_dicts:\n        stream_id = stream_dict[\"id\"]\n        is_subscribed = stream_id in subscribed_stream_ids\n\n        try:\n            validate_user_access_to_subscribers_helper(\n                user_profile,\n                stream_dict,\n                lambda user_profile: is_subscribed,\n            )\n        except JsonableError:\n            continue\n        target_stream_dicts.append(stream_dict)\n\n    recip_to_stream_id = {stream[\"recipient_id\"]: stream[\"id\"] for stream in target_stream_dicts}\n    recipient_ids = sorted(stream[\"recipient_id\"] for stream in target_stream_dicts)\n\n    result: Dict[int, List[int]] = {stream[\"id\"]: [] for stream in stream_dicts}\n    if not recipient_ids:\n        return result\n\n    \"\"\"\n    The raw SQL below leads to more than a 2x speedup when tested with\n    20k+ total subscribers.  (For large realms with lots of default\n    streams, this function deals with LOTS of data, so it is important\n    to optimize.)\n    \"\"\"\n\n    query = SQL(\n        \"\"\"\n        SELECT\n            zerver_subscription.recipient_id,\n            zerver_subscription.user_profile_id\n        FROM\n            zerver_subscription\n        WHERE\n            zerver_subscription.recipient_id in %(recipient_ids)s AND\n            zerver_subscription.active AND\n            zerver_subscription.is_user_active\n        ORDER BY\n            zerver_subscription.recipient_id,\n            zerver_subscription.user_profile_id\n        \"\"\"\n    )\n\n    cursor = connection.cursor()\n    cursor.execute(query, {\"recipient_ids\": tuple(recipient_ids)})\n    rows = cursor.fetchall()\n    cursor.close()\n\n    \"\"\"\n    Using groupby/itemgetter here is important for performance, at scale.\n    It makes it so that all interpreter overhead is just O(N) in nature.\n    \"\"\"\n    for recip_id, recip_rows in itertools.groupby(rows, itemgetter(0)):\n        user_profile_ids = [r[1] for r in recip_rows]\n        stream_id = recip_to_stream_id[recip_id]\n        result[stream_id] = list(user_profile_ids)\n\n    return result\n\n\ndef get_subscribers_query(stream: Stream, requesting_user: Optional[UserProfile]) -> QuerySet:\n    # TODO: Make a generic stub for QuerySet\n    \"\"\"Build a query to get the subscribers list for a stream, raising a JsonableError if:\n\n    'realm' is optional in stream.\n\n    The caller can refine this query with select_related(), values(), etc. depending\n    on whether it wants objects or just certain fields\n    \"\"\"\n    validate_user_access_to_subscribers(requesting_user, stream)\n\n    return get_active_subscriptions_for_stream_id(stream.id, include_deactivated_users=False)\n\n\ndef get_subscriber_ids(stream: Stream, requesting_user: Optional[UserProfile] = None) -> List[str]:\n    subscriptions_query = get_subscribers_query(stream, requesting_user)\n    return subscriptions_query.values_list(\"user_profile_id\", flat=True)\n\n\n@dataclass\nclass StreamInfo:\n    email_address: str\n    stream_weekly_traffic: Optional[int]\n    subscribers: List[int]\n\n\ndef send_subscription_add_events(\n    realm: Realm,\n    sub_info_list: List[SubInfo],\n    subscriber_dict: Dict[int, Set[int]],\n) -> None:\n    info_by_user: Dict[int, List[SubInfo]] = defaultdict(list)\n    for sub_info in sub_info_list:\n        info_by_user[sub_info.user.id].append(sub_info)\n\n    stream_ids = {sub_info.stream.id for sub_info in sub_info_list}\n    recent_traffic = get_streams_traffic(stream_ids=stream_ids)\n\n    # We generally only have a few streams, so we compute stream\n    # data in its own loop.\n    stream_info_dict: Dict[int, StreamInfo] = {}\n    for sub_info in sub_info_list:\n        stream = sub_info.stream\n        if stream.id not in stream_info_dict:\n            email_address = encode_email_address(stream, show_sender=True)\n            stream_weekly_traffic = get_average_weekly_stream_traffic(\n                stream.id, stream.date_created, recent_traffic\n            )\n            if stream.is_in_zephyr_realm and not stream.invite_only:\n                subscribers = []\n            else:\n                subscribers = list(subscriber_dict[stream.id])\n            stream_info_dict[stream.id] = StreamInfo(\n                email_address=email_address,\n                stream_weekly_traffic=stream_weekly_traffic,\n                subscribers=subscribers,\n            )\n\n    for user_id, sub_infos in info_by_user.items():\n        sub_dicts = []\n        for sub_info in sub_infos:\n            stream = sub_info.stream\n            stream_info = stream_info_dict[stream.id]\n            subscription = sub_info.sub\n            sub_dict = stream.to_dict()\n            for field_name in Subscription.API_FIELDS:\n                sub_dict[field_name] = getattr(subscription, field_name)\n\n            sub_dict[\"in_home_view\"] = not subscription.is_muted\n            sub_dict[\"email_address\"] = stream_info.email_address\n            sub_dict[\"stream_weekly_traffic\"] = stream_info.stream_weekly_traffic\n            sub_dict[\"subscribers\"] = stream_info.subscribers\n            sub_dicts.append(sub_dict)\n\n        # Send a notification to the user who subscribed.\n        event = dict(type=\"subscription\", op=\"add\", subscriptions=sub_dicts)\n        send_event(realm, event, [user_id])\n\n\nSubT = Tuple[List[SubInfo], List[SubInfo]]\n\n\ndef bulk_add_subscriptions(\n    realm: Realm,\n    streams: Collection[Stream],\n    users: Iterable[UserProfile],\n    color_map: Mapping[str, str] = {},\n    from_user_creation: bool = False,\n    *,\n    acting_user: Optional[UserProfile],\n) -> SubT:\n    users = list(users)\n    user_ids = [user.id for user in users]\n\n    # Sanity check out callers\n    for stream in streams:\n        assert stream.realm_id == realm.id\n\n    for user in users:\n        assert user.realm_id == realm.id\n\n    recipient_ids = [stream.recipient_id for stream in streams]\n    recipient_id_to_stream = {stream.recipient_id: stream for stream in streams}\n\n    recipient_color_map = {}\n    for stream in streams:\n        color: Optional[str] = color_map.get(stream.name, None)\n        if color is not None:\n            recipient_color_map[stream.recipient_id] = color\n\n    used_colors_for_user_ids: Dict[int, Set[str]] = get_used_colors_for_user_ids(user_ids)\n\n    existing_subs = Subscription.objects.filter(\n        user_profile_id__in=user_ids,\n        recipient__type=Recipient.STREAM,\n        recipient_id__in=recipient_ids,\n    )\n\n    subs_by_user: Dict[int, List[Subscription]] = defaultdict(list)\n    for sub in existing_subs:\n        subs_by_user[sub.user_profile_id].append(sub)\n\n    already_subscribed: List[SubInfo] = []\n    subs_to_activate: List[SubInfo] = []\n    subs_to_add: List[SubInfo] = []\n    for user_profile in users:\n        my_subs = subs_by_user[user_profile.id]\n\n        # Make a fresh set of all new recipient ids, and then we will\n        # remove any for which our user already has a subscription\n        # (and we'll re-activate any subscriptions as needed).\n        new_recipient_ids: Set[int] = {stream.recipient_id for stream in streams}\n\n        for sub in my_subs:\n            if sub.recipient_id in new_recipient_ids:\n                new_recipient_ids.remove(sub.recipient_id)\n                stream = recipient_id_to_stream[sub.recipient_id]\n                sub_info = SubInfo(user_profile, sub, stream)\n                if sub.active:\n                    already_subscribed.append(sub_info)\n                else:\n                    subs_to_activate.append(sub_info)\n\n        used_colors = used_colors_for_user_ids.get(user_profile.id, set())\n        user_color_map = pick_colors(used_colors, recipient_color_map, list(new_recipient_ids))\n\n        for recipient_id in new_recipient_ids:\n            stream = recipient_id_to_stream[recipient_id]\n            color = user_color_map[recipient_id]\n\n            sub = Subscription(\n                user_profile=user_profile,\n                is_user_active=user_profile.is_active,\n                active=True,\n                color=color,\n                recipient_id=recipient_id,\n            )\n            sub_info = SubInfo(user_profile, sub, stream)\n            subs_to_add.append(sub_info)\n\n    bulk_add_subs_to_db_with_logging(\n        realm=realm,\n        acting_user=acting_user,\n        subs_to_add=subs_to_add,\n        subs_to_activate=subs_to_activate,\n    )\n\n    altered_user_dict: Dict[int, Set[int]] = defaultdict(set)\n    for sub_info in subs_to_add + subs_to_activate:\n        altered_user_dict[sub_info.stream.id].add(sub_info.user.id)\n\n    stream_dict = {stream.id: stream for stream in streams}\n\n    new_streams = [stream_dict[stream_id] for stream_id in altered_user_dict]\n\n    subscriber_peer_info = bulk_get_subscriber_peer_info(\n        realm=realm,\n        streams=new_streams,\n    )\n\n    # We now send several types of events to notify browsers.  The\n    # first batches of notifications are sent only to the user(s)\n    # being subscribed; we can skip these notifications when this is\n    # being called from the new user creation flow.\n    if not from_user_creation:\n        send_stream_creation_events_for_private_streams(\n            realm=realm,\n            stream_dict=stream_dict,\n            altered_user_dict=altered_user_dict,\n        )\n\n        send_subscription_add_events(\n            realm=realm,\n            sub_info_list=subs_to_add + subs_to_activate,\n            subscriber_dict=subscriber_peer_info.subscribed_ids,\n        )\n\n    send_peer_subscriber_events(\n        op=\"peer_add\",\n        realm=realm,\n        altered_user_dict=altered_user_dict,\n        stream_dict=stream_dict,\n        private_peer_dict=subscriber_peer_info.private_peer_dict,\n    )\n\n    return (\n        subs_to_add + subs_to_activate,\n        already_subscribed,\n    )\n\n\n# This function contains all the database changes as part of\n# subscribing users to streams; we use a transaction to ensure that\n# the RealmAuditLog entries are created atomically with the\n# Subscription object creation (and updates).\n@transaction.atomic(savepoint=False)\ndef bulk_add_subs_to_db_with_logging(\n    realm: Realm,\n    acting_user: Optional[UserProfile],\n    subs_to_add: List[SubInfo],\n    subs_to_activate: List[SubInfo],\n) -> None:\n\n    Subscription.objects.bulk_create(info.sub for info in subs_to_add)\n    sub_ids = [info.sub.id for info in subs_to_activate]\n    Subscription.objects.filter(id__in=sub_ids).update(active=True)\n\n    # Log subscription activities in RealmAuditLog\n    event_time = timezone_now()\n    event_last_message_id = get_last_message_id()\n\n    all_subscription_logs: (List[RealmAuditLog]) = []\n    for sub_info in subs_to_add:\n        all_subscription_logs.append(\n            RealmAuditLog(\n                realm=realm,\n                acting_user=acting_user,\n                modified_user=sub_info.user,\n                modified_stream=sub_info.stream,\n                event_last_message_id=event_last_message_id,\n                event_type=RealmAuditLog.SUBSCRIPTION_CREATED,\n                event_time=event_time,\n            )\n        )\n    for sub_info in subs_to_activate:\n        all_subscription_logs.append(\n            RealmAuditLog(\n                realm=realm,\n                acting_user=acting_user,\n                modified_user=sub_info.user,\n                modified_stream=sub_info.stream,\n                event_last_message_id=event_last_message_id,\n                event_type=RealmAuditLog.SUBSCRIPTION_ACTIVATED,\n                event_time=event_time,\n            )\n        )\n    # Now since we have all log objects generated we can do a bulk insert\n    RealmAuditLog.objects.bulk_create(all_subscription_logs)\n\n\ndef send_stream_creation_events_for_private_streams(\n    realm: Realm,\n    stream_dict: Dict[int, Stream],\n    altered_user_dict: Dict[int, Set[int]],\n) -> None:\n    for stream_id, stream_users_ids in altered_user_dict.items():\n        stream = stream_dict[stream_id]\n\n        if not stream.is_public():\n            # Users newly added to invite-only streams\n            # need a `create` notification.  The former, because\n            # they need the stream to exist before\n            # they get the \"subscribe\" notification, and the latter so\n            # they can manage the new stream.\n            # Realm admins already have all created private streams.\n            realm_admin_ids = {user.id for user in realm.get_admin_users_and_bots()}\n            notify_user_ids = list(stream_users_ids - realm_admin_ids)\n\n            if notify_user_ids:\n                send_stream_creation_event(stream, notify_user_ids)\n\n\ndef send_peer_subscriber_events(\n    op: str,\n    realm: Realm,\n    stream_dict: Dict[int, Stream],\n    altered_user_dict: Dict[int, Set[int]],\n    private_peer_dict: Dict[int, Set[int]],\n) -> None:\n    # Send peer_add/peer_remove events to other users who are tracking the\n    # subscribers lists of streams in their browser; everyone for\n    # public streams and only existing subscribers for private streams.\n\n    assert op in [\"peer_add\", \"peer_remove\"]\n\n    private_stream_ids = [\n        stream_id for stream_id in altered_user_dict if stream_dict[stream_id].invite_only\n    ]\n\n    for stream_id in private_stream_ids:\n        altered_user_ids = altered_user_dict[stream_id]\n        peer_user_ids = private_peer_dict[stream_id] - altered_user_ids\n\n        if peer_user_ids and altered_user_ids:\n            event = dict(\n                type=\"subscription\",\n                op=op,\n                stream_ids=[stream_id],\n                user_ids=sorted(list(altered_user_ids)),\n            )\n            send_event(realm, event, peer_user_ids)\n\n    public_stream_ids = [\n        stream_id\n        for stream_id in altered_user_dict\n        if not stream_dict[stream_id].invite_only and not stream_dict[stream_id].is_in_zephyr_realm\n    ]\n\n    if public_stream_ids:\n        user_streams: Dict[int, Set[int]] = defaultdict(set)\n\n        public_peer_ids = set(active_non_guest_user_ids(realm.id))\n\n        for stream_id in public_stream_ids:\n            altered_user_ids = altered_user_dict[stream_id]\n            peer_user_ids = public_peer_ids - altered_user_ids\n\n            if peer_user_ids and altered_user_ids:\n                if len(altered_user_ids) == 1:\n                    # If we only have one user, we will try to\n                    # find other streams they have (un)subscribed to\n                    # (where it's just them).  This optimization\n                    # typically works when a single user is subscribed\n                    # to multiple default public streams during\n                    # new-user registration.\n                    #\n                    # This optimization depends on all public streams\n                    # having the same peers for any single user, which\n                    # isn't the case for private streams.\n                    altered_user_id = list(altered_user_ids)[0]\n                    user_streams[altered_user_id].add(stream_id)\n                else:\n                    event = dict(\n                        type=\"subscription\",\n                        op=op,\n                        stream_ids=[stream_id],\n                        user_ids=sorted(list(altered_user_ids)),\n                    )\n                    send_event(realm, event, peer_user_ids)\n\n        for user_id, stream_ids in user_streams.items():\n            peer_user_ids = public_peer_ids - {user_id}\n            event = dict(\n                type=\"subscription\",\n                op=op,\n                stream_ids=sorted(list(stream_ids)),\n                user_ids=[user_id],\n            )\n            send_event(realm, event, peer_user_ids)\n\n\ndef send_peer_remove_events(\n    realm: Realm,\n    streams: List[Stream],\n    altered_user_dict: Dict[int, Set[int]],\n) -> None:\n    private_streams = [stream for stream in streams if stream.invite_only]\n\n    private_peer_dict = bulk_get_private_peers(\n        realm=realm,\n        private_streams=private_streams,\n    )\n    stream_dict = {stream.id: stream for stream in streams}\n\n    send_peer_subscriber_events(\n        op=\"peer_remove\",\n        realm=realm,\n        stream_dict=stream_dict,\n        altered_user_dict=altered_user_dict,\n        private_peer_dict=private_peer_dict,\n    )\n\n\ndef get_available_notification_sounds() -> List[str]:\n    notification_sounds_path = static_path(\"audio/notification_sounds\")\n    available_notification_sounds = []\n\n    for file_name in os.listdir(notification_sounds_path):\n        root, ext = os.path.splitext(file_name)\n        if \".\" in root:  # nocoverage\n            # Exclude e.g. zulip.abcd1234.ogg (generated by production hash-naming)\n            # to avoid spurious duplicates.\n            continue\n        if ext == \".ogg\":\n            available_notification_sounds.append(root)\n\n    return sorted(available_notification_sounds)\n\n\ndef notify_subscriptions_removed(\n    realm: Realm, user_profile: UserProfile, streams: Iterable[Stream]\n) -> None:\n\n    payload = [dict(name=stream.name, stream_id=stream.id) for stream in streams]\n    event = dict(type=\"subscription\", op=\"remove\", subscriptions=payload)\n    send_event(realm, event, [user_profile.id])\n\n\nSubAndRemovedT = Tuple[List[Tuple[UserProfile, Stream]], List[Tuple[UserProfile, Stream]]]\n\n\ndef bulk_remove_subscriptions(\n    realm: Realm,\n    users: Iterable[UserProfile],\n    streams: Iterable[Stream],\n    *,\n    acting_user: Optional[UserProfile],\n) -> SubAndRemovedT:\n\n    users = list(users)\n    streams = list(streams)\n\n    # Sanity check our callers\n    for stream in streams:\n        assert stream.realm_id == realm.id\n\n    for user in users:\n        assert user.realm_id == realm.id\n\n    stream_dict = {stream.id: stream for stream in streams}\n\n    existing_subs_by_user = get_bulk_stream_subscriber_info(users, streams)\n\n    def get_non_subscribed_subs() -> List[Tuple[UserProfile, Stream]]:\n        stream_ids = {stream.id for stream in streams}\n\n        not_subscribed: List[Tuple[UserProfile, Stream]] = []\n\n        for user_profile in users:\n            user_sub_stream_info = existing_subs_by_user[user_profile.id]\n\n            subscribed_stream_ids = {sub_info.stream.id for sub_info in user_sub_stream_info}\n            not_subscribed_stream_ids = stream_ids - subscribed_stream_ids\n\n            for stream_id in not_subscribed_stream_ids:\n                stream = stream_dict[stream_id]\n                not_subscribed.append((user_profile, stream))\n\n        return not_subscribed\n\n    not_subscribed = get_non_subscribed_subs()\n\n    subs_to_deactivate: List[SubInfo] = []\n    sub_ids_to_deactivate: List[int] = []\n\n    # This loop just flattens out our data into big lists for\n    # bulk operations.\n    for sub_infos in existing_subs_by_user.values():\n        for sub_info in sub_infos:\n            subs_to_deactivate.append(sub_info)\n            sub_ids_to_deactivate.append(sub_info.sub.id)\n\n    # We do all the database changes in a transaction to ensure\n    # RealmAuditLog entries are atomically created when making changes.\n    with transaction.atomic():\n        occupied_streams_before = list(get_occupied_streams(realm))\n        Subscription.objects.filter(\n            id__in=sub_ids_to_deactivate,\n        ).update(active=False)\n        occupied_streams_after = list(get_occupied_streams(realm))\n\n        # Log subscription activities in RealmAuditLog\n        event_time = timezone_now()\n        event_last_message_id = get_last_message_id()\n        all_subscription_logs = [\n            RealmAuditLog(\n                realm=sub_info.user.realm,\n                acting_user=acting_user,\n                modified_user=sub_info.user,\n                modified_stream=sub_info.stream,\n                event_last_message_id=event_last_message_id,\n                event_type=RealmAuditLog.SUBSCRIPTION_DEACTIVATED,\n                event_time=event_time,\n            )\n            for sub_info in subs_to_deactivate\n        ]\n\n        # Now since we have all log objects generated we can do a bulk insert\n        RealmAuditLog.objects.bulk_create(all_subscription_logs)\n\n    altered_user_dict: Dict[int, Set[int]] = defaultdict(set)\n    streams_by_user: Dict[int, List[Stream]] = defaultdict(list)\n    for sub_info in subs_to_deactivate:\n        stream = sub_info.stream\n        streams_by_user[sub_info.user.id].append(stream)\n        altered_user_dict[stream.id].add(sub_info.user.id)\n\n    for user_profile in users:\n        if len(streams_by_user[user_profile.id]) == 0:\n            continue\n        notify_subscriptions_removed(realm, user_profile, streams_by_user[user_profile.id])\n\n        event = {\n            \"type\": \"mark_stream_messages_as_read\",\n            \"user_profile_id\": user_profile.id,\n            \"stream_recipient_ids\": [stream.recipient_id for stream in streams],\n        }\n        queue_json_publish(\"deferred_work\", event)\n\n    send_peer_remove_events(\n        realm=realm,\n        streams=streams,\n        altered_user_dict=altered_user_dict,\n    )\n\n    new_vacant_streams = set(occupied_streams_before) - set(occupied_streams_after)\n    new_vacant_private_streams = [stream for stream in new_vacant_streams if stream.invite_only]\n\n    if new_vacant_private_streams:\n        # Deactivate any newly-vacant private streams\n        for stream in new_vacant_private_streams:\n            do_deactivate_stream(stream, acting_user=acting_user)\n\n    return (\n        [(sub_info.user, sub_info.stream) for sub_info in subs_to_deactivate],\n        not_subscribed,\n    )\n\n\ndef do_change_subscription_property(\n    user_profile: UserProfile,\n    sub: Subscription,\n    stream: Stream,\n    property_name: str,\n    value: Any,\n    *,\n    acting_user: Optional[UserProfile],\n) -> None:\n    database_property_name = property_name\n    event_property_name = property_name\n    database_value = value\n    event_value = value\n\n    # For this property, is_muted is used in the database, but\n    # in_home_view in the API, since we haven't migrated the events\n    # API to the new name yet.\n    if property_name == \"in_home_view\":\n        database_property_name = \"is_muted\"\n        database_value = not value\n    if property_name == \"is_muted\":\n        event_property_name = \"in_home_view\"\n        event_value = not value\n\n    old_value = getattr(sub, database_property_name)\n    setattr(sub, database_property_name, database_value)\n    sub.save(update_fields=[database_property_name])\n    event_time = timezone_now()\n    RealmAuditLog.objects.create(\n        realm=user_profile.realm,\n        event_type=RealmAuditLog.SUBSCRIPTION_PROPERTY_CHANGED,\n        event_time=event_time,\n        modified_user=user_profile,\n        acting_user=acting_user,\n        modified_stream=stream,\n        extra_data=orjson.dumps(\n            {\n                RealmAuditLog.OLD_VALUE: old_value,\n                RealmAuditLog.NEW_VALUE: database_value,\n                \"property\": database_property_name,\n            }\n        ).decode(),\n    )\n\n    event = dict(\n        type=\"subscription\",\n        op=\"update\",\n        property=event_property_name,\n        value=event_value,\n        stream_id=stream.id,\n    )\n    send_event(user_profile.realm, event, [user_profile.id])\n\n\ndef do_change_password(user_profile: UserProfile, password: str, commit: bool = True) -> None:\n    user_profile.set_password(password)\n    if commit:\n        user_profile.save(update_fields=[\"password\"])\n    event_time = timezone_now()\n    RealmAuditLog.objects.create(\n        realm=user_profile.realm,\n        acting_user=user_profile,\n        modified_user=user_profile,\n        event_type=RealmAuditLog.USER_PASSWORD_CHANGED,\n        event_time=event_time,\n    )\n\n\ndef do_change_full_name(\n    user_profile: UserProfile, full_name: str, acting_user: Optional[UserProfile]\n) -> None:\n    old_name = user_profile.full_name\n    user_profile.full_name = full_name\n    user_profile.save(update_fields=[\"full_name\"])\n    event_time = timezone_now()\n    RealmAuditLog.objects.create(\n        realm=user_profile.realm,\n        acting_user=acting_user,\n        modified_user=user_profile,\n        event_type=RealmAuditLog.USER_FULL_NAME_CHANGED,\n        event_time=event_time,\n        extra_data=old_name,\n    )\n    payload = dict(user_id=user_profile.id, full_name=user_profile.full_name)\n    send_event(\n        user_profile.realm,\n        dict(type=\"realm_user\", op=\"update\", person=payload),\n        active_user_ids(user_profile.realm_id),\n    )\n    if user_profile.is_bot:\n        send_event(\n            user_profile.realm,\n            dict(type=\"realm_bot\", op=\"update\", bot=payload),\n            bot_owner_user_ids(user_profile),\n        )\n\n\ndef check_change_full_name(\n    user_profile: UserProfile, full_name_raw: str, acting_user: Optional[UserProfile]\n) -> str:\n    \"\"\"Verifies that the user's proposed full name is valid.  The caller\n    is responsible for checking check permissions.  Returns the new\n    full name, which may differ from what was passed in (because this\n    function strips whitespace).\"\"\"\n    new_full_name = check_full_name(full_name_raw)\n    do_change_full_name(user_profile, new_full_name, acting_user)\n    return new_full_name\n\n\ndef check_change_bot_full_name(\n    user_profile: UserProfile, full_name_raw: str, acting_user: UserProfile\n) -> None:\n    new_full_name = check_full_name(full_name_raw)\n\n    if new_full_name == user_profile.full_name:\n        # Our web app will try to patch full_name even if the user didn't\n        # modify the name in the form.  We just silently ignore those\n        # situations.\n        return\n\n    check_bot_name_available(\n        realm_id=user_profile.realm_id,\n        full_name=new_full_name,\n    )\n    do_change_full_name(user_profile, new_full_name, acting_user)\n\n\n@transaction.atomic(durable=True)\ndef do_change_bot_owner(\n    user_profile: UserProfile, bot_owner: UserProfile, acting_user: UserProfile\n) -> None:\n    previous_owner = user_profile.bot_owner\n    user_profile.bot_owner = bot_owner\n    user_profile.save()  # Can't use update_fields because of how the foreign key works.\n    event_time = timezone_now()\n    RealmAuditLog.objects.create(\n        realm=user_profile.realm,\n        acting_user=acting_user,\n        modified_user=user_profile,\n        event_type=RealmAuditLog.USER_BOT_OWNER_CHANGED,\n        event_time=event_time,\n    )\n\n    update_users = bot_owner_user_ids(user_profile)\n\n    # For admins, update event is sent instead of delete/add\n    # event. bot_data of admin contains all the\n    # bots and none of them should be removed/(added again).\n\n    # Delete the bot from previous owner's bot data.\n    if previous_owner and not previous_owner.is_realm_admin:\n        delete_event = dict(\n            type=\"realm_bot\",\n            op=\"delete\",\n            bot=dict(\n                user_id=user_profile.id,\n            ),\n        )\n        transaction.on_commit(\n            lambda: send_event(\n                user_profile.realm,\n                delete_event,\n                {previous_owner.id},\n            )\n        )\n        # Do not send update event for previous bot owner.\n        update_users = update_users - {previous_owner.id}\n\n    # Notify the new owner that the bot has been added.\n    if not bot_owner.is_realm_admin:\n        add_event = created_bot_event(user_profile)\n        transaction.on_commit(lambda: send_event(user_profile.realm, add_event, {bot_owner.id}))\n        # Do not send update event for bot_owner.\n        update_users = update_users - {bot_owner.id}\n\n    bot_event = dict(\n        type=\"realm_bot\",\n        op=\"update\",\n        bot=dict(\n            user_id=user_profile.id,\n            owner_id=user_profile.bot_owner.id,\n        ),\n    )\n    transaction.on_commit(\n        lambda: send_event(\n            user_profile.realm,\n            bot_event,\n            update_users,\n        )\n    )\n\n    # Since `bot_owner_id` is included in the user profile dict we need\n    # to update the users dict with the new bot owner id\n    event = dict(\n        type=\"realm_user\",\n        op=\"update\",\n        person=dict(\n            user_id=user_profile.id,\n            bot_owner_id=user_profile.bot_owner.id,\n        ),\n    )\n    transaction.on_commit(\n        lambda: send_event(user_profile.realm, event, active_user_ids(user_profile.realm_id))\n    )\n\n\n@transaction.atomic(durable=True)\ndef do_change_tos_version(user_profile: UserProfile, tos_version: str) -> None:\n    user_profile.tos_version = tos_version\n    user_profile.save(update_fields=[\"tos_version\"])\n    event_time = timezone_now()\n    RealmAuditLog.objects.create(\n        realm=user_profile.realm,\n        acting_user=user_profile,\n        modified_user=user_profile,\n        event_type=RealmAuditLog.USER_TERMS_OF_SERVICE_VERSION_CHANGED,\n        event_time=event_time,\n    )\n\n\ndef do_regenerate_api_key(user_profile: UserProfile, acting_user: UserProfile) -> str:\n    old_api_key = user_profile.api_key\n    new_api_key = generate_api_key()\n    user_profile.api_key = new_api_key\n    user_profile.save(update_fields=[\"api_key\"])\n\n    # We need to explicitly delete the old API key from our caches,\n    # because the on-save handler for flushing the UserProfile object\n    # in zerver/lib/cache.py only has access to the new API key.\n    cache_delete(user_profile_by_api_key_cache_key(old_api_key))\n\n    event_time = timezone_now()\n    RealmAuditLog.objects.create(\n        realm=user_profile.realm,\n        acting_user=acting_user,\n        modified_user=user_profile,\n        event_type=RealmAuditLog.USER_API_KEY_CHANGED,\n        event_time=event_time,\n    )\n\n    if user_profile.is_bot:\n        send_event(\n            user_profile.realm,\n            dict(\n                type=\"realm_bot\",\n                op=\"update\",\n                bot=dict(\n                    user_id=user_profile.id,\n                    api_key=new_api_key,\n                ),\n            ),\n            bot_owner_user_ids(user_profile),\n        )\n\n    event = {\"type\": \"clear_push_device_tokens\", \"user_profile_id\": user_profile.id}\n    queue_json_publish(\"deferred_work\", event)\n\n    return new_api_key\n\n\ndef notify_avatar_url_change(user_profile: UserProfile) -> None:\n    if user_profile.is_bot:\n        bot_event = dict(\n            type=\"realm_bot\",\n            op=\"update\",\n            bot=dict(\n                user_id=user_profile.id,\n                avatar_url=avatar_url(user_profile),\n            ),\n        )\n        transaction.on_commit(\n            lambda: send_event(\n                user_profile.realm,\n                bot_event,\n                bot_owner_user_ids(user_profile),\n            )\n        )\n\n    payload = dict(\n        avatar_source=user_profile.avatar_source,\n        avatar_url=avatar_url(user_profile),\n        avatar_url_medium=avatar_url(user_profile, medium=True),\n        avatar_version=user_profile.avatar_version,\n        # Even clients using client_gravatar don't need the email,\n        # since we're sending the URL anyway.\n        user_id=user_profile.id,\n    )\n\n    event = dict(type=\"realm_user\", op=\"update\", person=payload)\n    transaction.on_commit(\n        lambda: send_event(\n            user_profile.realm,\n            event,\n            active_user_ids(user_profile.realm_id),\n        )\n    )\n\n\n@transaction.atomic(savepoint=False)\ndef do_change_avatar_fields(\n    user_profile: UserProfile,\n    avatar_source: str,\n    skip_notify: bool = False,\n    *,\n    acting_user: Optional[UserProfile],\n) -> None:\n    user_profile.avatar_source = avatar_source\n    user_profile.avatar_version += 1\n    user_profile.save(update_fields=[\"avatar_source\", \"avatar_version\"])\n    event_time = timezone_now()\n    RealmAuditLog.objects.create(\n        realm=user_profile.realm,\n        modified_user=user_profile,\n        event_type=RealmAuditLog.USER_AVATAR_SOURCE_CHANGED,\n        extra_data={\"avatar_source\": avatar_source},\n        event_time=event_time,\n        acting_user=acting_user,\n    )\n\n    if not skip_notify:\n        notify_avatar_url_change(user_profile)\n\n\ndef do_delete_avatar_image(user: UserProfile, *, acting_user: Optional[UserProfile]) -> None:\n    do_change_avatar_fields(user, UserProfile.AVATAR_FROM_GRAVATAR, acting_user=acting_user)\n    delete_avatar_image(user)\n\n\n@transaction.atomic(durable=True)\ndef do_change_icon_source(\n    realm: Realm, icon_source: str, *, acting_user: Optional[UserProfile]\n) -> None:\n    realm.icon_source = icon_source\n    realm.icon_version += 1\n    realm.save(update_fields=[\"icon_source\", \"icon_version\"])\n\n    event_time = timezone_now()\n    RealmAuditLog.objects.create(\n        realm=realm,\n        event_type=RealmAuditLog.REALM_ICON_SOURCE_CHANGED,\n        extra_data={\"icon_source\": icon_source, \"icon_version\": realm.icon_version},\n        event_time=event_time,\n        acting_user=acting_user,\n    )\n\n    event = dict(\n        type=\"realm\",\n        op=\"update_dict\",\n        property=\"icon\",\n        data=dict(icon_source=realm.icon_source, icon_url=realm_icon_url(realm)),\n    )\n    transaction.on_commit(\n        lambda: send_event(\n            realm,\n            event,\n            active_user_ids(realm.id),\n        )\n    )\n\n\n@transaction.atomic(durable=True)\ndef do_change_logo_source(\n    realm: Realm, logo_source: str, night: bool, *, acting_user: Optional[UserProfile]\n) -> None:\n    if not night:\n        realm.logo_source = logo_source\n        realm.logo_version += 1\n        realm.save(update_fields=[\"logo_source\", \"logo_version\"])\n\n    else:\n        realm.night_logo_source = logo_source\n        realm.night_logo_version += 1\n        realm.save(update_fields=[\"night_logo_source\", \"night_logo_version\"])\n\n    RealmAuditLog.objects.create(\n        event_type=RealmAuditLog.REALM_LOGO_CHANGED,\n        realm=realm,\n        event_time=timezone_now(),\n        acting_user=acting_user,\n    )\n\n    event = dict(\n        type=\"realm\",\n        op=\"update_dict\",\n        property=\"night_logo\" if night else \"logo\",\n        data=get_realm_logo_data(realm, night),\n    )\n    transaction.on_commit(lambda: send_event(realm, event, active_user_ids(realm.id)))\n\n\n@transaction.atomic(durable=True)\ndef do_change_realm_org_type(\n    realm: Realm,\n    org_type: int,\n    acting_user: Optional[UserProfile],\n) -> None:\n    old_value = realm.org_type\n    realm.org_type = org_type\n    realm.save(update_fields=[\"org_type\"])\n\n    RealmAuditLog.objects.create(\n        event_type=RealmAuditLog.REALM_ORG_TYPE_CHANGED,\n        realm=realm,\n        event_time=timezone_now(),\n        acting_user=acting_user,\n        extra_data={\"old_value\": old_value, \"new_value\": org_type},\n    )\n\n\n@transaction.atomic(savepoint=False)\ndef do_change_realm_plan_type(\n    realm: Realm, plan_type: int, *, acting_user: Optional[UserProfile]\n) -> None:\n    old_value = realm.plan_type\n    realm.plan_type = plan_type\n    realm.save(update_fields=[\"plan_type\"])\n    RealmAuditLog.objects.create(\n        event_type=RealmAuditLog.REALM_PLAN_TYPE_CHANGED,\n        realm=realm,\n        event_time=timezone_now(),\n        acting_user=acting_user,\n        extra_data={\"old_value\": old_value, \"new_value\": plan_type},\n    )\n\n    if plan_type == Realm.PLAN_TYPE_PLUS:\n        realm.max_invites = Realm.INVITES_STANDARD_REALM_DAILY_MAX\n        realm.message_visibility_limit = None\n        realm.upload_quota_gb = Realm.UPLOAD_QUOTA_STANDARD\n    elif plan_type == Realm.PLAN_TYPE_STANDARD:\n        realm.max_invites = Realm.INVITES_STANDARD_REALM_DAILY_MAX\n        realm.message_visibility_limit = None\n        realm.upload_quota_gb = Realm.UPLOAD_QUOTA_STANDARD\n    elif plan_type == Realm.PLAN_TYPE_SELF_HOSTED:\n        realm.max_invites = None  # type: ignore[assignment] # Apparent mypy bug with Optional[int] setter.\n        realm.message_visibility_limit = None\n        realm.upload_quota_gb = None\n    elif plan_type == Realm.PLAN_TYPE_STANDARD_FREE:\n        realm.max_invites = Realm.INVITES_STANDARD_REALM_DAILY_MAX\n        realm.message_visibility_limit = None\n        realm.upload_quota_gb = Realm.UPLOAD_QUOTA_STANDARD\n    elif plan_type == Realm.PLAN_TYPE_LIMITED:\n        realm.max_invites = settings.INVITES_DEFAULT_REALM_DAILY_MAX\n        realm.message_visibility_limit = Realm.MESSAGE_VISIBILITY_LIMITED\n        realm.upload_quota_gb = Realm.UPLOAD_QUOTA_LIMITED\n    else:\n        raise AssertionError(\"Invalid plan type\")\n\n    update_first_visible_message_id(realm)\n\n    realm.save(update_fields=[\"_max_invites\", \"message_visibility_limit\", \"upload_quota_gb\"])\n\n    event = {\n        \"type\": \"realm\",\n        \"op\": \"update\",\n        \"property\": \"plan_type\",\n        \"value\": plan_type,\n        \"extra_data\": {\"upload_quota\": realm.upload_quota_bytes()},\n    }\n    transaction.on_commit(lambda: send_event(realm, event, active_user_ids(realm.id)))\n\n\n@transaction.atomic(durable=True)\ndef do_change_default_sending_stream(\n    user_profile: UserProfile, stream: Optional[Stream], *, acting_user: Optional[UserProfile]\n) -> None:\n    old_value = user_profile.default_sending_stream_id\n    user_profile.default_sending_stream = stream\n    user_profile.save(update_fields=[\"default_sending_stream\"])\n\n    event_time = timezone_now()\n    RealmAuditLog.objects.create(\n        realm=user_profile.realm,\n        event_type=RealmAuditLog.USER_DEFAULT_SENDING_STREAM_CHANGED,\n        event_time=event_time,\n        modified_user=user_profile,\n        acting_user=acting_user,\n        extra_data=orjson.dumps(\n            {\n                RealmAuditLog.OLD_VALUE: old_value,\n                RealmAuditLog.NEW_VALUE: None if stream is None else stream.id,\n            }\n        ).decode(),\n    )\n\n    if user_profile.is_bot:\n        if stream:\n            stream_name: Optional[str] = stream.name\n        else:\n            stream_name = None\n        event = dict(\n            type=\"realm_bot\",\n            op=\"update\",\n            bot=dict(\n                user_id=user_profile.id,\n                default_sending_stream=stream_name,\n            ),\n        )\n        transaction.on_commit(\n            lambda: send_event(\n                user_profile.realm,\n                event,\n                bot_owner_user_ids(user_profile),\n            )\n        )\n\n\n@transaction.atomic(durable=True)\ndef do_change_default_events_register_stream(\n    user_profile: UserProfile, stream: Optional[Stream], *, acting_user: Optional[UserProfile]\n) -> None:\n    old_value = user_profile.default_events_register_stream_id\n    user_profile.default_events_register_stream = stream\n    user_profile.save(update_fields=[\"default_events_register_stream\"])\n\n    event_time = timezone_now()\n    RealmAuditLog.objects.create(\n        realm=user_profile.realm,\n        event_type=RealmAuditLog.USER_DEFAULT_REGISTER_STREAM_CHANGED,\n        event_time=event_time,\n        modified_user=user_profile,\n        acting_user=acting_user,\n        extra_data=orjson.dumps(\n            {\n                RealmAuditLog.OLD_VALUE: old_value,\n                RealmAuditLog.NEW_VALUE: None if stream is None else stream.id,\n            }\n        ).decode(),\n    )\n\n    if user_profile.is_bot:\n        if stream:\n            stream_name: Optional[str] = stream.name\n        else:\n            stream_name = None\n\n        event = dict(\n            type=\"realm_bot\",\n            op=\"update\",\n            bot=dict(\n                user_id=user_profile.id,\n                default_events_register_stream=stream_name,\n            ),\n        )\n        transaction.on_commit(\n            lambda: send_event(\n                user_profile.realm,\n                event,\n                bot_owner_user_ids(user_profile),\n            )\n        )\n\n\n@transaction.atomic(durable=True)\ndef do_change_default_all_public_streams(\n    user_profile: UserProfile, value: bool, *, acting_user: Optional[UserProfile]\n) -> None:\n    old_value = user_profile.default_all_public_streams\n    user_profile.default_all_public_streams = value\n    user_profile.save(update_fields=[\"default_all_public_streams\"])\n\n    event_time = timezone_now()\n    RealmAuditLog.objects.create(\n        realm=user_profile.realm,\n        event_type=RealmAuditLog.USER_DEFAULT_ALL_PUBLIC_STREAMS_CHANGED,\n        event_time=event_time,\n        modified_user=user_profile,\n        acting_user=acting_user,\n        extra_data=orjson.dumps(\n            {\n                RealmAuditLog.OLD_VALUE: old_value,\n                RealmAuditLog.NEW_VALUE: value,\n            }\n        ).decode(),\n    )\n\n    if user_profile.is_bot:\n        event = dict(\n            type=\"realm_bot\",\n            op=\"update\",\n            bot=dict(\n                user_id=user_profile.id,\n                default_all_public_streams=user_profile.default_all_public_streams,\n            ),\n        )\n        transaction.on_commit(\n            lambda: send_event(\n                user_profile.realm,\n                event,\n                bot_owner_user_ids(user_profile),\n            )\n        )\n\n\n@transaction.atomic(durable=True)\ndef do_change_user_role(\n    user_profile: UserProfile, value: int, *, acting_user: Optional[UserProfile]\n) -> None:\n    old_value = user_profile.role\n    old_system_group = get_system_user_group_for_user(user_profile)\n\n    user_profile.role = value\n    user_profile.save(update_fields=[\"role\"])\n    RealmAuditLog.objects.create(\n        realm=user_profile.realm,\n        modified_user=user_profile,\n        acting_user=acting_user,\n        event_type=RealmAuditLog.USER_ROLE_CHANGED,\n        event_time=timezone_now(),\n        extra_data=orjson.dumps(\n            {\n                RealmAuditLog.OLD_VALUE: old_value,\n                RealmAuditLog.NEW_VALUE: value,\n                RealmAuditLog.ROLE_COUNT: realm_user_count_by_role(user_profile.realm),\n            }\n        ).decode(),\n    )\n    event = dict(\n        type=\"realm_user\", op=\"update\", person=dict(user_id=user_profile.id, role=user_profile.role)\n    )\n    transaction.on_commit(\n        lambda: send_event(user_profile.realm, event, active_user_ids(user_profile.realm_id))\n    )\n\n    UserGroupMembership.objects.filter(\n        user_profile=user_profile, user_group=old_system_group\n    ).delete()\n\n    system_group = get_system_user_group_for_user(user_profile)\n    UserGroupMembership.objects.create(user_profile=user_profile, user_group=system_group)\n\n    do_send_user_group_members_update_event(\"remove_members\", old_system_group, [user_profile.id])\n\n    do_send_user_group_members_update_event(\"add_members\", system_group, [user_profile.id])\n\n    if UserProfile.ROLE_MEMBER in [old_value, value]:\n        update_users_in_full_members_system_group(user_profile.realm, [user_profile.id])\n\n\ndef do_make_user_billing_admin(user_profile: UserProfile) -> None:\n    user_profile.is_billing_admin = True\n    user_profile.save(update_fields=[\"is_billing_admin\"])\n    event = dict(\n        type=\"realm_user\", op=\"update\", person=dict(user_id=user_profile.id, is_billing_admin=True)\n    )\n    send_event(user_profile.realm, event, active_user_ids(user_profile.realm_id))\n\n\ndef do_change_can_forge_sender(user_profile: UserProfile, value: bool) -> None:\n    user_profile.can_forge_sender = value\n    user_profile.save(update_fields=[\"can_forge_sender\"])\n\n\ndef do_change_can_create_users(user_profile: UserProfile, value: bool) -> None:\n    user_profile.can_create_users = value\n    user_profile.save(update_fields=[\"can_create_users\"])\n\n\ndef send_change_stream_permission_notification(\n    stream: Stream,\n    *,\n    old_policy_name: str,\n    new_policy_name: str,\n    acting_user: UserProfile,\n) -> None:\n    sender = get_system_bot(settings.NOTIFICATION_BOT, acting_user.realm_id)\n    user_mention = silent_mention_syntax_for_user(acting_user)\n\n    with override_language(stream.realm.default_language):\n        notification_string = _(\n            \"{user} changed the [access permissions](/help/stream-permissions) \"\n            \"for this stream from **{old_policy}** to **{new_policy}**.\"\n        )\n        notification_string = notification_string.format(\n            user=user_mention,\n            old_policy=old_policy_name,\n            new_policy=new_policy_name,\n        )\n        internal_send_stream_message(\n            sender, stream, Realm.STREAM_EVENTS_NOTIFICATION_TOPIC, notification_string\n        )\n\n\ndef do_change_stream_permission(\n    stream: Stream,\n    *,\n    invite_only: Optional[bool] = None,\n    history_public_to_subscribers: Optional[bool] = None,\n    is_web_public: Optional[bool] = None,\n    acting_user: UserProfile,\n) -> None:\n    old_invite_only_value = stream.invite_only\n    old_history_public_to_subscribers_value = stream.history_public_to_subscribers\n    old_is_web_public_value = stream.is_web_public\n\n    # A note on these assertions: It's possible we'd be better off\n    # making all callers of this function pass the full set of\n    # parameters, rather than having default values.  Doing so would\n    # allow us to remove the messy logic below, where we sometimes\n    # ignore the passed parameters.\n    #\n    # But absent such a refactoring, it's important to assert that\n    # we're not requesting an unsupported configurations.\n    if is_web_public:\n        assert history_public_to_subscribers is not False\n        assert invite_only is not True\n        stream.is_web_public = True\n        stream.invite_only = False\n        stream.history_public_to_subscribers = True\n    else:\n        assert invite_only is not None\n        # is_web_public is falsey\n        history_public_to_subscribers = get_default_value_for_history_public_to_subscribers(\n            stream.realm,\n            invite_only,\n            history_public_to_subscribers,\n        )\n        stream.invite_only = invite_only\n        stream.history_public_to_subscribers = history_public_to_subscribers\n        stream.is_web_public = False\n\n    with transaction.atomic():\n        stream.save(update_fields=[\"invite_only\", \"history_public_to_subscribers\", \"is_web_public\"])\n\n        event_time = timezone_now()\n        if old_invite_only_value != stream.invite_only:\n            RealmAuditLog.objects.create(\n                realm=stream.realm,\n                acting_user=acting_user,\n                modified_stream=stream,\n                event_type=RealmAuditLog.STREAM_PROPERTY_CHANGED,\n                event_time=event_time,\n                extra_data=orjson.dumps(\n                    {\n                        RealmAuditLog.OLD_VALUE: old_invite_only_value,\n                        RealmAuditLog.NEW_VALUE: stream.invite_only,\n                        \"property\": \"invite_only\",\n                    }\n                ).decode(),\n            )\n\n        if old_history_public_to_subscribers_value != stream.history_public_to_subscribers:\n            RealmAuditLog.objects.create(\n                realm=stream.realm,\n                acting_user=acting_user,\n                modified_stream=stream,\n                event_type=RealmAuditLog.STREAM_PROPERTY_CHANGED,\n                event_time=event_time,\n                extra_data=orjson.dumps(\n                    {\n                        RealmAuditLog.OLD_VALUE: old_history_public_to_subscribers_value,\n                        RealmAuditLog.NEW_VALUE: stream.history_public_to_subscribers,\n                        \"property\": \"history_public_to_subscribers\",\n                    }\n                ).decode(),\n            )\n\n        if old_is_web_public_value != stream.is_web_public:\n            RealmAuditLog.objects.create(\n                realm=stream.realm,\n                acting_user=acting_user,\n                modified_stream=stream,\n                event_type=RealmAuditLog.STREAM_PROPERTY_CHANGED,\n                event_time=event_time,\n                extra_data=orjson.dumps(\n                    {\n                        RealmAuditLog.OLD_VALUE: old_is_web_public_value,\n                        RealmAuditLog.NEW_VALUE: stream.is_web_public,\n                        \"property\": \"is_web_public\",\n                    }\n                ).decode(),\n            )\n\n    event = dict(\n        op=\"update\",\n        type=\"stream\",\n        property=\"invite_only\",\n        value=stream.invite_only,\n        history_public_to_subscribers=stream.history_public_to_subscribers,\n        is_web_public=stream.is_web_public,\n        stream_id=stream.id,\n        name=stream.name,\n    )\n    send_event(stream.realm, event, can_access_stream_user_ids(stream))\n\n    old_policy_name = get_stream_permission_policy_name(\n        invite_only=old_invite_only_value,\n        history_public_to_subscribers=old_history_public_to_subscribers_value,\n        is_web_public=old_is_web_public_value,\n    )\n    new_policy_name = get_stream_permission_policy_name(\n        invite_only=stream.invite_only,\n        history_public_to_subscribers=stream.history_public_to_subscribers,\n        is_web_public=stream.is_web_public,\n    )\n    send_change_stream_permission_notification(\n        stream,\n        old_policy_name=old_policy_name,\n        new_policy_name=new_policy_name,\n        acting_user=acting_user,\n    )\n\n\ndef send_change_stream_post_policy_notification(\n    stream: Stream, *, old_post_policy: int, new_post_policy: int, acting_user: UserProfile\n) -> None:\n    sender = get_system_bot(settings.NOTIFICATION_BOT, acting_user.realm_id)\n    user_mention = silent_mention_syntax_for_user(acting_user)\n\n    with override_language(stream.realm.default_language):\n        notification_string = _(\n            \"{user} changed the [posting permissions](/help/stream-sending-policy) \"\n            \"for this stream:\\n\\n\"\n            \"* **Old permissions**: {old_policy}.\\n\"\n            \"* **New permissions**: {new_policy}.\\n\"\n        )\n        notification_string = notification_string.format(\n            user=user_mention,\n            old_policy=Stream.POST_POLICIES[old_post_policy],\n            new_policy=Stream.POST_POLICIES[new_post_policy],\n        )\n        internal_send_stream_message(\n            sender, stream, Realm.STREAM_EVENTS_NOTIFICATION_TOPIC, notification_string\n        )\n\n\ndef do_change_stream_post_policy(\n    stream: Stream, stream_post_policy: int, *, acting_user: UserProfile\n) -> None:\n    old_post_policy = stream.stream_post_policy\n    with transaction.atomic():\n        stream.stream_post_policy = stream_post_policy\n        stream.save(update_fields=[\"stream_post_policy\"])\n        RealmAuditLog.objects.create(\n            realm=stream.realm,\n            acting_user=acting_user,\n            modified_stream=stream,\n            event_type=RealmAuditLog.STREAM_PROPERTY_CHANGED,\n            event_time=timezone_now(),\n            extra_data=orjson.dumps(\n                {\n                    RealmAuditLog.OLD_VALUE: old_post_policy,\n                    RealmAuditLog.NEW_VALUE: stream_post_policy,\n                    \"property\": \"stream_post_policy\",\n                }\n            ).decode(),\n        )\n\n    event = dict(\n        op=\"update\",\n        type=\"stream\",\n        property=\"stream_post_policy\",\n        value=stream_post_policy,\n        stream_id=stream.id,\n        name=stream.name,\n    )\n    send_event(stream.realm, event, can_access_stream_user_ids(stream))\n\n    # Backwards-compatibility code: We removed the\n    # is_announcement_only property in early 2020, but we send a\n    # duplicate event for legacy mobile clients that might want the\n    # data.\n    event = dict(\n        op=\"update\",\n        type=\"stream\",\n        property=\"is_announcement_only\",\n        value=stream.stream_post_policy == Stream.STREAM_POST_POLICY_ADMINS,\n        stream_id=stream.id,\n        name=stream.name,\n    )\n    send_event(stream.realm, event, can_access_stream_user_ids(stream))\n\n    send_change_stream_post_policy_notification(\n        stream,\n        old_post_policy=old_post_policy,\n        new_post_policy=stream_post_policy,\n        acting_user=acting_user,\n    )\n\n\ndef do_rename_stream(stream: Stream, new_name: str, user_profile: UserProfile) -> Dict[str, str]:\n    old_name = stream.name\n    stream.name = new_name\n    stream.save(update_fields=[\"name\"])\n\n    RealmAuditLog.objects.create(\n        realm=stream.realm,\n        acting_user=user_profile,\n        modified_stream=stream,\n        event_type=RealmAuditLog.STREAM_NAME_CHANGED,\n        event_time=timezone_now(),\n        extra_data=orjson.dumps(\n            {\n                RealmAuditLog.OLD_VALUE: old_name,\n                RealmAuditLog.NEW_VALUE: new_name,\n            }\n        ).decode(),\n    )\n\n    recipient_id = stream.recipient_id\n    messages = Message.objects.filter(recipient_id=recipient_id).only(\"id\")\n\n    # Update the display recipient and stream, which are easy single\n    # items to set.\n    old_cache_key = get_stream_cache_key(old_name, stream.realm_id)\n    new_cache_key = get_stream_cache_key(stream.name, stream.realm_id)\n    if old_cache_key != new_cache_key:\n        cache_delete(old_cache_key)\n        cache_set(new_cache_key, stream)\n    cache_set(display_recipient_cache_key(recipient_id), stream.name)\n\n    # Delete cache entries for everything else, which is cheaper and\n    # clearer than trying to set them. display_recipient is the out of\n    # date field in all cases.\n    cache_delete_many(to_dict_cache_key_id(message.id) for message in messages)\n    new_email = encode_email_address(stream, show_sender=True)\n\n    # We will tell our users to essentially\n    # update stream.name = new_name where name = old_name\n    # and update stream.email = new_email where name = old_name.\n    # We could optimize this by trying to send one message, but the\n    # client code really wants one property update at a time, and\n    # updating stream names is a pretty infrequent operation.\n    # More importantly, we want to key these updates by id, not name,\n    # since id is the immutable primary key, and obviously name is not.\n    data_updates = [\n        [\"email_address\", new_email],\n        [\"name\", new_name],\n    ]\n    for property, value in data_updates:\n        event = dict(\n            op=\"update\",\n            type=\"stream\",\n            property=property,\n            value=value,\n            stream_id=stream.id,\n            name=old_name,\n        )\n        send_event(stream.realm, event, can_access_stream_user_ids(stream))\n    sender = get_system_bot(settings.NOTIFICATION_BOT, stream.realm_id)\n    with override_language(stream.realm.default_language):\n        internal_send_stream_message(\n            sender,\n            stream,\n            Realm.STREAM_EVENTS_NOTIFICATION_TOPIC,\n            _(\"{user_name} renamed stream {old_stream_name} to {new_stream_name}.\").format(\n                user_name=silent_mention_syntax_for_user(user_profile),\n                old_stream_name=f\"**{old_name}**\",\n                new_stream_name=f\"**{new_name}**\",\n            ),\n        )\n    # Even though the token doesn't change, the web client needs to update the\n    # email forwarding address to display the correctly-escaped new name.\n    return {\"email_address\": new_email}\n\n\ndef send_change_stream_description_notification(\n    stream: Stream, *, old_description: str, new_description: str, acting_user: UserProfile\n) -> None:\n    sender = get_system_bot(settings.NOTIFICATION_BOT, acting_user.realm_id)\n    user_mention = silent_mention_syntax_for_user(acting_user)\n\n    with override_language(stream.realm.default_language):\n        notification_string = (\n            _(\"{user} changed the description for this stream.\").format(user=user_mention)\n            + \"\\n\\n* **\"\n            + _(\"Old description\")\n            + \":**\"\n            + f\"\\n```` quote\\n{old_description}\\n````\\n\"\n            + \"* **\"\n            + _(\"New description\")\n            + \":**\"\n            + f\"\\n```` quote\\n{new_description}\\n````\"\n        )\n\n        internal_send_stream_message(\n            sender, stream, Realm.STREAM_EVENTS_NOTIFICATION_TOPIC, notification_string\n        )\n\n\ndef do_change_stream_description(\n    stream: Stream, new_description: str, *, acting_user: UserProfile\n) -> None:\n    old_description = stream.description\n\n    with transaction.atomic():\n        stream.description = new_description\n        stream.rendered_description = render_stream_description(new_description)\n        stream.save(update_fields=[\"description\", \"rendered_description\"])\n        RealmAuditLog.objects.create(\n            realm=stream.realm,\n            acting_user=acting_user,\n            modified_stream=stream,\n            event_type=RealmAuditLog.STREAM_PROPERTY_CHANGED,\n            event_time=timezone_now(),\n            extra_data=orjson.dumps(\n                {\n                    RealmAuditLog.OLD_VALUE: old_description,\n                    RealmAuditLog.NEW_VALUE: new_description,\n                    \"property\": \"description\",\n                }\n            ).decode(),\n        )\n\n    event = dict(\n        type=\"stream\",\n        op=\"update\",\n        property=\"description\",\n        name=stream.name,\n        stream_id=stream.id,\n        value=new_description,\n        rendered_description=stream.rendered_description,\n    )\n    send_event(stream.realm, event, can_access_stream_user_ids(stream))\n\n    send_change_stream_description_notification(\n        stream,\n        old_description=old_description,\n        new_description=new_description,\n        acting_user=acting_user,\n    )\n\n\ndef send_change_stream_message_retention_days_notification(\n    user_profile: UserProfile, stream: Stream, old_value: Optional[int], new_value: Optional[int]\n) -> None:\n    sender = get_system_bot(settings.NOTIFICATION_BOT, user_profile.realm_id)\n    user_mention = silent_mention_syntax_for_user(user_profile)\n\n    # If switching from or to the organization's default retention policy,\n    # we want to take the realm's default into account.\n    if old_value is None:\n        old_value = stream.realm.message_retention_days\n    if new_value is None:\n        new_value = stream.realm.message_retention_days\n\n    with override_language(stream.realm.default_language):\n        if old_value == Stream.MESSAGE_RETENTION_SPECIAL_VALUES_MAP[\"unlimited\"]:\n            old_retention_period = _(\"Forever\")\n            new_retention_period = f\"{new_value} days\"\n            summary_line = f\"Messages in this stream will now be automatically deleted {new_value} days after they are sent.\"\n        elif new_value == Stream.MESSAGE_RETENTION_SPECIAL_VALUES_MAP[\"unlimited\"]:\n            old_retention_period = f\"{old_value} days\"\n            new_retention_period = _(\"Forever\")\n            summary_line = _(\"Messages in this stream will now be retained forever.\")\n        else:\n            old_retention_period = f\"{old_value} days\"\n            new_retention_period = f\"{new_value} days\"\n            summary_line = f\"Messages in this stream will now be automatically deleted {new_value} days after they are sent.\"\n        notification_string = _(\n            \"{user} has changed the [message retention period](/help/message-retention-policy) for this stream:\\n\"\n            \"* **Old retention period**: {old_retention_period}\\n\"\n            \"* **New retention period**: {new_retention_period}\\n\\n\"\n            \"{summary_line}\"\n        )\n        notification_string = notification_string.format(\n            user=user_mention,\n            old_retention_period=old_retention_period,\n            new_retention_period=new_retention_period,\n            summary_line=summary_line,\n        )\n        internal_send_stream_message(\n            sender, stream, Realm.STREAM_EVENTS_NOTIFICATION_TOPIC, notification_string\n        )\n\n\ndef do_change_stream_message_retention_days(\n    stream: Stream, acting_user: UserProfile, message_retention_days: Optional[int] = None\n) -> None:\n    old_message_retention_days_value = stream.message_retention_days\n\n    with transaction.atomic():\n        stream.message_retention_days = message_retention_days\n        stream.save(update_fields=[\"message_retention_days\"])\n        RealmAuditLog.objects.create(\n            realm=stream.realm,\n            acting_user=acting_user,\n            modified_stream=stream,\n            event_type=RealmAuditLog.STREAM_MESSAGE_RETENTION_DAYS_CHANGED,\n            event_time=timezone_now(),\n            extra_data=orjson.dumps(\n                {\n                    RealmAuditLog.OLD_VALUE: old_message_retention_days_value,\n                    RealmAuditLog.NEW_VALUE: message_retention_days,\n                }\n            ).decode(),\n        )\n\n    event = dict(\n        op=\"update\",\n        type=\"stream\",\n        property=\"message_retention_days\",\n        value=message_retention_days,\n        stream_id=stream.id,\n        name=stream.name,\n    )\n    send_event(stream.realm, event, can_access_stream_user_ids(stream))\n    send_change_stream_message_retention_days_notification(\n        user_profile=acting_user,\n        stream=stream,\n        old_value=old_message_retention_days_value,\n        new_value=message_retention_days,\n    )\n\n\ndef set_realm_permissions_based_on_org_type(realm: Realm) -> None:\n    \"\"\"This function implements overrides for the default configuration\n    for new organizations when the administrator selected specific\n    organization types.\n\n    This substantially simplifies our /help/ advice for folks setting\n    up new organizations of these types.\n    \"\"\"\n\n    # Custom configuration for educational organizations.  The present\n    # defaults are designed for a single class, not a department or\n    # larger institution, since those are more common.\n    if (\n        realm.org_type == Realm.ORG_TYPES[\"education_nonprofit\"][\"id\"]\n        or realm.org_type == Realm.ORG_TYPES[\"education\"][\"id\"]\n    ):\n        # Limit email address visibility and user creation to administrators.\n        realm.email_address_visibility = Realm.EMAIL_ADDRESS_VISIBILITY_ADMINS\n        realm.invite_to_realm_policy = Realm.POLICY_ADMINS_ONLY\n        # Restrict public stream creation to staff, but allow private\n        # streams (useful for study groups, etc.).\n        realm.create_public_stream_policy = Realm.POLICY_ADMINS_ONLY\n        # Don't allow members (students) to manage user groups or\n        # stream subscriptions.\n        realm.user_group_edit_policy = Realm.POLICY_MODERATORS_ONLY\n        realm.invite_to_stream_policy = Realm.POLICY_MODERATORS_ONLY\n        # Allow moderators (TAs?) to move topics between streams.\n        realm.move_messages_between_streams_policy = Realm.POLICY_MODERATORS_ONLY\n\n\ndef do_create_realm(\n    string_id: str,\n    name: str,\n    *,\n    emails_restricted_to_domains: Optional[bool] = None,\n    email_address_visibility: Optional[int] = None,\n    description: Optional[str] = None,\n    invite_required: Optional[bool] = None,\n    plan_type: Optional[int] = None,\n    org_type: Optional[int] = None,\n    date_created: Optional[datetime.datetime] = None,\n    is_demo_organization: Optional[bool] = False,\n    enable_spectator_access: Optional[bool] = False,\n) -> Realm:\n    if string_id == settings.SOCIAL_AUTH_SUBDOMAIN:\n        raise AssertionError(\"Creating a realm on SOCIAL_AUTH_SUBDOMAIN is not allowed!\")\n    if Realm.objects.filter(string_id=string_id).exists():\n        raise AssertionError(f\"Realm {string_id} already exists!\")\n    if not server_initialized():\n        logging.info(\"Server not yet initialized. Creating the internal realm first.\")\n        create_internal_realm()\n\n    kwargs: Dict[str, Any] = {}\n    if emails_restricted_to_domains is not None:\n        kwargs[\"emails_restricted_to_domains\"] = emails_restricted_to_domains\n    if email_address_visibility is not None:\n        kwargs[\"email_address_visibility\"] = email_address_visibility\n    if description is not None:\n        kwargs[\"description\"] = description\n    if invite_required is not None:\n        kwargs[\"invite_required\"] = invite_required\n    if plan_type is not None:\n        kwargs[\"plan_type\"] = plan_type\n    if org_type is not None:\n        kwargs[\"org_type\"] = org_type\n    if enable_spectator_access is not None:\n        kwargs[\"enable_spectator_access\"] = enable_spectator_access\n\n    if date_created is not None:\n        # The date_created parameter is intended only for use by test\n        # suites that want to backdate the date of a realm's creation.\n        assert not settings.PRODUCTION\n        kwargs[\"date_created\"] = date_created\n\n    with transaction.atomic():\n        realm = Realm(string_id=string_id, name=name, **kwargs)\n        if is_demo_organization:\n            realm.demo_organization_scheduled_deletion_date = (\n                realm.date_created + datetime.timedelta(days=settings.DEMO_ORG_DEADLINE_DAYS)\n            )\n\n        set_realm_permissions_based_on_org_type(realm)\n        realm.save()\n\n        RealmAuditLog.objects.create(\n            realm=realm, event_type=RealmAuditLog.REALM_CREATED, event_time=realm.date_created\n        )\n\n        RealmUserDefault.objects.create(realm=realm)\n\n        create_system_user_groups_for_realm(realm)\n\n    # Create stream once Realm object has been saved\n    notifications_stream = ensure_stream(\n        realm,\n        Realm.DEFAULT_NOTIFICATION_STREAM_NAME,\n        stream_description=\"Everyone is added to this stream by default. Welcome! :octopus:\",\n        acting_user=None,\n    )\n    realm.notifications_stream = notifications_stream\n\n    # With the current initial streams situation, the only public\n    # stream is the notifications_stream.\n    DefaultStream.objects.create(stream=notifications_stream, realm=realm)\n\n    signup_notifications_stream = ensure_stream(\n        realm,\n        Realm.INITIAL_PRIVATE_STREAM_NAME,\n        invite_only=True,\n        stream_description=\"A private stream for core team members.\",\n        acting_user=None,\n    )\n    realm.signup_notifications_stream = signup_notifications_stream\n\n    realm.save(update_fields=[\"notifications_stream\", \"signup_notifications_stream\"])\n\n    if plan_type is None and settings.BILLING_ENABLED:\n        do_change_realm_plan_type(realm, Realm.PLAN_TYPE_LIMITED, acting_user=None)\n\n    admin_realm = get_realm(settings.SYSTEM_BOT_REALM)\n    sender = get_system_bot(settings.NOTIFICATION_BOT, admin_realm.id)\n    # Send a notification to the admin realm\n    signup_message = _(\"Signups enabled\")\n\n    try:\n        signups_stream = get_signups_stream(admin_realm)\n        topic = realm.display_subdomain\n\n        internal_send_stream_message(\n            sender,\n            signups_stream,\n            topic,\n            signup_message,\n        )\n    except Stream.DoesNotExist:  # nocoverage\n        # If the signups stream hasn't been created in the admin\n        # realm, don't auto-create it to send to it; just do nothing.\n        pass\n    return realm\n\n\ndef update_scheduled_email_notifications_time(\n    user_profile: UserProfile, old_batching_period: int, new_batching_period: int\n) -> None:\n    existing_scheduled_emails = ScheduledMessageNotificationEmail.objects.filter(\n        user_profile=user_profile\n    )\n\n    scheduled_timestamp_change = datetime.timedelta(\n        seconds=new_batching_period\n    ) - datetime.timedelta(seconds=old_batching_period)\n\n    existing_scheduled_emails.update(\n        scheduled_timestamp=F(\"scheduled_timestamp\") + scheduled_timestamp_change\n    )\n\n\n@transaction.atomic(durable=True)\ndef do_change_user_setting(\n    user_profile: UserProfile,\n    setting_name: str,\n    setting_value: Union[bool, str, int],\n    *,\n    acting_user: Optional[UserProfile],\n) -> None:\n    old_value = getattr(user_profile, setting_name)\n    event_time = timezone_now()\n\n    if setting_name == \"timezone\":\n        assert isinstance(setting_value, str)\n        setting_value = canonicalize_timezone(setting_value)\n    else:\n        property_type = UserProfile.property_types[setting_name]\n        assert isinstance(setting_value, property_type)\n    setattr(user_profile, setting_name, setting_value)\n\n    # TODO: Move these database actions into a transaction.atomic block.\n    user_profile.save(update_fields=[setting_name])\n\n    if setting_name in UserProfile.notification_setting_types:\n        # Prior to all personal settings being managed by property_types,\n        # these were only created for notification settings.\n        #\n        # TODO: Start creating these for all settings, and do a\n        # backfilled=True migration.\n        RealmAuditLog.objects.create(\n            realm=user_profile.realm,\n            event_type=RealmAuditLog.USER_SETTING_CHANGED,\n            event_time=event_time,\n            acting_user=acting_user,\n            modified_user=user_profile,\n            extra_data=orjson.dumps(\n                {\n                    RealmAuditLog.OLD_VALUE: old_value,\n                    RealmAuditLog.NEW_VALUE: setting_value,\n                    \"property\": setting_name,\n                }\n            ).decode(),\n        )\n    # Disabling digest emails should clear a user's email queue\n    if setting_name == \"enable_digest_emails\" and not setting_value:\n        clear_scheduled_emails(user_profile.id, ScheduledEmail.DIGEST)\n\n    if setting_name == \"email_notifications_batching_period_seconds\":\n        assert isinstance(old_value, int)\n        assert isinstance(setting_value, int)\n        update_scheduled_email_notifications_time(user_profile, old_value, setting_value)\n\n    event = {\n        \"type\": \"user_settings\",\n        \"op\": \"update\",\n        \"property\": setting_name,\n        \"value\": setting_value,\n    }\n    if setting_name == \"default_language\":\n        assert isinstance(setting_value, str)\n        event[\"language_name\"] = get_language_name(setting_value)\n\n    transaction.on_commit(lambda: send_event(user_profile.realm, event, [user_profile.id]))\n\n    if setting_name in UserProfile.notification_settings_legacy:\n        # This legacy event format is for backwards-compatibility with\n        # clients that don't support the new user_settings event type.\n        # We only send this for settings added before Feature level 89.\n        legacy_event = {\n            \"type\": \"update_global_notifications\",\n            \"user\": user_profile.email,\n            \"notification_name\": setting_name,\n            \"setting\": setting_value,\n        }\n        transaction.on_commit(\n            lambda: send_event(user_profile.realm, legacy_event, [user_profile.id])\n        )\n\n    if setting_name in UserProfile.display_settings_legacy or setting_name == \"timezone\":\n        # This legacy event format is for backwards-compatibility with\n        # clients that don't support the new user_settings event type.\n        # We only send this for settings added before Feature level 89.\n        legacy_event = {\n            \"type\": \"update_display_settings\",\n            \"user\": user_profile.email,\n            \"setting_name\": setting_name,\n            \"setting\": setting_value,\n        }\n        if setting_name == \"default_language\":\n            assert isinstance(setting_value, str)\n            legacy_event[\"language_name\"] = get_language_name(setting_value)\n\n        transaction.on_commit(\n            lambda: send_event(user_profile.realm, legacy_event, [user_profile.id])\n        )\n\n    # Updates to the time zone display setting are sent to all users\n    if setting_name == \"timezone\":\n        payload = dict(\n            email=user_profile.email,\n            user_id=user_profile.id,\n            timezone=canonicalize_timezone(user_profile.timezone),\n        )\n        timezone_event = dict(type=\"realm_user\", op=\"update\", person=payload)\n        transaction.on_commit(\n            lambda: send_event(\n                user_profile.realm,\n                timezone_event,\n                active_user_ids(user_profile.realm_id),\n            )\n        )\n\n    if setting_name == \"enable_drafts_synchronization\" and setting_value is False:\n        # Delete all of the drafts from the backend but don't send delete events\n        # for them since all that's happened is that we stopped syncing changes,\n        # not deleted every previously synced draft - to do that use the DELETE\n        # endpoint.\n        Draft.objects.filter(user_profile=user_profile).delete()\n\n\ndef lookup_default_stream_groups(\n    default_stream_group_names: List[str], realm: Realm\n) -> List[DefaultStreamGroup]:\n    default_stream_groups = []\n    for group_name in default_stream_group_names:\n        try:\n            default_stream_group = DefaultStreamGroup.objects.get(name=group_name, realm=realm)\n        except DefaultStreamGroup.DoesNotExist:\n            raise JsonableError(_(\"Invalid default stream group {}\").format(group_name))\n        default_stream_groups.append(default_stream_group)\n    return default_stream_groups\n\n\ndef notify_default_streams(realm: Realm) -> None:\n    event = dict(\n        type=\"default_streams\",\n        default_streams=streams_to_dicts_sorted(get_default_streams_for_realm(realm.id)),\n    )\n    transaction.on_commit(lambda: send_event(realm, event, active_non_guest_user_ids(realm.id)))\n\n\ndef notify_default_stream_groups(realm: Realm) -> None:\n    event = dict(\n        type=\"default_stream_groups\",\n        default_stream_groups=default_stream_groups_to_dicts_sorted(\n            get_default_stream_groups(realm)\n        ),\n    )\n    transaction.on_commit(lambda: send_event(realm, event, active_non_guest_user_ids(realm.id)))\n\n\ndef do_add_default_stream(stream: Stream) -> None:\n    realm_id = stream.realm_id\n    stream_id = stream.id\n    if not DefaultStream.objects.filter(realm_id=realm_id, stream_id=stream_id).exists():\n        DefaultStream.objects.create(realm_id=realm_id, stream_id=stream_id)\n        notify_default_streams(stream.realm)\n\n\n@transaction.atomic(savepoint=False)\ndef do_remove_default_stream(stream: Stream) -> None:\n    realm_id = stream.realm_id\n    stream_id = stream.id\n    DefaultStream.objects.filter(realm_id=realm_id, stream_id=stream_id).delete()\n    notify_default_streams(stream.realm)\n\n\ndef do_create_default_stream_group(\n    realm: Realm, group_name: str, description: str, streams: List[Stream]\n) -> None:\n    default_streams = get_default_streams_for_realm(realm.id)\n    for stream in streams:\n        if stream in default_streams:\n            raise JsonableError(\n                _(\n                    \"'{stream_name}' is a default stream and cannot be added to '{group_name}'\",\n                ).format(stream_name=stream.name, group_name=group_name)\n            )\n\n    check_default_stream_group_name(group_name)\n    (group, created) = DefaultStreamGroup.objects.get_or_create(\n        name=group_name, realm=realm, description=description\n    )\n    if not created:\n        raise JsonableError(\n            _(\n                \"Default stream group '{group_name}' already exists\",\n            ).format(group_name=group_name)\n        )\n\n    group.streams.set(streams)\n    notify_default_stream_groups(realm)\n\n\ndef do_add_streams_to_default_stream_group(\n    realm: Realm, group: DefaultStreamGroup, streams: List[Stream]\n) -> None:\n    default_streams = get_default_streams_for_realm(realm.id)\n    for stream in streams:\n        if stream in default_streams:\n            raise JsonableError(\n                _(\n                    \"'{stream_name}' is a default stream and cannot be added to '{group_name}'\",\n                ).format(stream_name=stream.name, group_name=group.name)\n            )\n        if stream in group.streams.all():\n            raise JsonableError(\n                _(\n                    \"Stream '{stream_name}' is already present in default stream group '{group_name}'\",\n                ).format(stream_name=stream.name, group_name=group.name)\n            )\n        group.streams.add(stream)\n\n    group.save()\n    notify_default_stream_groups(realm)\n\n\ndef do_remove_streams_from_default_stream_group(\n    realm: Realm, group: DefaultStreamGroup, streams: List[Stream]\n) -> None:\n    for stream in streams:\n        if stream not in group.streams.all():\n            raise JsonableError(\n                _(\n                    \"Stream '{stream_name}' is not present in default stream group '{group_name}'\",\n                ).format(stream_name=stream.name, group_name=group.name)\n            )\n        group.streams.remove(stream)\n\n    group.save()\n    notify_default_stream_groups(realm)\n\n\ndef do_change_default_stream_group_name(\n    realm: Realm, group: DefaultStreamGroup, new_group_name: str\n) -> None:\n    if group.name == new_group_name:\n        raise JsonableError(\n            _(\"This default stream group is already named '{}'\").format(new_group_name)\n        )\n\n    if DefaultStreamGroup.objects.filter(name=new_group_name, realm=realm).exists():\n        raise JsonableError(_(\"Default stream group '{}' already exists\").format(new_group_name))\n\n    group.name = new_group_name\n    group.save()\n    notify_default_stream_groups(realm)\n\n\ndef do_change_default_stream_group_description(\n    realm: Realm, group: DefaultStreamGroup, new_description: str\n) -> None:\n    group.description = new_description\n    group.save()\n    notify_default_stream_groups(realm)\n\n\ndef do_remove_default_stream_group(realm: Realm, group: DefaultStreamGroup) -> None:\n    group.delete()\n    notify_default_stream_groups(realm)\n\n\ndef get_default_streams_for_realm(realm_id: int) -> List[Stream]:\n    return [\n        default.stream\n        for default in DefaultStream.objects.select_related().filter(realm_id=realm_id)\n    ]\n\n\ndef get_default_subs(user_profile: UserProfile) -> List[Stream]:\n    # Right now default streams are realm-wide.  This wrapper gives us flexibility\n    # to some day further customize how we set up default streams for new users.\n    return get_default_streams_for_realm(user_profile.realm_id)\n\n\n# returns default streams in JSON serializable format\ndef streams_to_dicts_sorted(streams: List[Stream]) -> List[Dict[str, Any]]:\n    return sorted((stream.to_dict() for stream in streams), key=lambda elt: elt[\"name\"])\n\n\ndef default_stream_groups_to_dicts_sorted(groups: List[DefaultStreamGroup]) -> List[Dict[str, Any]]:\n    return sorted((group.to_dict() for group in groups), key=lambda elt: elt[\"name\"])\n\n\ndef do_update_user_activity_interval(\n    user_profile: UserProfile, log_time: datetime.datetime\n) -> None:\n    effective_end = log_time + UserActivityInterval.MIN_INTERVAL_LENGTH\n    # This code isn't perfect, because with various races we might end\n    # up creating two overlapping intervals, but that shouldn't happen\n    # often, and can be corrected for in post-processing\n    try:\n        last = UserActivityInterval.objects.filter(user_profile=user_profile).order_by(\"-end\")[0]\n        # Two intervals overlap iff each interval ends after the other\n        # begins.  In this case, we just extend the old interval to\n        # include the new interval.\n        if log_time <= last.end and effective_end >= last.start:\n            last.end = max(last.end, effective_end)\n            last.start = min(last.start, log_time)\n            last.save(update_fields=[\"start\", \"end\"])\n            return\n    except IndexError:\n        pass\n\n    # Otherwise, the intervals don't overlap, so we should make a new one\n    UserActivityInterval.objects.create(\n        user_profile=user_profile, start=log_time, end=effective_end\n    )\n\n\n@statsd_increment(\"user_activity\")\ndef do_update_user_activity(\n    user_profile_id: int, client_id: int, query: str, count: int, log_time: datetime.datetime\n) -> None:\n    (activity, created) = UserActivity.objects.get_or_create(\n        user_profile_id=user_profile_id,\n        client_id=client_id,\n        query=query,\n        defaults={\"last_visit\": log_time, \"count\": count},\n    )\n\n    if not created:\n        activity.count += count\n        activity.last_visit = log_time\n        activity.save(update_fields=[\"last_visit\", \"count\"])\n\n\ndef send_presence_changed(user_profile: UserProfile, presence: UserPresence) -> None:\n    # Most presence data is sent to clients in the main presence\n    # endpoint in response to the user's own presence; this results\n    # data that is 1-2 minutes stale for who is online.  The flaw with\n    # this plan is when a user comes back online and then immediately\n    # sends a message, recipients may still see that user as offline!\n    # We solve that by sending an immediate presence update clients.\n    #\n    # See https://zulip.readthedocs.io/en/latest/subsystems/presence.html for\n    # internals documentation on presence.\n    user_ids = active_user_ids(user_profile.realm_id)\n    if len(user_ids) > settings.USER_LIMIT_FOR_SENDING_PRESENCE_UPDATE_EVENTS:\n        # These immediate presence generate quadratic work for Tornado\n        # (linear number of users in each event and the frequency of\n        # users coming online grows linearly with userbase too).  In\n        # organizations with thousands of users, this can overload\n        # Tornado, especially if much of the realm comes online at the\n        # same time.\n        #\n        # The utility of these live-presence updates goes down as\n        # organizations get bigger (since one is much less likely to\n        # be paying attention to the sidebar); so beyond a limit, we\n        # stop sending them at all.\n        return\n\n    presence_dict = presence.to_dict()\n    event = dict(\n        type=\"presence\",\n        email=user_profile.email,\n        user_id=user_profile.id,\n        server_timestamp=time.time(),\n        presence={presence_dict[\"client\"]: presence_dict},\n    )\n    send_event(user_profile.realm, event, user_ids)\n\n\ndef consolidate_client(client: Client) -> Client:\n    # The web app reports a client as 'website'\n    # The desktop app reports a client as ZulipDesktop\n    # due to it setting a custom user agent. We want both\n    # to count as web users\n\n    # Alias ZulipDesktop to website\n    if client.name in [\"ZulipDesktop\"]:\n        return get_client(\"website\")\n    else:\n        return client\n\n\n@statsd_increment(\"user_presence\")\ndef do_update_user_presence(\n    user_profile: UserProfile, client: Client, log_time: datetime.datetime, status: int\n) -> None:\n    client = consolidate_client(client)\n\n    defaults = dict(\n        timestamp=log_time,\n        status=status,\n        realm_id=user_profile.realm_id,\n    )\n\n    (presence, created) = UserPresence.objects.get_or_create(\n        user_profile=user_profile,\n        client=client,\n        defaults=defaults,\n    )\n\n    stale_status = (log_time - presence.timestamp) > datetime.timedelta(minutes=1, seconds=10)\n    was_idle = presence.status == UserPresence.IDLE\n    became_online = (status == UserPresence.ACTIVE) and (stale_status or was_idle)\n\n    # If an object was created, it has already been saved.\n    #\n    # We suppress changes from ACTIVE to IDLE before stale_status is reached;\n    # this protects us from the user having two clients open: one active, the\n    # other idle. Without this check, we would constantly toggle their status\n    # between the two states.\n    if not created and stale_status or was_idle or status == presence.status:\n        # The following block attempts to only update the \"status\"\n        # field in the event that it actually changed.  This is\n        # important to avoid flushing the UserPresence cache when the\n        # data it would return to a client hasn't actually changed\n        # (see the UserPresence post_save hook for details).\n        presence.timestamp = log_time\n        update_fields = [\"timestamp\"]\n        if presence.status != status:\n            presence.status = status\n            update_fields.append(\"status\")\n        presence.save(update_fields=update_fields)\n\n    if not user_profile.realm.presence_disabled and (created or became_online):\n        send_presence_changed(user_profile, presence)\n\n\ndef update_user_activity_interval(user_profile: UserProfile, log_time: datetime.datetime) -> None:\n    event = {\"user_profile_id\": user_profile.id, \"time\": datetime_to_timestamp(log_time)}\n    queue_json_publish(\"user_activity_interval\", event)\n\n\ndef update_user_presence(\n    user_profile: UserProfile,\n    client: Client,\n    log_time: datetime.datetime,\n    status: int,\n    new_user_input: bool,\n) -> None:\n    event = {\n        \"user_profile_id\": user_profile.id,\n        \"status\": status,\n        \"time\": datetime_to_timestamp(log_time),\n        \"client\": client.name,\n    }\n\n    queue_json_publish(\"user_presence\", event)\n\n    if new_user_input:\n        update_user_activity_interval(user_profile, log_time)\n\n\ndef do_update_user_status(\n    user_profile: UserProfile,\n    away: Optional[bool],\n    status_text: Optional[str],\n    client_id: int,\n    emoji_name: Optional[str],\n    emoji_code: Optional[str],\n    reaction_type: Optional[str],\n) -> None:\n    if away is None:\n        status = None\n    elif away:\n        status = UserStatus.AWAY\n    else:\n        status = UserStatus.NORMAL\n\n    realm = user_profile.realm\n\n    update_user_status(\n        user_profile_id=user_profile.id,\n        status=status,\n        status_text=status_text,\n        client_id=client_id,\n        emoji_name=emoji_name,\n        emoji_code=emoji_code,\n        reaction_type=reaction_type,\n    )\n\n    event = dict(\n        type=\"user_status\",\n        user_id=user_profile.id,\n    )\n\n    if away is not None:\n        event[\"away\"] = away\n\n    if status_text is not None:\n        event[\"status_text\"] = status_text\n\n    if emoji_name is not None:\n        event[\"emoji_name\"] = emoji_name\n        event[\"emoji_code\"] = emoji_code\n        event[\"reaction_type\"] = reaction_type\n    send_event(realm, event, active_user_ids(realm.id))\n\n\n@dataclass\nclass ReadMessagesEvent:\n    messages: List[int]\n    all: bool\n    type: str = field(default=\"update_message_flags\", init=False)\n    op: str = field(default=\"add\", init=False)\n    operation: str = field(default=\"add\", init=False)\n    flag: str = field(default=\"read\", init=False)\n\n\ndef do_mark_all_as_read(user_profile: UserProfile) -> int:\n    log_statsd_event(\"bankruptcy\")\n\n    # First, we clear mobile push notifications.  This is safer in the\n    # event that the below logic times out and we're killed.\n    all_push_message_ids = (\n        UserMessage.objects.filter(\n            user_profile=user_profile,\n        )\n        .extra(\n            where=[UserMessage.where_active_push_notification()],\n        )\n        .values_list(\"message_id\", flat=True)[0:10000]\n    )\n    do_clear_mobile_push_notifications_for_ids([user_profile.id], all_push_message_ids)\n\n    msgs = UserMessage.objects.filter(user_profile=user_profile).extra(\n        where=[UserMessage.where_unread()],\n    )\n\n    count = msgs.update(\n        flags=F(\"flags\").bitor(UserMessage.flags.read),\n    )\n\n    event = asdict(\n        ReadMessagesEvent(\n            messages=[],  # we don't send messages, since the client reloads anyway\n            all=True,\n        )\n    )\n    event_time = timezone_now()\n\n    send_event(user_profile.realm, event, [user_profile.id])\n\n    do_increment_logging_stat(\n        user_profile, COUNT_STATS[\"messages_read::hour\"], None, event_time, increment=count\n    )\n    do_increment_logging_stat(\n        user_profile,\n        COUNT_STATS[\"messages_read_interactions::hour\"],\n        None,\n        event_time,\n        increment=min(1, count),\n    )\n\n    return count\n\n\ndef do_mark_stream_messages_as_read(\n    user_profile: UserProfile, stream_recipient_id: int, topic_name: Optional[str] = None\n) -> int:\n    log_statsd_event(\"mark_stream_as_read\")\n\n    msgs = UserMessage.objects.filter(\n        user_profile=user_profile,\n    )\n\n    msgs = msgs.filter(message__recipient_id=stream_recipient_id)\n\n    if topic_name:\n        msgs = filter_by_topic_name_via_message(\n            query=msgs,\n            topic_name=topic_name,\n        )\n\n    msgs = msgs.extra(\n        where=[UserMessage.where_unread()],\n    )\n\n    message_ids = list(msgs.values_list(\"message_id\", flat=True))\n\n    count = msgs.update(\n        flags=F(\"flags\").bitor(UserMessage.flags.read),\n    )\n\n    event = asdict(\n        ReadMessagesEvent(\n            messages=message_ids,\n            all=False,\n        )\n    )\n    event_time = timezone_now()\n\n    send_event(user_profile.realm, event, [user_profile.id])\n    do_clear_mobile_push_notifications_for_ids([user_profile.id], message_ids)\n\n    do_increment_logging_stat(\n        user_profile, COUNT_STATS[\"messages_read::hour\"], None, event_time, increment=count\n    )\n    do_increment_logging_stat(\n        user_profile,\n        COUNT_STATS[\"messages_read_interactions::hour\"],\n        None,\n        event_time,\n        increment=min(1, count),\n    )\n    return count\n\n\ndef do_mark_muted_user_messages_as_read(\n    user_profile: UserProfile,\n    muted_user: UserProfile,\n) -> int:\n    messages = UserMessage.objects.filter(\n        user_profile=user_profile, message__sender=muted_user\n    ).extra(where=[UserMessage.where_unread()])\n\n    message_ids = list(messages.values_list(\"message_id\", flat=True))\n\n    count = messages.update(\n        flags=F(\"flags\").bitor(UserMessage.flags.read),\n    )\n\n    event = asdict(\n        ReadMessagesEvent(\n            messages=message_ids,\n            all=False,\n        )\n    )\n    event_time = timezone_now()\n\n    send_event(user_profile.realm, event, [user_profile.id])\n    do_clear_mobile_push_notifications_for_ids([user_profile.id], message_ids)\n\n    do_increment_logging_stat(\n        user_profile, COUNT_STATS[\"messages_read::hour\"], None, event_time, increment=count\n    )\n    do_increment_logging_stat(\n        user_profile,\n        COUNT_STATS[\"messages_read_interactions::hour\"],\n        None,\n        event_time,\n        increment=min(1, count),\n    )\n    return count\n\n\ndef do_update_mobile_push_notification(\n    message: Message,\n    prior_mention_user_ids: Set[int],\n    mentions_user_ids: Set[int],\n    stream_push_user_ids: Set[int],\n) -> None:\n    # Called during the message edit code path to remove mobile push\n    # notifications for users who are no longer mentioned following\n    # the edit.  See #15428 for details.\n    #\n    # A perfect implementation would also support updating the message\n    # in a sent notification if a message was edited to mention a\n    # group rather than a user (or vice versa), though it is likely\n    # not worth the effort to do such a change.\n    if not message.is_stream_message():\n        return\n\n    remove_notify_users = prior_mention_user_ids - mentions_user_ids - stream_push_user_ids\n    do_clear_mobile_push_notifications_for_ids(list(remove_notify_users), [message.id])\n\n\ndef do_clear_mobile_push_notifications_for_ids(\n    user_profile_ids: List[int], message_ids: List[int]\n) -> None:\n    if len(message_ids) == 0:\n        return\n\n    # This function supports clearing notifications for several users\n    # only for the message-edit use case where we'll have a single message_id.\n    assert len(user_profile_ids) == 1 or len(message_ids) == 1\n\n    messages_by_user = defaultdict(list)\n    notifications_to_update = list(\n        UserMessage.objects.filter(\n            message_id__in=message_ids,\n            user_profile_id__in=user_profile_ids,\n        )\n        .extra(\n            where=[UserMessage.where_active_push_notification()],\n        )\n        .values_list(\"user_profile_id\", \"message_id\")\n    )\n\n    for (user_id, message_id) in notifications_to_update:\n        messages_by_user[user_id].append(message_id)\n\n    for (user_profile_id, event_message_ids) in messages_by_user.items():\n        queue_json_publish(\n            \"missedmessage_mobile_notifications\",\n            {\n                \"type\": \"remove\",\n                \"user_profile_id\": user_profile_id,\n                \"message_ids\": event_message_ids,\n            },\n        )\n\n\ndef do_update_message_flags(\n    user_profile: UserProfile, operation: str, flag: str, messages: List[int]\n) -> int:\n    valid_flags = [item for item in UserMessage.flags if item not in UserMessage.NON_API_FLAGS]\n    if flag not in valid_flags:\n        raise JsonableError(_(\"Invalid flag: '{}'\").format(flag))\n    if flag in UserMessage.NON_EDITABLE_FLAGS:\n        raise JsonableError(_(\"Flag not editable: '{}'\").format(flag))\n    if operation not in (\"add\", \"remove\"):\n        raise JsonableError(_(\"Invalid message flag operation: '{}'\").format(operation))\n    flagattr = getattr(UserMessage.flags, flag)\n\n    msgs = UserMessage.objects.filter(user_profile=user_profile, message_id__in=messages)\n    um_message_ids = {um.message_id for um in msgs}\n    historical_message_ids = list(set(messages) - um_message_ids)\n\n    # Users can mutate flags for messages that don't have a UserMessage yet.\n    # First, validate that the user is even allowed to access these message_ids.\n    for message_id in historical_message_ids:\n        access_message(user_profile, message_id)\n\n    # And then create historical UserMessage records.  See the called function for more context.\n    create_historical_user_messages(user_id=user_profile.id, message_ids=historical_message_ids)\n\n    if operation == \"add\":\n        count = msgs.update(flags=F(\"flags\").bitor(flagattr))\n    elif operation == \"remove\":\n        count = msgs.update(flags=F(\"flags\").bitand(~flagattr))\n\n    event = {\n        \"type\": \"update_message_flags\",\n        \"op\": operation,\n        \"operation\": operation,\n        \"flag\": flag,\n        \"messages\": messages,\n        \"all\": False,\n    }\n    send_event(user_profile.realm, event, [user_profile.id])\n\n    if flag == \"read\" and operation == \"add\":\n        event_time = timezone_now()\n        do_clear_mobile_push_notifications_for_ids([user_profile.id], messages)\n\n        do_increment_logging_stat(\n            user_profile, COUNT_STATS[\"messages_read::hour\"], None, event_time, increment=count\n        )\n        do_increment_logging_stat(\n            user_profile,\n            COUNT_STATS[\"messages_read_interactions::hour\"],\n            None,\n            event_time,\n            increment=min(1, count),\n        )\n    return count\n\n\nclass MessageUpdateUserInfoResult(TypedDict):\n    message_user_ids: Set[int]\n    mention_user_ids: Set[int]\n\n\ndef maybe_send_resolve_topic_notifications(\n    *,\n    user_profile: UserProfile,\n    stream: Stream,\n    old_topic: str,\n    new_topic: str,\n    changed_messages: List[Message],\n) -> None:\n    # Note that topics will have already been stripped in check_update_message.\n    #\n    # This logic is designed to treat removing a weird \"\u2714 \u2714\u2714 \"\n    # prefix as unresolving the topic.\n    if old_topic.lstrip(RESOLVED_TOPIC_PREFIX) != new_topic.lstrip(RESOLVED_TOPIC_PREFIX):\n        return\n\n    topic_resolved: bool = new_topic.startswith(RESOLVED_TOPIC_PREFIX) and not old_topic.startswith(\n        RESOLVED_TOPIC_PREFIX\n    )\n    topic_unresolved: bool = old_topic.startswith(\n        RESOLVED_TOPIC_PREFIX\n    ) and not new_topic.startswith(RESOLVED_TOPIC_PREFIX)\n\n    if not topic_resolved and not topic_unresolved:\n        # If there's some other weird topic that does not toggle the\n        # state of \"topic starts with RESOLVED_TOPIC_PREFIX\", we do\n        # nothing. Any other logic could result in cases where we send\n        # these notifications in a non-alternating fashion.\n        #\n        # Note that it is still possible for an individual topic to\n        # have multiple \"This topic was marked as resolved\"\n        # notifications in a row: one can send new messages to the\n        # pre-resolve topic and then resolve the topic created that\n        # way to get multiple in the resolved topic. And then an\n        # administrator can the messages in between. We consider this\n        # to be a fundamental risk of irresponsible message deletion,\n        # not a bug with the \"resolve topics\" feature.\n        return\n\n    # Compute the users who either sent or reacted to messages that\n    # were moved via the \"resolve topic' action. Only those users\n    # should be eligible for this message being managed as unread.\n    affected_participant_ids = (set(message.sender_id for message in changed_messages)) | set(\n        Reaction.objects.filter(message__in=changed_messages).values_list(\n            \"user_profile_id\", flat=True\n        )\n    )\n    sender = get_system_bot(settings.NOTIFICATION_BOT, user_profile.realm_id)\n    user_mention = silent_mention_syntax_for_user(user_profile)\n    with override_language(stream.realm.default_language):\n        if topic_resolved:\n            notification_string = _(\"{user} has marked this topic as resolved.\")\n        elif topic_unresolved:\n            notification_string = _(\"{user} has marked this topic as unresolved.\")\n\n        internal_send_stream_message(\n            sender,\n            stream,\n            new_topic,\n            notification_string.format(\n                user=user_mention,\n            ),\n            limit_unread_user_ids=affected_participant_ids,\n        )\n\n\ndef send_message_moved_breadcrumbs(\n    user_profile: UserProfile,\n    old_stream: Stream,\n    old_topic: str,\n    old_thread_notification_string: Optional[str],\n    new_stream: Stream,\n    new_topic: Optional[str],\n    new_thread_notification_string: Optional[str],\n    changed_messages_count: int,\n) -> None:\n    # Since moving content between streams is highly disruptive,\n    # it's worth adding a couple tombstone messages showing what\n    # happened.\n    sender = get_system_bot(settings.NOTIFICATION_BOT, old_stream.realm_id)\n\n    if new_topic is None:\n        new_topic = old_topic\n\n    user_mention = silent_mention_syntax_for_user(user_profile)\n    old_topic_link = f\"#**{old_stream.name}>{old_topic}**\"\n    new_topic_link = f\"#**{new_stream.name}>{new_topic}**\"\n\n    if new_thread_notification_string is not None:\n        with override_language(new_stream.realm.default_language):\n            internal_send_stream_message(\n                sender,\n                new_stream,\n                new_topic,\n                new_thread_notification_string.format(\n                    old_location=old_topic_link,\n                    user=user_mention,\n                    changed_messages_count=changed_messages_count,\n                ),\n            )\n\n    if old_thread_notification_string is not None:\n        with override_language(old_stream.realm.default_language):\n            # Send a notification to the old stream that the topic was moved.\n            internal_send_stream_message(\n                sender,\n                old_stream,\n                old_topic,\n                old_thread_notification_string.format(\n                    user=user_mention,\n                    new_location=new_topic_link,\n                    changed_messages_count=changed_messages_count,\n                ),\n            )\n\n\ndef get_user_info_for_message_updates(message_id: int) -> MessageUpdateUserInfoResult:\n\n    # We exclude UserMessage.flags.historical rows since those\n    # users did not receive the message originally, and thus\n    # probably are not relevant for reprocessed alert_words,\n    # mentions and similar rendering features.  This may be a\n    # decision we change in the future.\n    query = UserMessage.objects.filter(\n        message=message_id,\n        flags=~UserMessage.flags.historical,\n    ).values(\"user_profile_id\", \"flags\")\n    rows = list(query)\n\n    message_user_ids = {row[\"user_profile_id\"] for row in rows}\n\n    mask = UserMessage.flags.mentioned | UserMessage.flags.wildcard_mentioned\n\n    mention_user_ids = {row[\"user_profile_id\"] for row in rows if int(row[\"flags\"]) & mask}\n\n    return dict(\n        message_user_ids=message_user_ids,\n        mention_user_ids=mention_user_ids,\n    )\n\n\ndef update_user_message_flags(\n    rendering_result: MessageRenderingResult, ums: Iterable[UserMessage]\n) -> None:\n    wildcard = rendering_result.mentions_wildcard\n    mentioned_ids = rendering_result.mentions_user_ids\n    ids_with_alert_words = rendering_result.user_ids_with_alert_words\n    changed_ums: Set[UserMessage] = set()\n\n    def update_flag(um: UserMessage, should_set: bool, flag: int) -> None:\n        if should_set:\n            if not (um.flags & flag):\n                um.flags |= flag\n                changed_ums.add(um)\n        else:\n            if um.flags & flag:\n                um.flags &= ~flag\n                changed_ums.add(um)\n\n    for um in ums:\n        has_alert_word = um.user_profile_id in ids_with_alert_words\n        update_flag(um, has_alert_word, UserMessage.flags.has_alert_word)\n\n        mentioned = um.user_profile_id in mentioned_ids\n        update_flag(um, mentioned, UserMessage.flags.mentioned)\n\n        update_flag(um, wildcard, UserMessage.flags.wildcard_mentioned)\n\n    for um in changed_ums:\n        um.save(update_fields=[\"flags\"])\n\n\ndef update_to_dict_cache(\n    changed_messages: List[Message], realm_id: Optional[int] = None\n) -> List[int]:\n    \"\"\"Updates the message as stored in the to_dict cache (for serving\n    messages).\"\"\"\n    items_for_remote_cache = {}\n    message_ids = []\n    changed_messages_to_dict = MessageDict.to_dict_uncached(changed_messages, realm_id)\n    for msg_id, msg in changed_messages_to_dict.items():\n        message_ids.append(msg_id)\n        key = to_dict_cache_key_id(msg_id)\n        items_for_remote_cache[key] = (msg,)\n\n    cache_set_many(items_for_remote_cache)\n    return message_ids\n\n\ndef do_update_embedded_data(\n    user_profile: UserProfile,\n    message: Message,\n    content: Optional[str],\n    rendering_result: MessageRenderingResult,\n) -> None:\n    timestamp = timezone_now()\n    event: Dict[str, Any] = {\n        \"type\": \"update_message\",\n        \"user_id\": None,\n        \"edit_timestamp\": datetime_to_timestamp(timestamp),\n        \"message_id\": message.id,\n        \"rendering_only\": True,\n    }\n    changed_messages = [message]\n    rendered_content: Optional[str] = None\n\n    ums = UserMessage.objects.filter(message=message.id)\n\n    if content is not None:\n        update_user_message_flags(rendering_result, ums)\n        rendered_content = rendering_result.rendered_content\n        message.rendered_content = rendered_content\n        message.rendered_content_version = markdown_version\n        event[\"content\"] = content\n        event[\"rendered_content\"] = rendered_content\n\n    message.save(update_fields=[\"content\", \"rendered_content\"])\n\n    event[\"message_ids\"] = update_to_dict_cache(changed_messages)\n\n    def user_info(um: UserMessage) -> Dict[str, Any]:\n        return {\n            \"id\": um.user_profile_id,\n            \"flags\": um.flags_list(),\n        }\n\n    send_event(user_profile.realm, event, list(map(user_info, ums)))\n\n\nclass DeleteMessagesEvent(TypedDict, total=False):\n    type: str\n    message_ids: List[int]\n    message_type: str\n    topic: str\n    stream_id: int\n\n\n# We use transaction.atomic to support select_for_update in the attachment codepath.\n@transaction.atomic(savepoint=False)\ndef do_update_message(\n    user_profile: UserProfile,\n    target_message: Message,\n    new_stream: Optional[Stream],\n    topic_name: Optional[str],\n    propagate_mode: str,\n    send_notification_to_old_thread: bool,\n    send_notification_to_new_thread: bool,\n    content: Optional[str],\n    rendering_result: Optional[MessageRenderingResult],\n    prior_mention_user_ids: Set[int],\n    mention_data: Optional[MentionData] = None,\n) -> int:\n    \"\"\"\n    The main function for message editing.  A message edit event can\n    modify:\n    * the message's content (in which case the caller will have\n      set both content and rendered_content),\n    * the topic, in which case the caller will have set topic_name\n    * or both message's content and the topic\n    * or stream and/or topic, in which case the caller will have set\n        new_stream and/or topic_name.\n\n    With topic edits, propagate_mode determines whether other message\n    also have their topics edited.\n    \"\"\"\n    timestamp = timezone_now()\n    target_message.last_edit_time = timestamp\n\n    event: Dict[str, Any] = {\n        \"type\": \"update_message\",\n        \"user_id\": user_profile.id,\n        \"edit_timestamp\": datetime_to_timestamp(timestamp),\n        \"message_id\": target_message.id,\n        \"rendering_only\": False,\n    }\n\n    edit_history_event: EditHistoryEvent = {\n        \"user_id\": user_profile.id,\n        \"timestamp\": event[\"edit_timestamp\"],\n    }\n\n    changed_messages = [target_message]\n\n    realm = user_profile.realm\n\n    stream_being_edited = None\n    if target_message.is_stream_message():\n        stream_id = target_message.recipient.type_id\n        stream_being_edited = get_stream_by_id_in_realm(stream_id, realm)\n        event[\"stream_name\"] = stream_being_edited.name\n        event[\"stream_id\"] = stream_being_edited.id\n\n    ums = UserMessage.objects.filter(message=target_message.id)\n\n    if content is not None:\n        assert rendering_result is not None\n\n        # mention_data is required if there's a content edit.\n        assert mention_data is not None\n\n        # add data from group mentions to mentions_user_ids.\n        for group_id in rendering_result.mentions_user_group_ids:\n            members = mention_data.get_group_members(group_id)\n            rendering_result.mentions_user_ids.update(members)\n\n        update_user_message_flags(rendering_result, ums)\n\n        # One could imagine checking realm.allow_edit_history here and\n        # modifying the events based on that setting, but doing so\n        # doesn't really make sense.  We need to send the edit event\n        # to clients regardless, and a client already had access to\n        # the original/pre-edit content of the message anyway.  That\n        # setting must be enforced on the client side, and making a\n        # change here simply complicates the logic for clients parsing\n        # edit history events.\n        event[\"orig_content\"] = target_message.content\n        event[\"orig_rendered_content\"] = target_message.rendered_content\n        edit_history_event[\"prev_content\"] = target_message.content\n        edit_history_event[\"prev_rendered_content\"] = target_message.rendered_content\n        edit_history_event[\n            \"prev_rendered_content_version\"\n        ] = target_message.rendered_content_version\n        target_message.content = content\n        target_message.rendered_content = rendering_result.rendered_content\n        target_message.rendered_content_version = markdown_version\n        event[\"content\"] = content\n        event[\"rendered_content\"] = rendering_result.rendered_content\n        event[\"prev_rendered_content_version\"] = target_message.rendered_content_version\n        event[\"is_me_message\"] = Message.is_status_message(\n            content, rendering_result.rendered_content\n        )\n\n        # target_message.has_image and target_message.has_link will have been\n        # already updated by Markdown rendering in the caller.\n        target_message.has_attachment = check_attachment_reference_change(\n            target_message, rendering_result\n        )\n\n        if target_message.is_stream_message():\n            if topic_name is not None:\n                new_topic_name = topic_name\n            else:\n                new_topic_name = target_message.topic_name()\n\n            stream_topic: Optional[StreamTopicTarget] = StreamTopicTarget(\n                stream_id=stream_id,\n                topic_name=new_topic_name,\n            )\n        else:\n            stream_topic = None\n\n        info = get_recipient_info(\n            realm_id=realm.id,\n            recipient=target_message.recipient,\n            sender_id=target_message.sender_id,\n            stream_topic=stream_topic,\n            possible_wildcard_mention=mention_data.message_has_wildcards(),\n        )\n\n        event[\"online_push_user_ids\"] = list(info[\"online_push_user_ids\"])\n        event[\"pm_mention_push_disabled_user_ids\"] = list(info[\"pm_mention_push_disabled_user_ids\"])\n        event[\"pm_mention_email_disabled_user_ids\"] = list(\n            info[\"pm_mention_email_disabled_user_ids\"]\n        )\n        event[\"stream_push_user_ids\"] = list(info[\"stream_push_user_ids\"])\n        event[\"stream_email_user_ids\"] = list(info[\"stream_email_user_ids\"])\n        event[\"muted_sender_user_ids\"] = list(info[\"muted_sender_user_ids\"])\n        event[\"prior_mention_user_ids\"] = list(prior_mention_user_ids)\n        event[\"presence_idle_user_ids\"] = filter_presence_idle_user_ids(info[\"active_user_ids\"])\n        event[\"all_bot_user_ids\"] = list(info[\"all_bot_user_ids\"])\n        if rendering_result.mentions_wildcard:\n            event[\"wildcard_mention_user_ids\"] = list(info[\"wildcard_mention_user_ids\"])\n        else:\n            event[\"wildcard_mention_user_ids\"] = []\n\n        do_update_mobile_push_notification(\n            target_message,\n            prior_mention_user_ids,\n            rendering_result.mentions_user_ids,\n            info[\"stream_push_user_ids\"],\n        )\n\n    if topic_name is not None or new_stream is not None:\n        orig_topic_name = target_message.topic_name()\n        event[\"propagate_mode\"] = propagate_mode\n\n    if new_stream is not None:\n        assert content is None\n        assert target_message.is_stream_message()\n        assert stream_being_edited is not None\n\n        edit_history_event[\"prev_stream\"] = stream_being_edited.id\n        edit_history_event[\"stream\"] = new_stream.id\n        event[ORIG_TOPIC] = orig_topic_name\n        target_message.recipient_id = new_stream.recipient_id\n\n        event[\"new_stream_id\"] = new_stream.id\n        event[\"propagate_mode\"] = propagate_mode\n\n        # When messages are moved from one stream to another, some\n        # users may lose access to those messages, including guest\n        # users and users not subscribed to the new stream (if it is a\n        # private stream).  For those users, their experience is as\n        # though the messages were deleted, and we should send a\n        # delete_message event to them instead.\n\n        subs_to_old_stream = get_active_subscriptions_for_stream_id(\n            stream_id, include_deactivated_users=True\n        ).select_related(\"user_profile\")\n        subs_to_new_stream = list(\n            get_active_subscriptions_for_stream_id(\n                new_stream.id, include_deactivated_users=True\n            ).select_related(\"user_profile\")\n        )\n\n        old_stream_sub_ids = [user.user_profile_id for user in subs_to_old_stream]\n        new_stream_sub_ids = [user.user_profile_id for user in subs_to_new_stream]\n\n        # Get users who aren't subscribed to the new_stream.\n        subs_losing_usermessages = [\n            sub for sub in subs_to_old_stream if sub.user_profile_id not in new_stream_sub_ids\n        ]\n        # Users who can longer access the message without some action\n        # from administrators.\n        subs_losing_access = [\n            sub\n            for sub in subs_losing_usermessages\n            if sub.user_profile.is_guest or not new_stream.is_public()\n        ]\n        ums = ums.exclude(\n            user_profile_id__in=[sub.user_profile_id for sub in subs_losing_usermessages]\n        )\n\n        subs_gaining_usermessages = []\n        if not new_stream.is_history_public_to_subscribers():\n            # For private streams, with history not public to subscribers,\n            # We find out users who are not present in the msgs' old stream\n            # and create new UserMessage for these users so that they can\n            # access this message.\n            subs_gaining_usermessages += [\n                user_id for user_id in new_stream_sub_ids if user_id not in old_stream_sub_ids\n            ]\n\n    if topic_name is not None:\n        topic_name = truncate_topic(topic_name)\n        target_message.set_topic_name(topic_name)\n\n        # These fields have legacy field names.\n        event[ORIG_TOPIC] = orig_topic_name\n        event[TOPIC_NAME] = topic_name\n        event[TOPIC_LINKS] = topic_links(target_message.sender.realm_id, topic_name)\n        edit_history_event[\"prev_topic\"] = orig_topic_name\n        edit_history_event[\"topic\"] = topic_name\n\n    update_edit_history(target_message, timestamp, edit_history_event)\n\n    delete_event_notify_user_ids: List[int] = []\n    if propagate_mode in [\"change_later\", \"change_all\"]:\n        assert topic_name is not None or new_stream is not None\n        assert stream_being_edited is not None\n\n        # Other messages should only get topic/stream fields in their edit history.\n        topic_only_edit_history_event: EditHistoryEvent = {\n            \"user_id\": edit_history_event[\"user_id\"],\n            \"timestamp\": edit_history_event[\"timestamp\"],\n        }\n        if topic_name is not None:\n            topic_only_edit_history_event[\"prev_topic\"] = edit_history_event[\"prev_topic\"]\n            topic_only_edit_history_event[\"topic\"] = edit_history_event[\"topic\"]\n        if new_stream is not None:\n            topic_only_edit_history_event[\"prev_stream\"] = edit_history_event[\"prev_stream\"]\n            topic_only_edit_history_event[\"stream\"] = edit_history_event[\"stream\"]\n\n        messages_list = update_messages_for_topic_edit(\n            acting_user=user_profile,\n            edited_message=target_message,\n            propagate_mode=propagate_mode,\n            orig_topic_name=orig_topic_name,\n            topic_name=topic_name,\n            new_stream=new_stream,\n            old_stream=stream_being_edited,\n            edit_history_event=topic_only_edit_history_event,\n            last_edit_time=timestamp,\n        )\n        changed_messages += messages_list\n\n        if new_stream is not None:\n            assert stream_being_edited is not None\n            changed_message_ids = [msg.id for msg in changed_messages]\n\n            if subs_gaining_usermessages:\n                ums_to_create = []\n                for message_id in changed_message_ids:\n                    for user_profile_id in subs_gaining_usermessages:\n                        # The fact that the user didn't have a UserMessage originally means we can infer that the user\n                        # was not mentioned in the original message (even if mention syntax was present, it would not\n                        # take effect for a user who was not subscribed). If we were editing the message's content, we\n                        # would rerender the message and then use the new stream's data to determine whether this is\n                        # a mention of a subscriber; but as we are not doing so, we choose to preserve the \"was this\n                        # mention syntax an actual mention\" decision made during the original rendering for implementation\n                        # simplicity. As a result, the only flag to consider applying here is read.\n                        um = UserMessageLite(\n                            user_profile_id=user_profile_id,\n                            message_id=message_id,\n                            flags=UserMessage.flags.read,\n                        )\n                        ums_to_create.append(um)\n                bulk_insert_ums(ums_to_create)\n\n            # Delete UserMessage objects for users who will no\n            # longer have access to these messages.  Note: This could be\n            # very expensive, since it's N guest users x M messages.\n            UserMessage.objects.filter(\n                user_profile_id__in=[sub.user_profile_id for sub in subs_losing_usermessages],\n                message_id__in=changed_message_ids,\n            ).delete()\n\n            delete_event: DeleteMessagesEvent = {\n                \"type\": \"delete_message\",\n                \"message_ids\": changed_message_ids,\n                \"message_type\": \"stream\",\n                \"stream_id\": stream_being_edited.id,\n                \"topic\": orig_topic_name,\n            }\n            delete_event_notify_user_ids = [sub.user_profile_id for sub in subs_losing_access]\n            send_event(user_profile.realm, delete_event, delete_event_notify_user_ids)\n\n    # This does message.save(update_fields=[...])\n    save_message_for_edit_use_case(message=target_message)\n\n    realm_id: Optional[int] = None\n    if stream_being_edited is not None:\n        realm_id = stream_being_edited.realm_id\n\n    event[\"message_ids\"] = update_to_dict_cache(changed_messages, realm_id)\n\n    def user_info(um: UserMessage) -> Dict[str, Any]:\n        return {\n            \"id\": um.user_profile_id,\n            \"flags\": um.flags_list(),\n        }\n\n    # The following blocks arranges that users who are subscribed to a\n    # stream and can see history from before they subscribed get\n    # live-update when old messages are edited (e.g. if the user does\n    # a topic edit themself).\n    #\n    # We still don't send an update event to users who are not\n    # subscribed to this stream and don't have a UserMessage row. This\n    # means if a non-subscriber is viewing the narrow, they won't get\n    # a real-time updates. This is a balance between sending\n    # message-edit notifications for every public stream to every user\n    # in the organization (too expansive, and also not what we do for\n    # newly sent messages anyway) and having magical live-updates\n    # where possible.\n    users_to_be_notified = list(map(user_info, ums))\n    if stream_being_edited is not None:\n        if stream_being_edited.is_history_public_to_subscribers:\n            subscriptions = get_active_subscriptions_for_stream_id(\n                stream_id, include_deactivated_users=False\n            )\n            # We exclude long-term idle users, since they by\n            # definition have no active clients.\n            subscriptions = subscriptions.exclude(user_profile__long_term_idle=True)\n            # Remove duplicates by excluding the id of users already\n            # in users_to_be_notified list.  This is the case where a\n            # user both has a UserMessage row and is a current\n            # Subscriber\n            subscriptions = subscriptions.exclude(\n                user_profile_id__in=[um.user_profile_id for um in ums]\n            )\n\n            if new_stream is not None:\n                assert delete_event_notify_user_ids is not None\n                subscriptions = subscriptions.exclude(\n                    user_profile_id__in=delete_event_notify_user_ids\n                )\n\n            # All users that are subscribed to the stream must be\n            # notified when a message is edited\n            subscriber_ids = set(subscriptions.values_list(\"user_profile_id\", flat=True))\n\n            if new_stream is not None:\n                # TODO: Guest users don't see the new moved topic\n                # unless breadcrumb message for new stream is\n                # enabled. Excluding these users from receiving this\n                # event helps us avoid a error traceback for our\n                # clients. We should figure out a way to inform the\n                # guest users of this new topic if sending a 'message'\n                # event for these messages is not an option.\n                #\n                # Don't send this event to guest subs who are not\n                # subscribers of the old stream but are subscribed to\n                # the new stream; clients will be confused.\n                old_stream_unsubbed_guests = [\n                    sub\n                    for sub in subs_to_new_stream\n                    if sub.user_profile.is_guest and sub.user_profile_id not in subscriber_ids\n                ]\n                subscriptions = subscriptions.exclude(\n                    user_profile_id__in=[sub.user_profile_id for sub in old_stream_unsubbed_guests]\n                )\n                subscriber_ids = set(subscriptions.values_list(\"user_profile_id\", flat=True))\n\n            users_to_be_notified += list(map(subscriber_info, sorted(list(subscriber_ids))))\n\n    send_event(user_profile.realm, event, users_to_be_notified)\n\n    if len(changed_messages) > 0 and new_stream is not None and stream_being_edited is not None:\n        # Notify users that the topic was moved.\n        changed_messages_count = len(changed_messages)\n\n        if propagate_mode == \"change_all\":\n            moved_all_visible_messages = True\n        else:\n            # With other propagate modes, if the user in fact moved\n            # all messages in the stream, we want to explain it was a\n            # full-topic move.\n            #\n            # For security model reasons, we don't want to allow a\n            # user to take any action that would leak information\n            # about older messages they cannot access (E.g. the only\n            # remaining messages are in a stream without shared\n            # history). The bulk_access_messages call below addresses\n            # that concern.\n            #\n            # bulk_access_messages is inefficient for this task, since\n            # we just want to do the exists() version of this\n            # query. But it's nice to reuse code, and this bulk\n            # operation is likely cheaper than a `GET /messages`\n            # unless the topic has thousands of messages of history.\n            unmoved_messages = messages_for_topic(\n                stream_being_edited.recipient_id,\n                orig_topic_name,\n            )\n            visible_unmoved_messages = bulk_access_messages(\n                user_profile, unmoved_messages, stream=stream_being_edited\n            )\n            moved_all_visible_messages = len(visible_unmoved_messages) == 0\n\n        old_thread_notification_string = None\n        if send_notification_to_old_thread:\n            if moved_all_visible_messages:\n                old_thread_notification_string = gettext_lazy(\n                    \"This topic was moved to {new_location} by {user}.\"\n                )\n            elif changed_messages_count == 1:\n                old_thread_notification_string = gettext_lazy(\n                    \"A message was moved from this topic to {new_location} by {user}.\"\n                )\n            else:\n                old_thread_notification_string = gettext_lazy(\n                    \"{changed_messages_count} messages were moved from this topic to {new_location} by {user}.\"\n                )\n\n        new_thread_notification_string = None\n        if send_notification_to_new_thread:\n            if moved_all_visible_messages:\n                new_thread_notification_string = gettext_lazy(\n                    \"This topic was moved here from {old_location} by {user}.\"\n                )\n            elif changed_messages_count == 1:\n                new_thread_notification_string = gettext_lazy(\n                    \"A message was moved here from {old_location} by {user}.\"\n                )\n            else:\n                new_thread_notification_string = gettext_lazy(\n                    \"{changed_messages_count} messages were moved here from {old_location} by {user}.\"\n                )\n\n        send_message_moved_breadcrumbs(\n            user_profile,\n            stream_being_edited,\n            orig_topic_name,\n            old_thread_notification_string,\n            new_stream,\n            topic_name,\n            new_thread_notification_string,\n            changed_messages_count,\n        )\n\n    if (\n        topic_name is not None\n        and new_stream is None\n        and content is None\n        and len(changed_messages) > 0\n    ):\n        assert stream_being_edited is not None\n        maybe_send_resolve_topic_notifications(\n            user_profile=user_profile,\n            stream=stream_being_edited,\n            old_topic=orig_topic_name,\n            new_topic=topic_name,\n            changed_messages=changed_messages,\n        )\n\n    return len(changed_messages)\n\n\ndef do_delete_messages(realm: Realm, messages: Iterable[Message]) -> None:\n    # messages in delete_message event belong to the same topic\n    # or is a single private message, as any other behaviour is not possible with\n    # the current callers to this method.\n    messages = list(messages)\n    message_ids = [message.id for message in messages]\n    if not message_ids:\n        return\n\n    event: DeleteMessagesEvent = {\n        \"type\": \"delete_message\",\n        \"message_ids\": message_ids,\n    }\n\n    sample_message = messages[0]\n    message_type = \"stream\"\n    users_to_notify = []\n    if not sample_message.is_stream_message():\n        assert len(messages) == 1\n        message_type = \"private\"\n        ums = UserMessage.objects.filter(message_id__in=message_ids)\n        users_to_notify = [um.user_profile_id for um in ums]\n        archiving_chunk_size = retention.MESSAGE_BATCH_SIZE\n\n    if message_type == \"stream\":\n        stream_id = sample_message.recipient.type_id\n        event[\"stream_id\"] = stream_id\n        event[\"topic\"] = sample_message.topic_name()\n        subscriptions = get_active_subscriptions_for_stream_id(\n            stream_id, include_deactivated_users=False\n        )\n        # We exclude long-term idle users, since they by definition have no active clients.\n        subscriptions = subscriptions.exclude(user_profile__long_term_idle=True)\n        users_to_notify = list(subscriptions.values_list(\"user_profile_id\", flat=True))\n        archiving_chunk_size = retention.STREAM_MESSAGE_BATCH_SIZE\n\n    move_messages_to_archive(message_ids, realm=realm, chunk_size=archiving_chunk_size)\n\n    event[\"message_type\"] = message_type\n    transaction.on_commit(lambda: send_event(realm, event, users_to_notify))\n\n\ndef do_delete_messages_by_sender(user: UserProfile) -> None:\n    message_ids = list(\n        Message.objects.filter(sender=user).values_list(\"id\", flat=True).order_by(\"id\")\n    )\n    if message_ids:\n        move_messages_to_archive(message_ids, chunk_size=retention.STREAM_MESSAGE_BATCH_SIZE)\n\n\n# In general, it's better to avoid using .values() because it makes\n# the code pretty ugly, but in this case, it has significant\n# performance impact for loading / for users with large numbers of\n# subscriptions, so it's worth optimizing.\ndef gather_subscriptions_helper(\n    user_profile: UserProfile,\n    include_subscribers: bool = True,\n) -> SubscriptionInfo:\n    realm = user_profile.realm\n    all_streams: QuerySet[RawStreamDict] = get_active_streams(realm).values(\n        *Stream.API_FIELDS,\n        # The realm_id and recipient_id are generally not needed in the API.\n        \"realm_id\",\n        \"recipient_id\",\n        # email_token isn't public to some users with access to\n        # the stream, so doesn't belong in API_FIELDS.\n        \"email_token\",\n    )\n    recip_id_to_stream_id: Dict[int, int] = {\n        stream[\"recipient_id\"]: stream[\"id\"] for stream in all_streams\n    }\n    all_streams_map: Dict[int, RawStreamDict] = {stream[\"id\"]: stream for stream in all_streams}\n\n    sub_dicts_query: Iterable[RawSubscriptionDict] = (\n        get_stream_subscriptions_for_user(user_profile)\n        .values(\n            *Subscription.API_FIELDS,\n            \"recipient_id\",\n            \"active\",\n        )\n        .order_by(\"recipient_id\")\n    )\n\n    # We only care about subscriptions for active streams.\n    sub_dicts: List[RawSubscriptionDict] = [\n        sub_dict\n        for sub_dict in sub_dicts_query\n        if recip_id_to_stream_id.get(sub_dict[\"recipient_id\"])\n    ]\n\n    def get_stream_id(sub_dict: RawSubscriptionDict) -> int:\n        return recip_id_to_stream_id[sub_dict[\"recipient_id\"]]\n\n    traffic_stream_ids = {get_stream_id(sub_dict) for sub_dict in sub_dicts}\n    recent_traffic = get_streams_traffic(stream_ids=traffic_stream_ids)\n\n    # Okay, now we finally get to populating our main results, which\n    # will be these three lists.\n    subscribed: List[SubscriptionStreamDict] = []\n    unsubscribed: List[SubscriptionStreamDict] = []\n    never_subscribed: List[NeverSubscribedStreamDict] = []\n\n    sub_unsub_stream_ids = set()\n    for sub_dict in sub_dicts:\n        stream_id = get_stream_id(sub_dict)\n        sub_unsub_stream_ids.add(stream_id)\n        raw_stream_dict = all_streams_map[stream_id]\n\n        stream_dict = build_stream_dict_for_sub(\n            user=user_profile,\n            sub_dict=sub_dict,\n            raw_stream_dict=raw_stream_dict,\n            recent_traffic=recent_traffic,\n        )\n\n        # is_active is represented in this structure by which list we include it in.\n        is_active = sub_dict[\"active\"]\n        if is_active:\n            subscribed.append(stream_dict)\n        else:\n            unsubscribed.append(stream_dict)\n\n    if user_profile.can_access_public_streams():\n        never_subscribed_stream_ids = set(all_streams_map) - sub_unsub_stream_ids\n    else:\n        web_public_stream_ids = {stream[\"id\"] for stream in all_streams if stream[\"is_web_public\"]}\n        never_subscribed_stream_ids = web_public_stream_ids - sub_unsub_stream_ids\n\n    never_subscribed_streams = [\n        all_streams_map[stream_id] for stream_id in never_subscribed_stream_ids\n    ]\n\n    for raw_stream_dict in never_subscribed_streams:\n        is_public = not raw_stream_dict[\"invite_only\"]\n        if is_public or user_profile.is_realm_admin:\n            slim_stream_dict = build_stream_dict_for_never_sub(\n                raw_stream_dict=raw_stream_dict, recent_traffic=recent_traffic\n            )\n\n            never_subscribed.append(slim_stream_dict)\n\n    if include_subscribers:\n        # The highly optimized bulk_get_subscriber_user_ids wants to know which\n        # streams we are subscribed to, for validation purposes, and it uses that\n        # info to know if it's allowed to find OTHER subscribers.\n        subscribed_stream_ids = {\n            get_stream_id(sub_dict) for sub_dict in sub_dicts if sub_dict[\"active\"]\n        }\n\n        subscriber_map = bulk_get_subscriber_user_ids(\n            all_streams,\n            user_profile,\n            subscribed_stream_ids,\n        )\n\n        for lst in [subscribed, unsubscribed]:\n            for stream_dict in lst:\n                assert isinstance(stream_dict[\"stream_id\"], int)\n                stream_id = stream_dict[\"stream_id\"]\n                stream_dict[\"subscribers\"] = subscriber_map[stream_id]\n\n        for slim_stream_dict in never_subscribed:\n            assert isinstance(slim_stream_dict[\"stream_id\"], int)\n            stream_id = slim_stream_dict[\"stream_id\"]\n            slim_stream_dict[\"subscribers\"] = subscriber_map[stream_id]\n\n    subscribed.sort(key=lambda x: x[\"name\"])\n    unsubscribed.sort(key=lambda x: x[\"name\"])\n    never_subscribed.sort(key=lambda x: x[\"name\"])\n\n    return SubscriptionInfo(\n        subscriptions=subscribed,\n        unsubscribed=unsubscribed,\n        never_subscribed=never_subscribed,\n    )\n\n\ndef gather_subscriptions(\n    user_profile: UserProfile,\n    include_subscribers: bool = False,\n) -> Tuple[List[SubscriptionStreamDict], List[SubscriptionStreamDict]]:\n    helper_result = gather_subscriptions_helper(\n        user_profile,\n        include_subscribers=include_subscribers,\n    )\n    subscribed = helper_result.subscriptions\n    unsubscribed = helper_result.unsubscribed\n    return (subscribed, unsubscribed)\n\n\nclass ActivePresenceIdleUserData(TypedDict):\n    alerted: bool\n    notifications_data: UserMessageNotificationsData\n\n\ndef get_active_presence_idle_user_ids(\n    realm: Realm,\n    sender_id: int,\n    active_users_data: List[ActivePresenceIdleUserData],\n) -> List[int]:\n    \"\"\"\n    Given a list of active_user_ids, we build up a subset\n    of those users who fit these criteria:\n\n        * They are likely to need notifications.\n        * They are no longer \"present\" according to the\n          UserPresence table.\n    \"\"\"\n\n    if realm.presence_disabled:\n        return []\n\n    user_ids = set()\n    for user_data in active_users_data:\n        user_notifications_data: UserMessageNotificationsData = user_data[\"notifications_data\"]\n        alerted = user_data[\"alerted\"]\n\n        # We only need to know the presence idle state for a user if this message would be notifiable\n        # for them if they were indeed idle. Only including those users in the calculation below is a\n        # very important optimization for open communities with many inactive users.\n        if user_notifications_data.is_notifiable(sender_id, idle=True) or alerted:\n            user_ids.add(user_notifications_data.user_id)\n\n    return filter_presence_idle_user_ids(user_ids)\n\n\ndef filter_presence_idle_user_ids(user_ids: Set[int]) -> List[int]:\n    # Given a set of user IDs (the recipients of a message), accesses\n    # the UserPresence table to determine which of these users are\n    # currently idle and should potentially get email notifications\n    # (and push notifications with with\n    # user_profile.enable_online_push_notifications=False).\n    #\n    # We exclude any presence data from ZulipMobile for the purpose of\n    # triggering these notifications; the mobile app can more\n    # effectively do its own client-side filtering of notification\n    # sounds/etc. for the case that the user is actively doing a PM\n    # conversation in the app.\n\n    if not user_ids:\n        return []\n\n    # Matches presence.js constant\n    OFFLINE_THRESHOLD_SECS = 140\n\n    recent = timezone_now() - datetime.timedelta(seconds=OFFLINE_THRESHOLD_SECS)\n    rows = (\n        UserPresence.objects.filter(\n            user_profile_id__in=user_ids,\n            status=UserPresence.ACTIVE,\n            timestamp__gte=recent,\n        )\n        .exclude(client__name=\"ZulipMobile\")\n        .distinct(\"user_profile_id\")\n        .values(\"user_profile_id\")\n    )\n    active_user_ids = {row[\"user_profile_id\"] for row in rows}\n    idle_user_ids = user_ids - active_user_ids\n    return sorted(idle_user_ids)\n\n\ndef do_send_confirmation_email(\n    invitee: PreregistrationUser,\n    referrer: UserProfile,\n    email_language: str,\n    invite_expires_in_days: Union[Optional[int], UnspecifiedValue] = UnspecifiedValue(),\n) -> str:\n    \"\"\"\n    Send the confirmation/welcome e-mail to an invited user.\n    \"\"\"\n    activation_url = create_confirmation_link(\n        invitee, Confirmation.INVITATION, validity_in_days=invite_expires_in_days\n    )\n    context = {\n        \"referrer_full_name\": referrer.full_name,\n        \"referrer_email\": referrer.delivery_email,\n        \"activate_url\": activation_url,\n        \"referrer_realm_name\": referrer.realm.name,\n    }\n    send_email(\n        \"zerver/emails/invitation\",\n        to_emails=[invitee.email],\n        from_address=FromAddress.tokenized_no_reply_address(),\n        language=email_language,\n        context=context,\n        realm=referrer.realm,\n    )\n    return activation_url\n\n\ndef email_not_system_bot(email: str) -> None:\n    if is_cross_realm_bot_email(email):\n        msg = email_reserved_for_system_bots_error(email)\n        code = msg\n        raise ValidationError(\n            msg,\n            code=code,\n            params=dict(deactivated=False),\n        )\n\n\ndef estimate_recent_invites(realms: Collection[Realm], *, days: int) -> int:\n    \"\"\"An upper bound on the number of invites sent in the last `days` days\"\"\"\n    recent_invites = RealmCount.objects.filter(\n        realm__in=realms,\n        property=\"invites_sent::day\",\n        end_time__gte=timezone_now() - datetime.timedelta(days=days),\n    ).aggregate(Sum(\"value\"))[\"value__sum\"]\n    if recent_invites is None:\n        return 0\n    return recent_invites\n\n\ndef check_invite_limit(realm: Realm, num_invitees: int) -> None:\n    \"\"\"Discourage using invitation emails as a vector for carrying spam.\"\"\"\n    msg = _(\n        \"To protect users, Zulip limits the number of invitations you can send in one day. Because you have reached the limit, no invitations were sent.\"\n    )\n    if not settings.OPEN_REALM_CREATION:\n        return\n\n    recent_invites = estimate_recent_invites([realm], days=1)\n    if num_invitees + recent_invites > realm.max_invites:\n        raise InvitationError(\n            msg,\n            [],\n            sent_invitations=False,\n            daily_limit_reached=True,\n        )\n\n    default_max = settings.INVITES_DEFAULT_REALM_DAILY_MAX\n    newrealm_age = datetime.timedelta(days=settings.INVITES_NEW_REALM_DAYS)\n    if realm.date_created <= timezone_now() - newrealm_age:\n        # If this isn't a \"newly-created\" realm, we're done. The\n        # remaining code applies an aggregate limit across all\n        # \"new\" realms, to address sudden bursts of spam realms.\n        return\n\n    if realm.max_invites > default_max:\n        # If a user is on a realm where we've bumped up\n        # max_invites, then we exempt them from invite limits.\n        return\n\n    new_realms = Realm.objects.filter(\n        date_created__gte=timezone_now() - newrealm_age,\n        _max_invites__lte=default_max,\n    ).all()\n\n    for days, count in settings.INVITES_NEW_REALM_LIMIT_DAYS:\n        recent_invites = estimate_recent_invites(new_realms, days=days)\n        if num_invitees + recent_invites > count:\n            raise InvitationError(\n                msg,\n                [],\n                sent_invitations=False,\n                daily_limit_reached=True,\n            )\n\n\ndef do_invite_users(\n    user_profile: UserProfile,\n    invitee_emails: Collection[str],\n    streams: Collection[Stream],\n    *,\n    invite_expires_in_days: Optional[int],\n    invite_as: int = PreregistrationUser.INVITE_AS[\"MEMBER\"],\n) -> None:\n    num_invites = len(invitee_emails)\n\n    check_invite_limit(user_profile.realm, num_invites)\n    if settings.BILLING_ENABLED:\n        from corporate.lib.registration import check_spare_licenses_available_for_inviting_new_users\n\n        check_spare_licenses_available_for_inviting_new_users(user_profile.realm, num_invites)\n\n    realm = user_profile.realm\n    if not realm.invite_required:\n        # Inhibit joining an open realm to send spam invitations.\n        min_age = datetime.timedelta(days=settings.INVITES_MIN_USER_AGE_DAYS)\n        if user_profile.date_joined > timezone_now() - min_age and not user_profile.is_realm_admin:\n            raise InvitationError(\n                _(\n                    \"Your account is too new to send invites for this organization. \"\n                    \"Ask an organization admin, or a more experienced user.\"\n                ),\n                [],\n                sent_invitations=False,\n            )\n\n    good_emails: Set[str] = set()\n    errors: List[Tuple[str, str, bool]] = []\n    validate_email_allowed_in_realm = get_realm_email_validator(user_profile.realm)\n    for email in invitee_emails:\n        if email == \"\":\n            continue\n        email_error = validate_email_is_valid(\n            email,\n            validate_email_allowed_in_realm,\n        )\n\n        if email_error:\n            errors.append((email, email_error, False))\n        else:\n            good_emails.add(email)\n\n    \"\"\"\n    good_emails are emails that look ok so far,\n    but we still need to make sure they're not\n    gonna conflict with existing users\n    \"\"\"\n    error_dict = get_existing_user_errors(user_profile.realm, good_emails)\n\n    skipped: List[Tuple[str, str, bool]] = []\n    for email in error_dict:\n        msg, deactivated = error_dict[email]\n        skipped.append((email, msg, deactivated))\n        good_emails.remove(email)\n\n    validated_emails = list(good_emails)\n\n    if errors:\n        raise InvitationError(\n            _(\"Some emails did not validate, so we didn't send any invitations.\"),\n            errors + skipped,\n            sent_invitations=False,\n        )\n\n    if skipped and len(skipped) == len(invitee_emails):\n        # All e-mails were skipped, so we didn't actually invite anyone.\n        raise InvitationError(\n            _(\"We weren't able to invite anyone.\"), skipped, sent_invitations=False\n        )\n\n    # We do this here rather than in the invite queue processor since this\n    # is used for rate limiting invitations, rather than keeping track of\n    # when exactly invitations were sent\n    do_increment_logging_stat(\n        user_profile.realm,\n        COUNT_STATS[\"invites_sent::day\"],\n        None,\n        timezone_now(),\n        increment=len(validated_emails),\n    )\n\n    # Now that we are past all the possible errors, we actually create\n    # the PreregistrationUser objects and trigger the email invitations.\n    for email in validated_emails:\n        # The logged in user is the referrer.\n        prereg_user = PreregistrationUser(\n            email=email, referred_by=user_profile, invited_as=invite_as, realm=user_profile.realm\n        )\n        prereg_user.save()\n        stream_ids = [stream.id for stream in streams]\n        prereg_user.streams.set(stream_ids)\n\n        event = {\n            \"prereg_id\": prereg_user.id,\n            \"referrer_id\": user_profile.id,\n            \"email_language\": user_profile.realm.default_language,\n            \"invite_expires_in_days\": invite_expires_in_days,\n        }\n        queue_json_publish(\"invites\", event)\n\n    if skipped:\n        raise InvitationError(\n            _(\n                \"Some of those addresses are already using Zulip, \"\n                \"so we didn't send them an invitation. We did send \"\n                \"invitations to everyone else!\"\n            ),\n            skipped,\n            sent_invitations=True,\n        )\n    notify_invites_changed(user_profile.realm)\n\n\ndef get_invitation_expiry_date(confirmation_obj: Confirmation) -> Optional[int]:\n    expiry_date = confirmation_obj.expiry_date\n    if expiry_date is None:\n        return expiry_date\n    return datetime_to_timestamp(expiry_date)\n\n\ndef do_get_invites_controlled_by_user(user_profile: UserProfile) -> List[Dict[str, Any]]:\n    \"\"\"\n    Returns a list of dicts representing invitations that can be controlled by user_profile.\n    This isn't necessarily the same as all the invitations generated by the user, as administrators\n    can control also invitations that they did not themselves create.\n    \"\"\"\n    if user_profile.is_realm_admin:\n        prereg_users = filter_to_valid_prereg_users(\n            PreregistrationUser.objects.filter(referred_by__realm=user_profile.realm)\n        )\n    else:\n        prereg_users = filter_to_valid_prereg_users(\n            PreregistrationUser.objects.filter(referred_by=user_profile)\n        )\n\n    invites = []\n\n    for invitee in prereg_users:\n        invites.append(\n            dict(\n                email=invitee.email,\n                invited_by_user_id=invitee.referred_by.id,\n                invited=datetime_to_timestamp(invitee.invited_at),\n                expiry_date=get_invitation_expiry_date(invitee.confirmation.get()),\n                id=invitee.id,\n                invited_as=invitee.invited_as,\n                is_multiuse=False,\n            )\n        )\n\n    if not user_profile.is_realm_admin:\n        # We do not return multiuse invites to non-admin users.\n        return invites\n\n    multiuse_confirmation_objs = Confirmation.objects.filter(\n        realm=user_profile.realm, type=Confirmation.MULTIUSE_INVITE\n    ).filter(Q(expiry_date__gte=timezone_now()) | Q(expiry_date=None))\n    for confirmation_obj in multiuse_confirmation_objs:\n        invite = confirmation_obj.content_object\n        assert invite is not None\n        invites.append(\n            dict(\n                invited_by_user_id=invite.referred_by.id,\n                invited=datetime_to_timestamp(confirmation_obj.date_sent),\n                expiry_date=get_invitation_expiry_date(confirmation_obj),\n                id=invite.id,\n                link_url=confirmation_url(\n                    confirmation_obj.confirmation_key,\n                    user_profile.realm,\n                    Confirmation.MULTIUSE_INVITE,\n                ),\n                invited_as=invite.invited_as,\n                is_multiuse=True,\n            )\n        )\n    return invites\n\n\ndef get_valid_invite_confirmations_generated_by_user(\n    user_profile: UserProfile,\n) -> List[Confirmation]:\n    prereg_user_ids = filter_to_valid_prereg_users(\n        PreregistrationUser.objects.filter(referred_by=user_profile)\n    ).values_list(\"id\", flat=True)\n    confirmations = list(\n        Confirmation.objects.filter(type=Confirmation.INVITATION, object_id__in=prereg_user_ids)\n    )\n\n    multiuse_invite_ids = MultiuseInvite.objects.filter(referred_by=user_profile).values_list(\n        \"id\", flat=True\n    )\n    confirmations += list(\n        Confirmation.objects.filter(\n            type=Confirmation.MULTIUSE_INVITE,\n            object_id__in=multiuse_invite_ids,\n        ).filter(Q(expiry_date__gte=timezone_now()) | Q(expiry_date=None))\n    )\n\n    return confirmations\n\n\ndef revoke_invites_generated_by_user(user_profile: UserProfile) -> None:\n    confirmations_to_revoke = get_valid_invite_confirmations_generated_by_user(user_profile)\n    now = timezone_now()\n    for confirmation in confirmations_to_revoke:\n        confirmation.expiry_date = now\n\n    Confirmation.objects.bulk_update(confirmations_to_revoke, [\"expiry_date\"])\n    if len(confirmations_to_revoke):\n        notify_invites_changed(realm=user_profile.realm)\n\n\ndef do_create_multiuse_invite_link(\n    referred_by: UserProfile,\n    invited_as: int,\n    invite_expires_in_days: Optional[int],\n    streams: Sequence[Stream] = [],\n) -> str:\n    realm = referred_by.realm\n    invite = MultiuseInvite.objects.create(realm=realm, referred_by=referred_by)\n    if streams:\n        invite.streams.set(streams)\n    invite.invited_as = invited_as\n    invite.save()\n    notify_invites_changed(referred_by.realm)\n    return create_confirmation_link(\n        invite, Confirmation.MULTIUSE_INVITE, validity_in_days=invite_expires_in_days\n    )\n\n\ndef do_revoke_user_invite(prereg_user: PreregistrationUser) -> None:\n    email = prereg_user.email\n    realm = prereg_user.realm\n    assert realm is not None\n\n    # Delete both the confirmation objects and the prereg_user object.\n    # TODO: Probably we actually want to set the confirmation objects\n    # to a \"revoked\" status so that we can give the invited user a better\n    # error message.\n    content_type = ContentType.objects.get_for_model(PreregistrationUser)\n    Confirmation.objects.filter(content_type=content_type, object_id=prereg_user.id).delete()\n    prereg_user.delete()\n    clear_scheduled_invitation_emails(email)\n    notify_invites_changed(realm)\n\n\ndef do_revoke_multi_use_invite(multiuse_invite: MultiuseInvite) -> None:\n    realm = multiuse_invite.referred_by.realm\n\n    content_type = ContentType.objects.get_for_model(MultiuseInvite)\n    Confirmation.objects.filter(content_type=content_type, object_id=multiuse_invite.id).delete()\n    multiuse_invite.delete()\n    notify_invites_changed(realm)\n\n\ndef do_resend_user_invite_email(prereg_user: PreregistrationUser) -> int:\n    # These are two structurally for the caller's code path.\n    assert prereg_user.referred_by is not None\n    assert prereg_user.realm is not None\n\n    check_invite_limit(prereg_user.referred_by.realm, 1)\n\n    prereg_user.invited_at = timezone_now()\n    prereg_user.save()\n\n    expiry_date = prereg_user.confirmation.get().expiry_date\n    if expiry_date is None:\n        invite_expires_in_days = None\n    else:\n        # The resent invitation is reset to expire as long after the\n        # reminder is sent as it lasted originally.\n        invite_expires_in_days = (expiry_date - prereg_user.invited_at).days\n    prereg_user.confirmation.clear()\n\n    do_increment_logging_stat(\n        prereg_user.realm, COUNT_STATS[\"invites_sent::day\"], None, prereg_user.invited_at\n    )\n\n    clear_scheduled_invitation_emails(prereg_user.email)\n    # We don't store the custom email body, so just set it to None\n    event = {\n        \"prereg_id\": prereg_user.id,\n        \"referrer_id\": prereg_user.referred_by.id,\n        \"email_language\": prereg_user.referred_by.realm.default_language,\n        \"invite_expires_in_days\": invite_expires_in_days,\n    }\n    queue_json_publish(\"invites\", event)\n\n    return datetime_to_timestamp(prereg_user.invited_at)\n\n\ndef notify_realm_emoji(realm: Realm) -> None:\n    event = dict(type=\"realm_emoji\", op=\"update\", realm_emoji=realm.get_emoji())\n    send_event(realm, event, active_user_ids(realm.id))\n\n\ndef check_add_realm_emoji(\n    realm: Realm, name: str, author: UserProfile, image_file: IO[bytes]\n) -> RealmEmoji:\n    try:\n        realm_emoji = RealmEmoji(realm=realm, name=name, author=author)\n        realm_emoji.full_clean()\n        realm_emoji.save()\n    except django.db.utils.IntegrityError:\n        # Match the string in upload_emoji.\n        raise JsonableError(_(\"A custom emoji with this name already exists.\"))\n\n    emoji_file_name = get_emoji_file_name(image_file.name, realm_emoji.id)\n\n    # The only user-controlled portion of 'emoji_file_name' is an extension,\n    # which can not contain '..' or '/' or '\\', making it difficult to exploit\n    emoji_file_name = mark_sanitized(emoji_file_name)\n\n    emoji_uploaded_successfully = False\n    is_animated = False\n    try:\n        is_animated = upload_emoji_image(image_file, emoji_file_name, author)\n        emoji_uploaded_successfully = True\n    finally:\n        if not emoji_uploaded_successfully:\n            realm_emoji.delete()\n    realm_emoji.file_name = emoji_file_name\n    realm_emoji.is_animated = is_animated\n    realm_emoji.save(update_fields=[\"file_name\", \"is_animated\"])\n    notify_realm_emoji(realm_emoji.realm)\n    return realm_emoji\n\n\ndef do_remove_realm_emoji(realm: Realm, name: str) -> None:\n    emoji = RealmEmoji.objects.get(realm=realm, name=name, deactivated=False)\n    emoji.deactivated = True\n    emoji.save(update_fields=[\"deactivated\"])\n    notify_realm_emoji(realm)\n\n\ndef notify_alert_words(user_profile: UserProfile, words: Sequence[str]) -> None:\n    event = dict(type=\"alert_words\", alert_words=words)\n    send_event(user_profile.realm, event, [user_profile.id])\n\n\ndef do_add_alert_words(user_profile: UserProfile, alert_words: Iterable[str]) -> None:\n    words = add_user_alert_words(user_profile, alert_words)\n    notify_alert_words(user_profile, words)\n\n\ndef do_remove_alert_words(user_profile: UserProfile, alert_words: Iterable[str]) -> None:\n    words = remove_user_alert_words(user_profile, alert_words)\n    notify_alert_words(user_profile, words)\n\n\ndef do_mute_topic(\n    user_profile: UserProfile,\n    stream: Stream,\n    topic: str,\n    date_muted: Optional[datetime.datetime] = None,\n) -> None:\n    if date_muted is None:\n        date_muted = timezone_now()\n    add_topic_mute(user_profile, stream.id, stream.recipient_id, topic, date_muted)\n    event = dict(type=\"muted_topics\", muted_topics=get_topic_mutes(user_profile))\n    send_event(user_profile.realm, event, [user_profile.id])\n\n\ndef do_unmute_topic(user_profile: UserProfile, stream: Stream, topic: str) -> None:\n    try:\n        remove_topic_mute(user_profile, stream.id, topic)\n    except UserTopic.DoesNotExist:\n        raise JsonableError(_(\"Topic is not muted\"))\n    event = dict(type=\"muted_topics\", muted_topics=get_topic_mutes(user_profile))\n    send_event(user_profile.realm, event, [user_profile.id])\n\n\ndef do_mute_user(\n    user_profile: UserProfile,\n    muted_user: UserProfile,\n    date_muted: Optional[datetime.datetime] = None,\n) -> None:\n    if date_muted is None:\n        date_muted = timezone_now()\n    add_user_mute(user_profile, muted_user, date_muted)\n    do_mark_muted_user_messages_as_read(user_profile, muted_user)\n    event = dict(type=\"muted_users\", muted_users=get_user_mutes(user_profile))\n    send_event(user_profile.realm, event, [user_profile.id])\n\n    RealmAuditLog.objects.create(\n        realm=user_profile.realm,\n        acting_user=user_profile,\n        modified_user=user_profile,\n        event_type=RealmAuditLog.USER_MUTED,\n        event_time=date_muted,\n        extra_data=orjson.dumps({\"muted_user_id\": muted_user.id}).decode(),\n    )\n\n\ndef do_unmute_user(mute_object: MutedUser) -> None:\n    user_profile = mute_object.user_profile\n    muted_user = mute_object.muted_user\n    mute_object.delete()\n    event = dict(type=\"muted_users\", muted_users=get_user_mutes(user_profile))\n    send_event(user_profile.realm, event, [user_profile.id])\n\n    RealmAuditLog.objects.create(\n        realm=user_profile.realm,\n        acting_user=user_profile,\n        modified_user=user_profile,\n        event_type=RealmAuditLog.USER_UNMUTED,\n        event_time=timezone_now(),\n        extra_data=orjson.dumps({\"unmuted_user_id\": muted_user.id}).decode(),\n    )\n\n\ndef do_mark_hotspot_as_read(user: UserProfile, hotspot: str) -> None:\n    UserHotspot.objects.get_or_create(user=user, hotspot=hotspot)\n    event = dict(type=\"hotspots\", hotspots=get_next_hotspots(user))\n    send_event(user.realm, event, [user.id])\n\n\ndef notify_linkifiers(realm: Realm) -> None:\n    realm_linkifiers = linkifiers_for_realm(realm.id)\n    event: Dict[str, object] = dict(type=\"realm_linkifiers\", realm_linkifiers=realm_linkifiers)\n    send_event(realm, event, active_user_ids(realm.id))\n\n    # Below is code for backwards compatibility. The now deprecated\n    # \"realm_filters\" event-type is used by older clients, and uses\n    # tuples.\n    realm_filters = realm_filters_for_realm(realm.id)\n    event = dict(type=\"realm_filters\", realm_filters=realm_filters)\n    send_event(realm, event, active_user_ids(realm.id))\n\n\n# NOTE: Regexes must be simple enough that they can be easily translated to JavaScript\n# RegExp syntax. In addition to JS-compatible syntax, the following features are available:\n#   * Named groups will be converted to numbered groups automatically\n#   * Inline-regex flags will be stripped, and where possible translated to RegExp-wide flags\ndef do_add_linkifier(realm: Realm, pattern: str, url_format_string: str) -> int:\n    pattern = pattern.strip()\n    url_format_string = url_format_string.strip()\n    linkifier = RealmFilter(realm=realm, pattern=pattern, url_format_string=url_format_string)\n    linkifier.full_clean()\n    linkifier.save()\n    notify_linkifiers(realm)\n\n    return linkifier.id\n\n\ndef do_remove_linkifier(\n    realm: Realm, pattern: Optional[str] = None, id: Optional[int] = None\n) -> None:\n    if pattern is not None:\n        RealmFilter.objects.get(realm=realm, pattern=pattern).delete()\n    else:\n        RealmFilter.objects.get(realm=realm, id=id).delete()\n    notify_linkifiers(realm)\n\n\ndef do_update_linkifier(realm: Realm, id: int, pattern: str, url_format_string: str) -> None:\n    pattern = pattern.strip()\n    url_format_string = url_format_string.strip()\n    linkifier = RealmFilter.objects.get(realm=realm, id=id)\n    linkifier.pattern = pattern\n    linkifier.url_format_string = url_format_string\n    linkifier.full_clean()\n    linkifier.save(update_fields=[\"pattern\", \"url_format_string\"])\n    notify_linkifiers(realm)\n\n\n@transaction.atomic(durable=True)\ndef do_add_realm_domain(\n    realm: Realm, domain: str, allow_subdomains: bool, *, acting_user: Optional[UserProfile]\n) -> (RealmDomain):\n    realm_domain = RealmDomain.objects.create(\n        realm=realm, domain=domain, allow_subdomains=allow_subdomains\n    )\n\n    RealmAuditLog.objects.create(\n        realm=realm,\n        acting_user=acting_user,\n        event_type=RealmAuditLog.REALM_DOMAIN_ADDED,\n        event_time=timezone_now(),\n        extra_data=orjson.dumps(\n            {\n                \"realm_domains\": get_realm_domains(realm),\n                \"added_domain\": {\"domain\": domain, \"allow_subdomains\": allow_subdomains},\n            }\n        ).decode(),\n    )\n\n    event = dict(\n        type=\"realm_domains\",\n        op=\"add\",\n        realm_domain=dict(\n            domain=realm_domain.domain, allow_subdomains=realm_domain.allow_subdomains\n        ),\n    )\n    transaction.on_commit(lambda: send_event(realm, event, active_user_ids(realm.id)))\n\n    return realm_domain\n\n\n@transaction.atomic(durable=True)\ndef do_change_realm_domain(\n    realm_domain: RealmDomain, allow_subdomains: bool, *, acting_user: Optional[UserProfile]\n) -> None:\n    realm_domain.allow_subdomains = allow_subdomains\n    realm_domain.save(update_fields=[\"allow_subdomains\"])\n\n    RealmAuditLog.objects.create(\n        realm=realm_domain.realm,\n        acting_user=acting_user,\n        event_type=RealmAuditLog.REALM_DOMAIN_CHANGED,\n        event_time=timezone_now(),\n        extra_data=orjson.dumps(\n            {\n                \"realm_domains\": get_realm_domains(realm_domain.realm),\n                \"changed_domain\": {\n                    \"domain\": realm_domain.domain,\n                    \"allow_subdomains\": realm_domain.allow_subdomains,\n                },\n            }\n        ).decode(),\n    )\n\n    event = dict(\n        type=\"realm_domains\",\n        op=\"change\",\n        realm_domain=dict(\n            domain=realm_domain.domain, allow_subdomains=realm_domain.allow_subdomains\n        ),\n    )\n    transaction.on_commit(\n        lambda: send_event(realm_domain.realm, event, active_user_ids(realm_domain.realm_id))\n    )\n\n\n@transaction.atomic(durable=True)\ndef do_remove_realm_domain(\n    realm_domain: RealmDomain, *, acting_user: Optional[UserProfile]\n) -> None:\n    realm = realm_domain.realm\n    domain = realm_domain.domain\n    realm_domain.delete()\n\n    RealmAuditLog.objects.create(\n        realm=realm,\n        acting_user=acting_user,\n        event_type=RealmAuditLog.REALM_DOMAIN_REMOVED,\n        event_time=timezone_now(),\n        extra_data=orjson.dumps(\n            {\n                \"realm_domains\": get_realm_domains(realm),\n                \"removed_domain\": {\n                    \"domain\": realm_domain.domain,\n                    \"allow_subdomains\": realm_domain.allow_subdomains,\n                },\n            }\n        ).decode(),\n    )\n\n    if RealmDomain.objects.filter(realm=realm).count() == 0 and realm.emails_restricted_to_domains:\n        # If this was the last realm domain, we mark the realm as no\n        # longer restricted to domain, because the feature doesn't do\n        # anything if there are no domains, and this is probably less\n        # confusing than the alternative.\n        do_set_realm_property(realm, \"emails_restricted_to_domains\", False, acting_user=acting_user)\n    event = dict(type=\"realm_domains\", op=\"remove\", domain=domain)\n    transaction.on_commit(lambda: send_event(realm, event, active_user_ids(realm.id)))\n\n\ndef notify_realm_playgrounds(realm: Realm) -> None:\n    event = dict(type=\"realm_playgrounds\", realm_playgrounds=get_realm_playgrounds(realm))\n    send_event(realm, event, active_user_ids(realm.id))\n\n\ndef do_add_realm_playground(realm: Realm, **kwargs: Any) -> int:\n    realm_playground = RealmPlayground(realm=realm, **kwargs)\n    # We expect full_clean to always pass since a thorough input validation\n    # is performed in the view (using check_url, check_pygments_language, etc)\n    # before calling this function.\n    realm_playground.full_clean()\n    realm_playground.save()\n    notify_realm_playgrounds(realm)\n    return realm_playground.id\n\n\ndef do_remove_realm_playground(realm: Realm, realm_playground: RealmPlayground) -> None:\n    realm_playground.delete()\n    notify_realm_playgrounds(realm)\n\n\ndef get_occupied_streams(realm: Realm) -> QuerySet:\n    # TODO: Make a generic stub for QuerySet\n    \"\"\"Get streams with subscribers\"\"\"\n    exists_expression = Exists(\n        Subscription.objects.filter(\n            active=True,\n            is_user_active=True,\n            user_profile__realm=realm,\n            recipient_id=OuterRef(\"recipient_id\"),\n        ),\n    )\n    occupied_streams = (\n        Stream.objects.filter(realm=realm, deactivated=False)\n        .annotate(occupied=exists_expression)\n        .filter(occupied=True)\n    )\n    return occupied_streams\n\n\ndef get_web_public_streams(realm: Realm) -> List[Dict[str, Any]]:  # nocoverage\n    query = get_web_public_streams_queryset(realm)\n    streams = Stream.get_client_data(query)\n    return streams\n\n\ndef do_get_streams(\n    user_profile: UserProfile,\n    include_public: bool = True,\n    include_web_public: bool = False,\n    include_subscribed: bool = True,\n    include_all_active: bool = False,\n    include_default: bool = False,\n    include_owner_subscribed: bool = False,\n) -> List[Dict[str, Any]]:\n    # This function is only used by API clients now.\n\n    if include_all_active and not user_profile.is_realm_admin:\n        raise JsonableError(_(\"User not authorized for this query\"))\n\n    include_public = include_public and user_profile.can_access_public_streams()\n\n    # Start out with all active streams in the realm.\n    query = Stream.objects.filter(realm=user_profile.realm, deactivated=False)\n\n    if include_all_active:\n        streams = Stream.get_client_data(query)\n    else:\n        # We construct a query as the or (|) of the various sources\n        # this user requested streams from.\n        query_filter: Optional[Q] = None\n\n        def add_filter_option(option: Q) -> None:\n            nonlocal query_filter\n            if query_filter is None:\n                query_filter = option\n            else:\n                query_filter |= option\n\n        if include_subscribed:\n            subscribed_stream_ids = get_subscribed_stream_ids_for_user(user_profile)\n            recipient_check = Q(id__in=set(subscribed_stream_ids))\n            add_filter_option(recipient_check)\n        if include_public:\n            invite_only_check = Q(invite_only=False)\n            add_filter_option(invite_only_check)\n        if include_web_public:\n            # This should match get_web_public_streams_queryset\n            web_public_check = Q(\n                is_web_public=True,\n                invite_only=False,\n                history_public_to_subscribers=True,\n                deactivated=False,\n            )\n            add_filter_option(web_public_check)\n        if include_owner_subscribed and user_profile.is_bot:\n            bot_owner = user_profile.bot_owner\n            assert bot_owner is not None\n            owner_stream_ids = get_subscribed_stream_ids_for_user(bot_owner)\n            owner_subscribed_check = Q(id__in=set(owner_stream_ids))\n            add_filter_option(owner_subscribed_check)\n\n        if query_filter is not None:\n            query = query.filter(query_filter)\n            streams = Stream.get_client_data(query)\n        else:\n            # Don't bother going to the database with no valid sources\n            streams = []\n\n    streams.sort(key=lambda elt: elt[\"name\"])\n\n    if include_default:\n        is_default = {}\n        default_streams = get_default_streams_for_realm(user_profile.realm_id)\n        for default_stream in default_streams:\n            is_default[default_stream.id] = True\n        for stream in streams:\n            stream[\"is_default\"] = is_default.get(stream[\"stream_id\"], False)\n\n    return streams\n\n\ndef notify_attachment_update(\n    user_profile: UserProfile, op: str, attachment_dict: Dict[str, Any]\n) -> None:\n    event = {\n        \"type\": \"attachment\",\n        \"op\": op,\n        \"attachment\": attachment_dict,\n        \"upload_space_used\": user_profile.realm.currently_used_upload_space_bytes(),\n    }\n    send_event(user_profile.realm, event, [user_profile.id])\n\n\ndef do_claim_attachments(message: Message, potential_path_ids: List[str]) -> bool:\n    claimed = False\n    for path_id in potential_path_ids:\n        user_profile = message.sender\n        is_message_realm_public = False\n        is_message_web_public = False\n        if message.is_stream_message():\n            stream = Stream.objects.get(id=message.recipient.type_id)\n            is_message_realm_public = stream.is_public()\n            is_message_web_public = stream.is_web_public\n\n        if not validate_attachment_request(user_profile, path_id):\n            # Technically, there are 2 cases here:\n            # * The user put something in their message that has the form\n            # of an upload, but doesn't correspond to a file that doesn't\n            # exist.  validate_attachment_request will return None.\n            # * The user is trying to send a link to a file they don't have permission to\n            # access themselves.  validate_attachment_request will return False.\n            #\n            # Either case is unusual and suggests a UI bug that got\n            # the user in this situation, so we log in these cases.\n            logging.warning(\n                \"User %s tried to share upload %s in message %s, but lacks permission\",\n                user_profile.id,\n                path_id,\n                message.id,\n            )\n            continue\n\n        claimed = True\n        attachment = claim_attachment(\n            user_profile, path_id, message, is_message_realm_public, is_message_web_public\n        )\n        notify_attachment_update(user_profile, \"update\", attachment.to_dict())\n    return claimed\n\n\ndef do_delete_old_unclaimed_attachments(weeks_ago: int) -> None:\n    old_unclaimed_attachments = get_old_unclaimed_attachments(weeks_ago)\n\n    for attachment in old_unclaimed_attachments:\n        delete_message_image(attachment.path_id)\n        attachment.delete()\n\n\ndef check_attachment_reference_change(\n    message: Message, rendering_result: MessageRenderingResult\n) -> bool:\n    # For a unsaved message edit (message.* has been updated, but not\n    # saved to the database), adjusts Attachment data to correspond to\n    # the new content.\n    prev_attachments = {a.path_id for a in message.attachment_set.all()}\n    new_attachments = set(rendering_result.potential_attachment_path_ids)\n\n    if new_attachments == prev_attachments:\n        return bool(prev_attachments)\n\n    to_remove = list(prev_attachments - new_attachments)\n    if len(to_remove) > 0:\n        attachments_to_update = Attachment.objects.filter(path_id__in=to_remove).select_for_update()\n        message.attachment_set.remove(*attachments_to_update)\n\n    to_add = list(new_attachments - prev_attachments)\n    if len(to_add) > 0:\n        do_claim_attachments(message, to_add)\n\n    return message.attachment_set.exists()\n\n\ndef notify_realm_custom_profile_fields(realm: Realm) -> None:\n    fields = custom_profile_fields_for_realm(realm.id)\n    event = dict(type=\"custom_profile_fields\", fields=[f.as_dict() for f in fields])\n    send_event(realm, event, active_user_ids(realm.id))\n\n\ndef try_add_realm_default_custom_profile_field(\n    realm: Realm, field_subtype: str\n) -> CustomProfileField:\n    field_data = DEFAULT_EXTERNAL_ACCOUNTS[field_subtype]\n    custom_profile_field = CustomProfileField(\n        realm=realm,\n        name=field_data[\"name\"],\n        field_type=CustomProfileField.EXTERNAL_ACCOUNT,\n        hint=field_data[\"hint\"],\n        field_data=orjson.dumps(dict(subtype=field_subtype)).decode(),\n    )\n    custom_profile_field.save()\n    custom_profile_field.order = custom_profile_field.id\n    custom_profile_field.save(update_fields=[\"order\"])\n    notify_realm_custom_profile_fields(realm)\n    return custom_profile_field\n\n\ndef try_add_realm_custom_profile_field(\n    realm: Realm,\n    name: str,\n    field_type: int,\n    hint: str = \"\",\n    field_data: Optional[ProfileFieldData] = None,\n) -> CustomProfileField:\n    custom_profile_field = CustomProfileField(realm=realm, name=name, field_type=field_type)\n    custom_profile_field.hint = hint\n    if (\n        custom_profile_field.field_type == CustomProfileField.SELECT\n        or custom_profile_field.field_type == CustomProfileField.EXTERNAL_ACCOUNT\n    ):\n        custom_profile_field.field_data = orjson.dumps(field_data or {}).decode()\n\n    custom_profile_field.save()\n    custom_profile_field.order = custom_profile_field.id\n    custom_profile_field.save(update_fields=[\"order\"])\n    notify_realm_custom_profile_fields(realm)\n    return custom_profile_field\n\n\ndef do_remove_realm_custom_profile_field(realm: Realm, field: CustomProfileField) -> None:\n    \"\"\"\n    Deleting a field will also delete the user profile data\n    associated with it in CustomProfileFieldValue model.\n    \"\"\"\n    field.delete()\n    notify_realm_custom_profile_fields(realm)\n\n\ndef do_remove_realm_custom_profile_fields(realm: Realm) -> None:\n    CustomProfileField.objects.filter(realm=realm).delete()\n\n\ndef try_update_realm_custom_profile_field(\n    realm: Realm,\n    field: CustomProfileField,\n    name: str,\n    hint: str = \"\",\n    field_data: Optional[ProfileFieldData] = None,\n) -> None:\n    field.name = name\n    field.hint = hint\n    if (\n        field.field_type == CustomProfileField.SELECT\n        or field.field_type == CustomProfileField.EXTERNAL_ACCOUNT\n    ):\n        field.field_data = orjson.dumps(field_data or {}).decode()\n    field.save()\n    notify_realm_custom_profile_fields(realm)\n\n\ndef try_reorder_realm_custom_profile_fields(realm: Realm, order: List[int]) -> None:\n    order_mapping = {_[1]: _[0] for _ in enumerate(order)}\n    custom_profile_fields = CustomProfileField.objects.filter(realm=realm)\n    for custom_profile_field in custom_profile_fields:\n        if custom_profile_field.id not in order_mapping:\n            raise JsonableError(_(\"Invalid order mapping.\"))\n    for custom_profile_field in custom_profile_fields:\n        custom_profile_field.order = order_mapping[custom_profile_field.id]\n        custom_profile_field.save(update_fields=[\"order\"])\n    notify_realm_custom_profile_fields(realm)\n\n\ndef notify_user_update_custom_profile_data(\n    user_profile: UserProfile, field: Dict[str, Union[int, str, List[int], None]]\n) -> None:\n    data = dict(id=field[\"id\"], value=field[\"value\"])\n\n    if field[\"rendered_value\"]:\n        data[\"rendered_value\"] = field[\"rendered_value\"]\n    payload = dict(user_id=user_profile.id, custom_profile_field=data)\n    event = dict(type=\"realm_user\", op=\"update\", person=payload)\n    send_event(user_profile.realm, event, active_user_ids(user_profile.realm.id))\n\n\ndef do_update_user_custom_profile_data_if_changed(\n    user_profile: UserProfile,\n    data: List[Dict[str, Union[int, ProfileDataElementValue]]],\n) -> None:\n    with transaction.atomic():\n        for custom_profile_field in data:\n            field_value, created = CustomProfileFieldValue.objects.get_or_create(\n                user_profile=user_profile, field_id=custom_profile_field[\"id\"]\n            )\n\n            # field_value.value is a TextField() so we need to have field[\"value\"]\n            # in string form to correctly make comparisons and assignments.\n            if isinstance(custom_profile_field[\"value\"], str):\n                custom_profile_field_value_string = custom_profile_field[\"value\"]\n            else:\n                custom_profile_field_value_string = orjson.dumps(\n                    custom_profile_field[\"value\"]\n                ).decode()\n\n            if not created and field_value.value == custom_profile_field_value_string:\n                # If the field value isn't actually being changed to a different one,\n                # we have nothing to do here for this field.\n                continue\n\n            field_value.value = custom_profile_field_value_string\n            if field_value.field.is_renderable():\n                field_value.rendered_value = render_stream_description(\n                    custom_profile_field_value_string\n                )\n                field_value.save(update_fields=[\"value\", \"rendered_value\"])\n            else:\n                field_value.save(update_fields=[\"value\"])\n            notify_user_update_custom_profile_data(\n                user_profile,\n                {\n                    \"id\": field_value.field_id,\n                    \"value\": field_value.value,\n                    \"rendered_value\": field_value.rendered_value,\n                    \"type\": field_value.field.field_type,\n                },\n            )\n\n\ndef check_remove_custom_profile_field_value(user_profile: UserProfile, field_id: int) -> None:\n    try:\n        custom_profile_field = CustomProfileField.objects.get(realm=user_profile.realm, id=field_id)\n        field_value = CustomProfileFieldValue.objects.get(\n            field=custom_profile_field, user_profile=user_profile\n        )\n        field_value.delete()\n        notify_user_update_custom_profile_data(\n            user_profile,\n            {\n                \"id\": field_id,\n                \"value\": None,\n                \"rendered_value\": None,\n                \"type\": custom_profile_field.field_type,\n            },\n        )\n    except CustomProfileField.DoesNotExist:\n        raise JsonableError(_(\"Field id {id} not found.\").format(id=field_id))\n    except CustomProfileFieldValue.DoesNotExist:\n        pass\n\n\ndef do_send_create_user_group_event(user_group: UserGroup, members: List[UserProfile]) -> None:\n    event = dict(\n        type=\"user_group\",\n        op=\"add\",\n        group=dict(\n            name=user_group.name,\n            members=[member.id for member in members],\n            description=user_group.description,\n            id=user_group.id,\n            is_system_group=user_group.is_system_group,\n        ),\n    )\n    send_event(user_group.realm, event, active_user_ids(user_group.realm_id))\n\n\ndef check_add_user_group(\n    realm: Realm, name: str, initial_members: List[UserProfile], description: str\n) -> None:\n    try:\n        user_group = create_user_group(name, initial_members, realm, description=description)\n        do_send_create_user_group_event(user_group, initial_members)\n    except django.db.utils.IntegrityError:\n        raise JsonableError(_(\"User group '{}' already exists.\").format(name))\n\n\ndef do_send_user_group_update_event(user_group: UserGroup, data: Dict[str, str]) -> None:\n    event = dict(type=\"user_group\", op=\"update\", group_id=user_group.id, data=data)\n    send_event(user_group.realm, event, active_user_ids(user_group.realm_id))\n\n\ndef do_update_user_group_name(user_group: UserGroup, name: str) -> None:\n    try:\n        user_group.name = name\n        user_group.save(update_fields=[\"name\"])\n    except django.db.utils.IntegrityError:\n        raise JsonableError(_(\"User group '{}' already exists.\").format(name))\n    do_send_user_group_update_event(user_group, dict(name=name))\n\n\ndef do_update_user_group_description(user_group: UserGroup, description: str) -> None:\n    user_group.description = description\n    user_group.save(update_fields=[\"description\"])\n    do_send_user_group_update_event(user_group, dict(description=description))\n\n\ndef do_update_outgoing_webhook_service(\n    bot_profile: UserProfile, service_interface: int, service_payload_url: str\n) -> None:\n    # TODO: First service is chosen because currently one bot can only have one service.\n    # Update this once multiple services are supported.\n    service = get_bot_services(bot_profile.id)[0]\n    service.base_url = service_payload_url\n    service.interface = service_interface\n    service.save()\n    send_event(\n        bot_profile.realm,\n        dict(\n            type=\"realm_bot\",\n            op=\"update\",\n            bot=dict(\n                user_id=bot_profile.id,\n                services=[\n                    dict(\n                        base_url=service.base_url, interface=service.interface, token=service.token\n                    )\n                ],\n            ),\n        ),\n        bot_owner_user_ids(bot_profile),\n    )\n\n\ndef do_update_bot_config_data(bot_profile: UserProfile, config_data: Dict[str, str]) -> None:\n    for key, value in config_data.items():\n        set_bot_config(bot_profile, key, value)\n    updated_config_data = get_bot_config(bot_profile)\n    send_event(\n        bot_profile.realm,\n        dict(\n            type=\"realm_bot\",\n            op=\"update\",\n            bot=dict(\n                user_id=bot_profile.id,\n                services=[dict(config_data=updated_config_data)],\n            ),\n        ),\n        bot_owner_user_ids(bot_profile),\n    )\n\n\ndef get_service_dicts_for_bot(user_profile_id: int) -> List[Dict[str, Any]]:\n    user_profile = get_user_profile_by_id(user_profile_id)\n    services = get_bot_services(user_profile_id)\n    service_dicts: List[Dict[str, Any]] = []\n    if user_profile.bot_type == UserProfile.OUTGOING_WEBHOOK_BOT:\n        service_dicts = [\n            {\n                \"base_url\": service.base_url,\n                \"interface\": service.interface,\n                \"token\": service.token,\n            }\n            for service in services\n        ]\n    elif user_profile.bot_type == UserProfile.EMBEDDED_BOT:\n        try:\n            service_dicts = [\n                {\n                    \"config_data\": get_bot_config(user_profile),\n                    \"service_name\": services[0].name,\n                }\n            ]\n        # A ConfigError just means that there are no config entries for user_profile.\n        except ConfigError:\n            pass\n    return service_dicts\n\n\ndef get_service_dicts_for_bots(\n    bot_dicts: List[Dict[str, Any]], realm: Realm\n) -> Dict[int, List[Dict[str, Any]]]:\n    bot_profile_ids = [bot_dict[\"id\"] for bot_dict in bot_dicts]\n    bot_services_by_uid: Dict[int, List[Service]] = defaultdict(list)\n    for service in Service.objects.filter(user_profile_id__in=bot_profile_ids):\n        bot_services_by_uid[service.user_profile_id].append(service)\n\n    embedded_bot_ids = [\n        bot_dict[\"id\"] for bot_dict in bot_dicts if bot_dict[\"bot_type\"] == UserProfile.EMBEDDED_BOT\n    ]\n    embedded_bot_configs = get_bot_configs(embedded_bot_ids)\n\n    service_dicts_by_uid: Dict[int, List[Dict[str, Any]]] = {}\n    for bot_dict in bot_dicts:\n        bot_profile_id = bot_dict[\"id\"]\n        bot_type = bot_dict[\"bot_type\"]\n        services = bot_services_by_uid[bot_profile_id]\n        service_dicts: List[Dict[str, Any]] = []\n        if bot_type == UserProfile.OUTGOING_WEBHOOK_BOT:\n            service_dicts = [\n                {\n                    \"base_url\": service.base_url,\n                    \"interface\": service.interface,\n                    \"token\": service.token,\n                }\n                for service in services\n            ]\n        elif bot_type == UserProfile.EMBEDDED_BOT:\n            if bot_profile_id in embedded_bot_configs.keys():\n                bot_config = embedded_bot_configs[bot_profile_id]\n                service_dicts = [\n                    {\n                        \"config_data\": bot_config,\n                        \"service_name\": services[0].name,\n                    }\n                ]\n        service_dicts_by_uid[bot_profile_id] = service_dicts\n    return service_dicts_by_uid\n\n\ndef get_owned_bot_dicts(\n    user_profile: UserProfile, include_all_realm_bots_if_admin: bool = True\n) -> List[Dict[str, Any]]:\n    if user_profile.is_realm_admin and include_all_realm_bots_if_admin:\n        result = get_bot_dicts_in_realm(user_profile.realm)\n    else:\n        result = UserProfile.objects.filter(\n            realm=user_profile.realm, is_bot=True, bot_owner=user_profile\n        ).values(*bot_dict_fields)\n    services_by_ids = get_service_dicts_for_bots(result, user_profile.realm)\n    return [\n        {\n            \"email\": botdict[\"email\"],\n            \"user_id\": botdict[\"id\"],\n            \"full_name\": botdict[\"full_name\"],\n            \"bot_type\": botdict[\"bot_type\"],\n            \"is_active\": botdict[\"is_active\"],\n            \"api_key\": botdict[\"api_key\"],\n            \"default_sending_stream\": botdict[\"default_sending_stream__name\"],\n            \"default_events_register_stream\": botdict[\"default_events_register_stream__name\"],\n            \"default_all_public_streams\": botdict[\"default_all_public_streams\"],\n            \"owner_id\": botdict[\"bot_owner_id\"],\n            \"avatar_url\": avatar_url_from_dict(botdict),\n            \"services\": services_by_ids[botdict[\"id\"]],\n        }\n        for botdict in result\n    ]\n\n\ndef do_send_user_group_members_update_event(\n    event_name: str, user_group: UserGroup, user_ids: List[int]\n) -> None:\n    event = dict(type=\"user_group\", op=event_name, group_id=user_group.id, user_ids=user_ids)\n    transaction.on_commit(\n        lambda: send_event(user_group.realm, event, active_user_ids(user_group.realm_id))\n    )\n\n\n@transaction.atomic(savepoint=False)\ndef bulk_add_members_to_user_group(user_group: UserGroup, user_profile_ids: List[int]) -> None:\n    memberships = [\n        UserGroupMembership(user_group_id=user_group.id, user_profile_id=user_id)\n        for user_id in user_profile_ids\n    ]\n    UserGroupMembership.objects.bulk_create(memberships)\n\n    do_send_user_group_members_update_event(\"add_members\", user_group, user_profile_ids)\n\n\n@transaction.atomic(savepoint=False)\ndef remove_members_from_user_group(user_group: UserGroup, user_profile_ids: List[int]) -> None:\n    UserGroupMembership.objects.filter(\n        user_group_id=user_group.id, user_profile_id__in=user_profile_ids\n    ).delete()\n\n    do_send_user_group_members_update_event(\"remove_members\", user_group, user_profile_ids)\n\n\ndef do_send_delete_user_group_event(realm: Realm, user_group_id: int, realm_id: int) -> None:\n    event = dict(type=\"user_group\", op=\"remove\", group_id=user_group_id)\n    send_event(realm, event, active_user_ids(realm_id))\n\n\ndef check_delete_user_group(user_group_id: int, user_profile: UserProfile) -> None:\n    user_group = access_user_group_by_id(user_group_id, user_profile)\n    user_group.delete()\n    do_send_delete_user_group_event(user_profile.realm, user_group_id, user_profile.realm.id)\n\n\ndef do_send_realm_reactivation_email(realm: Realm, *, acting_user: Optional[UserProfile]) -> None:\n    url = create_confirmation_link(realm, Confirmation.REALM_REACTIVATION)\n    RealmAuditLog.objects.create(\n        realm=realm,\n        acting_user=acting_user,\n        event_type=RealmAuditLog.REALM_REACTIVATION_EMAIL_SENT,\n        event_time=timezone_now(),\n    )\n    context = {\"confirmation_url\": url, \"realm_uri\": realm.uri, \"realm_name\": realm.name}\n    language = realm.default_language\n    send_email_to_admins(\n        \"zerver/emails/realm_reactivation\",\n        realm,\n        from_address=FromAddress.tokenized_no_reply_address(),\n        from_name=FromAddress.security_email_from_name(language=language),\n        language=language,\n        context=context,\n    )\n\n\ndef do_set_zoom_token(user: UserProfile, token: Optional[Dict[str, object]]) -> None:\n    user.zoom_token = token\n    user.save(update_fields=[\"zoom_token\"])\n    send_event(\n        user.realm,\n        dict(type=\"has_zoom_token\", value=token is not None),\n        [user.id],\n    )\n\n\ndef notify_realm_export(user_profile: UserProfile) -> None:\n    # In the future, we may want to send this event to all realm admins.\n    event = dict(type=\"realm_export\", exports=get_realm_exports_serialized(user_profile))\n    send_event(user_profile.realm, event, [user_profile.id])\n\n\ndef do_delete_realm_export(user_profile: UserProfile, export: RealmAuditLog) -> None:\n    # Give mypy a hint so it knows `orjson.loads`\n    # isn't being passed an `Optional[str]`.\n    export_extra_data = export.extra_data\n    assert export_extra_data is not None\n    export_data = orjson.loads(export_extra_data)\n    export_path = export_data.get(\"export_path\")\n\n    if export_path:\n        # Allow removal even if the export failed.\n        delete_export_tarball(export_path)\n\n    export_data.update(deleted_timestamp=timezone_now().timestamp())\n    export.extra_data = orjson.dumps(export_data).decode()\n    export.save(update_fields=[\"extra_data\"])\n    notify_realm_export(user_profile)\n\n\ndef get_topic_messages(user_profile: UserProfile, stream: Stream, topic_name: str) -> List[Message]:\n    query = UserMessage.objects.filter(\n        user_profile=user_profile,\n        message__recipient=stream.recipient,\n    ).order_by(\"id\")\n    return [um.message for um in filter_by_topic_name_via_message(query, topic_name)]\n", "import datetime\nfrom email.headerregistry import Address\nfrom typing import Any, Dict, Iterable, List, Mapping, Optional, TypeVar, Union\nfrom unittest import mock\n\nimport orjson\nfrom django.conf import settings\nfrom django.contrib.contenttypes.models import ContentType\nfrom django.core.exceptions import ValidationError\nfrom django.test import override_settings\nfrom django.utils.timezone import now as timezone_now\n\nfrom confirmation.models import Confirmation\nfrom zerver.lib.actions import (\n    change_user_is_active,\n    create_users,\n    do_change_can_create_users,\n    do_change_user_role,\n    do_create_multiuse_invite_link,\n    do_create_user,\n    do_deactivate_user,\n    do_delete_user,\n    do_invite_users,\n    do_mute_user,\n    do_reactivate_user,\n    do_set_realm_property,\n    get_recipient_info,\n)\nfrom zerver.lib.avatar import avatar_url, get_gravatar_url\nfrom zerver.lib.create_user import copy_default_settings\nfrom zerver.lib.events import do_events_register\nfrom zerver.lib.exceptions import JsonableError\nfrom zerver.lib.send_email import (\n    clear_scheduled_emails,\n    deliver_scheduled_emails,\n    send_future_email,\n)\nfrom zerver.lib.stream_topic import StreamTopicTarget\nfrom zerver.lib.test_classes import ZulipTestCase\nfrom zerver.lib.test_helpers import (\n    cache_tries_captured,\n    get_subscription,\n    get_test_image_file,\n    queries_captured,\n    reset_emails_in_zulip_realm,\n    simulated_empty_cache,\n)\nfrom zerver.lib.upload import upload_avatar_image\nfrom zerver.lib.user_groups import get_system_user_group_for_user\nfrom zerver.lib.user_topics import add_topic_mute\nfrom zerver.lib.users import Accounts, access_user_by_id, get_accounts_for_email, user_ids_to_users\nfrom zerver.lib.utils import assert_is_not_none\nfrom zerver.models import (\n    CustomProfileField,\n    InvalidFakeEmailDomain,\n    Message,\n    PreregistrationUser,\n    Realm,\n    RealmDomain,\n    RealmUserDefault,\n    Recipient,\n    ScheduledEmail,\n    Stream,\n    Subscription,\n    UserGroupMembership,\n    UserHotspot,\n    UserProfile,\n    check_valid_user_ids,\n    filter_to_valid_prereg_users,\n    get_client,\n    get_fake_email_domain,\n    get_realm,\n    get_source_profile,\n    get_stream,\n    get_system_bot,\n    get_user,\n    get_user_by_delivery_email,\n    get_user_by_id_in_realm_including_cross_realm,\n)\n\nK = TypeVar(\"K\")\nV = TypeVar(\"V\")\n\n\ndef find_dict(lst: Iterable[Dict[K, V]], k: K, v: V) -> Dict[K, V]:\n    for dct in lst:\n        if dct[k] == v:\n            return dct\n    raise AssertionError(f\"Cannot find element in list where key {k} == {v}\")\n\n\nclass PermissionTest(ZulipTestCase):\n    def test_role_setters(self) -> None:\n        user_profile = self.example_user(\"hamlet\")\n\n        user_profile.is_realm_admin = True\n        self.assertEqual(user_profile.is_realm_admin, True)\n        self.assertEqual(user_profile.role, UserProfile.ROLE_REALM_ADMINISTRATOR)\n\n        user_profile.is_guest = False\n        self.assertEqual(user_profile.is_guest, False)\n        self.assertEqual(user_profile.role, UserProfile.ROLE_REALM_ADMINISTRATOR)\n\n        user_profile.is_realm_owner = False\n        self.assertEqual(user_profile.is_realm_owner, False)\n        self.assertEqual(user_profile.role, UserProfile.ROLE_REALM_ADMINISTRATOR)\n\n        user_profile.is_moderator = False\n        self.assertEqual(user_profile.is_moderator, False)\n        self.assertEqual(user_profile.role, UserProfile.ROLE_REALM_ADMINISTRATOR)\n\n        user_profile.is_realm_admin = False\n        self.assertEqual(user_profile.is_realm_admin, False)\n        self.assertEqual(user_profile.role, UserProfile.ROLE_MEMBER)\n\n        user_profile.is_guest = True\n        self.assertEqual(user_profile.is_guest, True)\n        self.assertEqual(user_profile.role, UserProfile.ROLE_GUEST)\n\n        user_profile.is_realm_admin = False\n        self.assertEqual(user_profile.is_guest, True)\n        self.assertEqual(user_profile.role, UserProfile.ROLE_GUEST)\n\n        user_profile.is_guest = False\n        self.assertEqual(user_profile.is_guest, False)\n        self.assertEqual(user_profile.role, UserProfile.ROLE_MEMBER)\n\n        user_profile.is_realm_owner = True\n        self.assertEqual(user_profile.is_realm_owner, True)\n        self.assertEqual(user_profile.role, UserProfile.ROLE_REALM_OWNER)\n\n        user_profile.is_realm_owner = False\n        self.assertEqual(user_profile.is_realm_owner, False)\n        self.assertEqual(user_profile.role, UserProfile.ROLE_MEMBER)\n\n        user_profile.is_moderator = True\n        self.assertEqual(user_profile.is_moderator, True)\n        self.assertEqual(user_profile.role, UserProfile.ROLE_MODERATOR)\n\n        user_profile.is_moderator = False\n        self.assertEqual(user_profile.is_moderator, False)\n        self.assertEqual(user_profile.role, UserProfile.ROLE_MEMBER)\n\n    def test_get_admin_users(self) -> None:\n        user_profile = self.example_user(\"hamlet\")\n        do_change_user_role(user_profile, UserProfile.ROLE_MEMBER, acting_user=None)\n        self.assertFalse(user_profile.is_realm_owner)\n        admin_users = user_profile.realm.get_human_admin_users()\n        self.assertFalse(user_profile in admin_users)\n        admin_users = user_profile.realm.get_admin_users_and_bots()\n        self.assertFalse(user_profile in admin_users)\n\n        do_change_user_role(user_profile, UserProfile.ROLE_REALM_ADMINISTRATOR, acting_user=None)\n        self.assertFalse(user_profile.is_realm_owner)\n        admin_users = user_profile.realm.get_human_admin_users()\n        self.assertTrue(user_profile in admin_users)\n        admin_users = user_profile.realm.get_admin_users_and_bots()\n        self.assertTrue(user_profile in admin_users)\n\n        do_change_user_role(user_profile, UserProfile.ROLE_REALM_OWNER, acting_user=None)\n        self.assertTrue(user_profile.is_realm_owner)\n        admin_users = user_profile.realm.get_human_admin_users()\n        self.assertTrue(user_profile in admin_users)\n        admin_users = user_profile.realm.get_human_admin_users(include_realm_owners=False)\n        self.assertFalse(user_profile in admin_users)\n        admin_users = user_profile.realm.get_admin_users_and_bots()\n        self.assertTrue(user_profile in admin_users)\n        admin_users = user_profile.realm.get_admin_users_and_bots(include_realm_owners=False)\n        self.assertFalse(user_profile in admin_users)\n\n    def test_get_first_human_user(self) -> None:\n        realm = get_realm(\"zulip\")\n        UserProfile.objects.filter(realm=realm).delete()\n\n        UserProfile.objects.create(\n            realm=realm, email=\"bot1@zulip.com\", delivery_email=\"bot1@zulip.com\", is_bot=True\n        )\n        first_human_user = UserProfile.objects.create(\n            realm=realm, email=\"user1@zulip.com\", delivery_email=\"user1@zulip.com\", is_bot=False\n        )\n        UserProfile.objects.create(\n            realm=realm, email=\"user2@zulip.com\", delivery_email=\"user2@zulip.com\", is_bot=False\n        )\n        UserProfile.objects.create(\n            realm=realm, email=\"bot2@zulip.com\", delivery_email=\"bot2@zulip.com\", is_bot=True\n        )\n        self.assertEqual(first_human_user, realm.get_first_human_user())\n\n    def test_updating_non_existent_user(self) -> None:\n        self.login(\"hamlet\")\n        admin = self.example_user(\"hamlet\")\n        do_change_user_role(admin, UserProfile.ROLE_REALM_ADMINISTRATOR, acting_user=None)\n\n        invalid_user_id = 1000\n        result = self.client_patch(f\"/json/users/{invalid_user_id}\", {})\n        self.assert_json_error(result, \"No such user\")\n\n    def test_owner_api(self) -> None:\n        self.login(\"iago\")\n\n        desdemona = self.example_user(\"desdemona\")\n        othello = self.example_user(\"othello\")\n        iago = self.example_user(\"iago\")\n        realm = iago.realm\n\n        do_change_user_role(iago, UserProfile.ROLE_REALM_OWNER, acting_user=None)\n\n        result = self.client_get(\"/json/users\")\n        self.assert_json_success(result)\n        members = result.json()[\"members\"]\n        iago_dict = find_dict(members, \"email\", iago.email)\n        self.assertTrue(iago_dict[\"is_owner\"])\n        othello_dict = find_dict(members, \"email\", othello.email)\n        self.assertFalse(othello_dict[\"is_owner\"])\n\n        req = dict(role=UserProfile.ROLE_REALM_OWNER)\n        events: List[Mapping[str, Any]] = []\n        with self.tornado_redirected_to_list(events, expected_num_events=4):\n            result = self.client_patch(f\"/json/users/{othello.id}\", req)\n        self.assert_json_success(result)\n        owner_users = realm.get_human_owner_users()\n        self.assertTrue(othello in owner_users)\n        person = events[0][\"event\"][\"person\"]\n        self.assertEqual(person[\"user_id\"], othello.id)\n        self.assertEqual(person[\"role\"], UserProfile.ROLE_REALM_OWNER)\n\n        req = dict(role=UserProfile.ROLE_MEMBER)\n        with self.tornado_redirected_to_list(events, expected_num_events=4):\n            result = self.client_patch(f\"/json/users/{othello.id}\", req)\n        self.assert_json_success(result)\n        owner_users = realm.get_human_owner_users()\n        self.assertFalse(othello in owner_users)\n        person = events[0][\"event\"][\"person\"]\n        self.assertEqual(person[\"user_id\"], othello.id)\n        self.assertEqual(person[\"role\"], UserProfile.ROLE_MEMBER)\n\n        # Cannot take away from last owner\n        self.login(\"desdemona\")\n        req = dict(role=UserProfile.ROLE_MEMBER)\n        with self.tornado_redirected_to_list(events, expected_num_events=4):\n            result = self.client_patch(f\"/json/users/{iago.id}\", req)\n        self.assert_json_success(result)\n        owner_users = realm.get_human_owner_users()\n        self.assertFalse(iago in owner_users)\n        person = events[0][\"event\"][\"person\"]\n        self.assertEqual(person[\"user_id\"], iago.id)\n        self.assertEqual(person[\"role\"], UserProfile.ROLE_MEMBER)\n        with self.tornado_redirected_to_list([], expected_num_events=0):\n            result = self.client_patch(f\"/json/users/{desdemona.id}\", req)\n        self.assert_json_error(\n            result, \"The owner permission cannot be removed from the only organization owner.\"\n        )\n\n        do_change_user_role(iago, UserProfile.ROLE_REALM_ADMINISTRATOR, acting_user=None)\n        self.login(\"iago\")\n        with self.tornado_redirected_to_list([], expected_num_events=0):\n            result = self.client_patch(f\"/json/users/{desdemona.id}\", req)\n        self.assert_json_error(result, \"Must be an organization owner\")\n\n    def test_admin_api(self) -> None:\n        self.login(\"desdemona\")\n\n        hamlet = self.example_user(\"hamlet\")\n        othello = self.example_user(\"othello\")\n        desdemona = self.example_user(\"desdemona\")\n        realm = hamlet.realm\n\n        # Make sure we see is_admin flag in /json/users\n        result = self.client_get(\"/json/users\")\n        self.assert_json_success(result)\n        members = result.json()[\"members\"]\n        desdemona_dict = find_dict(members, \"email\", desdemona.email)\n        self.assertTrue(desdemona_dict[\"is_admin\"])\n        othello_dict = find_dict(members, \"email\", othello.email)\n        self.assertFalse(othello_dict[\"is_admin\"])\n\n        # Giveth\n        req = dict(role=orjson.dumps(UserProfile.ROLE_REALM_ADMINISTRATOR).decode())\n\n        events: List[Mapping[str, Any]] = []\n        with self.tornado_redirected_to_list(events, expected_num_events=4):\n            result = self.client_patch(f\"/json/users/{othello.id}\", req)\n        self.assert_json_success(result)\n        admin_users = realm.get_human_admin_users()\n        self.assertTrue(othello in admin_users)\n        person = events[0][\"event\"][\"person\"]\n        self.assertEqual(person[\"user_id\"], othello.id)\n        self.assertEqual(person[\"role\"], UserProfile.ROLE_REALM_ADMINISTRATOR)\n\n        # Taketh away\n        req = dict(role=orjson.dumps(UserProfile.ROLE_MEMBER).decode())\n        with self.tornado_redirected_to_list(events, expected_num_events=4):\n            result = self.client_patch(f\"/json/users/{othello.id}\", req)\n        self.assert_json_success(result)\n        admin_users = realm.get_human_admin_users()\n        self.assertFalse(othello in admin_users)\n        person = events[0][\"event\"][\"person\"]\n        self.assertEqual(person[\"user_id\"], othello.id)\n        self.assertEqual(person[\"role\"], UserProfile.ROLE_MEMBER)\n\n        # Make sure only admins can patch other user's info.\n        self.login(\"othello\")\n        result = self.client_patch(f\"/json/users/{hamlet.id}\", req)\n        self.assert_json_error(result, \"Insufficient permission\")\n\n    def test_admin_api_hide_emails(self) -> None:\n        reset_emails_in_zulip_realm()\n\n        user = self.example_user(\"hamlet\")\n        admin = self.example_user(\"iago\")\n        self.login_user(user)\n\n        # First, verify client_gravatar works normally\n        result = self.client_get(\"/json/users\", {\"client_gravatar\": \"true\"})\n        self.assert_json_success(result)\n        members = result.json()[\"members\"]\n        hamlet = find_dict(members, \"user_id\", user.id)\n        self.assertEqual(hamlet[\"email\"], user.email)\n        self.assertIsNone(hamlet[\"avatar_url\"])\n        self.assertNotIn(\"delivery_email\", hamlet)\n\n        # Also verify the /events code path.  This is a bit hacky, but\n        # we need to verify client_gravatar is not being overridden.\n        with mock.patch(\n            \"zerver.lib.events.request_event_queue\", return_value=None\n        ) as mock_request_event_queue:\n            with self.assertRaises(JsonableError):\n                do_events_register(user, get_client(\"website\"), client_gravatar=True)\n            self.assertEqual(mock_request_event_queue.call_args_list[0][0][3], True)\n\n        #############################################################\n        # Now, switch email address visibility, check client_gravatar\n        # is automatically disabled for the user.\n        with self.captureOnCommitCallbacks(execute=True):\n            do_set_realm_property(\n                user.realm,\n                \"email_address_visibility\",\n                Realm.EMAIL_ADDRESS_VISIBILITY_ADMINS,\n                acting_user=None,\n            )\n        result = self.client_get(\"/json/users\", {\"client_gravatar\": \"true\"})\n        self.assert_json_success(result)\n        members = result.json()[\"members\"]\n        hamlet = find_dict(members, \"user_id\", user.id)\n        self.assertEqual(hamlet[\"email\"], f\"user{user.id}@zulip.testserver\")\n        # Note that the Gravatar URL should still be computed from the\n        # `delivery_email`; otherwise, we won't be able to serve the\n        # user's Gravatar.\n        self.assertEqual(hamlet[\"avatar_url\"], get_gravatar_url(user.delivery_email, 1))\n        self.assertNotIn(\"delivery_email\", hamlet)\n\n        # Also verify the /events code path.  This is a bit hacky, but\n        # basically we want to verify client_gravatar is being\n        # overridden.\n        with mock.patch(\n            \"zerver.lib.events.request_event_queue\", return_value=None\n        ) as mock_request_event_queue:\n            with self.assertRaises(JsonableError):\n                do_events_register(user, get_client(\"website\"), client_gravatar=True)\n            self.assertEqual(mock_request_event_queue.call_args_list[0][0][3], False)\n\n        # client_gravatar is still turned off for admins.  In theory,\n        # it doesn't need to be, but client-side changes would be\n        # required in apps like the mobile apps.\n        # delivery_email is sent for admins.\n        admin.refresh_from_db()\n        user.refresh_from_db()\n        self.login_user(admin)\n        result = self.client_get(\"/json/users\", {\"client_gravatar\": \"true\"})\n        self.assert_json_success(result)\n        members = result.json()[\"members\"]\n        hamlet = find_dict(members, \"user_id\", user.id)\n        self.assertEqual(hamlet[\"email\"], f\"user{user.id}@zulip.testserver\")\n        self.assertEqual(hamlet[\"avatar_url\"], get_gravatar_url(user.delivery_email, 1))\n        self.assertEqual(hamlet[\"delivery_email\"], self.example_email(\"hamlet\"))\n\n    def test_user_cannot_promote_to_admin(self) -> None:\n        self.login(\"hamlet\")\n        req = dict(role=orjson.dumps(UserProfile.ROLE_REALM_ADMINISTRATOR).decode())\n        result = self.client_patch(\"/json/users/{}\".format(self.example_user(\"hamlet\").id), req)\n        self.assert_json_error(result, \"Insufficient permission\")\n\n    def test_admin_user_can_change_full_name(self) -> None:\n        new_name = \"new name\"\n        self.login(\"iago\")\n        hamlet = self.example_user(\"hamlet\")\n        req = dict(full_name=new_name)\n        result = self.client_patch(f\"/json/users/{hamlet.id}\", req)\n        self.assert_json_success(result)\n        hamlet = self.example_user(\"hamlet\")\n        self.assertEqual(hamlet.full_name, new_name)\n\n    def test_non_admin_cannot_change_full_name(self) -> None:\n        self.login(\"hamlet\")\n        req = dict(full_name=\"new name\")\n        result = self.client_patch(\"/json/users/{}\".format(self.example_user(\"othello\").id), req)\n        self.assert_json_error(result, \"Insufficient permission\")\n\n    def test_admin_cannot_set_long_full_name(self) -> None:\n        new_name = \"a\" * (UserProfile.MAX_NAME_LENGTH + 1)\n        self.login(\"iago\")\n        req = dict(full_name=new_name)\n        result = self.client_patch(\"/json/users/{}\".format(self.example_user(\"hamlet\").id), req)\n        self.assert_json_error(result, \"Name too long!\")\n\n    def test_admin_cannot_set_short_full_name(self) -> None:\n        new_name = \"a\"\n        self.login(\"iago\")\n        req = dict(full_name=new_name)\n        result = self.client_patch(\"/json/users/{}\".format(self.example_user(\"hamlet\").id), req)\n        self.assert_json_error(result, \"Name too short!\")\n\n    def test_not_allowed_format(self) -> None:\n        # Name of format \"Alice|999\" breaks in Markdown\n        new_name = \"iago|72\"\n        self.login(\"iago\")\n        req = dict(full_name=new_name)\n        result = self.client_patch(\"/json/users/{}\".format(self.example_user(\"hamlet\").id), req)\n        self.assert_json_error(result, \"Invalid format!\")\n\n    def test_allowed_format_complex(self) -> None:\n        # Adding characters after r'|d+' doesn't break Markdown\n        new_name = \"Hello- 12iago|72k\"\n        self.login(\"iago\")\n        req = dict(full_name=new_name)\n        result = self.client_patch(\"/json/users/{}\".format(self.example_user(\"hamlet\").id), req)\n        self.assert_json_success(result)\n\n    def test_not_allowed_format_complex(self) -> None:\n        new_name = \"Hello- 12iago|72\"\n        self.login(\"iago\")\n        req = dict(full_name=new_name)\n        result = self.client_patch(\"/json/users/{}\".format(self.example_user(\"hamlet\").id), req)\n        self.assert_json_error(result, \"Invalid format!\")\n\n    def test_admin_cannot_set_full_name_with_invalid_characters(self) -> None:\n        new_name = \"Opheli*\"\n        self.login(\"iago\")\n        req = dict(full_name=new_name)\n        result = self.client_patch(\"/json/users/{}\".format(self.example_user(\"hamlet\").id), req)\n        self.assert_json_error(result, \"Invalid characters in name!\")\n\n    def test_access_user_by_id(self) -> None:\n        iago = self.example_user(\"iago\")\n\n        # Must be a valid user ID in the realm\n        with self.assertRaises(JsonableError):\n            access_user_by_id(iago, 1234, for_admin=False)\n        with self.assertRaises(JsonableError):\n            access_user_by_id(iago, self.mit_user(\"sipbtest\").id, for_admin=False)\n\n        # Can only access bot users if allow_bots is passed\n        bot = self.example_user(\"default_bot\")\n        access_user_by_id(iago, bot.id, allow_bots=True, for_admin=True)\n        with self.assertRaises(JsonableError):\n            access_user_by_id(iago, bot.id, for_admin=True)\n\n        # Can only access deactivated users if allow_deactivated is passed\n        hamlet = self.example_user(\"hamlet\")\n        do_deactivate_user(hamlet, acting_user=None)\n        with self.assertRaises(JsonableError):\n            access_user_by_id(iago, hamlet.id, for_admin=False)\n        with self.assertRaises(JsonableError):\n            access_user_by_id(iago, hamlet.id, for_admin=True)\n        access_user_by_id(iago, hamlet.id, allow_deactivated=True, for_admin=True)\n\n        # Non-admin user can't admin another user\n        with self.assertRaises(JsonableError):\n            access_user_by_id(\n                self.example_user(\"cordelia\"), self.example_user(\"aaron\").id, for_admin=True\n            )\n        # But does have read-only access to it.\n        access_user_by_id(\n            self.example_user(\"cordelia\"), self.example_user(\"aaron\").id, for_admin=False\n        )\n\n    def check_property_for_role(self, user_profile: UserProfile, role: int) -> bool:\n        if role == UserProfile.ROLE_REALM_ADMINISTRATOR:\n            return (\n                user_profile.is_realm_admin\n                and not user_profile.is_guest\n                and not user_profile.is_realm_owner\n                and not user_profile.is_moderator\n            )\n        elif role == UserProfile.ROLE_REALM_OWNER:\n            return (\n                user_profile.is_realm_owner\n                and user_profile.is_realm_admin\n                and not user_profile.is_moderator\n                and not user_profile.is_guest\n            )\n        elif role == UserProfile.ROLE_MODERATOR:\n            return (\n                user_profile.is_moderator\n                and not user_profile.is_realm_owner\n                and not user_profile.is_realm_admin\n                and not user_profile.is_guest\n            )\n\n        if role == UserProfile.ROLE_MEMBER:\n            return (\n                not user_profile.is_guest\n                and not user_profile.is_moderator\n                and not user_profile.is_realm_admin\n                and not user_profile.is_realm_owner\n            )\n\n        assert role == UserProfile.ROLE_GUEST\n        return (\n            user_profile.is_guest\n            and not user_profile.is_moderator\n            and not user_profile.is_realm_admin\n            and not user_profile.is_realm_owner\n        )\n\n    def check_user_role_change(\n        self,\n        user_email: str,\n        new_role: int,\n    ) -> None:\n        self.login(\"desdemona\")\n\n        user_profile = self.example_user(user_email)\n        old_role = user_profile.role\n        old_system_group = get_system_user_group_for_user(user_profile)\n\n        self.assertTrue(self.check_property_for_role(user_profile, old_role))\n        self.assertTrue(\n            UserGroupMembership.objects.filter(\n                user_profile=user_profile, user_group=old_system_group\n            ).exists()\n        )\n\n        req = dict(role=orjson.dumps(new_role).decode())\n        events: List[Mapping[str, Any]] = []\n        num_events = 3\n        if UserProfile.ROLE_MEMBER in [old_role, new_role]:\n            num_events = 4\n        with self.tornado_redirected_to_list(events, expected_num_events=num_events):\n            result = self.client_patch(f\"/json/users/{user_profile.id}\", req)\n        self.assert_json_success(result)\n\n        user_profile = self.example_user(user_email)\n        self.assertTrue(self.check_property_for_role(user_profile, new_role))\n        system_group = get_system_user_group_for_user(user_profile)\n        self.assertTrue(\n            UserGroupMembership.objects.filter(\n                user_profile=user_profile, user_group=system_group\n            ).exists()\n        )\n\n        person = events[0][\"event\"][\"person\"]\n        self.assertEqual(person[\"user_id\"], user_profile.id)\n        self.assertTrue(person[\"role\"], new_role)\n\n    def test_change_regular_member_to_guest(self) -> None:\n        self.check_user_role_change(\"hamlet\", UserProfile.ROLE_GUEST)\n\n    def test_change_guest_to_regular_member(self) -> None:\n        self.check_user_role_change(\"polonius\", UserProfile.ROLE_MEMBER)\n\n    def test_change_admin_to_guest(self) -> None:\n        self.check_user_role_change(\"iago\", UserProfile.ROLE_GUEST)\n\n    def test_change_guest_to_admin(self) -> None:\n        self.check_user_role_change(\"polonius\", UserProfile.ROLE_REALM_ADMINISTRATOR)\n\n    def test_change_owner_to_guest(self) -> None:\n        self.login(\"desdemona\")\n        iago = self.example_user(\"iago\")\n        do_change_user_role(iago, UserProfile.ROLE_REALM_OWNER, acting_user=None)\n        self.check_user_role_change(\"iago\", UserProfile.ROLE_GUEST)\n\n    def test_change_guest_to_owner(self) -> None:\n        self.check_user_role_change(\"polonius\", UserProfile.ROLE_REALM_OWNER)\n\n    def test_change_admin_to_owner(self) -> None:\n        self.check_user_role_change(\"iago\", UserProfile.ROLE_REALM_OWNER)\n\n    def test_change_owner_to_admin(self) -> None:\n        self.login(\"desdemona\")\n        iago = self.example_user(\"iago\")\n        do_change_user_role(iago, UserProfile.ROLE_REALM_OWNER, acting_user=None)\n        self.check_user_role_change(\"iago\", UserProfile.ROLE_REALM_ADMINISTRATOR)\n\n    def test_change_owner_to_moderator(self) -> None:\n        iago = self.example_user(\"iago\")\n        do_change_user_role(iago, UserProfile.ROLE_REALM_OWNER, acting_user=None)\n        self.check_user_role_change(\"iago\", UserProfile.ROLE_MODERATOR)\n\n    def test_change_moderator_to_owner(self) -> None:\n        self.check_user_role_change(\"shiva\", UserProfile.ROLE_REALM_OWNER)\n\n    def test_change_admin_to_moderator(self) -> None:\n        self.check_user_role_change(\"iago\", UserProfile.ROLE_MODERATOR)\n\n    def test_change_moderator_to_admin(self) -> None:\n        self.check_user_role_change(\"shiva\", UserProfile.ROLE_REALM_ADMINISTRATOR)\n\n    def test_change_guest_to_moderator(self) -> None:\n        self.check_user_role_change(\"polonius\", UserProfile.ROLE_MODERATOR)\n\n    def test_change_moderator_to_guest(self) -> None:\n        self.check_user_role_change(\"shiva\", UserProfile.ROLE_GUEST)\n\n    def test_admin_user_can_change_profile_data(self) -> None:\n        realm = get_realm(\"zulip\")\n        self.login(\"iago\")\n        new_profile_data = []\n        cordelia = self.example_user(\"cordelia\")\n\n        # Test for all type of data\n        fields = {\n            \"Phone number\": \"short text data\",\n            \"Biography\": \"long text data\",\n            \"Favorite food\": \"short text data\",\n            \"Favorite editor\": \"vim\",\n            \"Birthday\": \"1909-03-05\",\n            \"Favorite website\": \"https://zulip.com\",\n            \"Mentor\": [cordelia.id],\n            \"GitHub\": \"timabbott\",\n        }\n\n        for field_name in fields:\n            field = CustomProfileField.objects.get(name=field_name, realm=realm)\n            new_profile_data.append(\n                {\n                    \"id\": field.id,\n                    \"value\": fields[field_name],\n                }\n            )\n\n        result = self.client_patch(\n            f\"/json/users/{cordelia.id}\", {\"profile_data\": orjson.dumps(new_profile_data).decode()}\n        )\n        self.assert_json_success(result)\n\n        cordelia = self.example_user(\"cordelia\")\n        for field_dict in cordelia.profile_data():\n            with self.subTest(field_name=field_dict[\"name\"]):\n                self.assertEqual(field_dict[\"value\"], fields[field_dict[\"name\"]])\n\n        # Test admin user cannot set invalid profile data\n        invalid_fields = [\n            (\n                \"Favorite editor\",\n                \"invalid choice\",\n                \"'invalid choice' is not a valid choice for 'Favorite editor'.\",\n            ),\n            (\"Birthday\", \"1909-34-55\", \"Birthday is not a date\"),\n            (\"Favorite website\", \"not url\", \"Favorite website is not a URL\"),\n            (\"Mentor\", \"not list of user ids\", \"User IDs is not a list\"),\n        ]\n\n        for field_name, field_value, error_msg in invalid_fields:\n            new_profile_data = []\n            field = CustomProfileField.objects.get(name=field_name, realm=realm)\n            new_profile_data.append(\n                {\n                    \"id\": field.id,\n                    \"value\": field_value,\n                }\n            )\n\n            result = self.client_patch(\n                f\"/json/users/{cordelia.id}\",\n                {\"profile_data\": orjson.dumps(new_profile_data).decode()},\n            )\n            self.assert_json_error(result, error_msg)\n\n        # non-existent field and no data\n        invalid_profile_data = [\n            {\n                \"id\": 9001,\n                \"value\": \"\",\n            }\n        ]\n        result = self.client_patch(\n            f\"/json/users/{cordelia.id}\",\n            {\"profile_data\": orjson.dumps(invalid_profile_data).decode()},\n        )\n        self.assert_json_error(result, \"Field id 9001 not found.\")\n\n        # non-existent field and data\n        invalid_profile_data = [\n            {\n                \"id\": 9001,\n                \"value\": \"some data\",\n            }\n        ]\n        result = self.client_patch(\n            f\"/json/users/{cordelia.id}\",\n            {\"profile_data\": orjson.dumps(invalid_profile_data).decode()},\n        )\n        self.assert_json_error(result, \"Field id 9001 not found.\")\n\n        # Test for clearing/resetting field values.\n        empty_profile_data = []\n        for field_name in fields:\n            field = CustomProfileField.objects.get(name=field_name, realm=realm)\n            value: Union[str, None, List[Any]] = \"\"\n            if field.field_type == CustomProfileField.USER:\n                value = []\n            empty_profile_data.append(\n                {\n                    \"id\": field.id,\n                    \"value\": value,\n                }\n            )\n        result = self.client_patch(\n            f\"/json/users/{cordelia.id}\",\n            {\"profile_data\": orjson.dumps(empty_profile_data).decode()},\n        )\n        self.assert_json_success(result)\n        for field_dict in cordelia.profile_data():\n            with self.subTest(field_name=field_dict[\"name\"]):\n                self.assertEqual(field_dict[\"value\"], None)\n\n        # Test adding some of the field values after removing all.\n        hamlet = self.example_user(\"hamlet\")\n        new_fields = {\n            \"Phone number\": None,\n            \"Biography\": \"A test user\",\n            \"Favorite food\": None,\n            \"Favorite editor\": None,\n            \"Birthday\": None,\n            \"Favorite website\": \"https://zulip.github.io\",\n            \"Mentor\": [hamlet.id],\n            \"GitHub\": \"timabbott\",\n        }\n        new_profile_data = []\n        for field_name in fields:\n            field = CustomProfileField.objects.get(name=field_name, realm=realm)\n            value = None\n            if new_fields[field_name]:\n                value = new_fields[field_name]\n            new_profile_data.append(\n                {\n                    \"id\": field.id,\n                    \"value\": value,\n                }\n            )\n        result = self.client_patch(\n            f\"/json/users/{cordelia.id}\", {\"profile_data\": orjson.dumps(new_profile_data).decode()}\n        )\n        self.assert_json_success(result)\n        for field_dict in cordelia.profile_data():\n            with self.subTest(field_name=field_dict[\"name\"]):\n                self.assertEqual(field_dict[\"value\"], new_fields[str(field_dict[\"name\"])])\n\n    def test_non_admin_user_cannot_change_profile_data(self) -> None:\n        self.login(\"cordelia\")\n        hamlet = self.example_user(\"hamlet\")\n        realm = get_realm(\"zulip\")\n\n        new_profile_data = []\n        field = CustomProfileField.objects.get(name=\"Biography\", realm=realm)\n        new_profile_data.append(\n            {\n                \"id\": field.id,\n                \"value\": \"New hamlet Biography\",\n            }\n        )\n        result = self.client_patch(\n            f\"/json/users/{hamlet.id}\", {\"profile_data\": orjson.dumps(new_profile_data).decode()}\n        )\n        self.assert_json_error(result, \"Insufficient permission\")\n\n        result = self.client_patch(\n            \"/json/users/{}\".format(self.example_user(\"cordelia\").id),\n            {\"profile_data\": orjson.dumps(new_profile_data).decode()},\n        )\n        self.assert_json_error(result, \"Insufficient permission\")\n\n\nclass QueryCountTest(ZulipTestCase):\n    def test_create_user_with_multiple_streams(self) -> None:\n        # add_new_user_history needs messages to be current\n        Message.objects.all().update(date_sent=timezone_now())\n\n        ContentType.objects.clear_cache()\n\n        # This just focuses on making sure we don't too many\n        # queries/cache tries or send too many events.\n        realm = get_realm(\"zulip\")\n\n        self.make_stream(\"private_stream1\", invite_only=True)\n        self.make_stream(\"private_stream2\", invite_only=True)\n\n        stream_names = [\n            \"Denmark\",\n            \"Scotland\",\n            \"Verona\",\n            \"private_stream1\",\n            \"private_stream2\",\n        ]\n        streams = [get_stream(stream_name, realm) for stream_name in stream_names]\n\n        invite_expires_in_days = 4\n        do_invite_users(\n            user_profile=self.example_user(\"hamlet\"),\n            invitee_emails=[\"fred@zulip.com\"],\n            streams=streams,\n            invite_expires_in_days=invite_expires_in_days,\n        )\n\n        prereg_user = PreregistrationUser.objects.get(email=\"fred@zulip.com\")\n\n        events: List[Mapping[str, Any]] = []\n\n        with queries_captured() as queries:\n            with cache_tries_captured() as cache_tries:\n                with self.tornado_redirected_to_list(events, expected_num_events=10):\n                    fred = do_create_user(\n                        email=\"fred@zulip.com\",\n                        password=\"password\",\n                        realm=realm,\n                        full_name=\"Fred Flintstone\",\n                        prereg_user=prereg_user,\n                        acting_user=None,\n                    )\n\n        self.assert_length(queries, 90)\n        self.assert_length(cache_tries, 29)\n\n        peer_add_events = [event for event in events if event[\"event\"].get(\"op\") == \"peer_add\"]\n\n        notifications = set()\n        for event in peer_add_events:\n            stream_ids = event[\"event\"][\"stream_ids\"]\n            stream_names = sorted(Stream.objects.get(id=stream_id).name for stream_id in stream_ids)\n            self.assertTrue(event[\"event\"][\"user_ids\"], {fred.id})\n            notifications.add(\",\".join(stream_names))\n\n        self.assertEqual(\n            notifications, {\"Denmark,Scotland,Verona\", \"private_stream1\", \"private_stream2\"}\n        )\n\n\nclass BulkCreateUserTest(ZulipTestCase):\n    def test_create_users(self) -> None:\n        realm = get_realm(\"zulip\")\n        realm.email_address_visibility = Realm.EMAIL_ADDRESS_VISIBILITY_ADMINS\n        realm.save()\n\n        name_list = [\n            (\"Fred Flintstone\", \"fred@zulip.com\"),\n            (\"Lisa Simpson\", \"lisa@zulip.com\"),\n        ]\n\n        create_users(realm, name_list)\n\n        fred = get_user_by_delivery_email(\"fred@zulip.com\", realm)\n        self.assertEqual(\n            fred.email,\n            f\"user{fred.id}@zulip.testserver\",\n        )\n\n        lisa = get_user_by_delivery_email(\"lisa@zulip.com\", realm)\n        self.assertEqual(lisa.full_name, \"Lisa Simpson\")\n        self.assertEqual(lisa.is_bot, False)\n        self.assertEqual(lisa.bot_type, None)\n\n        realm.email_address_visibility = Realm.EMAIL_ADDRESS_VISIBILITY_EVERYONE\n        realm.save()\n\n        name_list = [\n            (\"Bono\", \"bono@zulip.com\"),\n            (\"Cher\", \"cher@zulip.com\"),\n        ]\n\n        create_users(realm, name_list)\n        bono = get_user_by_delivery_email(\"bono@zulip.com\", realm)\n        self.assertEqual(bono.email, \"bono@zulip.com\")\n        self.assertEqual(bono.delivery_email, \"bono@zulip.com\")\n\n        cher = get_user_by_delivery_email(\"cher@zulip.com\", realm)\n        self.assertEqual(cher.full_name, \"Cher\")\n\n\nclass AdminCreateUserTest(ZulipTestCase):\n    def test_create_user_backend(self) -> None:\n\n        # This test should give us complete coverage on\n        # create_user_backend.  It mostly exercises error\n        # conditions, and it also does a basic test of the success\n        # path.\n\n        admin = self.example_user(\"hamlet\")\n        realm = admin.realm\n        self.login_user(admin)\n        do_change_user_role(admin, UserProfile.ROLE_REALM_ADMINISTRATOR, acting_user=None)\n        valid_params = dict(\n            email=\"romeo@zulip.net\",\n            password=\"xxxx\",\n            full_name=\"Romeo Montague\",\n        )\n\n        self.assertEqual(admin.can_create_users, False)\n        result = self.client_post(\"/json/users\", valid_params)\n        self.assert_json_error(result, \"User not authorized for this query\")\n\n        do_change_can_create_users(admin, True)\n        # can_create_users is insufficient without being a realm administrator:\n        do_change_user_role(admin, UserProfile.ROLE_MEMBER, acting_user=None)\n        result = self.client_post(\"/json/users\", valid_params)\n        self.assert_json_error(result, \"Must be an organization administrator\")\n\n        do_change_user_role(admin, UserProfile.ROLE_REALM_ADMINISTRATOR, acting_user=None)\n\n        result = self.client_post(\"/json/users\", {})\n        self.assert_json_error(result, \"Missing 'email' argument\")\n\n        result = self.client_post(\n            \"/json/users\",\n            dict(\n                email=\"romeo@not-zulip.com\",\n            ),\n        )\n        self.assert_json_error(result, \"Missing 'password' argument\")\n\n        result = self.client_post(\n            \"/json/users\",\n            dict(\n                email=\"romeo@not-zulip.com\",\n                password=\"xxxx\",\n            ),\n        )\n        self.assert_json_error(result, \"Missing 'full_name' argument\")\n\n        # Test short_name gets properly ignored\n        result = self.client_post(\n            \"/json/users\",\n            dict(\n                email=\"romeo@zulip.com\",\n                password=\"xxxx\",\n                full_name=\"Romeo Montague\",\n                short_name=\"DEPRECATED\",\n            ),\n        )\n        self.assert_json_success(result)\n\n        result = self.client_post(\n            \"/json/users\",\n            dict(\n                email=\"broken\",\n                password=\"xxxx\",\n                full_name=\"Romeo Montague\",\n            ),\n        )\n        self.assert_json_error(result, \"Bad name or username\")\n\n        do_set_realm_property(realm, \"emails_restricted_to_domains\", True, acting_user=None)\n        result = self.client_post(\n            \"/json/users\",\n            dict(\n                email=\"romeo@not-zulip.com\",\n                password=\"xxxx\",\n                full_name=\"Romeo Montague\",\n            ),\n        )\n        self.assert_json_error(\n            result, \"Email 'romeo@not-zulip.com' not allowed in this organization\"\n        )\n\n        RealmDomain.objects.create(realm=get_realm(\"zulip\"), domain=\"zulip.net\")\n        # Check can't use a bad password with zxcvbn enabled\n        with self.settings(PASSWORD_MIN_LENGTH=6, PASSWORD_MIN_GUESSES=1000):\n            result = self.client_post(\"/json/users\", valid_params)\n            self.assert_json_error(result, \"The password is too weak.\")\n\n        result = self.client_post(\"/json/users\", valid_params)\n        self.assert_json_success(result)\n\n        # Romeo is a newly registered user\n        new_user = get_user_by_delivery_email(\"romeo@zulip.net\", get_realm(\"zulip\"))\n        result = orjson.loads(result.content)\n        self.assertEqual(new_user.full_name, \"Romeo Montague\")\n        self.assertEqual(new_user.id, result[\"user_id\"])\n\n        # Make sure the recipient field is set correctly.\n        self.assertEqual(\n            new_user.recipient, Recipient.objects.get(type=Recipient.PERSONAL, type_id=new_user.id)\n        )\n\n        # we can't create the same user twice.\n        result = self.client_post(\"/json/users\", valid_params)\n        self.assert_json_error(result, \"Email 'romeo@zulip.net' already in use\")\n\n        # Don't allow user to sign up with disposable email.\n        realm.emails_restricted_to_domains = False\n        realm.disallow_disposable_email_addresses = True\n        realm.save()\n\n        valid_params[\"email\"] = \"abc@mailnator.com\"\n        result = self.client_post(\"/json/users\", valid_params)\n        self.assert_json_error(\n            result, \"Disposable email addresses are not allowed in this organization\"\n        )\n\n        # Don't allow creating a user with + in their email address when realm\n        # is restricted to a domain.\n        realm.emails_restricted_to_domains = True\n        realm.save()\n\n        valid_params[\"email\"] = \"iago+label@zulip.com\"\n        result = self.client_post(\"/json/users\", valid_params)\n        self.assert_json_error(result, \"Email addresses containing + are not allowed.\")\n\n        # Users can be created with + in their email address when realm\n        # is not restricted to a domain.\n        realm.emails_restricted_to_domains = False\n        realm.save()\n\n        valid_params[\"email\"] = \"iago+label@zulip.com\"\n        result = self.client_post(\"/json/users\", valid_params)\n        self.assert_json_success(result)\n\n\nclass UserProfileTest(ZulipTestCase):\n    def test_valid_user_id(self) -> None:\n        realm = get_realm(\"zulip\")\n        hamlet = self.example_user(\"hamlet\")\n        othello = self.example_user(\"othello\")\n        bot = self.example_user(\"default_bot\")\n\n        # Invalid user ID\n        invalid_uid: object = 1000\n        with self.assertRaisesRegex(ValidationError, r\"User IDs is not a list\"):\n            check_valid_user_ids(realm.id, invalid_uid)\n        with self.assertRaisesRegex(ValidationError, rf\"Invalid user ID: {invalid_uid}\"):\n            check_valid_user_ids(realm.id, [invalid_uid])\n\n        invalid_uid = \"abc\"\n        with self.assertRaisesRegex(ValidationError, r\"User IDs\\[0\\] is not an integer\"):\n            check_valid_user_ids(realm.id, [invalid_uid])\n\n        invalid_uid = str(othello.id)\n        with self.assertRaisesRegex(ValidationError, r\"User IDs\\[0\\] is not an integer\"):\n            check_valid_user_ids(realm.id, [invalid_uid])\n\n        # User is in different realm\n        with self.assertRaisesRegex(ValidationError, rf\"Invalid user ID: {hamlet.id}\"):\n            check_valid_user_ids(get_realm(\"zephyr\").id, [hamlet.id])\n\n        # User is not active\n        change_user_is_active(hamlet, False)\n        with self.assertRaisesRegex(ValidationError, rf\"User with ID {hamlet.id} is deactivated\"):\n            check_valid_user_ids(realm.id, [hamlet.id])\n        check_valid_user_ids(realm.id, [hamlet.id], allow_deactivated=True)\n\n        # User is a bot\n        with self.assertRaisesRegex(ValidationError, rf\"User with ID {bot.id} is a bot\"):\n            check_valid_user_ids(realm.id, [bot.id])\n\n        # Successfully get non-bot, active user belong to your realm\n        check_valid_user_ids(realm.id, [othello.id])\n\n    def test_cache_invalidation(self) -> None:\n        hamlet = self.example_user(\"hamlet\")\n        with mock.patch(\"zerver.lib.cache.delete_display_recipient_cache\") as m:\n            hamlet.full_name = \"Hamlet Junior\"\n            hamlet.save(update_fields=[\"full_name\"])\n\n        self.assertTrue(m.called)\n\n        with mock.patch(\"zerver.lib.cache.delete_display_recipient_cache\") as m:\n            hamlet.long_term_idle = True\n            hamlet.save(update_fields=[\"long_term_idle\"])\n\n        self.assertFalse(m.called)\n\n    def test_user_ids_to_users(self) -> None:\n        real_user_ids = [\n            self.example_user(\"hamlet\").id,\n            self.example_user(\"cordelia\").id,\n        ]\n\n        self.assertEqual(user_ids_to_users([], get_realm(\"zulip\")), [])\n        self.assertEqual(\n            {\n                user_profile.id\n                for user_profile in user_ids_to_users(real_user_ids, get_realm(\"zulip\"))\n            },\n            set(real_user_ids),\n        )\n        with self.assertRaises(JsonableError):\n            user_ids_to_users([1234], get_realm(\"zephyr\"))\n        with self.assertRaises(JsonableError):\n            user_ids_to_users(real_user_ids, get_realm(\"zephyr\"))\n\n    def test_bulk_get_users(self) -> None:\n        from zerver.lib.users import bulk_get_users\n\n        hamlet = self.example_user(\"hamlet\")\n        cordelia = self.example_user(\"cordelia\")\n        webhook_bot = self.example_user(\"webhook_bot\")\n        result = bulk_get_users(\n            [hamlet.email, cordelia.email],\n            get_realm(\"zulip\"),\n        )\n        self.assertEqual(result[hamlet.email].email, hamlet.email)\n        self.assertEqual(result[cordelia.email].email, cordelia.email)\n\n        result = bulk_get_users(\n            [hamlet.email, cordelia.email, webhook_bot.email],\n            None,\n            base_query=UserProfile.objects.all(),\n        )\n        self.assertEqual(result[hamlet.email].email, hamlet.email)\n        self.assertEqual(result[cordelia.email].email, cordelia.email)\n        self.assertEqual(result[webhook_bot.email].email, webhook_bot.email)\n\n    def test_get_accounts_for_email(self) -> None:\n        reset_emails_in_zulip_realm()\n\n        def check_account_present_in_accounts(user: UserProfile, accounts: List[Accounts]) -> None:\n            for account in accounts:\n                realm = user.realm\n                if (\n                    account[\"avatar\"] == avatar_url(user)\n                    and account[\"full_name\"] == user.full_name\n                    and account[\"realm_name\"] == realm.name\n                    and account[\"realm_id\"] == realm.id\n                ):\n                    return\n            raise AssertionError(\"Account not found\")\n\n        lear_realm = get_realm(\"lear\")\n        cordelia_in_zulip = self.example_user(\"cordelia\")\n        cordelia_in_lear = get_user_by_delivery_email(\"cordelia@zulip.com\", lear_realm)\n\n        email = \"cordelia@zulip.com\"\n        accounts = get_accounts_for_email(email)\n        self.assert_length(accounts, 2)\n        check_account_present_in_accounts(cordelia_in_zulip, accounts)\n        check_account_present_in_accounts(cordelia_in_lear, accounts)\n\n        email = \"CORDelia@zulip.com\"\n        accounts = get_accounts_for_email(email)\n        self.assert_length(accounts, 2)\n        check_account_present_in_accounts(cordelia_in_zulip, accounts)\n        check_account_present_in_accounts(cordelia_in_lear, accounts)\n\n        email = \"IAGO@ZULIP.COM\"\n        accounts = get_accounts_for_email(email)\n        self.assert_length(accounts, 1)\n        check_account_present_in_accounts(self.example_user(\"iago\"), accounts)\n\n        # We verify that get_accounts_for_email don't return deactivated users accounts\n        user = self.example_user(\"hamlet\")\n        do_deactivate_user(user, acting_user=None)\n        email = self.example_email(\"hamlet\")\n        accounts = get_accounts_for_email(email)\n        with self.assertRaises(AssertionError):\n            check_account_present_in_accounts(user, accounts)\n\n    def test_get_source_profile(self) -> None:\n        reset_emails_in_zulip_realm()\n        zulip_realm_id = get_realm(\"zulip\").id\n        iago = get_source_profile(\"iago@zulip.com\", zulip_realm_id)\n        assert iago is not None\n        self.assertEqual(iago.email, \"iago@zulip.com\")\n        self.assertEqual(iago.realm, get_realm(\"zulip\"))\n\n        iago = get_source_profile(\"IAGO@ZULIP.com\", zulip_realm_id)\n        assert iago is not None\n        self.assertEqual(iago.email, \"iago@zulip.com\")\n\n        lear_realm_id = get_realm(\"lear\").id\n        cordelia = get_source_profile(\"cordelia@zulip.com\", lear_realm_id)\n        assert cordelia is not None\n        self.assertEqual(cordelia.email, \"cordelia@zulip.com\")\n\n        self.assertIsNone(get_source_profile(\"iagod@zulip.com\", zulip_realm_id))\n        self.assertIsNone(get_source_profile(\"iago@zulip.com\", 0))\n        self.assertIsNone(get_source_profile(\"iago@zulip.com\", lear_realm_id))\n\n    def test_copy_default_settings_from_another_user(self) -> None:\n        iago = self.example_user(\"iago\")\n        cordelia = self.example_user(\"cordelia\")\n        hamlet = self.example_user(\"hamlet\")\n        hamlet.color_scheme = UserProfile.COLOR_SCHEME_LIGHT\n\n        cordelia.default_language = \"de\"\n        cordelia.default_view = \"all_messages\"\n        cordelia.emojiset = \"twitter\"\n        cordelia.timezone = \"America/Phoenix\"\n        cordelia.color_scheme = UserProfile.COLOR_SCHEME_NIGHT\n        cordelia.enable_offline_email_notifications = False\n        cordelia.enable_stream_push_notifications = True\n        cordelia.enter_sends = False\n        cordelia.avatar_source = UserProfile.AVATAR_FROM_USER\n        cordelia.save()\n\n        # Upload cordelia's avatar\n        with get_test_image_file(\"img.png\") as image_file:\n            upload_avatar_image(image_file, cordelia, cordelia)\n\n        UserHotspot.objects.filter(user=cordelia).delete()\n        UserHotspot.objects.filter(user=iago).delete()\n        hotspots_completed = {\"intro_streams\", \"intro_topics\"}\n        for hotspot in hotspots_completed:\n            UserHotspot.objects.create(user=cordelia, hotspot=hotspot)\n\n        # Check that we didn't send an realm_user update events to\n        # users; this work is happening before the user account is\n        # created, so any changes will be reflected in the \"add\" event\n        # introducing the user to clients.\n        events: List[Mapping[str, Any]] = []\n        with self.tornado_redirected_to_list(events, expected_num_events=0):\n            copy_default_settings(cordelia, iago)\n\n        # We verify that cordelia and iago match, but hamlet has the defaults.\n        self.assertEqual(iago.full_name, \"Cordelia, Lear's daughter\")\n        self.assertEqual(cordelia.full_name, \"Cordelia, Lear's daughter\")\n        self.assertEqual(hamlet.full_name, \"King Hamlet\")\n\n        self.assertEqual(iago.default_language, \"de\")\n        self.assertEqual(cordelia.default_language, \"de\")\n        self.assertEqual(hamlet.default_language, \"en\")\n\n        self.assertEqual(iago.emojiset, \"twitter\")\n        self.assertEqual(cordelia.emojiset, \"twitter\")\n        self.assertEqual(hamlet.emojiset, \"google\")\n\n        self.assertEqual(iago.timezone, \"America/Phoenix\")\n        self.assertEqual(cordelia.timezone, \"America/Phoenix\")\n        self.assertEqual(hamlet.timezone, \"\")\n\n        self.assertEqual(iago.color_scheme, UserProfile.COLOR_SCHEME_NIGHT)\n        self.assertEqual(cordelia.color_scheme, UserProfile.COLOR_SCHEME_NIGHT)\n        self.assertEqual(hamlet.color_scheme, UserProfile.COLOR_SCHEME_LIGHT)\n\n        self.assertEqual(iago.enable_offline_email_notifications, False)\n        self.assertEqual(cordelia.enable_offline_email_notifications, False)\n        self.assertEqual(hamlet.enable_offline_email_notifications, True)\n\n        self.assertEqual(iago.enable_stream_push_notifications, True)\n        self.assertEqual(cordelia.enable_stream_push_notifications, True)\n        self.assertEqual(hamlet.enable_stream_push_notifications, False)\n\n        self.assertEqual(iago.enter_sends, False)\n        self.assertEqual(cordelia.enter_sends, False)\n        self.assertEqual(hamlet.enter_sends, True)\n\n        hotspots = set(UserHotspot.objects.filter(user=iago).values_list(\"hotspot\", flat=True))\n        self.assertEqual(hotspots, hotspots_completed)\n\n    def test_copy_default_settings_from_realm_user_default(self) -> None:\n        cordelia = self.example_user(\"cordelia\")\n        realm = get_realm(\"zulip\")\n        realm_user_default = RealmUserDefault.objects.get(realm=realm)\n\n        realm_user_default.default_view = \"recent_topics\"\n        realm_user_default.emojiset = \"twitter\"\n        realm_user_default.color_scheme = UserProfile.COLOR_SCHEME_LIGHT\n        realm_user_default.enable_offline_email_notifications = False\n        realm_user_default.enable_stream_push_notifications = True\n        realm_user_default.enter_sends = True\n        realm_user_default.save()\n\n        # Check that we didn't send an realm_user update events to\n        # users; this work is happening before the user account is\n        # created, so any changes will be reflected in the \"add\" event\n        # introducing the user to clients.\n        events: List[Mapping[str, Any]] = []\n        with self.tornado_redirected_to_list(events, expected_num_events=0):\n            copy_default_settings(realm_user_default, cordelia)\n\n        self.assertEqual(cordelia.default_view, \"recent_topics\")\n        self.assertEqual(cordelia.emojiset, \"twitter\")\n        self.assertEqual(cordelia.color_scheme, UserProfile.COLOR_SCHEME_LIGHT)\n        self.assertEqual(cordelia.enable_offline_email_notifications, False)\n        self.assertEqual(cordelia.enable_stream_push_notifications, True)\n        self.assertEqual(cordelia.enter_sends, True)\n\n    def test_get_user_by_id_in_realm_including_cross_realm(self) -> None:\n        realm = get_realm(\"zulip\")\n        internal_realm = get_realm(settings.SYSTEM_BOT_REALM)\n        hamlet = self.example_user(\"hamlet\")\n        othello = self.example_user(\"othello\")\n        bot = get_system_bot(settings.WELCOME_BOT, internal_realm.id)\n\n        # Pass in the ID of a cross-realm bot and a valid realm\n        cross_realm_bot = get_user_by_id_in_realm_including_cross_realm(bot.id, realm)\n        self.assertEqual(cross_realm_bot.email, bot.email)\n        self.assertEqual(cross_realm_bot.id, bot.id)\n\n        # Pass in the ID of a cross-realm bot but with a invalid realm,\n        # note that the realm should be irrelevant here\n        cross_realm_bot = get_user_by_id_in_realm_including_cross_realm(bot.id, None)\n        self.assertEqual(cross_realm_bot.email, bot.email)\n        self.assertEqual(cross_realm_bot.id, bot.id)\n\n        # Pass in the ID of a non-cross-realm user with a realm\n        user_profile = get_user_by_id_in_realm_including_cross_realm(othello.id, realm)\n        self.assertEqual(user_profile.email, othello.email)\n        self.assertEqual(user_profile.id, othello.id)\n\n        # If the realm doesn't match, or if the ID is not that of a\n        # cross-realm bot, UserProfile.DoesNotExist is raised\n        with self.assertRaises(UserProfile.DoesNotExist):\n            get_user_by_id_in_realm_including_cross_realm(hamlet.id, None)\n\n    def test_get_user_subscription_status(self) -> None:\n        self.login(\"hamlet\")\n        iago = self.example_user(\"iago\")\n        stream = get_stream(\"Rome\", iago.realm)\n\n        # Invalid user ID.\n        result = self.client_get(f\"/json/users/25/subscriptions/{stream.id}\")\n        self.assert_json_error(result, \"No such user\")\n\n        # Invalid stream ID.\n        result = self.client_get(f\"/json/users/{iago.id}/subscriptions/25\")\n        self.assert_json_error(result, \"Invalid stream id\")\n\n        result = orjson.loads(\n            self.client_get(f\"/json/users/{iago.id}/subscriptions/{stream.id}\").content\n        )\n        self.assertFalse(result[\"is_subscribed\"])\n\n        # Subscribe to the stream.\n        self.subscribe(iago, stream.name)\n        with queries_captured() as queries:\n            result = orjson.loads(\n                self.client_get(f\"/json/users/{iago.id}/subscriptions/{stream.id}\").content\n            )\n\n        self.assert_length(queries, 6)\n        self.assertTrue(result[\"is_subscribed\"])\n\n        # Logging in with a Guest user.\n        polonius = self.example_user(\"polonius\")\n        self.login(\"polonius\")\n        self.assertTrue(polonius.is_guest)\n        self.assertTrue(stream.is_web_public)\n\n        result = orjson.loads(\n            self.client_get(f\"/json/users/{iago.id}/subscriptions/{stream.id}\").content\n        )\n        self.assertTrue(result[\"is_subscribed\"])\n\n        self.login(\"iago\")\n        stream = self.make_stream(\"private_stream\", invite_only=True)\n        # Unsubscribed admin can check subscription status in a private stream.\n        result = orjson.loads(\n            self.client_get(f\"/json/users/{iago.id}/subscriptions/{stream.id}\").content\n        )\n        self.assertFalse(result[\"is_subscribed\"])\n\n        # Unsubscribed non-admins cannot check subscription status in a private stream.\n        self.login(\"shiva\")\n        result = self.client_get(f\"/json/users/{iago.id}/subscriptions/{stream.id}\")\n        self.assert_json_error(result, \"Invalid stream id\")\n\n        # Subscribed non-admins can check subscription status in a private stream\n        self.subscribe(self.example_user(\"shiva\"), stream.name)\n        result = orjson.loads(\n            self.client_get(f\"/json/users/{iago.id}/subscriptions/{stream.id}\").content\n        )\n        self.assertFalse(result[\"is_subscribed\"])\n\n\nclass ActivateTest(ZulipTestCase):\n    def test_basics(self) -> None:\n        user = self.example_user(\"hamlet\")\n        do_deactivate_user(user, acting_user=None)\n        self.assertFalse(user.is_active)\n        do_reactivate_user(user, acting_user=None)\n        self.assertTrue(user.is_active)\n\n    def test_subscriptions_is_user_active(self) -> None:\n        user = self.example_user(\"hamlet\")\n        do_deactivate_user(user, acting_user=None)\n        self.assertFalse(user.is_active)\n        self.assertTrue(Subscription.objects.filter(user_profile=user).exists())\n        self.assertFalse(\n            Subscription.objects.filter(user_profile=user, is_user_active=True).exists()\n        )\n\n        do_reactivate_user(user, acting_user=None)\n        self.assertTrue(user.is_active)\n        self.assertTrue(Subscription.objects.filter(user_profile=user).exists())\n        self.assertFalse(\n            Subscription.objects.filter(user_profile=user, is_user_active=False).exists()\n        )\n\n    def test_api(self) -> None:\n        admin = self.example_user(\"othello\")\n        do_change_user_role(admin, UserProfile.ROLE_REALM_ADMINISTRATOR, acting_user=None)\n        self.login(\"othello\")\n\n        user = self.example_user(\"hamlet\")\n        self.assertTrue(user.is_active)\n\n        result = self.client_delete(f\"/json/users/{user.id}\")\n        self.assert_json_success(result)\n        user = self.example_user(\"hamlet\")\n        self.assertFalse(user.is_active)\n\n        result = self.client_post(f\"/json/users/{user.id}/reactivate\")\n        self.assert_json_success(result)\n        user = self.example_user(\"hamlet\")\n        self.assertTrue(user.is_active)\n\n    def test_api_with_nonexistent_user(self) -> None:\n        self.login(\"iago\")\n\n        # Organization administrator cannot deactivate organization owner.\n        result = self.client_delete(f'/json/users/{self.example_user(\"desdemona\").id}')\n        self.assert_json_error(result, \"Must be an organization owner\")\n\n        iago = self.example_user(\"iago\")\n        desdemona = self.example_user(\"desdemona\")\n        do_change_user_role(iago, UserProfile.ROLE_REALM_OWNER, acting_user=None)\n\n        # Cannot deactivate a user with the bot api\n        result = self.client_delete(\"/json/bots/{}\".format(self.example_user(\"hamlet\").id))\n        self.assert_json_error(result, \"No such bot\")\n\n        # Cannot deactivate a nonexistent user.\n        invalid_user_id = 1000\n        result = self.client_delete(f\"/json/users/{invalid_user_id}\")\n        self.assert_json_error(result, \"No such user\")\n\n        result = self.client_delete(\"/json/users/{}\".format(self.example_user(\"webhook_bot\").id))\n        self.assert_json_error(result, \"No such user\")\n\n        result = self.client_delete(f\"/json/users/{desdemona.id}\")\n        self.assert_json_success(result)\n\n        result = self.client_delete(f\"/json/users/{iago.id}\")\n        self.assert_json_error(result, \"Cannot deactivate the only organization owner\")\n\n        # Cannot reactivate a nonexistent user.\n        invalid_user_id = 1000\n        result = self.client_post(f\"/json/users/{invalid_user_id}/reactivate\")\n        self.assert_json_error(result, \"No such user\")\n\n    def test_api_with_insufficient_permissions(self) -> None:\n        non_admin = self.example_user(\"othello\")\n        do_change_user_role(non_admin, UserProfile.ROLE_MEMBER, acting_user=None)\n        self.login(\"othello\")\n\n        # Cannot deactivate a user with the users api\n        result = self.client_delete(\"/json/users/{}\".format(self.example_user(\"hamlet\").id))\n        self.assert_json_error(result, \"Insufficient permission\")\n\n        # Cannot reactivate a user\n        result = self.client_post(\n            \"/json/users/{}/reactivate\".format(self.example_user(\"hamlet\").id)\n        )\n        self.assert_json_error(result, \"Insufficient permission\")\n\n    def test_revoke_invites(self) -> None:\n        \"\"\"\n        Verify that any invitations generated by the user get revoked\n        when the user is deactivated\n        \"\"\"\n        iago = self.example_user(\"iago\")\n        desdemona = self.example_user(\"desdemona\")\n\n        invite_expires_in_days = 2\n        do_invite_users(\n            iago,\n            [\"new1@zulip.com\", \"new2@zulip.com\"],\n            [],\n            invite_expires_in_days=invite_expires_in_days,\n            invite_as=PreregistrationUser.INVITE_AS[\"REALM_ADMIN\"],\n        )\n        do_invite_users(\n            desdemona,\n            [\"new3@zulip.com\", \"new4@zulip.com\"],\n            [],\n            invite_expires_in_days=invite_expires_in_days,\n            invite_as=PreregistrationUser.INVITE_AS[\"REALM_ADMIN\"],\n        )\n\n        do_invite_users(\n            iago,\n            [\"new5@zulip.com\"],\n            [],\n            invite_expires_in_days=None,\n            invite_as=PreregistrationUser.INVITE_AS[\"REALM_ADMIN\"],\n        )\n        do_invite_users(\n            desdemona,\n            [\"new6@zulip.com\"],\n            [],\n            invite_expires_in_days=None,\n            invite_as=PreregistrationUser.INVITE_AS[\"REALM_ADMIN\"],\n        )\n\n        iago_multiuse_key = do_create_multiuse_invite_link(\n            iago, PreregistrationUser.INVITE_AS[\"MEMBER\"], invite_expires_in_days\n        ).split(\"/\")[-2]\n        desdemona_multiuse_key = do_create_multiuse_invite_link(\n            desdemona, PreregistrationUser.INVITE_AS[\"MEMBER\"], invite_expires_in_days\n        ).split(\"/\")[-2]\n\n        iago_never_expire_multiuse_key = do_create_multiuse_invite_link(\n            iago, PreregistrationUser.INVITE_AS[\"MEMBER\"], None\n        ).split(\"/\")[-2]\n        desdemona_never_expire_multiuse_key = do_create_multiuse_invite_link(\n            desdemona, PreregistrationUser.INVITE_AS[\"MEMBER\"], None\n        ).split(\"/\")[-2]\n\n        self.assertEqual(\n            filter_to_valid_prereg_users(\n                PreregistrationUser.objects.filter(referred_by=iago)\n            ).count(),\n            3,\n        )\n        self.assertEqual(\n            filter_to_valid_prereg_users(\n                PreregistrationUser.objects.filter(referred_by=desdemona)\n            ).count(),\n            3,\n        )\n        self.assertTrue(\n            Confirmation.objects.get(confirmation_key=iago_multiuse_key).expiry_date\n            > timezone_now()\n        )\n        self.assertTrue(\n            Confirmation.objects.get(confirmation_key=desdemona_multiuse_key).expiry_date\n            > timezone_now()\n        )\n        self.assertIsNone(\n            Confirmation.objects.get(confirmation_key=iago_never_expire_multiuse_key).expiry_date\n        )\n        self.assertIsNone(\n            Confirmation.objects.get(\n                confirmation_key=desdemona_never_expire_multiuse_key\n            ).expiry_date\n        )\n\n        do_deactivate_user(iago, acting_user=None)\n\n        # Now we verify that invitations generated by iago were revoked, while desdemona's\n        # remain valid.\n        self.assertEqual(\n            filter_to_valid_prereg_users(\n                PreregistrationUser.objects.filter(referred_by=iago)\n            ).count(),\n            0,\n        )\n        self.assertEqual(\n            filter_to_valid_prereg_users(\n                PreregistrationUser.objects.filter(referred_by=desdemona)\n            ).count(),\n            3,\n        )\n        self.assertTrue(\n            Confirmation.objects.get(confirmation_key=iago_multiuse_key).expiry_date\n            <= timezone_now()\n        )\n        self.assertTrue(\n            Confirmation.objects.get(confirmation_key=desdemona_multiuse_key).expiry_date\n            > timezone_now()\n        )\n        self.assertTrue(\n            Confirmation.objects.get(confirmation_key=iago_never_expire_multiuse_key).expiry_date\n            <= timezone_now()\n        )\n        self.assertIsNone(\n            Confirmation.objects.get(\n                confirmation_key=desdemona_never_expire_multiuse_key\n            ).expiry_date\n        )\n\n    def test_clear_scheduled_jobs(self) -> None:\n        user = self.example_user(\"hamlet\")\n        send_future_email(\n            \"zerver/emails/followup_day1\",\n            user.realm,\n            to_user_ids=[user.id],\n            delay=datetime.timedelta(hours=1),\n        )\n        self.assertEqual(ScheduledEmail.objects.count(), 1)\n        do_deactivate_user(user, acting_user=None)\n        self.assertEqual(ScheduledEmail.objects.count(), 0)\n\n    def test_send_future_email_with_multiple_recipients(self) -> None:\n        hamlet = self.example_user(\"hamlet\")\n        iago = self.example_user(\"iago\")\n        send_future_email(\n            \"zerver/emails/followup_day1\",\n            iago.realm,\n            to_user_ids=[hamlet.id, iago.id],\n            delay=datetime.timedelta(hours=1),\n        )\n        self.assertEqual(\n            ScheduledEmail.objects.filter(users__in=[hamlet, iago]).distinct().count(), 1\n        )\n        email = ScheduledEmail.objects.all().first()\n        assert email is not None and email.users is not None\n        self.assertEqual(email.users.count(), 2)\n\n    def test_clear_schedule_emails(self) -> None:\n        hamlet = self.example_user(\"hamlet\")\n        iago = self.example_user(\"iago\")\n        send_future_email(\n            \"zerver/emails/followup_day1\",\n            iago.realm,\n            to_user_ids=[hamlet.id, iago.id],\n            delay=datetime.timedelta(hours=1),\n        )\n        self.assertEqual(ScheduledEmail.objects.count(), 1)\n        clear_scheduled_emails(hamlet.id)\n        self.assertEqual(ScheduledEmail.objects.count(), 1)\n        self.assertEqual(ScheduledEmail.objects.filter(users=hamlet).count(), 0)\n        self.assertEqual(ScheduledEmail.objects.filter(users=iago).count(), 1)\n\n    def test_deliver_scheduled_emails(self) -> None:\n        iago = self.example_user(\"iago\")\n        hamlet = self.example_user(\"hamlet\")\n        send_future_email(\n            \"zerver/emails/followup_day1\",\n            iago.realm,\n            to_user_ids=[hamlet.id, iago.id],\n            delay=datetime.timedelta(hours=1),\n        )\n        self.assertEqual(ScheduledEmail.objects.count(), 1)\n        email = ScheduledEmail.objects.all().first()\n        deliver_scheduled_emails(assert_is_not_none(email))\n        from django.core.mail import outbox\n\n        self.assert_length(outbox, 1)\n        for message in outbox:\n            self.assertEqual(\n                set(message.to),\n                {\n                    str(Address(display_name=hamlet.full_name, addr_spec=hamlet.delivery_email)),\n                    str(Address(display_name=iago.full_name, addr_spec=iago.delivery_email)),\n                },\n            )\n        self.assertEqual(ScheduledEmail.objects.count(), 0)\n\n    def test_deliver_scheduled_emails_no_addressees(self) -> None:\n        iago = self.example_user(\"iago\")\n        hamlet = self.example_user(\"hamlet\")\n        to_user_ids = [hamlet.id, iago.id]\n        send_future_email(\n            \"zerver/emails/followup_day1\",\n            iago.realm,\n            to_user_ids=to_user_ids,\n            delay=datetime.timedelta(hours=1),\n        )\n        self.assertEqual(ScheduledEmail.objects.count(), 1)\n        email = ScheduledEmail.objects.all().first()\n        assert email is not None\n        email.users.remove(*to_user_ids)\n\n        with self.assertLogs(\"zulip.send_email\", level=\"INFO\") as info_log:\n            deliver_scheduled_emails(email)\n        from django.core.mail import outbox\n\n        self.assert_length(outbox, 0)\n        self.assertEqual(ScheduledEmail.objects.count(), 1)\n        self.assertEqual(\n            info_log.output,\n            [\n                f\"ERROR:zulip.send_email:ScheduledEmail id {email.id} has empty users and address attributes.\"\n            ],\n        )\n\n\nclass RecipientInfoTest(ZulipTestCase):\n    def test_stream_recipient_info(self) -> None:\n        hamlet = self.example_user(\"hamlet\")\n        cordelia = self.example_user(\"cordelia\")\n        othello = self.example_user(\"othello\")\n\n        # These tests were written with the old default for\n        # enable_online_push_notifications; that default is better for\n        # testing the full code path anyway.\n        hamlet.enable_online_push_notifications = False\n        cordelia.enable_online_push_notifications = False\n        othello.enable_online_push_notifications = False\n        hamlet.save()\n        cordelia.save()\n        othello.save()\n\n        realm = hamlet.realm\n\n        stream_name = \"Test stream\"\n        topic_name = \"test topic\"\n\n        for user in [hamlet, cordelia, othello]:\n            self.subscribe(user, stream_name)\n\n        stream = get_stream(stream_name, realm)\n        recipient = stream.recipient\n        assert recipient is not None\n\n        stream_topic = StreamTopicTarget(\n            stream_id=stream.id,\n            topic_name=topic_name,\n        )\n\n        info = get_recipient_info(\n            realm_id=realm.id,\n            recipient=recipient,\n            sender_id=hamlet.id,\n            stream_topic=stream_topic,\n            possible_wildcard_mention=False,\n        )\n\n        all_user_ids = {hamlet.id, cordelia.id, othello.id}\n\n        expected_info = dict(\n            active_user_ids=all_user_ids,\n            online_push_user_ids=set(),\n            pm_mention_email_disabled_user_ids=set(),\n            pm_mention_push_disabled_user_ids=set(),\n            stream_push_user_ids=set(),\n            stream_email_user_ids=set(),\n            wildcard_mention_user_ids=set(),\n            muted_sender_user_ids=set(),\n            um_eligible_user_ids=all_user_ids,\n            long_term_idle_user_ids=set(),\n            default_bot_user_ids=set(),\n            service_bot_tuples=[],\n            all_bot_user_ids=set(),\n        )\n\n        self.assertEqual(info, expected_info)\n\n        hamlet.enable_offline_email_notifications = False\n        hamlet.enable_offline_push_notifications = False\n        hamlet.save()\n        info = get_recipient_info(\n            realm_id=realm.id,\n            recipient=recipient,\n            sender_id=hamlet.id,\n            stream_topic=stream_topic,\n            possible_wildcard_mention=False,\n        )\n        self.assertEqual(info[\"pm_mention_email_disabled_user_ids\"], {hamlet.id})\n        self.assertEqual(info[\"pm_mention_push_disabled_user_ids\"], {hamlet.id})\n        hamlet.enable_offline_email_notifications = True\n        hamlet.enable_offline_push_notifications = True\n        hamlet.save()\n\n        cordelia.wildcard_mentions_notify = False\n        cordelia.save()\n        hamlet.enable_stream_push_notifications = True\n        hamlet.save()\n        info = get_recipient_info(\n            realm_id=realm.id,\n            recipient=recipient,\n            sender_id=hamlet.id,\n            stream_topic=stream_topic,\n            possible_wildcard_mention=False,\n        )\n        self.assertEqual(info[\"stream_push_user_ids\"], {hamlet.id})\n        self.assertEqual(info[\"wildcard_mention_user_ids\"], set())\n\n        info = get_recipient_info(\n            realm_id=realm.id,\n            recipient=recipient,\n            sender_id=hamlet.id,\n            stream_topic=stream_topic,\n            possible_wildcard_mention=True,\n        )\n        self.assertEqual(info[\"wildcard_mention_user_ids\"], {hamlet.id, othello.id})\n\n        sub = get_subscription(stream_name, hamlet)\n        sub.push_notifications = False\n        sub.save()\n        info = get_recipient_info(\n            realm_id=realm.id,\n            recipient=recipient,\n            sender_id=hamlet.id,\n            stream_topic=stream_topic,\n        )\n        self.assertEqual(info[\"stream_push_user_ids\"], set())\n\n        hamlet.enable_stream_push_notifications = False\n        hamlet.save()\n        sub = get_subscription(stream_name, hamlet)\n        sub.push_notifications = True\n        sub.save()\n        info = get_recipient_info(\n            realm_id=realm.id,\n            recipient=recipient,\n            sender_id=hamlet.id,\n            stream_topic=stream_topic,\n        )\n        self.assertEqual(info[\"stream_push_user_ids\"], {hamlet.id})\n\n        # Now have Hamlet mute the topic to omit him from stream_push_user_ids.\n        add_topic_mute(\n            user_profile=hamlet,\n            stream_id=stream.id,\n            recipient_id=recipient.id,\n            topic_name=topic_name,\n        )\n\n        info = get_recipient_info(\n            realm_id=realm.id,\n            recipient=recipient,\n            sender_id=hamlet.id,\n            stream_topic=stream_topic,\n            possible_wildcard_mention=False,\n        )\n        self.assertEqual(info[\"stream_push_user_ids\"], set())\n        self.assertEqual(info[\"wildcard_mention_user_ids\"], set())\n\n        info = get_recipient_info(\n            realm_id=realm.id,\n            recipient=recipient,\n            sender_id=hamlet.id,\n            stream_topic=stream_topic,\n            possible_wildcard_mention=True,\n        )\n        self.assertEqual(info[\"stream_push_user_ids\"], set())\n        # Since Hamlet has muted the stream and Cordelia has disabled\n        # wildcard notifications, it should just be Othello here.\n        self.assertEqual(info[\"wildcard_mention_user_ids\"], {othello.id})\n\n        # If Hamlet mutes Cordelia, he should be in `muted_sender_user_ids` for a message\n        # sent by Cordelia.\n        do_mute_user(hamlet, cordelia)\n        info = get_recipient_info(\n            realm_id=realm.id,\n            recipient=recipient,\n            sender_id=cordelia.id,\n            stream_topic=stream_topic,\n            possible_wildcard_mention=True,\n        )\n        self.assertTrue(hamlet.id in info[\"muted_sender_user_ids\"])\n\n        sub = get_subscription(stream_name, othello)\n        sub.wildcard_mentions_notify = False\n        sub.save()\n\n        info = get_recipient_info(\n            realm_id=realm.id,\n            recipient=recipient,\n            sender_id=hamlet.id,\n            stream_topic=stream_topic,\n            possible_wildcard_mention=True,\n        )\n        self.assertEqual(info[\"stream_push_user_ids\"], set())\n        # Verify that stream-level wildcard_mentions_notify=False works correctly.\n        self.assertEqual(info[\"wildcard_mention_user_ids\"], set())\n\n        # Verify that True works as expected as well\n        sub = get_subscription(stream_name, othello)\n        sub.wildcard_mentions_notify = True\n        sub.save()\n\n        info = get_recipient_info(\n            realm_id=realm.id,\n            recipient=recipient,\n            sender_id=hamlet.id,\n            stream_topic=stream_topic,\n            possible_wildcard_mention=True,\n        )\n        self.assertEqual(info[\"stream_push_user_ids\"], set())\n        self.assertEqual(info[\"wildcard_mention_user_ids\"], {othello.id})\n\n        # Add a service bot.\n        service_bot = do_create_user(\n            email=\"service-bot@zulip.com\",\n            password=\"\",\n            realm=realm,\n            full_name=\"\",\n            bot_type=UserProfile.EMBEDDED_BOT,\n            acting_user=None,\n        )\n\n        info = get_recipient_info(\n            realm_id=realm.id,\n            recipient=recipient,\n            sender_id=hamlet.id,\n            stream_topic=stream_topic,\n            possibly_mentioned_user_ids={service_bot.id},\n        )\n        self.assertEqual(\n            info[\"service_bot_tuples\"],\n            [\n                (service_bot.id, UserProfile.EMBEDDED_BOT),\n            ],\n        )\n\n        # Add a normal bot.\n        normal_bot = do_create_user(\n            email=\"normal-bot@zulip.com\",\n            password=\"\",\n            realm=realm,\n            full_name=\"\",\n            bot_type=UserProfile.DEFAULT_BOT,\n            acting_user=None,\n        )\n\n        info = get_recipient_info(\n            realm_id=realm.id,\n            recipient=recipient,\n            sender_id=hamlet.id,\n            stream_topic=stream_topic,\n            possibly_mentioned_user_ids={service_bot.id, normal_bot.id},\n        )\n        self.assertEqual(info[\"default_bot_user_ids\"], {normal_bot.id})\n        self.assertEqual(info[\"all_bot_user_ids\"], {normal_bot.id, service_bot.id})\n\n    def test_get_recipient_info_invalid_recipient_type(self) -> None:\n        hamlet = self.example_user(\"hamlet\")\n        realm = hamlet.realm\n\n        stream = get_stream(\"Rome\", realm)\n        stream_topic = StreamTopicTarget(\n            stream_id=stream.id,\n            topic_name=\"test topic\",\n        )\n\n        # Make sure get_recipient_info asserts on invalid recipient types\n        with self.assertRaisesRegex(ValueError, \"Bad recipient type\"):\n            invalid_recipient = Recipient(type=999)  # 999 is not a valid type\n            get_recipient_info(\n                realm_id=realm.id,\n                recipient=invalid_recipient,\n                sender_id=hamlet.id,\n                stream_topic=stream_topic,\n            )\n\n\nclass BulkUsersTest(ZulipTestCase):\n    def test_client_gravatar_option(self) -> None:\n        reset_emails_in_zulip_realm()\n        self.login(\"cordelia\")\n\n        hamlet = self.example_user(\"hamlet\")\n\n        def get_hamlet_avatar(client_gravatar: bool) -> Optional[str]:\n            data = dict(client_gravatar=orjson.dumps(client_gravatar).decode())\n            result = self.client_get(\"/json/users\", data)\n            self.assert_json_success(result)\n            rows = result.json()[\"members\"]\n            hamlet_data = [row for row in rows if row[\"user_id\"] == hamlet.id][0]\n            return hamlet_data[\"avatar_url\"]\n\n        self.assertEqual(\n            get_hamlet_avatar(client_gravatar=True),\n            None,\n        )\n\n        \"\"\"\n        The main purpose of this test is to make sure we\n        return None for avatar_url when client_gravatar is\n        set to True.  And we do a sanity check for when it's\n        False, but we leave it to other tests to validate\n        the specific URL.\n        \"\"\"\n        self.assertIn(\n            \"gravatar.com\",\n            assert_is_not_none(get_hamlet_avatar(client_gravatar=False)),\n        )\n\n\nclass GetProfileTest(ZulipTestCase):\n    def test_cache_behavior(self) -> None:\n        \"\"\"Tests whether fetching a user object the normal way, with\n        `get_user`, makes 1 cache query and 1 database query.\n        \"\"\"\n        realm = get_realm(\"zulip\")\n        email = self.example_user(\"hamlet\").email\n        with queries_captured() as queries:\n            with simulated_empty_cache() as cache_queries:\n                user_profile = get_user(email, realm)\n\n        self.assert_length(queries, 1)\n        self.assert_length(cache_queries, 1)\n        self.assertEqual(user_profile.email, email)\n\n    def test_get_user_profile(self) -> None:\n        hamlet = self.example_user(\"hamlet\")\n        iago = self.example_user(\"iago\")\n        desdemona = self.example_user(\"desdemona\")\n        shiva = self.example_user(\"shiva\")\n        self.login(\"hamlet\")\n        result = orjson.loads(self.client_get(\"/json/users/me\").content)\n        self.assertEqual(result[\"email\"], hamlet.email)\n        self.assertEqual(result[\"full_name\"], \"King Hamlet\")\n        self.assertIn(\"user_id\", result)\n        self.assertFalse(result[\"is_bot\"])\n        self.assertFalse(result[\"is_admin\"])\n        self.assertFalse(result[\"is_owner\"])\n        self.assertFalse(result[\"is_guest\"])\n        self.assertEqual(result[\"role\"], UserProfile.ROLE_MEMBER)\n        self.assertFalse(\"delivery_email\" in result)\n        self.login(\"iago\")\n        result = orjson.loads(self.client_get(\"/json/users/me\").content)\n        self.assertEqual(result[\"email\"], iago.email)\n        self.assertEqual(result[\"full_name\"], \"Iago\")\n        self.assertFalse(result[\"is_bot\"])\n        self.assertTrue(result[\"is_admin\"])\n        self.assertFalse(result[\"is_owner\"])\n        self.assertFalse(result[\"is_guest\"])\n        self.assertEqual(result[\"role\"], UserProfile.ROLE_REALM_ADMINISTRATOR)\n        self.login(\"desdemona\")\n        result = orjson.loads(self.client_get(\"/json/users/me\").content)\n        self.assertEqual(result[\"email\"], desdemona.email)\n        self.assertFalse(result[\"is_bot\"])\n        self.assertTrue(result[\"is_admin\"])\n        self.assertTrue(result[\"is_owner\"])\n        self.assertFalse(result[\"is_guest\"])\n        self.assertEqual(result[\"role\"], UserProfile.ROLE_REALM_OWNER)\n        self.login(\"shiva\")\n        result = orjson.loads(self.client_get(\"/json/users/me\").content)\n        self.assertEqual(result[\"email\"], shiva.email)\n        self.assertFalse(result[\"is_bot\"])\n        self.assertFalse(result[\"is_admin\"])\n        self.assertFalse(result[\"is_owner\"])\n        self.assertFalse(result[\"is_guest\"])\n        self.assertEqual(result[\"role\"], UserProfile.ROLE_MODERATOR)\n\n        # Tests the GET ../users/{id} API endpoint.\n        user = self.example_user(\"hamlet\")\n        result = orjson.loads(self.client_get(f\"/json/users/{user.id}\").content)\n        self.assertEqual(result[\"user\"][\"email\"], user.email)\n        self.assertEqual(result[\"user\"][\"full_name\"], user.full_name)\n        self.assertIn(\"user_id\", result[\"user\"])\n        self.assertNotIn(\"profile_data\", result[\"user\"])\n        self.assertFalse(result[\"user\"][\"is_bot\"])\n        self.assertFalse(result[\"user\"][\"is_admin\"])\n        self.assertFalse(result[\"user\"][\"is_owner\"])\n\n        result = orjson.loads(\n            self.client_get(\n                f\"/json/users/{user.id}\", {\"include_custom_profile_fields\": \"true\"}\n            ).content\n        )\n\n        self.assertIn(\"profile_data\", result[\"user\"])\n        result = self.client_get(\"/json/users/30\")\n        self.assert_json_error(result, \"No such user\")\n\n        bot = self.example_user(\"default_bot\")\n        result = orjson.loads(self.client_get(f\"/json/users/{bot.id}\").content)\n        self.assertEqual(result[\"user\"][\"email\"], bot.email)\n        self.assertTrue(result[\"user\"][\"is_bot\"])\n\n    def test_get_user_by_email(self) -> None:\n        user = self.example_user(\"hamlet\")\n        self.login(\"hamlet\")\n        result = orjson.loads(self.client_get(f\"/json/users/{user.email}\").content)\n\n        self.assertEqual(result[\"user\"][\"email\"], user.email)\n\n        self.assertEqual(result[\"user\"][\"full_name\"], user.full_name)\n        self.assertIn(\"user_id\", result[\"user\"])\n        self.assertNotIn(\"profile_data\", result[\"user\"])\n        self.assertFalse(result[\"user\"][\"is_bot\"])\n        self.assertFalse(result[\"user\"][\"is_admin\"])\n        self.assertFalse(result[\"user\"][\"is_owner\"])\n\n        result = orjson.loads(\n            self.client_get(\n                f\"/json/users/{user.email}\", {\"include_custom_profile_fields\": \"true\"}\n            ).content\n        )\n        self.assertIn(\"profile_data\", result[\"user\"])\n\n        result = self.client_get(\"/json/users/invalid\")\n        self.assert_json_error(result, \"No such user\")\n\n        bot = self.example_user(\"default_bot\")\n        result = orjson.loads(self.client_get(f\"/json/users/{bot.email}\").content)\n        self.assertEqual(result[\"user\"][\"email\"], bot.email)\n        self.assertTrue(result[\"user\"][\"is_bot\"])\n\n    def test_get_all_profiles_avatar_urls(self) -> None:\n        hamlet = self.example_user(\"hamlet\")\n        result = self.api_get(hamlet, \"/api/v1/users\")\n        self.assert_json_success(result)\n\n        (my_user,) = (user for user in result.json()[\"members\"] if user[\"email\"] == hamlet.email)\n\n        self.assertEqual(\n            my_user[\"avatar_url\"],\n            avatar_url(hamlet),\n        )\n\n    def test_user_email_according_to_email_address_visibility_setting(self) -> None:\n        hamlet = self.example_user(\"hamlet\")\n\n        realm = hamlet.realm\n        do_set_realm_property(\n            realm,\n            \"email_address_visibility\",\n            Realm.EMAIL_ADDRESS_VISIBILITY_NOBODY,\n            acting_user=None,\n        )\n\n        # Check that even admin cannot access email when setting is set to\n        # EMAIL_ADDRESS_VISIBILITY_NOBODY.\n        self.login(\"iago\")\n        result = orjson.loads(self.client_get(f\"/json/users/{hamlet.id}\").content)\n        self.assertEqual(result[\"user\"].get(\"delivery_email\"), None)\n        self.assertEqual(result[\"user\"].get(\"email\"), f\"user{hamlet.id}@zulip.testserver\")\n\n        do_set_realm_property(\n            realm,\n            \"email_address_visibility\",\n            Realm.EMAIL_ADDRESS_VISIBILITY_ADMINS,\n            acting_user=None,\n        )\n\n        # Check that admin can access email when setting is set to\n        # EMAIL_ADDRESS_VISIBILITY_ADMINS.\n        result = orjson.loads(self.client_get(f\"/json/users/{hamlet.id}\").content)\n        self.assertEqual(result[\"user\"].get(\"delivery_email\"), hamlet.delivery_email)\n        self.assertEqual(result[\"user\"].get(\"email\"), f\"user{hamlet.id}@zulip.testserver\")\n\n        # Check that moderator cannot access email when setting is set to\n        # EMAIL_ADDRESS_VISIBILITY_ADMINS.\n        self.login(\"shiva\")\n        result = orjson.loads(self.client_get(f\"/json/users/{hamlet.id}\").content)\n        self.assertEqual(result[\"user\"].get(\"delivery_email\"), None)\n        self.assertEqual(result[\"user\"].get(\"email\"), f\"user{hamlet.id}@zulip.testserver\")\n\n        do_set_realm_property(\n            realm,\n            \"email_address_visibility\",\n            Realm.EMAIL_ADDRESS_VISIBILITY_MODERATORS,\n            acting_user=None,\n        )\n\n        # Check that moderator can access email when setting is set to\n        # EMAIL_ADDRESS_VISIBILITY_MODERATORS.\n        result = orjson.loads(self.client_get(f\"/json/users/{hamlet.id}\").content)\n        self.assertEqual(result[\"user\"].get(\"delivery_email\"), hamlet.delivery_email)\n        self.assertEqual(result[\"user\"].get(\"email\"), f\"user{hamlet.id}@zulip.testserver\")\n\n        # Check that normal user cannot access email when setting is set to\n        # EMAIL_ADDRESS_VISIBILITY_MODERATORS.\n        self.login(\"cordelia\")\n        result = orjson.loads(self.client_get(f\"/json/users/{hamlet.id}\").content)\n        self.assertEqual(result[\"user\"].get(\"delivery_email\"), None)\n        self.assertEqual(result[\"user\"].get(\"email\"), f\"user{hamlet.id}@zulip.testserver\")\n\n        do_set_realm_property(\n            realm,\n            \"email_address_visibility\",\n            Realm.EMAIL_ADDRESS_VISIBILITY_EVERYONE,\n            acting_user=None,\n        )\n\n        # Check that moderator, member and guest all can access email when setting\n        # is set to EMAIL_ADDRESS_VISIBILITY_EVERYONE.\n        self.login(\"shiva\")\n        result = orjson.loads(self.client_get(f\"/json/users/{hamlet.id}\").content)\n        self.assertEqual(result[\"user\"].get(\"delivery_email\"), None)\n        self.assertEqual(result[\"user\"].get(\"email\"), hamlet.delivery_email)\n\n        self.login(\"cordelia\")\n        result = orjson.loads(self.client_get(f\"/json/users/{hamlet.id}\").content)\n        self.assertEqual(result[\"user\"].get(\"delivery_email\"), None)\n        self.assertEqual(result[\"user\"].get(\"email\"), hamlet.delivery_email)\n\n        self.login(\"polonius\")\n        result = orjson.loads(self.client_get(f\"/json/users/{hamlet.id}\").content)\n        self.assertEqual(result[\"user\"].get(\"delivery_email\"), None)\n        self.assertEqual(result[\"user\"].get(\"email\"), hamlet.delivery_email)\n\n\nclass DeleteUserTest(ZulipTestCase):\n    def test_do_delete_user(self) -> None:\n        realm = get_realm(\"zulip\")\n        cordelia = self.example_user(\"cordelia\")\n        othello = self.example_user(\"othello\")\n        hamlet = self.example_user(\"hamlet\")\n        hamlet_personal_recipient = hamlet.recipient\n        hamlet_user_id = hamlet.id\n        hamlet_date_joined = hamlet.date_joined\n\n        self.send_personal_message(cordelia, hamlet)\n        self.send_personal_message(hamlet, cordelia)\n\n        personal_message_ids_to_hamlet = Message.objects.filter(\n            recipient=hamlet_personal_recipient\n        ).values_list(\"id\", flat=True)\n        self.assertGreater(len(personal_message_ids_to_hamlet), 0)\n        self.assertTrue(Message.objects.filter(sender=hamlet).exists())\n\n        huddle_message_ids_from_cordelia = [\n            self.send_huddle_message(cordelia, [hamlet, othello]) for i in range(3)\n        ]\n        huddle_message_ids_from_hamlet = [\n            self.send_huddle_message(hamlet, [cordelia, othello]) for i in range(3)\n        ]\n\n        huddle_with_hamlet_recipient_ids = list(\n            Subscription.objects.filter(\n                user_profile=hamlet, recipient__type=Recipient.HUDDLE\n            ).values_list(\"recipient_id\", flat=True)\n        )\n        self.assertGreater(len(huddle_with_hamlet_recipient_ids), 0)\n\n        do_delete_user(hamlet)\n\n        replacement_dummy_user = UserProfile.objects.get(id=hamlet_user_id, realm=realm)\n\n        self.assertEqual(\n            replacement_dummy_user.delivery_email, f\"deleteduser{hamlet_user_id}@zulip.testserver\"\n        )\n        self.assertEqual(replacement_dummy_user.is_mirror_dummy, True)\n        self.assertEqual(replacement_dummy_user.is_active, False)\n        self.assertEqual(replacement_dummy_user.date_joined, hamlet_date_joined)\n\n        self.assertEqual(Message.objects.filter(id__in=personal_message_ids_to_hamlet).count(), 0)\n        # Huddle messages from hamlet should have been deleted, but messages of other participants should\n        # be kept.\n        self.assertEqual(Message.objects.filter(id__in=huddle_message_ids_from_hamlet).count(), 0)\n        self.assertEqual(Message.objects.filter(id__in=huddle_message_ids_from_cordelia).count(), 3)\n\n        self.assertEqual(Message.objects.filter(sender_id=hamlet_user_id).count(), 0)\n\n        # Verify that the dummy user is subscribed to the deleted user's huddles, to keep huddle data\n        # in a correct state.\n        for recipient_id in huddle_with_hamlet_recipient_ids:\n            self.assertTrue(\n                Subscription.objects.filter(\n                    user_profile=replacement_dummy_user, recipient_id=recipient_id\n                ).exists()\n            )\n\n\nclass FakeEmailDomainTest(ZulipTestCase):\n    def test_get_fake_email_domain(self) -> None:\n        realm = get_realm(\"zulip\")\n        self.assertEqual(\"zulip.testserver\", get_fake_email_domain(realm))\n\n        with self.settings(EXTERNAL_HOST=\"example.com\"):\n            self.assertEqual(\"zulip.example.com\", get_fake_email_domain(realm))\n\n    @override_settings(FAKE_EMAIL_DOMAIN=\"fakedomain.com\", REALM_HOSTS={\"zulip\": \"127.0.0.1\"})\n    def test_get_fake_email_domain_realm_host_is_ip_addr(self) -> None:\n        realm = get_realm(\"zulip\")\n        self.assertEqual(\"fakedomain.com\", get_fake_email_domain(realm))\n\n    @override_settings(FAKE_EMAIL_DOMAIN=\"invaliddomain\", REALM_HOSTS={\"zulip\": \"127.0.0.1\"})\n    def test_invalid_fake_email_domain(self) -> None:\n        realm = get_realm(\"zulip\")\n        with self.assertRaises(InvalidFakeEmailDomain):\n            get_fake_email_domain(realm)\n\n    @override_settings(FAKE_EMAIL_DOMAIN=\"127.0.0.1\", REALM_HOSTS={\"zulip\": \"127.0.0.1\"})\n    def test_invalid_fake_email_domain_ip(self) -> None:\n        with self.assertRaises(InvalidFakeEmailDomain):\n            realm = get_realm(\"zulip\")\n            get_fake_email_domain(realm)\n"], "fixing_code": ["import datetime\nimport hashlib\nimport itertools\nimport logging\nimport os\nimport time\nfrom collections import defaultdict\nfrom dataclasses import asdict, dataclass, field\nfrom operator import itemgetter\nfrom typing import (\n    IO,\n    AbstractSet,\n    Any,\n    Callable,\n    Collection,\n    Dict,\n    Iterable,\n    List,\n    Mapping,\n    Optional,\n    Sequence,\n    Set,\n    Tuple,\n    Union,\n)\n\nimport django.db.utils\nimport orjson\nfrom django.conf import settings\nfrom django.contrib.contenttypes.models import ContentType\nfrom django.core.exceptions import ValidationError\nfrom django.db import IntegrityError, connection, transaction\nfrom django.db.models import Count, Exists, F, OuterRef, Q, Sum\nfrom django.db.models.query import QuerySet\nfrom django.utils.html import escape\nfrom django.utils.timezone import now as timezone_now\nfrom django.utils.translation import gettext as _\nfrom django.utils.translation import gettext_lazy\nfrom django.utils.translation import override as override_language\nfrom psycopg2.extras import execute_values\nfrom psycopg2.sql import SQL\nfrom typing_extensions import TypedDict\n\nfrom analytics.lib.counts import COUNT_STATS, do_increment_logging_stat\nfrom analytics.models import RealmCount\nfrom confirmation import settings as confirmation_settings\nfrom confirmation.models import (\n    Confirmation,\n    confirmation_url,\n    create_confirmation_link,\n    generate_key,\n)\nfrom zerver.decorator import statsd_increment\nfrom zerver.lib import retention as retention\nfrom zerver.lib.addressee import Addressee\nfrom zerver.lib.alert_words import (\n    add_user_alert_words,\n    get_alert_word_automaton,\n    remove_user_alert_words,\n)\nfrom zerver.lib.avatar import avatar_url, avatar_url_from_dict\nfrom zerver.lib.bot_config import ConfigError, get_bot_config, get_bot_configs, set_bot_config\nfrom zerver.lib.bulk_create import bulk_create_users\nfrom zerver.lib.cache import (\n    bot_dict_fields,\n    cache_delete,\n    cache_delete_many,\n    cache_set,\n    cache_set_many,\n    cache_with_key,\n    delete_user_profile_caches,\n    display_recipient_cache_key,\n    flush_user_profile,\n    get_stream_cache_key,\n    to_dict_cache_key_id,\n    user_profile_by_api_key_cache_key,\n    user_profile_delivery_email_cache_key,\n)\nfrom zerver.lib.create_user import create_user, get_display_email_address\nfrom zerver.lib.email_mirror_helpers import encode_email_address\nfrom zerver.lib.email_notifications import enqueue_welcome_emails\nfrom zerver.lib.email_validation import (\n    email_reserved_for_system_bots_error,\n    get_existing_user_errors,\n    get_realm_email_validator,\n    validate_email_is_valid,\n)\nfrom zerver.lib.emoji import check_emoji_request, emoji_name_to_emoji_code, get_emoji_file_name\nfrom zerver.lib.exceptions import (\n    InvitationError,\n    JsonableError,\n    MarkdownRenderingException,\n    StreamDoesNotExistError,\n    StreamWithIDDoesNotExistError,\n    ZephyrMessageAlreadySentException,\n)\nfrom zerver.lib.export import get_realm_exports_serialized\nfrom zerver.lib.external_accounts import DEFAULT_EXTERNAL_ACCOUNTS\nfrom zerver.lib.hotspots import get_next_hotspots\nfrom zerver.lib.i18n import get_language_name\nfrom zerver.lib.markdown import MessageRenderingResult, topic_links\nfrom zerver.lib.markdown import version as markdown_version\nfrom zerver.lib.mention import MentionBackend, MentionData, silent_mention_syntax_for_user\nfrom zerver.lib.message import (\n    MessageDict,\n    SendMessageRequest,\n    access_message,\n    bulk_access_messages,\n    get_last_message_id,\n    normalize_body,\n    render_markdown,\n    truncate_topic,\n    update_first_visible_message_id,\n    wildcard_mention_allowed,\n)\nfrom zerver.lib.notification_data import UserMessageNotificationsData, get_user_group_mentions_data\nfrom zerver.lib.pysa import mark_sanitized\nfrom zerver.lib.queue import queue_json_publish\nfrom zerver.lib.realm_icon import realm_icon_url\nfrom zerver.lib.realm_logo import get_realm_logo_data\nfrom zerver.lib.retention import move_messages_to_archive\nfrom zerver.lib.send_email import (\n    FromAddress,\n    clear_scheduled_emails,\n    clear_scheduled_invitation_emails,\n    send_email,\n    send_email_to_admins,\n)\nfrom zerver.lib.server_initialization import create_internal_realm, server_initialized\nfrom zerver.lib.sessions import delete_user_sessions\nfrom zerver.lib.storage import static_path\nfrom zerver.lib.stream_color import pick_colors\nfrom zerver.lib.stream_subscription import (\n    SubInfo,\n    bulk_get_private_peers,\n    bulk_get_subscriber_peer_info,\n    get_active_subscriptions_for_stream_id,\n    get_bulk_stream_subscriber_info,\n    get_stream_subscriptions_for_user,\n    get_subscribed_stream_ids_for_user,\n    get_subscriptions_for_send_message,\n    get_used_colors_for_user_ids,\n    get_user_ids_for_streams,\n    num_subscribers_for_stream_id,\n    subscriber_ids_with_stream_history_access,\n)\nfrom zerver.lib.stream_topic import StreamTopicTarget\nfrom zerver.lib.stream_traffic import get_average_weekly_stream_traffic, get_streams_traffic\nfrom zerver.lib.streams import (\n    access_stream_by_id,\n    access_stream_for_send_message,\n    can_access_stream_user_ids,\n    check_stream_access_based_on_stream_post_policy,\n    create_stream_if_needed,\n    get_default_value_for_history_public_to_subscribers,\n    get_stream_permission_policy_name,\n    get_web_public_streams_queryset,\n    render_stream_description,\n    send_stream_creation_event,\n    subscribed_to_stream,\n)\nfrom zerver.lib.string_validation import check_stream_name, check_stream_topic\nfrom zerver.lib.subscription_info import build_stream_dict_for_never_sub, build_stream_dict_for_sub\nfrom zerver.lib.timestamp import datetime_to_timestamp, timestamp_to_datetime\nfrom zerver.lib.timezone import canonicalize_timezone\nfrom zerver.lib.topic import (\n    ORIG_TOPIC,\n    RESOLVED_TOPIC_PREFIX,\n    TOPIC_LINKS,\n    TOPIC_NAME,\n    filter_by_exact_message_topic,\n    filter_by_topic_name_via_message,\n    messages_for_topic,\n    save_message_for_edit_use_case,\n    update_edit_history,\n    update_messages_for_topic_edit,\n)\nfrom zerver.lib.types import (\n    EditHistoryEvent,\n    NeverSubscribedStreamDict,\n    ProfileDataElementValue,\n    ProfileFieldData,\n    RawStreamDict,\n    RawSubscriptionDict,\n    SubscriptionInfo,\n    SubscriptionStreamDict,\n    UnspecifiedValue,\n)\nfrom zerver.lib.upload import (\n    claim_attachment,\n    delete_avatar_image,\n    delete_export_tarball,\n    delete_message_image,\n    upload_emoji_image,\n)\nfrom zerver.lib.user_groups import (\n    access_user_group_by_id,\n    create_system_user_groups_for_realm,\n    create_user_group,\n    get_system_user_group_for_user,\n)\nfrom zerver.lib.user_mutes import add_user_mute, get_muting_users, get_user_mutes\nfrom zerver.lib.user_status import update_user_status\nfrom zerver.lib.user_topics import add_topic_mute, get_topic_mutes, remove_topic_mute\nfrom zerver.lib.users import (\n    check_bot_name_available,\n    check_full_name,\n    format_user_row,\n    get_api_key,\n    user_profile_to_user_row,\n)\nfrom zerver.lib.utils import generate_api_key, log_statsd_event\nfrom zerver.lib.validator import check_widget_content\nfrom zerver.lib.widget import do_widget_post_save_actions, is_widget_message\nfrom zerver.models import (\n    Attachment,\n    Client,\n    CustomProfileField,\n    CustomProfileFieldValue,\n    DefaultStream,\n    DefaultStreamGroup,\n    Draft,\n    EmailChangeStatus,\n    Message,\n    MultiuseInvite,\n    MutedUser,\n    PreregistrationUser,\n    Reaction,\n    Realm,\n    RealmAuditLog,\n    RealmDomain,\n    RealmEmoji,\n    RealmFilter,\n    RealmPlayground,\n    RealmUserDefault,\n    Recipient,\n    ScheduledEmail,\n    ScheduledMessage,\n    ScheduledMessageNotificationEmail,\n    Service,\n    Stream,\n    SubMessage,\n    Subscription,\n    UserActivity,\n    UserActivityInterval,\n    UserGroup,\n    UserGroupMembership,\n    UserHotspot,\n    UserMessage,\n    UserPresence,\n    UserProfile,\n    UserStatus,\n    UserTopic,\n    active_non_guest_user_ids,\n    active_user_ids,\n    custom_profile_fields_for_realm,\n    filter_to_valid_prereg_users,\n    get_active_streams,\n    get_bot_dicts_in_realm,\n    get_bot_services,\n    get_client,\n    get_default_stream_groups,\n    get_fake_email_domain,\n    get_huddle_recipient,\n    get_huddle_user_ids,\n    get_old_unclaimed_attachments,\n    get_realm,\n    get_realm_domains,\n    get_realm_playgrounds,\n    get_stream,\n    get_stream_by_id_in_realm,\n    get_system_bot,\n    get_user_by_delivery_email,\n    get_user_by_id_in_realm_including_cross_realm,\n    get_user_profile_by_id,\n    is_cross_realm_bot_email,\n    linkifiers_for_realm,\n    query_for_ids,\n    realm_filters_for_realm,\n    validate_attachment_request,\n)\nfrom zerver.tornado.django_api import send_event\n\nif settings.BILLING_ENABLED:\n    from corporate.lib.stripe import (\n        downgrade_now_without_creating_additional_invoices,\n        update_license_ledger_if_needed,\n    )\n\n\nONBOARDING_TOTAL_MESSAGES = 1000\nONBOARDING_UNREAD_MESSAGES = 20\nONBOARDING_RECENT_TIMEDELTA = datetime.timedelta(weeks=1)\n\n\ndef create_historical_user_messages(*, user_id: int, message_ids: List[int]) -> None:\n    # Users can see and interact with messages sent to streams with\n    # public history for which they do not have a UserMessage because\n    # they were not a subscriber at the time the message was sent.\n    # In order to add emoji reactions or mutate message flags for\n    # those messages, we create UserMessage objects for those messages;\n    # these have the special historical flag which keeps track of the\n    # fact that the user did not receive the message at the time it was sent.\n    for message_id in message_ids:\n        UserMessage.objects.create(\n            user_profile_id=user_id,\n            message_id=message_id,\n            flags=UserMessage.flags.historical | UserMessage.flags.read,\n        )\n\n\ndef subscriber_info(user_id: int) -> Dict[str, Any]:\n    return {\"id\": user_id, \"flags\": [\"read\"]}\n\n\ndef bot_owner_user_ids(user_profile: UserProfile) -> Set[int]:\n    is_private_bot = (\n        user_profile.default_sending_stream\n        and user_profile.default_sending_stream.invite_only\n        or user_profile.default_events_register_stream\n        and user_profile.default_events_register_stream.invite_only\n    )\n    if is_private_bot:\n        return {user_profile.bot_owner_id}\n    else:\n        users = {user.id for user in user_profile.realm.get_human_admin_users()}\n        users.add(user_profile.bot_owner_id)\n        return users\n\n\ndef realm_user_count(realm: Realm) -> int:\n    return UserProfile.objects.filter(realm=realm, is_active=True, is_bot=False).count()\n\n\ndef realm_user_count_by_role(realm: Realm) -> Dict[str, Any]:\n    human_counts = {\n        str(UserProfile.ROLE_REALM_ADMINISTRATOR): 0,\n        str(UserProfile.ROLE_REALM_OWNER): 0,\n        str(UserProfile.ROLE_MODERATOR): 0,\n        str(UserProfile.ROLE_MEMBER): 0,\n        str(UserProfile.ROLE_GUEST): 0,\n    }\n    for value_dict in list(\n        UserProfile.objects.filter(realm=realm, is_bot=False, is_active=True)\n        .values(\"role\")\n        .annotate(Count(\"role\"))\n    ):\n        human_counts[str(value_dict[\"role\"])] = value_dict[\"role__count\"]\n    bot_count = UserProfile.objects.filter(realm=realm, is_bot=True, is_active=True).count()\n    return {\n        RealmAuditLog.ROLE_COUNT_HUMANS: human_counts,\n        RealmAuditLog.ROLE_COUNT_BOTS: bot_count,\n    }\n\n\ndef get_signups_stream(realm: Realm) -> Stream:\n    # This one-liner helps us work around a lint rule.\n    return get_stream(\"signups\", realm)\n\n\ndef send_message_to_signup_notification_stream(\n    sender: UserProfile, realm: Realm, message: str, topic_name: str = _(\"signups\")\n) -> None:\n    signup_notifications_stream = realm.get_signup_notifications_stream()\n    if signup_notifications_stream is None:\n        return\n\n    with override_language(realm.default_language):\n        internal_send_stream_message(sender, signup_notifications_stream, topic_name, message)\n\n\ndef notify_new_user(user_profile: UserProfile) -> None:\n    user_count = realm_user_count(user_profile.realm)\n    sender_email = settings.NOTIFICATION_BOT\n    sender = get_system_bot(sender_email, user_profile.realm_id)\n\n    is_first_user = user_count == 1\n    if not is_first_user:\n        message = _(\"{user} just signed up for Zulip. (total: {user_count})\").format(\n            user=silent_mention_syntax_for_user(user_profile), user_count=user_count\n        )\n\n        if settings.BILLING_ENABLED:\n            from corporate.lib.registration import generate_licenses_low_warning_message_if_required\n\n            licenses_low_warning_message = generate_licenses_low_warning_message_if_required(\n                user_profile.realm\n            )\n            if licenses_low_warning_message is not None:\n                message += \"\\n\"\n                message += licenses_low_warning_message\n\n        send_message_to_signup_notification_stream(sender, user_profile.realm, message)\n\n    # We also send a notification to the Zulip administrative realm\n    admin_realm = get_realm(settings.SYSTEM_BOT_REALM)\n    admin_realm_sender = get_system_bot(sender_email, admin_realm.id)\n    try:\n        # Check whether the stream exists\n        signups_stream = get_signups_stream(admin_realm)\n        # We intentionally use the same strings as above to avoid translation burden.\n        message = _(\"{user} just signed up for Zulip. (total: {user_count})\").format(\n            user=f\"{user_profile.full_name} <`{user_profile.email}`>\", user_count=user_count\n        )\n        internal_send_stream_message(\n            admin_realm_sender, signups_stream, user_profile.realm.display_subdomain, message\n        )\n\n    except Stream.DoesNotExist:\n        # If the signups stream hasn't been created in the admin\n        # realm, don't auto-create it to send to it; just do nothing.\n        pass\n\n\ndef notify_invites_changed(realm: Realm) -> None:\n    event = dict(type=\"invites_changed\")\n    admin_ids = [user.id for user in realm.get_admin_users_and_bots()]\n    send_event(realm, event, admin_ids)\n\n\ndef add_new_user_history(user_profile: UserProfile, streams: Iterable[Stream]) -> None:\n    \"\"\"Give you the last ONBOARDING_TOTAL_MESSAGES messages on your public\n    streams, so you have something to look at in your home view once\n    you finish the tutorial.  The most recent ONBOARDING_UNREAD_MESSAGES\n    are marked unread.\n    \"\"\"\n    one_week_ago = timezone_now() - ONBOARDING_RECENT_TIMEDELTA\n\n    recipient_ids = [stream.recipient_id for stream in streams if not stream.invite_only]\n    recent_messages = Message.objects.filter(\n        recipient_id__in=recipient_ids, date_sent__gt=one_week_ago\n    ).order_by(\"-id\")\n    message_ids_to_use = list(\n        reversed(recent_messages.values_list(\"id\", flat=True)[0:ONBOARDING_TOTAL_MESSAGES])\n    )\n    if len(message_ids_to_use) == 0:\n        return\n\n    # Handle the race condition where a message arrives between\n    # bulk_add_subscriptions above and the Message query just above\n    already_ids = set(\n        UserMessage.objects.filter(\n            message_id__in=message_ids_to_use, user_profile=user_profile\n        ).values_list(\"message_id\", flat=True)\n    )\n\n    # Mark the newest ONBOARDING_UNREAD_MESSAGES as unread.\n    marked_unread = 0\n    ums_to_create = []\n    for message_id in reversed(message_ids_to_use):\n        if message_id in already_ids:\n            continue\n\n        um = UserMessage(user_profile=user_profile, message_id=message_id)\n        if marked_unread < ONBOARDING_UNREAD_MESSAGES:\n            marked_unread += 1\n        else:\n            um.flags = UserMessage.flags.read\n        ums_to_create.append(um)\n\n    UserMessage.objects.bulk_create(reversed(ums_to_create))\n\n\n# Does the processing for a new user account:\n# * Subscribes to default/invitation streams\n# * Fills in some recent historical messages\n# * Notifies other users in realm and Zulip about the signup\n# * Deactivates PreregistrationUser objects\ndef process_new_human_user(\n    user_profile: UserProfile,\n    prereg_user: Optional[PreregistrationUser] = None,\n    default_stream_groups: Sequence[DefaultStreamGroup] = [],\n    realm_creation: bool = False,\n) -> None:\n    realm = user_profile.realm\n\n    mit_beta_user = realm.is_zephyr_mirror_realm\n    if prereg_user is not None:\n        streams: List[Stream] = list(prereg_user.streams.all())\n        acting_user: Optional[UserProfile] = prereg_user.referred_by\n    else:\n        streams = []\n        acting_user = None\n\n    # If the user's invitation didn't explicitly list some streams, we\n    # add the default streams\n    if len(streams) == 0:\n        streams = get_default_subs(user_profile)\n\n    for default_stream_group in default_stream_groups:\n        default_stream_group_streams = default_stream_group.streams.all()\n        for stream in default_stream_group_streams:\n            if stream not in streams:\n                streams.append(stream)\n\n    bulk_add_subscriptions(\n        realm,\n        streams,\n        [user_profile],\n        from_user_creation=True,\n        acting_user=acting_user,\n    )\n\n    add_new_user_history(user_profile, streams)\n\n    # mit_beta_users don't have a referred_by field\n    if (\n        not mit_beta_user\n        and prereg_user is not None\n        and prereg_user.referred_by is not None\n        and prereg_user.referred_by.is_active\n    ):\n        # This is a cross-realm private message.\n        with override_language(prereg_user.referred_by.default_language):\n            internal_send_private_message(\n                get_system_bot(settings.NOTIFICATION_BOT, prereg_user.referred_by.realm_id),\n                prereg_user.referred_by,\n                _(\"{user} accepted your invitation to join Zulip!\").format(\n                    user=f\"{user_profile.full_name} <`{user_profile.email}`>\"\n                ),\n            )\n\n    revoke_preregistration_users(user_profile, prereg_user, realm_creation)\n    if not realm_creation and prereg_user is not None and prereg_user.referred_by is not None:\n        notify_invites_changed(user_profile.realm)\n\n    notify_new_user(user_profile)\n    # Clear any scheduled invitation emails to prevent them\n    # from being sent after the user is created.\n    clear_scheduled_invitation_emails(user_profile.delivery_email)\n    if realm.send_welcome_emails:\n        enqueue_welcome_emails(user_profile, realm_creation)\n\n    # We have an import loop here; it's intentional, because we want\n    # to keep all the onboarding code in zerver/lib/onboarding.py.\n    from zerver.lib.onboarding import send_initial_pms\n\n    send_initial_pms(user_profile)\n\n\ndef revoke_preregistration_users(\n    created_user_profile: UserProfile,\n    used_preregistration_user: Optional[PreregistrationUser],\n    realm_creation: bool,\n) -> None:\n    if used_preregistration_user is None:\n        assert not realm_creation, \"realm_creation should only happen with a PreregistrationUser\"\n\n    if used_preregistration_user is not None:\n        used_preregistration_user.status = confirmation_settings.STATUS_ACTIVE\n        used_preregistration_user.save(update_fields=[\"status\"])\n\n    # In the special case of realm creation, there can be no additional PreregistrationUser\n    # for us to want to modify - because other realm_creation PreregistrationUsers should be\n    # left usable for creating different realms.\n    if realm_creation:\n        return\n\n    # Mark any other PreregistrationUsers in the realm that are STATUS_ACTIVE as\n    # inactive so we can keep track of the PreregistrationUser we\n    # actually used for analytics.\n    if used_preregistration_user is not None:\n        PreregistrationUser.objects.filter(\n            email__iexact=created_user_profile.delivery_email, realm=created_user_profile.realm\n        ).exclude(id=used_preregistration_user.id).update(\n            status=confirmation_settings.STATUS_REVOKED\n        )\n    else:\n        PreregistrationUser.objects.filter(\n            email__iexact=created_user_profile.delivery_email, realm=created_user_profile.realm\n        ).update(status=confirmation_settings.STATUS_REVOKED)\n\n\ndef notify_created_user(user_profile: UserProfile) -> None:\n    user_row = user_profile_to_user_row(user_profile)\n    person = format_user_row(\n        user_profile.realm,\n        user_profile,\n        user_row,\n        # Since we don't know what the client\n        # supports at this point in the code, we\n        # just assume client_gravatar and\n        # user_avatar_url_field_optional = False :(\n        client_gravatar=False,\n        user_avatar_url_field_optional=False,\n        # We assume there's no custom profile\n        # field data for a new user; initial\n        # values are expected to be added in a\n        # later event.\n        custom_profile_field_data={},\n    )\n    event: Dict[str, Any] = dict(type=\"realm_user\", op=\"add\", person=person)\n    send_event(user_profile.realm, event, active_user_ids(user_profile.realm_id))\n\n\ndef created_bot_event(user_profile: UserProfile) -> Dict[str, Any]:\n    def stream_name(stream: Optional[Stream]) -> Optional[str]:\n        if not stream:\n            return None\n        return stream.name\n\n    default_sending_stream_name = stream_name(user_profile.default_sending_stream)\n    default_events_register_stream_name = stream_name(user_profile.default_events_register_stream)\n\n    bot = dict(\n        email=user_profile.email,\n        user_id=user_profile.id,\n        full_name=user_profile.full_name,\n        bot_type=user_profile.bot_type,\n        is_active=user_profile.is_active,\n        api_key=get_api_key(user_profile),\n        default_sending_stream=default_sending_stream_name,\n        default_events_register_stream=default_events_register_stream_name,\n        default_all_public_streams=user_profile.default_all_public_streams,\n        avatar_url=avatar_url(user_profile),\n        services=get_service_dicts_for_bot(user_profile.id),\n    )\n\n    # Set the owner key only when the bot has an owner.\n    # The default bots don't have an owner. So don't\n    # set the owner key while reactivating them.\n    if user_profile.bot_owner is not None:\n        bot[\"owner_id\"] = user_profile.bot_owner.id\n\n    return dict(type=\"realm_bot\", op=\"add\", bot=bot)\n\n\ndef notify_created_bot(user_profile: UserProfile) -> None:\n    event = created_bot_event(user_profile)\n    send_event(user_profile.realm, event, bot_owner_user_ids(user_profile))\n\n\ndef create_users(\n    realm: Realm, name_list: Iterable[Tuple[str, str]], bot_type: Optional[int] = None\n) -> None:\n    user_set = set()\n    for full_name, email in name_list:\n        user_set.add((email, full_name, True))\n    bulk_create_users(realm, user_set, bot_type)\n\n\ndef do_create_user(\n    email: str,\n    password: Optional[str],\n    realm: Realm,\n    full_name: str,\n    bot_type: Optional[int] = None,\n    role: Optional[int] = None,\n    bot_owner: Optional[UserProfile] = None,\n    tos_version: Optional[str] = None,\n    timezone: str = \"\",\n    avatar_source: str = UserProfile.AVATAR_FROM_GRAVATAR,\n    default_sending_stream: Optional[Stream] = None,\n    default_events_register_stream: Optional[Stream] = None,\n    default_all_public_streams: Optional[bool] = None,\n    prereg_user: Optional[PreregistrationUser] = None,\n    default_stream_groups: Sequence[DefaultStreamGroup] = [],\n    source_profile: Optional[UserProfile] = None,\n    realm_creation: bool = False,\n    *,\n    acting_user: Optional[UserProfile],\n    enable_marketing_emails: bool = True,\n) -> UserProfile:\n    with transaction.atomic():\n        user_profile = create_user(\n            email=email,\n            password=password,\n            realm=realm,\n            full_name=full_name,\n            role=role,\n            bot_type=bot_type,\n            bot_owner=bot_owner,\n            tos_version=tos_version,\n            timezone=timezone,\n            avatar_source=avatar_source,\n            default_sending_stream=default_sending_stream,\n            default_events_register_stream=default_events_register_stream,\n            default_all_public_streams=default_all_public_streams,\n            source_profile=source_profile,\n            enable_marketing_emails=enable_marketing_emails,\n        )\n\n        event_time = user_profile.date_joined\n        if not acting_user:\n            acting_user = user_profile\n        RealmAuditLog.objects.create(\n            realm=user_profile.realm,\n            acting_user=acting_user,\n            modified_user=user_profile,\n            event_type=RealmAuditLog.USER_CREATED,\n            event_time=event_time,\n            extra_data=orjson.dumps(\n                {\n                    RealmAuditLog.ROLE_COUNT: realm_user_count_by_role(user_profile.realm),\n                }\n            ).decode(),\n        )\n\n        if realm_creation:\n            # If this user just created a realm, make sure they are\n            # properly tagged as the creator of the realm.\n            realm_creation_audit_log = (\n                RealmAuditLog.objects.filter(event_type=RealmAuditLog.REALM_CREATED, realm=realm)\n                .order_by(\"id\")\n                .last()\n            )\n            assert realm_creation_audit_log is not None\n            realm_creation_audit_log.acting_user = user_profile\n            realm_creation_audit_log.save(update_fields=[\"acting_user\"])\n\n        do_increment_logging_stat(\n            user_profile.realm,\n            COUNT_STATS[\"active_users_log:is_bot:day\"],\n            user_profile.is_bot,\n            event_time,\n        )\n        if settings.BILLING_ENABLED:\n            update_license_ledger_if_needed(user_profile.realm, event_time)\n\n        system_user_group = get_system_user_group_for_user(user_profile)\n        UserGroupMembership.objects.create(user_profile=user_profile, user_group=system_user_group)\n\n        if user_profile.role == UserProfile.ROLE_MEMBER and not user_profile.is_provisional_member:\n            full_members_system_group = UserGroup.objects.get(\n                name=\"@role:fullmembers\", realm=user_profile.realm, is_system_group=True\n            )\n            UserGroupMembership.objects.create(\n                user_profile=user_profile, user_group=full_members_system_group\n            )\n\n    # Note that for bots, the caller will send an additional event\n    # with bot-specific info like services.\n    notify_created_user(user_profile)\n\n    do_send_user_group_members_update_event(\"add_members\", system_user_group, [user_profile.id])\n    if user_profile.role == UserProfile.ROLE_MEMBER and not user_profile.is_provisional_member:\n        do_send_user_group_members_update_event(\n            \"add_members\", full_members_system_group, [user_profile.id]\n        )\n\n    if bot_type is None:\n        process_new_human_user(\n            user_profile,\n            prereg_user=prereg_user,\n            default_stream_groups=default_stream_groups,\n            realm_creation=realm_creation,\n        )\n    return user_profile\n\n\ndef do_activate_mirror_dummy_user(\n    user_profile: UserProfile, *, acting_user: Optional[UserProfile]\n) -> None:\n    \"\"\"Called to have a user \"take over\" a \"mirror dummy\" user\n    (i.e. is_mirror_dummy=True) account when they sign up with the\n    same email address.\n\n    Essentially, the result should be as though we had created the\n    UserProfile just now with do_create_user, except that the mirror\n    dummy user may appear as the recipient or sender of messages from\n    before their account was fully created.\n\n    TODO: This function likely has bugs resulting from this being a\n    parallel code path to do_create_user; e.g. it likely does not\n    handle preferences or default streams properly.\n    \"\"\"\n    with transaction.atomic():\n        change_user_is_active(user_profile, True)\n        user_profile.is_mirror_dummy = False\n        user_profile.set_unusable_password()\n        user_profile.date_joined = timezone_now()\n        user_profile.tos_version = settings.TERMS_OF_SERVICE_VERSION\n        user_profile.save(\n            update_fields=[\"date_joined\", \"password\", \"is_mirror_dummy\", \"tos_version\"]\n        )\n\n        event_time = user_profile.date_joined\n        RealmAuditLog.objects.create(\n            realm=user_profile.realm,\n            modified_user=user_profile,\n            acting_user=acting_user,\n            event_type=RealmAuditLog.USER_ACTIVATED,\n            event_time=event_time,\n            extra_data=orjson.dumps(\n                {\n                    RealmAuditLog.ROLE_COUNT: realm_user_count_by_role(user_profile.realm),\n                }\n            ).decode(),\n        )\n        do_increment_logging_stat(\n            user_profile.realm,\n            COUNT_STATS[\"active_users_log:is_bot:day\"],\n            user_profile.is_bot,\n            event_time,\n        )\n        if settings.BILLING_ENABLED:\n            update_license_ledger_if_needed(user_profile.realm, event_time)\n\n    notify_created_user(user_profile)\n\n\ndef do_reactivate_user(user_profile: UserProfile, *, acting_user: Optional[UserProfile]) -> None:\n    \"\"\"Reactivate a user that had previously been deactivated\"\"\"\n    with transaction.atomic():\n        change_user_is_active(user_profile, True)\n\n        event_time = timezone_now()\n        RealmAuditLog.objects.create(\n            realm=user_profile.realm,\n            modified_user=user_profile,\n            acting_user=acting_user,\n            event_type=RealmAuditLog.USER_REACTIVATED,\n            event_time=event_time,\n            extra_data=orjson.dumps(\n                {\n                    RealmAuditLog.ROLE_COUNT: realm_user_count_by_role(user_profile.realm),\n                }\n            ).decode(),\n        )\n        do_increment_logging_stat(\n            user_profile.realm,\n            COUNT_STATS[\"active_users_log:is_bot:day\"],\n            user_profile.is_bot,\n            event_time,\n        )\n        if settings.BILLING_ENABLED:\n            update_license_ledger_if_needed(user_profile.realm, event_time)\n\n    notify_created_user(user_profile)\n\n    if user_profile.is_bot:\n        notify_created_bot(user_profile)\n\n    subscribed_recipient_ids = Subscription.objects.filter(\n        user_profile_id=user_profile.id, active=True, recipient__type=Recipient.STREAM\n    ).values_list(\"recipient__type_id\", flat=True)\n    subscribed_streams = Stream.objects.filter(id__in=subscribed_recipient_ids, deactivated=False)\n    subscriber_peer_info = bulk_get_subscriber_peer_info(\n        realm=user_profile.realm,\n        streams=subscribed_streams,\n    )\n\n    altered_user_dict: Dict[int, Set[int]] = defaultdict(set)\n    for stream in subscribed_streams:\n        altered_user_dict[stream.id] = {user_profile.id}\n\n    stream_dict = {stream.id: stream for stream in subscribed_streams}\n\n    send_peer_subscriber_events(\n        op=\"peer_add\",\n        realm=user_profile.realm,\n        altered_user_dict=altered_user_dict,\n        stream_dict=stream_dict,\n        private_peer_dict=subscriber_peer_info.private_peer_dict,\n    )\n\n\ndef active_humans_in_realm(realm: Realm) -> Sequence[UserProfile]:\n    return UserProfile.objects.filter(realm=realm, is_active=True, is_bot=False)\n\n\n@transaction.atomic(savepoint=False)\ndef update_users_in_full_members_system_group(\n    realm: Realm, affected_user_ids: Sequence[int] = []\n) -> None:\n    full_members_system_group = UserGroup.objects.get(\n        realm=realm, name=\"@role:fullmembers\", is_system_group=True\n    )\n    members_system_group = UserGroup.objects.get(\n        realm=realm, name=\"@role:members\", is_system_group=True\n    )\n\n    full_member_group_users: List[Dict[str, Union[int, datetime.datetime]]] = list()\n    member_group_users: List[Dict[str, Union[int, datetime.datetime]]] = list()\n\n    if affected_user_ids:\n        full_member_group_users = list(\n            full_members_system_group.direct_members.filter(id__in=affected_user_ids).values(\n                \"id\", \"role\", \"date_joined\"\n            )\n        )\n        member_group_users = list(\n            members_system_group.direct_members.filter(id__in=affected_user_ids).values(\n                \"id\", \"role\", \"date_joined\"\n            )\n        )\n    else:\n        full_member_group_users = list(\n            full_members_system_group.direct_members.all().values(\"id\", \"role\", \"date_joined\")\n        )\n        member_group_users = list(\n            members_system_group.direct_members.all().values(\"id\", \"role\", \"date_joined\")\n        )\n\n    def is_provisional_member(user: Dict[str, Union[int, datetime.datetime]]) -> bool:\n        diff = (timezone_now() - user[\"date_joined\"]).days\n        if diff < realm.waiting_period_threshold:\n            return True\n        return False\n\n    old_full_members = [\n        user\n        for user in full_member_group_users\n        if is_provisional_member(user) or user[\"role\"] != UserProfile.ROLE_MEMBER\n    ]\n\n    full_member_group_user_ids = [user[\"id\"] for user in full_member_group_users]\n    members_excluding_full_members = [\n        user for user in member_group_users if user[\"id\"] not in full_member_group_user_ids\n    ]\n\n    new_full_members = [\n        user for user in members_excluding_full_members if not is_provisional_member(user)\n    ]\n\n    old_full_member_ids = [user[\"id\"] for user in old_full_members]\n    new_full_member_ids = [user[\"id\"] for user in new_full_members]\n\n    if len(old_full_members) > 0:\n        remove_members_from_user_group(full_members_system_group, old_full_member_ids)\n\n    if len(new_full_members) > 0:\n        bulk_add_members_to_user_group(full_members_system_group, new_full_member_ids)\n\n\ndef promote_new_full_members() -> None:\n    for realm in Realm.objects.filter(deactivated=False).exclude(waiting_period_threshold=0):\n        update_users_in_full_members_system_group(realm)\n\n\n@transaction.atomic(savepoint=False)\ndef do_set_realm_property(\n    realm: Realm, name: str, value: Any, *, acting_user: Optional[UserProfile]\n) -> None:\n    \"\"\"Takes in a realm object, the name of an attribute to update, the\n    value to update and and the user who initiated the update.\n    \"\"\"\n    property_type = Realm.property_types[name]\n    assert isinstance(\n        value, property_type\n    ), f\"Cannot update {name}: {value} is not an instance of {property_type}\"\n\n    old_value = getattr(realm, name)\n    setattr(realm, name, value)\n    realm.save(update_fields=[name])\n\n    event = dict(\n        type=\"realm\",\n        op=\"update\",\n        property=name,\n        value=value,\n    )\n    transaction.on_commit(lambda: send_event(realm, event, active_user_ids(realm.id)))\n\n    event_time = timezone_now()\n    RealmAuditLog.objects.create(\n        realm=realm,\n        event_type=RealmAuditLog.REALM_PROPERTY_CHANGED,\n        event_time=event_time,\n        acting_user=acting_user,\n        extra_data=orjson.dumps(\n            {\n                RealmAuditLog.OLD_VALUE: old_value,\n                RealmAuditLog.NEW_VALUE: value,\n                \"property\": name,\n            }\n        ).decode(),\n    )\n\n    if name == \"email_address_visibility\":\n        if Realm.EMAIL_ADDRESS_VISIBILITY_EVERYONE not in [old_value, value]:\n            # We use real email addresses on UserProfile.email only if\n            # EMAIL_ADDRESS_VISIBILITY_EVERYONE is configured, so\n            # changes between values that will not require changing\n            # that field, so we can save work and return here.\n            return\n\n        user_profiles = UserProfile.objects.filter(realm=realm, is_bot=False)\n        for user_profile in user_profiles:\n            user_profile.email = get_display_email_address(user_profile)\n        UserProfile.objects.bulk_update(user_profiles, [\"email\"])\n\n        for user_profile in user_profiles:\n            transaction.on_commit(\n                lambda: flush_user_profile(sender=UserProfile, instance=user_profile)\n            )\n            # TODO: Design a bulk event for this or force-reload all clients\n            send_user_email_update_event(user_profile)\n\n    if name == \"waiting_period_threshold\":\n        update_users_in_full_members_system_group(realm)\n\n\ndef do_set_realm_authentication_methods(\n    realm: Realm, authentication_methods: Dict[str, bool], *, acting_user: Optional[UserProfile]\n) -> None:\n    old_value = realm.authentication_methods_dict()\n    with transaction.atomic():\n        for key, value in list(authentication_methods.items()):\n            index = getattr(realm.authentication_methods, key).number\n            realm.authentication_methods.set_bit(index, int(value))\n        realm.save(update_fields=[\"authentication_methods\"])\n        updated_value = realm.authentication_methods_dict()\n        RealmAuditLog.objects.create(\n            realm=realm,\n            event_type=RealmAuditLog.REALM_PROPERTY_CHANGED,\n            event_time=timezone_now(),\n            acting_user=acting_user,\n            extra_data=orjson.dumps(\n                {\n                    RealmAuditLog.OLD_VALUE: old_value,\n                    RealmAuditLog.NEW_VALUE: updated_value,\n                    \"property\": \"authentication_methods\",\n                }\n            ).decode(),\n        )\n\n    event = dict(\n        type=\"realm\",\n        op=\"update_dict\",\n        property=\"default\",\n        data=dict(authentication_methods=updated_value),\n    )\n    send_event(realm, event, active_user_ids(realm.id))\n\n\ndef do_set_realm_message_editing(\n    realm: Realm,\n    allow_message_editing: bool,\n    message_content_edit_limit_seconds: int,\n    edit_topic_policy: int,\n    *,\n    acting_user: Optional[UserProfile],\n) -> None:\n    old_values = dict(\n        allow_message_editing=realm.allow_message_editing,\n        message_content_edit_limit_seconds=realm.message_content_edit_limit_seconds,\n        edit_topic_policy=realm.edit_topic_policy,\n    )\n\n    realm.allow_message_editing = allow_message_editing\n    realm.message_content_edit_limit_seconds = message_content_edit_limit_seconds\n    realm.edit_topic_policy = edit_topic_policy\n\n    event_time = timezone_now()\n    updated_properties = dict(\n        allow_message_editing=allow_message_editing,\n        message_content_edit_limit_seconds=message_content_edit_limit_seconds,\n        edit_topic_policy=edit_topic_policy,\n    )\n\n    with transaction.atomic():\n        for updated_property, updated_value in updated_properties.items():\n            if updated_value == old_values[updated_property]:\n                continue\n            RealmAuditLog.objects.create(\n                realm=realm,\n                event_type=RealmAuditLog.REALM_PROPERTY_CHANGED,\n                event_time=event_time,\n                acting_user=acting_user,\n                extra_data=orjson.dumps(\n                    {\n                        RealmAuditLog.OLD_VALUE: old_values[updated_property],\n                        RealmAuditLog.NEW_VALUE: updated_value,\n                        \"property\": updated_property,\n                    }\n                ).decode(),\n            )\n\n        realm.save(update_fields=list(updated_properties.keys()))\n\n    event = dict(\n        type=\"realm\",\n        op=\"update_dict\",\n        property=\"default\",\n        data=updated_properties,\n    )\n    send_event(realm, event, active_user_ids(realm.id))\n\n\ndef do_set_realm_notifications_stream(\n    realm: Realm, stream: Optional[Stream], stream_id: int, *, acting_user: Optional[UserProfile]\n) -> None:\n    old_value = realm.notifications_stream_id\n    realm.notifications_stream = stream\n    with transaction.atomic():\n        realm.save(update_fields=[\"notifications_stream\"])\n\n        event_time = timezone_now()\n        RealmAuditLog.objects.create(\n            realm=realm,\n            event_type=RealmAuditLog.REALM_PROPERTY_CHANGED,\n            event_time=event_time,\n            acting_user=acting_user,\n            extra_data=orjson.dumps(\n                {\n                    RealmAuditLog.OLD_VALUE: old_value,\n                    RealmAuditLog.NEW_VALUE: stream_id,\n                    \"property\": \"notifications_stream\",\n                }\n            ).decode(),\n        )\n\n    event = dict(\n        type=\"realm\",\n        op=\"update\",\n        property=\"notifications_stream_id\",\n        value=stream_id,\n    )\n    send_event(realm, event, active_user_ids(realm.id))\n\n\ndef do_set_realm_signup_notifications_stream(\n    realm: Realm, stream: Optional[Stream], stream_id: int, *, acting_user: Optional[UserProfile]\n) -> None:\n    old_value = realm.signup_notifications_stream_id\n    realm.signup_notifications_stream = stream\n    with transaction.atomic():\n        realm.save(update_fields=[\"signup_notifications_stream\"])\n\n        event_time = timezone_now()\n        RealmAuditLog.objects.create(\n            realm=realm,\n            event_type=RealmAuditLog.REALM_PROPERTY_CHANGED,\n            event_time=event_time,\n            acting_user=acting_user,\n            extra_data=orjson.dumps(\n                {\n                    RealmAuditLog.OLD_VALUE: old_value,\n                    RealmAuditLog.NEW_VALUE: stream_id,\n                    \"property\": \"signup_notifications_stream\",\n                }\n            ).decode(),\n        )\n    event = dict(\n        type=\"realm\",\n        op=\"update\",\n        property=\"signup_notifications_stream_id\",\n        value=stream_id,\n    )\n    send_event(realm, event, active_user_ids(realm.id))\n\n\ndef do_set_realm_user_default_setting(\n    realm_user_default: RealmUserDefault,\n    name: str,\n    value: Any,\n    *,\n    acting_user: Optional[UserProfile],\n) -> None:\n    old_value = getattr(realm_user_default, name)\n    realm = realm_user_default.realm\n    event_time = timezone_now()\n\n    with transaction.atomic(savepoint=False):\n        setattr(realm_user_default, name, value)\n        realm_user_default.save(update_fields=[name])\n\n        RealmAuditLog.objects.create(\n            realm=realm,\n            event_type=RealmAuditLog.REALM_DEFAULT_USER_SETTINGS_CHANGED,\n            event_time=event_time,\n            acting_user=acting_user,\n            extra_data=orjson.dumps(\n                {\n                    RealmAuditLog.OLD_VALUE: old_value,\n                    RealmAuditLog.NEW_VALUE: value,\n                    \"property\": name,\n                }\n            ).decode(),\n        )\n\n    event = dict(\n        type=\"realm_user_settings_defaults\",\n        op=\"update\",\n        property=name,\n        value=value,\n    )\n    send_event(realm, event, active_user_ids(realm.id))\n\n\ndef do_deactivate_realm(realm: Realm, *, acting_user: Optional[UserProfile]) -> None:\n    \"\"\"\n    Deactivate this realm. Do NOT deactivate the users -- we need to be able to\n    tell the difference between users that were intentionally deactivated,\n    e.g. by a realm admin, and users who can't currently use Zulip because their\n    realm has been deactivated.\n    \"\"\"\n    if realm.deactivated:\n        return\n\n    realm.deactivated = True\n    realm.save(update_fields=[\"deactivated\"])\n\n    if settings.BILLING_ENABLED:\n        downgrade_now_without_creating_additional_invoices(realm)\n\n    event_time = timezone_now()\n    RealmAuditLog.objects.create(\n        realm=realm,\n        event_type=RealmAuditLog.REALM_DEACTIVATED,\n        event_time=event_time,\n        acting_user=acting_user,\n        extra_data=orjson.dumps(\n            {\n                RealmAuditLog.ROLE_COUNT: realm_user_count_by_role(realm),\n            }\n        ).decode(),\n    )\n\n    ScheduledEmail.objects.filter(realm=realm).delete()\n    for user in active_humans_in_realm(realm):\n        # Don't deactivate the users, but do delete their sessions so they get\n        # bumped to the login screen, where they'll get a realm deactivation\n        # notice when they try to log in.\n        delete_user_sessions(user)\n\n    # This event will only ever be received by clients with an active\n    # longpoll connection, because by this point clients will be\n    # unable to authenticate again to their event queue (triggering an\n    # immediate reload into the page explaining the realm was\n    # deactivated). So the purpose of sending this is to flush all\n    # active longpoll connections for the realm.\n    event = dict(type=\"realm\", op=\"deactivated\", realm_id=realm.id)\n    send_event(realm, event, active_user_ids(realm.id))\n\n\ndef do_reactivate_realm(realm: Realm) -> None:\n    realm.deactivated = False\n    with transaction.atomic():\n        realm.save(update_fields=[\"deactivated\"])\n\n        event_time = timezone_now()\n        RealmAuditLog.objects.create(\n            realm=realm,\n            event_type=RealmAuditLog.REALM_REACTIVATED,\n            event_time=event_time,\n            extra_data=orjson.dumps(\n                {\n                    RealmAuditLog.ROLE_COUNT: realm_user_count_by_role(realm),\n                }\n            ).decode(),\n        )\n\n\ndef do_change_realm_subdomain(\n    realm: Realm, new_subdomain: str, *, acting_user: Optional[UserProfile]\n) -> None:\n    \"\"\"Changing a realm's subdomain is a highly disruptive operation,\n    because all existing clients will need to be updated to point to\n    the new URL.  Further, requests to fetch data from existing event\n    queues will fail with an authentication error when this change\n    happens (because the old subdomain is no longer associated with\n    the realm), making it hard for us to provide a graceful update\n    experience for clients.\n    \"\"\"\n    old_subdomain = realm.subdomain\n    old_uri = realm.uri\n    # If the realm had been a demo organization scheduled for\n    # deleting, clear that state.\n    realm.demo_organization_scheduled_deletion_date = None\n    realm.string_id = new_subdomain\n    with transaction.atomic():\n        realm.save(update_fields=[\"string_id\", \"demo_organization_scheduled_deletion_date\"])\n        RealmAuditLog.objects.create(\n            realm=realm,\n            event_type=RealmAuditLog.REALM_SUBDOMAIN_CHANGED,\n            event_time=timezone_now(),\n            acting_user=acting_user,\n            extra_data={\"old_subdomain\": old_subdomain, \"new_subdomain\": new_subdomain},\n        )\n\n        # If a realm if being renamed multiple times, we should find all the placeholder\n        # realms and reset their deactivated_redirect field to point to the new realm uri\n        placeholder_realms = Realm.objects.filter(deactivated_redirect=old_uri, deactivated=True)\n        for placeholder_realm in placeholder_realms:\n            do_add_deactivated_redirect(placeholder_realm, realm.uri)\n\n    # The below block isn't executed in a transaction with the earlier code due to\n    # the functions called below being complex and potentially sending events,\n    # which we don't want to do in atomic blocks.\n    # When we change a realm's subdomain the realm with old subdomain is basically\n    # deactivated. We are creating a deactivated realm using old subdomain and setting\n    # it's deactivated redirect to new_subdomain so that we can tell the users that\n    # the realm has been moved to a new subdomain.\n    placeholder_realm = do_create_realm(old_subdomain, realm.name)\n    do_deactivate_realm(placeholder_realm, acting_user=None)\n    do_add_deactivated_redirect(placeholder_realm, realm.uri)\n\n\ndef do_add_deactivated_redirect(realm: Realm, redirect_url: str) -> None:\n    realm.deactivated_redirect = redirect_url\n    realm.save(update_fields=[\"deactivated_redirect\"])\n\n\ndef do_scrub_realm(realm: Realm, *, acting_user: Optional[UserProfile]) -> None:\n    if settings.BILLING_ENABLED:\n        downgrade_now_without_creating_additional_invoices(realm)\n\n    users = UserProfile.objects.filter(realm=realm)\n    for user in users:\n        do_delete_messages_by_sender(user)\n        do_delete_avatar_image(user, acting_user=acting_user)\n        user.full_name = f\"Scrubbed {generate_key()[:15]}\"\n        scrubbed_email = f\"scrubbed-{generate_key()[:15]}@{realm.host}\"\n        user.email = scrubbed_email\n        user.delivery_email = scrubbed_email\n        user.save(update_fields=[\"full_name\", \"email\", \"delivery_email\"])\n\n    do_remove_realm_custom_profile_fields(realm)\n    Attachment.objects.filter(realm=realm).delete()\n\n    RealmAuditLog.objects.create(\n        realm=realm,\n        event_time=timezone_now(),\n        acting_user=acting_user,\n        event_type=RealmAuditLog.REALM_SCRUBBED,\n    )\n\n\ndef do_delete_user(user_profile: UserProfile) -> None:\n    if user_profile.realm.is_zephyr_mirror_realm:\n        raise AssertionError(\"Deleting zephyr mirror users is not supported\")\n\n    do_deactivate_user(user_profile, acting_user=None)\n\n    subscribed_huddle_recipient_ids = set(\n        Subscription.objects.filter(\n            user_profile=user_profile, recipient__type=Recipient.HUDDLE\n        ).values_list(\"recipient_id\", flat=True)\n    )\n    user_id = user_profile.id\n    realm = user_profile.realm\n    date_joined = user_profile.date_joined\n    personal_recipient = user_profile.recipient\n\n    with transaction.atomic():\n        user_profile.delete()\n        # Recipient objects don't get deleted through CASCADE, so we need to handle\n        # the user's personal recipient manually. This will also delete all Messages pointing\n        # to this recipient (all private messages sent to the user).\n        assert personal_recipient is not None\n        personal_recipient.delete()\n        replacement_user = create_user(\n            force_id=user_id,\n            email=f\"deleteduser{user_id}@{get_fake_email_domain(realm)}\",\n            password=None,\n            realm=realm,\n            full_name=f\"Deleted User {user_id}\",\n            active=False,\n            is_mirror_dummy=True,\n            force_date_joined=date_joined,\n        )\n        subs_to_recreate = [\n            Subscription(\n                user_profile=replacement_user,\n                recipient=recipient,\n                is_user_active=replacement_user.is_active,\n            )\n            for recipient in Recipient.objects.filter(id__in=subscribed_huddle_recipient_ids)\n        ]\n        Subscription.objects.bulk_create(subs_to_recreate)\n\n        RealmAuditLog.objects.create(\n            realm=replacement_user.realm,\n            modified_user=replacement_user,\n            acting_user=None,\n            event_type=RealmAuditLog.USER_DELETED,\n            event_time=timezone_now(),\n        )\n\n\ndef change_user_is_active(user_profile: UserProfile, value: bool) -> None:\n    \"\"\"\n    Helper function for changing the .is_active field. Not meant as a standalone function\n    in production code as properly activating/deactivating users requires more steps.\n    This changes the is_active value and saves it, while ensuring\n    Subscription.is_user_active values are updated in the same db transaction.\n    \"\"\"\n    with transaction.atomic(savepoint=False):\n        user_profile.is_active = value\n        user_profile.save(update_fields=[\"is_active\"])\n        Subscription.objects.filter(user_profile=user_profile).update(is_user_active=value)\n\n\ndef get_active_bots_owned_by_user(user_profile: UserProfile) -> QuerySet:\n    return UserProfile.objects.filter(is_bot=True, is_active=True, bot_owner=user_profile)\n\n\ndef do_deactivate_user(\n    user_profile: UserProfile, _cascade: bool = True, *, acting_user: Optional[UserProfile]\n) -> None:\n    if not user_profile.is_active:\n        return\n\n    if _cascade:\n        # We need to deactivate bots before the target user, to ensure\n        # that a failure partway through this function cannot result\n        # in only the user being deactivated.\n        bot_profiles = get_active_bots_owned_by_user(user_profile)\n        for profile in bot_profiles:\n            do_deactivate_user(profile, _cascade=False, acting_user=acting_user)\n\n    with transaction.atomic():\n        if user_profile.realm.is_zephyr_mirror_realm:  # nocoverage\n            # For zephyr mirror users, we need to make them a mirror dummy\n            # again; otherwise, other users won't get the correct behavior\n            # when trying to send messages to this person inside Zulip.\n            #\n            # Ideally, we need to also ensure their zephyr mirroring bot\n            # isn't running, but that's a separate issue.\n            user_profile.is_mirror_dummy = True\n            user_profile.save(update_fields=[\"is_mirror_dummy\"])\n\n        change_user_is_active(user_profile, False)\n\n        clear_scheduled_emails(user_profile.id)\n        revoke_invites_generated_by_user(user_profile)\n\n        event_time = timezone_now()\n        RealmAuditLog.objects.create(\n            realm=user_profile.realm,\n            modified_user=user_profile,\n            acting_user=acting_user,\n            event_type=RealmAuditLog.USER_DEACTIVATED,\n            event_time=event_time,\n            extra_data=orjson.dumps(\n                {\n                    RealmAuditLog.ROLE_COUNT: realm_user_count_by_role(user_profile.realm),\n                }\n            ).decode(),\n        )\n        do_increment_logging_stat(\n            user_profile.realm,\n            COUNT_STATS[\"active_users_log:is_bot:day\"],\n            user_profile.is_bot,\n            event_time,\n            increment=-1,\n        )\n        if settings.BILLING_ENABLED:\n            update_license_ledger_if_needed(user_profile.realm, event_time)\n\n    delete_user_sessions(user_profile)\n    event = dict(\n        type=\"realm_user\",\n        op=\"remove\",\n        person=dict(user_id=user_profile.id, full_name=user_profile.full_name),\n    )\n    send_event(user_profile.realm, event, active_user_ids(user_profile.realm_id))\n\n    if user_profile.is_bot:\n        event = dict(\n            type=\"realm_bot\",\n            op=\"remove\",\n            bot=dict(user_id=user_profile.id, full_name=user_profile.full_name),\n        )\n        send_event(user_profile.realm, event, bot_owner_user_ids(user_profile))\n\n\n@transaction.atomic(savepoint=False)\ndef do_deactivate_stream(\n    stream: Stream, log: bool = True, *, acting_user: Optional[UserProfile]\n) -> None:\n    # We want to mark all messages in the to-be-deactivated stream as\n    # read for all users; otherwise they will pollute queries like\n    # \"Get the user's first unread message\".  Since this can be an\n    # expensive operation, we do it via the deferred_work queue\n    # processor.\n    deferred_work_event = {\n        \"type\": \"mark_stream_messages_as_read_for_everyone\",\n        \"stream_recipient_id\": stream.recipient_id,\n    }\n    transaction.on_commit(lambda: queue_json_publish(\"deferred_work\", deferred_work_event))\n\n    # Get the affected user ids *before* we deactivate everybody.\n    affected_user_ids = can_access_stream_user_ids(stream)\n\n    get_active_subscriptions_for_stream_id(stream.id, include_deactivated_users=True).update(\n        active=False\n    )\n\n    was_invite_only = stream.invite_only\n    stream.deactivated = True\n    stream.invite_only = True\n    # Preserve as much as possible the original stream name while giving it a\n    # special prefix that both indicates that the stream is deactivated and\n    # frees up the original name for reuse.\n    old_name = stream.name\n\n    # Prepend a substring of the hashed stream ID to the new stream name\n    streamID = str(stream.id)\n    stream_id_hash_object = hashlib.sha512(streamID.encode())\n    hashed_stream_id = stream_id_hash_object.hexdigest()[0:7]\n\n    new_name = (hashed_stream_id + \"!DEACTIVATED:\" + old_name)[: Stream.MAX_NAME_LENGTH]\n\n    stream.name = new_name[: Stream.MAX_NAME_LENGTH]\n    stream.save(update_fields=[\"name\", \"deactivated\", \"invite_only\"])\n\n    # If this is a default stream, remove it, properly sending a\n    # notification to browser clients.\n    if DefaultStream.objects.filter(realm_id=stream.realm_id, stream_id=stream.id).exists():\n        do_remove_default_stream(stream)\n\n    default_stream_groups_for_stream = DefaultStreamGroup.objects.filter(streams__id=stream.id)\n    for group in default_stream_groups_for_stream:\n        do_remove_streams_from_default_stream_group(stream.realm, group, [stream])\n\n    # Remove the old stream information from remote cache.\n    old_cache_key = get_stream_cache_key(old_name, stream.realm_id)\n    cache_delete(old_cache_key)\n\n    stream_dict = stream.to_dict()\n    stream_dict.update(dict(name=old_name, invite_only=was_invite_only))\n    event = dict(type=\"stream\", op=\"delete\", streams=[stream_dict])\n    transaction.on_commit(lambda: send_event(stream.realm, event, affected_user_ids))\n\n    event_time = timezone_now()\n    RealmAuditLog.objects.create(\n        realm=stream.realm,\n        acting_user=acting_user,\n        modified_stream=stream,\n        event_type=RealmAuditLog.STREAM_DEACTIVATED,\n        event_time=event_time,\n    )\n\n\ndef send_user_email_update_event(user_profile: UserProfile) -> None:\n    payload = dict(user_id=user_profile.id, new_email=user_profile.email)\n    event = dict(type=\"realm_user\", op=\"update\", person=payload)\n    transaction.on_commit(\n        lambda: send_event(\n            user_profile.realm,\n            event,\n            active_user_ids(user_profile.realm_id),\n        )\n    )\n\n\n@transaction.atomic(savepoint=False)\ndef do_change_user_delivery_email(user_profile: UserProfile, new_email: str) -> None:\n    delete_user_profile_caches([user_profile])\n\n    user_profile.delivery_email = new_email\n    if user_profile.email_address_is_realm_public():\n        user_profile.email = new_email\n        user_profile.save(update_fields=[\"email\", \"delivery_email\"])\n    else:\n        user_profile.save(update_fields=[\"delivery_email\"])\n\n    # We notify just the target user (and eventually org admins, only\n    # when email_address_visibility=EMAIL_ADDRESS_VISIBILITY_ADMINS)\n    # about their new delivery email, since that field is private.\n    payload = dict(user_id=user_profile.id, delivery_email=new_email)\n    event = dict(type=\"realm_user\", op=\"update\", person=payload)\n    transaction.on_commit(lambda: send_event(user_profile.realm, event, [user_profile.id]))\n\n    if user_profile.avatar_source == UserProfile.AVATAR_FROM_GRAVATAR:\n        # If the user is using Gravatar to manage their email address,\n        # their Gravatar just changed, and we need to notify other\n        # clients.\n        notify_avatar_url_change(user_profile)\n\n    if user_profile.email_address_is_realm_public():\n        # Additionally, if we're also changing the publicly visible\n        # email, we send a new_email event as well.\n        send_user_email_update_event(user_profile)\n\n    event_time = timezone_now()\n    RealmAuditLog.objects.create(\n        realm=user_profile.realm,\n        acting_user=user_profile,\n        modified_user=user_profile,\n        event_type=RealmAuditLog.USER_EMAIL_CHANGED,\n        event_time=event_time,\n    )\n\n\ndef do_start_email_change_process(user_profile: UserProfile, new_email: str) -> None:\n    old_email = user_profile.delivery_email\n    obj = EmailChangeStatus.objects.create(\n        new_email=new_email,\n        old_email=old_email,\n        user_profile=user_profile,\n        realm=user_profile.realm,\n    )\n\n    activation_url = create_confirmation_link(obj, Confirmation.EMAIL_CHANGE)\n    from zerver.context_processors import common_context\n\n    context = common_context(user_profile)\n    context.update(\n        old_email=old_email,\n        new_email=new_email,\n        activate_url=activation_url,\n    )\n    language = user_profile.default_language\n    send_email(\n        \"zerver/emails/confirm_new_email\",\n        to_emails=[new_email],\n        from_name=FromAddress.security_email_from_name(language=language),\n        from_address=FromAddress.tokenized_no_reply_address(),\n        language=language,\n        context=context,\n        realm=user_profile.realm,\n    )\n\n\ndef compute_irc_user_fullname(email: str) -> str:\n    return email.split(\"@\")[0] + \" (IRC)\"\n\n\ndef compute_jabber_user_fullname(email: str) -> str:\n    return email.split(\"@\")[0] + \" (XMPP)\"\n\n\n@cache_with_key(\n    lambda realm, email, f: user_profile_delivery_email_cache_key(email, realm),\n    timeout=3600 * 24 * 7,\n)\ndef create_mirror_user_if_needed(\n    realm: Realm, email: str, email_to_fullname: Callable[[str], str]\n) -> UserProfile:\n    try:\n        return get_user_by_delivery_email(email, realm)\n    except UserProfile.DoesNotExist:\n        try:\n            # Forge a user for this person\n            return create_user(\n                email=email,\n                password=None,\n                realm=realm,\n                full_name=email_to_fullname(email),\n                active=False,\n                is_mirror_dummy=True,\n            )\n        except IntegrityError:\n            return get_user_by_delivery_email(email, realm)\n\n\ndef render_incoming_message(\n    message: Message,\n    content: str,\n    user_ids: Set[int],\n    realm: Realm,\n    mention_data: Optional[MentionData] = None,\n    email_gateway: bool = False,\n) -> MessageRenderingResult:\n    realm_alert_words_automaton = get_alert_word_automaton(realm)\n    try:\n        rendering_result = render_markdown(\n            message=message,\n            content=content,\n            realm=realm,\n            realm_alert_words_automaton=realm_alert_words_automaton,\n            mention_data=mention_data,\n            email_gateway=email_gateway,\n        )\n    except MarkdownRenderingException:\n        raise JsonableError(_(\"Unable to render message\"))\n    return rendering_result\n\n\nclass RecipientInfoResult(TypedDict):\n    active_user_ids: Set[int]\n    online_push_user_ids: Set[int]\n    pm_mention_email_disabled_user_ids: Set[int]\n    pm_mention_push_disabled_user_ids: Set[int]\n    stream_email_user_ids: Set[int]\n    stream_push_user_ids: Set[int]\n    wildcard_mention_user_ids: Set[int]\n    muted_sender_user_ids: Set[int]\n    um_eligible_user_ids: Set[int]\n    long_term_idle_user_ids: Set[int]\n    default_bot_user_ids: Set[int]\n    service_bot_tuples: List[Tuple[int, int]]\n    all_bot_user_ids: Set[int]\n\n\ndef get_recipient_info(\n    *,\n    realm_id: int,\n    recipient: Recipient,\n    sender_id: int,\n    stream_topic: Optional[StreamTopicTarget],\n    possibly_mentioned_user_ids: AbstractSet[int] = set(),\n    possible_wildcard_mention: bool = True,\n) -> RecipientInfoResult:\n    stream_push_user_ids: Set[int] = set()\n    stream_email_user_ids: Set[int] = set()\n    wildcard_mention_user_ids: Set[int] = set()\n    muted_sender_user_ids: Set[int] = get_muting_users(sender_id)\n\n    if recipient.type == Recipient.PERSONAL:\n        # The sender and recipient may be the same id, so\n        # de-duplicate using a set.\n        message_to_user_ids = list({recipient.type_id, sender_id})\n        assert len(message_to_user_ids) in [1, 2]\n\n    elif recipient.type == Recipient.STREAM:\n        # Anybody calling us w/r/t a stream message needs to supply\n        # stream_topic.  We may eventually want to have different versions\n        # of this function for different message types.\n        assert stream_topic is not None\n        user_ids_muting_topic = stream_topic.user_ids_muting_topic()\n\n        subscription_rows = (\n            get_subscriptions_for_send_message(\n                realm_id=realm_id,\n                stream_id=stream_topic.stream_id,\n                possible_wildcard_mention=possible_wildcard_mention,\n                possibly_mentioned_user_ids=possibly_mentioned_user_ids,\n            )\n            .annotate(\n                user_profile_email_notifications=F(\n                    \"user_profile__enable_stream_email_notifications\"\n                ),\n                user_profile_push_notifications=F(\"user_profile__enable_stream_push_notifications\"),\n                user_profile_wildcard_mentions_notify=F(\"user_profile__wildcard_mentions_notify\"),\n            )\n            .values(\n                \"user_profile_id\",\n                \"push_notifications\",\n                \"email_notifications\",\n                \"wildcard_mentions_notify\",\n                \"user_profile_email_notifications\",\n                \"user_profile_push_notifications\",\n                \"user_profile_wildcard_mentions_notify\",\n                \"is_muted\",\n            )\n            .order_by(\"user_profile_id\")\n        )\n\n        message_to_user_ids = [row[\"user_profile_id\"] for row in subscription_rows]\n\n        def should_send(setting: str, row: Dict[str, Any]) -> bool:\n            # This implements the structure that the UserProfile stream notification settings\n            # are defaults, which can be overridden by the stream-level settings (if those\n            # values are not null).\n            if row[\"is_muted\"]:\n                return False\n            if row[\"user_profile_id\"] in user_ids_muting_topic:\n                return False\n            if row[setting] is not None:\n                return row[setting]\n            return row[\"user_profile_\" + setting]\n\n        stream_push_user_ids = {\n            row[\"user_profile_id\"]\n            for row in subscription_rows\n            # Note: muting a stream overrides stream_push_notify\n            if should_send(\"push_notifications\", row)\n        }\n\n        stream_email_user_ids = {\n            row[\"user_profile_id\"]\n            for row in subscription_rows\n            # Note: muting a stream overrides stream_email_notify\n            if should_send(\"email_notifications\", row)\n        }\n\n        if possible_wildcard_mention:\n            # If there's a possible wildcard mention, we need to\n            # determine the set of users who have enabled the\n            # \"wildcard_mentions_notify\" setting (that is, the set of\n            # users for whom wildcard mentions should be treated like\n            # personal mentions for notifications). This setting\n            # applies to both email and push notifications.\n            wildcard_mention_user_ids = {\n                row[\"user_profile_id\"]\n                for row in subscription_rows\n                if should_send(\"wildcard_mentions_notify\", row)\n            }\n\n    elif recipient.type == Recipient.HUDDLE:\n        message_to_user_ids = get_huddle_user_ids(recipient)\n\n    else:\n        raise ValueError(\"Bad recipient type\")\n\n    message_to_user_id_set = set(message_to_user_ids)\n\n    user_ids = set(message_to_user_id_set)\n    # Important note: Because we haven't rendered Markdown yet, we\n    # don't yet know which of these possibly-mentioned users was\n    # actually mentioned in the message (in other words, the\n    # mention syntax might have been in a code block or otherwise\n    # escaped).  `get_ids_for` will filter these extra user rows\n    # for our data structures not related to bots\n    user_ids |= possibly_mentioned_user_ids\n\n    if user_ids:\n        query = UserProfile.objects.filter(is_active=True).values(\n            \"id\",\n            \"enable_online_push_notifications\",\n            \"enable_offline_email_notifications\",\n            \"enable_offline_push_notifications\",\n            \"is_bot\",\n            \"bot_type\",\n            \"long_term_idle\",\n        )\n\n        # query_for_ids is fast highly optimized for large queries, and we\n        # need this codepath to be fast (it's part of sending messages)\n        query = query_for_ids(\n            query=query,\n            user_ids=sorted(user_ids),\n            field=\"id\",\n        )\n        rows = list(query)\n    else:\n        # TODO: We should always have at least one user_id as a recipient\n        #       of any message we send.  Right now the exception to this\n        #       rule is `notify_new_user`, which, at least in a possibly\n        #       contrived test scenario, can attempt to send messages\n        #       to an inactive bot.  When we plug that hole, we can avoid\n        #       this `else` clause and just `assert(user_ids)`.\n        #\n        # UPDATE: It's February 2020 (and a couple years after the above\n        #         comment was written).  We have simplified notify_new_user\n        #         so that it should be a little easier to reason about.\n        #         There is currently some cleanup to how we handle cross\n        #         realm bots that is still under development.  Once that\n        #         effort is complete, we should be able to address this\n        #         to-do.\n        rows = []\n\n    def get_ids_for(f: Callable[[Dict[str, Any]], bool]) -> Set[int]:\n        \"\"\"Only includes users on the explicit message to line\"\"\"\n        return {row[\"id\"] for row in rows if f(row)} & message_to_user_id_set\n\n    def is_service_bot(row: Dict[str, Any]) -> bool:\n        return row[\"is_bot\"] and (row[\"bot_type\"] in UserProfile.SERVICE_BOT_TYPES)\n\n    active_user_ids = get_ids_for(lambda r: True)\n    online_push_user_ids = get_ids_for(\n        lambda r: r[\"enable_online_push_notifications\"],\n    )\n\n    # We deal with only the users who have disabled this setting, since that\n    # will usually be much smaller a set than those who have enabled it (which\n    # is the default)\n    pm_mention_email_disabled_user_ids = get_ids_for(\n        lambda r: not r[\"enable_offline_email_notifications\"]\n    )\n    pm_mention_push_disabled_user_ids = get_ids_for(\n        lambda r: not r[\"enable_offline_push_notifications\"]\n    )\n\n    # Service bots don't get UserMessage rows.\n    um_eligible_user_ids = get_ids_for(\n        lambda r: not is_service_bot(r),\n    )\n\n    long_term_idle_user_ids = get_ids_for(\n        lambda r: r[\"long_term_idle\"],\n    )\n\n    # These three bot data structures need to filter from the full set\n    # of users who either are receiving the message or might have been\n    # mentioned in it, and so can't use get_ids_for.\n    #\n    # Further in the do_send_messages code path, once\n    # `mentioned_user_ids` has been computed via Markdown, we'll filter\n    # these data structures for just those users who are either a\n    # direct recipient or were mentioned; for now, we're just making\n    # sure we have the data we need for that without extra database\n    # queries.\n    default_bot_user_ids = {\n        row[\"id\"] for row in rows if row[\"is_bot\"] and row[\"bot_type\"] == UserProfile.DEFAULT_BOT\n    }\n\n    service_bot_tuples = [(row[\"id\"], row[\"bot_type\"]) for row in rows if is_service_bot(row)]\n\n    # We also need the user IDs of all bots, to avoid trying to send push/email\n    # notifications to them. This set will be directly sent to the event queue code\n    # where we determine notifiability of the message for users.\n    all_bot_user_ids = {row[\"id\"] for row in rows if row[\"is_bot\"]}\n\n    info: RecipientInfoResult = dict(\n        active_user_ids=active_user_ids,\n        online_push_user_ids=online_push_user_ids,\n        pm_mention_email_disabled_user_ids=pm_mention_email_disabled_user_ids,\n        pm_mention_push_disabled_user_ids=pm_mention_push_disabled_user_ids,\n        stream_push_user_ids=stream_push_user_ids,\n        stream_email_user_ids=stream_email_user_ids,\n        wildcard_mention_user_ids=wildcard_mention_user_ids,\n        muted_sender_user_ids=muted_sender_user_ids,\n        um_eligible_user_ids=um_eligible_user_ids,\n        long_term_idle_user_ids=long_term_idle_user_ids,\n        default_bot_user_ids=default_bot_user_ids,\n        service_bot_tuples=service_bot_tuples,\n        all_bot_user_ids=all_bot_user_ids,\n    )\n    return info\n\n\ndef get_service_bot_events(\n    sender: UserProfile,\n    service_bot_tuples: List[Tuple[int, int]],\n    mentioned_user_ids: Set[int],\n    active_user_ids: Set[int],\n    recipient_type: int,\n) -> Dict[str, List[Dict[str, Any]]]:\n\n    event_dict: Dict[str, List[Dict[str, Any]]] = defaultdict(list)\n\n    # Avoid infinite loops by preventing messages sent by bots from generating\n    # Service events.\n    if sender.is_bot:\n        return event_dict\n\n    def maybe_add_event(user_profile_id: int, bot_type: int) -> None:\n        if bot_type == UserProfile.OUTGOING_WEBHOOK_BOT:\n            queue_name = \"outgoing_webhooks\"\n        elif bot_type == UserProfile.EMBEDDED_BOT:\n            queue_name = \"embedded_bots\"\n        else:\n            logging.error(\n                \"Unexpected bot_type for Service bot id=%s: %s\",\n                user_profile_id,\n                bot_type,\n            )\n            return\n\n        is_stream = recipient_type == Recipient.STREAM\n\n        # Important note: service_bot_tuples may contain service bots\n        # who were not actually mentioned in the message (e.g. if\n        # mention syntax for that bot appeared in a code block).\n        # Thus, it is important to filter any users who aren't part of\n        # either mentioned_user_ids (the actual mentioned users) or\n        # active_user_ids (the actual recipients).\n        #\n        # So even though this is implied by the logic below, we filter\n        # these not-actually-mentioned users here, to help keep this\n        # function future-proof.\n        if user_profile_id not in mentioned_user_ids and user_profile_id not in active_user_ids:\n            return\n\n        # Mention triggers, for stream messages\n        if is_stream and user_profile_id in mentioned_user_ids:\n            trigger = \"mention\"\n        # PM triggers for personal and huddle messages\n        elif (not is_stream) and (user_profile_id in active_user_ids):\n            trigger = \"private_message\"\n        else:\n            return\n\n        event_dict[queue_name].append(\n            {\n                \"trigger\": trigger,\n                \"user_profile_id\": user_profile_id,\n            }\n        )\n\n    for user_profile_id, bot_type in service_bot_tuples:\n        maybe_add_event(\n            user_profile_id=user_profile_id,\n            bot_type=bot_type,\n        )\n\n    return event_dict\n\n\ndef do_schedule_messages(send_message_requests: Sequence[SendMessageRequest]) -> List[int]:\n    scheduled_messages: List[ScheduledMessage] = []\n\n    for send_request in send_message_requests:\n        scheduled_message = ScheduledMessage()\n        scheduled_message.sender = send_request.message.sender\n        scheduled_message.recipient = send_request.message.recipient\n        topic_name = send_request.message.topic_name()\n        scheduled_message.set_topic_name(topic_name=topic_name)\n        scheduled_message.content = send_request.message.content\n        scheduled_message.sending_client = send_request.message.sending_client\n        scheduled_message.stream = send_request.stream\n        scheduled_message.realm = send_request.realm\n        assert send_request.deliver_at is not None\n        scheduled_message.scheduled_timestamp = send_request.deliver_at\n        if send_request.delivery_type == \"send_later\":\n            scheduled_message.delivery_type = ScheduledMessage.SEND_LATER\n        elif send_request.delivery_type == \"remind\":\n            scheduled_message.delivery_type = ScheduledMessage.REMIND\n\n        scheduled_messages.append(scheduled_message)\n\n    ScheduledMessage.objects.bulk_create(scheduled_messages)\n    return [scheduled_message.id for scheduled_message in scheduled_messages]\n\n\ndef build_message_send_dict(\n    message: Message,\n    stream: Optional[Stream] = None,\n    local_id: Optional[str] = None,\n    sender_queue_id: Optional[str] = None,\n    realm: Optional[Realm] = None,\n    widget_content_dict: Optional[Dict[str, Any]] = None,\n    email_gateway: bool = False,\n    mention_backend: Optional[MentionBackend] = None,\n    limit_unread_user_ids: Optional[Set[int]] = None,\n) -> SendMessageRequest:\n    \"\"\"Returns a dictionary that can be passed into do_send_messages.  In\n    production, this is always called by check_message, but some\n    testing code paths call it directly.\n    \"\"\"\n    if realm is None:\n        realm = message.sender.realm\n\n    if mention_backend is None:\n        mention_backend = MentionBackend(realm.id)\n\n    mention_data = MentionData(\n        mention_backend=mention_backend,\n        content=message.content,\n    )\n\n    if message.is_stream_message():\n        stream_id = message.recipient.type_id\n        stream_topic: Optional[StreamTopicTarget] = StreamTopicTarget(\n            stream_id=stream_id,\n            topic_name=message.topic_name(),\n        )\n    else:\n        stream_topic = None\n\n    info = get_recipient_info(\n        realm_id=realm.id,\n        recipient=message.recipient,\n        sender_id=message.sender_id,\n        stream_topic=stream_topic,\n        possibly_mentioned_user_ids=mention_data.get_user_ids(),\n        possible_wildcard_mention=mention_data.message_has_wildcards(),\n    )\n\n    # Render our message_dicts.\n    assert message.rendered_content is None\n\n    rendering_result = render_incoming_message(\n        message,\n        message.content,\n        info[\"active_user_ids\"],\n        realm,\n        mention_data=mention_data,\n        email_gateway=email_gateway,\n    )\n    message.rendered_content = rendering_result.rendered_content\n    message.rendered_content_version = markdown_version\n    links_for_embed = rendering_result.links_for_preview\n\n    mentioned_user_groups_map = get_user_group_mentions_data(\n        mentioned_user_ids=rendering_result.mentions_user_ids,\n        mentioned_user_group_ids=list(rendering_result.mentions_user_group_ids),\n        mention_data=mention_data,\n    )\n\n    # For single user as well as user group mentions, we set the `mentioned`\n    # flag on `UserMessage`\n    for group_id in rendering_result.mentions_user_group_ids:\n        members = mention_data.get_group_members(group_id)\n        rendering_result.mentions_user_ids.update(members)\n\n    # Only send data to Tornado about wildcard mentions if message\n    # rendering determined the message had an actual wildcard\n    # mention in it (and not e.g. wildcard mention syntax inside a\n    # code block).\n    if rendering_result.mentions_wildcard:\n        wildcard_mention_user_ids = info[\"wildcard_mention_user_ids\"]\n    else:\n        wildcard_mention_user_ids = set()\n\n    \"\"\"\n    Once we have the actual list of mentioned ids from message\n    rendering, we can patch in \"default bots\" (aka normal bots)\n    who were directly mentioned in this message as eligible to\n    get UserMessage rows.\n    \"\"\"\n    mentioned_user_ids = rendering_result.mentions_user_ids\n    default_bot_user_ids = info[\"default_bot_user_ids\"]\n    mentioned_bot_user_ids = default_bot_user_ids & mentioned_user_ids\n    info[\"um_eligible_user_ids\"] |= mentioned_bot_user_ids\n\n    message_send_dict = SendMessageRequest(\n        stream=stream,\n        local_id=local_id,\n        sender_queue_id=sender_queue_id,\n        realm=realm,\n        mention_data=mention_data,\n        mentioned_user_groups_map=mentioned_user_groups_map,\n        message=message,\n        rendering_result=rendering_result,\n        active_user_ids=info[\"active_user_ids\"],\n        online_push_user_ids=info[\"online_push_user_ids\"],\n        pm_mention_email_disabled_user_ids=info[\"pm_mention_email_disabled_user_ids\"],\n        pm_mention_push_disabled_user_ids=info[\"pm_mention_push_disabled_user_ids\"],\n        stream_push_user_ids=info[\"stream_push_user_ids\"],\n        stream_email_user_ids=info[\"stream_email_user_ids\"],\n        muted_sender_user_ids=info[\"muted_sender_user_ids\"],\n        um_eligible_user_ids=info[\"um_eligible_user_ids\"],\n        long_term_idle_user_ids=info[\"long_term_idle_user_ids\"],\n        default_bot_user_ids=info[\"default_bot_user_ids\"],\n        service_bot_tuples=info[\"service_bot_tuples\"],\n        all_bot_user_ids=info[\"all_bot_user_ids\"],\n        wildcard_mention_user_ids=wildcard_mention_user_ids,\n        links_for_embed=links_for_embed,\n        widget_content=widget_content_dict,\n        limit_unread_user_ids=limit_unread_user_ids,\n    )\n\n    return message_send_dict\n\n\ndef do_send_messages(\n    send_message_requests_maybe_none: Sequence[Optional[SendMessageRequest]],\n    email_gateway: bool = False,\n    mark_as_read: Sequence[int] = [],\n) -> List[int]:\n    \"\"\"See\n    https://zulip.readthedocs.io/en/latest/subsystems/sending-messages.html\n    for high-level documentation on this subsystem.\n    \"\"\"\n\n    # Filter out messages which didn't pass internal_prep_message properly\n    send_message_requests = [\n        send_request\n        for send_request in send_message_requests_maybe_none\n        if send_request is not None\n    ]\n\n    # Save the message receipts in the database\n    user_message_flags: Dict[int, Dict[int, List[str]]] = defaultdict(dict)\n    with transaction.atomic():\n        Message.objects.bulk_create(send_request.message for send_request in send_message_requests)\n\n        # Claim attachments in message\n        for send_request in send_message_requests:\n            if do_claim_attachments(\n                send_request.message, send_request.rendering_result.potential_attachment_path_ids\n            ):\n                send_request.message.has_attachment = True\n                send_request.message.save(update_fields=[\"has_attachment\"])\n\n        ums: List[UserMessageLite] = []\n        for send_request in send_message_requests:\n            # Service bots (outgoing webhook bots and embedded bots) don't store UserMessage rows;\n            # they will be processed later.\n            mentioned_user_ids = send_request.rendering_result.mentions_user_ids\n\n            # Extend the set with users who have muted the sender.\n            mark_as_read_user_ids = send_request.muted_sender_user_ids\n            mark_as_read_user_ids.update(mark_as_read)\n\n            user_messages = create_user_messages(\n                message=send_request.message,\n                rendering_result=send_request.rendering_result,\n                um_eligible_user_ids=send_request.um_eligible_user_ids,\n                long_term_idle_user_ids=send_request.long_term_idle_user_ids,\n                stream_push_user_ids=send_request.stream_push_user_ids,\n                stream_email_user_ids=send_request.stream_email_user_ids,\n                mentioned_user_ids=mentioned_user_ids,\n                mark_as_read_user_ids=mark_as_read_user_ids,\n                limit_unread_user_ids=send_request.limit_unread_user_ids,\n            )\n\n            for um in user_messages:\n                user_message_flags[send_request.message.id][um.user_profile_id] = um.flags_list()\n\n            ums.extend(user_messages)\n\n            send_request.message.service_queue_events = get_service_bot_events(\n                sender=send_request.message.sender,\n                service_bot_tuples=send_request.service_bot_tuples,\n                mentioned_user_ids=mentioned_user_ids,\n                active_user_ids=send_request.active_user_ids,\n                recipient_type=send_request.message.recipient.type,\n            )\n\n        bulk_insert_ums(ums)\n\n        for send_request in send_message_requests:\n            do_widget_post_save_actions(send_request)\n\n    # This next loop is responsible for notifying other parts of the\n    # Zulip system about the messages we just committed to the database:\n    # * Notifying clients via send_event\n    # * Triggering outgoing webhooks via the service event queue.\n    # * Updating the `first_message_id` field for streams without any message history.\n    # * Implementing the Welcome Bot reply hack\n    # * Adding links to the embed_links queue for open graph processing.\n    for send_request in send_message_requests:\n        realm_id: Optional[int] = None\n        if send_request.message.is_stream_message():\n            if send_request.stream is None:\n                stream_id = send_request.message.recipient.type_id\n                send_request.stream = Stream.objects.select_related().get(id=stream_id)\n            # assert needed because stubs for django are missing\n            assert send_request.stream is not None\n            realm_id = send_request.stream.realm_id\n\n        # Deliver events to the real-time push system, as well as\n        # enqueuing any additional processing triggered by the message.\n        wide_message_dict = MessageDict.wide_dict(send_request.message, realm_id)\n\n        user_flags = user_message_flags.get(send_request.message.id, {})\n\n        \"\"\"\n        TODO:  We may want to limit user_ids to only those users who have\n               UserMessage rows, if only for minor performance reasons.\n\n               For now we queue events for all subscribers/sendees of the\n               message, since downstream code may still do notifications\n               that don't require UserMessage rows.\n\n               Our automated tests have gotten better on this codepath,\n               but we may have coverage gaps, so we should be careful\n               about changing the next line.\n        \"\"\"\n        user_ids = send_request.active_user_ids | set(user_flags.keys())\n        sender_id = send_request.message.sender_id\n\n        # We make sure the sender is listed first in the `users` list;\n        # this results in the sender receiving the message first if\n        # there are thousands of recipients, decreasing perceived latency.\n        if sender_id in user_ids:\n            user_list = [sender_id] + list(user_ids - {sender_id})\n        else:\n            user_list = list(user_ids)\n\n        class UserData(TypedDict):\n            id: int\n            flags: List[str]\n            mentioned_user_group_id: Optional[int]\n\n        users: List[UserData] = []\n        for user_id in user_list:\n            flags = user_flags.get(user_id, [])\n            user_data: UserData = dict(id=user_id, flags=flags, mentioned_user_group_id=None)\n\n            if user_id in send_request.mentioned_user_groups_map:\n                user_data[\"mentioned_user_group_id\"] = send_request.mentioned_user_groups_map[\n                    user_id\n                ]\n\n            users.append(user_data)\n\n        sender = send_request.message.sender\n        message_type = wide_message_dict[\"type\"]\n        active_users_data = [\n            ActivePresenceIdleUserData(\n                alerted=\"has_alert_word\" in user_flags.get(user_id, []),\n                notifications_data=UserMessageNotificationsData.from_user_id_sets(\n                    user_id=user_id,\n                    flags=user_flags.get(user_id, []),\n                    private_message=(message_type == \"private\"),\n                    online_push_user_ids=send_request.online_push_user_ids,\n                    pm_mention_push_disabled_user_ids=send_request.pm_mention_push_disabled_user_ids,\n                    pm_mention_email_disabled_user_ids=send_request.pm_mention_email_disabled_user_ids,\n                    stream_push_user_ids=send_request.stream_push_user_ids,\n                    stream_email_user_ids=send_request.stream_email_user_ids,\n                    wildcard_mention_user_ids=send_request.wildcard_mention_user_ids,\n                    muted_sender_user_ids=send_request.muted_sender_user_ids,\n                    all_bot_user_ids=send_request.all_bot_user_ids,\n                ),\n            )\n            for user_id in send_request.active_user_ids\n        ]\n\n        presence_idle_user_ids = get_active_presence_idle_user_ids(\n            realm=sender.realm,\n            sender_id=sender.id,\n            active_users_data=active_users_data,\n        )\n\n        event = dict(\n            type=\"message\",\n            message=send_request.message.id,\n            message_dict=wide_message_dict,\n            presence_idle_user_ids=presence_idle_user_ids,\n            online_push_user_ids=list(send_request.online_push_user_ids),\n            pm_mention_push_disabled_user_ids=list(send_request.pm_mention_push_disabled_user_ids),\n            pm_mention_email_disabled_user_ids=list(\n                send_request.pm_mention_email_disabled_user_ids\n            ),\n            stream_push_user_ids=list(send_request.stream_push_user_ids),\n            stream_email_user_ids=list(send_request.stream_email_user_ids),\n            wildcard_mention_user_ids=list(send_request.wildcard_mention_user_ids),\n            muted_sender_user_ids=list(send_request.muted_sender_user_ids),\n            all_bot_user_ids=list(send_request.all_bot_user_ids),\n        )\n\n        if send_request.message.is_stream_message():\n            # Note: This is where authorization for single-stream\n            # get_updates happens! We only attach stream data to the\n            # notify new_message request if it's a public stream,\n            # ensuring that in the tornado server, non-public stream\n            # messages are only associated to their subscribed users.\n\n            # assert needed because stubs for django are missing\n            assert send_request.stream is not None\n            if send_request.stream.is_public():\n                event[\"realm_id\"] = send_request.stream.realm_id\n                event[\"stream_name\"] = send_request.stream.name\n            if send_request.stream.invite_only:\n                event[\"invite_only\"] = True\n            if send_request.stream.first_message_id is None:\n                send_request.stream.first_message_id = send_request.message.id\n                send_request.stream.save(update_fields=[\"first_message_id\"])\n        if send_request.local_id is not None:\n            event[\"local_id\"] = send_request.local_id\n        if send_request.sender_queue_id is not None:\n            event[\"sender_queue_id\"] = send_request.sender_queue_id\n        send_event(send_request.realm, event, users)\n\n        if send_request.links_for_embed:\n            event_data = {\n                \"message_id\": send_request.message.id,\n                \"message_content\": send_request.message.content,\n                \"message_realm_id\": send_request.realm.id,\n                \"urls\": list(send_request.links_for_embed),\n            }\n            queue_json_publish(\"embed_links\", event_data)\n\n        if send_request.message.recipient.type == Recipient.PERSONAL:\n            welcome_bot_id = get_system_bot(\n                settings.WELCOME_BOT, send_request.message.sender.realm_id\n            ).id\n            if (\n                welcome_bot_id in send_request.active_user_ids\n                and welcome_bot_id != send_request.message.sender_id\n            ):\n                from zerver.lib.onboarding import send_welcome_bot_response\n\n                send_welcome_bot_response(send_request)\n\n        for queue_name, events in send_request.message.service_queue_events.items():\n            for event in events:\n                queue_json_publish(\n                    queue_name,\n                    {\n                        \"message\": wide_message_dict,\n                        \"trigger\": event[\"trigger\"],\n                        \"user_profile_id\": event[\"user_profile_id\"],\n                    },\n                )\n\n    return [send_request.message.id for send_request in send_message_requests]\n\n\nclass UserMessageLite:\n    \"\"\"\n    The Django ORM is too slow for bulk operations.  This class\n    is optimized for the simple use case of inserting a bunch of\n    rows into zerver_usermessage.\n    \"\"\"\n\n    def __init__(self, user_profile_id: int, message_id: int, flags: int) -> None:\n        self.user_profile_id = user_profile_id\n        self.message_id = message_id\n        self.flags = flags\n\n    def flags_list(self) -> List[str]:\n        return UserMessage.flags_list_for_flags(self.flags)\n\n\ndef create_user_messages(\n    message: Message,\n    rendering_result: MessageRenderingResult,\n    um_eligible_user_ids: AbstractSet[int],\n    long_term_idle_user_ids: AbstractSet[int],\n    stream_push_user_ids: AbstractSet[int],\n    stream_email_user_ids: AbstractSet[int],\n    mentioned_user_ids: AbstractSet[int],\n    mark_as_read_user_ids: Set[int],\n    limit_unread_user_ids: Optional[Set[int]],\n) -> List[UserMessageLite]:\n    # These properties on the Message are set via\n    # render_markdown by code in the Markdown inline patterns\n    ids_with_alert_words = rendering_result.user_ids_with_alert_words\n    sender_id = message.sender.id\n    is_stream_message = message.is_stream_message()\n\n    base_flags = 0\n    if rendering_result.mentions_wildcard:\n        base_flags |= UserMessage.flags.wildcard_mentioned\n    if message.recipient.type in [Recipient.HUDDLE, Recipient.PERSONAL]:\n        base_flags |= UserMessage.flags.is_private\n\n    # For long_term_idle (aka soft-deactivated) users, we are allowed\n    # to optimize by lazily not creating UserMessage rows that would\n    # have the default 0 flag set (since the soft-reactivation logic\n    # knows how to create those when the user comes back).  We need to\n    # create the UserMessage rows for these long_term_idle users\n    # non-lazily in a few cases:\n    #\n    # * There are nonzero flags (e.g. the user was mentioned), since\n    #   that case is rare and this saves a lot of complexity in\n    #   soft-reactivation.\n    #\n    # * If the user is going to be notified (e.g. they get push/email\n    #   notifications for every message on a stream), since in that\n    #   case the notifications code will call `access_message` on the\n    #   message to re-verify permissions, and for private streams,\n    #   will get an error if the UserMessage row doesn't exist yet.\n    #\n    # See https://zulip.readthedocs.io/en/latest/subsystems/sending-messages.html#soft-deactivation\n    # for details on this system.\n    user_messages = []\n    for user_profile_id in um_eligible_user_ids:\n        flags = base_flags\n        if (\n            (user_profile_id == sender_id and message.sent_by_human())\n            or user_profile_id in mark_as_read_user_ids\n            or (limit_unread_user_ids is not None and user_profile_id not in limit_unread_user_ids)\n        ):\n            flags |= UserMessage.flags.read\n        if user_profile_id in mentioned_user_ids:\n            flags |= UserMessage.flags.mentioned\n        if user_profile_id in ids_with_alert_words:\n            flags |= UserMessage.flags.has_alert_word\n\n        if (\n            user_profile_id in long_term_idle_user_ids\n            and user_profile_id not in stream_push_user_ids\n            and user_profile_id not in stream_email_user_ids\n            and is_stream_message\n            and int(flags) == 0\n        ):\n            continue\n\n        um = UserMessageLite(\n            user_profile_id=user_profile_id,\n            message_id=message.id,\n            flags=flags,\n        )\n        user_messages.append(um)\n\n    return user_messages\n\n\ndef bulk_insert_ums(ums: List[UserMessageLite]) -> None:\n    \"\"\"\n    Doing bulk inserts this way is much faster than using Django,\n    since we don't have any ORM overhead.  Profiling with 1000\n    users shows a speedup of 0.436 -> 0.027 seconds, so we're\n    talking about a 15x speedup.\n    \"\"\"\n    if not ums:\n        return\n\n    vals = [(um.user_profile_id, um.message_id, um.flags) for um in ums]\n    query = SQL(\n        \"\"\"\n        INSERT into\n            zerver_usermessage (user_profile_id, message_id, flags)\n        VALUES %s\n    \"\"\"\n    )\n\n    with connection.cursor() as cursor:\n        execute_values(cursor.cursor, query, vals)\n\n\ndef verify_submessage_sender(\n    *,\n    message_id: int,\n    message_sender_id: int,\n    submessage_sender_id: int,\n) -> None:\n    \"\"\"Even though our submessage architecture is geared toward\n    collaboration among all message readers, we still enforce\n    the the first person to attach a submessage to the message\n    must be the original sender of the message.\n    \"\"\"\n\n    if message_sender_id == submessage_sender_id:\n        return\n\n    if SubMessage.objects.filter(\n        message_id=message_id,\n        sender_id=message_sender_id,\n    ).exists():\n        return\n\n    raise JsonableError(_(\"You cannot attach a submessage to this message.\"))\n\n\ndef do_add_submessage(\n    realm: Realm,\n    sender_id: int,\n    message_id: int,\n    msg_type: str,\n    content: str,\n) -> None:\n    \"\"\"Should be called while holding a SELECT FOR UPDATE lock\n    (e.g. via access_message(..., lock_message=True)) on the\n    Message row, to prevent race conditions.\n    \"\"\"\n    submessage = SubMessage(\n        sender_id=sender_id,\n        message_id=message_id,\n        msg_type=msg_type,\n        content=content,\n    )\n    submessage.save()\n\n    event = dict(\n        type=\"submessage\",\n        msg_type=msg_type,\n        message_id=message_id,\n        submessage_id=submessage.id,\n        sender_id=sender_id,\n        content=content,\n    )\n    ums = UserMessage.objects.filter(message_id=message_id)\n    target_user_ids = [um.user_profile_id for um in ums]\n\n    transaction.on_commit(lambda: send_event(realm, event, target_user_ids))\n\n\ndef notify_reaction_update(\n    user_profile: UserProfile, message: Message, reaction: Reaction, op: str\n) -> None:\n    user_dict = {\n        \"user_id\": user_profile.id,\n        \"email\": user_profile.email,\n        \"full_name\": user_profile.full_name,\n    }\n\n    event: Dict[str, Any] = {\n        \"type\": \"reaction\",\n        \"op\": op,\n        \"user_id\": user_profile.id,\n        # TODO: We plan to remove this redundant user_dict object once\n        # clients are updated to support accessing use user_id.  See\n        # https://github.com/zulip/zulip/pull/14711 for details.\n        \"user\": user_dict,\n        \"message_id\": message.id,\n        \"emoji_name\": reaction.emoji_name,\n        \"emoji_code\": reaction.emoji_code,\n        \"reaction_type\": reaction.reaction_type,\n    }\n\n    # Update the cached message since new reaction is added.\n    update_to_dict_cache([message])\n\n    # Recipients for message update events, including reactions, are\n    # everyone who got the original message, plus subscribers of\n    # streams with the access to stream's full history.\n    #\n    # This means reactions won't live-update in preview narrows for a\n    # stream the user isn't yet subscribed to; this is the right\n    # performance tradeoff to avoid sending every reaction to public\n    # stream messages to all users.\n    #\n    # To ensure that reactions do live-update for any user who has\n    # actually participated in reacting to a message, we add a\n    # \"historical\" UserMessage row for any user who reacts to message,\n    # subscribing them to future notifications, even if they are not\n    # subscribed to the stream.\n    user_ids = set(\n        UserMessage.objects.filter(message=message.id).values_list(\"user_profile_id\", flat=True)\n    )\n    if message.recipient.type == Recipient.STREAM:\n        stream_id = message.recipient.type_id\n        stream = Stream.objects.get(id=stream_id)\n        user_ids |= subscriber_ids_with_stream_history_access(stream)\n\n    transaction.on_commit(lambda: send_event(user_profile.realm, event, list(user_ids)))\n\n\ndef do_add_reaction(\n    user_profile: UserProfile,\n    message: Message,\n    emoji_name: str,\n    emoji_code: str,\n    reaction_type: str,\n) -> None:\n    \"\"\"Should be called while holding a SELECT FOR UPDATE lock\n    (e.g. via access_message(..., lock_message=True)) on the\n    Message row, to prevent race conditions.\n    \"\"\"\n\n    reaction = Reaction(\n        user_profile=user_profile,\n        message=message,\n        emoji_name=emoji_name,\n        emoji_code=emoji_code,\n        reaction_type=reaction_type,\n    )\n\n    reaction.save()\n\n    notify_reaction_update(user_profile, message, reaction, \"add\")\n\n\ndef check_add_reaction(\n    user_profile: UserProfile,\n    message_id: int,\n    emoji_name: str,\n    emoji_code: Optional[str],\n    reaction_type: Optional[str],\n) -> None:\n    message, user_message = access_message(user_profile, message_id, lock_message=True)\n\n    if emoji_code is None:\n        # The emoji_code argument is only required for rare corner\n        # cases discussed in the long block comment below.  For simple\n        # API clients, we allow specifying just the name, and just\n        # look up the code using the current name->code mapping.\n        emoji_code = emoji_name_to_emoji_code(message.sender.realm, emoji_name)[0]\n\n    if reaction_type is None:\n        reaction_type = emoji_name_to_emoji_code(message.sender.realm, emoji_name)[1]\n\n    if Reaction.objects.filter(\n        user_profile=user_profile,\n        message=message,\n        emoji_code=emoji_code,\n        reaction_type=reaction_type,\n    ).exists():\n        raise JsonableError(_(\"Reaction already exists.\"))\n\n    query = Reaction.objects.filter(\n        message=message, emoji_code=emoji_code, reaction_type=reaction_type\n    )\n    if query.exists():\n        # If another user has already reacted to this message with\n        # same emoji code, we treat the new reaction as a vote for the\n        # existing reaction.  So the emoji name used by that earlier\n        # reaction takes precedence over whatever was passed in this\n        # request.  This is necessary to avoid a message having 2\n        # \"different\" emoji reactions with the same emoji code (and\n        # thus same image) on the same message, which looks ugly.\n        #\n        # In this \"voting for an existing reaction\" case, we shouldn't\n        # check whether the emoji code and emoji name match, since\n        # it's possible that the (emoji_type, emoji_name, emoji_code)\n        # triple for this existing reaction may not pass validation\n        # now (e.g. because it is for a realm emoji that has been\n        # since deactivated).  We still want to allow users to add a\n        # vote any old reaction they see in the UI even if that is a\n        # deactivated custom emoji, so we just use the emoji name from\n        # the existing reaction with no further validation.\n        reaction = query.first()\n        assert reaction is not None\n        emoji_name = reaction.emoji_name\n    else:\n        # Otherwise, use the name provided in this request, but verify\n        # it is valid in the user's realm (e.g. not a deactivated\n        # realm emoji).\n        check_emoji_request(user_profile.realm, emoji_name, emoji_code, reaction_type)\n\n    if user_message is None:\n        # See called function for more context.\n        create_historical_user_messages(user_id=user_profile.id, message_ids=[message.id])\n\n    do_add_reaction(user_profile, message, emoji_name, emoji_code, reaction_type)\n\n\ndef do_remove_reaction(\n    user_profile: UserProfile, message: Message, emoji_code: str, reaction_type: str\n) -> None:\n    \"\"\"Should be called while holding a SELECT FOR UPDATE lock\n    (e.g. via access_message(..., lock_message=True)) on the\n    Message row, to prevent race conditions.\n    \"\"\"\n    reaction = Reaction.objects.filter(\n        user_profile=user_profile,\n        message=message,\n        emoji_code=emoji_code,\n        reaction_type=reaction_type,\n    ).get()\n    reaction.delete()\n\n    notify_reaction_update(user_profile, message, reaction, \"remove\")\n\n\ndef do_send_typing_notification(\n    realm: Realm, sender: UserProfile, recipient_user_profiles: List[UserProfile], operator: str\n) -> None:\n\n    sender_dict = {\"user_id\": sender.id, \"email\": sender.email}\n\n    # Include a list of recipients in the event body to help identify where the typing is happening\n    recipient_dicts = [\n        {\"user_id\": profile.id, \"email\": profile.email} for profile in recipient_user_profiles\n    ]\n    event = dict(\n        type=\"typing\",\n        message_type=\"private\",\n        op=operator,\n        sender=sender_dict,\n        recipients=recipient_dicts,\n    )\n\n    # Only deliver the notification to active user recipients\n    user_ids_to_notify = [user.id for user in recipient_user_profiles if user.is_active]\n\n    send_event(realm, event, user_ids_to_notify)\n\n\n# check_send_typing_notification:\n# Checks the typing notification and sends it\ndef check_send_typing_notification(sender: UserProfile, user_ids: List[int], operator: str) -> None:\n    realm = sender.realm\n\n    if sender.id not in user_ids:\n        user_ids.append(sender.id)\n\n    # If any of the user_ids being sent in are invalid, we will\n    # just reject the whole request, since a partial list of user_ids\n    # can create confusion related to huddles.  Plus it's a good\n    # sign that a client is confused (or possibly even malicious) if\n    # we get bad user_ids.\n    user_profiles = []\n    for user_id in user_ids:\n        try:\n            # We include cross-bot realms as possible recipients,\n            # so that clients can know which huddle conversation\n            # is relevant here.\n            user_profile = get_user_by_id_in_realm_including_cross_realm(user_id, sender.realm)\n        except UserProfile.DoesNotExist:\n            raise JsonableError(_(\"Invalid user ID {}\").format(user_id))\n        user_profiles.append(user_profile)\n\n    do_send_typing_notification(\n        realm=realm,\n        sender=sender,\n        recipient_user_profiles=user_profiles,\n        operator=operator,\n    )\n\n\ndef do_send_stream_typing_notification(\n    sender: UserProfile, operator: str, stream: Stream, topic: str\n) -> None:\n\n    sender_dict = {\"user_id\": sender.id, \"email\": sender.email}\n\n    event = dict(\n        type=\"typing\",\n        message_type=\"stream\",\n        op=operator,\n        sender=sender_dict,\n        stream_id=stream.id,\n        topic=topic,\n    )\n\n    user_ids_to_notify = get_user_ids_for_streams({stream.id})[stream.id]\n\n    send_event(sender.realm, event, user_ids_to_notify)\n\n\ndef ensure_stream(\n    realm: Realm,\n    stream_name: str,\n    invite_only: bool = False,\n    stream_description: str = \"\",\n    *,\n    acting_user: Optional[UserProfile],\n) -> Stream:\n    return create_stream_if_needed(\n        realm,\n        stream_name,\n        invite_only=invite_only,\n        stream_description=stream_description,\n        acting_user=acting_user,\n    )[0]\n\n\ndef get_recipient_from_user_profiles(\n    recipient_profiles: Sequence[UserProfile],\n    forwarded_mirror_message: bool,\n    forwarder_user_profile: Optional[UserProfile],\n    sender: UserProfile,\n) -> Recipient:\n\n    # Avoid mutating the passed in list of recipient_profiles.\n    recipient_profiles_map = {user_profile.id: user_profile for user_profile in recipient_profiles}\n\n    if forwarded_mirror_message:\n        # In our mirroring integrations with some third-party\n        # protocols, bots subscribed to the third-party protocol\n        # forward to Zulip messages that they received in the\n        # third-party service.  The permissions model for that\n        # forwarding is that users can only submit to Zulip private\n        # messages they personally received, and here we do the check\n        # for whether forwarder_user_profile is among the private\n        # message recipients of the message.\n        assert forwarder_user_profile is not None\n        if forwarder_user_profile.id not in recipient_profiles_map:\n            raise ValidationError(_(\"User not authorized for this query\"))\n\n    # If the private message is just between the sender and\n    # another person, force it to be a personal internally\n    if len(recipient_profiles_map) == 2 and sender.id in recipient_profiles_map:\n        del recipient_profiles_map[sender.id]\n\n    assert recipient_profiles_map\n    if len(recipient_profiles_map) == 1:\n        [user_profile] = recipient_profiles_map.values()\n        return Recipient(\n            id=user_profile.recipient_id,\n            type=Recipient.PERSONAL,\n            type_id=user_profile.id,\n        )\n\n    # Otherwise, we need a huddle.  Make sure the sender is included in huddle messages\n    recipient_profiles_map[sender.id] = sender\n\n    user_ids = set(recipient_profiles_map)\n    return get_huddle_recipient(user_ids)\n\n\ndef validate_recipient_user_profiles(\n    user_profiles: Sequence[UserProfile], sender: UserProfile, allow_deactivated: bool = False\n) -> Sequence[UserProfile]:\n    recipient_profiles_map: Dict[int, UserProfile] = {}\n\n    # We exempt cross-realm bots from the check that all the recipients\n    # are in the same realm.\n    realms = set()\n    if not is_cross_realm_bot_email(sender.email):\n        realms.add(sender.realm_id)\n\n    for user_profile in user_profiles:\n        if (\n            not user_profile.is_active\n            and not user_profile.is_mirror_dummy\n            and not allow_deactivated\n        ) or user_profile.realm.deactivated:\n            raise ValidationError(\n                _(\"'{email}' is no longer using Zulip.\").format(email=user_profile.email)\n            )\n        recipient_profiles_map[user_profile.id] = user_profile\n        if not is_cross_realm_bot_email(user_profile.email):\n            realms.add(user_profile.realm_id)\n\n    if len(realms) > 1:\n        raise ValidationError(_(\"You can't send private messages outside of your organization.\"))\n\n    return list(recipient_profiles_map.values())\n\n\ndef recipient_for_user_profiles(\n    user_profiles: Sequence[UserProfile],\n    forwarded_mirror_message: bool,\n    forwarder_user_profile: Optional[UserProfile],\n    sender: UserProfile,\n    allow_deactivated: bool = False,\n) -> Recipient:\n\n    recipient_profiles = validate_recipient_user_profiles(\n        user_profiles, sender, allow_deactivated=allow_deactivated\n    )\n\n    return get_recipient_from_user_profiles(\n        recipient_profiles, forwarded_mirror_message, forwarder_user_profile, sender\n    )\n\n\ndef already_sent_mirrored_message_id(message: Message) -> Optional[int]:\n    if message.recipient.type == Recipient.HUDDLE:\n        # For huddle messages, we use a 10-second window because the\n        # timestamps aren't guaranteed to actually match between two\n        # copies of the same message.\n        time_window = datetime.timedelta(seconds=10)\n    else:\n        time_window = datetime.timedelta(seconds=0)\n\n    query = Message.objects.filter(\n        sender=message.sender,\n        recipient=message.recipient,\n        content=message.content,\n        sending_client=message.sending_client,\n        date_sent__gte=message.date_sent - time_window,\n        date_sent__lte=message.date_sent + time_window,\n    )\n\n    messages = filter_by_exact_message_topic(\n        query=query,\n        message=message,\n    )\n\n    if messages.exists():\n        return messages[0].id\n    return None\n\n\ndef extract_stream_indicator(s: str) -> Union[str, int]:\n    # Users can pass stream name as either an id or a name,\n    # and if they choose to pass a name, they may JSON encode\n    # it for legacy reasons.\n\n    try:\n        data = orjson.loads(s)\n    except orjson.JSONDecodeError:\n        # If there was no JSON encoding, then we just\n        # have a raw stream name.\n        return s\n\n    # We should stop supporting this odd use case\n    # once we improve our documentation.\n    if isinstance(data, list):\n        if len(data) != 1:  # nocoverage\n            raise JsonableError(_(\"Expected exactly one stream\"))\n        data = data[0]\n\n    if isinstance(data, str):\n        # We had a JSON-encoded stream name.\n        return data\n\n    if isinstance(data, int):\n        # We had a stream id.\n        return data\n\n    raise JsonableError(_(\"Invalid data type for stream\"))\n\n\ndef extract_private_recipients(s: str) -> Union[List[str], List[int]]:\n    # We try to accept multiple incoming formats for recipients.\n    # See test_extract_recipients() for examples of what we allow.\n\n    try:\n        data = orjson.loads(s)\n    except orjson.JSONDecodeError:\n        data = s\n\n    if isinstance(data, str):\n        data = data.split(\",\")\n\n    if not isinstance(data, list):\n        raise JsonableError(_(\"Invalid data type for recipients\"))\n\n    if not data:\n        # We don't complain about empty message recipients here\n        return data\n\n    if isinstance(data[0], str):\n        return get_validated_emails(data)\n\n    if not isinstance(data[0], int):\n        raise JsonableError(_(\"Invalid data type for recipients\"))\n\n    return get_validated_user_ids(data)\n\n\ndef get_validated_user_ids(user_ids: Collection[int]) -> List[int]:\n    for user_id in user_ids:\n        if not isinstance(user_id, int):\n            raise JsonableError(_(\"Recipient lists may contain emails or user IDs, but not both.\"))\n\n    return list(set(user_ids))\n\n\ndef get_validated_emails(emails: Collection[str]) -> List[str]:\n    for email in emails:\n        if not isinstance(email, str):\n            raise JsonableError(_(\"Recipient lists may contain emails or user IDs, but not both.\"))\n\n    return list(filter(bool, {email.strip() for email in emails}))\n\n\ndef check_send_stream_message(\n    sender: UserProfile,\n    client: Client,\n    stream_name: str,\n    topic: str,\n    body: str,\n    realm: Optional[Realm] = None,\n) -> int:\n    addressee = Addressee.for_stream_name(stream_name, topic)\n    message = check_message(sender, client, addressee, body, realm)\n\n    return do_send_messages([message])[0]\n\n\ndef check_send_stream_message_by_id(\n    sender: UserProfile,\n    client: Client,\n    stream_id: int,\n    topic: str,\n    body: str,\n    realm: Optional[Realm] = None,\n) -> int:\n    addressee = Addressee.for_stream_id(stream_id, topic)\n    message = check_message(sender, client, addressee, body, realm)\n\n    return do_send_messages([message])[0]\n\n\ndef check_send_private_message(\n    sender: UserProfile, client: Client, receiving_user: UserProfile, body: str\n) -> int:\n    addressee = Addressee.for_user_profile(receiving_user)\n    message = check_message(sender, client, addressee, body)\n\n    return do_send_messages([message])[0]\n\n\n# check_send_message:\n# Returns the id of the sent message.  Has same argspec as check_message.\ndef check_send_message(\n    sender: UserProfile,\n    client: Client,\n    message_type_name: str,\n    message_to: Union[Sequence[int], Sequence[str]],\n    topic_name: Optional[str],\n    message_content: str,\n    realm: Optional[Realm] = None,\n    forged: bool = False,\n    forged_timestamp: Optional[float] = None,\n    forwarder_user_profile: Optional[UserProfile] = None,\n    local_id: Optional[str] = None,\n    sender_queue_id: Optional[str] = None,\n    widget_content: Optional[str] = None,\n    *,\n    skip_stream_access_check: bool = False,\n) -> int:\n\n    addressee = Addressee.legacy_build(sender, message_type_name, message_to, topic_name)\n    try:\n        message = check_message(\n            sender,\n            client,\n            addressee,\n            message_content,\n            realm,\n            forged,\n            forged_timestamp,\n            forwarder_user_profile,\n            local_id,\n            sender_queue_id,\n            widget_content,\n            skip_stream_access_check=skip_stream_access_check,\n        )\n    except ZephyrMessageAlreadySentException as e:\n        return e.message_id\n    return do_send_messages([message])[0]\n\n\ndef check_schedule_message(\n    sender: UserProfile,\n    client: Client,\n    message_type_name: str,\n    message_to: Union[Sequence[str], Sequence[int]],\n    topic_name: Optional[str],\n    message_content: str,\n    delivery_type: str,\n    deliver_at: datetime.datetime,\n    realm: Optional[Realm] = None,\n    forwarder_user_profile: Optional[UserProfile] = None,\n) -> int:\n    addressee = Addressee.legacy_build(sender, message_type_name, message_to, topic_name)\n\n    send_request = check_message(\n        sender,\n        client,\n        addressee,\n        message_content,\n        realm=realm,\n        forwarder_user_profile=forwarder_user_profile,\n    )\n    send_request.deliver_at = deliver_at\n    send_request.delivery_type = delivery_type\n\n    recipient = send_request.message.recipient\n    if delivery_type == \"remind\" and (\n        recipient.type != Recipient.STREAM and recipient.type_id != sender.id\n    ):\n        raise JsonableError(_(\"Reminders can only be set for streams.\"))\n\n    return do_schedule_messages([send_request])[0]\n\n\ndef validate_message_edit_payload(\n    message: Message,\n    stream_id: Optional[int],\n    topic_name: Optional[str],\n    propagate_mode: Optional[str],\n    content: Optional[str],\n) -> None:\n    \"\"\"\n    Checks that the data sent is well-formed. Does not handle editability, permissions etc.\n    \"\"\"\n    if topic_name is None and content is None and stream_id is None:\n        raise JsonableError(_(\"Nothing to change\"))\n\n    if not message.is_stream_message():\n        if stream_id is not None:\n            raise JsonableError(_(\"Private messages cannot be moved to streams.\"))\n        if topic_name is not None:\n            raise JsonableError(_(\"Private messages cannot have topics.\"))\n\n    if propagate_mode != \"change_one\" and topic_name is None and stream_id is None:\n        raise JsonableError(_(\"Invalid propagate_mode without topic edit\"))\n\n    if topic_name is not None:\n        check_stream_topic(topic_name)\n\n    if stream_id is not None and content is not None:\n        raise JsonableError(_(\"Cannot change message content while changing stream\"))\n\n    # Right now, we prevent users from editing widgets.\n    if content is not None and is_widget_message(message):\n        raise JsonableError(_(\"Widgets cannot be edited.\"))\n\n\ndef can_edit_content_or_topic(\n    message: Message,\n    user_profile: UserProfile,\n    is_no_topic_msg: bool,\n    content: Optional[str] = None,\n    topic_name: Optional[str] = None,\n) -> bool:\n    # You have permission to edit the message (both content and topic) if you sent it.\n    if message.sender_id == user_profile.id:\n        return True\n\n    # You cannot edit the content of message sent by someone else.\n    if content is not None:\n        return False\n\n    assert topic_name is not None\n\n    # The following cases are the various reasons a user might be\n    # allowed to edit topics.\n\n    # We allow anyone to edit (no topic) messages to help tend them.\n    if is_no_topic_msg:\n        return True\n\n    # The can_edit_topic_of_any_message helper returns whether the user can edit the topic\n    # or not based on edit_topic_policy setting and the user's role.\n    if user_profile.can_edit_topic_of_any_message():\n        return True\n\n    return False\n\n\ndef check_update_message(\n    user_profile: UserProfile,\n    message_id: int,\n    stream_id: Optional[int] = None,\n    topic_name: Optional[str] = None,\n    propagate_mode: str = \"change_one\",\n    send_notification_to_old_thread: bool = True,\n    send_notification_to_new_thread: bool = True,\n    content: Optional[str] = None,\n) -> int:\n    \"\"\"This will update a message given the message id and user profile.\n    It checks whether the user profile has the permission to edit the message\n    and raises a JsonableError if otherwise.\n    It returns the number changed.\n    \"\"\"\n    message, ignored_user_message = access_message(user_profile, message_id)\n\n    if not user_profile.realm.allow_message_editing:\n        raise JsonableError(_(\"Your organization has turned off message editing\"))\n\n    # The zerver/views/message_edit.py call point already strips this\n    # via REQ_topic; so we can delete this line if we arrange a\n    # contract where future callers in the embedded bots system strip\n    # use REQ_topic as well (or otherwise are guaranteed to strip input).\n    if topic_name is not None:\n        topic_name = topic_name.strip()\n        if topic_name == message.topic_name():\n            topic_name = None\n\n    validate_message_edit_payload(message, stream_id, topic_name, propagate_mode, content)\n\n    is_no_topic_msg = message.topic_name() == \"(no topic)\"\n\n    if content is not None or topic_name is not None:\n        if not can_edit_content_or_topic(\n            message, user_profile, is_no_topic_msg, content, topic_name\n        ):\n            raise JsonableError(_(\"You don't have permission to edit this message\"))\n\n    # If there is a change to the content, check that it hasn't been too long\n    # Allow an extra 20 seconds since we potentially allow editing 15 seconds\n    # past the limit, and in case there are network issues, etc. The 15 comes\n    # from (min_seconds_to_edit + seconds_left_buffer) in message_edit.js; if\n    # you change this value also change those two parameters in message_edit.js.\n    edit_limit_buffer = 20\n    if content is not None and user_profile.realm.message_content_edit_limit_seconds > 0:\n        deadline_seconds = user_profile.realm.message_content_edit_limit_seconds + edit_limit_buffer\n        if (timezone_now() - message.date_sent) > datetime.timedelta(seconds=deadline_seconds):\n            raise JsonableError(_(\"The time limit for editing this message has passed\"))\n\n    # If there is a change to the topic, check that the user is allowed to\n    # edit it and that it has not been too long. If this is not the user who\n    # sent the message, they are not the admin, and the time limit for editing\n    # topics is passed, raise an error.\n    if (\n        topic_name is not None\n        and message.sender != user_profile\n        and not user_profile.is_realm_admin\n        and not user_profile.is_moderator\n        and not is_no_topic_msg\n    ):\n        deadline_seconds = Realm.DEFAULT_COMMUNITY_TOPIC_EDITING_LIMIT_SECONDS + edit_limit_buffer\n        if (timezone_now() - message.date_sent) > datetime.timedelta(seconds=deadline_seconds):\n            raise JsonableError(_(\"The time limit for editing this message's topic has passed\"))\n\n    rendering_result = None\n    links_for_embed: Set[str] = set()\n    prior_mention_user_ids: Set[int] = set()\n    mention_data: Optional[MentionData] = None\n    if content is not None:\n        if content.rstrip() == \"\":\n            content = \"(deleted)\"\n        content = normalize_body(content)\n\n        mention_backend = MentionBackend(user_profile.realm_id)\n        mention_data = MentionData(\n            mention_backend=mention_backend,\n            content=content,\n        )\n        user_info = get_user_info_for_message_updates(message.id)\n        prior_mention_user_ids = user_info[\"mention_user_ids\"]\n\n        # We render the message using the current user's realm; since\n        # the cross-realm bots never edit messages, this should be\n        # always correct.\n        # Note: If rendering fails, the called code will raise a JsonableError.\n        rendering_result = render_incoming_message(\n            message,\n            content,\n            user_info[\"message_user_ids\"],\n            user_profile.realm,\n            mention_data=mention_data,\n        )\n        links_for_embed |= rendering_result.links_for_preview\n\n        if message.is_stream_message() and rendering_result.mentions_wildcard:\n            stream = access_stream_by_id(user_profile, message.recipient.type_id)[0]\n            if not wildcard_mention_allowed(message.sender, stream):\n                raise JsonableError(\n                    _(\"You do not have permission to use wildcard mentions in this stream.\")\n                )\n\n    new_stream = None\n    number_changed = 0\n\n    if stream_id is not None:\n        assert message.is_stream_message()\n        if not user_profile.can_move_messages_between_streams():\n            raise JsonableError(_(\"You don't have permission to move this message\"))\n        try:\n            access_stream_by_id(user_profile, message.recipient.type_id)\n        except JsonableError:\n            raise JsonableError(\n                _(\n                    \"You don't have permission to move this message due to missing access to its stream\"\n                )\n            )\n\n        new_stream = access_stream_by_id(user_profile, stream_id, require_active=True)[0]\n        check_stream_access_based_on_stream_post_policy(user_profile, new_stream)\n\n    number_changed = do_update_message(\n        user_profile,\n        message,\n        new_stream,\n        topic_name,\n        propagate_mode,\n        send_notification_to_old_thread,\n        send_notification_to_new_thread,\n        content,\n        rendering_result,\n        prior_mention_user_ids,\n        mention_data,\n    )\n\n    if links_for_embed:\n        event_data = {\n            \"message_id\": message.id,\n            \"message_content\": message.content,\n            # The choice of `user_profile.realm_id` rather than\n            # `sender.realm_id` must match the decision made in the\n            # `render_incoming_message` call earlier in this function.\n            \"message_realm_id\": user_profile.realm_id,\n            \"urls\": list(links_for_embed),\n        }\n        queue_json_publish(\"embed_links\", event_data)\n\n    return number_changed\n\n\ndef check_default_stream_group_name(group_name: str) -> None:\n    if group_name.strip() == \"\":\n        raise JsonableError(_(\"Invalid default stream group name '{}'\").format(group_name))\n    if len(group_name) > DefaultStreamGroup.MAX_NAME_LENGTH:\n        raise JsonableError(\n            _(\"Default stream group name too long (limit: {} characters)\").format(\n                DefaultStreamGroup.MAX_NAME_LENGTH,\n            )\n        )\n    for i in group_name:\n        if ord(i) == 0:\n            raise JsonableError(\n                _(\"Default stream group name '{}' contains NULL (0x00) characters.\").format(\n                    group_name,\n                )\n            )\n\n\ndef send_rate_limited_pm_notification_to_bot_owner(\n    sender: UserProfile, realm: Realm, content: str\n) -> None:\n    \"\"\"\n    Sends a PM error notification to a bot's owner if one hasn't already\n    been sent in the last 5 minutes.\n    \"\"\"\n    if sender.realm.is_zephyr_mirror_realm or sender.realm.deactivated:\n        return\n\n    if not sender.is_bot or sender.bot_owner is None:\n        return\n\n    # Don't send these notifications for cross-realm bot messages\n    # (e.g. from EMAIL_GATEWAY_BOT) since the owner for\n    # EMAIL_GATEWAY_BOT is probably the server administrator, not\n    # the owner of the bot who could potentially fix the problem.\n    if sender.realm != realm:\n        return\n\n    # We warn the user once every 5 minutes to avoid a flood of\n    # PMs on a misconfigured integration, re-using the\n    # UserProfile.last_reminder field, which is not used for bots.\n    last_reminder = sender.last_reminder\n    waitperiod = datetime.timedelta(minutes=UserProfile.BOT_OWNER_STREAM_ALERT_WAITPERIOD)\n    if last_reminder and timezone_now() - last_reminder <= waitperiod:\n        return\n\n    internal_send_private_message(\n        get_system_bot(settings.NOTIFICATION_BOT, sender.bot_owner.realm_id),\n        sender.bot_owner,\n        content,\n    )\n\n    sender.last_reminder = timezone_now()\n    sender.save(update_fields=[\"last_reminder\"])\n\n\ndef send_pm_if_empty_stream(\n    stream: Optional[Stream],\n    realm: Realm,\n    sender: UserProfile,\n    stream_name: Optional[str] = None,\n    stream_id: Optional[int] = None,\n) -> None:\n    \"\"\"If a bot sends a message to a stream that doesn't exist or has no\n    subscribers, sends a notification to the bot owner (if not a\n    cross-realm bot) so that the owner can correct the issue.\"\"\"\n    if not sender.is_bot or sender.bot_owner is None:\n        return\n\n    arg_dict = {\n        \"bot_identity\": f\"`{sender.delivery_email}`\",\n        \"stream_id\": stream_id,\n        \"stream_name\": f\"#**{stream_name}**\",\n        \"new_stream_link\": \"#streams/new\",\n    }\n    if sender.bot_owner is not None:\n        with override_language(sender.bot_owner.default_language):\n            if stream is None:\n                if stream_id is not None:\n                    content = _(\n                        \"Your bot {bot_identity} tried to send a message to stream ID \"\n                        \"{stream_id}, but there is no stream with that ID.\"\n                    ).format(**arg_dict)\n                else:\n                    assert stream_name is not None\n                    content = _(\n                        \"Your bot {bot_identity} tried to send a message to stream \"\n                        \"{stream_name}, but that stream does not exist. \"\n                        \"Click [here]({new_stream_link}) to create it.\"\n                    ).format(**arg_dict)\n            else:\n                if num_subscribers_for_stream_id(stream.id) > 0:\n                    return\n                content = _(\n                    \"Your bot {bot_identity} tried to send a message to \"\n                    \"stream {stream_name}. The stream exists but \"\n                    \"does not have any subscribers.\"\n                ).format(**arg_dict)\n\n        send_rate_limited_pm_notification_to_bot_owner(sender, realm, content)\n\n\ndef validate_stream_name_with_pm_notification(\n    stream_name: str, realm: Realm, sender: UserProfile\n) -> Stream:\n    stream_name = stream_name.strip()\n    check_stream_name(stream_name)\n\n    try:\n        stream = get_stream(stream_name, realm)\n        send_pm_if_empty_stream(stream, realm, sender)\n    except Stream.DoesNotExist:\n        send_pm_if_empty_stream(None, realm, sender, stream_name=stream_name)\n        raise StreamDoesNotExistError(escape(stream_name))\n\n    return stream\n\n\ndef validate_stream_id_with_pm_notification(\n    stream_id: int, realm: Realm, sender: UserProfile\n) -> Stream:\n    try:\n        stream = get_stream_by_id_in_realm(stream_id, realm)\n        send_pm_if_empty_stream(stream, realm, sender)\n    except Stream.DoesNotExist:\n        send_pm_if_empty_stream(None, realm, sender, stream_id=stream_id)\n        raise StreamWithIDDoesNotExistError(stream_id)\n\n    return stream\n\n\ndef check_private_message_policy(\n    realm: Realm, sender: UserProfile, user_profiles: Sequence[UserProfile]\n) -> None:\n    if realm.private_message_policy == Realm.PRIVATE_MESSAGE_POLICY_DISABLED:\n        if sender.is_bot or (len(user_profiles) == 1 and user_profiles[0].is_bot):\n            # We allow PMs only between users and bots, to avoid\n            # breaking the tutorial as well as automated\n            # notifications from system bots to users.\n            return\n\n        raise JsonableError(_(\"Private messages are disabled in this organization.\"))\n\n\n# check_message:\n# Returns message ready for sending with do_send_message on success or the error message (string) on error.\ndef check_message(\n    sender: UserProfile,\n    client: Client,\n    addressee: Addressee,\n    message_content_raw: str,\n    realm: Optional[Realm] = None,\n    forged: bool = False,\n    forged_timestamp: Optional[float] = None,\n    forwarder_user_profile: Optional[UserProfile] = None,\n    local_id: Optional[str] = None,\n    sender_queue_id: Optional[str] = None,\n    widget_content: Optional[str] = None,\n    email_gateway: bool = False,\n    *,\n    skip_stream_access_check: bool = False,\n    mention_backend: Optional[MentionBackend] = None,\n    limit_unread_user_ids: Optional[Set[int]] = None,\n) -> SendMessageRequest:\n    \"\"\"See\n    https://zulip.readthedocs.io/en/latest/subsystems/sending-messages.html\n    for high-level documentation on this subsystem.\n    \"\"\"\n    stream = None\n\n    message_content = normalize_body(message_content_raw)\n\n    if realm is None:\n        realm = sender.realm\n\n    if addressee.is_stream():\n        topic_name = addressee.topic()\n        topic_name = truncate_topic(topic_name)\n\n        stream_name = addressee.stream_name()\n        stream_id = addressee.stream_id()\n\n        if stream_name is not None:\n            stream = validate_stream_name_with_pm_notification(stream_name, realm, sender)\n        elif stream_id is not None:\n            stream = validate_stream_id_with_pm_notification(stream_id, realm, sender)\n        else:\n            stream = addressee.stream()\n        assert stream is not None\n\n        # To save a database round trip, we construct the Recipient\n        # object for the Stream rather than fetching it from the\n        # database using the stream.recipient foreign key.\n        #\n        # This is simpler than ensuring that code paths that fetch a\n        # Stream that will be used for sending a message have a\n        # `select_related(\"recipient\"), which would also needlessly\n        # expand Stream objects in memory (all the fields of Recipient\n        # are already known given the Stream object).\n        recipient = Recipient(\n            id=stream.recipient_id,\n            type_id=stream.id,\n            type=Recipient.STREAM,\n        )\n\n        if not skip_stream_access_check:\n            access_stream_for_send_message(\n                sender=sender, stream=stream, forwarder_user_profile=forwarder_user_profile\n            )\n        else:\n            # Defensive assertion - the only currently supported use case\n            # for this option is for outgoing webhook bots and since this\n            # is security-sensitive code, it's beneficial to ensure nothing\n            # else can sneak past the access check.\n            assert sender.bot_type == sender.OUTGOING_WEBHOOK_BOT\n\n        if realm.mandatory_topics and topic_name == \"(no topic)\":\n            raise JsonableError(_(\"Topics are required in this organization\"))\n\n    elif addressee.is_private():\n        user_profiles = addressee.user_profiles()\n        mirror_message = client and client.name in [\n            \"zephyr_mirror\",\n            \"irc_mirror\",\n            \"jabber_mirror\",\n            \"JabberMirror\",\n        ]\n\n        check_private_message_policy(realm, sender, user_profiles)\n\n        # API super-users who set the `forged` flag are allowed to\n        # forge messages sent by any user, so we disable the\n        # `forwarded_mirror_message` security check in that case.\n        forwarded_mirror_message = mirror_message and not forged\n        try:\n            recipient = recipient_for_user_profiles(\n                user_profiles, forwarded_mirror_message, forwarder_user_profile, sender\n            )\n        except ValidationError as e:\n            assert isinstance(e.messages[0], str)\n            raise JsonableError(e.messages[0])\n    else:\n        # This is defensive code--Addressee already validates\n        # the message type.\n        raise AssertionError(\"Invalid message type\")\n\n    message = Message()\n    message.sender = sender\n    message.content = message_content\n    message.recipient = recipient\n    if addressee.is_stream():\n        message.set_topic_name(topic_name)\n    if forged and forged_timestamp is not None:\n        # Forged messages come with a timestamp\n        message.date_sent = timestamp_to_datetime(forged_timestamp)\n    else:\n        message.date_sent = timezone_now()\n    message.sending_client = client\n\n    # We render messages later in the process.\n    assert message.rendered_content is None\n\n    if client.name == \"zephyr_mirror\":\n        id = already_sent_mirrored_message_id(message)\n        if id is not None:\n            raise ZephyrMessageAlreadySentException(id)\n\n    widget_content_dict = None\n    if widget_content is not None:\n        try:\n            widget_content_dict = orjson.loads(widget_content)\n        except orjson.JSONDecodeError:\n            raise JsonableError(_(\"Widgets: API programmer sent invalid JSON content\"))\n\n        try:\n            check_widget_content(widget_content_dict)\n        except ValidationError as error:\n            raise JsonableError(\n                _(\"Widgets: {error_msg}\").format(\n                    error_msg=error.message,\n                )\n            )\n\n    message_send_dict = build_message_send_dict(\n        message=message,\n        stream=stream,\n        local_id=local_id,\n        sender_queue_id=sender_queue_id,\n        realm=realm,\n        widget_content_dict=widget_content_dict,\n        email_gateway=email_gateway,\n        mention_backend=mention_backend,\n        limit_unread_user_ids=limit_unread_user_ids,\n    )\n\n    if stream is not None and message_send_dict.rendering_result.mentions_wildcard:\n        if not wildcard_mention_allowed(sender, stream):\n            raise JsonableError(\n                _(\"You do not have permission to use wildcard mentions in this stream.\")\n            )\n    return message_send_dict\n\n\ndef _internal_prep_message(\n    realm: Realm,\n    sender: UserProfile,\n    addressee: Addressee,\n    content: str,\n    email_gateway: bool = False,\n    mention_backend: Optional[MentionBackend] = None,\n    limit_unread_user_ids: Optional[Set[int]] = None,\n) -> Optional[SendMessageRequest]:\n    \"\"\"\n    Create a message object and checks it, but doesn't send it or save it to the database.\n    The internal function that calls this can therefore batch send a bunch of created\n    messages together as one database query.\n    Call do_send_messages with a list of the return values of this method.\n    \"\"\"\n    # Remove any null bytes from the content\n    if len(content) > settings.MAX_MESSAGE_LENGTH:\n        content = content[0:3900] + \"\\n\\n[message was too long and has been truncated]\"\n\n    # If we have a stream name, and the stream doesn't exist, we\n    # create it here (though this code path should probably be removed\n    # eventually, moving that responsibility to the caller).  If\n    # addressee.stream_name() is None (i.e. we're sending to a stream\n    # by ID), we skip this, as the stream object must already exist.\n    if addressee.is_stream():\n        stream_name = addressee.stream_name()\n        if stream_name is not None:\n            ensure_stream(realm, stream_name, acting_user=sender)\n\n    try:\n        return check_message(\n            sender,\n            get_client(\"Internal\"),\n            addressee,\n            content,\n            realm=realm,\n            email_gateway=email_gateway,\n            mention_backend=mention_backend,\n            limit_unread_user_ids=limit_unread_user_ids,\n        )\n    except JsonableError as e:\n        logging.exception(\n            \"Error queueing internal message by %s: %s\",\n            sender.delivery_email,\n            e.msg,\n            stack_info=True,\n        )\n\n    return None\n\n\ndef internal_prep_stream_message(\n    sender: UserProfile,\n    stream: Stream,\n    topic: str,\n    content: str,\n    email_gateway: bool = False,\n    limit_unread_user_ids: Optional[Set[int]] = None,\n) -> Optional[SendMessageRequest]:\n    \"\"\"\n    See _internal_prep_message for details of how this works.\n    \"\"\"\n    realm = stream.realm\n    addressee = Addressee.for_stream(stream, topic)\n\n    return _internal_prep_message(\n        realm=realm,\n        sender=sender,\n        addressee=addressee,\n        content=content,\n        email_gateway=email_gateway,\n        limit_unread_user_ids=limit_unread_user_ids,\n    )\n\n\ndef internal_prep_stream_message_by_name(\n    realm: Realm,\n    sender: UserProfile,\n    stream_name: str,\n    topic: str,\n    content: str,\n) -> Optional[SendMessageRequest]:\n    \"\"\"\n    See _internal_prep_message for details of how this works.\n    \"\"\"\n    addressee = Addressee.for_stream_name(stream_name, topic)\n\n    return _internal_prep_message(\n        realm=realm,\n        sender=sender,\n        addressee=addressee,\n        content=content,\n    )\n\n\ndef internal_prep_private_message(\n    realm: Realm,\n    sender: UserProfile,\n    recipient_user: UserProfile,\n    content: str,\n    mention_backend: Optional[MentionBackend] = None,\n) -> Optional[SendMessageRequest]:\n    \"\"\"\n    See _internal_prep_message for details of how this works.\n    \"\"\"\n    addressee = Addressee.for_user_profile(recipient_user)\n\n    return _internal_prep_message(\n        realm=realm,\n        sender=sender,\n        addressee=addressee,\n        content=content,\n        mention_backend=mention_backend,\n    )\n\n\ndef internal_send_private_message(\n    sender: UserProfile, recipient_user: UserProfile, content: str\n) -> Optional[int]:\n    realm = recipient_user.realm\n    message = internal_prep_private_message(realm, sender, recipient_user, content)\n    if message is None:\n        return None\n    message_ids = do_send_messages([message])\n    return message_ids[0]\n\n\ndef internal_send_stream_message(\n    sender: UserProfile,\n    stream: Stream,\n    topic: str,\n    content: str,\n    email_gateway: bool = False,\n    limit_unread_user_ids: Optional[Set[int]] = None,\n) -> Optional[int]:\n\n    message = internal_prep_stream_message(\n        sender, stream, topic, content, email_gateway, limit_unread_user_ids=limit_unread_user_ids\n    )\n\n    if message is None:\n        return None\n    message_ids = do_send_messages([message])\n    return message_ids[0]\n\n\ndef internal_send_stream_message_by_name(\n    realm: Realm,\n    sender: UserProfile,\n    stream_name: str,\n    topic: str,\n    content: str,\n) -> Optional[int]:\n    message = internal_prep_stream_message_by_name(\n        realm,\n        sender,\n        stream_name,\n        topic,\n        content,\n    )\n\n    if message is None:\n        return None\n    message_ids = do_send_messages([message])\n    return message_ids[0]\n\n\ndef internal_send_huddle_message(\n    realm: Realm, sender: UserProfile, emails: List[str], content: str\n) -> Optional[int]:\n    addressee = Addressee.for_private(emails, realm)\n    message = _internal_prep_message(\n        realm=realm,\n        sender=sender,\n        addressee=addressee,\n        content=content,\n    )\n    if message is None:\n        return None\n    message_ids = do_send_messages([message])\n    return message_ids[0]\n\n\ndef validate_user_access_to_subscribers(\n    user_profile: Optional[UserProfile], stream: Stream\n) -> None:\n    \"\"\"Validates whether the user can view the subscribers of a stream.  Raises a JsonableError if:\n    * The user and the stream are in different realms\n    * The realm is MIT and the stream is not invite only.\n    * The stream is invite only, requesting_user is passed, and that user\n      does not subscribe to the stream.\n    \"\"\"\n    validate_user_access_to_subscribers_helper(\n        user_profile,\n        {\n            \"realm_id\": stream.realm_id,\n            \"is_web_public\": stream.is_web_public,\n            \"invite_only\": stream.invite_only,\n        },\n        # We use a lambda here so that we only compute whether the\n        # user is subscribed if we have to\n        lambda user_profile: subscribed_to_stream(user_profile, stream.id),\n    )\n\n\ndef validate_user_access_to_subscribers_helper(\n    user_profile: Optional[UserProfile],\n    stream_dict: Mapping[str, Any],\n    check_user_subscribed: Callable[[UserProfile], bool],\n) -> None:\n    \"\"\"Helper for validate_user_access_to_subscribers that doesn't require\n    a full stream object.  This function is a bit hard to read,\n    because it is carefully optimized for performance in the two code\n    paths we call it from:\n\n    * In `bulk_get_subscriber_user_ids`, we already know whether the\n    user was subscribed via `sub_dict`, and so we want to avoid a\n    database query at all (especially since it calls this in a loop);\n    * In `validate_user_access_to_subscribers`, we want to only check\n    if the user is subscribed when we absolutely have to, since it\n    costs a database query.\n\n    The `check_user_subscribed` argument is a function that reports\n    whether the user is subscribed to the stream.\n\n    Note also that we raise a ValidationError in cases where the\n    caller is doing the wrong thing (maybe these should be\n    AssertionErrors), and JsonableError for 400 type errors.\n    \"\"\"\n    if user_profile is None:\n        raise ValidationError(\"Missing user to validate access for\")\n\n    if user_profile.realm_id != stream_dict[\"realm_id\"]:\n        raise ValidationError(\"Requesting user not in given realm\")\n\n    # Even guest users can access subscribers to web-public streams,\n    # since they can freely become subscribers to these streams.\n    if stream_dict[\"is_web_public\"]:\n        return\n\n    # With the exception of web-public streams, a guest must\n    # be subscribed to a stream (even a public one) in order\n    # to see subscribers.\n    if user_profile.is_guest:\n        if check_user_subscribed(user_profile):\n            return\n        # We could explicitly handle the case where guests aren't\n        # subscribed here in an `else` statement or we can fall\n        # through to the subsequent logic.  Tim prefers the latter.\n        # Adding an `else` would ensure better code coverage.\n\n    if not user_profile.can_access_public_streams() and not stream_dict[\"invite_only\"]:\n        raise JsonableError(_(\"Subscriber data is not available for this stream\"))\n\n    # Organization administrators can view subscribers for all streams.\n    if user_profile.is_realm_admin:\n        return\n\n    if stream_dict[\"invite_only\"] and not check_user_subscribed(user_profile):\n        raise JsonableError(_(\"Unable to retrieve subscribers for private stream\"))\n\n\ndef bulk_get_subscriber_user_ids(\n    stream_dicts: Collection[Mapping[str, Any]],\n    user_profile: UserProfile,\n    subscribed_stream_ids: Set[int],\n) -> Dict[int, List[int]]:\n    \"\"\"sub_dict maps stream_id => whether the user is subscribed to that stream.\"\"\"\n    target_stream_dicts = []\n    for stream_dict in stream_dicts:\n        stream_id = stream_dict[\"id\"]\n        is_subscribed = stream_id in subscribed_stream_ids\n\n        try:\n            validate_user_access_to_subscribers_helper(\n                user_profile,\n                stream_dict,\n                lambda user_profile: is_subscribed,\n            )\n        except JsonableError:\n            continue\n        target_stream_dicts.append(stream_dict)\n\n    recip_to_stream_id = {stream[\"recipient_id\"]: stream[\"id\"] for stream in target_stream_dicts}\n    recipient_ids = sorted(stream[\"recipient_id\"] for stream in target_stream_dicts)\n\n    result: Dict[int, List[int]] = {stream[\"id\"]: [] for stream in stream_dicts}\n    if not recipient_ids:\n        return result\n\n    \"\"\"\n    The raw SQL below leads to more than a 2x speedup when tested with\n    20k+ total subscribers.  (For large realms with lots of default\n    streams, this function deals with LOTS of data, so it is important\n    to optimize.)\n    \"\"\"\n\n    query = SQL(\n        \"\"\"\n        SELECT\n            zerver_subscription.recipient_id,\n            zerver_subscription.user_profile_id\n        FROM\n            zerver_subscription\n        WHERE\n            zerver_subscription.recipient_id in %(recipient_ids)s AND\n            zerver_subscription.active AND\n            zerver_subscription.is_user_active\n        ORDER BY\n            zerver_subscription.recipient_id,\n            zerver_subscription.user_profile_id\n        \"\"\"\n    )\n\n    cursor = connection.cursor()\n    cursor.execute(query, {\"recipient_ids\": tuple(recipient_ids)})\n    rows = cursor.fetchall()\n    cursor.close()\n\n    \"\"\"\n    Using groupby/itemgetter here is important for performance, at scale.\n    It makes it so that all interpreter overhead is just O(N) in nature.\n    \"\"\"\n    for recip_id, recip_rows in itertools.groupby(rows, itemgetter(0)):\n        user_profile_ids = [r[1] for r in recip_rows]\n        stream_id = recip_to_stream_id[recip_id]\n        result[stream_id] = list(user_profile_ids)\n\n    return result\n\n\ndef get_subscribers_query(stream: Stream, requesting_user: Optional[UserProfile]) -> QuerySet:\n    # TODO: Make a generic stub for QuerySet\n    \"\"\"Build a query to get the subscribers list for a stream, raising a JsonableError if:\n\n    'realm' is optional in stream.\n\n    The caller can refine this query with select_related(), values(), etc. depending\n    on whether it wants objects or just certain fields\n    \"\"\"\n    validate_user_access_to_subscribers(requesting_user, stream)\n\n    return get_active_subscriptions_for_stream_id(stream.id, include_deactivated_users=False)\n\n\ndef get_subscriber_ids(stream: Stream, requesting_user: Optional[UserProfile] = None) -> List[str]:\n    subscriptions_query = get_subscribers_query(stream, requesting_user)\n    return subscriptions_query.values_list(\"user_profile_id\", flat=True)\n\n\n@dataclass\nclass StreamInfo:\n    email_address: str\n    stream_weekly_traffic: Optional[int]\n    subscribers: List[int]\n\n\ndef send_subscription_add_events(\n    realm: Realm,\n    sub_info_list: List[SubInfo],\n    subscriber_dict: Dict[int, Set[int]],\n) -> None:\n    info_by_user: Dict[int, List[SubInfo]] = defaultdict(list)\n    for sub_info in sub_info_list:\n        info_by_user[sub_info.user.id].append(sub_info)\n\n    stream_ids = {sub_info.stream.id for sub_info in sub_info_list}\n    recent_traffic = get_streams_traffic(stream_ids=stream_ids)\n\n    # We generally only have a few streams, so we compute stream\n    # data in its own loop.\n    stream_info_dict: Dict[int, StreamInfo] = {}\n    for sub_info in sub_info_list:\n        stream = sub_info.stream\n        if stream.id not in stream_info_dict:\n            email_address = encode_email_address(stream, show_sender=True)\n            stream_weekly_traffic = get_average_weekly_stream_traffic(\n                stream.id, stream.date_created, recent_traffic\n            )\n            if stream.is_in_zephyr_realm and not stream.invite_only:\n                subscribers = []\n            else:\n                subscribers = list(subscriber_dict[stream.id])\n            stream_info_dict[stream.id] = StreamInfo(\n                email_address=email_address,\n                stream_weekly_traffic=stream_weekly_traffic,\n                subscribers=subscribers,\n            )\n\n    for user_id, sub_infos in info_by_user.items():\n        sub_dicts = []\n        for sub_info in sub_infos:\n            stream = sub_info.stream\n            stream_info = stream_info_dict[stream.id]\n            subscription = sub_info.sub\n            sub_dict = stream.to_dict()\n            for field_name in Subscription.API_FIELDS:\n                sub_dict[field_name] = getattr(subscription, field_name)\n\n            sub_dict[\"in_home_view\"] = not subscription.is_muted\n            sub_dict[\"email_address\"] = stream_info.email_address\n            sub_dict[\"stream_weekly_traffic\"] = stream_info.stream_weekly_traffic\n            sub_dict[\"subscribers\"] = stream_info.subscribers\n            sub_dicts.append(sub_dict)\n\n        # Send a notification to the user who subscribed.\n        event = dict(type=\"subscription\", op=\"add\", subscriptions=sub_dicts)\n        send_event(realm, event, [user_id])\n\n\nSubT = Tuple[List[SubInfo], List[SubInfo]]\n\n\ndef bulk_add_subscriptions(\n    realm: Realm,\n    streams: Collection[Stream],\n    users: Iterable[UserProfile],\n    color_map: Mapping[str, str] = {},\n    from_user_creation: bool = False,\n    *,\n    acting_user: Optional[UserProfile],\n) -> SubT:\n    users = list(users)\n    user_ids = [user.id for user in users]\n\n    # Sanity check out callers\n    for stream in streams:\n        assert stream.realm_id == realm.id\n\n    for user in users:\n        assert user.realm_id == realm.id\n\n    recipient_ids = [stream.recipient_id for stream in streams]\n    recipient_id_to_stream = {stream.recipient_id: stream for stream in streams}\n\n    recipient_color_map = {}\n    for stream in streams:\n        color: Optional[str] = color_map.get(stream.name, None)\n        if color is not None:\n            recipient_color_map[stream.recipient_id] = color\n\n    used_colors_for_user_ids: Dict[int, Set[str]] = get_used_colors_for_user_ids(user_ids)\n\n    existing_subs = Subscription.objects.filter(\n        user_profile_id__in=user_ids,\n        recipient__type=Recipient.STREAM,\n        recipient_id__in=recipient_ids,\n    )\n\n    subs_by_user: Dict[int, List[Subscription]] = defaultdict(list)\n    for sub in existing_subs:\n        subs_by_user[sub.user_profile_id].append(sub)\n\n    already_subscribed: List[SubInfo] = []\n    subs_to_activate: List[SubInfo] = []\n    subs_to_add: List[SubInfo] = []\n    for user_profile in users:\n        my_subs = subs_by_user[user_profile.id]\n\n        # Make a fresh set of all new recipient ids, and then we will\n        # remove any for which our user already has a subscription\n        # (and we'll re-activate any subscriptions as needed).\n        new_recipient_ids: Set[int] = {stream.recipient_id for stream in streams}\n\n        for sub in my_subs:\n            if sub.recipient_id in new_recipient_ids:\n                new_recipient_ids.remove(sub.recipient_id)\n                stream = recipient_id_to_stream[sub.recipient_id]\n                sub_info = SubInfo(user_profile, sub, stream)\n                if sub.active:\n                    already_subscribed.append(sub_info)\n                else:\n                    subs_to_activate.append(sub_info)\n\n        used_colors = used_colors_for_user_ids.get(user_profile.id, set())\n        user_color_map = pick_colors(used_colors, recipient_color_map, list(new_recipient_ids))\n\n        for recipient_id in new_recipient_ids:\n            stream = recipient_id_to_stream[recipient_id]\n            color = user_color_map[recipient_id]\n\n            sub = Subscription(\n                user_profile=user_profile,\n                is_user_active=user_profile.is_active,\n                active=True,\n                color=color,\n                recipient_id=recipient_id,\n            )\n            sub_info = SubInfo(user_profile, sub, stream)\n            subs_to_add.append(sub_info)\n\n    bulk_add_subs_to_db_with_logging(\n        realm=realm,\n        acting_user=acting_user,\n        subs_to_add=subs_to_add,\n        subs_to_activate=subs_to_activate,\n    )\n\n    altered_user_dict: Dict[int, Set[int]] = defaultdict(set)\n    for sub_info in subs_to_add + subs_to_activate:\n        altered_user_dict[sub_info.stream.id].add(sub_info.user.id)\n\n    stream_dict = {stream.id: stream for stream in streams}\n\n    new_streams = [stream_dict[stream_id] for stream_id in altered_user_dict]\n\n    subscriber_peer_info = bulk_get_subscriber_peer_info(\n        realm=realm,\n        streams=new_streams,\n    )\n\n    # We now send several types of events to notify browsers.  The\n    # first batches of notifications are sent only to the user(s)\n    # being subscribed; we can skip these notifications when this is\n    # being called from the new user creation flow.\n    if not from_user_creation:\n        send_stream_creation_events_for_private_streams(\n            realm=realm,\n            stream_dict=stream_dict,\n            altered_user_dict=altered_user_dict,\n        )\n\n        send_subscription_add_events(\n            realm=realm,\n            sub_info_list=subs_to_add + subs_to_activate,\n            subscriber_dict=subscriber_peer_info.subscribed_ids,\n        )\n\n    send_peer_subscriber_events(\n        op=\"peer_add\",\n        realm=realm,\n        altered_user_dict=altered_user_dict,\n        stream_dict=stream_dict,\n        private_peer_dict=subscriber_peer_info.private_peer_dict,\n    )\n\n    return (\n        subs_to_add + subs_to_activate,\n        already_subscribed,\n    )\n\n\n# This function contains all the database changes as part of\n# subscribing users to streams; we use a transaction to ensure that\n# the RealmAuditLog entries are created atomically with the\n# Subscription object creation (and updates).\n@transaction.atomic(savepoint=False)\ndef bulk_add_subs_to_db_with_logging(\n    realm: Realm,\n    acting_user: Optional[UserProfile],\n    subs_to_add: List[SubInfo],\n    subs_to_activate: List[SubInfo],\n) -> None:\n\n    Subscription.objects.bulk_create(info.sub for info in subs_to_add)\n    sub_ids = [info.sub.id for info in subs_to_activate]\n    Subscription.objects.filter(id__in=sub_ids).update(active=True)\n\n    # Log subscription activities in RealmAuditLog\n    event_time = timezone_now()\n    event_last_message_id = get_last_message_id()\n\n    all_subscription_logs: (List[RealmAuditLog]) = []\n    for sub_info in subs_to_add:\n        all_subscription_logs.append(\n            RealmAuditLog(\n                realm=realm,\n                acting_user=acting_user,\n                modified_user=sub_info.user,\n                modified_stream=sub_info.stream,\n                event_last_message_id=event_last_message_id,\n                event_type=RealmAuditLog.SUBSCRIPTION_CREATED,\n                event_time=event_time,\n            )\n        )\n    for sub_info in subs_to_activate:\n        all_subscription_logs.append(\n            RealmAuditLog(\n                realm=realm,\n                acting_user=acting_user,\n                modified_user=sub_info.user,\n                modified_stream=sub_info.stream,\n                event_last_message_id=event_last_message_id,\n                event_type=RealmAuditLog.SUBSCRIPTION_ACTIVATED,\n                event_time=event_time,\n            )\n        )\n    # Now since we have all log objects generated we can do a bulk insert\n    RealmAuditLog.objects.bulk_create(all_subscription_logs)\n\n\ndef send_stream_creation_events_for_private_streams(\n    realm: Realm,\n    stream_dict: Dict[int, Stream],\n    altered_user_dict: Dict[int, Set[int]],\n) -> None:\n    for stream_id, stream_users_ids in altered_user_dict.items():\n        stream = stream_dict[stream_id]\n\n        if not stream.is_public():\n            # Users newly added to invite-only streams\n            # need a `create` notification.  The former, because\n            # they need the stream to exist before\n            # they get the \"subscribe\" notification, and the latter so\n            # they can manage the new stream.\n            # Realm admins already have all created private streams.\n            realm_admin_ids = {user.id for user in realm.get_admin_users_and_bots()}\n            notify_user_ids = list(stream_users_ids - realm_admin_ids)\n\n            if notify_user_ids:\n                send_stream_creation_event(stream, notify_user_ids)\n\n\ndef send_peer_subscriber_events(\n    op: str,\n    realm: Realm,\n    stream_dict: Dict[int, Stream],\n    altered_user_dict: Dict[int, Set[int]],\n    private_peer_dict: Dict[int, Set[int]],\n) -> None:\n    # Send peer_add/peer_remove events to other users who are tracking the\n    # subscribers lists of streams in their browser; everyone for\n    # public streams and only existing subscribers for private streams.\n\n    assert op in [\"peer_add\", \"peer_remove\"]\n\n    private_stream_ids = [\n        stream_id for stream_id in altered_user_dict if stream_dict[stream_id].invite_only\n    ]\n\n    for stream_id in private_stream_ids:\n        altered_user_ids = altered_user_dict[stream_id]\n        peer_user_ids = private_peer_dict[stream_id] - altered_user_ids\n\n        if peer_user_ids and altered_user_ids:\n            event = dict(\n                type=\"subscription\",\n                op=op,\n                stream_ids=[stream_id],\n                user_ids=sorted(list(altered_user_ids)),\n            )\n            send_event(realm, event, peer_user_ids)\n\n    public_stream_ids = [\n        stream_id\n        for stream_id in altered_user_dict\n        if not stream_dict[stream_id].invite_only and not stream_dict[stream_id].is_in_zephyr_realm\n    ]\n\n    if public_stream_ids:\n        user_streams: Dict[int, Set[int]] = defaultdict(set)\n\n        public_peer_ids = set(active_non_guest_user_ids(realm.id))\n\n        for stream_id in public_stream_ids:\n            altered_user_ids = altered_user_dict[stream_id]\n            peer_user_ids = public_peer_ids - altered_user_ids\n\n            if peer_user_ids and altered_user_ids:\n                if len(altered_user_ids) == 1:\n                    # If we only have one user, we will try to\n                    # find other streams they have (un)subscribed to\n                    # (where it's just them).  This optimization\n                    # typically works when a single user is subscribed\n                    # to multiple default public streams during\n                    # new-user registration.\n                    #\n                    # This optimization depends on all public streams\n                    # having the same peers for any single user, which\n                    # isn't the case for private streams.\n                    altered_user_id = list(altered_user_ids)[0]\n                    user_streams[altered_user_id].add(stream_id)\n                else:\n                    event = dict(\n                        type=\"subscription\",\n                        op=op,\n                        stream_ids=[stream_id],\n                        user_ids=sorted(list(altered_user_ids)),\n                    )\n                    send_event(realm, event, peer_user_ids)\n\n        for user_id, stream_ids in user_streams.items():\n            peer_user_ids = public_peer_ids - {user_id}\n            event = dict(\n                type=\"subscription\",\n                op=op,\n                stream_ids=sorted(list(stream_ids)),\n                user_ids=[user_id],\n            )\n            send_event(realm, event, peer_user_ids)\n\n\ndef send_peer_remove_events(\n    realm: Realm,\n    streams: List[Stream],\n    altered_user_dict: Dict[int, Set[int]],\n) -> None:\n    private_streams = [stream for stream in streams if stream.invite_only]\n\n    private_peer_dict = bulk_get_private_peers(\n        realm=realm,\n        private_streams=private_streams,\n    )\n    stream_dict = {stream.id: stream for stream in streams}\n\n    send_peer_subscriber_events(\n        op=\"peer_remove\",\n        realm=realm,\n        stream_dict=stream_dict,\n        altered_user_dict=altered_user_dict,\n        private_peer_dict=private_peer_dict,\n    )\n\n\ndef get_available_notification_sounds() -> List[str]:\n    notification_sounds_path = static_path(\"audio/notification_sounds\")\n    available_notification_sounds = []\n\n    for file_name in os.listdir(notification_sounds_path):\n        root, ext = os.path.splitext(file_name)\n        if \".\" in root:  # nocoverage\n            # Exclude e.g. zulip.abcd1234.ogg (generated by production hash-naming)\n            # to avoid spurious duplicates.\n            continue\n        if ext == \".ogg\":\n            available_notification_sounds.append(root)\n\n    return sorted(available_notification_sounds)\n\n\ndef notify_subscriptions_removed(\n    realm: Realm, user_profile: UserProfile, streams: Iterable[Stream]\n) -> None:\n\n    payload = [dict(name=stream.name, stream_id=stream.id) for stream in streams]\n    event = dict(type=\"subscription\", op=\"remove\", subscriptions=payload)\n    send_event(realm, event, [user_profile.id])\n\n\nSubAndRemovedT = Tuple[List[Tuple[UserProfile, Stream]], List[Tuple[UserProfile, Stream]]]\n\n\ndef bulk_remove_subscriptions(\n    realm: Realm,\n    users: Iterable[UserProfile],\n    streams: Iterable[Stream],\n    *,\n    acting_user: Optional[UserProfile],\n) -> SubAndRemovedT:\n\n    users = list(users)\n    streams = list(streams)\n\n    # Sanity check our callers\n    for stream in streams:\n        assert stream.realm_id == realm.id\n\n    for user in users:\n        assert user.realm_id == realm.id\n\n    stream_dict = {stream.id: stream for stream in streams}\n\n    existing_subs_by_user = get_bulk_stream_subscriber_info(users, streams)\n\n    def get_non_subscribed_subs() -> List[Tuple[UserProfile, Stream]]:\n        stream_ids = {stream.id for stream in streams}\n\n        not_subscribed: List[Tuple[UserProfile, Stream]] = []\n\n        for user_profile in users:\n            user_sub_stream_info = existing_subs_by_user[user_profile.id]\n\n            subscribed_stream_ids = {sub_info.stream.id for sub_info in user_sub_stream_info}\n            not_subscribed_stream_ids = stream_ids - subscribed_stream_ids\n\n            for stream_id in not_subscribed_stream_ids:\n                stream = stream_dict[stream_id]\n                not_subscribed.append((user_profile, stream))\n\n        return not_subscribed\n\n    not_subscribed = get_non_subscribed_subs()\n\n    subs_to_deactivate: List[SubInfo] = []\n    sub_ids_to_deactivate: List[int] = []\n\n    # This loop just flattens out our data into big lists for\n    # bulk operations.\n    for sub_infos in existing_subs_by_user.values():\n        for sub_info in sub_infos:\n            subs_to_deactivate.append(sub_info)\n            sub_ids_to_deactivate.append(sub_info.sub.id)\n\n    # We do all the database changes in a transaction to ensure\n    # RealmAuditLog entries are atomically created when making changes.\n    with transaction.atomic():\n        occupied_streams_before = list(get_occupied_streams(realm))\n        Subscription.objects.filter(\n            id__in=sub_ids_to_deactivate,\n        ).update(active=False)\n        occupied_streams_after = list(get_occupied_streams(realm))\n\n        # Log subscription activities in RealmAuditLog\n        event_time = timezone_now()\n        event_last_message_id = get_last_message_id()\n        all_subscription_logs = [\n            RealmAuditLog(\n                realm=sub_info.user.realm,\n                acting_user=acting_user,\n                modified_user=sub_info.user,\n                modified_stream=sub_info.stream,\n                event_last_message_id=event_last_message_id,\n                event_type=RealmAuditLog.SUBSCRIPTION_DEACTIVATED,\n                event_time=event_time,\n            )\n            for sub_info in subs_to_deactivate\n        ]\n\n        # Now since we have all log objects generated we can do a bulk insert\n        RealmAuditLog.objects.bulk_create(all_subscription_logs)\n\n    altered_user_dict: Dict[int, Set[int]] = defaultdict(set)\n    streams_by_user: Dict[int, List[Stream]] = defaultdict(list)\n    for sub_info in subs_to_deactivate:\n        stream = sub_info.stream\n        streams_by_user[sub_info.user.id].append(stream)\n        altered_user_dict[stream.id].add(sub_info.user.id)\n\n    for user_profile in users:\n        if len(streams_by_user[user_profile.id]) == 0:\n            continue\n        notify_subscriptions_removed(realm, user_profile, streams_by_user[user_profile.id])\n\n        event = {\n            \"type\": \"mark_stream_messages_as_read\",\n            \"user_profile_id\": user_profile.id,\n            \"stream_recipient_ids\": [stream.recipient_id for stream in streams],\n        }\n        queue_json_publish(\"deferred_work\", event)\n\n    send_peer_remove_events(\n        realm=realm,\n        streams=streams,\n        altered_user_dict=altered_user_dict,\n    )\n\n    new_vacant_streams = set(occupied_streams_before) - set(occupied_streams_after)\n    new_vacant_private_streams = [stream for stream in new_vacant_streams if stream.invite_only]\n\n    if new_vacant_private_streams:\n        # Deactivate any newly-vacant private streams\n        for stream in new_vacant_private_streams:\n            do_deactivate_stream(stream, acting_user=acting_user)\n\n    return (\n        [(sub_info.user, sub_info.stream) for sub_info in subs_to_deactivate],\n        not_subscribed,\n    )\n\n\ndef do_change_subscription_property(\n    user_profile: UserProfile,\n    sub: Subscription,\n    stream: Stream,\n    property_name: str,\n    value: Any,\n    *,\n    acting_user: Optional[UserProfile],\n) -> None:\n    database_property_name = property_name\n    event_property_name = property_name\n    database_value = value\n    event_value = value\n\n    # For this property, is_muted is used in the database, but\n    # in_home_view in the API, since we haven't migrated the events\n    # API to the new name yet.\n    if property_name == \"in_home_view\":\n        database_property_name = \"is_muted\"\n        database_value = not value\n    if property_name == \"is_muted\":\n        event_property_name = \"in_home_view\"\n        event_value = not value\n\n    old_value = getattr(sub, database_property_name)\n    setattr(sub, database_property_name, database_value)\n    sub.save(update_fields=[database_property_name])\n    event_time = timezone_now()\n    RealmAuditLog.objects.create(\n        realm=user_profile.realm,\n        event_type=RealmAuditLog.SUBSCRIPTION_PROPERTY_CHANGED,\n        event_time=event_time,\n        modified_user=user_profile,\n        acting_user=acting_user,\n        modified_stream=stream,\n        extra_data=orjson.dumps(\n            {\n                RealmAuditLog.OLD_VALUE: old_value,\n                RealmAuditLog.NEW_VALUE: database_value,\n                \"property\": database_property_name,\n            }\n        ).decode(),\n    )\n\n    event = dict(\n        type=\"subscription\",\n        op=\"update\",\n        property=event_property_name,\n        value=event_value,\n        stream_id=stream.id,\n    )\n    send_event(user_profile.realm, event, [user_profile.id])\n\n\ndef do_change_password(user_profile: UserProfile, password: str, commit: bool = True) -> None:\n    user_profile.set_password(password)\n    if commit:\n        user_profile.save(update_fields=[\"password\"])\n    event_time = timezone_now()\n    RealmAuditLog.objects.create(\n        realm=user_profile.realm,\n        acting_user=user_profile,\n        modified_user=user_profile,\n        event_type=RealmAuditLog.USER_PASSWORD_CHANGED,\n        event_time=event_time,\n    )\n\n\ndef do_change_full_name(\n    user_profile: UserProfile, full_name: str, acting_user: Optional[UserProfile]\n) -> None:\n    old_name = user_profile.full_name\n    user_profile.full_name = full_name\n    user_profile.save(update_fields=[\"full_name\"])\n    event_time = timezone_now()\n    RealmAuditLog.objects.create(\n        realm=user_profile.realm,\n        acting_user=acting_user,\n        modified_user=user_profile,\n        event_type=RealmAuditLog.USER_FULL_NAME_CHANGED,\n        event_time=event_time,\n        extra_data=old_name,\n    )\n    payload = dict(user_id=user_profile.id, full_name=user_profile.full_name)\n    send_event(\n        user_profile.realm,\n        dict(type=\"realm_user\", op=\"update\", person=payload),\n        active_user_ids(user_profile.realm_id),\n    )\n    if user_profile.is_bot:\n        send_event(\n            user_profile.realm,\n            dict(type=\"realm_bot\", op=\"update\", bot=payload),\n            bot_owner_user_ids(user_profile),\n        )\n\n\ndef check_change_full_name(\n    user_profile: UserProfile, full_name_raw: str, acting_user: Optional[UserProfile]\n) -> str:\n    \"\"\"Verifies that the user's proposed full name is valid.  The caller\n    is responsible for checking check permissions.  Returns the new\n    full name, which may differ from what was passed in (because this\n    function strips whitespace).\"\"\"\n    new_full_name = check_full_name(full_name_raw)\n    do_change_full_name(user_profile, new_full_name, acting_user)\n    return new_full_name\n\n\ndef check_change_bot_full_name(\n    user_profile: UserProfile, full_name_raw: str, acting_user: UserProfile\n) -> None:\n    new_full_name = check_full_name(full_name_raw)\n\n    if new_full_name == user_profile.full_name:\n        # Our web app will try to patch full_name even if the user didn't\n        # modify the name in the form.  We just silently ignore those\n        # situations.\n        return\n\n    check_bot_name_available(\n        realm_id=user_profile.realm_id,\n        full_name=new_full_name,\n    )\n    do_change_full_name(user_profile, new_full_name, acting_user)\n\n\n@transaction.atomic(durable=True)\ndef do_change_bot_owner(\n    user_profile: UserProfile, bot_owner: UserProfile, acting_user: UserProfile\n) -> None:\n    previous_owner = user_profile.bot_owner\n    user_profile.bot_owner = bot_owner\n    user_profile.save()  # Can't use update_fields because of how the foreign key works.\n    event_time = timezone_now()\n    RealmAuditLog.objects.create(\n        realm=user_profile.realm,\n        acting_user=acting_user,\n        modified_user=user_profile,\n        event_type=RealmAuditLog.USER_BOT_OWNER_CHANGED,\n        event_time=event_time,\n    )\n\n    update_users = bot_owner_user_ids(user_profile)\n\n    # For admins, update event is sent instead of delete/add\n    # event. bot_data of admin contains all the\n    # bots and none of them should be removed/(added again).\n\n    # Delete the bot from previous owner's bot data.\n    if previous_owner and not previous_owner.is_realm_admin:\n        delete_event = dict(\n            type=\"realm_bot\",\n            op=\"delete\",\n            bot=dict(\n                user_id=user_profile.id,\n            ),\n        )\n        transaction.on_commit(\n            lambda: send_event(\n                user_profile.realm,\n                delete_event,\n                {previous_owner.id},\n            )\n        )\n        # Do not send update event for previous bot owner.\n        update_users = update_users - {previous_owner.id}\n\n    # Notify the new owner that the bot has been added.\n    if not bot_owner.is_realm_admin:\n        add_event = created_bot_event(user_profile)\n        transaction.on_commit(lambda: send_event(user_profile.realm, add_event, {bot_owner.id}))\n        # Do not send update event for bot_owner.\n        update_users = update_users - {bot_owner.id}\n\n    bot_event = dict(\n        type=\"realm_bot\",\n        op=\"update\",\n        bot=dict(\n            user_id=user_profile.id,\n            owner_id=user_profile.bot_owner.id,\n        ),\n    )\n    transaction.on_commit(\n        lambda: send_event(\n            user_profile.realm,\n            bot_event,\n            update_users,\n        )\n    )\n\n    # Since `bot_owner_id` is included in the user profile dict we need\n    # to update the users dict with the new bot owner id\n    event = dict(\n        type=\"realm_user\",\n        op=\"update\",\n        person=dict(\n            user_id=user_profile.id,\n            bot_owner_id=user_profile.bot_owner.id,\n        ),\n    )\n    transaction.on_commit(\n        lambda: send_event(user_profile.realm, event, active_user_ids(user_profile.realm_id))\n    )\n\n\n@transaction.atomic(durable=True)\ndef do_change_tos_version(user_profile: UserProfile, tos_version: str) -> None:\n    user_profile.tos_version = tos_version\n    user_profile.save(update_fields=[\"tos_version\"])\n    event_time = timezone_now()\n    RealmAuditLog.objects.create(\n        realm=user_profile.realm,\n        acting_user=user_profile,\n        modified_user=user_profile,\n        event_type=RealmAuditLog.USER_TERMS_OF_SERVICE_VERSION_CHANGED,\n        event_time=event_time,\n    )\n\n\ndef do_regenerate_api_key(user_profile: UserProfile, acting_user: UserProfile) -> str:\n    old_api_key = user_profile.api_key\n    new_api_key = generate_api_key()\n    user_profile.api_key = new_api_key\n    user_profile.save(update_fields=[\"api_key\"])\n\n    # We need to explicitly delete the old API key from our caches,\n    # because the on-save handler for flushing the UserProfile object\n    # in zerver/lib/cache.py only has access to the new API key.\n    cache_delete(user_profile_by_api_key_cache_key(old_api_key))\n\n    event_time = timezone_now()\n    RealmAuditLog.objects.create(\n        realm=user_profile.realm,\n        acting_user=acting_user,\n        modified_user=user_profile,\n        event_type=RealmAuditLog.USER_API_KEY_CHANGED,\n        event_time=event_time,\n    )\n\n    if user_profile.is_bot:\n        send_event(\n            user_profile.realm,\n            dict(\n                type=\"realm_bot\",\n                op=\"update\",\n                bot=dict(\n                    user_id=user_profile.id,\n                    api_key=new_api_key,\n                ),\n            ),\n            bot_owner_user_ids(user_profile),\n        )\n\n    event = {\"type\": \"clear_push_device_tokens\", \"user_profile_id\": user_profile.id}\n    queue_json_publish(\"deferred_work\", event)\n\n    return new_api_key\n\n\ndef notify_avatar_url_change(user_profile: UserProfile) -> None:\n    if user_profile.is_bot:\n        bot_event = dict(\n            type=\"realm_bot\",\n            op=\"update\",\n            bot=dict(\n                user_id=user_profile.id,\n                avatar_url=avatar_url(user_profile),\n            ),\n        )\n        transaction.on_commit(\n            lambda: send_event(\n                user_profile.realm,\n                bot_event,\n                bot_owner_user_ids(user_profile),\n            )\n        )\n\n    payload = dict(\n        avatar_source=user_profile.avatar_source,\n        avatar_url=avatar_url(user_profile),\n        avatar_url_medium=avatar_url(user_profile, medium=True),\n        avatar_version=user_profile.avatar_version,\n        # Even clients using client_gravatar don't need the email,\n        # since we're sending the URL anyway.\n        user_id=user_profile.id,\n    )\n\n    event = dict(type=\"realm_user\", op=\"update\", person=payload)\n    transaction.on_commit(\n        lambda: send_event(\n            user_profile.realm,\n            event,\n            active_user_ids(user_profile.realm_id),\n        )\n    )\n\n\n@transaction.atomic(savepoint=False)\ndef do_change_avatar_fields(\n    user_profile: UserProfile,\n    avatar_source: str,\n    skip_notify: bool = False,\n    *,\n    acting_user: Optional[UserProfile],\n) -> None:\n    user_profile.avatar_source = avatar_source\n    user_profile.avatar_version += 1\n    user_profile.save(update_fields=[\"avatar_source\", \"avatar_version\"])\n    event_time = timezone_now()\n    RealmAuditLog.objects.create(\n        realm=user_profile.realm,\n        modified_user=user_profile,\n        event_type=RealmAuditLog.USER_AVATAR_SOURCE_CHANGED,\n        extra_data={\"avatar_source\": avatar_source},\n        event_time=event_time,\n        acting_user=acting_user,\n    )\n\n    if not skip_notify:\n        notify_avatar_url_change(user_profile)\n\n\ndef do_delete_avatar_image(user: UserProfile, *, acting_user: Optional[UserProfile]) -> None:\n    do_change_avatar_fields(user, UserProfile.AVATAR_FROM_GRAVATAR, acting_user=acting_user)\n    delete_avatar_image(user)\n\n\n@transaction.atomic(durable=True)\ndef do_change_icon_source(\n    realm: Realm, icon_source: str, *, acting_user: Optional[UserProfile]\n) -> None:\n    realm.icon_source = icon_source\n    realm.icon_version += 1\n    realm.save(update_fields=[\"icon_source\", \"icon_version\"])\n\n    event_time = timezone_now()\n    RealmAuditLog.objects.create(\n        realm=realm,\n        event_type=RealmAuditLog.REALM_ICON_SOURCE_CHANGED,\n        extra_data={\"icon_source\": icon_source, \"icon_version\": realm.icon_version},\n        event_time=event_time,\n        acting_user=acting_user,\n    )\n\n    event = dict(\n        type=\"realm\",\n        op=\"update_dict\",\n        property=\"icon\",\n        data=dict(icon_source=realm.icon_source, icon_url=realm_icon_url(realm)),\n    )\n    transaction.on_commit(\n        lambda: send_event(\n            realm,\n            event,\n            active_user_ids(realm.id),\n        )\n    )\n\n\n@transaction.atomic(durable=True)\ndef do_change_logo_source(\n    realm: Realm, logo_source: str, night: bool, *, acting_user: Optional[UserProfile]\n) -> None:\n    if not night:\n        realm.logo_source = logo_source\n        realm.logo_version += 1\n        realm.save(update_fields=[\"logo_source\", \"logo_version\"])\n\n    else:\n        realm.night_logo_source = logo_source\n        realm.night_logo_version += 1\n        realm.save(update_fields=[\"night_logo_source\", \"night_logo_version\"])\n\n    RealmAuditLog.objects.create(\n        event_type=RealmAuditLog.REALM_LOGO_CHANGED,\n        realm=realm,\n        event_time=timezone_now(),\n        acting_user=acting_user,\n    )\n\n    event = dict(\n        type=\"realm\",\n        op=\"update_dict\",\n        property=\"night_logo\" if night else \"logo\",\n        data=get_realm_logo_data(realm, night),\n    )\n    transaction.on_commit(lambda: send_event(realm, event, active_user_ids(realm.id)))\n\n\n@transaction.atomic(durable=True)\ndef do_change_realm_org_type(\n    realm: Realm,\n    org_type: int,\n    acting_user: Optional[UserProfile],\n) -> None:\n    old_value = realm.org_type\n    realm.org_type = org_type\n    realm.save(update_fields=[\"org_type\"])\n\n    RealmAuditLog.objects.create(\n        event_type=RealmAuditLog.REALM_ORG_TYPE_CHANGED,\n        realm=realm,\n        event_time=timezone_now(),\n        acting_user=acting_user,\n        extra_data={\"old_value\": old_value, \"new_value\": org_type},\n    )\n\n\n@transaction.atomic(savepoint=False)\ndef do_change_realm_plan_type(\n    realm: Realm, plan_type: int, *, acting_user: Optional[UserProfile]\n) -> None:\n    old_value = realm.plan_type\n    realm.plan_type = plan_type\n    realm.save(update_fields=[\"plan_type\"])\n    RealmAuditLog.objects.create(\n        event_type=RealmAuditLog.REALM_PLAN_TYPE_CHANGED,\n        realm=realm,\n        event_time=timezone_now(),\n        acting_user=acting_user,\n        extra_data={\"old_value\": old_value, \"new_value\": plan_type},\n    )\n\n    if plan_type == Realm.PLAN_TYPE_PLUS:\n        realm.max_invites = Realm.INVITES_STANDARD_REALM_DAILY_MAX\n        realm.message_visibility_limit = None\n        realm.upload_quota_gb = Realm.UPLOAD_QUOTA_STANDARD\n    elif plan_type == Realm.PLAN_TYPE_STANDARD:\n        realm.max_invites = Realm.INVITES_STANDARD_REALM_DAILY_MAX\n        realm.message_visibility_limit = None\n        realm.upload_quota_gb = Realm.UPLOAD_QUOTA_STANDARD\n    elif plan_type == Realm.PLAN_TYPE_SELF_HOSTED:\n        realm.max_invites = None  # type: ignore[assignment] # Apparent mypy bug with Optional[int] setter.\n        realm.message_visibility_limit = None\n        realm.upload_quota_gb = None\n    elif plan_type == Realm.PLAN_TYPE_STANDARD_FREE:\n        realm.max_invites = Realm.INVITES_STANDARD_REALM_DAILY_MAX\n        realm.message_visibility_limit = None\n        realm.upload_quota_gb = Realm.UPLOAD_QUOTA_STANDARD\n    elif plan_type == Realm.PLAN_TYPE_LIMITED:\n        realm.max_invites = settings.INVITES_DEFAULT_REALM_DAILY_MAX\n        realm.message_visibility_limit = Realm.MESSAGE_VISIBILITY_LIMITED\n        realm.upload_quota_gb = Realm.UPLOAD_QUOTA_LIMITED\n    else:\n        raise AssertionError(\"Invalid plan type\")\n\n    update_first_visible_message_id(realm)\n\n    realm.save(update_fields=[\"_max_invites\", \"message_visibility_limit\", \"upload_quota_gb\"])\n\n    event = {\n        \"type\": \"realm\",\n        \"op\": \"update\",\n        \"property\": \"plan_type\",\n        \"value\": plan_type,\n        \"extra_data\": {\"upload_quota\": realm.upload_quota_bytes()},\n    }\n    transaction.on_commit(lambda: send_event(realm, event, active_user_ids(realm.id)))\n\n\n@transaction.atomic(durable=True)\ndef do_change_default_sending_stream(\n    user_profile: UserProfile, stream: Optional[Stream], *, acting_user: Optional[UserProfile]\n) -> None:\n    old_value = user_profile.default_sending_stream_id\n    user_profile.default_sending_stream = stream\n    user_profile.save(update_fields=[\"default_sending_stream\"])\n\n    event_time = timezone_now()\n    RealmAuditLog.objects.create(\n        realm=user_profile.realm,\n        event_type=RealmAuditLog.USER_DEFAULT_SENDING_STREAM_CHANGED,\n        event_time=event_time,\n        modified_user=user_profile,\n        acting_user=acting_user,\n        extra_data=orjson.dumps(\n            {\n                RealmAuditLog.OLD_VALUE: old_value,\n                RealmAuditLog.NEW_VALUE: None if stream is None else stream.id,\n            }\n        ).decode(),\n    )\n\n    if user_profile.is_bot:\n        if stream:\n            stream_name: Optional[str] = stream.name\n        else:\n            stream_name = None\n        event = dict(\n            type=\"realm_bot\",\n            op=\"update\",\n            bot=dict(\n                user_id=user_profile.id,\n                default_sending_stream=stream_name,\n            ),\n        )\n        transaction.on_commit(\n            lambda: send_event(\n                user_profile.realm,\n                event,\n                bot_owner_user_ids(user_profile),\n            )\n        )\n\n\n@transaction.atomic(durable=True)\ndef do_change_default_events_register_stream(\n    user_profile: UserProfile, stream: Optional[Stream], *, acting_user: Optional[UserProfile]\n) -> None:\n    old_value = user_profile.default_events_register_stream_id\n    user_profile.default_events_register_stream = stream\n    user_profile.save(update_fields=[\"default_events_register_stream\"])\n\n    event_time = timezone_now()\n    RealmAuditLog.objects.create(\n        realm=user_profile.realm,\n        event_type=RealmAuditLog.USER_DEFAULT_REGISTER_STREAM_CHANGED,\n        event_time=event_time,\n        modified_user=user_profile,\n        acting_user=acting_user,\n        extra_data=orjson.dumps(\n            {\n                RealmAuditLog.OLD_VALUE: old_value,\n                RealmAuditLog.NEW_VALUE: None if stream is None else stream.id,\n            }\n        ).decode(),\n    )\n\n    if user_profile.is_bot:\n        if stream:\n            stream_name: Optional[str] = stream.name\n        else:\n            stream_name = None\n\n        event = dict(\n            type=\"realm_bot\",\n            op=\"update\",\n            bot=dict(\n                user_id=user_profile.id,\n                default_events_register_stream=stream_name,\n            ),\n        )\n        transaction.on_commit(\n            lambda: send_event(\n                user_profile.realm,\n                event,\n                bot_owner_user_ids(user_profile),\n            )\n        )\n\n\n@transaction.atomic(durable=True)\ndef do_change_default_all_public_streams(\n    user_profile: UserProfile, value: bool, *, acting_user: Optional[UserProfile]\n) -> None:\n    old_value = user_profile.default_all_public_streams\n    user_profile.default_all_public_streams = value\n    user_profile.save(update_fields=[\"default_all_public_streams\"])\n\n    event_time = timezone_now()\n    RealmAuditLog.objects.create(\n        realm=user_profile.realm,\n        event_type=RealmAuditLog.USER_DEFAULT_ALL_PUBLIC_STREAMS_CHANGED,\n        event_time=event_time,\n        modified_user=user_profile,\n        acting_user=acting_user,\n        extra_data=orjson.dumps(\n            {\n                RealmAuditLog.OLD_VALUE: old_value,\n                RealmAuditLog.NEW_VALUE: value,\n            }\n        ).decode(),\n    )\n\n    if user_profile.is_bot:\n        event = dict(\n            type=\"realm_bot\",\n            op=\"update\",\n            bot=dict(\n                user_id=user_profile.id,\n                default_all_public_streams=user_profile.default_all_public_streams,\n            ),\n        )\n        transaction.on_commit(\n            lambda: send_event(\n                user_profile.realm,\n                event,\n                bot_owner_user_ids(user_profile),\n            )\n        )\n\n\n@transaction.atomic(durable=True)\ndef do_change_user_role(\n    user_profile: UserProfile, value: int, *, acting_user: Optional[UserProfile]\n) -> None:\n    old_value = user_profile.role\n    old_system_group = get_system_user_group_for_user(user_profile)\n\n    user_profile.role = value\n    user_profile.save(update_fields=[\"role\"])\n    RealmAuditLog.objects.create(\n        realm=user_profile.realm,\n        modified_user=user_profile,\n        acting_user=acting_user,\n        event_type=RealmAuditLog.USER_ROLE_CHANGED,\n        event_time=timezone_now(),\n        extra_data=orjson.dumps(\n            {\n                RealmAuditLog.OLD_VALUE: old_value,\n                RealmAuditLog.NEW_VALUE: value,\n                RealmAuditLog.ROLE_COUNT: realm_user_count_by_role(user_profile.realm),\n            }\n        ).decode(),\n    )\n    event = dict(\n        type=\"realm_user\", op=\"update\", person=dict(user_id=user_profile.id, role=user_profile.role)\n    )\n    transaction.on_commit(\n        lambda: send_event(user_profile.realm, event, active_user_ids(user_profile.realm_id))\n    )\n\n    UserGroupMembership.objects.filter(\n        user_profile=user_profile, user_group=old_system_group\n    ).delete()\n\n    system_group = get_system_user_group_for_user(user_profile)\n    UserGroupMembership.objects.create(user_profile=user_profile, user_group=system_group)\n\n    do_send_user_group_members_update_event(\"remove_members\", old_system_group, [user_profile.id])\n\n    do_send_user_group_members_update_event(\"add_members\", system_group, [user_profile.id])\n\n    if UserProfile.ROLE_MEMBER in [old_value, value]:\n        update_users_in_full_members_system_group(user_profile.realm, [user_profile.id])\n\n\ndef do_make_user_billing_admin(user_profile: UserProfile) -> None:\n    user_profile.is_billing_admin = True\n    user_profile.save(update_fields=[\"is_billing_admin\"])\n    event = dict(\n        type=\"realm_user\", op=\"update\", person=dict(user_id=user_profile.id, is_billing_admin=True)\n    )\n    send_event(user_profile.realm, event, active_user_ids(user_profile.realm_id))\n\n\ndef do_change_can_forge_sender(user_profile: UserProfile, value: bool) -> None:\n    user_profile.can_forge_sender = value\n    user_profile.save(update_fields=[\"can_forge_sender\"])\n\n\ndef do_change_can_create_users(user_profile: UserProfile, value: bool) -> None:\n    user_profile.can_create_users = value\n    user_profile.save(update_fields=[\"can_create_users\"])\n\n\ndef send_change_stream_permission_notification(\n    stream: Stream,\n    *,\n    old_policy_name: str,\n    new_policy_name: str,\n    acting_user: UserProfile,\n) -> None:\n    sender = get_system_bot(settings.NOTIFICATION_BOT, acting_user.realm_id)\n    user_mention = silent_mention_syntax_for_user(acting_user)\n\n    with override_language(stream.realm.default_language):\n        notification_string = _(\n            \"{user} changed the [access permissions](/help/stream-permissions) \"\n            \"for this stream from **{old_policy}** to **{new_policy}**.\"\n        )\n        notification_string = notification_string.format(\n            user=user_mention,\n            old_policy=old_policy_name,\n            new_policy=new_policy_name,\n        )\n        internal_send_stream_message(\n            sender, stream, Realm.STREAM_EVENTS_NOTIFICATION_TOPIC, notification_string\n        )\n\n\ndef do_change_stream_permission(\n    stream: Stream,\n    *,\n    invite_only: Optional[bool] = None,\n    history_public_to_subscribers: Optional[bool] = None,\n    is_web_public: Optional[bool] = None,\n    acting_user: UserProfile,\n) -> None:\n    old_invite_only_value = stream.invite_only\n    old_history_public_to_subscribers_value = stream.history_public_to_subscribers\n    old_is_web_public_value = stream.is_web_public\n\n    # A note on these assertions: It's possible we'd be better off\n    # making all callers of this function pass the full set of\n    # parameters, rather than having default values.  Doing so would\n    # allow us to remove the messy logic below, where we sometimes\n    # ignore the passed parameters.\n    #\n    # But absent such a refactoring, it's important to assert that\n    # we're not requesting an unsupported configurations.\n    if is_web_public:\n        assert history_public_to_subscribers is not False\n        assert invite_only is not True\n        stream.is_web_public = True\n        stream.invite_only = False\n        stream.history_public_to_subscribers = True\n    else:\n        assert invite_only is not None\n        # is_web_public is falsey\n        history_public_to_subscribers = get_default_value_for_history_public_to_subscribers(\n            stream.realm,\n            invite_only,\n            history_public_to_subscribers,\n        )\n        stream.invite_only = invite_only\n        stream.history_public_to_subscribers = history_public_to_subscribers\n        stream.is_web_public = False\n\n    with transaction.atomic():\n        stream.save(update_fields=[\"invite_only\", \"history_public_to_subscribers\", \"is_web_public\"])\n\n        event_time = timezone_now()\n        if old_invite_only_value != stream.invite_only:\n            RealmAuditLog.objects.create(\n                realm=stream.realm,\n                acting_user=acting_user,\n                modified_stream=stream,\n                event_type=RealmAuditLog.STREAM_PROPERTY_CHANGED,\n                event_time=event_time,\n                extra_data=orjson.dumps(\n                    {\n                        RealmAuditLog.OLD_VALUE: old_invite_only_value,\n                        RealmAuditLog.NEW_VALUE: stream.invite_only,\n                        \"property\": \"invite_only\",\n                    }\n                ).decode(),\n            )\n\n        if old_history_public_to_subscribers_value != stream.history_public_to_subscribers:\n            RealmAuditLog.objects.create(\n                realm=stream.realm,\n                acting_user=acting_user,\n                modified_stream=stream,\n                event_type=RealmAuditLog.STREAM_PROPERTY_CHANGED,\n                event_time=event_time,\n                extra_data=orjson.dumps(\n                    {\n                        RealmAuditLog.OLD_VALUE: old_history_public_to_subscribers_value,\n                        RealmAuditLog.NEW_VALUE: stream.history_public_to_subscribers,\n                        \"property\": \"history_public_to_subscribers\",\n                    }\n                ).decode(),\n            )\n\n        if old_is_web_public_value != stream.is_web_public:\n            RealmAuditLog.objects.create(\n                realm=stream.realm,\n                acting_user=acting_user,\n                modified_stream=stream,\n                event_type=RealmAuditLog.STREAM_PROPERTY_CHANGED,\n                event_time=event_time,\n                extra_data=orjson.dumps(\n                    {\n                        RealmAuditLog.OLD_VALUE: old_is_web_public_value,\n                        RealmAuditLog.NEW_VALUE: stream.is_web_public,\n                        \"property\": \"is_web_public\",\n                    }\n                ).decode(),\n            )\n\n    event = dict(\n        op=\"update\",\n        type=\"stream\",\n        property=\"invite_only\",\n        value=stream.invite_only,\n        history_public_to_subscribers=stream.history_public_to_subscribers,\n        is_web_public=stream.is_web_public,\n        stream_id=stream.id,\n        name=stream.name,\n    )\n    send_event(stream.realm, event, can_access_stream_user_ids(stream))\n\n    old_policy_name = get_stream_permission_policy_name(\n        invite_only=old_invite_only_value,\n        history_public_to_subscribers=old_history_public_to_subscribers_value,\n        is_web_public=old_is_web_public_value,\n    )\n    new_policy_name = get_stream_permission_policy_name(\n        invite_only=stream.invite_only,\n        history_public_to_subscribers=stream.history_public_to_subscribers,\n        is_web_public=stream.is_web_public,\n    )\n    send_change_stream_permission_notification(\n        stream,\n        old_policy_name=old_policy_name,\n        new_policy_name=new_policy_name,\n        acting_user=acting_user,\n    )\n\n\ndef send_change_stream_post_policy_notification(\n    stream: Stream, *, old_post_policy: int, new_post_policy: int, acting_user: UserProfile\n) -> None:\n    sender = get_system_bot(settings.NOTIFICATION_BOT, acting_user.realm_id)\n    user_mention = silent_mention_syntax_for_user(acting_user)\n\n    with override_language(stream.realm.default_language):\n        notification_string = _(\n            \"{user} changed the [posting permissions](/help/stream-sending-policy) \"\n            \"for this stream:\\n\\n\"\n            \"* **Old permissions**: {old_policy}.\\n\"\n            \"* **New permissions**: {new_policy}.\\n\"\n        )\n        notification_string = notification_string.format(\n            user=user_mention,\n            old_policy=Stream.POST_POLICIES[old_post_policy],\n            new_policy=Stream.POST_POLICIES[new_post_policy],\n        )\n        internal_send_stream_message(\n            sender, stream, Realm.STREAM_EVENTS_NOTIFICATION_TOPIC, notification_string\n        )\n\n\ndef do_change_stream_post_policy(\n    stream: Stream, stream_post_policy: int, *, acting_user: UserProfile\n) -> None:\n    old_post_policy = stream.stream_post_policy\n    with transaction.atomic():\n        stream.stream_post_policy = stream_post_policy\n        stream.save(update_fields=[\"stream_post_policy\"])\n        RealmAuditLog.objects.create(\n            realm=stream.realm,\n            acting_user=acting_user,\n            modified_stream=stream,\n            event_type=RealmAuditLog.STREAM_PROPERTY_CHANGED,\n            event_time=timezone_now(),\n            extra_data=orjson.dumps(\n                {\n                    RealmAuditLog.OLD_VALUE: old_post_policy,\n                    RealmAuditLog.NEW_VALUE: stream_post_policy,\n                    \"property\": \"stream_post_policy\",\n                }\n            ).decode(),\n        )\n\n    event = dict(\n        op=\"update\",\n        type=\"stream\",\n        property=\"stream_post_policy\",\n        value=stream_post_policy,\n        stream_id=stream.id,\n        name=stream.name,\n    )\n    send_event(stream.realm, event, can_access_stream_user_ids(stream))\n\n    # Backwards-compatibility code: We removed the\n    # is_announcement_only property in early 2020, but we send a\n    # duplicate event for legacy mobile clients that might want the\n    # data.\n    event = dict(\n        op=\"update\",\n        type=\"stream\",\n        property=\"is_announcement_only\",\n        value=stream.stream_post_policy == Stream.STREAM_POST_POLICY_ADMINS,\n        stream_id=stream.id,\n        name=stream.name,\n    )\n    send_event(stream.realm, event, can_access_stream_user_ids(stream))\n\n    send_change_stream_post_policy_notification(\n        stream,\n        old_post_policy=old_post_policy,\n        new_post_policy=stream_post_policy,\n        acting_user=acting_user,\n    )\n\n\ndef do_rename_stream(stream: Stream, new_name: str, user_profile: UserProfile) -> Dict[str, str]:\n    old_name = stream.name\n    stream.name = new_name\n    stream.save(update_fields=[\"name\"])\n\n    RealmAuditLog.objects.create(\n        realm=stream.realm,\n        acting_user=user_profile,\n        modified_stream=stream,\n        event_type=RealmAuditLog.STREAM_NAME_CHANGED,\n        event_time=timezone_now(),\n        extra_data=orjson.dumps(\n            {\n                RealmAuditLog.OLD_VALUE: old_name,\n                RealmAuditLog.NEW_VALUE: new_name,\n            }\n        ).decode(),\n    )\n\n    recipient_id = stream.recipient_id\n    messages = Message.objects.filter(recipient_id=recipient_id).only(\"id\")\n\n    # Update the display recipient and stream, which are easy single\n    # items to set.\n    old_cache_key = get_stream_cache_key(old_name, stream.realm_id)\n    new_cache_key = get_stream_cache_key(stream.name, stream.realm_id)\n    if old_cache_key != new_cache_key:\n        cache_delete(old_cache_key)\n        cache_set(new_cache_key, stream)\n    cache_set(display_recipient_cache_key(recipient_id), stream.name)\n\n    # Delete cache entries for everything else, which is cheaper and\n    # clearer than trying to set them. display_recipient is the out of\n    # date field in all cases.\n    cache_delete_many(to_dict_cache_key_id(message.id) for message in messages)\n    new_email = encode_email_address(stream, show_sender=True)\n\n    # We will tell our users to essentially\n    # update stream.name = new_name where name = old_name\n    # and update stream.email = new_email where name = old_name.\n    # We could optimize this by trying to send one message, but the\n    # client code really wants one property update at a time, and\n    # updating stream names is a pretty infrequent operation.\n    # More importantly, we want to key these updates by id, not name,\n    # since id is the immutable primary key, and obviously name is not.\n    data_updates = [\n        [\"email_address\", new_email],\n        [\"name\", new_name],\n    ]\n    for property, value in data_updates:\n        event = dict(\n            op=\"update\",\n            type=\"stream\",\n            property=property,\n            value=value,\n            stream_id=stream.id,\n            name=old_name,\n        )\n        send_event(stream.realm, event, can_access_stream_user_ids(stream))\n    sender = get_system_bot(settings.NOTIFICATION_BOT, stream.realm_id)\n    with override_language(stream.realm.default_language):\n        internal_send_stream_message(\n            sender,\n            stream,\n            Realm.STREAM_EVENTS_NOTIFICATION_TOPIC,\n            _(\"{user_name} renamed stream {old_stream_name} to {new_stream_name}.\").format(\n                user_name=silent_mention_syntax_for_user(user_profile),\n                old_stream_name=f\"**{old_name}**\",\n                new_stream_name=f\"**{new_name}**\",\n            ),\n        )\n    # Even though the token doesn't change, the web client needs to update the\n    # email forwarding address to display the correctly-escaped new name.\n    return {\"email_address\": new_email}\n\n\ndef send_change_stream_description_notification(\n    stream: Stream, *, old_description: str, new_description: str, acting_user: UserProfile\n) -> None:\n    sender = get_system_bot(settings.NOTIFICATION_BOT, acting_user.realm_id)\n    user_mention = silent_mention_syntax_for_user(acting_user)\n\n    with override_language(stream.realm.default_language):\n        notification_string = (\n            _(\"{user} changed the description for this stream.\").format(user=user_mention)\n            + \"\\n\\n* **\"\n            + _(\"Old description\")\n            + \":**\"\n            + f\"\\n```` quote\\n{old_description}\\n````\\n\"\n            + \"* **\"\n            + _(\"New description\")\n            + \":**\"\n            + f\"\\n```` quote\\n{new_description}\\n````\"\n        )\n\n        internal_send_stream_message(\n            sender, stream, Realm.STREAM_EVENTS_NOTIFICATION_TOPIC, notification_string\n        )\n\n\ndef do_change_stream_description(\n    stream: Stream, new_description: str, *, acting_user: UserProfile\n) -> None:\n    old_description = stream.description\n\n    with transaction.atomic():\n        stream.description = new_description\n        stream.rendered_description = render_stream_description(new_description)\n        stream.save(update_fields=[\"description\", \"rendered_description\"])\n        RealmAuditLog.objects.create(\n            realm=stream.realm,\n            acting_user=acting_user,\n            modified_stream=stream,\n            event_type=RealmAuditLog.STREAM_PROPERTY_CHANGED,\n            event_time=timezone_now(),\n            extra_data=orjson.dumps(\n                {\n                    RealmAuditLog.OLD_VALUE: old_description,\n                    RealmAuditLog.NEW_VALUE: new_description,\n                    \"property\": \"description\",\n                }\n            ).decode(),\n        )\n\n    event = dict(\n        type=\"stream\",\n        op=\"update\",\n        property=\"description\",\n        name=stream.name,\n        stream_id=stream.id,\n        value=new_description,\n        rendered_description=stream.rendered_description,\n    )\n    send_event(stream.realm, event, can_access_stream_user_ids(stream))\n\n    send_change_stream_description_notification(\n        stream,\n        old_description=old_description,\n        new_description=new_description,\n        acting_user=acting_user,\n    )\n\n\ndef send_change_stream_message_retention_days_notification(\n    user_profile: UserProfile, stream: Stream, old_value: Optional[int], new_value: Optional[int]\n) -> None:\n    sender = get_system_bot(settings.NOTIFICATION_BOT, user_profile.realm_id)\n    user_mention = silent_mention_syntax_for_user(user_profile)\n\n    # If switching from or to the organization's default retention policy,\n    # we want to take the realm's default into account.\n    if old_value is None:\n        old_value = stream.realm.message_retention_days\n    if new_value is None:\n        new_value = stream.realm.message_retention_days\n\n    with override_language(stream.realm.default_language):\n        if old_value == Stream.MESSAGE_RETENTION_SPECIAL_VALUES_MAP[\"unlimited\"]:\n            old_retention_period = _(\"Forever\")\n            new_retention_period = f\"{new_value} days\"\n            summary_line = f\"Messages in this stream will now be automatically deleted {new_value} days after they are sent.\"\n        elif new_value == Stream.MESSAGE_RETENTION_SPECIAL_VALUES_MAP[\"unlimited\"]:\n            old_retention_period = f\"{old_value} days\"\n            new_retention_period = _(\"Forever\")\n            summary_line = _(\"Messages in this stream will now be retained forever.\")\n        else:\n            old_retention_period = f\"{old_value} days\"\n            new_retention_period = f\"{new_value} days\"\n            summary_line = f\"Messages in this stream will now be automatically deleted {new_value} days after they are sent.\"\n        notification_string = _(\n            \"{user} has changed the [message retention period](/help/message-retention-policy) for this stream:\\n\"\n            \"* **Old retention period**: {old_retention_period}\\n\"\n            \"* **New retention period**: {new_retention_period}\\n\\n\"\n            \"{summary_line}\"\n        )\n        notification_string = notification_string.format(\n            user=user_mention,\n            old_retention_period=old_retention_period,\n            new_retention_period=new_retention_period,\n            summary_line=summary_line,\n        )\n        internal_send_stream_message(\n            sender, stream, Realm.STREAM_EVENTS_NOTIFICATION_TOPIC, notification_string\n        )\n\n\ndef do_change_stream_message_retention_days(\n    stream: Stream, acting_user: UserProfile, message_retention_days: Optional[int] = None\n) -> None:\n    old_message_retention_days_value = stream.message_retention_days\n\n    with transaction.atomic():\n        stream.message_retention_days = message_retention_days\n        stream.save(update_fields=[\"message_retention_days\"])\n        RealmAuditLog.objects.create(\n            realm=stream.realm,\n            acting_user=acting_user,\n            modified_stream=stream,\n            event_type=RealmAuditLog.STREAM_MESSAGE_RETENTION_DAYS_CHANGED,\n            event_time=timezone_now(),\n            extra_data=orjson.dumps(\n                {\n                    RealmAuditLog.OLD_VALUE: old_message_retention_days_value,\n                    RealmAuditLog.NEW_VALUE: message_retention_days,\n                }\n            ).decode(),\n        )\n\n    event = dict(\n        op=\"update\",\n        type=\"stream\",\n        property=\"message_retention_days\",\n        value=message_retention_days,\n        stream_id=stream.id,\n        name=stream.name,\n    )\n    send_event(stream.realm, event, can_access_stream_user_ids(stream))\n    send_change_stream_message_retention_days_notification(\n        user_profile=acting_user,\n        stream=stream,\n        old_value=old_message_retention_days_value,\n        new_value=message_retention_days,\n    )\n\n\ndef set_realm_permissions_based_on_org_type(realm: Realm) -> None:\n    \"\"\"This function implements overrides for the default configuration\n    for new organizations when the administrator selected specific\n    organization types.\n\n    This substantially simplifies our /help/ advice for folks setting\n    up new organizations of these types.\n    \"\"\"\n\n    # Custom configuration for educational organizations.  The present\n    # defaults are designed for a single class, not a department or\n    # larger institution, since those are more common.\n    if (\n        realm.org_type == Realm.ORG_TYPES[\"education_nonprofit\"][\"id\"]\n        or realm.org_type == Realm.ORG_TYPES[\"education\"][\"id\"]\n    ):\n        # Limit email address visibility and user creation to administrators.\n        realm.email_address_visibility = Realm.EMAIL_ADDRESS_VISIBILITY_ADMINS\n        realm.invite_to_realm_policy = Realm.POLICY_ADMINS_ONLY\n        # Restrict public stream creation to staff, but allow private\n        # streams (useful for study groups, etc.).\n        realm.create_public_stream_policy = Realm.POLICY_ADMINS_ONLY\n        # Don't allow members (students) to manage user groups or\n        # stream subscriptions.\n        realm.user_group_edit_policy = Realm.POLICY_MODERATORS_ONLY\n        realm.invite_to_stream_policy = Realm.POLICY_MODERATORS_ONLY\n        # Allow moderators (TAs?) to move topics between streams.\n        realm.move_messages_between_streams_policy = Realm.POLICY_MODERATORS_ONLY\n\n\ndef do_create_realm(\n    string_id: str,\n    name: str,\n    *,\n    emails_restricted_to_domains: Optional[bool] = None,\n    email_address_visibility: Optional[int] = None,\n    description: Optional[str] = None,\n    invite_required: Optional[bool] = None,\n    plan_type: Optional[int] = None,\n    org_type: Optional[int] = None,\n    date_created: Optional[datetime.datetime] = None,\n    is_demo_organization: Optional[bool] = False,\n    enable_spectator_access: Optional[bool] = False,\n) -> Realm:\n    if string_id == settings.SOCIAL_AUTH_SUBDOMAIN:\n        raise AssertionError(\"Creating a realm on SOCIAL_AUTH_SUBDOMAIN is not allowed!\")\n    if Realm.objects.filter(string_id=string_id).exists():\n        raise AssertionError(f\"Realm {string_id} already exists!\")\n    if not server_initialized():\n        logging.info(\"Server not yet initialized. Creating the internal realm first.\")\n        create_internal_realm()\n\n    kwargs: Dict[str, Any] = {}\n    if emails_restricted_to_domains is not None:\n        kwargs[\"emails_restricted_to_domains\"] = emails_restricted_to_domains\n    if email_address_visibility is not None:\n        kwargs[\"email_address_visibility\"] = email_address_visibility\n    if description is not None:\n        kwargs[\"description\"] = description\n    if invite_required is not None:\n        kwargs[\"invite_required\"] = invite_required\n    if plan_type is not None:\n        kwargs[\"plan_type\"] = plan_type\n    if org_type is not None:\n        kwargs[\"org_type\"] = org_type\n    if enable_spectator_access is not None:\n        kwargs[\"enable_spectator_access\"] = enable_spectator_access\n\n    if date_created is not None:\n        # The date_created parameter is intended only for use by test\n        # suites that want to backdate the date of a realm's creation.\n        assert not settings.PRODUCTION\n        kwargs[\"date_created\"] = date_created\n\n    with transaction.atomic():\n        realm = Realm(string_id=string_id, name=name, **kwargs)\n        if is_demo_organization:\n            realm.demo_organization_scheduled_deletion_date = (\n                realm.date_created + datetime.timedelta(days=settings.DEMO_ORG_DEADLINE_DAYS)\n            )\n\n        set_realm_permissions_based_on_org_type(realm)\n        realm.save()\n\n        RealmAuditLog.objects.create(\n            realm=realm, event_type=RealmAuditLog.REALM_CREATED, event_time=realm.date_created\n        )\n\n        RealmUserDefault.objects.create(realm=realm)\n\n        create_system_user_groups_for_realm(realm)\n\n    # Create stream once Realm object has been saved\n    notifications_stream = ensure_stream(\n        realm,\n        Realm.DEFAULT_NOTIFICATION_STREAM_NAME,\n        stream_description=\"Everyone is added to this stream by default. Welcome! :octopus:\",\n        acting_user=None,\n    )\n    realm.notifications_stream = notifications_stream\n\n    # With the current initial streams situation, the only public\n    # stream is the notifications_stream.\n    DefaultStream.objects.create(stream=notifications_stream, realm=realm)\n\n    signup_notifications_stream = ensure_stream(\n        realm,\n        Realm.INITIAL_PRIVATE_STREAM_NAME,\n        invite_only=True,\n        stream_description=\"A private stream for core team members.\",\n        acting_user=None,\n    )\n    realm.signup_notifications_stream = signup_notifications_stream\n\n    realm.save(update_fields=[\"notifications_stream\", \"signup_notifications_stream\"])\n\n    if plan_type is None and settings.BILLING_ENABLED:\n        do_change_realm_plan_type(realm, Realm.PLAN_TYPE_LIMITED, acting_user=None)\n\n    admin_realm = get_realm(settings.SYSTEM_BOT_REALM)\n    sender = get_system_bot(settings.NOTIFICATION_BOT, admin_realm.id)\n    # Send a notification to the admin realm\n    signup_message = _(\"Signups enabled\")\n\n    try:\n        signups_stream = get_signups_stream(admin_realm)\n        topic = realm.display_subdomain\n\n        internal_send_stream_message(\n            sender,\n            signups_stream,\n            topic,\n            signup_message,\n        )\n    except Stream.DoesNotExist:  # nocoverage\n        # If the signups stream hasn't been created in the admin\n        # realm, don't auto-create it to send to it; just do nothing.\n        pass\n    return realm\n\n\ndef update_scheduled_email_notifications_time(\n    user_profile: UserProfile, old_batching_period: int, new_batching_period: int\n) -> None:\n    existing_scheduled_emails = ScheduledMessageNotificationEmail.objects.filter(\n        user_profile=user_profile\n    )\n\n    scheduled_timestamp_change = datetime.timedelta(\n        seconds=new_batching_period\n    ) - datetime.timedelta(seconds=old_batching_period)\n\n    existing_scheduled_emails.update(\n        scheduled_timestamp=F(\"scheduled_timestamp\") + scheduled_timestamp_change\n    )\n\n\n@transaction.atomic(durable=True)\ndef do_change_user_setting(\n    user_profile: UserProfile,\n    setting_name: str,\n    setting_value: Union[bool, str, int],\n    *,\n    acting_user: Optional[UserProfile],\n) -> None:\n    old_value = getattr(user_profile, setting_name)\n    event_time = timezone_now()\n\n    if setting_name == \"timezone\":\n        assert isinstance(setting_value, str)\n        setting_value = canonicalize_timezone(setting_value)\n    else:\n        property_type = UserProfile.property_types[setting_name]\n        assert isinstance(setting_value, property_type)\n    setattr(user_profile, setting_name, setting_value)\n\n    # TODO: Move these database actions into a transaction.atomic block.\n    user_profile.save(update_fields=[setting_name])\n\n    if setting_name in UserProfile.notification_setting_types:\n        # Prior to all personal settings being managed by property_types,\n        # these were only created for notification settings.\n        #\n        # TODO: Start creating these for all settings, and do a\n        # backfilled=True migration.\n        RealmAuditLog.objects.create(\n            realm=user_profile.realm,\n            event_type=RealmAuditLog.USER_SETTING_CHANGED,\n            event_time=event_time,\n            acting_user=acting_user,\n            modified_user=user_profile,\n            extra_data=orjson.dumps(\n                {\n                    RealmAuditLog.OLD_VALUE: old_value,\n                    RealmAuditLog.NEW_VALUE: setting_value,\n                    \"property\": setting_name,\n                }\n            ).decode(),\n        )\n    # Disabling digest emails should clear a user's email queue\n    if setting_name == \"enable_digest_emails\" and not setting_value:\n        clear_scheduled_emails(user_profile.id, ScheduledEmail.DIGEST)\n\n    if setting_name == \"email_notifications_batching_period_seconds\":\n        assert isinstance(old_value, int)\n        assert isinstance(setting_value, int)\n        update_scheduled_email_notifications_time(user_profile, old_value, setting_value)\n\n    event = {\n        \"type\": \"user_settings\",\n        \"op\": \"update\",\n        \"property\": setting_name,\n        \"value\": setting_value,\n    }\n    if setting_name == \"default_language\":\n        assert isinstance(setting_value, str)\n        event[\"language_name\"] = get_language_name(setting_value)\n\n    transaction.on_commit(lambda: send_event(user_profile.realm, event, [user_profile.id]))\n\n    if setting_name in UserProfile.notification_settings_legacy:\n        # This legacy event format is for backwards-compatibility with\n        # clients that don't support the new user_settings event type.\n        # We only send this for settings added before Feature level 89.\n        legacy_event = {\n            \"type\": \"update_global_notifications\",\n            \"user\": user_profile.email,\n            \"notification_name\": setting_name,\n            \"setting\": setting_value,\n        }\n        transaction.on_commit(\n            lambda: send_event(user_profile.realm, legacy_event, [user_profile.id])\n        )\n\n    if setting_name in UserProfile.display_settings_legacy or setting_name == \"timezone\":\n        # This legacy event format is for backwards-compatibility with\n        # clients that don't support the new user_settings event type.\n        # We only send this for settings added before Feature level 89.\n        legacy_event = {\n            \"type\": \"update_display_settings\",\n            \"user\": user_profile.email,\n            \"setting_name\": setting_name,\n            \"setting\": setting_value,\n        }\n        if setting_name == \"default_language\":\n            assert isinstance(setting_value, str)\n            legacy_event[\"language_name\"] = get_language_name(setting_value)\n\n        transaction.on_commit(\n            lambda: send_event(user_profile.realm, legacy_event, [user_profile.id])\n        )\n\n    # Updates to the time zone display setting are sent to all users\n    if setting_name == \"timezone\":\n        payload = dict(\n            email=user_profile.email,\n            user_id=user_profile.id,\n            timezone=canonicalize_timezone(user_profile.timezone),\n        )\n        timezone_event = dict(type=\"realm_user\", op=\"update\", person=payload)\n        transaction.on_commit(\n            lambda: send_event(\n                user_profile.realm,\n                timezone_event,\n                active_user_ids(user_profile.realm_id),\n            )\n        )\n\n    if setting_name == \"enable_drafts_synchronization\" and setting_value is False:\n        # Delete all of the drafts from the backend but don't send delete events\n        # for them since all that's happened is that we stopped syncing changes,\n        # not deleted every previously synced draft - to do that use the DELETE\n        # endpoint.\n        Draft.objects.filter(user_profile=user_profile).delete()\n\n\ndef lookup_default_stream_groups(\n    default_stream_group_names: List[str], realm: Realm\n) -> List[DefaultStreamGroup]:\n    default_stream_groups = []\n    for group_name in default_stream_group_names:\n        try:\n            default_stream_group = DefaultStreamGroup.objects.get(name=group_name, realm=realm)\n        except DefaultStreamGroup.DoesNotExist:\n            raise JsonableError(_(\"Invalid default stream group {}\").format(group_name))\n        default_stream_groups.append(default_stream_group)\n    return default_stream_groups\n\n\ndef notify_default_streams(realm: Realm) -> None:\n    event = dict(\n        type=\"default_streams\",\n        default_streams=streams_to_dicts_sorted(get_default_streams_for_realm(realm.id)),\n    )\n    transaction.on_commit(lambda: send_event(realm, event, active_non_guest_user_ids(realm.id)))\n\n\ndef notify_default_stream_groups(realm: Realm) -> None:\n    event = dict(\n        type=\"default_stream_groups\",\n        default_stream_groups=default_stream_groups_to_dicts_sorted(\n            get_default_stream_groups(realm)\n        ),\n    )\n    transaction.on_commit(lambda: send_event(realm, event, active_non_guest_user_ids(realm.id)))\n\n\ndef do_add_default_stream(stream: Stream) -> None:\n    realm_id = stream.realm_id\n    stream_id = stream.id\n    if not DefaultStream.objects.filter(realm_id=realm_id, stream_id=stream_id).exists():\n        DefaultStream.objects.create(realm_id=realm_id, stream_id=stream_id)\n        notify_default_streams(stream.realm)\n\n\n@transaction.atomic(savepoint=False)\ndef do_remove_default_stream(stream: Stream) -> None:\n    realm_id = stream.realm_id\n    stream_id = stream.id\n    DefaultStream.objects.filter(realm_id=realm_id, stream_id=stream_id).delete()\n    notify_default_streams(stream.realm)\n\n\ndef do_create_default_stream_group(\n    realm: Realm, group_name: str, description: str, streams: List[Stream]\n) -> None:\n    default_streams = get_default_streams_for_realm(realm.id)\n    for stream in streams:\n        if stream in default_streams:\n            raise JsonableError(\n                _(\n                    \"'{stream_name}' is a default stream and cannot be added to '{group_name}'\",\n                ).format(stream_name=stream.name, group_name=group_name)\n            )\n\n    check_default_stream_group_name(group_name)\n    (group, created) = DefaultStreamGroup.objects.get_or_create(\n        name=group_name, realm=realm, description=description\n    )\n    if not created:\n        raise JsonableError(\n            _(\n                \"Default stream group '{group_name}' already exists\",\n            ).format(group_name=group_name)\n        )\n\n    group.streams.set(streams)\n    notify_default_stream_groups(realm)\n\n\ndef do_add_streams_to_default_stream_group(\n    realm: Realm, group: DefaultStreamGroup, streams: List[Stream]\n) -> None:\n    default_streams = get_default_streams_for_realm(realm.id)\n    for stream in streams:\n        if stream in default_streams:\n            raise JsonableError(\n                _(\n                    \"'{stream_name}' is a default stream and cannot be added to '{group_name}'\",\n                ).format(stream_name=stream.name, group_name=group.name)\n            )\n        if stream in group.streams.all():\n            raise JsonableError(\n                _(\n                    \"Stream '{stream_name}' is already present in default stream group '{group_name}'\",\n                ).format(stream_name=stream.name, group_name=group.name)\n            )\n        group.streams.add(stream)\n\n    group.save()\n    notify_default_stream_groups(realm)\n\n\ndef do_remove_streams_from_default_stream_group(\n    realm: Realm, group: DefaultStreamGroup, streams: List[Stream]\n) -> None:\n    for stream in streams:\n        if stream not in group.streams.all():\n            raise JsonableError(\n                _(\n                    \"Stream '{stream_name}' is not present in default stream group '{group_name}'\",\n                ).format(stream_name=stream.name, group_name=group.name)\n            )\n        group.streams.remove(stream)\n\n    group.save()\n    notify_default_stream_groups(realm)\n\n\ndef do_change_default_stream_group_name(\n    realm: Realm, group: DefaultStreamGroup, new_group_name: str\n) -> None:\n    if group.name == new_group_name:\n        raise JsonableError(\n            _(\"This default stream group is already named '{}'\").format(new_group_name)\n        )\n\n    if DefaultStreamGroup.objects.filter(name=new_group_name, realm=realm).exists():\n        raise JsonableError(_(\"Default stream group '{}' already exists\").format(new_group_name))\n\n    group.name = new_group_name\n    group.save()\n    notify_default_stream_groups(realm)\n\n\ndef do_change_default_stream_group_description(\n    realm: Realm, group: DefaultStreamGroup, new_description: str\n) -> None:\n    group.description = new_description\n    group.save()\n    notify_default_stream_groups(realm)\n\n\ndef do_remove_default_stream_group(realm: Realm, group: DefaultStreamGroup) -> None:\n    group.delete()\n    notify_default_stream_groups(realm)\n\n\ndef get_default_streams_for_realm(realm_id: int) -> List[Stream]:\n    return [\n        default.stream\n        for default in DefaultStream.objects.select_related().filter(realm_id=realm_id)\n    ]\n\n\ndef get_default_subs(user_profile: UserProfile) -> List[Stream]:\n    # Right now default streams are realm-wide.  This wrapper gives us flexibility\n    # to some day further customize how we set up default streams for new users.\n    return get_default_streams_for_realm(user_profile.realm_id)\n\n\n# returns default streams in JSON serializable format\ndef streams_to_dicts_sorted(streams: List[Stream]) -> List[Dict[str, Any]]:\n    return sorted((stream.to_dict() for stream in streams), key=lambda elt: elt[\"name\"])\n\n\ndef default_stream_groups_to_dicts_sorted(groups: List[DefaultStreamGroup]) -> List[Dict[str, Any]]:\n    return sorted((group.to_dict() for group in groups), key=lambda elt: elt[\"name\"])\n\n\ndef do_update_user_activity_interval(\n    user_profile: UserProfile, log_time: datetime.datetime\n) -> None:\n    effective_end = log_time + UserActivityInterval.MIN_INTERVAL_LENGTH\n    # This code isn't perfect, because with various races we might end\n    # up creating two overlapping intervals, but that shouldn't happen\n    # often, and can be corrected for in post-processing\n    try:\n        last = UserActivityInterval.objects.filter(user_profile=user_profile).order_by(\"-end\")[0]\n        # Two intervals overlap iff each interval ends after the other\n        # begins.  In this case, we just extend the old interval to\n        # include the new interval.\n        if log_time <= last.end and effective_end >= last.start:\n            last.end = max(last.end, effective_end)\n            last.start = min(last.start, log_time)\n            last.save(update_fields=[\"start\", \"end\"])\n            return\n    except IndexError:\n        pass\n\n    # Otherwise, the intervals don't overlap, so we should make a new one\n    UserActivityInterval.objects.create(\n        user_profile=user_profile, start=log_time, end=effective_end\n    )\n\n\n@statsd_increment(\"user_activity\")\ndef do_update_user_activity(\n    user_profile_id: int, client_id: int, query: str, count: int, log_time: datetime.datetime\n) -> None:\n    (activity, created) = UserActivity.objects.get_or_create(\n        user_profile_id=user_profile_id,\n        client_id=client_id,\n        query=query,\n        defaults={\"last_visit\": log_time, \"count\": count},\n    )\n\n    if not created:\n        activity.count += count\n        activity.last_visit = log_time\n        activity.save(update_fields=[\"last_visit\", \"count\"])\n\n\ndef send_presence_changed(user_profile: UserProfile, presence: UserPresence) -> None:\n    # Most presence data is sent to clients in the main presence\n    # endpoint in response to the user's own presence; this results\n    # data that is 1-2 minutes stale for who is online.  The flaw with\n    # this plan is when a user comes back online and then immediately\n    # sends a message, recipients may still see that user as offline!\n    # We solve that by sending an immediate presence update clients.\n    #\n    # See https://zulip.readthedocs.io/en/latest/subsystems/presence.html for\n    # internals documentation on presence.\n    user_ids = active_user_ids(user_profile.realm_id)\n    if len(user_ids) > settings.USER_LIMIT_FOR_SENDING_PRESENCE_UPDATE_EVENTS:\n        # These immediate presence generate quadratic work for Tornado\n        # (linear number of users in each event and the frequency of\n        # users coming online grows linearly with userbase too).  In\n        # organizations with thousands of users, this can overload\n        # Tornado, especially if much of the realm comes online at the\n        # same time.\n        #\n        # The utility of these live-presence updates goes down as\n        # organizations get bigger (since one is much less likely to\n        # be paying attention to the sidebar); so beyond a limit, we\n        # stop sending them at all.\n        return\n\n    presence_dict = presence.to_dict()\n    event = dict(\n        type=\"presence\",\n        email=user_profile.email,\n        user_id=user_profile.id,\n        server_timestamp=time.time(),\n        presence={presence_dict[\"client\"]: presence_dict},\n    )\n    send_event(user_profile.realm, event, user_ids)\n\n\ndef consolidate_client(client: Client) -> Client:\n    # The web app reports a client as 'website'\n    # The desktop app reports a client as ZulipDesktop\n    # due to it setting a custom user agent. We want both\n    # to count as web users\n\n    # Alias ZulipDesktop to website\n    if client.name in [\"ZulipDesktop\"]:\n        return get_client(\"website\")\n    else:\n        return client\n\n\n@statsd_increment(\"user_presence\")\ndef do_update_user_presence(\n    user_profile: UserProfile, client: Client, log_time: datetime.datetime, status: int\n) -> None:\n    client = consolidate_client(client)\n\n    defaults = dict(\n        timestamp=log_time,\n        status=status,\n        realm_id=user_profile.realm_id,\n    )\n\n    (presence, created) = UserPresence.objects.get_or_create(\n        user_profile=user_profile,\n        client=client,\n        defaults=defaults,\n    )\n\n    stale_status = (log_time - presence.timestamp) > datetime.timedelta(minutes=1, seconds=10)\n    was_idle = presence.status == UserPresence.IDLE\n    became_online = (status == UserPresence.ACTIVE) and (stale_status or was_idle)\n\n    # If an object was created, it has already been saved.\n    #\n    # We suppress changes from ACTIVE to IDLE before stale_status is reached;\n    # this protects us from the user having two clients open: one active, the\n    # other idle. Without this check, we would constantly toggle their status\n    # between the two states.\n    if not created and stale_status or was_idle or status == presence.status:\n        # The following block attempts to only update the \"status\"\n        # field in the event that it actually changed.  This is\n        # important to avoid flushing the UserPresence cache when the\n        # data it would return to a client hasn't actually changed\n        # (see the UserPresence post_save hook for details).\n        presence.timestamp = log_time\n        update_fields = [\"timestamp\"]\n        if presence.status != status:\n            presence.status = status\n            update_fields.append(\"status\")\n        presence.save(update_fields=update_fields)\n\n    if not user_profile.realm.presence_disabled and (created or became_online):\n        send_presence_changed(user_profile, presence)\n\n\ndef update_user_activity_interval(user_profile: UserProfile, log_time: datetime.datetime) -> None:\n    event = {\"user_profile_id\": user_profile.id, \"time\": datetime_to_timestamp(log_time)}\n    queue_json_publish(\"user_activity_interval\", event)\n\n\ndef update_user_presence(\n    user_profile: UserProfile,\n    client: Client,\n    log_time: datetime.datetime,\n    status: int,\n    new_user_input: bool,\n) -> None:\n    event = {\n        \"user_profile_id\": user_profile.id,\n        \"status\": status,\n        \"time\": datetime_to_timestamp(log_time),\n        \"client\": client.name,\n    }\n\n    queue_json_publish(\"user_presence\", event)\n\n    if new_user_input:\n        update_user_activity_interval(user_profile, log_time)\n\n\ndef do_update_user_status(\n    user_profile: UserProfile,\n    away: Optional[bool],\n    status_text: Optional[str],\n    client_id: int,\n    emoji_name: Optional[str],\n    emoji_code: Optional[str],\n    reaction_type: Optional[str],\n) -> None:\n    if away is None:\n        status = None\n    elif away:\n        status = UserStatus.AWAY\n    else:\n        status = UserStatus.NORMAL\n\n    realm = user_profile.realm\n\n    update_user_status(\n        user_profile_id=user_profile.id,\n        status=status,\n        status_text=status_text,\n        client_id=client_id,\n        emoji_name=emoji_name,\n        emoji_code=emoji_code,\n        reaction_type=reaction_type,\n    )\n\n    event = dict(\n        type=\"user_status\",\n        user_id=user_profile.id,\n    )\n\n    if away is not None:\n        event[\"away\"] = away\n\n    if status_text is not None:\n        event[\"status_text\"] = status_text\n\n    if emoji_name is not None:\n        event[\"emoji_name\"] = emoji_name\n        event[\"emoji_code\"] = emoji_code\n        event[\"reaction_type\"] = reaction_type\n    send_event(realm, event, active_user_ids(realm.id))\n\n\n@dataclass\nclass ReadMessagesEvent:\n    messages: List[int]\n    all: bool\n    type: str = field(default=\"update_message_flags\", init=False)\n    op: str = field(default=\"add\", init=False)\n    operation: str = field(default=\"add\", init=False)\n    flag: str = field(default=\"read\", init=False)\n\n\ndef do_mark_all_as_read(user_profile: UserProfile) -> int:\n    log_statsd_event(\"bankruptcy\")\n\n    # First, we clear mobile push notifications.  This is safer in the\n    # event that the below logic times out and we're killed.\n    all_push_message_ids = (\n        UserMessage.objects.filter(\n            user_profile=user_profile,\n        )\n        .extra(\n            where=[UserMessage.where_active_push_notification()],\n        )\n        .values_list(\"message_id\", flat=True)[0:10000]\n    )\n    do_clear_mobile_push_notifications_for_ids([user_profile.id], all_push_message_ids)\n\n    msgs = UserMessage.objects.filter(user_profile=user_profile).extra(\n        where=[UserMessage.where_unread()],\n    )\n\n    count = msgs.update(\n        flags=F(\"flags\").bitor(UserMessage.flags.read),\n    )\n\n    event = asdict(\n        ReadMessagesEvent(\n            messages=[],  # we don't send messages, since the client reloads anyway\n            all=True,\n        )\n    )\n    event_time = timezone_now()\n\n    send_event(user_profile.realm, event, [user_profile.id])\n\n    do_increment_logging_stat(\n        user_profile, COUNT_STATS[\"messages_read::hour\"], None, event_time, increment=count\n    )\n    do_increment_logging_stat(\n        user_profile,\n        COUNT_STATS[\"messages_read_interactions::hour\"],\n        None,\n        event_time,\n        increment=min(1, count),\n    )\n\n    return count\n\n\ndef do_mark_stream_messages_as_read(\n    user_profile: UserProfile, stream_recipient_id: int, topic_name: Optional[str] = None\n) -> int:\n    log_statsd_event(\"mark_stream_as_read\")\n\n    msgs = UserMessage.objects.filter(\n        user_profile=user_profile,\n    )\n\n    msgs = msgs.filter(message__recipient_id=stream_recipient_id)\n\n    if topic_name:\n        msgs = filter_by_topic_name_via_message(\n            query=msgs,\n            topic_name=topic_name,\n        )\n\n    msgs = msgs.extra(\n        where=[UserMessage.where_unread()],\n    )\n\n    message_ids = list(msgs.values_list(\"message_id\", flat=True))\n\n    count = msgs.update(\n        flags=F(\"flags\").bitor(UserMessage.flags.read),\n    )\n\n    event = asdict(\n        ReadMessagesEvent(\n            messages=message_ids,\n            all=False,\n        )\n    )\n    event_time = timezone_now()\n\n    send_event(user_profile.realm, event, [user_profile.id])\n    do_clear_mobile_push_notifications_for_ids([user_profile.id], message_ids)\n\n    do_increment_logging_stat(\n        user_profile, COUNT_STATS[\"messages_read::hour\"], None, event_time, increment=count\n    )\n    do_increment_logging_stat(\n        user_profile,\n        COUNT_STATS[\"messages_read_interactions::hour\"],\n        None,\n        event_time,\n        increment=min(1, count),\n    )\n    return count\n\n\ndef do_mark_muted_user_messages_as_read(\n    user_profile: UserProfile,\n    muted_user: UserProfile,\n) -> int:\n    messages = UserMessage.objects.filter(\n        user_profile=user_profile, message__sender=muted_user\n    ).extra(where=[UserMessage.where_unread()])\n\n    message_ids = list(messages.values_list(\"message_id\", flat=True))\n\n    count = messages.update(\n        flags=F(\"flags\").bitor(UserMessage.flags.read),\n    )\n\n    event = asdict(\n        ReadMessagesEvent(\n            messages=message_ids,\n            all=False,\n        )\n    )\n    event_time = timezone_now()\n\n    send_event(user_profile.realm, event, [user_profile.id])\n    do_clear_mobile_push_notifications_for_ids([user_profile.id], message_ids)\n\n    do_increment_logging_stat(\n        user_profile, COUNT_STATS[\"messages_read::hour\"], None, event_time, increment=count\n    )\n    do_increment_logging_stat(\n        user_profile,\n        COUNT_STATS[\"messages_read_interactions::hour\"],\n        None,\n        event_time,\n        increment=min(1, count),\n    )\n    return count\n\n\ndef do_update_mobile_push_notification(\n    message: Message,\n    prior_mention_user_ids: Set[int],\n    mentions_user_ids: Set[int],\n    stream_push_user_ids: Set[int],\n) -> None:\n    # Called during the message edit code path to remove mobile push\n    # notifications for users who are no longer mentioned following\n    # the edit.  See #15428 for details.\n    #\n    # A perfect implementation would also support updating the message\n    # in a sent notification if a message was edited to mention a\n    # group rather than a user (or vice versa), though it is likely\n    # not worth the effort to do such a change.\n    if not message.is_stream_message():\n        return\n\n    remove_notify_users = prior_mention_user_ids - mentions_user_ids - stream_push_user_ids\n    do_clear_mobile_push_notifications_for_ids(list(remove_notify_users), [message.id])\n\n\ndef do_clear_mobile_push_notifications_for_ids(\n    user_profile_ids: List[int], message_ids: List[int]\n) -> None:\n    if len(message_ids) == 0:\n        return\n\n    # This function supports clearing notifications for several users\n    # only for the message-edit use case where we'll have a single message_id.\n    assert len(user_profile_ids) == 1 or len(message_ids) == 1\n\n    messages_by_user = defaultdict(list)\n    notifications_to_update = list(\n        UserMessage.objects.filter(\n            message_id__in=message_ids,\n            user_profile_id__in=user_profile_ids,\n        )\n        .extra(\n            where=[UserMessage.where_active_push_notification()],\n        )\n        .values_list(\"user_profile_id\", \"message_id\")\n    )\n\n    for (user_id, message_id) in notifications_to_update:\n        messages_by_user[user_id].append(message_id)\n\n    for (user_profile_id, event_message_ids) in messages_by_user.items():\n        queue_json_publish(\n            \"missedmessage_mobile_notifications\",\n            {\n                \"type\": \"remove\",\n                \"user_profile_id\": user_profile_id,\n                \"message_ids\": event_message_ids,\n            },\n        )\n\n\ndef do_update_message_flags(\n    user_profile: UserProfile, operation: str, flag: str, messages: List[int]\n) -> int:\n    valid_flags = [item for item in UserMessage.flags if item not in UserMessage.NON_API_FLAGS]\n    if flag not in valid_flags:\n        raise JsonableError(_(\"Invalid flag: '{}'\").format(flag))\n    if flag in UserMessage.NON_EDITABLE_FLAGS:\n        raise JsonableError(_(\"Flag not editable: '{}'\").format(flag))\n    if operation not in (\"add\", \"remove\"):\n        raise JsonableError(_(\"Invalid message flag operation: '{}'\").format(operation))\n    flagattr = getattr(UserMessage.flags, flag)\n\n    msgs = UserMessage.objects.filter(user_profile=user_profile, message_id__in=messages)\n    um_message_ids = {um.message_id for um in msgs}\n    historical_message_ids = list(set(messages) - um_message_ids)\n\n    # Users can mutate flags for messages that don't have a UserMessage yet.\n    # First, validate that the user is even allowed to access these message_ids.\n    for message_id in historical_message_ids:\n        access_message(user_profile, message_id)\n\n    # And then create historical UserMessage records.  See the called function for more context.\n    create_historical_user_messages(user_id=user_profile.id, message_ids=historical_message_ids)\n\n    if operation == \"add\":\n        count = msgs.update(flags=F(\"flags\").bitor(flagattr))\n    elif operation == \"remove\":\n        count = msgs.update(flags=F(\"flags\").bitand(~flagattr))\n\n    event = {\n        \"type\": \"update_message_flags\",\n        \"op\": operation,\n        \"operation\": operation,\n        \"flag\": flag,\n        \"messages\": messages,\n        \"all\": False,\n    }\n    send_event(user_profile.realm, event, [user_profile.id])\n\n    if flag == \"read\" and operation == \"add\":\n        event_time = timezone_now()\n        do_clear_mobile_push_notifications_for_ids([user_profile.id], messages)\n\n        do_increment_logging_stat(\n            user_profile, COUNT_STATS[\"messages_read::hour\"], None, event_time, increment=count\n        )\n        do_increment_logging_stat(\n            user_profile,\n            COUNT_STATS[\"messages_read_interactions::hour\"],\n            None,\n            event_time,\n            increment=min(1, count),\n        )\n    return count\n\n\nclass MessageUpdateUserInfoResult(TypedDict):\n    message_user_ids: Set[int]\n    mention_user_ids: Set[int]\n\n\ndef maybe_send_resolve_topic_notifications(\n    *,\n    user_profile: UserProfile,\n    stream: Stream,\n    old_topic: str,\n    new_topic: str,\n    changed_messages: List[Message],\n) -> None:\n    # Note that topics will have already been stripped in check_update_message.\n    #\n    # This logic is designed to treat removing a weird \"\u2714 \u2714\u2714 \"\n    # prefix as unresolving the topic.\n    if old_topic.lstrip(RESOLVED_TOPIC_PREFIX) != new_topic.lstrip(RESOLVED_TOPIC_PREFIX):\n        return\n\n    topic_resolved: bool = new_topic.startswith(RESOLVED_TOPIC_PREFIX) and not old_topic.startswith(\n        RESOLVED_TOPIC_PREFIX\n    )\n    topic_unresolved: bool = old_topic.startswith(\n        RESOLVED_TOPIC_PREFIX\n    ) and not new_topic.startswith(RESOLVED_TOPIC_PREFIX)\n\n    if not topic_resolved and not topic_unresolved:\n        # If there's some other weird topic that does not toggle the\n        # state of \"topic starts with RESOLVED_TOPIC_PREFIX\", we do\n        # nothing. Any other logic could result in cases where we send\n        # these notifications in a non-alternating fashion.\n        #\n        # Note that it is still possible for an individual topic to\n        # have multiple \"This topic was marked as resolved\"\n        # notifications in a row: one can send new messages to the\n        # pre-resolve topic and then resolve the topic created that\n        # way to get multiple in the resolved topic. And then an\n        # administrator can the messages in between. We consider this\n        # to be a fundamental risk of irresponsible message deletion,\n        # not a bug with the \"resolve topics\" feature.\n        return\n\n    # Compute the users who either sent or reacted to messages that\n    # were moved via the \"resolve topic' action. Only those users\n    # should be eligible for this message being managed as unread.\n    affected_participant_ids = (set(message.sender_id for message in changed_messages)) | set(\n        Reaction.objects.filter(message__in=changed_messages).values_list(\n            \"user_profile_id\", flat=True\n        )\n    )\n    sender = get_system_bot(settings.NOTIFICATION_BOT, user_profile.realm_id)\n    user_mention = silent_mention_syntax_for_user(user_profile)\n    with override_language(stream.realm.default_language):\n        if topic_resolved:\n            notification_string = _(\"{user} has marked this topic as resolved.\")\n        elif topic_unresolved:\n            notification_string = _(\"{user} has marked this topic as unresolved.\")\n\n        internal_send_stream_message(\n            sender,\n            stream,\n            new_topic,\n            notification_string.format(\n                user=user_mention,\n            ),\n            limit_unread_user_ids=affected_participant_ids,\n        )\n\n\ndef send_message_moved_breadcrumbs(\n    user_profile: UserProfile,\n    old_stream: Stream,\n    old_topic: str,\n    old_thread_notification_string: Optional[str],\n    new_stream: Stream,\n    new_topic: Optional[str],\n    new_thread_notification_string: Optional[str],\n    changed_messages_count: int,\n) -> None:\n    # Since moving content between streams is highly disruptive,\n    # it's worth adding a couple tombstone messages showing what\n    # happened.\n    sender = get_system_bot(settings.NOTIFICATION_BOT, old_stream.realm_id)\n\n    if new_topic is None:\n        new_topic = old_topic\n\n    user_mention = silent_mention_syntax_for_user(user_profile)\n    old_topic_link = f\"#**{old_stream.name}>{old_topic}**\"\n    new_topic_link = f\"#**{new_stream.name}>{new_topic}**\"\n\n    if new_thread_notification_string is not None:\n        with override_language(new_stream.realm.default_language):\n            internal_send_stream_message(\n                sender,\n                new_stream,\n                new_topic,\n                new_thread_notification_string.format(\n                    old_location=old_topic_link,\n                    user=user_mention,\n                    changed_messages_count=changed_messages_count,\n                ),\n            )\n\n    if old_thread_notification_string is not None:\n        with override_language(old_stream.realm.default_language):\n            # Send a notification to the old stream that the topic was moved.\n            internal_send_stream_message(\n                sender,\n                old_stream,\n                old_topic,\n                old_thread_notification_string.format(\n                    user=user_mention,\n                    new_location=new_topic_link,\n                    changed_messages_count=changed_messages_count,\n                ),\n            )\n\n\ndef get_user_info_for_message_updates(message_id: int) -> MessageUpdateUserInfoResult:\n\n    # We exclude UserMessage.flags.historical rows since those\n    # users did not receive the message originally, and thus\n    # probably are not relevant for reprocessed alert_words,\n    # mentions and similar rendering features.  This may be a\n    # decision we change in the future.\n    query = UserMessage.objects.filter(\n        message=message_id,\n        flags=~UserMessage.flags.historical,\n    ).values(\"user_profile_id\", \"flags\")\n    rows = list(query)\n\n    message_user_ids = {row[\"user_profile_id\"] for row in rows}\n\n    mask = UserMessage.flags.mentioned | UserMessage.flags.wildcard_mentioned\n\n    mention_user_ids = {row[\"user_profile_id\"] for row in rows if int(row[\"flags\"]) & mask}\n\n    return dict(\n        message_user_ids=message_user_ids,\n        mention_user_ids=mention_user_ids,\n    )\n\n\ndef update_user_message_flags(\n    rendering_result: MessageRenderingResult, ums: Iterable[UserMessage]\n) -> None:\n    wildcard = rendering_result.mentions_wildcard\n    mentioned_ids = rendering_result.mentions_user_ids\n    ids_with_alert_words = rendering_result.user_ids_with_alert_words\n    changed_ums: Set[UserMessage] = set()\n\n    def update_flag(um: UserMessage, should_set: bool, flag: int) -> None:\n        if should_set:\n            if not (um.flags & flag):\n                um.flags |= flag\n                changed_ums.add(um)\n        else:\n            if um.flags & flag:\n                um.flags &= ~flag\n                changed_ums.add(um)\n\n    for um in ums:\n        has_alert_word = um.user_profile_id in ids_with_alert_words\n        update_flag(um, has_alert_word, UserMessage.flags.has_alert_word)\n\n        mentioned = um.user_profile_id in mentioned_ids\n        update_flag(um, mentioned, UserMessage.flags.mentioned)\n\n        update_flag(um, wildcard, UserMessage.flags.wildcard_mentioned)\n\n    for um in changed_ums:\n        um.save(update_fields=[\"flags\"])\n\n\ndef update_to_dict_cache(\n    changed_messages: List[Message], realm_id: Optional[int] = None\n) -> List[int]:\n    \"\"\"Updates the message as stored in the to_dict cache (for serving\n    messages).\"\"\"\n    items_for_remote_cache = {}\n    message_ids = []\n    changed_messages_to_dict = MessageDict.to_dict_uncached(changed_messages, realm_id)\n    for msg_id, msg in changed_messages_to_dict.items():\n        message_ids.append(msg_id)\n        key = to_dict_cache_key_id(msg_id)\n        items_for_remote_cache[key] = (msg,)\n\n    cache_set_many(items_for_remote_cache)\n    return message_ids\n\n\ndef do_update_embedded_data(\n    user_profile: UserProfile,\n    message: Message,\n    content: Optional[str],\n    rendering_result: MessageRenderingResult,\n) -> None:\n    timestamp = timezone_now()\n    event: Dict[str, Any] = {\n        \"type\": \"update_message\",\n        \"user_id\": None,\n        \"edit_timestamp\": datetime_to_timestamp(timestamp),\n        \"message_id\": message.id,\n        \"rendering_only\": True,\n    }\n    changed_messages = [message]\n    rendered_content: Optional[str] = None\n\n    ums = UserMessage.objects.filter(message=message.id)\n\n    if content is not None:\n        update_user_message_flags(rendering_result, ums)\n        rendered_content = rendering_result.rendered_content\n        message.rendered_content = rendered_content\n        message.rendered_content_version = markdown_version\n        event[\"content\"] = content\n        event[\"rendered_content\"] = rendered_content\n\n    message.save(update_fields=[\"content\", \"rendered_content\"])\n\n    event[\"message_ids\"] = update_to_dict_cache(changed_messages)\n\n    def user_info(um: UserMessage) -> Dict[str, Any]:\n        return {\n            \"id\": um.user_profile_id,\n            \"flags\": um.flags_list(),\n        }\n\n    send_event(user_profile.realm, event, list(map(user_info, ums)))\n\n\nclass DeleteMessagesEvent(TypedDict, total=False):\n    type: str\n    message_ids: List[int]\n    message_type: str\n    topic: str\n    stream_id: int\n\n\n# We use transaction.atomic to support select_for_update in the attachment codepath.\n@transaction.atomic(savepoint=False)\ndef do_update_message(\n    user_profile: UserProfile,\n    target_message: Message,\n    new_stream: Optional[Stream],\n    topic_name: Optional[str],\n    propagate_mode: str,\n    send_notification_to_old_thread: bool,\n    send_notification_to_new_thread: bool,\n    content: Optional[str],\n    rendering_result: Optional[MessageRenderingResult],\n    prior_mention_user_ids: Set[int],\n    mention_data: Optional[MentionData] = None,\n) -> int:\n    \"\"\"\n    The main function for message editing.  A message edit event can\n    modify:\n    * the message's content (in which case the caller will have\n      set both content and rendered_content),\n    * the topic, in which case the caller will have set topic_name\n    * or both message's content and the topic\n    * or stream and/or topic, in which case the caller will have set\n        new_stream and/or topic_name.\n\n    With topic edits, propagate_mode determines whether other message\n    also have their topics edited.\n    \"\"\"\n    timestamp = timezone_now()\n    target_message.last_edit_time = timestamp\n\n    event: Dict[str, Any] = {\n        \"type\": \"update_message\",\n        \"user_id\": user_profile.id,\n        \"edit_timestamp\": datetime_to_timestamp(timestamp),\n        \"message_id\": target_message.id,\n        \"rendering_only\": False,\n    }\n\n    edit_history_event: EditHistoryEvent = {\n        \"user_id\": user_profile.id,\n        \"timestamp\": event[\"edit_timestamp\"],\n    }\n\n    changed_messages = [target_message]\n\n    realm = user_profile.realm\n\n    stream_being_edited = None\n    if target_message.is_stream_message():\n        stream_id = target_message.recipient.type_id\n        stream_being_edited = get_stream_by_id_in_realm(stream_id, realm)\n        event[\"stream_name\"] = stream_being_edited.name\n        event[\"stream_id\"] = stream_being_edited.id\n\n    ums = UserMessage.objects.filter(message=target_message.id)\n\n    if content is not None:\n        assert rendering_result is not None\n\n        # mention_data is required if there's a content edit.\n        assert mention_data is not None\n\n        # add data from group mentions to mentions_user_ids.\n        for group_id in rendering_result.mentions_user_group_ids:\n            members = mention_data.get_group_members(group_id)\n            rendering_result.mentions_user_ids.update(members)\n\n        update_user_message_flags(rendering_result, ums)\n\n        # One could imagine checking realm.allow_edit_history here and\n        # modifying the events based on that setting, but doing so\n        # doesn't really make sense.  We need to send the edit event\n        # to clients regardless, and a client already had access to\n        # the original/pre-edit content of the message anyway.  That\n        # setting must be enforced on the client side, and making a\n        # change here simply complicates the logic for clients parsing\n        # edit history events.\n        event[\"orig_content\"] = target_message.content\n        event[\"orig_rendered_content\"] = target_message.rendered_content\n        edit_history_event[\"prev_content\"] = target_message.content\n        edit_history_event[\"prev_rendered_content\"] = target_message.rendered_content\n        edit_history_event[\n            \"prev_rendered_content_version\"\n        ] = target_message.rendered_content_version\n        target_message.content = content\n        target_message.rendered_content = rendering_result.rendered_content\n        target_message.rendered_content_version = markdown_version\n        event[\"content\"] = content\n        event[\"rendered_content\"] = rendering_result.rendered_content\n        event[\"prev_rendered_content_version\"] = target_message.rendered_content_version\n        event[\"is_me_message\"] = Message.is_status_message(\n            content, rendering_result.rendered_content\n        )\n\n        # target_message.has_image and target_message.has_link will have been\n        # already updated by Markdown rendering in the caller.\n        target_message.has_attachment = check_attachment_reference_change(\n            target_message, rendering_result\n        )\n\n        if target_message.is_stream_message():\n            if topic_name is not None:\n                new_topic_name = topic_name\n            else:\n                new_topic_name = target_message.topic_name()\n\n            stream_topic: Optional[StreamTopicTarget] = StreamTopicTarget(\n                stream_id=stream_id,\n                topic_name=new_topic_name,\n            )\n        else:\n            stream_topic = None\n\n        info = get_recipient_info(\n            realm_id=realm.id,\n            recipient=target_message.recipient,\n            sender_id=target_message.sender_id,\n            stream_topic=stream_topic,\n            possible_wildcard_mention=mention_data.message_has_wildcards(),\n        )\n\n        event[\"online_push_user_ids\"] = list(info[\"online_push_user_ids\"])\n        event[\"pm_mention_push_disabled_user_ids\"] = list(info[\"pm_mention_push_disabled_user_ids\"])\n        event[\"pm_mention_email_disabled_user_ids\"] = list(\n            info[\"pm_mention_email_disabled_user_ids\"]\n        )\n        event[\"stream_push_user_ids\"] = list(info[\"stream_push_user_ids\"])\n        event[\"stream_email_user_ids\"] = list(info[\"stream_email_user_ids\"])\n        event[\"muted_sender_user_ids\"] = list(info[\"muted_sender_user_ids\"])\n        event[\"prior_mention_user_ids\"] = list(prior_mention_user_ids)\n        event[\"presence_idle_user_ids\"] = filter_presence_idle_user_ids(info[\"active_user_ids\"])\n        event[\"all_bot_user_ids\"] = list(info[\"all_bot_user_ids\"])\n        if rendering_result.mentions_wildcard:\n            event[\"wildcard_mention_user_ids\"] = list(info[\"wildcard_mention_user_ids\"])\n        else:\n            event[\"wildcard_mention_user_ids\"] = []\n\n        do_update_mobile_push_notification(\n            target_message,\n            prior_mention_user_ids,\n            rendering_result.mentions_user_ids,\n            info[\"stream_push_user_ids\"],\n        )\n\n    if topic_name is not None or new_stream is not None:\n        orig_topic_name = target_message.topic_name()\n        event[\"propagate_mode\"] = propagate_mode\n\n    if new_stream is not None:\n        assert content is None\n        assert target_message.is_stream_message()\n        assert stream_being_edited is not None\n\n        edit_history_event[\"prev_stream\"] = stream_being_edited.id\n        edit_history_event[\"stream\"] = new_stream.id\n        event[ORIG_TOPIC] = orig_topic_name\n        target_message.recipient_id = new_stream.recipient_id\n\n        event[\"new_stream_id\"] = new_stream.id\n        event[\"propagate_mode\"] = propagate_mode\n\n        # When messages are moved from one stream to another, some\n        # users may lose access to those messages, including guest\n        # users and users not subscribed to the new stream (if it is a\n        # private stream).  For those users, their experience is as\n        # though the messages were deleted, and we should send a\n        # delete_message event to them instead.\n\n        subs_to_old_stream = get_active_subscriptions_for_stream_id(\n            stream_id, include_deactivated_users=True\n        ).select_related(\"user_profile\")\n        subs_to_new_stream = list(\n            get_active_subscriptions_for_stream_id(\n                new_stream.id, include_deactivated_users=True\n            ).select_related(\"user_profile\")\n        )\n\n        old_stream_sub_ids = [user.user_profile_id for user in subs_to_old_stream]\n        new_stream_sub_ids = [user.user_profile_id for user in subs_to_new_stream]\n\n        # Get users who aren't subscribed to the new_stream.\n        subs_losing_usermessages = [\n            sub for sub in subs_to_old_stream if sub.user_profile_id not in new_stream_sub_ids\n        ]\n        # Users who can longer access the message without some action\n        # from administrators.\n        subs_losing_access = [\n            sub\n            for sub in subs_losing_usermessages\n            if sub.user_profile.is_guest or not new_stream.is_public()\n        ]\n        ums = ums.exclude(\n            user_profile_id__in=[sub.user_profile_id for sub in subs_losing_usermessages]\n        )\n\n        subs_gaining_usermessages = []\n        if not new_stream.is_history_public_to_subscribers():\n            # For private streams, with history not public to subscribers,\n            # We find out users who are not present in the msgs' old stream\n            # and create new UserMessage for these users so that they can\n            # access this message.\n            subs_gaining_usermessages += [\n                user_id for user_id in new_stream_sub_ids if user_id not in old_stream_sub_ids\n            ]\n\n    if topic_name is not None:\n        topic_name = truncate_topic(topic_name)\n        target_message.set_topic_name(topic_name)\n\n        # These fields have legacy field names.\n        event[ORIG_TOPIC] = orig_topic_name\n        event[TOPIC_NAME] = topic_name\n        event[TOPIC_LINKS] = topic_links(target_message.sender.realm_id, topic_name)\n        edit_history_event[\"prev_topic\"] = orig_topic_name\n        edit_history_event[\"topic\"] = topic_name\n\n    update_edit_history(target_message, timestamp, edit_history_event)\n\n    delete_event_notify_user_ids: List[int] = []\n    if propagate_mode in [\"change_later\", \"change_all\"]:\n        assert topic_name is not None or new_stream is not None\n        assert stream_being_edited is not None\n\n        # Other messages should only get topic/stream fields in their edit history.\n        topic_only_edit_history_event: EditHistoryEvent = {\n            \"user_id\": edit_history_event[\"user_id\"],\n            \"timestamp\": edit_history_event[\"timestamp\"],\n        }\n        if topic_name is not None:\n            topic_only_edit_history_event[\"prev_topic\"] = edit_history_event[\"prev_topic\"]\n            topic_only_edit_history_event[\"topic\"] = edit_history_event[\"topic\"]\n        if new_stream is not None:\n            topic_only_edit_history_event[\"prev_stream\"] = edit_history_event[\"prev_stream\"]\n            topic_only_edit_history_event[\"stream\"] = edit_history_event[\"stream\"]\n\n        messages_list = update_messages_for_topic_edit(\n            acting_user=user_profile,\n            edited_message=target_message,\n            propagate_mode=propagate_mode,\n            orig_topic_name=orig_topic_name,\n            topic_name=topic_name,\n            new_stream=new_stream,\n            old_stream=stream_being_edited,\n            edit_history_event=topic_only_edit_history_event,\n            last_edit_time=timestamp,\n        )\n        changed_messages += messages_list\n\n        if new_stream is not None:\n            assert stream_being_edited is not None\n            changed_message_ids = [msg.id for msg in changed_messages]\n\n            if subs_gaining_usermessages:\n                ums_to_create = []\n                for message_id in changed_message_ids:\n                    for user_profile_id in subs_gaining_usermessages:\n                        # The fact that the user didn't have a UserMessage originally means we can infer that the user\n                        # was not mentioned in the original message (even if mention syntax was present, it would not\n                        # take effect for a user who was not subscribed). If we were editing the message's content, we\n                        # would rerender the message and then use the new stream's data to determine whether this is\n                        # a mention of a subscriber; but as we are not doing so, we choose to preserve the \"was this\n                        # mention syntax an actual mention\" decision made during the original rendering for implementation\n                        # simplicity. As a result, the only flag to consider applying here is read.\n                        um = UserMessageLite(\n                            user_profile_id=user_profile_id,\n                            message_id=message_id,\n                            flags=UserMessage.flags.read,\n                        )\n                        ums_to_create.append(um)\n                bulk_insert_ums(ums_to_create)\n\n            # Delete UserMessage objects for users who will no\n            # longer have access to these messages.  Note: This could be\n            # very expensive, since it's N guest users x M messages.\n            UserMessage.objects.filter(\n                user_profile_id__in=[sub.user_profile_id for sub in subs_losing_usermessages],\n                message_id__in=changed_message_ids,\n            ).delete()\n\n            delete_event: DeleteMessagesEvent = {\n                \"type\": \"delete_message\",\n                \"message_ids\": changed_message_ids,\n                \"message_type\": \"stream\",\n                \"stream_id\": stream_being_edited.id,\n                \"topic\": orig_topic_name,\n            }\n            delete_event_notify_user_ids = [sub.user_profile_id for sub in subs_losing_access]\n            send_event(user_profile.realm, delete_event, delete_event_notify_user_ids)\n\n    # This does message.save(update_fields=[...])\n    save_message_for_edit_use_case(message=target_message)\n\n    realm_id: Optional[int] = None\n    if stream_being_edited is not None:\n        realm_id = stream_being_edited.realm_id\n\n    event[\"message_ids\"] = update_to_dict_cache(changed_messages, realm_id)\n\n    def user_info(um: UserMessage) -> Dict[str, Any]:\n        return {\n            \"id\": um.user_profile_id,\n            \"flags\": um.flags_list(),\n        }\n\n    # The following blocks arranges that users who are subscribed to a\n    # stream and can see history from before they subscribed get\n    # live-update when old messages are edited (e.g. if the user does\n    # a topic edit themself).\n    #\n    # We still don't send an update event to users who are not\n    # subscribed to this stream and don't have a UserMessage row. This\n    # means if a non-subscriber is viewing the narrow, they won't get\n    # a real-time updates. This is a balance between sending\n    # message-edit notifications for every public stream to every user\n    # in the organization (too expansive, and also not what we do for\n    # newly sent messages anyway) and having magical live-updates\n    # where possible.\n    users_to_be_notified = list(map(user_info, ums))\n    if stream_being_edited is not None:\n        if stream_being_edited.is_history_public_to_subscribers:\n            subscriptions = get_active_subscriptions_for_stream_id(\n                stream_id, include_deactivated_users=False\n            )\n            # We exclude long-term idle users, since they by\n            # definition have no active clients.\n            subscriptions = subscriptions.exclude(user_profile__long_term_idle=True)\n            # Remove duplicates by excluding the id of users already\n            # in users_to_be_notified list.  This is the case where a\n            # user both has a UserMessage row and is a current\n            # Subscriber\n            subscriptions = subscriptions.exclude(\n                user_profile_id__in=[um.user_profile_id for um in ums]\n            )\n\n            if new_stream is not None:\n                assert delete_event_notify_user_ids is not None\n                subscriptions = subscriptions.exclude(\n                    user_profile_id__in=delete_event_notify_user_ids\n                )\n\n            # All users that are subscribed to the stream must be\n            # notified when a message is edited\n            subscriber_ids = set(subscriptions.values_list(\"user_profile_id\", flat=True))\n\n            if new_stream is not None:\n                # TODO: Guest users don't see the new moved topic\n                # unless breadcrumb message for new stream is\n                # enabled. Excluding these users from receiving this\n                # event helps us avoid a error traceback for our\n                # clients. We should figure out a way to inform the\n                # guest users of this new topic if sending a 'message'\n                # event for these messages is not an option.\n                #\n                # Don't send this event to guest subs who are not\n                # subscribers of the old stream but are subscribed to\n                # the new stream; clients will be confused.\n                old_stream_unsubbed_guests = [\n                    sub\n                    for sub in subs_to_new_stream\n                    if sub.user_profile.is_guest and sub.user_profile_id not in subscriber_ids\n                ]\n                subscriptions = subscriptions.exclude(\n                    user_profile_id__in=[sub.user_profile_id for sub in old_stream_unsubbed_guests]\n                )\n                subscriber_ids = set(subscriptions.values_list(\"user_profile_id\", flat=True))\n\n            users_to_be_notified += list(map(subscriber_info, sorted(list(subscriber_ids))))\n\n    send_event(user_profile.realm, event, users_to_be_notified)\n\n    if len(changed_messages) > 0 and new_stream is not None and stream_being_edited is not None:\n        # Notify users that the topic was moved.\n        changed_messages_count = len(changed_messages)\n\n        if propagate_mode == \"change_all\":\n            moved_all_visible_messages = True\n        else:\n            # With other propagate modes, if the user in fact moved\n            # all messages in the stream, we want to explain it was a\n            # full-topic move.\n            #\n            # For security model reasons, we don't want to allow a\n            # user to take any action that would leak information\n            # about older messages they cannot access (E.g. the only\n            # remaining messages are in a stream without shared\n            # history). The bulk_access_messages call below addresses\n            # that concern.\n            #\n            # bulk_access_messages is inefficient for this task, since\n            # we just want to do the exists() version of this\n            # query. But it's nice to reuse code, and this bulk\n            # operation is likely cheaper than a `GET /messages`\n            # unless the topic has thousands of messages of history.\n            unmoved_messages = messages_for_topic(\n                stream_being_edited.recipient_id,\n                orig_topic_name,\n            )\n            visible_unmoved_messages = bulk_access_messages(\n                user_profile, unmoved_messages, stream=stream_being_edited\n            )\n            moved_all_visible_messages = len(visible_unmoved_messages) == 0\n\n        old_thread_notification_string = None\n        if send_notification_to_old_thread:\n            if moved_all_visible_messages:\n                old_thread_notification_string = gettext_lazy(\n                    \"This topic was moved to {new_location} by {user}.\"\n                )\n            elif changed_messages_count == 1:\n                old_thread_notification_string = gettext_lazy(\n                    \"A message was moved from this topic to {new_location} by {user}.\"\n                )\n            else:\n                old_thread_notification_string = gettext_lazy(\n                    \"{changed_messages_count} messages were moved from this topic to {new_location} by {user}.\"\n                )\n\n        new_thread_notification_string = None\n        if send_notification_to_new_thread:\n            if moved_all_visible_messages:\n                new_thread_notification_string = gettext_lazy(\n                    \"This topic was moved here from {old_location} by {user}.\"\n                )\n            elif changed_messages_count == 1:\n                new_thread_notification_string = gettext_lazy(\n                    \"A message was moved here from {old_location} by {user}.\"\n                )\n            else:\n                new_thread_notification_string = gettext_lazy(\n                    \"{changed_messages_count} messages were moved here from {old_location} by {user}.\"\n                )\n\n        send_message_moved_breadcrumbs(\n            user_profile,\n            stream_being_edited,\n            orig_topic_name,\n            old_thread_notification_string,\n            new_stream,\n            topic_name,\n            new_thread_notification_string,\n            changed_messages_count,\n        )\n\n    if (\n        topic_name is not None\n        and new_stream is None\n        and content is None\n        and len(changed_messages) > 0\n    ):\n        assert stream_being_edited is not None\n        maybe_send_resolve_topic_notifications(\n            user_profile=user_profile,\n            stream=stream_being_edited,\n            old_topic=orig_topic_name,\n            new_topic=topic_name,\n            changed_messages=changed_messages,\n        )\n\n    return len(changed_messages)\n\n\ndef do_delete_messages(realm: Realm, messages: Iterable[Message]) -> None:\n    # messages in delete_message event belong to the same topic\n    # or is a single private message, as any other behaviour is not possible with\n    # the current callers to this method.\n    messages = list(messages)\n    message_ids = [message.id for message in messages]\n    if not message_ids:\n        return\n\n    event: DeleteMessagesEvent = {\n        \"type\": \"delete_message\",\n        \"message_ids\": message_ids,\n    }\n\n    sample_message = messages[0]\n    message_type = \"stream\"\n    users_to_notify = []\n    if not sample_message.is_stream_message():\n        assert len(messages) == 1\n        message_type = \"private\"\n        ums = UserMessage.objects.filter(message_id__in=message_ids)\n        users_to_notify = [um.user_profile_id for um in ums]\n        archiving_chunk_size = retention.MESSAGE_BATCH_SIZE\n\n    if message_type == \"stream\":\n        stream_id = sample_message.recipient.type_id\n        event[\"stream_id\"] = stream_id\n        event[\"topic\"] = sample_message.topic_name()\n        subscriptions = get_active_subscriptions_for_stream_id(\n            stream_id, include_deactivated_users=False\n        )\n        # We exclude long-term idle users, since they by definition have no active clients.\n        subscriptions = subscriptions.exclude(user_profile__long_term_idle=True)\n        users_to_notify = list(subscriptions.values_list(\"user_profile_id\", flat=True))\n        archiving_chunk_size = retention.STREAM_MESSAGE_BATCH_SIZE\n\n    move_messages_to_archive(message_ids, realm=realm, chunk_size=archiving_chunk_size)\n\n    event[\"message_type\"] = message_type\n    transaction.on_commit(lambda: send_event(realm, event, users_to_notify))\n\n\ndef do_delete_messages_by_sender(user: UserProfile) -> None:\n    message_ids = list(\n        Message.objects.filter(sender=user).values_list(\"id\", flat=True).order_by(\"id\")\n    )\n    if message_ids:\n        move_messages_to_archive(message_ids, chunk_size=retention.STREAM_MESSAGE_BATCH_SIZE)\n\n\n# In general, it's better to avoid using .values() because it makes\n# the code pretty ugly, but in this case, it has significant\n# performance impact for loading / for users with large numbers of\n# subscriptions, so it's worth optimizing.\ndef gather_subscriptions_helper(\n    user_profile: UserProfile,\n    include_subscribers: bool = True,\n) -> SubscriptionInfo:\n    realm = user_profile.realm\n    all_streams: QuerySet[RawStreamDict] = get_active_streams(realm).values(\n        *Stream.API_FIELDS,\n        # The realm_id and recipient_id are generally not needed in the API.\n        \"realm_id\",\n        \"recipient_id\",\n        # email_token isn't public to some users with access to\n        # the stream, so doesn't belong in API_FIELDS.\n        \"email_token\",\n    )\n    recip_id_to_stream_id: Dict[int, int] = {\n        stream[\"recipient_id\"]: stream[\"id\"] for stream in all_streams\n    }\n    all_streams_map: Dict[int, RawStreamDict] = {stream[\"id\"]: stream for stream in all_streams}\n\n    sub_dicts_query: Iterable[RawSubscriptionDict] = (\n        get_stream_subscriptions_for_user(user_profile)\n        .values(\n            *Subscription.API_FIELDS,\n            \"recipient_id\",\n            \"active\",\n        )\n        .order_by(\"recipient_id\")\n    )\n\n    # We only care about subscriptions for active streams.\n    sub_dicts: List[RawSubscriptionDict] = [\n        sub_dict\n        for sub_dict in sub_dicts_query\n        if recip_id_to_stream_id.get(sub_dict[\"recipient_id\"])\n    ]\n\n    def get_stream_id(sub_dict: RawSubscriptionDict) -> int:\n        return recip_id_to_stream_id[sub_dict[\"recipient_id\"]]\n\n    traffic_stream_ids = {get_stream_id(sub_dict) for sub_dict in sub_dicts}\n    recent_traffic = get_streams_traffic(stream_ids=traffic_stream_ids)\n\n    # Okay, now we finally get to populating our main results, which\n    # will be these three lists.\n    subscribed: List[SubscriptionStreamDict] = []\n    unsubscribed: List[SubscriptionStreamDict] = []\n    never_subscribed: List[NeverSubscribedStreamDict] = []\n\n    sub_unsub_stream_ids = set()\n    for sub_dict in sub_dicts:\n        stream_id = get_stream_id(sub_dict)\n        sub_unsub_stream_ids.add(stream_id)\n        raw_stream_dict = all_streams_map[stream_id]\n\n        stream_dict = build_stream_dict_for_sub(\n            user=user_profile,\n            sub_dict=sub_dict,\n            raw_stream_dict=raw_stream_dict,\n            recent_traffic=recent_traffic,\n        )\n\n        # is_active is represented in this structure by which list we include it in.\n        is_active = sub_dict[\"active\"]\n        if is_active:\n            subscribed.append(stream_dict)\n        else:\n            unsubscribed.append(stream_dict)\n\n    if user_profile.can_access_public_streams():\n        never_subscribed_stream_ids = set(all_streams_map) - sub_unsub_stream_ids\n    else:\n        web_public_stream_ids = {stream[\"id\"] for stream in all_streams if stream[\"is_web_public\"]}\n        never_subscribed_stream_ids = web_public_stream_ids - sub_unsub_stream_ids\n\n    never_subscribed_streams = [\n        all_streams_map[stream_id] for stream_id in never_subscribed_stream_ids\n    ]\n\n    for raw_stream_dict in never_subscribed_streams:\n        is_public = not raw_stream_dict[\"invite_only\"]\n        if is_public or user_profile.is_realm_admin:\n            slim_stream_dict = build_stream_dict_for_never_sub(\n                raw_stream_dict=raw_stream_dict, recent_traffic=recent_traffic\n            )\n\n            never_subscribed.append(slim_stream_dict)\n\n    if include_subscribers:\n        # The highly optimized bulk_get_subscriber_user_ids wants to know which\n        # streams we are subscribed to, for validation purposes, and it uses that\n        # info to know if it's allowed to find OTHER subscribers.\n        subscribed_stream_ids = {\n            get_stream_id(sub_dict) for sub_dict in sub_dicts if sub_dict[\"active\"]\n        }\n\n        subscriber_map = bulk_get_subscriber_user_ids(\n            all_streams,\n            user_profile,\n            subscribed_stream_ids,\n        )\n\n        for lst in [subscribed, unsubscribed]:\n            for stream_dict in lst:\n                assert isinstance(stream_dict[\"stream_id\"], int)\n                stream_id = stream_dict[\"stream_id\"]\n                stream_dict[\"subscribers\"] = subscriber_map[stream_id]\n\n        for slim_stream_dict in never_subscribed:\n            assert isinstance(slim_stream_dict[\"stream_id\"], int)\n            stream_id = slim_stream_dict[\"stream_id\"]\n            slim_stream_dict[\"subscribers\"] = subscriber_map[stream_id]\n\n    subscribed.sort(key=lambda x: x[\"name\"])\n    unsubscribed.sort(key=lambda x: x[\"name\"])\n    never_subscribed.sort(key=lambda x: x[\"name\"])\n\n    return SubscriptionInfo(\n        subscriptions=subscribed,\n        unsubscribed=unsubscribed,\n        never_subscribed=never_subscribed,\n    )\n\n\ndef gather_subscriptions(\n    user_profile: UserProfile,\n    include_subscribers: bool = False,\n) -> Tuple[List[SubscriptionStreamDict], List[SubscriptionStreamDict]]:\n    helper_result = gather_subscriptions_helper(\n        user_profile,\n        include_subscribers=include_subscribers,\n    )\n    subscribed = helper_result.subscriptions\n    unsubscribed = helper_result.unsubscribed\n    return (subscribed, unsubscribed)\n\n\nclass ActivePresenceIdleUserData(TypedDict):\n    alerted: bool\n    notifications_data: UserMessageNotificationsData\n\n\ndef get_active_presence_idle_user_ids(\n    realm: Realm,\n    sender_id: int,\n    active_users_data: List[ActivePresenceIdleUserData],\n) -> List[int]:\n    \"\"\"\n    Given a list of active_user_ids, we build up a subset\n    of those users who fit these criteria:\n\n        * They are likely to need notifications.\n        * They are no longer \"present\" according to the\n          UserPresence table.\n    \"\"\"\n\n    if realm.presence_disabled:\n        return []\n\n    user_ids = set()\n    for user_data in active_users_data:\n        user_notifications_data: UserMessageNotificationsData = user_data[\"notifications_data\"]\n        alerted = user_data[\"alerted\"]\n\n        # We only need to know the presence idle state for a user if this message would be notifiable\n        # for them if they were indeed idle. Only including those users in the calculation below is a\n        # very important optimization for open communities with many inactive users.\n        if user_notifications_data.is_notifiable(sender_id, idle=True) or alerted:\n            user_ids.add(user_notifications_data.user_id)\n\n    return filter_presence_idle_user_ids(user_ids)\n\n\ndef filter_presence_idle_user_ids(user_ids: Set[int]) -> List[int]:\n    # Given a set of user IDs (the recipients of a message), accesses\n    # the UserPresence table to determine which of these users are\n    # currently idle and should potentially get email notifications\n    # (and push notifications with with\n    # user_profile.enable_online_push_notifications=False).\n    #\n    # We exclude any presence data from ZulipMobile for the purpose of\n    # triggering these notifications; the mobile app can more\n    # effectively do its own client-side filtering of notification\n    # sounds/etc. for the case that the user is actively doing a PM\n    # conversation in the app.\n\n    if not user_ids:\n        return []\n\n    # Matches presence.js constant\n    OFFLINE_THRESHOLD_SECS = 140\n\n    recent = timezone_now() - datetime.timedelta(seconds=OFFLINE_THRESHOLD_SECS)\n    rows = (\n        UserPresence.objects.filter(\n            user_profile_id__in=user_ids,\n            status=UserPresence.ACTIVE,\n            timestamp__gte=recent,\n        )\n        .exclude(client__name=\"ZulipMobile\")\n        .distinct(\"user_profile_id\")\n        .values(\"user_profile_id\")\n    )\n    active_user_ids = {row[\"user_profile_id\"] for row in rows}\n    idle_user_ids = user_ids - active_user_ids\n    return sorted(idle_user_ids)\n\n\ndef do_send_confirmation_email(\n    invitee: PreregistrationUser,\n    referrer: UserProfile,\n    email_language: str,\n    invite_expires_in_days: Union[Optional[int], UnspecifiedValue] = UnspecifiedValue(),\n) -> str:\n    \"\"\"\n    Send the confirmation/welcome e-mail to an invited user.\n    \"\"\"\n    activation_url = create_confirmation_link(\n        invitee, Confirmation.INVITATION, validity_in_days=invite_expires_in_days\n    )\n    context = {\n        \"referrer_full_name\": referrer.full_name,\n        \"referrer_email\": referrer.delivery_email,\n        \"activate_url\": activation_url,\n        \"referrer_realm_name\": referrer.realm.name,\n    }\n    send_email(\n        \"zerver/emails/invitation\",\n        to_emails=[invitee.email],\n        from_address=FromAddress.tokenized_no_reply_address(),\n        language=email_language,\n        context=context,\n        realm=referrer.realm,\n    )\n    return activation_url\n\n\ndef email_not_system_bot(email: str) -> None:\n    if is_cross_realm_bot_email(email):\n        msg = email_reserved_for_system_bots_error(email)\n        code = msg\n        raise ValidationError(\n            msg,\n            code=code,\n            params=dict(deactivated=False),\n        )\n\n\ndef estimate_recent_invites(realms: Collection[Realm], *, days: int) -> int:\n    \"\"\"An upper bound on the number of invites sent in the last `days` days\"\"\"\n    recent_invites = RealmCount.objects.filter(\n        realm__in=realms,\n        property=\"invites_sent::day\",\n        end_time__gte=timezone_now() - datetime.timedelta(days=days),\n    ).aggregate(Sum(\"value\"))[\"value__sum\"]\n    if recent_invites is None:\n        return 0\n    return recent_invites\n\n\ndef check_invite_limit(realm: Realm, num_invitees: int) -> None:\n    \"\"\"Discourage using invitation emails as a vector for carrying spam.\"\"\"\n    msg = _(\n        \"To protect users, Zulip limits the number of invitations you can send in one day. Because you have reached the limit, no invitations were sent.\"\n    )\n    if not settings.OPEN_REALM_CREATION:\n        return\n\n    recent_invites = estimate_recent_invites([realm], days=1)\n    if num_invitees + recent_invites > realm.max_invites:\n        raise InvitationError(\n            msg,\n            [],\n            sent_invitations=False,\n            daily_limit_reached=True,\n        )\n\n    default_max = settings.INVITES_DEFAULT_REALM_DAILY_MAX\n    newrealm_age = datetime.timedelta(days=settings.INVITES_NEW_REALM_DAYS)\n    if realm.date_created <= timezone_now() - newrealm_age:\n        # If this isn't a \"newly-created\" realm, we're done. The\n        # remaining code applies an aggregate limit across all\n        # \"new\" realms, to address sudden bursts of spam realms.\n        return\n\n    if realm.max_invites > default_max:\n        # If a user is on a realm where we've bumped up\n        # max_invites, then we exempt them from invite limits.\n        return\n\n    new_realms = Realm.objects.filter(\n        date_created__gte=timezone_now() - newrealm_age,\n        _max_invites__lte=default_max,\n    ).all()\n\n    for days, count in settings.INVITES_NEW_REALM_LIMIT_DAYS:\n        recent_invites = estimate_recent_invites(new_realms, days=days)\n        if num_invitees + recent_invites > count:\n            raise InvitationError(\n                msg,\n                [],\n                sent_invitations=False,\n                daily_limit_reached=True,\n            )\n\n\ndef do_invite_users(\n    user_profile: UserProfile,\n    invitee_emails: Collection[str],\n    streams: Collection[Stream],\n    *,\n    invite_expires_in_days: Optional[int],\n    invite_as: int = PreregistrationUser.INVITE_AS[\"MEMBER\"],\n) -> None:\n    num_invites = len(invitee_emails)\n\n    check_invite_limit(user_profile.realm, num_invites)\n    if settings.BILLING_ENABLED:\n        from corporate.lib.registration import check_spare_licenses_available_for_inviting_new_users\n\n        check_spare_licenses_available_for_inviting_new_users(user_profile.realm, num_invites)\n\n    realm = user_profile.realm\n    if not realm.invite_required:\n        # Inhibit joining an open realm to send spam invitations.\n        min_age = datetime.timedelta(days=settings.INVITES_MIN_USER_AGE_DAYS)\n        if user_profile.date_joined > timezone_now() - min_age and not user_profile.is_realm_admin:\n            raise InvitationError(\n                _(\n                    \"Your account is too new to send invites for this organization. \"\n                    \"Ask an organization admin, or a more experienced user.\"\n                ),\n                [],\n                sent_invitations=False,\n            )\n\n    good_emails: Set[str] = set()\n    errors: List[Tuple[str, str, bool]] = []\n    validate_email_allowed_in_realm = get_realm_email_validator(user_profile.realm)\n    for email in invitee_emails:\n        if email == \"\":\n            continue\n        email_error = validate_email_is_valid(\n            email,\n            validate_email_allowed_in_realm,\n        )\n\n        if email_error:\n            errors.append((email, email_error, False))\n        else:\n            good_emails.add(email)\n\n    \"\"\"\n    good_emails are emails that look ok so far,\n    but we still need to make sure they're not\n    gonna conflict with existing users\n    \"\"\"\n    error_dict = get_existing_user_errors(user_profile.realm, good_emails)\n\n    skipped: List[Tuple[str, str, bool]] = []\n    for email in error_dict:\n        msg, deactivated = error_dict[email]\n        skipped.append((email, msg, deactivated))\n        good_emails.remove(email)\n\n    validated_emails = list(good_emails)\n\n    if errors:\n        raise InvitationError(\n            _(\"Some emails did not validate, so we didn't send any invitations.\"),\n            errors + skipped,\n            sent_invitations=False,\n        )\n\n    if skipped and len(skipped) == len(invitee_emails):\n        # All e-mails were skipped, so we didn't actually invite anyone.\n        raise InvitationError(\n            _(\"We weren't able to invite anyone.\"), skipped, sent_invitations=False\n        )\n\n    # We do this here rather than in the invite queue processor since this\n    # is used for rate limiting invitations, rather than keeping track of\n    # when exactly invitations were sent\n    do_increment_logging_stat(\n        user_profile.realm,\n        COUNT_STATS[\"invites_sent::day\"],\n        None,\n        timezone_now(),\n        increment=len(validated_emails),\n    )\n\n    # Now that we are past all the possible errors, we actually create\n    # the PreregistrationUser objects and trigger the email invitations.\n    for email in validated_emails:\n        # The logged in user is the referrer.\n        prereg_user = PreregistrationUser(\n            email=email, referred_by=user_profile, invited_as=invite_as, realm=user_profile.realm\n        )\n        prereg_user.save()\n        stream_ids = [stream.id for stream in streams]\n        prereg_user.streams.set(stream_ids)\n\n        event = {\n            \"prereg_id\": prereg_user.id,\n            \"referrer_id\": user_profile.id,\n            \"email_language\": user_profile.realm.default_language,\n            \"invite_expires_in_days\": invite_expires_in_days,\n        }\n        queue_json_publish(\"invites\", event)\n\n    if skipped:\n        raise InvitationError(\n            _(\n                \"Some of those addresses are already using Zulip, \"\n                \"so we didn't send them an invitation. We did send \"\n                \"invitations to everyone else!\"\n            ),\n            skipped,\n            sent_invitations=True,\n        )\n    notify_invites_changed(user_profile.realm)\n\n\ndef get_invitation_expiry_date(confirmation_obj: Confirmation) -> Optional[int]:\n    expiry_date = confirmation_obj.expiry_date\n    if expiry_date is None:\n        return expiry_date\n    return datetime_to_timestamp(expiry_date)\n\n\ndef do_get_invites_controlled_by_user(user_profile: UserProfile) -> List[Dict[str, Any]]:\n    \"\"\"\n    Returns a list of dicts representing invitations that can be controlled by user_profile.\n    This isn't necessarily the same as all the invitations generated by the user, as administrators\n    can control also invitations that they did not themselves create.\n    \"\"\"\n    if user_profile.is_realm_admin:\n        prereg_users = filter_to_valid_prereg_users(\n            PreregistrationUser.objects.filter(referred_by__realm=user_profile.realm)\n        )\n    else:\n        prereg_users = filter_to_valid_prereg_users(\n            PreregistrationUser.objects.filter(referred_by=user_profile)\n        )\n\n    invites = []\n\n    for invitee in prereg_users:\n        invites.append(\n            dict(\n                email=invitee.email,\n                invited_by_user_id=invitee.referred_by.id,\n                invited=datetime_to_timestamp(invitee.invited_at),\n                expiry_date=get_invitation_expiry_date(invitee.confirmation.get()),\n                id=invitee.id,\n                invited_as=invitee.invited_as,\n                is_multiuse=False,\n            )\n        )\n\n    if not user_profile.is_realm_admin:\n        # We do not return multiuse invites to non-admin users.\n        return invites\n\n    multiuse_confirmation_objs = Confirmation.objects.filter(\n        realm=user_profile.realm, type=Confirmation.MULTIUSE_INVITE\n    ).filter(Q(expiry_date__gte=timezone_now()) | Q(expiry_date=None))\n    for confirmation_obj in multiuse_confirmation_objs:\n        invite = confirmation_obj.content_object\n        assert invite is not None\n        invites.append(\n            dict(\n                invited_by_user_id=invite.referred_by.id,\n                invited=datetime_to_timestamp(confirmation_obj.date_sent),\n                expiry_date=get_invitation_expiry_date(confirmation_obj),\n                id=invite.id,\n                link_url=confirmation_url(\n                    confirmation_obj.confirmation_key,\n                    user_profile.realm,\n                    Confirmation.MULTIUSE_INVITE,\n                ),\n                invited_as=invite.invited_as,\n                is_multiuse=True,\n            )\n        )\n    return invites\n\n\ndef get_valid_invite_confirmations_generated_by_user(\n    user_profile: UserProfile,\n) -> List[Confirmation]:\n    prereg_user_ids = filter_to_valid_prereg_users(\n        PreregistrationUser.objects.filter(referred_by=user_profile)\n    ).values_list(\"id\", flat=True)\n    confirmations = list(\n        Confirmation.objects.filter(type=Confirmation.INVITATION, object_id__in=prereg_user_ids)\n    )\n\n    multiuse_invite_ids = MultiuseInvite.objects.filter(referred_by=user_profile).values_list(\n        \"id\", flat=True\n    )\n    confirmations += list(\n        Confirmation.objects.filter(\n            type=Confirmation.MULTIUSE_INVITE,\n            object_id__in=multiuse_invite_ids,\n        ).filter(Q(expiry_date__gte=timezone_now()) | Q(expiry_date=None))\n    )\n\n    return confirmations\n\n\ndef revoke_invites_generated_by_user(user_profile: UserProfile) -> None:\n    confirmations_to_revoke = get_valid_invite_confirmations_generated_by_user(user_profile)\n    now = timezone_now()\n    for confirmation in confirmations_to_revoke:\n        confirmation.expiry_date = now\n\n    Confirmation.objects.bulk_update(confirmations_to_revoke, [\"expiry_date\"])\n    if len(confirmations_to_revoke):\n        notify_invites_changed(realm=user_profile.realm)\n\n\ndef do_create_multiuse_invite_link(\n    referred_by: UserProfile,\n    invited_as: int,\n    invite_expires_in_days: Optional[int],\n    streams: Sequence[Stream] = [],\n) -> str:\n    realm = referred_by.realm\n    invite = MultiuseInvite.objects.create(realm=realm, referred_by=referred_by)\n    if streams:\n        invite.streams.set(streams)\n    invite.invited_as = invited_as\n    invite.save()\n    notify_invites_changed(referred_by.realm)\n    return create_confirmation_link(\n        invite, Confirmation.MULTIUSE_INVITE, validity_in_days=invite_expires_in_days\n    )\n\n\ndef do_revoke_user_invite(prereg_user: PreregistrationUser) -> None:\n    email = prereg_user.email\n    realm = prereg_user.realm\n    assert realm is not None\n\n    # Delete both the confirmation objects and the prereg_user object.\n    # TODO: Probably we actually want to set the confirmation objects\n    # to a \"revoked\" status so that we can give the invited user a better\n    # error message.\n    content_type = ContentType.objects.get_for_model(PreregistrationUser)\n    Confirmation.objects.filter(content_type=content_type, object_id=prereg_user.id).delete()\n    prereg_user.delete()\n    clear_scheduled_invitation_emails(email)\n    notify_invites_changed(realm)\n\n\ndef do_revoke_multi_use_invite(multiuse_invite: MultiuseInvite) -> None:\n    realm = multiuse_invite.referred_by.realm\n\n    content_type = ContentType.objects.get_for_model(MultiuseInvite)\n    Confirmation.objects.filter(content_type=content_type, object_id=multiuse_invite.id).delete()\n    multiuse_invite.delete()\n    notify_invites_changed(realm)\n\n\ndef do_resend_user_invite_email(prereg_user: PreregistrationUser) -> int:\n    # These are two structurally for the caller's code path.\n    assert prereg_user.referred_by is not None\n    assert prereg_user.realm is not None\n\n    check_invite_limit(prereg_user.referred_by.realm, 1)\n\n    prereg_user.invited_at = timezone_now()\n    prereg_user.save()\n\n    expiry_date = prereg_user.confirmation.get().expiry_date\n    if expiry_date is None:\n        invite_expires_in_days = None\n    else:\n        # The resent invitation is reset to expire as long after the\n        # reminder is sent as it lasted originally.\n        invite_expires_in_days = (expiry_date - prereg_user.invited_at).days\n    prereg_user.confirmation.clear()\n\n    do_increment_logging_stat(\n        prereg_user.realm, COUNT_STATS[\"invites_sent::day\"], None, prereg_user.invited_at\n    )\n\n    clear_scheduled_invitation_emails(prereg_user.email)\n    # We don't store the custom email body, so just set it to None\n    event = {\n        \"prereg_id\": prereg_user.id,\n        \"referrer_id\": prereg_user.referred_by.id,\n        \"email_language\": prereg_user.referred_by.realm.default_language,\n        \"invite_expires_in_days\": invite_expires_in_days,\n    }\n    queue_json_publish(\"invites\", event)\n\n    return datetime_to_timestamp(prereg_user.invited_at)\n\n\ndef notify_realm_emoji(realm: Realm) -> None:\n    event = dict(type=\"realm_emoji\", op=\"update\", realm_emoji=realm.get_emoji())\n    send_event(realm, event, active_user_ids(realm.id))\n\n\ndef check_add_realm_emoji(\n    realm: Realm, name: str, author: UserProfile, image_file: IO[bytes]\n) -> RealmEmoji:\n    try:\n        realm_emoji = RealmEmoji(realm=realm, name=name, author=author)\n        realm_emoji.full_clean()\n        realm_emoji.save()\n    except django.db.utils.IntegrityError:\n        # Match the string in upload_emoji.\n        raise JsonableError(_(\"A custom emoji with this name already exists.\"))\n\n    emoji_file_name = get_emoji_file_name(image_file.name, realm_emoji.id)\n\n    # The only user-controlled portion of 'emoji_file_name' is an extension,\n    # which can not contain '..' or '/' or '\\', making it difficult to exploit\n    emoji_file_name = mark_sanitized(emoji_file_name)\n\n    emoji_uploaded_successfully = False\n    is_animated = False\n    try:\n        is_animated = upload_emoji_image(image_file, emoji_file_name, author)\n        emoji_uploaded_successfully = True\n    finally:\n        if not emoji_uploaded_successfully:\n            realm_emoji.delete()\n    realm_emoji.file_name = emoji_file_name\n    realm_emoji.is_animated = is_animated\n    realm_emoji.save(update_fields=[\"file_name\", \"is_animated\"])\n    notify_realm_emoji(realm_emoji.realm)\n    return realm_emoji\n\n\ndef do_remove_realm_emoji(realm: Realm, name: str) -> None:\n    emoji = RealmEmoji.objects.get(realm=realm, name=name, deactivated=False)\n    emoji.deactivated = True\n    emoji.save(update_fields=[\"deactivated\"])\n    notify_realm_emoji(realm)\n\n\ndef notify_alert_words(user_profile: UserProfile, words: Sequence[str]) -> None:\n    event = dict(type=\"alert_words\", alert_words=words)\n    send_event(user_profile.realm, event, [user_profile.id])\n\n\ndef do_add_alert_words(user_profile: UserProfile, alert_words: Iterable[str]) -> None:\n    words = add_user_alert_words(user_profile, alert_words)\n    notify_alert_words(user_profile, words)\n\n\ndef do_remove_alert_words(user_profile: UserProfile, alert_words: Iterable[str]) -> None:\n    words = remove_user_alert_words(user_profile, alert_words)\n    notify_alert_words(user_profile, words)\n\n\ndef do_mute_topic(\n    user_profile: UserProfile,\n    stream: Stream,\n    topic: str,\n    date_muted: Optional[datetime.datetime] = None,\n) -> None:\n    if date_muted is None:\n        date_muted = timezone_now()\n    add_topic_mute(user_profile, stream.id, stream.recipient_id, topic, date_muted)\n    event = dict(type=\"muted_topics\", muted_topics=get_topic_mutes(user_profile))\n    send_event(user_profile.realm, event, [user_profile.id])\n\n\ndef do_unmute_topic(user_profile: UserProfile, stream: Stream, topic: str) -> None:\n    try:\n        remove_topic_mute(user_profile, stream.id, topic)\n    except UserTopic.DoesNotExist:\n        raise JsonableError(_(\"Topic is not muted\"))\n    event = dict(type=\"muted_topics\", muted_topics=get_topic_mutes(user_profile))\n    send_event(user_profile.realm, event, [user_profile.id])\n\n\ndef do_mute_user(\n    user_profile: UserProfile,\n    muted_user: UserProfile,\n    date_muted: Optional[datetime.datetime] = None,\n) -> None:\n    if date_muted is None:\n        date_muted = timezone_now()\n    add_user_mute(user_profile, muted_user, date_muted)\n    do_mark_muted_user_messages_as_read(user_profile, muted_user)\n    event = dict(type=\"muted_users\", muted_users=get_user_mutes(user_profile))\n    send_event(user_profile.realm, event, [user_profile.id])\n\n    RealmAuditLog.objects.create(\n        realm=user_profile.realm,\n        acting_user=user_profile,\n        modified_user=user_profile,\n        event_type=RealmAuditLog.USER_MUTED,\n        event_time=date_muted,\n        extra_data=orjson.dumps({\"muted_user_id\": muted_user.id}).decode(),\n    )\n\n\ndef do_unmute_user(mute_object: MutedUser) -> None:\n    user_profile = mute_object.user_profile\n    muted_user = mute_object.muted_user\n    mute_object.delete()\n    event = dict(type=\"muted_users\", muted_users=get_user_mutes(user_profile))\n    send_event(user_profile.realm, event, [user_profile.id])\n\n    RealmAuditLog.objects.create(\n        realm=user_profile.realm,\n        acting_user=user_profile,\n        modified_user=user_profile,\n        event_type=RealmAuditLog.USER_UNMUTED,\n        event_time=timezone_now(),\n        extra_data=orjson.dumps({\"unmuted_user_id\": muted_user.id}).decode(),\n    )\n\n\ndef do_mark_hotspot_as_read(user: UserProfile, hotspot: str) -> None:\n    UserHotspot.objects.get_or_create(user=user, hotspot=hotspot)\n    event = dict(type=\"hotspots\", hotspots=get_next_hotspots(user))\n    send_event(user.realm, event, [user.id])\n\n\ndef notify_linkifiers(realm: Realm) -> None:\n    realm_linkifiers = linkifiers_for_realm(realm.id)\n    event: Dict[str, object] = dict(type=\"realm_linkifiers\", realm_linkifiers=realm_linkifiers)\n    send_event(realm, event, active_user_ids(realm.id))\n\n    # Below is code for backwards compatibility. The now deprecated\n    # \"realm_filters\" event-type is used by older clients, and uses\n    # tuples.\n    realm_filters = realm_filters_for_realm(realm.id)\n    event = dict(type=\"realm_filters\", realm_filters=realm_filters)\n    send_event(realm, event, active_user_ids(realm.id))\n\n\n# NOTE: Regexes must be simple enough that they can be easily translated to JavaScript\n# RegExp syntax. In addition to JS-compatible syntax, the following features are available:\n#   * Named groups will be converted to numbered groups automatically\n#   * Inline-regex flags will be stripped, and where possible translated to RegExp-wide flags\ndef do_add_linkifier(realm: Realm, pattern: str, url_format_string: str) -> int:\n    pattern = pattern.strip()\n    url_format_string = url_format_string.strip()\n    linkifier = RealmFilter(realm=realm, pattern=pattern, url_format_string=url_format_string)\n    linkifier.full_clean()\n    linkifier.save()\n    notify_linkifiers(realm)\n\n    return linkifier.id\n\n\ndef do_remove_linkifier(\n    realm: Realm, pattern: Optional[str] = None, id: Optional[int] = None\n) -> None:\n    if pattern is not None:\n        RealmFilter.objects.get(realm=realm, pattern=pattern).delete()\n    else:\n        RealmFilter.objects.get(realm=realm, id=id).delete()\n    notify_linkifiers(realm)\n\n\ndef do_update_linkifier(realm: Realm, id: int, pattern: str, url_format_string: str) -> None:\n    pattern = pattern.strip()\n    url_format_string = url_format_string.strip()\n    linkifier = RealmFilter.objects.get(realm=realm, id=id)\n    linkifier.pattern = pattern\n    linkifier.url_format_string = url_format_string\n    linkifier.full_clean()\n    linkifier.save(update_fields=[\"pattern\", \"url_format_string\"])\n    notify_linkifiers(realm)\n\n\n@transaction.atomic(durable=True)\ndef do_add_realm_domain(\n    realm: Realm, domain: str, allow_subdomains: bool, *, acting_user: Optional[UserProfile]\n) -> (RealmDomain):\n    realm_domain = RealmDomain.objects.create(\n        realm=realm, domain=domain, allow_subdomains=allow_subdomains\n    )\n\n    RealmAuditLog.objects.create(\n        realm=realm,\n        acting_user=acting_user,\n        event_type=RealmAuditLog.REALM_DOMAIN_ADDED,\n        event_time=timezone_now(),\n        extra_data=orjson.dumps(\n            {\n                \"realm_domains\": get_realm_domains(realm),\n                \"added_domain\": {\"domain\": domain, \"allow_subdomains\": allow_subdomains},\n            }\n        ).decode(),\n    )\n\n    event = dict(\n        type=\"realm_domains\",\n        op=\"add\",\n        realm_domain=dict(\n            domain=realm_domain.domain, allow_subdomains=realm_domain.allow_subdomains\n        ),\n    )\n    transaction.on_commit(lambda: send_event(realm, event, active_user_ids(realm.id)))\n\n    return realm_domain\n\n\n@transaction.atomic(durable=True)\ndef do_change_realm_domain(\n    realm_domain: RealmDomain, allow_subdomains: bool, *, acting_user: Optional[UserProfile]\n) -> None:\n    realm_domain.allow_subdomains = allow_subdomains\n    realm_domain.save(update_fields=[\"allow_subdomains\"])\n\n    RealmAuditLog.objects.create(\n        realm=realm_domain.realm,\n        acting_user=acting_user,\n        event_type=RealmAuditLog.REALM_DOMAIN_CHANGED,\n        event_time=timezone_now(),\n        extra_data=orjson.dumps(\n            {\n                \"realm_domains\": get_realm_domains(realm_domain.realm),\n                \"changed_domain\": {\n                    \"domain\": realm_domain.domain,\n                    \"allow_subdomains\": realm_domain.allow_subdomains,\n                },\n            }\n        ).decode(),\n    )\n\n    event = dict(\n        type=\"realm_domains\",\n        op=\"change\",\n        realm_domain=dict(\n            domain=realm_domain.domain, allow_subdomains=realm_domain.allow_subdomains\n        ),\n    )\n    transaction.on_commit(\n        lambda: send_event(realm_domain.realm, event, active_user_ids(realm_domain.realm_id))\n    )\n\n\n@transaction.atomic(durable=True)\ndef do_remove_realm_domain(\n    realm_domain: RealmDomain, *, acting_user: Optional[UserProfile]\n) -> None:\n    realm = realm_domain.realm\n    domain = realm_domain.domain\n    realm_domain.delete()\n\n    RealmAuditLog.objects.create(\n        realm=realm,\n        acting_user=acting_user,\n        event_type=RealmAuditLog.REALM_DOMAIN_REMOVED,\n        event_time=timezone_now(),\n        extra_data=orjson.dumps(\n            {\n                \"realm_domains\": get_realm_domains(realm),\n                \"removed_domain\": {\n                    \"domain\": realm_domain.domain,\n                    \"allow_subdomains\": realm_domain.allow_subdomains,\n                },\n            }\n        ).decode(),\n    )\n\n    if RealmDomain.objects.filter(realm=realm).count() == 0 and realm.emails_restricted_to_domains:\n        # If this was the last realm domain, we mark the realm as no\n        # longer restricted to domain, because the feature doesn't do\n        # anything if there are no domains, and this is probably less\n        # confusing than the alternative.\n        do_set_realm_property(realm, \"emails_restricted_to_domains\", False, acting_user=acting_user)\n    event = dict(type=\"realm_domains\", op=\"remove\", domain=domain)\n    transaction.on_commit(lambda: send_event(realm, event, active_user_ids(realm.id)))\n\n\ndef notify_realm_playgrounds(realm: Realm) -> None:\n    event = dict(type=\"realm_playgrounds\", realm_playgrounds=get_realm_playgrounds(realm))\n    send_event(realm, event, active_user_ids(realm.id))\n\n\ndef do_add_realm_playground(realm: Realm, **kwargs: Any) -> int:\n    realm_playground = RealmPlayground(realm=realm, **kwargs)\n    # We expect full_clean to always pass since a thorough input validation\n    # is performed in the view (using check_url, check_pygments_language, etc)\n    # before calling this function.\n    realm_playground.full_clean()\n    realm_playground.save()\n    notify_realm_playgrounds(realm)\n    return realm_playground.id\n\n\ndef do_remove_realm_playground(realm: Realm, realm_playground: RealmPlayground) -> None:\n    realm_playground.delete()\n    notify_realm_playgrounds(realm)\n\n\ndef get_occupied_streams(realm: Realm) -> QuerySet:\n    # TODO: Make a generic stub for QuerySet\n    \"\"\"Get streams with subscribers\"\"\"\n    exists_expression = Exists(\n        Subscription.objects.filter(\n            active=True,\n            is_user_active=True,\n            user_profile__realm=realm,\n            recipient_id=OuterRef(\"recipient_id\"),\n        ),\n    )\n    occupied_streams = (\n        Stream.objects.filter(realm=realm, deactivated=False)\n        .annotate(occupied=exists_expression)\n        .filter(occupied=True)\n    )\n    return occupied_streams\n\n\ndef get_web_public_streams(realm: Realm) -> List[Dict[str, Any]]:  # nocoverage\n    query = get_web_public_streams_queryset(realm)\n    streams = Stream.get_client_data(query)\n    return streams\n\n\ndef do_get_streams(\n    user_profile: UserProfile,\n    include_public: bool = True,\n    include_web_public: bool = False,\n    include_subscribed: bool = True,\n    include_all_active: bool = False,\n    include_default: bool = False,\n    include_owner_subscribed: bool = False,\n) -> List[Dict[str, Any]]:\n    # This function is only used by API clients now.\n\n    if include_all_active and not user_profile.is_realm_admin:\n        raise JsonableError(_(\"User not authorized for this query\"))\n\n    include_public = include_public and user_profile.can_access_public_streams()\n\n    # Start out with all active streams in the realm.\n    query = Stream.objects.filter(realm=user_profile.realm, deactivated=False)\n\n    if include_all_active:\n        streams = Stream.get_client_data(query)\n    else:\n        # We construct a query as the or (|) of the various sources\n        # this user requested streams from.\n        query_filter: Optional[Q] = None\n\n        def add_filter_option(option: Q) -> None:\n            nonlocal query_filter\n            if query_filter is None:\n                query_filter = option\n            else:\n                query_filter |= option\n\n        if include_subscribed:\n            subscribed_stream_ids = get_subscribed_stream_ids_for_user(user_profile)\n            recipient_check = Q(id__in=set(subscribed_stream_ids))\n            add_filter_option(recipient_check)\n        if include_public:\n            invite_only_check = Q(invite_only=False)\n            add_filter_option(invite_only_check)\n        if include_web_public:\n            # This should match get_web_public_streams_queryset\n            web_public_check = Q(\n                is_web_public=True,\n                invite_only=False,\n                history_public_to_subscribers=True,\n                deactivated=False,\n            )\n            add_filter_option(web_public_check)\n        if include_owner_subscribed and user_profile.is_bot:\n            bot_owner = user_profile.bot_owner\n            assert bot_owner is not None\n            owner_stream_ids = get_subscribed_stream_ids_for_user(bot_owner)\n            owner_subscribed_check = Q(id__in=set(owner_stream_ids))\n            add_filter_option(owner_subscribed_check)\n\n        if query_filter is not None:\n            query = query.filter(query_filter)\n            streams = Stream.get_client_data(query)\n        else:\n            # Don't bother going to the database with no valid sources\n            streams = []\n\n    streams.sort(key=lambda elt: elt[\"name\"])\n\n    if include_default:\n        is_default = {}\n        default_streams = get_default_streams_for_realm(user_profile.realm_id)\n        for default_stream in default_streams:\n            is_default[default_stream.id] = True\n        for stream in streams:\n            stream[\"is_default\"] = is_default.get(stream[\"stream_id\"], False)\n\n    return streams\n\n\ndef notify_attachment_update(\n    user_profile: UserProfile, op: str, attachment_dict: Dict[str, Any]\n) -> None:\n    event = {\n        \"type\": \"attachment\",\n        \"op\": op,\n        \"attachment\": attachment_dict,\n        \"upload_space_used\": user_profile.realm.currently_used_upload_space_bytes(),\n    }\n    send_event(user_profile.realm, event, [user_profile.id])\n\n\ndef do_claim_attachments(message: Message, potential_path_ids: List[str]) -> bool:\n    claimed = False\n    for path_id in potential_path_ids:\n        user_profile = message.sender\n        is_message_realm_public = False\n        is_message_web_public = False\n        if message.is_stream_message():\n            stream = Stream.objects.get(id=message.recipient.type_id)\n            is_message_realm_public = stream.is_public()\n            is_message_web_public = stream.is_web_public\n\n        if not validate_attachment_request(user_profile, path_id):\n            # Technically, there are 2 cases here:\n            # * The user put something in their message that has the form\n            # of an upload, but doesn't correspond to a file that doesn't\n            # exist.  validate_attachment_request will return None.\n            # * The user is trying to send a link to a file they don't have permission to\n            # access themselves.  validate_attachment_request will return False.\n            #\n            # Either case is unusual and suggests a UI bug that got\n            # the user in this situation, so we log in these cases.\n            logging.warning(\n                \"User %s tried to share upload %s in message %s, but lacks permission\",\n                user_profile.id,\n                path_id,\n                message.id,\n            )\n            continue\n\n        claimed = True\n        attachment = claim_attachment(\n            user_profile, path_id, message, is_message_realm_public, is_message_web_public\n        )\n        notify_attachment_update(user_profile, \"update\", attachment.to_dict())\n    return claimed\n\n\ndef do_delete_old_unclaimed_attachments(weeks_ago: int) -> None:\n    old_unclaimed_attachments = get_old_unclaimed_attachments(weeks_ago)\n\n    for attachment in old_unclaimed_attachments:\n        delete_message_image(attachment.path_id)\n        attachment.delete()\n\n\ndef check_attachment_reference_change(\n    message: Message, rendering_result: MessageRenderingResult\n) -> bool:\n    # For a unsaved message edit (message.* has been updated, but not\n    # saved to the database), adjusts Attachment data to correspond to\n    # the new content.\n    prev_attachments = {a.path_id for a in message.attachment_set.all()}\n    new_attachments = set(rendering_result.potential_attachment_path_ids)\n\n    if new_attachments == prev_attachments:\n        return bool(prev_attachments)\n\n    to_remove = list(prev_attachments - new_attachments)\n    if len(to_remove) > 0:\n        attachments_to_update = Attachment.objects.filter(path_id__in=to_remove).select_for_update()\n        message.attachment_set.remove(*attachments_to_update)\n\n    to_add = list(new_attachments - prev_attachments)\n    if len(to_add) > 0:\n        do_claim_attachments(message, to_add)\n\n    return message.attachment_set.exists()\n\n\ndef notify_realm_custom_profile_fields(realm: Realm) -> None:\n    fields = custom_profile_fields_for_realm(realm.id)\n    event = dict(type=\"custom_profile_fields\", fields=[f.as_dict() for f in fields])\n    send_event(realm, event, active_user_ids(realm.id))\n\n\ndef try_add_realm_default_custom_profile_field(\n    realm: Realm, field_subtype: str\n) -> CustomProfileField:\n    field_data = DEFAULT_EXTERNAL_ACCOUNTS[field_subtype]\n    custom_profile_field = CustomProfileField(\n        realm=realm,\n        name=field_data[\"name\"],\n        field_type=CustomProfileField.EXTERNAL_ACCOUNT,\n        hint=field_data[\"hint\"],\n        field_data=orjson.dumps(dict(subtype=field_subtype)).decode(),\n    )\n    custom_profile_field.save()\n    custom_profile_field.order = custom_profile_field.id\n    custom_profile_field.save(update_fields=[\"order\"])\n    notify_realm_custom_profile_fields(realm)\n    return custom_profile_field\n\n\ndef try_add_realm_custom_profile_field(\n    realm: Realm,\n    name: str,\n    field_type: int,\n    hint: str = \"\",\n    field_data: Optional[ProfileFieldData] = None,\n) -> CustomProfileField:\n    custom_profile_field = CustomProfileField(realm=realm, name=name, field_type=field_type)\n    custom_profile_field.hint = hint\n    if (\n        custom_profile_field.field_type == CustomProfileField.SELECT\n        or custom_profile_field.field_type == CustomProfileField.EXTERNAL_ACCOUNT\n    ):\n        custom_profile_field.field_data = orjson.dumps(field_data or {}).decode()\n\n    custom_profile_field.save()\n    custom_profile_field.order = custom_profile_field.id\n    custom_profile_field.save(update_fields=[\"order\"])\n    notify_realm_custom_profile_fields(realm)\n    return custom_profile_field\n\n\ndef do_remove_realm_custom_profile_field(realm: Realm, field: CustomProfileField) -> None:\n    \"\"\"\n    Deleting a field will also delete the user profile data\n    associated with it in CustomProfileFieldValue model.\n    \"\"\"\n    field.delete()\n    notify_realm_custom_profile_fields(realm)\n\n\ndef do_remove_realm_custom_profile_fields(realm: Realm) -> None:\n    CustomProfileField.objects.filter(realm=realm).delete()\n\n\ndef try_update_realm_custom_profile_field(\n    realm: Realm,\n    field: CustomProfileField,\n    name: str,\n    hint: str = \"\",\n    field_data: Optional[ProfileFieldData] = None,\n) -> None:\n    field.name = name\n    field.hint = hint\n    if (\n        field.field_type == CustomProfileField.SELECT\n        or field.field_type == CustomProfileField.EXTERNAL_ACCOUNT\n    ):\n        field.field_data = orjson.dumps(field_data or {}).decode()\n    field.save()\n    notify_realm_custom_profile_fields(realm)\n\n\ndef try_reorder_realm_custom_profile_fields(realm: Realm, order: List[int]) -> None:\n    order_mapping = {_[1]: _[0] for _ in enumerate(order)}\n    custom_profile_fields = CustomProfileField.objects.filter(realm=realm)\n    for custom_profile_field in custom_profile_fields:\n        if custom_profile_field.id not in order_mapping:\n            raise JsonableError(_(\"Invalid order mapping.\"))\n    for custom_profile_field in custom_profile_fields:\n        custom_profile_field.order = order_mapping[custom_profile_field.id]\n        custom_profile_field.save(update_fields=[\"order\"])\n    notify_realm_custom_profile_fields(realm)\n\n\ndef notify_user_update_custom_profile_data(\n    user_profile: UserProfile, field: Dict[str, Union[int, str, List[int], None]]\n) -> None:\n    data = dict(id=field[\"id\"], value=field[\"value\"])\n\n    if field[\"rendered_value\"]:\n        data[\"rendered_value\"] = field[\"rendered_value\"]\n    payload = dict(user_id=user_profile.id, custom_profile_field=data)\n    event = dict(type=\"realm_user\", op=\"update\", person=payload)\n    send_event(user_profile.realm, event, active_user_ids(user_profile.realm.id))\n\n\ndef do_update_user_custom_profile_data_if_changed(\n    user_profile: UserProfile,\n    data: List[Dict[str, Union[int, ProfileDataElementValue]]],\n) -> None:\n    with transaction.atomic():\n        for custom_profile_field in data:\n            field_value, created = CustomProfileFieldValue.objects.get_or_create(\n                user_profile=user_profile, field_id=custom_profile_field[\"id\"]\n            )\n\n            # field_value.value is a TextField() so we need to have field[\"value\"]\n            # in string form to correctly make comparisons and assignments.\n            if isinstance(custom_profile_field[\"value\"], str):\n                custom_profile_field_value_string = custom_profile_field[\"value\"]\n            else:\n                custom_profile_field_value_string = orjson.dumps(\n                    custom_profile_field[\"value\"]\n                ).decode()\n\n            if not created and field_value.value == custom_profile_field_value_string:\n                # If the field value isn't actually being changed to a different one,\n                # we have nothing to do here for this field.\n                continue\n\n            field_value.value = custom_profile_field_value_string\n            if field_value.field.is_renderable():\n                field_value.rendered_value = render_stream_description(\n                    custom_profile_field_value_string\n                )\n                field_value.save(update_fields=[\"value\", \"rendered_value\"])\n            else:\n                field_value.save(update_fields=[\"value\"])\n            notify_user_update_custom_profile_data(\n                user_profile,\n                {\n                    \"id\": field_value.field_id,\n                    \"value\": field_value.value,\n                    \"rendered_value\": field_value.rendered_value,\n                    \"type\": field_value.field.field_type,\n                },\n            )\n\n\ndef check_remove_custom_profile_field_value(user_profile: UserProfile, field_id: int) -> None:\n    try:\n        custom_profile_field = CustomProfileField.objects.get(realm=user_profile.realm, id=field_id)\n        field_value = CustomProfileFieldValue.objects.get(\n            field=custom_profile_field, user_profile=user_profile\n        )\n        field_value.delete()\n        notify_user_update_custom_profile_data(\n            user_profile,\n            {\n                \"id\": field_id,\n                \"value\": None,\n                \"rendered_value\": None,\n                \"type\": custom_profile_field.field_type,\n            },\n        )\n    except CustomProfileField.DoesNotExist:\n        raise JsonableError(_(\"Field id {id} not found.\").format(id=field_id))\n    except CustomProfileFieldValue.DoesNotExist:\n        pass\n\n\ndef do_send_create_user_group_event(user_group: UserGroup, members: List[UserProfile]) -> None:\n    event = dict(\n        type=\"user_group\",\n        op=\"add\",\n        group=dict(\n            name=user_group.name,\n            members=[member.id for member in members],\n            description=user_group.description,\n            id=user_group.id,\n            is_system_group=user_group.is_system_group,\n        ),\n    )\n    send_event(user_group.realm, event, active_user_ids(user_group.realm_id))\n\n\ndef check_add_user_group(\n    realm: Realm, name: str, initial_members: List[UserProfile], description: str\n) -> None:\n    try:\n        user_group = create_user_group(name, initial_members, realm, description=description)\n        do_send_create_user_group_event(user_group, initial_members)\n    except django.db.utils.IntegrityError:\n        raise JsonableError(_(\"User group '{}' already exists.\").format(name))\n\n\ndef do_send_user_group_update_event(user_group: UserGroup, data: Dict[str, str]) -> None:\n    event = dict(type=\"user_group\", op=\"update\", group_id=user_group.id, data=data)\n    send_event(user_group.realm, event, active_user_ids(user_group.realm_id))\n\n\ndef do_update_user_group_name(user_group: UserGroup, name: str) -> None:\n    try:\n        user_group.name = name\n        user_group.save(update_fields=[\"name\"])\n    except django.db.utils.IntegrityError:\n        raise JsonableError(_(\"User group '{}' already exists.\").format(name))\n    do_send_user_group_update_event(user_group, dict(name=name))\n\n\ndef do_update_user_group_description(user_group: UserGroup, description: str) -> None:\n    user_group.description = description\n    user_group.save(update_fields=[\"description\"])\n    do_send_user_group_update_event(user_group, dict(description=description))\n\n\ndef do_update_outgoing_webhook_service(\n    bot_profile: UserProfile, service_interface: int, service_payload_url: str\n) -> None:\n    # TODO: First service is chosen because currently one bot can only have one service.\n    # Update this once multiple services are supported.\n    service = get_bot_services(bot_profile.id)[0]\n    service.base_url = service_payload_url\n    service.interface = service_interface\n    service.save()\n    send_event(\n        bot_profile.realm,\n        dict(\n            type=\"realm_bot\",\n            op=\"update\",\n            bot=dict(\n                user_id=bot_profile.id,\n                services=[\n                    dict(\n                        base_url=service.base_url, interface=service.interface, token=service.token\n                    )\n                ],\n            ),\n        ),\n        bot_owner_user_ids(bot_profile),\n    )\n\n\ndef do_update_bot_config_data(bot_profile: UserProfile, config_data: Dict[str, str]) -> None:\n    for key, value in config_data.items():\n        set_bot_config(bot_profile, key, value)\n    updated_config_data = get_bot_config(bot_profile)\n    send_event(\n        bot_profile.realm,\n        dict(\n            type=\"realm_bot\",\n            op=\"update\",\n            bot=dict(\n                user_id=bot_profile.id,\n                services=[dict(config_data=updated_config_data)],\n            ),\n        ),\n        bot_owner_user_ids(bot_profile),\n    )\n\n\ndef get_service_dicts_for_bot(user_profile_id: int) -> List[Dict[str, Any]]:\n    user_profile = get_user_profile_by_id(user_profile_id)\n    services = get_bot_services(user_profile_id)\n    service_dicts: List[Dict[str, Any]] = []\n    if user_profile.bot_type == UserProfile.OUTGOING_WEBHOOK_BOT:\n        service_dicts = [\n            {\n                \"base_url\": service.base_url,\n                \"interface\": service.interface,\n                \"token\": service.token,\n            }\n            for service in services\n        ]\n    elif user_profile.bot_type == UserProfile.EMBEDDED_BOT:\n        try:\n            service_dicts = [\n                {\n                    \"config_data\": get_bot_config(user_profile),\n                    \"service_name\": services[0].name,\n                }\n            ]\n        # A ConfigError just means that there are no config entries for user_profile.\n        except ConfigError:\n            pass\n    return service_dicts\n\n\ndef get_service_dicts_for_bots(\n    bot_dicts: List[Dict[str, Any]], realm: Realm\n) -> Dict[int, List[Dict[str, Any]]]:\n    bot_profile_ids = [bot_dict[\"id\"] for bot_dict in bot_dicts]\n    bot_services_by_uid: Dict[int, List[Service]] = defaultdict(list)\n    for service in Service.objects.filter(user_profile_id__in=bot_profile_ids):\n        bot_services_by_uid[service.user_profile_id].append(service)\n\n    embedded_bot_ids = [\n        bot_dict[\"id\"] for bot_dict in bot_dicts if bot_dict[\"bot_type\"] == UserProfile.EMBEDDED_BOT\n    ]\n    embedded_bot_configs = get_bot_configs(embedded_bot_ids)\n\n    service_dicts_by_uid: Dict[int, List[Dict[str, Any]]] = {}\n    for bot_dict in bot_dicts:\n        bot_profile_id = bot_dict[\"id\"]\n        bot_type = bot_dict[\"bot_type\"]\n        services = bot_services_by_uid[bot_profile_id]\n        service_dicts: List[Dict[str, Any]] = []\n        if bot_type == UserProfile.OUTGOING_WEBHOOK_BOT:\n            service_dicts = [\n                {\n                    \"base_url\": service.base_url,\n                    \"interface\": service.interface,\n                    \"token\": service.token,\n                }\n                for service in services\n            ]\n        elif bot_type == UserProfile.EMBEDDED_BOT:\n            if bot_profile_id in embedded_bot_configs.keys():\n                bot_config = embedded_bot_configs[bot_profile_id]\n                service_dicts = [\n                    {\n                        \"config_data\": bot_config,\n                        \"service_name\": services[0].name,\n                    }\n                ]\n        service_dicts_by_uid[bot_profile_id] = service_dicts\n    return service_dicts_by_uid\n\n\ndef get_owned_bot_dicts(\n    user_profile: UserProfile, include_all_realm_bots_if_admin: bool = True\n) -> List[Dict[str, Any]]:\n    if user_profile.is_realm_admin and include_all_realm_bots_if_admin:\n        result = get_bot_dicts_in_realm(user_profile.realm)\n    else:\n        result = UserProfile.objects.filter(\n            realm=user_profile.realm, is_bot=True, bot_owner=user_profile\n        ).values(*bot_dict_fields)\n    services_by_ids = get_service_dicts_for_bots(result, user_profile.realm)\n    return [\n        {\n            \"email\": botdict[\"email\"],\n            \"user_id\": botdict[\"id\"],\n            \"full_name\": botdict[\"full_name\"],\n            \"bot_type\": botdict[\"bot_type\"],\n            \"is_active\": botdict[\"is_active\"],\n            \"api_key\": botdict[\"api_key\"],\n            \"default_sending_stream\": botdict[\"default_sending_stream__name\"],\n            \"default_events_register_stream\": botdict[\"default_events_register_stream__name\"],\n            \"default_all_public_streams\": botdict[\"default_all_public_streams\"],\n            \"owner_id\": botdict[\"bot_owner_id\"],\n            \"avatar_url\": avatar_url_from_dict(botdict),\n            \"services\": services_by_ids[botdict[\"id\"]],\n        }\n        for botdict in result\n    ]\n\n\ndef do_send_user_group_members_update_event(\n    event_name: str, user_group: UserGroup, user_ids: List[int]\n) -> None:\n    event = dict(type=\"user_group\", op=event_name, group_id=user_group.id, user_ids=user_ids)\n    transaction.on_commit(\n        lambda: send_event(user_group.realm, event, active_user_ids(user_group.realm_id))\n    )\n\n\n@transaction.atomic(savepoint=False)\ndef bulk_add_members_to_user_group(user_group: UserGroup, user_profile_ids: List[int]) -> None:\n    memberships = [\n        UserGroupMembership(user_group_id=user_group.id, user_profile_id=user_id)\n        for user_id in user_profile_ids\n    ]\n    UserGroupMembership.objects.bulk_create(memberships)\n\n    do_send_user_group_members_update_event(\"add_members\", user_group, user_profile_ids)\n\n\n@transaction.atomic(savepoint=False)\ndef remove_members_from_user_group(user_group: UserGroup, user_profile_ids: List[int]) -> None:\n    UserGroupMembership.objects.filter(\n        user_group_id=user_group.id, user_profile_id__in=user_profile_ids\n    ).delete()\n\n    do_send_user_group_members_update_event(\"remove_members\", user_group, user_profile_ids)\n\n\ndef do_send_delete_user_group_event(realm: Realm, user_group_id: int, realm_id: int) -> None:\n    event = dict(type=\"user_group\", op=\"remove\", group_id=user_group_id)\n    send_event(realm, event, active_user_ids(realm_id))\n\n\ndef check_delete_user_group(user_group_id: int, user_profile: UserProfile) -> None:\n    user_group = access_user_group_by_id(user_group_id, user_profile)\n    user_group.delete()\n    do_send_delete_user_group_event(user_profile.realm, user_group_id, user_profile.realm.id)\n\n\ndef do_send_realm_reactivation_email(realm: Realm, *, acting_user: Optional[UserProfile]) -> None:\n    url = create_confirmation_link(realm, Confirmation.REALM_REACTIVATION)\n    RealmAuditLog.objects.create(\n        realm=realm,\n        acting_user=acting_user,\n        event_type=RealmAuditLog.REALM_REACTIVATION_EMAIL_SENT,\n        event_time=timezone_now(),\n    )\n    context = {\"confirmation_url\": url, \"realm_uri\": realm.uri, \"realm_name\": realm.name}\n    language = realm.default_language\n    send_email_to_admins(\n        \"zerver/emails/realm_reactivation\",\n        realm,\n        from_address=FromAddress.tokenized_no_reply_address(),\n        from_name=FromAddress.security_email_from_name(language=language),\n        language=language,\n        context=context,\n    )\n\n\ndef do_set_zoom_token(user: UserProfile, token: Optional[Dict[str, object]]) -> None:\n    user.zoom_token = token\n    user.save(update_fields=[\"zoom_token\"])\n    send_event(\n        user.realm,\n        dict(type=\"has_zoom_token\", value=token is not None),\n        [user.id],\n    )\n\n\ndef notify_realm_export(user_profile: UserProfile) -> None:\n    # In the future, we may want to send this event to all realm admins.\n    event = dict(type=\"realm_export\", exports=get_realm_exports_serialized(user_profile))\n    send_event(user_profile.realm, event, [user_profile.id])\n\n\ndef do_delete_realm_export(user_profile: UserProfile, export: RealmAuditLog) -> None:\n    # Give mypy a hint so it knows `orjson.loads`\n    # isn't being passed an `Optional[str]`.\n    export_extra_data = export.extra_data\n    assert export_extra_data is not None\n    export_data = orjson.loads(export_extra_data)\n    export_path = export_data.get(\"export_path\")\n\n    if export_path:\n        # Allow removal even if the export failed.\n        delete_export_tarball(export_path)\n\n    export_data.update(deleted_timestamp=timezone_now().timestamp())\n    export.extra_data = orjson.dumps(export_data).decode()\n    export.save(update_fields=[\"extra_data\"])\n    notify_realm_export(user_profile)\n\n\ndef get_topic_messages(user_profile: UserProfile, stream: Stream, topic_name: str) -> List[Message]:\n    query = UserMessage.objects.filter(\n        user_profile=user_profile,\n        message__recipient=stream.recipient,\n    ).order_by(\"id\")\n    return [um.message for um in filter_by_topic_name_via_message(query, topic_name)]\n", "import datetime\nfrom email.headerregistry import Address\nfrom typing import Any, Dict, Iterable, List, Mapping, Optional, TypeVar, Union\nfrom unittest import mock\n\nimport orjson\nfrom django.conf import settings\nfrom django.contrib.contenttypes.models import ContentType\nfrom django.contrib.sessions.models import Session\nfrom django.core.exceptions import ValidationError\nfrom django.test import override_settings\nfrom django.utils.timezone import now as timezone_now\n\nfrom confirmation.models import Confirmation\nfrom zerver.lib.actions import (\n    change_user_is_active,\n    create_users,\n    do_change_can_create_users,\n    do_change_user_role,\n    do_create_multiuse_invite_link,\n    do_create_user,\n    do_deactivate_user,\n    do_delete_user,\n    do_invite_users,\n    do_mute_user,\n    do_reactivate_user,\n    do_set_realm_property,\n    get_recipient_info,\n)\nfrom zerver.lib.avatar import avatar_url, get_gravatar_url\nfrom zerver.lib.create_user import copy_default_settings\nfrom zerver.lib.events import do_events_register\nfrom zerver.lib.exceptions import JsonableError\nfrom zerver.lib.send_email import (\n    clear_scheduled_emails,\n    deliver_scheduled_emails,\n    send_future_email,\n)\nfrom zerver.lib.stream_topic import StreamTopicTarget\nfrom zerver.lib.test_classes import ZulipTestCase\nfrom zerver.lib.test_helpers import (\n    cache_tries_captured,\n    get_subscription,\n    get_test_image_file,\n    queries_captured,\n    reset_emails_in_zulip_realm,\n    simulated_empty_cache,\n)\nfrom zerver.lib.upload import upload_avatar_image\nfrom zerver.lib.user_groups import get_system_user_group_for_user\nfrom zerver.lib.user_topics import add_topic_mute\nfrom zerver.lib.users import Accounts, access_user_by_id, get_accounts_for_email, user_ids_to_users\nfrom zerver.lib.utils import assert_is_not_none\nfrom zerver.models import (\n    CustomProfileField,\n    InvalidFakeEmailDomain,\n    Message,\n    PreregistrationUser,\n    Realm,\n    RealmDomain,\n    RealmUserDefault,\n    Recipient,\n    ScheduledEmail,\n    Stream,\n    Subscription,\n    UserGroupMembership,\n    UserHotspot,\n    UserProfile,\n    check_valid_user_ids,\n    filter_to_valid_prereg_users,\n    get_client,\n    get_fake_email_domain,\n    get_realm,\n    get_source_profile,\n    get_stream,\n    get_system_bot,\n    get_user,\n    get_user_by_delivery_email,\n    get_user_by_id_in_realm_including_cross_realm,\n)\n\nK = TypeVar(\"K\")\nV = TypeVar(\"V\")\n\n\ndef find_dict(lst: Iterable[Dict[K, V]], k: K, v: V) -> Dict[K, V]:\n    for dct in lst:\n        if dct[k] == v:\n            return dct\n    raise AssertionError(f\"Cannot find element in list where key {k} == {v}\")\n\n\nclass PermissionTest(ZulipTestCase):\n    def test_role_setters(self) -> None:\n        user_profile = self.example_user(\"hamlet\")\n\n        user_profile.is_realm_admin = True\n        self.assertEqual(user_profile.is_realm_admin, True)\n        self.assertEqual(user_profile.role, UserProfile.ROLE_REALM_ADMINISTRATOR)\n\n        user_profile.is_guest = False\n        self.assertEqual(user_profile.is_guest, False)\n        self.assertEqual(user_profile.role, UserProfile.ROLE_REALM_ADMINISTRATOR)\n\n        user_profile.is_realm_owner = False\n        self.assertEqual(user_profile.is_realm_owner, False)\n        self.assertEqual(user_profile.role, UserProfile.ROLE_REALM_ADMINISTRATOR)\n\n        user_profile.is_moderator = False\n        self.assertEqual(user_profile.is_moderator, False)\n        self.assertEqual(user_profile.role, UserProfile.ROLE_REALM_ADMINISTRATOR)\n\n        user_profile.is_realm_admin = False\n        self.assertEqual(user_profile.is_realm_admin, False)\n        self.assertEqual(user_profile.role, UserProfile.ROLE_MEMBER)\n\n        user_profile.is_guest = True\n        self.assertEqual(user_profile.is_guest, True)\n        self.assertEqual(user_profile.role, UserProfile.ROLE_GUEST)\n\n        user_profile.is_realm_admin = False\n        self.assertEqual(user_profile.is_guest, True)\n        self.assertEqual(user_profile.role, UserProfile.ROLE_GUEST)\n\n        user_profile.is_guest = False\n        self.assertEqual(user_profile.is_guest, False)\n        self.assertEqual(user_profile.role, UserProfile.ROLE_MEMBER)\n\n        user_profile.is_realm_owner = True\n        self.assertEqual(user_profile.is_realm_owner, True)\n        self.assertEqual(user_profile.role, UserProfile.ROLE_REALM_OWNER)\n\n        user_profile.is_realm_owner = False\n        self.assertEqual(user_profile.is_realm_owner, False)\n        self.assertEqual(user_profile.role, UserProfile.ROLE_MEMBER)\n\n        user_profile.is_moderator = True\n        self.assertEqual(user_profile.is_moderator, True)\n        self.assertEqual(user_profile.role, UserProfile.ROLE_MODERATOR)\n\n        user_profile.is_moderator = False\n        self.assertEqual(user_profile.is_moderator, False)\n        self.assertEqual(user_profile.role, UserProfile.ROLE_MEMBER)\n\n    def test_get_admin_users(self) -> None:\n        user_profile = self.example_user(\"hamlet\")\n        do_change_user_role(user_profile, UserProfile.ROLE_MEMBER, acting_user=None)\n        self.assertFalse(user_profile.is_realm_owner)\n        admin_users = user_profile.realm.get_human_admin_users()\n        self.assertFalse(user_profile in admin_users)\n        admin_users = user_profile.realm.get_admin_users_and_bots()\n        self.assertFalse(user_profile in admin_users)\n\n        do_change_user_role(user_profile, UserProfile.ROLE_REALM_ADMINISTRATOR, acting_user=None)\n        self.assertFalse(user_profile.is_realm_owner)\n        admin_users = user_profile.realm.get_human_admin_users()\n        self.assertTrue(user_profile in admin_users)\n        admin_users = user_profile.realm.get_admin_users_and_bots()\n        self.assertTrue(user_profile in admin_users)\n\n        do_change_user_role(user_profile, UserProfile.ROLE_REALM_OWNER, acting_user=None)\n        self.assertTrue(user_profile.is_realm_owner)\n        admin_users = user_profile.realm.get_human_admin_users()\n        self.assertTrue(user_profile in admin_users)\n        admin_users = user_profile.realm.get_human_admin_users(include_realm_owners=False)\n        self.assertFalse(user_profile in admin_users)\n        admin_users = user_profile.realm.get_admin_users_and_bots()\n        self.assertTrue(user_profile in admin_users)\n        admin_users = user_profile.realm.get_admin_users_and_bots(include_realm_owners=False)\n        self.assertFalse(user_profile in admin_users)\n\n    def test_get_first_human_user(self) -> None:\n        realm = get_realm(\"zulip\")\n        UserProfile.objects.filter(realm=realm).delete()\n\n        UserProfile.objects.create(\n            realm=realm, email=\"bot1@zulip.com\", delivery_email=\"bot1@zulip.com\", is_bot=True\n        )\n        first_human_user = UserProfile.objects.create(\n            realm=realm, email=\"user1@zulip.com\", delivery_email=\"user1@zulip.com\", is_bot=False\n        )\n        UserProfile.objects.create(\n            realm=realm, email=\"user2@zulip.com\", delivery_email=\"user2@zulip.com\", is_bot=False\n        )\n        UserProfile.objects.create(\n            realm=realm, email=\"bot2@zulip.com\", delivery_email=\"bot2@zulip.com\", is_bot=True\n        )\n        self.assertEqual(first_human_user, realm.get_first_human_user())\n\n    def test_updating_non_existent_user(self) -> None:\n        self.login(\"hamlet\")\n        admin = self.example_user(\"hamlet\")\n        do_change_user_role(admin, UserProfile.ROLE_REALM_ADMINISTRATOR, acting_user=None)\n\n        invalid_user_id = 1000\n        result = self.client_patch(f\"/json/users/{invalid_user_id}\", {})\n        self.assert_json_error(result, \"No such user\")\n\n    def test_owner_api(self) -> None:\n        self.login(\"iago\")\n\n        desdemona = self.example_user(\"desdemona\")\n        othello = self.example_user(\"othello\")\n        iago = self.example_user(\"iago\")\n        realm = iago.realm\n\n        do_change_user_role(iago, UserProfile.ROLE_REALM_OWNER, acting_user=None)\n\n        result = self.client_get(\"/json/users\")\n        self.assert_json_success(result)\n        members = result.json()[\"members\"]\n        iago_dict = find_dict(members, \"email\", iago.email)\n        self.assertTrue(iago_dict[\"is_owner\"])\n        othello_dict = find_dict(members, \"email\", othello.email)\n        self.assertFalse(othello_dict[\"is_owner\"])\n\n        req = dict(role=UserProfile.ROLE_REALM_OWNER)\n        events: List[Mapping[str, Any]] = []\n        with self.tornado_redirected_to_list(events, expected_num_events=4):\n            result = self.client_patch(f\"/json/users/{othello.id}\", req)\n        self.assert_json_success(result)\n        owner_users = realm.get_human_owner_users()\n        self.assertTrue(othello in owner_users)\n        person = events[0][\"event\"][\"person\"]\n        self.assertEqual(person[\"user_id\"], othello.id)\n        self.assertEqual(person[\"role\"], UserProfile.ROLE_REALM_OWNER)\n\n        req = dict(role=UserProfile.ROLE_MEMBER)\n        with self.tornado_redirected_to_list(events, expected_num_events=4):\n            result = self.client_patch(f\"/json/users/{othello.id}\", req)\n        self.assert_json_success(result)\n        owner_users = realm.get_human_owner_users()\n        self.assertFalse(othello in owner_users)\n        person = events[0][\"event\"][\"person\"]\n        self.assertEqual(person[\"user_id\"], othello.id)\n        self.assertEqual(person[\"role\"], UserProfile.ROLE_MEMBER)\n\n        # Cannot take away from last owner\n        self.login(\"desdemona\")\n        req = dict(role=UserProfile.ROLE_MEMBER)\n        with self.tornado_redirected_to_list(events, expected_num_events=4):\n            result = self.client_patch(f\"/json/users/{iago.id}\", req)\n        self.assert_json_success(result)\n        owner_users = realm.get_human_owner_users()\n        self.assertFalse(iago in owner_users)\n        person = events[0][\"event\"][\"person\"]\n        self.assertEqual(person[\"user_id\"], iago.id)\n        self.assertEqual(person[\"role\"], UserProfile.ROLE_MEMBER)\n        with self.tornado_redirected_to_list([], expected_num_events=0):\n            result = self.client_patch(f\"/json/users/{desdemona.id}\", req)\n        self.assert_json_error(\n            result, \"The owner permission cannot be removed from the only organization owner.\"\n        )\n\n        do_change_user_role(iago, UserProfile.ROLE_REALM_ADMINISTRATOR, acting_user=None)\n        self.login(\"iago\")\n        with self.tornado_redirected_to_list([], expected_num_events=0):\n            result = self.client_patch(f\"/json/users/{desdemona.id}\", req)\n        self.assert_json_error(result, \"Must be an organization owner\")\n\n    def test_admin_api(self) -> None:\n        self.login(\"desdemona\")\n\n        hamlet = self.example_user(\"hamlet\")\n        othello = self.example_user(\"othello\")\n        desdemona = self.example_user(\"desdemona\")\n        realm = hamlet.realm\n\n        # Make sure we see is_admin flag in /json/users\n        result = self.client_get(\"/json/users\")\n        self.assert_json_success(result)\n        members = result.json()[\"members\"]\n        desdemona_dict = find_dict(members, \"email\", desdemona.email)\n        self.assertTrue(desdemona_dict[\"is_admin\"])\n        othello_dict = find_dict(members, \"email\", othello.email)\n        self.assertFalse(othello_dict[\"is_admin\"])\n\n        # Giveth\n        req = dict(role=orjson.dumps(UserProfile.ROLE_REALM_ADMINISTRATOR).decode())\n\n        events: List[Mapping[str, Any]] = []\n        with self.tornado_redirected_to_list(events, expected_num_events=4):\n            result = self.client_patch(f\"/json/users/{othello.id}\", req)\n        self.assert_json_success(result)\n        admin_users = realm.get_human_admin_users()\n        self.assertTrue(othello in admin_users)\n        person = events[0][\"event\"][\"person\"]\n        self.assertEqual(person[\"user_id\"], othello.id)\n        self.assertEqual(person[\"role\"], UserProfile.ROLE_REALM_ADMINISTRATOR)\n\n        # Taketh away\n        req = dict(role=orjson.dumps(UserProfile.ROLE_MEMBER).decode())\n        with self.tornado_redirected_to_list(events, expected_num_events=4):\n            result = self.client_patch(f\"/json/users/{othello.id}\", req)\n        self.assert_json_success(result)\n        admin_users = realm.get_human_admin_users()\n        self.assertFalse(othello in admin_users)\n        person = events[0][\"event\"][\"person\"]\n        self.assertEqual(person[\"user_id\"], othello.id)\n        self.assertEqual(person[\"role\"], UserProfile.ROLE_MEMBER)\n\n        # Make sure only admins can patch other user's info.\n        self.login(\"othello\")\n        result = self.client_patch(f\"/json/users/{hamlet.id}\", req)\n        self.assert_json_error(result, \"Insufficient permission\")\n\n    def test_admin_api_hide_emails(self) -> None:\n        reset_emails_in_zulip_realm()\n\n        user = self.example_user(\"hamlet\")\n        admin = self.example_user(\"iago\")\n        self.login_user(user)\n\n        # First, verify client_gravatar works normally\n        result = self.client_get(\"/json/users\", {\"client_gravatar\": \"true\"})\n        self.assert_json_success(result)\n        members = result.json()[\"members\"]\n        hamlet = find_dict(members, \"user_id\", user.id)\n        self.assertEqual(hamlet[\"email\"], user.email)\n        self.assertIsNone(hamlet[\"avatar_url\"])\n        self.assertNotIn(\"delivery_email\", hamlet)\n\n        # Also verify the /events code path.  This is a bit hacky, but\n        # we need to verify client_gravatar is not being overridden.\n        with mock.patch(\n            \"zerver.lib.events.request_event_queue\", return_value=None\n        ) as mock_request_event_queue:\n            with self.assertRaises(JsonableError):\n                do_events_register(user, get_client(\"website\"), client_gravatar=True)\n            self.assertEqual(mock_request_event_queue.call_args_list[0][0][3], True)\n\n        #############################################################\n        # Now, switch email address visibility, check client_gravatar\n        # is automatically disabled for the user.\n        with self.captureOnCommitCallbacks(execute=True):\n            do_set_realm_property(\n                user.realm,\n                \"email_address_visibility\",\n                Realm.EMAIL_ADDRESS_VISIBILITY_ADMINS,\n                acting_user=None,\n            )\n        result = self.client_get(\"/json/users\", {\"client_gravatar\": \"true\"})\n        self.assert_json_success(result)\n        members = result.json()[\"members\"]\n        hamlet = find_dict(members, \"user_id\", user.id)\n        self.assertEqual(hamlet[\"email\"], f\"user{user.id}@zulip.testserver\")\n        # Note that the Gravatar URL should still be computed from the\n        # `delivery_email`; otherwise, we won't be able to serve the\n        # user's Gravatar.\n        self.assertEqual(hamlet[\"avatar_url\"], get_gravatar_url(user.delivery_email, 1))\n        self.assertNotIn(\"delivery_email\", hamlet)\n\n        # Also verify the /events code path.  This is a bit hacky, but\n        # basically we want to verify client_gravatar is being\n        # overridden.\n        with mock.patch(\n            \"zerver.lib.events.request_event_queue\", return_value=None\n        ) as mock_request_event_queue:\n            with self.assertRaises(JsonableError):\n                do_events_register(user, get_client(\"website\"), client_gravatar=True)\n            self.assertEqual(mock_request_event_queue.call_args_list[0][0][3], False)\n\n        # client_gravatar is still turned off for admins.  In theory,\n        # it doesn't need to be, but client-side changes would be\n        # required in apps like the mobile apps.\n        # delivery_email is sent for admins.\n        admin.refresh_from_db()\n        user.refresh_from_db()\n        self.login_user(admin)\n        result = self.client_get(\"/json/users\", {\"client_gravatar\": \"true\"})\n        self.assert_json_success(result)\n        members = result.json()[\"members\"]\n        hamlet = find_dict(members, \"user_id\", user.id)\n        self.assertEqual(hamlet[\"email\"], f\"user{user.id}@zulip.testserver\")\n        self.assertEqual(hamlet[\"avatar_url\"], get_gravatar_url(user.delivery_email, 1))\n        self.assertEqual(hamlet[\"delivery_email\"], self.example_email(\"hamlet\"))\n\n    def test_user_cannot_promote_to_admin(self) -> None:\n        self.login(\"hamlet\")\n        req = dict(role=orjson.dumps(UserProfile.ROLE_REALM_ADMINISTRATOR).decode())\n        result = self.client_patch(\"/json/users/{}\".format(self.example_user(\"hamlet\").id), req)\n        self.assert_json_error(result, \"Insufficient permission\")\n\n    def test_admin_user_can_change_full_name(self) -> None:\n        new_name = \"new name\"\n        self.login(\"iago\")\n        hamlet = self.example_user(\"hamlet\")\n        req = dict(full_name=new_name)\n        result = self.client_patch(f\"/json/users/{hamlet.id}\", req)\n        self.assert_json_success(result)\n        hamlet = self.example_user(\"hamlet\")\n        self.assertEqual(hamlet.full_name, new_name)\n\n    def test_non_admin_cannot_change_full_name(self) -> None:\n        self.login(\"hamlet\")\n        req = dict(full_name=\"new name\")\n        result = self.client_patch(\"/json/users/{}\".format(self.example_user(\"othello\").id), req)\n        self.assert_json_error(result, \"Insufficient permission\")\n\n    def test_admin_cannot_set_long_full_name(self) -> None:\n        new_name = \"a\" * (UserProfile.MAX_NAME_LENGTH + 1)\n        self.login(\"iago\")\n        req = dict(full_name=new_name)\n        result = self.client_patch(\"/json/users/{}\".format(self.example_user(\"hamlet\").id), req)\n        self.assert_json_error(result, \"Name too long!\")\n\n    def test_admin_cannot_set_short_full_name(self) -> None:\n        new_name = \"a\"\n        self.login(\"iago\")\n        req = dict(full_name=new_name)\n        result = self.client_patch(\"/json/users/{}\".format(self.example_user(\"hamlet\").id), req)\n        self.assert_json_error(result, \"Name too short!\")\n\n    def test_not_allowed_format(self) -> None:\n        # Name of format \"Alice|999\" breaks in Markdown\n        new_name = \"iago|72\"\n        self.login(\"iago\")\n        req = dict(full_name=new_name)\n        result = self.client_patch(\"/json/users/{}\".format(self.example_user(\"hamlet\").id), req)\n        self.assert_json_error(result, \"Invalid format!\")\n\n    def test_allowed_format_complex(self) -> None:\n        # Adding characters after r'|d+' doesn't break Markdown\n        new_name = \"Hello- 12iago|72k\"\n        self.login(\"iago\")\n        req = dict(full_name=new_name)\n        result = self.client_patch(\"/json/users/{}\".format(self.example_user(\"hamlet\").id), req)\n        self.assert_json_success(result)\n\n    def test_not_allowed_format_complex(self) -> None:\n        new_name = \"Hello- 12iago|72\"\n        self.login(\"iago\")\n        req = dict(full_name=new_name)\n        result = self.client_patch(\"/json/users/{}\".format(self.example_user(\"hamlet\").id), req)\n        self.assert_json_error(result, \"Invalid format!\")\n\n    def test_admin_cannot_set_full_name_with_invalid_characters(self) -> None:\n        new_name = \"Opheli*\"\n        self.login(\"iago\")\n        req = dict(full_name=new_name)\n        result = self.client_patch(\"/json/users/{}\".format(self.example_user(\"hamlet\").id), req)\n        self.assert_json_error(result, \"Invalid characters in name!\")\n\n    def test_access_user_by_id(self) -> None:\n        iago = self.example_user(\"iago\")\n\n        # Must be a valid user ID in the realm\n        with self.assertRaises(JsonableError):\n            access_user_by_id(iago, 1234, for_admin=False)\n        with self.assertRaises(JsonableError):\n            access_user_by_id(iago, self.mit_user(\"sipbtest\").id, for_admin=False)\n\n        # Can only access bot users if allow_bots is passed\n        bot = self.example_user(\"default_bot\")\n        access_user_by_id(iago, bot.id, allow_bots=True, for_admin=True)\n        with self.assertRaises(JsonableError):\n            access_user_by_id(iago, bot.id, for_admin=True)\n\n        # Can only access deactivated users if allow_deactivated is passed\n        hamlet = self.example_user(\"hamlet\")\n        do_deactivate_user(hamlet, acting_user=None)\n        with self.assertRaises(JsonableError):\n            access_user_by_id(iago, hamlet.id, for_admin=False)\n        with self.assertRaises(JsonableError):\n            access_user_by_id(iago, hamlet.id, for_admin=True)\n        access_user_by_id(iago, hamlet.id, allow_deactivated=True, for_admin=True)\n\n        # Non-admin user can't admin another user\n        with self.assertRaises(JsonableError):\n            access_user_by_id(\n                self.example_user(\"cordelia\"), self.example_user(\"aaron\").id, for_admin=True\n            )\n        # But does have read-only access to it.\n        access_user_by_id(\n            self.example_user(\"cordelia\"), self.example_user(\"aaron\").id, for_admin=False\n        )\n\n    def check_property_for_role(self, user_profile: UserProfile, role: int) -> bool:\n        if role == UserProfile.ROLE_REALM_ADMINISTRATOR:\n            return (\n                user_profile.is_realm_admin\n                and not user_profile.is_guest\n                and not user_profile.is_realm_owner\n                and not user_profile.is_moderator\n            )\n        elif role == UserProfile.ROLE_REALM_OWNER:\n            return (\n                user_profile.is_realm_owner\n                and user_profile.is_realm_admin\n                and not user_profile.is_moderator\n                and not user_profile.is_guest\n            )\n        elif role == UserProfile.ROLE_MODERATOR:\n            return (\n                user_profile.is_moderator\n                and not user_profile.is_realm_owner\n                and not user_profile.is_realm_admin\n                and not user_profile.is_guest\n            )\n\n        if role == UserProfile.ROLE_MEMBER:\n            return (\n                not user_profile.is_guest\n                and not user_profile.is_moderator\n                and not user_profile.is_realm_admin\n                and not user_profile.is_realm_owner\n            )\n\n        assert role == UserProfile.ROLE_GUEST\n        return (\n            user_profile.is_guest\n            and not user_profile.is_moderator\n            and not user_profile.is_realm_admin\n            and not user_profile.is_realm_owner\n        )\n\n    def check_user_role_change(\n        self,\n        user_email: str,\n        new_role: int,\n    ) -> None:\n        self.login(\"desdemona\")\n\n        user_profile = self.example_user(user_email)\n        old_role = user_profile.role\n        old_system_group = get_system_user_group_for_user(user_profile)\n\n        self.assertTrue(self.check_property_for_role(user_profile, old_role))\n        self.assertTrue(\n            UserGroupMembership.objects.filter(\n                user_profile=user_profile, user_group=old_system_group\n            ).exists()\n        )\n\n        req = dict(role=orjson.dumps(new_role).decode())\n        events: List[Mapping[str, Any]] = []\n        num_events = 3\n        if UserProfile.ROLE_MEMBER in [old_role, new_role]:\n            num_events = 4\n        with self.tornado_redirected_to_list(events, expected_num_events=num_events):\n            result = self.client_patch(f\"/json/users/{user_profile.id}\", req)\n        self.assert_json_success(result)\n\n        user_profile = self.example_user(user_email)\n        self.assertTrue(self.check_property_for_role(user_profile, new_role))\n        system_group = get_system_user_group_for_user(user_profile)\n        self.assertTrue(\n            UserGroupMembership.objects.filter(\n                user_profile=user_profile, user_group=system_group\n            ).exists()\n        )\n\n        person = events[0][\"event\"][\"person\"]\n        self.assertEqual(person[\"user_id\"], user_profile.id)\n        self.assertTrue(person[\"role\"], new_role)\n\n    def test_change_regular_member_to_guest(self) -> None:\n        self.check_user_role_change(\"hamlet\", UserProfile.ROLE_GUEST)\n\n    def test_change_guest_to_regular_member(self) -> None:\n        self.check_user_role_change(\"polonius\", UserProfile.ROLE_MEMBER)\n\n    def test_change_admin_to_guest(self) -> None:\n        self.check_user_role_change(\"iago\", UserProfile.ROLE_GUEST)\n\n    def test_change_guest_to_admin(self) -> None:\n        self.check_user_role_change(\"polonius\", UserProfile.ROLE_REALM_ADMINISTRATOR)\n\n    def test_change_owner_to_guest(self) -> None:\n        self.login(\"desdemona\")\n        iago = self.example_user(\"iago\")\n        do_change_user_role(iago, UserProfile.ROLE_REALM_OWNER, acting_user=None)\n        self.check_user_role_change(\"iago\", UserProfile.ROLE_GUEST)\n\n    def test_change_guest_to_owner(self) -> None:\n        self.check_user_role_change(\"polonius\", UserProfile.ROLE_REALM_OWNER)\n\n    def test_change_admin_to_owner(self) -> None:\n        self.check_user_role_change(\"iago\", UserProfile.ROLE_REALM_OWNER)\n\n    def test_change_owner_to_admin(self) -> None:\n        self.login(\"desdemona\")\n        iago = self.example_user(\"iago\")\n        do_change_user_role(iago, UserProfile.ROLE_REALM_OWNER, acting_user=None)\n        self.check_user_role_change(\"iago\", UserProfile.ROLE_REALM_ADMINISTRATOR)\n\n    def test_change_owner_to_moderator(self) -> None:\n        iago = self.example_user(\"iago\")\n        do_change_user_role(iago, UserProfile.ROLE_REALM_OWNER, acting_user=None)\n        self.check_user_role_change(\"iago\", UserProfile.ROLE_MODERATOR)\n\n    def test_change_moderator_to_owner(self) -> None:\n        self.check_user_role_change(\"shiva\", UserProfile.ROLE_REALM_OWNER)\n\n    def test_change_admin_to_moderator(self) -> None:\n        self.check_user_role_change(\"iago\", UserProfile.ROLE_MODERATOR)\n\n    def test_change_moderator_to_admin(self) -> None:\n        self.check_user_role_change(\"shiva\", UserProfile.ROLE_REALM_ADMINISTRATOR)\n\n    def test_change_guest_to_moderator(self) -> None:\n        self.check_user_role_change(\"polonius\", UserProfile.ROLE_MODERATOR)\n\n    def test_change_moderator_to_guest(self) -> None:\n        self.check_user_role_change(\"shiva\", UserProfile.ROLE_GUEST)\n\n    def test_admin_user_can_change_profile_data(self) -> None:\n        realm = get_realm(\"zulip\")\n        self.login(\"iago\")\n        new_profile_data = []\n        cordelia = self.example_user(\"cordelia\")\n\n        # Test for all type of data\n        fields = {\n            \"Phone number\": \"short text data\",\n            \"Biography\": \"long text data\",\n            \"Favorite food\": \"short text data\",\n            \"Favorite editor\": \"vim\",\n            \"Birthday\": \"1909-03-05\",\n            \"Favorite website\": \"https://zulip.com\",\n            \"Mentor\": [cordelia.id],\n            \"GitHub\": \"timabbott\",\n        }\n\n        for field_name in fields:\n            field = CustomProfileField.objects.get(name=field_name, realm=realm)\n            new_profile_data.append(\n                {\n                    \"id\": field.id,\n                    \"value\": fields[field_name],\n                }\n            )\n\n        result = self.client_patch(\n            f\"/json/users/{cordelia.id}\", {\"profile_data\": orjson.dumps(new_profile_data).decode()}\n        )\n        self.assert_json_success(result)\n\n        cordelia = self.example_user(\"cordelia\")\n        for field_dict in cordelia.profile_data():\n            with self.subTest(field_name=field_dict[\"name\"]):\n                self.assertEqual(field_dict[\"value\"], fields[field_dict[\"name\"]])\n\n        # Test admin user cannot set invalid profile data\n        invalid_fields = [\n            (\n                \"Favorite editor\",\n                \"invalid choice\",\n                \"'invalid choice' is not a valid choice for 'Favorite editor'.\",\n            ),\n            (\"Birthday\", \"1909-34-55\", \"Birthday is not a date\"),\n            (\"Favorite website\", \"not url\", \"Favorite website is not a URL\"),\n            (\"Mentor\", \"not list of user ids\", \"User IDs is not a list\"),\n        ]\n\n        for field_name, field_value, error_msg in invalid_fields:\n            new_profile_data = []\n            field = CustomProfileField.objects.get(name=field_name, realm=realm)\n            new_profile_data.append(\n                {\n                    \"id\": field.id,\n                    \"value\": field_value,\n                }\n            )\n\n            result = self.client_patch(\n                f\"/json/users/{cordelia.id}\",\n                {\"profile_data\": orjson.dumps(new_profile_data).decode()},\n            )\n            self.assert_json_error(result, error_msg)\n\n        # non-existent field and no data\n        invalid_profile_data = [\n            {\n                \"id\": 9001,\n                \"value\": \"\",\n            }\n        ]\n        result = self.client_patch(\n            f\"/json/users/{cordelia.id}\",\n            {\"profile_data\": orjson.dumps(invalid_profile_data).decode()},\n        )\n        self.assert_json_error(result, \"Field id 9001 not found.\")\n\n        # non-existent field and data\n        invalid_profile_data = [\n            {\n                \"id\": 9001,\n                \"value\": \"some data\",\n            }\n        ]\n        result = self.client_patch(\n            f\"/json/users/{cordelia.id}\",\n            {\"profile_data\": orjson.dumps(invalid_profile_data).decode()},\n        )\n        self.assert_json_error(result, \"Field id 9001 not found.\")\n\n        # Test for clearing/resetting field values.\n        empty_profile_data = []\n        for field_name in fields:\n            field = CustomProfileField.objects.get(name=field_name, realm=realm)\n            value: Union[str, None, List[Any]] = \"\"\n            if field.field_type == CustomProfileField.USER:\n                value = []\n            empty_profile_data.append(\n                {\n                    \"id\": field.id,\n                    \"value\": value,\n                }\n            )\n        result = self.client_patch(\n            f\"/json/users/{cordelia.id}\",\n            {\"profile_data\": orjson.dumps(empty_profile_data).decode()},\n        )\n        self.assert_json_success(result)\n        for field_dict in cordelia.profile_data():\n            with self.subTest(field_name=field_dict[\"name\"]):\n                self.assertEqual(field_dict[\"value\"], None)\n\n        # Test adding some of the field values after removing all.\n        hamlet = self.example_user(\"hamlet\")\n        new_fields = {\n            \"Phone number\": None,\n            \"Biography\": \"A test user\",\n            \"Favorite food\": None,\n            \"Favorite editor\": None,\n            \"Birthday\": None,\n            \"Favorite website\": \"https://zulip.github.io\",\n            \"Mentor\": [hamlet.id],\n            \"GitHub\": \"timabbott\",\n        }\n        new_profile_data = []\n        for field_name in fields:\n            field = CustomProfileField.objects.get(name=field_name, realm=realm)\n            value = None\n            if new_fields[field_name]:\n                value = new_fields[field_name]\n            new_profile_data.append(\n                {\n                    \"id\": field.id,\n                    \"value\": value,\n                }\n            )\n        result = self.client_patch(\n            f\"/json/users/{cordelia.id}\", {\"profile_data\": orjson.dumps(new_profile_data).decode()}\n        )\n        self.assert_json_success(result)\n        for field_dict in cordelia.profile_data():\n            with self.subTest(field_name=field_dict[\"name\"]):\n                self.assertEqual(field_dict[\"value\"], new_fields[str(field_dict[\"name\"])])\n\n    def test_non_admin_user_cannot_change_profile_data(self) -> None:\n        self.login(\"cordelia\")\n        hamlet = self.example_user(\"hamlet\")\n        realm = get_realm(\"zulip\")\n\n        new_profile_data = []\n        field = CustomProfileField.objects.get(name=\"Biography\", realm=realm)\n        new_profile_data.append(\n            {\n                \"id\": field.id,\n                \"value\": \"New hamlet Biography\",\n            }\n        )\n        result = self.client_patch(\n            f\"/json/users/{hamlet.id}\", {\"profile_data\": orjson.dumps(new_profile_data).decode()}\n        )\n        self.assert_json_error(result, \"Insufficient permission\")\n\n        result = self.client_patch(\n            \"/json/users/{}\".format(self.example_user(\"cordelia\").id),\n            {\"profile_data\": orjson.dumps(new_profile_data).decode()},\n        )\n        self.assert_json_error(result, \"Insufficient permission\")\n\n\nclass QueryCountTest(ZulipTestCase):\n    def test_create_user_with_multiple_streams(self) -> None:\n        # add_new_user_history needs messages to be current\n        Message.objects.all().update(date_sent=timezone_now())\n\n        ContentType.objects.clear_cache()\n\n        # This just focuses on making sure we don't too many\n        # queries/cache tries or send too many events.\n        realm = get_realm(\"zulip\")\n\n        self.make_stream(\"private_stream1\", invite_only=True)\n        self.make_stream(\"private_stream2\", invite_only=True)\n\n        stream_names = [\n            \"Denmark\",\n            \"Scotland\",\n            \"Verona\",\n            \"private_stream1\",\n            \"private_stream2\",\n        ]\n        streams = [get_stream(stream_name, realm) for stream_name in stream_names]\n\n        invite_expires_in_days = 4\n        do_invite_users(\n            user_profile=self.example_user(\"hamlet\"),\n            invitee_emails=[\"fred@zulip.com\"],\n            streams=streams,\n            invite_expires_in_days=invite_expires_in_days,\n        )\n\n        prereg_user = PreregistrationUser.objects.get(email=\"fred@zulip.com\")\n\n        events: List[Mapping[str, Any]] = []\n\n        with queries_captured() as queries:\n            with cache_tries_captured() as cache_tries:\n                with self.tornado_redirected_to_list(events, expected_num_events=10):\n                    fred = do_create_user(\n                        email=\"fred@zulip.com\",\n                        password=\"password\",\n                        realm=realm,\n                        full_name=\"Fred Flintstone\",\n                        prereg_user=prereg_user,\n                        acting_user=None,\n                    )\n\n        self.assert_length(queries, 90)\n        self.assert_length(cache_tries, 29)\n\n        peer_add_events = [event for event in events if event[\"event\"].get(\"op\") == \"peer_add\"]\n\n        notifications = set()\n        for event in peer_add_events:\n            stream_ids = event[\"event\"][\"stream_ids\"]\n            stream_names = sorted(Stream.objects.get(id=stream_id).name for stream_id in stream_ids)\n            self.assertTrue(event[\"event\"][\"user_ids\"], {fred.id})\n            notifications.add(\",\".join(stream_names))\n\n        self.assertEqual(\n            notifications, {\"Denmark,Scotland,Verona\", \"private_stream1\", \"private_stream2\"}\n        )\n\n\nclass BulkCreateUserTest(ZulipTestCase):\n    def test_create_users(self) -> None:\n        realm = get_realm(\"zulip\")\n        realm.email_address_visibility = Realm.EMAIL_ADDRESS_VISIBILITY_ADMINS\n        realm.save()\n\n        name_list = [\n            (\"Fred Flintstone\", \"fred@zulip.com\"),\n            (\"Lisa Simpson\", \"lisa@zulip.com\"),\n        ]\n\n        create_users(realm, name_list)\n\n        fred = get_user_by_delivery_email(\"fred@zulip.com\", realm)\n        self.assertEqual(\n            fred.email,\n            f\"user{fred.id}@zulip.testserver\",\n        )\n\n        lisa = get_user_by_delivery_email(\"lisa@zulip.com\", realm)\n        self.assertEqual(lisa.full_name, \"Lisa Simpson\")\n        self.assertEqual(lisa.is_bot, False)\n        self.assertEqual(lisa.bot_type, None)\n\n        realm.email_address_visibility = Realm.EMAIL_ADDRESS_VISIBILITY_EVERYONE\n        realm.save()\n\n        name_list = [\n            (\"Bono\", \"bono@zulip.com\"),\n            (\"Cher\", \"cher@zulip.com\"),\n        ]\n\n        create_users(realm, name_list)\n        bono = get_user_by_delivery_email(\"bono@zulip.com\", realm)\n        self.assertEqual(bono.email, \"bono@zulip.com\")\n        self.assertEqual(bono.delivery_email, \"bono@zulip.com\")\n\n        cher = get_user_by_delivery_email(\"cher@zulip.com\", realm)\n        self.assertEqual(cher.full_name, \"Cher\")\n\n\nclass AdminCreateUserTest(ZulipTestCase):\n    def test_create_user_backend(self) -> None:\n\n        # This test should give us complete coverage on\n        # create_user_backend.  It mostly exercises error\n        # conditions, and it also does a basic test of the success\n        # path.\n\n        admin = self.example_user(\"hamlet\")\n        realm = admin.realm\n        self.login_user(admin)\n        do_change_user_role(admin, UserProfile.ROLE_REALM_ADMINISTRATOR, acting_user=None)\n        valid_params = dict(\n            email=\"romeo@zulip.net\",\n            password=\"xxxx\",\n            full_name=\"Romeo Montague\",\n        )\n\n        self.assertEqual(admin.can_create_users, False)\n        result = self.client_post(\"/json/users\", valid_params)\n        self.assert_json_error(result, \"User not authorized for this query\")\n\n        do_change_can_create_users(admin, True)\n        # can_create_users is insufficient without being a realm administrator:\n        do_change_user_role(admin, UserProfile.ROLE_MEMBER, acting_user=None)\n        result = self.client_post(\"/json/users\", valid_params)\n        self.assert_json_error(result, \"Must be an organization administrator\")\n\n        do_change_user_role(admin, UserProfile.ROLE_REALM_ADMINISTRATOR, acting_user=None)\n\n        result = self.client_post(\"/json/users\", {})\n        self.assert_json_error(result, \"Missing 'email' argument\")\n\n        result = self.client_post(\n            \"/json/users\",\n            dict(\n                email=\"romeo@not-zulip.com\",\n            ),\n        )\n        self.assert_json_error(result, \"Missing 'password' argument\")\n\n        result = self.client_post(\n            \"/json/users\",\n            dict(\n                email=\"romeo@not-zulip.com\",\n                password=\"xxxx\",\n            ),\n        )\n        self.assert_json_error(result, \"Missing 'full_name' argument\")\n\n        # Test short_name gets properly ignored\n        result = self.client_post(\n            \"/json/users\",\n            dict(\n                email=\"romeo@zulip.com\",\n                password=\"xxxx\",\n                full_name=\"Romeo Montague\",\n                short_name=\"DEPRECATED\",\n            ),\n        )\n        self.assert_json_success(result)\n\n        result = self.client_post(\n            \"/json/users\",\n            dict(\n                email=\"broken\",\n                password=\"xxxx\",\n                full_name=\"Romeo Montague\",\n            ),\n        )\n        self.assert_json_error(result, \"Bad name or username\")\n\n        do_set_realm_property(realm, \"emails_restricted_to_domains\", True, acting_user=None)\n        result = self.client_post(\n            \"/json/users\",\n            dict(\n                email=\"romeo@not-zulip.com\",\n                password=\"xxxx\",\n                full_name=\"Romeo Montague\",\n            ),\n        )\n        self.assert_json_error(\n            result, \"Email 'romeo@not-zulip.com' not allowed in this organization\"\n        )\n\n        RealmDomain.objects.create(realm=get_realm(\"zulip\"), domain=\"zulip.net\")\n        # Check can't use a bad password with zxcvbn enabled\n        with self.settings(PASSWORD_MIN_LENGTH=6, PASSWORD_MIN_GUESSES=1000):\n            result = self.client_post(\"/json/users\", valid_params)\n            self.assert_json_error(result, \"The password is too weak.\")\n\n        result = self.client_post(\"/json/users\", valid_params)\n        self.assert_json_success(result)\n\n        # Romeo is a newly registered user\n        new_user = get_user_by_delivery_email(\"romeo@zulip.net\", get_realm(\"zulip\"))\n        result = orjson.loads(result.content)\n        self.assertEqual(new_user.full_name, \"Romeo Montague\")\n        self.assertEqual(new_user.id, result[\"user_id\"])\n\n        # Make sure the recipient field is set correctly.\n        self.assertEqual(\n            new_user.recipient, Recipient.objects.get(type=Recipient.PERSONAL, type_id=new_user.id)\n        )\n\n        # we can't create the same user twice.\n        result = self.client_post(\"/json/users\", valid_params)\n        self.assert_json_error(result, \"Email 'romeo@zulip.net' already in use\")\n\n        # Don't allow user to sign up with disposable email.\n        realm.emails_restricted_to_domains = False\n        realm.disallow_disposable_email_addresses = True\n        realm.save()\n\n        valid_params[\"email\"] = \"abc@mailnator.com\"\n        result = self.client_post(\"/json/users\", valid_params)\n        self.assert_json_error(\n            result, \"Disposable email addresses are not allowed in this organization\"\n        )\n\n        # Don't allow creating a user with + in their email address when realm\n        # is restricted to a domain.\n        realm.emails_restricted_to_domains = True\n        realm.save()\n\n        valid_params[\"email\"] = \"iago+label@zulip.com\"\n        result = self.client_post(\"/json/users\", valid_params)\n        self.assert_json_error(result, \"Email addresses containing + are not allowed.\")\n\n        # Users can be created with + in their email address when realm\n        # is not restricted to a domain.\n        realm.emails_restricted_to_domains = False\n        realm.save()\n\n        valid_params[\"email\"] = \"iago+label@zulip.com\"\n        result = self.client_post(\"/json/users\", valid_params)\n        self.assert_json_success(result)\n\n\nclass UserProfileTest(ZulipTestCase):\n    def test_valid_user_id(self) -> None:\n        realm = get_realm(\"zulip\")\n        hamlet = self.example_user(\"hamlet\")\n        othello = self.example_user(\"othello\")\n        bot = self.example_user(\"default_bot\")\n\n        # Invalid user ID\n        invalid_uid: object = 1000\n        with self.assertRaisesRegex(ValidationError, r\"User IDs is not a list\"):\n            check_valid_user_ids(realm.id, invalid_uid)\n        with self.assertRaisesRegex(ValidationError, rf\"Invalid user ID: {invalid_uid}\"):\n            check_valid_user_ids(realm.id, [invalid_uid])\n\n        invalid_uid = \"abc\"\n        with self.assertRaisesRegex(ValidationError, r\"User IDs\\[0\\] is not an integer\"):\n            check_valid_user_ids(realm.id, [invalid_uid])\n\n        invalid_uid = str(othello.id)\n        with self.assertRaisesRegex(ValidationError, r\"User IDs\\[0\\] is not an integer\"):\n            check_valid_user_ids(realm.id, [invalid_uid])\n\n        # User is in different realm\n        with self.assertRaisesRegex(ValidationError, rf\"Invalid user ID: {hamlet.id}\"):\n            check_valid_user_ids(get_realm(\"zephyr\").id, [hamlet.id])\n\n        # User is not active\n        change_user_is_active(hamlet, False)\n        with self.assertRaisesRegex(ValidationError, rf\"User with ID {hamlet.id} is deactivated\"):\n            check_valid_user_ids(realm.id, [hamlet.id])\n        check_valid_user_ids(realm.id, [hamlet.id], allow_deactivated=True)\n\n        # User is a bot\n        with self.assertRaisesRegex(ValidationError, rf\"User with ID {bot.id} is a bot\"):\n            check_valid_user_ids(realm.id, [bot.id])\n\n        # Successfully get non-bot, active user belong to your realm\n        check_valid_user_ids(realm.id, [othello.id])\n\n    def test_cache_invalidation(self) -> None:\n        hamlet = self.example_user(\"hamlet\")\n        with mock.patch(\"zerver.lib.cache.delete_display_recipient_cache\") as m:\n            hamlet.full_name = \"Hamlet Junior\"\n            hamlet.save(update_fields=[\"full_name\"])\n\n        self.assertTrue(m.called)\n\n        with mock.patch(\"zerver.lib.cache.delete_display_recipient_cache\") as m:\n            hamlet.long_term_idle = True\n            hamlet.save(update_fields=[\"long_term_idle\"])\n\n        self.assertFalse(m.called)\n\n    def test_user_ids_to_users(self) -> None:\n        real_user_ids = [\n            self.example_user(\"hamlet\").id,\n            self.example_user(\"cordelia\").id,\n        ]\n\n        self.assertEqual(user_ids_to_users([], get_realm(\"zulip\")), [])\n        self.assertEqual(\n            {\n                user_profile.id\n                for user_profile in user_ids_to_users(real_user_ids, get_realm(\"zulip\"))\n            },\n            set(real_user_ids),\n        )\n        with self.assertRaises(JsonableError):\n            user_ids_to_users([1234], get_realm(\"zephyr\"))\n        with self.assertRaises(JsonableError):\n            user_ids_to_users(real_user_ids, get_realm(\"zephyr\"))\n\n    def test_bulk_get_users(self) -> None:\n        from zerver.lib.users import bulk_get_users\n\n        hamlet = self.example_user(\"hamlet\")\n        cordelia = self.example_user(\"cordelia\")\n        webhook_bot = self.example_user(\"webhook_bot\")\n        result = bulk_get_users(\n            [hamlet.email, cordelia.email],\n            get_realm(\"zulip\"),\n        )\n        self.assertEqual(result[hamlet.email].email, hamlet.email)\n        self.assertEqual(result[cordelia.email].email, cordelia.email)\n\n        result = bulk_get_users(\n            [hamlet.email, cordelia.email, webhook_bot.email],\n            None,\n            base_query=UserProfile.objects.all(),\n        )\n        self.assertEqual(result[hamlet.email].email, hamlet.email)\n        self.assertEqual(result[cordelia.email].email, cordelia.email)\n        self.assertEqual(result[webhook_bot.email].email, webhook_bot.email)\n\n    def test_get_accounts_for_email(self) -> None:\n        reset_emails_in_zulip_realm()\n\n        def check_account_present_in_accounts(user: UserProfile, accounts: List[Accounts]) -> None:\n            for account in accounts:\n                realm = user.realm\n                if (\n                    account[\"avatar\"] == avatar_url(user)\n                    and account[\"full_name\"] == user.full_name\n                    and account[\"realm_name\"] == realm.name\n                    and account[\"realm_id\"] == realm.id\n                ):\n                    return\n            raise AssertionError(\"Account not found\")\n\n        lear_realm = get_realm(\"lear\")\n        cordelia_in_zulip = self.example_user(\"cordelia\")\n        cordelia_in_lear = get_user_by_delivery_email(\"cordelia@zulip.com\", lear_realm)\n\n        email = \"cordelia@zulip.com\"\n        accounts = get_accounts_for_email(email)\n        self.assert_length(accounts, 2)\n        check_account_present_in_accounts(cordelia_in_zulip, accounts)\n        check_account_present_in_accounts(cordelia_in_lear, accounts)\n\n        email = \"CORDelia@zulip.com\"\n        accounts = get_accounts_for_email(email)\n        self.assert_length(accounts, 2)\n        check_account_present_in_accounts(cordelia_in_zulip, accounts)\n        check_account_present_in_accounts(cordelia_in_lear, accounts)\n\n        email = \"IAGO@ZULIP.COM\"\n        accounts = get_accounts_for_email(email)\n        self.assert_length(accounts, 1)\n        check_account_present_in_accounts(self.example_user(\"iago\"), accounts)\n\n        # We verify that get_accounts_for_email don't return deactivated users accounts\n        user = self.example_user(\"hamlet\")\n        do_deactivate_user(user, acting_user=None)\n        email = self.example_email(\"hamlet\")\n        accounts = get_accounts_for_email(email)\n        with self.assertRaises(AssertionError):\n            check_account_present_in_accounts(user, accounts)\n\n    def test_get_source_profile(self) -> None:\n        reset_emails_in_zulip_realm()\n        zulip_realm_id = get_realm(\"zulip\").id\n        iago = get_source_profile(\"iago@zulip.com\", zulip_realm_id)\n        assert iago is not None\n        self.assertEqual(iago.email, \"iago@zulip.com\")\n        self.assertEqual(iago.realm, get_realm(\"zulip\"))\n\n        iago = get_source_profile(\"IAGO@ZULIP.com\", zulip_realm_id)\n        assert iago is not None\n        self.assertEqual(iago.email, \"iago@zulip.com\")\n\n        lear_realm_id = get_realm(\"lear\").id\n        cordelia = get_source_profile(\"cordelia@zulip.com\", lear_realm_id)\n        assert cordelia is not None\n        self.assertEqual(cordelia.email, \"cordelia@zulip.com\")\n\n        self.assertIsNone(get_source_profile(\"iagod@zulip.com\", zulip_realm_id))\n        self.assertIsNone(get_source_profile(\"iago@zulip.com\", 0))\n        self.assertIsNone(get_source_profile(\"iago@zulip.com\", lear_realm_id))\n\n    def test_copy_default_settings_from_another_user(self) -> None:\n        iago = self.example_user(\"iago\")\n        cordelia = self.example_user(\"cordelia\")\n        hamlet = self.example_user(\"hamlet\")\n        hamlet.color_scheme = UserProfile.COLOR_SCHEME_LIGHT\n\n        cordelia.default_language = \"de\"\n        cordelia.default_view = \"all_messages\"\n        cordelia.emojiset = \"twitter\"\n        cordelia.timezone = \"America/Phoenix\"\n        cordelia.color_scheme = UserProfile.COLOR_SCHEME_NIGHT\n        cordelia.enable_offline_email_notifications = False\n        cordelia.enable_stream_push_notifications = True\n        cordelia.enter_sends = False\n        cordelia.avatar_source = UserProfile.AVATAR_FROM_USER\n        cordelia.save()\n\n        # Upload cordelia's avatar\n        with get_test_image_file(\"img.png\") as image_file:\n            upload_avatar_image(image_file, cordelia, cordelia)\n\n        UserHotspot.objects.filter(user=cordelia).delete()\n        UserHotspot.objects.filter(user=iago).delete()\n        hotspots_completed = {\"intro_streams\", \"intro_topics\"}\n        for hotspot in hotspots_completed:\n            UserHotspot.objects.create(user=cordelia, hotspot=hotspot)\n\n        # Check that we didn't send an realm_user update events to\n        # users; this work is happening before the user account is\n        # created, so any changes will be reflected in the \"add\" event\n        # introducing the user to clients.\n        events: List[Mapping[str, Any]] = []\n        with self.tornado_redirected_to_list(events, expected_num_events=0):\n            copy_default_settings(cordelia, iago)\n\n        # We verify that cordelia and iago match, but hamlet has the defaults.\n        self.assertEqual(iago.full_name, \"Cordelia, Lear's daughter\")\n        self.assertEqual(cordelia.full_name, \"Cordelia, Lear's daughter\")\n        self.assertEqual(hamlet.full_name, \"King Hamlet\")\n\n        self.assertEqual(iago.default_language, \"de\")\n        self.assertEqual(cordelia.default_language, \"de\")\n        self.assertEqual(hamlet.default_language, \"en\")\n\n        self.assertEqual(iago.emojiset, \"twitter\")\n        self.assertEqual(cordelia.emojiset, \"twitter\")\n        self.assertEqual(hamlet.emojiset, \"google\")\n\n        self.assertEqual(iago.timezone, \"America/Phoenix\")\n        self.assertEqual(cordelia.timezone, \"America/Phoenix\")\n        self.assertEqual(hamlet.timezone, \"\")\n\n        self.assertEqual(iago.color_scheme, UserProfile.COLOR_SCHEME_NIGHT)\n        self.assertEqual(cordelia.color_scheme, UserProfile.COLOR_SCHEME_NIGHT)\n        self.assertEqual(hamlet.color_scheme, UserProfile.COLOR_SCHEME_LIGHT)\n\n        self.assertEqual(iago.enable_offline_email_notifications, False)\n        self.assertEqual(cordelia.enable_offline_email_notifications, False)\n        self.assertEqual(hamlet.enable_offline_email_notifications, True)\n\n        self.assertEqual(iago.enable_stream_push_notifications, True)\n        self.assertEqual(cordelia.enable_stream_push_notifications, True)\n        self.assertEqual(hamlet.enable_stream_push_notifications, False)\n\n        self.assertEqual(iago.enter_sends, False)\n        self.assertEqual(cordelia.enter_sends, False)\n        self.assertEqual(hamlet.enter_sends, True)\n\n        hotspots = set(UserHotspot.objects.filter(user=iago).values_list(\"hotspot\", flat=True))\n        self.assertEqual(hotspots, hotspots_completed)\n\n    def test_copy_default_settings_from_realm_user_default(self) -> None:\n        cordelia = self.example_user(\"cordelia\")\n        realm = get_realm(\"zulip\")\n        realm_user_default = RealmUserDefault.objects.get(realm=realm)\n\n        realm_user_default.default_view = \"recent_topics\"\n        realm_user_default.emojiset = \"twitter\"\n        realm_user_default.color_scheme = UserProfile.COLOR_SCHEME_LIGHT\n        realm_user_default.enable_offline_email_notifications = False\n        realm_user_default.enable_stream_push_notifications = True\n        realm_user_default.enter_sends = True\n        realm_user_default.save()\n\n        # Check that we didn't send an realm_user update events to\n        # users; this work is happening before the user account is\n        # created, so any changes will be reflected in the \"add\" event\n        # introducing the user to clients.\n        events: List[Mapping[str, Any]] = []\n        with self.tornado_redirected_to_list(events, expected_num_events=0):\n            copy_default_settings(realm_user_default, cordelia)\n\n        self.assertEqual(cordelia.default_view, \"recent_topics\")\n        self.assertEqual(cordelia.emojiset, \"twitter\")\n        self.assertEqual(cordelia.color_scheme, UserProfile.COLOR_SCHEME_LIGHT)\n        self.assertEqual(cordelia.enable_offline_email_notifications, False)\n        self.assertEqual(cordelia.enable_stream_push_notifications, True)\n        self.assertEqual(cordelia.enter_sends, True)\n\n    def test_get_user_by_id_in_realm_including_cross_realm(self) -> None:\n        realm = get_realm(\"zulip\")\n        internal_realm = get_realm(settings.SYSTEM_BOT_REALM)\n        hamlet = self.example_user(\"hamlet\")\n        othello = self.example_user(\"othello\")\n        bot = get_system_bot(settings.WELCOME_BOT, internal_realm.id)\n\n        # Pass in the ID of a cross-realm bot and a valid realm\n        cross_realm_bot = get_user_by_id_in_realm_including_cross_realm(bot.id, realm)\n        self.assertEqual(cross_realm_bot.email, bot.email)\n        self.assertEqual(cross_realm_bot.id, bot.id)\n\n        # Pass in the ID of a cross-realm bot but with a invalid realm,\n        # note that the realm should be irrelevant here\n        cross_realm_bot = get_user_by_id_in_realm_including_cross_realm(bot.id, None)\n        self.assertEqual(cross_realm_bot.email, bot.email)\n        self.assertEqual(cross_realm_bot.id, bot.id)\n\n        # Pass in the ID of a non-cross-realm user with a realm\n        user_profile = get_user_by_id_in_realm_including_cross_realm(othello.id, realm)\n        self.assertEqual(user_profile.email, othello.email)\n        self.assertEqual(user_profile.id, othello.id)\n\n        # If the realm doesn't match, or if the ID is not that of a\n        # cross-realm bot, UserProfile.DoesNotExist is raised\n        with self.assertRaises(UserProfile.DoesNotExist):\n            get_user_by_id_in_realm_including_cross_realm(hamlet.id, None)\n\n    def test_get_user_subscription_status(self) -> None:\n        self.login(\"hamlet\")\n        iago = self.example_user(\"iago\")\n        stream = get_stream(\"Rome\", iago.realm)\n\n        # Invalid user ID.\n        result = self.client_get(f\"/json/users/25/subscriptions/{stream.id}\")\n        self.assert_json_error(result, \"No such user\")\n\n        # Invalid stream ID.\n        result = self.client_get(f\"/json/users/{iago.id}/subscriptions/25\")\n        self.assert_json_error(result, \"Invalid stream id\")\n\n        result = orjson.loads(\n            self.client_get(f\"/json/users/{iago.id}/subscriptions/{stream.id}\").content\n        )\n        self.assertFalse(result[\"is_subscribed\"])\n\n        # Subscribe to the stream.\n        self.subscribe(iago, stream.name)\n        with queries_captured() as queries:\n            result = orjson.loads(\n                self.client_get(f\"/json/users/{iago.id}/subscriptions/{stream.id}\").content\n            )\n\n        self.assert_length(queries, 6)\n        self.assertTrue(result[\"is_subscribed\"])\n\n        # Logging in with a Guest user.\n        polonius = self.example_user(\"polonius\")\n        self.login(\"polonius\")\n        self.assertTrue(polonius.is_guest)\n        self.assertTrue(stream.is_web_public)\n\n        result = orjson.loads(\n            self.client_get(f\"/json/users/{iago.id}/subscriptions/{stream.id}\").content\n        )\n        self.assertTrue(result[\"is_subscribed\"])\n\n        self.login(\"iago\")\n        stream = self.make_stream(\"private_stream\", invite_only=True)\n        # Unsubscribed admin can check subscription status in a private stream.\n        result = orjson.loads(\n            self.client_get(f\"/json/users/{iago.id}/subscriptions/{stream.id}\").content\n        )\n        self.assertFalse(result[\"is_subscribed\"])\n\n        # Unsubscribed non-admins cannot check subscription status in a private stream.\n        self.login(\"shiva\")\n        result = self.client_get(f\"/json/users/{iago.id}/subscriptions/{stream.id}\")\n        self.assert_json_error(result, \"Invalid stream id\")\n\n        # Subscribed non-admins can check subscription status in a private stream\n        self.subscribe(self.example_user(\"shiva\"), stream.name)\n        result = orjson.loads(\n            self.client_get(f\"/json/users/{iago.id}/subscriptions/{stream.id}\").content\n        )\n        self.assertFalse(result[\"is_subscribed\"])\n\n\nclass ActivateTest(ZulipTestCase):\n    def test_basics(self) -> None:\n        user = self.example_user(\"hamlet\")\n        do_deactivate_user(user, acting_user=None)\n        self.assertFalse(user.is_active)\n        do_reactivate_user(user, acting_user=None)\n        self.assertTrue(user.is_active)\n\n    def test_subscriptions_is_user_active(self) -> None:\n        user = self.example_user(\"hamlet\")\n        do_deactivate_user(user, acting_user=None)\n        self.assertFalse(user.is_active)\n        self.assertTrue(Subscription.objects.filter(user_profile=user).exists())\n        self.assertFalse(\n            Subscription.objects.filter(user_profile=user, is_user_active=True).exists()\n        )\n\n        do_reactivate_user(user, acting_user=None)\n        self.assertTrue(user.is_active)\n        self.assertTrue(Subscription.objects.filter(user_profile=user).exists())\n        self.assertFalse(\n            Subscription.objects.filter(user_profile=user, is_user_active=False).exists()\n        )\n\n    def test_api(self) -> None:\n        admin = self.example_user(\"othello\")\n        do_change_user_role(admin, UserProfile.ROLE_REALM_ADMINISTRATOR, acting_user=None)\n        self.login(\"othello\")\n\n        user = self.example_user(\"hamlet\")\n        self.assertTrue(user.is_active)\n\n        result = self.client_delete(f\"/json/users/{user.id}\")\n        self.assert_json_success(result)\n        user = self.example_user(\"hamlet\")\n        self.assertFalse(user.is_active)\n\n        result = self.client_post(f\"/json/users/{user.id}/reactivate\")\n        self.assert_json_success(result)\n        user = self.example_user(\"hamlet\")\n        self.assertTrue(user.is_active)\n\n    def test_api_with_nonexistent_user(self) -> None:\n        self.login(\"iago\")\n\n        # Organization administrator cannot deactivate organization owner.\n        result = self.client_delete(f'/json/users/{self.example_user(\"desdemona\").id}')\n        self.assert_json_error(result, \"Must be an organization owner\")\n\n        iago = self.example_user(\"iago\")\n        desdemona = self.example_user(\"desdemona\")\n        do_change_user_role(iago, UserProfile.ROLE_REALM_OWNER, acting_user=None)\n\n        # Cannot deactivate a user with the bot api\n        result = self.client_delete(\"/json/bots/{}\".format(self.example_user(\"hamlet\").id))\n        self.assert_json_error(result, \"No such bot\")\n\n        # Cannot deactivate a nonexistent user.\n        invalid_user_id = 1000\n        result = self.client_delete(f\"/json/users/{invalid_user_id}\")\n        self.assert_json_error(result, \"No such user\")\n\n        result = self.client_delete(\"/json/users/{}\".format(self.example_user(\"webhook_bot\").id))\n        self.assert_json_error(result, \"No such user\")\n\n        result = self.client_delete(f\"/json/users/{desdemona.id}\")\n        self.assert_json_success(result)\n\n        result = self.client_delete(f\"/json/users/{iago.id}\")\n        self.assert_json_error(result, \"Cannot deactivate the only organization owner\")\n\n        # Cannot reactivate a nonexistent user.\n        invalid_user_id = 1000\n        result = self.client_post(f\"/json/users/{invalid_user_id}/reactivate\")\n        self.assert_json_error(result, \"No such user\")\n\n    def test_api_with_insufficient_permissions(self) -> None:\n        non_admin = self.example_user(\"othello\")\n        do_change_user_role(non_admin, UserProfile.ROLE_MEMBER, acting_user=None)\n        self.login(\"othello\")\n\n        # Cannot deactivate a user with the users api\n        result = self.client_delete(\"/json/users/{}\".format(self.example_user(\"hamlet\").id))\n        self.assert_json_error(result, \"Insufficient permission\")\n\n        # Cannot reactivate a user\n        result = self.client_post(\n            \"/json/users/{}/reactivate\".format(self.example_user(\"hamlet\").id)\n        )\n        self.assert_json_error(result, \"Insufficient permission\")\n\n    def test_revoke_invites(self) -> None:\n        \"\"\"\n        Verify that any invitations generated by the user get revoked\n        when the user is deactivated\n        \"\"\"\n        iago = self.example_user(\"iago\")\n        desdemona = self.example_user(\"desdemona\")\n\n        invite_expires_in_days = 2\n        do_invite_users(\n            iago,\n            [\"new1@zulip.com\", \"new2@zulip.com\"],\n            [],\n            invite_expires_in_days=invite_expires_in_days,\n            invite_as=PreregistrationUser.INVITE_AS[\"REALM_ADMIN\"],\n        )\n        do_invite_users(\n            desdemona,\n            [\"new3@zulip.com\", \"new4@zulip.com\"],\n            [],\n            invite_expires_in_days=invite_expires_in_days,\n            invite_as=PreregistrationUser.INVITE_AS[\"REALM_ADMIN\"],\n        )\n\n        do_invite_users(\n            iago,\n            [\"new5@zulip.com\"],\n            [],\n            invite_expires_in_days=None,\n            invite_as=PreregistrationUser.INVITE_AS[\"REALM_ADMIN\"],\n        )\n        do_invite_users(\n            desdemona,\n            [\"new6@zulip.com\"],\n            [],\n            invite_expires_in_days=None,\n            invite_as=PreregistrationUser.INVITE_AS[\"REALM_ADMIN\"],\n        )\n\n        iago_multiuse_key = do_create_multiuse_invite_link(\n            iago, PreregistrationUser.INVITE_AS[\"MEMBER\"], invite_expires_in_days\n        ).split(\"/\")[-2]\n        desdemona_multiuse_key = do_create_multiuse_invite_link(\n            desdemona, PreregistrationUser.INVITE_AS[\"MEMBER\"], invite_expires_in_days\n        ).split(\"/\")[-2]\n\n        iago_never_expire_multiuse_key = do_create_multiuse_invite_link(\n            iago, PreregistrationUser.INVITE_AS[\"MEMBER\"], None\n        ).split(\"/\")[-2]\n        desdemona_never_expire_multiuse_key = do_create_multiuse_invite_link(\n            desdemona, PreregistrationUser.INVITE_AS[\"MEMBER\"], None\n        ).split(\"/\")[-2]\n\n        self.assertEqual(\n            filter_to_valid_prereg_users(\n                PreregistrationUser.objects.filter(referred_by=iago)\n            ).count(),\n            3,\n        )\n        self.assertEqual(\n            filter_to_valid_prereg_users(\n                PreregistrationUser.objects.filter(referred_by=desdemona)\n            ).count(),\n            3,\n        )\n        self.assertTrue(\n            Confirmation.objects.get(confirmation_key=iago_multiuse_key).expiry_date\n            > timezone_now()\n        )\n        self.assertTrue(\n            Confirmation.objects.get(confirmation_key=desdemona_multiuse_key).expiry_date\n            > timezone_now()\n        )\n        self.assertIsNone(\n            Confirmation.objects.get(confirmation_key=iago_never_expire_multiuse_key).expiry_date\n        )\n        self.assertIsNone(\n            Confirmation.objects.get(\n                confirmation_key=desdemona_never_expire_multiuse_key\n            ).expiry_date\n        )\n\n        do_deactivate_user(iago, acting_user=None)\n\n        # Now we verify that invitations generated by iago were revoked, while desdemona's\n        # remain valid.\n        self.assertEqual(\n            filter_to_valid_prereg_users(\n                PreregistrationUser.objects.filter(referred_by=iago)\n            ).count(),\n            0,\n        )\n        self.assertEqual(\n            filter_to_valid_prereg_users(\n                PreregistrationUser.objects.filter(referred_by=desdemona)\n            ).count(),\n            3,\n        )\n        self.assertTrue(\n            Confirmation.objects.get(confirmation_key=iago_multiuse_key).expiry_date\n            <= timezone_now()\n        )\n        self.assertTrue(\n            Confirmation.objects.get(confirmation_key=desdemona_multiuse_key).expiry_date\n            > timezone_now()\n        )\n        self.assertTrue(\n            Confirmation.objects.get(confirmation_key=iago_never_expire_multiuse_key).expiry_date\n            <= timezone_now()\n        )\n        self.assertIsNone(\n            Confirmation.objects.get(\n                confirmation_key=desdemona_never_expire_multiuse_key\n            ).expiry_date\n        )\n\n    def test_clear_sessions(self) -> None:\n        user = self.example_user(\"hamlet\")\n        self.login_user(user)\n        session_key = self.client.session.session_key\n        self.assertTrue(session_key)\n\n        result = self.client_get(\"/json/users\")\n        self.assert_json_success(result)\n        self.assertEqual(Session.objects.filter(pk=session_key).count(), 1)\n\n        do_deactivate_user(user, acting_user=None)\n        self.assertEqual(Session.objects.filter(pk=session_key).count(), 0)\n\n        result = self.client_get(\"/json/users\")\n        self.assert_json_error(\n            result, \"Not logged in: API authentication or user session required\", 401\n        )\n\n    def test_clear_scheduled_jobs(self) -> None:\n        user = self.example_user(\"hamlet\")\n        send_future_email(\n            \"zerver/emails/followup_day1\",\n            user.realm,\n            to_user_ids=[user.id],\n            delay=datetime.timedelta(hours=1),\n        )\n        self.assertEqual(ScheduledEmail.objects.count(), 1)\n        do_deactivate_user(user, acting_user=None)\n        self.assertEqual(ScheduledEmail.objects.count(), 0)\n\n    def test_send_future_email_with_multiple_recipients(self) -> None:\n        hamlet = self.example_user(\"hamlet\")\n        iago = self.example_user(\"iago\")\n        send_future_email(\n            \"zerver/emails/followup_day1\",\n            iago.realm,\n            to_user_ids=[hamlet.id, iago.id],\n            delay=datetime.timedelta(hours=1),\n        )\n        self.assertEqual(\n            ScheduledEmail.objects.filter(users__in=[hamlet, iago]).distinct().count(), 1\n        )\n        email = ScheduledEmail.objects.all().first()\n        assert email is not None and email.users is not None\n        self.assertEqual(email.users.count(), 2)\n\n    def test_clear_schedule_emails(self) -> None:\n        hamlet = self.example_user(\"hamlet\")\n        iago = self.example_user(\"iago\")\n        send_future_email(\n            \"zerver/emails/followup_day1\",\n            iago.realm,\n            to_user_ids=[hamlet.id, iago.id],\n            delay=datetime.timedelta(hours=1),\n        )\n        self.assertEqual(ScheduledEmail.objects.count(), 1)\n        clear_scheduled_emails(hamlet.id)\n        self.assertEqual(ScheduledEmail.objects.count(), 1)\n        self.assertEqual(ScheduledEmail.objects.filter(users=hamlet).count(), 0)\n        self.assertEqual(ScheduledEmail.objects.filter(users=iago).count(), 1)\n\n    def test_deliver_scheduled_emails(self) -> None:\n        iago = self.example_user(\"iago\")\n        hamlet = self.example_user(\"hamlet\")\n        send_future_email(\n            \"zerver/emails/followup_day1\",\n            iago.realm,\n            to_user_ids=[hamlet.id, iago.id],\n            delay=datetime.timedelta(hours=1),\n        )\n        self.assertEqual(ScheduledEmail.objects.count(), 1)\n        email = ScheduledEmail.objects.all().first()\n        deliver_scheduled_emails(assert_is_not_none(email))\n        from django.core.mail import outbox\n\n        self.assert_length(outbox, 1)\n        for message in outbox:\n            self.assertEqual(\n                set(message.to),\n                {\n                    str(Address(display_name=hamlet.full_name, addr_spec=hamlet.delivery_email)),\n                    str(Address(display_name=iago.full_name, addr_spec=iago.delivery_email)),\n                },\n            )\n        self.assertEqual(ScheduledEmail.objects.count(), 0)\n\n    def test_deliver_scheduled_emails_no_addressees(self) -> None:\n        iago = self.example_user(\"iago\")\n        hamlet = self.example_user(\"hamlet\")\n        to_user_ids = [hamlet.id, iago.id]\n        send_future_email(\n            \"zerver/emails/followup_day1\",\n            iago.realm,\n            to_user_ids=to_user_ids,\n            delay=datetime.timedelta(hours=1),\n        )\n        self.assertEqual(ScheduledEmail.objects.count(), 1)\n        email = ScheduledEmail.objects.all().first()\n        assert email is not None\n        email.users.remove(*to_user_ids)\n\n        with self.assertLogs(\"zulip.send_email\", level=\"INFO\") as info_log:\n            deliver_scheduled_emails(email)\n        from django.core.mail import outbox\n\n        self.assert_length(outbox, 0)\n        self.assertEqual(ScheduledEmail.objects.count(), 1)\n        self.assertEqual(\n            info_log.output,\n            [\n                f\"ERROR:zulip.send_email:ScheduledEmail id {email.id} has empty users and address attributes.\"\n            ],\n        )\n\n\nclass RecipientInfoTest(ZulipTestCase):\n    def test_stream_recipient_info(self) -> None:\n        hamlet = self.example_user(\"hamlet\")\n        cordelia = self.example_user(\"cordelia\")\n        othello = self.example_user(\"othello\")\n\n        # These tests were written with the old default for\n        # enable_online_push_notifications; that default is better for\n        # testing the full code path anyway.\n        hamlet.enable_online_push_notifications = False\n        cordelia.enable_online_push_notifications = False\n        othello.enable_online_push_notifications = False\n        hamlet.save()\n        cordelia.save()\n        othello.save()\n\n        realm = hamlet.realm\n\n        stream_name = \"Test stream\"\n        topic_name = \"test topic\"\n\n        for user in [hamlet, cordelia, othello]:\n            self.subscribe(user, stream_name)\n\n        stream = get_stream(stream_name, realm)\n        recipient = stream.recipient\n        assert recipient is not None\n\n        stream_topic = StreamTopicTarget(\n            stream_id=stream.id,\n            topic_name=topic_name,\n        )\n\n        info = get_recipient_info(\n            realm_id=realm.id,\n            recipient=recipient,\n            sender_id=hamlet.id,\n            stream_topic=stream_topic,\n            possible_wildcard_mention=False,\n        )\n\n        all_user_ids = {hamlet.id, cordelia.id, othello.id}\n\n        expected_info = dict(\n            active_user_ids=all_user_ids,\n            online_push_user_ids=set(),\n            pm_mention_email_disabled_user_ids=set(),\n            pm_mention_push_disabled_user_ids=set(),\n            stream_push_user_ids=set(),\n            stream_email_user_ids=set(),\n            wildcard_mention_user_ids=set(),\n            muted_sender_user_ids=set(),\n            um_eligible_user_ids=all_user_ids,\n            long_term_idle_user_ids=set(),\n            default_bot_user_ids=set(),\n            service_bot_tuples=[],\n            all_bot_user_ids=set(),\n        )\n\n        self.assertEqual(info, expected_info)\n\n        hamlet.enable_offline_email_notifications = False\n        hamlet.enable_offline_push_notifications = False\n        hamlet.save()\n        info = get_recipient_info(\n            realm_id=realm.id,\n            recipient=recipient,\n            sender_id=hamlet.id,\n            stream_topic=stream_topic,\n            possible_wildcard_mention=False,\n        )\n        self.assertEqual(info[\"pm_mention_email_disabled_user_ids\"], {hamlet.id})\n        self.assertEqual(info[\"pm_mention_push_disabled_user_ids\"], {hamlet.id})\n        hamlet.enable_offline_email_notifications = True\n        hamlet.enable_offline_push_notifications = True\n        hamlet.save()\n\n        cordelia.wildcard_mentions_notify = False\n        cordelia.save()\n        hamlet.enable_stream_push_notifications = True\n        hamlet.save()\n        info = get_recipient_info(\n            realm_id=realm.id,\n            recipient=recipient,\n            sender_id=hamlet.id,\n            stream_topic=stream_topic,\n            possible_wildcard_mention=False,\n        )\n        self.assertEqual(info[\"stream_push_user_ids\"], {hamlet.id})\n        self.assertEqual(info[\"wildcard_mention_user_ids\"], set())\n\n        info = get_recipient_info(\n            realm_id=realm.id,\n            recipient=recipient,\n            sender_id=hamlet.id,\n            stream_topic=stream_topic,\n            possible_wildcard_mention=True,\n        )\n        self.assertEqual(info[\"wildcard_mention_user_ids\"], {hamlet.id, othello.id})\n\n        sub = get_subscription(stream_name, hamlet)\n        sub.push_notifications = False\n        sub.save()\n        info = get_recipient_info(\n            realm_id=realm.id,\n            recipient=recipient,\n            sender_id=hamlet.id,\n            stream_topic=stream_topic,\n        )\n        self.assertEqual(info[\"stream_push_user_ids\"], set())\n\n        hamlet.enable_stream_push_notifications = False\n        hamlet.save()\n        sub = get_subscription(stream_name, hamlet)\n        sub.push_notifications = True\n        sub.save()\n        info = get_recipient_info(\n            realm_id=realm.id,\n            recipient=recipient,\n            sender_id=hamlet.id,\n            stream_topic=stream_topic,\n        )\n        self.assertEqual(info[\"stream_push_user_ids\"], {hamlet.id})\n\n        # Now have Hamlet mute the topic to omit him from stream_push_user_ids.\n        add_topic_mute(\n            user_profile=hamlet,\n            stream_id=stream.id,\n            recipient_id=recipient.id,\n            topic_name=topic_name,\n        )\n\n        info = get_recipient_info(\n            realm_id=realm.id,\n            recipient=recipient,\n            sender_id=hamlet.id,\n            stream_topic=stream_topic,\n            possible_wildcard_mention=False,\n        )\n        self.assertEqual(info[\"stream_push_user_ids\"], set())\n        self.assertEqual(info[\"wildcard_mention_user_ids\"], set())\n\n        info = get_recipient_info(\n            realm_id=realm.id,\n            recipient=recipient,\n            sender_id=hamlet.id,\n            stream_topic=stream_topic,\n            possible_wildcard_mention=True,\n        )\n        self.assertEqual(info[\"stream_push_user_ids\"], set())\n        # Since Hamlet has muted the stream and Cordelia has disabled\n        # wildcard notifications, it should just be Othello here.\n        self.assertEqual(info[\"wildcard_mention_user_ids\"], {othello.id})\n\n        # If Hamlet mutes Cordelia, he should be in `muted_sender_user_ids` for a message\n        # sent by Cordelia.\n        do_mute_user(hamlet, cordelia)\n        info = get_recipient_info(\n            realm_id=realm.id,\n            recipient=recipient,\n            sender_id=cordelia.id,\n            stream_topic=stream_topic,\n            possible_wildcard_mention=True,\n        )\n        self.assertTrue(hamlet.id in info[\"muted_sender_user_ids\"])\n\n        sub = get_subscription(stream_name, othello)\n        sub.wildcard_mentions_notify = False\n        sub.save()\n\n        info = get_recipient_info(\n            realm_id=realm.id,\n            recipient=recipient,\n            sender_id=hamlet.id,\n            stream_topic=stream_topic,\n            possible_wildcard_mention=True,\n        )\n        self.assertEqual(info[\"stream_push_user_ids\"], set())\n        # Verify that stream-level wildcard_mentions_notify=False works correctly.\n        self.assertEqual(info[\"wildcard_mention_user_ids\"], set())\n\n        # Verify that True works as expected as well\n        sub = get_subscription(stream_name, othello)\n        sub.wildcard_mentions_notify = True\n        sub.save()\n\n        info = get_recipient_info(\n            realm_id=realm.id,\n            recipient=recipient,\n            sender_id=hamlet.id,\n            stream_topic=stream_topic,\n            possible_wildcard_mention=True,\n        )\n        self.assertEqual(info[\"stream_push_user_ids\"], set())\n        self.assertEqual(info[\"wildcard_mention_user_ids\"], {othello.id})\n\n        # Add a service bot.\n        service_bot = do_create_user(\n            email=\"service-bot@zulip.com\",\n            password=\"\",\n            realm=realm,\n            full_name=\"\",\n            bot_type=UserProfile.EMBEDDED_BOT,\n            acting_user=None,\n        )\n\n        info = get_recipient_info(\n            realm_id=realm.id,\n            recipient=recipient,\n            sender_id=hamlet.id,\n            stream_topic=stream_topic,\n            possibly_mentioned_user_ids={service_bot.id},\n        )\n        self.assertEqual(\n            info[\"service_bot_tuples\"],\n            [\n                (service_bot.id, UserProfile.EMBEDDED_BOT),\n            ],\n        )\n\n        # Add a normal bot.\n        normal_bot = do_create_user(\n            email=\"normal-bot@zulip.com\",\n            password=\"\",\n            realm=realm,\n            full_name=\"\",\n            bot_type=UserProfile.DEFAULT_BOT,\n            acting_user=None,\n        )\n\n        info = get_recipient_info(\n            realm_id=realm.id,\n            recipient=recipient,\n            sender_id=hamlet.id,\n            stream_topic=stream_topic,\n            possibly_mentioned_user_ids={service_bot.id, normal_bot.id},\n        )\n        self.assertEqual(info[\"default_bot_user_ids\"], {normal_bot.id})\n        self.assertEqual(info[\"all_bot_user_ids\"], {normal_bot.id, service_bot.id})\n\n    def test_get_recipient_info_invalid_recipient_type(self) -> None:\n        hamlet = self.example_user(\"hamlet\")\n        realm = hamlet.realm\n\n        stream = get_stream(\"Rome\", realm)\n        stream_topic = StreamTopicTarget(\n            stream_id=stream.id,\n            topic_name=\"test topic\",\n        )\n\n        # Make sure get_recipient_info asserts on invalid recipient types\n        with self.assertRaisesRegex(ValueError, \"Bad recipient type\"):\n            invalid_recipient = Recipient(type=999)  # 999 is not a valid type\n            get_recipient_info(\n                realm_id=realm.id,\n                recipient=invalid_recipient,\n                sender_id=hamlet.id,\n                stream_topic=stream_topic,\n            )\n\n\nclass BulkUsersTest(ZulipTestCase):\n    def test_client_gravatar_option(self) -> None:\n        reset_emails_in_zulip_realm()\n        self.login(\"cordelia\")\n\n        hamlet = self.example_user(\"hamlet\")\n\n        def get_hamlet_avatar(client_gravatar: bool) -> Optional[str]:\n            data = dict(client_gravatar=orjson.dumps(client_gravatar).decode())\n            result = self.client_get(\"/json/users\", data)\n            self.assert_json_success(result)\n            rows = result.json()[\"members\"]\n            hamlet_data = [row for row in rows if row[\"user_id\"] == hamlet.id][0]\n            return hamlet_data[\"avatar_url\"]\n\n        self.assertEqual(\n            get_hamlet_avatar(client_gravatar=True),\n            None,\n        )\n\n        \"\"\"\n        The main purpose of this test is to make sure we\n        return None for avatar_url when client_gravatar is\n        set to True.  And we do a sanity check for when it's\n        False, but we leave it to other tests to validate\n        the specific URL.\n        \"\"\"\n        self.assertIn(\n            \"gravatar.com\",\n            assert_is_not_none(get_hamlet_avatar(client_gravatar=False)),\n        )\n\n\nclass GetProfileTest(ZulipTestCase):\n    def test_cache_behavior(self) -> None:\n        \"\"\"Tests whether fetching a user object the normal way, with\n        `get_user`, makes 1 cache query and 1 database query.\n        \"\"\"\n        realm = get_realm(\"zulip\")\n        email = self.example_user(\"hamlet\").email\n        with queries_captured() as queries:\n            with simulated_empty_cache() as cache_queries:\n                user_profile = get_user(email, realm)\n\n        self.assert_length(queries, 1)\n        self.assert_length(cache_queries, 1)\n        self.assertEqual(user_profile.email, email)\n\n    def test_get_user_profile(self) -> None:\n        hamlet = self.example_user(\"hamlet\")\n        iago = self.example_user(\"iago\")\n        desdemona = self.example_user(\"desdemona\")\n        shiva = self.example_user(\"shiva\")\n        self.login(\"hamlet\")\n        result = orjson.loads(self.client_get(\"/json/users/me\").content)\n        self.assertEqual(result[\"email\"], hamlet.email)\n        self.assertEqual(result[\"full_name\"], \"King Hamlet\")\n        self.assertIn(\"user_id\", result)\n        self.assertFalse(result[\"is_bot\"])\n        self.assertFalse(result[\"is_admin\"])\n        self.assertFalse(result[\"is_owner\"])\n        self.assertFalse(result[\"is_guest\"])\n        self.assertEqual(result[\"role\"], UserProfile.ROLE_MEMBER)\n        self.assertFalse(\"delivery_email\" in result)\n        self.login(\"iago\")\n        result = orjson.loads(self.client_get(\"/json/users/me\").content)\n        self.assertEqual(result[\"email\"], iago.email)\n        self.assertEqual(result[\"full_name\"], \"Iago\")\n        self.assertFalse(result[\"is_bot\"])\n        self.assertTrue(result[\"is_admin\"])\n        self.assertFalse(result[\"is_owner\"])\n        self.assertFalse(result[\"is_guest\"])\n        self.assertEqual(result[\"role\"], UserProfile.ROLE_REALM_ADMINISTRATOR)\n        self.login(\"desdemona\")\n        result = orjson.loads(self.client_get(\"/json/users/me\").content)\n        self.assertEqual(result[\"email\"], desdemona.email)\n        self.assertFalse(result[\"is_bot\"])\n        self.assertTrue(result[\"is_admin\"])\n        self.assertTrue(result[\"is_owner\"])\n        self.assertFalse(result[\"is_guest\"])\n        self.assertEqual(result[\"role\"], UserProfile.ROLE_REALM_OWNER)\n        self.login(\"shiva\")\n        result = orjson.loads(self.client_get(\"/json/users/me\").content)\n        self.assertEqual(result[\"email\"], shiva.email)\n        self.assertFalse(result[\"is_bot\"])\n        self.assertFalse(result[\"is_admin\"])\n        self.assertFalse(result[\"is_owner\"])\n        self.assertFalse(result[\"is_guest\"])\n        self.assertEqual(result[\"role\"], UserProfile.ROLE_MODERATOR)\n\n        # Tests the GET ../users/{id} API endpoint.\n        user = self.example_user(\"hamlet\")\n        result = orjson.loads(self.client_get(f\"/json/users/{user.id}\").content)\n        self.assertEqual(result[\"user\"][\"email\"], user.email)\n        self.assertEqual(result[\"user\"][\"full_name\"], user.full_name)\n        self.assertIn(\"user_id\", result[\"user\"])\n        self.assertNotIn(\"profile_data\", result[\"user\"])\n        self.assertFalse(result[\"user\"][\"is_bot\"])\n        self.assertFalse(result[\"user\"][\"is_admin\"])\n        self.assertFalse(result[\"user\"][\"is_owner\"])\n\n        result = orjson.loads(\n            self.client_get(\n                f\"/json/users/{user.id}\", {\"include_custom_profile_fields\": \"true\"}\n            ).content\n        )\n\n        self.assertIn(\"profile_data\", result[\"user\"])\n        result = self.client_get(\"/json/users/30\")\n        self.assert_json_error(result, \"No such user\")\n\n        bot = self.example_user(\"default_bot\")\n        result = orjson.loads(self.client_get(f\"/json/users/{bot.id}\").content)\n        self.assertEqual(result[\"user\"][\"email\"], bot.email)\n        self.assertTrue(result[\"user\"][\"is_bot\"])\n\n    def test_get_user_by_email(self) -> None:\n        user = self.example_user(\"hamlet\")\n        self.login(\"hamlet\")\n        result = orjson.loads(self.client_get(f\"/json/users/{user.email}\").content)\n\n        self.assertEqual(result[\"user\"][\"email\"], user.email)\n\n        self.assertEqual(result[\"user\"][\"full_name\"], user.full_name)\n        self.assertIn(\"user_id\", result[\"user\"])\n        self.assertNotIn(\"profile_data\", result[\"user\"])\n        self.assertFalse(result[\"user\"][\"is_bot\"])\n        self.assertFalse(result[\"user\"][\"is_admin\"])\n        self.assertFalse(result[\"user\"][\"is_owner\"])\n\n        result = orjson.loads(\n            self.client_get(\n                f\"/json/users/{user.email}\", {\"include_custom_profile_fields\": \"true\"}\n            ).content\n        )\n        self.assertIn(\"profile_data\", result[\"user\"])\n\n        result = self.client_get(\"/json/users/invalid\")\n        self.assert_json_error(result, \"No such user\")\n\n        bot = self.example_user(\"default_bot\")\n        result = orjson.loads(self.client_get(f\"/json/users/{bot.email}\").content)\n        self.assertEqual(result[\"user\"][\"email\"], bot.email)\n        self.assertTrue(result[\"user\"][\"is_bot\"])\n\n    def test_get_all_profiles_avatar_urls(self) -> None:\n        hamlet = self.example_user(\"hamlet\")\n        result = self.api_get(hamlet, \"/api/v1/users\")\n        self.assert_json_success(result)\n\n        (my_user,) = (user for user in result.json()[\"members\"] if user[\"email\"] == hamlet.email)\n\n        self.assertEqual(\n            my_user[\"avatar_url\"],\n            avatar_url(hamlet),\n        )\n\n    def test_user_email_according_to_email_address_visibility_setting(self) -> None:\n        hamlet = self.example_user(\"hamlet\")\n\n        realm = hamlet.realm\n        do_set_realm_property(\n            realm,\n            \"email_address_visibility\",\n            Realm.EMAIL_ADDRESS_VISIBILITY_NOBODY,\n            acting_user=None,\n        )\n\n        # Check that even admin cannot access email when setting is set to\n        # EMAIL_ADDRESS_VISIBILITY_NOBODY.\n        self.login(\"iago\")\n        result = orjson.loads(self.client_get(f\"/json/users/{hamlet.id}\").content)\n        self.assertEqual(result[\"user\"].get(\"delivery_email\"), None)\n        self.assertEqual(result[\"user\"].get(\"email\"), f\"user{hamlet.id}@zulip.testserver\")\n\n        do_set_realm_property(\n            realm,\n            \"email_address_visibility\",\n            Realm.EMAIL_ADDRESS_VISIBILITY_ADMINS,\n            acting_user=None,\n        )\n\n        # Check that admin can access email when setting is set to\n        # EMAIL_ADDRESS_VISIBILITY_ADMINS.\n        result = orjson.loads(self.client_get(f\"/json/users/{hamlet.id}\").content)\n        self.assertEqual(result[\"user\"].get(\"delivery_email\"), hamlet.delivery_email)\n        self.assertEqual(result[\"user\"].get(\"email\"), f\"user{hamlet.id}@zulip.testserver\")\n\n        # Check that moderator cannot access email when setting is set to\n        # EMAIL_ADDRESS_VISIBILITY_ADMINS.\n        self.login(\"shiva\")\n        result = orjson.loads(self.client_get(f\"/json/users/{hamlet.id}\").content)\n        self.assertEqual(result[\"user\"].get(\"delivery_email\"), None)\n        self.assertEqual(result[\"user\"].get(\"email\"), f\"user{hamlet.id}@zulip.testserver\")\n\n        do_set_realm_property(\n            realm,\n            \"email_address_visibility\",\n            Realm.EMAIL_ADDRESS_VISIBILITY_MODERATORS,\n            acting_user=None,\n        )\n\n        # Check that moderator can access email when setting is set to\n        # EMAIL_ADDRESS_VISIBILITY_MODERATORS.\n        result = orjson.loads(self.client_get(f\"/json/users/{hamlet.id}\").content)\n        self.assertEqual(result[\"user\"].get(\"delivery_email\"), hamlet.delivery_email)\n        self.assertEqual(result[\"user\"].get(\"email\"), f\"user{hamlet.id}@zulip.testserver\")\n\n        # Check that normal user cannot access email when setting is set to\n        # EMAIL_ADDRESS_VISIBILITY_MODERATORS.\n        self.login(\"cordelia\")\n        result = orjson.loads(self.client_get(f\"/json/users/{hamlet.id}\").content)\n        self.assertEqual(result[\"user\"].get(\"delivery_email\"), None)\n        self.assertEqual(result[\"user\"].get(\"email\"), f\"user{hamlet.id}@zulip.testserver\")\n\n        do_set_realm_property(\n            realm,\n            \"email_address_visibility\",\n            Realm.EMAIL_ADDRESS_VISIBILITY_EVERYONE,\n            acting_user=None,\n        )\n\n        # Check that moderator, member and guest all can access email when setting\n        # is set to EMAIL_ADDRESS_VISIBILITY_EVERYONE.\n        self.login(\"shiva\")\n        result = orjson.loads(self.client_get(f\"/json/users/{hamlet.id}\").content)\n        self.assertEqual(result[\"user\"].get(\"delivery_email\"), None)\n        self.assertEqual(result[\"user\"].get(\"email\"), hamlet.delivery_email)\n\n        self.login(\"cordelia\")\n        result = orjson.loads(self.client_get(f\"/json/users/{hamlet.id}\").content)\n        self.assertEqual(result[\"user\"].get(\"delivery_email\"), None)\n        self.assertEqual(result[\"user\"].get(\"email\"), hamlet.delivery_email)\n\n        self.login(\"polonius\")\n        result = orjson.loads(self.client_get(f\"/json/users/{hamlet.id}\").content)\n        self.assertEqual(result[\"user\"].get(\"delivery_email\"), None)\n        self.assertEqual(result[\"user\"].get(\"email\"), hamlet.delivery_email)\n\n\nclass DeleteUserTest(ZulipTestCase):\n    def test_do_delete_user(self) -> None:\n        realm = get_realm(\"zulip\")\n        cordelia = self.example_user(\"cordelia\")\n        othello = self.example_user(\"othello\")\n        hamlet = self.example_user(\"hamlet\")\n        hamlet_personal_recipient = hamlet.recipient\n        hamlet_user_id = hamlet.id\n        hamlet_date_joined = hamlet.date_joined\n\n        self.send_personal_message(cordelia, hamlet)\n        self.send_personal_message(hamlet, cordelia)\n\n        personal_message_ids_to_hamlet = Message.objects.filter(\n            recipient=hamlet_personal_recipient\n        ).values_list(\"id\", flat=True)\n        self.assertGreater(len(personal_message_ids_to_hamlet), 0)\n        self.assertTrue(Message.objects.filter(sender=hamlet).exists())\n\n        huddle_message_ids_from_cordelia = [\n            self.send_huddle_message(cordelia, [hamlet, othello]) for i in range(3)\n        ]\n        huddle_message_ids_from_hamlet = [\n            self.send_huddle_message(hamlet, [cordelia, othello]) for i in range(3)\n        ]\n\n        huddle_with_hamlet_recipient_ids = list(\n            Subscription.objects.filter(\n                user_profile=hamlet, recipient__type=Recipient.HUDDLE\n            ).values_list(\"recipient_id\", flat=True)\n        )\n        self.assertGreater(len(huddle_with_hamlet_recipient_ids), 0)\n\n        do_delete_user(hamlet)\n\n        replacement_dummy_user = UserProfile.objects.get(id=hamlet_user_id, realm=realm)\n\n        self.assertEqual(\n            replacement_dummy_user.delivery_email, f\"deleteduser{hamlet_user_id}@zulip.testserver\"\n        )\n        self.assertEqual(replacement_dummy_user.is_mirror_dummy, True)\n        self.assertEqual(replacement_dummy_user.is_active, False)\n        self.assertEqual(replacement_dummy_user.date_joined, hamlet_date_joined)\n\n        self.assertEqual(Message.objects.filter(id__in=personal_message_ids_to_hamlet).count(), 0)\n        # Huddle messages from hamlet should have been deleted, but messages of other participants should\n        # be kept.\n        self.assertEqual(Message.objects.filter(id__in=huddle_message_ids_from_hamlet).count(), 0)\n        self.assertEqual(Message.objects.filter(id__in=huddle_message_ids_from_cordelia).count(), 3)\n\n        self.assertEqual(Message.objects.filter(sender_id=hamlet_user_id).count(), 0)\n\n        # Verify that the dummy user is subscribed to the deleted user's huddles, to keep huddle data\n        # in a correct state.\n        for recipient_id in huddle_with_hamlet_recipient_ids:\n            self.assertTrue(\n                Subscription.objects.filter(\n                    user_profile=replacement_dummy_user, recipient_id=recipient_id\n                ).exists()\n            )\n\n\nclass FakeEmailDomainTest(ZulipTestCase):\n    def test_get_fake_email_domain(self) -> None:\n        realm = get_realm(\"zulip\")\n        self.assertEqual(\"zulip.testserver\", get_fake_email_domain(realm))\n\n        with self.settings(EXTERNAL_HOST=\"example.com\"):\n            self.assertEqual(\"zulip.example.com\", get_fake_email_domain(realm))\n\n    @override_settings(FAKE_EMAIL_DOMAIN=\"fakedomain.com\", REALM_HOSTS={\"zulip\": \"127.0.0.1\"})\n    def test_get_fake_email_domain_realm_host_is_ip_addr(self) -> None:\n        realm = get_realm(\"zulip\")\n        self.assertEqual(\"fakedomain.com\", get_fake_email_domain(realm))\n\n    @override_settings(FAKE_EMAIL_DOMAIN=\"invaliddomain\", REALM_HOSTS={\"zulip\": \"127.0.0.1\"})\n    def test_invalid_fake_email_domain(self) -> None:\n        realm = get_realm(\"zulip\")\n        with self.assertRaises(InvalidFakeEmailDomain):\n            get_fake_email_domain(realm)\n\n    @override_settings(FAKE_EMAIL_DOMAIN=\"127.0.0.1\", REALM_HOSTS={\"zulip\": \"127.0.0.1\"})\n    def test_invalid_fake_email_domain_ip(self) -> None:\n        with self.assertRaises(InvalidFakeEmailDomain):\n            realm = get_realm(\"zulip\")\n            get_fake_email_domain(realm)\n"], "filenames": ["zerver/lib/actions.py", "zerver/tests/test_users.py"], "buggy_code_start_loc": [1417, 8], "buggy_code_end_loc": [1443, 1572], "fixing_code_start_loc": [1416, 9], "fixing_code_end_loc": [1444, 1592], "type": "CWE-362", "message": "Zulip is an open source group chat application. Starting with version 4.0 and prior to version 4.11, Zulip is vulnerable to a race condition during account deactivation, where a simultaneous access by the user being deactivated may, in rare cases, allow continued access by the deactivated user. A patch is available in version 4.11 on the 4.x branch and version 5.0-rc1 on the 5.x branch. Upgrading to a fixed version will, as a side effect, deactivate any cached sessions that may have been leaked through this bug. There are currently no known workarounds.", "other": {"cve": {"id": "CVE-2022-24751", "sourceIdentifier": "security-advisories@github.com", "published": "2022-03-16T14:15:08.487", "lastModified": "2022-03-22T15:25:06.063", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "Zulip is an open source group chat application. Starting with version 4.0 and prior to version 4.11, Zulip is vulnerable to a race condition during account deactivation, where a simultaneous access by the user being deactivated may, in rare cases, allow continued access by the deactivated user. A patch is available in version 4.11 on the 4.x branch and version 5.0-rc1 on the 5.x branch. Upgrading to a fixed version will, as a side effect, deactivate any cached sessions that may have been leaked through this bug. There are currently no known workarounds."}, {"lang": "es", "value": "Zulip es una aplicaci\u00f3n de chat de grupo de c\u00f3digo abierto. A partir de la versi\u00f3n 4.0 y versiones anteriores a 4.11, Zulip es vulnerable a una condici\u00f3n de carrera durante la deshabilitaci\u00f3n de la cuenta, donde un acceso simult\u00e1neo por parte del usuario que est\u00e1 siendo deshabilitado puede, en raros casos, permitir el acceso continuo por parte del usuario deshabilitado. Se presenta un parche disponible en versi\u00f3n 4.11 en la rama 4.x y en versi\u00f3n 5.0-rc1 en la rama 5.x. Una actualizaci\u00f3n a una versi\u00f3n corregida deshabilitar\u00e1, como efecto secundario, cualquier sesi\u00f3n en cach\u00e9 que pueda haberse filtrado mediante este bug. Actualmente no se presentan medidas de mitigaci\u00f3n conocidas"}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:H/PR:N/UI:N/S:U/C:H/I:H/A:N", "attackVector": "NETWORK", "attackComplexity": "HIGH", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "HIGH", "availabilityImpact": "NONE", "baseScore": 7.4, "baseSeverity": "HIGH"}, "exploitabilityScore": 2.2, "impactScore": 5.2}, {"source": "security-advisories@github.com", "type": "Secondary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:L/I:L/A:N", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "LOW", "integrityImpact": "LOW", "availabilityImpact": "NONE", "baseScore": 5.4, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 2.8, "impactScore": 2.5}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:N/AC:M/Au:N/C:P/I:P/A:N", "accessVector": "NETWORK", "accessComplexity": "MEDIUM", "authentication": "NONE", "confidentialityImpact": "PARTIAL", "integrityImpact": "PARTIAL", "availabilityImpact": "NONE", "baseScore": 5.8}, "baseSeverity": "MEDIUM", "exploitabilityScore": 8.6, "impactScore": 4.9, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "security-advisories@github.com", "type": "Primary", "description": [{"lang": "en", "value": "CWE-362"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:zulip:zulip:*:*:*:*:*:*:*:*", "versionStartIncluding": "4.0", "versionEndExcluding": "4.11", "matchCriteriaId": "011572BD-FA58-42D2-AC46-1503D66E31D3"}]}]}], "references": [{"url": "https://github.com/zulip/zulip/commit/62ba8e455d8f460001d9fb486a6dabfd1ed67717", "source": "security-advisories@github.com", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/zulip/zulip/commit/e6eace307ef435eec3395c99247155efed9219e4", "source": "security-advisories@github.com", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/zulip/zulip/security/advisories/GHSA-6v98-m5x5-phqj", "source": "security-advisories@github.com", "tags": ["Third Party Advisory"]}]}, "github_commit_url": "https://github.com/zulip/zulip/commit/62ba8e455d8f460001d9fb486a6dabfd1ed67717"}}
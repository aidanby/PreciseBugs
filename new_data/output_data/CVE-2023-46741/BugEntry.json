{"buggy_code": ["// Copyright 2022 The CubeFS Authors.\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n// implied. See the License for the specific language governing\n// permissions and limitations under the License.\n\npackage access\n\nimport (\n\t\"crypto/sha1\"\n\t\"fmt\"\n\t\"net/http\"\n\t\"strconv\"\n\t\"sync\"\n\t\"time\"\n\n\t\"github.com/cubefs/cubefs/blobstore/access/controller\"\n\t\"github.com/cubefs/cubefs/blobstore/api/access\"\n\t\"github.com/cubefs/cubefs/blobstore/api/clustermgr\"\n\t\"github.com/cubefs/cubefs/blobstore/cmd\"\n\t\"github.com/cubefs/cubefs/blobstore/common/consul\"\n\terrcode \"github.com/cubefs/cubefs/blobstore/common/errors\"\n\t\"github.com/cubefs/cubefs/blobstore/common/profile\"\n\t\"github.com/cubefs/cubefs/blobstore/common/proto\"\n\t\"github.com/cubefs/cubefs/blobstore/common/resourcepool\"\n\t\"github.com/cubefs/cubefs/blobstore/common/rpc\"\n\t\"github.com/cubefs/cubefs/blobstore/common/trace\"\n\t\"github.com/cubefs/cubefs/blobstore/common/uptoken\"\n\t\"github.com/cubefs/cubefs/blobstore/util/closer\"\n\t\"github.com/cubefs/cubefs/blobstore/util/errors\"\n\t\"github.com/cubefs/cubefs/blobstore/util/log\"\n)\n\nconst (\n\tlimitNameAlloc  = \"alloc\"\n\tlimitNamePut    = \"put\"\n\tlimitNamePutAt  = \"putat\"\n\tlimitNameGet    = \"get\"\n\tlimitNameDelete = \"delete\"\n\tlimitNameSign   = \"sign\"\n)\n\nconst (\n\t_tokenExpiration = time.Hour * 12\n)\n\nvar (\n\t// tokenSecretKeys alloc token with the first secret key always,\n\t// so that you can change the secret key.\n\t//\n\t// parse-1: insert a new key at the first index,\n\t// parse-2: delete the old key at the last index after _tokenExpiration duration.\n\ttokenSecretKeys = [...][20]byte{\n\t\t{0x5f, 0x00, 0x88, 0x96, 0x00, 0xa1, 0xfe, 0x1b},\n\t\t{0xff, 0x1f, 0x2f, 0x4f, 0x7f, 0xaf, 0xef, 0xff},\n\t}\n\t_initTokenSecret sync.Once\n)\n\nfunc initTokenSecret(b []byte) {\n\t_initTokenSecret.Do(func() {\n\t\tfor idx := range tokenSecretKeys {\n\t\t\tcopy(tokenSecretKeys[idx][7:], b)\n\t\t}\n\t})\n}\n\nfunc initWithRegionMagic(regionMagic string) {\n\tif regionMagic == \"\" {\n\t\tlog.Warn(\"no region magic setting, using default secret keys for checksum\")\n\t\treturn\n\t}\n\n\tlog.Info(\"using magic secret keys for checksum with:\", regionMagic)\n\tb := sha1.Sum([]byte(regionMagic))\n\tinitTokenSecret(b[:8])\n\tinitLocationSecret(b[:8])\n}\n\ntype accessStatus struct {\n\tLimit Status              `json:\"limit\"`\n\tPool  resourcepool.Status `json:\"pool\"`\n\n\tConfig   StreamConfig                            `json:\"config\"`\n\tClusters []*clustermgr.ClusterInfo               `json:\"clusters\"`\n\tServices map[proto.ClusterID]map[string][]string `json:\"services\"`\n}\n\n// Config service configs\ntype Config struct {\n\tcmd.Config\n\n\tServiceRegister consul.Config `json:\"service_register\"`\n\tStream          StreamConfig  `json:\"stream\"`\n\tLimit           LimitConfig   `json:\"limit\"`\n}\n\n// Service rpc service\ntype Service struct {\n\tconfig        Config\n\tstreamHandler StreamHandler\n\tlimiter       Limiter\n\tcloser        closer.Closer\n}\n\n// New returns an access service\nfunc New(cfg Config) *Service {\n\t// add region magic checksum to the secret keys\n\tinitWithRegionMagic(cfg.Stream.ClusterConfig.RegionMagic)\n\n\tcl := closer.New()\n\treturn &Service{\n\t\tconfig:        cfg,\n\t\tstreamHandler: NewStreamHandler(&cfg.Stream, cl.Done()),\n\t\tlimiter:       NewLimiter(cfg.Limit),\n\t\tcloser:        cl,\n\t}\n}\n\n// Close close server\nfunc (s *Service) Close() {\n\ts.closer.Close()\n}\n\n// RegisterService register service to rpc\nfunc (s *Service) RegisterService() {\n\tif s.config.ServiceRegister.ConsulAddr == \"\" {\n\t\treturn\n\t}\n\t_, err := consul.ServiceRegister(s.config.BindAddr, &s.config.ServiceRegister)\n\tif err != nil {\n\t\tlog.Fatalf(\"service register failed, err: %v\", err)\n\t}\n}\n\n// RegisterAdminHandler register admin handler to profile\nfunc (s *Service) RegisterAdminHandler() {\n\tprofile.HandleFunc(http.MethodGet, \"/access/status\", func(c *rpc.Context) {\n\t\tvar admin *streamAdmin\n\t\tif sa := s.streamHandler.Admin(); sa != nil {\n\t\t\tif ad, ok := sa.(*streamAdmin); ok {\n\t\t\t\tadmin = ad\n\t\t\t}\n\t\t}\n\t\tif admin == nil {\n\t\t\tc.RespondStatus(http.StatusServiceUnavailable)\n\t\t\treturn\n\t\t}\n\n\t\tctx := c.Request.Context()\n\t\tspan := trace.SpanFromContextSafe(ctx)\n\n\t\tstatus := new(accessStatus)\n\t\tstatus.Limit = s.limiter.Status()\n\t\tstatus.Pool = admin.memPool.Status()\n\t\tstatus.Config = admin.config\n\t\tstatus.Clusters = admin.controller.All()\n\t\tstatus.Services = make(map[proto.ClusterID]map[string][]string, len(status.Clusters))\n\n\t\tfor _, cluster := range status.Clusters {\n\t\t\tservice, err := admin.controller.GetServiceController(cluster.ClusterID)\n\t\t\tif err != nil {\n\t\t\t\tspan.Warn(err.Error())\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tsvrs := make(map[string][]string, 1)\n\t\t\tsvrName := proto.ServiceNameProxy\n\t\t\tif hosts, err := service.GetServiceHosts(ctx, svrName); err == nil {\n\t\t\t\tsvrs[svrName] = hosts\n\t\t\t} else {\n\t\t\t\tspan.Warn(err.Error())\n\t\t\t}\n\t\t\tstatus.Services[cluster.ClusterID] = svrs\n\t\t}\n\t\tc.RespondJSON(status)\n\t})\n\n\tprofile.HandleFunc(http.MethodPost, \"/access/stream/controller/alg/:alg\", func(c *rpc.Context) {\n\t\talgInt, err := strconv.ParseUint(c.Param.ByName(\"alg\"), 10, 32)\n\t\tif err != nil {\n\t\t\tc.RespondWith(http.StatusBadRequest, \"\", []byte(err.Error()))\n\t\t\treturn\n\t\t}\n\n\t\talg := controller.AlgChoose(algInt)\n\t\tif sa := s.streamHandler.Admin(); sa != nil {\n\t\t\tif admin, ok := sa.(*streamAdmin); ok {\n\t\t\t\tif err := admin.controller.ChangeChooseAlg(alg); err != nil {\n\t\t\t\t\tc.RespondWith(http.StatusForbidden, \"\", []byte(err.Error()))\n\t\t\t\t\treturn\n\t\t\t\t}\n\n\t\t\t\tspan := trace.SpanFromContextSafe(c.Request.Context())\n\t\t\t\tspan.Warnf(\"change cluster choose algorithm to (%d %s)\", alg, alg.String())\n\t\t\t\tc.Respond()\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\n\t\tc.RespondStatus(http.StatusServiceUnavailable)\n\t}, rpc.OptArgsURI())\n}\n\n// Limit rps controller\nfunc (s *Service) Limit(c *rpc.Context) {\n\tname := \"\"\n\tswitch c.Request.URL.Path {\n\tcase \"/alloc\":\n\t\tname = limitNameAlloc\n\tcase \"/put\":\n\t\tname = limitNamePut\n\tcase \"/putat\":\n\t\tname = limitNamePutAt\n\tcase \"/get\":\n\t\tname = limitNameGet\n\tcase \"/delete\":\n\t\tname = limitNameDelete\n\tcase \"/sign\":\n\t\tname = limitNameSign\n\tdefault:\n\t}\n\tif name == \"\" {\n\t\treturn\n\t}\n\n\tif err := s.limiter.Acquire(name); err != nil {\n\t\tspan := trace.SpanFromContextSafe(c.Request.Context())\n\t\tspan.Info(\"access concurrent limited\", name, err)\n\t\tc.AbortWithError(errcode.ErrAccessLimited)\n\t\treturn\n\t}\n\tdefer s.limiter.Release(name)\n\tc.Next()\n}\n\n// Put one object\nfunc (s *Service) Put(c *rpc.Context) {\n\targs := new(access.PutArgs)\n\tif err := c.ParseArgs(args); err != nil {\n\t\tc.RespondError(err)\n\t\treturn\n\t}\n\n\tctx := c.Request.Context()\n\tspan := trace.SpanFromContextSafe(ctx)\n\n\tspan.Debugf(\"accept /put request args:%+v\", args)\n\tif !args.IsValid() {\n\t\tc.RespondError(errcode.ErrIllegalArguments)\n\t\treturn\n\t}\n\n\thashSumMap := args.Hashes.ToHashSumMap()\n\thasherMap := make(access.HasherMap, len(hashSumMap))\n\t// make hashser\n\tfor alg := range hashSumMap {\n\t\thasherMap[alg] = alg.ToHasher()\n\t}\n\n\trc := s.limiter.Reader(ctx, c.Request.Body)\n\tloc, err := s.streamHandler.Put(ctx, rc, args.Size, hasherMap)\n\tif err != nil {\n\t\tspan.Error(\"stream put failed\", errors.Detail(err))\n\t\tc.RespondError(httpError(err))\n\t\treturn\n\t}\n\n\t// hasher sum\n\tfor alg, hasher := range hasherMap {\n\t\thashSumMap[alg] = hasher.Sum(nil)\n\t}\n\n\tif err := fillCrc(loc); err != nil {\n\t\tspan.Error(\"stream put fill location crc\", err)\n\t\tc.RespondError(httpError(err))\n\t\treturn\n\t}\n\n\tc.RespondJSON(access.PutResp{\n\t\tLocation:   *loc,\n\t\tHashSumMap: hashSumMap,\n\t})\n\tspan.Infof(\"done /put request location:%+v hash:%+v\", loc, hashSumMap.All())\n}\n\n// PutAt put one blob\nfunc (s *Service) PutAt(c *rpc.Context) {\n\targs := new(access.PutAtArgs)\n\tif err := c.ParseArgs(args); err != nil {\n\t\tc.RespondError(err)\n\t\treturn\n\t}\n\n\tctx := c.Request.Context()\n\tspan := trace.SpanFromContextSafe(ctx)\n\n\tspan.Debugf(\"accept /putat request args:%+v\", args)\n\tif !args.IsValid() {\n\t\tc.RespondError(errcode.ErrIllegalArguments)\n\t\treturn\n\t}\n\n\tvalid := false\n\tfor _, secretKey := range tokenSecretKeys {\n\t\ttoken := uptoken.DecodeToken(args.Token)\n\t\tif token.IsValid(args.ClusterID, args.Vid, args.BlobID, uint32(args.Size), secretKey[:]) {\n\t\t\tvalid = true\n\t\t\tbreak\n\t\t}\n\t}\n\tif !valid {\n\t\tspan.Debugf(\"invalid token:%s\", args.Token)\n\t\tc.RespondError(errcode.ErrIllegalArguments)\n\t\treturn\n\t}\n\n\thashSumMap := args.Hashes.ToHashSumMap()\n\thasherMap := make(access.HasherMap, len(hashSumMap))\n\t// make hashser\n\tfor alg := range hashSumMap {\n\t\thasherMap[alg] = alg.ToHasher()\n\t}\n\n\trc := s.limiter.Reader(ctx, c.Request.Body)\n\terr := s.streamHandler.PutAt(ctx, rc, args.ClusterID, args.Vid, args.BlobID, args.Size, hasherMap)\n\tif err != nil {\n\t\tspan.Error(\"stream putat failed\", errors.Detail(err))\n\t\tc.RespondError(httpError(err))\n\t\treturn\n\t}\n\n\t// hasher sum\n\tfor alg, hasher := range hasherMap {\n\t\thashSumMap[alg] = hasher.Sum(nil)\n\t}\n\n\tc.RespondJSON(access.PutAtResp{HashSumMap: hashSumMap})\n\tspan.Infof(\"done /putat request hash:%+v\", hashSumMap.All())\n}\n\n// Alloc alloc one location\nfunc (s *Service) Alloc(c *rpc.Context) {\n\targs := new(access.AllocArgs)\n\tif err := c.ParseArgs(args); err != nil {\n\t\tc.RespondError(err)\n\t\treturn\n\t}\n\n\tctx := c.Request.Context()\n\tspan := trace.SpanFromContextSafe(ctx)\n\n\tspan.Debugf(\"accept /alloc request args:%+v\", args)\n\tif !args.IsValid() {\n\t\tc.RespondError(errcode.ErrIllegalArguments)\n\t\treturn\n\t}\n\n\tlocation, err := s.streamHandler.Alloc(ctx, args.Size, args.BlobSize, args.AssignClusterID, args.CodeMode)\n\tif err != nil {\n\t\tspan.Error(\"stream alloc failed\", errors.Detail(err))\n\t\tc.RespondError(httpError(err))\n\t\treturn\n\t}\n\n\tif err := fillCrc(location); err != nil {\n\t\tspan.Error(\"stream alloc fill location crc\", err)\n\t\tc.RespondError(httpError(err))\n\t\treturn\n\t}\n\n\tresp := access.AllocResp{\n\t\tLocation: *location,\n\t\tTokens:   genTokens(location),\n\t}\n\tc.RespondJSON(resp)\n\tspan.Infof(\"done /alloc request resp:%+v\", resp)\n}\n\n// Get read file\nfunc (s *Service) Get(c *rpc.Context) {\n\targs := new(access.GetArgs)\n\tif err := c.ParseArgs(args); err != nil {\n\t\tc.RespondError(err)\n\t\treturn\n\t}\n\n\tctx := c.Request.Context()\n\tspan := trace.SpanFromContextSafe(ctx)\n\n\tspan.Debugf(\"accept /get request args:%+v\", args)\n\tif !args.IsValid() || !verifyCrc(&args.Location) {\n\t\tc.RespondError(errcode.ErrIllegalArguments)\n\t\treturn\n\t}\n\n\tw := c.Writer\n\twriter := s.limiter.Writer(ctx, w)\n\ttransfer, err := s.streamHandler.Get(ctx, writer, args.Location, args.ReadSize, args.Offset)\n\tif err != nil {\n\t\tspan.Error(\"stream get prepare failed\", errors.Detail(err))\n\t\tc.RespondError(httpError(err))\n\t\treturn\n\t}\n\n\tw.Header().Set(rpc.HeaderContentType, rpc.MIMEStream)\n\tw.Header().Set(rpc.HeaderContentLength, strconv.FormatInt(int64(args.ReadSize), 10))\n\tif args.ReadSize > 0 && args.ReadSize != args.Location.Size {\n\t\tw.Header().Set(rpc.HeaderContentRange, fmt.Sprintf(\"bytes %d-%d/%d\",\n\t\t\targs.Offset, args.Offset+args.ReadSize-1, args.Location.Size))\n\t\tc.RespondStatus(http.StatusPartialContent)\n\t} else {\n\t\tc.RespondStatus(http.StatusOK)\n\t}\n\n\t// flush headers to client firstly\n\tc.Flush()\n\n\terr = transfer()\n\tif err != nil {\n\t\treportDownload(args.Location.ClusterID, \"StatusOKError\", \"-\")\n\t\tspan.Error(\"stream get transfer failed\", errors.Detail(err))\n\t\treturn\n\t}\n\tspan.Info(\"done /get request\")\n}\n\n// Delete  all blobs in this location\nfunc (s *Service) Delete(c *rpc.Context) {\n\targs := new(access.DeleteArgs)\n\tif err := c.ParseArgs(args); err != nil {\n\t\tc.RespondError(err)\n\t\treturn\n\t}\n\n\tctx := c.Request.Context()\n\tspan := trace.SpanFromContextSafe(ctx)\n\n\tvar err error\n\tvar resp access.DeleteResp\n\tdefer func() {\n\t\tif err != nil {\n\t\t\tc.RespondError(httpError(err))\n\t\t\treturn\n\t\t}\n\n\t\tif len(resp.FailedLocations) > 0 {\n\t\t\tspan.Errorf(\"failed locations N %d of %d\", len(resp.FailedLocations), len(args.Locations))\n\t\t\t// must return 2xx even if has failed locations,\n\t\t\t// cos rpc read body only on 2xx.\n\t\t\t// TODO: return other http status code\n\t\t\tc.RespondStatusData(http.StatusIMUsed, resp)\n\t\t\treturn\n\t\t}\n\n\t\tc.RespondJSON(resp)\n\t}()\n\n\tif !args.IsValid() {\n\t\terr = errcode.ErrIllegalArguments\n\t\treturn\n\t}\n\tspan.Debugf(\"accept /delete request args: locations %d\", len(args.Locations))\n\tdefer span.Info(\"done /delete request\")\n\n\tclusterBlobsN := make(map[proto.ClusterID]int, 4)\n\tfor _, loc := range args.Locations {\n\t\tif !verifyCrc(&loc) {\n\t\t\tspan.Infof(\"invalid crc %+v\", loc)\n\t\t\terr = errcode.ErrIllegalArguments\n\t\t\treturn\n\t\t}\n\t\tclusterBlobsN[loc.ClusterID] += len(loc.Blobs)\n\t}\n\n\tif len(args.Locations) == 1 {\n\t\tloc := args.Locations[0]\n\t\tif err := s.streamHandler.Delete(ctx, &loc); err != nil {\n\t\t\tspan.Error(\"stream delete failed\", errors.Detail(err))\n\t\t\tresp.FailedLocations = []access.Location{loc}\n\t\t}\n\t\treturn\n\t}\n\n\t// merge the same cluster locations to one delete message,\n\t// anyone of this cluster failed, all locations mark failure,\n\t//\n\t// a min delete message about 10-20 bytes,\n\t// max delete locations is 1024, one location is max to 5G,\n\t// merged message max size about 40MB.\n\n\tmerged := make(map[proto.ClusterID][]access.SliceInfo, len(clusterBlobsN))\n\tfor id, n := range clusterBlobsN {\n\t\tmerged[id] = make([]access.SliceInfo, 0, n)\n\t}\n\tfor _, loc := range args.Locations {\n\t\tmerged[loc.ClusterID] = append(merged[loc.ClusterID], loc.Blobs...)\n\t}\n\n\tvar wg sync.WaitGroup\n\tfailedCh := make(chan proto.ClusterID, 1)\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tfor id := range failedCh {\n\t\t\tif resp.FailedLocations == nil {\n\t\t\t\tresp.FailedLocations = make([]access.Location, 0, len(args.Locations))\n\t\t\t}\n\t\t\tfor _, loc := range args.Locations {\n\t\t\t\tif loc.ClusterID == id {\n\t\t\t\t\tresp.FailedLocations = append(resp.FailedLocations, loc)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tclose(done)\n\t}()\n\n\twg.Add(len(merged))\n\tfor id := range merged {\n\t\tgo func(id proto.ClusterID) {\n\t\t\tif err := s.streamHandler.Delete(ctx, &access.Location{\n\t\t\t\tClusterID: id,\n\t\t\t\tBlobSize:  1,\n\t\t\t\tBlobs:     merged[id],\n\t\t\t}); err != nil {\n\t\t\t\tspan.Error(\"stream delete failed\", id, errors.Detail(err))\n\t\t\t\tfailedCh <- id\n\t\t\t}\n\t\t\twg.Done()\n\t\t}(id)\n\t}\n\n\twg.Wait()\n\tclose(failedCh)\n\t<-done\n}\n\n// DeleteBlob delete one blob\nfunc (s *Service) DeleteBlob(c *rpc.Context) {\n\targs := new(access.DeleteBlobArgs)\n\tif err := c.ParseArgs(args); err != nil {\n\t\tc.RespondError(err)\n\t\treturn\n\t}\n\n\tctx := c.Request.Context()\n\tspan := trace.SpanFromContextSafe(ctx)\n\n\tspan.Debugf(\"accept /deleteblob request args:%+v\", args)\n\tif !args.IsValid() {\n\t\tc.RespondError(errcode.ErrIllegalArguments)\n\t\treturn\n\t}\n\n\tvalid := false\n\tfor _, secretKey := range tokenSecretKeys {\n\t\ttoken := uptoken.DecodeToken(args.Token)\n\t\tif token.IsValid(args.ClusterID, args.Vid, args.BlobID, uint32(args.Size), secretKey[:]) {\n\t\t\tvalid = true\n\t\t\tbreak\n\t\t}\n\t}\n\tif !valid {\n\t\tspan.Debugf(\"invalid token:%s\", args.Token)\n\t\tc.RespondError(errcode.ErrIllegalArguments)\n\t\treturn\n\t}\n\n\tif err := s.streamHandler.Delete(ctx, &access.Location{\n\t\tClusterID: args.ClusterID,\n\t\tBlobSize:  1,\n\t\tBlobs: []access.SliceInfo{{\n\t\t\tMinBid: args.BlobID,\n\t\t\tVid:    args.Vid,\n\t\t\tCount:  1,\n\t\t}},\n\t}); err != nil {\n\t\tspan.Error(\"stream delete blob failed\", errors.Detail(err))\n\t\tc.RespondError(httpError(err))\n\t\treturn\n\t}\n\n\tc.Respond()\n\tspan.Info(\"done /deleteblob request\")\n}\n\n// Sign generate crc with locations\nfunc (s *Service) Sign(c *rpc.Context) {\n\targs := new(access.SignArgs)\n\tif err := c.ParseArgs(args); err != nil {\n\t\tc.RespondError(err)\n\t\treturn\n\t}\n\n\tctx := c.Request.Context()\n\tspan := trace.SpanFromContextSafe(ctx)\n\n\tif !args.IsValid() {\n\t\tc.RespondError(errcode.ErrIllegalArguments)\n\t\treturn\n\t}\n\tspan.Debugf(\"accept /sign request args: %+v\", args)\n\n\tloc := args.Location\n\tcrcOld := loc.Crc\n\tif err := signCrc(&loc, args.Locations); err != nil {\n\t\tspan.Error(\"stream sign failed\", errors.Detail(err))\n\t\tc.RespondError(errcode.ErrIllegalArguments)\n\t\treturn\n\t}\n\n\tc.RespondJSON(access.SignResp{Location: loc})\n\tspan.Infof(\"done /sign request crc %d -> %d, resp:%+v\", crcOld, loc.Crc, loc)\n}\n\nfunc httpError(err error) error {\n\tif e, ok := err.(rpc.HTTPError); ok {\n\t\treturn e\n\t}\n\tif e, ok := err.(*errors.Error); ok {\n\t\treturn rpc.NewError(http.StatusInternalServerError, \"ServerError\", e.Cause())\n\t}\n\treturn errcode.ErrUnexpected\n}\n\n// genTokens generate tokens\n//  1. Returns 0 token if has no blobs.\n//  2. Returns 1 token if file size less than blobsize.\n//  3. Returns len(blobs) tokens if size divided by blobsize.\n//  4. Otherwise returns len(blobs)+1 tokens, the last token\n//     will be used by the last blob, even if the last slice blobs' size\n//     less than blobsize.\n//  5. Each segment blob has its specified token include the last blob.\nfunc genTokens(location *access.Location) []string {\n\ttokens := make([]string, 0, len(location.Blobs)+1)\n\n\thasMultiBlobs := location.Size >= uint64(location.BlobSize)\n\tlastSize := uint32(location.Size % uint64(location.BlobSize))\n\tfor idx, blob := range location.Blobs {\n\t\t// returns one token if size < blobsize\n\t\tif hasMultiBlobs {\n\t\t\tcount := blob.Count\n\t\t\tif idx == len(location.Blobs)-1 && lastSize > 0 {\n\t\t\t\tcount--\n\t\t\t}\n\t\t\ttokens = append(tokens, uptoken.EncodeToken(uptoken.NewUploadToken(location.ClusterID,\n\t\t\t\tblob.Vid, blob.MinBid, count,\n\t\t\t\tlocation.BlobSize, _tokenExpiration, tokenSecretKeys[0][:])))\n\t\t}\n\n\t\t// token of the last blob\n\t\tif idx == len(location.Blobs)-1 && lastSize > 0 {\n\t\t\ttokens = append(tokens, uptoken.EncodeToken(uptoken.NewUploadToken(location.ClusterID,\n\t\t\t\tblob.Vid, blob.MinBid+proto.BlobID(blob.Count)-1, 1,\n\t\t\t\tlastSize, _tokenExpiration, tokenSecretKeys[0][:])))\n\t\t}\n\t}\n\n\treturn tokens\n}\n"], "fixing_code": ["// Copyright 2022 The CubeFS Authors.\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n// implied. See the License for the specific language governing\n// permissions and limitations under the License.\n\npackage access\n\nimport (\n\t\"crypto/sha1\"\n\t\"fmt\"\n\t\"net/http\"\n\t\"strconv\"\n\t\"sync\"\n\t\"time\"\n\n\t\"github.com/cubefs/cubefs/blobstore/access/controller\"\n\t\"github.com/cubefs/cubefs/blobstore/api/access\"\n\t\"github.com/cubefs/cubefs/blobstore/api/clustermgr\"\n\t\"github.com/cubefs/cubefs/blobstore/cmd\"\n\t\"github.com/cubefs/cubefs/blobstore/common/consul\"\n\terrcode \"github.com/cubefs/cubefs/blobstore/common/errors\"\n\t\"github.com/cubefs/cubefs/blobstore/common/profile\"\n\t\"github.com/cubefs/cubefs/blobstore/common/proto\"\n\t\"github.com/cubefs/cubefs/blobstore/common/resourcepool\"\n\t\"github.com/cubefs/cubefs/blobstore/common/rpc\"\n\t\"github.com/cubefs/cubefs/blobstore/common/trace\"\n\t\"github.com/cubefs/cubefs/blobstore/common/uptoken\"\n\t\"github.com/cubefs/cubefs/blobstore/util/closer\"\n\t\"github.com/cubefs/cubefs/blobstore/util/errors\"\n\t\"github.com/cubefs/cubefs/blobstore/util/log\"\n)\n\nconst (\n\tlimitNameAlloc  = \"alloc\"\n\tlimitNamePut    = \"put\"\n\tlimitNamePutAt  = \"putat\"\n\tlimitNameGet    = \"get\"\n\tlimitNameDelete = \"delete\"\n\tlimitNameSign   = \"sign\"\n)\n\nconst (\n\t_tokenExpiration = time.Hour * 12\n)\n\nvar (\n\t// tokenSecretKeys alloc token with the first secret key always,\n\t// so that you can change the secret key.\n\t//\n\t// parse-1: insert a new key at the first index,\n\t// parse-2: delete the old key at the last index after _tokenExpiration duration.\n\ttokenSecretKeys = [...][20]byte{\n\t\t{0x5f, 0x00, 0x88, 0x96, 0x00, 0xa1, 0xfe, 0x1b},\n\t\t{0xff, 0x1f, 0x2f, 0x4f, 0x7f, 0xaf, 0xef, 0xff},\n\t}\n\t_initTokenSecret sync.Once\n)\n\nfunc initTokenSecret(b []byte) {\n\t_initTokenSecret.Do(func() {\n\t\tfor idx := range tokenSecretKeys {\n\t\t\tcopy(tokenSecretKeys[idx][7:], b)\n\t\t}\n\t})\n}\n\nfunc initWithRegionMagic(regionMagic string) {\n\tif regionMagic == \"\" {\n\t\tlog.Warn(\"no region magic setting, using default secret keys for checksum\")\n\t\treturn\n\t}\n\tb := sha1.Sum([]byte(regionMagic))\n\tinitTokenSecret(b[:8])\n\tinitLocationSecret(b[:8])\n}\n\ntype accessStatus struct {\n\tLimit Status              `json:\"limit\"`\n\tPool  resourcepool.Status `json:\"pool\"`\n\n\tConfig   StreamConfig                            `json:\"config\"`\n\tClusters []*clustermgr.ClusterInfo               `json:\"clusters\"`\n\tServices map[proto.ClusterID]map[string][]string `json:\"services\"`\n}\n\n// Config service configs\ntype Config struct {\n\tcmd.Config\n\n\tServiceRegister consul.Config `json:\"service_register\"`\n\tStream          StreamConfig  `json:\"stream\"`\n\tLimit           LimitConfig   `json:\"limit\"`\n}\n\n// Service rpc service\ntype Service struct {\n\tconfig        Config\n\tstreamHandler StreamHandler\n\tlimiter       Limiter\n\tcloser        closer.Closer\n}\n\n// New returns an access service\nfunc New(cfg Config) *Service {\n\t// add region magic checksum to the secret keys\n\tinitWithRegionMagic(cfg.Stream.ClusterConfig.RegionMagic)\n\n\tcl := closer.New()\n\treturn &Service{\n\t\tconfig:        cfg,\n\t\tstreamHandler: NewStreamHandler(&cfg.Stream, cl.Done()),\n\t\tlimiter:       NewLimiter(cfg.Limit),\n\t\tcloser:        cl,\n\t}\n}\n\n// Close close server\nfunc (s *Service) Close() {\n\ts.closer.Close()\n}\n\n// RegisterService register service to rpc\nfunc (s *Service) RegisterService() {\n\tif s.config.ServiceRegister.ConsulAddr == \"\" {\n\t\treturn\n\t}\n\t_, err := consul.ServiceRegister(s.config.BindAddr, &s.config.ServiceRegister)\n\tif err != nil {\n\t\tlog.Fatalf(\"service register failed, err: %v\", err)\n\t}\n}\n\n// RegisterAdminHandler register admin handler to profile\nfunc (s *Service) RegisterAdminHandler() {\n\tprofile.HandleFunc(http.MethodGet, \"/access/status\", func(c *rpc.Context) {\n\t\tvar admin *streamAdmin\n\t\tif sa := s.streamHandler.Admin(); sa != nil {\n\t\t\tif ad, ok := sa.(*streamAdmin); ok {\n\t\t\t\tadmin = ad\n\t\t\t}\n\t\t}\n\t\tif admin == nil {\n\t\t\tc.RespondStatus(http.StatusServiceUnavailable)\n\t\t\treturn\n\t\t}\n\n\t\tctx := c.Request.Context()\n\t\tspan := trace.SpanFromContextSafe(ctx)\n\n\t\tstatus := new(accessStatus)\n\t\tstatus.Limit = s.limiter.Status()\n\t\tstatus.Pool = admin.memPool.Status()\n\t\tstatus.Config = admin.config\n\t\tstatus.Clusters = admin.controller.All()\n\t\tstatus.Services = make(map[proto.ClusterID]map[string][]string, len(status.Clusters))\n\n\t\tfor _, cluster := range status.Clusters {\n\t\t\tservice, err := admin.controller.GetServiceController(cluster.ClusterID)\n\t\t\tif err != nil {\n\t\t\t\tspan.Warn(err.Error())\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tsvrs := make(map[string][]string, 1)\n\t\t\tsvrName := proto.ServiceNameProxy\n\t\t\tif hosts, err := service.GetServiceHosts(ctx, svrName); err == nil {\n\t\t\t\tsvrs[svrName] = hosts\n\t\t\t} else {\n\t\t\t\tspan.Warn(err.Error())\n\t\t\t}\n\t\t\tstatus.Services[cluster.ClusterID] = svrs\n\t\t}\n\t\tc.RespondJSON(status)\n\t})\n\n\tprofile.HandleFunc(http.MethodPost, \"/access/stream/controller/alg/:alg\", func(c *rpc.Context) {\n\t\talgInt, err := strconv.ParseUint(c.Param.ByName(\"alg\"), 10, 32)\n\t\tif err != nil {\n\t\t\tc.RespondWith(http.StatusBadRequest, \"\", []byte(err.Error()))\n\t\t\treturn\n\t\t}\n\n\t\talg := controller.AlgChoose(algInt)\n\t\tif sa := s.streamHandler.Admin(); sa != nil {\n\t\t\tif admin, ok := sa.(*streamAdmin); ok {\n\t\t\t\tif err := admin.controller.ChangeChooseAlg(alg); err != nil {\n\t\t\t\t\tc.RespondWith(http.StatusForbidden, \"\", []byte(err.Error()))\n\t\t\t\t\treturn\n\t\t\t\t}\n\n\t\t\t\tspan := trace.SpanFromContextSafe(c.Request.Context())\n\t\t\t\tspan.Warnf(\"change cluster choose algorithm to (%d %s)\", alg, alg.String())\n\t\t\t\tc.Respond()\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\n\t\tc.RespondStatus(http.StatusServiceUnavailable)\n\t}, rpc.OptArgsURI())\n}\n\n// Limit rps controller\nfunc (s *Service) Limit(c *rpc.Context) {\n\tname := \"\"\n\tswitch c.Request.URL.Path {\n\tcase \"/alloc\":\n\t\tname = limitNameAlloc\n\tcase \"/put\":\n\t\tname = limitNamePut\n\tcase \"/putat\":\n\t\tname = limitNamePutAt\n\tcase \"/get\":\n\t\tname = limitNameGet\n\tcase \"/delete\":\n\t\tname = limitNameDelete\n\tcase \"/sign\":\n\t\tname = limitNameSign\n\tdefault:\n\t}\n\tif name == \"\" {\n\t\treturn\n\t}\n\n\tif err := s.limiter.Acquire(name); err != nil {\n\t\tspan := trace.SpanFromContextSafe(c.Request.Context())\n\t\tspan.Info(\"access concurrent limited\", name, err)\n\t\tc.AbortWithError(errcode.ErrAccessLimited)\n\t\treturn\n\t}\n\tdefer s.limiter.Release(name)\n\tc.Next()\n}\n\n// Put one object\nfunc (s *Service) Put(c *rpc.Context) {\n\targs := new(access.PutArgs)\n\tif err := c.ParseArgs(args); err != nil {\n\t\tc.RespondError(err)\n\t\treturn\n\t}\n\n\tctx := c.Request.Context()\n\tspan := trace.SpanFromContextSafe(ctx)\n\n\tspan.Debugf(\"accept /put request args:%+v\", args)\n\tif !args.IsValid() {\n\t\tc.RespondError(errcode.ErrIllegalArguments)\n\t\treturn\n\t}\n\n\thashSumMap := args.Hashes.ToHashSumMap()\n\thasherMap := make(access.HasherMap, len(hashSumMap))\n\t// make hashser\n\tfor alg := range hashSumMap {\n\t\thasherMap[alg] = alg.ToHasher()\n\t}\n\n\trc := s.limiter.Reader(ctx, c.Request.Body)\n\tloc, err := s.streamHandler.Put(ctx, rc, args.Size, hasherMap)\n\tif err != nil {\n\t\tspan.Error(\"stream put failed\", errors.Detail(err))\n\t\tc.RespondError(httpError(err))\n\t\treturn\n\t}\n\n\t// hasher sum\n\tfor alg, hasher := range hasherMap {\n\t\thashSumMap[alg] = hasher.Sum(nil)\n\t}\n\n\tif err := fillCrc(loc); err != nil {\n\t\tspan.Error(\"stream put fill location crc\", err)\n\t\tc.RespondError(httpError(err))\n\t\treturn\n\t}\n\n\tc.RespondJSON(access.PutResp{\n\t\tLocation:   *loc,\n\t\tHashSumMap: hashSumMap,\n\t})\n\tspan.Infof(\"done /put request location:%+v hash:%+v\", loc, hashSumMap.All())\n}\n\n// PutAt put one blob\nfunc (s *Service) PutAt(c *rpc.Context) {\n\targs := new(access.PutAtArgs)\n\tif err := c.ParseArgs(args); err != nil {\n\t\tc.RespondError(err)\n\t\treturn\n\t}\n\n\tctx := c.Request.Context()\n\tspan := trace.SpanFromContextSafe(ctx)\n\n\tspan.Debugf(\"accept /putat request args:%+v\", args)\n\tif !args.IsValid() {\n\t\tc.RespondError(errcode.ErrIllegalArguments)\n\t\treturn\n\t}\n\n\tvalid := false\n\tfor _, secretKey := range tokenSecretKeys {\n\t\ttoken := uptoken.DecodeToken(args.Token)\n\t\tif token.IsValid(args.ClusterID, args.Vid, args.BlobID, uint32(args.Size), secretKey[:]) {\n\t\t\tvalid = true\n\t\t\tbreak\n\t\t}\n\t}\n\tif !valid {\n\t\tspan.Debugf(\"invalid token:%s\", args.Token)\n\t\tc.RespondError(errcode.ErrIllegalArguments)\n\t\treturn\n\t}\n\n\thashSumMap := args.Hashes.ToHashSumMap()\n\thasherMap := make(access.HasherMap, len(hashSumMap))\n\t// make hashser\n\tfor alg := range hashSumMap {\n\t\thasherMap[alg] = alg.ToHasher()\n\t}\n\n\trc := s.limiter.Reader(ctx, c.Request.Body)\n\terr := s.streamHandler.PutAt(ctx, rc, args.ClusterID, args.Vid, args.BlobID, args.Size, hasherMap)\n\tif err != nil {\n\t\tspan.Error(\"stream putat failed\", errors.Detail(err))\n\t\tc.RespondError(httpError(err))\n\t\treturn\n\t}\n\n\t// hasher sum\n\tfor alg, hasher := range hasherMap {\n\t\thashSumMap[alg] = hasher.Sum(nil)\n\t}\n\n\tc.RespondJSON(access.PutAtResp{HashSumMap: hashSumMap})\n\tspan.Infof(\"done /putat request hash:%+v\", hashSumMap.All())\n}\n\n// Alloc alloc one location\nfunc (s *Service) Alloc(c *rpc.Context) {\n\targs := new(access.AllocArgs)\n\tif err := c.ParseArgs(args); err != nil {\n\t\tc.RespondError(err)\n\t\treturn\n\t}\n\n\tctx := c.Request.Context()\n\tspan := trace.SpanFromContextSafe(ctx)\n\n\tspan.Debugf(\"accept /alloc request args:%+v\", args)\n\tif !args.IsValid() {\n\t\tc.RespondError(errcode.ErrIllegalArguments)\n\t\treturn\n\t}\n\n\tlocation, err := s.streamHandler.Alloc(ctx, args.Size, args.BlobSize, args.AssignClusterID, args.CodeMode)\n\tif err != nil {\n\t\tspan.Error(\"stream alloc failed\", errors.Detail(err))\n\t\tc.RespondError(httpError(err))\n\t\treturn\n\t}\n\n\tif err := fillCrc(location); err != nil {\n\t\tspan.Error(\"stream alloc fill location crc\", err)\n\t\tc.RespondError(httpError(err))\n\t\treturn\n\t}\n\n\tresp := access.AllocResp{\n\t\tLocation: *location,\n\t\tTokens:   genTokens(location),\n\t}\n\tc.RespondJSON(resp)\n\tspan.Infof(\"done /alloc request resp:%+v\", resp)\n}\n\n// Get read file\nfunc (s *Service) Get(c *rpc.Context) {\n\targs := new(access.GetArgs)\n\tif err := c.ParseArgs(args); err != nil {\n\t\tc.RespondError(err)\n\t\treturn\n\t}\n\n\tctx := c.Request.Context()\n\tspan := trace.SpanFromContextSafe(ctx)\n\n\tspan.Debugf(\"accept /get request args:%+v\", args)\n\tif !args.IsValid() || !verifyCrc(&args.Location) {\n\t\tc.RespondError(errcode.ErrIllegalArguments)\n\t\treturn\n\t}\n\n\tw := c.Writer\n\twriter := s.limiter.Writer(ctx, w)\n\ttransfer, err := s.streamHandler.Get(ctx, writer, args.Location, args.ReadSize, args.Offset)\n\tif err != nil {\n\t\tspan.Error(\"stream get prepare failed\", errors.Detail(err))\n\t\tc.RespondError(httpError(err))\n\t\treturn\n\t}\n\n\tw.Header().Set(rpc.HeaderContentType, rpc.MIMEStream)\n\tw.Header().Set(rpc.HeaderContentLength, strconv.FormatInt(int64(args.ReadSize), 10))\n\tif args.ReadSize > 0 && args.ReadSize != args.Location.Size {\n\t\tw.Header().Set(rpc.HeaderContentRange, fmt.Sprintf(\"bytes %d-%d/%d\",\n\t\t\targs.Offset, args.Offset+args.ReadSize-1, args.Location.Size))\n\t\tc.RespondStatus(http.StatusPartialContent)\n\t} else {\n\t\tc.RespondStatus(http.StatusOK)\n\t}\n\n\t// flush headers to client firstly\n\tc.Flush()\n\n\terr = transfer()\n\tif err != nil {\n\t\treportDownload(args.Location.ClusterID, \"StatusOKError\", \"-\")\n\t\tspan.Error(\"stream get transfer failed\", errors.Detail(err))\n\t\treturn\n\t}\n\tspan.Info(\"done /get request\")\n}\n\n// Delete  all blobs in this location\nfunc (s *Service) Delete(c *rpc.Context) {\n\targs := new(access.DeleteArgs)\n\tif err := c.ParseArgs(args); err != nil {\n\t\tc.RespondError(err)\n\t\treturn\n\t}\n\n\tctx := c.Request.Context()\n\tspan := trace.SpanFromContextSafe(ctx)\n\n\tvar err error\n\tvar resp access.DeleteResp\n\tdefer func() {\n\t\tif err != nil {\n\t\t\tc.RespondError(httpError(err))\n\t\t\treturn\n\t\t}\n\n\t\tif len(resp.FailedLocations) > 0 {\n\t\t\tspan.Errorf(\"failed locations N %d of %d\", len(resp.FailedLocations), len(args.Locations))\n\t\t\t// must return 2xx even if has failed locations,\n\t\t\t// cos rpc read body only on 2xx.\n\t\t\t// TODO: return other http status code\n\t\t\tc.RespondStatusData(http.StatusIMUsed, resp)\n\t\t\treturn\n\t\t}\n\n\t\tc.RespondJSON(resp)\n\t}()\n\n\tif !args.IsValid() {\n\t\terr = errcode.ErrIllegalArguments\n\t\treturn\n\t}\n\tspan.Debugf(\"accept /delete request args: locations %d\", len(args.Locations))\n\tdefer span.Info(\"done /delete request\")\n\n\tclusterBlobsN := make(map[proto.ClusterID]int, 4)\n\tfor _, loc := range args.Locations {\n\t\tif !verifyCrc(&loc) {\n\t\t\tspan.Infof(\"invalid crc %+v\", loc)\n\t\t\terr = errcode.ErrIllegalArguments\n\t\t\treturn\n\t\t}\n\t\tclusterBlobsN[loc.ClusterID] += len(loc.Blobs)\n\t}\n\n\tif len(args.Locations) == 1 {\n\t\tloc := args.Locations[0]\n\t\tif err := s.streamHandler.Delete(ctx, &loc); err != nil {\n\t\t\tspan.Error(\"stream delete failed\", errors.Detail(err))\n\t\t\tresp.FailedLocations = []access.Location{loc}\n\t\t}\n\t\treturn\n\t}\n\n\t// merge the same cluster locations to one delete message,\n\t// anyone of this cluster failed, all locations mark failure,\n\t//\n\t// a min delete message about 10-20 bytes,\n\t// max delete locations is 1024, one location is max to 5G,\n\t// merged message max size about 40MB.\n\n\tmerged := make(map[proto.ClusterID][]access.SliceInfo, len(clusterBlobsN))\n\tfor id, n := range clusterBlobsN {\n\t\tmerged[id] = make([]access.SliceInfo, 0, n)\n\t}\n\tfor _, loc := range args.Locations {\n\t\tmerged[loc.ClusterID] = append(merged[loc.ClusterID], loc.Blobs...)\n\t}\n\n\tvar wg sync.WaitGroup\n\tfailedCh := make(chan proto.ClusterID, 1)\n\tdone := make(chan struct{})\n\tgo func() {\n\t\tfor id := range failedCh {\n\t\t\tif resp.FailedLocations == nil {\n\t\t\t\tresp.FailedLocations = make([]access.Location, 0, len(args.Locations))\n\t\t\t}\n\t\t\tfor _, loc := range args.Locations {\n\t\t\t\tif loc.ClusterID == id {\n\t\t\t\t\tresp.FailedLocations = append(resp.FailedLocations, loc)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tclose(done)\n\t}()\n\n\twg.Add(len(merged))\n\tfor id := range merged {\n\t\tgo func(id proto.ClusterID) {\n\t\t\tif err := s.streamHandler.Delete(ctx, &access.Location{\n\t\t\t\tClusterID: id,\n\t\t\t\tBlobSize:  1,\n\t\t\t\tBlobs:     merged[id],\n\t\t\t}); err != nil {\n\t\t\t\tspan.Error(\"stream delete failed\", id, errors.Detail(err))\n\t\t\t\tfailedCh <- id\n\t\t\t}\n\t\t\twg.Done()\n\t\t}(id)\n\t}\n\n\twg.Wait()\n\tclose(failedCh)\n\t<-done\n}\n\n// DeleteBlob delete one blob\nfunc (s *Service) DeleteBlob(c *rpc.Context) {\n\targs := new(access.DeleteBlobArgs)\n\tif err := c.ParseArgs(args); err != nil {\n\t\tc.RespondError(err)\n\t\treturn\n\t}\n\n\tctx := c.Request.Context()\n\tspan := trace.SpanFromContextSafe(ctx)\n\n\tspan.Debugf(\"accept /deleteblob request args:%+v\", args)\n\tif !args.IsValid() {\n\t\tc.RespondError(errcode.ErrIllegalArguments)\n\t\treturn\n\t}\n\n\tvalid := false\n\tfor _, secretKey := range tokenSecretKeys {\n\t\ttoken := uptoken.DecodeToken(args.Token)\n\t\tif token.IsValid(args.ClusterID, args.Vid, args.BlobID, uint32(args.Size), secretKey[:]) {\n\t\t\tvalid = true\n\t\t\tbreak\n\t\t}\n\t}\n\tif !valid {\n\t\tspan.Debugf(\"invalid token:%s\", args.Token)\n\t\tc.RespondError(errcode.ErrIllegalArguments)\n\t\treturn\n\t}\n\n\tif err := s.streamHandler.Delete(ctx, &access.Location{\n\t\tClusterID: args.ClusterID,\n\t\tBlobSize:  1,\n\t\tBlobs: []access.SliceInfo{{\n\t\t\tMinBid: args.BlobID,\n\t\t\tVid:    args.Vid,\n\t\t\tCount:  1,\n\t\t}},\n\t}); err != nil {\n\t\tspan.Error(\"stream delete blob failed\", errors.Detail(err))\n\t\tc.RespondError(httpError(err))\n\t\treturn\n\t}\n\n\tc.Respond()\n\tspan.Info(\"done /deleteblob request\")\n}\n\n// Sign generate crc with locations\nfunc (s *Service) Sign(c *rpc.Context) {\n\targs := new(access.SignArgs)\n\tif err := c.ParseArgs(args); err != nil {\n\t\tc.RespondError(err)\n\t\treturn\n\t}\n\n\tctx := c.Request.Context()\n\tspan := trace.SpanFromContextSafe(ctx)\n\n\tif !args.IsValid() {\n\t\tc.RespondError(errcode.ErrIllegalArguments)\n\t\treturn\n\t}\n\tspan.Debugf(\"accept /sign request args: %+v\", args)\n\n\tloc := args.Location\n\tcrcOld := loc.Crc\n\tif err := signCrc(&loc, args.Locations); err != nil {\n\t\tspan.Error(\"stream sign failed\", errors.Detail(err))\n\t\tc.RespondError(errcode.ErrIllegalArguments)\n\t\treturn\n\t}\n\n\tc.RespondJSON(access.SignResp{Location: loc})\n\tspan.Infof(\"done /sign request crc %d -> %d, resp:%+v\", crcOld, loc.Crc, loc)\n}\n\nfunc httpError(err error) error {\n\tif e, ok := err.(rpc.HTTPError); ok {\n\t\treturn e\n\t}\n\tif e, ok := err.(*errors.Error); ok {\n\t\treturn rpc.NewError(http.StatusInternalServerError, \"ServerError\", e.Cause())\n\t}\n\treturn errcode.ErrUnexpected\n}\n\n// genTokens generate tokens\n//  1. Returns 0 token if has no blobs.\n//  2. Returns 1 token if file size less than blobsize.\n//  3. Returns len(blobs) tokens if size divided by blobsize.\n//  4. Otherwise returns len(blobs)+1 tokens, the last token\n//     will be used by the last blob, even if the last slice blobs' size\n//     less than blobsize.\n//  5. Each segment blob has its specified token include the last blob.\nfunc genTokens(location *access.Location) []string {\n\ttokens := make([]string, 0, len(location.Blobs)+1)\n\n\thasMultiBlobs := location.Size >= uint64(location.BlobSize)\n\tlastSize := uint32(location.Size % uint64(location.BlobSize))\n\tfor idx, blob := range location.Blobs {\n\t\t// returns one token if size < blobsize\n\t\tif hasMultiBlobs {\n\t\t\tcount := blob.Count\n\t\t\tif idx == len(location.Blobs)-1 && lastSize > 0 {\n\t\t\t\tcount--\n\t\t\t}\n\t\t\ttokens = append(tokens, uptoken.EncodeToken(uptoken.NewUploadToken(location.ClusterID,\n\t\t\t\tblob.Vid, blob.MinBid, count,\n\t\t\t\tlocation.BlobSize, _tokenExpiration, tokenSecretKeys[0][:])))\n\t\t}\n\n\t\t// token of the last blob\n\t\tif idx == len(location.Blobs)-1 && lastSize > 0 {\n\t\t\ttokens = append(tokens, uptoken.EncodeToken(uptoken.NewUploadToken(location.ClusterID,\n\t\t\t\tblob.Vid, blob.MinBid+proto.BlobID(blob.Count)-1, 1,\n\t\t\t\tlastSize, _tokenExpiration, tokenSecretKeys[0][:])))\n\t\t}\n\t}\n\n\treturn tokens\n}\n"], "filenames": ["blobstore/access/server.go"], "buggy_code_start_loc": [81], "buggy_code_end_loc": [83], "fixing_code_start_loc": [80], "fixing_code_end_loc": [80], "type": "NVD-CWE-noinfo", "message": "CubeFS is an open-source cloud-native file storage system. A vulnerability was found in CubeFS prior to version 3.3.1 that could allow users to read sensitive data from the logs which could allow them escalate privileges. CubeFS leaks configuration keys in plaintext format in the logs. These keys could allow anyone to carry out operations on blobs that they otherwise do not have permissions for. For example, an attacker that has succesfully retrieved a secret key from the logs can delete blogs from the blob store. The attacker can either be an internal user with limited privileges to read the log, or they can be an external user who has escalated privileges sufficiently to access the logs. The vulnerability has been patched in v3.3.1. There is no other mitigation than upgrading.\n", "other": {"cve": {"id": "CVE-2023-46741", "sourceIdentifier": "security-advisories@github.com", "published": "2024-01-03T17:15:10.797", "lastModified": "2024-01-10T16:46:10.643", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "CubeFS is an open-source cloud-native file storage system. A vulnerability was found in CubeFS prior to version 3.3.1 that could allow users to read sensitive data from the logs which could allow them escalate privileges. CubeFS leaks configuration keys in plaintext format in the logs. These keys could allow anyone to carry out operations on blobs that they otherwise do not have permissions for. For example, an attacker that has succesfully retrieved a secret key from the logs can delete blogs from the blob store. The attacker can either be an internal user with limited privileges to read the log, or they can be an external user who has escalated privileges sufficiently to access the logs. The vulnerability has been patched in v3.3.1. There is no other mitigation than upgrading.\n"}, {"lang": "es", "value": "CubeFS es un sistema de almacenamiento de archivos nativo de la nube de c\u00f3digo abierto. Se encontr\u00f3 una vulnerabilidad en CubeFS anterior a la versi\u00f3n 3.3.1 que podr\u00eda permitir a los usuarios leer datos confidenciales de los registros, lo que podr\u00eda permitirles escalar privilegios. CubeFS filtra claves de configuraci\u00f3n en formato de texto plano en los registros. Estas claves podr\u00edan permitir que cualquiera realice operaciones en blobs para las que de otro modo no tendr\u00eda permisos. Por ejemplo, un atacante que haya recuperado con \u00e9xito una clave secreta de los registros puede eliminar blogs del almac\u00e9n de blobs. El atacante puede ser un usuario interno con privilegios limitados para leer el registro o puede ser un usuario externo con privilegios aumentados lo suficiente para acceder a los registros. La vulnerabilidad ha sido parcheada en v3.3.1. No hay otra mitigaci\u00f3n que la actualizaci\u00f3n."}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "HIGH", "availabilityImpact": "HIGH", "baseScore": 9.8, "baseSeverity": "CRITICAL"}, "exploitabilityScore": 3.9, "impactScore": 5.9}, {"source": "security-advisories@github.com", "type": "Secondary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:L/AC:L/PR:L/UI:R/S:U/C:L/I:L/A:L", "attackVector": "LOCAL", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "REQUIRED", "scope": "UNCHANGED", "confidentialityImpact": "LOW", "integrityImpact": "LOW", "availabilityImpact": "LOW", "baseScore": 4.8, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 1.3, "impactScore": 3.4}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "NVD-CWE-noinfo"}]}, {"source": "security-advisories@github.com", "type": "Secondary", "description": [{"lang": "en", "value": "CWE-200"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:linuxfoundation:cubefs:*:*:*:*:*:*:*:*", "versionEndExcluding": "3.3.1", "matchCriteriaId": "6E8D59D8-6863-4398-9D77-2442BAF81108"}]}]}], "references": [{"url": "https://github.com/cubefs/cubefs/commit/972f0275ee8d5dbba4b1530da7c145c269b31ef5", "source": "security-advisories@github.com", "tags": ["Patch"]}, {"url": "https://github.com/cubefs/cubefs/security/advisories/GHSA-8h2x-gr2c-c275", "source": "security-advisories@github.com", "tags": ["Third Party Advisory"]}]}, "github_commit_url": "https://github.com/cubefs/cubefs/commit/972f0275ee8d5dbba4b1530da7c145c269b31ef5"}}
{"buggy_code": ["/*\n * Generic PPP layer for Linux.\n *\n * Copyright 1999-2002 Paul Mackerras.\n *\n *  This program is free software; you can redistribute it and/or\n *  modify it under the terms of the GNU General Public License\n *  as published by the Free Software Foundation; either version\n *  2 of the License, or (at your option) any later version.\n *\n * The generic PPP layer handles the PPP network interfaces, the\n * /dev/ppp device, packet and VJ compression, and multilink.\n * It talks to PPP `channels' via the interface defined in\n * include/linux/ppp_channel.h.  Channels provide the basic means for\n * sending and receiving PPP frames on some kind of communications\n * channel.\n *\n * Part of the code in this driver was inspired by the old async-only\n * PPP driver, written by Michael Callahan and Al Longyear, and\n * subsequently hacked by Paul Mackerras.\n *\n * ==FILEVERSION 20041108==\n */\n\n#include <linux/module.h>\n#include <linux/kernel.h>\n#include <linux/kmod.h>\n#include <linux/init.h>\n#include <linux/list.h>\n#include <linux/idr.h>\n#include <linux/netdevice.h>\n#include <linux/poll.h>\n#include <linux/ppp_defs.h>\n#include <linux/filter.h>\n#include <linux/ppp-ioctl.h>\n#include <linux/ppp_channel.h>\n#include <linux/ppp-comp.h>\n#include <linux/skbuff.h>\n#include <linux/rtnetlink.h>\n#include <linux/if_arp.h>\n#include <linux/ip.h>\n#include <linux/tcp.h>\n#include <linux/spinlock.h>\n#include <linux/rwsem.h>\n#include <linux/stddef.h>\n#include <linux/device.h>\n#include <linux/mutex.h>\n#include <linux/slab.h>\n#include <asm/unaligned.h>\n#include <net/slhc_vj.h>\n#include <linux/atomic.h>\n\n#include <linux/nsproxy.h>\n#include <net/net_namespace.h>\n#include <net/netns/generic.h>\n\n#define PPP_VERSION\t\"2.4.2\"\n\n/*\n * Network protocols we support.\n */\n#define NP_IP\t0\t\t/* Internet Protocol V4 */\n#define NP_IPV6\t1\t\t/* Internet Protocol V6 */\n#define NP_IPX\t2\t\t/* IPX protocol */\n#define NP_AT\t3\t\t/* Appletalk protocol */\n#define NP_MPLS_UC 4\t\t/* MPLS unicast */\n#define NP_MPLS_MC 5\t\t/* MPLS multicast */\n#define NUM_NP\t6\t\t/* Number of NPs. */\n\n#define MPHDRLEN\t6\t/* multilink protocol header length */\n#define MPHDRLEN_SSN\t4\t/* ditto with short sequence numbers */\n\n/*\n * An instance of /dev/ppp can be associated with either a ppp\n * interface unit or a ppp channel.  In both cases, file->private_data\n * points to one of these.\n */\nstruct ppp_file {\n\tenum {\n\t\tINTERFACE=1, CHANNEL\n\t}\t\tkind;\n\tstruct sk_buff_head xq;\t\t/* pppd transmit queue */\n\tstruct sk_buff_head rq;\t\t/* receive queue for pppd */\n\twait_queue_head_t rwait;\t/* for poll on reading /dev/ppp */\n\tatomic_t\trefcnt;\t\t/* # refs (incl /dev/ppp attached) */\n\tint\t\thdrlen;\t\t/* space to leave for headers */\n\tint\t\tindex;\t\t/* interface unit / channel number */\n\tint\t\tdead;\t\t/* unit/channel has been shut down */\n};\n\n#define PF_TO_X(pf, X)\t\tcontainer_of(pf, X, file)\n\n#define PF_TO_PPP(pf)\t\tPF_TO_X(pf, struct ppp)\n#define PF_TO_CHANNEL(pf)\tPF_TO_X(pf, struct channel)\n\n/*\n * Data structure to hold primary network stats for which\n * we want to use 64 bit storage.  Other network stats\n * are stored in dev->stats of the ppp strucute.\n */\nstruct ppp_link_stats {\n\tu64 rx_packets;\n\tu64 tx_packets;\n\tu64 rx_bytes;\n\tu64 tx_bytes;\n};\n\n/*\n * Data structure describing one ppp unit.\n * A ppp unit corresponds to a ppp network interface device\n * and represents a multilink bundle.\n * It can have 0 or more ppp channels connected to it.\n */\nstruct ppp {\n\tstruct ppp_file\tfile;\t\t/* stuff for read/write/poll 0 */\n\tstruct file\t*owner;\t\t/* file that owns this unit 48 */\n\tstruct list_head channels;\t/* list of attached channels 4c */\n\tint\t\tn_channels;\t/* how many channels are attached 54 */\n\tspinlock_t\trlock;\t\t/* lock for receive side 58 */\n\tspinlock_t\twlock;\t\t/* lock for transmit side 5c */\n\tint\t\tmru;\t\t/* max receive unit 60 */\n\tunsigned int\tflags;\t\t/* control bits 64 */\n\tunsigned int\txstate;\t\t/* transmit state bits 68 */\n\tunsigned int\trstate;\t\t/* receive state bits 6c */\n\tint\t\tdebug;\t\t/* debug flags 70 */\n\tstruct slcompress *vj;\t\t/* state for VJ header compression */\n\tenum NPmode\tnpmode[NUM_NP];\t/* what to do with each net proto 78 */\n\tstruct sk_buff\t*xmit_pending;\t/* a packet ready to go out 88 */\n\tstruct compressor *xcomp;\t/* transmit packet compressor 8c */\n\tvoid\t\t*xc_state;\t/* its internal state 90 */\n\tstruct compressor *rcomp;\t/* receive decompressor 94 */\n\tvoid\t\t*rc_state;\t/* its internal state 98 */\n\tunsigned long\tlast_xmit;\t/* jiffies when last pkt sent 9c */\n\tunsigned long\tlast_recv;\t/* jiffies when last pkt rcvd a0 */\n\tstruct net_device *dev;\t\t/* network interface device a4 */\n\tint\t\tclosing;\t/* is device closing down? a8 */\n#ifdef CONFIG_PPP_MULTILINK\n\tint\t\tnxchan;\t\t/* next channel to send something on */\n\tu32\t\tnxseq;\t\t/* next sequence number to send */\n\tint\t\tmrru;\t\t/* MP: max reconst. receive unit */\n\tu32\t\tnextseq;\t/* MP: seq no of next packet */\n\tu32\t\tminseq;\t\t/* MP: min of most recent seqnos */\n\tstruct sk_buff_head mrq;\t/* MP: receive reconstruction queue */\n#endif /* CONFIG_PPP_MULTILINK */\n#ifdef CONFIG_PPP_FILTER\n\tstruct bpf_prog *pass_filter;\t/* filter for packets to pass */\n\tstruct bpf_prog *active_filter; /* filter for pkts to reset idle */\n#endif /* CONFIG_PPP_FILTER */\n\tstruct net\t*ppp_net;\t/* the net we belong to */\n\tstruct ppp_link_stats stats64;\t/* 64 bit network stats */\n};\n\n/*\n * Bits in flags: SC_NO_TCP_CCID, SC_CCP_OPEN, SC_CCP_UP, SC_LOOP_TRAFFIC,\n * SC_MULTILINK, SC_MP_SHORTSEQ, SC_MP_XSHORTSEQ, SC_COMP_TCP, SC_REJ_COMP_TCP,\n * SC_MUST_COMP\n * Bits in rstate: SC_DECOMP_RUN, SC_DC_ERROR, SC_DC_FERROR.\n * Bits in xstate: SC_COMP_RUN\n */\n#define SC_FLAG_BITS\t(SC_NO_TCP_CCID|SC_CCP_OPEN|SC_CCP_UP|SC_LOOP_TRAFFIC \\\n\t\t\t |SC_MULTILINK|SC_MP_SHORTSEQ|SC_MP_XSHORTSEQ \\\n\t\t\t |SC_COMP_TCP|SC_REJ_COMP_TCP|SC_MUST_COMP)\n\n/*\n * Private data structure for each channel.\n * This includes the data structure used for multilink.\n */\nstruct channel {\n\tstruct ppp_file\tfile;\t\t/* stuff for read/write/poll */\n\tstruct list_head list;\t\t/* link in all/new_channels list */\n\tstruct ppp_channel *chan;\t/* public channel data structure */\n\tstruct rw_semaphore chan_sem;\t/* protects `chan' during chan ioctl */\n\tspinlock_t\tdownl;\t\t/* protects `chan', file.xq dequeue */\n\tstruct ppp\t*ppp;\t\t/* ppp unit we're connected to */\n\tstruct net\t*chan_net;\t/* the net channel belongs to */\n\tstruct list_head clist;\t\t/* link in list of channels per unit */\n\trwlock_t\tupl;\t\t/* protects `ppp' */\n#ifdef CONFIG_PPP_MULTILINK\n\tu8\t\tavail;\t\t/* flag used in multilink stuff */\n\tu8\t\thad_frag;\t/* >= 1 fragments have been sent */\n\tu32\t\tlastseq;\t/* MP: last sequence # received */\n\tint\t\tspeed;\t\t/* speed of the corresponding ppp channel*/\n#endif /* CONFIG_PPP_MULTILINK */\n};\n\n/*\n * SMP locking issues:\n * Both the ppp.rlock and ppp.wlock locks protect the ppp.channels\n * list and the ppp.n_channels field, you need to take both locks\n * before you modify them.\n * The lock ordering is: channel.upl -> ppp.wlock -> ppp.rlock ->\n * channel.downl.\n */\n\nstatic DEFINE_MUTEX(ppp_mutex);\nstatic atomic_t ppp_unit_count = ATOMIC_INIT(0);\nstatic atomic_t channel_count = ATOMIC_INIT(0);\n\n/* per-net private data for this module */\nstatic int ppp_net_id __read_mostly;\nstruct ppp_net {\n\t/* units to ppp mapping */\n\tstruct idr units_idr;\n\n\t/*\n\t * all_ppp_mutex protects the units_idr mapping.\n\t * It also ensures that finding a ppp unit in the units_idr\n\t * map and updating its file.refcnt field is atomic.\n\t */\n\tstruct mutex all_ppp_mutex;\n\n\t/* channels */\n\tstruct list_head all_channels;\n\tstruct list_head new_channels;\n\tint last_channel_index;\n\n\t/*\n\t * all_channels_lock protects all_channels and\n\t * last_channel_index, and the atomicity of find\n\t * a channel and updating its file.refcnt field.\n\t */\n\tspinlock_t all_channels_lock;\n};\n\n/* Get the PPP protocol number from a skb */\n#define PPP_PROTO(skb)\tget_unaligned_be16((skb)->data)\n\n/* We limit the length of ppp->file.rq to this (arbitrary) value */\n#define PPP_MAX_RQLEN\t32\n\n/*\n * Maximum number of multilink fragments queued up.\n * This has to be large enough to cope with the maximum latency of\n * the slowest channel relative to the others.  Strictly it should\n * depend on the number of channels and their characteristics.\n */\n#define PPP_MP_MAX_QLEN\t128\n\n/* Multilink header bits. */\n#define B\t0x80\t\t/* this fragment begins a packet */\n#define E\t0x40\t\t/* this fragment ends a packet */\n\n/* Compare multilink sequence numbers (assumed to be 32 bits wide) */\n#define seq_before(a, b)\t((s32)((a) - (b)) < 0)\n#define seq_after(a, b)\t\t((s32)((a) - (b)) > 0)\n\n/* Prototypes. */\nstatic int ppp_unattached_ioctl(struct net *net, struct ppp_file *pf,\n\t\t\tstruct file *file, unsigned int cmd, unsigned long arg);\nstatic void ppp_xmit_process(struct ppp *ppp);\nstatic void ppp_send_frame(struct ppp *ppp, struct sk_buff *skb);\nstatic void ppp_push(struct ppp *ppp);\nstatic void ppp_channel_push(struct channel *pch);\nstatic void ppp_receive_frame(struct ppp *ppp, struct sk_buff *skb,\n\t\t\t      struct channel *pch);\nstatic void ppp_receive_error(struct ppp *ppp);\nstatic void ppp_receive_nonmp_frame(struct ppp *ppp, struct sk_buff *skb);\nstatic struct sk_buff *ppp_decompress_frame(struct ppp *ppp,\n\t\t\t\t\t    struct sk_buff *skb);\n#ifdef CONFIG_PPP_MULTILINK\nstatic void ppp_receive_mp_frame(struct ppp *ppp, struct sk_buff *skb,\n\t\t\t\tstruct channel *pch);\nstatic void ppp_mp_insert(struct ppp *ppp, struct sk_buff *skb);\nstatic struct sk_buff *ppp_mp_reconstruct(struct ppp *ppp);\nstatic int ppp_mp_explode(struct ppp *ppp, struct sk_buff *skb);\n#endif /* CONFIG_PPP_MULTILINK */\nstatic int ppp_set_compress(struct ppp *ppp, unsigned long arg);\nstatic void ppp_ccp_peek(struct ppp *ppp, struct sk_buff *skb, int inbound);\nstatic void ppp_ccp_closed(struct ppp *ppp);\nstatic struct compressor *find_compressor(int type);\nstatic void ppp_get_stats(struct ppp *ppp, struct ppp_stats *st);\nstatic struct ppp *ppp_create_interface(struct net *net, int unit,\n\t\t\t\t\tstruct file *file, int *retp);\nstatic void init_ppp_file(struct ppp_file *pf, int kind);\nstatic void ppp_destroy_interface(struct ppp *ppp);\nstatic struct ppp *ppp_find_unit(struct ppp_net *pn, int unit);\nstatic struct channel *ppp_find_channel(struct ppp_net *pn, int unit);\nstatic int ppp_connect_channel(struct channel *pch, int unit);\nstatic int ppp_disconnect_channel(struct channel *pch);\nstatic void ppp_destroy_channel(struct channel *pch);\nstatic int unit_get(struct idr *p, void *ptr);\nstatic int unit_set(struct idr *p, void *ptr, int n);\nstatic void unit_put(struct idr *p, int n);\nstatic void *unit_find(struct idr *p, int n);\n\nstatic const struct net_device_ops ppp_netdev_ops;\n\nstatic struct class *ppp_class;\n\n/* per net-namespace data */\nstatic inline struct ppp_net *ppp_pernet(struct net *net)\n{\n\tBUG_ON(!net);\n\n\treturn net_generic(net, ppp_net_id);\n}\n\n/* Translates a PPP protocol number to a NP index (NP == network protocol) */\nstatic inline int proto_to_npindex(int proto)\n{\n\tswitch (proto) {\n\tcase PPP_IP:\n\t\treturn NP_IP;\n\tcase PPP_IPV6:\n\t\treturn NP_IPV6;\n\tcase PPP_IPX:\n\t\treturn NP_IPX;\n\tcase PPP_AT:\n\t\treturn NP_AT;\n\tcase PPP_MPLS_UC:\n\t\treturn NP_MPLS_UC;\n\tcase PPP_MPLS_MC:\n\t\treturn NP_MPLS_MC;\n\t}\n\treturn -EINVAL;\n}\n\n/* Translates an NP index into a PPP protocol number */\nstatic const int npindex_to_proto[NUM_NP] = {\n\tPPP_IP,\n\tPPP_IPV6,\n\tPPP_IPX,\n\tPPP_AT,\n\tPPP_MPLS_UC,\n\tPPP_MPLS_MC,\n};\n\n/* Translates an ethertype into an NP index */\nstatic inline int ethertype_to_npindex(int ethertype)\n{\n\tswitch (ethertype) {\n\tcase ETH_P_IP:\n\t\treturn NP_IP;\n\tcase ETH_P_IPV6:\n\t\treturn NP_IPV6;\n\tcase ETH_P_IPX:\n\t\treturn NP_IPX;\n\tcase ETH_P_PPPTALK:\n\tcase ETH_P_ATALK:\n\t\treturn NP_AT;\n\tcase ETH_P_MPLS_UC:\n\t\treturn NP_MPLS_UC;\n\tcase ETH_P_MPLS_MC:\n\t\treturn NP_MPLS_MC;\n\t}\n\treturn -1;\n}\n\n/* Translates an NP index into an ethertype */\nstatic const int npindex_to_ethertype[NUM_NP] = {\n\tETH_P_IP,\n\tETH_P_IPV6,\n\tETH_P_IPX,\n\tETH_P_PPPTALK,\n\tETH_P_MPLS_UC,\n\tETH_P_MPLS_MC,\n};\n\n/*\n * Locking shorthand.\n */\n#define ppp_xmit_lock(ppp)\tspin_lock_bh(&(ppp)->wlock)\n#define ppp_xmit_unlock(ppp)\tspin_unlock_bh(&(ppp)->wlock)\n#define ppp_recv_lock(ppp)\tspin_lock_bh(&(ppp)->rlock)\n#define ppp_recv_unlock(ppp)\tspin_unlock_bh(&(ppp)->rlock)\n#define ppp_lock(ppp)\t\tdo { ppp_xmit_lock(ppp); \\\n\t\t\t\t     ppp_recv_lock(ppp); } while (0)\n#define ppp_unlock(ppp)\t\tdo { ppp_recv_unlock(ppp); \\\n\t\t\t\t     ppp_xmit_unlock(ppp); } while (0)\n\n/*\n * /dev/ppp device routines.\n * The /dev/ppp device is used by pppd to control the ppp unit.\n * It supports the read, write, ioctl and poll functions.\n * Open instances of /dev/ppp can be in one of three states:\n * unattached, attached to a ppp unit, or attached to a ppp channel.\n */\nstatic int ppp_open(struct inode *inode, struct file *file)\n{\n\t/*\n\t * This could (should?) be enforced by the permissions on /dev/ppp.\n\t */\n\tif (!capable(CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\treturn 0;\n}\n\nstatic int ppp_release(struct inode *unused, struct file *file)\n{\n\tstruct ppp_file *pf = file->private_data;\n\tstruct ppp *ppp;\n\n\tif (pf) {\n\t\tfile->private_data = NULL;\n\t\tif (pf->kind == INTERFACE) {\n\t\t\tppp = PF_TO_PPP(pf);\n\t\t\trtnl_lock();\n\t\t\tif (file == ppp->owner)\n\t\t\t\tunregister_netdevice(ppp->dev);\n\t\t\trtnl_unlock();\n\t\t}\n\t\tif (atomic_dec_and_test(&pf->refcnt)) {\n\t\t\tswitch (pf->kind) {\n\t\t\tcase INTERFACE:\n\t\t\t\tppp_destroy_interface(PF_TO_PPP(pf));\n\t\t\t\tbreak;\n\t\t\tcase CHANNEL:\n\t\t\t\tppp_destroy_channel(PF_TO_CHANNEL(pf));\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\treturn 0;\n}\n\nstatic ssize_t ppp_read(struct file *file, char __user *buf,\n\t\t\tsize_t count, loff_t *ppos)\n{\n\tstruct ppp_file *pf = file->private_data;\n\tDECLARE_WAITQUEUE(wait, current);\n\tssize_t ret;\n\tstruct sk_buff *skb = NULL;\n\tstruct iovec iov;\n\tstruct iov_iter to;\n\n\tret = count;\n\n\tif (!pf)\n\t\treturn -ENXIO;\n\tadd_wait_queue(&pf->rwait, &wait);\n\tfor (;;) {\n\t\tset_current_state(TASK_INTERRUPTIBLE);\n\t\tskb = skb_dequeue(&pf->rq);\n\t\tif (skb)\n\t\t\tbreak;\n\t\tret = 0;\n\t\tif (pf->dead)\n\t\t\tbreak;\n\t\tif (pf->kind == INTERFACE) {\n\t\t\t/*\n\t\t\t * Return 0 (EOF) on an interface that has no\n\t\t\t * channels connected, unless it is looping\n\t\t\t * network traffic (demand mode).\n\t\t\t */\n\t\t\tstruct ppp *ppp = PF_TO_PPP(pf);\n\n\t\t\tppp_recv_lock(ppp);\n\t\t\tif (ppp->n_channels == 0 &&\n\t\t\t    (ppp->flags & SC_LOOP_TRAFFIC) == 0) {\n\t\t\t\tppp_recv_unlock(ppp);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tppp_recv_unlock(ppp);\n\t\t}\n\t\tret = -EAGAIN;\n\t\tif (file->f_flags & O_NONBLOCK)\n\t\t\tbreak;\n\t\tret = -ERESTARTSYS;\n\t\tif (signal_pending(current))\n\t\t\tbreak;\n\t\tschedule();\n\t}\n\tset_current_state(TASK_RUNNING);\n\tremove_wait_queue(&pf->rwait, &wait);\n\n\tif (!skb)\n\t\tgoto out;\n\n\tret = -EOVERFLOW;\n\tif (skb->len > count)\n\t\tgoto outf;\n\tret = -EFAULT;\n\tiov.iov_base = buf;\n\tiov.iov_len = count;\n\tiov_iter_init(&to, READ, &iov, 1, count);\n\tif (skb_copy_datagram_iter(skb, 0, &to, skb->len))\n\t\tgoto outf;\n\tret = skb->len;\n\n outf:\n\tkfree_skb(skb);\n out:\n\treturn ret;\n}\n\nstatic ssize_t ppp_write(struct file *file, const char __user *buf,\n\t\t\t size_t count, loff_t *ppos)\n{\n\tstruct ppp_file *pf = file->private_data;\n\tstruct sk_buff *skb;\n\tssize_t ret;\n\n\tif (!pf)\n\t\treturn -ENXIO;\n\tret = -ENOMEM;\n\tskb = alloc_skb(count + pf->hdrlen, GFP_KERNEL);\n\tif (!skb)\n\t\tgoto out;\n\tskb_reserve(skb, pf->hdrlen);\n\tret = -EFAULT;\n\tif (copy_from_user(skb_put(skb, count), buf, count)) {\n\t\tkfree_skb(skb);\n\t\tgoto out;\n\t}\n\n\tskb_queue_tail(&pf->xq, skb);\n\n\tswitch (pf->kind) {\n\tcase INTERFACE:\n\t\tppp_xmit_process(PF_TO_PPP(pf));\n\t\tbreak;\n\tcase CHANNEL:\n\t\tppp_channel_push(PF_TO_CHANNEL(pf));\n\t\tbreak;\n\t}\n\n\tret = count;\n\n out:\n\treturn ret;\n}\n\n/* No kernel lock - fine */\nstatic unsigned int ppp_poll(struct file *file, poll_table *wait)\n{\n\tstruct ppp_file *pf = file->private_data;\n\tunsigned int mask;\n\n\tif (!pf)\n\t\treturn 0;\n\tpoll_wait(file, &pf->rwait, wait);\n\tmask = POLLOUT | POLLWRNORM;\n\tif (skb_peek(&pf->rq))\n\t\tmask |= POLLIN | POLLRDNORM;\n\tif (pf->dead)\n\t\tmask |= POLLHUP;\n\telse if (pf->kind == INTERFACE) {\n\t\t/* see comment in ppp_read */\n\t\tstruct ppp *ppp = PF_TO_PPP(pf);\n\n\t\tppp_recv_lock(ppp);\n\t\tif (ppp->n_channels == 0 &&\n\t\t    (ppp->flags & SC_LOOP_TRAFFIC) == 0)\n\t\t\tmask |= POLLIN | POLLRDNORM;\n\t\tppp_recv_unlock(ppp);\n\t}\n\n\treturn mask;\n}\n\n#ifdef CONFIG_PPP_FILTER\nstatic int get_filter(void __user *arg, struct sock_filter **p)\n{\n\tstruct sock_fprog uprog;\n\tstruct sock_filter *code = NULL;\n\tint len;\n\n\tif (copy_from_user(&uprog, arg, sizeof(uprog)))\n\t\treturn -EFAULT;\n\n\tif (!uprog.len) {\n\t\t*p = NULL;\n\t\treturn 0;\n\t}\n\n\tlen = uprog.len * sizeof(struct sock_filter);\n\tcode = memdup_user(uprog.filter, len);\n\tif (IS_ERR(code))\n\t\treturn PTR_ERR(code);\n\n\t*p = code;\n\treturn uprog.len;\n}\n#endif /* CONFIG_PPP_FILTER */\n\nstatic long ppp_ioctl(struct file *file, unsigned int cmd, unsigned long arg)\n{\n\tstruct ppp_file *pf;\n\tstruct ppp *ppp;\n\tint err = -EFAULT, val, val2, i;\n\tstruct ppp_idle idle;\n\tstruct npioctl npi;\n\tint unit, cflags;\n\tstruct slcompress *vj;\n\tvoid __user *argp = (void __user *)arg;\n\tint __user *p = argp;\n\n\tmutex_lock(&ppp_mutex);\n\n\tpf = file->private_data;\n\tif (!pf) {\n\t\terr = ppp_unattached_ioctl(current->nsproxy->net_ns,\n\t\t\t\t\t   pf, file, cmd, arg);\n\t\tgoto out;\n\t}\n\n\tif (cmd == PPPIOCDETACH) {\n\t\t/*\n\t\t * We have to be careful here... if the file descriptor\n\t\t * has been dup'd, we could have another process in the\n\t\t * middle of a poll using the same file *, so we had\n\t\t * better not free the interface data structures -\n\t\t * instead we fail the ioctl.  Even in this case, we\n\t\t * shut down the interface if we are the owner of it.\n\t\t * Actually, we should get rid of PPPIOCDETACH, userland\n\t\t * (i.e. pppd) could achieve the same effect by closing\n\t\t * this fd and reopening /dev/ppp.\n\t\t */\n\t\terr = -EINVAL;\n\t\tif (pf->kind == INTERFACE) {\n\t\t\tppp = PF_TO_PPP(pf);\n\t\t\trtnl_lock();\n\t\t\tif (file == ppp->owner)\n\t\t\t\tunregister_netdevice(ppp->dev);\n\t\t\trtnl_unlock();\n\t\t}\n\t\tif (atomic_long_read(&file->f_count) < 2) {\n\t\t\tppp_release(NULL, file);\n\t\t\terr = 0;\n\t\t} else\n\t\t\tpr_warn(\"PPPIOCDETACH file->f_count=%ld\\n\",\n\t\t\t\tatomic_long_read(&file->f_count));\n\t\tgoto out;\n\t}\n\n\tif (pf->kind == CHANNEL) {\n\t\tstruct channel *pch;\n\t\tstruct ppp_channel *chan;\n\n\t\tpch = PF_TO_CHANNEL(pf);\n\n\t\tswitch (cmd) {\n\t\tcase PPPIOCCONNECT:\n\t\t\tif (get_user(unit, p))\n\t\t\t\tbreak;\n\t\t\terr = ppp_connect_channel(pch, unit);\n\t\t\tbreak;\n\n\t\tcase PPPIOCDISCONN:\n\t\t\terr = ppp_disconnect_channel(pch);\n\t\t\tbreak;\n\n\t\tdefault:\n\t\t\tdown_read(&pch->chan_sem);\n\t\t\tchan = pch->chan;\n\t\t\terr = -ENOTTY;\n\t\t\tif (chan && chan->ops->ioctl)\n\t\t\t\terr = chan->ops->ioctl(chan, cmd, arg);\n\t\t\tup_read(&pch->chan_sem);\n\t\t}\n\t\tgoto out;\n\t}\n\n\tif (pf->kind != INTERFACE) {\n\t\t/* can't happen */\n\t\tpr_err(\"PPP: not interface or channel??\\n\");\n\t\terr = -EINVAL;\n\t\tgoto out;\n\t}\n\n\tppp = PF_TO_PPP(pf);\n\tswitch (cmd) {\n\tcase PPPIOCSMRU:\n\t\tif (get_user(val, p))\n\t\t\tbreak;\n\t\tppp->mru = val;\n\t\terr = 0;\n\t\tbreak;\n\n\tcase PPPIOCSFLAGS:\n\t\tif (get_user(val, p))\n\t\t\tbreak;\n\t\tppp_lock(ppp);\n\t\tcflags = ppp->flags & ~val;\n#ifdef CONFIG_PPP_MULTILINK\n\t\tif (!(ppp->flags & SC_MULTILINK) && (val & SC_MULTILINK))\n\t\t\tppp->nextseq = 0;\n#endif\n\t\tppp->flags = val & SC_FLAG_BITS;\n\t\tppp_unlock(ppp);\n\t\tif (cflags & SC_CCP_OPEN)\n\t\t\tppp_ccp_closed(ppp);\n\t\terr = 0;\n\t\tbreak;\n\n\tcase PPPIOCGFLAGS:\n\t\tval = ppp->flags | ppp->xstate | ppp->rstate;\n\t\tif (put_user(val, p))\n\t\t\tbreak;\n\t\terr = 0;\n\t\tbreak;\n\n\tcase PPPIOCSCOMPRESS:\n\t\terr = ppp_set_compress(ppp, arg);\n\t\tbreak;\n\n\tcase PPPIOCGUNIT:\n\t\tif (put_user(ppp->file.index, p))\n\t\t\tbreak;\n\t\terr = 0;\n\t\tbreak;\n\n\tcase PPPIOCSDEBUG:\n\t\tif (get_user(val, p))\n\t\t\tbreak;\n\t\tppp->debug = val;\n\t\terr = 0;\n\t\tbreak;\n\n\tcase PPPIOCGDEBUG:\n\t\tif (put_user(ppp->debug, p))\n\t\t\tbreak;\n\t\terr = 0;\n\t\tbreak;\n\n\tcase PPPIOCGIDLE:\n\t\tidle.xmit_idle = (jiffies - ppp->last_xmit) / HZ;\n\t\tidle.recv_idle = (jiffies - ppp->last_recv) / HZ;\n\t\tif (copy_to_user(argp, &idle, sizeof(idle)))\n\t\t\tbreak;\n\t\terr = 0;\n\t\tbreak;\n\n\tcase PPPIOCSMAXCID:\n\t\tif (get_user(val, p))\n\t\t\tbreak;\n\t\tval2 = 15;\n\t\tif ((val >> 16) != 0) {\n\t\t\tval2 = val >> 16;\n\t\t\tval &= 0xffff;\n\t\t}\n\t\tvj = slhc_init(val2+1, val+1);\n\t\tif (IS_ERR(vj)) {\n\t\t\terr = PTR_ERR(vj);\n\t\t\tbreak;\n\t\t}\n\t\tppp_lock(ppp);\n\t\tif (ppp->vj)\n\t\t\tslhc_free(ppp->vj);\n\t\tppp->vj = vj;\n\t\tppp_unlock(ppp);\n\t\terr = 0;\n\t\tbreak;\n\n\tcase PPPIOCGNPMODE:\n\tcase PPPIOCSNPMODE:\n\t\tif (copy_from_user(&npi, argp, sizeof(npi)))\n\t\t\tbreak;\n\t\terr = proto_to_npindex(npi.protocol);\n\t\tif (err < 0)\n\t\t\tbreak;\n\t\ti = err;\n\t\tif (cmd == PPPIOCGNPMODE) {\n\t\t\terr = -EFAULT;\n\t\t\tnpi.mode = ppp->npmode[i];\n\t\t\tif (copy_to_user(argp, &npi, sizeof(npi)))\n\t\t\t\tbreak;\n\t\t} else {\n\t\t\tppp->npmode[i] = npi.mode;\n\t\t\t/* we may be able to transmit more packets now (??) */\n\t\t\tnetif_wake_queue(ppp->dev);\n\t\t}\n\t\terr = 0;\n\t\tbreak;\n\n#ifdef CONFIG_PPP_FILTER\n\tcase PPPIOCSPASS:\n\t{\n\t\tstruct sock_filter *code;\n\n\t\terr = get_filter(argp, &code);\n\t\tif (err >= 0) {\n\t\t\tstruct bpf_prog *pass_filter = NULL;\n\t\t\tstruct sock_fprog_kern fprog = {\n\t\t\t\t.len = err,\n\t\t\t\t.filter = code,\n\t\t\t};\n\n\t\t\terr = 0;\n\t\t\tif (fprog.filter)\n\t\t\t\terr = bpf_prog_create(&pass_filter, &fprog);\n\t\t\tif (!err) {\n\t\t\t\tppp_lock(ppp);\n\t\t\t\tif (ppp->pass_filter)\n\t\t\t\t\tbpf_prog_destroy(ppp->pass_filter);\n\t\t\t\tppp->pass_filter = pass_filter;\n\t\t\t\tppp_unlock(ppp);\n\t\t\t}\n\t\t\tkfree(code);\n\t\t}\n\t\tbreak;\n\t}\n\tcase PPPIOCSACTIVE:\n\t{\n\t\tstruct sock_filter *code;\n\n\t\terr = get_filter(argp, &code);\n\t\tif (err >= 0) {\n\t\t\tstruct bpf_prog *active_filter = NULL;\n\t\t\tstruct sock_fprog_kern fprog = {\n\t\t\t\t.len = err,\n\t\t\t\t.filter = code,\n\t\t\t};\n\n\t\t\terr = 0;\n\t\t\tif (fprog.filter)\n\t\t\t\terr = bpf_prog_create(&active_filter, &fprog);\n\t\t\tif (!err) {\n\t\t\t\tppp_lock(ppp);\n\t\t\t\tif (ppp->active_filter)\n\t\t\t\t\tbpf_prog_destroy(ppp->active_filter);\n\t\t\t\tppp->active_filter = active_filter;\n\t\t\t\tppp_unlock(ppp);\n\t\t\t}\n\t\t\tkfree(code);\n\t\t}\n\t\tbreak;\n\t}\n#endif /* CONFIG_PPP_FILTER */\n\n#ifdef CONFIG_PPP_MULTILINK\n\tcase PPPIOCSMRRU:\n\t\tif (get_user(val, p))\n\t\t\tbreak;\n\t\tppp_recv_lock(ppp);\n\t\tppp->mrru = val;\n\t\tppp_recv_unlock(ppp);\n\t\terr = 0;\n\t\tbreak;\n#endif /* CONFIG_PPP_MULTILINK */\n\n\tdefault:\n\t\terr = -ENOTTY;\n\t}\n\nout:\n\tmutex_unlock(&ppp_mutex);\n\n\treturn err;\n}\n\nstatic int ppp_unattached_ioctl(struct net *net, struct ppp_file *pf,\n\t\t\tstruct file *file, unsigned int cmd, unsigned long arg)\n{\n\tint unit, err = -EFAULT;\n\tstruct ppp *ppp;\n\tstruct channel *chan;\n\tstruct ppp_net *pn;\n\tint __user *p = (int __user *)arg;\n\n\tswitch (cmd) {\n\tcase PPPIOCNEWUNIT:\n\t\t/* Create a new ppp unit */\n\t\tif (get_user(unit, p))\n\t\t\tbreak;\n\t\tppp = ppp_create_interface(net, unit, file, &err);\n\t\tif (!ppp)\n\t\t\tbreak;\n\t\tfile->private_data = &ppp->file;\n\t\terr = -EFAULT;\n\t\tif (put_user(ppp->file.index, p))\n\t\t\tbreak;\n\t\terr = 0;\n\t\tbreak;\n\n\tcase PPPIOCATTACH:\n\t\t/* Attach to an existing ppp unit */\n\t\tif (get_user(unit, p))\n\t\t\tbreak;\n\t\terr = -ENXIO;\n\t\tpn = ppp_pernet(net);\n\t\tmutex_lock(&pn->all_ppp_mutex);\n\t\tppp = ppp_find_unit(pn, unit);\n\t\tif (ppp) {\n\t\t\tatomic_inc(&ppp->file.refcnt);\n\t\t\tfile->private_data = &ppp->file;\n\t\t\terr = 0;\n\t\t}\n\t\tmutex_unlock(&pn->all_ppp_mutex);\n\t\tbreak;\n\n\tcase PPPIOCATTCHAN:\n\t\tif (get_user(unit, p))\n\t\t\tbreak;\n\t\terr = -ENXIO;\n\t\tpn = ppp_pernet(net);\n\t\tspin_lock_bh(&pn->all_channels_lock);\n\t\tchan = ppp_find_channel(pn, unit);\n\t\tif (chan) {\n\t\t\tatomic_inc(&chan->file.refcnt);\n\t\t\tfile->private_data = &chan->file;\n\t\t\terr = 0;\n\t\t}\n\t\tspin_unlock_bh(&pn->all_channels_lock);\n\t\tbreak;\n\n\tdefault:\n\t\terr = -ENOTTY;\n\t}\n\n\treturn err;\n}\n\nstatic const struct file_operations ppp_device_fops = {\n\t.owner\t\t= THIS_MODULE,\n\t.read\t\t= ppp_read,\n\t.write\t\t= ppp_write,\n\t.poll\t\t= ppp_poll,\n\t.unlocked_ioctl\t= ppp_ioctl,\n\t.open\t\t= ppp_open,\n\t.release\t= ppp_release,\n\t.llseek\t\t= noop_llseek,\n};\n\nstatic __net_init int ppp_init_net(struct net *net)\n{\n\tstruct ppp_net *pn = net_generic(net, ppp_net_id);\n\n\tidr_init(&pn->units_idr);\n\tmutex_init(&pn->all_ppp_mutex);\n\n\tINIT_LIST_HEAD(&pn->all_channels);\n\tINIT_LIST_HEAD(&pn->new_channels);\n\n\tspin_lock_init(&pn->all_channels_lock);\n\n\treturn 0;\n}\n\nstatic __net_exit void ppp_exit_net(struct net *net)\n{\n\tstruct ppp_net *pn = net_generic(net, ppp_net_id);\n\tstruct net_device *dev;\n\tstruct net_device *aux;\n\tstruct ppp *ppp;\n\tLIST_HEAD(list);\n\tint id;\n\n\trtnl_lock();\n\tfor_each_netdev_safe(net, dev, aux) {\n\t\tif (dev->netdev_ops == &ppp_netdev_ops)\n\t\t\tunregister_netdevice_queue(dev, &list);\n\t}\n\n\tidr_for_each_entry(&pn->units_idr, ppp, id)\n\t\t/* Skip devices already unregistered by previous loop */\n\t\tif (!net_eq(dev_net(ppp->dev), net))\n\t\t\tunregister_netdevice_queue(ppp->dev, &list);\n\n\tunregister_netdevice_many(&list);\n\trtnl_unlock();\n\n\tidr_destroy(&pn->units_idr);\n}\n\nstatic struct pernet_operations ppp_net_ops = {\n\t.init = ppp_init_net,\n\t.exit = ppp_exit_net,\n\t.id   = &ppp_net_id,\n\t.size = sizeof(struct ppp_net),\n};\n\n#define PPP_MAJOR\t108\n\n/* Called at boot time if ppp is compiled into the kernel,\n   or at module load time (from init_module) if compiled as a module. */\nstatic int __init ppp_init(void)\n{\n\tint err;\n\n\tpr_info(\"PPP generic driver version \" PPP_VERSION \"\\n\");\n\n\terr = register_pernet_device(&ppp_net_ops);\n\tif (err) {\n\t\tpr_err(\"failed to register PPP pernet device (%d)\\n\", err);\n\t\tgoto out;\n\t}\n\n\terr = register_chrdev(PPP_MAJOR, \"ppp\", &ppp_device_fops);\n\tif (err) {\n\t\tpr_err(\"failed to register PPP device (%d)\\n\", err);\n\t\tgoto out_net;\n\t}\n\n\tppp_class = class_create(THIS_MODULE, \"ppp\");\n\tif (IS_ERR(ppp_class)) {\n\t\terr = PTR_ERR(ppp_class);\n\t\tgoto out_chrdev;\n\t}\n\n\t/* not a big deal if we fail here :-) */\n\tdevice_create(ppp_class, NULL, MKDEV(PPP_MAJOR, 0), NULL, \"ppp\");\n\n\treturn 0;\n\nout_chrdev:\n\tunregister_chrdev(PPP_MAJOR, \"ppp\");\nout_net:\n\tunregister_pernet_device(&ppp_net_ops);\nout:\n\treturn err;\n}\n\n/*\n * Network interface unit routines.\n */\nstatic netdev_tx_t\nppp_start_xmit(struct sk_buff *skb, struct net_device *dev)\n{\n\tstruct ppp *ppp = netdev_priv(dev);\n\tint npi, proto;\n\tunsigned char *pp;\n\n\tnpi = ethertype_to_npindex(ntohs(skb->protocol));\n\tif (npi < 0)\n\t\tgoto outf;\n\n\t/* Drop, accept or reject the packet */\n\tswitch (ppp->npmode[npi]) {\n\tcase NPMODE_PASS:\n\t\tbreak;\n\tcase NPMODE_QUEUE:\n\t\t/* it would be nice to have a way to tell the network\n\t\t   system to queue this one up for later. */\n\t\tgoto outf;\n\tcase NPMODE_DROP:\n\tcase NPMODE_ERROR:\n\t\tgoto outf;\n\t}\n\n\t/* Put the 2-byte PPP protocol number on the front,\n\t   making sure there is room for the address and control fields. */\n\tif (skb_cow_head(skb, PPP_HDRLEN))\n\t\tgoto outf;\n\n\tpp = skb_push(skb, 2);\n\tproto = npindex_to_proto[npi];\n\tput_unaligned_be16(proto, pp);\n\n\tskb_scrub_packet(skb, !net_eq(ppp->ppp_net, dev_net(dev)));\n\tskb_queue_tail(&ppp->file.xq, skb);\n\tppp_xmit_process(ppp);\n\treturn NETDEV_TX_OK;\n\n outf:\n\tkfree_skb(skb);\n\t++dev->stats.tx_dropped;\n\treturn NETDEV_TX_OK;\n}\n\nstatic int\nppp_net_ioctl(struct net_device *dev, struct ifreq *ifr, int cmd)\n{\n\tstruct ppp *ppp = netdev_priv(dev);\n\tint err = -EFAULT;\n\tvoid __user *addr = (void __user *) ifr->ifr_ifru.ifru_data;\n\tstruct ppp_stats stats;\n\tstruct ppp_comp_stats cstats;\n\tchar *vers;\n\n\tswitch (cmd) {\n\tcase SIOCGPPPSTATS:\n\t\tppp_get_stats(ppp, &stats);\n\t\tif (copy_to_user(addr, &stats, sizeof(stats)))\n\t\t\tbreak;\n\t\terr = 0;\n\t\tbreak;\n\n\tcase SIOCGPPPCSTATS:\n\t\tmemset(&cstats, 0, sizeof(cstats));\n\t\tif (ppp->xc_state)\n\t\t\tppp->xcomp->comp_stat(ppp->xc_state, &cstats.c);\n\t\tif (ppp->rc_state)\n\t\t\tppp->rcomp->decomp_stat(ppp->rc_state, &cstats.d);\n\t\tif (copy_to_user(addr, &cstats, sizeof(cstats)))\n\t\t\tbreak;\n\t\terr = 0;\n\t\tbreak;\n\n\tcase SIOCGPPPVER:\n\t\tvers = PPP_VERSION;\n\t\tif (copy_to_user(addr, vers, strlen(vers) + 1))\n\t\t\tbreak;\n\t\terr = 0;\n\t\tbreak;\n\n\tdefault:\n\t\terr = -EINVAL;\n\t}\n\n\treturn err;\n}\n\nstatic struct rtnl_link_stats64*\nppp_get_stats64(struct net_device *dev, struct rtnl_link_stats64 *stats64)\n{\n\tstruct ppp *ppp = netdev_priv(dev);\n\n\tppp_recv_lock(ppp);\n\tstats64->rx_packets = ppp->stats64.rx_packets;\n\tstats64->rx_bytes   = ppp->stats64.rx_bytes;\n\tppp_recv_unlock(ppp);\n\n\tppp_xmit_lock(ppp);\n\tstats64->tx_packets = ppp->stats64.tx_packets;\n\tstats64->tx_bytes   = ppp->stats64.tx_bytes;\n\tppp_xmit_unlock(ppp);\n\n\tstats64->rx_errors        = dev->stats.rx_errors;\n\tstats64->tx_errors        = dev->stats.tx_errors;\n\tstats64->rx_dropped       = dev->stats.rx_dropped;\n\tstats64->tx_dropped       = dev->stats.tx_dropped;\n\tstats64->rx_length_errors = dev->stats.rx_length_errors;\n\n\treturn stats64;\n}\n\nstatic struct lock_class_key ppp_tx_busylock;\nstatic int ppp_dev_init(struct net_device *dev)\n{\n\tdev->qdisc_tx_busylock = &ppp_tx_busylock;\n\treturn 0;\n}\n\nstatic void ppp_dev_uninit(struct net_device *dev)\n{\n\tstruct ppp *ppp = netdev_priv(dev);\n\tstruct ppp_net *pn = ppp_pernet(ppp->ppp_net);\n\n\tppp_lock(ppp);\n\tppp->closing = 1;\n\tppp_unlock(ppp);\n\n\tmutex_lock(&pn->all_ppp_mutex);\n\tunit_put(&pn->units_idr, ppp->file.index);\n\tmutex_unlock(&pn->all_ppp_mutex);\n\n\tppp->owner = NULL;\n\n\tppp->file.dead = 1;\n\twake_up_interruptible(&ppp->file.rwait);\n}\n\nstatic const struct net_device_ops ppp_netdev_ops = {\n\t.ndo_init\t = ppp_dev_init,\n\t.ndo_uninit      = ppp_dev_uninit,\n\t.ndo_start_xmit  = ppp_start_xmit,\n\t.ndo_do_ioctl    = ppp_net_ioctl,\n\t.ndo_get_stats64 = ppp_get_stats64,\n};\n\nstatic struct device_type ppp_type = {\n\t.name = \"ppp\",\n};\n\nstatic void ppp_setup(struct net_device *dev)\n{\n\tdev->netdev_ops = &ppp_netdev_ops;\n\tSET_NETDEV_DEVTYPE(dev, &ppp_type);\n\n\tdev->hard_header_len = PPP_HDRLEN;\n\tdev->mtu = PPP_MRU;\n\tdev->addr_len = 0;\n\tdev->tx_queue_len = 3;\n\tdev->type = ARPHRD_PPP;\n\tdev->flags = IFF_POINTOPOINT | IFF_NOARP | IFF_MULTICAST;\n\tnetif_keep_dst(dev);\n}\n\n/*\n * Transmit-side routines.\n */\n\n/*\n * Called to do any work queued up on the transmit side\n * that can now be done.\n */\nstatic void\nppp_xmit_process(struct ppp *ppp)\n{\n\tstruct sk_buff *skb;\n\n\tppp_xmit_lock(ppp);\n\tif (!ppp->closing) {\n\t\tppp_push(ppp);\n\t\twhile (!ppp->xmit_pending &&\n\t\t       (skb = skb_dequeue(&ppp->file.xq)))\n\t\t\tppp_send_frame(ppp, skb);\n\t\t/* If there's no work left to do, tell the core net\n\t\t   code that we can accept some more. */\n\t\tif (!ppp->xmit_pending && !skb_peek(&ppp->file.xq))\n\t\t\tnetif_wake_queue(ppp->dev);\n\t\telse\n\t\t\tnetif_stop_queue(ppp->dev);\n\t}\n\tppp_xmit_unlock(ppp);\n}\n\nstatic inline struct sk_buff *\npad_compress_skb(struct ppp *ppp, struct sk_buff *skb)\n{\n\tstruct sk_buff *new_skb;\n\tint len;\n\tint new_skb_size = ppp->dev->mtu +\n\t\tppp->xcomp->comp_extra + ppp->dev->hard_header_len;\n\tint compressor_skb_size = ppp->dev->mtu +\n\t\tppp->xcomp->comp_extra + PPP_HDRLEN;\n\tnew_skb = alloc_skb(new_skb_size, GFP_ATOMIC);\n\tif (!new_skb) {\n\t\tif (net_ratelimit())\n\t\t\tnetdev_err(ppp->dev, \"PPP: no memory (comp pkt)\\n\");\n\t\treturn NULL;\n\t}\n\tif (ppp->dev->hard_header_len > PPP_HDRLEN)\n\t\tskb_reserve(new_skb,\n\t\t\t    ppp->dev->hard_header_len - PPP_HDRLEN);\n\n\t/* compressor still expects A/C bytes in hdr */\n\tlen = ppp->xcomp->compress(ppp->xc_state, skb->data - 2,\n\t\t\t\t   new_skb->data, skb->len + 2,\n\t\t\t\t   compressor_skb_size);\n\tif (len > 0 && (ppp->flags & SC_CCP_UP)) {\n\t\tconsume_skb(skb);\n\t\tskb = new_skb;\n\t\tskb_put(skb, len);\n\t\tskb_pull(skb, 2);\t/* pull off A/C bytes */\n\t} else if (len == 0) {\n\t\t/* didn't compress, or CCP not up yet */\n\t\tconsume_skb(new_skb);\n\t\tnew_skb = skb;\n\t} else {\n\t\t/*\n\t\t * (len < 0)\n\t\t * MPPE requires that we do not send unencrypted\n\t\t * frames.  The compressor will return -1 if we\n\t\t * should drop the frame.  We cannot simply test\n\t\t * the compress_proto because MPPE and MPPC share\n\t\t * the same number.\n\t\t */\n\t\tif (net_ratelimit())\n\t\t\tnetdev_err(ppp->dev, \"ppp: compressor dropped pkt\\n\");\n\t\tkfree_skb(skb);\n\t\tconsume_skb(new_skb);\n\t\tnew_skb = NULL;\n\t}\n\treturn new_skb;\n}\n\n/*\n * Compress and send a frame.\n * The caller should have locked the xmit path,\n * and xmit_pending should be 0.\n */\nstatic void\nppp_send_frame(struct ppp *ppp, struct sk_buff *skb)\n{\n\tint proto = PPP_PROTO(skb);\n\tstruct sk_buff *new_skb;\n\tint len;\n\tunsigned char *cp;\n\n\tif (proto < 0x8000) {\n#ifdef CONFIG_PPP_FILTER\n\t\t/* check if we should pass this packet */\n\t\t/* the filter instructions are constructed assuming\n\t\t   a four-byte PPP header on each packet */\n\t\t*skb_push(skb, 2) = 1;\n\t\tif (ppp->pass_filter &&\n\t\t    BPF_PROG_RUN(ppp->pass_filter, skb) == 0) {\n\t\t\tif (ppp->debug & 1)\n\t\t\t\tnetdev_printk(KERN_DEBUG, ppp->dev,\n\t\t\t\t\t      \"PPP: outbound frame \"\n\t\t\t\t\t      \"not passed\\n\");\n\t\t\tkfree_skb(skb);\n\t\t\treturn;\n\t\t}\n\t\t/* if this packet passes the active filter, record the time */\n\t\tif (!(ppp->active_filter &&\n\t\t      BPF_PROG_RUN(ppp->active_filter, skb) == 0))\n\t\t\tppp->last_xmit = jiffies;\n\t\tskb_pull(skb, 2);\n#else\n\t\t/* for data packets, record the time */\n\t\tppp->last_xmit = jiffies;\n#endif /* CONFIG_PPP_FILTER */\n\t}\n\n\t++ppp->stats64.tx_packets;\n\tppp->stats64.tx_bytes += skb->len - 2;\n\n\tswitch (proto) {\n\tcase PPP_IP:\n\t\tif (!ppp->vj || (ppp->flags & SC_COMP_TCP) == 0)\n\t\t\tbreak;\n\t\t/* try to do VJ TCP header compression */\n\t\tnew_skb = alloc_skb(skb->len + ppp->dev->hard_header_len - 2,\n\t\t\t\t    GFP_ATOMIC);\n\t\tif (!new_skb) {\n\t\t\tnetdev_err(ppp->dev, \"PPP: no memory (VJ comp pkt)\\n\");\n\t\t\tgoto drop;\n\t\t}\n\t\tskb_reserve(new_skb, ppp->dev->hard_header_len - 2);\n\t\tcp = skb->data + 2;\n\t\tlen = slhc_compress(ppp->vj, cp, skb->len - 2,\n\t\t\t\t    new_skb->data + 2, &cp,\n\t\t\t\t    !(ppp->flags & SC_NO_TCP_CCID));\n\t\tif (cp == skb->data + 2) {\n\t\t\t/* didn't compress */\n\t\t\tconsume_skb(new_skb);\n\t\t} else {\n\t\t\tif (cp[0] & SL_TYPE_COMPRESSED_TCP) {\n\t\t\t\tproto = PPP_VJC_COMP;\n\t\t\t\tcp[0] &= ~SL_TYPE_COMPRESSED_TCP;\n\t\t\t} else {\n\t\t\t\tproto = PPP_VJC_UNCOMP;\n\t\t\t\tcp[0] = skb->data[2];\n\t\t\t}\n\t\t\tconsume_skb(skb);\n\t\t\tskb = new_skb;\n\t\t\tcp = skb_put(skb, len + 2);\n\t\t\tcp[0] = 0;\n\t\t\tcp[1] = proto;\n\t\t}\n\t\tbreak;\n\n\tcase PPP_CCP:\n\t\t/* peek at outbound CCP frames */\n\t\tppp_ccp_peek(ppp, skb, 0);\n\t\tbreak;\n\t}\n\n\t/* try to do packet compression */\n\tif ((ppp->xstate & SC_COMP_RUN) && ppp->xc_state &&\n\t    proto != PPP_LCP && proto != PPP_CCP) {\n\t\tif (!(ppp->flags & SC_CCP_UP) && (ppp->flags & SC_MUST_COMP)) {\n\t\t\tif (net_ratelimit())\n\t\t\t\tnetdev_err(ppp->dev,\n\t\t\t\t\t   \"ppp: compression required but \"\n\t\t\t\t\t   \"down - pkt dropped.\\n\");\n\t\t\tgoto drop;\n\t\t}\n\t\tskb = pad_compress_skb(ppp, skb);\n\t\tif (!skb)\n\t\t\tgoto drop;\n\t}\n\n\t/*\n\t * If we are waiting for traffic (demand dialling),\n\t * queue it up for pppd to receive.\n\t */\n\tif (ppp->flags & SC_LOOP_TRAFFIC) {\n\t\tif (ppp->file.rq.qlen > PPP_MAX_RQLEN)\n\t\t\tgoto drop;\n\t\tskb_queue_tail(&ppp->file.rq, skb);\n\t\twake_up_interruptible(&ppp->file.rwait);\n\t\treturn;\n\t}\n\n\tppp->xmit_pending = skb;\n\tppp_push(ppp);\n\treturn;\n\n drop:\n\tkfree_skb(skb);\n\t++ppp->dev->stats.tx_errors;\n}\n\n/*\n * Try to send the frame in xmit_pending.\n * The caller should have the xmit path locked.\n */\nstatic void\nppp_push(struct ppp *ppp)\n{\n\tstruct list_head *list;\n\tstruct channel *pch;\n\tstruct sk_buff *skb = ppp->xmit_pending;\n\n\tif (!skb)\n\t\treturn;\n\n\tlist = &ppp->channels;\n\tif (list_empty(list)) {\n\t\t/* nowhere to send the packet, just drop it */\n\t\tppp->xmit_pending = NULL;\n\t\tkfree_skb(skb);\n\t\treturn;\n\t}\n\n\tif ((ppp->flags & SC_MULTILINK) == 0) {\n\t\t/* not doing multilink: send it down the first channel */\n\t\tlist = list->next;\n\t\tpch = list_entry(list, struct channel, clist);\n\n\t\tspin_lock_bh(&pch->downl);\n\t\tif (pch->chan) {\n\t\t\tif (pch->chan->ops->start_xmit(pch->chan, skb))\n\t\t\t\tppp->xmit_pending = NULL;\n\t\t} else {\n\t\t\t/* channel got unregistered */\n\t\t\tkfree_skb(skb);\n\t\t\tppp->xmit_pending = NULL;\n\t\t}\n\t\tspin_unlock_bh(&pch->downl);\n\t\treturn;\n\t}\n\n#ifdef CONFIG_PPP_MULTILINK\n\t/* Multilink: fragment the packet over as many links\n\t   as can take the packet at the moment. */\n\tif (!ppp_mp_explode(ppp, skb))\n\t\treturn;\n#endif /* CONFIG_PPP_MULTILINK */\n\n\tppp->xmit_pending = NULL;\n\tkfree_skb(skb);\n}\n\n#ifdef CONFIG_PPP_MULTILINK\nstatic bool mp_protocol_compress __read_mostly = true;\nmodule_param(mp_protocol_compress, bool, S_IRUGO | S_IWUSR);\nMODULE_PARM_DESC(mp_protocol_compress,\n\t\t \"compress protocol id in multilink fragments\");\n\n/*\n * Divide a packet to be transmitted into fragments and\n * send them out the individual links.\n */\nstatic int ppp_mp_explode(struct ppp *ppp, struct sk_buff *skb)\n{\n\tint len, totlen;\n\tint i, bits, hdrlen, mtu;\n\tint flen;\n\tint navail, nfree, nzero;\n\tint nbigger;\n\tint totspeed;\n\tint totfree;\n\tunsigned char *p, *q;\n\tstruct list_head *list;\n\tstruct channel *pch;\n\tstruct sk_buff *frag;\n\tstruct ppp_channel *chan;\n\n\ttotspeed = 0; /*total bitrate of the bundle*/\n\tnfree = 0; /* # channels which have no packet already queued */\n\tnavail = 0; /* total # of usable channels (not deregistered) */\n\tnzero = 0; /* number of channels with zero speed associated*/\n\ttotfree = 0; /*total # of channels available and\n\t\t\t\t  *having no queued packets before\n\t\t\t\t  *starting the fragmentation*/\n\n\thdrlen = (ppp->flags & SC_MP_XSHORTSEQ)? MPHDRLEN_SSN: MPHDRLEN;\n\ti = 0;\n\tlist_for_each_entry(pch, &ppp->channels, clist) {\n\t\tif (pch->chan) {\n\t\t\tpch->avail = 1;\n\t\t\tnavail++;\n\t\t\tpch->speed = pch->chan->speed;\n\t\t} else {\n\t\t\tpch->avail = 0;\n\t\t}\n\t\tif (pch->avail) {\n\t\t\tif (skb_queue_empty(&pch->file.xq) ||\n\t\t\t\t!pch->had_frag) {\n\t\t\t\t\tif (pch->speed == 0)\n\t\t\t\t\t\tnzero++;\n\t\t\t\t\telse\n\t\t\t\t\t\ttotspeed += pch->speed;\n\n\t\t\t\t\tpch->avail = 2;\n\t\t\t\t\t++nfree;\n\t\t\t\t\t++totfree;\n\t\t\t\t}\n\t\t\tif (!pch->had_frag && i < ppp->nxchan)\n\t\t\t\tppp->nxchan = i;\n\t\t}\n\t\t++i;\n\t}\n\t/*\n\t * Don't start sending this packet unless at least half of\n\t * the channels are free.  This gives much better TCP\n\t * performance if we have a lot of channels.\n\t */\n\tif (nfree == 0 || nfree < navail / 2)\n\t\treturn 0; /* can't take now, leave it in xmit_pending */\n\n\t/* Do protocol field compression */\n\tp = skb->data;\n\tlen = skb->len;\n\tif (*p == 0 && mp_protocol_compress) {\n\t\t++p;\n\t\t--len;\n\t}\n\n\ttotlen = len;\n\tnbigger = len % nfree;\n\n\t/* skip to the channel after the one we last used\n\t   and start at that one */\n\tlist = &ppp->channels;\n\tfor (i = 0; i < ppp->nxchan; ++i) {\n\t\tlist = list->next;\n\t\tif (list == &ppp->channels) {\n\t\t\ti = 0;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\t/* create a fragment for each channel */\n\tbits = B;\n\twhile (len > 0) {\n\t\tlist = list->next;\n\t\tif (list == &ppp->channels) {\n\t\t\ti = 0;\n\t\t\tcontinue;\n\t\t}\n\t\tpch = list_entry(list, struct channel, clist);\n\t\t++i;\n\t\tif (!pch->avail)\n\t\t\tcontinue;\n\n\t\t/*\n\t\t * Skip this channel if it has a fragment pending already and\n\t\t * we haven't given a fragment to all of the free channels.\n\t\t */\n\t\tif (pch->avail == 1) {\n\t\t\tif (nfree > 0)\n\t\t\t\tcontinue;\n\t\t} else {\n\t\t\tpch->avail = 1;\n\t\t}\n\n\t\t/* check the channel's mtu and whether it is still attached. */\n\t\tspin_lock_bh(&pch->downl);\n\t\tif (pch->chan == NULL) {\n\t\t\t/* can't use this channel, it's being deregistered */\n\t\t\tif (pch->speed == 0)\n\t\t\t\tnzero--;\n\t\t\telse\n\t\t\t\ttotspeed -= pch->speed;\n\n\t\t\tspin_unlock_bh(&pch->downl);\n\t\t\tpch->avail = 0;\n\t\t\ttotlen = len;\n\t\t\ttotfree--;\n\t\t\tnfree--;\n\t\t\tif (--navail == 0)\n\t\t\t\tbreak;\n\t\t\tcontinue;\n\t\t}\n\n\t\t/*\n\t\t*if the channel speed is not set divide\n\t\t*the packet evenly among the free channels;\n\t\t*otherwise divide it according to the speed\n\t\t*of the channel we are going to transmit on\n\t\t*/\n\t\tflen = len;\n\t\tif (nfree > 0) {\n\t\t\tif (pch->speed == 0) {\n\t\t\t\tflen = len/nfree;\n\t\t\t\tif (nbigger > 0) {\n\t\t\t\t\tflen++;\n\t\t\t\t\tnbigger--;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tflen = (((totfree - nzero)*(totlen + hdrlen*totfree)) /\n\t\t\t\t\t((totspeed*totfree)/pch->speed)) - hdrlen;\n\t\t\t\tif (nbigger > 0) {\n\t\t\t\t\tflen += ((totfree - nzero)*pch->speed)/totspeed;\n\t\t\t\t\tnbigger -= ((totfree - nzero)*pch->speed)/\n\t\t\t\t\t\t\ttotspeed;\n\t\t\t\t}\n\t\t\t}\n\t\t\tnfree--;\n\t\t}\n\n\t\t/*\n\t\t *check if we are on the last channel or\n\t\t *we exceded the length of the data to\n\t\t *fragment\n\t\t */\n\t\tif ((nfree <= 0) || (flen > len))\n\t\t\tflen = len;\n\t\t/*\n\t\t *it is not worth to tx on slow channels:\n\t\t *in that case from the resulting flen according to the\n\t\t *above formula will be equal or less than zero.\n\t\t *Skip the channel in this case\n\t\t */\n\t\tif (flen <= 0) {\n\t\t\tpch->avail = 2;\n\t\t\tspin_unlock_bh(&pch->downl);\n\t\t\tcontinue;\n\t\t}\n\n\t\t/*\n\t\t * hdrlen includes the 2-byte PPP protocol field, but the\n\t\t * MTU counts only the payload excluding the protocol field.\n\t\t * (RFC1661 Section 2)\n\t\t */\n\t\tmtu = pch->chan->mtu - (hdrlen - 2);\n\t\tif (mtu < 4)\n\t\t\tmtu = 4;\n\t\tif (flen > mtu)\n\t\t\tflen = mtu;\n\t\tif (flen == len)\n\t\t\tbits |= E;\n\t\tfrag = alloc_skb(flen + hdrlen + (flen == 0), GFP_ATOMIC);\n\t\tif (!frag)\n\t\t\tgoto noskb;\n\t\tq = skb_put(frag, flen + hdrlen);\n\n\t\t/* make the MP header */\n\t\tput_unaligned_be16(PPP_MP, q);\n\t\tif (ppp->flags & SC_MP_XSHORTSEQ) {\n\t\t\tq[2] = bits + ((ppp->nxseq >> 8) & 0xf);\n\t\t\tq[3] = ppp->nxseq;\n\t\t} else {\n\t\t\tq[2] = bits;\n\t\t\tq[3] = ppp->nxseq >> 16;\n\t\t\tq[4] = ppp->nxseq >> 8;\n\t\t\tq[5] = ppp->nxseq;\n\t\t}\n\n\t\tmemcpy(q + hdrlen, p, flen);\n\n\t\t/* try to send it down the channel */\n\t\tchan = pch->chan;\n\t\tif (!skb_queue_empty(&pch->file.xq) ||\n\t\t\t!chan->ops->start_xmit(chan, frag))\n\t\t\tskb_queue_tail(&pch->file.xq, frag);\n\t\tpch->had_frag = 1;\n\t\tp += flen;\n\t\tlen -= flen;\n\t\t++ppp->nxseq;\n\t\tbits = 0;\n\t\tspin_unlock_bh(&pch->downl);\n\t}\n\tppp->nxchan = i;\n\n\treturn 1;\n\n noskb:\n\tspin_unlock_bh(&pch->downl);\n\tif (ppp->debug & 1)\n\t\tnetdev_err(ppp->dev, \"PPP: no memory (fragment)\\n\");\n\t++ppp->dev->stats.tx_errors;\n\t++ppp->nxseq;\n\treturn 1;\t/* abandon the frame */\n}\n#endif /* CONFIG_PPP_MULTILINK */\n\n/*\n * Try to send data out on a channel.\n */\nstatic void\nppp_channel_push(struct channel *pch)\n{\n\tstruct sk_buff *skb;\n\tstruct ppp *ppp;\n\n\tspin_lock_bh(&pch->downl);\n\tif (pch->chan) {\n\t\twhile (!skb_queue_empty(&pch->file.xq)) {\n\t\t\tskb = skb_dequeue(&pch->file.xq);\n\t\t\tif (!pch->chan->ops->start_xmit(pch->chan, skb)) {\n\t\t\t\t/* put the packet back and try again later */\n\t\t\t\tskb_queue_head(&pch->file.xq, skb);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t} else {\n\t\t/* channel got deregistered */\n\t\tskb_queue_purge(&pch->file.xq);\n\t}\n\tspin_unlock_bh(&pch->downl);\n\t/* see if there is anything from the attached unit to be sent */\n\tif (skb_queue_empty(&pch->file.xq)) {\n\t\tread_lock_bh(&pch->upl);\n\t\tppp = pch->ppp;\n\t\tif (ppp)\n\t\t\tppp_xmit_process(ppp);\n\t\tread_unlock_bh(&pch->upl);\n\t}\n}\n\n/*\n * Receive-side routines.\n */\n\nstruct ppp_mp_skb_parm {\n\tu32\t\tsequence;\n\tu8\t\tBEbits;\n};\n#define PPP_MP_CB(skb)\t((struct ppp_mp_skb_parm *)((skb)->cb))\n\nstatic inline void\nppp_do_recv(struct ppp *ppp, struct sk_buff *skb, struct channel *pch)\n{\n\tppp_recv_lock(ppp);\n\tif (!ppp->closing)\n\t\tppp_receive_frame(ppp, skb, pch);\n\telse\n\t\tkfree_skb(skb);\n\tppp_recv_unlock(ppp);\n}\n\nvoid\nppp_input(struct ppp_channel *chan, struct sk_buff *skb)\n{\n\tstruct channel *pch = chan->ppp;\n\tint proto;\n\n\tif (!pch) {\n\t\tkfree_skb(skb);\n\t\treturn;\n\t}\n\n\tread_lock_bh(&pch->upl);\n\tif (!pskb_may_pull(skb, 2)) {\n\t\tkfree_skb(skb);\n\t\tif (pch->ppp) {\n\t\t\t++pch->ppp->dev->stats.rx_length_errors;\n\t\t\tppp_receive_error(pch->ppp);\n\t\t}\n\t\tgoto done;\n\t}\n\n\tproto = PPP_PROTO(skb);\n\tif (!pch->ppp || proto >= 0xc000 || proto == PPP_CCPFRAG) {\n\t\t/* put it on the channel queue */\n\t\tskb_queue_tail(&pch->file.rq, skb);\n\t\t/* drop old frames if queue too long */\n\t\twhile (pch->file.rq.qlen > PPP_MAX_RQLEN &&\n\t\t       (skb = skb_dequeue(&pch->file.rq)))\n\t\t\tkfree_skb(skb);\n\t\twake_up_interruptible(&pch->file.rwait);\n\t} else {\n\t\tppp_do_recv(pch->ppp, skb, pch);\n\t}\n\ndone:\n\tread_unlock_bh(&pch->upl);\n}\n\n/* Put a 0-length skb in the receive queue as an error indication */\nvoid\nppp_input_error(struct ppp_channel *chan, int code)\n{\n\tstruct channel *pch = chan->ppp;\n\tstruct sk_buff *skb;\n\n\tif (!pch)\n\t\treturn;\n\n\tread_lock_bh(&pch->upl);\n\tif (pch->ppp) {\n\t\tskb = alloc_skb(0, GFP_ATOMIC);\n\t\tif (skb) {\n\t\t\tskb->len = 0;\t\t/* probably unnecessary */\n\t\t\tskb->cb[0] = code;\n\t\t\tppp_do_recv(pch->ppp, skb, pch);\n\t\t}\n\t}\n\tread_unlock_bh(&pch->upl);\n}\n\n/*\n * We come in here to process a received frame.\n * The receive side of the ppp unit is locked.\n */\nstatic void\nppp_receive_frame(struct ppp *ppp, struct sk_buff *skb, struct channel *pch)\n{\n\t/* note: a 0-length skb is used as an error indication */\n\tif (skb->len > 0) {\n\t\tskb_checksum_complete_unset(skb);\n#ifdef CONFIG_PPP_MULTILINK\n\t\t/* XXX do channel-level decompression here */\n\t\tif (PPP_PROTO(skb) == PPP_MP)\n\t\t\tppp_receive_mp_frame(ppp, skb, pch);\n\t\telse\n#endif /* CONFIG_PPP_MULTILINK */\n\t\t\tppp_receive_nonmp_frame(ppp, skb);\n\t} else {\n\t\tkfree_skb(skb);\n\t\tppp_receive_error(ppp);\n\t}\n}\n\nstatic void\nppp_receive_error(struct ppp *ppp)\n{\n\t++ppp->dev->stats.rx_errors;\n\tif (ppp->vj)\n\t\tslhc_toss(ppp->vj);\n}\n\nstatic void\nppp_receive_nonmp_frame(struct ppp *ppp, struct sk_buff *skb)\n{\n\tstruct sk_buff *ns;\n\tint proto, len, npi;\n\n\t/*\n\t * Decompress the frame, if compressed.\n\t * Note that some decompressors need to see uncompressed frames\n\t * that come in as well as compressed frames.\n\t */\n\tif (ppp->rc_state && (ppp->rstate & SC_DECOMP_RUN) &&\n\t    (ppp->rstate & (SC_DC_FERROR | SC_DC_ERROR)) == 0)\n\t\tskb = ppp_decompress_frame(ppp, skb);\n\n\tif (ppp->flags & SC_MUST_COMP && ppp->rstate & SC_DC_FERROR)\n\t\tgoto err;\n\n\tproto = PPP_PROTO(skb);\n\tswitch (proto) {\n\tcase PPP_VJC_COMP:\n\t\t/* decompress VJ compressed packets */\n\t\tif (!ppp->vj || (ppp->flags & SC_REJ_COMP_TCP))\n\t\t\tgoto err;\n\n\t\tif (skb_tailroom(skb) < 124 || skb_cloned(skb)) {\n\t\t\t/* copy to a new sk_buff with more tailroom */\n\t\t\tns = dev_alloc_skb(skb->len + 128);\n\t\t\tif (!ns) {\n\t\t\t\tnetdev_err(ppp->dev, \"PPP: no memory \"\n\t\t\t\t\t   \"(VJ decomp)\\n\");\n\t\t\t\tgoto err;\n\t\t\t}\n\t\t\tskb_reserve(ns, 2);\n\t\t\tskb_copy_bits(skb, 0, skb_put(ns, skb->len), skb->len);\n\t\t\tconsume_skb(skb);\n\t\t\tskb = ns;\n\t\t}\n\t\telse\n\t\t\tskb->ip_summed = CHECKSUM_NONE;\n\n\t\tlen = slhc_uncompress(ppp->vj, skb->data + 2, skb->len - 2);\n\t\tif (len <= 0) {\n\t\t\tnetdev_printk(KERN_DEBUG, ppp->dev,\n\t\t\t\t      \"PPP: VJ decompression error\\n\");\n\t\t\tgoto err;\n\t\t}\n\t\tlen += 2;\n\t\tif (len > skb->len)\n\t\t\tskb_put(skb, len - skb->len);\n\t\telse if (len < skb->len)\n\t\t\tskb_trim(skb, len);\n\t\tproto = PPP_IP;\n\t\tbreak;\n\n\tcase PPP_VJC_UNCOMP:\n\t\tif (!ppp->vj || (ppp->flags & SC_REJ_COMP_TCP))\n\t\t\tgoto err;\n\n\t\t/* Until we fix the decompressor need to make sure\n\t\t * data portion is linear.\n\t\t */\n\t\tif (!pskb_may_pull(skb, skb->len))\n\t\t\tgoto err;\n\n\t\tif (slhc_remember(ppp->vj, skb->data + 2, skb->len - 2) <= 0) {\n\t\t\tnetdev_err(ppp->dev, \"PPP: VJ uncompressed error\\n\");\n\t\t\tgoto err;\n\t\t}\n\t\tproto = PPP_IP;\n\t\tbreak;\n\n\tcase PPP_CCP:\n\t\tppp_ccp_peek(ppp, skb, 1);\n\t\tbreak;\n\t}\n\n\t++ppp->stats64.rx_packets;\n\tppp->stats64.rx_bytes += skb->len - 2;\n\n\tnpi = proto_to_npindex(proto);\n\tif (npi < 0) {\n\t\t/* control or unknown frame - pass it to pppd */\n\t\tskb_queue_tail(&ppp->file.rq, skb);\n\t\t/* limit queue length by dropping old frames */\n\t\twhile (ppp->file.rq.qlen > PPP_MAX_RQLEN &&\n\t\t       (skb = skb_dequeue(&ppp->file.rq)))\n\t\t\tkfree_skb(skb);\n\t\t/* wake up any process polling or blocking on read */\n\t\twake_up_interruptible(&ppp->file.rwait);\n\n\t} else {\n\t\t/* network protocol frame - give it to the kernel */\n\n#ifdef CONFIG_PPP_FILTER\n\t\t/* check if the packet passes the pass and active filters */\n\t\t/* the filter instructions are constructed assuming\n\t\t   a four-byte PPP header on each packet */\n\t\tif (ppp->pass_filter || ppp->active_filter) {\n\t\t\tif (skb_unclone(skb, GFP_ATOMIC))\n\t\t\t\tgoto err;\n\n\t\t\t*skb_push(skb, 2) = 0;\n\t\t\tif (ppp->pass_filter &&\n\t\t\t    BPF_PROG_RUN(ppp->pass_filter, skb) == 0) {\n\t\t\t\tif (ppp->debug & 1)\n\t\t\t\t\tnetdev_printk(KERN_DEBUG, ppp->dev,\n\t\t\t\t\t\t      \"PPP: inbound frame \"\n\t\t\t\t\t\t      \"not passed\\n\");\n\t\t\t\tkfree_skb(skb);\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tif (!(ppp->active_filter &&\n\t\t\t      BPF_PROG_RUN(ppp->active_filter, skb) == 0))\n\t\t\t\tppp->last_recv = jiffies;\n\t\t\t__skb_pull(skb, 2);\n\t\t} else\n#endif /* CONFIG_PPP_FILTER */\n\t\t\tppp->last_recv = jiffies;\n\n\t\tif ((ppp->dev->flags & IFF_UP) == 0 ||\n\t\t    ppp->npmode[npi] != NPMODE_PASS) {\n\t\t\tkfree_skb(skb);\n\t\t} else {\n\t\t\t/* chop off protocol */\n\t\t\tskb_pull_rcsum(skb, 2);\n\t\t\tskb->dev = ppp->dev;\n\t\t\tskb->protocol = htons(npindex_to_ethertype[npi]);\n\t\t\tskb_reset_mac_header(skb);\n\t\t\tskb_scrub_packet(skb, !net_eq(ppp->ppp_net,\n\t\t\t\t\t\t      dev_net(ppp->dev)));\n\t\t\tnetif_rx(skb);\n\t\t}\n\t}\n\treturn;\n\n err:\n\tkfree_skb(skb);\n\tppp_receive_error(ppp);\n}\n\nstatic struct sk_buff *\nppp_decompress_frame(struct ppp *ppp, struct sk_buff *skb)\n{\n\tint proto = PPP_PROTO(skb);\n\tstruct sk_buff *ns;\n\tint len;\n\n\t/* Until we fix all the decompressor's need to make sure\n\t * data portion is linear.\n\t */\n\tif (!pskb_may_pull(skb, skb->len))\n\t\tgoto err;\n\n\tif (proto == PPP_COMP) {\n\t\tint obuff_size;\n\n\t\tswitch(ppp->rcomp->compress_proto) {\n\t\tcase CI_MPPE:\n\t\t\tobuff_size = ppp->mru + PPP_HDRLEN + 1;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tobuff_size = ppp->mru + PPP_HDRLEN;\n\t\t\tbreak;\n\t\t}\n\n\t\tns = dev_alloc_skb(obuff_size);\n\t\tif (!ns) {\n\t\t\tnetdev_err(ppp->dev, \"ppp_decompress_frame: \"\n\t\t\t\t   \"no memory\\n\");\n\t\t\tgoto err;\n\t\t}\n\t\t/* the decompressor still expects the A/C bytes in the hdr */\n\t\tlen = ppp->rcomp->decompress(ppp->rc_state, skb->data - 2,\n\t\t\t\tskb->len + 2, ns->data, obuff_size);\n\t\tif (len < 0) {\n\t\t\t/* Pass the compressed frame to pppd as an\n\t\t\t   error indication. */\n\t\t\tif (len == DECOMP_FATALERROR)\n\t\t\t\tppp->rstate |= SC_DC_FERROR;\n\t\t\tkfree_skb(ns);\n\t\t\tgoto err;\n\t\t}\n\n\t\tconsume_skb(skb);\n\t\tskb = ns;\n\t\tskb_put(skb, len);\n\t\tskb_pull(skb, 2);\t/* pull off the A/C bytes */\n\n\t} else {\n\t\t/* Uncompressed frame - pass to decompressor so it\n\t\t   can update its dictionary if necessary. */\n\t\tif (ppp->rcomp->incomp)\n\t\t\tppp->rcomp->incomp(ppp->rc_state, skb->data - 2,\n\t\t\t\t\t   skb->len + 2);\n\t}\n\n\treturn skb;\n\n err:\n\tppp->rstate |= SC_DC_ERROR;\n\tppp_receive_error(ppp);\n\treturn skb;\n}\n\n#ifdef CONFIG_PPP_MULTILINK\n/*\n * Receive a multilink frame.\n * We put it on the reconstruction queue and then pull off\n * as many completed frames as we can.\n */\nstatic void\nppp_receive_mp_frame(struct ppp *ppp, struct sk_buff *skb, struct channel *pch)\n{\n\tu32 mask, seq;\n\tstruct channel *ch;\n\tint mphdrlen = (ppp->flags & SC_MP_SHORTSEQ)? MPHDRLEN_SSN: MPHDRLEN;\n\n\tif (!pskb_may_pull(skb, mphdrlen + 1) || ppp->mrru == 0)\n\t\tgoto err;\t\t/* no good, throw it away */\n\n\t/* Decode sequence number and begin/end bits */\n\tif (ppp->flags & SC_MP_SHORTSEQ) {\n\t\tseq = ((skb->data[2] & 0x0f) << 8) | skb->data[3];\n\t\tmask = 0xfff;\n\t} else {\n\t\tseq = (skb->data[3] << 16) | (skb->data[4] << 8)| skb->data[5];\n\t\tmask = 0xffffff;\n\t}\n\tPPP_MP_CB(skb)->BEbits = skb->data[2];\n\tskb_pull(skb, mphdrlen);\t/* pull off PPP and MP headers */\n\n\t/*\n\t * Do protocol ID decompression on the first fragment of each packet.\n\t */\n\tif ((PPP_MP_CB(skb)->BEbits & B) && (skb->data[0] & 1))\n\t\t*skb_push(skb, 1) = 0;\n\n\t/*\n\t * Expand sequence number to 32 bits, making it as close\n\t * as possible to ppp->minseq.\n\t */\n\tseq |= ppp->minseq & ~mask;\n\tif ((int)(ppp->minseq - seq) > (int)(mask >> 1))\n\t\tseq += mask + 1;\n\telse if ((int)(seq - ppp->minseq) > (int)(mask >> 1))\n\t\tseq -= mask + 1;\t/* should never happen */\n\tPPP_MP_CB(skb)->sequence = seq;\n\tpch->lastseq = seq;\n\n\t/*\n\t * If this packet comes before the next one we were expecting,\n\t * drop it.\n\t */\n\tif (seq_before(seq, ppp->nextseq)) {\n\t\tkfree_skb(skb);\n\t\t++ppp->dev->stats.rx_dropped;\n\t\tppp_receive_error(ppp);\n\t\treturn;\n\t}\n\n\t/*\n\t * Reevaluate minseq, the minimum over all channels of the\n\t * last sequence number received on each channel.  Because of\n\t * the increasing sequence number rule, we know that any fragment\n\t * before `minseq' which hasn't arrived is never going to arrive.\n\t * The list of channels can't change because we have the receive\n\t * side of the ppp unit locked.\n\t */\n\tlist_for_each_entry(ch, &ppp->channels, clist) {\n\t\tif (seq_before(ch->lastseq, seq))\n\t\t\tseq = ch->lastseq;\n\t}\n\tif (seq_before(ppp->minseq, seq))\n\t\tppp->minseq = seq;\n\n\t/* Put the fragment on the reconstruction queue */\n\tppp_mp_insert(ppp, skb);\n\n\t/* If the queue is getting long, don't wait any longer for packets\n\t   before the start of the queue. */\n\tif (skb_queue_len(&ppp->mrq) >= PPP_MP_MAX_QLEN) {\n\t\tstruct sk_buff *mskb = skb_peek(&ppp->mrq);\n\t\tif (seq_before(ppp->minseq, PPP_MP_CB(mskb)->sequence))\n\t\t\tppp->minseq = PPP_MP_CB(mskb)->sequence;\n\t}\n\n\t/* Pull completed packets off the queue and receive them. */\n\twhile ((skb = ppp_mp_reconstruct(ppp))) {\n\t\tif (pskb_may_pull(skb, 2))\n\t\t\tppp_receive_nonmp_frame(ppp, skb);\n\t\telse {\n\t\t\t++ppp->dev->stats.rx_length_errors;\n\t\t\tkfree_skb(skb);\n\t\t\tppp_receive_error(ppp);\n\t\t}\n\t}\n\n\treturn;\n\n err:\n\tkfree_skb(skb);\n\tppp_receive_error(ppp);\n}\n\n/*\n * Insert a fragment on the MP reconstruction queue.\n * The queue is ordered by increasing sequence number.\n */\nstatic void\nppp_mp_insert(struct ppp *ppp, struct sk_buff *skb)\n{\n\tstruct sk_buff *p;\n\tstruct sk_buff_head *list = &ppp->mrq;\n\tu32 seq = PPP_MP_CB(skb)->sequence;\n\n\t/* N.B. we don't need to lock the list lock because we have the\n\t   ppp unit receive-side lock. */\n\tskb_queue_walk(list, p) {\n\t\tif (seq_before(seq, PPP_MP_CB(p)->sequence))\n\t\t\tbreak;\n\t}\n\t__skb_queue_before(list, p, skb);\n}\n\n/*\n * Reconstruct a packet from the MP fragment queue.\n * We go through increasing sequence numbers until we find a\n * complete packet, or we get to the sequence number for a fragment\n * which hasn't arrived but might still do so.\n */\nstatic struct sk_buff *\nppp_mp_reconstruct(struct ppp *ppp)\n{\n\tu32 seq = ppp->nextseq;\n\tu32 minseq = ppp->minseq;\n\tstruct sk_buff_head *list = &ppp->mrq;\n\tstruct sk_buff *p, *tmp;\n\tstruct sk_buff *head, *tail;\n\tstruct sk_buff *skb = NULL;\n\tint lost = 0, len = 0;\n\n\tif (ppp->mrru == 0)\t/* do nothing until mrru is set */\n\t\treturn NULL;\n\thead = list->next;\n\ttail = NULL;\n\tskb_queue_walk_safe(list, p, tmp) {\n\tagain:\n\t\tif (seq_before(PPP_MP_CB(p)->sequence, seq)) {\n\t\t\t/* this can't happen, anyway ignore the skb */\n\t\t\tnetdev_err(ppp->dev, \"ppp_mp_reconstruct bad \"\n\t\t\t\t   \"seq %u < %u\\n\",\n\t\t\t\t   PPP_MP_CB(p)->sequence, seq);\n\t\t\t__skb_unlink(p, list);\n\t\t\tkfree_skb(p);\n\t\t\tcontinue;\n\t\t}\n\t\tif (PPP_MP_CB(p)->sequence != seq) {\n\t\t\tu32 oldseq;\n\t\t\t/* Fragment `seq' is missing.  If it is after\n\t\t\t   minseq, it might arrive later, so stop here. */\n\t\t\tif (seq_after(seq, minseq))\n\t\t\t\tbreak;\n\t\t\t/* Fragment `seq' is lost, keep going. */\n\t\t\tlost = 1;\n\t\t\toldseq = seq;\n\t\t\tseq = seq_before(minseq, PPP_MP_CB(p)->sequence)?\n\t\t\t\tminseq + 1: PPP_MP_CB(p)->sequence;\n\n\t\t\tif (ppp->debug & 1)\n\t\t\t\tnetdev_printk(KERN_DEBUG, ppp->dev,\n\t\t\t\t\t      \"lost frag %u..%u\\n\",\n\t\t\t\t\t      oldseq, seq-1);\n\n\t\t\tgoto again;\n\t\t}\n\n\t\t/*\n\t\t * At this point we know that all the fragments from\n\t\t * ppp->nextseq to seq are either present or lost.\n\t\t * Also, there are no complete packets in the queue\n\t\t * that have no missing fragments and end before this\n\t\t * fragment.\n\t\t */\n\n\t\t/* B bit set indicates this fragment starts a packet */\n\t\tif (PPP_MP_CB(p)->BEbits & B) {\n\t\t\thead = p;\n\t\t\tlost = 0;\n\t\t\tlen = 0;\n\t\t}\n\n\t\tlen += p->len;\n\n\t\t/* Got a complete packet yet? */\n\t\tif (lost == 0 && (PPP_MP_CB(p)->BEbits & E) &&\n\t\t    (PPP_MP_CB(head)->BEbits & B)) {\n\t\t\tif (len > ppp->mrru + 2) {\n\t\t\t\t++ppp->dev->stats.rx_length_errors;\n\t\t\t\tnetdev_printk(KERN_DEBUG, ppp->dev,\n\t\t\t\t\t      \"PPP: reconstructed packet\"\n\t\t\t\t\t      \" is too long (%d)\\n\", len);\n\t\t\t} else {\n\t\t\t\ttail = p;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tppp->nextseq = seq + 1;\n\t\t}\n\n\t\t/*\n\t\t * If this is the ending fragment of a packet,\n\t\t * and we haven't found a complete valid packet yet,\n\t\t * we can discard up to and including this fragment.\n\t\t */\n\t\tif (PPP_MP_CB(p)->BEbits & E) {\n\t\t\tstruct sk_buff *tmp2;\n\n\t\t\tskb_queue_reverse_walk_from_safe(list, p, tmp2) {\n\t\t\t\tif (ppp->debug & 1)\n\t\t\t\t\tnetdev_printk(KERN_DEBUG, ppp->dev,\n\t\t\t\t\t\t      \"discarding frag %u\\n\",\n\t\t\t\t\t\t      PPP_MP_CB(p)->sequence);\n\t\t\t\t__skb_unlink(p, list);\n\t\t\t\tkfree_skb(p);\n\t\t\t}\n\t\t\thead = skb_peek(list);\n\t\t\tif (!head)\n\t\t\t\tbreak;\n\t\t}\n\t\t++seq;\n\t}\n\n\t/* If we have a complete packet, copy it all into one skb. */\n\tif (tail != NULL) {\n\t\t/* If we have discarded any fragments,\n\t\t   signal a receive error. */\n\t\tif (PPP_MP_CB(head)->sequence != ppp->nextseq) {\n\t\t\tskb_queue_walk_safe(list, p, tmp) {\n\t\t\t\tif (p == head)\n\t\t\t\t\tbreak;\n\t\t\t\tif (ppp->debug & 1)\n\t\t\t\t\tnetdev_printk(KERN_DEBUG, ppp->dev,\n\t\t\t\t\t\t      \"discarding frag %u\\n\",\n\t\t\t\t\t\t      PPP_MP_CB(p)->sequence);\n\t\t\t\t__skb_unlink(p, list);\n\t\t\t\tkfree_skb(p);\n\t\t\t}\n\n\t\t\tif (ppp->debug & 1)\n\t\t\t\tnetdev_printk(KERN_DEBUG, ppp->dev,\n\t\t\t\t\t      \"  missed pkts %u..%u\\n\",\n\t\t\t\t\t      ppp->nextseq,\n\t\t\t\t\t      PPP_MP_CB(head)->sequence-1);\n\t\t\t++ppp->dev->stats.rx_dropped;\n\t\t\tppp_receive_error(ppp);\n\t\t}\n\n\t\tskb = head;\n\t\tif (head != tail) {\n\t\t\tstruct sk_buff **fragpp = &skb_shinfo(skb)->frag_list;\n\t\t\tp = skb_queue_next(list, head);\n\t\t\t__skb_unlink(skb, list);\n\t\t\tskb_queue_walk_from_safe(list, p, tmp) {\n\t\t\t\t__skb_unlink(p, list);\n\t\t\t\t*fragpp = p;\n\t\t\t\tp->next = NULL;\n\t\t\t\tfragpp = &p->next;\n\n\t\t\t\tskb->len += p->len;\n\t\t\t\tskb->data_len += p->len;\n\t\t\t\tskb->truesize += p->truesize;\n\n\t\t\t\tif (p == tail)\n\t\t\t\t\tbreak;\n\t\t\t}\n\t\t} else {\n\t\t\t__skb_unlink(skb, list);\n\t\t}\n\n\t\tppp->nextseq = PPP_MP_CB(tail)->sequence + 1;\n\t}\n\n\treturn skb;\n}\n#endif /* CONFIG_PPP_MULTILINK */\n\n/*\n * Channel interface.\n */\n\n/* Create a new, unattached ppp channel. */\nint ppp_register_channel(struct ppp_channel *chan)\n{\n\treturn ppp_register_net_channel(current->nsproxy->net_ns, chan);\n}\n\n/* Create a new, unattached ppp channel for specified net. */\nint ppp_register_net_channel(struct net *net, struct ppp_channel *chan)\n{\n\tstruct channel *pch;\n\tstruct ppp_net *pn;\n\n\tpch = kzalloc(sizeof(struct channel), GFP_KERNEL);\n\tif (!pch)\n\t\treturn -ENOMEM;\n\n\tpn = ppp_pernet(net);\n\n\tpch->ppp = NULL;\n\tpch->chan = chan;\n\tpch->chan_net = net;\n\tchan->ppp = pch;\n\tinit_ppp_file(&pch->file, CHANNEL);\n\tpch->file.hdrlen = chan->hdrlen;\n#ifdef CONFIG_PPP_MULTILINK\n\tpch->lastseq = -1;\n#endif /* CONFIG_PPP_MULTILINK */\n\tinit_rwsem(&pch->chan_sem);\n\tspin_lock_init(&pch->downl);\n\trwlock_init(&pch->upl);\n\n\tspin_lock_bh(&pn->all_channels_lock);\n\tpch->file.index = ++pn->last_channel_index;\n\tlist_add(&pch->list, &pn->new_channels);\n\tatomic_inc(&channel_count);\n\tspin_unlock_bh(&pn->all_channels_lock);\n\n\treturn 0;\n}\n\n/*\n * Return the index of a channel.\n */\nint ppp_channel_index(struct ppp_channel *chan)\n{\n\tstruct channel *pch = chan->ppp;\n\n\tif (pch)\n\t\treturn pch->file.index;\n\treturn -1;\n}\n\n/*\n * Return the PPP unit number to which a channel is connected.\n */\nint ppp_unit_number(struct ppp_channel *chan)\n{\n\tstruct channel *pch = chan->ppp;\n\tint unit = -1;\n\n\tif (pch) {\n\t\tread_lock_bh(&pch->upl);\n\t\tif (pch->ppp)\n\t\t\tunit = pch->ppp->file.index;\n\t\tread_unlock_bh(&pch->upl);\n\t}\n\treturn unit;\n}\n\n/*\n * Return the PPP device interface name of a channel.\n */\nchar *ppp_dev_name(struct ppp_channel *chan)\n{\n\tstruct channel *pch = chan->ppp;\n\tchar *name = NULL;\n\n\tif (pch) {\n\t\tread_lock_bh(&pch->upl);\n\t\tif (pch->ppp && pch->ppp->dev)\n\t\t\tname = pch->ppp->dev->name;\n\t\tread_unlock_bh(&pch->upl);\n\t}\n\treturn name;\n}\n\n\n/*\n * Disconnect a channel from the generic layer.\n * This must be called in process context.\n */\nvoid\nppp_unregister_channel(struct ppp_channel *chan)\n{\n\tstruct channel *pch = chan->ppp;\n\tstruct ppp_net *pn;\n\n\tif (!pch)\n\t\treturn;\t\t/* should never happen */\n\n\tchan->ppp = NULL;\n\n\t/*\n\t * This ensures that we have returned from any calls into the\n\t * the channel's start_xmit or ioctl routine before we proceed.\n\t */\n\tdown_write(&pch->chan_sem);\n\tspin_lock_bh(&pch->downl);\n\tpch->chan = NULL;\n\tspin_unlock_bh(&pch->downl);\n\tup_write(&pch->chan_sem);\n\tppp_disconnect_channel(pch);\n\n\tpn = ppp_pernet(pch->chan_net);\n\tspin_lock_bh(&pn->all_channels_lock);\n\tlist_del(&pch->list);\n\tspin_unlock_bh(&pn->all_channels_lock);\n\n\tpch->file.dead = 1;\n\twake_up_interruptible(&pch->file.rwait);\n\tif (atomic_dec_and_test(&pch->file.refcnt))\n\t\tppp_destroy_channel(pch);\n}\n\n/*\n * Callback from a channel when it can accept more to transmit.\n * This should be called at BH/softirq level, not interrupt level.\n */\nvoid\nppp_output_wakeup(struct ppp_channel *chan)\n{\n\tstruct channel *pch = chan->ppp;\n\n\tif (!pch)\n\t\treturn;\n\tppp_channel_push(pch);\n}\n\n/*\n * Compression control.\n */\n\n/* Process the PPPIOCSCOMPRESS ioctl. */\nstatic int\nppp_set_compress(struct ppp *ppp, unsigned long arg)\n{\n\tint err;\n\tstruct compressor *cp, *ocomp;\n\tstruct ppp_option_data data;\n\tvoid *state, *ostate;\n\tunsigned char ccp_option[CCP_MAX_OPTION_LENGTH];\n\n\terr = -EFAULT;\n\tif (copy_from_user(&data, (void __user *) arg, sizeof(data)))\n\t\tgoto out;\n\tif (data.length > CCP_MAX_OPTION_LENGTH)\n\t\tgoto out;\n\tif (copy_from_user(ccp_option, (void __user *) data.ptr, data.length))\n\t\tgoto out;\n\n\terr = -EINVAL;\n\tif (data.length < 2 || ccp_option[1] < 2 || ccp_option[1] > data.length)\n\t\tgoto out;\n\n\tcp = try_then_request_module(\n\t\tfind_compressor(ccp_option[0]),\n\t\t\"ppp-compress-%d\", ccp_option[0]);\n\tif (!cp)\n\t\tgoto out;\n\n\terr = -ENOBUFS;\n\tif (data.transmit) {\n\t\tstate = cp->comp_alloc(ccp_option, data.length);\n\t\tif (state) {\n\t\t\tppp_xmit_lock(ppp);\n\t\t\tppp->xstate &= ~SC_COMP_RUN;\n\t\t\tocomp = ppp->xcomp;\n\t\t\tostate = ppp->xc_state;\n\t\t\tppp->xcomp = cp;\n\t\t\tppp->xc_state = state;\n\t\t\tppp_xmit_unlock(ppp);\n\t\t\tif (ostate) {\n\t\t\t\tocomp->comp_free(ostate);\n\t\t\t\tmodule_put(ocomp->owner);\n\t\t\t}\n\t\t\terr = 0;\n\t\t} else\n\t\t\tmodule_put(cp->owner);\n\n\t} else {\n\t\tstate = cp->decomp_alloc(ccp_option, data.length);\n\t\tif (state) {\n\t\t\tppp_recv_lock(ppp);\n\t\t\tppp->rstate &= ~SC_DECOMP_RUN;\n\t\t\tocomp = ppp->rcomp;\n\t\t\tostate = ppp->rc_state;\n\t\t\tppp->rcomp = cp;\n\t\t\tppp->rc_state = state;\n\t\t\tppp_recv_unlock(ppp);\n\t\t\tif (ostate) {\n\t\t\t\tocomp->decomp_free(ostate);\n\t\t\t\tmodule_put(ocomp->owner);\n\t\t\t}\n\t\t\terr = 0;\n\t\t} else\n\t\t\tmodule_put(cp->owner);\n\t}\n\n out:\n\treturn err;\n}\n\n/*\n * Look at a CCP packet and update our state accordingly.\n * We assume the caller has the xmit or recv path locked.\n */\nstatic void\nppp_ccp_peek(struct ppp *ppp, struct sk_buff *skb, int inbound)\n{\n\tunsigned char *dp;\n\tint len;\n\n\tif (!pskb_may_pull(skb, CCP_HDRLEN + 2))\n\t\treturn;\t/* no header */\n\tdp = skb->data + 2;\n\n\tswitch (CCP_CODE(dp)) {\n\tcase CCP_CONFREQ:\n\n\t\t/* A ConfReq starts negotiation of compression\n\t\t * in one direction of transmission,\n\t\t * and hence brings it down...but which way?\n\t\t *\n\t\t * Remember:\n\t\t * A ConfReq indicates what the sender would like to receive\n\t\t */\n\t\tif(inbound)\n\t\t\t/* He is proposing what I should send */\n\t\t\tppp->xstate &= ~SC_COMP_RUN;\n\t\telse\n\t\t\t/* I am proposing to what he should send */\n\t\t\tppp->rstate &= ~SC_DECOMP_RUN;\n\n\t\tbreak;\n\n\tcase CCP_TERMREQ:\n\tcase CCP_TERMACK:\n\t\t/*\n\t\t * CCP is going down, both directions of transmission\n\t\t */\n\t\tppp->rstate &= ~SC_DECOMP_RUN;\n\t\tppp->xstate &= ~SC_COMP_RUN;\n\t\tbreak;\n\n\tcase CCP_CONFACK:\n\t\tif ((ppp->flags & (SC_CCP_OPEN | SC_CCP_UP)) != SC_CCP_OPEN)\n\t\t\tbreak;\n\t\tlen = CCP_LENGTH(dp);\n\t\tif (!pskb_may_pull(skb, len + 2))\n\t\t\treturn;\t\t/* too short */\n\t\tdp += CCP_HDRLEN;\n\t\tlen -= CCP_HDRLEN;\n\t\tif (len < CCP_OPT_MINLEN || len < CCP_OPT_LENGTH(dp))\n\t\t\tbreak;\n\t\tif (inbound) {\n\t\t\t/* we will start receiving compressed packets */\n\t\t\tif (!ppp->rc_state)\n\t\t\t\tbreak;\n\t\t\tif (ppp->rcomp->decomp_init(ppp->rc_state, dp, len,\n\t\t\t\t\tppp->file.index, 0, ppp->mru, ppp->debug)) {\n\t\t\t\tppp->rstate |= SC_DECOMP_RUN;\n\t\t\t\tppp->rstate &= ~(SC_DC_ERROR | SC_DC_FERROR);\n\t\t\t}\n\t\t} else {\n\t\t\t/* we will soon start sending compressed packets */\n\t\t\tif (!ppp->xc_state)\n\t\t\t\tbreak;\n\t\t\tif (ppp->xcomp->comp_init(ppp->xc_state, dp, len,\n\t\t\t\t\tppp->file.index, 0, ppp->debug))\n\t\t\t\tppp->xstate |= SC_COMP_RUN;\n\t\t}\n\t\tbreak;\n\n\tcase CCP_RESETACK:\n\t\t/* reset the [de]compressor */\n\t\tif ((ppp->flags & SC_CCP_UP) == 0)\n\t\t\tbreak;\n\t\tif (inbound) {\n\t\t\tif (ppp->rc_state && (ppp->rstate & SC_DECOMP_RUN)) {\n\t\t\t\tppp->rcomp->decomp_reset(ppp->rc_state);\n\t\t\t\tppp->rstate &= ~SC_DC_ERROR;\n\t\t\t}\n\t\t} else {\n\t\t\tif (ppp->xc_state && (ppp->xstate & SC_COMP_RUN))\n\t\t\t\tppp->xcomp->comp_reset(ppp->xc_state);\n\t\t}\n\t\tbreak;\n\t}\n}\n\n/* Free up compression resources. */\nstatic void\nppp_ccp_closed(struct ppp *ppp)\n{\n\tvoid *xstate, *rstate;\n\tstruct compressor *xcomp, *rcomp;\n\n\tppp_lock(ppp);\n\tppp->flags &= ~(SC_CCP_OPEN | SC_CCP_UP);\n\tppp->xstate = 0;\n\txcomp = ppp->xcomp;\n\txstate = ppp->xc_state;\n\tppp->xc_state = NULL;\n\tppp->rstate = 0;\n\trcomp = ppp->rcomp;\n\trstate = ppp->rc_state;\n\tppp->rc_state = NULL;\n\tppp_unlock(ppp);\n\n\tif (xstate) {\n\t\txcomp->comp_free(xstate);\n\t\tmodule_put(xcomp->owner);\n\t}\n\tif (rstate) {\n\t\trcomp->decomp_free(rstate);\n\t\tmodule_put(rcomp->owner);\n\t}\n}\n\n/* List of compressors. */\nstatic LIST_HEAD(compressor_list);\nstatic DEFINE_SPINLOCK(compressor_list_lock);\n\nstruct compressor_entry {\n\tstruct list_head list;\n\tstruct compressor *comp;\n};\n\nstatic struct compressor_entry *\nfind_comp_entry(int proto)\n{\n\tstruct compressor_entry *ce;\n\n\tlist_for_each_entry(ce, &compressor_list, list) {\n\t\tif (ce->comp->compress_proto == proto)\n\t\t\treturn ce;\n\t}\n\treturn NULL;\n}\n\n/* Register a compressor */\nint\nppp_register_compressor(struct compressor *cp)\n{\n\tstruct compressor_entry *ce;\n\tint ret;\n\tspin_lock(&compressor_list_lock);\n\tret = -EEXIST;\n\tif (find_comp_entry(cp->compress_proto))\n\t\tgoto out;\n\tret = -ENOMEM;\n\tce = kmalloc(sizeof(struct compressor_entry), GFP_ATOMIC);\n\tif (!ce)\n\t\tgoto out;\n\tret = 0;\n\tce->comp = cp;\n\tlist_add(&ce->list, &compressor_list);\n out:\n\tspin_unlock(&compressor_list_lock);\n\treturn ret;\n}\n\n/* Unregister a compressor */\nvoid\nppp_unregister_compressor(struct compressor *cp)\n{\n\tstruct compressor_entry *ce;\n\n\tspin_lock(&compressor_list_lock);\n\tce = find_comp_entry(cp->compress_proto);\n\tif (ce && ce->comp == cp) {\n\t\tlist_del(&ce->list);\n\t\tkfree(ce);\n\t}\n\tspin_unlock(&compressor_list_lock);\n}\n\n/* Find a compressor. */\nstatic struct compressor *\nfind_compressor(int type)\n{\n\tstruct compressor_entry *ce;\n\tstruct compressor *cp = NULL;\n\n\tspin_lock(&compressor_list_lock);\n\tce = find_comp_entry(type);\n\tif (ce) {\n\t\tcp = ce->comp;\n\t\tif (!try_module_get(cp->owner))\n\t\t\tcp = NULL;\n\t}\n\tspin_unlock(&compressor_list_lock);\n\treturn cp;\n}\n\n/*\n * Miscelleneous stuff.\n */\n\nstatic void\nppp_get_stats(struct ppp *ppp, struct ppp_stats *st)\n{\n\tstruct slcompress *vj = ppp->vj;\n\n\tmemset(st, 0, sizeof(*st));\n\tst->p.ppp_ipackets = ppp->stats64.rx_packets;\n\tst->p.ppp_ierrors = ppp->dev->stats.rx_errors;\n\tst->p.ppp_ibytes = ppp->stats64.rx_bytes;\n\tst->p.ppp_opackets = ppp->stats64.tx_packets;\n\tst->p.ppp_oerrors = ppp->dev->stats.tx_errors;\n\tst->p.ppp_obytes = ppp->stats64.tx_bytes;\n\tif (!vj)\n\t\treturn;\n\tst->vj.vjs_packets = vj->sls_o_compressed + vj->sls_o_uncompressed;\n\tst->vj.vjs_compressed = vj->sls_o_compressed;\n\tst->vj.vjs_searches = vj->sls_o_searches;\n\tst->vj.vjs_misses = vj->sls_o_misses;\n\tst->vj.vjs_errorin = vj->sls_i_error;\n\tst->vj.vjs_tossed = vj->sls_i_tossed;\n\tst->vj.vjs_uncompressedin = vj->sls_i_uncompressed;\n\tst->vj.vjs_compressedin = vj->sls_i_compressed;\n}\n\n/*\n * Stuff for handling the lists of ppp units and channels\n * and for initialization.\n */\n\n/*\n * Create a new ppp interface unit.  Fails if it can't allocate memory\n * or if there is already a unit with the requested number.\n * unit == -1 means allocate a new number.\n */\nstatic struct ppp *ppp_create_interface(struct net *net, int unit,\n\t\t\t\t\tstruct file *file, int *retp)\n{\n\tstruct ppp *ppp;\n\tstruct ppp_net *pn;\n\tstruct net_device *dev = NULL;\n\tint ret = -ENOMEM;\n\tint i;\n\n\tdev = alloc_netdev(sizeof(struct ppp), \"\", NET_NAME_ENUM, ppp_setup);\n\tif (!dev)\n\t\tgoto out1;\n\n\tpn = ppp_pernet(net);\n\n\tppp = netdev_priv(dev);\n\tppp->dev = dev;\n\tppp->mru = PPP_MRU;\n\tinit_ppp_file(&ppp->file, INTERFACE);\n\tppp->file.hdrlen = PPP_HDRLEN - 2;\t/* don't count proto bytes */\n\tppp->owner = file;\n\tfor (i = 0; i < NUM_NP; ++i)\n\t\tppp->npmode[i] = NPMODE_PASS;\n\tINIT_LIST_HEAD(&ppp->channels);\n\tspin_lock_init(&ppp->rlock);\n\tspin_lock_init(&ppp->wlock);\n#ifdef CONFIG_PPP_MULTILINK\n\tppp->minseq = -1;\n\tskb_queue_head_init(&ppp->mrq);\n#endif /* CONFIG_PPP_MULTILINK */\n#ifdef CONFIG_PPP_FILTER\n\tppp->pass_filter = NULL;\n\tppp->active_filter = NULL;\n#endif /* CONFIG_PPP_FILTER */\n\n\t/*\n\t * drum roll: don't forget to set\n\t * the net device is belong to\n\t */\n\tdev_net_set(dev, net);\n\n\trtnl_lock();\n\tmutex_lock(&pn->all_ppp_mutex);\n\n\tif (unit < 0) {\n\t\tunit = unit_get(&pn->units_idr, ppp);\n\t\tif (unit < 0) {\n\t\t\tret = unit;\n\t\t\tgoto out2;\n\t\t}\n\t} else {\n\t\tret = -EEXIST;\n\t\tif (unit_find(&pn->units_idr, unit))\n\t\t\tgoto out2; /* unit already exists */\n\t\t/*\n\t\t * if caller need a specified unit number\n\t\t * lets try to satisfy him, otherwise --\n\t\t * he should better ask us for new unit number\n\t\t *\n\t\t * NOTE: yes I know that returning EEXIST it's not\n\t\t * fair but at least pppd will ask us to allocate\n\t\t * new unit in this case so user is happy :)\n\t\t */\n\t\tunit = unit_set(&pn->units_idr, ppp, unit);\n\t\tif (unit < 0)\n\t\t\tgoto out2;\n\t}\n\n\t/* Initialize the new ppp unit */\n\tppp->file.index = unit;\n\tsprintf(dev->name, \"ppp%d\", unit);\n\n\tret = register_netdevice(dev);\n\tif (ret != 0) {\n\t\tunit_put(&pn->units_idr, unit);\n\t\tnetdev_err(ppp->dev, \"PPP: couldn't register device %s (%d)\\n\",\n\t\t\t   dev->name, ret);\n\t\tgoto out2;\n\t}\n\n\tppp->ppp_net = net;\n\n\tatomic_inc(&ppp_unit_count);\n\tmutex_unlock(&pn->all_ppp_mutex);\n\trtnl_unlock();\n\n\t*retp = 0;\n\treturn ppp;\n\nout2:\n\tmutex_unlock(&pn->all_ppp_mutex);\n\trtnl_unlock();\n\tfree_netdev(dev);\nout1:\n\t*retp = ret;\n\treturn NULL;\n}\n\n/*\n * Initialize a ppp_file structure.\n */\nstatic void\ninit_ppp_file(struct ppp_file *pf, int kind)\n{\n\tpf->kind = kind;\n\tskb_queue_head_init(&pf->xq);\n\tskb_queue_head_init(&pf->rq);\n\tatomic_set(&pf->refcnt, 1);\n\tinit_waitqueue_head(&pf->rwait);\n}\n\n/*\n * Free the memory used by a ppp unit.  This is only called once\n * there are no channels connected to the unit and no file structs\n * that reference the unit.\n */\nstatic void ppp_destroy_interface(struct ppp *ppp)\n{\n\tatomic_dec(&ppp_unit_count);\n\n\tif (!ppp->file.dead || ppp->n_channels) {\n\t\t/* \"can't happen\" */\n\t\tnetdev_err(ppp->dev, \"ppp: destroying ppp struct %p \"\n\t\t\t   \"but dead=%d n_channels=%d !\\n\",\n\t\t\t   ppp, ppp->file.dead, ppp->n_channels);\n\t\treturn;\n\t}\n\n\tppp_ccp_closed(ppp);\n\tif (ppp->vj) {\n\t\tslhc_free(ppp->vj);\n\t\tppp->vj = NULL;\n\t}\n\tskb_queue_purge(&ppp->file.xq);\n\tskb_queue_purge(&ppp->file.rq);\n#ifdef CONFIG_PPP_MULTILINK\n\tskb_queue_purge(&ppp->mrq);\n#endif /* CONFIG_PPP_MULTILINK */\n#ifdef CONFIG_PPP_FILTER\n\tif (ppp->pass_filter) {\n\t\tbpf_prog_destroy(ppp->pass_filter);\n\t\tppp->pass_filter = NULL;\n\t}\n\n\tif (ppp->active_filter) {\n\t\tbpf_prog_destroy(ppp->active_filter);\n\t\tppp->active_filter = NULL;\n\t}\n#endif /* CONFIG_PPP_FILTER */\n\n\tkfree_skb(ppp->xmit_pending);\n\n\tfree_netdev(ppp->dev);\n}\n\n/*\n * Locate an existing ppp unit.\n * The caller should have locked the all_ppp_mutex.\n */\nstatic struct ppp *\nppp_find_unit(struct ppp_net *pn, int unit)\n{\n\treturn unit_find(&pn->units_idr, unit);\n}\n\n/*\n * Locate an existing ppp channel.\n * The caller should have locked the all_channels_lock.\n * First we look in the new_channels list, then in the\n * all_channels list.  If found in the new_channels list,\n * we move it to the all_channels list.  This is for speed\n * when we have a lot of channels in use.\n */\nstatic struct channel *\nppp_find_channel(struct ppp_net *pn, int unit)\n{\n\tstruct channel *pch;\n\n\tlist_for_each_entry(pch, &pn->new_channels, list) {\n\t\tif (pch->file.index == unit) {\n\t\t\tlist_move(&pch->list, &pn->all_channels);\n\t\t\treturn pch;\n\t\t}\n\t}\n\n\tlist_for_each_entry(pch, &pn->all_channels, list) {\n\t\tif (pch->file.index == unit)\n\t\t\treturn pch;\n\t}\n\n\treturn NULL;\n}\n\n/*\n * Connect a PPP channel to a PPP interface unit.\n */\nstatic int\nppp_connect_channel(struct channel *pch, int unit)\n{\n\tstruct ppp *ppp;\n\tstruct ppp_net *pn;\n\tint ret = -ENXIO;\n\tint hdrlen;\n\n\tpn = ppp_pernet(pch->chan_net);\n\n\tmutex_lock(&pn->all_ppp_mutex);\n\tppp = ppp_find_unit(pn, unit);\n\tif (!ppp)\n\t\tgoto out;\n\twrite_lock_bh(&pch->upl);\n\tret = -EINVAL;\n\tif (pch->ppp)\n\t\tgoto outl;\n\n\tppp_lock(ppp);\n\tif (pch->file.hdrlen > ppp->file.hdrlen)\n\t\tppp->file.hdrlen = pch->file.hdrlen;\n\thdrlen = pch->file.hdrlen + 2;\t/* for protocol bytes */\n\tif (hdrlen > ppp->dev->hard_header_len)\n\t\tppp->dev->hard_header_len = hdrlen;\n\tlist_add_tail(&pch->clist, &ppp->channels);\n\t++ppp->n_channels;\n\tpch->ppp = ppp;\n\tatomic_inc(&ppp->file.refcnt);\n\tppp_unlock(ppp);\n\tret = 0;\n\n outl:\n\twrite_unlock_bh(&pch->upl);\n out:\n\tmutex_unlock(&pn->all_ppp_mutex);\n\treturn ret;\n}\n\n/*\n * Disconnect a channel from its ppp unit.\n */\nstatic int\nppp_disconnect_channel(struct channel *pch)\n{\n\tstruct ppp *ppp;\n\tint err = -EINVAL;\n\n\twrite_lock_bh(&pch->upl);\n\tppp = pch->ppp;\n\tpch->ppp = NULL;\n\twrite_unlock_bh(&pch->upl);\n\tif (ppp) {\n\t\t/* remove it from the ppp unit's list */\n\t\tppp_lock(ppp);\n\t\tlist_del(&pch->clist);\n\t\tif (--ppp->n_channels == 0)\n\t\t\twake_up_interruptible(&ppp->file.rwait);\n\t\tppp_unlock(ppp);\n\t\tif (atomic_dec_and_test(&ppp->file.refcnt))\n\t\t\tppp_destroy_interface(ppp);\n\t\terr = 0;\n\t}\n\treturn err;\n}\n\n/*\n * Free up the resources used by a ppp channel.\n */\nstatic void ppp_destroy_channel(struct channel *pch)\n{\n\tatomic_dec(&channel_count);\n\n\tif (!pch->file.dead) {\n\t\t/* \"can't happen\" */\n\t\tpr_err(\"ppp: destroying undead channel %p !\\n\", pch);\n\t\treturn;\n\t}\n\tskb_queue_purge(&pch->file.xq);\n\tskb_queue_purge(&pch->file.rq);\n\tkfree(pch);\n}\n\nstatic void __exit ppp_cleanup(void)\n{\n\t/* should never happen */\n\tif (atomic_read(&ppp_unit_count) || atomic_read(&channel_count))\n\t\tpr_err(\"PPP: removing module but units remain!\\n\");\n\tunregister_chrdev(PPP_MAJOR, \"ppp\");\n\tdevice_destroy(ppp_class, MKDEV(PPP_MAJOR, 0));\n\tclass_destroy(ppp_class);\n\tunregister_pernet_device(&ppp_net_ops);\n}\n\n/*\n * Units handling. Caller must protect concurrent access\n * by holding all_ppp_mutex\n */\n\n/* associate pointer with specified number */\nstatic int unit_set(struct idr *p, void *ptr, int n)\n{\n\tint unit;\n\n\tunit = idr_alloc(p, ptr, n, n + 1, GFP_KERNEL);\n\tif (unit == -ENOSPC)\n\t\tunit = -EINVAL;\n\treturn unit;\n}\n\n/* get new free unit number and associate pointer with it */\nstatic int unit_get(struct idr *p, void *ptr)\n{\n\treturn idr_alloc(p, ptr, 0, 0, GFP_KERNEL);\n}\n\n/* put unit number back to a pool */\nstatic void unit_put(struct idr *p, int n)\n{\n\tidr_remove(p, n);\n}\n\n/* get pointer associated with the number */\nstatic void *unit_find(struct idr *p, int n)\n{\n\treturn idr_find(p, n);\n}\n\n/* Module/initialization stuff */\n\nmodule_init(ppp_init);\nmodule_exit(ppp_cleanup);\n\nEXPORT_SYMBOL(ppp_register_net_channel);\nEXPORT_SYMBOL(ppp_register_channel);\nEXPORT_SYMBOL(ppp_unregister_channel);\nEXPORT_SYMBOL(ppp_channel_index);\nEXPORT_SYMBOL(ppp_unit_number);\nEXPORT_SYMBOL(ppp_dev_name);\nEXPORT_SYMBOL(ppp_input);\nEXPORT_SYMBOL(ppp_input_error);\nEXPORT_SYMBOL(ppp_output_wakeup);\nEXPORT_SYMBOL(ppp_register_compressor);\nEXPORT_SYMBOL(ppp_unregister_compressor);\nMODULE_LICENSE(\"GPL\");\nMODULE_ALIAS_CHARDEV(PPP_MAJOR, 0);\nMODULE_ALIAS(\"devname:ppp\");\n"], "fixing_code": ["/*\n * Generic PPP layer for Linux.\n *\n * Copyright 1999-2002 Paul Mackerras.\n *\n *  This program is free software; you can redistribute it and/or\n *  modify it under the terms of the GNU General Public License\n *  as published by the Free Software Foundation; either version\n *  2 of the License, or (at your option) any later version.\n *\n * The generic PPP layer handles the PPP network interfaces, the\n * /dev/ppp device, packet and VJ compression, and multilink.\n * It talks to PPP `channels' via the interface defined in\n * include/linux/ppp_channel.h.  Channels provide the basic means for\n * sending and receiving PPP frames on some kind of communications\n * channel.\n *\n * Part of the code in this driver was inspired by the old async-only\n * PPP driver, written by Michael Callahan and Al Longyear, and\n * subsequently hacked by Paul Mackerras.\n *\n * ==FILEVERSION 20041108==\n */\n\n#include <linux/module.h>\n#include <linux/kernel.h>\n#include <linux/kmod.h>\n#include <linux/init.h>\n#include <linux/list.h>\n#include <linux/idr.h>\n#include <linux/netdevice.h>\n#include <linux/poll.h>\n#include <linux/ppp_defs.h>\n#include <linux/filter.h>\n#include <linux/ppp-ioctl.h>\n#include <linux/ppp_channel.h>\n#include <linux/ppp-comp.h>\n#include <linux/skbuff.h>\n#include <linux/rtnetlink.h>\n#include <linux/if_arp.h>\n#include <linux/ip.h>\n#include <linux/tcp.h>\n#include <linux/spinlock.h>\n#include <linux/rwsem.h>\n#include <linux/stddef.h>\n#include <linux/device.h>\n#include <linux/mutex.h>\n#include <linux/slab.h>\n#include <asm/unaligned.h>\n#include <net/slhc_vj.h>\n#include <linux/atomic.h>\n\n#include <linux/nsproxy.h>\n#include <net/net_namespace.h>\n#include <net/netns/generic.h>\n\n#define PPP_VERSION\t\"2.4.2\"\n\n/*\n * Network protocols we support.\n */\n#define NP_IP\t0\t\t/* Internet Protocol V4 */\n#define NP_IPV6\t1\t\t/* Internet Protocol V6 */\n#define NP_IPX\t2\t\t/* IPX protocol */\n#define NP_AT\t3\t\t/* Appletalk protocol */\n#define NP_MPLS_UC 4\t\t/* MPLS unicast */\n#define NP_MPLS_MC 5\t\t/* MPLS multicast */\n#define NUM_NP\t6\t\t/* Number of NPs. */\n\n#define MPHDRLEN\t6\t/* multilink protocol header length */\n#define MPHDRLEN_SSN\t4\t/* ditto with short sequence numbers */\n\n/*\n * An instance of /dev/ppp can be associated with either a ppp\n * interface unit or a ppp channel.  In both cases, file->private_data\n * points to one of these.\n */\nstruct ppp_file {\n\tenum {\n\t\tINTERFACE=1, CHANNEL\n\t}\t\tkind;\n\tstruct sk_buff_head xq;\t\t/* pppd transmit queue */\n\tstruct sk_buff_head rq;\t\t/* receive queue for pppd */\n\twait_queue_head_t rwait;\t/* for poll on reading /dev/ppp */\n\tatomic_t\trefcnt;\t\t/* # refs (incl /dev/ppp attached) */\n\tint\t\thdrlen;\t\t/* space to leave for headers */\n\tint\t\tindex;\t\t/* interface unit / channel number */\n\tint\t\tdead;\t\t/* unit/channel has been shut down */\n};\n\n#define PF_TO_X(pf, X)\t\tcontainer_of(pf, X, file)\n\n#define PF_TO_PPP(pf)\t\tPF_TO_X(pf, struct ppp)\n#define PF_TO_CHANNEL(pf)\tPF_TO_X(pf, struct channel)\n\n/*\n * Data structure to hold primary network stats for which\n * we want to use 64 bit storage.  Other network stats\n * are stored in dev->stats of the ppp strucute.\n */\nstruct ppp_link_stats {\n\tu64 rx_packets;\n\tu64 tx_packets;\n\tu64 rx_bytes;\n\tu64 tx_bytes;\n};\n\n/*\n * Data structure describing one ppp unit.\n * A ppp unit corresponds to a ppp network interface device\n * and represents a multilink bundle.\n * It can have 0 or more ppp channels connected to it.\n */\nstruct ppp {\n\tstruct ppp_file\tfile;\t\t/* stuff for read/write/poll 0 */\n\tstruct file\t*owner;\t\t/* file that owns this unit 48 */\n\tstruct list_head channels;\t/* list of attached channels 4c */\n\tint\t\tn_channels;\t/* how many channels are attached 54 */\n\tspinlock_t\trlock;\t\t/* lock for receive side 58 */\n\tspinlock_t\twlock;\t\t/* lock for transmit side 5c */\n\tint\t\tmru;\t\t/* max receive unit 60 */\n\tunsigned int\tflags;\t\t/* control bits 64 */\n\tunsigned int\txstate;\t\t/* transmit state bits 68 */\n\tunsigned int\trstate;\t\t/* receive state bits 6c */\n\tint\t\tdebug;\t\t/* debug flags 70 */\n\tstruct slcompress *vj;\t\t/* state for VJ header compression */\n\tenum NPmode\tnpmode[NUM_NP];\t/* what to do with each net proto 78 */\n\tstruct sk_buff\t*xmit_pending;\t/* a packet ready to go out 88 */\n\tstruct compressor *xcomp;\t/* transmit packet compressor 8c */\n\tvoid\t\t*xc_state;\t/* its internal state 90 */\n\tstruct compressor *rcomp;\t/* receive decompressor 94 */\n\tvoid\t\t*rc_state;\t/* its internal state 98 */\n\tunsigned long\tlast_xmit;\t/* jiffies when last pkt sent 9c */\n\tunsigned long\tlast_recv;\t/* jiffies when last pkt rcvd a0 */\n\tstruct net_device *dev;\t\t/* network interface device a4 */\n\tint\t\tclosing;\t/* is device closing down? a8 */\n#ifdef CONFIG_PPP_MULTILINK\n\tint\t\tnxchan;\t\t/* next channel to send something on */\n\tu32\t\tnxseq;\t\t/* next sequence number to send */\n\tint\t\tmrru;\t\t/* MP: max reconst. receive unit */\n\tu32\t\tnextseq;\t/* MP: seq no of next packet */\n\tu32\t\tminseq;\t\t/* MP: min of most recent seqnos */\n\tstruct sk_buff_head mrq;\t/* MP: receive reconstruction queue */\n#endif /* CONFIG_PPP_MULTILINK */\n#ifdef CONFIG_PPP_FILTER\n\tstruct bpf_prog *pass_filter;\t/* filter for packets to pass */\n\tstruct bpf_prog *active_filter; /* filter for pkts to reset idle */\n#endif /* CONFIG_PPP_FILTER */\n\tstruct net\t*ppp_net;\t/* the net we belong to */\n\tstruct ppp_link_stats stats64;\t/* 64 bit network stats */\n};\n\n/*\n * Bits in flags: SC_NO_TCP_CCID, SC_CCP_OPEN, SC_CCP_UP, SC_LOOP_TRAFFIC,\n * SC_MULTILINK, SC_MP_SHORTSEQ, SC_MP_XSHORTSEQ, SC_COMP_TCP, SC_REJ_COMP_TCP,\n * SC_MUST_COMP\n * Bits in rstate: SC_DECOMP_RUN, SC_DC_ERROR, SC_DC_FERROR.\n * Bits in xstate: SC_COMP_RUN\n */\n#define SC_FLAG_BITS\t(SC_NO_TCP_CCID|SC_CCP_OPEN|SC_CCP_UP|SC_LOOP_TRAFFIC \\\n\t\t\t |SC_MULTILINK|SC_MP_SHORTSEQ|SC_MP_XSHORTSEQ \\\n\t\t\t |SC_COMP_TCP|SC_REJ_COMP_TCP|SC_MUST_COMP)\n\n/*\n * Private data structure for each channel.\n * This includes the data structure used for multilink.\n */\nstruct channel {\n\tstruct ppp_file\tfile;\t\t/* stuff for read/write/poll */\n\tstruct list_head list;\t\t/* link in all/new_channels list */\n\tstruct ppp_channel *chan;\t/* public channel data structure */\n\tstruct rw_semaphore chan_sem;\t/* protects `chan' during chan ioctl */\n\tspinlock_t\tdownl;\t\t/* protects `chan', file.xq dequeue */\n\tstruct ppp\t*ppp;\t\t/* ppp unit we're connected to */\n\tstruct net\t*chan_net;\t/* the net channel belongs to */\n\tstruct list_head clist;\t\t/* link in list of channels per unit */\n\trwlock_t\tupl;\t\t/* protects `ppp' */\n#ifdef CONFIG_PPP_MULTILINK\n\tu8\t\tavail;\t\t/* flag used in multilink stuff */\n\tu8\t\thad_frag;\t/* >= 1 fragments have been sent */\n\tu32\t\tlastseq;\t/* MP: last sequence # received */\n\tint\t\tspeed;\t\t/* speed of the corresponding ppp channel*/\n#endif /* CONFIG_PPP_MULTILINK */\n};\n\n/*\n * SMP locking issues:\n * Both the ppp.rlock and ppp.wlock locks protect the ppp.channels\n * list and the ppp.n_channels field, you need to take both locks\n * before you modify them.\n * The lock ordering is: channel.upl -> ppp.wlock -> ppp.rlock ->\n * channel.downl.\n */\n\nstatic DEFINE_MUTEX(ppp_mutex);\nstatic atomic_t ppp_unit_count = ATOMIC_INIT(0);\nstatic atomic_t channel_count = ATOMIC_INIT(0);\n\n/* per-net private data for this module */\nstatic int ppp_net_id __read_mostly;\nstruct ppp_net {\n\t/* units to ppp mapping */\n\tstruct idr units_idr;\n\n\t/*\n\t * all_ppp_mutex protects the units_idr mapping.\n\t * It also ensures that finding a ppp unit in the units_idr\n\t * map and updating its file.refcnt field is atomic.\n\t */\n\tstruct mutex all_ppp_mutex;\n\n\t/* channels */\n\tstruct list_head all_channels;\n\tstruct list_head new_channels;\n\tint last_channel_index;\n\n\t/*\n\t * all_channels_lock protects all_channels and\n\t * last_channel_index, and the atomicity of find\n\t * a channel and updating its file.refcnt field.\n\t */\n\tspinlock_t all_channels_lock;\n};\n\n/* Get the PPP protocol number from a skb */\n#define PPP_PROTO(skb)\tget_unaligned_be16((skb)->data)\n\n/* We limit the length of ppp->file.rq to this (arbitrary) value */\n#define PPP_MAX_RQLEN\t32\n\n/*\n * Maximum number of multilink fragments queued up.\n * This has to be large enough to cope with the maximum latency of\n * the slowest channel relative to the others.  Strictly it should\n * depend on the number of channels and their characteristics.\n */\n#define PPP_MP_MAX_QLEN\t128\n\n/* Multilink header bits. */\n#define B\t0x80\t\t/* this fragment begins a packet */\n#define E\t0x40\t\t/* this fragment ends a packet */\n\n/* Compare multilink sequence numbers (assumed to be 32 bits wide) */\n#define seq_before(a, b)\t((s32)((a) - (b)) < 0)\n#define seq_after(a, b)\t\t((s32)((a) - (b)) > 0)\n\n/* Prototypes. */\nstatic int ppp_unattached_ioctl(struct net *net, struct ppp_file *pf,\n\t\t\tstruct file *file, unsigned int cmd, unsigned long arg);\nstatic void ppp_xmit_process(struct ppp *ppp);\nstatic void ppp_send_frame(struct ppp *ppp, struct sk_buff *skb);\nstatic void ppp_push(struct ppp *ppp);\nstatic void ppp_channel_push(struct channel *pch);\nstatic void ppp_receive_frame(struct ppp *ppp, struct sk_buff *skb,\n\t\t\t      struct channel *pch);\nstatic void ppp_receive_error(struct ppp *ppp);\nstatic void ppp_receive_nonmp_frame(struct ppp *ppp, struct sk_buff *skb);\nstatic struct sk_buff *ppp_decompress_frame(struct ppp *ppp,\n\t\t\t\t\t    struct sk_buff *skb);\n#ifdef CONFIG_PPP_MULTILINK\nstatic void ppp_receive_mp_frame(struct ppp *ppp, struct sk_buff *skb,\n\t\t\t\tstruct channel *pch);\nstatic void ppp_mp_insert(struct ppp *ppp, struct sk_buff *skb);\nstatic struct sk_buff *ppp_mp_reconstruct(struct ppp *ppp);\nstatic int ppp_mp_explode(struct ppp *ppp, struct sk_buff *skb);\n#endif /* CONFIG_PPP_MULTILINK */\nstatic int ppp_set_compress(struct ppp *ppp, unsigned long arg);\nstatic void ppp_ccp_peek(struct ppp *ppp, struct sk_buff *skb, int inbound);\nstatic void ppp_ccp_closed(struct ppp *ppp);\nstatic struct compressor *find_compressor(int type);\nstatic void ppp_get_stats(struct ppp *ppp, struct ppp_stats *st);\nstatic struct ppp *ppp_create_interface(struct net *net, int unit,\n\t\t\t\t\tstruct file *file, int *retp);\nstatic void init_ppp_file(struct ppp_file *pf, int kind);\nstatic void ppp_destroy_interface(struct ppp *ppp);\nstatic struct ppp *ppp_find_unit(struct ppp_net *pn, int unit);\nstatic struct channel *ppp_find_channel(struct ppp_net *pn, int unit);\nstatic int ppp_connect_channel(struct channel *pch, int unit);\nstatic int ppp_disconnect_channel(struct channel *pch);\nstatic void ppp_destroy_channel(struct channel *pch);\nstatic int unit_get(struct idr *p, void *ptr);\nstatic int unit_set(struct idr *p, void *ptr, int n);\nstatic void unit_put(struct idr *p, int n);\nstatic void *unit_find(struct idr *p, int n);\n\nstatic const struct net_device_ops ppp_netdev_ops;\n\nstatic struct class *ppp_class;\n\n/* per net-namespace data */\nstatic inline struct ppp_net *ppp_pernet(struct net *net)\n{\n\tBUG_ON(!net);\n\n\treturn net_generic(net, ppp_net_id);\n}\n\n/* Translates a PPP protocol number to a NP index (NP == network protocol) */\nstatic inline int proto_to_npindex(int proto)\n{\n\tswitch (proto) {\n\tcase PPP_IP:\n\t\treturn NP_IP;\n\tcase PPP_IPV6:\n\t\treturn NP_IPV6;\n\tcase PPP_IPX:\n\t\treturn NP_IPX;\n\tcase PPP_AT:\n\t\treturn NP_AT;\n\tcase PPP_MPLS_UC:\n\t\treturn NP_MPLS_UC;\n\tcase PPP_MPLS_MC:\n\t\treturn NP_MPLS_MC;\n\t}\n\treturn -EINVAL;\n}\n\n/* Translates an NP index into a PPP protocol number */\nstatic const int npindex_to_proto[NUM_NP] = {\n\tPPP_IP,\n\tPPP_IPV6,\n\tPPP_IPX,\n\tPPP_AT,\n\tPPP_MPLS_UC,\n\tPPP_MPLS_MC,\n};\n\n/* Translates an ethertype into an NP index */\nstatic inline int ethertype_to_npindex(int ethertype)\n{\n\tswitch (ethertype) {\n\tcase ETH_P_IP:\n\t\treturn NP_IP;\n\tcase ETH_P_IPV6:\n\t\treturn NP_IPV6;\n\tcase ETH_P_IPX:\n\t\treturn NP_IPX;\n\tcase ETH_P_PPPTALK:\n\tcase ETH_P_ATALK:\n\t\treturn NP_AT;\n\tcase ETH_P_MPLS_UC:\n\t\treturn NP_MPLS_UC;\n\tcase ETH_P_MPLS_MC:\n\t\treturn NP_MPLS_MC;\n\t}\n\treturn -1;\n}\n\n/* Translates an NP index into an ethertype */\nstatic const int npindex_to_ethertype[NUM_NP] = {\n\tETH_P_IP,\n\tETH_P_IPV6,\n\tETH_P_IPX,\n\tETH_P_PPPTALK,\n\tETH_P_MPLS_UC,\n\tETH_P_MPLS_MC,\n};\n\n/*\n * Locking shorthand.\n */\n#define ppp_xmit_lock(ppp)\tspin_lock_bh(&(ppp)->wlock)\n#define ppp_xmit_unlock(ppp)\tspin_unlock_bh(&(ppp)->wlock)\n#define ppp_recv_lock(ppp)\tspin_lock_bh(&(ppp)->rlock)\n#define ppp_recv_unlock(ppp)\tspin_unlock_bh(&(ppp)->rlock)\n#define ppp_lock(ppp)\t\tdo { ppp_xmit_lock(ppp); \\\n\t\t\t\t     ppp_recv_lock(ppp); } while (0)\n#define ppp_unlock(ppp)\t\tdo { ppp_recv_unlock(ppp); \\\n\t\t\t\t     ppp_xmit_unlock(ppp); } while (0)\n\n/*\n * /dev/ppp device routines.\n * The /dev/ppp device is used by pppd to control the ppp unit.\n * It supports the read, write, ioctl and poll functions.\n * Open instances of /dev/ppp can be in one of three states:\n * unattached, attached to a ppp unit, or attached to a ppp channel.\n */\nstatic int ppp_open(struct inode *inode, struct file *file)\n{\n\t/*\n\t * This could (should?) be enforced by the permissions on /dev/ppp.\n\t */\n\tif (!capable(CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\treturn 0;\n}\n\nstatic int ppp_release(struct inode *unused, struct file *file)\n{\n\tstruct ppp_file *pf = file->private_data;\n\tstruct ppp *ppp;\n\n\tif (pf) {\n\t\tfile->private_data = NULL;\n\t\tif (pf->kind == INTERFACE) {\n\t\t\tppp = PF_TO_PPP(pf);\n\t\t\trtnl_lock();\n\t\t\tif (file == ppp->owner)\n\t\t\t\tunregister_netdevice(ppp->dev);\n\t\t\trtnl_unlock();\n\t\t}\n\t\tif (atomic_dec_and_test(&pf->refcnt)) {\n\t\t\tswitch (pf->kind) {\n\t\t\tcase INTERFACE:\n\t\t\t\tppp_destroy_interface(PF_TO_PPP(pf));\n\t\t\t\tbreak;\n\t\t\tcase CHANNEL:\n\t\t\t\tppp_destroy_channel(PF_TO_CHANNEL(pf));\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\treturn 0;\n}\n\nstatic ssize_t ppp_read(struct file *file, char __user *buf,\n\t\t\tsize_t count, loff_t *ppos)\n{\n\tstruct ppp_file *pf = file->private_data;\n\tDECLARE_WAITQUEUE(wait, current);\n\tssize_t ret;\n\tstruct sk_buff *skb = NULL;\n\tstruct iovec iov;\n\tstruct iov_iter to;\n\n\tret = count;\n\n\tif (!pf)\n\t\treturn -ENXIO;\n\tadd_wait_queue(&pf->rwait, &wait);\n\tfor (;;) {\n\t\tset_current_state(TASK_INTERRUPTIBLE);\n\t\tskb = skb_dequeue(&pf->rq);\n\t\tif (skb)\n\t\t\tbreak;\n\t\tret = 0;\n\t\tif (pf->dead)\n\t\t\tbreak;\n\t\tif (pf->kind == INTERFACE) {\n\t\t\t/*\n\t\t\t * Return 0 (EOF) on an interface that has no\n\t\t\t * channels connected, unless it is looping\n\t\t\t * network traffic (demand mode).\n\t\t\t */\n\t\t\tstruct ppp *ppp = PF_TO_PPP(pf);\n\n\t\t\tppp_recv_lock(ppp);\n\t\t\tif (ppp->n_channels == 0 &&\n\t\t\t    (ppp->flags & SC_LOOP_TRAFFIC) == 0) {\n\t\t\t\tppp_recv_unlock(ppp);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tppp_recv_unlock(ppp);\n\t\t}\n\t\tret = -EAGAIN;\n\t\tif (file->f_flags & O_NONBLOCK)\n\t\t\tbreak;\n\t\tret = -ERESTARTSYS;\n\t\tif (signal_pending(current))\n\t\t\tbreak;\n\t\tschedule();\n\t}\n\tset_current_state(TASK_RUNNING);\n\tremove_wait_queue(&pf->rwait, &wait);\n\n\tif (!skb)\n\t\tgoto out;\n\n\tret = -EOVERFLOW;\n\tif (skb->len > count)\n\t\tgoto outf;\n\tret = -EFAULT;\n\tiov.iov_base = buf;\n\tiov.iov_len = count;\n\tiov_iter_init(&to, READ, &iov, 1, count);\n\tif (skb_copy_datagram_iter(skb, 0, &to, skb->len))\n\t\tgoto outf;\n\tret = skb->len;\n\n outf:\n\tkfree_skb(skb);\n out:\n\treturn ret;\n}\n\nstatic ssize_t ppp_write(struct file *file, const char __user *buf,\n\t\t\t size_t count, loff_t *ppos)\n{\n\tstruct ppp_file *pf = file->private_data;\n\tstruct sk_buff *skb;\n\tssize_t ret;\n\n\tif (!pf)\n\t\treturn -ENXIO;\n\tret = -ENOMEM;\n\tskb = alloc_skb(count + pf->hdrlen, GFP_KERNEL);\n\tif (!skb)\n\t\tgoto out;\n\tskb_reserve(skb, pf->hdrlen);\n\tret = -EFAULT;\n\tif (copy_from_user(skb_put(skb, count), buf, count)) {\n\t\tkfree_skb(skb);\n\t\tgoto out;\n\t}\n\n\tskb_queue_tail(&pf->xq, skb);\n\n\tswitch (pf->kind) {\n\tcase INTERFACE:\n\t\tppp_xmit_process(PF_TO_PPP(pf));\n\t\tbreak;\n\tcase CHANNEL:\n\t\tppp_channel_push(PF_TO_CHANNEL(pf));\n\t\tbreak;\n\t}\n\n\tret = count;\n\n out:\n\treturn ret;\n}\n\n/* No kernel lock - fine */\nstatic unsigned int ppp_poll(struct file *file, poll_table *wait)\n{\n\tstruct ppp_file *pf = file->private_data;\n\tunsigned int mask;\n\n\tif (!pf)\n\t\treturn 0;\n\tpoll_wait(file, &pf->rwait, wait);\n\tmask = POLLOUT | POLLWRNORM;\n\tif (skb_peek(&pf->rq))\n\t\tmask |= POLLIN | POLLRDNORM;\n\tif (pf->dead)\n\t\tmask |= POLLHUP;\n\telse if (pf->kind == INTERFACE) {\n\t\t/* see comment in ppp_read */\n\t\tstruct ppp *ppp = PF_TO_PPP(pf);\n\n\t\tppp_recv_lock(ppp);\n\t\tif (ppp->n_channels == 0 &&\n\t\t    (ppp->flags & SC_LOOP_TRAFFIC) == 0)\n\t\t\tmask |= POLLIN | POLLRDNORM;\n\t\tppp_recv_unlock(ppp);\n\t}\n\n\treturn mask;\n}\n\n#ifdef CONFIG_PPP_FILTER\nstatic int get_filter(void __user *arg, struct sock_filter **p)\n{\n\tstruct sock_fprog uprog;\n\tstruct sock_filter *code = NULL;\n\tint len;\n\n\tif (copy_from_user(&uprog, arg, sizeof(uprog)))\n\t\treturn -EFAULT;\n\n\tif (!uprog.len) {\n\t\t*p = NULL;\n\t\treturn 0;\n\t}\n\n\tlen = uprog.len * sizeof(struct sock_filter);\n\tcode = memdup_user(uprog.filter, len);\n\tif (IS_ERR(code))\n\t\treturn PTR_ERR(code);\n\n\t*p = code;\n\treturn uprog.len;\n}\n#endif /* CONFIG_PPP_FILTER */\n\nstatic long ppp_ioctl(struct file *file, unsigned int cmd, unsigned long arg)\n{\n\tstruct ppp_file *pf;\n\tstruct ppp *ppp;\n\tint err = -EFAULT, val, val2, i;\n\tstruct ppp_idle idle;\n\tstruct npioctl npi;\n\tint unit, cflags;\n\tstruct slcompress *vj;\n\tvoid __user *argp = (void __user *)arg;\n\tint __user *p = argp;\n\n\tmutex_lock(&ppp_mutex);\n\n\tpf = file->private_data;\n\tif (!pf) {\n\t\terr = ppp_unattached_ioctl(current->nsproxy->net_ns,\n\t\t\t\t\t   pf, file, cmd, arg);\n\t\tgoto out;\n\t}\n\n\tif (cmd == PPPIOCDETACH) {\n\t\t/*\n\t\t * We have to be careful here... if the file descriptor\n\t\t * has been dup'd, we could have another process in the\n\t\t * middle of a poll using the same file *, so we had\n\t\t * better not free the interface data structures -\n\t\t * instead we fail the ioctl.  Even in this case, we\n\t\t * shut down the interface if we are the owner of it.\n\t\t * Actually, we should get rid of PPPIOCDETACH, userland\n\t\t * (i.e. pppd) could achieve the same effect by closing\n\t\t * this fd and reopening /dev/ppp.\n\t\t */\n\t\terr = -EINVAL;\n\t\tif (pf->kind == INTERFACE) {\n\t\t\tppp = PF_TO_PPP(pf);\n\t\t\trtnl_lock();\n\t\t\tif (file == ppp->owner)\n\t\t\t\tunregister_netdevice(ppp->dev);\n\t\t\trtnl_unlock();\n\t\t}\n\t\tif (atomic_long_read(&file->f_count) < 2) {\n\t\t\tppp_release(NULL, file);\n\t\t\terr = 0;\n\t\t} else\n\t\t\tpr_warn(\"PPPIOCDETACH file->f_count=%ld\\n\",\n\t\t\t\tatomic_long_read(&file->f_count));\n\t\tgoto out;\n\t}\n\n\tif (pf->kind == CHANNEL) {\n\t\tstruct channel *pch;\n\t\tstruct ppp_channel *chan;\n\n\t\tpch = PF_TO_CHANNEL(pf);\n\n\t\tswitch (cmd) {\n\t\tcase PPPIOCCONNECT:\n\t\t\tif (get_user(unit, p))\n\t\t\t\tbreak;\n\t\t\terr = ppp_connect_channel(pch, unit);\n\t\t\tbreak;\n\n\t\tcase PPPIOCDISCONN:\n\t\t\terr = ppp_disconnect_channel(pch);\n\t\t\tbreak;\n\n\t\tdefault:\n\t\t\tdown_read(&pch->chan_sem);\n\t\t\tchan = pch->chan;\n\t\t\terr = -ENOTTY;\n\t\t\tif (chan && chan->ops->ioctl)\n\t\t\t\terr = chan->ops->ioctl(chan, cmd, arg);\n\t\t\tup_read(&pch->chan_sem);\n\t\t}\n\t\tgoto out;\n\t}\n\n\tif (pf->kind != INTERFACE) {\n\t\t/* can't happen */\n\t\tpr_err(\"PPP: not interface or channel??\\n\");\n\t\terr = -EINVAL;\n\t\tgoto out;\n\t}\n\n\tppp = PF_TO_PPP(pf);\n\tswitch (cmd) {\n\tcase PPPIOCSMRU:\n\t\tif (get_user(val, p))\n\t\t\tbreak;\n\t\tppp->mru = val;\n\t\terr = 0;\n\t\tbreak;\n\n\tcase PPPIOCSFLAGS:\n\t\tif (get_user(val, p))\n\t\t\tbreak;\n\t\tppp_lock(ppp);\n\t\tcflags = ppp->flags & ~val;\n#ifdef CONFIG_PPP_MULTILINK\n\t\tif (!(ppp->flags & SC_MULTILINK) && (val & SC_MULTILINK))\n\t\t\tppp->nextseq = 0;\n#endif\n\t\tppp->flags = val & SC_FLAG_BITS;\n\t\tppp_unlock(ppp);\n\t\tif (cflags & SC_CCP_OPEN)\n\t\t\tppp_ccp_closed(ppp);\n\t\terr = 0;\n\t\tbreak;\n\n\tcase PPPIOCGFLAGS:\n\t\tval = ppp->flags | ppp->xstate | ppp->rstate;\n\t\tif (put_user(val, p))\n\t\t\tbreak;\n\t\terr = 0;\n\t\tbreak;\n\n\tcase PPPIOCSCOMPRESS:\n\t\terr = ppp_set_compress(ppp, arg);\n\t\tbreak;\n\n\tcase PPPIOCGUNIT:\n\t\tif (put_user(ppp->file.index, p))\n\t\t\tbreak;\n\t\terr = 0;\n\t\tbreak;\n\n\tcase PPPIOCSDEBUG:\n\t\tif (get_user(val, p))\n\t\t\tbreak;\n\t\tppp->debug = val;\n\t\terr = 0;\n\t\tbreak;\n\n\tcase PPPIOCGDEBUG:\n\t\tif (put_user(ppp->debug, p))\n\t\t\tbreak;\n\t\terr = 0;\n\t\tbreak;\n\n\tcase PPPIOCGIDLE:\n\t\tidle.xmit_idle = (jiffies - ppp->last_xmit) / HZ;\n\t\tidle.recv_idle = (jiffies - ppp->last_recv) / HZ;\n\t\tif (copy_to_user(argp, &idle, sizeof(idle)))\n\t\t\tbreak;\n\t\terr = 0;\n\t\tbreak;\n\n\tcase PPPIOCSMAXCID:\n\t\tif (get_user(val, p))\n\t\t\tbreak;\n\t\tval2 = 15;\n\t\tif ((val >> 16) != 0) {\n\t\t\tval2 = val >> 16;\n\t\t\tval &= 0xffff;\n\t\t}\n\t\tvj = slhc_init(val2+1, val+1);\n\t\tif (IS_ERR(vj)) {\n\t\t\terr = PTR_ERR(vj);\n\t\t\tbreak;\n\t\t}\n\t\tppp_lock(ppp);\n\t\tif (ppp->vj)\n\t\t\tslhc_free(ppp->vj);\n\t\tppp->vj = vj;\n\t\tppp_unlock(ppp);\n\t\terr = 0;\n\t\tbreak;\n\n\tcase PPPIOCGNPMODE:\n\tcase PPPIOCSNPMODE:\n\t\tif (copy_from_user(&npi, argp, sizeof(npi)))\n\t\t\tbreak;\n\t\terr = proto_to_npindex(npi.protocol);\n\t\tif (err < 0)\n\t\t\tbreak;\n\t\ti = err;\n\t\tif (cmd == PPPIOCGNPMODE) {\n\t\t\terr = -EFAULT;\n\t\t\tnpi.mode = ppp->npmode[i];\n\t\t\tif (copy_to_user(argp, &npi, sizeof(npi)))\n\t\t\t\tbreak;\n\t\t} else {\n\t\t\tppp->npmode[i] = npi.mode;\n\t\t\t/* we may be able to transmit more packets now (??) */\n\t\t\tnetif_wake_queue(ppp->dev);\n\t\t}\n\t\terr = 0;\n\t\tbreak;\n\n#ifdef CONFIG_PPP_FILTER\n\tcase PPPIOCSPASS:\n\t{\n\t\tstruct sock_filter *code;\n\n\t\terr = get_filter(argp, &code);\n\t\tif (err >= 0) {\n\t\t\tstruct bpf_prog *pass_filter = NULL;\n\t\t\tstruct sock_fprog_kern fprog = {\n\t\t\t\t.len = err,\n\t\t\t\t.filter = code,\n\t\t\t};\n\n\t\t\terr = 0;\n\t\t\tif (fprog.filter)\n\t\t\t\terr = bpf_prog_create(&pass_filter, &fprog);\n\t\t\tif (!err) {\n\t\t\t\tppp_lock(ppp);\n\t\t\t\tif (ppp->pass_filter)\n\t\t\t\t\tbpf_prog_destroy(ppp->pass_filter);\n\t\t\t\tppp->pass_filter = pass_filter;\n\t\t\t\tppp_unlock(ppp);\n\t\t\t}\n\t\t\tkfree(code);\n\t\t}\n\t\tbreak;\n\t}\n\tcase PPPIOCSACTIVE:\n\t{\n\t\tstruct sock_filter *code;\n\n\t\terr = get_filter(argp, &code);\n\t\tif (err >= 0) {\n\t\t\tstruct bpf_prog *active_filter = NULL;\n\t\t\tstruct sock_fprog_kern fprog = {\n\t\t\t\t.len = err,\n\t\t\t\t.filter = code,\n\t\t\t};\n\n\t\t\terr = 0;\n\t\t\tif (fprog.filter)\n\t\t\t\terr = bpf_prog_create(&active_filter, &fprog);\n\t\t\tif (!err) {\n\t\t\t\tppp_lock(ppp);\n\t\t\t\tif (ppp->active_filter)\n\t\t\t\t\tbpf_prog_destroy(ppp->active_filter);\n\t\t\t\tppp->active_filter = active_filter;\n\t\t\t\tppp_unlock(ppp);\n\t\t\t}\n\t\t\tkfree(code);\n\t\t}\n\t\tbreak;\n\t}\n#endif /* CONFIG_PPP_FILTER */\n\n#ifdef CONFIG_PPP_MULTILINK\n\tcase PPPIOCSMRRU:\n\t\tif (get_user(val, p))\n\t\t\tbreak;\n\t\tppp_recv_lock(ppp);\n\t\tppp->mrru = val;\n\t\tppp_recv_unlock(ppp);\n\t\terr = 0;\n\t\tbreak;\n#endif /* CONFIG_PPP_MULTILINK */\n\n\tdefault:\n\t\terr = -ENOTTY;\n\t}\n\nout:\n\tmutex_unlock(&ppp_mutex);\n\n\treturn err;\n}\n\nstatic int ppp_unattached_ioctl(struct net *net, struct ppp_file *pf,\n\t\t\tstruct file *file, unsigned int cmd, unsigned long arg)\n{\n\tint unit, err = -EFAULT;\n\tstruct ppp *ppp;\n\tstruct channel *chan;\n\tstruct ppp_net *pn;\n\tint __user *p = (int __user *)arg;\n\n\tswitch (cmd) {\n\tcase PPPIOCNEWUNIT:\n\t\t/* Create a new ppp unit */\n\t\tif (get_user(unit, p))\n\t\t\tbreak;\n\t\tppp = ppp_create_interface(net, unit, file, &err);\n\t\tif (!ppp)\n\t\t\tbreak;\n\t\tfile->private_data = &ppp->file;\n\t\terr = -EFAULT;\n\t\tif (put_user(ppp->file.index, p))\n\t\t\tbreak;\n\t\terr = 0;\n\t\tbreak;\n\n\tcase PPPIOCATTACH:\n\t\t/* Attach to an existing ppp unit */\n\t\tif (get_user(unit, p))\n\t\t\tbreak;\n\t\terr = -ENXIO;\n\t\tpn = ppp_pernet(net);\n\t\tmutex_lock(&pn->all_ppp_mutex);\n\t\tppp = ppp_find_unit(pn, unit);\n\t\tif (ppp) {\n\t\t\tatomic_inc(&ppp->file.refcnt);\n\t\t\tfile->private_data = &ppp->file;\n\t\t\terr = 0;\n\t\t}\n\t\tmutex_unlock(&pn->all_ppp_mutex);\n\t\tbreak;\n\n\tcase PPPIOCATTCHAN:\n\t\tif (get_user(unit, p))\n\t\t\tbreak;\n\t\terr = -ENXIO;\n\t\tpn = ppp_pernet(net);\n\t\tspin_lock_bh(&pn->all_channels_lock);\n\t\tchan = ppp_find_channel(pn, unit);\n\t\tif (chan) {\n\t\t\tatomic_inc(&chan->file.refcnt);\n\t\t\tfile->private_data = &chan->file;\n\t\t\terr = 0;\n\t\t}\n\t\tspin_unlock_bh(&pn->all_channels_lock);\n\t\tbreak;\n\n\tdefault:\n\t\terr = -ENOTTY;\n\t}\n\n\treturn err;\n}\n\nstatic const struct file_operations ppp_device_fops = {\n\t.owner\t\t= THIS_MODULE,\n\t.read\t\t= ppp_read,\n\t.write\t\t= ppp_write,\n\t.poll\t\t= ppp_poll,\n\t.unlocked_ioctl\t= ppp_ioctl,\n\t.open\t\t= ppp_open,\n\t.release\t= ppp_release,\n\t.llseek\t\t= noop_llseek,\n};\n\nstatic __net_init int ppp_init_net(struct net *net)\n{\n\tstruct ppp_net *pn = net_generic(net, ppp_net_id);\n\n\tidr_init(&pn->units_idr);\n\tmutex_init(&pn->all_ppp_mutex);\n\n\tINIT_LIST_HEAD(&pn->all_channels);\n\tINIT_LIST_HEAD(&pn->new_channels);\n\n\tspin_lock_init(&pn->all_channels_lock);\n\n\treturn 0;\n}\n\nstatic __net_exit void ppp_exit_net(struct net *net)\n{\n\tstruct ppp_net *pn = net_generic(net, ppp_net_id);\n\tstruct net_device *dev;\n\tstruct net_device *aux;\n\tstruct ppp *ppp;\n\tLIST_HEAD(list);\n\tint id;\n\n\trtnl_lock();\n\tfor_each_netdev_safe(net, dev, aux) {\n\t\tif (dev->netdev_ops == &ppp_netdev_ops)\n\t\t\tunregister_netdevice_queue(dev, &list);\n\t}\n\n\tidr_for_each_entry(&pn->units_idr, ppp, id)\n\t\t/* Skip devices already unregistered by previous loop */\n\t\tif (!net_eq(dev_net(ppp->dev), net))\n\t\t\tunregister_netdevice_queue(ppp->dev, &list);\n\n\tunregister_netdevice_many(&list);\n\trtnl_unlock();\n\n\tidr_destroy(&pn->units_idr);\n}\n\nstatic struct pernet_operations ppp_net_ops = {\n\t.init = ppp_init_net,\n\t.exit = ppp_exit_net,\n\t.id   = &ppp_net_id,\n\t.size = sizeof(struct ppp_net),\n};\n\n#define PPP_MAJOR\t108\n\n/* Called at boot time if ppp is compiled into the kernel,\n   or at module load time (from init_module) if compiled as a module. */\nstatic int __init ppp_init(void)\n{\n\tint err;\n\n\tpr_info(\"PPP generic driver version \" PPP_VERSION \"\\n\");\n\n\terr = register_pernet_device(&ppp_net_ops);\n\tif (err) {\n\t\tpr_err(\"failed to register PPP pernet device (%d)\\n\", err);\n\t\tgoto out;\n\t}\n\n\terr = register_chrdev(PPP_MAJOR, \"ppp\", &ppp_device_fops);\n\tif (err) {\n\t\tpr_err(\"failed to register PPP device (%d)\\n\", err);\n\t\tgoto out_net;\n\t}\n\n\tppp_class = class_create(THIS_MODULE, \"ppp\");\n\tif (IS_ERR(ppp_class)) {\n\t\terr = PTR_ERR(ppp_class);\n\t\tgoto out_chrdev;\n\t}\n\n\t/* not a big deal if we fail here :-) */\n\tdevice_create(ppp_class, NULL, MKDEV(PPP_MAJOR, 0), NULL, \"ppp\");\n\n\treturn 0;\n\nout_chrdev:\n\tunregister_chrdev(PPP_MAJOR, \"ppp\");\nout_net:\n\tunregister_pernet_device(&ppp_net_ops);\nout:\n\treturn err;\n}\n\n/*\n * Network interface unit routines.\n */\nstatic netdev_tx_t\nppp_start_xmit(struct sk_buff *skb, struct net_device *dev)\n{\n\tstruct ppp *ppp = netdev_priv(dev);\n\tint npi, proto;\n\tunsigned char *pp;\n\n\tnpi = ethertype_to_npindex(ntohs(skb->protocol));\n\tif (npi < 0)\n\t\tgoto outf;\n\n\t/* Drop, accept or reject the packet */\n\tswitch (ppp->npmode[npi]) {\n\tcase NPMODE_PASS:\n\t\tbreak;\n\tcase NPMODE_QUEUE:\n\t\t/* it would be nice to have a way to tell the network\n\t\t   system to queue this one up for later. */\n\t\tgoto outf;\n\tcase NPMODE_DROP:\n\tcase NPMODE_ERROR:\n\t\tgoto outf;\n\t}\n\n\t/* Put the 2-byte PPP protocol number on the front,\n\t   making sure there is room for the address and control fields. */\n\tif (skb_cow_head(skb, PPP_HDRLEN))\n\t\tgoto outf;\n\n\tpp = skb_push(skb, 2);\n\tproto = npindex_to_proto[npi];\n\tput_unaligned_be16(proto, pp);\n\n\tskb_scrub_packet(skb, !net_eq(ppp->ppp_net, dev_net(dev)));\n\tskb_queue_tail(&ppp->file.xq, skb);\n\tppp_xmit_process(ppp);\n\treturn NETDEV_TX_OK;\n\n outf:\n\tkfree_skb(skb);\n\t++dev->stats.tx_dropped;\n\treturn NETDEV_TX_OK;\n}\n\nstatic int\nppp_net_ioctl(struct net_device *dev, struct ifreq *ifr, int cmd)\n{\n\tstruct ppp *ppp = netdev_priv(dev);\n\tint err = -EFAULT;\n\tvoid __user *addr = (void __user *) ifr->ifr_ifru.ifru_data;\n\tstruct ppp_stats stats;\n\tstruct ppp_comp_stats cstats;\n\tchar *vers;\n\n\tswitch (cmd) {\n\tcase SIOCGPPPSTATS:\n\t\tppp_get_stats(ppp, &stats);\n\t\tif (copy_to_user(addr, &stats, sizeof(stats)))\n\t\t\tbreak;\n\t\terr = 0;\n\t\tbreak;\n\n\tcase SIOCGPPPCSTATS:\n\t\tmemset(&cstats, 0, sizeof(cstats));\n\t\tif (ppp->xc_state)\n\t\t\tppp->xcomp->comp_stat(ppp->xc_state, &cstats.c);\n\t\tif (ppp->rc_state)\n\t\t\tppp->rcomp->decomp_stat(ppp->rc_state, &cstats.d);\n\t\tif (copy_to_user(addr, &cstats, sizeof(cstats)))\n\t\t\tbreak;\n\t\terr = 0;\n\t\tbreak;\n\n\tcase SIOCGPPPVER:\n\t\tvers = PPP_VERSION;\n\t\tif (copy_to_user(addr, vers, strlen(vers) + 1))\n\t\t\tbreak;\n\t\terr = 0;\n\t\tbreak;\n\n\tdefault:\n\t\terr = -EINVAL;\n\t}\n\n\treturn err;\n}\n\nstatic struct rtnl_link_stats64*\nppp_get_stats64(struct net_device *dev, struct rtnl_link_stats64 *stats64)\n{\n\tstruct ppp *ppp = netdev_priv(dev);\n\n\tppp_recv_lock(ppp);\n\tstats64->rx_packets = ppp->stats64.rx_packets;\n\tstats64->rx_bytes   = ppp->stats64.rx_bytes;\n\tppp_recv_unlock(ppp);\n\n\tppp_xmit_lock(ppp);\n\tstats64->tx_packets = ppp->stats64.tx_packets;\n\tstats64->tx_bytes   = ppp->stats64.tx_bytes;\n\tppp_xmit_unlock(ppp);\n\n\tstats64->rx_errors        = dev->stats.rx_errors;\n\tstats64->tx_errors        = dev->stats.tx_errors;\n\tstats64->rx_dropped       = dev->stats.rx_dropped;\n\tstats64->tx_dropped       = dev->stats.tx_dropped;\n\tstats64->rx_length_errors = dev->stats.rx_length_errors;\n\n\treturn stats64;\n}\n\nstatic struct lock_class_key ppp_tx_busylock;\nstatic int ppp_dev_init(struct net_device *dev)\n{\n\tdev->qdisc_tx_busylock = &ppp_tx_busylock;\n\treturn 0;\n}\n\nstatic void ppp_dev_uninit(struct net_device *dev)\n{\n\tstruct ppp *ppp = netdev_priv(dev);\n\tstruct ppp_net *pn = ppp_pernet(ppp->ppp_net);\n\n\tppp_lock(ppp);\n\tppp->closing = 1;\n\tppp_unlock(ppp);\n\n\tmutex_lock(&pn->all_ppp_mutex);\n\tunit_put(&pn->units_idr, ppp->file.index);\n\tmutex_unlock(&pn->all_ppp_mutex);\n\n\tppp->owner = NULL;\n\n\tppp->file.dead = 1;\n\twake_up_interruptible(&ppp->file.rwait);\n}\n\nstatic const struct net_device_ops ppp_netdev_ops = {\n\t.ndo_init\t = ppp_dev_init,\n\t.ndo_uninit      = ppp_dev_uninit,\n\t.ndo_start_xmit  = ppp_start_xmit,\n\t.ndo_do_ioctl    = ppp_net_ioctl,\n\t.ndo_get_stats64 = ppp_get_stats64,\n};\n\nstatic struct device_type ppp_type = {\n\t.name = \"ppp\",\n};\n\nstatic void ppp_setup(struct net_device *dev)\n{\n\tdev->netdev_ops = &ppp_netdev_ops;\n\tSET_NETDEV_DEVTYPE(dev, &ppp_type);\n\n\tdev->hard_header_len = PPP_HDRLEN;\n\tdev->mtu = PPP_MRU;\n\tdev->addr_len = 0;\n\tdev->tx_queue_len = 3;\n\tdev->type = ARPHRD_PPP;\n\tdev->flags = IFF_POINTOPOINT | IFF_NOARP | IFF_MULTICAST;\n\tnetif_keep_dst(dev);\n}\n\n/*\n * Transmit-side routines.\n */\n\n/*\n * Called to do any work queued up on the transmit side\n * that can now be done.\n */\nstatic void\nppp_xmit_process(struct ppp *ppp)\n{\n\tstruct sk_buff *skb;\n\n\tppp_xmit_lock(ppp);\n\tif (!ppp->closing) {\n\t\tppp_push(ppp);\n\t\twhile (!ppp->xmit_pending &&\n\t\t       (skb = skb_dequeue(&ppp->file.xq)))\n\t\t\tppp_send_frame(ppp, skb);\n\t\t/* If there's no work left to do, tell the core net\n\t\t   code that we can accept some more. */\n\t\tif (!ppp->xmit_pending && !skb_peek(&ppp->file.xq))\n\t\t\tnetif_wake_queue(ppp->dev);\n\t\telse\n\t\t\tnetif_stop_queue(ppp->dev);\n\t}\n\tppp_xmit_unlock(ppp);\n}\n\nstatic inline struct sk_buff *\npad_compress_skb(struct ppp *ppp, struct sk_buff *skb)\n{\n\tstruct sk_buff *new_skb;\n\tint len;\n\tint new_skb_size = ppp->dev->mtu +\n\t\tppp->xcomp->comp_extra + ppp->dev->hard_header_len;\n\tint compressor_skb_size = ppp->dev->mtu +\n\t\tppp->xcomp->comp_extra + PPP_HDRLEN;\n\tnew_skb = alloc_skb(new_skb_size, GFP_ATOMIC);\n\tif (!new_skb) {\n\t\tif (net_ratelimit())\n\t\t\tnetdev_err(ppp->dev, \"PPP: no memory (comp pkt)\\n\");\n\t\treturn NULL;\n\t}\n\tif (ppp->dev->hard_header_len > PPP_HDRLEN)\n\t\tskb_reserve(new_skb,\n\t\t\t    ppp->dev->hard_header_len - PPP_HDRLEN);\n\n\t/* compressor still expects A/C bytes in hdr */\n\tlen = ppp->xcomp->compress(ppp->xc_state, skb->data - 2,\n\t\t\t\t   new_skb->data, skb->len + 2,\n\t\t\t\t   compressor_skb_size);\n\tif (len > 0 && (ppp->flags & SC_CCP_UP)) {\n\t\tconsume_skb(skb);\n\t\tskb = new_skb;\n\t\tskb_put(skb, len);\n\t\tskb_pull(skb, 2);\t/* pull off A/C bytes */\n\t} else if (len == 0) {\n\t\t/* didn't compress, or CCP not up yet */\n\t\tconsume_skb(new_skb);\n\t\tnew_skb = skb;\n\t} else {\n\t\t/*\n\t\t * (len < 0)\n\t\t * MPPE requires that we do not send unencrypted\n\t\t * frames.  The compressor will return -1 if we\n\t\t * should drop the frame.  We cannot simply test\n\t\t * the compress_proto because MPPE and MPPC share\n\t\t * the same number.\n\t\t */\n\t\tif (net_ratelimit())\n\t\t\tnetdev_err(ppp->dev, \"ppp: compressor dropped pkt\\n\");\n\t\tkfree_skb(skb);\n\t\tconsume_skb(new_skb);\n\t\tnew_skb = NULL;\n\t}\n\treturn new_skb;\n}\n\n/*\n * Compress and send a frame.\n * The caller should have locked the xmit path,\n * and xmit_pending should be 0.\n */\nstatic void\nppp_send_frame(struct ppp *ppp, struct sk_buff *skb)\n{\n\tint proto = PPP_PROTO(skb);\n\tstruct sk_buff *new_skb;\n\tint len;\n\tunsigned char *cp;\n\n\tif (proto < 0x8000) {\n#ifdef CONFIG_PPP_FILTER\n\t\t/* check if we should pass this packet */\n\t\t/* the filter instructions are constructed assuming\n\t\t   a four-byte PPP header on each packet */\n\t\t*skb_push(skb, 2) = 1;\n\t\tif (ppp->pass_filter &&\n\t\t    BPF_PROG_RUN(ppp->pass_filter, skb) == 0) {\n\t\t\tif (ppp->debug & 1)\n\t\t\t\tnetdev_printk(KERN_DEBUG, ppp->dev,\n\t\t\t\t\t      \"PPP: outbound frame \"\n\t\t\t\t\t      \"not passed\\n\");\n\t\t\tkfree_skb(skb);\n\t\t\treturn;\n\t\t}\n\t\t/* if this packet passes the active filter, record the time */\n\t\tif (!(ppp->active_filter &&\n\t\t      BPF_PROG_RUN(ppp->active_filter, skb) == 0))\n\t\t\tppp->last_xmit = jiffies;\n\t\tskb_pull(skb, 2);\n#else\n\t\t/* for data packets, record the time */\n\t\tppp->last_xmit = jiffies;\n#endif /* CONFIG_PPP_FILTER */\n\t}\n\n\t++ppp->stats64.tx_packets;\n\tppp->stats64.tx_bytes += skb->len - 2;\n\n\tswitch (proto) {\n\tcase PPP_IP:\n\t\tif (!ppp->vj || (ppp->flags & SC_COMP_TCP) == 0)\n\t\t\tbreak;\n\t\t/* try to do VJ TCP header compression */\n\t\tnew_skb = alloc_skb(skb->len + ppp->dev->hard_header_len - 2,\n\t\t\t\t    GFP_ATOMIC);\n\t\tif (!new_skb) {\n\t\t\tnetdev_err(ppp->dev, \"PPP: no memory (VJ comp pkt)\\n\");\n\t\t\tgoto drop;\n\t\t}\n\t\tskb_reserve(new_skb, ppp->dev->hard_header_len - 2);\n\t\tcp = skb->data + 2;\n\t\tlen = slhc_compress(ppp->vj, cp, skb->len - 2,\n\t\t\t\t    new_skb->data + 2, &cp,\n\t\t\t\t    !(ppp->flags & SC_NO_TCP_CCID));\n\t\tif (cp == skb->data + 2) {\n\t\t\t/* didn't compress */\n\t\t\tconsume_skb(new_skb);\n\t\t} else {\n\t\t\tif (cp[0] & SL_TYPE_COMPRESSED_TCP) {\n\t\t\t\tproto = PPP_VJC_COMP;\n\t\t\t\tcp[0] &= ~SL_TYPE_COMPRESSED_TCP;\n\t\t\t} else {\n\t\t\t\tproto = PPP_VJC_UNCOMP;\n\t\t\t\tcp[0] = skb->data[2];\n\t\t\t}\n\t\t\tconsume_skb(skb);\n\t\t\tskb = new_skb;\n\t\t\tcp = skb_put(skb, len + 2);\n\t\t\tcp[0] = 0;\n\t\t\tcp[1] = proto;\n\t\t}\n\t\tbreak;\n\n\tcase PPP_CCP:\n\t\t/* peek at outbound CCP frames */\n\t\tppp_ccp_peek(ppp, skb, 0);\n\t\tbreak;\n\t}\n\n\t/* try to do packet compression */\n\tif ((ppp->xstate & SC_COMP_RUN) && ppp->xc_state &&\n\t    proto != PPP_LCP && proto != PPP_CCP) {\n\t\tif (!(ppp->flags & SC_CCP_UP) && (ppp->flags & SC_MUST_COMP)) {\n\t\t\tif (net_ratelimit())\n\t\t\t\tnetdev_err(ppp->dev,\n\t\t\t\t\t   \"ppp: compression required but \"\n\t\t\t\t\t   \"down - pkt dropped.\\n\");\n\t\t\tgoto drop;\n\t\t}\n\t\tskb = pad_compress_skb(ppp, skb);\n\t\tif (!skb)\n\t\t\tgoto drop;\n\t}\n\n\t/*\n\t * If we are waiting for traffic (demand dialling),\n\t * queue it up for pppd to receive.\n\t */\n\tif (ppp->flags & SC_LOOP_TRAFFIC) {\n\t\tif (ppp->file.rq.qlen > PPP_MAX_RQLEN)\n\t\t\tgoto drop;\n\t\tskb_queue_tail(&ppp->file.rq, skb);\n\t\twake_up_interruptible(&ppp->file.rwait);\n\t\treturn;\n\t}\n\n\tppp->xmit_pending = skb;\n\tppp_push(ppp);\n\treturn;\n\n drop:\n\tkfree_skb(skb);\n\t++ppp->dev->stats.tx_errors;\n}\n\n/*\n * Try to send the frame in xmit_pending.\n * The caller should have the xmit path locked.\n */\nstatic void\nppp_push(struct ppp *ppp)\n{\n\tstruct list_head *list;\n\tstruct channel *pch;\n\tstruct sk_buff *skb = ppp->xmit_pending;\n\n\tif (!skb)\n\t\treturn;\n\n\tlist = &ppp->channels;\n\tif (list_empty(list)) {\n\t\t/* nowhere to send the packet, just drop it */\n\t\tppp->xmit_pending = NULL;\n\t\tkfree_skb(skb);\n\t\treturn;\n\t}\n\n\tif ((ppp->flags & SC_MULTILINK) == 0) {\n\t\t/* not doing multilink: send it down the first channel */\n\t\tlist = list->next;\n\t\tpch = list_entry(list, struct channel, clist);\n\n\t\tspin_lock_bh(&pch->downl);\n\t\tif (pch->chan) {\n\t\t\tif (pch->chan->ops->start_xmit(pch->chan, skb))\n\t\t\t\tppp->xmit_pending = NULL;\n\t\t} else {\n\t\t\t/* channel got unregistered */\n\t\t\tkfree_skb(skb);\n\t\t\tppp->xmit_pending = NULL;\n\t\t}\n\t\tspin_unlock_bh(&pch->downl);\n\t\treturn;\n\t}\n\n#ifdef CONFIG_PPP_MULTILINK\n\t/* Multilink: fragment the packet over as many links\n\t   as can take the packet at the moment. */\n\tif (!ppp_mp_explode(ppp, skb))\n\t\treturn;\n#endif /* CONFIG_PPP_MULTILINK */\n\n\tppp->xmit_pending = NULL;\n\tkfree_skb(skb);\n}\n\n#ifdef CONFIG_PPP_MULTILINK\nstatic bool mp_protocol_compress __read_mostly = true;\nmodule_param(mp_protocol_compress, bool, S_IRUGO | S_IWUSR);\nMODULE_PARM_DESC(mp_protocol_compress,\n\t\t \"compress protocol id in multilink fragments\");\n\n/*\n * Divide a packet to be transmitted into fragments and\n * send them out the individual links.\n */\nstatic int ppp_mp_explode(struct ppp *ppp, struct sk_buff *skb)\n{\n\tint len, totlen;\n\tint i, bits, hdrlen, mtu;\n\tint flen;\n\tint navail, nfree, nzero;\n\tint nbigger;\n\tint totspeed;\n\tint totfree;\n\tunsigned char *p, *q;\n\tstruct list_head *list;\n\tstruct channel *pch;\n\tstruct sk_buff *frag;\n\tstruct ppp_channel *chan;\n\n\ttotspeed = 0; /*total bitrate of the bundle*/\n\tnfree = 0; /* # channels which have no packet already queued */\n\tnavail = 0; /* total # of usable channels (not deregistered) */\n\tnzero = 0; /* number of channels with zero speed associated*/\n\ttotfree = 0; /*total # of channels available and\n\t\t\t\t  *having no queued packets before\n\t\t\t\t  *starting the fragmentation*/\n\n\thdrlen = (ppp->flags & SC_MP_XSHORTSEQ)? MPHDRLEN_SSN: MPHDRLEN;\n\ti = 0;\n\tlist_for_each_entry(pch, &ppp->channels, clist) {\n\t\tif (pch->chan) {\n\t\t\tpch->avail = 1;\n\t\t\tnavail++;\n\t\t\tpch->speed = pch->chan->speed;\n\t\t} else {\n\t\t\tpch->avail = 0;\n\t\t}\n\t\tif (pch->avail) {\n\t\t\tif (skb_queue_empty(&pch->file.xq) ||\n\t\t\t\t!pch->had_frag) {\n\t\t\t\t\tif (pch->speed == 0)\n\t\t\t\t\t\tnzero++;\n\t\t\t\t\telse\n\t\t\t\t\t\ttotspeed += pch->speed;\n\n\t\t\t\t\tpch->avail = 2;\n\t\t\t\t\t++nfree;\n\t\t\t\t\t++totfree;\n\t\t\t\t}\n\t\t\tif (!pch->had_frag && i < ppp->nxchan)\n\t\t\t\tppp->nxchan = i;\n\t\t}\n\t\t++i;\n\t}\n\t/*\n\t * Don't start sending this packet unless at least half of\n\t * the channels are free.  This gives much better TCP\n\t * performance if we have a lot of channels.\n\t */\n\tif (nfree == 0 || nfree < navail / 2)\n\t\treturn 0; /* can't take now, leave it in xmit_pending */\n\n\t/* Do protocol field compression */\n\tp = skb->data;\n\tlen = skb->len;\n\tif (*p == 0 && mp_protocol_compress) {\n\t\t++p;\n\t\t--len;\n\t}\n\n\ttotlen = len;\n\tnbigger = len % nfree;\n\n\t/* skip to the channel after the one we last used\n\t   and start at that one */\n\tlist = &ppp->channels;\n\tfor (i = 0; i < ppp->nxchan; ++i) {\n\t\tlist = list->next;\n\t\tif (list == &ppp->channels) {\n\t\t\ti = 0;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\t/* create a fragment for each channel */\n\tbits = B;\n\twhile (len > 0) {\n\t\tlist = list->next;\n\t\tif (list == &ppp->channels) {\n\t\t\ti = 0;\n\t\t\tcontinue;\n\t\t}\n\t\tpch = list_entry(list, struct channel, clist);\n\t\t++i;\n\t\tif (!pch->avail)\n\t\t\tcontinue;\n\n\t\t/*\n\t\t * Skip this channel if it has a fragment pending already and\n\t\t * we haven't given a fragment to all of the free channels.\n\t\t */\n\t\tif (pch->avail == 1) {\n\t\t\tif (nfree > 0)\n\t\t\t\tcontinue;\n\t\t} else {\n\t\t\tpch->avail = 1;\n\t\t}\n\n\t\t/* check the channel's mtu and whether it is still attached. */\n\t\tspin_lock_bh(&pch->downl);\n\t\tif (pch->chan == NULL) {\n\t\t\t/* can't use this channel, it's being deregistered */\n\t\t\tif (pch->speed == 0)\n\t\t\t\tnzero--;\n\t\t\telse\n\t\t\t\ttotspeed -= pch->speed;\n\n\t\t\tspin_unlock_bh(&pch->downl);\n\t\t\tpch->avail = 0;\n\t\t\ttotlen = len;\n\t\t\ttotfree--;\n\t\t\tnfree--;\n\t\t\tif (--navail == 0)\n\t\t\t\tbreak;\n\t\t\tcontinue;\n\t\t}\n\n\t\t/*\n\t\t*if the channel speed is not set divide\n\t\t*the packet evenly among the free channels;\n\t\t*otherwise divide it according to the speed\n\t\t*of the channel we are going to transmit on\n\t\t*/\n\t\tflen = len;\n\t\tif (nfree > 0) {\n\t\t\tif (pch->speed == 0) {\n\t\t\t\tflen = len/nfree;\n\t\t\t\tif (nbigger > 0) {\n\t\t\t\t\tflen++;\n\t\t\t\t\tnbigger--;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tflen = (((totfree - nzero)*(totlen + hdrlen*totfree)) /\n\t\t\t\t\t((totspeed*totfree)/pch->speed)) - hdrlen;\n\t\t\t\tif (nbigger > 0) {\n\t\t\t\t\tflen += ((totfree - nzero)*pch->speed)/totspeed;\n\t\t\t\t\tnbigger -= ((totfree - nzero)*pch->speed)/\n\t\t\t\t\t\t\ttotspeed;\n\t\t\t\t}\n\t\t\t}\n\t\t\tnfree--;\n\t\t}\n\n\t\t/*\n\t\t *check if we are on the last channel or\n\t\t *we exceded the length of the data to\n\t\t *fragment\n\t\t */\n\t\tif ((nfree <= 0) || (flen > len))\n\t\t\tflen = len;\n\t\t/*\n\t\t *it is not worth to tx on slow channels:\n\t\t *in that case from the resulting flen according to the\n\t\t *above formula will be equal or less than zero.\n\t\t *Skip the channel in this case\n\t\t */\n\t\tif (flen <= 0) {\n\t\t\tpch->avail = 2;\n\t\t\tspin_unlock_bh(&pch->downl);\n\t\t\tcontinue;\n\t\t}\n\n\t\t/*\n\t\t * hdrlen includes the 2-byte PPP protocol field, but the\n\t\t * MTU counts only the payload excluding the protocol field.\n\t\t * (RFC1661 Section 2)\n\t\t */\n\t\tmtu = pch->chan->mtu - (hdrlen - 2);\n\t\tif (mtu < 4)\n\t\t\tmtu = 4;\n\t\tif (flen > mtu)\n\t\t\tflen = mtu;\n\t\tif (flen == len)\n\t\t\tbits |= E;\n\t\tfrag = alloc_skb(flen + hdrlen + (flen == 0), GFP_ATOMIC);\n\t\tif (!frag)\n\t\t\tgoto noskb;\n\t\tq = skb_put(frag, flen + hdrlen);\n\n\t\t/* make the MP header */\n\t\tput_unaligned_be16(PPP_MP, q);\n\t\tif (ppp->flags & SC_MP_XSHORTSEQ) {\n\t\t\tq[2] = bits + ((ppp->nxseq >> 8) & 0xf);\n\t\t\tq[3] = ppp->nxseq;\n\t\t} else {\n\t\t\tq[2] = bits;\n\t\t\tq[3] = ppp->nxseq >> 16;\n\t\t\tq[4] = ppp->nxseq >> 8;\n\t\t\tq[5] = ppp->nxseq;\n\t\t}\n\n\t\tmemcpy(q + hdrlen, p, flen);\n\n\t\t/* try to send it down the channel */\n\t\tchan = pch->chan;\n\t\tif (!skb_queue_empty(&pch->file.xq) ||\n\t\t\t!chan->ops->start_xmit(chan, frag))\n\t\t\tskb_queue_tail(&pch->file.xq, frag);\n\t\tpch->had_frag = 1;\n\t\tp += flen;\n\t\tlen -= flen;\n\t\t++ppp->nxseq;\n\t\tbits = 0;\n\t\tspin_unlock_bh(&pch->downl);\n\t}\n\tppp->nxchan = i;\n\n\treturn 1;\n\n noskb:\n\tspin_unlock_bh(&pch->downl);\n\tif (ppp->debug & 1)\n\t\tnetdev_err(ppp->dev, \"PPP: no memory (fragment)\\n\");\n\t++ppp->dev->stats.tx_errors;\n\t++ppp->nxseq;\n\treturn 1;\t/* abandon the frame */\n}\n#endif /* CONFIG_PPP_MULTILINK */\n\n/*\n * Try to send data out on a channel.\n */\nstatic void\nppp_channel_push(struct channel *pch)\n{\n\tstruct sk_buff *skb;\n\tstruct ppp *ppp;\n\n\tspin_lock_bh(&pch->downl);\n\tif (pch->chan) {\n\t\twhile (!skb_queue_empty(&pch->file.xq)) {\n\t\t\tskb = skb_dequeue(&pch->file.xq);\n\t\t\tif (!pch->chan->ops->start_xmit(pch->chan, skb)) {\n\t\t\t\t/* put the packet back and try again later */\n\t\t\t\tskb_queue_head(&pch->file.xq, skb);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t} else {\n\t\t/* channel got deregistered */\n\t\tskb_queue_purge(&pch->file.xq);\n\t}\n\tspin_unlock_bh(&pch->downl);\n\t/* see if there is anything from the attached unit to be sent */\n\tif (skb_queue_empty(&pch->file.xq)) {\n\t\tread_lock_bh(&pch->upl);\n\t\tppp = pch->ppp;\n\t\tif (ppp)\n\t\t\tppp_xmit_process(ppp);\n\t\tread_unlock_bh(&pch->upl);\n\t}\n}\n\n/*\n * Receive-side routines.\n */\n\nstruct ppp_mp_skb_parm {\n\tu32\t\tsequence;\n\tu8\t\tBEbits;\n};\n#define PPP_MP_CB(skb)\t((struct ppp_mp_skb_parm *)((skb)->cb))\n\nstatic inline void\nppp_do_recv(struct ppp *ppp, struct sk_buff *skb, struct channel *pch)\n{\n\tppp_recv_lock(ppp);\n\tif (!ppp->closing)\n\t\tppp_receive_frame(ppp, skb, pch);\n\telse\n\t\tkfree_skb(skb);\n\tppp_recv_unlock(ppp);\n}\n\nvoid\nppp_input(struct ppp_channel *chan, struct sk_buff *skb)\n{\n\tstruct channel *pch = chan->ppp;\n\tint proto;\n\n\tif (!pch) {\n\t\tkfree_skb(skb);\n\t\treturn;\n\t}\n\n\tread_lock_bh(&pch->upl);\n\tif (!pskb_may_pull(skb, 2)) {\n\t\tkfree_skb(skb);\n\t\tif (pch->ppp) {\n\t\t\t++pch->ppp->dev->stats.rx_length_errors;\n\t\t\tppp_receive_error(pch->ppp);\n\t\t}\n\t\tgoto done;\n\t}\n\n\tproto = PPP_PROTO(skb);\n\tif (!pch->ppp || proto >= 0xc000 || proto == PPP_CCPFRAG) {\n\t\t/* put it on the channel queue */\n\t\tskb_queue_tail(&pch->file.rq, skb);\n\t\t/* drop old frames if queue too long */\n\t\twhile (pch->file.rq.qlen > PPP_MAX_RQLEN &&\n\t\t       (skb = skb_dequeue(&pch->file.rq)))\n\t\t\tkfree_skb(skb);\n\t\twake_up_interruptible(&pch->file.rwait);\n\t} else {\n\t\tppp_do_recv(pch->ppp, skb, pch);\n\t}\n\ndone:\n\tread_unlock_bh(&pch->upl);\n}\n\n/* Put a 0-length skb in the receive queue as an error indication */\nvoid\nppp_input_error(struct ppp_channel *chan, int code)\n{\n\tstruct channel *pch = chan->ppp;\n\tstruct sk_buff *skb;\n\n\tif (!pch)\n\t\treturn;\n\n\tread_lock_bh(&pch->upl);\n\tif (pch->ppp) {\n\t\tskb = alloc_skb(0, GFP_ATOMIC);\n\t\tif (skb) {\n\t\t\tskb->len = 0;\t\t/* probably unnecessary */\n\t\t\tskb->cb[0] = code;\n\t\t\tppp_do_recv(pch->ppp, skb, pch);\n\t\t}\n\t}\n\tread_unlock_bh(&pch->upl);\n}\n\n/*\n * We come in here to process a received frame.\n * The receive side of the ppp unit is locked.\n */\nstatic void\nppp_receive_frame(struct ppp *ppp, struct sk_buff *skb, struct channel *pch)\n{\n\t/* note: a 0-length skb is used as an error indication */\n\tif (skb->len > 0) {\n\t\tskb_checksum_complete_unset(skb);\n#ifdef CONFIG_PPP_MULTILINK\n\t\t/* XXX do channel-level decompression here */\n\t\tif (PPP_PROTO(skb) == PPP_MP)\n\t\t\tppp_receive_mp_frame(ppp, skb, pch);\n\t\telse\n#endif /* CONFIG_PPP_MULTILINK */\n\t\t\tppp_receive_nonmp_frame(ppp, skb);\n\t} else {\n\t\tkfree_skb(skb);\n\t\tppp_receive_error(ppp);\n\t}\n}\n\nstatic void\nppp_receive_error(struct ppp *ppp)\n{\n\t++ppp->dev->stats.rx_errors;\n\tif (ppp->vj)\n\t\tslhc_toss(ppp->vj);\n}\n\nstatic void\nppp_receive_nonmp_frame(struct ppp *ppp, struct sk_buff *skb)\n{\n\tstruct sk_buff *ns;\n\tint proto, len, npi;\n\n\t/*\n\t * Decompress the frame, if compressed.\n\t * Note that some decompressors need to see uncompressed frames\n\t * that come in as well as compressed frames.\n\t */\n\tif (ppp->rc_state && (ppp->rstate & SC_DECOMP_RUN) &&\n\t    (ppp->rstate & (SC_DC_FERROR | SC_DC_ERROR)) == 0)\n\t\tskb = ppp_decompress_frame(ppp, skb);\n\n\tif (ppp->flags & SC_MUST_COMP && ppp->rstate & SC_DC_FERROR)\n\t\tgoto err;\n\n\tproto = PPP_PROTO(skb);\n\tswitch (proto) {\n\tcase PPP_VJC_COMP:\n\t\t/* decompress VJ compressed packets */\n\t\tif (!ppp->vj || (ppp->flags & SC_REJ_COMP_TCP))\n\t\t\tgoto err;\n\n\t\tif (skb_tailroom(skb) < 124 || skb_cloned(skb)) {\n\t\t\t/* copy to a new sk_buff with more tailroom */\n\t\t\tns = dev_alloc_skb(skb->len + 128);\n\t\t\tif (!ns) {\n\t\t\t\tnetdev_err(ppp->dev, \"PPP: no memory \"\n\t\t\t\t\t   \"(VJ decomp)\\n\");\n\t\t\t\tgoto err;\n\t\t\t}\n\t\t\tskb_reserve(ns, 2);\n\t\t\tskb_copy_bits(skb, 0, skb_put(ns, skb->len), skb->len);\n\t\t\tconsume_skb(skb);\n\t\t\tskb = ns;\n\t\t}\n\t\telse\n\t\t\tskb->ip_summed = CHECKSUM_NONE;\n\n\t\tlen = slhc_uncompress(ppp->vj, skb->data + 2, skb->len - 2);\n\t\tif (len <= 0) {\n\t\t\tnetdev_printk(KERN_DEBUG, ppp->dev,\n\t\t\t\t      \"PPP: VJ decompression error\\n\");\n\t\t\tgoto err;\n\t\t}\n\t\tlen += 2;\n\t\tif (len > skb->len)\n\t\t\tskb_put(skb, len - skb->len);\n\t\telse if (len < skb->len)\n\t\t\tskb_trim(skb, len);\n\t\tproto = PPP_IP;\n\t\tbreak;\n\n\tcase PPP_VJC_UNCOMP:\n\t\tif (!ppp->vj || (ppp->flags & SC_REJ_COMP_TCP))\n\t\t\tgoto err;\n\n\t\t/* Until we fix the decompressor need to make sure\n\t\t * data portion is linear.\n\t\t */\n\t\tif (!pskb_may_pull(skb, skb->len))\n\t\t\tgoto err;\n\n\t\tif (slhc_remember(ppp->vj, skb->data + 2, skb->len - 2) <= 0) {\n\t\t\tnetdev_err(ppp->dev, \"PPP: VJ uncompressed error\\n\");\n\t\t\tgoto err;\n\t\t}\n\t\tproto = PPP_IP;\n\t\tbreak;\n\n\tcase PPP_CCP:\n\t\tppp_ccp_peek(ppp, skb, 1);\n\t\tbreak;\n\t}\n\n\t++ppp->stats64.rx_packets;\n\tppp->stats64.rx_bytes += skb->len - 2;\n\n\tnpi = proto_to_npindex(proto);\n\tif (npi < 0) {\n\t\t/* control or unknown frame - pass it to pppd */\n\t\tskb_queue_tail(&ppp->file.rq, skb);\n\t\t/* limit queue length by dropping old frames */\n\t\twhile (ppp->file.rq.qlen > PPP_MAX_RQLEN &&\n\t\t       (skb = skb_dequeue(&ppp->file.rq)))\n\t\t\tkfree_skb(skb);\n\t\t/* wake up any process polling or blocking on read */\n\t\twake_up_interruptible(&ppp->file.rwait);\n\n\t} else {\n\t\t/* network protocol frame - give it to the kernel */\n\n#ifdef CONFIG_PPP_FILTER\n\t\t/* check if the packet passes the pass and active filters */\n\t\t/* the filter instructions are constructed assuming\n\t\t   a four-byte PPP header on each packet */\n\t\tif (ppp->pass_filter || ppp->active_filter) {\n\t\t\tif (skb_unclone(skb, GFP_ATOMIC))\n\t\t\t\tgoto err;\n\n\t\t\t*skb_push(skb, 2) = 0;\n\t\t\tif (ppp->pass_filter &&\n\t\t\t    BPF_PROG_RUN(ppp->pass_filter, skb) == 0) {\n\t\t\t\tif (ppp->debug & 1)\n\t\t\t\t\tnetdev_printk(KERN_DEBUG, ppp->dev,\n\t\t\t\t\t\t      \"PPP: inbound frame \"\n\t\t\t\t\t\t      \"not passed\\n\");\n\t\t\t\tkfree_skb(skb);\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tif (!(ppp->active_filter &&\n\t\t\t      BPF_PROG_RUN(ppp->active_filter, skb) == 0))\n\t\t\t\tppp->last_recv = jiffies;\n\t\t\t__skb_pull(skb, 2);\n\t\t} else\n#endif /* CONFIG_PPP_FILTER */\n\t\t\tppp->last_recv = jiffies;\n\n\t\tif ((ppp->dev->flags & IFF_UP) == 0 ||\n\t\t    ppp->npmode[npi] != NPMODE_PASS) {\n\t\t\tkfree_skb(skb);\n\t\t} else {\n\t\t\t/* chop off protocol */\n\t\t\tskb_pull_rcsum(skb, 2);\n\t\t\tskb->dev = ppp->dev;\n\t\t\tskb->protocol = htons(npindex_to_ethertype[npi]);\n\t\t\tskb_reset_mac_header(skb);\n\t\t\tskb_scrub_packet(skb, !net_eq(ppp->ppp_net,\n\t\t\t\t\t\t      dev_net(ppp->dev)));\n\t\t\tnetif_rx(skb);\n\t\t}\n\t}\n\treturn;\n\n err:\n\tkfree_skb(skb);\n\tppp_receive_error(ppp);\n}\n\nstatic struct sk_buff *\nppp_decompress_frame(struct ppp *ppp, struct sk_buff *skb)\n{\n\tint proto = PPP_PROTO(skb);\n\tstruct sk_buff *ns;\n\tint len;\n\n\t/* Until we fix all the decompressor's need to make sure\n\t * data portion is linear.\n\t */\n\tif (!pskb_may_pull(skb, skb->len))\n\t\tgoto err;\n\n\tif (proto == PPP_COMP) {\n\t\tint obuff_size;\n\n\t\tswitch(ppp->rcomp->compress_proto) {\n\t\tcase CI_MPPE:\n\t\t\tobuff_size = ppp->mru + PPP_HDRLEN + 1;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tobuff_size = ppp->mru + PPP_HDRLEN;\n\t\t\tbreak;\n\t\t}\n\n\t\tns = dev_alloc_skb(obuff_size);\n\t\tif (!ns) {\n\t\t\tnetdev_err(ppp->dev, \"ppp_decompress_frame: \"\n\t\t\t\t   \"no memory\\n\");\n\t\t\tgoto err;\n\t\t}\n\t\t/* the decompressor still expects the A/C bytes in the hdr */\n\t\tlen = ppp->rcomp->decompress(ppp->rc_state, skb->data - 2,\n\t\t\t\tskb->len + 2, ns->data, obuff_size);\n\t\tif (len < 0) {\n\t\t\t/* Pass the compressed frame to pppd as an\n\t\t\t   error indication. */\n\t\t\tif (len == DECOMP_FATALERROR)\n\t\t\t\tppp->rstate |= SC_DC_FERROR;\n\t\t\tkfree_skb(ns);\n\t\t\tgoto err;\n\t\t}\n\n\t\tconsume_skb(skb);\n\t\tskb = ns;\n\t\tskb_put(skb, len);\n\t\tskb_pull(skb, 2);\t/* pull off the A/C bytes */\n\n\t} else {\n\t\t/* Uncompressed frame - pass to decompressor so it\n\t\t   can update its dictionary if necessary. */\n\t\tif (ppp->rcomp->incomp)\n\t\t\tppp->rcomp->incomp(ppp->rc_state, skb->data - 2,\n\t\t\t\t\t   skb->len + 2);\n\t}\n\n\treturn skb;\n\n err:\n\tppp->rstate |= SC_DC_ERROR;\n\tppp_receive_error(ppp);\n\treturn skb;\n}\n\n#ifdef CONFIG_PPP_MULTILINK\n/*\n * Receive a multilink frame.\n * We put it on the reconstruction queue and then pull off\n * as many completed frames as we can.\n */\nstatic void\nppp_receive_mp_frame(struct ppp *ppp, struct sk_buff *skb, struct channel *pch)\n{\n\tu32 mask, seq;\n\tstruct channel *ch;\n\tint mphdrlen = (ppp->flags & SC_MP_SHORTSEQ)? MPHDRLEN_SSN: MPHDRLEN;\n\n\tif (!pskb_may_pull(skb, mphdrlen + 1) || ppp->mrru == 0)\n\t\tgoto err;\t\t/* no good, throw it away */\n\n\t/* Decode sequence number and begin/end bits */\n\tif (ppp->flags & SC_MP_SHORTSEQ) {\n\t\tseq = ((skb->data[2] & 0x0f) << 8) | skb->data[3];\n\t\tmask = 0xfff;\n\t} else {\n\t\tseq = (skb->data[3] << 16) | (skb->data[4] << 8)| skb->data[5];\n\t\tmask = 0xffffff;\n\t}\n\tPPP_MP_CB(skb)->BEbits = skb->data[2];\n\tskb_pull(skb, mphdrlen);\t/* pull off PPP and MP headers */\n\n\t/*\n\t * Do protocol ID decompression on the first fragment of each packet.\n\t */\n\tif ((PPP_MP_CB(skb)->BEbits & B) && (skb->data[0] & 1))\n\t\t*skb_push(skb, 1) = 0;\n\n\t/*\n\t * Expand sequence number to 32 bits, making it as close\n\t * as possible to ppp->minseq.\n\t */\n\tseq |= ppp->minseq & ~mask;\n\tif ((int)(ppp->minseq - seq) > (int)(mask >> 1))\n\t\tseq += mask + 1;\n\telse if ((int)(seq - ppp->minseq) > (int)(mask >> 1))\n\t\tseq -= mask + 1;\t/* should never happen */\n\tPPP_MP_CB(skb)->sequence = seq;\n\tpch->lastseq = seq;\n\n\t/*\n\t * If this packet comes before the next one we were expecting,\n\t * drop it.\n\t */\n\tif (seq_before(seq, ppp->nextseq)) {\n\t\tkfree_skb(skb);\n\t\t++ppp->dev->stats.rx_dropped;\n\t\tppp_receive_error(ppp);\n\t\treturn;\n\t}\n\n\t/*\n\t * Reevaluate minseq, the minimum over all channels of the\n\t * last sequence number received on each channel.  Because of\n\t * the increasing sequence number rule, we know that any fragment\n\t * before `minseq' which hasn't arrived is never going to arrive.\n\t * The list of channels can't change because we have the receive\n\t * side of the ppp unit locked.\n\t */\n\tlist_for_each_entry(ch, &ppp->channels, clist) {\n\t\tif (seq_before(ch->lastseq, seq))\n\t\t\tseq = ch->lastseq;\n\t}\n\tif (seq_before(ppp->minseq, seq))\n\t\tppp->minseq = seq;\n\n\t/* Put the fragment on the reconstruction queue */\n\tppp_mp_insert(ppp, skb);\n\n\t/* If the queue is getting long, don't wait any longer for packets\n\t   before the start of the queue. */\n\tif (skb_queue_len(&ppp->mrq) >= PPP_MP_MAX_QLEN) {\n\t\tstruct sk_buff *mskb = skb_peek(&ppp->mrq);\n\t\tif (seq_before(ppp->minseq, PPP_MP_CB(mskb)->sequence))\n\t\t\tppp->minseq = PPP_MP_CB(mskb)->sequence;\n\t}\n\n\t/* Pull completed packets off the queue and receive them. */\n\twhile ((skb = ppp_mp_reconstruct(ppp))) {\n\t\tif (pskb_may_pull(skb, 2))\n\t\t\tppp_receive_nonmp_frame(ppp, skb);\n\t\telse {\n\t\t\t++ppp->dev->stats.rx_length_errors;\n\t\t\tkfree_skb(skb);\n\t\t\tppp_receive_error(ppp);\n\t\t}\n\t}\n\n\treturn;\n\n err:\n\tkfree_skb(skb);\n\tppp_receive_error(ppp);\n}\n\n/*\n * Insert a fragment on the MP reconstruction queue.\n * The queue is ordered by increasing sequence number.\n */\nstatic void\nppp_mp_insert(struct ppp *ppp, struct sk_buff *skb)\n{\n\tstruct sk_buff *p;\n\tstruct sk_buff_head *list = &ppp->mrq;\n\tu32 seq = PPP_MP_CB(skb)->sequence;\n\n\t/* N.B. we don't need to lock the list lock because we have the\n\t   ppp unit receive-side lock. */\n\tskb_queue_walk(list, p) {\n\t\tif (seq_before(seq, PPP_MP_CB(p)->sequence))\n\t\t\tbreak;\n\t}\n\t__skb_queue_before(list, p, skb);\n}\n\n/*\n * Reconstruct a packet from the MP fragment queue.\n * We go through increasing sequence numbers until we find a\n * complete packet, or we get to the sequence number for a fragment\n * which hasn't arrived but might still do so.\n */\nstatic struct sk_buff *\nppp_mp_reconstruct(struct ppp *ppp)\n{\n\tu32 seq = ppp->nextseq;\n\tu32 minseq = ppp->minseq;\n\tstruct sk_buff_head *list = &ppp->mrq;\n\tstruct sk_buff *p, *tmp;\n\tstruct sk_buff *head, *tail;\n\tstruct sk_buff *skb = NULL;\n\tint lost = 0, len = 0;\n\n\tif (ppp->mrru == 0)\t/* do nothing until mrru is set */\n\t\treturn NULL;\n\thead = list->next;\n\ttail = NULL;\n\tskb_queue_walk_safe(list, p, tmp) {\n\tagain:\n\t\tif (seq_before(PPP_MP_CB(p)->sequence, seq)) {\n\t\t\t/* this can't happen, anyway ignore the skb */\n\t\t\tnetdev_err(ppp->dev, \"ppp_mp_reconstruct bad \"\n\t\t\t\t   \"seq %u < %u\\n\",\n\t\t\t\t   PPP_MP_CB(p)->sequence, seq);\n\t\t\t__skb_unlink(p, list);\n\t\t\tkfree_skb(p);\n\t\t\tcontinue;\n\t\t}\n\t\tif (PPP_MP_CB(p)->sequence != seq) {\n\t\t\tu32 oldseq;\n\t\t\t/* Fragment `seq' is missing.  If it is after\n\t\t\t   minseq, it might arrive later, so stop here. */\n\t\t\tif (seq_after(seq, minseq))\n\t\t\t\tbreak;\n\t\t\t/* Fragment `seq' is lost, keep going. */\n\t\t\tlost = 1;\n\t\t\toldseq = seq;\n\t\t\tseq = seq_before(minseq, PPP_MP_CB(p)->sequence)?\n\t\t\t\tminseq + 1: PPP_MP_CB(p)->sequence;\n\n\t\t\tif (ppp->debug & 1)\n\t\t\t\tnetdev_printk(KERN_DEBUG, ppp->dev,\n\t\t\t\t\t      \"lost frag %u..%u\\n\",\n\t\t\t\t\t      oldseq, seq-1);\n\n\t\t\tgoto again;\n\t\t}\n\n\t\t/*\n\t\t * At this point we know that all the fragments from\n\t\t * ppp->nextseq to seq are either present or lost.\n\t\t * Also, there are no complete packets in the queue\n\t\t * that have no missing fragments and end before this\n\t\t * fragment.\n\t\t */\n\n\t\t/* B bit set indicates this fragment starts a packet */\n\t\tif (PPP_MP_CB(p)->BEbits & B) {\n\t\t\thead = p;\n\t\t\tlost = 0;\n\t\t\tlen = 0;\n\t\t}\n\n\t\tlen += p->len;\n\n\t\t/* Got a complete packet yet? */\n\t\tif (lost == 0 && (PPP_MP_CB(p)->BEbits & E) &&\n\t\t    (PPP_MP_CB(head)->BEbits & B)) {\n\t\t\tif (len > ppp->mrru + 2) {\n\t\t\t\t++ppp->dev->stats.rx_length_errors;\n\t\t\t\tnetdev_printk(KERN_DEBUG, ppp->dev,\n\t\t\t\t\t      \"PPP: reconstructed packet\"\n\t\t\t\t\t      \" is too long (%d)\\n\", len);\n\t\t\t} else {\n\t\t\t\ttail = p;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tppp->nextseq = seq + 1;\n\t\t}\n\n\t\t/*\n\t\t * If this is the ending fragment of a packet,\n\t\t * and we haven't found a complete valid packet yet,\n\t\t * we can discard up to and including this fragment.\n\t\t */\n\t\tif (PPP_MP_CB(p)->BEbits & E) {\n\t\t\tstruct sk_buff *tmp2;\n\n\t\t\tskb_queue_reverse_walk_from_safe(list, p, tmp2) {\n\t\t\t\tif (ppp->debug & 1)\n\t\t\t\t\tnetdev_printk(KERN_DEBUG, ppp->dev,\n\t\t\t\t\t\t      \"discarding frag %u\\n\",\n\t\t\t\t\t\t      PPP_MP_CB(p)->sequence);\n\t\t\t\t__skb_unlink(p, list);\n\t\t\t\tkfree_skb(p);\n\t\t\t}\n\t\t\thead = skb_peek(list);\n\t\t\tif (!head)\n\t\t\t\tbreak;\n\t\t}\n\t\t++seq;\n\t}\n\n\t/* If we have a complete packet, copy it all into one skb. */\n\tif (tail != NULL) {\n\t\t/* If we have discarded any fragments,\n\t\t   signal a receive error. */\n\t\tif (PPP_MP_CB(head)->sequence != ppp->nextseq) {\n\t\t\tskb_queue_walk_safe(list, p, tmp) {\n\t\t\t\tif (p == head)\n\t\t\t\t\tbreak;\n\t\t\t\tif (ppp->debug & 1)\n\t\t\t\t\tnetdev_printk(KERN_DEBUG, ppp->dev,\n\t\t\t\t\t\t      \"discarding frag %u\\n\",\n\t\t\t\t\t\t      PPP_MP_CB(p)->sequence);\n\t\t\t\t__skb_unlink(p, list);\n\t\t\t\tkfree_skb(p);\n\t\t\t}\n\n\t\t\tif (ppp->debug & 1)\n\t\t\t\tnetdev_printk(KERN_DEBUG, ppp->dev,\n\t\t\t\t\t      \"  missed pkts %u..%u\\n\",\n\t\t\t\t\t      ppp->nextseq,\n\t\t\t\t\t      PPP_MP_CB(head)->sequence-1);\n\t\t\t++ppp->dev->stats.rx_dropped;\n\t\t\tppp_receive_error(ppp);\n\t\t}\n\n\t\tskb = head;\n\t\tif (head != tail) {\n\t\t\tstruct sk_buff **fragpp = &skb_shinfo(skb)->frag_list;\n\t\t\tp = skb_queue_next(list, head);\n\t\t\t__skb_unlink(skb, list);\n\t\t\tskb_queue_walk_from_safe(list, p, tmp) {\n\t\t\t\t__skb_unlink(p, list);\n\t\t\t\t*fragpp = p;\n\t\t\t\tp->next = NULL;\n\t\t\t\tfragpp = &p->next;\n\n\t\t\t\tskb->len += p->len;\n\t\t\t\tskb->data_len += p->len;\n\t\t\t\tskb->truesize += p->truesize;\n\n\t\t\t\tif (p == tail)\n\t\t\t\t\tbreak;\n\t\t\t}\n\t\t} else {\n\t\t\t__skb_unlink(skb, list);\n\t\t}\n\n\t\tppp->nextseq = PPP_MP_CB(tail)->sequence + 1;\n\t}\n\n\treturn skb;\n}\n#endif /* CONFIG_PPP_MULTILINK */\n\n/*\n * Channel interface.\n */\n\n/* Create a new, unattached ppp channel. */\nint ppp_register_channel(struct ppp_channel *chan)\n{\n\treturn ppp_register_net_channel(current->nsproxy->net_ns, chan);\n}\n\n/* Create a new, unattached ppp channel for specified net. */\nint ppp_register_net_channel(struct net *net, struct ppp_channel *chan)\n{\n\tstruct channel *pch;\n\tstruct ppp_net *pn;\n\n\tpch = kzalloc(sizeof(struct channel), GFP_KERNEL);\n\tif (!pch)\n\t\treturn -ENOMEM;\n\n\tpn = ppp_pernet(net);\n\n\tpch->ppp = NULL;\n\tpch->chan = chan;\n\tpch->chan_net = get_net(net);\n\tchan->ppp = pch;\n\tinit_ppp_file(&pch->file, CHANNEL);\n\tpch->file.hdrlen = chan->hdrlen;\n#ifdef CONFIG_PPP_MULTILINK\n\tpch->lastseq = -1;\n#endif /* CONFIG_PPP_MULTILINK */\n\tinit_rwsem(&pch->chan_sem);\n\tspin_lock_init(&pch->downl);\n\trwlock_init(&pch->upl);\n\n\tspin_lock_bh(&pn->all_channels_lock);\n\tpch->file.index = ++pn->last_channel_index;\n\tlist_add(&pch->list, &pn->new_channels);\n\tatomic_inc(&channel_count);\n\tspin_unlock_bh(&pn->all_channels_lock);\n\n\treturn 0;\n}\n\n/*\n * Return the index of a channel.\n */\nint ppp_channel_index(struct ppp_channel *chan)\n{\n\tstruct channel *pch = chan->ppp;\n\n\tif (pch)\n\t\treturn pch->file.index;\n\treturn -1;\n}\n\n/*\n * Return the PPP unit number to which a channel is connected.\n */\nint ppp_unit_number(struct ppp_channel *chan)\n{\n\tstruct channel *pch = chan->ppp;\n\tint unit = -1;\n\n\tif (pch) {\n\t\tread_lock_bh(&pch->upl);\n\t\tif (pch->ppp)\n\t\t\tunit = pch->ppp->file.index;\n\t\tread_unlock_bh(&pch->upl);\n\t}\n\treturn unit;\n}\n\n/*\n * Return the PPP device interface name of a channel.\n */\nchar *ppp_dev_name(struct ppp_channel *chan)\n{\n\tstruct channel *pch = chan->ppp;\n\tchar *name = NULL;\n\n\tif (pch) {\n\t\tread_lock_bh(&pch->upl);\n\t\tif (pch->ppp && pch->ppp->dev)\n\t\t\tname = pch->ppp->dev->name;\n\t\tread_unlock_bh(&pch->upl);\n\t}\n\treturn name;\n}\n\n\n/*\n * Disconnect a channel from the generic layer.\n * This must be called in process context.\n */\nvoid\nppp_unregister_channel(struct ppp_channel *chan)\n{\n\tstruct channel *pch = chan->ppp;\n\tstruct ppp_net *pn;\n\n\tif (!pch)\n\t\treturn;\t\t/* should never happen */\n\n\tchan->ppp = NULL;\n\n\t/*\n\t * This ensures that we have returned from any calls into the\n\t * the channel's start_xmit or ioctl routine before we proceed.\n\t */\n\tdown_write(&pch->chan_sem);\n\tspin_lock_bh(&pch->downl);\n\tpch->chan = NULL;\n\tspin_unlock_bh(&pch->downl);\n\tup_write(&pch->chan_sem);\n\tppp_disconnect_channel(pch);\n\n\tpn = ppp_pernet(pch->chan_net);\n\tspin_lock_bh(&pn->all_channels_lock);\n\tlist_del(&pch->list);\n\tspin_unlock_bh(&pn->all_channels_lock);\n\tput_net(pch->chan_net);\n\tpch->chan_net = NULL;\n\n\tpch->file.dead = 1;\n\twake_up_interruptible(&pch->file.rwait);\n\tif (atomic_dec_and_test(&pch->file.refcnt))\n\t\tppp_destroy_channel(pch);\n}\n\n/*\n * Callback from a channel when it can accept more to transmit.\n * This should be called at BH/softirq level, not interrupt level.\n */\nvoid\nppp_output_wakeup(struct ppp_channel *chan)\n{\n\tstruct channel *pch = chan->ppp;\n\n\tif (!pch)\n\t\treturn;\n\tppp_channel_push(pch);\n}\n\n/*\n * Compression control.\n */\n\n/* Process the PPPIOCSCOMPRESS ioctl. */\nstatic int\nppp_set_compress(struct ppp *ppp, unsigned long arg)\n{\n\tint err;\n\tstruct compressor *cp, *ocomp;\n\tstruct ppp_option_data data;\n\tvoid *state, *ostate;\n\tunsigned char ccp_option[CCP_MAX_OPTION_LENGTH];\n\n\terr = -EFAULT;\n\tif (copy_from_user(&data, (void __user *) arg, sizeof(data)))\n\t\tgoto out;\n\tif (data.length > CCP_MAX_OPTION_LENGTH)\n\t\tgoto out;\n\tif (copy_from_user(ccp_option, (void __user *) data.ptr, data.length))\n\t\tgoto out;\n\n\terr = -EINVAL;\n\tif (data.length < 2 || ccp_option[1] < 2 || ccp_option[1] > data.length)\n\t\tgoto out;\n\n\tcp = try_then_request_module(\n\t\tfind_compressor(ccp_option[0]),\n\t\t\"ppp-compress-%d\", ccp_option[0]);\n\tif (!cp)\n\t\tgoto out;\n\n\terr = -ENOBUFS;\n\tif (data.transmit) {\n\t\tstate = cp->comp_alloc(ccp_option, data.length);\n\t\tif (state) {\n\t\t\tppp_xmit_lock(ppp);\n\t\t\tppp->xstate &= ~SC_COMP_RUN;\n\t\t\tocomp = ppp->xcomp;\n\t\t\tostate = ppp->xc_state;\n\t\t\tppp->xcomp = cp;\n\t\t\tppp->xc_state = state;\n\t\t\tppp_xmit_unlock(ppp);\n\t\t\tif (ostate) {\n\t\t\t\tocomp->comp_free(ostate);\n\t\t\t\tmodule_put(ocomp->owner);\n\t\t\t}\n\t\t\terr = 0;\n\t\t} else\n\t\t\tmodule_put(cp->owner);\n\n\t} else {\n\t\tstate = cp->decomp_alloc(ccp_option, data.length);\n\t\tif (state) {\n\t\t\tppp_recv_lock(ppp);\n\t\t\tppp->rstate &= ~SC_DECOMP_RUN;\n\t\t\tocomp = ppp->rcomp;\n\t\t\tostate = ppp->rc_state;\n\t\t\tppp->rcomp = cp;\n\t\t\tppp->rc_state = state;\n\t\t\tppp_recv_unlock(ppp);\n\t\t\tif (ostate) {\n\t\t\t\tocomp->decomp_free(ostate);\n\t\t\t\tmodule_put(ocomp->owner);\n\t\t\t}\n\t\t\terr = 0;\n\t\t} else\n\t\t\tmodule_put(cp->owner);\n\t}\n\n out:\n\treturn err;\n}\n\n/*\n * Look at a CCP packet and update our state accordingly.\n * We assume the caller has the xmit or recv path locked.\n */\nstatic void\nppp_ccp_peek(struct ppp *ppp, struct sk_buff *skb, int inbound)\n{\n\tunsigned char *dp;\n\tint len;\n\n\tif (!pskb_may_pull(skb, CCP_HDRLEN + 2))\n\t\treturn;\t/* no header */\n\tdp = skb->data + 2;\n\n\tswitch (CCP_CODE(dp)) {\n\tcase CCP_CONFREQ:\n\n\t\t/* A ConfReq starts negotiation of compression\n\t\t * in one direction of transmission,\n\t\t * and hence brings it down...but which way?\n\t\t *\n\t\t * Remember:\n\t\t * A ConfReq indicates what the sender would like to receive\n\t\t */\n\t\tif(inbound)\n\t\t\t/* He is proposing what I should send */\n\t\t\tppp->xstate &= ~SC_COMP_RUN;\n\t\telse\n\t\t\t/* I am proposing to what he should send */\n\t\t\tppp->rstate &= ~SC_DECOMP_RUN;\n\n\t\tbreak;\n\n\tcase CCP_TERMREQ:\n\tcase CCP_TERMACK:\n\t\t/*\n\t\t * CCP is going down, both directions of transmission\n\t\t */\n\t\tppp->rstate &= ~SC_DECOMP_RUN;\n\t\tppp->xstate &= ~SC_COMP_RUN;\n\t\tbreak;\n\n\tcase CCP_CONFACK:\n\t\tif ((ppp->flags & (SC_CCP_OPEN | SC_CCP_UP)) != SC_CCP_OPEN)\n\t\t\tbreak;\n\t\tlen = CCP_LENGTH(dp);\n\t\tif (!pskb_may_pull(skb, len + 2))\n\t\t\treturn;\t\t/* too short */\n\t\tdp += CCP_HDRLEN;\n\t\tlen -= CCP_HDRLEN;\n\t\tif (len < CCP_OPT_MINLEN || len < CCP_OPT_LENGTH(dp))\n\t\t\tbreak;\n\t\tif (inbound) {\n\t\t\t/* we will start receiving compressed packets */\n\t\t\tif (!ppp->rc_state)\n\t\t\t\tbreak;\n\t\t\tif (ppp->rcomp->decomp_init(ppp->rc_state, dp, len,\n\t\t\t\t\tppp->file.index, 0, ppp->mru, ppp->debug)) {\n\t\t\t\tppp->rstate |= SC_DECOMP_RUN;\n\t\t\t\tppp->rstate &= ~(SC_DC_ERROR | SC_DC_FERROR);\n\t\t\t}\n\t\t} else {\n\t\t\t/* we will soon start sending compressed packets */\n\t\t\tif (!ppp->xc_state)\n\t\t\t\tbreak;\n\t\t\tif (ppp->xcomp->comp_init(ppp->xc_state, dp, len,\n\t\t\t\t\tppp->file.index, 0, ppp->debug))\n\t\t\t\tppp->xstate |= SC_COMP_RUN;\n\t\t}\n\t\tbreak;\n\n\tcase CCP_RESETACK:\n\t\t/* reset the [de]compressor */\n\t\tif ((ppp->flags & SC_CCP_UP) == 0)\n\t\t\tbreak;\n\t\tif (inbound) {\n\t\t\tif (ppp->rc_state && (ppp->rstate & SC_DECOMP_RUN)) {\n\t\t\t\tppp->rcomp->decomp_reset(ppp->rc_state);\n\t\t\t\tppp->rstate &= ~SC_DC_ERROR;\n\t\t\t}\n\t\t} else {\n\t\t\tif (ppp->xc_state && (ppp->xstate & SC_COMP_RUN))\n\t\t\t\tppp->xcomp->comp_reset(ppp->xc_state);\n\t\t}\n\t\tbreak;\n\t}\n}\n\n/* Free up compression resources. */\nstatic void\nppp_ccp_closed(struct ppp *ppp)\n{\n\tvoid *xstate, *rstate;\n\tstruct compressor *xcomp, *rcomp;\n\n\tppp_lock(ppp);\n\tppp->flags &= ~(SC_CCP_OPEN | SC_CCP_UP);\n\tppp->xstate = 0;\n\txcomp = ppp->xcomp;\n\txstate = ppp->xc_state;\n\tppp->xc_state = NULL;\n\tppp->rstate = 0;\n\trcomp = ppp->rcomp;\n\trstate = ppp->rc_state;\n\tppp->rc_state = NULL;\n\tppp_unlock(ppp);\n\n\tif (xstate) {\n\t\txcomp->comp_free(xstate);\n\t\tmodule_put(xcomp->owner);\n\t}\n\tif (rstate) {\n\t\trcomp->decomp_free(rstate);\n\t\tmodule_put(rcomp->owner);\n\t}\n}\n\n/* List of compressors. */\nstatic LIST_HEAD(compressor_list);\nstatic DEFINE_SPINLOCK(compressor_list_lock);\n\nstruct compressor_entry {\n\tstruct list_head list;\n\tstruct compressor *comp;\n};\n\nstatic struct compressor_entry *\nfind_comp_entry(int proto)\n{\n\tstruct compressor_entry *ce;\n\n\tlist_for_each_entry(ce, &compressor_list, list) {\n\t\tif (ce->comp->compress_proto == proto)\n\t\t\treturn ce;\n\t}\n\treturn NULL;\n}\n\n/* Register a compressor */\nint\nppp_register_compressor(struct compressor *cp)\n{\n\tstruct compressor_entry *ce;\n\tint ret;\n\tspin_lock(&compressor_list_lock);\n\tret = -EEXIST;\n\tif (find_comp_entry(cp->compress_proto))\n\t\tgoto out;\n\tret = -ENOMEM;\n\tce = kmalloc(sizeof(struct compressor_entry), GFP_ATOMIC);\n\tif (!ce)\n\t\tgoto out;\n\tret = 0;\n\tce->comp = cp;\n\tlist_add(&ce->list, &compressor_list);\n out:\n\tspin_unlock(&compressor_list_lock);\n\treturn ret;\n}\n\n/* Unregister a compressor */\nvoid\nppp_unregister_compressor(struct compressor *cp)\n{\n\tstruct compressor_entry *ce;\n\n\tspin_lock(&compressor_list_lock);\n\tce = find_comp_entry(cp->compress_proto);\n\tif (ce && ce->comp == cp) {\n\t\tlist_del(&ce->list);\n\t\tkfree(ce);\n\t}\n\tspin_unlock(&compressor_list_lock);\n}\n\n/* Find a compressor. */\nstatic struct compressor *\nfind_compressor(int type)\n{\n\tstruct compressor_entry *ce;\n\tstruct compressor *cp = NULL;\n\n\tspin_lock(&compressor_list_lock);\n\tce = find_comp_entry(type);\n\tif (ce) {\n\t\tcp = ce->comp;\n\t\tif (!try_module_get(cp->owner))\n\t\t\tcp = NULL;\n\t}\n\tspin_unlock(&compressor_list_lock);\n\treturn cp;\n}\n\n/*\n * Miscelleneous stuff.\n */\n\nstatic void\nppp_get_stats(struct ppp *ppp, struct ppp_stats *st)\n{\n\tstruct slcompress *vj = ppp->vj;\n\n\tmemset(st, 0, sizeof(*st));\n\tst->p.ppp_ipackets = ppp->stats64.rx_packets;\n\tst->p.ppp_ierrors = ppp->dev->stats.rx_errors;\n\tst->p.ppp_ibytes = ppp->stats64.rx_bytes;\n\tst->p.ppp_opackets = ppp->stats64.tx_packets;\n\tst->p.ppp_oerrors = ppp->dev->stats.tx_errors;\n\tst->p.ppp_obytes = ppp->stats64.tx_bytes;\n\tif (!vj)\n\t\treturn;\n\tst->vj.vjs_packets = vj->sls_o_compressed + vj->sls_o_uncompressed;\n\tst->vj.vjs_compressed = vj->sls_o_compressed;\n\tst->vj.vjs_searches = vj->sls_o_searches;\n\tst->vj.vjs_misses = vj->sls_o_misses;\n\tst->vj.vjs_errorin = vj->sls_i_error;\n\tst->vj.vjs_tossed = vj->sls_i_tossed;\n\tst->vj.vjs_uncompressedin = vj->sls_i_uncompressed;\n\tst->vj.vjs_compressedin = vj->sls_i_compressed;\n}\n\n/*\n * Stuff for handling the lists of ppp units and channels\n * and for initialization.\n */\n\n/*\n * Create a new ppp interface unit.  Fails if it can't allocate memory\n * or if there is already a unit with the requested number.\n * unit == -1 means allocate a new number.\n */\nstatic struct ppp *ppp_create_interface(struct net *net, int unit,\n\t\t\t\t\tstruct file *file, int *retp)\n{\n\tstruct ppp *ppp;\n\tstruct ppp_net *pn;\n\tstruct net_device *dev = NULL;\n\tint ret = -ENOMEM;\n\tint i;\n\n\tdev = alloc_netdev(sizeof(struct ppp), \"\", NET_NAME_ENUM, ppp_setup);\n\tif (!dev)\n\t\tgoto out1;\n\n\tpn = ppp_pernet(net);\n\n\tppp = netdev_priv(dev);\n\tppp->dev = dev;\n\tppp->mru = PPP_MRU;\n\tinit_ppp_file(&ppp->file, INTERFACE);\n\tppp->file.hdrlen = PPP_HDRLEN - 2;\t/* don't count proto bytes */\n\tppp->owner = file;\n\tfor (i = 0; i < NUM_NP; ++i)\n\t\tppp->npmode[i] = NPMODE_PASS;\n\tINIT_LIST_HEAD(&ppp->channels);\n\tspin_lock_init(&ppp->rlock);\n\tspin_lock_init(&ppp->wlock);\n#ifdef CONFIG_PPP_MULTILINK\n\tppp->minseq = -1;\n\tskb_queue_head_init(&ppp->mrq);\n#endif /* CONFIG_PPP_MULTILINK */\n#ifdef CONFIG_PPP_FILTER\n\tppp->pass_filter = NULL;\n\tppp->active_filter = NULL;\n#endif /* CONFIG_PPP_FILTER */\n\n\t/*\n\t * drum roll: don't forget to set\n\t * the net device is belong to\n\t */\n\tdev_net_set(dev, net);\n\n\trtnl_lock();\n\tmutex_lock(&pn->all_ppp_mutex);\n\n\tif (unit < 0) {\n\t\tunit = unit_get(&pn->units_idr, ppp);\n\t\tif (unit < 0) {\n\t\t\tret = unit;\n\t\t\tgoto out2;\n\t\t}\n\t} else {\n\t\tret = -EEXIST;\n\t\tif (unit_find(&pn->units_idr, unit))\n\t\t\tgoto out2; /* unit already exists */\n\t\t/*\n\t\t * if caller need a specified unit number\n\t\t * lets try to satisfy him, otherwise --\n\t\t * he should better ask us for new unit number\n\t\t *\n\t\t * NOTE: yes I know that returning EEXIST it's not\n\t\t * fair but at least pppd will ask us to allocate\n\t\t * new unit in this case so user is happy :)\n\t\t */\n\t\tunit = unit_set(&pn->units_idr, ppp, unit);\n\t\tif (unit < 0)\n\t\t\tgoto out2;\n\t}\n\n\t/* Initialize the new ppp unit */\n\tppp->file.index = unit;\n\tsprintf(dev->name, \"ppp%d\", unit);\n\n\tret = register_netdevice(dev);\n\tif (ret != 0) {\n\t\tunit_put(&pn->units_idr, unit);\n\t\tnetdev_err(ppp->dev, \"PPP: couldn't register device %s (%d)\\n\",\n\t\t\t   dev->name, ret);\n\t\tgoto out2;\n\t}\n\n\tppp->ppp_net = net;\n\n\tatomic_inc(&ppp_unit_count);\n\tmutex_unlock(&pn->all_ppp_mutex);\n\trtnl_unlock();\n\n\t*retp = 0;\n\treturn ppp;\n\nout2:\n\tmutex_unlock(&pn->all_ppp_mutex);\n\trtnl_unlock();\n\tfree_netdev(dev);\nout1:\n\t*retp = ret;\n\treturn NULL;\n}\n\n/*\n * Initialize a ppp_file structure.\n */\nstatic void\ninit_ppp_file(struct ppp_file *pf, int kind)\n{\n\tpf->kind = kind;\n\tskb_queue_head_init(&pf->xq);\n\tskb_queue_head_init(&pf->rq);\n\tatomic_set(&pf->refcnt, 1);\n\tinit_waitqueue_head(&pf->rwait);\n}\n\n/*\n * Free the memory used by a ppp unit.  This is only called once\n * there are no channels connected to the unit and no file structs\n * that reference the unit.\n */\nstatic void ppp_destroy_interface(struct ppp *ppp)\n{\n\tatomic_dec(&ppp_unit_count);\n\n\tif (!ppp->file.dead || ppp->n_channels) {\n\t\t/* \"can't happen\" */\n\t\tnetdev_err(ppp->dev, \"ppp: destroying ppp struct %p \"\n\t\t\t   \"but dead=%d n_channels=%d !\\n\",\n\t\t\t   ppp, ppp->file.dead, ppp->n_channels);\n\t\treturn;\n\t}\n\n\tppp_ccp_closed(ppp);\n\tif (ppp->vj) {\n\t\tslhc_free(ppp->vj);\n\t\tppp->vj = NULL;\n\t}\n\tskb_queue_purge(&ppp->file.xq);\n\tskb_queue_purge(&ppp->file.rq);\n#ifdef CONFIG_PPP_MULTILINK\n\tskb_queue_purge(&ppp->mrq);\n#endif /* CONFIG_PPP_MULTILINK */\n#ifdef CONFIG_PPP_FILTER\n\tif (ppp->pass_filter) {\n\t\tbpf_prog_destroy(ppp->pass_filter);\n\t\tppp->pass_filter = NULL;\n\t}\n\n\tif (ppp->active_filter) {\n\t\tbpf_prog_destroy(ppp->active_filter);\n\t\tppp->active_filter = NULL;\n\t}\n#endif /* CONFIG_PPP_FILTER */\n\n\tkfree_skb(ppp->xmit_pending);\n\n\tfree_netdev(ppp->dev);\n}\n\n/*\n * Locate an existing ppp unit.\n * The caller should have locked the all_ppp_mutex.\n */\nstatic struct ppp *\nppp_find_unit(struct ppp_net *pn, int unit)\n{\n\treturn unit_find(&pn->units_idr, unit);\n}\n\n/*\n * Locate an existing ppp channel.\n * The caller should have locked the all_channels_lock.\n * First we look in the new_channels list, then in the\n * all_channels list.  If found in the new_channels list,\n * we move it to the all_channels list.  This is for speed\n * when we have a lot of channels in use.\n */\nstatic struct channel *\nppp_find_channel(struct ppp_net *pn, int unit)\n{\n\tstruct channel *pch;\n\n\tlist_for_each_entry(pch, &pn->new_channels, list) {\n\t\tif (pch->file.index == unit) {\n\t\t\tlist_move(&pch->list, &pn->all_channels);\n\t\t\treturn pch;\n\t\t}\n\t}\n\n\tlist_for_each_entry(pch, &pn->all_channels, list) {\n\t\tif (pch->file.index == unit)\n\t\t\treturn pch;\n\t}\n\n\treturn NULL;\n}\n\n/*\n * Connect a PPP channel to a PPP interface unit.\n */\nstatic int\nppp_connect_channel(struct channel *pch, int unit)\n{\n\tstruct ppp *ppp;\n\tstruct ppp_net *pn;\n\tint ret = -ENXIO;\n\tint hdrlen;\n\n\tpn = ppp_pernet(pch->chan_net);\n\n\tmutex_lock(&pn->all_ppp_mutex);\n\tppp = ppp_find_unit(pn, unit);\n\tif (!ppp)\n\t\tgoto out;\n\twrite_lock_bh(&pch->upl);\n\tret = -EINVAL;\n\tif (pch->ppp)\n\t\tgoto outl;\n\n\tppp_lock(ppp);\n\tif (pch->file.hdrlen > ppp->file.hdrlen)\n\t\tppp->file.hdrlen = pch->file.hdrlen;\n\thdrlen = pch->file.hdrlen + 2;\t/* for protocol bytes */\n\tif (hdrlen > ppp->dev->hard_header_len)\n\t\tppp->dev->hard_header_len = hdrlen;\n\tlist_add_tail(&pch->clist, &ppp->channels);\n\t++ppp->n_channels;\n\tpch->ppp = ppp;\n\tatomic_inc(&ppp->file.refcnt);\n\tppp_unlock(ppp);\n\tret = 0;\n\n outl:\n\twrite_unlock_bh(&pch->upl);\n out:\n\tmutex_unlock(&pn->all_ppp_mutex);\n\treturn ret;\n}\n\n/*\n * Disconnect a channel from its ppp unit.\n */\nstatic int\nppp_disconnect_channel(struct channel *pch)\n{\n\tstruct ppp *ppp;\n\tint err = -EINVAL;\n\n\twrite_lock_bh(&pch->upl);\n\tppp = pch->ppp;\n\tpch->ppp = NULL;\n\twrite_unlock_bh(&pch->upl);\n\tif (ppp) {\n\t\t/* remove it from the ppp unit's list */\n\t\tppp_lock(ppp);\n\t\tlist_del(&pch->clist);\n\t\tif (--ppp->n_channels == 0)\n\t\t\twake_up_interruptible(&ppp->file.rwait);\n\t\tppp_unlock(ppp);\n\t\tif (atomic_dec_and_test(&ppp->file.refcnt))\n\t\t\tppp_destroy_interface(ppp);\n\t\terr = 0;\n\t}\n\treturn err;\n}\n\n/*\n * Free up the resources used by a ppp channel.\n */\nstatic void ppp_destroy_channel(struct channel *pch)\n{\n\tatomic_dec(&channel_count);\n\n\tif (!pch->file.dead) {\n\t\t/* \"can't happen\" */\n\t\tpr_err(\"ppp: destroying undead channel %p !\\n\", pch);\n\t\treturn;\n\t}\n\tskb_queue_purge(&pch->file.xq);\n\tskb_queue_purge(&pch->file.rq);\n\tkfree(pch);\n}\n\nstatic void __exit ppp_cleanup(void)\n{\n\t/* should never happen */\n\tif (atomic_read(&ppp_unit_count) || atomic_read(&channel_count))\n\t\tpr_err(\"PPP: removing module but units remain!\\n\");\n\tunregister_chrdev(PPP_MAJOR, \"ppp\");\n\tdevice_destroy(ppp_class, MKDEV(PPP_MAJOR, 0));\n\tclass_destroy(ppp_class);\n\tunregister_pernet_device(&ppp_net_ops);\n}\n\n/*\n * Units handling. Caller must protect concurrent access\n * by holding all_ppp_mutex\n */\n\n/* associate pointer with specified number */\nstatic int unit_set(struct idr *p, void *ptr, int n)\n{\n\tint unit;\n\n\tunit = idr_alloc(p, ptr, n, n + 1, GFP_KERNEL);\n\tif (unit == -ENOSPC)\n\t\tunit = -EINVAL;\n\treturn unit;\n}\n\n/* get new free unit number and associate pointer with it */\nstatic int unit_get(struct idr *p, void *ptr)\n{\n\treturn idr_alloc(p, ptr, 0, 0, GFP_KERNEL);\n}\n\n/* put unit number back to a pool */\nstatic void unit_put(struct idr *p, int n)\n{\n\tidr_remove(p, n);\n}\n\n/* get pointer associated with the number */\nstatic void *unit_find(struct idr *p, int n)\n{\n\treturn idr_find(p, n);\n}\n\n/* Module/initialization stuff */\n\nmodule_init(ppp_init);\nmodule_exit(ppp_cleanup);\n\nEXPORT_SYMBOL(ppp_register_net_channel);\nEXPORT_SYMBOL(ppp_register_channel);\nEXPORT_SYMBOL(ppp_unregister_channel);\nEXPORT_SYMBOL(ppp_channel_index);\nEXPORT_SYMBOL(ppp_unit_number);\nEXPORT_SYMBOL(ppp_dev_name);\nEXPORT_SYMBOL(ppp_input);\nEXPORT_SYMBOL(ppp_input_error);\nEXPORT_SYMBOL(ppp_output_wakeup);\nEXPORT_SYMBOL(ppp_register_compressor);\nEXPORT_SYMBOL(ppp_unregister_compressor);\nMODULE_LICENSE(\"GPL\");\nMODULE_ALIAS_CHARDEV(PPP_MAJOR, 0);\nMODULE_ALIAS(\"devname:ppp\");\n"], "filenames": ["drivers/net/ppp/ppp_generic.c"], "buggy_code_start_loc": [2310], "buggy_code_end_loc": [2406], "fixing_code_start_loc": [2310], "fixing_code_end_loc": [2409], "type": "CWE-416", "message": "Use-after-free vulnerability in drivers/net/ppp/ppp_generic.c in the Linux kernel before 4.5.2 allows local users to cause a denial of service (memory corruption and system crash, or spinlock) or possibly have unspecified other impact by removing a network namespace, related to the ppp_register_net_channel and ppp_unregister_channel functions.", "other": {"cve": {"id": "CVE-2016-4805", "sourceIdentifier": "cve@mitre.org", "published": "2016-05-23T10:59:13.443", "lastModified": "2023-01-17T21:18:02.860", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "Use-after-free vulnerability in drivers/net/ppp/ppp_generic.c in the Linux kernel before 4.5.2 allows local users to cause a denial of service (memory corruption and system crash, or spinlock) or possibly have unspecified other impact by removing a network namespace, related to the ppp_register_net_channel and ppp_unregister_channel functions."}, {"lang": "es", "value": "Vulnerabilidad de uso despu\u00e9s de liberaci\u00f3n de memoria en drivers/net/ppp/ppp_generic.c en el kernel de Linux en versiones anteriores a 4.5.2 permite a usuarios locales provocar una denegaci\u00f3n de servicio (corrupci\u00f3n de memoria y ca\u00edda de sistema o spinlock) o posiblemente tener otro impacto no especificado eliminando una red namespace, relacionado con las funciones ppp_register_net_channel y ppp_unregister_channel."}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:L/AC:L/PR:L/UI:N/S:U/C:H/I:H/A:H", "attackVector": "LOCAL", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "HIGH", "availabilityImpact": "HIGH", "baseScore": 7.8, "baseSeverity": "HIGH"}, "exploitabilityScore": 1.8, "impactScore": 5.9}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:L/AC:L/Au:N/C:C/I:C/A:C", "accessVector": "LOCAL", "accessComplexity": "LOW", "authentication": "NONE", "confidentialityImpact": "COMPLETE", "integrityImpact": "COMPLETE", "availabilityImpact": "COMPLETE", "baseScore": 7.2}, "baseSeverity": "HIGH", "exploitabilityScore": 3.9, "impactScore": 10.0, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-416"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:novell:suse_linux_enterprise_desktop:12.0:-:*:*:*:*:*:*", "matchCriteriaId": "5767DAFA-095A-45F6-BCFD-0F0FE10CC0F2"}]}]}, {"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:novell:suse_linux_enterprise_workstation_extension:12.0:-:*:*:*:*:*:*", "matchCriteriaId": "59F75102-8532-4F54-9E0B-EC65EC294956"}]}]}, {"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:novell:suse_linux_enterprise_module_for_public_cloud:12.0:-:*:*:*:*:*:*", "matchCriteriaId": "D7DA4C2F-8A24-4618-AF74-6B1772423147"}]}]}, {"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:novell:suse_linux_enterprise_server:11.0:sp4:*:*:*:*:*:*", "matchCriteriaId": "ADE9D807-6690-4D67-A6B3-68BBC9B50153"}]}]}, {"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:novell:suse_linux_enterprise_module_for_public_cloud:12.0:-:*:*:*:*:*:*", "matchCriteriaId": "D7DA4C2F-8A24-4618-AF74-6B1772423147"}]}]}, {"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:novell:opensuse_leap:42.1:*:*:*:*:*:*:*", "matchCriteriaId": "8FB8F4ED-D00F-4BE4-9EA9-B4C0A09CF681"}]}]}, {"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:novell:suse_linux_enterprise_software_development_kit:11.0:sp4:*:*:*:*:*:*", "matchCriteriaId": "A5FDEDA8-6F51-4945-B443-438CC987F235"}]}]}, {"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:redhat:enterprise_linux:6.0:*:*:*:*:*:*:*", "matchCriteriaId": "2F6AB192-9D7D-4A9A-8995-E53A9DE9EAFC"}]}]}, {"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:canonical:ubuntu_linux:12.04:-:lts:*:*:*:*:*", "matchCriteriaId": "F5D324C4-97C7-49D3-A809-9EAD4B690C69"}]}]}, {"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionStartIncluding": "2.6.30", "versionEndExcluding": "3.2.80", "matchCriteriaId": "4C4DFE87-2B4C-4B51-B7C8-AC7D57F14A60"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionStartIncluding": "3.3", "versionEndExcluding": "3.10.102", "matchCriteriaId": "0F147711-AD8B-484D-8393-5BCFC6C59EC3"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionStartIncluding": "3.11", "versionEndExcluding": "3.12.59", "matchCriteriaId": "584CA2EF-2339-4C1A-93C3-464EB59A2D76"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionStartIncluding": "3.13", "versionEndExcluding": "3.14.67", "matchCriteriaId": "3D15B81D-86E5-4DCD-B9D6-8E1B363C890B"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionStartIncluding": "3.15", "versionEndExcluding": "3.16.35", "matchCriteriaId": "7DC4BA70-B111-4D2E-BC78-6601CED68F08"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionStartIncluding": "3.17", "versionEndExcluding": "3.18.37", "matchCriteriaId": "B55F09A2-F470-41BA-9585-40E8C1960ABA"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionStartIncluding": "3.19", "versionEndExcluding": "4.1.28", "matchCriteriaId": "2BACB680-D42D-4EFF-9B8B-121AA348DB7A"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionStartIncluding": "4.2", "versionEndExcluding": "4.4.8", "matchCriteriaId": "824C5EA8-82AC-4C0A-AC84-7EDDF4D78C5E"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionStartIncluding": "4.5", "versionEndExcluding": "4.5.2", "matchCriteriaId": "44B0678C-60EC-4992-893A-7C76EEE0E0B5"}]}]}, {"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:novell:suse_linux_enterprise_software_development_kit:12.0:-:*:*:*:*:*:*", "matchCriteriaId": "2C5269FF-3D79-4D5F-BF2C-E76F3C2904AA"}]}]}, {"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:novell:suse_linux_enterprise_workstation_extension:12.0:sp1:*:*:*:*:*:*", "matchCriteriaId": "E8CF34B9-B384-4297-9B83-57A520E39131"}]}]}, {"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:novell:suse_linux_enterprise_server:12.0:-:*:*:*:*:*:*", "matchCriteriaId": "1B097F99-D0D7-4B32-9E1A-BE5E653CFA7C"}]}]}, {"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:novell:suse_linux_enterprise_desktop:12.0:sp1:*:*:*:*:*:*", "matchCriteriaId": "6359EF76-9371-4418-8694-B604CF02CF63"}]}]}, {"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:redhat:enterprise_linux:7.0:*:*:*:*:*:*:*", "matchCriteriaId": "142AD0DD-4CF3-4D74-9442-459CE3347E3A"}]}]}, {"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:oracle:linux:6:*:*:*:*:*:*:*", "matchCriteriaId": "CC7A498A-A669-4C42-8134-86103C799D13"}]}]}, {"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:novell:suse_linux_enterprise_real_time_extension:11.0:sp4:*:*:*:*:*:*", "matchCriteriaId": "5BFCA0A7-8EB8-4C6F-9039-2B6A224080D3"}]}]}, {"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:novell:suse_linux_enterprise_server:12.0:sp1:*:*:*:*:*:*", "matchCriteriaId": "81D94366-47D6-445A-A811-39327B150FCD"}]}]}, {"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:novell:suse_linux_enterprise_real_time_extension:12.0:sp1:*:*:*:*:*:*", "matchCriteriaId": "B2905A9C-3E00-4188-8341-E5C2F62EF405"}]}]}, {"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:novell:suse_linux_enterprise_software_development_kit:12.0:sp1:*:*:*:*:*:*", "matchCriteriaId": "01E6CAD9-DC1F-4C7C-8C8E-98E4BFABAC94"}]}]}, {"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:novell:suse_linux_enterprise_live_patching:12.0:-:*:*:*:*:*:*", "matchCriteriaId": "87992023-1565-477A-BB3C-CC582E8BDEBE"}]}]}], "references": [{"url": "http://git.kernel.org/cgit/linux/kernel/git/torvalds/linux.git/commit/?id=1f461dcdd296eecedaffffc6bae2bfa90bd7eb89", "source": "cve@mitre.org", "tags": ["Patch", "Vendor Advisory"]}, {"url": "http://lists.opensuse.org/opensuse-security-announce/2016-06/msg00044.html", "source": "cve@mitre.org", "tags": ["Mailing List", "Third Party Advisory"]}, {"url": "http://lists.opensuse.org/opensuse-security-announce/2016-06/msg00052.html", "source": "cve@mitre.org", "tags": ["Mailing List", "Release Notes", "Third Party Advisory"]}, {"url": "http://lists.opensuse.org/opensuse-security-announce/2016-06/msg00054.html", "source": "cve@mitre.org", "tags": ["Mailing List", "Release Notes", "Third Party Advisory"]}, {"url": "http://lists.opensuse.org/opensuse-security-announce/2016-08/msg00000.html", "source": "cve@mitre.org", "tags": ["Mailing List", "Release Notes", "Third Party Advisory"]}, {"url": "http://lists.opensuse.org/opensuse-security-announce/2016-08/msg00007.html", "source": "cve@mitre.org", "tags": ["Mailing List", "Third Party Advisory"]}, {"url": "http://lists.opensuse.org/opensuse-security-announce/2016-08/msg00044.html", "source": "cve@mitre.org", "tags": ["Mailing List", "Third Party Advisory"]}, {"url": "http://lists.opensuse.org/opensuse-security-announce/2016-08/msg00055.html", "source": "cve@mitre.org", "tags": ["Mailing List", "Third Party Advisory"]}, {"url": "http://www.debian.org/security/2016/dsa-3607", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}, {"url": "http://www.kernel.org/pub/linux/kernel/v4.x/ChangeLog-4.5.2", "source": "cve@mitre.org", "tags": ["Mailing List", "Vendor Advisory"]}, {"url": "http://www.openwall.com/lists/oss-security/2016/05/15/2", "source": "cve@mitre.org", "tags": ["Mailing List", "Patch", "Third Party Advisory"]}, {"url": "http://www.oracle.com/technetwork/topics/security/linuxbulletinjul2016-3090544.html", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}, {"url": "http://www.oracle.com/technetwork/topics/security/ovmbulletinoct2016-3090547.html", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}, {"url": "http://www.securityfocus.com/bid/90605", "source": "cve@mitre.org", "tags": ["Third Party Advisory", "VDB Entry"]}, {"url": "http://www.securitytracker.com/id/1036763", "source": "cve@mitre.org", "tags": ["Third Party Advisory", "VDB Entry"]}, {"url": "http://www.ubuntu.com/usn/USN-3021-1", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}, {"url": "http://www.ubuntu.com/usn/USN-3021-2", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}, {"url": "https://bugzilla.redhat.com/show_bug.cgi?id=1335803", "source": "cve@mitre.org", "tags": ["Issue Tracking", "Third Party Advisory"]}, {"url": "https://github.com/torvalds/linux/commit/1f461dcdd296eecedaffffc6bae2bfa90bd7eb89", "source": "cve@mitre.org", "tags": ["Patch", "Third Party Advisory"]}]}, "github_commit_url": "https://github.com/torvalds/linux/commit/1f461dcdd296eecedaffffc6bae2bfa90bd7eb89"}}
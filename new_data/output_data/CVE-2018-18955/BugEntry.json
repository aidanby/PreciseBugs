{"buggy_code": ["/*\n *  This program is free software; you can redistribute it and/or\n *  modify it under the terms of the GNU General Public License as\n *  published by the Free Software Foundation, version 2 of the\n *  License.\n */\n\n#include <linux/export.h>\n#include <linux/nsproxy.h>\n#include <linux/slab.h>\n#include <linux/sched/signal.h>\n#include <linux/user_namespace.h>\n#include <linux/proc_ns.h>\n#include <linux/highuid.h>\n#include <linux/cred.h>\n#include <linux/securebits.h>\n#include <linux/keyctl.h>\n#include <linux/key-type.h>\n#include <keys/user-type.h>\n#include <linux/seq_file.h>\n#include <linux/fs.h>\n#include <linux/uaccess.h>\n#include <linux/ctype.h>\n#include <linux/projid.h>\n#include <linux/fs_struct.h>\n#include <linux/bsearch.h>\n#include <linux/sort.h>\n\nstatic struct kmem_cache *user_ns_cachep __read_mostly;\nstatic DEFINE_MUTEX(userns_state_mutex);\n\nstatic bool new_idmap_permitted(const struct file *file,\n\t\t\t\tstruct user_namespace *ns, int cap_setid,\n\t\t\t\tstruct uid_gid_map *map);\nstatic void free_user_ns(struct work_struct *work);\n\nstatic struct ucounts *inc_user_namespaces(struct user_namespace *ns, kuid_t uid)\n{\n\treturn inc_ucount(ns, uid, UCOUNT_USER_NAMESPACES);\n}\n\nstatic void dec_user_namespaces(struct ucounts *ucounts)\n{\n\treturn dec_ucount(ucounts, UCOUNT_USER_NAMESPACES);\n}\n\nstatic void set_cred_user_ns(struct cred *cred, struct user_namespace *user_ns)\n{\n\t/* Start with the same capabilities as init but useless for doing\n\t * anything as the capabilities are bound to the new user namespace.\n\t */\n\tcred->securebits = SECUREBITS_DEFAULT;\n\tcred->cap_inheritable = CAP_EMPTY_SET;\n\tcred->cap_permitted = CAP_FULL_SET;\n\tcred->cap_effective = CAP_FULL_SET;\n\tcred->cap_ambient = CAP_EMPTY_SET;\n\tcred->cap_bset = CAP_FULL_SET;\n#ifdef CONFIG_KEYS\n\tkey_put(cred->request_key_auth);\n\tcred->request_key_auth = NULL;\n#endif\n\t/* tgcred will be cleared in our caller bc CLONE_THREAD won't be set */\n\tcred->user_ns = user_ns;\n}\n\n/*\n * Create a new user namespace, deriving the creator from the user in the\n * passed credentials, and replacing that user with the new root user for the\n * new namespace.\n *\n * This is called by copy_creds(), which will finish setting the target task's\n * credentials.\n */\nint create_user_ns(struct cred *new)\n{\n\tstruct user_namespace *ns, *parent_ns = new->user_ns;\n\tkuid_t owner = new->euid;\n\tkgid_t group = new->egid;\n\tstruct ucounts *ucounts;\n\tint ret, i;\n\n\tret = -ENOSPC;\n\tif (parent_ns->level > 32)\n\t\tgoto fail;\n\n\tucounts = inc_user_namespaces(parent_ns, owner);\n\tif (!ucounts)\n\t\tgoto fail;\n\n\t/*\n\t * Verify that we can not violate the policy of which files\n\t * may be accessed that is specified by the root directory,\n\t * by verifing that the root directory is at the root of the\n\t * mount namespace which allows all files to be accessed.\n\t */\n\tret = -EPERM;\n\tif (current_chrooted())\n\t\tgoto fail_dec;\n\n\t/* The creator needs a mapping in the parent user namespace\n\t * or else we won't be able to reasonably tell userspace who\n\t * created a user_namespace.\n\t */\n\tret = -EPERM;\n\tif (!kuid_has_mapping(parent_ns, owner) ||\n\t    !kgid_has_mapping(parent_ns, group))\n\t\tgoto fail_dec;\n\n\tret = -ENOMEM;\n\tns = kmem_cache_zalloc(user_ns_cachep, GFP_KERNEL);\n\tif (!ns)\n\t\tgoto fail_dec;\n\n\tret = ns_alloc_inum(&ns->ns);\n\tif (ret)\n\t\tgoto fail_free;\n\tns->ns.ops = &userns_operations;\n\n\tatomic_set(&ns->count, 1);\n\t/* Leave the new->user_ns reference with the new user namespace. */\n\tns->parent = parent_ns;\n\tns->level = parent_ns->level + 1;\n\tns->owner = owner;\n\tns->group = group;\n\tINIT_WORK(&ns->work, free_user_ns);\n\tfor (i = 0; i < UCOUNT_COUNTS; i++) {\n\t\tns->ucount_max[i] = INT_MAX;\n\t}\n\tns->ucounts = ucounts;\n\n\t/* Inherit USERNS_SETGROUPS_ALLOWED from our parent */\n\tmutex_lock(&userns_state_mutex);\n\tns->flags = parent_ns->flags;\n\tmutex_unlock(&userns_state_mutex);\n\n#ifdef CONFIG_PERSISTENT_KEYRINGS\n\tinit_rwsem(&ns->persistent_keyring_register_sem);\n#endif\n\tret = -ENOMEM;\n\tif (!setup_userns_sysctls(ns))\n\t\tgoto fail_keyring;\n\n\tset_cred_user_ns(new, ns);\n\treturn 0;\nfail_keyring:\n#ifdef CONFIG_PERSISTENT_KEYRINGS\n\tkey_put(ns->persistent_keyring_register);\n#endif\n\tns_free_inum(&ns->ns);\nfail_free:\n\tkmem_cache_free(user_ns_cachep, ns);\nfail_dec:\n\tdec_user_namespaces(ucounts);\nfail:\n\treturn ret;\n}\n\nint unshare_userns(unsigned long unshare_flags, struct cred **new_cred)\n{\n\tstruct cred *cred;\n\tint err = -ENOMEM;\n\n\tif (!(unshare_flags & CLONE_NEWUSER))\n\t\treturn 0;\n\n\tcred = prepare_creds();\n\tif (cred) {\n\t\terr = create_user_ns(cred);\n\t\tif (err)\n\t\t\tput_cred(cred);\n\t\telse\n\t\t\t*new_cred = cred;\n\t}\n\n\treturn err;\n}\n\nstatic void free_user_ns(struct work_struct *work)\n{\n\tstruct user_namespace *parent, *ns =\n\t\tcontainer_of(work, struct user_namespace, work);\n\n\tdo {\n\t\tstruct ucounts *ucounts = ns->ucounts;\n\t\tparent = ns->parent;\n\t\tif (ns->gid_map.nr_extents > UID_GID_MAP_MAX_BASE_EXTENTS) {\n\t\t\tkfree(ns->gid_map.forward);\n\t\t\tkfree(ns->gid_map.reverse);\n\t\t}\n\t\tif (ns->uid_map.nr_extents > UID_GID_MAP_MAX_BASE_EXTENTS) {\n\t\t\tkfree(ns->uid_map.forward);\n\t\t\tkfree(ns->uid_map.reverse);\n\t\t}\n\t\tif (ns->projid_map.nr_extents > UID_GID_MAP_MAX_BASE_EXTENTS) {\n\t\t\tkfree(ns->projid_map.forward);\n\t\t\tkfree(ns->projid_map.reverse);\n\t\t}\n\t\tretire_userns_sysctls(ns);\n#ifdef CONFIG_PERSISTENT_KEYRINGS\n\t\tkey_put(ns->persistent_keyring_register);\n#endif\n\t\tns_free_inum(&ns->ns);\n\t\tkmem_cache_free(user_ns_cachep, ns);\n\t\tdec_user_namespaces(ucounts);\n\t\tns = parent;\n\t} while (atomic_dec_and_test(&parent->count));\n}\n\nvoid __put_user_ns(struct user_namespace *ns)\n{\n\tschedule_work(&ns->work);\n}\nEXPORT_SYMBOL(__put_user_ns);\n\n/**\n * idmap_key struct holds the information necessary to find an idmapping in a\n * sorted idmap array. It is passed to cmp_map_id() as first argument.\n */\nstruct idmap_key {\n\tbool map_up; /* true  -> id from kid; false -> kid from id */\n\tu32 id; /* id to find */\n\tu32 count; /* == 0 unless used with map_id_range_down() */\n};\n\n/**\n * cmp_map_id - Function to be passed to bsearch() to find the requested\n * idmapping. Expects struct idmap_key to be passed via @k.\n */\nstatic int cmp_map_id(const void *k, const void *e)\n{\n\tu32 first, last, id2;\n\tconst struct idmap_key *key = k;\n\tconst struct uid_gid_extent *el = e;\n\n\tid2 = key->id + key->count - 1;\n\n\t/* handle map_id_{down,up}() */\n\tif (key->map_up)\n\t\tfirst = el->lower_first;\n\telse\n\t\tfirst = el->first;\n\n\tlast = first + el->count - 1;\n\n\tif (key->id >= first && key->id <= last &&\n\t    (id2 >= first && id2 <= last))\n\t\treturn 0;\n\n\tif (key->id < first || id2 < first)\n\t\treturn -1;\n\n\treturn 1;\n}\n\n/**\n * map_id_range_down_max - Find idmap via binary search in ordered idmap array.\n * Can only be called if number of mappings exceeds UID_GID_MAP_MAX_BASE_EXTENTS.\n */\nstatic struct uid_gid_extent *\nmap_id_range_down_max(unsigned extents, struct uid_gid_map *map, u32 id, u32 count)\n{\n\tstruct idmap_key key;\n\n\tkey.map_up = false;\n\tkey.count = count;\n\tkey.id = id;\n\n\treturn bsearch(&key, map->forward, extents,\n\t\t       sizeof(struct uid_gid_extent), cmp_map_id);\n}\n\n/**\n * map_id_range_down_base - Find idmap via binary search in static extent array.\n * Can only be called if number of mappings is equal or less than\n * UID_GID_MAP_MAX_BASE_EXTENTS.\n */\nstatic struct uid_gid_extent *\nmap_id_range_down_base(unsigned extents, struct uid_gid_map *map, u32 id, u32 count)\n{\n\tunsigned idx;\n\tu32 first, last, id2;\n\n\tid2 = id + count - 1;\n\n\t/* Find the matching extent */\n\tfor (idx = 0; idx < extents; idx++) {\n\t\tfirst = map->extent[idx].first;\n\t\tlast = first + map->extent[idx].count - 1;\n\t\tif (id >= first && id <= last &&\n\t\t    (id2 >= first && id2 <= last))\n\t\t\treturn &map->extent[idx];\n\t}\n\treturn NULL;\n}\n\nstatic u32 map_id_range_down(struct uid_gid_map *map, u32 id, u32 count)\n{\n\tstruct uid_gid_extent *extent;\n\tunsigned extents = map->nr_extents;\n\tsmp_rmb();\n\n\tif (extents <= UID_GID_MAP_MAX_BASE_EXTENTS)\n\t\textent = map_id_range_down_base(extents, map, id, count);\n\telse\n\t\textent = map_id_range_down_max(extents, map, id, count);\n\n\t/* Map the id or note failure */\n\tif (extent)\n\t\tid = (id - extent->first) + extent->lower_first;\n\telse\n\t\tid = (u32) -1;\n\n\treturn id;\n}\n\nstatic u32 map_id_down(struct uid_gid_map *map, u32 id)\n{\n\treturn map_id_range_down(map, id, 1);\n}\n\n/**\n * map_id_up_base - Find idmap via binary search in static extent array.\n * Can only be called if number of mappings is equal or less than\n * UID_GID_MAP_MAX_BASE_EXTENTS.\n */\nstatic struct uid_gid_extent *\nmap_id_up_base(unsigned extents, struct uid_gid_map *map, u32 id)\n{\n\tunsigned idx;\n\tu32 first, last;\n\n\t/* Find the matching extent */\n\tfor (idx = 0; idx < extents; idx++) {\n\t\tfirst = map->extent[idx].lower_first;\n\t\tlast = first + map->extent[idx].count - 1;\n\t\tif (id >= first && id <= last)\n\t\t\treturn &map->extent[idx];\n\t}\n\treturn NULL;\n}\n\n/**\n * map_id_up_max - Find idmap via binary search in ordered idmap array.\n * Can only be called if number of mappings exceeds UID_GID_MAP_MAX_BASE_EXTENTS.\n */\nstatic struct uid_gid_extent *\nmap_id_up_max(unsigned extents, struct uid_gid_map *map, u32 id)\n{\n\tstruct idmap_key key;\n\n\tkey.map_up = true;\n\tkey.count = 1;\n\tkey.id = id;\n\n\treturn bsearch(&key, map->reverse, extents,\n\t\t       sizeof(struct uid_gid_extent), cmp_map_id);\n}\n\nstatic u32 map_id_up(struct uid_gid_map *map, u32 id)\n{\n\tstruct uid_gid_extent *extent;\n\tunsigned extents = map->nr_extents;\n\tsmp_rmb();\n\n\tif (extents <= UID_GID_MAP_MAX_BASE_EXTENTS)\n\t\textent = map_id_up_base(extents, map, id);\n\telse\n\t\textent = map_id_up_max(extents, map, id);\n\n\t/* Map the id or note failure */\n\tif (extent)\n\t\tid = (id - extent->lower_first) + extent->first;\n\telse\n\t\tid = (u32) -1;\n\n\treturn id;\n}\n\n/**\n *\tmake_kuid - Map a user-namespace uid pair into a kuid.\n *\t@ns:  User namespace that the uid is in\n *\t@uid: User identifier\n *\n *\tMaps a user-namespace uid pair into a kernel internal kuid,\n *\tand returns that kuid.\n *\n *\tWhen there is no mapping defined for the user-namespace uid\n *\tpair INVALID_UID is returned.  Callers are expected to test\n *\tfor and handle INVALID_UID being returned.  INVALID_UID\n *\tmay be tested for using uid_valid().\n */\nkuid_t make_kuid(struct user_namespace *ns, uid_t uid)\n{\n\t/* Map the uid to a global kernel uid */\n\treturn KUIDT_INIT(map_id_down(&ns->uid_map, uid));\n}\nEXPORT_SYMBOL(make_kuid);\n\n/**\n *\tfrom_kuid - Create a uid from a kuid user-namespace pair.\n *\t@targ: The user namespace we want a uid in.\n *\t@kuid: The kernel internal uid to start with.\n *\n *\tMap @kuid into the user-namespace specified by @targ and\n *\treturn the resulting uid.\n *\n *\tThere is always a mapping into the initial user_namespace.\n *\n *\tIf @kuid has no mapping in @targ (uid_t)-1 is returned.\n */\nuid_t from_kuid(struct user_namespace *targ, kuid_t kuid)\n{\n\t/* Map the uid from a global kernel uid */\n\treturn map_id_up(&targ->uid_map, __kuid_val(kuid));\n}\nEXPORT_SYMBOL(from_kuid);\n\n/**\n *\tfrom_kuid_munged - Create a uid from a kuid user-namespace pair.\n *\t@targ: The user namespace we want a uid in.\n *\t@kuid: The kernel internal uid to start with.\n *\n *\tMap @kuid into the user-namespace specified by @targ and\n *\treturn the resulting uid.\n *\n *\tThere is always a mapping into the initial user_namespace.\n *\n *\tUnlike from_kuid from_kuid_munged never fails and always\n *\treturns a valid uid.  This makes from_kuid_munged appropriate\n *\tfor use in syscalls like stat and getuid where failing the\n *\tsystem call and failing to provide a valid uid are not an\n *\toptions.\n *\n *\tIf @kuid has no mapping in @targ overflowuid is returned.\n */\nuid_t from_kuid_munged(struct user_namespace *targ, kuid_t kuid)\n{\n\tuid_t uid;\n\tuid = from_kuid(targ, kuid);\n\n\tif (uid == (uid_t) -1)\n\t\tuid = overflowuid;\n\treturn uid;\n}\nEXPORT_SYMBOL(from_kuid_munged);\n\n/**\n *\tmake_kgid - Map a user-namespace gid pair into a kgid.\n *\t@ns:  User namespace that the gid is in\n *\t@gid: group identifier\n *\n *\tMaps a user-namespace gid pair into a kernel internal kgid,\n *\tand returns that kgid.\n *\n *\tWhen there is no mapping defined for the user-namespace gid\n *\tpair INVALID_GID is returned.  Callers are expected to test\n *\tfor and handle INVALID_GID being returned.  INVALID_GID may be\n *\ttested for using gid_valid().\n */\nkgid_t make_kgid(struct user_namespace *ns, gid_t gid)\n{\n\t/* Map the gid to a global kernel gid */\n\treturn KGIDT_INIT(map_id_down(&ns->gid_map, gid));\n}\nEXPORT_SYMBOL(make_kgid);\n\n/**\n *\tfrom_kgid - Create a gid from a kgid user-namespace pair.\n *\t@targ: The user namespace we want a gid in.\n *\t@kgid: The kernel internal gid to start with.\n *\n *\tMap @kgid into the user-namespace specified by @targ and\n *\treturn the resulting gid.\n *\n *\tThere is always a mapping into the initial user_namespace.\n *\n *\tIf @kgid has no mapping in @targ (gid_t)-1 is returned.\n */\ngid_t from_kgid(struct user_namespace *targ, kgid_t kgid)\n{\n\t/* Map the gid from a global kernel gid */\n\treturn map_id_up(&targ->gid_map, __kgid_val(kgid));\n}\nEXPORT_SYMBOL(from_kgid);\n\n/**\n *\tfrom_kgid_munged - Create a gid from a kgid user-namespace pair.\n *\t@targ: The user namespace we want a gid in.\n *\t@kgid: The kernel internal gid to start with.\n *\n *\tMap @kgid into the user-namespace specified by @targ and\n *\treturn the resulting gid.\n *\n *\tThere is always a mapping into the initial user_namespace.\n *\n *\tUnlike from_kgid from_kgid_munged never fails and always\n *\treturns a valid gid.  This makes from_kgid_munged appropriate\n *\tfor use in syscalls like stat and getgid where failing the\n *\tsystem call and failing to provide a valid gid are not options.\n *\n *\tIf @kgid has no mapping in @targ overflowgid is returned.\n */\ngid_t from_kgid_munged(struct user_namespace *targ, kgid_t kgid)\n{\n\tgid_t gid;\n\tgid = from_kgid(targ, kgid);\n\n\tif (gid == (gid_t) -1)\n\t\tgid = overflowgid;\n\treturn gid;\n}\nEXPORT_SYMBOL(from_kgid_munged);\n\n/**\n *\tmake_kprojid - Map a user-namespace projid pair into a kprojid.\n *\t@ns:  User namespace that the projid is in\n *\t@projid: Project identifier\n *\n *\tMaps a user-namespace uid pair into a kernel internal kuid,\n *\tand returns that kuid.\n *\n *\tWhen there is no mapping defined for the user-namespace projid\n *\tpair INVALID_PROJID is returned.  Callers are expected to test\n *\tfor and handle handle INVALID_PROJID being returned.  INVALID_PROJID\n *\tmay be tested for using projid_valid().\n */\nkprojid_t make_kprojid(struct user_namespace *ns, projid_t projid)\n{\n\t/* Map the uid to a global kernel uid */\n\treturn KPROJIDT_INIT(map_id_down(&ns->projid_map, projid));\n}\nEXPORT_SYMBOL(make_kprojid);\n\n/**\n *\tfrom_kprojid - Create a projid from a kprojid user-namespace pair.\n *\t@targ: The user namespace we want a projid in.\n *\t@kprojid: The kernel internal project identifier to start with.\n *\n *\tMap @kprojid into the user-namespace specified by @targ and\n *\treturn the resulting projid.\n *\n *\tThere is always a mapping into the initial user_namespace.\n *\n *\tIf @kprojid has no mapping in @targ (projid_t)-1 is returned.\n */\nprojid_t from_kprojid(struct user_namespace *targ, kprojid_t kprojid)\n{\n\t/* Map the uid from a global kernel uid */\n\treturn map_id_up(&targ->projid_map, __kprojid_val(kprojid));\n}\nEXPORT_SYMBOL(from_kprojid);\n\n/**\n *\tfrom_kprojid_munged - Create a projiid from a kprojid user-namespace pair.\n *\t@targ: The user namespace we want a projid in.\n *\t@kprojid: The kernel internal projid to start with.\n *\n *\tMap @kprojid into the user-namespace specified by @targ and\n *\treturn the resulting projid.\n *\n *\tThere is always a mapping into the initial user_namespace.\n *\n *\tUnlike from_kprojid from_kprojid_munged never fails and always\n *\treturns a valid projid.  This makes from_kprojid_munged\n *\tappropriate for use in syscalls like stat and where\n *\tfailing the system call and failing to provide a valid projid are\n *\tnot an options.\n *\n *\tIf @kprojid has no mapping in @targ OVERFLOW_PROJID is returned.\n */\nprojid_t from_kprojid_munged(struct user_namespace *targ, kprojid_t kprojid)\n{\n\tprojid_t projid;\n\tprojid = from_kprojid(targ, kprojid);\n\n\tif (projid == (projid_t) -1)\n\t\tprojid = OVERFLOW_PROJID;\n\treturn projid;\n}\nEXPORT_SYMBOL(from_kprojid_munged);\n\n\nstatic int uid_m_show(struct seq_file *seq, void *v)\n{\n\tstruct user_namespace *ns = seq->private;\n\tstruct uid_gid_extent *extent = v;\n\tstruct user_namespace *lower_ns;\n\tuid_t lower;\n\n\tlower_ns = seq_user_ns(seq);\n\tif ((lower_ns == ns) && lower_ns->parent)\n\t\tlower_ns = lower_ns->parent;\n\n\tlower = from_kuid(lower_ns, KUIDT_INIT(extent->lower_first));\n\n\tseq_printf(seq, \"%10u %10u %10u\\n\",\n\t\textent->first,\n\t\tlower,\n\t\textent->count);\n\n\treturn 0;\n}\n\nstatic int gid_m_show(struct seq_file *seq, void *v)\n{\n\tstruct user_namespace *ns = seq->private;\n\tstruct uid_gid_extent *extent = v;\n\tstruct user_namespace *lower_ns;\n\tgid_t lower;\n\n\tlower_ns = seq_user_ns(seq);\n\tif ((lower_ns == ns) && lower_ns->parent)\n\t\tlower_ns = lower_ns->parent;\n\n\tlower = from_kgid(lower_ns, KGIDT_INIT(extent->lower_first));\n\n\tseq_printf(seq, \"%10u %10u %10u\\n\",\n\t\textent->first,\n\t\tlower,\n\t\textent->count);\n\n\treturn 0;\n}\n\nstatic int projid_m_show(struct seq_file *seq, void *v)\n{\n\tstruct user_namespace *ns = seq->private;\n\tstruct uid_gid_extent *extent = v;\n\tstruct user_namespace *lower_ns;\n\tprojid_t lower;\n\n\tlower_ns = seq_user_ns(seq);\n\tif ((lower_ns == ns) && lower_ns->parent)\n\t\tlower_ns = lower_ns->parent;\n\n\tlower = from_kprojid(lower_ns, KPROJIDT_INIT(extent->lower_first));\n\n\tseq_printf(seq, \"%10u %10u %10u\\n\",\n\t\textent->first,\n\t\tlower,\n\t\textent->count);\n\n\treturn 0;\n}\n\nstatic void *m_start(struct seq_file *seq, loff_t *ppos,\n\t\t     struct uid_gid_map *map)\n{\n\tloff_t pos = *ppos;\n\tunsigned extents = map->nr_extents;\n\tsmp_rmb();\n\n\tif (pos >= extents)\n\t\treturn NULL;\n\n\tif (extents <= UID_GID_MAP_MAX_BASE_EXTENTS)\n\t\treturn &map->extent[pos];\n\n\treturn &map->forward[pos];\n}\n\nstatic void *uid_m_start(struct seq_file *seq, loff_t *ppos)\n{\n\tstruct user_namespace *ns = seq->private;\n\n\treturn m_start(seq, ppos, &ns->uid_map);\n}\n\nstatic void *gid_m_start(struct seq_file *seq, loff_t *ppos)\n{\n\tstruct user_namespace *ns = seq->private;\n\n\treturn m_start(seq, ppos, &ns->gid_map);\n}\n\nstatic void *projid_m_start(struct seq_file *seq, loff_t *ppos)\n{\n\tstruct user_namespace *ns = seq->private;\n\n\treturn m_start(seq, ppos, &ns->projid_map);\n}\n\nstatic void *m_next(struct seq_file *seq, void *v, loff_t *pos)\n{\n\t(*pos)++;\n\treturn seq->op->start(seq, pos);\n}\n\nstatic void m_stop(struct seq_file *seq, void *v)\n{\n\treturn;\n}\n\nconst struct seq_operations proc_uid_seq_operations = {\n\t.start = uid_m_start,\n\t.stop = m_stop,\n\t.next = m_next,\n\t.show = uid_m_show,\n};\n\nconst struct seq_operations proc_gid_seq_operations = {\n\t.start = gid_m_start,\n\t.stop = m_stop,\n\t.next = m_next,\n\t.show = gid_m_show,\n};\n\nconst struct seq_operations proc_projid_seq_operations = {\n\t.start = projid_m_start,\n\t.stop = m_stop,\n\t.next = m_next,\n\t.show = projid_m_show,\n};\n\nstatic bool mappings_overlap(struct uid_gid_map *new_map,\n\t\t\t     struct uid_gid_extent *extent)\n{\n\tu32 upper_first, lower_first, upper_last, lower_last;\n\tunsigned idx;\n\n\tupper_first = extent->first;\n\tlower_first = extent->lower_first;\n\tupper_last = upper_first + extent->count - 1;\n\tlower_last = lower_first + extent->count - 1;\n\n\tfor (idx = 0; idx < new_map->nr_extents; idx++) {\n\t\tu32 prev_upper_first, prev_lower_first;\n\t\tu32 prev_upper_last, prev_lower_last;\n\t\tstruct uid_gid_extent *prev;\n\n\t\tif (new_map->nr_extents <= UID_GID_MAP_MAX_BASE_EXTENTS)\n\t\t\tprev = &new_map->extent[idx];\n\t\telse\n\t\t\tprev = &new_map->forward[idx];\n\n\t\tprev_upper_first = prev->first;\n\t\tprev_lower_first = prev->lower_first;\n\t\tprev_upper_last = prev_upper_first + prev->count - 1;\n\t\tprev_lower_last = prev_lower_first + prev->count - 1;\n\n\t\t/* Does the upper range intersect a previous extent? */\n\t\tif ((prev_upper_first <= upper_last) &&\n\t\t    (prev_upper_last >= upper_first))\n\t\t\treturn true;\n\n\t\t/* Does the lower range intersect a previous extent? */\n\t\tif ((prev_lower_first <= lower_last) &&\n\t\t    (prev_lower_last >= lower_first))\n\t\t\treturn true;\n\t}\n\treturn false;\n}\n\n/**\n * insert_extent - Safely insert a new idmap extent into struct uid_gid_map.\n * Takes care to allocate a 4K block of memory if the number of mappings exceeds\n * UID_GID_MAP_MAX_BASE_EXTENTS.\n */\nstatic int insert_extent(struct uid_gid_map *map, struct uid_gid_extent *extent)\n{\n\tstruct uid_gid_extent *dest;\n\n\tif (map->nr_extents == UID_GID_MAP_MAX_BASE_EXTENTS) {\n\t\tstruct uid_gid_extent *forward;\n\n\t\t/* Allocate memory for 340 mappings. */\n\t\tforward = kmalloc_array(UID_GID_MAP_MAX_EXTENTS,\n\t\t\t\t\tsizeof(struct uid_gid_extent),\n\t\t\t\t\tGFP_KERNEL);\n\t\tif (!forward)\n\t\t\treturn -ENOMEM;\n\n\t\t/* Copy over memory. Only set up memory for the forward pointer.\n\t\t * Defer the memory setup for the reverse pointer.\n\t\t */\n\t\tmemcpy(forward, map->extent,\n\t\t       map->nr_extents * sizeof(map->extent[0]));\n\n\t\tmap->forward = forward;\n\t\tmap->reverse = NULL;\n\t}\n\n\tif (map->nr_extents < UID_GID_MAP_MAX_BASE_EXTENTS)\n\t\tdest = &map->extent[map->nr_extents];\n\telse\n\t\tdest = &map->forward[map->nr_extents];\n\n\t*dest = *extent;\n\tmap->nr_extents++;\n\treturn 0;\n}\n\n/* cmp function to sort() forward mappings */\nstatic int cmp_extents_forward(const void *a, const void *b)\n{\n\tconst struct uid_gid_extent *e1 = a;\n\tconst struct uid_gid_extent *e2 = b;\n\n\tif (e1->first < e2->first)\n\t\treturn -1;\n\n\tif (e1->first > e2->first)\n\t\treturn 1;\n\n\treturn 0;\n}\n\n/* cmp function to sort() reverse mappings */\nstatic int cmp_extents_reverse(const void *a, const void *b)\n{\n\tconst struct uid_gid_extent *e1 = a;\n\tconst struct uid_gid_extent *e2 = b;\n\n\tif (e1->lower_first < e2->lower_first)\n\t\treturn -1;\n\n\tif (e1->lower_first > e2->lower_first)\n\t\treturn 1;\n\n\treturn 0;\n}\n\n/**\n * sort_idmaps - Sorts an array of idmap entries.\n * Can only be called if number of mappings exceeds UID_GID_MAP_MAX_BASE_EXTENTS.\n */\nstatic int sort_idmaps(struct uid_gid_map *map)\n{\n\tif (map->nr_extents <= UID_GID_MAP_MAX_BASE_EXTENTS)\n\t\treturn 0;\n\n\t/* Sort forward array. */\n\tsort(map->forward, map->nr_extents, sizeof(struct uid_gid_extent),\n\t     cmp_extents_forward, NULL);\n\n\t/* Only copy the memory from forward we actually need. */\n\tmap->reverse = kmemdup(map->forward,\n\t\t\t       map->nr_extents * sizeof(struct uid_gid_extent),\n\t\t\t       GFP_KERNEL);\n\tif (!map->reverse)\n\t\treturn -ENOMEM;\n\n\t/* Sort reverse array. */\n\tsort(map->reverse, map->nr_extents, sizeof(struct uid_gid_extent),\n\t     cmp_extents_reverse, NULL);\n\n\treturn 0;\n}\n\nstatic ssize_t map_write(struct file *file, const char __user *buf,\n\t\t\t size_t count, loff_t *ppos,\n\t\t\t int cap_setid,\n\t\t\t struct uid_gid_map *map,\n\t\t\t struct uid_gid_map *parent_map)\n{\n\tstruct seq_file *seq = file->private_data;\n\tstruct user_namespace *ns = seq->private;\n\tstruct uid_gid_map new_map;\n\tunsigned idx;\n\tstruct uid_gid_extent extent;\n\tchar *kbuf = NULL, *pos, *next_line;\n\tssize_t ret;\n\n\t/* Only allow < page size writes at the beginning of the file */\n\tif ((*ppos != 0) || (count >= PAGE_SIZE))\n\t\treturn -EINVAL;\n\n\t/* Slurp in the user data */\n\tkbuf = memdup_user_nul(buf, count);\n\tif (IS_ERR(kbuf))\n\t\treturn PTR_ERR(kbuf);\n\n\t/*\n\t * The userns_state_mutex serializes all writes to any given map.\n\t *\n\t * Any map is only ever written once.\n\t *\n\t * An id map fits within 1 cache line on most architectures.\n\t *\n\t * On read nothing needs to be done unless you are on an\n\t * architecture with a crazy cache coherency model like alpha.\n\t *\n\t * There is a one time data dependency between reading the\n\t * count of the extents and the values of the extents.  The\n\t * desired behavior is to see the values of the extents that\n\t * were written before the count of the extents.\n\t *\n\t * To achieve this smp_wmb() is used on guarantee the write\n\t * order and smp_rmb() is guaranteed that we don't have crazy\n\t * architectures returning stale data.\n\t */\n\tmutex_lock(&userns_state_mutex);\n\n\tmemset(&new_map, 0, sizeof(struct uid_gid_map));\n\n\tret = -EPERM;\n\t/* Only allow one successful write to the map */\n\tif (map->nr_extents != 0)\n\t\tgoto out;\n\n\t/*\n\t * Adjusting namespace settings requires capabilities on the target.\n\t */\n\tif (cap_valid(cap_setid) && !file_ns_capable(file, ns, CAP_SYS_ADMIN))\n\t\tgoto out;\n\n\t/* Parse the user data */\n\tret = -EINVAL;\n\tpos = kbuf;\n\tfor (; pos; pos = next_line) {\n\n\t\t/* Find the end of line and ensure I don't look past it */\n\t\tnext_line = strchr(pos, '\\n');\n\t\tif (next_line) {\n\t\t\t*next_line = '\\0';\n\t\t\tnext_line++;\n\t\t\tif (*next_line == '\\0')\n\t\t\t\tnext_line = NULL;\n\t\t}\n\n\t\tpos = skip_spaces(pos);\n\t\textent.first = simple_strtoul(pos, &pos, 10);\n\t\tif (!isspace(*pos))\n\t\t\tgoto out;\n\n\t\tpos = skip_spaces(pos);\n\t\textent.lower_first = simple_strtoul(pos, &pos, 10);\n\t\tif (!isspace(*pos))\n\t\t\tgoto out;\n\n\t\tpos = skip_spaces(pos);\n\t\textent.count = simple_strtoul(pos, &pos, 10);\n\t\tif (*pos && !isspace(*pos))\n\t\t\tgoto out;\n\n\t\t/* Verify there is not trailing junk on the line */\n\t\tpos = skip_spaces(pos);\n\t\tif (*pos != '\\0')\n\t\t\tgoto out;\n\n\t\t/* Verify we have been given valid starting values */\n\t\tif ((extent.first == (u32) -1) ||\n\t\t    (extent.lower_first == (u32) -1))\n\t\t\tgoto out;\n\n\t\t/* Verify count is not zero and does not cause the\n\t\t * extent to wrap\n\t\t */\n\t\tif ((extent.first + extent.count) <= extent.first)\n\t\t\tgoto out;\n\t\tif ((extent.lower_first + extent.count) <=\n\t\t     extent.lower_first)\n\t\t\tgoto out;\n\n\t\t/* Do the ranges in extent overlap any previous extents? */\n\t\tif (mappings_overlap(&new_map, &extent))\n\t\t\tgoto out;\n\n\t\tif ((new_map.nr_extents + 1) == UID_GID_MAP_MAX_EXTENTS &&\n\t\t    (next_line != NULL))\n\t\t\tgoto out;\n\n\t\tret = insert_extent(&new_map, &extent);\n\t\tif (ret < 0)\n\t\t\tgoto out;\n\t\tret = -EINVAL;\n\t}\n\t/* Be very certaint the new map actually exists */\n\tif (new_map.nr_extents == 0)\n\t\tgoto out;\n\n\tret = -EPERM;\n\t/* Validate the user is allowed to use user id's mapped to. */\n\tif (!new_idmap_permitted(file, ns, cap_setid, &new_map))\n\t\tgoto out;\n\n\tret = sort_idmaps(&new_map);\n\tif (ret < 0)\n\t\tgoto out;\n\n\tret = -EPERM;\n\t/* Map the lower ids from the parent user namespace to the\n\t * kernel global id space.\n\t */\n\tfor (idx = 0; idx < new_map.nr_extents; idx++) {\n\t\tstruct uid_gid_extent *e;\n\t\tu32 lower_first;\n\n\t\tif (new_map.nr_extents <= UID_GID_MAP_MAX_BASE_EXTENTS)\n\t\t\te = &new_map.extent[idx];\n\t\telse\n\t\t\te = &new_map.forward[idx];\n\n\t\tlower_first = map_id_range_down(parent_map,\n\t\t\t\t\t\te->lower_first,\n\t\t\t\t\t\te->count);\n\n\t\t/* Fail if we can not map the specified extent to\n\t\t * the kernel global id space.\n\t\t */\n\t\tif (lower_first == (u32) -1)\n\t\t\tgoto out;\n\n\t\te->lower_first = lower_first;\n\t}\n\n\t/* Install the map */\n\tif (new_map.nr_extents <= UID_GID_MAP_MAX_BASE_EXTENTS) {\n\t\tmemcpy(map->extent, new_map.extent,\n\t\t       new_map.nr_extents * sizeof(new_map.extent[0]));\n\t} else {\n\t\tmap->forward = new_map.forward;\n\t\tmap->reverse = new_map.reverse;\n\t}\n\tsmp_wmb();\n\tmap->nr_extents = new_map.nr_extents;\n\n\t*ppos = count;\n\tret = count;\nout:\n\tif (ret < 0 && new_map.nr_extents > UID_GID_MAP_MAX_BASE_EXTENTS) {\n\t\tkfree(new_map.forward);\n\t\tkfree(new_map.reverse);\n\t\tmap->forward = NULL;\n\t\tmap->reverse = NULL;\n\t\tmap->nr_extents = 0;\n\t}\n\n\tmutex_unlock(&userns_state_mutex);\n\tkfree(kbuf);\n\treturn ret;\n}\n\nssize_t proc_uid_map_write(struct file *file, const char __user *buf,\n\t\t\t   size_t size, loff_t *ppos)\n{\n\tstruct seq_file *seq = file->private_data;\n\tstruct user_namespace *ns = seq->private;\n\tstruct user_namespace *seq_ns = seq_user_ns(seq);\n\n\tif (!ns->parent)\n\t\treturn -EPERM;\n\n\tif ((seq_ns != ns) && (seq_ns != ns->parent))\n\t\treturn -EPERM;\n\n\treturn map_write(file, buf, size, ppos, CAP_SETUID,\n\t\t\t &ns->uid_map, &ns->parent->uid_map);\n}\n\nssize_t proc_gid_map_write(struct file *file, const char __user *buf,\n\t\t\t   size_t size, loff_t *ppos)\n{\n\tstruct seq_file *seq = file->private_data;\n\tstruct user_namespace *ns = seq->private;\n\tstruct user_namespace *seq_ns = seq_user_ns(seq);\n\n\tif (!ns->parent)\n\t\treturn -EPERM;\n\n\tif ((seq_ns != ns) && (seq_ns != ns->parent))\n\t\treturn -EPERM;\n\n\treturn map_write(file, buf, size, ppos, CAP_SETGID,\n\t\t\t &ns->gid_map, &ns->parent->gid_map);\n}\n\nssize_t proc_projid_map_write(struct file *file, const char __user *buf,\n\t\t\t      size_t size, loff_t *ppos)\n{\n\tstruct seq_file *seq = file->private_data;\n\tstruct user_namespace *ns = seq->private;\n\tstruct user_namespace *seq_ns = seq_user_ns(seq);\n\n\tif (!ns->parent)\n\t\treturn -EPERM;\n\n\tif ((seq_ns != ns) && (seq_ns != ns->parent))\n\t\treturn -EPERM;\n\n\t/* Anyone can set any valid project id no capability needed */\n\treturn map_write(file, buf, size, ppos, -1,\n\t\t\t &ns->projid_map, &ns->parent->projid_map);\n}\n\nstatic bool new_idmap_permitted(const struct file *file,\n\t\t\t\tstruct user_namespace *ns, int cap_setid,\n\t\t\t\tstruct uid_gid_map *new_map)\n{\n\tconst struct cred *cred = file->f_cred;\n\t/* Don't allow mappings that would allow anything that wouldn't\n\t * be allowed without the establishment of unprivileged mappings.\n\t */\n\tif ((new_map->nr_extents == 1) && (new_map->extent[0].count == 1) &&\n\t    uid_eq(ns->owner, cred->euid)) {\n\t\tu32 id = new_map->extent[0].lower_first;\n\t\tif (cap_setid == CAP_SETUID) {\n\t\t\tkuid_t uid = make_kuid(ns->parent, id);\n\t\t\tif (uid_eq(uid, cred->euid))\n\t\t\t\treturn true;\n\t\t} else if (cap_setid == CAP_SETGID) {\n\t\t\tkgid_t gid = make_kgid(ns->parent, id);\n\t\t\tif (!(ns->flags & USERNS_SETGROUPS_ALLOWED) &&\n\t\t\t    gid_eq(gid, cred->egid))\n\t\t\t\treturn true;\n\t\t}\n\t}\n\n\t/* Allow anyone to set a mapping that doesn't require privilege */\n\tif (!cap_valid(cap_setid))\n\t\treturn true;\n\n\t/* Allow the specified ids if we have the appropriate capability\n\t * (CAP_SETUID or CAP_SETGID) over the parent user namespace.\n\t * And the opener of the id file also had the approprpiate capability.\n\t */\n\tif (ns_capable(ns->parent, cap_setid) &&\n\t    file_ns_capable(file, ns->parent, cap_setid))\n\t\treturn true;\n\n\treturn false;\n}\n\nint proc_setgroups_show(struct seq_file *seq, void *v)\n{\n\tstruct user_namespace *ns = seq->private;\n\tunsigned long userns_flags = READ_ONCE(ns->flags);\n\n\tseq_printf(seq, \"%s\\n\",\n\t\t   (userns_flags & USERNS_SETGROUPS_ALLOWED) ?\n\t\t   \"allow\" : \"deny\");\n\treturn 0;\n}\n\nssize_t proc_setgroups_write(struct file *file, const char __user *buf,\n\t\t\t     size_t count, loff_t *ppos)\n{\n\tstruct seq_file *seq = file->private_data;\n\tstruct user_namespace *ns = seq->private;\n\tchar kbuf[8], *pos;\n\tbool setgroups_allowed;\n\tssize_t ret;\n\n\t/* Only allow a very narrow range of strings to be written */\n\tret = -EINVAL;\n\tif ((*ppos != 0) || (count >= sizeof(kbuf)))\n\t\tgoto out;\n\n\t/* What was written? */\n\tret = -EFAULT;\n\tif (copy_from_user(kbuf, buf, count))\n\t\tgoto out;\n\tkbuf[count] = '\\0';\n\tpos = kbuf;\n\n\t/* What is being requested? */\n\tret = -EINVAL;\n\tif (strncmp(pos, \"allow\", 5) == 0) {\n\t\tpos += 5;\n\t\tsetgroups_allowed = true;\n\t}\n\telse if (strncmp(pos, \"deny\", 4) == 0) {\n\t\tpos += 4;\n\t\tsetgroups_allowed = false;\n\t}\n\telse\n\t\tgoto out;\n\n\t/* Verify there is not trailing junk on the line */\n\tpos = skip_spaces(pos);\n\tif (*pos != '\\0')\n\t\tgoto out;\n\n\tret = -EPERM;\n\tmutex_lock(&userns_state_mutex);\n\tif (setgroups_allowed) {\n\t\t/* Enabling setgroups after setgroups has been disabled\n\t\t * is not allowed.\n\t\t */\n\t\tif (!(ns->flags & USERNS_SETGROUPS_ALLOWED))\n\t\t\tgoto out_unlock;\n\t} else {\n\t\t/* Permanently disabling setgroups after setgroups has\n\t\t * been enabled by writing the gid_map is not allowed.\n\t\t */\n\t\tif (ns->gid_map.nr_extents != 0)\n\t\t\tgoto out_unlock;\n\t\tns->flags &= ~USERNS_SETGROUPS_ALLOWED;\n\t}\n\tmutex_unlock(&userns_state_mutex);\n\n\t/* Report a successful write */\n\t*ppos = count;\n\tret = count;\nout:\n\treturn ret;\nout_unlock:\n\tmutex_unlock(&userns_state_mutex);\n\tgoto out;\n}\n\nbool userns_may_setgroups(const struct user_namespace *ns)\n{\n\tbool allowed;\n\n\tmutex_lock(&userns_state_mutex);\n\t/* It is not safe to use setgroups until a gid mapping in\n\t * the user namespace has been established.\n\t */\n\tallowed = ns->gid_map.nr_extents != 0;\n\t/* Is setgroups allowed? */\n\tallowed = allowed && (ns->flags & USERNS_SETGROUPS_ALLOWED);\n\tmutex_unlock(&userns_state_mutex);\n\n\treturn allowed;\n}\n\n/*\n * Returns true if @child is the same namespace or a descendant of\n * @ancestor.\n */\nbool in_userns(const struct user_namespace *ancestor,\n\t       const struct user_namespace *child)\n{\n\tconst struct user_namespace *ns;\n\tfor (ns = child; ns->level > ancestor->level; ns = ns->parent)\n\t\t;\n\treturn (ns == ancestor);\n}\n\nbool current_in_userns(const struct user_namespace *target_ns)\n{\n\treturn in_userns(target_ns, current_user_ns());\n}\nEXPORT_SYMBOL(current_in_userns);\n\nstatic inline struct user_namespace *to_user_ns(struct ns_common *ns)\n{\n\treturn container_of(ns, struct user_namespace, ns);\n}\n\nstatic struct ns_common *userns_get(struct task_struct *task)\n{\n\tstruct user_namespace *user_ns;\n\n\trcu_read_lock();\n\tuser_ns = get_user_ns(__task_cred(task)->user_ns);\n\trcu_read_unlock();\n\n\treturn user_ns ? &user_ns->ns : NULL;\n}\n\nstatic void userns_put(struct ns_common *ns)\n{\n\tput_user_ns(to_user_ns(ns));\n}\n\nstatic int userns_install(struct nsproxy *nsproxy, struct ns_common *ns)\n{\n\tstruct user_namespace *user_ns = to_user_ns(ns);\n\tstruct cred *cred;\n\n\t/* Don't allow gaining capabilities by reentering\n\t * the same user namespace.\n\t */\n\tif (user_ns == current_user_ns())\n\t\treturn -EINVAL;\n\n\t/* Tasks that share a thread group must share a user namespace */\n\tif (!thread_group_empty(current))\n\t\treturn -EINVAL;\n\n\tif (current->fs->users != 1)\n\t\treturn -EINVAL;\n\n\tif (!ns_capable(user_ns, CAP_SYS_ADMIN))\n\t\treturn -EPERM;\n\n\tcred = prepare_creds();\n\tif (!cred)\n\t\treturn -ENOMEM;\n\n\tput_user_ns(cred->user_ns);\n\tset_cred_user_ns(cred, get_user_ns(user_ns));\n\n\treturn commit_creds(cred);\n}\n\nstruct ns_common *ns_get_owner(struct ns_common *ns)\n{\n\tstruct user_namespace *my_user_ns = current_user_ns();\n\tstruct user_namespace *owner, *p;\n\n\t/* See if the owner is in the current user namespace */\n\towner = p = ns->ops->owner(ns);\n\tfor (;;) {\n\t\tif (!p)\n\t\t\treturn ERR_PTR(-EPERM);\n\t\tif (p == my_user_ns)\n\t\t\tbreak;\n\t\tp = p->parent;\n\t}\n\n\treturn &get_user_ns(owner)->ns;\n}\n\nstatic struct user_namespace *userns_owner(struct ns_common *ns)\n{\n\treturn to_user_ns(ns)->parent;\n}\n\nconst struct proc_ns_operations userns_operations = {\n\t.name\t\t= \"user\",\n\t.type\t\t= CLONE_NEWUSER,\n\t.get\t\t= userns_get,\n\t.put\t\t= userns_put,\n\t.install\t= userns_install,\n\t.owner\t\t= userns_owner,\n\t.get_parent\t= ns_get_owner,\n};\n\nstatic __init int user_namespaces_init(void)\n{\n\tuser_ns_cachep = KMEM_CACHE(user_namespace, SLAB_PANIC);\n\treturn 0;\n}\nsubsys_initcall(user_namespaces_init);\n"], "fixing_code": ["/*\n *  This program is free software; you can redistribute it and/or\n *  modify it under the terms of the GNU General Public License as\n *  published by the Free Software Foundation, version 2 of the\n *  License.\n */\n\n#include <linux/export.h>\n#include <linux/nsproxy.h>\n#include <linux/slab.h>\n#include <linux/sched/signal.h>\n#include <linux/user_namespace.h>\n#include <linux/proc_ns.h>\n#include <linux/highuid.h>\n#include <linux/cred.h>\n#include <linux/securebits.h>\n#include <linux/keyctl.h>\n#include <linux/key-type.h>\n#include <keys/user-type.h>\n#include <linux/seq_file.h>\n#include <linux/fs.h>\n#include <linux/uaccess.h>\n#include <linux/ctype.h>\n#include <linux/projid.h>\n#include <linux/fs_struct.h>\n#include <linux/bsearch.h>\n#include <linux/sort.h>\n\nstatic struct kmem_cache *user_ns_cachep __read_mostly;\nstatic DEFINE_MUTEX(userns_state_mutex);\n\nstatic bool new_idmap_permitted(const struct file *file,\n\t\t\t\tstruct user_namespace *ns, int cap_setid,\n\t\t\t\tstruct uid_gid_map *map);\nstatic void free_user_ns(struct work_struct *work);\n\nstatic struct ucounts *inc_user_namespaces(struct user_namespace *ns, kuid_t uid)\n{\n\treturn inc_ucount(ns, uid, UCOUNT_USER_NAMESPACES);\n}\n\nstatic void dec_user_namespaces(struct ucounts *ucounts)\n{\n\treturn dec_ucount(ucounts, UCOUNT_USER_NAMESPACES);\n}\n\nstatic void set_cred_user_ns(struct cred *cred, struct user_namespace *user_ns)\n{\n\t/* Start with the same capabilities as init but useless for doing\n\t * anything as the capabilities are bound to the new user namespace.\n\t */\n\tcred->securebits = SECUREBITS_DEFAULT;\n\tcred->cap_inheritable = CAP_EMPTY_SET;\n\tcred->cap_permitted = CAP_FULL_SET;\n\tcred->cap_effective = CAP_FULL_SET;\n\tcred->cap_ambient = CAP_EMPTY_SET;\n\tcred->cap_bset = CAP_FULL_SET;\n#ifdef CONFIG_KEYS\n\tkey_put(cred->request_key_auth);\n\tcred->request_key_auth = NULL;\n#endif\n\t/* tgcred will be cleared in our caller bc CLONE_THREAD won't be set */\n\tcred->user_ns = user_ns;\n}\n\n/*\n * Create a new user namespace, deriving the creator from the user in the\n * passed credentials, and replacing that user with the new root user for the\n * new namespace.\n *\n * This is called by copy_creds(), which will finish setting the target task's\n * credentials.\n */\nint create_user_ns(struct cred *new)\n{\n\tstruct user_namespace *ns, *parent_ns = new->user_ns;\n\tkuid_t owner = new->euid;\n\tkgid_t group = new->egid;\n\tstruct ucounts *ucounts;\n\tint ret, i;\n\n\tret = -ENOSPC;\n\tif (parent_ns->level > 32)\n\t\tgoto fail;\n\n\tucounts = inc_user_namespaces(parent_ns, owner);\n\tif (!ucounts)\n\t\tgoto fail;\n\n\t/*\n\t * Verify that we can not violate the policy of which files\n\t * may be accessed that is specified by the root directory,\n\t * by verifing that the root directory is at the root of the\n\t * mount namespace which allows all files to be accessed.\n\t */\n\tret = -EPERM;\n\tif (current_chrooted())\n\t\tgoto fail_dec;\n\n\t/* The creator needs a mapping in the parent user namespace\n\t * or else we won't be able to reasonably tell userspace who\n\t * created a user_namespace.\n\t */\n\tret = -EPERM;\n\tif (!kuid_has_mapping(parent_ns, owner) ||\n\t    !kgid_has_mapping(parent_ns, group))\n\t\tgoto fail_dec;\n\n\tret = -ENOMEM;\n\tns = kmem_cache_zalloc(user_ns_cachep, GFP_KERNEL);\n\tif (!ns)\n\t\tgoto fail_dec;\n\n\tret = ns_alloc_inum(&ns->ns);\n\tif (ret)\n\t\tgoto fail_free;\n\tns->ns.ops = &userns_operations;\n\n\tatomic_set(&ns->count, 1);\n\t/* Leave the new->user_ns reference with the new user namespace. */\n\tns->parent = parent_ns;\n\tns->level = parent_ns->level + 1;\n\tns->owner = owner;\n\tns->group = group;\n\tINIT_WORK(&ns->work, free_user_ns);\n\tfor (i = 0; i < UCOUNT_COUNTS; i++) {\n\t\tns->ucount_max[i] = INT_MAX;\n\t}\n\tns->ucounts = ucounts;\n\n\t/* Inherit USERNS_SETGROUPS_ALLOWED from our parent */\n\tmutex_lock(&userns_state_mutex);\n\tns->flags = parent_ns->flags;\n\tmutex_unlock(&userns_state_mutex);\n\n#ifdef CONFIG_PERSISTENT_KEYRINGS\n\tinit_rwsem(&ns->persistent_keyring_register_sem);\n#endif\n\tret = -ENOMEM;\n\tif (!setup_userns_sysctls(ns))\n\t\tgoto fail_keyring;\n\n\tset_cred_user_ns(new, ns);\n\treturn 0;\nfail_keyring:\n#ifdef CONFIG_PERSISTENT_KEYRINGS\n\tkey_put(ns->persistent_keyring_register);\n#endif\n\tns_free_inum(&ns->ns);\nfail_free:\n\tkmem_cache_free(user_ns_cachep, ns);\nfail_dec:\n\tdec_user_namespaces(ucounts);\nfail:\n\treturn ret;\n}\n\nint unshare_userns(unsigned long unshare_flags, struct cred **new_cred)\n{\n\tstruct cred *cred;\n\tint err = -ENOMEM;\n\n\tif (!(unshare_flags & CLONE_NEWUSER))\n\t\treturn 0;\n\n\tcred = prepare_creds();\n\tif (cred) {\n\t\terr = create_user_ns(cred);\n\t\tif (err)\n\t\t\tput_cred(cred);\n\t\telse\n\t\t\t*new_cred = cred;\n\t}\n\n\treturn err;\n}\n\nstatic void free_user_ns(struct work_struct *work)\n{\n\tstruct user_namespace *parent, *ns =\n\t\tcontainer_of(work, struct user_namespace, work);\n\n\tdo {\n\t\tstruct ucounts *ucounts = ns->ucounts;\n\t\tparent = ns->parent;\n\t\tif (ns->gid_map.nr_extents > UID_GID_MAP_MAX_BASE_EXTENTS) {\n\t\t\tkfree(ns->gid_map.forward);\n\t\t\tkfree(ns->gid_map.reverse);\n\t\t}\n\t\tif (ns->uid_map.nr_extents > UID_GID_MAP_MAX_BASE_EXTENTS) {\n\t\t\tkfree(ns->uid_map.forward);\n\t\t\tkfree(ns->uid_map.reverse);\n\t\t}\n\t\tif (ns->projid_map.nr_extents > UID_GID_MAP_MAX_BASE_EXTENTS) {\n\t\t\tkfree(ns->projid_map.forward);\n\t\t\tkfree(ns->projid_map.reverse);\n\t\t}\n\t\tretire_userns_sysctls(ns);\n#ifdef CONFIG_PERSISTENT_KEYRINGS\n\t\tkey_put(ns->persistent_keyring_register);\n#endif\n\t\tns_free_inum(&ns->ns);\n\t\tkmem_cache_free(user_ns_cachep, ns);\n\t\tdec_user_namespaces(ucounts);\n\t\tns = parent;\n\t} while (atomic_dec_and_test(&parent->count));\n}\n\nvoid __put_user_ns(struct user_namespace *ns)\n{\n\tschedule_work(&ns->work);\n}\nEXPORT_SYMBOL(__put_user_ns);\n\n/**\n * idmap_key struct holds the information necessary to find an idmapping in a\n * sorted idmap array. It is passed to cmp_map_id() as first argument.\n */\nstruct idmap_key {\n\tbool map_up; /* true  -> id from kid; false -> kid from id */\n\tu32 id; /* id to find */\n\tu32 count; /* == 0 unless used with map_id_range_down() */\n};\n\n/**\n * cmp_map_id - Function to be passed to bsearch() to find the requested\n * idmapping. Expects struct idmap_key to be passed via @k.\n */\nstatic int cmp_map_id(const void *k, const void *e)\n{\n\tu32 first, last, id2;\n\tconst struct idmap_key *key = k;\n\tconst struct uid_gid_extent *el = e;\n\n\tid2 = key->id + key->count - 1;\n\n\t/* handle map_id_{down,up}() */\n\tif (key->map_up)\n\t\tfirst = el->lower_first;\n\telse\n\t\tfirst = el->first;\n\n\tlast = first + el->count - 1;\n\n\tif (key->id >= first && key->id <= last &&\n\t    (id2 >= first && id2 <= last))\n\t\treturn 0;\n\n\tif (key->id < first || id2 < first)\n\t\treturn -1;\n\n\treturn 1;\n}\n\n/**\n * map_id_range_down_max - Find idmap via binary search in ordered idmap array.\n * Can only be called if number of mappings exceeds UID_GID_MAP_MAX_BASE_EXTENTS.\n */\nstatic struct uid_gid_extent *\nmap_id_range_down_max(unsigned extents, struct uid_gid_map *map, u32 id, u32 count)\n{\n\tstruct idmap_key key;\n\n\tkey.map_up = false;\n\tkey.count = count;\n\tkey.id = id;\n\n\treturn bsearch(&key, map->forward, extents,\n\t\t       sizeof(struct uid_gid_extent), cmp_map_id);\n}\n\n/**\n * map_id_range_down_base - Find idmap via binary search in static extent array.\n * Can only be called if number of mappings is equal or less than\n * UID_GID_MAP_MAX_BASE_EXTENTS.\n */\nstatic struct uid_gid_extent *\nmap_id_range_down_base(unsigned extents, struct uid_gid_map *map, u32 id, u32 count)\n{\n\tunsigned idx;\n\tu32 first, last, id2;\n\n\tid2 = id + count - 1;\n\n\t/* Find the matching extent */\n\tfor (idx = 0; idx < extents; idx++) {\n\t\tfirst = map->extent[idx].first;\n\t\tlast = first + map->extent[idx].count - 1;\n\t\tif (id >= first && id <= last &&\n\t\t    (id2 >= first && id2 <= last))\n\t\t\treturn &map->extent[idx];\n\t}\n\treturn NULL;\n}\n\nstatic u32 map_id_range_down(struct uid_gid_map *map, u32 id, u32 count)\n{\n\tstruct uid_gid_extent *extent;\n\tunsigned extents = map->nr_extents;\n\tsmp_rmb();\n\n\tif (extents <= UID_GID_MAP_MAX_BASE_EXTENTS)\n\t\textent = map_id_range_down_base(extents, map, id, count);\n\telse\n\t\textent = map_id_range_down_max(extents, map, id, count);\n\n\t/* Map the id or note failure */\n\tif (extent)\n\t\tid = (id - extent->first) + extent->lower_first;\n\telse\n\t\tid = (u32) -1;\n\n\treturn id;\n}\n\nstatic u32 map_id_down(struct uid_gid_map *map, u32 id)\n{\n\treturn map_id_range_down(map, id, 1);\n}\n\n/**\n * map_id_up_base - Find idmap via binary search in static extent array.\n * Can only be called if number of mappings is equal or less than\n * UID_GID_MAP_MAX_BASE_EXTENTS.\n */\nstatic struct uid_gid_extent *\nmap_id_up_base(unsigned extents, struct uid_gid_map *map, u32 id)\n{\n\tunsigned idx;\n\tu32 first, last;\n\n\t/* Find the matching extent */\n\tfor (idx = 0; idx < extents; idx++) {\n\t\tfirst = map->extent[idx].lower_first;\n\t\tlast = first + map->extent[idx].count - 1;\n\t\tif (id >= first && id <= last)\n\t\t\treturn &map->extent[idx];\n\t}\n\treturn NULL;\n}\n\n/**\n * map_id_up_max - Find idmap via binary search in ordered idmap array.\n * Can only be called if number of mappings exceeds UID_GID_MAP_MAX_BASE_EXTENTS.\n */\nstatic struct uid_gid_extent *\nmap_id_up_max(unsigned extents, struct uid_gid_map *map, u32 id)\n{\n\tstruct idmap_key key;\n\n\tkey.map_up = true;\n\tkey.count = 1;\n\tkey.id = id;\n\n\treturn bsearch(&key, map->reverse, extents,\n\t\t       sizeof(struct uid_gid_extent), cmp_map_id);\n}\n\nstatic u32 map_id_up(struct uid_gid_map *map, u32 id)\n{\n\tstruct uid_gid_extent *extent;\n\tunsigned extents = map->nr_extents;\n\tsmp_rmb();\n\n\tif (extents <= UID_GID_MAP_MAX_BASE_EXTENTS)\n\t\textent = map_id_up_base(extents, map, id);\n\telse\n\t\textent = map_id_up_max(extents, map, id);\n\n\t/* Map the id or note failure */\n\tif (extent)\n\t\tid = (id - extent->lower_first) + extent->first;\n\telse\n\t\tid = (u32) -1;\n\n\treturn id;\n}\n\n/**\n *\tmake_kuid - Map a user-namespace uid pair into a kuid.\n *\t@ns:  User namespace that the uid is in\n *\t@uid: User identifier\n *\n *\tMaps a user-namespace uid pair into a kernel internal kuid,\n *\tand returns that kuid.\n *\n *\tWhen there is no mapping defined for the user-namespace uid\n *\tpair INVALID_UID is returned.  Callers are expected to test\n *\tfor and handle INVALID_UID being returned.  INVALID_UID\n *\tmay be tested for using uid_valid().\n */\nkuid_t make_kuid(struct user_namespace *ns, uid_t uid)\n{\n\t/* Map the uid to a global kernel uid */\n\treturn KUIDT_INIT(map_id_down(&ns->uid_map, uid));\n}\nEXPORT_SYMBOL(make_kuid);\n\n/**\n *\tfrom_kuid - Create a uid from a kuid user-namespace pair.\n *\t@targ: The user namespace we want a uid in.\n *\t@kuid: The kernel internal uid to start with.\n *\n *\tMap @kuid into the user-namespace specified by @targ and\n *\treturn the resulting uid.\n *\n *\tThere is always a mapping into the initial user_namespace.\n *\n *\tIf @kuid has no mapping in @targ (uid_t)-1 is returned.\n */\nuid_t from_kuid(struct user_namespace *targ, kuid_t kuid)\n{\n\t/* Map the uid from a global kernel uid */\n\treturn map_id_up(&targ->uid_map, __kuid_val(kuid));\n}\nEXPORT_SYMBOL(from_kuid);\n\n/**\n *\tfrom_kuid_munged - Create a uid from a kuid user-namespace pair.\n *\t@targ: The user namespace we want a uid in.\n *\t@kuid: The kernel internal uid to start with.\n *\n *\tMap @kuid into the user-namespace specified by @targ and\n *\treturn the resulting uid.\n *\n *\tThere is always a mapping into the initial user_namespace.\n *\n *\tUnlike from_kuid from_kuid_munged never fails and always\n *\treturns a valid uid.  This makes from_kuid_munged appropriate\n *\tfor use in syscalls like stat and getuid where failing the\n *\tsystem call and failing to provide a valid uid are not an\n *\toptions.\n *\n *\tIf @kuid has no mapping in @targ overflowuid is returned.\n */\nuid_t from_kuid_munged(struct user_namespace *targ, kuid_t kuid)\n{\n\tuid_t uid;\n\tuid = from_kuid(targ, kuid);\n\n\tif (uid == (uid_t) -1)\n\t\tuid = overflowuid;\n\treturn uid;\n}\nEXPORT_SYMBOL(from_kuid_munged);\n\n/**\n *\tmake_kgid - Map a user-namespace gid pair into a kgid.\n *\t@ns:  User namespace that the gid is in\n *\t@gid: group identifier\n *\n *\tMaps a user-namespace gid pair into a kernel internal kgid,\n *\tand returns that kgid.\n *\n *\tWhen there is no mapping defined for the user-namespace gid\n *\tpair INVALID_GID is returned.  Callers are expected to test\n *\tfor and handle INVALID_GID being returned.  INVALID_GID may be\n *\ttested for using gid_valid().\n */\nkgid_t make_kgid(struct user_namespace *ns, gid_t gid)\n{\n\t/* Map the gid to a global kernel gid */\n\treturn KGIDT_INIT(map_id_down(&ns->gid_map, gid));\n}\nEXPORT_SYMBOL(make_kgid);\n\n/**\n *\tfrom_kgid - Create a gid from a kgid user-namespace pair.\n *\t@targ: The user namespace we want a gid in.\n *\t@kgid: The kernel internal gid to start with.\n *\n *\tMap @kgid into the user-namespace specified by @targ and\n *\treturn the resulting gid.\n *\n *\tThere is always a mapping into the initial user_namespace.\n *\n *\tIf @kgid has no mapping in @targ (gid_t)-1 is returned.\n */\ngid_t from_kgid(struct user_namespace *targ, kgid_t kgid)\n{\n\t/* Map the gid from a global kernel gid */\n\treturn map_id_up(&targ->gid_map, __kgid_val(kgid));\n}\nEXPORT_SYMBOL(from_kgid);\n\n/**\n *\tfrom_kgid_munged - Create a gid from a kgid user-namespace pair.\n *\t@targ: The user namespace we want a gid in.\n *\t@kgid: The kernel internal gid to start with.\n *\n *\tMap @kgid into the user-namespace specified by @targ and\n *\treturn the resulting gid.\n *\n *\tThere is always a mapping into the initial user_namespace.\n *\n *\tUnlike from_kgid from_kgid_munged never fails and always\n *\treturns a valid gid.  This makes from_kgid_munged appropriate\n *\tfor use in syscalls like stat and getgid where failing the\n *\tsystem call and failing to provide a valid gid are not options.\n *\n *\tIf @kgid has no mapping in @targ overflowgid is returned.\n */\ngid_t from_kgid_munged(struct user_namespace *targ, kgid_t kgid)\n{\n\tgid_t gid;\n\tgid = from_kgid(targ, kgid);\n\n\tif (gid == (gid_t) -1)\n\t\tgid = overflowgid;\n\treturn gid;\n}\nEXPORT_SYMBOL(from_kgid_munged);\n\n/**\n *\tmake_kprojid - Map a user-namespace projid pair into a kprojid.\n *\t@ns:  User namespace that the projid is in\n *\t@projid: Project identifier\n *\n *\tMaps a user-namespace uid pair into a kernel internal kuid,\n *\tand returns that kuid.\n *\n *\tWhen there is no mapping defined for the user-namespace projid\n *\tpair INVALID_PROJID is returned.  Callers are expected to test\n *\tfor and handle handle INVALID_PROJID being returned.  INVALID_PROJID\n *\tmay be tested for using projid_valid().\n */\nkprojid_t make_kprojid(struct user_namespace *ns, projid_t projid)\n{\n\t/* Map the uid to a global kernel uid */\n\treturn KPROJIDT_INIT(map_id_down(&ns->projid_map, projid));\n}\nEXPORT_SYMBOL(make_kprojid);\n\n/**\n *\tfrom_kprojid - Create a projid from a kprojid user-namespace pair.\n *\t@targ: The user namespace we want a projid in.\n *\t@kprojid: The kernel internal project identifier to start with.\n *\n *\tMap @kprojid into the user-namespace specified by @targ and\n *\treturn the resulting projid.\n *\n *\tThere is always a mapping into the initial user_namespace.\n *\n *\tIf @kprojid has no mapping in @targ (projid_t)-1 is returned.\n */\nprojid_t from_kprojid(struct user_namespace *targ, kprojid_t kprojid)\n{\n\t/* Map the uid from a global kernel uid */\n\treturn map_id_up(&targ->projid_map, __kprojid_val(kprojid));\n}\nEXPORT_SYMBOL(from_kprojid);\n\n/**\n *\tfrom_kprojid_munged - Create a projiid from a kprojid user-namespace pair.\n *\t@targ: The user namespace we want a projid in.\n *\t@kprojid: The kernel internal projid to start with.\n *\n *\tMap @kprojid into the user-namespace specified by @targ and\n *\treturn the resulting projid.\n *\n *\tThere is always a mapping into the initial user_namespace.\n *\n *\tUnlike from_kprojid from_kprojid_munged never fails and always\n *\treturns a valid projid.  This makes from_kprojid_munged\n *\tappropriate for use in syscalls like stat and where\n *\tfailing the system call and failing to provide a valid projid are\n *\tnot an options.\n *\n *\tIf @kprojid has no mapping in @targ OVERFLOW_PROJID is returned.\n */\nprojid_t from_kprojid_munged(struct user_namespace *targ, kprojid_t kprojid)\n{\n\tprojid_t projid;\n\tprojid = from_kprojid(targ, kprojid);\n\n\tif (projid == (projid_t) -1)\n\t\tprojid = OVERFLOW_PROJID;\n\treturn projid;\n}\nEXPORT_SYMBOL(from_kprojid_munged);\n\n\nstatic int uid_m_show(struct seq_file *seq, void *v)\n{\n\tstruct user_namespace *ns = seq->private;\n\tstruct uid_gid_extent *extent = v;\n\tstruct user_namespace *lower_ns;\n\tuid_t lower;\n\n\tlower_ns = seq_user_ns(seq);\n\tif ((lower_ns == ns) && lower_ns->parent)\n\t\tlower_ns = lower_ns->parent;\n\n\tlower = from_kuid(lower_ns, KUIDT_INIT(extent->lower_first));\n\n\tseq_printf(seq, \"%10u %10u %10u\\n\",\n\t\textent->first,\n\t\tlower,\n\t\textent->count);\n\n\treturn 0;\n}\n\nstatic int gid_m_show(struct seq_file *seq, void *v)\n{\n\tstruct user_namespace *ns = seq->private;\n\tstruct uid_gid_extent *extent = v;\n\tstruct user_namespace *lower_ns;\n\tgid_t lower;\n\n\tlower_ns = seq_user_ns(seq);\n\tif ((lower_ns == ns) && lower_ns->parent)\n\t\tlower_ns = lower_ns->parent;\n\n\tlower = from_kgid(lower_ns, KGIDT_INIT(extent->lower_first));\n\n\tseq_printf(seq, \"%10u %10u %10u\\n\",\n\t\textent->first,\n\t\tlower,\n\t\textent->count);\n\n\treturn 0;\n}\n\nstatic int projid_m_show(struct seq_file *seq, void *v)\n{\n\tstruct user_namespace *ns = seq->private;\n\tstruct uid_gid_extent *extent = v;\n\tstruct user_namespace *lower_ns;\n\tprojid_t lower;\n\n\tlower_ns = seq_user_ns(seq);\n\tif ((lower_ns == ns) && lower_ns->parent)\n\t\tlower_ns = lower_ns->parent;\n\n\tlower = from_kprojid(lower_ns, KPROJIDT_INIT(extent->lower_first));\n\n\tseq_printf(seq, \"%10u %10u %10u\\n\",\n\t\textent->first,\n\t\tlower,\n\t\textent->count);\n\n\treturn 0;\n}\n\nstatic void *m_start(struct seq_file *seq, loff_t *ppos,\n\t\t     struct uid_gid_map *map)\n{\n\tloff_t pos = *ppos;\n\tunsigned extents = map->nr_extents;\n\tsmp_rmb();\n\n\tif (pos >= extents)\n\t\treturn NULL;\n\n\tif (extents <= UID_GID_MAP_MAX_BASE_EXTENTS)\n\t\treturn &map->extent[pos];\n\n\treturn &map->forward[pos];\n}\n\nstatic void *uid_m_start(struct seq_file *seq, loff_t *ppos)\n{\n\tstruct user_namespace *ns = seq->private;\n\n\treturn m_start(seq, ppos, &ns->uid_map);\n}\n\nstatic void *gid_m_start(struct seq_file *seq, loff_t *ppos)\n{\n\tstruct user_namespace *ns = seq->private;\n\n\treturn m_start(seq, ppos, &ns->gid_map);\n}\n\nstatic void *projid_m_start(struct seq_file *seq, loff_t *ppos)\n{\n\tstruct user_namespace *ns = seq->private;\n\n\treturn m_start(seq, ppos, &ns->projid_map);\n}\n\nstatic void *m_next(struct seq_file *seq, void *v, loff_t *pos)\n{\n\t(*pos)++;\n\treturn seq->op->start(seq, pos);\n}\n\nstatic void m_stop(struct seq_file *seq, void *v)\n{\n\treturn;\n}\n\nconst struct seq_operations proc_uid_seq_operations = {\n\t.start = uid_m_start,\n\t.stop = m_stop,\n\t.next = m_next,\n\t.show = uid_m_show,\n};\n\nconst struct seq_operations proc_gid_seq_operations = {\n\t.start = gid_m_start,\n\t.stop = m_stop,\n\t.next = m_next,\n\t.show = gid_m_show,\n};\n\nconst struct seq_operations proc_projid_seq_operations = {\n\t.start = projid_m_start,\n\t.stop = m_stop,\n\t.next = m_next,\n\t.show = projid_m_show,\n};\n\nstatic bool mappings_overlap(struct uid_gid_map *new_map,\n\t\t\t     struct uid_gid_extent *extent)\n{\n\tu32 upper_first, lower_first, upper_last, lower_last;\n\tunsigned idx;\n\n\tupper_first = extent->first;\n\tlower_first = extent->lower_first;\n\tupper_last = upper_first + extent->count - 1;\n\tlower_last = lower_first + extent->count - 1;\n\n\tfor (idx = 0; idx < new_map->nr_extents; idx++) {\n\t\tu32 prev_upper_first, prev_lower_first;\n\t\tu32 prev_upper_last, prev_lower_last;\n\t\tstruct uid_gid_extent *prev;\n\n\t\tif (new_map->nr_extents <= UID_GID_MAP_MAX_BASE_EXTENTS)\n\t\t\tprev = &new_map->extent[idx];\n\t\telse\n\t\t\tprev = &new_map->forward[idx];\n\n\t\tprev_upper_first = prev->first;\n\t\tprev_lower_first = prev->lower_first;\n\t\tprev_upper_last = prev_upper_first + prev->count - 1;\n\t\tprev_lower_last = prev_lower_first + prev->count - 1;\n\n\t\t/* Does the upper range intersect a previous extent? */\n\t\tif ((prev_upper_first <= upper_last) &&\n\t\t    (prev_upper_last >= upper_first))\n\t\t\treturn true;\n\n\t\t/* Does the lower range intersect a previous extent? */\n\t\tif ((prev_lower_first <= lower_last) &&\n\t\t    (prev_lower_last >= lower_first))\n\t\t\treturn true;\n\t}\n\treturn false;\n}\n\n/**\n * insert_extent - Safely insert a new idmap extent into struct uid_gid_map.\n * Takes care to allocate a 4K block of memory if the number of mappings exceeds\n * UID_GID_MAP_MAX_BASE_EXTENTS.\n */\nstatic int insert_extent(struct uid_gid_map *map, struct uid_gid_extent *extent)\n{\n\tstruct uid_gid_extent *dest;\n\n\tif (map->nr_extents == UID_GID_MAP_MAX_BASE_EXTENTS) {\n\t\tstruct uid_gid_extent *forward;\n\n\t\t/* Allocate memory for 340 mappings. */\n\t\tforward = kmalloc_array(UID_GID_MAP_MAX_EXTENTS,\n\t\t\t\t\tsizeof(struct uid_gid_extent),\n\t\t\t\t\tGFP_KERNEL);\n\t\tif (!forward)\n\t\t\treturn -ENOMEM;\n\n\t\t/* Copy over memory. Only set up memory for the forward pointer.\n\t\t * Defer the memory setup for the reverse pointer.\n\t\t */\n\t\tmemcpy(forward, map->extent,\n\t\t       map->nr_extents * sizeof(map->extent[0]));\n\n\t\tmap->forward = forward;\n\t\tmap->reverse = NULL;\n\t}\n\n\tif (map->nr_extents < UID_GID_MAP_MAX_BASE_EXTENTS)\n\t\tdest = &map->extent[map->nr_extents];\n\telse\n\t\tdest = &map->forward[map->nr_extents];\n\n\t*dest = *extent;\n\tmap->nr_extents++;\n\treturn 0;\n}\n\n/* cmp function to sort() forward mappings */\nstatic int cmp_extents_forward(const void *a, const void *b)\n{\n\tconst struct uid_gid_extent *e1 = a;\n\tconst struct uid_gid_extent *e2 = b;\n\n\tif (e1->first < e2->first)\n\t\treturn -1;\n\n\tif (e1->first > e2->first)\n\t\treturn 1;\n\n\treturn 0;\n}\n\n/* cmp function to sort() reverse mappings */\nstatic int cmp_extents_reverse(const void *a, const void *b)\n{\n\tconst struct uid_gid_extent *e1 = a;\n\tconst struct uid_gid_extent *e2 = b;\n\n\tif (e1->lower_first < e2->lower_first)\n\t\treturn -1;\n\n\tif (e1->lower_first > e2->lower_first)\n\t\treturn 1;\n\n\treturn 0;\n}\n\n/**\n * sort_idmaps - Sorts an array of idmap entries.\n * Can only be called if number of mappings exceeds UID_GID_MAP_MAX_BASE_EXTENTS.\n */\nstatic int sort_idmaps(struct uid_gid_map *map)\n{\n\tif (map->nr_extents <= UID_GID_MAP_MAX_BASE_EXTENTS)\n\t\treturn 0;\n\n\t/* Sort forward array. */\n\tsort(map->forward, map->nr_extents, sizeof(struct uid_gid_extent),\n\t     cmp_extents_forward, NULL);\n\n\t/* Only copy the memory from forward we actually need. */\n\tmap->reverse = kmemdup(map->forward,\n\t\t\t       map->nr_extents * sizeof(struct uid_gid_extent),\n\t\t\t       GFP_KERNEL);\n\tif (!map->reverse)\n\t\treturn -ENOMEM;\n\n\t/* Sort reverse array. */\n\tsort(map->reverse, map->nr_extents, sizeof(struct uid_gid_extent),\n\t     cmp_extents_reverse, NULL);\n\n\treturn 0;\n}\n\nstatic ssize_t map_write(struct file *file, const char __user *buf,\n\t\t\t size_t count, loff_t *ppos,\n\t\t\t int cap_setid,\n\t\t\t struct uid_gid_map *map,\n\t\t\t struct uid_gid_map *parent_map)\n{\n\tstruct seq_file *seq = file->private_data;\n\tstruct user_namespace *ns = seq->private;\n\tstruct uid_gid_map new_map;\n\tunsigned idx;\n\tstruct uid_gid_extent extent;\n\tchar *kbuf = NULL, *pos, *next_line;\n\tssize_t ret;\n\n\t/* Only allow < page size writes at the beginning of the file */\n\tif ((*ppos != 0) || (count >= PAGE_SIZE))\n\t\treturn -EINVAL;\n\n\t/* Slurp in the user data */\n\tkbuf = memdup_user_nul(buf, count);\n\tif (IS_ERR(kbuf))\n\t\treturn PTR_ERR(kbuf);\n\n\t/*\n\t * The userns_state_mutex serializes all writes to any given map.\n\t *\n\t * Any map is only ever written once.\n\t *\n\t * An id map fits within 1 cache line on most architectures.\n\t *\n\t * On read nothing needs to be done unless you are on an\n\t * architecture with a crazy cache coherency model like alpha.\n\t *\n\t * There is a one time data dependency between reading the\n\t * count of the extents and the values of the extents.  The\n\t * desired behavior is to see the values of the extents that\n\t * were written before the count of the extents.\n\t *\n\t * To achieve this smp_wmb() is used on guarantee the write\n\t * order and smp_rmb() is guaranteed that we don't have crazy\n\t * architectures returning stale data.\n\t */\n\tmutex_lock(&userns_state_mutex);\n\n\tmemset(&new_map, 0, sizeof(struct uid_gid_map));\n\n\tret = -EPERM;\n\t/* Only allow one successful write to the map */\n\tif (map->nr_extents != 0)\n\t\tgoto out;\n\n\t/*\n\t * Adjusting namespace settings requires capabilities on the target.\n\t */\n\tif (cap_valid(cap_setid) && !file_ns_capable(file, ns, CAP_SYS_ADMIN))\n\t\tgoto out;\n\n\t/* Parse the user data */\n\tret = -EINVAL;\n\tpos = kbuf;\n\tfor (; pos; pos = next_line) {\n\n\t\t/* Find the end of line and ensure I don't look past it */\n\t\tnext_line = strchr(pos, '\\n');\n\t\tif (next_line) {\n\t\t\t*next_line = '\\0';\n\t\t\tnext_line++;\n\t\t\tif (*next_line == '\\0')\n\t\t\t\tnext_line = NULL;\n\t\t}\n\n\t\tpos = skip_spaces(pos);\n\t\textent.first = simple_strtoul(pos, &pos, 10);\n\t\tif (!isspace(*pos))\n\t\t\tgoto out;\n\n\t\tpos = skip_spaces(pos);\n\t\textent.lower_first = simple_strtoul(pos, &pos, 10);\n\t\tif (!isspace(*pos))\n\t\t\tgoto out;\n\n\t\tpos = skip_spaces(pos);\n\t\textent.count = simple_strtoul(pos, &pos, 10);\n\t\tif (*pos && !isspace(*pos))\n\t\t\tgoto out;\n\n\t\t/* Verify there is not trailing junk on the line */\n\t\tpos = skip_spaces(pos);\n\t\tif (*pos != '\\0')\n\t\t\tgoto out;\n\n\t\t/* Verify we have been given valid starting values */\n\t\tif ((extent.first == (u32) -1) ||\n\t\t    (extent.lower_first == (u32) -1))\n\t\t\tgoto out;\n\n\t\t/* Verify count is not zero and does not cause the\n\t\t * extent to wrap\n\t\t */\n\t\tif ((extent.first + extent.count) <= extent.first)\n\t\t\tgoto out;\n\t\tif ((extent.lower_first + extent.count) <=\n\t\t     extent.lower_first)\n\t\t\tgoto out;\n\n\t\t/* Do the ranges in extent overlap any previous extents? */\n\t\tif (mappings_overlap(&new_map, &extent))\n\t\t\tgoto out;\n\n\t\tif ((new_map.nr_extents + 1) == UID_GID_MAP_MAX_EXTENTS &&\n\t\t    (next_line != NULL))\n\t\t\tgoto out;\n\n\t\tret = insert_extent(&new_map, &extent);\n\t\tif (ret < 0)\n\t\t\tgoto out;\n\t\tret = -EINVAL;\n\t}\n\t/* Be very certaint the new map actually exists */\n\tif (new_map.nr_extents == 0)\n\t\tgoto out;\n\n\tret = -EPERM;\n\t/* Validate the user is allowed to use user id's mapped to. */\n\tif (!new_idmap_permitted(file, ns, cap_setid, &new_map))\n\t\tgoto out;\n\n\tret = -EPERM;\n\t/* Map the lower ids from the parent user namespace to the\n\t * kernel global id space.\n\t */\n\tfor (idx = 0; idx < new_map.nr_extents; idx++) {\n\t\tstruct uid_gid_extent *e;\n\t\tu32 lower_first;\n\n\t\tif (new_map.nr_extents <= UID_GID_MAP_MAX_BASE_EXTENTS)\n\t\t\te = &new_map.extent[idx];\n\t\telse\n\t\t\te = &new_map.forward[idx];\n\n\t\tlower_first = map_id_range_down(parent_map,\n\t\t\t\t\t\te->lower_first,\n\t\t\t\t\t\te->count);\n\n\t\t/* Fail if we can not map the specified extent to\n\t\t * the kernel global id space.\n\t\t */\n\t\tif (lower_first == (u32) -1)\n\t\t\tgoto out;\n\n\t\te->lower_first = lower_first;\n\t}\n\n\t/*\n\t * If we want to use binary search for lookup, this clones the extent\n\t * array and sorts both copies.\n\t */\n\tret = sort_idmaps(&new_map);\n\tif (ret < 0)\n\t\tgoto out;\n\n\t/* Install the map */\n\tif (new_map.nr_extents <= UID_GID_MAP_MAX_BASE_EXTENTS) {\n\t\tmemcpy(map->extent, new_map.extent,\n\t\t       new_map.nr_extents * sizeof(new_map.extent[0]));\n\t} else {\n\t\tmap->forward = new_map.forward;\n\t\tmap->reverse = new_map.reverse;\n\t}\n\tsmp_wmb();\n\tmap->nr_extents = new_map.nr_extents;\n\n\t*ppos = count;\n\tret = count;\nout:\n\tif (ret < 0 && new_map.nr_extents > UID_GID_MAP_MAX_BASE_EXTENTS) {\n\t\tkfree(new_map.forward);\n\t\tkfree(new_map.reverse);\n\t\tmap->forward = NULL;\n\t\tmap->reverse = NULL;\n\t\tmap->nr_extents = 0;\n\t}\n\n\tmutex_unlock(&userns_state_mutex);\n\tkfree(kbuf);\n\treturn ret;\n}\n\nssize_t proc_uid_map_write(struct file *file, const char __user *buf,\n\t\t\t   size_t size, loff_t *ppos)\n{\n\tstruct seq_file *seq = file->private_data;\n\tstruct user_namespace *ns = seq->private;\n\tstruct user_namespace *seq_ns = seq_user_ns(seq);\n\n\tif (!ns->parent)\n\t\treturn -EPERM;\n\n\tif ((seq_ns != ns) && (seq_ns != ns->parent))\n\t\treturn -EPERM;\n\n\treturn map_write(file, buf, size, ppos, CAP_SETUID,\n\t\t\t &ns->uid_map, &ns->parent->uid_map);\n}\n\nssize_t proc_gid_map_write(struct file *file, const char __user *buf,\n\t\t\t   size_t size, loff_t *ppos)\n{\n\tstruct seq_file *seq = file->private_data;\n\tstruct user_namespace *ns = seq->private;\n\tstruct user_namespace *seq_ns = seq_user_ns(seq);\n\n\tif (!ns->parent)\n\t\treturn -EPERM;\n\n\tif ((seq_ns != ns) && (seq_ns != ns->parent))\n\t\treturn -EPERM;\n\n\treturn map_write(file, buf, size, ppos, CAP_SETGID,\n\t\t\t &ns->gid_map, &ns->parent->gid_map);\n}\n\nssize_t proc_projid_map_write(struct file *file, const char __user *buf,\n\t\t\t      size_t size, loff_t *ppos)\n{\n\tstruct seq_file *seq = file->private_data;\n\tstruct user_namespace *ns = seq->private;\n\tstruct user_namespace *seq_ns = seq_user_ns(seq);\n\n\tif (!ns->parent)\n\t\treturn -EPERM;\n\n\tif ((seq_ns != ns) && (seq_ns != ns->parent))\n\t\treturn -EPERM;\n\n\t/* Anyone can set any valid project id no capability needed */\n\treturn map_write(file, buf, size, ppos, -1,\n\t\t\t &ns->projid_map, &ns->parent->projid_map);\n}\n\nstatic bool new_idmap_permitted(const struct file *file,\n\t\t\t\tstruct user_namespace *ns, int cap_setid,\n\t\t\t\tstruct uid_gid_map *new_map)\n{\n\tconst struct cred *cred = file->f_cred;\n\t/* Don't allow mappings that would allow anything that wouldn't\n\t * be allowed without the establishment of unprivileged mappings.\n\t */\n\tif ((new_map->nr_extents == 1) && (new_map->extent[0].count == 1) &&\n\t    uid_eq(ns->owner, cred->euid)) {\n\t\tu32 id = new_map->extent[0].lower_first;\n\t\tif (cap_setid == CAP_SETUID) {\n\t\t\tkuid_t uid = make_kuid(ns->parent, id);\n\t\t\tif (uid_eq(uid, cred->euid))\n\t\t\t\treturn true;\n\t\t} else if (cap_setid == CAP_SETGID) {\n\t\t\tkgid_t gid = make_kgid(ns->parent, id);\n\t\t\tif (!(ns->flags & USERNS_SETGROUPS_ALLOWED) &&\n\t\t\t    gid_eq(gid, cred->egid))\n\t\t\t\treturn true;\n\t\t}\n\t}\n\n\t/* Allow anyone to set a mapping that doesn't require privilege */\n\tif (!cap_valid(cap_setid))\n\t\treturn true;\n\n\t/* Allow the specified ids if we have the appropriate capability\n\t * (CAP_SETUID or CAP_SETGID) over the parent user namespace.\n\t * And the opener of the id file also had the approprpiate capability.\n\t */\n\tif (ns_capable(ns->parent, cap_setid) &&\n\t    file_ns_capable(file, ns->parent, cap_setid))\n\t\treturn true;\n\n\treturn false;\n}\n\nint proc_setgroups_show(struct seq_file *seq, void *v)\n{\n\tstruct user_namespace *ns = seq->private;\n\tunsigned long userns_flags = READ_ONCE(ns->flags);\n\n\tseq_printf(seq, \"%s\\n\",\n\t\t   (userns_flags & USERNS_SETGROUPS_ALLOWED) ?\n\t\t   \"allow\" : \"deny\");\n\treturn 0;\n}\n\nssize_t proc_setgroups_write(struct file *file, const char __user *buf,\n\t\t\t     size_t count, loff_t *ppos)\n{\n\tstruct seq_file *seq = file->private_data;\n\tstruct user_namespace *ns = seq->private;\n\tchar kbuf[8], *pos;\n\tbool setgroups_allowed;\n\tssize_t ret;\n\n\t/* Only allow a very narrow range of strings to be written */\n\tret = -EINVAL;\n\tif ((*ppos != 0) || (count >= sizeof(kbuf)))\n\t\tgoto out;\n\n\t/* What was written? */\n\tret = -EFAULT;\n\tif (copy_from_user(kbuf, buf, count))\n\t\tgoto out;\n\tkbuf[count] = '\\0';\n\tpos = kbuf;\n\n\t/* What is being requested? */\n\tret = -EINVAL;\n\tif (strncmp(pos, \"allow\", 5) == 0) {\n\t\tpos += 5;\n\t\tsetgroups_allowed = true;\n\t}\n\telse if (strncmp(pos, \"deny\", 4) == 0) {\n\t\tpos += 4;\n\t\tsetgroups_allowed = false;\n\t}\n\telse\n\t\tgoto out;\n\n\t/* Verify there is not trailing junk on the line */\n\tpos = skip_spaces(pos);\n\tif (*pos != '\\0')\n\t\tgoto out;\n\n\tret = -EPERM;\n\tmutex_lock(&userns_state_mutex);\n\tif (setgroups_allowed) {\n\t\t/* Enabling setgroups after setgroups has been disabled\n\t\t * is not allowed.\n\t\t */\n\t\tif (!(ns->flags & USERNS_SETGROUPS_ALLOWED))\n\t\t\tgoto out_unlock;\n\t} else {\n\t\t/* Permanently disabling setgroups after setgroups has\n\t\t * been enabled by writing the gid_map is not allowed.\n\t\t */\n\t\tif (ns->gid_map.nr_extents != 0)\n\t\t\tgoto out_unlock;\n\t\tns->flags &= ~USERNS_SETGROUPS_ALLOWED;\n\t}\n\tmutex_unlock(&userns_state_mutex);\n\n\t/* Report a successful write */\n\t*ppos = count;\n\tret = count;\nout:\n\treturn ret;\nout_unlock:\n\tmutex_unlock(&userns_state_mutex);\n\tgoto out;\n}\n\nbool userns_may_setgroups(const struct user_namespace *ns)\n{\n\tbool allowed;\n\n\tmutex_lock(&userns_state_mutex);\n\t/* It is not safe to use setgroups until a gid mapping in\n\t * the user namespace has been established.\n\t */\n\tallowed = ns->gid_map.nr_extents != 0;\n\t/* Is setgroups allowed? */\n\tallowed = allowed && (ns->flags & USERNS_SETGROUPS_ALLOWED);\n\tmutex_unlock(&userns_state_mutex);\n\n\treturn allowed;\n}\n\n/*\n * Returns true if @child is the same namespace or a descendant of\n * @ancestor.\n */\nbool in_userns(const struct user_namespace *ancestor,\n\t       const struct user_namespace *child)\n{\n\tconst struct user_namespace *ns;\n\tfor (ns = child; ns->level > ancestor->level; ns = ns->parent)\n\t\t;\n\treturn (ns == ancestor);\n}\n\nbool current_in_userns(const struct user_namespace *target_ns)\n{\n\treturn in_userns(target_ns, current_user_ns());\n}\nEXPORT_SYMBOL(current_in_userns);\n\nstatic inline struct user_namespace *to_user_ns(struct ns_common *ns)\n{\n\treturn container_of(ns, struct user_namespace, ns);\n}\n\nstatic struct ns_common *userns_get(struct task_struct *task)\n{\n\tstruct user_namespace *user_ns;\n\n\trcu_read_lock();\n\tuser_ns = get_user_ns(__task_cred(task)->user_ns);\n\trcu_read_unlock();\n\n\treturn user_ns ? &user_ns->ns : NULL;\n}\n\nstatic void userns_put(struct ns_common *ns)\n{\n\tput_user_ns(to_user_ns(ns));\n}\n\nstatic int userns_install(struct nsproxy *nsproxy, struct ns_common *ns)\n{\n\tstruct user_namespace *user_ns = to_user_ns(ns);\n\tstruct cred *cred;\n\n\t/* Don't allow gaining capabilities by reentering\n\t * the same user namespace.\n\t */\n\tif (user_ns == current_user_ns())\n\t\treturn -EINVAL;\n\n\t/* Tasks that share a thread group must share a user namespace */\n\tif (!thread_group_empty(current))\n\t\treturn -EINVAL;\n\n\tif (current->fs->users != 1)\n\t\treturn -EINVAL;\n\n\tif (!ns_capable(user_ns, CAP_SYS_ADMIN))\n\t\treturn -EPERM;\n\n\tcred = prepare_creds();\n\tif (!cred)\n\t\treturn -ENOMEM;\n\n\tput_user_ns(cred->user_ns);\n\tset_cred_user_ns(cred, get_user_ns(user_ns));\n\n\treturn commit_creds(cred);\n}\n\nstruct ns_common *ns_get_owner(struct ns_common *ns)\n{\n\tstruct user_namespace *my_user_ns = current_user_ns();\n\tstruct user_namespace *owner, *p;\n\n\t/* See if the owner is in the current user namespace */\n\towner = p = ns->ops->owner(ns);\n\tfor (;;) {\n\t\tif (!p)\n\t\t\treturn ERR_PTR(-EPERM);\n\t\tif (p == my_user_ns)\n\t\t\tbreak;\n\t\tp = p->parent;\n\t}\n\n\treturn &get_user_ns(owner)->ns;\n}\n\nstatic struct user_namespace *userns_owner(struct ns_common *ns)\n{\n\treturn to_user_ns(ns)->parent;\n}\n\nconst struct proc_ns_operations userns_operations = {\n\t.name\t\t= \"user\",\n\t.type\t\t= CLONE_NEWUSER,\n\t.get\t\t= userns_get,\n\t.put\t\t= userns_put,\n\t.install\t= userns_install,\n\t.owner\t\t= userns_owner,\n\t.get_parent\t= ns_get_owner,\n};\n\nstatic __init int user_namespaces_init(void)\n{\n\tuser_ns_cachep = KMEM_CACHE(user_namespace, SLAB_PANIC);\n\treturn 0;\n}\nsubsys_initcall(user_namespaces_init);\n"], "filenames": ["kernel/user_namespace.c"], "buggy_code_start_loc": [977], "buggy_code_end_loc": [1005], "fixing_code_start_loc": [976], "fixing_code_end_loc": [1010], "type": "CWE-863", "message": "In the Linux kernel 4.15.x through 4.19.x before 4.19.2, map_write() in kernel/user_namespace.c allows privilege escalation because it mishandles nested user namespaces with more than 5 UID or GID ranges. A user who has CAP_SYS_ADMIN in an affected user namespace can bypass access controls on resources outside the namespace, as demonstrated by reading /etc/shadow. This occurs because an ID transformation takes place properly for the namespaced-to-kernel direction but not for the kernel-to-namespaced direction.", "other": {"cve": {"id": "CVE-2018-18955", "sourceIdentifier": "cve@mitre.org", "published": "2018-11-16T20:29:00.233", "lastModified": "2020-08-24T17:37:01.140", "vulnStatus": "Modified", "descriptions": [{"lang": "en", "value": "In the Linux kernel 4.15.x through 4.19.x before 4.19.2, map_write() in kernel/user_namespace.c allows privilege escalation because it mishandles nested user namespaces with more than 5 UID or GID ranges. A user who has CAP_SYS_ADMIN in an affected user namespace can bypass access controls on resources outside the namespace, as demonstrated by reading /etc/shadow. This occurs because an ID transformation takes place properly for the namespaced-to-kernel direction but not for the kernel-to-namespaced direction."}, {"lang": "es", "value": "En el kernel de Linux, de las versiones 4.15.x hasta las 4.19.x anteriores a la 4.19.2, map_write() en kernel/user_namespace.c permite el escalado de privilegios debido a que gestiona incorrectamente los espacios de nombre de usuario anidados con m\u00e1s de 5 rangos UID o GID. Un usuario que tenga CAP_SYS_ADMIN en un espacio de nombre de usuario afectado puede omitir los controles de acceso en los recursos fuera del espacio de nombre, tal y como queda demostrado con la lectura de /etc/shadow. Esto ocurre debido a que una transformaci\u00f3n ID ocurre correctamente para la direcci\u00f3n namespaced-to-kernel, pero no para la direcci\u00f3n kernel-to-namespaced."}], "metrics": {"cvssMetricV30": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.0", "vectorString": "CVSS:3.0/AV:L/AC:H/PR:L/UI:N/S:U/C:H/I:H/A:H", "attackVector": "LOCAL", "attackComplexity": "HIGH", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "HIGH", "availabilityImpact": "HIGH", "baseScore": 7.0, "baseSeverity": "HIGH"}, "exploitabilityScore": 1.0, "impactScore": 5.9}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:L/AC:M/Au:N/C:P/I:P/A:P", "accessVector": "LOCAL", "accessComplexity": "MEDIUM", "authentication": "NONE", "confidentialityImpact": "PARTIAL", "integrityImpact": "PARTIAL", "availabilityImpact": "PARTIAL", "baseScore": 4.4}, "baseSeverity": "MEDIUM", "exploitabilityScore": 3.4, "impactScore": 6.4, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-863"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionStartIncluding": "4.15", "versionEndExcluding": "4.19.2", "matchCriteriaId": "6572A2C1-2389-4DD6-A22F-40A8F0835AAB"}]}]}, {"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:canonical:ubuntu_linux:16.04:*:*:*:lts:*:*:*", "matchCriteriaId": "F7016A2A-8365-4F1A-89A2-7A19F2BCAE5B"}, {"vulnerable": true, "criteria": "cpe:2.3:o:canonical:ubuntu_linux:18.04:*:*:*:lts:*:*:*", "matchCriteriaId": "23A7C53F-B80F-4E6A-AFA9-58EEA84BE11D"}, {"vulnerable": true, "criteria": "cpe:2.3:o:canonical:ubuntu_linux:18.10:*:*:*:*:*:*:*", "matchCriteriaId": "07C312A0-CD2C-4B9C-B064-6409B25C278F"}]}]}], "references": [{"url": "http://git.kernel.org/cgit/linux/kernel/git/torvalds/linux.git/commit/?id=d2f007dbe7e4c9583eea6eb04d60001e85c6f1bd", "source": "cve@mitre.org", "tags": ["Patch", "Vendor Advisory"]}, {"url": "http://www.securityfocus.com/bid/105941", "source": "cve@mitre.org", "tags": ["Third Party Advisory", "VDB Entry"]}, {"url": "https://bugs.chromium.org/p/project-zero/issues/detail?id=1712", "source": "cve@mitre.org", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://cdn.kernel.org/pub/linux/kernel/v4.x/ChangeLog-4.18.19", "source": "cve@mitre.org", "tags": ["Patch", "Vendor Advisory"]}, {"url": "https://cdn.kernel.org/pub/linux/kernel/v4.x/ChangeLog-4.19.2", "source": "cve@mitre.org", "tags": ["Patch", "Vendor Advisory"]}, {"url": "https://github.com/torvalds/linux/commit/d2f007dbe7e4c9583eea6eb04d60001e85c6f1bd", "source": "cve@mitre.org", "tags": ["Patch", "Vendor Advisory"]}, {"url": "https://security.netapp.com/advisory/ntap-20190416-0003/", "source": "cve@mitre.org"}, {"url": "https://support.f5.com/csp/article/K39103040", "source": "cve@mitre.org"}, {"url": "https://usn.ubuntu.com/3832-1/", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}, {"url": "https://usn.ubuntu.com/3833-1/", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}, {"url": "https://usn.ubuntu.com/3835-1/", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}, {"url": "https://usn.ubuntu.com/3836-1/", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}, {"url": "https://usn.ubuntu.com/3836-2/", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}, {"url": "https://www.exploit-db.com/exploits/45886/", "source": "cve@mitre.org", "tags": ["Exploit", "Patch", "Third Party Advisory", "VDB Entry"]}, {"url": "https://www.exploit-db.com/exploits/45915/", "source": "cve@mitre.org", "tags": ["Exploit", "Third Party Advisory", "VDB Entry"]}]}, "github_commit_url": "https://github.com/torvalds/linux/commit/d2f007dbe7e4c9583eea6eb04d60001e85c6f1bd"}}
{"buggy_code": ["# coding: utf-8\nfrom __future__ import print_function, unicode_literals\n\nimport argparse  # typechk\nimport base64\nimport calendar\nimport copy\nimport errno\nimport gzip\nimport itertools\nimport json\nimport os\nimport random\nimport re\nimport stat\nimport string\nimport threading  # typechk\nimport time\nimport uuid\nfrom datetime import datetime\nfrom email.utils import formatdate, parsedate\nfrom operator import itemgetter\n\nimport jinja2  # typechk\n\ntry:\n    import lzma\nexcept:\n    pass\n\nfrom .__init__ import ANYWIN, PY2, TYPE_CHECKING, EnvParams, unicode\nfrom .__version__ import S_VERSION\nfrom .authsrv import VFS  # typechk\nfrom .bos import bos\nfrom .star import StreamTar\nfrom .sutil import StreamArc  # typechk\nfrom .szip import StreamZip\nfrom .util import (\n    HTTPCODE,\n    META_NOBOTS,\n    MultipartParser,\n    Pebkac,\n    UnrecvEOF,\n    alltrace,\n    atomic_move,\n    exclude_dotfiles,\n    fsenc,\n    gen_filekey,\n    gen_filekey_dbg,\n    gencookie,\n    get_df,\n    get_spd,\n    guess_mime,\n    gzip_orig_sz,\n    hashcopy,\n    hidedir,\n    html_bescape,\n    html_escape,\n    humansize,\n    ipnorm,\n    loadpy,\n    min_ex,\n    quotep,\n    rand_name,\n    read_header,\n    read_socket,\n    read_socket_chunked,\n    read_socket_unbounded,\n    relchk,\n    ren_open,\n    runhook,\n    s3enc,\n    sanitize_fn,\n    sendfile_kern,\n    sendfile_py,\n    undot,\n    unescape_cookie,\n    unquote,\n    unquotep,\n    vjoin,\n    vol_san,\n    vsplit,\n    yieldfile,\n)\n\nif True:  # pylint: disable=using-constant-test\n    import typing\n    from typing import Any, Generator, Match, Optional, Pattern, Type, Union\n\nif TYPE_CHECKING:\n    from .httpconn import HttpConn\n\n_ = (argparse, threading)\n\nNO_CACHE = {\"Cache-Control\": \"no-cache\"}\n\n\nclass HttpCli(object):\n    \"\"\"\n    Spawned by HttpConn to process one http transaction\n    \"\"\"\n\n    def __init__(self, conn: \"HttpConn\") -> None:\n        assert conn.sr\n\n        self.t0 = time.time()\n        self.conn = conn\n        self.mutex = conn.mutex  # mypy404\n        self.s = conn.s\n        self.sr = conn.sr\n        self.ip = conn.addr[0]\n        self.addr: tuple[str, int] = conn.addr\n        self.args = conn.args  # mypy404\n        self.E: EnvParams = self.args.E\n        self.asrv = conn.asrv  # mypy404\n        self.ico = conn.ico  # mypy404\n        self.thumbcli = conn.thumbcli  # mypy404\n        self.u2fh = conn.u2fh  # mypy404\n        self.log_func = conn.log_func  # mypy404\n        self.log_src = conn.log_src  # mypy404\n        self.gen_fk = self._gen_fk if self.args.log_fk else gen_filekey\n        self.tls: bool = hasattr(self.s, \"cipher\")\n\n        # placeholders; assigned by run()\n        self.keepalive = False\n        self.is_https = False\n        self.is_vproxied = False\n        self.in_hdr_recv = True\n        self.headers: dict[str, str] = {}\n        self.mode = \" \"\n        self.req = \" \"\n        self.http_ver = \" \"\n        self.host = \" \"\n        self.ua = \" \"\n        self.is_rclone = False\n        self.ouparam: dict[str, str] = {}\n        self.uparam: dict[str, str] = {}\n        self.cookies: dict[str, str] = {}\n        self.avn: Optional[VFS] = None\n        self.vn = self.asrv.vfs\n        self.rem = \" \"\n        self.vpath = \" \"\n        self.uname = \" \"\n        self.pw = \" \"\n        self.rvol = [\" \"]\n        self.wvol = [\" \"]\n        self.mvol = [\" \"]\n        self.dvol = [\" \"]\n        self.gvol = [\" \"]\n        self.upvol = [\" \"]\n        self.do_log = True\n        self.can_read = False\n        self.can_write = False\n        self.can_move = False\n        self.can_delete = False\n        self.can_get = False\n        self.can_upget = False\n        self.can_admin = False\n        # post\n        self.parser: Optional[MultipartParser] = None\n        # end placeholders\n\n        self.bufsz = 1024 * 32\n        self.hint = \"\"\n        self.trailing_slash = True\n        self.out_headerlist: list[tuple[str, str]] = []\n        self.out_headers = {\n            \"Vary\": \"Origin, PW, Cookie\",\n            \"Cache-Control\": \"no-store, max-age=0\",\n        }\n        h = self.args.html_head\n        if self.args.no_robots:\n            h = META_NOBOTS + ((\"\\n\" + h) if h else \"\")\n            self.out_headers[\"X-Robots-Tag\"] = \"noindex, nofollow\"\n        self.html_head = h\n\n    def log(self, msg: str, c: Union[int, str] = 0) -> None:\n        ptn = self.asrv.re_pwd\n        if ptn and ptn.search(msg):\n            if self.asrv.ah.on:\n                msg = ptn.sub(\"\\033[7m pw \\033[27m\", msg)\n            else:\n                msg = ptn.sub(self.unpwd, msg)\n\n        self.log_func(self.log_src, msg, c)\n\n    def unpwd(self, m: Match[str]) -> str:\n        a, b, c = m.groups()\n        return \"{}\\033[7m {} \\033[27m{}\".format(a, self.asrv.iacct[b], c)\n\n    def _check_nonfatal(self, ex: Pebkac, post: bool) -> bool:\n        if post:\n            return ex.code < 300\n\n        return ex.code < 400 or ex.code in [404, 429]\n\n    def _assert_safe_rem(self, rem: str) -> None:\n        # sanity check to prevent any disasters\n        if rem.startswith(\"/\") or rem.startswith(\"../\") or \"/../\" in rem:\n            raise Exception(\"that was close\")\n\n    def _gen_fk(self, salt: str, fspath: str, fsize: int, inode: int) -> str:\n        return gen_filekey_dbg(salt, fspath, fsize, inode, self.log, self.args.log_fk)\n\n    def j2s(self, name: str, **ka: Any) -> str:\n        tpl = self.conn.hsrv.j2[name]\n        ka[\"r\"] = self.args.SR if self.is_vproxied else \"\"\n        ka[\"ts\"] = self.conn.hsrv.cachebuster()\n        ka[\"lang\"] = self.args.lang\n        ka[\"favico\"] = self.args.favico\n        ka[\"svcname\"] = self.args.doctitle\n        ka[\"html_head\"] = self.html_head\n        return tpl.render(**ka)  # type: ignore\n\n    def j2j(self, name: str) -> jinja2.Template:\n        return self.conn.hsrv.j2[name]\n\n    def run(self) -> bool:\n        \"\"\"returns true if connection can be reused\"\"\"\n        self.keepalive = False\n        self.is_https = False\n        self.headers = {}\n        self.hint = \"\"\n\n        if self.is_banned():\n            return False\n\n        try:\n            self.s.settimeout(2)\n            headerlines = read_header(self.sr, self.args.s_thead, self.args.s_thead)\n            self.in_hdr_recv = False\n            if not headerlines:\n                return False\n\n            if not headerlines[0]:\n                # seen after login with IE6.0.2900.5512.xpsp.080413-2111 (xp-sp3)\n                self.log(\"BUG: trailing newline from previous request\", c=\"1;31\")\n                headerlines.pop(0)\n\n            try:\n                self.mode, self.req, self.http_ver = headerlines[0].split(\" \")\n\n                # normalize incoming headers to lowercase;\n                # outgoing headers however are Correct-Case\n                for header_line in headerlines[1:]:\n                    k, zs = header_line.split(\":\", 1)\n                    self.headers[k.lower()] = zs.strip()\n            except:\n                msg = \" ]\\n#[ \".join(headerlines)\n                raise Pebkac(400, \"bad headers:\\n#[ \" + msg + \" ]\")\n\n        except Pebkac as ex:\n            self.mode = \"GET\"\n            self.req = \"[junk]\"\n            self.http_ver = \"HTTP/1.1\"\n            # self.log(\"pebkac at httpcli.run #1: \" + repr(ex))\n            self.keepalive = False\n            h = {\"WWW-Authenticate\": 'Basic realm=\"a\"'} if ex.code == 401 else {}\n            try:\n                self.loud_reply(unicode(ex), status=ex.code, headers=h, volsan=True)\n                return self.keepalive\n            except:\n                return False\n\n        self.ua = self.headers.get(\"user-agent\", \"\")\n        self.is_rclone = self.ua.startswith(\"rclone/\")\n\n        zs = self.headers.get(\"connection\", \"\").lower()\n        self.keepalive = \"close\" not in zs and (\n            self.http_ver != \"HTTP/1.0\" or zs == \"keep-alive\"\n        )\n        self.is_https = (\n            self.headers.get(\"x-forwarded-proto\", \"\").lower() == \"https\" or self.tls\n        )\n        self.host = self.headers.get(\"host\") or \"\"\n        if not self.host:\n            zs = \"%s:%s\" % self.s.getsockname()[:2]\n            self.host = zs[7:] if zs.startswith(\"::ffff:\") else zs\n\n        n = self.args.rproxy\n        if n:\n            zso = self.headers.get(\"x-forwarded-for\")\n            if zso and self.conn.addr[0] in [\"127.0.0.1\", \"::1\"]:\n                if n > 0:\n                    n -= 1\n\n                zsl = zso.split(\",\")\n                try:\n                    self.ip = zsl[n].strip()\n                except:\n                    self.ip = zsl[0].strip()\n                    t = \"rproxy={} oob x-fwd {}\"\n                    self.log(t.format(self.args.rproxy, zso), c=3)\n\n                self.log_src = self.conn.set_rproxy(self.ip)\n                self.is_vproxied = bool(self.args.R)\n                self.host = self.headers.get(\"x-forwarded-host\") or self.host\n\n        if self.is_banned():\n            return False\n\n        if self.conn.aclose:\n            nka = self.conn.aclose\n            ip = ipnorm(self.ip)\n            if ip in nka:\n                rt = nka[ip] - time.time()\n                if rt < 0:\n                    self.log(\"client uncapped\", 3)\n                    del nka[ip]\n                else:\n                    self.keepalive = False\n\n        ptn: Optional[Pattern[str]] = self.conn.lf_url  # mypy404\n        self.do_log = not ptn or not ptn.search(self.req)\n\n        if self.args.ihead and self.do_log:\n            keys = self.args.ihead\n            if \"*\" in keys:\n                keys = list(sorted(self.headers.keys()))\n\n            for k in keys:\n                zso = self.headers.get(k)\n                if zso is not None:\n                    self.log(\"[H] {}: \\033[33m[{}]\".format(k, zso), 6)\n\n        if \"&\" in self.req and \"?\" not in self.req:\n            self.hint = \"did you mean '?' instead of '&'\"\n\n        # split req into vpath + uparam\n        uparam = {}\n        if \"?\" not in self.req:\n            self.trailing_slash = self.req.endswith(\"/\")\n            vpath = undot(self.req)\n        else:\n            vpath, arglist = self.req.split(\"?\", 1)\n            self.trailing_slash = vpath.endswith(\"/\")\n            vpath = undot(vpath)\n            for k in arglist.split(\"&\"):\n                if \"=\" in k:\n                    k, zs = k.split(\"=\", 1)\n                    uparam[k.lower()] = unquotep(zs.strip().replace(\"+\", \" \"))\n                else:\n                    uparam[k.lower()] = \"\"\n\n        if self.is_vproxied:\n            if vpath.startswith(self.args.R):\n                vpath = vpath[len(self.args.R) + 1 :]\n            else:\n                t = \"incorrect --rp-loc or webserver config; expected vpath starting with [{}] but got [{}]\"\n                self.log(t.format(self.args.R, vpath), 1)\n\n        self.ouparam = {k: zs for k, zs in uparam.items()}\n\n        if self.args.rsp_slp:\n            time.sleep(self.args.rsp_slp)\n            if self.args.rsp_jtr:\n                time.sleep(random.random() * self.args.rsp_jtr)\n\n        zso = self.headers.get(\"cookie\")\n        if zso:\n            zsll = [x.split(\"=\", 1) for x in zso.split(\";\") if \"=\" in x]\n            cookies = {k.strip(): unescape_cookie(zs) for k, zs in zsll}\n            cookie_pw = cookies.get(\"cppws\") or cookies.get(\"cppwd\") or \"\"\n            if \"b\" in cookies and \"b\" not in uparam:\n                uparam[\"b\"] = cookies[\"b\"]\n        else:\n            cookies = {}\n            cookie_pw = \"\"\n\n        if len(uparam) > 10 or len(cookies) > 50:\n            raise Pebkac(400, \"u wot m8\")\n\n        self.uparam = uparam\n        self.cookies = cookies\n        self.vpath = unquotep(vpath)  # not query, so + means +\n\n        ok = \"\\x00\" not in self.vpath\n        if ANYWIN:\n            ok = ok and not relchk(self.vpath)\n\n        if not ok and (self.vpath != \"*\" or self.mode != \"OPTIONS\"):\n            self.log(\"invalid relpath [{}]\".format(self.vpath))\n            return self.tx_404() and self.keepalive\n\n        zso = self.headers.get(\"authorization\")\n        bauth = \"\"\n        if zso:\n            try:\n                zb = zso.split(\" \")[1].encode(\"ascii\")\n                zs = base64.b64decode(zb).decode(\"utf-8\")\n                # try \"pwd\", \"x:pwd\", \"pwd:x\"\n                for bauth in [zs] + zs.split(\":\", 1)[::-1]:\n                    hpw = self.asrv.ah.hash(bauth)\n                    if self.asrv.iacct.get(hpw):\n                        break\n            except:\n                pass\n\n        self.pw = uparam.get(\"pw\") or self.headers.get(\"pw\") or bauth or cookie_pw\n        self.uname = self.asrv.iacct.get(self.asrv.ah.hash(self.pw)) or \"*\"\n        self.rvol = self.asrv.vfs.aread[self.uname]\n        self.wvol = self.asrv.vfs.awrite[self.uname]\n        self.mvol = self.asrv.vfs.amove[self.uname]\n        self.dvol = self.asrv.vfs.adel[self.uname]\n        self.gvol = self.asrv.vfs.aget[self.uname]\n        self.upvol = self.asrv.vfs.apget[self.uname]\n\n        if self.pw and (\n            self.pw != cookie_pw or self.conn.freshen_pwd + 30 < time.time()\n        ):\n            self.conn.freshen_pwd = time.time()\n            self.get_pwd_cookie(self.pw)\n\n        if self.is_rclone:\n            # dots: always include dotfiles if permitted\n            # lt: probably more important showing the correct timestamps of any dupes it just uploaded rather than the lastmod time of any non-copyparty-managed symlinks\n            # b: basic-browser if it tries to parse the html listing\n            uparam[\"dots\"] = \"\"\n            uparam[\"lt\"] = \"\"\n            uparam[\"b\"] = \"\"\n            cookies[\"b\"] = \"\"\n\n        vn, rem = self.asrv.vfs.get(self.vpath, self.uname, False, False)\n        if \"xdev\" in vn.flags or \"xvol\" in vn.flags:\n            ap = vn.canonical(rem)\n            avn = vn.chk_ap(ap)\n        else:\n            avn = vn\n\n        (\n            self.can_read,\n            self.can_write,\n            self.can_move,\n            self.can_delete,\n            self.can_get,\n            self.can_upget,\n            self.can_admin,\n        ) = (\n            avn.can_access(\"\", self.uname) if avn else [False] * 6\n        )\n        self.avn = avn\n        self.vn = vn\n        self.rem = rem\n\n        self.s.settimeout(self.args.s_tbody or None)\n\n        try:\n            cors_k = self._cors()\n            if self.mode in (\"GET\", \"HEAD\"):\n                return self.handle_get() and self.keepalive\n            if self.mode == \"OPTIONS\":\n                return self.handle_options() and self.keepalive\n\n            if not cors_k:\n                origin = self.headers.get(\"origin\", \"<?>\")\n                self.log(\"cors-reject {} from {}\".format(self.mode, origin), 3)\n                raise Pebkac(403, \"no surfing\")\n\n            # getattr(self.mode) is not yet faster than this\n            if self.mode == \"POST\":\n                return self.handle_post() and self.keepalive\n            elif self.mode == \"PUT\":\n                return self.handle_put() and self.keepalive\n            elif self.mode == \"PROPFIND\":\n                return self.handle_propfind() and self.keepalive\n            elif self.mode == \"DELETE\":\n                return self.handle_delete() and self.keepalive\n            elif self.mode == \"PROPPATCH\":\n                return self.handle_proppatch() and self.keepalive\n            elif self.mode == \"LOCK\":\n                return self.handle_lock() and self.keepalive\n            elif self.mode == \"UNLOCK\":\n                return self.handle_unlock() and self.keepalive\n            elif self.mode == \"MKCOL\":\n                return self.handle_mkcol() and self.keepalive\n            elif self.mode == \"MOVE\":\n                return self.handle_move() and self.keepalive\n            else:\n                raise Pebkac(400, 'invalid HTTP mode \"{0}\"'.format(self.mode))\n\n        except Exception as ex:\n            if not isinstance(ex, Pebkac):\n                pex = Pebkac(500)\n            else:\n                pex: Pebkac = ex  # type: ignore\n\n            try:\n                post = self.mode in [\"POST\", \"PUT\"] or \"content-length\" in self.headers\n                if not self._check_nonfatal(pex, post):\n                    self.keepalive = False\n\n                em = str(ex)\n                msg = em if pex == ex else min_ex()\n                if pex.code != 404 or self.do_log:\n                    self.log(\n                        \"{}\\033[0m, {}\".format(msg, self.vpath),\n                        6 if em.startswith(\"client d/c \") else 3,\n                    )\n\n                msg = \"{}\\r\\nURL: {}\\r\\n\".format(em, self.vpath)\n                if self.hint:\n                    msg += \"hint: {}\\r\\n\".format(self.hint)\n\n                if \"database is locked\" in em:\n                    self.conn.hsrv.broker.say(\"log_stacks\")\n                    msg += \"hint: important info in the server log\\r\\n\"\n\n                zb = b\"<pre>\" + html_escape(msg).encode(\"utf-8\", \"replace\")\n                h = {\"WWW-Authenticate\": 'Basic realm=\"a\"'} if pex.code == 401 else {}\n                self.reply(zb, status=pex.code, headers=h, volsan=True)\n                return self.keepalive\n            except Pebkac:\n                return False\n\n    def dip(self) -> str:\n        if self.args.plain_ip:\n            return self.ip.replace(\":\", \".\")\n        else:\n            return self.conn.iphash.s(self.ip)\n\n    def is_banned(self) -> bool:\n        if not self.conn.bans:\n            return False\n\n        bans = self.conn.bans\n        ip = ipnorm(self.ip)\n        if ip not in bans:\n            return False\n\n        rt = bans[ip] - time.time()\n        if rt < 0:\n            self.log(\"client unbanned\", 3)\n            del bans[ip]\n            return False\n\n        self.log(\"banned for {:.0f} sec\".format(rt), 6)\n        zb = b\"HTTP/1.0 403 Forbidden\\r\\n\\r\\nthank you for playing\"\n        self.s.sendall(zb)\n        return True\n\n    def permit_caching(self) -> None:\n        cache = self.uparam.get(\"cache\")\n        if cache is None:\n            self.out_headers.update(NO_CACHE)\n            return\n\n        n = \"604869\" if cache == \"i\" else cache or \"69\"\n        self.out_headers[\"Cache-Control\"] = \"max-age=\" + n\n\n    def k304(self) -> bool:\n        k304 = self.cookies.get(\"k304\")\n        return k304 == \"y\" or (\"; Trident/\" in self.ua and not k304)\n\n    def send_headers(\n        self,\n        length: Optional[int],\n        status: int = 200,\n        mime: Optional[str] = None,\n        headers: Optional[dict[str, str]] = None,\n    ) -> None:\n        response = [\"%s %s %s\" % (self.http_ver, status, HTTPCODE[status])]\n\n        if length is not None:\n            response.append(\"Content-Length: \" + unicode(length))\n\n        if status == 304 and self.k304():\n            self.keepalive = False\n\n        # close if unknown length, otherwise take client's preference\n        response.append(\"Connection: \" + (\"Keep-Alive\" if self.keepalive else \"Close\"))\n        response.append(\"Date: \" + formatdate(usegmt=True))\n\n        # headers{} overrides anything set previously\n        if headers:\n            self.out_headers.update(headers)\n\n        # default to utf8 html if no content-type is set\n        if not mime:\n            mime = self.out_headers.get(\"Content-Type\") or \"text/html; charset=utf-8\"\n\n        self.out_headers[\"Content-Type\"] = mime\n\n        for k, zs in list(self.out_headers.items()) + self.out_headerlist:\n            response.append(\"%s: %s\" % (k, zs))\n\n        try:\n            # best practice to separate headers and body into different packets\n            self.s.sendall(\"\\r\\n\".join(response).encode(\"utf-8\") + b\"\\r\\n\\r\\n\")\n        except:\n            raise Pebkac(400, \"client d/c while replying headers\")\n\n    def reply(\n        self,\n        body: bytes,\n        status: int = 200,\n        mime: Optional[str] = None,\n        headers: Optional[dict[str, str]] = None,\n        volsan: bool = False,\n    ) -> bytes:\n        if status == 404:\n            g = self.conn.hsrv.g404\n            if g.lim:\n                bonk, ip = g.bonk(self.ip, self.vpath)\n                if bonk:\n                    xban = self.vn.flags.get(\"xban\")\n                    if not xban or not runhook(\n                        self.log,\n                        xban,\n                        self.vn.canonical(self.rem),\n                        self.vpath,\n                        self.host,\n                        self.uname,\n                        time.time(),\n                        0,\n                        self.ip,\n                        time.time(),\n                        \"404\",\n                    ):\n                        self.log(\"client banned: 404s\", 1)\n                        self.conn.hsrv.bans[ip] = bonk\n\n        if volsan:\n            vols = list(self.asrv.vfs.all_vols.values())\n            body = vol_san(vols, body)\n\n        self.send_headers(len(body), status, mime, headers)\n\n        try:\n            if self.mode != \"HEAD\":\n                self.s.sendall(body)\n        except:\n            raise Pebkac(400, \"client d/c while replying body\")\n\n        return body\n\n    def loud_reply(self, body: str, *args: Any, **kwargs: Any) -> None:\n        if not kwargs.get(\"mime\"):\n            kwargs[\"mime\"] = \"text/plain; charset=utf-8\"\n\n        self.log(body.rstrip())\n        self.reply(body.encode(\"utf-8\") + b\"\\r\\n\", *list(args), **kwargs)\n\n    def urlq(self, add: dict[str, str], rm: list[str]) -> str:\n        \"\"\"\n        generates url query based on uparam (b, pw, all others)\n        removing anything in rm, adding pairs in add\n\n        also list faster than set until ~20 items\n        \"\"\"\n\n        if self.is_rclone:\n            return \"\"\n\n        kv = {k: zs for k, zs in self.uparam.items() if k not in rm}\n        if \"pw\" in kv:\n            pw = self.cookies.get(\"cppws\") or self.cookies.get(\"cppwd\")\n            if kv[\"pw\"] == pw:\n                del kv[\"pw\"]\n\n        kv.update(add)\n        if not kv:\n            return \"\"\n\n        r = [\"%s=%s\" % (k, quotep(zs)) if zs else k for k, zs in kv.items()]\n        return \"?\" + \"&amp;\".join(r)\n\n    def redirect(\n        self,\n        vpath: str,\n        suf: str = \"\",\n        msg: str = \"aight\",\n        flavor: str = \"go to\",\n        click: bool = True,\n        status: int = 200,\n        use302: bool = False,\n    ) -> bool:\n        vp = self.args.RS + vpath\n        html = self.j2s(\n            \"msg\",\n            h2='<a href=\"/{}\">{} /{}</a>'.format(\n                quotep(vp) + suf, flavor, html_escape(vp, crlf=True) + suf\n            ),\n            pre=msg,\n            click=click,\n        ).encode(\"utf-8\", \"replace\")\n\n        if use302:\n            self.reply(html, status=302, headers={\"Location\": \"/\" + vpath})\n        else:\n            self.reply(html, status=status)\n\n        return True\n\n    def _cors(self) -> bool:\n        ih = self.headers\n        origin = ih.get(\"origin\")\n        if not origin:\n            sfsite = ih.get(\"sec-fetch-site\")\n            if sfsite and sfsite.lower().startswith(\"cross\"):\n                origin = \":|\"  # sandboxed iframe\n            else:\n                return True\n\n        oh = self.out_headers\n        origin = origin.lower()\n        good_origins = self.args.acao + [\n            \"{}://{}\".format(\n                \"https\" if self.is_https else \"http\",\n                self.host.lower().split(\":\")[0],\n            )\n        ]\n        if re.sub(r\"(:[0-9]{1,5})?/?$\", \"\", origin) in good_origins:\n            good_origin = True\n            bad_hdrs = (\"\",)\n        else:\n            good_origin = False\n            bad_hdrs = (\"\", \"pw\")\n\n        # '*' blocks all credentials (cookies, http-auth);\n        # exact-match for Origin is necessary to unlock those,\n        # however yolo-requests (?pw=) are always allowed\n        acah = ih.get(\"access-control-request-headers\", \"\")\n        acao = (origin if good_origin else None) or (\n            \"*\" if \"*\" in good_origins else None\n        )\n        if self.args.allow_csrf:\n            acao = origin or acao or \"*\"  # explicitly permit impersonation\n            acam = \", \".join(self.conn.hsrv.mallow)  # and all methods + headers\n            oh[\"Access-Control-Allow-Credentials\"] = \"true\"\n            good_origin = True\n        else:\n            acam = \", \".join(self.args.acam)\n            # wash client-requested headers and roll with that\n            if \"range\" not in acah.lower():\n                acah += \",Range\"  # firefox\n            req_h = acah.split(\",\")\n            req_h = [x.strip() for x in req_h]\n            req_h = [x for x in req_h if x.lower() not in bad_hdrs]\n            acah = \", \".join(req_h)\n\n        if not acao:\n            return False\n\n        oh[\"Access-Control-Allow-Origin\"] = acao\n        oh[\"Access-Control-Allow-Methods\"] = acam.upper()\n        if acah:\n            oh[\"Access-Control-Allow-Headers\"] = acah\n\n        return good_origin\n\n    def handle_get(self) -> bool:\n        if self.do_log:\n            logmsg = \"%-4s %s @%s\" % (self.mode, self.req, self.uname)\n\n            if \"range\" in self.headers:\n                try:\n                    rval = self.headers[\"range\"].split(\"=\", 1)[1]\n                except:\n                    rval = self.headers[\"range\"]\n\n                logmsg += \" [\\033[36m\" + rval + \"\\033[0m]\"\n\n            self.log(logmsg)\n\n        # \"embedded\" resources\n        if self.vpath.startswith(\".cpr\"):\n            if self.vpath.startswith(\".cpr/ico/\"):\n                return self.tx_ico(self.vpath.split(\"/\")[-1], exact=True)\n\n            if self.vpath.startswith(\".cpr/ssdp\"):\n                return self.conn.hsrv.ssdp.reply(self)\n\n            if self.vpath.startswith(\".cpr/dd/\") and self.args.mpmc:\n                if self.args.mpmc == \".\":\n                    raise Pebkac(404)\n\n                loc = self.args.mpmc.rstrip(\"/\") + self.vpath[self.vpath.rfind(\"/\") :]\n                h = {\"Location\": loc, \"Cache-Control\": \"max-age=39\"}\n                self.reply(b\"\", 301, headers=h)\n                return True\n\n            static_path = os.path.join(self.E.mod, \"web/\", self.vpath[5:])\n            return self.tx_file(static_path)\n\n        if \"cf_challenge\" in self.uparam:\n            self.reply(self.j2s(\"cf\").encode(\"utf-8\", \"replace\"))\n            return True\n\n        if not self.can_read and not self.can_write and not self.can_get:\n            t = \"@{} has no access to [{}]\"\n            self.log(t.format(self.uname, self.vpath))\n\n            if \"on403\" in self.vn.flags:\n                ret = self.on40x(self.vn.flags[\"on403\"], self.vn, self.rem)\n                if ret == \"true\":\n                    return True\n                elif ret == \"false\":\n                    return False\n                elif ret == \"allow\":\n                    self.log(\"plugin override; access permitted\")\n                    self.can_read = self.can_write = self.can_move = True\n                    self.can_delete = self.can_get = self.can_upget = True\n                    self.can_admin = True\n                else:\n                    return self.tx_404(True)\n            else:\n                if self.vpath:\n                    return self.tx_404(True)\n\n                self.uparam[\"h\"] = \"\"\n\n        if \"tree\" in self.uparam:\n            return self.tx_tree()\n\n        if \"scan\" in self.uparam:\n            return self.scanvol()\n\n        if self.args.getmod:\n            if \"delete\" in self.uparam:\n                return self.handle_rm([])\n\n            if \"move\" in self.uparam:\n                return self.handle_mv()\n\n        if not self.vpath:\n            if \"reload\" in self.uparam:\n                return self.handle_reload()\n\n            if \"stack\" in self.uparam:\n                return self.tx_stack()\n\n            if \"ups\" in self.uparam:\n                return self.tx_ups()\n\n            if \"k304\" in self.uparam:\n                return self.set_k304()\n\n            if \"setck\" in self.uparam:\n                return self.setck()\n\n            if \"reset\" in self.uparam:\n                return self.set_cfg_reset()\n\n            if \"hc\" in self.uparam:\n                return self.tx_svcs()\n\n        if \"h\" in self.uparam:\n            return self.tx_mounts()\n\n        # conditional redirect to single volumes\n        if self.vpath == \"\" and not self.ouparam:\n            nread = len(self.rvol)\n            nwrite = len(self.wvol)\n            if nread + nwrite == 1 or (self.rvol == self.wvol and nread == 1):\n                if nread == 1:\n                    vpath = self.rvol[0]\n                else:\n                    vpath = self.wvol[0]\n\n                if self.vpath != vpath:\n                    self.redirect(vpath, flavor=\"redirecting to\", use302=True)\n                    return True\n\n        return self.tx_browser()\n\n    def handle_propfind(self) -> bool:\n        if self.do_log:\n            self.log(\"PFIND %s @%s\" % (self.req, self.uname))\n\n        if self.args.no_dav:\n            raise Pebkac(405, \"WebDAV is disabled in server config\")\n\n        vn, rem = self.asrv.vfs.get(self.vpath, self.uname, False, False, err=401)\n        tap = vn.canonical(rem)\n\n        if \"davauth\" in vn.flags and self.uname == \"*\":\n            self.can_read = self.can_write = self.can_get = False\n\n        if not self.can_read and not self.can_write and not self.can_get:\n            self.log(\"inaccessible: [{}]\".format(self.vpath))\n            raise Pebkac(401, \"authenticate\")\n\n        from .dxml import parse_xml\n\n        # enc = \"windows-31j\"\n        # enc = \"shift_jis\"\n        enc = \"utf-8\"\n        uenc = enc.upper()\n\n        clen = int(self.headers.get(\"content-length\", 0))\n        if clen:\n            buf = b\"\"\n            for rbuf in self.get_body_reader()[0]:\n                buf += rbuf\n                if not rbuf or len(buf) >= 32768:\n                    break\n\n            xroot = parse_xml(buf.decode(enc, \"replace\"))\n            xtag = next(x for x in xroot if x.tag.split(\"}\")[-1] == \"prop\")\n            props_lst = [y.tag.split(\"}\")[-1] for y in xtag]\n        else:\n            props_lst = [\n                \"contentclass\",\n                \"creationdate\",\n                \"defaultdocument\",\n                \"displayname\",\n                \"getcontentlanguage\",\n                \"getcontentlength\",\n                \"getcontenttype\",\n                \"getlastmodified\",\n                \"href\",\n                \"iscollection\",\n                \"ishidden\",\n                \"isreadonly\",\n                \"isroot\",\n                \"isstructureddocument\",\n                \"lastaccessed\",\n                \"name\",\n                \"parentname\",\n                \"resourcetype\",\n                \"supportedlock\",\n            ]\n\n        props = set(props_lst)\n        depth = self.headers.get(\"depth\", \"infinity\").lower()\n\n        try:\n            topdir = {\"vp\": \"\", \"st\": bos.stat(tap)}\n        except OSError as ex:\n            if ex.errno not in (errno.ENOENT, errno.ENOTDIR):\n                raise\n            raise Pebkac(404)\n\n        if depth == \"0\" or not self.can_read or not stat.S_ISDIR(topdir[\"st\"].st_mode):\n            fgen = []\n\n        elif depth == \"infinity\":\n            if not self.args.dav_inf:\n                self.log(\"client wants --dav-inf\", 3)\n                zb = b'<?xml version=\"1.0\" encoding=\"utf-8\"?>\\n<D:error xmlns:D=\"DAV:\"><D:propfind-finite-depth/></D:error>'\n                self.reply(zb, 403, \"application/xml; charset=utf-8\")\n                return True\n\n            # this will return symlink-target timestamps\n            # because lstat=true would not recurse into subfolders\n            # and this is a rare case where we actually want that\n            fgen = vn.zipgen(\n                rem,\n                rem,\n                set(),\n                self.uname,\n                self.args.ed,\n                True,\n                not self.args.no_scandir,\n                wrap=False,\n            )\n\n        elif depth == \"1\":\n            _, vfs_ls, vfs_virt = vn.ls(\n                rem,\n                self.uname,\n                not self.args.no_scandir,\n                [[True, False]],\n                lstat=\"davrt\" not in vn.flags,\n            )\n            if not self.args.ed:\n                names = set(exclude_dotfiles([x[0] for x in vfs_ls]))\n                vfs_ls = [x for x in vfs_ls if x[0] in names]\n\n            zi = int(time.time())\n            zsr = os.stat_result((16877, -1, -1, 1, 1000, 1000, 8, zi, zi, zi))\n            ls = [{\"vp\": vp, \"st\": st} for vp, st in vfs_ls]\n            ls += [{\"vp\": v, \"st\": zsr} for v in vfs_virt]\n            fgen = ls  # type: ignore\n\n        else:\n            t = \"invalid depth value '{}' (must be either '0' or '1'{})\"\n            t2 = \" or 'infinity'\" if self.args.dav_inf else \"\"\n            raise Pebkac(412, t.format(depth, t2))\n\n        fgen = itertools.chain([topdir], fgen)  # type: ignore\n        vtop = vjoin(self.args.R, vjoin(vn.vpath, rem))\n\n        chunksz = 0x7FF8  # preferred by nginx or cf (dunno which)\n\n        self.send_headers(\n            None, 207, \"text/xml; charset=\" + enc, {\"Transfer-Encoding\": \"chunked\"}\n        )\n\n        ret = '<?xml version=\"1.0\" encoding=\"{}\"?>\\n<D:multistatus xmlns:D=\"DAV:\">'\n        ret = ret.format(uenc)\n        for x in fgen:\n            rp = vjoin(vtop, x[\"vp\"])\n            st: os.stat_result = x[\"st\"]\n            mtime = st.st_mtime\n            if stat.S_ISLNK(st.st_mode):\n                try:\n                    st = bos.stat(os.path.join(tap, x[\"vp\"]))\n                except:\n                    continue\n\n            isdir = stat.S_ISDIR(st.st_mode)\n\n            ret += \"<D:response><D:href>/%s%s</D:href><D:propstat><D:prop>\" % (\n                quotep(rp),\n                \"/\" if isdir and rp else \"\",\n            )\n\n            pvs: dict[str, str] = {\n                \"displayname\": html_escape(rp.split(\"/\")[-1]),\n                \"getlastmodified\": formatdate(mtime, usegmt=True),\n                \"resourcetype\": '<D:collection xmlns:D=\"DAV:\"/>' if isdir else \"\",\n                \"supportedlock\": '<D:lockentry xmlns:D=\"DAV:\"><D:lockscope><D:exclusive/></D:lockscope><D:locktype><D:write/></D:locktype></D:lockentry>',\n            }\n            if not isdir:\n                pvs[\"getcontenttype\"] = html_escape(guess_mime(rp))\n                pvs[\"getcontentlength\"] = str(st.st_size)\n\n            for k, v in pvs.items():\n                if k not in props:\n                    continue\n                elif v:\n                    ret += \"<D:%s>%s</D:%s>\" % (k, v, k)\n                else:\n                    ret += \"<D:%s/>\" % (k,)\n\n            ret += \"</D:prop><D:status>HTTP/1.1 200 OK</D:status></D:propstat>\"\n\n            missing = [\"<D:%s/>\" % (x,) for x in props if x not in pvs]\n            if missing and clen:\n                t = \"<D:propstat><D:prop>{}</D:prop><D:status>HTTP/1.1 404 Not Found</D:status></D:propstat>\"\n                ret += t.format(\"\".join(missing))\n\n            ret += \"</D:response>\"\n            while len(ret) >= chunksz:\n                ret = self.send_chunk(ret, enc, chunksz)\n\n        ret += \"</D:multistatus>\"\n        while ret:\n            ret = self.send_chunk(ret, enc, chunksz)\n\n        self.send_chunk(\"\", enc, chunksz)\n        # self.reply(ret.encode(enc, \"replace\"),207, \"text/xml; charset=\" + enc)\n        return True\n\n    def handle_proppatch(self) -> bool:\n        if self.do_log:\n            self.log(\"PPATCH %s @%s\" % (self.req, self.uname))\n\n        if self.args.no_dav:\n            raise Pebkac(405, \"WebDAV is disabled in server config\")\n\n        if not self.can_write:\n            self.log(\"{} tried to proppatch [{}]\".format(self.uname, self.vpath))\n            raise Pebkac(401, \"authenticate\")\n\n        from xml.etree import ElementTree as ET\n\n        from .dxml import mkenod, mktnod, parse_xml\n\n        buf = b\"\"\n        for rbuf in self.get_body_reader()[0]:\n            buf += rbuf\n            if not rbuf or len(buf) >= 128 * 1024:\n                break\n\n        if self._applesan():\n            return True\n\n        txt = buf.decode(\"ascii\", \"replace\").lower()\n        enc = self.get_xml_enc(txt)\n        uenc = enc.upper()\n\n        txt = buf.decode(enc, \"replace\")\n        ET.register_namespace(\"D\", \"DAV:\")\n        xroot = mkenod(\"D:orz\")\n        xroot.insert(0, parse_xml(txt))\n        xprop = xroot.find(r\"./{DAV:}propertyupdate/{DAV:}set/{DAV:}prop\")\n        assert xprop\n        for ze in xprop:\n            ze.clear()\n\n        txt = \"\"\"<multistatus xmlns=\"DAV:\"><response><propstat><status>HTTP/1.1 403 Forbidden</status></propstat></response></multistatus>\"\"\"\n        xroot = parse_xml(txt)\n\n        el = xroot.find(r\"./{DAV:}response\")\n        assert el\n        e2 = mktnod(\"D:href\", quotep(self.args.SRS + self.vpath))\n        el.insert(0, e2)\n\n        el = xroot.find(r\"./{DAV:}response/{DAV:}propstat\")\n        assert el\n        el.insert(0, xprop)\n\n        ret = '<?xml version=\"1.0\" encoding=\"{}\"?>\\n'.format(uenc)\n        ret += ET.tostring(xroot).decode(\"utf-8\")\n\n        self.reply(ret.encode(enc, \"replace\"), 207, \"text/xml; charset=\" + enc)\n        return True\n\n    def handle_lock(self) -> bool:\n        if self.do_log:\n            self.log(\"LOCK %s @%s\" % (self.req, self.uname))\n\n        if self.args.no_dav:\n            raise Pebkac(405, \"WebDAV is disabled in server config\")\n\n        # win7+ deadlocks if we say no; just smile and nod\n        if not self.can_write and \"Microsoft-WebDAV\" not in self.ua:\n            self.log(\"{} tried to lock [{}]\".format(self.uname, self.vpath))\n            raise Pebkac(401, \"authenticate\")\n\n        from xml.etree import ElementTree as ET\n\n        from .dxml import mkenod, mktnod, parse_xml\n\n        abspath = self.vn.dcanonical(self.rem)\n\n        buf = b\"\"\n        for rbuf in self.get_body_reader()[0]:\n            buf += rbuf\n            if not rbuf or len(buf) >= 128 * 1024:\n                break\n\n        if self._applesan():\n            return True\n\n        txt = buf.decode(\"ascii\", \"replace\").lower()\n        enc = self.get_xml_enc(txt)\n        uenc = enc.upper()\n\n        txt = buf.decode(enc, \"replace\")\n        ET.register_namespace(\"D\", \"DAV:\")\n        lk = parse_xml(txt)\n        assert lk.tag == \"{DAV:}lockinfo\"\n\n        token = str(uuid.uuid4())\n\n        if not lk.find(r\"./{DAV:}depth\"):\n            depth = self.headers.get(\"depth\", \"infinity\")\n            lk.append(mktnod(\"D:depth\", depth))\n\n        lk.append(mktnod(\"D:timeout\", \"Second-3310\"))\n        lk.append(mkenod(\"D:locktoken\", mktnod(\"D:href\", token)))\n        lk.append(\n            mkenod(\"D:lockroot\", mktnod(\"D:href\", quotep(self.args.SRS + self.vpath)))\n        )\n\n        lk2 = mkenod(\"D:activelock\")\n        xroot = mkenod(\"D:prop\", mkenod(\"D:lockdiscovery\", lk2))\n        for a in lk:\n            lk2.append(a)\n\n        ret = '<?xml version=\"1.0\" encoding=\"{}\"?>\\n'.format(uenc)\n        ret += ET.tostring(xroot).decode(\"utf-8\")\n\n        rc = 200\n        if self.can_write and not bos.path.isfile(abspath):\n            with open(fsenc(abspath), \"wb\") as _:\n                rc = 201\n\n        self.out_headers[\"Lock-Token\"] = \"<{}>\".format(token)\n        self.reply(ret.encode(enc, \"replace\"), rc, \"text/xml; charset=\" + enc)\n        return True\n\n    def handle_unlock(self) -> bool:\n        if self.do_log:\n            self.log(\"UNLOCK %s @%s\" % (self.req, self.uname))\n\n        if self.args.no_dav:\n            raise Pebkac(405, \"WebDAV is disabled in server config\")\n\n        if not self.can_write and \"Microsoft-WebDAV\" not in self.ua:\n            self.log(\"{} tried to lock [{}]\".format(self.uname, self.vpath))\n            raise Pebkac(401, \"authenticate\")\n\n        self.send_headers(None, 204)\n        return True\n\n    def handle_mkcol(self) -> bool:\n        if self._applesan():\n            return True\n\n        if self.do_log:\n            self.log(\"MKCOL %s @%s\" % (self.req, self.uname))\n\n        try:\n            return self._mkdir(self.vpath, True)\n        except Pebkac as ex:\n            if ex.code >= 500:\n                raise\n\n            self.reply(b\"\", ex.code)\n            return True\n\n    def handle_move(self) -> bool:\n        dst = self.headers[\"destination\"]\n        dst = re.sub(\"^https?://[^/]+\", \"\", dst).lstrip()\n        dst = unquotep(dst)\n        if not self._mv(self.vpath, dst.lstrip(\"/\")):\n            return False\n\n        return True\n\n    def _applesan(self) -> bool:\n        if self.args.dav_mac or \"Darwin/\" not in self.ua:\n            return False\n\n        vp = \"/\" + self.vpath\n        ptn = r\"/\\.(_|DS_Store|Spotlight-|fseventsd|Trashes|AppleDouble)|/__MACOS\"\n        if re.search(ptn, vp):\n            zt = '<?xml version=\"1.0\" encoding=\"utf-8\"?>\\n<D:error xmlns:D=\"DAV:\"><D:lock-token-submitted><D:href>{}</D:href></D:lock-token-submitted></D:error>'\n            zb = zt.format(vp).encode(\"utf-8\", \"replace\")\n            self.reply(zb, 423, \"text/xml; charset=utf-8\")\n            return True\n\n        return False\n\n    def send_chunk(self, txt: str, enc: str, bmax: int) -> str:\n        orig_len = len(txt)\n        buf = txt[:bmax].encode(enc, \"replace\")[:bmax]\n        try:\n            _ = buf.decode(enc)\n        except UnicodeDecodeError as ude:\n            buf = buf[: ude.start]\n\n        txt = txt[len(buf.decode(enc)) :]\n        if txt and len(txt) == orig_len:\n            raise Pebkac(500, \"chunk slicing failed\")\n\n        buf = \"{:x}\\r\\n\".format(len(buf)).encode(enc) + buf\n        self.s.sendall(buf + b\"\\r\\n\")\n        return txt\n\n    def handle_options(self) -> bool:\n        if self.do_log:\n            self.log(\"OPTIONS %s @%s\" % (self.req, self.uname))\n\n        oh = self.out_headers\n        oh[\"Allow\"] = \", \".join(self.conn.hsrv.mallow)\n\n        if not self.args.no_dav:\n            # PROPPATCH, LOCK, UNLOCK, COPY: noop (spec-must)\n            oh[\"Dav\"] = \"1, 2\"\n            oh[\"Ms-Author-Via\"] = \"DAV\"\n\n        # winxp-webdav doesnt know what 204 is\n        self.send_headers(0, 200)\n        return True\n\n    def handle_delete(self) -> bool:\n        self.log(\"DELETE %s @%s\" % (self.req, self.uname))\n        return self.handle_rm([])\n\n    def handle_put(self) -> bool:\n        self.log(\"PUT %s @%s\" % (self.req, self.uname))\n\n        if not self.can_write:\n            t = \"user {} does not have write-access here\"\n            raise Pebkac(403, t.format(self.uname))\n\n        if not self.args.no_dav and self._applesan():\n            return self.headers.get(\"content-length\") == \"0\"\n\n        if self.headers.get(\"expect\", \"\").lower() == \"100-continue\":\n            try:\n                self.s.sendall(b\"HTTP/1.1 100 Continue\\r\\n\\r\\n\")\n            except:\n                raise Pebkac(400, \"client d/c before 100 continue\")\n\n        return self.handle_stash(True)\n\n    def handle_post(self) -> bool:\n        self.log(\"POST %s @%s\" % (self.req, self.uname))\n\n        if self.headers.get(\"expect\", \"\").lower() == \"100-continue\":\n            try:\n                self.s.sendall(b\"HTTP/1.1 100 Continue\\r\\n\\r\\n\")\n            except:\n                raise Pebkac(400, \"client d/c before 100 continue\")\n\n        if \"raw\" in self.uparam:\n            return self.handle_stash(False)\n\n        ctype = self.headers.get(\"content-type\", \"\").lower()\n\n        if \"multipart/form-data\" in ctype:\n            return self.handle_post_multipart()\n\n        if (\n            \"application/json\" in ctype\n            or \"text/plain\" in ctype\n            or \"application/xml\" in ctype\n        ):\n            return self.handle_post_json()\n\n        if \"move\" in self.uparam:\n            return self.handle_mv()\n\n        if \"delete\" in self.uparam:\n            return self.handle_rm([])\n\n        if \"application/octet-stream\" in ctype:\n            return self.handle_post_binary()\n\n        if \"application/x-www-form-urlencoded\" in ctype:\n            opt = self.args.urlform\n            if \"stash\" in opt:\n                return self.handle_stash(False)\n\n            if \"save\" in opt:\n                post_sz, _, _, _, path, _ = self.dump_to_file(False)\n                self.log(\"urlform: {} bytes, {}\".format(post_sz, path))\n            elif \"print\" in opt:\n                reader, _ = self.get_body_reader()\n                buf = b\"\"\n                for rbuf in reader:\n                    buf += rbuf\n                    if not rbuf or len(buf) >= 32768:\n                        break\n\n                if buf:\n                    orig = buf.decode(\"utf-8\", \"replace\")\n                    t = \"urlform_raw {} @ {}\\n  {}\\n\"\n                    self.log(t.format(len(orig), self.vpath, orig))\n                    try:\n                        zb = unquote(buf.replace(b\"+\", b\" \"))\n                        plain = zb.decode(\"utf-8\", \"replace\")\n                        if buf.startswith(b\"msg=\"):\n                            plain = plain[4:]\n                            xm = self.vn.flags.get(\"xm\")\n                            if xm:\n                                runhook(\n                                    self.log,\n                                    xm,\n                                    self.vn.canonical(self.rem),\n                                    self.vpath,\n                                    self.host,\n                                    self.uname,\n                                    time.time(),\n                                    len(buf),\n                                    self.ip,\n                                    time.time(),\n                                    plain,\n                                )\n\n                        t = \"urlform_dec {} @ {}\\n  {}\\n\"\n                        self.log(t.format(len(plain), self.vpath, plain))\n\n                    except Exception as ex:\n                        self.log(repr(ex))\n\n            if \"get\" in opt:\n                return self.handle_get()\n\n            raise Pebkac(405, \"POST({}) is disabled in server config\".format(ctype))\n\n        raise Pebkac(405, \"don't know how to handle POST({})\".format(ctype))\n\n    def get_xml_enc(self, txt: str) -> str:\n        ofs = txt[:512].find(' encoding=\"')\n        enc = \"\"\n        if ofs + 1:\n            enc = txt[ofs + 6 :].split('\"')[1]\n        else:\n            enc = self.headers.get(\"content-type\", \"\").lower()\n            ofs = enc.find(\"charset=\")\n            if ofs + 1:\n                enc = enc[ofs + 4].split(\"=\")[1].split(\";\")[0].strip(\"\\\"'\")\n            else:\n                enc = \"\"\n\n        return enc or \"utf-8\"\n\n    def get_body_reader(self) -> tuple[Generator[bytes, None, None], int]:\n        if \"chunked\" in self.headers.get(\"transfer-encoding\", \"\").lower():\n            return read_socket_chunked(self.sr), -1\n\n        remains = int(self.headers.get(\"content-length\", -1))\n        if remains == -1:\n            self.keepalive = False\n            return read_socket_unbounded(self.sr), remains\n        else:\n            return read_socket(self.sr, remains), remains\n\n    def dump_to_file(self, is_put: bool) -> tuple[int, str, str, int, str, str]:\n        # post_sz, sha_hex, sha_b64, remains, path, url\n        reader, remains = self.get_body_reader()\n        vfs, rem = self.asrv.vfs.get(self.vpath, self.uname, False, True)\n        rnd, _, lifetime, xbu, xau = self.upload_flags(vfs)\n        lim = vfs.get_dbv(rem)[0].lim\n        fdir = vfs.canonical(rem)\n        if lim:\n            fdir, rem = lim.all(\n                self.ip, rem, remains, vfs.realpath, fdir, self.conn.hsrv.broker\n            )\n\n        fn = None\n        if rem and not self.trailing_slash and not bos.path.isdir(fdir):\n            fdir, fn = os.path.split(fdir)\n            rem, _ = vsplit(rem)\n\n        bos.makedirs(fdir)\n\n        open_ka: dict[str, Any] = {\"fun\": open}\n        open_a = [\"wb\", 512 * 1024]\n\n        # user-request || config-force\n        if (\"gz\" in vfs.flags or \"xz\" in vfs.flags) and (\n            \"pk\" in vfs.flags\n            or \"pk\" in self.uparam\n            or \"gz\" in self.uparam\n            or \"xz\" in self.uparam\n        ):\n            fb = {\"gz\": 9, \"xz\": 0}  # default/fallback level\n            lv = {}  # selected level\n            alg = \"\"  # selected algo (gz=preferred)\n\n            # user-prefs first\n            if \"gz\" in self.uparam or \"pk\" in self.uparam:  # def.pk\n                alg = \"gz\"\n            if \"xz\" in self.uparam:\n                alg = \"xz\"\n            if alg:\n                zso = self.uparam.get(alg)\n                lv[alg] = fb[alg] if zso is None else int(zso)\n\n            if alg not in vfs.flags:\n                alg = \"gz\" if \"gz\" in vfs.flags else \"xz\"\n\n            # then server overrides\n            pk = vfs.flags.get(\"pk\")\n            if pk is not None:\n                # config-forced on\n                alg = alg or \"gz\"  # def.pk\n                try:\n                    # config-forced opts\n                    alg, nlv = pk.split(\",\")\n                    lv[alg] = int(nlv)\n                except:\n                    pass\n\n            lv[alg] = lv.get(alg) or fb.get(alg) or 0\n\n            self.log(\"compressing with {} level {}\".format(alg, lv.get(alg)))\n            if alg == \"gz\":\n                open_ka[\"fun\"] = gzip.GzipFile\n                open_a = [\"wb\", lv[alg], None, 0x5FEE6600]  # 2021-01-01\n            elif alg == \"xz\":\n                open_ka = {\"fun\": lzma.open, \"preset\": lv[alg]}\n                open_a = [\"wb\"]\n            else:\n                self.log(\"fallthrough? thats a bug\", 1)\n\n        suffix = \"-{:.6f}-{}\".format(time.time(), self.dip())\n        nameless = not fn\n        if nameless:\n            suffix += \".bin\"\n            fn = \"put\" + suffix\n\n        params = {\"suffix\": suffix, \"fdir\": fdir}\n        if self.args.nw:\n            params = {}\n            fn = os.devnull\n\n        params.update(open_ka)\n        assert fn\n\n        if not self.args.nw:\n            if rnd:\n                fn = rand_name(fdir, fn, rnd)\n\n            fn = sanitize_fn(fn or \"\", \"\", [\".prologue.html\", \".epilogue.html\"])\n\n        path = os.path.join(fdir, fn)\n\n        if xbu:\n            at = time.time() - lifetime\n            if not runhook(\n                self.log,\n                xbu,\n                path,\n                self.vpath,\n                self.host,\n                self.uname,\n                at,\n                remains,\n                self.ip,\n                at,\n                \"\",\n            ):\n                t = \"upload blocked by xbu server config\"\n                self.log(t, 1)\n                raise Pebkac(403, t)\n\n        if is_put and not (self.args.no_dav or self.args.nw) and bos.path.exists(path):\n            # allow overwrite if...\n            #  * volflag 'daw' is set, or client is definitely webdav\n            #  * and account has delete-access\n            # or...\n            #  * file exists, is empty, sufficiently new\n            #  * and there is no .PARTIAL\n\n            tnam = fn + \".PARTIAL\"\n            if self.args.dotpart:\n                tnam = \".\" + tnam\n\n            if (\n                self.can_delete\n                and (vfs.flags.get(\"daw\") or \"x-oc-mtime\" in self.headers)\n            ) or (\n                not bos.path.exists(os.path.join(fdir, tnam))\n                and not bos.path.getsize(path)\n                and bos.path.getmtime(path) >= time.time() - self.args.blank_wt\n            ):\n                # small toctou, but better than clobbering a hardlink\n                bos.unlink(path)\n\n        with ren_open(fn, *open_a, **params) as zfw:\n            f, fn = zfw[\"orz\"]\n            path = os.path.join(fdir, fn)\n            post_sz, sha_hex, sha_b64 = hashcopy(reader, f, self.args.s_wr_slp)\n\n        if lim:\n            lim.nup(self.ip)\n            lim.bup(self.ip, post_sz)\n            try:\n                lim.chk_sz(post_sz)\n                lim.chk_vsz(self.conn.hsrv.broker, vfs.realpath, post_sz)\n            except:\n                bos.unlink(path)\n                raise\n\n        if self.args.nw:\n            return post_sz, sha_hex, sha_b64, remains, path, \"\"\n\n        at = mt = time.time() - lifetime\n        cli_mt = self.headers.get(\"x-oc-mtime\")\n        if cli_mt:\n            try:\n                mt = int(cli_mt)\n                times = (int(time.time()), mt)\n                bos.utime(path, times, False)\n            except:\n                pass\n\n        if nameless and \"magic\" in vfs.flags:\n            try:\n                ext = self.conn.hsrv.magician.ext(path)\n            except Exception as ex:\n                self.log(\"filetype detection failed for [{}]: {}\".format(path, ex), 6)\n                ext = None\n\n            if ext:\n                if rnd:\n                    fn2 = rand_name(fdir, \"a.\" + ext, rnd)\n                else:\n                    fn2 = fn.rsplit(\".\", 1)[0] + \".\" + ext\n\n                params[\"suffix\"] = suffix[:-4]\n                with ren_open(fn, *open_a, **params) as zfw:\n                    f, fn = zfw[\"orz\"]\n\n                path2 = os.path.join(fdir, fn2)\n                atomic_move(path, path2)\n                fn = fn2\n                path = path2\n\n        if xau and not runhook(\n            self.log,\n            xau,\n            path,\n            self.vpath,\n            self.host,\n            self.uname,\n            mt,\n            post_sz,\n            self.ip,\n            at,\n            \"\",\n        ):\n            t = \"upload blocked by xau server config\"\n            self.log(t, 1)\n            os.unlink(path)\n            raise Pebkac(403, t)\n\n        vfs, rem = vfs.get_dbv(rem)\n        self.conn.hsrv.broker.say(\n            \"up2k.hash_file\",\n            vfs.realpath,\n            vfs.vpath,\n            vfs.flags,\n            rem,\n            fn,\n            self.ip,\n            at,\n            self.uname,\n            True,\n        )\n\n        vsuf = \"\"\n        if (self.can_read or self.can_upget) and \"fk\" in vfs.flags:\n            vsuf = \"?k=\" + self.gen_fk(\n                self.args.fk_salt,\n                path,\n                post_sz,\n                0 if ANYWIN else bos.stat(path).st_ino,\n            )[: vfs.flags[\"fk\"]]\n\n        vpath = \"/\".join([x for x in [vfs.vpath, rem, fn] if x])\n        vpath = quotep(vpath)\n\n        url = \"{}://{}/{}\".format(\n            \"https\" if self.is_https else \"http\",\n            self.host,\n            self.args.RS + vpath + vsuf,\n        )\n\n        return post_sz, sha_hex, sha_b64, remains, path, url\n\n    def handle_stash(self, is_put: bool) -> bool:\n        post_sz, sha_hex, sha_b64, remains, path, url = self.dump_to_file(is_put)\n        spd = self._spd(post_sz)\n        t = \"{} wrote {}/{} bytes to {}  # {}\"\n        self.log(t.format(spd, post_sz, remains, path, sha_b64[:28]))  # 21\n\n        ac = self.uparam.get(\n            \"want\", self.headers.get(\"accept\", \"\").lower().split(\";\")[-1]\n        )\n        if ac == \"url\":\n            t = url\n        else:\n            t = \"{}\\n{}\\n{}\\n{}\\n\".format(post_sz, sha_b64, sha_hex[:56], url)\n\n        h = {\"Location\": url} if is_put and url else {}\n\n        if \"x-oc-mtime\" in self.headers:\n            h[\"X-OC-MTime\"] = \"accepted\"\n            t = \"\"  # some webdav clients expect/prefer this\n\n        self.reply(t.encode(\"utf-8\"), 201, headers=h)\n        return True\n\n    def bakflip(self, f: typing.BinaryIO, ofs: int, sz: int, sha: str) -> None:\n        if not self.args.bak_flips or self.args.nw:\n            return\n\n        sdir = self.args.bf_dir\n        fp = os.path.join(sdir, sha)\n        if bos.path.exists(fp):\n            return self.log(\"no bakflip; have it\", 6)\n\n        if not bos.path.isdir(sdir):\n            bos.makedirs(sdir)\n\n        if len(bos.listdir(sdir)) >= self.args.bf_nc:\n            return self.log(\"no bakflip; too many\", 3)\n\n        nrem = sz\n        f.seek(ofs)\n        with open(fp, \"wb\") as fo:\n            while nrem:\n                buf = f.read(min(nrem, 512 * 1024))\n                if not buf:\n                    break\n\n                nrem -= len(buf)\n                fo.write(buf)\n\n        if nrem:\n            self.log(\"bakflip truncated; {} remains\".format(nrem), 1)\n            atomic_move(fp, fp + \".trunc\")\n        else:\n            self.log(\"bakflip ok\", 2)\n\n    def _spd(self, nbytes: int, add: bool = True) -> str:\n        if add:\n            self.conn.nbyte += nbytes\n\n        spd1 = get_spd(nbytes, self.t0)\n        spd2 = get_spd(self.conn.nbyte, self.conn.t0)\n        return \"%s %s n%s\" % (spd1, spd2, self.conn.nreq)\n\n    def handle_post_multipart(self) -> bool:\n        self.parser = MultipartParser(self.log, self.sr, self.headers)\n        self.parser.parse()\n\n        act = self.parser.require(\"act\", 64)\n\n        if act == \"login\":\n            return self.handle_login()\n\n        if act == \"mkdir\":\n            return self.handle_mkdir()\n\n        if act == \"new_md\":\n            # kinda silly but has the least side effects\n            return self.handle_new_md()\n\n        if act == \"bput\":\n            return self.handle_plain_upload()\n\n        if act == \"tput\":\n            return self.handle_text_upload()\n\n        if act == \"zip\":\n            return self.handle_zip_post()\n\n        raise Pebkac(422, 'invalid action \"{}\"'.format(act))\n\n    def handle_zip_post(self) -> bool:\n        assert self.parser\n        try:\n            k = next(x for x in self.uparam if x in (\"zip\", \"tar\"))\n        except:\n            raise Pebkac(422, \"need zip or tar keyword\")\n\n        v = self.uparam[k]\n\n        vn, rem = self.asrv.vfs.get(self.vpath, self.uname, True, False)\n        zs = self.parser.require(\"files\", 1024 * 1024)\n        if not zs:\n            raise Pebkac(422, \"need files list\")\n\n        items = zs.replace(\"\\r\", \"\").split(\"\\n\")\n        items = [unquotep(x) for x in items if items]\n\n        self.parser.drop()\n        return self.tx_zip(k, v, \"\", vn, rem, items, self.args.ed)\n\n    def handle_post_json(self) -> bool:\n        try:\n            remains = int(self.headers[\"content-length\"])\n        except:\n            raise Pebkac(411)\n\n        if remains > 1024 * 1024:\n            raise Pebkac(413, \"json 2big\")\n\n        enc = \"utf-8\"\n        ctype = self.headers.get(\"content-type\", \"\").lower()\n        if \"charset\" in ctype:\n            enc = ctype.split(\"charset\")[1].strip(\" =\").split(\";\")[0].strip()\n\n        try:\n            json_buf = self.sr.recv_ex(remains)\n        except UnrecvEOF:\n            raise Pebkac(422, \"client disconnected while posting JSON\")\n\n        self.log(\"decoding {} bytes of {} json\".format(len(json_buf), enc))\n        try:\n            body = json.loads(json_buf.decode(enc, \"replace\"))\n        except:\n            raise Pebkac(422, \"you POSTed invalid json\")\n\n        # self.reply(b\"cloudflare\", 503)\n        # return True\n\n        if \"srch\" in self.uparam or \"srch\" in body:\n            return self.handle_search(body)\n\n        if \"delete\" in self.uparam:\n            return self.handle_rm(body)\n\n        name = undot(body[\"name\"])\n        if \"/\" in name:\n            raise Pebkac(400, \"your client is old; press CTRL-SHIFT-R and try again\")\n\n        vfs, rem = self.asrv.vfs.get(self.vpath, self.uname, False, True)\n        dbv, vrem = vfs.get_dbv(rem)\n\n        body[\"vtop\"] = dbv.vpath\n        body[\"ptop\"] = dbv.realpath\n        body[\"prel\"] = vrem\n        body[\"host\"] = self.host\n        body[\"user\"] = self.uname\n        body[\"addr\"] = self.ip\n        body[\"vcfg\"] = dbv.flags\n\n        if not self.can_delete:\n            body.pop(\"replace\", None)\n\n        if rem:\n            dst = vfs.canonical(rem)\n            try:\n                if not bos.path.isdir(dst):\n                    bos.makedirs(dst)\n            except OSError as ex:\n                self.log(\"makedirs failed [{}]\".format(dst))\n                if not bos.path.isdir(dst):\n                    if ex.errno == errno.EACCES:\n                        raise Pebkac(500, \"the server OS denied write-access\")\n\n                    if ex.errno == errno.EEXIST:\n                        raise Pebkac(400, \"some file got your folder name\")\n\n                    raise Pebkac(500, min_ex())\n            except:\n                raise Pebkac(500, min_ex())\n\n        x = self.conn.hsrv.broker.ask(\"up2k.handle_json\", body, self.u2fh.aps)\n        ret = x.get()\n        if self.is_vproxied:\n            if \"purl\" in ret:\n                ret[\"purl\"] = self.args.SR + ret[\"purl\"]\n\n        ret = json.dumps(ret)\n        self.log(ret)\n        self.reply(ret.encode(\"utf-8\"), mime=\"application/json\")\n        return True\n\n    def handle_search(self, body: dict[str, Any]) -> bool:\n        idx = self.conn.get_u2idx()\n        if not idx or not hasattr(idx, \"p_end\"):\n            raise Pebkac(500, \"sqlite3 is not available on the server; cannot search\")\n\n        vols = []\n        seen = {}\n        for vtop in self.rvol:\n            vfs, _ = self.asrv.vfs.get(vtop, self.uname, True, False)\n            vfs = vfs.dbv or vfs\n            if vfs in seen:\n                continue\n\n            seen[vfs] = True\n            vols.append((vfs.vpath, vfs.realpath, vfs.flags))\n\n        t0 = time.time()\n        if idx.p_end:\n            penalty = 0.7\n            t_idle = t0 - idx.p_end\n            if idx.p_dur > 0.7 and t_idle < penalty:\n                t = \"rate-limit {:.1f} sec, cost {:.2f}, idle {:.2f}\"\n                raise Pebkac(429, t.format(penalty, idx.p_dur, t_idle))\n\n        if \"srch\" in body:\n            # search by up2k hashlist\n            vbody = copy.deepcopy(body)\n            vbody[\"hash\"] = len(vbody[\"hash\"])\n            self.log(\"qj: \" + repr(vbody))\n            hits = idx.fsearch(vols, body)\n            msg: Any = repr(hits)\n            taglist: list[str] = []\n            trunc = False\n        else:\n            # search by query params\n            q = body[\"q\"]\n            n = body.get(\"n\", self.args.srch_hits)\n            self.log(\"qj: {} |{}|\".format(q, n))\n            hits, taglist, trunc = idx.search(vols, q, n)\n            msg = len(hits)\n\n        idx.p_end = time.time()\n        idx.p_dur = idx.p_end - t0\n        self.log(\"q#: {} ({:.2f}s)\".format(msg, idx.p_dur))\n\n        order = []\n        cfg = self.args.mte.split(\",\")\n        for t in cfg:\n            if t in taglist:\n                order.append(t)\n        for t in taglist:\n            if t not in order:\n                order.append(t)\n\n        if self.is_vproxied:\n            for hit in hits:\n                hit[\"rp\"] = self.args.RS + hit[\"rp\"]\n\n        rj = {\"hits\": hits, \"tag_order\": order, \"trunc\": trunc}\n        r = json.dumps(rj).encode(\"utf-8\")\n        self.reply(r, mime=\"application/json\")\n        return True\n\n    def handle_post_binary(self) -> bool:\n        try:\n            remains = int(self.headers[\"content-length\"])\n        except:\n            raise Pebkac(400, \"you must supply a content-length for binary POST\")\n\n        try:\n            chash = self.headers[\"x-up2k-hash\"]\n            wark = self.headers[\"x-up2k-wark\"]\n        except KeyError:\n            raise Pebkac(400, \"need hash and wark headers for binary POST\")\n\n        vfs, _ = self.asrv.vfs.get(self.vpath, self.uname, False, True)\n        ptop = (vfs.dbv or vfs).realpath\n\n        x = self.conn.hsrv.broker.ask(\"up2k.handle_chunk\", ptop, wark, chash)\n        response = x.get()\n        chunksize, cstart, path, lastmod, sprs = response\n\n        try:\n            if self.args.nw:\n                path = os.devnull\n\n            if remains > chunksize:\n                raise Pebkac(400, \"your chunk is too big to fit\")\n\n            self.log(\"writing {} #{} @{} len {}\".format(path, chash, cstart, remains))\n\n            reader = read_socket(self.sr, remains)\n\n            f = None\n            fpool = not self.args.no_fpool and sprs\n            if fpool:\n                with self.mutex:\n                    try:\n                        f = self.u2fh.pop(path)\n                    except:\n                        pass\n\n            f = f or open(fsenc(path), \"rb+\", 512 * 1024)\n\n            try:\n                f.seek(cstart[0])\n                post_sz, _, sha_b64 = hashcopy(reader, f, self.args.s_wr_slp)\n\n                if sha_b64 != chash:\n                    try:\n                        self.bakflip(f, cstart[0], post_sz, sha_b64)\n                    except:\n                        self.log(\"bakflip failed: \" + min_ex())\n\n                    t = \"your chunk got corrupted somehow (received {} bytes); expected vs received hash:\\n{}\\n{}\"\n                    raise Pebkac(400, t.format(post_sz, chash, sha_b64))\n\n                if len(cstart) > 1 and path != os.devnull:\n                    self.log(\n                        \"clone {} to {}\".format(\n                            cstart[0], \" & \".join(unicode(x) for x in cstart[1:])\n                        )\n                    )\n                    ofs = 0\n                    while ofs < chunksize:\n                        bufsz = min(chunksize - ofs, 4 * 1024 * 1024)\n                        f.seek(cstart[0] + ofs)\n                        buf = f.read(bufsz)\n                        for wofs in cstart[1:]:\n                            f.seek(wofs + ofs)\n                            f.write(buf)\n\n                        ofs += len(buf)\n\n                    self.log(\"clone {} done\".format(cstart[0]))\n\n                if not fpool:\n                    f.close()\n                else:\n                    with self.mutex:\n                        self.u2fh.put(path, f)\n            except:\n                # maybe busted handle (eg. disk went full)\n                f.close()\n                raise\n        finally:\n            x = self.conn.hsrv.broker.ask(\"up2k.release_chunk\", ptop, wark, chash)\n            x.get()  # block client until released\n\n        x = self.conn.hsrv.broker.ask(\"up2k.confirm_chunk\", ptop, wark, chash)\n        ztis = x.get()\n        try:\n            num_left, fin_path = ztis\n        except:\n            self.loud_reply(ztis, status=500)\n            return False\n\n        if not num_left and fpool:\n            with self.mutex:\n                self.u2fh.close(path)\n\n        if not num_left and not self.args.nw:\n            self.conn.hsrv.broker.ask(\n                \"up2k.finish_upload\", ptop, wark, self.u2fh.aps\n            ).get()\n\n        cinf = self.headers.get(\"x-up2k-stat\", \"\")\n\n        spd = self._spd(post_sz)\n        self.log(\"{:70} thank {}\".format(spd, cinf))\n        self.reply(b\"thank\")\n        return True\n\n    def handle_login(self) -> bool:\n        assert self.parser\n        pwd = self.parser.require(\"cppwd\", 64)\n        self.parser.drop()\n\n        self.out_headerlist = [\n            x for x in self.out_headerlist if x[0] != \"Set-Cookie\" or \"cppw\" != x[1][:4]\n        ]\n\n        dst = self.args.SRS\n        if self.vpath:\n            dst += quotep(self.vpath)\n\n        msg = self.get_pwd_cookie(pwd)\n        html = self.j2s(\"msg\", h1=msg, h2='<a href=\"' + dst + '\">ack</a>', redir=dst)\n        self.reply(html.encode(\"utf-8\"))\n        return True\n\n    def get_pwd_cookie(self, pwd: str) -> str:\n        if self.asrv.ah.hash(pwd) in self.asrv.iacct:\n            msg = \"login ok\"\n            dur = int(60 * 60 * self.args.logout)\n        else:\n            self.log(\"invalid password: {}\".format(pwd), 3)\n            g = self.conn.hsrv.gpwd\n            if g.lim:\n                bonk, ip = g.bonk(self.ip, pwd)\n                if bonk:\n                    xban = self.vn.flags.get(\"xban\")\n                    if not xban or not runhook(\n                        self.log,\n                        xban,\n                        self.vn.canonical(self.rem),\n                        self.vpath,\n                        self.host,\n                        self.uname,\n                        time.time(),\n                        0,\n                        self.ip,\n                        time.time(),\n                        \"pw\",\n                    ):\n                        self.log(\"client banned: invalid passwords\", 1)\n                        self.conn.hsrv.bans[ip] = bonk\n\n            msg = \"naw dude\"\n            pwd = \"x\"  # nosec\n            dur = None\n\n        if pwd == \"x\":\n            # reset both plaintext and tls\n            # (only affects active tls cookies when tls)\n            for k in (\"cppwd\", \"cppws\") if self.is_https else (\"cppwd\",):\n                ck = gencookie(k, pwd, self.args.R, False, dur)\n                self.out_headerlist.append((\"Set-Cookie\", ck))\n        else:\n            k = \"cppws\" if self.is_https else \"cppwd\"\n            ck = gencookie(k, pwd, self.args.R, self.is_https, dur)\n            self.out_headerlist.append((\"Set-Cookie\", ck))\n\n        return msg\n\n    def handle_mkdir(self) -> bool:\n        assert self.parser\n        new_dir = self.parser.require(\"name\", 512)\n        self.parser.drop()\n\n        sanitized = sanitize_fn(new_dir, \"\", [])\n        return self._mkdir(vjoin(self.vpath, sanitized))\n\n    def _mkdir(self, vpath: str, dav: bool = False) -> bool:\n        nullwrite = self.args.nw\n        vfs, rem = self.asrv.vfs.get(vpath, self.uname, False, True)\n        self._assert_safe_rem(rem)\n        fn = vfs.canonical(rem)\n\n        if not nullwrite:\n            fdir = os.path.dirname(fn)\n\n            if not bos.path.isdir(fdir):\n                raise Pebkac(409, \"parent folder does not exist\")\n\n            if bos.path.isdir(fn):\n                raise Pebkac(405, \"that folder exists already\")\n\n            try:\n                bos.mkdir(fn)\n            except OSError as ex:\n                if ex.errno == errno.EACCES:\n                    raise Pebkac(500, \"the server OS denied write-access\")\n\n                raise Pebkac(500, \"mkdir failed:\\n\" + min_ex())\n            except:\n                raise Pebkac(500, min_ex())\n\n        self.out_headers[\"X-New-Dir\"] = quotep(vpath.split(\"/\")[-1])\n\n        if dav:\n            self.reply(b\"\", 201)\n        else:\n            self.redirect(vpath, status=201)\n\n        return True\n\n    def handle_new_md(self) -> bool:\n        assert self.parser\n        new_file = self.parser.require(\"name\", 512)\n        self.parser.drop()\n\n        nullwrite = self.args.nw\n        vfs, rem = self.asrv.vfs.get(self.vpath, self.uname, False, True)\n        self._assert_safe_rem(rem)\n\n        if not new_file.endswith(\".md\"):\n            new_file += \".md\"\n\n        sanitized = sanitize_fn(new_file, \"\", [])\n\n        if not nullwrite:\n            fdir = vfs.canonical(rem)\n            fn = os.path.join(fdir, sanitized)\n\n            if bos.path.exists(fn):\n                raise Pebkac(500, \"that file exists already\")\n\n            with open(fsenc(fn), \"wb\") as f:\n                f.write(b\"`GRUNNUR`\\n\")\n\n        vpath = \"{}/{}\".format(self.vpath, sanitized).lstrip(\"/\")\n        self.redirect(vpath, \"?edit\")\n        return True\n\n    def upload_flags(self, vfs: VFS) -> tuple[int, bool, int, list[str], list[str]]:\n        if self.args.nw:\n            rnd = 0\n        else:\n            rnd = int(self.uparam.get(\"rand\") or self.headers.get(\"rand\") or 0)\n            if vfs.flags.get(\"rand\"):  # force-enable\n                rnd = max(rnd, vfs.flags[\"nrand\"])\n\n        ac = self.uparam.get(\n            \"want\", self.headers.get(\"accept\", \"\").lower().split(\";\")[-1]\n        )\n        want_url = ac == \"url\"\n        zs = self.uparam.get(\"life\", self.headers.get(\"life\", \"\"))\n        if zs:\n            vlife = vfs.flags.get(\"lifetime\") or 0\n            lifetime = max(0, int(vlife - int(zs)))\n        else:\n            lifetime = 0\n\n        return (\n            rnd,\n            want_url,\n            lifetime,\n            vfs.flags.get(\"xbu\") or [],\n            vfs.flags.get(\"xau\") or [],\n        )\n\n    def handle_plain_upload(self) -> bool:\n        assert self.parser\n        nullwrite = self.args.nw\n        vfs, rem = self.asrv.vfs.get(self.vpath, self.uname, False, True)\n        self._assert_safe_rem(rem)\n\n        upload_vpath = self.vpath\n        lim = vfs.get_dbv(rem)[0].lim\n        fdir_base = vfs.canonical(rem)\n        if lim:\n            fdir_base, rem = lim.all(\n                self.ip, rem, -1, vfs.realpath, fdir_base, self.conn.hsrv.broker\n            )\n            upload_vpath = \"{}/{}\".format(vfs.vpath, rem).strip(\"/\")\n            if not nullwrite:\n                bos.makedirs(fdir_base)\n\n        rnd, want_url, lifetime, xbu, xau = self.upload_flags(vfs)\n\n        files: list[tuple[int, str, str, str, str, str]] = []\n        # sz, sha_hex, sha_b64, p_file, fname, abspath\n        errmsg = \"\"\n        dip = self.dip()\n        t0 = time.time()\n        try:\n            assert self.parser.gen\n            for nfile, (p_field, p_file, p_data) in enumerate(self.parser.gen):\n                if not p_file:\n                    self.log(\"discarding incoming file without filename\")\n                    # fallthrough\n\n                fdir = fdir_base\n                fname = sanitize_fn(\n                    p_file or \"\", \"\", [\".prologue.html\", \".epilogue.html\"]\n                )\n                if p_file and not nullwrite:\n                    if rnd:\n                        fname = rand_name(fdir, fname, rnd)\n\n                    if not bos.path.isdir(fdir):\n                        raise Pebkac(404, \"that folder does not exist\")\n\n                    suffix = \"-{:.6f}-{}\".format(time.time(), dip)\n                    open_args = {\"fdir\": fdir, \"suffix\": suffix}\n\n                    # reserve destination filename\n                    with ren_open(fname, \"wb\", fdir=fdir, suffix=suffix) as zfw:\n                        fname = zfw[\"orz\"][1]\n\n                    tnam = fname + \".PARTIAL\"\n                    if self.args.dotpart:\n                        tnam = \".\" + tnam\n\n                    abspath = os.path.join(fdir, fname)\n                else:\n                    open_args = {}\n                    tnam = fname = os.devnull\n                    fdir = abspath = \"\"\n\n                if xbu:\n                    at = time.time() - lifetime\n                    if not runhook(\n                        self.log,\n                        xbu,\n                        abspath,\n                        self.vpath,\n                        self.host,\n                        self.uname,\n                        at,\n                        0,\n                        self.ip,\n                        at,\n                        \"\",\n                    ):\n                        t = \"upload blocked by xbu server config\"\n                        self.log(t, 1)\n                        raise Pebkac(403, t)\n\n                if lim:\n                    lim.chk_bup(self.ip)\n                    lim.chk_nup(self.ip)\n\n                try:\n                    max_sz = 0\n                    if lim:\n                        v1 = lim.smax\n                        v2 = lim.dfv - lim.dfl\n                        max_sz = min(v1, v2) if v1 and v2 else v1 or v2\n\n                    with ren_open(tnam, \"wb\", 512 * 1024, **open_args) as zfw:\n                        f, tnam = zfw[\"orz\"]\n                        tabspath = os.path.join(fdir, tnam)\n                        self.log(\"writing to {}\".format(tabspath))\n                        sz, sha_hex, sha_b64 = hashcopy(\n                            p_data, f, self.args.s_wr_slp, max_sz\n                        )\n                        if sz == 0:\n                            raise Pebkac(400, \"empty files in post\")\n\n                    if lim:\n                        lim.nup(self.ip)\n                        lim.bup(self.ip, sz)\n                        try:\n                            lim.chk_df(tabspath, sz, True)\n                            lim.chk_sz(sz)\n                            lim.chk_vsz(self.conn.hsrv.broker, vfs.realpath, sz)\n                            lim.chk_bup(self.ip)\n                            lim.chk_nup(self.ip)\n                        except:\n                            if not nullwrite:\n                                bos.unlink(tabspath)\n                                bos.unlink(abspath)\n                            fname = os.devnull\n                            raise\n\n                    if not nullwrite:\n                        atomic_move(tabspath, abspath)\n\n                    files.append(\n                        (sz, sha_hex, sha_b64, p_file or \"(discarded)\", fname, abspath)\n                    )\n                    at = time.time() - lifetime\n                    if xau and not runhook(\n                        self.log,\n                        xau,\n                        abspath,\n                        self.vpath,\n                        self.host,\n                        self.uname,\n                        at,\n                        sz,\n                        self.ip,\n                        at,\n                        \"\",\n                    ):\n                        t = \"upload blocked by xau server config\"\n                        self.log(t, 1)\n                        os.unlink(abspath)\n                        raise Pebkac(403, t)\n\n                    dbv, vrem = vfs.get_dbv(rem)\n                    self.conn.hsrv.broker.say(\n                        \"up2k.hash_file\",\n                        dbv.realpath,\n                        vfs.vpath,\n                        dbv.flags,\n                        vrem,\n                        fname,\n                        self.ip,\n                        at,\n                        self.uname,\n                        True,\n                    )\n                    self.conn.nbyte += sz\n\n                except Pebkac:\n                    self.parser.drop()\n                    raise\n\n        except Pebkac as ex:\n            errmsg = vol_san(\n                list(self.asrv.vfs.all_vols.values()), unicode(ex).encode(\"utf-8\")\n            ).decode(\"utf-8\")\n\n        td = max(0.1, time.time() - t0)\n        sz_total = sum(x[0] for x in files)\n        spd = (sz_total / td) / (1024 * 1024)\n\n        status = \"OK\"\n        if errmsg:\n            self.log(errmsg, 3)\n            status = \"ERROR\"\n\n        msg = \"{} // {} bytes // {:.3f} MiB/s\\n\".format(status, sz_total, spd)\n        jmsg: dict[str, Any] = {\n            \"status\": status,\n            \"sz\": sz_total,\n            \"mbps\": round(spd, 3),\n            \"files\": [],\n        }\n\n        if errmsg:\n            msg += errmsg + \"\\n\"\n            jmsg[\"error\"] = errmsg\n            errmsg = \"ERROR: \" + errmsg\n\n        for sz, sha_hex, sha_b64, ofn, lfn, ap in files:\n            vsuf = \"\"\n            if (self.can_read or self.can_upget) and \"fk\" in vfs.flags:\n                vsuf = \"?k=\" + self.gen_fk(\n                    self.args.fk_salt,\n                    ap,\n                    sz,\n                    0 if ANYWIN or not ap else bos.stat(ap).st_ino,\n                )[: vfs.flags[\"fk\"]]\n\n            vpath = \"{}/{}\".format(upload_vpath, lfn).strip(\"/\")\n            rel_url = quotep(self.args.RS + vpath) + vsuf\n            msg += 'sha512: {} // {} // {} bytes // <a href=\"/{}\">{}</a> {}\\n'.format(\n                sha_hex[:56],\n                sha_b64,\n                sz,\n                rel_url,\n                html_escape(ofn, crlf=True),\n                vsuf,\n            )\n            # truncated SHA-512 prevents length extension attacks;\n            # using SHA-512/224, optionally SHA-512/256 = :64\n            jpart = {\n                \"url\": \"{}://{}/{}\".format(\n                    \"https\" if self.is_https else \"http\",\n                    self.host,\n                    rel_url,\n                ),\n                \"sha512\": sha_hex[:56],\n                \"sha_b64\": sha_b64,\n                \"sz\": sz,\n                \"fn\": lfn,\n                \"fn_orig\": ofn,\n                \"path\": rel_url,\n            }\n            jmsg[\"files\"].append(jpart)\n\n        vspd = self._spd(sz_total, False)\n        self.log(\"{} {}\".format(vspd, msg))\n\n        suf = \"\"\n        if not nullwrite and self.args.write_uplog:\n            try:\n                log_fn = \"up.{:.6f}.txt\".format(t0)\n                with open(log_fn, \"wb\") as f:\n                    ft = \"{}:{}\".format(self.ip, self.addr[1])\n                    ft = \"{}\\n{}\\n{}\\n\".format(ft, msg.rstrip(), errmsg)\n                    f.write(ft.encode(\"utf-8\"))\n            except Exception as ex:\n                suf = \"\\nfailed to write the upload report: {}\".format(ex)\n\n        sc = 400 if errmsg else 201\n        if want_url:\n            msg = \"\\n\".join([x[\"url\"] for x in jmsg[\"files\"]])\n            if errmsg:\n                msg += \"\\n\" + errmsg\n\n            self.reply(msg.encode(\"utf-8\", \"replace\"), status=sc)\n        elif \"j\" in self.uparam:\n            jtxt = json.dumps(jmsg, indent=2, sort_keys=True).encode(\"utf-8\", \"replace\")\n            self.reply(jtxt, mime=\"application/json\", status=sc)\n        else:\n            self.redirect(\n                self.vpath,\n                msg=msg + suf,\n                flavor=\"return to\",\n                click=False,\n                status=sc,\n            )\n\n        if errmsg:\n            return False\n\n        self.parser.drop()\n        return True\n\n    def handle_text_upload(self) -> bool:\n        assert self.parser\n        try:\n            cli_lastmod3 = int(self.parser.require(\"lastmod\", 16))\n        except:\n            raise Pebkac(400, \"could not read lastmod from request\")\n\n        nullwrite = self.args.nw\n        vfs, rem = self.asrv.vfs.get(self.vpath, self.uname, True, True)\n        self._assert_safe_rem(rem)\n\n        clen = int(self.headers.get(\"content-length\", -1))\n        if clen == -1:\n            raise Pebkac(411)\n\n        rp, fn = vsplit(rem)\n        fp = vfs.canonical(rp)\n        lim = vfs.get_dbv(rem)[0].lim\n        if lim:\n            fp, rp = lim.all(self.ip, rp, clen, vfs.realpath, fp, self.conn.hsrv.broker)\n            bos.makedirs(fp)\n\n        fp = os.path.join(fp, fn)\n        rem = \"{}/{}\".format(rp, fn).strip(\"/\")\n\n        if not rem.endswith(\".md\"):\n            raise Pebkac(400, \"only markdown pls\")\n\n        if nullwrite:\n            response = json.dumps({\"ok\": True, \"lastmod\": 0})\n            self.log(response)\n            # TODO reply should parser.drop()\n            self.parser.drop()\n            self.reply(response.encode(\"utf-8\"))\n            return True\n\n        srv_lastmod = -1.0\n        srv_lastmod3 = -1\n        try:\n            st = bos.stat(fp)\n            srv_lastmod = st.st_mtime\n            srv_lastmod3 = int(srv_lastmod * 1000)\n        except OSError as ex:\n            if ex.errno != errno.ENOENT:\n                raise\n\n        # if file exists, chekc that timestamp matches the client's\n        if srv_lastmod >= 0:\n            same_lastmod = cli_lastmod3 in [-1, srv_lastmod3]\n            if not same_lastmod:\n                # some filesystems/transports limit precision to 1sec, hopefully floored\n                same_lastmod = (\n                    srv_lastmod == int(cli_lastmod3 / 1000)\n                    and cli_lastmod3 > srv_lastmod3\n                    and cli_lastmod3 - srv_lastmod3 < 1000\n                )\n\n            if not same_lastmod:\n                response = json.dumps(\n                    {\n                        \"ok\": False,\n                        \"lastmod\": srv_lastmod3,\n                        \"now\": int(time.time() * 1000),\n                    }\n                )\n                self.log(\n                    \"{} - {} = {}\".format(\n                        srv_lastmod3, cli_lastmod3, srv_lastmod3 - cli_lastmod3\n                    )\n                )\n                self.log(response)\n                self.parser.drop()\n                self.reply(response.encode(\"utf-8\"))\n                return True\n\n            mdir, mfile = os.path.split(fp)\n            mfile2 = \"{}.{:.3f}.md\".format(mfile[:-3], srv_lastmod)\n            try:\n                dp = os.path.join(mdir, \".hist\")\n                bos.mkdir(dp)\n                hidedir(dp)\n            except:\n                pass\n            bos.rename(fp, os.path.join(mdir, \".hist\", mfile2))\n\n        assert self.parser.gen\n        p_field, _, p_data = next(self.parser.gen)\n        if p_field != \"body\":\n            raise Pebkac(400, \"expected body, got {}\".format(p_field))\n\n        xbu = vfs.flags.get(\"xbu\")\n        if xbu:\n            if not runhook(\n                self.log,\n                xbu,\n                fp,\n                self.vpath,\n                self.host,\n                self.uname,\n                time.time(),\n                0,\n                self.ip,\n                time.time(),\n                \"\",\n            ):\n                t = \"save blocked by xbu server config\"\n                self.log(t, 1)\n                raise Pebkac(403, t)\n\n        if bos.path.exists(fp):\n            bos.unlink(fp)\n\n        with open(fsenc(fp), \"wb\", 512 * 1024) as f:\n            sz, sha512, _ = hashcopy(p_data, f, self.args.s_wr_slp)\n\n        if lim:\n            lim.nup(self.ip)\n            lim.bup(self.ip, sz)\n            try:\n                lim.chk_sz(sz)\n                lim.chk_vsz(self.conn.hsrv.broker, vfs.realpath, sz)\n            except:\n                bos.unlink(fp)\n                raise\n\n        new_lastmod = bos.stat(fp).st_mtime\n        new_lastmod3 = int(new_lastmod * 1000)\n        sha512 = sha512[:56]\n\n        xau = vfs.flags.get(\"xau\")\n        if xau and not runhook(\n            self.log,\n            xau,\n            fp,\n            self.vpath,\n            self.host,\n            self.uname,\n            new_lastmod,\n            sz,\n            self.ip,\n            new_lastmod,\n            \"\",\n        ):\n            t = \"save blocked by xau server config\"\n            self.log(t, 1)\n            os.unlink(fp)\n            raise Pebkac(403, t)\n\n        vfs, rem = vfs.get_dbv(rem)\n        self.conn.hsrv.broker.say(\n            \"up2k.hash_file\",\n            vfs.realpath,\n            vfs.vpath,\n            vfs.flags,\n            vsplit(rem)[0],\n            fn,\n            self.ip,\n            new_lastmod,\n            self.uname,\n            True,\n        )\n\n        response = json.dumps(\n            {\"ok\": True, \"lastmod\": new_lastmod3, \"size\": sz, \"sha512\": sha512}\n        )\n        self.log(response)\n        self.parser.drop()\n        self.reply(response.encode(\"utf-8\"))\n        return True\n\n    def _chk_lastmod(self, file_ts: int) -> tuple[str, bool]:\n        file_lastmod = formatdate(file_ts, usegmt=True)\n        cli_lastmod = self.headers.get(\"if-modified-since\")\n        if cli_lastmod:\n            try:\n                # some browser append \"; length=573\"\n                cli_lastmod = cli_lastmod.split(\";\")[0].strip()\n                cli_dt = parsedate(cli_lastmod)\n                assert cli_dt\n                cli_ts = calendar.timegm(cli_dt)\n                return file_lastmod, int(file_ts) > int(cli_ts)\n            except Exception as ex:\n                self.log(\n                    \"lastmod {}\\nremote: [{}]\\n local: [{}]\".format(\n                        repr(ex), cli_lastmod, file_lastmod\n                    )\n                )\n                return file_lastmod, file_lastmod != cli_lastmod\n\n        return file_lastmod, True\n\n    def tx_file(self, req_path: str) -> bool:\n        status = 200\n        logmsg = \"{:4} {} \".format(\"\", self.req)\n        logtail = \"\"\n\n        #\n        # if request is for foo.js, check if we have foo.js.{gz,br}\n\n        file_ts = 0\n        editions: dict[str, tuple[str, int]] = {}\n        for ext in [\"\", \".gz\", \".br\"]:\n            try:\n                fs_path = req_path + ext\n                st = bos.stat(fs_path)\n                if stat.S_ISDIR(st.st_mode):\n                    continue\n\n                if stat.S_ISBLK(st.st_mode):\n                    fd = bos.open(fs_path, os.O_RDONLY)\n                    try:\n                        sz = os.lseek(fd, 0, os.SEEK_END)\n                    finally:\n                        os.close(fd)\n                else:\n                    sz = st.st_size\n\n                file_ts = max(file_ts, int(st.st_mtime))\n                editions[ext or \"plain\"] = (fs_path, sz)\n            except:\n                pass\n            if not self.vpath.startswith(\".cpr/\"):\n                break\n\n        if not editions:\n            return self.tx_404()\n\n        #\n        # if-modified\n\n        file_lastmod, do_send = self._chk_lastmod(file_ts)\n        self.out_headers[\"Last-Modified\"] = file_lastmod\n        if not do_send:\n            status = 304\n\n        #\n        # Accept-Encoding and UA decides which edition to send\n\n        decompress = False\n        supported_editions = [\n            x.strip()\n            for x in self.headers.get(\"accept-encoding\", \"\").lower().split(\",\")\n        ]\n        if \".br\" in editions and \"br\" in supported_editions:\n            is_compressed = True\n            selected_edition = \".br\"\n            fs_path, file_sz = editions[\".br\"]\n            self.out_headers[\"Content-Encoding\"] = \"br\"\n        elif \".gz\" in editions:\n            is_compressed = True\n            selected_edition = \".gz\"\n            fs_path, file_sz = editions[\".gz\"]\n            if \"gzip\" not in supported_editions:\n                decompress = True\n            else:\n                if re.match(r\"MSIE [4-6]\\.\", self.ua) and \" SV1\" not in self.ua:\n                    decompress = True\n\n            if not decompress:\n                self.out_headers[\"Content-Encoding\"] = \"gzip\"\n        else:\n            is_compressed = False\n            selected_edition = \"plain\"\n\n        try:\n            fs_path, file_sz = editions[selected_edition]\n            logmsg += \"{} \".format(selected_edition.lstrip(\".\"))\n        except:\n            # client is old and we only have .br\n            # (could make brotli a dep to fix this but it's not worth)\n            raise Pebkac(404)\n\n        #\n        # partial\n\n        lower = 0\n        upper = file_sz\n        hrange = self.headers.get(\"range\")\n\n        # let's not support 206 with compression\n        # and multirange / multipart is also not-impl (mostly because calculating contentlength is a pain)\n        if do_send and not is_compressed and hrange and file_sz and \",\" not in hrange:\n            try:\n                if not hrange.lower().startswith(\"bytes\"):\n                    raise Exception()\n\n                a, b = hrange.split(\"=\", 1)[1].split(\"-\")\n\n                if a.strip():\n                    lower = int(a.strip())\n                else:\n                    lower = 0\n\n                if b.strip():\n                    upper = int(b.strip()) + 1\n                else:\n                    upper = file_sz\n\n                if upper > file_sz:\n                    upper = file_sz\n\n                if lower < 0 or lower >= upper:\n                    raise Exception()\n\n            except:\n                err = \"invalid range ({}), size={}\".format(hrange, file_sz)\n                self.loud_reply(\n                    err,\n                    status=416,\n                    headers={\"Content-Range\": \"bytes */{}\".format(file_sz)},\n                )\n                return True\n\n            status = 206\n            self.out_headers[\"Content-Range\"] = \"bytes {}-{}/{}\".format(\n                lower, upper - 1, file_sz\n            )\n\n            logtail += \" [\\033[36m{}-{}\\033[0m]\".format(lower, upper)\n\n        use_sendfile = False\n        if decompress:\n            open_func: Any = gzip.open\n            open_args: list[Any] = [fsenc(fs_path), \"rb\"]\n            # Content-Length := original file size\n            upper = gzip_orig_sz(fs_path)\n        else:\n            open_func = open\n            # 512 kB is optimal for huge files, use 64k\n            open_args = [fsenc(fs_path), \"rb\", 64 * 1024]\n            use_sendfile = (\n                not self.tls  #\n                and not self.args.no_sendfile\n                and hasattr(os, \"sendfile\")\n            )\n\n        #\n        # send reply\n\n        if is_compressed:\n            self.out_headers[\"Cache-Control\"] = \"max-age=604869\"\n        else:\n            self.permit_caching()\n\n        if \"txt\" in self.uparam:\n            mime = \"text/plain; charset={}\".format(self.uparam[\"txt\"] or \"utf-8\")\n        elif \"mime\" in self.uparam:\n            mime = str(self.uparam.get(\"mime\"))\n        else:\n            mime = guess_mime(req_path)\n\n        if \"nohtml\" in self.vn.flags and \"html\" in mime:\n            mime = \"text/plain; charset=utf-8\"\n\n        self.out_headers[\"Accept-Ranges\"] = \"bytes\"\n        self.send_headers(length=upper - lower, status=status, mime=mime)\n\n        logmsg += unicode(status) + logtail\n\n        if self.mode == \"HEAD\" or not do_send:\n            if self.do_log:\n                self.log(logmsg)\n\n            return True\n\n        ret = True\n        with open_func(*open_args) as f:\n            sendfun = sendfile_kern if use_sendfile else sendfile_py\n            remains = sendfun(\n                self.log, lower, upper, f, self.s, self.args.s_wr_sz, self.args.s_wr_slp\n            )\n\n        if remains > 0:\n            logmsg += \" \\033[31m\" + unicode(upper - remains) + \"\\033[0m\"\n            self.keepalive = False\n\n        spd = self._spd((upper - lower) - remains)\n        if self.do_log:\n            self.log(\"{},  {}\".format(logmsg, spd))\n\n        return ret\n\n    def tx_zip(\n        self,\n        fmt: str,\n        uarg: str,\n        vpath: str,\n        vn: VFS,\n        rem: str,\n        items: list[str],\n        dots: bool,\n    ) -> bool:\n        if self.args.no_zip:\n            raise Pebkac(400, \"not enabled\")\n\n        logmsg = \"{:4} {} \".format(\"\", self.req)\n        self.keepalive = False\n\n        if fmt == \"tar\":\n            mime = \"application/x-tar\"\n            packer: Type[StreamArc] = StreamTar\n        else:\n            mime = \"application/zip\"\n            packer = StreamZip\n\n        fn = items[0] if items and items[0] else self.vpath\n        if fn:\n            fn = fn.rstrip(\"/\").split(\"/\")[-1]\n        else:\n            fn = self.host.split(\":\")[0]\n\n        safe = (string.ascii_letters + string.digits).replace(\"%\", \"\")\n        afn = \"\".join([x if x in safe.replace('\"', \"\") else \"_\" for x in fn])\n        bascii = unicode(safe).encode(\"utf-8\")\n        zb = fn.encode(\"utf-8\", \"xmlcharrefreplace\")\n        if not PY2:\n            zbl = [\n                chr(x).encode(\"utf-8\")\n                if x in bascii\n                else \"%{:02x}\".format(x).encode(\"ascii\")\n                for x in zb\n            ]\n        else:\n            zbl = [unicode(x) if x in bascii else \"%{:02x}\".format(ord(x)) for x in zb]\n\n        ufn = b\"\".join(zbl).decode(\"ascii\")\n\n        cdis = \"attachment; filename=\\\"{}.{}\\\"; filename*=UTF-8''{}.{}\"\n        cdis = cdis.format(afn, fmt, ufn, fmt)\n        self.log(cdis)\n        self.send_headers(None, mime=mime, headers={\"Content-Disposition\": cdis})\n\n        fgen = vn.zipgen(\n            vpath, rem, set(items), self.uname, dots, False, not self.args.no_scandir\n        )\n        # for f in fgen: print(repr({k: f[k] for k in [\"vp\", \"ap\"]}))\n        bgen = packer(self.log, fgen, utf8=\"utf\" in uarg, pre_crc=\"crc\" in uarg)\n        bsent = 0\n        for buf in bgen.gen():\n            if not buf:\n                break\n\n            try:\n                self.s.sendall(buf)\n                bsent += len(buf)\n            except:\n                logmsg += \" \\033[31m\" + unicode(bsent) + \"\\033[0m\"\n                break\n\n        spd = self._spd(bsent)\n        self.log(\"{},  {}\".format(logmsg, spd))\n        return True\n\n    def tx_ico(self, ext: str, exact: bool = False) -> bool:\n        self.permit_caching()\n        if ext.endswith(\"/\"):\n            ext = \"folder\"\n            exact = True\n\n        bad = re.compile(r\"[](){}/ []|^[0-9_-]*$\")\n        n = ext.split(\".\")[::-1]\n        if not exact:\n            n = n[:-1]\n\n        ext = \"\"\n        for v in n:\n            if len(v) > 7 or bad.search(v):\n                break\n\n            ext = \"{}.{}\".format(v, ext)\n\n        ext = ext.rstrip(\".\") or \"unk\"\n        if len(ext) > 11:\n            ext = \"\u22ef\" + ext[-9:]\n\n        # chrome cannot handle more than ~2000 unique SVGs\n        chrome = \" rv:\" not in self.ua\n        mime, ico = self.ico.get(ext, not exact, chrome)\n\n        lm = formatdate(self.E.t0, usegmt=True)\n        self.reply(ico, mime=mime, headers={\"Last-Modified\": lm})\n        return True\n\n    def tx_md(self, fs_path: str) -> bool:\n        logmsg = \"     %s @%s \" % (self.req, self.uname)\n\n        if not self.can_write:\n            if \"edit\" in self.uparam or \"edit2\" in self.uparam:\n                return self.tx_404(True)\n\n        tpl = \"mde\" if \"edit2\" in self.uparam else \"md\"\n        html_path = os.path.join(self.E.mod, \"web\", \"{}.html\".format(tpl))\n        template = self.j2j(tpl)\n\n        st = bos.stat(fs_path)\n        ts_md = st.st_mtime\n\n        st = bos.stat(html_path)\n        ts_html = st.st_mtime\n\n        sz_md = 0\n        for buf in yieldfile(fs_path):\n            sz_md += len(buf)\n            for c, v in [(b\"&\", 4), (b\"<\", 3), (b\">\", 3)]:\n                sz_md += (len(buf) - len(buf.replace(c, b\"\"))) * v\n\n        file_ts = int(max(ts_md, ts_html, self.E.t0))\n        file_lastmod, do_send = self._chk_lastmod(file_ts)\n        self.out_headers[\"Last-Modified\"] = file_lastmod\n        self.out_headers.update(NO_CACHE)\n        status = 200 if do_send else 304\n\n        arg_base = \"?\"\n        if \"k\" in self.uparam:\n            arg_base = \"?k={}&\".format(self.uparam[\"k\"])\n\n        boundary = \"\\roll\\tide\"\n        targs = {\n            \"r\": self.args.SR if self.is_vproxied else \"\",\n            \"ts\": self.conn.hsrv.cachebuster(),\n            \"svcname\": self.args.doctitle,\n            \"html_head\": self.html_head,\n            \"edit\": \"edit\" in self.uparam,\n            \"title\": html_escape(self.vpath, crlf=True),\n            \"lastmod\": int(ts_md * 1000),\n            \"lang\": self.args.lang,\n            \"favico\": self.args.favico,\n            \"have_emp\": self.args.emp,\n            \"md_chk_rate\": self.args.mcr,\n            \"md\": boundary,\n            \"arg_base\": arg_base,\n        }\n        zs = template.render(**targs).encode(\"utf-8\", \"replace\")\n        html = zs.split(boundary.encode(\"utf-8\"))\n        if len(html) != 2:\n            raise Exception(\"boundary appears in \" + html_path)\n\n        self.send_headers(sz_md + len(html[0]) + len(html[1]), status)\n\n        logmsg += unicode(status)\n        if self.mode == \"HEAD\" or not do_send:\n            if self.do_log:\n                self.log(logmsg)\n\n            return True\n\n        try:\n            self.s.sendall(html[0])\n            for buf in yieldfile(fs_path):\n                self.s.sendall(html_bescape(buf))\n\n            self.s.sendall(html[1])\n\n        except:\n            self.log(logmsg + \" \\033[31md/c\\033[0m\")\n            return False\n\n        if self.do_log:\n            self.log(logmsg + \" \" + unicode(len(html)))\n\n        return True\n\n    def tx_svcs(self) -> bool:\n        aname = re.sub(\"[^0-9a-zA-Z]+\", \"\", self.args.name) or \"a\"\n        ep = self.host\n        host = ep.split(\":\")[0]\n        hport = ep[ep.find(\":\") :] if \":\" in ep else \"\"\n        rip = (\n            host\n            if self.args.rclone_mdns or not self.args.zm\n            else self.conn.hsrv.nm.map(self.ip) or host\n        )\n        vp = (self.uparam[\"hc\"] or \"\").lstrip(\"/\")\n        html = self.j2s(\n            \"svcs\",\n            args=self.args,\n            accs=bool(self.asrv.acct),\n            s=\"s\" if self.is_https else \"\",\n            rip=rip,\n            ep=ep,\n            vp=vp,\n            rvp=vjoin(self.args.R, vp),\n            host=host,\n            hport=hport,\n            aname=aname,\n            pw=self.pw or \"pw\",\n        )\n        self.reply(html.encode(\"utf-8\"))\n        return True\n\n    def tx_mounts(self) -> bool:\n        suf = self.urlq({}, [\"h\"])\n        avol = [x for x in self.wvol if x in self.rvol]\n        rvol, wvol, avol = [\n            [(\"/\" + x).rstrip(\"/\") + \"/\" for x in y]\n            for y in [self.rvol, self.wvol, avol]\n        ]\n\n        if avol and not self.args.no_rescan:\n            x = self.conn.hsrv.broker.ask(\"up2k.get_state\")\n            vs = json.loads(x.get())\n            vstate = {(\"/\" + k).rstrip(\"/\") + \"/\": v for k, v in vs[\"volstate\"].items()}\n        else:\n            vstate = {}\n            vs = {\n                \"scanning\": None,\n                \"hashq\": None,\n                \"tagq\": None,\n                \"mtpq\": None,\n                \"dbwt\": None,\n            }\n\n        fmt = self.uparam.get(\"ls\", \"\")\n        if not fmt and (self.ua.startswith(\"curl/\") or self.ua.startswith(\"fetch\")):\n            fmt = \"v\"\n\n        if fmt in [\"v\", \"t\", \"txt\"]:\n            if self.uname == \"*\":\n                txt = \"howdy stranger (you're not logged in)\"\n            else:\n                txt = \"welcome back {}\".format(self.uname)\n\n            if vstate:\n                txt += \"\\nstatus:\"\n                for k in [\"scanning\", \"hashq\", \"tagq\", \"mtpq\", \"dbwt\"]:\n                    txt += \" {}({})\".format(k, vs[k])\n\n            if rvol:\n                txt += \"\\nyou can browse:\"\n                for v in rvol:\n                    txt += \"\\n  \" + v\n\n            if wvol:\n                txt += \"\\nyou can upload to:\"\n                for v in wvol:\n                    txt += \"\\n  \" + v\n\n            zb = txt.encode(\"utf-8\", \"replace\") + b\"\\n\"\n            self.reply(zb, mime=\"text/plain; charset=utf-8\")\n            return True\n\n        html = self.j2s(\n            \"splash\",\n            this=self,\n            qvpath=quotep(self.vpath),\n            rvol=rvol,\n            wvol=wvol,\n            avol=avol,\n            vstate=vstate,\n            scanning=vs[\"scanning\"],\n            hashq=vs[\"hashq\"],\n            tagq=vs[\"tagq\"],\n            mtpq=vs[\"mtpq\"],\n            dbwt=vs[\"dbwt\"],\n            url_suf=suf,\n            k304=self.k304(),\n            ver=S_VERSION if self.args.ver else \"\",\n            ahttps=\"\" if self.is_https else \"https://\" + self.host + self.req,\n        )\n        self.reply(html.encode(\"utf-8\"))\n        return True\n\n    def set_k304(self) -> bool:\n        ck = gencookie(\"k304\", self.uparam[\"k304\"], self.args.R, False, 86400 * 299)\n        self.out_headerlist.append((\"Set-Cookie\", ck))\n        self.redirect(\"\", \"?h#cc\")\n        return True\n\n    def setck(self) -> bool:\n        k, v = self.uparam[\"setck\"].split(\"=\", 1)\n        t = None if v == \"\" else 86400 * 299\n        ck = gencookie(k, v, self.args.R, False, t)\n        self.out_headerlist.append((\"Set-Cookie\", ck))\n        self.reply(b\"o7\\n\")\n        return True\n\n    def set_cfg_reset(self) -> bool:\n        for k in (\"k304\", \"js\", \"idxh\", \"cppwd\", \"cppws\"):\n            cookie = gencookie(k, \"x\", self.args.R, False, None)\n            self.out_headerlist.append((\"Set-Cookie\", cookie))\n\n        self.redirect(\"\", \"?h#cc\")\n        return True\n\n    def tx_404(self, is_403: bool = False) -> bool:\n        rc = 404\n        if self.args.vague_403:\n            t = '<h1 id=\"n\">404 not found &nbsp;\u2510( \u00b4 -`)\u250c</h1><p id=\"o\">or maybe you don\\'t have access -- try logging in or <a href=\"{}/?h\">go home</a></p>'\n        elif is_403:\n            t = '<h1 id=\"p\">403 forbiddena &nbsp;~\u253b\u2501\u253b</h1><p id=\"q\">you\\'ll have to log in or <a href=\"{}/?h\">go home</a></p>'\n            rc = 403\n        else:\n            t = '<h1 id=\"n\">404 not found &nbsp;\u2510( \u00b4 -`)\u250c</h1><p><a id=\"r\" href=\"{}/?h\">go home</a></p>'\n\n        t = t.format(self.args.SR)\n        html = self.j2s(\"splash\", this=self, qvpath=quotep(self.vpath), msg=t)\n        self.reply(html.encode(\"utf-8\"), status=rc)\n        return True\n\n    def on40x(self, mods: list[str], vn: VFS, rem: str) -> str:\n        for mpath in mods:\n            try:\n                mod = loadpy(mpath, self.args.hot_handlers)\n            except Exception as ex:\n                self.log(\"import failed: {!r}\".format(ex))\n                continue\n\n            ret = mod.main(self, vn, rem)\n            if ret:\n                return ret.lower()\n\n        return \"\"  # unhandled / fallthrough\n\n    def scanvol(self) -> bool:\n        if not self.can_read or not self.can_write:\n            raise Pebkac(403, \"not allowed for user \" + self.uname)\n\n        if self.args.no_rescan:\n            raise Pebkac(403, \"the rescan feature is disabled in server config\")\n\n        vn, _ = self.asrv.vfs.get(self.vpath, self.uname, True, True)\n\n        args = [self.asrv.vfs.all_vols, [vn.vpath], False, True]\n\n        x = self.conn.hsrv.broker.ask(\"up2k.rescan\", *args)\n        err = x.get()\n        if not err:\n            self.redirect(\"\", \"?h\")\n            return True\n\n        raise Pebkac(500, err)\n\n    def handle_reload(self) -> bool:\n        act = self.uparam.get(\"reload\")\n        if act != \"cfg\":\n            raise Pebkac(400, \"only config files ('cfg') can be reloaded rn\")\n\n        if not [x for x in self.wvol if x in self.rvol]:\n            raise Pebkac(403, \"not allowed for user \" + self.uname)\n\n        if self.args.no_reload:\n            raise Pebkac(403, \"the reload feature is disabled in server config\")\n\n        x = self.conn.hsrv.broker.ask(\"reload\")\n        return self.redirect(\"\", \"?h\", x.get(), \"return to\", False)\n\n    def tx_stack(self) -> bool:\n        if not [x for x in self.wvol if x in self.rvol]:\n            raise Pebkac(403, \"not allowed for user \" + self.uname)\n\n        if self.args.no_stack:\n            raise Pebkac(403, \"the stackdump feature is disabled in server config\")\n\n        ret = \"<pre>{}\\n{}\".format(time.time(), html_escape(alltrace()))\n        self.reply(ret.encode(\"utf-8\"))\n        return True\n\n    def tx_tree(self) -> bool:\n        top = self.uparam[\"tree\"] or \"\"\n        dst = self.vpath\n        if top in [\".\", \"..\"]:\n            top = undot(self.vpath + \"/\" + top)\n\n        if top == dst:\n            dst = \"\"\n        elif top:\n            if not dst.startswith(top + \"/\"):\n                raise Pebkac(400, \"arg funk\")\n\n            dst = dst[len(top) + 1 :]\n\n        ret = self.gen_tree(top, dst)\n        if self.is_vproxied:\n            parents = self.args.R.split(\"/\")\n            for parent in reversed(parents):\n                ret = {\"k%s\" % (parent,): ret, \"a\": []}\n\n        zs = json.dumps(ret)\n        self.reply(zs.encode(\"utf-8\"), mime=\"application/json\")\n        return True\n\n    def gen_tree(self, top: str, target: str) -> dict[str, Any]:\n        ret: dict[str, Any] = {}\n        excl = None\n        if target:\n            excl, target = (target.split(\"/\", 1) + [\"\"])[:2]\n            sub = self.gen_tree(\"/\".join([top, excl]).strip(\"/\"), target)\n            ret[\"k\" + quotep(excl)] = sub\n\n        try:\n            vn, rem = self.asrv.vfs.get(top, self.uname, True, False)\n            fsroot, vfs_ls, vfs_virt = vn.ls(\n                rem,\n                self.uname,\n                not self.args.no_scandir,\n                [[True, False], [False, True]],\n            )\n        except:\n            vfs_ls = []\n            vfs_virt = {}\n            for v in self.rvol:\n                d1, d2 = v.rsplit(\"/\", 1) if \"/\" in v else [\"\", v]\n                if d1 == top:\n                    vfs_virt[d2] = self.asrv.vfs  # typechk, value never read\n\n        dirs = []\n\n        dirnames = [x[0] for x in vfs_ls if stat.S_ISDIR(x[1].st_mode)]\n\n        if not self.args.ed or \"dots\" not in self.uparam:\n            dirnames = exclude_dotfiles(dirnames)\n\n        for fn in [x for x in dirnames if x != excl]:\n            dirs.append(quotep(fn))\n\n        for x in vfs_virt:\n            if x != excl:\n                dirs.append(x)\n\n        ret[\"a\"] = dirs\n        return ret\n\n    def tx_ups(self) -> bool:\n        if not self.args.unpost:\n            raise Pebkac(403, \"the unpost feature is disabled in server config\")\n\n        idx = self.conn.get_u2idx()\n        if not idx or not hasattr(idx, \"p_end\"):\n            raise Pebkac(500, \"sqlite3 is not available on the server; cannot unpost\")\n\n        filt = self.uparam.get(\"filter\")\n        filt = unquotep(filt or \"\")\n        lm = \"ups [{}]\".format(filt)\n        self.log(lm)\n\n        ret: list[dict[str, Any]] = []\n        t0 = time.time()\n        lim = time.time() - self.args.unpost\n        fk_vols = {\n            vol: vol.flags[\"fk\"]\n            for vp, vol in self.asrv.vfs.all_vols.items()\n            if \"fk\" in vol.flags and (vp in self.rvol or vp in self.upvol)\n        }\n        for vol in self.asrv.vfs.all_vols.values():\n            cur = idx.get_cur(vol.realpath)\n            if not cur:\n                continue\n\n            nfk = fk_vols.get(vol, 0)\n\n            q = \"select sz, rd, fn, at from up where ip=? and at>?\"\n            for sz, rd, fn, at in cur.execute(q, (self.ip, lim)):\n                vp = \"/\" + \"/\".join(x for x in [vol.vpath, rd, fn] if x)\n                if filt and filt not in vp:\n                    continue\n\n                rv = {\"vp\": quotep(vp), \"sz\": sz, \"at\": at, \"nfk\": nfk}\n                if nfk:\n                    rv[\"ap\"] = vol.canonical(vjoin(rd, fn))\n\n                ret.append(rv)\n                if len(ret) > 3000:\n                    ret.sort(key=lambda x: x[\"at\"], reverse=True)  # type: ignore\n                    ret = ret[:2000]\n\n        ret.sort(key=lambda x: x[\"at\"], reverse=True)  # type: ignore\n        n = 0\n        for rv in ret[:11000]:\n            nfk = rv.pop(\"nfk\")\n            if not nfk:\n                continue\n\n            ap = rv.pop(\"ap\")\n            try:\n                st = bos.stat(ap)\n            except:\n                continue\n\n            fk = self.gen_fk(\n                self.args.fk_salt, ap, st.st_size, 0 if ANYWIN else st.st_ino\n            )\n            rv[\"vp\"] += \"?k=\" + fk[:nfk]\n\n            n += 1\n            if n > 2000:\n                break\n\n        ret = ret[:2000]\n\n        if self.is_vproxied:\n            for v in ret:\n                v[\"vp\"] = self.args.SR + v[\"vp\"]\n\n        jtxt = json.dumps(ret, indent=2, sort_keys=True).encode(\"utf-8\", \"replace\")\n        self.log(\"{} #{} {:.2f}sec\".format(lm, len(ret), time.time() - t0))\n        self.reply(jtxt, mime=\"application/json\")\n        return True\n\n    def handle_rm(self, req: list[str]) -> bool:\n        if not req and not self.can_delete:\n            raise Pebkac(403, \"not allowed for user \" + self.uname)\n\n        if self.args.no_del:\n            raise Pebkac(403, \"the delete feature is disabled in server config\")\n\n        if not req:\n            req = [self.vpath]\n        elif self.is_vproxied:\n            req = [x[len(self.args.SR) :] for x in req]\n\n        nlim = int(self.uparam.get(\"lim\") or 0)\n        lim = [nlim, nlim] if nlim else []\n\n        x = self.conn.hsrv.broker.ask(\n            \"up2k.handle_rm\", self.uname, self.ip, req, lim, False\n        )\n        self.loud_reply(x.get())\n        return True\n\n    def handle_mv(self) -> bool:\n        # full path of new loc (incl filename)\n        dst = self.uparam.get(\"move\")\n\n        if self.is_vproxied and dst and dst.startswith(self.args.SR):\n            dst = dst[len(self.args.RS) :]\n\n        if not dst:\n            raise Pebkac(400, \"need dst vpath\")\n\n        # x-www-form-urlencoded (url query part) uses\n        # either + or %20 for 0x20 so handle both\n        dst = unquotep(dst.replace(\"+\", \" \"))\n        return self._mv(self.vpath, dst.lstrip(\"/\"))\n\n    def _mv(self, vsrc: str, vdst: str) -> bool:\n        if not self.can_move:\n            raise Pebkac(403, \"not allowed for user \" + self.uname)\n\n        if self.args.no_mv:\n            raise Pebkac(403, \"the rename/move feature is disabled in server config\")\n\n        x = self.conn.hsrv.broker.ask(\"up2k.handle_mv\", self.uname, vsrc, vdst)\n        self.loud_reply(x.get(), status=201)\n        return True\n\n    def tx_ls(self, ls: dict[str, Any]) -> bool:\n        dirs = ls[\"dirs\"]\n        files = ls[\"files\"]\n        arg = self.uparam[\"ls\"]\n        if arg in [\"v\", \"t\", \"txt\"]:\n            try:\n                biggest = max(ls[\"files\"] + ls[\"dirs\"], key=itemgetter(\"sz\"))[\"sz\"]\n            except:\n                biggest = 0\n\n            if arg == \"v\":\n                fmt = \"\\033[0;7;36m{{}}{{:>{}}}\\033[0m {{}}\"\n                nfmt = \"{}\"\n                biggest = 0\n                f2 = \"\".join(\n                    \"{}{{}}\".format(x)\n                    for x in [\n                        \"\\033[7m\",\n                        \"\\033[27m\",\n                        \"\",\n                        \"\\033[0;1m\",\n                        \"\\033[0;36m\",\n                        \"\\033[0m\",\n                    ]\n                )\n                ctab = {\"B\": 6, \"K\": 5, \"M\": 1, \"G\": 3}\n                for lst in [dirs, files]:\n                    for x in lst:\n                        a = x[\"dt\"].replace(\"-\", \" \").replace(\":\", \" \").split(\" \")\n                        x[\"dt\"] = f2.format(*list(a))\n                        sz = humansize(x[\"sz\"], True)\n                        x[\"sz\"] = \"\\033[0;3{}m {:>5}\".format(ctab.get(sz[-1:], 0), sz)\n            else:\n                fmt = \"{{}}  {{:{},}}  {{}}\"\n                nfmt = \"{:,}\"\n\n            for x in dirs:\n                n = x[\"name\"] + \"/\"\n                if arg == \"v\":\n                    n = \"\\033[94m\" + n\n\n                x[\"name\"] = n\n\n            fmt = fmt.format(len(nfmt.format(biggest)))\n            retl = [\n                \"# {}: {}\".format(x, ls[x])\n                for x in [\"acct\", \"perms\", \"srvinf\"]\n                if x in ls\n            ]\n            retl += [\n                fmt.format(x[\"dt\"], x[\"sz\"], x[\"name\"])\n                for y in [dirs, files]\n                for x in y\n            ]\n            ret = \"\\n\".join(retl)\n            mime = \"text/plain; charset=utf-8\"\n        else:\n            [x.pop(k) for k in [\"name\", \"dt\"] for y in [dirs, files] for x in y]\n\n            ret = json.dumps(ls)\n            mime = \"application/json\"\n\n        ret += \"\\n\\033[0m\" if arg == \"v\" else \"\\n\"\n        self.reply(ret.encode(\"utf-8\", \"replace\"), mime=mime)\n        return True\n\n    def tx_browser(self) -> bool:\n        vpath = \"\"\n        vpnodes = [[\"\", \"/\"]]\n        if self.vpath:\n            for node in self.vpath.split(\"/\"):\n                if not vpath:\n                    vpath = node\n                else:\n                    vpath += \"/\" + node\n\n                vpnodes.append([quotep(vpath) + \"/\", html_escape(node, crlf=True)])\n\n        vn = self.vn\n        rem = self.rem\n        abspath = vn.dcanonical(rem)\n        dbv, vrem = vn.get_dbv(rem)\n\n        try:\n            st = bos.stat(abspath)\n        except:\n            if \"on404\" not in vn.flags:\n                return self.tx_404()\n\n            ret = self.on40x(vn.flags[\"on404\"], vn, rem)\n            if ret == \"true\":\n                return True\n            elif ret == \"false\":\n                return False\n            elif ret == \"retry\":\n                try:\n                    st = bos.stat(abspath)\n                except:\n                    return self.tx_404()\n            else:\n                return self.tx_404()\n\n        if rem.startswith(\".hist/up2k.\") or (\n            rem.endswith(\"/dir.txt\") and rem.startswith(\".hist/th/\")\n        ):\n            raise Pebkac(403)\n\n        e2d = \"e2d\" in vn.flags\n        e2t = \"e2t\" in vn.flags\n\n        self.html_head = vn.flags.get(\"html_head\", \"\")\n        if vn.flags.get(\"norobots\") or \"b\" in self.uparam:\n            self.out_headers[\"X-Robots-Tag\"] = \"noindex, nofollow\"\n        else:\n            self.out_headers.pop(\"X-Robots-Tag\", None)\n\n        is_dir = stat.S_ISDIR(st.st_mode)\n        icur = None\n        if is_dir and (e2t or e2d):\n            idx = self.conn.get_u2idx()\n            if idx and hasattr(idx, \"p_end\"):\n                icur = idx.get_cur(dbv.realpath)\n\n        if self.can_read:\n            th_fmt = self.uparam.get(\"th\")\n            if th_fmt is not None:\n                if is_dir:\n                    vrem = vrem.rstrip(\"/\")\n                    if icur and vrem:\n                        q = \"select fn from cv where rd=? and dn=?\"\n                        crd, cdn = vrem.rsplit(\"/\", 1) if \"/\" in vrem else (\"\", vrem)\n                        # no mojibake support:\n                        try:\n                            cfn = icur.execute(q, (crd, cdn)).fetchone()\n                            if cfn:\n                                fn = cfn[0]\n                                fp = os.path.join(abspath, fn)\n                                if bos.path.exists(fp):\n                                    vrem = \"{}/{}\".format(vrem, fn).strip(\"/\")\n                                    is_dir = False\n                        except:\n                            pass\n                    else:\n                        for fn in self.args.th_covers:\n                            fp = os.path.join(abspath, fn)\n                            if bos.path.exists(fp):\n                                vrem = \"{}/{}\".format(vrem, fn).strip(\"/\")\n                                is_dir = False\n                                break\n\n                    if is_dir:\n                        return self.tx_ico(\"a.folder\")\n\n                thp = None\n                if self.thumbcli:\n                    thp = self.thumbcli.get(dbv, vrem, int(st.st_mtime), th_fmt)\n\n                if thp:\n                    return self.tx_file(thp)\n\n                if th_fmt == \"p\":\n                    raise Pebkac(404)\n\n                return self.tx_ico(rem)\n\n        if not is_dir and (self.can_read or self.can_get):\n            if not self.can_read and \"fk\" in vn.flags:\n                correct = self.gen_fk(\n                    self.args.fk_salt, abspath, st.st_size, 0 if ANYWIN else st.st_ino\n                )[: vn.flags[\"fk\"]]\n                got = self.uparam.get(\"k\")\n                if got != correct:\n                    self.log(\"wrong filekey, want {}, got {}\".format(correct, got))\n                    return self.tx_404()\n\n            if (\n                abspath.endswith(\".md\")\n                and \"nohtml\" not in vn.flags\n                and (\n                    \"v\" in self.uparam\n                    or \"edit\" in self.uparam\n                    or \"edit2\" in self.uparam\n                )\n            ):\n                return self.tx_md(abspath)\n\n            return self.tx_file(abspath)\n\n        elif is_dir and not self.can_read and not self.can_write:\n            return self.tx_404(True)\n\n        srv_info = []\n\n        try:\n            if not self.args.nih:\n                srv_info.append(self.args.name)\n        except:\n            self.log(\"#wow #whoa\")\n\n        if not self.args.nid:\n            free, total = get_df(abspath)\n            if total is not None:\n                h1 = humansize(free or 0)\n                h2 = humansize(total)\n                srv_info.append(\"{} free of {}\".format(h1, h2))\n            elif free is not None:\n                srv_info.append(humansize(free, True) + \" free\")\n\n        srv_infot = \"</span> // <span>\".join(srv_info)\n\n        perms = []\n        if self.can_read:\n            perms.append(\"read\")\n        if self.can_write:\n            perms.append(\"write\")\n        if self.can_move:\n            perms.append(\"move\")\n        if self.can_delete:\n            perms.append(\"delete\")\n        if self.can_get:\n            perms.append(\"get\")\n        if self.can_upget:\n            perms.append(\"upget\")\n        if self.can_admin:\n            perms.append(\"admin\")\n\n        url_suf = self.urlq({}, [\"k\"])\n        is_ls = \"ls\" in self.uparam\n        is_js = self.args.force_js or self.cookies.get(\"js\") == \"y\"\n\n        if not is_ls and (self.ua.startswith(\"curl/\") or self.ua.startswith(\"fetch\")):\n            self.uparam[\"ls\"] = \"v\"\n            is_ls = True\n\n        tpl = \"browser\"\n        if \"b\" in self.uparam:\n            tpl = \"browser2\"\n            is_js = False\n\n        logues = [\"\", \"\"]\n        if not self.args.no_logues:\n            for n, fn in enumerate([\".prologue.html\", \".epilogue.html\"]):\n                fn = os.path.join(abspath, fn)\n                if bos.path.exists(fn):\n                    with open(fsenc(fn), \"rb\") as f:\n                        logues[n] = f.read().decode(\"utf-8\")\n\n        readme = \"\"\n        if not self.args.no_readme and not logues[1]:\n            for fn in [\"README.md\", \"readme.md\"]:\n                fn = os.path.join(abspath, fn)\n                if bos.path.isfile(fn):\n                    with open(fsenc(fn), \"rb\") as f:\n                        readme = f.read().decode(\"utf-8\")\n                        break\n\n        vf = vn.flags\n        unlist = vf.get(\"unlist\", \"\")\n        ls_ret = {\n            \"dirs\": [],\n            \"files\": [],\n            \"taglist\": [],\n            \"srvinf\": srv_infot,\n            \"acct\": self.uname,\n            \"idx\": e2d,\n            \"itag\": e2t,\n            \"lifetime\": vn.flags.get(\"lifetime\") or 0,\n            \"frand\": bool(vn.flags.get(\"rand\")),\n            \"unlist\": unlist,\n            \"perms\": perms,\n            \"logues\": logues,\n            \"readme\": readme,\n        }\n        j2a = {\n            \"vdir\": quotep(self.vpath),\n            \"vpnodes\": vpnodes,\n            \"files\": [],\n            \"ls0\": None,\n            \"acct\": self.uname,\n            \"perms\": json.dumps(perms),\n            \"lifetime\": ls_ret[\"lifetime\"],\n            \"frand\": bool(vn.flags.get(\"rand\")),\n            \"taglist\": [],\n            \"def_hcols\": [],\n            \"have_emp\": self.args.emp,\n            \"have_up2k_idx\": e2d,\n            \"have_tags_idx\": e2t,\n            \"have_acode\": (not self.args.no_acode),\n            \"have_mv\": (not self.args.no_mv),\n            \"have_del\": (not self.args.no_del),\n            \"have_zip\": (not self.args.no_zip),\n            \"have_unpost\": int(self.args.unpost),\n            \"have_b_u\": (self.can_write and self.uparam.get(\"b\") == \"u\"),\n            \"sb_md\": \"\" if \"no_sb_md\" in vf else (vf.get(\"md_sbf\") or \"y\"),\n            \"sb_lg\": \"\" if \"no_sb_lg\" in vf else (vf.get(\"lg_sbf\") or \"y\"),\n            \"url_suf\": url_suf,\n            \"logues\": logues,\n            \"readme\": readme,\n            \"title\": html_escape(self.vpath, crlf=True) or \"\ud83d\udcbe\ud83c\udf89\",\n            \"srv_info\": srv_infot,\n            \"dgrid\": \"grid\" in vf,\n            \"unlist\": unlist,\n            \"dtheme\": self.args.theme,\n            \"themes\": self.args.themes,\n            \"turbolvl\": self.args.turbo,\n            \"idxh\": int(self.args.ih),\n            \"u2sort\": self.args.u2sort,\n        }\n\n        if self.args.js_browser:\n            j2a[\"js\"] = self.args.js_browser\n\n        if self.args.css_browser:\n            j2a[\"css\"] = self.args.css_browser\n\n        if not self.conn.hsrv.prism:\n            j2a[\"no_prism\"] = True\n\n        if not self.can_read:\n            if is_ls:\n                return self.tx_ls(ls_ret)\n\n            if not stat.S_ISDIR(st.st_mode):\n                return self.tx_404(True)\n\n            if \"zip\" in self.uparam or \"tar\" in self.uparam:\n                raise Pebkac(403)\n\n            html = self.j2s(tpl, **j2a)\n            self.reply(html.encode(\"utf-8\", \"replace\"))\n            return True\n\n        for k in [\"zip\", \"tar\"]:\n            v = self.uparam.get(k)\n            if v is not None:\n                return self.tx_zip(k, v, self.vpath, vn, rem, [], self.args.ed)\n\n        fsroot, vfs_ls, vfs_virt = vn.ls(\n            rem,\n            self.uname,\n            not self.args.no_scandir,\n            [[True, False], [False, True]],\n            lstat=\"lt\" in self.uparam,\n        )\n        stats = {k: v for k, v in vfs_ls}\n        ls_names = [x[0] for x in vfs_ls]\n        ls_names.extend(list(vfs_virt.keys()))\n\n        # check for old versions of files,\n        # [num-backups, most-recent, hist-path]\n        hist: dict[str, tuple[int, float, str]] = {}\n        histdir = os.path.join(fsroot, \".hist\")\n        ptn = re.compile(r\"(.*)\\.([0-9]+\\.[0-9]{3})(\\.[^\\.]+)$\")\n        try:\n            for hfn in bos.listdir(histdir):\n                m = ptn.match(hfn)\n                if not m:\n                    continue\n\n                fn = m.group(1) + m.group(3)\n                n, ts, _ = hist.get(fn, (0, 0, \"\"))\n                hist[fn] = (n + 1, max(ts, float(m.group(2))), hfn)\n        except:\n            pass\n\n        # show dotfiles if permitted and requested\n        if not self.args.ed or \"dots\" not in self.uparam:\n            ls_names = exclude_dotfiles(ls_names)\n\n        add_fk = vn.flags.get(\"fk\")\n\n        dirs = []\n        files = []\n        for fn in ls_names:\n            base = \"\"\n            href = fn\n            if not is_ls and not is_js and not self.trailing_slash and vpath:\n                base = \"/\" + vpath + \"/\"\n                href = base + fn\n\n            if fn in vfs_virt:\n                fspath = vfs_virt[fn].realpath\n            else:\n                fspath = fsroot + \"/\" + fn\n\n            try:\n                linf = stats.get(fn) or bos.lstat(fspath)\n                inf = bos.stat(fspath) if stat.S_ISLNK(linf.st_mode) else linf\n            except:\n                self.log(\"broken symlink: {}\".format(repr(fspath)))\n                continue\n\n            is_dir = stat.S_ISDIR(inf.st_mode)\n            if is_dir:\n                href += \"/\"\n                if self.args.no_zip:\n                    margin = \"DIR\"\n                else:\n                    margin = '<a href=\"%s?zip\" rel=\"nofollow\">zip</a>' % (quotep(href),)\n            elif fn in hist:\n                margin = '<a href=\"%s.hist/%s\">#%s</a>' % (\n                    base,\n                    html_escape(hist[fn][2], quot=True, crlf=True),\n                    hist[fn][0],\n                )\n            else:\n                margin = \"-\"\n\n            sz = inf.st_size\n            zd = datetime.utcfromtimestamp(linf.st_mtime)\n            dt = \"%04d-%02d-%02d %02d:%02d:%02d\" % (\n                zd.year,\n                zd.month,\n                zd.day,\n                zd.hour,\n                zd.minute,\n                zd.second,\n            )\n\n            try:\n                ext = \"---\" if is_dir else fn.rsplit(\".\", 1)[1]\n                if len(ext) > 16:\n                    ext = ext[:16]\n            except:\n                ext = \"%\"\n\n            if add_fk:\n                href = \"%s?k=%s\" % (\n                    quotep(href),\n                    self.gen_fk(\n                        self.args.fk_salt, fspath, sz, 0 if ANYWIN else inf.st_ino\n                    )[:add_fk],\n                )\n            else:\n                href = quotep(href)\n\n            item = {\n                \"lead\": margin,\n                \"href\": href,\n                \"name\": fn,\n                \"sz\": sz,\n                \"ext\": ext,\n                \"dt\": dt,\n                \"ts\": int(linf.st_mtime),\n            }\n            if is_dir:\n                dirs.append(item)\n            else:\n                files.append(item)\n                item[\"rd\"] = rem\n\n        if (\n            self.cookies.get(\"idxh\") == \"y\"\n            and \"ls\" not in self.uparam\n            and \"v\" not in self.uparam\n        ):\n            idx_html = set([\"index.htm\", \"index.html\"])\n            for item in files:\n                if item[\"name\"] in idx_html:\n                    # do full resolve in case of shadowed file\n                    vp = vjoin(self.vpath.split(\"?\")[0], item[\"name\"])\n                    vn, rem = self.asrv.vfs.get(vp, self.uname, True, False)\n                    ap = vn.canonical(rem)\n                    return self.tx_file(ap)  # is no-cache\n\n        tagset: set[str] = set()\n        for fe in files:\n            fn = fe[\"name\"]\n            rd = fe[\"rd\"]\n            del fe[\"rd\"]\n            if not icur:\n                continue\n\n            if vn != dbv:\n                _, rd = vn.get_dbv(rd)\n\n            erd_efn = (rd, fn)\n            q = \"select mt.k, mt.v from up inner join mt on mt.w = substr(up.w,1,16) where up.rd = ? and up.fn = ? and +mt.k != 'x'\"\n            try:\n                r = icur.execute(q, erd_efn)\n            except Exception as ex:\n                if \"database is locked\" in str(ex):\n                    break\n\n                try:\n                    erd_efn = s3enc(idx.mem_cur, rd, fn)\n                    r = icur.execute(q, erd_efn)\n                except:\n                    t = \"tag read error, {}/{}\\n{}\"\n                    self.log(t.format(rd, fn, min_ex()))\n                    break\n\n            fe[\"tags\"] = {k: v for k, v in r}\n\n            if self.can_admin:\n                q = \"select ip, at from up where rd=? and fn=?\"\n                try:\n                    zs1, zs2 = icur.execute(q, erd_efn).fetchone()\n                    fe[\"tags\"][\"up_ip\"] = zs1\n                    fe[\"tags\"][\".up_at\"] = zs2\n                except:\n                    pass\n\n            _ = [tagset.add(k) for k in fe[\"tags\"]]\n\n        if icur:\n            taglist = [k for k in vn.flags.get(\"mte\", \"\").split(\",\") if k in tagset]\n            for fe in dirs:\n                fe[\"tags\"] = {}\n        else:\n            taglist = list(tagset)\n\n        if is_ls:\n            ls_ret[\"dirs\"] = dirs\n            ls_ret[\"files\"] = files\n            ls_ret[\"taglist\"] = taglist\n            return self.tx_ls(ls_ret)\n\n        doc = self.uparam.get(\"doc\") if self.can_read else None\n        if doc:\n            doc = unquotep(doc.replace(\"+\", \" \").split(\"?\")[0])\n            j2a[\"docname\"] = doc\n            doctxt = None\n            if next((x for x in files if x[\"name\"] == doc), None):\n                docpath = os.path.join(abspath, doc)\n                sz = bos.path.getsize(docpath)\n                if sz < 1024 * self.args.txt_max:\n                    with open(fsenc(docpath), \"rb\") as f:\n                        doctxt = f.read().decode(\"utf-8\", \"replace\")\n            else:\n                self.log(\"doc 404: [{}]\".format(doc), c=6)\n                doctxt = \"( textfile not found )\"\n\n            if doctxt is not None:\n                j2a[\"doc\"] = doctxt\n\n        for d in dirs:\n            d[\"name\"] += \"/\"\n\n        dirs.sort(key=itemgetter(\"name\"))\n\n        if is_js:\n            j2a[\"ls0\"] = {\n                \"dirs\": dirs,\n                \"files\": files,\n                \"taglist\": taglist,\n                \"unlist\": unlist,\n            }\n            j2a[\"files\"] = []\n        else:\n            j2a[\"files\"] = dirs + files\n\n        j2a[\"taglist\"] = taglist\n        j2a[\"txt_ext\"] = self.args.textfiles.replace(\",\", \" \")\n\n        if \"mth\" in vn.flags:\n            j2a[\"def_hcols\"] = vn.flags[\"mth\"].split(\",\")\n\n        html = self.j2s(tpl, **j2a)\n        self.reply(html.encode(\"utf-8\", \"replace\"))\n        return True\n"], "fixing_code": ["# coding: utf-8\nfrom __future__ import print_function, unicode_literals\n\nimport argparse  # typechk\nimport base64\nimport calendar\nimport copy\nimport errno\nimport gzip\nimport itertools\nimport json\nimport os\nimport random\nimport re\nimport stat\nimport string\nimport threading  # typechk\nimport time\nimport uuid\nfrom datetime import datetime\nfrom email.utils import formatdate, parsedate\nfrom operator import itemgetter\n\nimport jinja2  # typechk\n\ntry:\n    import lzma\nexcept:\n    pass\n\nfrom .__init__ import ANYWIN, PY2, TYPE_CHECKING, EnvParams, unicode\nfrom .__version__ import S_VERSION\nfrom .authsrv import VFS  # typechk\nfrom .bos import bos\nfrom .star import StreamTar\nfrom .sutil import StreamArc  # typechk\nfrom .szip import StreamZip\nfrom .util import (\n    HTTPCODE,\n    META_NOBOTS,\n    MultipartParser,\n    Pebkac,\n    UnrecvEOF,\n    alltrace,\n    absreal,\n    atomic_move,\n    exclude_dotfiles,\n    fsenc,\n    gen_filekey,\n    gen_filekey_dbg,\n    gencookie,\n    get_df,\n    get_spd,\n    guess_mime,\n    gzip_orig_sz,\n    hashcopy,\n    hidedir,\n    html_bescape,\n    html_escape,\n    humansize,\n    ipnorm,\n    loadpy,\n    min_ex,\n    quotep,\n    rand_name,\n    read_header,\n    read_socket,\n    read_socket_chunked,\n    read_socket_unbounded,\n    relchk,\n    ren_open,\n    runhook,\n    s3enc,\n    sanitize_fn,\n    sendfile_kern,\n    sendfile_py,\n    undot,\n    unescape_cookie,\n    unquote,\n    unquotep,\n    vjoin,\n    vol_san,\n    vsplit,\n    yieldfile,\n)\n\nif True:  # pylint: disable=using-constant-test\n    import typing\n    from typing import Any, Generator, Match, Optional, Pattern, Type, Union\n\nif TYPE_CHECKING:\n    from .httpconn import HttpConn\n\n_ = (argparse, threading)\n\nNO_CACHE = {\"Cache-Control\": \"no-cache\"}\n\n\nclass HttpCli(object):\n    \"\"\"\n    Spawned by HttpConn to process one http transaction\n    \"\"\"\n\n    def __init__(self, conn: \"HttpConn\") -> None:\n        assert conn.sr\n\n        self.t0 = time.time()\n        self.conn = conn\n        self.mutex = conn.mutex  # mypy404\n        self.s = conn.s\n        self.sr = conn.sr\n        self.ip = conn.addr[0]\n        self.addr: tuple[str, int] = conn.addr\n        self.args = conn.args  # mypy404\n        self.E: EnvParams = self.args.E\n        self.asrv = conn.asrv  # mypy404\n        self.ico = conn.ico  # mypy404\n        self.thumbcli = conn.thumbcli  # mypy404\n        self.u2fh = conn.u2fh  # mypy404\n        self.log_func = conn.log_func  # mypy404\n        self.log_src = conn.log_src  # mypy404\n        self.gen_fk = self._gen_fk if self.args.log_fk else gen_filekey\n        self.tls: bool = hasattr(self.s, \"cipher\")\n\n        # placeholders; assigned by run()\n        self.keepalive = False\n        self.is_https = False\n        self.is_vproxied = False\n        self.in_hdr_recv = True\n        self.headers: dict[str, str] = {}\n        self.mode = \" \"\n        self.req = \" \"\n        self.http_ver = \" \"\n        self.host = \" \"\n        self.ua = \" \"\n        self.is_rclone = False\n        self.ouparam: dict[str, str] = {}\n        self.uparam: dict[str, str] = {}\n        self.cookies: dict[str, str] = {}\n        self.avn: Optional[VFS] = None\n        self.vn = self.asrv.vfs\n        self.rem = \" \"\n        self.vpath = \" \"\n        self.uname = \" \"\n        self.pw = \" \"\n        self.rvol = [\" \"]\n        self.wvol = [\" \"]\n        self.mvol = [\" \"]\n        self.dvol = [\" \"]\n        self.gvol = [\" \"]\n        self.upvol = [\" \"]\n        self.do_log = True\n        self.can_read = False\n        self.can_write = False\n        self.can_move = False\n        self.can_delete = False\n        self.can_get = False\n        self.can_upget = False\n        self.can_admin = False\n        # post\n        self.parser: Optional[MultipartParser] = None\n        # end placeholders\n\n        self.bufsz = 1024 * 32\n        self.hint = \"\"\n        self.trailing_slash = True\n        self.out_headerlist: list[tuple[str, str]] = []\n        self.out_headers = {\n            \"Vary\": \"Origin, PW, Cookie\",\n            \"Cache-Control\": \"no-store, max-age=0\",\n        }\n        h = self.args.html_head\n        if self.args.no_robots:\n            h = META_NOBOTS + ((\"\\n\" + h) if h else \"\")\n            self.out_headers[\"X-Robots-Tag\"] = \"noindex, nofollow\"\n        self.html_head = h\n\n    def log(self, msg: str, c: Union[int, str] = 0) -> None:\n        ptn = self.asrv.re_pwd\n        if ptn and ptn.search(msg):\n            if self.asrv.ah.on:\n                msg = ptn.sub(\"\\033[7m pw \\033[27m\", msg)\n            else:\n                msg = ptn.sub(self.unpwd, msg)\n\n        self.log_func(self.log_src, msg, c)\n\n    def unpwd(self, m: Match[str]) -> str:\n        a, b, c = m.groups()\n        return \"{}\\033[7m {} \\033[27m{}\".format(a, self.asrv.iacct[b], c)\n\n    def _check_nonfatal(self, ex: Pebkac, post: bool) -> bool:\n        if post:\n            return ex.code < 300\n\n        return ex.code < 400 or ex.code in [404, 429]\n\n    def _assert_safe_rem(self, rem: str) -> None:\n        # sanity check to prevent any disasters\n        if rem.startswith(\"/\") or rem.startswith(\"../\") or \"/../\" in rem:\n            raise Exception(\"that was close\")\n\n    def _gen_fk(self, salt: str, fspath: str, fsize: int, inode: int) -> str:\n        return gen_filekey_dbg(salt, fspath, fsize, inode, self.log, self.args.log_fk)\n\n    def j2s(self, name: str, **ka: Any) -> str:\n        tpl = self.conn.hsrv.j2[name]\n        ka[\"r\"] = self.args.SR if self.is_vproxied else \"\"\n        ka[\"ts\"] = self.conn.hsrv.cachebuster()\n        ka[\"lang\"] = self.args.lang\n        ka[\"favico\"] = self.args.favico\n        ka[\"svcname\"] = self.args.doctitle\n        ka[\"html_head\"] = self.html_head\n        return tpl.render(**ka)  # type: ignore\n\n    def j2j(self, name: str) -> jinja2.Template:\n        return self.conn.hsrv.j2[name]\n\n    def run(self) -> bool:\n        \"\"\"returns true if connection can be reused\"\"\"\n        self.keepalive = False\n        self.is_https = False\n        self.headers = {}\n        self.hint = \"\"\n\n        if self.is_banned():\n            return False\n\n        try:\n            self.s.settimeout(2)\n            headerlines = read_header(self.sr, self.args.s_thead, self.args.s_thead)\n            self.in_hdr_recv = False\n            if not headerlines:\n                return False\n\n            if not headerlines[0]:\n                # seen after login with IE6.0.2900.5512.xpsp.080413-2111 (xp-sp3)\n                self.log(\"BUG: trailing newline from previous request\", c=\"1;31\")\n                headerlines.pop(0)\n\n            try:\n                self.mode, self.req, self.http_ver = headerlines[0].split(\" \")\n\n                # normalize incoming headers to lowercase;\n                # outgoing headers however are Correct-Case\n                for header_line in headerlines[1:]:\n                    k, zs = header_line.split(\":\", 1)\n                    self.headers[k.lower()] = zs.strip()\n            except:\n                msg = \" ]\\n#[ \".join(headerlines)\n                raise Pebkac(400, \"bad headers:\\n#[ \" + msg + \" ]\")\n\n        except Pebkac as ex:\n            self.mode = \"GET\"\n            self.req = \"[junk]\"\n            self.http_ver = \"HTTP/1.1\"\n            # self.log(\"pebkac at httpcli.run #1: \" + repr(ex))\n            self.keepalive = False\n            h = {\"WWW-Authenticate\": 'Basic realm=\"a\"'} if ex.code == 401 else {}\n            try:\n                self.loud_reply(unicode(ex), status=ex.code, headers=h, volsan=True)\n                return self.keepalive\n            except:\n                return False\n\n        self.ua = self.headers.get(\"user-agent\", \"\")\n        self.is_rclone = self.ua.startswith(\"rclone/\")\n\n        zs = self.headers.get(\"connection\", \"\").lower()\n        self.keepalive = \"close\" not in zs and (\n            self.http_ver != \"HTTP/1.0\" or zs == \"keep-alive\"\n        )\n        self.is_https = (\n            self.headers.get(\"x-forwarded-proto\", \"\").lower() == \"https\" or self.tls\n        )\n        self.host = self.headers.get(\"host\") or \"\"\n        if not self.host:\n            zs = \"%s:%s\" % self.s.getsockname()[:2]\n            self.host = zs[7:] if zs.startswith(\"::ffff:\") else zs\n\n        n = self.args.rproxy\n        if n:\n            zso = self.headers.get(\"x-forwarded-for\")\n            if zso and self.conn.addr[0] in [\"127.0.0.1\", \"::1\"]:\n                if n > 0:\n                    n -= 1\n\n                zsl = zso.split(\",\")\n                try:\n                    self.ip = zsl[n].strip()\n                except:\n                    self.ip = zsl[0].strip()\n                    t = \"rproxy={} oob x-fwd {}\"\n                    self.log(t.format(self.args.rproxy, zso), c=3)\n\n                self.log_src = self.conn.set_rproxy(self.ip)\n                self.is_vproxied = bool(self.args.R)\n                self.host = self.headers.get(\"x-forwarded-host\") or self.host\n\n        if self.is_banned():\n            return False\n\n        if self.conn.aclose:\n            nka = self.conn.aclose\n            ip = ipnorm(self.ip)\n            if ip in nka:\n                rt = nka[ip] - time.time()\n                if rt < 0:\n                    self.log(\"client uncapped\", 3)\n                    del nka[ip]\n                else:\n                    self.keepalive = False\n\n        ptn: Optional[Pattern[str]] = self.conn.lf_url  # mypy404\n        self.do_log = not ptn or not ptn.search(self.req)\n\n        if self.args.ihead and self.do_log:\n            keys = self.args.ihead\n            if \"*\" in keys:\n                keys = list(sorted(self.headers.keys()))\n\n            for k in keys:\n                zso = self.headers.get(k)\n                if zso is not None:\n                    self.log(\"[H] {}: \\033[33m[{}]\".format(k, zso), 6)\n\n        if \"&\" in self.req and \"?\" not in self.req:\n            self.hint = \"did you mean '?' instead of '&'\"\n\n        # split req into vpath + uparam\n        uparam = {}\n        if \"?\" not in self.req:\n            self.trailing_slash = self.req.endswith(\"/\")\n            vpath = undot(self.req)\n        else:\n            vpath, arglist = self.req.split(\"?\", 1)\n            self.trailing_slash = vpath.endswith(\"/\")\n            vpath = undot(vpath)\n            for k in arglist.split(\"&\"):\n                if \"=\" in k:\n                    k, zs = k.split(\"=\", 1)\n                    uparam[k.lower()] = unquotep(zs.strip().replace(\"+\", \" \"))\n                else:\n                    uparam[k.lower()] = \"\"\n\n        if self.is_vproxied:\n            if vpath.startswith(self.args.R):\n                vpath = vpath[len(self.args.R) + 1 :]\n            else:\n                t = \"incorrect --rp-loc or webserver config; expected vpath starting with [{}] but got [{}]\"\n                self.log(t.format(self.args.R, vpath), 1)\n\n        self.ouparam = {k: zs for k, zs in uparam.items()}\n\n        if self.args.rsp_slp:\n            time.sleep(self.args.rsp_slp)\n            if self.args.rsp_jtr:\n                time.sleep(random.random() * self.args.rsp_jtr)\n\n        zso = self.headers.get(\"cookie\")\n        if zso:\n            zsll = [x.split(\"=\", 1) for x in zso.split(\";\") if \"=\" in x]\n            cookies = {k.strip(): unescape_cookie(zs) for k, zs in zsll}\n            cookie_pw = cookies.get(\"cppws\") or cookies.get(\"cppwd\") or \"\"\n            if \"b\" in cookies and \"b\" not in uparam:\n                uparam[\"b\"] = cookies[\"b\"]\n        else:\n            cookies = {}\n            cookie_pw = \"\"\n\n        if len(uparam) > 10 or len(cookies) > 50:\n            raise Pebkac(400, \"u wot m8\")\n\n        self.uparam = uparam\n        self.cookies = cookies\n        self.vpath = unquotep(vpath)  # not query, so + means +\n\n        ok = \"\\x00\" not in self.vpath\n        if ANYWIN:\n            ok = ok and not relchk(self.vpath)\n\n        if not ok and (self.vpath != \"*\" or self.mode != \"OPTIONS\"):\n            self.log(\"invalid relpath [{}]\".format(self.vpath))\n            return self.tx_404() and self.keepalive\n\n        zso = self.headers.get(\"authorization\")\n        bauth = \"\"\n        if zso:\n            try:\n                zb = zso.split(\" \")[1].encode(\"ascii\")\n                zs = base64.b64decode(zb).decode(\"utf-8\")\n                # try \"pwd\", \"x:pwd\", \"pwd:x\"\n                for bauth in [zs] + zs.split(\":\", 1)[::-1]:\n                    hpw = self.asrv.ah.hash(bauth)\n                    if self.asrv.iacct.get(hpw):\n                        break\n            except:\n                pass\n\n        self.pw = uparam.get(\"pw\") or self.headers.get(\"pw\") or bauth or cookie_pw\n        self.uname = self.asrv.iacct.get(self.asrv.ah.hash(self.pw)) or \"*\"\n        self.rvol = self.asrv.vfs.aread[self.uname]\n        self.wvol = self.asrv.vfs.awrite[self.uname]\n        self.mvol = self.asrv.vfs.amove[self.uname]\n        self.dvol = self.asrv.vfs.adel[self.uname]\n        self.gvol = self.asrv.vfs.aget[self.uname]\n        self.upvol = self.asrv.vfs.apget[self.uname]\n\n        if self.pw and (\n            self.pw != cookie_pw or self.conn.freshen_pwd + 30 < time.time()\n        ):\n            self.conn.freshen_pwd = time.time()\n            self.get_pwd_cookie(self.pw)\n\n        if self.is_rclone:\n            # dots: always include dotfiles if permitted\n            # lt: probably more important showing the correct timestamps of any dupes it just uploaded rather than the lastmod time of any non-copyparty-managed symlinks\n            # b: basic-browser if it tries to parse the html listing\n            uparam[\"dots\"] = \"\"\n            uparam[\"lt\"] = \"\"\n            uparam[\"b\"] = \"\"\n            cookies[\"b\"] = \"\"\n\n        vn, rem = self.asrv.vfs.get(self.vpath, self.uname, False, False)\n        if \"xdev\" in vn.flags or \"xvol\" in vn.flags:\n            ap = vn.canonical(rem)\n            avn = vn.chk_ap(ap)\n        else:\n            avn = vn\n\n        (\n            self.can_read,\n            self.can_write,\n            self.can_move,\n            self.can_delete,\n            self.can_get,\n            self.can_upget,\n            self.can_admin,\n        ) = (\n            avn.can_access(\"\", self.uname) if avn else [False] * 6\n        )\n        self.avn = avn\n        self.vn = vn\n        self.rem = rem\n\n        self.s.settimeout(self.args.s_tbody or None)\n\n        try:\n            cors_k = self._cors()\n            if self.mode in (\"GET\", \"HEAD\"):\n                return self.handle_get() and self.keepalive\n            if self.mode == \"OPTIONS\":\n                return self.handle_options() and self.keepalive\n\n            if not cors_k:\n                origin = self.headers.get(\"origin\", \"<?>\")\n                self.log(\"cors-reject {} from {}\".format(self.mode, origin), 3)\n                raise Pebkac(403, \"no surfing\")\n\n            # getattr(self.mode) is not yet faster than this\n            if self.mode == \"POST\":\n                return self.handle_post() and self.keepalive\n            elif self.mode == \"PUT\":\n                return self.handle_put() and self.keepalive\n            elif self.mode == \"PROPFIND\":\n                return self.handle_propfind() and self.keepalive\n            elif self.mode == \"DELETE\":\n                return self.handle_delete() and self.keepalive\n            elif self.mode == \"PROPPATCH\":\n                return self.handle_proppatch() and self.keepalive\n            elif self.mode == \"LOCK\":\n                return self.handle_lock() and self.keepalive\n            elif self.mode == \"UNLOCK\":\n                return self.handle_unlock() and self.keepalive\n            elif self.mode == \"MKCOL\":\n                return self.handle_mkcol() and self.keepalive\n            elif self.mode == \"MOVE\":\n                return self.handle_move() and self.keepalive\n            else:\n                raise Pebkac(400, 'invalid HTTP mode \"{0}\"'.format(self.mode))\n\n        except Exception as ex:\n            if not isinstance(ex, Pebkac):\n                pex = Pebkac(500)\n            else:\n                pex: Pebkac = ex  # type: ignore\n\n            try:\n                post = self.mode in [\"POST\", \"PUT\"] or \"content-length\" in self.headers\n                if not self._check_nonfatal(pex, post):\n                    self.keepalive = False\n\n                em = str(ex)\n                msg = em if pex == ex else min_ex()\n                if pex.code != 404 or self.do_log:\n                    self.log(\n                        \"{}\\033[0m, {}\".format(msg, self.vpath),\n                        6 if em.startswith(\"client d/c \") else 3,\n                    )\n\n                msg = \"{}\\r\\nURL: {}\\r\\n\".format(em, self.vpath)\n                if self.hint:\n                    msg += \"hint: {}\\r\\n\".format(self.hint)\n\n                if \"database is locked\" in em:\n                    self.conn.hsrv.broker.say(\"log_stacks\")\n                    msg += \"hint: important info in the server log\\r\\n\"\n\n                zb = b\"<pre>\" + html_escape(msg).encode(\"utf-8\", \"replace\")\n                h = {\"WWW-Authenticate\": 'Basic realm=\"a\"'} if pex.code == 401 else {}\n                self.reply(zb, status=pex.code, headers=h, volsan=True)\n                return self.keepalive\n            except Pebkac:\n                return False\n\n    def dip(self) -> str:\n        if self.args.plain_ip:\n            return self.ip.replace(\":\", \".\")\n        else:\n            return self.conn.iphash.s(self.ip)\n\n    def is_banned(self) -> bool:\n        if not self.conn.bans:\n            return False\n\n        bans = self.conn.bans\n        ip = ipnorm(self.ip)\n        if ip not in bans:\n            return False\n\n        rt = bans[ip] - time.time()\n        if rt < 0:\n            self.log(\"client unbanned\", 3)\n            del bans[ip]\n            return False\n\n        self.log(\"banned for {:.0f} sec\".format(rt), 6)\n        zb = b\"HTTP/1.0 403 Forbidden\\r\\n\\r\\nthank you for playing\"\n        self.s.sendall(zb)\n        return True\n\n    def permit_caching(self) -> None:\n        cache = self.uparam.get(\"cache\")\n        if cache is None:\n            self.out_headers.update(NO_CACHE)\n            return\n\n        n = \"604869\" if cache == \"i\" else cache or \"69\"\n        self.out_headers[\"Cache-Control\"] = \"max-age=\" + n\n\n    def k304(self) -> bool:\n        k304 = self.cookies.get(\"k304\")\n        return k304 == \"y\" or (\"; Trident/\" in self.ua and not k304)\n\n    def send_headers(\n        self,\n        length: Optional[int],\n        status: int = 200,\n        mime: Optional[str] = None,\n        headers: Optional[dict[str, str]] = None,\n    ) -> None:\n        response = [\"%s %s %s\" % (self.http_ver, status, HTTPCODE[status])]\n\n        if length is not None:\n            response.append(\"Content-Length: \" + unicode(length))\n\n        if status == 304 and self.k304():\n            self.keepalive = False\n\n        # close if unknown length, otherwise take client's preference\n        response.append(\"Connection: \" + (\"Keep-Alive\" if self.keepalive else \"Close\"))\n        response.append(\"Date: \" + formatdate(usegmt=True))\n\n        # headers{} overrides anything set previously\n        if headers:\n            self.out_headers.update(headers)\n\n        # default to utf8 html if no content-type is set\n        if not mime:\n            mime = self.out_headers.get(\"Content-Type\") or \"text/html; charset=utf-8\"\n\n        self.out_headers[\"Content-Type\"] = mime\n\n        for k, zs in list(self.out_headers.items()) + self.out_headerlist:\n            response.append(\"%s: %s\" % (k, zs))\n\n        try:\n            # best practice to separate headers and body into different packets\n            self.s.sendall(\"\\r\\n\".join(response).encode(\"utf-8\") + b\"\\r\\n\\r\\n\")\n        except:\n            raise Pebkac(400, \"client d/c while replying headers\")\n\n    def reply(\n        self,\n        body: bytes,\n        status: int = 200,\n        mime: Optional[str] = None,\n        headers: Optional[dict[str, str]] = None,\n        volsan: bool = False,\n    ) -> bytes:\n        if status == 404:\n            g = self.conn.hsrv.g404\n            if g.lim:\n                bonk, ip = g.bonk(self.ip, self.vpath)\n                if bonk:\n                    xban = self.vn.flags.get(\"xban\")\n                    if not xban or not runhook(\n                        self.log,\n                        xban,\n                        self.vn.canonical(self.rem),\n                        self.vpath,\n                        self.host,\n                        self.uname,\n                        time.time(),\n                        0,\n                        self.ip,\n                        time.time(),\n                        \"404\",\n                    ):\n                        self.log(\"client banned: 404s\", 1)\n                        self.conn.hsrv.bans[ip] = bonk\n\n        if volsan:\n            vols = list(self.asrv.vfs.all_vols.values())\n            body = vol_san(vols, body)\n\n        self.send_headers(len(body), status, mime, headers)\n\n        try:\n            if self.mode != \"HEAD\":\n                self.s.sendall(body)\n        except:\n            raise Pebkac(400, \"client d/c while replying body\")\n\n        return body\n\n    def loud_reply(self, body: str, *args: Any, **kwargs: Any) -> None:\n        if not kwargs.get(\"mime\"):\n            kwargs[\"mime\"] = \"text/plain; charset=utf-8\"\n\n        self.log(body.rstrip())\n        self.reply(body.encode(\"utf-8\") + b\"\\r\\n\", *list(args), **kwargs)\n\n    def urlq(self, add: dict[str, str], rm: list[str]) -> str:\n        \"\"\"\n        generates url query based on uparam (b, pw, all others)\n        removing anything in rm, adding pairs in add\n\n        also list faster than set until ~20 items\n        \"\"\"\n\n        if self.is_rclone:\n            return \"\"\n\n        kv = {k: zs for k, zs in self.uparam.items() if k not in rm}\n        if \"pw\" in kv:\n            pw = self.cookies.get(\"cppws\") or self.cookies.get(\"cppwd\")\n            if kv[\"pw\"] == pw:\n                del kv[\"pw\"]\n\n        kv.update(add)\n        if not kv:\n            return \"\"\n\n        r = [\"%s=%s\" % (k, quotep(zs)) if zs else k for k, zs in kv.items()]\n        return \"?\" + \"&amp;\".join(r)\n\n    def redirect(\n        self,\n        vpath: str,\n        suf: str = \"\",\n        msg: str = \"aight\",\n        flavor: str = \"go to\",\n        click: bool = True,\n        status: int = 200,\n        use302: bool = False,\n    ) -> bool:\n        vp = self.args.RS + vpath\n        html = self.j2s(\n            \"msg\",\n            h2='<a href=\"/{}\">{} /{}</a>'.format(\n                quotep(vp) + suf, flavor, html_escape(vp, crlf=True) + suf\n            ),\n            pre=msg,\n            click=click,\n        ).encode(\"utf-8\", \"replace\")\n\n        if use302:\n            self.reply(html, status=302, headers={\"Location\": \"/\" + vpath})\n        else:\n            self.reply(html, status=status)\n\n        return True\n\n    def _cors(self) -> bool:\n        ih = self.headers\n        origin = ih.get(\"origin\")\n        if not origin:\n            sfsite = ih.get(\"sec-fetch-site\")\n            if sfsite and sfsite.lower().startswith(\"cross\"):\n                origin = \":|\"  # sandboxed iframe\n            else:\n                return True\n\n        oh = self.out_headers\n        origin = origin.lower()\n        good_origins = self.args.acao + [\n            \"{}://{}\".format(\n                \"https\" if self.is_https else \"http\",\n                self.host.lower().split(\":\")[0],\n            )\n        ]\n        if re.sub(r\"(:[0-9]{1,5})?/?$\", \"\", origin) in good_origins:\n            good_origin = True\n            bad_hdrs = (\"\",)\n        else:\n            good_origin = False\n            bad_hdrs = (\"\", \"pw\")\n\n        # '*' blocks all credentials (cookies, http-auth);\n        # exact-match for Origin is necessary to unlock those,\n        # however yolo-requests (?pw=) are always allowed\n        acah = ih.get(\"access-control-request-headers\", \"\")\n        acao = (origin if good_origin else None) or (\n            \"*\" if \"*\" in good_origins else None\n        )\n        if self.args.allow_csrf:\n            acao = origin or acao or \"*\"  # explicitly permit impersonation\n            acam = \", \".join(self.conn.hsrv.mallow)  # and all methods + headers\n            oh[\"Access-Control-Allow-Credentials\"] = \"true\"\n            good_origin = True\n        else:\n            acam = \", \".join(self.args.acam)\n            # wash client-requested headers and roll with that\n            if \"range\" not in acah.lower():\n                acah += \",Range\"  # firefox\n            req_h = acah.split(\",\")\n            req_h = [x.strip() for x in req_h]\n            req_h = [x for x in req_h if x.lower() not in bad_hdrs]\n            acah = \", \".join(req_h)\n\n        if not acao:\n            return False\n\n        oh[\"Access-Control-Allow-Origin\"] = acao\n        oh[\"Access-Control-Allow-Methods\"] = acam.upper()\n        if acah:\n            oh[\"Access-Control-Allow-Headers\"] = acah\n\n        return good_origin\n\n    def handle_get(self) -> bool:\n        if self.do_log:\n            logmsg = \"%-4s %s @%s\" % (self.mode, self.req, self.uname)\n\n            if \"range\" in self.headers:\n                try:\n                    rval = self.headers[\"range\"].split(\"=\", 1)[1]\n                except:\n                    rval = self.headers[\"range\"]\n\n                logmsg += \" [\\033[36m\" + rval + \"\\033[0m]\"\n\n            self.log(logmsg)\n\n        # \"embedded\" resources\n        if self.vpath.startswith(\".cpr\"):\n            if self.vpath.startswith(\".cpr/ico/\"):\n                return self.tx_ico(self.vpath.split(\"/\")[-1], exact=True)\n\n            if self.vpath.startswith(\".cpr/ssdp\"):\n                return self.conn.hsrv.ssdp.reply(self)\n\n            if self.vpath.startswith(\".cpr/dd/\") and self.args.mpmc:\n                if self.args.mpmc == \".\":\n                    raise Pebkac(404)\n\n                loc = self.args.mpmc.rstrip(\"/\") + self.vpath[self.vpath.rfind(\"/\") :]\n                h = {\"Location\": loc, \"Cache-Control\": \"max-age=39\"}\n                self.reply(b\"\", 301, headers=h)\n                return True\n\n            path_base = os.path.join(self.E.mod, \"web\")\n            static_path = absreal(os.path.join(path_base, self.vpath[5:]))\n            if not static_path.startswith(path_base):\n                t = \"attempted path traversal [{}] => [{}]\"\n                self.log(t.format(self.vpath, static_path), 1)\n                self.tx_404()\n                return False\n\n            return self.tx_file(static_path)\n\n        if \"cf_challenge\" in self.uparam:\n            self.reply(self.j2s(\"cf\").encode(\"utf-8\", \"replace\"))\n            return True\n\n        if not self.can_read and not self.can_write and not self.can_get:\n            t = \"@{} has no access to [{}]\"\n            self.log(t.format(self.uname, self.vpath))\n\n            if \"on403\" in self.vn.flags:\n                ret = self.on40x(self.vn.flags[\"on403\"], self.vn, self.rem)\n                if ret == \"true\":\n                    return True\n                elif ret == \"false\":\n                    return False\n                elif ret == \"allow\":\n                    self.log(\"plugin override; access permitted\")\n                    self.can_read = self.can_write = self.can_move = True\n                    self.can_delete = self.can_get = self.can_upget = True\n                    self.can_admin = True\n                else:\n                    return self.tx_404(True)\n            else:\n                if self.vpath:\n                    return self.tx_404(True)\n\n                self.uparam[\"h\"] = \"\"\n\n        if \"tree\" in self.uparam:\n            return self.tx_tree()\n\n        if \"scan\" in self.uparam:\n            return self.scanvol()\n\n        if self.args.getmod:\n            if \"delete\" in self.uparam:\n                return self.handle_rm([])\n\n            if \"move\" in self.uparam:\n                return self.handle_mv()\n\n        if not self.vpath:\n            if \"reload\" in self.uparam:\n                return self.handle_reload()\n\n            if \"stack\" in self.uparam:\n                return self.tx_stack()\n\n            if \"ups\" in self.uparam:\n                return self.tx_ups()\n\n            if \"k304\" in self.uparam:\n                return self.set_k304()\n\n            if \"setck\" in self.uparam:\n                return self.setck()\n\n            if \"reset\" in self.uparam:\n                return self.set_cfg_reset()\n\n            if \"hc\" in self.uparam:\n                return self.tx_svcs()\n\n        if \"h\" in self.uparam:\n            return self.tx_mounts()\n\n        # conditional redirect to single volumes\n        if self.vpath == \"\" and not self.ouparam:\n            nread = len(self.rvol)\n            nwrite = len(self.wvol)\n            if nread + nwrite == 1 or (self.rvol == self.wvol and nread == 1):\n                if nread == 1:\n                    vpath = self.rvol[0]\n                else:\n                    vpath = self.wvol[0]\n\n                if self.vpath != vpath:\n                    self.redirect(vpath, flavor=\"redirecting to\", use302=True)\n                    return True\n\n        return self.tx_browser()\n\n    def handle_propfind(self) -> bool:\n        if self.do_log:\n            self.log(\"PFIND %s @%s\" % (self.req, self.uname))\n\n        if self.args.no_dav:\n            raise Pebkac(405, \"WebDAV is disabled in server config\")\n\n        vn, rem = self.asrv.vfs.get(self.vpath, self.uname, False, False, err=401)\n        tap = vn.canonical(rem)\n\n        if \"davauth\" in vn.flags and self.uname == \"*\":\n            self.can_read = self.can_write = self.can_get = False\n\n        if not self.can_read and not self.can_write and not self.can_get:\n            self.log(\"inaccessible: [{}]\".format(self.vpath))\n            raise Pebkac(401, \"authenticate\")\n\n        from .dxml import parse_xml\n\n        # enc = \"windows-31j\"\n        # enc = \"shift_jis\"\n        enc = \"utf-8\"\n        uenc = enc.upper()\n\n        clen = int(self.headers.get(\"content-length\", 0))\n        if clen:\n            buf = b\"\"\n            for rbuf in self.get_body_reader()[0]:\n                buf += rbuf\n                if not rbuf or len(buf) >= 32768:\n                    break\n\n            xroot = parse_xml(buf.decode(enc, \"replace\"))\n            xtag = next(x for x in xroot if x.tag.split(\"}\")[-1] == \"prop\")\n            props_lst = [y.tag.split(\"}\")[-1] for y in xtag]\n        else:\n            props_lst = [\n                \"contentclass\",\n                \"creationdate\",\n                \"defaultdocument\",\n                \"displayname\",\n                \"getcontentlanguage\",\n                \"getcontentlength\",\n                \"getcontenttype\",\n                \"getlastmodified\",\n                \"href\",\n                \"iscollection\",\n                \"ishidden\",\n                \"isreadonly\",\n                \"isroot\",\n                \"isstructureddocument\",\n                \"lastaccessed\",\n                \"name\",\n                \"parentname\",\n                \"resourcetype\",\n                \"supportedlock\",\n            ]\n\n        props = set(props_lst)\n        depth = self.headers.get(\"depth\", \"infinity\").lower()\n\n        try:\n            topdir = {\"vp\": \"\", \"st\": bos.stat(tap)}\n        except OSError as ex:\n            if ex.errno not in (errno.ENOENT, errno.ENOTDIR):\n                raise\n            raise Pebkac(404)\n\n        if depth == \"0\" or not self.can_read or not stat.S_ISDIR(topdir[\"st\"].st_mode):\n            fgen = []\n\n        elif depth == \"infinity\":\n            if not self.args.dav_inf:\n                self.log(\"client wants --dav-inf\", 3)\n                zb = b'<?xml version=\"1.0\" encoding=\"utf-8\"?>\\n<D:error xmlns:D=\"DAV:\"><D:propfind-finite-depth/></D:error>'\n                self.reply(zb, 403, \"application/xml; charset=utf-8\")\n                return True\n\n            # this will return symlink-target timestamps\n            # because lstat=true would not recurse into subfolders\n            # and this is a rare case where we actually want that\n            fgen = vn.zipgen(\n                rem,\n                rem,\n                set(),\n                self.uname,\n                self.args.ed,\n                True,\n                not self.args.no_scandir,\n                wrap=False,\n            )\n\n        elif depth == \"1\":\n            _, vfs_ls, vfs_virt = vn.ls(\n                rem,\n                self.uname,\n                not self.args.no_scandir,\n                [[True, False]],\n                lstat=\"davrt\" not in vn.flags,\n            )\n            if not self.args.ed:\n                names = set(exclude_dotfiles([x[0] for x in vfs_ls]))\n                vfs_ls = [x for x in vfs_ls if x[0] in names]\n\n            zi = int(time.time())\n            zsr = os.stat_result((16877, -1, -1, 1, 1000, 1000, 8, zi, zi, zi))\n            ls = [{\"vp\": vp, \"st\": st} for vp, st in vfs_ls]\n            ls += [{\"vp\": v, \"st\": zsr} for v in vfs_virt]\n            fgen = ls  # type: ignore\n\n        else:\n            t = \"invalid depth value '{}' (must be either '0' or '1'{})\"\n            t2 = \" or 'infinity'\" if self.args.dav_inf else \"\"\n            raise Pebkac(412, t.format(depth, t2))\n\n        fgen = itertools.chain([topdir], fgen)  # type: ignore\n        vtop = vjoin(self.args.R, vjoin(vn.vpath, rem))\n\n        chunksz = 0x7FF8  # preferred by nginx or cf (dunno which)\n\n        self.send_headers(\n            None, 207, \"text/xml; charset=\" + enc, {\"Transfer-Encoding\": \"chunked\"}\n        )\n\n        ret = '<?xml version=\"1.0\" encoding=\"{}\"?>\\n<D:multistatus xmlns:D=\"DAV:\">'\n        ret = ret.format(uenc)\n        for x in fgen:\n            rp = vjoin(vtop, x[\"vp\"])\n            st: os.stat_result = x[\"st\"]\n            mtime = st.st_mtime\n            if stat.S_ISLNK(st.st_mode):\n                try:\n                    st = bos.stat(os.path.join(tap, x[\"vp\"]))\n                except:\n                    continue\n\n            isdir = stat.S_ISDIR(st.st_mode)\n\n            ret += \"<D:response><D:href>/%s%s</D:href><D:propstat><D:prop>\" % (\n                quotep(rp),\n                \"/\" if isdir and rp else \"\",\n            )\n\n            pvs: dict[str, str] = {\n                \"displayname\": html_escape(rp.split(\"/\")[-1]),\n                \"getlastmodified\": formatdate(mtime, usegmt=True),\n                \"resourcetype\": '<D:collection xmlns:D=\"DAV:\"/>' if isdir else \"\",\n                \"supportedlock\": '<D:lockentry xmlns:D=\"DAV:\"><D:lockscope><D:exclusive/></D:lockscope><D:locktype><D:write/></D:locktype></D:lockentry>',\n            }\n            if not isdir:\n                pvs[\"getcontenttype\"] = html_escape(guess_mime(rp))\n                pvs[\"getcontentlength\"] = str(st.st_size)\n\n            for k, v in pvs.items():\n                if k not in props:\n                    continue\n                elif v:\n                    ret += \"<D:%s>%s</D:%s>\" % (k, v, k)\n                else:\n                    ret += \"<D:%s/>\" % (k,)\n\n            ret += \"</D:prop><D:status>HTTP/1.1 200 OK</D:status></D:propstat>\"\n\n            missing = [\"<D:%s/>\" % (x,) for x in props if x not in pvs]\n            if missing and clen:\n                t = \"<D:propstat><D:prop>{}</D:prop><D:status>HTTP/1.1 404 Not Found</D:status></D:propstat>\"\n                ret += t.format(\"\".join(missing))\n\n            ret += \"</D:response>\"\n            while len(ret) >= chunksz:\n                ret = self.send_chunk(ret, enc, chunksz)\n\n        ret += \"</D:multistatus>\"\n        while ret:\n            ret = self.send_chunk(ret, enc, chunksz)\n\n        self.send_chunk(\"\", enc, chunksz)\n        # self.reply(ret.encode(enc, \"replace\"),207, \"text/xml; charset=\" + enc)\n        return True\n\n    def handle_proppatch(self) -> bool:\n        if self.do_log:\n            self.log(\"PPATCH %s @%s\" % (self.req, self.uname))\n\n        if self.args.no_dav:\n            raise Pebkac(405, \"WebDAV is disabled in server config\")\n\n        if not self.can_write:\n            self.log(\"{} tried to proppatch [{}]\".format(self.uname, self.vpath))\n            raise Pebkac(401, \"authenticate\")\n\n        from xml.etree import ElementTree as ET\n\n        from .dxml import mkenod, mktnod, parse_xml\n\n        buf = b\"\"\n        for rbuf in self.get_body_reader()[0]:\n            buf += rbuf\n            if not rbuf or len(buf) >= 128 * 1024:\n                break\n\n        if self._applesan():\n            return True\n\n        txt = buf.decode(\"ascii\", \"replace\").lower()\n        enc = self.get_xml_enc(txt)\n        uenc = enc.upper()\n\n        txt = buf.decode(enc, \"replace\")\n        ET.register_namespace(\"D\", \"DAV:\")\n        xroot = mkenod(\"D:orz\")\n        xroot.insert(0, parse_xml(txt))\n        xprop = xroot.find(r\"./{DAV:}propertyupdate/{DAV:}set/{DAV:}prop\")\n        assert xprop\n        for ze in xprop:\n            ze.clear()\n\n        txt = \"\"\"<multistatus xmlns=\"DAV:\"><response><propstat><status>HTTP/1.1 403 Forbidden</status></propstat></response></multistatus>\"\"\"\n        xroot = parse_xml(txt)\n\n        el = xroot.find(r\"./{DAV:}response\")\n        assert el\n        e2 = mktnod(\"D:href\", quotep(self.args.SRS + self.vpath))\n        el.insert(0, e2)\n\n        el = xroot.find(r\"./{DAV:}response/{DAV:}propstat\")\n        assert el\n        el.insert(0, xprop)\n\n        ret = '<?xml version=\"1.0\" encoding=\"{}\"?>\\n'.format(uenc)\n        ret += ET.tostring(xroot).decode(\"utf-8\")\n\n        self.reply(ret.encode(enc, \"replace\"), 207, \"text/xml; charset=\" + enc)\n        return True\n\n    def handle_lock(self) -> bool:\n        if self.do_log:\n            self.log(\"LOCK %s @%s\" % (self.req, self.uname))\n\n        if self.args.no_dav:\n            raise Pebkac(405, \"WebDAV is disabled in server config\")\n\n        # win7+ deadlocks if we say no; just smile and nod\n        if not self.can_write and \"Microsoft-WebDAV\" not in self.ua:\n            self.log(\"{} tried to lock [{}]\".format(self.uname, self.vpath))\n            raise Pebkac(401, \"authenticate\")\n\n        from xml.etree import ElementTree as ET\n\n        from .dxml import mkenod, mktnod, parse_xml\n\n        abspath = self.vn.dcanonical(self.rem)\n\n        buf = b\"\"\n        for rbuf in self.get_body_reader()[0]:\n            buf += rbuf\n            if not rbuf or len(buf) >= 128 * 1024:\n                break\n\n        if self._applesan():\n            return True\n\n        txt = buf.decode(\"ascii\", \"replace\").lower()\n        enc = self.get_xml_enc(txt)\n        uenc = enc.upper()\n\n        txt = buf.decode(enc, \"replace\")\n        ET.register_namespace(\"D\", \"DAV:\")\n        lk = parse_xml(txt)\n        assert lk.tag == \"{DAV:}lockinfo\"\n\n        token = str(uuid.uuid4())\n\n        if not lk.find(r\"./{DAV:}depth\"):\n            depth = self.headers.get(\"depth\", \"infinity\")\n            lk.append(mktnod(\"D:depth\", depth))\n\n        lk.append(mktnod(\"D:timeout\", \"Second-3310\"))\n        lk.append(mkenod(\"D:locktoken\", mktnod(\"D:href\", token)))\n        lk.append(\n            mkenod(\"D:lockroot\", mktnod(\"D:href\", quotep(self.args.SRS + self.vpath)))\n        )\n\n        lk2 = mkenod(\"D:activelock\")\n        xroot = mkenod(\"D:prop\", mkenod(\"D:lockdiscovery\", lk2))\n        for a in lk:\n            lk2.append(a)\n\n        ret = '<?xml version=\"1.0\" encoding=\"{}\"?>\\n'.format(uenc)\n        ret += ET.tostring(xroot).decode(\"utf-8\")\n\n        rc = 200\n        if self.can_write and not bos.path.isfile(abspath):\n            with open(fsenc(abspath), \"wb\") as _:\n                rc = 201\n\n        self.out_headers[\"Lock-Token\"] = \"<{}>\".format(token)\n        self.reply(ret.encode(enc, \"replace\"), rc, \"text/xml; charset=\" + enc)\n        return True\n\n    def handle_unlock(self) -> bool:\n        if self.do_log:\n            self.log(\"UNLOCK %s @%s\" % (self.req, self.uname))\n\n        if self.args.no_dav:\n            raise Pebkac(405, \"WebDAV is disabled in server config\")\n\n        if not self.can_write and \"Microsoft-WebDAV\" not in self.ua:\n            self.log(\"{} tried to lock [{}]\".format(self.uname, self.vpath))\n            raise Pebkac(401, \"authenticate\")\n\n        self.send_headers(None, 204)\n        return True\n\n    def handle_mkcol(self) -> bool:\n        if self._applesan():\n            return True\n\n        if self.do_log:\n            self.log(\"MKCOL %s @%s\" % (self.req, self.uname))\n\n        try:\n            return self._mkdir(self.vpath, True)\n        except Pebkac as ex:\n            if ex.code >= 500:\n                raise\n\n            self.reply(b\"\", ex.code)\n            return True\n\n    def handle_move(self) -> bool:\n        dst = self.headers[\"destination\"]\n        dst = re.sub(\"^https?://[^/]+\", \"\", dst).lstrip()\n        dst = unquotep(dst)\n        if not self._mv(self.vpath, dst.lstrip(\"/\")):\n            return False\n\n        return True\n\n    def _applesan(self) -> bool:\n        if self.args.dav_mac or \"Darwin/\" not in self.ua:\n            return False\n\n        vp = \"/\" + self.vpath\n        ptn = r\"/\\.(_|DS_Store|Spotlight-|fseventsd|Trashes|AppleDouble)|/__MACOS\"\n        if re.search(ptn, vp):\n            zt = '<?xml version=\"1.0\" encoding=\"utf-8\"?>\\n<D:error xmlns:D=\"DAV:\"><D:lock-token-submitted><D:href>{}</D:href></D:lock-token-submitted></D:error>'\n            zb = zt.format(vp).encode(\"utf-8\", \"replace\")\n            self.reply(zb, 423, \"text/xml; charset=utf-8\")\n            return True\n\n        return False\n\n    def send_chunk(self, txt: str, enc: str, bmax: int) -> str:\n        orig_len = len(txt)\n        buf = txt[:bmax].encode(enc, \"replace\")[:bmax]\n        try:\n            _ = buf.decode(enc)\n        except UnicodeDecodeError as ude:\n            buf = buf[: ude.start]\n\n        txt = txt[len(buf.decode(enc)) :]\n        if txt and len(txt) == orig_len:\n            raise Pebkac(500, \"chunk slicing failed\")\n\n        buf = \"{:x}\\r\\n\".format(len(buf)).encode(enc) + buf\n        self.s.sendall(buf + b\"\\r\\n\")\n        return txt\n\n    def handle_options(self) -> bool:\n        if self.do_log:\n            self.log(\"OPTIONS %s @%s\" % (self.req, self.uname))\n\n        oh = self.out_headers\n        oh[\"Allow\"] = \", \".join(self.conn.hsrv.mallow)\n\n        if not self.args.no_dav:\n            # PROPPATCH, LOCK, UNLOCK, COPY: noop (spec-must)\n            oh[\"Dav\"] = \"1, 2\"\n            oh[\"Ms-Author-Via\"] = \"DAV\"\n\n        # winxp-webdav doesnt know what 204 is\n        self.send_headers(0, 200)\n        return True\n\n    def handle_delete(self) -> bool:\n        self.log(\"DELETE %s @%s\" % (self.req, self.uname))\n        return self.handle_rm([])\n\n    def handle_put(self) -> bool:\n        self.log(\"PUT %s @%s\" % (self.req, self.uname))\n\n        if not self.can_write:\n            t = \"user {} does not have write-access here\"\n            raise Pebkac(403, t.format(self.uname))\n\n        if not self.args.no_dav and self._applesan():\n            return self.headers.get(\"content-length\") == \"0\"\n\n        if self.headers.get(\"expect\", \"\").lower() == \"100-continue\":\n            try:\n                self.s.sendall(b\"HTTP/1.1 100 Continue\\r\\n\\r\\n\")\n            except:\n                raise Pebkac(400, \"client d/c before 100 continue\")\n\n        return self.handle_stash(True)\n\n    def handle_post(self) -> bool:\n        self.log(\"POST %s @%s\" % (self.req, self.uname))\n\n        if self.headers.get(\"expect\", \"\").lower() == \"100-continue\":\n            try:\n                self.s.sendall(b\"HTTP/1.1 100 Continue\\r\\n\\r\\n\")\n            except:\n                raise Pebkac(400, \"client d/c before 100 continue\")\n\n        if \"raw\" in self.uparam:\n            return self.handle_stash(False)\n\n        ctype = self.headers.get(\"content-type\", \"\").lower()\n\n        if \"multipart/form-data\" in ctype:\n            return self.handle_post_multipart()\n\n        if (\n            \"application/json\" in ctype\n            or \"text/plain\" in ctype\n            or \"application/xml\" in ctype\n        ):\n            return self.handle_post_json()\n\n        if \"move\" in self.uparam:\n            return self.handle_mv()\n\n        if \"delete\" in self.uparam:\n            return self.handle_rm([])\n\n        if \"application/octet-stream\" in ctype:\n            return self.handle_post_binary()\n\n        if \"application/x-www-form-urlencoded\" in ctype:\n            opt = self.args.urlform\n            if \"stash\" in opt:\n                return self.handle_stash(False)\n\n            if \"save\" in opt:\n                post_sz, _, _, _, path, _ = self.dump_to_file(False)\n                self.log(\"urlform: {} bytes, {}\".format(post_sz, path))\n            elif \"print\" in opt:\n                reader, _ = self.get_body_reader()\n                buf = b\"\"\n                for rbuf in reader:\n                    buf += rbuf\n                    if not rbuf or len(buf) >= 32768:\n                        break\n\n                if buf:\n                    orig = buf.decode(\"utf-8\", \"replace\")\n                    t = \"urlform_raw {} @ {}\\n  {}\\n\"\n                    self.log(t.format(len(orig), self.vpath, orig))\n                    try:\n                        zb = unquote(buf.replace(b\"+\", b\" \"))\n                        plain = zb.decode(\"utf-8\", \"replace\")\n                        if buf.startswith(b\"msg=\"):\n                            plain = plain[4:]\n                            xm = self.vn.flags.get(\"xm\")\n                            if xm:\n                                runhook(\n                                    self.log,\n                                    xm,\n                                    self.vn.canonical(self.rem),\n                                    self.vpath,\n                                    self.host,\n                                    self.uname,\n                                    time.time(),\n                                    len(buf),\n                                    self.ip,\n                                    time.time(),\n                                    plain,\n                                )\n\n                        t = \"urlform_dec {} @ {}\\n  {}\\n\"\n                        self.log(t.format(len(plain), self.vpath, plain))\n\n                    except Exception as ex:\n                        self.log(repr(ex))\n\n            if \"get\" in opt:\n                return self.handle_get()\n\n            raise Pebkac(405, \"POST({}) is disabled in server config\".format(ctype))\n\n        raise Pebkac(405, \"don't know how to handle POST({})\".format(ctype))\n\n    def get_xml_enc(self, txt: str) -> str:\n        ofs = txt[:512].find(' encoding=\"')\n        enc = \"\"\n        if ofs + 1:\n            enc = txt[ofs + 6 :].split('\"')[1]\n        else:\n            enc = self.headers.get(\"content-type\", \"\").lower()\n            ofs = enc.find(\"charset=\")\n            if ofs + 1:\n                enc = enc[ofs + 4].split(\"=\")[1].split(\";\")[0].strip(\"\\\"'\")\n            else:\n                enc = \"\"\n\n        return enc or \"utf-8\"\n\n    def get_body_reader(self) -> tuple[Generator[bytes, None, None], int]:\n        if \"chunked\" in self.headers.get(\"transfer-encoding\", \"\").lower():\n            return read_socket_chunked(self.sr), -1\n\n        remains = int(self.headers.get(\"content-length\", -1))\n        if remains == -1:\n            self.keepalive = False\n            return read_socket_unbounded(self.sr), remains\n        else:\n            return read_socket(self.sr, remains), remains\n\n    def dump_to_file(self, is_put: bool) -> tuple[int, str, str, int, str, str]:\n        # post_sz, sha_hex, sha_b64, remains, path, url\n        reader, remains = self.get_body_reader()\n        vfs, rem = self.asrv.vfs.get(self.vpath, self.uname, False, True)\n        rnd, _, lifetime, xbu, xau = self.upload_flags(vfs)\n        lim = vfs.get_dbv(rem)[0].lim\n        fdir = vfs.canonical(rem)\n        if lim:\n            fdir, rem = lim.all(\n                self.ip, rem, remains, vfs.realpath, fdir, self.conn.hsrv.broker\n            )\n\n        fn = None\n        if rem and not self.trailing_slash and not bos.path.isdir(fdir):\n            fdir, fn = os.path.split(fdir)\n            rem, _ = vsplit(rem)\n\n        bos.makedirs(fdir)\n\n        open_ka: dict[str, Any] = {\"fun\": open}\n        open_a = [\"wb\", 512 * 1024]\n\n        # user-request || config-force\n        if (\"gz\" in vfs.flags or \"xz\" in vfs.flags) and (\n            \"pk\" in vfs.flags\n            or \"pk\" in self.uparam\n            or \"gz\" in self.uparam\n            or \"xz\" in self.uparam\n        ):\n            fb = {\"gz\": 9, \"xz\": 0}  # default/fallback level\n            lv = {}  # selected level\n            alg = \"\"  # selected algo (gz=preferred)\n\n            # user-prefs first\n            if \"gz\" in self.uparam or \"pk\" in self.uparam:  # def.pk\n                alg = \"gz\"\n            if \"xz\" in self.uparam:\n                alg = \"xz\"\n            if alg:\n                zso = self.uparam.get(alg)\n                lv[alg] = fb[alg] if zso is None else int(zso)\n\n            if alg not in vfs.flags:\n                alg = \"gz\" if \"gz\" in vfs.flags else \"xz\"\n\n            # then server overrides\n            pk = vfs.flags.get(\"pk\")\n            if pk is not None:\n                # config-forced on\n                alg = alg or \"gz\"  # def.pk\n                try:\n                    # config-forced opts\n                    alg, nlv = pk.split(\",\")\n                    lv[alg] = int(nlv)\n                except:\n                    pass\n\n            lv[alg] = lv.get(alg) or fb.get(alg) or 0\n\n            self.log(\"compressing with {} level {}\".format(alg, lv.get(alg)))\n            if alg == \"gz\":\n                open_ka[\"fun\"] = gzip.GzipFile\n                open_a = [\"wb\", lv[alg], None, 0x5FEE6600]  # 2021-01-01\n            elif alg == \"xz\":\n                open_ka = {\"fun\": lzma.open, \"preset\": lv[alg]}\n                open_a = [\"wb\"]\n            else:\n                self.log(\"fallthrough? thats a bug\", 1)\n\n        suffix = \"-{:.6f}-{}\".format(time.time(), self.dip())\n        nameless = not fn\n        if nameless:\n            suffix += \".bin\"\n            fn = \"put\" + suffix\n\n        params = {\"suffix\": suffix, \"fdir\": fdir}\n        if self.args.nw:\n            params = {}\n            fn = os.devnull\n\n        params.update(open_ka)\n        assert fn\n\n        if not self.args.nw:\n            if rnd:\n                fn = rand_name(fdir, fn, rnd)\n\n            fn = sanitize_fn(fn or \"\", \"\", [\".prologue.html\", \".epilogue.html\"])\n\n        path = os.path.join(fdir, fn)\n\n        if xbu:\n            at = time.time() - lifetime\n            if not runhook(\n                self.log,\n                xbu,\n                path,\n                self.vpath,\n                self.host,\n                self.uname,\n                at,\n                remains,\n                self.ip,\n                at,\n                \"\",\n            ):\n                t = \"upload blocked by xbu server config\"\n                self.log(t, 1)\n                raise Pebkac(403, t)\n\n        if is_put and not (self.args.no_dav or self.args.nw) and bos.path.exists(path):\n            # allow overwrite if...\n            #  * volflag 'daw' is set, or client is definitely webdav\n            #  * and account has delete-access\n            # or...\n            #  * file exists, is empty, sufficiently new\n            #  * and there is no .PARTIAL\n\n            tnam = fn + \".PARTIAL\"\n            if self.args.dotpart:\n                tnam = \".\" + tnam\n\n            if (\n                self.can_delete\n                and (vfs.flags.get(\"daw\") or \"x-oc-mtime\" in self.headers)\n            ) or (\n                not bos.path.exists(os.path.join(fdir, tnam))\n                and not bos.path.getsize(path)\n                and bos.path.getmtime(path) >= time.time() - self.args.blank_wt\n            ):\n                # small toctou, but better than clobbering a hardlink\n                bos.unlink(path)\n\n        with ren_open(fn, *open_a, **params) as zfw:\n            f, fn = zfw[\"orz\"]\n            path = os.path.join(fdir, fn)\n            post_sz, sha_hex, sha_b64 = hashcopy(reader, f, self.args.s_wr_slp)\n\n        if lim:\n            lim.nup(self.ip)\n            lim.bup(self.ip, post_sz)\n            try:\n                lim.chk_sz(post_sz)\n                lim.chk_vsz(self.conn.hsrv.broker, vfs.realpath, post_sz)\n            except:\n                bos.unlink(path)\n                raise\n\n        if self.args.nw:\n            return post_sz, sha_hex, sha_b64, remains, path, \"\"\n\n        at = mt = time.time() - lifetime\n        cli_mt = self.headers.get(\"x-oc-mtime\")\n        if cli_mt:\n            try:\n                mt = int(cli_mt)\n                times = (int(time.time()), mt)\n                bos.utime(path, times, False)\n            except:\n                pass\n\n        if nameless and \"magic\" in vfs.flags:\n            try:\n                ext = self.conn.hsrv.magician.ext(path)\n            except Exception as ex:\n                self.log(\"filetype detection failed for [{}]: {}\".format(path, ex), 6)\n                ext = None\n\n            if ext:\n                if rnd:\n                    fn2 = rand_name(fdir, \"a.\" + ext, rnd)\n                else:\n                    fn2 = fn.rsplit(\".\", 1)[0] + \".\" + ext\n\n                params[\"suffix\"] = suffix[:-4]\n                with ren_open(fn, *open_a, **params) as zfw:\n                    f, fn = zfw[\"orz\"]\n\n                path2 = os.path.join(fdir, fn2)\n                atomic_move(path, path2)\n                fn = fn2\n                path = path2\n\n        if xau and not runhook(\n            self.log,\n            xau,\n            path,\n            self.vpath,\n            self.host,\n            self.uname,\n            mt,\n            post_sz,\n            self.ip,\n            at,\n            \"\",\n        ):\n            t = \"upload blocked by xau server config\"\n            self.log(t, 1)\n            os.unlink(path)\n            raise Pebkac(403, t)\n\n        vfs, rem = vfs.get_dbv(rem)\n        self.conn.hsrv.broker.say(\n            \"up2k.hash_file\",\n            vfs.realpath,\n            vfs.vpath,\n            vfs.flags,\n            rem,\n            fn,\n            self.ip,\n            at,\n            self.uname,\n            True,\n        )\n\n        vsuf = \"\"\n        if (self.can_read or self.can_upget) and \"fk\" in vfs.flags:\n            vsuf = \"?k=\" + self.gen_fk(\n                self.args.fk_salt,\n                path,\n                post_sz,\n                0 if ANYWIN else bos.stat(path).st_ino,\n            )[: vfs.flags[\"fk\"]]\n\n        vpath = \"/\".join([x for x in [vfs.vpath, rem, fn] if x])\n        vpath = quotep(vpath)\n\n        url = \"{}://{}/{}\".format(\n            \"https\" if self.is_https else \"http\",\n            self.host,\n            self.args.RS + vpath + vsuf,\n        )\n\n        return post_sz, sha_hex, sha_b64, remains, path, url\n\n    def handle_stash(self, is_put: bool) -> bool:\n        post_sz, sha_hex, sha_b64, remains, path, url = self.dump_to_file(is_put)\n        spd = self._spd(post_sz)\n        t = \"{} wrote {}/{} bytes to {}  # {}\"\n        self.log(t.format(spd, post_sz, remains, path, sha_b64[:28]))  # 21\n\n        ac = self.uparam.get(\n            \"want\", self.headers.get(\"accept\", \"\").lower().split(\";\")[-1]\n        )\n        if ac == \"url\":\n            t = url\n        else:\n            t = \"{}\\n{}\\n{}\\n{}\\n\".format(post_sz, sha_b64, sha_hex[:56], url)\n\n        h = {\"Location\": url} if is_put and url else {}\n\n        if \"x-oc-mtime\" in self.headers:\n            h[\"X-OC-MTime\"] = \"accepted\"\n            t = \"\"  # some webdav clients expect/prefer this\n\n        self.reply(t.encode(\"utf-8\"), 201, headers=h)\n        return True\n\n    def bakflip(self, f: typing.BinaryIO, ofs: int, sz: int, sha: str) -> None:\n        if not self.args.bak_flips or self.args.nw:\n            return\n\n        sdir = self.args.bf_dir\n        fp = os.path.join(sdir, sha)\n        if bos.path.exists(fp):\n            return self.log(\"no bakflip; have it\", 6)\n\n        if not bos.path.isdir(sdir):\n            bos.makedirs(sdir)\n\n        if len(bos.listdir(sdir)) >= self.args.bf_nc:\n            return self.log(\"no bakflip; too many\", 3)\n\n        nrem = sz\n        f.seek(ofs)\n        with open(fp, \"wb\") as fo:\n            while nrem:\n                buf = f.read(min(nrem, 512 * 1024))\n                if not buf:\n                    break\n\n                nrem -= len(buf)\n                fo.write(buf)\n\n        if nrem:\n            self.log(\"bakflip truncated; {} remains\".format(nrem), 1)\n            atomic_move(fp, fp + \".trunc\")\n        else:\n            self.log(\"bakflip ok\", 2)\n\n    def _spd(self, nbytes: int, add: bool = True) -> str:\n        if add:\n            self.conn.nbyte += nbytes\n\n        spd1 = get_spd(nbytes, self.t0)\n        spd2 = get_spd(self.conn.nbyte, self.conn.t0)\n        return \"%s %s n%s\" % (spd1, spd2, self.conn.nreq)\n\n    def handle_post_multipart(self) -> bool:\n        self.parser = MultipartParser(self.log, self.sr, self.headers)\n        self.parser.parse()\n\n        act = self.parser.require(\"act\", 64)\n\n        if act == \"login\":\n            return self.handle_login()\n\n        if act == \"mkdir\":\n            return self.handle_mkdir()\n\n        if act == \"new_md\":\n            # kinda silly but has the least side effects\n            return self.handle_new_md()\n\n        if act == \"bput\":\n            return self.handle_plain_upload()\n\n        if act == \"tput\":\n            return self.handle_text_upload()\n\n        if act == \"zip\":\n            return self.handle_zip_post()\n\n        raise Pebkac(422, 'invalid action \"{}\"'.format(act))\n\n    def handle_zip_post(self) -> bool:\n        assert self.parser\n        try:\n            k = next(x for x in self.uparam if x in (\"zip\", \"tar\"))\n        except:\n            raise Pebkac(422, \"need zip or tar keyword\")\n\n        v = self.uparam[k]\n\n        vn, rem = self.asrv.vfs.get(self.vpath, self.uname, True, False)\n        zs = self.parser.require(\"files\", 1024 * 1024)\n        if not zs:\n            raise Pebkac(422, \"need files list\")\n\n        items = zs.replace(\"\\r\", \"\").split(\"\\n\")\n        items = [unquotep(x) for x in items if items]\n\n        self.parser.drop()\n        return self.tx_zip(k, v, \"\", vn, rem, items, self.args.ed)\n\n    def handle_post_json(self) -> bool:\n        try:\n            remains = int(self.headers[\"content-length\"])\n        except:\n            raise Pebkac(411)\n\n        if remains > 1024 * 1024:\n            raise Pebkac(413, \"json 2big\")\n\n        enc = \"utf-8\"\n        ctype = self.headers.get(\"content-type\", \"\").lower()\n        if \"charset\" in ctype:\n            enc = ctype.split(\"charset\")[1].strip(\" =\").split(\";\")[0].strip()\n\n        try:\n            json_buf = self.sr.recv_ex(remains)\n        except UnrecvEOF:\n            raise Pebkac(422, \"client disconnected while posting JSON\")\n\n        self.log(\"decoding {} bytes of {} json\".format(len(json_buf), enc))\n        try:\n            body = json.loads(json_buf.decode(enc, \"replace\"))\n        except:\n            raise Pebkac(422, \"you POSTed invalid json\")\n\n        # self.reply(b\"cloudflare\", 503)\n        # return True\n\n        if \"srch\" in self.uparam or \"srch\" in body:\n            return self.handle_search(body)\n\n        if \"delete\" in self.uparam:\n            return self.handle_rm(body)\n\n        name = undot(body[\"name\"])\n        if \"/\" in name:\n            raise Pebkac(400, \"your client is old; press CTRL-SHIFT-R and try again\")\n\n        vfs, rem = self.asrv.vfs.get(self.vpath, self.uname, False, True)\n        dbv, vrem = vfs.get_dbv(rem)\n\n        body[\"vtop\"] = dbv.vpath\n        body[\"ptop\"] = dbv.realpath\n        body[\"prel\"] = vrem\n        body[\"host\"] = self.host\n        body[\"user\"] = self.uname\n        body[\"addr\"] = self.ip\n        body[\"vcfg\"] = dbv.flags\n\n        if not self.can_delete:\n            body.pop(\"replace\", None)\n\n        if rem:\n            dst = vfs.canonical(rem)\n            try:\n                if not bos.path.isdir(dst):\n                    bos.makedirs(dst)\n            except OSError as ex:\n                self.log(\"makedirs failed [{}]\".format(dst))\n                if not bos.path.isdir(dst):\n                    if ex.errno == errno.EACCES:\n                        raise Pebkac(500, \"the server OS denied write-access\")\n\n                    if ex.errno == errno.EEXIST:\n                        raise Pebkac(400, \"some file got your folder name\")\n\n                    raise Pebkac(500, min_ex())\n            except:\n                raise Pebkac(500, min_ex())\n\n        x = self.conn.hsrv.broker.ask(\"up2k.handle_json\", body, self.u2fh.aps)\n        ret = x.get()\n        if self.is_vproxied:\n            if \"purl\" in ret:\n                ret[\"purl\"] = self.args.SR + ret[\"purl\"]\n\n        ret = json.dumps(ret)\n        self.log(ret)\n        self.reply(ret.encode(\"utf-8\"), mime=\"application/json\")\n        return True\n\n    def handle_search(self, body: dict[str, Any]) -> bool:\n        idx = self.conn.get_u2idx()\n        if not idx or not hasattr(idx, \"p_end\"):\n            raise Pebkac(500, \"sqlite3 is not available on the server; cannot search\")\n\n        vols = []\n        seen = {}\n        for vtop in self.rvol:\n            vfs, _ = self.asrv.vfs.get(vtop, self.uname, True, False)\n            vfs = vfs.dbv or vfs\n            if vfs in seen:\n                continue\n\n            seen[vfs] = True\n            vols.append((vfs.vpath, vfs.realpath, vfs.flags))\n\n        t0 = time.time()\n        if idx.p_end:\n            penalty = 0.7\n            t_idle = t0 - idx.p_end\n            if idx.p_dur > 0.7 and t_idle < penalty:\n                t = \"rate-limit {:.1f} sec, cost {:.2f}, idle {:.2f}\"\n                raise Pebkac(429, t.format(penalty, idx.p_dur, t_idle))\n\n        if \"srch\" in body:\n            # search by up2k hashlist\n            vbody = copy.deepcopy(body)\n            vbody[\"hash\"] = len(vbody[\"hash\"])\n            self.log(\"qj: \" + repr(vbody))\n            hits = idx.fsearch(vols, body)\n            msg: Any = repr(hits)\n            taglist: list[str] = []\n            trunc = False\n        else:\n            # search by query params\n            q = body[\"q\"]\n            n = body.get(\"n\", self.args.srch_hits)\n            self.log(\"qj: {} |{}|\".format(q, n))\n            hits, taglist, trunc = idx.search(vols, q, n)\n            msg = len(hits)\n\n        idx.p_end = time.time()\n        idx.p_dur = idx.p_end - t0\n        self.log(\"q#: {} ({:.2f}s)\".format(msg, idx.p_dur))\n\n        order = []\n        cfg = self.args.mte.split(\",\")\n        for t in cfg:\n            if t in taglist:\n                order.append(t)\n        for t in taglist:\n            if t not in order:\n                order.append(t)\n\n        if self.is_vproxied:\n            for hit in hits:\n                hit[\"rp\"] = self.args.RS + hit[\"rp\"]\n\n        rj = {\"hits\": hits, \"tag_order\": order, \"trunc\": trunc}\n        r = json.dumps(rj).encode(\"utf-8\")\n        self.reply(r, mime=\"application/json\")\n        return True\n\n    def handle_post_binary(self) -> bool:\n        try:\n            remains = int(self.headers[\"content-length\"])\n        except:\n            raise Pebkac(400, \"you must supply a content-length for binary POST\")\n\n        try:\n            chash = self.headers[\"x-up2k-hash\"]\n            wark = self.headers[\"x-up2k-wark\"]\n        except KeyError:\n            raise Pebkac(400, \"need hash and wark headers for binary POST\")\n\n        vfs, _ = self.asrv.vfs.get(self.vpath, self.uname, False, True)\n        ptop = (vfs.dbv or vfs).realpath\n\n        x = self.conn.hsrv.broker.ask(\"up2k.handle_chunk\", ptop, wark, chash)\n        response = x.get()\n        chunksize, cstart, path, lastmod, sprs = response\n\n        try:\n            if self.args.nw:\n                path = os.devnull\n\n            if remains > chunksize:\n                raise Pebkac(400, \"your chunk is too big to fit\")\n\n            self.log(\"writing {} #{} @{} len {}\".format(path, chash, cstart, remains))\n\n            reader = read_socket(self.sr, remains)\n\n            f = None\n            fpool = not self.args.no_fpool and sprs\n            if fpool:\n                with self.mutex:\n                    try:\n                        f = self.u2fh.pop(path)\n                    except:\n                        pass\n\n            f = f or open(fsenc(path), \"rb+\", 512 * 1024)\n\n            try:\n                f.seek(cstart[0])\n                post_sz, _, sha_b64 = hashcopy(reader, f, self.args.s_wr_slp)\n\n                if sha_b64 != chash:\n                    try:\n                        self.bakflip(f, cstart[0], post_sz, sha_b64)\n                    except:\n                        self.log(\"bakflip failed: \" + min_ex())\n\n                    t = \"your chunk got corrupted somehow (received {} bytes); expected vs received hash:\\n{}\\n{}\"\n                    raise Pebkac(400, t.format(post_sz, chash, sha_b64))\n\n                if len(cstart) > 1 and path != os.devnull:\n                    self.log(\n                        \"clone {} to {}\".format(\n                            cstart[0], \" & \".join(unicode(x) for x in cstart[1:])\n                        )\n                    )\n                    ofs = 0\n                    while ofs < chunksize:\n                        bufsz = min(chunksize - ofs, 4 * 1024 * 1024)\n                        f.seek(cstart[0] + ofs)\n                        buf = f.read(bufsz)\n                        for wofs in cstart[1:]:\n                            f.seek(wofs + ofs)\n                            f.write(buf)\n\n                        ofs += len(buf)\n\n                    self.log(\"clone {} done\".format(cstart[0]))\n\n                if not fpool:\n                    f.close()\n                else:\n                    with self.mutex:\n                        self.u2fh.put(path, f)\n            except:\n                # maybe busted handle (eg. disk went full)\n                f.close()\n                raise\n        finally:\n            x = self.conn.hsrv.broker.ask(\"up2k.release_chunk\", ptop, wark, chash)\n            x.get()  # block client until released\n\n        x = self.conn.hsrv.broker.ask(\"up2k.confirm_chunk\", ptop, wark, chash)\n        ztis = x.get()\n        try:\n            num_left, fin_path = ztis\n        except:\n            self.loud_reply(ztis, status=500)\n            return False\n\n        if not num_left and fpool:\n            with self.mutex:\n                self.u2fh.close(path)\n\n        if not num_left and not self.args.nw:\n            self.conn.hsrv.broker.ask(\n                \"up2k.finish_upload\", ptop, wark, self.u2fh.aps\n            ).get()\n\n        cinf = self.headers.get(\"x-up2k-stat\", \"\")\n\n        spd = self._spd(post_sz)\n        self.log(\"{:70} thank {}\".format(spd, cinf))\n        self.reply(b\"thank\")\n        return True\n\n    def handle_login(self) -> bool:\n        assert self.parser\n        pwd = self.parser.require(\"cppwd\", 64)\n        self.parser.drop()\n\n        self.out_headerlist = [\n            x for x in self.out_headerlist if x[0] != \"Set-Cookie\" or \"cppw\" != x[1][:4]\n        ]\n\n        dst = self.args.SRS\n        if self.vpath:\n            dst += quotep(self.vpath)\n\n        msg = self.get_pwd_cookie(pwd)\n        html = self.j2s(\"msg\", h1=msg, h2='<a href=\"' + dst + '\">ack</a>', redir=dst)\n        self.reply(html.encode(\"utf-8\"))\n        return True\n\n    def get_pwd_cookie(self, pwd: str) -> str:\n        if self.asrv.ah.hash(pwd) in self.asrv.iacct:\n            msg = \"login ok\"\n            dur = int(60 * 60 * self.args.logout)\n        else:\n            self.log(\"invalid password: {}\".format(pwd), 3)\n            g = self.conn.hsrv.gpwd\n            if g.lim:\n                bonk, ip = g.bonk(self.ip, pwd)\n                if bonk:\n                    xban = self.vn.flags.get(\"xban\")\n                    if not xban or not runhook(\n                        self.log,\n                        xban,\n                        self.vn.canonical(self.rem),\n                        self.vpath,\n                        self.host,\n                        self.uname,\n                        time.time(),\n                        0,\n                        self.ip,\n                        time.time(),\n                        \"pw\",\n                    ):\n                        self.log(\"client banned: invalid passwords\", 1)\n                        self.conn.hsrv.bans[ip] = bonk\n\n            msg = \"naw dude\"\n            pwd = \"x\"  # nosec\n            dur = None\n\n        if pwd == \"x\":\n            # reset both plaintext and tls\n            # (only affects active tls cookies when tls)\n            for k in (\"cppwd\", \"cppws\") if self.is_https else (\"cppwd\",):\n                ck = gencookie(k, pwd, self.args.R, False, dur)\n                self.out_headerlist.append((\"Set-Cookie\", ck))\n        else:\n            k = \"cppws\" if self.is_https else \"cppwd\"\n            ck = gencookie(k, pwd, self.args.R, self.is_https, dur)\n            self.out_headerlist.append((\"Set-Cookie\", ck))\n\n        return msg\n\n    def handle_mkdir(self) -> bool:\n        assert self.parser\n        new_dir = self.parser.require(\"name\", 512)\n        self.parser.drop()\n\n        sanitized = sanitize_fn(new_dir, \"\", [])\n        return self._mkdir(vjoin(self.vpath, sanitized))\n\n    def _mkdir(self, vpath: str, dav: bool = False) -> bool:\n        nullwrite = self.args.nw\n        vfs, rem = self.asrv.vfs.get(vpath, self.uname, False, True)\n        self._assert_safe_rem(rem)\n        fn = vfs.canonical(rem)\n\n        if not nullwrite:\n            fdir = os.path.dirname(fn)\n\n            if not bos.path.isdir(fdir):\n                raise Pebkac(409, \"parent folder does not exist\")\n\n            if bos.path.isdir(fn):\n                raise Pebkac(405, \"that folder exists already\")\n\n            try:\n                bos.mkdir(fn)\n            except OSError as ex:\n                if ex.errno == errno.EACCES:\n                    raise Pebkac(500, \"the server OS denied write-access\")\n\n                raise Pebkac(500, \"mkdir failed:\\n\" + min_ex())\n            except:\n                raise Pebkac(500, min_ex())\n\n        self.out_headers[\"X-New-Dir\"] = quotep(vpath.split(\"/\")[-1])\n\n        if dav:\n            self.reply(b\"\", 201)\n        else:\n            self.redirect(vpath, status=201)\n\n        return True\n\n    def handle_new_md(self) -> bool:\n        assert self.parser\n        new_file = self.parser.require(\"name\", 512)\n        self.parser.drop()\n\n        nullwrite = self.args.nw\n        vfs, rem = self.asrv.vfs.get(self.vpath, self.uname, False, True)\n        self._assert_safe_rem(rem)\n\n        if not new_file.endswith(\".md\"):\n            new_file += \".md\"\n\n        sanitized = sanitize_fn(new_file, \"\", [])\n\n        if not nullwrite:\n            fdir = vfs.canonical(rem)\n            fn = os.path.join(fdir, sanitized)\n\n            if bos.path.exists(fn):\n                raise Pebkac(500, \"that file exists already\")\n\n            with open(fsenc(fn), \"wb\") as f:\n                f.write(b\"`GRUNNUR`\\n\")\n\n        vpath = \"{}/{}\".format(self.vpath, sanitized).lstrip(\"/\")\n        self.redirect(vpath, \"?edit\")\n        return True\n\n    def upload_flags(self, vfs: VFS) -> tuple[int, bool, int, list[str], list[str]]:\n        if self.args.nw:\n            rnd = 0\n        else:\n            rnd = int(self.uparam.get(\"rand\") or self.headers.get(\"rand\") or 0)\n            if vfs.flags.get(\"rand\"):  # force-enable\n                rnd = max(rnd, vfs.flags[\"nrand\"])\n\n        ac = self.uparam.get(\n            \"want\", self.headers.get(\"accept\", \"\").lower().split(\";\")[-1]\n        )\n        want_url = ac == \"url\"\n        zs = self.uparam.get(\"life\", self.headers.get(\"life\", \"\"))\n        if zs:\n            vlife = vfs.flags.get(\"lifetime\") or 0\n            lifetime = max(0, int(vlife - int(zs)))\n        else:\n            lifetime = 0\n\n        return (\n            rnd,\n            want_url,\n            lifetime,\n            vfs.flags.get(\"xbu\") or [],\n            vfs.flags.get(\"xau\") or [],\n        )\n\n    def handle_plain_upload(self) -> bool:\n        assert self.parser\n        nullwrite = self.args.nw\n        vfs, rem = self.asrv.vfs.get(self.vpath, self.uname, False, True)\n        self._assert_safe_rem(rem)\n\n        upload_vpath = self.vpath\n        lim = vfs.get_dbv(rem)[0].lim\n        fdir_base = vfs.canonical(rem)\n        if lim:\n            fdir_base, rem = lim.all(\n                self.ip, rem, -1, vfs.realpath, fdir_base, self.conn.hsrv.broker\n            )\n            upload_vpath = \"{}/{}\".format(vfs.vpath, rem).strip(\"/\")\n            if not nullwrite:\n                bos.makedirs(fdir_base)\n\n        rnd, want_url, lifetime, xbu, xau = self.upload_flags(vfs)\n\n        files: list[tuple[int, str, str, str, str, str]] = []\n        # sz, sha_hex, sha_b64, p_file, fname, abspath\n        errmsg = \"\"\n        dip = self.dip()\n        t0 = time.time()\n        try:\n            assert self.parser.gen\n            for nfile, (p_field, p_file, p_data) in enumerate(self.parser.gen):\n                if not p_file:\n                    self.log(\"discarding incoming file without filename\")\n                    # fallthrough\n\n                fdir = fdir_base\n                fname = sanitize_fn(\n                    p_file or \"\", \"\", [\".prologue.html\", \".epilogue.html\"]\n                )\n                if p_file and not nullwrite:\n                    if rnd:\n                        fname = rand_name(fdir, fname, rnd)\n\n                    if not bos.path.isdir(fdir):\n                        raise Pebkac(404, \"that folder does not exist\")\n\n                    suffix = \"-{:.6f}-{}\".format(time.time(), dip)\n                    open_args = {\"fdir\": fdir, \"suffix\": suffix}\n\n                    # reserve destination filename\n                    with ren_open(fname, \"wb\", fdir=fdir, suffix=suffix) as zfw:\n                        fname = zfw[\"orz\"][1]\n\n                    tnam = fname + \".PARTIAL\"\n                    if self.args.dotpart:\n                        tnam = \".\" + tnam\n\n                    abspath = os.path.join(fdir, fname)\n                else:\n                    open_args = {}\n                    tnam = fname = os.devnull\n                    fdir = abspath = \"\"\n\n                if xbu:\n                    at = time.time() - lifetime\n                    if not runhook(\n                        self.log,\n                        xbu,\n                        abspath,\n                        self.vpath,\n                        self.host,\n                        self.uname,\n                        at,\n                        0,\n                        self.ip,\n                        at,\n                        \"\",\n                    ):\n                        t = \"upload blocked by xbu server config\"\n                        self.log(t, 1)\n                        raise Pebkac(403, t)\n\n                if lim:\n                    lim.chk_bup(self.ip)\n                    lim.chk_nup(self.ip)\n\n                try:\n                    max_sz = 0\n                    if lim:\n                        v1 = lim.smax\n                        v2 = lim.dfv - lim.dfl\n                        max_sz = min(v1, v2) if v1 and v2 else v1 or v2\n\n                    with ren_open(tnam, \"wb\", 512 * 1024, **open_args) as zfw:\n                        f, tnam = zfw[\"orz\"]\n                        tabspath = os.path.join(fdir, tnam)\n                        self.log(\"writing to {}\".format(tabspath))\n                        sz, sha_hex, sha_b64 = hashcopy(\n                            p_data, f, self.args.s_wr_slp, max_sz\n                        )\n                        if sz == 0:\n                            raise Pebkac(400, \"empty files in post\")\n\n                    if lim:\n                        lim.nup(self.ip)\n                        lim.bup(self.ip, sz)\n                        try:\n                            lim.chk_df(tabspath, sz, True)\n                            lim.chk_sz(sz)\n                            lim.chk_vsz(self.conn.hsrv.broker, vfs.realpath, sz)\n                            lim.chk_bup(self.ip)\n                            lim.chk_nup(self.ip)\n                        except:\n                            if not nullwrite:\n                                bos.unlink(tabspath)\n                                bos.unlink(abspath)\n                            fname = os.devnull\n                            raise\n\n                    if not nullwrite:\n                        atomic_move(tabspath, abspath)\n\n                    files.append(\n                        (sz, sha_hex, sha_b64, p_file or \"(discarded)\", fname, abspath)\n                    )\n                    at = time.time() - lifetime\n                    if xau and not runhook(\n                        self.log,\n                        xau,\n                        abspath,\n                        self.vpath,\n                        self.host,\n                        self.uname,\n                        at,\n                        sz,\n                        self.ip,\n                        at,\n                        \"\",\n                    ):\n                        t = \"upload blocked by xau server config\"\n                        self.log(t, 1)\n                        os.unlink(abspath)\n                        raise Pebkac(403, t)\n\n                    dbv, vrem = vfs.get_dbv(rem)\n                    self.conn.hsrv.broker.say(\n                        \"up2k.hash_file\",\n                        dbv.realpath,\n                        vfs.vpath,\n                        dbv.flags,\n                        vrem,\n                        fname,\n                        self.ip,\n                        at,\n                        self.uname,\n                        True,\n                    )\n                    self.conn.nbyte += sz\n\n                except Pebkac:\n                    self.parser.drop()\n                    raise\n\n        except Pebkac as ex:\n            errmsg = vol_san(\n                list(self.asrv.vfs.all_vols.values()), unicode(ex).encode(\"utf-8\")\n            ).decode(\"utf-8\")\n\n        td = max(0.1, time.time() - t0)\n        sz_total = sum(x[0] for x in files)\n        spd = (sz_total / td) / (1024 * 1024)\n\n        status = \"OK\"\n        if errmsg:\n            self.log(errmsg, 3)\n            status = \"ERROR\"\n\n        msg = \"{} // {} bytes // {:.3f} MiB/s\\n\".format(status, sz_total, spd)\n        jmsg: dict[str, Any] = {\n            \"status\": status,\n            \"sz\": sz_total,\n            \"mbps\": round(spd, 3),\n            \"files\": [],\n        }\n\n        if errmsg:\n            msg += errmsg + \"\\n\"\n            jmsg[\"error\"] = errmsg\n            errmsg = \"ERROR: \" + errmsg\n\n        for sz, sha_hex, sha_b64, ofn, lfn, ap in files:\n            vsuf = \"\"\n            if (self.can_read or self.can_upget) and \"fk\" in vfs.flags:\n                vsuf = \"?k=\" + self.gen_fk(\n                    self.args.fk_salt,\n                    ap,\n                    sz,\n                    0 if ANYWIN or not ap else bos.stat(ap).st_ino,\n                )[: vfs.flags[\"fk\"]]\n\n            vpath = \"{}/{}\".format(upload_vpath, lfn).strip(\"/\")\n            rel_url = quotep(self.args.RS + vpath) + vsuf\n            msg += 'sha512: {} // {} // {} bytes // <a href=\"/{}\">{}</a> {}\\n'.format(\n                sha_hex[:56],\n                sha_b64,\n                sz,\n                rel_url,\n                html_escape(ofn, crlf=True),\n                vsuf,\n            )\n            # truncated SHA-512 prevents length extension attacks;\n            # using SHA-512/224, optionally SHA-512/256 = :64\n            jpart = {\n                \"url\": \"{}://{}/{}\".format(\n                    \"https\" if self.is_https else \"http\",\n                    self.host,\n                    rel_url,\n                ),\n                \"sha512\": sha_hex[:56],\n                \"sha_b64\": sha_b64,\n                \"sz\": sz,\n                \"fn\": lfn,\n                \"fn_orig\": ofn,\n                \"path\": rel_url,\n            }\n            jmsg[\"files\"].append(jpart)\n\n        vspd = self._spd(sz_total, False)\n        self.log(\"{} {}\".format(vspd, msg))\n\n        suf = \"\"\n        if not nullwrite and self.args.write_uplog:\n            try:\n                log_fn = \"up.{:.6f}.txt\".format(t0)\n                with open(log_fn, \"wb\") as f:\n                    ft = \"{}:{}\".format(self.ip, self.addr[1])\n                    ft = \"{}\\n{}\\n{}\\n\".format(ft, msg.rstrip(), errmsg)\n                    f.write(ft.encode(\"utf-8\"))\n            except Exception as ex:\n                suf = \"\\nfailed to write the upload report: {}\".format(ex)\n\n        sc = 400 if errmsg else 201\n        if want_url:\n            msg = \"\\n\".join([x[\"url\"] for x in jmsg[\"files\"]])\n            if errmsg:\n                msg += \"\\n\" + errmsg\n\n            self.reply(msg.encode(\"utf-8\", \"replace\"), status=sc)\n        elif \"j\" in self.uparam:\n            jtxt = json.dumps(jmsg, indent=2, sort_keys=True).encode(\"utf-8\", \"replace\")\n            self.reply(jtxt, mime=\"application/json\", status=sc)\n        else:\n            self.redirect(\n                self.vpath,\n                msg=msg + suf,\n                flavor=\"return to\",\n                click=False,\n                status=sc,\n            )\n\n        if errmsg:\n            return False\n\n        self.parser.drop()\n        return True\n\n    def handle_text_upload(self) -> bool:\n        assert self.parser\n        try:\n            cli_lastmod3 = int(self.parser.require(\"lastmod\", 16))\n        except:\n            raise Pebkac(400, \"could not read lastmod from request\")\n\n        nullwrite = self.args.nw\n        vfs, rem = self.asrv.vfs.get(self.vpath, self.uname, True, True)\n        self._assert_safe_rem(rem)\n\n        clen = int(self.headers.get(\"content-length\", -1))\n        if clen == -1:\n            raise Pebkac(411)\n\n        rp, fn = vsplit(rem)\n        fp = vfs.canonical(rp)\n        lim = vfs.get_dbv(rem)[0].lim\n        if lim:\n            fp, rp = lim.all(self.ip, rp, clen, vfs.realpath, fp, self.conn.hsrv.broker)\n            bos.makedirs(fp)\n\n        fp = os.path.join(fp, fn)\n        rem = \"{}/{}\".format(rp, fn).strip(\"/\")\n\n        if not rem.endswith(\".md\"):\n            raise Pebkac(400, \"only markdown pls\")\n\n        if nullwrite:\n            response = json.dumps({\"ok\": True, \"lastmod\": 0})\n            self.log(response)\n            # TODO reply should parser.drop()\n            self.parser.drop()\n            self.reply(response.encode(\"utf-8\"))\n            return True\n\n        srv_lastmod = -1.0\n        srv_lastmod3 = -1\n        try:\n            st = bos.stat(fp)\n            srv_lastmod = st.st_mtime\n            srv_lastmod3 = int(srv_lastmod * 1000)\n        except OSError as ex:\n            if ex.errno != errno.ENOENT:\n                raise\n\n        # if file exists, chekc that timestamp matches the client's\n        if srv_lastmod >= 0:\n            same_lastmod = cli_lastmod3 in [-1, srv_lastmod3]\n            if not same_lastmod:\n                # some filesystems/transports limit precision to 1sec, hopefully floored\n                same_lastmod = (\n                    srv_lastmod == int(cli_lastmod3 / 1000)\n                    and cli_lastmod3 > srv_lastmod3\n                    and cli_lastmod3 - srv_lastmod3 < 1000\n                )\n\n            if not same_lastmod:\n                response = json.dumps(\n                    {\n                        \"ok\": False,\n                        \"lastmod\": srv_lastmod3,\n                        \"now\": int(time.time() * 1000),\n                    }\n                )\n                self.log(\n                    \"{} - {} = {}\".format(\n                        srv_lastmod3, cli_lastmod3, srv_lastmod3 - cli_lastmod3\n                    )\n                )\n                self.log(response)\n                self.parser.drop()\n                self.reply(response.encode(\"utf-8\"))\n                return True\n\n            mdir, mfile = os.path.split(fp)\n            mfile2 = \"{}.{:.3f}.md\".format(mfile[:-3], srv_lastmod)\n            try:\n                dp = os.path.join(mdir, \".hist\")\n                bos.mkdir(dp)\n                hidedir(dp)\n            except:\n                pass\n            bos.rename(fp, os.path.join(mdir, \".hist\", mfile2))\n\n        assert self.parser.gen\n        p_field, _, p_data = next(self.parser.gen)\n        if p_field != \"body\":\n            raise Pebkac(400, \"expected body, got {}\".format(p_field))\n\n        xbu = vfs.flags.get(\"xbu\")\n        if xbu:\n            if not runhook(\n                self.log,\n                xbu,\n                fp,\n                self.vpath,\n                self.host,\n                self.uname,\n                time.time(),\n                0,\n                self.ip,\n                time.time(),\n                \"\",\n            ):\n                t = \"save blocked by xbu server config\"\n                self.log(t, 1)\n                raise Pebkac(403, t)\n\n        if bos.path.exists(fp):\n            bos.unlink(fp)\n\n        with open(fsenc(fp), \"wb\", 512 * 1024) as f:\n            sz, sha512, _ = hashcopy(p_data, f, self.args.s_wr_slp)\n\n        if lim:\n            lim.nup(self.ip)\n            lim.bup(self.ip, sz)\n            try:\n                lim.chk_sz(sz)\n                lim.chk_vsz(self.conn.hsrv.broker, vfs.realpath, sz)\n            except:\n                bos.unlink(fp)\n                raise\n\n        new_lastmod = bos.stat(fp).st_mtime\n        new_lastmod3 = int(new_lastmod * 1000)\n        sha512 = sha512[:56]\n\n        xau = vfs.flags.get(\"xau\")\n        if xau and not runhook(\n            self.log,\n            xau,\n            fp,\n            self.vpath,\n            self.host,\n            self.uname,\n            new_lastmod,\n            sz,\n            self.ip,\n            new_lastmod,\n            \"\",\n        ):\n            t = \"save blocked by xau server config\"\n            self.log(t, 1)\n            os.unlink(fp)\n            raise Pebkac(403, t)\n\n        vfs, rem = vfs.get_dbv(rem)\n        self.conn.hsrv.broker.say(\n            \"up2k.hash_file\",\n            vfs.realpath,\n            vfs.vpath,\n            vfs.flags,\n            vsplit(rem)[0],\n            fn,\n            self.ip,\n            new_lastmod,\n            self.uname,\n            True,\n        )\n\n        response = json.dumps(\n            {\"ok\": True, \"lastmod\": new_lastmod3, \"size\": sz, \"sha512\": sha512}\n        )\n        self.log(response)\n        self.parser.drop()\n        self.reply(response.encode(\"utf-8\"))\n        return True\n\n    def _chk_lastmod(self, file_ts: int) -> tuple[str, bool]:\n        file_lastmod = formatdate(file_ts, usegmt=True)\n        cli_lastmod = self.headers.get(\"if-modified-since\")\n        if cli_lastmod:\n            try:\n                # some browser append \"; length=573\"\n                cli_lastmod = cli_lastmod.split(\";\")[0].strip()\n                cli_dt = parsedate(cli_lastmod)\n                assert cli_dt\n                cli_ts = calendar.timegm(cli_dt)\n                return file_lastmod, int(file_ts) > int(cli_ts)\n            except Exception as ex:\n                self.log(\n                    \"lastmod {}\\nremote: [{}]\\n local: [{}]\".format(\n                        repr(ex), cli_lastmod, file_lastmod\n                    )\n                )\n                return file_lastmod, file_lastmod != cli_lastmod\n\n        return file_lastmod, True\n\n    def tx_file(self, req_path: str) -> bool:\n        status = 200\n        logmsg = \"{:4} {} \".format(\"\", self.req)\n        logtail = \"\"\n\n        #\n        # if request is for foo.js, check if we have foo.js.{gz,br}\n\n        file_ts = 0\n        editions: dict[str, tuple[str, int]] = {}\n        for ext in [\"\", \".gz\", \".br\"]:\n            try:\n                fs_path = req_path + ext\n                st = bos.stat(fs_path)\n                if stat.S_ISDIR(st.st_mode):\n                    continue\n\n                if stat.S_ISBLK(st.st_mode):\n                    fd = bos.open(fs_path, os.O_RDONLY)\n                    try:\n                        sz = os.lseek(fd, 0, os.SEEK_END)\n                    finally:\n                        os.close(fd)\n                else:\n                    sz = st.st_size\n\n                file_ts = max(file_ts, int(st.st_mtime))\n                editions[ext or \"plain\"] = (fs_path, sz)\n            except:\n                pass\n            if not self.vpath.startswith(\".cpr/\"):\n                break\n\n        if not editions:\n            return self.tx_404()\n\n        #\n        # if-modified\n\n        file_lastmod, do_send = self._chk_lastmod(file_ts)\n        self.out_headers[\"Last-Modified\"] = file_lastmod\n        if not do_send:\n            status = 304\n\n        #\n        # Accept-Encoding and UA decides which edition to send\n\n        decompress = False\n        supported_editions = [\n            x.strip()\n            for x in self.headers.get(\"accept-encoding\", \"\").lower().split(\",\")\n        ]\n        if \".br\" in editions and \"br\" in supported_editions:\n            is_compressed = True\n            selected_edition = \".br\"\n            fs_path, file_sz = editions[\".br\"]\n            self.out_headers[\"Content-Encoding\"] = \"br\"\n        elif \".gz\" in editions:\n            is_compressed = True\n            selected_edition = \".gz\"\n            fs_path, file_sz = editions[\".gz\"]\n            if \"gzip\" not in supported_editions:\n                decompress = True\n            else:\n                if re.match(r\"MSIE [4-6]\\.\", self.ua) and \" SV1\" not in self.ua:\n                    decompress = True\n\n            if not decompress:\n                self.out_headers[\"Content-Encoding\"] = \"gzip\"\n        else:\n            is_compressed = False\n            selected_edition = \"plain\"\n\n        try:\n            fs_path, file_sz = editions[selected_edition]\n            logmsg += \"{} \".format(selected_edition.lstrip(\".\"))\n        except:\n            # client is old and we only have .br\n            # (could make brotli a dep to fix this but it's not worth)\n            raise Pebkac(404)\n\n        #\n        # partial\n\n        lower = 0\n        upper = file_sz\n        hrange = self.headers.get(\"range\")\n\n        # let's not support 206 with compression\n        # and multirange / multipart is also not-impl (mostly because calculating contentlength is a pain)\n        if do_send and not is_compressed and hrange and file_sz and \",\" not in hrange:\n            try:\n                if not hrange.lower().startswith(\"bytes\"):\n                    raise Exception()\n\n                a, b = hrange.split(\"=\", 1)[1].split(\"-\")\n\n                if a.strip():\n                    lower = int(a.strip())\n                else:\n                    lower = 0\n\n                if b.strip():\n                    upper = int(b.strip()) + 1\n                else:\n                    upper = file_sz\n\n                if upper > file_sz:\n                    upper = file_sz\n\n                if lower < 0 or lower >= upper:\n                    raise Exception()\n\n            except:\n                err = \"invalid range ({}), size={}\".format(hrange, file_sz)\n                self.loud_reply(\n                    err,\n                    status=416,\n                    headers={\"Content-Range\": \"bytes */{}\".format(file_sz)},\n                )\n                return True\n\n            status = 206\n            self.out_headers[\"Content-Range\"] = \"bytes {}-{}/{}\".format(\n                lower, upper - 1, file_sz\n            )\n\n            logtail += \" [\\033[36m{}-{}\\033[0m]\".format(lower, upper)\n\n        use_sendfile = False\n        if decompress:\n            open_func: Any = gzip.open\n            open_args: list[Any] = [fsenc(fs_path), \"rb\"]\n            # Content-Length := original file size\n            upper = gzip_orig_sz(fs_path)\n        else:\n            open_func = open\n            # 512 kB is optimal for huge files, use 64k\n            open_args = [fsenc(fs_path), \"rb\", 64 * 1024]\n            use_sendfile = (\n                not self.tls  #\n                and not self.args.no_sendfile\n                and hasattr(os, \"sendfile\")\n            )\n\n        #\n        # send reply\n\n        if is_compressed:\n            self.out_headers[\"Cache-Control\"] = \"max-age=604869\"\n        else:\n            self.permit_caching()\n\n        if \"txt\" in self.uparam:\n            mime = \"text/plain; charset={}\".format(self.uparam[\"txt\"] or \"utf-8\")\n        elif \"mime\" in self.uparam:\n            mime = str(self.uparam.get(\"mime\"))\n        else:\n            mime = guess_mime(req_path)\n\n        if \"nohtml\" in self.vn.flags and \"html\" in mime:\n            mime = \"text/plain; charset=utf-8\"\n\n        self.out_headers[\"Accept-Ranges\"] = \"bytes\"\n        self.send_headers(length=upper - lower, status=status, mime=mime)\n\n        logmsg += unicode(status) + logtail\n\n        if self.mode == \"HEAD\" or not do_send:\n            if self.do_log:\n                self.log(logmsg)\n\n            return True\n\n        ret = True\n        with open_func(*open_args) as f:\n            sendfun = sendfile_kern if use_sendfile else sendfile_py\n            remains = sendfun(\n                self.log, lower, upper, f, self.s, self.args.s_wr_sz, self.args.s_wr_slp\n            )\n\n        if remains > 0:\n            logmsg += \" \\033[31m\" + unicode(upper - remains) + \"\\033[0m\"\n            self.keepalive = False\n\n        spd = self._spd((upper - lower) - remains)\n        if self.do_log:\n            self.log(\"{},  {}\".format(logmsg, spd))\n\n        return ret\n\n    def tx_zip(\n        self,\n        fmt: str,\n        uarg: str,\n        vpath: str,\n        vn: VFS,\n        rem: str,\n        items: list[str],\n        dots: bool,\n    ) -> bool:\n        if self.args.no_zip:\n            raise Pebkac(400, \"not enabled\")\n\n        logmsg = \"{:4} {} \".format(\"\", self.req)\n        self.keepalive = False\n\n        if fmt == \"tar\":\n            mime = \"application/x-tar\"\n            packer: Type[StreamArc] = StreamTar\n        else:\n            mime = \"application/zip\"\n            packer = StreamZip\n\n        fn = items[0] if items and items[0] else self.vpath\n        if fn:\n            fn = fn.rstrip(\"/\").split(\"/\")[-1]\n        else:\n            fn = self.host.split(\":\")[0]\n\n        safe = (string.ascii_letters + string.digits).replace(\"%\", \"\")\n        afn = \"\".join([x if x in safe.replace('\"', \"\") else \"_\" for x in fn])\n        bascii = unicode(safe).encode(\"utf-8\")\n        zb = fn.encode(\"utf-8\", \"xmlcharrefreplace\")\n        if not PY2:\n            zbl = [\n                chr(x).encode(\"utf-8\")\n                if x in bascii\n                else \"%{:02x}\".format(x).encode(\"ascii\")\n                for x in zb\n            ]\n        else:\n            zbl = [unicode(x) if x in bascii else \"%{:02x}\".format(ord(x)) for x in zb]\n\n        ufn = b\"\".join(zbl).decode(\"ascii\")\n\n        cdis = \"attachment; filename=\\\"{}.{}\\\"; filename*=UTF-8''{}.{}\"\n        cdis = cdis.format(afn, fmt, ufn, fmt)\n        self.log(cdis)\n        self.send_headers(None, mime=mime, headers={\"Content-Disposition\": cdis})\n\n        fgen = vn.zipgen(\n            vpath, rem, set(items), self.uname, dots, False, not self.args.no_scandir\n        )\n        # for f in fgen: print(repr({k: f[k] for k in [\"vp\", \"ap\"]}))\n        bgen = packer(self.log, fgen, utf8=\"utf\" in uarg, pre_crc=\"crc\" in uarg)\n        bsent = 0\n        for buf in bgen.gen():\n            if not buf:\n                break\n\n            try:\n                self.s.sendall(buf)\n                bsent += len(buf)\n            except:\n                logmsg += \" \\033[31m\" + unicode(bsent) + \"\\033[0m\"\n                break\n\n        spd = self._spd(bsent)\n        self.log(\"{},  {}\".format(logmsg, spd))\n        return True\n\n    def tx_ico(self, ext: str, exact: bool = False) -> bool:\n        self.permit_caching()\n        if ext.endswith(\"/\"):\n            ext = \"folder\"\n            exact = True\n\n        bad = re.compile(r\"[](){}/ []|^[0-9_-]*$\")\n        n = ext.split(\".\")[::-1]\n        if not exact:\n            n = n[:-1]\n\n        ext = \"\"\n        for v in n:\n            if len(v) > 7 or bad.search(v):\n                break\n\n            ext = \"{}.{}\".format(v, ext)\n\n        ext = ext.rstrip(\".\") or \"unk\"\n        if len(ext) > 11:\n            ext = \"\u22ef\" + ext[-9:]\n\n        # chrome cannot handle more than ~2000 unique SVGs\n        chrome = \" rv:\" not in self.ua\n        mime, ico = self.ico.get(ext, not exact, chrome)\n\n        lm = formatdate(self.E.t0, usegmt=True)\n        self.reply(ico, mime=mime, headers={\"Last-Modified\": lm})\n        return True\n\n    def tx_md(self, fs_path: str) -> bool:\n        logmsg = \"     %s @%s \" % (self.req, self.uname)\n\n        if not self.can_write:\n            if \"edit\" in self.uparam or \"edit2\" in self.uparam:\n                return self.tx_404(True)\n\n        tpl = \"mde\" if \"edit2\" in self.uparam else \"md\"\n        html_path = os.path.join(self.E.mod, \"web\", \"{}.html\".format(tpl))\n        template = self.j2j(tpl)\n\n        st = bos.stat(fs_path)\n        ts_md = st.st_mtime\n\n        st = bos.stat(html_path)\n        ts_html = st.st_mtime\n\n        sz_md = 0\n        for buf in yieldfile(fs_path):\n            sz_md += len(buf)\n            for c, v in [(b\"&\", 4), (b\"<\", 3), (b\">\", 3)]:\n                sz_md += (len(buf) - len(buf.replace(c, b\"\"))) * v\n\n        file_ts = int(max(ts_md, ts_html, self.E.t0))\n        file_lastmod, do_send = self._chk_lastmod(file_ts)\n        self.out_headers[\"Last-Modified\"] = file_lastmod\n        self.out_headers.update(NO_CACHE)\n        status = 200 if do_send else 304\n\n        arg_base = \"?\"\n        if \"k\" in self.uparam:\n            arg_base = \"?k={}&\".format(self.uparam[\"k\"])\n\n        boundary = \"\\roll\\tide\"\n        targs = {\n            \"r\": self.args.SR if self.is_vproxied else \"\",\n            \"ts\": self.conn.hsrv.cachebuster(),\n            \"svcname\": self.args.doctitle,\n            \"html_head\": self.html_head,\n            \"edit\": \"edit\" in self.uparam,\n            \"title\": html_escape(self.vpath, crlf=True),\n            \"lastmod\": int(ts_md * 1000),\n            \"lang\": self.args.lang,\n            \"favico\": self.args.favico,\n            \"have_emp\": self.args.emp,\n            \"md_chk_rate\": self.args.mcr,\n            \"md\": boundary,\n            \"arg_base\": arg_base,\n        }\n        zs = template.render(**targs).encode(\"utf-8\", \"replace\")\n        html = zs.split(boundary.encode(\"utf-8\"))\n        if len(html) != 2:\n            raise Exception(\"boundary appears in \" + html_path)\n\n        self.send_headers(sz_md + len(html[0]) + len(html[1]), status)\n\n        logmsg += unicode(status)\n        if self.mode == \"HEAD\" or not do_send:\n            if self.do_log:\n                self.log(logmsg)\n\n            return True\n\n        try:\n            self.s.sendall(html[0])\n            for buf in yieldfile(fs_path):\n                self.s.sendall(html_bescape(buf))\n\n            self.s.sendall(html[1])\n\n        except:\n            self.log(logmsg + \" \\033[31md/c\\033[0m\")\n            return False\n\n        if self.do_log:\n            self.log(logmsg + \" \" + unicode(len(html)))\n\n        return True\n\n    def tx_svcs(self) -> bool:\n        aname = re.sub(\"[^0-9a-zA-Z]+\", \"\", self.args.name) or \"a\"\n        ep = self.host\n        host = ep.split(\":\")[0]\n        hport = ep[ep.find(\":\") :] if \":\" in ep else \"\"\n        rip = (\n            host\n            if self.args.rclone_mdns or not self.args.zm\n            else self.conn.hsrv.nm.map(self.ip) or host\n        )\n        vp = (self.uparam[\"hc\"] or \"\").lstrip(\"/\")\n        html = self.j2s(\n            \"svcs\",\n            args=self.args,\n            accs=bool(self.asrv.acct),\n            s=\"s\" if self.is_https else \"\",\n            rip=rip,\n            ep=ep,\n            vp=vp,\n            rvp=vjoin(self.args.R, vp),\n            host=host,\n            hport=hport,\n            aname=aname,\n            pw=self.pw or \"pw\",\n        )\n        self.reply(html.encode(\"utf-8\"))\n        return True\n\n    def tx_mounts(self) -> bool:\n        suf = self.urlq({}, [\"h\"])\n        avol = [x for x in self.wvol if x in self.rvol]\n        rvol, wvol, avol = [\n            [(\"/\" + x).rstrip(\"/\") + \"/\" for x in y]\n            for y in [self.rvol, self.wvol, avol]\n        ]\n\n        if avol and not self.args.no_rescan:\n            x = self.conn.hsrv.broker.ask(\"up2k.get_state\")\n            vs = json.loads(x.get())\n            vstate = {(\"/\" + k).rstrip(\"/\") + \"/\": v for k, v in vs[\"volstate\"].items()}\n        else:\n            vstate = {}\n            vs = {\n                \"scanning\": None,\n                \"hashq\": None,\n                \"tagq\": None,\n                \"mtpq\": None,\n                \"dbwt\": None,\n            }\n\n        fmt = self.uparam.get(\"ls\", \"\")\n        if not fmt and (self.ua.startswith(\"curl/\") or self.ua.startswith(\"fetch\")):\n            fmt = \"v\"\n\n        if fmt in [\"v\", \"t\", \"txt\"]:\n            if self.uname == \"*\":\n                txt = \"howdy stranger (you're not logged in)\"\n            else:\n                txt = \"welcome back {}\".format(self.uname)\n\n            if vstate:\n                txt += \"\\nstatus:\"\n                for k in [\"scanning\", \"hashq\", \"tagq\", \"mtpq\", \"dbwt\"]:\n                    txt += \" {}({})\".format(k, vs[k])\n\n            if rvol:\n                txt += \"\\nyou can browse:\"\n                for v in rvol:\n                    txt += \"\\n  \" + v\n\n            if wvol:\n                txt += \"\\nyou can upload to:\"\n                for v in wvol:\n                    txt += \"\\n  \" + v\n\n            zb = txt.encode(\"utf-8\", \"replace\") + b\"\\n\"\n            self.reply(zb, mime=\"text/plain; charset=utf-8\")\n            return True\n\n        html = self.j2s(\n            \"splash\",\n            this=self,\n            qvpath=quotep(self.vpath),\n            rvol=rvol,\n            wvol=wvol,\n            avol=avol,\n            vstate=vstate,\n            scanning=vs[\"scanning\"],\n            hashq=vs[\"hashq\"],\n            tagq=vs[\"tagq\"],\n            mtpq=vs[\"mtpq\"],\n            dbwt=vs[\"dbwt\"],\n            url_suf=suf,\n            k304=self.k304(),\n            ver=S_VERSION if self.args.ver else \"\",\n            ahttps=\"\" if self.is_https else \"https://\" + self.host + self.req,\n        )\n        self.reply(html.encode(\"utf-8\"))\n        return True\n\n    def set_k304(self) -> bool:\n        ck = gencookie(\"k304\", self.uparam[\"k304\"], self.args.R, False, 86400 * 299)\n        self.out_headerlist.append((\"Set-Cookie\", ck))\n        self.redirect(\"\", \"?h#cc\")\n        return True\n\n    def setck(self) -> bool:\n        k, v = self.uparam[\"setck\"].split(\"=\", 1)\n        t = None if v == \"\" else 86400 * 299\n        ck = gencookie(k, v, self.args.R, False, t)\n        self.out_headerlist.append((\"Set-Cookie\", ck))\n        self.reply(b\"o7\\n\")\n        return True\n\n    def set_cfg_reset(self) -> bool:\n        for k in (\"k304\", \"js\", \"idxh\", \"cppwd\", \"cppws\"):\n            cookie = gencookie(k, \"x\", self.args.R, False, None)\n            self.out_headerlist.append((\"Set-Cookie\", cookie))\n\n        self.redirect(\"\", \"?h#cc\")\n        return True\n\n    def tx_404(self, is_403: bool = False) -> bool:\n        rc = 404\n        if self.args.vague_403:\n            t = '<h1 id=\"n\">404 not found &nbsp;\u2510( \u00b4 -`)\u250c</h1><p id=\"o\">or maybe you don\\'t have access -- try logging in or <a href=\"{}/?h\">go home</a></p>'\n        elif is_403:\n            t = '<h1 id=\"p\">403 forbiddena &nbsp;~\u253b\u2501\u253b</h1><p id=\"q\">you\\'ll have to log in or <a href=\"{}/?h\">go home</a></p>'\n            rc = 403\n        else:\n            t = '<h1 id=\"n\">404 not found &nbsp;\u2510( \u00b4 -`)\u250c</h1><p><a id=\"r\" href=\"{}/?h\">go home</a></p>'\n\n        t = t.format(self.args.SR)\n        html = self.j2s(\"splash\", this=self, qvpath=quotep(self.vpath), msg=t)\n        self.reply(html.encode(\"utf-8\"), status=rc)\n        return True\n\n    def on40x(self, mods: list[str], vn: VFS, rem: str) -> str:\n        for mpath in mods:\n            try:\n                mod = loadpy(mpath, self.args.hot_handlers)\n            except Exception as ex:\n                self.log(\"import failed: {!r}\".format(ex))\n                continue\n\n            ret = mod.main(self, vn, rem)\n            if ret:\n                return ret.lower()\n\n        return \"\"  # unhandled / fallthrough\n\n    def scanvol(self) -> bool:\n        if not self.can_read or not self.can_write:\n            raise Pebkac(403, \"not allowed for user \" + self.uname)\n\n        if self.args.no_rescan:\n            raise Pebkac(403, \"the rescan feature is disabled in server config\")\n\n        vn, _ = self.asrv.vfs.get(self.vpath, self.uname, True, True)\n\n        args = [self.asrv.vfs.all_vols, [vn.vpath], False, True]\n\n        x = self.conn.hsrv.broker.ask(\"up2k.rescan\", *args)\n        err = x.get()\n        if not err:\n            self.redirect(\"\", \"?h\")\n            return True\n\n        raise Pebkac(500, err)\n\n    def handle_reload(self) -> bool:\n        act = self.uparam.get(\"reload\")\n        if act != \"cfg\":\n            raise Pebkac(400, \"only config files ('cfg') can be reloaded rn\")\n\n        if not [x for x in self.wvol if x in self.rvol]:\n            raise Pebkac(403, \"not allowed for user \" + self.uname)\n\n        if self.args.no_reload:\n            raise Pebkac(403, \"the reload feature is disabled in server config\")\n\n        x = self.conn.hsrv.broker.ask(\"reload\")\n        return self.redirect(\"\", \"?h\", x.get(), \"return to\", False)\n\n    def tx_stack(self) -> bool:\n        if not [x for x in self.wvol if x in self.rvol]:\n            raise Pebkac(403, \"not allowed for user \" + self.uname)\n\n        if self.args.no_stack:\n            raise Pebkac(403, \"the stackdump feature is disabled in server config\")\n\n        ret = \"<pre>{}\\n{}\".format(time.time(), html_escape(alltrace()))\n        self.reply(ret.encode(\"utf-8\"))\n        return True\n\n    def tx_tree(self) -> bool:\n        top = self.uparam[\"tree\"] or \"\"\n        dst = self.vpath\n        if top in [\".\", \"..\"]:\n            top = undot(self.vpath + \"/\" + top)\n\n        if top == dst:\n            dst = \"\"\n        elif top:\n            if not dst.startswith(top + \"/\"):\n                raise Pebkac(400, \"arg funk\")\n\n            dst = dst[len(top) + 1 :]\n\n        ret = self.gen_tree(top, dst)\n        if self.is_vproxied:\n            parents = self.args.R.split(\"/\")\n            for parent in reversed(parents):\n                ret = {\"k%s\" % (parent,): ret, \"a\": []}\n\n        zs = json.dumps(ret)\n        self.reply(zs.encode(\"utf-8\"), mime=\"application/json\")\n        return True\n\n    def gen_tree(self, top: str, target: str) -> dict[str, Any]:\n        ret: dict[str, Any] = {}\n        excl = None\n        if target:\n            excl, target = (target.split(\"/\", 1) + [\"\"])[:2]\n            sub = self.gen_tree(\"/\".join([top, excl]).strip(\"/\"), target)\n            ret[\"k\" + quotep(excl)] = sub\n\n        try:\n            vn, rem = self.asrv.vfs.get(top, self.uname, True, False)\n            fsroot, vfs_ls, vfs_virt = vn.ls(\n                rem,\n                self.uname,\n                not self.args.no_scandir,\n                [[True, False], [False, True]],\n            )\n        except:\n            vfs_ls = []\n            vfs_virt = {}\n            for v in self.rvol:\n                d1, d2 = v.rsplit(\"/\", 1) if \"/\" in v else [\"\", v]\n                if d1 == top:\n                    vfs_virt[d2] = self.asrv.vfs  # typechk, value never read\n\n        dirs = []\n\n        dirnames = [x[0] for x in vfs_ls if stat.S_ISDIR(x[1].st_mode)]\n\n        if not self.args.ed or \"dots\" not in self.uparam:\n            dirnames = exclude_dotfiles(dirnames)\n\n        for fn in [x for x in dirnames if x != excl]:\n            dirs.append(quotep(fn))\n\n        for x in vfs_virt:\n            if x != excl:\n                dirs.append(x)\n\n        ret[\"a\"] = dirs\n        return ret\n\n    def tx_ups(self) -> bool:\n        if not self.args.unpost:\n            raise Pebkac(403, \"the unpost feature is disabled in server config\")\n\n        idx = self.conn.get_u2idx()\n        if not idx or not hasattr(idx, \"p_end\"):\n            raise Pebkac(500, \"sqlite3 is not available on the server; cannot unpost\")\n\n        filt = self.uparam.get(\"filter\")\n        filt = unquotep(filt or \"\")\n        lm = \"ups [{}]\".format(filt)\n        self.log(lm)\n\n        ret: list[dict[str, Any]] = []\n        t0 = time.time()\n        lim = time.time() - self.args.unpost\n        fk_vols = {\n            vol: vol.flags[\"fk\"]\n            for vp, vol in self.asrv.vfs.all_vols.items()\n            if \"fk\" in vol.flags and (vp in self.rvol or vp in self.upvol)\n        }\n        for vol in self.asrv.vfs.all_vols.values():\n            cur = idx.get_cur(vol.realpath)\n            if not cur:\n                continue\n\n            nfk = fk_vols.get(vol, 0)\n\n            q = \"select sz, rd, fn, at from up where ip=? and at>?\"\n            for sz, rd, fn, at in cur.execute(q, (self.ip, lim)):\n                vp = \"/\" + \"/\".join(x for x in [vol.vpath, rd, fn] if x)\n                if filt and filt not in vp:\n                    continue\n\n                rv = {\"vp\": quotep(vp), \"sz\": sz, \"at\": at, \"nfk\": nfk}\n                if nfk:\n                    rv[\"ap\"] = vol.canonical(vjoin(rd, fn))\n\n                ret.append(rv)\n                if len(ret) > 3000:\n                    ret.sort(key=lambda x: x[\"at\"], reverse=True)  # type: ignore\n                    ret = ret[:2000]\n\n        ret.sort(key=lambda x: x[\"at\"], reverse=True)  # type: ignore\n        n = 0\n        for rv in ret[:11000]:\n            nfk = rv.pop(\"nfk\")\n            if not nfk:\n                continue\n\n            ap = rv.pop(\"ap\")\n            try:\n                st = bos.stat(ap)\n            except:\n                continue\n\n            fk = self.gen_fk(\n                self.args.fk_salt, ap, st.st_size, 0 if ANYWIN else st.st_ino\n            )\n            rv[\"vp\"] += \"?k=\" + fk[:nfk]\n\n            n += 1\n            if n > 2000:\n                break\n\n        ret = ret[:2000]\n\n        if self.is_vproxied:\n            for v in ret:\n                v[\"vp\"] = self.args.SR + v[\"vp\"]\n\n        jtxt = json.dumps(ret, indent=2, sort_keys=True).encode(\"utf-8\", \"replace\")\n        self.log(\"{} #{} {:.2f}sec\".format(lm, len(ret), time.time() - t0))\n        self.reply(jtxt, mime=\"application/json\")\n        return True\n\n    def handle_rm(self, req: list[str]) -> bool:\n        if not req and not self.can_delete:\n            raise Pebkac(403, \"not allowed for user \" + self.uname)\n\n        if self.args.no_del:\n            raise Pebkac(403, \"the delete feature is disabled in server config\")\n\n        if not req:\n            req = [self.vpath]\n        elif self.is_vproxied:\n            req = [x[len(self.args.SR) :] for x in req]\n\n        nlim = int(self.uparam.get(\"lim\") or 0)\n        lim = [nlim, nlim] if nlim else []\n\n        x = self.conn.hsrv.broker.ask(\n            \"up2k.handle_rm\", self.uname, self.ip, req, lim, False\n        )\n        self.loud_reply(x.get())\n        return True\n\n    def handle_mv(self) -> bool:\n        # full path of new loc (incl filename)\n        dst = self.uparam.get(\"move\")\n\n        if self.is_vproxied and dst and dst.startswith(self.args.SR):\n            dst = dst[len(self.args.RS) :]\n\n        if not dst:\n            raise Pebkac(400, \"need dst vpath\")\n\n        # x-www-form-urlencoded (url query part) uses\n        # either + or %20 for 0x20 so handle both\n        dst = unquotep(dst.replace(\"+\", \" \"))\n        return self._mv(self.vpath, dst.lstrip(\"/\"))\n\n    def _mv(self, vsrc: str, vdst: str) -> bool:\n        if not self.can_move:\n            raise Pebkac(403, \"not allowed for user \" + self.uname)\n\n        if self.args.no_mv:\n            raise Pebkac(403, \"the rename/move feature is disabled in server config\")\n\n        x = self.conn.hsrv.broker.ask(\"up2k.handle_mv\", self.uname, vsrc, vdst)\n        self.loud_reply(x.get(), status=201)\n        return True\n\n    def tx_ls(self, ls: dict[str, Any]) -> bool:\n        dirs = ls[\"dirs\"]\n        files = ls[\"files\"]\n        arg = self.uparam[\"ls\"]\n        if arg in [\"v\", \"t\", \"txt\"]:\n            try:\n                biggest = max(ls[\"files\"] + ls[\"dirs\"], key=itemgetter(\"sz\"))[\"sz\"]\n            except:\n                biggest = 0\n\n            if arg == \"v\":\n                fmt = \"\\033[0;7;36m{{}}{{:>{}}}\\033[0m {{}}\"\n                nfmt = \"{}\"\n                biggest = 0\n                f2 = \"\".join(\n                    \"{}{{}}\".format(x)\n                    for x in [\n                        \"\\033[7m\",\n                        \"\\033[27m\",\n                        \"\",\n                        \"\\033[0;1m\",\n                        \"\\033[0;36m\",\n                        \"\\033[0m\",\n                    ]\n                )\n                ctab = {\"B\": 6, \"K\": 5, \"M\": 1, \"G\": 3}\n                for lst in [dirs, files]:\n                    for x in lst:\n                        a = x[\"dt\"].replace(\"-\", \" \").replace(\":\", \" \").split(\" \")\n                        x[\"dt\"] = f2.format(*list(a))\n                        sz = humansize(x[\"sz\"], True)\n                        x[\"sz\"] = \"\\033[0;3{}m {:>5}\".format(ctab.get(sz[-1:], 0), sz)\n            else:\n                fmt = \"{{}}  {{:{},}}  {{}}\"\n                nfmt = \"{:,}\"\n\n            for x in dirs:\n                n = x[\"name\"] + \"/\"\n                if arg == \"v\":\n                    n = \"\\033[94m\" + n\n\n                x[\"name\"] = n\n\n            fmt = fmt.format(len(nfmt.format(biggest)))\n            retl = [\n                \"# {}: {}\".format(x, ls[x])\n                for x in [\"acct\", \"perms\", \"srvinf\"]\n                if x in ls\n            ]\n            retl += [\n                fmt.format(x[\"dt\"], x[\"sz\"], x[\"name\"])\n                for y in [dirs, files]\n                for x in y\n            ]\n            ret = \"\\n\".join(retl)\n            mime = \"text/plain; charset=utf-8\"\n        else:\n            [x.pop(k) for k in [\"name\", \"dt\"] for y in [dirs, files] for x in y]\n\n            ret = json.dumps(ls)\n            mime = \"application/json\"\n\n        ret += \"\\n\\033[0m\" if arg == \"v\" else \"\\n\"\n        self.reply(ret.encode(\"utf-8\", \"replace\"), mime=mime)\n        return True\n\n    def tx_browser(self) -> bool:\n        vpath = \"\"\n        vpnodes = [[\"\", \"/\"]]\n        if self.vpath:\n            for node in self.vpath.split(\"/\"):\n                if not vpath:\n                    vpath = node\n                else:\n                    vpath += \"/\" + node\n\n                vpnodes.append([quotep(vpath) + \"/\", html_escape(node, crlf=True)])\n\n        vn = self.vn\n        rem = self.rem\n        abspath = vn.dcanonical(rem)\n        dbv, vrem = vn.get_dbv(rem)\n\n        try:\n            st = bos.stat(abspath)\n        except:\n            if \"on404\" not in vn.flags:\n                return self.tx_404()\n\n            ret = self.on40x(vn.flags[\"on404\"], vn, rem)\n            if ret == \"true\":\n                return True\n            elif ret == \"false\":\n                return False\n            elif ret == \"retry\":\n                try:\n                    st = bos.stat(abspath)\n                except:\n                    return self.tx_404()\n            else:\n                return self.tx_404()\n\n        if rem.startswith(\".hist/up2k.\") or (\n            rem.endswith(\"/dir.txt\") and rem.startswith(\".hist/th/\")\n        ):\n            raise Pebkac(403)\n\n        e2d = \"e2d\" in vn.flags\n        e2t = \"e2t\" in vn.flags\n\n        self.html_head = vn.flags.get(\"html_head\", \"\")\n        if vn.flags.get(\"norobots\") or \"b\" in self.uparam:\n            self.out_headers[\"X-Robots-Tag\"] = \"noindex, nofollow\"\n        else:\n            self.out_headers.pop(\"X-Robots-Tag\", None)\n\n        is_dir = stat.S_ISDIR(st.st_mode)\n        icur = None\n        if is_dir and (e2t or e2d):\n            idx = self.conn.get_u2idx()\n            if idx and hasattr(idx, \"p_end\"):\n                icur = idx.get_cur(dbv.realpath)\n\n        if self.can_read:\n            th_fmt = self.uparam.get(\"th\")\n            if th_fmt is not None:\n                if is_dir:\n                    vrem = vrem.rstrip(\"/\")\n                    if icur and vrem:\n                        q = \"select fn from cv where rd=? and dn=?\"\n                        crd, cdn = vrem.rsplit(\"/\", 1) if \"/\" in vrem else (\"\", vrem)\n                        # no mojibake support:\n                        try:\n                            cfn = icur.execute(q, (crd, cdn)).fetchone()\n                            if cfn:\n                                fn = cfn[0]\n                                fp = os.path.join(abspath, fn)\n                                if bos.path.exists(fp):\n                                    vrem = \"{}/{}\".format(vrem, fn).strip(\"/\")\n                                    is_dir = False\n                        except:\n                            pass\n                    else:\n                        for fn in self.args.th_covers:\n                            fp = os.path.join(abspath, fn)\n                            if bos.path.exists(fp):\n                                vrem = \"{}/{}\".format(vrem, fn).strip(\"/\")\n                                is_dir = False\n                                break\n\n                    if is_dir:\n                        return self.tx_ico(\"a.folder\")\n\n                thp = None\n                if self.thumbcli:\n                    thp = self.thumbcli.get(dbv, vrem, int(st.st_mtime), th_fmt)\n\n                if thp:\n                    return self.tx_file(thp)\n\n                if th_fmt == \"p\":\n                    raise Pebkac(404)\n\n                return self.tx_ico(rem)\n\n        if not is_dir and (self.can_read or self.can_get):\n            if not self.can_read and \"fk\" in vn.flags:\n                correct = self.gen_fk(\n                    self.args.fk_salt, abspath, st.st_size, 0 if ANYWIN else st.st_ino\n                )[: vn.flags[\"fk\"]]\n                got = self.uparam.get(\"k\")\n                if got != correct:\n                    self.log(\"wrong filekey, want {}, got {}\".format(correct, got))\n                    return self.tx_404()\n\n            if (\n                abspath.endswith(\".md\")\n                and \"nohtml\" not in vn.flags\n                and (\n                    \"v\" in self.uparam\n                    or \"edit\" in self.uparam\n                    or \"edit2\" in self.uparam\n                )\n            ):\n                return self.tx_md(abspath)\n\n            return self.tx_file(abspath)\n\n        elif is_dir and not self.can_read and not self.can_write:\n            return self.tx_404(True)\n\n        srv_info = []\n\n        try:\n            if not self.args.nih:\n                srv_info.append(self.args.name)\n        except:\n            self.log(\"#wow #whoa\")\n\n        if not self.args.nid:\n            free, total = get_df(abspath)\n            if total is not None:\n                h1 = humansize(free or 0)\n                h2 = humansize(total)\n                srv_info.append(\"{} free of {}\".format(h1, h2))\n            elif free is not None:\n                srv_info.append(humansize(free, True) + \" free\")\n\n        srv_infot = \"</span> // <span>\".join(srv_info)\n\n        perms = []\n        if self.can_read:\n            perms.append(\"read\")\n        if self.can_write:\n            perms.append(\"write\")\n        if self.can_move:\n            perms.append(\"move\")\n        if self.can_delete:\n            perms.append(\"delete\")\n        if self.can_get:\n            perms.append(\"get\")\n        if self.can_upget:\n            perms.append(\"upget\")\n        if self.can_admin:\n            perms.append(\"admin\")\n\n        url_suf = self.urlq({}, [\"k\"])\n        is_ls = \"ls\" in self.uparam\n        is_js = self.args.force_js or self.cookies.get(\"js\") == \"y\"\n\n        if not is_ls and (self.ua.startswith(\"curl/\") or self.ua.startswith(\"fetch\")):\n            self.uparam[\"ls\"] = \"v\"\n            is_ls = True\n\n        tpl = \"browser\"\n        if \"b\" in self.uparam:\n            tpl = \"browser2\"\n            is_js = False\n\n        logues = [\"\", \"\"]\n        if not self.args.no_logues:\n            for n, fn in enumerate([\".prologue.html\", \".epilogue.html\"]):\n                fn = os.path.join(abspath, fn)\n                if bos.path.exists(fn):\n                    with open(fsenc(fn), \"rb\") as f:\n                        logues[n] = f.read().decode(\"utf-8\")\n\n        readme = \"\"\n        if not self.args.no_readme and not logues[1]:\n            for fn in [\"README.md\", \"readme.md\"]:\n                fn = os.path.join(abspath, fn)\n                if bos.path.isfile(fn):\n                    with open(fsenc(fn), \"rb\") as f:\n                        readme = f.read().decode(\"utf-8\")\n                        break\n\n        vf = vn.flags\n        unlist = vf.get(\"unlist\", \"\")\n        ls_ret = {\n            \"dirs\": [],\n            \"files\": [],\n            \"taglist\": [],\n            \"srvinf\": srv_infot,\n            \"acct\": self.uname,\n            \"idx\": e2d,\n            \"itag\": e2t,\n            \"lifetime\": vn.flags.get(\"lifetime\") or 0,\n            \"frand\": bool(vn.flags.get(\"rand\")),\n            \"unlist\": unlist,\n            \"perms\": perms,\n            \"logues\": logues,\n            \"readme\": readme,\n        }\n        j2a = {\n            \"vdir\": quotep(self.vpath),\n            \"vpnodes\": vpnodes,\n            \"files\": [],\n            \"ls0\": None,\n            \"acct\": self.uname,\n            \"perms\": json.dumps(perms),\n            \"lifetime\": ls_ret[\"lifetime\"],\n            \"frand\": bool(vn.flags.get(\"rand\")),\n            \"taglist\": [],\n            \"def_hcols\": [],\n            \"have_emp\": self.args.emp,\n            \"have_up2k_idx\": e2d,\n            \"have_tags_idx\": e2t,\n            \"have_acode\": (not self.args.no_acode),\n            \"have_mv\": (not self.args.no_mv),\n            \"have_del\": (not self.args.no_del),\n            \"have_zip\": (not self.args.no_zip),\n            \"have_unpost\": int(self.args.unpost),\n            \"have_b_u\": (self.can_write and self.uparam.get(\"b\") == \"u\"),\n            \"sb_md\": \"\" if \"no_sb_md\" in vf else (vf.get(\"md_sbf\") or \"y\"),\n            \"sb_lg\": \"\" if \"no_sb_lg\" in vf else (vf.get(\"lg_sbf\") or \"y\"),\n            \"url_suf\": url_suf,\n            \"logues\": logues,\n            \"readme\": readme,\n            \"title\": html_escape(self.vpath, crlf=True) or \"\ud83d\udcbe\ud83c\udf89\",\n            \"srv_info\": srv_infot,\n            \"dgrid\": \"grid\" in vf,\n            \"unlist\": unlist,\n            \"dtheme\": self.args.theme,\n            \"themes\": self.args.themes,\n            \"turbolvl\": self.args.turbo,\n            \"idxh\": int(self.args.ih),\n            \"u2sort\": self.args.u2sort,\n        }\n\n        if self.args.js_browser:\n            j2a[\"js\"] = self.args.js_browser\n\n        if self.args.css_browser:\n            j2a[\"css\"] = self.args.css_browser\n\n        if not self.conn.hsrv.prism:\n            j2a[\"no_prism\"] = True\n\n        if not self.can_read:\n            if is_ls:\n                return self.tx_ls(ls_ret)\n\n            if not stat.S_ISDIR(st.st_mode):\n                return self.tx_404(True)\n\n            if \"zip\" in self.uparam or \"tar\" in self.uparam:\n                raise Pebkac(403)\n\n            html = self.j2s(tpl, **j2a)\n            self.reply(html.encode(\"utf-8\", \"replace\"))\n            return True\n\n        for k in [\"zip\", \"tar\"]:\n            v = self.uparam.get(k)\n            if v is not None:\n                return self.tx_zip(k, v, self.vpath, vn, rem, [], self.args.ed)\n\n        fsroot, vfs_ls, vfs_virt = vn.ls(\n            rem,\n            self.uname,\n            not self.args.no_scandir,\n            [[True, False], [False, True]],\n            lstat=\"lt\" in self.uparam,\n        )\n        stats = {k: v for k, v in vfs_ls}\n        ls_names = [x[0] for x in vfs_ls]\n        ls_names.extend(list(vfs_virt.keys()))\n\n        # check for old versions of files,\n        # [num-backups, most-recent, hist-path]\n        hist: dict[str, tuple[int, float, str]] = {}\n        histdir = os.path.join(fsroot, \".hist\")\n        ptn = re.compile(r\"(.*)\\.([0-9]+\\.[0-9]{3})(\\.[^\\.]+)$\")\n        try:\n            for hfn in bos.listdir(histdir):\n                m = ptn.match(hfn)\n                if not m:\n                    continue\n\n                fn = m.group(1) + m.group(3)\n                n, ts, _ = hist.get(fn, (0, 0, \"\"))\n                hist[fn] = (n + 1, max(ts, float(m.group(2))), hfn)\n        except:\n            pass\n\n        # show dotfiles if permitted and requested\n        if not self.args.ed or \"dots\" not in self.uparam:\n            ls_names = exclude_dotfiles(ls_names)\n\n        add_fk = vn.flags.get(\"fk\")\n\n        dirs = []\n        files = []\n        for fn in ls_names:\n            base = \"\"\n            href = fn\n            if not is_ls and not is_js and not self.trailing_slash and vpath:\n                base = \"/\" + vpath + \"/\"\n                href = base + fn\n\n            if fn in vfs_virt:\n                fspath = vfs_virt[fn].realpath\n            else:\n                fspath = fsroot + \"/\" + fn\n\n            try:\n                linf = stats.get(fn) or bos.lstat(fspath)\n                inf = bos.stat(fspath) if stat.S_ISLNK(linf.st_mode) else linf\n            except:\n                self.log(\"broken symlink: {}\".format(repr(fspath)))\n                continue\n\n            is_dir = stat.S_ISDIR(inf.st_mode)\n            if is_dir:\n                href += \"/\"\n                if self.args.no_zip:\n                    margin = \"DIR\"\n                else:\n                    margin = '<a href=\"%s?zip\" rel=\"nofollow\">zip</a>' % (quotep(href),)\n            elif fn in hist:\n                margin = '<a href=\"%s.hist/%s\">#%s</a>' % (\n                    base,\n                    html_escape(hist[fn][2], quot=True, crlf=True),\n                    hist[fn][0],\n                )\n            else:\n                margin = \"-\"\n\n            sz = inf.st_size\n            zd = datetime.utcfromtimestamp(linf.st_mtime)\n            dt = \"%04d-%02d-%02d %02d:%02d:%02d\" % (\n                zd.year,\n                zd.month,\n                zd.day,\n                zd.hour,\n                zd.minute,\n                zd.second,\n            )\n\n            try:\n                ext = \"---\" if is_dir else fn.rsplit(\".\", 1)[1]\n                if len(ext) > 16:\n                    ext = ext[:16]\n            except:\n                ext = \"%\"\n\n            if add_fk:\n                href = \"%s?k=%s\" % (\n                    quotep(href),\n                    self.gen_fk(\n                        self.args.fk_salt, fspath, sz, 0 if ANYWIN else inf.st_ino\n                    )[:add_fk],\n                )\n            else:\n                href = quotep(href)\n\n            item = {\n                \"lead\": margin,\n                \"href\": href,\n                \"name\": fn,\n                \"sz\": sz,\n                \"ext\": ext,\n                \"dt\": dt,\n                \"ts\": int(linf.st_mtime),\n            }\n            if is_dir:\n                dirs.append(item)\n            else:\n                files.append(item)\n                item[\"rd\"] = rem\n\n        if (\n            self.cookies.get(\"idxh\") == \"y\"\n            and \"ls\" not in self.uparam\n            and \"v\" not in self.uparam\n        ):\n            idx_html = set([\"index.htm\", \"index.html\"])\n            for item in files:\n                if item[\"name\"] in idx_html:\n                    # do full resolve in case of shadowed file\n                    vp = vjoin(self.vpath.split(\"?\")[0], item[\"name\"])\n                    vn, rem = self.asrv.vfs.get(vp, self.uname, True, False)\n                    ap = vn.canonical(rem)\n                    return self.tx_file(ap)  # is no-cache\n\n        tagset: set[str] = set()\n        for fe in files:\n            fn = fe[\"name\"]\n            rd = fe[\"rd\"]\n            del fe[\"rd\"]\n            if not icur:\n                continue\n\n            if vn != dbv:\n                _, rd = vn.get_dbv(rd)\n\n            erd_efn = (rd, fn)\n            q = \"select mt.k, mt.v from up inner join mt on mt.w = substr(up.w,1,16) where up.rd = ? and up.fn = ? and +mt.k != 'x'\"\n            try:\n                r = icur.execute(q, erd_efn)\n            except Exception as ex:\n                if \"database is locked\" in str(ex):\n                    break\n\n                try:\n                    erd_efn = s3enc(idx.mem_cur, rd, fn)\n                    r = icur.execute(q, erd_efn)\n                except:\n                    t = \"tag read error, {}/{}\\n{}\"\n                    self.log(t.format(rd, fn, min_ex()))\n                    break\n\n            fe[\"tags\"] = {k: v for k, v in r}\n\n            if self.can_admin:\n                q = \"select ip, at from up where rd=? and fn=?\"\n                try:\n                    zs1, zs2 = icur.execute(q, erd_efn).fetchone()\n                    fe[\"tags\"][\"up_ip\"] = zs1\n                    fe[\"tags\"][\".up_at\"] = zs2\n                except:\n                    pass\n\n            _ = [tagset.add(k) for k in fe[\"tags\"]]\n\n        if icur:\n            taglist = [k for k in vn.flags.get(\"mte\", \"\").split(\",\") if k in tagset]\n            for fe in dirs:\n                fe[\"tags\"] = {}\n        else:\n            taglist = list(tagset)\n\n        if is_ls:\n            ls_ret[\"dirs\"] = dirs\n            ls_ret[\"files\"] = files\n            ls_ret[\"taglist\"] = taglist\n            return self.tx_ls(ls_ret)\n\n        doc = self.uparam.get(\"doc\") if self.can_read else None\n        if doc:\n            doc = unquotep(doc.replace(\"+\", \" \").split(\"?\")[0])\n            j2a[\"docname\"] = doc\n            doctxt = None\n            if next((x for x in files if x[\"name\"] == doc), None):\n                docpath = os.path.join(abspath, doc)\n                sz = bos.path.getsize(docpath)\n                if sz < 1024 * self.args.txt_max:\n                    with open(fsenc(docpath), \"rb\") as f:\n                        doctxt = f.read().decode(\"utf-8\", \"replace\")\n            else:\n                self.log(\"doc 404: [{}]\".format(doc), c=6)\n                doctxt = \"( textfile not found )\"\n\n            if doctxt is not None:\n                j2a[\"doc\"] = doctxt\n\n        for d in dirs:\n            d[\"name\"] += \"/\"\n\n        dirs.sort(key=itemgetter(\"name\"))\n\n        if is_js:\n            j2a[\"ls0\"] = {\n                \"dirs\": dirs,\n                \"files\": files,\n                \"taglist\": taglist,\n                \"unlist\": unlist,\n            }\n            j2a[\"files\"] = []\n        else:\n            j2a[\"files\"] = dirs + files\n\n        j2a[\"taglist\"] = taglist\n        j2a[\"txt_ext\"] = self.args.textfiles.replace(\",\", \" \")\n\n        if \"mth\" in vn.flags:\n            j2a[\"def_hcols\"] = vn.flags[\"mth\"].split(\",\")\n\n        html = self.j2s(tpl, **j2a)\n        self.reply(html.encode(\"utf-8\", \"replace\"))\n        return True\n"], "filenames": ["copyparty/httpcli.py"], "buggy_code_start_loc": [44], "buggy_code_end_loc": [783], "fixing_code_start_loc": [45], "fixing_code_end_loc": [791], "type": "CWE-22", "message": "Copyparty is a portable file server. Versions prior to 1.8.2 are subject to a path traversal vulnerability detected in the `.cpr` subfolder. The Path Traversal attack technique allows an attacker access to files, directories, and commands that reside outside the web document root directory. This issue has been addressed in commit `043e3c7d` which has been included in release 1.8.2. Users are advised to upgrade. There are no known workarounds for this vulnerability.", "other": {"cve": {"id": "CVE-2023-37474", "sourceIdentifier": "security-advisories@github.com", "published": "2023-07-14T20:15:09.083", "lastModified": "2023-07-31T19:15:17.570", "vulnStatus": "Modified", "descriptions": [{"lang": "en", "value": "Copyparty is a portable file server. Versions prior to 1.8.2 are subject to a path traversal vulnerability detected in the `.cpr` subfolder. The Path Traversal attack technique allows an attacker access to files, directories, and commands that reside outside the web document root directory. This issue has been addressed in commit `043e3c7d` which has been included in release 1.8.2. Users are advised to upgrade. There are no known workarounds for this vulnerability."}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "NONE", "availabilityImpact": "NONE", "baseScore": 7.5, "baseSeverity": "HIGH"}, "exploitabilityScore": 3.9, "impactScore": 3.6}], "cvssMetricV30": [{"source": "security-advisories@github.com", "type": "Secondary", "cvssData": {"version": "3.0", "vectorString": "CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "NONE", "availabilityImpact": "NONE", "baseScore": 7.5, "baseSeverity": "HIGH"}, "exploitabilityScore": 3.9, "impactScore": 3.6}]}, "weaknesses": [{"source": "security-advisories@github.com", "type": "Primary", "description": [{"lang": "en", "value": "CWE-22"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:copyparty_project:copyparty:*:*:*:*:*:*:*:*", "versionEndExcluding": "1.8.2", "matchCriteriaId": "70E4D74A-BEE5-4FD5-85C2-29C30D148751"}]}]}], "references": [{"url": "http://packetstormsecurity.com/files/173822/Copyparty-1.8.2-Directory-Traversal.html", "source": "security-advisories@github.com"}, {"url": "https://github.com/9001/copyparty/commit/043e3c7dd683113e2b1c15cacb9c8e68f76513ff", "source": "security-advisories@github.com", "tags": ["Patch"]}, {"url": "https://github.com/9001/copyparty/security/advisories/GHSA-pxfv-7rr3-2qjg", "source": "security-advisories@github.com", "tags": ["Exploit", "Third Party Advisory"]}]}, "github_commit_url": "https://github.com/9001/copyparty/commit/043e3c7dd683113e2b1c15cacb9c8e68f76513ff"}}
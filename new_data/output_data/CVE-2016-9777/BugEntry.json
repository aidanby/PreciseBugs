{"buggy_code": ["/*\n *  Copyright (C) 2001  MandrakeSoft S.A.\n *  Copyright 2010 Red Hat, Inc. and/or its affiliates.\n *\n *    MandrakeSoft S.A.\n *    43, rue d'Aboukir\n *    75002 Paris - France\n *    http://www.linux-mandrake.com/\n *    http://www.mandrakesoft.com/\n *\n *  This library is free software; you can redistribute it and/or\n *  modify it under the terms of the GNU Lesser General Public\n *  License as published by the Free Software Foundation; either\n *  version 2 of the License, or (at your option) any later version.\n *\n *  This library is distributed in the hope that it will be useful,\n *  but WITHOUT ANY WARRANTY; without even the implied warranty of\n *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n *  Lesser General Public License for more details.\n *\n *  You should have received a copy of the GNU Lesser General Public\n *  License along with this library; if not, write to the Free Software\n *  Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307 USA\n *\n *  Yunhong Jiang <yunhong.jiang@intel.com>\n *  Yaozu (Eddie) Dong <eddie.dong@intel.com>\n *  Based on Xen 3.1 code.\n */\n\n#include <linux/kvm_host.h>\n#include <linux/kvm.h>\n#include <linux/mm.h>\n#include <linux/highmem.h>\n#include <linux/smp.h>\n#include <linux/hrtimer.h>\n#include <linux/io.h>\n#include <linux/slab.h>\n#include <linux/export.h>\n#include <asm/processor.h>\n#include <asm/page.h>\n#include <asm/current.h>\n#include <trace/events/kvm.h>\n\n#include \"ioapic.h\"\n#include \"lapic.h\"\n#include \"irq.h\"\n\n#if 0\n#define ioapic_debug(fmt,arg...) printk(KERN_WARNING fmt,##arg)\n#else\n#define ioapic_debug(fmt, arg...)\n#endif\nstatic int ioapic_service(struct kvm_ioapic *vioapic, int irq,\n\t\tbool line_status);\n\nstatic unsigned long ioapic_read_indirect(struct kvm_ioapic *ioapic,\n\t\t\t\t\t  unsigned long addr,\n\t\t\t\t\t  unsigned long length)\n{\n\tunsigned long result = 0;\n\n\tswitch (ioapic->ioregsel) {\n\tcase IOAPIC_REG_VERSION:\n\t\tresult = ((((IOAPIC_NUM_PINS - 1) & 0xff) << 16)\n\t\t\t  | (IOAPIC_VERSION_ID & 0xff));\n\t\tbreak;\n\n\tcase IOAPIC_REG_APIC_ID:\n\tcase IOAPIC_REG_ARB_ID:\n\t\tresult = ((ioapic->id & 0xf) << 24);\n\t\tbreak;\n\n\tdefault:\n\t\t{\n\t\t\tu32 redir_index = (ioapic->ioregsel - 0x10) >> 1;\n\t\t\tu64 redir_content;\n\n\t\t\tif (redir_index < IOAPIC_NUM_PINS)\n\t\t\t\tredir_content =\n\t\t\t\t\tioapic->redirtbl[redir_index].bits;\n\t\t\telse\n\t\t\t\tredir_content = ~0ULL;\n\n\t\t\tresult = (ioapic->ioregsel & 0x1) ?\n\t\t\t    (redir_content >> 32) & 0xffffffff :\n\t\t\t    redir_content & 0xffffffff;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\treturn result;\n}\n\nstatic void rtc_irq_eoi_tracking_reset(struct kvm_ioapic *ioapic)\n{\n\tioapic->rtc_status.pending_eoi = 0;\n\tbitmap_zero(ioapic->rtc_status.dest_map.map, KVM_MAX_VCPUS);\n}\n\nstatic void kvm_rtc_eoi_tracking_restore_all(struct kvm_ioapic *ioapic);\n\nstatic void rtc_status_pending_eoi_check_valid(struct kvm_ioapic *ioapic)\n{\n\tif (WARN_ON(ioapic->rtc_status.pending_eoi < 0))\n\t\tkvm_rtc_eoi_tracking_restore_all(ioapic);\n}\n\nstatic void __rtc_irq_eoi_tracking_restore_one(struct kvm_vcpu *vcpu)\n{\n\tbool new_val, old_val;\n\tstruct kvm_ioapic *ioapic = vcpu->kvm->arch.vioapic;\n\tstruct dest_map *dest_map = &ioapic->rtc_status.dest_map;\n\tunion kvm_ioapic_redirect_entry *e;\n\n\te = &ioapic->redirtbl[RTC_GSI];\n\tif (!kvm_apic_match_dest(vcpu, NULL, 0,\te->fields.dest_id,\n\t\t\t\te->fields.dest_mode))\n\t\treturn;\n\n\tnew_val = kvm_apic_pending_eoi(vcpu, e->fields.vector);\n\told_val = test_bit(vcpu->vcpu_id, dest_map->map);\n\n\tif (new_val == old_val)\n\t\treturn;\n\n\tif (new_val) {\n\t\t__set_bit(vcpu->vcpu_id, dest_map->map);\n\t\tdest_map->vectors[vcpu->vcpu_id] = e->fields.vector;\n\t\tioapic->rtc_status.pending_eoi++;\n\t} else {\n\t\t__clear_bit(vcpu->vcpu_id, dest_map->map);\n\t\tioapic->rtc_status.pending_eoi--;\n\t\trtc_status_pending_eoi_check_valid(ioapic);\n\t}\n}\n\nvoid kvm_rtc_eoi_tracking_restore_one(struct kvm_vcpu *vcpu)\n{\n\tstruct kvm_ioapic *ioapic = vcpu->kvm->arch.vioapic;\n\n\tspin_lock(&ioapic->lock);\n\t__rtc_irq_eoi_tracking_restore_one(vcpu);\n\tspin_unlock(&ioapic->lock);\n}\n\nstatic void kvm_rtc_eoi_tracking_restore_all(struct kvm_ioapic *ioapic)\n{\n\tstruct kvm_vcpu *vcpu;\n\tint i;\n\n\tif (RTC_GSI >= IOAPIC_NUM_PINS)\n\t\treturn;\n\n\trtc_irq_eoi_tracking_reset(ioapic);\n\tkvm_for_each_vcpu(i, vcpu, ioapic->kvm)\n\t    __rtc_irq_eoi_tracking_restore_one(vcpu);\n}\n\nstatic void rtc_irq_eoi(struct kvm_ioapic *ioapic, struct kvm_vcpu *vcpu)\n{\n\tif (test_and_clear_bit(vcpu->vcpu_id,\n\t\t\t       ioapic->rtc_status.dest_map.map)) {\n\t\t--ioapic->rtc_status.pending_eoi;\n\t\trtc_status_pending_eoi_check_valid(ioapic);\n\t}\n}\n\nstatic bool rtc_irq_check_coalesced(struct kvm_ioapic *ioapic)\n{\n\tif (ioapic->rtc_status.pending_eoi > 0)\n\t\treturn true; /* coalesced */\n\n\treturn false;\n}\n\nstatic int ioapic_set_irq(struct kvm_ioapic *ioapic, unsigned int irq,\n\t\tint irq_level, bool line_status)\n{\n\tunion kvm_ioapic_redirect_entry entry;\n\tu32 mask = 1 << irq;\n\tu32 old_irr;\n\tint edge, ret;\n\n\tentry = ioapic->redirtbl[irq];\n\tedge = (entry.fields.trig_mode == IOAPIC_EDGE_TRIG);\n\n\tif (!irq_level) {\n\t\tioapic->irr &= ~mask;\n\t\tret = 1;\n\t\tgoto out;\n\t}\n\n\t/*\n\t * Return 0 for coalesced interrupts; for edge-triggered interrupts,\n\t * this only happens if a previous edge has not been delivered due\n\t * do masking.  For level interrupts, the remote_irr field tells\n\t * us if the interrupt is waiting for an EOI.\n\t *\n\t * RTC is special: it is edge-triggered, but userspace likes to know\n\t * if it has been already ack-ed via EOI because coalesced RTC\n\t * interrupts lead to time drift in Windows guests.  So we track\n\t * EOI manually for the RTC interrupt.\n\t */\n\tif (irq == RTC_GSI && line_status &&\n\t\trtc_irq_check_coalesced(ioapic)) {\n\t\tret = 0;\n\t\tgoto out;\n\t}\n\n\told_irr = ioapic->irr;\n\tioapic->irr |= mask;\n\tif (edge)\n\t\tioapic->irr_delivered &= ~mask;\n\tif ((edge && old_irr == ioapic->irr) ||\n\t    (!edge && entry.fields.remote_irr)) {\n\t\tret = 0;\n\t\tgoto out;\n\t}\n\n\tret = ioapic_service(ioapic, irq, line_status);\n\nout:\n\ttrace_kvm_ioapic_set_irq(entry.bits, irq, ret == 0);\n\treturn ret;\n}\n\nstatic void kvm_ioapic_inject_all(struct kvm_ioapic *ioapic, unsigned long irr)\n{\n\tu32 idx;\n\n\trtc_irq_eoi_tracking_reset(ioapic);\n\tfor_each_set_bit(idx, &irr, IOAPIC_NUM_PINS)\n\t\tioapic_set_irq(ioapic, idx, 1, true);\n\n\tkvm_rtc_eoi_tracking_restore_all(ioapic);\n}\n\n\nvoid kvm_ioapic_scan_entry(struct kvm_vcpu *vcpu, ulong *ioapic_handled_vectors)\n{\n\tstruct kvm_ioapic *ioapic = vcpu->kvm->arch.vioapic;\n\tstruct dest_map *dest_map = &ioapic->rtc_status.dest_map;\n\tunion kvm_ioapic_redirect_entry *e;\n\tint index;\n\n\tspin_lock(&ioapic->lock);\n\n\t/* Make sure we see any missing RTC EOI */\n\tif (test_bit(vcpu->vcpu_id, dest_map->map))\n\t\t__set_bit(dest_map->vectors[vcpu->vcpu_id],\n\t\t\t  ioapic_handled_vectors);\n\n\tfor (index = 0; index < IOAPIC_NUM_PINS; index++) {\n\t\te = &ioapic->redirtbl[index];\n\t\tif (e->fields.trig_mode == IOAPIC_LEVEL_TRIG ||\n\t\t    kvm_irq_has_notifier(ioapic->kvm, KVM_IRQCHIP_IOAPIC, index) ||\n\t\t    index == RTC_GSI) {\n\t\t\tif (kvm_apic_match_dest(vcpu, NULL, 0,\n\t\t\t             e->fields.dest_id, e->fields.dest_mode) ||\n\t\t\t    (e->fields.trig_mode == IOAPIC_EDGE_TRIG &&\n\t\t\t     kvm_apic_pending_eoi(vcpu, e->fields.vector)))\n\t\t\t\t__set_bit(e->fields.vector,\n\t\t\t\t\t  ioapic_handled_vectors);\n\t\t}\n\t}\n\tspin_unlock(&ioapic->lock);\n}\n\nvoid kvm_vcpu_request_scan_ioapic(struct kvm *kvm)\n{\n\tstruct kvm_ioapic *ioapic = kvm->arch.vioapic;\n\n\tif (!ioapic)\n\t\treturn;\n\tkvm_make_scan_ioapic_request(kvm);\n}\n\nstatic void ioapic_write_indirect(struct kvm_ioapic *ioapic, u32 val)\n{\n\tunsigned index;\n\tbool mask_before, mask_after;\n\tunion kvm_ioapic_redirect_entry *e;\n\n\tswitch (ioapic->ioregsel) {\n\tcase IOAPIC_REG_VERSION:\n\t\t/* Writes are ignored. */\n\t\tbreak;\n\n\tcase IOAPIC_REG_APIC_ID:\n\t\tioapic->id = (val >> 24) & 0xf;\n\t\tbreak;\n\n\tcase IOAPIC_REG_ARB_ID:\n\t\tbreak;\n\n\tdefault:\n\t\tindex = (ioapic->ioregsel - 0x10) >> 1;\n\n\t\tioapic_debug(\"change redir index %x val %x\\n\", index, val);\n\t\tif (index >= IOAPIC_NUM_PINS)\n\t\t\treturn;\n\t\te = &ioapic->redirtbl[index];\n\t\tmask_before = e->fields.mask;\n\t\tif (ioapic->ioregsel & 1) {\n\t\t\te->bits &= 0xffffffff;\n\t\t\te->bits |= (u64) val << 32;\n\t\t} else {\n\t\t\te->bits &= ~0xffffffffULL;\n\t\t\te->bits |= (u32) val;\n\t\t\te->fields.remote_irr = 0;\n\t\t}\n\t\tmask_after = e->fields.mask;\n\t\tif (mask_before != mask_after)\n\t\t\tkvm_fire_mask_notifiers(ioapic->kvm, KVM_IRQCHIP_IOAPIC, index, mask_after);\n\t\tif (e->fields.trig_mode == IOAPIC_LEVEL_TRIG\n\t\t    && ioapic->irr & (1 << index))\n\t\t\tioapic_service(ioapic, index, false);\n\t\tkvm_vcpu_request_scan_ioapic(ioapic->kvm);\n\t\tbreak;\n\t}\n}\n\nstatic int ioapic_service(struct kvm_ioapic *ioapic, int irq, bool line_status)\n{\n\tunion kvm_ioapic_redirect_entry *entry = &ioapic->redirtbl[irq];\n\tstruct kvm_lapic_irq irqe;\n\tint ret;\n\n\tif (entry->fields.mask)\n\t\treturn -1;\n\n\tioapic_debug(\"dest=%x dest_mode=%x delivery_mode=%x \"\n\t\t     \"vector=%x trig_mode=%x\\n\",\n\t\t     entry->fields.dest_id, entry->fields.dest_mode,\n\t\t     entry->fields.delivery_mode, entry->fields.vector,\n\t\t     entry->fields.trig_mode);\n\n\tirqe.dest_id = entry->fields.dest_id;\n\tirqe.vector = entry->fields.vector;\n\tirqe.dest_mode = entry->fields.dest_mode;\n\tirqe.trig_mode = entry->fields.trig_mode;\n\tirqe.delivery_mode = entry->fields.delivery_mode << 8;\n\tirqe.level = 1;\n\tirqe.shorthand = 0;\n\tirqe.msi_redir_hint = false;\n\n\tif (irqe.trig_mode == IOAPIC_EDGE_TRIG)\n\t\tioapic->irr_delivered |= 1 << irq;\n\n\tif (irq == RTC_GSI && line_status) {\n\t\t/*\n\t\t * pending_eoi cannot ever become negative (see\n\t\t * rtc_status_pending_eoi_check_valid) and the caller\n\t\t * ensures that it is only called if it is >= zero, namely\n\t\t * if rtc_irq_check_coalesced returns false).\n\t\t */\n\t\tBUG_ON(ioapic->rtc_status.pending_eoi != 0);\n\t\tret = kvm_irq_delivery_to_apic(ioapic->kvm, NULL, &irqe,\n\t\t\t\t\t       &ioapic->rtc_status.dest_map);\n\t\tioapic->rtc_status.pending_eoi = (ret < 0 ? 0 : ret);\n\t} else\n\t\tret = kvm_irq_delivery_to_apic(ioapic->kvm, NULL, &irqe, NULL);\n\n\tif (ret && irqe.trig_mode == IOAPIC_LEVEL_TRIG)\n\t\tentry->fields.remote_irr = 1;\n\n\treturn ret;\n}\n\nint kvm_ioapic_set_irq(struct kvm_ioapic *ioapic, int irq, int irq_source_id,\n\t\t       int level, bool line_status)\n{\n\tint ret, irq_level;\n\n\tBUG_ON(irq < 0 || irq >= IOAPIC_NUM_PINS);\n\n\tspin_lock(&ioapic->lock);\n\tirq_level = __kvm_irq_line_state(&ioapic->irq_states[irq],\n\t\t\t\t\t irq_source_id, level);\n\tret = ioapic_set_irq(ioapic, irq, irq_level, line_status);\n\n\tspin_unlock(&ioapic->lock);\n\n\treturn ret;\n}\n\nvoid kvm_ioapic_clear_all(struct kvm_ioapic *ioapic, int irq_source_id)\n{\n\tint i;\n\n\tspin_lock(&ioapic->lock);\n\tfor (i = 0; i < KVM_IOAPIC_NUM_PINS; i++)\n\t\t__clear_bit(irq_source_id, &ioapic->irq_states[i]);\n\tspin_unlock(&ioapic->lock);\n}\n\nstatic void kvm_ioapic_eoi_inject_work(struct work_struct *work)\n{\n\tint i;\n\tstruct kvm_ioapic *ioapic = container_of(work, struct kvm_ioapic,\n\t\t\t\t\t\t eoi_inject.work);\n\tspin_lock(&ioapic->lock);\n\tfor (i = 0; i < IOAPIC_NUM_PINS; i++) {\n\t\tunion kvm_ioapic_redirect_entry *ent = &ioapic->redirtbl[i];\n\n\t\tif (ent->fields.trig_mode != IOAPIC_LEVEL_TRIG)\n\t\t\tcontinue;\n\n\t\tif (ioapic->irr & (1 << i) && !ent->fields.remote_irr)\n\t\t\tioapic_service(ioapic, i, false);\n\t}\n\tspin_unlock(&ioapic->lock);\n}\n\n#define IOAPIC_SUCCESSIVE_IRQ_MAX_COUNT 10000\n\nstatic void __kvm_ioapic_update_eoi(struct kvm_vcpu *vcpu,\n\t\t\tstruct kvm_ioapic *ioapic, int vector, int trigger_mode)\n{\n\tstruct dest_map *dest_map = &ioapic->rtc_status.dest_map;\n\tstruct kvm_lapic *apic = vcpu->arch.apic;\n\tint i;\n\n\t/* RTC special handling */\n\tif (test_bit(vcpu->vcpu_id, dest_map->map) &&\n\t    vector == dest_map->vectors[vcpu->vcpu_id])\n\t\trtc_irq_eoi(ioapic, vcpu);\n\n\tfor (i = 0; i < IOAPIC_NUM_PINS; i++) {\n\t\tunion kvm_ioapic_redirect_entry *ent = &ioapic->redirtbl[i];\n\n\t\tif (ent->fields.vector != vector)\n\t\t\tcontinue;\n\n\t\t/*\n\t\t * We are dropping lock while calling ack notifiers because ack\n\t\t * notifier callbacks for assigned devices call into IOAPIC\n\t\t * recursively. Since remote_irr is cleared only after call\n\t\t * to notifiers if the same vector will be delivered while lock\n\t\t * is dropped it will be put into irr and will be delivered\n\t\t * after ack notifier returns.\n\t\t */\n\t\tspin_unlock(&ioapic->lock);\n\t\tkvm_notify_acked_irq(ioapic->kvm, KVM_IRQCHIP_IOAPIC, i);\n\t\tspin_lock(&ioapic->lock);\n\n\t\tif (trigger_mode != IOAPIC_LEVEL_TRIG ||\n\t\t    kvm_lapic_get_reg(apic, APIC_SPIV) & APIC_SPIV_DIRECTED_EOI)\n\t\t\tcontinue;\n\n\t\tASSERT(ent->fields.trig_mode == IOAPIC_LEVEL_TRIG);\n\t\tent->fields.remote_irr = 0;\n\t\tif (!ent->fields.mask && (ioapic->irr & (1 << i))) {\n\t\t\t++ioapic->irq_eoi[i];\n\t\t\tif (ioapic->irq_eoi[i] == IOAPIC_SUCCESSIVE_IRQ_MAX_COUNT) {\n\t\t\t\t/*\n\t\t\t\t * Real hardware does not deliver the interrupt\n\t\t\t\t * immediately during eoi broadcast, and this\n\t\t\t\t * lets a buggy guest make slow progress\n\t\t\t\t * even if it does not correctly handle a\n\t\t\t\t * level-triggered interrupt.  Emulate this\n\t\t\t\t * behavior if we detect an interrupt storm.\n\t\t\t\t */\n\t\t\t\tschedule_delayed_work(&ioapic->eoi_inject, HZ / 100);\n\t\t\t\tioapic->irq_eoi[i] = 0;\n\t\t\t\ttrace_kvm_ioapic_delayed_eoi_inj(ent->bits);\n\t\t\t} else {\n\t\t\t\tioapic_service(ioapic, i, false);\n\t\t\t}\n\t\t} else {\n\t\t\tioapic->irq_eoi[i] = 0;\n\t\t}\n\t}\n}\n\nvoid kvm_ioapic_update_eoi(struct kvm_vcpu *vcpu, int vector, int trigger_mode)\n{\n\tstruct kvm_ioapic *ioapic = vcpu->kvm->arch.vioapic;\n\n\tspin_lock(&ioapic->lock);\n\t__kvm_ioapic_update_eoi(vcpu, ioapic, vector, trigger_mode);\n\tspin_unlock(&ioapic->lock);\n}\n\nstatic inline struct kvm_ioapic *to_ioapic(struct kvm_io_device *dev)\n{\n\treturn container_of(dev, struct kvm_ioapic, dev);\n}\n\nstatic inline int ioapic_in_range(struct kvm_ioapic *ioapic, gpa_t addr)\n{\n\treturn ((addr >= ioapic->base_address &&\n\t\t (addr < ioapic->base_address + IOAPIC_MEM_LENGTH)));\n}\n\nstatic int ioapic_mmio_read(struct kvm_vcpu *vcpu, struct kvm_io_device *this,\n\t\t\t\tgpa_t addr, int len, void *val)\n{\n\tstruct kvm_ioapic *ioapic = to_ioapic(this);\n\tu32 result;\n\tif (!ioapic_in_range(ioapic, addr))\n\t\treturn -EOPNOTSUPP;\n\n\tioapic_debug(\"addr %lx\\n\", (unsigned long)addr);\n\tASSERT(!(addr & 0xf));\t/* check alignment */\n\n\taddr &= 0xff;\n\tspin_lock(&ioapic->lock);\n\tswitch (addr) {\n\tcase IOAPIC_REG_SELECT:\n\t\tresult = ioapic->ioregsel;\n\t\tbreak;\n\n\tcase IOAPIC_REG_WINDOW:\n\t\tresult = ioapic_read_indirect(ioapic, addr, len);\n\t\tbreak;\n\n\tdefault:\n\t\tresult = 0;\n\t\tbreak;\n\t}\n\tspin_unlock(&ioapic->lock);\n\n\tswitch (len) {\n\tcase 8:\n\t\t*(u64 *) val = result;\n\t\tbreak;\n\tcase 1:\n\tcase 2:\n\tcase 4:\n\t\tmemcpy(val, (char *)&result, len);\n\t\tbreak;\n\tdefault:\n\t\tprintk(KERN_WARNING \"ioapic: wrong length %d\\n\", len);\n\t}\n\treturn 0;\n}\n\nstatic int ioapic_mmio_write(struct kvm_vcpu *vcpu, struct kvm_io_device *this,\n\t\t\t\t gpa_t addr, int len, const void *val)\n{\n\tstruct kvm_ioapic *ioapic = to_ioapic(this);\n\tu32 data;\n\tif (!ioapic_in_range(ioapic, addr))\n\t\treturn -EOPNOTSUPP;\n\n\tioapic_debug(\"ioapic_mmio_write addr=%p len=%d val=%p\\n\",\n\t\t     (void*)addr, len, val);\n\tASSERT(!(addr & 0xf));\t/* check alignment */\n\n\tswitch (len) {\n\tcase 8:\n\tcase 4:\n\t\tdata = *(u32 *) val;\n\t\tbreak;\n\tcase 2:\n\t\tdata = *(u16 *) val;\n\t\tbreak;\n\tcase 1:\n\t\tdata = *(u8  *) val;\n\t\tbreak;\n\tdefault:\n\t\tprintk(KERN_WARNING \"ioapic: Unsupported size %d\\n\", len);\n\t\treturn 0;\n\t}\n\n\taddr &= 0xff;\n\tspin_lock(&ioapic->lock);\n\tswitch (addr) {\n\tcase IOAPIC_REG_SELECT:\n\t\tioapic->ioregsel = data & 0xFF; /* 8-bit register */\n\t\tbreak;\n\n\tcase IOAPIC_REG_WINDOW:\n\t\tioapic_write_indirect(ioapic, data);\n\t\tbreak;\n\n\tdefault:\n\t\tbreak;\n\t}\n\tspin_unlock(&ioapic->lock);\n\treturn 0;\n}\n\nstatic void kvm_ioapic_reset(struct kvm_ioapic *ioapic)\n{\n\tint i;\n\n\tcancel_delayed_work_sync(&ioapic->eoi_inject);\n\tfor (i = 0; i < IOAPIC_NUM_PINS; i++)\n\t\tioapic->redirtbl[i].fields.mask = 1;\n\tioapic->base_address = IOAPIC_DEFAULT_BASE_ADDRESS;\n\tioapic->ioregsel = 0;\n\tioapic->irr = 0;\n\tioapic->irr_delivered = 0;\n\tioapic->id = 0;\n\tmemset(ioapic->irq_eoi, 0x00, sizeof(ioapic->irq_eoi));\n\trtc_irq_eoi_tracking_reset(ioapic);\n}\n\nstatic const struct kvm_io_device_ops ioapic_mmio_ops = {\n\t.read     = ioapic_mmio_read,\n\t.write    = ioapic_mmio_write,\n};\n\nint kvm_ioapic_init(struct kvm *kvm)\n{\n\tstruct kvm_ioapic *ioapic;\n\tint ret;\n\n\tioapic = kzalloc(sizeof(struct kvm_ioapic), GFP_KERNEL);\n\tif (!ioapic)\n\t\treturn -ENOMEM;\n\tspin_lock_init(&ioapic->lock);\n\tINIT_DELAYED_WORK(&ioapic->eoi_inject, kvm_ioapic_eoi_inject_work);\n\tkvm->arch.vioapic = ioapic;\n\tkvm_ioapic_reset(ioapic);\n\tkvm_iodevice_init(&ioapic->dev, &ioapic_mmio_ops);\n\tioapic->kvm = kvm;\n\tmutex_lock(&kvm->slots_lock);\n\tret = kvm_io_bus_register_dev(kvm, KVM_MMIO_BUS, ioapic->base_address,\n\t\t\t\t      IOAPIC_MEM_LENGTH, &ioapic->dev);\n\tmutex_unlock(&kvm->slots_lock);\n\tif (ret < 0) {\n\t\tkvm->arch.vioapic = NULL;\n\t\tkfree(ioapic);\n\t\treturn ret;\n\t}\n\n\tkvm_vcpu_request_scan_ioapic(kvm);\n\treturn ret;\n}\n\nvoid kvm_ioapic_destroy(struct kvm *kvm)\n{\n\tstruct kvm_ioapic *ioapic = kvm->arch.vioapic;\n\n\tcancel_delayed_work_sync(&ioapic->eoi_inject);\n\tkvm_io_bus_unregister_dev(kvm, KVM_MMIO_BUS, &ioapic->dev);\n\tkvm->arch.vioapic = NULL;\n\tkfree(ioapic);\n}\n\nint kvm_get_ioapic(struct kvm *kvm, struct kvm_ioapic_state *state)\n{\n\tstruct kvm_ioapic *ioapic = ioapic_irqchip(kvm);\n\tif (!ioapic)\n\t\treturn -EINVAL;\n\n\tspin_lock(&ioapic->lock);\n\tmemcpy(state, ioapic, sizeof(struct kvm_ioapic_state));\n\tstate->irr &= ~ioapic->irr_delivered;\n\tspin_unlock(&ioapic->lock);\n\treturn 0;\n}\n\nint kvm_set_ioapic(struct kvm *kvm, struct kvm_ioapic_state *state)\n{\n\tstruct kvm_ioapic *ioapic = ioapic_irqchip(kvm);\n\tif (!ioapic)\n\t\treturn -EINVAL;\n\n\tspin_lock(&ioapic->lock);\n\tmemcpy(ioapic, state, sizeof(struct kvm_ioapic_state));\n\tioapic->irr = 0;\n\tioapic->irr_delivered = 0;\n\tkvm_vcpu_request_scan_ioapic(kvm);\n\tkvm_ioapic_inject_all(ioapic, state->irr);\n\tspin_unlock(&ioapic->lock);\n\treturn 0;\n}\n", "#ifndef __KVM_IO_APIC_H\n#define __KVM_IO_APIC_H\n\n#include <linux/kvm_host.h>\n\n#include <kvm/iodev.h>\n\nstruct kvm;\nstruct kvm_vcpu;\n\n#define IOAPIC_NUM_PINS  KVM_IOAPIC_NUM_PINS\n#define MAX_NR_RESERVED_IOAPIC_PINS KVM_MAX_IRQ_ROUTES\n#define IOAPIC_VERSION_ID 0x11\t/* IOAPIC version */\n#define IOAPIC_EDGE_TRIG  0\n#define IOAPIC_LEVEL_TRIG 1\n\n#define IOAPIC_DEFAULT_BASE_ADDRESS  0xfec00000\n#define IOAPIC_MEM_LENGTH            0x100\n\n/* Direct registers. */\n#define IOAPIC_REG_SELECT  0x00\n#define IOAPIC_REG_WINDOW  0x10\n\n/* Indirect registers. */\n#define IOAPIC_REG_APIC_ID 0x00\t/* x86 IOAPIC only */\n#define IOAPIC_REG_VERSION 0x01\n#define IOAPIC_REG_ARB_ID  0x02\t/* x86 IOAPIC only */\n\n/*ioapic delivery mode*/\n#define\tIOAPIC_FIXED\t\t\t0x0\n#define\tIOAPIC_LOWEST_PRIORITY\t\t0x1\n#define\tIOAPIC_PMI\t\t\t0x2\n#define\tIOAPIC_NMI\t\t\t0x4\n#define\tIOAPIC_INIT\t\t\t0x5\n#define\tIOAPIC_EXTINT\t\t\t0x7\n\n#ifdef CONFIG_X86\n#define RTC_GSI 8\n#else\n#define RTC_GSI -1U\n#endif\n\nstruct dest_map {\n\t/* vcpu bitmap where IRQ has been sent */\n\tDECLARE_BITMAP(map, KVM_MAX_VCPUS);\n\n\t/*\n\t * Vector sent to a given vcpu, only valid when\n\t * the vcpu's bit in map is set\n\t */\n\tu8 vectors[KVM_MAX_VCPUS];\n};\n\n\nstruct rtc_status {\n\tint pending_eoi;\n\tstruct dest_map dest_map;\n};\n\nunion kvm_ioapic_redirect_entry {\n\tu64 bits;\n\tstruct {\n\t\tu8 vector;\n\t\tu8 delivery_mode:3;\n\t\tu8 dest_mode:1;\n\t\tu8 delivery_status:1;\n\t\tu8 polarity:1;\n\t\tu8 remote_irr:1;\n\t\tu8 trig_mode:1;\n\t\tu8 mask:1;\n\t\tu8 reserve:7;\n\t\tu8 reserved[4];\n\t\tu8 dest_id;\n\t} fields;\n};\n\nstruct kvm_ioapic {\n\tu64 base_address;\n\tu32 ioregsel;\n\tu32 id;\n\tu32 irr;\n\tu32 pad;\n\tunion kvm_ioapic_redirect_entry redirtbl[IOAPIC_NUM_PINS];\n\tunsigned long irq_states[IOAPIC_NUM_PINS];\n\tstruct kvm_io_device dev;\n\tstruct kvm *kvm;\n\tvoid (*ack_notifier)(void *opaque, int irq);\n\tspinlock_t lock;\n\tstruct rtc_status rtc_status;\n\tstruct delayed_work eoi_inject;\n\tu32 irq_eoi[IOAPIC_NUM_PINS];\n\tu32 irr_delivered;\n};\n\n#ifdef DEBUG\n#define ASSERT(x)  \t\t\t\t\t\t\t\\\ndo {\t\t\t\t\t\t\t\t\t\\\n\tif (!(x)) {\t\t\t\t\t\t\t\\\n\t\tprintk(KERN_EMERG \"assertion failed %s: %d: %s\\n\",\t\\\n\t\t       __FILE__, __LINE__, #x);\t\t\t\t\\\n\t\tBUG();\t\t\t\t\t\t\t\\\n\t}\t\t\t\t\t\t\t\t\\\n} while (0)\n#else\n#define ASSERT(x) do { } while (0)\n#endif\n\nstatic inline struct kvm_ioapic *ioapic_irqchip(struct kvm *kvm)\n{\n\treturn kvm->arch.vioapic;\n}\n\nstatic inline int ioapic_in_kernel(struct kvm *kvm)\n{\n\tint ret;\n\n\tret = (ioapic_irqchip(kvm) != NULL);\n\treturn ret;\n}\n\nvoid kvm_rtc_eoi_tracking_restore_one(struct kvm_vcpu *vcpu);\nbool kvm_apic_match_dest(struct kvm_vcpu *vcpu, struct kvm_lapic *source,\n\t\tint short_hand, unsigned int dest, int dest_mode);\nint kvm_apic_compare_prio(struct kvm_vcpu *vcpu1, struct kvm_vcpu *vcpu2);\nvoid kvm_ioapic_update_eoi(struct kvm_vcpu *vcpu, int vector,\n\t\t\tint trigger_mode);\nint kvm_ioapic_init(struct kvm *kvm);\nvoid kvm_ioapic_destroy(struct kvm *kvm);\nint kvm_ioapic_set_irq(struct kvm_ioapic *ioapic, int irq, int irq_source_id,\n\t\t       int level, bool line_status);\nvoid kvm_ioapic_clear_all(struct kvm_ioapic *ioapic, int irq_source_id);\nint kvm_irq_delivery_to_apic(struct kvm *kvm, struct kvm_lapic *src,\n\t\t\t     struct kvm_lapic_irq *irq,\n\t\t\t     struct dest_map *dest_map);\nint kvm_get_ioapic(struct kvm *kvm, struct kvm_ioapic_state *state);\nint kvm_set_ioapic(struct kvm *kvm, struct kvm_ioapic_state *state);\nvoid kvm_ioapic_scan_entry(struct kvm_vcpu *vcpu,\n\t\t\t   ulong *ioapic_handled_vectors);\nvoid kvm_scan_ioapic_routes(struct kvm_vcpu *vcpu,\n\t\t\t    ulong *ioapic_handled_vectors);\n#endif\n"], "fixing_code": ["/*\n *  Copyright (C) 2001  MandrakeSoft S.A.\n *  Copyright 2010 Red Hat, Inc. and/or its affiliates.\n *\n *    MandrakeSoft S.A.\n *    43, rue d'Aboukir\n *    75002 Paris - France\n *    http://www.linux-mandrake.com/\n *    http://www.mandrakesoft.com/\n *\n *  This library is free software; you can redistribute it and/or\n *  modify it under the terms of the GNU Lesser General Public\n *  License as published by the Free Software Foundation; either\n *  version 2 of the License, or (at your option) any later version.\n *\n *  This library is distributed in the hope that it will be useful,\n *  but WITHOUT ANY WARRANTY; without even the implied warranty of\n *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n *  Lesser General Public License for more details.\n *\n *  You should have received a copy of the GNU Lesser General Public\n *  License along with this library; if not, write to the Free Software\n *  Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307 USA\n *\n *  Yunhong Jiang <yunhong.jiang@intel.com>\n *  Yaozu (Eddie) Dong <eddie.dong@intel.com>\n *  Based on Xen 3.1 code.\n */\n\n#include <linux/kvm_host.h>\n#include <linux/kvm.h>\n#include <linux/mm.h>\n#include <linux/highmem.h>\n#include <linux/smp.h>\n#include <linux/hrtimer.h>\n#include <linux/io.h>\n#include <linux/slab.h>\n#include <linux/export.h>\n#include <asm/processor.h>\n#include <asm/page.h>\n#include <asm/current.h>\n#include <trace/events/kvm.h>\n\n#include \"ioapic.h\"\n#include \"lapic.h\"\n#include \"irq.h\"\n\n#if 0\n#define ioapic_debug(fmt,arg...) printk(KERN_WARNING fmt,##arg)\n#else\n#define ioapic_debug(fmt, arg...)\n#endif\nstatic int ioapic_service(struct kvm_ioapic *vioapic, int irq,\n\t\tbool line_status);\n\nstatic unsigned long ioapic_read_indirect(struct kvm_ioapic *ioapic,\n\t\t\t\t\t  unsigned long addr,\n\t\t\t\t\t  unsigned long length)\n{\n\tunsigned long result = 0;\n\n\tswitch (ioapic->ioregsel) {\n\tcase IOAPIC_REG_VERSION:\n\t\tresult = ((((IOAPIC_NUM_PINS - 1) & 0xff) << 16)\n\t\t\t  | (IOAPIC_VERSION_ID & 0xff));\n\t\tbreak;\n\n\tcase IOAPIC_REG_APIC_ID:\n\tcase IOAPIC_REG_ARB_ID:\n\t\tresult = ((ioapic->id & 0xf) << 24);\n\t\tbreak;\n\n\tdefault:\n\t\t{\n\t\t\tu32 redir_index = (ioapic->ioregsel - 0x10) >> 1;\n\t\t\tu64 redir_content;\n\n\t\t\tif (redir_index < IOAPIC_NUM_PINS)\n\t\t\t\tredir_content =\n\t\t\t\t\tioapic->redirtbl[redir_index].bits;\n\t\t\telse\n\t\t\t\tredir_content = ~0ULL;\n\n\t\t\tresult = (ioapic->ioregsel & 0x1) ?\n\t\t\t    (redir_content >> 32) & 0xffffffff :\n\t\t\t    redir_content & 0xffffffff;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\treturn result;\n}\n\nstatic void rtc_irq_eoi_tracking_reset(struct kvm_ioapic *ioapic)\n{\n\tioapic->rtc_status.pending_eoi = 0;\n\tbitmap_zero(ioapic->rtc_status.dest_map.map, KVM_MAX_VCPU_ID);\n}\n\nstatic void kvm_rtc_eoi_tracking_restore_all(struct kvm_ioapic *ioapic);\n\nstatic void rtc_status_pending_eoi_check_valid(struct kvm_ioapic *ioapic)\n{\n\tif (WARN_ON(ioapic->rtc_status.pending_eoi < 0))\n\t\tkvm_rtc_eoi_tracking_restore_all(ioapic);\n}\n\nstatic void __rtc_irq_eoi_tracking_restore_one(struct kvm_vcpu *vcpu)\n{\n\tbool new_val, old_val;\n\tstruct kvm_ioapic *ioapic = vcpu->kvm->arch.vioapic;\n\tstruct dest_map *dest_map = &ioapic->rtc_status.dest_map;\n\tunion kvm_ioapic_redirect_entry *e;\n\n\te = &ioapic->redirtbl[RTC_GSI];\n\tif (!kvm_apic_match_dest(vcpu, NULL, 0,\te->fields.dest_id,\n\t\t\t\te->fields.dest_mode))\n\t\treturn;\n\n\tnew_val = kvm_apic_pending_eoi(vcpu, e->fields.vector);\n\told_val = test_bit(vcpu->vcpu_id, dest_map->map);\n\n\tif (new_val == old_val)\n\t\treturn;\n\n\tif (new_val) {\n\t\t__set_bit(vcpu->vcpu_id, dest_map->map);\n\t\tdest_map->vectors[vcpu->vcpu_id] = e->fields.vector;\n\t\tioapic->rtc_status.pending_eoi++;\n\t} else {\n\t\t__clear_bit(vcpu->vcpu_id, dest_map->map);\n\t\tioapic->rtc_status.pending_eoi--;\n\t\trtc_status_pending_eoi_check_valid(ioapic);\n\t}\n}\n\nvoid kvm_rtc_eoi_tracking_restore_one(struct kvm_vcpu *vcpu)\n{\n\tstruct kvm_ioapic *ioapic = vcpu->kvm->arch.vioapic;\n\n\tspin_lock(&ioapic->lock);\n\t__rtc_irq_eoi_tracking_restore_one(vcpu);\n\tspin_unlock(&ioapic->lock);\n}\n\nstatic void kvm_rtc_eoi_tracking_restore_all(struct kvm_ioapic *ioapic)\n{\n\tstruct kvm_vcpu *vcpu;\n\tint i;\n\n\tif (RTC_GSI >= IOAPIC_NUM_PINS)\n\t\treturn;\n\n\trtc_irq_eoi_tracking_reset(ioapic);\n\tkvm_for_each_vcpu(i, vcpu, ioapic->kvm)\n\t    __rtc_irq_eoi_tracking_restore_one(vcpu);\n}\n\nstatic void rtc_irq_eoi(struct kvm_ioapic *ioapic, struct kvm_vcpu *vcpu)\n{\n\tif (test_and_clear_bit(vcpu->vcpu_id,\n\t\t\t       ioapic->rtc_status.dest_map.map)) {\n\t\t--ioapic->rtc_status.pending_eoi;\n\t\trtc_status_pending_eoi_check_valid(ioapic);\n\t}\n}\n\nstatic bool rtc_irq_check_coalesced(struct kvm_ioapic *ioapic)\n{\n\tif (ioapic->rtc_status.pending_eoi > 0)\n\t\treturn true; /* coalesced */\n\n\treturn false;\n}\n\nstatic int ioapic_set_irq(struct kvm_ioapic *ioapic, unsigned int irq,\n\t\tint irq_level, bool line_status)\n{\n\tunion kvm_ioapic_redirect_entry entry;\n\tu32 mask = 1 << irq;\n\tu32 old_irr;\n\tint edge, ret;\n\n\tentry = ioapic->redirtbl[irq];\n\tedge = (entry.fields.trig_mode == IOAPIC_EDGE_TRIG);\n\n\tif (!irq_level) {\n\t\tioapic->irr &= ~mask;\n\t\tret = 1;\n\t\tgoto out;\n\t}\n\n\t/*\n\t * Return 0 for coalesced interrupts; for edge-triggered interrupts,\n\t * this only happens if a previous edge has not been delivered due\n\t * do masking.  For level interrupts, the remote_irr field tells\n\t * us if the interrupt is waiting for an EOI.\n\t *\n\t * RTC is special: it is edge-triggered, but userspace likes to know\n\t * if it has been already ack-ed via EOI because coalesced RTC\n\t * interrupts lead to time drift in Windows guests.  So we track\n\t * EOI manually for the RTC interrupt.\n\t */\n\tif (irq == RTC_GSI && line_status &&\n\t\trtc_irq_check_coalesced(ioapic)) {\n\t\tret = 0;\n\t\tgoto out;\n\t}\n\n\told_irr = ioapic->irr;\n\tioapic->irr |= mask;\n\tif (edge)\n\t\tioapic->irr_delivered &= ~mask;\n\tif ((edge && old_irr == ioapic->irr) ||\n\t    (!edge && entry.fields.remote_irr)) {\n\t\tret = 0;\n\t\tgoto out;\n\t}\n\n\tret = ioapic_service(ioapic, irq, line_status);\n\nout:\n\ttrace_kvm_ioapic_set_irq(entry.bits, irq, ret == 0);\n\treturn ret;\n}\n\nstatic void kvm_ioapic_inject_all(struct kvm_ioapic *ioapic, unsigned long irr)\n{\n\tu32 idx;\n\n\trtc_irq_eoi_tracking_reset(ioapic);\n\tfor_each_set_bit(idx, &irr, IOAPIC_NUM_PINS)\n\t\tioapic_set_irq(ioapic, idx, 1, true);\n\n\tkvm_rtc_eoi_tracking_restore_all(ioapic);\n}\n\n\nvoid kvm_ioapic_scan_entry(struct kvm_vcpu *vcpu, ulong *ioapic_handled_vectors)\n{\n\tstruct kvm_ioapic *ioapic = vcpu->kvm->arch.vioapic;\n\tstruct dest_map *dest_map = &ioapic->rtc_status.dest_map;\n\tunion kvm_ioapic_redirect_entry *e;\n\tint index;\n\n\tspin_lock(&ioapic->lock);\n\n\t/* Make sure we see any missing RTC EOI */\n\tif (test_bit(vcpu->vcpu_id, dest_map->map))\n\t\t__set_bit(dest_map->vectors[vcpu->vcpu_id],\n\t\t\t  ioapic_handled_vectors);\n\n\tfor (index = 0; index < IOAPIC_NUM_PINS; index++) {\n\t\te = &ioapic->redirtbl[index];\n\t\tif (e->fields.trig_mode == IOAPIC_LEVEL_TRIG ||\n\t\t    kvm_irq_has_notifier(ioapic->kvm, KVM_IRQCHIP_IOAPIC, index) ||\n\t\t    index == RTC_GSI) {\n\t\t\tif (kvm_apic_match_dest(vcpu, NULL, 0,\n\t\t\t             e->fields.dest_id, e->fields.dest_mode) ||\n\t\t\t    (e->fields.trig_mode == IOAPIC_EDGE_TRIG &&\n\t\t\t     kvm_apic_pending_eoi(vcpu, e->fields.vector)))\n\t\t\t\t__set_bit(e->fields.vector,\n\t\t\t\t\t  ioapic_handled_vectors);\n\t\t}\n\t}\n\tspin_unlock(&ioapic->lock);\n}\n\nvoid kvm_vcpu_request_scan_ioapic(struct kvm *kvm)\n{\n\tstruct kvm_ioapic *ioapic = kvm->arch.vioapic;\n\n\tif (!ioapic)\n\t\treturn;\n\tkvm_make_scan_ioapic_request(kvm);\n}\n\nstatic void ioapic_write_indirect(struct kvm_ioapic *ioapic, u32 val)\n{\n\tunsigned index;\n\tbool mask_before, mask_after;\n\tunion kvm_ioapic_redirect_entry *e;\n\n\tswitch (ioapic->ioregsel) {\n\tcase IOAPIC_REG_VERSION:\n\t\t/* Writes are ignored. */\n\t\tbreak;\n\n\tcase IOAPIC_REG_APIC_ID:\n\t\tioapic->id = (val >> 24) & 0xf;\n\t\tbreak;\n\n\tcase IOAPIC_REG_ARB_ID:\n\t\tbreak;\n\n\tdefault:\n\t\tindex = (ioapic->ioregsel - 0x10) >> 1;\n\n\t\tioapic_debug(\"change redir index %x val %x\\n\", index, val);\n\t\tif (index >= IOAPIC_NUM_PINS)\n\t\t\treturn;\n\t\te = &ioapic->redirtbl[index];\n\t\tmask_before = e->fields.mask;\n\t\tif (ioapic->ioregsel & 1) {\n\t\t\te->bits &= 0xffffffff;\n\t\t\te->bits |= (u64) val << 32;\n\t\t} else {\n\t\t\te->bits &= ~0xffffffffULL;\n\t\t\te->bits |= (u32) val;\n\t\t\te->fields.remote_irr = 0;\n\t\t}\n\t\tmask_after = e->fields.mask;\n\t\tif (mask_before != mask_after)\n\t\t\tkvm_fire_mask_notifiers(ioapic->kvm, KVM_IRQCHIP_IOAPIC, index, mask_after);\n\t\tif (e->fields.trig_mode == IOAPIC_LEVEL_TRIG\n\t\t    && ioapic->irr & (1 << index))\n\t\t\tioapic_service(ioapic, index, false);\n\t\tkvm_vcpu_request_scan_ioapic(ioapic->kvm);\n\t\tbreak;\n\t}\n}\n\nstatic int ioapic_service(struct kvm_ioapic *ioapic, int irq, bool line_status)\n{\n\tunion kvm_ioapic_redirect_entry *entry = &ioapic->redirtbl[irq];\n\tstruct kvm_lapic_irq irqe;\n\tint ret;\n\n\tif (entry->fields.mask)\n\t\treturn -1;\n\n\tioapic_debug(\"dest=%x dest_mode=%x delivery_mode=%x \"\n\t\t     \"vector=%x trig_mode=%x\\n\",\n\t\t     entry->fields.dest_id, entry->fields.dest_mode,\n\t\t     entry->fields.delivery_mode, entry->fields.vector,\n\t\t     entry->fields.trig_mode);\n\n\tirqe.dest_id = entry->fields.dest_id;\n\tirqe.vector = entry->fields.vector;\n\tirqe.dest_mode = entry->fields.dest_mode;\n\tirqe.trig_mode = entry->fields.trig_mode;\n\tirqe.delivery_mode = entry->fields.delivery_mode << 8;\n\tirqe.level = 1;\n\tirqe.shorthand = 0;\n\tirqe.msi_redir_hint = false;\n\n\tif (irqe.trig_mode == IOAPIC_EDGE_TRIG)\n\t\tioapic->irr_delivered |= 1 << irq;\n\n\tif (irq == RTC_GSI && line_status) {\n\t\t/*\n\t\t * pending_eoi cannot ever become negative (see\n\t\t * rtc_status_pending_eoi_check_valid) and the caller\n\t\t * ensures that it is only called if it is >= zero, namely\n\t\t * if rtc_irq_check_coalesced returns false).\n\t\t */\n\t\tBUG_ON(ioapic->rtc_status.pending_eoi != 0);\n\t\tret = kvm_irq_delivery_to_apic(ioapic->kvm, NULL, &irqe,\n\t\t\t\t\t       &ioapic->rtc_status.dest_map);\n\t\tioapic->rtc_status.pending_eoi = (ret < 0 ? 0 : ret);\n\t} else\n\t\tret = kvm_irq_delivery_to_apic(ioapic->kvm, NULL, &irqe, NULL);\n\n\tif (ret && irqe.trig_mode == IOAPIC_LEVEL_TRIG)\n\t\tentry->fields.remote_irr = 1;\n\n\treturn ret;\n}\n\nint kvm_ioapic_set_irq(struct kvm_ioapic *ioapic, int irq, int irq_source_id,\n\t\t       int level, bool line_status)\n{\n\tint ret, irq_level;\n\n\tBUG_ON(irq < 0 || irq >= IOAPIC_NUM_PINS);\n\n\tspin_lock(&ioapic->lock);\n\tirq_level = __kvm_irq_line_state(&ioapic->irq_states[irq],\n\t\t\t\t\t irq_source_id, level);\n\tret = ioapic_set_irq(ioapic, irq, irq_level, line_status);\n\n\tspin_unlock(&ioapic->lock);\n\n\treturn ret;\n}\n\nvoid kvm_ioapic_clear_all(struct kvm_ioapic *ioapic, int irq_source_id)\n{\n\tint i;\n\n\tspin_lock(&ioapic->lock);\n\tfor (i = 0; i < KVM_IOAPIC_NUM_PINS; i++)\n\t\t__clear_bit(irq_source_id, &ioapic->irq_states[i]);\n\tspin_unlock(&ioapic->lock);\n}\n\nstatic void kvm_ioapic_eoi_inject_work(struct work_struct *work)\n{\n\tint i;\n\tstruct kvm_ioapic *ioapic = container_of(work, struct kvm_ioapic,\n\t\t\t\t\t\t eoi_inject.work);\n\tspin_lock(&ioapic->lock);\n\tfor (i = 0; i < IOAPIC_NUM_PINS; i++) {\n\t\tunion kvm_ioapic_redirect_entry *ent = &ioapic->redirtbl[i];\n\n\t\tif (ent->fields.trig_mode != IOAPIC_LEVEL_TRIG)\n\t\t\tcontinue;\n\n\t\tif (ioapic->irr & (1 << i) && !ent->fields.remote_irr)\n\t\t\tioapic_service(ioapic, i, false);\n\t}\n\tspin_unlock(&ioapic->lock);\n}\n\n#define IOAPIC_SUCCESSIVE_IRQ_MAX_COUNT 10000\n\nstatic void __kvm_ioapic_update_eoi(struct kvm_vcpu *vcpu,\n\t\t\tstruct kvm_ioapic *ioapic, int vector, int trigger_mode)\n{\n\tstruct dest_map *dest_map = &ioapic->rtc_status.dest_map;\n\tstruct kvm_lapic *apic = vcpu->arch.apic;\n\tint i;\n\n\t/* RTC special handling */\n\tif (test_bit(vcpu->vcpu_id, dest_map->map) &&\n\t    vector == dest_map->vectors[vcpu->vcpu_id])\n\t\trtc_irq_eoi(ioapic, vcpu);\n\n\tfor (i = 0; i < IOAPIC_NUM_PINS; i++) {\n\t\tunion kvm_ioapic_redirect_entry *ent = &ioapic->redirtbl[i];\n\n\t\tif (ent->fields.vector != vector)\n\t\t\tcontinue;\n\n\t\t/*\n\t\t * We are dropping lock while calling ack notifiers because ack\n\t\t * notifier callbacks for assigned devices call into IOAPIC\n\t\t * recursively. Since remote_irr is cleared only after call\n\t\t * to notifiers if the same vector will be delivered while lock\n\t\t * is dropped it will be put into irr and will be delivered\n\t\t * after ack notifier returns.\n\t\t */\n\t\tspin_unlock(&ioapic->lock);\n\t\tkvm_notify_acked_irq(ioapic->kvm, KVM_IRQCHIP_IOAPIC, i);\n\t\tspin_lock(&ioapic->lock);\n\n\t\tif (trigger_mode != IOAPIC_LEVEL_TRIG ||\n\t\t    kvm_lapic_get_reg(apic, APIC_SPIV) & APIC_SPIV_DIRECTED_EOI)\n\t\t\tcontinue;\n\n\t\tASSERT(ent->fields.trig_mode == IOAPIC_LEVEL_TRIG);\n\t\tent->fields.remote_irr = 0;\n\t\tif (!ent->fields.mask && (ioapic->irr & (1 << i))) {\n\t\t\t++ioapic->irq_eoi[i];\n\t\t\tif (ioapic->irq_eoi[i] == IOAPIC_SUCCESSIVE_IRQ_MAX_COUNT) {\n\t\t\t\t/*\n\t\t\t\t * Real hardware does not deliver the interrupt\n\t\t\t\t * immediately during eoi broadcast, and this\n\t\t\t\t * lets a buggy guest make slow progress\n\t\t\t\t * even if it does not correctly handle a\n\t\t\t\t * level-triggered interrupt.  Emulate this\n\t\t\t\t * behavior if we detect an interrupt storm.\n\t\t\t\t */\n\t\t\t\tschedule_delayed_work(&ioapic->eoi_inject, HZ / 100);\n\t\t\t\tioapic->irq_eoi[i] = 0;\n\t\t\t\ttrace_kvm_ioapic_delayed_eoi_inj(ent->bits);\n\t\t\t} else {\n\t\t\t\tioapic_service(ioapic, i, false);\n\t\t\t}\n\t\t} else {\n\t\t\tioapic->irq_eoi[i] = 0;\n\t\t}\n\t}\n}\n\nvoid kvm_ioapic_update_eoi(struct kvm_vcpu *vcpu, int vector, int trigger_mode)\n{\n\tstruct kvm_ioapic *ioapic = vcpu->kvm->arch.vioapic;\n\n\tspin_lock(&ioapic->lock);\n\t__kvm_ioapic_update_eoi(vcpu, ioapic, vector, trigger_mode);\n\tspin_unlock(&ioapic->lock);\n}\n\nstatic inline struct kvm_ioapic *to_ioapic(struct kvm_io_device *dev)\n{\n\treturn container_of(dev, struct kvm_ioapic, dev);\n}\n\nstatic inline int ioapic_in_range(struct kvm_ioapic *ioapic, gpa_t addr)\n{\n\treturn ((addr >= ioapic->base_address &&\n\t\t (addr < ioapic->base_address + IOAPIC_MEM_LENGTH)));\n}\n\nstatic int ioapic_mmio_read(struct kvm_vcpu *vcpu, struct kvm_io_device *this,\n\t\t\t\tgpa_t addr, int len, void *val)\n{\n\tstruct kvm_ioapic *ioapic = to_ioapic(this);\n\tu32 result;\n\tif (!ioapic_in_range(ioapic, addr))\n\t\treturn -EOPNOTSUPP;\n\n\tioapic_debug(\"addr %lx\\n\", (unsigned long)addr);\n\tASSERT(!(addr & 0xf));\t/* check alignment */\n\n\taddr &= 0xff;\n\tspin_lock(&ioapic->lock);\n\tswitch (addr) {\n\tcase IOAPIC_REG_SELECT:\n\t\tresult = ioapic->ioregsel;\n\t\tbreak;\n\n\tcase IOAPIC_REG_WINDOW:\n\t\tresult = ioapic_read_indirect(ioapic, addr, len);\n\t\tbreak;\n\n\tdefault:\n\t\tresult = 0;\n\t\tbreak;\n\t}\n\tspin_unlock(&ioapic->lock);\n\n\tswitch (len) {\n\tcase 8:\n\t\t*(u64 *) val = result;\n\t\tbreak;\n\tcase 1:\n\tcase 2:\n\tcase 4:\n\t\tmemcpy(val, (char *)&result, len);\n\t\tbreak;\n\tdefault:\n\t\tprintk(KERN_WARNING \"ioapic: wrong length %d\\n\", len);\n\t}\n\treturn 0;\n}\n\nstatic int ioapic_mmio_write(struct kvm_vcpu *vcpu, struct kvm_io_device *this,\n\t\t\t\t gpa_t addr, int len, const void *val)\n{\n\tstruct kvm_ioapic *ioapic = to_ioapic(this);\n\tu32 data;\n\tif (!ioapic_in_range(ioapic, addr))\n\t\treturn -EOPNOTSUPP;\n\n\tioapic_debug(\"ioapic_mmio_write addr=%p len=%d val=%p\\n\",\n\t\t     (void*)addr, len, val);\n\tASSERT(!(addr & 0xf));\t/* check alignment */\n\n\tswitch (len) {\n\tcase 8:\n\tcase 4:\n\t\tdata = *(u32 *) val;\n\t\tbreak;\n\tcase 2:\n\t\tdata = *(u16 *) val;\n\t\tbreak;\n\tcase 1:\n\t\tdata = *(u8  *) val;\n\t\tbreak;\n\tdefault:\n\t\tprintk(KERN_WARNING \"ioapic: Unsupported size %d\\n\", len);\n\t\treturn 0;\n\t}\n\n\taddr &= 0xff;\n\tspin_lock(&ioapic->lock);\n\tswitch (addr) {\n\tcase IOAPIC_REG_SELECT:\n\t\tioapic->ioregsel = data & 0xFF; /* 8-bit register */\n\t\tbreak;\n\n\tcase IOAPIC_REG_WINDOW:\n\t\tioapic_write_indirect(ioapic, data);\n\t\tbreak;\n\n\tdefault:\n\t\tbreak;\n\t}\n\tspin_unlock(&ioapic->lock);\n\treturn 0;\n}\n\nstatic void kvm_ioapic_reset(struct kvm_ioapic *ioapic)\n{\n\tint i;\n\n\tcancel_delayed_work_sync(&ioapic->eoi_inject);\n\tfor (i = 0; i < IOAPIC_NUM_PINS; i++)\n\t\tioapic->redirtbl[i].fields.mask = 1;\n\tioapic->base_address = IOAPIC_DEFAULT_BASE_ADDRESS;\n\tioapic->ioregsel = 0;\n\tioapic->irr = 0;\n\tioapic->irr_delivered = 0;\n\tioapic->id = 0;\n\tmemset(ioapic->irq_eoi, 0x00, sizeof(ioapic->irq_eoi));\n\trtc_irq_eoi_tracking_reset(ioapic);\n}\n\nstatic const struct kvm_io_device_ops ioapic_mmio_ops = {\n\t.read     = ioapic_mmio_read,\n\t.write    = ioapic_mmio_write,\n};\n\nint kvm_ioapic_init(struct kvm *kvm)\n{\n\tstruct kvm_ioapic *ioapic;\n\tint ret;\n\n\tioapic = kzalloc(sizeof(struct kvm_ioapic), GFP_KERNEL);\n\tif (!ioapic)\n\t\treturn -ENOMEM;\n\tspin_lock_init(&ioapic->lock);\n\tINIT_DELAYED_WORK(&ioapic->eoi_inject, kvm_ioapic_eoi_inject_work);\n\tkvm->arch.vioapic = ioapic;\n\tkvm_ioapic_reset(ioapic);\n\tkvm_iodevice_init(&ioapic->dev, &ioapic_mmio_ops);\n\tioapic->kvm = kvm;\n\tmutex_lock(&kvm->slots_lock);\n\tret = kvm_io_bus_register_dev(kvm, KVM_MMIO_BUS, ioapic->base_address,\n\t\t\t\t      IOAPIC_MEM_LENGTH, &ioapic->dev);\n\tmutex_unlock(&kvm->slots_lock);\n\tif (ret < 0) {\n\t\tkvm->arch.vioapic = NULL;\n\t\tkfree(ioapic);\n\t\treturn ret;\n\t}\n\n\tkvm_vcpu_request_scan_ioapic(kvm);\n\treturn ret;\n}\n\nvoid kvm_ioapic_destroy(struct kvm *kvm)\n{\n\tstruct kvm_ioapic *ioapic = kvm->arch.vioapic;\n\n\tcancel_delayed_work_sync(&ioapic->eoi_inject);\n\tkvm_io_bus_unregister_dev(kvm, KVM_MMIO_BUS, &ioapic->dev);\n\tkvm->arch.vioapic = NULL;\n\tkfree(ioapic);\n}\n\nint kvm_get_ioapic(struct kvm *kvm, struct kvm_ioapic_state *state)\n{\n\tstruct kvm_ioapic *ioapic = ioapic_irqchip(kvm);\n\tif (!ioapic)\n\t\treturn -EINVAL;\n\n\tspin_lock(&ioapic->lock);\n\tmemcpy(state, ioapic, sizeof(struct kvm_ioapic_state));\n\tstate->irr &= ~ioapic->irr_delivered;\n\tspin_unlock(&ioapic->lock);\n\treturn 0;\n}\n\nint kvm_set_ioapic(struct kvm *kvm, struct kvm_ioapic_state *state)\n{\n\tstruct kvm_ioapic *ioapic = ioapic_irqchip(kvm);\n\tif (!ioapic)\n\t\treturn -EINVAL;\n\n\tspin_lock(&ioapic->lock);\n\tmemcpy(ioapic, state, sizeof(struct kvm_ioapic_state));\n\tioapic->irr = 0;\n\tioapic->irr_delivered = 0;\n\tkvm_vcpu_request_scan_ioapic(kvm);\n\tkvm_ioapic_inject_all(ioapic, state->irr);\n\tspin_unlock(&ioapic->lock);\n\treturn 0;\n}\n", "#ifndef __KVM_IO_APIC_H\n#define __KVM_IO_APIC_H\n\n#include <linux/kvm_host.h>\n\n#include <kvm/iodev.h>\n\nstruct kvm;\nstruct kvm_vcpu;\n\n#define IOAPIC_NUM_PINS  KVM_IOAPIC_NUM_PINS\n#define MAX_NR_RESERVED_IOAPIC_PINS KVM_MAX_IRQ_ROUTES\n#define IOAPIC_VERSION_ID 0x11\t/* IOAPIC version */\n#define IOAPIC_EDGE_TRIG  0\n#define IOAPIC_LEVEL_TRIG 1\n\n#define IOAPIC_DEFAULT_BASE_ADDRESS  0xfec00000\n#define IOAPIC_MEM_LENGTH            0x100\n\n/* Direct registers. */\n#define IOAPIC_REG_SELECT  0x00\n#define IOAPIC_REG_WINDOW  0x10\n\n/* Indirect registers. */\n#define IOAPIC_REG_APIC_ID 0x00\t/* x86 IOAPIC only */\n#define IOAPIC_REG_VERSION 0x01\n#define IOAPIC_REG_ARB_ID  0x02\t/* x86 IOAPIC only */\n\n/*ioapic delivery mode*/\n#define\tIOAPIC_FIXED\t\t\t0x0\n#define\tIOAPIC_LOWEST_PRIORITY\t\t0x1\n#define\tIOAPIC_PMI\t\t\t0x2\n#define\tIOAPIC_NMI\t\t\t0x4\n#define\tIOAPIC_INIT\t\t\t0x5\n#define\tIOAPIC_EXTINT\t\t\t0x7\n\n#ifdef CONFIG_X86\n#define RTC_GSI 8\n#else\n#define RTC_GSI -1U\n#endif\n\nstruct dest_map {\n\t/* vcpu bitmap where IRQ has been sent */\n\tDECLARE_BITMAP(map, KVM_MAX_VCPU_ID);\n\n\t/*\n\t * Vector sent to a given vcpu, only valid when\n\t * the vcpu's bit in map is set\n\t */\n\tu8 vectors[KVM_MAX_VCPU_ID];\n};\n\n\nstruct rtc_status {\n\tint pending_eoi;\n\tstruct dest_map dest_map;\n};\n\nunion kvm_ioapic_redirect_entry {\n\tu64 bits;\n\tstruct {\n\t\tu8 vector;\n\t\tu8 delivery_mode:3;\n\t\tu8 dest_mode:1;\n\t\tu8 delivery_status:1;\n\t\tu8 polarity:1;\n\t\tu8 remote_irr:1;\n\t\tu8 trig_mode:1;\n\t\tu8 mask:1;\n\t\tu8 reserve:7;\n\t\tu8 reserved[4];\n\t\tu8 dest_id;\n\t} fields;\n};\n\nstruct kvm_ioapic {\n\tu64 base_address;\n\tu32 ioregsel;\n\tu32 id;\n\tu32 irr;\n\tu32 pad;\n\tunion kvm_ioapic_redirect_entry redirtbl[IOAPIC_NUM_PINS];\n\tunsigned long irq_states[IOAPIC_NUM_PINS];\n\tstruct kvm_io_device dev;\n\tstruct kvm *kvm;\n\tvoid (*ack_notifier)(void *opaque, int irq);\n\tspinlock_t lock;\n\tstruct rtc_status rtc_status;\n\tstruct delayed_work eoi_inject;\n\tu32 irq_eoi[IOAPIC_NUM_PINS];\n\tu32 irr_delivered;\n};\n\n#ifdef DEBUG\n#define ASSERT(x)  \t\t\t\t\t\t\t\\\ndo {\t\t\t\t\t\t\t\t\t\\\n\tif (!(x)) {\t\t\t\t\t\t\t\\\n\t\tprintk(KERN_EMERG \"assertion failed %s: %d: %s\\n\",\t\\\n\t\t       __FILE__, __LINE__, #x);\t\t\t\t\\\n\t\tBUG();\t\t\t\t\t\t\t\\\n\t}\t\t\t\t\t\t\t\t\\\n} while (0)\n#else\n#define ASSERT(x) do { } while (0)\n#endif\n\nstatic inline struct kvm_ioapic *ioapic_irqchip(struct kvm *kvm)\n{\n\treturn kvm->arch.vioapic;\n}\n\nstatic inline int ioapic_in_kernel(struct kvm *kvm)\n{\n\tint ret;\n\n\tret = (ioapic_irqchip(kvm) != NULL);\n\treturn ret;\n}\n\nvoid kvm_rtc_eoi_tracking_restore_one(struct kvm_vcpu *vcpu);\nbool kvm_apic_match_dest(struct kvm_vcpu *vcpu, struct kvm_lapic *source,\n\t\tint short_hand, unsigned int dest, int dest_mode);\nint kvm_apic_compare_prio(struct kvm_vcpu *vcpu1, struct kvm_vcpu *vcpu2);\nvoid kvm_ioapic_update_eoi(struct kvm_vcpu *vcpu, int vector,\n\t\t\tint trigger_mode);\nint kvm_ioapic_init(struct kvm *kvm);\nvoid kvm_ioapic_destroy(struct kvm *kvm);\nint kvm_ioapic_set_irq(struct kvm_ioapic *ioapic, int irq, int irq_source_id,\n\t\t       int level, bool line_status);\nvoid kvm_ioapic_clear_all(struct kvm_ioapic *ioapic, int irq_source_id);\nint kvm_irq_delivery_to_apic(struct kvm *kvm, struct kvm_lapic *src,\n\t\t\t     struct kvm_lapic_irq *irq,\n\t\t\t     struct dest_map *dest_map);\nint kvm_get_ioapic(struct kvm *kvm, struct kvm_ioapic_state *state);\nint kvm_set_ioapic(struct kvm *kvm, struct kvm_ioapic_state *state);\nvoid kvm_ioapic_scan_entry(struct kvm_vcpu *vcpu,\n\t\t\t   ulong *ioapic_handled_vectors);\nvoid kvm_scan_ioapic_routes(struct kvm_vcpu *vcpu,\n\t\t\t    ulong *ioapic_handled_vectors);\n#endif\n"], "filenames": ["arch/x86/kvm/ioapic.c", "arch/x86/kvm/ioapic.h"], "buggy_code_start_loc": [97, 45], "buggy_code_end_loc": [98, 52], "fixing_code_start_loc": [97, 45], "fixing_code_end_loc": [98, 52], "type": "CWE-125", "message": "KVM in the Linux kernel before 4.8.12, when I/O APIC is enabled, does not properly restrict the VCPU index, which allows guest OS users to gain host OS privileges or cause a denial of service (out-of-bounds array access and host OS crash) via a crafted interrupt request, related to arch/x86/kvm/ioapic.c and arch/x86/kvm/ioapic.h.", "other": {"cve": {"id": "CVE-2016-9777", "sourceIdentifier": "secalert@redhat.com", "published": "2016-12-28T07:59:00.510", "lastModified": "2023-05-16T11:09:07.767", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "KVM in the Linux kernel before 4.8.12, when I/O APIC is enabled, does not properly restrict the VCPU index, which allows guest OS users to gain host OS privileges or cause a denial of service (out-of-bounds array access and host OS crash) via a crafted interrupt request, related to arch/x86/kvm/ioapic.c and arch/x86/kvm/ioapic.h."}, {"lang": "es", "value": "KVM en el kernel de Linux en versiones anteriores a 4.8.12, cuando se habilita I/O APIC, no restringe adecuadamente el \u00edndice VCPU, lo que permite a usuarios de SO invitados obtener privilegios del SO de anfitri\u00f3n o provocar una denegaci\u00f3n de servicio (acceso al array fuera de rango y ca\u00edda del SO anfitri\u00f3n) a trav\u00e9s de una petici\u00f3n interrumpida manipulada, relacionado con arch/x86/kvm/ioapic.c y arch/x86/kvm/ioapic.h."}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:L/AC:H/PR:L/UI:N/S:C/C:H/I:H/A:H", "attackVector": "LOCAL", "attackComplexity": "HIGH", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "CHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "HIGH", "availabilityImpact": "HIGH", "baseScore": 7.8, "baseSeverity": "HIGH"}, "exploitabilityScore": 1.1, "impactScore": 6.0}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:L/AC:M/Au:N/C:C/I:C/A:C", "accessVector": "LOCAL", "accessComplexity": "MEDIUM", "authentication": "NONE", "confidentialityImpact": "COMPLETE", "integrityImpact": "COMPLETE", "availabilityImpact": "COMPLETE", "baseScore": 6.9}, "baseSeverity": "MEDIUM", "exploitabilityScore": 3.4, "impactScore": 10.0, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-125"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionStartIncluding": "4.8", "versionEndExcluding": "4.8.12", "matchCriteriaId": "DC8CAAEA-FB80-41CC-BECF-346FCF47EFF1"}]}]}], "references": [{"url": "http://git.kernel.org/cgit/linux/kernel/git/torvalds/linux.git/commit/?id=81cdb259fb6d8c1c4ecfeea389ff5a73c07f5755", "source": "secalert@redhat.com", "tags": ["Patch", "Vendor Advisory"]}, {"url": "http://www.kernel.org/pub/linux/kernel/v4.x/ChangeLog-4.8.12", "source": "secalert@redhat.com", "tags": ["Release Notes"]}, {"url": "http://www.openwall.com/lists/oss-security/2016/12/02/2", "source": "secalert@redhat.com", "tags": ["Mailing List", "Patch"]}, {"url": "http://www.securityfocus.com/bid/94640", "source": "secalert@redhat.com", "tags": ["Third Party Advisory", "VDB Entry"]}, {"url": "https://bugzilla.redhat.com/show_bug.cgi?id=1400804", "source": "secalert@redhat.com", "tags": ["Issue Tracking"]}, {"url": "https://github.com/torvalds/linux/commit/81cdb259fb6d8c1c4ecfeea389ff5a73c07f5755", "source": "secalert@redhat.com", "tags": ["Patch", "Vendor Advisory"]}]}, "github_commit_url": "https://github.com/torvalds/linux/commit/81cdb259fb6d8c1c4ecfeea389ff5a73c07f5755"}}
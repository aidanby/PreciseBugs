{"buggy_code": ["#\n# Copyright 2017-2018 Amazon.com, Inc. and its affiliates. All Rights Reserved.\n#\n# Licensed under the MIT License. See the LICENSE accompanying this file\n# for the specific language governing permissions and limitations under\n# the License.\n#\n\n%if 0%{?amzn1}\n%global python_requires python36\n%else\n%global python_requires python3\n%endif\n\n%if 0%{?amzn1} || 0%{?rhel} == 6\n%global with_systemd 0\n%else\n%global with_systemd 1\n%endif\n\n%if 0%{?dist:1}\n%global platform %{dist}\n%else\n%if 0%{?suse_version}\n%global platform .suse\n%else\n%global platform .unknown\n%endif\n%endif\n\n%if 0%{?amzn} > 2\n%global efs_bindir %{_sbindir}\n%else\n%global efs_bindir /sbin\n%endif\n\nName      : amazon-efs-utils\nVersion   : 1.34.3\nRelease   : 1%{platform}\nSummary   : This package provides utilities for simplifying the use of EFS file systems\n\nGroup     : Amazon/Tools\nLicense   : MIT\nURL       : https://aws.amazon.com/efs\n\n\nBuildArch : noarch\n\nRequires  : nfs-utils\n%if 0%{?amzn2}\nRequires  : stunnel5\n%else\nRequires  : stunnel >= 4.56\n%endif\nRequires  : %{python_requires}\nRequires  : openssl >= 1.0.2\nRequires  : util-linux\nRequires  : which\n\n%if %{with_systemd}\nBuildRequires    : systemd\n%{?systemd_requires}\n%else\nRequires(post)   : /sbin/chkconfig\nRequires(preun)  : /sbin/service /sbin/chkconfig\nRequires(postun) : /sbin/service\n%endif\n\nSource    : %{name}.tar.gz\n\n%description\nThis package provides utilities for simplifying the use of EFS file systems\n\n%prep\n%setup -n %{name}\n\n%install\nmkdir -p %{buildroot}%{_sysconfdir}/amazon/efs\n%if %{with_systemd}\nmkdir -p %{buildroot}%{_unitdir}\ninstall -p -m 644 %{_builddir}/%{name}/dist/amazon-efs-mount-watchdog.service %{buildroot}%{_unitdir}\n%else\nmkdir -p %{buildroot}%{_sysconfdir}/init\ninstall -p -m 644 %{_builddir}/%{name}/dist/amazon-efs-mount-watchdog.conf %{buildroot}%{_sysconfdir}/init\n%endif\n\nmkdir -p %{buildroot}%{efs_bindir}\nmkdir -p %{buildroot}%{_bindir}\nmkdir -p %{buildroot}%{_localstatedir}/log/amazon/efs\nmkdir -p  %{buildroot}%{_mandir}/man8\n\ninstall -p -m 644 %{_builddir}/%{name}/dist/efs-utils.conf %{buildroot}%{_sysconfdir}/amazon/efs\ninstall -p -m 444 %{_builddir}/%{name}/dist/efs-utils.crt %{buildroot}%{_sysconfdir}/amazon/efs\ninstall -p -m 755 %{_builddir}/%{name}/src/mount_efs/__init__.py %{buildroot}%{efs_bindir}/mount.efs\ninstall -p -m 755 %{_builddir}/%{name}/src/watchdog/__init__.py %{buildroot}%{_bindir}/amazon-efs-mount-watchdog\ninstall -p -m 644 %{_builddir}/%{name}/man/mount.efs.8 %{buildroot}%{_mandir}/man8\n\n%files\n%defattr(-,root,root,-)\n%if %{with_systemd}\n%{_unitdir}/amazon-efs-mount-watchdog.service\n%else\n%config(noreplace) %{_sysconfdir}/init/amazon-efs-mount-watchdog.conf\n%endif\n%{_sysconfdir}/amazon/efs/efs-utils.crt\n%{efs_bindir}/mount.efs\n%{_bindir}/amazon-efs-mount-watchdog\n/var/log/amazon\n%{_mandir}/man8/mount.efs.8.gz\n\n%config(noreplace) %{_sysconfdir}/amazon/efs/efs-utils.conf\n\n%if %{with_systemd}\n%post\n%systemd_post amazon-efs-mount-watchdog.service\n\n%preun\n%systemd_preun amazon-efs-mount-watchdog.service\n\n%postun\n%systemd_postun_with_restart amazon-efs-mount-watchdog.service\n\n%else\n\n%preun\nif [ $1 -eq 0 ]; then\n   /sbin/stop amazon-efs-mount-watchdog &> /dev/null || true\nfi\n\n%postun\nif [ $1 -eq 1 ]; then\n    /sbin/restart amazon-efs-mount-watchdog &> /dev/null || true\nfi\n\n%endif\n\n%clean\n\n%changelog\n* Thu Dec 1 2022 Preetham Puneeth Munipalli <tmunipre@amazon.com> - 1.34.3\n- Fix potential tlsport selection race condition by closing socket right before establishing stunnel\n- Fix stunnel constantly restart issue when upgrading from 1.32.1 and before version to latest version\n- Speed up the way to check network availability by using systemctl is-active\n\n* Tue Nov 22 2022 Preetham Puneeth Munipalli <tmunipre@amazon.com> - 1.34.2\n- Fix potential issue on AL2 when watchdog trying to restart stunnel for the TLS mounts that existing before upgrade\n\n* Thu Sep 29 2022 Preetham Puneeth Munipalli <tmunipre@amazon.com> - 1.34.1\n- Update Amazon Linux 2 platform to use namespaced stunnel5\n\n* Thu Sep 1 2022 Yuan Gao <ygaochn@amazon.com> - 1.33.4\n- Fix potential issue where watchdog sending signal to incorrect processes.\n- Add support for enabling FIPS mode for both stunnel and AWS API calls.\n\n* Wed Jul 13 2022 Yuan Gao <ygaochn@amazon.com> - 1.33.3\n- Fix potential stunnel hanging issue caused by full subprocess PIPE filled by stunnel log.\n\n* Mon Jun 6 2022 Yuan Gao <ygaochn@amazon.com> - 1.33.2\n- Fix the incorrect path to generate read_ahead_kb config file.\n- Bump the default tls port range from 400 to 1000.\n\n* Fri May 6 2022 Yuan Gao <ygaochn@amazon.com> - 1.33.1\n- Enable mount process to retry on failed or timed out mount.nfs command.\n\n* Thu Apr 28 2022 Yuan Gao <ygaochn@amazon.com> - 1.32.2\n- Fix potential race condition issue when stunnel creating pid file.\n\n* Thu Mar 31 2022 Shivam Gupta <lshigupt@amazon.com> - 1.32.1\n- Enable watchdog to check stunnel health periodically and restart hanging stunnel process when necessary.\n- Fix potential race condition issue when removing lock files.\n- Add efs-utils Support for MacOS Monterey EC2 instances.\n\n* Tue Nov 23 2021 Jigar Dedhia <dedhiajd@amazon.com> - 1.31.3\n- Add unmount_time and unmount_count to handle inconsistent mount reads\n- Allow specifying fs_id in cloudwatch log group name\n\n* Thu Jun 10 2021 Yuan Gao <ygaochn@amazon.com> - 1.31.2\n- Handle the fallback to IMDSv1 call when either HTTPError or unknown exception is thrown\n- Cleanup private key lock file at watchdog startup\n\n* Thu May 06 2021 Yuan Gao <ygaochn@amazon.com> - 1.31.1\n- Support new option: mounttargetip, enable mount file system to specific mount target ip address\n- Support using botocore to retrieve and mount via file system mount target ip address when DNS resolution fails\n- Use IMDSv2 by default to access instance metadata service\n\n* Thu Apr 15 2021 Yue Wang <wangnyue@amazon.com> - 1.30.2\n- Fix the throughput regression due to read_ahead configuration change on Linux distribution with kernel version 5.4.x and above\n\n* Mon Mar 22 2021 Yuan Gao <ygaochn@amazon.com> - 1.30.1\n- Support new option: az, enable mount file system to specific availability zone mount target\n- Merge PR #84 on Github. Fix to use regional AWS STS endpoints instead of the global endpoint to reduce latency\n\n* Mon Jan 25 2021 Yuan Gao <ygaochn@amazon.com> - 1.29.1\n- Update the python dependency to python3\n- Support SLES and OpenSUSE\n\n* Thu Oct 8 2020 Yuan Gao <ygaochn@amazon.com> - 1.28.2\n- Fix an issue where fs cannot be mounted with iam using instance profile when IMDSv2 is enabled\n\n* Fri Sep 18 2020 Yuan Gao <ygaochn@amazon.com> - 1.28.1\n- Introduce botocore to publish mount success/failure notification to cloudwatch log\n- Revert stop emitting unrecognized init system supervisord if the watchdog daemon has already been launched by supervisor check\n\n* Tue Aug 4 2020 Karthik Basavaraj <kbbasav@amazon.com> - 1.27.1\n- Merge PR #60 on GitHub. Adds support for AssumeRoleWithWebIdentity\n\n* Wed Jul 1 2020 Yuan Gao <ygaochn@amazon.com> - 1.26.3\n- Fix an issue where watchdog crashed during restart because stunnel was killed and pid key was removed from state file\n\n* Tue Jun 16 2020 Karthik Basavaraj <kbbasav@amazon.com> - 1.26.2\n- Clean up stunnel PIDs in state files persisted by previous efs-csi-driver to ensure watchdog spawns a new stunnel after driver restarts.\n- Fix an issue where fs cannot be mounted with tls using systemd.automount-units due to mountpoint check\n\n* Tue May 26 2020 Yuan Gao <ygaochn@amazon.com> - 1.25.3\n- Fix an issue where subprocess was not killed successfully\n- Stop emitting unrecognized init system supervisord if the watchdog daemon has already been launched by supervisor\n- Support Fedora\n- Check if mountpoint is already mounted beforehand for tls mount\n\n* Tue May 05 2020 Yuan Gao <ygaochn@amazon.com> - 1.25.2\n- Fix the issue that IAM role name format is not correctly encoded in python3\n- Add optional override for stunnel debug log output location\n\n* Mon Apr 20 2020 Yuan Gao <ygaochn@amazon.com> - 1.25.1\n- Create self-signed certificate for tls-only mount\n\n* Tue Apr 7 2020 Yuan Gao <ygaochn@amazon.com> - 1.24.4\n- Fix the malformed certificate info\n\n* Fri Mar 27 2020 Yuan Gao <ygaochn@amazon.com> - 1.24.3\n- Use IMDSv1 by default, and use IMDSv2 where required\n\n* Tue Mar 10 2020 Yuan Gao <ygaochn@amazon.com> - 1.24.2\n- List which as dependency\n\n* Tue Mar 10 2020 Yuan Gao <ygaochn@amazon.com> - 1.24.1\n- Enable efs-utils to source region from config file for sigv4 auth\n- Fix the issue that stunnel bin exec cannot be found in certain linux distributions\n\n* Tue Mar 03 2020 Yuan Gao <ygaochn@amazon.com> - 1.23.2\n- Support new option: netns, enable file system to mount in given network namespace\n- Support new option: awscredsuri, enable sourcing iam authorization from aws credentials relative uri\n- List openssl and util-linux as package dependency for IAM/AP authorization and command nsenter to mount file system to given network namespace\n", "#!/usr/bin/env sh\n#\n# Copyright 2017-2018 Amazon.com, Inc. and its affiliates. All Rights Reserved.\n#\n# Licensed under the MIT License. See the LICENSE accompanying this file\n# for the specific language governing permissions and limitations under\n# the License.\n#\n\nset -ex\n\nBASE_DIR=$(pwd)\nBUILD_ROOT=${BASE_DIR}/build/debbuild\nVERSION=1.34.3\nRELEASE=1\nDEB_SYSTEM_RELEASE_PATH=/etc/os-release\n\necho 'Cleaning deb build workspace'\nrm -rf ${BUILD_ROOT}\nmkdir -p ${BUILD_ROOT}\n\necho 'Creating application directories'\nmkdir -p ${BUILD_ROOT}/etc/amazon/efs\nmkdir -p ${BUILD_ROOT}/etc/init/\nmkdir -p ${BUILD_ROOT}/etc/systemd/system\nmkdir -p ${BUILD_ROOT}/sbin\nmkdir -p ${BUILD_ROOT}/usr/bin\nmkdir -p ${BUILD_ROOT}/var/log/amazon/efs\nmkdir -p ${BUILD_ROOT}/usr/share/man/man8\n\necho 'Copying application files'\ninstall -p -m 644 dist/amazon-efs-mount-watchdog.conf ${BUILD_ROOT}/etc/init\ninstall -p -m 644 dist/amazon-efs-mount-watchdog.service ${BUILD_ROOT}/etc/systemd/system\ninstall -p -m 444 dist/efs-utils.crt ${BUILD_ROOT}/etc/amazon/efs\ninstall -p -m 644 dist/efs-utils.conf ${BUILD_ROOT}/etc/amazon/efs\ninstall -p -m 755 src/mount_efs/__init__.py ${BUILD_ROOT}/sbin/mount.efs\ninstall -p -m 755 src/watchdog/__init__.py ${BUILD_ROOT}/usr/bin/amazon-efs-mount-watchdog\n\necho 'Copying install scripts'\ninstall -p -m 755 dist/scriptlets/after-install-upgrade ${BUILD_ROOT}/postinst\ninstall -p -m 755 dist/scriptlets/before-remove ${BUILD_ROOT}/prerm\ninstall -p -m 755 dist/scriptlets/after-remove ${BUILD_ROOT}/postrm\n\necho 'Copying control file'\ninstall -p -m 644 dist/amazon-efs-utils.control ${BUILD_ROOT}/control\n\necho 'Copying conffiles'\ninstall -p -m 644 dist/amazon-efs-utils.conffiles ${BUILD_ROOT}/conffiles\n\necho 'Copying manpages'\ninstall -p -m 644 man/mount.efs.8 ${BUILD_ROOT}/usr/share/man/man8/mount.efs.8\n\necho 'Creating deb binary file'\necho '2.0'> ${BUILD_ROOT}/debian-binary\n\necho 'Setting permissions'\nfind ${BUILD_ROOT} -type d | xargs chmod 755;\n\necho 'Creating tar'\ncd ${BUILD_ROOT}\ntar czf control.tar.gz control conffiles postinst prerm postrm --owner=0 --group=0\ntar czf data.tar.gz etc sbin usr var --owner=0 --group=0\ncd ${BASE_DIR}\n\necho 'Building deb'\nDEB=${BUILD_ROOT}/amazon-efs-utils-${VERSION}-${RELEASE}_all.deb\nar r ${DEB} ${BUILD_ROOT}/debian-binary\nar r ${DEB} ${BUILD_ROOT}/control.tar.gz\nar r ${DEB} ${BUILD_ROOT}/data.tar.gz\n\necho 'Copying deb to output directory'\ncp ${BUILD_ROOT}/amazon-efs-utils*deb build/\n", "#\n# Copyright 2017-2018 Amazon.com, Inc. and its affiliates. All Rights Reserved.\n#\n# Licensed under the MIT License. See the LICENSE accompanying this file\n# for the specific language governing permissions and limitations under\n# the License.\n#\n\n[global]\nversion=1.34.3\nrelease=1\n", "Package: amazon-efs-utils\nArchitecture: all\nVersion: 1.34.3\nSection: utils\nDepends: python3, nfs-common, stunnel4 (>= 4.56), openssl (>= 1.0.2), util-linux\nPriority: optional\nCopyright: MIT License\nMaintainer: Amazon.com, Inc. <efs-utils@amazon.com>\nDescription: This package provides utilities for simplifying the use of EFS file systems\n", "#!/usr/bin/env python3\n#\n# Copyright 2017-2018 Amazon.com, Inc. and its affiliates. All Rights Reserved.\n#\n# Licensed under the MIT License. See the LICENSE accompanying this file\n# for the specific language governing permissions and limitations under\n# the License.\n#\n#\n# Copy this script to /sbin/mount.efs and make sure it is executable.\n#\n# You will be able to mount an EFS file system by its short name, by adding it\n# to /etc/fstab. The syntax of an fstab entry is:\n#\n# [Device] [Mount Point] [File System Type] [Options] [Dump] [Pass]\n#\n# Add an entry like this:\n#\n#   fs-deadbeef     /mount_point    efs     _netdev         0   0\n#\n# Using the 'efs' type will cause '/sbin/mount.efs' to be called by 'mount -a'\n# for this file system. The '_netdev' option tells the init system that the\n# 'efs' type is a networked file system type. This has been tested with systemd\n# (Amazon Linux 2, CentOS 7, RHEL 7, Debian 9, and Ubuntu 16.04), and upstart\n# (Amazon Linux 2017.09).\n#\n# Once there is an entry in fstab, the file system can be mounted with:\n#\n#   sudo mount /mount_point\n#\n# The script will add recommended mount options, if not provided in fstab.\n\nimport base64\nimport errno\nimport hashlib\nimport hmac\nimport json\nimport logging\nimport os\nimport platform\nimport pwd\nimport random\nimport re\nimport socket\nimport subprocess\nimport sys\nimport threading\nimport time\nfrom contextlib import contextmanager\nfrom datetime import datetime, timedelta\nfrom logging.handlers import RotatingFileHandler\n\ntry:\n    from configparser import ConfigParser, NoOptionError, NoSectionError\nexcept ImportError:\n    import ConfigParser\n    from ConfigParser import NoOptionError, NoSectionError\n\ntry:\n    from urllib.parse import quote_plus\nexcept ImportError:\n    from urllib import quote_plus\n\ntry:\n    from urllib.error import HTTPError, URLError\n    from urllib.parse import urlencode\n    from urllib.request import Request, urlopen\nexcept ImportError:\n    from urllib import urlencode\n\n    from urllib2 import HTTPError, HTTPHandler, Request, URLError, build_opener, urlopen\n\ntry:\n    import botocore.config\n    import botocore.session\n    from botocore.exceptions import (\n        ClientError,\n        EndpointConnectionError,\n        NoCredentialsError,\n        ProfileNotFound,\n    )\n\n    BOTOCORE_PRESENT = True\nexcept ImportError:\n    BOTOCORE_PRESENT = False\n\n\nVERSION = \"1.34.3\"\nSERVICE = \"elasticfilesystem\"\n\nAMAZON_LINUX_2_RELEASE_ID = \"Amazon Linux release 2 (Karoo)\"\nAMAZON_LINUX_2_PRETTY_NAME = \"Amazon Linux 2\"\nAMAZON_LINUX_2_RELEASE_VERSIONS = [\n    AMAZON_LINUX_2_RELEASE_ID,\n    AMAZON_LINUX_2_PRETTY_NAME,\n]\n\nCLONE_NEWNET = 0x40000000\nCONFIG_FILE = \"/etc/amazon/efs/efs-utils.conf\"\nCONFIG_SECTION = \"mount\"\nCLIENT_INFO_SECTION = \"client-info\"\nCLIENT_SOURCE_STR_LEN_LIMIT = 100\n# Cloudwatchlog agent dict includes cloudwatchlog botocore client, cloudwatchlog group name, cloudwatchlog stream name\nCLOUDWATCHLOG_AGENT = None\nCLOUDWATCH_LOG_SECTION = \"cloudwatch-log\"\nDEFAULT_CLOUDWATCH_LOG_GROUP = \"/aws/efs/utils\"\nDEFAULT_FALLBACK_ENABLED = True\nDEFAULT_RETENTION_DAYS = 14\nDEFAULT_UNKNOWN_VALUE = \"unknown\"\n# 50ms\nDEFAULT_TIMEOUT = 0.05\nDEFAULT_MACOS_VALUE = \"macos\"\nDEFAULT_NFS_MOUNT_COMMAND_RETRY_COUNT = 3\nDEFAULT_NFS_MOUNT_COMMAND_TIMEOUT_SEC = 15\nDISABLE_FETCH_EC2_METADATA_TOKEN_ITEM = \"disable_fetch_ec2_metadata_token\"\nFALLBACK_TO_MOUNT_TARGET_IP_ADDRESS_ITEM = (\n    \"fall_back_to_mount_target_ip_address_enabled\"\n)\nINSTANCE_IDENTITY = None\nRETRYABLE_ERRORS = [\"reset by peer\"]\nOPTIMIZE_READAHEAD_ITEM = \"optimize_readahead\"\n\nLOG_DIR = \"/var/log/amazon/efs\"\nLOG_FILE = \"mount.log\"\n\nSTATE_FILE_DIR = \"/var/run/efs\"\n\nPRIVATE_KEY_FILE = \"/etc/amazon/efs/privateKey.pem\"\nDATE_ONLY_FORMAT = \"%Y%m%d\"\nSIGV4_DATETIME_FORMAT = \"%Y%m%dT%H%M%SZ\"\nCERT_DATETIME_FORMAT = \"%y%m%d%H%M%SZ\"\n\nAWS_CREDENTIALS_FILE = os.path.expanduser(\n    os.path.join(\"~\" + pwd.getpwuid(os.getuid()).pw_name, \".aws\", \"credentials\")\n)\nAWS_CONFIG_FILE = os.path.expanduser(\n    os.path.join(\"~\" + pwd.getpwuid(os.getuid()).pw_name, \".aws\", \"config\")\n)\n\nCA_CONFIG_BODY = \"\"\"dir = %s\nRANDFILE = $dir/database/.rand\n\n[ ca ]\ndefault_ca = local_ca\n\n[ local_ca ]\ndatabase = $dir/database/index.txt\nserial = $dir/database/serial\nprivate_key = %s\ncert = $dir/certificate.pem\nnew_certs_dir = $dir/certs\ndefault_md = sha256\npreserve = no\npolicy = efsPolicy\nx509_extensions = v3_ca\n\n[ efsPolicy ]\nCN = supplied\n\n[ req ]\nprompt = no\ndistinguished_name = req_distinguished_name\n\n[ req_distinguished_name ]\nCN = %s\n\n%s\n\n%s\n\n%s\n\"\"\"\n\n# SigV4 Auth\nALGORITHM = \"AWS4-HMAC-SHA256\"\nAWS4_REQUEST = \"aws4_request\"\n\nHTTP_REQUEST_METHOD = \"GET\"\nCANONICAL_URI = \"/\"\nCANONICAL_HEADERS_DICT = {\"host\": \"%s\"}\nCANONICAL_HEADERS = \"\\n\".join(\n    [\"%s:%s\" % (k, v) for k, v in sorted(CANONICAL_HEADERS_DICT.items())]\n)\nSIGNED_HEADERS = \";\".join(CANONICAL_HEADERS_DICT.keys())\nREQUEST_PAYLOAD = \"\"\n\nFS_ID_RE = re.compile(\"^(?P<fs_id>fs-[0-9a-f]+)$\")\nEFS_FQDN_RE = re.compile(\n    r\"^((?P<az>[a-z0-9-]+)\\.)?(?P<fs_id>fs-[0-9a-f]+)\\.efs\\.\"\n    r\"(?P<region>[a-z0-9-]+)\\.(?P<dns_name_suffix>[a-z0-9.]+)$\"\n)\nAP_ID_RE = re.compile(\"^fsap-[0-9a-f]{17}$\")\n\nCREDENTIALS_KEYS = [\"AccessKeyId\", \"SecretAccessKey\", \"Token\"]\nECS_TASK_METADATA_API = \"http://169.254.170.2\"\nSTS_ENDPOINT_URL_FORMAT = \"https://sts.{}.amazonaws.com/\"\nINSTANCE_METADATA_TOKEN_URL = \"http://169.254.169.254/latest/api/token\"\nINSTANCE_METADATA_SERVICE_URL = (\n    \"http://169.254.169.254/latest/dynamic/instance-identity/document/\"\n)\nINSTANCE_IAM_URL = \"http://169.254.169.254/latest/meta-data/iam/security-credentials/\"\nNAMED_PROFILE_HELP_URL = (\n    \"https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-profiles.html\"\n)\nCONFIG_FILE_SETTINGS_HELP_URL = (\n    \"https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-files.html\"\n    \"#cli-configure-files-settings\"\n)\n\nSECURITY_CREDS_ECS_URI_HELP_URL = (\n    \"https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task-iam-roles.html\"\n)\nSECURITY_CREDS_WEBIDENTITY_HELP_URL = \"https://docs.aws.amazon.com/eks/latest/userguide/iam-roles-for-service-accounts.html\"\nSECURITY_CREDS_IAM_ROLE_HELP_URL = (\n    \"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/iam-roles-for-amazon-ec2.html\"\n)\n\nDEFAULT_STUNNEL_VERIFY_LEVEL = 2\nDEFAULT_STUNNEL_CAFILE = \"/etc/amazon/efs/efs-utils.crt\"\n\nNOT_BEFORE_MINS = 15\nNOT_AFTER_HOURS = 3\n\nEFS_ONLY_OPTIONS = [\n    \"accesspoint\",\n    \"awscredsuri\",\n    \"awsprofile\",\n    \"az\",\n    \"cafile\",\n    \"iam\",\n    \"mounttargetip\",\n    \"netns\",\n    \"noocsp\",\n    \"notls\",\n    \"ocsp\",\n    \"tls\",\n    \"tlsport\",\n    \"verify\",\n]\n\nUNSUPPORTED_OPTIONS = [\"capath\"]\n\nSTUNNEL_GLOBAL_CONFIG = {\n    \"fips\": \"no\",\n    \"foreground\": \"yes\",\n    \"socket\": [\n        \"l:SO_REUSEADDR=yes\",\n        \"a:SO_BINDTODEVICE=lo\",\n    ],\n}\n\nSTUNNEL_EFS_CONFIG = {\n    \"client\": \"yes\",\n    \"accept\": \"127.0.0.1:%s\",\n    \"connect\": \"%s:2049\",\n    \"sslVersion\": \"TLSv1.2\",\n    \"renegotiation\": \"no\",\n    \"TIMEOUTbusy\": \"20\",\n    \"TIMEOUTclose\": \"0\",\n    \"TIMEOUTidle\": \"70\",\n    \"delay\": \"yes\",\n}\n\nWATCHDOG_SERVICE = \"amazon-efs-mount-watchdog\"\n# MacOS instances use plist files. This files needs to be loaded on launchctl (init system of MacOS)\nWATCHDOG_SERVICE_PLIST_PATH = \"/Library/LaunchAgents/amazon-efs-mount-watchdog.plist\"\nSYSTEM_RELEASE_PATH = \"/etc/system-release\"\nOS_RELEASE_PATH = \"/etc/os-release\"\nMACOS_BIG_SUR_RELEASE = \"macOS-11\"\nMACOS_MONTEREY_RELEASE = \"macOS-12\"\n\n# Multiplier for max read ahead buffer size\n# Set default as 15 aligning with prior linux kernel 5.4\nDEFAULT_NFS_MAX_READAHEAD_MULTIPLIER = 15\nNFS_READAHEAD_CONFIG_PATH_FORMAT = \"/sys/class/bdi/%s:%s/read_ahead_kb\"\nNFS_READAHEAD_OPTIMIZE_LINUX_KERNEL_MIN_VERSION = [5, 4]\n\n# MacOS does not support the property of Socket SO_BINDTODEVICE in stunnel configuration\nSKIP_NO_SO_BINDTODEVICE_RELEASES = [MACOS_BIG_SUR_RELEASE, MACOS_MONTEREY_RELEASE]\n\nMAC_OS_PLATFORM_LIST = [\"darwin\"]\n# MacOS Versions : Monterey - 21.*, Big Sur - 20.*, Catalina - 19.*, Mojave - 18.*. Catalina and Mojave are not supported for now\nMAC_OS_SUPPORTED_VERSION_LIST = [\"20\", \"21\"]\n\nAWS_FIPS_ENDPOINT_CONFIG_ENV = \"AWS_USE_FIPS_ENDPOINT\"\nECS_URI_ENV = \"AWS_CONTAINER_CREDENTIALS_RELATIVE_URI\"\nWEB_IDENTITY_ROLE_ARN_ENV = \"AWS_ROLE_ARN\"\nWEB_IDENTITY_TOKEN_FILE_ENV = \"AWS_WEB_IDENTITY_TOKEN_FILE\"\n\n\ndef errcheck(ret, func, args):\n    from ctypes import get_errno\n\n    if ret == -1:\n        e = get_errno()\n        raise OSError(e, os.strerror(e))\n\n\ndef setns(fd, nstype):\n    from ctypes import CDLL\n\n    libc = CDLL(\"libc.so.6\", use_errno=True)\n    libc.setns.errcheck = errcheck\n    if hasattr(fd, \"fileno\"):\n        fd = fd.fileno()\n    return libc.setns(fd, nstype)\n\n\nclass NetNS(object):\n    # Open sockets from given network namespace: stackoverflow.com/questions/28846059\n    def __init__(self, nspath):\n        self.original_nspath = \"/proc/%d/ns/net\" % os.getpid()\n        self.target_nspath = nspath\n\n    def __enter__(self):\n        self.original_namespace = open(self.original_nspath)\n        with open(self.target_nspath) as fd:\n            setns(fd, CLONE_NEWNET)\n\n    def __exit__(self, *args):\n        setns(self.original_namespace, CLONE_NEWNET)\n        self.original_namespace.close()\n\n\nclass FallbackException(Exception):\n    \"\"\"Exception raised for errors happens when dns resolve and fallback to mount target ip address attempt both fail\n\n    Attributes:\n        message -- explanation of the error\n    \"\"\"\n\n    def __init__(self, message):\n        self.message = message\n        super().__init__(self.message)\n\n\ndef fatal_error(user_message, log_message=None, exit_code=1):\n    if log_message is None:\n        log_message = user_message\n\n    sys.stderr.write(\"%s\\n\" % user_message)\n    logging.error(log_message)\n    publish_cloudwatch_log(CLOUDWATCHLOG_AGENT, \"Mount failed, %s\" % log_message)\n    sys.exit(exit_code)\n\n\ndef get_target_region(config):\n    def _fatal_error(message):\n        fatal_error(\n            'Error retrieving region. Please set the \"region\" parameter '\n            \"in the efs-utils configuration file.\",\n            message,\n        )\n\n    try:\n        return config.get(CONFIG_SECTION, \"region\")\n    except NoOptionError:\n        pass\n\n    try:\n        return get_region_from_instance_metadata(config)\n    except Exception as e:\n        metadata_exception = e\n        logging.warning(\n            \"Region not found in config file and metadata service call failed, falling back \"\n            'to legacy \"dns_name_format\" check'\n        )\n\n    try:\n        region = get_region_from_legacy_dns_format(config)\n        sys.stdout.write(\n            'Warning: region obtained from \"dns_name_format\" field. Please set the \"region\" '\n            \"parameter in the efs-utils configuration file.\"\n        )\n        return region\n    except Exception:\n        logging.warning('Legacy check for region in \"dns_name_format\" failed')\n\n    _fatal_error(metadata_exception)\n\n\ndef get_target_az(config, options):\n    if \"az\" in options:\n        return options.get(\"az\")\n\n    try:\n        return get_az_from_instance_metadata(config)\n    except Exception as e:\n        logging.warning(\"Get AZ via metadata service call failed, %s\", e)\n\n    return None\n\n\ndef get_region_from_instance_metadata(config):\n    instance_identity = get_instance_identity_info_from_instance_metadata(\n        config, \"region\"\n    )\n\n    if not instance_identity:\n        raise Exception(\n            \"Cannot retrieve region from instance_metadata. \"\n            \"Please set the 'region' parameter in the efs-utils configuration file.\"\n        )\n\n    return instance_identity\n\n\ndef get_az_from_instance_metadata(config):\n    instance_identity = get_instance_identity_info_from_instance_metadata(\n        config, \"availabilityZone\"\n    )\n\n    if not instance_identity:\n        raise Exception(\"Cannot retrieve az from instance_metadata\")\n\n    return instance_identity\n\n\ndef get_instance_identity_info_from_instance_metadata(config, property):\n    logging.debug(\"Retrieve property %s from instance metadata\", property)\n    ec2_metadata_unsuccessful_resp = (\n        \"Unsuccessful retrieval of EC2 metadata at %s.\" % INSTANCE_METADATA_SERVICE_URL\n    )\n    ec2_metadata_url_error_msg = (\n        \"Unable to reach %s to retrieve EC2 instance metadata.\"\n        % INSTANCE_METADATA_SERVICE_URL\n    )\n\n    global INSTANCE_IDENTITY\n    if INSTANCE_IDENTITY:\n        logging.debug(\n            \"Instance metadata already retrieved in previous call, use the cached values.\"\n        )\n        instance_identity = INSTANCE_IDENTITY\n    else:\n        instance_identity = url_request_helper(\n            config,\n            INSTANCE_METADATA_SERVICE_URL,\n            ec2_metadata_unsuccessful_resp,\n            ec2_metadata_url_error_msg,\n        )\n        INSTANCE_IDENTITY = instance_identity\n\n    if instance_identity:\n        try:\n            return instance_identity[property]\n        except KeyError as e:\n            logging.warning(\n                \"%s not present in %s: %s\" % (property, instance_identity, e)\n            )\n        except TypeError as e:\n            logging.warning(\n                \"response %s is not a json object: %s\" % (instance_identity, e)\n            )\n\n    return None\n\n\ndef get_region_from_legacy_dns_format(config):\n    \"\"\"\n    For backwards compatibility check dns_name_format to obtain the target region. This functionality\n    should only be used if region is not present in the config file and metadata calls fail.\n    \"\"\"\n    dns_name_format = config.get(CONFIG_SECTION, \"dns_name_format\")\n    if \"{region}\" not in dns_name_format:\n        split_dns_name_format = dns_name_format.split(\".\")\n        if \"{dns_name_suffix}\" in dns_name_format:\n            return split_dns_name_format[-2]\n        elif \"amazonaws.com\" in dns_name_format:\n            return split_dns_name_format[-3]\n    raise Exception(\"Region not found in dns_name_format\")\n\n\ndef get_boolean_config_item_value(\n    config, config_section, config_item, default_value, emit_warning_message=True\n):\n    warning_message = None\n    if not config.has_section(config_section):\n        warning_message = (\n            \"Warning: config file does not have section %s.\" % config_section\n        )\n    elif not config.has_option(config_section, config_item):\n        warning_message = (\n            \"Warning: config file does not have %s item in section %s.\"\n            % (config_item, config_section)\n        )\n\n    if warning_message:\n        if emit_warning_message:\n            sys.stdout.write(\n                \"%s. You should be able to find a new config file in the same folder as current config file %s. \"\n                \"Consider update the new config file to latest config file. Use the default value [%s = %s].\"\n                % (warning_message, CONFIG_FILE, config_item, default_value)\n            )\n        return default_value\n    return config.getboolean(config_section, config_item)\n\n\ndef fetch_ec2_metadata_token_disabled(config):\n    return get_boolean_config_item_value(\n        config,\n        CONFIG_SECTION,\n        DISABLE_FETCH_EC2_METADATA_TOKEN_ITEM,\n        default_value=False,\n    )\n\n\ndef get_aws_ec2_metadata_token(timeout=DEFAULT_TIMEOUT):\n    # Normally the session token is fetched within 10ms, setting a timeout of 50ms here to abort the request\n    # and return None if the token has not returned within 50ms\n    try:\n        opener = build_opener(HTTPHandler)\n        request = Request(INSTANCE_METADATA_TOKEN_URL)\n\n        request.add_header(\"X-aws-ec2-metadata-token-ttl-seconds\", \"21600\")\n        request.get_method = lambda: \"PUT\"\n        try:\n            res = opener.open(request, timeout=timeout)\n            return res.read()\n        except socket.timeout:\n            exception_message = \"Timeout when getting the aws ec2 metadata token\"\n        except HTTPError as e:\n            exception_message = \"Failed to fetch token due to %s\" % e\n        except Exception as e:\n            exception_message = (\n                \"Unknown error when fetching aws ec2 metadata token, %s\" % e\n            )\n        logging.debug(exception_message)\n        return None\n    except NameError:\n        headers = {\"X-aws-ec2-metadata-token-ttl-seconds\": \"21600\"}\n        req = Request(INSTANCE_METADATA_TOKEN_URL, headers=headers, method=\"PUT\")\n        try:\n            res = urlopen(req, timeout=timeout)\n            return res.read()\n        except socket.timeout:\n            exception_message = \"Timeout when getting the aws ec2 metadata token\"\n        except HTTPError as e:\n            exception_message = \"Failed to fetch token due to %s\" % e\n        except Exception as e:\n            exception_message = (\n                \"Unknown error when fetching aws ec2 metadata token, %s\" % e\n            )\n        logging.debug(exception_message)\n        return None\n\n\ndef get_aws_security_credentials(\n    config, use_iam, region, awsprofile=None, aws_creds_uri=None\n):\n    \"\"\"\n    Lookup AWS security credentials (access key ID and secret access key). Adapted credentials provider chain from:\n    https://boto3.amazonaws.com/v1/documentation/api/latest/guide/configuration.html and\n    https://docs.aws.amazon.com/sdk-for-java/v1/developer-guide/credentials.html\n    \"\"\"\n    if not use_iam:\n        return None, None\n\n    # attempt to lookup AWS security credentials through the credentials URI the ECS agent generated\n    if aws_creds_uri:\n        return get_aws_security_credentials_from_ecs(config, aws_creds_uri, True)\n\n    # attempt to lookup AWS security credentials in AWS credentials file (~/.aws/credentials)\n    # and configs file (~/.aws/config) with given awsprofile\n    # if the credentials are not present in above filepath, and botocore is present, attempt to assume the given awsprofile\n    if awsprofile:\n        return get_aws_security_credentials_from_awsprofile(awsprofile, True)\n\n    # attempt to lookup AWS security credentials through AWS_CONTAINER_CREDENTIALS_RELATIVE_URI environment variable\n    if ECS_URI_ENV in os.environ:\n        credentials, credentials_source = get_aws_security_credentials_from_ecs(\n            config, os.environ[ECS_URI_ENV], False\n        )\n        if credentials and credentials_source:\n            return credentials, credentials_source\n\n    # attempt to lookup AWS security credentials through AssumeRoleWithWebIdentity\n    # (e.g. for IAM Role for Service Accounts (IRSA) approach on EKS)\n    if (\n        WEB_IDENTITY_ROLE_ARN_ENV in os.environ\n        and WEB_IDENTITY_TOKEN_FILE_ENV in os.environ\n    ):\n        credentials, credentials_source = get_aws_security_credentials_from_webidentity(\n            config,\n            os.environ[WEB_IDENTITY_ROLE_ARN_ENV],\n            os.environ[WEB_IDENTITY_TOKEN_FILE_ENV],\n            region,\n            False,\n        )\n        if credentials and credentials_source:\n            return credentials, credentials_source\n\n    # attempt to lookup AWS security credentials with IAM role name attached to instance\n    # through IAM role name security credentials lookup uri\n    iam_role_name = get_iam_role_name(config)\n    if iam_role_name:\n        (\n            credentials,\n            credentials_source,\n        ) = get_aws_security_credentials_from_instance_metadata(config, iam_role_name)\n        if credentials and credentials_source:\n            return credentials, credentials_source\n\n    error_msg = (\n        \"AWS Access Key ID and Secret Access Key are not found in AWS credentials file (%s), config file (%s), \"\n        \"from ECS credentials relative uri, or from the instance security credentials service\"\n        % (AWS_CREDENTIALS_FILE, AWS_CONFIG_FILE)\n    )\n    fatal_error(error_msg, error_msg)\n\n\ndef get_aws_security_credentials_from_awsprofile(awsprofile, is_fatal=False):\n    for file_path in [AWS_CREDENTIALS_FILE, AWS_CONFIG_FILE]:\n        if os.path.exists(file_path):\n            credentials = credentials_file_helper(file_path, awsprofile)\n            if credentials[\"AccessKeyId\"]:\n                logging.debug(\"Retrieved credentials from %s\" % file_path)\n                return credentials, os.path.basename(file_path) + \":\" + awsprofile\n\n    # If credentials are not defined in the aws credentials and config file, attempt to assume the named profile\n    credentials = botocore_credentials_helper(awsprofile)\n    if credentials[\"AccessKeyId\"]:\n        logging.debug(\"Retrieved credentials from assumed profile %s\" % awsprofile)\n        return credentials, \"named_profile:\" + awsprofile\n\n    # Fail if credentials cannot be fetched from the given awsprofile\n    if is_fatal:\n        log_message = (\n            \"AWS security credentials not found in %s or %s under named profile [%s]\"\n            % (AWS_CREDENTIALS_FILE, AWS_CONFIG_FILE, awsprofile)\n        )\n        fatal_error(log_message)\n    else:\n        return None, None\n\n\ndef get_aws_security_credentials_from_ecs(config, aws_creds_uri, is_fatal=False):\n    ecs_uri = ECS_TASK_METADATA_API + aws_creds_uri\n    ecs_unsuccessful_resp = (\n        \"Unsuccessful retrieval of AWS security credentials at %s.\" % ecs_uri\n    )\n    ecs_url_error_msg = (\n        \"Unable to reach %s to retrieve AWS security credentials. See %s for more info.\"\n        % (ecs_uri, SECURITY_CREDS_ECS_URI_HELP_URL)\n    )\n    ecs_security_dict = url_request_helper(\n        config, ecs_uri, ecs_unsuccessful_resp, ecs_url_error_msg\n    )\n\n    if ecs_security_dict and all(k in ecs_security_dict for k in CREDENTIALS_KEYS):\n        return ecs_security_dict, \"ecs:\" + aws_creds_uri\n\n    # Fail if credentials cannot be fetched from the given aws_creds_uri\n    if is_fatal:\n        fatal_error(ecs_unsuccessful_resp, ecs_unsuccessful_resp)\n    else:\n        return None, None\n\n\ndef get_aws_security_credentials_from_webidentity(\n    config, role_arn, token_file, region, is_fatal=False\n):\n    try:\n        with open(token_file, \"r\") as f:\n            token = f.read()\n    except Exception as e:\n        if is_fatal:\n            unsuccessful_resp = \"Error reading token file %s: %s\" % (token_file, e)\n            fatal_error(unsuccessful_resp, unsuccessful_resp)\n        else:\n            return None, None\n\n    STS_ENDPOINT_URL = STS_ENDPOINT_URL_FORMAT.format(region)\n    webidentity_url = (\n        STS_ENDPOINT_URL\n        + \"?\"\n        + urlencode(\n            {\n                \"Version\": \"2011-06-15\",\n                \"Action\": \"AssumeRoleWithWebIdentity\",\n                \"RoleArn\": role_arn,\n                \"RoleSessionName\": \"efs-mount-helper\",\n                \"WebIdentityToken\": token,\n            }\n        )\n    )\n\n    unsuccessful_resp = (\n        \"Unsuccessful retrieval of AWS security credentials at %s.\" % STS_ENDPOINT_URL\n    )\n    url_error_msg = (\n        \"Unable to reach %s to retrieve AWS security credentials. See %s for more info.\"\n        % (STS_ENDPOINT_URL, SECURITY_CREDS_WEBIDENTITY_HELP_URL)\n    )\n    resp = url_request_helper(\n        config,\n        webidentity_url,\n        unsuccessful_resp,\n        url_error_msg,\n        headers={\"Accept\": \"application/json\"},\n    )\n\n    if resp:\n        creds = (\n            resp.get(\"AssumeRoleWithWebIdentityResponse\", {})\n            .get(\"AssumeRoleWithWebIdentityResult\", {})\n            .get(\"Credentials\", {})\n        )\n        if all(k in creds for k in [\"AccessKeyId\", \"SecretAccessKey\", \"SessionToken\"]):\n            return {\n                \"AccessKeyId\": creds[\"AccessKeyId\"],\n                \"SecretAccessKey\": creds[\"SecretAccessKey\"],\n                \"Token\": creds[\"SessionToken\"],\n            }, \"webidentity:\" + \",\".join([role_arn, token_file])\n\n    # Fail if credentials cannot be fetched from the given aws_creds_uri\n    if is_fatal:\n        fatal_error(unsuccessful_resp, unsuccessful_resp)\n    else:\n        return None, None\n\n\ndef get_aws_security_credentials_from_instance_metadata(config, iam_role_name):\n    security_creds_lookup_url = INSTANCE_IAM_URL + iam_role_name\n    unsuccessful_resp = (\n        \"Unsuccessful retrieval of AWS security credentials at %s.\"\n        % security_creds_lookup_url\n    )\n    url_error_msg = (\n        \"Unable to reach %s to retrieve AWS security credentials. See %s for more info.\"\n        % (security_creds_lookup_url, SECURITY_CREDS_IAM_ROLE_HELP_URL)\n    )\n    iam_security_dict = url_request_helper(\n        config, security_creds_lookup_url, unsuccessful_resp, url_error_msg\n    )\n\n    if iam_security_dict and all(k in iam_security_dict for k in CREDENTIALS_KEYS):\n        return iam_security_dict, \"metadata:\"\n    else:\n        return None, None\n\n\ndef get_iam_role_name(config):\n    iam_role_unsuccessful_resp = (\n        \"Unsuccessful retrieval of IAM role name at %s.\" % INSTANCE_IAM_URL\n    )\n    iam_role_url_error_msg = (\n        \"Unable to reach %s to retrieve IAM role name. See %s for more info.\"\n        % (INSTANCE_IAM_URL, SECURITY_CREDS_IAM_ROLE_HELP_URL)\n    )\n    iam_role_name = url_request_helper(\n        config, INSTANCE_IAM_URL, iam_role_unsuccessful_resp, iam_role_url_error_msg\n    )\n    return iam_role_name\n\n\ndef credentials_file_helper(file_path, awsprofile):\n    aws_credentials_configs = read_config(file_path)\n    credentials = {\"AccessKeyId\": None, \"SecretAccessKey\": None, \"Token\": None}\n\n    try:\n        access_key = aws_credentials_configs.get(awsprofile, \"aws_access_key_id\")\n        secret_key = aws_credentials_configs.get(awsprofile, \"aws_secret_access_key\")\n        session_token = aws_credentials_configs.get(awsprofile, \"aws_session_token\")\n\n        credentials[\"AccessKeyId\"] = access_key\n        credentials[\"SecretAccessKey\"] = secret_key\n        credentials[\"Token\"] = session_token\n    except NoOptionError as e:\n        if \"aws_access_key_id\" in str(e) or \"aws_secret_access_key\" in str(e):\n            logging.debug(\n                \"aws_access_key_id or aws_secret_access_key not found in %s under named profile [%s]\",\n                file_path,\n                awsprofile,\n            )\n        if \"aws_session_token\" in str(e):\n            logging.debug(\"aws_session_token not found in %s\", file_path)\n            credentials[\"AccessKeyId\"] = aws_credentials_configs.get(\n                awsprofile, \"aws_access_key_id\"\n            )\n            credentials[\"SecretAccessKey\"] = aws_credentials_configs.get(\n                awsprofile, \"aws_secret_access_key\"\n            )\n    except NoSectionError:\n        logging.debug(\"No [%s] section found in config file %s\", awsprofile, file_path)\n\n    return credentials\n\n\ndef botocore_credentials_helper(awsprofile):\n    # This method retrieves credentials from aws named profile using botocore, botocore will then assume that named profile, get\n    # and return the credentials\n    credentials = {\"AccessKeyId\": None, \"SecretAccessKey\": None, \"Token\": None}\n    if not BOTOCORE_PRESENT:\n        logging.error(\n            \"Cannot find credentials for %s, to assume this profile, please install botocore first.\"\n            % awsprofile\n        )\n        return credentials\n    session = botocore.session.get_session()\n    session.set_config_variable(\"profile\", awsprofile)\n\n    try:\n        frozen_credentials = session.get_credentials().get_frozen_credentials()\n    except ProfileNotFound as e:\n        fatal_error(\n            \"%s, please add the [profile %s] section in the aws config file following %s and %s.\"\n            % (e, awsprofile, NAMED_PROFILE_HELP_URL, CONFIG_FILE_SETTINGS_HELP_URL)\n        )\n\n    credentials[\"AccessKeyId\"] = frozen_credentials.access_key\n    credentials[\"SecretAccessKey\"] = frozen_credentials.secret_key\n    credentials[\"Token\"] = frozen_credentials.token\n    return credentials\n\n\ndef get_aws_profile(options, use_iam):\n    awsprofile = options.get(\"awsprofile\")\n    if not awsprofile and use_iam:\n        for file_path in [AWS_CREDENTIALS_FILE, AWS_CONFIG_FILE]:\n            aws_credentials_configs = read_config(file_path)\n            # check if aws access key id is found under [default] section in current file and return 'default' if so\n            try:\n                access_key = aws_credentials_configs.get(\"default\", \"aws_access_key_id\")\n                if access_key is not None:\n                    return \"default\"\n            except (NoSectionError, NoOptionError):\n                continue\n\n    return awsprofile\n\n\ndef is_instance_metadata_url(url):\n    return url.startswith(\"http://169.254.169.254\")\n\n\ndef url_request_helper(config, url, unsuccessful_resp, url_error_msg, headers={}):\n    try:\n        req = Request(url)\n        for k, v in headers.items():\n            req.add_header(k, v)\n\n        if not fetch_ec2_metadata_token_disabled(config) and is_instance_metadata_url(\n            url\n        ):\n            # https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/configuring-instance-metadata-service.html\n            # IMDSv1 is a request/response method to access instance metadata\n            # IMDSv2 is a session-oriented method to access instance metadata\n            # We expect the token retrieve will fail in bridge networking environment (e.g. container) since the default hop\n            # limit for getting the token is 1. If the token retrieve does timeout, we fallback to use IMDSv1 instead\n            token = get_aws_ec2_metadata_token()\n            if token:\n                req.add_header(\"X-aws-ec2-metadata-token\", token)\n\n        request_resp = urlopen(req, timeout=1)\n\n        return get_resp_obj(request_resp, url, unsuccessful_resp)\n    except socket.timeout:\n        err_msg = \"Request timeout\"\n    except HTTPError as e:\n        # For instance enable with IMDSv2 and fetch token disabled, Unauthorized 401 error will be thrown\n        if (\n            e.code == 401\n            and fetch_ec2_metadata_token_disabled(config)\n            and is_instance_metadata_url(url)\n        ):\n            logging.warning(\n                \"Unauthorized request to instance metadata url %s, IMDSv2 is enabled on the instance, while fetching \"\n                \"ec2 metadata token is disabled. Please set the value of config item \"\n                '\"%s\" to \"false\" in config file %s.'\n                % (url, DISABLE_FETCH_EC2_METADATA_TOKEN_ITEM, CONFIG_FILE)\n            )\n        err_msg = \"Unable to reach the url at %s: status=%d, reason is %s\" % (\n            url,\n            e.code,\n            e.reason,\n        )\n    except URLError as e:\n        err_msg = \"Unable to reach the url at %s, reason is %s\" % (url, e.reason)\n\n    if err_msg:\n        logging.debug(\"%s %s\", url_error_msg, err_msg)\n    return None\n\n\ndef get_resp_obj(request_resp, url, unsuccessful_resp):\n    \"\"\"\n    Parse the response of an url request\n\n    :return: If the response result can be parsed into json object, return the json object parsed from the response.\n             Otherwise return the response body in string format.\n    \"\"\"\n\n    if request_resp.getcode() != 200:\n        logging.debug(\n            unsuccessful_resp + \" %s: ResponseCode=%d\", url, request_resp.getcode()\n        )\n        return None\n\n    resp_body = request_resp.read()\n    resp_body_type = type(resp_body)\n    try:\n        if resp_body_type is str:\n            resp_dict = json.loads(resp_body)\n        else:\n            resp_dict = json.loads(\n                resp_body.decode(\n                    request_resp.headers.get_content_charset() or \"us-ascii\"\n                )\n            )\n\n        return resp_dict\n    except ValueError:\n        return resp_body if resp_body_type is str else resp_body.decode(\"utf-8\")\n\n\ndef parse_options(options):\n    opts = {}\n    for o in options.split(\",\"):\n        if \"=\" in o:\n            k, v = o.split(\"=\")\n            opts[k] = v\n        else:\n            opts[o] = None\n    return opts\n\n\ndef get_tls_port_range(config):\n    lower_bound = config.getint(CONFIG_SECTION, \"port_range_lower_bound\")\n    upper_bound = config.getint(CONFIG_SECTION, \"port_range_upper_bound\")\n\n    if lower_bound >= upper_bound:\n        fatal_error(\n            'Configuration option \"port_range_upper_bound\" defined as %d '\n            'must be strictly greater than \"port_range_lower_bound\" defined as %d.'\n            % (upper_bound, lower_bound)\n        )\n\n    return lower_bound, upper_bound\n\n\ndef choose_tls_port_and_get_bind_sock(config, options):\n    if \"tlsport\" in options:\n        ports_to_try = [int(options[\"tlsport\"])]\n    else:\n        lower_bound, upper_bound = get_tls_port_range(config)\n\n        ports_to_try = list(range(lower_bound, upper_bound))\n\n        # shuffle the ports_to_try to reduce possibility of multiple mounts starting from same port range\n        random.shuffle(ports_to_try)\n\n    if \"netns\" not in options:\n        tls_port_sock = find_tls_port_in_range_and_get_bind_sock(ports_to_try)\n    else:\n        with NetNS(nspath=options[\"netns\"]):\n            tls_port_sock = find_tls_port_in_range_and_get_bind_sock(ports_to_try)\n\n    if tls_port_sock:\n        return tls_port_sock\n\n    if \"tlsport\" in options:\n        fatal_error(\n            \"Specified port [%s] is unavailable. Try selecting a different port.\"\n            % options[\"tlsport\"]\n        )\n    else:\n        fatal_error(\n            \"Failed to locate an available port in the range [%d, %d], try specifying a different port range in %s\"\n            % (lower_bound, upper_bound, CONFIG_FILE)\n        )\n\n\ndef find_tls_port_in_range_and_get_bind_sock(ports_to_try):\n    sock = socket.socket()\n    for tls_port in ports_to_try:\n        try:\n            logging.info(\"binding %s\", tls_port)\n            sock.bind((\"localhost\", tls_port))\n            return sock\n        except socket.error as e:\n            logging.info(e)\n            continue\n    sock.close()\n    return None\n\n\ndef is_ocsp_enabled(config, options):\n    if \"ocsp\" in options:\n        return True\n    elif \"noocsp\" in options:\n        return False\n    else:\n        return get_boolean_config_item_value(\n            config, CONFIG_SECTION, \"stunnel_check_cert_validity\", default_value=False\n        )\n\n\ndef get_mount_specific_filename(fs_id, mountpoint, tls_port):\n    return \"%s.%s.%d\" % (\n        fs_id,\n        os.path.abspath(mountpoint).replace(os.sep, \".\").lstrip(\".\"),\n        tls_port,\n    )\n\n\ndef serialize_stunnel_config(config, header=None):\n    lines = []\n\n    if header:\n        lines.append(\"[%s]\" % header)\n\n    for k, v in config.items():\n        if type(v) is list:\n            for item in v:\n                lines.append(\"%s = %s\" % (k, item))\n        else:\n            lines.append(\"%s = %s\" % (k, v))\n\n    return lines\n\n\ndef add_stunnel_ca_options(efs_config, config, options, region):\n    if \"cafile\" in options:\n        stunnel_cafile = options[\"cafile\"]\n    else:\n        try:\n            config_section = get_config_section(config, region)\n            stunnel_cafile = config.get(config_section, \"stunnel_cafile\")\n            logging.debug(\n                \"Using stunnel_cafile %s in config section [%s]\",\n                stunnel_cafile,\n                config_section,\n            )\n        except NoOptionError:\n            logging.debug(\n                \"No CA file configured, using default CA file %s\",\n                DEFAULT_STUNNEL_CAFILE,\n            )\n            stunnel_cafile = DEFAULT_STUNNEL_CAFILE\n\n    if not os.path.exists(stunnel_cafile):\n        fatal_error(\n            \"Failed to find certificate authority file for verification\",\n            'Failed to find CAfile \"%s\"' % stunnel_cafile,\n        )\n\n    efs_config[\"CAfile\"] = stunnel_cafile\n\n\ndef get_config_section(config, region):\n    region_specific_config_section = \"%s.%s\" % (CONFIG_SECTION, region)\n    if config.has_section(region_specific_config_section):\n        config_section = region_specific_config_section\n    else:\n        config_section = CONFIG_SECTION\n    return config_section\n\n\ndef is_stunnel_option_supported(\n    stunnel_output,\n    stunnel_option_name,\n    stunnel_option_value=None,\n    emit_warning_log=True,\n):\n    supported = False\n    for line in stunnel_output:\n        if line.startswith(stunnel_option_name):\n            if not stunnel_option_value:\n                supported = True\n                break\n            elif stunnel_option_value and stunnel_option_value in line:\n                supported = True\n                break\n\n    if not supported and emit_warning_log:\n        if not stunnel_option_value:\n            logging.warning('stunnel does not support \"%s\"', stunnel_option_name)\n        else:\n            logging.warning(\n                'stunnel does not support \"%s\" as value of \"%s\"',\n                stunnel_option_value,\n                stunnel_option_name,\n            )\n\n    return supported\n\n\ndef get_stunnel_options():\n    stunnel_command = [_stunnel_bin(), \"-help\"]\n    proc = subprocess.Popen(\n        stunnel_command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, close_fds=True\n    )\n    proc.wait()\n    _, err = proc.communicate()\n\n    return err.splitlines()\n\n\ndef _stunnel_bin():\n    installation_message = \"Please install it following the instructions at: https://docs.aws.amazon.com/efs/latest/ug/using-amazon-efs-utils.html#upgrading-stunnel\"\n    if get_system_release_version() in AMAZON_LINUX_2_RELEASE_VERSIONS:\n        return find_command_path(\"stunnel5\", installation_message)\n    else:\n        return find_command_path(\"stunnel\", installation_message)\n\n\ndef find_command_path(command, install_method):\n    # If not running on macOS, use linux paths\n    if not check_if_platform_is_mac():\n        env_path = (\n            \"/sbin:/usr/sbin:/usr/local/sbin:/root/bin:/usr/local/bin:/usr/bin:/bin\"\n        )\n    # Homebrew on x86 macOS uses /usr/local/bin; Homebrew on Apple Silicon macOS uses /opt/homebrew/bin since v3.0.0\n    # For more information, see https://brew.sh/2021/02/05/homebrew-3.0.0/\n    else:\n        env_path = \"/opt/homebrew/bin:/usr/local/bin\"\n    os.putenv(\"PATH\", env_path)\n\n    try:\n        path = subprocess.check_output([\"which\", command])\n        return path.strip().decode()\n    except subprocess.CalledProcessError as e:\n        fatal_error(\n            \"Failed to locate %s in %s - %s\" % (command, env_path, install_method), e\n        )\n\n\ndef get_system_release_version():\n    # MacOS does not maintain paths /etc/os-release and /etc/sys-release\n    if check_if_platform_is_mac():\n        return platform.platform()\n\n    try:\n        with open(SYSTEM_RELEASE_PATH) as f:\n            return f.read().strip()\n    except IOError:\n        logging.debug(\"Unable to read %s\", SYSTEM_RELEASE_PATH)\n\n    try:\n        with open(OS_RELEASE_PATH) as f:\n            for line in f:\n                if \"PRETTY_NAME\" in line:\n                    return line.split(\"=\")[1].strip()\n    except IOError:\n        logging.debug(\"Unable to read %s\", OS_RELEASE_PATH)\n\n    return DEFAULT_UNKNOWN_VALUE\n\n\ndef write_stunnel_config_file(\n    config,\n    state_file_dir,\n    fs_id,\n    mountpoint,\n    tls_port,\n    dns_name,\n    verify_level,\n    ocsp_enabled,\n    options,\n    region,\n    log_dir=LOG_DIR,\n    cert_details=None,\n    fallback_ip_address=None,\n):\n    \"\"\"\n    Serializes stunnel configuration to a file. Unfortunately this does not conform to Python's config file format, so we have to\n    hand-serialize it.\n    \"\"\"\n\n    stunnel_options = get_stunnel_options()\n    mount_filename = get_mount_specific_filename(fs_id, mountpoint, tls_port)\n\n    system_release_version = get_system_release_version()\n    global_config = dict(STUNNEL_GLOBAL_CONFIG)\n\n    if is_stunnel_option_supported(\n        stunnel_options, b\"foreground\", b\"quiet\", emit_warning_log=False\n    ):\n        # Do not log to stderr of subprocess in addition to the destinations specified with syslog and output.\n        # Only support in stunnel version 5.25+.\n        global_config[\"foreground\"] = \"quiet\"\n    if any(\n        release in system_release_version\n        for release in SKIP_NO_SO_BINDTODEVICE_RELEASES\n    ):\n        global_config[\"socket\"].remove(\"a:SO_BINDTODEVICE=lo\")\n\n    if get_boolean_config_item_value(\n        config, CONFIG_SECTION, \"stunnel_debug_enabled\", default_value=False\n    ):\n        global_config[\"debug\"] = \"debug\"\n        # If the stunnel debug is enabled, we also redirect stunnel log to stderr to capture any error while launching\n        # the stunnel.\n        global_config[\"foreground\"] = \"yes\"\n        if config.has_option(CONFIG_SECTION, \"stunnel_logs_file\"):\n            global_config[\"output\"] = config.get(\n                CONFIG_SECTION, \"stunnel_logs_file\"\n            ).replace(\"{fs_id}\", fs_id)\n        else:\n            global_config[\"output\"] = os.path.join(\n                log_dir, \"%s.stunnel.log\" % mount_filename\n            )\n    global_config[\"pid\"] = os.path.join(\n        state_file_dir, mount_filename + \"+\", \"stunnel.pid\"\n    )\n    if get_fips_config(config):\n        global_config[\"fips\"] = \"yes\"\n\n    efs_config = dict(STUNNEL_EFS_CONFIG)\n    efs_config[\"accept\"] = efs_config[\"accept\"] % tls_port\n\n    if fallback_ip_address:\n        efs_config[\"connect\"] = efs_config[\"connect\"] % fallback_ip_address\n    else:\n        efs_config[\"connect\"] = efs_config[\"connect\"] % dns_name\n\n    efs_config[\"verify\"] = verify_level\n    if verify_level > 0:\n        add_stunnel_ca_options(efs_config, config, options, region)\n\n    if cert_details:\n        efs_config[\"cert\"] = cert_details[\"certificate\"]\n        efs_config[\"key\"] = cert_details[\"privateKey\"]\n\n    tls_controls_message = (\n        \"WARNING: Your client lacks sufficient controls to properly enforce TLS. Please upgrade stunnel, \"\n        'or disable \"%%s\" in %s.\\nSee %s for more detail.'\n        % (CONFIG_FILE, \"https://docs.aws.amazon.com/console/efs/troubleshooting-tls\")\n    )\n\n    if get_boolean_config_item_value(\n        config, CONFIG_SECTION, \"stunnel_check_cert_hostname\", default_value=True\n    ):\n        if is_stunnel_option_supported(stunnel_options, b\"checkHost\"):\n            # Stunnel checkHost option checks if the specified DNS host name or wildcard matches any of the provider in peer\n            # certificate's CN fields, after introducing the AZ field in dns name, the host name in the stunnel config file\n            # is not valid, remove the az info there\n            efs_config[\"checkHost\"] = dns_name[dns_name.index(fs_id) :]\n        else:\n            fatal_error(tls_controls_message % \"stunnel_check_cert_hostname\")\n\n    # Only use the config setting if the override is not set\n    if ocsp_enabled:\n        if is_stunnel_option_supported(stunnel_options, b\"OCSPaia\"):\n            efs_config[\"OCSPaia\"] = \"yes\"\n        else:\n            fatal_error(tls_controls_message % \"stunnel_check_cert_validity\")\n\n    # If the stunnel libwrap option is supported, we disable the usage of /etc/hosts.allow and /etc/hosts.deny by\n    # setting the option to no\n    if is_stunnel_option_supported(stunnel_options, b\"libwrap\"):\n        efs_config[\"libwrap\"] = \"no\"\n\n    stunnel_config = \"\\n\".join(\n        serialize_stunnel_config(global_config)\n        + serialize_stunnel_config(efs_config, \"efs\")\n    )\n    logging.debug(\"Writing stunnel configuration:\\n%s\", stunnel_config)\n\n    stunnel_config_file = os.path.join(\n        state_file_dir, \"stunnel-config.%s\" % mount_filename\n    )\n\n    with open(stunnel_config_file, \"w\") as f:\n        f.write(stunnel_config)\n\n    return stunnel_config_file\n\n\ndef write_tls_tunnel_state_file(\n    fs_id,\n    mountpoint,\n    tls_port,\n    tunnel_pid,\n    command,\n    files,\n    state_file_dir,\n    cert_details=None,\n):\n    \"\"\"\n    Return the name of the temporary file containing TLS tunnel state, prefixed with a '~'. This file needs to be renamed to a\n    non-temporary version following a successful mount.\n    \"\"\"\n    state_file = \"~\" + get_mount_specific_filename(fs_id, mountpoint, tls_port)\n\n    state = {\n        \"pid\": tunnel_pid,\n        \"cmd\": command,\n        \"files\": files,\n        \"mount_time\": time.time(),\n        \"mountpoint\": mountpoint,\n    }\n\n    if cert_details:\n        state.update(cert_details)\n\n    with open(os.path.join(state_file_dir, state_file), \"w\") as f:\n        json.dump(state, f)\n\n    return state_file\n\n\ndef test_tunnel_process(tunnel_proc, fs_id):\n    tunnel_proc.poll()\n    if tunnel_proc.returncode is not None:\n        _, err = tunnel_proc.communicate()\n        fatal_error(\n            \"Failed to initialize TLS tunnel for %s, please check mount.log for the failure reason.\"\n            % fs_id,\n            'Failed to start TLS tunnel (errno=%d), stderr=\"%s\". If the stderr is lacking enough details, please '\n            \"enable stunnel debug log in efs-utils config file and retry the mount to capture more info.\"\n            % (tunnel_proc.returncode, err.strip()),\n        )\n\n\ndef poll_tunnel_process(tunnel_proc, fs_id, mount_completed):\n    \"\"\"\n    poll the tunnel process health every .5s during the mount attempt to fail fast if the tunnel dies - since this is not called\n    from the main thread, if the tunnel fails, exit uncleanly with os._exit\n    \"\"\"\n    while not mount_completed.is_set():\n        try:\n            test_tunnel_process(tunnel_proc, fs_id)\n        except SystemExit as e:\n            os._exit(e.code)\n        mount_completed.wait(0.5)\n\n\ndef get_init_system(comm_file=\"/proc/1/comm\"):\n    init_system = DEFAULT_UNKNOWN_VALUE\n    if not check_if_platform_is_mac():\n        try:\n            with open(comm_file) as f:\n                init_system = f.read().strip()\n        except IOError:\n            logging.warning(\"Unable to read %s\", comm_file)\n    else:\n        init_system = \"launchd\"\n\n    logging.debug(\"Identified init system: %s\", init_system)\n    return init_system\n\n\ndef check_network_target(fs_id):\n    with open(os.devnull, \"w\") as devnull:\n        if not check_if_platform_is_mac():\n            rc = subprocess.call(\n                [\"systemctl\", \"is-active\", \"network.target\"],\n                stdout=devnull,\n                stderr=devnull,\n                close_fds=True,\n            )\n        else:\n            rc = subprocess.call(\n                [\"sudo\", \"ifconfig\", \"en0\"],\n                stdout=devnull,\n                stderr=devnull,\n                close_fds=True,\n            )\n\n    if rc != 0:\n        fatal_error(\n            'Failed to mount %s because the network was not yet available, add \"_netdev\" to your mount options'\n            % fs_id,\n            exit_code=0,\n        )\n\n\ndef check_network_status(fs_id, init_system):\n    if init_system != \"systemd\":\n        logging.debug(\"Not testing network on non-systemd init systems\")\n        return\n\n    check_network_target(fs_id)\n\n\ndef start_watchdog(init_system):\n    if init_system == \"init\":\n        proc = subprocess.Popen(\n            [\"/sbin/status\", WATCHDOG_SERVICE],\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE,\n            close_fds=True,\n        )\n        status, _ = proc.communicate()\n        if \"stop\" in str(status):\n            subprocess.Popen(\n                [\"/sbin/start\", WATCHDOG_SERVICE],\n                stdout=subprocess.DEVNULL,\n                stderr=subprocess.DEVNULL,\n                close_fds=True,\n            )\n        elif \"start\" in str(status):\n            logging.debug(\"%s is already running\", WATCHDOG_SERVICE)\n\n    elif init_system == \"systemd\":\n        rc = subprocess.call(\n            [\"systemctl\", \"is-active\", \"--quiet\", WATCHDOG_SERVICE], close_fds=True\n        )\n        if rc != 0:\n            subprocess.Popen(\n                [\"systemctl\", \"start\", WATCHDOG_SERVICE],\n                stdout=subprocess.DEVNULL,\n                stderr=subprocess.DEVNULL,\n                close_fds=True,\n            )\n        else:\n            logging.debug(\"%s is already running\", WATCHDOG_SERVICE)\n\n    elif init_system == \"launchd\":\n        rc = subprocess.Popen(\n            [\"sudo\", \"launchctl\", \"list\", WATCHDOG_SERVICE],\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE,\n            close_fds=True,\n        )\n        if rc != 0:\n            if not os.path.exists(WATCHDOG_SERVICE_PLIST_PATH):\n                fatal_error(\n                    \"Watchdog plist file missing. Copy the watchdog plist file in directory /Library/LaunchAgents\"\n                )\n            subprocess.Popen(\n                [\"sudo\", \"launchctl\", \"load\", WATCHDOG_SERVICE_PLIST_PATH],\n                stdout=subprocess.DEVNULL,\n                stderr=subprocess.DEVNULL,\n                close_fds=True,\n            )\n        else:\n            logging.debug(\"%s is already running\", WATCHDOG_SERVICE)\n\n    else:\n        error_message = 'Could not start %s, unrecognized init system \"%s\"' % (\n            WATCHDOG_SERVICE,\n            init_system,\n        )\n        sys.stderr.write(\"%s\\n\" % error_message)\n        logging.warning(error_message)\n\n\ndef create_required_directory(config, directory):\n    mode = 0o750\n    try:\n        mode_str = config.get(CONFIG_SECTION, \"state_file_dir_mode\")\n        try:\n            mode = int(mode_str, 8)\n        except ValueError:\n            logging.warning(\n                'Bad state_file_dir_mode \"%s\" in config file \"%s\"',\n                mode_str,\n                CONFIG_FILE,\n            )\n    except NoOptionError:\n        pass\n\n    try:\n        os.makedirs(directory, mode)\n    except OSError as e:\n        if errno.EEXIST != e.errno or not os.path.isdir(directory):\n            raise\n\n\n# Example of a localhost bind sock: sock.bind(('localhost',12345))\n# sock.getsockname() -> ('127.0.0.1', 12345)\n# This function returns the port of the bind socket, in the example is 12345\ndef get_tls_port_from_sock(tls_port_sock):\n    return tls_port_sock.getsockname()[1]\n\n\n@contextmanager\ndef bootstrap_tls(\n    config,\n    init_system,\n    dns_name,\n    fs_id,\n    mountpoint,\n    options,\n    state_file_dir=STATE_FILE_DIR,\n    fallback_ip_address=None,\n):\n    tls_port_sock = choose_tls_port_and_get_bind_sock(config, options)\n    tls_port = get_tls_port_from_sock(tls_port_sock)\n\n    try:\n        # override the tlsport option so that we can later override the port the NFS client uses to connect to stunnel.\n        # if the user has specified tlsport=X at the command line this will just re-set tlsport to X.\n        options[\"tlsport\"] = tls_port\n\n        use_iam = \"iam\" in options\n        ap_id = options.get(\"accesspoint\")\n        cert_details = {}\n        security_credentials = None\n        client_info = get_client_info(config)\n        region = get_target_region(config)\n\n        if use_iam:\n            aws_creds_uri = options.get(\"awscredsuri\")\n            if aws_creds_uri:\n                kwargs = {\"aws_creds_uri\": aws_creds_uri}\n            else:\n                kwargs = {\"awsprofile\": get_aws_profile(options, use_iam)}\n\n            security_credentials, credentials_source = get_aws_security_credentials(\n                config, use_iam, region, **kwargs\n            )\n\n            if credentials_source:\n                cert_details[\"awsCredentialsMethod\"] = credentials_source\n\n        if ap_id:\n            cert_details[\"accessPoint\"] = ap_id\n\n        # additional symbol appended to avoid naming collisions\n        cert_details[\"mountStateDir\"] = (\n            get_mount_specific_filename(fs_id, mountpoint, tls_port) + \"+\"\n        )\n        # common name for certificate signing request is max 64 characters\n        cert_details[\"commonName\"] = socket.gethostname()[0:64]\n        region = get_target_region(config)\n        cert_details[\"region\"] = region\n        cert_details[\"certificateCreationTime\"] = create_certificate(\n            config,\n            cert_details[\"mountStateDir\"],\n            cert_details[\"commonName\"],\n            cert_details[\"region\"],\n            fs_id,\n            security_credentials,\n            ap_id,\n            client_info,\n            base_path=state_file_dir,\n        )\n        cert_details[\"certificate\"] = os.path.join(\n            state_file_dir, cert_details[\"mountStateDir\"], \"certificate.pem\"\n        )\n        cert_details[\"privateKey\"] = get_private_key_path()\n        cert_details[\"fsId\"] = fs_id\n\n        start_watchdog(init_system)\n\n        if not os.path.exists(state_file_dir):\n            create_required_directory(config, state_file_dir)\n\n        verify_level = int(options.get(\"verify\", DEFAULT_STUNNEL_VERIFY_LEVEL))\n        ocsp_enabled = is_ocsp_enabled(config, options)\n\n        stunnel_config_file = write_stunnel_config_file(\n            config,\n            state_file_dir,\n            fs_id,\n            mountpoint,\n            tls_port,\n            dns_name,\n            verify_level,\n            ocsp_enabled,\n            options,\n            region,\n            cert_details=cert_details,\n            fallback_ip_address=fallback_ip_address,\n        )\n        tunnel_args = [_stunnel_bin(), stunnel_config_file]\n        if \"netns\" in options:\n            tunnel_args = [\"nsenter\", \"--net=\" + options[\"netns\"]] + tunnel_args\n    finally:\n        # Always close the socket we created when choosing TLS port only until now to\n        # 1. avoid concurrent TLS mount port collision 2. enable stunnel process to bind the port\n        logging.debug(\"Closing socket used to choose TLS port %s.\", tls_port)\n        tls_port_sock.close()\n\n    # launch the tunnel in a process group so if it has any child processes, they can be killed easily by the mount watchdog\n    logging.info('Starting TLS tunnel: \"%s\"', \" \".join(tunnel_args))\n    tunnel_proc = subprocess.Popen(\n        tunnel_args,\n        stdout=subprocess.DEVNULL,\n        stderr=subprocess.PIPE,\n        preexec_fn=os.setsid,\n        close_fds=True,\n    )\n    logging.info(\"Started TLS tunnel, pid: %d\", tunnel_proc.pid)\n\n    temp_tls_state_file = write_tls_tunnel_state_file(\n        fs_id,\n        mountpoint,\n        tls_port,\n        tunnel_proc.pid,\n        tunnel_args,\n        [stunnel_config_file],\n        state_file_dir,\n        cert_details=cert_details,\n    )\n\n    if \"netns\" not in options:\n        test_tlsport(options[\"tlsport\"])\n    else:\n        with NetNS(nspath=options[\"netns\"]):\n            test_tlsport(options[\"tlsport\"])\n\n    try:\n        yield tunnel_proc\n    finally:\n        os.rename(\n            os.path.join(state_file_dir, temp_tls_state_file),\n            os.path.join(state_file_dir, temp_tls_state_file[1:]),\n        )\n\n\ndef test_tlsport(tlsport):\n    retry_times = 5\n    while not verify_tlsport_can_be_connected(tlsport) and retry_times > 0:\n        logging.debug(\n            \"The tlsport %s cannot be connected yet, sleep %s(s), %s retry time(s) left\",\n            tlsport,\n            DEFAULT_TIMEOUT,\n            retry_times,\n        )\n        time.sleep(DEFAULT_TIMEOUT)\n        retry_times -= 1\n\n\ndef check_if_nfsvers_is_compatible_with_macos(options):\n    # MacOS does not support NFSv4.1\n    if (\n        (\"nfsvers\" in options and options[\"nfsvers\"] == \"4.1\")\n        or (\"vers\" in options and options[\"vers\"] == \"4.1\")\n        or (\"minorversion\" in options and options[\"minorversion\"] == 1)\n    ):\n        fatal_error(\"NFSv4.1 is not supported on MacOS, please switch to NFSv4.0\")\n\n\ndef get_nfs_mount_options(options):\n    # If you change these options, update the man page as well at man/mount.efs.8\n    if \"nfsvers\" not in options and \"vers\" not in options:\n        options[\"nfsvers\"] = \"4.1\" if not check_if_platform_is_mac() else \"4.0\"\n\n    if check_if_platform_is_mac():\n        check_if_nfsvers_is_compatible_with_macos(options)\n\n    if \"rsize\" not in options:\n        options[\"rsize\"] = \"1048576\"\n    if \"wsize\" not in options:\n        options[\"wsize\"] = \"1048576\"\n    if \"soft\" not in options and \"hard\" not in options:\n        options[\"hard\"] = None\n    if \"timeo\" not in options:\n        options[\"timeo\"] = \"600\"\n    if \"retrans\" not in options:\n        options[\"retrans\"] = \"2\"\n    if \"noresvport\" not in options:\n        options[\"noresvport\"] = None\n\n    # Set mountport to 2049 for MacOS\n    if check_if_platform_is_mac():\n        options[\"mountport\"] = \"2049\"\n\n    if \"tls\" in options:\n        options[\"port\"] = options[\"tlsport\"]\n\n    def to_nfs_option(k, v):\n        if v is None:\n            return k\n        return \"%s=%s\" % (str(k), str(v))\n\n    nfs_options = [\n        to_nfs_option(k, v) for k, v in options.items() if k not in EFS_ONLY_OPTIONS\n    ]\n\n    return \",\".join(nfs_options)\n\n\ndef mount_nfs(config, dns_name, path, mountpoint, options, fallback_ip_address=None):\n\n    if \"tls\" in options:\n        mount_path = \"127.0.0.1:%s\" % path\n    elif fallback_ip_address:\n        mount_path = \"%s:%s\" % (fallback_ip_address, path)\n    else:\n        mount_path = \"%s:%s\" % (dns_name, path)\n\n    if not check_if_platform_is_mac():\n        command = [\n            \"/sbin/mount.nfs4\",\n            mount_path,\n            mountpoint,\n            \"-o\",\n            get_nfs_mount_options(options),\n        ]\n    else:\n        command = [\n            \"/sbin/mount_nfs\",\n            \"-o\",\n            get_nfs_mount_options(options),\n            mount_path,\n            mountpoint,\n        ]\n\n    if \"netns\" in options:\n        command = [\"nsenter\", \"--net=\" + options[\"netns\"]] + command\n\n    if call_nfs_mount_command_with_retry_succeed(\n        config, options, command, dns_name, mountpoint\n    ):\n        return\n\n    logging.info('Executing: \"%s\"', \" \".join(command))\n\n    proc = subprocess.Popen(\n        command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, close_fds=True\n    )\n    out, err = proc.communicate()\n\n    if proc.returncode == 0:\n        post_mount_nfs_success(config, options, dns_name, mountpoint)\n    else:\n        message = 'Failed to mount %s at %s: returncode=%d, stderr=\"%s\"' % (\n            dns_name,\n            mountpoint,\n            proc.returncode,\n            err.strip(),\n        )\n        fatal_error(err.strip(), message, proc.returncode)\n\n\ndef post_mount_nfs_success(config, options, dns_name, mountpoint):\n    message = \"Successfully mounted %s at %s\" % (dns_name, mountpoint)\n    logging.info(message)\n    publish_cloudwatch_log(CLOUDWATCHLOG_AGENT, message)\n\n    # only perform readahead optimize after mount succeed\n    optimize_readahead_window(mountpoint, options, config)\n\n\ndef call_nfs_mount_command_with_retry_succeed(\n    config, options, command, dns_name, mountpoint\n):\n    def backoff_function(i):\n        \"\"\"Backoff exponentially and add a constant 0-1 second jitter\"\"\"\n        return (1.5 ** i) + random.random()\n\n    if not get_boolean_config_item_value(\n        config, CONFIG_SECTION, \"retry_nfs_mount_command\", default_value=True\n    ):\n        logging.debug(\n            \"Configuration 'retry_nfs_mount_command' is not enabled, skip retrying mount.nfs command.\"\n        )\n        return\n\n    retry_nfs_mount_command_timeout_sec = get_int_value_from_config_file(\n        config,\n        \"retry_nfs_mount_command_timeout_sec\",\n        DEFAULT_NFS_MOUNT_COMMAND_TIMEOUT_SEC,\n    )\n    retry_count = get_int_value_from_config_file(\n        config,\n        \"retry_nfs_mount_command_count\",\n        DEFAULT_NFS_MOUNT_COMMAND_RETRY_COUNT,\n    )\n\n    for retry in range(retry_count - 1):\n        retry_sleep_time_sec = backoff_function(retry)\n        err = \"unknown error\"\n        logging.info(\n            'Executing: \"%s\" with %s sec time limit.'\n            % (\" \".join(command), retry_nfs_mount_command_timeout_sec)\n        )\n        proc = subprocess.Popen(\n            command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, close_fds=True\n        )\n\n        try:\n            out, err = proc.communicate(timeout=retry_nfs_mount_command_timeout_sec)\n            rc = proc.poll()\n            if rc != 0:\n                continue_retry = any(\n                    error_string in str(err) for error_string in RETRYABLE_ERRORS\n                )\n                if continue_retry:\n                    logging.error(\n                        'Mounting %s to %s failed, return code=%s, stdout=\"%s\", stderr=\"%s\", mount attempt %d/%d, '\n                        \"wait %d sec before next attempt.\"\n                        % (\n                            dns_name,\n                            mountpoint,\n                            rc,\n                            out,\n                            err,\n                            retry + 1,\n                            retry_count,\n                            retry_sleep_time_sec,\n                        )\n                    )\n                else:\n                    message = 'Failed to mount %s at %s: returncode=%d, stderr=\"%s\"' % (\n                        dns_name,\n                        mountpoint,\n                        proc.returncode,\n                        err.strip(),\n                    )\n                    fatal_error(err.strip(), message, proc.returncode)\n            else:\n                post_mount_nfs_success(config, options, dns_name, mountpoint)\n                return True\n        except subprocess.TimeoutExpired:\n            try:\n                proc.kill()\n            except OSError:\n                # Silently fail if the subprocess has exited already\n                pass\n            retry_sleep_time_sec = 0\n            err = \"timeout after %s sec\" % retry_nfs_mount_command_timeout_sec\n            logging.error(\n                \"Mounting %s to %s failed due to %s, mount attempt %d/%d, wait %d sec before next attempt.\"\n                % (\n                    dns_name,\n                    mountpoint,\n                    err,\n                    retry + 1,\n                    retry_count,\n                    retry_sleep_time_sec,\n                )\n            )\n        except Exception as e:\n            message = 'Failed to mount %s at %s: returncode=%d, stderr=\"%s\", %s' % (\n                dns_name,\n                mountpoint,\n                proc.returncode,\n                err.strip(),\n                e,\n            )\n            fatal_error(err.strip(), message, proc.returncode)\n\n        sys.stderr.write(\n            \"Mount attempt %d/%d failed due to %s, wait %d sec before next attempt.\\n\"\n            % (retry + 1, retry_count, err, retry_sleep_time_sec)\n        )\n        time.sleep(retry_sleep_time_sec)\n\n    return False\n\n\ndef get_int_value_from_config_file(config, config_name, default_config_value):\n    val = default_config_value\n    try:\n        value_from_config = config.get(CONFIG_SECTION, config_name)\n        try:\n            if int(value_from_config) > 0:\n                val = int(value_from_config)\n            else:\n                logging.debug(\n                    '%s value in config file \"%s\" is lower than 1. Defaulting to %d.',\n                    config_name,\n                    CONFIG_FILE,\n                    default_config_value,\n                )\n        except ValueError:\n            logging.debug(\n                'Bad %s, \"%s\", in config file \"%s\". Defaulting to %d.',\n                config_name,\n                value_from_config,\n                CONFIG_FILE,\n                default_config_value,\n            )\n    except NoOptionError:\n        logging.debug(\n            'No %s value in config file \"%s\". Defaulting to %d.',\n            config_name,\n            CONFIG_FILE,\n            default_config_value,\n        )\n\n    return val\n\n\ndef usage(out, exit_code=1):\n    out.write(\n        \"Usage: mount.efs [--version] [-h|--help] <fsname> <mountpoint> [-o <options>]\\n\"\n    )\n    sys.exit(exit_code)\n\n\ndef parse_arguments_early_exit(args=None):\n    \"\"\"Parse arguments, checking for early exit conditions only\"\"\"\n    if args is None:\n        args = sys.argv\n\n    if \"-h\" in args[1:] or \"--help\" in args[1:]:\n        usage(out=sys.stdout, exit_code=0)\n\n    if \"--version\" in args[1:]:\n        sys.stdout.write(\"%s Version: %s\\n\" % (args[0], VERSION))\n        sys.exit(0)\n\n\ndef parse_arguments(config, args=None):\n    \"\"\"Parse arguments, return (fsid, path, mountpoint, options)\"\"\"\n    if args is None:\n        args = sys.argv\n\n    fsname = None\n    mountpoint = None\n    options = {}\n\n    if not check_if_platform_is_mac():\n        if len(args) > 1:\n            fsname = args[1]\n        if len(args) > 2:\n            mountpoint = args[2]\n        if len(args) > 4 and \"-o\" in args[:-1]:\n            options_index = args.index(\"-o\") + 1\n            options = parse_options(args[options_index])\n    else:\n        if len(args) > 1:\n            fsname = args[-2]\n        if len(args) > 2:\n            mountpoint = args[-1]\n        if len(args) > 4 and \"-o\" in args[:-2]:\n            for arg in args[1:-2]:\n                if arg != \"-o\":\n                    options.update(parse_options(arg))\n\n    if not fsname or not mountpoint:\n        usage(out=sys.stderr)\n\n    # We treat az as an option when customer is using dns name of az mount target to mount,\n    # even if they don't provide az with option, we update the options with that info\n    fs_id, path, az = match_device(config, fsname, options)\n\n    return fs_id, path, mountpoint, add_field_in_options(options, \"az\", az)\n\n\ndef get_client_info(config):\n    client_info = {}\n\n    # source key/value pair in config file\n    if config.has_option(CLIENT_INFO_SECTION, \"source\"):\n        client_source = config.get(CLIENT_INFO_SECTION, \"source\")\n        if 0 < len(client_source) <= CLIENT_SOURCE_STR_LEN_LIMIT:\n            client_info[\"source\"] = client_source\n    if not client_info.get(\"source\"):\n        if check_if_platform_is_mac():\n            client_info[\"source\"] = DEFAULT_MACOS_VALUE\n        else:\n            client_info[\"source\"] = DEFAULT_UNKNOWN_VALUE\n\n    client_info[\"efs_utils_version\"] = VERSION\n\n    return client_info\n\n\ndef create_certificate(\n    config,\n    mount_name,\n    common_name,\n    region,\n    fs_id,\n    security_credentials,\n    ap_id,\n    client_info,\n    base_path=STATE_FILE_DIR,\n):\n    current_time = get_utc_now()\n    tls_paths = tls_paths_dictionary(mount_name, base_path)\n\n    certificate_config = os.path.join(tls_paths[\"mount_dir\"], \"config.conf\")\n    certificate_signing_request = os.path.join(tls_paths[\"mount_dir\"], \"request.csr\")\n    certificate = os.path.join(tls_paths[\"mount_dir\"], \"certificate.pem\")\n\n    ca_dirs_check(config, tls_paths[\"database_dir\"], tls_paths[\"certs_dir\"])\n    ca_supporting_files_check(\n        tls_paths[\"index\"],\n        tls_paths[\"index_attr\"],\n        tls_paths[\"serial\"],\n        tls_paths[\"rand\"],\n    )\n\n    private_key = check_and_create_private_key(base_path)\n\n    if security_credentials:\n        public_key = os.path.join(tls_paths[\"mount_dir\"], \"publicKey.pem\")\n        create_public_key(private_key, public_key)\n\n    create_ca_conf(\n        certificate_config,\n        common_name,\n        tls_paths[\"mount_dir\"],\n        private_key,\n        current_time,\n        region,\n        fs_id,\n        security_credentials,\n        ap_id,\n        client_info,\n    )\n    create_certificate_signing_request(\n        certificate_config, private_key, certificate_signing_request\n    )\n\n    not_before = get_certificate_timestamp(current_time, minutes=-NOT_BEFORE_MINS)\n    not_after = get_certificate_timestamp(current_time, hours=NOT_AFTER_HOURS)\n\n    cmd = \"openssl ca -startdate %s -enddate %s -selfsign -batch -notext -config %s -in %s -out %s\" % (\n        not_before,\n        not_after,\n        certificate_config,\n        certificate_signing_request,\n        certificate,\n    )\n    subprocess_call(cmd, \"Failed to create self-signed client-side certificate\")\n    return current_time.strftime(CERT_DATETIME_FORMAT)\n\n\ndef get_private_key_path():\n    \"\"\"Wrapped for mocking purposes in unit tests\"\"\"\n    return PRIVATE_KEY_FILE\n\n\ndef check_and_create_private_key(base_path=STATE_FILE_DIR):\n    # Creating RSA private keys is slow, so we will create one private key and allow mounts to share it.\n    # This means, however, that we have to include a locking mechanism to ensure that the private key is\n    # atomically created, as mounts occurring in parallel may try to create the key simultaneously.\n    key = get_private_key_path()\n\n    @contextmanager\n    def open_lock_file():\n        lock_file = os.path.join(base_path, \"efs-utils-lock\")\n        f = os.open(lock_file, os.O_CREAT | os.O_DSYNC | os.O_EXCL | os.O_RDWR)\n        try:\n            lock_file_contents = \"PID: %s\" % os.getpid()\n            os.write(f, lock_file_contents.encode(\"utf-8\"))\n            yield f\n        finally:\n            check_and_remove_lock_file(lock_file, f)\n\n    def do_with_lock(function):\n        while True:\n            try:\n                with open_lock_file():\n                    return function()\n            except OSError as e:\n                if e.errno == errno.EEXIST:\n                    logging.info(\n                        \"Failed to take out private key creation lock, sleeping %s (s)\",\n                        DEFAULT_TIMEOUT,\n                    )\n                    time.sleep(DEFAULT_TIMEOUT)\n                else:\n                    # errno.ENOENT: No such file or directory, errno.EBADF: Bad file descriptor\n                    if e.errno == errno.ENOENT or e.errno == errno.EBADF:\n                        logging.debug(\n                            \"lock file does not exist or Bad file descriptor, The file is already removed nothing to do.\"\n                        )\n                    else:\n                        raise Exception(\n                            \"Could not remove lock file unexpected exception: %s\", e\n                        )\n\n    def generate_key():\n        if os.path.isfile(key):\n            return\n\n        cmd = (\n            \"openssl genpkey -algorithm RSA -out %s -pkeyopt rsa_keygen_bits:3072\" % key\n        )\n        subprocess_call(cmd, \"Failed to create private key\")\n        read_only_mode = 0o400\n        os.chmod(key, read_only_mode)\n\n    do_with_lock(generate_key)\n    return key\n\n\ndef create_certificate_signing_request(config_path, private_key, csr_path):\n    cmd = \"openssl req -new -config %s -key %s -out %s\" % (\n        config_path,\n        private_key,\n        csr_path,\n    )\n    subprocess_call(cmd, \"Failed to create certificate signing request (csr)\")\n\n\ndef create_ca_conf(\n    config_path,\n    common_name,\n    directory,\n    private_key,\n    date,\n    region,\n    fs_id,\n    security_credentials,\n    ap_id,\n    client_info,\n):\n    \"\"\"Populate ca/req configuration file with fresh configurations at every mount since SigV4 signature can change\"\"\"\n    public_key_path = os.path.join(directory, \"publicKey.pem\")\n    ca_extension_body = ca_extension_builder(\n        ap_id, security_credentials, fs_id, client_info\n    )\n    efs_client_auth_body = (\n        efs_client_auth_builder(\n            public_key_path,\n            security_credentials[\"AccessKeyId\"],\n            security_credentials[\"SecretAccessKey\"],\n            date,\n            region,\n            fs_id,\n            security_credentials[\"Token\"],\n        )\n        if security_credentials\n        else \"\"\n    )\n    efs_client_info_body = efs_client_info_builder(client_info) if client_info else \"\"\n    full_config_body = CA_CONFIG_BODY % (\n        directory,\n        private_key,\n        common_name,\n        ca_extension_body,\n        efs_client_auth_body,\n        efs_client_info_body,\n    )\n\n    with open(config_path, \"w\") as f:\n        f.write(full_config_body)\n\n    return full_config_body\n\n\ndef ca_extension_builder(ap_id, security_credentials, fs_id, client_info):\n    ca_extension_str = \"[ v3_ca ]\\nsubjectKeyIdentifier = hash\"\n    if ap_id:\n        ca_extension_str += \"\\n1.3.6.1.4.1.4843.7.1 = ASN1:UTF8String:\" + ap_id\n    if security_credentials:\n        ca_extension_str += \"\\n1.3.6.1.4.1.4843.7.2 = ASN1:SEQUENCE:efs_client_auth\"\n\n    ca_extension_str += \"\\n1.3.6.1.4.1.4843.7.3 = ASN1:UTF8String:\" + fs_id\n\n    if client_info:\n        ca_extension_str += \"\\n1.3.6.1.4.1.4843.7.4 = ASN1:SEQUENCE:efs_client_info\"\n\n    return ca_extension_str\n\n\ndef efs_client_auth_builder(\n    public_key_path,\n    access_key_id,\n    secret_access_key,\n    date,\n    region,\n    fs_id,\n    session_token=None,\n):\n    public_key_hash = get_public_key_sha1(public_key_path)\n    canonical_request = create_canonical_request(\n        public_key_hash, date, access_key_id, region, fs_id, session_token\n    )\n    string_to_sign = create_string_to_sign(canonical_request, date, region)\n    signature = calculate_signature(string_to_sign, date, secret_access_key, region)\n    efs_client_auth_str = \"[ efs_client_auth ]\"\n    efs_client_auth_str += \"\\naccessKeyId = UTF8String:\" + access_key_id\n    efs_client_auth_str += \"\\nsignature = OCTETSTRING:\" + signature\n    efs_client_auth_str += \"\\nsigv4DateTime = UTCTIME:\" + date.strftime(\n        CERT_DATETIME_FORMAT\n    )\n\n    if session_token:\n        efs_client_auth_str += \"\\nsessionToken = EXPLICIT:0,UTF8String:\" + session_token\n\n    return efs_client_auth_str\n\n\ndef efs_client_info_builder(client_info):\n    efs_client_info_str = \"[ efs_client_info ]\"\n    for key, value in client_info.items():\n        efs_client_info_str += \"\\n%s = UTF8String:%s\" % (key, value)\n    return efs_client_info_str\n\n\ndef create_public_key(private_key, public_key):\n    cmd = \"openssl rsa -in %s -outform PEM -pubout -out %s\" % (private_key, public_key)\n    subprocess_call(cmd, \"Failed to create public key\")\n\n\ndef subprocess_call(cmd, error_message):\n    \"\"\"Helper method to run shell openssl command and to handle response error messages\"\"\"\n    retry_times = 3\n    for retry in range(retry_times):\n        process = subprocess.Popen(\n            cmd.split(), stdout=subprocess.PIPE, stderr=subprocess.PIPE, close_fds=True\n        )\n        (output, err) = process.communicate()\n        rc = process.poll()\n        if rc != 0:\n            logging.error(\n                'Command %s failed, rc=%s, stdout=\"%s\", stderr=\"%s\"'\n                % (cmd, rc, output, err),\n                exc_info=True,\n            )\n            try:\n                process.kill()\n            except OSError:\n                # Silently fail if the subprocess has exited already\n                pass\n        else:\n            return output, err\n    error_message = \"%s, error is: %s\" % (error_message, err)\n    fatal_error(error_message, error_message)\n\n\ndef ca_dirs_check(config, database_dir, certs_dir):\n    \"\"\"Check if mount's database and certs directories exist and if not, create directories (also create all intermediate\n    directories if they don't exist).\"\"\"\n    if not os.path.exists(database_dir):\n        create_required_directory(config, database_dir)\n    if not os.path.exists(certs_dir):\n        create_required_directory(config, certs_dir)\n\n\ndef ca_supporting_files_check(index_path, index_attr_path, serial_path, rand_path):\n    \"\"\"Recreate all supporting openssl ca and req files if they're not present in their respective directories\"\"\"\n    if not os.path.isfile(index_path):\n        open(index_path, \"w\").close()\n    if not os.path.isfile(index_attr_path):\n        with open(index_attr_path, \"w+\") as f:\n            f.write(\"unique_subject = no\")\n    if not os.path.isfile(serial_path):\n        with open(serial_path, \"w+\") as f:\n            f.write(\"00\")\n    if not os.path.isfile(rand_path):\n        open(rand_path, \"w\").close()\n\n\ndef get_certificate_timestamp(current_time, **kwargs):\n    updated_time = current_time + timedelta(**kwargs)\n    return updated_time.strftime(CERT_DATETIME_FORMAT)\n\n\ndef get_utc_now():\n    \"\"\"\n    Wrapped for patching purposes in unit tests\n    \"\"\"\n    return datetime.utcnow()\n\n\ndef assert_root():\n    if os.geteuid() != 0:\n        sys.stderr.write(\"only root can run mount.efs\\n\")\n        sys.exit(1)\n\n\ndef read_config(config_file=CONFIG_FILE):\n    try:\n        p = ConfigParser.SafeConfigParser()\n    except AttributeError:\n        p = ConfigParser()\n    p.read(config_file)\n    return p\n\n\ndef bootstrap_logging(config, log_dir=LOG_DIR):\n    raw_level = config.get(CONFIG_SECTION, \"logging_level\")\n    levels = {\n        \"debug\": logging.DEBUG,\n        \"info\": logging.INFO,\n        \"warning\": logging.WARNING,\n        \"error\": logging.ERROR,\n        \"critical\": logging.CRITICAL,\n    }\n    level = levels.get(raw_level.lower())\n    level_error = False\n\n    if not level:\n        # delay logging error about malformed log level until after logging is configured\n        level_error = True\n        level = logging.INFO\n\n    max_bytes = config.getint(CONFIG_SECTION, \"logging_max_bytes\")\n    file_count = config.getint(CONFIG_SECTION, \"logging_file_count\")\n\n    handler = RotatingFileHandler(\n        os.path.join(log_dir, LOG_FILE), maxBytes=max_bytes, backupCount=file_count\n    )\n    handler.setFormatter(\n        logging.Formatter(\n            fmt=\"%(asctime)s - %(levelname)s - %(message)s\",\n            datefmt=\"%Y-%m-%d %H:%M:%S %Z\",\n        )\n    )\n\n    logger = logging.getLogger()\n    logger.setLevel(level)\n    logger.addHandler(handler)\n\n    if level_error:\n        logging.error(\n            'Malformed logging level \"%s\", setting logging level to %s',\n            raw_level,\n            level,\n        )\n\n\ndef get_dns_name_and_fallback_mount_target_ip_address(config, fs_id, options):\n    def _validate_replacement_field_count(format_str, expected_ct):\n        if format_str.count(\"{\") != expected_ct or format_str.count(\"}\") != expected_ct:\n            raise ValueError(\n                \"DNS name format has an incorrect number of replacement fields\"\n            )\n\n    dns_name_format = config.get(CONFIG_SECTION, \"dns_name_format\")\n\n    if \"{fs_id}\" not in dns_name_format:\n        raise ValueError(\"DNS name format must include {fs_id}\")\n\n    format_args = {\"fs_id\": fs_id}\n\n    expected_replacement_field_ct = 1\n\n    if \"{az}\" in dns_name_format:\n        az = options.get(\"az\")\n        if az:\n            expected_replacement_field_ct += 1\n            format_args[\"az\"] = az\n        else:\n            dns_name_format = dns_name_format.replace(\"{az}.\", \"\")\n\n    if \"{region}\" in dns_name_format:\n        expected_replacement_field_ct += 1\n        format_args[\"region\"] = get_target_region(config)\n\n    if \"{dns_name_suffix}\" in dns_name_format:\n        expected_replacement_field_ct += 1\n        config_section = CONFIG_SECTION\n        region = format_args.get(\"region\")\n\n        if region:\n            config_section = get_config_section(config, region)\n\n        format_args[\"dns_name_suffix\"] = config.get(config_section, \"dns_name_suffix\")\n\n        logging.debug(\n            \"Using dns_name_suffix %s in config section [%s]\",\n            format_args.get(\"dns_name_suffix\"),\n            config_section,\n        )\n\n    _validate_replacement_field_count(dns_name_format, expected_replacement_field_ct)\n\n    dns_name = dns_name_format.format(**format_args)\n\n    if \"mounttargetip\" in options:\n        ip_address = options.get(\"mounttargetip\")\n        logging.info(\n            \"Use the mount target ip address %s provided in the mount options to mount.\"\n            % ip_address\n        )\n        try:\n            mount_target_ip_address_can_be_resolved(\n                ip_address,\n                passed_via_options=True,\n                network_namespace=options.get(\"netns\") if \"netns\" in options else None,\n            )\n            return dns_name, options.get(\"mounttargetip\")\n        except FallbackException as e:\n            fallback_message = e.message\n            throw_ip_address_connect_failure_with_fallback_message(\n                ip_address=ip_address, fallback_message=fallback_message\n            )\n\n    if dns_name_can_be_resolved(dns_name):\n        return dns_name, None\n\n    logging.info(\n        \"Failed to resolve %s, attempting to lookup mount target ip address using botocore.\",\n        dns_name,\n    )\n\n    try:\n        fallback_mount_target_ip_address = get_fallback_mount_target_ip_address(\n            config, options, fs_id, dns_name\n        )\n        logging.info(\n            \"Found fall back mount target ip address %s for file system %s\",\n            fallback_mount_target_ip_address,\n            fs_id,\n        )\n        return dns_name, fallback_mount_target_ip_address\n    except FallbackException as e:\n        fallback_message = e.message\n\n    throw_dns_resolve_failure_with_fallback_message(dns_name, fallback_message)\n\n\ndef get_fallback_mount_target_ip_address(config, options, fs_id, dns_name):\n    fall_back_to_ip_address_enabled = (\n        check_if_fall_back_to_mount_target_ip_address_is_enabled(config)\n    )\n\n    if not fall_back_to_ip_address_enabled:\n        fallback_message = (\n            \"Fallback to mount target ip address feature is not enabled in config file %s.\"\n            % CONFIG_FILE\n        )\n        raise FallbackException(fallback_message)\n\n    if not BOTOCORE_PRESENT:\n        fallback_message = \"Failed to import necessary dependency botocore, please install botocore first.\"\n        raise FallbackException(fallback_message)\n\n    mount_target_ip_address = None\n    try:\n        mount_target_ip_address = get_fallback_mount_target_ip_address_helper(\n            config, options, fs_id\n        )\n        mount_target_ip_address_can_be_resolved(\n            mount_target_ip_address,\n            network_namespace=options.get(\"netns\") if \"netns\" in options else None,\n        )\n        return mount_target_ip_address\n    except FallbackException as e:\n        throw_ip_address_connect_failure_with_fallback_message(\n            dns_name, mount_target_ip_address, e.message\n        )\n\n\ndef check_if_fall_back_to_mount_target_ip_address_is_enabled(config):\n    return get_boolean_config_item_value(\n        config,\n        CONFIG_SECTION,\n        FALLBACK_TO_MOUNT_TARGET_IP_ADDRESS_ITEM,\n        default_value=DEFAULT_FALLBACK_ENABLED,\n    )\n\n\ndef check_and_remove_lock_file(path, file):\n    \"\"\"\n    There is a possibility of having a race condition as the lock file is getting deleted in both mount_efs and watchdog,\n    so creating a function in order to check whether the path exist or not before removing the lock file.\n    \"\"\"\n    try:\n        os.close(file)\n        os.remove(path)\n        logging.debug(\"Removed %s successfully\", path)\n    except OSError as e:\n        if not (e.errno == errno.ENOENT or e.errno == errno.EBADF):\n            raise Exception(\"Could not remove %s. Unexpected exception: %s\", path, e)\n        else:\n            logging.debug(\n                \"%s does not exist, The file is already removed nothing to do\", path\n            )\n\n\ndef dns_name_can_be_resolved(dns_name):\n    try:\n        socket.gethostbyname(dns_name)\n        return True\n    except socket.gaierror:\n        return False\n\n\ndef mount_target_ip_address_can_be_resolved(\n    mount_target_ip_address, passed_via_options=False, network_namespace=None\n):\n    tries = 3\n    for attempt in range(tries):\n        try:\n            # Open a socket connection to mount target nfs port to verify that the mount target can be connected\n            if not network_namespace:\n                s = socket.create_connection((mount_target_ip_address, 2049), timeout=2)\n            else:\n                with NetNS(nspath=network_namespace):\n                    s = socket.create_connection(\n                        (mount_target_ip_address, 2049), timeout=2\n                    )\n            s.close()\n            return True\n        except socket.timeout:\n            if attempt < tries - 1:\n                message = (\n                    \"The ip address %s cannot be connected yet, sleep 0.5s, %s retry time(s) left\"\n                    % (mount_target_ip_address, tries - attempt - 1)\n                )\n                logging.warning(message)\n                time.sleep(0.5)\n                continue\n            else:\n                raise FallbackException(\n                    \"Connection to the mount target IP address %s timeout. Please retry in 5 minutes if the \"\n                    \"mount target is newly created. Otherwise check your VPC and security group \"\n                    \"configuration to ensure your file system is reachable via TCP port 2049 from your \"\n                    \"instance.\" % mount_target_ip_address\n                )\n        except Exception as e:\n            hint_message = (\n                \" Please check if the mount target ip address passed via mount option is correct.\"\n                if passed_via_options\n                else \"\"\n            )\n            raise FallbackException(\n                \"Unknown error when connecting to mount target IP address %s, %s.%s\"\n                % (mount_target_ip_address, e, hint_message)\n            )\n\n\ndef get_fallback_mount_target_ip_address_helper(config, options, fs_id):\n    az_name = get_target_az(config, options)\n\n    ec2_client = get_botocore_client(config, \"ec2\", options)\n    efs_client = get_botocore_client(config, \"efs\", options)\n\n    mount_target = get_mount_target_in_az(efs_client, ec2_client, fs_id, az_name)\n    mount_target_ip = mount_target.get(\"IpAddress\")\n    logging.debug(\"Found mount target ip address %s in AZ %s\", mount_target_ip, az_name)\n\n    return mount_target_ip\n\n\ndef throw_dns_resolve_failure_with_fallback_message(dns_name, fallback_message=None):\n    fallback_message = (\n        \"\\nAttempting to lookup mount target ip address using botocore. %s\"\n        % fallback_message\n        if fallback_message\n        else \"\"\n    )\n    message = (\n        'Failed to resolve \"%s\" - check that your file system ID is correct, and ensure that the VPC has an EFS mount '\n        \"target for this file system ID.\\nSee %s for more detail.%s\"\n    ) % (\n        dns_name,\n        \"https://docs.aws.amazon.com/console/efs/mount-dns-name\",\n        fallback_message,\n    )\n    fatal_error(message)\n\n\ndef throw_ip_address_connect_failure_with_fallback_message(\n    dns_name=None, ip_address=None, fallback_message=None\n):\n    dns_message = 'Failed to resolve \"%s\". ' % dns_name if dns_name else \"\"\n    if not ip_address:\n        ip_address_message = (\n            \"The file system mount target ip address cannot be found, please pass mount target ip \"\n            \"address via mount options. \"\n        )\n    else:\n        ip_address_message = (\n            \"Cannot connect to file system mount target ip address %s. \" % ip_address\n        )\n    fallback_message = \"\\n%s\" % fallback_message if fallback_message else \"\"\n    fatal_error(\"%s%s%s\" % (dns_message, ip_address_message, fallback_message))\n\n\ndef tls_paths_dictionary(mount_name, base_path=STATE_FILE_DIR):\n    tls_dict = {\n        \"mount_dir\": os.path.join(base_path, mount_name),\n        # every mount will have its own ca mode assets due to lack of multi-threading support in openssl\n        \"database_dir\": os.path.join(base_path, mount_name, \"database\"),\n        \"certs_dir\": os.path.join(base_path, mount_name, \"certs\"),\n        \"index\": os.path.join(base_path, mount_name, \"database/index.txt\"),\n        \"index_attr\": os.path.join(base_path, mount_name, \"database/index.txt.attr\"),\n        \"serial\": os.path.join(base_path, mount_name, \"database/serial\"),\n        \"rand\": os.path.join(base_path, mount_name, \"database/.rand\"),\n    }\n\n    return tls_dict\n\n\ndef get_public_key_sha1(public_key):\n    # truncating public key to remove the header and footer '-----(BEGIN|END) PUBLIC KEY-----'\n    with open(public_key, \"r\") as f:\n        lines = f.readlines()\n        lines = lines[1:-1]\n\n    key = \"\".join(lines)\n    key = bytearray(base64.b64decode(key))\n\n    # Parse the public key to pull out the actual key material by looking for the key BIT STRING\n    # Example:\n    #     0:d=0  hl=4 l= 418 cons: SEQUENCE\n    #     4:d=1  hl=2 l=  13 cons: SEQUENCE\n    #     6:d=2  hl=2 l=   9 prim: OBJECT            :rsaEncryption\n    #    17:d=2  hl=2 l=   0 prim: NULL\n    #    19:d=1  hl=4 l= 399 prim: BIT STRING\n    cmd = \"openssl asn1parse -inform PEM -in %s\" % public_key\n    output, err = subprocess_call(\n        cmd, \"Unable to ASN1 parse public key file, %s, correctly\" % public_key\n    )\n\n    key_line = \"\"\n    for line in output.splitlines():\n        if \"BIT STRING\" in line.decode(\"utf-8\"):\n            key_line = line.decode(\"utf-8\")\n\n    if not key_line:\n        err_msg = \"Public key file, %s, is incorrectly formatted\" % public_key\n        fatal_error(err_msg, err_msg)\n\n    key_line = key_line.replace(\" \", \"\")\n\n    # DER encoding TLV (Tag, Length, Value)\n    # - the first octet (byte) is the tag (type)\n    # - the next octets are the length - \"definite form\"\n    #   - the first octet always has the high order bit (8) set to 1\n    #   - the remaining 127 bits are used to encode the number of octets that follow\n    #   - the following octets encode, as big-endian, the length (which may be 0) as a number of octets\n    # - the remaining octets are the \"value\" aka content\n    #\n    # For a BIT STRING, the first octet of the value is used to signify the number of unused bits that exist in the last\n    # content byte. Note that this is explicitly excluded from the SubjectKeyIdentifier hash, per\n    # https://tools.ietf.org/html/rfc5280#section-4.2.1.2\n    #\n    # Example:\n    #   0382018f00...<subjectPublicKey>\n    #   - 03 - BIT STRING tag\n    #   - 82 - 2 length octets to follow (ignore high order bit)\n    #   - 018f - length of 399\n    #   - 00 - no unused bits in the last content byte\n    offset = int(key_line.split(\":\")[0])\n    key = key[offset:]\n\n    num_length_octets = key[1] & 0b01111111\n\n    # Exclude the tag (1), length (1 + num_length_octets), and number of unused bits (1)\n    offset = 1 + 1 + num_length_octets + 1\n    key = key[offset:]\n\n    sha1 = hashlib.sha1()\n    sha1.update(key)\n\n    return sha1.hexdigest()\n\n\ndef create_canonical_request(\n    public_key_hash, date, access_key, region, fs_id, session_token=None\n):\n    \"\"\"\n    Create a Canonical Request - https://docs.aws.amazon.com/general/latest/gr/sigv4-create-canonical-request.html\n    \"\"\"\n    formatted_datetime = date.strftime(SIGV4_DATETIME_FORMAT)\n    credential = quote_plus(access_key + \"/\" + get_credential_scope(date, region))\n\n    request = HTTP_REQUEST_METHOD + \"\\n\"\n    request += CANONICAL_URI + \"\\n\"\n    request += (\n        create_canonical_query_string(\n            public_key_hash, credential, formatted_datetime, session_token\n        )\n        + \"\\n\"\n    )\n    request += CANONICAL_HEADERS % fs_id + \"\\n\"\n    request += SIGNED_HEADERS + \"\\n\"\n\n    sha256 = hashlib.sha256()\n    sha256.update(REQUEST_PAYLOAD.encode())\n    request += sha256.hexdigest()\n\n    return request\n\n\ndef create_canonical_query_string(\n    public_key_hash, credential, formatted_datetime, session_token=None\n):\n    canonical_query_params = {\n        \"Action\": \"Connect\",\n        # Public key hash is included in canonical request to tie the signature to a specific key pair to avoid replay attacks\n        \"PublicKeyHash\": quote_plus(public_key_hash),\n        \"X-Amz-Algorithm\": ALGORITHM,\n        \"X-Amz-Credential\": credential,\n        \"X-Amz-Date\": quote_plus(formatted_datetime),\n        \"X-Amz-Expires\": 86400,\n        \"X-Amz-SignedHeaders\": SIGNED_HEADERS,\n    }\n\n    if session_token:\n        canonical_query_params[\"X-Amz-Security-Token\"] = quote_plus(session_token)\n\n    # Cannot use urllib.urlencode because it replaces the %s's\n    return \"&\".join(\n        [\"%s=%s\" % (k, v) for k, v in sorted(canonical_query_params.items())]\n    )\n\n\ndef create_string_to_sign(canonical_request, date, region):\n    \"\"\"\n    Create a String to Sign - https://docs.aws.amazon.com/general/latest/gr/sigv4-create-string-to-sign.html\n    \"\"\"\n    string_to_sign = ALGORITHM + \"\\n\"\n    string_to_sign += date.strftime(SIGV4_DATETIME_FORMAT) + \"\\n\"\n    string_to_sign += get_credential_scope(date, region) + \"\\n\"\n\n    sha256 = hashlib.sha256()\n    sha256.update(canonical_request.encode())\n    string_to_sign += sha256.hexdigest()\n\n    return string_to_sign\n\n\ndef calculate_signature(string_to_sign, date, secret_access_key, region):\n    \"\"\"\n    Calculate the Signature - https://docs.aws.amazon.com/general/latest/gr/sigv4-calculate-signature.html\n    \"\"\"\n\n    def _sign(key, msg):\n        return hmac.new(key, msg.encode(\"utf-8\"), hashlib.sha256)\n\n    key_date = _sign(\n        (\"AWS4\" + secret_access_key).encode(\"utf-8\"), date.strftime(DATE_ONLY_FORMAT)\n    ).digest()\n    add_region = _sign(key_date, region).digest()\n    add_service = _sign(add_region, SERVICE).digest()\n    signing_key = _sign(add_service, \"aws4_request\").digest()\n\n    return _sign(signing_key, string_to_sign).hexdigest()\n\n\ndef get_credential_scope(date, region):\n    return \"/\".join([date.strftime(DATE_ONLY_FORMAT), region, SERVICE, AWS4_REQUEST])\n\n\ndef match_device(config, device, options):\n    \"\"\"Return the EFS id, the remote path, and the az to mount\"\"\"\n\n    try:\n        remote, path = device.split(\":\", 1)\n    except ValueError:\n        remote = device\n        path = \"/\"\n\n    if FS_ID_RE.match(remote):\n        return remote, path, None\n\n    try:\n        primary, secondaries, _ = socket.gethostbyname_ex(remote)\n        hostnames = list(filter(lambda e: e is not None, [primary] + secondaries))\n    except socket.gaierror:\n        create_default_cloudwatchlog_agent_if_not_exist(config, options)\n        fatal_error(\n            'Failed to resolve \"%s\" - check that the specified DNS name is a CNAME record resolving to a valid EFS DNS '\n            \"name\" % remote,\n            'Failed to resolve \"%s\"' % remote,\n        )\n\n    if not hostnames:\n        create_default_cloudwatchlog_agent_if_not_exist(config, options)\n        fatal_error(\n            'The specified domain name \"%s\" did not resolve to an EFS mount target'\n            % remote\n        )\n\n    for hostname in hostnames:\n        efs_fqdn_match = EFS_FQDN_RE.match(hostname)\n\n        if efs_fqdn_match:\n            az = efs_fqdn_match.group(\"az\")\n            fs_id = efs_fqdn_match.group(\"fs_id\")\n\n            if az and \"az\" in options and az != options[\"az\"]:\n                fatal_error(\n                    'The hostname \"%s\" resolved by the specified domain name \"%s\" does not match the az provided in the '\n                    \"mount options, expected = %s, given = %s\"\n                    % (hostname, remote, options[\"az\"], az)\n                )\n\n            expected_dns_name, _ = get_dns_name_and_fallback_mount_target_ip_address(\n                config, fs_id, add_field_in_options(options, \"az\", az)\n            )\n\n            # check that the DNS name of the mount target matches exactly the DNS name the CNAME resolves to\n            if hostname == expected_dns_name:\n                return fs_id, path, az\n    else:\n        create_default_cloudwatchlog_agent_if_not_exist(config, options)\n        fatal_error(\n            'The specified CNAME \"%s\" did not resolve to a valid DNS name for an EFS mount target. '\n            \"Please refer to the EFS documentation for mounting with DNS names for examples: %s\"\n            % (\n                remote,\n                \"https://docs.aws.amazon.com/efs/latest/ug/mounting-fs-mount-cmd-dns-name.html\",\n            )\n        )\n\n\ndef add_field_in_options(options, field_key, field_value):\n    if field_value and field_key not in options:\n        options[field_key] = field_value\n    return options\n\n\ndef is_nfs_mount(mountpoint):\n    if not check_if_platform_is_mac():\n        cmd = [\"stat\", \"-f\", \"-L\", \"-c\", \"%T\", mountpoint]\n        p = subprocess.Popen(\n            cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, close_fds=True\n        )\n        output, _ = p.communicate()\n        return output and \"nfs\" in str(output)\n    else:\n        process = subprocess.run(\n            [\"mount\", \"-t\", \"nfs\"],\n            check=True,\n            stdout=subprocess.PIPE,\n            universal_newlines=True,\n        )\n        stdout = process.stdout\n        if not stdout:\n            return False\n        mounts = stdout.split(\"\\n\")\n        for mount in mounts:\n            _mount = mount.split()\n            if len(_mount) >= 4 and _mount[2] == mountpoint and \"nfs\" in _mount[3]:\n                return True\n        return False\n\n\ndef mount_tls(\n    config,\n    init_system,\n    dns_name,\n    path,\n    fs_id,\n    mountpoint,\n    options,\n    fallback_ip_address=None,\n):\n    if os.path.ismount(mountpoint) and is_nfs_mount(mountpoint):\n        sys.stdout.write(\n            \"%s is already mounted, please run 'mount' command to verify\\n\" % mountpoint\n        )\n        logging.warning(\"%s is already mounted, mount aborted\" % mountpoint)\n        return\n\n    with bootstrap_tls(\n        config,\n        init_system,\n        dns_name,\n        fs_id,\n        mountpoint,\n        options,\n        fallback_ip_address=fallback_ip_address,\n    ) as tunnel_proc:\n        mount_completed = threading.Event()\n        t = threading.Thread(\n            target=poll_tunnel_process, args=(tunnel_proc, fs_id, mount_completed)\n        )\n        t.daemon = True\n        t.start()\n        mount_nfs(config, dns_name, path, mountpoint, options)\n        mount_completed.set()\n        t.join()\n\n\ndef verify_tlsport_can_be_connected(tlsport):\n    try:\n        test_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM, 0)\n    except Exception as e:\n        logging.warning(\"Error opening a socket, %s\", e)\n        return False\n    try:\n        logging.debug(\"Trying to connect to 127.0.0.1: %s\", tlsport)\n        test_socket.connect((\"127.0.0.1\", tlsport))\n        return True\n    except ConnectionRefusedError:\n        return False\n    finally:\n        test_socket.close()\n\n\ndef check_unsupported_options(options):\n    for unsupported_option in UNSUPPORTED_OPTIONS:\n        if unsupported_option in options:\n            warn_message = (\n                'The \"%s\" option is not supported and has been ignored, as amazon-efs-utils relies on a built-in '\n                \"trust store.\" % unsupported_option\n            )\n            sys.stderr.write(\"WARN: %s\\n\" % warn_message)\n            logging.warning(warn_message)\n            del options[unsupported_option]\n\n\ndef check_options_validity(options):\n    if \"tls\" in options:\n        if \"port\" in options:\n            fatal_error('The \"port\" and \"tls\" options are mutually exclusive')\n\n        if \"tlsport\" in options:\n            try:\n                int(options[\"tlsport\"])\n            except ValueError:\n                fatal_error(\n                    \"tlsport option [%s] is not an integer\" % options[\"tlsport\"]\n                )\n\n        if \"ocsp\" in options and \"noocsp\" in options:\n            fatal_error('The \"ocsp\" and \"noocsp\" options are mutually exclusive')\n\n        if \"notls\" in options:\n            fatal_error('The \"tls\" and \"notls\" options are mutually exclusive')\n\n    if \"accesspoint\" in options:\n        if \"tls\" not in options:\n            fatal_error('The \"tls\" option is required when mounting via \"accesspoint\"')\n        if not AP_ID_RE.match(options[\"accesspoint\"]):\n            fatal_error(\"Access Point ID %s is malformed\" % options[\"accesspoint\"])\n\n    if \"iam\" in options and \"tls\" not in options:\n        fatal_error('The \"tls\" option is required when mounting via \"iam\"')\n\n    if \"awsprofile\" in options and \"iam\" not in options:\n        fatal_error(\n            'The \"iam\" option is required when mounting with named profile option, \"awsprofile\"'\n        )\n\n    if \"awscredsuri\" in options:\n        if \"iam\" not in options:\n            fatal_error('The \"iam\" option is required when mounting with \"awscredsuri\"')\n        if \"awsprofile\" in options:\n            fatal_error(\n                'The \"awscredsuri\" and \"awsprofile\" options are mutually exclusive'\n            )\n        # The URI must start with slash symbol as it will be appended to the ECS task metadata endpoint\n        if not options[\"awscredsuri\"].startswith(\"/\"):\n            fatal_error(\"awscredsuri %s is malformed\" % options[\"awscredsuri\"])\n\n\ndef bootstrap_cloudwatch_logging(config, options, fs_id=None):\n    if not check_if_cloudwatch_log_enabled(config):\n        return None\n\n    cloudwatchlog_client = get_botocore_client(config, \"logs\", options)\n\n    if not cloudwatchlog_client:\n        return None\n\n    cloudwatchlog_config = get_cloudwatchlog_config(config, fs_id)\n\n    log_group_name = cloudwatchlog_config.get(\"log_group_name\")\n    log_stream_name = cloudwatchlog_config.get(\"log_stream_name\")\n    retention_days = cloudwatchlog_config.get(\"retention_days\")\n\n    group_creation_completed = create_cloudwatch_log_group(\n        cloudwatchlog_client, log_group_name\n    )\n\n    if not group_creation_completed:\n        return None\n\n    put_retention_policy_completed = put_cloudwatch_log_retention_policy(\n        cloudwatchlog_client, log_group_name, retention_days\n    )\n\n    if not put_retention_policy_completed:\n        return None\n\n    stream_creation_completed = create_cloudwatch_log_stream(\n        cloudwatchlog_client, log_group_name, log_stream_name\n    )\n\n    if not stream_creation_completed:\n        return None\n\n    return {\n        \"client\": cloudwatchlog_client,\n        \"log_group_name\": log_group_name,\n        \"log_stream_name\": log_stream_name,\n    }\n\n\ndef create_default_cloudwatchlog_agent_if_not_exist(config, options):\n    if not check_if_cloudwatch_log_enabled(config):\n        return None\n    global CLOUDWATCHLOG_AGENT\n    if not CLOUDWATCHLOG_AGENT:\n        CLOUDWATCHLOG_AGENT = bootstrap_cloudwatch_logging(config, options)\n\n\ndef get_fips_config(config):\n    \"\"\"\n    Check whether FIPS is enabled either by setting the `AWS_USE_FIPS_ENDPOINT`\n    environmental variable, or through the efs-utils config file.\n\n    Enabling FIPS means that both the Botocore client and stunnel will be configured\n    to use FIPS.\n    \"\"\"\n\n    return os.getenv(\n        AWS_FIPS_ENDPOINT_CONFIG_ENV, \"False\"\n    ).lower() == \"true\" or get_boolean_config_item_value(\n        config, CONFIG_SECTION, \"fips_mode_enabled\", default_value=False\n    )\n\n\ndef get_botocore_client(config, service, options):\n    if not BOTOCORE_PRESENT:\n        logging.error(\"Failed to import botocore, please install botocore first.\")\n        return None\n\n    botocore_config = None\n    if get_fips_config(config):\n        botocore_config = botocore.config.Config(use_fips_endpoint=True)\n\n    session = botocore.session.get_session()\n    region = get_target_region(config)\n\n    if options and options.get(\"awsprofile\"):\n        profile = options.get(\"awsprofile\")\n        session.set_config_variable(\"profile\", profile)\n        try:\n            return session.create_client(\n                service, region_name=region, config=botocore_config\n            )\n        except ProfileNotFound as e:\n            fatal_error(\n                \"%s, please add the [profile %s] section in the aws config file following %s and %s.\"\n                % (e, profile, NAMED_PROFILE_HELP_URL, CONFIG_FILE_SETTINGS_HELP_URL)\n            )\n\n    return session.create_client(service, region_name=region, config=botocore_config)\n\n\ndef get_cloudwatchlog_config(config, fs_id=None):\n    log_group_name = DEFAULT_CLOUDWATCH_LOG_GROUP\n    if config.has_option(CLOUDWATCH_LOG_SECTION, \"log_group_name\"):\n        log_group_name = config.get(CLOUDWATCH_LOG_SECTION, \"log_group_name\")\n\n        if \"{fs_id}\" in log_group_name:\n            if fs_id:\n                # Formatting the log_group_name with the fs_id.\n                log_group_name = log_group_name.format(fs_id=fs_id)\n            else:\n                # If fs_id is None so putting the logs into the log-group by removing '/{fs_id}' in log_group_name.\n                log_group_name = log_group_name.replace(\"/{fs_id}\", \"\")\n                logging.warning(\n                    \"Failed to load the File System ID, pushing logs to log group %s.\",\n                    log_group_name,\n                )\n\n    logging.debug(\"Pushing logs to log group named %s in Cloudwatch.\", log_group_name)\n    retention_days = DEFAULT_RETENTION_DAYS\n    if config.has_option(CLOUDWATCH_LOG_SECTION, \"retention_in_days\"):\n        retention_days = config.get(CLOUDWATCH_LOG_SECTION, \"retention_in_days\")\n\n    log_stream_name = get_cloudwatch_log_stream_name(config, fs_id)\n\n    return {\n        \"log_group_name\": log_group_name,\n        \"retention_days\": int(retention_days),\n        \"log_stream_name\": log_stream_name,\n    }\n\n\ndef get_cloudwatch_log_stream_name(config, fs_id=None):\n    instance_id = get_instance_identity_info_from_instance_metadata(\n        config, \"instanceId\"\n    )\n    if instance_id and fs_id:\n        log_stream_name = \"%s - %s - mount.log\" % (fs_id, instance_id)\n    elif instance_id:\n        log_stream_name = \"%s - mount.log\" % (instance_id)\n    elif fs_id:\n        log_stream_name = \"%s - mount.log\" % (fs_id)\n    else:\n        log_stream_name = \"default - mount.log\"\n\n    return log_stream_name\n\n\ndef check_if_platform_is_mac():\n    return sys.platform in MAC_OS_PLATFORM_LIST\n\n\ndef check_if_mac_version_is_supported():\n    return any(\n        release in platform.release() for release in MAC_OS_SUPPORTED_VERSION_LIST\n    )\n\n\ndef check_if_cloudwatch_log_enabled(config):\n    # We don't emit warning message here as there will always no `enabled` config item even for a new config file. By default we\n    # comment out the `enabled = true` in config file so that the cloudwatch log feature is disabled. This is not set as\n    # `enabled = false` because we enable this feature by uncommenting this item for user who use System Manager Distributor\n    # to install efs-utils. This gives user an opportunity to still disable the feature by setting `enabled = false`.\n    return get_boolean_config_item_value(\n        config,\n        CLOUDWATCH_LOG_SECTION,\n        \"enabled\",\n        default_value=False,\n        emit_warning_message=False,\n    )\n\n\ndef cloudwatch_create_log_group_helper(cloudwatchlog_client, log_group_name):\n    cloudwatchlog_client.create_log_group(logGroupName=log_group_name)\n    logging.info(\"Created cloudwatch log group %s\" % log_group_name)\n\n\ndef create_cloudwatch_log_group(cloudwatchlog_client, log_group_name):\n    try:\n        cloudwatch_create_log_group_helper(cloudwatchlog_client, log_group_name)\n    except ClientError as e:\n        exception = e.response[\"Error\"][\"Code\"]\n\n        if exception == \"ResourceAlreadyExistsException\":\n            logging.debug(\n                \"Log group %s already exist, %s\" % (log_group_name, e.response)\n            )\n            return True\n        elif exception == \"LimitExceededException\":\n            logging.error(\n                \"Reached the maximum number of log groups that can be created, %s\"\n                % e.response\n            )\n            return False\n        elif exception == \"OperationAbortedException\":\n            logging.debug(\n                \"Multiple requests to update the same log group %s were in conflict, %s\"\n                % (log_group_name, e.response)\n            )\n            return False\n        elif exception == \"InvalidParameterException\":\n            logging.error(\n                \"Log group name %s is specified incorrectly, %s\"\n                % (log_group_name, e.response)\n            )\n            return False\n        else:\n            handle_general_botocore_exceptions(e)\n            return False\n    except NoCredentialsError as e:\n        logging.warning(\"Credentials are not properly configured, %s\" % e)\n        return False\n    except EndpointConnectionError as e:\n        logging.warning(\"Could not connect to the endpoint, %s\" % e)\n        return False\n    except Exception as e:\n        logging.warning(\"Unknown error, %s.\" % e)\n        return False\n    return True\n\n\ndef cloudwatch_put_retention_policy_helper(\n    cloudwatchlog_client, log_group_name, retention_days\n):\n    cloudwatchlog_client.put_retention_policy(\n        logGroupName=log_group_name, retentionInDays=retention_days\n    )\n    logging.debug(\"Set cloudwatch log group retention days to %s\" % retention_days)\n\n\ndef put_cloudwatch_log_retention_policy(\n    cloudwatchlog_client, log_group_name, retention_days\n):\n    try:\n        cloudwatch_put_retention_policy_helper(\n            cloudwatchlog_client, log_group_name, retention_days\n        )\n    except ClientError as e:\n        exception = e.response[\"Error\"][\"Code\"]\n\n        if exception == \"ResourceNotFoundException\":\n            logging.error(\n                \"Log group %s does not exist, %s\" % (log_group_name, e.response)\n            )\n            return False\n        elif exception == \"OperationAbortedException\":\n            logging.debug(\n                \"Multiple requests to update the same log group %s were in conflict, %s\"\n                % (log_group_name, e.response)\n            )\n            return False\n        elif exception == \"InvalidParameterException\":\n            logging.error(\n                \"Either parameter log group name %s or retention in days %s is specified incorrectly, %s\"\n                % (log_group_name, retention_days, e.response)\n            )\n            return False\n        else:\n            handle_general_botocore_exceptions(e)\n            return False\n    except NoCredentialsError as e:\n        logging.warning(\"Credentials are not properly configured, %s\" % e)\n        return False\n    except EndpointConnectionError as e:\n        logging.warning(\"Could not connect to the endpoint, %s\" % e)\n        return False\n    except Exception as e:\n        logging.warning(\"Unknown error, %s.\" % e)\n        return False\n    return True\n\n\ndef cloudwatch_create_log_stream_helper(\n    cloudwatchlog_client, log_group_name, log_stream_name\n):\n    cloudwatchlog_client.create_log_stream(\n        logGroupName=log_group_name, logStreamName=log_stream_name\n    )\n    logging.info(\n        \"Created cloudwatch log stream %s in log group %s\"\n        % (log_stream_name, log_group_name)\n    )\n\n\ndef create_cloudwatch_log_stream(cloudwatchlog_client, log_group_name, log_stream_name):\n    try:\n        cloudwatch_create_log_stream_helper(\n            cloudwatchlog_client, log_group_name, log_stream_name\n        )\n    except ClientError as e:\n        exception = e.response[\"Error\"][\"Code\"]\n\n        if exception == \"ResourceAlreadyExistsException\":\n            logging.debug(\n                \"Log stream %s already exist in log group %s, %s\"\n                % (log_stream_name, log_group_name, e.response)\n            )\n            return True\n        elif exception == \"InvalidParameterException\":\n            logging.error(\n                \"Either parameter log group name %s or log stream name %s is specified incorrectly, %s\"\n                % (log_group_name, log_stream_name, e.response)\n            )\n            return False\n        elif exception == \"ResourceNotFoundException\":\n            logging.error(\n                \"Log group %s does not exist, %s\" % (log_group_name, e.response)\n            )\n            return False\n        else:\n            handle_general_botocore_exceptions(e)\n            return False\n    except NoCredentialsError as e:\n        logging.warning(\"Credentials are not properly configured, %s\" % e)\n        return False\n    except EndpointConnectionError as e:\n        logging.warning(\"Could not connect to the endpoint, %s\" % e)\n        return False\n    except Exception as e:\n        logging.warning(\"Unknown error, %s.\" % e)\n        return False\n    return True\n\n\ndef cloudwatch_put_log_events_helper(cloudwatchlog_agent, message, token=None):\n    kwargs = {\n        \"logGroupName\": cloudwatchlog_agent.get(\"log_group_name\"),\n        \"logStreamName\": cloudwatchlog_agent.get(\"log_stream_name\"),\n        \"logEvents\": [\n            {\"timestamp\": int(round(time.time() * 1000)), \"message\": message}\n        ],\n    }\n    if token:\n        kwargs[\"sequenceToken\"] = token\n    cloudwatchlog_agent.get(\"client\").put_log_events(**kwargs)\n\n\ndef publish_cloudwatch_log(cloudwatchlog_agent, message):\n    if not cloudwatchlog_agent or not cloudwatchlog_agent.get(\"client\"):\n        return False\n\n    token = get_log_stream_next_token(cloudwatchlog_agent)\n\n    try:\n        cloudwatch_put_log_events_helper(cloudwatchlog_agent, message, token)\n    except ClientError as e:\n        exception = e.response[\"Error\"][\"Code\"]\n\n        if exception == \"InvalidSequenceTokenException\":\n            logging.debug(\"The sequence token is not valid, %s\" % e.response)\n            return False\n        elif exception == \"InvalidParameterException\":\n            logging.debug(\n                \"One of the parameter to put log events is not valid, %s\" % e.response\n            )\n            return False\n        elif exception == \"DataAlreadyAcceptedException\":\n            logging.debug(\"The event %s was already logged, %s\" % (message, e.response))\n            return False\n        elif exception == \"UnrecognizedClientException\":\n            logging.debug(\n                \"The most likely cause is an invalid AWS access key ID or secret Key, %s\"\n                % e.response\n            )\n            return False\n        elif exception == \"ResourceNotFoundException\":\n            logging.error(\n                \"Either log group %s or log stream %s does not exist, %s\"\n                % (\n                    cloudwatchlog_agent.get(\"log_group_name\"),\n                    cloudwatchlog_agent.get(\"log_stream_name\"),\n                    e.response,\n                )\n            )\n            return False\n        else:\n            logging.debug(\"Unexpected error: %s\" % e)\n            return False\n    except NoCredentialsError as e:\n        logging.warning(\"Credentials are not properly configured, %s\" % e)\n        return False\n    except EndpointConnectionError as e:\n        logging.warning(\"Could not connect to the endpoint, %s\" % e)\n        return False\n    except Exception as e:\n        logging.warning(\"Unknown error, %s.\" % e)\n        return False\n    return True\n\n\ndef cloudwatch_describe_log_streams_helper(cloudwatchlog_agent):\n    return cloudwatchlog_agent.get(\"client\").describe_log_streams(\n        logGroupName=cloudwatchlog_agent.get(\"log_group_name\"),\n        logStreamNamePrefix=cloudwatchlog_agent.get(\"log_stream_name\"),\n    )\n\n\ndef get_log_stream_next_token(cloudwatchlog_agent):\n    try:\n        response = cloudwatch_describe_log_streams_helper(cloudwatchlog_agent)\n    except ClientError as e:\n        exception = e.response[\"Error\"][\"Code\"]\n\n        if exception == \"InvalidParameterException\":\n            logging.debug(\n                \"Either parameter log group name %s or log stream name %s is specified incorrectly, %s\"\n                % (\n                    cloudwatchlog_agent.get(\"log_group_name\"),\n                    cloudwatchlog_agent.get(\"log_stream_name\"),\n                    e.response,\n                )\n            )\n        elif exception == \"ResourceNotFoundException\":\n            logging.debug(\n                \"Either log group %s or log stream %s does not exist, %s\"\n                % (\n                    cloudwatchlog_agent.get(\"log_group_name\"),\n                    cloudwatchlog_agent.get(\"log_stream_name\"),\n                    e.response,\n                )\n            )\n        else:\n            handle_general_botocore_exceptions(e)\n        return None\n    except NoCredentialsError as e:\n        logging.warning(\"Credentials are not properly configured, %s\" % e)\n        return None\n    except EndpointConnectionError as e:\n        logging.warning(\"Could not connect to the endpoint, %s\" % e)\n        return None\n    except Exception as e:\n        logging.warning(\"Unknown error, %s\" % e)\n        return None\n\n    try:\n        log_stream = response[\"logStreams\"][0]\n        return log_stream.get(\"uploadSequenceToken\")\n    except (IndexError, TypeError, KeyError):\n        pass\n\n    return None\n\n\ndef ec2_describe_availability_zones_helper(ec2_client, kwargs):\n    # https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/ec2.html#EC2.Client.describe_availability_zones\n    return ec2_client.describe_availability_zones(**kwargs)\n\n\ndef get_az_id_by_az_name_helper(ec2_client, az_name, dryrun=False):\n    operation = \"DescribeAvailabilityZones\"\n    kwargs = {\"ZoneNames\": [az_name]}\n    if dryrun:\n        kwargs[\"DryRun\"] = True\n\n    try:\n        az_info = ec2_describe_availability_zones_helper(ec2_client, kwargs)\n        logging.debug(\"Found the az information for %s: %s\", az_name, az_info)\n        return az_info\n    except ClientError as e:\n        exception = e.response[\"Error\"][\"Code\"]\n        exception_message = e.response[\"Error\"][\"Message\"]\n\n        if exception == \"DryRunOperation\":\n            logging.debug(\"Describe availability zones dryrun succeed.\")\n            return\n        elif exception == \"UnauthorizedOperation\":\n            fallback_message = \"Unauthorized to perform operation %s.\" % operation\n        elif exception == \"InvalidParameterValue\":\n            fallback_message = \"Invalid availability zone %s\" % az_name\n        elif exception == \"ServiceUnavailableException\":\n            fallback_message = (\n                \"The ec2 service cannot complete the request, %s\" % exception_message\n            )\n        elif exception == \"AccessDeniedException\":\n            fallback_message = exception_message\n        else:\n            fallback_message = \"Unexpected error: %s\" % exception_message\n    except NoCredentialsError as e:\n        fallback_message = (\n            \"%s when performing operation %s, please confirm your aws credentials are properly configured.\"\n            % (e, operation)\n        )\n    except EndpointConnectionError as e:\n        fallback_message = (\n            \"Could not connect to the endpoint when performing operation %s, %s\"\n            % (operation, e)\n        )\n    except Exception as e:\n        fallback_message = \"Unknown error when performing operation %s, %s.\" % (\n            operation,\n            e,\n        )\n    raise FallbackException(fallback_message)\n\n\ndef get_az_id_by_az_name(ec2_client, az_name):\n    # Perform a dryrun api call first\n    get_az_id_by_az_name_helper(ec2_client, az_name, dryrun=True)\n    az_info = get_az_id_by_az_name_helper(ec2_client, az_name, dryrun=False)\n    if az_info and az_info.get(\"AvailabilityZones\"):\n        az_id = az_info[\"AvailabilityZones\"][0][\"ZoneId\"]\n        logging.debug(\"Found AZ mapping [AZ name: %s, AZ ID: %s]\", az_name, az_id)\n        return az_id\n    return None\n\n\ndef efs_describe_mount_targets_helper(efs_client, kwargs):\n    # https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/efs.html#EFS.Client.describe_mount_targets\n    return efs_client.describe_mount_targets(**kwargs)\n\n\ndef get_mount_targets_info(efs_client, fs_id):\n    operation = \"DescribeMountTargets\"\n    kwargs = {\"FileSystemId\": fs_id}\n\n    try:\n        mount_targets_info = efs_describe_mount_targets_helper(efs_client, kwargs)\n        logging.debug(\n            \"Found these mount targets for file system %s: %s\",\n            fs_id,\n            mount_targets_info,\n        )\n        return mount_targets_info.get(\"MountTargets\")\n    except ClientError as e:\n        exception = e.response[\"Error\"][\"Code\"]\n        exception_message = e.response[\"Error\"][\"Message\"]\n\n        if exception == \"FileSystemNotFound\":\n            fallback_message = \"The file system %s is not found\" % fs_id\n        elif exception == \"ServiceUnavailableException\":\n            fallback_message = (\n                \"The elasticfilesystem service cannot complete the request, %s\"\n                % exception_message\n            )\n        elif exception == \"AccessDeniedException\":\n            fallback_message = exception_message\n        else:\n            fallback_message = \"Unexpected error: %s\" % exception_message\n    except NoCredentialsError as e:\n        fallback_message = (\n            \"%s when performing operation %s, please confirm your aws credentials are properly configured.\"\n            % (e, operation)\n        )\n    except EndpointConnectionError as e:\n        fallback_message = (\n            \"Could not connect to the endpoint when performing operation %s, %s\"\n            % (operation, e)\n        )\n    except Exception as e:\n        fallback_message = \"Unknown error when performing operation %s, %s.\" % (\n            operation,\n            e,\n        )\n\n    raise FallbackException(fallback_message)\n\n\ndef get_mount_target_in_az(efs_client, ec2_client, fs_id, az_name=None):\n    if not efs_client or not ec2_client:\n        raise FallbackException(\"Boto client cannot be null\")\n\n    mount_targets = get_mount_targets_info(efs_client, fs_id)\n    if not mount_targets:\n        message = (\n            \"Cannot find mount target for the file system %s, please create a mount target in %s.\"\n            % (fs_id, az_name if az_name else \"any availability zone.\")\n        )\n        raise FallbackException(message)\n\n    available_mount_targets = [\n        mount_target\n        for mount_target in mount_targets\n        if mount_target.get(\"LifeCycleState\") == \"available\"\n    ]\n    if not available_mount_targets:\n        message = (\n            \"No mount target created for the file system %s is in available state yet, please retry in 5 minutes.\"\n            % fs_id\n        )\n        raise FallbackException(message)\n\n    if az_name:\n        az_id = get_az_id_by_az_name(ec2_client, az_name)\n    else:\n        # If the az_name is None, which means the IMDS instance identity retrieve failed,\n        # in that case randomly pick one available mount target\n        logging.info(\n            \"No az info passed via options, randomly pick one available mount target.\"\n        )\n        return random.choice(available_mount_targets)\n\n    az_names_of_available_mount_targets = [\n        mount_target.get(\"AvailabilityZoneName\")\n        for mount_target in available_mount_targets\n    ]\n    available_mount_targets_message = (\n        \"Available mount target(s) are in az %s\" % az_names_of_available_mount_targets\n    )\n\n    if not az_id:\n        message = (\n            \"No matching az id for the az %s. Please check the az option passed. %s\"\n            % (az_name, available_mount_targets_message)\n        )\n        raise FallbackException(message)\n\n    for mount_target in mount_targets:\n        if mount_target[\"AvailabilityZoneId\"] == az_id:\n            mount_target_state = mount_target.get(\"LifeCycleState\")\n            if mount_target_state != \"available\":\n                message = \"Unknown mount target state\"\n                if mount_target_state in [\"creating\", \"updating\", \"error\"]:\n                    message = (\n                        \"Mount target in the az %s is %s, please retry in 5 minutes, or use the \"\n                        \"mount target in the other az by passing the availability zone name option. %s\"\n                        % (az_name, mount_target_state, available_mount_targets_message)\n                    )\n                elif mount_target_state in [\"deleted\", \"deleting\"]:\n                    message = (\n                        \"Mount target in the availability zone %s is %s, \"\n                        'please create a new one in %s, or use the \" \"mount target '\n                        \"in the other az by passing the availability zone name option. %s\"\n                    ) % (\n                        az_name,\n                        mount_target_state,\n                        az_name,\n                        available_mount_targets_message,\n                    )\n                raise FallbackException(message)\n            return mount_target\n\n    message = (\n        \"No matching mount target in the az %s. Please create one mount target in %s, or try the mount target in another \"\n        \"AZ by passing the availability zone name option. %s\"\n        % (az_name, az_name, available_mount_targets_message)\n    )\n    raise FallbackException(message)\n\n\ndef handle_general_botocore_exceptions(error):\n    exception = error.response[\"Error\"][\"Code\"]\n\n    if exception == \"ServiceUnavailableException\":\n        logging.debug(\"The service cannot complete the request, %s\" % error.response)\n    elif exception == \"AccessDeniedException\":\n        logging.debug(\n            \"User is not authorized to perform the action, %s\" % error.response\n        )\n    else:\n        logging.debug(\"Unexpected error: %s\" % error)\n\n\n# A change in the Linux kernel 5.4+ results a throughput regression on NFS client.\n# With patch (https://bugzilla.kernel.org/show_bug.cgi?id=204939), starting from 5.4.*,\n# Linux NFS client is using a fixed default value of 128K as read_ahead_kb.\n# Before this patch, the read_ahead_kb equation is (NFS_MAX_READAHEAD) 15 * (client configured read size).\n# Thus, with EFS recommendation of rsize (1MB) in mount option,\n# NFS client might see a throughput drop in kernel 5.4+, especially for sequential read.\n# To fix the issue, below function will modify read_ahead_kb to 15 * rsize (1MB by default) after mount.\ndef optimize_readahead_window(mountpoint, options, config):\n\n    if not should_revise_readahead(config):\n        return\n\n    fixed_readahead_kb = int(\n        DEFAULT_NFS_MAX_READAHEAD_MULTIPLIER * int(options[\"rsize\"]) / 1024\n    )\n\n    try:\n        major, minor = decode_device_number(os.stat(mountpoint).st_dev)\n        # modify read_ahead_kb in /sys/class/bdi/<bdi>/read_ahead_kb\n        # The bdi identifier is in the form of MAJOR:MINOR, which can be derived from device number\n        #\n        read_ahead_kb_config_file = NFS_READAHEAD_CONFIG_PATH_FORMAT % (major, minor)\n\n        logging.debug(\n            \"Modifying value in %s to %s.\",\n            read_ahead_kb_config_file,\n            str(fixed_readahead_kb),\n        )\n        p = subprocess.Popen(\n            \"echo %s > %s\" % (fixed_readahead_kb, read_ahead_kb_config_file),\n            shell=True,\n            stderr=subprocess.PIPE,\n            stdout=subprocess.DEVNULL,\n        )\n        _, error = p.communicate()\n        if p.returncode != 0:\n            logging.warning(\n                'Failed to modify read_ahead_kb: %s with returncode: %d, error: \"%s\".'\n                % (fixed_readahead_kb, p.returncode, error.strip())\n            )\n    except Exception as e:\n        logging.warning(\n            'Failed to modify read_ahead_kb: %s with error: \"%s\".'\n            % (fixed_readahead_kb, e)\n        )\n\n\n# https://github.com/torvalds/linux/blob/master/include/linux/kdev_t.h#L48-L49\ndef decode_device_number(device_number):\n    major = (device_number & 0xFFF00) >> 8\n    minor = (device_number & 0xFF) | ((device_number >> 12) & 0xFFF00)\n    return major, minor\n\n\n# Only modify read_ahead_kb iff\n# 1. instance platform is linux\n# 2. kernel version of instance is 5.4+\n# 3. 'optimize_readahead' is set to true in efs-utils config file\ndef should_revise_readahead(config):\n    if platform.system() != \"Linux\":\n        return False\n\n    if (\n        get_linux_kernel_version(len(NFS_READAHEAD_OPTIMIZE_LINUX_KERNEL_MIN_VERSION))\n        < NFS_READAHEAD_OPTIMIZE_LINUX_KERNEL_MIN_VERSION\n    ):\n        return False\n\n    return get_boolean_config_item_value(\n        config, CONFIG_SECTION, OPTIMIZE_READAHEAD_ITEM, default_value=False\n    )\n\n\n# Parse Linux kernel version from platform.release()\n# Failback to 0.0.0... as invalid version\n# Examples:\n#             platform.release()                Parsed version with desired_length:2\n# RHEL        3.10.0-1160.el7.x86_64            [3, 10]\n# AL2         5.4.105-48.177.amzn2.x86_64       [5, 4]\n# Ubuntu      5.4.0-1038-aws                    [5, 4]\n# OpenSUSE    5.3.18-24.37-default              [5, 3]\ndef get_linux_kernel_version(desired_length):\n    version = []\n    try:\n        version = [\n            int(v)\n            for v in platform.release().split(\"-\", 1)[0].split(\".\")[:desired_length]\n        ]\n    except ValueError:\n        logging.warning(\"Failed to retrieve linux kernel version\")\n    # filling 0 at the end\n    for i in range(len(version), desired_length):\n        version.append(0)\n    return version\n\n\ndef main():\n    parse_arguments_early_exit()\n\n    assert_root()\n\n    config = read_config()\n    bootstrap_logging(config)\n\n    if check_if_platform_is_mac() and not check_if_mac_version_is_supported():\n        fatal_error(\n            \"We do not support EFS on MacOS Kernel version \" + platform.release()\n        )\n\n    fs_id, path, mountpoint, options = parse_arguments(config)\n\n    logging.info(\"version=%s options=%s\", VERSION, options)\n\n    global CLOUDWATCHLOG_AGENT\n    CLOUDWATCHLOG_AGENT = bootstrap_cloudwatch_logging(config, options, fs_id)\n\n    check_unsupported_options(options)\n    check_options_validity(options)\n\n    init_system = get_init_system()\n    check_network_status(fs_id, init_system)\n\n    dns_name, fallback_ip_address = get_dns_name_and_fallback_mount_target_ip_address(\n        config, fs_id, options\n    )\n\n    if check_if_platform_is_mac() and \"notls\" not in options:\n        options[\"tls\"] = None\n\n    if \"tls\" in options:\n        mount_tls(\n            config,\n            init_system,\n            dns_name,\n            path,\n            fs_id,\n            mountpoint,\n            options,\n            fallback_ip_address=fallback_ip_address,\n        )\n    else:\n        mount_nfs(\n            config,\n            dns_name,\n            path,\n            mountpoint,\n            options,\n            fallback_ip_address=fallback_ip_address,\n        )\n\n\nif \"__main__\" == __name__:\n    main()\n", "#!/usr/bin/env python3\n#\n# Copyright 2017-2018 Amazon.com, Inc. and its affiliates. All Rights Reserved.\n#\n# Licensed under the MIT License. See the LICENSE accompanying this file\n# for the specific language governing permissions and limitations under\n# the License.\n#\n\nimport base64\nimport errno\nimport hashlib\nimport hmac\nimport json\nimport logging\nimport logging.handlers\nimport os\nimport platform\nimport pwd\nimport re\nimport shutil\nimport socket\nimport subprocess\nimport sys\nimport time\nfrom collections import namedtuple\nfrom contextlib import contextmanager\nfrom datetime import datetime, timedelta\nfrom logging.handlers import RotatingFileHandler\nfrom signal import SIGHUP, SIGKILL, SIGTERM\n\ntry:\n    from configparser import ConfigParser, NoOptionError, NoSectionError\nexcept ImportError:\n    import ConfigParser\n    from ConfigParser import NoOptionError, NoSectionError\n\ntry:\n    from urllib.parse import quote_plus\nexcept ImportError:\n    from urllib import quote_plus\n\ntry:\n    from urllib.error import HTTPError, URLError\n    from urllib.parse import urlencode\n    from urllib.request import Request, urlopen\nexcept ImportError:\n    from urllib import urlencode\n\n    from urllib2 import HTTPError, HTTPHandler, Request, URLError, build_opener, urlopen\n\n\nAMAZON_LINUX_2_RELEASE_ID = \"Amazon Linux release 2 (Karoo)\"\nAMAZON_LINUX_2_PRETTY_NAME = \"Amazon Linux 2\"\nAMAZON_LINUX_2_RELEASE_VERSIONS = [\n    AMAZON_LINUX_2_RELEASE_ID,\n    AMAZON_LINUX_2_PRETTY_NAME,\n]\nVERSION = \"1.34.3\"\nSERVICE = \"elasticfilesystem\"\n\nCONFIG_FILE = \"/etc/amazon/efs/efs-utils.conf\"\nCONFIG_SECTION = \"mount-watchdog\"\nMOUNT_CONFIG_SECTION = \"mount\"\nCLIENT_INFO_SECTION = \"client-info\"\nCLIENT_SOURCE_STR_LEN_LIMIT = 100\nDISABLE_FETCH_EC2_METADATA_TOKEN_ITEM = \"disable_fetch_ec2_metadata_token\"\nDEFAULT_UNKNOWN_VALUE = \"unknown\"\nDEFAULT_MACOS_VALUE = \"macos\"\n# 50ms\nDEFAULT_TIMEOUT = 0.05\n\nLOG_DIR = \"/var/log/amazon/efs\"\nLOG_FILE = \"mount-watchdog.log\"\n\nSTATE_FILE_DIR = \"/var/run/efs\"\nSTUNNEL_PID_FILE = \"stunnel.pid\"\n\nDEFAULT_NFS_PORT = \"2049\"\nPRIVATE_KEY_FILE = \"/etc/amazon/efs/privateKey.pem\"\nDEFAULT_REFRESH_SELF_SIGNED_CERT_INTERVAL_MIN = 60\nDEFAULT_STUNNEL_HEALTH_CHECK_INTERVAL_MIN = 5\nDEFAULT_STUNNEL_HEALTH_CHECK_TIMEOUT_SEC = 30\nNOT_BEFORE_MINS = 15\nNOT_AFTER_HOURS = 3\nDATE_ONLY_FORMAT = \"%Y%m%d\"\nSIGV4_DATETIME_FORMAT = \"%Y%m%dT%H%M%SZ\"\nCERT_DATETIME_FORMAT = \"%y%m%d%H%M%SZ\"\n\nAWS_CREDENTIALS_FILES = {\n    \"credentials\": os.path.expanduser(\n        os.path.join(\"~\" + pwd.getpwuid(os.getuid()).pw_name, \".aws\", \"credentials\")\n    ),\n    \"config\": os.path.expanduser(\n        os.path.join(\"~\" + pwd.getpwuid(os.getuid()).pw_name, \".aws\", \"config\")\n    ),\n}\n\nCA_CONFIG_BODY = \"\"\"dir = %s\nRANDFILE = $dir/database/.rand\n\n[ ca ]\ndefault_ca = local_ca\n\n[ local_ca ]\ndatabase = $dir/database/index.txt\nserial = $dir/database/serial\nprivate_key = %s\ncert = $dir/certificate.pem\nnew_certs_dir = $dir/certs\ndefault_md = sha256\npreserve = no\npolicy = efsPolicy\nx509_extensions = v3_ca\n\n[ efsPolicy ]\nCN = supplied\n\n[ req ]\nprompt = no\ndistinguished_name = req_distinguished_name\n\n[ req_distinguished_name ]\nCN = %s\n\n%s\n\n%s\n\n%s\n\"\"\"\n\n# SigV4 Auth\nALGORITHM = \"AWS4-HMAC-SHA256\"\nAWS4_REQUEST = \"aws4_request\"\n\nHTTP_REQUEST_METHOD = \"GET\"\nCANONICAL_URI = \"/\"\nCANONICAL_HEADERS_DICT = {\"host\": \"%s\"}\nCANONICAL_HEADERS = \"\\n\".join(\n    [\"%s:%s\" % (k, v) for k, v in sorted(CANONICAL_HEADERS_DICT.items())]\n)\nSIGNED_HEADERS = \";\".join(CANONICAL_HEADERS_DICT.keys())\nREQUEST_PAYLOAD = \"\"\n\nAP_ID_RE = re.compile(\"^fsap-[0-9a-f]{17}$\")\n\nECS_TASK_METADATA_API = \"http://169.254.170.2\"\nSTS_ENDPOINT_URL_FORMAT = \"https://sts.{}.amazonaws.com/\"\nINSTANCE_IAM_URL = \"http://169.254.169.254/latest/meta-data/iam/security-credentials/\"\nINSTANCE_METADATA_TOKEN_URL = \"http://169.254.169.254/latest/api/token\"\nSECURITY_CREDS_ECS_URI_HELP_URL = (\n    \"https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task-iam-roles.html\"\n)\nSECURITY_CREDS_WEBIDENTITY_HELP_URL = \"https://docs.aws.amazon.com/eks/latest/userguide/iam-roles-for-service-accounts.html\"\nSECURITY_CREDS_IAM_ROLE_HELP_URL = (\n    \"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/iam-roles-for-amazon-ec2.html\"\n)\nNAMED_PROFILE_HELP_URL = (\n    \"https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-profiles.html\"\n)\nCONFIG_FILE_SETTINGS_HELP_URL = (\n    \"https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-files.html\"\n    \"#cli-configure-files-settings\"\n)\n\nMount = namedtuple(\n    \"Mount\", [\"server\", \"mountpoint\", \"type\", \"options\", \"freq\", \"passno\"]\n)\n\nNFSSTAT_TIMEOUT = 5\n\n# Unmount difference time in seconds\nUNMOUNT_DIFF_TIME = 30\n\n# Default unmount count for consistency\nDEFAULT_UNMOUNT_COUNT_FOR_CONSISTENCY = 5\n\nMAC_OS_PLATFORM_LIST = [\"darwin\"]\nSYSTEM_RELEASE_PATH = \"/etc/system-release\"\nOS_RELEASE_PATH = \"/etc/os-release\"\nSTUNNEL_INSTALLATION_MESSAGE = \"Please install it following the instructions at: https://docs.aws.amazon.com/efs/latest/ug/using-amazon-efs-utils.html#upgrading-stunnel\"\n\n\ndef fatal_error(user_message, log_message=None):\n    if log_message is None:\n        log_message = user_message\n\n    sys.stderr.write(\"%s\\n\" % user_message)\n    logging.error(log_message)\n    sys.exit(1)\n\n\ndef get_aws_security_credentials(config, credentials_source, region):\n    \"\"\"\n    Lookup AWS security credentials (access key ID and secret access key). Adapted credentials provider chain from:\n    https://boto3.amazonaws.com/v1/documentation/api/latest/guide/configuration.html and\n    https://docs.aws.amazon.com/sdk-for-java/v1/developer-guide/credentials.html\n    \"\"\"\n    method, value = credentials_source.split(\":\", 1)\n\n    if method == \"credentials\":\n        return get_aws_security_credentials_from_file(\"credentials\", value)\n    elif method == \"named_profile\":\n        return get_aws_security_credentials_from_assumed_profile(value)\n    elif method == \"config\":\n        return get_aws_security_credentials_from_file(\"config\", value)\n    elif method == \"ecs\":\n        return get_aws_security_credentials_from_ecs(config, value)\n    elif method == \"webidentity\":\n        return get_aws_security_credentials_from_webidentity(\n            config, *(value.split(\",\")), region=region\n        )\n    elif method == \"metadata\":\n        return get_aws_security_credentials_from_instance_metadata(config)\n    else:\n        logging.error(\n            'Improper credentials source string \"%s\" found from mount state file',\n            credentials_source,\n        )\n        return None\n\n\ndef get_boolean_config_item_value(\n    config, config_section, config_item, default_value, emit_warning_message=False\n):\n    warning_message = None\n    if not config.has_section(config_section):\n        warning_message = (\n            \"Warning: config file does not have section %s.\" % config_section\n        )\n    elif not config.has_option(config_section, config_item):\n        warning_message = (\n            \"Warning: config file does not have %s item in section %s.\"\n            % (config_item, config_section)\n        )\n\n    if warning_message:\n        if emit_warning_message:\n            sys.stdout.write(\n                \"%s. You should be able to find a new config file in the same folder as current config file %s. \"\n                \"Consider update the new config file to latest config file. Use the default value [%s = %s].\"\n                % (warning_message, CONFIG_FILE, config_item, default_value)\n            )\n        return default_value\n    return config.getboolean(config_section, config_item)\n\n\ndef fetch_ec2_metadata_token_disabled(config):\n    return get_boolean_config_item_value(\n        config,\n        MOUNT_CONFIG_SECTION,\n        DISABLE_FETCH_EC2_METADATA_TOKEN_ITEM,\n        default_value=False,\n    )\n\n\ndef get_aws_ec2_metadata_token(timeout=DEFAULT_TIMEOUT):\n    # Normally the session token is fetched within 10ms, setting a timeout of 50ms here to abort the request\n    # and return None if the token has not returned within 50ms\n    try:\n        opener = build_opener(HTTPHandler)\n        request = Request(INSTANCE_METADATA_TOKEN_URL)\n        request.add_header(\"X-aws-ec2-metadata-token-ttl-seconds\", \"21600\")\n        request.get_method = lambda: \"PUT\"\n        try:\n            res = opener.open(request, timeout=timeout)\n            return res.read()\n        except socket.timeout:\n            exception_message = \"Timeout when getting the aws ec2 metadata token\"\n        except HTTPError as e:\n            exception_message = \"Failed to fetch token due to %s\" % e\n        except Exception as e:\n            exception_message = (\n                \"Unknown error when fetching aws ec2 metadata token, %s\" % e\n            )\n        logging.debug(exception_message)\n        return None\n    except NameError:\n        headers = {\"X-aws-ec2-metadata-token-ttl-seconds\": \"21600\"}\n        req = Request(INSTANCE_METADATA_TOKEN_URL, headers=headers, method=\"PUT\")\n        try:\n            res = urlopen(req, timeout=timeout)\n            return res.read()\n        except socket.timeout:\n            exception_message = \"Timeout when getting the aws ec2 metadata token\"\n        except HTTPError as e:\n            exception_message = \"Failed to fetch token due to %s\" % e\n        except Exception as e:\n            exception_message = (\n                \"Unknown error when fetching aws ec2 metadata token, %s\" % e\n            )\n        logging.debug(exception_message)\n        return None\n\n\ndef get_aws_security_credentials_from_file(file_name, awsprofile):\n    # attempt to lookup AWS security credentials in AWS credentials file (~/.aws/credentials) and configs file (~/.aws/config)\n    file_path = AWS_CREDENTIALS_FILES.get(file_name)\n    if file_path and os.path.exists(file_path):\n        credentials = credentials_file_helper(file_path, awsprofile)\n        if credentials[\"AccessKeyId\"]:\n            return credentials\n\n    logging.error(\n        \"AWS security credentials not found in %s under named profile [%s]\",\n        file_path,\n        awsprofile,\n    )\n    return None\n\n\ndef get_aws_security_credentials_from_assumed_profile(awsprofile):\n    credentials = botocore_credentials_helper(awsprofile)\n    if credentials[\"AccessKeyId\"]:\n        return credentials\n\n    logging.error(\n        \"AWS security credentials not found via assuming named profile [%s] using botocore\",\n        awsprofile,\n    )\n    return None\n\n\ndef botocore_credentials_helper(awsprofile):\n    credentials = {\"AccessKeyId\": None, \"SecretAccessKey\": None, \"Token\": None}\n\n    try:\n        import botocore.session\n        from botocore.exceptions import ProfileNotFound\n    except ImportError:\n        logging.error(\n            \"Named profile credentials cannot be retrieved without botocore, please install botocore first.\"\n        )\n        return credentials\n\n    session = botocore.session.get_session()\n    session.set_config_variable(\"profile\", awsprofile)\n\n    try:\n        frozen_credentials = session.get_credentials().get_frozen_credentials()\n    except ProfileNotFound as e:\n        logging.error(\n            \"%s, please add the [profile %s] section in the aws config file following %s and %s.\"\n            % (e, awsprofile, NAMED_PROFILE_HELP_URL, CONFIG_FILE_SETTINGS_HELP_URL)\n        )\n        return credentials\n\n    credentials[\"AccessKeyId\"] = frozen_credentials.access_key\n    credentials[\"SecretAccessKey\"] = frozen_credentials.secret_key\n    credentials[\"Token\"] = frozen_credentials.token\n    return credentials\n\n\ndef get_aws_security_credentials_from_ecs(config, uri):\n    # through ECS security credentials uri found in AWS_CONTAINER_CREDENTIALS_RELATIVE_URI environment variable\n    dict_keys = [\"AccessKeyId\", \"SecretAccessKey\", \"Token\"]\n    ecs_uri = ECS_TASK_METADATA_API + uri\n    ecs_unsuccessful_resp = (\n        \"Unsuccessful retrieval of AWS security credentials at %s.\" % ecs_uri\n    )\n    ecs_url_error_msg = (\n        \"Unable to reach %s to retrieve AWS security credentials. See %s for more info.\"\n        % (ecs_uri, SECURITY_CREDS_ECS_URI_HELP_URL)\n    )\n    ecs_security_dict = url_request_helper(\n        config, ecs_uri, ecs_unsuccessful_resp, ecs_url_error_msg\n    )\n\n    if ecs_security_dict and all(k in ecs_security_dict for k in dict_keys):\n        return ecs_security_dict\n\n    return None\n\n\ndef get_aws_security_credentials_from_webidentity(config, role_arn, token_file, region):\n    try:\n        with open(token_file, \"r\") as f:\n            token = f.read()\n    except Exception as e:\n        logging.error(\"Error reading token file %s: %s\", token_file, e)\n        return None\n\n    STS_ENDPOINT_URL = STS_ENDPOINT_URL_FORMAT.format(region)\n    webidentity_url = (\n        STS_ENDPOINT_URL\n        + \"?\"\n        + urlencode(\n            {\n                \"Version\": \"2011-06-15\",\n                \"Action\": \"AssumeRoleWithWebIdentity\",\n                \"RoleArn\": role_arn,\n                \"RoleSessionName\": \"efs-mount-helper\",\n                \"WebIdentityToken\": token,\n            }\n        )\n    )\n\n    unsuccessful_resp = (\n        \"Unsuccessful retrieval of AWS security credentials at %s.\" % STS_ENDPOINT_URL\n    )\n    url_error_msg = (\n        \"Unable to reach %s to retrieve AWS security credentials. See %s for more info.\"\n        % (STS_ENDPOINT_URL, SECURITY_CREDS_WEBIDENTITY_HELP_URL)\n    )\n    resp = url_request_helper(\n        config,\n        webidentity_url,\n        unsuccessful_resp,\n        url_error_msg,\n        headers={\"Accept\": \"application/json\"},\n    )\n\n    if resp:\n        creds = (\n            resp.get(\"AssumeRoleWithWebIdentityResponse\", {})\n            .get(\"AssumeRoleWithWebIdentityResult\", {})\n            .get(\"Credentials\", {})\n        )\n        if all(k in creds for k in [\"AccessKeyId\", \"SecretAccessKey\", \"SessionToken\"]):\n            return {\n                \"AccessKeyId\": creds[\"AccessKeyId\"],\n                \"SecretAccessKey\": creds[\"SecretAccessKey\"],\n                \"Token\": creds[\"SessionToken\"],\n            }\n\n    return None\n\n\ndef get_aws_security_credentials_from_instance_metadata(config):\n    # through IAM role name security credentials lookup uri (after lookup for IAM role name attached to instance)\n    dict_keys = [\"AccessKeyId\", \"SecretAccessKey\", \"Token\"]\n    iam_role_unsuccessful_resp = (\n        \"Unsuccessful retrieval of IAM role name at %s.\" % INSTANCE_IAM_URL\n    )\n    iam_role_url_error_msg = (\n        \"Unable to reach %s to retrieve IAM role name. See %s for more info.\"\n        % (INSTANCE_IAM_URL, SECURITY_CREDS_IAM_ROLE_HELP_URL)\n    )\n    iam_role_name = url_request_helper(\n        config, INSTANCE_IAM_URL, iam_role_unsuccessful_resp, iam_role_url_error_msg\n    )\n    if iam_role_name:\n        security_creds_lookup_url = INSTANCE_IAM_URL + iam_role_name\n        unsuccessful_resp = (\n            \"Unsuccessful retrieval of AWS security credentials at %s.\"\n            % security_creds_lookup_url\n        )\n        url_error_msg = (\n            \"Unable to reach %s to retrieve AWS security credentials. See %s for more info.\"\n            % (security_creds_lookup_url, SECURITY_CREDS_IAM_ROLE_HELP_URL)\n        )\n        iam_security_dict = url_request_helper(\n            config, security_creds_lookup_url, unsuccessful_resp, url_error_msg\n        )\n\n        if iam_security_dict and all(k in iam_security_dict for k in dict_keys):\n            return iam_security_dict\n\n    return None\n\n\ndef credentials_file_helper(file_path, awsprofile):\n    aws_credentials_configs = read_config(file_path)\n    credentials = {\"AccessKeyId\": None, \"SecretAccessKey\": None, \"Token\": None}\n\n    try:\n        aws_access_key_id = aws_credentials_configs.get(awsprofile, \"aws_access_key_id\")\n        secret_access_key = aws_credentials_configs.get(\n            awsprofile, \"aws_secret_access_key\"\n        )\n        session_token = aws_credentials_configs.get(awsprofile, \"aws_session_token\")\n\n        credentials[\"AccessKeyId\"] = aws_access_key_id\n        credentials[\"SecretAccessKey\"] = secret_access_key\n        credentials[\"Token\"] = session_token\n    except NoOptionError as e:\n        if \"aws_access_key_id\" in str(e) or \"aws_secret_access_key\" in str(e):\n            logging.debug(\n                \"aws_access_key_id or aws_secret_access_key not found in %s under named profile [%s]\",\n                file_path,\n                awsprofile,\n            )\n        if \"aws_session_token\" in str(e):\n            logging.debug(\"aws_session_token not found in %s\", file_path)\n            credentials[\"AccessKeyId\"] = aws_credentials_configs.get(\n                awsprofile, \"aws_access_key_id\"\n            )\n            credentials[\"SecretAccessKey\"] = aws_credentials_configs.get(\n                awsprofile, \"aws_secret_access_key\"\n            )\n    except NoSectionError:\n        logging.debug(\"No [%s] section found in config file %s\", awsprofile, file_path)\n\n    return credentials\n\n\ndef is_instance_metadata_url(url):\n    return url.startswith(\"http://169.254.169.254\")\n\n\ndef url_request_helper(config, url, unsuccessful_resp, url_error_msg, headers={}):\n    try:\n        req = Request(url)\n        for k, v in headers.items():\n            req.add_header(k, v)\n\n        if not fetch_ec2_metadata_token_disabled(config) and is_instance_metadata_url(\n            url\n        ):\n            # https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/configuring-instance-metadata-service.html\n            # IMDSv1 is a request/response method to access instance metadata\n            # IMDSv2 is a session-oriented method to access instance metadata\n            # We expect the token retrieve will fail in bridge networking environment (e.g. container) since the default hop\n            # limit for getting the token is 1. If the token retrieve does timeout, we fallback to use IMDSv1 instead\n            token = get_aws_ec2_metadata_token()\n            if token:\n                req.add_header(\"X-aws-ec2-metadata-token\", token)\n\n        request_resp = urlopen(req, timeout=1)\n\n        return get_resp_obj(request_resp, url, unsuccessful_resp)\n    except socket.timeout:\n        err_msg = \"Request timeout\"\n    except HTTPError as e:\n        # For instance enable with IMDSv2 and fetch token disabled, Unauthorized 401 error will be thrown\n        if (\n            e.code == 401\n            and fetch_ec2_metadata_token_disabled(config)\n            and is_instance_metadata_url(url)\n        ):\n            logging.warning(\n                \"Unauthorized request to instance metadata url %s, IMDSv2 is enabled on the instance, while fetching \"\n                \"ec2 metadata token is disabled. Please set the value of config item \"\n                '\"%s\" to \"false\" in config file %s.'\n                % (url, DISABLE_FETCH_EC2_METADATA_TOKEN_ITEM, CONFIG_FILE)\n            )\n        err_msg = \"Unable to reach the url at %s: status=%d, reason is %s\" % (\n            url,\n            e.code,\n            e.reason,\n        )\n    except URLError as e:\n        err_msg = \"Unable to reach the url at %s, reason is %s\" % (url, e.reason)\n\n    if err_msg:\n        logging.debug(\"%s %s\", url_error_msg, err_msg)\n    return None\n\n\ndef get_resp_obj(request_resp, url, unsuccessful_resp):\n    if request_resp.getcode() != 200:\n        logging.debug(\n            unsuccessful_resp + \" %s: ResponseCode=%d\", url, request_resp.getcode()\n        )\n        return None\n\n    resp_body = request_resp.read()\n    resp_body_type = type(resp_body)\n    try:\n        if resp_body_type is str:\n            resp_dict = json.loads(resp_body)\n        else:\n            resp_dict = json.loads(\n                resp_body.decode(\n                    request_resp.headers.get_content_charset() or \"us-ascii\"\n                )\n            )\n\n        return resp_dict\n    except ValueError:\n        return resp_body if resp_body_type is str else resp_body.decode(\"utf-8\")\n\n\ndef bootstrap_logging(config, log_dir=LOG_DIR):\n    raw_level = config.get(CONFIG_SECTION, \"logging_level\")\n    levels = {\n        \"debug\": logging.DEBUG,\n        \"info\": logging.INFO,\n        \"warning\": logging.WARNING,\n        \"error\": logging.ERROR,\n        \"critical\": logging.CRITICAL,\n    }\n    level = levels.get(raw_level.lower())\n    level_error = False\n\n    if not level:\n        # delay logging error about malformed log level until after logging is configured\n        level_error = True\n        level = logging.INFO\n\n    max_bytes = config.getint(CONFIG_SECTION, \"logging_max_bytes\")\n    file_count = config.getint(CONFIG_SECTION, \"logging_file_count\")\n\n    handler = RotatingFileHandler(\n        os.path.join(log_dir, LOG_FILE), maxBytes=max_bytes, backupCount=file_count\n    )\n    handler.setFormatter(\n        logging.Formatter(\n            fmt=\"%(asctime)s - %(levelname)s - %(message)s\",\n            datefmt=\"%Y-%m-%d %H:%M:%S %Z\",\n        )\n    )\n\n    logger = logging.getLogger()\n    logger.setLevel(level)\n    logger.addHandler(handler)\n\n    if level_error:\n        logging.error(\n            'Malformed logging level \"%s\", setting logging level to %s',\n            raw_level,\n            level,\n        )\n\n\ndef parse_options(options):\n    opts = {}\n    for o in options.split(\",\"):\n        if \"=\" in o:\n            k, v = o.split(\"=\")\n            opts[k] = v\n        else:\n            opts[o] = None\n    return opts\n\n\ndef get_file_safe_mountpoint(mount):\n    mountpoint = os.path.abspath(mount.mountpoint).replace(os.sep, \".\")\n    if mountpoint.startswith(\".\"):\n        mountpoint = mountpoint[1:]\n\n    opts = parse_options(mount.options)\n    if \"port\" not in opts:\n        if not check_if_running_on_macos():\n            # /proc/mounts provides a list of all mounts in use by the system (including the mount options used).\n            # In the case of tls mount: stunnel establishes a localhost port connection in order to listen on the requests,\n            # and then send packets further to the server:2049. If the port is 2049 which is the default nfs port,\n            # /proc/mounts will not display the port number in the options information, thus watchdog process will not treat\n            # the mount as EFS mount and won't restart the killed stunnel which cause the mount hang.\n            # So, tlsport=2049 is being added here by appending with the mountpoint.\n            # Putting a default port 2049 to fix the Stunnel process being killed issue.\n            opts[\"port\"] = DEFAULT_NFS_PORT\n        # some other localhost nfs mount not running over stunnel.\n        # For MacOS, we ignore the port if the port is missing in mount options.\n        else:\n            return mountpoint\n    return mountpoint + \".\" + opts[\"port\"]\n\n\ndef get_current_local_nfs_mounts(mount_file=\"/proc/mounts\"):\n    \"\"\"\n    Return a dict of the current NFS mounts for servers running on localhost, keyed by the mountpoint and port as it\n    appears in EFS watchdog state files.\n    \"\"\"\n    mounts = []\n\n    if not check_if_running_on_macos():\n        with open(mount_file) as f:\n            for mount in f:\n                mounts.append(Mount._make(mount.strip().split()))\n    else:\n        # stat command on MacOS does not have '--file-system' option to verify the filesystem type of a mount point,\n        # traverse all the mounts, and find if current mount point is already mounted\n        process = subprocess.run(\n            [\"mount\", \"-t\", \"nfs\"],\n            check=True,\n            stdout=subprocess.PIPE,\n            universal_newlines=True,\n        )\n        stdout = process.stdout\n        if stdout:\n            output = stdout.split(\"\\n\")\n            for mount in output:\n                _mount = mount.split()\n                if len(_mount) >= 4:\n                    mount_ops = get_nfs_mount_options_on_macos(_mount[2], _mount[0])\n                    # Sample output: 127.0.0.1:/ on /Users/ec2-user/efs (nfs)\n                    mounts.append(\n                        Mount._make(\n                            [\n                                _mount[0],\n                                _mount[2],\n                                _mount[3],\n                                mount_ops if mount_ops else \"\",\n                                0,\n                                0,\n                            ]\n                        )\n                    )\n        else:\n            logging.warning(\"No nfs mounts found\")\n\n    mounts = [m for m in mounts if m.server.startswith(\"127.0.0.1\") and \"nfs\" in m.type]\n\n    mount_dict = {}\n    for m in mounts:\n        safe_mnt = get_file_safe_mountpoint(m)\n        if safe_mnt:\n            mount_dict[safe_mnt] = m\n\n    return mount_dict\n\n\ndef get_nfs_mount_options_on_macos(mount_point, mount_server=\"127.0.0.1:/\"):\n\n    if not mount_point:\n        logging.warning(\"Unable to get local mount options with empty mount point\")\n        return None\n\n    try:\n        process = subprocess.run(\n            [\"nfsstat\", \"-f\", \"JSON\", \"-m\", mount_point],\n            check=True,\n            stdout=subprocess.PIPE,\n            universal_newlines=True,\n            timeout=NFSSTAT_TIMEOUT,\n        )\n        stdout = process.stdout\n        if not stdout:\n            logging.warning(\n                \"Unable to get local mount options with mount point: %s\", mount_point\n            )\n            return None\n        try:\n            state_json = json.loads(stdout)\n        except ValueError:\n            logging.exception(\"Unable to parse json of %s\", stdout)\n            return None\n        try:\n            return \",\".join(\n                state_json.get(mount_server)\n                .get(\"Original mount options\")\n                .get(\"NFS parameters\")\n            )\n        except AttributeError:\n            logging.exception(\"Unable to get object in %s\", state_json)\n            return None\n    except subprocess.TimeoutExpired:\n        logging.warning(\n            \"Fetching nfs mount parameters timed out for mount point %s. Ignoring port option.\",\n            mount_point,\n        )\n        return None\n\n\ndef get_state_files(state_file_dir):\n    \"\"\"\n    Return a dict of the absolute path of state files in state_file_dir,\n    keyed by the mountpoint and port portion of the filename.\n    \"\"\"\n    state_files = {}\n\n    if os.path.isdir(state_file_dir):\n        for sf in os.listdir(state_file_dir):\n            if not sf.startswith(\"fs-\") or os.path.isdir(\n                os.path.join(state_file_dir, sf)\n            ):\n                continue\n\n            # This translates the state file name \"fs-deadbeaf.home.user.mnt.12345\"\n            # into file-safe mountpoint \"home.user.mnt.12345\"\n            first_period = sf.find(\".\")\n            mount_point_and_port = sf[first_period + 1 :]\n            logging.debug(\n                'Translating \"%s\" into mount point and port \"%s\"',\n                sf,\n                mount_point_and_port,\n            )\n            state_files[mount_point_and_port] = sf\n\n    return state_files\n\n\ndef get_pid_in_state_dir(state_file, state_file_dir):\n    \"\"\"\n    :param state_file: The state file path, e.g. fs-deadbeef.mnt.20560.\n    :param state_file_dir: The state file dir path, e.g. /var/run/efs.\n    \"\"\"\n    state_dir_pid_path = os.path.join(\n        state_file_dir, state_file + \"+\", STUNNEL_PID_FILE\n    )\n    if os.path.exists(state_dir_pid_path):\n        with open(state_dir_pid_path) as f:\n            return f.read()\n    return None\n\n\ndef is_mount_stunnel_proc_running(state_pid, state_file, state_file_dir):\n    \"\"\"\n    Check whether a given stunnel process id in state file is running for the mount. To avoid we incorrectly checking\n    processes running by other applications and send signal further, the stunnel process in state file is counted as\n    running iff:\n    1. The pid in state file is not None.\n    2. The process running with the pid is a stunnel process. This is validated through process command name.\n    3. The process can be reached via os.kill(pid, 0).\n    4. Every launched stunnel process will write its process id to the pid file in the mount state_file_dir, and only\n       when the stunnel is terminated this pid file can be removed. Check whether the stunnel pid file exists and its\n       value is equal to the pid documented in state file. This step is to make sure we don't send signal later to any\n       stunnel process that is not owned by the mount.\n\n    :param state_pid: The pid in state file.\n    :param state_file: The state file path, e.g. fs-deadbeef.mnt.20560.\n    :param state_file_dir: The state file dir path, e.g. /var/run/efs.\n    \"\"\"\n    if not state_pid:\n        logging.debug(\"State pid is None for %s\", state_file)\n        return False\n\n    process_name = check_process_name(state_pid)\n    if not process_name or \"stunnel\" not in str(process_name):\n        logging.debug(\n            \"Process running on %s is not a stunnel process, full command: %s.\",\n            state_pid,\n            str(process_name) if process_name else \"\",\n        )\n        return False\n\n    if not is_pid_running(state_pid):\n        logging.debug(\n            \"Stunnel process with pid %s is not running anymore for %s.\",\n            state_pid,\n            state_file,\n        )\n        return False\n\n    pid_in_stunnel_pid_file = get_pid_in_state_dir(state_file, state_file_dir)\n    # efs-utils versions older than 1.32.2 does not create a pid file in state dir\n    # To avoid the healthy stunnel established by those version to be treated as not running due to the missing pid file, which can result in stunnel being constantly restarted,\n    # assuming the stunnel is still running even if the stunnel pid file does not exist.\n    if not pid_in_stunnel_pid_file:\n        logging.debug(\n            \"Pid file of stunnel does not exist for %s. It is possible that the stunnel is no longer running or the mount was mounted using an older version efs-utils (<1.32.2). Assuming the stunnel with pid %s is still running.\",\n            state_file,\n            state_pid,\n        )\n\n    elif int(state_pid) != int(pid_in_stunnel_pid_file):\n        logging.warning(\n            \"Stunnel pid mismatch in state file (pid = %s) and stunnel pid file (pid = %s). Assuming the \"\n            \"stunnel is not running.\",\n            int(state_pid),\n            int(pid_in_stunnel_pid_file),\n        )\n        return False\n\n    logging.debug(\"TLS tunnel for %s is running with pid %s\", state_file, state_pid)\n    return True\n\n\ndef is_pid_running(pid):\n    if not pid:\n        return False\n    try:\n        os.kill(pid, 0)\n        return True\n    except OSError:\n        return False\n\n\ndef check_if_platform_is_mac():\n    return sys.platform in MAC_OS_PLATFORM_LIST\n\n\ndef get_system_release_version():\n    # MacOS does not maintain paths /etc/os-release and /etc/sys-release\n    if check_if_platform_is_mac():\n        return platform.platform()\n\n    try:\n        with open(SYSTEM_RELEASE_PATH) as f:\n            return f.read().strip()\n    except IOError:\n        logging.debug(\"Unable to read %s\", SYSTEM_RELEASE_PATH)\n\n    try:\n        with open(OS_RELEASE_PATH) as f:\n            for line in f:\n                if \"PRETTY_NAME\" in line:\n                    return line.split(\"=\")[1].strip()\n    except IOError:\n        logging.debug(\"Unable to read %s\", OS_RELEASE_PATH)\n\n    return DEFAULT_UNKNOWN_VALUE\n\n\ndef find_command_path(command, install_method):\n    # If not running on macOS, use linux paths\n    if not check_if_platform_is_mac():\n        env_path = (\n            \"/sbin:/usr/sbin:/usr/local/sbin:/root/bin:/usr/local/bin:/usr/bin:/bin\"\n        )\n    # Homebrew on x86 macOS uses /usr/local/bin; Homebrew on Apple Silicon macOS uses /opt/homebrew/bin since v3.0.0\n    # For more information, see https://brew.sh/2021/02/05/homebrew-3.0.0/\n    else:\n        env_path = \"/opt/homebrew/bin:/usr/local/bin\"\n    os.putenv(\"PATH\", env_path)\n\n    try:\n        path = subprocess.check_output([\"which\", command])\n        return path.strip().decode()\n    except subprocess.CalledProcessError as e:\n        fatal_error(\n            \"Failed to locate %s in %s - %s\" % (command, env_path, install_method), e\n        )\n\n\n# In ECS amazon linux 2, we start stunnel using `nsenter` which will run as a subprocess of bash, utilizes the `setns`\n# system call to join an existing namespace and then executes the specified program using `exec`. Any exception won't\n# be caught properly by subprocess.\n# As a precaution on ECS AL2 that stunnel bin is removed after installing new efs-utils, and watchdog cannot launch\n# stunnel for previous old mount, we do a replacement of stunnel path in the command to the stunnel5 path.\n#\ndef update_stunnel_command_for_ecs_amazon_linux_2(\n    command, state, state_file_dir, state_file\n):\n    if (\n        \"nsenter\" in command\n        and \"stunnel5\" not in \" \".join(command)\n        and get_system_release_version() in AMAZON_LINUX_2_RELEASE_VERSIONS\n    ):\n        for i in range(len(command)):\n            if \"stunnel\" in command[i] and \"stunnel-config\" not in command[i]:\n                command[i] = find_command_path(\"stunnel5\", STUNNEL_INSTALLATION_MESSAGE)\n                break\n        logging.info(\n            \"Rewriting %s with new stunnel cmd: %s for ECS Amazon Linux 2 platform.\",\n            state_file,\n            \" \".join(state[\"cmd\"]),\n        )\n        rewrite_state_file(state, state_file_dir, state_file)\n    return command\n\n\ndef start_tls_tunnel(child_procs, state, state_file_dir, state_file):\n    # launch the tunnel in a process group so if it has any child processes, they can be killed easily\n    command = state[\"cmd\"]\n    logging.info('Starting TLS tunnel: \"%s\"', \" \".join(command))\n\n    command = update_stunnel_command_for_ecs_amazon_linux_2(\n        command, state, state_file_dir, state_file\n    )\n    tunnel = None\n    try:\n        tunnel = subprocess.Popen(\n            command,\n            stdout=subprocess.DEVNULL,\n            stderr=subprocess.DEVNULL,\n            preexec_fn=os.setsid,\n            close_fds=True,\n        )\n    except FileNotFoundError as e:\n        logging.warning(\"Watchdog failed to start stunnel due to %s\", e)\n\n        # https://github.com/kubernetes-sigs/aws-efs-csi-driver/issues/812 It is possible that the stunnel is not\n        # present anymore and replaced by stunnel5 on AL2, meanwhile watchdog is attempting to restart stunnel for\n        # mount using old efs-utils based on old state file generated during previous mount, which has stale command\n        # using stunnel bin. Update the state file if the stunnel does not exist anymore, and use stunnel5 on Al2.\n        #\n        if get_system_release_version() in AMAZON_LINUX_2_RELEASE_VERSIONS:\n            for i in range(len(command)):\n                if \"stunnel\" in command[i] and \"stunnel-config\" not in command[i]:\n                    command[i] = find_command_path(\n                        \"stunnel5\", STUNNEL_INSTALLATION_MESSAGE\n                    )\n                    break\n\n            tunnel = subprocess.Popen(\n                command,\n                stdout=subprocess.DEVNULL,\n                stderr=subprocess.DEVNULL,\n                preexec_fn=os.setsid,\n                close_fds=True,\n            )\n\n            state[\"cmd\"] = command\n            logging.info(\n                \"Rewriting %s with new stunnel cmd: %s for Amazon Linux 2 platform.\",\n                state_file,\n                \" \".join(state[\"cmd\"]),\n            )\n            rewrite_state_file(state, state_file_dir, state_file)\n\n    if tunnel is None or not is_pid_running(tunnel.pid):\n        fatal_error(\n            \"Failed to initialize TLS tunnel for %s\" % state_file,\n            \"Failed to start TLS tunnel.\",\n        )\n\n    logging.info(\"Started TLS tunnel, pid: %d\", tunnel.pid)\n\n    child_procs.append(tunnel)\n    return tunnel.pid\n\n\ndef clean_up_mount_state(state_file_dir, state_file, pid, mount_state_dir=None):\n    send_signal_to_running_stunnel_process_group(\n        pid, state_file, state_file_dir, SIGTERM\n    )\n    cleanup_mount_state_if_stunnel_not_running(\n        pid, state_file, state_file_dir, mount_state_dir\n    )\n\n\ndef cleanup_mount_state_if_stunnel_not_running(\n    pid, state_file, state_file_dir, mount_state_dir\n):\n    if is_mount_stunnel_proc_running(pid, state_file, state_file_dir):\n        logging.info(\"TLS tunnel: %d is still running, will retry termination\", pid)\n    else:\n        if not pid:\n            logging.info(\"TLS tunnel has been killed, cleaning up state\")\n        else:\n            logging.info(\"TLS tunnel: %d is no longer running, cleaning up state\", pid)\n        state_file_path = os.path.join(state_file_dir, state_file)\n        with open(state_file_path) as f:\n            state = json.load(f)\n\n        for f in state.get(\"files\", list()):\n            logging.debug(\"Deleting %s\", f)\n            try:\n                os.remove(f)\n                logging.debug(\"Deleted %s\", f)\n            except OSError as e:\n                if e.errno != errno.ENOENT:\n                    raise\n\n        os.remove(state_file_path)\n\n        if mount_state_dir is not None:\n            mount_state_dir_abs_path = os.path.join(state_file_dir, mount_state_dir)\n            if os.path.isdir(mount_state_dir_abs_path):\n                shutil.rmtree(mount_state_dir_abs_path)\n            else:\n                logging.debug(\n                    \"Attempt to remove mount state directory %s failed. Directory is not present.\",\n                    mount_state_dir_abs_path,\n                )\n\n\ndef rewrite_state_file(state, state_file_dir, state_file):\n    tmp_state_file = os.path.join(state_file_dir, \"~%s\" % state_file)\n    with open(tmp_state_file, \"w\") as f:\n        json.dump(state, f)\n\n    os.rename(tmp_state_file, os.path.join(state_file_dir, state_file))\n\n\ndef mark_as_unmounted(state, state_file_dir, state_file, current_time):\n    logging.debug(\"Marking %s as unmounted at %d\", state_file, current_time)\n    state[\"unmount_time\"] = current_time\n\n    rewrite_state_file(state, state_file_dir, state_file)\n\n    return state\n\n\ndef restart_tls_tunnel(child_procs, state, state_file_dir, state_file):\n    if \"certificate\" in state and not os.path.exists(state[\"certificate\"]):\n        logging.error(\n            \"Cannot restart stunnel because self-signed certificate at %s is missing\"\n            % state[\"certificate\"]\n        )\n        return\n\n    new_tunnel_pid = start_tls_tunnel(child_procs, state, state_file_dir, state_file)\n    state[\"pid\"] = new_tunnel_pid\n\n    logging.debug(\"Rewriting %s with new pid: %d\", state_file, new_tunnel_pid)\n    rewrite_state_file(state, state_file_dir, state_file)\n\n\ndef check_efs_mounts(\n    config,\n    child_procs,\n    unmount_grace_period_sec,\n    unmount_count_for_consistency,\n    state_file_dir=STATE_FILE_DIR,\n):\n    nfs_mounts = get_current_local_nfs_mounts()\n    logging.debug(\"Current local NFS mounts: %s\", list(nfs_mounts.values()))\n\n    state_files = get_state_files(state_file_dir)\n    logging.debug(\n        'Current state files in \"%s\": %s', state_file_dir, list(state_files.values())\n    )\n\n    for mount, state_file in state_files.items():\n        state_file_path = os.path.join(state_file_dir, state_file)\n        with open(state_file_path) as f:\n            try:\n                state = json.load(f)\n            except ValueError:\n                logging.exception(\"Unable to parse json in %s\", state_file_path)\n                continue\n\n        current_time = time.time()\n        if \"unmount_time\" in state:\n            if state[\"unmount_time\"] + unmount_grace_period_sec < current_time:\n                logging.info(\"Unmount grace period expired for %s\", state_file)\n                clean_up_mount_state(\n                    state_file_dir,\n                    state_file,\n                    state.get(\"pid\"),\n                    state.get(\"mountStateDir\"),\n                )\n        # For MacOS, if we don't have port from previous system call (nfsstat -F JSON -m mount_point), we ignore the port\n        elif mount not in nfs_mounts and (\n            not check_if_running_on_macos()\n            or mount[: mount.rindex(\".\")] not in nfs_mounts\n        ):\n            # Wait 30 seconds before deciding mount no longer exists to prevent race condition\n            # of watchdog's reads of nfs mounts and state files.\n            if current_time - state.get(\"mount_time\", 0) > UNMOUNT_DIFF_TIME:\n                # Ensure we have consistent unmount reads for at least 5 times by default.\n                if state.get(\"unmount_count\", 0) > unmount_count_for_consistency:\n                    logging.info('No mount found for \"%s\"', state_file)\n                    state = mark_as_unmounted(\n                        state, state_file_dir, state_file, current_time\n                    )\n                else:\n                    state[\"unmount_count\"] = state.get(\"unmount_count\", 0) + 1\n                    rewrite_state_file(state, state_file_dir, state_file)\n\n        else:\n            # Set unmount count to 0 if there were inconsistent reads\n            state[\"unmount_count\"] = 0\n            rewrite_state_file(state, state_file_dir, state_file)\n            if \"certificate\" in state:\n                check_certificate(config, state, state_file_dir, state_file)\n\n            if is_mount_stunnel_proc_running(\n                state.get(\"pid\"), state_file, state_file_dir\n            ):\n                # https://github.com/kubernetes-sigs/aws-efs-csi-driver/issues/616 We have seen EFS hanging issue caused\n                # by stuck stunnel (version: 4.56) process. Apart from checking whether stunnel is running or not, we\n                # need to check whether the stunnel connection established is healthy periodically.\n                #\n                # The way to check the stunnel health is by `df` the mountpoint, i.e. check the file system information,\n                # which will trigger a remote GETATTR on the root of the file system. Normally the command will finish\n                # in 10 milliseconds, thus if the command hang for certain period (defined as 30 sec as of now), the\n                # stunnel connection is likely to be unhealthy. Watchdog will kill the old stunnel process and restart\n                # a new one for the unhealthy mount. The health check will run every 5 min since mount.\n                #\n                # Both the command hang timeout and health check interval are configurable in efs-utils config file.\n                #\n                check_stunnel_health(\n                    config, state, state_file_dir, state_file, child_procs, nfs_mounts\n                )\n            else:\n                logging.warning(\"TLS tunnel for %s is not running\", state_file)\n                restart_tls_tunnel(child_procs, state, state_file_dir, state_file)\n\n\ndef check_stunnel_health(\n    config, state, state_file_dir, state_file, child_procs, nfs_mounts\n):\n    if not get_boolean_config_item_value(\n        config, CONFIG_SECTION, \"stunnel_health_check_enabled\", default_value=True\n    ):\n        return\n\n    check_interval_min = get_int_value_from_config_file(\n        config,\n        \"stunnel_health_check_interval_min\",\n        DEFAULT_STUNNEL_HEALTH_CHECK_INTERVAL_MIN,\n    )\n\n    current_time = time.time()\n\n    # The mount_time info in the state file is added in version 1.31.3. It is possible for existing mounts, there are\n    # no mount_time in state file, which will cause watchdog to crash. If the information does not exist, we just take\n    # current time as the initial mount time of the mount.\n    #\n    if \"mount_time\" not in state:\n        state[\"mount_time\"] = current_time\n        rewrite_state_file(state, state_file_dir, state_file)\n        return\n\n    # Only start to perform the stunnel health check after the check interval passed.\n    if current_time - state[\"mount_time\"] < check_interval_min * 60:\n        return\n\n    last_stunnel_check_time = (\n        state[\"last_stunnel_check_time\"] if \"last_stunnel_check_time\" in state else 0\n    )\n    if (\n        last_stunnel_check_time != 0\n        and current_time - last_stunnel_check_time < check_interval_min * 60\n    ):\n        return\n\n    # We add this mountpoint info in the state file along with this change. It is possible for existing mounts, there\n    # are no mountpoint in state file, which will cause watchdog to crash. To handle that case, we need to extract the\n    # mountpoint from the state file name, and write that information to state file.\n    #\n    if \"mountpoint\" in state:\n        mountpoint = state[\"mountpoint\"]\n    else:\n        mountpoint = get_mountpoint_from_nfs_mounts(state_file, nfs_mounts)\n        state[\"mountpoint\"] = mountpoint\n        rewrite_state_file(state, state_file_dir, state_file)\n\n    stunnel_pid = state[\"pid\"]\n    process = subprocess.Popen(\n        [\"df\", mountpoint],\n        stdout=subprocess.DEVNULL,\n        stderr=subprocess.DEVNULL,\n        close_fds=True,\n    )\n\n    command_timeout_sec = get_int_value_from_config_file(\n        config,\n        \"stunnel_health_check_command_timeout_sec\",\n        DEFAULT_STUNNEL_HEALTH_CHECK_TIMEOUT_SEC,\n    )\n    try:\n        state[\"last_stunnel_check_time\"] = current_time\n        process.communicate(timeout=command_timeout_sec)\n        logging.debug(\n            \"Stunnel [PID: %d] running for tls mount on %s passed health check.\",\n            stunnel_pid,\n            mountpoint,\n        )\n        rewrite_state_file(state, state_file_dir, state_file)\n    except subprocess.TimeoutExpired:\n        if send_signal_to_running_stunnel_process_group(\n            stunnel_pid, state_file, state_file_dir, SIGKILL\n        ):\n            logging.warning(\n                \"Connection timeout for %s after %d sec, SIGKILL has been sent to the potential unhealthy stunnel %s, \"\n                \"restarting a new stunnel process.\",\n                mountpoint,\n                command_timeout_sec,\n                stunnel_pid,\n            )\n            restart_tls_tunnel(child_procs, state, state_file_dir, state_file)\n        else:\n            logging.warning(\n                \"Stunnel health check timed out for %s, stunnel [PID: %d] is not running anymore.\",\n                mountpoint,\n                stunnel_pid,\n            )\n        # The child process is not killed if the timeout expires, so in order to cleanup properly, kill the child\n        # process after the timeout.\n        #\n        process.kill()\n\n\n# Retrieve the nfs mountpoint with the port information in the mount option\ndef get_mountpoint_from_nfs_mounts(state_file, nfs_mounts):\n    search_pattern = \"port={port}\".format(\n        port=os.path.basename(state_file).split(\".\")[-1]\n    )\n    for mount in nfs_mounts.values():\n        if search_pattern in mount[3]:\n            return mount[1]\n\n\ndef get_int_value_from_config_file(config, config_name, default_config_value):\n    val = default_config_value\n    try:\n        value_from_config = config.get(CONFIG_SECTION, config_name)\n        try:\n            if int(value_from_config) > 0:\n                val = int(value_from_config)\n            else:\n                logging.debug(\n                    '%s value in config file \"%s\" is lower than 1. Defaulting to %d.',\n                    config_name,\n                    CONFIG_FILE,\n                    default_config_value,\n                )\n        except ValueError:\n            logging.debug(\n                'Bad %s, \"%s\", in config file \"%s\". Defaulting to %d.',\n                config_name,\n                value_from_config,\n                CONFIG_FILE,\n                default_config_value,\n            )\n    except NoOptionError:\n        logging.debug(\n            'No %s value in config file \"%s\". Defaulting to %d.',\n            config_name,\n            CONFIG_FILE,\n            default_config_value,\n        )\n\n    return val\n\n\ndef check_child_procs(child_procs):\n    for proc in child_procs:\n        proc.poll()\n        if proc.returncode is not None:\n            logging.warning(\n                \"Child TLS tunnel process %d has exited, returncode=%d\",\n                proc.pid,\n                proc.returncode,\n            )\n            child_procs.remove(proc)\n\n\ndef parse_arguments(args=None):\n    if args is None:\n        args = sys.argv\n\n    if \"-h\" in args[1:] or \"--help\" in args[1:]:\n        sys.stdout.write(\"Usage: %s [--version] [-h|--help]\\n\" % args[0])\n        sys.exit(0)\n\n    if \"--version\" in args[1:]:\n        sys.stdout.write(\"%s Version: %s\\n\" % (args[0], VERSION))\n        sys.exit(0)\n\n\ndef assert_root():\n    if os.geteuid() != 0:\n        sys.stderr.write(\"only root can run amazon-efs-mount-watchdog\\n\")\n        sys.exit(1)\n\n\ndef read_config(config_file=CONFIG_FILE):\n    try:\n        p = ConfigParser.SafeConfigParser()\n    except AttributeError:\n        p = ConfigParser()\n    p.read(config_file)\n    return p\n\n\ndef check_certificate(\n    config, state, state_file_dir, state_file, base_path=STATE_FILE_DIR\n):\n    certificate_creation_time = datetime.strptime(\n        state[\"certificateCreationTime\"], CERT_DATETIME_FORMAT\n    )\n    certificate_exists = os.path.isfile(state[\"certificate\"])\n    certificate_renewal_interval_secs = (\n        get_certificate_renewal_interval_mins(config) * 60\n    )\n    # creation instead of NOT_BEFORE datetime is used for refresh of cert because NOT_BEFORE derives from creation datetime\n    should_refresh_cert = (\n        get_utc_now() - certificate_creation_time\n    ).total_seconds() > certificate_renewal_interval_secs\n\n    if certificate_exists and not should_refresh_cert:\n        return\n\n    ap_state = state.get(\"accessPoint\")\n    if ap_state and not AP_ID_RE.match(ap_state):\n        logging.error(\n            'Access Point ID \"%s\" has been changed in the state file to a malformed format'\n            % ap_state\n        )\n        return\n\n    if not certificate_exists:\n        logging.debug(\n            \"Certificate (at %s) is missing. Recreating self-signed certificate\"\n            % state[\"certificate\"]\n        )\n    else:\n        logging.debug(\n            \"Refreshing self-signed certificate (at %s)\" % state[\"certificate\"]\n        )\n\n    credentials_source = state.get(\"awsCredentialsMethod\")\n    updated_certificate_creation_time = recreate_certificate(\n        config,\n        state[\"mountStateDir\"],\n        state[\"commonName\"],\n        state[\"fsId\"],\n        credentials_source,\n        ap_state,\n        state[\"region\"],\n        base_path=base_path,\n    )\n    if updated_certificate_creation_time:\n        state[\"certificateCreationTime\"] = updated_certificate_creation_time\n        rewrite_state_file(state, state_file_dir, state_file)\n\n        # send SIGHUP to force a reload of the configuration file to trigger the stunnel process to notice the new certificate\n        send_signal_to_running_stunnel_process_group(\n            state.get(\"pid\"), state_file, state_file_dir, SIGHUP\n        )\n\n\ndef send_signal_to_running_stunnel_process_group(\n    stunnel_pid, state_file, state_file_dir, signal\n):\n    \"\"\"\n    Send a signal to the given stunnel_pid if the process running with the pid is the mount stunnel process.\n\n    :param stunnel_pid: The pid in state file.\n    :param state_file: The state file path, e.g. fs-deadbeef.mnt.20560.\n    :param state_file_dir: The state file dir path, e.g. /var/run/efs.\n    :param signal: OS signal send to stunnel process group, e.g. SIGHUP, SIGKILL, SIGTERM.\n    \"\"\"\n    if is_mount_stunnel_proc_running(stunnel_pid, state_file, state_file_dir):\n        process_group = os.getpgid(stunnel_pid)\n        try:\n            logging.info(\n                \"Sending signal %s(%d) to stunnel. PID: %d, group ID: %s\",\n                signal.name,\n                signal.value,\n                stunnel_pid,\n                process_group,\n            )\n        except AttributeError:\n            # In python3.4, the signal is a int object, so it does not have name and value property\n            logging.info(\n                \"Sending signal(%s) to stunnel. PID: %d, group ID: %s\",\n                signal,\n                stunnel_pid,\n                process_group,\n            )\n        os.killpg(process_group, signal)\n        return True\n    else:\n        logging.warning(\"TLS tunnel is not running for %s\", state_file)\n        return False\n\n\ndef create_required_directory(config, directory):\n    mode = 0o750\n    try:\n        mode_str = config.get(CONFIG_SECTION, \"state_file_dir_mode\")\n        try:\n            mode = int(mode_str, 8)\n        except ValueError:\n            logging.warning(\n                'Bad state_file_dir_mode \"%s\" in config file \"%s\"',\n                mode_str,\n                CONFIG_FILE,\n            )\n    except NoOptionError:\n        pass\n\n    try:\n        os.makedirs(directory, mode)\n        logging.debug(\"Expected %s not found, recreating asset\", directory)\n    except OSError as e:\n        if errno.EEXIST != e.errno or not os.path.isdir(directory):\n            raise\n\n\ndef get_client_info(config):\n    client_info = {}\n\n    # source key/value pair in config file\n    if config.has_option(CLIENT_INFO_SECTION, \"source\"):\n        client_source = config.get(CLIENT_INFO_SECTION, \"source\")\n        if 0 < len(client_source) <= CLIENT_SOURCE_STR_LEN_LIMIT:\n            client_info[\"source\"] = client_source\n    if not client_info.get(\"source\"):\n        if check_if_running_on_macos():\n            client_info[\"source\"] = DEFAULT_MACOS_VALUE\n        else:\n            client_info[\"source\"] = DEFAULT_UNKNOWN_VALUE\n\n    client_info[\"efs_utils_version\"] = VERSION\n\n    return client_info\n\n\ndef recreate_certificate(\n    config,\n    mount_name,\n    common_name,\n    fs_id,\n    credentials_source,\n    ap_id,\n    region,\n    base_path=STATE_FILE_DIR,\n):\n    current_time = get_utc_now()\n    tls_paths = tls_paths_dictionary(mount_name, base_path)\n\n    certificate_config = os.path.join(tls_paths[\"mount_dir\"], \"config.conf\")\n    certificate_signing_request = os.path.join(tls_paths[\"mount_dir\"], \"request.csr\")\n    certificate = os.path.join(tls_paths[\"mount_dir\"], \"certificate.pem\")\n\n    ca_dirs_check(config, tls_paths[\"database_dir\"], tls_paths[\"certs_dir\"])\n    ca_supporting_files_check(\n        tls_paths[\"index\"],\n        tls_paths[\"index_attr\"],\n        tls_paths[\"serial\"],\n        tls_paths[\"rand\"],\n    )\n\n    private_key = check_and_create_private_key(base_path)\n\n    if credentials_source:\n        public_key = os.path.join(tls_paths[\"mount_dir\"], \"publicKey.pem\")\n        create_public_key(private_key, public_key)\n\n    client_info = get_client_info(config)\n    config_body = create_ca_conf(\n        config,\n        certificate_config,\n        common_name,\n        tls_paths[\"mount_dir\"],\n        private_key,\n        current_time,\n        region,\n        fs_id,\n        credentials_source,\n        ap_id=ap_id,\n        client_info=client_info,\n    )\n\n    if not config_body:\n        logging.error(\"Cannot recreate self-signed certificate\")\n        return None\n\n    create_certificate_signing_request(\n        certificate_config, private_key, certificate_signing_request\n    )\n\n    not_before = get_certificate_timestamp(current_time, minutes=-NOT_BEFORE_MINS)\n    not_after = get_certificate_timestamp(current_time, hours=NOT_AFTER_HOURS)\n\n    cmd = \"openssl ca -startdate %s -enddate %s -selfsign -batch -notext -config %s -in %s -out %s\" % (\n        not_before,\n        not_after,\n        certificate_config,\n        certificate_signing_request,\n        certificate,\n    )\n    subprocess_call(cmd, \"Failed to create self-signed client-side certificate\")\n    return current_time.strftime(CERT_DATETIME_FORMAT)\n\n\ndef get_private_key_path():\n    \"\"\"Wrapped for mocking purposes in unit tests\"\"\"\n    return PRIVATE_KEY_FILE\n\n\ndef check_and_create_private_key(base_path=STATE_FILE_DIR):\n    # Creating RSA private keys is slow, so we will create one private key and allow mounts to share it.\n    # This means, however, that we have to include a locking mechanism to ensure that the private key is\n    # atomically created, as mounts occurring in parallel may try to create the key simultaneously.\n    # The key should have been created during mounting, but the watchdog will recreate the private key if\n    # it is missing.\n    key = get_private_key_path()\n\n    @contextmanager\n    def open_lock_file():\n        lock_file = os.path.join(base_path, \"efs-utils-lock\")\n        f = os.open(lock_file, os.O_CREAT | os.O_DSYNC | os.O_EXCL | os.O_RDWR)\n        try:\n            lock_file_contents = \"PID: %s\" % os.getpid()\n            os.write(f, lock_file_contents.encode(\"utf-8\"))\n            yield f\n        finally:\n            check_and_remove_lock_file(lock_file, f)\n\n    def do_with_lock(function):\n        while True:\n            try:\n                with open_lock_file():\n                    return function()\n            except OSError as e:\n                if e.errno == errno.EEXIST:\n                    logging.info(\n                        \"Failed to take out private key creation lock, sleeping %s (s)\"\n                        % DEFAULT_TIMEOUT\n                    )\n                    time.sleep(DEFAULT_TIMEOUT)\n                else:\n                    # errno.ENOENT: No such file or directory, errno.EBADF: Bad file descriptor\n                    if e.errno == errno.ENOENT or e.errno == errno.EBADF:\n                        logging.debug(\n                            \"lock file does not exist or Bad file descriptor, The file is already removed nothing to do.\"\n                        )\n                    else:\n                        raise Exception(\n                            \"Could not remove lock file unexpected exception: %s\", e\n                        )\n\n    def generate_key():\n        if os.path.isfile(key):\n            return\n\n        cmd = (\n            \"openssl genpkey -algorithm RSA -out %s -pkeyopt rsa_keygen_bits:3072\" % key\n        )\n        subprocess_call(cmd, \"Failed to create private key\")\n        read_only_mode = 0o400\n        os.chmod(key, read_only_mode)\n\n    do_with_lock(generate_key)\n    return key\n\n\ndef create_certificate_signing_request(config_path, key_path, csr_path):\n    cmd = \"openssl req -new -config %s -key %s -out %s\" % (\n        config_path,\n        key_path,\n        csr_path,\n    )\n    subprocess_call(cmd, \"Failed to create certificate signing request (csr)\")\n\n\ndef create_ca_conf(\n    config,\n    config_path,\n    common_name,\n    directory,\n    private_key,\n    date,\n    region,\n    fs_id,\n    credentials_source,\n    ap_id=None,\n    client_info=None,\n):\n    \"\"\"Populate ca/req configuration file with fresh configurations at every mount since SigV4 signature can change\"\"\"\n    public_key_path = os.path.join(directory, \"publicKey.pem\")\n    security_credentials = (\n        get_aws_security_credentials(config, credentials_source, region)\n        if credentials_source\n        else \"\"\n    )\n\n    if credentials_source and security_credentials is None:\n        logging.error(\n            \"Failed to retrieve AWS security credentials using lookup method: %s\",\n            credentials_source,\n        )\n        return None\n\n    ca_extension_body = ca_extension_builder(\n        ap_id, security_credentials, fs_id, client_info\n    )\n    efs_client_auth_body = (\n        efs_client_auth_builder(\n            public_key_path,\n            security_credentials[\"AccessKeyId\"],\n            security_credentials[\"SecretAccessKey\"],\n            date,\n            region,\n            fs_id,\n            security_credentials[\"Token\"],\n        )\n        if credentials_source\n        else \"\"\n    )\n    if credentials_source and not efs_client_auth_body:\n        logging.error(\n            \"Failed to create AWS SigV4 signature section for OpenSSL config. Public Key path: %s\",\n            public_key_path,\n        )\n        return None\n    efs_client_info_body = efs_client_info_builder(client_info) if client_info else \"\"\n    full_config_body = CA_CONFIG_BODY % (\n        directory,\n        private_key,\n        common_name,\n        ca_extension_body,\n        efs_client_auth_body,\n        efs_client_info_body,\n    )\n\n    with open(config_path, \"w\") as f:\n        f.write(full_config_body)\n\n    return full_config_body\n\n\ndef ca_extension_builder(ap_id, security_credentials, fs_id, client_info):\n    ca_extension_str = \"[ v3_ca ]\\nsubjectKeyIdentifier = hash\"\n    if ap_id:\n        ca_extension_str += \"\\n1.3.6.1.4.1.4843.7.1 = ASN1:UTF8String:\" + ap_id\n    if security_credentials:\n        ca_extension_str += \"\\n1.3.6.1.4.1.4843.7.2 = ASN1:SEQUENCE:efs_client_auth\"\n\n    ca_extension_str += \"\\n1.3.6.1.4.1.4843.7.3 = ASN1:UTF8String:\" + fs_id\n    if client_info:\n        ca_extension_str += \"\\n1.3.6.1.4.1.4843.7.4 = ASN1:SEQUENCE:efs_client_info\"\n\n    return ca_extension_str\n\n\ndef efs_client_auth_builder(\n    public_key_path,\n    access_key_id,\n    secret_access_key,\n    date,\n    region,\n    fs_id,\n    session_token=None,\n):\n    public_key_hash = get_public_key_sha1(public_key_path)\n\n    if not public_key_hash:\n        return None\n\n    canonical_request = create_canonical_request(\n        public_key_hash, date, access_key_id, region, fs_id, session_token\n    )\n    string_to_sign = create_string_to_sign(canonical_request, date, region)\n    signature = calculate_signature(string_to_sign, date, secret_access_key, region)\n    efs_client_auth_str = \"[ efs_client_auth ]\"\n    efs_client_auth_str += \"\\naccessKeyId = UTF8String:\" + access_key_id\n    efs_client_auth_str += \"\\nsignature = OCTETSTRING:\" + signature\n    efs_client_auth_str += \"\\nsigv4DateTime = UTCTIME:\" + date.strftime(\n        CERT_DATETIME_FORMAT\n    )\n\n    if session_token:\n        efs_client_auth_str += \"\\nsessionToken = EXPLICIT:0,UTF8String:\" + session_token\n\n    return efs_client_auth_str\n\n\ndef efs_client_info_builder(client_info):\n    efs_client_info_str = \"[ efs_client_info ]\"\n    for key, value in client_info.items():\n        efs_client_info_str += \"\\n%s = UTF8String: %s\" % (key, value)\n    return efs_client_info_str\n\n\ndef create_public_key(private_key, public_key):\n    cmd = \"openssl rsa -in %s -outform PEM -pubout -out %s\" % (private_key, public_key)\n    subprocess_call(cmd, \"Failed to create public key\")\n\n\ndef subprocess_call(cmd, error_message):\n    \"\"\"Helper method to run shell openssl command and to handle response error messages\"\"\"\n    process = subprocess.Popen(\n        cmd.split(), stdout=subprocess.PIPE, stderr=subprocess.PIPE, close_fds=True\n    )\n    (output, err) = process.communicate()\n    rc = process.poll()\n    if rc != 0:\n        logging.debug(\n            '%s. Command %s failed, rc=%s, stdout=\"%s\", stderr=\"%s\"',\n            error_message,\n            cmd,\n            rc,\n            output,\n            err,\n        )\n    else:\n        return output, err\n\n\ndef ca_dirs_check(config, database_dir, certs_dir):\n    \"\"\"Check if mount's database and certs directories exist and if not, create directories (also create all intermediate\n    directories if they don't exist).\"\"\"\n    if not os.path.exists(database_dir):\n        create_required_directory(config, database_dir)\n    if not os.path.exists(certs_dir):\n        create_required_directory(config, certs_dir)\n\n\ndef ca_supporting_files_check(index_path, index_attr_path, serial_path, rand_path):\n    \"\"\"Create all supporting openssl ca and req files if they're not present in their respective directories\"\"\"\n\n    def _recreate_file_warning(path):\n        logging.warning(\"Expected %s not found, recreating file\", path)\n\n    if not os.path.isfile(index_path):\n        open(index_path, \"w\").close()\n        _recreate_file_warning(index_path)\n    if not os.path.isfile(index_attr_path):\n        with open(index_attr_path, \"w+\") as f:\n            f.write(\"unique_subject = no\")\n        _recreate_file_warning(index_attr_path)\n    if not os.path.isfile(serial_path):\n        with open(serial_path, \"w+\") as f:\n            f.write(\"00\")\n        _recreate_file_warning(serial_path)\n    if not os.path.isfile(rand_path):\n        open(rand_path, \"w\").close()\n        _recreate_file_warning(rand_path)\n\n\ndef tls_paths_dictionary(mount_name, base_path=STATE_FILE_DIR):\n    tls_dict = {\n        \"mount_dir\": os.path.join(base_path, mount_name),\n        \"database_dir\": os.path.join(base_path, mount_name, \"database\"),\n        \"certs_dir\": os.path.join(base_path, mount_name, \"certs\"),\n        \"index\": os.path.join(base_path, mount_name, \"database/index.txt\"),\n        \"index_attr\": os.path.join(base_path, mount_name, \"database/index.txt.attr\"),\n        \"serial\": os.path.join(base_path, mount_name, \"database/serial\"),\n        \"rand\": os.path.join(base_path, mount_name, \"database/.rand\"),\n    }\n\n    return tls_dict\n\n\ndef get_public_key_sha1(public_key):\n    # truncating public key to remove the header and footer '-----(BEGIN|END) PUBLIC KEY-----'\n    with open(public_key, \"r\") as f:\n        lines = f.readlines()\n        lines = lines[1:-1]\n\n    key = \"\".join(lines)\n    key = bytearray(base64.b64decode(key))\n\n    # Parse the public key to pull out the actual key material by looking for the key BIT STRING\n    # Example:\n    #     0:d=0  hl=4 l= 418 cons: SEQUENCE\n    #     4:d=1  hl=2 l=  13 cons: SEQUENCE\n    #     6:d=2  hl=2 l=   9 prim: OBJECT            :rsaEncryption\n    #    17:d=2  hl=2 l=   0 prim: NULL\n    #    19:d=1  hl=4 l= 399 prim: BIT STRING\n    cmd = \"openssl asn1parse -inform PEM -in %s\" % public_key\n    output, err = subprocess_call(\n        cmd, \"Unable to ASN1 parse public key file, %s, correctly\" % public_key\n    )\n\n    key_line = \"\"\n    for line in output.splitlines():\n        if \"BIT STRING\" in line.decode(\"utf-8\"):\n            key_line = line.decode(\"utf-8\")\n\n    if not key_line:\n        logging.error(\"Public key file, %s, is incorrectly formatted\", public_key)\n        return None\n\n    key_line = key_line.replace(\" \", \"\")\n\n    # DER encoding TLV (Tag, Length, Value)\n    # - the first octet (byte) is the tag (type)\n    # - the next octets are the length - \"definite form\"\n    #   - the first octet always has the high order bit (8) set to 1\n    #   - the remaining 127 bits are used to encode the number of octets that follow\n    #   - the following octets encode, as big-endian, the length (which may be 0) as a number of octets\n    # - the remaining octets are the \"value\" aka content\n    #\n    # For a BIT STRING, the first octet of the value is used to signify the number of unused bits that exist in the last\n    # content byte. Note that this is explicitly excluded from the SubjectKeyIdentifier hash, per\n    # https://tools.ietf.org/html/rfc5280#section-4.2.1.2\n    #\n    # Example:\n    #   0382018f00...<subjectPublicKey>\n    #   - 03 - BIT STRING tag\n    #   - 82 - 2 length octets to follow (ignore high order bit)\n    #   - 018f - length of 399\n    #   - 00 - no unused bits in the last content byte\n    offset = int(key_line.split(\":\")[0])\n    key = key[offset:]\n\n    num_length_octets = key[1] & 0b01111111\n\n    # Exclude the tag (1), length (1 + num_length_octets), and number of unused bits (1)\n    offset = 1 + 1 + num_length_octets + 1\n    key = key[offset:]\n\n    sha1 = hashlib.sha1()\n    sha1.update(key)\n\n    return sha1.hexdigest()\n\n\ndef create_canonical_request(\n    public_key_hash, date, access_key, region, fs_id, session_token=None\n):\n    \"\"\"\n    Create a Canonical Request - https://docs.aws.amazon.com/general/latest/gr/sigv4-create-canonical-request.html\n    \"\"\"\n    formatted_datetime = date.strftime(SIGV4_DATETIME_FORMAT)\n    credential = quote_plus(access_key + \"/\" + get_credential_scope(date, region))\n\n    request = HTTP_REQUEST_METHOD + \"\\n\"\n    request += CANONICAL_URI + \"\\n\"\n    request += (\n        create_canonical_query_string(\n            public_key_hash, credential, formatted_datetime, session_token\n        )\n        + \"\\n\"\n    )\n    request += CANONICAL_HEADERS % fs_id + \"\\n\"\n    request += SIGNED_HEADERS + \"\\n\"\n\n    sha256 = hashlib.sha256()\n    sha256.update(REQUEST_PAYLOAD.encode())\n    request += sha256.hexdigest()\n\n    return request\n\n\ndef create_canonical_query_string(\n    public_key_hash, credential, formatted_datetime, session_token=None\n):\n    canonical_query_params = {\n        \"Action\": \"Connect\",\n        # Public key hash is included in canonical request to tie the signature to a specific key pair to avoid replay attacks\n        \"PublicKeyHash\": quote_plus(public_key_hash),\n        \"X-Amz-Algorithm\": ALGORITHM,\n        \"X-Amz-Credential\": credential,\n        \"X-Amz-Date\": quote_plus(formatted_datetime),\n        \"X-Amz-Expires\": 86400,\n        \"X-Amz-SignedHeaders\": SIGNED_HEADERS,\n    }\n\n    if session_token:\n        canonical_query_params[\"X-Amz-Security-Token\"] = quote_plus(session_token)\n\n    # Cannot use urllib.urlencode because it replaces the %s's\n    return \"&\".join(\n        [\"%s=%s\" % (k, v) for k, v in sorted(canonical_query_params.items())]\n    )\n\n\ndef create_string_to_sign(canonical_request, date, region):\n    \"\"\"\n    Create a String to Sign - https://docs.aws.amazon.com/general/latest/gr/sigv4-create-string-to-sign.html\n    \"\"\"\n    string_to_sign = ALGORITHM + \"\\n\"\n    string_to_sign += date.strftime(SIGV4_DATETIME_FORMAT) + \"\\n\"\n    string_to_sign += get_credential_scope(date, region) + \"\\n\"\n\n    sha256 = hashlib.sha256()\n    sha256.update(canonical_request.encode())\n    string_to_sign += sha256.hexdigest()\n\n    return string_to_sign\n\n\ndef calculate_signature(string_to_sign, date, secret_access_key, region):\n    \"\"\"\n    Calculate the Signature - https://docs.aws.amazon.com/general/latest/gr/sigv4-calculate-signature.html\n    \"\"\"\n\n    def _sign(key, msg):\n        return hmac.new(key, msg.encode(\"utf-8\"), hashlib.sha256)\n\n    key_date = _sign(\n        (\"AWS4\" + secret_access_key).encode(\"utf-8\"), date.strftime(DATE_ONLY_FORMAT)\n    ).digest()\n    add_region = _sign(key_date, region).digest()\n    add_service = _sign(add_region, SERVICE).digest()\n    signing_key = _sign(add_service, \"aws4_request\").digest()\n\n    return _sign(signing_key, string_to_sign).hexdigest()\n\n\ndef get_certificate_renewal_interval_mins(config):\n    interval = DEFAULT_REFRESH_SELF_SIGNED_CERT_INTERVAL_MIN\n    try:\n        mins_from_config = config.get(CONFIG_SECTION, \"tls_cert_renewal_interval_min\")\n        try:\n            if int(mins_from_config) > 0:\n                interval = int(mins_from_config)\n            else:\n                logging.warning(\n                    'tls_cert_renewal_interval_min value in config file \"%s\" is lower than 1 minute. Defaulting '\n                    \"to %d minutes.\",\n                    CONFIG_FILE,\n                    DEFAULT_REFRESH_SELF_SIGNED_CERT_INTERVAL_MIN,\n                )\n        except ValueError:\n            logging.warning(\n                'Bad tls_cert_renewal_interval_min value, \"%s\", in config file \"%s\". Defaulting to %d minutes.',\n                mins_from_config,\n                CONFIG_FILE,\n                DEFAULT_REFRESH_SELF_SIGNED_CERT_INTERVAL_MIN,\n            )\n    except NoOptionError:\n        logging.warning(\n            'No tls_cert_renewal_interval_min value in config file \"%s\". Defaulting to %d minutes.',\n            CONFIG_FILE,\n            DEFAULT_REFRESH_SELF_SIGNED_CERT_INTERVAL_MIN,\n        )\n\n    return interval\n\n\ndef get_credential_scope(date, region):\n    return \"/\".join([date.strftime(DATE_ONLY_FORMAT), region, SERVICE, AWS4_REQUEST])\n\n\ndef get_certificate_timestamp(current_time, **kwargs):\n    updated_time = current_time + timedelta(**kwargs)\n    return updated_time.strftime(CERT_DATETIME_FORMAT)\n\n\ndef get_utc_now():\n    \"\"\"\n    Wrapped for patching purposes in unit tests\n    \"\"\"\n    return datetime.utcnow()\n\n\ndef check_process_name(pid):\n    if not check_if_running_on_macos():\n        cmd = [\"cat\", \"/proc/{pid}/cmdline\".format(pid=pid)]\n    else:\n        cmd = [\"ps\", \"-p\", str(pid), \"-o\", \"command=\"]\n\n    p = subprocess.Popen(\n        cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, close_fds=True\n    )\n    return p.communicate()[0]\n\n\ndef check_if_running_on_macos():\n    return sys.platform == \"darwin\"\n\n\ndef check_and_remove_file(path):\n    try:\n        os.remove(path)\n        logging.debug(\"Removed %s successfully\", path)\n    except OSError as e:\n        if e.errno != errno.ENOENT:\n            logging.debug(\"Could not remove %s. Unexpected exception: %s\", path, e)\n        else:\n            logging.debug(\"%s does not exist, nothing to do\", path)\n\n\ndef check_and_remove_lock_file(path, file):\n    \"\"\"\n    There is a possibility of having a race condition as the lock file is getting deleted in both mount_efs and watchdog,\n    so creating a function in order to check whether the path exist or not before removing the lock file.\n    \"\"\"\n    try:\n        os.close(file)\n        os.remove(path)\n        logging.debug(\"Removed %s successfully\", path)\n    except OSError as e:\n        if not (e.errno == errno.ENOENT or e.errno == errno.EBADF):\n            raise Exception(\"Could not remove %s. Unexpected exception: %s\", path, e)\n        else:\n            logging.debug(\n                \"%s does not exist, The file is already removed nothing to do\", path\n            )\n\n\ndef clean_up_certificate_lock_file(state_file_dir=STATE_FILE_DIR):\n    \"\"\"\n    Cleans up private key lock file 'efs-utils-lock' left behind by a previous process attempting to create private key\n    and efs-csi-driver is restarted. Once driver restarts, a new mount/watchdog process will fail to create private key\n    since contents of `STATE_FILE_DIR` is persisted on a node across driver pod restarts.\n    \"\"\"\n    lock_file = os.path.join(state_file_dir, \"efs-utils-lock\")\n    logging.debug(\"Removing private key file\")\n    check_and_remove_file(lock_file)\n\n\ndef clean_up_previous_stunnel_pids(state_file_dir=STATE_FILE_DIR):\n    \"\"\"\n    Cleans up stunnel pids created by mount watchdog spawned by a previous efs-csi-driver pod after driver restart, upgrade\n    or crash. This method attempts to clean PIDs from persisted state files after efs-csi-driver restart to\n    ensure watchdog creates a new stunnel.\n    \"\"\"\n    state_files = get_state_files(state_file_dir)\n    logging.debug(\n        'Persisted state files in \"%s\": %s', state_file_dir, list(state_files.values())\n    )\n\n    for state_file in state_files.values():\n        state_file_path = os.path.join(state_file_dir, state_file)\n        with open(state_file_path) as f:\n            try:\n                state = json.load(f)\n            except ValueError:\n                logging.exception(\"Unable to parse json in %s\", state_file_path)\n                continue\n\n            try:\n                pid = state[\"pid\"]\n            except KeyError:\n                logging.debug(\"No PID found in state file %s\", state_file)\n                continue\n\n            out = check_process_name(pid)\n\n            if out and \"stunnel\" in str(out):\n                logging.debug(\n                    \"PID %s in state file %s is active. Skipping clean up\",\n                    pid,\n                    state_file,\n                )\n                continue\n\n            state.pop(\"pid\")\n            logging.debug(\"Cleaning up pid %s in state file %s\", pid, state_file)\n\n            rewrite_state_file(state, state_file_dir, state_file)\n\n\ndef main():\n    parse_arguments()\n    assert_root()\n\n    config = read_config()\n    bootstrap_logging(config)\n\n    child_procs = []\n\n    if get_boolean_config_item_value(\n        config, CONFIG_SECTION, \"enabled\", default_value=True, emit_warning_message=True\n    ):\n        logging.info(\n            \"amazon-efs-mount-watchdog, version %s, is enabled and started\", VERSION\n        )\n        poll_interval_sec = config.getint(CONFIG_SECTION, \"poll_interval_sec\")\n\n        if config.has_option(CONFIG_SECTION, \"unmount_count_for_consistency\"):\n            unmount_count_for_consistency = config.getint(\n                CONFIG_SECTION, \"unmount_count_for_consistency\"\n            )\n        else:\n            unmount_count_for_consistency = DEFAULT_UNMOUNT_COUNT_FOR_CONSISTENCY\n\n        unmount_grace_period_sec = config.getint(\n            CONFIG_SECTION, \"unmount_grace_period_sec\"\n        )\n\n        clean_up_previous_stunnel_pids()\n        clean_up_certificate_lock_file()\n\n        while True:\n            config = read_config()\n\n            check_efs_mounts(\n                config,\n                child_procs,\n                unmount_grace_period_sec,\n                unmount_count_for_consistency,\n            )\n            check_child_procs(child_procs)\n\n            time.sleep(poll_interval_sec)\n    else:\n        logging.info(\"amazon-efs-mount-watchdog is not enabled\")\n\n\nif \"__main__\" == __name__:\n    main()\n", "# Copyright 2017-2018 Amazon.com, Inc. and its affiliates. All Rights Reserved.\n#\n# Licensed under the MIT License. See the LICENSE accompanying this file\n# for the specific language governing permissions and limitations under\n# the License.\n\nimport os\nimport tempfile\nfrom unittest.mock import MagicMock\n\nimport mount_efs\n\nAP_ID = \"fsap-beefdead\"\nFS_ID = \"fs-deadbeef\"\nCLIENT_SOURCE = \"test\"\nDNS_NAME = \"%s.efs.us-east-1.amazonaws.com\" % FS_ID\nMOUNT_POINT = \"/mnt\"\nREGION = \"us-east-1\"\n\n\nDEFAULT_TLS_PORT = 20049\n\nEXPECTED_STUNNEL_CONFIG_FILE_BASE = \"stunnel-config.fs-deadbeef.mnt.\"\nEXPECTED_STUNNEL_CONFIG_FILE = EXPECTED_STUNNEL_CONFIG_FILE_BASE + str(DEFAULT_TLS_PORT)\n\nINIT_SYSTEM = \"upstart\"\n\nMOCK_CONFIG = MagicMock()\n\n\ndef setup_mocks(mocker):\n    mocker.patch(\"mount_efs.start_watchdog\")\n    mocker.patch(\n        \"mount_efs.get_tls_port_range\",\n        return_value=(DEFAULT_TLS_PORT, DEFAULT_TLS_PORT + 10),\n    )\n    mocker.patch(\"socket.socket\", return_value=MagicMock())\n    mocker.patch(\n        \"mount_efs.get_dns_name_and_fallback_mount_target_ip_address\",\n        return_value=(DNS_NAME, None),\n    )\n    mocker.patch(\"mount_efs.get_target_region\", return_value=REGION)\n    mocker.patch(\"mount_efs.write_tls_tunnel_state_file\", return_value=\"~mocktempfile\")\n    mocker.patch(\"mount_efs.create_certificate\")\n    mocker.patch(\"os.rename\")\n    mocker.patch(\"os.kill\")\n\n    process_mock = MagicMock()\n    process_mock.communicate.return_value = (\n        \"stdout\",\n        \"stderr\",\n    )\n    process_mock.returncode = 0\n\n    popen_mock = mocker.patch(\"subprocess.Popen\", return_value=process_mock)\n    write_config_mock = mocker.patch(\n        \"mount_efs.write_stunnel_config_file\", return_value=EXPECTED_STUNNEL_CONFIG_FILE\n    )\n    return popen_mock, write_config_mock\n\n\ndef setup_mocks_without_popen(mocker):\n    mocker.patch(\"mount_efs.start_watchdog\")\n    mocker.patch(\n        \"mount_efs.get_tls_port_range\",\n        return_value=(DEFAULT_TLS_PORT, DEFAULT_TLS_PORT + 10),\n    )\n    mocker.patch(\"socket.gethostname\", return_value=DNS_NAME)\n    mocker.patch(\n        \"mount_efs.get_dns_name_and_fallback_mount_target_ip_address\",\n        return_value=(DNS_NAME, None),\n    )\n    mocker.patch(\"mount_efs.write_tls_tunnel_state_file\", return_value=\"~mocktempfile\")\n    mocker.patch(\"os.kill\")\n\n    write_config_mock = mocker.patch(\n        \"mount_efs.write_stunnel_config_file\", return_value=EXPECTED_STUNNEL_CONFIG_FILE\n    )\n    return write_config_mock\n\n\ndef test_bootstrap_tls_state_file_dir_exists(mocker, tmpdir):\n    popen_mock, _ = setup_mocks(mocker)\n    state_file_dir = str(tmpdir)\n\n    mocker.patch(\"mount_efs._stunnel_bin\", return_value=\"/usr/bin/stunnel\")\n    with mount_efs.bootstrap_tls(\n        MOCK_CONFIG, INIT_SYSTEM, DNS_NAME, FS_ID, MOUNT_POINT, {}, state_file_dir\n    ):\n        pass\n\n    args, _ = popen_mock.call_args\n    args = args[0]\n\n    assert \"/usr/bin/stunnel\" in args\n    assert EXPECTED_STUNNEL_CONFIG_FILE in args\n\n\ndef test_bootstrap_tls_state_file_nonexistent_dir(mocker, tmpdir):\n    popen_mock, _ = setup_mocks(mocker)\n    state_file_dir = str(tmpdir.join(tempfile.mkdtemp()[1]))\n\n    def config_get_side_effect(section, field):\n        if section == mount_efs.CONFIG_SECTION and field == \"state_file_dir_mode\":\n            return \"0755\"\n        elif section == mount_efs.CONFIG_SECTION and field == \"dns_name_format\":\n            return \"{fs_id}.efs.{region}.amazonaws.com\"\n        elif section == mount_efs.CLIENT_INFO_SECTION and field == \"source\":\n            return CLIENT_SOURCE\n        else:\n            raise ValueError(\"Unexpected arguments\")\n\n    MOCK_CONFIG.get.side_effect = config_get_side_effect\n\n    assert not os.path.exists(state_file_dir)\n\n    mocker.patch(\"mount_efs._stunnel_bin\", return_value=\"/usr/bin/stunnel\")\n    with mount_efs.bootstrap_tls(\n        MOCK_CONFIG, INIT_SYSTEM, DNS_NAME, FS_ID, MOUNT_POINT, {}, state_file_dir\n    ):\n        pass\n\n    assert os.path.exists(state_file_dir)\n\n\ndef test_bootstrap_tls_cert_created(mocker, tmpdir):\n    setup_mocks_without_popen(mocker)\n    mocker.patch(\"mount_efs.get_mount_specific_filename\", return_value=DNS_NAME)\n    mocker.patch(\"mount_efs.get_target_region\", return_value=REGION)\n    state_file_dir = str(tmpdir)\n    tls_dict = mount_efs.tls_paths_dictionary(DNS_NAME + \"+\", state_file_dir)\n\n    pk_path = os.path.join(str(tmpdir), \"privateKey.pem\")\n    mocker.patch(\"mount_efs.get_private_key_path\", return_value=pk_path)\n\n    def config_get_side_effect(section, field):\n        if section == mount_efs.CONFIG_SECTION and field == \"state_file_dir_mode\":\n            return \"0755\"\n        elif section == mount_efs.CONFIG_SECTION and field == \"dns_name_format\":\n            return \"{fs_id}.efs.{region}.amazonaws.com\"\n        elif section == mount_efs.CLIENT_INFO_SECTION and field == \"source\":\n            return CLIENT_SOURCE\n        else:\n            raise ValueError(\"Unexpected arguments\")\n\n    MOCK_CONFIG.get.side_effect = config_get_side_effect\n\n    mocker.patch(\"mount_efs._stunnel_bin\", return_value=\"/usr/bin/stunnel\")\n    try:\n        with mount_efs.bootstrap_tls(\n            MOCK_CONFIG,\n            INIT_SYSTEM,\n            DNS_NAME,\n            FS_ID,\n            MOUNT_POINT,\n            {\"accesspoint\": AP_ID},\n            state_file_dir,\n        ):\n            pass\n    except OSError as e:\n        assert \"[Errno 2] No such file or directory\" in str(e)\n\n    assert os.path.exists(os.path.join(tls_dict[\"mount_dir\"], \"certificate.pem\"))\n    assert os.path.exists(os.path.join(tls_dict[\"mount_dir\"], \"request.csr\"))\n    assert os.path.exists(os.path.join(tls_dict[\"mount_dir\"], \"config.conf\"))\n    assert os.path.exists(pk_path)\n\n\ndef test_bootstrap_tls_non_default_port(mocker, tmpdir):\n    popen_mock, write_config_mock = setup_mocks(mocker)\n    mocker.patch(\"os.rename\")\n    state_file_dir = str(tmpdir)\n\n    tls_port = 1000\n    tls_port_sock_mock = MagicMock()\n    tls_port_sock_mock.getsockname.return_value = (\"local_host\", tls_port)\n    tls_port_sock_mock.close.side_effect = None\n    mocker.patch(\"socket.socket\", return_value=tls_port_sock_mock)\n\n    mocker.patch(\"mount_efs._stunnel_bin\", return_value=\"/usr/bin/stunnel\")\n    with mount_efs.bootstrap_tls(\n        MOCK_CONFIG,\n        INIT_SYSTEM,\n        DNS_NAME,\n        FS_ID,\n        MOUNT_POINT,\n        {\"tlsport\": tls_port},\n        state_file_dir,\n    ):\n        pass\n\n    popen_args, _ = popen_mock.call_args\n    popen_args = popen_args[0]\n    write_config_args, _ = write_config_mock.call_args\n\n    assert \"/usr/bin/stunnel\" in popen_args\n    assert EXPECTED_STUNNEL_CONFIG_FILE in popen_args\n    assert tls_port == write_config_args[4]  # positional argument for tls_port\n    # Ensure tls port socket is closed in bootstrap_tls\n    # The number is two here, the first one is the actual socket when choosing tls port, the second one is a socket to\n    # verify tls port can be connected after establishing TLS stunnel. They share the same mock.\n    assert 2 == tls_port_sock_mock.close.call_count\n\n\ndef test_bootstrap_tls_non_default_verify_level(mocker, tmpdir):\n    popen_mock, write_config_mock = setup_mocks(mocker)\n    state_file_dir = str(tmpdir)\n\n    verify = 0\n    mocker.patch(\"mount_efs._stunnel_bin\", return_value=\"/usr/bin/stunnel\")\n    with mount_efs.bootstrap_tls(\n        MOCK_CONFIG,\n        INIT_SYSTEM,\n        DNS_NAME,\n        FS_ID,\n        MOUNT_POINT,\n        {\"verify\": verify},\n        state_file_dir,\n    ):\n        pass\n\n    popen_args, _ = popen_mock.call_args\n    popen_args = popen_args[0]\n    write_config_args, _ = write_config_mock.call_args\n\n    assert \"/usr/bin/stunnel\" in popen_args\n    assert EXPECTED_STUNNEL_CONFIG_FILE in popen_args\n    assert 0 == write_config_args[6]  # positional argument for verify_level\n\n\ndef test_bootstrap_tls_ocsp_option(mocker, tmpdir):\n    popen_mock, write_config_mock = setup_mocks(mocker)\n    state_file_dir = str(tmpdir)\n\n    mocker.patch(\"mount_efs._stunnel_bin\", return_value=\"/usr/bin/stunnel\")\n    with mount_efs.bootstrap_tls(\n        MOCK_CONFIG,\n        INIT_SYSTEM,\n        DNS_NAME,\n        FS_ID,\n        MOUNT_POINT,\n        {\"ocsp\": None},\n        state_file_dir,\n    ):\n        pass\n\n    popen_args, _ = popen_mock.call_args\n    popen_args = popen_args[0]\n    write_config_args, _ = write_config_mock.call_args\n\n    assert \"/usr/bin/stunnel\" in popen_args\n    assert EXPECTED_STUNNEL_CONFIG_FILE in popen_args\n    # positional argument for ocsp_override\n    assert write_config_args[7] is True\n\n\ndef test_bootstrap_tls_noocsp_option(mocker, tmpdir):\n    popen_mock, write_config_mock = setup_mocks(mocker)\n    state_file_dir = str(tmpdir)\n\n    mocker.patch(\"mount_efs._stunnel_bin\", return_value=\"/usr/bin/stunnel\")\n    with mount_efs.bootstrap_tls(\n        MOCK_CONFIG,\n        INIT_SYSTEM,\n        DNS_NAME,\n        FS_ID,\n        MOUNT_POINT,\n        {\"noocsp\": None},\n        state_file_dir,\n    ):\n        pass\n\n    popen_args, _ = popen_mock.call_args\n    popen_args = popen_args[0]\n    write_config_args, _ = write_config_mock.call_args\n\n    assert \"/usr/bin/stunnel\" in popen_args\n    assert EXPECTED_STUNNEL_CONFIG_FILE in popen_args\n    # positional argument for ocsp_override\n    assert write_config_args[7] is False\n", "# Copyright 2017-2018 Amazon.com, Inc. and its affiliates. All Rights Reserved.\n#\n# Licensed under the MIT License. See the LICENSE accompanying this file\n# for the specific language governing permissions and limitations under\n# the License.\n\nimport random\nimport socket\nfrom unittest.mock import MagicMock\n\nimport pytest\n\nimport mount_efs\n\nfrom .. import utils\n\ntry:\n    import ConfigParser\nexcept ImportError:\n    from configparser import ConfigParser\n\nDEFAULT_TLS_PORT_RANGE_LOW = 20049\nDEFAULT_TLS_PORT_RANGE_HIGH = 21049\nDEFAULT_TLS_PORT = random.randrange(\n    DEFAULT_TLS_PORT_RANGE_LOW, DEFAULT_TLS_PORT_RANGE_HIGH\n)\n\n\ndef _get_config():\n    try:\n        config = ConfigParser.SafeConfigParser()\n    except AttributeError:\n        config = ConfigParser()\n    config.add_section(mount_efs.CONFIG_SECTION)\n    config.set(\n        mount_efs.CONFIG_SECTION,\n        \"port_range_lower_bound\",\n        str(DEFAULT_TLS_PORT_RANGE_LOW),\n    )\n    config.set(\n        mount_efs.CONFIG_SECTION,\n        \"port_range_upper_bound\",\n        str(DEFAULT_TLS_PORT_RANGE_HIGH),\n    )\n    return config\n\n\ndef test_choose_tls_port_first_try(mocker):\n    sock_mock = MagicMock()\n    sock_mock.getsockname.return_value = (\"local_host\", DEFAULT_TLS_PORT)\n    mocker.patch(\"socket.socket\", return_value=sock_mock)\n    options = {}\n\n    tls_port_sock = mount_efs.choose_tls_port_and_get_bind_sock(_get_config(), options)\n    tls_port = mount_efs.get_tls_port_from_sock(tls_port_sock)\n    assert DEFAULT_TLS_PORT_RANGE_LOW <= tls_port <= DEFAULT_TLS_PORT_RANGE_HIGH\n\n\ndef test_choose_tls_port_second_try(mocker):\n    bad_sock = MagicMock()\n    bad_sock.bind.side_effect = [socket.error, None]\n    bad_sock.getsockname.return_value = (\"local_host\", DEFAULT_TLS_PORT)\n    options = {}\n\n    mocker.patch(\"socket.socket\", return_value=bad_sock)\n\n    tls_port_sock = mount_efs.choose_tls_port_and_get_bind_sock(_get_config(), options)\n    tls_port = mount_efs.get_tls_port_from_sock(tls_port_sock)\n\n    assert DEFAULT_TLS_PORT_RANGE_LOW <= tls_port <= DEFAULT_TLS_PORT_RANGE_HIGH\n    assert 2 == bad_sock.bind.call_count\n    assert 1 == bad_sock.getsockname.call_count\n\n\ndef test_choose_tls_port_never_succeeds(mocker, capsys):\n    bad_sock = MagicMock()\n    bad_sock.bind.side_effect = socket.error()\n    options = {}\n\n    mocker.patch(\"socket.socket\", return_value=bad_sock)\n\n    with pytest.raises(SystemExit) as ex:\n        mount_efs.choose_tls_port_and_get_bind_sock(_get_config(), options)\n\n    assert 0 != ex.value.code\n\n    out, err = capsys.readouterr()\n    assert \"Failed to locate an available port\" in err\n\n    assert (\n        DEFAULT_TLS_PORT_RANGE_HIGH - DEFAULT_TLS_PORT_RANGE_LOW\n        == bad_sock.bind.call_count\n    )\n\n\ndef test_choose_tls_port_option_specified(mocker):\n    sock_mock = MagicMock()\n    sock_mock.getsockname.return_value = (\"local_host\", DEFAULT_TLS_PORT)\n    mocker.patch(\"socket.socket\", return_value=sock_mock)\n    options = {\"tlsport\": DEFAULT_TLS_PORT}\n\n    tls_port_sock = mount_efs.choose_tls_port_and_get_bind_sock(_get_config(), options)\n    tls_port = mount_efs.get_tls_port_from_sock(tls_port_sock)\n\n    assert DEFAULT_TLS_PORT == tls_port\n\n\ndef test_choose_tls_port_option_specified_unavailable(mocker, capsys):\n    bad_sock = MagicMock()\n    bad_sock.bind.side_effect = socket.error()\n    options = {\"tlsport\": 1000}\n\n    mocker.patch(\"socket.socket\", return_value=bad_sock)\n\n    with pytest.raises(SystemExit) as ex:\n        mount_efs.choose_tls_port_and_get_bind_sock(_get_config(), options)\n\n    assert 0 != ex.value.code\n\n    out, err = capsys.readouterr()\n    assert \"Specified port [1000] is unavailable\" in err\n\n    assert 1 == bad_sock.bind.call_count\n\n\ndef test_choose_tls_port_under_netns(mocker, capsys):\n    mocker.patch(\"builtins.open\")\n    setns_mock = mocker.patch(\"mount_efs.setns\", return_value=(None, None))\n    mocker.patch(\"socket.socket\", return_value=MagicMock())\n    options = {\"netns\": \"/proc/1000/ns/net\"}\n\n    mount_efs.choose_tls_port_and_get_bind_sock(_get_config(), options)\n    utils.assert_called(setns_mock)\n\n\ndef test_verify_tls_port(mocker):\n    sock = MagicMock()\n    sock.connect.side_effect = [ConnectionRefusedError, None]\n    mocker.patch(\"socket.socket\", return_value=sock)\n    result = mount_efs.verify_tlsport_can_be_connected(1000)\n    assert result is False\n    result = mount_efs.verify_tlsport_can_be_connected(1000)\n    assert result is True\n    assert 2 == sock.connect.call_count\n"], "fixing_code": ["#\n# Copyright 2017-2018 Amazon.com, Inc. and its affiliates. All Rights Reserved.\n#\n# Licensed under the MIT License. See the LICENSE accompanying this file\n# for the specific language governing permissions and limitations under\n# the License.\n#\n\n%if 0%{?amzn1}\n%global python_requires python36\n%else\n%global python_requires python3\n%endif\n\n%if 0%{?amzn1} || 0%{?rhel} == 6\n%global with_systemd 0\n%else\n%global with_systemd 1\n%endif\n\n%if 0%{?dist:1}\n%global platform %{dist}\n%else\n%if 0%{?suse_version}\n%global platform .suse\n%else\n%global platform .unknown\n%endif\n%endif\n\n%if 0%{?amzn} > 2\n%global efs_bindir %{_sbindir}\n%else\n%global efs_bindir /sbin\n%endif\n\nName      : amazon-efs-utils\nVersion   : 1.34.4\nRelease   : 1%{platform}\nSummary   : This package provides utilities for simplifying the use of EFS file systems\n\nGroup     : Amazon/Tools\nLicense   : MIT\nURL       : https://aws.amazon.com/efs\n\n\nBuildArch : noarch\n\nRequires  : nfs-utils\n%if 0%{?amzn2}\nRequires  : stunnel5\n%else\nRequires  : stunnel >= 4.56\n%endif\nRequires  : %{python_requires}\nRequires  : openssl >= 1.0.2\nRequires  : util-linux\nRequires  : which\n\n%if %{with_systemd}\nBuildRequires    : systemd\n%{?systemd_requires}\n%else\nRequires(post)   : /sbin/chkconfig\nRequires(preun)  : /sbin/service /sbin/chkconfig\nRequires(postun) : /sbin/service\n%endif\n\nSource    : %{name}.tar.gz\n\n%description\nThis package provides utilities for simplifying the use of EFS file systems\n\n%prep\n%setup -n %{name}\n\n%install\nmkdir -p %{buildroot}%{_sysconfdir}/amazon/efs\n%if %{with_systemd}\nmkdir -p %{buildroot}%{_unitdir}\ninstall -p -m 644 %{_builddir}/%{name}/dist/amazon-efs-mount-watchdog.service %{buildroot}%{_unitdir}\n%else\nmkdir -p %{buildroot}%{_sysconfdir}/init\ninstall -p -m 644 %{_builddir}/%{name}/dist/amazon-efs-mount-watchdog.conf %{buildroot}%{_sysconfdir}/init\n%endif\n\nmkdir -p %{buildroot}%{efs_bindir}\nmkdir -p %{buildroot}%{_bindir}\nmkdir -p %{buildroot}%{_localstatedir}/log/amazon/efs\nmkdir -p  %{buildroot}%{_mandir}/man8\n\ninstall -p -m 644 %{_builddir}/%{name}/dist/efs-utils.conf %{buildroot}%{_sysconfdir}/amazon/efs\ninstall -p -m 444 %{_builddir}/%{name}/dist/efs-utils.crt %{buildroot}%{_sysconfdir}/amazon/efs\ninstall -p -m 755 %{_builddir}/%{name}/src/mount_efs/__init__.py %{buildroot}%{efs_bindir}/mount.efs\ninstall -p -m 755 %{_builddir}/%{name}/src/watchdog/__init__.py %{buildroot}%{_bindir}/amazon-efs-mount-watchdog\ninstall -p -m 644 %{_builddir}/%{name}/man/mount.efs.8 %{buildroot}%{_mandir}/man8\n\n%files\n%defattr(-,root,root,-)\n%if %{with_systemd}\n%{_unitdir}/amazon-efs-mount-watchdog.service\n%else\n%config(noreplace) %{_sysconfdir}/init/amazon-efs-mount-watchdog.conf\n%endif\n%{_sysconfdir}/amazon/efs/efs-utils.crt\n%{efs_bindir}/mount.efs\n%{_bindir}/amazon-efs-mount-watchdog\n/var/log/amazon\n%{_mandir}/man8/mount.efs.8.gz\n\n%config(noreplace) %{_sysconfdir}/amazon/efs/efs-utils.conf\n\n%if %{with_systemd}\n%post\n%systemd_post amazon-efs-mount-watchdog.service\n\n%preun\n%systemd_preun amazon-efs-mount-watchdog.service\n\n%postun\n%systemd_postun_with_restart amazon-efs-mount-watchdog.service\n\n%else\n\n%preun\nif [ $1 -eq 0 ]; then\n   /sbin/stop amazon-efs-mount-watchdog &> /dev/null || true\nfi\n\n%postun\nif [ $1 -eq 1 ]; then\n    /sbin/restart amazon-efs-mount-watchdog &> /dev/null || true\nfi\n\n%endif\n\n%clean\n\n%changelog\n* Tue Dec 13 2022 Ryan Stankiewicz <rjstank@amazon.com> - 1.34.4\n- Fix potential tlsport selection collision by using state file as tlsport lock file.\n\n* Thu Dec 1 2022 Preetham Puneeth Munipalli <tmunipre@amazon.com> - 1.34.3\n- Fix potential tlsport selection race condition by closing socket right before establishing stunnel\n- Fix stunnel constantly restart issue when upgrading from 1.32.1 and before version to latest version\n- Speed up the way to check network availability by using systemctl is-active\n\n* Tue Nov 22 2022 Preetham Puneeth Munipalli <tmunipre@amazon.com> - 1.34.2\n- Fix potential issue on AL2 when watchdog trying to restart stunnel for the TLS mounts that existing before upgrade\n\n* Thu Sep 29 2022 Preetham Puneeth Munipalli <tmunipre@amazon.com> - 1.34.1\n- Update Amazon Linux 2 platform to use namespaced stunnel5\n\n* Thu Sep 1 2022 Yuan Gao <ygaochn@amazon.com> - 1.33.4\n- Fix potential issue where watchdog sending signal to incorrect processes.\n- Add support for enabling FIPS mode for both stunnel and AWS API calls.\n\n* Wed Jul 13 2022 Yuan Gao <ygaochn@amazon.com> - 1.33.3\n- Fix potential stunnel hanging issue caused by full subprocess PIPE filled by stunnel log.\n\n* Mon Jun 6 2022 Yuan Gao <ygaochn@amazon.com> - 1.33.2\n- Fix the incorrect path to generate read_ahead_kb config file.\n- Bump the default tls port range from 400 to 1000.\n\n* Fri May 6 2022 Yuan Gao <ygaochn@amazon.com> - 1.33.1\n- Enable mount process to retry on failed or timed out mount.nfs command.\n\n* Thu Apr 28 2022 Yuan Gao <ygaochn@amazon.com> - 1.32.2\n- Fix potential race condition issue when stunnel creating pid file.\n\n* Thu Mar 31 2022 Shivam Gupta <lshigupt@amazon.com> - 1.32.1\n- Enable watchdog to check stunnel health periodically and restart hanging stunnel process when necessary.\n- Fix potential race condition issue when removing lock files.\n- Add efs-utils Support for MacOS Monterey EC2 instances.\n\n* Tue Nov 23 2021 Jigar Dedhia <dedhiajd@amazon.com> - 1.31.3\n- Add unmount_time and unmount_count to handle inconsistent mount reads\n- Allow specifying fs_id in cloudwatch log group name\n\n* Thu Jun 10 2021 Yuan Gao <ygaochn@amazon.com> - 1.31.2\n- Handle the fallback to IMDSv1 call when either HTTPError or unknown exception is thrown\n- Cleanup private key lock file at watchdog startup\n\n* Thu May 06 2021 Yuan Gao <ygaochn@amazon.com> - 1.31.1\n- Support new option: mounttargetip, enable mount file system to specific mount target ip address\n- Support using botocore to retrieve and mount via file system mount target ip address when DNS resolution fails\n- Use IMDSv2 by default to access instance metadata service\n\n* Thu Apr 15 2021 Yue Wang <wangnyue@amazon.com> - 1.30.2\n- Fix the throughput regression due to read_ahead configuration change on Linux distribution with kernel version 5.4.x and above\n\n* Mon Mar 22 2021 Yuan Gao <ygaochn@amazon.com> - 1.30.1\n- Support new option: az, enable mount file system to specific availability zone mount target\n- Merge PR #84 on Github. Fix to use regional AWS STS endpoints instead of the global endpoint to reduce latency\n\n* Mon Jan 25 2021 Yuan Gao <ygaochn@amazon.com> - 1.29.1\n- Update the python dependency to python3\n- Support SLES and OpenSUSE\n\n* Thu Oct 8 2020 Yuan Gao <ygaochn@amazon.com> - 1.28.2\n- Fix an issue where fs cannot be mounted with iam using instance profile when IMDSv2 is enabled\n\n* Fri Sep 18 2020 Yuan Gao <ygaochn@amazon.com> - 1.28.1\n- Introduce botocore to publish mount success/failure notification to cloudwatch log\n- Revert stop emitting unrecognized init system supervisord if the watchdog daemon has already been launched by supervisor check\n\n* Tue Aug 4 2020 Karthik Basavaraj <kbbasav@amazon.com> - 1.27.1\n- Merge PR #60 on GitHub. Adds support for AssumeRoleWithWebIdentity\n\n* Wed Jul 1 2020 Yuan Gao <ygaochn@amazon.com> - 1.26.3\n- Fix an issue where watchdog crashed during restart because stunnel was killed and pid key was removed from state file\n\n* Tue Jun 16 2020 Karthik Basavaraj <kbbasav@amazon.com> - 1.26.2\n- Clean up stunnel PIDs in state files persisted by previous efs-csi-driver to ensure watchdog spawns a new stunnel after driver restarts.\n- Fix an issue where fs cannot be mounted with tls using systemd.automount-units due to mountpoint check\n\n* Tue May 26 2020 Yuan Gao <ygaochn@amazon.com> - 1.25.3\n- Fix an issue where subprocess was not killed successfully\n- Stop emitting unrecognized init system supervisord if the watchdog daemon has already been launched by supervisor\n- Support Fedora\n- Check if mountpoint is already mounted beforehand for tls mount\n\n* Tue May 05 2020 Yuan Gao <ygaochn@amazon.com> - 1.25.2\n- Fix the issue that IAM role name format is not correctly encoded in python3\n- Add optional override for stunnel debug log output location\n\n* Mon Apr 20 2020 Yuan Gao <ygaochn@amazon.com> - 1.25.1\n- Create self-signed certificate for tls-only mount\n\n* Tue Apr 7 2020 Yuan Gao <ygaochn@amazon.com> - 1.24.4\n- Fix the malformed certificate info\n\n* Fri Mar 27 2020 Yuan Gao <ygaochn@amazon.com> - 1.24.3\n- Use IMDSv1 by default, and use IMDSv2 where required\n\n* Tue Mar 10 2020 Yuan Gao <ygaochn@amazon.com> - 1.24.2\n- List which as dependency\n\n* Tue Mar 10 2020 Yuan Gao <ygaochn@amazon.com> - 1.24.1\n- Enable efs-utils to source region from config file for sigv4 auth\n- Fix the issue that stunnel bin exec cannot be found in certain linux distributions\n\n* Tue Mar 03 2020 Yuan Gao <ygaochn@amazon.com> - 1.23.2\n- Support new option: netns, enable file system to mount in given network namespace\n- Support new option: awscredsuri, enable sourcing iam authorization from aws credentials relative uri\n- List openssl and util-linux as package dependency for IAM/AP authorization and command nsenter to mount file system to given network namespace\n", "#!/usr/bin/env sh\n#\n# Copyright 2017-2018 Amazon.com, Inc. and its affiliates. All Rights Reserved.\n#\n# Licensed under the MIT License. See the LICENSE accompanying this file\n# for the specific language governing permissions and limitations under\n# the License.\n#\n\nset -ex\n\nBASE_DIR=$(pwd)\nBUILD_ROOT=${BASE_DIR}/build/debbuild\nVERSION=1.34.4\nRELEASE=1\nDEB_SYSTEM_RELEASE_PATH=/etc/os-release\n\necho 'Cleaning deb build workspace'\nrm -rf ${BUILD_ROOT}\nmkdir -p ${BUILD_ROOT}\n\necho 'Creating application directories'\nmkdir -p ${BUILD_ROOT}/etc/amazon/efs\nmkdir -p ${BUILD_ROOT}/etc/init/\nmkdir -p ${BUILD_ROOT}/etc/systemd/system\nmkdir -p ${BUILD_ROOT}/sbin\nmkdir -p ${BUILD_ROOT}/usr/bin\nmkdir -p ${BUILD_ROOT}/var/log/amazon/efs\nmkdir -p ${BUILD_ROOT}/usr/share/man/man8\n\necho 'Copying application files'\ninstall -p -m 644 dist/amazon-efs-mount-watchdog.conf ${BUILD_ROOT}/etc/init\ninstall -p -m 644 dist/amazon-efs-mount-watchdog.service ${BUILD_ROOT}/etc/systemd/system\ninstall -p -m 444 dist/efs-utils.crt ${BUILD_ROOT}/etc/amazon/efs\ninstall -p -m 644 dist/efs-utils.conf ${BUILD_ROOT}/etc/amazon/efs\ninstall -p -m 755 src/mount_efs/__init__.py ${BUILD_ROOT}/sbin/mount.efs\ninstall -p -m 755 src/watchdog/__init__.py ${BUILD_ROOT}/usr/bin/amazon-efs-mount-watchdog\n\necho 'Copying install scripts'\ninstall -p -m 755 dist/scriptlets/after-install-upgrade ${BUILD_ROOT}/postinst\ninstall -p -m 755 dist/scriptlets/before-remove ${BUILD_ROOT}/prerm\ninstall -p -m 755 dist/scriptlets/after-remove ${BUILD_ROOT}/postrm\n\necho 'Copying control file'\ninstall -p -m 644 dist/amazon-efs-utils.control ${BUILD_ROOT}/control\n\necho 'Copying conffiles'\ninstall -p -m 644 dist/amazon-efs-utils.conffiles ${BUILD_ROOT}/conffiles\n\necho 'Copying manpages'\ninstall -p -m 644 man/mount.efs.8 ${BUILD_ROOT}/usr/share/man/man8/mount.efs.8\n\necho 'Creating deb binary file'\necho '2.0'> ${BUILD_ROOT}/debian-binary\n\necho 'Setting permissions'\nfind ${BUILD_ROOT} -type d | xargs chmod 755;\n\necho 'Creating tar'\ncd ${BUILD_ROOT}\ntar czf control.tar.gz control conffiles postinst prerm postrm --owner=0 --group=0\ntar czf data.tar.gz etc sbin usr var --owner=0 --group=0\ncd ${BASE_DIR}\n\necho 'Building deb'\nDEB=${BUILD_ROOT}/amazon-efs-utils-${VERSION}-${RELEASE}_all.deb\nar r ${DEB} ${BUILD_ROOT}/debian-binary\nar r ${DEB} ${BUILD_ROOT}/control.tar.gz\nar r ${DEB} ${BUILD_ROOT}/data.tar.gz\n\necho 'Copying deb to output directory'\ncp ${BUILD_ROOT}/amazon-efs-utils*deb build/\n", "#\n# Copyright 2017-2018 Amazon.com, Inc. and its affiliates. All Rights Reserved.\n#\n# Licensed under the MIT License. See the LICENSE accompanying this file\n# for the specific language governing permissions and limitations under\n# the License.\n#\n\n[global]\nversion=1.34.4\nrelease=1\n", "Package: amazon-efs-utils\nArchitecture: all\nVersion: 1.34.4\nSection: utils\nDepends: python3, nfs-common, stunnel4 (>= 4.56), openssl (>= 1.0.2), util-linux\nPriority: optional\nCopyright: MIT License\nMaintainer: Amazon.com, Inc. <efs-utils@amazon.com>\nDescription: This package provides utilities for simplifying the use of EFS file systems\n", "#!/usr/bin/env python3\n#\n# Copyright 2017-2018 Amazon.com, Inc. and its affiliates. All Rights Reserved.\n#\n# Licensed under the MIT License. See the LICENSE accompanying this file\n# for the specific language governing permissions and limitations under\n# the License.\n#\n#\n# Copy this script to /sbin/mount.efs and make sure it is executable.\n#\n# You will be able to mount an EFS file system by its short name, by adding it\n# to /etc/fstab. The syntax of an fstab entry is:\n#\n# [Device] [Mount Point] [File System Type] [Options] [Dump] [Pass]\n#\n# Add an entry like this:\n#\n#   fs-deadbeef     /mount_point    efs     _netdev         0   0\n#\n# Using the 'efs' type will cause '/sbin/mount.efs' to be called by 'mount -a'\n# for this file system. The '_netdev' option tells the init system that the\n# 'efs' type is a networked file system type. This has been tested with systemd\n# (Amazon Linux 2, CentOS 7, RHEL 7, Debian 9, and Ubuntu 16.04), and upstart\n# (Amazon Linux 2017.09).\n#\n# Once there is an entry in fstab, the file system can be mounted with:\n#\n#   sudo mount /mount_point\n#\n# The script will add recommended mount options, if not provided in fstab.\n\nimport base64\nimport errno\nimport hashlib\nimport hmac\nimport json\nimport logging\nimport os\nimport platform\nimport pwd\nimport random\nimport re\nimport socket\nimport subprocess\nimport sys\nimport threading\nimport time\nfrom contextlib import contextmanager\nfrom datetime import datetime, timedelta\nfrom logging.handlers import RotatingFileHandler\n\ntry:\n    from configparser import ConfigParser, NoOptionError, NoSectionError\nexcept ImportError:\n    import ConfigParser\n    from ConfigParser import NoOptionError, NoSectionError\n\ntry:\n    from urllib.parse import quote_plus\nexcept ImportError:\n    from urllib import quote_plus\n\ntry:\n    from urllib.error import HTTPError, URLError\n    from urllib.parse import urlencode\n    from urllib.request import Request, urlopen\nexcept ImportError:\n    from urllib import urlencode\n\n    from urllib2 import HTTPError, HTTPHandler, Request, URLError, build_opener, urlopen\n\ntry:\n    import botocore.config\n    import botocore.session\n    from botocore.exceptions import (\n        ClientError,\n        EndpointConnectionError,\n        NoCredentialsError,\n        ProfileNotFound,\n    )\n\n    BOTOCORE_PRESENT = True\nexcept ImportError:\n    BOTOCORE_PRESENT = False\n\n\nVERSION = \"1.34.4\"\nSERVICE = \"elasticfilesystem\"\n\nAMAZON_LINUX_2_RELEASE_ID = \"Amazon Linux release 2 (Karoo)\"\nAMAZON_LINUX_2_PRETTY_NAME = \"Amazon Linux 2\"\nAMAZON_LINUX_2_RELEASE_VERSIONS = [\n    AMAZON_LINUX_2_RELEASE_ID,\n    AMAZON_LINUX_2_PRETTY_NAME,\n]\n\nCLONE_NEWNET = 0x40000000\nCONFIG_FILE = \"/etc/amazon/efs/efs-utils.conf\"\nCONFIG_SECTION = \"mount\"\nCLIENT_INFO_SECTION = \"client-info\"\nCLIENT_SOURCE_STR_LEN_LIMIT = 100\n# Cloudwatchlog agent dict includes cloudwatchlog botocore client, cloudwatchlog group name, cloudwatchlog stream name\nCLOUDWATCHLOG_AGENT = None\nCLOUDWATCH_LOG_SECTION = \"cloudwatch-log\"\nDEFAULT_CLOUDWATCH_LOG_GROUP = \"/aws/efs/utils\"\nDEFAULT_FALLBACK_ENABLED = True\nDEFAULT_RETENTION_DAYS = 14\nDEFAULT_UNKNOWN_VALUE = \"unknown\"\n# 50ms\nDEFAULT_TIMEOUT = 0.05\nDEFAULT_MACOS_VALUE = \"macos\"\nDEFAULT_NFS_MOUNT_COMMAND_RETRY_COUNT = 3\nDEFAULT_NFS_MOUNT_COMMAND_TIMEOUT_SEC = 15\nDISABLE_FETCH_EC2_METADATA_TOKEN_ITEM = \"disable_fetch_ec2_metadata_token\"\nFALLBACK_TO_MOUNT_TARGET_IP_ADDRESS_ITEM = (\n    \"fall_back_to_mount_target_ip_address_enabled\"\n)\nINSTANCE_IDENTITY = None\nRETRYABLE_ERRORS = [\"reset by peer\"]\nOPTIMIZE_READAHEAD_ITEM = \"optimize_readahead\"\n\nLOG_DIR = \"/var/log/amazon/efs\"\nLOG_FILE = \"mount.log\"\n\nSTATE_FILE_DIR = \"/var/run/efs\"\n\nPRIVATE_KEY_FILE = \"/etc/amazon/efs/privateKey.pem\"\nDATE_ONLY_FORMAT = \"%Y%m%d\"\nSIGV4_DATETIME_FORMAT = \"%Y%m%dT%H%M%SZ\"\nCERT_DATETIME_FORMAT = \"%y%m%d%H%M%SZ\"\n\nAWS_CREDENTIALS_FILE = os.path.expanduser(\n    os.path.join(\"~\" + pwd.getpwuid(os.getuid()).pw_name, \".aws\", \"credentials\")\n)\nAWS_CONFIG_FILE = os.path.expanduser(\n    os.path.join(\"~\" + pwd.getpwuid(os.getuid()).pw_name, \".aws\", \"config\")\n)\n\nCA_CONFIG_BODY = \"\"\"dir = %s\nRANDFILE = $dir/database/.rand\n\n[ ca ]\ndefault_ca = local_ca\n\n[ local_ca ]\ndatabase = $dir/database/index.txt\nserial = $dir/database/serial\nprivate_key = %s\ncert = $dir/certificate.pem\nnew_certs_dir = $dir/certs\ndefault_md = sha256\npreserve = no\npolicy = efsPolicy\nx509_extensions = v3_ca\n\n[ efsPolicy ]\nCN = supplied\n\n[ req ]\nprompt = no\ndistinguished_name = req_distinguished_name\n\n[ req_distinguished_name ]\nCN = %s\n\n%s\n\n%s\n\n%s\n\"\"\"\n\n# SigV4 Auth\nALGORITHM = \"AWS4-HMAC-SHA256\"\nAWS4_REQUEST = \"aws4_request\"\n\nHTTP_REQUEST_METHOD = \"GET\"\nCANONICAL_URI = \"/\"\nCANONICAL_HEADERS_DICT = {\"host\": \"%s\"}\nCANONICAL_HEADERS = \"\\n\".join(\n    [\"%s:%s\" % (k, v) for k, v in sorted(CANONICAL_HEADERS_DICT.items())]\n)\nSIGNED_HEADERS = \";\".join(CANONICAL_HEADERS_DICT.keys())\nREQUEST_PAYLOAD = \"\"\n\nFS_ID_RE = re.compile(\"^(?P<fs_id>fs-[0-9a-f]+)$\")\nEFS_FQDN_RE = re.compile(\n    r\"^((?P<az>[a-z0-9-]+)\\.)?(?P<fs_id>fs-[0-9a-f]+)\\.efs\\.\"\n    r\"(?P<region>[a-z0-9-]+)\\.(?P<dns_name_suffix>[a-z0-9.]+)$\"\n)\nAP_ID_RE = re.compile(\"^fsap-[0-9a-f]{17}$\")\n\nCREDENTIALS_KEYS = [\"AccessKeyId\", \"SecretAccessKey\", \"Token\"]\nECS_TASK_METADATA_API = \"http://169.254.170.2\"\nSTS_ENDPOINT_URL_FORMAT = \"https://sts.{}.amazonaws.com/\"\nINSTANCE_METADATA_TOKEN_URL = \"http://169.254.169.254/latest/api/token\"\nINSTANCE_METADATA_SERVICE_URL = (\n    \"http://169.254.169.254/latest/dynamic/instance-identity/document/\"\n)\nINSTANCE_IAM_URL = \"http://169.254.169.254/latest/meta-data/iam/security-credentials/\"\nNAMED_PROFILE_HELP_URL = (\n    \"https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-profiles.html\"\n)\nCONFIG_FILE_SETTINGS_HELP_URL = (\n    \"https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-files.html\"\n    \"#cli-configure-files-settings\"\n)\n\nSECURITY_CREDS_ECS_URI_HELP_URL = (\n    \"https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task-iam-roles.html\"\n)\nSECURITY_CREDS_WEBIDENTITY_HELP_URL = \"https://docs.aws.amazon.com/eks/latest/userguide/iam-roles-for-service-accounts.html\"\nSECURITY_CREDS_IAM_ROLE_HELP_URL = (\n    \"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/iam-roles-for-amazon-ec2.html\"\n)\n\nDEFAULT_STUNNEL_VERIFY_LEVEL = 2\nDEFAULT_STUNNEL_CAFILE = \"/etc/amazon/efs/efs-utils.crt\"\n\nNOT_BEFORE_MINS = 15\nNOT_AFTER_HOURS = 3\n\nEFS_ONLY_OPTIONS = [\n    \"accesspoint\",\n    \"awscredsuri\",\n    \"awsprofile\",\n    \"az\",\n    \"cafile\",\n    \"iam\",\n    \"mounttargetip\",\n    \"netns\",\n    \"noocsp\",\n    \"notls\",\n    \"ocsp\",\n    \"tls\",\n    \"tlsport\",\n    \"verify\",\n]\n\nUNSUPPORTED_OPTIONS = [\"capath\"]\n\nSTUNNEL_GLOBAL_CONFIG = {\n    \"fips\": \"no\",\n    \"foreground\": \"yes\",\n    \"socket\": [\n        \"l:SO_REUSEADDR=yes\",\n        \"a:SO_BINDTODEVICE=lo\",\n    ],\n}\n\nSTUNNEL_EFS_CONFIG = {\n    \"client\": \"yes\",\n    \"accept\": \"127.0.0.1:%s\",\n    \"connect\": \"%s:2049\",\n    \"sslVersion\": \"TLSv1.2\",\n    \"renegotiation\": \"no\",\n    \"TIMEOUTbusy\": \"20\",\n    \"TIMEOUTclose\": \"0\",\n    \"TIMEOUTidle\": \"70\",\n    \"delay\": \"yes\",\n}\n\nWATCHDOG_SERVICE = \"amazon-efs-mount-watchdog\"\n# MacOS instances use plist files. This files needs to be loaded on launchctl (init system of MacOS)\nWATCHDOG_SERVICE_PLIST_PATH = \"/Library/LaunchAgents/amazon-efs-mount-watchdog.plist\"\nSYSTEM_RELEASE_PATH = \"/etc/system-release\"\nOS_RELEASE_PATH = \"/etc/os-release\"\nMACOS_BIG_SUR_RELEASE = \"macOS-11\"\nMACOS_MONTEREY_RELEASE = \"macOS-12\"\n\n# Multiplier for max read ahead buffer size\n# Set default as 15 aligning with prior linux kernel 5.4\nDEFAULT_NFS_MAX_READAHEAD_MULTIPLIER = 15\nNFS_READAHEAD_CONFIG_PATH_FORMAT = \"/sys/class/bdi/%s:%s/read_ahead_kb\"\nNFS_READAHEAD_OPTIMIZE_LINUX_KERNEL_MIN_VERSION = [5, 4]\n\n# MacOS does not support the property of Socket SO_BINDTODEVICE in stunnel configuration\nSKIP_NO_SO_BINDTODEVICE_RELEASES = [MACOS_BIG_SUR_RELEASE, MACOS_MONTEREY_RELEASE]\n\nMAC_OS_PLATFORM_LIST = [\"darwin\"]\n# MacOS Versions : Monterey - 21.*, Big Sur - 20.*, Catalina - 19.*, Mojave - 18.*. Catalina and Mojave are not supported for now\nMAC_OS_SUPPORTED_VERSION_LIST = [\"20\", \"21\"]\n\nAWS_FIPS_ENDPOINT_CONFIG_ENV = \"AWS_USE_FIPS_ENDPOINT\"\nECS_URI_ENV = \"AWS_CONTAINER_CREDENTIALS_RELATIVE_URI\"\nWEB_IDENTITY_ROLE_ARN_ENV = \"AWS_ROLE_ARN\"\nWEB_IDENTITY_TOKEN_FILE_ENV = \"AWS_WEB_IDENTITY_TOKEN_FILE\"\n\n\ndef errcheck(ret, func, args):\n    from ctypes import get_errno\n\n    if ret == -1:\n        e = get_errno()\n        raise OSError(e, os.strerror(e))\n\n\ndef setns(fd, nstype):\n    from ctypes import CDLL\n\n    libc = CDLL(\"libc.so.6\", use_errno=True)\n    libc.setns.errcheck = errcheck\n    if hasattr(fd, \"fileno\"):\n        fd = fd.fileno()\n    return libc.setns(fd, nstype)\n\n\nclass NetNS(object):\n    # Open sockets from given network namespace: stackoverflow.com/questions/28846059\n    def __init__(self, nspath):\n        self.original_nspath = \"/proc/%d/ns/net\" % os.getpid()\n        self.target_nspath = nspath\n\n    def __enter__(self):\n        self.original_namespace = open(self.original_nspath)\n        with open(self.target_nspath) as fd:\n            setns(fd, CLONE_NEWNET)\n\n    def __exit__(self, *args):\n        setns(self.original_namespace, CLONE_NEWNET)\n        self.original_namespace.close()\n\n\nclass FallbackException(Exception):\n    \"\"\"Exception raised for errors happens when dns resolve and fallback to mount target ip address attempt both fail\n\n    Attributes:\n        message -- explanation of the error\n    \"\"\"\n\n    def __init__(self, message):\n        self.message = message\n        super().__init__(self.message)\n\n\ndef fatal_error(user_message, log_message=None, exit_code=1):\n    if log_message is None:\n        log_message = user_message\n\n    sys.stderr.write(\"%s\\n\" % user_message)\n    logging.error(log_message)\n    publish_cloudwatch_log(CLOUDWATCHLOG_AGENT, \"Mount failed, %s\" % log_message)\n    sys.exit(exit_code)\n\n\ndef get_target_region(config):\n    def _fatal_error(message):\n        fatal_error(\n            'Error retrieving region. Please set the \"region\" parameter '\n            \"in the efs-utils configuration file.\",\n            message,\n        )\n\n    try:\n        return config.get(CONFIG_SECTION, \"region\")\n    except NoOptionError:\n        pass\n\n    try:\n        return get_region_from_instance_metadata(config)\n    except Exception as e:\n        metadata_exception = e\n        logging.warning(\n            \"Region not found in config file and metadata service call failed, falling back \"\n            'to legacy \"dns_name_format\" check'\n        )\n\n    try:\n        region = get_region_from_legacy_dns_format(config)\n        sys.stdout.write(\n            'Warning: region obtained from \"dns_name_format\" field. Please set the \"region\" '\n            \"parameter in the efs-utils configuration file.\"\n        )\n        return region\n    except Exception:\n        logging.warning('Legacy check for region in \"dns_name_format\" failed')\n\n    _fatal_error(metadata_exception)\n\n\ndef get_target_az(config, options):\n    if \"az\" in options:\n        return options.get(\"az\")\n\n    try:\n        return get_az_from_instance_metadata(config)\n    except Exception as e:\n        logging.warning(\"Get AZ via metadata service call failed, %s\", e)\n\n    return None\n\n\ndef get_region_from_instance_metadata(config):\n    instance_identity = get_instance_identity_info_from_instance_metadata(\n        config, \"region\"\n    )\n\n    if not instance_identity:\n        raise Exception(\n            \"Cannot retrieve region from instance_metadata. \"\n            \"Please set the 'region' parameter in the efs-utils configuration file.\"\n        )\n\n    return instance_identity\n\n\ndef get_az_from_instance_metadata(config):\n    instance_identity = get_instance_identity_info_from_instance_metadata(\n        config, \"availabilityZone\"\n    )\n\n    if not instance_identity:\n        raise Exception(\"Cannot retrieve az from instance_metadata\")\n\n    return instance_identity\n\n\ndef get_instance_identity_info_from_instance_metadata(config, property):\n    logging.debug(\"Retrieve property %s from instance metadata\", property)\n    ec2_metadata_unsuccessful_resp = (\n        \"Unsuccessful retrieval of EC2 metadata at %s.\" % INSTANCE_METADATA_SERVICE_URL\n    )\n    ec2_metadata_url_error_msg = (\n        \"Unable to reach %s to retrieve EC2 instance metadata.\"\n        % INSTANCE_METADATA_SERVICE_URL\n    )\n\n    global INSTANCE_IDENTITY\n    if INSTANCE_IDENTITY:\n        logging.debug(\n            \"Instance metadata already retrieved in previous call, use the cached values.\"\n        )\n        instance_identity = INSTANCE_IDENTITY\n    else:\n        instance_identity = url_request_helper(\n            config,\n            INSTANCE_METADATA_SERVICE_URL,\n            ec2_metadata_unsuccessful_resp,\n            ec2_metadata_url_error_msg,\n        )\n        INSTANCE_IDENTITY = instance_identity\n\n    if instance_identity:\n        try:\n            return instance_identity[property]\n        except KeyError as e:\n            logging.warning(\n                \"%s not present in %s: %s\" % (property, instance_identity, e)\n            )\n        except TypeError as e:\n            logging.warning(\n                \"response %s is not a json object: %s\" % (instance_identity, e)\n            )\n\n    return None\n\n\ndef get_region_from_legacy_dns_format(config):\n    \"\"\"\n    For backwards compatibility check dns_name_format to obtain the target region. This functionality\n    should only be used if region is not present in the config file and metadata calls fail.\n    \"\"\"\n    dns_name_format = config.get(CONFIG_SECTION, \"dns_name_format\")\n    if \"{region}\" not in dns_name_format:\n        split_dns_name_format = dns_name_format.split(\".\")\n        if \"{dns_name_suffix}\" in dns_name_format:\n            return split_dns_name_format[-2]\n        elif \"amazonaws.com\" in dns_name_format:\n            return split_dns_name_format[-3]\n    raise Exception(\"Region not found in dns_name_format\")\n\n\ndef get_boolean_config_item_value(\n    config, config_section, config_item, default_value, emit_warning_message=True\n):\n    warning_message = None\n    if not config.has_section(config_section):\n        warning_message = (\n            \"Warning: config file does not have section %s.\" % config_section\n        )\n    elif not config.has_option(config_section, config_item):\n        warning_message = (\n            \"Warning: config file does not have %s item in section %s.\"\n            % (config_item, config_section)\n        )\n\n    if warning_message:\n        if emit_warning_message:\n            sys.stdout.write(\n                \"%s. You should be able to find a new config file in the same folder as current config file %s. \"\n                \"Consider update the new config file to latest config file. Use the default value [%s = %s].\"\n                % (warning_message, CONFIG_FILE, config_item, default_value)\n            )\n        return default_value\n    return config.getboolean(config_section, config_item)\n\n\ndef fetch_ec2_metadata_token_disabled(config):\n    return get_boolean_config_item_value(\n        config,\n        CONFIG_SECTION,\n        DISABLE_FETCH_EC2_METADATA_TOKEN_ITEM,\n        default_value=False,\n    )\n\n\ndef get_aws_ec2_metadata_token(timeout=DEFAULT_TIMEOUT):\n    # Normally the session token is fetched within 10ms, setting a timeout of 50ms here to abort the request\n    # and return None if the token has not returned within 50ms\n    try:\n        opener = build_opener(HTTPHandler)\n        request = Request(INSTANCE_METADATA_TOKEN_URL)\n\n        request.add_header(\"X-aws-ec2-metadata-token-ttl-seconds\", \"21600\")\n        request.get_method = lambda: \"PUT\"\n        try:\n            res = opener.open(request, timeout=timeout)\n            return res.read()\n        except socket.timeout:\n            exception_message = \"Timeout when getting the aws ec2 metadata token\"\n        except HTTPError as e:\n            exception_message = \"Failed to fetch token due to %s\" % e\n        except Exception as e:\n            exception_message = (\n                \"Unknown error when fetching aws ec2 metadata token, %s\" % e\n            )\n        logging.debug(exception_message)\n        return None\n    except NameError:\n        headers = {\"X-aws-ec2-metadata-token-ttl-seconds\": \"21600\"}\n        req = Request(INSTANCE_METADATA_TOKEN_URL, headers=headers, method=\"PUT\")\n        try:\n            res = urlopen(req, timeout=timeout)\n            return res.read()\n        except socket.timeout:\n            exception_message = \"Timeout when getting the aws ec2 metadata token\"\n        except HTTPError as e:\n            exception_message = \"Failed to fetch token due to %s\" % e\n        except Exception as e:\n            exception_message = (\n                \"Unknown error when fetching aws ec2 metadata token, %s\" % e\n            )\n        logging.debug(exception_message)\n        return None\n\n\ndef get_aws_security_credentials(\n    config, use_iam, region, awsprofile=None, aws_creds_uri=None\n):\n    \"\"\"\n    Lookup AWS security credentials (access key ID and secret access key). Adapted credentials provider chain from:\n    https://boto3.amazonaws.com/v1/documentation/api/latest/guide/configuration.html and\n    https://docs.aws.amazon.com/sdk-for-java/v1/developer-guide/credentials.html\n    \"\"\"\n    if not use_iam:\n        return None, None\n\n    # attempt to lookup AWS security credentials through the credentials URI the ECS agent generated\n    if aws_creds_uri:\n        return get_aws_security_credentials_from_ecs(config, aws_creds_uri, True)\n\n    # attempt to lookup AWS security credentials in AWS credentials file (~/.aws/credentials)\n    # and configs file (~/.aws/config) with given awsprofile\n    # if the credentials are not present in above filepath, and botocore is present, attempt to assume the given awsprofile\n    if awsprofile:\n        return get_aws_security_credentials_from_awsprofile(awsprofile, True)\n\n    # attempt to lookup AWS security credentials through AWS_CONTAINER_CREDENTIALS_RELATIVE_URI environment variable\n    if ECS_URI_ENV in os.environ:\n        credentials, credentials_source = get_aws_security_credentials_from_ecs(\n            config, os.environ[ECS_URI_ENV], False\n        )\n        if credentials and credentials_source:\n            return credentials, credentials_source\n\n    # attempt to lookup AWS security credentials through AssumeRoleWithWebIdentity\n    # (e.g. for IAM Role for Service Accounts (IRSA) approach on EKS)\n    if (\n        WEB_IDENTITY_ROLE_ARN_ENV in os.environ\n        and WEB_IDENTITY_TOKEN_FILE_ENV in os.environ\n    ):\n        credentials, credentials_source = get_aws_security_credentials_from_webidentity(\n            config,\n            os.environ[WEB_IDENTITY_ROLE_ARN_ENV],\n            os.environ[WEB_IDENTITY_TOKEN_FILE_ENV],\n            region,\n            False,\n        )\n        if credentials and credentials_source:\n            return credentials, credentials_source\n\n    # attempt to lookup AWS security credentials with IAM role name attached to instance\n    # through IAM role name security credentials lookup uri\n    iam_role_name = get_iam_role_name(config)\n    if iam_role_name:\n        (\n            credentials,\n            credentials_source,\n        ) = get_aws_security_credentials_from_instance_metadata(config, iam_role_name)\n        if credentials and credentials_source:\n            return credentials, credentials_source\n\n    error_msg = (\n        \"AWS Access Key ID and Secret Access Key are not found in AWS credentials file (%s), config file (%s), \"\n        \"from ECS credentials relative uri, or from the instance security credentials service\"\n        % (AWS_CREDENTIALS_FILE, AWS_CONFIG_FILE)\n    )\n    fatal_error(error_msg, error_msg)\n\n\ndef get_aws_security_credentials_from_awsprofile(awsprofile, is_fatal=False):\n    for file_path in [AWS_CREDENTIALS_FILE, AWS_CONFIG_FILE]:\n        if os.path.exists(file_path):\n            credentials = credentials_file_helper(file_path, awsprofile)\n            if credentials[\"AccessKeyId\"]:\n                logging.debug(\"Retrieved credentials from %s\" % file_path)\n                return credentials, os.path.basename(file_path) + \":\" + awsprofile\n\n    # If credentials are not defined in the aws credentials and config file, attempt to assume the named profile\n    credentials = botocore_credentials_helper(awsprofile)\n    if credentials[\"AccessKeyId\"]:\n        logging.debug(\"Retrieved credentials from assumed profile %s\" % awsprofile)\n        return credentials, \"named_profile:\" + awsprofile\n\n    # Fail if credentials cannot be fetched from the given awsprofile\n    if is_fatal:\n        log_message = (\n            \"AWS security credentials not found in %s or %s under named profile [%s]\"\n            % (AWS_CREDENTIALS_FILE, AWS_CONFIG_FILE, awsprofile)\n        )\n        fatal_error(log_message)\n    else:\n        return None, None\n\n\ndef get_aws_security_credentials_from_ecs(config, aws_creds_uri, is_fatal=False):\n    ecs_uri = ECS_TASK_METADATA_API + aws_creds_uri\n    ecs_unsuccessful_resp = (\n        \"Unsuccessful retrieval of AWS security credentials at %s.\" % ecs_uri\n    )\n    ecs_url_error_msg = (\n        \"Unable to reach %s to retrieve AWS security credentials. See %s for more info.\"\n        % (ecs_uri, SECURITY_CREDS_ECS_URI_HELP_URL)\n    )\n    ecs_security_dict = url_request_helper(\n        config, ecs_uri, ecs_unsuccessful_resp, ecs_url_error_msg\n    )\n\n    if ecs_security_dict and all(k in ecs_security_dict for k in CREDENTIALS_KEYS):\n        return ecs_security_dict, \"ecs:\" + aws_creds_uri\n\n    # Fail if credentials cannot be fetched from the given aws_creds_uri\n    if is_fatal:\n        fatal_error(ecs_unsuccessful_resp, ecs_unsuccessful_resp)\n    else:\n        return None, None\n\n\ndef get_aws_security_credentials_from_webidentity(\n    config, role_arn, token_file, region, is_fatal=False\n):\n    try:\n        with open(token_file, \"r\") as f:\n            token = f.read()\n    except Exception as e:\n        if is_fatal:\n            unsuccessful_resp = \"Error reading token file %s: %s\" % (token_file, e)\n            fatal_error(unsuccessful_resp, unsuccessful_resp)\n        else:\n            return None, None\n\n    STS_ENDPOINT_URL = STS_ENDPOINT_URL_FORMAT.format(region)\n    webidentity_url = (\n        STS_ENDPOINT_URL\n        + \"?\"\n        + urlencode(\n            {\n                \"Version\": \"2011-06-15\",\n                \"Action\": \"AssumeRoleWithWebIdentity\",\n                \"RoleArn\": role_arn,\n                \"RoleSessionName\": \"efs-mount-helper\",\n                \"WebIdentityToken\": token,\n            }\n        )\n    )\n\n    unsuccessful_resp = (\n        \"Unsuccessful retrieval of AWS security credentials at %s.\" % STS_ENDPOINT_URL\n    )\n    url_error_msg = (\n        \"Unable to reach %s to retrieve AWS security credentials. See %s for more info.\"\n        % (STS_ENDPOINT_URL, SECURITY_CREDS_WEBIDENTITY_HELP_URL)\n    )\n    resp = url_request_helper(\n        config,\n        webidentity_url,\n        unsuccessful_resp,\n        url_error_msg,\n        headers={\"Accept\": \"application/json\"},\n    )\n\n    if resp:\n        creds = (\n            resp.get(\"AssumeRoleWithWebIdentityResponse\", {})\n            .get(\"AssumeRoleWithWebIdentityResult\", {})\n            .get(\"Credentials\", {})\n        )\n        if all(k in creds for k in [\"AccessKeyId\", \"SecretAccessKey\", \"SessionToken\"]):\n            return {\n                \"AccessKeyId\": creds[\"AccessKeyId\"],\n                \"SecretAccessKey\": creds[\"SecretAccessKey\"],\n                \"Token\": creds[\"SessionToken\"],\n            }, \"webidentity:\" + \",\".join([role_arn, token_file])\n\n    # Fail if credentials cannot be fetched from the given aws_creds_uri\n    if is_fatal:\n        fatal_error(unsuccessful_resp, unsuccessful_resp)\n    else:\n        return None, None\n\n\ndef get_aws_security_credentials_from_instance_metadata(config, iam_role_name):\n    security_creds_lookup_url = INSTANCE_IAM_URL + iam_role_name\n    unsuccessful_resp = (\n        \"Unsuccessful retrieval of AWS security credentials at %s.\"\n        % security_creds_lookup_url\n    )\n    url_error_msg = (\n        \"Unable to reach %s to retrieve AWS security credentials. See %s for more info.\"\n        % (security_creds_lookup_url, SECURITY_CREDS_IAM_ROLE_HELP_URL)\n    )\n    iam_security_dict = url_request_helper(\n        config, security_creds_lookup_url, unsuccessful_resp, url_error_msg\n    )\n\n    if iam_security_dict and all(k in iam_security_dict for k in CREDENTIALS_KEYS):\n        return iam_security_dict, \"metadata:\"\n    else:\n        return None, None\n\n\ndef get_iam_role_name(config):\n    iam_role_unsuccessful_resp = (\n        \"Unsuccessful retrieval of IAM role name at %s.\" % INSTANCE_IAM_URL\n    )\n    iam_role_url_error_msg = (\n        \"Unable to reach %s to retrieve IAM role name. See %s for more info.\"\n        % (INSTANCE_IAM_URL, SECURITY_CREDS_IAM_ROLE_HELP_URL)\n    )\n    iam_role_name = url_request_helper(\n        config, INSTANCE_IAM_URL, iam_role_unsuccessful_resp, iam_role_url_error_msg\n    )\n    return iam_role_name\n\n\ndef credentials_file_helper(file_path, awsprofile):\n    aws_credentials_configs = read_config(file_path)\n    credentials = {\"AccessKeyId\": None, \"SecretAccessKey\": None, \"Token\": None}\n\n    try:\n        access_key = aws_credentials_configs.get(awsprofile, \"aws_access_key_id\")\n        secret_key = aws_credentials_configs.get(awsprofile, \"aws_secret_access_key\")\n        session_token = aws_credentials_configs.get(awsprofile, \"aws_session_token\")\n\n        credentials[\"AccessKeyId\"] = access_key\n        credentials[\"SecretAccessKey\"] = secret_key\n        credentials[\"Token\"] = session_token\n    except NoOptionError as e:\n        if \"aws_access_key_id\" in str(e) or \"aws_secret_access_key\" in str(e):\n            logging.debug(\n                \"aws_access_key_id or aws_secret_access_key not found in %s under named profile [%s]\",\n                file_path,\n                awsprofile,\n            )\n        if \"aws_session_token\" in str(e):\n            logging.debug(\"aws_session_token not found in %s\", file_path)\n            credentials[\"AccessKeyId\"] = aws_credentials_configs.get(\n                awsprofile, \"aws_access_key_id\"\n            )\n            credentials[\"SecretAccessKey\"] = aws_credentials_configs.get(\n                awsprofile, \"aws_secret_access_key\"\n            )\n    except NoSectionError:\n        logging.debug(\"No [%s] section found in config file %s\", awsprofile, file_path)\n\n    return credentials\n\n\ndef botocore_credentials_helper(awsprofile):\n    # This method retrieves credentials from aws named profile using botocore, botocore will then assume that named profile, get\n    # and return the credentials\n    credentials = {\"AccessKeyId\": None, \"SecretAccessKey\": None, \"Token\": None}\n    if not BOTOCORE_PRESENT:\n        logging.error(\n            \"Cannot find credentials for %s, to assume this profile, please install botocore first.\"\n            % awsprofile\n        )\n        return credentials\n    session = botocore.session.get_session()\n    session.set_config_variable(\"profile\", awsprofile)\n\n    try:\n        frozen_credentials = session.get_credentials().get_frozen_credentials()\n    except ProfileNotFound as e:\n        fatal_error(\n            \"%s, please add the [profile %s] section in the aws config file following %s and %s.\"\n            % (e, awsprofile, NAMED_PROFILE_HELP_URL, CONFIG_FILE_SETTINGS_HELP_URL)\n        )\n\n    credentials[\"AccessKeyId\"] = frozen_credentials.access_key\n    credentials[\"SecretAccessKey\"] = frozen_credentials.secret_key\n    credentials[\"Token\"] = frozen_credentials.token\n    return credentials\n\n\ndef get_aws_profile(options, use_iam):\n    awsprofile = options.get(\"awsprofile\")\n    if not awsprofile and use_iam:\n        for file_path in [AWS_CREDENTIALS_FILE, AWS_CONFIG_FILE]:\n            aws_credentials_configs = read_config(file_path)\n            # check if aws access key id is found under [default] section in current file and return 'default' if so\n            try:\n                access_key = aws_credentials_configs.get(\"default\", \"aws_access_key_id\")\n                if access_key is not None:\n                    return \"default\"\n            except (NoSectionError, NoOptionError):\n                continue\n\n    return awsprofile\n\n\ndef is_instance_metadata_url(url):\n    return url.startswith(\"http://169.254.169.254\")\n\n\ndef url_request_helper(config, url, unsuccessful_resp, url_error_msg, headers={}):\n    try:\n        req = Request(url)\n        for k, v in headers.items():\n            req.add_header(k, v)\n\n        if not fetch_ec2_metadata_token_disabled(config) and is_instance_metadata_url(\n            url\n        ):\n            # https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/configuring-instance-metadata-service.html\n            # IMDSv1 is a request/response method to access instance metadata\n            # IMDSv2 is a session-oriented method to access instance metadata\n            # We expect the token retrieve will fail in bridge networking environment (e.g. container) since the default hop\n            # limit for getting the token is 1. If the token retrieve does timeout, we fallback to use IMDSv1 instead\n            token = get_aws_ec2_metadata_token()\n            if token:\n                req.add_header(\"X-aws-ec2-metadata-token\", token)\n\n        request_resp = urlopen(req, timeout=1)\n\n        return get_resp_obj(request_resp, url, unsuccessful_resp)\n    except socket.timeout:\n        err_msg = \"Request timeout\"\n    except HTTPError as e:\n        # For instance enable with IMDSv2 and fetch token disabled, Unauthorized 401 error will be thrown\n        if (\n            e.code == 401\n            and fetch_ec2_metadata_token_disabled(config)\n            and is_instance_metadata_url(url)\n        ):\n            logging.warning(\n                \"Unauthorized request to instance metadata url %s, IMDSv2 is enabled on the instance, while fetching \"\n                \"ec2 metadata token is disabled. Please set the value of config item \"\n                '\"%s\" to \"false\" in config file %s.'\n                % (url, DISABLE_FETCH_EC2_METADATA_TOKEN_ITEM, CONFIG_FILE)\n            )\n        err_msg = \"Unable to reach the url at %s: status=%d, reason is %s\" % (\n            url,\n            e.code,\n            e.reason,\n        )\n    except URLError as e:\n        err_msg = \"Unable to reach the url at %s, reason is %s\" % (url, e.reason)\n\n    if err_msg:\n        logging.debug(\"%s %s\", url_error_msg, err_msg)\n    return None\n\n\ndef get_resp_obj(request_resp, url, unsuccessful_resp):\n    \"\"\"\n    Parse the response of an url request\n\n    :return: If the response result can be parsed into json object, return the json object parsed from the response.\n             Otherwise return the response body in string format.\n    \"\"\"\n\n    if request_resp.getcode() != 200:\n        logging.debug(\n            unsuccessful_resp + \" %s: ResponseCode=%d\", url, request_resp.getcode()\n        )\n        return None\n\n    resp_body = request_resp.read()\n    resp_body_type = type(resp_body)\n    try:\n        if resp_body_type is str:\n            resp_dict = json.loads(resp_body)\n        else:\n            resp_dict = json.loads(\n                resp_body.decode(\n                    request_resp.headers.get_content_charset() or \"us-ascii\"\n                )\n            )\n\n        return resp_dict\n    except ValueError:\n        return resp_body if resp_body_type is str else resp_body.decode(\"utf-8\")\n\n\ndef parse_options(options):\n    opts = {}\n    for o in options.split(\",\"):\n        if \"=\" in o:\n            k, v = o.split(\"=\")\n            opts[k] = v\n        else:\n            opts[o] = None\n    return opts\n\n\ndef get_tls_port_range(config):\n    lower_bound = config.getint(CONFIG_SECTION, \"port_range_lower_bound\")\n    upper_bound = config.getint(CONFIG_SECTION, \"port_range_upper_bound\")\n\n    if lower_bound >= upper_bound:\n        fatal_error(\n            'Configuration option \"port_range_upper_bound\" defined as %d '\n            'must be strictly greater than \"port_range_lower_bound\" defined as %d.'\n            % (upper_bound, lower_bound)\n        )\n\n    return lower_bound, upper_bound\n\n\ndef choose_tls_port_and_get_bind_sock(config, options, state_file_dir):\n    if \"tlsport\" in options:\n        ports_to_try = [int(options[\"tlsport\"])]\n    else:\n        lower_bound, upper_bound = get_tls_port_range(config)\n\n        ports_to_try = list(range(lower_bound, upper_bound))\n\n        # shuffle the ports_to_try to reduce possibility of multiple mounts starting from same port range\n        random.shuffle(ports_to_try)\n\n    if \"netns\" not in options:\n        tls_port_sock = find_tls_port_in_range_and_get_bind_sock(\n            ports_to_try, state_file_dir\n        )\n    else:\n        with NetNS(nspath=options[\"netns\"]):\n            tls_port_sock = find_tls_port_in_range_and_get_bind_sock(\n                ports_to_try, state_file_dir\n            )\n\n    if tls_port_sock:\n        return tls_port_sock\n\n    if \"tlsport\" in options:\n        fatal_error(\n            \"Specified port [%s] is unavailable. Try selecting a different port.\"\n            % options[\"tlsport\"]\n        )\n    else:\n        fatal_error(\n            \"Failed to locate an available port in the range [%d, %d], try specifying a different port range in %s\"\n            % (lower_bound, upper_bound, CONFIG_FILE)\n        )\n\n\ndef find_tls_port_in_range_and_get_bind_sock(ports_to_try, state_file_dir):\n    sock = socket.socket()\n    for tls_port in ports_to_try:\n        mount = find_existing_mount_using_tls_port(state_file_dir, tls_port)\n        if mount:\n            logging.debug(\n                \"Skip binding TLS port %s as it is already assigned to %s\",\n                tls_port,\n                mount,\n            )\n            continue\n        try:\n            logging.info(\"binding %s\", tls_port)\n            sock.bind((\"localhost\", tls_port))\n            return sock\n        except socket.error as e:\n            logging.warning(e)\n            continue\n    sock.close()\n    return None\n\n\ndef find_existing_mount_using_tls_port(state_file_dir, tls_port):\n    if not os.path.exists(state_file_dir):\n        logging.debug(\n            \"State file dir %s does not exist, assuming no existing mount using tls port %s\",\n            state_file_dir,\n            tls_port,\n        )\n        return None\n\n    for fname in os.listdir(state_file_dir):\n        if fname.endswith(\".%s\" % tls_port):\n            return fname\n\n    return None\n\n\ndef is_ocsp_enabled(config, options):\n    if \"ocsp\" in options:\n        return True\n    elif \"noocsp\" in options:\n        return False\n    else:\n        return get_boolean_config_item_value(\n            config, CONFIG_SECTION, \"stunnel_check_cert_validity\", default_value=False\n        )\n\n\ndef get_mount_specific_filename(fs_id, mountpoint, tls_port):\n    return \"%s.%s.%d\" % (\n        fs_id,\n        os.path.abspath(mountpoint).replace(os.sep, \".\").lstrip(\".\"),\n        tls_port,\n    )\n\n\ndef serialize_stunnel_config(config, header=None):\n    lines = []\n\n    if header:\n        lines.append(\"[%s]\" % header)\n\n    for k, v in config.items():\n        if type(v) is list:\n            for item in v:\n                lines.append(\"%s = %s\" % (k, item))\n        else:\n            lines.append(\"%s = %s\" % (k, v))\n\n    return lines\n\n\ndef add_stunnel_ca_options(efs_config, config, options, region):\n    if \"cafile\" in options:\n        stunnel_cafile = options[\"cafile\"]\n    else:\n        try:\n            config_section = get_config_section(config, region)\n            stunnel_cafile = config.get(config_section, \"stunnel_cafile\")\n            logging.debug(\n                \"Using stunnel_cafile %s in config section [%s]\",\n                stunnel_cafile,\n                config_section,\n            )\n        except NoOptionError:\n            logging.debug(\n                \"No CA file configured, using default CA file %s\",\n                DEFAULT_STUNNEL_CAFILE,\n            )\n            stunnel_cafile = DEFAULT_STUNNEL_CAFILE\n\n    if not os.path.exists(stunnel_cafile):\n        fatal_error(\n            \"Failed to find certificate authority file for verification\",\n            'Failed to find CAfile \"%s\"' % stunnel_cafile,\n        )\n\n    efs_config[\"CAfile\"] = stunnel_cafile\n\n\ndef get_config_section(config, region):\n    region_specific_config_section = \"%s.%s\" % (CONFIG_SECTION, region)\n    if config.has_section(region_specific_config_section):\n        config_section = region_specific_config_section\n    else:\n        config_section = CONFIG_SECTION\n    return config_section\n\n\ndef is_stunnel_option_supported(\n    stunnel_output,\n    stunnel_option_name,\n    stunnel_option_value=None,\n    emit_warning_log=True,\n):\n    supported = False\n    for line in stunnel_output:\n        if line.startswith(stunnel_option_name):\n            if not stunnel_option_value:\n                supported = True\n                break\n            elif stunnel_option_value and stunnel_option_value in line:\n                supported = True\n                break\n\n    if not supported and emit_warning_log:\n        if not stunnel_option_value:\n            logging.warning('stunnel does not support \"%s\"', stunnel_option_name)\n        else:\n            logging.warning(\n                'stunnel does not support \"%s\" as value of \"%s\"',\n                stunnel_option_value,\n                stunnel_option_name,\n            )\n\n    return supported\n\n\ndef get_stunnel_options():\n    stunnel_command = [_stunnel_bin(), \"-help\"]\n    proc = subprocess.Popen(\n        stunnel_command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, close_fds=True\n    )\n    proc.wait()\n    _, err = proc.communicate()\n\n    return err.splitlines()\n\n\ndef _stunnel_bin():\n    installation_message = \"Please install it following the instructions at: https://docs.aws.amazon.com/efs/latest/ug/using-amazon-efs-utils.html#upgrading-stunnel\"\n    if get_system_release_version() in AMAZON_LINUX_2_RELEASE_VERSIONS:\n        return find_command_path(\"stunnel5\", installation_message)\n    else:\n        return find_command_path(\"stunnel\", installation_message)\n\n\ndef find_command_path(command, install_method):\n    # If not running on macOS, use linux paths\n    if not check_if_platform_is_mac():\n        env_path = (\n            \"/sbin:/usr/sbin:/usr/local/sbin:/root/bin:/usr/local/bin:/usr/bin:/bin\"\n        )\n    # Homebrew on x86 macOS uses /usr/local/bin; Homebrew on Apple Silicon macOS uses /opt/homebrew/bin since v3.0.0\n    # For more information, see https://brew.sh/2021/02/05/homebrew-3.0.0/\n    else:\n        env_path = \"/opt/homebrew/bin:/usr/local/bin\"\n    os.putenv(\"PATH\", env_path)\n\n    try:\n        path = subprocess.check_output([\"which\", command])\n        return path.strip().decode()\n    except subprocess.CalledProcessError as e:\n        fatal_error(\n            \"Failed to locate %s in %s - %s\" % (command, env_path, install_method), e\n        )\n\n\ndef get_system_release_version():\n    # MacOS does not maintain paths /etc/os-release and /etc/sys-release\n    if check_if_platform_is_mac():\n        return platform.platform()\n\n    try:\n        with open(SYSTEM_RELEASE_PATH) as f:\n            return f.read().strip()\n    except IOError:\n        logging.debug(\"Unable to read %s\", SYSTEM_RELEASE_PATH)\n\n    try:\n        with open(OS_RELEASE_PATH) as f:\n            for line in f:\n                if \"PRETTY_NAME\" in line:\n                    return line.split(\"=\")[1].strip()\n    except IOError:\n        logging.debug(\"Unable to read %s\", OS_RELEASE_PATH)\n\n    return DEFAULT_UNKNOWN_VALUE\n\n\ndef write_stunnel_config_file(\n    config,\n    state_file_dir,\n    fs_id,\n    mountpoint,\n    tls_port,\n    dns_name,\n    verify_level,\n    ocsp_enabled,\n    options,\n    region,\n    log_dir=LOG_DIR,\n    cert_details=None,\n    fallback_ip_address=None,\n):\n    \"\"\"\n    Serializes stunnel configuration to a file. Unfortunately this does not conform to Python's config file format, so we have to\n    hand-serialize it.\n    \"\"\"\n\n    stunnel_options = get_stunnel_options()\n    mount_filename = get_mount_specific_filename(fs_id, mountpoint, tls_port)\n\n    system_release_version = get_system_release_version()\n    global_config = dict(STUNNEL_GLOBAL_CONFIG)\n\n    if is_stunnel_option_supported(\n        stunnel_options, b\"foreground\", b\"quiet\", emit_warning_log=False\n    ):\n        # Do not log to stderr of subprocess in addition to the destinations specified with syslog and output.\n        # Only support in stunnel version 5.25+.\n        global_config[\"foreground\"] = \"quiet\"\n    if any(\n        release in system_release_version\n        for release in SKIP_NO_SO_BINDTODEVICE_RELEASES\n    ):\n        global_config[\"socket\"].remove(\"a:SO_BINDTODEVICE=lo\")\n\n    if get_boolean_config_item_value(\n        config, CONFIG_SECTION, \"stunnel_debug_enabled\", default_value=False\n    ):\n        global_config[\"debug\"] = \"debug\"\n        # If the stunnel debug is enabled, we also redirect stunnel log to stderr to capture any error while launching\n        # the stunnel.\n        global_config[\"foreground\"] = \"yes\"\n        if config.has_option(CONFIG_SECTION, \"stunnel_logs_file\"):\n            global_config[\"output\"] = config.get(\n                CONFIG_SECTION, \"stunnel_logs_file\"\n            ).replace(\"{fs_id}\", fs_id)\n        else:\n            global_config[\"output\"] = os.path.join(\n                log_dir, \"%s.stunnel.log\" % mount_filename\n            )\n    global_config[\"pid\"] = os.path.join(\n        state_file_dir, mount_filename + \"+\", \"stunnel.pid\"\n    )\n    if get_fips_config(config):\n        global_config[\"fips\"] = \"yes\"\n\n    efs_config = dict(STUNNEL_EFS_CONFIG)\n    efs_config[\"accept\"] = efs_config[\"accept\"] % tls_port\n\n    if fallback_ip_address:\n        efs_config[\"connect\"] = efs_config[\"connect\"] % fallback_ip_address\n    else:\n        efs_config[\"connect\"] = efs_config[\"connect\"] % dns_name\n\n    efs_config[\"verify\"] = verify_level\n    if verify_level > 0:\n        add_stunnel_ca_options(efs_config, config, options, region)\n\n    if cert_details:\n        efs_config[\"cert\"] = cert_details[\"certificate\"]\n        efs_config[\"key\"] = cert_details[\"privateKey\"]\n\n    tls_controls_message = (\n        \"WARNING: Your client lacks sufficient controls to properly enforce TLS. Please upgrade stunnel, \"\n        'or disable \"%%s\" in %s.\\nSee %s for more detail.'\n        % (CONFIG_FILE, \"https://docs.aws.amazon.com/console/efs/troubleshooting-tls\")\n    )\n\n    if get_boolean_config_item_value(\n        config, CONFIG_SECTION, \"stunnel_check_cert_hostname\", default_value=True\n    ):\n        if is_stunnel_option_supported(stunnel_options, b\"checkHost\"):\n            # Stunnel checkHost option checks if the specified DNS host name or wildcard matches any of the provider in peer\n            # certificate's CN fields, after introducing the AZ field in dns name, the host name in the stunnel config file\n            # is not valid, remove the az info there\n            efs_config[\"checkHost\"] = dns_name[dns_name.index(fs_id) :]\n        else:\n            fatal_error(tls_controls_message % \"stunnel_check_cert_hostname\")\n\n    # Only use the config setting if the override is not set\n    if ocsp_enabled:\n        if is_stunnel_option_supported(stunnel_options, b\"OCSPaia\"):\n            efs_config[\"OCSPaia\"] = \"yes\"\n        else:\n            fatal_error(tls_controls_message % \"stunnel_check_cert_validity\")\n\n    # If the stunnel libwrap option is supported, we disable the usage of /etc/hosts.allow and /etc/hosts.deny by\n    # setting the option to no\n    if is_stunnel_option_supported(stunnel_options, b\"libwrap\"):\n        efs_config[\"libwrap\"] = \"no\"\n\n    stunnel_config = \"\\n\".join(\n        serialize_stunnel_config(global_config)\n        + serialize_stunnel_config(efs_config, \"efs\")\n    )\n    logging.debug(\"Writing stunnel configuration:\\n%s\", stunnel_config)\n\n    stunnel_config_file = os.path.join(\n        state_file_dir, \"stunnel-config.%s\" % mount_filename\n    )\n\n    with open(stunnel_config_file, \"w\") as f:\n        f.write(stunnel_config)\n\n    return stunnel_config_file\n\n\ndef write_tls_tunnel_state_file(\n    fs_id,\n    mountpoint,\n    tls_port,\n    tunnel_pid,\n    command,\n    files,\n    state_file_dir,\n    cert_details=None,\n):\n    \"\"\"\n    Return the name of the temporary file containing TLS tunnel state, prefixed with a '~'. This file needs to be renamed to a\n    non-temporary version following a successful mount.\n    \"\"\"\n    state_file = \"~\" + get_mount_specific_filename(fs_id, mountpoint, tls_port)\n\n    state = {\n        \"pid\": tunnel_pid,\n        \"cmd\": command,\n        \"files\": files,\n        \"mount_time\": time.time(),\n        \"mountpoint\": mountpoint,\n    }\n\n    if cert_details:\n        state.update(cert_details)\n\n    with open(os.path.join(state_file_dir, state_file), \"w\") as f:\n        json.dump(state, f)\n\n    return state_file\n\n\ndef rewrite_tls_tunnel_state_file(state, state_file_dir, state_file):\n    with open(os.path.join(state_file_dir, state_file), \"w\") as f:\n        json.dump(state, f)\n    return state_file\n\n\ndef update_tls_tunnel_temp_state_file_with_tunnel_pid(\n    temp_tls_state_file, state_file_dir, stunnel_pid\n):\n    with open(os.path.join(state_file_dir, temp_tls_state_file), \"r\") as f:\n        state = json.load(f)\n    state[\"pid\"] = stunnel_pid\n    temp_tls_state_file = rewrite_tls_tunnel_state_file(\n        state, state_file_dir, temp_tls_state_file\n    )\n    return temp_tls_state_file\n\n\ndef test_tunnel_process(tunnel_proc, fs_id):\n    tunnel_proc.poll()\n    if tunnel_proc.returncode is not None:\n        _, err = tunnel_proc.communicate()\n        fatal_error(\n            \"Failed to initialize TLS tunnel for %s, please check mount.log for the failure reason.\"\n            % fs_id,\n            'Failed to start TLS tunnel (errno=%d), stderr=\"%s\". If the stderr is lacking enough details, please '\n            \"enable stunnel debug log in efs-utils config file and retry the mount to capture more info.\"\n            % (tunnel_proc.returncode, err.strip()),\n        )\n\n\ndef poll_tunnel_process(tunnel_proc, fs_id, mount_completed):\n    \"\"\"\n    poll the tunnel process health every .5s during the mount attempt to fail fast if the tunnel dies - since this is not called\n    from the main thread, if the tunnel fails, exit uncleanly with os._exit\n    \"\"\"\n    while not mount_completed.is_set():\n        try:\n            test_tunnel_process(tunnel_proc, fs_id)\n        except SystemExit as e:\n            os._exit(e.code)\n        mount_completed.wait(0.5)\n\n\ndef get_init_system(comm_file=\"/proc/1/comm\"):\n    init_system = DEFAULT_UNKNOWN_VALUE\n    if not check_if_platform_is_mac():\n        try:\n            with open(comm_file) as f:\n                init_system = f.read().strip()\n        except IOError:\n            logging.warning(\"Unable to read %s\", comm_file)\n    else:\n        init_system = \"launchd\"\n\n    logging.debug(\"Identified init system: %s\", init_system)\n    return init_system\n\n\ndef check_network_target(fs_id):\n    with open(os.devnull, \"w\") as devnull:\n        if not check_if_platform_is_mac():\n            rc = subprocess.call(\n                [\"systemctl\", \"is-active\", \"network.target\"],\n                stdout=devnull,\n                stderr=devnull,\n                close_fds=True,\n            )\n        else:\n            rc = subprocess.call(\n                [\"sudo\", \"ifconfig\", \"en0\"],\n                stdout=devnull,\n                stderr=devnull,\n                close_fds=True,\n            )\n\n    if rc != 0:\n        fatal_error(\n            'Failed to mount %s because the network was not yet available, add \"_netdev\" to your mount options'\n            % fs_id,\n            exit_code=0,\n        )\n\n\ndef check_network_status(fs_id, init_system):\n    if init_system != \"systemd\":\n        logging.debug(\"Not testing network on non-systemd init systems\")\n        return\n\n    check_network_target(fs_id)\n\n\ndef start_watchdog(init_system):\n    if init_system == \"init\":\n        proc = subprocess.Popen(\n            [\"/sbin/status\", WATCHDOG_SERVICE],\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE,\n            close_fds=True,\n        )\n        status, _ = proc.communicate()\n        if \"stop\" in str(status):\n            subprocess.Popen(\n                [\"/sbin/start\", WATCHDOG_SERVICE],\n                stdout=subprocess.DEVNULL,\n                stderr=subprocess.DEVNULL,\n                close_fds=True,\n            )\n        elif \"start\" in str(status):\n            logging.debug(\"%s is already running\", WATCHDOG_SERVICE)\n\n    elif init_system == \"systemd\":\n        rc = subprocess.call(\n            [\"systemctl\", \"is-active\", \"--quiet\", WATCHDOG_SERVICE], close_fds=True\n        )\n        if rc != 0:\n            subprocess.Popen(\n                [\"systemctl\", \"start\", WATCHDOG_SERVICE],\n                stdout=subprocess.DEVNULL,\n                stderr=subprocess.DEVNULL,\n                close_fds=True,\n            )\n        else:\n            logging.debug(\"%s is already running\", WATCHDOG_SERVICE)\n\n    elif init_system == \"launchd\":\n        rc = subprocess.Popen(\n            [\"sudo\", \"launchctl\", \"list\", WATCHDOG_SERVICE],\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE,\n            close_fds=True,\n        )\n        if rc != 0:\n            if not os.path.exists(WATCHDOG_SERVICE_PLIST_PATH):\n                fatal_error(\n                    \"Watchdog plist file missing. Copy the watchdog plist file in directory /Library/LaunchAgents\"\n                )\n            subprocess.Popen(\n                [\"sudo\", \"launchctl\", \"load\", WATCHDOG_SERVICE_PLIST_PATH],\n                stdout=subprocess.DEVNULL,\n                stderr=subprocess.DEVNULL,\n                close_fds=True,\n            )\n        else:\n            logging.debug(\"%s is already running\", WATCHDOG_SERVICE)\n\n    else:\n        error_message = 'Could not start %s, unrecognized init system \"%s\"' % (\n            WATCHDOG_SERVICE,\n            init_system,\n        )\n        sys.stderr.write(\"%s\\n\" % error_message)\n        logging.warning(error_message)\n\n\ndef create_required_directory(config, directory):\n    mode = 0o750\n    try:\n        mode_str = config.get(CONFIG_SECTION, \"state_file_dir_mode\")\n        try:\n            mode = int(mode_str, 8)\n        except ValueError:\n            logging.warning(\n                'Bad state_file_dir_mode \"%s\" in config file \"%s\"',\n                mode_str,\n                CONFIG_FILE,\n            )\n    except NoOptionError:\n        pass\n\n    try:\n        os.makedirs(directory, mode)\n    except OSError as e:\n        if errno.EEXIST != e.errno or not os.path.isdir(directory):\n            raise\n\n\n# Example of a localhost bind sock: sock.bind(('localhost',12345))\n# sock.getsockname() -> ('127.0.0.1', 12345)\n# This function returns the port of the bind socket, in the example is 12345\ndef get_tls_port_from_sock(tls_port_sock):\n    return tls_port_sock.getsockname()[1]\n\n\n@contextmanager\ndef bootstrap_tls(\n    config,\n    init_system,\n    dns_name,\n    fs_id,\n    mountpoint,\n    options,\n    state_file_dir=STATE_FILE_DIR,\n    fallback_ip_address=None,\n):\n    tls_port_sock = choose_tls_port_and_get_bind_sock(config, options, state_file_dir)\n    tls_port = get_tls_port_from_sock(tls_port_sock)\n\n    try:\n        # override the tlsport option so that we can later override the port the NFS client uses to connect to stunnel.\n        # if the user has specified tlsport=X at the command line this will just re-set tlsport to X.\n        options[\"tlsport\"] = tls_port\n\n        use_iam = \"iam\" in options\n        ap_id = options.get(\"accesspoint\")\n        cert_details = {}\n        security_credentials = None\n        client_info = get_client_info(config)\n        region = get_target_region(config)\n\n        if use_iam:\n            aws_creds_uri = options.get(\"awscredsuri\")\n            if aws_creds_uri:\n                kwargs = {\"aws_creds_uri\": aws_creds_uri}\n            else:\n                kwargs = {\"awsprofile\": get_aws_profile(options, use_iam)}\n\n            security_credentials, credentials_source = get_aws_security_credentials(\n                config, use_iam, region, **kwargs\n            )\n\n            if credentials_source:\n                cert_details[\"awsCredentialsMethod\"] = credentials_source\n\n        if ap_id:\n            cert_details[\"accessPoint\"] = ap_id\n\n        # additional symbol appended to avoid naming collisions\n        cert_details[\"mountStateDir\"] = (\n            get_mount_specific_filename(fs_id, mountpoint, tls_port) + \"+\"\n        )\n        # common name for certificate signing request is max 64 characters\n        cert_details[\"commonName\"] = socket.gethostname()[0:64]\n        region = get_target_region(config)\n        cert_details[\"region\"] = region\n        cert_details[\"certificateCreationTime\"] = create_certificate(\n            config,\n            cert_details[\"mountStateDir\"],\n            cert_details[\"commonName\"],\n            cert_details[\"region\"],\n            fs_id,\n            security_credentials,\n            ap_id,\n            client_info,\n            base_path=state_file_dir,\n        )\n        cert_details[\"certificate\"] = os.path.join(\n            state_file_dir, cert_details[\"mountStateDir\"], \"certificate.pem\"\n        )\n        cert_details[\"privateKey\"] = get_private_key_path()\n        cert_details[\"fsId\"] = fs_id\n\n        start_watchdog(init_system)\n\n        if not os.path.exists(state_file_dir):\n            create_required_directory(config, state_file_dir)\n\n        verify_level = int(options.get(\"verify\", DEFAULT_STUNNEL_VERIFY_LEVEL))\n        ocsp_enabled = is_ocsp_enabled(config, options)\n\n        stunnel_config_file = write_stunnel_config_file(\n            config,\n            state_file_dir,\n            fs_id,\n            mountpoint,\n            tls_port,\n            dns_name,\n            verify_level,\n            ocsp_enabled,\n            options,\n            region,\n            cert_details=cert_details,\n            fallback_ip_address=fallback_ip_address,\n        )\n        tunnel_args = [_stunnel_bin(), stunnel_config_file]\n        if \"netns\" in options:\n            tunnel_args = [\"nsenter\", \"--net=\" + options[\"netns\"]] + tunnel_args\n\n        # This temp state file is acting like a tlsport lock file, which is why pid =- 1\n        temp_tls_state_file = write_tls_tunnel_state_file(\n            fs_id,\n            mountpoint,\n            tls_port,\n            -1,\n            tunnel_args,\n            [stunnel_config_file],\n            state_file_dir,\n            cert_details=cert_details,\n        )\n    finally:\n        # Always close the socket we created when choosing TLS port only until now to\n        # 1. avoid concurrent TLS mount port collision 2. enable stunnel process to bind the port\n        logging.debug(\"Closing socket used to choose TLS port %s.\", tls_port)\n        tls_port_sock.close()\n\n    # launch the tunnel in a process group so if it has any child processes, they can be killed easily by the mount watchdog\n    logging.info('Starting TLS tunnel: \"%s\"', \" \".join(tunnel_args))\n    tunnel_proc = subprocess.Popen(\n        tunnel_args,\n        stdout=subprocess.DEVNULL,\n        stderr=subprocess.PIPE,\n        preexec_fn=os.setsid,\n        close_fds=True,\n    )\n    logging.info(\"Started TLS tunnel, pid: %d\", tunnel_proc.pid)\n\n    update_tls_tunnel_temp_state_file_with_tunnel_pid(\n        temp_tls_state_file, state_file_dir, tunnel_proc.pid\n    )\n\n    if \"netns\" not in options:\n        test_tlsport(options[\"tlsport\"])\n    else:\n        with NetNS(nspath=options[\"netns\"]):\n            test_tlsport(options[\"tlsport\"])\n\n    try:\n        yield tunnel_proc\n    finally:\n        os.rename(\n            os.path.join(state_file_dir, temp_tls_state_file),\n            os.path.join(state_file_dir, temp_tls_state_file[1:]),\n        )\n\n\ndef test_tlsport(tlsport):\n    retry_times = 5\n    while not verify_tlsport_can_be_connected(tlsport) and retry_times > 0:\n        logging.debug(\n            \"The tlsport %s cannot be connected yet, sleep %s(s), %s retry time(s) left\",\n            tlsport,\n            DEFAULT_TIMEOUT,\n            retry_times,\n        )\n        time.sleep(DEFAULT_TIMEOUT)\n        retry_times -= 1\n\n\ndef check_if_nfsvers_is_compatible_with_macos(options):\n    # MacOS does not support NFSv4.1\n    if (\n        (\"nfsvers\" in options and options[\"nfsvers\"] == \"4.1\")\n        or (\"vers\" in options and options[\"vers\"] == \"4.1\")\n        or (\"minorversion\" in options and options[\"minorversion\"] == 1)\n    ):\n        fatal_error(\"NFSv4.1 is not supported on MacOS, please switch to NFSv4.0\")\n\n\ndef get_nfs_mount_options(options):\n    # If you change these options, update the man page as well at man/mount.efs.8\n    if \"nfsvers\" not in options and \"vers\" not in options:\n        options[\"nfsvers\"] = \"4.1\" if not check_if_platform_is_mac() else \"4.0\"\n\n    if check_if_platform_is_mac():\n        check_if_nfsvers_is_compatible_with_macos(options)\n\n    if \"rsize\" not in options:\n        options[\"rsize\"] = \"1048576\"\n    if \"wsize\" not in options:\n        options[\"wsize\"] = \"1048576\"\n    if \"soft\" not in options and \"hard\" not in options:\n        options[\"hard\"] = None\n    if \"timeo\" not in options:\n        options[\"timeo\"] = \"600\"\n    if \"retrans\" not in options:\n        options[\"retrans\"] = \"2\"\n    if \"noresvport\" not in options:\n        options[\"noresvport\"] = None\n\n    # Set mountport to 2049 for MacOS\n    if check_if_platform_is_mac():\n        options[\"mountport\"] = \"2049\"\n\n    if \"tls\" in options:\n        options[\"port\"] = options[\"tlsport\"]\n\n    def to_nfs_option(k, v):\n        if v is None:\n            return k\n        return \"%s=%s\" % (str(k), str(v))\n\n    nfs_options = [\n        to_nfs_option(k, v) for k, v in options.items() if k not in EFS_ONLY_OPTIONS\n    ]\n\n    return \",\".join(nfs_options)\n\n\ndef mount_nfs(config, dns_name, path, mountpoint, options, fallback_ip_address=None):\n\n    if \"tls\" in options:\n        mount_path = \"127.0.0.1:%s\" % path\n    elif fallback_ip_address:\n        mount_path = \"%s:%s\" % (fallback_ip_address, path)\n    else:\n        mount_path = \"%s:%s\" % (dns_name, path)\n\n    if not check_if_platform_is_mac():\n        command = [\n            \"/sbin/mount.nfs4\",\n            mount_path,\n            mountpoint,\n            \"-o\",\n            get_nfs_mount_options(options),\n        ]\n    else:\n        command = [\n            \"/sbin/mount_nfs\",\n            \"-o\",\n            get_nfs_mount_options(options),\n            mount_path,\n            mountpoint,\n        ]\n\n    if \"netns\" in options:\n        command = [\"nsenter\", \"--net=\" + options[\"netns\"]] + command\n\n    if call_nfs_mount_command_with_retry_succeed(\n        config, options, command, dns_name, mountpoint\n    ):\n        return\n\n    logging.info('Executing: \"%s\"', \" \".join(command))\n\n    proc = subprocess.Popen(\n        command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, close_fds=True\n    )\n    out, err = proc.communicate()\n\n    if proc.returncode == 0:\n        post_mount_nfs_success(config, options, dns_name, mountpoint)\n    else:\n        message = 'Failed to mount %s at %s: returncode=%d, stderr=\"%s\"' % (\n            dns_name,\n            mountpoint,\n            proc.returncode,\n            err.strip(),\n        )\n        fatal_error(err.strip(), message, proc.returncode)\n\n\ndef post_mount_nfs_success(config, options, dns_name, mountpoint):\n    message = \"Successfully mounted %s at %s\" % (dns_name, mountpoint)\n    logging.info(message)\n    publish_cloudwatch_log(CLOUDWATCHLOG_AGENT, message)\n\n    # only perform readahead optimize after mount succeed\n    optimize_readahead_window(mountpoint, options, config)\n\n\ndef call_nfs_mount_command_with_retry_succeed(\n    config, options, command, dns_name, mountpoint\n):\n    def backoff_function(i):\n        \"\"\"Backoff exponentially and add a constant 0-1 second jitter\"\"\"\n        return (1.5 ** i) + random.random()\n\n    if not get_boolean_config_item_value(\n        config, CONFIG_SECTION, \"retry_nfs_mount_command\", default_value=True\n    ):\n        logging.debug(\n            \"Configuration 'retry_nfs_mount_command' is not enabled, skip retrying mount.nfs command.\"\n        )\n        return\n\n    retry_nfs_mount_command_timeout_sec = get_int_value_from_config_file(\n        config,\n        \"retry_nfs_mount_command_timeout_sec\",\n        DEFAULT_NFS_MOUNT_COMMAND_TIMEOUT_SEC,\n    )\n    retry_count = get_int_value_from_config_file(\n        config,\n        \"retry_nfs_mount_command_count\",\n        DEFAULT_NFS_MOUNT_COMMAND_RETRY_COUNT,\n    )\n\n    for retry in range(retry_count - 1):\n        retry_sleep_time_sec = backoff_function(retry)\n        err = \"unknown error\"\n        logging.info(\n            'Executing: \"%s\" with %s sec time limit.'\n            % (\" \".join(command), retry_nfs_mount_command_timeout_sec)\n        )\n        proc = subprocess.Popen(\n            command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, close_fds=True\n        )\n\n        try:\n            out, err = proc.communicate(timeout=retry_nfs_mount_command_timeout_sec)\n            rc = proc.poll()\n            if rc != 0:\n                continue_retry = any(\n                    error_string in str(err) for error_string in RETRYABLE_ERRORS\n                )\n                if continue_retry:\n                    logging.error(\n                        'Mounting %s to %s failed, return code=%s, stdout=\"%s\", stderr=\"%s\", mount attempt %d/%d, '\n                        \"wait %d sec before next attempt.\"\n                        % (\n                            dns_name,\n                            mountpoint,\n                            rc,\n                            out,\n                            err,\n                            retry + 1,\n                            retry_count,\n                            retry_sleep_time_sec,\n                        )\n                    )\n                else:\n                    message = 'Failed to mount %s at %s: returncode=%d, stderr=\"%s\"' % (\n                        dns_name,\n                        mountpoint,\n                        proc.returncode,\n                        err.strip(),\n                    )\n                    fatal_error(err.strip(), message, proc.returncode)\n            else:\n                post_mount_nfs_success(config, options, dns_name, mountpoint)\n                return True\n        except subprocess.TimeoutExpired:\n            try:\n                proc.kill()\n            except OSError:\n                # Silently fail if the subprocess has exited already\n                pass\n            retry_sleep_time_sec = 0\n            err = \"timeout after %s sec\" % retry_nfs_mount_command_timeout_sec\n            logging.error(\n                \"Mounting %s to %s failed due to %s, mount attempt %d/%d, wait %d sec before next attempt.\"\n                % (\n                    dns_name,\n                    mountpoint,\n                    err,\n                    retry + 1,\n                    retry_count,\n                    retry_sleep_time_sec,\n                )\n            )\n        except Exception as e:\n            message = 'Failed to mount %s at %s: returncode=%d, stderr=\"%s\", %s' % (\n                dns_name,\n                mountpoint,\n                proc.returncode,\n                err.strip(),\n                e,\n            )\n            fatal_error(err.strip(), message, proc.returncode)\n\n        sys.stderr.write(\n            \"Mount attempt %d/%d failed due to %s, wait %d sec before next attempt.\\n\"\n            % (retry + 1, retry_count, err, retry_sleep_time_sec)\n        )\n        time.sleep(retry_sleep_time_sec)\n\n    return False\n\n\ndef get_int_value_from_config_file(config, config_name, default_config_value):\n    val = default_config_value\n    try:\n        value_from_config = config.get(CONFIG_SECTION, config_name)\n        try:\n            if int(value_from_config) > 0:\n                val = int(value_from_config)\n            else:\n                logging.debug(\n                    '%s value in config file \"%s\" is lower than 1. Defaulting to %d.',\n                    config_name,\n                    CONFIG_FILE,\n                    default_config_value,\n                )\n        except ValueError:\n            logging.debug(\n                'Bad %s, \"%s\", in config file \"%s\". Defaulting to %d.',\n                config_name,\n                value_from_config,\n                CONFIG_FILE,\n                default_config_value,\n            )\n    except NoOptionError:\n        logging.debug(\n            'No %s value in config file \"%s\". Defaulting to %d.',\n            config_name,\n            CONFIG_FILE,\n            default_config_value,\n        )\n\n    return val\n\n\ndef usage(out, exit_code=1):\n    out.write(\n        \"Usage: mount.efs [--version] [-h|--help] <fsname> <mountpoint> [-o <options>]\\n\"\n    )\n    sys.exit(exit_code)\n\n\ndef parse_arguments_early_exit(args=None):\n    \"\"\"Parse arguments, checking for early exit conditions only\"\"\"\n    if args is None:\n        args = sys.argv\n\n    if \"-h\" in args[1:] or \"--help\" in args[1:]:\n        usage(out=sys.stdout, exit_code=0)\n\n    if \"--version\" in args[1:]:\n        sys.stdout.write(\"%s Version: %s\\n\" % (args[0], VERSION))\n        sys.exit(0)\n\n\ndef parse_arguments(config, args=None):\n    \"\"\"Parse arguments, return (fsid, path, mountpoint, options)\"\"\"\n    if args is None:\n        args = sys.argv\n\n    fsname = None\n    mountpoint = None\n    options = {}\n\n    if not check_if_platform_is_mac():\n        if len(args) > 1:\n            fsname = args[1]\n        if len(args) > 2:\n            mountpoint = args[2]\n        if len(args) > 4 and \"-o\" in args[:-1]:\n            options_index = args.index(\"-o\") + 1\n            options = parse_options(args[options_index])\n    else:\n        if len(args) > 1:\n            fsname = args[-2]\n        if len(args) > 2:\n            mountpoint = args[-1]\n        if len(args) > 4 and \"-o\" in args[:-2]:\n            for arg in args[1:-2]:\n                if arg != \"-o\":\n                    options.update(parse_options(arg))\n\n    if not fsname or not mountpoint:\n        usage(out=sys.stderr)\n\n    # We treat az as an option when customer is using dns name of az mount target to mount,\n    # even if they don't provide az with option, we update the options with that info\n    fs_id, path, az = match_device(config, fsname, options)\n\n    return fs_id, path, mountpoint, add_field_in_options(options, \"az\", az)\n\n\ndef get_client_info(config):\n    client_info = {}\n\n    # source key/value pair in config file\n    if config.has_option(CLIENT_INFO_SECTION, \"source\"):\n        client_source = config.get(CLIENT_INFO_SECTION, \"source\")\n        if 0 < len(client_source) <= CLIENT_SOURCE_STR_LEN_LIMIT:\n            client_info[\"source\"] = client_source\n    if not client_info.get(\"source\"):\n        if check_if_platform_is_mac():\n            client_info[\"source\"] = DEFAULT_MACOS_VALUE\n        else:\n            client_info[\"source\"] = DEFAULT_UNKNOWN_VALUE\n\n    client_info[\"efs_utils_version\"] = VERSION\n\n    return client_info\n\n\ndef create_certificate(\n    config,\n    mount_name,\n    common_name,\n    region,\n    fs_id,\n    security_credentials,\n    ap_id,\n    client_info,\n    base_path=STATE_FILE_DIR,\n):\n    current_time = get_utc_now()\n    tls_paths = tls_paths_dictionary(mount_name, base_path)\n\n    certificate_config = os.path.join(tls_paths[\"mount_dir\"], \"config.conf\")\n    certificate_signing_request = os.path.join(tls_paths[\"mount_dir\"], \"request.csr\")\n    certificate = os.path.join(tls_paths[\"mount_dir\"], \"certificate.pem\")\n\n    ca_dirs_check(config, tls_paths[\"database_dir\"], tls_paths[\"certs_dir\"])\n    ca_supporting_files_check(\n        tls_paths[\"index\"],\n        tls_paths[\"index_attr\"],\n        tls_paths[\"serial\"],\n        tls_paths[\"rand\"],\n    )\n\n    private_key = check_and_create_private_key(base_path)\n\n    if security_credentials:\n        public_key = os.path.join(tls_paths[\"mount_dir\"], \"publicKey.pem\")\n        create_public_key(private_key, public_key)\n\n    create_ca_conf(\n        certificate_config,\n        common_name,\n        tls_paths[\"mount_dir\"],\n        private_key,\n        current_time,\n        region,\n        fs_id,\n        security_credentials,\n        ap_id,\n        client_info,\n    )\n    create_certificate_signing_request(\n        certificate_config, private_key, certificate_signing_request\n    )\n\n    not_before = get_certificate_timestamp(current_time, minutes=-NOT_BEFORE_MINS)\n    not_after = get_certificate_timestamp(current_time, hours=NOT_AFTER_HOURS)\n\n    cmd = \"openssl ca -startdate %s -enddate %s -selfsign -batch -notext -config %s -in %s -out %s\" % (\n        not_before,\n        not_after,\n        certificate_config,\n        certificate_signing_request,\n        certificate,\n    )\n    subprocess_call(cmd, \"Failed to create self-signed client-side certificate\")\n    return current_time.strftime(CERT_DATETIME_FORMAT)\n\n\ndef get_private_key_path():\n    \"\"\"Wrapped for mocking purposes in unit tests\"\"\"\n    return PRIVATE_KEY_FILE\n\n\ndef check_and_create_private_key(base_path=STATE_FILE_DIR):\n    # Creating RSA private keys is slow, so we will create one private key and allow mounts to share it.\n    # This means, however, that we have to include a locking mechanism to ensure that the private key is\n    # atomically created, as mounts occurring in parallel may try to create the key simultaneously.\n    key = get_private_key_path()\n\n    @contextmanager\n    def open_lock_file():\n        lock_file = os.path.join(base_path, \"efs-utils-lock\")\n        f = os.open(lock_file, os.O_CREAT | os.O_DSYNC | os.O_EXCL | os.O_RDWR)\n        try:\n            lock_file_contents = \"PID: %s\" % os.getpid()\n            os.write(f, lock_file_contents.encode(\"utf-8\"))\n            yield f\n        finally:\n            check_and_remove_lock_file(lock_file, f)\n\n    def do_with_lock(function):\n        while True:\n            try:\n                with open_lock_file():\n                    return function()\n            except OSError as e:\n                if e.errno == errno.EEXIST:\n                    logging.info(\n                        \"Failed to take out private key creation lock, sleeping %s (s)\",\n                        DEFAULT_TIMEOUT,\n                    )\n                    time.sleep(DEFAULT_TIMEOUT)\n                else:\n                    # errno.ENOENT: No such file or directory, errno.EBADF: Bad file descriptor\n                    if e.errno == errno.ENOENT or e.errno == errno.EBADF:\n                        logging.debug(\n                            \"lock file does not exist or Bad file descriptor, The file is already removed nothing to do.\"\n                        )\n                    else:\n                        raise Exception(\n                            \"Could not remove lock file unexpected exception: %s\", e\n                        )\n\n    def generate_key():\n        if os.path.isfile(key):\n            return\n\n        cmd = (\n            \"openssl genpkey -algorithm RSA -out %s -pkeyopt rsa_keygen_bits:3072\" % key\n        )\n        subprocess_call(cmd, \"Failed to create private key\")\n        read_only_mode = 0o400\n        os.chmod(key, read_only_mode)\n\n    do_with_lock(generate_key)\n    return key\n\n\ndef create_certificate_signing_request(config_path, private_key, csr_path):\n    cmd = \"openssl req -new -config %s -key %s -out %s\" % (\n        config_path,\n        private_key,\n        csr_path,\n    )\n    subprocess_call(cmd, \"Failed to create certificate signing request (csr)\")\n\n\ndef create_ca_conf(\n    config_path,\n    common_name,\n    directory,\n    private_key,\n    date,\n    region,\n    fs_id,\n    security_credentials,\n    ap_id,\n    client_info,\n):\n    \"\"\"Populate ca/req configuration file with fresh configurations at every mount since SigV4 signature can change\"\"\"\n    public_key_path = os.path.join(directory, \"publicKey.pem\")\n    ca_extension_body = ca_extension_builder(\n        ap_id, security_credentials, fs_id, client_info\n    )\n    efs_client_auth_body = (\n        efs_client_auth_builder(\n            public_key_path,\n            security_credentials[\"AccessKeyId\"],\n            security_credentials[\"SecretAccessKey\"],\n            date,\n            region,\n            fs_id,\n            security_credentials[\"Token\"],\n        )\n        if security_credentials\n        else \"\"\n    )\n    efs_client_info_body = efs_client_info_builder(client_info) if client_info else \"\"\n    full_config_body = CA_CONFIG_BODY % (\n        directory,\n        private_key,\n        common_name,\n        ca_extension_body,\n        efs_client_auth_body,\n        efs_client_info_body,\n    )\n\n    with open(config_path, \"w\") as f:\n        f.write(full_config_body)\n\n    return full_config_body\n\n\ndef ca_extension_builder(ap_id, security_credentials, fs_id, client_info):\n    ca_extension_str = \"[ v3_ca ]\\nsubjectKeyIdentifier = hash\"\n    if ap_id:\n        ca_extension_str += \"\\n1.3.6.1.4.1.4843.7.1 = ASN1:UTF8String:\" + ap_id\n    if security_credentials:\n        ca_extension_str += \"\\n1.3.6.1.4.1.4843.7.2 = ASN1:SEQUENCE:efs_client_auth\"\n\n    ca_extension_str += \"\\n1.3.6.1.4.1.4843.7.3 = ASN1:UTF8String:\" + fs_id\n\n    if client_info:\n        ca_extension_str += \"\\n1.3.6.1.4.1.4843.7.4 = ASN1:SEQUENCE:efs_client_info\"\n\n    return ca_extension_str\n\n\ndef efs_client_auth_builder(\n    public_key_path,\n    access_key_id,\n    secret_access_key,\n    date,\n    region,\n    fs_id,\n    session_token=None,\n):\n    public_key_hash = get_public_key_sha1(public_key_path)\n    canonical_request = create_canonical_request(\n        public_key_hash, date, access_key_id, region, fs_id, session_token\n    )\n    string_to_sign = create_string_to_sign(canonical_request, date, region)\n    signature = calculate_signature(string_to_sign, date, secret_access_key, region)\n    efs_client_auth_str = \"[ efs_client_auth ]\"\n    efs_client_auth_str += \"\\naccessKeyId = UTF8String:\" + access_key_id\n    efs_client_auth_str += \"\\nsignature = OCTETSTRING:\" + signature\n    efs_client_auth_str += \"\\nsigv4DateTime = UTCTIME:\" + date.strftime(\n        CERT_DATETIME_FORMAT\n    )\n\n    if session_token:\n        efs_client_auth_str += \"\\nsessionToken = EXPLICIT:0,UTF8String:\" + session_token\n\n    return efs_client_auth_str\n\n\ndef efs_client_info_builder(client_info):\n    efs_client_info_str = \"[ efs_client_info ]\"\n    for key, value in client_info.items():\n        efs_client_info_str += \"\\n%s = UTF8String:%s\" % (key, value)\n    return efs_client_info_str\n\n\ndef create_public_key(private_key, public_key):\n    cmd = \"openssl rsa -in %s -outform PEM -pubout -out %s\" % (private_key, public_key)\n    subprocess_call(cmd, \"Failed to create public key\")\n\n\ndef subprocess_call(cmd, error_message):\n    \"\"\"Helper method to run shell openssl command and to handle response error messages\"\"\"\n    retry_times = 3\n    for retry in range(retry_times):\n        process = subprocess.Popen(\n            cmd.split(), stdout=subprocess.PIPE, stderr=subprocess.PIPE, close_fds=True\n        )\n        (output, err) = process.communicate()\n        rc = process.poll()\n        if rc != 0:\n            logging.error(\n                'Command %s failed, rc=%s, stdout=\"%s\", stderr=\"%s\"'\n                % (cmd, rc, output, err),\n                exc_info=True,\n            )\n            try:\n                process.kill()\n            except OSError:\n                # Silently fail if the subprocess has exited already\n                pass\n        else:\n            return output, err\n    error_message = \"%s, error is: %s\" % (error_message, err)\n    fatal_error(error_message, error_message)\n\n\ndef ca_dirs_check(config, database_dir, certs_dir):\n    \"\"\"Check if mount's database and certs directories exist and if not, create directories (also create all intermediate\n    directories if they don't exist).\"\"\"\n    if not os.path.exists(database_dir):\n        create_required_directory(config, database_dir)\n    if not os.path.exists(certs_dir):\n        create_required_directory(config, certs_dir)\n\n\ndef ca_supporting_files_check(index_path, index_attr_path, serial_path, rand_path):\n    \"\"\"Recreate all supporting openssl ca and req files if they're not present in their respective directories\"\"\"\n    if not os.path.isfile(index_path):\n        open(index_path, \"w\").close()\n    if not os.path.isfile(index_attr_path):\n        with open(index_attr_path, \"w+\") as f:\n            f.write(\"unique_subject = no\")\n    if not os.path.isfile(serial_path):\n        with open(serial_path, \"w+\") as f:\n            f.write(\"00\")\n    if not os.path.isfile(rand_path):\n        open(rand_path, \"w\").close()\n\n\ndef get_certificate_timestamp(current_time, **kwargs):\n    updated_time = current_time + timedelta(**kwargs)\n    return updated_time.strftime(CERT_DATETIME_FORMAT)\n\n\ndef get_utc_now():\n    \"\"\"\n    Wrapped for patching purposes in unit tests\n    \"\"\"\n    return datetime.utcnow()\n\n\ndef assert_root():\n    if os.geteuid() != 0:\n        sys.stderr.write(\"only root can run mount.efs\\n\")\n        sys.exit(1)\n\n\ndef read_config(config_file=CONFIG_FILE):\n    try:\n        p = ConfigParser.SafeConfigParser()\n    except AttributeError:\n        p = ConfigParser()\n    p.read(config_file)\n    return p\n\n\ndef bootstrap_logging(config, log_dir=LOG_DIR):\n    raw_level = config.get(CONFIG_SECTION, \"logging_level\")\n    levels = {\n        \"debug\": logging.DEBUG,\n        \"info\": logging.INFO,\n        \"warning\": logging.WARNING,\n        \"error\": logging.ERROR,\n        \"critical\": logging.CRITICAL,\n    }\n    level = levels.get(raw_level.lower())\n    level_error = False\n\n    if not level:\n        # delay logging error about malformed log level until after logging is configured\n        level_error = True\n        level = logging.INFO\n\n    max_bytes = config.getint(CONFIG_SECTION, \"logging_max_bytes\")\n    file_count = config.getint(CONFIG_SECTION, \"logging_file_count\")\n\n    handler = RotatingFileHandler(\n        os.path.join(log_dir, LOG_FILE), maxBytes=max_bytes, backupCount=file_count\n    )\n    handler.setFormatter(\n        logging.Formatter(\n            fmt=\"%(asctime)s - %(levelname)s - %(message)s\",\n            datefmt=\"%Y-%m-%d %H:%M:%S %Z\",\n        )\n    )\n\n    logger = logging.getLogger()\n    logger.setLevel(level)\n    logger.addHandler(handler)\n\n    if level_error:\n        logging.error(\n            'Malformed logging level \"%s\", setting logging level to %s',\n            raw_level,\n            level,\n        )\n\n\ndef get_dns_name_and_fallback_mount_target_ip_address(config, fs_id, options):\n    def _validate_replacement_field_count(format_str, expected_ct):\n        if format_str.count(\"{\") != expected_ct or format_str.count(\"}\") != expected_ct:\n            raise ValueError(\n                \"DNS name format has an incorrect number of replacement fields\"\n            )\n\n    dns_name_format = config.get(CONFIG_SECTION, \"dns_name_format\")\n\n    if \"{fs_id}\" not in dns_name_format:\n        raise ValueError(\"DNS name format must include {fs_id}\")\n\n    format_args = {\"fs_id\": fs_id}\n\n    expected_replacement_field_ct = 1\n\n    if \"{az}\" in dns_name_format:\n        az = options.get(\"az\")\n        if az:\n            expected_replacement_field_ct += 1\n            format_args[\"az\"] = az\n        else:\n            dns_name_format = dns_name_format.replace(\"{az}.\", \"\")\n\n    if \"{region}\" in dns_name_format:\n        expected_replacement_field_ct += 1\n        format_args[\"region\"] = get_target_region(config)\n\n    if \"{dns_name_suffix}\" in dns_name_format:\n        expected_replacement_field_ct += 1\n        config_section = CONFIG_SECTION\n        region = format_args.get(\"region\")\n\n        if region:\n            config_section = get_config_section(config, region)\n\n        format_args[\"dns_name_suffix\"] = config.get(config_section, \"dns_name_suffix\")\n\n        logging.debug(\n            \"Using dns_name_suffix %s in config section [%s]\",\n            format_args.get(\"dns_name_suffix\"),\n            config_section,\n        )\n\n    _validate_replacement_field_count(dns_name_format, expected_replacement_field_ct)\n\n    dns_name = dns_name_format.format(**format_args)\n\n    if \"mounttargetip\" in options:\n        ip_address = options.get(\"mounttargetip\")\n        logging.info(\n            \"Use the mount target ip address %s provided in the mount options to mount.\"\n            % ip_address\n        )\n        try:\n            mount_target_ip_address_can_be_resolved(\n                ip_address,\n                passed_via_options=True,\n                network_namespace=options.get(\"netns\") if \"netns\" in options else None,\n            )\n            return dns_name, options.get(\"mounttargetip\")\n        except FallbackException as e:\n            fallback_message = e.message\n            throw_ip_address_connect_failure_with_fallback_message(\n                ip_address=ip_address, fallback_message=fallback_message\n            )\n\n    if dns_name_can_be_resolved(dns_name):\n        return dns_name, None\n\n    logging.info(\n        \"Failed to resolve %s, attempting to lookup mount target ip address using botocore.\",\n        dns_name,\n    )\n\n    try:\n        fallback_mount_target_ip_address = get_fallback_mount_target_ip_address(\n            config, options, fs_id, dns_name\n        )\n        logging.info(\n            \"Found fall back mount target ip address %s for file system %s\",\n            fallback_mount_target_ip_address,\n            fs_id,\n        )\n        return dns_name, fallback_mount_target_ip_address\n    except FallbackException as e:\n        fallback_message = e.message\n\n    throw_dns_resolve_failure_with_fallback_message(dns_name, fallback_message)\n\n\ndef get_fallback_mount_target_ip_address(config, options, fs_id, dns_name):\n    fall_back_to_ip_address_enabled = (\n        check_if_fall_back_to_mount_target_ip_address_is_enabled(config)\n    )\n\n    if not fall_back_to_ip_address_enabled:\n        fallback_message = (\n            \"Fallback to mount target ip address feature is not enabled in config file %s.\"\n            % CONFIG_FILE\n        )\n        raise FallbackException(fallback_message)\n\n    if not BOTOCORE_PRESENT:\n        fallback_message = \"Failed to import necessary dependency botocore, please install botocore first.\"\n        raise FallbackException(fallback_message)\n\n    mount_target_ip_address = None\n    try:\n        mount_target_ip_address = get_fallback_mount_target_ip_address_helper(\n            config, options, fs_id\n        )\n        mount_target_ip_address_can_be_resolved(\n            mount_target_ip_address,\n            network_namespace=options.get(\"netns\") if \"netns\" in options else None,\n        )\n        return mount_target_ip_address\n    except FallbackException as e:\n        throw_ip_address_connect_failure_with_fallback_message(\n            dns_name, mount_target_ip_address, e.message\n        )\n\n\ndef check_if_fall_back_to_mount_target_ip_address_is_enabled(config):\n    return get_boolean_config_item_value(\n        config,\n        CONFIG_SECTION,\n        FALLBACK_TO_MOUNT_TARGET_IP_ADDRESS_ITEM,\n        default_value=DEFAULT_FALLBACK_ENABLED,\n    )\n\n\ndef check_and_remove_lock_file(path, file):\n    \"\"\"\n    There is a possibility of having a race condition as the lock file is getting deleted in both mount_efs and watchdog,\n    so creating a function in order to check whether the path exist or not before removing the lock file.\n    \"\"\"\n    try:\n        os.close(file)\n        os.remove(path)\n        logging.debug(\"Removed %s successfully\", path)\n    except OSError as e:\n        if not (e.errno == errno.ENOENT or e.errno == errno.EBADF):\n            raise Exception(\"Could not remove %s. Unexpected exception: %s\", path, e)\n        else:\n            logging.debug(\n                \"%s does not exist, The file is already removed nothing to do\", path\n            )\n\n\ndef dns_name_can_be_resolved(dns_name):\n    try:\n        socket.gethostbyname(dns_name)\n        return True\n    except socket.gaierror:\n        return False\n\n\ndef mount_target_ip_address_can_be_resolved(\n    mount_target_ip_address, passed_via_options=False, network_namespace=None\n):\n    tries = 3\n    for attempt in range(tries):\n        try:\n            # Open a socket connection to mount target nfs port to verify that the mount target can be connected\n            if not network_namespace:\n                s = socket.create_connection((mount_target_ip_address, 2049), timeout=2)\n            else:\n                with NetNS(nspath=network_namespace):\n                    s = socket.create_connection(\n                        (mount_target_ip_address, 2049), timeout=2\n                    )\n            s.close()\n            return True\n        except socket.timeout:\n            if attempt < tries - 1:\n                message = (\n                    \"The ip address %s cannot be connected yet, sleep 0.5s, %s retry time(s) left\"\n                    % (mount_target_ip_address, tries - attempt - 1)\n                )\n                logging.warning(message)\n                time.sleep(0.5)\n                continue\n            else:\n                raise FallbackException(\n                    \"Connection to the mount target IP address %s timeout. Please retry in 5 minutes if the \"\n                    \"mount target is newly created. Otherwise check your VPC and security group \"\n                    \"configuration to ensure your file system is reachable via TCP port 2049 from your \"\n                    \"instance.\" % mount_target_ip_address\n                )\n        except Exception as e:\n            hint_message = (\n                \" Please check if the mount target ip address passed via mount option is correct.\"\n                if passed_via_options\n                else \"\"\n            )\n            raise FallbackException(\n                \"Unknown error when connecting to mount target IP address %s, %s.%s\"\n                % (mount_target_ip_address, e, hint_message)\n            )\n\n\ndef get_fallback_mount_target_ip_address_helper(config, options, fs_id):\n    az_name = get_target_az(config, options)\n\n    ec2_client = get_botocore_client(config, \"ec2\", options)\n    efs_client = get_botocore_client(config, \"efs\", options)\n\n    mount_target = get_mount_target_in_az(efs_client, ec2_client, fs_id, az_name)\n    mount_target_ip = mount_target.get(\"IpAddress\")\n    logging.debug(\"Found mount target ip address %s in AZ %s\", mount_target_ip, az_name)\n\n    return mount_target_ip\n\n\ndef throw_dns_resolve_failure_with_fallback_message(dns_name, fallback_message=None):\n    fallback_message = (\n        \"\\nAttempting to lookup mount target ip address using botocore. %s\"\n        % fallback_message\n        if fallback_message\n        else \"\"\n    )\n    message = (\n        'Failed to resolve \"%s\" - check that your file system ID is correct, and ensure that the VPC has an EFS mount '\n        \"target for this file system ID.\\nSee %s for more detail.%s\"\n    ) % (\n        dns_name,\n        \"https://docs.aws.amazon.com/console/efs/mount-dns-name\",\n        fallback_message,\n    )\n    fatal_error(message)\n\n\ndef throw_ip_address_connect_failure_with_fallback_message(\n    dns_name=None, ip_address=None, fallback_message=None\n):\n    dns_message = 'Failed to resolve \"%s\". ' % dns_name if dns_name else \"\"\n    if not ip_address:\n        ip_address_message = (\n            \"The file system mount target ip address cannot be found, please pass mount target ip \"\n            \"address via mount options. \"\n        )\n    else:\n        ip_address_message = (\n            \"Cannot connect to file system mount target ip address %s. \" % ip_address\n        )\n    fallback_message = \"\\n%s\" % fallback_message if fallback_message else \"\"\n    fatal_error(\"%s%s%s\" % (dns_message, ip_address_message, fallback_message))\n\n\ndef tls_paths_dictionary(mount_name, base_path=STATE_FILE_DIR):\n    tls_dict = {\n        \"mount_dir\": os.path.join(base_path, mount_name),\n        # every mount will have its own ca mode assets due to lack of multi-threading support in openssl\n        \"database_dir\": os.path.join(base_path, mount_name, \"database\"),\n        \"certs_dir\": os.path.join(base_path, mount_name, \"certs\"),\n        \"index\": os.path.join(base_path, mount_name, \"database/index.txt\"),\n        \"index_attr\": os.path.join(base_path, mount_name, \"database/index.txt.attr\"),\n        \"serial\": os.path.join(base_path, mount_name, \"database/serial\"),\n        \"rand\": os.path.join(base_path, mount_name, \"database/.rand\"),\n    }\n\n    return tls_dict\n\n\ndef get_public_key_sha1(public_key):\n    # truncating public key to remove the header and footer '-----(BEGIN|END) PUBLIC KEY-----'\n    with open(public_key, \"r\") as f:\n        lines = f.readlines()\n        lines = lines[1:-1]\n\n    key = \"\".join(lines)\n    key = bytearray(base64.b64decode(key))\n\n    # Parse the public key to pull out the actual key material by looking for the key BIT STRING\n    # Example:\n    #     0:d=0  hl=4 l= 418 cons: SEQUENCE\n    #     4:d=1  hl=2 l=  13 cons: SEQUENCE\n    #     6:d=2  hl=2 l=   9 prim: OBJECT            :rsaEncryption\n    #    17:d=2  hl=2 l=   0 prim: NULL\n    #    19:d=1  hl=4 l= 399 prim: BIT STRING\n    cmd = \"openssl asn1parse -inform PEM -in %s\" % public_key\n    output, err = subprocess_call(\n        cmd, \"Unable to ASN1 parse public key file, %s, correctly\" % public_key\n    )\n\n    key_line = \"\"\n    for line in output.splitlines():\n        if \"BIT STRING\" in line.decode(\"utf-8\"):\n            key_line = line.decode(\"utf-8\")\n\n    if not key_line:\n        err_msg = \"Public key file, %s, is incorrectly formatted\" % public_key\n        fatal_error(err_msg, err_msg)\n\n    key_line = key_line.replace(\" \", \"\")\n\n    # DER encoding TLV (Tag, Length, Value)\n    # - the first octet (byte) is the tag (type)\n    # - the next octets are the length - \"definite form\"\n    #   - the first octet always has the high order bit (8) set to 1\n    #   - the remaining 127 bits are used to encode the number of octets that follow\n    #   - the following octets encode, as big-endian, the length (which may be 0) as a number of octets\n    # - the remaining octets are the \"value\" aka content\n    #\n    # For a BIT STRING, the first octet of the value is used to signify the number of unused bits that exist in the last\n    # content byte. Note that this is explicitly excluded from the SubjectKeyIdentifier hash, per\n    # https://tools.ietf.org/html/rfc5280#section-4.2.1.2\n    #\n    # Example:\n    #   0382018f00...<subjectPublicKey>\n    #   - 03 - BIT STRING tag\n    #   - 82 - 2 length octets to follow (ignore high order bit)\n    #   - 018f - length of 399\n    #   - 00 - no unused bits in the last content byte\n    offset = int(key_line.split(\":\")[0])\n    key = key[offset:]\n\n    num_length_octets = key[1] & 0b01111111\n\n    # Exclude the tag (1), length (1 + num_length_octets), and number of unused bits (1)\n    offset = 1 + 1 + num_length_octets + 1\n    key = key[offset:]\n\n    sha1 = hashlib.sha1()\n    sha1.update(key)\n\n    return sha1.hexdigest()\n\n\ndef create_canonical_request(\n    public_key_hash, date, access_key, region, fs_id, session_token=None\n):\n    \"\"\"\n    Create a Canonical Request - https://docs.aws.amazon.com/general/latest/gr/sigv4-create-canonical-request.html\n    \"\"\"\n    formatted_datetime = date.strftime(SIGV4_DATETIME_FORMAT)\n    credential = quote_plus(access_key + \"/\" + get_credential_scope(date, region))\n\n    request = HTTP_REQUEST_METHOD + \"\\n\"\n    request += CANONICAL_URI + \"\\n\"\n    request += (\n        create_canonical_query_string(\n            public_key_hash, credential, formatted_datetime, session_token\n        )\n        + \"\\n\"\n    )\n    request += CANONICAL_HEADERS % fs_id + \"\\n\"\n    request += SIGNED_HEADERS + \"\\n\"\n\n    sha256 = hashlib.sha256()\n    sha256.update(REQUEST_PAYLOAD.encode())\n    request += sha256.hexdigest()\n\n    return request\n\n\ndef create_canonical_query_string(\n    public_key_hash, credential, formatted_datetime, session_token=None\n):\n    canonical_query_params = {\n        \"Action\": \"Connect\",\n        # Public key hash is included in canonical request to tie the signature to a specific key pair to avoid replay attacks\n        \"PublicKeyHash\": quote_plus(public_key_hash),\n        \"X-Amz-Algorithm\": ALGORITHM,\n        \"X-Amz-Credential\": credential,\n        \"X-Amz-Date\": quote_plus(formatted_datetime),\n        \"X-Amz-Expires\": 86400,\n        \"X-Amz-SignedHeaders\": SIGNED_HEADERS,\n    }\n\n    if session_token:\n        canonical_query_params[\"X-Amz-Security-Token\"] = quote_plus(session_token)\n\n    # Cannot use urllib.urlencode because it replaces the %s's\n    return \"&\".join(\n        [\"%s=%s\" % (k, v) for k, v in sorted(canonical_query_params.items())]\n    )\n\n\ndef create_string_to_sign(canonical_request, date, region):\n    \"\"\"\n    Create a String to Sign - https://docs.aws.amazon.com/general/latest/gr/sigv4-create-string-to-sign.html\n    \"\"\"\n    string_to_sign = ALGORITHM + \"\\n\"\n    string_to_sign += date.strftime(SIGV4_DATETIME_FORMAT) + \"\\n\"\n    string_to_sign += get_credential_scope(date, region) + \"\\n\"\n\n    sha256 = hashlib.sha256()\n    sha256.update(canonical_request.encode())\n    string_to_sign += sha256.hexdigest()\n\n    return string_to_sign\n\n\ndef calculate_signature(string_to_sign, date, secret_access_key, region):\n    \"\"\"\n    Calculate the Signature - https://docs.aws.amazon.com/general/latest/gr/sigv4-calculate-signature.html\n    \"\"\"\n\n    def _sign(key, msg):\n        return hmac.new(key, msg.encode(\"utf-8\"), hashlib.sha256)\n\n    key_date = _sign(\n        (\"AWS4\" + secret_access_key).encode(\"utf-8\"), date.strftime(DATE_ONLY_FORMAT)\n    ).digest()\n    add_region = _sign(key_date, region).digest()\n    add_service = _sign(add_region, SERVICE).digest()\n    signing_key = _sign(add_service, \"aws4_request\").digest()\n\n    return _sign(signing_key, string_to_sign).hexdigest()\n\n\ndef get_credential_scope(date, region):\n    return \"/\".join([date.strftime(DATE_ONLY_FORMAT), region, SERVICE, AWS4_REQUEST])\n\n\ndef match_device(config, device, options):\n    \"\"\"Return the EFS id, the remote path, and the az to mount\"\"\"\n\n    try:\n        remote, path = device.split(\":\", 1)\n    except ValueError:\n        remote = device\n        path = \"/\"\n\n    if FS_ID_RE.match(remote):\n        return remote, path, None\n\n    try:\n        primary, secondaries, _ = socket.gethostbyname_ex(remote)\n        hostnames = list(filter(lambda e: e is not None, [primary] + secondaries))\n    except socket.gaierror:\n        create_default_cloudwatchlog_agent_if_not_exist(config, options)\n        fatal_error(\n            'Failed to resolve \"%s\" - check that the specified DNS name is a CNAME record resolving to a valid EFS DNS '\n            \"name\" % remote,\n            'Failed to resolve \"%s\"' % remote,\n        )\n\n    if not hostnames:\n        create_default_cloudwatchlog_agent_if_not_exist(config, options)\n        fatal_error(\n            'The specified domain name \"%s\" did not resolve to an EFS mount target'\n            % remote\n        )\n\n    for hostname in hostnames:\n        efs_fqdn_match = EFS_FQDN_RE.match(hostname)\n\n        if efs_fqdn_match:\n            az = efs_fqdn_match.group(\"az\")\n            fs_id = efs_fqdn_match.group(\"fs_id\")\n\n            if az and \"az\" in options and az != options[\"az\"]:\n                fatal_error(\n                    'The hostname \"%s\" resolved by the specified domain name \"%s\" does not match the az provided in the '\n                    \"mount options, expected = %s, given = %s\"\n                    % (hostname, remote, options[\"az\"], az)\n                )\n\n            expected_dns_name, _ = get_dns_name_and_fallback_mount_target_ip_address(\n                config, fs_id, add_field_in_options(options, \"az\", az)\n            )\n\n            # check that the DNS name of the mount target matches exactly the DNS name the CNAME resolves to\n            if hostname == expected_dns_name:\n                return fs_id, path, az\n    else:\n        create_default_cloudwatchlog_agent_if_not_exist(config, options)\n        fatal_error(\n            'The specified CNAME \"%s\" did not resolve to a valid DNS name for an EFS mount target. '\n            \"Please refer to the EFS documentation for mounting with DNS names for examples: %s\"\n            % (\n                remote,\n                \"https://docs.aws.amazon.com/efs/latest/ug/mounting-fs-mount-cmd-dns-name.html\",\n            )\n        )\n\n\ndef add_field_in_options(options, field_key, field_value):\n    if field_value and field_key not in options:\n        options[field_key] = field_value\n    return options\n\n\ndef is_nfs_mount(mountpoint):\n    if not check_if_platform_is_mac():\n        cmd = [\"stat\", \"-f\", \"-L\", \"-c\", \"%T\", mountpoint]\n        p = subprocess.Popen(\n            cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, close_fds=True\n        )\n        output, _ = p.communicate()\n        return output and \"nfs\" in str(output)\n    else:\n        process = subprocess.run(\n            [\"mount\", \"-t\", \"nfs\"],\n            check=True,\n            stdout=subprocess.PIPE,\n            universal_newlines=True,\n        )\n        stdout = process.stdout\n        if not stdout:\n            return False\n        mounts = stdout.split(\"\\n\")\n        for mount in mounts:\n            _mount = mount.split()\n            if len(_mount) >= 4 and _mount[2] == mountpoint and \"nfs\" in _mount[3]:\n                return True\n        return False\n\n\ndef mount_tls(\n    config,\n    init_system,\n    dns_name,\n    path,\n    fs_id,\n    mountpoint,\n    options,\n    fallback_ip_address=None,\n):\n    if os.path.ismount(mountpoint) and is_nfs_mount(mountpoint):\n        sys.stdout.write(\n            \"%s is already mounted, please run 'mount' command to verify\\n\" % mountpoint\n        )\n        logging.warning(\"%s is already mounted, mount aborted\" % mountpoint)\n        return\n\n    with bootstrap_tls(\n        config,\n        init_system,\n        dns_name,\n        fs_id,\n        mountpoint,\n        options,\n        fallback_ip_address=fallback_ip_address,\n    ) as tunnel_proc:\n        mount_completed = threading.Event()\n        t = threading.Thread(\n            target=poll_tunnel_process, args=(tunnel_proc, fs_id, mount_completed)\n        )\n        t.daemon = True\n        t.start()\n        mount_nfs(config, dns_name, path, mountpoint, options)\n        mount_completed.set()\n        t.join()\n\n\ndef verify_tlsport_can_be_connected(tlsport):\n    try:\n        test_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM, 0)\n    except Exception as e:\n        logging.warning(\"Error opening a socket, %s\", e)\n        return False\n    try:\n        logging.debug(\"Trying to connect to 127.0.0.1: %s\", tlsport)\n        test_socket.connect((\"127.0.0.1\", tlsport))\n        return True\n    except ConnectionRefusedError:\n        return False\n    finally:\n        test_socket.close()\n\n\ndef check_unsupported_options(options):\n    for unsupported_option in UNSUPPORTED_OPTIONS:\n        if unsupported_option in options:\n            warn_message = (\n                'The \"%s\" option is not supported and has been ignored, as amazon-efs-utils relies on a built-in '\n                \"trust store.\" % unsupported_option\n            )\n            sys.stderr.write(\"WARN: %s\\n\" % warn_message)\n            logging.warning(warn_message)\n            del options[unsupported_option]\n\n\ndef check_options_validity(options):\n    if \"tls\" in options:\n        if \"port\" in options:\n            fatal_error('The \"port\" and \"tls\" options are mutually exclusive')\n\n        if \"tlsport\" in options:\n            try:\n                int(options[\"tlsport\"])\n            except ValueError:\n                fatal_error(\n                    \"tlsport option [%s] is not an integer\" % options[\"tlsport\"]\n                )\n\n        if \"ocsp\" in options and \"noocsp\" in options:\n            fatal_error('The \"ocsp\" and \"noocsp\" options are mutually exclusive')\n\n        if \"notls\" in options:\n            fatal_error('The \"tls\" and \"notls\" options are mutually exclusive')\n\n    if \"accesspoint\" in options:\n        if \"tls\" not in options:\n            fatal_error('The \"tls\" option is required when mounting via \"accesspoint\"')\n        if not AP_ID_RE.match(options[\"accesspoint\"]):\n            fatal_error(\"Access Point ID %s is malformed\" % options[\"accesspoint\"])\n\n    if \"iam\" in options and \"tls\" not in options:\n        fatal_error('The \"tls\" option is required when mounting via \"iam\"')\n\n    if \"awsprofile\" in options and \"iam\" not in options:\n        fatal_error(\n            'The \"iam\" option is required when mounting with named profile option, \"awsprofile\"'\n        )\n\n    if \"awscredsuri\" in options:\n        if \"iam\" not in options:\n            fatal_error('The \"iam\" option is required when mounting with \"awscredsuri\"')\n        if \"awsprofile\" in options:\n            fatal_error(\n                'The \"awscredsuri\" and \"awsprofile\" options are mutually exclusive'\n            )\n        # The URI must start with slash symbol as it will be appended to the ECS task metadata endpoint\n        if not options[\"awscredsuri\"].startswith(\"/\"):\n            fatal_error(\"awscredsuri %s is malformed\" % options[\"awscredsuri\"])\n\n\ndef bootstrap_cloudwatch_logging(config, options, fs_id=None):\n    if not check_if_cloudwatch_log_enabled(config):\n        return None\n\n    cloudwatchlog_client = get_botocore_client(config, \"logs\", options)\n\n    if not cloudwatchlog_client:\n        return None\n\n    cloudwatchlog_config = get_cloudwatchlog_config(config, fs_id)\n\n    log_group_name = cloudwatchlog_config.get(\"log_group_name\")\n    log_stream_name = cloudwatchlog_config.get(\"log_stream_name\")\n    retention_days = cloudwatchlog_config.get(\"retention_days\")\n\n    group_creation_completed = create_cloudwatch_log_group(\n        cloudwatchlog_client, log_group_name\n    )\n\n    if not group_creation_completed:\n        return None\n\n    put_retention_policy_completed = put_cloudwatch_log_retention_policy(\n        cloudwatchlog_client, log_group_name, retention_days\n    )\n\n    if not put_retention_policy_completed:\n        return None\n\n    stream_creation_completed = create_cloudwatch_log_stream(\n        cloudwatchlog_client, log_group_name, log_stream_name\n    )\n\n    if not stream_creation_completed:\n        return None\n\n    return {\n        \"client\": cloudwatchlog_client,\n        \"log_group_name\": log_group_name,\n        \"log_stream_name\": log_stream_name,\n    }\n\n\ndef create_default_cloudwatchlog_agent_if_not_exist(config, options):\n    if not check_if_cloudwatch_log_enabled(config):\n        return None\n    global CLOUDWATCHLOG_AGENT\n    if not CLOUDWATCHLOG_AGENT:\n        CLOUDWATCHLOG_AGENT = bootstrap_cloudwatch_logging(config, options)\n\n\ndef get_fips_config(config):\n    \"\"\"\n    Check whether FIPS is enabled either by setting the `AWS_USE_FIPS_ENDPOINT`\n    environmental variable, or through the efs-utils config file.\n\n    Enabling FIPS means that both the Botocore client and stunnel will be configured\n    to use FIPS.\n    \"\"\"\n\n    return os.getenv(\n        AWS_FIPS_ENDPOINT_CONFIG_ENV, \"False\"\n    ).lower() == \"true\" or get_boolean_config_item_value(\n        config, CONFIG_SECTION, \"fips_mode_enabled\", default_value=False\n    )\n\n\ndef get_botocore_client(config, service, options):\n    if not BOTOCORE_PRESENT:\n        logging.error(\"Failed to import botocore, please install botocore first.\")\n        return None\n\n    botocore_config = None\n    if get_fips_config(config):\n        botocore_config = botocore.config.Config(use_fips_endpoint=True)\n\n    session = botocore.session.get_session()\n    region = get_target_region(config)\n\n    if options and options.get(\"awsprofile\"):\n        profile = options.get(\"awsprofile\")\n        session.set_config_variable(\"profile\", profile)\n        try:\n            return session.create_client(\n                service, region_name=region, config=botocore_config\n            )\n        except ProfileNotFound as e:\n            fatal_error(\n                \"%s, please add the [profile %s] section in the aws config file following %s and %s.\"\n                % (e, profile, NAMED_PROFILE_HELP_URL, CONFIG_FILE_SETTINGS_HELP_URL)\n            )\n\n    return session.create_client(service, region_name=region, config=botocore_config)\n\n\ndef get_cloudwatchlog_config(config, fs_id=None):\n    log_group_name = DEFAULT_CLOUDWATCH_LOG_GROUP\n    if config.has_option(CLOUDWATCH_LOG_SECTION, \"log_group_name\"):\n        log_group_name = config.get(CLOUDWATCH_LOG_SECTION, \"log_group_name\")\n\n        if \"{fs_id}\" in log_group_name:\n            if fs_id:\n                # Formatting the log_group_name with the fs_id.\n                log_group_name = log_group_name.format(fs_id=fs_id)\n            else:\n                # If fs_id is None so putting the logs into the log-group by removing '/{fs_id}' in log_group_name.\n                log_group_name = log_group_name.replace(\"/{fs_id}\", \"\")\n                logging.warning(\n                    \"Failed to load the File System ID, pushing logs to log group %s.\",\n                    log_group_name,\n                )\n\n    logging.debug(\"Pushing logs to log group named %s in Cloudwatch.\", log_group_name)\n    retention_days = DEFAULT_RETENTION_DAYS\n    if config.has_option(CLOUDWATCH_LOG_SECTION, \"retention_in_days\"):\n        retention_days = config.get(CLOUDWATCH_LOG_SECTION, \"retention_in_days\")\n\n    log_stream_name = get_cloudwatch_log_stream_name(config, fs_id)\n\n    return {\n        \"log_group_name\": log_group_name,\n        \"retention_days\": int(retention_days),\n        \"log_stream_name\": log_stream_name,\n    }\n\n\ndef get_cloudwatch_log_stream_name(config, fs_id=None):\n    instance_id = get_instance_identity_info_from_instance_metadata(\n        config, \"instanceId\"\n    )\n    if instance_id and fs_id:\n        log_stream_name = \"%s - %s - mount.log\" % (fs_id, instance_id)\n    elif instance_id:\n        log_stream_name = \"%s - mount.log\" % (instance_id)\n    elif fs_id:\n        log_stream_name = \"%s - mount.log\" % (fs_id)\n    else:\n        log_stream_name = \"default - mount.log\"\n\n    return log_stream_name\n\n\ndef check_if_platform_is_mac():\n    return sys.platform in MAC_OS_PLATFORM_LIST\n\n\ndef check_if_mac_version_is_supported():\n    return any(\n        release in platform.release() for release in MAC_OS_SUPPORTED_VERSION_LIST\n    )\n\n\ndef check_if_cloudwatch_log_enabled(config):\n    # We don't emit warning message here as there will always no `enabled` config item even for a new config file. By default we\n    # comment out the `enabled = true` in config file so that the cloudwatch log feature is disabled. This is not set as\n    # `enabled = false` because we enable this feature by uncommenting this item for user who use System Manager Distributor\n    # to install efs-utils. This gives user an opportunity to still disable the feature by setting `enabled = false`.\n    return get_boolean_config_item_value(\n        config,\n        CLOUDWATCH_LOG_SECTION,\n        \"enabled\",\n        default_value=False,\n        emit_warning_message=False,\n    )\n\n\ndef cloudwatch_create_log_group_helper(cloudwatchlog_client, log_group_name):\n    cloudwatchlog_client.create_log_group(logGroupName=log_group_name)\n    logging.info(\"Created cloudwatch log group %s\" % log_group_name)\n\n\ndef create_cloudwatch_log_group(cloudwatchlog_client, log_group_name):\n    try:\n        cloudwatch_create_log_group_helper(cloudwatchlog_client, log_group_name)\n    except ClientError as e:\n        exception = e.response[\"Error\"][\"Code\"]\n\n        if exception == \"ResourceAlreadyExistsException\":\n            logging.debug(\n                \"Log group %s already exist, %s\" % (log_group_name, e.response)\n            )\n            return True\n        elif exception == \"LimitExceededException\":\n            logging.error(\n                \"Reached the maximum number of log groups that can be created, %s\"\n                % e.response\n            )\n            return False\n        elif exception == \"OperationAbortedException\":\n            logging.debug(\n                \"Multiple requests to update the same log group %s were in conflict, %s\"\n                % (log_group_name, e.response)\n            )\n            return False\n        elif exception == \"InvalidParameterException\":\n            logging.error(\n                \"Log group name %s is specified incorrectly, %s\"\n                % (log_group_name, e.response)\n            )\n            return False\n        else:\n            handle_general_botocore_exceptions(e)\n            return False\n    except NoCredentialsError as e:\n        logging.warning(\"Credentials are not properly configured, %s\" % e)\n        return False\n    except EndpointConnectionError as e:\n        logging.warning(\"Could not connect to the endpoint, %s\" % e)\n        return False\n    except Exception as e:\n        logging.warning(\"Unknown error, %s.\" % e)\n        return False\n    return True\n\n\ndef cloudwatch_put_retention_policy_helper(\n    cloudwatchlog_client, log_group_name, retention_days\n):\n    cloudwatchlog_client.put_retention_policy(\n        logGroupName=log_group_name, retentionInDays=retention_days\n    )\n    logging.debug(\"Set cloudwatch log group retention days to %s\" % retention_days)\n\n\ndef put_cloudwatch_log_retention_policy(\n    cloudwatchlog_client, log_group_name, retention_days\n):\n    try:\n        cloudwatch_put_retention_policy_helper(\n            cloudwatchlog_client, log_group_name, retention_days\n        )\n    except ClientError as e:\n        exception = e.response[\"Error\"][\"Code\"]\n\n        if exception == \"ResourceNotFoundException\":\n            logging.error(\n                \"Log group %s does not exist, %s\" % (log_group_name, e.response)\n            )\n            return False\n        elif exception == \"OperationAbortedException\":\n            logging.debug(\n                \"Multiple requests to update the same log group %s were in conflict, %s\"\n                % (log_group_name, e.response)\n            )\n            return False\n        elif exception == \"InvalidParameterException\":\n            logging.error(\n                \"Either parameter log group name %s or retention in days %s is specified incorrectly, %s\"\n                % (log_group_name, retention_days, e.response)\n            )\n            return False\n        else:\n            handle_general_botocore_exceptions(e)\n            return False\n    except NoCredentialsError as e:\n        logging.warning(\"Credentials are not properly configured, %s\" % e)\n        return False\n    except EndpointConnectionError as e:\n        logging.warning(\"Could not connect to the endpoint, %s\" % e)\n        return False\n    except Exception as e:\n        logging.warning(\"Unknown error, %s.\" % e)\n        return False\n    return True\n\n\ndef cloudwatch_create_log_stream_helper(\n    cloudwatchlog_client, log_group_name, log_stream_name\n):\n    cloudwatchlog_client.create_log_stream(\n        logGroupName=log_group_name, logStreamName=log_stream_name\n    )\n    logging.info(\n        \"Created cloudwatch log stream %s in log group %s\"\n        % (log_stream_name, log_group_name)\n    )\n\n\ndef create_cloudwatch_log_stream(cloudwatchlog_client, log_group_name, log_stream_name):\n    try:\n        cloudwatch_create_log_stream_helper(\n            cloudwatchlog_client, log_group_name, log_stream_name\n        )\n    except ClientError as e:\n        exception = e.response[\"Error\"][\"Code\"]\n\n        if exception == \"ResourceAlreadyExistsException\":\n            logging.debug(\n                \"Log stream %s already exist in log group %s, %s\"\n                % (log_stream_name, log_group_name, e.response)\n            )\n            return True\n        elif exception == \"InvalidParameterException\":\n            logging.error(\n                \"Either parameter log group name %s or log stream name %s is specified incorrectly, %s\"\n                % (log_group_name, log_stream_name, e.response)\n            )\n            return False\n        elif exception == \"ResourceNotFoundException\":\n            logging.error(\n                \"Log group %s does not exist, %s\" % (log_group_name, e.response)\n            )\n            return False\n        else:\n            handle_general_botocore_exceptions(e)\n            return False\n    except NoCredentialsError as e:\n        logging.warning(\"Credentials are not properly configured, %s\" % e)\n        return False\n    except EndpointConnectionError as e:\n        logging.warning(\"Could not connect to the endpoint, %s\" % e)\n        return False\n    except Exception as e:\n        logging.warning(\"Unknown error, %s.\" % e)\n        return False\n    return True\n\n\ndef cloudwatch_put_log_events_helper(cloudwatchlog_agent, message, token=None):\n    kwargs = {\n        \"logGroupName\": cloudwatchlog_agent.get(\"log_group_name\"),\n        \"logStreamName\": cloudwatchlog_agent.get(\"log_stream_name\"),\n        \"logEvents\": [\n            {\"timestamp\": int(round(time.time() * 1000)), \"message\": message}\n        ],\n    }\n    if token:\n        kwargs[\"sequenceToken\"] = token\n    cloudwatchlog_agent.get(\"client\").put_log_events(**kwargs)\n\n\ndef publish_cloudwatch_log(cloudwatchlog_agent, message):\n    if not cloudwatchlog_agent or not cloudwatchlog_agent.get(\"client\"):\n        return False\n\n    token = get_log_stream_next_token(cloudwatchlog_agent)\n\n    try:\n        cloudwatch_put_log_events_helper(cloudwatchlog_agent, message, token)\n    except ClientError as e:\n        exception = e.response[\"Error\"][\"Code\"]\n\n        if exception == \"InvalidSequenceTokenException\":\n            logging.debug(\"The sequence token is not valid, %s\" % e.response)\n            return False\n        elif exception == \"InvalidParameterException\":\n            logging.debug(\n                \"One of the parameter to put log events is not valid, %s\" % e.response\n            )\n            return False\n        elif exception == \"DataAlreadyAcceptedException\":\n            logging.debug(\"The event %s was already logged, %s\" % (message, e.response))\n            return False\n        elif exception == \"UnrecognizedClientException\":\n            logging.debug(\n                \"The most likely cause is an invalid AWS access key ID or secret Key, %s\"\n                % e.response\n            )\n            return False\n        elif exception == \"ResourceNotFoundException\":\n            logging.error(\n                \"Either log group %s or log stream %s does not exist, %s\"\n                % (\n                    cloudwatchlog_agent.get(\"log_group_name\"),\n                    cloudwatchlog_agent.get(\"log_stream_name\"),\n                    e.response,\n                )\n            )\n            return False\n        else:\n            logging.debug(\"Unexpected error: %s\" % e)\n            return False\n    except NoCredentialsError as e:\n        logging.warning(\"Credentials are not properly configured, %s\" % e)\n        return False\n    except EndpointConnectionError as e:\n        logging.warning(\"Could not connect to the endpoint, %s\" % e)\n        return False\n    except Exception as e:\n        logging.warning(\"Unknown error, %s.\" % e)\n        return False\n    return True\n\n\ndef cloudwatch_describe_log_streams_helper(cloudwatchlog_agent):\n    return cloudwatchlog_agent.get(\"client\").describe_log_streams(\n        logGroupName=cloudwatchlog_agent.get(\"log_group_name\"),\n        logStreamNamePrefix=cloudwatchlog_agent.get(\"log_stream_name\"),\n    )\n\n\ndef get_log_stream_next_token(cloudwatchlog_agent):\n    try:\n        response = cloudwatch_describe_log_streams_helper(cloudwatchlog_agent)\n    except ClientError as e:\n        exception = e.response[\"Error\"][\"Code\"]\n\n        if exception == \"InvalidParameterException\":\n            logging.debug(\n                \"Either parameter log group name %s or log stream name %s is specified incorrectly, %s\"\n                % (\n                    cloudwatchlog_agent.get(\"log_group_name\"),\n                    cloudwatchlog_agent.get(\"log_stream_name\"),\n                    e.response,\n                )\n            )\n        elif exception == \"ResourceNotFoundException\":\n            logging.debug(\n                \"Either log group %s or log stream %s does not exist, %s\"\n                % (\n                    cloudwatchlog_agent.get(\"log_group_name\"),\n                    cloudwatchlog_agent.get(\"log_stream_name\"),\n                    e.response,\n                )\n            )\n        else:\n            handle_general_botocore_exceptions(e)\n        return None\n    except NoCredentialsError as e:\n        logging.warning(\"Credentials are not properly configured, %s\" % e)\n        return None\n    except EndpointConnectionError as e:\n        logging.warning(\"Could not connect to the endpoint, %s\" % e)\n        return None\n    except Exception as e:\n        logging.warning(\"Unknown error, %s\" % e)\n        return None\n\n    try:\n        log_stream = response[\"logStreams\"][0]\n        return log_stream.get(\"uploadSequenceToken\")\n    except (IndexError, TypeError, KeyError):\n        pass\n\n    return None\n\n\ndef ec2_describe_availability_zones_helper(ec2_client, kwargs):\n    # https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/ec2.html#EC2.Client.describe_availability_zones\n    return ec2_client.describe_availability_zones(**kwargs)\n\n\ndef get_az_id_by_az_name_helper(ec2_client, az_name, dryrun=False):\n    operation = \"DescribeAvailabilityZones\"\n    kwargs = {\"ZoneNames\": [az_name]}\n    if dryrun:\n        kwargs[\"DryRun\"] = True\n\n    try:\n        az_info = ec2_describe_availability_zones_helper(ec2_client, kwargs)\n        logging.debug(\"Found the az information for %s: %s\", az_name, az_info)\n        return az_info\n    except ClientError as e:\n        exception = e.response[\"Error\"][\"Code\"]\n        exception_message = e.response[\"Error\"][\"Message\"]\n\n        if exception == \"DryRunOperation\":\n            logging.debug(\"Describe availability zones dryrun succeed.\")\n            return\n        elif exception == \"UnauthorizedOperation\":\n            fallback_message = \"Unauthorized to perform operation %s.\" % operation\n        elif exception == \"InvalidParameterValue\":\n            fallback_message = \"Invalid availability zone %s\" % az_name\n        elif exception == \"ServiceUnavailableException\":\n            fallback_message = (\n                \"The ec2 service cannot complete the request, %s\" % exception_message\n            )\n        elif exception == \"AccessDeniedException\":\n            fallback_message = exception_message\n        else:\n            fallback_message = \"Unexpected error: %s\" % exception_message\n    except NoCredentialsError as e:\n        fallback_message = (\n            \"%s when performing operation %s, please confirm your aws credentials are properly configured.\"\n            % (e, operation)\n        )\n    except EndpointConnectionError as e:\n        fallback_message = (\n            \"Could not connect to the endpoint when performing operation %s, %s\"\n            % (operation, e)\n        )\n    except Exception as e:\n        fallback_message = \"Unknown error when performing operation %s, %s.\" % (\n            operation,\n            e,\n        )\n    raise FallbackException(fallback_message)\n\n\ndef get_az_id_by_az_name(ec2_client, az_name):\n    # Perform a dryrun api call first\n    get_az_id_by_az_name_helper(ec2_client, az_name, dryrun=True)\n    az_info = get_az_id_by_az_name_helper(ec2_client, az_name, dryrun=False)\n    if az_info and az_info.get(\"AvailabilityZones\"):\n        az_id = az_info[\"AvailabilityZones\"][0][\"ZoneId\"]\n        logging.debug(\"Found AZ mapping [AZ name: %s, AZ ID: %s]\", az_name, az_id)\n        return az_id\n    return None\n\n\ndef efs_describe_mount_targets_helper(efs_client, kwargs):\n    # https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/efs.html#EFS.Client.describe_mount_targets\n    return efs_client.describe_mount_targets(**kwargs)\n\n\ndef get_mount_targets_info(efs_client, fs_id):\n    operation = \"DescribeMountTargets\"\n    kwargs = {\"FileSystemId\": fs_id}\n\n    try:\n        mount_targets_info = efs_describe_mount_targets_helper(efs_client, kwargs)\n        logging.debug(\n            \"Found these mount targets for file system %s: %s\",\n            fs_id,\n            mount_targets_info,\n        )\n        return mount_targets_info.get(\"MountTargets\")\n    except ClientError as e:\n        exception = e.response[\"Error\"][\"Code\"]\n        exception_message = e.response[\"Error\"][\"Message\"]\n\n        if exception == \"FileSystemNotFound\":\n            fallback_message = \"The file system %s is not found\" % fs_id\n        elif exception == \"ServiceUnavailableException\":\n            fallback_message = (\n                \"The elasticfilesystem service cannot complete the request, %s\"\n                % exception_message\n            )\n        elif exception == \"AccessDeniedException\":\n            fallback_message = exception_message\n        else:\n            fallback_message = \"Unexpected error: %s\" % exception_message\n    except NoCredentialsError as e:\n        fallback_message = (\n            \"%s when performing operation %s, please confirm your aws credentials are properly configured.\"\n            % (e, operation)\n        )\n    except EndpointConnectionError as e:\n        fallback_message = (\n            \"Could not connect to the endpoint when performing operation %s, %s\"\n            % (operation, e)\n        )\n    except Exception as e:\n        fallback_message = \"Unknown error when performing operation %s, %s.\" % (\n            operation,\n            e,\n        )\n\n    raise FallbackException(fallback_message)\n\n\ndef get_mount_target_in_az(efs_client, ec2_client, fs_id, az_name=None):\n    if not efs_client or not ec2_client:\n        raise FallbackException(\"Boto client cannot be null\")\n\n    mount_targets = get_mount_targets_info(efs_client, fs_id)\n    if not mount_targets:\n        message = (\n            \"Cannot find mount target for the file system %s, please create a mount target in %s.\"\n            % (fs_id, az_name if az_name else \"any availability zone.\")\n        )\n        raise FallbackException(message)\n\n    available_mount_targets = [\n        mount_target\n        for mount_target in mount_targets\n        if mount_target.get(\"LifeCycleState\") == \"available\"\n    ]\n    if not available_mount_targets:\n        message = (\n            \"No mount target created for the file system %s is in available state yet, please retry in 5 minutes.\"\n            % fs_id\n        )\n        raise FallbackException(message)\n\n    if az_name:\n        az_id = get_az_id_by_az_name(ec2_client, az_name)\n    else:\n        # If the az_name is None, which means the IMDS instance identity retrieve failed,\n        # in that case randomly pick one available mount target\n        logging.info(\n            \"No az info passed via options, randomly pick one available mount target.\"\n        )\n        return random.choice(available_mount_targets)\n\n    az_names_of_available_mount_targets = [\n        mount_target.get(\"AvailabilityZoneName\")\n        for mount_target in available_mount_targets\n    ]\n    available_mount_targets_message = (\n        \"Available mount target(s) are in az %s\" % az_names_of_available_mount_targets\n    )\n\n    if not az_id:\n        message = (\n            \"No matching az id for the az %s. Please check the az option passed. %s\"\n            % (az_name, available_mount_targets_message)\n        )\n        raise FallbackException(message)\n\n    for mount_target in mount_targets:\n        if mount_target[\"AvailabilityZoneId\"] == az_id:\n            mount_target_state = mount_target.get(\"LifeCycleState\")\n            if mount_target_state != \"available\":\n                message = \"Unknown mount target state\"\n                if mount_target_state in [\"creating\", \"updating\", \"error\"]:\n                    message = (\n                        \"Mount target in the az %s is %s, please retry in 5 minutes, or use the \"\n                        \"mount target in the other az by passing the availability zone name option. %s\"\n                        % (az_name, mount_target_state, available_mount_targets_message)\n                    )\n                elif mount_target_state in [\"deleted\", \"deleting\"]:\n                    message = (\n                        \"Mount target in the availability zone %s is %s, \"\n                        'please create a new one in %s, or use the \" \"mount target '\n                        \"in the other az by passing the availability zone name option. %s\"\n                    ) % (\n                        az_name,\n                        mount_target_state,\n                        az_name,\n                        available_mount_targets_message,\n                    )\n                raise FallbackException(message)\n            return mount_target\n\n    message = (\n        \"No matching mount target in the az %s. Please create one mount target in %s, or try the mount target in another \"\n        \"AZ by passing the availability zone name option. %s\"\n        % (az_name, az_name, available_mount_targets_message)\n    )\n    raise FallbackException(message)\n\n\ndef handle_general_botocore_exceptions(error):\n    exception = error.response[\"Error\"][\"Code\"]\n\n    if exception == \"ServiceUnavailableException\":\n        logging.debug(\"The service cannot complete the request, %s\" % error.response)\n    elif exception == \"AccessDeniedException\":\n        logging.debug(\n            \"User is not authorized to perform the action, %s\" % error.response\n        )\n    else:\n        logging.debug(\"Unexpected error: %s\" % error)\n\n\n# A change in the Linux kernel 5.4+ results a throughput regression on NFS client.\n# With patch (https://bugzilla.kernel.org/show_bug.cgi?id=204939), starting from 5.4.*,\n# Linux NFS client is using a fixed default value of 128K as read_ahead_kb.\n# Before this patch, the read_ahead_kb equation is (NFS_MAX_READAHEAD) 15 * (client configured read size).\n# Thus, with EFS recommendation of rsize (1MB) in mount option,\n# NFS client might see a throughput drop in kernel 5.4+, especially for sequential read.\n# To fix the issue, below function will modify read_ahead_kb to 15 * rsize (1MB by default) after mount.\ndef optimize_readahead_window(mountpoint, options, config):\n\n    if not should_revise_readahead(config):\n        return\n\n    fixed_readahead_kb = int(\n        DEFAULT_NFS_MAX_READAHEAD_MULTIPLIER * int(options[\"rsize\"]) / 1024\n    )\n\n    try:\n        major, minor = decode_device_number(os.stat(mountpoint).st_dev)\n        # modify read_ahead_kb in /sys/class/bdi/<bdi>/read_ahead_kb\n        # The bdi identifier is in the form of MAJOR:MINOR, which can be derived from device number\n        #\n        read_ahead_kb_config_file = NFS_READAHEAD_CONFIG_PATH_FORMAT % (major, minor)\n\n        logging.debug(\n            \"Modifying value in %s to %s.\",\n            read_ahead_kb_config_file,\n            str(fixed_readahead_kb),\n        )\n        p = subprocess.Popen(\n            \"echo %s > %s\" % (fixed_readahead_kb, read_ahead_kb_config_file),\n            shell=True,\n            stderr=subprocess.PIPE,\n            stdout=subprocess.DEVNULL,\n        )\n        _, error = p.communicate()\n        if p.returncode != 0:\n            logging.warning(\n                'Failed to modify read_ahead_kb: %s with returncode: %d, error: \"%s\".'\n                % (fixed_readahead_kb, p.returncode, error.strip())\n            )\n    except Exception as e:\n        logging.warning(\n            'Failed to modify read_ahead_kb: %s with error: \"%s\".'\n            % (fixed_readahead_kb, e)\n        )\n\n\n# https://github.com/torvalds/linux/blob/master/include/linux/kdev_t.h#L48-L49\ndef decode_device_number(device_number):\n    major = (device_number & 0xFFF00) >> 8\n    minor = (device_number & 0xFF) | ((device_number >> 12) & 0xFFF00)\n    return major, minor\n\n\n# Only modify read_ahead_kb iff\n# 1. instance platform is linux\n# 2. kernel version of instance is 5.4+\n# 3. 'optimize_readahead' is set to true in efs-utils config file\ndef should_revise_readahead(config):\n    if platform.system() != \"Linux\":\n        return False\n\n    if (\n        get_linux_kernel_version(len(NFS_READAHEAD_OPTIMIZE_LINUX_KERNEL_MIN_VERSION))\n        < NFS_READAHEAD_OPTIMIZE_LINUX_KERNEL_MIN_VERSION\n    ):\n        return False\n\n    return get_boolean_config_item_value(\n        config, CONFIG_SECTION, OPTIMIZE_READAHEAD_ITEM, default_value=False\n    )\n\n\n# Parse Linux kernel version from platform.release()\n# Failback to 0.0.0... as invalid version\n# Examples:\n#             platform.release()                Parsed version with desired_length:2\n# RHEL        3.10.0-1160.el7.x86_64            [3, 10]\n# AL2         5.4.105-48.177.amzn2.x86_64       [5, 4]\n# Ubuntu      5.4.0-1038-aws                    [5, 4]\n# OpenSUSE    5.3.18-24.37-default              [5, 3]\ndef get_linux_kernel_version(desired_length):\n    version = []\n    try:\n        version = [\n            int(v)\n            for v in platform.release().split(\"-\", 1)[0].split(\".\")[:desired_length]\n        ]\n    except ValueError:\n        logging.warning(\"Failed to retrieve linux kernel version\")\n    # filling 0 at the end\n    for i in range(len(version), desired_length):\n        version.append(0)\n    return version\n\n\ndef main():\n    parse_arguments_early_exit()\n\n    assert_root()\n\n    config = read_config()\n    bootstrap_logging(config)\n\n    if check_if_platform_is_mac() and not check_if_mac_version_is_supported():\n        fatal_error(\n            \"We do not support EFS on MacOS Kernel version \" + platform.release()\n        )\n\n    fs_id, path, mountpoint, options = parse_arguments(config)\n\n    logging.info(\"version=%s options=%s\", VERSION, options)\n\n    global CLOUDWATCHLOG_AGENT\n    CLOUDWATCHLOG_AGENT = bootstrap_cloudwatch_logging(config, options, fs_id)\n\n    check_unsupported_options(options)\n    check_options_validity(options)\n\n    init_system = get_init_system()\n    check_network_status(fs_id, init_system)\n\n    dns_name, fallback_ip_address = get_dns_name_and_fallback_mount_target_ip_address(\n        config, fs_id, options\n    )\n\n    if check_if_platform_is_mac() and \"notls\" not in options:\n        options[\"tls\"] = None\n\n    if \"tls\" in options:\n        mount_tls(\n            config,\n            init_system,\n            dns_name,\n            path,\n            fs_id,\n            mountpoint,\n            options,\n            fallback_ip_address=fallback_ip_address,\n        )\n    else:\n        mount_nfs(\n            config,\n            dns_name,\n            path,\n            mountpoint,\n            options,\n            fallback_ip_address=fallback_ip_address,\n        )\n\n\nif \"__main__\" == __name__:\n    main()\n", "#!/usr/bin/env python3\n#\n# Copyright 2017-2018 Amazon.com, Inc. and its affiliates. All Rights Reserved.\n#\n# Licensed under the MIT License. See the LICENSE accompanying this file\n# for the specific language governing permissions and limitations under\n# the License.\n#\n\nimport base64\nimport errno\nimport hashlib\nimport hmac\nimport json\nimport logging\nimport logging.handlers\nimport os\nimport platform\nimport pwd\nimport re\nimport shutil\nimport socket\nimport subprocess\nimport sys\nimport time\nfrom collections import namedtuple\nfrom contextlib import contextmanager\nfrom datetime import datetime, timedelta\nfrom logging.handlers import RotatingFileHandler\nfrom signal import SIGHUP, SIGKILL, SIGTERM\n\ntry:\n    from configparser import ConfigParser, NoOptionError, NoSectionError\nexcept ImportError:\n    import ConfigParser\n    from ConfigParser import NoOptionError, NoSectionError\n\ntry:\n    from urllib.parse import quote_plus\nexcept ImportError:\n    from urllib import quote_plus\n\ntry:\n    from urllib.error import HTTPError, URLError\n    from urllib.parse import urlencode\n    from urllib.request import Request, urlopen\nexcept ImportError:\n    from urllib import urlencode\n\n    from urllib2 import HTTPError, HTTPHandler, Request, URLError, build_opener, urlopen\n\n\nAMAZON_LINUX_2_RELEASE_ID = \"Amazon Linux release 2 (Karoo)\"\nAMAZON_LINUX_2_PRETTY_NAME = \"Amazon Linux 2\"\nAMAZON_LINUX_2_RELEASE_VERSIONS = [\n    AMAZON_LINUX_2_RELEASE_ID,\n    AMAZON_LINUX_2_PRETTY_NAME,\n]\nVERSION = \"1.34.4\"\nSERVICE = \"elasticfilesystem\"\n\nCONFIG_FILE = \"/etc/amazon/efs/efs-utils.conf\"\nCONFIG_SECTION = \"mount-watchdog\"\nMOUNT_CONFIG_SECTION = \"mount\"\nCLIENT_INFO_SECTION = \"client-info\"\nCLIENT_SOURCE_STR_LEN_LIMIT = 100\nDISABLE_FETCH_EC2_METADATA_TOKEN_ITEM = \"disable_fetch_ec2_metadata_token\"\nDEFAULT_UNKNOWN_VALUE = \"unknown\"\nDEFAULT_MACOS_VALUE = \"macos\"\n# 50ms\nDEFAULT_TIMEOUT = 0.05\n\nLOG_DIR = \"/var/log/amazon/efs\"\nLOG_FILE = \"mount-watchdog.log\"\n\nSTATE_FILE_DIR = \"/var/run/efs\"\nSTUNNEL_PID_FILE = \"stunnel.pid\"\n\nDEFAULT_NFS_PORT = \"2049\"\nPRIVATE_KEY_FILE = \"/etc/amazon/efs/privateKey.pem\"\nDEFAULT_REFRESH_SELF_SIGNED_CERT_INTERVAL_MIN = 60\nDEFAULT_STUNNEL_HEALTH_CHECK_INTERVAL_MIN = 5\nDEFAULT_STUNNEL_HEALTH_CHECK_TIMEOUT_SEC = 30\nNOT_BEFORE_MINS = 15\nNOT_AFTER_HOURS = 3\nDATE_ONLY_FORMAT = \"%Y%m%d\"\nSIGV4_DATETIME_FORMAT = \"%Y%m%dT%H%M%SZ\"\nCERT_DATETIME_FORMAT = \"%y%m%d%H%M%SZ\"\n\nAWS_CREDENTIALS_FILES = {\n    \"credentials\": os.path.expanduser(\n        os.path.join(\"~\" + pwd.getpwuid(os.getuid()).pw_name, \".aws\", \"credentials\")\n    ),\n    \"config\": os.path.expanduser(\n        os.path.join(\"~\" + pwd.getpwuid(os.getuid()).pw_name, \".aws\", \"config\")\n    ),\n}\n\nCA_CONFIG_BODY = \"\"\"dir = %s\nRANDFILE = $dir/database/.rand\n\n[ ca ]\ndefault_ca = local_ca\n\n[ local_ca ]\ndatabase = $dir/database/index.txt\nserial = $dir/database/serial\nprivate_key = %s\ncert = $dir/certificate.pem\nnew_certs_dir = $dir/certs\ndefault_md = sha256\npreserve = no\npolicy = efsPolicy\nx509_extensions = v3_ca\n\n[ efsPolicy ]\nCN = supplied\n\n[ req ]\nprompt = no\ndistinguished_name = req_distinguished_name\n\n[ req_distinguished_name ]\nCN = %s\n\n%s\n\n%s\n\n%s\n\"\"\"\n\n# SigV4 Auth\nALGORITHM = \"AWS4-HMAC-SHA256\"\nAWS4_REQUEST = \"aws4_request\"\n\nHTTP_REQUEST_METHOD = \"GET\"\nCANONICAL_URI = \"/\"\nCANONICAL_HEADERS_DICT = {\"host\": \"%s\"}\nCANONICAL_HEADERS = \"\\n\".join(\n    [\"%s:%s\" % (k, v) for k, v in sorted(CANONICAL_HEADERS_DICT.items())]\n)\nSIGNED_HEADERS = \";\".join(CANONICAL_HEADERS_DICT.keys())\nREQUEST_PAYLOAD = \"\"\n\nAP_ID_RE = re.compile(\"^fsap-[0-9a-f]{17}$\")\n\nECS_TASK_METADATA_API = \"http://169.254.170.2\"\nSTS_ENDPOINT_URL_FORMAT = \"https://sts.{}.amazonaws.com/\"\nINSTANCE_IAM_URL = \"http://169.254.169.254/latest/meta-data/iam/security-credentials/\"\nINSTANCE_METADATA_TOKEN_URL = \"http://169.254.169.254/latest/api/token\"\nSECURITY_CREDS_ECS_URI_HELP_URL = (\n    \"https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task-iam-roles.html\"\n)\nSECURITY_CREDS_WEBIDENTITY_HELP_URL = \"https://docs.aws.amazon.com/eks/latest/userguide/iam-roles-for-service-accounts.html\"\nSECURITY_CREDS_IAM_ROLE_HELP_URL = (\n    \"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/iam-roles-for-amazon-ec2.html\"\n)\nNAMED_PROFILE_HELP_URL = (\n    \"https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-profiles.html\"\n)\nCONFIG_FILE_SETTINGS_HELP_URL = (\n    \"https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-files.html\"\n    \"#cli-configure-files-settings\"\n)\n\nMount = namedtuple(\n    \"Mount\", [\"server\", \"mountpoint\", \"type\", \"options\", \"freq\", \"passno\"]\n)\n\nNFSSTAT_TIMEOUT = 5\n\n# Unmount difference time in seconds\nUNMOUNT_DIFF_TIME = 30\n\n# Default unmount count for consistency\nDEFAULT_UNMOUNT_COUNT_FOR_CONSISTENCY = 5\n\nMAC_OS_PLATFORM_LIST = [\"darwin\"]\nSYSTEM_RELEASE_PATH = \"/etc/system-release\"\nOS_RELEASE_PATH = \"/etc/os-release\"\nSTUNNEL_INSTALLATION_MESSAGE = \"Please install it following the instructions at: https://docs.aws.amazon.com/efs/latest/ug/using-amazon-efs-utils.html#upgrading-stunnel\"\n\n\ndef fatal_error(user_message, log_message=None):\n    if log_message is None:\n        log_message = user_message\n\n    sys.stderr.write(\"%s\\n\" % user_message)\n    logging.error(log_message)\n    sys.exit(1)\n\n\ndef get_aws_security_credentials(config, credentials_source, region):\n    \"\"\"\n    Lookup AWS security credentials (access key ID and secret access key). Adapted credentials provider chain from:\n    https://boto3.amazonaws.com/v1/documentation/api/latest/guide/configuration.html and\n    https://docs.aws.amazon.com/sdk-for-java/v1/developer-guide/credentials.html\n    \"\"\"\n    method, value = credentials_source.split(\":\", 1)\n\n    if method == \"credentials\":\n        return get_aws_security_credentials_from_file(\"credentials\", value)\n    elif method == \"named_profile\":\n        return get_aws_security_credentials_from_assumed_profile(value)\n    elif method == \"config\":\n        return get_aws_security_credentials_from_file(\"config\", value)\n    elif method == \"ecs\":\n        return get_aws_security_credentials_from_ecs(config, value)\n    elif method == \"webidentity\":\n        return get_aws_security_credentials_from_webidentity(\n            config, *(value.split(\",\")), region=region\n        )\n    elif method == \"metadata\":\n        return get_aws_security_credentials_from_instance_metadata(config)\n    else:\n        logging.error(\n            'Improper credentials source string \"%s\" found from mount state file',\n            credentials_source,\n        )\n        return None\n\n\ndef get_boolean_config_item_value(\n    config, config_section, config_item, default_value, emit_warning_message=False\n):\n    warning_message = None\n    if not config.has_section(config_section):\n        warning_message = (\n            \"Warning: config file does not have section %s.\" % config_section\n        )\n    elif not config.has_option(config_section, config_item):\n        warning_message = (\n            \"Warning: config file does not have %s item in section %s.\"\n            % (config_item, config_section)\n        )\n\n    if warning_message:\n        if emit_warning_message:\n            sys.stdout.write(\n                \"%s. You should be able to find a new config file in the same folder as current config file %s. \"\n                \"Consider update the new config file to latest config file. Use the default value [%s = %s].\"\n                % (warning_message, CONFIG_FILE, config_item, default_value)\n            )\n        return default_value\n    return config.getboolean(config_section, config_item)\n\n\ndef fetch_ec2_metadata_token_disabled(config):\n    return get_boolean_config_item_value(\n        config,\n        MOUNT_CONFIG_SECTION,\n        DISABLE_FETCH_EC2_METADATA_TOKEN_ITEM,\n        default_value=False,\n    )\n\n\ndef get_aws_ec2_metadata_token(timeout=DEFAULT_TIMEOUT):\n    # Normally the session token is fetched within 10ms, setting a timeout of 50ms here to abort the request\n    # and return None if the token has not returned within 50ms\n    try:\n        opener = build_opener(HTTPHandler)\n        request = Request(INSTANCE_METADATA_TOKEN_URL)\n        request.add_header(\"X-aws-ec2-metadata-token-ttl-seconds\", \"21600\")\n        request.get_method = lambda: \"PUT\"\n        try:\n            res = opener.open(request, timeout=timeout)\n            return res.read()\n        except socket.timeout:\n            exception_message = \"Timeout when getting the aws ec2 metadata token\"\n        except HTTPError as e:\n            exception_message = \"Failed to fetch token due to %s\" % e\n        except Exception as e:\n            exception_message = (\n                \"Unknown error when fetching aws ec2 metadata token, %s\" % e\n            )\n        logging.debug(exception_message)\n        return None\n    except NameError:\n        headers = {\"X-aws-ec2-metadata-token-ttl-seconds\": \"21600\"}\n        req = Request(INSTANCE_METADATA_TOKEN_URL, headers=headers, method=\"PUT\")\n        try:\n            res = urlopen(req, timeout=timeout)\n            return res.read()\n        except socket.timeout:\n            exception_message = \"Timeout when getting the aws ec2 metadata token\"\n        except HTTPError as e:\n            exception_message = \"Failed to fetch token due to %s\" % e\n        except Exception as e:\n            exception_message = (\n                \"Unknown error when fetching aws ec2 metadata token, %s\" % e\n            )\n        logging.debug(exception_message)\n        return None\n\n\ndef get_aws_security_credentials_from_file(file_name, awsprofile):\n    # attempt to lookup AWS security credentials in AWS credentials file (~/.aws/credentials) and configs file (~/.aws/config)\n    file_path = AWS_CREDENTIALS_FILES.get(file_name)\n    if file_path and os.path.exists(file_path):\n        credentials = credentials_file_helper(file_path, awsprofile)\n        if credentials[\"AccessKeyId\"]:\n            return credentials\n\n    logging.error(\n        \"AWS security credentials not found in %s under named profile [%s]\",\n        file_path,\n        awsprofile,\n    )\n    return None\n\n\ndef get_aws_security_credentials_from_assumed_profile(awsprofile):\n    credentials = botocore_credentials_helper(awsprofile)\n    if credentials[\"AccessKeyId\"]:\n        return credentials\n\n    logging.error(\n        \"AWS security credentials not found via assuming named profile [%s] using botocore\",\n        awsprofile,\n    )\n    return None\n\n\ndef botocore_credentials_helper(awsprofile):\n    credentials = {\"AccessKeyId\": None, \"SecretAccessKey\": None, \"Token\": None}\n\n    try:\n        import botocore.session\n        from botocore.exceptions import ProfileNotFound\n    except ImportError:\n        logging.error(\n            \"Named profile credentials cannot be retrieved without botocore, please install botocore first.\"\n        )\n        return credentials\n\n    session = botocore.session.get_session()\n    session.set_config_variable(\"profile\", awsprofile)\n\n    try:\n        frozen_credentials = session.get_credentials().get_frozen_credentials()\n    except ProfileNotFound as e:\n        logging.error(\n            \"%s, please add the [profile %s] section in the aws config file following %s and %s.\"\n            % (e, awsprofile, NAMED_PROFILE_HELP_URL, CONFIG_FILE_SETTINGS_HELP_URL)\n        )\n        return credentials\n\n    credentials[\"AccessKeyId\"] = frozen_credentials.access_key\n    credentials[\"SecretAccessKey\"] = frozen_credentials.secret_key\n    credentials[\"Token\"] = frozen_credentials.token\n    return credentials\n\n\ndef get_aws_security_credentials_from_ecs(config, uri):\n    # through ECS security credentials uri found in AWS_CONTAINER_CREDENTIALS_RELATIVE_URI environment variable\n    dict_keys = [\"AccessKeyId\", \"SecretAccessKey\", \"Token\"]\n    ecs_uri = ECS_TASK_METADATA_API + uri\n    ecs_unsuccessful_resp = (\n        \"Unsuccessful retrieval of AWS security credentials at %s.\" % ecs_uri\n    )\n    ecs_url_error_msg = (\n        \"Unable to reach %s to retrieve AWS security credentials. See %s for more info.\"\n        % (ecs_uri, SECURITY_CREDS_ECS_URI_HELP_URL)\n    )\n    ecs_security_dict = url_request_helper(\n        config, ecs_uri, ecs_unsuccessful_resp, ecs_url_error_msg\n    )\n\n    if ecs_security_dict and all(k in ecs_security_dict for k in dict_keys):\n        return ecs_security_dict\n\n    return None\n\n\ndef get_aws_security_credentials_from_webidentity(config, role_arn, token_file, region):\n    try:\n        with open(token_file, \"r\") as f:\n            token = f.read()\n    except Exception as e:\n        logging.error(\"Error reading token file %s: %s\", token_file, e)\n        return None\n\n    STS_ENDPOINT_URL = STS_ENDPOINT_URL_FORMAT.format(region)\n    webidentity_url = (\n        STS_ENDPOINT_URL\n        + \"?\"\n        + urlencode(\n            {\n                \"Version\": \"2011-06-15\",\n                \"Action\": \"AssumeRoleWithWebIdentity\",\n                \"RoleArn\": role_arn,\n                \"RoleSessionName\": \"efs-mount-helper\",\n                \"WebIdentityToken\": token,\n            }\n        )\n    )\n\n    unsuccessful_resp = (\n        \"Unsuccessful retrieval of AWS security credentials at %s.\" % STS_ENDPOINT_URL\n    )\n    url_error_msg = (\n        \"Unable to reach %s to retrieve AWS security credentials. See %s for more info.\"\n        % (STS_ENDPOINT_URL, SECURITY_CREDS_WEBIDENTITY_HELP_URL)\n    )\n    resp = url_request_helper(\n        config,\n        webidentity_url,\n        unsuccessful_resp,\n        url_error_msg,\n        headers={\"Accept\": \"application/json\"},\n    )\n\n    if resp:\n        creds = (\n            resp.get(\"AssumeRoleWithWebIdentityResponse\", {})\n            .get(\"AssumeRoleWithWebIdentityResult\", {})\n            .get(\"Credentials\", {})\n        )\n        if all(k in creds for k in [\"AccessKeyId\", \"SecretAccessKey\", \"SessionToken\"]):\n            return {\n                \"AccessKeyId\": creds[\"AccessKeyId\"],\n                \"SecretAccessKey\": creds[\"SecretAccessKey\"],\n                \"Token\": creds[\"SessionToken\"],\n            }\n\n    return None\n\n\ndef get_aws_security_credentials_from_instance_metadata(config):\n    # through IAM role name security credentials lookup uri (after lookup for IAM role name attached to instance)\n    dict_keys = [\"AccessKeyId\", \"SecretAccessKey\", \"Token\"]\n    iam_role_unsuccessful_resp = (\n        \"Unsuccessful retrieval of IAM role name at %s.\" % INSTANCE_IAM_URL\n    )\n    iam_role_url_error_msg = (\n        \"Unable to reach %s to retrieve IAM role name. See %s for more info.\"\n        % (INSTANCE_IAM_URL, SECURITY_CREDS_IAM_ROLE_HELP_URL)\n    )\n    iam_role_name = url_request_helper(\n        config, INSTANCE_IAM_URL, iam_role_unsuccessful_resp, iam_role_url_error_msg\n    )\n    if iam_role_name:\n        security_creds_lookup_url = INSTANCE_IAM_URL + iam_role_name\n        unsuccessful_resp = (\n            \"Unsuccessful retrieval of AWS security credentials at %s.\"\n            % security_creds_lookup_url\n        )\n        url_error_msg = (\n            \"Unable to reach %s to retrieve AWS security credentials. See %s for more info.\"\n            % (security_creds_lookup_url, SECURITY_CREDS_IAM_ROLE_HELP_URL)\n        )\n        iam_security_dict = url_request_helper(\n            config, security_creds_lookup_url, unsuccessful_resp, url_error_msg\n        )\n\n        if iam_security_dict and all(k in iam_security_dict for k in dict_keys):\n            return iam_security_dict\n\n    return None\n\n\ndef credentials_file_helper(file_path, awsprofile):\n    aws_credentials_configs = read_config(file_path)\n    credentials = {\"AccessKeyId\": None, \"SecretAccessKey\": None, \"Token\": None}\n\n    try:\n        aws_access_key_id = aws_credentials_configs.get(awsprofile, \"aws_access_key_id\")\n        secret_access_key = aws_credentials_configs.get(\n            awsprofile, \"aws_secret_access_key\"\n        )\n        session_token = aws_credentials_configs.get(awsprofile, \"aws_session_token\")\n\n        credentials[\"AccessKeyId\"] = aws_access_key_id\n        credentials[\"SecretAccessKey\"] = secret_access_key\n        credentials[\"Token\"] = session_token\n    except NoOptionError as e:\n        if \"aws_access_key_id\" in str(e) or \"aws_secret_access_key\" in str(e):\n            logging.debug(\n                \"aws_access_key_id or aws_secret_access_key not found in %s under named profile [%s]\",\n                file_path,\n                awsprofile,\n            )\n        if \"aws_session_token\" in str(e):\n            logging.debug(\"aws_session_token not found in %s\", file_path)\n            credentials[\"AccessKeyId\"] = aws_credentials_configs.get(\n                awsprofile, \"aws_access_key_id\"\n            )\n            credentials[\"SecretAccessKey\"] = aws_credentials_configs.get(\n                awsprofile, \"aws_secret_access_key\"\n            )\n    except NoSectionError:\n        logging.debug(\"No [%s] section found in config file %s\", awsprofile, file_path)\n\n    return credentials\n\n\ndef is_instance_metadata_url(url):\n    return url.startswith(\"http://169.254.169.254\")\n\n\ndef url_request_helper(config, url, unsuccessful_resp, url_error_msg, headers={}):\n    try:\n        req = Request(url)\n        for k, v in headers.items():\n            req.add_header(k, v)\n\n        if not fetch_ec2_metadata_token_disabled(config) and is_instance_metadata_url(\n            url\n        ):\n            # https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/configuring-instance-metadata-service.html\n            # IMDSv1 is a request/response method to access instance metadata\n            # IMDSv2 is a session-oriented method to access instance metadata\n            # We expect the token retrieve will fail in bridge networking environment (e.g. container) since the default hop\n            # limit for getting the token is 1. If the token retrieve does timeout, we fallback to use IMDSv1 instead\n            token = get_aws_ec2_metadata_token()\n            if token:\n                req.add_header(\"X-aws-ec2-metadata-token\", token)\n\n        request_resp = urlopen(req, timeout=1)\n\n        return get_resp_obj(request_resp, url, unsuccessful_resp)\n    except socket.timeout:\n        err_msg = \"Request timeout\"\n    except HTTPError as e:\n        # For instance enable with IMDSv2 and fetch token disabled, Unauthorized 401 error will be thrown\n        if (\n            e.code == 401\n            and fetch_ec2_metadata_token_disabled(config)\n            and is_instance_metadata_url(url)\n        ):\n            logging.warning(\n                \"Unauthorized request to instance metadata url %s, IMDSv2 is enabled on the instance, while fetching \"\n                \"ec2 metadata token is disabled. Please set the value of config item \"\n                '\"%s\" to \"false\" in config file %s.'\n                % (url, DISABLE_FETCH_EC2_METADATA_TOKEN_ITEM, CONFIG_FILE)\n            )\n        err_msg = \"Unable to reach the url at %s: status=%d, reason is %s\" % (\n            url,\n            e.code,\n            e.reason,\n        )\n    except URLError as e:\n        err_msg = \"Unable to reach the url at %s, reason is %s\" % (url, e.reason)\n\n    if err_msg:\n        logging.debug(\"%s %s\", url_error_msg, err_msg)\n    return None\n\n\ndef get_resp_obj(request_resp, url, unsuccessful_resp):\n    if request_resp.getcode() != 200:\n        logging.debug(\n            unsuccessful_resp + \" %s: ResponseCode=%d\", url, request_resp.getcode()\n        )\n        return None\n\n    resp_body = request_resp.read()\n    resp_body_type = type(resp_body)\n    try:\n        if resp_body_type is str:\n            resp_dict = json.loads(resp_body)\n        else:\n            resp_dict = json.loads(\n                resp_body.decode(\n                    request_resp.headers.get_content_charset() or \"us-ascii\"\n                )\n            )\n\n        return resp_dict\n    except ValueError:\n        return resp_body if resp_body_type is str else resp_body.decode(\"utf-8\")\n\n\ndef bootstrap_logging(config, log_dir=LOG_DIR):\n    raw_level = config.get(CONFIG_SECTION, \"logging_level\")\n    levels = {\n        \"debug\": logging.DEBUG,\n        \"info\": logging.INFO,\n        \"warning\": logging.WARNING,\n        \"error\": logging.ERROR,\n        \"critical\": logging.CRITICAL,\n    }\n    level = levels.get(raw_level.lower())\n    level_error = False\n\n    if not level:\n        # delay logging error about malformed log level until after logging is configured\n        level_error = True\n        level = logging.INFO\n\n    max_bytes = config.getint(CONFIG_SECTION, \"logging_max_bytes\")\n    file_count = config.getint(CONFIG_SECTION, \"logging_file_count\")\n\n    handler = RotatingFileHandler(\n        os.path.join(log_dir, LOG_FILE), maxBytes=max_bytes, backupCount=file_count\n    )\n    handler.setFormatter(\n        logging.Formatter(\n            fmt=\"%(asctime)s - %(levelname)s - %(message)s\",\n            datefmt=\"%Y-%m-%d %H:%M:%S %Z\",\n        )\n    )\n\n    logger = logging.getLogger()\n    logger.setLevel(level)\n    logger.addHandler(handler)\n\n    if level_error:\n        logging.error(\n            'Malformed logging level \"%s\", setting logging level to %s',\n            raw_level,\n            level,\n        )\n\n\ndef parse_options(options):\n    opts = {}\n    for o in options.split(\",\"):\n        if \"=\" in o:\n            k, v = o.split(\"=\")\n            opts[k] = v\n        else:\n            opts[o] = None\n    return opts\n\n\ndef get_file_safe_mountpoint(mount):\n    mountpoint = os.path.abspath(mount.mountpoint).replace(os.sep, \".\")\n    if mountpoint.startswith(\".\"):\n        mountpoint = mountpoint[1:]\n\n    opts = parse_options(mount.options)\n    if \"port\" not in opts:\n        if not check_if_running_on_macos():\n            # /proc/mounts provides a list of all mounts in use by the system (including the mount options used).\n            # In the case of tls mount: stunnel establishes a localhost port connection in order to listen on the requests,\n            # and then send packets further to the server:2049. If the port is 2049 which is the default nfs port,\n            # /proc/mounts will not display the port number in the options information, thus watchdog process will not treat\n            # the mount as EFS mount and won't restart the killed stunnel which cause the mount hang.\n            # So, tlsport=2049 is being added here by appending with the mountpoint.\n            # Putting a default port 2049 to fix the Stunnel process being killed issue.\n            opts[\"port\"] = DEFAULT_NFS_PORT\n        # some other localhost nfs mount not running over stunnel.\n        # For MacOS, we ignore the port if the port is missing in mount options.\n        else:\n            return mountpoint\n    return mountpoint + \".\" + opts[\"port\"]\n\n\ndef get_current_local_nfs_mounts(mount_file=\"/proc/mounts\"):\n    \"\"\"\n    Return a dict of the current NFS mounts for servers running on localhost, keyed by the mountpoint and port as it\n    appears in EFS watchdog state files.\n    \"\"\"\n    mounts = []\n\n    if not check_if_running_on_macos():\n        with open(mount_file) as f:\n            for mount in f:\n                mounts.append(Mount._make(mount.strip().split()))\n    else:\n        # stat command on MacOS does not have '--file-system' option to verify the filesystem type of a mount point,\n        # traverse all the mounts, and find if current mount point is already mounted\n        process = subprocess.run(\n            [\"mount\", \"-t\", \"nfs\"],\n            check=True,\n            stdout=subprocess.PIPE,\n            universal_newlines=True,\n        )\n        stdout = process.stdout\n        if stdout:\n            output = stdout.split(\"\\n\")\n            for mount in output:\n                _mount = mount.split()\n                if len(_mount) >= 4:\n                    mount_ops = get_nfs_mount_options_on_macos(_mount[2], _mount[0])\n                    # Sample output: 127.0.0.1:/ on /Users/ec2-user/efs (nfs)\n                    mounts.append(\n                        Mount._make(\n                            [\n                                _mount[0],\n                                _mount[2],\n                                _mount[3],\n                                mount_ops if mount_ops else \"\",\n                                0,\n                                0,\n                            ]\n                        )\n                    )\n        else:\n            logging.warning(\"No nfs mounts found\")\n\n    mounts = [m for m in mounts if m.server.startswith(\"127.0.0.1\") and \"nfs\" in m.type]\n\n    mount_dict = {}\n    for m in mounts:\n        safe_mnt = get_file_safe_mountpoint(m)\n        if safe_mnt:\n            mount_dict[safe_mnt] = m\n\n    return mount_dict\n\n\ndef get_nfs_mount_options_on_macos(mount_point, mount_server=\"127.0.0.1:/\"):\n\n    if not mount_point:\n        logging.warning(\"Unable to get local mount options with empty mount point\")\n        return None\n\n    try:\n        process = subprocess.run(\n            [\"nfsstat\", \"-f\", \"JSON\", \"-m\", mount_point],\n            check=True,\n            stdout=subprocess.PIPE,\n            universal_newlines=True,\n            timeout=NFSSTAT_TIMEOUT,\n        )\n        stdout = process.stdout\n        if not stdout:\n            logging.warning(\n                \"Unable to get local mount options with mount point: %s\", mount_point\n            )\n            return None\n        try:\n            state_json = json.loads(stdout)\n        except ValueError:\n            logging.exception(\"Unable to parse json of %s\", stdout)\n            return None\n        try:\n            return \",\".join(\n                state_json.get(mount_server)\n                .get(\"Original mount options\")\n                .get(\"NFS parameters\")\n            )\n        except AttributeError:\n            logging.exception(\"Unable to get object in %s\", state_json)\n            return None\n    except subprocess.TimeoutExpired:\n        logging.warning(\n            \"Fetching nfs mount parameters timed out for mount point %s. Ignoring port option.\",\n            mount_point,\n        )\n        return None\n\n\ndef get_state_files(state_file_dir):\n    \"\"\"\n    Return a dict of the absolute path of state files in state_file_dir,\n    keyed by the mountpoint and port portion of the filename.\n    \"\"\"\n    state_files = {}\n\n    if os.path.isdir(state_file_dir):\n        for sf in os.listdir(state_file_dir):\n            if not sf.startswith(\"fs-\") or os.path.isdir(\n                os.path.join(state_file_dir, sf)\n            ):\n                continue\n\n            # This translates the state file name \"fs-deadbeaf.home.user.mnt.12345\"\n            # into file-safe mountpoint \"home.user.mnt.12345\"\n            first_period = sf.find(\".\")\n            mount_point_and_port = sf[first_period + 1 :]\n            logging.debug(\n                'Translating \"%s\" into mount point and port \"%s\"',\n                sf,\n                mount_point_and_port,\n            )\n            state_files[mount_point_and_port] = sf\n\n    return state_files\n\n\ndef get_pid_in_state_dir(state_file, state_file_dir):\n    \"\"\"\n    :param state_file: The state file path, e.g. fs-deadbeef.mnt.20560.\n    :param state_file_dir: The state file dir path, e.g. /var/run/efs.\n    \"\"\"\n    state_dir_pid_path = os.path.join(\n        state_file_dir, state_file + \"+\", STUNNEL_PID_FILE\n    )\n    if os.path.exists(state_dir_pid_path):\n        with open(state_dir_pid_path) as f:\n            return f.read()\n    return None\n\n\ndef is_mount_stunnel_proc_running(state_pid, state_file, state_file_dir):\n    \"\"\"\n    Check whether a given stunnel process id in state file is running for the mount. To avoid we incorrectly checking\n    processes running by other applications and send signal further, the stunnel process in state file is counted as\n    running iff:\n    1. The pid in state file is not None.\n    2. The process running with the pid is a stunnel process. This is validated through process command name.\n    3. The process can be reached via os.kill(pid, 0).\n    4. Every launched stunnel process will write its process id to the pid file in the mount state_file_dir, and only\n       when the stunnel is terminated this pid file can be removed. Check whether the stunnel pid file exists and its\n       value is equal to the pid documented in state file. This step is to make sure we don't send signal later to any\n       stunnel process that is not owned by the mount.\n\n    :param state_pid: The pid in state file.\n    :param state_file: The state file path, e.g. fs-deadbeef.mnt.20560.\n    :param state_file_dir: The state file dir path, e.g. /var/run/efs.\n    \"\"\"\n    if not state_pid:\n        logging.debug(\"State pid is None for %s\", state_file)\n        return False\n\n    process_name = check_process_name(state_pid)\n    if not process_name or \"stunnel\" not in str(process_name):\n        logging.debug(\n            \"Process running on %s is not a stunnel process, full command: %s.\",\n            state_pid,\n            str(process_name) if process_name else \"\",\n        )\n        return False\n\n    if not is_pid_running(state_pid):\n        logging.debug(\n            \"Stunnel process with pid %s is not running anymore for %s.\",\n            state_pid,\n            state_file,\n        )\n        return False\n\n    pid_in_stunnel_pid_file = get_pid_in_state_dir(state_file, state_file_dir)\n    # efs-utils versions older than 1.32.2 does not create a pid file in state dir\n    # To avoid the healthy stunnel established by those version to be treated as not running due to the missing pid file, which can result in stunnel being constantly restarted,\n    # assuming the stunnel is still running even if the stunnel pid file does not exist.\n    if not pid_in_stunnel_pid_file:\n        logging.debug(\n            \"Pid file of stunnel does not exist for %s. It is possible that the stunnel is no longer running or the mount was mounted using an older version efs-utils (<1.32.2). Assuming the stunnel with pid %s is still running.\",\n            state_file,\n            state_pid,\n        )\n\n    elif int(state_pid) != int(pid_in_stunnel_pid_file):\n        logging.warning(\n            \"Stunnel pid mismatch in state file (pid = %s) and stunnel pid file (pid = %s). Assuming the \"\n            \"stunnel is not running.\",\n            int(state_pid),\n            int(pid_in_stunnel_pid_file),\n        )\n        return False\n\n    logging.debug(\"TLS tunnel for %s is running with pid %s\", state_file, state_pid)\n    return True\n\n\ndef is_pid_running(pid):\n    if not pid:\n        return False\n    try:\n        os.kill(pid, 0)\n        return True\n    except OSError:\n        return False\n\n\ndef check_if_platform_is_mac():\n    return sys.platform in MAC_OS_PLATFORM_LIST\n\n\ndef get_system_release_version():\n    # MacOS does not maintain paths /etc/os-release and /etc/sys-release\n    if check_if_platform_is_mac():\n        return platform.platform()\n\n    try:\n        with open(SYSTEM_RELEASE_PATH) as f:\n            return f.read().strip()\n    except IOError:\n        logging.debug(\"Unable to read %s\", SYSTEM_RELEASE_PATH)\n\n    try:\n        with open(OS_RELEASE_PATH) as f:\n            for line in f:\n                if \"PRETTY_NAME\" in line:\n                    return line.split(\"=\")[1].strip()\n    except IOError:\n        logging.debug(\"Unable to read %s\", OS_RELEASE_PATH)\n\n    return DEFAULT_UNKNOWN_VALUE\n\n\ndef find_command_path(command, install_method):\n    # If not running on macOS, use linux paths\n    if not check_if_platform_is_mac():\n        env_path = (\n            \"/sbin:/usr/sbin:/usr/local/sbin:/root/bin:/usr/local/bin:/usr/bin:/bin\"\n        )\n    # Homebrew on x86 macOS uses /usr/local/bin; Homebrew on Apple Silicon macOS uses /opt/homebrew/bin since v3.0.0\n    # For more information, see https://brew.sh/2021/02/05/homebrew-3.0.0/\n    else:\n        env_path = \"/opt/homebrew/bin:/usr/local/bin\"\n    os.putenv(\"PATH\", env_path)\n\n    try:\n        path = subprocess.check_output([\"which\", command])\n        return path.strip().decode()\n    except subprocess.CalledProcessError as e:\n        fatal_error(\n            \"Failed to locate %s in %s - %s\" % (command, env_path, install_method), e\n        )\n\n\n# In ECS amazon linux 2, we start stunnel using `nsenter` which will run as a subprocess of bash, utilizes the `setns`\n# system call to join an existing namespace and then executes the specified program using `exec`. Any exception won't\n# be caught properly by subprocess.\n# As a precaution on ECS AL2 that stunnel bin is removed after installing new efs-utils, and watchdog cannot launch\n# stunnel for previous old mount, we do a replacement of stunnel path in the command to the stunnel5 path.\n#\ndef update_stunnel_command_for_ecs_amazon_linux_2(\n    command, state, state_file_dir, state_file\n):\n    if (\n        \"nsenter\" in command\n        and \"stunnel5\" not in \" \".join(command)\n        and get_system_release_version() in AMAZON_LINUX_2_RELEASE_VERSIONS\n    ):\n        for i in range(len(command)):\n            if \"stunnel\" in command[i] and \"stunnel-config\" not in command[i]:\n                command[i] = find_command_path(\"stunnel5\", STUNNEL_INSTALLATION_MESSAGE)\n                break\n        logging.info(\n            \"Rewriting %s with new stunnel cmd: %s for ECS Amazon Linux 2 platform.\",\n            state_file,\n            \" \".join(state[\"cmd\"]),\n        )\n        rewrite_state_file(state, state_file_dir, state_file)\n    return command\n\n\ndef start_tls_tunnel(child_procs, state, state_file_dir, state_file):\n    # launch the tunnel in a process group so if it has any child processes, they can be killed easily\n    command = state[\"cmd\"]\n    logging.info('Starting TLS tunnel: \"%s\"', \" \".join(command))\n\n    command = update_stunnel_command_for_ecs_amazon_linux_2(\n        command, state, state_file_dir, state_file\n    )\n    tunnel = None\n    try:\n        tunnel = subprocess.Popen(\n            command,\n            stdout=subprocess.DEVNULL,\n            stderr=subprocess.DEVNULL,\n            preexec_fn=os.setsid,\n            close_fds=True,\n        )\n    except FileNotFoundError as e:\n        logging.warning(\"Watchdog failed to start stunnel due to %s\", e)\n\n        # https://github.com/kubernetes-sigs/aws-efs-csi-driver/issues/812 It is possible that the stunnel is not\n        # present anymore and replaced by stunnel5 on AL2, meanwhile watchdog is attempting to restart stunnel for\n        # mount using old efs-utils based on old state file generated during previous mount, which has stale command\n        # using stunnel bin. Update the state file if the stunnel does not exist anymore, and use stunnel5 on Al2.\n        #\n        if get_system_release_version() in AMAZON_LINUX_2_RELEASE_VERSIONS:\n            for i in range(len(command)):\n                if \"stunnel\" in command[i] and \"stunnel-config\" not in command[i]:\n                    command[i] = find_command_path(\n                        \"stunnel5\", STUNNEL_INSTALLATION_MESSAGE\n                    )\n                    break\n\n            tunnel = subprocess.Popen(\n                command,\n                stdout=subprocess.DEVNULL,\n                stderr=subprocess.DEVNULL,\n                preexec_fn=os.setsid,\n                close_fds=True,\n            )\n\n            state[\"cmd\"] = command\n            logging.info(\n                \"Rewriting %s with new stunnel cmd: %s for Amazon Linux 2 platform.\",\n                state_file,\n                \" \".join(state[\"cmd\"]),\n            )\n            rewrite_state_file(state, state_file_dir, state_file)\n\n    if tunnel is None or not is_pid_running(tunnel.pid):\n        fatal_error(\n            \"Failed to initialize TLS tunnel for %s\" % state_file,\n            \"Failed to start TLS tunnel.\",\n        )\n\n    logging.info(\"Started TLS tunnel, pid: %d\", tunnel.pid)\n\n    child_procs.append(tunnel)\n    return tunnel.pid\n\n\ndef clean_up_mount_state(state_file_dir, state_file, pid, mount_state_dir=None):\n    send_signal_to_running_stunnel_process_group(\n        pid, state_file, state_file_dir, SIGTERM\n    )\n    cleanup_mount_state_if_stunnel_not_running(\n        pid, state_file, state_file_dir, mount_state_dir\n    )\n\n\ndef cleanup_mount_state_if_stunnel_not_running(\n    pid, state_file, state_file_dir, mount_state_dir\n):\n    if is_mount_stunnel_proc_running(pid, state_file, state_file_dir):\n        logging.info(\"TLS tunnel: %d is still running, will retry termination\", pid)\n    else:\n        if not pid:\n            logging.info(\"TLS tunnel has been killed, cleaning up state\")\n        else:\n            logging.info(\"TLS tunnel: %d is no longer running, cleaning up state\", pid)\n        state_file_path = os.path.join(state_file_dir, state_file)\n        with open(state_file_path) as f:\n            state = json.load(f)\n\n        for f in state.get(\"files\", list()):\n            logging.debug(\"Deleting %s\", f)\n            try:\n                os.remove(f)\n                logging.debug(\"Deleted %s\", f)\n            except OSError as e:\n                if e.errno != errno.ENOENT:\n                    raise\n\n        os.remove(state_file_path)\n\n        if mount_state_dir is not None:\n            mount_state_dir_abs_path = os.path.join(state_file_dir, mount_state_dir)\n            if os.path.isdir(mount_state_dir_abs_path):\n                shutil.rmtree(mount_state_dir_abs_path)\n            else:\n                logging.debug(\n                    \"Attempt to remove mount state directory %s failed. Directory is not present.\",\n                    mount_state_dir_abs_path,\n                )\n\n\ndef rewrite_state_file(state, state_file_dir, state_file):\n    tmp_state_file = os.path.join(state_file_dir, \"~%s\" % state_file)\n    with open(tmp_state_file, \"w\") as f:\n        json.dump(state, f)\n\n    os.rename(tmp_state_file, os.path.join(state_file_dir, state_file))\n\n\ndef mark_as_unmounted(state, state_file_dir, state_file, current_time):\n    logging.debug(\"Marking %s as unmounted at %d\", state_file, current_time)\n    state[\"unmount_time\"] = current_time\n\n    rewrite_state_file(state, state_file_dir, state_file)\n\n    return state\n\n\ndef restart_tls_tunnel(child_procs, state, state_file_dir, state_file):\n    if \"certificate\" in state and not os.path.exists(state[\"certificate\"]):\n        logging.error(\n            \"Cannot restart stunnel because self-signed certificate at %s is missing\"\n            % state[\"certificate\"]\n        )\n        return\n\n    new_tunnel_pid = start_tls_tunnel(child_procs, state, state_file_dir, state_file)\n    state[\"pid\"] = new_tunnel_pid\n\n    logging.debug(\"Rewriting %s with new pid: %d\", state_file, new_tunnel_pid)\n    rewrite_state_file(state, state_file_dir, state_file)\n\n\ndef check_efs_mounts(\n    config,\n    child_procs,\n    unmount_grace_period_sec,\n    unmount_count_for_consistency,\n    state_file_dir=STATE_FILE_DIR,\n):\n    nfs_mounts = get_current_local_nfs_mounts()\n    logging.debug(\"Current local NFS mounts: %s\", list(nfs_mounts.values()))\n\n    state_files = get_state_files(state_file_dir)\n    logging.debug(\n        'Current state files in \"%s\": %s', state_file_dir, list(state_files.values())\n    )\n\n    for mount, state_file in state_files.items():\n        state_file_path = os.path.join(state_file_dir, state_file)\n        with open(state_file_path) as f:\n            try:\n                state = json.load(f)\n            except ValueError:\n                logging.exception(\"Unable to parse json in %s\", state_file_path)\n                continue\n\n        current_time = time.time()\n        if \"unmount_time\" in state:\n            if state[\"unmount_time\"] + unmount_grace_period_sec < current_time:\n                logging.info(\"Unmount grace period expired for %s\", state_file)\n                clean_up_mount_state(\n                    state_file_dir,\n                    state_file,\n                    state.get(\"pid\"),\n                    state.get(\"mountStateDir\"),\n                )\n        # For MacOS, if we don't have port from previous system call (nfsstat -F JSON -m mount_point), we ignore the port\n        elif mount not in nfs_mounts and (\n            not check_if_running_on_macos()\n            or mount[: mount.rindex(\".\")] not in nfs_mounts\n        ):\n            # Wait 30 seconds before deciding mount no longer exists to prevent race condition\n            # of watchdog's reads of nfs mounts and state files.\n            if current_time - state.get(\"mount_time\", 0) > UNMOUNT_DIFF_TIME:\n                # Ensure we have consistent unmount reads for at least 5 times by default.\n                if state.get(\"unmount_count\", 0) > unmount_count_for_consistency:\n                    logging.info('No mount found for \"%s\"', state_file)\n                    state = mark_as_unmounted(\n                        state, state_file_dir, state_file, current_time\n                    )\n                else:\n                    state[\"unmount_count\"] = state.get(\"unmount_count\", 0) + 1\n                    rewrite_state_file(state, state_file_dir, state_file)\n\n        else:\n            # Set unmount count to 0 if there were inconsistent reads\n            state[\"unmount_count\"] = 0\n            rewrite_state_file(state, state_file_dir, state_file)\n            if \"certificate\" in state:\n                check_certificate(config, state, state_file_dir, state_file)\n\n            if is_mount_stunnel_proc_running(\n                state.get(\"pid\"), state_file, state_file_dir\n            ):\n                # https://github.com/kubernetes-sigs/aws-efs-csi-driver/issues/616 We have seen EFS hanging issue caused\n                # by stuck stunnel (version: 4.56) process. Apart from checking whether stunnel is running or not, we\n                # need to check whether the stunnel connection established is healthy periodically.\n                #\n                # The way to check the stunnel health is by `df` the mountpoint, i.e. check the file system information,\n                # which will trigger a remote GETATTR on the root of the file system. Normally the command will finish\n                # in 10 milliseconds, thus if the command hang for certain period (defined as 30 sec as of now), the\n                # stunnel connection is likely to be unhealthy. Watchdog will kill the old stunnel process and restart\n                # a new one for the unhealthy mount. The health check will run every 5 min since mount.\n                #\n                # Both the command hang timeout and health check interval are configurable in efs-utils config file.\n                #\n                check_stunnel_health(\n                    config, state, state_file_dir, state_file, child_procs, nfs_mounts\n                )\n            else:\n                logging.warning(\"TLS tunnel for %s is not running\", state_file)\n                restart_tls_tunnel(child_procs, state, state_file_dir, state_file)\n\n\ndef check_stunnel_health(\n    config, state, state_file_dir, state_file, child_procs, nfs_mounts\n):\n    if not get_boolean_config_item_value(\n        config, CONFIG_SECTION, \"stunnel_health_check_enabled\", default_value=True\n    ):\n        return\n\n    check_interval_min = get_int_value_from_config_file(\n        config,\n        \"stunnel_health_check_interval_min\",\n        DEFAULT_STUNNEL_HEALTH_CHECK_INTERVAL_MIN,\n    )\n\n    current_time = time.time()\n\n    # The mount_time info in the state file is added in version 1.31.3. It is possible for existing mounts, there are\n    # no mount_time in state file, which will cause watchdog to crash. If the information does not exist, we just take\n    # current time as the initial mount time of the mount.\n    #\n    if \"mount_time\" not in state:\n        state[\"mount_time\"] = current_time\n        rewrite_state_file(state, state_file_dir, state_file)\n        return\n\n    # Only start to perform the stunnel health check after the check interval passed.\n    if current_time - state[\"mount_time\"] < check_interval_min * 60:\n        return\n\n    last_stunnel_check_time = (\n        state[\"last_stunnel_check_time\"] if \"last_stunnel_check_time\" in state else 0\n    )\n    if (\n        last_stunnel_check_time != 0\n        and current_time - last_stunnel_check_time < check_interval_min * 60\n    ):\n        return\n\n    # We add this mountpoint info in the state file along with this change. It is possible for existing mounts, there\n    # are no mountpoint in state file, which will cause watchdog to crash. To handle that case, we need to extract the\n    # mountpoint from the state file name, and write that information to state file.\n    #\n    if \"mountpoint\" in state:\n        mountpoint = state[\"mountpoint\"]\n    else:\n        mountpoint = get_mountpoint_from_nfs_mounts(state_file, nfs_mounts)\n        state[\"mountpoint\"] = mountpoint\n        rewrite_state_file(state, state_file_dir, state_file)\n\n    stunnel_pid = state[\"pid\"]\n    process = subprocess.Popen(\n        [\"df\", mountpoint],\n        stdout=subprocess.DEVNULL,\n        stderr=subprocess.DEVNULL,\n        close_fds=True,\n    )\n\n    command_timeout_sec = get_int_value_from_config_file(\n        config,\n        \"stunnel_health_check_command_timeout_sec\",\n        DEFAULT_STUNNEL_HEALTH_CHECK_TIMEOUT_SEC,\n    )\n    try:\n        state[\"last_stunnel_check_time\"] = current_time\n        process.communicate(timeout=command_timeout_sec)\n        logging.debug(\n            \"Stunnel [PID: %d] running for tls mount on %s passed health check.\",\n            stunnel_pid,\n            mountpoint,\n        )\n        rewrite_state_file(state, state_file_dir, state_file)\n    except subprocess.TimeoutExpired:\n        if send_signal_to_running_stunnel_process_group(\n            stunnel_pid, state_file, state_file_dir, SIGKILL\n        ):\n            logging.warning(\n                \"Connection timeout for %s after %d sec, SIGKILL has been sent to the potential unhealthy stunnel %s, \"\n                \"restarting a new stunnel process.\",\n                mountpoint,\n                command_timeout_sec,\n                stunnel_pid,\n            )\n            restart_tls_tunnel(child_procs, state, state_file_dir, state_file)\n        else:\n            logging.warning(\n                \"Stunnel health check timed out for %s, stunnel [PID: %d] is not running anymore.\",\n                mountpoint,\n                stunnel_pid,\n            )\n        # The child process is not killed if the timeout expires, so in order to cleanup properly, kill the child\n        # process after the timeout.\n        #\n        process.kill()\n\n\n# Retrieve the nfs mountpoint with the port information in the mount option\ndef get_mountpoint_from_nfs_mounts(state_file, nfs_mounts):\n    search_pattern = \"port={port}\".format(\n        port=os.path.basename(state_file).split(\".\")[-1]\n    )\n    for mount in nfs_mounts.values():\n        if search_pattern in mount[3]:\n            return mount[1]\n\n\ndef get_int_value_from_config_file(config, config_name, default_config_value):\n    val = default_config_value\n    try:\n        value_from_config = config.get(CONFIG_SECTION, config_name)\n        try:\n            if int(value_from_config) > 0:\n                val = int(value_from_config)\n            else:\n                logging.debug(\n                    '%s value in config file \"%s\" is lower than 1. Defaulting to %d.',\n                    config_name,\n                    CONFIG_FILE,\n                    default_config_value,\n                )\n        except ValueError:\n            logging.debug(\n                'Bad %s, \"%s\", in config file \"%s\". Defaulting to %d.',\n                config_name,\n                value_from_config,\n                CONFIG_FILE,\n                default_config_value,\n            )\n    except NoOptionError:\n        logging.debug(\n            'No %s value in config file \"%s\". Defaulting to %d.',\n            config_name,\n            CONFIG_FILE,\n            default_config_value,\n        )\n\n    return val\n\n\ndef check_child_procs(child_procs):\n    for proc in child_procs:\n        proc.poll()\n        if proc.returncode is not None:\n            logging.warning(\n                \"Child TLS tunnel process %d has exited, returncode=%d\",\n                proc.pid,\n                proc.returncode,\n            )\n            child_procs.remove(proc)\n\n\ndef parse_arguments(args=None):\n    if args is None:\n        args = sys.argv\n\n    if \"-h\" in args[1:] or \"--help\" in args[1:]:\n        sys.stdout.write(\"Usage: %s [--version] [-h|--help]\\n\" % args[0])\n        sys.exit(0)\n\n    if \"--version\" in args[1:]:\n        sys.stdout.write(\"%s Version: %s\\n\" % (args[0], VERSION))\n        sys.exit(0)\n\n\ndef assert_root():\n    if os.geteuid() != 0:\n        sys.stderr.write(\"only root can run amazon-efs-mount-watchdog\\n\")\n        sys.exit(1)\n\n\ndef read_config(config_file=CONFIG_FILE):\n    try:\n        p = ConfigParser.SafeConfigParser()\n    except AttributeError:\n        p = ConfigParser()\n    p.read(config_file)\n    return p\n\n\ndef check_certificate(\n    config, state, state_file_dir, state_file, base_path=STATE_FILE_DIR\n):\n    certificate_creation_time = datetime.strptime(\n        state[\"certificateCreationTime\"], CERT_DATETIME_FORMAT\n    )\n    certificate_exists = os.path.isfile(state[\"certificate\"])\n    certificate_renewal_interval_secs = (\n        get_certificate_renewal_interval_mins(config) * 60\n    )\n    # creation instead of NOT_BEFORE datetime is used for refresh of cert because NOT_BEFORE derives from creation datetime\n    should_refresh_cert = (\n        get_utc_now() - certificate_creation_time\n    ).total_seconds() > certificate_renewal_interval_secs\n\n    if certificate_exists and not should_refresh_cert:\n        return\n\n    ap_state = state.get(\"accessPoint\")\n    if ap_state and not AP_ID_RE.match(ap_state):\n        logging.error(\n            'Access Point ID \"%s\" has been changed in the state file to a malformed format'\n            % ap_state\n        )\n        return\n\n    if not certificate_exists:\n        logging.debug(\n            \"Certificate (at %s) is missing. Recreating self-signed certificate\"\n            % state[\"certificate\"]\n        )\n    else:\n        logging.debug(\n            \"Refreshing self-signed certificate (at %s)\" % state[\"certificate\"]\n        )\n\n    credentials_source = state.get(\"awsCredentialsMethod\")\n    updated_certificate_creation_time = recreate_certificate(\n        config,\n        state[\"mountStateDir\"],\n        state[\"commonName\"],\n        state[\"fsId\"],\n        credentials_source,\n        ap_state,\n        state[\"region\"],\n        base_path=base_path,\n    )\n    if updated_certificate_creation_time:\n        state[\"certificateCreationTime\"] = updated_certificate_creation_time\n        rewrite_state_file(state, state_file_dir, state_file)\n\n        # send SIGHUP to force a reload of the configuration file to trigger the stunnel process to notice the new certificate\n        send_signal_to_running_stunnel_process_group(\n            state.get(\"pid\"), state_file, state_file_dir, SIGHUP\n        )\n\n\ndef send_signal_to_running_stunnel_process_group(\n    stunnel_pid, state_file, state_file_dir, signal\n):\n    \"\"\"\n    Send a signal to the given stunnel_pid if the process running with the pid is the mount stunnel process.\n\n    :param stunnel_pid: The pid in state file.\n    :param state_file: The state file path, e.g. fs-deadbeef.mnt.20560.\n    :param state_file_dir: The state file dir path, e.g. /var/run/efs.\n    :param signal: OS signal send to stunnel process group, e.g. SIGHUP, SIGKILL, SIGTERM.\n    \"\"\"\n    if is_mount_stunnel_proc_running(stunnel_pid, state_file, state_file_dir):\n        process_group = os.getpgid(stunnel_pid)\n        try:\n            logging.info(\n                \"Sending signal %s(%d) to stunnel. PID: %d, group ID: %s\",\n                signal.name,\n                signal.value,\n                stunnel_pid,\n                process_group,\n            )\n        except AttributeError:\n            # In python3.4, the signal is a int object, so it does not have name and value property\n            logging.info(\n                \"Sending signal(%s) to stunnel. PID: %d, group ID: %s\",\n                signal,\n                stunnel_pid,\n                process_group,\n            )\n        os.killpg(process_group, signal)\n        return True\n    else:\n        logging.warning(\"TLS tunnel is not running for %s\", state_file)\n        return False\n\n\ndef create_required_directory(config, directory):\n    mode = 0o750\n    try:\n        mode_str = config.get(CONFIG_SECTION, \"state_file_dir_mode\")\n        try:\n            mode = int(mode_str, 8)\n        except ValueError:\n            logging.warning(\n                'Bad state_file_dir_mode \"%s\" in config file \"%s\"',\n                mode_str,\n                CONFIG_FILE,\n            )\n    except NoOptionError:\n        pass\n\n    try:\n        os.makedirs(directory, mode)\n        logging.debug(\"Expected %s not found, recreating asset\", directory)\n    except OSError as e:\n        if errno.EEXIST != e.errno or not os.path.isdir(directory):\n            raise\n\n\ndef get_client_info(config):\n    client_info = {}\n\n    # source key/value pair in config file\n    if config.has_option(CLIENT_INFO_SECTION, \"source\"):\n        client_source = config.get(CLIENT_INFO_SECTION, \"source\")\n        if 0 < len(client_source) <= CLIENT_SOURCE_STR_LEN_LIMIT:\n            client_info[\"source\"] = client_source\n    if not client_info.get(\"source\"):\n        if check_if_running_on_macos():\n            client_info[\"source\"] = DEFAULT_MACOS_VALUE\n        else:\n            client_info[\"source\"] = DEFAULT_UNKNOWN_VALUE\n\n    client_info[\"efs_utils_version\"] = VERSION\n\n    return client_info\n\n\ndef recreate_certificate(\n    config,\n    mount_name,\n    common_name,\n    fs_id,\n    credentials_source,\n    ap_id,\n    region,\n    base_path=STATE_FILE_DIR,\n):\n    current_time = get_utc_now()\n    tls_paths = tls_paths_dictionary(mount_name, base_path)\n\n    certificate_config = os.path.join(tls_paths[\"mount_dir\"], \"config.conf\")\n    certificate_signing_request = os.path.join(tls_paths[\"mount_dir\"], \"request.csr\")\n    certificate = os.path.join(tls_paths[\"mount_dir\"], \"certificate.pem\")\n\n    ca_dirs_check(config, tls_paths[\"database_dir\"], tls_paths[\"certs_dir\"])\n    ca_supporting_files_check(\n        tls_paths[\"index\"],\n        tls_paths[\"index_attr\"],\n        tls_paths[\"serial\"],\n        tls_paths[\"rand\"],\n    )\n\n    private_key = check_and_create_private_key(base_path)\n\n    if credentials_source:\n        public_key = os.path.join(tls_paths[\"mount_dir\"], \"publicKey.pem\")\n        create_public_key(private_key, public_key)\n\n    client_info = get_client_info(config)\n    config_body = create_ca_conf(\n        config,\n        certificate_config,\n        common_name,\n        tls_paths[\"mount_dir\"],\n        private_key,\n        current_time,\n        region,\n        fs_id,\n        credentials_source,\n        ap_id=ap_id,\n        client_info=client_info,\n    )\n\n    if not config_body:\n        logging.error(\"Cannot recreate self-signed certificate\")\n        return None\n\n    create_certificate_signing_request(\n        certificate_config, private_key, certificate_signing_request\n    )\n\n    not_before = get_certificate_timestamp(current_time, minutes=-NOT_BEFORE_MINS)\n    not_after = get_certificate_timestamp(current_time, hours=NOT_AFTER_HOURS)\n\n    cmd = \"openssl ca -startdate %s -enddate %s -selfsign -batch -notext -config %s -in %s -out %s\" % (\n        not_before,\n        not_after,\n        certificate_config,\n        certificate_signing_request,\n        certificate,\n    )\n    subprocess_call(cmd, \"Failed to create self-signed client-side certificate\")\n    return current_time.strftime(CERT_DATETIME_FORMAT)\n\n\ndef get_private_key_path():\n    \"\"\"Wrapped for mocking purposes in unit tests\"\"\"\n    return PRIVATE_KEY_FILE\n\n\ndef check_and_create_private_key(base_path=STATE_FILE_DIR):\n    # Creating RSA private keys is slow, so we will create one private key and allow mounts to share it.\n    # This means, however, that we have to include a locking mechanism to ensure that the private key is\n    # atomically created, as mounts occurring in parallel may try to create the key simultaneously.\n    # The key should have been created during mounting, but the watchdog will recreate the private key if\n    # it is missing.\n    key = get_private_key_path()\n\n    @contextmanager\n    def open_lock_file():\n        lock_file = os.path.join(base_path, \"efs-utils-lock\")\n        f = os.open(lock_file, os.O_CREAT | os.O_DSYNC | os.O_EXCL | os.O_RDWR)\n        try:\n            lock_file_contents = \"PID: %s\" % os.getpid()\n            os.write(f, lock_file_contents.encode(\"utf-8\"))\n            yield f\n        finally:\n            check_and_remove_lock_file(lock_file, f)\n\n    def do_with_lock(function):\n        while True:\n            try:\n                with open_lock_file():\n                    return function()\n            except OSError as e:\n                if e.errno == errno.EEXIST:\n                    logging.info(\n                        \"Failed to take out private key creation lock, sleeping %s (s)\"\n                        % DEFAULT_TIMEOUT\n                    )\n                    time.sleep(DEFAULT_TIMEOUT)\n                else:\n                    # errno.ENOENT: No such file or directory, errno.EBADF: Bad file descriptor\n                    if e.errno == errno.ENOENT or e.errno == errno.EBADF:\n                        logging.debug(\n                            \"lock file does not exist or Bad file descriptor, The file is already removed nothing to do.\"\n                        )\n                    else:\n                        raise Exception(\n                            \"Could not remove lock file unexpected exception: %s\", e\n                        )\n\n    def generate_key():\n        if os.path.isfile(key):\n            return\n\n        cmd = (\n            \"openssl genpkey -algorithm RSA -out %s -pkeyopt rsa_keygen_bits:3072\" % key\n        )\n        subprocess_call(cmd, \"Failed to create private key\")\n        read_only_mode = 0o400\n        os.chmod(key, read_only_mode)\n\n    do_with_lock(generate_key)\n    return key\n\n\ndef create_certificate_signing_request(config_path, key_path, csr_path):\n    cmd = \"openssl req -new -config %s -key %s -out %s\" % (\n        config_path,\n        key_path,\n        csr_path,\n    )\n    subprocess_call(cmd, \"Failed to create certificate signing request (csr)\")\n\n\ndef create_ca_conf(\n    config,\n    config_path,\n    common_name,\n    directory,\n    private_key,\n    date,\n    region,\n    fs_id,\n    credentials_source,\n    ap_id=None,\n    client_info=None,\n):\n    \"\"\"Populate ca/req configuration file with fresh configurations at every mount since SigV4 signature can change\"\"\"\n    public_key_path = os.path.join(directory, \"publicKey.pem\")\n    security_credentials = (\n        get_aws_security_credentials(config, credentials_source, region)\n        if credentials_source\n        else \"\"\n    )\n\n    if credentials_source and security_credentials is None:\n        logging.error(\n            \"Failed to retrieve AWS security credentials using lookup method: %s\",\n            credentials_source,\n        )\n        return None\n\n    ca_extension_body = ca_extension_builder(\n        ap_id, security_credentials, fs_id, client_info\n    )\n    efs_client_auth_body = (\n        efs_client_auth_builder(\n            public_key_path,\n            security_credentials[\"AccessKeyId\"],\n            security_credentials[\"SecretAccessKey\"],\n            date,\n            region,\n            fs_id,\n            security_credentials[\"Token\"],\n        )\n        if credentials_source\n        else \"\"\n    )\n    if credentials_source and not efs_client_auth_body:\n        logging.error(\n            \"Failed to create AWS SigV4 signature section for OpenSSL config. Public Key path: %s\",\n            public_key_path,\n        )\n        return None\n    efs_client_info_body = efs_client_info_builder(client_info) if client_info else \"\"\n    full_config_body = CA_CONFIG_BODY % (\n        directory,\n        private_key,\n        common_name,\n        ca_extension_body,\n        efs_client_auth_body,\n        efs_client_info_body,\n    )\n\n    with open(config_path, \"w\") as f:\n        f.write(full_config_body)\n\n    return full_config_body\n\n\ndef ca_extension_builder(ap_id, security_credentials, fs_id, client_info):\n    ca_extension_str = \"[ v3_ca ]\\nsubjectKeyIdentifier = hash\"\n    if ap_id:\n        ca_extension_str += \"\\n1.3.6.1.4.1.4843.7.1 = ASN1:UTF8String:\" + ap_id\n    if security_credentials:\n        ca_extension_str += \"\\n1.3.6.1.4.1.4843.7.2 = ASN1:SEQUENCE:efs_client_auth\"\n\n    ca_extension_str += \"\\n1.3.6.1.4.1.4843.7.3 = ASN1:UTF8String:\" + fs_id\n    if client_info:\n        ca_extension_str += \"\\n1.3.6.1.4.1.4843.7.4 = ASN1:SEQUENCE:efs_client_info\"\n\n    return ca_extension_str\n\n\ndef efs_client_auth_builder(\n    public_key_path,\n    access_key_id,\n    secret_access_key,\n    date,\n    region,\n    fs_id,\n    session_token=None,\n):\n    public_key_hash = get_public_key_sha1(public_key_path)\n\n    if not public_key_hash:\n        return None\n\n    canonical_request = create_canonical_request(\n        public_key_hash, date, access_key_id, region, fs_id, session_token\n    )\n    string_to_sign = create_string_to_sign(canonical_request, date, region)\n    signature = calculate_signature(string_to_sign, date, secret_access_key, region)\n    efs_client_auth_str = \"[ efs_client_auth ]\"\n    efs_client_auth_str += \"\\naccessKeyId = UTF8String:\" + access_key_id\n    efs_client_auth_str += \"\\nsignature = OCTETSTRING:\" + signature\n    efs_client_auth_str += \"\\nsigv4DateTime = UTCTIME:\" + date.strftime(\n        CERT_DATETIME_FORMAT\n    )\n\n    if session_token:\n        efs_client_auth_str += \"\\nsessionToken = EXPLICIT:0,UTF8String:\" + session_token\n\n    return efs_client_auth_str\n\n\ndef efs_client_info_builder(client_info):\n    efs_client_info_str = \"[ efs_client_info ]\"\n    for key, value in client_info.items():\n        efs_client_info_str += \"\\n%s = UTF8String: %s\" % (key, value)\n    return efs_client_info_str\n\n\ndef create_public_key(private_key, public_key):\n    cmd = \"openssl rsa -in %s -outform PEM -pubout -out %s\" % (private_key, public_key)\n    subprocess_call(cmd, \"Failed to create public key\")\n\n\ndef subprocess_call(cmd, error_message):\n    \"\"\"Helper method to run shell openssl command and to handle response error messages\"\"\"\n    process = subprocess.Popen(\n        cmd.split(), stdout=subprocess.PIPE, stderr=subprocess.PIPE, close_fds=True\n    )\n    (output, err) = process.communicate()\n    rc = process.poll()\n    if rc != 0:\n        logging.debug(\n            '%s. Command %s failed, rc=%s, stdout=\"%s\", stderr=\"%s\"',\n            error_message,\n            cmd,\n            rc,\n            output,\n            err,\n        )\n    else:\n        return output, err\n\n\ndef ca_dirs_check(config, database_dir, certs_dir):\n    \"\"\"Check if mount's database and certs directories exist and if not, create directories (also create all intermediate\n    directories if they don't exist).\"\"\"\n    if not os.path.exists(database_dir):\n        create_required_directory(config, database_dir)\n    if not os.path.exists(certs_dir):\n        create_required_directory(config, certs_dir)\n\n\ndef ca_supporting_files_check(index_path, index_attr_path, serial_path, rand_path):\n    \"\"\"Create all supporting openssl ca and req files if they're not present in their respective directories\"\"\"\n\n    def _recreate_file_warning(path):\n        logging.warning(\"Expected %s not found, recreating file\", path)\n\n    if not os.path.isfile(index_path):\n        open(index_path, \"w\").close()\n        _recreate_file_warning(index_path)\n    if not os.path.isfile(index_attr_path):\n        with open(index_attr_path, \"w+\") as f:\n            f.write(\"unique_subject = no\")\n        _recreate_file_warning(index_attr_path)\n    if not os.path.isfile(serial_path):\n        with open(serial_path, \"w+\") as f:\n            f.write(\"00\")\n        _recreate_file_warning(serial_path)\n    if not os.path.isfile(rand_path):\n        open(rand_path, \"w\").close()\n        _recreate_file_warning(rand_path)\n\n\ndef tls_paths_dictionary(mount_name, base_path=STATE_FILE_DIR):\n    tls_dict = {\n        \"mount_dir\": os.path.join(base_path, mount_name),\n        \"database_dir\": os.path.join(base_path, mount_name, \"database\"),\n        \"certs_dir\": os.path.join(base_path, mount_name, \"certs\"),\n        \"index\": os.path.join(base_path, mount_name, \"database/index.txt\"),\n        \"index_attr\": os.path.join(base_path, mount_name, \"database/index.txt.attr\"),\n        \"serial\": os.path.join(base_path, mount_name, \"database/serial\"),\n        \"rand\": os.path.join(base_path, mount_name, \"database/.rand\"),\n    }\n\n    return tls_dict\n\n\ndef get_public_key_sha1(public_key):\n    # truncating public key to remove the header and footer '-----(BEGIN|END) PUBLIC KEY-----'\n    with open(public_key, \"r\") as f:\n        lines = f.readlines()\n        lines = lines[1:-1]\n\n    key = \"\".join(lines)\n    key = bytearray(base64.b64decode(key))\n\n    # Parse the public key to pull out the actual key material by looking for the key BIT STRING\n    # Example:\n    #     0:d=0  hl=4 l= 418 cons: SEQUENCE\n    #     4:d=1  hl=2 l=  13 cons: SEQUENCE\n    #     6:d=2  hl=2 l=   9 prim: OBJECT            :rsaEncryption\n    #    17:d=2  hl=2 l=   0 prim: NULL\n    #    19:d=1  hl=4 l= 399 prim: BIT STRING\n    cmd = \"openssl asn1parse -inform PEM -in %s\" % public_key\n    output, err = subprocess_call(\n        cmd, \"Unable to ASN1 parse public key file, %s, correctly\" % public_key\n    )\n\n    key_line = \"\"\n    for line in output.splitlines():\n        if \"BIT STRING\" in line.decode(\"utf-8\"):\n            key_line = line.decode(\"utf-8\")\n\n    if not key_line:\n        logging.error(\"Public key file, %s, is incorrectly formatted\", public_key)\n        return None\n\n    key_line = key_line.replace(\" \", \"\")\n\n    # DER encoding TLV (Tag, Length, Value)\n    # - the first octet (byte) is the tag (type)\n    # - the next octets are the length - \"definite form\"\n    #   - the first octet always has the high order bit (8) set to 1\n    #   - the remaining 127 bits are used to encode the number of octets that follow\n    #   - the following octets encode, as big-endian, the length (which may be 0) as a number of octets\n    # - the remaining octets are the \"value\" aka content\n    #\n    # For a BIT STRING, the first octet of the value is used to signify the number of unused bits that exist in the last\n    # content byte. Note that this is explicitly excluded from the SubjectKeyIdentifier hash, per\n    # https://tools.ietf.org/html/rfc5280#section-4.2.1.2\n    #\n    # Example:\n    #   0382018f00...<subjectPublicKey>\n    #   - 03 - BIT STRING tag\n    #   - 82 - 2 length octets to follow (ignore high order bit)\n    #   - 018f - length of 399\n    #   - 00 - no unused bits in the last content byte\n    offset = int(key_line.split(\":\")[0])\n    key = key[offset:]\n\n    num_length_octets = key[1] & 0b01111111\n\n    # Exclude the tag (1), length (1 + num_length_octets), and number of unused bits (1)\n    offset = 1 + 1 + num_length_octets + 1\n    key = key[offset:]\n\n    sha1 = hashlib.sha1()\n    sha1.update(key)\n\n    return sha1.hexdigest()\n\n\ndef create_canonical_request(\n    public_key_hash, date, access_key, region, fs_id, session_token=None\n):\n    \"\"\"\n    Create a Canonical Request - https://docs.aws.amazon.com/general/latest/gr/sigv4-create-canonical-request.html\n    \"\"\"\n    formatted_datetime = date.strftime(SIGV4_DATETIME_FORMAT)\n    credential = quote_plus(access_key + \"/\" + get_credential_scope(date, region))\n\n    request = HTTP_REQUEST_METHOD + \"\\n\"\n    request += CANONICAL_URI + \"\\n\"\n    request += (\n        create_canonical_query_string(\n            public_key_hash, credential, formatted_datetime, session_token\n        )\n        + \"\\n\"\n    )\n    request += CANONICAL_HEADERS % fs_id + \"\\n\"\n    request += SIGNED_HEADERS + \"\\n\"\n\n    sha256 = hashlib.sha256()\n    sha256.update(REQUEST_PAYLOAD.encode())\n    request += sha256.hexdigest()\n\n    return request\n\n\ndef create_canonical_query_string(\n    public_key_hash, credential, formatted_datetime, session_token=None\n):\n    canonical_query_params = {\n        \"Action\": \"Connect\",\n        # Public key hash is included in canonical request to tie the signature to a specific key pair to avoid replay attacks\n        \"PublicKeyHash\": quote_plus(public_key_hash),\n        \"X-Amz-Algorithm\": ALGORITHM,\n        \"X-Amz-Credential\": credential,\n        \"X-Amz-Date\": quote_plus(formatted_datetime),\n        \"X-Amz-Expires\": 86400,\n        \"X-Amz-SignedHeaders\": SIGNED_HEADERS,\n    }\n\n    if session_token:\n        canonical_query_params[\"X-Amz-Security-Token\"] = quote_plus(session_token)\n\n    # Cannot use urllib.urlencode because it replaces the %s's\n    return \"&\".join(\n        [\"%s=%s\" % (k, v) for k, v in sorted(canonical_query_params.items())]\n    )\n\n\ndef create_string_to_sign(canonical_request, date, region):\n    \"\"\"\n    Create a String to Sign - https://docs.aws.amazon.com/general/latest/gr/sigv4-create-string-to-sign.html\n    \"\"\"\n    string_to_sign = ALGORITHM + \"\\n\"\n    string_to_sign += date.strftime(SIGV4_DATETIME_FORMAT) + \"\\n\"\n    string_to_sign += get_credential_scope(date, region) + \"\\n\"\n\n    sha256 = hashlib.sha256()\n    sha256.update(canonical_request.encode())\n    string_to_sign += sha256.hexdigest()\n\n    return string_to_sign\n\n\ndef calculate_signature(string_to_sign, date, secret_access_key, region):\n    \"\"\"\n    Calculate the Signature - https://docs.aws.amazon.com/general/latest/gr/sigv4-calculate-signature.html\n    \"\"\"\n\n    def _sign(key, msg):\n        return hmac.new(key, msg.encode(\"utf-8\"), hashlib.sha256)\n\n    key_date = _sign(\n        (\"AWS4\" + secret_access_key).encode(\"utf-8\"), date.strftime(DATE_ONLY_FORMAT)\n    ).digest()\n    add_region = _sign(key_date, region).digest()\n    add_service = _sign(add_region, SERVICE).digest()\n    signing_key = _sign(add_service, \"aws4_request\").digest()\n\n    return _sign(signing_key, string_to_sign).hexdigest()\n\n\ndef get_certificate_renewal_interval_mins(config):\n    interval = DEFAULT_REFRESH_SELF_SIGNED_CERT_INTERVAL_MIN\n    try:\n        mins_from_config = config.get(CONFIG_SECTION, \"tls_cert_renewal_interval_min\")\n        try:\n            if int(mins_from_config) > 0:\n                interval = int(mins_from_config)\n            else:\n                logging.warning(\n                    'tls_cert_renewal_interval_min value in config file \"%s\" is lower than 1 minute. Defaulting '\n                    \"to %d minutes.\",\n                    CONFIG_FILE,\n                    DEFAULT_REFRESH_SELF_SIGNED_CERT_INTERVAL_MIN,\n                )\n        except ValueError:\n            logging.warning(\n                'Bad tls_cert_renewal_interval_min value, \"%s\", in config file \"%s\". Defaulting to %d minutes.',\n                mins_from_config,\n                CONFIG_FILE,\n                DEFAULT_REFRESH_SELF_SIGNED_CERT_INTERVAL_MIN,\n            )\n    except NoOptionError:\n        logging.warning(\n            'No tls_cert_renewal_interval_min value in config file \"%s\". Defaulting to %d minutes.',\n            CONFIG_FILE,\n            DEFAULT_REFRESH_SELF_SIGNED_CERT_INTERVAL_MIN,\n        )\n\n    return interval\n\n\ndef get_credential_scope(date, region):\n    return \"/\".join([date.strftime(DATE_ONLY_FORMAT), region, SERVICE, AWS4_REQUEST])\n\n\ndef get_certificate_timestamp(current_time, **kwargs):\n    updated_time = current_time + timedelta(**kwargs)\n    return updated_time.strftime(CERT_DATETIME_FORMAT)\n\n\ndef get_utc_now():\n    \"\"\"\n    Wrapped for patching purposes in unit tests\n    \"\"\"\n    return datetime.utcnow()\n\n\ndef check_process_name(pid):\n    if not check_if_running_on_macos():\n        cmd = [\"cat\", \"/proc/{pid}/cmdline\".format(pid=pid)]\n    else:\n        cmd = [\"ps\", \"-p\", str(pid), \"-o\", \"command=\"]\n\n    p = subprocess.Popen(\n        cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, close_fds=True\n    )\n    return p.communicate()[0]\n\n\ndef check_if_running_on_macos():\n    return sys.platform == \"darwin\"\n\n\ndef check_and_remove_file(path):\n    try:\n        os.remove(path)\n        logging.debug(\"Removed %s successfully\", path)\n    except OSError as e:\n        if e.errno != errno.ENOENT:\n            logging.debug(\"Could not remove %s. Unexpected exception: %s\", path, e)\n        else:\n            logging.debug(\"%s does not exist, nothing to do\", path)\n\n\ndef check_and_remove_lock_file(path, file):\n    \"\"\"\n    There is a possibility of having a race condition as the lock file is getting deleted in both mount_efs and watchdog,\n    so creating a function in order to check whether the path exist or not before removing the lock file.\n    \"\"\"\n    try:\n        os.close(file)\n        os.remove(path)\n        logging.debug(\"Removed %s successfully\", path)\n    except OSError as e:\n        if not (e.errno == errno.ENOENT or e.errno == errno.EBADF):\n            raise Exception(\"Could not remove %s. Unexpected exception: %s\", path, e)\n        else:\n            logging.debug(\n                \"%s does not exist, The file is already removed nothing to do\", path\n            )\n\n\ndef clean_up_certificate_lock_file(state_file_dir=STATE_FILE_DIR):\n    \"\"\"\n    Cleans up private key lock file 'efs-utils-lock' left behind by a previous process attempting to create private key\n    and efs-csi-driver is restarted. Once driver restarts, a new mount/watchdog process will fail to create private key\n    since contents of `STATE_FILE_DIR` is persisted on a node across driver pod restarts.\n    \"\"\"\n    lock_file = os.path.join(state_file_dir, \"efs-utils-lock\")\n    logging.debug(\"Removing private key file\")\n    check_and_remove_file(lock_file)\n\n\ndef clean_up_previous_stunnel_pids(state_file_dir=STATE_FILE_DIR):\n    \"\"\"\n    Cleans up stunnel pids created by mount watchdog spawned by a previous efs-csi-driver pod after driver restart, upgrade\n    or crash. This method attempts to clean PIDs from persisted state files after efs-csi-driver restart to\n    ensure watchdog creates a new stunnel.\n    \"\"\"\n    state_files = get_state_files(state_file_dir)\n    logging.debug(\n        'Persisted state files in \"%s\": %s', state_file_dir, list(state_files.values())\n    )\n\n    for state_file in state_files.values():\n        state_file_path = os.path.join(state_file_dir, state_file)\n        with open(state_file_path) as f:\n            try:\n                state = json.load(f)\n            except ValueError:\n                logging.exception(\"Unable to parse json in %s\", state_file_path)\n                continue\n\n            try:\n                pid = state[\"pid\"]\n            except KeyError:\n                logging.debug(\"No PID found in state file %s\", state_file)\n                continue\n\n            out = check_process_name(pid)\n\n            if out and \"stunnel\" in str(out):\n                logging.debug(\n                    \"PID %s in state file %s is active. Skipping clean up\",\n                    pid,\n                    state_file,\n                )\n                continue\n\n            state.pop(\"pid\")\n            logging.debug(\"Cleaning up pid %s in state file %s\", pid, state_file)\n\n            rewrite_state_file(state, state_file_dir, state_file)\n\n\ndef main():\n    parse_arguments()\n    assert_root()\n\n    config = read_config()\n    bootstrap_logging(config)\n\n    child_procs = []\n\n    if get_boolean_config_item_value(\n        config, CONFIG_SECTION, \"enabled\", default_value=True, emit_warning_message=True\n    ):\n        logging.info(\n            \"amazon-efs-mount-watchdog, version %s, is enabled and started\", VERSION\n        )\n        poll_interval_sec = config.getint(CONFIG_SECTION, \"poll_interval_sec\")\n\n        if config.has_option(CONFIG_SECTION, \"unmount_count_for_consistency\"):\n            unmount_count_for_consistency = config.getint(\n                CONFIG_SECTION, \"unmount_count_for_consistency\"\n            )\n        else:\n            unmount_count_for_consistency = DEFAULT_UNMOUNT_COUNT_FOR_CONSISTENCY\n\n        unmount_grace_period_sec = config.getint(\n            CONFIG_SECTION, \"unmount_grace_period_sec\"\n        )\n\n        clean_up_previous_stunnel_pids()\n        clean_up_certificate_lock_file()\n\n        while True:\n            config = read_config()\n\n            check_efs_mounts(\n                config,\n                child_procs,\n                unmount_grace_period_sec,\n                unmount_count_for_consistency,\n            )\n            check_child_procs(child_procs)\n\n            time.sleep(poll_interval_sec)\n    else:\n        logging.info(\"amazon-efs-mount-watchdog is not enabled\")\n\n\nif \"__main__\" == __name__:\n    main()\n", "# Copyright 2017-2018 Amazon.com, Inc. and its affiliates. All Rights Reserved.\n#\n# Licensed under the MIT License. See the LICENSE accompanying this file\n# for the specific language governing permissions and limitations under\n# the License.\n\nimport os\nimport tempfile\nfrom unittest.mock import MagicMock\n\nimport mount_efs\n\nAP_ID = \"fsap-beefdead\"\nFS_ID = \"fs-deadbeef\"\nCLIENT_SOURCE = \"test\"\nDNS_NAME = \"%s.efs.us-east-1.amazonaws.com\" % FS_ID\nMOUNT_POINT = \"/mnt\"\nREGION = \"us-east-1\"\n\n\nDEFAULT_TLS_PORT = 20049\n\nEXPECTED_STUNNEL_CONFIG_FILE_BASE = \"stunnel-config.fs-deadbeef.mnt.\"\nEXPECTED_STUNNEL_CONFIG_FILE = EXPECTED_STUNNEL_CONFIG_FILE_BASE + str(DEFAULT_TLS_PORT)\n\nINIT_SYSTEM = \"upstart\"\n\nMOCK_CONFIG = MagicMock()\n\n\ndef setup_mocks(mocker):\n    mocker.patch(\"mount_efs.start_watchdog\")\n    mocker.patch(\n        \"mount_efs.get_tls_port_range\",\n        return_value=(DEFAULT_TLS_PORT, DEFAULT_TLS_PORT + 10),\n    )\n    mocker.patch(\"socket.socket\", return_value=MagicMock())\n    mocker.patch(\n        \"mount_efs.get_dns_name_and_fallback_mount_target_ip_address\",\n        return_value=(DNS_NAME, None),\n    )\n    mocker.patch(\"mount_efs.get_target_region\", return_value=REGION)\n    mocker.patch(\"mount_efs.write_tls_tunnel_state_file\", return_value=\"~mocktempfile\")\n    mocker.patch(\"mount_efs.create_certificate\")\n    mocker.patch(\"os.rename\")\n    mocker.patch(\"os.kill\")\n    mocker.patch(\n        \"mount_efs.update_tls_tunnel_temp_state_file_with_tunnel_pid\",\n        return_value=\"~mocktempfile\",\n    )\n\n    process_mock = MagicMock()\n    process_mock.communicate.return_value = (\n        \"stdout\",\n        \"stderr\",\n    )\n    process_mock.returncode = 0\n\n    popen_mock = mocker.patch(\"subprocess.Popen\", return_value=process_mock)\n    write_config_mock = mocker.patch(\n        \"mount_efs.write_stunnel_config_file\", return_value=EXPECTED_STUNNEL_CONFIG_FILE\n    )\n    return popen_mock, write_config_mock\n\n\ndef setup_mocks_without_popen(mocker):\n    mocker.patch(\"mount_efs.start_watchdog\")\n    mocker.patch(\n        \"mount_efs.get_tls_port_range\",\n        return_value=(DEFAULT_TLS_PORT, DEFAULT_TLS_PORT + 10),\n    )\n    mocker.patch(\"socket.gethostname\", return_value=DNS_NAME)\n    mocker.patch(\n        \"mount_efs.get_dns_name_and_fallback_mount_target_ip_address\",\n        return_value=(DNS_NAME, None),\n    )\n    mocker.patch(\"mount_efs.write_tls_tunnel_state_file\", return_value=\"~mocktempfile\")\n    mocker.patch(\"os.kill\")\n    mocker.patch(\n        \"mount_efs.update_tls_tunnel_temp_state_file_with_tunnel_pid\",\n        return_value=\"~mocktempfile\",\n    )\n\n    write_config_mock = mocker.patch(\n        \"mount_efs.write_stunnel_config_file\", return_value=EXPECTED_STUNNEL_CONFIG_FILE\n    )\n    return write_config_mock\n\n\ndef test_bootstrap_tls_state_file_dir_exists(mocker, tmpdir):\n    popen_mock, _ = setup_mocks(mocker)\n    state_file_dir = str(tmpdir)\n\n    mocker.patch(\"mount_efs._stunnel_bin\", return_value=\"/usr/bin/stunnel\")\n    with mount_efs.bootstrap_tls(\n        MOCK_CONFIG, INIT_SYSTEM, DNS_NAME, FS_ID, MOUNT_POINT, {}, state_file_dir\n    ):\n        pass\n\n    args, _ = popen_mock.call_args\n    args = args[0]\n\n    assert \"/usr/bin/stunnel\" in args\n    assert EXPECTED_STUNNEL_CONFIG_FILE in args\n\n\ndef test_bootstrap_tls_state_file_nonexistent_dir(mocker, tmpdir):\n    popen_mock, _ = setup_mocks(mocker)\n    state_file_dir = str(tmpdir.join(tempfile.mkdtemp()[1]))\n\n    def config_get_side_effect(section, field):\n        if section == mount_efs.CONFIG_SECTION and field == \"state_file_dir_mode\":\n            return \"0755\"\n        elif section == mount_efs.CONFIG_SECTION and field == \"dns_name_format\":\n            return \"{fs_id}.efs.{region}.amazonaws.com\"\n        elif section == mount_efs.CLIENT_INFO_SECTION and field == \"source\":\n            return CLIENT_SOURCE\n        else:\n            raise ValueError(\"Unexpected arguments\")\n\n    MOCK_CONFIG.get.side_effect = config_get_side_effect\n\n    assert not os.path.exists(state_file_dir)\n\n    mocker.patch(\"mount_efs._stunnel_bin\", return_value=\"/usr/bin/stunnel\")\n    mocker.patch(\"mount_efs.find_existing_mount_using_tls_port\", return_value=None)\n    with mount_efs.bootstrap_tls(\n        MOCK_CONFIG, INIT_SYSTEM, DNS_NAME, FS_ID, MOUNT_POINT, {}, state_file_dir\n    ):\n        pass\n\n    assert os.path.exists(state_file_dir)\n\n\ndef test_bootstrap_tls_cert_created(mocker, tmpdir):\n    setup_mocks_without_popen(mocker)\n    mocker.patch(\"mount_efs.get_mount_specific_filename\", return_value=DNS_NAME)\n    mocker.patch(\"mount_efs.get_target_region\", return_value=REGION)\n    state_file_dir = str(tmpdir)\n    tls_dict = mount_efs.tls_paths_dictionary(DNS_NAME + \"+\", state_file_dir)\n\n    pk_path = os.path.join(str(tmpdir), \"privateKey.pem\")\n    mocker.patch(\"mount_efs.get_private_key_path\", return_value=pk_path)\n\n    def config_get_side_effect(section, field):\n        if section == mount_efs.CONFIG_SECTION and field == \"state_file_dir_mode\":\n            return \"0755\"\n        elif section == mount_efs.CONFIG_SECTION and field == \"dns_name_format\":\n            return \"{fs_id}.efs.{region}.amazonaws.com\"\n        elif section == mount_efs.CLIENT_INFO_SECTION and field == \"source\":\n            return CLIENT_SOURCE\n        else:\n            raise ValueError(\"Unexpected arguments\")\n\n    MOCK_CONFIG.get.side_effect = config_get_side_effect\n\n    mocker.patch(\"mount_efs._stunnel_bin\", return_value=\"/usr/bin/stunnel\")\n    try:\n        with mount_efs.bootstrap_tls(\n            MOCK_CONFIG,\n            INIT_SYSTEM,\n            DNS_NAME,\n            FS_ID,\n            MOUNT_POINT,\n            {\"accesspoint\": AP_ID},\n            state_file_dir,\n        ):\n            pass\n    except OSError as e:\n        assert \"[Errno 2] No such file or directory\" in str(e)\n\n    assert os.path.exists(os.path.join(tls_dict[\"mount_dir\"], \"certificate.pem\"))\n    assert os.path.exists(os.path.join(tls_dict[\"mount_dir\"], \"request.csr\"))\n    assert os.path.exists(os.path.join(tls_dict[\"mount_dir\"], \"config.conf\"))\n    assert os.path.exists(pk_path)\n\n\ndef test_bootstrap_tls_non_default_port(mocker, tmpdir):\n    popen_mock, write_config_mock = setup_mocks(mocker)\n    mocker.patch(\"os.rename\")\n    state_file_dir = str(tmpdir)\n\n    tls_port = 1000\n    tls_port_sock_mock = MagicMock()\n    tls_port_sock_mock.getsockname.return_value = (\"local_host\", tls_port)\n    tls_port_sock_mock.close.side_effect = None\n    mocker.patch(\"socket.socket\", return_value=tls_port_sock_mock)\n\n    mocker.patch(\"mount_efs._stunnel_bin\", return_value=\"/usr/bin/stunnel\")\n    with mount_efs.bootstrap_tls(\n        MOCK_CONFIG,\n        INIT_SYSTEM,\n        DNS_NAME,\n        FS_ID,\n        MOUNT_POINT,\n        {\"tlsport\": tls_port},\n        state_file_dir,\n    ):\n        pass\n\n    popen_args, _ = popen_mock.call_args\n    popen_args = popen_args[0]\n    write_config_args, _ = write_config_mock.call_args\n\n    assert \"/usr/bin/stunnel\" in popen_args\n    assert EXPECTED_STUNNEL_CONFIG_FILE in popen_args\n    assert tls_port == write_config_args[4]  # positional argument for tls_port\n    # Ensure tls port socket is closed in bootstrap_tls\n    # The number is two here, the first one is the actual socket when choosing tls port, the second one is a socket to\n    # verify tls port can be connected after establishing TLS stunnel. They share the same mock.\n    assert 2 == tls_port_sock_mock.close.call_count\n\n\ndef test_bootstrap_tls_non_default_verify_level(mocker, tmpdir):\n    popen_mock, write_config_mock = setup_mocks(mocker)\n    state_file_dir = str(tmpdir)\n\n    verify = 0\n    mocker.patch(\"mount_efs._stunnel_bin\", return_value=\"/usr/bin/stunnel\")\n    with mount_efs.bootstrap_tls(\n        MOCK_CONFIG,\n        INIT_SYSTEM,\n        DNS_NAME,\n        FS_ID,\n        MOUNT_POINT,\n        {\"verify\": verify},\n        state_file_dir,\n    ):\n        pass\n\n    popen_args, _ = popen_mock.call_args\n    popen_args = popen_args[0]\n    write_config_args, _ = write_config_mock.call_args\n\n    assert \"/usr/bin/stunnel\" in popen_args\n    assert EXPECTED_STUNNEL_CONFIG_FILE in popen_args\n    assert 0 == write_config_args[6]  # positional argument for verify_level\n\n\ndef test_bootstrap_tls_ocsp_option(mocker, tmpdir):\n    popen_mock, write_config_mock = setup_mocks(mocker)\n    state_file_dir = str(tmpdir)\n\n    mocker.patch(\"mount_efs._stunnel_bin\", return_value=\"/usr/bin/stunnel\")\n    with mount_efs.bootstrap_tls(\n        MOCK_CONFIG,\n        INIT_SYSTEM,\n        DNS_NAME,\n        FS_ID,\n        MOUNT_POINT,\n        {\"ocsp\": None},\n        state_file_dir,\n    ):\n        pass\n\n    popen_args, _ = popen_mock.call_args\n    popen_args = popen_args[0]\n    write_config_args, _ = write_config_mock.call_args\n\n    assert \"/usr/bin/stunnel\" in popen_args\n    assert EXPECTED_STUNNEL_CONFIG_FILE in popen_args\n    # positional argument for ocsp_override\n    assert write_config_args[7] is True\n\n\ndef test_bootstrap_tls_noocsp_option(mocker, tmpdir):\n    popen_mock, write_config_mock = setup_mocks(mocker)\n    state_file_dir = str(tmpdir)\n\n    mocker.patch(\"mount_efs._stunnel_bin\", return_value=\"/usr/bin/stunnel\")\n    with mount_efs.bootstrap_tls(\n        MOCK_CONFIG,\n        INIT_SYSTEM,\n        DNS_NAME,\n        FS_ID,\n        MOUNT_POINT,\n        {\"noocsp\": None},\n        state_file_dir,\n    ):\n        pass\n\n    popen_args, _ = popen_mock.call_args\n    popen_args = popen_args[0]\n    write_config_args, _ = write_config_mock.call_args\n\n    assert \"/usr/bin/stunnel\" in popen_args\n    assert EXPECTED_STUNNEL_CONFIG_FILE in popen_args\n    # positional argument for ocsp_override\n    assert write_config_args[7] is False\n", "# Copyright 2017-2018 Amazon.com, Inc. and its affiliates. All Rights Reserved.\n#\n# Licensed under the MIT License. See the LICENSE accompanying this file\n# for the specific language governing permissions and limitations under\n# the License.\nimport logging\nimport random\nimport socket\nimport sys\nimport tempfile\nimport unittest\nfrom unittest.mock import MagicMock\n\nimport pytest\n\nimport mount_efs\n\nfrom .. import utils\n\ntry:\n    import ConfigParser\nexcept ImportError:\n    from configparser import ConfigParser\n\nDEFAULT_TLS_PORT_RANGE_LOW = 20049\nDEFAULT_TLS_PORT_RANGE_HIGH = 21049\nDEFAULT_TLS_PORT = random.randrange(\n    DEFAULT_TLS_PORT_RANGE_LOW, DEFAULT_TLS_PORT_RANGE_HIGH\n)\n\n\ndef _get_config():\n    try:\n        config = ConfigParser.SafeConfigParser()\n    except AttributeError:\n        config = ConfigParser()\n    config.add_section(mount_efs.CONFIG_SECTION)\n    config.set(\n        mount_efs.CONFIG_SECTION,\n        \"port_range_lower_bound\",\n        str(DEFAULT_TLS_PORT_RANGE_LOW),\n    )\n    config.set(\n        mount_efs.CONFIG_SECTION,\n        \"port_range_upper_bound\",\n        str(DEFAULT_TLS_PORT_RANGE_HIGH),\n    )\n    return config\n\n\ndef test_choose_tls_port_first_try(mocker, tmpdir):\n    sock_mock = MagicMock()\n    sock_mock.getsockname.return_value = (\"local_host\", DEFAULT_TLS_PORT)\n    mocker.patch(\"socket.socket\", return_value=sock_mock)\n    options = {}\n\n    tls_port_sock = mount_efs.choose_tls_port_and_get_bind_sock(\n        _get_config(), options, str(tmpdir)\n    )\n    tls_port = mount_efs.get_tls_port_from_sock(tls_port_sock)\n    assert DEFAULT_TLS_PORT_RANGE_LOW <= tls_port <= DEFAULT_TLS_PORT_RANGE_HIGH\n\n\ndef test_choose_tls_port_second_try(mocker, tmpdir):\n    bad_sock = MagicMock()\n    bad_sock.bind.side_effect = [socket.error, None]\n    bad_sock.getsockname.return_value = (\"local_host\", DEFAULT_TLS_PORT)\n    options = {}\n\n    mocker.patch(\"socket.socket\", return_value=bad_sock)\n\n    tls_port_sock = mount_efs.choose_tls_port_and_get_bind_sock(\n        _get_config(), options, str(tmpdir)\n    )\n    tls_port = mount_efs.get_tls_port_from_sock(tls_port_sock)\n\n    assert DEFAULT_TLS_PORT_RANGE_LOW <= tls_port <= DEFAULT_TLS_PORT_RANGE_HIGH\n    assert 2 == bad_sock.bind.call_count\n    assert 1 == bad_sock.getsockname.call_count\n\n\n@unittest.skipIf(sys.version_info < (3, 6), reason=\"requires python3.6\")\ndef test_choose_tls_port_collision(mocker, tmpdir, caplog):\n    \"\"\"Ensure we don't choose a port that is pending mount\"\"\"\n    sock = MagicMock()\n    mocker.patch(\"socket.socket\", return_value=sock)\n    mocker.patch(\n        \"random.shuffle\",\n        return_value=range(DEFAULT_TLS_PORT_RANGE_LOW, DEFAULT_TLS_PORT_RANGE_HIGH),\n    )\n\n    port_suffix = \".%s\" % str(DEFAULT_TLS_PORT_RANGE_LOW)\n    temp_state_file = tempfile.NamedTemporaryFile(\n        suffix=port_suffix, prefix=\"~\", dir=tmpdir\n    )\n\n    options = {}\n    with caplog.at_level(logging.DEBUG):\n        mount_efs.choose_tls_port_and_get_bind_sock(_get_config(), options, tmpdir)\n\n    temp_state_file.close()\n    sock.bind.assert_called_once_with((\"localhost\", DEFAULT_TLS_PORT_RANGE_LOW + 1))\n    assert \"Skip binding TLS port\" in caplog.text\n\n\ndef test_choose_tls_port_never_succeeds(mocker, tmpdir, capsys):\n    bad_sock = MagicMock()\n    bad_sock.bind.side_effect = socket.error()\n    options = {}\n\n    mocker.patch(\"socket.socket\", return_value=bad_sock)\n\n    with pytest.raises(SystemExit) as ex:\n        mount_efs.choose_tls_port_and_get_bind_sock(_get_config(), options, str(tmpdir))\n\n    assert 0 != ex.value.code\n\n    out, err = capsys.readouterr()\n    assert \"Failed to locate an available port\" in err\n\n    assert (\n        DEFAULT_TLS_PORT_RANGE_HIGH - DEFAULT_TLS_PORT_RANGE_LOW\n        == bad_sock.bind.call_count\n    )\n\n\ndef test_choose_tls_port_option_specified(mocker, tmpdir):\n    sock_mock = MagicMock()\n    sock_mock.getsockname.return_value = (\"local_host\", DEFAULT_TLS_PORT)\n    mocker.patch(\"socket.socket\", return_value=sock_mock)\n    options = {\"tlsport\": DEFAULT_TLS_PORT}\n\n    tls_port_sock = mount_efs.choose_tls_port_and_get_bind_sock(\n        _get_config(), options, str(tmpdir)\n    )\n    tls_port = mount_efs.get_tls_port_from_sock(tls_port_sock)\n\n    assert DEFAULT_TLS_PORT == tls_port\n\n\ndef test_choose_tls_port_option_specified_unavailable(mocker, tmpdir, capsys):\n    bad_sock = MagicMock()\n    bad_sock.bind.side_effect = socket.error()\n    options = {\"tlsport\": 1000}\n\n    mocker.patch(\"socket.socket\", return_value=bad_sock)\n\n    with pytest.raises(SystemExit) as ex:\n        mount_efs.choose_tls_port_and_get_bind_sock(_get_config(), options, str(tmpdir))\n\n    assert 0 != ex.value.code\n\n    out, err = capsys.readouterr()\n    assert \"Specified port [1000] is unavailable\" in err\n\n    assert 1 == bad_sock.bind.call_count\n\n\ndef test_choose_tls_port_under_netns(mocker, tmpdir):\n    mocker.patch(\"builtins.open\")\n    setns_mock = mocker.patch(\"mount_efs.setns\", return_value=(None, None))\n    mocker.patch(\"socket.socket\", return_value=MagicMock())\n    options = {\"netns\": \"/proc/1000/ns/net\"}\n\n    mount_efs.choose_tls_port_and_get_bind_sock(_get_config(), options, str(tmpdir))\n    utils.assert_called(setns_mock)\n\n\ndef test_verify_tls_port(mocker):\n    sock = MagicMock()\n    sock.connect.side_effect = [ConnectionRefusedError, None]\n    mocker.patch(\"socket.socket\", return_value=sock)\n    result = mount_efs.verify_tlsport_can_be_connected(1000)\n    assert result is False\n    result = mount_efs.verify_tlsport_can_be_connected(1000)\n    assert result is True\n    assert 2 == sock.connect.call_count\n"], "filenames": ["amazon-efs-utils.spec", "build-deb.sh", "config.ini", "dist/amazon-efs-utils.control", "src/mount_efs/__init__.py", "src/watchdog/__init__.py", "test/mount_efs_test/test_bootstrap_tls.py", "test/mount_efs_test/test_choose_tls_port.py"], "buggy_code_start_loc": [38, 14, 10, 3, 88, 59, 46, 6], "buggy_code_end_loc": [139, 15, 11, 4, 1589, 60, 117, 133], "fixing_code_start_loc": [38, 14, 10, 3, 88, 59, 47, 6], "fixing_code_end_loc": [143, 15, 11, 4, 1640, 60, 127, 166], "type": "CWE-362", "message": "efs-utils is a set of Utilities for Amazon Elastic File System (EFS). A potential race condition issue exists within the Amazon EFS mount helper in efs-utils versions v1.34.3 and below. When using TLS to mount file systems, the mount helper allocates a local port for stunnel to receive NFS connections prior to applying the TLS tunnel. In affected versions, concurrent mount operations can allocate the same local port, leading to either failed mount operations or an inappropriate mapping from an EFS customer\u2019s local mount points to that customer\u2019s EFS file systems. This issue is patched in version v1.34.4. There is no recommended work around. We recommend affected users update the installed version of efs-utils to v1.34.4 or later.", "other": {"cve": {"id": "CVE-2022-46174", "sourceIdentifier": "security-advisories@github.com", "published": "2022-12-28T07:15:08.860", "lastModified": "2023-01-11T16:16:07.343", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "efs-utils is a set of Utilities for Amazon Elastic File System (EFS). A potential race condition issue exists within the Amazon EFS mount helper in efs-utils versions v1.34.3 and below. When using TLS to mount file systems, the mount helper allocates a local port for stunnel to receive NFS connections prior to applying the TLS tunnel. In affected versions, concurrent mount operations can allocate the same local port, leading to either failed mount operations or an inappropriate mapping from an EFS customer\u2019s local mount points to that customer\u2019s EFS file systems. This issue is patched in version v1.34.4. There is no recommended work around. We recommend affected users update the installed version of efs-utils to v1.34.4 or later."}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:H/PR:L/UI:N/S:U/C:N/I:L/A:L", "attackVector": "NETWORK", "attackComplexity": "HIGH", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "LOW", "availabilityImpact": "LOW", "baseScore": 4.2, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 1.6, "impactScore": 2.5}, {"source": "security-advisories@github.com", "type": "Secondary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:H/PR:L/UI:N/S:U/C:N/I:L/A:L", "attackVector": "NETWORK", "attackComplexity": "HIGH", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "LOW", "availabilityImpact": "LOW", "baseScore": 4.2, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 1.6, "impactScore": 2.5}]}, "weaknesses": [{"source": "security-advisories@github.com", "type": "Primary", "description": [{"lang": "en", "value": "CWE-362"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:amazon:efs-utils:*:*:*:*:*:*:*:*", "versionEndExcluding": "1.34.4", "matchCriteriaId": "F40EC4D8-9E3D-402D-B095-CCD5D8DCD6EF"}, {"vulnerable": true, "criteria": "cpe:2.3:a:amazon:elastic_file_system_container_storage_interface_driver:*:*:*:*:*:go:*:*", "versionEndExcluding": "1.4.8", "matchCriteriaId": "43EBB724-0B0C-49E4-B312-2154D1800F2D"}]}]}], "references": [{"url": "https://github.com/aws/efs-utils/commit/f3a8f88167d55caa2f78aeb72d4dc1987a9ed62d", "source": "security-advisories@github.com", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/aws/efs-utils/issues/125", "source": "security-advisories@github.com", "tags": ["Third Party Advisory"]}, {"url": "https://github.com/aws/efs-utils/security/advisories/GHSA-4fv8-w65m-3932", "source": "security-advisories@github.com", "tags": ["Third Party Advisory"]}]}, "github_commit_url": "https://github.com/aws/efs-utils/commit/f3a8f88167d55caa2f78aeb72d4dc1987a9ed62d"}}
{"buggy_code": ["# -*- coding: utf-8 -*-\n\n# Copyright 2014 OpenMarket Ltd\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport logging\n\nimport twisted.internet.ssl\n\nlogger = logging.getLogger(__name__)\n\nclass SslComponents:\n    def __init__(self, sydent):\n        self.sydent = sydent\n\n        self.myPrivateCertificate = self.makeMyCertificate()\n        self.trustRoot = self.makeTrustRoot()\n\n    def makeMyCertificate(self):\n        privKeyAndCertFilename = self.sydent.cfg.get('http', 'replication.https.certfile')\n        if privKeyAndCertFilename == '':\n            logger.warn(\"No HTTPS private key / cert found: not starting replication server \"\n                        \"or doing replication pushes\")\n            return None\n\n        try:\n            fp = open(privKeyAndCertFilename)\n        except IOError:\n            logger.warn(\"Unable to read private key / cert file from %s: not starting the replication HTTPS server \"\n                        \"or doing replication pushes.\",\n                        privKeyAndCertFilename)\n            return None\n\n        authData = fp.read()\n        fp.close()\n        return twisted.internet.ssl.PrivateCertificate.loadPEM(authData)\n\n    def makeTrustRoot(self):\n        # If this option is specified, use a specific root CA cert. This is useful for testing when it's not\n        # practical to get the client cert signed by a real root CA but should never be used on a production server.\n        caCertFilename = self.sydent.cfg.get('http', 'replication.https.cacert')\n        if len(caCertFilename) > 0:\n            try:\n                fp = open(caCertFilename)\n                caCert = twisted.internet.ssl.Certificate.loadPEM(fp.read())\n                fp.close()\n            except:\n                logger.warn(\"Failed to open CA cert file %s\", caCertFilename)\n                raise\n            logger.warn(\"Using custom CA cert file: %s\", caCertFilename)\n            return twisted.internet._sslverify.OpenSSLCertificateAuthorities([caCert.original])\n        else:\n            return twisted.internet.ssl.OpenSSLDefaultPaths()\n", "# -*- coding: utf-8 -*-\n# Copyright 2019 New Vector Ltd\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nfrom __future__ import absolute_import\n\nimport json\nimport logging\nimport random\nimport time\n\nimport attr\nfrom netaddr import IPAddress\nfrom zope.interface import implementer\n\nfrom twisted.internet import defer\nfrom twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS\nfrom twisted.internet.interfaces import IStreamClientEndpoint\nfrom twisted.web.client import URI, Agent, HTTPConnectionPool, RedirectAgent, readBody\nfrom twisted.web.http import stringToDatetime\nfrom twisted.web.http_headers import Headers\nfrom twisted.web.iweb import IAgent\n\nfrom sydent.http.srvresolver import SrvResolver, pick_server_from_list\nfrom sydent.util.ttlcache import TTLCache\n\n# period to cache .well-known results for by default\nWELL_KNOWN_DEFAULT_CACHE_PERIOD = 24 * 3600\n\n# jitter to add to the .well-known default cache ttl\nWELL_KNOWN_DEFAULT_CACHE_PERIOD_JITTER = 10 * 60\n\n# period to cache failure to fetch .well-known for\nWELL_KNOWN_INVALID_CACHE_PERIOD = 1 * 3600\n\n# cap for .well-known cache period\nWELL_KNOWN_MAX_CACHE_PERIOD = 48 * 3600\n\nlogger = logging.getLogger(__name__)\nwell_known_cache = TTLCache('well-known')\n\n@implementer(IAgent)\nclass MatrixFederationAgent(object):\n    \"\"\"An Agent-like thing which provides a `request` method which will look up a matrix\n    server and send an HTTP request to it.\n    Doesn't implement any retries. (Those are done in MatrixFederationHttpClient.)\n\n    :param reactor: twisted reactor to use for underlying requests\n    :type reactor: IReactor\n\n    :param tls_client_options_factory: Factory to use for fetching client tls\n        options, or none to disable TLS.\n    :type tls_client_options_factory: ClientTLSOptionsFactory, None\n\n    :param _well_known_tls_policy: TLS policy to use for fetching .well-known\n        files. None to use a default (browser-like) implementation.\n    :type _well_known_tls_policy: IPolicyForHTTPS, None\n\n    :param _srv_resolver: SRVResolver impl to use for looking up SRV records.\n        None to use a default implementation.\n    :type _srv_resolver: SrvResolver, None\n\n    :param _well_known_cache: TTLCache impl for storing cached well-known\n        lookups. None to use a default implementation.\n    :type _well_known_cache: TTLCache, None\n    \"\"\"\n\n    def __init__(\n        self, reactor, tls_client_options_factory,\n        _well_known_tls_policy=None,\n        _srv_resolver=None,\n        _well_known_cache=well_known_cache,\n    ):\n        self._reactor = reactor\n\n        self._tls_client_options_factory = tls_client_options_factory\n        if _srv_resolver is None:\n            _srv_resolver = SrvResolver()\n        self._srv_resolver = _srv_resolver\n\n        self._pool = HTTPConnectionPool(reactor)\n        self._pool.retryAutomatically = False\n        self._pool.maxPersistentPerHost = 5\n        self._pool.cachedConnectionTimeout = 2 * 60\n\n        agent_args = {}\n        if _well_known_tls_policy is not None:\n            # the param is called 'contextFactory', but actually passing a\n            # contextfactory is deprecated, and it expects an IPolicyForHTTPS.\n            agent_args['contextFactory'] = _well_known_tls_policy\n        _well_known_agent = RedirectAgent(\n            Agent(self._reactor, pool=self._pool, **agent_args),\n        )\n        self._well_known_agent = _well_known_agent\n\n        # our cache of .well-known lookup results, mapping from server name\n        # to delegated name. The values can be:\n        #   `bytes`:     a valid server-name\n        #   `None`:      there is no (valid) .well-known here\n        self._well_known_cache = _well_known_cache\n\n    @defer.inlineCallbacks\n    def request(self, method, uri, headers=None, bodyProducer=None):\n        \"\"\"\n        :param method: HTTP method (GET/POST/etc).\n        :type method: bytes\n\n        :param uri: Absolute URI to be retrieved.\n        :type uri: bytes\n\n        :param headers: HTTP headers to send with the request, or None to\n            send no extra headers.\n        :type headers: twisted.web.http_headers.Headers, None\n\n        :param bodyProducer: An object which can generate bytes to make up the\n            body of this request (for example, the properly encoded contents of\n            a file for a file upload).  Or None if the request is to have\n            no body.\n        :type bodyProducer: twisted.web.iweb.IBodyProducer, None\n\n        :returns a deferred that fires when the header of the response has\n            been received (regardless of the response status code). Fails if\n            there is any problem which prevents that response from being received\n            (including problems that prevent the request from being sent).\n        :rtype: Deferred[twisted.web.iweb.IResponse]\n        \"\"\"\n        parsed_uri = URI.fromBytes(uri, defaultPort=-1)\n        res = yield self._route_matrix_uri(parsed_uri)\n\n        # set up the TLS connection params\n        #\n        # XXX disabling TLS is really only supported here for the benefit of the\n        # unit tests. We should make the UTs cope with TLS rather than having to make\n        # the code support the unit tests.\n        if self._tls_client_options_factory is None:\n            tls_options = None\n        else:\n            tls_options = self._tls_client_options_factory.get_options(\n                res.tls_server_name.decode(\"ascii\")\n            )\n\n        # make sure that the Host header is set correctly\n        if headers is None:\n            headers = Headers()\n        else:\n            headers = headers.copy()\n\n        if not headers.hasHeader(b'host'):\n            headers.addRawHeader(b'host', res.host_header)\n\n        class EndpointFactory(object):\n            @staticmethod\n            def endpointForURI(_uri):\n                ep = LoggingHostnameEndpoint(\n                    self._reactor, res.target_host, res.target_port,\n                )\n                if tls_options is not None:\n                    ep = wrapClientTLS(tls_options, ep)\n                return ep\n\n        agent = Agent.usingEndpointFactory(self._reactor, EndpointFactory(), self._pool)\n        res = yield agent.request(method, uri, headers, bodyProducer)\n        defer.returnValue(res)\n\n    @defer.inlineCallbacks\n    def _route_matrix_uri(self, parsed_uri, lookup_well_known=True):\n        \"\"\"Helper for `request`: determine the routing for a Matrix URI\n\n        :param parsed_uri: uri to route. Note that it should be parsed with\n            URI.fromBytes(uri, defaultPort=-1) to set the `port` to -1 if there\n            is no explicit port given.\n        :type parsed_uri: twisted.web.client.URI\n        :param lookup_well_known: True if we should look up the .well-known\n            file if there is no SRV record.\n        :type lookup_well_known: bool\n\n        :returns a routing result.\n        :rtype: Deferred[_RoutingResult]\n        \"\"\"\n        # check for an IP literal\n        try:\n            ip_address = IPAddress(parsed_uri.host.decode(\"ascii\"))\n        except Exception:\n            # not an IP address\n            ip_address = None\n\n        if ip_address:\n            port = parsed_uri.port\n            if port == -1:\n                port = 8448\n            defer.returnValue(_RoutingResult(\n                host_header=parsed_uri.netloc,\n                tls_server_name=parsed_uri.host,\n                target_host=parsed_uri.host,\n                target_port=port,\n            ))\n\n        if parsed_uri.port != -1:\n            # there is an explicit port\n            defer.returnValue(_RoutingResult(\n                host_header=parsed_uri.netloc,\n                tls_server_name=parsed_uri.host,\n                target_host=parsed_uri.host,\n                target_port=parsed_uri.port,\n            ))\n\n        if lookup_well_known:\n            # try a .well-known lookup\n            well_known_server = yield self._get_well_known(parsed_uri.host)\n\n            if well_known_server:\n                # if we found a .well-known, start again, but don't do another\n                # .well-known lookup.\n\n                # parse the server name in the .well-known response into host/port.\n                # (This code is lifted from twisted.web.client.URI.fromBytes).\n                if b':' in well_known_server:\n                    well_known_host, well_known_port = well_known_server.rsplit(b':', 1)\n                    try:\n                        well_known_port = int(well_known_port)\n                    except ValueError:\n                        # the part after the colon could not be parsed as an int\n                        # - we assume it is an IPv6 literal with no port (the closing\n                        # ']' stops it being parsed as an int)\n                        well_known_host, well_known_port = well_known_server, -1\n                else:\n                    well_known_host, well_known_port = well_known_server, -1\n\n                new_uri = URI(\n                    scheme=parsed_uri.scheme,\n                    netloc=well_known_server,\n                    host=well_known_host,\n                    port=well_known_port,\n                    path=parsed_uri.path,\n                    params=parsed_uri.params,\n                    query=parsed_uri.query,\n                    fragment=parsed_uri.fragment,\n                )\n\n                res = yield self._route_matrix_uri(new_uri, lookup_well_known=False)\n                defer.returnValue(res)\n\n        # try a SRV lookup\n        service_name = b\"_matrix._tcp.%s\" % (parsed_uri.host,)\n        server_list = yield self._srv_resolver.resolve_service(service_name)\n\n        if not server_list:\n            target_host = parsed_uri.host\n            port = 8448\n            logger.debug(\n                \"No SRV record for %s, using %s:%i\",\n                parsed_uri.host.decode(\"ascii\"), target_host.decode(\"ascii\"), port,\n            )\n        else:\n            target_host, port = pick_server_from_list(server_list)\n            logger.debug(\n                \"Picked %s:%i from SRV records for %s\",\n                target_host.decode(\"ascii\"), port, parsed_uri.host.decode(\"ascii\"),\n            )\n\n        defer.returnValue(_RoutingResult(\n            host_header=parsed_uri.netloc,\n            tls_server_name=parsed_uri.host,\n            target_host=target_host,\n            target_port=port,\n        ))\n\n    @defer.inlineCallbacks\n    def _get_well_known(self, server_name):\n        \"\"\"Attempt to fetch and parse a .well-known file for the given server\n\n        :param server_name: Name of the server, from the requested url.\n        :type server_name: bytes\n\n        :returns either the new server name, from the .well-known, or None if\n            there was no .well-known file.\n        :rtype: Deferred[bytes|None]\n        \"\"\"\n        try:\n            result = self._well_known_cache[server_name]\n        except KeyError:\n            # TODO: should we linearise so that we don't end up doing two .well-known\n            # requests for the same server in parallel?\n            result, cache_period = yield self._do_get_well_known(server_name)\n\n            if cache_period > 0:\n                self._well_known_cache.set(server_name, result, cache_period)\n\n        defer.returnValue(result)\n\n    @defer.inlineCallbacks\n    def _do_get_well_known(self, server_name):\n        \"\"\"Actually fetch and parse a .well-known, without checking the cache\n\n        :param server_name: Name of the server, from the requested url\n        :type server_name: bytes\n\n        :returns a tuple of (result, cache period), where result is one of:\n            - the new server name from the .well-known (as a `bytes`)\n            - None if there was no .well-known file.\n            - INVALID_WELL_KNOWN if the .well-known was invalid\n        :rtype: Deferred[Tuple[bytes|None|object],int]\n        \"\"\"\n        uri = b\"https://%s/.well-known/matrix/server\" % (server_name, )\n        uri_str = uri.decode(\"ascii\")\n        logger.info(\"Fetching %s\", uri_str)\n        try:\n            response = yield self._well_known_agent.request(b\"GET\", uri)\n            body = yield readBody(response)\n            if response.code != 200:\n                raise Exception(\"Non-200 response %s\" % (response.code, ))\n\n            parsed_body = json.loads(body.decode('utf-8'))\n            logger.info(\"Response from .well-known: %s\", parsed_body)\n            if not isinstance(parsed_body, dict):\n                raise Exception(\"not a dict\")\n            if \"m.server\" not in parsed_body:\n                raise Exception(\"Missing key 'm.server'\")\n        except Exception as e:\n            logger.info(\"Error fetching %s: %s\", uri_str, e)\n\n            # add some randomness to the TTL to avoid a stampeding herd every hour\n            # after startup\n            cache_period = WELL_KNOWN_INVALID_CACHE_PERIOD\n            cache_period += random.uniform(0, WELL_KNOWN_DEFAULT_CACHE_PERIOD_JITTER)\n            defer.returnValue((None, cache_period))\n\n        result = parsed_body[\"m.server\"].encode(\"ascii\")\n\n        cache_period = _cache_period_from_headers(\n            response.headers,\n            time_now=self._reactor.seconds,\n        )\n        if cache_period is None:\n            cache_period = WELL_KNOWN_DEFAULT_CACHE_PERIOD\n            # add some randomness to the TTL to avoid a stampeding herd every 24 hours\n            # after startup\n            cache_period += random.uniform(0, WELL_KNOWN_DEFAULT_CACHE_PERIOD_JITTER)\n        else:\n            cache_period = min(cache_period, WELL_KNOWN_MAX_CACHE_PERIOD)\n\n        defer.returnValue((result, cache_period))\n\n\n@implementer(IStreamClientEndpoint)\nclass LoggingHostnameEndpoint(object):\n    \"\"\"A wrapper for HostnameEndpint which logs when it connects\"\"\"\n    def __init__(self, reactor, host, port, *args, **kwargs):\n        self.host = host\n        self.port = port\n        self.ep = HostnameEndpoint(reactor, host, port, *args, **kwargs)\n        logger.info(\"Endpoint created with %s:%d\", host, port)\n\n    def connect(self, protocol_factory):\n        logger.info(\"Connecting to %s:%i\", self.host.decode(\"ascii\"), self.port)\n        return self.ep.connect(protocol_factory)\n\n\ndef _cache_period_from_headers(headers, time_now=time.time):\n    cache_controls = _parse_cache_control(headers)\n\n    if b'no-store' in cache_controls:\n        return 0\n\n    if b'max-age' in cache_controls:\n        try:\n            max_age = int(cache_controls[b'max-age'])\n            return max_age\n        except ValueError:\n            pass\n\n    expires = headers.getRawHeaders(b'expires')\n    if expires is not None:\n        try:\n            expires_date = stringToDatetime(expires[-1])\n            return expires_date - time_now()\n        except ValueError:\n            # RFC7234 says 'A cache recipient MUST interpret invalid date formats,\n            # especially the value \"0\", as representing a time in the past (i.e.,\n            # \"already expired\").\n            return 0\n\n    return None\n\n\ndef _parse_cache_control(headers):\n    cache_controls = {}\n    for hdr in headers.getRawHeaders(b'cache-control', []):\n        for directive in hdr.split(b','):\n            splits = [x.strip() for x in directive.split(b'=', 1)]\n            k = splits[0].lower()\n            v = splits[1] if len(splits) > 1 else None\n            cache_controls[k] = v\n    return cache_controls\n\n\n@attr.s\nclass _RoutingResult(object):\n    \"\"\"The result returned by `_route_matrix_uri`.\n    Contains the parameters needed to direct a federation connection to a particular\n    server.\n    Where a SRV record points to several servers, this object contains a single server\n    chosen from the list.\n    \"\"\"\n\n    host_header = attr.ib()\n    \"\"\"\n    The value we should assign to the Host header (host:port from the matrix\n    URI, or .well-known).\n    :type: bytes\n    \"\"\"\n\n    tls_server_name = attr.ib()\n    \"\"\"\n    The server name we should set in the SNI (typically host, without port, from the\n    matrix URI or .well-known)\n    :type: bytes\n    \"\"\"\n\n    target_host = attr.ib()\n    \"\"\"\n    The hostname (or IP literal) we should route the TCP connection to (the target of the\n    SRV record, or the hostname from the URL/.well-known)\n    :type: bytes\n    \"\"\"\n\n    target_port = attr.ib()\n    \"\"\"\n    The port we should route the TCP connection to (the target of the SRV record, or\n    the port from the URL/.well-known, or 8448)\n    :type: int\n    \"\"\""], "fixing_code": ["# -*- coding: utf-8 -*-\n\n# Copyright 2014 OpenMarket Ltd\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport logging\nfrom io import BytesIO\n\nimport twisted.internet.ssl\nfrom twisted.internet import defer, protocol\nfrom twisted.internet.protocol import connectionDone\nfrom twisted.web._newclient import ResponseDone\nfrom twisted.web.http import PotentialDataLoss\nfrom twisted.web.iweb import UNKNOWN_LENGTH\n\nlogger = logging.getLogger(__name__)\n\nclass SslComponents:\n    def __init__(self, sydent):\n        self.sydent = sydent\n\n        self.myPrivateCertificate = self.makeMyCertificate()\n        self.trustRoot = self.makeTrustRoot()\n\n    def makeMyCertificate(self):\n        privKeyAndCertFilename = self.sydent.cfg.get('http', 'replication.https.certfile')\n        if privKeyAndCertFilename == '':\n            logger.warn(\"No HTTPS private key / cert found: not starting replication server \"\n                        \"or doing replication pushes\")\n            return None\n\n        try:\n            fp = open(privKeyAndCertFilename)\n        except IOError:\n            logger.warn(\"Unable to read private key / cert file from %s: not starting the replication HTTPS server \"\n                        \"or doing replication pushes.\",\n                        privKeyAndCertFilename)\n            return None\n\n        authData = fp.read()\n        fp.close()\n        return twisted.internet.ssl.PrivateCertificate.loadPEM(authData)\n\n    def makeTrustRoot(self):\n        # If this option is specified, use a specific root CA cert. This is useful for testing when it's not\n        # practical to get the client cert signed by a real root CA but should never be used on a production server.\n        caCertFilename = self.sydent.cfg.get('http', 'replication.https.cacert')\n        if len(caCertFilename) > 0:\n            try:\n                fp = open(caCertFilename)\n                caCert = twisted.internet.ssl.Certificate.loadPEM(fp.read())\n                fp.close()\n            except:\n                logger.warn(\"Failed to open CA cert file %s\", caCertFilename)\n                raise\n            logger.warn(\"Using custom CA cert file: %s\", caCertFilename)\n            return twisted.internet._sslverify.OpenSSLCertificateAuthorities([caCert.original])\n        else:\n            return twisted.internet.ssl.OpenSSLDefaultPaths()\n\n\n\nclass BodyExceededMaxSize(Exception):\n    \"\"\"The maximum allowed size of the HTTP body was exceeded.\"\"\"\n\n\nclass _DiscardBodyWithMaxSizeProtocol(protocol.Protocol):\n    \"\"\"A protocol which immediately errors upon receiving data.\"\"\"\n\n    def __init__(self, deferred):\n        self.deferred = deferred\n\n    def _maybe_fail(self):\n        \"\"\"\n        Report a max size exceed error and disconnect the first time this is called.\n        \"\"\"\n        if not self.deferred.called:\n            self.deferred.errback(BodyExceededMaxSize())\n            # Close the connection (forcefully) since all the data will get\n            # discarded anyway.\n            self.transport.abortConnection()\n\n    def dataReceived(self, data) -> None:\n        self._maybe_fail()\n\n    def connectionLost(self, reason) -> None:\n        self._maybe_fail()\n\n\nclass _ReadBodyWithMaxSizeProtocol(protocol.Protocol):\n    \"\"\"A protocol which reads body to a stream, erroring if the body exceeds a maximum size.\"\"\"\n\n    def __init__(self, deferred, max_size):\n        self.stream = BytesIO()\n        self.deferred = deferred\n        self.length = 0\n        self.max_size = max_size\n\n    def dataReceived(self, data) -> None:\n        # If the deferred was called, bail early.\n        if self.deferred.called:\n            return\n\n        self.stream.write(data)\n        self.length += len(data)\n        # The first time the maximum size is exceeded, error and cancel the\n        # connection. dataReceived might be called again if data was received\n        # in the meantime.\n        if self.max_size is not None and self.length >= self.max_size:\n            self.deferred.errback(BodyExceededMaxSize())\n            # Close the connection (forcefully) since all the data will get\n            # discarded anyway.\n            self.transport.abortConnection()\n\n    def connectionLost(self, reason = connectionDone) -> None:\n        # If the maximum size was already exceeded, there's nothing to do.\n        if self.deferred.called:\n            return\n\n        if reason.check(ResponseDone):\n            self.deferred.callback(self.stream.getvalue())\n        elif reason.check(PotentialDataLoss):\n            # stolen from https://github.com/twisted/treq/pull/49/files\n            # http://twistedmatrix.com/trac/ticket/4840\n            self.deferred.callback(self.stream.getvalue())\n        else:\n            self.deferred.errback(reason)\n\n\ndef read_body_with_max_size(response, max_size):\n    \"\"\"\n    Read a HTTP response body to a file-object. Optionally enforcing a maximum file size.\n\n    If the maximum file size is reached, the returned Deferred will resolve to a\n    Failure with a BodyExceededMaxSize exception.\n\n    Args:\n        response: The HTTP response to read from.\n        max_size: The maximum file size to allow.\n\n    Returns:\n        A Deferred which resolves to the read body.\n    \"\"\"\n    d = defer.Deferred()\n\n    # If the Content-Length header gives a size larger than the maximum allowed\n    # size, do not bother downloading the body.\n    if max_size is not None and response.length != UNKNOWN_LENGTH:\n        if response.length > max_size:\n            response.deliverBody(_DiscardBodyWithMaxSizeProtocol(d))\n            return d\n\n    response.deliverBody(_ReadBodyWithMaxSizeProtocol(d, max_size))\n    return d\n", "# -*- coding: utf-8 -*-\n# Copyright 2019 New Vector Ltd\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nfrom __future__ import absolute_import\n\nimport json\nimport logging\nimport random\nimport time\n\nimport attr\nfrom netaddr import IPAddress\nfrom zope.interface import implementer\n\nfrom twisted.internet import defer\nfrom twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS\nfrom twisted.internet.interfaces import IStreamClientEndpoint\nfrom twisted.web.client import URI, Agent, HTTPConnectionPool, RedirectAgent\nfrom twisted.web.http import stringToDatetime\nfrom twisted.web.http_headers import Headers\nfrom twisted.web.iweb import IAgent\n\nfrom sydent.http.httpcommon import BodyExceededMaxSize, read_body_with_max_size\nfrom sydent.http.srvresolver import SrvResolver, pick_server_from_list\nfrom sydent.util.ttlcache import TTLCache\n\n# period to cache .well-known results for by default\nWELL_KNOWN_DEFAULT_CACHE_PERIOD = 24 * 3600\n\n# jitter to add to the .well-known default cache ttl\nWELL_KNOWN_DEFAULT_CACHE_PERIOD_JITTER = 10 * 60\n\n# period to cache failure to fetch .well-known for\nWELL_KNOWN_INVALID_CACHE_PERIOD = 1 * 3600\n\n# cap for .well-known cache period\nWELL_KNOWN_MAX_CACHE_PERIOD = 48 * 3600\n\n# The maximum size (in bytes) to allow a well-known file to be.\nWELL_KNOWN_MAX_SIZE = 50 * 1024  # 50 KiB\n\nlogger = logging.getLogger(__name__)\nwell_known_cache = TTLCache('well-known')\n\n@implementer(IAgent)\nclass MatrixFederationAgent(object):\n    \"\"\"An Agent-like thing which provides a `request` method which will look up a matrix\n    server and send an HTTP request to it.\n    Doesn't implement any retries. (Those are done in MatrixFederationHttpClient.)\n\n    :param reactor: twisted reactor to use for underlying requests\n    :type reactor: IReactor\n\n    :param tls_client_options_factory: Factory to use for fetching client tls\n        options, or none to disable TLS.\n    :type tls_client_options_factory: ClientTLSOptionsFactory, None\n\n    :param _well_known_tls_policy: TLS policy to use for fetching .well-known\n        files. None to use a default (browser-like) implementation.\n    :type _well_known_tls_policy: IPolicyForHTTPS, None\n\n    :param _srv_resolver: SRVResolver impl to use for looking up SRV records.\n        None to use a default implementation.\n    :type _srv_resolver: SrvResolver, None\n\n    :param _well_known_cache: TTLCache impl for storing cached well-known\n        lookups. None to use a default implementation.\n    :type _well_known_cache: TTLCache, None\n    \"\"\"\n\n    def __init__(\n        self, reactor, tls_client_options_factory,\n        _well_known_tls_policy=None,\n        _srv_resolver=None,\n        _well_known_cache=well_known_cache,\n    ):\n        self._reactor = reactor\n\n        self._tls_client_options_factory = tls_client_options_factory\n        if _srv_resolver is None:\n            _srv_resolver = SrvResolver()\n        self._srv_resolver = _srv_resolver\n\n        self._pool = HTTPConnectionPool(reactor)\n        self._pool.retryAutomatically = False\n        self._pool.maxPersistentPerHost = 5\n        self._pool.cachedConnectionTimeout = 2 * 60\n\n        agent_args = {}\n        if _well_known_tls_policy is not None:\n            # the param is called 'contextFactory', but actually passing a\n            # contextfactory is deprecated, and it expects an IPolicyForHTTPS.\n            agent_args['contextFactory'] = _well_known_tls_policy\n        _well_known_agent = RedirectAgent(\n            Agent(self._reactor, pool=self._pool, **agent_args),\n        )\n        self._well_known_agent = _well_known_agent\n\n        # our cache of .well-known lookup results, mapping from server name\n        # to delegated name. The values can be:\n        #   `bytes`:     a valid server-name\n        #   `None`:      there is no (valid) .well-known here\n        self._well_known_cache = _well_known_cache\n\n    @defer.inlineCallbacks\n    def request(self, method, uri, headers=None, bodyProducer=None):\n        \"\"\"\n        :param method: HTTP method (GET/POST/etc).\n        :type method: bytes\n\n        :param uri: Absolute URI to be retrieved.\n        :type uri: bytes\n\n        :param headers: HTTP headers to send with the request, or None to\n            send no extra headers.\n        :type headers: twisted.web.http_headers.Headers, None\n\n        :param bodyProducer: An object which can generate bytes to make up the\n            body of this request (for example, the properly encoded contents of\n            a file for a file upload).  Or None if the request is to have\n            no body.\n        :type bodyProducer: twisted.web.iweb.IBodyProducer, None\n\n        :returns a deferred that fires when the header of the response has\n            been received (regardless of the response status code). Fails if\n            there is any problem which prevents that response from being received\n            (including problems that prevent the request from being sent).\n        :rtype: Deferred[twisted.web.iweb.IResponse]\n        \"\"\"\n        parsed_uri = URI.fromBytes(uri, defaultPort=-1)\n        res = yield self._route_matrix_uri(parsed_uri)\n\n        # set up the TLS connection params\n        #\n        # XXX disabling TLS is really only supported here for the benefit of the\n        # unit tests. We should make the UTs cope with TLS rather than having to make\n        # the code support the unit tests.\n        if self._tls_client_options_factory is None:\n            tls_options = None\n        else:\n            tls_options = self._tls_client_options_factory.get_options(\n                res.tls_server_name.decode(\"ascii\")\n            )\n\n        # make sure that the Host header is set correctly\n        if headers is None:\n            headers = Headers()\n        else:\n            headers = headers.copy()\n\n        if not headers.hasHeader(b'host'):\n            headers.addRawHeader(b'host', res.host_header)\n\n        class EndpointFactory(object):\n            @staticmethod\n            def endpointForURI(_uri):\n                ep = LoggingHostnameEndpoint(\n                    self._reactor, res.target_host, res.target_port,\n                )\n                if tls_options is not None:\n                    ep = wrapClientTLS(tls_options, ep)\n                return ep\n\n        agent = Agent.usingEndpointFactory(self._reactor, EndpointFactory(), self._pool)\n        res = yield agent.request(method, uri, headers, bodyProducer)\n        defer.returnValue(res)\n\n    @defer.inlineCallbacks\n    def _route_matrix_uri(self, parsed_uri, lookup_well_known=True):\n        \"\"\"Helper for `request`: determine the routing for a Matrix URI\n\n        :param parsed_uri: uri to route. Note that it should be parsed with\n            URI.fromBytes(uri, defaultPort=-1) to set the `port` to -1 if there\n            is no explicit port given.\n        :type parsed_uri: twisted.web.client.URI\n        :param lookup_well_known: True if we should look up the .well-known\n            file if there is no SRV record.\n        :type lookup_well_known: bool\n\n        :returns a routing result.\n        :rtype: Deferred[_RoutingResult]\n        \"\"\"\n        # check for an IP literal\n        try:\n            ip_address = IPAddress(parsed_uri.host.decode(\"ascii\"))\n        except Exception:\n            # not an IP address\n            ip_address = None\n\n        if ip_address:\n            port = parsed_uri.port\n            if port == -1:\n                port = 8448\n            defer.returnValue(_RoutingResult(\n                host_header=parsed_uri.netloc,\n                tls_server_name=parsed_uri.host,\n                target_host=parsed_uri.host,\n                target_port=port,\n            ))\n\n        if parsed_uri.port != -1:\n            # there is an explicit port\n            defer.returnValue(_RoutingResult(\n                host_header=parsed_uri.netloc,\n                tls_server_name=parsed_uri.host,\n                target_host=parsed_uri.host,\n                target_port=parsed_uri.port,\n            ))\n\n        if lookup_well_known:\n            # try a .well-known lookup\n            well_known_server = yield self._get_well_known(parsed_uri.host)\n\n            if well_known_server:\n                # if we found a .well-known, start again, but don't do another\n                # .well-known lookup.\n\n                # parse the server name in the .well-known response into host/port.\n                # (This code is lifted from twisted.web.client.URI.fromBytes).\n                if b':' in well_known_server:\n                    well_known_host, well_known_port = well_known_server.rsplit(b':', 1)\n                    try:\n                        well_known_port = int(well_known_port)\n                    except ValueError:\n                        # the part after the colon could not be parsed as an int\n                        # - we assume it is an IPv6 literal with no port (the closing\n                        # ']' stops it being parsed as an int)\n                        well_known_host, well_known_port = well_known_server, -1\n                else:\n                    well_known_host, well_known_port = well_known_server, -1\n\n                new_uri = URI(\n                    scheme=parsed_uri.scheme,\n                    netloc=well_known_server,\n                    host=well_known_host,\n                    port=well_known_port,\n                    path=parsed_uri.path,\n                    params=parsed_uri.params,\n                    query=parsed_uri.query,\n                    fragment=parsed_uri.fragment,\n                )\n\n                res = yield self._route_matrix_uri(new_uri, lookup_well_known=False)\n                defer.returnValue(res)\n\n        # try a SRV lookup\n        service_name = b\"_matrix._tcp.%s\" % (parsed_uri.host,)\n        server_list = yield self._srv_resolver.resolve_service(service_name)\n\n        if not server_list:\n            target_host = parsed_uri.host\n            port = 8448\n            logger.debug(\n                \"No SRV record for %s, using %s:%i\",\n                parsed_uri.host.decode(\"ascii\"), target_host.decode(\"ascii\"), port,\n            )\n        else:\n            target_host, port = pick_server_from_list(server_list)\n            logger.debug(\n                \"Picked %s:%i from SRV records for %s\",\n                target_host.decode(\"ascii\"), port, parsed_uri.host.decode(\"ascii\"),\n            )\n\n        defer.returnValue(_RoutingResult(\n            host_header=parsed_uri.netloc,\n            tls_server_name=parsed_uri.host,\n            target_host=target_host,\n            target_port=port,\n        ))\n\n    @defer.inlineCallbacks\n    def _get_well_known(self, server_name):\n        \"\"\"Attempt to fetch and parse a .well-known file for the given server\n\n        :param server_name: Name of the server, from the requested url.\n        :type server_name: bytes\n\n        :returns either the new server name, from the .well-known, or None if\n            there was no .well-known file.\n        :rtype: Deferred[bytes|None]\n        \"\"\"\n        try:\n            result = self._well_known_cache[server_name]\n        except KeyError:\n            # TODO: should we linearise so that we don't end up doing two .well-known\n            # requests for the same server in parallel?\n            result, cache_period = yield self._do_get_well_known(server_name)\n\n            if cache_period > 0:\n                self._well_known_cache.set(server_name, result, cache_period)\n\n        defer.returnValue(result)\n\n    @defer.inlineCallbacks\n    def _do_get_well_known(self, server_name):\n        \"\"\"Actually fetch and parse a .well-known, without checking the cache\n\n        :param server_name: Name of the server, from the requested url\n        :type server_name: bytes\n\n        :returns a tuple of (result, cache period), where result is one of:\n            - the new server name from the .well-known (as a `bytes`)\n            - None if there was no .well-known file.\n            - INVALID_WELL_KNOWN if the .well-known was invalid\n        :rtype: Deferred[Tuple[bytes|None|object],int]\n        \"\"\"\n        uri = b\"https://%s/.well-known/matrix/server\" % (server_name, )\n        uri_str = uri.decode(\"ascii\")\n        logger.info(\"Fetching %s\", uri_str)\n        try:\n            response = yield self._well_known_agent.request(b\"GET\", uri)\n            body = yield read_body_with_max_size(response, WELL_KNOWN_MAX_SIZE)\n            if response.code != 200:\n                raise Exception(\"Non-200 response %s\" % (response.code, ))\n\n            parsed_body = json.loads(body.decode('utf-8'))\n            logger.info(\"Response from .well-known: %s\", parsed_body)\n            if not isinstance(parsed_body, dict):\n                raise Exception(\"not a dict\")\n            if \"m.server\" not in parsed_body:\n                raise Exception(\"Missing key 'm.server'\")\n        except Exception as e:\n            logger.info(\"Error fetching %s: %s\", uri_str, e)\n\n            # add some randomness to the TTL to avoid a stampeding herd every hour\n            # after startup\n            cache_period = WELL_KNOWN_INVALID_CACHE_PERIOD\n            cache_period += random.uniform(0, WELL_KNOWN_DEFAULT_CACHE_PERIOD_JITTER)\n            defer.returnValue((None, cache_period))\n            return\n\n        result = parsed_body[\"m.server\"].encode(\"ascii\")\n\n        cache_period = _cache_period_from_headers(\n            response.headers,\n            time_now=self._reactor.seconds,\n        )\n        if cache_period is None:\n            cache_period = WELL_KNOWN_DEFAULT_CACHE_PERIOD\n            # add some randomness to the TTL to avoid a stampeding herd every 24 hours\n            # after startup\n            cache_period += random.uniform(0, WELL_KNOWN_DEFAULT_CACHE_PERIOD_JITTER)\n        else:\n            cache_period = min(cache_period, WELL_KNOWN_MAX_CACHE_PERIOD)\n\n        defer.returnValue((result, cache_period))\n\n\n@implementer(IStreamClientEndpoint)\nclass LoggingHostnameEndpoint(object):\n    \"\"\"A wrapper for HostnameEndpint which logs when it connects\"\"\"\n    def __init__(self, reactor, host, port, *args, **kwargs):\n        self.host = host\n        self.port = port\n        self.ep = HostnameEndpoint(reactor, host, port, *args, **kwargs)\n        logger.info(\"Endpoint created with %s:%d\", host, port)\n\n    def connect(self, protocol_factory):\n        logger.info(\"Connecting to %s:%i\", self.host.decode(\"ascii\"), self.port)\n        return self.ep.connect(protocol_factory)\n\n\ndef _cache_period_from_headers(headers, time_now=time.time):\n    cache_controls = _parse_cache_control(headers)\n\n    if b'no-store' in cache_controls:\n        return 0\n\n    if b'max-age' in cache_controls:\n        try:\n            max_age = int(cache_controls[b'max-age'])\n            return max_age\n        except ValueError:\n            pass\n\n    expires = headers.getRawHeaders(b'expires')\n    if expires is not None:\n        try:\n            expires_date = stringToDatetime(expires[-1])\n            return expires_date - time_now()\n        except ValueError:\n            # RFC7234 says 'A cache recipient MUST interpret invalid date formats,\n            # especially the value \"0\", as representing a time in the past (i.e.,\n            # \"already expired\").\n            return 0\n\n    return None\n\n\ndef _parse_cache_control(headers):\n    cache_controls = {}\n    for hdr in headers.getRawHeaders(b'cache-control', []):\n        for directive in hdr.split(b','):\n            splits = [x.strip() for x in directive.split(b'=', 1)]\n            k = splits[0].lower()\n            v = splits[1] if len(splits) > 1 else None\n            cache_controls[k] = v\n    return cache_controls\n\n\n@attr.s\nclass _RoutingResult(object):\n    \"\"\"The result returned by `_route_matrix_uri`.\n    Contains the parameters needed to direct a federation connection to a particular\n    server.\n    Where a SRV record points to several servers, this object contains a single server\n    chosen from the list.\n    \"\"\"\n\n    host_header = attr.ib()\n    \"\"\"\n    The value we should assign to the Host header (host:port from the matrix\n    URI, or .well-known).\n    :type: bytes\n    \"\"\"\n\n    tls_server_name = attr.ib()\n    \"\"\"\n    The server name we should set in the SNI (typically host, without port, from the\n    matrix URI or .well-known)\n    :type: bytes\n    \"\"\"\n\n    target_host = attr.ib()\n    \"\"\"\n    The hostname (or IP literal) we should route the TCP connection to (the target of the\n    SRV record, or the hostname from the URL/.well-known)\n    :type: bytes\n    \"\"\"\n\n    target_port = attr.ib()\n    \"\"\"\n    The port we should route the TCP connection to (the target of the SRV record, or\n    the port from the URL/.well-known, or 8448)\n    :type: int\n    \"\"\""], "filenames": ["sydent/http/httpcommon.py", "sydent/http/matrixfederationagent.py"], "buggy_code_start_loc": [17, 29], "buggy_code_end_loc": [64, 336], "fixing_code_start_loc": [18, 29], "fixing_code_end_loc": [166, 342], "type": "CWE-770", "message": "Sydent is a reference Matrix identity server. Sydent does not limit the size of requests it receives from HTTP clients. A malicious user could send an HTTP request with a very large body, leading to memory exhaustion and denial of service. Sydent also does not limit response size for requests it makes to remote Matrix homeservers. A malicious homeserver could return a very large response, again leading to memory exhaustion and denial of service. This affects any server which accepts registration requests from untrusted clients. This issue has been patched by releases 89071a1, 0523511, f56eee3. As a workaround request sizes can be limited in an HTTP reverse-proxy. There are no known workarounds for the problem with overlarge responses.", "other": {"cve": {"id": "CVE-2021-29430", "sourceIdentifier": "security-advisories@github.com", "published": "2021-04-15T21:15:17.413", "lastModified": "2022-08-03T10:13:56.370", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "Sydent is a reference Matrix identity server. Sydent does not limit the size of requests it receives from HTTP clients. A malicious user could send an HTTP request with a very large body, leading to memory exhaustion and denial of service. Sydent also does not limit response size for requests it makes to remote Matrix homeservers. A malicious homeserver could return a very large response, again leading to memory exhaustion and denial of service. This affects any server which accepts registration requests from untrusted clients. This issue has been patched by releases 89071a1, 0523511, f56eee3. As a workaround request sizes can be limited in an HTTP reverse-proxy. There are no known workarounds for the problem with overlarge responses."}, {"lang": "es", "value": "Sydent es un servidor de identidad Matrix de referencia.&#xa0;Sydent no limita el tama\u00f1o de las peticiones que recibe de los clientes HTTP.&#xa0;Un usuario malicioso podr\u00eda enviar una petici\u00f3n HTTP con un cuerpo muy grande, conllevando al agotamiento de la memoria y una denegaci\u00f3n de servicio.&#xa0;Sydent tampoco limita el tama\u00f1o de respuesta para las peticiones que realiza a los servidores dom\u00e9sticos de Matrix remotos.&#xa0;Un servidor dom\u00e9stico malicioso podr\u00eda devolver una respuesta muy grande, lo que nuevamente conlleva al agotamiento de la memoria y a una denegaci\u00f3n de servicio.&#xa0;Esto afecta a cualquier servidor que acepte peticiones de registro de clientes no confiables.&#xa0;Este problema ha sido parcheado para las versiones 89071a1, 0523511, f56eee3.&#xa0;Como soluci\u00f3n alternativa, los tama\u00f1os de las peticiones pueden ser limitados en un proxy inverso HTTP.&#xa0;No se conocen soluciones alternativas para el problema de las respuestas demasiado grandes"}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 7.5, "baseSeverity": "HIGH"}, "exploitabilityScore": 3.9, "impactScore": 3.6}, {"source": "security-advisories@github.com", "type": "Secondary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 7.5, "baseSeverity": "HIGH"}, "exploitabilityScore": 3.9, "impactScore": 3.6}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:N/AC:L/Au:N/C:N/I:N/A:P", "accessVector": "NETWORK", "accessComplexity": "LOW", "authentication": "NONE", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "PARTIAL", "baseScore": 5.0}, "baseSeverity": "MEDIUM", "exploitabilityScore": 10.0, "impactScore": 2.9, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-770"}]}, {"source": "security-advisories@github.com", "type": "Secondary", "description": [{"lang": "en", "value": "CWE-20"}, {"lang": "en", "value": "CWE-400"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:matrix:sydent:*:*:*:*:*:*:*:*", "versionEndExcluding": "2.3.0", "matchCriteriaId": "C77C5A80-7302-49F8-8DAA-37B269691C9C"}]}]}], "references": [{"url": "https://github.com/matrix-org/sydent/commit/0523511d2fb40f2738f8a8549868f44b96e5dab7", "source": "security-advisories@github.com", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/matrix-org/sydent/commit/89071a1a754c69a50deac89e6bb74002d4cda19d", "source": "security-advisories@github.com", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/matrix-org/sydent/commit/f56eee315b6c44fdd9f6aa785cc2ec744a594428", "source": "security-advisories@github.com", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/matrix-org/sydent/releases/tag/v2.3.0", "source": "security-advisories@github.com", "tags": ["Release Notes", "Third Party Advisory"]}, {"url": "https://github.com/matrix-org/sydent/security/advisories/GHSA-wmg4-8cp2-hpg9", "source": "security-advisories@github.com", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://pypi.org/project/matrix-sydent/", "source": "security-advisories@github.com", "tags": ["Product", "Third Party Advisory"]}]}, "github_commit_url": "https://github.com/matrix-org/sydent/commit/0523511d2fb40f2738f8a8549868f44b96e5dab7"}}
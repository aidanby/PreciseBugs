{"buggy_code": ["# -*- coding: utf-8 -*-\n# Copyright 2014-2016 OpenMarket Ltd\n# Copyright 2017 Vector Creations Ltd\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Contains constants from the specification.\"\"\"\n\n\nclass Membership(object):\n\n    \"\"\"Represents the membership states of a user in a room.\"\"\"\n    INVITE = u\"invite\"\n    JOIN = u\"join\"\n    KNOCK = u\"knock\"\n    LEAVE = u\"leave\"\n    BAN = u\"ban\"\n    LIST = (INVITE, JOIN, KNOCK, LEAVE, BAN)\n\n\nclass PresenceState(object):\n    \"\"\"Represents the presence state of a user.\"\"\"\n    OFFLINE = u\"offline\"\n    UNAVAILABLE = u\"unavailable\"\n    ONLINE = u\"online\"\n\n\nclass JoinRules(object):\n    PUBLIC = u\"public\"\n    KNOCK = u\"knock\"\n    INVITE = u\"invite\"\n    PRIVATE = u\"private\"\n\n\nclass LoginType(object):\n    PASSWORD = u\"m.login.password\"\n    EMAIL_IDENTITY = u\"m.login.email.identity\"\n    MSISDN = u\"m.login.msisdn\"\n    RECAPTCHA = u\"m.login.recaptcha\"\n    DUMMY = u\"m.login.dummy\"\n\n    # Only for C/S API v1\n    APPLICATION_SERVICE = u\"m.login.application_service\"\n    SHARED_SECRET = u\"org.matrix.login.shared_secret\"\n\n\nclass EventTypes(object):\n    Member = \"m.room.member\"\n    Create = \"m.room.create\"\n    JoinRules = \"m.room.join_rules\"\n    PowerLevels = \"m.room.power_levels\"\n    Aliases = \"m.room.aliases\"\n    Redaction = \"m.room.redaction\"\n    ThirdPartyInvite = \"m.room.third_party_invite\"\n\n    RoomHistoryVisibility = \"m.room.history_visibility\"\n    CanonicalAlias = \"m.room.canonical_alias\"\n    RoomAvatar = \"m.room.avatar\"\n    GuestAccess = \"m.room.guest_access\"\n\n    # These are used for validation\n    Message = \"m.room.message\"\n    Topic = \"m.room.topic\"\n    Name = \"m.room.name\"\n\n\nclass RejectedReason(object):\n    AUTH_ERROR = \"auth_error\"\n    REPLACED = \"replaced\"\n    NOT_ANCESTOR = \"not_ancestor\"\n\n\nclass RoomCreationPreset(object):\n    PRIVATE_CHAT = \"private_chat\"\n    PUBLIC_CHAT = \"public_chat\"\n    TRUSTED_PRIVATE_CHAT = \"trusted_private_chat\"\n\n\nclass ThirdPartyEntityKind(object):\n    USER = \"user\"\n    LOCATION = \"location\"\n", "# -*- coding: utf-8 -*-\n# Copyright 2015, 2016 OpenMarket Ltd\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nimport logging\n\nfrom synapse.api.errors import SynapseError\nfrom synapse.crypto.event_signing import check_event_content_hash\nfrom synapse.events import FrozenEvent\nfrom synapse.events.utils import prune_event\nfrom synapse.http.servlet import assert_params_in_request\nfrom synapse.util import unwrapFirstError, logcontext\nfrom twisted.internet import defer\n\nlogger = logging.getLogger(__name__)\n\n\nclass FederationBase(object):\n    def __init__(self, hs):\n        self.hs = hs\n\n        self.server_name = hs.hostname\n        self.keyring = hs.get_keyring()\n        self.spam_checker = hs.get_spam_checker()\n        self.store = hs.get_datastore()\n        self._clock = hs.get_clock()\n\n    @defer.inlineCallbacks\n    def _check_sigs_and_hash_and_fetch(self, origin, pdus, outlier=False,\n                                       include_none=False):\n        \"\"\"Takes a list of PDUs and checks the signatures and hashs of each\n        one. If a PDU fails its signature check then we check if we have it in\n        the database and if not then request if from the originating server of\n        that PDU.\n\n        If a PDU fails its content hash check then it is redacted.\n\n        The given list of PDUs are not modified, instead the function returns\n        a new list.\n\n        Args:\n            pdu (list)\n            outlier (bool)\n\n        Returns:\n            Deferred : A list of PDUs that have valid signatures and hashes.\n        \"\"\"\n        deferreds = self._check_sigs_and_hashes(pdus)\n\n        @defer.inlineCallbacks\n        def handle_check_result(pdu, deferred):\n            try:\n                res = yield logcontext.make_deferred_yieldable(deferred)\n            except SynapseError:\n                res = None\n\n            if not res:\n                # Check local db.\n                res = yield self.store.get_event(\n                    pdu.event_id,\n                    allow_rejected=True,\n                    allow_none=True,\n                )\n\n            if not res and pdu.origin != origin:\n                try:\n                    res = yield self.get_pdu(\n                        destinations=[pdu.origin],\n                        event_id=pdu.event_id,\n                        outlier=outlier,\n                        timeout=10000,\n                    )\n                except SynapseError:\n                    pass\n\n            if not res:\n                logger.warn(\n                    \"Failed to find copy of %s with valid signature\",\n                    pdu.event_id,\n                )\n\n            defer.returnValue(res)\n\n        handle = logcontext.preserve_fn(handle_check_result)\n        deferreds2 = [\n            handle(pdu, deferred)\n            for pdu, deferred in zip(pdus, deferreds)\n        ]\n\n        valid_pdus = yield logcontext.make_deferred_yieldable(\n            defer.gatherResults(\n                deferreds2,\n                consumeErrors=True,\n            )\n        ).addErrback(unwrapFirstError)\n\n        if include_none:\n            defer.returnValue(valid_pdus)\n        else:\n            defer.returnValue([p for p in valid_pdus if p])\n\n    def _check_sigs_and_hash(self, pdu):\n        return logcontext.make_deferred_yieldable(\n            self._check_sigs_and_hashes([pdu])[0],\n        )\n\n    def _check_sigs_and_hashes(self, pdus):\n        \"\"\"Checks that each of the received events is correctly signed by the\n        sending server.\n\n        Args:\n            pdus (list[FrozenEvent]): the events to be checked\n\n        Returns:\n            list[Deferred]: for each input event, a deferred which:\n              * returns the original event if the checks pass\n              * returns a redacted version of the event (if the signature\n                matched but the hash did not)\n              * throws a SynapseError if the signature check failed.\n            The deferreds run their callbacks in the sentinel logcontext.\n        \"\"\"\n\n        redacted_pdus = [\n            prune_event(pdu)\n            for pdu in pdus\n        ]\n\n        deferreds = self.keyring.verify_json_objects_for_server([\n            (p.origin, p.get_pdu_json())\n            for p in redacted_pdus\n        ])\n\n        ctx = logcontext.LoggingContext.current_context()\n\n        def callback(_, pdu, redacted):\n            with logcontext.PreserveLoggingContext(ctx):\n                if not check_event_content_hash(pdu):\n                    logger.warn(\n                        \"Event content has been tampered, redacting %s: %s\",\n                        pdu.event_id, pdu.get_pdu_json()\n                    )\n                    return redacted\n\n                if self.spam_checker.check_event_for_spam(pdu):\n                    logger.warn(\n                        \"Event contains spam, redacting %s: %s\",\n                        pdu.event_id, pdu.get_pdu_json()\n                    )\n                    return redacted\n\n                return pdu\n\n        def errback(failure, pdu):\n            failure.trap(SynapseError)\n            with logcontext.PreserveLoggingContext(ctx):\n                logger.warn(\n                    \"Signature check failed for %s\",\n                    pdu.event_id,\n                )\n            return failure\n\n        for deferred, pdu, redacted in zip(deferreds, pdus, redacted_pdus):\n            deferred.addCallbacks(\n                callback, errback,\n                callbackArgs=[pdu, redacted],\n                errbackArgs=[pdu],\n            )\n\n        return deferreds\n\n\ndef event_from_pdu_json(pdu_json, outlier=False):\n    \"\"\"Construct a FrozenEvent from an event json received over federation\n\n    Args:\n        pdu_json (object): pdu as received over federation\n        outlier (bool): True to mark this event as an outlier\n\n    Returns:\n        FrozenEvent\n\n    Raises:\n        SynapseError: if the pdu is missing required fields\n    \"\"\"\n    # we could probably enforce a bunch of other fields here (room_id, sender,\n    # origin, etc etc)\n    assert_params_in_request(pdu_json, ('event_id', 'type'))\n    event = FrozenEvent(\n        pdu_json\n    )\n\n    event.internal_metadata.outlier = outlier\n\n    return event\n", "# -*- coding: utf-8 -*-\n# Copyright 2014 - 2016 OpenMarket Ltd\n# Copyright 2017 - 2018 New Vector Ltd\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nfrom twisted.internet import defer, reactor\nfrom twisted.python.failure import Failure\n\nfrom synapse.api.constants import EventTypes, Membership\nfrom synapse.api.errors import AuthError, Codes, SynapseError\nfrom synapse.crypto.event_signing import add_hashes_and_signatures\nfrom synapse.events.utils import serialize_event\nfrom synapse.events.validator import EventValidator\nfrom synapse.types import (\n    UserID, RoomAlias, RoomStreamToken,\n)\nfrom synapse.util.async import run_on_reactor, ReadWriteLock, Limiter\nfrom synapse.util.logcontext import preserve_fn, run_in_background\nfrom synapse.util.metrics import measure_func\nfrom synapse.util.frozenutils import frozendict_json_encoder\nfrom synapse.util.stringutils import random_string\nfrom synapse.visibility import filter_events_for_client\nfrom synapse.replication.http.send_event import send_event_to_master\n\nfrom ._base import BaseHandler\n\nfrom canonicaljson import encode_canonical_json\n\nimport logging\nimport simplejson\n\nlogger = logging.getLogger(__name__)\n\n\nclass PurgeStatus(object):\n    \"\"\"Object tracking the status of a purge request\n\n    This class contains information on the progress of a purge request, for\n    return by get_purge_status.\n\n    Attributes:\n        status (int): Tracks whether this request has completed. One of\n            STATUS_{ACTIVE,COMPLETE,FAILED}\n    \"\"\"\n\n    STATUS_ACTIVE = 0\n    STATUS_COMPLETE = 1\n    STATUS_FAILED = 2\n\n    STATUS_TEXT = {\n        STATUS_ACTIVE: \"active\",\n        STATUS_COMPLETE: \"complete\",\n        STATUS_FAILED: \"failed\",\n    }\n\n    def __init__(self):\n        self.status = PurgeStatus.STATUS_ACTIVE\n\n    def asdict(self):\n        return {\n            \"status\": PurgeStatus.STATUS_TEXT[self.status]\n        }\n\n\nclass MessageHandler(BaseHandler):\n\n    def __init__(self, hs):\n        super(MessageHandler, self).__init__(hs)\n        self.hs = hs\n        self.state = hs.get_state_handler()\n        self.clock = hs.get_clock()\n\n        self.pagination_lock = ReadWriteLock()\n        self._purges_in_progress_by_room = set()\n        # map from purge id to PurgeStatus\n        self._purges_by_id = {}\n\n    def start_purge_history(self, room_id, topological_ordering,\n                            delete_local_events=False):\n        \"\"\"Start off a history purge on a room.\n\n        Args:\n            room_id (str): The room to purge from\n\n            topological_ordering (int): minimum topo ordering to preserve\n            delete_local_events (bool): True to delete local events as well as\n                remote ones\n\n        Returns:\n            str: unique ID for this purge transaction.\n        \"\"\"\n        if room_id in self._purges_in_progress_by_room:\n            raise SynapseError(\n                400,\n                \"History purge already in progress for %s\" % (room_id, ),\n            )\n\n        purge_id = random_string(16)\n\n        # we log the purge_id here so that it can be tied back to the\n        # request id in the log lines.\n        logger.info(\"[purge] starting purge_id %s\", purge_id)\n\n        self._purges_by_id[purge_id] = PurgeStatus()\n        run_in_background(\n            self._purge_history,\n            purge_id, room_id, topological_ordering, delete_local_events,\n        )\n        return purge_id\n\n    @defer.inlineCallbacks\n    def _purge_history(self, purge_id, room_id, topological_ordering,\n                       delete_local_events):\n        \"\"\"Carry out a history purge on a room.\n\n        Args:\n            purge_id (str): The id for this purge\n            room_id (str): The room to purge from\n            topological_ordering (int): minimum topo ordering to preserve\n            delete_local_events (bool): True to delete local events as well as\n                remote ones\n\n        Returns:\n            Deferred\n        \"\"\"\n        self._purges_in_progress_by_room.add(room_id)\n        try:\n            with (yield self.pagination_lock.write(room_id)):\n                yield self.store.purge_history(\n                    room_id, topological_ordering, delete_local_events,\n                )\n            logger.info(\"[purge] complete\")\n            self._purges_by_id[purge_id].status = PurgeStatus.STATUS_COMPLETE\n        except Exception:\n            logger.error(\"[purge] failed: %s\", Failure().getTraceback().rstrip())\n            self._purges_by_id[purge_id].status = PurgeStatus.STATUS_FAILED\n        finally:\n            self._purges_in_progress_by_room.discard(room_id)\n\n            # remove the purge from the list 24 hours after it completes\n            def clear_purge():\n                del self._purges_by_id[purge_id]\n            reactor.callLater(24 * 3600, clear_purge)\n\n    def get_purge_status(self, purge_id):\n        \"\"\"Get the current status of an active purge\n\n        Args:\n            purge_id (str): purge_id returned by start_purge_history\n\n        Returns:\n            PurgeStatus|None\n        \"\"\"\n        return self._purges_by_id.get(purge_id)\n\n    @defer.inlineCallbacks\n    def get_messages(self, requester, room_id=None, pagin_config=None,\n                     as_client_event=True, event_filter=None):\n        \"\"\"Get messages in a room.\n\n        Args:\n            requester (Requester): The user requesting messages.\n            room_id (str): The room they want messages from.\n            pagin_config (synapse.api.streams.PaginationConfig): The pagination\n                config rules to apply, if any.\n            as_client_event (bool): True to get events in client-server format.\n            event_filter (Filter): Filter to apply to results or None\n        Returns:\n            dict: Pagination API results\n        \"\"\"\n        user_id = requester.user.to_string()\n\n        if pagin_config.from_token:\n            room_token = pagin_config.from_token.room_key\n        else:\n            pagin_config.from_token = (\n                yield self.hs.get_event_sources().get_current_token_for_room(\n                    room_id=room_id\n                )\n            )\n            room_token = pagin_config.from_token.room_key\n\n        room_token = RoomStreamToken.parse(room_token)\n\n        pagin_config.from_token = pagin_config.from_token.copy_and_replace(\n            \"room_key\", str(room_token)\n        )\n\n        source_config = pagin_config.get_source_config(\"room\")\n\n        with (yield self.pagination_lock.read(room_id)):\n            membership, member_event_id = yield self._check_in_room_or_world_readable(\n                room_id, user_id\n            )\n\n            if source_config.direction == 'b':\n                # if we're going backwards, we might need to backfill. This\n                # requires that we have a topo token.\n                if room_token.topological:\n                    max_topo = room_token.topological\n                else:\n                    max_topo = yield self.store.get_max_topological_token(\n                        room_id, room_token.stream\n                    )\n\n                if membership == Membership.LEAVE:\n                    # If they have left the room then clamp the token to be before\n                    # they left the room, to save the effort of loading from the\n                    # database.\n                    leave_token = yield self.store.get_topological_token_for_event(\n                        member_event_id\n                    )\n                    leave_token = RoomStreamToken.parse(leave_token)\n                    if leave_token.topological < max_topo:\n                        source_config.from_key = str(leave_token)\n\n                yield self.hs.get_handlers().federation_handler.maybe_backfill(\n                    room_id, max_topo\n                )\n\n            events, next_key = yield self.store.paginate_room_events(\n                room_id=room_id,\n                from_key=source_config.from_key,\n                to_key=source_config.to_key,\n                direction=source_config.direction,\n                limit=source_config.limit,\n                event_filter=event_filter,\n            )\n\n            next_token = pagin_config.from_token.copy_and_replace(\n                \"room_key\", next_key\n            )\n\n        if not events:\n            defer.returnValue({\n                \"chunk\": [],\n                \"start\": pagin_config.from_token.to_string(),\n                \"end\": next_token.to_string(),\n            })\n\n        if event_filter:\n            events = event_filter.filter(events)\n\n        events = yield filter_events_for_client(\n            self.store,\n            user_id,\n            events,\n            is_peeking=(member_event_id is None),\n        )\n\n        time_now = self.clock.time_msec()\n\n        chunk = {\n            \"chunk\": [\n                serialize_event(e, time_now, as_client_event)\n                for e in events\n            ],\n            \"start\": pagin_config.from_token.to_string(),\n            \"end\": next_token.to_string(),\n        }\n\n        defer.returnValue(chunk)\n\n    @defer.inlineCallbacks\n    def get_room_data(self, user_id=None, room_id=None,\n                      event_type=None, state_key=\"\", is_guest=False):\n        \"\"\" Get data from a room.\n\n        Args:\n            event : The room path event\n        Returns:\n            The path data content.\n        Raises:\n            SynapseError if something went wrong.\n        \"\"\"\n        membership, membership_event_id = yield self._check_in_room_or_world_readable(\n            room_id, user_id\n        )\n\n        if membership == Membership.JOIN:\n            data = yield self.state_handler.get_current_state(\n                room_id, event_type, state_key\n            )\n        elif membership == Membership.LEAVE:\n            key = (event_type, state_key)\n            room_state = yield self.store.get_state_for_events(\n                [membership_event_id], [key]\n            )\n            data = room_state[membership_event_id].get(key)\n\n        defer.returnValue(data)\n\n    @defer.inlineCallbacks\n    def _check_in_room_or_world_readable(self, room_id, user_id):\n        try:\n            # check_user_was_in_room will return the most recent membership\n            # event for the user if:\n            #  * The user is a non-guest user, and was ever in the room\n            #  * The user is a guest user, and has joined the room\n            # else it will throw.\n            member_event = yield self.auth.check_user_was_in_room(room_id, user_id)\n            defer.returnValue((member_event.membership, member_event.event_id))\n            return\n        except AuthError:\n            visibility = yield self.state_handler.get_current_state(\n                room_id, EventTypes.RoomHistoryVisibility, \"\"\n            )\n            if (\n                visibility and\n                visibility.content[\"history_visibility\"] == \"world_readable\"\n            ):\n                defer.returnValue((Membership.JOIN, None))\n                return\n            raise AuthError(\n                403, \"Guest access not allowed\", errcode=Codes.GUEST_ACCESS_FORBIDDEN\n            )\n\n    @defer.inlineCallbacks\n    def get_state_events(self, user_id, room_id, is_guest=False):\n        \"\"\"Retrieve all state events for a given room. If the user is\n        joined to the room then return the current state. If the user has\n        left the room return the state events from when they left.\n\n        Args:\n            user_id(str): The user requesting state events.\n            room_id(str): The room ID to get all state events from.\n        Returns:\n            A list of dicts representing state events. [{}, {}, {}]\n        \"\"\"\n        membership, membership_event_id = yield self._check_in_room_or_world_readable(\n            room_id, user_id\n        )\n\n        if membership == Membership.JOIN:\n            room_state = yield self.state_handler.get_current_state(room_id)\n        elif membership == Membership.LEAVE:\n            room_state = yield self.store.get_state_for_events(\n                [membership_event_id], None\n            )\n            room_state = room_state[membership_event_id]\n\n        now = self.clock.time_msec()\n        defer.returnValue(\n            [serialize_event(c, now) for c in room_state.values()]\n        )\n\n    @defer.inlineCallbacks\n    def get_joined_members(self, requester, room_id):\n        \"\"\"Get all the joined members in the room and their profile information.\n\n        If the user has left the room return the state events from when they left.\n\n        Args:\n            requester(Requester): The user requesting state events.\n            room_id(str): The room ID to get all state events from.\n        Returns:\n            A dict of user_id to profile info\n        \"\"\"\n        user_id = requester.user.to_string()\n        if not requester.app_service:\n            # We check AS auth after fetching the room membership, as it\n            # requires us to pull out all joined members anyway.\n            membership, _ = yield self._check_in_room_or_world_readable(\n                room_id, user_id\n            )\n            if membership != Membership.JOIN:\n                raise NotImplementedError(\n                    \"Getting joined members after leaving is not implemented\"\n                )\n\n        users_with_profile = yield self.state.get_current_user_in_room(room_id)\n\n        # If this is an AS, double check that they are allowed to see the members.\n        # This can either be because the AS user is in the room or becuase there\n        # is a user in the room that the AS is \"interested in\"\n        if requester.app_service and user_id not in users_with_profile:\n            for uid in users_with_profile:\n                if requester.app_service.is_interested_in_user(uid):\n                    break\n            else:\n                # Loop fell through, AS has no interested users in room\n                raise AuthError(403, \"Appservice not in room\")\n\n        defer.returnValue({\n            user_id: {\n                \"avatar_url\": profile.avatar_url,\n                \"display_name\": profile.display_name,\n            }\n            for user_id, profile in users_with_profile.iteritems()\n        })\n\n\nclass EventCreationHandler(object):\n    def __init__(self, hs):\n        self.hs = hs\n        self.auth = hs.get_auth()\n        self.store = hs.get_datastore()\n        self.state = hs.get_state_handler()\n        self.clock = hs.get_clock()\n        self.validator = EventValidator()\n        self.profile_handler = hs.get_profile_handler()\n        self.event_builder_factory = hs.get_event_builder_factory()\n        self.server_name = hs.hostname\n        self.ratelimiter = hs.get_ratelimiter()\n        self.notifier = hs.get_notifier()\n        self.config = hs.config\n\n        self.http_client = hs.get_simple_http_client()\n\n        # This is only used to get at ratelimit function, and maybe_kick_guest_users\n        self.base_handler = BaseHandler(hs)\n\n        self.pusher_pool = hs.get_pusherpool()\n\n        # We arbitrarily limit concurrent event creation for a room to 5.\n        # This is to stop us from diverging history *too* much.\n        self.limiter = Limiter(max_count=5)\n\n        self.action_generator = hs.get_action_generator()\n\n        self.spam_checker = hs.get_spam_checker()\n\n    @defer.inlineCallbacks\n    def create_event(self, requester, event_dict, token_id=None, txn_id=None,\n                     prev_events_and_hashes=None):\n        \"\"\"\n        Given a dict from a client, create a new event.\n\n        Creates an FrozenEvent object, filling out auth_events, prev_events,\n        etc.\n\n        Adds display names to Join membership events.\n\n        Args:\n            requester\n            event_dict (dict): An entire event\n            token_id (str)\n            txn_id (str)\n\n            prev_events_and_hashes (list[(str, dict[str, str], int)]|None):\n                the forward extremities to use as the prev_events for the\n                new event. For each event, a tuple of (event_id, hashes, depth)\n                where *hashes* is a map from algorithm to hash.\n\n                If None, they will be requested from the database.\n\n        Returns:\n            Tuple of created event (FrozenEvent), Context\n        \"\"\"\n        builder = self.event_builder_factory.new(event_dict)\n\n        self.validator.validate_new(builder)\n\n        if builder.type == EventTypes.Member:\n            membership = builder.content.get(\"membership\", None)\n            target = UserID.from_string(builder.state_key)\n\n            if membership in {Membership.JOIN, Membership.INVITE}:\n                # If event doesn't include a display name, add one.\n                profile = self.profile_handler\n                content = builder.content\n\n                try:\n                    if \"displayname\" not in content:\n                        content[\"displayname\"] = yield profile.get_displayname(target)\n                    if \"avatar_url\" not in content:\n                        content[\"avatar_url\"] = yield profile.get_avatar_url(target)\n                except Exception as e:\n                    logger.info(\n                        \"Failed to get profile information for %r: %s\",\n                        target, e\n                    )\n\n        if token_id is not None:\n            builder.internal_metadata.token_id = token_id\n\n        if txn_id is not None:\n            builder.internal_metadata.txn_id = txn_id\n\n        event, context = yield self.create_new_client_event(\n            builder=builder,\n            requester=requester,\n            prev_events_and_hashes=prev_events_and_hashes,\n        )\n\n        defer.returnValue((event, context))\n\n    @defer.inlineCallbacks\n    def send_nonmember_event(self, requester, event, context, ratelimit=True):\n        \"\"\"\n        Persists and notifies local clients and federation of an event.\n\n        Args:\n            event (FrozenEvent) the event to send.\n            context (Context) the context of the event.\n            ratelimit (bool): Whether to rate limit this send.\n            is_guest (bool): Whether the sender is a guest.\n        \"\"\"\n        if event.type == EventTypes.Member:\n            raise SynapseError(\n                500,\n                \"Tried to send member event through non-member codepath\"\n            )\n\n        user = UserID.from_string(event.sender)\n\n        assert self.hs.is_mine(user), \"User must be our own: %s\" % (user,)\n\n        if event.is_state():\n            prev_state = yield self.deduplicate_state_event(event, context)\n            if prev_state is not None:\n                defer.returnValue(prev_state)\n\n        yield self.handle_new_client_event(\n            requester=requester,\n            event=event,\n            context=context,\n            ratelimit=ratelimit,\n        )\n\n    @defer.inlineCallbacks\n    def deduplicate_state_event(self, event, context):\n        \"\"\"\n        Checks whether event is in the latest resolved state in context.\n\n        If so, returns the version of the event in context.\n        Otherwise, returns None.\n        \"\"\"\n        prev_event_id = context.prev_state_ids.get((event.type, event.state_key))\n        prev_event = yield self.store.get_event(prev_event_id, allow_none=True)\n        if not prev_event:\n            return\n\n        if prev_event and event.user_id == prev_event.user_id:\n            prev_content = encode_canonical_json(prev_event.content)\n            next_content = encode_canonical_json(event.content)\n            if prev_content == next_content:\n                defer.returnValue(prev_event)\n        return\n\n    @defer.inlineCallbacks\n    def create_and_send_nonmember_event(\n        self,\n        requester,\n        event_dict,\n        ratelimit=True,\n        txn_id=None\n    ):\n        \"\"\"\n        Creates an event, then sends it.\n\n        See self.create_event and self.send_nonmember_event.\n        \"\"\"\n\n        # We limit the number of concurrent event sends in a room so that we\n        # don't fork the DAG too much. If we don't limit then we can end up in\n        # a situation where event persistence can't keep up, causing\n        # extremities to pile up, which in turn leads to state resolution\n        # taking longer.\n        with (yield self.limiter.queue(event_dict[\"room_id\"])):\n            event, context = yield self.create_event(\n                requester,\n                event_dict,\n                token_id=requester.access_token_id,\n                txn_id=txn_id\n            )\n\n            spam_error = self.spam_checker.check_event_for_spam(event)\n            if spam_error:\n                if not isinstance(spam_error, basestring):\n                    spam_error = \"Spam is not permitted here\"\n                raise SynapseError(\n                    403, spam_error, Codes.FORBIDDEN\n                )\n\n            yield self.send_nonmember_event(\n                requester,\n                event,\n                context,\n                ratelimit=ratelimit,\n            )\n        defer.returnValue(event)\n\n    @measure_func(\"create_new_client_event\")\n    @defer.inlineCallbacks\n    def create_new_client_event(self, builder, requester=None,\n                                prev_events_and_hashes=None):\n        \"\"\"Create a new event for a local client\n\n        Args:\n            builder (EventBuilder):\n\n            requester (synapse.types.Requester|None):\n\n            prev_events_and_hashes (list[(str, dict[str, str], int)]|None):\n                the forward extremities to use as the prev_events for the\n                new event. For each event, a tuple of (event_id, hashes, depth)\n                where *hashes* is a map from algorithm to hash.\n\n                If None, they will be requested from the database.\n\n        Returns:\n            Deferred[(synapse.events.EventBase, synapse.events.snapshot.EventContext)]\n        \"\"\"\n\n        if prev_events_and_hashes is not None:\n            assert len(prev_events_and_hashes) <= 10, \\\n                \"Attempting to create an event with %i prev_events\" % (\n                    len(prev_events_and_hashes),\n            )\n        else:\n            prev_events_and_hashes = \\\n                yield self.store.get_prev_events_for_room(builder.room_id)\n\n        if prev_events_and_hashes:\n            depth = max([d for _, _, d in prev_events_and_hashes]) + 1\n        else:\n            depth = 1\n\n        prev_events = [\n            (event_id, prev_hashes)\n            for event_id, prev_hashes, _ in prev_events_and_hashes\n        ]\n\n        builder.prev_events = prev_events\n        builder.depth = depth\n\n        context = yield self.state.compute_event_context(builder)\n        if requester:\n            context.app_service = requester.app_service\n\n        if builder.is_state():\n            builder.prev_state = yield self.store.add_event_hashes(\n                context.prev_state_events\n            )\n\n        yield self.auth.add_auth_events(builder, context)\n\n        signing_key = self.hs.config.signing_key[0]\n        add_hashes_and_signatures(\n            builder, self.server_name, signing_key\n        )\n\n        event = builder.build()\n\n        logger.debug(\n            \"Created event %s with state: %s\",\n            event.event_id, context.prev_state_ids,\n        )\n\n        defer.returnValue(\n            (event, context,)\n        )\n\n    @measure_func(\"handle_new_client_event\")\n    @defer.inlineCallbacks\n    def handle_new_client_event(\n        self,\n        requester,\n        event,\n        context,\n        ratelimit=True,\n        extra_users=[],\n    ):\n        \"\"\"Processes a new event. This includes checking auth, persisting it,\n        notifying users, sending to remote servers, etc.\n\n        If called from a worker will hit out to the master process for final\n        processing.\n\n        Args:\n            requester (Requester)\n            event (FrozenEvent)\n            context (EventContext)\n            ratelimit (bool)\n            extra_users (list(UserID)): Any extra users to notify about event\n        \"\"\"\n\n        try:\n            yield self.auth.check_from_context(event, context)\n        except AuthError as err:\n            logger.warn(\"Denying new event %r because %s\", event, err)\n            raise err\n\n        # Ensure that we can round trip before trying to persist in db\n        try:\n            dump = frozendict_json_encoder.encode(event.content)\n            simplejson.loads(dump)\n        except Exception:\n            logger.exception(\"Failed to encode content: %r\", event.content)\n            raise\n\n        yield self.action_generator.handle_push_actions_for_event(\n            event, context\n        )\n\n        try:\n            # If we're a worker we need to hit out to the master.\n            if self.config.worker_app:\n                yield send_event_to_master(\n                    self.http_client,\n                    host=self.config.worker_replication_host,\n                    port=self.config.worker_replication_http_port,\n                    requester=requester,\n                    event=event,\n                    context=context,\n                    ratelimit=ratelimit,\n                    extra_users=extra_users,\n                )\n                return\n\n            yield self.persist_and_notify_client_event(\n                requester,\n                event,\n                context,\n                ratelimit=ratelimit,\n                extra_users=extra_users,\n            )\n        except:  # noqa: E722, as we reraise the exception this is fine.\n            # Ensure that we actually remove the entries in the push actions\n            # staging area, if we calculated them.\n            preserve_fn(self.store.remove_push_actions_from_staging)(event.event_id)\n            raise\n\n    @defer.inlineCallbacks\n    def persist_and_notify_client_event(\n        self,\n        requester,\n        event,\n        context,\n        ratelimit=True,\n        extra_users=[],\n    ):\n        \"\"\"Called when we have fully built the event, have already\n        calculated the push actions for the event, and checked auth.\n\n        This should only be run on master.\n        \"\"\"\n        assert not self.config.worker_app\n\n        if ratelimit:\n            yield self.base_handler.ratelimit(requester)\n\n        yield self.base_handler.maybe_kick_guest_users(event, context)\n\n        if event.type == EventTypes.CanonicalAlias:\n            # Check the alias is acually valid (at this time at least)\n            room_alias_str = event.content.get(\"alias\", None)\n            if room_alias_str:\n                room_alias = RoomAlias.from_string(room_alias_str)\n                directory_handler = self.hs.get_handlers().directory_handler\n                mapping = yield directory_handler.get_association(room_alias)\n\n                if mapping[\"room_id\"] != event.room_id:\n                    raise SynapseError(\n                        400,\n                        \"Room alias %s does not point to the room\" % (\n                            room_alias_str,\n                        )\n                    )\n\n        federation_handler = self.hs.get_handlers().federation_handler\n\n        if event.type == EventTypes.Member:\n            if event.content[\"membership\"] == Membership.INVITE:\n                def is_inviter_member_event(e):\n                    return (\n                        e.type == EventTypes.Member and\n                        e.sender == event.sender\n                    )\n\n                state_to_include_ids = [\n                    e_id\n                    for k, e_id in context.current_state_ids.iteritems()\n                    if k[0] in self.hs.config.room_invite_state_types\n                    or k == (EventTypes.Member, event.sender)\n                ]\n\n                state_to_include = yield self.store.get_events(state_to_include_ids)\n\n                event.unsigned[\"invite_room_state\"] = [\n                    {\n                        \"type\": e.type,\n                        \"state_key\": e.state_key,\n                        \"content\": e.content,\n                        \"sender\": e.sender,\n                    }\n                    for e in state_to_include.itervalues()\n                ]\n\n                invitee = UserID.from_string(event.state_key)\n                if not self.hs.is_mine(invitee):\n                    # TODO: Can we add signature from remote server in a nicer\n                    # way? If we have been invited by a remote server, we need\n                    # to get them to sign the event.\n\n                    returned_invite = yield federation_handler.send_invite(\n                        invitee.domain,\n                        event,\n                    )\n\n                    event.unsigned.pop(\"room_state\", None)\n\n                    # TODO: Make sure the signatures actually are correct.\n                    event.signatures.update(\n                        returned_invite.signatures\n                    )\n\n        if event.type == EventTypes.Redaction:\n            auth_events_ids = yield self.auth.compute_auth_events(\n                event, context.prev_state_ids, for_verification=True,\n            )\n            auth_events = yield self.store.get_events(auth_events_ids)\n            auth_events = {\n                (e.type, e.state_key): e for e in auth_events.values()\n            }\n            if self.auth.check_redaction(event, auth_events=auth_events):\n                original_event = yield self.store.get_event(\n                    event.redacts,\n                    check_redacted=False,\n                    get_prev_content=False,\n                    allow_rejected=False,\n                    allow_none=False\n                )\n                if event.user_id != original_event.user_id:\n                    raise AuthError(\n                        403,\n                        \"You don't have permission to redact events\"\n                    )\n\n        if event.type == EventTypes.Create and context.prev_state_ids:\n            raise AuthError(\n                403,\n                \"Changing the room create event is forbidden\",\n            )\n\n        (event_stream_id, max_stream_id) = yield self.store.persist_event(\n            event, context=context\n        )\n\n        # this intentionally does not yield: we don't care about the result\n        # and don't need to wait for it.\n        preserve_fn(self.pusher_pool.on_new_notifications)(\n            event_stream_id, max_stream_id\n        )\n\n        @defer.inlineCallbacks\n        def _notify():\n            yield run_on_reactor()\n            self.notifier.on_new_room_event(\n                event, event_stream_id, max_stream_id,\n                extra_users=extra_users\n            )\n\n        preserve_fn(_notify)()\n\n        if event.type == EventTypes.Message:\n            presence = self.hs.get_presence_handler()\n            # We don't want to block sending messages on any presence code. This\n            # matters as sometimes presence code can take a while.\n            preserve_fn(presence.bump_presence_active_time)(requester.user)\n"], "fixing_code": ["# -*- coding: utf-8 -*-\n# Copyright 2014-2016 OpenMarket Ltd\n# Copyright 2017 Vector Creations Ltd\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\"\"\"Contains constants from the specification.\"\"\"\n\n# the \"depth\" field on events is limited to 2**63 - 1\nMAX_DEPTH = 2**63 - 1\n\n\nclass Membership(object):\n\n    \"\"\"Represents the membership states of a user in a room.\"\"\"\n    INVITE = u\"invite\"\n    JOIN = u\"join\"\n    KNOCK = u\"knock\"\n    LEAVE = u\"leave\"\n    BAN = u\"ban\"\n    LIST = (INVITE, JOIN, KNOCK, LEAVE, BAN)\n\n\nclass PresenceState(object):\n    \"\"\"Represents the presence state of a user.\"\"\"\n    OFFLINE = u\"offline\"\n    UNAVAILABLE = u\"unavailable\"\n    ONLINE = u\"online\"\n\n\nclass JoinRules(object):\n    PUBLIC = u\"public\"\n    KNOCK = u\"knock\"\n    INVITE = u\"invite\"\n    PRIVATE = u\"private\"\n\n\nclass LoginType(object):\n    PASSWORD = u\"m.login.password\"\n    EMAIL_IDENTITY = u\"m.login.email.identity\"\n    MSISDN = u\"m.login.msisdn\"\n    RECAPTCHA = u\"m.login.recaptcha\"\n    DUMMY = u\"m.login.dummy\"\n\n    # Only for C/S API v1\n    APPLICATION_SERVICE = u\"m.login.application_service\"\n    SHARED_SECRET = u\"org.matrix.login.shared_secret\"\n\n\nclass EventTypes(object):\n    Member = \"m.room.member\"\n    Create = \"m.room.create\"\n    JoinRules = \"m.room.join_rules\"\n    PowerLevels = \"m.room.power_levels\"\n    Aliases = \"m.room.aliases\"\n    Redaction = \"m.room.redaction\"\n    ThirdPartyInvite = \"m.room.third_party_invite\"\n\n    RoomHistoryVisibility = \"m.room.history_visibility\"\n    CanonicalAlias = \"m.room.canonical_alias\"\n    RoomAvatar = \"m.room.avatar\"\n    GuestAccess = \"m.room.guest_access\"\n\n    # These are used for validation\n    Message = \"m.room.message\"\n    Topic = \"m.room.topic\"\n    Name = \"m.room.name\"\n\n\nclass RejectedReason(object):\n    AUTH_ERROR = \"auth_error\"\n    REPLACED = \"replaced\"\n    NOT_ANCESTOR = \"not_ancestor\"\n\n\nclass RoomCreationPreset(object):\n    PRIVATE_CHAT = \"private_chat\"\n    PUBLIC_CHAT = \"public_chat\"\n    TRUSTED_PRIVATE_CHAT = \"trusted_private_chat\"\n\n\nclass ThirdPartyEntityKind(object):\n    USER = \"user\"\n    LOCATION = \"location\"\n", "# -*- coding: utf-8 -*-\n# Copyright 2015, 2016 OpenMarket Ltd\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nimport logging\n\nimport six\n\nfrom synapse.api.constants import MAX_DEPTH\nfrom synapse.api.errors import SynapseError, Codes\nfrom synapse.crypto.event_signing import check_event_content_hash\nfrom synapse.events import FrozenEvent\nfrom synapse.events.utils import prune_event\nfrom synapse.http.servlet import assert_params_in_request\nfrom synapse.util import unwrapFirstError, logcontext\nfrom twisted.internet import defer\n\nlogger = logging.getLogger(__name__)\n\n\nclass FederationBase(object):\n    def __init__(self, hs):\n        self.hs = hs\n\n        self.server_name = hs.hostname\n        self.keyring = hs.get_keyring()\n        self.spam_checker = hs.get_spam_checker()\n        self.store = hs.get_datastore()\n        self._clock = hs.get_clock()\n\n    @defer.inlineCallbacks\n    def _check_sigs_and_hash_and_fetch(self, origin, pdus, outlier=False,\n                                       include_none=False):\n        \"\"\"Takes a list of PDUs and checks the signatures and hashs of each\n        one. If a PDU fails its signature check then we check if we have it in\n        the database and if not then request if from the originating server of\n        that PDU.\n\n        If a PDU fails its content hash check then it is redacted.\n\n        The given list of PDUs are not modified, instead the function returns\n        a new list.\n\n        Args:\n            pdu (list)\n            outlier (bool)\n\n        Returns:\n            Deferred : A list of PDUs that have valid signatures and hashes.\n        \"\"\"\n        deferreds = self._check_sigs_and_hashes(pdus)\n\n        @defer.inlineCallbacks\n        def handle_check_result(pdu, deferred):\n            try:\n                res = yield logcontext.make_deferred_yieldable(deferred)\n            except SynapseError:\n                res = None\n\n            if not res:\n                # Check local db.\n                res = yield self.store.get_event(\n                    pdu.event_id,\n                    allow_rejected=True,\n                    allow_none=True,\n                )\n\n            if not res and pdu.origin != origin:\n                try:\n                    res = yield self.get_pdu(\n                        destinations=[pdu.origin],\n                        event_id=pdu.event_id,\n                        outlier=outlier,\n                        timeout=10000,\n                    )\n                except SynapseError:\n                    pass\n\n            if not res:\n                logger.warn(\n                    \"Failed to find copy of %s with valid signature\",\n                    pdu.event_id,\n                )\n\n            defer.returnValue(res)\n\n        handle = logcontext.preserve_fn(handle_check_result)\n        deferreds2 = [\n            handle(pdu, deferred)\n            for pdu, deferred in zip(pdus, deferreds)\n        ]\n\n        valid_pdus = yield logcontext.make_deferred_yieldable(\n            defer.gatherResults(\n                deferreds2,\n                consumeErrors=True,\n            )\n        ).addErrback(unwrapFirstError)\n\n        if include_none:\n            defer.returnValue(valid_pdus)\n        else:\n            defer.returnValue([p for p in valid_pdus if p])\n\n    def _check_sigs_and_hash(self, pdu):\n        return logcontext.make_deferred_yieldable(\n            self._check_sigs_and_hashes([pdu])[0],\n        )\n\n    def _check_sigs_and_hashes(self, pdus):\n        \"\"\"Checks that each of the received events is correctly signed by the\n        sending server.\n\n        Args:\n            pdus (list[FrozenEvent]): the events to be checked\n\n        Returns:\n            list[Deferred]: for each input event, a deferred which:\n              * returns the original event if the checks pass\n              * returns a redacted version of the event (if the signature\n                matched but the hash did not)\n              * throws a SynapseError if the signature check failed.\n            The deferreds run their callbacks in the sentinel logcontext.\n        \"\"\"\n\n        redacted_pdus = [\n            prune_event(pdu)\n            for pdu in pdus\n        ]\n\n        deferreds = self.keyring.verify_json_objects_for_server([\n            (p.origin, p.get_pdu_json())\n            for p in redacted_pdus\n        ])\n\n        ctx = logcontext.LoggingContext.current_context()\n\n        def callback(_, pdu, redacted):\n            with logcontext.PreserveLoggingContext(ctx):\n                if not check_event_content_hash(pdu):\n                    logger.warn(\n                        \"Event content has been tampered, redacting %s: %s\",\n                        pdu.event_id, pdu.get_pdu_json()\n                    )\n                    return redacted\n\n                if self.spam_checker.check_event_for_spam(pdu):\n                    logger.warn(\n                        \"Event contains spam, redacting %s: %s\",\n                        pdu.event_id, pdu.get_pdu_json()\n                    )\n                    return redacted\n\n                return pdu\n\n        def errback(failure, pdu):\n            failure.trap(SynapseError)\n            with logcontext.PreserveLoggingContext(ctx):\n                logger.warn(\n                    \"Signature check failed for %s\",\n                    pdu.event_id,\n                )\n            return failure\n\n        for deferred, pdu, redacted in zip(deferreds, pdus, redacted_pdus):\n            deferred.addCallbacks(\n                callback, errback,\n                callbackArgs=[pdu, redacted],\n                errbackArgs=[pdu],\n            )\n\n        return deferreds\n\n\ndef event_from_pdu_json(pdu_json, outlier=False):\n    \"\"\"Construct a FrozenEvent from an event json received over federation\n\n    Args:\n        pdu_json (object): pdu as received over federation\n        outlier (bool): True to mark this event as an outlier\n\n    Returns:\n        FrozenEvent\n\n    Raises:\n        SynapseError: if the pdu is missing required fields or is otherwise\n            not a valid matrix event\n    \"\"\"\n    # we could probably enforce a bunch of other fields here (room_id, sender,\n    # origin, etc etc)\n    assert_params_in_request(pdu_json, ('event_id', 'type', 'depth'))\n\n    depth = pdu_json['depth']\n    if not isinstance(depth, six.integer_types):\n        raise SynapseError(400, \"Depth %r not an intger\" % (depth, ),\n                           Codes.BAD_JSON)\n\n    if depth < 0:\n        raise SynapseError(400, \"Depth too small\", Codes.BAD_JSON)\n    elif depth > MAX_DEPTH:\n        raise SynapseError(400, \"Depth too large\", Codes.BAD_JSON)\n\n    event = FrozenEvent(\n        pdu_json\n    )\n\n    event.internal_metadata.outlier = outlier\n\n    return event\n", "# -*- coding: utf-8 -*-\n# Copyright 2014 - 2016 OpenMarket Ltd\n# Copyright 2017 - 2018 New Vector Ltd\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nfrom twisted.internet import defer, reactor\nfrom twisted.python.failure import Failure\n\nfrom synapse.api.constants import EventTypes, Membership, MAX_DEPTH\nfrom synapse.api.errors import AuthError, Codes, SynapseError\nfrom synapse.crypto.event_signing import add_hashes_and_signatures\nfrom synapse.events.utils import serialize_event\nfrom synapse.events.validator import EventValidator\nfrom synapse.types import (\n    UserID, RoomAlias, RoomStreamToken,\n)\nfrom synapse.util.async import run_on_reactor, ReadWriteLock, Limiter\nfrom synapse.util.logcontext import preserve_fn, run_in_background\nfrom synapse.util.metrics import measure_func\nfrom synapse.util.frozenutils import frozendict_json_encoder\nfrom synapse.util.stringutils import random_string\nfrom synapse.visibility import filter_events_for_client\nfrom synapse.replication.http.send_event import send_event_to_master\n\nfrom ._base import BaseHandler\n\nfrom canonicaljson import encode_canonical_json\n\nimport logging\nimport simplejson\n\nlogger = logging.getLogger(__name__)\n\n\nclass PurgeStatus(object):\n    \"\"\"Object tracking the status of a purge request\n\n    This class contains information on the progress of a purge request, for\n    return by get_purge_status.\n\n    Attributes:\n        status (int): Tracks whether this request has completed. One of\n            STATUS_{ACTIVE,COMPLETE,FAILED}\n    \"\"\"\n\n    STATUS_ACTIVE = 0\n    STATUS_COMPLETE = 1\n    STATUS_FAILED = 2\n\n    STATUS_TEXT = {\n        STATUS_ACTIVE: \"active\",\n        STATUS_COMPLETE: \"complete\",\n        STATUS_FAILED: \"failed\",\n    }\n\n    def __init__(self):\n        self.status = PurgeStatus.STATUS_ACTIVE\n\n    def asdict(self):\n        return {\n            \"status\": PurgeStatus.STATUS_TEXT[self.status]\n        }\n\n\nclass MessageHandler(BaseHandler):\n\n    def __init__(self, hs):\n        super(MessageHandler, self).__init__(hs)\n        self.hs = hs\n        self.state = hs.get_state_handler()\n        self.clock = hs.get_clock()\n\n        self.pagination_lock = ReadWriteLock()\n        self._purges_in_progress_by_room = set()\n        # map from purge id to PurgeStatus\n        self._purges_by_id = {}\n\n    def start_purge_history(self, room_id, topological_ordering,\n                            delete_local_events=False):\n        \"\"\"Start off a history purge on a room.\n\n        Args:\n            room_id (str): The room to purge from\n\n            topological_ordering (int): minimum topo ordering to preserve\n            delete_local_events (bool): True to delete local events as well as\n                remote ones\n\n        Returns:\n            str: unique ID for this purge transaction.\n        \"\"\"\n        if room_id in self._purges_in_progress_by_room:\n            raise SynapseError(\n                400,\n                \"History purge already in progress for %s\" % (room_id, ),\n            )\n\n        purge_id = random_string(16)\n\n        # we log the purge_id here so that it can be tied back to the\n        # request id in the log lines.\n        logger.info(\"[purge] starting purge_id %s\", purge_id)\n\n        self._purges_by_id[purge_id] = PurgeStatus()\n        run_in_background(\n            self._purge_history,\n            purge_id, room_id, topological_ordering, delete_local_events,\n        )\n        return purge_id\n\n    @defer.inlineCallbacks\n    def _purge_history(self, purge_id, room_id, topological_ordering,\n                       delete_local_events):\n        \"\"\"Carry out a history purge on a room.\n\n        Args:\n            purge_id (str): The id for this purge\n            room_id (str): The room to purge from\n            topological_ordering (int): minimum topo ordering to preserve\n            delete_local_events (bool): True to delete local events as well as\n                remote ones\n\n        Returns:\n            Deferred\n        \"\"\"\n        self._purges_in_progress_by_room.add(room_id)\n        try:\n            with (yield self.pagination_lock.write(room_id)):\n                yield self.store.purge_history(\n                    room_id, topological_ordering, delete_local_events,\n                )\n            logger.info(\"[purge] complete\")\n            self._purges_by_id[purge_id].status = PurgeStatus.STATUS_COMPLETE\n        except Exception:\n            logger.error(\"[purge] failed: %s\", Failure().getTraceback().rstrip())\n            self._purges_by_id[purge_id].status = PurgeStatus.STATUS_FAILED\n        finally:\n            self._purges_in_progress_by_room.discard(room_id)\n\n            # remove the purge from the list 24 hours after it completes\n            def clear_purge():\n                del self._purges_by_id[purge_id]\n            reactor.callLater(24 * 3600, clear_purge)\n\n    def get_purge_status(self, purge_id):\n        \"\"\"Get the current status of an active purge\n\n        Args:\n            purge_id (str): purge_id returned by start_purge_history\n\n        Returns:\n            PurgeStatus|None\n        \"\"\"\n        return self._purges_by_id.get(purge_id)\n\n    @defer.inlineCallbacks\n    def get_messages(self, requester, room_id=None, pagin_config=None,\n                     as_client_event=True, event_filter=None):\n        \"\"\"Get messages in a room.\n\n        Args:\n            requester (Requester): The user requesting messages.\n            room_id (str): The room they want messages from.\n            pagin_config (synapse.api.streams.PaginationConfig): The pagination\n                config rules to apply, if any.\n            as_client_event (bool): True to get events in client-server format.\n            event_filter (Filter): Filter to apply to results or None\n        Returns:\n            dict: Pagination API results\n        \"\"\"\n        user_id = requester.user.to_string()\n\n        if pagin_config.from_token:\n            room_token = pagin_config.from_token.room_key\n        else:\n            pagin_config.from_token = (\n                yield self.hs.get_event_sources().get_current_token_for_room(\n                    room_id=room_id\n                )\n            )\n            room_token = pagin_config.from_token.room_key\n\n        room_token = RoomStreamToken.parse(room_token)\n\n        pagin_config.from_token = pagin_config.from_token.copy_and_replace(\n            \"room_key\", str(room_token)\n        )\n\n        source_config = pagin_config.get_source_config(\"room\")\n\n        with (yield self.pagination_lock.read(room_id)):\n            membership, member_event_id = yield self._check_in_room_or_world_readable(\n                room_id, user_id\n            )\n\n            if source_config.direction == 'b':\n                # if we're going backwards, we might need to backfill. This\n                # requires that we have a topo token.\n                if room_token.topological:\n                    max_topo = room_token.topological\n                else:\n                    max_topo = yield self.store.get_max_topological_token(\n                        room_id, room_token.stream\n                    )\n\n                if membership == Membership.LEAVE:\n                    # If they have left the room then clamp the token to be before\n                    # they left the room, to save the effort of loading from the\n                    # database.\n                    leave_token = yield self.store.get_topological_token_for_event(\n                        member_event_id\n                    )\n                    leave_token = RoomStreamToken.parse(leave_token)\n                    if leave_token.topological < max_topo:\n                        source_config.from_key = str(leave_token)\n\n                yield self.hs.get_handlers().federation_handler.maybe_backfill(\n                    room_id, max_topo\n                )\n\n            events, next_key = yield self.store.paginate_room_events(\n                room_id=room_id,\n                from_key=source_config.from_key,\n                to_key=source_config.to_key,\n                direction=source_config.direction,\n                limit=source_config.limit,\n                event_filter=event_filter,\n            )\n\n            next_token = pagin_config.from_token.copy_and_replace(\n                \"room_key\", next_key\n            )\n\n        if not events:\n            defer.returnValue({\n                \"chunk\": [],\n                \"start\": pagin_config.from_token.to_string(),\n                \"end\": next_token.to_string(),\n            })\n\n        if event_filter:\n            events = event_filter.filter(events)\n\n        events = yield filter_events_for_client(\n            self.store,\n            user_id,\n            events,\n            is_peeking=(member_event_id is None),\n        )\n\n        time_now = self.clock.time_msec()\n\n        chunk = {\n            \"chunk\": [\n                serialize_event(e, time_now, as_client_event)\n                for e in events\n            ],\n            \"start\": pagin_config.from_token.to_string(),\n            \"end\": next_token.to_string(),\n        }\n\n        defer.returnValue(chunk)\n\n    @defer.inlineCallbacks\n    def get_room_data(self, user_id=None, room_id=None,\n                      event_type=None, state_key=\"\", is_guest=False):\n        \"\"\" Get data from a room.\n\n        Args:\n            event : The room path event\n        Returns:\n            The path data content.\n        Raises:\n            SynapseError if something went wrong.\n        \"\"\"\n        membership, membership_event_id = yield self._check_in_room_or_world_readable(\n            room_id, user_id\n        )\n\n        if membership == Membership.JOIN:\n            data = yield self.state_handler.get_current_state(\n                room_id, event_type, state_key\n            )\n        elif membership == Membership.LEAVE:\n            key = (event_type, state_key)\n            room_state = yield self.store.get_state_for_events(\n                [membership_event_id], [key]\n            )\n            data = room_state[membership_event_id].get(key)\n\n        defer.returnValue(data)\n\n    @defer.inlineCallbacks\n    def _check_in_room_or_world_readable(self, room_id, user_id):\n        try:\n            # check_user_was_in_room will return the most recent membership\n            # event for the user if:\n            #  * The user is a non-guest user, and was ever in the room\n            #  * The user is a guest user, and has joined the room\n            # else it will throw.\n            member_event = yield self.auth.check_user_was_in_room(room_id, user_id)\n            defer.returnValue((member_event.membership, member_event.event_id))\n            return\n        except AuthError:\n            visibility = yield self.state_handler.get_current_state(\n                room_id, EventTypes.RoomHistoryVisibility, \"\"\n            )\n            if (\n                visibility and\n                visibility.content[\"history_visibility\"] == \"world_readable\"\n            ):\n                defer.returnValue((Membership.JOIN, None))\n                return\n            raise AuthError(\n                403, \"Guest access not allowed\", errcode=Codes.GUEST_ACCESS_FORBIDDEN\n            )\n\n    @defer.inlineCallbacks\n    def get_state_events(self, user_id, room_id, is_guest=False):\n        \"\"\"Retrieve all state events for a given room. If the user is\n        joined to the room then return the current state. If the user has\n        left the room return the state events from when they left.\n\n        Args:\n            user_id(str): The user requesting state events.\n            room_id(str): The room ID to get all state events from.\n        Returns:\n            A list of dicts representing state events. [{}, {}, {}]\n        \"\"\"\n        membership, membership_event_id = yield self._check_in_room_or_world_readable(\n            room_id, user_id\n        )\n\n        if membership == Membership.JOIN:\n            room_state = yield self.state_handler.get_current_state(room_id)\n        elif membership == Membership.LEAVE:\n            room_state = yield self.store.get_state_for_events(\n                [membership_event_id], None\n            )\n            room_state = room_state[membership_event_id]\n\n        now = self.clock.time_msec()\n        defer.returnValue(\n            [serialize_event(c, now) for c in room_state.values()]\n        )\n\n    @defer.inlineCallbacks\n    def get_joined_members(self, requester, room_id):\n        \"\"\"Get all the joined members in the room and their profile information.\n\n        If the user has left the room return the state events from when they left.\n\n        Args:\n            requester(Requester): The user requesting state events.\n            room_id(str): The room ID to get all state events from.\n        Returns:\n            A dict of user_id to profile info\n        \"\"\"\n        user_id = requester.user.to_string()\n        if not requester.app_service:\n            # We check AS auth after fetching the room membership, as it\n            # requires us to pull out all joined members anyway.\n            membership, _ = yield self._check_in_room_or_world_readable(\n                room_id, user_id\n            )\n            if membership != Membership.JOIN:\n                raise NotImplementedError(\n                    \"Getting joined members after leaving is not implemented\"\n                )\n\n        users_with_profile = yield self.state.get_current_user_in_room(room_id)\n\n        # If this is an AS, double check that they are allowed to see the members.\n        # This can either be because the AS user is in the room or becuase there\n        # is a user in the room that the AS is \"interested in\"\n        if requester.app_service and user_id not in users_with_profile:\n            for uid in users_with_profile:\n                if requester.app_service.is_interested_in_user(uid):\n                    break\n            else:\n                # Loop fell through, AS has no interested users in room\n                raise AuthError(403, \"Appservice not in room\")\n\n        defer.returnValue({\n            user_id: {\n                \"avatar_url\": profile.avatar_url,\n                \"display_name\": profile.display_name,\n            }\n            for user_id, profile in users_with_profile.iteritems()\n        })\n\n\nclass EventCreationHandler(object):\n    def __init__(self, hs):\n        self.hs = hs\n        self.auth = hs.get_auth()\n        self.store = hs.get_datastore()\n        self.state = hs.get_state_handler()\n        self.clock = hs.get_clock()\n        self.validator = EventValidator()\n        self.profile_handler = hs.get_profile_handler()\n        self.event_builder_factory = hs.get_event_builder_factory()\n        self.server_name = hs.hostname\n        self.ratelimiter = hs.get_ratelimiter()\n        self.notifier = hs.get_notifier()\n        self.config = hs.config\n\n        self.http_client = hs.get_simple_http_client()\n\n        # This is only used to get at ratelimit function, and maybe_kick_guest_users\n        self.base_handler = BaseHandler(hs)\n\n        self.pusher_pool = hs.get_pusherpool()\n\n        # We arbitrarily limit concurrent event creation for a room to 5.\n        # This is to stop us from diverging history *too* much.\n        self.limiter = Limiter(max_count=5)\n\n        self.action_generator = hs.get_action_generator()\n\n        self.spam_checker = hs.get_spam_checker()\n\n    @defer.inlineCallbacks\n    def create_event(self, requester, event_dict, token_id=None, txn_id=None,\n                     prev_events_and_hashes=None):\n        \"\"\"\n        Given a dict from a client, create a new event.\n\n        Creates an FrozenEvent object, filling out auth_events, prev_events,\n        etc.\n\n        Adds display names to Join membership events.\n\n        Args:\n            requester\n            event_dict (dict): An entire event\n            token_id (str)\n            txn_id (str)\n\n            prev_events_and_hashes (list[(str, dict[str, str], int)]|None):\n                the forward extremities to use as the prev_events for the\n                new event. For each event, a tuple of (event_id, hashes, depth)\n                where *hashes* is a map from algorithm to hash.\n\n                If None, they will be requested from the database.\n\n        Returns:\n            Tuple of created event (FrozenEvent), Context\n        \"\"\"\n        builder = self.event_builder_factory.new(event_dict)\n\n        self.validator.validate_new(builder)\n\n        if builder.type == EventTypes.Member:\n            membership = builder.content.get(\"membership\", None)\n            target = UserID.from_string(builder.state_key)\n\n            if membership in {Membership.JOIN, Membership.INVITE}:\n                # If event doesn't include a display name, add one.\n                profile = self.profile_handler\n                content = builder.content\n\n                try:\n                    if \"displayname\" not in content:\n                        content[\"displayname\"] = yield profile.get_displayname(target)\n                    if \"avatar_url\" not in content:\n                        content[\"avatar_url\"] = yield profile.get_avatar_url(target)\n                except Exception as e:\n                    logger.info(\n                        \"Failed to get profile information for %r: %s\",\n                        target, e\n                    )\n\n        if token_id is not None:\n            builder.internal_metadata.token_id = token_id\n\n        if txn_id is not None:\n            builder.internal_metadata.txn_id = txn_id\n\n        event, context = yield self.create_new_client_event(\n            builder=builder,\n            requester=requester,\n            prev_events_and_hashes=prev_events_and_hashes,\n        )\n\n        defer.returnValue((event, context))\n\n    @defer.inlineCallbacks\n    def send_nonmember_event(self, requester, event, context, ratelimit=True):\n        \"\"\"\n        Persists and notifies local clients and federation of an event.\n\n        Args:\n            event (FrozenEvent) the event to send.\n            context (Context) the context of the event.\n            ratelimit (bool): Whether to rate limit this send.\n            is_guest (bool): Whether the sender is a guest.\n        \"\"\"\n        if event.type == EventTypes.Member:\n            raise SynapseError(\n                500,\n                \"Tried to send member event through non-member codepath\"\n            )\n\n        user = UserID.from_string(event.sender)\n\n        assert self.hs.is_mine(user), \"User must be our own: %s\" % (user,)\n\n        if event.is_state():\n            prev_state = yield self.deduplicate_state_event(event, context)\n            if prev_state is not None:\n                defer.returnValue(prev_state)\n\n        yield self.handle_new_client_event(\n            requester=requester,\n            event=event,\n            context=context,\n            ratelimit=ratelimit,\n        )\n\n    @defer.inlineCallbacks\n    def deduplicate_state_event(self, event, context):\n        \"\"\"\n        Checks whether event is in the latest resolved state in context.\n\n        If so, returns the version of the event in context.\n        Otherwise, returns None.\n        \"\"\"\n        prev_event_id = context.prev_state_ids.get((event.type, event.state_key))\n        prev_event = yield self.store.get_event(prev_event_id, allow_none=True)\n        if not prev_event:\n            return\n\n        if prev_event and event.user_id == prev_event.user_id:\n            prev_content = encode_canonical_json(prev_event.content)\n            next_content = encode_canonical_json(event.content)\n            if prev_content == next_content:\n                defer.returnValue(prev_event)\n        return\n\n    @defer.inlineCallbacks\n    def create_and_send_nonmember_event(\n        self,\n        requester,\n        event_dict,\n        ratelimit=True,\n        txn_id=None\n    ):\n        \"\"\"\n        Creates an event, then sends it.\n\n        See self.create_event and self.send_nonmember_event.\n        \"\"\"\n\n        # We limit the number of concurrent event sends in a room so that we\n        # don't fork the DAG too much. If we don't limit then we can end up in\n        # a situation where event persistence can't keep up, causing\n        # extremities to pile up, which in turn leads to state resolution\n        # taking longer.\n        with (yield self.limiter.queue(event_dict[\"room_id\"])):\n            event, context = yield self.create_event(\n                requester,\n                event_dict,\n                token_id=requester.access_token_id,\n                txn_id=txn_id\n            )\n\n            spam_error = self.spam_checker.check_event_for_spam(event)\n            if spam_error:\n                if not isinstance(spam_error, basestring):\n                    spam_error = \"Spam is not permitted here\"\n                raise SynapseError(\n                    403, spam_error, Codes.FORBIDDEN\n                )\n\n            yield self.send_nonmember_event(\n                requester,\n                event,\n                context,\n                ratelimit=ratelimit,\n            )\n        defer.returnValue(event)\n\n    @measure_func(\"create_new_client_event\")\n    @defer.inlineCallbacks\n    def create_new_client_event(self, builder, requester=None,\n                                prev_events_and_hashes=None):\n        \"\"\"Create a new event for a local client\n\n        Args:\n            builder (EventBuilder):\n\n            requester (synapse.types.Requester|None):\n\n            prev_events_and_hashes (list[(str, dict[str, str], int)]|None):\n                the forward extremities to use as the prev_events for the\n                new event. For each event, a tuple of (event_id, hashes, depth)\n                where *hashes* is a map from algorithm to hash.\n\n                If None, they will be requested from the database.\n\n        Returns:\n            Deferred[(synapse.events.EventBase, synapse.events.snapshot.EventContext)]\n        \"\"\"\n\n        if prev_events_and_hashes is not None:\n            assert len(prev_events_and_hashes) <= 10, \\\n                \"Attempting to create an event with %i prev_events\" % (\n                    len(prev_events_and_hashes),\n            )\n        else:\n            prev_events_and_hashes = \\\n                yield self.store.get_prev_events_for_room(builder.room_id)\n\n        if prev_events_and_hashes:\n            depth = max([d for _, _, d in prev_events_and_hashes]) + 1\n            # we cap depth of generated events, to ensure that they are not\n            # rejected by other servers (and so that they can be persisted in\n            # the db)\n            depth = min(depth, MAX_DEPTH)\n        else:\n            depth = 1\n\n        prev_events = [\n            (event_id, prev_hashes)\n            for event_id, prev_hashes, _ in prev_events_and_hashes\n        ]\n\n        builder.prev_events = prev_events\n        builder.depth = depth\n\n        context = yield self.state.compute_event_context(builder)\n        if requester:\n            context.app_service = requester.app_service\n\n        if builder.is_state():\n            builder.prev_state = yield self.store.add_event_hashes(\n                context.prev_state_events\n            )\n\n        yield self.auth.add_auth_events(builder, context)\n\n        signing_key = self.hs.config.signing_key[0]\n        add_hashes_and_signatures(\n            builder, self.server_name, signing_key\n        )\n\n        event = builder.build()\n\n        logger.debug(\n            \"Created event %s with state: %s\",\n            event.event_id, context.prev_state_ids,\n        )\n\n        defer.returnValue(\n            (event, context,)\n        )\n\n    @measure_func(\"handle_new_client_event\")\n    @defer.inlineCallbacks\n    def handle_new_client_event(\n        self,\n        requester,\n        event,\n        context,\n        ratelimit=True,\n        extra_users=[],\n    ):\n        \"\"\"Processes a new event. This includes checking auth, persisting it,\n        notifying users, sending to remote servers, etc.\n\n        If called from a worker will hit out to the master process for final\n        processing.\n\n        Args:\n            requester (Requester)\n            event (FrozenEvent)\n            context (EventContext)\n            ratelimit (bool)\n            extra_users (list(UserID)): Any extra users to notify about event\n        \"\"\"\n\n        try:\n            yield self.auth.check_from_context(event, context)\n        except AuthError as err:\n            logger.warn(\"Denying new event %r because %s\", event, err)\n            raise err\n\n        # Ensure that we can round trip before trying to persist in db\n        try:\n            dump = frozendict_json_encoder.encode(event.content)\n            simplejson.loads(dump)\n        except Exception:\n            logger.exception(\"Failed to encode content: %r\", event.content)\n            raise\n\n        yield self.action_generator.handle_push_actions_for_event(\n            event, context\n        )\n\n        try:\n            # If we're a worker we need to hit out to the master.\n            if self.config.worker_app:\n                yield send_event_to_master(\n                    self.http_client,\n                    host=self.config.worker_replication_host,\n                    port=self.config.worker_replication_http_port,\n                    requester=requester,\n                    event=event,\n                    context=context,\n                    ratelimit=ratelimit,\n                    extra_users=extra_users,\n                )\n                return\n\n            yield self.persist_and_notify_client_event(\n                requester,\n                event,\n                context,\n                ratelimit=ratelimit,\n                extra_users=extra_users,\n            )\n        except:  # noqa: E722, as we reraise the exception this is fine.\n            # Ensure that we actually remove the entries in the push actions\n            # staging area, if we calculated them.\n            preserve_fn(self.store.remove_push_actions_from_staging)(event.event_id)\n            raise\n\n    @defer.inlineCallbacks\n    def persist_and_notify_client_event(\n        self,\n        requester,\n        event,\n        context,\n        ratelimit=True,\n        extra_users=[],\n    ):\n        \"\"\"Called when we have fully built the event, have already\n        calculated the push actions for the event, and checked auth.\n\n        This should only be run on master.\n        \"\"\"\n        assert not self.config.worker_app\n\n        if ratelimit:\n            yield self.base_handler.ratelimit(requester)\n\n        yield self.base_handler.maybe_kick_guest_users(event, context)\n\n        if event.type == EventTypes.CanonicalAlias:\n            # Check the alias is acually valid (at this time at least)\n            room_alias_str = event.content.get(\"alias\", None)\n            if room_alias_str:\n                room_alias = RoomAlias.from_string(room_alias_str)\n                directory_handler = self.hs.get_handlers().directory_handler\n                mapping = yield directory_handler.get_association(room_alias)\n\n                if mapping[\"room_id\"] != event.room_id:\n                    raise SynapseError(\n                        400,\n                        \"Room alias %s does not point to the room\" % (\n                            room_alias_str,\n                        )\n                    )\n\n        federation_handler = self.hs.get_handlers().federation_handler\n\n        if event.type == EventTypes.Member:\n            if event.content[\"membership\"] == Membership.INVITE:\n                def is_inviter_member_event(e):\n                    return (\n                        e.type == EventTypes.Member and\n                        e.sender == event.sender\n                    )\n\n                state_to_include_ids = [\n                    e_id\n                    for k, e_id in context.current_state_ids.iteritems()\n                    if k[0] in self.hs.config.room_invite_state_types\n                    or k == (EventTypes.Member, event.sender)\n                ]\n\n                state_to_include = yield self.store.get_events(state_to_include_ids)\n\n                event.unsigned[\"invite_room_state\"] = [\n                    {\n                        \"type\": e.type,\n                        \"state_key\": e.state_key,\n                        \"content\": e.content,\n                        \"sender\": e.sender,\n                    }\n                    for e in state_to_include.itervalues()\n                ]\n\n                invitee = UserID.from_string(event.state_key)\n                if not self.hs.is_mine(invitee):\n                    # TODO: Can we add signature from remote server in a nicer\n                    # way? If we have been invited by a remote server, we need\n                    # to get them to sign the event.\n\n                    returned_invite = yield federation_handler.send_invite(\n                        invitee.domain,\n                        event,\n                    )\n\n                    event.unsigned.pop(\"room_state\", None)\n\n                    # TODO: Make sure the signatures actually are correct.\n                    event.signatures.update(\n                        returned_invite.signatures\n                    )\n\n        if event.type == EventTypes.Redaction:\n            auth_events_ids = yield self.auth.compute_auth_events(\n                event, context.prev_state_ids, for_verification=True,\n            )\n            auth_events = yield self.store.get_events(auth_events_ids)\n            auth_events = {\n                (e.type, e.state_key): e for e in auth_events.values()\n            }\n            if self.auth.check_redaction(event, auth_events=auth_events):\n                original_event = yield self.store.get_event(\n                    event.redacts,\n                    check_redacted=False,\n                    get_prev_content=False,\n                    allow_rejected=False,\n                    allow_none=False\n                )\n                if event.user_id != original_event.user_id:\n                    raise AuthError(\n                        403,\n                        \"You don't have permission to redact events\"\n                    )\n\n        if event.type == EventTypes.Create and context.prev_state_ids:\n            raise AuthError(\n                403,\n                \"Changing the room create event is forbidden\",\n            )\n\n        (event_stream_id, max_stream_id) = yield self.store.persist_event(\n            event, context=context\n        )\n\n        # this intentionally does not yield: we don't care about the result\n        # and don't need to wait for it.\n        preserve_fn(self.pusher_pool.on_new_notifications)(\n            event_stream_id, max_stream_id\n        )\n\n        @defer.inlineCallbacks\n        def _notify():\n            yield run_on_reactor()\n            self.notifier.on_new_room_event(\n                event, event_stream_id, max_stream_id,\n                extra_users=extra_users\n            )\n\n        preserve_fn(_notify)()\n\n        if event.type == EventTypes.Message:\n            presence = self.hs.get_presence_handler()\n            # We don't want to block sending messages on any presence code. This\n            # matters as sometimes presence code can take a while.\n            preserve_fn(presence.bump_presence_active_time)(requester.user)\n"], "filenames": ["synapse/api/constants.py", "synapse/federation/federation_base.py", "synapse/handlers/message.py"], "buggy_code_start_loc": [17, 17, 19], "buggy_code_end_loc": [17, 198, 626], "fixing_code_start_loc": [18, 17, 19], "fixing_code_end_loc": [21, 213, 631], "type": "CWE-20", "message": "Matrix Synapse before 0.28.1 is prone to a denial of service flaw where malicious events injected with depth = 2^63 - 1 render rooms unusable, related to federation/federation_base.py and handlers/message.py, as exploited in the wild in April 2018.", "other": {"cve": {"id": "CVE-2018-10657", "sourceIdentifier": "cve@mitre.org", "published": "2018-05-02T16:29:00.233", "lastModified": "2018-06-07T15:49:26.590", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "Matrix Synapse before 0.28.1 is prone to a denial of service flaw where malicious events injected with depth = 2^63 - 1 render rooms unusable, related to federation/federation_base.py and handlers/message.py, as exploited in the wild in April 2018."}, {"lang": "es", "value": "Matrix Synapse en versiones anteriores a la 0.28.1 es propenso a un error de denegaci\u00f3n de servicio (DoS) en el que los eventos maliciosos inyectados con una profundidad de = 2^63 - 1 hacen que las habitaciones no puedan usarse. Esto est\u00e1 relacionado con federation/federation_base.py y handlers/message.py, tal y como se explotaron \"in the wild\" en abril de 2018."}], "metrics": {"cvssMetricV30": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.0", "vectorString": "CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 7.5, "baseSeverity": "HIGH"}, "exploitabilityScore": 3.9, "impactScore": 3.6}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:N/AC:L/Au:N/C:N/I:N/A:P", "accessVector": "NETWORK", "accessComplexity": "LOW", "authentication": "NONE", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "PARTIAL", "baseScore": 5.0}, "baseSeverity": "MEDIUM", "exploitabilityScore": 10.0, "impactScore": 2.9, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-20"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:matrix:synapse:*:*:*:*:*:*:*:*", "versionEndExcluding": "0.28.1", "matchCriteriaId": "187C1F04-C28B-487A-99F0-781C47519B75"}]}]}], "references": [{"url": "https://github.com/matrix-org/synapse/commit/33f469ba19586bbafa0cf2c7d7c35463bdab87eb", "source": "cve@mitre.org", "tags": ["Patch"]}, {"url": "https://matrix.org/blog/2018/05/01/security-update-synapse-0-28-1/", "source": "cve@mitre.org", "tags": ["Vendor Advisory"]}]}, "github_commit_url": "https://github.com/matrix-org/synapse/commit/33f469ba19586bbafa0cf2c7d7c35463bdab87eb"}}
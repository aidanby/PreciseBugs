{"buggy_code": ["// Copyright 2019 The CubeFS Authors.\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n// implied. See the License for the specific language governing\n// permissions and limitations under the License.\n\npackage objectnode\n\nimport (\n\t\"crypto/md5\"\n\t\"encoding/hex\"\n\t\"encoding/json\"\n\t\"encoding/xml\"\n\t\"io\"\n\t\"io/ioutil\"\n\t\"net/http\"\n\t\"regexp\"\n\t\"strconv\"\n\t\"strings\"\n\n\t\"github.com/cubefs/cubefs/proto\"\n\t\"github.com/cubefs/cubefs/util/log\"\n)\n\nconst (\n\tDefaultMinBucketLength = 3\n\tDefaultMaxBucketLength = 63\n)\n\nvar regexBucketName = regexp.MustCompile(`^[0-9a-z][-0-9a-z]+[0-9a-z]$`)\n\n// Head bucket\n// API reference: https://docs.aws.amazon.com/AmazonS3/latest/API/API_HeadBucket.html\nfunc (o *ObjectNode) headBucketHandler(w http.ResponseWriter, r *http.Request) {\n\tw.Header().Set(XAmzBucketRegion, o.region)\n}\n\n// Create bucket\n// API reference: https://docs.aws.amazon.com/AmazonS3/latest/API/API_CreateBucket.html\nfunc (o *ObjectNode) createBucketHandler(w http.ResponseWriter, r *http.Request) {\n\tvar (\n\t\terr       error\n\t\terrorCode *ErrorCode\n\t)\n\tdefer func() {\n\t\to.errorResponse(w, r, err, errorCode)\n\t}()\n\n\tparam := ParseRequestParam(r)\n\tbucket := param.Bucket()\n\tif bucket == \"\" {\n\t\terrorCode = InvalidBucketName\n\t\treturn\n\t}\n\n\tif !IsValidBucketName(bucket, DefaultMinBucketLength, DefaultMaxBucketLength) {\n\t\terrorCode = InvalidBucketName\n\t\treturn\n\t}\n\n\tif vol, _ := o.vm.VolumeWithoutBlacklist(bucket); vol != nil {\n\t\tlog.LogInfof(\"createBucketHandler: duplicated bucket name: requestID(%v) bucket(%v)\", GetRequestID(r), bucket)\n\t\terrorCode = BucketAlreadyOwnedByYou\n\t\treturn\n\t}\n\n\tvar userInfo *proto.UserInfo\n\tif userInfo, err = o.getUserInfoByAccessKeyV2(param.AccessKey()); err != nil {\n\t\tlog.LogErrorf(\"createBucketHandler: get user info from master fail: requestID(%v) accessKey(%v) err(%v)\",\n\t\t\tGetRequestID(r), param.AccessKey(), err)\n\t\treturn\n\t}\n\n\t// QPS and Concurrency Limit\n\trateLimit := o.AcquireRateLimiter()\n\tif err = rateLimit.AcquireLimitResource(userInfo.UserID, param.apiName); err != nil {\n\t\treturn\n\t}\n\tdefer rateLimit.ReleaseLimitResource(userInfo.UserID, param.apiName)\n\n\t// get LocationConstraint if any\n\tcontentLenStr := r.Header.Get(ContentLength)\n\tif contentLen, errConv := strconv.Atoi(contentLenStr); errConv == nil && contentLen > 0 {\n\t\tvar requestBytes []byte\n\t\trequestBytes, err = ioutil.ReadAll(r.Body)\n\t\tif err != nil && err != io.EOF {\n\t\t\tlog.LogErrorf(\"createBucketHandler: read request body fail: requestID(%v) err(%v)\", GetRequestID(r), err)\n\t\t\treturn\n\t\t}\n\n\t\tcreateBucketRequest := &CreateBucketRequest{}\n\t\terr = UnmarshalXMLEntity(requestBytes, createBucketRequest)\n\t\tif err != nil {\n\t\t\tlog.LogErrorf(\"createBucketHandler: unmarshal xml fail: requestID(%v) err(%v)\",\n\t\t\t\tGetRequestID(r), err)\n\t\t\terrorCode = InvalidArgument\n\t\t\treturn\n\t\t}\n\t\tif createBucketRequest.LocationConstraint != o.region {\n\t\t\tlog.LogErrorf(\"createBucketHandler: location constraint not match the service: requestID(%v) LocationConstraint(%v) region(%v)\",\n\t\t\t\tGetRequestID(r), createBucketRequest.LocationConstraint, o.region)\n\t\t\terrorCode = InvalidLocationConstraint\n\t\t\treturn\n\t\t}\n\t}\n\n\tvar acl *AccessControlPolicy\n\tif acl, err = ParseACL(r, userInfo.UserID, false, false); err != nil {\n\t\tlog.LogErrorf(\"createBucketHandler: parse acl fail: requestID(%v) err(%v)\", GetRequestID(r), err)\n\t\treturn\n\t}\n\n\tif err = o.mc.AdminAPI().CreateDefaultVolume(bucket, userInfo.UserID); err != nil {\n\t\tlog.LogErrorf(\"createBucketHandler: create bucket fail: requestID(%v) volume(%v) accessKey(%v) err(%v)\",\n\t\t\tGetRequestID(r), bucket, param.AccessKey(), err)\n\t\treturn\n\t}\n\n\tw.Header().Set(Location, \"/\"+bucket)\n\tw.Header().Set(Connection, \"close\")\n\n\tvol, err1 := o.vm.VolumeWithoutBlacklist(bucket)\n\tif err1 != nil {\n\t\tlog.LogWarnf(\"createBucketHandler: load volume fail: requestID(%v) volume(%v) err(%v)\",\n\t\t\tGetRequestID(r), bucket, err1)\n\t\treturn\n\t}\n\tif acl != nil {\n\t\tif err1 = putBucketACL(vol, acl); err1 != nil {\n\t\t\tlog.LogWarnf(\"createBucketHandler: put acl fail: requestID(%v) volume(%v) acl(%+v) err(%v)\",\n\t\t\t\tGetRequestID(r), bucket, acl, err1)\n\t\t}\n\t\tvol.metaLoader.storeACL(acl)\n\t}\n\n\treturn\n}\n\n// Delete bucket\n// API reference: https://docs.aws.amazon.com/AmazonS3/latest/API/API_DeleteBucket.html\nfunc (o *ObjectNode) deleteBucketHandler(w http.ResponseWriter, r *http.Request) {\n\tvar (\n\t\terr       error\n\t\terrorCode *ErrorCode\n\t)\n\tdefer func() {\n\t\to.errorResponse(w, r, err, errorCode)\n\t}()\n\n\tparam := ParseRequestParam(r)\n\tbucket := param.Bucket()\n\tif bucket == \"\" {\n\t\terrorCode = InvalidBucketName\n\t\treturn\n\t}\n\n\tvar userInfo *proto.UserInfo\n\tif userInfo, err = o.getUserInfoByAccessKeyV2(param.AccessKey()); err != nil {\n\t\tlog.LogErrorf(\"deleteBucketHandler: get user info fail: requestID(%v) volume(%v) accessKey(%v) err(%v)\",\n\t\t\tGetRequestID(r), bucket, param.AccessKey(), err)\n\t\treturn\n\t}\n\tvar vol *Volume\n\tif vol, err = o.getVol(bucket); err != nil {\n\t\tlog.LogErrorf(\"deleteBucketHandler: load volume fail: requestID(%v) volume(%v) err(%v)\",\n\t\t\tGetRequestID(r), bucket, err)\n\t\treturn\n\t}\n\n\t// QPS and Concurrency Limit\n\trateLimit := o.AcquireRateLimiter()\n\tif err = rateLimit.AcquireLimitResource(vol.owner, param.apiName); err != nil {\n\t\treturn\n\t}\n\tdefer rateLimit.ReleaseLimitResource(vol.owner, param.apiName)\n\n\tif !vol.IsEmpty() {\n\t\terrorCode = BucketNotEmpty\n\t\treturn\n\t}\n\n\t// delete Volume from master\n\tvar authKey string\n\tif authKey, err = calculateAuthKey(userInfo.UserID); err != nil {\n\t\tlog.LogErrorf(\"deleteBucketHandler: calculate authKey fail: requestID(%v) volume(%v) authKey(%v) err(%v)\",\n\t\t\tGetRequestID(r), bucket, userInfo.UserID, err)\n\t\treturn\n\t}\n\tif err = o.mc.AdminAPI().DeleteVolume(bucket, authKey); err != nil {\n\t\tlog.LogErrorf(\"deleteBucketHandler: delete volume fail: requestID(%v) volume(%v) accessKey(%v) err(%v)\",\n\t\t\tGetRequestID(r), bucket, param.AccessKey(), err)\n\t\treturn\n\t}\n\tlog.LogInfof(\"deleteBucketHandler: delete bucket success: requestID(%v) volume(%v) accessKey(%v)\",\n\t\tGetRequestID(r), bucket, param.AccessKey())\n\n\t// release Volume from Volume manager\n\to.vm.Release(bucket)\n\tw.WriteHeader(http.StatusNoContent)\n\treturn\n}\n\n// List buckets\n// API reference: https://docs.aws.amazon.com/AmazonS3/latest/API/API_ListBuckets.html\nfunc (o *ObjectNode) listBucketsHandler(w http.ResponseWriter, r *http.Request) {\n\tvar (\n\t\terr       error\n\t\terrorCode *ErrorCode\n\t)\n\tdefer func() {\n\t\to.errorResponse(w, r, err, errorCode)\n\t}()\n\n\tparam := ParseRequestParam(r)\n\tvar userInfo *proto.UserInfo\n\tif userInfo, err = o.getUserInfoByAccessKeyV2(param.accessKey); err != nil {\n\t\tlog.LogErrorf(\"listBucketsHandler: get user info fail: requestID(%v) accessKey(%v) err(%v)\",\n\t\t\tGetRequestID(r), param.AccessKey(), err)\n\t\treturn\n\t}\n\n\t// QPS and Concurrency Limit\n\trateLimit := o.AcquireRateLimiter()\n\tif err = rateLimit.AcquireLimitResource(userInfo.UserID, param.apiName); err != nil {\n\t\treturn\n\t}\n\tdefer rateLimit.ReleaseLimitResource(userInfo.UserID, param.apiName)\n\n\ttype bucket struct {\n\t\tXMLName      xml.Name `xml:\"Bucket\"`\n\t\tCreationDate string   `xml:\"CreationDate\"`\n\t\tName         string   `xml:\"Name\"`\n\t}\n\n\ttype listBucketsOutput struct {\n\t\tXMLName xml.Name `xml:\"ListAllMyBucketsResult\"`\n\t\tOwner   Owner    `xml:\"Owner\"`\n\t\tBuckets []bucket `xml:\"Buckets>Bucket\"`\n\t}\n\n\tvar output listBucketsOutput\n\tfor _, ownVol := range userInfo.Policy.OwnVols {\n\t\tvar vol *Volume\n\t\tif vol, err = o.getVol(ownVol); err != nil {\n\t\t\tlog.LogErrorf(\"listBucketsHandler: load volume fail: requestID(%v) volume(%v) err(%v)\",\n\t\t\t\tGetRequestID(r), ownVol, err)\n\t\t\tcontinue\n\t\t}\n\t\toutput.Buckets = append(output.Buckets, bucket{\n\t\t\tName:         ownVol,\n\t\t\tCreationDate: formatTimeISO(vol.CreateTime()),\n\t\t})\n\t}\n\toutput.Owner = Owner{DisplayName: userInfo.UserID, Id: userInfo.UserID}\n\n\tresponse, err := MarshalXMLEntity(&output)\n\tif err != nil {\n\t\tlog.LogErrorf(\"listBucketsHandler: xml marshal result fail: requestID(%v) result(%v) err(%v)\",\n\t\t\tGetRequestID(r), output, err)\n\t\treturn\n\t}\n\n\twriteSuccessResponseXML(w, response)\n\treturn\n}\n\n// Get bucket location\n// API reference: https://docs.aws.amazon.com/AmazonS3/latest/API/API_GetBucketLocation.html\nfunc (o *ObjectNode) getBucketLocationHandler(w http.ResponseWriter, r *http.Request) {\n\tvar (\n\t\terr       error\n\t\terrorCode *ErrorCode\n\t)\n\tdefer func() {\n\t\to.errorResponse(w, r, err, errorCode)\n\t}()\n\n\tvar vol *Volume\n\tparam := ParseRequestParam(r)\n\tif param.Bucket() == \"\" {\n\t\terrorCode = InvalidBucketName\n\t\treturn\n\t}\n\tif vol, err = o.getVol(param.Bucket()); err != nil {\n\t\tlog.LogErrorf(\"getBucketLocationHandler: load volume fail: requestID(%v) volume(%v) err(%v)\",\n\t\t\tGetRequestID(r), param.Bucket(), err)\n\t\treturn\n\t}\n\n\t// QPS and Concurrency Limit\n\trateLimit := o.AcquireRateLimiter()\n\tif err = rateLimit.AcquireLimitResource(vol.owner, param.apiName); err != nil {\n\t\treturn\n\t}\n\tdefer rateLimit.ReleaseLimitResource(vol.owner, param.apiName)\n\n\tlocation := LocationResponse{Location: o.region}\n\tresponse, err := MarshalXMLEntity(location)\n\tif err != nil {\n\t\tlog.LogErrorf(\"getBucketLocationHandler: xml marshal fail: requestID(%v) location(%v) err(%v)\",\n\t\t\tGetRequestID(r), location, err)\n\t\treturn\n\t}\n\n\twriteSuccessResponseXML(w, response)\n\treturn\n}\n\n// Get bucket tagging\n// API reference: https://docs.aws.amazon.com/AmazonS3/latest/API/API_GetBucketTagging.html\nfunc (o *ObjectNode) getBucketTaggingHandler(w http.ResponseWriter, r *http.Request) {\n\tvar (\n\t\terr       error\n\t\terrorCode *ErrorCode\n\t)\n\tdefer func() {\n\t\to.errorResponse(w, r, err, errorCode)\n\t}()\n\n\tvar param = ParseRequestParam(r)\n\tif len(param.Bucket()) == 0 {\n\t\terrorCode = InvalidBucketName\n\t\treturn\n\t}\n\tvar vol *Volume\n\tif vol, err = o.getVol(param.Bucket()); err != nil {\n\t\tlog.LogErrorf(\"getBucketTaggingHandler: load volume fail: requestID(%v) volume(%v) err(%v)\",\n\t\t\tGetRequestID(r), param.Bucket(), err)\n\t\treturn\n\t}\n\n\t// QPS and Concurrency Limit\n\trateLimit := o.AcquireRateLimiter()\n\tif err = rateLimit.AcquireLimitResource(vol.owner, param.apiName); err != nil {\n\t\treturn\n\t}\n\tdefer rateLimit.ReleaseLimitResource(vol.owner, param.apiName)\n\n\tvar xattrInfo *proto.XAttrInfo\n\tif xattrInfo, err = vol.GetXAttr(bucketRootPath, XAttrKeyOSSTagging); err != nil {\n\t\tlog.LogErrorf(\"getBucketTaggingHandler: Volume get XAttr fail: requestID(%v) err(%v)\", GetRequestID(r), err)\n\t\treturn\n\t}\n\tossTaggingData := xattrInfo.Get(XAttrKeyOSSTagging)\n\tvar output, _ = ParseTagging(string(ossTaggingData))\n\tif nil == output || len(output.TagSet) == 0 {\n\t\terrorCode = NoSuchTagSetError\n\t\treturn\n\t}\n\n\tresponse, err := MarshalXMLEntity(output)\n\tif err != nil {\n\t\tlog.LogErrorf(\"getBucketTaggingHandler: xml marshal result fail: requestID(%v) result(%v) err(%v)\",\n\t\t\tGetRequestID(r), output, err)\n\t\treturn\n\t}\n\n\twriteSuccessResponseXML(w, response)\n\treturn\n}\n\n// Put bucket tagging\n// API reference: https://docs.aws.amazon.com/AmazonS3/latest/API/API_PutBucketTagging.html\nfunc (o *ObjectNode) putBucketTaggingHandler(w http.ResponseWriter, r *http.Request) {\n\tvar (\n\t\terr       error\n\t\terrorCode *ErrorCode\n\t)\n\tdefer func() {\n\t\to.errorResponse(w, r, err, errorCode)\n\t}()\n\n\tvar param = ParseRequestParam(r)\n\tif param.Bucket() == \"\" {\n\t\terrorCode = InvalidBucketName\n\t\treturn\n\t}\n\tvar vol *Volume\n\tif vol, err = o.getVol(param.Bucket()); err != nil {\n\t\tlog.LogErrorf(\"putBucketTaggingHandler: load volume fail: requestID(%v) volume(%v) err(%v)\",\n\t\t\tGetRequestID(r), param.Bucket(), err)\n\t\treturn\n\t}\n\n\t// QPS and Concurrency Limit\n\trateLimit := o.AcquireRateLimiter()\n\tif err = rateLimit.AcquireLimitResource(vol.owner, param.apiName); err != nil {\n\t\treturn\n\t}\n\tdefer rateLimit.ReleaseLimitResource(vol.owner, param.apiName)\n\n\tvar body []byte\n\tif body, err = ioutil.ReadAll(r.Body); err != nil {\n\t\tlog.LogErrorf(\"putBucketTaggingHandler: read request body data fail: requestID(%v) err(%v)\",\n\t\t\tGetRequestID(r), err)\n\t\terrorCode = InvalidArgument\n\t\treturn\n\t}\n\n\tvar tagging = NewTagging()\n\tif err = UnmarshalXMLEntity(body, tagging); err != nil {\n\t\tlog.LogWarnf(\"putBucketTaggingHandler: unmarshal request body fail: requestID(%v) body(%v) err(%v)\",\n\t\t\tGetRequestID(r), string(body), err)\n\t\terrorCode = InvalidArgument\n\t\treturn\n\t}\n\tvalidateRes, errorCode := tagging.Validate()\n\tif !validateRes {\n\t\tlog.LogErrorf(\"putBucketTaggingHandler: tagging validate fail: requestID(%v) tagging(%v) err(%v)\",\n\t\t\tGetRequestID(r), tagging, errorCode.Error())\n\t\treturn\n\t}\n\n\terr = vol.SetXAttr(bucketRootPath, XAttrKeyOSSTagging, []byte(tagging.Encode()), false)\n\tif err != nil {\n\t\tlog.LogErrorf(\"putBucketTaggingHandler: set tagging xattr fail: requestID(%v) tagging(%v) err(%v)\",\n\t\t\tGetRequestID(r), tagging.Encode(), err)\n\t\treturn\n\t}\n\n\tw.WriteHeader(http.StatusNoContent)\n\treturn\n}\n\n// Delete bucket tagging\n// API reference: https://docs.aws.amazon.com/AmazonS3/latest/API/API_DeleteBucketTagging.html\nfunc (o *ObjectNode) deleteBucketTaggingHandler(w http.ResponseWriter, r *http.Request) {\n\tvar (\n\t\terr       error\n\t\terrorCode *ErrorCode\n\t)\n\tdefer func() {\n\t\to.errorResponse(w, r, err, errorCode)\n\t}()\n\n\tvar param = ParseRequestParam(r)\n\tif len(param.Bucket()) == 0 {\n\t\terrorCode = InvalidBucketName\n\t\treturn\n\t}\n\tvar vol *Volume\n\tif vol, err = o.getVol(param.Bucket()); err != nil {\n\t\tlog.LogErrorf(\"deleteBucketTaggingHandler: load volume fail: requestID(%v) volume(%v) err(%v)\",\n\t\t\tGetRequestID(r), param.Bucket(), err)\n\t\treturn\n\t}\n\n\t// QPS and Concurrency Limit\n\trateLimit := o.AcquireRateLimiter()\n\tif err = rateLimit.AcquireLimitResource(vol.owner, param.apiName); err != nil {\n\t\treturn\n\t}\n\tdefer rateLimit.ReleaseLimitResource(vol.owner, param.apiName)\n\n\tif err = vol.DeleteXAttr(bucketRootPath, XAttrKeyOSSTagging); err != nil {\n\t\tlog.LogErrorf(\"deleteBucketTaggingHandler: delete tagging xattr fail: requestID(%v) volume(%v) err(%v)\",\n\t\t\tGetRequestID(r), param.Bucket(), err)\n\t\treturn\n\t}\n\n\tw.WriteHeader(http.StatusNoContent)\n\treturn\n}\n\nfunc calculateAuthKey(key string) (authKey string, err error) {\n\th := md5.New()\n\t_, err = h.Write([]byte(key))\n\tif err != nil {\n\t\tlog.LogErrorf(\"calculateAuthKey: calculate auth key fail: key[%v] err[%v]\", key, err)\n\t\treturn\n\t}\n\tcipherStr := h.Sum(nil)\n\treturn strings.ToLower(hex.EncodeToString(cipherStr)), nil\n}\n\nfunc (o *ObjectNode) getUserInfoByAccessKey(accessKey string) (userInfo *proto.UserInfo, err error) {\n\tuserInfo, err = o.userStore.LoadUser(accessKey)\n\treturn\n}\n\n// Put Object Lock Configuration\n// https://docs.aws.amazon.com/AmazonS3/latest/API/API_PutObjectLockConfiguration.html\nfunc (o *ObjectNode) putObjectLockConfigurationHandler(w http.ResponseWriter, r *http.Request) {\n\tvar (\n\t\terr       error\n\t\terrorCode *ErrorCode\n\t)\n\tdefer func() {\n\t\to.errorResponse(w, r, err, errorCode)\n\t}()\n\n\tvar param = ParseRequestParam(r)\n\tif param.Bucket() == \"\" {\n\t\terrorCode = InvalidBucketName\n\t\treturn\n\t}\n\tvar vol *Volume\n\tif vol, err = o.getVol(param.Bucket()); err != nil {\n\t\tlog.LogErrorf(\"putObjectLockConfigurationHandler: load volume fail: requestID(%v) volume(%v) err(%v)\",\n\t\t\tGetRequestID(r), param.Bucket(), err)\n\t\treturn\n\t}\n\tvar body []byte\n\tif body, err = ioutil.ReadAll(io.LimitReader(r.Body, MaxObjectLockSize+1)); err != nil {\n\t\tlog.LogErrorf(\"putObjectLockConfigurationHandler: read request body fail: requestID(%v) volume(%v) err(%v)\",\n\t\t\tGetRequestID(r), vol.Name(), err)\n\t\treturn\n\t}\n\tif len(body) > MaxObjectLockSize {\n\t\terrorCode = EntityTooLarge\n\t\treturn\n\t}\n\tvar config *ObjectLockConfig\n\tif config, err = ParseObjectLockConfigFromXML(body); err != nil {\n\t\tlog.LogErrorf(\"putObjectLockConfigurationHandler: parse object lock config fail: requestID(%v) volume(%v) config(%v) err(%v)\",\n\t\t\tGetRequestID(r), vol.Name(), string(body), err)\n\t\treturn\n\t}\n\tif body, err = json.Marshal(config); err != nil {\n\t\tlog.LogErrorf(\"putObjectLockConfigurationHandler: json.Marshal object lock config fail: requestID(%v) volume(%v) config(%v) err(%v)\",\n\t\t\tGetRequestID(r), vol.Name(), config, err)\n\t\treturn\n\t}\n\tif err = storeObjectLock(body, vol); err != nil {\n\t\tlog.LogErrorf(\"putObjectLockConfigurationHandler: store object lock config fail: requestID(%v) volume(%v) config(%v) err(%v)\",\n\t\t\tGetRequestID(r), vol.Name(), string(body), err)\n\t\treturn\n\t}\n\tvol.metaLoader.storeObjectLock(config)\n\n\tw.WriteHeader(http.StatusNoContent)\n\treturn\n}\n\n// Get Object Lock Configuration\n// https://docs.aws.amazon.com/AmazonS3/latest/API/API_GetObjectLockConfiguration.html\nfunc (o *ObjectNode) getObjectLockConfigurationHandler(w http.ResponseWriter, r *http.Request) {\n\tvar (\n\t\terr       error\n\t\terrorCode *ErrorCode\n\t)\n\tdefer func() {\n\t\to.errorResponse(w, r, err, errorCode)\n\t}()\n\n\tvar param = ParseRequestParam(r)\n\tif param.Bucket() == \"\" {\n\t\terrorCode = InvalidBucketName\n\t\treturn\n\t}\n\n\tvar vol *Volume\n\tif vol, err = o.getVol(param.Bucket()); err != nil {\n\t\tlog.LogErrorf(\"getObjectLockConfigurationHandler: load volume fail: requestID(%v) volume(%v) err(%v)\",\n\t\t\tGetRequestID(r), param.Bucket(), err)\n\t\treturn\n\t}\n\n\tvar config *ObjectLockConfig\n\tif config, err = vol.metaLoader.loadObjectLock(); err != nil {\n\t\tlog.LogErrorf(\"getObjectLockConfigurationHandler: load object lock fail: requestID(%v) volume(%v) err(%v)\",\n\t\t\tGetRequestID(r), vol.Name(), err)\n\t\treturn\n\t}\n\tif config == nil || config.IsEmpty() {\n\t\terrorCode = ObjectLockConfigurationNotFound\n\t\treturn\n\t}\n\tvar data []byte\n\tif data, err = MarshalXMLEntity(config); err != nil {\n\t\tlog.LogErrorf(\"getObjectLockConfigurationHandler: xml marshal fail: requestID(%v) volume(%v) cors(%+v) err(%v)\",\n\t\t\tGetRequestID(r), vol.Name(), config, err)\n\t\treturn\n\t}\n\n\twriteSuccessResponseXML(w, data)\n\treturn\n}\n\nfunc (o *ObjectNode) getUserInfoByAccessKeyV2(accessKey string) (userInfo *proto.UserInfo, err error) {\n\tuserInfo, err = o.userStore.LoadUser(accessKey)\n\tif err == proto.ErrUserNotExists || err == proto.ErrAccessKeyNotExists || err == proto.ErrParamError {\n\t\terr = InvalidAccessKeyId\n\t}\n\treturn\n}\n\nfunc IsValidBucketName(bucketName string, minBucketLength, maxBucketLength int) bool {\n\tif len(bucketName) < minBucketLength || len(bucketName) > maxBucketLength {\n\t\treturn false\n\t}\n\tif !regexBucketName.MatchString(bucketName) {\n\t\treturn false\n\t}\n\treturn true\n}\n", "// Copyright 2019 The CubeFS Authors.\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n// implied. See the License for the specific language governing\n// permissions and limitations under the License.\n\npackage objectnode\n\nimport (\n\t\"encoding/base64\"\n\t\"encoding/hex\"\n\t\"encoding/xml\"\n\t\"io\"\n\t\"io/ioutil\"\n\t\"net/http\"\n\t\"strconv\"\n\t\"strings\"\n\t\"syscall\"\n\t\"time\"\n\n\t\"github.com/cubefs/cubefs/proto\"\n\t\"github.com/cubefs/cubefs/util/log\"\n)\n\nvar (\n\tMinPartNumberValid        = 1\n\tMaxPartNumberValid        = 10000\n\tMinPartSizeBytes   uint64 = 1024 * 1024\n\tMaxPartCopySize    int64  = 5 << 30 // 5GBytes\n)\n\n// Create multipart upload\n// API reference: https://docs.aws.amazon.com/AmazonS3/latest/API/API_CreateMultipartUpload.html\nfunc (o *ObjectNode) createMultipleUploadHandler(w http.ResponseWriter, r *http.Request) {\n\tvar (\n\t\terr       error\n\t\terrorCode *ErrorCode\n\t)\n\tdefer func() {\n\t\to.errorResponse(w, r, err, errorCode)\n\t}()\n\n\tvar param = ParseRequestParam(r)\n\tif param.Bucket() == \"\" {\n\t\terrorCode = InvalidBucketName\n\t\treturn\n\t}\n\tif param.Object() == \"\" {\n\t\terrorCode = InvalidKey\n\t\treturn\n\t}\n\tif len(param.Object()) > MaxKeyLength {\n\t\terrorCode = KeyTooLong\n\t\treturn\n\t}\n\tvar vol *Volume\n\tif vol, err = o.getVol(param.Bucket()); err != nil {\n\t\tlog.LogErrorf(\"createMultipleUploadHandler: load volume fail: requestID(%v) err(%v)\",\n\t\t\tGetRequestID(r), err)\n\t\treturn\n\t}\n\n\t// QPS and Concurrency Limit\n\trateLimit := o.AcquireRateLimiter()\n\tif err = rateLimit.AcquireLimitResource(vol.owner, param.apiName); err != nil {\n\t\treturn\n\t}\n\tdefer rateLimit.ReleaseLimitResource(vol.owner, param.apiName)\n\n\tvar userInfo *proto.UserInfo\n\tif userInfo, err = o.getUserInfoByAccessKeyV2(param.AccessKey()); err != nil {\n\t\tlog.LogErrorf(\"createMultipleUploadHandler: get user info fail: requestID(%v) accessKey(%v) err(%v)\",\n\t\t\tGetRequestID(r), param.AccessKey(), err)\n\t\treturn\n\t}\n\n\t// metadata\n\tcontentType := r.Header.Get(ContentType)\n\tcontentDisposition := r.Header.Get(ContentDisposition)\n\tcacheControl := r.Header.Get(CacheControl)\n\tif len(cacheControl) > 0 && !ValidateCacheControl(cacheControl) {\n\t\terrorCode = InvalidCacheArgument\n\t\treturn\n\t}\n\texpires := r.Header.Get(Expires)\n\tif len(expires) > 0 && !ValidateCacheExpires(expires) {\n\t\terrorCode = InvalidCacheArgument\n\t\treturn\n\t}\n\n\t// Checking user-defined metadata\n\tvar metadata = ParseUserDefinedMetadata(r.Header)\n\n\t// Check 'x-amz-tagging' header\n\tvar tagging *Tagging\n\tif xAmxTagging := r.Header.Get(XAmzTagging); xAmxTagging != \"\" {\n\t\tif tagging, err = ParseTagging(xAmxTagging); err != nil {\n\t\t\terrorCode = InvalidArgument\n\t\t\treturn\n\t\t}\n\t}\n\t// Check ACL\n\tvar acl *AccessControlPolicy\n\tacl, err = ParseACL(r, userInfo.UserID, false, vol.GetOwner() != userInfo.UserID)\n\tif err != nil {\n\t\tlog.LogErrorf(\"createMultipleUploadHandler: parse acl fail: requestID(%v) acl(%+v) err(%v)\",\n\t\t\tGetRequestID(r), acl, err)\n\t\treturn\n\t}\n\tvar opt = &PutFileOption{\n\t\tMIMEType:     contentType,\n\t\tDisposition:  contentDisposition,\n\t\tTagging:      tagging,\n\t\tMetadata:     metadata,\n\t\tCacheControl: cacheControl,\n\t\tExpires:      expires,\n\t\tACL:          acl,\n\t}\n\n\tvar uploadID string\n\tif uploadID, err = vol.InitMultipart(param.Object(), opt); err != nil {\n\t\tlog.LogErrorf(\"createMultipleUploadHandler: init multipart fail: requestID(%v) err(%v)\",\n\t\t\tGetRequestID(r), err)\n\t\treturn\n\t}\n\n\tinitResult := InitMultipartResult{\n\t\tBucket:   param.Bucket(),\n\t\tKey:      param.Object(),\n\t\tUploadId: uploadID,\n\t}\n\tresponse, err := MarshalXMLEntity(initResult)\n\tif err != nil {\n\t\tlog.LogErrorf(\"createMultipleUploadHandler: xml marshal result fail: requestID(%v) result(%v) err(%v)\",\n\t\t\tGetRequestID(r), initResult, err)\n\t\treturn\n\t}\n\n\twriteSuccessResponseXML(w, response)\n\treturn\n}\n\n// Upload part\n// Uploads a part in a multipart upload.\n// API reference: https://docs.aws.amazon.com/AmazonS3/latest/API/API_UploadPart.html .\nfunc (o *ObjectNode) uploadPartHandler(w http.ResponseWriter, r *http.Request) {\n\tvar (\n\t\terr       error\n\t\terrorCode *ErrorCode\n\t)\n\tdefer func() {\n\t\to.errorResponse(w, r, err, errorCode)\n\t}()\n\n\t// check args\n\tvar param = ParseRequestParam(r)\n\t// get upload id and part number\n\tuploadId := param.GetVar(ParamUploadId)\n\tpartNumber := param.GetVar(ParamPartNumber)\n\tif uploadId == \"\" || partNumber == \"\" {\n\t\tlog.LogErrorf(\"uploadPartHandler: illegal uploadID or partNumber, requestID(%v)\", GetRequestID(r))\n\t\terrorCode = InvalidArgument\n\t\treturn\n\t}\n\n\tvar partNumberInt uint16\n\tif partNumberInt, err = safeConvertStrToUint16(partNumber); err != nil {\n\t\tlog.LogErrorf(\"uploadPartHandler: parse part number fail, requestID(%v) raw(%v) err(%v)\",\n\t\t\tGetRequestID(r), partNumber, err)\n\t\terrorCode = InvalidArgument\n\t\treturn\n\t}\n\tif param.Bucket() == \"\" {\n\t\terrorCode = InvalidBucketName\n\t\treturn\n\t}\n\tif param.Object() == \"\" {\n\t\terrorCode = InvalidKey\n\t\treturn\n\t}\n\n\t// Get request MD5, if request MD5 is not empty, compute and verify it.\n\trequestMD5 := r.Header.Get(ContentMD5)\n\tif requestMD5 != \"\" {\n\t\tdecoded, err := base64.StdEncoding.DecodeString(requestMD5)\n\t\tif err != nil {\n\t\t\terrorCode = InvalidDigest\n\t\t\treturn\n\t\t}\n\t\trequestMD5 = hex.EncodeToString(decoded)\n\t}\n\n\t// Verify ContentLength\n\tlength := GetContentLength(r)\n\tif length > SinglePutLimit {\n\t\terrorCode = EntityTooLarge\n\t\treturn\n\t}\n\tif length < 0 {\n\t\terrorCode = MissingContentLength\n\t\treturn\n\t}\n\n\tvar vol *Volume\n\tif vol, err = o.getVol(param.Bucket()); err != nil {\n\t\tlog.LogErrorf(\"uploadPartHandler: load volume fail: requestID(%v) err(%v)\",\n\t\t\tGetRequestID(r), err)\n\t\treturn\n\t}\n\n\t// ObjectLock  Config\n\tobjetLock, err := vol.metaLoader.loadObjectLock()\n\tif err != nil {\n\t\tlog.LogErrorf(\"putObjectHandler: load volume objetLock: requestID(%v)  volume(%v) err(%v)\",\n\t\t\tGetRequestID(r), param.Bucket(), err)\n\t\treturn\n\t}\n\tif objetLock != nil && objetLock.ToRetention() != nil && requestMD5 == \"\" {\n\t\terrorCode = NoContentMd5HeaderErr\n\t\treturn\n\t}\n\n\t// QPS and Concurrency Limit\n\trateLimit := o.AcquireRateLimiter()\n\tif err = rateLimit.AcquireLimitResource(vol.owner, param.apiName); err != nil {\n\t\treturn\n\t}\n\tdefer rateLimit.ReleaseLimitResource(vol.owner, param.apiName)\n\n\t// Flow Control\n\tvar reader io.Reader\n\tif length > DefaultFlowLimitSize {\n\t\treader = rateLimit.GetReader(vol.owner, param.apiName, r.Body)\n\t} else {\n\t\treader = r.Body\n\t}\n\tvar fsFileInfo *FSFileInfo\n\tif fsFileInfo, err = vol.WritePart(param.Object(), uploadId, uint16(partNumberInt), reader); err != nil {\n\t\tlog.LogErrorf(\"uploadPartHandler: write part fail: requestID(%v) volume(%v) path(%v) uploadId(%v) part(%v) err(%v)\",\n\t\t\tGetRequestID(r), vol.Name(), param.Object(), uploadId, partNumberInt, err)\n\t\terr = handleWritePartErr(err)\n\t\treturn\n\t}\n\t// check content MD5\n\tif requestMD5 != \"\" && requestMD5 != fsFileInfo.ETag {\n\t\tlog.LogErrorf(\"uploadPartHandler: MD5 validate fail: requestID(%v) volume(%v) path(%v) requestMD5(%v) serverMD5(%v)\",\n\t\t\tGetRequestID(r), vol.Name(), param.Object(), requestMD5, fsFileInfo.ETag)\n\t\terrorCode = BadDigest\n\t\treturn\n\t}\n\n\t// write header to response\n\tw.Header()[ETag] = []string{\"\\\"\" + fsFileInfo.ETag + \"\\\"\"}\n\treturn\n}\n\n// Upload part copy\n// Uploads a part in a multipart upload by copying a existed object.\n// API reference: https://docs.aws.amazon.com/AmazonS3/latest/API/API_UploadPartCopy.html .\nfunc (o *ObjectNode) uploadPartCopyHandler(w http.ResponseWriter, r *http.Request) {\n\tvar (\n\t\terr       error\n\t\terrorCode *ErrorCode\n\t)\n\tdefer func() {\n\t\to.errorResponse(w, r, err, errorCode)\n\t}()\n\n\t// step1: check args\n\tvar param = ParseRequestParam(r)\n\tuploadId := param.GetVar(ParamUploadId)\n\tpartNumber := param.GetVar(ParamPartNumber)\n\tif uploadId == \"\" || partNumber == \"\" {\n\t\tlog.LogErrorf(\"uploadPartCopyHandler: illegal uploadID or partNumber, requestID(%v)\", GetRequestID(r))\n\t\terrorCode = InvalidArgument\n\t\treturn\n\t}\n\tvar partNumberInt uint16\n\tif partNumberInt, err = safeConvertStrToUint16(partNumber); err != nil {\n\t\tlog.LogErrorf(\"uploadPartCopyHandler: parse part number fail, requestID(%v) raw(%v) err(%v)\",\n\t\t\tGetRequestID(r), partNumber, err)\n\t\terrorCode = InvalidArgument\n\t\treturn\n\t}\n\tif param.Bucket() == \"\" {\n\t\terrorCode = InvalidBucketName\n\t\treturn\n\t}\n\tif param.Object() == \"\" {\n\t\terrorCode = InvalidKey\n\t\treturn\n\t}\n\tvar vol *Volume\n\tif vol, err = o.getVol(param.Bucket()); err != nil {\n\t\tlog.LogErrorf(\"uploadPartCopyHandler: load volume fail: requestID(%v) volume(%v) err(%v)\",\n\t\t\tGetRequestID(r), param.Bucket(), err)\n\t\treturn\n\t}\n\n\t// QPS and Concurrency Limit\n\trateLimit := o.AcquireRateLimiter()\n\tif err = rateLimit.AcquireLimitResource(vol.owner, param.apiName); err != nil {\n\t\treturn\n\t}\n\tdefer rateLimit.ReleaseLimitResource(vol.owner, param.apiName)\n\n\t// step2: extract params from req\n\tsrcBucket, srcObject, _, err := extractSrcBucketKey(r)\n\tif err != nil {\n\t\tlog.LogDebugf(\"uploadPartCopyHandler: copySource(%v) argument invalid: requestID(%v)\",\n\t\t\tr.Header.Get(XAmzCopySource), GetRequestID(r))\n\t\treturn\n\t}\n\n\t// step3: get srcObject metadata\n\tvar srcVol *Volume\n\tif srcVol, err = o.getVol(srcBucket); err != nil {\n\t\tlog.LogErrorf(\"uploadPartCopyHandler: load src volume fail: requestID(%v) volume(%v) err(%v)\",\n\t\t\tGetRequestID(r), srcBucket, err)\n\t\treturn\n\t}\n\tsrcFileInfo, _, err := srcVol.ObjectMeta(srcObject)\n\tif err != nil {\n\t\tlog.LogErrorf(\"uploadPartCopyHandler: get fileMeta fail: requestId(%v) srcVol(%v) path(%v) err(%v)\",\n\t\t\tGetRequestID(r), srcBucket, srcObject, err)\n\t\tif err == syscall.ENOENT {\n\t\t\terrorCode = NoSuchKey\n\t\t}\n\t\treturn\n\t}\n\n\terrorCode = CheckConditionInHeader(r, srcFileInfo)\n\tif errorCode != nil {\n\t\treturn\n\t}\n\n\t// step4: extract range params\n\tcopyRange := r.Header.Get(XAmzCopySourceRange)\n\tfirstByte, copyLength, errorCode := determineCopyRange(copyRange, srcFileInfo.Size)\n\tif errorCode != nil {\n\t\treturn\n\t}\n\tsize, err := safeConvertInt64ToUint64(srcFileInfo.Size)\n\tif err != nil {\n\t\treturn\n\t}\n\tfb, err := safeConvertInt64ToUint64(firstByte)\n\tif err != nil {\n\t\treturn\n\t}\n\tcl, err := safeConvertInt64ToUint64(copyLength)\n\tif err != nil {\n\t\treturn\n\t}\n\treader, writer := io.Pipe()\n\tgo func() {\n\t\terr = srcVol.readFile(srcFileInfo.Inode, size, srcObject, writer, fb, cl)\n\t\tif err != nil {\n\t\t\tlog.LogErrorf(\"uploadPartCopyHandler: read srcObj err(%v): requestId(%v) srcVol(%v) path(%v)\",\n\t\t\t\terr, GetRequestID(r), srcBucket, srcObject)\n\t\t}\n\t\twriter.CloseWithError(err)\n\t}()\n\n\t// step5: upload part by copy and flow control\n\tvar rd io.Reader\n\tif copyLength > DefaultFlowLimitSize {\n\t\trd = rateLimit.GetReader(vol.owner, param.apiName, reader)\n\t} else {\n\t\trd = reader\n\t}\n\tfsFileInfo, err := vol.WritePart(param.Object(), uploadId, uint16(partNumberInt), rd)\n\tif err != nil {\n\t\tlog.LogErrorf(\"uploadPartCopyHandler: write part fail: requestID(%v) volume(%v) path(%v) uploadId(%v) part(%v) err(%v)\",\n\t\t\tGetRequestID(r), vol.Name(), param.Object(), uploadId, partNumberInt, err)\n\t\tif err == syscall.ENOENT {\n\t\t\terrorCode = NoSuchUpload\n\t\t\treturn\n\t\t}\n\t\tif err == syscall.EAGAIN {\n\t\t\terrorCode = ConflictUploadRequest\n\t\t\treturn\n\t\t}\n\t\tif err == io.ErrUnexpectedEOF {\n\t\t\terrorCode = EntityTooSmall\n\t\t}\n\t\treturn\n\t}\n\n\tEtag := \"\\\"\" + fsFileInfo.ETag + \"\\\"\"\n\tw.Header()[ETag] = []string{Etag}\n\tresponse := NewS3CopyPartResult(Etag, fsFileInfo.CreateTime.UTC().Format(time.RFC3339)).String()\n\n\twriteSuccessResponseXML(w, []byte(response))\n\treturn\n}\n\nfunc handleWritePartErr(err error) error {\n\tif err == syscall.ENOENT {\n\t\treturn NoSuchUpload\n\t}\n\tif err == syscall.EEXIST {\n\t\treturn ConflictUploadRequest\n\t}\n\tif err == io.ErrUnexpectedEOF {\n\t\treturn EntityTooSmall\n\t}\n\treturn err\n}\n\n// List parts\n// API reference: https://docs.aws.amazon.com/AmazonS3/latest/API/API_ListParts.html\nfunc (o *ObjectNode) listPartsHandler(w http.ResponseWriter, r *http.Request) {\n\tvar (\n\t\terr       error\n\t\terrorCode *ErrorCode\n\t)\n\tdefer func() {\n\t\to.errorResponse(w, r, err, errorCode)\n\t}()\n\n\tvar param = ParseRequestParam(r)\n\t// get upload id and part number\n\tuploadId := param.GetVar(ParamUploadId)\n\tmaxParts := param.GetVar(ParamMaxParts)\n\tpartNoMarker := param.GetVar(ParamPartNoMarker)\n\n\tvar maxPartsInt uint64\n\tvar partNoMarkerInt uint64\n\n\tif uploadId == \"\" {\n\t\tlog.LogErrorf(\"listPartsHandler: illegal update ID, requestID(%v) err(%v)\", GetRequestID(r), err)\n\t\terrorCode = InvalidArgument\n\t\treturn\n\t}\n\n\tif maxParts == \"\" {\n\t\tmaxPartsInt = MaxParts\n\t} else {\n\t\tmaxPartsInt, err = strconv.ParseUint(maxParts, 10, 64)\n\t\tif err != nil {\n\t\t\tlog.LogErrorf(\"listPartsHandler: parse max parts fail: requestID(%v) raw(%v) err(%v)\",\n\t\t\t\tGetRequestID(r), maxParts, err)\n\t\t\terrorCode = InvalidArgument\n\t\t\treturn\n\t\t}\n\t\tif maxPartsInt > MaxParts {\n\t\t\tmaxPartsInt = MaxParts\n\t\t}\n\t}\n\tif partNoMarker != \"\" {\n\t\tres, err := strconv.ParseUint(partNoMarker, 10, 64)\n\t\tif err != nil {\n\t\t\tlog.LogErrorf(\"listPatsHandler: parse part number marker fail: requestID(%v) raw(%v) err(%v)\",\n\t\t\t\tGetRequestID(r), partNoMarker, err)\n\t\t\terrorCode = InvalidArgument\n\t\t\treturn\n\t\t}\n\t\tpartNoMarkerInt = res\n\t}\n\n\tif param.Bucket() == \"\" {\n\t\terrorCode = InvalidBucketName\n\t\treturn\n\t}\n\tif param.Object() == \"\" {\n\t\terrorCode = InvalidKey\n\t\treturn\n\t}\n\n\tvar vol *Volume\n\tif vol, err = o.getVol(param.Bucket()); err != nil {\n\t\tlog.LogErrorf(\"listPartsHandler: load volume fail: requestID(%v) err(%v)\",\n\t\t\tGetRequestID(r), err)\n\t\treturn\n\t}\n\n\t// QPS and Concurrency Limit\n\trateLimit := o.AcquireRateLimiter()\n\tif err = rateLimit.AcquireLimitResource(vol.owner, param.apiName); err != nil {\n\t\treturn\n\t}\n\tdefer rateLimit.ReleaseLimitResource(vol.owner, param.apiName)\n\n\tfsParts, nextMarker, isTruncated, err := vol.ListParts(param.Object(), uploadId, maxPartsInt, partNoMarkerInt)\n\tif err != nil {\n\t\tlog.LogErrorf(\"listPartsHandler: list parts fail, requestID(%v) uploadID(%v) maxParts(%v) partNoMarker(%v) err(%v)\",\n\t\t\tGetRequestID(r), uploadId, maxPartsInt, partNoMarkerInt, err)\n\t\tif err == syscall.ENOENT {\n\t\t\terrorCode = NoSuchUpload\n\t\t}\n\t\treturn\n\t}\n\tlog.LogDebugf(\"listPartsHandler: Volume list parts, \"+\n\t\t\"requestID(%v) uploadID(%v) maxParts(%v) partNoMarker(%v) numFSParts(%v) nextMarker(%v) isTruncated(%v)\",\n\t\tGetRequestID(r), uploadId, maxPartsInt, partNoMarkerInt, len(fsParts), nextMarker, isTruncated)\n\n\t// get owner\n\tbucketOwner := NewBucketOwner(vol)\n\tinitiator := NewInitiator(vol)\n\n\t// get parts\n\tparts := NewParts(fsParts)\n\n\tlistPartsResult := ListPartsResult{\n\t\tBucket:       param.Bucket(),\n\t\tKey:          param.Object(),\n\t\tUploadId:     uploadId,\n\t\tStorageClass: StorageClassStandard,\n\t\tNextMarker:   nextMarker,\n\t\tMaxParts:     maxPartsInt,\n\t\tIsTruncated:  isTruncated,\n\t\tParts:        parts,\n\t\tOwner:        bucketOwner,\n\t\tInitiator:    initiator,\n\t}\n\tresponse, err := MarshalXMLEntity(listPartsResult)\n\tif err != nil {\n\t\tlog.LogErrorf(\"listPartsHandler: xml marshal result fail: requestID(%v) err(%v)\",\n\t\t\tGetRequestID(r), err)\n\t\treturn\n\t}\n\n\twriteSuccessResponseXML(w, response)\n\treturn\n}\n\nfunc (o *ObjectNode) checkReqParts(param *RequestParam, reqParts *CompleteMultipartUploadRequest, multipartInfo *proto.MultipartInfo) (\n\tdiscardedPartInodes map[uint64]uint16, committedPartInfo *proto.MultipartInfo, err error) {\n\tif len(reqParts.Parts) <= 0 {\n\t\terr = InvalidPart\n\t\tlog.LogErrorf(\"checkReqParts: upload part is empty: requestID(%v) volume(%v)\", GetRequestID(param.r), param.Bucket())\n\t\treturn\n\t}\n\n\treqInfo := make(map[int]int, 0)\n\tfor _, reqPart := range reqParts.Parts {\n\t\treqInfo[reqPart.PartNumber] = 0\n\t}\n\n\tcommittedPartInfo = &proto.MultipartInfo{\n\t\tID:       multipartInfo.ID,\n\t\tPath:     multipartInfo.Path,\n\t\tInitTime: multipartInfo.InitTime,\n\t\tParts:    make([]*proto.MultipartPartInfo, 0),\n\t\tExtend:   make(map[string]string),\n\t}\n\tfor key, val := range multipartInfo.Extend {\n\t\tcommittedPartInfo.Extend[key] = val\n\t}\n\tuploadedInfo := make(map[uint16]string, 0)\n\tdiscardedPartInodes = make(map[uint64]uint16, 0)\n\tfor _, uploadedPart := range multipartInfo.Parts {\n\t\tlog.LogDebugf(\"checkReqParts: server save part check: requestID(%v) volume(%v) part(%v)\",\n\t\t\tGetRequestID(param.r), param.Bucket(), uploadedPart)\n\t\teTag := uploadedPart.MD5\n\t\tif strings.Contains(eTag, \"\\\"\") {\n\t\t\teTag = strings.ReplaceAll(eTag, \"\\\"\", \"\")\n\t\t}\n\t\tuploadedInfo[uploadedPart.ID] = eTag\n\t\tif _, existed := reqInfo[int(uploadedPart.ID)]; !existed {\n\t\t\tdiscardedPartInodes[uploadedPart.Inode] = uploadedPart.ID\n\t\t} else {\n\t\t\tcommittedPartInfo.Parts = append(committedPartInfo.Parts, uploadedPart)\n\t\t}\n\t}\n\n\tfor idx, reqPart := range reqParts.Parts {\n\t\tif reqPart.PartNumber > len(multipartInfo.Parts) {\n\t\t\terr = InvalidPart\n\t\t\treturn\n\t\t}\n\t\tif multipartInfo.Parts[reqPart.PartNumber-1].Size < MinPartSizeBytes && idx < len(reqParts.Parts)-1 {\n\t\t\terr = EntityTooSmall\n\t\t\treturn\n\t\t}\n\t\tif eTag, existed := uploadedInfo[uint16(reqPart.PartNumber)]; !existed {\n\t\t\tlog.LogErrorf(\"checkReqParts: request part not existed: requestID(%v) volume(%v) part(%v)\",\n\t\t\t\tGetRequestID(param.r), param.Bucket(), reqPart)\n\t\t\terr = InvalidPart\n\t\t\treturn\n\t\t} else {\n\t\t\treqEtag := reqPart.ETag\n\t\t\tif strings.Contains(reqEtag, \"\\\"\") {\n\t\t\t\treqEtag = strings.ReplaceAll(reqEtag, \"\\\"\", \"\")\n\t\t\t}\n\t\t\tif eTag != reqEtag {\n\t\t\t\tlog.LogErrorf(\"checkReqParts: part(%v) md5 not matched: requestID(%v) volume(%v) reqETag(%v) eTag(%v)\",\n\t\t\t\t\treqPart.PartNumber, GetRequestID(param.r), param.Bucket(), reqEtag, eTag)\n\t\t\t\terr = InvalidPart\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\t}\n\treturn\n}\n\n// Complete multipart\n// API reference: https://docs.aws.amazon.com/AmazonS3/latest/API/API_CompleteMultipartUpload.html\nfunc (o *ObjectNode) completeMultipartUploadHandler(w http.ResponseWriter, r *http.Request) {\n\tvar (\n\t\terr       error\n\t\terrorCode *ErrorCode\n\t)\n\tdefer func() {\n\t\to.errorResponse(w, r, err, errorCode)\n\t}()\n\n\tvar param = ParseRequestParam(r)\n\t// get upload id and part number\n\tuploadId := param.GetVar(ParamUploadId)\n\tif uploadId == \"\" {\n\t\tlog.LogErrorf(\"completeMultipartUploadHandler: non upload ID specified: requestID(%v)\", GetRequestID(r))\n\t\terrorCode = InvalidArgument\n\t\treturn\n\t}\n\n\tif param.Bucket() == \"\" {\n\t\terrorCode = InvalidBucketName\n\t\treturn\n\t}\n\tif param.Object() == \"\" {\n\t\terrorCode = InvalidKey\n\t\treturn\n\t}\n\tif len(param.Object()) > MaxKeyLength {\n\t\terrorCode = KeyTooLong\n\t\treturn\n\t}\n\n\tvar vol *Volume\n\tif vol, err = o.getVol(param.Bucket()); err != nil {\n\t\tlog.LogErrorf(\"completeMultipartUploadHandler: load volume fail: requestID(%v) err(%v)\",\n\t\t\tGetRequestID(r), err)\n\t\treturn\n\t}\n\n\t// QPS and Concurrency Limit\n\trateLimit := o.AcquireRateLimiter()\n\tif err = rateLimit.AcquireLimitResource(vol.owner, param.apiName); err != nil {\n\t\treturn\n\t}\n\tdefer rateLimit.ReleaseLimitResource(vol.owner, param.apiName)\n\n\t// get uploaded part info in request\n\tvar requestBytes []byte\n\trequestBytes, err = ioutil.ReadAll(r.Body)\n\tif err != nil && err != io.EOF {\n\t\tlog.LogErrorf(\"completeMultipartUploadHandler: read request body fail: requestID(%v) err(%v)\",\n\t\t\tGetRequestID(r), err)\n\t\treturn\n\t}\n\tmultipartUploadRequest := &CompleteMultipartUploadRequest{}\n\terr = UnmarshalXMLEntity(requestBytes, multipartUploadRequest)\n\tif err != nil {\n\t\tlog.LogErrorf(\"completeMultipartUploadHandler: unmarshal xml fail: requestID(%v) err(%v)\",\n\t\t\tGetRequestID(r), err)\n\t\terrorCode = MalformedXML\n\t\treturn\n\t}\n\t// check part parameter\n\tpartsLen := len(multipartUploadRequest.Parts)\n\tif partsLen > MaxPartNumberValid {\n\t\terrorCode = InvalidMaxPartNumber\n\t\treturn\n\t}\n\tif partsLen < MinPartNumberValid {\n\t\terrorCode = InvalidMinPartNumber\n\t\treturn\n\t}\n\tpreviousPartNum := 0\n\tfor _, p := range multipartUploadRequest.Parts {\n\t\tif p.PartNumber < previousPartNum {\n\t\t\tlog.LogDebugf(\"completeMultipartUploadHandler: invalid part order: requestID(%v) prevPartNum=%d partNum=%d\",\n\t\t\t\tGetRequestID(r), previousPartNum, p.PartNumber)\n\t\t\terrorCode = InvalidPartOrder\n\t\t\treturn\n\t\t}\n\t\tpreviousPartNum = p.PartNumber\n\t\tetag := strings.ReplaceAll(p.ETag, \"\\\"\", \"\")\n\t\tif etag == \"\" {\n\t\t\terrorCode = InvalidPart\n\t\t\treturn\n\t\t}\n\t}\n\t// get multipart info\n\tvar multipartInfo *proto.MultipartInfo\n\tif multipartInfo, err = vol.mw.GetMultipart_ll(param.object, uploadId); err != nil {\n\t\tlog.LogErrorf(\"completeMultipartUploadHandler: meta get multipart fail: requestID(%v) path(%v) err(%v)\",\n\t\t\tGetRequestID(r), param.object, err)\n\t\tif err == syscall.ENOENT {\n\t\t\terrorCode = NoSuchUpload\n\t\t\treturn\n\t\t}\n\t\tif err == syscall.EINVAL {\n\t\t\terrorCode = ObjectModeConflict\n\t\t}\n\t\treturn\n\t}\n\n\tdiscardedInods, committedPartInfo, err := o.checkReqParts(param, multipartUploadRequest, multipartInfo)\n\tif err != nil {\n\t\tlog.LogWarnf(\"completeMultipartUploadHandler: check request parts fail: requestID(%v) path(%v) err(%v)\",\n\t\t\tGetRequestID(r), param.object, errorCode)\n\t\treturn\n\t}\n\tfsFileInfo, err := vol.CompleteMultipart(param.Object(), uploadId, committedPartInfo, discardedInods)\n\tif err != nil {\n\t\tlog.LogErrorf(\"completeMultipartUploadHandler: complete multipart fail: requestID(%v) volume(%v) uploadID(%v) err(%v)\",\n\t\t\tGetRequestID(r), param.Bucket(), uploadId, err)\n\t\tif err == syscall.EINVAL {\n\t\t\terrorCode = ObjectModeConflict\n\t\t}\n\t\treturn\n\t}\n\n\tcompleteResult := CompleteMultipartResult{\n\t\tBucket: param.Bucket(),\n\t\tKey:    param.Object(),\n\t\tETag:   wrapUnescapedQuot(fsFileInfo.ETag),\n\t}\n\tresponse, err := MarshalXMLEntity(completeResult)\n\tif err != nil {\n\t\tlog.LogErrorf(\"completeMultipartUploadHandler: xml marshal result fail: requestID(%v) result(%v) err(%v)\",\n\t\t\tGetRequestID(r), completeResult, err)\n\t\treturn\n\t}\n\n\twriteSuccessResponseXML(w, response)\n\treturn\n}\n\n// Abort multipart\n// API reference: https://docs.aws.amazon.com/AmazonS3/latest/API/API_AbortMultipartUpload.html .\nfunc (o *ObjectNode) abortMultipartUploadHandler(w http.ResponseWriter, r *http.Request) {\n\tvar (\n\t\terr       error\n\t\terrorCode *ErrorCode\n\t)\n\tdefer func() {\n\t\to.errorResponse(w, r, err, errorCode)\n\t}()\n\n\t// check args\n\tvar param = ParseRequestParam(r)\n\tuploadId := param.GetVar(ParamUploadId)\n\tif uploadId == \"\" {\n\t\terrorCode = InvalidArgument\n\t\treturn\n\t}\n\tif param.Bucket() == \"\" {\n\t\terrorCode = InvalidBucketName\n\t\treturn\n\t}\n\tif param.Object() == \"\" {\n\t\terrorCode = InvalidKey\n\t\treturn\n\t}\n\n\tvar vol *Volume\n\tif vol, err = o.getVol(param.Bucket()); err != nil {\n\t\tlog.LogErrorf(\"abortMultipartUploadHandler: load volume fail: requestID(%v) err(%v)\",\n\t\t\tGetRequestID(r), err)\n\t\treturn\n\t}\n\n\t// QPS and Concurrency Limit\n\trateLimit := o.AcquireRateLimiter()\n\tif err = rateLimit.AcquireLimitResource(vol.owner, param.apiName); err != nil {\n\t\treturn\n\t}\n\tdefer rateLimit.ReleaseLimitResource(vol.owner, param.apiName)\n\n\t// Abort multipart upload\n\tif err = vol.AbortMultipart(param.Object(), uploadId); err != nil {\n\t\tlog.LogErrorf(\"abortMultipartUploadHandler: abort multipart fail: requestID(%v) uploadID(%v) err(%v)\",\n\t\t\tGetRequestID(r), uploadId, err)\n\t\tif err == syscall.ENOENT {\n\t\t\terrorCode = NoSuchUpload\n\t\t}\n\t\treturn\n\t}\n\n\tw.WriteHeader(http.StatusNoContent)\n\treturn\n}\n\n// List multipart uploads\n// API reference: https://docs.aws.amazon.com/AmazonS3/latest/API/API_ListMultipartUploads.html\nfunc (o *ObjectNode) listMultipartUploadsHandler(w http.ResponseWriter, r *http.Request) {\n\tvar (\n\t\terr       error\n\t\terrorCode *ErrorCode\n\t)\n\tdefer func() {\n\t\to.errorResponse(w, r, err, errorCode)\n\t}()\n\n\tvar param = ParseRequestParam(r)\n\t// get list uploads parameter\n\tprefix := param.GetVar(ParamPrefix)\n\tkeyMarker := param.GetVar(ParamKeyMarker)\n\tdelimiter := param.GetVar(ParamPartDelimiter)\n\tmaxUploads := param.GetVar(ParamPartMaxUploads)\n\tuploadIdMarker := param.GetVar(ParamUploadIdMarker)\n\n\tvar maxUploadsInt uint64\n\tif maxUploads == \"\" {\n\t\tmaxUploadsInt = MaxUploads\n\t} else {\n\t\tmaxUploadsInt, err = strconv.ParseUint(maxUploads, 10, 64)\n\t\tif err != nil {\n\t\t\tlog.LogErrorf(\"listMultipartUploadsHandler: parse max uploads fail: requestID(%v) raw(%v) err(%v)\",\n\t\t\t\tGetRequestID(r), maxUploads, err)\n\t\t\terrorCode = InvalidArgument\n\t\t\treturn\n\t\t}\n\t\tif maxUploadsInt > MaxUploads {\n\t\t\tmaxUploadsInt = MaxUploads\n\t\t}\n\t}\n\n\tif param.Bucket() == \"\" {\n\t\terrorCode = InvalidBucketName\n\t\treturn\n\t}\n\n\tvar vol *Volume\n\tif vol, err = o.getVol(param.Bucket()); err != nil {\n\t\tlog.LogErrorf(\"listMultipartUploadsHandler: load volume fail: requestID(%v) vol(%v) err(%v)\",\n\t\t\tGetRequestID(r), param.Bucket(), err)\n\t\treturn\n\t}\n\n\t// QPS and Concurrency Limit\n\trateLimit := o.AcquireRateLimiter()\n\tif err = rateLimit.AcquireLimitResource(vol.owner, param.apiName); err != nil {\n\t\treturn\n\t}\n\tdefer rateLimit.ReleaseLimitResource(vol.owner, param.apiName)\n\n\tfsUploads, nextKeyMarker, nextUploadIdMarker, IsTruncated, prefixes, err := vol.ListMultipartUploads(prefix, delimiter, keyMarker, uploadIdMarker, maxUploadsInt)\n\tif err != nil {\n\t\tlog.LogErrorf(\"listMultipartUploadsHandler: list multipart uploads fail: requestID(%v) err(%v)\",\n\t\t\tGetRequestID(r), err)\n\t\treturn\n\t}\n\n\tuploads := NewUploads(fsUploads, param.AccessKey())\n\n\tvar commonPrefixes = make([]*CommonPrefix, 0)\n\tfor _, prefix := range prefixes {\n\t\tcommonPrefix := &CommonPrefix{\n\t\t\tPrefix: prefix,\n\t\t}\n\t\tcommonPrefixes = append(commonPrefixes, commonPrefix)\n\t}\n\n\tlistUploadsResult := ListUploadsResult{\n\t\tBucket:             param.Bucket(),\n\t\tKeyMarker:          keyMarker,\n\t\tUploadIdMarker:     uploadIdMarker,\n\t\tNextKeyMarker:      nextKeyMarker,\n\t\tNextUploadIdMarker: nextUploadIdMarker,\n\t\tDelimiter:          delimiter,\n\t\tPrefix:             prefix,\n\t\tMaxUploads:         maxUploadsInt,\n\t\tIsTruncated:        IsTruncated,\n\t\tUploads:            uploads,\n\t\tCommonPrefixes:     commonPrefixes,\n\t}\n\tresponse, err := MarshalXMLEntity(listUploadsResult)\n\tif err != nil {\n\t\tlog.LogErrorf(\"listMultipartUploadsHandler: xml marshal result fail: requestID(%v) result(%v) err(%v)\",\n\t\t\tGetRequestID(r), listUploadsResult, err)\n\t\treturn\n\t}\n\n\twriteSuccessResponseXML(w, response)\n\treturn\n}\n\nfunc determineCopyRange(copyRange string, fsize int64) (firstByte, copyLength int64, err *ErrorCode) {\n\tif copyRange == \"\" { // whole file\n\t\treturn 0, fsize, nil\n\t}\n\tfirstByte, lastByte, err := extractCopyRangeParam(copyRange)\n\tif err != nil {\n\t\treturn\n\t}\n\tif !(0 <= firstByte && firstByte <= lastByte && lastByte < fsize) {\n\t\terr = InvalidArgument\n\t\treturn\n\t}\n\tcopyLength = lastByte + 1 - firstByte\n\tif copyLength > MaxPartCopySize {\n\t\terr = EntityTooLarge\n\t\treturn\n\t}\n\treturn\n}\n\nfunc extractCopyRangeParam(copRange string) (firstByte, lastByte int64, err *ErrorCode) {\n\t// copRange must use the form : bytes=first-last\n\tstrs := strings.SplitN(copRange, \"=\", 2)\n\tif len(strs) < 2 {\n\t\terr = InvalidArgument\n\t\treturn\n\t}\n\tbyteRange := strings.SplitN(strs[1], \"-\", 2)\n\tif len(byteRange) < 2 {\n\t\terr = InvalidArgument\n\t\treturn\n\t}\n\tfirstByteStr, lastByteStr := byteRange[0], byteRange[1]\n\tfirstByte, err1 := strconv.ParseInt(firstByteStr, 10, 64)\n\tlastByte, err2 := strconv.ParseInt(lastByteStr, 10, 64)\n\tif err1 != nil || err2 != nil {\n\t\terr = InvalidArgument\n\t\treturn\n\t}\n\treturn\n}\n\ntype S3CopyPartResult struct {\n\tXMLName      xml.Name\n\tETag         string `xml:\"ETag\"`\n\tLastModified string `xml:\"LastModified\"`\n}\n\nfunc NewS3CopyPartResult(etag, lastModified string) *S3CopyPartResult {\n\treturn &S3CopyPartResult{\n\t\tXMLName: xml.Name{\n\t\t\tSpace: S3Namespace,\n\t\t\tLocal: \"CopyPartResult\",\n\t\t},\n\t\tETag:         etag,\n\t\tLastModified: lastModified,\n\t}\n}\n\nfunc (s *S3CopyPartResult) String() string {\n\tb, _ := xml.Marshal(s)\n\treturn string(b)\n}\n", "// Copyright 2019 The CubeFS Authors.\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n// implied. See the License for the specific language governing\n// permissions and limitations under the License.\n\npackage objectnode\n\nimport (\n\t\"encoding/base64\"\n\t\"encoding/hex\"\n\t\"encoding/xml\"\n\t\"fmt\"\n\t\"io\"\n\t\"io/ioutil\"\n\t\"net/http\"\n\t\"net/url\"\n\t\"regexp\"\n\t\"sort\"\n\t\"strconv\"\n\t\"strings\"\n\t\"syscall\"\n\t\"time\"\n\n\t\"github.com/cubefs/cubefs/proto\"\n\t\"github.com/cubefs/cubefs/util/log\"\n)\n\nvar (\n\trangeRegexp  = regexp.MustCompile(\"^bytes=(\\\\d)*-(\\\\d)*$\")\n\tMaxKeyLength = 750\n)\n\n// Get object\n// API reference: https://docs.aws.amazon.com/AmazonS3/latest/API/API_GetObject.html\nfunc (o *ObjectNode) getObjectHandler(w http.ResponseWriter, r *http.Request) {\n\tvar (\n\t\terr       error\n\t\terrorCode *ErrorCode\n\t)\n\tvar startGet = time.Now()\n\tdefer func() {\n\t\to.errorResponse(w, r, err, errorCode)\n\t}()\n\n\tvar param = ParseRequestParam(r)\n\tif param.Bucket() == \"\" {\n\t\terrorCode = InvalidBucketName\n\t\treturn\n\t}\n\tif param.Object() == \"\" {\n\t\terrorCode = InvalidKey\n\t\treturn\n\t}\n\tvar vol *Volume\n\tif vol, err = o.getVol(param.Bucket()); err != nil {\n\t\tlog.LogErrorf(\"getObjectHandler: load volume fail: requestID(%v) volume(%v) path(%v) err(%v)\",\n\t\t\tGetRequestID(r), param.Bucket(), param.Object(), err)\n\t\treturn\n\t}\n\n\t// QPS and Concurrency Limit\n\trateLimit := o.AcquireRateLimiter()\n\tif err = rateLimit.AcquireLimitResource(vol.owner, param.apiName); err != nil {\n\t\treturn\n\t}\n\tdefer rateLimit.ReleaseLimitResource(vol.owner, param.apiName)\n\n\t// parse http range option\n\tvar (\n\t\trevRange    bool\n\t\tisRangeRead bool\n\t\trangeLower  uint64\n\t\trangeUpper  uint64\n\t\tpartSize    uint64\n\t\tpartCount   uint64\n\t)\n\trangeOpt := strings.TrimSpace(r.Header.Get(Range))\n\tif len(rangeOpt) > 0 {\n\t\tif !rangeRegexp.MatchString(rangeOpt) {\n\t\t\tlog.LogErrorf(\"getObjectHandler: invalid range header: requestID(%v) volume(%v) path(%v) rangeOpt(%v)\",\n\t\t\t\tGetRequestID(r), param.Bucket(), param.Object(), rangeOpt)\n\t\t\terrorCode = InvalidRange\n\t\t\treturn\n\t\t}\n\t\thyphenIndex := strings.Index(rangeOpt, \"-\")\n\t\tif hyphenIndex < 0 {\n\t\t\tlog.LogErrorf(\"getObjectHandler: invalid range header: requestID(%v) volume(%v) path(%v) rangeOpt(%v)\",\n\t\t\t\tGetRequestID(r), param.Bucket(), param.Object(), rangeOpt)\n\t\t\terrorCode = InvalidRange\n\t\t\treturn\n\t\t}\n\t\tlowerPart := rangeOpt[len(\"bytes=\"):hyphenIndex]\n\t\tupperPart := \"\"\n\t\tif hyphenIndex+1 < len(rangeOpt) {\n\t\t\t// bytes=-5\n\t\t\tif hyphenIndex == len(\"bytes=\") { // suffix range opt\n\t\t\t\trevRange = true\n\t\t\t\trangeUpper = 1<<64 - 1\n\t\t\t\tlowerPart = rangeOpt[hyphenIndex+1:]\n\t\t\t} else { // bytes=1-10\n\t\t\t\tupperPart = rangeOpt[hyphenIndex+1:]\n\t\t\t}\n\t\t} else if hyphenIndex+1 == len(rangeOpt) { // bytes=1-\n\t\t\trangeUpper = 1<<64 - 1\n\t\t}\n\t\tif len(lowerPart) > 0 {\n\t\t\tif rangeLower, err = strconv.ParseUint(lowerPart, 10, 64); err != nil {\n\t\t\t\tlog.LogErrorf(\"getObjectHandler: parse range lower fail: requestID(%v) volume(%v) path(%v) rangeOpt(%v) err(%v)\",\n\t\t\t\t\tGetRequestID(r), param.Bucket(), param.Object(), rangeOpt, err)\n\t\t\t\terrorCode = InvalidRange\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\t\tif len(upperPart) > 0 {\n\t\t\tif rangeUpper, err = strconv.ParseUint(upperPart, 10, 64); err != nil {\n\t\t\t\tlog.LogErrorf(\"getObjectHandler: parse range upper fail: requestID(%v) volume(%v) path(%v) rangeOpt(%v) err(%v)\",\n\t\t\t\t\tGetRequestID(r), param.Bucket(), param.Object(), rangeOpt, err)\n\t\t\t\terrorCode = InvalidRange\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\t\tif rangeUpper < rangeLower {\n\t\t\t// upper enabled and lower than lower side\n\t\t\tlog.LogErrorf(\"getObjectHandler: invalid range header: requestID(%v) volume(%v) path(%v) rangeOpt(%v)\",\n\t\t\t\tGetRequestID(r), param.Bucket(), param.Object(), rangeOpt)\n\t\t\terrorCode = InvalidRange\n\t\t\treturn\n\t\t}\n\t\tisRangeRead = true\n\t\tlog.LogDebugf(\"getObjectHandler: parse range header: requestID(%v) volume(%v) path(%v) rangeOpt(%v) lower(%v) upper(%v)\",\n\t\t\tGetRequestID(r), param.Bucket(), param.Object(), rangeOpt, rangeLower, rangeUpper)\n\t}\n\n\tresponseCacheControl := r.URL.Query().Get(ParamResponseCacheControl)\n\tif len(responseCacheControl) > 0 && !ValidateCacheControl(responseCacheControl) {\n\t\terrorCode = InvalidCacheArgument\n\t\treturn\n\t}\n\tresponseExpires := r.URL.Query().Get(ParamResponseExpires)\n\tif len(responseExpires) > 0 && !ValidateCacheExpires(responseExpires) {\n\t\terrorCode = InvalidCacheArgument\n\t\treturn\n\t}\n\tresponseContentType := r.URL.Query().Get(ParamResponseContentType)\n\tresponseContentDisposition := r.URL.Query().Get(ParamResponseContentDisposition)\n\n\t// get object meta\n\tvar fileInfo *FSFileInfo\n\tvar xattr *proto.XAttrInfo\n\tvar start = time.Now()\n\tfileInfo, xattr, err = vol.ObjectMeta(param.Object())\n\tlog.LogDebugf(\"getObjectHandler: get object meta cost: %v\", time.Since(start))\n\tif err != nil {\n\t\tlog.LogErrorf(\"getObjectHandler: get file meta fail: requestId(%v) volume(%v) path(%v) err(%v)\",\n\t\t\tGetRequestID(r), vol.Name(), param.Object(), err)\n\t\tif err == syscall.ENOENT {\n\t\t\terrorCode = NoSuchKey\n\t\t}\n\t\treturn\n\t}\n\n\t// header condition check\n\terrorCode = CheckConditionInHeader(r, fileInfo)\n\tif errorCode != nil {\n\t\treturn\n\t}\n\n\t// validate and fix range\n\tif isRangeRead && rangeUpper > uint64(fileInfo.Size)-1 {\n\t\trangeUpper = uint64(fileInfo.Size) - 1\n\t\tif revRange && rangeLower > 0 {\n\t\t\trangeLower = rangeUpper + 1 - rangeLower\n\t\t}\n\t}\n\n\t// compute content length\n\tvar contentLength = uint64(fileInfo.Size)\n\tif isRangeRead {\n\t\tcontentLength = rangeUpper - rangeLower + 1\n\t}\n\n\t// get object tagging size\n\tossTaggingData := xattr.Get(XAttrKeyOSSTagging)\n\toutput, _ := ParseTagging(string(ossTaggingData))\n\tif output != nil && len(output.TagSet) > 0 {\n\t\tw.Header().Set(XAmzTaggingCount, strconv.Itoa(len(output.TagSet)))\n\t}\n\n\t// set response header for GetObject\n\tw.Header().Set(AcceptRanges, ValueAcceptRanges)\n\tw.Header().Set(LastModified, formatTimeRFC1123(fileInfo.ModifyTime))\n\tif len(responseContentType) > 0 {\n\t\tw.Header().Set(ContentType, responseContentType)\n\t} else if len(fileInfo.MIMEType) > 0 {\n\t\tw.Header().Set(ContentType, fileInfo.MIMEType)\n\t} else {\n\t\tw.Header().Set(ContentType, ValueContentTypeStream)\n\t}\n\tif len(responseContentDisposition) > 0 {\n\t\tw.Header().Set(ContentDisposition, responseContentDisposition)\n\t} else if len(fileInfo.Disposition) > 0 {\n\t\tw.Header().Set(ContentDisposition, fileInfo.Disposition)\n\t}\n\tif len(responseCacheControl) > 0 {\n\t\tw.Header().Set(CacheControl, responseCacheControl)\n\t} else if len(fileInfo.CacheControl) > 0 {\n\t\tw.Header().Set(CacheControl, fileInfo.CacheControl)\n\t}\n\tif len(responseExpires) > 0 {\n\t\tw.Header().Set(Expires, responseExpires)\n\t} else if len(fileInfo.Expires) > 0 {\n\t\tw.Header().Set(Expires, fileInfo.Expires)\n\t}\n\tif len(fileInfo.RetainUntilDate) > 0 {\n\t\tw.Header().Set(XAmzObjectLockMode, ComplianceMode)\n\t\tw.Header().Set(XAmzObjectLockRetainUntilDate, fileInfo.RetainUntilDate)\n\t}\n\n\t// check request is whether contain param : partNumber\n\tpartNumber := r.URL.Query().Get(ParamPartNumber)\n\tif len(partNumber) > 0 && fileInfo.Size >= MinParallelDownloadFileSize {\n\t\tpartNumberInt, err := strconv.ParseUint(partNumber, 10, 64)\n\t\tif err != nil {\n\t\t\tlog.LogErrorf(\"getObjectHandler: parse partNumber(%v) fail: requestID(%v) volume(%v) path(%v) err(%v)\",\n\t\t\t\tpartNumber, GetRequestID(r), param.Bucket(), param.Object(), err)\n\t\t\terrorCode = InvalidArgument\n\t\t\treturn\n\t\t}\n\t\tpartSize, partCount, rangeLower, rangeUpper = parsePartInfo(partNumberInt, uint64(fileInfo.Size))\n\t\tlog.LogDebugf(\"getObjectHandler: partNumber(%v) fileSize(%v) parsed: partSize(%d) partCount(%d) rangeLower(%d) rangeUpper(%d)\",\n\t\t\tpartNumberInt, fileInfo.Size, partSize, partCount, rangeLower, rangeUpper)\n\t\tif partNumberInt > partCount {\n\t\t\tlog.LogErrorf(\"getObjectHandler: partNumber(%d) > partCount(%d): requestID(%v) volume(%v) path(%v)\",\n\t\t\t\tpartNumberInt, partCount, GetRequestID(r), param.Bucket(), param.Object())\n\t\t\terrorCode = NoSuchKey\n\t\t\treturn\n\t\t}\n\t\t// Header : Accept-Range, Content-Length, Content-Range, ETag, x-amz-mp-parts-count\n\t\tw.Header().Set(ContentLength, strconv.Itoa(int(partSize)))\n\t\tw.Header().Set(ContentRange, fmt.Sprintf(\"bytes %d-%d/%d\", rangeLower, rangeUpper, fileInfo.Size))\n\t\tw.Header().Set(XAmzMpPartsCount, strconv.Itoa(int(partCount)))\n\t\tif len(fileInfo.ETag) > 0 && !strings.Contains(fileInfo.ETag, \"-\") {\n\t\t\tw.Header()[ETag] = []string{fmt.Sprintf(\"%s-%d\", fileInfo.ETag, partCount)}\n\t\t}\n\t} else {\n\t\tw.Header().Set(ContentLength, strconv.FormatUint(contentLength, 10))\n\t\tif len(fileInfo.ETag) > 0 {\n\t\t\tw.Header()[ETag] = []string{wrapUnescapedQuot(fileInfo.ETag)}\n\t\t}\n\t\tif isRangeRead {\n\t\t\tw.Header().Set(ContentRange, fmt.Sprintf(\"bytes %d-%d/%d\", rangeLower, rangeUpper, fileInfo.Size))\n\t\t}\n\t}\n\n\t// User-defined metadata\n\tfor name, value := range fileInfo.Metadata {\n\t\tw.Header().Set(XAmzMetaPrefix+name, value)\n\t}\n\n\tif fileInfo.Mode.IsDir() {\n\t\treturn\n\t}\n\n\t// get object content\n\tvar offset = rangeLower\n\tsize, err := safeConvertInt64ToUint64(fileInfo.Size)\n\tfileSize := size\n\tif err != nil {\n\t\treturn\n\t}\n\tif isRangeRead || len(partNumber) > 0 {\n\t\tsize = rangeUpper - rangeLower + 1\n\t\tw.WriteHeader(http.StatusPartialContent)\n\t}\n\n\t// Flow Control\n\tvar writer io.Writer\n\tif size > DefaultFlowLimitSize {\n\t\twriter = rateLimit.GetResponseWriter(vol.owner, param.apiName, w)\n\t} else {\n\t\twriter = w\n\t}\n\terr = vol.readFile(fileInfo.Inode, fileSize, param.Object(), writer, offset, size)\n\tif err != nil {\n\t\tlog.LogErrorf(\"getObjectHandler: read file fail: requestID(%v) volume(%v) path(%v) offset(%v) size(%v) err(%v)\",\n\t\t\tGetRequestID(r), param.Bucket(), param.Object(), offset, size, err)\n\t\tif err == syscall.ENOENT {\n\t\t\terrorCode = NoSuchKey\n\t\t}\n\t\treturn\n\t}\n\tlog.LogDebugf(\"getObjectHandler: read file success: requestID(%v) volume(%v) path(%v) offset(%v) size(%v) cost(%v)\",\n\t\tGetRequestID(r), param.Bucket(), param.Object(), offset, size, time.Since(startGet))\n\n\treturn\n}\n\nfunc CheckConditionInHeader(r *http.Request, fileInfo *FSFileInfo) *ErrorCode {\n\t// parse request header\n\tmatch := r.Header.Get(IfMatch)\n\tnoneMatch := r.Header.Get(IfNoneMatch)\n\tmodified := r.Header.Get(IfModifiedSince)\n\tunmodified := r.Header.Get(IfUnmodifiedSince)\n\t// Checking precondition: If-Match\n\t// Reference: https://docs.aws.amazon.com/AmazonS3/latest/API/API_GetObject.html#API_GetObject_RequestSyntax\n\tif match != \"\" {\n\t\tif matchEag := strings.Trim(match, \"\\\"\"); matchEag != fileInfo.ETag {\n\t\t\tlog.LogDebugf(\"getObjectHandler: object eTag(%s) not match If-Match header value(%s), requestId(%v)\",\n\t\t\t\tfileInfo.ETag, matchEag, GetRequestID(r))\n\t\t\treturn PreconditionFailed\n\n\t\t}\n\t}\n\t// Checking precondition: If-Modified-Since\n\t// Reference: https://docs.aws.amazon.com/AmazonS3/latest/API/API_GetObject.html#API_GetObject_RequestSyntax\n\tif modified != \"\" {\n\t\tfileModTime := fileInfo.ModifyTime\n\t\tmodifiedTime, err := parseTimeRFC1123(modified)\n\t\tif err != nil {\n\t\t\tlog.LogErrorf(\"getObjectHandler: parse RFC1123 time fail: requestID(%v) err(%v)\", GetRequestID(r), err)\n\t\t\treturn InvalidArgument\n\t\t}\n\t\tif !fileModTime.After(modifiedTime) {\n\t\t\tlog.LogInfof(\"getObjectHandler: file modified time not after than specified time: requestID(%v)\", GetRequestID(r))\n\t\t\treturn NotModified\n\t\t}\n\t}\n\t// Checking precondition: If-None-Match\n\t// Reference: https://docs.aws.amazon.com/AmazonS3/latest/API/API_GetObject.html#API_GetObject_RequestSyntax\n\tif noneMatch != \"\" {\n\t\tif noneMatchEtag := strings.Trim(noneMatch, \"\\\"\"); noneMatchEtag == fileInfo.ETag {\n\t\t\tlog.LogErrorf(\"getObjectHandler: object eTag(%s) match If-None-Match header value(%s), requestId(%v)\",\n\t\t\t\tfileInfo.ETag, noneMatchEtag, GetRequestID(r))\n\t\t\treturn NotModified\n\t\t}\n\t}\n\t// Checking precondition: If-Unmodified-Since\n\t// Reference: https://docs.aws.amazon.com/AmazonS3/latest/API/API_GetObject.html#API_GetObject_RequestSyntax\n\tif unmodified != \"\" && match == \"\" {\n\t\tfileModTime := fileInfo.ModifyTime\n\t\tmodifiedTime, err := parseTimeRFC1123(unmodified)\n\t\tif err != nil {\n\t\t\tlog.LogErrorf(\"getObjectHandler: parse RFC1123 time fail: requestID(%v) err(%v)\", GetRequestID(r), err)\n\t\t\treturn InvalidArgument\n\t\t}\n\t\tif fileModTime.After(modifiedTime) {\n\t\t\tlog.LogInfof(\"getObjectHandler: file modified time after than specified time: requestID(%v)\", GetRequestID(r))\n\t\t\treturn PreconditionFailed\n\t\t}\n\t}\n\treturn nil\n}\n\n// Head object\n// API reference: https://docs.aws.amazon.com/AmazonS3/latest/API/API_HeadObject.html\nfunc (o *ObjectNode) headObjectHandler(w http.ResponseWriter, r *http.Request) {\n\tvar (\n\t\terr       error\n\t\terrorCode *ErrorCode\n\t)\n\tdefer func() {\n\t\to.errorResponse(w, r, err, errorCode)\n\t}()\n\n\t// check args\n\tvar param = ParseRequestParam(r)\n\tif param.Bucket() == \"\" {\n\t\terrorCode = InvalidBucketName\n\t\treturn\n\t}\n\tif param.Object() == \"\" {\n\t\terrorCode = InvalidKey\n\t\treturn\n\t}\n\n\tvar vol *Volume\n\tif vol, err = o.getVol(param.Bucket()); err != nil {\n\t\tlog.LogErrorf(\"headObjectHandler: load volume fail: requestID(%v) err(%v)\",\n\t\t\tGetRequestID(r), err)\n\t\treturn\n\t}\n\n\t// QPS and Concurrency Limit\n\trateLimit := o.AcquireRateLimiter()\n\tif err = rateLimit.AcquireLimitResource(vol.owner, param.apiName); err != nil {\n\t\treturn\n\t}\n\tdefer rateLimit.ReleaseLimitResource(vol.owner, param.apiName)\n\n\t// get object meta\n\tvar fileInfo *FSFileInfo\n\tfileInfo, _, err = vol.ObjectMeta(param.Object())\n\tif err != nil {\n\t\tlog.LogErrorf(\"headObjectHandler: get file meta fail: requestId(%v) volume(%v) path(%v) err(%v)\",\n\t\t\tGetRequestID(r), vol.Name(), param.Object(), err)\n\t\tif err == syscall.ENOENT {\n\t\t\terrorCode = NoSuchKey\n\t\t}\n\t\treturn\n\t}\n\n\t// parse request header\n\tmatch := r.Header.Get(IfMatch)\n\tnoneMatch := r.Header.Get(IfNoneMatch)\n\tmodified := r.Header.Get(IfModifiedSince)\n\tunmodified := r.Header.Get(IfUnmodifiedSince)\n\n\t// Checking precondition: If-Match\n\t// Reference: https://docs.aws.amazon.com/AmazonS3/latest/API/API_HeadObject.html#API_HeadObject_RequestSyntax\n\tif match != \"\" {\n\t\tif matchEag := strings.Trim(match, \"\\\"\"); matchEag != fileInfo.ETag {\n\t\t\tlog.LogDebugf(\"headObjectHandler: object eTag(%s) not match If-Match header value(%s), requestId(%v)\",\n\t\t\t\tfileInfo.ETag, matchEag, GetRequestID(r))\n\t\t\terrorCode = PreconditionFailed\n\t\t\treturn\n\t\t}\n\t}\n\t// Checking precondition: If-Modified-Since\n\t// Reference: https://docs.aws.amazon.com/AmazonS3/latest/API/API_HeadObject.html#API_HeadObject_RequestSyntax\n\tif modified != \"\" {\n\t\tfileModTime := fileInfo.ModifyTime\n\t\tmodifiedTime, err := parseTimeRFC1123(modified)\n\t\tif err != nil {\n\t\t\tlog.LogDebugf(\"headObjectHandler: parse RFC1123 time fail: requestID(%v) err(%v)\", GetRequestID(r), err)\n\t\t\terrorCode = InvalidArgument\n\t\t\treturn\n\t\t}\n\t\tif !fileModTime.After(modifiedTime) {\n\t\t\tlog.LogDebugf(\"headObjectHandler: file modified time not after than specified time: requestID(%v)\", GetRequestID(r))\n\t\t\terrorCode = NotModified\n\t\t\treturn\n\t\t}\n\t}\n\t// Checking precondition: If-None-Match\n\t// Reference: https://docs.aws.amazon.com/AmazonS3/latest/API/API_HeadObject.html#API_HeadObject_RequestSyntax\n\tif noneMatch != \"\" {\n\t\tif noneMatchEtag := strings.Trim(noneMatch, \"\\\"\"); noneMatchEtag == fileInfo.ETag {\n\t\t\tlog.LogDebugf(\"headObjectHandler: object eTag(%s) match If-None-Match header value(%s), requestId(%v)\",\n\t\t\t\tfileInfo.ETag, noneMatchEtag, GetRequestID(r))\n\t\t\terrorCode = NotModified\n\t\t\treturn\n\t\t}\n\t}\n\t// Checking precondition: If-Unmodified-Since\n\t// Reference: https://docs.aws.amazon.com/AmazonS3/latest/API/API_HeadObject.html#API_HeadObject_RequestSyntax\n\tif unmodified != \"\" && match == \"\" {\n\t\tfileModTime := fileInfo.ModifyTime\n\t\tmodifiedTime, err := parseTimeRFC1123(unmodified)\n\t\tif err != nil {\n\t\t\tlog.LogDebugf(\"headObjectHandler: parse RFC1123 time fail: requestID(%v) err(%v)\", GetRequestID(r), err)\n\t\t\terrorCode = InvalidArgument\n\t\t\treturn\n\t\t}\n\t\tif fileModTime.After(modifiedTime) {\n\t\t\tlog.LogDebugf(\"headObjectHandler: file modified time after than specified time: requestID(%v)\", GetRequestID(r))\n\t\t\terrorCode = PreconditionFailed\n\t\t\treturn\n\t\t}\n\t}\n\n\t// set response header\n\tw.Header().Set(AcceptRanges, ValueAcceptRanges)\n\tw.Header().Set(LastModified, formatTimeRFC1123(fileInfo.ModifyTime))\n\tw.Header().Set(ContentMD5, EmptyContentMD5String)\n\tif len(fileInfo.MIMEType) > 0 {\n\t\tw.Header().Set(ContentType, fileInfo.MIMEType)\n\t} else {\n\t\tw.Header().Set(ContentType, ValueContentTypeStream)\n\t}\n\tif len(fileInfo.Disposition) > 0 {\n\t\tw.Header().Set(ContentDisposition, fileInfo.Disposition)\n\t}\n\tif len(fileInfo.CacheControl) > 0 {\n\t\tw.Header().Set(CacheControl, fileInfo.CacheControl)\n\t}\n\tif len(fileInfo.Expires) > 0 {\n\t\tw.Header().Set(Expires, fileInfo.Expires)\n\t}\n\tif len(fileInfo.RetainUntilDate) > 0 {\n\t\tw.Header().Set(XAmzObjectLockMode, ComplianceMode)\n\t\tw.Header().Set(XAmzObjectLockRetainUntilDate, fileInfo.RetainUntilDate)\n\t}\n\n\t// check request is whether contain param : partNumber\n\tpartNumber := r.URL.Query().Get(ParamPartNumber)\n\tif len(partNumber) > 0 && fileInfo.Size >= MinParallelDownloadFileSize {\n\t\tpartNumberInt, err := strconv.ParseUint(partNumber, 10, 64)\n\t\tif err != nil {\n\t\t\tlog.LogErrorf(\"headObjectHandler: parse param partNumber(%s) fail: requestID(%v) err(%v)\", partNumber, GetRequestID(r), err)\n\t\t\terrorCode = InvalidArgument\n\t\t\treturn\n\t\t}\n\t\tpartSize, partCount, rangeLower, rangeUpper := parsePartInfo(partNumberInt, uint64(fileInfo.Size))\n\t\tlog.LogDebugf(\"headObjectHandler: parsed partSize(%d), partCount(%d), rangeLower(%d), rangeUpper(%d)\", partSize, partCount, rangeLower, rangeUpper)\n\t\tif partNumberInt > partCount {\n\t\t\tlog.LogErrorf(\"headObjectHandler: param partNumber(%d) is more then partCount(%d): requestID(%v)\", partNumberInt, partCount, GetRequestID(r))\n\t\t\terrorCode = NoSuchKey\n\t\t\treturn\n\t\t}\n\t\tw.Header().Set(ContentLength, strconv.Itoa(int(partSize)))\n\t\tw.Header().Set(ContentRange, fmt.Sprintf(\"bytes %d-%d/%d\", rangeLower, rangeUpper, fileInfo.Size))\n\t\tw.Header().Set(XAmzMpPartsCount, strconv.Itoa(int(partCount)))\n\t\tif len(fileInfo.ETag) > 0 && !strings.Contains(fileInfo.ETag, \"-\") {\n\t\t\tw.Header()[ETag] = []string{fmt.Sprintf(\"%s-%d\", fileInfo.ETag, partCount)}\n\t\t}\n\t} else {\n\t\tw.Header().Set(ContentLength, strconv.Itoa(int(fileInfo.Size)))\n\t\tif len(fileInfo.ETag) > 0 {\n\t\t\tw.Header()[ETag] = []string{wrapUnescapedQuot(fileInfo.ETag)}\n\t\t}\n\t}\n\n\t// User-defined metadata\n\tfor name, value := range fileInfo.Metadata {\n\t\tw.Header().Set(XAmzMetaPrefix+name, value)\n\t}\n\n\treturn\n}\n\n// Delete objects (multiple objects)\n// API reference: https://docs.aws.amazon.com/AmazonS3/latest/API/API_DeleteObjects.html\nfunc (o *ObjectNode) deleteObjectsHandler(w http.ResponseWriter, r *http.Request) {\n\tvar (\n\t\terr       error\n\t\terrorCode *ErrorCode\n\t)\n\tdefer func() {\n\t\to.errorResponse(w, r, err, errorCode)\n\t}()\n\n\tvar param = ParseRequestParam(r)\n\tif param.Bucket() == \"\" {\n\t\terrorCode = InvalidBucketName\n\t\treturn\n\t}\n\n\tvar vol *Volume\n\tif vol, err = o.getVol(param.Bucket()); err != nil {\n\t\tlog.LogErrorf(\"deleteObjectsHandler: load volume fail: requestID(%v) volume(%v) err(%v)\",\n\t\t\tGetRequestID(r), param.Bucket(), err)\n\t\treturn\n\t}\n\n\trequestMD5 := r.Header.Get(ContentMD5)\n\tif requestMD5 == \"\" {\n\t\terrorCode = MissingContentMD5\n\t\treturn\n\t}\n\n\tvar bytes []byte\n\tbytes, err = ioutil.ReadAll(r.Body)\n\tif err != nil {\n\t\tlog.LogErrorf(\"deleteObjectsHandler: read request body fail: requestID(%v) volume(%v) err(%v)\",\n\t\t\tGetRequestID(r), param.Bucket(), err)\n\t\terrorCode = UnexpectedContent\n\t\treturn\n\t}\n\tif requestMD5 != GetMD5(bytes) {\n\t\terrorCode = BadDigest\n\t\treturn\n\t}\n\n\tdeleteReq := DeleteRequest{}\n\terr = UnmarshalXMLEntity(bytes, &deleteReq)\n\tif err != nil {\n\t\tlog.LogErrorf(\"deleteObjectsHandler: unmarshal xml fail: requestID(%v) volume(%v) request(%v) err(%v)\",\n\t\t\tGetRequestID(r), param.Bucket(), string(bytes), err)\n\t\terrorCode = MalformedXML\n\t\treturn\n\t}\n\tif len(deleteReq.Objects) > 1000 {\n\t\terrorCode = EntityTooLarge\n\t\treturn\n\t}\n\n\t// Sort the key values in reverse order.\n\t// The purpose of this is to delete the child leaf first and then the parent node.\n\t// Source:\n\t//  0. backup/\n\t//  1. backup/20200101.bak\n\t//  2. backup/20200102.bak\n\t// Result:\n\t//  0. backup/20200102.bak\n\t//  1. backup/20200101.bak\n\t//  2. backup/\n\tsort.SliceStable(deleteReq.Objects, func(i, j int) bool {\n\t\treturn deleteReq.Objects[i].Key > deleteReq.Objects[j].Key\n\t})\n\n\tvol, acl, policy, err := o.loadBucketMeta(param.Bucket())\n\tif err != nil {\n\t\tlog.LogErrorf(\"deleteObjectsHandler: load bucket metadata fail: requestID(%v) volume(%v) err(%v)\",\n\t\t\tGetRequestID(r), param.Bucket(), err)\n\t\treturn\n\t}\n\n\tuserInfo, err := o.getUserInfoByAccessKeyV2(param.AccessKey())\n\tif err != nil {\n\t\tlog.LogErrorf(\"deleteObjectsHandler: get userinfo fail: requestID(%v) volume(%v) accessKey(%v) err(%v)\",\n\t\t\tGetRequestID(r), param.Bucket(), param.AccessKey(), err)\n\t\treturn\n\t}\n\n\tallowByAcl := false\n\tif acl == nil && userInfo.UserID == vol.owner {\n\t\tallowByAcl = true\n\t}\n\tif acl != nil && acl.IsAllowed(userInfo.UserID, param.Action()) {\n\t\tallowByAcl = true\n\t}\n\n\tdeletedObjects := make([]Deleted, 0, len(deleteReq.Objects))\n\tdeletedErrors := make([]Error, 0)\n\tobjectKeys := make([]string, 0, len(deleteReq.Objects))\n\tfor _, object := range deleteReq.Objects {\n\t\tresult := POLICY_UNKNOW\n\t\tif policy != nil && !policy.IsEmpty() {\n\t\t\tlog.LogDebugf(\"deleteObjectsHandler: policy check: requestID(%v) volume(%v) path(%v) policy(%v)\",\n\t\t\t\tGetRequestID(r), param.Bucket(), object.Key, policy)\n\t\t\tconditionCheck := map[string]string{\n\t\t\t\tSOURCEIP: param.sourceIP,\n\t\t\t\tREFERER:  param.r.Referer(),\n\t\t\t\tKEYNAME:  object.Key,\n\t\t\t\tHOST:     param.r.Host,\n\t\t\t}\n\t\t\tresult = policy.IsAllowed(param, userInfo.UserID, vol.owner, conditionCheck)\n\t\t}\n\t\tif result == POLICY_DENY || (result == POLICY_UNKNOW && !allowByAcl) {\n\t\t\tdeletedErrors = append(deletedErrors, Error{\n\t\t\t\tKey:     object.Key,\n\t\t\t\tCode:    \"AccessDenied\",\n\t\t\t\tMessage: \"Not Allowed By Policy\",\n\t\t\t})\n\t\t\tcontinue\n\t\t}\n\t\tobjectKeys = append(objectKeys, object.Key)\n\t\tlog.LogWarnf(\"deleteObjectsHandler: delete path: requestID(%v) remote(%v) volume(%v) path(%v)\",\n\t\t\tGetRequestID(r), getRequestIP(r), vol.Name(), object.Key)\n\t\t// QPS and Concurrency Limit\n\t\trateLimit := o.AcquireRateLimiter()\n\t\tif err = rateLimit.AcquireLimitResource(vol.owner, DELETE_OBJECT); err != nil {\n\t\t\treturn\n\t\t}\n\t\tif err1 := vol.DeletePath(object.Key); err1 != nil {\n\t\t\tlog.LogErrorf(\"deleteObjectsHandler: delete object failed: requestID(%v) volume(%v) path(%v) err(%v)\",\n\t\t\t\tGetRequestID(r), vol.Name(), object.Key, err1)\n\t\t\tif !strings.Contains(err1.Error(), AccessDenied.ErrorMessage) {\n\t\t\t\tdeletedErrors = append(deletedErrors, Error{Key: object.Key, Code: \"InternalError\", Message: err1.Error()})\n\t\t\t} else {\n\t\t\t\tdeletedErrors = append(deletedErrors, Error{Key: object.Key, Code: \"AccessDenied\", Message: err1.Error()})\n\t\t\t}\n\t\t} else {\n\t\t\tlog.LogDebugf(\"deleteObjectsHandler: delete object success: requestID(%v) volume(%v) path(%v)\",\n\t\t\t\tGetRequestID(r), vol.Name(), object.Key)\n\t\t\tdeletedObjects = append(deletedObjects, Deleted{Key: object.Key})\n\t\t}\n\t\trateLimit.ReleaseLimitResource(vol.owner, param.apiName)\n\t}\n\n\tdeleteResult := DeleteResult{\n\t\tDeleted: deletedObjects,\n\t\tError:   deletedErrors,\n\t}\n\tresponse, err1 := MarshalXMLEntity(deleteResult)\n\tif err1 != nil {\n\t\tlog.LogErrorf(\"deleteObjectsHandler: xml marshal fail: requestID(%v) volume(%v) result(%+v) err(%v)\",\n\t\t\tGetRequestID(r), param.Bucket(), deleteResult, err1)\n\t}\n\n\twriteSuccessResponseXML(w, response)\n\treturn\n}\n\nfunc extractSrcBucketKey(r *http.Request) (srcBucketId, srcKey, versionId string, err error) {\n\tcopySource := r.Header.Get(XAmzCopySource)\n\tcopySource, err = url.QueryUnescape(copySource)\n\tif err != nil {\n\t\treturn \"\", \"\", \"\", InvalidArgument\n\t}\n\t// path could be /bucket/key or bucket/key\n\tcopySource = strings.TrimPrefix(copySource, \"/\")\n\telements := strings.SplitN(copySource, \"?versionId=\", 2)\n\tif len(elements) == 1 {\n\t\tversionId = \"\"\n\t} else {\n\t\tversionId = elements[1]\n\t}\n\tpath := strings.SplitN(elements[0], \"/\", 2)\n\tif len(path) == 1 {\n\t\treturn \"\", \"\", \"\", InvalidArgument\n\t}\n\tsrcBucketId, srcKey = path[0], path[1]\n\tif srcBucketId == \"\" || srcKey == \"\" {\n\t\treturn \"\", \"\", \"\", InvalidArgument\n\t}\n\treturn\n}\n\n// Copy object\n// API reference: https://docs.aws.amazon.com/AmazonS3/latest/API/API_CopyObject.html .\nfunc (o *ObjectNode) copyObjectHandler(w http.ResponseWriter, r *http.Request) {\n\tvar err error\n\tvar errorCode *ErrorCode\n\tdefer func() {\n\t\to.errorResponse(w, r, err, errorCode)\n\t}()\n\n\tvar param = ParseRequestParam(r)\n\tif param.Bucket() == \"\" {\n\t\terrorCode = InvalidBucketName\n\t\treturn\n\t}\n\tif param.Object() == \"\" {\n\t\terrorCode = InvalidKey\n\t\treturn\n\t}\n\tif len(param.Object()) > MaxKeyLength {\n\t\terrorCode = KeyTooLong\n\t\treturn\n\t}\n\tvar vol *Volume\n\tif vol, err = o.getVol(param.Bucket()); err != nil {\n\t\tlog.LogErrorf(\"copyObjectHandler: load volume fail: requestID(%v) volume(%v) err(%v)\",\n\t\t\tGetRequestID(r), param.Bucket(), err)\n\t\treturn\n\t}\n\n\t// QPS and Concurrency Limit\n\trateLimit := o.AcquireRateLimiter()\n\tif err = rateLimit.AcquireLimitResource(vol.owner, param.apiName); err != nil {\n\t\treturn\n\t}\n\tdefer rateLimit.ReleaseLimitResource(vol.owner, param.apiName)\n\n\t// client can reset these system metadata: Content-Type, Content-Disposition\n\tcontentType := r.Header.Get(ContentType)\n\tcontentDisposition := r.Header.Get(ContentDisposition)\n\tcacheControl := r.Header.Get(CacheControl)\n\tif len(cacheControl) > 0 && !ValidateCacheControl(cacheControl) {\n\t\terrorCode = InvalidCacheArgument\n\t\treturn\n\t}\n\texpires := r.Header.Get(Expires)\n\tif len(expires) > 0 && !ValidateCacheExpires(expires) {\n\t\terrorCode = InvalidCacheArgument\n\t\treturn\n\t}\n\n\t// metadata directive, direct object node use source file metadata or recreate metadata for target file\n\tmetadataDirective := r.Header.Get(XAmzMetadataDirective)\n\t// metadata directive default value is COPY\n\tif len(metadataDirective) == 0 {\n\t\tmetadataDirective = MetadataDirectiveCopy\n\t}\n\tif metadataDirective != MetadataDirectiveCopy && metadataDirective != MetadataDirectiveReplace {\n\t\tlog.LogErrorf(\"copyObjectHandler: x-amz-metadata-directive invalid: requestID(%v) volume(%v) x-amz-metadata-directive(%v) err(%v)\",\n\t\t\tGetRequestID(r), param.Bucket(), metadataDirective, err)\n\t\terrorCode = InvalidArgument\n\t\treturn\n\t}\n\t// parse x-amz-copy-source header\n\tsourceBucket, sourceObject, _, err := extractSrcBucketKey(r)\n\tif err != nil {\n\t\tlog.LogErrorf(\"copyObjectHandler: copySource(%v) argument invalid: requestID(%v) volume(%v) err(%v)\",\n\t\t\tr.Header.Get(XAmzCopySource), GetRequestID(r), param.Bucket(), err)\n\t\treturn\n\t}\n\n\t// check ACL\n\tuserInfo, err := o.getUserInfoByAccessKeyV2(param.AccessKey())\n\tif err != nil {\n\t\tlog.LogErrorf(\"copyObjectHandler: get user info fail: requestID(%v) volume(%v) accessKey(%v) err(%v)\",\n\t\t\tGetRequestID(r), param.Bucket(), param.AccessKey(), err)\n\t\treturn\n\t}\n\tacl, err := ParseACL(r, userInfo.UserID, false, vol.GetOwner() != userInfo.UserID)\n\tif err != nil {\n\t\tlog.LogErrorf(\"copyObjectHandler: parse acl fail: requestID(%v) volume(%v) acl(%+v) err(%v)\",\n\t\t\tGetRequestID(r), param.Bucket(), acl, err)\n\t\treturn\n\t}\n\n\t// get src object meta\n\tvar sourceVol *Volume\n\tif sourceVol, err = o.getVol(sourceBucket); err != nil {\n\t\tlog.LogErrorf(\"copyObjectHandler: load source volume fail: requestID(%v) srcVolume(%v) err(%v)\",\n\t\t\tGetRequestID(r), sourceBucket, err)\n\t\treturn\n\t}\n\tvar fileInfo *FSFileInfo\n\tfileInfo, _, err = sourceVol.ObjectMeta(sourceObject)\n\tif err != nil {\n\t\tlog.LogErrorf(\"copyObjectHandler: get object meta fail: requestID(%v) srcVolume(%v) srcObject(%v) err(%v)\",\n\t\t\tGetRequestID(r), sourceBucket, sourceObject, err)\n\t\tif err == syscall.ENOENT {\n\t\t\terrorCode = NoSuchKey\n\t\t}\n\t\treturn\n\t}\n\tif fileInfo.Size > SinglePutLimit {\n\t\terrorCode = EntityTooLarge\n\t\treturn\n\t}\n\tif fileInfo.Size > SinglePutLimit {\n\t\terrorCode = EntityTooLarge\n\t\treturn\n\t}\n\n\t// get header\n\tcopyMatch := r.Header.Get(XAmzCopySourceIfMatch)\n\tnoneMatch := r.Header.Get(XAmzCopySourceIfNoneMatch)\n\tmodified := r.Header.Get(XAmzCopySourceIfModifiedSince)\n\tunModified := r.Header.Get(XAmzCopySourceIfUnmodifiedSince)\n\n\t// response 412\n\tif modified != \"\" {\n\t\tfileModTime := fileInfo.ModifyTime\n\t\tmodifiedTime, err := parseTimeRFC1123(modified)\n\t\tif err != nil {\n\t\t\tlog.LogErrorf(\"copyObjectHandler: parse RFC1123 time fail: requestID(%v) err(%v)\", GetRequestID(r), err)\n\t\t\terrorCode = InvalidArgument\n\t\t\treturn\n\t\t}\n\t\tif fileModTime.Before(modifiedTime) {\n\t\t\tlog.LogInfof(\"copyObjectHandler: file modified time not after than specified time: requestID(%v)\", GetRequestID(r))\n\t\t\terrorCode = PreconditionFailed\n\t\t\treturn\n\t\t}\n\t}\n\tif unModified != \"\" {\n\t\tfileModTime := fileInfo.ModifyTime\n\t\tunmodifiedTime, err := parseTimeRFC1123(unModified)\n\t\tif err != nil {\n\t\t\tlog.LogErrorf(\"copyObjectHandler: parse RFC1123 time fail: requestID(%v) err(%v)\", GetRequestID(r), err)\n\t\t\terrorCode = InvalidArgument\n\t\t\treturn\n\t\t}\n\t\tif fileModTime.After(unmodifiedTime) {\n\t\t\tlog.LogInfof(\"copyObjectHandler: file modified time not before than specified time: requestID(%v)\", GetRequestID(r))\n\t\t\terrorCode = PreconditionFailed\n\t\t\treturn\n\t\t}\n\t}\n\tif copyMatch != \"\" && fileInfo.ETag != copyMatch {\n\t\tlog.LogInfof(\"copyObjectHandler: eTag mismatched with specified: requestID(%v)\", GetRequestID(r))\n\t\terrorCode = PreconditionFailed\n\t\treturn\n\t}\n\tif noneMatch != \"\" && fileInfo.ETag == noneMatch {\n\t\tlog.LogInfof(\"copyObjectHandler: eTag same with specified: requestID(%v)\", GetRequestID(r))\n\t\terrorCode = PreconditionFailed\n\t\treturn\n\t}\n\n\t// ObjectLock  Config\n\tobjetLock, err := vol.metaLoader.loadObjectLock()\n\tif err != nil {\n\t\tlog.LogErrorf(\"copyObjectHandler: load volume objetLock: requestID(%v)  volume(%v) err(%v)\",\n\t\t\tGetRequestID(r), param.Bucket(), err)\n\t\treturn\n\t}\n\n\t// parse user-defined metadata\n\tmetadata := ParseUserDefinedMetadata(r.Header)\n\t// copy file\n\topt := &PutFileOption{\n\t\tMIMEType:     contentType,\n\t\tDisposition:  contentDisposition,\n\t\tMetadata:     metadata,\n\t\tCacheControl: cacheControl,\n\t\tExpires:      expires,\n\t\tACL:          acl,\n\t\tObjectLock:   objetLock,\n\t}\n\tfsFileInfo, err := vol.CopyFile(sourceVol, sourceObject, param.Object(), metadataDirective, opt)\n\tif err != nil && err != syscall.EINVAL && err != syscall.EFBIG {\n\t\tlog.LogErrorf(\"copyObjectHandler: Volume copy file fail: requestID(%v) Volume(%v) source(%v) target(%v) err(%v)\",\n\t\t\tGetRequestID(r), param.Bucket(), sourceObject, param.Object(), err)\n\t\treturn\n\t}\n\tif err == syscall.EINVAL {\n\t\tlog.LogErrorf(\"copyObjectHandler: target file existed, and mode conflict: requestID(%v) Volume(%v) source(%v) target(%v) err(%v)\",\n\t\t\tGetRequestID(r), param.Bucket(), sourceObject, param.Object(), err)\n\t\terrorCode = ObjectModeConflict\n\t\treturn\n\t}\n\tif err == syscall.EFBIG {\n\t\tlog.LogErrorf(\"copyObjectHandler: source file size greater than 5GB: requestID(%v) Volume(%v) source(%v) target(%v) err(%v)\",\n\t\t\tGetRequestID(r), param.Bucket(), sourceObject, param.Object(), err)\n\t\terrorCode = CopySourceSizeTooLarge\n\t\treturn\n\t}\n\n\tcopyResult := CopyResult{\n\t\tETag:         \"\\\"\" + fsFileInfo.ETag + \"\\\"\",\n\t\tLastModified: formatTimeISO(fsFileInfo.ModifyTime),\n\t}\n\tresponse, err := MarshalXMLEntity(copyResult)\n\tif err != nil {\n\t\tlog.LogErrorf(\"copyObjectHandler: marshal xml entity fail: requestID(%v) err(%v)\", GetRequestID(r), err)\n\t\treturn\n\t}\n\n\twriteSuccessResponseXML(w, response)\n\treturn\n}\n\n// List objects v1\n// API reference: https://docs.aws.amazon.com/AmazonS3/latest/API/API_ListObjects.html\nfunc (o *ObjectNode) getBucketV1Handler(w http.ResponseWriter, r *http.Request) {\n\tvar err error\n\tvar errorCode *ErrorCode\n\tdefer func() {\n\t\to.errorResponse(w, r, err, errorCode)\n\t}()\n\n\tvar param = ParseRequestParam(r)\n\tif param.Bucket() == \"\" {\n\t\terrorCode = InvalidBucketName\n\t\treturn\n\t}\n\tvar vol *Volume\n\tif vol, err = o.getVol(param.Bucket()); err != nil {\n\t\tlog.LogErrorf(\"getBucketV1Handler: load volume fail: requestID(%v) volume(%v) err(%v)\",\n\t\t\tGetRequestID(r), param.Bucket(), err)\n\t\treturn\n\t}\n\n\t// QPS and Concurrency Limit\n\trateLimit := o.AcquireRateLimiter()\n\tif err = rateLimit.AcquireLimitResource(vol.owner, param.apiName); err != nil {\n\t\treturn\n\t}\n\tdefer rateLimit.ReleaseLimitResource(vol.owner, param.apiName)\n\n\t// get options\n\tmarker := r.URL.Query().Get(ParamMarker)\n\tprefix := r.URL.Query().Get(ParamPrefix)\n\tmaxKeys := r.URL.Query().Get(ParamMaxKeys)\n\tdelimiter := r.URL.Query().Get(ParamPartDelimiter)\n\tencodingType := r.URL.Query().Get(ParamEncodingType)\n\n\tvar maxKeysInt uint64\n\tif maxKeys != \"\" {\n\t\tmaxKeysInt, err = strconv.ParseUint(maxKeys, 10, 16)\n\t\tif err != nil {\n\t\t\tlog.LogErrorf(\"getBucketV1Handler: parse max key fail: requestID(%v) volume(%v) maxKeys(%v) err(%v)\",\n\t\t\t\tGetRequestID(r), vol.Name(), maxKeys, err)\n\t\t\terrorCode = InvalidArgument\n\t\t\treturn\n\t\t}\n\t\tif maxKeysInt > MaxKeys {\n\t\t\tmaxKeysInt = MaxKeys\n\t\t}\n\t} else {\n\t\tmaxKeysInt = uint64(MaxKeys)\n\t}\n\n\t// Validate encoding type option\n\tif encodingType != \"\" && encodingType != \"url\" {\n\t\terrorCode = InvalidArgument\n\t\treturn\n\t}\n\n\tif marker != \"\" && prefix != \"\" && !strings.HasPrefix(marker, prefix) {\n\t\terrorCode = InvalidArgument\n\t\treturn\n\t}\n\n\tvar option = &ListFilesV1Option{\n\t\tPrefix:     prefix,\n\t\tDelimiter:  delimiter,\n\t\tMarker:     marker,\n\t\tMaxKeys:    maxKeysInt,\n\t\tOnlyObject: true,\n\t}\n\n\tvar result *ListFilesV1Result\n\tresult, err = vol.ListFilesV1(option)\n\tif err != nil {\n\t\tlog.LogErrorf(\"getBucketV1Handler: list files fail: requestID(%v) volume(%v) option(%v) err(%v)\",\n\t\t\tGetRequestID(r), vol.Name(), option, err)\n\t\treturn\n\t}\n\t// The result of next list request should not include nextMarker.\n\tif result.Truncated && len(result.Files) != 0 {\n\t\tresult.NextMarker = result.Files[len(result.Files)-1].Path\n\t}\n\n\t// get owner\n\tvar bucketOwner = NewBucketOwner(vol)\n\tlog.LogDebugf(\"Owner: %v\", bucketOwner)\n\tvar contents = make([]*Content, 0, len(result.Files))\n\tfor _, file := range result.Files {\n\t\tif file.Mode == 0 {\n\t\t\t// Invalid file mode, which means that the inode of the file may not exist.\n\t\t\t// Record and filter out the file.\n\t\t\tlog.LogWarnf(\"getBucketV1Handler: invalid file found: requestID(%v) volume(%v) path(%v) inode(%v)\",\n\t\t\t\tGetRequestID(r), vol.Name(), file.Path, file.Inode)\n\t\t\tcontinue\n\t\t}\n\t\tcontent := &Content{\n\t\t\tKey:          encodeKey(file.Path, encodingType),\n\t\t\tLastModified: formatTimeISO(file.ModifyTime),\n\t\t\tETag:         wrapUnescapedQuot(file.ETag),\n\t\t\tSize:         int(file.Size),\n\t\t\tStorageClass: StorageClassStandard,\n\t\t\tOwner:        bucketOwner,\n\t\t}\n\t\tcontents = append(contents, content)\n\t}\n\n\tvar commonPrefixes = make([]*CommonPrefix, 0)\n\tfor _, prefix := range result.CommonPrefixes {\n\t\tcommonPrefix := &CommonPrefix{\n\t\t\tPrefix: prefix,\n\t\t}\n\t\tcommonPrefixes = append(commonPrefixes, commonPrefix)\n\t}\n\n\tlistBucketResult := &ListBucketResult{\n\t\tBucket:         param.Bucket(),\n\t\tPrefix:         prefix,\n\t\tMarker:         marker,\n\t\tMaxKeys:        int(maxKeysInt),\n\t\tDelimiter:      delimiter,\n\t\tIsTruncated:    result.Truncated,\n\t\tNextMarker:     result.NextMarker,\n\t\tContents:       contents,\n\t\tCommonPrefixes: commonPrefixes,\n\t}\n\tresponse, err := MarshalXMLEntity(listBucketResult)\n\tif err != nil {\n\t\tlog.LogErrorf(\"getBucketV1Handler: xml marshal result fail: requestID(%v) volume(%v) err(%v)\",\n\t\t\tGetRequestID(r), vol.Name(), err)\n\t\treturn\n\t}\n\n\twriteSuccessResponseXML(w, response)\n\treturn\n}\n\n// List objects version 2\n// API reference: https://docs.aws.amazon.com/AmazonS3/latest/API/API_ListObjectsV2.html\nfunc (o *ObjectNode) getBucketV2Handler(w http.ResponseWriter, r *http.Request) {\n\tvar err error\n\tvar errorCode *ErrorCode\n\tdefer func() {\n\t\to.errorResponse(w, r, err, errorCode)\n\t}()\n\n\tvar param = ParseRequestParam(r)\n\tif param.Bucket() == \"\" {\n\t\terrorCode = InvalidBucketName\n\t\treturn\n\t}\n\tvar vol *Volume\n\tif vol, err = o.getVol(param.Bucket()); err != nil {\n\t\tlog.LogErrorf(\"getBucketV2Handler: load volume fail: requestID(%v) volume(%v) err(%v)\",\n\t\t\tGetRequestID(r), param.Bucket(), err)\n\t\treturn\n\t}\n\n\t// QPS and Concurrency Limit\n\trateLimit := o.AcquireRateLimiter()\n\tif err = rateLimit.AcquireLimitResource(vol.owner, param.apiName); err != nil {\n\t\treturn\n\t}\n\tdefer rateLimit.ReleaseLimitResource(vol.owner, param.apiName)\n\n\t// get options\n\tprefix := r.URL.Query().Get(ParamPrefix)\n\tmaxKeys := r.URL.Query().Get(ParamMaxKeys)\n\tdelimiter := r.URL.Query().Get(ParamPartDelimiter)\n\tcontToken := r.URL.Query().Get(ParamContToken)\n\tfetchOwner := r.URL.Query().Get(ParamFetchOwner)\n\tstartAfter := r.URL.Query().Get(ParamStartAfter)\n\tencodingType := r.URL.Query().Get(ParamEncodingType)\n\n\tvar maxKeysInt uint64\n\tif maxKeys != \"\" {\n\t\tmaxKeysInt, err = strconv.ParseUint(maxKeys, 10, 16)\n\t\tif err != nil {\n\t\t\tlog.LogErrorf(\"getBucketV2Handler: parse max keys fail: requestID(%v) volume(%v) maxKeys(%v) err(%v)\",\n\t\t\t\tGetRequestID(r), vol.Name(), maxKeys, err)\n\t\t\terrorCode = InvalidArgument\n\t\t\treturn\n\t\t}\n\t\tif maxKeysInt > MaxKeys {\n\t\t\tmaxKeysInt = MaxKeys\n\t\t}\n\t} else {\n\t\tmaxKeysInt = MaxKeys\n\t}\n\n\tvar fetchOwnerBool bool\n\tif fetchOwner != \"\" {\n\t\tfetchOwnerBool, err = strconv.ParseBool(fetchOwner)\n\t\tif err != nil {\n\t\t\tlog.LogErrorf(\"getBucketV2Handler: parse fetch owner fail: requestID(%v) volume(%v) fetchOwner(%v) err(%v)\",\n\t\t\t\tGetRequestID(r), vol.Name(), fetchOwner, err)\n\t\t\terrorCode = InvalidArgument\n\t\t\treturn\n\t\t}\n\t} else {\n\t\tfetchOwnerBool = false\n\t}\n\n\t// Validate encoding type option\n\tif encodingType != \"\" && encodingType != \"url\" {\n\t\terrorCode = InvalidArgument\n\t\treturn\n\t}\n\n\tvar marker string\n\tif contToken != \"\" {\n\t\tmarker = contToken\n\t} else {\n\t\tmarker = startAfter\n\t}\n\tif marker != \"\" && prefix != \"\" && !strings.HasPrefix(marker, prefix) {\n\t\terrorCode = InvalidArgument\n\t\treturn\n\t}\n\n\tvar option = &ListFilesV2Option{\n\t\tDelimiter:  delimiter,\n\t\tMaxKeys:    maxKeysInt,\n\t\tPrefix:     prefix,\n\t\tContToken:  contToken,\n\t\tFetchOwner: fetchOwnerBool,\n\t\tStartAfter: startAfter,\n\t}\n\n\tvar result *ListFilesV2Result\n\tresult, err = vol.ListFilesV2(option)\n\tif err != nil {\n\t\tlog.LogErrorf(\"getBucketV2Handler: list files fail, requestID(%v) volume(%v) option(%v) err(%v)\",\n\t\t\tGetRequestID(r), vol.Name(), option, err)\n\t\treturn\n\t}\n\t// The result of next list request should not include continuationToken.\n\tif result.Truncated && len(result.Files) > 0 {\n\t\tresult.NextToken = result.Files[len(result.Files)-1].Path\n\t}\n\n\t// get owner\n\tvar bucketOwner *BucketOwner\n\tif fetchOwnerBool {\n\t\tbucketOwner = NewBucketOwner(vol)\n\t}\n\n\tvar contents = make([]*Content, 0)\n\tif len(result.Files) > 0 {\n\t\tfor _, file := range result.Files {\n\t\t\tif file.Mode == 0 {\n\t\t\t\t// Invalid file mode, which means that the inode of the file may not exist.\n\t\t\t\t// Record and filter out the file.\n\t\t\t\tlog.LogWarnf(\"getBucketV2Handler: invalid file found: requestID(%v) volume(%v) path(%v) inode(%v)\",\n\t\t\t\t\tGetRequestID(r), vol.Name(), file.Path, file.Inode)\n\t\t\t\tresult.KeyCount--\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tcontent := &Content{\n\t\t\t\tKey:          encodeKey(file.Path, encodingType),\n\t\t\t\tLastModified: formatTimeISO(file.ModifyTime),\n\t\t\t\tETag:         wrapUnescapedQuot(file.ETag),\n\t\t\t\tSize:         int(file.Size),\n\t\t\t\tStorageClass: StorageClassStandard,\n\t\t\t\tOwner:        bucketOwner,\n\t\t\t}\n\t\t\tcontents = append(contents, content)\n\t\t}\n\t}\n\n\tvar commonPrefixes = make([]*CommonPrefix, 0)\n\tfor _, prefix := range result.CommonPrefixes {\n\t\tcommonPrefix := &CommonPrefix{\n\t\t\tPrefix: prefix,\n\t\t}\n\t\tcommonPrefixes = append(commonPrefixes, commonPrefix)\n\t}\n\n\tlistBucketResult := ListBucketResultV2{\n\t\tName:           param.Bucket(),\n\t\tPrefix:         prefix,\n\t\tToken:          contToken,\n\t\tNextToken:      result.NextToken,\n\t\tKeyCount:       result.KeyCount,\n\t\tMaxKeys:        maxKeysInt,\n\t\tDelimiter:      delimiter,\n\t\tIsTruncated:    result.Truncated,\n\t\tContents:       contents,\n\t\tCommonPrefixes: commonPrefixes,\n\t}\n\tresponse, err := MarshalXMLEntity(listBucketResult)\n\tif err != nil {\n\t\tlog.LogErrorf(\"getBucketV2Handler: xml marshal result fail: requestID(%v) volume(%v) err(%v)\",\n\t\t\tGetRequestID(r), vol.Name(), err)\n\t\treturn\n\t}\n\n\twriteSuccessResponseXML(w, response)\n\treturn\n}\n\n// Put object\n// API reference: https://docs.aws.amazon.com/AmazonS3/latest/API/API_PutObject.html\nfunc (o *ObjectNode) putObjectHandler(w http.ResponseWriter, r *http.Request) {\n\tvar err error\n\tvar errorCode *ErrorCode\n\tdefer func() {\n\t\to.errorResponse(w, r, err, errorCode)\n\t}()\n\n\tvar param = ParseRequestParam(r)\n\tif param.Bucket() == \"\" {\n\t\terrorCode = InvalidBucketName\n\t\treturn\n\t}\n\tif param.Object() == \"\" {\n\t\terrorCode = InvalidKey\n\t\treturn\n\t}\n\tif len(param.Object()) > MaxKeyLength {\n\t\terrorCode = KeyTooLong\n\t\treturn\n\t}\n\tvar vol *Volume\n\tif vol, err = o.getVol(param.Bucket()); err != nil {\n\t\tlog.LogErrorf(\"putObjectHandler: load volume fail: requestID(%v)  volume(%v) err(%v)\",\n\t\t\tGetRequestID(r), param.Bucket(), err)\n\t\treturn\n\t}\n\n\t// Get request MD5, if request MD5 is not empty, compute and verify it.\n\trequestMD5 := r.Header.Get(ContentMD5)\n\tif requestMD5 != \"\" {\n\t\tdecoded, err := base64.StdEncoding.DecodeString(requestMD5)\n\t\tif err != nil {\n\t\t\terrorCode = InvalidDigest\n\t\t\treturn\n\t\t}\n\t\trequestMD5 = hex.EncodeToString(decoded)\n\t}\n\n\t// ObjectLock  Config\n\tobjetLock, err := vol.metaLoader.loadObjectLock()\n\tif err != nil {\n\t\tlog.LogErrorf(\"putObjectHandler: load volume objetLock: requestID(%v)  volume(%v) err(%v)\",\n\t\t\tGetRequestID(r), param.Bucket(), err)\n\t\treturn\n\t}\n\tif objetLock != nil && objetLock.ToRetention() != nil && requestMD5 == \"\" {\n\t\terrorCode = NoContentMd5HeaderErr\n\t\treturn\n\t}\n\n\t// QPS and Concurrency Limit\n\trateLimit := o.AcquireRateLimiter()\n\tif err = rateLimit.AcquireLimitResource(vol.owner, param.apiName); err != nil {\n\t\treturn\n\t}\n\tdefer rateLimit.ReleaseLimitResource(vol.owner, param.apiName)\n\n\t// Check 'x-amz-tagging' header\n\t// Reference: https://docs.aws.amazon.com/AmazonS3/latest/API/API_PutObject.html#API_PutObject_RequestSyntax\n\tvar tagging *Tagging\n\tif xAmxTagging := r.Header.Get(XAmzTagging); xAmxTagging != \"\" {\n\t\tif tagging, err = ParseTagging(xAmxTagging); err != nil {\n\t\t\terrorCode = InvalidArgument\n\t\t\treturn\n\t\t}\n\t\tvar validateRes bool\n\t\tif validateRes, errorCode = tagging.Validate(); !validateRes {\n\t\t\tlog.LogErrorf(\"putObjectHandler: tagging validate fail: requestID(%v) volume(%v) path(%v) tagging(%v) err(%v)\",\n\t\t\t\tGetRequestID(r), vol.Name(), param.Object(), tagging, errorCode)\n\t\t\treturn\n\t\t}\n\t}\n\n\tvar userInfo *proto.UserInfo\n\tif userInfo, err = o.getUserInfoByAccessKeyV2(param.AccessKey()); err != nil {\n\t\tlog.LogErrorf(\"putObjectHandler: get user info fail: requestID(%v) volume(%v) accessKey(%v) err(%v)\",\n\t\t\tGetRequestID(r), param.Bucket(), param.AccessKey(), err)\n\t\treturn\n\t}\n\n\t// Check ACL\n\tacl, err := ParseACL(r, userInfo.UserID, false, vol.GetOwner() != userInfo.UserID)\n\tif err != nil {\n\t\tlog.LogErrorf(\"putObjectHandler: parse acl fail: requestID(%v) volume(%v) path(%v) acl(%+v) err(%v)\",\n\t\t\tGetRequestID(r), vol.Name(), param.Object(), acl, err)\n\t\treturn\n\t}\n\n\t// Verify ContentLength\n\tlength := GetContentLength(r)\n\tif length > SinglePutLimit {\n\t\terrorCode = EntityTooLarge\n\t\treturn\n\t}\n\tif length < 0 {\n\t\terrorCode = MissingContentLength\n\t\treturn\n\t}\n\n\t// Get the requested content-type.\n\t// In addition to being used to manage data types, it is used to distinguish\n\t// whether the request is to create a directory.\n\tcontentType := r.Header.Get(ContentType)\n\t// Get request header : content-disposition\n\tcontentDisposition := r.Header.Get(ContentDisposition)\n\t// Get request header : Cache-Control\n\tcacheControl := r.Header.Get(CacheControl)\n\tif len(cacheControl) > 0 && !ValidateCacheControl(cacheControl) {\n\t\terrorCode = InvalidCacheArgument\n\t\treturn\n\t}\n\t// Get request header : Expires\n\texpires := r.Header.Get(Expires)\n\tif len(expires) > 0 && !ValidateCacheExpires(expires) {\n\t\terrorCode = InvalidCacheArgument\n\t\treturn\n\t}\n\t// Checking user-defined metadata\n\tmetadata := ParseUserDefinedMetadata(r.Header)\n\t// Audit file write\n\tlog.LogInfof(\"Audit: put object: requestID(%v) remote(%v) volume(%v) path(%v) type(%v)\",\n\t\tGetRequestID(r), getRequestIP(r), vol.Name(), param.Object(), contentType)\n\n\tvar fsFileInfo *FSFileInfo\n\tvar opt = &PutFileOption{\n\t\tMIMEType:     contentType,\n\t\tDisposition:  contentDisposition,\n\t\tTagging:      tagging,\n\t\tMetadata:     metadata,\n\t\tCacheControl: cacheControl,\n\t\tExpires:      expires,\n\t\tACL:          acl,\n\t\tObjectLock:   objetLock,\n\t}\n\tvar startPut = time.Now()\n\n\t// Flow Control\n\tvar reader io.Reader\n\tif length > DefaultFlowLimitSize {\n\t\treader = rateLimit.GetReader(vol.owner, param.apiName, r.Body)\n\t} else {\n\t\treader = r.Body\n\t}\n\tif fsFileInfo, err = vol.PutObject(param.Object(), reader, opt); err != nil {\n\t\tlog.LogErrorf(\"putObjectHandler: put object fail: requestId(%v) volume(%v) path(%v) remote(%v) err(%v)\",\n\t\t\tGetRequestID(r), vol.Name(), param.Object(), getRequestIP(r), err)\n\t\terr = handlePutObjectErr(err)\n\t\treturn\n\t}\n\t// check content MD5\n\tif requestMD5 != \"\" && requestMD5 != fsFileInfo.ETag {\n\t\tlog.LogErrorf(\"putObjectHandler: MD5 validate fail: requestID(%v) volume(%v) path(%v) requestMD5(%v) serverMD5(%v)\",\n\t\t\tGetRequestID(r), vol.Name(), param.Object(), requestMD5, fsFileInfo.ETag)\n\t\terrorCode = BadDigest\n\t\treturn\n\t}\n\tlog.LogDebugf(\"PutObject succeed, requestID(%v) volume(%v) key(%v) costTime: %v\", GetRequestID(r),\n\t\tvol.Name(), param.Object(), time.Since(startPut))\n\n\t// set response header\n\tw.Header()[ETag] = []string{wrapUnescapedQuot(fsFileInfo.ETag)}\n\treturn\n}\n\n// Post object\n// API reference: https://docs.aws.amazon.com/AmazonS3/latest/API/RESTObjectPOST.html\nfunc (o *ObjectNode) postObjectHandler(w http.ResponseWriter, r *http.Request) {\n\tvar err error\n\tvar errorCode *ErrorCode\n\tdefer func() {\n\t\to.errorResponse(w, r, err, errorCode)\n\t}()\n\n\tparam := ParseRequestParam(r)\n\tif param.Bucket() == \"\" {\n\t\terrorCode = InvalidBucketName\n\t\treturn\n\t}\n\n\t// TODO: will be implemented\n\terrorCode = UnsupportedOperation\n\n\treturn\n}\n\nfunc handlePutObjectErr(err error) error {\n\tif err == syscall.EINVAL {\n\t\treturn ObjectModeConflict\n\t}\n\tif err == syscall.EEXIST {\n\t\treturn ConflictUploadRequest\n\t}\n\tif err == io.ErrUnexpectedEOF {\n\t\treturn EntityTooSmall\n\t}\n\treturn err\n}\n\n// Delete object\n// API reference: https://docs.aws.amazon.com/AmazonS3/latest/API/API_DeleteObject.html .\nfunc (o *ObjectNode) deleteObjectHandler(w http.ResponseWriter, r *http.Request) {\n\tvar (\n\t\terr       error\n\t\terrorCode *ErrorCode\n\t)\n\tdefer func() {\n\t\to.errorResponse(w, r, err, errorCode)\n\t}()\n\n\tvar param = ParseRequestParam(r)\n\tif param.Bucket() == \"\" {\n\t\terrorCode = InvalidBucketName\n\t\treturn\n\t}\n\tif param.Object() == \"\" {\n\t\terrorCode = InvalidKey\n\t\treturn\n\t}\n\n\tvar vol *Volume\n\tif vol, err = o.getVol(param.Bucket()); err != nil {\n\t\tlog.LogErrorf(\"deleteObjectHandler: load volume fail: requestID(%v) volume(%v) err(%v)\",\n\t\t\tGetRequestID(r), param.Bucket(), err)\n\t\treturn\n\t}\n\n\t// QPS and Concurrency Limit\n\trateLimit := o.AcquireRateLimiter()\n\tif err = rateLimit.AcquireLimitResource(vol.owner, param.apiName); err != nil {\n\t\treturn\n\t}\n\tdefer rateLimit.ReleaseLimitResource(vol.owner, param.apiName)\n\n\t// Audit deletion\n\tlog.LogInfof(\"Audit: delete object: requestID(%v) remote(%v) volume(%v) path(%v)\",\n\t\tGetRequestID(r), getRequestIP(r), vol.Name(), param.Object())\n\n\terr = vol.DeletePath(param.Object())\n\tif err != nil {\n\t\tlog.LogErrorf(\"deleteObjectHandler: Volume delete file fail: \"+\n\t\t\t\"requestID(%v) volume(%v) path(%v) err(%v)\", GetRequestID(r), vol.Name(), param.Object(), err)\n\t\treturn\n\t}\n\n\tw.WriteHeader(http.StatusNoContent)\n\treturn\n}\n\n// Get object tagging\n// API reference: https://docs.aws.amazon.com/AmazonS3/latest/API/API_GetObjectTagging.html\nfunc (o *ObjectNode) getObjectTaggingHandler(w http.ResponseWriter, r *http.Request) {\n\tvar err error\n\tvar errorCode *ErrorCode\n\tdefer func() {\n\t\to.errorResponse(w, r, err, errorCode)\n\t}()\n\n\tvar param = ParseRequestParam(r)\n\tif param.Bucket() == \"\" {\n\t\terrorCode = InvalidBucketName\n\t\treturn\n\t}\n\tif param.Object() == \"\" {\n\t\terrorCode = InvalidKey\n\t\treturn\n\t}\n\tvar vol *Volume\n\tif vol, err = o.getVol(param.Bucket()); err != nil {\n\t\tlog.LogErrorf(\"getObjectTaggingHandler: load volume fail: requestID(%v) volume(%v) err(%v)\",\n\t\t\tGetRequestID(r), param.Bucket(), err)\n\t\treturn\n\t}\n\n\t// QPS and Concurrency Limit\n\trateLimit := o.AcquireRateLimiter()\n\tif err = rateLimit.AcquireLimitResource(vol.owner, param.apiName); err != nil {\n\t\treturn\n\t}\n\tdefer rateLimit.ReleaseLimitResource(vol.owner, param.apiName)\n\n\tvar xattrInfo *proto.XAttrInfo\n\tif xattrInfo, err = vol.GetXAttr(param.object, XAttrKeyOSSTagging); err != nil {\n\t\tlog.LogErrorf(\"getObjectTaggingHandler: get volume XAttr fail: requestID(%v) err(%v)\", GetRequestID(r), err)\n\t\tif err == syscall.ENOENT {\n\t\t\terrorCode = NoSuchKey\n\t\t}\n\t\treturn\n\t}\n\n\tossTaggingData := xattrInfo.Get(XAttrKeyOSSTagging)\n\n\tvar output, _ = ParseTagging(string(ossTaggingData))\n\tresponse, err := MarshalXMLEntity(output)\n\tif err != nil {\n\t\tlog.LogErrorf(\"getObjectTaggingHandler: xml marshal result fail: requestID(%v) result(%v) err(%v)\",\n\t\t\tGetRequestID(r), output, err)\n\t\treturn\n\t}\n\n\twriteSuccessResponseXML(w, response)\n\treturn\n}\n\n// Put object tagging\n// API reference: https://docs.aws.amazon.com/AmazonS3/latest/API/API_PutObjectTagging.html\nfunc (o *ObjectNode) putObjectTaggingHandler(w http.ResponseWriter, r *http.Request) {\n\tvar err error\n\tvar errorCode *ErrorCode\n\tdefer func() {\n\t\to.errorResponse(w, r, err, errorCode)\n\t}()\n\n\tvar param = ParseRequestParam(r)\n\tif param.Bucket() == \"\" {\n\t\terrorCode = InvalidBucketName\n\t\treturn\n\t}\n\tif param.Object() == \"\" {\n\t\terrorCode = InvalidKey\n\t\treturn\n\t}\n\n\tvar vol *Volume\n\tif vol, err = o.getVol(param.Bucket()); err != nil {\n\t\tlog.LogErrorf(\"putObjectTaggingHandler: load volume fail: requestID(%v) err(%v)\",\n\t\t\tGetRequestID(r), err)\n\t\treturn\n\t}\n\n\t// QPS and Concurrency Limit\n\trateLimit := o.AcquireRateLimiter()\n\tif err = rateLimit.AcquireLimitResource(vol.owner, param.apiName); err != nil {\n\t\treturn\n\t}\n\tdefer rateLimit.ReleaseLimitResource(vol.owner, param.apiName)\n\n\tvar requestBody []byte\n\tif requestBody, err = ioutil.ReadAll(r.Body); err != nil {\n\t\tlog.LogErrorf(\"putObjectTaggingHandler: read request body data fail: requestID(%v) err(%v)\",\n\t\t\tGetRequestID(r), err)\n\t\terrorCode = InvalidArgument\n\t\treturn\n\t}\n\n\tvar tagging = NewTagging()\n\tif err = xml.Unmarshal(requestBody, tagging); err != nil {\n\t\tlog.LogWarnf(\"putObjectTaggingHandler: decode request body fail: requestID(%v) err(%v)\",\n\t\t\tGetRequestID(r), err)\n\t\terrorCode = InvalidArgument\n\t\treturn\n\t}\n\tvalidateRes, errorCode := tagging.Validate()\n\tif !validateRes {\n\t\tlog.LogErrorf(\"putObjectTaggingHandler: tagging validate fail: requestID(%v) tagging(%v) err(%v)\",\n\t\t\tGetRequestID(r), tagging, errorCode.Error())\n\t\treturn\n\t}\n\n\terr = vol.SetXAttr(param.object, XAttrKeyOSSTagging, []byte(tagging.Encode()), false)\n\tif err != nil {\n\t\tlog.LogErrorf(\"pubObjectTaggingHandler: set tagging xattr fail: requestID(%v) volume(%v) object(%v) err(%v)\",\n\t\t\tGetRequestID(r), param.Bucket(), param.Object(), err)\n\t\tif err == syscall.ENOENT {\n\t\t\terrorCode = NoSuchKey\n\t\t}\n\t\treturn\n\t}\n\n\treturn\n}\n\n// Delete object tagging\n// API reference: https://docs.aws.amazon.com/AmazonS3/latest/API/API_DeleteObjectTagging.html\nfunc (o *ObjectNode) deleteObjectTaggingHandler(w http.ResponseWriter, r *http.Request) {\n\tvar err error\n\tvar errorCode *ErrorCode\n\tdefer func() {\n\t\to.errorResponse(w, r, err, errorCode)\n\t}()\n\n\tvar param = ParseRequestParam(r)\n\tif param.Bucket() == \"\" {\n\t\terrorCode = InvalidBucketName\n\t\treturn\n\t}\n\tif param.Object() == \"\" {\n\t\terrorCode = InvalidKey\n\t\treturn\n\t}\n\tvar vol *Volume\n\tif vol, err = o.getVol(param.Bucket()); err != nil {\n\t\tlog.LogErrorf(\"deleteObjectTaggingHandler: load volume fail: requestID(%v) err(%v)\",\n\t\t\tGetRequestID(r), err)\n\t\treturn\n\t}\n\n\t// QPS and Concurrency Limit\n\trateLimit := o.AcquireRateLimiter()\n\tif err = rateLimit.AcquireLimitResource(vol.owner, param.apiName); err != nil {\n\t\treturn\n\t}\n\tdefer rateLimit.ReleaseLimitResource(vol.owner, param.apiName)\n\n\tif err = vol.DeleteXAttr(param.object, XAttrKeyOSSTagging); err != nil {\n\t\tlog.LogErrorf(\"deleteObjectTaggingHandler: volume delete tagging fail: requestID(%v) volume(%v) object(%v) err(%v)\",\n\t\t\tGetRequestID(r), param.Bucket(), param.Object(), err)\n\t\treturn\n\t}\n\n\tw.WriteHeader(http.StatusNoContent)\n\treturn\n}\n\n// Put object extend attribute (xattr)\nfunc (o *ObjectNode) putObjectXAttrHandler(w http.ResponseWriter, r *http.Request) {\n\tvar err error\n\tvar errorCode *ErrorCode\n\tdefer func() {\n\t\to.errorResponse(w, r, err, errorCode)\n\t}()\n\n\tvar param = ParseRequestParam(r)\n\tif len(param.Bucket()) == 0 {\n\t\terrorCode = InvalidBucketName\n\t\treturn\n\t}\n\tif len(param.Object()) == 0 {\n\t\terrorCode = InvalidKey\n\t\treturn\n\t}\n\tvar vol *Volume\n\tif vol, err = o.getVol(param.bucket); err != nil {\n\t\tlog.LogErrorf(\"pubObjectXAttrHandler: load volume fail: requestID(%v) err(%v)\",\n\t\t\tGetRequestID(r), err)\n\t\treturn\n\t}\n\n\t// QPS and Concurrency Limit\n\trateLimit := o.AcquireRateLimiter()\n\tif err = rateLimit.AcquireLimitResource(vol.owner, param.apiName); err != nil {\n\t\treturn\n\t}\n\tdefer rateLimit.ReleaseLimitResource(vol.owner, param.apiName)\n\n\tvar requestBody []byte\n\tif requestBody, err = ioutil.ReadAll(r.Body); err != nil {\n\t\terrorCode = &ErrorCode{\n\t\t\tErrorCode:    \"BadRequest\",\n\t\t\tErrorMessage: err.Error(),\n\t\t\tStatusCode:   http.StatusBadRequest,\n\t\t}\n\t\treturn\n\t}\n\tvar putXAttrRequest = PutXAttrRequest{}\n\tif err = xml.Unmarshal(requestBody, &putXAttrRequest); err != nil {\n\t\terrorCode = &ErrorCode{\n\t\t\tErrorCode:    \"BadRequest\",\n\t\t\tErrorMessage: err.Error(),\n\t\t\tStatusCode:   http.StatusBadRequest,\n\t\t}\n\t\treturn\n\t}\n\tvar key, value = putXAttrRequest.XAttr.Key, putXAttrRequest.XAttr.Value\n\tif len(key) == 0 {\n\t\treturn\n\t}\n\n\tif err = vol.SetXAttr(param.object, key, []byte(value), true); err != nil {\n\t\tlog.LogErrorf(\"pubObjectXAttrHandler: volume set extend attribute fail: requestID(%v) err(%v)\",\n\t\t\tGetRequestID(r), err)\n\t\tif err == syscall.ENOENT {\n\t\t\terrorCode = NoSuchKey\n\t\t}\n\t\treturn\n\t}\n\n\treturn\n}\n\n// Get object extend attribute (xattr)\nfunc (o *ObjectNode) getObjectXAttrHandler(w http.ResponseWriter, r *http.Request) {\n\tvar err error\n\tvar errorCode *ErrorCode\n\tdefer func() {\n\t\to.errorResponse(w, r, err, errorCode)\n\t}()\n\n\tvar param = ParseRequestParam(r)\n\tif len(param.Bucket()) == 0 {\n\t\terrorCode = InvalidBucketName\n\t\treturn\n\t}\n\tif len(param.Object()) == 0 {\n\t\terrorCode = InvalidKey\n\t\treturn\n\t}\n\tvar vol *Volume\n\tif vol, err = o.getVol(param.Bucket()); err != nil {\n\t\tlog.LogErrorf(\"getObjectXAttrHandler: load volume fail: requestID(%v) err(%v)\",\n\t\t\tGetRequestID(r), err)\n\t\treturn\n\t}\n\n\t// QPS and Concurrency Limit\n\trateLimit := o.AcquireRateLimiter()\n\tif err = rateLimit.AcquireLimitResource(vol.owner, param.apiName); err != nil {\n\t\treturn\n\t}\n\tdefer rateLimit.ReleaseLimitResource(vol.owner, param.apiName)\n\n\tvar xattrKey string\n\tif xattrKey = param.GetVar(ParamKey); len(xattrKey) == 0 {\n\t\terrorCode = InvalidArgument\n\t\treturn\n\t}\n\n\tvar info *proto.XAttrInfo\n\tif info, err = vol.GetXAttr(param.object, xattrKey); err != nil {\n\t\tlog.LogErrorf(\"getObjectXAttrHandler: get extend attribute fail: requestID(%v) volume(%v) object(%v) key(%v) err(%v)\",\n\t\t\tGetRequestID(r), param.Bucket(), param.Object(), xattrKey, err)\n\t\tif err == syscall.ENOENT {\n\t\t\terrorCode = NoSuchKey\n\t\t}\n\t\treturn\n\t}\n\toutput := GetXAttrOutput{\n\t\tXAttr: &XAttr{\n\t\t\tKey:   xattrKey,\n\t\t\tValue: string(info.Get(xattrKey)),\n\t\t},\n\t}\n\tresponse, err := MarshalXMLEntity(&output)\n\tif err != nil {\n\t\tlog.LogErrorf(\"getObjectXAttrHandler: xml marshal result fail: requestID(%v) result(%v) err(%v)\",\n\t\t\tGetRequestID(r), output, err)\n\t\treturn\n\t}\n\n\twriteSuccessResponseXML(w, response)\n\treturn\n}\n\n// Delete object extend attribute (xattr)\nfunc (o *ObjectNode) deleteObjectXAttrHandler(w http.ResponseWriter, r *http.Request) {\n\tvar err error\n\tvar errorCode *ErrorCode\n\tdefer func() {\n\t\to.errorResponse(w, r, err, errorCode)\n\t}()\n\n\tvar param = ParseRequestParam(r)\n\tif len(param.Bucket()) == 0 {\n\t\terrorCode = InvalidBucketName\n\t\treturn\n\t}\n\tif len(param.Object()) == 0 {\n\t\terrorCode = InvalidKey\n\t\treturn\n\t}\n\tvar vol *Volume\n\tif vol, err = o.getVol(param.Bucket()); err != nil {\n\t\tlog.LogErrorf(\"deleteObjectXAttrHandler: load volume fail: requestID(%v) err(%v)\",\n\t\t\tGetRequestID(r), err)\n\t\treturn\n\t}\n\n\t// QPS and Concurrency Limit\n\trateLimit := o.AcquireRateLimiter()\n\tif err = rateLimit.AcquireLimitResource(vol.owner, param.apiName); err != nil {\n\t\treturn\n\t}\n\tdefer rateLimit.ReleaseLimitResource(vol.owner, param.apiName)\n\n\tvar xattrKey string\n\tif xattrKey = param.GetVar(ParamKey); len(xattrKey) == 0 {\n\t\terrorCode = InvalidArgument\n\t\treturn\n\t}\n\n\tif err = vol.DeleteXAttr(param.object, xattrKey); err != nil {\n\t\tlog.LogErrorf(\"deleteObjectXAttrHandler: delete extend attribute fail: requestID(%v) err(%v)\",\n\t\t\tGetRequestID(r), err)\n\t\tif err == syscall.ENOENT {\n\t\t\terrorCode = NoSuchKey\n\t\t}\n\t\treturn\n\t}\n\n\treturn\n}\n\n// List object xattrs\nfunc (o *ObjectNode) listObjectXAttrs(w http.ResponseWriter, r *http.Request) {\n\tvar err error\n\tvar errorCode *ErrorCode\n\tdefer func() {\n\t\to.errorResponse(w, r, err, errorCode)\n\t}()\n\n\tvar param = ParseRequestParam(r)\n\tif len(param.Bucket()) == 0 {\n\t\terrorCode = InvalidBucketName\n\t\treturn\n\t}\n\tif len(param.Object()) == 0 {\n\t\terrorCode = InvalidKey\n\t\treturn\n\t}\n\tvar vol *Volume\n\tif vol, err = o.getVol(param.bucket); err != nil {\n\t\tlog.LogErrorf(\"listObjectXAttrs: load volume fail: requestID(%v) err(%v)\",\n\t\t\tGetRequestID(r), err)\n\t\treturn\n\t}\n\n\t// QPS and Concurrency Limit\n\trateLimit := o.AcquireRateLimiter()\n\tif err = rateLimit.AcquireLimitResource(vol.owner, param.apiName); err != nil {\n\t\treturn\n\t}\n\tdefer rateLimit.ReleaseLimitResource(vol.owner, param.apiName)\n\n\tvar keys []string\n\tif keys, err = vol.ListXAttrs(param.object); err != nil {\n\t\tlog.LogErrorf(\"listObjectXAttrs: volume list extend attributes fail: requestID(%v) volume(%v) object(%v) err(%v)\",\n\t\t\tGetRequestID(r), param.Bucket(), param.Object(), err)\n\t\tif err == syscall.ENOENT {\n\t\t\terrorCode = NoSuchKey\n\t\t}\n\t\treturn\n\t}\n\n\toutput := ListXAttrsOutput{\n\t\tKeys: keys,\n\t}\n\tresponse, err := MarshalXMLEntity(&output)\n\tif err != nil {\n\t\tlog.LogErrorf(\"listObjectXAttrs: marshal response body fail: requestID(%v) volume(%v) object(%v) err(%v)\",\n\t\t\tGetRequestID(r), param.Bucket(), param.Object(), err)\n\t\treturn\n\t}\n\n\twriteSuccessResponseXML(w, response)\n\treturn\n}\n\n// GetObjectRetention\n// API reference: https://docs.aws.amazon.com/AmazonS3/latest/API/API_GetObjectRetention.html\nfunc (o *ObjectNode) getObjectRetentionHandler(w http.ResponseWriter, r *http.Request) {\n\tvar (\n\t\terr       error\n\t\terrorCode *ErrorCode\n\t)\n\tdefer func() {\n\t\to.errorResponse(w, r, err, errorCode)\n\t}()\n\n\t// check args\n\tvar param = ParseRequestParam(r)\n\tif param.Bucket() == \"\" {\n\t\terrorCode = InvalidBucketName\n\t\treturn\n\t}\n\tif param.Object() == \"\" {\n\t\terrorCode = InvalidKey\n\t\treturn\n\t}\n\tvar vol *Volume\n\tif vol, err = o.getVol(param.Bucket()); err != nil {\n\t\tlog.LogErrorf(\"getObjectRetentionHandler: load volume fail: requestID(%v) err(%v)\",\n\t\t\tGetRequestID(r), err)\n\t\treturn\n\t}\n\n\t// get object meta\n\t_, xattrs, err := vol.ObjectMeta(param.Object())\n\tif err != nil {\n\t\tlog.LogErrorf(\"getObjectRetentionHandler: get file meta fail: requestId(%v) volume(%v) path(%v) err(%v)\",\n\t\t\tGetRequestID(r), vol.Name(), param.Object(), err)\n\t\tif err == syscall.ENOENT {\n\t\t\terrorCode = NoSuchKey\n\t\t}\n\t\treturn\n\t}\n\tretainUntilDate := string(xattrs.Get(XAttrKeyOSSLock))\n\tif retainUntilDate == \"\" {\n\t\terrorCode = NoSuchObjectLockConfiguration\n\t\treturn\n\t}\n\tretainUntilDateInt64, err := strconv.ParseInt(retainUntilDate, 10, 64)\n\tif err != nil {\n\t\tlog.LogErrorf(\"getObjectRetentionHandler: parse retainUntilDate fail: requestId(%v) volume(%v) path(%v) err(%v)\",\n\t\t\tGetRequestID(r), vol.Name(), param.Object(), err)\n\t\treturn\n\t}\n\tvar objectRetention ObjectRetention\n\tobjectRetention.Mode = ComplianceMode\n\tobjectRetention.RetainUntilDate = RetentionDate{Time: time.Unix(0, retainUntilDateInt64).UTC()}\n\tb, err := xml.Marshal(objectRetention)\n\tif err != nil {\n\t\tlog.LogErrorf(\"getObjectRetentionHandler: xml marshal fail: requestId(%v) volume(%v) result(%v) err(%v)\",\n\t\t\tGetRequestID(r), vol.Name(), objectRetention, err)\n\t\treturn\n\t}\n\n\twriteSuccessResponseXML(w, b)\n\treturn\n}\n\nfunc parsePartInfo(partNumber uint64, fileSize uint64) (uint64, uint64, uint64, uint64) {\n\tvar partSize uint64\n\tvar partCount uint64\n\tvar rangeLower uint64\n\tvar rangeUpper uint64\n\t// partSize, partCount, rangeLower, rangeUpper\n\tpartSizeConst := ParallelDownloadPartSize\n\tpartCount = fileSize / uint64(partSizeConst)\n\tlastSize := fileSize % uint64(partSizeConst)\n\tif lastSize > 0 {\n\t\tpartCount += 1\n\t}\n\n\trangeLower = uint64(partSizeConst) * (partNumber - 1)\n\tif lastSize > 0 && partNumber == partCount {\n\t\tpartSize = lastSize\n\t\trangeUpper = fileSize - 1\n\t} else {\n\t\tpartSize = uint64(partSizeConst)\n\t\trangeUpper = (partSize * partNumber) - 1\n\t}\n\tif partNumber > partCount {\n\t\treturn 0, 0, 0, 0\n\t}\n\treturn partSize, partCount, rangeLower, rangeUpper\n}\n\nfunc GetContentLength(r *http.Request) int64 {\n\tdcl := r.Header.Get(HeaderNameXAmzDecodedContentLength)\n\tif dcl != \"\" {\n\t\tlength, err := strconv.ParseInt(dcl, 10, 64)\n\t\tif err == nil {\n\t\t\treturn length\n\t\t}\n\t}\n\treturn r.ContentLength\n}\n", "// Copyright 2019 The CubeFS Authors.\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n// implied. See the License for the specific language governing\n// permissions and limitations under the License.\n\npackage objectnode\n\nimport \"os\"\n\nconst (\n\tMaxRetry = 3\n)\n\nconst (\n\tS3Namespace        = \"http://s3.amazonaws.com/doc/2006-03-01/\"\n\tServer             = \"Server\"\n\tHost               = \"Host\"\n\tLastModified       = \"Last-Modified\"\n\tETag               = \"ETag\"\n\tDate               = \"Date\"\n\tContentMD5         = \"Content-MD5\"\n\tContentEncoding    = \"Content-Encoding\"\n\tContentType        = \"Content-Type\"\n\tContentLength      = \"Content-Length\"\n\tContentRange       = \"Content-Range\"\n\tContentDisposition = \"Content-Disposition\"\n\tAuthorization      = \"Authorization\"\n\tAcceptRanges       = \"Accept-Ranges\"\n\tRange              = \"Range\"\n\tExpect             = \"Expect\"\n\tXForwardedExpect   = \"X-Forwarded-Expect\"\n\tLocation           = \"Location\"\n\tCacheControl       = \"Cache-Control\"\n\tExpires            = \"Expires\"\n\tConnection         = \"Connection\"\n\tSignature          = \"Signature\"\n\tOrigin             = \"Origin\"\n\n\tAccessControlRequestMethod    = \"Access-Control-Request-Method\"\n\tAccessControlRequestHeaders   = \"Access-Control-Request-Headers\"\n\tAccessControlAllowOrigin      = \"Access-Control-Allow-Origin\"\n\tAccessControlAllowCredentials = \"Access-Control-Allow-Credentials\"\n\tAccessControlMaxAge           = \"Access-Control-Max-Age\"\n\tAccessControlAllowMethods     = \"Access-Control-Allow-Methods\"\n\tAccessControlAllowHeaders     = \"Access-Control-Allow-Headers\"\n\tAccessControlExposeHeaders    = \"Access-Control-Expose-Headers\"\n\n\tIfMatch           = \"If-Match\"\n\tIfNoneMatch       = \"If-None-Match\"\n\tIfModifiedSince   = \"If-Modified-Since\"\n\tIfUnmodifiedSince = \"If-Unmodified-Since\"\n\n\tXAmzRequestId                   = \"x-amz-request-id\"\n\tXAmzCopySource                  = \"x-amz-copy-source\"\n\tXAmzCopySourceRange             = \"x-amz-copy-source-range\"\n\tXAmzCopySourceIfMatch           = \"x-amz-copy-source-if-match\"\n\tXAmzCopySourceIfNoneMatch       = \"x-amz-copy-source-if-none-match\"\n\tXAmzCopySourceIfModifiedSince   = \"x-amz-copy-source-if-modified-since\"\n\tXAmzCopySourceIfUnmodifiedSince = \"x-amz-copy-source-if-unmodified-since\"\n\tXAmzDecodedContentLength        = \"x-amz-decoded-content-length\"\n\tXAmzTagging                     = \"x-amz-tagging\"\n\tXAmzMetaPrefix                  = \"x-amz-meta-\"\n\tXAmzMpPartsCount                = \"x-amz-mp-parts-count\"\n\tXAmzMetadataDirective           = \"x-amz-metadata-directive\"\n\tXAmzBucketRegion                = \"x-amz-bucket-region\"\n\tXAmzStorageClass                = \"x-amz-storage-class\"\n\tXAmzTaggingCount                = \"x-amz-tagging-count\"\n\tXAmzContentSha256               = \"X-Amz-Content-Sha256\"\n\tXAmzCredential                  = \"X-Amz-Credential\"\n\tXAmzSignature                   = \"X-Amz-Signature\"\n\tXAmzSignedHeaders               = \"X-Amz-SignedHeaders\"\n\tXAmzAlgorithm                   = \"X-Amz-Algorithm\"\n\tXAmzDate                        = \"X-Amz-Date\"\n\tXAmzExpires                     = \"X-Amz-Expires\"\n\tXAmzSecurityToken               = \"X-Amz-Security-Token\"\n\tXAmzObjectLockMode              = \"X-Amz-Object-Lock-Mode\"\n\tXAmzObjectLockRetainUntilDate   = \"X-Amz-Object-Lock-Retain-Until-Date\"\n\n\tHeaderNameXAmzDecodedContentLength = \"x-amz-decoded-content-length\"\n)\n\nconst (\n\tValueServer               = \"CubeFS\"\n\tValueAcceptRanges         = \"bytes\"\n\tValueContentTypeStream    = \"application/octet-stream\"\n\tValueContentTypeXML       = \"application/xml\"\n\tValueContentTypeJSON      = \"application/json\"\n\tValueContentTypeDirectory = \"application/directory\"\n\tValueMultipartFormData    = \"multipart/form-data\"\n)\n\nconst (\n\tSubObjectDelete    = \"delete\"\n\tSubMultipartUpload = \"uploads\"\n)\n\nconst (\n\tParamUploadId   = \"uploadId\"\n\tParamPartNumber = \"partNumber\"\n\tParamKeyMarker  = \"key-marker\"\n\tParamMarker     = \"marker\"\n\tParamPrefix     = \"prefix\"\n\tParamContToken  = \"continuation-token\"\n\tParamFetchOwner = \"fetch-owner\"\n\tParamMaxKeys    = \"max-keys\"\n\tParamStartAfter = \"start-after\"\n\tParamKey        = \"key\"\n\n\tParamMaxParts       = \"max-parts\"\n\tParamUploadIdMarker = \"upload-id-marker\"\n\tParamPartNoMarker   = \"part-number-marker\"\n\tParamPartMaxUploads = \"max-uploads\"\n\tParamPartDelimiter  = \"delimiter\"\n\tParamEncodingType   = \"encoding-type\"\n\n\tParamResponseCacheControl       = \"response-cache-control\"\n\tParamResponseContentType        = \"response-content-type\"\n\tParamResponseContentDisposition = \"response-content-disposition\"\n\tParamResponseExpires            = \"response-expires\"\n)\n\nconst (\n\tMaxKeys        = 1000\n\tMaxParts       = 1000\n\tMaxUploads     = 1000\n\tSinglePutLimit = 5 * 1 << 30 // 5G\n)\n\nconst (\n\tStorageClassStandard = \"STANDARD\"\n)\n\n// XAttr keys for ObjectNode compatible feature\nconst (\n\tXAttrKeyOSSPrefix       = \"oss:\"\n\tXAttrKeyOSSETag         = \"oss:etag\"\n\tXAttrKeyOSSTagging      = \"oss:tagging\"\n\tXAttrKeyOSSPolicy       = \"oss:policy\"\n\tXAttrKeyOSSACL          = \"oss:acl\"\n\tXAttrKeyOSSMIME         = \"oss:mime\"\n\tXAttrKeyOSSDISPOSITION  = \"oss:disposition\"\n\tXAttrKeyOSSCORS         = \"oss:cors\"\n\tXAttrKeyOSSLock         = \"oss:lock\"\n\tXAttrKeyOSSCacheControl = \"oss:cache\"\n\tXAttrKeyOSSExpires      = \"oss:expires\"\n\n\t// Deprecated\n\tXAttrKeyOSSETagDeprecated = \"oss:tag\"\n)\n\nconst (\n\tDateLayout              = \"20060102\"\n\tISO8601Format           = \"20060102T150405Z\"\n\tISO8601Layout           = \"2006-01-02T15:04:05.000Z\"\n\tISO8601LayoutCompatible = \"2006-01-02T15:04:05Z\"\n\tRFC1123Format           = \"Mon, 02 Jan 2006 15:04:05 GMT\"\n)\n\nconst (\n\tEmptyContentMD5String = \"d41d8cd98f00b204e9800998ecf8427e\"\n)\n\nconst (\n\tDefaultFileMode = 0644\n\tDefaultDirMode  = DefaultFileMode | os.ModeDir\n)\n\nconst (\n\tSplitFileRangeBlockSize     = 10 * 1024 * 1024 // 10MB\n\tParallelDownloadPartSize    = 10 * 1024 * 1024\n\tMinParallelDownloadFileSize = 2 * ParallelDownloadPartSize\n)\n\nconst (\n\tMaxCopyObjectSize = 5 * 1024 * 1024 * 1024\n)\n\nconst (\n\tMetadataDirectiveCopy    = \"COPY\"\n\tMetadataDirectiveReplace = \"REPLACE\"\n)\n\nconst (\n\tTaggingCounts         = 10\n\tTaggingKeyMaxLength   = 128\n\tTaggingValueMaxLength = 256\n)\n", "// Copyright 2023 The CubeFS Authors.\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n// implied. See the License for the specific language governing\n// permissions and limitations under the License.\n\npackage objectnode\n\nimport (\n\t\"encoding/xml\"\n\t\"io\"\n\t\"io/ioutil\"\n\t\"net/http\"\n\n\t\"github.com/cubefs/cubefs/proto\"\n\t\"github.com/cubefs/cubefs/util/log\"\n)\n\n// API reference: https://docs.aws.amazon.com/zh_cn/AmazonS3/latest/API/API_GetBucketLifecycleConfiguration.html\nfunc (o *ObjectNode) getBucketLifecycleConfigurationHandler(w http.ResponseWriter, r *http.Request) {\n\tvar err error\n\tvar errorCode *ErrorCode\n\n\tdefer func() {\n\t\to.errorResponse(w, r, err, errorCode)\n\t}()\n\n\tvar param = ParseRequestParam(r)\n\tif param.Bucket() == \"\" {\n\t\terrorCode = InvalidBucketName\n\t\treturn\n\t}\n\tif _, err = o.vm.Volume(param.Bucket()); err != nil {\n\t\terrorCode = NoSuchBucket\n\t\treturn\n\t}\n\n\tvar lcConf *proto.LcConfiguration\n\tif lcConf, err = o.mc.AdminAPI().GetBucketLifecycle(param.Bucket()); err != nil {\n\t\tlog.LogErrorf(\"getBucketLifecycle failed: bucket[%v] err(%v)\", param.Bucket(), err)\n\t\terrorCode = NoSuchLifecycleConfiguration\n\t\treturn\n\t}\n\n\tvar lifeCycle = NewLifeCycle()\n\tlifeCycle.Rules = make([]*Rule, 0)\n\tfor _, lc := range lcConf.Rules {\n\t\trule := &Rule{\n\t\t\tID:     lc.ID,\n\t\t\tStatus: lc.Status,\n\t\t}\n\t\tif lc.Expire != nil {\n\t\t\trule.Expire = &Expiration{}\n\t\t\tif lc.Expire.Date != nil {\n\t\t\t\trule.Expire.Date = lc.Expire.Date\n\t\t\t}\n\t\t\tif lc.Expire.Days != 0 {\n\t\t\t\trule.Expire.Days = &lc.Expire.Days\n\t\t\t}\n\t\t}\n\t\tif lc.Filter != nil {\n\t\t\trule.Filter = &Filter{\n\t\t\t\tPrefix: lc.Filter.Prefix,\n\t\t\t}\n\t\t}\n\t\tlifeCycle.Rules = append(lifeCycle.Rules, rule)\n\t}\n\n\tvar data []byte\n\tdata, err = xml.Marshal(lifeCycle)\n\tif err != nil {\n\t\tlog.LogErrorf(\"getBucketLifecycle failed: bucket[%v] err(%v)\", param.Bucket(), err)\n\t\terrorCode = NoSuchLifecycleConfiguration\n\t\treturn\n\t}\n\n\twriteSuccessResponseXML(w, data)\n\treturn\n\n}\n\n// API reference: https://docs.aws.amazon.com/zh_cn/AmazonS3/latest/API/API_PutBucketLifecycleConfiguration.html\nfunc (o *ObjectNode) putBucketLifecycleConfigurationHandler(w http.ResponseWriter, r *http.Request) {\n\tvar err error\n\tvar errorCode *ErrorCode\n\n\tdefer func() {\n\t\to.errorResponse(w, r, err, errorCode)\n\t}()\n\n\tvar param = ParseRequestParam(r)\n\tif param.Bucket() == \"\" {\n\t\terrorCode = InvalidBucketName\n\t\treturn\n\t}\n\tif _, err = o.vm.Volume(param.Bucket()); err != nil {\n\t\terrorCode = NoSuchBucket\n\t\treturn\n\t}\n\n\tvar requestBody []byte\n\tif requestBody, err = ioutil.ReadAll(r.Body); err != nil && err != io.EOF {\n\t\tlog.LogErrorf(\"putBucketLifecycle failed: read request body data err: requestID(%v) err(%v)\", GetRequestID(r), err)\n\t\terrorCode = &ErrorCode{\n\t\t\tErrorCode:    http.StatusText(http.StatusBadRequest),\n\t\t\tErrorMessage: err.Error(),\n\t\t\tStatusCode:   http.StatusBadRequest,\n\t\t}\n\t\treturn\n\t}\n\n\tvar lifeCycle = NewLifeCycle()\n\tif err = UnmarshalXMLEntity(requestBody, lifeCycle); err != nil {\n\t\tlog.LogWarnf(\"putBucketLifecycle failed: decode request body err: requestID(%v) err(%v)\", GetRequestID(r), err)\n\t\terrorCode = LifeCycleErrMalformedXML\n\t\treturn\n\t}\n\n\tok, errorCode := lifeCycle.Validate()\n\tif !ok {\n\t\tlog.LogErrorf(\"putBucketLifecycle failed: validate err: requestID(%v) lifeCycle(%v) err(%v)\", GetRequestID(r), lifeCycle, errorCode)\n\t\treturn\n\t}\n\n\treq := proto.LcConfiguration{\n\t\tVolName: param.Bucket(),\n\t\tRules:   make([]*proto.Rule, 0),\n\t}\n\n\tfor _, lr := range lifeCycle.Rules {\n\t\trule := &proto.Rule{\n\t\t\tID:     lr.ID,\n\t\t\tStatus: lr.Status,\n\t\t}\n\t\tif lr.Expire != nil {\n\t\t\trule.Expire = &proto.ExpirationConfig{}\n\t\t\tif lr.Expire.Date != nil {\n\t\t\t\trule.Expire.Date = lr.Expire.Date\n\t\t\t}\n\t\t\tif lr.Expire.Days != nil {\n\t\t\t\trule.Expire.Days = *lr.Expire.Days\n\t\t\t}\n\t\t}\n\t\tif lr.Filter != nil {\n\t\t\trule.Filter = &proto.FilterConfig{\n\t\t\t\tPrefix: lr.Filter.Prefix,\n\t\t\t}\n\t\t}\n\t\treq.Rules = append(req.Rules, rule)\n\t}\n\n\tif err = o.mc.AdminAPI().SetBucketLifecycle(&req); err != nil {\n\t\tlog.LogErrorf(\"putBucketLifecycle failed: SetBucketLifecycle err: bucket[%v] err(%v)\", param.Bucket(), err)\n\t\treturn\n\t}\n\n\tlog.LogInfof(\"putBucketLifecycle success: requestID(%v) volume(%v) lifeCycle(%v)\",\n\t\tGetRequestID(r), param.Bucket(), lifeCycle)\n}\n\n// API reference: https://docs.aws.amazon.com/zh_cn/AmazonS3/latest/API/API_DeleteBucketLifecycle.html\nfunc (o *ObjectNode) deleteBucketLifecycleConfigurationHandler(w http.ResponseWriter, r *http.Request) {\n\tvar err error\n\tvar errorCode *ErrorCode\n\n\tdefer func() {\n\t\to.errorResponse(w, r, err, errorCode)\n\t}()\n\n\tvar param = ParseRequestParam(r)\n\tif param.Bucket() == \"\" {\n\t\terrorCode = InvalidBucketName\n\t\treturn\n\t}\n\tif _, err = o.vm.Volume(param.Bucket()); err != nil {\n\t\terrorCode = NoSuchBucket\n\t\treturn\n\t}\n\n\tif err = o.mc.AdminAPI().DelBucketLifecycle(param.Bucket()); err != nil {\n\t\tlog.LogErrorf(\"deleteBucketLifecycle failed: bucket[%v] err(%v)\", param.Bucket(), err)\n\t\treturn\n\t}\n\tw.WriteHeader(http.StatusNoContent)\n}\n"], "fixing_code": ["// Copyright 2019 The CubeFS Authors.\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n// implied. See the License for the specific language governing\n// permissions and limitations under the License.\n\npackage objectnode\n\nimport (\n\t\"crypto/md5\"\n\t\"encoding/hex\"\n\t\"encoding/json\"\n\t\"encoding/xml\"\n\t\"io\"\n\t\"io/ioutil\"\n\t\"net/http\"\n\t\"regexp\"\n\t\"strings\"\n\n\t\"github.com/cubefs/cubefs/proto\"\n\t\"github.com/cubefs/cubefs/util/log\"\n)\n\nconst (\n\tDefaultMinBucketLength = 3\n\tDefaultMaxBucketLength = 63\n)\n\nvar regexBucketName = regexp.MustCompile(`^[0-9a-z][-0-9a-z]+[0-9a-z]$`)\n\n// Head bucket\n// API reference: https://docs.aws.amazon.com/AmazonS3/latest/API/API_HeadBucket.html\nfunc (o *ObjectNode) headBucketHandler(w http.ResponseWriter, r *http.Request) {\n\tw.Header().Set(XAmzBucketRegion, o.region)\n}\n\n// Create bucket\n// API reference: https://docs.aws.amazon.com/AmazonS3/latest/API/API_CreateBucket.html\nfunc (o *ObjectNode) createBucketHandler(w http.ResponseWriter, r *http.Request) {\n\tvar (\n\t\terr       error\n\t\terrorCode *ErrorCode\n\t)\n\tdefer func() {\n\t\to.errorResponse(w, r, err, errorCode)\n\t}()\n\n\tparam := ParseRequestParam(r)\n\tbucket := param.Bucket()\n\tif bucket == \"\" {\n\t\terrorCode = InvalidBucketName\n\t\treturn\n\t}\n\n\tif !IsValidBucketName(bucket, DefaultMinBucketLength, DefaultMaxBucketLength) {\n\t\terrorCode = InvalidBucketName\n\t\treturn\n\t}\n\n\tif vol, _ := o.vm.VolumeWithoutBlacklist(bucket); vol != nil {\n\t\tlog.LogInfof(\"createBucketHandler: duplicated bucket name: requestID(%v) bucket(%v)\", GetRequestID(r), bucket)\n\t\terrorCode = BucketAlreadyOwnedByYou\n\t\treturn\n\t}\n\n\tvar userInfo *proto.UserInfo\n\tif userInfo, err = o.getUserInfoByAccessKeyV2(param.AccessKey()); err != nil {\n\t\tlog.LogErrorf(\"createBucketHandler: get user info from master fail: requestID(%v) accessKey(%v) err(%v)\",\n\t\t\tGetRequestID(r), param.AccessKey(), err)\n\t\treturn\n\t}\n\n\t// QPS and Concurrency Limit\n\trateLimit := o.AcquireRateLimiter()\n\tif err = rateLimit.AcquireLimitResource(userInfo.UserID, param.apiName); err != nil {\n\t\treturn\n\t}\n\tdefer rateLimit.ReleaseLimitResource(userInfo.UserID, param.apiName)\n\n\t_, errorCode = VerifyContentLength(r, BodyLimit)\n\tif errorCode != nil {\n\t\treturn\n\t}\n\trequestBytes, err := ioutil.ReadAll(r.Body)\n\tif err != nil && err != io.EOF {\n\t\tlog.LogErrorf(\"createBucketHandler: read request body fail: requestID(%v) err(%v)\", GetRequestID(r), err)\n\t\treturn\n\t}\n\n\tcreateBucketRequest := &CreateBucketRequest{}\n\terr = UnmarshalXMLEntity(requestBytes, createBucketRequest)\n\tif err != nil {\n\t\tlog.LogErrorf(\"createBucketHandler: unmarshal xml fail: requestID(%v) err(%v)\",\n\t\t\tGetRequestID(r), err)\n\t\terrorCode = InvalidArgument\n\t\treturn\n\t}\n\tif createBucketRequest.LocationConstraint != o.region {\n\t\tlog.LogErrorf(\"createBucketHandler: location constraint not match the service: requestID(%v) LocationConstraint(%v) region(%v)\",\n\t\t\tGetRequestID(r), createBucketRequest.LocationConstraint, o.region)\n\t\terrorCode = InvalidLocationConstraint\n\t\treturn\n\t}\n\n\tvar acl *AccessControlPolicy\n\tif acl, err = ParseACL(r, userInfo.UserID, false, false); err != nil {\n\t\tlog.LogErrorf(\"createBucketHandler: parse acl fail: requestID(%v) err(%v)\", GetRequestID(r), err)\n\t\treturn\n\t}\n\n\tif err = o.mc.AdminAPI().CreateDefaultVolume(bucket, userInfo.UserID); err != nil {\n\t\tlog.LogErrorf(\"createBucketHandler: create bucket fail: requestID(%v) volume(%v) accessKey(%v) err(%v)\",\n\t\t\tGetRequestID(r), bucket, param.AccessKey(), err)\n\t\treturn\n\t}\n\n\tw.Header().Set(Location, \"/\"+bucket)\n\tw.Header().Set(Connection, \"close\")\n\n\tvol, err1 := o.vm.VolumeWithoutBlacklist(bucket)\n\tif err1 != nil {\n\t\tlog.LogWarnf(\"createBucketHandler: load volume fail: requestID(%v) volume(%v) err(%v)\",\n\t\t\tGetRequestID(r), bucket, err1)\n\t\treturn\n\t}\n\tif acl != nil {\n\t\tif err1 = putBucketACL(vol, acl); err1 != nil {\n\t\t\tlog.LogWarnf(\"createBucketHandler: put acl fail: requestID(%v) volume(%v) acl(%+v) err(%v)\",\n\t\t\t\tGetRequestID(r), bucket, acl, err1)\n\t\t}\n\t\tvol.metaLoader.storeACL(acl)\n\t}\n\n\treturn\n}\n\n// Delete bucket\n// API reference: https://docs.aws.amazon.com/AmazonS3/latest/API/API_DeleteBucket.html\nfunc (o *ObjectNode) deleteBucketHandler(w http.ResponseWriter, r *http.Request) {\n\tvar (\n\t\terr       error\n\t\terrorCode *ErrorCode\n\t)\n\tdefer func() {\n\t\to.errorResponse(w, r, err, errorCode)\n\t}()\n\n\tparam := ParseRequestParam(r)\n\tbucket := param.Bucket()\n\tif bucket == \"\" {\n\t\terrorCode = InvalidBucketName\n\t\treturn\n\t}\n\n\tvar userInfo *proto.UserInfo\n\tif userInfo, err = o.getUserInfoByAccessKeyV2(param.AccessKey()); err != nil {\n\t\tlog.LogErrorf(\"deleteBucketHandler: get user info fail: requestID(%v) volume(%v) accessKey(%v) err(%v)\",\n\t\t\tGetRequestID(r), bucket, param.AccessKey(), err)\n\t\treturn\n\t}\n\tvar vol *Volume\n\tif vol, err = o.getVol(bucket); err != nil {\n\t\tlog.LogErrorf(\"deleteBucketHandler: load volume fail: requestID(%v) volume(%v) err(%v)\",\n\t\t\tGetRequestID(r), bucket, err)\n\t\treturn\n\t}\n\n\t// QPS and Concurrency Limit\n\trateLimit := o.AcquireRateLimiter()\n\tif err = rateLimit.AcquireLimitResource(vol.owner, param.apiName); err != nil {\n\t\treturn\n\t}\n\tdefer rateLimit.ReleaseLimitResource(vol.owner, param.apiName)\n\n\tif !vol.IsEmpty() {\n\t\terrorCode = BucketNotEmpty\n\t\treturn\n\t}\n\n\t// delete Volume from master\n\tvar authKey string\n\tif authKey, err = calculateAuthKey(userInfo.UserID); err != nil {\n\t\tlog.LogErrorf(\"deleteBucketHandler: calculate authKey fail: requestID(%v) volume(%v) authKey(%v) err(%v)\",\n\t\t\tGetRequestID(r), bucket, userInfo.UserID, err)\n\t\treturn\n\t}\n\tif err = o.mc.AdminAPI().DeleteVolume(bucket, authKey); err != nil {\n\t\tlog.LogErrorf(\"deleteBucketHandler: delete volume fail: requestID(%v) volume(%v) accessKey(%v) err(%v)\",\n\t\t\tGetRequestID(r), bucket, param.AccessKey(), err)\n\t\treturn\n\t}\n\tlog.LogInfof(\"deleteBucketHandler: delete bucket success: requestID(%v) volume(%v) accessKey(%v)\",\n\t\tGetRequestID(r), bucket, param.AccessKey())\n\n\t// release Volume from Volume manager\n\to.vm.Release(bucket)\n\tw.WriteHeader(http.StatusNoContent)\n\treturn\n}\n\n// List buckets\n// API reference: https://docs.aws.amazon.com/AmazonS3/latest/API/API_ListBuckets.html\nfunc (o *ObjectNode) listBucketsHandler(w http.ResponseWriter, r *http.Request) {\n\tvar (\n\t\terr       error\n\t\terrorCode *ErrorCode\n\t)\n\tdefer func() {\n\t\to.errorResponse(w, r, err, errorCode)\n\t}()\n\n\tparam := ParseRequestParam(r)\n\tvar userInfo *proto.UserInfo\n\tif userInfo, err = o.getUserInfoByAccessKeyV2(param.accessKey); err != nil {\n\t\tlog.LogErrorf(\"listBucketsHandler: get user info fail: requestID(%v) accessKey(%v) err(%v)\",\n\t\t\tGetRequestID(r), param.AccessKey(), err)\n\t\treturn\n\t}\n\n\t// QPS and Concurrency Limit\n\trateLimit := o.AcquireRateLimiter()\n\tif err = rateLimit.AcquireLimitResource(userInfo.UserID, param.apiName); err != nil {\n\t\treturn\n\t}\n\tdefer rateLimit.ReleaseLimitResource(userInfo.UserID, param.apiName)\n\n\ttype bucket struct {\n\t\tXMLName      xml.Name `xml:\"Bucket\"`\n\t\tCreationDate string   `xml:\"CreationDate\"`\n\t\tName         string   `xml:\"Name\"`\n\t}\n\n\ttype listBucketsOutput struct {\n\t\tXMLName xml.Name `xml:\"ListAllMyBucketsResult\"`\n\t\tOwner   Owner    `xml:\"Owner\"`\n\t\tBuckets []bucket `xml:\"Buckets>Bucket\"`\n\t}\n\n\tvar output listBucketsOutput\n\tfor _, ownVol := range userInfo.Policy.OwnVols {\n\t\tvar vol *Volume\n\t\tif vol, err = o.getVol(ownVol); err != nil {\n\t\t\tlog.LogErrorf(\"listBucketsHandler: load volume fail: requestID(%v) volume(%v) err(%v)\",\n\t\t\t\tGetRequestID(r), ownVol, err)\n\t\t\tcontinue\n\t\t}\n\t\toutput.Buckets = append(output.Buckets, bucket{\n\t\t\tName:         ownVol,\n\t\t\tCreationDate: formatTimeISO(vol.CreateTime()),\n\t\t})\n\t}\n\toutput.Owner = Owner{DisplayName: userInfo.UserID, Id: userInfo.UserID}\n\n\tresponse, err := MarshalXMLEntity(&output)\n\tif err != nil {\n\t\tlog.LogErrorf(\"listBucketsHandler: xml marshal result fail: requestID(%v) result(%v) err(%v)\",\n\t\t\tGetRequestID(r), output, err)\n\t\treturn\n\t}\n\n\twriteSuccessResponseXML(w, response)\n\treturn\n}\n\n// Get bucket location\n// API reference: https://docs.aws.amazon.com/AmazonS3/latest/API/API_GetBucketLocation.html\nfunc (o *ObjectNode) getBucketLocationHandler(w http.ResponseWriter, r *http.Request) {\n\tvar (\n\t\terr       error\n\t\terrorCode *ErrorCode\n\t)\n\tdefer func() {\n\t\to.errorResponse(w, r, err, errorCode)\n\t}()\n\n\tvar vol *Volume\n\tparam := ParseRequestParam(r)\n\tif param.Bucket() == \"\" {\n\t\terrorCode = InvalidBucketName\n\t\treturn\n\t}\n\tif vol, err = o.getVol(param.Bucket()); err != nil {\n\t\tlog.LogErrorf(\"getBucketLocationHandler: load volume fail: requestID(%v) volume(%v) err(%v)\",\n\t\t\tGetRequestID(r), param.Bucket(), err)\n\t\treturn\n\t}\n\n\t// QPS and Concurrency Limit\n\trateLimit := o.AcquireRateLimiter()\n\tif err = rateLimit.AcquireLimitResource(vol.owner, param.apiName); err != nil {\n\t\treturn\n\t}\n\tdefer rateLimit.ReleaseLimitResource(vol.owner, param.apiName)\n\n\tlocation := LocationResponse{Location: o.region}\n\tresponse, err := MarshalXMLEntity(location)\n\tif err != nil {\n\t\tlog.LogErrorf(\"getBucketLocationHandler: xml marshal fail: requestID(%v) location(%v) err(%v)\",\n\t\t\tGetRequestID(r), location, err)\n\t\treturn\n\t}\n\n\twriteSuccessResponseXML(w, response)\n\treturn\n}\n\n// Get bucket tagging\n// API reference: https://docs.aws.amazon.com/AmazonS3/latest/API/API_GetBucketTagging.html\nfunc (o *ObjectNode) getBucketTaggingHandler(w http.ResponseWriter, r *http.Request) {\n\tvar (\n\t\terr       error\n\t\terrorCode *ErrorCode\n\t)\n\tdefer func() {\n\t\to.errorResponse(w, r, err, errorCode)\n\t}()\n\n\tvar param = ParseRequestParam(r)\n\tif len(param.Bucket()) == 0 {\n\t\terrorCode = InvalidBucketName\n\t\treturn\n\t}\n\tvar vol *Volume\n\tif vol, err = o.getVol(param.Bucket()); err != nil {\n\t\tlog.LogErrorf(\"getBucketTaggingHandler: load volume fail: requestID(%v) volume(%v) err(%v)\",\n\t\t\tGetRequestID(r), param.Bucket(), err)\n\t\treturn\n\t}\n\n\t// QPS and Concurrency Limit\n\trateLimit := o.AcquireRateLimiter()\n\tif err = rateLimit.AcquireLimitResource(vol.owner, param.apiName); err != nil {\n\t\treturn\n\t}\n\tdefer rateLimit.ReleaseLimitResource(vol.owner, param.apiName)\n\n\tvar xattrInfo *proto.XAttrInfo\n\tif xattrInfo, err = vol.GetXAttr(bucketRootPath, XAttrKeyOSSTagging); err != nil {\n\t\tlog.LogErrorf(\"getBucketTaggingHandler: Volume get XAttr fail: requestID(%v) err(%v)\", GetRequestID(r), err)\n\t\treturn\n\t}\n\tossTaggingData := xattrInfo.Get(XAttrKeyOSSTagging)\n\tvar output, _ = ParseTagging(string(ossTaggingData))\n\tif nil == output || len(output.TagSet) == 0 {\n\t\terrorCode = NoSuchTagSetError\n\t\treturn\n\t}\n\n\tresponse, err := MarshalXMLEntity(output)\n\tif err != nil {\n\t\tlog.LogErrorf(\"getBucketTaggingHandler: xml marshal result fail: requestID(%v) result(%v) err(%v)\",\n\t\t\tGetRequestID(r), output, err)\n\t\treturn\n\t}\n\n\twriteSuccessResponseXML(w, response)\n\treturn\n}\n\n// Put bucket tagging\n// API reference: https://docs.aws.amazon.com/AmazonS3/latest/API/API_PutBucketTagging.html\nfunc (o *ObjectNode) putBucketTaggingHandler(w http.ResponseWriter, r *http.Request) {\n\tvar (\n\t\terr       error\n\t\terrorCode *ErrorCode\n\t)\n\tdefer func() {\n\t\to.errorResponse(w, r, err, errorCode)\n\t}()\n\n\tvar param = ParseRequestParam(r)\n\tif param.Bucket() == \"\" {\n\t\terrorCode = InvalidBucketName\n\t\treturn\n\t}\n\tvar vol *Volume\n\tif vol, err = o.getVol(param.Bucket()); err != nil {\n\t\tlog.LogErrorf(\"putBucketTaggingHandler: load volume fail: requestID(%v) volume(%v) err(%v)\",\n\t\t\tGetRequestID(r), param.Bucket(), err)\n\t\treturn\n\t}\n\n\t// QPS and Concurrency Limit\n\trateLimit := o.AcquireRateLimiter()\n\tif err = rateLimit.AcquireLimitResource(vol.owner, param.apiName); err != nil {\n\t\treturn\n\t}\n\tdefer rateLimit.ReleaseLimitResource(vol.owner, param.apiName)\n\n\t_, errorCode = VerifyContentLength(r, BodyLimit)\n\tif errorCode != nil {\n\t\treturn\n\t}\n\tvar body []byte\n\tif body, err = ioutil.ReadAll(r.Body); err != nil {\n\t\tlog.LogErrorf(\"putBucketTaggingHandler: read request body data fail: requestID(%v) err(%v)\",\n\t\t\tGetRequestID(r), err)\n\t\terrorCode = InvalidArgument\n\t\treturn\n\t}\n\n\tvar tagging = NewTagging()\n\tif err = UnmarshalXMLEntity(body, tagging); err != nil {\n\t\tlog.LogWarnf(\"putBucketTaggingHandler: unmarshal request body fail: requestID(%v) body(%v) err(%v)\",\n\t\t\tGetRequestID(r), string(body), err)\n\t\terrorCode = InvalidArgument\n\t\treturn\n\t}\n\tvalidateRes, errorCode := tagging.Validate()\n\tif !validateRes {\n\t\tlog.LogErrorf(\"putBucketTaggingHandler: tagging validate fail: requestID(%v) tagging(%v) err(%v)\",\n\t\t\tGetRequestID(r), tagging, errorCode.Error())\n\t\treturn\n\t}\n\n\terr = vol.SetXAttr(bucketRootPath, XAttrKeyOSSTagging, []byte(tagging.Encode()), false)\n\tif err != nil {\n\t\tlog.LogErrorf(\"putBucketTaggingHandler: set tagging xattr fail: requestID(%v) tagging(%v) err(%v)\",\n\t\t\tGetRequestID(r), tagging.Encode(), err)\n\t\treturn\n\t}\n\n\tw.WriteHeader(http.StatusNoContent)\n\treturn\n}\n\n// Delete bucket tagging\n// API reference: https://docs.aws.amazon.com/AmazonS3/latest/API/API_DeleteBucketTagging.html\nfunc (o *ObjectNode) deleteBucketTaggingHandler(w http.ResponseWriter, r *http.Request) {\n\tvar (\n\t\terr       error\n\t\terrorCode *ErrorCode\n\t)\n\tdefer func() {\n\t\to.errorResponse(w, r, err, errorCode)\n\t}()\n\n\tvar param = ParseRequestParam(r)\n\tif len(param.Bucket()) == 0 {\n\t\terrorCode = InvalidBucketName\n\t\treturn\n\t}\n\tvar vol *Volume\n\tif vol, err = o.getVol(param.Bucket()); err != nil {\n\t\tlog.LogErrorf(\"deleteBucketTaggingHandler: load volume fail: requestID(%v) volume(%v) err(%v)\",\n\t\t\tGetRequestID(r), param.Bucket(), err)\n\t\treturn\n\t}\n\n\t// QPS and Concurrency Limit\n\trateLimit := o.AcquireRateLimiter()\n\tif err = rateLimit.AcquireLimitResource(vol.owner, param.apiName); err != nil {\n\t\treturn\n\t}\n\tdefer rateLimit.ReleaseLimitResource(vol.owner, param.apiName)\n\n\tif err = vol.DeleteXAttr(bucketRootPath, XAttrKeyOSSTagging); err != nil {\n\t\tlog.LogErrorf(\"deleteBucketTaggingHandler: delete tagging xattr fail: requestID(%v) volume(%v) err(%v)\",\n\t\t\tGetRequestID(r), param.Bucket(), err)\n\t\treturn\n\t}\n\n\tw.WriteHeader(http.StatusNoContent)\n\treturn\n}\n\nfunc calculateAuthKey(key string) (authKey string, err error) {\n\th := md5.New()\n\t_, err = h.Write([]byte(key))\n\tif err != nil {\n\t\tlog.LogErrorf(\"calculateAuthKey: calculate auth key fail: key[%v] err[%v]\", key, err)\n\t\treturn\n\t}\n\tcipherStr := h.Sum(nil)\n\treturn strings.ToLower(hex.EncodeToString(cipherStr)), nil\n}\n\nfunc (o *ObjectNode) getUserInfoByAccessKey(accessKey string) (userInfo *proto.UserInfo, err error) {\n\tuserInfo, err = o.userStore.LoadUser(accessKey)\n\treturn\n}\n\n// Put Object Lock Configuration\n// https://docs.aws.amazon.com/AmazonS3/latest/API/API_PutObjectLockConfiguration.html\nfunc (o *ObjectNode) putObjectLockConfigurationHandler(w http.ResponseWriter, r *http.Request) {\n\tvar (\n\t\terr       error\n\t\terrorCode *ErrorCode\n\t)\n\tdefer func() {\n\t\to.errorResponse(w, r, err, errorCode)\n\t}()\n\n\tvar param = ParseRequestParam(r)\n\tif param.Bucket() == \"\" {\n\t\terrorCode = InvalidBucketName\n\t\treturn\n\t}\n\tvar vol *Volume\n\tif vol, err = o.getVol(param.Bucket()); err != nil {\n\t\tlog.LogErrorf(\"putObjectLockConfigurationHandler: load volume fail: requestID(%v) volume(%v) err(%v)\",\n\t\t\tGetRequestID(r), param.Bucket(), err)\n\t\treturn\n\t}\n\tvar body []byte\n\tif body, err = ioutil.ReadAll(io.LimitReader(r.Body, MaxObjectLockSize+1)); err != nil {\n\t\tlog.LogErrorf(\"putObjectLockConfigurationHandler: read request body fail: requestID(%v) volume(%v) err(%v)\",\n\t\t\tGetRequestID(r), vol.Name(), err)\n\t\treturn\n\t}\n\tif len(body) > MaxObjectLockSize {\n\t\terrorCode = EntityTooLarge\n\t\treturn\n\t}\n\tvar config *ObjectLockConfig\n\tif config, err = ParseObjectLockConfigFromXML(body); err != nil {\n\t\tlog.LogErrorf(\"putObjectLockConfigurationHandler: parse object lock config fail: requestID(%v) volume(%v) config(%v) err(%v)\",\n\t\t\tGetRequestID(r), vol.Name(), string(body), err)\n\t\treturn\n\t}\n\tif body, err = json.Marshal(config); err != nil {\n\t\tlog.LogErrorf(\"putObjectLockConfigurationHandler: json.Marshal object lock config fail: requestID(%v) volume(%v) config(%v) err(%v)\",\n\t\t\tGetRequestID(r), vol.Name(), config, err)\n\t\treturn\n\t}\n\tif err = storeObjectLock(body, vol); err != nil {\n\t\tlog.LogErrorf(\"putObjectLockConfigurationHandler: store object lock config fail: requestID(%v) volume(%v) config(%v) err(%v)\",\n\t\t\tGetRequestID(r), vol.Name(), string(body), err)\n\t\treturn\n\t}\n\tvol.metaLoader.storeObjectLock(config)\n\n\tw.WriteHeader(http.StatusNoContent)\n\treturn\n}\n\n// Get Object Lock Configuration\n// https://docs.aws.amazon.com/AmazonS3/latest/API/API_GetObjectLockConfiguration.html\nfunc (o *ObjectNode) getObjectLockConfigurationHandler(w http.ResponseWriter, r *http.Request) {\n\tvar (\n\t\terr       error\n\t\terrorCode *ErrorCode\n\t)\n\tdefer func() {\n\t\to.errorResponse(w, r, err, errorCode)\n\t}()\n\n\tvar param = ParseRequestParam(r)\n\tif param.Bucket() == \"\" {\n\t\terrorCode = InvalidBucketName\n\t\treturn\n\t}\n\n\tvar vol *Volume\n\tif vol, err = o.getVol(param.Bucket()); err != nil {\n\t\tlog.LogErrorf(\"getObjectLockConfigurationHandler: load volume fail: requestID(%v) volume(%v) err(%v)\",\n\t\t\tGetRequestID(r), param.Bucket(), err)\n\t\treturn\n\t}\n\n\tvar config *ObjectLockConfig\n\tif config, err = vol.metaLoader.loadObjectLock(); err != nil {\n\t\tlog.LogErrorf(\"getObjectLockConfigurationHandler: load object lock fail: requestID(%v) volume(%v) err(%v)\",\n\t\t\tGetRequestID(r), vol.Name(), err)\n\t\treturn\n\t}\n\tif config == nil || config.IsEmpty() {\n\t\terrorCode = ObjectLockConfigurationNotFound\n\t\treturn\n\t}\n\tvar data []byte\n\tif data, err = MarshalXMLEntity(config); err != nil {\n\t\tlog.LogErrorf(\"getObjectLockConfigurationHandler: xml marshal fail: requestID(%v) volume(%v) cors(%+v) err(%v)\",\n\t\t\tGetRequestID(r), vol.Name(), config, err)\n\t\treturn\n\t}\n\n\twriteSuccessResponseXML(w, data)\n\treturn\n}\n\nfunc (o *ObjectNode) getUserInfoByAccessKeyV2(accessKey string) (userInfo *proto.UserInfo, err error) {\n\tuserInfo, err = o.userStore.LoadUser(accessKey)\n\tif err == proto.ErrUserNotExists || err == proto.ErrAccessKeyNotExists || err == proto.ErrParamError {\n\t\terr = InvalidAccessKeyId\n\t}\n\treturn\n}\n\nfunc IsValidBucketName(bucketName string, minBucketLength, maxBucketLength int) bool {\n\tif len(bucketName) < minBucketLength || len(bucketName) > maxBucketLength {\n\t\treturn false\n\t}\n\tif !regexBucketName.MatchString(bucketName) {\n\t\treturn false\n\t}\n\treturn true\n}\n", "// Copyright 2019 The CubeFS Authors.\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n// implied. See the License for the specific language governing\n// permissions and limitations under the License.\n\npackage objectnode\n\nimport (\n\t\"encoding/base64\"\n\t\"encoding/hex\"\n\t\"encoding/xml\"\n\t\"io\"\n\t\"io/ioutil\"\n\t\"net/http\"\n\t\"strconv\"\n\t\"strings\"\n\t\"syscall\"\n\t\"time\"\n\n\t\"github.com/cubefs/cubefs/proto\"\n\t\"github.com/cubefs/cubefs/util/log\"\n)\n\nvar (\n\tMinPartNumberValid        = 1\n\tMaxPartNumberValid        = 10000\n\tMinPartSizeBytes   uint64 = 1024 * 1024\n\tMaxPartCopySize    int64  = 5 << 30 // 5GBytes\n)\n\n// Create multipart upload\n// API reference: https://docs.aws.amazon.com/AmazonS3/latest/API/API_CreateMultipartUpload.html\nfunc (o *ObjectNode) createMultipleUploadHandler(w http.ResponseWriter, r *http.Request) {\n\tvar (\n\t\terr       error\n\t\terrorCode *ErrorCode\n\t)\n\tdefer func() {\n\t\to.errorResponse(w, r, err, errorCode)\n\t}()\n\n\tvar param = ParseRequestParam(r)\n\tif param.Bucket() == \"\" {\n\t\terrorCode = InvalidBucketName\n\t\treturn\n\t}\n\tif param.Object() == \"\" {\n\t\terrorCode = InvalidKey\n\t\treturn\n\t}\n\tif len(param.Object()) > MaxKeyLength {\n\t\terrorCode = KeyTooLong\n\t\treturn\n\t}\n\tvar vol *Volume\n\tif vol, err = o.getVol(param.Bucket()); err != nil {\n\t\tlog.LogErrorf(\"createMultipleUploadHandler: load volume fail: requestID(%v) err(%v)\",\n\t\t\tGetRequestID(r), err)\n\t\treturn\n\t}\n\n\t// QPS and Concurrency Limit\n\trateLimit := o.AcquireRateLimiter()\n\tif err = rateLimit.AcquireLimitResource(vol.owner, param.apiName); err != nil {\n\t\treturn\n\t}\n\tdefer rateLimit.ReleaseLimitResource(vol.owner, param.apiName)\n\n\tvar userInfo *proto.UserInfo\n\tif userInfo, err = o.getUserInfoByAccessKeyV2(param.AccessKey()); err != nil {\n\t\tlog.LogErrorf(\"createMultipleUploadHandler: get user info fail: requestID(%v) accessKey(%v) err(%v)\",\n\t\t\tGetRequestID(r), param.AccessKey(), err)\n\t\treturn\n\t}\n\n\t// metadata\n\tcontentType := r.Header.Get(ContentType)\n\tcontentDisposition := r.Header.Get(ContentDisposition)\n\tcacheControl := r.Header.Get(CacheControl)\n\tif len(cacheControl) > 0 && !ValidateCacheControl(cacheControl) {\n\t\terrorCode = InvalidCacheArgument\n\t\treturn\n\t}\n\texpires := r.Header.Get(Expires)\n\tif len(expires) > 0 && !ValidateCacheExpires(expires) {\n\t\terrorCode = InvalidCacheArgument\n\t\treturn\n\t}\n\n\t// Checking user-defined metadata\n\tvar metadata = ParseUserDefinedMetadata(r.Header)\n\n\t// Check 'x-amz-tagging' header\n\tvar tagging *Tagging\n\tif xAmxTagging := r.Header.Get(XAmzTagging); xAmxTagging != \"\" {\n\t\tif tagging, err = ParseTagging(xAmxTagging); err != nil {\n\t\t\terrorCode = InvalidArgument\n\t\t\treturn\n\t\t}\n\t}\n\t// Check ACL\n\tvar acl *AccessControlPolicy\n\tacl, err = ParseACL(r, userInfo.UserID, false, vol.GetOwner() != userInfo.UserID)\n\tif err != nil {\n\t\tlog.LogErrorf(\"createMultipleUploadHandler: parse acl fail: requestID(%v) acl(%+v) err(%v)\",\n\t\t\tGetRequestID(r), acl, err)\n\t\treturn\n\t}\n\tvar opt = &PutFileOption{\n\t\tMIMEType:     contentType,\n\t\tDisposition:  contentDisposition,\n\t\tTagging:      tagging,\n\t\tMetadata:     metadata,\n\t\tCacheControl: cacheControl,\n\t\tExpires:      expires,\n\t\tACL:          acl,\n\t}\n\n\tvar uploadID string\n\tif uploadID, err = vol.InitMultipart(param.Object(), opt); err != nil {\n\t\tlog.LogErrorf(\"createMultipleUploadHandler: init multipart fail: requestID(%v) err(%v)\",\n\t\t\tGetRequestID(r), err)\n\t\treturn\n\t}\n\n\tinitResult := InitMultipartResult{\n\t\tBucket:   param.Bucket(),\n\t\tKey:      param.Object(),\n\t\tUploadId: uploadID,\n\t}\n\tresponse, err := MarshalXMLEntity(initResult)\n\tif err != nil {\n\t\tlog.LogErrorf(\"createMultipleUploadHandler: xml marshal result fail: requestID(%v) result(%v) err(%v)\",\n\t\t\tGetRequestID(r), initResult, err)\n\t\treturn\n\t}\n\n\twriteSuccessResponseXML(w, response)\n\treturn\n}\n\n// Upload part\n// Uploads a part in a multipart upload.\n// API reference: https://docs.aws.amazon.com/AmazonS3/latest/API/API_UploadPart.html .\nfunc (o *ObjectNode) uploadPartHandler(w http.ResponseWriter, r *http.Request) {\n\tvar (\n\t\terr       error\n\t\terrorCode *ErrorCode\n\t)\n\tdefer func() {\n\t\to.errorResponse(w, r, err, errorCode)\n\t}()\n\n\t// check args\n\tvar param = ParseRequestParam(r)\n\t// get upload id and part number\n\tuploadId := param.GetVar(ParamUploadId)\n\tpartNumber := param.GetVar(ParamPartNumber)\n\tif uploadId == \"\" || partNumber == \"\" {\n\t\tlog.LogErrorf(\"uploadPartHandler: illegal uploadID or partNumber, requestID(%v)\", GetRequestID(r))\n\t\terrorCode = InvalidArgument\n\t\treturn\n\t}\n\n\tvar partNumberInt uint16\n\tif partNumberInt, err = safeConvertStrToUint16(partNumber); err != nil {\n\t\tlog.LogErrorf(\"uploadPartHandler: parse part number fail, requestID(%v) raw(%v) err(%v)\",\n\t\t\tGetRequestID(r), partNumber, err)\n\t\terrorCode = InvalidArgument\n\t\treturn\n\t}\n\tif param.Bucket() == \"\" {\n\t\terrorCode = InvalidBucketName\n\t\treturn\n\t}\n\tif param.Object() == \"\" {\n\t\terrorCode = InvalidKey\n\t\treturn\n\t}\n\n\t// Get request MD5, if request MD5 is not empty, compute and verify it.\n\trequestMD5 := r.Header.Get(ContentMD5)\n\tif requestMD5 != \"\" {\n\t\tdecoded, err := base64.StdEncoding.DecodeString(requestMD5)\n\t\tif err != nil {\n\t\t\terrorCode = InvalidDigest\n\t\t\treturn\n\t\t}\n\t\trequestMD5 = hex.EncodeToString(decoded)\n\t}\n\n\t// Verify ContentLength\n\tlength := GetContentLength(r)\n\tif length > SinglePutLimit {\n\t\terrorCode = EntityTooLarge\n\t\treturn\n\t}\n\tif length < 0 {\n\t\terrorCode = MissingContentLength\n\t\treturn\n\t}\n\n\tvar vol *Volume\n\tif vol, err = o.getVol(param.Bucket()); err != nil {\n\t\tlog.LogErrorf(\"uploadPartHandler: load volume fail: requestID(%v) err(%v)\",\n\t\t\tGetRequestID(r), err)\n\t\treturn\n\t}\n\n\t// ObjectLock  Config\n\tobjetLock, err := vol.metaLoader.loadObjectLock()\n\tif err != nil {\n\t\tlog.LogErrorf(\"putObjectHandler: load volume objetLock: requestID(%v)  volume(%v) err(%v)\",\n\t\t\tGetRequestID(r), param.Bucket(), err)\n\t\treturn\n\t}\n\tif objetLock != nil && objetLock.ToRetention() != nil && requestMD5 == \"\" {\n\t\terrorCode = NoContentMd5HeaderErr\n\t\treturn\n\t}\n\n\t// QPS and Concurrency Limit\n\trateLimit := o.AcquireRateLimiter()\n\tif err = rateLimit.AcquireLimitResource(vol.owner, param.apiName); err != nil {\n\t\treturn\n\t}\n\tdefer rateLimit.ReleaseLimitResource(vol.owner, param.apiName)\n\n\t// Flow Control\n\tvar reader io.Reader\n\tif length > DefaultFlowLimitSize {\n\t\treader = rateLimit.GetReader(vol.owner, param.apiName, r.Body)\n\t} else {\n\t\treader = r.Body\n\t}\n\tvar fsFileInfo *FSFileInfo\n\tif fsFileInfo, err = vol.WritePart(param.Object(), uploadId, uint16(partNumberInt), reader); err != nil {\n\t\tlog.LogErrorf(\"uploadPartHandler: write part fail: requestID(%v) volume(%v) path(%v) uploadId(%v) part(%v) err(%v)\",\n\t\t\tGetRequestID(r), vol.Name(), param.Object(), uploadId, partNumberInt, err)\n\t\terr = handleWritePartErr(err)\n\t\treturn\n\t}\n\t// check content MD5\n\tif requestMD5 != \"\" && requestMD5 != fsFileInfo.ETag {\n\t\tlog.LogErrorf(\"uploadPartHandler: MD5 validate fail: requestID(%v) volume(%v) path(%v) requestMD5(%v) serverMD5(%v)\",\n\t\t\tGetRequestID(r), vol.Name(), param.Object(), requestMD5, fsFileInfo.ETag)\n\t\terrorCode = BadDigest\n\t\treturn\n\t}\n\n\t// write header to response\n\tw.Header()[ETag] = []string{\"\\\"\" + fsFileInfo.ETag + \"\\\"\"}\n\treturn\n}\n\n// Upload part copy\n// Uploads a part in a multipart upload by copying a existed object.\n// API reference: https://docs.aws.amazon.com/AmazonS3/latest/API/API_UploadPartCopy.html .\nfunc (o *ObjectNode) uploadPartCopyHandler(w http.ResponseWriter, r *http.Request) {\n\tvar (\n\t\terr       error\n\t\terrorCode *ErrorCode\n\t)\n\tdefer func() {\n\t\to.errorResponse(w, r, err, errorCode)\n\t}()\n\n\t// step1: check args\n\tvar param = ParseRequestParam(r)\n\tuploadId := param.GetVar(ParamUploadId)\n\tpartNumber := param.GetVar(ParamPartNumber)\n\tif uploadId == \"\" || partNumber == \"\" {\n\t\tlog.LogErrorf(\"uploadPartCopyHandler: illegal uploadID or partNumber, requestID(%v)\", GetRequestID(r))\n\t\terrorCode = InvalidArgument\n\t\treturn\n\t}\n\tvar partNumberInt uint16\n\tif partNumberInt, err = safeConvertStrToUint16(partNumber); err != nil {\n\t\tlog.LogErrorf(\"uploadPartCopyHandler: parse part number fail, requestID(%v) raw(%v) err(%v)\",\n\t\t\tGetRequestID(r), partNumber, err)\n\t\terrorCode = InvalidArgument\n\t\treturn\n\t}\n\tif param.Bucket() == \"\" {\n\t\terrorCode = InvalidBucketName\n\t\treturn\n\t}\n\tif param.Object() == \"\" {\n\t\terrorCode = InvalidKey\n\t\treturn\n\t}\n\tvar vol *Volume\n\tif vol, err = o.getVol(param.Bucket()); err != nil {\n\t\tlog.LogErrorf(\"uploadPartCopyHandler: load volume fail: requestID(%v) volume(%v) err(%v)\",\n\t\t\tGetRequestID(r), param.Bucket(), err)\n\t\treturn\n\t}\n\n\t// QPS and Concurrency Limit\n\trateLimit := o.AcquireRateLimiter()\n\tif err = rateLimit.AcquireLimitResource(vol.owner, param.apiName); err != nil {\n\t\treturn\n\t}\n\tdefer rateLimit.ReleaseLimitResource(vol.owner, param.apiName)\n\n\t// step2: extract params from req\n\tsrcBucket, srcObject, _, err := extractSrcBucketKey(r)\n\tif err != nil {\n\t\tlog.LogDebugf(\"uploadPartCopyHandler: copySource(%v) argument invalid: requestID(%v)\",\n\t\t\tr.Header.Get(XAmzCopySource), GetRequestID(r))\n\t\treturn\n\t}\n\n\t// step3: get srcObject metadata\n\tvar srcVol *Volume\n\tif srcVol, err = o.getVol(srcBucket); err != nil {\n\t\tlog.LogErrorf(\"uploadPartCopyHandler: load src volume fail: requestID(%v) volume(%v) err(%v)\",\n\t\t\tGetRequestID(r), srcBucket, err)\n\t\treturn\n\t}\n\tsrcFileInfo, _, err := srcVol.ObjectMeta(srcObject)\n\tif err != nil {\n\t\tlog.LogErrorf(\"uploadPartCopyHandler: get fileMeta fail: requestId(%v) srcVol(%v) path(%v) err(%v)\",\n\t\t\tGetRequestID(r), srcBucket, srcObject, err)\n\t\tif err == syscall.ENOENT {\n\t\t\terrorCode = NoSuchKey\n\t\t}\n\t\treturn\n\t}\n\n\terrorCode = CheckConditionInHeader(r, srcFileInfo)\n\tif errorCode != nil {\n\t\treturn\n\t}\n\n\t// step4: extract range params\n\tcopyRange := r.Header.Get(XAmzCopySourceRange)\n\tfirstByte, copyLength, errorCode := determineCopyRange(copyRange, srcFileInfo.Size)\n\tif errorCode != nil {\n\t\treturn\n\t}\n\tsize, err := safeConvertInt64ToUint64(srcFileInfo.Size)\n\tif err != nil {\n\t\treturn\n\t}\n\tfb, err := safeConvertInt64ToUint64(firstByte)\n\tif err != nil {\n\t\treturn\n\t}\n\tcl, err := safeConvertInt64ToUint64(copyLength)\n\tif err != nil {\n\t\treturn\n\t}\n\treader, writer := io.Pipe()\n\tgo func() {\n\t\terr = srcVol.readFile(srcFileInfo.Inode, size, srcObject, writer, fb, cl)\n\t\tif err != nil {\n\t\t\tlog.LogErrorf(\"uploadPartCopyHandler: read srcObj err(%v): requestId(%v) srcVol(%v) path(%v)\",\n\t\t\t\terr, GetRequestID(r), srcBucket, srcObject)\n\t\t}\n\t\twriter.CloseWithError(err)\n\t}()\n\n\t// step5: upload part by copy and flow control\n\tvar rd io.Reader\n\tif copyLength > DefaultFlowLimitSize {\n\t\trd = rateLimit.GetReader(vol.owner, param.apiName, reader)\n\t} else {\n\t\trd = reader\n\t}\n\tfsFileInfo, err := vol.WritePart(param.Object(), uploadId, uint16(partNumberInt), rd)\n\tif err != nil {\n\t\tlog.LogErrorf(\"uploadPartCopyHandler: write part fail: requestID(%v) volume(%v) path(%v) uploadId(%v) part(%v) err(%v)\",\n\t\t\tGetRequestID(r), vol.Name(), param.Object(), uploadId, partNumberInt, err)\n\t\tif err == syscall.ENOENT {\n\t\t\terrorCode = NoSuchUpload\n\t\t\treturn\n\t\t}\n\t\tif err == syscall.EAGAIN {\n\t\t\terrorCode = ConflictUploadRequest\n\t\t\treturn\n\t\t}\n\t\tif err == io.ErrUnexpectedEOF {\n\t\t\terrorCode = EntityTooSmall\n\t\t}\n\t\treturn\n\t}\n\n\tEtag := \"\\\"\" + fsFileInfo.ETag + \"\\\"\"\n\tw.Header()[ETag] = []string{Etag}\n\tresponse := NewS3CopyPartResult(Etag, fsFileInfo.CreateTime.UTC().Format(time.RFC3339)).String()\n\n\twriteSuccessResponseXML(w, []byte(response))\n\treturn\n}\n\nfunc handleWritePartErr(err error) error {\n\tif err == syscall.ENOENT {\n\t\treturn NoSuchUpload\n\t}\n\tif err == syscall.EEXIST {\n\t\treturn ConflictUploadRequest\n\t}\n\tif err == io.ErrUnexpectedEOF {\n\t\treturn EntityTooSmall\n\t}\n\treturn err\n}\n\n// List parts\n// API reference: https://docs.aws.amazon.com/AmazonS3/latest/API/API_ListParts.html\nfunc (o *ObjectNode) listPartsHandler(w http.ResponseWriter, r *http.Request) {\n\tvar (\n\t\terr       error\n\t\terrorCode *ErrorCode\n\t)\n\tdefer func() {\n\t\to.errorResponse(w, r, err, errorCode)\n\t}()\n\n\tvar param = ParseRequestParam(r)\n\t// get upload id and part number\n\tuploadId := param.GetVar(ParamUploadId)\n\tmaxParts := param.GetVar(ParamMaxParts)\n\tpartNoMarker := param.GetVar(ParamPartNoMarker)\n\n\tvar maxPartsInt uint64\n\tvar partNoMarkerInt uint64\n\n\tif uploadId == \"\" {\n\t\tlog.LogErrorf(\"listPartsHandler: illegal update ID, requestID(%v) err(%v)\", GetRequestID(r), err)\n\t\terrorCode = InvalidArgument\n\t\treturn\n\t}\n\n\tif maxParts == \"\" {\n\t\tmaxPartsInt = MaxParts\n\t} else {\n\t\tmaxPartsInt, err = strconv.ParseUint(maxParts, 10, 64)\n\t\tif err != nil {\n\t\t\tlog.LogErrorf(\"listPartsHandler: parse max parts fail: requestID(%v) raw(%v) err(%v)\",\n\t\t\t\tGetRequestID(r), maxParts, err)\n\t\t\terrorCode = InvalidArgument\n\t\t\treturn\n\t\t}\n\t\tif maxPartsInt > MaxParts {\n\t\t\tmaxPartsInt = MaxParts\n\t\t}\n\t}\n\tif partNoMarker != \"\" {\n\t\tres, err := strconv.ParseUint(partNoMarker, 10, 64)\n\t\tif err != nil {\n\t\t\tlog.LogErrorf(\"listPatsHandler: parse part number marker fail: requestID(%v) raw(%v) err(%v)\",\n\t\t\t\tGetRequestID(r), partNoMarker, err)\n\t\t\terrorCode = InvalidArgument\n\t\t\treturn\n\t\t}\n\t\tpartNoMarkerInt = res\n\t}\n\n\tif param.Bucket() == \"\" {\n\t\terrorCode = InvalidBucketName\n\t\treturn\n\t}\n\tif param.Object() == \"\" {\n\t\terrorCode = InvalidKey\n\t\treturn\n\t}\n\n\tvar vol *Volume\n\tif vol, err = o.getVol(param.Bucket()); err != nil {\n\t\tlog.LogErrorf(\"listPartsHandler: load volume fail: requestID(%v) err(%v)\",\n\t\t\tGetRequestID(r), err)\n\t\treturn\n\t}\n\n\t// QPS and Concurrency Limit\n\trateLimit := o.AcquireRateLimiter()\n\tif err = rateLimit.AcquireLimitResource(vol.owner, param.apiName); err != nil {\n\t\treturn\n\t}\n\tdefer rateLimit.ReleaseLimitResource(vol.owner, param.apiName)\n\n\tfsParts, nextMarker, isTruncated, err := vol.ListParts(param.Object(), uploadId, maxPartsInt, partNoMarkerInt)\n\tif err != nil {\n\t\tlog.LogErrorf(\"listPartsHandler: list parts fail, requestID(%v) uploadID(%v) maxParts(%v) partNoMarker(%v) err(%v)\",\n\t\t\tGetRequestID(r), uploadId, maxPartsInt, partNoMarkerInt, err)\n\t\tif err == syscall.ENOENT {\n\t\t\terrorCode = NoSuchUpload\n\t\t}\n\t\treturn\n\t}\n\tlog.LogDebugf(\"listPartsHandler: Volume list parts, \"+\n\t\t\"requestID(%v) uploadID(%v) maxParts(%v) partNoMarker(%v) numFSParts(%v) nextMarker(%v) isTruncated(%v)\",\n\t\tGetRequestID(r), uploadId, maxPartsInt, partNoMarkerInt, len(fsParts), nextMarker, isTruncated)\n\n\t// get owner\n\tbucketOwner := NewBucketOwner(vol)\n\tinitiator := NewInitiator(vol)\n\n\t// get parts\n\tparts := NewParts(fsParts)\n\n\tlistPartsResult := ListPartsResult{\n\t\tBucket:       param.Bucket(),\n\t\tKey:          param.Object(),\n\t\tUploadId:     uploadId,\n\t\tStorageClass: StorageClassStandard,\n\t\tNextMarker:   nextMarker,\n\t\tMaxParts:     maxPartsInt,\n\t\tIsTruncated:  isTruncated,\n\t\tParts:        parts,\n\t\tOwner:        bucketOwner,\n\t\tInitiator:    initiator,\n\t}\n\tresponse, err := MarshalXMLEntity(listPartsResult)\n\tif err != nil {\n\t\tlog.LogErrorf(\"listPartsHandler: xml marshal result fail: requestID(%v) err(%v)\",\n\t\t\tGetRequestID(r), err)\n\t\treturn\n\t}\n\n\twriteSuccessResponseXML(w, response)\n\treturn\n}\n\nfunc (o *ObjectNode) checkReqParts(param *RequestParam, reqParts *CompleteMultipartUploadRequest, multipartInfo *proto.MultipartInfo) (\n\tdiscardedPartInodes map[uint64]uint16, committedPartInfo *proto.MultipartInfo, err error) {\n\tif len(reqParts.Parts) <= 0 {\n\t\terr = InvalidPart\n\t\tlog.LogErrorf(\"checkReqParts: upload part is empty: requestID(%v) volume(%v)\", GetRequestID(param.r), param.Bucket())\n\t\treturn\n\t}\n\n\treqInfo := make(map[int]int, 0)\n\tfor _, reqPart := range reqParts.Parts {\n\t\treqInfo[reqPart.PartNumber] = 0\n\t}\n\n\tcommittedPartInfo = &proto.MultipartInfo{\n\t\tID:       multipartInfo.ID,\n\t\tPath:     multipartInfo.Path,\n\t\tInitTime: multipartInfo.InitTime,\n\t\tParts:    make([]*proto.MultipartPartInfo, 0),\n\t\tExtend:   make(map[string]string),\n\t}\n\tfor key, val := range multipartInfo.Extend {\n\t\tcommittedPartInfo.Extend[key] = val\n\t}\n\tuploadedInfo := make(map[uint16]string, 0)\n\tdiscardedPartInodes = make(map[uint64]uint16, 0)\n\tfor _, uploadedPart := range multipartInfo.Parts {\n\t\tlog.LogDebugf(\"checkReqParts: server save part check: requestID(%v) volume(%v) part(%v)\",\n\t\t\tGetRequestID(param.r), param.Bucket(), uploadedPart)\n\t\teTag := uploadedPart.MD5\n\t\tif strings.Contains(eTag, \"\\\"\") {\n\t\t\teTag = strings.ReplaceAll(eTag, \"\\\"\", \"\")\n\t\t}\n\t\tuploadedInfo[uploadedPart.ID] = eTag\n\t\tif _, existed := reqInfo[int(uploadedPart.ID)]; !existed {\n\t\t\tdiscardedPartInodes[uploadedPart.Inode] = uploadedPart.ID\n\t\t} else {\n\t\t\tcommittedPartInfo.Parts = append(committedPartInfo.Parts, uploadedPart)\n\t\t}\n\t}\n\n\tfor idx, reqPart := range reqParts.Parts {\n\t\tif reqPart.PartNumber > len(multipartInfo.Parts) {\n\t\t\terr = InvalidPart\n\t\t\treturn\n\t\t}\n\t\tif multipartInfo.Parts[reqPart.PartNumber-1].Size < MinPartSizeBytes && idx < len(reqParts.Parts)-1 {\n\t\t\terr = EntityTooSmall\n\t\t\treturn\n\t\t}\n\t\tif eTag, existed := uploadedInfo[uint16(reqPart.PartNumber)]; !existed {\n\t\t\tlog.LogErrorf(\"checkReqParts: request part not existed: requestID(%v) volume(%v) part(%v)\",\n\t\t\t\tGetRequestID(param.r), param.Bucket(), reqPart)\n\t\t\terr = InvalidPart\n\t\t\treturn\n\t\t} else {\n\t\t\treqEtag := reqPart.ETag\n\t\t\tif strings.Contains(reqEtag, \"\\\"\") {\n\t\t\t\treqEtag = strings.ReplaceAll(reqEtag, \"\\\"\", \"\")\n\t\t\t}\n\t\t\tif eTag != reqEtag {\n\t\t\t\tlog.LogErrorf(\"checkReqParts: part(%v) md5 not matched: requestID(%v) volume(%v) reqETag(%v) eTag(%v)\",\n\t\t\t\t\treqPart.PartNumber, GetRequestID(param.r), param.Bucket(), reqEtag, eTag)\n\t\t\t\terr = InvalidPart\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\t}\n\treturn\n}\n\n// Complete multipart\n// API reference: https://docs.aws.amazon.com/AmazonS3/latest/API/API_CompleteMultipartUpload.html\nfunc (o *ObjectNode) completeMultipartUploadHandler(w http.ResponseWriter, r *http.Request) {\n\tvar (\n\t\terr       error\n\t\terrorCode *ErrorCode\n\t)\n\tdefer func() {\n\t\to.errorResponse(w, r, err, errorCode)\n\t}()\n\n\tvar param = ParseRequestParam(r)\n\t// get upload id and part number\n\tuploadId := param.GetVar(ParamUploadId)\n\tif uploadId == \"\" {\n\t\tlog.LogErrorf(\"completeMultipartUploadHandler: non upload ID specified: requestID(%v)\", GetRequestID(r))\n\t\terrorCode = InvalidArgument\n\t\treturn\n\t}\n\n\tif param.Bucket() == \"\" {\n\t\terrorCode = InvalidBucketName\n\t\treturn\n\t}\n\tif param.Object() == \"\" {\n\t\terrorCode = InvalidKey\n\t\treturn\n\t}\n\tif len(param.Object()) > MaxKeyLength {\n\t\terrorCode = KeyTooLong\n\t\treturn\n\t}\n\n\tvar vol *Volume\n\tif vol, err = o.getVol(param.Bucket()); err != nil {\n\t\tlog.LogErrorf(\"completeMultipartUploadHandler: load volume fail: requestID(%v) err(%v)\",\n\t\t\tGetRequestID(r), err)\n\t\treturn\n\t}\n\n\t// QPS and Concurrency Limit\n\trateLimit := o.AcquireRateLimiter()\n\tif err = rateLimit.AcquireLimitResource(vol.owner, param.apiName); err != nil {\n\t\treturn\n\t}\n\tdefer rateLimit.ReleaseLimitResource(vol.owner, param.apiName)\n\n\t// get uploaded part info in request\n\t_, errorCode = VerifyContentLength(r, BodyLimit)\n\tif errorCode != nil {\n\t\treturn\n\t}\n\trequestBytes, err := ioutil.ReadAll(r.Body)\n\tif err != nil && err != io.EOF {\n\t\tlog.LogErrorf(\"completeMultipartUploadHandler: read request body fail: requestID(%v) err(%v)\",\n\t\t\tGetRequestID(r), err)\n\t\treturn\n\t}\n\tmultipartUploadRequest := &CompleteMultipartUploadRequest{}\n\terr = UnmarshalXMLEntity(requestBytes, multipartUploadRequest)\n\tif err != nil {\n\t\tlog.LogErrorf(\"completeMultipartUploadHandler: unmarshal xml fail: requestID(%v) err(%v)\",\n\t\t\tGetRequestID(r), err)\n\t\terrorCode = MalformedXML\n\t\treturn\n\t}\n\t// check part parameter\n\tpartsLen := len(multipartUploadRequest.Parts)\n\tif partsLen > MaxPartNumberValid {\n\t\terrorCode = InvalidMaxPartNumber\n\t\treturn\n\t}\n\tif partsLen < MinPartNumberValid {\n\t\terrorCode = InvalidMinPartNumber\n\t\treturn\n\t}\n\tpreviousPartNum := 0\n\tfor _, p := range multipartUploadRequest.Parts {\n\t\tif p.PartNumber < previousPartNum {\n\t\t\tlog.LogDebugf(\"completeMultipartUploadHandler: invalid part order: requestID(%v) prevPartNum=%d partNum=%d\",\n\t\t\t\tGetRequestID(r), previousPartNum, p.PartNumber)\n\t\t\terrorCode = InvalidPartOrder\n\t\t\treturn\n\t\t}\n\t\tpreviousPartNum = p.PartNumber\n\t\tetag := strings.ReplaceAll(p.ETag, \"\\\"\", \"\")\n\t\tif etag == \"\" {\n\t\t\terrorCode = InvalidPart\n\t\t\treturn\n\t\t}\n\t}\n\t// get multipart info\n\tvar multipartInfo *proto.MultipartInfo\n\tif multipartInfo, err = vol.mw.GetMultipart_ll(param.object, uploadId); err != nil {\n\t\tlog.LogErrorf(\"completeMultipartUploadHandler: meta get multipart fail: requestID(%v) path(%v) err(%v)\",\n\t\t\tGetRequestID(r), param.object, err)\n\t\tif err == syscall.ENOENT {\n\t\t\terrorCode = NoSuchUpload\n\t\t\treturn\n\t\t}\n\t\tif err == syscall.EINVAL {\n\t\t\terrorCode = ObjectModeConflict\n\t\t}\n\t\treturn\n\t}\n\n\tdiscardedInods, committedPartInfo, err := o.checkReqParts(param, multipartUploadRequest, multipartInfo)\n\tif err != nil {\n\t\tlog.LogWarnf(\"completeMultipartUploadHandler: check request parts fail: requestID(%v) path(%v) err(%v)\",\n\t\t\tGetRequestID(r), param.object, errorCode)\n\t\treturn\n\t}\n\tfsFileInfo, err := vol.CompleteMultipart(param.Object(), uploadId, committedPartInfo, discardedInods)\n\tif err != nil {\n\t\tlog.LogErrorf(\"completeMultipartUploadHandler: complete multipart fail: requestID(%v) volume(%v) uploadID(%v) err(%v)\",\n\t\t\tGetRequestID(r), param.Bucket(), uploadId, err)\n\t\tif err == syscall.EINVAL {\n\t\t\terrorCode = ObjectModeConflict\n\t\t}\n\t\treturn\n\t}\n\n\tcompleteResult := CompleteMultipartResult{\n\t\tBucket: param.Bucket(),\n\t\tKey:    param.Object(),\n\t\tETag:   wrapUnescapedQuot(fsFileInfo.ETag),\n\t}\n\tresponse, err := MarshalXMLEntity(completeResult)\n\tif err != nil {\n\t\tlog.LogErrorf(\"completeMultipartUploadHandler: xml marshal result fail: requestID(%v) result(%v) err(%v)\",\n\t\t\tGetRequestID(r), completeResult, err)\n\t\treturn\n\t}\n\n\twriteSuccessResponseXML(w, response)\n\treturn\n}\n\n// Abort multipart\n// API reference: https://docs.aws.amazon.com/AmazonS3/latest/API/API_AbortMultipartUpload.html .\nfunc (o *ObjectNode) abortMultipartUploadHandler(w http.ResponseWriter, r *http.Request) {\n\tvar (\n\t\terr       error\n\t\terrorCode *ErrorCode\n\t)\n\tdefer func() {\n\t\to.errorResponse(w, r, err, errorCode)\n\t}()\n\n\t// check args\n\tvar param = ParseRequestParam(r)\n\tuploadId := param.GetVar(ParamUploadId)\n\tif uploadId == \"\" {\n\t\terrorCode = InvalidArgument\n\t\treturn\n\t}\n\tif param.Bucket() == \"\" {\n\t\terrorCode = InvalidBucketName\n\t\treturn\n\t}\n\tif param.Object() == \"\" {\n\t\terrorCode = InvalidKey\n\t\treturn\n\t}\n\n\tvar vol *Volume\n\tif vol, err = o.getVol(param.Bucket()); err != nil {\n\t\tlog.LogErrorf(\"abortMultipartUploadHandler: load volume fail: requestID(%v) err(%v)\",\n\t\t\tGetRequestID(r), err)\n\t\treturn\n\t}\n\n\t// QPS and Concurrency Limit\n\trateLimit := o.AcquireRateLimiter()\n\tif err = rateLimit.AcquireLimitResource(vol.owner, param.apiName); err != nil {\n\t\treturn\n\t}\n\tdefer rateLimit.ReleaseLimitResource(vol.owner, param.apiName)\n\n\t// Abort multipart upload\n\tif err = vol.AbortMultipart(param.Object(), uploadId); err != nil {\n\t\tlog.LogErrorf(\"abortMultipartUploadHandler: abort multipart fail: requestID(%v) uploadID(%v) err(%v)\",\n\t\t\tGetRequestID(r), uploadId, err)\n\t\tif err == syscall.ENOENT {\n\t\t\terrorCode = NoSuchUpload\n\t\t}\n\t\treturn\n\t}\n\n\tw.WriteHeader(http.StatusNoContent)\n\treturn\n}\n\n// List multipart uploads\n// API reference: https://docs.aws.amazon.com/AmazonS3/latest/API/API_ListMultipartUploads.html\nfunc (o *ObjectNode) listMultipartUploadsHandler(w http.ResponseWriter, r *http.Request) {\n\tvar (\n\t\terr       error\n\t\terrorCode *ErrorCode\n\t)\n\tdefer func() {\n\t\to.errorResponse(w, r, err, errorCode)\n\t}()\n\n\tvar param = ParseRequestParam(r)\n\t// get list uploads parameter\n\tprefix := param.GetVar(ParamPrefix)\n\tkeyMarker := param.GetVar(ParamKeyMarker)\n\tdelimiter := param.GetVar(ParamPartDelimiter)\n\tmaxUploads := param.GetVar(ParamPartMaxUploads)\n\tuploadIdMarker := param.GetVar(ParamUploadIdMarker)\n\n\tvar maxUploadsInt uint64\n\tif maxUploads == \"\" {\n\t\tmaxUploadsInt = MaxUploads\n\t} else {\n\t\tmaxUploadsInt, err = strconv.ParseUint(maxUploads, 10, 64)\n\t\tif err != nil {\n\t\t\tlog.LogErrorf(\"listMultipartUploadsHandler: parse max uploads fail: requestID(%v) raw(%v) err(%v)\",\n\t\t\t\tGetRequestID(r), maxUploads, err)\n\t\t\terrorCode = InvalidArgument\n\t\t\treturn\n\t\t}\n\t\tif maxUploadsInt > MaxUploads {\n\t\t\tmaxUploadsInt = MaxUploads\n\t\t}\n\t}\n\n\tif param.Bucket() == \"\" {\n\t\terrorCode = InvalidBucketName\n\t\treturn\n\t}\n\n\tvar vol *Volume\n\tif vol, err = o.getVol(param.Bucket()); err != nil {\n\t\tlog.LogErrorf(\"listMultipartUploadsHandler: load volume fail: requestID(%v) vol(%v) err(%v)\",\n\t\t\tGetRequestID(r), param.Bucket(), err)\n\t\treturn\n\t}\n\n\t// QPS and Concurrency Limit\n\trateLimit := o.AcquireRateLimiter()\n\tif err = rateLimit.AcquireLimitResource(vol.owner, param.apiName); err != nil {\n\t\treturn\n\t}\n\tdefer rateLimit.ReleaseLimitResource(vol.owner, param.apiName)\n\n\tfsUploads, nextKeyMarker, nextUploadIdMarker, IsTruncated, prefixes, err := vol.ListMultipartUploads(prefix, delimiter, keyMarker, uploadIdMarker, maxUploadsInt)\n\tif err != nil {\n\t\tlog.LogErrorf(\"listMultipartUploadsHandler: list multipart uploads fail: requestID(%v) err(%v)\",\n\t\t\tGetRequestID(r), err)\n\t\treturn\n\t}\n\n\tuploads := NewUploads(fsUploads, param.AccessKey())\n\n\tvar commonPrefixes = make([]*CommonPrefix, 0)\n\tfor _, prefix := range prefixes {\n\t\tcommonPrefix := &CommonPrefix{\n\t\t\tPrefix: prefix,\n\t\t}\n\t\tcommonPrefixes = append(commonPrefixes, commonPrefix)\n\t}\n\n\tlistUploadsResult := ListUploadsResult{\n\t\tBucket:             param.Bucket(),\n\t\tKeyMarker:          keyMarker,\n\t\tUploadIdMarker:     uploadIdMarker,\n\t\tNextKeyMarker:      nextKeyMarker,\n\t\tNextUploadIdMarker: nextUploadIdMarker,\n\t\tDelimiter:          delimiter,\n\t\tPrefix:             prefix,\n\t\tMaxUploads:         maxUploadsInt,\n\t\tIsTruncated:        IsTruncated,\n\t\tUploads:            uploads,\n\t\tCommonPrefixes:     commonPrefixes,\n\t}\n\tresponse, err := MarshalXMLEntity(listUploadsResult)\n\tif err != nil {\n\t\tlog.LogErrorf(\"listMultipartUploadsHandler: xml marshal result fail: requestID(%v) result(%v) err(%v)\",\n\t\t\tGetRequestID(r), listUploadsResult, err)\n\t\treturn\n\t}\n\n\twriteSuccessResponseXML(w, response)\n\treturn\n}\n\nfunc determineCopyRange(copyRange string, fsize int64) (firstByte, copyLength int64, err *ErrorCode) {\n\tif copyRange == \"\" { // whole file\n\t\treturn 0, fsize, nil\n\t}\n\tfirstByte, lastByte, err := extractCopyRangeParam(copyRange)\n\tif err != nil {\n\t\treturn\n\t}\n\tif !(0 <= firstByte && firstByte <= lastByte && lastByte < fsize) {\n\t\terr = InvalidArgument\n\t\treturn\n\t}\n\tcopyLength = lastByte + 1 - firstByte\n\tif copyLength > MaxPartCopySize {\n\t\terr = EntityTooLarge\n\t\treturn\n\t}\n\treturn\n}\n\nfunc extractCopyRangeParam(copRange string) (firstByte, lastByte int64, err *ErrorCode) {\n\t// copRange must use the form : bytes=first-last\n\tstrs := strings.SplitN(copRange, \"=\", 2)\n\tif len(strs) < 2 {\n\t\terr = InvalidArgument\n\t\treturn\n\t}\n\tbyteRange := strings.SplitN(strs[1], \"-\", 2)\n\tif len(byteRange) < 2 {\n\t\terr = InvalidArgument\n\t\treturn\n\t}\n\tfirstByteStr, lastByteStr := byteRange[0], byteRange[1]\n\tfirstByte, err1 := strconv.ParseInt(firstByteStr, 10, 64)\n\tlastByte, err2 := strconv.ParseInt(lastByteStr, 10, 64)\n\tif err1 != nil || err2 != nil {\n\t\terr = InvalidArgument\n\t\treturn\n\t}\n\treturn\n}\n\ntype S3CopyPartResult struct {\n\tXMLName      xml.Name\n\tETag         string `xml:\"ETag\"`\n\tLastModified string `xml:\"LastModified\"`\n}\n\nfunc NewS3CopyPartResult(etag, lastModified string) *S3CopyPartResult {\n\treturn &S3CopyPartResult{\n\t\tXMLName: xml.Name{\n\t\t\tSpace: S3Namespace,\n\t\t\tLocal: \"CopyPartResult\",\n\t\t},\n\t\tETag:         etag,\n\t\tLastModified: lastModified,\n\t}\n}\n\nfunc (s *S3CopyPartResult) String() string {\n\tb, _ := xml.Marshal(s)\n\treturn string(b)\n}\n", "// Copyright 2019 The CubeFS Authors.\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n// implied. See the License for the specific language governing\n// permissions and limitations under the License.\n\npackage objectnode\n\nimport (\n\t\"encoding/base64\"\n\t\"encoding/hex\"\n\t\"encoding/xml\"\n\t\"fmt\"\n\t\"io\"\n\t\"io/ioutil\"\n\t\"net/http\"\n\t\"net/url\"\n\t\"regexp\"\n\t\"sort\"\n\t\"strconv\"\n\t\"strings\"\n\t\"syscall\"\n\t\"time\"\n\n\t\"github.com/cubefs/cubefs/proto\"\n\t\"github.com/cubefs/cubefs/util/log\"\n)\n\nvar (\n\trangeRegexp  = regexp.MustCompile(\"^bytes=(\\\\d)*-(\\\\d)*$\")\n\tMaxKeyLength = 750\n)\n\n// Get object\n// API reference: https://docs.aws.amazon.com/AmazonS3/latest/API/API_GetObject.html\nfunc (o *ObjectNode) getObjectHandler(w http.ResponseWriter, r *http.Request) {\n\tvar (\n\t\terr       error\n\t\terrorCode *ErrorCode\n\t)\n\tvar startGet = time.Now()\n\tdefer func() {\n\t\to.errorResponse(w, r, err, errorCode)\n\t}()\n\n\tvar param = ParseRequestParam(r)\n\tif param.Bucket() == \"\" {\n\t\terrorCode = InvalidBucketName\n\t\treturn\n\t}\n\tif param.Object() == \"\" {\n\t\terrorCode = InvalidKey\n\t\treturn\n\t}\n\tvar vol *Volume\n\tif vol, err = o.getVol(param.Bucket()); err != nil {\n\t\tlog.LogErrorf(\"getObjectHandler: load volume fail: requestID(%v) volume(%v) path(%v) err(%v)\",\n\t\t\tGetRequestID(r), param.Bucket(), param.Object(), err)\n\t\treturn\n\t}\n\n\t// QPS and Concurrency Limit\n\trateLimit := o.AcquireRateLimiter()\n\tif err = rateLimit.AcquireLimitResource(vol.owner, param.apiName); err != nil {\n\t\treturn\n\t}\n\tdefer rateLimit.ReleaseLimitResource(vol.owner, param.apiName)\n\n\t// parse http range option\n\tvar (\n\t\trevRange    bool\n\t\tisRangeRead bool\n\t\trangeLower  uint64\n\t\trangeUpper  uint64\n\t\tpartSize    uint64\n\t\tpartCount   uint64\n\t)\n\trangeOpt := strings.TrimSpace(r.Header.Get(Range))\n\tif len(rangeOpt) > 0 {\n\t\tif !rangeRegexp.MatchString(rangeOpt) {\n\t\t\tlog.LogErrorf(\"getObjectHandler: invalid range header: requestID(%v) volume(%v) path(%v) rangeOpt(%v)\",\n\t\t\t\tGetRequestID(r), param.Bucket(), param.Object(), rangeOpt)\n\t\t\terrorCode = InvalidRange\n\t\t\treturn\n\t\t}\n\t\thyphenIndex := strings.Index(rangeOpt, \"-\")\n\t\tif hyphenIndex < 0 {\n\t\t\tlog.LogErrorf(\"getObjectHandler: invalid range header: requestID(%v) volume(%v) path(%v) rangeOpt(%v)\",\n\t\t\t\tGetRequestID(r), param.Bucket(), param.Object(), rangeOpt)\n\t\t\terrorCode = InvalidRange\n\t\t\treturn\n\t\t}\n\t\tlowerPart := rangeOpt[len(\"bytes=\"):hyphenIndex]\n\t\tupperPart := \"\"\n\t\tif hyphenIndex+1 < len(rangeOpt) {\n\t\t\t// bytes=-5\n\t\t\tif hyphenIndex == len(\"bytes=\") { // suffix range opt\n\t\t\t\trevRange = true\n\t\t\t\trangeUpper = 1<<64 - 1\n\t\t\t\tlowerPart = rangeOpt[hyphenIndex+1:]\n\t\t\t} else { // bytes=1-10\n\t\t\t\tupperPart = rangeOpt[hyphenIndex+1:]\n\t\t\t}\n\t\t} else if hyphenIndex+1 == len(rangeOpt) { // bytes=1-\n\t\t\trangeUpper = 1<<64 - 1\n\t\t}\n\t\tif len(lowerPart) > 0 {\n\t\t\tif rangeLower, err = strconv.ParseUint(lowerPart, 10, 64); err != nil {\n\t\t\t\tlog.LogErrorf(\"getObjectHandler: parse range lower fail: requestID(%v) volume(%v) path(%v) rangeOpt(%v) err(%v)\",\n\t\t\t\t\tGetRequestID(r), param.Bucket(), param.Object(), rangeOpt, err)\n\t\t\t\terrorCode = InvalidRange\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\t\tif len(upperPart) > 0 {\n\t\t\tif rangeUpper, err = strconv.ParseUint(upperPart, 10, 64); err != nil {\n\t\t\t\tlog.LogErrorf(\"getObjectHandler: parse range upper fail: requestID(%v) volume(%v) path(%v) rangeOpt(%v) err(%v)\",\n\t\t\t\t\tGetRequestID(r), param.Bucket(), param.Object(), rangeOpt, err)\n\t\t\t\terrorCode = InvalidRange\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\t\tif rangeUpper < rangeLower {\n\t\t\t// upper enabled and lower than lower side\n\t\t\tlog.LogErrorf(\"getObjectHandler: invalid range header: requestID(%v) volume(%v) path(%v) rangeOpt(%v)\",\n\t\t\t\tGetRequestID(r), param.Bucket(), param.Object(), rangeOpt)\n\t\t\terrorCode = InvalidRange\n\t\t\treturn\n\t\t}\n\t\tisRangeRead = true\n\t\tlog.LogDebugf(\"getObjectHandler: parse range header: requestID(%v) volume(%v) path(%v) rangeOpt(%v) lower(%v) upper(%v)\",\n\t\t\tGetRequestID(r), param.Bucket(), param.Object(), rangeOpt, rangeLower, rangeUpper)\n\t}\n\n\tresponseCacheControl := r.URL.Query().Get(ParamResponseCacheControl)\n\tif len(responseCacheControl) > 0 && !ValidateCacheControl(responseCacheControl) {\n\t\terrorCode = InvalidCacheArgument\n\t\treturn\n\t}\n\tresponseExpires := r.URL.Query().Get(ParamResponseExpires)\n\tif len(responseExpires) > 0 && !ValidateCacheExpires(responseExpires) {\n\t\terrorCode = InvalidCacheArgument\n\t\treturn\n\t}\n\tresponseContentType := r.URL.Query().Get(ParamResponseContentType)\n\tresponseContentDisposition := r.URL.Query().Get(ParamResponseContentDisposition)\n\n\t// get object meta\n\tvar fileInfo *FSFileInfo\n\tvar xattr *proto.XAttrInfo\n\tvar start = time.Now()\n\tfileInfo, xattr, err = vol.ObjectMeta(param.Object())\n\tlog.LogDebugf(\"getObjectHandler: get object meta cost: %v\", time.Since(start))\n\tif err != nil {\n\t\tlog.LogErrorf(\"getObjectHandler: get file meta fail: requestId(%v) volume(%v) path(%v) err(%v)\",\n\t\t\tGetRequestID(r), vol.Name(), param.Object(), err)\n\t\tif err == syscall.ENOENT {\n\t\t\terrorCode = NoSuchKey\n\t\t}\n\t\treturn\n\t}\n\n\t// header condition check\n\terrorCode = CheckConditionInHeader(r, fileInfo)\n\tif errorCode != nil {\n\t\treturn\n\t}\n\n\t// validate and fix range\n\tif isRangeRead && rangeUpper > uint64(fileInfo.Size)-1 {\n\t\trangeUpper = uint64(fileInfo.Size) - 1\n\t\tif revRange && rangeLower > 0 {\n\t\t\trangeLower = rangeUpper + 1 - rangeLower\n\t\t}\n\t}\n\n\t// compute content length\n\tvar contentLength = uint64(fileInfo.Size)\n\tif isRangeRead {\n\t\tcontentLength = rangeUpper - rangeLower + 1\n\t}\n\n\t// get object tagging size\n\tossTaggingData := xattr.Get(XAttrKeyOSSTagging)\n\toutput, _ := ParseTagging(string(ossTaggingData))\n\tif output != nil && len(output.TagSet) > 0 {\n\t\tw.Header().Set(XAmzTaggingCount, strconv.Itoa(len(output.TagSet)))\n\t}\n\n\t// set response header for GetObject\n\tw.Header().Set(AcceptRanges, ValueAcceptRanges)\n\tw.Header().Set(LastModified, formatTimeRFC1123(fileInfo.ModifyTime))\n\tif len(responseContentType) > 0 {\n\t\tw.Header().Set(ContentType, responseContentType)\n\t} else if len(fileInfo.MIMEType) > 0 {\n\t\tw.Header().Set(ContentType, fileInfo.MIMEType)\n\t} else {\n\t\tw.Header().Set(ContentType, ValueContentTypeStream)\n\t}\n\tif len(responseContentDisposition) > 0 {\n\t\tw.Header().Set(ContentDisposition, responseContentDisposition)\n\t} else if len(fileInfo.Disposition) > 0 {\n\t\tw.Header().Set(ContentDisposition, fileInfo.Disposition)\n\t}\n\tif len(responseCacheControl) > 0 {\n\t\tw.Header().Set(CacheControl, responseCacheControl)\n\t} else if len(fileInfo.CacheControl) > 0 {\n\t\tw.Header().Set(CacheControl, fileInfo.CacheControl)\n\t}\n\tif len(responseExpires) > 0 {\n\t\tw.Header().Set(Expires, responseExpires)\n\t} else if len(fileInfo.Expires) > 0 {\n\t\tw.Header().Set(Expires, fileInfo.Expires)\n\t}\n\tif len(fileInfo.RetainUntilDate) > 0 {\n\t\tw.Header().Set(XAmzObjectLockMode, ComplianceMode)\n\t\tw.Header().Set(XAmzObjectLockRetainUntilDate, fileInfo.RetainUntilDate)\n\t}\n\n\t// check request is whether contain param : partNumber\n\tpartNumber := r.URL.Query().Get(ParamPartNumber)\n\tif len(partNumber) > 0 && fileInfo.Size >= MinParallelDownloadFileSize {\n\t\tpartNumberInt, err := strconv.ParseUint(partNumber, 10, 64)\n\t\tif err != nil {\n\t\t\tlog.LogErrorf(\"getObjectHandler: parse partNumber(%v) fail: requestID(%v) volume(%v) path(%v) err(%v)\",\n\t\t\t\tpartNumber, GetRequestID(r), param.Bucket(), param.Object(), err)\n\t\t\terrorCode = InvalidArgument\n\t\t\treturn\n\t\t}\n\t\tpartSize, partCount, rangeLower, rangeUpper = parsePartInfo(partNumberInt, uint64(fileInfo.Size))\n\t\tlog.LogDebugf(\"getObjectHandler: partNumber(%v) fileSize(%v) parsed: partSize(%d) partCount(%d) rangeLower(%d) rangeUpper(%d)\",\n\t\t\tpartNumberInt, fileInfo.Size, partSize, partCount, rangeLower, rangeUpper)\n\t\tif partNumberInt > partCount {\n\t\t\tlog.LogErrorf(\"getObjectHandler: partNumber(%d) > partCount(%d): requestID(%v) volume(%v) path(%v)\",\n\t\t\t\tpartNumberInt, partCount, GetRequestID(r), param.Bucket(), param.Object())\n\t\t\terrorCode = NoSuchKey\n\t\t\treturn\n\t\t}\n\t\t// Header : Accept-Range, Content-Length, Content-Range, ETag, x-amz-mp-parts-count\n\t\tw.Header().Set(ContentLength, strconv.Itoa(int(partSize)))\n\t\tw.Header().Set(ContentRange, fmt.Sprintf(\"bytes %d-%d/%d\", rangeLower, rangeUpper, fileInfo.Size))\n\t\tw.Header().Set(XAmzMpPartsCount, strconv.Itoa(int(partCount)))\n\t\tif len(fileInfo.ETag) > 0 && !strings.Contains(fileInfo.ETag, \"-\") {\n\t\t\tw.Header()[ETag] = []string{fmt.Sprintf(\"%s-%d\", fileInfo.ETag, partCount)}\n\t\t}\n\t} else {\n\t\tw.Header().Set(ContentLength, strconv.FormatUint(contentLength, 10))\n\t\tif len(fileInfo.ETag) > 0 {\n\t\t\tw.Header()[ETag] = []string{wrapUnescapedQuot(fileInfo.ETag)}\n\t\t}\n\t\tif isRangeRead {\n\t\t\tw.Header().Set(ContentRange, fmt.Sprintf(\"bytes %d-%d/%d\", rangeLower, rangeUpper, fileInfo.Size))\n\t\t}\n\t}\n\n\t// User-defined metadata\n\tfor name, value := range fileInfo.Metadata {\n\t\tw.Header().Set(XAmzMetaPrefix+name, value)\n\t}\n\n\tif fileInfo.Mode.IsDir() {\n\t\treturn\n\t}\n\n\t// get object content\n\tvar offset = rangeLower\n\tsize, err := safeConvertInt64ToUint64(fileInfo.Size)\n\tfileSize := size\n\tif err != nil {\n\t\treturn\n\t}\n\tif isRangeRead || len(partNumber) > 0 {\n\t\tsize = rangeUpper - rangeLower + 1\n\t\tw.WriteHeader(http.StatusPartialContent)\n\t}\n\n\t// Flow Control\n\tvar writer io.Writer\n\tif size > DefaultFlowLimitSize {\n\t\twriter = rateLimit.GetResponseWriter(vol.owner, param.apiName, w)\n\t} else {\n\t\twriter = w\n\t}\n\terr = vol.readFile(fileInfo.Inode, fileSize, param.Object(), writer, offset, size)\n\tif err != nil {\n\t\tlog.LogErrorf(\"getObjectHandler: read file fail: requestID(%v) volume(%v) path(%v) offset(%v) size(%v) err(%v)\",\n\t\t\tGetRequestID(r), param.Bucket(), param.Object(), offset, size, err)\n\t\tif err == syscall.ENOENT {\n\t\t\terrorCode = NoSuchKey\n\t\t}\n\t\treturn\n\t}\n\tlog.LogDebugf(\"getObjectHandler: read file success: requestID(%v) volume(%v) path(%v) offset(%v) size(%v) cost(%v)\",\n\t\tGetRequestID(r), param.Bucket(), param.Object(), offset, size, time.Since(startGet))\n\n\treturn\n}\n\nfunc CheckConditionInHeader(r *http.Request, fileInfo *FSFileInfo) *ErrorCode {\n\t// parse request header\n\tmatch := r.Header.Get(IfMatch)\n\tnoneMatch := r.Header.Get(IfNoneMatch)\n\tmodified := r.Header.Get(IfModifiedSince)\n\tunmodified := r.Header.Get(IfUnmodifiedSince)\n\t// Checking precondition: If-Match\n\t// Reference: https://docs.aws.amazon.com/AmazonS3/latest/API/API_GetObject.html#API_GetObject_RequestSyntax\n\tif match != \"\" {\n\t\tif matchEag := strings.Trim(match, \"\\\"\"); matchEag != fileInfo.ETag {\n\t\t\tlog.LogDebugf(\"getObjectHandler: object eTag(%s) not match If-Match header value(%s), requestId(%v)\",\n\t\t\t\tfileInfo.ETag, matchEag, GetRequestID(r))\n\t\t\treturn PreconditionFailed\n\n\t\t}\n\t}\n\t// Checking precondition: If-Modified-Since\n\t// Reference: https://docs.aws.amazon.com/AmazonS3/latest/API/API_GetObject.html#API_GetObject_RequestSyntax\n\tif modified != \"\" {\n\t\tfileModTime := fileInfo.ModifyTime\n\t\tmodifiedTime, err := parseTimeRFC1123(modified)\n\t\tif err != nil {\n\t\t\tlog.LogErrorf(\"getObjectHandler: parse RFC1123 time fail: requestID(%v) err(%v)\", GetRequestID(r), err)\n\t\t\treturn InvalidArgument\n\t\t}\n\t\tif !fileModTime.After(modifiedTime) {\n\t\t\tlog.LogInfof(\"getObjectHandler: file modified time not after than specified time: requestID(%v)\", GetRequestID(r))\n\t\t\treturn NotModified\n\t\t}\n\t}\n\t// Checking precondition: If-None-Match\n\t// Reference: https://docs.aws.amazon.com/AmazonS3/latest/API/API_GetObject.html#API_GetObject_RequestSyntax\n\tif noneMatch != \"\" {\n\t\tif noneMatchEtag := strings.Trim(noneMatch, \"\\\"\"); noneMatchEtag == fileInfo.ETag {\n\t\t\tlog.LogErrorf(\"getObjectHandler: object eTag(%s) match If-None-Match header value(%s), requestId(%v)\",\n\t\t\t\tfileInfo.ETag, noneMatchEtag, GetRequestID(r))\n\t\t\treturn NotModified\n\t\t}\n\t}\n\t// Checking precondition: If-Unmodified-Since\n\t// Reference: https://docs.aws.amazon.com/AmazonS3/latest/API/API_GetObject.html#API_GetObject_RequestSyntax\n\tif unmodified != \"\" && match == \"\" {\n\t\tfileModTime := fileInfo.ModifyTime\n\t\tmodifiedTime, err := parseTimeRFC1123(unmodified)\n\t\tif err != nil {\n\t\t\tlog.LogErrorf(\"getObjectHandler: parse RFC1123 time fail: requestID(%v) err(%v)\", GetRequestID(r), err)\n\t\t\treturn InvalidArgument\n\t\t}\n\t\tif fileModTime.After(modifiedTime) {\n\t\t\tlog.LogInfof(\"getObjectHandler: file modified time after than specified time: requestID(%v)\", GetRequestID(r))\n\t\t\treturn PreconditionFailed\n\t\t}\n\t}\n\treturn nil\n}\n\n// Head object\n// API reference: https://docs.aws.amazon.com/AmazonS3/latest/API/API_HeadObject.html\nfunc (o *ObjectNode) headObjectHandler(w http.ResponseWriter, r *http.Request) {\n\tvar (\n\t\terr       error\n\t\terrorCode *ErrorCode\n\t)\n\tdefer func() {\n\t\to.errorResponse(w, r, err, errorCode)\n\t}()\n\n\t// check args\n\tvar param = ParseRequestParam(r)\n\tif param.Bucket() == \"\" {\n\t\terrorCode = InvalidBucketName\n\t\treturn\n\t}\n\tif param.Object() == \"\" {\n\t\terrorCode = InvalidKey\n\t\treturn\n\t}\n\n\tvar vol *Volume\n\tif vol, err = o.getVol(param.Bucket()); err != nil {\n\t\tlog.LogErrorf(\"headObjectHandler: load volume fail: requestID(%v) err(%v)\",\n\t\t\tGetRequestID(r), err)\n\t\treturn\n\t}\n\n\t// QPS and Concurrency Limit\n\trateLimit := o.AcquireRateLimiter()\n\tif err = rateLimit.AcquireLimitResource(vol.owner, param.apiName); err != nil {\n\t\treturn\n\t}\n\tdefer rateLimit.ReleaseLimitResource(vol.owner, param.apiName)\n\n\t// get object meta\n\tvar fileInfo *FSFileInfo\n\tfileInfo, _, err = vol.ObjectMeta(param.Object())\n\tif err != nil {\n\t\tlog.LogErrorf(\"headObjectHandler: get file meta fail: requestId(%v) volume(%v) path(%v) err(%v)\",\n\t\t\tGetRequestID(r), vol.Name(), param.Object(), err)\n\t\tif err == syscall.ENOENT {\n\t\t\terrorCode = NoSuchKey\n\t\t}\n\t\treturn\n\t}\n\n\t// parse request header\n\tmatch := r.Header.Get(IfMatch)\n\tnoneMatch := r.Header.Get(IfNoneMatch)\n\tmodified := r.Header.Get(IfModifiedSince)\n\tunmodified := r.Header.Get(IfUnmodifiedSince)\n\n\t// Checking precondition: If-Match\n\t// Reference: https://docs.aws.amazon.com/AmazonS3/latest/API/API_HeadObject.html#API_HeadObject_RequestSyntax\n\tif match != \"\" {\n\t\tif matchEag := strings.Trim(match, \"\\\"\"); matchEag != fileInfo.ETag {\n\t\t\tlog.LogDebugf(\"headObjectHandler: object eTag(%s) not match If-Match header value(%s), requestId(%v)\",\n\t\t\t\tfileInfo.ETag, matchEag, GetRequestID(r))\n\t\t\terrorCode = PreconditionFailed\n\t\t\treturn\n\t\t}\n\t}\n\t// Checking precondition: If-Modified-Since\n\t// Reference: https://docs.aws.amazon.com/AmazonS3/latest/API/API_HeadObject.html#API_HeadObject_RequestSyntax\n\tif modified != \"\" {\n\t\tfileModTime := fileInfo.ModifyTime\n\t\tmodifiedTime, err := parseTimeRFC1123(modified)\n\t\tif err != nil {\n\t\t\tlog.LogDebugf(\"headObjectHandler: parse RFC1123 time fail: requestID(%v) err(%v)\", GetRequestID(r), err)\n\t\t\terrorCode = InvalidArgument\n\t\t\treturn\n\t\t}\n\t\tif !fileModTime.After(modifiedTime) {\n\t\t\tlog.LogDebugf(\"headObjectHandler: file modified time not after than specified time: requestID(%v)\", GetRequestID(r))\n\t\t\terrorCode = NotModified\n\t\t\treturn\n\t\t}\n\t}\n\t// Checking precondition: If-None-Match\n\t// Reference: https://docs.aws.amazon.com/AmazonS3/latest/API/API_HeadObject.html#API_HeadObject_RequestSyntax\n\tif noneMatch != \"\" {\n\t\tif noneMatchEtag := strings.Trim(noneMatch, \"\\\"\"); noneMatchEtag == fileInfo.ETag {\n\t\t\tlog.LogDebugf(\"headObjectHandler: object eTag(%s) match If-None-Match header value(%s), requestId(%v)\",\n\t\t\t\tfileInfo.ETag, noneMatchEtag, GetRequestID(r))\n\t\t\terrorCode = NotModified\n\t\t\treturn\n\t\t}\n\t}\n\t// Checking precondition: If-Unmodified-Since\n\t// Reference: https://docs.aws.amazon.com/AmazonS3/latest/API/API_HeadObject.html#API_HeadObject_RequestSyntax\n\tif unmodified != \"\" && match == \"\" {\n\t\tfileModTime := fileInfo.ModifyTime\n\t\tmodifiedTime, err := parseTimeRFC1123(unmodified)\n\t\tif err != nil {\n\t\t\tlog.LogDebugf(\"headObjectHandler: parse RFC1123 time fail: requestID(%v) err(%v)\", GetRequestID(r), err)\n\t\t\terrorCode = InvalidArgument\n\t\t\treturn\n\t\t}\n\t\tif fileModTime.After(modifiedTime) {\n\t\t\tlog.LogDebugf(\"headObjectHandler: file modified time after than specified time: requestID(%v)\", GetRequestID(r))\n\t\t\terrorCode = PreconditionFailed\n\t\t\treturn\n\t\t}\n\t}\n\n\t// set response header\n\tw.Header().Set(AcceptRanges, ValueAcceptRanges)\n\tw.Header().Set(LastModified, formatTimeRFC1123(fileInfo.ModifyTime))\n\tw.Header().Set(ContentMD5, EmptyContentMD5String)\n\tif len(fileInfo.MIMEType) > 0 {\n\t\tw.Header().Set(ContentType, fileInfo.MIMEType)\n\t} else {\n\t\tw.Header().Set(ContentType, ValueContentTypeStream)\n\t}\n\tif len(fileInfo.Disposition) > 0 {\n\t\tw.Header().Set(ContentDisposition, fileInfo.Disposition)\n\t}\n\tif len(fileInfo.CacheControl) > 0 {\n\t\tw.Header().Set(CacheControl, fileInfo.CacheControl)\n\t}\n\tif len(fileInfo.Expires) > 0 {\n\t\tw.Header().Set(Expires, fileInfo.Expires)\n\t}\n\tif len(fileInfo.RetainUntilDate) > 0 {\n\t\tw.Header().Set(XAmzObjectLockMode, ComplianceMode)\n\t\tw.Header().Set(XAmzObjectLockRetainUntilDate, fileInfo.RetainUntilDate)\n\t}\n\n\t// check request is whether contain param : partNumber\n\tpartNumber := r.URL.Query().Get(ParamPartNumber)\n\tif len(partNumber) > 0 && fileInfo.Size >= MinParallelDownloadFileSize {\n\t\tpartNumberInt, err := strconv.ParseUint(partNumber, 10, 64)\n\t\tif err != nil {\n\t\t\tlog.LogErrorf(\"headObjectHandler: parse param partNumber(%s) fail: requestID(%v) err(%v)\", partNumber, GetRequestID(r), err)\n\t\t\terrorCode = InvalidArgument\n\t\t\treturn\n\t\t}\n\t\tpartSize, partCount, rangeLower, rangeUpper := parsePartInfo(partNumberInt, uint64(fileInfo.Size))\n\t\tlog.LogDebugf(\"headObjectHandler: parsed partSize(%d), partCount(%d), rangeLower(%d), rangeUpper(%d)\", partSize, partCount, rangeLower, rangeUpper)\n\t\tif partNumberInt > partCount {\n\t\t\tlog.LogErrorf(\"headObjectHandler: param partNumber(%d) is more then partCount(%d): requestID(%v)\", partNumberInt, partCount, GetRequestID(r))\n\t\t\terrorCode = NoSuchKey\n\t\t\treturn\n\t\t}\n\t\tw.Header().Set(ContentLength, strconv.Itoa(int(partSize)))\n\t\tw.Header().Set(ContentRange, fmt.Sprintf(\"bytes %d-%d/%d\", rangeLower, rangeUpper, fileInfo.Size))\n\t\tw.Header().Set(XAmzMpPartsCount, strconv.Itoa(int(partCount)))\n\t\tif len(fileInfo.ETag) > 0 && !strings.Contains(fileInfo.ETag, \"-\") {\n\t\t\tw.Header()[ETag] = []string{fmt.Sprintf(\"%s-%d\", fileInfo.ETag, partCount)}\n\t\t}\n\t} else {\n\t\tw.Header().Set(ContentLength, strconv.Itoa(int(fileInfo.Size)))\n\t\tif len(fileInfo.ETag) > 0 {\n\t\t\tw.Header()[ETag] = []string{wrapUnescapedQuot(fileInfo.ETag)}\n\t\t}\n\t}\n\n\t// User-defined metadata\n\tfor name, value := range fileInfo.Metadata {\n\t\tw.Header().Set(XAmzMetaPrefix+name, value)\n\t}\n\n\treturn\n}\n\n// Delete objects (multiple objects)\n// API reference: https://docs.aws.amazon.com/AmazonS3/latest/API/API_DeleteObjects.html\nfunc (o *ObjectNode) deleteObjectsHandler(w http.ResponseWriter, r *http.Request) {\n\tvar (\n\t\terr       error\n\t\terrorCode *ErrorCode\n\t)\n\tdefer func() {\n\t\to.errorResponse(w, r, err, errorCode)\n\t}()\n\n\tvar param = ParseRequestParam(r)\n\tif param.Bucket() == \"\" {\n\t\terrorCode = InvalidBucketName\n\t\treturn\n\t}\n\n\tvar vol *Volume\n\tif vol, err = o.getVol(param.Bucket()); err != nil {\n\t\tlog.LogErrorf(\"deleteObjectsHandler: load volume fail: requestID(%v) volume(%v) err(%v)\",\n\t\t\tGetRequestID(r), param.Bucket(), err)\n\t\treturn\n\t}\n\n\trequestMD5 := r.Header.Get(ContentMD5)\n\tif requestMD5 == \"\" {\n\t\terrorCode = MissingContentMD5\n\t\treturn\n\t}\n\n\t_, errorCode = VerifyContentLength(r, BodyLimit)\n\tif errorCode != nil {\n\t\treturn\n\t}\n\tbytes, err := ioutil.ReadAll(r.Body)\n\tif err != nil {\n\t\tlog.LogErrorf(\"deleteObjectsHandler: read request body fail: requestID(%v) volume(%v) err(%v)\",\n\t\t\tGetRequestID(r), param.Bucket(), err)\n\t\terrorCode = UnexpectedContent\n\t\treturn\n\t}\n\tif requestMD5 != GetMD5(bytes) {\n\t\terrorCode = BadDigest\n\t\treturn\n\t}\n\n\tdeleteReq := DeleteRequest{}\n\terr = UnmarshalXMLEntity(bytes, &deleteReq)\n\tif err != nil {\n\t\tlog.LogErrorf(\"deleteObjectsHandler: unmarshal xml fail: requestID(%v) volume(%v) request(%v) err(%v)\",\n\t\t\tGetRequestID(r), param.Bucket(), string(bytes), err)\n\t\terrorCode = MalformedXML\n\t\treturn\n\t}\n\tif len(deleteReq.Objects) > 1000 {\n\t\terrorCode = EntityTooLarge\n\t\treturn\n\t}\n\n\t// Sort the key values in reverse order.\n\t// The purpose of this is to delete the child leaf first and then the parent node.\n\t// Source:\n\t//  0. backup/\n\t//  1. backup/20200101.bak\n\t//  2. backup/20200102.bak\n\t// Result:\n\t//  0. backup/20200102.bak\n\t//  1. backup/20200101.bak\n\t//  2. backup/\n\tsort.SliceStable(deleteReq.Objects, func(i, j int) bool {\n\t\treturn deleteReq.Objects[i].Key > deleteReq.Objects[j].Key\n\t})\n\n\tvol, acl, policy, err := o.loadBucketMeta(param.Bucket())\n\tif err != nil {\n\t\tlog.LogErrorf(\"deleteObjectsHandler: load bucket metadata fail: requestID(%v) volume(%v) err(%v)\",\n\t\t\tGetRequestID(r), param.Bucket(), err)\n\t\treturn\n\t}\n\n\tuserInfo, err := o.getUserInfoByAccessKeyV2(param.AccessKey())\n\tif err != nil {\n\t\tlog.LogErrorf(\"deleteObjectsHandler: get userinfo fail: requestID(%v) volume(%v) accessKey(%v) err(%v)\",\n\t\t\tGetRequestID(r), param.Bucket(), param.AccessKey(), err)\n\t\treturn\n\t}\n\n\tallowByAcl := false\n\tif acl == nil && userInfo.UserID == vol.owner {\n\t\tallowByAcl = true\n\t}\n\tif acl != nil && acl.IsAllowed(userInfo.UserID, param.Action()) {\n\t\tallowByAcl = true\n\t}\n\n\tdeletedObjects := make([]Deleted, 0, len(deleteReq.Objects))\n\tdeletedErrors := make([]Error, 0)\n\tobjectKeys := make([]string, 0, len(deleteReq.Objects))\n\tfor _, object := range deleteReq.Objects {\n\t\tresult := POLICY_UNKNOW\n\t\tif policy != nil && !policy.IsEmpty() {\n\t\t\tlog.LogDebugf(\"deleteObjectsHandler: policy check: requestID(%v) volume(%v) path(%v) policy(%v)\",\n\t\t\t\tGetRequestID(r), param.Bucket(), object.Key, policy)\n\t\t\tconditionCheck := map[string]string{\n\t\t\t\tSOURCEIP: param.sourceIP,\n\t\t\t\tREFERER:  param.r.Referer(),\n\t\t\t\tKEYNAME:  object.Key,\n\t\t\t\tHOST:     param.r.Host,\n\t\t\t}\n\t\t\tresult = policy.IsAllowed(param, userInfo.UserID, vol.owner, conditionCheck)\n\t\t}\n\t\tif result == POLICY_DENY || (result == POLICY_UNKNOW && !allowByAcl) {\n\t\t\tdeletedErrors = append(deletedErrors, Error{\n\t\t\t\tKey:     object.Key,\n\t\t\t\tCode:    \"AccessDenied\",\n\t\t\t\tMessage: \"Not Allowed By Policy\",\n\t\t\t})\n\t\t\tcontinue\n\t\t}\n\t\tobjectKeys = append(objectKeys, object.Key)\n\t\tlog.LogWarnf(\"deleteObjectsHandler: delete path: requestID(%v) remote(%v) volume(%v) path(%v)\",\n\t\t\tGetRequestID(r), getRequestIP(r), vol.Name(), object.Key)\n\t\t// QPS and Concurrency Limit\n\t\trateLimit := o.AcquireRateLimiter()\n\t\tif err = rateLimit.AcquireLimitResource(vol.owner, DELETE_OBJECT); err != nil {\n\t\t\treturn\n\t\t}\n\t\tif err1 := vol.DeletePath(object.Key); err1 != nil {\n\t\t\tlog.LogErrorf(\"deleteObjectsHandler: delete object failed: requestID(%v) volume(%v) path(%v) err(%v)\",\n\t\t\t\tGetRequestID(r), vol.Name(), object.Key, err1)\n\t\t\tif !strings.Contains(err1.Error(), AccessDenied.ErrorMessage) {\n\t\t\t\tdeletedErrors = append(deletedErrors, Error{Key: object.Key, Code: \"InternalError\", Message: err1.Error()})\n\t\t\t} else {\n\t\t\t\tdeletedErrors = append(deletedErrors, Error{Key: object.Key, Code: \"AccessDenied\", Message: err1.Error()})\n\t\t\t}\n\t\t} else {\n\t\t\tlog.LogDebugf(\"deleteObjectsHandler: delete object success: requestID(%v) volume(%v) path(%v)\",\n\t\t\t\tGetRequestID(r), vol.Name(), object.Key)\n\t\t\tdeletedObjects = append(deletedObjects, Deleted{Key: object.Key})\n\t\t}\n\t\trateLimit.ReleaseLimitResource(vol.owner, param.apiName)\n\t}\n\n\tdeleteResult := DeleteResult{\n\t\tDeleted: deletedObjects,\n\t\tError:   deletedErrors,\n\t}\n\tresponse, err1 := MarshalXMLEntity(deleteResult)\n\tif err1 != nil {\n\t\tlog.LogErrorf(\"deleteObjectsHandler: xml marshal fail: requestID(%v) volume(%v) result(%+v) err(%v)\",\n\t\t\tGetRequestID(r), param.Bucket(), deleteResult, err1)\n\t}\n\n\twriteSuccessResponseXML(w, response)\n\treturn\n}\n\nfunc extractSrcBucketKey(r *http.Request) (srcBucketId, srcKey, versionId string, err error) {\n\tcopySource := r.Header.Get(XAmzCopySource)\n\tcopySource, err = url.QueryUnescape(copySource)\n\tif err != nil {\n\t\treturn \"\", \"\", \"\", InvalidArgument\n\t}\n\t// path could be /bucket/key or bucket/key\n\tcopySource = strings.TrimPrefix(copySource, \"/\")\n\telements := strings.SplitN(copySource, \"?versionId=\", 2)\n\tif len(elements) == 1 {\n\t\tversionId = \"\"\n\t} else {\n\t\tversionId = elements[1]\n\t}\n\tpath := strings.SplitN(elements[0], \"/\", 2)\n\tif len(path) == 1 {\n\t\treturn \"\", \"\", \"\", InvalidArgument\n\t}\n\tsrcBucketId, srcKey = path[0], path[1]\n\tif srcBucketId == \"\" || srcKey == \"\" {\n\t\treturn \"\", \"\", \"\", InvalidArgument\n\t}\n\treturn\n}\n\n// Copy object\n// API reference: https://docs.aws.amazon.com/AmazonS3/latest/API/API_CopyObject.html .\nfunc (o *ObjectNode) copyObjectHandler(w http.ResponseWriter, r *http.Request) {\n\tvar err error\n\tvar errorCode *ErrorCode\n\tdefer func() {\n\t\to.errorResponse(w, r, err, errorCode)\n\t}()\n\n\tvar param = ParseRequestParam(r)\n\tif param.Bucket() == \"\" {\n\t\terrorCode = InvalidBucketName\n\t\treturn\n\t}\n\tif param.Object() == \"\" {\n\t\terrorCode = InvalidKey\n\t\treturn\n\t}\n\tif len(param.Object()) > MaxKeyLength {\n\t\terrorCode = KeyTooLong\n\t\treturn\n\t}\n\tvar vol *Volume\n\tif vol, err = o.getVol(param.Bucket()); err != nil {\n\t\tlog.LogErrorf(\"copyObjectHandler: load volume fail: requestID(%v) volume(%v) err(%v)\",\n\t\t\tGetRequestID(r), param.Bucket(), err)\n\t\treturn\n\t}\n\n\t// QPS and Concurrency Limit\n\trateLimit := o.AcquireRateLimiter()\n\tif err = rateLimit.AcquireLimitResource(vol.owner, param.apiName); err != nil {\n\t\treturn\n\t}\n\tdefer rateLimit.ReleaseLimitResource(vol.owner, param.apiName)\n\n\t// client can reset these system metadata: Content-Type, Content-Disposition\n\tcontentType := r.Header.Get(ContentType)\n\tcontentDisposition := r.Header.Get(ContentDisposition)\n\tcacheControl := r.Header.Get(CacheControl)\n\tif len(cacheControl) > 0 && !ValidateCacheControl(cacheControl) {\n\t\terrorCode = InvalidCacheArgument\n\t\treturn\n\t}\n\texpires := r.Header.Get(Expires)\n\tif len(expires) > 0 && !ValidateCacheExpires(expires) {\n\t\terrorCode = InvalidCacheArgument\n\t\treturn\n\t}\n\n\t// metadata directive, direct object node use source file metadata or recreate metadata for target file\n\tmetadataDirective := r.Header.Get(XAmzMetadataDirective)\n\t// metadata directive default value is COPY\n\tif len(metadataDirective) == 0 {\n\t\tmetadataDirective = MetadataDirectiveCopy\n\t}\n\tif metadataDirective != MetadataDirectiveCopy && metadataDirective != MetadataDirectiveReplace {\n\t\tlog.LogErrorf(\"copyObjectHandler: x-amz-metadata-directive invalid: requestID(%v) volume(%v) x-amz-metadata-directive(%v) err(%v)\",\n\t\t\tGetRequestID(r), param.Bucket(), metadataDirective, err)\n\t\terrorCode = InvalidArgument\n\t\treturn\n\t}\n\t// parse x-amz-copy-source header\n\tsourceBucket, sourceObject, _, err := extractSrcBucketKey(r)\n\tif err != nil {\n\t\tlog.LogErrorf(\"copyObjectHandler: copySource(%v) argument invalid: requestID(%v) volume(%v) err(%v)\",\n\t\t\tr.Header.Get(XAmzCopySource), GetRequestID(r), param.Bucket(), err)\n\t\treturn\n\t}\n\n\t// check ACL\n\tuserInfo, err := o.getUserInfoByAccessKeyV2(param.AccessKey())\n\tif err != nil {\n\t\tlog.LogErrorf(\"copyObjectHandler: get user info fail: requestID(%v) volume(%v) accessKey(%v) err(%v)\",\n\t\t\tGetRequestID(r), param.Bucket(), param.AccessKey(), err)\n\t\treturn\n\t}\n\tacl, err := ParseACL(r, userInfo.UserID, false, vol.GetOwner() != userInfo.UserID)\n\tif err != nil {\n\t\tlog.LogErrorf(\"copyObjectHandler: parse acl fail: requestID(%v) volume(%v) acl(%+v) err(%v)\",\n\t\t\tGetRequestID(r), param.Bucket(), acl, err)\n\t\treturn\n\t}\n\n\t// get src object meta\n\tvar sourceVol *Volume\n\tif sourceVol, err = o.getVol(sourceBucket); err != nil {\n\t\tlog.LogErrorf(\"copyObjectHandler: load source volume fail: requestID(%v) srcVolume(%v) err(%v)\",\n\t\t\tGetRequestID(r), sourceBucket, err)\n\t\treturn\n\t}\n\tvar fileInfo *FSFileInfo\n\tfileInfo, _, err = sourceVol.ObjectMeta(sourceObject)\n\tif err != nil {\n\t\tlog.LogErrorf(\"copyObjectHandler: get object meta fail: requestID(%v) srcVolume(%v) srcObject(%v) err(%v)\",\n\t\t\tGetRequestID(r), sourceBucket, sourceObject, err)\n\t\tif err == syscall.ENOENT {\n\t\t\terrorCode = NoSuchKey\n\t\t}\n\t\treturn\n\t}\n\tif fileInfo.Size > SinglePutLimit {\n\t\terrorCode = EntityTooLarge\n\t\treturn\n\t}\n\tif fileInfo.Size > SinglePutLimit {\n\t\terrorCode = EntityTooLarge\n\t\treturn\n\t}\n\n\t// get header\n\tcopyMatch := r.Header.Get(XAmzCopySourceIfMatch)\n\tnoneMatch := r.Header.Get(XAmzCopySourceIfNoneMatch)\n\tmodified := r.Header.Get(XAmzCopySourceIfModifiedSince)\n\tunModified := r.Header.Get(XAmzCopySourceIfUnmodifiedSince)\n\n\t// response 412\n\tif modified != \"\" {\n\t\tfileModTime := fileInfo.ModifyTime\n\t\tmodifiedTime, err := parseTimeRFC1123(modified)\n\t\tif err != nil {\n\t\t\tlog.LogErrorf(\"copyObjectHandler: parse RFC1123 time fail: requestID(%v) err(%v)\", GetRequestID(r), err)\n\t\t\terrorCode = InvalidArgument\n\t\t\treturn\n\t\t}\n\t\tif fileModTime.Before(modifiedTime) {\n\t\t\tlog.LogInfof(\"copyObjectHandler: file modified time not after than specified time: requestID(%v)\", GetRequestID(r))\n\t\t\terrorCode = PreconditionFailed\n\t\t\treturn\n\t\t}\n\t}\n\tif unModified != \"\" {\n\t\tfileModTime := fileInfo.ModifyTime\n\t\tunmodifiedTime, err := parseTimeRFC1123(unModified)\n\t\tif err != nil {\n\t\t\tlog.LogErrorf(\"copyObjectHandler: parse RFC1123 time fail: requestID(%v) err(%v)\", GetRequestID(r), err)\n\t\t\terrorCode = InvalidArgument\n\t\t\treturn\n\t\t}\n\t\tif fileModTime.After(unmodifiedTime) {\n\t\t\tlog.LogInfof(\"copyObjectHandler: file modified time not before than specified time: requestID(%v)\", GetRequestID(r))\n\t\t\terrorCode = PreconditionFailed\n\t\t\treturn\n\t\t}\n\t}\n\tif copyMatch != \"\" && fileInfo.ETag != copyMatch {\n\t\tlog.LogInfof(\"copyObjectHandler: eTag mismatched with specified: requestID(%v)\", GetRequestID(r))\n\t\terrorCode = PreconditionFailed\n\t\treturn\n\t}\n\tif noneMatch != \"\" && fileInfo.ETag == noneMatch {\n\t\tlog.LogInfof(\"copyObjectHandler: eTag same with specified: requestID(%v)\", GetRequestID(r))\n\t\terrorCode = PreconditionFailed\n\t\treturn\n\t}\n\n\t// ObjectLock  Config\n\tobjetLock, err := vol.metaLoader.loadObjectLock()\n\tif err != nil {\n\t\tlog.LogErrorf(\"copyObjectHandler: load volume objetLock: requestID(%v)  volume(%v) err(%v)\",\n\t\t\tGetRequestID(r), param.Bucket(), err)\n\t\treturn\n\t}\n\n\t// parse user-defined metadata\n\tmetadata := ParseUserDefinedMetadata(r.Header)\n\t// copy file\n\topt := &PutFileOption{\n\t\tMIMEType:     contentType,\n\t\tDisposition:  contentDisposition,\n\t\tMetadata:     metadata,\n\t\tCacheControl: cacheControl,\n\t\tExpires:      expires,\n\t\tACL:          acl,\n\t\tObjectLock:   objetLock,\n\t}\n\tfsFileInfo, err := vol.CopyFile(sourceVol, sourceObject, param.Object(), metadataDirective, opt)\n\tif err != nil && err != syscall.EINVAL && err != syscall.EFBIG {\n\t\tlog.LogErrorf(\"copyObjectHandler: Volume copy file fail: requestID(%v) Volume(%v) source(%v) target(%v) err(%v)\",\n\t\t\tGetRequestID(r), param.Bucket(), sourceObject, param.Object(), err)\n\t\treturn\n\t}\n\tif err == syscall.EINVAL {\n\t\tlog.LogErrorf(\"copyObjectHandler: target file existed, and mode conflict: requestID(%v) Volume(%v) source(%v) target(%v) err(%v)\",\n\t\t\tGetRequestID(r), param.Bucket(), sourceObject, param.Object(), err)\n\t\terrorCode = ObjectModeConflict\n\t\treturn\n\t}\n\tif err == syscall.EFBIG {\n\t\tlog.LogErrorf(\"copyObjectHandler: source file size greater than 5GB: requestID(%v) Volume(%v) source(%v) target(%v) err(%v)\",\n\t\t\tGetRequestID(r), param.Bucket(), sourceObject, param.Object(), err)\n\t\terrorCode = CopySourceSizeTooLarge\n\t\treturn\n\t}\n\n\tcopyResult := CopyResult{\n\t\tETag:         \"\\\"\" + fsFileInfo.ETag + \"\\\"\",\n\t\tLastModified: formatTimeISO(fsFileInfo.ModifyTime),\n\t}\n\tresponse, err := MarshalXMLEntity(copyResult)\n\tif err != nil {\n\t\tlog.LogErrorf(\"copyObjectHandler: marshal xml entity fail: requestID(%v) err(%v)\", GetRequestID(r), err)\n\t\treturn\n\t}\n\n\twriteSuccessResponseXML(w, response)\n\treturn\n}\n\n// List objects v1\n// API reference: https://docs.aws.amazon.com/AmazonS3/latest/API/API_ListObjects.html\nfunc (o *ObjectNode) getBucketV1Handler(w http.ResponseWriter, r *http.Request) {\n\tvar err error\n\tvar errorCode *ErrorCode\n\tdefer func() {\n\t\to.errorResponse(w, r, err, errorCode)\n\t}()\n\n\tvar param = ParseRequestParam(r)\n\tif param.Bucket() == \"\" {\n\t\terrorCode = InvalidBucketName\n\t\treturn\n\t}\n\tvar vol *Volume\n\tif vol, err = o.getVol(param.Bucket()); err != nil {\n\t\tlog.LogErrorf(\"getBucketV1Handler: load volume fail: requestID(%v) volume(%v) err(%v)\",\n\t\t\tGetRequestID(r), param.Bucket(), err)\n\t\treturn\n\t}\n\n\t// QPS and Concurrency Limit\n\trateLimit := o.AcquireRateLimiter()\n\tif err = rateLimit.AcquireLimitResource(vol.owner, param.apiName); err != nil {\n\t\treturn\n\t}\n\tdefer rateLimit.ReleaseLimitResource(vol.owner, param.apiName)\n\n\t// get options\n\tmarker := r.URL.Query().Get(ParamMarker)\n\tprefix := r.URL.Query().Get(ParamPrefix)\n\tmaxKeys := r.URL.Query().Get(ParamMaxKeys)\n\tdelimiter := r.URL.Query().Get(ParamPartDelimiter)\n\tencodingType := r.URL.Query().Get(ParamEncodingType)\n\n\tvar maxKeysInt uint64\n\tif maxKeys != \"\" {\n\t\tmaxKeysInt, err = strconv.ParseUint(maxKeys, 10, 16)\n\t\tif err != nil {\n\t\t\tlog.LogErrorf(\"getBucketV1Handler: parse max key fail: requestID(%v) volume(%v) maxKeys(%v) err(%v)\",\n\t\t\t\tGetRequestID(r), vol.Name(), maxKeys, err)\n\t\t\terrorCode = InvalidArgument\n\t\t\treturn\n\t\t}\n\t\tif maxKeysInt > MaxKeys {\n\t\t\tmaxKeysInt = MaxKeys\n\t\t}\n\t} else {\n\t\tmaxKeysInt = uint64(MaxKeys)\n\t}\n\n\t// Validate encoding type option\n\tif encodingType != \"\" && encodingType != \"url\" {\n\t\terrorCode = InvalidArgument\n\t\treturn\n\t}\n\n\tif marker != \"\" && prefix != \"\" && !strings.HasPrefix(marker, prefix) {\n\t\terrorCode = InvalidArgument\n\t\treturn\n\t}\n\n\tvar option = &ListFilesV1Option{\n\t\tPrefix:     prefix,\n\t\tDelimiter:  delimiter,\n\t\tMarker:     marker,\n\t\tMaxKeys:    maxKeysInt,\n\t\tOnlyObject: true,\n\t}\n\n\tvar result *ListFilesV1Result\n\tresult, err = vol.ListFilesV1(option)\n\tif err != nil {\n\t\tlog.LogErrorf(\"getBucketV1Handler: list files fail: requestID(%v) volume(%v) option(%v) err(%v)\",\n\t\t\tGetRequestID(r), vol.Name(), option, err)\n\t\treturn\n\t}\n\t// The result of next list request should not include nextMarker.\n\tif result.Truncated && len(result.Files) != 0 {\n\t\tresult.NextMarker = result.Files[len(result.Files)-1].Path\n\t}\n\n\t// get owner\n\tvar bucketOwner = NewBucketOwner(vol)\n\tlog.LogDebugf(\"Owner: %v\", bucketOwner)\n\tvar contents = make([]*Content, 0, len(result.Files))\n\tfor _, file := range result.Files {\n\t\tif file.Mode == 0 {\n\t\t\t// Invalid file mode, which means that the inode of the file may not exist.\n\t\t\t// Record and filter out the file.\n\t\t\tlog.LogWarnf(\"getBucketV1Handler: invalid file found: requestID(%v) volume(%v) path(%v) inode(%v)\",\n\t\t\t\tGetRequestID(r), vol.Name(), file.Path, file.Inode)\n\t\t\tcontinue\n\t\t}\n\t\tcontent := &Content{\n\t\t\tKey:          encodeKey(file.Path, encodingType),\n\t\t\tLastModified: formatTimeISO(file.ModifyTime),\n\t\t\tETag:         wrapUnescapedQuot(file.ETag),\n\t\t\tSize:         int(file.Size),\n\t\t\tStorageClass: StorageClassStandard,\n\t\t\tOwner:        bucketOwner,\n\t\t}\n\t\tcontents = append(contents, content)\n\t}\n\n\tvar commonPrefixes = make([]*CommonPrefix, 0)\n\tfor _, prefix := range result.CommonPrefixes {\n\t\tcommonPrefix := &CommonPrefix{\n\t\t\tPrefix: prefix,\n\t\t}\n\t\tcommonPrefixes = append(commonPrefixes, commonPrefix)\n\t}\n\n\tlistBucketResult := &ListBucketResult{\n\t\tBucket:         param.Bucket(),\n\t\tPrefix:         prefix,\n\t\tMarker:         marker,\n\t\tMaxKeys:        int(maxKeysInt),\n\t\tDelimiter:      delimiter,\n\t\tIsTruncated:    result.Truncated,\n\t\tNextMarker:     result.NextMarker,\n\t\tContents:       contents,\n\t\tCommonPrefixes: commonPrefixes,\n\t}\n\tresponse, err := MarshalXMLEntity(listBucketResult)\n\tif err != nil {\n\t\tlog.LogErrorf(\"getBucketV1Handler: xml marshal result fail: requestID(%v) volume(%v) err(%v)\",\n\t\t\tGetRequestID(r), vol.Name(), err)\n\t\treturn\n\t}\n\n\twriteSuccessResponseXML(w, response)\n\treturn\n}\n\n// List objects version 2\n// API reference: https://docs.aws.amazon.com/AmazonS3/latest/API/API_ListObjectsV2.html\nfunc (o *ObjectNode) getBucketV2Handler(w http.ResponseWriter, r *http.Request) {\n\tvar err error\n\tvar errorCode *ErrorCode\n\tdefer func() {\n\t\to.errorResponse(w, r, err, errorCode)\n\t}()\n\n\tvar param = ParseRequestParam(r)\n\tif param.Bucket() == \"\" {\n\t\terrorCode = InvalidBucketName\n\t\treturn\n\t}\n\tvar vol *Volume\n\tif vol, err = o.getVol(param.Bucket()); err != nil {\n\t\tlog.LogErrorf(\"getBucketV2Handler: load volume fail: requestID(%v) volume(%v) err(%v)\",\n\t\t\tGetRequestID(r), param.Bucket(), err)\n\t\treturn\n\t}\n\n\t// QPS and Concurrency Limit\n\trateLimit := o.AcquireRateLimiter()\n\tif err = rateLimit.AcquireLimitResource(vol.owner, param.apiName); err != nil {\n\t\treturn\n\t}\n\tdefer rateLimit.ReleaseLimitResource(vol.owner, param.apiName)\n\n\t// get options\n\tprefix := r.URL.Query().Get(ParamPrefix)\n\tmaxKeys := r.URL.Query().Get(ParamMaxKeys)\n\tdelimiter := r.URL.Query().Get(ParamPartDelimiter)\n\tcontToken := r.URL.Query().Get(ParamContToken)\n\tfetchOwner := r.URL.Query().Get(ParamFetchOwner)\n\tstartAfter := r.URL.Query().Get(ParamStartAfter)\n\tencodingType := r.URL.Query().Get(ParamEncodingType)\n\n\tvar maxKeysInt uint64\n\tif maxKeys != \"\" {\n\t\tmaxKeysInt, err = strconv.ParseUint(maxKeys, 10, 16)\n\t\tif err != nil {\n\t\t\tlog.LogErrorf(\"getBucketV2Handler: parse max keys fail: requestID(%v) volume(%v) maxKeys(%v) err(%v)\",\n\t\t\t\tGetRequestID(r), vol.Name(), maxKeys, err)\n\t\t\terrorCode = InvalidArgument\n\t\t\treturn\n\t\t}\n\t\tif maxKeysInt > MaxKeys {\n\t\t\tmaxKeysInt = MaxKeys\n\t\t}\n\t} else {\n\t\tmaxKeysInt = MaxKeys\n\t}\n\n\tvar fetchOwnerBool bool\n\tif fetchOwner != \"\" {\n\t\tfetchOwnerBool, err = strconv.ParseBool(fetchOwner)\n\t\tif err != nil {\n\t\t\tlog.LogErrorf(\"getBucketV2Handler: parse fetch owner fail: requestID(%v) volume(%v) fetchOwner(%v) err(%v)\",\n\t\t\t\tGetRequestID(r), vol.Name(), fetchOwner, err)\n\t\t\terrorCode = InvalidArgument\n\t\t\treturn\n\t\t}\n\t} else {\n\t\tfetchOwnerBool = false\n\t}\n\n\t// Validate encoding type option\n\tif encodingType != \"\" && encodingType != \"url\" {\n\t\terrorCode = InvalidArgument\n\t\treturn\n\t}\n\n\tvar marker string\n\tif contToken != \"\" {\n\t\tmarker = contToken\n\t} else {\n\t\tmarker = startAfter\n\t}\n\tif marker != \"\" && prefix != \"\" && !strings.HasPrefix(marker, prefix) {\n\t\terrorCode = InvalidArgument\n\t\treturn\n\t}\n\n\tvar option = &ListFilesV2Option{\n\t\tDelimiter:  delimiter,\n\t\tMaxKeys:    maxKeysInt,\n\t\tPrefix:     prefix,\n\t\tContToken:  contToken,\n\t\tFetchOwner: fetchOwnerBool,\n\t\tStartAfter: startAfter,\n\t}\n\n\tvar result *ListFilesV2Result\n\tresult, err = vol.ListFilesV2(option)\n\tif err != nil {\n\t\tlog.LogErrorf(\"getBucketV2Handler: list files fail, requestID(%v) volume(%v) option(%v) err(%v)\",\n\t\t\tGetRequestID(r), vol.Name(), option, err)\n\t\treturn\n\t}\n\t// The result of next list request should not include continuationToken.\n\tif result.Truncated && len(result.Files) > 0 {\n\t\tresult.NextToken = result.Files[len(result.Files)-1].Path\n\t}\n\n\t// get owner\n\tvar bucketOwner *BucketOwner\n\tif fetchOwnerBool {\n\t\tbucketOwner = NewBucketOwner(vol)\n\t}\n\n\tvar contents = make([]*Content, 0)\n\tif len(result.Files) > 0 {\n\t\tfor _, file := range result.Files {\n\t\t\tif file.Mode == 0 {\n\t\t\t\t// Invalid file mode, which means that the inode of the file may not exist.\n\t\t\t\t// Record and filter out the file.\n\t\t\t\tlog.LogWarnf(\"getBucketV2Handler: invalid file found: requestID(%v) volume(%v) path(%v) inode(%v)\",\n\t\t\t\t\tGetRequestID(r), vol.Name(), file.Path, file.Inode)\n\t\t\t\tresult.KeyCount--\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tcontent := &Content{\n\t\t\t\tKey:          encodeKey(file.Path, encodingType),\n\t\t\t\tLastModified: formatTimeISO(file.ModifyTime),\n\t\t\t\tETag:         wrapUnescapedQuot(file.ETag),\n\t\t\t\tSize:         int(file.Size),\n\t\t\t\tStorageClass: StorageClassStandard,\n\t\t\t\tOwner:        bucketOwner,\n\t\t\t}\n\t\t\tcontents = append(contents, content)\n\t\t}\n\t}\n\n\tvar commonPrefixes = make([]*CommonPrefix, 0)\n\tfor _, prefix := range result.CommonPrefixes {\n\t\tcommonPrefix := &CommonPrefix{\n\t\t\tPrefix: prefix,\n\t\t}\n\t\tcommonPrefixes = append(commonPrefixes, commonPrefix)\n\t}\n\n\tlistBucketResult := ListBucketResultV2{\n\t\tName:           param.Bucket(),\n\t\tPrefix:         prefix,\n\t\tToken:          contToken,\n\t\tNextToken:      result.NextToken,\n\t\tKeyCount:       result.KeyCount,\n\t\tMaxKeys:        maxKeysInt,\n\t\tDelimiter:      delimiter,\n\t\tIsTruncated:    result.Truncated,\n\t\tContents:       contents,\n\t\tCommonPrefixes: commonPrefixes,\n\t}\n\tresponse, err := MarshalXMLEntity(listBucketResult)\n\tif err != nil {\n\t\tlog.LogErrorf(\"getBucketV2Handler: xml marshal result fail: requestID(%v) volume(%v) err(%v)\",\n\t\t\tGetRequestID(r), vol.Name(), err)\n\t\treturn\n\t}\n\n\twriteSuccessResponseXML(w, response)\n\treturn\n}\n\n// Put object\n// API reference: https://docs.aws.amazon.com/AmazonS3/latest/API/API_PutObject.html\nfunc (o *ObjectNode) putObjectHandler(w http.ResponseWriter, r *http.Request) {\n\tvar err error\n\tvar errorCode *ErrorCode\n\tdefer func() {\n\t\to.errorResponse(w, r, err, errorCode)\n\t}()\n\n\tvar param = ParseRequestParam(r)\n\tif param.Bucket() == \"\" {\n\t\terrorCode = InvalidBucketName\n\t\treturn\n\t}\n\tif param.Object() == \"\" {\n\t\terrorCode = InvalidKey\n\t\treturn\n\t}\n\tif len(param.Object()) > MaxKeyLength {\n\t\terrorCode = KeyTooLong\n\t\treturn\n\t}\n\tvar vol *Volume\n\tif vol, err = o.getVol(param.Bucket()); err != nil {\n\t\tlog.LogErrorf(\"putObjectHandler: load volume fail: requestID(%v)  volume(%v) err(%v)\",\n\t\t\tGetRequestID(r), param.Bucket(), err)\n\t\treturn\n\t}\n\n\t// Get request MD5, if request MD5 is not empty, compute and verify it.\n\trequestMD5 := r.Header.Get(ContentMD5)\n\tif requestMD5 != \"\" {\n\t\tdecoded, err := base64.StdEncoding.DecodeString(requestMD5)\n\t\tif err != nil {\n\t\t\terrorCode = InvalidDigest\n\t\t\treturn\n\t\t}\n\t\trequestMD5 = hex.EncodeToString(decoded)\n\t}\n\n\t// ObjectLock  Config\n\tobjetLock, err := vol.metaLoader.loadObjectLock()\n\tif err != nil {\n\t\tlog.LogErrorf(\"putObjectHandler: load volume objetLock: requestID(%v)  volume(%v) err(%v)\",\n\t\t\tGetRequestID(r), param.Bucket(), err)\n\t\treturn\n\t}\n\tif objetLock != nil && objetLock.ToRetention() != nil && requestMD5 == \"\" {\n\t\terrorCode = NoContentMd5HeaderErr\n\t\treturn\n\t}\n\n\t// QPS and Concurrency Limit\n\trateLimit := o.AcquireRateLimiter()\n\tif err = rateLimit.AcquireLimitResource(vol.owner, param.apiName); err != nil {\n\t\treturn\n\t}\n\tdefer rateLimit.ReleaseLimitResource(vol.owner, param.apiName)\n\n\t// Check 'x-amz-tagging' header\n\t// Reference: https://docs.aws.amazon.com/AmazonS3/latest/API/API_PutObject.html#API_PutObject_RequestSyntax\n\tvar tagging *Tagging\n\tif xAmxTagging := r.Header.Get(XAmzTagging); xAmxTagging != \"\" {\n\t\tif tagging, err = ParseTagging(xAmxTagging); err != nil {\n\t\t\terrorCode = InvalidArgument\n\t\t\treturn\n\t\t}\n\t\tvar validateRes bool\n\t\tif validateRes, errorCode = tagging.Validate(); !validateRes {\n\t\t\tlog.LogErrorf(\"putObjectHandler: tagging validate fail: requestID(%v) volume(%v) path(%v) tagging(%v) err(%v)\",\n\t\t\t\tGetRequestID(r), vol.Name(), param.Object(), tagging, errorCode)\n\t\t\treturn\n\t\t}\n\t}\n\n\tvar userInfo *proto.UserInfo\n\tif userInfo, err = o.getUserInfoByAccessKeyV2(param.AccessKey()); err != nil {\n\t\tlog.LogErrorf(\"putObjectHandler: get user info fail: requestID(%v) volume(%v) accessKey(%v) err(%v)\",\n\t\t\tGetRequestID(r), param.Bucket(), param.AccessKey(), err)\n\t\treturn\n\t}\n\n\t// Check ACL\n\tacl, err := ParseACL(r, userInfo.UserID, false, vol.GetOwner() != userInfo.UserID)\n\tif err != nil {\n\t\tlog.LogErrorf(\"putObjectHandler: parse acl fail: requestID(%v) volume(%v) path(%v) acl(%+v) err(%v)\",\n\t\t\tGetRequestID(r), vol.Name(), param.Object(), acl, err)\n\t\treturn\n\t}\n\n\t// Verify ContentLength\n\tlength := GetContentLength(r)\n\tif length > SinglePutLimit {\n\t\terrorCode = EntityTooLarge\n\t\treturn\n\t}\n\tif length < 0 {\n\t\terrorCode = MissingContentLength\n\t\treturn\n\t}\n\n\t// Get the requested content-type.\n\t// In addition to being used to manage data types, it is used to distinguish\n\t// whether the request is to create a directory.\n\tcontentType := r.Header.Get(ContentType)\n\t// Get request header : content-disposition\n\tcontentDisposition := r.Header.Get(ContentDisposition)\n\t// Get request header : Cache-Control\n\tcacheControl := r.Header.Get(CacheControl)\n\tif len(cacheControl) > 0 && !ValidateCacheControl(cacheControl) {\n\t\terrorCode = InvalidCacheArgument\n\t\treturn\n\t}\n\t// Get request header : Expires\n\texpires := r.Header.Get(Expires)\n\tif len(expires) > 0 && !ValidateCacheExpires(expires) {\n\t\terrorCode = InvalidCacheArgument\n\t\treturn\n\t}\n\t// Checking user-defined metadata\n\tmetadata := ParseUserDefinedMetadata(r.Header)\n\t// Audit file write\n\tlog.LogInfof(\"Audit: put object: requestID(%v) remote(%v) volume(%v) path(%v) type(%v)\",\n\t\tGetRequestID(r), getRequestIP(r), vol.Name(), param.Object(), contentType)\n\n\tvar fsFileInfo *FSFileInfo\n\tvar opt = &PutFileOption{\n\t\tMIMEType:     contentType,\n\t\tDisposition:  contentDisposition,\n\t\tTagging:      tagging,\n\t\tMetadata:     metadata,\n\t\tCacheControl: cacheControl,\n\t\tExpires:      expires,\n\t\tACL:          acl,\n\t\tObjectLock:   objetLock,\n\t}\n\tvar startPut = time.Now()\n\n\t// Flow Control\n\tvar reader io.Reader\n\tif length > DefaultFlowLimitSize {\n\t\treader = rateLimit.GetReader(vol.owner, param.apiName, r.Body)\n\t} else {\n\t\treader = r.Body\n\t}\n\tif fsFileInfo, err = vol.PutObject(param.Object(), reader, opt); err != nil {\n\t\tlog.LogErrorf(\"putObjectHandler: put object fail: requestId(%v) volume(%v) path(%v) remote(%v) err(%v)\",\n\t\t\tGetRequestID(r), vol.Name(), param.Object(), getRequestIP(r), err)\n\t\terr = handlePutObjectErr(err)\n\t\treturn\n\t}\n\t// check content MD5\n\tif requestMD5 != \"\" && requestMD5 != fsFileInfo.ETag {\n\t\tlog.LogErrorf(\"putObjectHandler: MD5 validate fail: requestID(%v) volume(%v) path(%v) requestMD5(%v) serverMD5(%v)\",\n\t\t\tGetRequestID(r), vol.Name(), param.Object(), requestMD5, fsFileInfo.ETag)\n\t\terrorCode = BadDigest\n\t\treturn\n\t}\n\tlog.LogDebugf(\"PutObject succeed, requestID(%v) volume(%v) key(%v) costTime: %v\", GetRequestID(r),\n\t\tvol.Name(), param.Object(), time.Since(startPut))\n\n\t// set response header\n\tw.Header()[ETag] = []string{wrapUnescapedQuot(fsFileInfo.ETag)}\n\treturn\n}\n\n// Post object\n// API reference: https://docs.aws.amazon.com/AmazonS3/latest/API/RESTObjectPOST.html\nfunc (o *ObjectNode) postObjectHandler(w http.ResponseWriter, r *http.Request) {\n\tvar err error\n\tvar errorCode *ErrorCode\n\tdefer func() {\n\t\to.errorResponse(w, r, err, errorCode)\n\t}()\n\n\tparam := ParseRequestParam(r)\n\tif param.Bucket() == \"\" {\n\t\terrorCode = InvalidBucketName\n\t\treturn\n\t}\n\n\t// TODO: will be implemented\n\terrorCode = UnsupportedOperation\n\n\treturn\n}\n\nfunc handlePutObjectErr(err error) error {\n\tif err == syscall.EINVAL {\n\t\treturn ObjectModeConflict\n\t}\n\tif err == syscall.EEXIST {\n\t\treturn ConflictUploadRequest\n\t}\n\tif err == io.ErrUnexpectedEOF {\n\t\treturn EntityTooSmall\n\t}\n\treturn err\n}\n\n// Delete object\n// API reference: https://docs.aws.amazon.com/AmazonS3/latest/API/API_DeleteObject.html .\nfunc (o *ObjectNode) deleteObjectHandler(w http.ResponseWriter, r *http.Request) {\n\tvar (\n\t\terr       error\n\t\terrorCode *ErrorCode\n\t)\n\tdefer func() {\n\t\to.errorResponse(w, r, err, errorCode)\n\t}()\n\n\tvar param = ParseRequestParam(r)\n\tif param.Bucket() == \"\" {\n\t\terrorCode = InvalidBucketName\n\t\treturn\n\t}\n\tif param.Object() == \"\" {\n\t\terrorCode = InvalidKey\n\t\treturn\n\t}\n\n\tvar vol *Volume\n\tif vol, err = o.getVol(param.Bucket()); err != nil {\n\t\tlog.LogErrorf(\"deleteObjectHandler: load volume fail: requestID(%v) volume(%v) err(%v)\",\n\t\t\tGetRequestID(r), param.Bucket(), err)\n\t\treturn\n\t}\n\n\t// QPS and Concurrency Limit\n\trateLimit := o.AcquireRateLimiter()\n\tif err = rateLimit.AcquireLimitResource(vol.owner, param.apiName); err != nil {\n\t\treturn\n\t}\n\tdefer rateLimit.ReleaseLimitResource(vol.owner, param.apiName)\n\n\t// Audit deletion\n\tlog.LogInfof(\"Audit: delete object: requestID(%v) remote(%v) volume(%v) path(%v)\",\n\t\tGetRequestID(r), getRequestIP(r), vol.Name(), param.Object())\n\n\terr = vol.DeletePath(param.Object())\n\tif err != nil {\n\t\tlog.LogErrorf(\"deleteObjectHandler: Volume delete file fail: \"+\n\t\t\t\"requestID(%v) volume(%v) path(%v) err(%v)\", GetRequestID(r), vol.Name(), param.Object(), err)\n\t\treturn\n\t}\n\n\tw.WriteHeader(http.StatusNoContent)\n\treturn\n}\n\n// Get object tagging\n// API reference: https://docs.aws.amazon.com/AmazonS3/latest/API/API_GetObjectTagging.html\nfunc (o *ObjectNode) getObjectTaggingHandler(w http.ResponseWriter, r *http.Request) {\n\tvar err error\n\tvar errorCode *ErrorCode\n\tdefer func() {\n\t\to.errorResponse(w, r, err, errorCode)\n\t}()\n\n\tvar param = ParseRequestParam(r)\n\tif param.Bucket() == \"\" {\n\t\terrorCode = InvalidBucketName\n\t\treturn\n\t}\n\tif param.Object() == \"\" {\n\t\terrorCode = InvalidKey\n\t\treturn\n\t}\n\tvar vol *Volume\n\tif vol, err = o.getVol(param.Bucket()); err != nil {\n\t\tlog.LogErrorf(\"getObjectTaggingHandler: load volume fail: requestID(%v) volume(%v) err(%v)\",\n\t\t\tGetRequestID(r), param.Bucket(), err)\n\t\treturn\n\t}\n\n\t// QPS and Concurrency Limit\n\trateLimit := o.AcquireRateLimiter()\n\tif err = rateLimit.AcquireLimitResource(vol.owner, param.apiName); err != nil {\n\t\treturn\n\t}\n\tdefer rateLimit.ReleaseLimitResource(vol.owner, param.apiName)\n\n\tvar xattrInfo *proto.XAttrInfo\n\tif xattrInfo, err = vol.GetXAttr(param.object, XAttrKeyOSSTagging); err != nil {\n\t\tlog.LogErrorf(\"getObjectTaggingHandler: get volume XAttr fail: requestID(%v) err(%v)\", GetRequestID(r), err)\n\t\tif err == syscall.ENOENT {\n\t\t\terrorCode = NoSuchKey\n\t\t}\n\t\treturn\n\t}\n\n\tossTaggingData := xattrInfo.Get(XAttrKeyOSSTagging)\n\n\tvar output, _ = ParseTagging(string(ossTaggingData))\n\tresponse, err := MarshalXMLEntity(output)\n\tif err != nil {\n\t\tlog.LogErrorf(\"getObjectTaggingHandler: xml marshal result fail: requestID(%v) result(%v) err(%v)\",\n\t\t\tGetRequestID(r), output, err)\n\t\treturn\n\t}\n\n\twriteSuccessResponseXML(w, response)\n\treturn\n}\n\n// Put object tagging\n// API reference: https://docs.aws.amazon.com/AmazonS3/latest/API/API_PutObjectTagging.html\nfunc (o *ObjectNode) putObjectTaggingHandler(w http.ResponseWriter, r *http.Request) {\n\tvar err error\n\tvar errorCode *ErrorCode\n\tdefer func() {\n\t\to.errorResponse(w, r, err, errorCode)\n\t}()\n\n\tvar param = ParseRequestParam(r)\n\tif param.Bucket() == \"\" {\n\t\terrorCode = InvalidBucketName\n\t\treturn\n\t}\n\tif param.Object() == \"\" {\n\t\terrorCode = InvalidKey\n\t\treturn\n\t}\n\n\tvar vol *Volume\n\tif vol, err = o.getVol(param.Bucket()); err != nil {\n\t\tlog.LogErrorf(\"putObjectTaggingHandler: load volume fail: requestID(%v) err(%v)\",\n\t\t\tGetRequestID(r), err)\n\t\treturn\n\t}\n\n\t// QPS and Concurrency Limit\n\trateLimit := o.AcquireRateLimiter()\n\tif err = rateLimit.AcquireLimitResource(vol.owner, param.apiName); err != nil {\n\t\treturn\n\t}\n\tdefer rateLimit.ReleaseLimitResource(vol.owner, param.apiName)\n\n\t_, errorCode = VerifyContentLength(r, BodyLimit)\n\tif errorCode != nil {\n\t\treturn\n\t}\n\tvar requestBody []byte\n\tif requestBody, err = ioutil.ReadAll(r.Body); err != nil {\n\t\tlog.LogErrorf(\"putObjectTaggingHandler: read request body data fail: requestID(%v) err(%v)\",\n\t\t\tGetRequestID(r), err)\n\t\terrorCode = InvalidArgument\n\t\treturn\n\t}\n\n\tvar tagging = NewTagging()\n\tif err = xml.Unmarshal(requestBody, tagging); err != nil {\n\t\tlog.LogWarnf(\"putObjectTaggingHandler: decode request body fail: requestID(%v) err(%v)\",\n\t\t\tGetRequestID(r), err)\n\t\terrorCode = InvalidArgument\n\t\treturn\n\t}\n\tvalidateRes, errorCode := tagging.Validate()\n\tif !validateRes {\n\t\tlog.LogErrorf(\"putObjectTaggingHandler: tagging validate fail: requestID(%v) tagging(%v) err(%v)\",\n\t\t\tGetRequestID(r), tagging, errorCode.Error())\n\t\treturn\n\t}\n\n\terr = vol.SetXAttr(param.object, XAttrKeyOSSTagging, []byte(tagging.Encode()), false)\n\tif err != nil {\n\t\tlog.LogErrorf(\"pubObjectTaggingHandler: set tagging xattr fail: requestID(%v) volume(%v) object(%v) err(%v)\",\n\t\t\tGetRequestID(r), param.Bucket(), param.Object(), err)\n\t\tif err == syscall.ENOENT {\n\t\t\terrorCode = NoSuchKey\n\t\t}\n\t\treturn\n\t}\n\n\treturn\n}\n\n// Delete object tagging\n// API reference: https://docs.aws.amazon.com/AmazonS3/latest/API/API_DeleteObjectTagging.html\nfunc (o *ObjectNode) deleteObjectTaggingHandler(w http.ResponseWriter, r *http.Request) {\n\tvar err error\n\tvar errorCode *ErrorCode\n\tdefer func() {\n\t\to.errorResponse(w, r, err, errorCode)\n\t}()\n\n\tvar param = ParseRequestParam(r)\n\tif param.Bucket() == \"\" {\n\t\terrorCode = InvalidBucketName\n\t\treturn\n\t}\n\tif param.Object() == \"\" {\n\t\terrorCode = InvalidKey\n\t\treturn\n\t}\n\tvar vol *Volume\n\tif vol, err = o.getVol(param.Bucket()); err != nil {\n\t\tlog.LogErrorf(\"deleteObjectTaggingHandler: load volume fail: requestID(%v) err(%v)\",\n\t\t\tGetRequestID(r), err)\n\t\treturn\n\t}\n\n\t// QPS and Concurrency Limit\n\trateLimit := o.AcquireRateLimiter()\n\tif err = rateLimit.AcquireLimitResource(vol.owner, param.apiName); err != nil {\n\t\treturn\n\t}\n\tdefer rateLimit.ReleaseLimitResource(vol.owner, param.apiName)\n\n\tif err = vol.DeleteXAttr(param.object, XAttrKeyOSSTagging); err != nil {\n\t\tlog.LogErrorf(\"deleteObjectTaggingHandler: volume delete tagging fail: requestID(%v) volume(%v) object(%v) err(%v)\",\n\t\t\tGetRequestID(r), param.Bucket(), param.Object(), err)\n\t\treturn\n\t}\n\n\tw.WriteHeader(http.StatusNoContent)\n\treturn\n}\n\n// Put object extend attribute (xattr)\nfunc (o *ObjectNode) putObjectXAttrHandler(w http.ResponseWriter, r *http.Request) {\n\tvar err error\n\tvar errorCode *ErrorCode\n\tdefer func() {\n\t\to.errorResponse(w, r, err, errorCode)\n\t}()\n\n\tvar param = ParseRequestParam(r)\n\tif len(param.Bucket()) == 0 {\n\t\terrorCode = InvalidBucketName\n\t\treturn\n\t}\n\tif len(param.Object()) == 0 {\n\t\terrorCode = InvalidKey\n\t\treturn\n\t}\n\tvar vol *Volume\n\tif vol, err = o.getVol(param.bucket); err != nil {\n\t\tlog.LogErrorf(\"pubObjectXAttrHandler: load volume fail: requestID(%v) err(%v)\",\n\t\t\tGetRequestID(r), err)\n\t\treturn\n\t}\n\n\t// QPS and Concurrency Limit\n\trateLimit := o.AcquireRateLimiter()\n\tif err = rateLimit.AcquireLimitResource(vol.owner, param.apiName); err != nil {\n\t\treturn\n\t}\n\tdefer rateLimit.ReleaseLimitResource(vol.owner, param.apiName)\n\n\t_, errorCode = VerifyContentLength(r, BodyLimit)\n\tif errorCode != nil {\n\t\treturn\n\t}\n\tvar requestBody []byte\n\tif requestBody, err = ioutil.ReadAll(r.Body); err != nil {\n\t\terrorCode = &ErrorCode{\n\t\t\tErrorCode:    \"BadRequest\",\n\t\t\tErrorMessage: err.Error(),\n\t\t\tStatusCode:   http.StatusBadRequest,\n\t\t}\n\t\treturn\n\t}\n\tvar putXAttrRequest = PutXAttrRequest{}\n\tif err = xml.Unmarshal(requestBody, &putXAttrRequest); err != nil {\n\t\terrorCode = &ErrorCode{\n\t\t\tErrorCode:    \"BadRequest\",\n\t\t\tErrorMessage: err.Error(),\n\t\t\tStatusCode:   http.StatusBadRequest,\n\t\t}\n\t\treturn\n\t}\n\tvar key, value = putXAttrRequest.XAttr.Key, putXAttrRequest.XAttr.Value\n\tif len(key) == 0 {\n\t\treturn\n\t}\n\n\tif err = vol.SetXAttr(param.object, key, []byte(value), true); err != nil {\n\t\tlog.LogErrorf(\"pubObjectXAttrHandler: volume set extend attribute fail: requestID(%v) err(%v)\",\n\t\t\tGetRequestID(r), err)\n\t\tif err == syscall.ENOENT {\n\t\t\terrorCode = NoSuchKey\n\t\t}\n\t\treturn\n\t}\n\n\treturn\n}\n\n// Get object extend attribute (xattr)\nfunc (o *ObjectNode) getObjectXAttrHandler(w http.ResponseWriter, r *http.Request) {\n\tvar err error\n\tvar errorCode *ErrorCode\n\tdefer func() {\n\t\to.errorResponse(w, r, err, errorCode)\n\t}()\n\n\tvar param = ParseRequestParam(r)\n\tif len(param.Bucket()) == 0 {\n\t\terrorCode = InvalidBucketName\n\t\treturn\n\t}\n\tif len(param.Object()) == 0 {\n\t\terrorCode = InvalidKey\n\t\treturn\n\t}\n\tvar vol *Volume\n\tif vol, err = o.getVol(param.Bucket()); err != nil {\n\t\tlog.LogErrorf(\"getObjectXAttrHandler: load volume fail: requestID(%v) err(%v)\",\n\t\t\tGetRequestID(r), err)\n\t\treturn\n\t}\n\n\t// QPS and Concurrency Limit\n\trateLimit := o.AcquireRateLimiter()\n\tif err = rateLimit.AcquireLimitResource(vol.owner, param.apiName); err != nil {\n\t\treturn\n\t}\n\tdefer rateLimit.ReleaseLimitResource(vol.owner, param.apiName)\n\n\tvar xattrKey string\n\tif xattrKey = param.GetVar(ParamKey); len(xattrKey) == 0 {\n\t\terrorCode = InvalidArgument\n\t\treturn\n\t}\n\n\tvar info *proto.XAttrInfo\n\tif info, err = vol.GetXAttr(param.object, xattrKey); err != nil {\n\t\tlog.LogErrorf(\"getObjectXAttrHandler: get extend attribute fail: requestID(%v) volume(%v) object(%v) key(%v) err(%v)\",\n\t\t\tGetRequestID(r), param.Bucket(), param.Object(), xattrKey, err)\n\t\tif err == syscall.ENOENT {\n\t\t\terrorCode = NoSuchKey\n\t\t}\n\t\treturn\n\t}\n\toutput := GetXAttrOutput{\n\t\tXAttr: &XAttr{\n\t\t\tKey:   xattrKey,\n\t\t\tValue: string(info.Get(xattrKey)),\n\t\t},\n\t}\n\tresponse, err := MarshalXMLEntity(&output)\n\tif err != nil {\n\t\tlog.LogErrorf(\"getObjectXAttrHandler: xml marshal result fail: requestID(%v) result(%v) err(%v)\",\n\t\t\tGetRequestID(r), output, err)\n\t\treturn\n\t}\n\n\twriteSuccessResponseXML(w, response)\n\treturn\n}\n\n// Delete object extend attribute (xattr)\nfunc (o *ObjectNode) deleteObjectXAttrHandler(w http.ResponseWriter, r *http.Request) {\n\tvar err error\n\tvar errorCode *ErrorCode\n\tdefer func() {\n\t\to.errorResponse(w, r, err, errorCode)\n\t}()\n\n\tvar param = ParseRequestParam(r)\n\tif len(param.Bucket()) == 0 {\n\t\terrorCode = InvalidBucketName\n\t\treturn\n\t}\n\tif len(param.Object()) == 0 {\n\t\terrorCode = InvalidKey\n\t\treturn\n\t}\n\tvar vol *Volume\n\tif vol, err = o.getVol(param.Bucket()); err != nil {\n\t\tlog.LogErrorf(\"deleteObjectXAttrHandler: load volume fail: requestID(%v) err(%v)\",\n\t\t\tGetRequestID(r), err)\n\t\treturn\n\t}\n\n\t// QPS and Concurrency Limit\n\trateLimit := o.AcquireRateLimiter()\n\tif err = rateLimit.AcquireLimitResource(vol.owner, param.apiName); err != nil {\n\t\treturn\n\t}\n\tdefer rateLimit.ReleaseLimitResource(vol.owner, param.apiName)\n\n\tvar xattrKey string\n\tif xattrKey = param.GetVar(ParamKey); len(xattrKey) == 0 {\n\t\terrorCode = InvalidArgument\n\t\treturn\n\t}\n\n\tif err = vol.DeleteXAttr(param.object, xattrKey); err != nil {\n\t\tlog.LogErrorf(\"deleteObjectXAttrHandler: delete extend attribute fail: requestID(%v) err(%v)\",\n\t\t\tGetRequestID(r), err)\n\t\tif err == syscall.ENOENT {\n\t\t\terrorCode = NoSuchKey\n\t\t}\n\t\treturn\n\t}\n\n\treturn\n}\n\n// List object xattrs\nfunc (o *ObjectNode) listObjectXAttrs(w http.ResponseWriter, r *http.Request) {\n\tvar err error\n\tvar errorCode *ErrorCode\n\tdefer func() {\n\t\to.errorResponse(w, r, err, errorCode)\n\t}()\n\n\tvar param = ParseRequestParam(r)\n\tif len(param.Bucket()) == 0 {\n\t\terrorCode = InvalidBucketName\n\t\treturn\n\t}\n\tif len(param.Object()) == 0 {\n\t\terrorCode = InvalidKey\n\t\treturn\n\t}\n\tvar vol *Volume\n\tif vol, err = o.getVol(param.bucket); err != nil {\n\t\tlog.LogErrorf(\"listObjectXAttrs: load volume fail: requestID(%v) err(%v)\",\n\t\t\tGetRequestID(r), err)\n\t\treturn\n\t}\n\n\t// QPS and Concurrency Limit\n\trateLimit := o.AcquireRateLimiter()\n\tif err = rateLimit.AcquireLimitResource(vol.owner, param.apiName); err != nil {\n\t\treturn\n\t}\n\tdefer rateLimit.ReleaseLimitResource(vol.owner, param.apiName)\n\n\tvar keys []string\n\tif keys, err = vol.ListXAttrs(param.object); err != nil {\n\t\tlog.LogErrorf(\"listObjectXAttrs: volume list extend attributes fail: requestID(%v) volume(%v) object(%v) err(%v)\",\n\t\t\tGetRequestID(r), param.Bucket(), param.Object(), err)\n\t\tif err == syscall.ENOENT {\n\t\t\terrorCode = NoSuchKey\n\t\t}\n\t\treturn\n\t}\n\n\toutput := ListXAttrsOutput{\n\t\tKeys: keys,\n\t}\n\tresponse, err := MarshalXMLEntity(&output)\n\tif err != nil {\n\t\tlog.LogErrorf(\"listObjectXAttrs: marshal response body fail: requestID(%v) volume(%v) object(%v) err(%v)\",\n\t\t\tGetRequestID(r), param.Bucket(), param.Object(), err)\n\t\treturn\n\t}\n\n\twriteSuccessResponseXML(w, response)\n\treturn\n}\n\n// GetObjectRetention\n// API reference: https://docs.aws.amazon.com/AmazonS3/latest/API/API_GetObjectRetention.html\nfunc (o *ObjectNode) getObjectRetentionHandler(w http.ResponseWriter, r *http.Request) {\n\tvar (\n\t\terr       error\n\t\terrorCode *ErrorCode\n\t)\n\tdefer func() {\n\t\to.errorResponse(w, r, err, errorCode)\n\t}()\n\n\t// check args\n\tvar param = ParseRequestParam(r)\n\tif param.Bucket() == \"\" {\n\t\terrorCode = InvalidBucketName\n\t\treturn\n\t}\n\tif param.Object() == \"\" {\n\t\terrorCode = InvalidKey\n\t\treturn\n\t}\n\tvar vol *Volume\n\tif vol, err = o.getVol(param.Bucket()); err != nil {\n\t\tlog.LogErrorf(\"getObjectRetentionHandler: load volume fail: requestID(%v) err(%v)\",\n\t\t\tGetRequestID(r), err)\n\t\treturn\n\t}\n\n\t// get object meta\n\t_, xattrs, err := vol.ObjectMeta(param.Object())\n\tif err != nil {\n\t\tlog.LogErrorf(\"getObjectRetentionHandler: get file meta fail: requestId(%v) volume(%v) path(%v) err(%v)\",\n\t\t\tGetRequestID(r), vol.Name(), param.Object(), err)\n\t\tif err == syscall.ENOENT {\n\t\t\terrorCode = NoSuchKey\n\t\t}\n\t\treturn\n\t}\n\tretainUntilDate := string(xattrs.Get(XAttrKeyOSSLock))\n\tif retainUntilDate == \"\" {\n\t\terrorCode = NoSuchObjectLockConfiguration\n\t\treturn\n\t}\n\tretainUntilDateInt64, err := strconv.ParseInt(retainUntilDate, 10, 64)\n\tif err != nil {\n\t\tlog.LogErrorf(\"getObjectRetentionHandler: parse retainUntilDate fail: requestId(%v) volume(%v) path(%v) err(%v)\",\n\t\t\tGetRequestID(r), vol.Name(), param.Object(), err)\n\t\treturn\n\t}\n\tvar objectRetention ObjectRetention\n\tobjectRetention.Mode = ComplianceMode\n\tobjectRetention.RetainUntilDate = RetentionDate{Time: time.Unix(0, retainUntilDateInt64).UTC()}\n\tb, err := xml.Marshal(objectRetention)\n\tif err != nil {\n\t\tlog.LogErrorf(\"getObjectRetentionHandler: xml marshal fail: requestId(%v) volume(%v) result(%v) err(%v)\",\n\t\t\tGetRequestID(r), vol.Name(), objectRetention, err)\n\t\treturn\n\t}\n\n\twriteSuccessResponseXML(w, b)\n\treturn\n}\n\nfunc parsePartInfo(partNumber uint64, fileSize uint64) (uint64, uint64, uint64, uint64) {\n\tvar partSize uint64\n\tvar partCount uint64\n\tvar rangeLower uint64\n\tvar rangeUpper uint64\n\t// partSize, partCount, rangeLower, rangeUpper\n\tpartSizeConst := ParallelDownloadPartSize\n\tpartCount = fileSize / uint64(partSizeConst)\n\tlastSize := fileSize % uint64(partSizeConst)\n\tif lastSize > 0 {\n\t\tpartCount += 1\n\t}\n\n\trangeLower = uint64(partSizeConst) * (partNumber - 1)\n\tif lastSize > 0 && partNumber == partCount {\n\t\tpartSize = lastSize\n\t\trangeUpper = fileSize - 1\n\t} else {\n\t\tpartSize = uint64(partSizeConst)\n\t\trangeUpper = (partSize * partNumber) - 1\n\t}\n\tif partNumber > partCount {\n\t\treturn 0, 0, 0, 0\n\t}\n\treturn partSize, partCount, rangeLower, rangeUpper\n}\n\nfunc GetContentLength(r *http.Request) int64 {\n\tdcl := r.Header.Get(HeaderNameXAmzDecodedContentLength)\n\tif dcl != \"\" {\n\t\tlength, err := strconv.ParseInt(dcl, 10, 64)\n\t\tif err == nil {\n\t\t\treturn length\n\t\t}\n\t}\n\treturn r.ContentLength\n}\n\nfunc VerifyContentLength(r *http.Request, bodyLimit int64) (int64, *ErrorCode) {\n\tdcl := r.Header.Get(HeaderNameXAmzDecodedContentLength)\n\tvar length = r.ContentLength\n\tif dcl != \"\" {\n\t\tl, err := strconv.ParseInt(dcl, 10, 64)\n\t\tif err == nil {\n\t\t\tlength = l\n\t\t}\n\t}\n\tif length > bodyLimit {\n\t\treturn 0, EntityTooLarge\n\t}\n\tif length <= 0 {\n\t\treturn 0, MissingContentLength\n\t}\n\treturn length, nil\n}\n", "// Copyright 2019 The CubeFS Authors.\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n// implied. See the License for the specific language governing\n// permissions and limitations under the License.\n\npackage objectnode\n\nimport \"os\"\n\nconst (\n\tMaxRetry = 3\n)\n\nconst (\n\tS3Namespace        = \"http://s3.amazonaws.com/doc/2006-03-01/\"\n\tServer             = \"Server\"\n\tHost               = \"Host\"\n\tLastModified       = \"Last-Modified\"\n\tETag               = \"ETag\"\n\tDate               = \"Date\"\n\tContentMD5         = \"Content-MD5\"\n\tContentEncoding    = \"Content-Encoding\"\n\tContentType        = \"Content-Type\"\n\tContentLength      = \"Content-Length\"\n\tContentRange       = \"Content-Range\"\n\tContentDisposition = \"Content-Disposition\"\n\tAuthorization      = \"Authorization\"\n\tAcceptRanges       = \"Accept-Ranges\"\n\tRange              = \"Range\"\n\tExpect             = \"Expect\"\n\tXForwardedExpect   = \"X-Forwarded-Expect\"\n\tLocation           = \"Location\"\n\tCacheControl       = \"Cache-Control\"\n\tExpires            = \"Expires\"\n\tConnection         = \"Connection\"\n\tSignature          = \"Signature\"\n\tOrigin             = \"Origin\"\n\n\tAccessControlRequestMethod    = \"Access-Control-Request-Method\"\n\tAccessControlRequestHeaders   = \"Access-Control-Request-Headers\"\n\tAccessControlAllowOrigin      = \"Access-Control-Allow-Origin\"\n\tAccessControlAllowCredentials = \"Access-Control-Allow-Credentials\"\n\tAccessControlMaxAge           = \"Access-Control-Max-Age\"\n\tAccessControlAllowMethods     = \"Access-Control-Allow-Methods\"\n\tAccessControlAllowHeaders     = \"Access-Control-Allow-Headers\"\n\tAccessControlExposeHeaders    = \"Access-Control-Expose-Headers\"\n\n\tIfMatch           = \"If-Match\"\n\tIfNoneMatch       = \"If-None-Match\"\n\tIfModifiedSince   = \"If-Modified-Since\"\n\tIfUnmodifiedSince = \"If-Unmodified-Since\"\n\n\tXAmzRequestId                   = \"x-amz-request-id\"\n\tXAmzCopySource                  = \"x-amz-copy-source\"\n\tXAmzCopySourceRange             = \"x-amz-copy-source-range\"\n\tXAmzCopySourceIfMatch           = \"x-amz-copy-source-if-match\"\n\tXAmzCopySourceIfNoneMatch       = \"x-amz-copy-source-if-none-match\"\n\tXAmzCopySourceIfModifiedSince   = \"x-amz-copy-source-if-modified-since\"\n\tXAmzCopySourceIfUnmodifiedSince = \"x-amz-copy-source-if-unmodified-since\"\n\tXAmzDecodedContentLength        = \"x-amz-decoded-content-length\"\n\tXAmzTagging                     = \"x-amz-tagging\"\n\tXAmzMetaPrefix                  = \"x-amz-meta-\"\n\tXAmzMpPartsCount                = \"x-amz-mp-parts-count\"\n\tXAmzMetadataDirective           = \"x-amz-metadata-directive\"\n\tXAmzBucketRegion                = \"x-amz-bucket-region\"\n\tXAmzStorageClass                = \"x-amz-storage-class\"\n\tXAmzTaggingCount                = \"x-amz-tagging-count\"\n\tXAmzContentSha256               = \"X-Amz-Content-Sha256\"\n\tXAmzCredential                  = \"X-Amz-Credential\"\n\tXAmzSignature                   = \"X-Amz-Signature\"\n\tXAmzSignedHeaders               = \"X-Amz-SignedHeaders\"\n\tXAmzAlgorithm                   = \"X-Amz-Algorithm\"\n\tXAmzDate                        = \"X-Amz-Date\"\n\tXAmzExpires                     = \"X-Amz-Expires\"\n\tXAmzSecurityToken               = \"X-Amz-Security-Token\"\n\tXAmzObjectLockMode              = \"X-Amz-Object-Lock-Mode\"\n\tXAmzObjectLockRetainUntilDate   = \"X-Amz-Object-Lock-Retain-Until-Date\"\n\n\tHeaderNameXAmzDecodedContentLength = \"x-amz-decoded-content-length\"\n)\n\nconst (\n\tValueServer               = \"CubeFS\"\n\tValueAcceptRanges         = \"bytes\"\n\tValueContentTypeStream    = \"application/octet-stream\"\n\tValueContentTypeXML       = \"application/xml\"\n\tValueContentTypeJSON      = \"application/json\"\n\tValueContentTypeDirectory = \"application/directory\"\n\tValueMultipartFormData    = \"multipart/form-data\"\n)\n\nconst (\n\tSubObjectDelete    = \"delete\"\n\tSubMultipartUpload = \"uploads\"\n)\n\nconst (\n\tParamUploadId   = \"uploadId\"\n\tParamPartNumber = \"partNumber\"\n\tParamKeyMarker  = \"key-marker\"\n\tParamMarker     = \"marker\"\n\tParamPrefix     = \"prefix\"\n\tParamContToken  = \"continuation-token\"\n\tParamFetchOwner = \"fetch-owner\"\n\tParamMaxKeys    = \"max-keys\"\n\tParamStartAfter = \"start-after\"\n\tParamKey        = \"key\"\n\n\tParamMaxParts       = \"max-parts\"\n\tParamUploadIdMarker = \"upload-id-marker\"\n\tParamPartNoMarker   = \"part-number-marker\"\n\tParamPartMaxUploads = \"max-uploads\"\n\tParamPartDelimiter  = \"delimiter\"\n\tParamEncodingType   = \"encoding-type\"\n\n\tParamResponseCacheControl       = \"response-cache-control\"\n\tParamResponseContentType        = \"response-content-type\"\n\tParamResponseContentDisposition = \"response-content-disposition\"\n\tParamResponseExpires            = \"response-expires\"\n)\n\nconst (\n\tMaxKeys        = 1000\n\tMaxParts       = 1000\n\tMaxUploads     = 1000\n\tSinglePutLimit = 5 * 1 << 30 // 5G\n\tBodyLimit      = 1 << 20\n)\n\nconst (\n\tStorageClassStandard = \"STANDARD\"\n)\n\n// XAttr keys for ObjectNode compatible feature\nconst (\n\tXAttrKeyOSSPrefix       = \"oss:\"\n\tXAttrKeyOSSETag         = \"oss:etag\"\n\tXAttrKeyOSSTagging      = \"oss:tagging\"\n\tXAttrKeyOSSPolicy       = \"oss:policy\"\n\tXAttrKeyOSSACL          = \"oss:acl\"\n\tXAttrKeyOSSMIME         = \"oss:mime\"\n\tXAttrKeyOSSDISPOSITION  = \"oss:disposition\"\n\tXAttrKeyOSSCORS         = \"oss:cors\"\n\tXAttrKeyOSSLock         = \"oss:lock\"\n\tXAttrKeyOSSCacheControl = \"oss:cache\"\n\tXAttrKeyOSSExpires      = \"oss:expires\"\n\n\t// Deprecated\n\tXAttrKeyOSSETagDeprecated = \"oss:tag\"\n)\n\nconst (\n\tDateLayout              = \"20060102\"\n\tISO8601Format           = \"20060102T150405Z\"\n\tISO8601Layout           = \"2006-01-02T15:04:05.000Z\"\n\tISO8601LayoutCompatible = \"2006-01-02T15:04:05Z\"\n\tRFC1123Format           = \"Mon, 02 Jan 2006 15:04:05 GMT\"\n)\n\nconst (\n\tEmptyContentMD5String = \"d41d8cd98f00b204e9800998ecf8427e\"\n)\n\nconst (\n\tDefaultFileMode = 0644\n\tDefaultDirMode  = DefaultFileMode | os.ModeDir\n)\n\nconst (\n\tSplitFileRangeBlockSize     = 10 * 1024 * 1024 // 10MB\n\tParallelDownloadPartSize    = 10 * 1024 * 1024\n\tMinParallelDownloadFileSize = 2 * ParallelDownloadPartSize\n)\n\nconst (\n\tMaxCopyObjectSize = 5 * 1024 * 1024 * 1024\n)\n\nconst (\n\tMetadataDirectiveCopy    = \"COPY\"\n\tMetadataDirectiveReplace = \"REPLACE\"\n)\n\nconst (\n\tTaggingCounts         = 10\n\tTaggingKeyMaxLength   = 128\n\tTaggingValueMaxLength = 256\n)\n", "// Copyright 2023 The CubeFS Authors.\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n// implied. See the License for the specific language governing\n// permissions and limitations under the License.\n\npackage objectnode\n\nimport (\n\t\"encoding/xml\"\n\t\"io\"\n\t\"io/ioutil\"\n\t\"net/http\"\n\n\t\"github.com/cubefs/cubefs/proto\"\n\t\"github.com/cubefs/cubefs/util/log\"\n)\n\n// API reference: https://docs.aws.amazon.com/zh_cn/AmazonS3/latest/API/API_GetBucketLifecycleConfiguration.html\nfunc (o *ObjectNode) getBucketLifecycleConfigurationHandler(w http.ResponseWriter, r *http.Request) {\n\tvar err error\n\tvar errorCode *ErrorCode\n\n\tdefer func() {\n\t\to.errorResponse(w, r, err, errorCode)\n\t}()\n\n\tvar param = ParseRequestParam(r)\n\tif param.Bucket() == \"\" {\n\t\terrorCode = InvalidBucketName\n\t\treturn\n\t}\n\tif _, err = o.vm.Volume(param.Bucket()); err != nil {\n\t\terrorCode = NoSuchBucket\n\t\treturn\n\t}\n\n\tvar lcConf *proto.LcConfiguration\n\tif lcConf, err = o.mc.AdminAPI().GetBucketLifecycle(param.Bucket()); err != nil {\n\t\tlog.LogErrorf(\"getBucketLifecycle failed: bucket[%v] err(%v)\", param.Bucket(), err)\n\t\terrorCode = NoSuchLifecycleConfiguration\n\t\treturn\n\t}\n\n\tvar lifeCycle = NewLifeCycle()\n\tlifeCycle.Rules = make([]*Rule, 0)\n\tfor _, lc := range lcConf.Rules {\n\t\trule := &Rule{\n\t\t\tID:     lc.ID,\n\t\t\tStatus: lc.Status,\n\t\t}\n\t\tif lc.Expire != nil {\n\t\t\trule.Expire = &Expiration{}\n\t\t\tif lc.Expire.Date != nil {\n\t\t\t\trule.Expire.Date = lc.Expire.Date\n\t\t\t}\n\t\t\tif lc.Expire.Days != 0 {\n\t\t\t\trule.Expire.Days = &lc.Expire.Days\n\t\t\t}\n\t\t}\n\t\tif lc.Filter != nil {\n\t\t\trule.Filter = &Filter{\n\t\t\t\tPrefix: lc.Filter.Prefix,\n\t\t\t}\n\t\t}\n\t\tlifeCycle.Rules = append(lifeCycle.Rules, rule)\n\t}\n\n\tvar data []byte\n\tdata, err = xml.Marshal(lifeCycle)\n\tif err != nil {\n\t\tlog.LogErrorf(\"getBucketLifecycle failed: bucket[%v] err(%v)\", param.Bucket(), err)\n\t\terrorCode = NoSuchLifecycleConfiguration\n\t\treturn\n\t}\n\n\twriteSuccessResponseXML(w, data)\n\treturn\n\n}\n\n// API reference: https://docs.aws.amazon.com/zh_cn/AmazonS3/latest/API/API_PutBucketLifecycleConfiguration.html\nfunc (o *ObjectNode) putBucketLifecycleConfigurationHandler(w http.ResponseWriter, r *http.Request) {\n\tvar err error\n\tvar errorCode *ErrorCode\n\n\tdefer func() {\n\t\to.errorResponse(w, r, err, errorCode)\n\t}()\n\n\tvar param = ParseRequestParam(r)\n\tif param.Bucket() == \"\" {\n\t\terrorCode = InvalidBucketName\n\t\treturn\n\t}\n\tif _, err = o.vm.Volume(param.Bucket()); err != nil {\n\t\terrorCode = NoSuchBucket\n\t\treturn\n\t}\n\n\t_, errorCode = VerifyContentLength(r, BodyLimit)\n\tif errorCode != nil {\n\t\treturn\n\t}\n\tvar requestBody []byte\n\tif requestBody, err = ioutil.ReadAll(r.Body); err != nil && err != io.EOF {\n\t\tlog.LogErrorf(\"putBucketLifecycle failed: read request body data err: requestID(%v) err(%v)\", GetRequestID(r), err)\n\t\terrorCode = &ErrorCode{\n\t\t\tErrorCode:    http.StatusText(http.StatusBadRequest),\n\t\t\tErrorMessage: err.Error(),\n\t\t\tStatusCode:   http.StatusBadRequest,\n\t\t}\n\t\treturn\n\t}\n\n\tvar lifeCycle = NewLifeCycle()\n\tif err = UnmarshalXMLEntity(requestBody, lifeCycle); err != nil {\n\t\tlog.LogWarnf(\"putBucketLifecycle failed: decode request body err: requestID(%v) err(%v)\", GetRequestID(r), err)\n\t\terrorCode = LifeCycleErrMalformedXML\n\t\treturn\n\t}\n\n\tok, errorCode := lifeCycle.Validate()\n\tif !ok {\n\t\tlog.LogErrorf(\"putBucketLifecycle failed: validate err: requestID(%v) lifeCycle(%v) err(%v)\", GetRequestID(r), lifeCycle, errorCode)\n\t\treturn\n\t}\n\n\treq := proto.LcConfiguration{\n\t\tVolName: param.Bucket(),\n\t\tRules:   make([]*proto.Rule, 0),\n\t}\n\n\tfor _, lr := range lifeCycle.Rules {\n\t\trule := &proto.Rule{\n\t\t\tID:     lr.ID,\n\t\t\tStatus: lr.Status,\n\t\t}\n\t\tif lr.Expire != nil {\n\t\t\trule.Expire = &proto.ExpirationConfig{}\n\t\t\tif lr.Expire.Date != nil {\n\t\t\t\trule.Expire.Date = lr.Expire.Date\n\t\t\t}\n\t\t\tif lr.Expire.Days != nil {\n\t\t\t\trule.Expire.Days = *lr.Expire.Days\n\t\t\t}\n\t\t}\n\t\tif lr.Filter != nil {\n\t\t\trule.Filter = &proto.FilterConfig{\n\t\t\t\tPrefix: lr.Filter.Prefix,\n\t\t\t}\n\t\t}\n\t\treq.Rules = append(req.Rules, rule)\n\t}\n\n\tif err = o.mc.AdminAPI().SetBucketLifecycle(&req); err != nil {\n\t\tlog.LogErrorf(\"putBucketLifecycle failed: SetBucketLifecycle err: bucket[%v] err(%v)\", param.Bucket(), err)\n\t\treturn\n\t}\n\n\tlog.LogInfof(\"putBucketLifecycle success: requestID(%v) volume(%v) lifeCycle(%v)\",\n\t\tGetRequestID(r), param.Bucket(), lifeCycle)\n}\n\n// API reference: https://docs.aws.amazon.com/zh_cn/AmazonS3/latest/API/API_DeleteBucketLifecycle.html\nfunc (o *ObjectNode) deleteBucketLifecycleConfigurationHandler(w http.ResponseWriter, r *http.Request) {\n\tvar err error\n\tvar errorCode *ErrorCode\n\n\tdefer func() {\n\t\to.errorResponse(w, r, err, errorCode)\n\t}()\n\n\tvar param = ParseRequestParam(r)\n\tif param.Bucket() == \"\" {\n\t\terrorCode = InvalidBucketName\n\t\treturn\n\t}\n\tif _, err = o.vm.Volume(param.Bucket()); err != nil {\n\t\terrorCode = NoSuchBucket\n\t\treturn\n\t}\n\n\tif err = o.mc.AdminAPI().DelBucketLifecycle(param.Bucket()); err != nil {\n\t\tlog.LogErrorf(\"deleteBucketLifecycle failed: bucket[%v] err(%v)\", param.Bucket(), err)\n\t\treturn\n\t}\n\tw.WriteHeader(http.StatusNoContent)\n}\n"], "filenames": ["objectnode/api_handler_bucket.go", "objectnode/api_handler_multipart.go", "objectnode/api_handler_object.go", "objectnode/const.go", "objectnode/lifecycle_handler.go"], "buggy_code_start_loc": [26, 654, 560, 135, 108], "buggy_code_end_loc": [399, 656, 1964, 135, 108], "fixing_code_start_loc": [25, 654, 560, 136, 109], "fixing_code_end_loc": [402, 659, 1994, 137, 113], "type": "CWE-770", "message": "CubeFS is an open-source cloud-native file storage system. A security vulnerability was found in CubeFS HandlerNode in versions prior to 3.3.1 that could allow authenticated users to send maliciously-crafted requests that would crash the ObjectNode and deny other users from using it. The root cause was improper handling of incoming HTTP requests that could allow an attacker to control the ammount of memory that the ObjectNode would allocate. A malicious request could make the ObjectNode allocate more memory that the machine had available, and the attacker could exhaust memory by way of a single malicious request. An attacker would need to be authenticated in order to invoke the vulnerable code with their malicious request and have permissions to delete objects. In addition, the attacker would need to know the names of existing buckets of the CubeFS deployment - otherwise the request would be rejected before it reached the vulnerable code. As such, the most likely attacker is an inside user or an attacker that has breached the account of an existing user in the cluster. The issue has been patched in v3.3.1. There is no other mitigation besides upgrading.", "other": {"cve": {"id": "CVE-2023-46738", "sourceIdentifier": "security-advisories@github.com", "published": "2024-01-03T16:15:08.470", "lastModified": "2024-01-10T16:59:52.620", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "CubeFS is an open-source cloud-native file storage system. A security vulnerability was found in CubeFS HandlerNode in versions prior to 3.3.1 that could allow authenticated users to send maliciously-crafted requests that would crash the ObjectNode and deny other users from using it. The root cause was improper handling of incoming HTTP requests that could allow an attacker to control the ammount of memory that the ObjectNode would allocate. A malicious request could make the ObjectNode allocate more memory that the machine had available, and the attacker could exhaust memory by way of a single malicious request. An attacker would need to be authenticated in order to invoke the vulnerable code with their malicious request and have permissions to delete objects. In addition, the attacker would need to know the names of existing buckets of the CubeFS deployment - otherwise the request would be rejected before it reached the vulnerable code. As such, the most likely attacker is an inside user or an attacker that has breached the account of an existing user in the cluster. The issue has been patched in v3.3.1. There is no other mitigation besides upgrading."}, {"lang": "es", "value": "CubeFS es un sistema de almacenamiento de archivos nativo de la nube de c\u00f3digo abierto. Se encontr\u00f3 una vulnerabilidad de seguridad en CubeFS HandlerNode en versiones anteriores a la 3.3.1 que podr\u00eda permitir a los usuarios autenticados enviar solicitudes manipuladas con fines malintencionados que bloquear\u00edan el ObjectNode y negar\u00edan a otros usuarios su uso. La causa principal fue el manejo inadecuado de las solicitudes HTTP entrantes que podr\u00edan permitir a un atacante controlar la cantidad de memoria que asignar\u00eda el ObjectNode. Una solicitud maliciosa podr\u00eda hacer que el ObjectNode asigne m\u00e1s memoria de la que la m\u00e1quina ten\u00eda disponible, y el atacante podr\u00eda agotar la memoria mediante una \u00fanica solicitud maliciosa. Un atacante necesitar\u00eda estar autenticado para poder invocar el c\u00f3digo vulnerable con su solicitud maliciosa y tener permisos para eliminar objetos. Adem\u00e1s, el atacante necesitar\u00eda conocer los nombres de los dep\u00f3sitos existentes de la implementaci\u00f3n de CubeFS; de lo contrario, la solicitud ser\u00eda rechazada antes de llegar al c\u00f3digo vulnerable. Como tal, el atacante m\u00e1s probable es un usuario interno o un atacante que ha violado la cuenta de un usuario existente en el cl\u00faster. El problema se solucion\u00f3 en la versi\u00f3n 3.3.1. No existe otra mitigaci\u00f3n adem\u00e1s de la actualizaci\u00f3n."}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:N/I:N/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 6.5, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 2.8, "impactScore": 3.6}, {"source": "security-advisories@github.com", "type": "Secondary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:N/I:N/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 6.5, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 2.8, "impactScore": 3.6}]}, "weaknesses": [{"source": "security-advisories@github.com", "type": "Primary", "description": [{"lang": "en", "value": "CWE-770"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:linuxfoundation:cubefs:*:*:*:*:*:*:*:*", "versionEndExcluding": "3.3.1", "matchCriteriaId": "6E8D59D8-6863-4398-9D77-2442BAF81108"}]}]}], "references": [{"url": "https://github.com/cubefs/cubefs/commit/dd46c24873c8f3df48d0a598b704ef9bd24b1ec1", "source": "security-advisories@github.com", "tags": ["Patch"]}, {"url": "https://github.com/cubefs/cubefs/security/advisories/GHSA-qc6v-g3xw-grmx", "source": "security-advisories@github.com", "tags": ["Third Party Advisory"]}]}, "github_commit_url": "https://github.com/cubefs/cubefs/commit/dd46c24873c8f3df48d0a598b704ef9bd24b1ec1"}}
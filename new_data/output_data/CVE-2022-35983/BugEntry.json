{"buggy_code": ["/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n\n#include \"tensorflow/core/util/tensor_slice_writer.h\"\n\n#include <utility>\n\n#include \"tensorflow/core/framework/versions.pb.h\"\n#include \"tensorflow/core/lib/core/errors.h\"\n#include \"tensorflow/core/lib/io/table_builder.h\"\n#include \"tensorflow/core/lib/random/random.h\"\n#include \"tensorflow/core/lib/strings/strcat.h\"\n#include \"tensorflow/core/platform/env.h\"\n#include \"tensorflow/core/platform/logging.h\"\n#include \"tensorflow/core/public/version.h\"\n#include \"tensorflow/core/util/saved_tensor_slice_util.h\"\n\nnamespace tensorflow {\n\nnamespace checkpoint {\n\nnamespace {\n\nclass TableBuilder : public TensorSliceWriter::Builder {\n public:\n  TableBuilder(const string& name, WritableFile* f) : name_(name), file_(f) {\n    table::Options option;\n    option.compression = table::kNoCompression;\n    builder_.reset(new table::TableBuilder(option, f));\n  }\n  void Add(StringPiece key, StringPiece val) override {\n    builder_->Add(key, val);\n  }\n  Status Finish(int64_t* file_size) override {\n    *file_size = -1;\n    Status s = builder_->Finish();\n    if (s.ok()) {\n      s = file_->Close();\n      if (s.ok()) {\n        *file_size = builder_->FileSize();\n      }\n    }\n    if (!s.ok()) {\n      s = errors::Internal(\"Error writing (tmp) checkpoint file: \", name_, \": \",\n                           s.error_message());\n    }\n    builder_.reset();\n    file_.reset();\n    return s;\n  }\n\n private:\n  string name_;\n  std::unique_ptr<WritableFile> file_;\n  std::unique_ptr<table::TableBuilder> builder_;\n};\n}  // anonymous namespace\n\nStatus CreateTableTensorSliceBuilder(const string& name,\n                                     TensorSliceWriter::Builder** builder) {\n  *builder = nullptr;\n  std::unique_ptr<WritableFile> f;\n  Status s = Env::Default()->NewWritableFile(name, &f);\n  if (s.ok()) {\n    *builder = new TableBuilder(name, f.release());\n    return OkStatus();\n  } else {\n    return s;\n  }\n}\n\nTensorSliceWriter::TensorSliceWriter(const string& filename,\n                                     CreateBuilderFunction create_builder)\n    : filename_(filename),\n      create_builder_(std::move(create_builder)),\n      tmpname_(strings::StrCat(filename, \".tempstate\", random::New64())),\n      slices_(0) {\n  VersionDef* versions = sts_.mutable_meta()->mutable_versions();\n  versions->set_producer(TF_CHECKPOINT_VERSION);\n  versions->set_min_consumer(TF_CHECKPOINT_VERSION_MIN_CONSUMER);\n}\n\nStatus TensorSliceWriter::Finish() {\n  Builder* b;\n  Status s = create_builder_(tmpname_, &b);\n  if (!s.ok()) {\n    delete b;\n    return s;\n  }\n  std::unique_ptr<Builder> builder(b);\n\n  // We save the saved tensor slice metadata as the first element.\n  string meta;\n  sts_.AppendToString(&meta);\n  builder->Add(kSavedTensorSlicesKey, meta);\n\n  // Go through all the data and add them\n  for (const auto& x : data_) {\n    builder->Add(x.first, x.second);\n  }\n\n  int64_t file_size;\n  s = builder->Finish(&file_size);\n  // We need to rename the file to the proper name\n  if (s.ok()) {\n    s = Env::Default()->RenameFile(tmpname_, filename_);\n    if (s.ok()) {\n      VLOG(1) << \"Written \" << slices_ << \" slices for \"\n              << sts_.meta().tensor_size() << \" tensors (\" << file_size\n              << \" bytes) to \" << filename_;\n    } else {\n      LOG(ERROR) << \"Failed to rename file \" << tmpname_ << \" to \" << filename_;\n    }\n  } else {\n    Env::Default()->DeleteFile(tmpname_).IgnoreError();\n  }\n  return s;\n}\n\n/* static */\nsize_t TensorSliceWriter::MaxBytesPerElement(DataType dt) {\n  switch (dt) {\n    case DT_FLOAT:\n      return 4;\n    case DT_DOUBLE:\n      return 8;\n    case DT_INT32:\n      return 10;\n    case DT_UINT8:\n      return 2;\n    case DT_INT16:\n      return 10;\n    case DT_INT8:\n      return 10;\n    case DT_COMPLEX64:\n      return 8;\n    case DT_INT64:\n      return 10;\n    case DT_BOOL:\n      return 1;\n    case DT_QINT8:\n      return 10;\n    case DT_QUINT8:\n      return 2;\n    case DT_QINT32:\n      return 10;\n    case DT_QINT16:\n      return 10;\n    case DT_QUINT16:\n      return 3;\n    case DT_UINT16:\n      return 3;\n    case DT_COMPLEX128:\n      return 16;\n    case DT_HALF:\n      return 3;\n    case DT_INVALID:\n    case DT_STRING:\n    case DT_BFLOAT16:\n    default:\n      LOG(FATAL) << \"MaxBytesPerElement not implemented for dtype: \" << dt;\n  }\n  return 0;\n}\n\ntemplate <>\nStatus TensorSliceWriter::SaveData(const tstring* data, int64_t num_elements,\n                                   SavedSlice* ss) {\n  size_t size_bound = ss->ByteSize() + kTensorProtoHeaderBytes +\n                      (num_elements * MaxBytesPerElement(DT_INT32));\n  for (int64_t i = 0; i < num_elements; ++i) {\n    size_bound += data[i].size();\n  }\n  if (size_bound > kMaxMessageBytes) {\n    return errors::InvalidArgument(\n        \"Tensor slice is too large to serialize (conservative estimate: \",\n        size_bound, \" bytes)\");\n  }\n  Fill(data, num_elements, ss->mutable_data());\n  DCHECK_GE(ss->ByteSize(), 0);\n  DCHECK_LE(ss->ByteSize(), size_bound);\n  return OkStatus();\n}\n\n}  // namespace checkpoint\n\n}  // namespace tensorflow\n", "/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n\n// The utility to write checkpoints for google brain tensor ops and v3\n// checkpoints for dist_belief.\n\n#ifndef TENSORFLOW_CORE_UTIL_TENSOR_SLICE_WRITER_H_\n#define TENSORFLOW_CORE_UTIL_TENSOR_SLICE_WRITER_H_\n\n#include <unordered_map>\n\n#include \"tensorflow/core/framework/tensor_shape.h\"\n#include \"tensorflow/core/framework/tensor_slice.h\"\n#include \"tensorflow/core/framework/types.h\"\n#include \"tensorflow/core/lib/core/errors.h\"\n#include \"tensorflow/core/lib/core/status.h\"\n#include \"tensorflow/core/lib/core/stringpiece.h\"\n#include \"tensorflow/core/lib/gtl/map_util.h\"\n#include \"tensorflow/core/lib/strings/stringprintf.h\"\n#include \"tensorflow/core/platform/logging.h\"\n#include \"tensorflow/core/platform/macros.h\"\n#include \"tensorflow/core/platform/types.h\"\n#include \"tensorflow/core/util/saved_tensor_slice.pb.h\"\n#include \"tensorflow/core/util/saved_tensor_slice_util.h\"\n\nnamespace tensorflow {\n\nnamespace checkpoint {\n\nclass TensorSliceWriter {\n public:\n  // Abstract interface that TensorSliceWriter uses for building\n  class Builder {\n   public:\n    virtual ~Builder() {}\n    virtual void Add(StringPiece key, StringPiece value) = 0;\n    virtual Status Finish(int64_t* file_size) = 0;\n  };\n  typedef std::function<Status(const string&, Builder**)> CreateBuilderFunction;\n\n  TensorSliceWriter(const string& filename,\n                    CreateBuilderFunction create_builder);\n  virtual ~TensorSliceWriter() {}\n  // Adds a slice. We support float and int32 for now.\n  // TODO(yangke): add more supports\n  template <typename T>\n  Status Add(const string& name, const TensorShape& shape,\n             const TensorSlice& slice, const T* data);\n  Status Finish();\n\n  // Allocate \"num_elements\" elements in \"ss\" and save the data in \"data\"\n  // there.\n  template <typename T>\n  static Status SaveData(const T* data, int64_t num_elements, SavedSlice* ss);\n\n  static size_t MaxBytesPerElement(DataType dt);\n\n private:\n  static constexpr size_t kMaxMessageBytes = 1LL << 31;\n  // Filling in the TensorProto in a SavedSlice will add the following\n  // header bytes, in addition to the data:\n  // - 1 byte: TensorProto tag and wire format\n  // - <= 5 bytes: TensorProto length\n  // - 1 byte: Repeated *_val tag and wire format\n  // - <= 5 bytes: *_val length\n  // However, we add 1KB of slack, to be conservative and guard\n  // against other additions to the TensorProto.\n  static constexpr size_t kTensorProtoHeaderBytes = 1 << 10;\n\n  const string filename_;\n  const CreateBuilderFunction create_builder_;\n  const string tmpname_;\n\n  // A mapping from the tensor names to their index in meta_.saved_slice_meta()\n  std::unordered_map<string, int> name_to_index_;\n  // The metadata that holds all the saved tensor slices.\n  SavedTensorSlices sts_;\n  // The data to be written to the builder\n  std::map<string, string> data_;\n  // Total number of slices written\n  int slices_;\n  TF_DISALLOW_COPY_AND_ASSIGN(TensorSliceWriter);\n};\n\ntemplate <typename T>\nStatus TensorSliceWriter::Add(const string& name, const TensorShape& shape,\n                              const TensorSlice& slice, const T* data) {\n  // The tensor and the slice have to be compatible\n  if (shape.dims() != slice.dims()) {\n    return errors::Internal(\"Incompatible tensor shape and slice: \", \"shape = \",\n                            shape.DebugString(),\n                            \", slice = \", slice.DebugString());\n  }\n  DataType dt = DataTypeToEnum<T>::value;\n  // We need to add an entry for \"name\" if there isn't an entry already.\n  int index = gtl::FindWithDefault(name_to_index_, name, -1);\n  if (index >= 0) {\n    // The same tensor has been registered -- we verify that the shapes and the\n    // type agree.\n    const SavedSliceMeta& ssm = sts_.meta().tensor(index);\n    CHECK_EQ(name, ssm.name()) << ssm.ShortDebugString();\n    TensorShape ssm_shape(ssm.shape());\n    if (!shape.IsSameSize(ssm_shape)) {\n      return errors::Internal(\n          \"Mismatching shapes: existing tensor = \", ssm_shape.DebugString(),\n          \", trying to add name \", name, \", shape = \", shape.DebugString());\n    }\n    if (dt != ssm.type()) {\n      return errors::Internal(\n          \"Mismatching types: existing type = \", DataTypeString(ssm.type()),\n          \", trying to add name \", name, \", type = \", DataTypeString(dt));\n    }\n  } else {\n    // Insert the new tensor name with the shape information\n    index = sts_.meta().tensor_size();\n    name_to_index_.insert(std::make_pair(name, index));\n    SavedSliceMeta* ssm = sts_.mutable_meta()->add_tensor();\n    ssm->set_name(name);\n    shape.AsProto(ssm->mutable_shape());\n    ssm->set_type(dt);\n  }\n  // Now we need to add the slice info the list of slices.\n  SavedSliceMeta* ssm = sts_.mutable_meta()->mutable_tensor(index);\n  slice.AsProto(ssm->add_slice());\n\n  // Now we need to add the real data.\n  {\n    SavedTensorSlices sts;\n    SavedSlice* ss = sts.mutable_data();\n    ss->set_name(name);\n    slice.AsProto(ss->mutable_slice());\n    TensorShape saved_shape(ssm->shape());\n    TensorShape sliced_shape;\n    TF_RETURN_IF_ERROR(slice.SliceTensorShape(saved_shape, &sliced_shape));\n    TF_RETURN_IF_ERROR(SaveData(data, sliced_shape.num_elements(), ss));\n    string key = EncodeTensorNameSlice(name, slice);\n    // TODO(yangke): consider doing a two-pass thing where the first pass just\n    // list the tensor slices we want to save and then another pass to actually\n    // set the data. Need to figure out if the interface works well.\n    std::pair<string, string> key_value(key, \"\");\n    if (!sts.AppendToString(&key_value.second)) {\n      return errors::Internal(\"Error writing Tensor. Possible size overflow.\");\n    }\n    data_.insert(key_value);\n  }\n  ++slices_;\n  return OkStatus();\n}\n\ntemplate <typename T>\nStatus TensorSliceWriter::SaveData(const T* data, int64_t num_elements,\n                                   SavedSlice* ss) {\n  size_t size_bound =\n      ss->ByteSize() + kTensorProtoHeaderBytes +\n      (MaxBytesPerElement(DataTypeToEnum<T>::value) * num_elements);\n  if (size_bound > kMaxMessageBytes) {\n    return errors::InvalidArgument(\n        \"Tensor slice is too large to serialize (conservative estimate: \",\n        size_bound, \" bytes)\");\n  }\n  Fill(data, num_elements, ss->mutable_data());\n  DCHECK_GE(ss->ByteSize(), 0);\n  DCHECK_LE(ss->ByteSize(), size_bound);\n  return OkStatus();\n}\n\ntemplate <>\nStatus TensorSliceWriter::SaveData(const tstring* data, int64_t num_elements,\n                                   SavedSlice* ss);\n\n// Create a table builder that will write to \"filename\" in\n// tensorflow::io::Table format.  If successful, return OK\n// and set \"*builder\" to the allocated builder.  Otherwise, return a\n// non-OK status.\nStatus CreateTableTensorSliceBuilder(const string& filename,\n                                     TensorSliceWriter::Builder** builder);\n\n}  // namespace checkpoint\n\n}  // namespace tensorflow\n\n#endif  // TENSORFLOW_CORE_UTIL_TENSOR_SLICE_WRITER_H_\n", "/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n\n#include \"tensorflow/core/util/tensor_slice_writer.h\"\n\n#include <array>\n\n#include \"tensorflow/core/framework/tensor_shape.pb.h\"\n#include \"tensorflow/core/framework/versions.pb.h\"\n#include \"tensorflow/core/lib/core/status_test_util.h\"\n#include \"tensorflow/core/lib/core/stringpiece.h\"\n#include \"tensorflow/core/lib/io/path.h\"\n#include \"tensorflow/core/lib/strings/str_util.h\"\n#include \"tensorflow/core/platform/logging.h\"\n#include \"tensorflow/core/platform/protobuf.h\"\n#include \"tensorflow/core/platform/test.h\"\n#include \"tensorflow/core/public/version.h\"\n#include \"tensorflow/core/util/saved_tensor_slice_util.h\"\n#include \"tensorflow/core/util/tensor_slice_reader.h\"\n\nnamespace tensorflow {\n\nnamespace checkpoint {\n\nclass TensorSliceWriteTestHelper {\n public:\n  static void CheckEntries(const string& fname);\n  static void GetData(TensorSliceReader::Table* table, const string& name,\n                      const TensorSlice& slice, SavedSlice* ss);\n};\n\nnamespace {\n\n// Testing that an array is what is expected\nvoid ExpectIdenticalFloatArrays(const float* expected, int size,\n                                const float* actual) {\n  // TODO(yangke): copy some of the Dump* functions over\n  //  LOG(INFO) << \"Expected = \" << DumpFloatArray(expected, size);\n  //  LOG(INFO) << \"Actual   = \" << DumpFloatArray(actual, size);\n  for (int i = 0; i < size; ++i) {\n    EXPECT_NEAR(expected[i], actual[i], 1e-6);\n  }\n}\n\ntemplate <typename T, typename U>\nvoid ExpectIdenticalIntArrays(const T* expected, int size, const U* actual) {\n  for (int i = 0; i < size; ++i) {\n    EXPECT_EQ(expected[i], static_cast<T>(actual[i]));\n  }\n}\n\n// Nifty routine to get the size of an array\ntemplate <typename T, unsigned SIZE>\ninline size_t ArraySize(const T (&v)[SIZE]) {\n  return SIZE;\n}\n\n// A simple test on writing a few tensor slices\n// TODO(yangke): refactor into smaller tests: will do as we add more stuff to\n// the writer.\nTEST(TensorSliceWriteTest, SimpleWrite) {\n  const string filename = io::JoinPath(testing::TmpDir(), \"checkpoint\");\n\n  TensorSliceWriter writer(filename, CreateTableTensorSliceBuilder);\n\n  // Add some int32 tensor slices\n  {\n    TensorShape shape({5, 10});\n    TensorSlice slice = TensorSlice::ParseOrDie(\"-:0,1\");\n    const int32 data[] = {0, 1, 2, 3, 4};\n    TF_CHECK_OK(writer.Add(\"test\", shape, slice, data));\n  }\n\n  // Two slices share the same tensor name\n  {\n    TensorShape shape({5, 10});\n    TensorSlice slice = TensorSlice::ParseOrDie(\"-:3,1\");\n    const int32 data[] = {10, 11, 12, 13, 14};\n    TF_CHECK_OK(writer.Add(\"test\", shape, slice, data));\n  }\n\n  // Another slice from a different float tensor -- it has a different name and\n  // should be inserted in front of the previous tensor\n  {\n    TensorShape shape({3, 2});\n    TensorSlice slice = TensorSlice::ParseOrDie(\"-:-\");\n    const float data[] = {1.2, 1.3, 1.4, 2.1, 2.2, 2.3};\n    TF_CHECK_OK(writer.Add(\"AA\", shape, slice, data));\n  }\n\n  // A slice with int64 data\n  {\n    TensorShape shape({5, 10});\n    TensorSlice slice = TensorSlice::ParseOrDie(\"-:3,1\");\n    const int64_t data[] = {10, 11, 12, 13, 14};\n    TF_CHECK_OK(writer.Add(\"int64\", shape, slice, data));\n  }\n\n  // A slice with int16 data\n  {\n    TensorShape shape({5, 10});\n    TensorSlice slice = TensorSlice::ParseOrDie(\"-:3,1\");\n    const int16 data[] = {10, 11, 12, 13, 14};\n    TF_CHECK_OK(writer.Add(\"int16\", shape, slice, data));\n  }\n\n  TF_CHECK_OK(writer.Finish());\n\n  // Now we examine the checkpoint file manually.\n  TensorSliceWriteTestHelper::CheckEntries(filename);\n}\n\n}  // namespace\n\nvoid TensorSliceWriteTestHelper::GetData(TensorSliceReader::Table* table,\n                                         const string& name,\n                                         const TensorSlice& slice,\n                                         SavedSlice* ss) {\n  string key = EncodeTensorNameSlice(name, slice);\n  string value;\n  EXPECT_TRUE(table->Get(key, &value));\n  SavedTensorSlices sts;\n  EXPECT_TRUE(ParseProtoUnlimited(&sts, value));\n  EXPECT_FALSE(sts.has_meta());\n  *ss = sts.data();\n  EXPECT_EQ(name, ss->name());\n  TensorSlice slice2(ss->slice());\n  EXPECT_EQ(slice.DebugString(), slice2.DebugString());\n}\n\nvoid TensorSliceWriteTestHelper::CheckEntries(const string& fname) {\n  TensorSliceReader::Table* tptr;\n  TF_CHECK_OK(OpenTableTensorSliceReader(fname, &tptr));\n  std::unique_ptr<TensorSliceReader::Table> table(tptr);\n  CHECK_NOTNULL(table.get());\n\n  // We expect a block of SavedTensorSlices\n  string value;\n  ASSERT_TRUE(table->Get(kSavedTensorSlicesKey, &value));\n  {\n    SavedTensorSlices sts;\n    EXPECT_TRUE(ParseProtoUnlimited(&sts, value));\n    // We also expect two entries for the tensors\n    EXPECT_TRUE(sts.has_meta());\n    EXPECT_EQ(4, sts.meta().tensor_size());\n    // We should have written nontrivial version information\n    EXPECT_LT(0, TF_CHECKPOINT_VERSION);\n    EXPECT_EQ(TF_CHECKPOINT_VERSION, sts.meta().versions().producer());\n    EXPECT_EQ(TF_CHECKPOINT_VERSION_MIN_CONSUMER,\n              sts.meta().versions().min_consumer());\n    // We don't expect any data in the first block.\n    EXPECT_FALSE(sts.has_data());\n    // The two tensors should be stored in the same order as they are first\n    // created.\n    {\n      // The two slices of the \"test\" tensor\n      const SavedSliceMeta& ssm = sts.meta().tensor(0);\n      EXPECT_EQ(\"test\", ssm.name());\n      TensorShapeProto expected_shape_proto;\n      protobuf::TextFormat::ParseFromString(\n          \"dim { size: 5 } \"\n          \"dim { size: 10 }\",\n          &expected_shape_proto);\n      EXPECT_EQ(ssm.shape().ShortDebugString(),\n                expected_shape_proto.ShortDebugString());\n      EXPECT_EQ(DT_INT32, ssm.type());\n      EXPECT_EQ(2, ssm.slice_size());\n      TensorSlice s0(ssm.slice(0));\n      TensorSlice s1(ssm.slice(1));\n      EXPECT_EQ(\"-:0,1\", s0.DebugString());\n      EXPECT_EQ(\"-:3,1\", s1.DebugString());\n    }\n    {\n      // The \"AA\" tensor\n      const SavedSliceMeta& ssm = sts.meta().tensor(1);\n      EXPECT_EQ(\"AA\", ssm.name());\n      TensorShapeProto expected_shape_proto;\n      protobuf::TextFormat::ParseFromString(\n          \"dim { size: 3 } \"\n          \"dim { size: 2 }\",\n          &expected_shape_proto);\n      EXPECT_EQ(ssm.shape().ShortDebugString(),\n                expected_shape_proto.ShortDebugString());\n      EXPECT_EQ(DT_FLOAT, ssm.type());\n      EXPECT_EQ(1, ssm.slice_size());\n      TensorSlice s0(ssm.slice(0));\n      EXPECT_EQ(\"-:-\", s0.DebugString());\n    }\n    {\n      // The \"int64\" tensor\n      const SavedSliceMeta& ssm = sts.meta().tensor(2);\n      EXPECT_EQ(\"int64\", ssm.name());\n      TensorShapeProto expected_shape_proto;\n      protobuf::TextFormat::ParseFromString(\n          \"dim { size: 5 } \"\n          \"dim { size: 10 }\",\n          &expected_shape_proto);\n      EXPECT_EQ(ssm.shape().ShortDebugString(),\n                expected_shape_proto.ShortDebugString());\n      EXPECT_EQ(DT_INT64, ssm.type());\n      EXPECT_EQ(1, ssm.slice_size());\n      TensorSlice s0(ssm.slice(0));\n      EXPECT_EQ(\"-:3,1\", s0.DebugString());\n    }\n    {\n      // The \"int16\" tensor\n      const SavedSliceMeta& ssm = sts.meta().tensor(3);\n      EXPECT_EQ(\"int16\", ssm.name());\n      TensorShapeProto expected_shape_proto;\n      protobuf::TextFormat::ParseFromString(\n          \"dim { size: 5 } \"\n          \"dim { size: 10 }\",\n          &expected_shape_proto);\n      EXPECT_EQ(ssm.shape().ShortDebugString(),\n                expected_shape_proto.ShortDebugString());\n      EXPECT_EQ(DT_INT16, ssm.type());\n      EXPECT_EQ(1, ssm.slice_size());\n      TensorSlice s0(ssm.slice(0));\n      EXPECT_EQ(\"-:3,1\", s0.DebugString());\n    }\n  }\n\n  // We expect 5 blocks of tensor data\n  {\n    // Block 1: we expect it to be the full slice of the \"AA\" tensor\n    SavedSlice ss;\n    GetData(table.get(), \"AA\", TensorSlice(2), &ss);\n    const float data[] = {1.2, 1.3, 1.4, 2.1, 2.2, 2.3};\n    EXPECT_EQ(ArraySize(data), ss.data().float_val_size());\n    ExpectIdenticalFloatArrays(data, ArraySize(data),\n                               ss.data().float_val().data());\n  }\n\n  {\n    // Block 2: we expect it to be the first slice of the \"test\" tensor\n    SavedSlice ss;\n    GetData(table.get(), \"test\", TensorSlice({{0, -1}, {0, 1}}), &ss);\n    const int32 data[] = {0, 1, 2, 3, 4};\n    EXPECT_EQ(ArraySize(data), ss.data().int_val_size());\n    ExpectIdenticalIntArrays(data, ArraySize(data), ss.data().int_val().data());\n  }\n\n  {\n    // Block 3: we expect it to be the second slice of the \"test\" tensor\n    SavedSlice ss;\n    GetData(table.get(), \"test\", TensorSlice({{0, -1}, {3, 1}}), &ss);\n    const int32 data[] = {10, 11, 12, 13, 14};\n    EXPECT_EQ(ArraySize(data), ss.data().int_val_size());\n    ExpectIdenticalIntArrays(data, ArraySize(data), ss.data().int_val().data());\n  }\n\n  {\n    // Block 4: we expect it to be the slice of the \"int64\" tensor\n    SavedSlice ss;\n    GetData(table.get(), \"int64\", TensorSlice({{0, -1}, {3, 1}}), &ss);\n    const int64_t data[] = {10, 11, 12, 13, 14};\n    EXPECT_EQ(ArraySize(data), ss.data().int64_val_size());\n    ExpectIdenticalIntArrays(data, ArraySize(data),\n                             ss.data().int64_val().data());\n  }\n\n  {\n    // Block 5: we expect it to be the slice of the \"int16\" tensor\n    SavedSlice ss;\n    GetData(table.get(), \"int16\", TensorSlice({{0, -1}, {3, 1}}), &ss);\n    const int16 data[] = {10, 11, 12, 13, 14};\n    EXPECT_EQ(ArraySize(data), ss.data().int_val_size());\n    ExpectIdenticalIntArrays(data, ArraySize(data), ss.data().int_val().data());\n  }\n}\n\ntemplate <typename DT>\nsize_t BytesPerElementHelper(DT value) {\n  SavedSlice ss;\n  std::array<DT, 1> lo_data;\n  std::fill(lo_data.begin(), lo_data.end(), value);\n  TF_EXPECT_OK(\n      TensorSliceWriter::SaveData(lo_data.data(), lo_data.size(), &ss));\n  size_t lo_byte_size = ss.ByteSizeLong();\n\n  std::array<DT, 1001> hi_data;\n  std::fill(hi_data.begin(), hi_data.end(), value);\n  TF_EXPECT_OK(\n      TensorSliceWriter::SaveData(hi_data.data(), hi_data.size(), &ss));\n  size_t hi_byte_size = ss.ByteSizeLong();\n\n  return (hi_byte_size - lo_byte_size) / (hi_data.size() - lo_data.size());\n}\n\nTEST(TensorSliceWriteTest, CheckpointSize) {\n  EXPECT_EQ(TensorSliceWriter::MaxBytesPerElement(DT_BOOL),\n            BytesPerElementHelper<bool>(false));\n  EXPECT_EQ(TensorSliceWriter::MaxBytesPerElement(DT_BOOL),\n            BytesPerElementHelper<bool>(true));\n  EXPECT_EQ(TensorSliceWriter::MaxBytesPerElement(DT_FLOAT),\n            BytesPerElementHelper<float>(-1.0));\n  EXPECT_EQ(TensorSliceWriter::MaxBytesPerElement(DT_DOUBLE),\n            BytesPerElementHelper<double>(-1.0));\n  EXPECT_EQ(TensorSliceWriter::MaxBytesPerElement(DT_COMPLEX64),\n            BytesPerElementHelper<complex64>(-1.0));\n  EXPECT_EQ(TensorSliceWriter::MaxBytesPerElement(DT_COMPLEX128),\n            BytesPerElementHelper<complex128>(-1.0));\n  EXPECT_EQ(TensorSliceWriter::MaxBytesPerElement(DT_INT32),\n            BytesPerElementHelper<int32>(-1));\n  EXPECT_EQ(TensorSliceWriter::MaxBytesPerElement(DT_INT64),\n            BytesPerElementHelper<int64_t>(-1));\n  EXPECT_EQ(TensorSliceWriter::MaxBytesPerElement(DT_UINT16),\n            BytesPerElementHelper<uint16>(std::numeric_limits<uint16>::max()));\n  EXPECT_EQ(TensorSliceWriter::MaxBytesPerElement(DT_UINT8),\n            BytesPerElementHelper<uint8>(std::numeric_limits<uint8>::max()));\n  EXPECT_EQ(TensorSliceWriter::MaxBytesPerElement(DT_INT8),\n            BytesPerElementHelper<int8>(-1));\n  EXPECT_EQ(TensorSliceWriter::MaxBytesPerElement(DT_INT16),\n            BytesPerElementHelper<int16>(-1));\n  EXPECT_EQ(TensorSliceWriter::MaxBytesPerElement(DT_QINT8),\n            BytesPerElementHelper<qint8>(-1));\n  EXPECT_EQ(TensorSliceWriter::MaxBytesPerElement(DT_QUINT8),\n            BytesPerElementHelper<quint8>(std::numeric_limits<uint8>::max()));\n  EXPECT_EQ(TensorSliceWriter::MaxBytesPerElement(DT_QINT32),\n            BytesPerElementHelper<qint32>(-1));\n  EXPECT_EQ(TensorSliceWriter::MaxBytesPerElement(DT_HALF),\n            BytesPerElementHelper<Eigen::half>(Eigen::half(-1.0)));\n}\n\nTEST(TensorSliceWriteTest, SizeErrors) {\n  const string filename = io::JoinPath(testing::TmpDir(), \"checkpoint\");\n\n  TensorSliceWriter writer(filename, CreateTableTensorSliceBuilder);\n\n  // Add a 300MB int8 tensor slice, which will fail because it expands to 3GB.\n  {\n    TensorShape shape({300, 1000000});\n    TensorSlice slice = TensorSlice::ParseOrDie(\"-:-\");\n    const std::vector<int8> data(300000000, -1);\n    Status s = writer.Add(\"test1\", shape, slice, data.data());\n    EXPECT_EQ(s.code(), error::INVALID_ARGUMENT);\n    EXPECT_TRUE(absl::StrContains(s.error_message(),\n                                  \"Tensor slice is too large to serialize\"));\n  }\n\n  // Add a large string tensor slice, which will fail.\n  {\n    TensorShape shape({256, 1024});\n    TensorSlice slice = TensorSlice::ParseOrDie(\"-:-\");\n    const std::vector<tstring> data(256 * 1024, std::string(8192, 'f'));\n    Status s = writer.Add(\"test2\", shape, slice, data.data());\n    EXPECT_EQ(s.code(), error::INVALID_ARGUMENT);\n    EXPECT_TRUE(absl::StrContains(s.error_message(),\n                                  \"Tensor slice is too large to serialize\"));\n  }\n}\n\n}  // namespace checkpoint\n\n}  // namespace tensorflow\n"], "fixing_code": ["/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n\n#include \"tensorflow/core/util/tensor_slice_writer.h\"\n\n#include <utility>\n\n#include \"tensorflow/core/framework/versions.pb.h\"\n#include \"tensorflow/core/lib/core/errors.h\"\n#include \"tensorflow/core/lib/io/table_builder.h\"\n#include \"tensorflow/core/lib/random/random.h\"\n#include \"tensorflow/core/lib/strings/strcat.h\"\n#include \"tensorflow/core/platform/env.h\"\n#include \"tensorflow/core/platform/logging.h\"\n#include \"tensorflow/core/public/version.h\"\n#include \"tensorflow/core/util/saved_tensor_slice_util.h\"\n\nnamespace tensorflow {\n\nnamespace checkpoint {\n\nnamespace {\n\nclass TableBuilder : public TensorSliceWriter::Builder {\n public:\n  TableBuilder(const string& name, WritableFile* f) : name_(name), file_(f) {\n    table::Options option;\n    option.compression = table::kNoCompression;\n    builder_.reset(new table::TableBuilder(option, f));\n  }\n  void Add(StringPiece key, StringPiece val) override {\n    builder_->Add(key, val);\n  }\n  Status Finish(int64_t* file_size) override {\n    *file_size = -1;\n    Status s = builder_->Finish();\n    if (s.ok()) {\n      s = file_->Close();\n      if (s.ok()) {\n        *file_size = builder_->FileSize();\n      }\n    }\n    if (!s.ok()) {\n      s = errors::Internal(\"Error writing (tmp) checkpoint file: \", name_, \": \",\n                           s.error_message());\n    }\n    builder_.reset();\n    file_.reset();\n    return s;\n  }\n\n private:\n  string name_;\n  std::unique_ptr<WritableFile> file_;\n  std::unique_ptr<table::TableBuilder> builder_;\n};\n}  // anonymous namespace\n\nStatus CreateTableTensorSliceBuilder(const string& name,\n                                     TensorSliceWriter::Builder** builder) {\n  *builder = nullptr;\n  std::unique_ptr<WritableFile> f;\n  Status s = Env::Default()->NewWritableFile(name, &f);\n  if (s.ok()) {\n    *builder = new TableBuilder(name, f.release());\n    return OkStatus();\n  } else {\n    return s;\n  }\n}\n\nTensorSliceWriter::TensorSliceWriter(const string& filename,\n                                     CreateBuilderFunction create_builder)\n    : filename_(filename),\n      create_builder_(std::move(create_builder)),\n      tmpname_(strings::StrCat(filename, \".tempstate\", random::New64())),\n      slices_(0) {\n  VersionDef* versions = sts_.mutable_meta()->mutable_versions();\n  versions->set_producer(TF_CHECKPOINT_VERSION);\n  versions->set_min_consumer(TF_CHECKPOINT_VERSION_MIN_CONSUMER);\n}\n\nStatus TensorSliceWriter::Finish() {\n  Builder* b;\n  Status s = create_builder_(tmpname_, &b);\n  if (!s.ok()) {\n    delete b;\n    return s;\n  }\n  std::unique_ptr<Builder> builder(b);\n\n  // We save the saved tensor slice metadata as the first element.\n  string meta;\n  sts_.AppendToString(&meta);\n  builder->Add(kSavedTensorSlicesKey, meta);\n\n  // Go through all the data and add them\n  for (const auto& x : data_) {\n    builder->Add(x.first, x.second);\n  }\n\n  int64_t file_size;\n  s = builder->Finish(&file_size);\n  // We need to rename the file to the proper name\n  if (s.ok()) {\n    s = Env::Default()->RenameFile(tmpname_, filename_);\n    if (s.ok()) {\n      VLOG(1) << \"Written \" << slices_ << \" slices for \"\n              << sts_.meta().tensor_size() << \" tensors (\" << file_size\n              << \" bytes) to \" << filename_;\n    } else {\n      LOG(ERROR) << \"Failed to rename file \" << tmpname_ << \" to \" << filename_;\n    }\n  } else {\n    Env::Default()->DeleteFile(tmpname_).IgnoreError();\n  }\n  return s;\n}\n\n/* static */\nsize_t TensorSliceWriter::MaxBytesPerElement(DataType dt) {\n  size_t max_bytes_per_element =\n      TensorSliceWriter::MaxBytesPerElementOrZero(dt);\n  if (max_bytes_per_element == 0) {\n    LOG(FATAL) << \"MaxBytesPerElement not implemented for dtype: \" << dt;\n  }\n  return max_bytes_per_element;\n}\n\n/* static */\nsize_t TensorSliceWriter::MaxBytesPerElementOrZero(DataType dt) {\n  switch (dt) {\n    case DT_FLOAT:\n      return 4;\n    case DT_DOUBLE:\n      return 8;\n    case DT_INT32:\n      return 10;\n    case DT_UINT8:\n      return 2;\n    case DT_INT16:\n      return 10;\n    case DT_INT8:\n      return 10;\n    case DT_COMPLEX64:\n      return 8;\n    case DT_INT64:\n      return 10;\n    case DT_BOOL:\n      return 1;\n    case DT_QINT8:\n      return 10;\n    case DT_QUINT8:\n      return 2;\n    case DT_QINT32:\n      return 10;\n    case DT_QINT16:\n      return 10;\n    case DT_QUINT16:\n      return 3;\n    case DT_UINT16:\n      return 3;\n    case DT_COMPLEX128:\n      return 16;\n    case DT_HALF:\n      return 3;\n    case DT_INVALID:\n    case DT_STRING:\n    case DT_BFLOAT16:\n    default:\n      return 0;\n  }\n}\n\ntemplate <>\nStatus TensorSliceWriter::SaveData(const tstring* data, int64_t num_elements,\n                                   SavedSlice* ss) {\n  size_t size_bound = ss->ByteSize() + kTensorProtoHeaderBytes +\n                      (num_elements * MaxBytesPerElement(DT_INT32));\n  for (int64_t i = 0; i < num_elements; ++i) {\n    size_bound += data[i].size();\n  }\n  if (size_bound > kMaxMessageBytes) {\n    return errors::InvalidArgument(\n        \"Tensor slice is too large to serialize (conservative estimate: \",\n        size_bound, \" bytes)\");\n  }\n  Fill(data, num_elements, ss->mutable_data());\n  DCHECK_GE(ss->ByteSize(), 0);\n  DCHECK_LE(ss->ByteSize(), size_bound);\n  return OkStatus();\n}\n\n}  // namespace checkpoint\n\n}  // namespace tensorflow\n", "/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n\n// The utility to write checkpoints for google brain tensor ops and v3\n// checkpoints for dist_belief.\n\n#ifndef TENSORFLOW_CORE_UTIL_TENSOR_SLICE_WRITER_H_\n#define TENSORFLOW_CORE_UTIL_TENSOR_SLICE_WRITER_H_\n\n#include <unordered_map>\n\n#include \"tensorflow/core/framework/tensor_shape.h\"\n#include \"tensorflow/core/framework/tensor_slice.h\"\n#include \"tensorflow/core/framework/types.h\"\n#include \"tensorflow/core/lib/core/errors.h\"\n#include \"tensorflow/core/lib/core/status.h\"\n#include \"tensorflow/core/lib/core/stringpiece.h\"\n#include \"tensorflow/core/lib/gtl/map_util.h\"\n#include \"tensorflow/core/lib/strings/stringprintf.h\"\n#include \"tensorflow/core/platform/logging.h\"\n#include \"tensorflow/core/platform/macros.h\"\n#include \"tensorflow/core/platform/types.h\"\n#include \"tensorflow/core/util/saved_tensor_slice.pb.h\"\n#include \"tensorflow/core/util/saved_tensor_slice_util.h\"\n\nnamespace tensorflow {\n\nnamespace checkpoint {\n\nclass TensorSliceWriter {\n public:\n  // Abstract interface that TensorSliceWriter uses for building\n  class Builder {\n   public:\n    virtual ~Builder() {}\n    virtual void Add(StringPiece key, StringPiece value) = 0;\n    virtual Status Finish(int64_t* file_size) = 0;\n  };\n  typedef std::function<Status(const string&, Builder**)> CreateBuilderFunction;\n\n  TensorSliceWriter(const string& filename,\n                    CreateBuilderFunction create_builder);\n  virtual ~TensorSliceWriter() {}\n  // Adds a slice. We support float and int32 for now.\n  // TODO(yangke): add more supports\n  template <typename T>\n  Status Add(const string& name, const TensorShape& shape,\n             const TensorSlice& slice, const T* data);\n  Status Finish();\n\n  // Allocate \"num_elements\" elements in \"ss\" and save the data in \"data\"\n  // there.\n  template <typename T>\n  static Status SaveData(const T* data, int64_t num_elements, SavedSlice* ss);\n\n  static size_t MaxBytesPerElement(DataType dt);\n\n private:\n  static size_t MaxBytesPerElementOrZero(DataType dt);\n\n  static constexpr size_t kMaxMessageBytes = 1LL << 31;\n  // Filling in the TensorProto in a SavedSlice will add the following\n  // header bytes, in addition to the data:\n  // - 1 byte: TensorProto tag and wire format\n  // - <= 5 bytes: TensorProto length\n  // - 1 byte: Repeated *_val tag and wire format\n  // - <= 5 bytes: *_val length\n  // However, we add 1KB of slack, to be conservative and guard\n  // against other additions to the TensorProto.\n  static constexpr size_t kTensorProtoHeaderBytes = 1 << 10;\n\n  const string filename_;\n  const CreateBuilderFunction create_builder_;\n  const string tmpname_;\n\n  // A mapping from the tensor names to their index in meta_.saved_slice_meta()\n  std::unordered_map<string, int> name_to_index_;\n  // The metadata that holds all the saved tensor slices.\n  SavedTensorSlices sts_;\n  // The data to be written to the builder\n  std::map<string, string> data_;\n  // Total number of slices written\n  int slices_;\n  TF_DISALLOW_COPY_AND_ASSIGN(TensorSliceWriter);\n};\n\ntemplate <typename T>\nStatus TensorSliceWriter::Add(const string& name, const TensorShape& shape,\n                              const TensorSlice& slice, const T* data) {\n  // The tensor and the slice have to be compatible\n  if (shape.dims() != slice.dims()) {\n    return errors::Internal(\"Incompatible tensor shape and slice: \", \"shape = \",\n                            shape.DebugString(),\n                            \", slice = \", slice.DebugString());\n  }\n  DataType dt = DataTypeToEnum<T>::value;\n  // We need to add an entry for \"name\" if there isn't an entry already.\n  int index = gtl::FindWithDefault(name_to_index_, name, -1);\n  if (index >= 0) {\n    // The same tensor has been registered -- we verify that the shapes and the\n    // type agree.\n    const SavedSliceMeta& ssm = sts_.meta().tensor(index);\n    CHECK_EQ(name, ssm.name()) << ssm.ShortDebugString();\n    TensorShape ssm_shape(ssm.shape());\n    if (!shape.IsSameSize(ssm_shape)) {\n      return errors::Internal(\n          \"Mismatching shapes: existing tensor = \", ssm_shape.DebugString(),\n          \", trying to add name \", name, \", shape = \", shape.DebugString());\n    }\n    if (dt != ssm.type()) {\n      return errors::Internal(\n          \"Mismatching types: existing type = \", DataTypeString(ssm.type()),\n          \", trying to add name \", name, \", type = \", DataTypeString(dt));\n    }\n  } else {\n    // Insert the new tensor name with the shape information\n    index = sts_.meta().tensor_size();\n    name_to_index_.insert(std::make_pair(name, index));\n    SavedSliceMeta* ssm = sts_.mutable_meta()->add_tensor();\n    ssm->set_name(name);\n    shape.AsProto(ssm->mutable_shape());\n    ssm->set_type(dt);\n  }\n  // Now we need to add the slice info the list of slices.\n  SavedSliceMeta* ssm = sts_.mutable_meta()->mutable_tensor(index);\n  slice.AsProto(ssm->add_slice());\n\n  // Now we need to add the real data.\n  {\n    SavedTensorSlices sts;\n    SavedSlice* ss = sts.mutable_data();\n    ss->set_name(name);\n    slice.AsProto(ss->mutable_slice());\n    TensorShape saved_shape(ssm->shape());\n    TensorShape sliced_shape;\n    TF_RETURN_IF_ERROR(slice.SliceTensorShape(saved_shape, &sliced_shape));\n    TF_RETURN_IF_ERROR(SaveData(data, sliced_shape.num_elements(), ss));\n    string key = EncodeTensorNameSlice(name, slice);\n    // TODO(yangke): consider doing a two-pass thing where the first pass just\n    // list the tensor slices we want to save and then another pass to actually\n    // set the data. Need to figure out if the interface works well.\n    std::pair<string, string> key_value(key, \"\");\n    if (!sts.AppendToString(&key_value.second)) {\n      return errors::Internal(\"Error writing Tensor. Possible size overflow.\");\n    }\n    data_.insert(key_value);\n  }\n  ++slices_;\n  return OkStatus();\n}\n\ntemplate <typename T>\nStatus TensorSliceWriter::SaveData(const T* data, int64_t num_elements,\n                                   SavedSlice* ss) {\n  size_t max_bytes_per_element =\n      MaxBytesPerElementOrZero(DataTypeToEnum<T>::value);\n  if (max_bytes_per_element == 0) {\n    return errors::InvalidArgument(\n        \"Tensor slice serialization not implemented for dtype \",\n        DataTypeToEnum<T>::value);\n  }\n  size_t size_bound = ss->ByteSize() + kTensorProtoHeaderBytes +\n                      (max_bytes_per_element * num_elements);\n  if (size_bound > kMaxMessageBytes) {\n    return errors::InvalidArgument(\n        \"Tensor slice is too large to serialize (conservative estimate: \",\n        size_bound, \" bytes)\");\n  }\n  Fill(data, num_elements, ss->mutable_data());\n  DCHECK_GE(ss->ByteSize(), 0);\n  DCHECK_LE(ss->ByteSize(), size_bound);\n  return OkStatus();\n}\n\ntemplate <>\nStatus TensorSliceWriter::SaveData(const tstring* data, int64_t num_elements,\n                                   SavedSlice* ss);\n\n// Create a table builder that will write to \"filename\" in\n// tensorflow::io::Table format.  If successful, return OK\n// and set \"*builder\" to the allocated builder.  Otherwise, return a\n// non-OK status.\nStatus CreateTableTensorSliceBuilder(const string& filename,\n                                     TensorSliceWriter::Builder** builder);\n\n}  // namespace checkpoint\n\n}  // namespace tensorflow\n\n#endif  // TENSORFLOW_CORE_UTIL_TENSOR_SLICE_WRITER_H_\n", "/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n\n#include \"tensorflow/core/util/tensor_slice_writer.h\"\n\n#include <algorithm>\n#include <array>\n#include <memory>\n#include <vector>\n\n#include \"tensorflow/core/framework/tensor_shape.pb.h\"\n#include \"tensorflow/core/framework/versions.pb.h\"\n#include \"tensorflow/core/lib/core/status_test_util.h\"\n#include \"tensorflow/core/platform/logging.h\"\n#include \"tensorflow/core/platform/path.h\"\n#include \"tensorflow/core/platform/protobuf.h\"\n#include \"tensorflow/core/platform/test.h\"\n#include \"tensorflow/core/protobuf/error_codes.pb.h\"\n#include \"tensorflow/core/public/version.h\"\n#include \"tensorflow/core/util/saved_tensor_slice_util.h\"\n#include \"tensorflow/core/util/tensor_slice_reader.h\"\n\nnamespace tensorflow {\n\nnamespace checkpoint {\n\nclass TensorSliceWriteTestHelper {\n public:\n  static void CheckEntries(const string& fname);\n  static void GetData(TensorSliceReader::Table* table, const string& name,\n                      const TensorSlice& slice, SavedSlice* ss);\n};\n\nnamespace {\n\n// Testing that an array is what is expected\nvoid ExpectIdenticalFloatArrays(const float* expected, int size,\n                                const float* actual) {\n  // TODO(yangke): copy some of the Dump* functions over\n  //  LOG(INFO) << \"Expected = \" << DumpFloatArray(expected, size);\n  //  LOG(INFO) << \"Actual   = \" << DumpFloatArray(actual, size);\n  for (int i = 0; i < size; ++i) {\n    EXPECT_NEAR(expected[i], actual[i], 1e-6);\n  }\n}\n\ntemplate <typename T, typename U>\nvoid ExpectIdenticalIntArrays(const T* expected, int size, const U* actual) {\n  for (int i = 0; i < size; ++i) {\n    EXPECT_EQ(expected[i], static_cast<T>(actual[i]));\n  }\n}\n\n// Nifty routine to get the size of an array\ntemplate <typename T, unsigned SIZE>\ninline size_t ArraySize(const T (&v)[SIZE]) {\n  return SIZE;\n}\n\n// A simple test on writing a few tensor slices\n// TODO(yangke): refactor into smaller tests: will do as we add more stuff to\n// the writer.\nTEST(TensorSliceWriteTest, SimpleWrite) {\n  const string filename = io::JoinPath(testing::TmpDir(), \"checkpoint\");\n\n  TensorSliceWriter writer(filename, CreateTableTensorSliceBuilder);\n\n  // Add some int32 tensor slices\n  {\n    TensorShape shape({5, 10});\n    TensorSlice slice = TensorSlice::ParseOrDie(\"-:0,1\");\n    const int32 data[] = {0, 1, 2, 3, 4};\n    TF_CHECK_OK(writer.Add(\"test\", shape, slice, data));\n  }\n\n  // Two slices share the same tensor name\n  {\n    TensorShape shape({5, 10});\n    TensorSlice slice = TensorSlice::ParseOrDie(\"-:3,1\");\n    const int32 data[] = {10, 11, 12, 13, 14};\n    TF_CHECK_OK(writer.Add(\"test\", shape, slice, data));\n  }\n\n  // Another slice from a different float tensor -- it has a different name and\n  // should be inserted in front of the previous tensor\n  {\n    TensorShape shape({3, 2});\n    TensorSlice slice = TensorSlice::ParseOrDie(\"-:-\");\n    const float data[] = {1.2, 1.3, 1.4, 2.1, 2.2, 2.3};\n    TF_CHECK_OK(writer.Add(\"AA\", shape, slice, data));\n  }\n\n  // A slice with int64 data\n  {\n    TensorShape shape({5, 10});\n    TensorSlice slice = TensorSlice::ParseOrDie(\"-:3,1\");\n    const int64_t data[] = {10, 11, 12, 13, 14};\n    TF_CHECK_OK(writer.Add(\"int64\", shape, slice, data));\n  }\n\n  // A slice with int16 data\n  {\n    TensorShape shape({5, 10});\n    TensorSlice slice = TensorSlice::ParseOrDie(\"-:3,1\");\n    const int16 data[] = {10, 11, 12, 13, 14};\n    TF_CHECK_OK(writer.Add(\"int16\", shape, slice, data));\n  }\n\n  TF_CHECK_OK(writer.Finish());\n\n  // Now we examine the checkpoint file manually.\n  TensorSliceWriteTestHelper::CheckEntries(filename);\n}\n\n}  // namespace\n\nvoid TensorSliceWriteTestHelper::GetData(TensorSliceReader::Table* table,\n                                         const string& name,\n                                         const TensorSlice& slice,\n                                         SavedSlice* ss) {\n  string key = EncodeTensorNameSlice(name, slice);\n  string value;\n  EXPECT_TRUE(table->Get(key, &value));\n  SavedTensorSlices sts;\n  EXPECT_TRUE(ParseProtoUnlimited(&sts, value));\n  EXPECT_FALSE(sts.has_meta());\n  *ss = sts.data();\n  EXPECT_EQ(name, ss->name());\n  TensorSlice slice2(ss->slice());\n  EXPECT_EQ(slice.DebugString(), slice2.DebugString());\n}\n\nvoid TensorSliceWriteTestHelper::CheckEntries(const string& fname) {\n  TensorSliceReader::Table* tptr;\n  TF_CHECK_OK(OpenTableTensorSliceReader(fname, &tptr));\n  std::unique_ptr<TensorSliceReader::Table> table(tptr);\n  CHECK_NOTNULL(table.get());\n\n  // We expect a block of SavedTensorSlices\n  string value;\n  ASSERT_TRUE(table->Get(kSavedTensorSlicesKey, &value));\n  {\n    SavedTensorSlices sts;\n    EXPECT_TRUE(ParseProtoUnlimited(&sts, value));\n    // We also expect two entries for the tensors\n    EXPECT_TRUE(sts.has_meta());\n    EXPECT_EQ(4, sts.meta().tensor_size());\n    // We should have written nontrivial version information\n    EXPECT_LT(0, TF_CHECKPOINT_VERSION);\n    EXPECT_EQ(TF_CHECKPOINT_VERSION, sts.meta().versions().producer());\n    EXPECT_EQ(TF_CHECKPOINT_VERSION_MIN_CONSUMER,\n              sts.meta().versions().min_consumer());\n    // We don't expect any data in the first block.\n    EXPECT_FALSE(sts.has_data());\n    // The two tensors should be stored in the same order as they are first\n    // created.\n    {\n      // The two slices of the \"test\" tensor\n      const SavedSliceMeta& ssm = sts.meta().tensor(0);\n      EXPECT_EQ(\"test\", ssm.name());\n      TensorShapeProto expected_shape_proto;\n      protobuf::TextFormat::ParseFromString(\n          \"dim { size: 5 } \"\n          \"dim { size: 10 }\",\n          &expected_shape_proto);\n      EXPECT_EQ(ssm.shape().ShortDebugString(),\n                expected_shape_proto.ShortDebugString());\n      EXPECT_EQ(DT_INT32, ssm.type());\n      EXPECT_EQ(2, ssm.slice_size());\n      TensorSlice s0(ssm.slice(0));\n      TensorSlice s1(ssm.slice(1));\n      EXPECT_EQ(\"-:0,1\", s0.DebugString());\n      EXPECT_EQ(\"-:3,1\", s1.DebugString());\n    }\n    {\n      // The \"AA\" tensor\n      const SavedSliceMeta& ssm = sts.meta().tensor(1);\n      EXPECT_EQ(\"AA\", ssm.name());\n      TensorShapeProto expected_shape_proto;\n      protobuf::TextFormat::ParseFromString(\n          \"dim { size: 3 } \"\n          \"dim { size: 2 }\",\n          &expected_shape_proto);\n      EXPECT_EQ(ssm.shape().ShortDebugString(),\n                expected_shape_proto.ShortDebugString());\n      EXPECT_EQ(DT_FLOAT, ssm.type());\n      EXPECT_EQ(1, ssm.slice_size());\n      TensorSlice s0(ssm.slice(0));\n      EXPECT_EQ(\"-:-\", s0.DebugString());\n    }\n    {\n      // The \"int64\" tensor\n      const SavedSliceMeta& ssm = sts.meta().tensor(2);\n      EXPECT_EQ(\"int64\", ssm.name());\n      TensorShapeProto expected_shape_proto;\n      protobuf::TextFormat::ParseFromString(\n          \"dim { size: 5 } \"\n          \"dim { size: 10 }\",\n          &expected_shape_proto);\n      EXPECT_EQ(ssm.shape().ShortDebugString(),\n                expected_shape_proto.ShortDebugString());\n      EXPECT_EQ(DT_INT64, ssm.type());\n      EXPECT_EQ(1, ssm.slice_size());\n      TensorSlice s0(ssm.slice(0));\n      EXPECT_EQ(\"-:3,1\", s0.DebugString());\n    }\n    {\n      // The \"int16\" tensor\n      const SavedSliceMeta& ssm = sts.meta().tensor(3);\n      EXPECT_EQ(\"int16\", ssm.name());\n      TensorShapeProto expected_shape_proto;\n      protobuf::TextFormat::ParseFromString(\n          \"dim { size: 5 } \"\n          \"dim { size: 10 }\",\n          &expected_shape_proto);\n      EXPECT_EQ(ssm.shape().ShortDebugString(),\n                expected_shape_proto.ShortDebugString());\n      EXPECT_EQ(DT_INT16, ssm.type());\n      EXPECT_EQ(1, ssm.slice_size());\n      TensorSlice s0(ssm.slice(0));\n      EXPECT_EQ(\"-:3,1\", s0.DebugString());\n    }\n  }\n\n  // We expect 5 blocks of tensor data\n  {\n    // Block 1: we expect it to be the full slice of the \"AA\" tensor\n    SavedSlice ss;\n    GetData(table.get(), \"AA\", TensorSlice(2), &ss);\n    const float data[] = {1.2, 1.3, 1.4, 2.1, 2.2, 2.3};\n    EXPECT_EQ(ArraySize(data), ss.data().float_val_size());\n    ExpectIdenticalFloatArrays(data, ArraySize(data),\n                               ss.data().float_val().data());\n  }\n\n  {\n    // Block 2: we expect it to be the first slice of the \"test\" tensor\n    SavedSlice ss;\n    GetData(table.get(), \"test\", TensorSlice({{0, -1}, {0, 1}}), &ss);\n    const int32 data[] = {0, 1, 2, 3, 4};\n    EXPECT_EQ(ArraySize(data), ss.data().int_val_size());\n    ExpectIdenticalIntArrays(data, ArraySize(data), ss.data().int_val().data());\n  }\n\n  {\n    // Block 3: we expect it to be the second slice of the \"test\" tensor\n    SavedSlice ss;\n    GetData(table.get(), \"test\", TensorSlice({{0, -1}, {3, 1}}), &ss);\n    const int32 data[] = {10, 11, 12, 13, 14};\n    EXPECT_EQ(ArraySize(data), ss.data().int_val_size());\n    ExpectIdenticalIntArrays(data, ArraySize(data), ss.data().int_val().data());\n  }\n\n  {\n    // Block 4: we expect it to be the slice of the \"int64\" tensor\n    SavedSlice ss;\n    GetData(table.get(), \"int64\", TensorSlice({{0, -1}, {3, 1}}), &ss);\n    const int64_t data[] = {10, 11, 12, 13, 14};\n    EXPECT_EQ(ArraySize(data), ss.data().int64_val_size());\n    ExpectIdenticalIntArrays(data, ArraySize(data),\n                             ss.data().int64_val().data());\n  }\n\n  {\n    // Block 5: we expect it to be the slice of the \"int16\" tensor\n    SavedSlice ss;\n    GetData(table.get(), \"int16\", TensorSlice({{0, -1}, {3, 1}}), &ss);\n    const int16 data[] = {10, 11, 12, 13, 14};\n    EXPECT_EQ(ArraySize(data), ss.data().int_val_size());\n    ExpectIdenticalIntArrays(data, ArraySize(data), ss.data().int_val().data());\n  }\n}\n\ntemplate <typename DT>\nsize_t BytesPerElementHelper(DT value) {\n  SavedSlice ss;\n  std::array<DT, 1> lo_data;\n  std::fill(lo_data.begin(), lo_data.end(), value);\n  TF_EXPECT_OK(\n      TensorSliceWriter::SaveData(lo_data.data(), lo_data.size(), &ss));\n  size_t lo_byte_size = ss.ByteSizeLong();\n\n  std::array<DT, 1001> hi_data;\n  std::fill(hi_data.begin(), hi_data.end(), value);\n  TF_EXPECT_OK(\n      TensorSliceWriter::SaveData(hi_data.data(), hi_data.size(), &ss));\n  size_t hi_byte_size = ss.ByteSizeLong();\n\n  return (hi_byte_size - lo_byte_size) / (hi_data.size() - lo_data.size());\n}\n\nTEST(TensorSliceWriteTest, CheckpointSize) {\n  EXPECT_EQ(TensorSliceWriter::MaxBytesPerElement(DT_BOOL),\n            BytesPerElementHelper<bool>(false));\n  EXPECT_EQ(TensorSliceWriter::MaxBytesPerElement(DT_BOOL),\n            BytesPerElementHelper<bool>(true));\n  EXPECT_EQ(TensorSliceWriter::MaxBytesPerElement(DT_FLOAT),\n            BytesPerElementHelper<float>(-1.0));\n  EXPECT_EQ(TensorSliceWriter::MaxBytesPerElement(DT_DOUBLE),\n            BytesPerElementHelper<double>(-1.0));\n  EXPECT_EQ(TensorSliceWriter::MaxBytesPerElement(DT_COMPLEX64),\n            BytesPerElementHelper<complex64>(-1.0));\n  EXPECT_EQ(TensorSliceWriter::MaxBytesPerElement(DT_COMPLEX128),\n            BytesPerElementHelper<complex128>(-1.0));\n  EXPECT_EQ(TensorSliceWriter::MaxBytesPerElement(DT_INT32),\n            BytesPerElementHelper<int32>(-1));\n  EXPECT_EQ(TensorSliceWriter::MaxBytesPerElement(DT_INT64),\n            BytesPerElementHelper<int64_t>(-1));\n  EXPECT_EQ(TensorSliceWriter::MaxBytesPerElement(DT_UINT16),\n            BytesPerElementHelper<uint16>(std::numeric_limits<uint16>::max()));\n  EXPECT_EQ(TensorSliceWriter::MaxBytesPerElement(DT_UINT8),\n            BytesPerElementHelper<uint8>(std::numeric_limits<uint8>::max()));\n  EXPECT_EQ(TensorSliceWriter::MaxBytesPerElement(DT_INT8),\n            BytesPerElementHelper<int8>(-1));\n  EXPECT_EQ(TensorSliceWriter::MaxBytesPerElement(DT_INT16),\n            BytesPerElementHelper<int16>(-1));\n  EXPECT_EQ(TensorSliceWriter::MaxBytesPerElement(DT_QINT8),\n            BytesPerElementHelper<qint8>(-1));\n  EXPECT_EQ(TensorSliceWriter::MaxBytesPerElement(DT_QUINT8),\n            BytesPerElementHelper<quint8>(std::numeric_limits<uint8>::max()));\n  EXPECT_EQ(TensorSliceWriter::MaxBytesPerElement(DT_QINT32),\n            BytesPerElementHelper<qint32>(-1));\n  EXPECT_EQ(TensorSliceWriter::MaxBytesPerElement(DT_HALF),\n            BytesPerElementHelper<Eigen::half>(Eigen::half(-1.0)));\n}\n\nTEST(TensorSliceWriteTest, SizeErrors) {\n  const string filename = io::JoinPath(testing::TmpDir(), \"checkpoint\");\n\n  TensorSliceWriter writer(filename, CreateTableTensorSliceBuilder);\n\n  // Add a 300MB int8 tensor slice, which will fail because it expands to 3GB.\n  {\n    TensorShape shape({300, 1000000});\n    TensorSlice slice = TensorSlice::ParseOrDie(\"-:-\");\n    const std::vector<int8> data(300000000, -1);\n    Status s = writer.Add(\"test1\", shape, slice, data.data());\n    EXPECT_EQ(s.code(), error::INVALID_ARGUMENT);\n    EXPECT_TRUE(absl::StrContains(s.error_message(),\n                                  \"Tensor slice is too large to serialize\"));\n  }\n\n  // Add a large string tensor slice, which will fail.\n  {\n    TensorShape shape({256, 1024});\n    TensorSlice slice = TensorSlice::ParseOrDie(\"-:-\");\n    const std::vector<tstring> data(256 * 1024, std::string(8192, 'f'));\n    Status s = writer.Add(\"test2\", shape, slice, data.data());\n    EXPECT_EQ(s.code(), error::INVALID_ARGUMENT);\n    EXPECT_TRUE(absl::StrContains(s.error_message(),\n                                  \"Tensor slice is too large to serialize\"));\n  }\n}\n\nTEST(TensorSliceWriterTest, InvalidInput) {\n  SavedSlice ss;\n  std::array<uint32_t, 1> data;\n  std::fill(data.begin(), data.end(), 1234);\n  Status s = TensorSliceWriter::SaveData(data.data(), data.size(), &ss);\n  EXPECT_EQ(s.code(), error::INVALID_ARGUMENT);\n  EXPECT_TRUE(absl::StrContains(\n      s.error_message(),\n      \"Tensor slice serialization not implemented for dtype\"));\n}\n\n}  // namespace checkpoint\n\n}  // namespace tensorflow\n"], "filenames": ["tensorflow/core/util/tensor_slice_writer.cc", "tensorflow/core/util/tensor_slice_writer.h", "tensorflow/core/util/tensor_slice_writer_test.cc"], "buggy_code_start_loc": [133, 70, 17], "buggy_code_end_loc": [176, 168, 364], "fixing_code_start_loc": [134, 71, 18], "fixing_code_end_loc": [185, 176, 378], "type": "CWE-617", "message": "TensorFlow is an open source platform for machine learning. If `Save` or `SaveSlices` is run over tensors of an unsupported `dtype`, it results in a `CHECK` fail that can be used to trigger a denial of service attack. We have patched the issue in GitHub commit 5dd7b86b84a864b834c6fa3d7f9f51c87efa99d4. The fix will be included in TensorFlow 2.10.0. We will also cherrypick this commit on TensorFlow 2.9.1, TensorFlow 2.8.1, and TensorFlow 2.7.2, as these are also affected and still in supported range. There are no known workarounds for this issue.", "other": {"cve": {"id": "CVE-2022-35983", "sourceIdentifier": "security-advisories@github.com", "published": "2022-09-16T22:15:11.303", "lastModified": "2022-09-20T14:53:35.177", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "TensorFlow is an open source platform for machine learning. If `Save` or `SaveSlices` is run over tensors of an unsupported `dtype`, it results in a `CHECK` fail that can be used to trigger a denial of service attack. We have patched the issue in GitHub commit 5dd7b86b84a864b834c6fa3d7f9f51c87efa99d4. The fix will be included in TensorFlow 2.10.0. We will also cherrypick this commit on TensorFlow 2.9.1, TensorFlow 2.8.1, and TensorFlow 2.7.2, as these are also affected and still in supported range. There are no known workarounds for this issue."}, {"lang": "es", "value": "TensorFlow es una plataforma de c\u00f3digo abierto para el aprendizaje autom\u00e1tico. Si \"Save\" o \"SaveSlices\" es ejecutado sobre tensores de un \"dtype\" no soportado, resulta en un fallo de \"CHECK\" que puede ser usado para desencadenar un ataque de denegaci\u00f3n de servicio. Hemos parcheado el problema en el commit 5dd7b86b84a864b834c6fa3d7f9f51c87efa99d4 de GitHub. La correcci\u00f3n ser\u00e1 incluida en TensorFlow versi\u00f3n 2.10.0. Tambi\u00e9n seleccionaremos este compromiso en TensorFlow versi\u00f3n 2.9.1, TensorFlow versi\u00f3n 2.8.1, y TensorFlow versi\u00f3n 2.7.2, ya que estos tambi\u00e9n est\u00e1n afectados y todav\u00eda est\u00e1n en el rango admitido. No se presentan mitigaciones conocidas para este problema"}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 7.5, "baseSeverity": "HIGH"}, "exploitabilityScore": 3.9, "impactScore": 3.6}, {"source": "security-advisories@github.com", "type": "Secondary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:H/PR:N/UI:N/S:U/C:N/I:N/A:H", "attackVector": "NETWORK", "attackComplexity": "HIGH", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 5.9, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 2.2, "impactScore": 3.6}]}, "weaknesses": [{"source": "security-advisories@github.com", "type": "Primary", "description": [{"lang": "en", "value": "CWE-617"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:*:*:*:*:*:*:*:*", "versionEndExcluding": "2.7.2", "matchCriteriaId": "C6622D95-1C86-45C5-AB55-E6EEEA0996DF"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:*:*:*:*:*:*:*:*", "versionStartIncluding": "2.8.0", "versionEndExcluding": "2.8.1", "matchCriteriaId": "0F9D273D-02DC-441E-AA91-EAC8DEAA4B44"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:*:*:*:*:*:*:*:*", "versionStartIncluding": "2.9.0", "versionEndExcluding": "2.9.1", "matchCriteriaId": "FE4F8A81-6CC2-4F7F-9602-C170FDD926E7"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:2.10:rc0:*:*:*:*:*:*", "matchCriteriaId": "1DBFBCE2-0A01-4575-BE45-6775ABFB8B28"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:2.10:rc1:*:*:*:*:*:*", "matchCriteriaId": "89806CF9-E423-4CA6-A01A-8175C260CB24"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:2.10:rc2:*:*:*:*:*:*", "matchCriteriaId": "F2B80690-A257-4E16-BD27-9AE045BC56ED"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:2.10:rc3:*:*:*:*:*:*", "matchCriteriaId": "F335F9A4-5AB8-4E53-BC18-E01F7C653E5E"}]}]}], "references": [{"url": "https://github.com/tensorflow/tensorflow/commit/5dd7b86b84a864b834c6fa3d7f9f51c87efa99d4", "source": "security-advisories@github.com", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-m6vp-8q9j-whx4", "source": "security-advisories@github.com", "tags": ["Third Party Advisory"]}]}, "github_commit_url": "https://github.com/tensorflow/tensorflow/commit/5dd7b86b84a864b834c6fa3d7f9f51c87efa99d4"}}
{"buggy_code": ["//\n// Copyright 2021 The Sigstore Authors.\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage app\n\nimport (\n\t\"fmt\"\n\t\"net/http\"\n\t\"net/http/pprof\"\n\t\"os\"\n\t\"time\"\n\n\thomedir \"github.com/mitchellh/go-homedir\"\n\t\"github.com/sigstore/rekor/pkg/log\"\n\t\"github.com/spf13/cobra\"\n\t\"github.com/spf13/viper\"\n)\n\nvar (\n\tcfgFile     string\n\tlogType     string\n\tenablePprof bool\n\t// these map to the operationId as defined in openapi.yaml file\n\toperationIds = []string{\n\t\t\"searchIndex\",\n\t\t\"getLogInfo\",\n\t\t\"getPublicKey\",\n\t\t\"getLogProof\",\n\t\t\"createLogEntry\",\n\t\t\"getLogEntryByIndex\",\n\t\t\"getLogEntryByUUID\",\n\t\t\"searchLogQuery\",\n\t}\n)\n\n// rootCmd represents the base command when called without any subcommands\nvar rootCmd = &cobra.Command{\n\tUse:   \"rekor-server\",\n\tShort: \"Rekor signature transparency log server\",\n\tLong: `Rekor fulfills the signature transparency role of sigstore's software\n\tsigning infrastructure. It can also be run on its own and is designed to be\n\textensible to work with different manifest schemas and PKI tooling`,\n\t// Uncomment the following line if your bare application\n\t// has an action associated with it:\n\t//\tRun: func(cmd *cobra.Command, args []string) { },\n}\n\n// Execute adds all child commands to the root command and sets flags appropriately.\n// This is called by main.main(). It only needs to happen once to the rootCmd.\nfunc Execute() {\n\tif err := rootCmd.Execute(); err != nil {\n\t\tlog.Logger.Error(err)\n\t\tos.Exit(1)\n\t}\n}\n\nfunc init() {\n\tcobra.OnInitialize(initConfig)\n\n\trootCmd.PersistentFlags().StringVar(&cfgFile, \"config\", \"\", \"config file (default is $HOME/.rekor-server.yaml)\")\n\trootCmd.PersistentFlags().StringVar(&logType, \"log_type\", \"dev\", \"logger type to use (dev/prod)\")\n\trootCmd.PersistentFlags().BoolVar(&enablePprof, \"enable_pprof\", false, \"enable pprof for profiling on port 6060\")\n\trootCmd.PersistentFlags().Bool(\"enable_killswitch\", false, \"enable killswitch for TESTING ONLY on port 2345\")\n\t_ = rootCmd.PersistentFlags().MarkHidden(\"enable_killswitch\")\n\n\trootCmd.PersistentFlags().String(\"trillian_log_server.address\", \"127.0.0.1\", \"Trillian log server address\")\n\trootCmd.PersistentFlags().Uint16(\"trillian_log_server.port\", 8090, \"Trillian log server port\")\n\trootCmd.PersistentFlags().Uint(\"trillian_log_server.tlog_id\", 0, \"Trillian tree id\")\n\trootCmd.PersistentFlags().String(\"trillian_log_server.sharding_config\", \"\", \"path to config file for inactive shards, in JSON or YAML\")\n\n\thostname, err := os.Hostname()\n\tif err != nil {\n\t\thostname = \"localhost\"\n\t}\n\trootCmd.PersistentFlags().String(\"rekor_server.hostname\", hostname, \"public hostname of instance\")\n\trootCmd.PersistentFlags().String(\"rekor_server.address\", \"127.0.0.1\", \"Address to bind to\")\n\n\trootCmd.PersistentFlags().String(\"rekor_server.signer\", \"memory\",\n\t\t`Rekor signer to use. Valid options are: [gcpkms, memory, filename containing PEM encoded private key].\nMemory and file-based signers should only be used for testing.`)\n\trootCmd.PersistentFlags().String(\"rekor_server.signer-passwd\", \"\", \"Password to decrypt signer private key\")\n\n\trootCmd.PersistentFlags().Uint16(\"port\", 3000, \"Port to bind to\")\n\n\trootCmd.PersistentFlags().Bool(\"enable_retrieve_api\", true, \"enables Redis-based index API endpoint\")\n\t_ = rootCmd.PersistentFlags().MarkDeprecated(\"enable_retrieve_api\", \"this flag is deprecated in favor of enabled_api_endpoints (searchIndex)\")\n\trootCmd.PersistentFlags().String(\"redis_server.address\", \"127.0.0.1\", \"Redis server address\")\n\trootCmd.PersistentFlags().Uint16(\"redis_server.port\", 6379, \"Redis server port\")\n\n\trootCmd.PersistentFlags().Bool(\"enable_attestation_storage\", false, \"enables rich attestation storage\")\n\trootCmd.PersistentFlags().String(\"attestation_storage_bucket\", \"\", \"url for attestation storage bucket\")\n\trootCmd.PersistentFlags().Int(\"max_attestation_size\", 100*1024, \"max size for attestation storage, in bytes\")\n\n\trootCmd.PersistentFlags().StringSlice(\"enabled_api_endpoints\", operationIds, \"list of API endpoints to enable using operationId from openapi.yaml\")\n\n\trootCmd.PersistentFlags().Uint64(\"max_request_body_size\", 0, \"maximum size for HTTP request body, in bytes; set to 0 for unlimited\")\n\n\tif err := viper.BindPFlags(rootCmd.PersistentFlags()); err != nil {\n\t\tlog.Logger.Fatal(err)\n\t}\n\n\trootCmd.Flags().BoolP(\"toggle\", \"t\", false, \"Help message for toggle\")\n\n\tlog.Logger.Debugf(\"pprof enabled %v\", enablePprof)\n\t// Enable pprof\n\tif enablePprof {\n\t\tgo func() {\n\t\t\tmux := http.NewServeMux()\n\n\t\t\tmux.HandleFunc(\"/debug/pprof/\", pprof.Index)\n\t\t\tmux.HandleFunc(\"/debug/pprof/{action}\", pprof.Index)\n\t\t\tmux.HandleFunc(\"/debug/pprof/symbol\", pprof.Symbol)\n\n\t\t\tsrv := &http.Server{\n\t\t\t\tAddr:         \":6060\",\n\t\t\t\tReadTimeout:  10 * time.Second,\n\t\t\t\tWriteTimeout: 10 * time.Second,\n\t\t\t\tHandler:      mux,\n\t\t\t}\n\n\t\t\tif err := srv.ListenAndServe(); err != nil && err != http.ErrServerClosed {\n\t\t\t\tlog.Logger.Fatalf(\"Error when starting or running http server: %v\", err)\n\t\t\t}\n\t\t}()\n\t}\n}\n\n// initConfig reads in config file and ENV variables if set.\nfunc initConfig() {\n\tif cfgFile != \"\" {\n\t\t// Use config file from the flag.\n\t\tviper.SetConfigFile(cfgFile)\n\t} else {\n\t\t// Find home directory.\n\t\thome, err := homedir.Dir()\n\t\tif err != nil {\n\t\t\tfmt.Println(err)\n\t\t\tos.Exit(1)\n\t\t}\n\n\t\tviper.AddConfigPath(home)\n\t\tviper.AddConfigPath(\".\")\n\t\tviper.SetConfigName(\"rekor-server\")\n\t\tviper.SetConfigType(\"yaml\")\n\t}\n\n\tviper.AutomaticEnv() // read in environment variables that match\n\n\t// If a config file is found, read it in.\n\tif err := viper.ReadInConfig(); err == nil {\n\t\tlog.Logger.Infof(\"Using config file: %s\", viper.ConfigFileUsed())\n\t}\n}\n", "//\n// Copyright 2021 The Sigstore Authors.\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage alpine\n\nimport (\n\t\"archive/tar\"\n\t\"bufio\"\n\t\"bytes\"\n\t\"compress/gzip\"\n\t\"crypto\"\n\t\"crypto/sha1\" // #nosec G505\n\t\"crypto/sha256\"\n\t\"encoding/hex\"\n\t\"encoding/pem\"\n\t\"errors\"\n\t\"fmt\"\n\t\"hash\"\n\t\"io\"\n\t\"strings\"\n\n\t\"github.com/sigstore/sigstore/pkg/signature\"\n\t\"github.com/sigstore/sigstore/pkg/signature/options\"\n\t\"gopkg.in/ini.v1\"\n)\n\ntype Package struct {\n\tPkginfo           map[string]string // KVP pairs\n\tSignature         []byte\n\tDatahash          []byte\n\tcontrolSHA1Digest []byte\n}\n\ntype sha1Reader struct {\n\tr         *bufio.Reader\n\taddToHash bool\n\thasher    hash.Hash\n}\n\nfunc newSHA1Reader(b *bufio.Reader) *sha1Reader {\n\t// #nosec G401\n\tc := sha1Reader{\n\t\tr:      b,\n\t\thasher: sha1.New(),\n\t}\n\treturn &c\n}\n\nfunc (s *sha1Reader) Read(p []byte) (int, error) {\n\tn, err := s.r.Read(p)\n\tif err == nil && n > 0 && s.addToHash {\n\t\ts.hasher.Write(p)\n\t}\n\treturn n, err\n}\n\nfunc (s *sha1Reader) ReadByte() (byte, error) {\n\tb, err := s.r.ReadByte()\n\tif err == nil && s.addToHash {\n\t\ts.hasher.Write([]byte{b})\n\t}\n\treturn b, err\n}\n\nfunc (s sha1Reader) Sum() []byte {\n\treturn s.hasher.Sum(nil)\n}\n\nfunc (s *sha1Reader) StartHashing() {\n\ts.hasher.Reset()\n\ts.addToHash = true\n}\n\nfunc (s *sha1Reader) StopHashing() {\n\ts.addToHash = false\n}\n\nfunc (p *Package) Unmarshal(pkgReader io.Reader) error {\n\tpkg := Package{}\n\t// bufio.Reader is required if Multistream(false) is used\n\tbufReader := bufio.NewReader(pkgReader)\n\tsha1BufReader := newSHA1Reader(bufReader)\n\tgzipReader, err := gzip.NewReader(sha1BufReader)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"create gzip reader: %w\", err)\n\t}\n\tdefer func() {\n\t\t_ = gzipReader.Close()\n\t}()\n\n\t// APKs are concatenated gzip files so we want to know where the boundary is\n\tgzipReader.Multistream(false)\n\n\t// GZIP headers/footers are left unmodified; Tar footers are removed on first two archives\n\t// signature.tar.gz | control.tar.gz | data.tar.gz\n\tsigBuf := bytes.Buffer{}\n\t// #nosec G110\n\tif _, err := io.Copy(&sigBuf, gzipReader); err != nil {\n\t\treturn fmt.Errorf(\"reading signature.tar.gz: %w\", err)\n\t}\n\n\t// the SHA1 sum used in the signature is over the entire file control.tar.gz so we need to\n\t// intercept the buffered reading to compute the hash correctly\n\t//\n\t// we start sha1 hashing now since the Reset() call will begin reading control.tar.gz headers\n\tsha1BufReader.StartHashing()\n\n\t// we reset the reader since we've found the end of signature.tar.gz\n\tif err := gzipReader.Reset(sha1BufReader); err != nil && err != io.EOF {\n\t\treturn fmt.Errorf(\"resetting to control.tar.gz: %w\", err)\n\t}\n\tgzipReader.Multistream(false)\n\n\tcontrolTar := bytes.Buffer{}\n\t// #nosec G110\n\tif _, err = io.Copy(&controlTar, gzipReader); err != nil {\n\t\treturn fmt.Errorf(\"reading control.tar.gz: %w\", err)\n\t}\n\n\t// signature uses sha1 digest hardcoded in abuild-sign tool\n\tpkg.controlSHA1Digest = sha1BufReader.Sum()\n\tsha1BufReader.StopHashing()\n\n\t// the gzip reader is NOT reset again since that advances the underlying reader\n\t// by reading the next GZIP header, which affects the datahash computation below\n\n\tsigReader := tar.NewReader(&sigBuf)\n\tfor {\n\t\theader, err := sigReader.Next()\n\t\tif err == io.EOF {\n\t\t\tif pkg.Signature == nil {\n\t\t\t\treturn errors.New(\"no signature detected in alpine package\")\n\t\t\t}\n\t\t\tbreak\n\t\t} else if err != nil {\n\t\t\treturn fmt.Errorf(\"getting next entry in tar archive: %w\", err)\n\t\t}\n\n\t\tif strings.HasPrefix(header.Name, \".SIGN\") && pkg.Signature == nil {\n\t\t\tsigBytes := make([]byte, header.Size)\n\t\t\tif _, err = sigReader.Read(sigBytes); err != nil && err != io.EOF {\n\t\t\t\treturn fmt.Errorf(\"reading signature: %w\", err)\n\t\t\t}\n\t\t\t// we're not sure whether this is PEM encoded or not, so handle both cases\n\t\t\tblock, _ := pem.Decode(sigBytes)\n\t\t\tif block == nil {\n\t\t\t\tpkg.Signature = sigBytes\n\t\t\t} else {\n\t\t\t\tpkg.Signature = block.Bytes\n\t\t\t}\n\t\t}\n\t}\n\n\tctlReader := tar.NewReader(&controlTar)\n\tfor {\n\t\theader, err := ctlReader.Next()\n\t\tif err == io.EOF {\n\t\t\tif pkg.Pkginfo == nil {\n\t\t\t\treturn errors.New(\".PKGINFO file was not located\")\n\t\t\t}\n\t\t\tbreak\n\t\t} else if err != nil {\n\t\t\treturn fmt.Errorf(\"getting next entry in tar archive: %w\", err)\n\t\t}\n\n\t\tif header.Name == \".PKGINFO\" {\n\t\t\tpkginfoContent := make([]byte, header.Size)\n\t\t\tif _, err = ctlReader.Read(pkginfoContent); err != nil && err != io.EOF {\n\t\t\t\treturn fmt.Errorf(\"reading .PKGINFO: %w\", err)\n\t\t\t}\n\n\t\t\tpkg.Pkginfo, err = parsePkginfo(pkginfoContent)\n\t\t\tif err != nil {\n\t\t\t\treturn fmt.Errorf(\"parsing .PKGINFO: %w\", err)\n\t\t\t}\n\t\t\tpkg.Datahash, err = hex.DecodeString(pkg.Pkginfo[\"datahash\"])\n\t\t\tif err != nil {\n\t\t\t\treturn fmt.Errorf(\"parsing datahash: %w\", err)\n\t\t\t}\n\t\t}\n\t}\n\n\t// at this point, bufReader should point to first byte of data.tar.gz\n\t// datahash value from .PKGINFO is sha256 sum of data.tar.gz\n\tsha256 := sha256.New()\n\tif _, err := io.Copy(sha256, bufReader); err != nil {\n\t\treturn fmt.Errorf(\"computing SHA256 sum of data.tar.gz: %w\", err)\n\t}\n\tcomputedSum := sha256.Sum(nil)\n\n\tif !bytes.Equal(computedSum, pkg.Datahash) {\n\t\treturn fmt.Errorf(\"checksum for data.tar.gz (%v) does not match value from .PKGINFO (%v)\", hex.EncodeToString(computedSum), hex.EncodeToString(pkg.Datahash))\n\t}\n\t*p = pkg\n\treturn nil\n}\n\n// VerifySignature verifies the signature of the alpine package using the provided\n// public key. It returns an error if verification fails, or nil if it is successful.\nfunc (p Package) VerifySignature(pub crypto.PublicKey) error {\n\tif p.Signature == nil {\n\t\treturn errors.New(\"no signature in alpine package object\")\n\t}\n\tif p.controlSHA1Digest == nil {\n\t\treturn errors.New(\"no digest value for data.tar.gz known\")\n\t}\n\n\tverifier, err := signature.LoadUnsafeVerifier(pub)\n\tif err != nil {\n\t\treturn err\n\t}\n\treturn verifier.VerifySignature(bytes.NewReader(p.Signature), nil, options.WithDigest(p.controlSHA1Digest), options.WithCryptoSignerOpts(crypto.SHA1))\n}\n\n// parsePkginfo parses the .PKGINFO file which is in a\n// key[space]=[space]value\\n\n// format. it returns a map[string]string of the key/value pairs, or\n// an error if parsing could not be completed successfully.\nfunc parsePkginfo(input []byte) (map[string]string, error) {\n\tcfg, err := ini.Load(input)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// .PKGINFO does not use sections, so using \"\" grabs the default values\n\treturn cfg.Section(\"\").KeysHash(), nil\n}\n", "//\n// Copyright 2021 The Sigstore Authors.\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage alpine\n\nimport (\n\t\"os\"\n\t\"testing\"\n\n\t\"github.com/sigstore/rekor/pkg/pki/x509\"\n)\n\nfunc TestAlpinePackage(t *testing.T) {\n\tinputArchive, err := os.Open(\"tests/test_alpine.apk\")\n\tif err != nil {\n\t\tt.Fatalf(\"could not open archive %v\", err)\n\t}\n\n\tp := Package{}\n\terr = p.Unmarshal(inputArchive)\n\tif err != nil {\n\t\tt.Fatalf(\"unmarshal error: %v\", err)\n\t}\n\n\tpubKey, err := os.Open(\"tests/test_alpine.pub\")\n\tif err != nil {\n\t\tt.Fatalf(\"could not open archive %v\", err)\n\t}\n\n\tpub, err := x509.NewPublicKey(pubKey)\n\tif err != nil {\n\t\tt.Fatalf(\"failed to parse public key: %v\", err)\n\t}\n\n\tif err = p.VerifySignature(pub.CryptoPubKey()); err != nil {\n\t\tt.Fatalf(\"signature verification failed: %v\", err)\n\t}\n}\n", "//\n// Copyright 2021 The Sigstore Authors.\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage jar\n\nimport (\n\t\"archive/zip\"\n\t\"bytes\"\n\t\"context\"\n\t\"crypto/sha256\"\n\t\"encoding/hex\"\n\t\"encoding/json\"\n\t\"errors\"\n\t\"fmt\"\n\t\"io\"\n\t\"os\"\n\t\"path\"\n\t\"path/filepath\"\n\t\"strings\"\n\n\t\"github.com/sigstore/rekor/pkg/log\"\n\t\"github.com/sigstore/rekor/pkg/pki\"\n\t\"github.com/sigstore/rekor/pkg/pki/pkcs7\"\n\t\"github.com/sigstore/rekor/pkg/pki/x509\"\n\t\"github.com/sigstore/rekor/pkg/types\"\n\t\"github.com/sigstore/rekor/pkg/types/jar\"\n\t\"github.com/sigstore/rekor/pkg/util\"\n\n\t\"github.com/asaskevich/govalidator\"\n\n\t\"github.com/go-openapi/strfmt\"\n\n\t\"github.com/go-openapi/swag\"\n\tjarutils \"github.com/sassoftware/relic/lib/signjar\"\n\t\"github.com/sigstore/rekor/pkg/generated/models\"\n)\n\nconst (\n\tAPIVERSION = \"0.0.1\"\n)\n\nfunc init() {\n\tif err := jar.VersionMap.SetEntryFactory(APIVERSION, NewEntry); err != nil {\n\t\tlog.Logger.Panic(err)\n\t}\n}\n\ntype V001Entry struct {\n\tJARModel models.JarV001Schema\n}\n\nfunc (v V001Entry) APIVersion() string {\n\treturn APIVERSION\n}\n\nfunc NewEntry() types.EntryImpl {\n\treturn &V001Entry{}\n}\n\nfunc (v *V001Entry) IndexKeys() ([]string, error) {\n\tvar result []string\n\n\tkeyObj, err := pkcs7.NewSignature(bytes.NewReader(v.JARModel.Signature.Content))\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tkey, err := keyObj.CanonicalValue()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tkeyHash := sha256.Sum256(key)\n\tresult = append(result, strings.ToLower(hex.EncodeToString(keyHash[:])))\n\n\tif v.JARModel.Archive.Hash != nil {\n\t\thashKey := strings.ToLower(fmt.Sprintf(\"%s:%s\", *v.JARModel.Archive.Hash.Algorithm, *v.JARModel.Archive.Hash.Value))\n\t\tresult = append(result, hashKey)\n\t}\n\n\treturn result, nil\n}\n\nfunc (v *V001Entry) Unmarshal(pe models.ProposedEntry) error {\n\tjar, ok := pe.(*models.Jar)\n\tif !ok {\n\t\treturn errors.New(\"cannot unmarshal non JAR v0.0.1 type\")\n\t}\n\n\tif err := types.DecodeEntry(jar.Spec, &v.JARModel); err != nil {\n\t\treturn err\n\t}\n\n\t// field validation\n\tif err := v.JARModel.Validate(strfmt.Default); err != nil {\n\t\treturn err\n\t}\n\n\treturn v.validate()\n}\n\nfunc (v *V001Entry) fetchExternalEntities(ctx context.Context) (*pkcs7.PublicKey, *pkcs7.Signature, error) {\n\tif err := v.validate(); err != nil {\n\t\treturn nil, nil, types.ValidationError(err)\n\t}\n\n\toldSHA := \"\"\n\tif v.JARModel.Archive.Hash != nil && v.JARModel.Archive.Hash.Value != nil {\n\t\toldSHA = swag.StringValue(v.JARModel.Archive.Hash.Value)\n\t}\n\n\tdataReadCloser := bytes.NewReader(v.JARModel.Archive.Content)\n\n\thasher := sha256.New()\n\tb := &bytes.Buffer{}\n\n\tn, err := io.Copy(io.MultiWriter(hasher, b), dataReadCloser)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\n\tcomputedSHA := hex.EncodeToString(hasher.Sum(nil))\n\tif oldSHA != \"\" && computedSHA != oldSHA {\n\t\treturn nil, nil, types.ValidationError(fmt.Errorf(\"SHA mismatch: %s != %s\", computedSHA, oldSHA))\n\t}\n\n\tzipReader, err := zip.NewReader(bytes.NewReader(b.Bytes()), n)\n\tif err != nil {\n\t\treturn nil, nil, types.ValidationError(err)\n\t}\n\n\t// this ensures that the JAR is signed and the signature verifies, as\n\t// well as checks that the hashes in the signed manifest are all valid\n\tjarObjs, err := jarutils.Verify(zipReader, false)\n\tif err != nil {\n\t\treturn nil, nil, types.ValidationError(err)\n\t}\n\tswitch len(jarObjs) {\n\tcase 0:\n\t\treturn nil, nil, types.ValidationError(errors.New(\"no signatures detected in JAR archive\"))\n\tcase 1:\n\tdefault:\n\t\treturn nil, nil, types.ValidationError(errors.New(\"multiple signatures detected in JAR; unable to process\"))\n\t}\n\n\t// we need to find and extract the PKCS7 bundle from the JAR file manually\n\tsigPKCS7, err := extractPKCS7SignatureFromJAR(zipReader)\n\tif err != nil {\n\t\treturn nil, nil, types.ValidationError(err)\n\t}\n\n\tkeyObj, err := pkcs7.NewPublicKey(bytes.NewReader(sigPKCS7))\n\tif err != nil {\n\t\treturn nil, nil, types.ValidationError(err)\n\t}\n\n\tsigObj, err := pkcs7.NewSignature(bytes.NewReader(sigPKCS7))\n\tif err != nil {\n\t\treturn nil, nil, types.ValidationError(err)\n\t}\n\n\t// if we get here, all goroutines succeeded without error\n\tif oldSHA == \"\" {\n\t\tv.JARModel.Archive.Hash = &models.JarV001SchemaArchiveHash{\n\t\t\tAlgorithm: swag.String(models.JarV001SchemaArchiveHashAlgorithmSha256),\n\t\t\tValue:     swag.String(computedSHA),\n\t\t}\n\n\t}\n\n\treturn keyObj, sigObj, nil\n}\n\nfunc (v *V001Entry) Canonicalize(ctx context.Context) ([]byte, error) {\n\tkeyObj, sigObj, err := v.fetchExternalEntities(ctx)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// need to canonicalize key content\n\tkeyContent, err := keyObj.CanonicalValue()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tsigContent, err := sigObj.CanonicalValue()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tcanonicalEntry := models.JarV001Schema{\n\t\tSignature: &models.JarV001SchemaSignature{\n\t\t\tPublicKey: &models.JarV001SchemaSignaturePublicKey{\n\t\t\t\tContent: (*strfmt.Base64)(&keyContent),\n\t\t\t},\n\t\t\tContent: sigContent,\n\t\t},\n\t\tArchive: &models.JarV001SchemaArchive{\n\t\t\tHash: &models.JarV001SchemaArchiveHash{\n\t\t\t\tAlgorithm: v.JARModel.Archive.Hash.Algorithm,\n\t\t\t\tValue:     v.JARModel.Archive.Hash.Value,\n\t\t\t},\n\t\t},\n\t}\n\t// archive content is not set deliberately\n\n\tv.JARModel = canonicalEntry\n\t// wrap in valid object with kind and apiVersion set\n\tjar := models.Jar{}\n\tjar.APIVersion = swag.String(APIVERSION)\n\tjar.Spec = &canonicalEntry\n\n\treturn json.Marshal(&jar)\n}\n\n// validate performs cross-field validation for fields in object\nfunc (v *V001Entry) validate() error {\n\tarchive := v.JARModel.Archive\n\tif archive == nil {\n\t\treturn errors.New(\"missing package\")\n\t}\n\n\t// if the signature isn't present, then we need content to extract\n\tif v.JARModel.Signature == nil || v.JARModel.Signature.Content == nil {\n\t\tif len(archive.Content) == 0 {\n\t\t\treturn errors.New(\"'content' must be specified for package\")\n\t\t}\n\t}\n\n\thash := archive.Hash\n\tif hash != nil {\n\t\tif !govalidator.IsHash(swag.StringValue(hash.Value), swag.StringValue(hash.Algorithm)) {\n\t\t\treturn errors.New(\"invalid value for hash\")\n\t\t}\n\t}\n\n\treturn nil\n}\n\n// extractPKCS7SignatureFromJAR extracts the first signature file from the JAR and returns it\nfunc extractPKCS7SignatureFromJAR(inz *zip.Reader) ([]byte, error) {\n\tfor _, f := range inz.File {\n\t\tdir, name := path.Split(strings.ToUpper(f.Name))\n\t\tif dir != \"META-INF/\" || name == \"\" {\n\t\t\tcontinue\n\t\t}\n\t\ti := strings.LastIndex(name, \".\")\n\t\tif i < 0 {\n\t\t\tcontinue\n\t\t}\n\t\tfileExt := name[i:]\n\t\tif fileExt == \".RSA\" || fileExt == \".DSA\" || fileExt == \".EC\" || strings.HasPrefix(name, \"SIG-\") {\n\t\t\tfileReader, err := f.Open()\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\tcontents, err := io.ReadAll(fileReader)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\tif err = fileReader.Close(); err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\treturn contents, nil\n\t\t}\n\t}\n\treturn nil, errors.New(\"unable to locate signature in JAR file\")\n}\n\nfunc (v *V001Entry) CreateFromArtifactProperties(ctx context.Context, props types.ArtifactProperties) (models.ProposedEntry, error) {\n\treturnVal := models.Jar{}\n\tre := V001Entry{}\n\n\t// we will need only the artifact; public-key & signature are embedded in JAR\n\tre.JARModel = models.JarV001Schema{}\n\tre.JARModel.Archive = &models.JarV001SchemaArchive{}\n\n\tvar err error\n\tartifactBytes := props.ArtifactBytes\n\tif artifactBytes == nil {\n\t\tvar artifactReader io.ReadCloser\n\t\tif props.ArtifactPath == nil {\n\t\t\treturn nil, errors.New(\"path to artifact file must be specified\")\n\t\t}\n\t\tif props.ArtifactPath.IsAbs() {\n\t\t\tartifactReader, err = util.FileOrURLReadCloser(ctx, props.ArtifactPath.String(), nil)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, fmt.Errorf(\"error reading JAR file: %w\", err)\n\t\t\t}\n\t\t} else {\n\t\t\tartifactReader, err = os.Open(filepath.Clean(props.ArtifactPath.Path))\n\t\t\tif err != nil {\n\t\t\t\treturn nil, fmt.Errorf(\"error opening JAR file: %w\", err)\n\t\t\t}\n\t\t}\n\t\tartifactBytes, err = io.ReadAll(artifactReader)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"error reading JAR file: %w\", err)\n\t\t}\n\t}\n\tre.JARModel.Archive.Content = (strfmt.Base64)(artifactBytes)\n\n\tif err := re.validate(); err != nil {\n\t\treturn nil, err\n\t}\n\n\tif _, _, err := re.fetchExternalEntities(ctx); err != nil {\n\t\treturn nil, fmt.Errorf(\"error retrieving external entities: %v\", err)\n\t}\n\n\treturnVal.APIVersion = swag.String(re.APIVersion())\n\treturnVal.Spec = re.JARModel\n\n\treturn &returnVal, nil\n}\n\nfunc (v V001Entry) Verifier() (pki.PublicKey, error) {\n\tif v.JARModel.Signature == nil || v.JARModel.Signature.PublicKey == nil || v.JARModel.Signature.PublicKey.Content == nil {\n\t\treturn nil, errors.New(\"jar v0.0.1 entry not initialized\")\n\t}\n\treturn x509.NewPublicKey(bytes.NewReader(*v.JARModel.Signature.PublicKey.Content))\n}\n", "//\n// Copyright 2021 The Sigstore Authors.\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage jar\n\nimport (\n\t\"bytes\"\n\t\"context\"\n\t\"os\"\n\t\"reflect\"\n\t\"testing\"\n\n\t\"github.com/go-openapi/runtime\"\n\t\"github.com/go-openapi/strfmt\"\n\t\"github.com/go-openapi/swag\"\n\t\"github.com/sigstore/rekor/pkg/generated/models\"\n\t\"github.com/sigstore/rekor/pkg/types\"\n\t\"go.uber.org/goleak\"\n)\n\nfunc TestMain(m *testing.M) {\n\tgoleak.VerifyTestMain(m)\n}\n\nfunc TestNewEntryReturnType(t *testing.T) {\n\tentry := NewEntry()\n\tif reflect.TypeOf(entry) != reflect.ValueOf(&V001Entry{}).Type() {\n\t\tt.Errorf(\"invalid type returned from NewEntry: %T\", entry)\n\t}\n}\n\nfunc TestCrossFieldValidation(t *testing.T) {\n\ttype TestCase struct {\n\t\tcaseDesc                  string\n\t\tentry                     V001Entry\n\t\texpectUnmarshalSuccess    bool\n\t\texpectCanonicalizeSuccess bool\n\t\texpectedVerifierSuccess   bool\n\t}\n\n\tjarBytes, _ := os.ReadFile(\"tests/test.jar\")\n\t// extracted from jar\n\tcertificate := `-----BEGIN CERTIFICATE-----\nMIIB+DCCAX6gAwIBAgITNVkDZoCiofPDsy7dfm6geLbuhzAKBggqhkjOPQQDAzAq\nMRUwEwYDVQQKEwxzaWdzdG9yZS5kZXYxETAPBgNVBAMTCHNpZ3N0b3JlMB4XDTIx\nMDMwNzAzMjAyOVoXDTMxMDIyMzAzMjAyOVowKjEVMBMGA1UEChMMc2lnc3RvcmUu\nZGV2MREwDwYDVQQDEwhzaWdzdG9yZTB2MBAGByqGSM49AgEGBSuBBAAiA2IABLSy\nA7Ii5k+pNO8ZEWY0ylemWDowOkNa3kL+GZE5Z5GWehL9/A9bRNA3RbrsZ5i0Jcas\ntaRL7Sp5fp/jD5dxqc/UdTVnlvS16an+2Yfswe/QuLolRUCrcOE2+2iA5+tzd6Nm\nMGQwDgYDVR0PAQH/BAQDAgEGMBIGA1UdEwEB/wQIMAYBAf8CAQEwHQYDVR0OBBYE\nFMjFHQBBmiQpMlEk6w2uSu1KBtPsMB8GA1UdIwQYMBaAFMjFHQBBmiQpMlEk6w2u\nSu1KBtPsMAoGCCqGSM49BAMDA2gAMGUCMH8liWJfMui6vXXBhjDgY4MwslmN/TJx\nVe/83WrFomwmNf056y1X48F9c4m3a3ozXAIxAKjRay5/aj/jsKKGIkmQatjI8uup\nHr/+CxFvaJWmpYqNkLDGRU+9orzh5hI2RrcuaQ==\n-----END CERTIFICATE-----\n`\n\n\ttestCases := []TestCase{\n\t\t{\n\t\t\tcaseDesc:                \"empty obj\",\n\t\t\tentry:                   V001Entry{},\n\t\t\texpectUnmarshalSuccess:  false,\n\t\t\texpectedVerifierSuccess: false,\n\t\t},\n\t\t{\n\t\t\tcaseDesc: \"empty archive\",\n\t\t\tentry: V001Entry{\n\t\t\t\tJARModel: models.JarV001Schema{\n\t\t\t\t\tArchive: &models.JarV001SchemaArchive{},\n\t\t\t\t},\n\t\t\t},\n\t\t\texpectUnmarshalSuccess:  false,\n\t\t\texpectedVerifierSuccess: false,\n\t\t},\n\t\t{\n\t\t\tcaseDesc: \"archive with inline content\",\n\t\t\tentry: V001Entry{\n\t\t\t\tJARModel: models.JarV001Schema{\n\t\t\t\t\tArchive: &models.JarV001SchemaArchive{\n\t\t\t\t\t\tContent: strfmt.Base64(jarBytes),\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\texpectUnmarshalSuccess:    true,\n\t\t\texpectCanonicalizeSuccess: true,\n\t\t\texpectedVerifierSuccess:   true,\n\t\t},\n\t}\n\n\tfor _, tc := range testCases {\n\t\tv := &V001Entry{}\n\t\tr := models.Jar{\n\t\t\tAPIVersion: swag.String(tc.entry.APIVersion()),\n\t\t\tSpec:       tc.entry.JARModel,\n\t\t}\n\n\t\tif err := v.Unmarshal(&r); (err == nil) != tc.expectUnmarshalSuccess {\n\t\t\tt.Errorf(\"unexpected result in '%v': %v\", tc.caseDesc, err)\n\t\t}\n\t\t// No need to continue here if unmarshal failed\n\t\tif !tc.expectUnmarshalSuccess {\n\t\t\tcontinue\n\t\t}\n\n\t\tb, err := v.Canonicalize(context.TODO())\n\t\tif (err == nil) != tc.expectCanonicalizeSuccess {\n\t\t\tt.Errorf(\"unexpected result from Canonicalize for '%v': %v\", tc.caseDesc, err)\n\t\t} else if err != nil {\n\t\t\tif _, ok := err.(types.ValidationError); !ok {\n\t\t\t\tt.Errorf(\"canonicalize returned an unexpected error that isn't of type types.ValidationError: %v\", err)\n\t\t\t}\n\t\t}\n\t\tif b != nil {\n\t\t\tpe, err := models.UnmarshalProposedEntry(bytes.NewReader(b), runtime.JSONConsumer())\n\t\t\tif err != nil {\n\t\t\t\tt.Errorf(\"unexpected err from Unmarshalling canonicalized entry for '%v': %v\", tc.caseDesc, err)\n\t\t\t}\n\t\t\tif _, err := types.UnmarshalEntry(pe); err != nil {\n\t\t\t\tt.Errorf(\"unexpected err from type-specific unmarshalling for '%v': %v\", tc.caseDesc, err)\n\t\t\t}\n\t\t}\n\n\t\tverifier, err := v.Verifier()\n\t\tif tc.expectedVerifierSuccess {\n\t\t\tif err != nil {\n\t\t\t\tt.Errorf(\"%v: unexpected error, got %v\", tc.caseDesc, err)\n\t\t\t} else {\n\t\t\t\tpub, _ := verifier.CanonicalValue()\n\t\t\t\tif !reflect.DeepEqual(pub, []byte(certificate)) {\n\t\t\t\t\tt.Errorf(\"verifier and public keys do not match: %v, %v\", string(pub), certificate)\n\t\t\t\t}\n\t\t\t}\n\t\t} else {\n\t\t\tif err == nil {\n\t\t\t\ts, _ := verifier.CanonicalValue()\n\t\t\t\tt.Errorf(\"%v: expected error for %v, got %v\", tc.caseDesc, string(s), err)\n\t\t\t}\n\t\t}\n\t}\n}\n"], "fixing_code": ["//\n// Copyright 2021 The Sigstore Authors.\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage app\n\nimport (\n\t\"fmt\"\n\t\"net/http\"\n\t\"net/http/pprof\"\n\t\"os\"\n\t\"time\"\n\n\thomedir \"github.com/mitchellh/go-homedir\"\n\t\"github.com/sigstore/rekor/pkg/log\"\n\t\"github.com/spf13/cobra\"\n\t\"github.com/spf13/viper\"\n)\n\nvar (\n\tcfgFile     string\n\tlogType     string\n\tenablePprof bool\n\t// these map to the operationId as defined in openapi.yaml file\n\toperationIds = []string{\n\t\t\"searchIndex\",\n\t\t\"getLogInfo\",\n\t\t\"getPublicKey\",\n\t\t\"getLogProof\",\n\t\t\"createLogEntry\",\n\t\t\"getLogEntryByIndex\",\n\t\t\"getLogEntryByUUID\",\n\t\t\"searchLogQuery\",\n\t}\n)\n\n// rootCmd represents the base command when called without any subcommands\nvar rootCmd = &cobra.Command{\n\tUse:   \"rekor-server\",\n\tShort: \"Rekor signature transparency log server\",\n\tLong: `Rekor fulfills the signature transparency role of sigstore's software\n\tsigning infrastructure. It can also be run on its own and is designed to be\n\textensible to work with different manifest schemas and PKI tooling`,\n\t// Uncomment the following line if your bare application\n\t// has an action associated with it:\n\t//\tRun: func(cmd *cobra.Command, args []string) { },\n}\n\n// Execute adds all child commands to the root command and sets flags appropriately.\n// This is called by main.main(). It only needs to happen once to the rootCmd.\nfunc Execute() {\n\tif err := rootCmd.Execute(); err != nil {\n\t\tlog.Logger.Error(err)\n\t\tos.Exit(1)\n\t}\n}\n\nfunc init() {\n\tcobra.OnInitialize(initConfig)\n\n\trootCmd.PersistentFlags().StringVar(&cfgFile, \"config\", \"\", \"config file (default is $HOME/.rekor-server.yaml)\")\n\trootCmd.PersistentFlags().StringVar(&logType, \"log_type\", \"dev\", \"logger type to use (dev/prod)\")\n\trootCmd.PersistentFlags().BoolVar(&enablePprof, \"enable_pprof\", false, \"enable pprof for profiling on port 6060\")\n\trootCmd.PersistentFlags().Bool(\"enable_killswitch\", false, \"enable killswitch for TESTING ONLY on port 2345\")\n\t_ = rootCmd.PersistentFlags().MarkHidden(\"enable_killswitch\")\n\n\trootCmd.PersistentFlags().String(\"trillian_log_server.address\", \"127.0.0.1\", \"Trillian log server address\")\n\trootCmd.PersistentFlags().Uint16(\"trillian_log_server.port\", 8090, \"Trillian log server port\")\n\trootCmd.PersistentFlags().Uint(\"trillian_log_server.tlog_id\", 0, \"Trillian tree id\")\n\trootCmd.PersistentFlags().String(\"trillian_log_server.sharding_config\", \"\", \"path to config file for inactive shards, in JSON or YAML\")\n\n\thostname, err := os.Hostname()\n\tif err != nil {\n\t\thostname = \"localhost\"\n\t}\n\trootCmd.PersistentFlags().String(\"rekor_server.hostname\", hostname, \"public hostname of instance\")\n\trootCmd.PersistentFlags().String(\"rekor_server.address\", \"127.0.0.1\", \"Address to bind to\")\n\n\trootCmd.PersistentFlags().String(\"rekor_server.signer\", \"memory\",\n\t\t`Rekor signer to use. Valid options are: [gcpkms, memory, filename containing PEM encoded private key].\nMemory and file-based signers should only be used for testing.`)\n\trootCmd.PersistentFlags().String(\"rekor_server.signer-passwd\", \"\", \"Password to decrypt signer private key\")\n\n\trootCmd.PersistentFlags().Uint16(\"port\", 3000, \"Port to bind to\")\n\n\trootCmd.PersistentFlags().Bool(\"enable_retrieve_api\", true, \"enables Redis-based index API endpoint\")\n\t_ = rootCmd.PersistentFlags().MarkDeprecated(\"enable_retrieve_api\", \"this flag is deprecated in favor of enabled_api_endpoints (searchIndex)\")\n\trootCmd.PersistentFlags().String(\"redis_server.address\", \"127.0.0.1\", \"Redis server address\")\n\trootCmd.PersistentFlags().Uint16(\"redis_server.port\", 6379, \"Redis server port\")\n\n\trootCmd.PersistentFlags().Bool(\"enable_attestation_storage\", false, \"enables rich attestation storage\")\n\trootCmd.PersistentFlags().String(\"attestation_storage_bucket\", \"\", \"url for attestation storage bucket\")\n\trootCmd.PersistentFlags().Int(\"max_attestation_size\", 100*1024, \"max size for attestation storage, in bytes\")\n\n\trootCmd.PersistentFlags().StringSlice(\"enabled_api_endpoints\", operationIds, \"list of API endpoints to enable using operationId from openapi.yaml\")\n\n\trootCmd.PersistentFlags().Uint64(\"max_request_body_size\", 0, \"maximum size for HTTP request body, in bytes; set to 0 for unlimited\")\n\trootCmd.PersistentFlags().Uint64(\"max_jar_metadata_size\", 1048576, \"maximum permitted size for jar META-INF/ files, in bytes; set to 0 for unlimited\")\n\trootCmd.PersistentFlags().Uint64(\"max_apk_metadata_size\", 1048576, \"maximum permitted size for apk .SIGN and .PKGINFO files, in bytes; set to 0 for unlimited\")\n\n\tif err := viper.BindPFlags(rootCmd.PersistentFlags()); err != nil {\n\t\tlog.Logger.Fatal(err)\n\t}\n\n\trootCmd.Flags().BoolP(\"toggle\", \"t\", false, \"Help message for toggle\")\n\n\tlog.Logger.Debugf(\"pprof enabled %v\", enablePprof)\n\t// Enable pprof\n\tif enablePprof {\n\t\tgo func() {\n\t\t\tmux := http.NewServeMux()\n\n\t\t\tmux.HandleFunc(\"/debug/pprof/\", pprof.Index)\n\t\t\tmux.HandleFunc(\"/debug/pprof/{action}\", pprof.Index)\n\t\t\tmux.HandleFunc(\"/debug/pprof/symbol\", pprof.Symbol)\n\n\t\t\tsrv := &http.Server{\n\t\t\t\tAddr:         \":6060\",\n\t\t\t\tReadTimeout:  10 * time.Second,\n\t\t\t\tWriteTimeout: 10 * time.Second,\n\t\t\t\tHandler:      mux,\n\t\t\t}\n\n\t\t\tif err := srv.ListenAndServe(); err != nil && err != http.ErrServerClosed {\n\t\t\t\tlog.Logger.Fatalf(\"Error when starting or running http server: %v\", err)\n\t\t\t}\n\t\t}()\n\t}\n}\n\n// initConfig reads in config file and ENV variables if set.\nfunc initConfig() {\n\tif cfgFile != \"\" {\n\t\t// Use config file from the flag.\n\t\tviper.SetConfigFile(cfgFile)\n\t} else {\n\t\t// Find home directory.\n\t\thome, err := homedir.Dir()\n\t\tif err != nil {\n\t\t\tfmt.Println(err)\n\t\t\tos.Exit(1)\n\t\t}\n\n\t\tviper.AddConfigPath(home)\n\t\tviper.AddConfigPath(\".\")\n\t\tviper.SetConfigName(\"rekor-server\")\n\t\tviper.SetConfigType(\"yaml\")\n\t}\n\n\tviper.AutomaticEnv() // read in environment variables that match\n\n\t// If a config file is found, read it in.\n\tif err := viper.ReadInConfig(); err == nil {\n\t\tlog.Logger.Infof(\"Using config file: %s\", viper.ConfigFileUsed())\n\t}\n}\n", "//\n// Copyright 2021 The Sigstore Authors.\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage alpine\n\nimport (\n\t\"archive/tar\"\n\t\"bufio\"\n\t\"bytes\"\n\t\"compress/gzip\"\n\t\"crypto\"\n\t\"crypto/sha1\" // #nosec G505\n\t\"crypto/sha256\"\n\t\"encoding/hex\"\n\t\"encoding/pem\"\n\t\"errors\"\n\t\"fmt\"\n\t\"hash\"\n\t\"io\"\n\t\"strings\"\n\n\t\"github.com/sigstore/sigstore/pkg/signature\"\n\t\"github.com/sigstore/sigstore/pkg/signature/options\"\n\t\"github.com/spf13/viper\"\n\t\"gopkg.in/ini.v1\"\n)\n\ntype Package struct {\n\tPkginfo           map[string]string // KVP pairs\n\tSignature         []byte\n\tDatahash          []byte\n\tcontrolSHA1Digest []byte\n}\n\ntype sha1Reader struct {\n\tr         *bufio.Reader\n\taddToHash bool\n\thasher    hash.Hash\n}\n\nfunc newSHA1Reader(b *bufio.Reader) *sha1Reader {\n\t// #nosec G401\n\tc := sha1Reader{\n\t\tr:      b,\n\t\thasher: sha1.New(),\n\t}\n\treturn &c\n}\n\nfunc (s *sha1Reader) Read(p []byte) (int, error) {\n\tn, err := s.r.Read(p)\n\tif err == nil && n > 0 && s.addToHash {\n\t\ts.hasher.Write(p)\n\t}\n\treturn n, err\n}\n\nfunc (s *sha1Reader) ReadByte() (byte, error) {\n\tb, err := s.r.ReadByte()\n\tif err == nil && s.addToHash {\n\t\ts.hasher.Write([]byte{b})\n\t}\n\treturn b, err\n}\n\nfunc (s sha1Reader) Sum() []byte {\n\treturn s.hasher.Sum(nil)\n}\n\nfunc (s *sha1Reader) StartHashing() {\n\ts.hasher.Reset()\n\ts.addToHash = true\n}\n\nfunc (s *sha1Reader) StopHashing() {\n\ts.addToHash = false\n}\n\nfunc (p *Package) Unmarshal(pkgReader io.Reader) error {\n\tpkg := Package{}\n\t// bufio.Reader is required if Multistream(false) is used\n\tbufReader := bufio.NewReader(pkgReader)\n\tsha1BufReader := newSHA1Reader(bufReader)\n\tgzipReader, err := gzip.NewReader(sha1BufReader)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"create gzip reader: %w\", err)\n\t}\n\tdefer func() {\n\t\t_ = gzipReader.Close()\n\t}()\n\n\t// APKs are concatenated gzip files so we want to know where the boundary is\n\tgzipReader.Multistream(false)\n\n\t// GZIP headers/footers are left unmodified; Tar footers are removed on first two archives\n\t// signature.tar.gz | control.tar.gz | data.tar.gz\n\tsigBuf := bytes.Buffer{}\n\t// #nosec G110\n\tif _, err := io.Copy(&sigBuf, gzipReader); err != nil {\n\t\treturn fmt.Errorf(\"reading signature.tar.gz: %w\", err)\n\t}\n\n\t// the SHA1 sum used in the signature is over the entire file control.tar.gz so we need to\n\t// intercept the buffered reading to compute the hash correctly\n\t//\n\t// we start sha1 hashing now since the Reset() call will begin reading control.tar.gz headers\n\tsha1BufReader.StartHashing()\n\n\t// we reset the reader since we've found the end of signature.tar.gz\n\tif err := gzipReader.Reset(sha1BufReader); err != nil && err != io.EOF {\n\t\treturn fmt.Errorf(\"resetting to control.tar.gz: %w\", err)\n\t}\n\tgzipReader.Multistream(false)\n\n\tcontrolTar := bytes.Buffer{}\n\t// #nosec G110\n\tif _, err = io.Copy(&controlTar, gzipReader); err != nil {\n\t\treturn fmt.Errorf(\"reading control.tar.gz: %w\", err)\n\t}\n\n\t// signature uses sha1 digest hardcoded in abuild-sign tool\n\tpkg.controlSHA1Digest = sha1BufReader.Sum()\n\tsha1BufReader.StopHashing()\n\n\t// the gzip reader is NOT reset again since that advances the underlying reader\n\t// by reading the next GZIP header, which affects the datahash computation below\n\n\tsigReader := tar.NewReader(&sigBuf)\n\tfor {\n\t\theader, err := sigReader.Next()\n\t\tif err == io.EOF {\n\t\t\tif pkg.Signature == nil {\n\t\t\t\treturn errors.New(\"no signature detected in alpine package\")\n\t\t\t}\n\t\t\tbreak\n\t\t} else if err != nil {\n\t\t\treturn fmt.Errorf(\"getting next entry in tar archive: %w\", err)\n\t\t}\n\n\t\tif strings.HasPrefix(header.Name, \".SIGN\") && pkg.Signature == nil {\n\t\t\tif header.Size < 0 {\n\t\t\t\treturn errors.New(\"negative header size for .SIGN file\")\n\t\t\t}\n\t\t\tif uint64(header.Size) > viper.GetUint64(\"max_apk_metadata_size\") && viper.GetUint64(\"max_apk_metadata_size\") > 0 {\n\t\t\t\treturn fmt.Errorf(\"uncompressed .SIGN file size %d exceeds max allowed size %d\", header.Size, viper.GetUint64(\"max_apk_metadata_size\"))\n\t\t\t}\n\t\t\tsigBytes := make([]byte, header.Size)\n\t\t\tif _, err = sigReader.Read(sigBytes); err != nil && err != io.EOF {\n\t\t\t\treturn fmt.Errorf(\"reading signature: %w\", err)\n\t\t\t}\n\t\t\t// we're not sure whether this is PEM encoded or not, so handle both cases\n\t\t\tblock, _ := pem.Decode(sigBytes)\n\t\t\tif block == nil {\n\t\t\t\tpkg.Signature = sigBytes\n\t\t\t} else {\n\t\t\t\tpkg.Signature = block.Bytes\n\t\t\t}\n\t\t}\n\t}\n\n\tctlReader := tar.NewReader(&controlTar)\n\tfor {\n\t\theader, err := ctlReader.Next()\n\t\tif err == io.EOF {\n\t\t\tif pkg.Pkginfo == nil {\n\t\t\t\treturn errors.New(\".PKGINFO file was not located\")\n\t\t\t}\n\t\t\tbreak\n\t\t} else if err != nil {\n\t\t\treturn fmt.Errorf(\"getting next entry in tar archive: %w\", err)\n\t\t}\n\n\t\tif header.Name == \".PKGINFO\" {\n\t\t\tif header.Size < 0 {\n\t\t\t\treturn errors.New(\"negative header size for .PKGINFO file\")\n\t\t\t}\n\t\t\tif uint64(header.Size) > viper.GetUint64(\"max_apk_metadata_size\") && viper.GetUint64(\"max_apk_metadata_size\") > 0 {\n\t\t\t\treturn fmt.Errorf(\"uncompressed .PKGINFO file size %d exceeds max allowed size %d\", header.Size, viper.GetUint64(\"max_apk_metadata_size\"))\n\t\t\t}\n\t\t\tpkginfoContent := make([]byte, header.Size)\n\t\t\tif _, err = ctlReader.Read(pkginfoContent); err != nil && err != io.EOF {\n\t\t\t\treturn fmt.Errorf(\"reading .PKGINFO: %w\", err)\n\t\t\t}\n\n\t\t\tpkg.Pkginfo, err = parsePkginfo(pkginfoContent)\n\t\t\tif err != nil {\n\t\t\t\treturn fmt.Errorf(\"parsing .PKGINFO: %w\", err)\n\t\t\t}\n\t\t\tpkg.Datahash, err = hex.DecodeString(pkg.Pkginfo[\"datahash\"])\n\t\t\tif err != nil {\n\t\t\t\treturn fmt.Errorf(\"parsing datahash: %w\", err)\n\t\t\t}\n\t\t}\n\t}\n\n\t// at this point, bufReader should point to first byte of data.tar.gz\n\t// datahash value from .PKGINFO is sha256 sum of data.tar.gz\n\tsha256 := sha256.New()\n\tif _, err := io.Copy(sha256, bufReader); err != nil {\n\t\treturn fmt.Errorf(\"computing SHA256 sum of data.tar.gz: %w\", err)\n\t}\n\tcomputedSum := sha256.Sum(nil)\n\n\tif !bytes.Equal(computedSum, pkg.Datahash) {\n\t\treturn fmt.Errorf(\"checksum for data.tar.gz (%v) does not match value from .PKGINFO (%v)\", hex.EncodeToString(computedSum), hex.EncodeToString(pkg.Datahash))\n\t}\n\t*p = pkg\n\treturn nil\n}\n\n// VerifySignature verifies the signature of the alpine package using the provided\n// public key. It returns an error if verification fails, or nil if it is successful.\nfunc (p Package) VerifySignature(pub crypto.PublicKey) error {\n\tif p.Signature == nil {\n\t\treturn errors.New(\"no signature in alpine package object\")\n\t}\n\tif p.controlSHA1Digest == nil {\n\t\treturn errors.New(\"no digest value for data.tar.gz known\")\n\t}\n\n\tverifier, err := signature.LoadUnsafeVerifier(pub)\n\tif err != nil {\n\t\treturn err\n\t}\n\treturn verifier.VerifySignature(bytes.NewReader(p.Signature), nil, options.WithDigest(p.controlSHA1Digest), options.WithCryptoSignerOpts(crypto.SHA1))\n}\n\n// parsePkginfo parses the .PKGINFO file which is in a\n// key[space]=[space]value\\n\n// format. it returns a map[string]string of the key/value pairs, or\n// an error if parsing could not be completed successfully.\nfunc parsePkginfo(input []byte) (map[string]string, error) {\n\tcfg, err := ini.Load(input)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// .PKGINFO does not use sections, so using \"\" grabs the default values\n\treturn cfg.Section(\"\").KeysHash(), nil\n}\n", "//\n// Copyright 2021 The Sigstore Authors.\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage alpine\n\nimport (\n\t\"os\"\n\t\"strings\"\n\t\"testing\"\n\n\t\"github.com/sigstore/rekor/pkg/pki/x509\"\n\t\"github.com/spf13/viper\"\n)\n\nfunc TestAlpinePackage(t *testing.T) {\n\n\tinputArchive, err := os.Open(\"tests/test_alpine.apk\")\n\tif err != nil {\n\t\tt.Fatalf(\"could not open archive %v\", err)\n\t}\n\n\tp := Package{}\n\terr = p.Unmarshal(inputArchive)\n\tif err != nil {\n\t\tt.Fatalf(\"unmarshal error: %v\", err)\n\t}\n\n\tpubKey, err := os.Open(\"tests/test_alpine.pub\")\n\tif err != nil {\n\t\tt.Fatalf(\"could not open archive %v\", err)\n\t}\n\n\tpub, err := x509.NewPublicKey(pubKey)\n\tif err != nil {\n\t\tt.Fatalf(\"failed to parse public key: %v\", err)\n\t}\n\n\tif err = p.VerifySignature(pub.CryptoPubKey()); err != nil {\n\t\tt.Fatalf(\"signature verification failed: %v\", err)\n\t}\n}\n\nfunc TestAlpineMetadataSize(t *testing.T) {\n\tos.Setenv(\"MAX_APK_METADATA_SIZE\", \"10\")\n\tviper.AutomaticEnv()\n\n\tinputArchive, err := os.Open(\"tests/test_alpine.apk\")\n\tif err != nil {\n\t\tt.Fatalf(\"could not open archive %v\", err)\n\t}\n\n\tp := Package{}\n\terr = p.Unmarshal(inputArchive)\n\tif err == nil {\n\t\tt.Fatal(\"expecting metadata too large err\")\n\t}\n\tif !strings.Contains(err.Error(), \"exceeds max allowed size 10\") {\n\t\tt.Fatalf(\"unexpected error %v\", err)\n\t}\n}\n", "//\n// Copyright 2021 The Sigstore Authors.\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage jar\n\nimport (\n\t\"archive/zip\"\n\t\"bytes\"\n\t\"context\"\n\t\"crypto/sha256\"\n\t\"encoding/hex\"\n\t\"encoding/json\"\n\t\"errors\"\n\t\"fmt\"\n\t\"io\"\n\t\"os\"\n\t\"path\"\n\t\"path/filepath\"\n\t\"strings\"\n\n\t\"github.com/sigstore/rekor/pkg/log\"\n\t\"github.com/sigstore/rekor/pkg/pki\"\n\t\"github.com/sigstore/rekor/pkg/pki/pkcs7\"\n\t\"github.com/sigstore/rekor/pkg/pki/x509\"\n\t\"github.com/sigstore/rekor/pkg/types\"\n\t\"github.com/sigstore/rekor/pkg/types/jar\"\n\t\"github.com/sigstore/rekor/pkg/util\"\n\n\t\"github.com/asaskevich/govalidator\"\n\n\t\"github.com/go-openapi/strfmt\"\n\n\t\"github.com/go-openapi/swag\"\n\tjarutils \"github.com/sassoftware/relic/lib/signjar\"\n\t\"github.com/sigstore/rekor/pkg/generated/models\"\n\t\"github.com/spf13/viper\"\n)\n\nconst (\n\tAPIVERSION = \"0.0.1\"\n)\n\nfunc init() {\n\tif err := jar.VersionMap.SetEntryFactory(APIVERSION, NewEntry); err != nil {\n\t\tlog.Logger.Panic(err)\n\t}\n}\n\ntype V001Entry struct {\n\tJARModel models.JarV001Schema\n}\n\nfunc (v V001Entry) APIVersion() string {\n\treturn APIVERSION\n}\n\nfunc NewEntry() types.EntryImpl {\n\treturn &V001Entry{}\n}\n\nfunc (v *V001Entry) IndexKeys() ([]string, error) {\n\tvar result []string\n\n\tkeyObj, err := pkcs7.NewSignature(bytes.NewReader(v.JARModel.Signature.Content))\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tkey, err := keyObj.CanonicalValue()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tkeyHash := sha256.Sum256(key)\n\tresult = append(result, strings.ToLower(hex.EncodeToString(keyHash[:])))\n\n\tif v.JARModel.Archive.Hash != nil {\n\t\thashKey := strings.ToLower(fmt.Sprintf(\"%s:%s\", *v.JARModel.Archive.Hash.Algorithm, *v.JARModel.Archive.Hash.Value))\n\t\tresult = append(result, hashKey)\n\t}\n\n\treturn result, nil\n}\n\nfunc (v *V001Entry) Unmarshal(pe models.ProposedEntry) error {\n\tjar, ok := pe.(*models.Jar)\n\tif !ok {\n\t\treturn errors.New(\"cannot unmarshal non JAR v0.0.1 type\")\n\t}\n\n\tif err := types.DecodeEntry(jar.Spec, &v.JARModel); err != nil {\n\t\treturn err\n\t}\n\n\t// field validation\n\tif err := v.JARModel.Validate(strfmt.Default); err != nil {\n\t\treturn err\n\t}\n\n\treturn v.validate()\n}\n\nfunc (v *V001Entry) fetchExternalEntities(ctx context.Context) (*pkcs7.PublicKey, *pkcs7.Signature, error) {\n\tif err := v.validate(); err != nil {\n\t\treturn nil, nil, types.ValidationError(err)\n\t}\n\n\toldSHA := \"\"\n\tif v.JARModel.Archive.Hash != nil && v.JARModel.Archive.Hash.Value != nil {\n\t\toldSHA = swag.StringValue(v.JARModel.Archive.Hash.Value)\n\t}\n\n\tdataReadCloser := bytes.NewReader(v.JARModel.Archive.Content)\n\n\thasher := sha256.New()\n\tb := &bytes.Buffer{}\n\n\tn, err := io.Copy(io.MultiWriter(hasher, b), dataReadCloser)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\n\tcomputedSHA := hex.EncodeToString(hasher.Sum(nil))\n\tif oldSHA != \"\" && computedSHA != oldSHA {\n\t\treturn nil, nil, types.ValidationError(fmt.Errorf(\"SHA mismatch: %s != %s\", computedSHA, oldSHA))\n\t}\n\n\tzipReader, err := zip.NewReader(bytes.NewReader(b.Bytes()), n)\n\tif err != nil {\n\t\treturn nil, nil, types.ValidationError(err)\n\t}\n\n\t// Checking that uncompressed metadata files are within acceptable bounds before reading into memory.\n\t// Checks match those performed by the relic library in the jarutils.Verify method below. For example,\n\t// the META-INF/MANIFEST.MF is read into memory by the relic lib, but a META-INF/LICENSE file is not.\n\tfor _, f := range zipReader.File {\n\t\tdir, name := path.Split(strings.ToUpper(f.Name))\n\t\tif dir != \"META-INF/\" || name == \"\" || strings.LastIndex(name, \".\") < 0 {\n\t\t\tcontinue\n\t\t}\n\t\tif f.UncompressedSize64 > viper.GetUint64(\"max_jar_metadata_size\") && viper.GetUint64(\"max_jar_metadata_size\") > 0 {\n\t\t\treturn nil, nil, types.ValidationError(\n\t\t\t\tfmt.Errorf(\"uncompressed jar metadata of size %d exceeds max allowed size %d\", f.UncompressedSize64, viper.GetUint64(\"max_jar_metadata_size\")))\n\t\t}\n\t}\n\n\t// this ensures that the JAR is signed and the signature verifies, as\n\t// well as checks that the hashes in the signed manifest are all valid\n\tjarObjs, err := jarutils.Verify(zipReader, false)\n\tif err != nil {\n\t\treturn nil, nil, types.ValidationError(err)\n\t}\n\tswitch len(jarObjs) {\n\tcase 0:\n\t\treturn nil, nil, types.ValidationError(errors.New(\"no signatures detected in JAR archive\"))\n\tcase 1:\n\tdefault:\n\t\treturn nil, nil, types.ValidationError(errors.New(\"multiple signatures detected in JAR; unable to process\"))\n\t}\n\n\t// we need to find and extract the PKCS7 bundle from the JAR file manually\n\tsigPKCS7, err := extractPKCS7SignatureFromJAR(zipReader)\n\tif err != nil {\n\t\treturn nil, nil, types.ValidationError(err)\n\t}\n\n\tkeyObj, err := pkcs7.NewPublicKey(bytes.NewReader(sigPKCS7))\n\tif err != nil {\n\t\treturn nil, nil, types.ValidationError(err)\n\t}\n\n\tsigObj, err := pkcs7.NewSignature(bytes.NewReader(sigPKCS7))\n\tif err != nil {\n\t\treturn nil, nil, types.ValidationError(err)\n\t}\n\n\t// if we get here, all goroutines succeeded without error\n\tif oldSHA == \"\" {\n\t\tv.JARModel.Archive.Hash = &models.JarV001SchemaArchiveHash{\n\t\t\tAlgorithm: swag.String(models.JarV001SchemaArchiveHashAlgorithmSha256),\n\t\t\tValue:     swag.String(computedSHA),\n\t\t}\n\n\t}\n\n\treturn keyObj, sigObj, nil\n}\n\nfunc (v *V001Entry) Canonicalize(ctx context.Context) ([]byte, error) {\n\tkeyObj, sigObj, err := v.fetchExternalEntities(ctx)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// need to canonicalize key content\n\tkeyContent, err := keyObj.CanonicalValue()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tsigContent, err := sigObj.CanonicalValue()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tcanonicalEntry := models.JarV001Schema{\n\t\tSignature: &models.JarV001SchemaSignature{\n\t\t\tPublicKey: &models.JarV001SchemaSignaturePublicKey{\n\t\t\t\tContent: (*strfmt.Base64)(&keyContent),\n\t\t\t},\n\t\t\tContent: sigContent,\n\t\t},\n\t\tArchive: &models.JarV001SchemaArchive{\n\t\t\tHash: &models.JarV001SchemaArchiveHash{\n\t\t\t\tAlgorithm: v.JARModel.Archive.Hash.Algorithm,\n\t\t\t\tValue:     v.JARModel.Archive.Hash.Value,\n\t\t\t},\n\t\t},\n\t}\n\t// archive content is not set deliberately\n\n\tv.JARModel = canonicalEntry\n\t// wrap in valid object with kind and apiVersion set\n\tjar := models.Jar{}\n\tjar.APIVersion = swag.String(APIVERSION)\n\tjar.Spec = &canonicalEntry\n\n\treturn json.Marshal(&jar)\n}\n\n// validate performs cross-field validation for fields in object\nfunc (v *V001Entry) validate() error {\n\tarchive := v.JARModel.Archive\n\tif archive == nil {\n\t\treturn errors.New(\"missing package\")\n\t}\n\n\t// if the signature isn't present, then we need content to extract\n\tif v.JARModel.Signature == nil || v.JARModel.Signature.Content == nil {\n\t\tif len(archive.Content) == 0 {\n\t\t\treturn errors.New(\"'content' must be specified for package\")\n\t\t}\n\t}\n\n\thash := archive.Hash\n\tif hash != nil {\n\t\tif !govalidator.IsHash(swag.StringValue(hash.Value), swag.StringValue(hash.Algorithm)) {\n\t\t\treturn errors.New(\"invalid value for hash\")\n\t\t}\n\t}\n\n\treturn nil\n}\n\n// extractPKCS7SignatureFromJAR extracts the first signature file from the JAR and returns it\nfunc extractPKCS7SignatureFromJAR(inz *zip.Reader) ([]byte, error) {\n\tfor _, f := range inz.File {\n\t\tdir, name := path.Split(strings.ToUpper(f.Name))\n\t\tif dir != \"META-INF/\" || name == \"\" {\n\t\t\tcontinue\n\t\t}\n\t\ti := strings.LastIndex(name, \".\")\n\t\tif i < 0 {\n\t\t\tcontinue\n\t\t}\n\t\tfileExt := name[i:]\n\t\tif fileExt == \".RSA\" || fileExt == \".DSA\" || fileExt == \".EC\" || strings.HasPrefix(name, \"SIG-\") {\n\t\t\tfileReader, err := f.Open()\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\tcontents, err := io.ReadAll(fileReader)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\tif err = fileReader.Close(); err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\treturn contents, nil\n\t\t}\n\t}\n\treturn nil, errors.New(\"unable to locate signature in JAR file\")\n}\n\nfunc (v *V001Entry) CreateFromArtifactProperties(ctx context.Context, props types.ArtifactProperties) (models.ProposedEntry, error) {\n\treturnVal := models.Jar{}\n\tre := V001Entry{}\n\n\t// we will need only the artifact; public-key & signature are embedded in JAR\n\tre.JARModel = models.JarV001Schema{}\n\tre.JARModel.Archive = &models.JarV001SchemaArchive{}\n\n\tvar err error\n\tartifactBytes := props.ArtifactBytes\n\tif artifactBytes == nil {\n\t\tvar artifactReader io.ReadCloser\n\t\tif props.ArtifactPath == nil {\n\t\t\treturn nil, errors.New(\"path to artifact file must be specified\")\n\t\t}\n\t\tif props.ArtifactPath.IsAbs() {\n\t\t\tartifactReader, err = util.FileOrURLReadCloser(ctx, props.ArtifactPath.String(), nil)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, fmt.Errorf(\"error reading JAR file: %w\", err)\n\t\t\t}\n\t\t} else {\n\t\t\tartifactReader, err = os.Open(filepath.Clean(props.ArtifactPath.Path))\n\t\t\tif err != nil {\n\t\t\t\treturn nil, fmt.Errorf(\"error opening JAR file: %w\", err)\n\t\t\t}\n\t\t}\n\t\tartifactBytes, err = io.ReadAll(artifactReader)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"error reading JAR file: %w\", err)\n\t\t}\n\t}\n\tre.JARModel.Archive.Content = (strfmt.Base64)(artifactBytes)\n\n\tif err := re.validate(); err != nil {\n\t\treturn nil, err\n\t}\n\n\tif _, _, err := re.fetchExternalEntities(ctx); err != nil {\n\t\treturn nil, fmt.Errorf(\"error retrieving external entities: %v\", err)\n\t}\n\n\treturnVal.APIVersion = swag.String(re.APIVersion())\n\treturnVal.Spec = re.JARModel\n\n\treturn &returnVal, nil\n}\n\nfunc (v V001Entry) Verifier() (pki.PublicKey, error) {\n\tif v.JARModel.Signature == nil || v.JARModel.Signature.PublicKey == nil || v.JARModel.Signature.PublicKey.Content == nil {\n\t\treturn nil, errors.New(\"jar v0.0.1 entry not initialized\")\n\t}\n\treturn x509.NewPublicKey(bytes.NewReader(*v.JARModel.Signature.PublicKey.Content))\n}\n", "//\n// Copyright 2021 The Sigstore Authors.\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage jar\n\nimport (\n\t\"bytes\"\n\t\"context\"\n\t\"os\"\n\t\"reflect\"\n\t\"strings\"\n\t\"testing\"\n\n\t\"github.com/go-openapi/runtime\"\n\t\"github.com/go-openapi/strfmt\"\n\t\"github.com/go-openapi/swag\"\n\t\"github.com/sigstore/rekor/pkg/generated/models\"\n\t\"github.com/sigstore/rekor/pkg/types\"\n\t\"github.com/spf13/viper\"\n\t\"go.uber.org/goleak\"\n)\n\nfunc TestMain(m *testing.M) {\n\tgoleak.VerifyTestMain(m)\n}\n\nfunc TestNewEntryReturnType(t *testing.T) {\n\tentry := NewEntry()\n\tif reflect.TypeOf(entry) != reflect.ValueOf(&V001Entry{}).Type() {\n\t\tt.Errorf(\"invalid type returned from NewEntry: %T\", entry)\n\t}\n}\n\nfunc TestCrossFieldValidation(t *testing.T) {\n\ttype TestCase struct {\n\t\tcaseDesc                  string\n\t\tentry                     V001Entry\n\t\texpectUnmarshalSuccess    bool\n\t\texpectCanonicalizeSuccess bool\n\t\texpectedVerifierSuccess   bool\n\t}\n\n\tjarBytes, _ := os.ReadFile(\"tests/test.jar\")\n\t// extracted from jar\n\tcertificate := `-----BEGIN CERTIFICATE-----\nMIIB+DCCAX6gAwIBAgITNVkDZoCiofPDsy7dfm6geLbuhzAKBggqhkjOPQQDAzAq\nMRUwEwYDVQQKEwxzaWdzdG9yZS5kZXYxETAPBgNVBAMTCHNpZ3N0b3JlMB4XDTIx\nMDMwNzAzMjAyOVoXDTMxMDIyMzAzMjAyOVowKjEVMBMGA1UEChMMc2lnc3RvcmUu\nZGV2MREwDwYDVQQDEwhzaWdzdG9yZTB2MBAGByqGSM49AgEGBSuBBAAiA2IABLSy\nA7Ii5k+pNO8ZEWY0ylemWDowOkNa3kL+GZE5Z5GWehL9/A9bRNA3RbrsZ5i0Jcas\ntaRL7Sp5fp/jD5dxqc/UdTVnlvS16an+2Yfswe/QuLolRUCrcOE2+2iA5+tzd6Nm\nMGQwDgYDVR0PAQH/BAQDAgEGMBIGA1UdEwEB/wQIMAYBAf8CAQEwHQYDVR0OBBYE\nFMjFHQBBmiQpMlEk6w2uSu1KBtPsMB8GA1UdIwQYMBaAFMjFHQBBmiQpMlEk6w2u\nSu1KBtPsMAoGCCqGSM49BAMDA2gAMGUCMH8liWJfMui6vXXBhjDgY4MwslmN/TJx\nVe/83WrFomwmNf056y1X48F9c4m3a3ozXAIxAKjRay5/aj/jsKKGIkmQatjI8uup\nHr/+CxFvaJWmpYqNkLDGRU+9orzh5hI2RrcuaQ==\n-----END CERTIFICATE-----\n`\n\n\ttestCases := []TestCase{\n\t\t{\n\t\t\tcaseDesc:                \"empty obj\",\n\t\t\tentry:                   V001Entry{},\n\t\t\texpectUnmarshalSuccess:  false,\n\t\t\texpectedVerifierSuccess: false,\n\t\t},\n\t\t{\n\t\t\tcaseDesc: \"empty archive\",\n\t\t\tentry: V001Entry{\n\t\t\t\tJARModel: models.JarV001Schema{\n\t\t\t\t\tArchive: &models.JarV001SchemaArchive{},\n\t\t\t\t},\n\t\t\t},\n\t\t\texpectUnmarshalSuccess:  false,\n\t\t\texpectedVerifierSuccess: false,\n\t\t},\n\t\t{\n\t\t\tcaseDesc: \"archive with inline content\",\n\t\t\tentry: V001Entry{\n\t\t\t\tJARModel: models.JarV001Schema{\n\t\t\t\t\tArchive: &models.JarV001SchemaArchive{\n\t\t\t\t\t\tContent: strfmt.Base64(jarBytes),\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\texpectUnmarshalSuccess:    true,\n\t\t\texpectCanonicalizeSuccess: true,\n\t\t\texpectedVerifierSuccess:   true,\n\t\t},\n\t}\n\n\tfor _, tc := range testCases {\n\t\tv := &V001Entry{}\n\t\tr := models.Jar{\n\t\t\tAPIVersion: swag.String(tc.entry.APIVersion()),\n\t\t\tSpec:       tc.entry.JARModel,\n\t\t}\n\n\t\tif err := v.Unmarshal(&r); (err == nil) != tc.expectUnmarshalSuccess {\n\t\t\tt.Errorf(\"unexpected result in '%v': %v\", tc.caseDesc, err)\n\t\t}\n\t\t// No need to continue here if unmarshal failed\n\t\tif !tc.expectUnmarshalSuccess {\n\t\t\tcontinue\n\t\t}\n\n\t\tb, err := v.Canonicalize(context.TODO())\n\t\tif (err == nil) != tc.expectCanonicalizeSuccess {\n\t\t\tt.Errorf(\"unexpected result from Canonicalize for '%v': %v\", tc.caseDesc, err)\n\t\t} else if err != nil {\n\t\t\tif _, ok := err.(types.ValidationError); !ok {\n\t\t\t\tt.Errorf(\"canonicalize returned an unexpected error that isn't of type types.ValidationError: %v\", err)\n\t\t\t}\n\t\t}\n\t\tif b != nil {\n\t\t\tpe, err := models.UnmarshalProposedEntry(bytes.NewReader(b), runtime.JSONConsumer())\n\t\t\tif err != nil {\n\t\t\t\tt.Errorf(\"unexpected err from Unmarshalling canonicalized entry for '%v': %v\", tc.caseDesc, err)\n\t\t\t}\n\t\t\tif _, err := types.UnmarshalEntry(pe); err != nil {\n\t\t\t\tt.Errorf(\"unexpected err from type-specific unmarshalling for '%v': %v\", tc.caseDesc, err)\n\t\t\t}\n\t\t}\n\n\t\tverifier, err := v.Verifier()\n\t\tif tc.expectedVerifierSuccess {\n\t\t\tif err != nil {\n\t\t\t\tt.Errorf(\"%v: unexpected error, got %v\", tc.caseDesc, err)\n\t\t\t} else {\n\t\t\t\tpub, _ := verifier.CanonicalValue()\n\t\t\t\tif !reflect.DeepEqual(pub, []byte(certificate)) {\n\t\t\t\t\tt.Errorf(\"verifier and public keys do not match: %v, %v\", string(pub), certificate)\n\t\t\t\t}\n\t\t\t}\n\t\t} else {\n\t\t\tif err == nil {\n\t\t\t\ts, _ := verifier.CanonicalValue()\n\t\t\t\tt.Errorf(\"%v: expected error for %v, got %v\", tc.caseDesc, string(s), err)\n\t\t\t}\n\t\t}\n\t}\n}\n\nfunc TestJarMetadataSize(t *testing.T) {\n\ttype TestCase struct {\n\t\tcaseDesc                  string\n\t\tentry                     V001Entry\n\t\texpectUnmarshalSuccess    bool\n\t\texpectCanonicalizeSuccess bool\n\t\texpectedVerifierSuccess   bool\n\t}\n\n\tjarBytes, _ := os.ReadFile(\"tests/test.jar\")\n\n\tos.Setenv(\"MAX_JAR_METADATA_SIZE\", \"10\")\n\tviper.AutomaticEnv()\n\n\tv := V001Entry{\n\t\tJARModel: models.JarV001Schema{\n\t\t\tArchive: &models.JarV001SchemaArchive{\n\t\t\t\tContent: strfmt.Base64(jarBytes),\n\t\t\t},\n\t\t},\n\t}\n\n\tr := models.Jar{\n\t\tAPIVersion: swag.String(v.APIVersion()),\n\t\tSpec:       v.JARModel,\n\t}\n\n\tif err := v.Unmarshal(&r); err != nil {\n\t\tt.Errorf(\"unexpected unmarshal failure: %v\", err)\n\t}\n\n\t_, err := v.Canonicalize(context.TODO())\n\tif err == nil {\n\t\tt.Fatal(\"expecting metadata too large err\")\n\t}\n\tif !strings.Contains(err.Error(), \"exceeds max allowed size 10\") {\n\t\tt.Fatalf(\"unexpected error %v\", err)\n\t}\n}\n"], "filenames": ["cmd/rekor-server/app/root.go", "pkg/types/alpine/apk.go", "pkg/types/alpine/apk_test.go", "pkg/types/jar/v0.0.1/entry.go", "pkg/types/jar/v0.0.1/entry_test.go"], "buggy_code_start_loc": [108, 35, 19, 47, 22], "buggy_code_end_loc": [108, 178, 50, 139, 152], "fixing_code_start_loc": [109, 36, 20, 48, 23], "fixing_code_end_loc": [111, 192, 73, 155, 195], "type": "CWE-770", "message": "Rekor is an open source software supply chain transparency log. Rekor prior to version 1.1.1 may crash due to out of memory (OOM) conditions caused by reading archive metadata files into memory without checking their sizes first. Verification of a JAR file submitted to Rekor can cause an out of memory crash if files within the META-INF directory of the JAR are sufficiently large. Parsing of an APK file submitted to Rekor can cause an out of memory crash if the .SIGN or .PKGINFO files within the APK are sufficiently large. The OOM crash has been patched in Rekor version 1.1.1. There are no known workarounds.", "other": {"cve": {"id": "CVE-2023-30551", "sourceIdentifier": "security-advisories@github.com", "published": "2023-05-08T16:15:09.453", "lastModified": "2023-05-12T16:27:55.070", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "Rekor is an open source software supply chain transparency log. Rekor prior to version 1.1.1 may crash due to out of memory (OOM) conditions caused by reading archive metadata files into memory without checking their sizes first. Verification of a JAR file submitted to Rekor can cause an out of memory crash if files within the META-INF directory of the JAR are sufficiently large. Parsing of an APK file submitted to Rekor can cause an out of memory crash if the .SIGN or .PKGINFO files within the APK are sufficiently large. The OOM crash has been patched in Rekor version 1.1.1. There are no known workarounds."}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 7.5, "baseSeverity": "HIGH"}, "exploitabilityScore": 3.9, "impactScore": 3.6}, {"source": "security-advisories@github.com", "type": "Secondary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 7.5, "baseSeverity": "HIGH"}, "exploitabilityScore": 3.9, "impactScore": 3.6}]}, "weaknesses": [{"source": "security-advisories@github.com", "type": "Primary", "description": [{"lang": "en", "value": "CWE-770"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:linuxfoundation:rekor:*:*:*:*:*:*:*:*", "versionEndExcluding": "1.1.1", "matchCriteriaId": "BE79DBAA-65F4-45F5-AB28-44BDC982EE4F"}]}]}], "references": [{"url": "https://github.com/sigstore/rekor/commit/cf42ace82667025fe128f7a50cf6b4cdff51cc48", "source": "security-advisories@github.com", "tags": ["Patch"]}, {"url": "https://github.com/sigstore/rekor/releases/tag/v1.1.1", "source": "security-advisories@github.com", "tags": ["Release Notes"]}, {"url": "https://github.com/sigstore/rekor/security/advisories/GHSA-2h5h-59f5-c5x9", "source": "security-advisories@github.com", "tags": ["Vendor Advisory"]}]}, "github_commit_url": "https://github.com/sigstore/rekor/commit/cf42ace82667025fe128f7a50cf6b4cdff51cc48"}}